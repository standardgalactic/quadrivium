Lecture Notes in Networks and Systems 27
Ludwik Czaja
Introduction 
to Distributed 
Computer 
Systems
Principles and Features

Lecture Notes in Networks and Systems
Volume 27
Series editor
Janusz Kacprzyk, Polish Academy of Sciences, Warsaw, Poland
e-mail: kacprzyk@ibspan.waw.pl

The
series
“Lecture
Notes
in
Networks
and
Systems”
publishes
the
latest
developments in Networks and Systems—quickly, informally and with high quality.
Original research reported in proceedings and post-proceedings represents the core
of LNNS.
Volumes published in LNNS embrace all aspects and subﬁelds of, as well as
new challenges in, Networks and Systems.
The series contains proceedings and edited volumes in systems and networks,
spanning the areas of Cyber-Physical
Systems, Autonomous Systems, Sensor
Networks, Control Systems, Energy Systems, Automotive Systems, Biological
Systems,
Vehicular
Networking
and
Connected
Vehicles,
Aerospace
Systems,
Automation, Manufacturing, Smart Grids, Nonlinear Systems, Power Systems,
Robotics, Social Systems, Economic Systems and other. Of particular value to both
the contributors and the readership are the short publication timeframe and the
world-wide distribution and exposure which enable both a wide and rapid dissemination
of research output.
The series covers the theory, applications, and perspectives on the state of the art
and future developments relevant to systems and networks, decision making, control,
complex processes and related areas, as embedded in the ﬁelds of interdisciplinary
and applied sciences, engineering, computer science, physics, economics, social, and
life sciences, as well as the paradigms and methodologies behind them.
Advisory Board
Fernando Gomide, Department of Computer Engineering and Automation—DCA, School of
Electrical and Computer Engineering—FEEC, University of Campinas—UNICAMP, São Paulo,
Brazil
e-mail: gomide@dca.fee.unicamp.br
Okyay Kaynak, Department of Electrical and Electronic Engineering, Bogazici University,
Istanbul, Turkey
e-mail: okyay.kaynak@boun.edu.tr
Derong Liu, Department of Electrical and Computer Engineering, University of Illinois at
Chicago, Chicago, USA and
Institute of Automation, Chinese Academy of Sciences, Beijing, China
e-mail: derong@uic.edu
Witold Pedrycz, Department of Electrical and Computer Engineering, University of Alberta,
Alberta, Canada and
Systems Research Institute, Polish Academy of Sciences, Warsaw, Poland
e-mail: wpedrycz@ualberta.ca
Marios M. Polycarpou, KIOS Research Center for Intelligent Systems and
Networks, Department of Electrical and Computer Engineering, University of Cyprus,
Nicosia, Cyprus
e-mail: mpolycar@ucy.ac.cy
Imre J. Rudas, Óbuda University, Budapest Hungary
e-mail: rudas@uni-obuda.hu
Jun Wang, Department of Computer Science, City University of Hong Kong
Kowloon, Hong Kong
e-mail: jwang.cs@cityu.edu.hk
More information about this series at http://www.springer.com/series/15179

Ludwik Czaja
Introduction to Distributed
Computer Systems
Principles and Features
123

Ludwik Czaja
Vistula University
Warsaw
Poland
and
Institute of Informatics
University of Warsaw
Warsaw
Poland
ISSN 2367-3370
ISSN 2367-3389
(electronic)
Lecture Notes in Networks and Systems
ISBN 978-3-319-72022-7
ISBN 978-3-319-72023-4
(eBook)
https://doi.org/10.1007/978-3-319-72023-4
Library of Congress Control Number: 2017959902
© Springer International Publishing AG 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made. The publisher remains neutral with regard to
jurisdictional claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

To Nina and Mateusz

Acknowledgement
I am indebted to my colleagues for encouragement to collect notes of my 12
lectures into a book form, but my special thanks go to Prof. Andrzej Skowron and
Prof. Janusz Kacprzyk for initiation and promoting idea of publication of the book
in Springer-Verlag. Also, Mr. Viju Falgon, a project manager at Scientiﬁc
Publishing Services of Springer who handled the editorial production of the book,
deserves special thanks, being bothered with numerous corrections of my errors and
misprints I noticed during the production process.
Ludwik Czaja
vii

Contents
1
Instruction Execution Cycle and Cooperation of Processes . . . . . . .
1
1.1
Instruction Execution Cycle of Sequential Processor . . . . . . . . . .
1
1.2
Concurrent Execution of Programs in the Language
of Machine Instructions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.3
Mutual Exclusion of Processes; Application of Semaphores . . . .
8
1.4
Synchronous Communication of Processes . . . . . . . . . . . . . . . . .
19
1.5
Asynchronous Communication of Processes . . . . . . . . . . . . . . . .
37
1.6
Synchronous Vector Systems. . . . . . . . . . . . . . . . . . . . . . . . . . .
43
1.7
Some Classiﬁcations of Computer Systems . . . . . . . . . . . . . . . .
47
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
2
Distributed Systems—Objectives, Features, Applications . . . . . . . .
49
2.1
What Systems Do We Consider as Distributed? . . . . . . . . . . . . .
49
2.2
Most Important Objectives of Distributed Systems . . . . . . . . . . .
53
2.2.1
Economy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
2.2.2
Increase of Computing Power . . . . . . . . . . . . . . . . . . . . .
53
2.2.3
Internal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
2.2.4
Reliability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
2.2.5
Independence from Changes of Environment . . . . . . . . . .
55
2.2.6
Flexibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
2.3
Main Features of Distributed Systems . . . . . . . . . . . . . . . . . . . .
56
2.3.1
Resource Sharing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
2.3.2
Openness. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
2.3.3
Transparency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
2.3.4
Scalability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
2.4
Exemplary Memory Connection Structures in Centralized
Multiprocessors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
ix

3
Concurrency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
3.1
Concurrent Execution of Programs . . . . . . . . . . . . . . . . . . . . . .
65
3.2
Deadlock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
3.3
Starvation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
3.4
Mutual Exclusion by Supervisory Server . . . . . . . . . . . . . . . . . .
78
3.5
Mutual Exclusion—Token-Ring Algorithm . . . . . . . . . . . . . . . .
79
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
4
Time, Coordination, Mutual Exclusion Without Supervisory
Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
4.1
Physical Time. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
4.1.1
The Cristian Method of Clock Synchronization
(Cristian 1989) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
4.1.2
The Berkeley Method of Clock Synchronization
(Gusella 1989) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
4.1.3
The Network Time Protocol (NTP) Method of
Synchronization of Clocks (Mills 1991) . . . . . . . . . . . . .
94
4.2
Logical Time: Precedence of Events, Time Compensation,
Timestamps, Logical Clock . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
4.3
Distributed Mutual Exclusion Without External Service for
Processes—A Method Based on Global Timestamps
(Ricart 1981) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
4.4
Distributed Mutual Exclusion Without External Service for
Processes—A Method Based on Vectors of Global Timestamps
(Czaja 2012) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
102
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
117
5
Interprocess Communication. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
119
5.1
Basic Problems of Communication . . . . . . . . . . . . . . . . . . . . . .
119
5.2
Tasks of Communication Protocols—Examples . . . . . . . . . . . . .
121
5.3
Dispatch and Reception. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
124
5.4
Modes of Communication: Synchronous and Asynchronous,
Connection-Oriented and Connectionless, Multicast and
Broadcast, Group Communication . . . . . . . . . . . . . . . . . . . . . . .
127
5.5
Layered Structure of the Set of Communication
Protocols: OSI/RM and ATM . . . . . . . . . . . . . . . . . . . . . . . . . .
133
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
139
6
Remote Procedure Call . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
6.1
Motivations, Problems, Limitations . . . . . . . . . . . . . . . . . . . . . .
141
6.1.1
Different Environments of the Client and Server . . . . . . .
142
6.1.2
Conﬂicts When Using Shared Resources . . . . . . . . . . . . .
143
6.1.3
The Stub . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
6.1.4
The Binder—Finding a Server . . . . . . . . . . . . . . . . . . . .
145
6.1.5
Exceptions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
146
x
Contents

6.1.6
Lost and Repeated Messages . . . . . . . . . . . . . . . . . . . . .
146
6.2
Example of RPC Mechanism Activity . . . . . . . . . . . . . . . . . . . .
147
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
155
7
Failures and Damages in Distributed Systems. . . . . . . . . . . . . . . . .
157
7.1
Chances and Kinds of Failure, Remedial Measures, Fault
Tolerance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
157
7.1.1
Probability of System’s Defective Activity; Expected
Time up to a Breakdown . . . . . . . . . . . . . . . . . . . . . . . .
158
7.1.2
Kinds of Failure and Some Mechanisms of the Fault-
Tolerant Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
159
7.2
Some Problems of Activity Coordination . . . . . . . . . . . . . . . . . .
162
7.2.1
Inﬁnite Cycle of Conﬁrmations—the “Two Army”
Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
162
7.2.2
Reaching Consensus with Fault Tolerance—the
“Byzantine Generals” Problem . . . . . . . . . . . . . . . . . . . .
165
7.3
Election of a New Coordinator Following Detection of the
Damaged . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
173
7.3.1
Bully Algorithm of Election . . . . . . . . . . . . . . . . . . . . . .
173
7.3.2
Ring Algorithm of Election . . . . . . . . . . . . . . . . . . . . . .
177
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
185
8
Distributed Shared Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
187
8.1
Structure, Motivations, Problems, Advantages, Disadvantages . . .
187
8.2
Interleaving Model of System Activity . . . . . . . . . . . . . . . . . . . .
190
8.3
Concurrency of Access Operations to Distributed Shared
Memory, Examples of Sequential and Strict Consistency,
Informal Description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
196
8.4
Events of Initiations and Terminations of Read/Write
Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
210
8.5
Formal Deﬁnitions of Sequential and Strict Consistency . . . . . . .
215
8.6
Some Other Models of Memory Consistency . . . . . . . . . . . . . . .
217
8.6.1
Causal Consistency (Hutto and Ahamad 1990) . . . . . . . .
217
8.6.2
PRAM (Pipelined Random Access Memory)
Consistency (Lipton and Sandberg 1988) . . . . . . . . . . . .
219
8.7
Exemplary Algorithms Realizing Memory Consistency . . . . . . . .
221
8.7.1
Algorithms for Sequential Consistency . . . . . . . . . . . . . .
222
8.7.2
An Algorithm Implementing Causal Consistency for
Computer of Number i . . . . . . . . . . . . . . . . . . . . . . . . . .
223
8.7.3
An Algorithm Implementing PRAM Consistency for
Computer of Number i . . . . . . . . . . . . . . . . . . . . . . . . . .
225
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
Contents
xi

9
The Control Flow During Execution of the Alternating Bit
Protocol Speciﬁed by the Cause-Effect Structure . . . . . . . . . . . . . .
227
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
239
10
Some Mathematical Notions Used in the Previous Chapters . . . . . .
241
10.1 Binary Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
241
10.2 Inﬁnite Series of Real Numbers . . . . . . . . . . . . . . . . . . . . . . . . .
242
10.2.1 D’Alambert (Sufﬁcient) Criterion of Convergence . . . . . .
242
10.2.2 Mertens Theorem on Multiplication of Series . . . . . . . . .
242
10.3 Probability, Independent Events, Random Variable and Its
Expected Value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
244
10.3.1 Basic Notions of Cause-Effect Structures . . . . . . . . . . . . .
246
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
249
Final Remarks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
251
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
255
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
257
xii
Contents

About the Author
Ludwik Czaja obtained his M.Sc., Ph.D., and habilitation degrees from the
University of Warsaw, where he was a professor of informatics at the Faculty of
Mathematics, Informatics, and Mechanics. He spent some years in other universi-
ties, like Carnegie-Mellon, Oxford, Ben-Gurion, Humboldt, as visiting professor or
a research fellow. Now he is a full professor of the Vistula University and professor
emeritus of the University of Warsaw. His work encompasses formal and pro-
gramming languages, compilers, theory of computation, parallel, and distributed
processing.
xiii

Introduction
In the most general meaning, a distributed computer system is identiﬁed with
computer network. There are two problems with this identiﬁcation. One concerns
the word “computer”. Even the origins of such systems encompassed not only
computers but also devices far from being computers, like missile launchers and
other military objects (a brief historical outline is in Chap. 2). Let alone today’s
networks that connect things of professional and everyday usage: one can hardly
say that the so-called intelligent refrigerator is a computer. The other problem
concerns the word “distributed”. The main feature of such architectures is lack of
shared physical memory, where processors intercommunicate by message passing
through data links (channels) of arbitrary length and bandwidth. So, in this
meaning, a motherboard of transputers (Sect. 5.3 in Chap. 5), processors interacting
by data packet exchange inside one machine, all are distributed systems too. But on
the other hand, a computer surrounded by simple terminals for data input and
output, multi-access computer or workstations with direct access to memory of a
mainframe, are systems categorized as not distributed in the aforesaid meaning,
though
distributed
in
the
common
parlance,
because
separated
spatially.
Nonetheless, the distinguishing characteristic of distributed computer systems as the
research and engineering domain, is inter-computer communication by message
passing based on networks. However, the design, technical solutions, and appli-
cation of distributed systems and general (“generic”) networks, are not identical.
The conceptual difference lies in their destination. A distributed system is being
often constructed as a computation environment for speciﬁc class of applications,
for a company of certain activity proﬁle, for a corporation or education center,
whereas a network is a universal tool for data transmission not limited to particular
applications. Thus, the constructional difference consists in software: in (dis-
tributed) operating system and programs on top of it—compilers of programming
languages and diverse applications. But dividing functions of a system into hard-
ware and software is not constitutive from the information processing point of view.
For distributed systems, hardware and software of a network constitute a com-
munication infrastructure. So, presentation of their principles takes into account
some issues of network technology, because design and implementation of
xv

distributed systems exploits solutions elaborated there. The principles concern, for
instance, physical and logical time, coordination of processes (synchronization in
particular), communication, exception handling, fault tolerance, and security of
system’s behavior. More speciﬁc are distributed transactions, scheduling joint
actions of computers, remote procedure call and simulation of distributed shared
memory, giving the user impression of having direct access to huge memory space.
Presentation of these issues, limited to principles, in order not to overshadow them
with technical details, is contained in successive chapters. The details change as the
research and technology develops, the principles remain longer. Therefore, great
many dedicated distributed systems and several of general usage, are not discussed
here. Their presentation would exceed capacity of any book, a few of such projects
are mentioned only in Chap. 2. Emphasis in this book is on objectives of distributed
systems. The objectives determine properties. As the most important is regarded
transparency, that is, hiding the joint usage of resources by multiple users—making
every user imagine to be exclusive one. He/she is to be unaware how and where the
resources and mechanisms of their usage are located: in hardware, operating system
kernels, application libraries, compilers, or runtime systems of programming lan-
guages. From the principles point of view, this is immaterial. In existent distributed
systems, the transparency has been accomplished only to a certain degree, as the
problem of balance of user’s convenience against system’s efﬁciency becomes of
prime importance. However, along with the development of communication
infrastructure and increase of large data sets’ transmission rate, attainment of full
transparency seems realistic. To keep up with the progress in materializing such
ideas, a look through professional writings is indispensable. Their short selection,
quoted in the following chapters, is in the Bibliography.
A presentation of the wide subject matter in a small book requires making
decision regarding its content. Apart from some issues belonging to the mainstream
of network technology and distributed systems outlined here, such topics like
construction of distributed operating systems (including resource naming and
mapping names onto addresses) and security of communication (cryptography in
particular), are beyond this book. They are broad and individual research and
technology branches, enjoying rich and easily available literature. Chapter 9,
however, contains a fairly well-known pattern-protocol “in action” (expressed by a
cause/effect structure diagram; the calculus of cause/effect structures is outlined in
Chap. 10) as a sequence of states which the protocol passes during execution. This
is the so-called alternating bit protocol, which reveals basic features of a certain
category of protocols (its enhanced versions like “sliding window”, “abracadabra”,
became a basis for some existent protocols design).
The book is inspired by a 30-h lecture course on distributed computer systems,
given on the elementary level by the author. It is a handbook, although containing
some monographic elements not published elsewhere, like a protocol described in
Sect. 4.4, formal proofs of some important facts and a method of presentation of
algorithms in action: as sequences of states. Experience shows that students,
especially not professional programmers, easier assimilate essence of algorithmic
constructs presented in action rather than in the form of static descriptions as
xvi
Introduction

programs. Hence, the method of presenting: a short explanation of a construct is
followed by a sequence of states it passes. If these states are regarded as animated
ﬁlm frames, then projection of the ﬁlm illustrates process of execution of the
construct. In accordance with such metaphor, description of a construct (a program)
is a screenplay, while the process—realization of this screenplay on the ﬁlm tape.
Furthermore, using computer for the animated show of the process gives rise to see
it as a live scenery in a slow motion.
Understanding of the following chapters does not require advanced knowledge
in informatics. Sufﬁcient will be familiarity with topics provided in an introductory
course to computer science accompanied by laboratory exercises, and to algorithms
and data structures. The participants acquire there a certain skill in design and
analysis of algorithms, to write them as programs and run on the computer.
Beneﬁcial will also be some knowledge in foundations of operating systems and
computer networks, where pretty much time is devoted to standard communication
protocols, being omitted here as technical realization of principles. Of great
importance is experience in a laboratory teamwork—a practical contact with a kind
of distributed system. However, a certain problem may be noticed. Despite having
acquired these foundations, the students of computer science or engineering, who
begin programming in a high-level language, often exhibit ignorance in knowledge
of structure and activity of a processor on the level of internal machine language,
what is the instruction execution cycle in particular. Yet, many functions of dis-
tributed system are found in ordinary, stand-alone machine, especially with mul-
tiprogram operating system. For instance, communication mechanisms in networks
play a part similar to input/output channels (serviced by protocols too), manage-
ment of concurrent transactions requires actions similar to synchronizing processes
in a sequential multiprogrammed machine, etc. That is why, the ﬁrst chapter con-
tains an outline of sequential machines activity with internal control, where many
mechanisms have counterparts, though signiﬁcantly more sophisticated, in network
systems. The activity of a machine model (also multiprogrammed) with a short set
of typical instructions, as well as a collection of such machines interconnected by
communication channels, has been demonstrated by means of abovementioned
“ﬁlm method”. This visual demonstration should clearly explain principle of
sequential processor’s activity. In Chap. 1, the reader will also ﬁnd example of a
synchronous vector machine “in action”. The presented material is, as usually based
on the principle of von Neumann’s stored program sequential machines. A few
sentences about other principles of information processing, though not yet mate-
rialized in architectures for the public use, are in the ﬁnal remarks of the book.
The question of mathematical description of phenomena appearing in distributed
systems remains. Excessive formalization has been avoided, yet clear presentation
of some issues demanded a formal notation, especially in a few proofs of properties.
To such issues belong, for instance, time (physical and logical), correctness of some
algorithms of distributed mutual exclusion, chances of system failure, unattainable
simultaneity of certain actions, deﬁnition of distributed memory consistency models
and its consequences. Therefore, to express some concepts, facts and proofs,
mathematical language has been used, though in a very modest extent: operations
Introduction
xvii

on sets and relations, partial and linear order, functions, sequences and series,
probability, elementary propositional and predicate calculus. Some of them are
outlined in Chap. 10. Such topics are familiar to everybody who attended intro-
ductory course at mathematical or engineering studies.
xviii
Introduction

Chapter 1
Instruction Execution Cycle
and Cooperation of Processes
1.1
Instruction Execution Cycle of Sequential Processor
This chapter contains an outline of structure and functioning of stand-alone inter-
nally controlled computer with sequential processor, as well as its functioning in a
collection of such machines. The internal control means that program instructions
(commands) and data, encoded (commonly nowadays) as sequences of bits, are
located in the internal memory (RAM) and are fetched by the processor to its
speciﬁc register. A distinction between instructions and data depends on this reg-
ister. If it is the instruction register (IR), the bit sequence is interpreted as instruction
and taken to suitable electronic circuits where it is executed, if another register, e.g.
accumulator (A), it is interpreted as data. This is the so-called stored-program
architecture, devised by von Neumann (1945) with J. W. Mauchly and J. P. Eckert
(in the 1940s), commonly known as the von Neumann’s architecture. The details of
a single instruction execution, that is actions of the electronic circuits, are on the
lower description level than principles of distributed systems, so will not be con-
sidered. Why this book begins with such architecture (a brief note on alternative
concepts of data processing is in the Final Remarks)? The following are some
reasons:
• Multiprocessor and multicomputer distributed system is a set of such machines:
– multiprocessor—a set of processors with common physical memory,
– multicomputer—a set of stand-alone (autonomous) computers without
common physical memory, possibly with diverse architectural details (e.g.
different coding of numbers); the computers are connected by means of
transmission channels and endowed with distributed operating system.
• The objective of the multiprocessor and multicomputer system is to give the
users impression of work on a sequential, autonomous machine of enhanced
performance of algorithms (due to concurrent processing of their parts) and
endowed
with
mechanisms
for
joint
resource
usage,
for
interprocess
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_1
1

communication, for correct cooperation (in particular synchronizing some
actions) between other machines, etc.
• Basic functions of distributed system are similar to those in stand-alone se-
quential machine (Fig. 1.1); for instance, communication mechanisms in a
computer network plays similar part as input/output mechanisms in a sequential
machine, but are signiﬁcant extension of the latter. This extension creates many
problems, absent in sequential machines, where communication proceeds only
between its own internal and external components.
• The book begins with demonstrative execution of simple programs by a model
of sequential von Neumann’s machine and their parallel execution by a col-
lection of such machines, connected by communication channels. Such pre-
sentation visualizes main problems of synchronization and communication in
the real distributed systems.
Instruction execution cycle depicted in Fig. 1.2 is a hardware-implemented al-
gorithm, that is, an automaton, which executes user programs being data for this
algorithm. For this reason, the instruction execution cycle may be called—a
„meta-program”. It is deﬁned by a structure of processor, that is, by its active
components (like transistors) and their connections. The structure is changeless in
processors not being microprogrammed. It can be modiﬁed in the microprogrammed
processors, where useful (for some applications) instructions may be created, that
processor: Central Processing Unit = 
ArithmeƟcal and Logical Unit + control
operaƟng memory (RAM)
coordinaƟng system
data 
transmission
channel 
disk
external device
DMA
(Direct 
Memory 
Access)
data 
transmission
channel 
data 
transmission
channel 
external device
Fig. 1.1 Diagram of main components of a single-processor stand-alone computer; the memory
arbiter, ensuring exclusive access to single memory cell by processor and various external devices,
is usually integrated with DMA controller
2
1
Instruction Execution Cycle and Cooperation …

means a modiﬁcation of the processor’s instruction set. To illustrate by examples,
action of the schematic computer depicted in Fig. 1.2, let us ﬁx the set of a few
instructions, typical in their function for many commercial processors, though—in
their form—freely adopted here for this purpose. Their names of operation part are
shortcuts of their meaning description. For simplicity, they are conﬁned to
one-argument. Their set is in Fig. 1.3. Obviously, commercial processors are
equipped with much broader instruction sets, of more complex functions as, for
instance, ﬁxed-point and ﬂoating-point arithmetic instructions and many more. The
clock, which organizes execution of the instruction cycle, in some architectures is the
processor’s component, whereas in some others is outside the processor. This detail
is immaterial for further exemplary presentation of instruction execution cycle.
Animated (when displayed on screen as consecutive transparencies) execution of
assignment statement x: = y  z + u / v on schematic computer from Fig. 1.2 is
shown in Table 1.1. This is a sequence of states of this computer, numbered 1–17,
during execution of machine instructions stored in the memory cells of addresses 0–7
and variables x, y, z, u, v, temp, allocated in some further memory cells. This sequence
is a process of computing the value of expression y  z + u / v for y = 3.14, z = 2.0,
u = 15.9, v = 3.0 and assigning this value to x. The small horizontal arrow points to
current (in a given state) action of the instruction execution cycle. Considering states
as an animated ﬁlm’s frames, projection of the ﬁlm presents dynamics of execution of
the assignment statement in machine instructions, that is a process of computation.
Admitting this metaphor, one may say that the program is a screenplay, whereas its
realization is the process, recorded on the ﬁlm tape.
Prześlij do
Prześlij do
0         1            2          3           4           5         6         7 ……  20      21        22        23        24      25 
20 
PC:
IR:
A:
other
registers:
RAM
IR := content of address indicated by PC 
instrucƟon execuƟon cycle
external memories 
Input/Output devices;
disk controller; 
cards, e.g. graphics,  
 network, sound, etc. 
external devices
data transmission
channels 
If IR contains instrucƟon of:
..
..
 uncondiƟonal jump then PC:=address part 
condiƟonal jump with saƟsﬁed condiƟon then
PC:=address part else PC:=PC+1
stop then PC:=address part and terminate run
 another then  execute it and PC:=PC+1                     
 processor (CPU = ALU + control and synchronizaƟon)
Fig. 1.2 Functional schema of internally controlled computer with instruction execution cycle;
PC—Program counter, IR—Instruction register, A—Accumulator
1.1
Instruction Execution Cycle of Sequential Processor
3

Although the distributed systems, as understood here, are multicomputer
decentralized systems, they may be implemented by a single computer, in the
so-called multiprogramming mode, realized by the time-sharing of one processor.
This is an interleaving of chunks of concurrent programs, the concept extensively
exploited in Chap. 8 for the real multicomputer systems. Such simulation of mul-
ticomputers is illustrated by Table 1.2, where a single computer, when performing
programs P1, P2, P3, P4, passes states 1–17. The computer is endowed with
instructions of interrupt (suspension) and resumption of processes and a queue of
processes suspended and may be in the following states: “before run”, “run”,
“suspended”, “terminated”. The memory of this computer is shared between the
four programs.
1.2
Concurrent Execution of Programs in the Language
of Machine Instructions
If a number of processes are running simultaneously, either in a single processor
system in the time-sharing mode or by a real multiprocessor system, some conﬂicts
between the processes utilizing shared resources may arise. Such case is illustrated
by Table 1.3—execution of erroneously programmed assignment statement x: =
y  z + u / v by the two-computer system with a shared memory for data. The
computers intercommunicate by a shared variable chan (pretending a communi-
cation channel). Computer 1 sends value y  z to chan, whereas computer 2—value
u / v. The conﬂict arises if both computers are sending these values to variable chan
at the same moment or very close to each other moments. This case occurs in the
LA
n
Load Accumulator with the content of a cell n and go to the next instruction in program 
SA
n
Store the content of Accumulator in a cell n and go to the next instruction in program 
AD
n
ADd to the content of accumulator the content of a cell n and go to the next instruction in program
SU
n
SUbtract from the content of accumulator the content of a cell n and go to the next instruction in program  
MU
n
MUltiply the content of accumulator by the content of a cell n and go to the next instruction in program 
DI
n
DIvide the content of accumulator by the content of a cell n and go to the next instruction in program;  
if the content of n is 0 then report an error 
JU
n
JUmp to the instruction stored in a cell n in program (unconditional jump)
JZ
n
Jump to the instruction stored in a cell n in program if accumulator contains Zero;  
                 otherwise go to the next instruction in program (conditional jump)
JΩ
n
Jump to the instruction stored in a cell n in program if the communication register (chan)
                 contains Ω; otherwise go to the next instruction in program (conditional jump)
ST
n
 go to the instruction stored in a cell n in program and STop activity of program  
ope-
raƟon
add-
ress
meaning of operaƟon
JN
n
Jump to the instruction stored in a cell n in program if accumulator contains Negative value;
                 otherwise go to the next instruction in program (conditional jump)
Fig. 1.3 Simple instruction set
4
1
Instruction Execution Cycle and Cooperation …

Table 1.1 Process of execution of assignment statement x: = y  z + u / v. States 1–17
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
1
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
0
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
2
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
0
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
LA y
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
3
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
1
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
3
LA y
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
4
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
1
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
3
MU z
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
5
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
2
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
SA temp
6
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
6
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
2
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
SA temp
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
7
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
3
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
6
SA temp
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
8
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
3
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
6
LA u
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
9
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
4
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
16
LA u
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
10
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
4
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
16
DI v
(continued)
1.2
Concurrent Execution of Programs in the Language of Machine Instructions
5

state 9 of the execution. It is not known which value will appear in the „channel”
chan: undesirable non-determinism occurs. Notice that if the two values are sent to
variable chan at sufﬁciently distant moments, the result will be correct, however the
programmer may not programm this way, not knowing the temporal relationships
of processes. Usually, the programmer does not know the pace of processes, thus
has to programm so that result of the program execution is independent of their
speed. This is the case of ordinary paradigms, languages and techniques of
programming.
Table 1.1 (continued)
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
11
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
5
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
8
DI v
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
12
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
5
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
8
AD temp
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
13
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
6
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
14
AD temp
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
14
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
6
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2
6
14
SA x
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
15
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
7
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2 14 6
14
SA x
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
16
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
7
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2 14 6
14
ST 0
Prześlij do
y z
u v
x temp
20
PC:
IR:
A:
other registers:
17
IR := content of address indicated by PC
If IR contains instrucƟon of:
• uncondiƟonal jump then PC := address part
• condiƟonal jump with saƟsﬁed condiƟon then
PC := address part else PC := PC+1
• stop then PC := address part and terminate run
• another then execute it and PC := PC+1
0
1
2
3
4
5
6
7
LA y MU z SA temp LA u DI v AD temp SA x ST 0
3 2 16 2 14 6
14
ST 0
0
6
1
Instruction Execution Cycle and Cooperation …

Table 1.2 Activity of a single multiprogrammed computer executing 4 programs in the
timesharing mode. States 1–17
P1: program
Prześlij do
processor
1
before run
P2: program
before run
P3: program
before run
P4: program
before run
queue of suspended
programs:
memory
tail
head
P1: program
Prześlij do
processor
2
before run
P2: program
before run
P3: program
run
P4: program
before run
queue of suspended
programs:
memory
tail
head
P1: program
Prześlij do
processor
3
run
P2: program
before run
P3: program
suspended
P4: program
before run
queue of suspended
programs:
memory
tail
head
P3
P1: program
Prześlij do
processor
4
suspended
P2: program
before run
P3: program
suspended
P4: program
run
queue of suspended
programs:
memory
tail
P3 P1
head
P1: program
Prześlij do
processor
5
suspended
P2: program
run
P3: program
suspended
P4: program
suspended
queue of suspended
programs:
memory
tail
P3 P1
head
P4
P1: program
Prześlij do
processor
6
suspended
P2: program
suspended
P3: program
run
P4: program
suspended
queue of suspended
programs:
memory
tail
P1
head
P4 P2
P1: program
Prześlij do
processor
7
run
P2: program
suspended
P3: program
P4: program
suspended
suspended
queue of suspended
programs:
memory
tail
head
P4 P2 P3
P1: program
Prześlij do
processor
8
P2: program
suspended
P3: program
P4: program
run
suspended
suspended
queue of suspended
programs:
memory
tail
head
P2 P3 P1
P1: program
Prześlij do
processor
9
P2: program
run
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
P1 P4
suspended
P3
suspended
suspended
P1: program
Prześlij do
processor
10
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
P1 P4
run
P2
suspended
suspended
suspended
P1: program
Prześlij do
processor
11
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
P3
P4 P2
run
suspended
suspended
suspended
P1: program
Prześlij do
processor
12
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
P3 P1
P2
run
run
suspended
suspended
P1: program
Prześlij do
processor
13
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
P3 P1
run
terminated
run
suspended
P1: program
Prześlij do
processor
14
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
P2
P1
terminated
suspended
run
suspended
(continued)
1.2
Concurrent Execution of Programs in the Language of Machine Instructions
7

1.3
Mutual Exclusion of Processes; Application
of Semaphores
In order to avoid conﬂicts between processes that use shared resources, some
mechanisms are applied ensuring access to a resource for at most one process at a
time and, after its usage, giving access to this resource for another process. Such
mechanisms implement mutual exclusion of processes, that is determine the
so-called critical section, being a program fragment. In exclusive execution of this
fragment, a protected resource is being used. Let us consider the semaphores as
such mechanism, leaving out others, like TEST&SET, as well as algorithms of
mutual exclusion, for instance the Dekker’s algorithm (published in Dijkstra 1965),
probably the ﬁrst correct solution to this problem. The semaphore, introduced by
the Dutch scientist Dijkstra (1965, 1968), is a variable, that assumes integer values
and is shared by cooperating programs. For further considerations, the semaphores
will be limited to binary ones, that is, they will assume only values 0 and 1.
Permissible operations on semaphores are named P and V, and are of the following
meaning, where sem is a semaphore:
• P(sem): if sem > 0 then sem: = sem −1, and if sem = 0 then suspend the
process
• V(sem): sem: = 1 and resume a certain suspended process (for instance, sus-
pended by the longest time)
The operations are indivisible (atomic): when a certain program performs one of
them, another program cannot perform none of them at the same time. Thus, they
are critical sections themselves, but performed at the lower level than the user’s
programs (for instance by computer hardware or in the kernel of operating system).
In some programming languages, the P operation is named „wait” and V—„signal”
(P and V are the ﬁrst letters of Dutch words “passeren” and “vrijmaken”, meaning
Table 1.2 (continued)
P1: program
Prześlij do
processor
15
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
run
terminated
suspended
terminated
P2
P1: program
Prześlij do
processor
16
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
terminated
run
terminated
terminated
P1: program
Prześlij do
processor
17
P2: program
P3: program
P4: program
queue of suspended
programs:
memory
tail
head
terminated
terminated
terminated
terminated
8
1
Instruction Execution Cycle and Cooperation …

Table 1.3 Beginning of execution of incorrectly programmed assignment statement x: = y  z +
u / v by 2 computers with a shared memory for data. States 1–11
2
PC:
IR:
A:
other registers:
2
1
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
0
1
2
3
4
5
6
7
0
0
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
acƟons of instrucƟon execuƟon cycle
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
acƟons of instrucƟon execuƟon cycle
2
PC:
IR:
A:
other registers:
2
2
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
0
1
2
3
4
5
6
7
0
0
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
LA
A
L
y
u
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
2
PC:
IR:
A:
other registers:
2
3
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
0
1
2
3
4
5
6
7
1
1
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
LA
A
L
y
u
1
3
6
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
2
PC:
IR:
A:
other registers:
2
4
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
0
1
2
3
4
5
6
7
1
1
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
MU z
DI v
1
3
6
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
1.3
Mutual Exclusion of Processes; Application of Semaphores
9

Table 1.3 (continued)
2
PC:
IR:
A:
other registers:
2
5
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
2
2
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
MU z
DI v
8
6
0
1
2
3
4
5
6
7
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
2
PC:
IR:
A:
other registers:
2
6
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
2
2
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
JΩ  
J
6
Ω  6
8
6
0
1
2
3
4
5
6
7
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
2
PC:
IR:
A:
other registers:
2
7
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
2
2
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
acƟons of instrucƟon execuƟon cycle like in Fig.1.2
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
acƟons of instrucƟon execuƟon cycle like in Fig.1.2
JΩ  
J
6
Ω  6
8
6
0
1
2
3
4
5
6
7
2
PC:
IR:
A:
other registers:
2
8
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
6
6
3
2
16
2
chan y
z
u
v
x
Ω
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
SA
A
S
n
a
h
c
chan
8
6
0
1
2
3
4
5
6
7
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
10
1
Instruction Execution Cycle and Cooperation …

“to pass” and “release”). They will be treated as computer’s instructions. The
operations encompass arbitrarily long piece of program where exclusive access to a
resource is performed, in contrast to a hardware device, called a memory arbiter,
which assures exclusive read/write of a single memory cell only. Notice that the
name „semaphore” is taken from the railway terminology, because the semaphore
closes entrance of program (train) to its critical section (occupied track) if another
program is executing critical section which protects the same resource. This is
illustrated in Table 1.4 (with somewhat outdated steam locomotive).
Table 1.3 (continued)
2
PC:
IR:
A:
other registers:
2
9
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
7
7
3
2
16
2
chan y
z
u
v
x
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
SA
A
S
n
a
h
c
chan
8
6
0
1
2
3
4
5
6
7
???
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
2
PC:
IR:
A:
other registers:
2
10
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
7
7
3
2
16
2
chan y
z
u
v
x
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
ST
S
0
T 0
8
6
???
0
1
2
3
4
5
6
7
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
2
PC:
IR:
A:
other registers:
2
11
PC:
IR:
A:
other registers:
computer 1
computer 2
shared data memory
LA y MU z JΩ  6 AD chan SA x ST 0
SA chan ST 0
0
0
3
2
16
2
chan y
z
u
v
x
0
1
2
3
4
5
6
7
local memory of program
IR := content of address indicated by PC
IR := content of address indicated by PC
LA u
DI v JΩ  6 AD chan SA x
ST 0
SA chan ST 0
local memory of program
ST
S
0
T 0
8
6
???
0
1
2
3
4
5
6
7
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
Undetermined value is stored in chan
1.3
Mutual Exclusion of Processes; Application of Semaphores
11

Table 1.5 illustrates an example of a process generated during execution of
correctly programmed assignment statement x: = y  z + u / v, performed by a
system of two computers with shared memory for data. The conﬂict of access to the
„communication channel”, chan, is avoided by using instructions P(sem) and
V(sem). The sem variable is a semaphore protecting critical section between these
instructions. Though the pace (clock frequency) of both computers is similar, notice
that the result of computation is independent of their pace.
Table 1.4 The semaphore precludes to stay both vehicles under the water pump, at the same time
sem = 1
programs
resource
c r i t i c a l s e c t i o n
1
sem = 0
2
sem = 0
3
sem = 0
4
sem = 1
5
sem = 0
6
sem = 0
7
sem = 0
8
sem = 1
9
sem = 1
10
12
1
Instruction Execution Cycle and Cooperation …

Table 1.5 Parallel computation of assignment statement x: = y  z + u / v, using semaphores
1
LA y
MU z P(sem)
JΩ 8 AD chan SA x V(sem) ST 0
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem) ST 0
SA chan V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
0
0
IR := content of address indicated by PC
IR := content of address indicated by PC
acƟons of instrucƟon execuƟon cycle
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
1
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem) ST 0
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
0
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
1
2
LA
A
L
y
u
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
1
1
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
1
3
LA
A
L
y
u
ST 0
3
16
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
1
1
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
1
4
MU
I
D
z
v
ST 0
3
16
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
(continued)
1.3
Mutual Exclusion of Processes; Application of Semaphores
13

0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
2
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
1
5
MU
I
D
z
v
ST 0
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
2
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
1
6
)
m
e
s(
P
)
m
e
s(
P
ST 0
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
3
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
0
7
)
m
e
s(
P
)
m
e
s(
P
ST 0
changed by computer 1
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
3
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
0
8
S 8
P(sem)
ST 0
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
(continued)
Table 1.5 (continued)
14
1
Instruction Execution Cycle and Cooperation …

0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
8
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
0
9
S 8
P(sem)
ST 0
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
8
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
Ω
computer 2
0
10
SA
)
m
e
s(
P
n
a
h
c
ST 0
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
9
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
11
SA
)
m
e
s(
P
n
a
h
c
ST 0
6
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
9
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
12
)
m
e
s(
P
)
m
e
s(
V
ST 0
6
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
Table 1.5 (continued)
(continued)
1.3
Mutual Exclusion of Processes; Application of Semaphores
15

0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
0
1
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
1
13
)
m
e
s(
P
)
m
e
s(
V
ST 0
6
changed by computer 1
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
2
0
1
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
1
14
ST 0
P(sem)
ST 0
6
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
3
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
15
ST 0
P(sem)
ST 0
6
6
changed by computer 2
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
3
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
16
ST 0
S 8
ST 0
6
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
(continued)
Table 1.5 (continued)
16
1
Instruction Execution Cycle and Cooperation …

0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
4
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
17
ST 0
S 8
ST 0
6
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
4
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
18
ST
A
0
D chan
ST 0
6
6
8
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
5
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
19
ST 0
ST 0
6
6
14
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
AD chan
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
5
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
sem chan y
z
u
v
x
computer 2
0
20
ST
S
0
A x
ST 0
6
6
14
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
(continued)
Table 1.5 (continued)
1.3
Mutual Exclusion of Processes; Application of Semaphores
17

0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
6
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
14
sem chan y
z
u
v
x
computer 2
0
21
ST
S
0
A x
ST 0
6
6
14
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
6
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
14
sem chan y
z
u
v
x
computer 2
0
22
ST 0
V(sem)
ST 0
6
6
14
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
7
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
14
sem chan y
z
u
v
x
computer 2
1
23
ST 0
V(sem)
ST 0
6
6
14
changed by computer 2
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
7
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
14
sem chan y
z
u
v
x
computer 2
1
24
ST
S
0
T 0
ST 0
6
6
14
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
JΩ 8
(continued)
Table 1.5 (continued)
18
1
Instruction Execution Cycle and Cooperation …

So far, synchronizing concurrent processes (occurring in not disjoint periods)
has been considered. The problem was outlined by examples, using machine
instructions of our computer model and a group of such cooperating computers. The
main problem was ensuring mutual exclusion in access to shared resources, realized
by means of operations on semaphores. Synchronization problems belong to a
broader class of issues appearing in concurrent execution of programs. This is their
coordination, which includes also scheduling of processes, like sequencing (seri-
alization), that is, enforcing their desirable ordering or simultaneity of some actions
(Sect. 7.2). Notice that mutual exclusion, in contrast to scheduling, does not require
knowing names of processes that compete for resources, but only names of some
shared variables—the semaphores. The sequencing problems constitute a vast
domain of research and application, skipped here. One of the most important
problems of distributed systems is communication between cooperating processes.
In this chapter they will be outlined again by examples, on the low level—of
machine instructions. To this end, names of processes and special instructions
(commands) „send” and „receive”, denoted concisely by symbols „!” and „?”, will
be introduced for synchronous communication, as well as symbols „S” and „R”—
for asynchronous. Shortcuts „!” and „?” are borrowed from a theoretical model of
communication between processes, called CSP (Communicating Sequential
Processes), developed by Hoare in (1978, 1985).
1.4
Synchronous Communication of Processes
The instruction set in Fig. 1.3 is extended with the following instructions:
As shown in Fig. 1.4, process P1 sends the value of its variable n to process P2,
which assigns this value to its variable m (in the original CSP notation, n is an
expression, but m must be a variable; so the joined action of P1 and P2 is, in fact a
distributed assignment statement m: = n). The transmission of the value of variable
0
1
2
3
4
5
6
7
0
1
2
3
4
5
6
7
8
9
10
SA chan V(sem)
SA chan V(sem) ST 0
8
9
10
local memory of
f
o
y
r
o
m
e
m
la
c
ol
m
a
r
g
o
r
p
program
2
PC:
IR:
A:
other registers:
2
PC:
IR:
A:
other registers:
0
0
IR := content of address indicated by PC
IR := content of address indicated by PC
computer 1
shared data memory
3
2
16
2
14
sem chan y
z
u
v
x
computer 2
1
25
ST
S
0
T 0
ST 0
6
6
14
LA y
MU z P(sem)
AD chan SA x V(sem) ST 0
LA u
DI v
P(sem)
AD chan SA x V(sem) ST 0
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
JΩ 8
JΩ 8
Table 1.5 (continued)
1.3
Mutual Exclusion of Processes; Application of Semaphores
19

n from P1 to P2 takes place, when instructions P2! n and P1? m are being executed
jointly, that is when control of both processes reached these actions. Such „meet-
ing” of the processes is called their handshaking, or randezvous: when one program
is ready to communicate and its partner is not, then the former waits until the latter
be ready. This is called a synchronous communication whose principle is depicted
in Fig. 1.5. Such mechanism has been implemented in many programming lan-
guages, for instance in ADA, OCCAM and a number of more commonly used like
Java, C++, etc.
Notice that such communication is speed-insensitive (computing result is inde-
pendent of relative computation speed of computers) and resembles a phone call:
the caller waits until the callee picks up the telephone receiver.
As an example consider a system of two-computers, which computes the greatest
common divisor (gcd) of two integer numbers, where at least one is not 0. Its
execution as consecutive states, is shown in Table 1.6. Since the task is not so trivial
as the previous exemplary parallel computing of a simple assignment statement and
more instructive for its algorithmic and program parallelization aspects, let us
devote a little more attention to it.
P2!   n 
(instruction in 
program P1)
If  program P2 is ready to receive a data from program P1, then send the 
content of cell with address n to program P2 (through communication 
channel) and go to execution of the next instruction; otherwise wait until P2 
is ready.
P1?  m
(instruction in 
program P2)
If program P1 is ready to send a message to program P2 then receive this 
message from program P1, store it in a cell with address m and go to 
execution of the next instruction; otherwise wait until P1 is ready.
Fig. 1.4 Instructions of synchronous communication
program P1
here is control 
and 
if:
then a transmission of a content of the cell with addres n in the memory of P1 takes place;
this content is stored in the cell with address m in the memory of P2.
here is control 
channel
program P2
P2!  
n
P1?  
m
Fig. 1.5 Illustration of the principle of synchronous communication; the channel links ports or
sockets in the processes (depending on a phraseology of concrete hardware or software
implementation solutions)
20
1
Instruction Execution Cycle and Cooperation …

Table 1.6 Computing gcd (9, 6) = 3 by two computers communicating synchronously
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
0 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
acƟons of instrucƟon execuƟon cycle
20 
PC: 
0 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
0 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
0 
1 
2 
P1? u
LA y 
computer P2 
computer P2 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
0 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
1 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
0 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
1 
3 
4 
P1? u
6 
LA y 
JZ 7 
P1? u
6 
computer P2 
computer P2 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
0 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
5 
6 
JZ 7 
P1? u
2 
computer P2 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
1.4
Synchronous Communication of Processes
21

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
1 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
1 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
3 
7 
8 
P1? v 
6 
P2! x 
P1? u
6 
3 
P2! y 
computer P2 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
0 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
2 
6 
P1? u
6 
P2! x 
computer P2 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
2 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
2 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
9 
10
LA u
6 
P2! y 
P1? v 
6 
4 
P2? y 
computer P2 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
22
1
Instruction Execution Cycle and Cooperation …

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
4 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
13
14
6 
 P2? y  
6 
4 
P2? y 
computer P2 
3 
SU v
3 
4 
JN 7
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
15
6 
 P2? y  
4 
3 
JN 7
5 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
5 2 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
3 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
5 2 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
3 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
11
12
SU v
6 
 P2? y  
6 
4 
P2? y 
computer P2 
9 
LA u
9 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
1.4
Synchronous Communication of Processes
23

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    2 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
18
6 
P2? y 
computer P2 
3 
JU 3
6 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
19
20
6 
 P2? y  
6 
4 
P2? y 
computer P2 
3 
JU 3
3 
3 
SU v 
3 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       9    6
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
16
6 
P2? y 
computer P2 
3 
5 
SA u
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
17
6 
 P2? y  
4 
3 
SA u
6 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
24
1
Instruction Execution Cycle and Cooperation …

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
21
22
6 
 P2? y  
6 
4 
P2? y 
computer P2 
SU v
JN 7
4 
-3 
4 
-3 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 6 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
23
24
6 
 P2? y  
6 
4 
P2? y 
computer P2 
JN 7
-3 
-3 
7 
P1! u
7 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
25
6 
 P2? y  
5 
P1! u
-3 
8 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
1.4
Synchronous Communication of Processes
25

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
9 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
5 
26
6 
P2? x 
computer P2 
-3 
P1! v
8 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
6 
27
28
6 
 P2? y  
6 
6 
JU 0 
computer P2 
P1! v
-3 
-3 
9 
JU 0
9 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
0 
29
30
6 
 P2? y  
6 
0 
LA y 
computer P2 
P1! v
-3 
0 
P1? u
0 
-3 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
26
1
Instruction Execution Cycle and Cooperation …

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
1 
31
32
3 
3 
1 
JZ 7 
computer P2 
-3 
0 
-3 
P1? u
0 
LA y 
P1? u
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
2 
33
34
3 
3 
2 
P2! x 
computer P2 
-3 
0 
-3 
P1? u
0 
JZ 7 
P1? u
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6
6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
35
3 
 P2! x  
1 
-3 
P1? u
3 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
1.4
Synchronous Communication of Processes
27

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6    6  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
3 
36
3 
computer P2 
-3 
1 
P2! y 
P1? v
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6    3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
37
38
3 
3 
4 
computer P2 
-3 
2 
-3 
2 
P2? y 
LA u
P1? v
P2! y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6    3 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
39
40
3 
3 
computer P2 
6 
6 
3 
4 
3 
LA u
P2? y 
P2? y 
SU v
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
28
1
Instruction Execution Cycle and Cooperation …

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6    3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
41
42
3 
3 
computer P2 
3 
3 
4 
4 
4 
4 
P2? y 
JN 7
SU v
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer
computer
 P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7
P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       6    3  
  0        1        2       3      4       5       
  0        1        2       3      4       5       
6
7
6
       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer
 P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
43
44
3 
3 
computer P2 
JN 7
3 
3 
SA u
5 
4 
PC: 
4 
5 
P2? y 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
45
3 
P1? v
3 
4 
6 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
  LA y  JZ 7
(continued)
Table 1.6 (continued)
1.4
Synchronous Communication of Processes
29

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
46
3 
computer P2 
3 
JU 3
6 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
47
48
3 
3 
P2? y 
computer P2 
LA u
3 
3 
SU v
3 
4 
3 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
49
3 
SU v
0 
4 
4 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
50
3 
P2? y 
computer P2 
0 
JN 7
4 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
30
1
Instruction Execution Cycle and Cooperation …

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       3    3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
51
52
3 
3 
P2? y 
computer P2 
JN 7
0 
0 
SA u
5 
4 
5 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
53
54
3 
3 
P2? y 
computer P2 
SA u
0 
0 
JU 3
6 
4 
6 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
55
3 
JU 3
0 
4 
3 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
1.4
Synchronous Communication of Processes
31

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
56
3 
P2? y 
computer P2 
0 
SU v
3 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
57
58
3 
3 
P2? y 
computer P2 
SU v
-3 
-3 
JN 7
4 
4 
4 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
59
3 
JN 7 
-3 
4 
7 
P2? y 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 3 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
4 
60
3 
P2? y  
computer P2 
-3 
P1! u
7 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
32
1
Instruction Execution Cycle and Cooperation …

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
6 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
5 
61
62
3 
3 
P2? x 
computer P2 
P1! u
-3 
-3 
8 
5 
8 
P2? y 
P1! v 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
6 
63
64
3 
3 
JU 0 
computer P2 
-3 
-3 
JU 0
9 
6 
9 
P2? y 
P1! v
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
65
3 
JU 0
-3 
0 
P2? y 
0 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
1.4
Synchronous Communication of Processes
33

20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
0 
66
3 
LA y
computer P2 
-3 
P1? u
0 
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
1 
67
68
0 
0 
JZ 7 
computer P2 
-3 
-3 
0 
1 
0 
LA y 
P1? u
P1? u
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0    3 
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
7 
69
70
0 
0 
ST 0 
computer P2 
-3 
-3 
7 
JZ 7 
0 
0 
P1? u
P1? u
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
(continued)
Table 1.6 (continued)
34
1
Instruction Execution Cycle and Cooperation …

First, the algoritm is based on the ancient theorem ascribed to Euclid and states the
following: if x > 0 then gcd of x and y equals x when y = 0; gcd of x and y equals
gcd of y and r when y > 0, where r is the remainder of division x by y. Concisely:
gcd(x, 0) = x and gcd(x, y) = gcd(y, r), where r = x mod y. Therefore, the algorithm
may look as follows:
step 1.
If x > 0 and y = 0 then stop—the gcd is x, otherwise go to step 2;
step 2.
r: = x mod y; x: = y; y: = r; go to step 1;
Notice that the algorithm will terminate activity, because the sequence of
remainders in consecutive executing actions in step 2 is decreasing and each
decreasing sequence of natural numbers is ﬁnite.
Second, the algorithm will be distributed among two processes (here—computers):
the actions of step 1 will be committed to computer 1, which sends values of x and
y to computer 2 if y > 0, while computation of remainder r will be performed by
computer 2, which sends values of r and y to computer 1.
Third, the algorithm may be coded concisely as the system of two programs P1
and P2 (shown in Fig. 1.6), written in machine instructions (from Figs. 1.3 and 1.4)
and loaded into two communicating computers.
It is assumed that input values of x, y are already stored in memory of computer
1 before actions of P1 and the result gcd(x, y) is assigned to variable x on termi-
nation of this program. The consecutive remainders computed by program P2 are
stored in variable u and transmitted to program P1, which stores it in variable
y. Notice that the separate variable for remainders is not needed due to synchronous
communication between the programs: its role plays communication channel
linking instruction P1! u with instruction P2? y. Table 1.6 illustrates two concurrent
processes generated during execution of this system with input values x = 9, y = 6
and the same speed of clocks. Notice, however that the result would be the same if
their speeds were different. The result gcd(9, 6) = 3 resides in variable x on ter-
mination of the processes. Both processes start simultaneously, but at different local
times.
20 
20 
PC: 
A: 
Prześlij dny
Prześlij do
IR: 
20 
PC: 
A: 
IR: 
  LA y  JZ 7 P2! x P2! y P2? y P2? x JU 0 ST 0      
0      1        2       3       4        5        6      7
3 0 
P1? u P1? v LA u SU v  JN 7 SA u JU 3 P1! u P1! v  JU 0       0
3  
  0        1        2       3      4       5       6       7        8      9   
x
y
other
registers: 
other
registers: 
u
v
computer P1  
computer P2 
IR := content of address indicated by PC
IR := content of address indicated by PC
20 
PC: 
71
0 
-3 
0 
ST 0 
0 
P1? u
acƟons of instrucƟon execuƟon cycle
acƟons of instrucƟon execuƟon cycle
Table 1.6 (continued)
1.4
Synchronous Communication of Processes
35

Though the gcd algorithm has been used here only as an example of its
distributive arrangement with synchronous communication, the importance of
the gcd notion, both in theory and many applications, its computational
methods and complexity is sketched in the few following, but not exhaustive
remarks:
1. The notion of gcd is commonly used for reducing fractions to the lowest
numerator and denominator.
2. The gcd for numbers may be extended to gcd for polynomials or to more
abstract mathematical notions, like rings, in particular to rational and real
numbers.
3. The gcd is used in factorization of integer numbers (in the simplest case)
into primes: in 1. representing them as product of prime numbers.
4. The gcd is used in computational geometry.
5. The notion of gcd is used in the cryptographic protocols, to secure net-
work communications and in methods for breaking the cryptosystems by
factoring large composite numbers.
6. There are known a number of algorithms computing the gcd, more efﬁ-
cient (of lower computational complexity than the Euclidean algorithm
shown in this chapter) but more mathematically involved, some of them
for some special numbers only.
7. There are some probabilistic methods to asses if a number (or an element
of a ring) is a gcd of given pair of numbers.
8. There are some methods of parallelization of computing of gcd, more
complicated than shown in this chapter.
LA  y 
JZ 
P2!  x 
P2!  y 
P2?  y 
P2?  x 
JU 
ST
P1: 
P2: 
P1?  u
P1?  v
LA  u
SU  v
JN 
SA  u
JU 
P1!  u
P1!  v
JU 
computer 1 
computer 2 
Fig. 1.6 Synchronous
interprocess communication
when computing the greatest
common divisor; the dashed
lines show passing messages,
the solid–control
36
1
Instruction Execution Cycle and Cooperation …

9. A great many investigations on computational complexity of gcd have
been carried out and results for particular algorithms obtained. However,
so far the lower bound of parallel computing complexity of the gcd
problem (roughly speaking—the most efﬁcient algorithm, not discovered
hitherto), is an open problem (Karp and Ramachandran 1990).
10. Some investigations on correctness of the gcd algorithms, especially their
distributed versions, are important examples belonging to the theory of
computation.
1.5
Asynchronous Communication of Processes
In order to explain the principle of asynchronous communication, let us imagine the
following organization of its participants. Each program has a mailbox of messages
delivered by senders to it. The mailbox is partitioned into pigeon-holes, each
assigned to one sender and containing a queue of messages sent by this sender. The
receiver of these messages, when needs a message from a certain sender, takes it
from a queue assigned to this sender—if the queue is nonempty. Otherwise, the
receiver waits until the sender dispatches the message to this queue. So, unlike in
synchronous communication, the sender is not suspended until receiver gets the
message, but continues activity, and symmetrically for the receiver—unless its
respective queue is not empty.
The instruction set is extended with two instructions shown in Fig. 1.7.
The asynchronous communication mechanism has been implemented for some
programming languages (in their syntax or libraries), like LINDA Carriero et al.
(1986), Carriero and Gelernter (1989), some extensions of COBOL and even the
old Fortran and a number of newer, like C#, Visual Basic, JavaScript and some
others. The principle of asynchronous communication is depicted in Fig. 1.8.
S(P2) n 
(instruction in 
program P1)
Send the content of cell with address n to the tail of queue assigned to 
program P1 in the mailbox of program P2 and go to execution of the next 
instruction; 
R(P1) m
(instruction in 
program P2)
If the queue assigned to program P1 in the mailbox of program P2 is non-
empty, take a message from the head of this queue, store it in the cell with 
address m and go to execution of the next instruction; otherwise wait until 
the queue becomes non-empty.
Fig. 1.7 Instructions of asynchronous communication; S stands for send, R—for receive
1.4
Synchronous Communication of Processes
37

Notice that the program in Fig. 1.6 computing the gcd by means of synchronous
communication may be rewritten as in Fig. 1.9, with replacement of synchronous
instructions „!”, „?” with asynchronous „S”, „R” and yields the same result, pro-
vided that the order of receiving messages is the same as the order of sending them
(i.e. in accordance with the FIFO discipline).
Table 1.7 illustrates a part of two concurrent processes, communicating asyn-
chronously and generated during execution of this system for input values x = 9,
computer P2
S(P2)   n
… 
… 
mailbox
R(P1)   m
… 
… 
mailbox
computer P1
R(P2)    l
S(P1)   k
program P1
program P2
head 
tail
tail
head 
queue assigned to P2
queue assigned to P1
Fig. 1.8 Illustration of the principle of asynchronous communication
LA  y 
JZ 
S(P2)  x 
S(P2)  y 
R(P2)  y 
R(P2)  x 
JU 
ST
P1: 
P2: 
R(P1)  u
R(P1)  v
LA  u
SU  v
JN 
SA  u
JU 
S(P1)  u
S(P1)  v
JU 
buﬀer 
buﬀer 
Fig. 1.9 Asynchronous interprocess communication when computing the greatest common
divisor; The dashed lines show passing of messages, the solid lines—control
38
1
Instruction Execution Cycle and Cooperation …

Table 1.7 Asynchronous computing gcd (9, 6) = 3
(continued)
1.5
Asynchronous Communication of Processes
39

(continued)
Table 1.7 (continued)
40
1
Instruction Execution Cycle and Cooperation …

(continued)
Table 1.7 (continued)
1.5
Asynchronous Communication of Processes
41

y = 6 and the same speed of clocks’ pace. Process P2 is idle until the state 8,
whereas process P1 starts in the state 1 and waits, since the state 10, for data from
P2 (i.e. the remainders) that will be put in the queue (buffer) located in the mailbox
associated with P1, collecting data from P2. The reader may continue the processes
until the end, when the variable x gets value 3 as the value of gcd (9, 6). Notice that,
every process may be suspended only when its control reached instruction „receive”
(R) with empty queue, unlike in case of synchronous communication, when the
control reaches also instruction „send” (S).
Table 1.7 (continued)
42
1
Instruction Execution Cycle and Cooperation …

1.6
Synchronous Vector Systems
Considerations on the level of machine instructions will be concluded with
demonstration of action of a synchronous vector system, composed of very simple
identical processors. Each of them executes only four instructions and has access to
shared memory for data. It is assumed that their clocks, of identical frequencies, are
precisely synchronized (or equivalently: the processes use a common clock). Such
systems, composed of a great number of very simple processors, are capable of
offering large computing power, when performing algorithms, where identical
instructions (machine commands) in each processor are being executed simulta-
neously in one instruction execution cycle. Systems of such architecture are spe-
cialized for certain tasks, for instance, in computation with vectors or matrices. To
illustrate such system, let us consider a simple example of adding vectors of four
components (obviously the gain of such architecture is signiﬁcant in case of vectors
of large number of components). Given vectors:
X = (X[1], X[2], X[3], X[4]) = (3, 8, −2, 6)
Y = (Y[1], Y[2], Y[3], Y[4]) = (5, −7, 0, 23)
let us compute their sum:
Z = X + Y = (Z[1], Z[2], Z[3], Z[4]) = (8, 1, −2, 29)
Table 1.8 shows the activity of of 4-processor vector system, computing the sum
X + Y and storing result in the vector Z. Note that computation of sum of
n-components vectors takes as much time as computing sum of two numbers
X[i] + Y[i] (i = 1,…, n): only 4 instructions are being executed, instead of at least 4
(n + 1), when performed by one processor. Replacing instruction of addition
(AD) with multiplication (MU), leads to computing products of respective com-
ponents, whose sum yields the inner product of vectors (summation of the products
may be performed by an algorithm which would sum up all the products; such
efﬁcient algorithms are elaborated and easily found in the literature). Note that
computation of the inner product of vectors is a basic activity of computation of the
product of matrices, which is encountered in a number of problems, like solving
linear equations systems, fast Fourier transform (FFT) and others. For this purpose,
synchronous matrix architectures are devised, included in the supercomputers, as
well as very fast, so-called systolic arrays, of very large integration scale (VLSI),
worked out by Kung and Leiserson (1979), Petkov (Petkov 1992), for special tasks.
Architectures like vector, matrix or others of regular interconnection structures
between simple but numerous processing and memory units, acting synchronously,
are sometimes referred to as massively parallel.
1.6
Synchronous Vector Systems
43

Table 1.8 Activity of of 4-processor vector system, computing sum of vectors X, Y
LA X[1] AD Y[1] SA Z[1] ST 0
PC:
IR:
A:
0
0
1
2
3
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
processor 1
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
1
LA X[2] AD Y[2] SA Z[2] ST 0
PC:
IR:
A:
0
0
1
2
3
processor 2
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
LA X[3] AD Y[3] SA Z[3] ST 0
PC:
IR:
A:
0
0
1
2
3
processor 3
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
PC:
IR:
A:
0
0
1
2
3
processor 4
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
LA X[4] AD Y[4] SA Z[4] ST 0
PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
2
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
LA X[1]
LA X[2]
LA X[3]
LA X[4]
processor 1
processor 2
processor 3
processor 4
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
1
3
3
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
1
8
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
1
-2
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
1
6
processor 1
processor 2
processor 3
processor 4
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
LA X[1]
LA X[2]
LA X[3]
LA X[4]
(continued)
44
1
Instruction Execution Cycle and Cooperation …

PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
4
AD Y[1]
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
processor 1
processor 2
processor 3
processor 4
3
8
-2
6
1
1
1
1
AD Y[2]
AD Y[3]
AD Y[4]
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
5
8
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
1
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
-2
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
29
processor 1
processor 2
processor 3
processor 4
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
AD Y[1]
AD Y[2]
AD Y[3]
AD Y[4]
PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
6
8
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
1
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
-2
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
2
29
processor 1
processor 2
processor 3
processor 4
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
SA Z[1]
SA Z[2]
SA Z[3]
SA Z[4]
(continued)
Table 1.8 (continued)
1.6
Synchronous Vector Systems
45

PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
3
7
8
8
1
-2
29
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
3
1
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
3
-2
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
3
processor 1
processor 2
processor 3
processor 4
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
SA Z[1]
SA Z[3]
SA Z[4]
SA Z[2]
29
PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
8
8
8
1
-2
29
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
8
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
8
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
8
processor 1
processor 2
processor 3
processor 4
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
3
3
3
3
ST 0
ST 0
ST 0
ST 0
PC:
IR:
A:
0
vector X
vector Y
vector Z
X[1] Y[1] Z[1] X[2] Y[2] Z[2] X[3] Y[3] Z[3] X[4] Y[4] Z[4]
3
8
-2
6
5
-7
0
23
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
9
8
8
1
-2
29
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
8
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
8
PC:
IR:
A:
0
copy to IR the content of
address indicated by PC
If IR contains instrucƟon of:
• stop then PC:=address part
and terminate run
• another then execute it
and PC:=PC+1
0
8
processor 1
processor 2
processor 3
processor 4
LA X[1] AD Y[1] SA Z[1] ST 0
0
1
2
3
LA X[2] AD Y[2] SA Z[2] ST 0
0
1
2
3
LA X[3] AD Y[3] SA Z[3] ST 0
0
1
2
3
0
1
2
3
LA X[4] AD Y[4] SA Z[4] ST 0
ST 0
ST 0
ST 0
ST 0
Table 1.8 (continued)
46
1
Instruction Execution Cycle and Cooperation …

1.7
Some Classiﬁcations of Computer Systems
Before we pass on, to presentation of fundamental features and functions of dis-
tributed systems, let us take a look at possible types of computer systems depicted
in the following diagram (Fig. 1.10).
The reader will easily ascribe exemplary computer systems outlined in this
chapter to some types shown in Fig. 1.10.
A classiﬁcation based on different principle (i.e. on multiplicity of instruction
streams and data streams) is the the so-called Flynn’s taxonomy (Flynn 1972):
• SISD (Single Instruction [stream] Single Data [stream])—traditional computers
with one instruction stream
• SIMD (Single Instruction [stream] Multiple Data [stream])—systems with one
nstruction stream and more than one stream of data
• MISD (Multiple Instruction [stream] Single Data [stream])—systems with more
than one instruction stream and one data stream (do not exist)
• MIMD (Multiple Instruction [stream] Multiple Data [stream])—systems with
more than one instruction and more than one data stream
computer systems
centralized
distributed
uniprocessor
mulƟprocessor
(shared memory) 
uniaccessed
(single
workplace) 
mulƟaccessed
(more than
one 
workplace) 
mulƟprogrammed
(Ɵme-sharing, 
simulated
parallelism)                         
synchronous
asynchronous
vector
array
systolic
Global Networks
Local Area Networks (LAN)
Personal Networks (PAN)
Corporate Networks
mulƟcomputer
(disconnected) 
mulƟcomputer
(connected) 
uniaccessed
(single
workplace) 
mulƟaccessed
(more than
one 
workplace) 
Wide Area Networks (WAN)
Metropolitan Networks (MAN)
single 
program
single 
program
mulƟpro-
grammed
distributed systems may
be implemented in various
network infrastructures 
Fig. 1.10 Outline of possible types of computer systems
1.7
Some Classiﬁcations of Computer Systems
47

References
Carriero, N., & Gelernter, D. (1989). Linda in context. Communication of the ACM, 32(4), 444–
458.
Carriero, N., Gelernter, D., & Leichter, J. (1986). Distributed data structures in linda, symposium
on principles of programming languages ACM. Proc: ACM.
Dijkstra, E. W. (1965). Cooperating sequential processes. Eindhoven, the Netherlands:
Technological University.
Dijkstra, E. W. (1968). Cooperating sequential processes. In F. Genuys (Ed.), The origin of
concurrent programming (pp. 43–112). New York: Academic Press.
Flynn, M. J. (1972). Some computer organizations and their effectiveness. IEEE Transactions on
Computers, C–21(9), 948–960.
Hoare, C. A. R. (1978). Communicating sequential processes. Communications of the ACM, 21(8),
666–677.
Hoare, C. A. R. (1985). Communicating sequential processes. London: Prentice-Hall International.
Karp, R. M., & Ramachandran, V. (1990). Parallel algorithms for shared-memory machines.
In J. Van Leeuwen (Ed.), Handbook of theoretical computer science (Vol. A). Elsevier.
Kung, H. T., & Leiserson, C. E. (1979). Algorithms for VLSI processor arrays. In C. Mead, L.
Conway (Eds.), Introduction to VLSI systems. Addison-Wesley.
Petkov, N. (1992). Systolic parallel processing. North Holland Publishing Co.
von Neumann, J. (1945). First draft of a report on the EDVAC.
48
1
Instruction Execution Cycle and Cooperation …

Chapter 2
Distributed Systems—Objectives,
Features, Applications
2.1
What Systems Do We Consider as Distributed?
No generally admitted deﬁnition of distributed computer system exists. Before
some understandings of this notion encountered in the professional literature will be
outlined in this chapter, let us turn attention to its sources. As the ﬁrst distributed
network-based system, the SAGE (Semi Automatic Ground Environment, USA,
50. of XX century) is recognized. It consisted of some tens of computers (some of
them of several hundred of tons!), radars, missile launchers and other military
installations, connected by telephone cables and dispersed over territory of USA
and Canada. A successive system enjoying distributed features was a network
ARPANET (Advanced Research Projects Agency Network, late 60. and 70. of XX
century), initiated by the ARPA agency of Defence Departments USA. At ﬁrst it
comprised several academic computers connected into a network, then a fast
increase of their number took place. In this network, radio and satelite links have
been used for the military purpose of USA and Canada—similarly to the SAGE, but
made available also for some academic institutions. It was the ﬁrst large system, in
which the so called packet switching (in contrast to circuit switching—as at that
time in telephone systems) were applied as well as the popular protocols FTP and
TCP/IP. On the turn of the 80. and 90. of XX century the ARPANET was parti-
tioned into a military and civilian part (academic), named then INTERNET. The
civilian part was gradually becoming a commercial system and in effect of fast
development, reached the worldwide range. Thus, INTERNET grew out of
ARPANET and took over from its military-academic prototype the basic ideas and
techniques. The Defence Advanced Research Projects Agency (DARPA) is until
now a mighty organization, launching various, not only military technological
projects. To history of large computer networks, having some features of distributed
system, belongs also BITNET (USA, developed and in operation in 1981–2000). It
was an academic network, stretched over a number of countries for the purpose of
electronic mail, remote conversation, access to remote scientiﬁc archives, etc., as
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_2
49

well as EARN (European Academic and Research Network, 1984), a network
linking academic institutions in Europe, connected with other networks like
BITNET and INTERNET. The Polish branch of the EARN network, called
PLEARN, has been connected to EARN in 1990 (closed in 2000) in Informatics
Center of Warsaw University but its beginning was in operation in mid 1980. Then
the Research and Academic Computer Network NASK was initiated in 1991 at
University of Warsaw by a team of physicists, which played essential role in
connecting Poland to INTERNET. Now, NASK has a status of a research institute.
Above mentioned computer networks are global and exhibit some features of
distributed
systems:
the
lack
of
common
(shared)
memory
and
clocks.
Communication between computers proceeds through data transmission channels.
These networks offer some services speciﬁc for a distributed software. On the other
hand, even groups of terminals, like workstations instaled in many places, often
remotely from one another, e.g. in different localities and connected to one main
computer (e.g. mainframe) are sometimes thought of as distributed systems. The term
„distributed system” will be used in a narrower meaning: not only as a network with a
communication software making possible access to common resources, but as a work
environment possessing certain properties mentioned further in this chapter. Closer to
this notion are the so-called corporate networks (INTRANET), whose computers,
apart from communication capability, are endowed with distributed software, devised
specially for tasks typical for activity of a given corporation.
Some informal deﬁnitions of distributed system emphasising various features,
dependently on different perspectives (users of various applications, programmers,
designers of programming languages or operating systems, computer architecture,
etc.) may be expressed as follows:
• collection of autonomous computers cooperating so that to reach a common
aims;
• multicomputer system, where all computers work over the same or similar
problem(s);
• set of independent computers linked by a network and managed by a distributed
software, that offers various facilities to users;
• a system of independent computers that makes a user’s impression of work on a
single computer;
• multicomputer system—a set of autonomous computers (possibly of diverse
architecture) interconnected by a network of transmission channels and equip-
ped by distributed operating system;
• set of distributed processes and their hardware environment (computers, trans-
mission channels, switches, routers, etc.). Each of these processes may be a set
of sequential processes (termed sometimes as threads), acting concurrently on
several or one procesor—in a time sharing mode;
• an informatics system where:
– arbitrary number of processes may run simultaneously; the system is modular
and open to extension: its components may be attached and removed;
50
2
Distributed Systems—Objectives, Features, Applications

– communication takes place by message passing through transmission channels,
not by common memory, which is absent;
– computer clocks are independent with various frequencies, but can be
synchronized;
– operating system manages the network of connected computers; some parts of
the operating system may be located on various computers; instants of dispatch
and reception of a message are separated by unpredictable time period—not
possible instantaneous (timeless) data transmission;
Basic difference between centralized and distributed systems
Centralized: processes in the system intercommunicate (interchange data) through
shared physical memory space (Fig. 2.1). Hence fast communication. However, mul-
tiprocessor computers with such memory space, accessible also to eventually attached
workstations, require quite sophisticated switchgear (see Sect. 2.4) to handle complex
structure („topology”) of wiring, which connects its processors to the memory. Access
time to such memory depends on the distance—in the sense of this topology. This is so,
because initiations of the access requires passing of the signal through a number of
switches between levels of the wiring. This signiﬁcantly limits a number of processors
(working units) in such systems. Their important feature: all cooperating units have the
currentinformationaboutthesystemglobalstate(contentofthesharedmemory),which
is not the case with systems based on message passing.
central
multiprocessor with
shared memory
Fig. 2.1 Exemplary structure of a centralized system with terminals and/or workstations
2.1
What Systems Do We Consider as Distributed?
51

Distributed: neither shared memory nor shared clock exists. A process in a node
of the network may communicate with processes in other nodes only by sending
data in packets through transmission channels (cables, radio links, waveguides, etc.
handled by appropriate devices like transmitters, receivers, ampliﬁers, etc.). For
correct mutual interpretation („understanding”) of messages travelling between
senders and receivers, the communication protocols are applied. A protocol is a set
of rules of data coding (by sender) and decoding (by receiver). In accordance with
the rules, the sender encodes (translates) a message into a certain „mutually com-
prehensible” form and the receiver decodes it for its usage. Such form is a sort of a
formal language, whose syntax (grammar) and semantics („mutual understanding”)
represent the rules. Therefore communication in distributed systems is much slower
than in centralized ones. But number of working units (network nodes, like com-
puters, of various architecture and purpose) is practically unlimited. The activity of
programs is managed by a software (distributed operating system), whose frag-
ments are located in servers and users’ computers (Fig. 2.2).
Such a software, when fulﬁls requirements after-mentioned in Sect. 2.3, makes
communication network a medium for distributed system, i.e. for environment that
allows to use resources located outside user’s computer in a way not essentially
different from using the local ones. Obviously, the same network may become an
infrastructure for various distributed systems.
Commonly known corporate information systems are distributed systems for
particular applications like computer system of a network of supermarkets, banks
and cashpoints, insurance companies, booking of air tickets, etc.
Some examples of operating systems (or their kernels) that make a networked
multicomputer to be a distributed system for general purpose, are the following:
Fig. 2.2 Exemplary structure of a distributed system
52
2
Distributed Systems—Objectives, Features, Applications

• UNIX 4BSD (Berkeley Software Distribution, USA end of 1980 and successive
years—a series of operating systems made in Berkeley University in California,
originating from the UNIX BSD devised in 1978). They are extensions of UNIX
(devised in the 70. of XX century in AT&T’s Bell Labs.) and belong to its
widespread family of operating systems. They were endowed with mechanisms
of interprocess communication in computer networks, like TCP/IP protocols,
socket interfaces, group communication, Remote Procedure Call, and a number
of improvements concerning efﬁciency, extendibility and reliability. Systems of
this series enjoy most of distributed systems’ features and became a design
pattern for respective projects.
• Chorus (France, INRIA, late 70. of XXcentury); the so-called micro-kernel for
distributed operating system, afterwards developed by Chorus Systèmes Co.
• Mach (Carnegie-Mellon Univ. USA, 1980–1990); a kernel of distributed
operating system, applied in several commercial systems;
• Amoeba (Vrije Universiteit Amsterdam, 1980-te-1990); distributed operating
system for which the Python programming language was devised;
• CLOUDS (Georgia Institute of Technology, USA, 80. of XX century);
• DCE (Distributed Computing Environment, USA, a number of consortiums,
early 1990);
2.2
Most Important Objectives of Distributed Systems
2.2.1
Economy
Distribution gives better cost-effective results than a single main (also powerful
mainframe) central computer. With a number of cheap computers connected by a
network, one may obtain computing power of a mainframe or higher, but the total
cost of the system signiﬁcantly lower. If a powerful computer is connected to the
network, the other computers may delegate to it particularly time consuming and
exceeding their capabilities fragments of computation, whereas most of activity is
being performed locally. Many computer centers, apart from large computers,
install in their premises local networks, that connect workstations and clusters of
servers, as well as systems of dedicated architectures, e.g. grid systems.
2.2.2
Increase of Computing Power
Sometimes possible only by parallel actions. That is, by execution of an algorithm
concurrently on multiple processors, one can overcome the physical barrier of a
sequential procesor’s power. Even if this barrier is far away, it is advisable
(sometimes necessary) to disperse the computation over a number of processes in
2.1
What Systems Do We Consider as Distributed?
53

case of handling with big data, when none large computer can cope this task e.g.
due to bottlenecks in memory access. Examples of distributed applications projects,
for which dedicated systems for big data processing were constructed are:
International
project
SETI@home—(Search
for
Extra-Terrestrial
Intelligence, University of California, Berkeley, USA) allows everybody who has a
computer with Internet, to download a program that analyses data collected by
largest radiotelescopes. The program fetches successive data portions, analyses
them when the computer is not engaged with ordinary everyday activity, or
underloaded is its processor. The results are returned to the head ofﬁce of the
project. Average effective speed of these data processing (now—2017) amounts to
over 260 TeraFLOPS (one TeraFlop: 1012 FLoating point Operations Per Second).
Another public program of similar purpose is the Planet Hunters (PH). So far, no
signals from extraterrestial civilization have been discovered. But amateur astron-
omers have found (October 2012) a planet PH1 that rotates around two stars (in the
system of 4 stars). Now several milion of personal computers are participating in
the project.
International project Folding@home—the so-called Blue Gene project. It
allows to download a program for analysis of proteins and simulates their folding
and misfolding (the latter causes some diseases). The program proceeds similarly to
SETI@home: analyses imported data and returns results. Average effective speed of
data processing amounts to over 1200 TeraFLOPS and increases as new volunteers
join the project. Some sources announce that it reached 5000 TeraFLOPS. The IBM
Blue Gene supercomputer used in the project is composed of many cheap pro-
cessors (applied in personal computers), with access to a large memory. It has
reached more that 1000 TeraFLOPS and is used also for other purposes, e.g. to
simulation of human brain cortex activity.
Many projects in astronomy, mathematics, physics, chemistry, genetics and
other research and application domains, are being elaborated by millions of people
working over a joint problem in such remote manner. Some other examples of such
distributed projects are: MilkyWay@home (design of exact 3D map of our
galaxy), Einstein@home (search for gravitational waves), ABC@home (veriﬁca-
tion of a certain conjecture in number theory), QMC@home (investigation of
molecule stuctures, by means of quantum chemistry methods), DNA@home
(discovery of gene regulators). There exist hundreds of computational projects
(„dispersed over homes”) that use special software like the mentioned above.
An extensive lecture course on distributed algorithms may be found e.g. in
Lynch (1996).
2.2.3
Internal Distribution
The only reasonable solution for some applications—examples: a network of
supermarkets (everyone should keep in its local computer its accounting of stock,
instead to overload the central data base of the company). Most of updates is
54
2
Distributed Systems—Objectives, Features, Applications

performed locally, but sometimes the company management needs a total infor-
mation about goods in stocks of all of their supermarkets at a time. Another
example: a collective work or game of a number of people, video conferences,
e-learning or systems using multimedia data like music, painting, photography, etc.
2.2.4
Reliability
In case of failure of one or several computers (hardware or software), the distributed
system can assure correct work of the whole. A user, independently of his/her
whereabouts, does not know that a failure occurred, because his/her processes run
correctly. Distributed operation system, when detects a source of the failure, con-
veys activities of the faulty machine to those being in full order. For instance,
establishes alternative routing in the network and recovers data from the faulty
machine. This is called a fault-tolerance. The failure may be caused by disap-
pearance of power supply, mechanical damage, viruses, etc. If this is not a total
breakdown, the system can remove the faulty entity by means of some error
recovery procedures and make a self-reconﬁguration. Apart from fault tolerance,
the distributed system should assure the so-called data consistency. For some
organizations (like banks, ﬂight control), reliability of the system is a paramount
necessity. It is worth to mention that fundamental aims of the aforetime military
devices based on widespread networks SAGE and ARPANET, was reliability:
destruction of one installation, would not paralyse activity of the whole.
Enhancement of reliability is also achieved by doubling (at least) certain compo-
nents of hardware, software or user’s programs and data.
2.2.5
Independence from Changes of Environment
Replacement of hardware components (servers, switches of packets, routers, etc.)
for more effective as well as adding of newer ones and removing of older, does not
entail necessity of modifying the software structure. Also, a change of require-
ments, e.g. for increasing a service offer should not destroy basic principles of
hardware and software construction, after adding of new components of different
type. To this end, a modular structure of the software is needed. This makes easier
its installation, exploitation and adding and removal of the modules.
2.2
Most Important Objectives of Distributed Systems
55

2.2.6
Flexibility
Possibility to use various computers for a job, depending on their current workload
and their computing capability. Example: if in a country A is night, while in B is
day, the computers from B may delegate some jobs to the computers from A.
Above mentioned objectives do not exhaust all requirements for distributed
systems. Particular systems are being devised for speciﬁed classes of tasks and
needs. Speciﬁc aims the systems should achieve, are determined by these tasks and
needs. Examples: widespread public access to informations (www pages), e-mail,
public communicators, social portals, etc.
2.3
Main Features of Distributed Systems
The distributed system should possess properties that ensure attainment of its
objectives by obeying assumptions on its project. The objectives are speciﬁc for
tasks the system has been intended for, but also general aims, listed in Sect. 2.2.
Typical features, following from these general assumptions are:
• sharing resources—a number of users may use the same resource, like printers,
ﬁles, procedures, databases, etc.
• openness—susceptibility to extension: enlargement of the system (hardware
and software) with retaining of hitherto existing solutions;
• concurrency—capability of performing many jobs or processes simultaneously;
• communication—interprocess data transfer by data transmission channels
offered by the network;
• lack of global time—various clock frequency of different computers, different
time indication of these clocks, different speed of processors’ activity;
• fault tolerance—system’s capability to remain active if an error of hardware or
software occurs (e.g. by maintenance of redundant hardware or taking over the
role of crashed device by a certain components working correctly);
• transparency—making possible the user to perceive the system as a whole, not
its separate components, by hiding technical details speciﬁc to cooperation of
multiple computers;
• scalability—preserving performance of the system after increasing its scale (e.g.
number of processes, computers, etc.).
So, some of these features pertain to advancement of processes, whereas some
others—to give the user impression of exclusive usage of resources. The former (let
us call them „dynamic”) will be illustrated in the successive chapters, by examples
of activity of mechanisms for management of concurrency, communication, fail-
ures, time, remote services and distributed shared memory. This illustration will
consist in presentation of exemplary processes, like in Chap. 1—as sequences of
56
2
Distributed Systems—Objectives, Features, Applications

states of a system during its activity. This chapter continues presentation of features
regarding usage of distributed systems—their pragmatics.
2.3.1
Resource Sharing
Every program acting in a computer system uses resources available from its
environment:
• hardware: processors, memory, input/output devices, other peripheral equip-
ment, communication channels, sensors, clocks, devices whose activity is
computer controlled like radiotelescopes mentioned above.
• software: application programs, procedures, methods, controllers, user ﬁles,
www pages, data bases, libraries and any data sets provided for the user’s needs.
• time: physical or logical magnitude (Chap. 4).
Resource management—assignation to processes, synchronization of their
usage, protection, recovery if lost, scheduling of time and other activities of this
management—is accomplished by operating system, whose parts are located in
servers, the managers of resources. The resources are categorized into types. To
every type, speciﬁc methods are being applied, but common for entire network are:
– the manner (schema) of resource naming for each type;
– enabled access to resources from each computer in the network—in accordance
with deﬁned accessibility rules; an access to a resource may change its state
(informally: a set of instantaneous values of its components like memory con-
tent, indications of clocks, etc.);
– mapping of resource names into communication addresses;
– coordination of concurrent access to resources—to ensure their consistency and
coherence.
For each resource type there exists its manager. The users are accessing
resources by communicating with the managers as depicted in Fig. 2.3.
More than one manager may be located on one server as depicted in Fig. 2.4.
Keeping resources on servers specially intended for this purpose is one of two
methods of resource sharing. This method, called a client-server model, assumes
that the server, the resource holder, decides to immediately assign it to the user on
his/her request, or to postpone, or to reject. Thus, a server plays a part of
decision-maker and provider of services. Figure 2.4 shows that a server may itself
become a user of resources located on other servers, that is may become a client, as
well as may hold various resource managers. Its typical services are the following:
– access to shared printers
– access to shared big data sets
– e-mail
– application programs
2.3
Main Features of Distributed Systems
57

– www pages
– social portals
– distributed data bases
– ﬁle and directory services
– time service
– naming services
– remote procedure call or remote method invocation
– transactions
– synchronization of clocks
– distributed shared memory.
manager of
resource A 
user 
user 
user 
user 
user 
user 
user 
user 
user 
user 
manager of
resource B 
manager of
resource C 
Fig. 2.3 Managers of resources A, B, C and users
server 1 
server 2 
user
user
user
user
user
user
manager of
resource A 
manager of
resource B 
manager of
resource C 
Fig. 2.4 Managers of resources A, B located on server 1 and resource C—on server 2
58
2
Distributed Systems—Objectives, Features, Applications

Some types of resources are located on the client’s computers, not on servers, to
achieve better performance of the former, e.g. local memory (RAM, ROM, cache,
disk), some interfaces and controllers, etc. The second resource sharing method,
called an object model, assumes that the resource is treated as a jointly used object
—in the meaning of object programming paradigm. In this approach, the resource is
an instance of an element of a class (a set of objects of the same type), with
algorithms (procedures or methods) that operate on this resource. A manager of
resource is then a collection of operations performed on this resource. There exist
systems supporting interprocess communication (thus, also resource sharing),
endowed with various systems of object programming. An example is CORBA
(Common Object Request Broker Architecture) that offers communication mecha-
nism of objects residing in computers of different hardware and software archi-
tectures, in particular, those endowed with various programming languages and
their compilers. The CORBA mechanism offers the so-called Interface Deﬁnition
Language (IDL) for deﬁning interfaces for communication between objects. The
interfaces are being translated from the IDL (by its compiler) into a programming
language used by the programmer for creating classes of objects. Some program-
ming systems, like Java, C++, Python and several others are outﬁtted with such
compilers that convert interfaces (translated by the IDL’s compiler) into a form used
by communication instructions like send and receive. A mechanism of Remote
Procedure Call (Chap. 6) is based on similar idea, but limited to creating interfaces
for calling procedures whose bodies are located in other computers (servers). Still
another example facilitating distributed objects communication is the CLOUDS
operating system (see Sect. 2.1).
2.3.2
Openness
This is capability to easy appending of hardware and software to the system. The
easiness means no need of change the system architecture in this case. The user may
do it himself, without ordering this job to a professional service. The openness is
being achieved by:
• ensuring independence of desired system behaviour, from its architecture
(hardware and software); to this end, standard controllers are used and—in case
of programming languages—intermediate languages and their compilers or
interpreters (e.g. virtual machine of Java);
• applying uniﬁed standardized communication mechanisms between processes
(like communication protocols);
• using widely offered standard interfaces of access to common resources like
libraries, controllers, application programs, etc.
Favourable for openness is modular construction of the system, both hardware
and software. Notice that the modularity allows for replacement of system
2.3
Main Features of Distributed Systems
59

components for more modern ones of the same functionality, as well as change of
universal components (commonly available in the market), into specially devised
for the system—in order to enhance its performance. The open, modular archi-
tecture makes easier its installation and putting into practice: for instance,
appending components when a part of the system has already been tested and is in
operation.
2.3.3
Transparency
Hiding (from the user) that various types of computers and devices are in the
system: giving the user impression of exclusiveness of using the system. This is a
consequence of a deﬁnition of distributed system, where the impression of working
with a single computer has been stressed. This impression remains, when the
system evolves during its usage (when adding and removing or replacing compo-
nents, etc.). It does not affect the user’s work, nor his perception of the system as a
whole—as a tool in exclusive usage. In general, the user is not aware of localization
of resources, like data stores, processors performing processes, etc. Obviously, in
case of some of them like shared printers or projectors, located in remote rooms,
etc., such knowledge is needed.
The International Standard Organization (ISO) deﬁnes the following types of
transparency in distributed systems:
• of access—enables getting both local and remote data by means of similar
operations;
• of location—enables access to data without knowledge of their site in the
system;
• of concurrency—enables undisturbed execution of many processes in parallel
with shared data;
• of multiplication—enables using many copies of data—to enhance reliability
and performance; sometimes this type of transparency is necessary—as in the
Distributed Shared Memory mechanism (Chap. 8);
• of faults—enables hiding some breakdowns; the programs continue execution
despite breakdowns of hardware or software; this is a consequence of reliability
as one of distributed system’s objectives;
• of migration—enables relocating data over the system with no inﬂuence on the
user’s work, or application programs, for instance naming of ﬁles is preserved;
• of performance—enables reconﬁguration of the system to enhance its efﬁ-
ciency when its workload is changed; this is a consequence of ﬂexibility as one
of distributed system’s objectives;
• of scaling—enables modiﬁcation of the system size without changing its
structure and application algorithms.
60
2
Distributed Systems—Objectives, Features, Applications

2.3.4
Scalability
The smallest scale: two connected computers or two workstations and server(s),
larger—local network (e.g. several hundred workstations or personal computers),
next—a system composed of a number of connected local networks (e.g. wide area
network), next—a number of connected latter systems (e.g. intranets), up to a global
network (e.g. internet). Scalability makes a certain alleviation of possible conse-
quences of openness. It aims at not worsening of efﬁciency after adding new
components to the system. Enlargement of the scale retains the system software
unchanged. The system adjusts its usage to the new scale. Modiﬁed are parameters
of attached components only, e.g. size of distributed database after adding larger
memory. A modiﬁcation of scale takes place with change of number of users, size
of data, as well as in effect of combining smaller networks into larger structures, e.g.
local networks into corporate ones, etc. Obviously, attainment of high degree of
scalability depends on the current potential of network technology.
Features like concurrency, communication, lack of global time, fault tolerance,
worth of more thorough consideration, are subject matter of successive chapters.
2.4
Exemplary Memory Connection Structures
in Centralized Multiprocessors
Since distributed multicomputer systems often take advantage of services delivered
by servers being large multiprocessors with shared memory (sometimes of a
powerful mainframe supercomputer), expediently will be to sketch main types of
structures connecting processors and memories: non-hierarchical (Figs. 2.5, 2.6 and
2.7) and hierarchical Figs. 2.8 and 2.9.
In the type depicted in Fig. 2.5, each processor can access the shared memory
with equal time (delay). Simple construction but heavily exposed to bottlenecks
with large number of processors.
In the crossbar switch with n processors and m memory banks, the crossbar
requires n  m 4-fold switches (4 connection points of each, n = m = 8 in
Fig. 2.6). Expensive with large number of processors and memory banks, so,
applied in architectures with rather small number of these units, or as a components
of more complicated connection structures.
processor 1 
global shared
memory
connecƟon bus
processor 2 
processor n 
cache 
memory
connecƟon bus
processor 1 
cache 
memory
processor 2 
cache 
memory
processor n 
global shared
memory
(a)
(b)
Fig. 2.5 Non-hierarchical connection with single homogeneous global memory space a Unibus
with one shared physical memory b Unibus with one shared physical memory with caches
2.3
Main Features of Distributed Systems
61

In the logarithmic switch (Fig. 2.7) with n processors and n memory banks, this
wiring structure requires log2n switching degrees; there are n/2 switches on every
switching degree, thus the omega-network requires (n/2) log2 n 4-fold switches—
substantial decrease in cost and action time in comparison with the crossbar.
In the binary tree structure with n processors with local memory each (Fig. 2.8),
there are n −2 3-fold switches and one 2-fold switch;
A generalization of the binary tree connection structure is the cluster structure,
exempliﬁed in Fig. 2.9.
In a certain terminology, the non-hierarchical connection structures are refered to
as Uniform Memory Access (UMA) exempliﬁed by Figs. 2.5, 2.6 and 2.7, whereas
hierarchical—as Non Uniform Memory Access (NUMA) exempliﬁed by Figs. 2.8
and 2.9. However:
Attention: The term UMA is ambiguous: in some technical areas it is used as
abbreviation of „Uniﬁed Memory Architecture”, a synonym of “Integrated
Graphics”, in some others—as abbreviation of „Unlicensed Mobile Access”.
Fig. 2.6 Crossbar switch: non-hierarchical multibus connection with heterogenous (partitioned
into „banks”) global memory space. Circles represent 4-fold switches (4 connection points)
between processors and memory banks (white—switched off, black—switched on)
62
2
Distributed Systems—Objectives, Features, Applications

The above examples show that in the UMA type connections the data transfer
time (latency) is roughly equal for every pair (processor, memory unit). But number
of components is substantially limited. In contrast, in the NUMA type, the time of
transfer essentially depends on the distance—in the sense of the wiring structure
(switchgear „topology”)—between a processor and required memory unit. The data
transfer time increases with number of switches the data must pass through. But
number of components may be larger. The processors in such architectures com-
municate between themselves by shared memory space. Another kind of
processor 1 
processor 2 
processor 3 
processor 4 
processor 5 
processor 6 
processor 7 
processor 8 
memory 1 
1 
 2
 3
switching degrees
memory 2 
memory 3 
memory 4 
memory 5 
memory 6 
memory 7 
memory 8 
Fig. 2.7 Logarithmic switch, the so-called omega-network: non-hierarchical multibus connection
with heterogenous (partitioned into banks) global memory space and 4-fold switches (white
switched off, black switched on, so, the route, e.g. from procesor 6 to memory bank 5 has been
established by a communication protocol)
processor 1 
memory 1 
processor 2 
processor 3 
processor 4 
processor 5 
processor 6 
processor 7 
processor 8 
memory 2 
memory 3 
memory 4 
memory 5 
memory 6 
memory 7 
memory 8 
Fig. 2.8 Binary tree—hierarchical multibus connection structure with local memory of processors
accessible from other processors; the route e.g. from procesor 3 to memory 8
2.4
Exemplary Memory Connection Structures in Centralized …
63

interprocessor or multicomputer communication in specialized architectures, also
within one large central computer, is by means of message passing through net-
works of various structures, not by common memory space. This kind is sometimes
referred to as NO Remote Memory Access (NORMA), the term somewhat mis-
leading (for instance, the multiprocessor in Fig. 2.5 could hardly be named a
„Remote Memory Access” architecture, thus as of the NORMA kind!). There are a
number of such structures („topologies”), usually intended for particular domains of
application. Example is a topology of cube and hypercube, star, ring, grid, torus.
Their detailed description does not belong to the subject of this book, but is easy
available in many books and articles concerning various computer architectures.
Reference
Lynch, N.A. (1996). Distributed algorithms, Morgan Kaufmann Publishers, Inc.
proscesor  
processor  
memory
processor  
processor  
processor  
processor  
processor  
processor  
processor  
processor  
processor  
processor  
cluster
of rank 1 
memory
memory
memory
memory
memory
cluster
of rank 2 
Fig. 2.9 Heterogeneous multibus interconnection of clusters; every cluster’s switch connects it to
a bus of cluster on the next, higher level, that is of the one rank greater
64
2
Distributed Systems—Objectives, Features, Applications

Chapter 3
Concurrency
3.1
Concurrent Execution of Programs
Concurrency is the capability of running a number of processes simultaneously, that
is existence of more than one process in the overlapping time periods. It can be real
—realized by more than one processor, or simulated—on a single processor with
time sharing for a number of processes (Table 1.2 in Chap. 1). Here, we will not
distinguish these two technical ways of concurrency realization: their properties in
principle („logically”) are the same, though their implementations require different
solution in hardware or software. The concurrent execution of programs is usually
desired or indispensable. For instance when several users (clients) send requests to a
server, which initiates respective processes to be run in overlapping time periods,
i.e. starts them before others are terminated, as well as for faster execution of
programs by executing their parts in many processors simultaneously. Problems
with concurrency arise when the processes share resources or transfer data between
one another and when some events in a process must precede some events in
another process—if required by speciﬁcation of the program. Event in a process is
execution of the active element in a program, like machine instruction or a state-
ment in a programming language, or reading/writing memory—depending on the
generality level of considerations. Management of concurrency means coordination
of processes, i.e. enforcing a desired ordering of their events. The main problem is
synchronization of some activities, that is, assurance of mutual exclusion or
determination of temporal order or eventual simultaneity of execution. This man-
agement is responsible also for handling with errors and with pathological situa-
tions, like deadlock and starvation. This chapter focuses on mutual exclusion in
distributed systems, that is, assurance of exclusive access to resources—if necessary
(e.g. when writing to a shared ﬁle) in the context of some transactions, as well as on
the deadlock and starvation that may occur during execution. There are several
methods of mutual exclusion realization: by means of „external force” for users’
computers and „truly distributed”—solely by exchange of messages between them.
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_3
65

Two methods are presented in this chapter: with supervisory server and with a token
ring. These without „external force”, based on the so-called global timestamps, are
postponed to Chap. 4, where issues of time will be examined.
Before coming to the mutual exclusion, let us mention some general features of
transactions—a typical activity, where management of concurrency is indispens-
able. They are the following:
• „all or nothing”—a transaction is either committed, i.e. completes successfully
with correct results, or is discarded (aborted) and returns to a state from before
its initiation (unexisting transaction)—never is being performed only partially;
• isolation—other transactions have no access to the intermediate results (not
ultimate);
• cohesion—structure of any data set (like data base), that is, a schema of inter-
relationship between subsets of this set, is not changed in effect of realization of
a transaction;
• serial equivalence—the outcome of concurrent execution of not mutually
excluding actions is the same as the outcome of their execution one by one
(sequentially);
• exclusivity (indivisibility)—of writing to memory but not reading from memory
—thus, the writing is performed in transaction protective sections.
(cf. the extensive book on transactional information systems (Weikum and
Vossen 2002)).
Any transaction is being initiated by execution of the „open-transaction” action and
terminated—by the „close-transaction”. A transaction may be committed or aborted,
depending on its success or failure. To this end, commit and abort actions are per-
formed. For conciseness of exemplary sketch-procedures of bank transactions, from
among these four only the abort will be explicitly used. It makes the transaction
interrupt and return to a state from before its initiation. An entire transaction and its sub
transactions will be marked by curly brackets. In successive examples, actions
belonging to the bank transfer procedures and summation of bank accounts, are exe-
cuted by a bank’s servers and are initiated on the client’s request. These actions are
being performed in the global (physical) time (Chap. 4) depicted by the time axis
directed downwards in the successive ﬁgures. The actions’ positions on this axis rep-
resent their temporal interrelations, that is their succession in a transaction.Execution of
bank transfers and summation of accounts are accomplished by sequences of actions
presented by the examples. For exclusive access to resources, bank accounts in
examples, apart from the mentioned abort, the following operations will be used:
• lock Z, where Z is a name of resource protected against simultaneous access
(reading/writing) by more than one process or a list of such resources. In the
distributed (multicomputer) systems, it plays a part similar to operation of
semaphore closing (P or wait) in centralized systems. The lock Z in a process,
attempts entry into system state where resources Z can be accessed, i.e. not
currently in use by another process. If impossible, the access to Z is delayed
until a state, which enables this, when other processes complete use of Z.
66
3
Concurrency

This prevents access to these resources by any other process at a time, that is,
serializes accesses to Z.
• unlock Z, where Z is as above. It plays a part similar to operation of semaphore
opening (V or signal) in centralized systems. Its execution causes the process
leave state where resources Z may be used at most by one process at a time, and
permits access to them by a process in which the access has been delayed, e.g.
the one which waited longest for Z.
• read Z, where Z is a name of a resource whose value is to be fetched from
memory.
• write Z, where Z is a name of a resource whose value is to be stored in memory.
In the following pictorial examples explaining distributed mutual exclusion,
these operations will be shown explicitly (in concrete implementations they are
accomplished by protocols of resource management). So, portions of processes
where they appear, will be illustrated on the grey framed background and called
here protective zones. They play a part similar to critical sections (Chap. 1), but
belong to tasks of resource management protocols, not user programs. What is
more, the identiﬁer of protected resource is explicitly used as the parameter of the
lock operation—that is why the name, “protective zone” instead of “critical section”
is used here. The exclusive access to resources Z require passing „request” and
„release” messages to the manager of resources or to the processes where usage of
Z must be exclusive. Thus, execution of these operations takes more time than that
of P and V, which use a semaphore located in the memory common to all processes.
Moreover: execution of the lock Z in a transaction, delays only access (read/write)
to resources Z being currently in use by another transaction, but not other actions in
this transaction.
Example 1: bank transfer transactions Figure 3.1 presents performing erro-
neously programmed bank transactions. Amount of balance of accounts B, C, D are
respectively 50, 200, 100 EUR. The gentleman makes a bank transfer of 5 EUR
from the account B to C and the lady—3 EUR from account D to C. After the
transactions, the balance of account C is 205 EUR, whereas it should amount to 208
EUR. A lost update of account C occurred: the gentleman destroyed update of
account C, made by the lady before. The conﬂict of updates will be eliminated if the
bank transfers are closed into protective zones for C, which is shown in Fig. 3.2.
The protective zones in Fig. 3.2 are „coarse-grained”. It sufﬁces to block account
C only, if accounts B and D are accessible to their owners but not to other clients in
the system. In this case such zones may be made more „ﬁne-grained”, as depicted in
Fig. 3.3.
Only the updates of account C must proceed one by one, i.e. sequentially. The
bank transfers in Figs. 3.2 and 3.3 are, thus, accomplished partly concurrently. This
exempliﬁes a property called a sequential equivalence: the outcome of concurrent
execution (with observance of exclusive access to resources—if necassary) must be
identical with that of sequential execution.
Transactions may be nested, as depicted in Fig. 3.4. The account owners make
bank transfer to C1 and C2, the latter nested inside C1.
3.1
Concurrent Execution of Programs
67

bank 
5 EUR  
B        C
 3 EUR  
C        D 
owner of account B 
DBMS 
accounts 
  balance of accounts 
B     C        D   
50 
200
100
45 
97
read C  to temB; 
temB := temB + 5; 
write temB to C 
read B to temB; 
if temB < 5 then abort;
temB := temB – 5;
write temB to B; 
payoﬀ from B  payment to C 
200
45 
97
203
45 
97
205
bank transfer transacƟon 
50 
200
read D to temD; 
if temD < 3 then abort; 
temD := temD – 3;
write temD to D; 
read C to temD; 
temD := temD + 3;
write temD to C; 
97
ERROR
B     
C       D   
external Ɵme 
owner of account D 
payoﬀ from D payment to C 
bank transfer transacƟon 
Fig. 3.1 No blocking—lost update of account C; temB and temD are variables for temporary
values
5 EUR 
B        C
3 EUR 
C        D
45 
97
read C  to temB; 
temB := temB + 5; 
write temB to C;
unlock B,C
lock B,C;
read B to temB; 
if temB < 5 then abort;
temB := temB – 5;
write temB to B;
200
45 
97
203
45 
97
208
50 
200
lock D,C;
97
      B         C       D  
the process waits
for unlock of 
account C
45 
97
203
external Ɵme
owner of account B  
owner of account D  
bank
DBMS 
accounts 
50 
200
100
  balance of accounts
        B        C        D  
read D to temD; 
if temD < 3 then abort;
temD := temD – 3;
write temD to D; 
read C to temD; 
temD := temD + 3;
write temD to C;
unlock D,C
bank transfer transacƟon
payoﬀfrom B 
payment to C
bank transfer transacƟon
payoﬀfrom D payment to C
Fig. 3.2 Correct blocking; protective zones are in frames on grey background; accounts B and D
are being concurrently read and written by their owners only
68
3
Concurrency

Nesting of transactions may be accomplished by two servers, as shown in
Fig. 3.5. For instance, server 1 that handles account C1, conveys to server 2 the
transfer of some amount of money to account C2 (and reciprocally).
50 
200
100
45 
97
lock C 
200
45 
97
203
45 
97
208
50 
200
lock C 
read C to temD; 
temD := temD + 5;
write temD to C
unlock C 
97
5 EUR 
B        C
3 EUR 
C        D
external Ɵme
owner of account B  
owner of account D  
bank
DBMS 
accounts 
balance of accounts
        B        C        D  
bank transfer transacƟon
payoﬀfrom B 
payment to C
bank transfer transacƟon
payoﬀfrom D
payment to C
read B to temB; 
if temB < 5 then abort;
temB := temB – 5;
write temB to B;
the process waits for 
unlock of account C 
read C  to temB; 
temB := temB + 5;
write temB to C
unlock C 
read D to temD; 
if temD < 3 then abort; 
temD := temD – 3;
write temD to D;
Fig. 3.3 Correct blocking with ﬁner-grained zones protecting account C if access to B and D is
restricted to their owners by resource management protocols
4 EUR 
B        C1
8 EUR 
C1        D 
B       C1       C2       D  
200
700
300
300
read C2  to temB; 
temB := temB + 5; 
write temB to C2
unlock C2 
lock C1 
read B to temB; 
if robB < 4 then abort;
temB := temB – 4; 
write temB to B;
96
200
100
5 EUR 
B        C2
3 EUR 
C2        D 
lock C2 
read B to temB; 
if temB < 5 then abort;
temB := temB – 5; 
write temB to B;
read C1  to temB; 
temB := temB + 4; 
write temB to C1
unlock C1 
lock C1 
read D to temD; 
if temD < 8 then abort;
temD := temD – 8; 
write temD to D;
read C1  to temD; 
temD := temD + 8; 
write temD to C1
unlock C1 
lock C2 
read D to temD; 
if temD < 3 then abort;
temD := temD – 3; 
write temD to D;
read C2  to temD; 
temD := temD + 3; 
write temD to C2
unlock C2 
waits for access to C1 
waits for access to C2 
700
292
91
200
700
289
91
200
705
289
91
200
700
292
96
200
700
289
91
204
708
289
91
200
708
289
91
212
708
bank
DBMS 
accounts 
external Ɵme
bank transfer to C1 and C2
bank transfer to C1 and C2
bank transfer to C2
bank transfer to C2
owner of account B  
owner of account D  
Fig. 3.4 Nested transactions
3.1
Concurrent Execution of Programs
69

However, nesting of transactions is fairly deadlock-prone, as shown in Fig. 3.6.
The lock Z entitles to access resources Z, only the process in which this action
has been performed and no other process is currently using Z. Thus, it prevents
access to Z for other processes, both to reading and writing. However, writing only
may change state of Z. So, to preserve consistency of resources, if a process is
writing something to Z, no other one may be reading from Z nor writing to Z at the
time. Though processes may read resource concurrently, they should prevent from
writing to it at the time. That is why before start of reading, delay of writing to Z
must be ensured until completion of all readings of Z. To this end the action read-
lock Z is introduced, which allows concurrent reading Z but prevents writing to Z
when Z is in use, as well as the action read-unlock Z which cancels the former.
Such actions are called shared locking. This mechanism fulﬁls the principle of
exclusive writing and concurrent reading. Yet, if for applications where the reading
only should be exclusive, but not the writing, the management system may offer
actions
„symmetric”
to
the
former:
write-lock,
write-unlock.
In
general,
5 EUR 
     B       C2
manager of 
account C1
server 1 
manager of 
accunt C2
server 2 
3 EUR 
C1      D
4 EUR 
     B      C1
5 EUR 
     B      C2
3 EUR 
C1      D
8 EUR 
C2      D
owner of account B  
owner of account D  
Fig. 3.5 Server 2 is a client for server 1 and conversely
bank
4 EUR 
B        C1
8 EUR 
C1        D 
owner of account B  
DBMS 
accounts 
B       C1       C2       D  
200
700
300
300
96
200
external Ɵme
100
5 EUR 
B        C2
3 EUR 
C2        D 
payoﬀfrom B
700
297
96
200
700
payoﬀfrom B
lock C1 
read B to temB; 
if temB < 4 then abort; 
temB := temB – 4; 
write temB to B;
lock C2 
read D to temD; 
if temD < 3 then abort; 
temD := temD - 3; 
write temD to B;
lock C2 
read B to temB; 
if temB < 5 then abort;
temB := temB – 5; 
write temB to B;
lock C1 
read D to temD; 
if temD < 8 then abort;
temD := temD – 8; 
write temD to D;
waits for access to 
C2, which will
never occur
waits for access to 
C1, which will
never occur
payoﬀfrom D payoﬀfrom D
297
91
200
700
297
96
200
700
289
91
200
700
owner of account D  
Fig. 3.6 Deadlock: endless mutual waiting for unlock of accounts
70
3
Concurrency

management protocols may enforce various access strategies. In this way they may
enhance degree of concurrency, but also chances of errors—when inattentively
applied, as illustrated in Fig. 3.7.
Obviously, the problem of concurrent reading/writing concerns not only bank
transactions, but all transactions where such operations are applied, for
instance in data bases. The principle of exclusive writing and concurrent
reading, in abstract setting, is referred to as the readers/writers problem,
originally described in (Courtois et al. 1971), then many times investigated in
various versions (e.g. with priority to the readers or writers). This principle,
embodied into access strategy, has been applied in our exemplary bank
transactions.
Example 2: check-up of bank assets Another (than the lost update), result of
incorrect programming of transaction, is the so-called the incoherent data recovery,
exempliﬁed in Fig. 3.8. A bank wants to know, from time to time, the total balance
of all accounts, so makes their summation. During this summation, the clients make
transactions—the lady makes a bank transfer from her account D, to the account C.
The total balance of all accounts after her bank transfer and after the summation is
1497 EUR instead of 1500 EUR. Incorrect outcome!
The correct outcome is obtained if the summation and the bank transfer are
closed into the protective zones, as in Fig. 3.9.
5 EUR 
B        C
3 EUR 
C        D
97
read C  to temB; 
temB := temB + 5; 
write temB to C;
read-unlock B,C
read-lock B,C;
read B to temB; 
if temB < 5 then abort;
temB := temB – 5;
write temB to B;
45 
97
205
45
200
read-lock D,C;
      B         C       D  
the process waits for 
unlock of account C
45 
97
203
external Ɵme
owner of account B  
owner of account D  
bank
DBMS 
accounts 
50 
200
100
  balance of accounts
        B        C        D  
read D to temD; 
if temD < 3 then abort;
temD := temD – 3;
write temD to D; 
read C to temD; 
temD := temD + 3;
write temD to C;
read-unlock D,C
bank transfer transacƟon
payoﬀfrom B 
payment to C
bank transfer transacƟon
payoﬀfrom D
payment to C
50 
200
100
shared locking for 
read – concurrent
reading of account C 
ERROR
Fig. 3.7 The lady made shared locking of account C for read, which caused the lost update
3.1
Concurrent Execution of Programs
71

         SUM     B      C       D       E       F        
100 200  300 400 500
000
read B to SUM;
read C to tem; 
SUM := SUM + tem; 
read D to tem; 
SUM := SUM + tem; 
read E to tem; 
SUM := SUM + tem; 
read F to tem; 
SUM := SUM + tem
summaƟon 
300
100
597
997
1497
100
100
100
100
100
200
200
200
203
203
297
300
297
297
297
400
400
400
400
400
500
500
500
500
500
3 EUR 
C        D
external Ɵme
bank
DBMS 
accounts
owner of account D  
read D to temD; 
if temD < 3 then abort; 
temD := temD – 3;
write temD to D;
read C to temD; 
temD := temD + 3;
write temD to C;
payoﬀfrom D
payment to C
bank transfer
ERROR
Fig. 3.8 No blocking—incoherent recovery; the total sum should amount to 1500 EUR
lock C,D
read D to temD; 
if robD < 3 then abort; 
temD := temD – 3;
write temD to D;
read C to temD; 
temD := temD + 3;
write temD to C; 
unlock C,D
lock B,C,D,E,F 
read B to SUM
read C to tem; 
SUM := SUM + tem; 
read D to tem; 
SUM := SUM + tem; 
read E to tem; 
SUM := SUM + tem; 
read F to tem; 
SUM := SUM + tem; 
unlock B,C,D,E,F 
303
100
600
1000
1500
100
100
100
100
100
203
203
203
203
203
297
297
297
297
297
400
400
400
400
400
500
500
500
500
500
3 EUR 
C        D
100 200  300 400 500
000
SUM    B      C       D       E       F     
bank
DBMS
accounts 
100 200  297 400
000
500
external Ɵme
summaƟon 
the process waits
for unlock of 
accounts C and D 
payoﬀfrom D payment to C
bank transfer
owner of account D 
Fig. 3.9 Correct blocking: coherent recovery; protective zones are in frames on grey background;
accounts C and D are ﬁrst blocked by the client, then, all accounts—by the bank manager, whose
activity has been delayed until unlock of C, D is executed
72
3
Concurrency

3.2
Deadlock
An exemplary pathological situation, occurrent in the parallel processing, is illus-
trated in Fig. 3.6 for nested transactions. The gentleman blocked access to account
C1 before the lady who blocked access to account C2 and both clients have made
pay-off from their own accounts B and D. Then the gentleman blocked C2, the lady
blocked C1 (the accounts already blocked) and both clients again made pay-off
from accounts B and D. The clients are waiting for unblock of accounts C1 and C2
delayed indeﬁnitely. This kind of deadlock is referred to as a deadly embrace,
illustrated in Fig. 3.10.
Such reciprocal expectation for events is a simplest case of deadlock. Some not
so simple is when transactions (processes in general) are expecting some events in a
single cycle as in Fig. 3.11 or quite complicated when transactions are interelated
creating a graph with cycles, as in Fig. 3.12.
intended bank transfers
B 
C1, B 
C2
the gentleman waiƟng for unblock C2 blocked by the lady 
the lady waiƟng for unblock C1 blocked by the gentleman 
intended bank transfers
D 
C1, D 
C2
Fig. 3.10 Deadly embrace of two transactions
T1
T2
T3
T4
Fig. 3.11 Transaction T1 expects event from T2 and so on, up to situation when T4, expects
event from T1. The deadlock is caused by a cycle of expectations (the so-called wait loop)
T1 
T2 
T3 
T5 
T7 
T6 
T4 
T9 
T8 
Fig. 3.12 The wait graph
containing cycles: numerous
deadlocks possible
3.2
Deadlock
73

A graph exemplifying current state of waiting for events by nine transactions is
in Fig. 3.12. Vertex (node) of the graph stands for a transaction whereas arrow—a
waiting for an event from transaction pointed to. Such a graph, called the wait
graph, characterizes existence of deadlocks in the current state of system execution:
In a set of processes, a deadlock occurs if and only if the respective wait graph
contains a cycle.
For any set of processes the system management may build the wait graph. Note
that in this notion, there is no requirement of concurrency of processes: in such
case, the relation of waiting is then empty. The wait graph is a dynamic structure: it
is evolving during the system run, because the nodes (processes) and arrows (ex-
pectations) appear and disappear.
Deadlock is a pathological situation. So the designer of a distributed system must
take it into account, and should provide a suitable remedy. To this end, the fol-
lowing kinds of salvage operations are distinguished:
Deadlock prevention—may be obtained by:
• blocking of all resources used during a transaction at its initiation and
unblocking at its termination, as in Fig. 3.2. However this makes slower access
to the shared resources (too coarse granulation), thus, this limits concurrency,
and what is more, usually it is not known at the beginning of the transaction,
what resources will be used;
• blocking resources in a ﬁxed order; but this also limits concurrency as well as
causes their untimely blocking.
Deadlock detection and removal—may be accomplished if:
• a module managing deadlocks creates and maintains the wait graph, in which
periodically detects cycles and makes decision, which transaction should be
aborted, so that to break the cycles; then makes the system return to a state from
before occurrence of the deadlock;
• the system returns to a state from before occurrence of the deadlock, if sus-
pension of activity exceeds predeﬁned time—the timeout occurred;
The above examples of deadlocks arise, when processes that compete for
resources, are not correctly ordered in time. Thus a source of such situations lies in
incorrect synchronization. Another source of deadlocks is incorrect organization of
communication between processes (Chap. 5). Notice that a system designer faces
some contradictory needs: deadlock control vs system efﬁciency. Admittance of
deadlocks, if are believed infrequent, enhances degree of concurrency—more
processes exist in overlapping time periods. On the other hand, prevention,
detection and removal procedures indispensable for protection against endless
suspension of activity, deteriorate the system performance. So, design policy must
resolve what is more favourable in applications the distributed system is intended
for. Perhaps a compromise.
74
3
Concurrency

3.3
Starvation
Besides the deadlock, a harmful situation is starvation of processes. Consider the
following example. Computers in companies A, B, C are performing the following
actions:
(1) check income in company book-keeping;
(2) block access to revenue ofﬁces accounts;
(3) pay tax to tax ofﬁce;
(4) pay fee to social security;
(5) unblock access to accounts blocked in 2;
(6) repay part of debt;
(7) check income and go to 2.
Actions 2 and 5 concern blocking and unblocking resources of ofﬁces in charge
of tax revenue and social security. Concurrent execution of this system by com-
puters A, B, C, may result in situation shown in Table 3.1 (the arrow pointing to
actions, indicates presence of control in the „programs”). This situation occurs
when computer of company B is never allowed to perform actions 3 and 4—
computers A and C always forestall it. The states (numbered on grey background)
are repeated cyclically: (4,5,6,7,8,9), (10,11,12,13,14,15), (16,17,18, …),… etc.,
that is, corresponding states in the bracketed groups are identical. Exactly:
state(n) = state(n + 6) for n > 3, where state(n) denotes the nth state of this inﬁnite
sequence. Computer of the company B will never go out of action 2. The situation
is called a starvation of the company’s B process. It may be said metaphorically
that a conspiracy of companies A and C against the company B has occurred.
Starvation is caused by faulty („unfair”) strategy of allocation of resources by
their managers. In general, this situation may be expressed as follows:
Starvation of a program during the run occurs if and only if execution of some
its actions that must be executed, will never be executed in ﬁnite time during
evolution of the system, resulting in the program activity indeﬁnite suspension.
In particular, starving of a process occurs when its request for access to a
resource will not be fulﬁlled in ﬁnite time during further evolution of the system.
There is a certain theoretical fact: the precise investigation of the starvation
notion requires stronger formal means than investigation of deadlock. In case
of starvation, they belong to the second order logic (where variables bound by
quantiﬁers may stand for sets, functions, relations), whereas in case of
deadlock—the ﬁrst order logic sufﬁces (the bound variables stand for simple,
indivisible objects like numbers) (Czaja 1980).
3.3
Starvation
75

Table 3.1 The process continued indeﬁnitely—computers of companies A and C permanently
outdistance the computer of company B in effective execution of action 2 (to inﬁnity)
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
2 
1 
3 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
5 
4 
6 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
8 
7 
(continued)
76
3
Concurrency

(continued)
Table 3.1 (continued)
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
9 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
11 
10 
12 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
14 
13 
15 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
16 
3.3
Starvation
77

This chapter is concluded with presenting two realizations of mutual exclusion
in distributed systems, where interprocess communication takes place by means of
message passing through the network only, not by shared memory. Synchronization
is, thus, possible only in this way. These two realizations are: by supervisory server
and by token ring. Others, based on logical clocks and global timestamps will be
presented in Chap. 4.
3.4
Mutual Exclusion by Supervisory Server
Assume there is one protective zone (a counterpart of critical section in centralized
systems) and during its execution no failure of the system occurs. The supervisory
server receives requests for protected resources from user processes and makes
decision if the resources can be accessed. If yes, it sends a message permission to
the requesting process, otherwise (because another process is using the resource)—
sends a message refusal and puts the process (its name and its current state) in the
queue of waiting processes. On completion of executing of protective zone, the
process sends a message release to the server and continues further run—execution
of the local section. Then the server removes a waiting process from the head of
queue and reactivates it. Notice that in this solution, the protective zone is being
performed by a process which requested a resource, not by the server. In the
opposite case, the server would send the release message to the user process.
A schema of the supervisory server is in Fig. 3.13 and its exemplary activity in
Table 3.2.
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company A 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company B 
1. check income in company book-keeping; 
2. block access to revenue oﬃces accounts;
3. pay tax due to tax oﬃce;
4. pay fee to social security;
5. unblock access to accounts blocked in 2;
6. repay part of debt;
7. check income and go to 2;
Company C 
17 
18 
Table 3.1 (continued)
78
3
Concurrency

3.5
Mutual Exclusion—Token-Ring Algorithm
Processes p1, p2, p3,…,pn are connected into a ring (cycle) which determines a
route of the token. Their order is arbitrary but ﬁxed, for instance like in Fig. 3.14.
A module of the system, that manages the ring, grants authorization for the
processes to enter the protective zone in the ordering determined by succession in
the ring. Metaphorically, this authorization is called a „token”. Every process
knows identiﬁer of its successor in the ring. If a process is not in the protective
zone, nor is requesting to execute it and has received a token from its predecessor,
then immediately conveys the token to its successor. If it has issued request, then
waits for a token, and as soon as receives the token—keeps it, executes the pro-
tective zone and on completion of the execution—conveys the token to the suc-
cessor in the ring. The processes may be in the same states as in case of the method
of the supervising server. A schema of the token ring of 4 processes is in Fig. 3.15
and its exemplary activity in Table 3.3.
Fig. 3.13 A schematic view of a system of 4 processes and server managing mutual exclusion
p1 
p2
 p3
…
pn
Fig. 3.14 Token ring
3.5
Mutual Exclusion—Token-Ring Algorithm
79

Table 3.2 States 1–12 of 4 processes with supervisory server managing mutual exclusion
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
1 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
2 
request
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
3 
permission 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
4 
request
 p3 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
5 
refusal
 p3 
 p1 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
6 
 p3 
 p1 
request
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
7 
 p3 
 p4 
refusal
 p1 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
tail
head 
8 
 p3 
 p4 
 p1 
request
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
9 
 p3 
 p4 
 p1 
refusal
 p2 
tail
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
10
 p3 
 p4 
 p1 
 p2 
release 
tail
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
11
 p4  p2 
permission 
tail
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
12
 p4  p2 
 p1 
tail
(continued)
80
3
Concurrency

protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
13
 p4  p2 
 p1 
release 
tail
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
14
 p2 
permission 
tail
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
15
 p2 
tail
 p4 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
16
 p2 
tail
 p4 
request
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
17
 p2 
tail
 p4 
 p3 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
18
 p2 
tail
 p4 
 p3 
release 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
19
tail
 p3 
permission 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
20
tail
 p3 
 p2 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
21
tail
 p3 
 p2 
release 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
22
tail
permission 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
23
tail
 p3 
protecƟve zone
p1
p3
p4
p2
queue of processes waiƟng to enter protecƟve zone
head 
24
tail
 p3 
release 
Table 3.2 (continued)
3.5
Mutual Exclusion—Token-Ring Algorithm
81

p1 
p2 
p4 
p3 
token
route of the token
execuƟon of 
local secƟon
execuƟon of 
local secƟon
execuƟon of 
local secƟon
execuƟon of 
local secƟon
state of process: 
request for execuƟng
protecƟve zone
permission 
execuƟon of 
local secƟon
execuƟon of 
protecƟve zone
release of 
protecƟve zone
refusal
Fig. 3.15 Schema of the token ring with four processes
82
3
Concurrency

Table 3.3 Four processes with token ring managing mutual exclusion
p1 
p2 
p4 
p3 
1 
local secƟon
p1 
p2 
p4 
p3 
2 
local secƟon
p1 
p2 
p4 
p3 
3 
local secƟon
p1 
p2 
p4
p3 
protecƟve
zone
4 
local secƟon
p1 
p2 
p4
p3 
5 
p1 
p2 
p4
p3 
protecƟve
zone
6 
refusal
local secƟon
local secƟon
local secƟon
local secƟon
request for 
protecƟve
zone
request for 
protecƟve
zone
local secƟon
local secƟon
request for 
protecƟve
zone
protecƟve
zone
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
permission 
p1 
p2 
p4
p3 
7 
p1 
p2 
p4
p3 
8 
p1 
p2 
p4
p3 
9 
p1 
p2 
p4
p3 
protecƟve
zone
10 
p1 
p2 
p4
p3 
11 
p1 
p2 
p4 
p3 
12 
local secƟon
local secƟon
request for 
protecƟve
zone
protecƟve
zone
protecƟve
zone
refusal
refusal
refusal
protecƟve
zone
refusal
refusal
request for 
protecƟve
zone
refusal
refusal
refusal
refusal
refusal
refusal
release
local secƟon
refusal
refusal
permission 
p1
p2 
p4 
p3 
13 
p1
p2 
p4 
p3 
14 
p1 
p2 
p4 
p3 
15 
protecƟve
zone
refusal
refusal
refusal
local secƟon
refusal
release
local secƟon
refusal
local secƟon
local secƟon
permission 
(continued)
3.5
Mutual Exclusion—Token-Ring Algorithm
83

References
Courtois, J., Heymans, F., & Parnas, D. L. (1971). Concurrent Control with “Readers” and
“Writers”. Communication of the ACM, 14(10), 667–668.
Czaja, L. (1980). Deadlock and fairness in parallel schemas: A set-theoretic characterization and
decision problems. Information Processing Letters, 10(4–5), 234–239.
Weikum, G., & Vossen, G. (2002). Transactional information systems: Theory, algorithms, and
the practice of concurrency control and recovery. Elsevier.
p1 
p2
p4 
p3 
protecƟve
zone
16 
p1 
p2
p4 
p3 
17 
p1 
p2 
p4 
p3 
18 
refusal
refusal
release
local secƟon
permission 
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
p1 
p2 
p4 
p3
19 
p1 
p2 
p4 
p3
20 
p1 
p2 
p4 
p3 
21 
p1 
p2 
p4 
p3 
protecƟve
zone
22 
p1 
p2 
p4 
p3 
23 
p1 
p2 
p4 
p3 
24 
release
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
local secƟon
Table 3.3 (continued)
84
3
Concurrency

Chapter 4
Time, Coordination, Mutual Exclusion
Without Supervisory Manager
4.1
Physical Time
In the sequential processor, time is measured by its clock and progresses linearly,
i.e. for any two distinct events, one of them precedes the other. Ordering of events,
that is lapse of time in the processor, is based on the notion of precedence. As an
indivisible (atomic) event, the clock’s pulse called a „tick” is admitted. But exe-
cution of a processor’s instruction (regarded before as an event) takes place usually
in several ticks, as well as between consecutive ticks, some electric actions appear,
being effect of some phenomena on the nuclear level, etc. That is why the set of real
numbers with ordinary ordering is admitted as a model of linear time, because
between two distinct real numbers (images of events—abstract objects), there is a
different real number (an image of certain event). But why not the set of rational
numbers, which enjoys the same characteristic? Because physical magnitudes that
depend on time, are often expressed by operations that return real numbers. Because
ﬂow of time in a processor is measured by ticks of its clock and clocks in different
processors have different ticking frequencies, we say about the local time of pro-
cessors. In the distributed system, i.e. in a collection of processors, the ﬂow of time
cannot be measured by ticks of their clocks: it is impossible to say for any two
events, that one event precedes the other: a common clock does not exist. Events
are partially ordered, not linearly. However, there is sometimes a need to con-
temporize some actions, e.g. dispatch of a message must precede its reception. For
some applications, a pattern of external (global) time is needed to which the system
may refer, when makes a coordination. Such a pattern is a sequence of some events
that occur in a chosen physical phenomenon. This is a sequence of occurrences of a
periodical phenomenon of a chosen physical reality. Such a choice is prompted by
possibly regular periodicity of the phenomenon. Examples:
• Sun-Earth (solar time, real and mean). Event: crossing a ﬁxedly agreed
meridian by the sun. As the mean solar second, has been admitted 1/86400 of
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_4
85

the period between two such consecutive events; This magnitude is not exactly
ﬁxed, because this period lengthens about 16 ls (in average) annually.
• Quartz crystal oscillator in clocks; chosen effect—deformation of quartz crystal
under electric ﬁeld; frequency spans between tens of thousand to tens of million
deformations (depending on workmanship) in the period deﬁned to be one
second—according to a certain ﬁxed pattern of time measure.
• Atomic oscillator—now a standard since 1967, one second: 9 192 631 770
periods of transition between two energy levels in the basic state of Caesium-133.
Event: change of energy level. On this oscillator is based nowadays the so-called
Universal Time Clock and Coordinated Universal Time (in English) or Temps
Universel Coordonné (in French) of accuracy better than 1 s in 1.4 milion years
(compromise acronym: UTC). Signals of the UTC time are broadcast by radio
broadcasting stations and by Internet (http://www.worldtimeserver.com/current_
time_in_UTC.aspx). This is the so-called timed signal service.
Remarks
1. It might be predicted that the race for better and better accuracy of time
measuring will never be ended. This is so, because of fast development of
technology and science, wherever this is indispensable. A few examples
are: GPS technology applied in vehicle navigation, particularly driverless,
for new kind of sensors in geological explorations, for precise navigation
of aircrafts and spacecrafts, for precise spectrometers in the international
space stations, also for observational astrophysics. That is why more
accurate time measurements have been invented recently, than that based
on Caesium-133. These are, for instance, the so-called mercury-clock,
reported of at least 5 times better accuracy than the caesium clock, an
optical single-ion clock of 100 times better accuracy than the caesium
clock, or quite recently the so-called Quantum Logic Clock. All these
clocks, exceeding the accuracy of the standard caesium clock, are
experimental devices so far, devised in 10 recent years.
2. The presentation of phenomena appearing in distributed systems will be
based on conventional, everyday practice perception of „ﬂow” of time.
So, the presentation refrains from taking into account such relativistic
facts like different outcomes of seeing order of the same events by two
external observers or lack of meaning of commonly experienced notions
like „simultaneity”, „earlier”, „later”, etc. On the generality level of pre-
sentation adopted here, such notions will be used liberally, whenever
prove helpful in explaining distributed systems’ properties. Although the
aforementioned consequences of ﬁnite light velocity will not inﬂuence our
considerations, the duration of data transmission through the network will
be of primary importance in this and next chapters.
86
4
Time, Coordination, Mutual Exclusion Without …

In a chosen physical system, the real numbers are univocally assigned to events
in a distributed system, in such way that if an event x occurs earlier than y (but
remember remark 2 above), then the number assigned to x is less than the number
assigned to y. We say that events appear in instants that are their numerical images.
Physical time is treated here as the linearly ordered set of instants—images of
events—in a given physical system. Therefore, it depends on this system. An event
will be treated as a primary notion, an indivisible, timeless object. The notion of a
partial and linear order relation will be needed (binary relations—see Sect. 10.1 in
Chap. 10):
A
set
Z
is
partially
ordered
iff
its
elements
are
related
by
relation ⊑ Z  Z satisfying: for every x 2 Z, y 2 Z, z 2 Z:
1. x ⊑x (reﬂexivity)
2. if x ⊑y and y ⊑x then x = y (antisymmetry)
3. if x ⊑y and y ⊑z then x ⊑z (transitivity)
Moreover, if apart from (1), (2), (3):
4. x ⊑y or y ⊑x (connectivity)
then Z is linearly (totally) ordered. As usually, x ⊏y iff x ⊑y and x 6¼ y.
The set Z  Z (Cartesian product) denotes the set of all ordered pairs of elements
of the set Z, thus the order ⊑and ⊏is a subset of Z  Z, satisfying above axioms.
In case of partial (but not linear) order, it is not necessary that any two elements be
related by ⊑order. The set of all events during activity of a distributed system, is
ordered only partially by relation ⊑(meant as „event x occurs earlier than y or
x = y”), because not all pairs of events are necessarily related by the ⊑order. The
set of events emited by any sequential processor is linearly ordered by ⊑. The order
of instants of time C(x), C(y), i.e. real numbers, assigned to events x, y, must be
coherent with the order of these events in the following sense: if x ⊑y then
C(x) < C(y). It will be seen that the converse implication is not true.
A coordination of local time of processors, that is synchronization of their
clocks, may be accomplished:
• by referring to a pattern of physical time, like UTC, for some applications, e.g.
when real time of banking transactions should be recorded;
• by periodical computing of arithmetic average of clocks’ indications in pro-
cessors and setting the clocks to this average;
• between clocks of various processors in the network, so that the logical order of
events be preserved, necessary for their meaning, for instance, reception of a
message can never occur earlier than its dispatch.
The two ﬁrst ways of clock synchronization are referred to as realization of
physical clock, the third one—realization of logical clock. Let us at ﬁrst consider
examples of realization of a physical clock.
4.1
Physical Time
87

4.1.1
The Cristian Method of Clock Synchronization
(Cristian 1989)
The standard time UTC, requested by client-computers, is being delivered by a time
server, thus, by an external source for the clients. In a moment of reception, the
standard time is later than delivered by the server, due to the transmission duration.
Moreover, if the client’s local time ﬂows faster than time of server and the client
announces e.g. time of takeoff of an aircraft, then, after receiving the server’s time,
announces the landing time, it might happen that the aircraft landed before the
takeoff—even in the same time zone. The client’s time „stepped back”, which is
impermissible in a correct synchronization. These problems are being solved by the
Cristian method as follows. Let t0 be a time of sending request to the server by the
client, let T0 be a time when the request reached the server, let T1 be a time of
sending reply T to the client by the server and let t1 be a time of reception of
message T (the reply T is the requested standard time). All these times are external,
standard, say, UTC, see Fig. 4.1.
In the simplest variant of the method it is assumed that the reply takes:
t1  t0
ð
Þ  T1  T0
ð
Þ
2
of time units
and the client sets its clock to time:
T þ t1  t0
ð
Þ  ðT1  T0Þ
2
¼ T þ T0  t0
ð
Þ þ ðt1  T1Þ
2
 T þ t1 T1
assuming that travel period of request (T0 −t0) and of reply (t1 −T1) through the
network are approximately equal. They are not ﬁxed: they depend on network load,
distance between server and client, etc. and may be estimated only [the reasoning
behind the estimation is in the original publication (Cristian 1989)]. The period
T1 −T0 of preparing a packet with reply T by the server, is negligible in com-
parison with transmission time, so is neglected. Thus, value T delivered by the
server is increased by t1 −T1.
Ɵme server
client
T0 T  T1
UTC
UTC
Ɵme UTC delivered by the Ɵme server
t0
T0 T  T1
t1
Fig. 4.1 Passing messages
between the client and time
server
88
4
Time, Coordination, Mutual Exclusion Without …

Estimation of the Cristian’s method accuracy
If the shortest possible time of sending a client’s request and (similar) time of
returning response of the server is known as m ¼ minðT0  t0Þ  minðt1  T1Þ,
then after sending request in a moment t, the server would get it at the earliest in the
moment t + m. On the other hand, the server returns response at the latest in the
moment t þ t0  t
ð
Þ m ¼ t0  m where t0 is a moment of reception of server’s time
T, by the client.
Therefore, T satisﬁes the inequalities: t þ m\T\t0−m i.e. T is contained in the
period:
t0m  t þ m
ð
Þ ¼
t0  t
ð
Þ2m. Hence, the accuracy of the method:
t0  t  2m
2
¼ t0  t
2
 m
Value t0  t
ð
Þ is the period from a request till response.
Because transmission time of the client’s request and the server’s reply are
indeﬁnite and possible are system failures, the Cristian’s paper (Cristian 1989)
focusses on a probabilistic analysis of synchronization between the client and server.
The avoidance of stepping back of the client’s clock
The second problem in synchronizing of clocks is avoidance of stepping back of
client’s clock if it is faster than the server’s clock. Let H be a client’s hardware
clock and suppose it cannot be set by software. In order to synchronize (approxi-
mately—the exact is impossible!) this clock with the server’s clock, the so-called
virtual clock C (sometimes called „logical”, but this term is reserved for the
Sect. 4.2) is programmed as a special register, and set periodically to the time
delivered by the server. This is a „clock” for correcting the hardware clock H
indications. Formally, H and C are functions of time:
H:
R ! R (R-the set of real numbers)
C:
R ! R
Values t −H(t) and t −C(t) are deviations of the times shown by clocks
H and C, from t—the physical time shown by the server. Thus, d(t) = (t −H(t) −
(t −C(t)) = C(t) −H(t) is the value, by which the time of H must be corrected so
that to obtain the time of the clock C:
C tð Þ ¼ H tð Þ þ d tð Þ
Assume that d is a continuous function (to ensure avoidance of „jumps” of the
virtual clock C) and in the simple variant let it be linear:
4.1
Physical Time
89

d tð Þ ¼ x  H tð Þ þ y
where x and y are constants which can be calculated as follows. First, note that
C tð Þ ¼ H tð Þ þ d tð Þ ¼ H tð Þ þ x  H tð Þ þ y ¼
1 þ x
ð
Þ  H tð Þ þ y
is
the
time
shown by clock C when clock H shows H(t). Next, assume that at the moment t, the
virtual clock C shows L = C(t) and hardware clock H shows h = H(t) and the server
shows physical time M. If M > L, then the time shown by C should be increased
and if M < L, it should be decreased, so that after a period Dt (from t), the clock C
would show time M + Dt, but not L + Dt. Putting these times to equation
C tð Þ ¼
1 þ x
ð
Þ  H tð Þ þ y we get that in the moment t the clock C shows time
L ¼
1 þ x
ð
Þ  h þ y and in the moment t + Dt the clock C shows a compensated
time M þ Dt ¼
1 þ x
ð
Þ  ðh þ DtÞ þ y. Therefore, we have two linear equations
with two unknowns x and y:
h  x þ y ¼ L  h
ðh þ DtÞ  x þ y ¼ M  h
Assuming Dt 6¼ 0, after solving the equations, we get:
x ¼ M  L
Dt
y ¼ ðh þ DtÞ  L  ðM þ DtÞ  h
Dt
The Cristian’s method is passive, in that the time server is inactive as long as it
does not receive a request for time synchronization from a client. Here, the external
source of clocks synchronization is applied. To avoid a system failure, in case of
time server crash, several time servers, providing time signals and mutually syn-
chronized, may be used. In this case, the clients send request to all time servers and
synchronize their clocks e.g. in accordance of the ﬁrst response received.
4.1.2
The Berkeley Method of Clock Synchronization
(Gusella 1989)
In this method, developed at the University of California, Berkeley in 1989, there is
no server delivering an external time, e.g. UTC. Instead, there is a computer, chosen
from among all in the system, called a time daemon, which periodically inspects the
local time of all, computes the average of all differences between its own local time
and local times of remaining computers called clients and informs every one how
many time units it should make a shift forward or backward the indication of its
local clock (the time register). Such synchronization is called internal, since does
not refer to the time delivered from outside. The two-way communication between
90
4
Time, Coordination, Mutual Exclusion Without …

the daemon and clients, takes some time, that must be taken into account in
computing the average. Therefore, the daemon must estimate the time of data
transmission: daemon ! clients ! daemon ! clients, as it was the case in the
Cristian’s method. The synchronization proceeds as follows. The daemon broad-
casts its time to all computers, who send back differences between their local times
and the time delivered by the daemon. Then, the daemon computes the average of
the differences and broadcasts amendments to the computers, which on this basis set
local clocks to the average time of all. Table 4.1 shows an example of two con-
secutive time corrections. At the states 1, 2, 3 the synchronization of clocks’
indications to the time 3:07 takes place and at the states 4, 5, 6—to the time 3:14.
The time ﬂow is here expressed in hours and minutes: 3:07 means seven minutes
past three o’clock, in reality, the time units are milliseconds or their fractions. Since
the end of ﬁrst correction till begin of the second, three minutes passed on the
daemon’s clock. It happens that indications of some clients’ clocks differ sub-
stantially (by a predeﬁned constant) from the remaining. Such clients do not take
part in computing the average, but the daemon sends the amendments to such
clients too, who set their clocks to the average time of all. The election of a
computer to play role of the daemon (e.g. if the current one gets faulty) will be
described in Chap. 7. The Berkeley method is active in that the daemon initiates
consecutive cycles of synchronization.
Remarks
1. In the original paper (Gusella 1989) on the Berkeley method, the terms
„master” and „slave” have been used for what we called here „daemon”
and „client”. The term „daemon” refers, in that paper, to a mechanism
responsible for time management inside all computers in question. The
detailed analysis of the method’s accuracy is avaiable in Gusella (1989).
2. Notice that the same result is obtained if the daemon would compute
directly the average time of all computers and broadcast it to all com-
puters. Such computation is shown in the upper right site of states 2 and 5
depicted in the Table 4.1, whereas computation based on deviations
between the daemon’s and clients’ time (for better accuracy)—in the
upper left site.
4.1
Physical Time
91

Table 4.1 Synchronization by means of a daemon. States 1–3 synchronization of clocks by the
daemon—in action
3:00
2:50
3:00
3:13
3:00
3:00
3:00
3:25
daemon
1
clocks not synchronized
the daemon sends its local
Ɵme to all computers
+0:25
2:50
+0:13
3:13
0:00
-0:10
3:00
3:25
daemon
2
(3:00+3:25+2:50+3:13)/4=
(11+0:88)/4=(11+1:28)/4=
(12+0:28)/4=3:07
computers return deviaƟons of
their local Ɵmes, from the
daemon’s; the daemon
computes average of all
deviaƟons:
(0:00+0:25-0:10+0:13)/4=0.07
-0:18
3:07
-0:06
3:07
+0:07
+0:17
3:07
3:07
daemon
3
clocks synchronized
the daemon noƟﬁes the
computers how much a
given computer should
decrease or increase its
local Ɵme, so thaƩ o
equalize all indicaƟons of
clocks, to be set on the
average Ɵme of all
computers.
(continued)
92
4
Time, Coordination, Mutual Exclusion Without …

3:10
3:10
3:10
3:10
daemon
3:10
3:08
3:13
3:25
4
aŌer 3 minutes clocks
not synchronized again
the daemon sends its local
Ɵme to all computers
+0:15
+0:03
-0:02
3:10
daemon
0:00
3:08
3:13
3:25
5
(3:10+3:25+3:08+3:13)/4=
(12+0:56)/4=3:14
computers return deviaƟons of
their local Ɵmes, from the
daemon’s; the daemon
computes the average of all
deviaƟons:
(0:00+0:15-0:02+0:03)/4=0.04
-
1
0:0
+
1
1:0
+0:06
3:14
daemon
+0:00
3:14
3:14
3:14
6
the daemon noƟﬁes the
computers how much a
given computer should
decrease or increase its
local Ɵme, so thaƩ o
equalize all indicaƟons of
clocks, to be set on the
average Ɵme of all
computers.
clocks synchronized
Table 4.1 (continued)
4.1
Physical Time
93

4.1.3
The Network Time Protocol (NTP) Method
of Synchronization of Clocks (Mills 1991)
In this method, computers in the system are arranged in a varying layered graph
structure. A graph has an n-layered structure (n > 1) if its set of vertices V can be
partitioned into a union of subsets numbered from 1 to n: V = V1 [ V2 [ ⋯[
Vn, Vi \ Vj = ∅(i, j = 1,…, n, i 6¼ j), called layers, so that edges may connect
vertices from the neighbouring layers Vi, Vi+1 only. The structure is called a syn-
chronization subnet. Computers in layer 1 receive directly signals of UTC from a
time service and are mutually synchronized. Computers of the i + 1 (i < n) layer
are being synchronized by computers of the layer i by means of a certain chosen
method, e.g. by the Cristian’s method, extended to a group of synchronizing
computers. Therefore computers of the layer i + 1 play a part of clients of com-
puters of the layer i. That is why all computers in this method are called servers.
Synchronization is all the more exact in layers closer to the time service, i.e. those
with low numbers. Apart from their function as synchronisers and clients, the
computers may intercommunicate regardless of their location in the graph layered
structure. Communication links not intended for synchronization, are used for
reconﬁguration of the graph structure, when a certain computer gets faulty and is
removed from the synchronization subnet, or crosses from one layer to another
when a disconnection of synchronizing links with it occured. So, the graph structure
may ﬂuctuate: the synchronization subnet is subject to reconﬁguration. An exem-
plary synchronization subnet in the course of working is depicted in Table 4.2.
Computer L has passed from layer 3 to layer 2 and computer D from layer 2 to layer
3. Note that the synchronization subnet, for n = 2 is a bipartite graph, which, in this
case, is the communication structure in the Cristian’s method but with more than
one time server. The synchronization subnet is a mechanism for time management
in various kind of networks. It became a basis for standard protocol of clocks
synchronization in the Internet (Network Time Protocol 1989). It takes into account
time zones and transmission delay periods. Advanced statistic methods reduce these
delays in large networks to milliseconds, whereas in local networks—to fractions of
milliseconds. Because of multiplicity of servers and links with clients, the NTP
method enjoys a good degree of fault resistance caused by computers’ failures and
loss of packets in transmission channels. For better efﬁciency, a simpliﬁed version
of the NTP protocol (abbreviated to SNTP) resigns from some algorithms of the full
protocol, not necessarily required by some distributed systems.
4.2
Logical Time: Precedence of Events, Time
Compensation, Timestamps, Logical Clock
Computers measure off time of processes by means of their own clocks, usually of
different frequencies. Thus, it is impossible to ﬁx a linear ordering of events
occurring in different computers working independently, only on the basis of
94
4
Time, Coordination, Mutual Exclusion Without …

Table 4.2 Synchronization of clocks by the NTP method—in action
2
A
B
C
H
G
F
E
D
N
M
L
K
J
I
O
S
R
Q
P
T
1
2
3
4
synchronized
layers 1,2
layers:
Ɵme service (UTC)
1
2
3
4
synchronized
layer 1
layers:
A
B
C
H
G
F
E
D
N
M
L
K
J
I
O
S
R
Q
P
T
1
Ɵme service (UTC)
3
A
B
C
H
G
F
E
D
N
M
L
K
J
I
O
S
R
Q
P
T
1
2
3
4
connecƟon
broken with
computer L
layers:
Ɵme service (UTC)
4
A
B
H
G
N
M
K
J
I
O
S
R
Q
P
T
1
2
3
4
C
F
E
D
L
computer L
passed to layer 2
layers:
Ɵme service (UTC)
5
A
B
H
G
N
K
J
I
O
S
R
Q
P
T
1
2
3
4
C
F
E
D
L
M
connecƟon
broken with
computer D
layers:
Ɵme service (UTC)
6
A
B
N
O
S
R
Q
P
T
1
2
3
4 M
C
H
G
L
F
E
K
J
I
D
computer D
passed to layer 3
layers:
Ɵme service (UTC)
7
A
B
N
O
S
R
Q
P
T
1
2
3
4 M
C
H
G
L
F
E
K
J
I
D
synchronized
layers 1,2,3
layers:
Ɵme service (UTC)
8
A
B
N
O
S
R
Q
P
T
1
2
3
4 M
C
H
G
L
F
E
K
J
I
D
synchronized
layers 1,2,3,4
layers:
Ɵme service (UTC)
4.2
Logical Time: Precedence of Events, Time …
95

indication of their local clocks. Events in the system are only partially ordered. The
computers cooperate by sending messages. There is no common memory, so the
transmission through communication links only makes possible this cooperation.
To avoid absurd situations perceived on the basis of indications of local clocks, it is
necessary to ensure that sending a message would precede (in physical, external
time) its reception. Sending and receiving messages will be the only events (in
different computers) requiring to determine the ordering. Obviously events occur-
ring in every computer with sequential processor are linearly ordered—this is
determined by the processor structure, its instruction cycle (Chap. 1). The abstract
relation of partial and linear order has been deﬁned in Sect. 4.1. Here, let us deﬁne
these relations between events occurring in the same process as well as between
sending and reception of a message, occurring in different processes and let us
combine them into a special partial ordering of events occurring in a system S. Let
E(S) denote the set of all such events. For events a, b 2 E(S) two auxiliary relations
are admitted as primary notions:
!
process and !
message of the following meaning
(1) If a precedes b in the same process or if a = b then a
!
process b
(2) If a is sending a message in a certain process and b is a reception of this
message in another process then a
!
message b
Acc relation of (weak) precedence  E S
ð Þ  E S
ð Þ of events in a system S is a
least (with respect to ) relation satisfying conditions:
i. If a !
process b or a !
message b then a  b
ii. If a  b and b  c then a  c
This precedence is called „weak”, since a a. This is a partial order in the set
E(S), a modiﬁed precedence introduced by Lamport (Lamport 1978), where !
process
is not reﬂexive.
Events a, b are said independent (concurrent) if neither a b nor b a, written
a||b.
Figure 4.2 shows processes p1, p2, p3 where events depicted black denote
sending a message, events grey—reception of a message and white—other events.
The following relationships take place:
a  i; b  k; h  e; c  q; j d
k ; d h
k ; b j
k ; j d
k ; c n
k .
So, x y holds if and only if in the diagram is a path from x to y leading by arrows.
Note that more than one path is possible. Partially ordered events are watched from
outside of the system as occurring in real (external) time, e.g. UTC, thus x y should
hold only if C(x)  C(y), where C(x), C(y) denote real numbers corresponding to
externally visible times of occurrences of the events x, y. Hence, the implication x y
) C(x)  C(y) is required. Because of absence of global clock, a problem arises:
how to determine time measurement in the distributed system, that is, how to assign
96
4
Time, Coordination, Mutual Exclusion Without …

a time instant to a given event, so that this implication be true? To this end, an
injective mapping C: E(S) ! R (R—set of real numbers), called an abstract logical
clock, is deﬁned, satisfying implication x  y ) C(x)  C(y), for all events x, y 2
E(S). If events x, y occur in the same process, then this implication holds evidently,
since relation  reduces to !
process in this case. If however x is a dispatch of a
message and y—its reception, then to make the implication algorithmically realiz-
able, this abstract logical clock should behave similarly to its algorithmic repre-
sentative in the method described in Sect. 4.1 (avoidance of time retreating). That
means, if the dispatch x appeared later than reception y—according to indications of
local clocks of sender and receiver, then the receiver must shift forth indication of its
local clock (time register), so that the local time of y would become somewhat later
than the local time of x. Therefore the sender dispatches—along with a message—its
current local time, the receiver compares it with its own current local time and if it is
earlier than the sender’s, then the receiver makes compensation of its local time. The
exemplary compensation of time during activity of three processes p1, p2, p3 is
shown in Table 4.3. The black fragments of „stretching ribbons” depict increase of
local time as result of compensation.
Deﬁning function C, the abstract logical clock and global timestamps of events
For the formal deﬁnition of function C, some denotations and assumptions will
be needed. If event x precedes y in a process p or if x = y then write x !
p y. By
Cp(x) is denoted indication of the local clock of process p at the moment of
occurrence of x in p. Therefore if x !
p y then
Cp(x)  Cp(y). If !
message where x occurs in a process p and y in a process q, then
two cases are possible:
1. If Cp(x)  Cq(y) (local time of dispatch is later or equal to local time of
reception) then Cq(y) := Cp(x) + Dxy where Dxy > 0 denotes the (estimated)
period of time from dispatch to reception of the message (shift forth indication
of local clock in the process q, slower than p).
2. If Cp(x) < Cq(y) (local time of dispatch is earlier than local time of reception)
then no action: Cq(y) remains unchanged.
external Ɵme
n
o
m
p
p3
h
i
k
a
b
c
d
e
p2
p1
g
f
l
j
q
r
external Ɵme
external Ɵme
Fig. 4.2 Diagram of relationships between events in processes p1, p2, p3 as seen by external
observer
4.2
Logical Time: Precedence of Events, Time …
97

Table 4.3 Periods of lapse of time in processes p1 and p2 shown as black, represent
compensation of local times, when they get messages from a process with faster clock
p1
1
external Ɵme
p2
p3
p1
p2
p3
external Ɵme
2
p1
p2
p3
external Ɵme
4
p1
p2
p3
external Ɵme
5
p1
p2
p3
external Ɵme
6
p1
p2
p3
external Ɵme
7
p1
p2
p3
external Ɵme
8
p1
p2
p3
external Ɵme
3
98
4
Time, Coordination, Mutual Exclusion Without …

The shift of the clock indication in process q in the case 1, is a time compen-
sation in this process.
The logical clock C: E(S) ! R is deﬁned as follows:
• C(x) = Cp(x) if x is a dispatch of a message in the process p or is not a com-
munication event;
• C(y) = Cq(y) if y is a reception of a message in the process q and Cq(y) is
computed in the case 1.
The value C(x) is referred to as a (compensated) timestamp of event x.
Activity of processes p1, p2, p3 before time compensations is depicted in
Fig. 4.3. Local times of events are projected onto the bottom axis (note that this is
not the ordinary geometric image of time). After time compensations, this diagram
transforms into the one depicted in Fig. 4.2.
The main fact concerning connection of the precedence relation  with the
order of the function C values (i.e. compensated time measured by the logical
clock) deﬁned above, is the implication x y ) C x
ð Þ  C y
ð Þ for all events
x; y 2 E S
ð Þ. An inductive proof may be formalized as follows. Write
, if
x directly precedes y in the same process or x = y. Let x1, x2, x3,… be a ﬁnite or
inﬁnite sequence of events such that
or xn !
message xn+1 for each n 
1. Suppose xi xi þ 1 ) CðxiÞ  Cðxi þ 1Þ for i less than a certain n > 1. If
then C(xn)  C(xn+1), because x !
p y ) Cp(x)  Cp(y) for any
process p and because C(x) = Cp(x) (by deﬁnition of function C), for all events x,
y. Thus xn xn þ 1 ) CðxnÞ  Cðxn þ 1Þ. If xn !
message xn+1 then consider two cases:
• If CpðxnÞ [ Cqðxn þ 1Þ then the compensation of time of (slower) receiver
process
q
takes
place:
Cqðxn þ 1Þ :¼ CpðxnÞ þ Dxnxn þ 1
for
a
certain
Dxnxn þ 1 [ 0, in effect of which CpðxnÞ \ Cqðxn þ 1Þ holds. Thus, after the time
compensing of the receiver q, implication xn xn þ 1 ) CpðxnÞ \ Cqðxn þ 1Þ
holds. Since CðxnÞ ¼ CpðxnÞ and Cðxn þ 1Þ ¼ Cqðxn þ 1Þ (by deﬁnition of
function C), we get the implication xn xn þ 1 ) CðxnÞ \ Cðxn þ 1Þ.
l
m
n
o
p
q
r
p3
g
h
i
j
k
a
b
c
d
e
p2
p1
Cp3(r)
Cp1(f)
Cp2(k)
Cp3(q)
Cp3(p)
Cp1(e)
Cp3(o)
Cp1(d)
Cp2(j)
Cp3(n)
Cp1(c)
Cp2(i)
Cp3(m)
Cp1(b)
Cp3(l)
Cp1(a)
Cp2(h)
Cp2(g)
local
local
local
f
Fig. 4.3 Diagram of events on axes of local times of their occurrence. On the bottom axis
projections of local clocks indications are recorded in the ordering of respective events position on
axes corresponding to local times of processes p1, p2, p3
4.2
Logical Time: Precedence of Events, Time …
99

• If CpðxnÞ \ Cqðxn þ 1Þ then the sender p is the slower process, so no time com-
pensation takes place and by deﬁnition of function C : CðxnÞ \ Cðxn þ 1Þ we
again get the implication xn xn þ 1 ) CðxnÞ \ Cðxn þ 1Þ.
Therefore in any case, the implication xn xn þ 1 ) CðxnÞ \ Cðxn þ 1Þ is ful-
ﬁlled, thus by virtue of the induction principle, the implication holds for all
n. Because the sequence (a chain) x1; x2; x3; . . . has been chosen arbitrarily, the
implication x y ) C x
ð Þ  C y
ð Þ holds for all events x; y 2 E S
ð Þ. This ends the
proof.
Now, we are ready to deﬁne a global timestamp of events, the main notion for
further considerations. Note that in general, reverse implication to x y )
C x
ð Þ  C y
ð Þ does not hold (some counterexamples are in Fig. 4.2, where
C b
ð Þ \C jð Þ but bjjjÞ. Moreover, though the logical clock C measures the com-
pensated time, it may happen that C(x) = C(y) and x 6¼ y for some concurrent x, y,
so the mapping C is not one-to-one function (e.g. in Fig. 4.2 C(c) = C(j) and c 6¼ j),
thus C does not establish unique representation of events by their timestamps.
However if the processes are linearly ordered, e.g. numbered, and the timestamp
C(x) is supplemented with a process number in which the event x occurs, then
events can be uniquely represented by the richer timestamps, called global. So,
let #(px) be a unique process number of process px, in which the event x occurs (a
given event may occur in exactly one process, thus it identiﬁes this process). A pair
〈C(x), #(px)〉is called a global timestamp of event x and let ≼denote a relation
between global timestamps deﬁned as 〈C(x), #(px)〉≼〈C(y), #(py)〉iff C(x) <
C(y) or if C(x) = C(y) then #(px)  #(py). Obviously ≼is a linear order, the
so-called
lexicographic
order
and
the
one-to-one
injective
mapping
C:
E(S) ! R  N (N—set of natural numbers) has been established by C(x) =
〈C(x), #(px)〉, because C(x) = C(y) ) x = y for all events x, y. Therefore, C
establishes a unique representation of events by their global timestamps. This
means that events, occurring as partially ordered, may be linearly ordered, using the
global timestamp construction. This linear order will be denoted by ⊑and deﬁned
as: x ⊑y if and only if C(x) ≼C(y).
As usually C x
ð Þ 	 C y
ð Þ means C(x) ≼C(y) and C(x) 6¼ C(y).
Evidently, the implication x y ) x Y y holds but not the reverse one (see
Fig. 4.2).
The representation of events by global timestamps and their linear order will be
applied in Sects. 4.3 and 4.4 for implementing distributed mutual exclusion without
an „external force” for cooperating computers, that is without a supervisory server.
Remark A widely known theorem states that any partial order relation on a
set can be extended to a linear, for some algebraic systems in general, whose
basic sets are inﬁnite, also non-enumerable (Kuratowski 1976; Marczewski
1996). The above construction utilizing global timestamps is a very special
and straightforward way of the needed extension.
100
4
Time, Coordination, Mutual Exclusion Without …

4.3
Distributed Mutual Exclusion Without External
Service for Processes—A Method Based on Global
Timestamps (Ricart 1981)
As in the former methods with supervisory server and token-ring, it is assumed that
there is one protective zone (extension to several of them is straightforward) and
during its execution no failure of the system occurs. Processes are cooperating by
broadcast of messages among themselves, taking advantage of global timestamps in
this cooperation. Figure 4.4 depicts structure of a system with four computers,
arbitrarily numbered, that compete for entrance to the protective zone. Similarly to
the methods presented in Sects. 3.4 and 3.5, the computers send „request”, „per-
mission” and „refuse” messages in the course of the competition, but between
themselves, not via any supervisory server.
These messages (of the form of system procedures) are interpreted as follows:
•
Process which requests the protecting zone broadcasts the „request” message
with its current global timestamp as parameter, stores it in its register „global
timestamp of process which has sent request” and waits for replies from
receivers. After having received all the replies, increases the content of its
register „number of granted permissions” by number of replies „permission”,
and if among them is the „refuse” message, passes to the waiting state. The
„refuse” message, the process receives from process executing protective zone
and from processes being in the waiting state, whose global timestamps are
smaller (according to the ≼order) than its own. If the content of register
„number of granted permissions” becomes by one smaller than the number of all
processes, the process enters the protective zone.
global Ɵmestamp
of process which 
has sent request 
number of granted permissions; 
if it equals 3, process enters
protecƟve zone  
protecƟve zone
network
queue of processes waiƟng
to enter protecƟve zone 
p1 
p2 
p3 
p4 
protecƟve zone
protecƟve zone
protecƟve zone
state of process: 
request for 
execuƟng
protecƟve zone
permission 
execuƟon of 
local secƟon
execuƟon of 
protecƟve zone
release of 
protecƟve zone
refusal
Fig. 4.4 Structure of a system without server managing usage of protective zone; computers are
running processes p1, p2, p3, p4 ﬁxedly numbered as #(p1) < #(p2) < #(p3) < #(p4)
4.3
Distributed Mutual Exclusion Without External …
101

•
Process which is not executing protective zone and is not in the waiting state ,
which received the „request” message, sends back to the sender the „permis-
sion” message.
•
Process which is in the waiting state and received the „request” message,
compares its global timestamp with a timestamp in the message received. If its
own timestamp is greater, then sends back the „permission” message, if
smaller, then sends back the „refuse” message and puts the received timestamp
into its queue of processes waiting to enter the protective zone.
•
Process which is executing the protective zone , which received the „request”
message, sends back the „refuse” message and puts the received timestamp into
its queue of processes waiting to enter the protective zone.
•
Process which leaves the protective zone , sends the „permission” message to
processes whose global timestamps are in its queue of processes waiting to enter
the protective zone and deletes content of this queue as well as content of the
registers „number of granted permissions” and „global timestamp of process
which has sent request”.
Table 4.4 presents an example of mutual exclusion in operation, accomplished
by exchange of messages between processors competing for a resource protected by
a protective zone, without service from a supervisory server. For brevity of nota-
tion, process’ numbers are identiﬁed with their names, e.g. „p1” will be written
instead of „#(p1)”. The processes are numbered as: #(p1) = 1, #(p2) = 2, #(p3) = 3,
#(p4) = 4.
Remark Remember that the time management must take into account the
time compensation during message passing—when message reception pre-
cedes its dispatch according to local clock indications of the sender and
receiver. We do not discuss problems of timestamp progress and a mecha-
nism of vector clocks [cf, for instance (Saxena 2003; Kuz et al. 2016)]. For
the purpose of the presentation here, it sufﬁces to assume that the value
Cp(x) of the current timestamp of the process p increases by a certain value
(e.g. a pulse duration of the clock) on every occurrence of an event x—with
regard time compensation, if needed.
4.4
Distributed Mutual Exclusion Without External
Service for Processes—A Method Based on Vectors
of Global Timestamps (Czaja 2012)
In this protocol, functionally somewhat similar to that presented in Sect. 4.3 but
differently designed, the global timestamps are also used. Each computer is
equipped with a vector of timestamps corresponding to computers of the system.
102
4
Time, Coordination, Mutual Exclusion Without …

Table 4.4 Exemplary run of a system with four computers striving to enter protective zone
protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
request (14,p3)
request (14,p3)
request (14,p3)
14,p3
1
protecƟve zone
protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
protecƟve zone
14,p3
permission
permission
permission
3
2
protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
14,p3
protecƟve zone
3
request (17,p1)
request (17,p1)
request (17,p1)
17,p1
3
protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
14,p3
protecƟve zone
3
17,p1
17,p1
permission
permission
refusal
2
4
(continued)
4.4
Distributed Mutual Exclusion Without External …
103

protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
14,p3
protecƟve zone
3
17,p1
17,p1
request (18,p4)
request (18,p4)
request (18,p4)
2
18,p4
5
protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
14,p3
protecƟve zone
3
17,p1
17,p1
2
18,p4
p1 refuses because (17,p1)
(18,p4)
refusal
permission
18,p4
18,p4
1
6
protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
14,p3
protecƟve zone
3
17,p1
17,p1
2
18,p4
18,p4
request (25,p2)
request (25,p2)
request (25,p2)
25,p2
18,p4
1
7
protecƟve zone
n e t w o r k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
14,p3
protecƟve zone
3
17,p1
17,p1
2
18,p4
18,p4
25,p2
18,p4
1
p1 refuses because
(17,p1)
(25,p2)
p4 refuses because (18,p4)
(25,p2)
refusal
25,p2
25,p2
25,p2
8
<
<
<
Table 4.4 (continued)
(continued)
104
4
Time, Coordination, Mutual Exclusion Without …

n e  t  w  o  r  k
p2
p4
protecƟve zone
protecƟve zone
18,p4
25,p2
3
25,p2
2
protecƟve zone
protecƟve zone
request (30,p1)
request (30,p3)
request (30,p1)
request (30,p1)
request (30,p3)
request (30,p3)
p1
30,p1
30,p3
p3
12
n e  t  w  o  r  k
p2
p3
p4
protecƟve zone
protecƟve zone
18,p4
25,p2
3
25,p2
2
protecƟve zone
permission
permission
protecƟve zone
p1
11
protecƟve zone
n e  t  w  o  r  k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
17,p1
3
18,p4
25,p2
18,p4
2
25,p2
25,p2
1
protecƟve zone
10
protecƟve zone
n e  t  w  o  r  k
p1
p2
p3
p4
protecƟve zone
protecƟve zone
protecƟve zone
17,p1
3
18,p4
25,p2
18,p4
2
25,p2
25,p2
permission
permission
permission
1
9
Table 4.4 (continued)
(continued)
4.4
Distributed Mutual Exclusion Without External …
105

n e  t  w  o  r  k
p2
p3
p4
protecƟve zone
protecƟve zone
18,p4
25,p2
3
25,p2
2
protecƟve zone
protecƟve zone
refusal
p1 refuses because (30,p1) 
(30, p3)
refusal
p3 permits because (30,p1) 
(30, p3)
p2 refuses because
(25,p2) 
(30,p1)
p2 refuses because
(25,p2) 
(30,p3)
p1
30,p3
1
30,p1
30,p3
30,p1 30,p3
30,p1 30,p3
13
n e  t  w  o  r  k
p2
p3
p4
protecƟve zone
25,p2
3
protecƟve zone
protecƟve zone
p1
30,p3
2
30,p1
30,p3
30,p1 30,p3
permission
permission
permission
1
protecƟve zone
14
n e  t  w  o  r  k
p2
p3
protecƟve zone
25,p2
3
protecƟve zone
protecƟve zone
p1
30,p3
2
30,p1
30,p3
30,p1 30,p3
1
p4
protecƟve zone
15
n e  t  w  o  r  k
p3
protecƟve zone
protecƟve zone
p1
30,p3
3
30,p1
30,p3
2
p4
protecƟve zone
p2
protecƟve zone
permission
permission
16
<
<
<
<
Table 4.4 (continued)
(continued)
106
4
Time, Coordination, Mutual Exclusion Without …

n e  t  w  o  r  k
p3
protecƟve zone
30,p3
2
p4
protecƟve zone
p2
protecƟve zone
protecƟve zone
p1
30,p1
3
30,p3
17
n e  t  w  o  r  k
p3
protecƟve zone
30,p3
3
p4
protecƟve zone
18
p2
protecƟve zone
protecƟve zone
p1
permission
n e  t  w  o  r  k
p4
protecƟve zone
p2
protecƟve zone
protecƟve zone
p1
p3
30,p3
protecƟve zone
3
19
n e  t  w  o  r  k
p4
protecƟve zone
p2
protecƟve zone
protecƟve zone
p1
20
p3
protecƟve zone
n e  t  w  o  r  k
p4
protecƟve zone
p2
protecƟve zone
protecƟve zone
p1
21
p3
protecƟve zone
Table 4.4 (continued)
4.4
Distributed Mutual Exclusion Without External …
107

Processes are updating the vectors in the course of system activity and make
decision on the basis of their content, whether to enter into protective zone or wait.
Also usage of the artiﬁcial value ∞, greater than any possible timestamp, makes
this protocol different than that in Sect. 4.3.
The following assumptions are admitted:
1. sequential computers work in parallel asynchronously and are numbered 1,2,…,
n;
2. writing and reading to/from memory is governed by the memory manager of
each computer;
3. each request to the protocol for the protective zone, delivers a current global
timestamp to the requesting process;
4. computer of number i keeps vector ri
! = [ri1, ri2,…, rin] of variables rik allocated
in its physical memory; it stores its current timestamp in the component rii when
requesting for the protective zone, then fetches values of components rkk
(k 6¼ i) from remaining computers and stores them in variables rik of its vector
ri
!. Figure 4.5 depicts location of vectors of timestamps in the local memories;
5. initially all variables rij contain ∞where ∞> x for any number x;
6. by min( ri
!) is denoted the least value of the components in the vector ri
!;
Computer of number i = 1, 2,…, n, using the protocol depicted as a transition
graph in Fig. 4.6 for exclusive access to a protected resource, passes through the
following states:
r11 r12 ….
r1n
computer 1
…….
system soŌware and
applicaƟon programs
r21 r22 ….
r2n
computer 2
rn1 rn2 ….
rnn
computer n
network
subsystem managing
memory access and
data transmission
subsystem managing
memory access and
data transmission
subsystem managing
memory access and
data transmission
system soŌware and
applicaƟon programs
system soŌware and
applicaƟon programs
Fig. 4.5 Structure of distributed system of n computers with vectors ri
! i ¼ 1; 2; . . .; n
ð
Þ of
timestamps allocated in local memories
108
4
Time, Coordination, Mutual Exclusion Without …

Denotations:
• Let Qi ! Q0
i mean: computer of number i passes from a state Qi 2 Xi to the next
state Q0
i 2 Xi in the transition graph in Fig. 4.6. Note that transitions Bi ! Ri
and Yi ! Ri are possible if and only if rii = min( ri
!), thus due to steady growth
of global timestamp as a strictly increasing function of time, at most one
computer may perform protective zone at a time. A formal proof is given
further.
• Set
of
global
states
X ¼ X1X2      Xn
satisfying:
if
~Q ¼
½Q1; Q2; . . .; Qn
 2 X then :9i; k : ði 6¼ k ^ Qi ¼ Ri ^ Qk ¼ RkÞ.
• Initial state: Qinit
! ¼ ½W1; W2; . . . ; Wn
 with rij ¼ 1 for every computer
i; j ¼ 1; 2; . . .; n.
• For
~Q ¼ ½Q1; Q2; . . .; Qn
 2 X
and
Q0
! ¼ ½Q0
1; Q0
2; . . .; Q0
n
 2 X let ~QQ0
!
mean: there exists a computer of number i such that Qi ! Q0
i Q0
! is the next
global state following ~Q.
It follows from the transition graph in Fig. 4.6 that for any computer of
number i:
request for 
protective zone
Bi: rii := global timestamp; 
fetch values of all rkk from  all
computers k ≠i and store them in rik ;
test rii > min(
)      
Yi: wait until rii = min(
); 
Ri: perform protective
zone
Gi: rii := ;
send to all rki
Wi: perform
local section
return to 
local section
exit from
prot. zone
no computer is in
protective zone
rii > min(
)
(certain computer
is in protective zone)
rii =  min(
)  (no computer is in protective zone)
 Wi – execution of local section 
     Bi – import of current timestamps stored in variables rkk of remaining computers;  
              execution of  n -1  assignments  rik := rkk  (k ≠i);  test of condition  rii > min(
)   
     Yi – refusal to perform protective zone (waiting state) 
     Ri – execution of protective zone 
     Gi – release of protective zone 
The set of states of the ith computer:  
i = {Wi , Bi , Yi , Ri , Gi}:  
Fig. 4.6 The distributed mutual exclusion protocol performed by computer of number i in the
cycle from request for protective zone till its release
4.4
Distributed Mutual Exclusion Without External …
109

1. Storing a timestamp in register rii proceeds only at the state Bi of computer of
number i; rii retains this value until the transition Ri ! Gi takes place.
2. Storing ∞in register rii and sending to rki of remaining computers proceeds
only at the state Gi. Thus, from point 1 follows that rii decreases its value only at
the state Bi.
3. Global
states
are
exactly
those
reachable
from
the
initial
state
Qinit
! ¼ ½W1; W2; . . .; Wn
.
4. Because computation of minð ri
!Þ at the state Bi of computer of number i takes
place on completion of fetching values of rkk from remaining computers, the
order of entering computers into the protective zone does not depend of the
transmission latency. This is the FCFS order (First Come, First Served) due to
the steady growth of the global timestamps.
Table 4.5 presents an exemplary run of a four computer system using the pro-
tocol depicted in Fig. 4.6. This is the succession of global states:
½W1; W2; W3; W4
½B1; W2; B3; W4
½Y1; W2; R3; W4
½Y1; W2; R3; B4
½Y1; B2; R3; Y4

½Y1; Y2; G3; Y4
½R1; Y2; W3; Y4
½G1; Y2; W3; Y4
½W1; Y2; W3; R4
½W1; Y2; W3; G4

½W1; R2; W3; W4
½W1; G2; W3; W4
Global timestamps, i.e. pairs of numbers, are coded by single numbers—for
brevity. That is why the order  (and <) instead of ≼will be used when comparing
global timestamps.
Correctness of the protocol in Fig. 4.6, which is to assure mutually exclusive
execution of protective zone in distributed systems, enjoys almost straightforward
formal veriﬁcation:
Theorem 4.4.1 At none of global state, two distinct computers using the protocol
in Fig. 4.6 can perform the same protective zone.
Proof Suppose on the contrary, that in a global state ~Q ¼ ½Q1; Q2; . . .; Qn
 2 X
computers of number i and k perform protective zone. Then rii ¼ minð ri
!Þ and
rkk ¼ minðrk
!Þ in the local states Qi and Qk of the computers. By deﬁnition of the
global timestamps: rii 6¼ rkk because events of request for protective zone are dis-
tinct, so, their global timestamps (i.e. values of rii and rkk) are also distinct—due to
the one-to-one function C (Sect. 4.2). But because of actions at the states Bi, Bk of
the protocol in Fig. 4.6, equations rik = rkk and rki = rii hold. Since rii and rkk are
minimal in vectors ri
! and rk
! respectively, so, rii ≼rik and rkk ≼rki, therefore
rii ≼rkk and rkk ≼rii which implies rii = rkk (by antisymmetry of ≼—by deﬁnition
of the order ≼between global timestamps—Sect. 4.2)—a contradiction!
□
Another important property of this protocol is stated in Theorem 4.4.2, whose
proof needs the following:
110
4
Time, Coordination, Mutual Exclusion Without …

Lemma In all computers whose timestamps vectors, at a certain global state ~Q,
contain at least one component less than ∞, the minimal components of such
vectors are equal.
Proof Let minð ri
!Þ\ 1 in a computer of number i. Then at the global state ~Q,
exactly one computer, say of number k, either is performing protective zone or is
ready to do this, therefore rkk ¼ minðrk
!Þ. According to the protocol in Fig. 4.6
rik = rkk and rik is the least component of vector
ri
! at the state ~Q, thus
minð ri
!Þ ¼ minðrk
!Þ.
□
The next theorem states the fair order (i.e. FCFS) of entering the protective zone.
Theorem 4.4.2 Computers are entering the critical section in the order of their
requests. This order is independent of the data transmission latency.
Proof Let ~Q ¼ ½Q1; . . .; Qi; . . .; Qj; . . .; Qn
 2 X be a global state with local states
Qi, Qj each of them either Bi, Bj or Yi, Yj thus rii < ∞, rjj < ∞. It is to be proved that
if computer of number i had reached its local state Qi before the computer of
number j has reached its local state Qj, i.e. if rii < rjj, then state Ri will be reached by
computer i before computer j reaches state Rj. By above Lemma, minðri
!Þ ¼
minð rj
!Þ at the state ~Q, and according to the protocol in Fig. 4.6, variables rii, rjj are
not changing their values until computers of number i and of number j have not
reached their local states Gi, Gj. Thus, if eventually, a global state Q0
! ¼
½Q0
1; . . .; Q0
i ¼ R0
i; . . .; Q0
j; . . .; Q0
n
 (nearest to ~Q) has been reached from ~Q then
rii = min( ri
!) at Q0
!. But if a global state Q00
! ¼ ½Q00
1; . . .; Q00
i ; . . .; Q00
j ¼ Rj; . . .; Q0
n
had been reached from ~Q before the state Q0
!, then rjj ¼ minðrj
!Þ at Q00
! would hold.
Thus, minð riÞ
!  rii\rjj ¼ minð rj
!Þ at the state Q00, because values of rii and of
rjj at this state are the same as at ~Q and minð ri
!Þ ¼ minð rj
!Þ—a contradiction! Now,
note that, in accordance with the protocol in Fig. 4.6, the value of minðri
!Þ is
established only when values of rkk have been completely transmitted from all
computers k 6¼ i to computer i and stored in rik. This value does not depend on
duration of these transmissions nor on their order. Therefore the order of entering
computers into the protective zone is independent of transmission latency but
depends only on the order of their requests.
□
Figure 4.7a, b illustrate independence of value minðri
!Þ from ordering and
duration of values transmission, when the system’s evolution, shown in Table 4.5,
has reached state 2: [B1,W2, B3,W4]. The symbol i"(rkk)k means: “computer of
number k sends value of rkk up to computer of number i” and the symbol k#(rik)i
means: “computer of number i receives a value sent by computer of number k and
stores it in rik. The transmitted values are annotations on respective arrows.
4.4
Distributed Mutual Exclusion Without External …
111

More remarks on the protocol in Fig. 4.6:
1. Consumption of time. At the state Bi, computer of number i when requesting
for protective zone, sends message „send me value of your rkk” to all n −1
remaining k 6¼ i computers, and waits for delivery. In the worst case the mes-
sage reaches all destinations one after one as well as responses arrive one after
one, which takes 2(n −1) transmissions. Next, at the state Gi, on release of
protectibe zone, the computer broadcasts ∞to all rki of all n −1 remaining
computers, which takes, in the worst case, n −1 transmissions.
2. Failure. If a faulty computer of number k permanently delivers incorrect
timestamp in rkk to remaining computers that fetch it at the state Bk of the
protocol, then their behaviour depends on this value. If, for instance, rkk is small
enough to make min( ri
!) smaller than rii, then computer of number i enters the
waiting state Yi and will remain there forever: a starvation! But if computer of
number k delivers to computer of number i value of rkk satisfying equality
rii = min( ri
!), and after a while it delivers to computer of number j value of rkk
satisfying equality rjj = min( rj
!), then computer of number j may enter the
protective zone before computer of number i leaves it: violation of mutual
exclusion! To solve this problem, the protocol in Fig. 4.6 would require suitable
supplementation. The failure issues is the subject of Chap. 7.
computer 1: 
3↑(r11)1 
1↑(r22)2 
external time 
state W2
1↑(r33)3 
2↓(r12)1
1↑(r44)4 
1↓(r31)3
10 
3↑(r22)2 
∞ 
∞ 
3↓(r13)1 
4↓(r14)1     
2↓(r32)3 
4↓(r34)3 
3↑(r44)4 
state B1: r11:=15; 
fetch r22, r33, r44        
state B3: r33:=10; 
fetch r11, r22, r44       
15 
∞ 
∞ 
computer 2: 
computer 3: 
computer 4: state W3
computer 1: 
3↑(r11)1 
1↑(r22)2 
external time 
1↑(r33)3 
2↓(r12)1
1↑(r44)4 
1↓(r31)3
10
3↑(r22)2 
∞
∞
3↓(r13)1
4↓(r14)1    
2↓(r32)3
4↓(r34)3
3↑(r44)4
15
∞
∞
computer 2: 
computer 3: 
computer 4: 
state B1: r11:=15; 
fetch r22, r33, r44
state W2
state B3: r33:=10; 
fetch r11, r22, r44
state W3
(a)
(b)
Fig. 4.7 a Diagram of global state [B1,W2, B3,W4] and message transmissions between
computers. b Diagram of the same global state and min( ri
!) as in a but different ordering and
duration of values transmissions
112
4
Time, Coordination, Mutual Exclusion Without …

Table 4.5 Exemplary run of a system with four computers using protocol depicted in Fig. 4.2.
Background of the computers corresponds to their local states as pictured in the protocol
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory
manager
state 1
[W1,W2,W3,W4]
………
lock 
………
………
unlock
……… 
protecƟve
zone
………
lock
………
………
signal
……… 
………
lock
………
………
unlock
……… 
………
lock
………
………
unlock
……… 
n e  t  w  o  r  k
memory
manager
memory
manager
memory
manager
computer 1 
computer 2
computer 3
computer 4
protecƟve
zone
protecƟve
zone
protecƟve
zone
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory
manager
[B1,W2,B3,W4]
n e  t  w  o  r  k
memory
manager
memory
manager
memory
manager
10
10
15
15
computer 1 
computer 2
computer 3
computer 4
state 2
………
lock 
………
………
unlock
……… 
protecƟve
zone
………
lock
………
………
signal
……… 
………
lock
………
………
unlock
……… 
………
lock
………
………
unlock
……… 
protecƟve
zone
protecƟve
zone
protecƟve
zone
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory
manager
………
lock
………
………
unlock
……… 
n e  t  w  o  r  k
memory
manager
memory
manager
memory
manager
10
10
15
15
computer 1 
computer 2
computer 3
computer 4
state 3
protecƟve
zone
[Y1,W2,R3,W4]
………
lock 
………
………
unlock
……… 
protecƟve
zone
………
lock
………
………
unlock
……… 
………
lock
………
………
unlock
……… 
protecƟve
zone
protecƟve
zone
computer 1 
computer 2
computer 3
computer 4
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory
manager
………
lock
………
………
unlock
……… 
n e  t  w  o  r  k
memory
manager
memory
manager
memory
manager
10
10
10
15
15
15
20
20
state 4
[Y1,W2,R3,B4]
protecƟve
zone
………
lock 
………
………
unlock
……… 
protecƟve
zone
………
lock
………
………
unlock
……… 
………
lock
………
………
unlock
……… 
protecƟve
zone
protecƟve
zone
(continued)
4.4
Distributed Mutual Exclusion Without External …
113

computer 1 
computer 2 
computer 3 
computer 4 
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
 r31 r32 r33 r34
memory
manager 
…… 
lock
……… 
……… 
unlock
………  
n e  t  w  o  r  k
memory
manager 
memory 
manager
memory
manager 
10
10
10
15
15
15
15
10
20
20
25
20
state 5 
[Y1,B2,R3,Y4]
protecƟve
zone
……… 
lock 
……… 
……… 
unlock
………  
protecƟve
zone
……… 
lock
……… 
……… 
unlock
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
computer 1 
computer 2 
computer 3 
computer 4 
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
 r31 r32 r33 r34
memory
manager 
……… 
lock
……… 
……… 
unlock
………  
n e  t  w  o  r  k
memory
manager 
memory 
manager
memory
manager 
15
15
15
20
20
25
state 6 
[Y1,Y2,G3,Y4]
protecƟve
zone
……… 
lock 
……… 
……… 
unlock
………  
protecƟve
zone
……… 
lock
……… 
……… 
unlock
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
computer 1 
computer 2 
computer 3 
computer 4 
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory 
manager
……… 
lock
……… 
……… 
unlock
………  
n e  t  w  o  r  k
memory
manager 
memory
manager 
memory
manager 
15
15
15
20
20
25
state 7 
[R1,Y2,W3,Y4]
protecƟve
zone
……… 
lock
……… 
……… 
signal
………  
……… 
lock
……… 
……… 
unlock
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
protecƟve
zone
computer 1 
computer 2 
computer 3 
computer 4 
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory 
manager
n e  t  w  o  r  k
memory
manager 
memory
manager 
memory
manager 
20
20
25
state 8 
[G1,Y2,W3,Y4]
protecƟve
zone
……… 
lock
……… 
……… 
signal
………  
……… 
lock
……… 
……… 
unlock
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
protecƟve
zone
……… 
lock
……… 
……… 
unlock
………  
Table 4.5 (continued)
(continued)
114
4
Time, Coordination, Mutual Exclusion Without …

computer 1 
computer 2 
computer 3 
computer 4 
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory
manager 
……… 
lock
……… 
……… 
unlock
………  
n e  t  w  o  r  k
memory
manager 
memory
manager 
memory 
manager
20
20
25
state 9 
[W1,Y2,W3,R4]
protecƟve
zone
……… 
lock 
……… 
……… 
unlock
………  
protecƟve
zone
……… 
lock
……… 
……… 
signal
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
computer 1 
computer 2 
computer 3 
computer 4 
r11 r12 r13 r14
r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory
manager 
n e  t  w  o  r  k
memory
manager 
memory
manager 
memory 
manager
25
state 10
[W1,Y2,W3,G4]
protecƟve
zone
……… 
lock 
……… 
……… 
unlock
………  
protecƟve
zone
……… 
lock
……… 
……… 
signal
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
……… 
lock
……… 
……… 
unlock
………  
computer 1 
computer 2 
computer 3 
computer 4 
r11 r12 r13 r14
 r21 r22 r23 r24
r41 r42 r43 r44
r31 r32 r33 r34
memory
manager 
……… 
lock
……… 
……… 
unlock
………  
n e  t  w  o  r  k
memory 
manager
memory
manager 
memory
manager 
25
state 11
[W1,R2,W3,W4]
protecƟve
zone
……… 
lock 
……… 
……… 
unlock
………  
protecƟve
zone
……… 
lock
……… 
……… 
signal
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
computer 1 
computer 2 
computer 3 
r11 r12 r13 r14
 r21 r22 r23 r24
r31 r32 r33 r34
memory
manager 
……… 
lock
……… 
……… 
unlock
……… 
n e  t  w  o  r  k
memory 
manager
memory
manager 
memory
manager 
computer 4 
r41 r42 r43 r44
state 12
[W1,G2,W3,W4]
protecƟve
zone
……… 
lock 
……… 
……… 
unlock
………  
protecƟve
zone
……… 
lock
……… 
……… 
signal
………  
……… 
lock
……… 
……… 
unlock
………  
protecƟve
zone
protecƟve
zone
Table 4.5 (continued)
4.4
Distributed Mutual Exclusion Without External …
115

3. Elimination of busy waiting. To make computers perform some computation
instead of useless permanent checking rkk = min(rk
!) at the states Yk, a computer
which exits protective zone (i.e. at the state Gk) might fetch values of rkk from
remaining computers and send a permission to execute protective zone, for such
computer, whose vector contains the minimal value from among the fetched
ones. This would, however, increase number of transmissions.
4. Representation by Petri nets (for those familiar with this theory). The
control ﬂow in the protocol depicted in Fig. 4.6, applied by a system of four
computers, may be modelled by ordinary Place/Transition Petri net (P/T) (Petri
1966; Reisig 1985) (even by Condition/Event Petri nets), like that in Fig. 4.8. In
this case, however, one should notice that temporal aspects, i.e. the essential role
of global timestamps, cannot be expressed in the P/T nets formalism. That is
why the control (the token) from the state Bi (i = 1, 2, 3, 4) may pass either to
the state Ri or Yi, provided that the shared synchronizer S holds a token, i.e. none
computer is performing the protective zone (is not at its state Rk). Moreover, the
existence of the shared synchronizer S (playing role of a semaphore) negates the
idea of „distributed mutual exclusion without external service for processes”. In
order to realize this idea when modeling by Petri nets, they should be equipped
with inhibitor arcs
(Peterson 1981; Christensen 1993) leading from places
Ri (execution of protective zone) to transitions, from which the ordinary arcs
, go out and lead to places representing protective zone. Such extended
Petri net is depicted in Fig. 4.9. Notice that in this ﬁgure, some junction points
on inhibitor arcs going out from the same place Ri to two distinct transitions,
have been used, so that to avoid excessive entanglement of such arcs (repre-
senting communication lines). Also, the net places are here understood as units
where some actions are being performed, whereas the transitions—as passing
control from actions to successive actions in the protocol. The readers familiar
B1
Y1
W1
G1
R1
B3
Y3
W3
R3
B2
Y2
W2
R2
B4
Y4
W4
R4
G2
G3
G4
S
Fig. 4.8 P/T Petri net representing four computers competing for a protective zone Ri; the
computers are synchronized by means of external service—a shared synchronizer S
116
4
Time, Coordination, Mutual Exclusion Without …

with Petri net theory know that expressive power of P/T nets with inhibitors
(with more than one such arc) is essentially higher than without them: it reaches
the Turing power, which is not the case with „pure” P/T nets.
References
Christensen, S., & Hansen N. D. (1993). Coloured Petri nets extended with place capacities, test
arcs and inhibitor arcs. In Application and theory of Petri Nets, Lecture Notes in Computer
Science book series (LNCS, vol 691).
Cristian, F. (1989). Probabilistic clock synchronization. Distributed Computing, Springer-Verlag,
3, 146–158.
Czaja,
L.
(2012).
Exclusive
Access
to
Resources
in
Distributed
Shared
Memory
ArchitectureVolume. Fundamenta Informaticae, 119(3–4), 265–280.
Gusella, R., & Zatti, S. (1989). The Accuracy of the Clock Synchronization Achieved by TEMPO
in Berkeley UNIX 4.3BSD. IEEE Transactions on Software Engineering, 15(7), 847–853.
Kuratowski, K., & Mostowski, A. (1976). Set Theory, with an Introduction to Descriptive Set
Theory (2nd ed., Studies in Logic and the Foundations of Mathematics—Vol 86) Hardcover—
26 Feb 1976.
Kuz, I., Manuel M. T., Chakravarty & Gernot Heiser. (2016). A course on distributed systems
COMP9243, 2016.
Lamport, L. (1978). Time, clocks and the ordering of events in a distributed system.
Communications of the ACM, 21(7), 558–565.
Marczewski (Spilrajn) K. (1930). Sur l’extension de l’ordre partiel, FM (Vol. 16, pp. 386–389). in
Edward Marczewski, Collected Mathematical Papers, IM PAN 1996.
Mills, D. L. (1991). Internet time synchronization: The network time protocol. IEEE Transactions
on Communications, 39(10), 1482–1493.
B1
Y1
W1
G1
R1
B3
Y3
W3
R3
B2
Y2
W2
R2
B4
Y4
W4
R4
G2
G3
G4
Fig. 4.9 Similar Petri net but without external service—for the price of introducing inhibitor arcs
4.4
Distributed Mutual Exclusion Without External …
117

Network Time Protocol (version 2), speciﬁcation and implementation. (1989). DARPA Network
Working Group Report RFC-119, University of Delaware, Sep 1989.
Peterson, J. L. (1981). Petri Net Theory and the Modeling of Systems, Prentice Hall, Inc.
Petri, C. A. (1996). Communication with automata, Report RADC TR-65-377, Applied Data
Research (Vol. 1, Suppl. 1), Contract AF 30 Princeton N.J.
Reisig, W. (1985). Petri Nets. An Introduction, Monographs on Theoretical Computer Science,
Springer-Verlag.
Ricart, G., & Agrawala, A. K. (1981). An optimal algorithm for mutual exclusion in computer
networks. Communications of the ACM, 24(1), 9–17.
Saxena, P. C., & Rai, J. (2003). A survey of permission-based distributed mutual exclusion
algorithms. Computer Standards & Interfaces, 25(2), 159–181. May 2003.
118
4
Time, Coordination, Mutual Exclusion Without …

Chapter 5
Interprocess Communication
5.1
Basic Problems of Communication
So far, some problems speciﬁc for distributed systems have been presented, such as
correctness of transactions, of banking in particular, resource sharing and protec-
tion, pathological phenomena (deadlock, starvation), synchronization of clocks and
processes and, in general, the issues of time and coordination. In such problems an
essential role plays interprocess communication, performed by computers con-
nected in a network, which ensures hardware infrastructure for distributed system. It
had been assumed that the communication mechanisms are already delivered by
hardware and software, so, there were no need to get into their implementation
details, which might hinder explaining the essence of the communication problems.
The
processes
were
just
capable
of
sending
and
receiving
messages.
Communication problems belong to science and engineering area wider than dis-
tributed systems characterized as in Chap. 2: to the telecommunication and com-
puter networks—the areas using techniques elaborated there. Now, selected
problems of communication in networks, essential for computer distributed sys-
tems, are presented on a certain generality level, in order to emphasise principles
independent of technical solutions in existing implemented systems. For instance,
neglected is number of bits for particular fragments of transmitted packets, the
methods of naming resources and communication participants, mapping the names
onto addresses or routing of messages. So, it is assumed that processes, ports,
sockets, channels, are named and addressed. Also, we do not enter into structure
details of particular communication protocols. A presentation of such problems is
easily available in writings on computer networks, e.g. Comer (2015), Dolińska
(2005), Sportack (2004), [Tanenbaum and Wetherall 2011] and more others. Thus,
we conﬁne ourselves to presentation on several examples, the role and names of
some protocols and their functions, collected in the so-called layer models of
arranging message transmission. Such models have been adopted as international
standards, independent of their concrete implementation.
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_5
119

Communication between a pair of processes encompasses:
• transmission of data from the environment of sending process, to the environ-
ment of receiving process through a common transmission channel; processes of
sender and receiver are often performed by computers of different hardware and
software architecture;
• mode of communication: synchronous or asynchronous (like the mechanisms
„!”, „?” and „S”, „R” in Chap. 1), connection oriented or connectionless,
peer-to-peer, multicast or broadcast;
• conversion of transmitted data from the format used by sender into format used
by receiver.
In contrast to the previous chapters, in this chapter the differences between
architecture of computers are not neglected. This requires transforming represen-
tation of messages dispatched onto representation which enables correct, i.e.
identical „understanding” (interpretation) by both sides: the sender and receiver,
differing often in hardware and software. This representation is, usually, a certain
standard commonly adopted in distributed systems and more general—in systems
based on networks. Successive stages of transforming of the sender’s representation
of data structures onto a standard („ﬂat”) representation for transmission through
communication channels and—farther—onto the receiver’s representation, are
realized by communication protocols. Actions of transformation and packing of
data to be dispatched, is called marshalling, whereas unpacking of data to be
received—unmarshalling.
„marshalling”—the term taken from railway terminology (similarly to the
semaphore), which means setting railway cars in a desired order in the
marshalling yard.
This is accomplished (depending of implementation) in kernels of operating
systems of communication participants, in runtime systems of programming lan-
guages equipped with communication mechanisms or in special protocols. Other
issues of interprocess communication presented in this chapter are various modes of
transmission, like synchronous, asynchronous, connected-oriented, connectionless,
as well as layer models of protocol sets, like OSI/RM and ATM standards and
broadcast and multicast communication (applied in the distributed mutual exclusion
presented in Chap. 4).
For a communication to appear it is necessary:
• to establish a connection between communicating processes;
• to ensure a buffering (queuing) of messages between the sender and receiver,
• to apply a certain communication protocol that ensures marshalling and un-
marshalling; to this end:
120
5
Interprocess Communication

– the sender converts a message from its language onto a language deﬁned by
rules of the protocol, and so translated sends to the receiver;
– the receiver converts the delivered message onto its language and, possibly,
returns a conﬁrmation;
• to perform transmission of message with marks of its begin and end, signals of
synchronization, information of encoding of numbers (the sender’s arithmetic)
and alphanumeric characters, of data structures necessary for their reproduction
on the receiver’s side;
• to signal the end of transmission and to release its route.
5.2
Tasks of Communication Protocols—Examples
A communication protocol is a set of rules of coding (by sender) and decoding (by
receiver) data traveling through communicating channels. In other words, this is a
formal description of a form (syntax) and meaning (semantics) of messages
transmitted in computer networks (in general—telecommunication networks) and
rules of their sending and reception. The rules determine a kind and mode of
communication, like synchronous or asynchronous, connection-oriented or con-
nectionless, with or without conﬁrmations, one-way or two-way. A particular
protocol is destined for realization of some functions in interprocess data trans-
mission. So, their suitable collection makes possible communication between
devices of various construction, e.g. computers of various architecture. Apart from
encoding and decoding messages and communication mode determination, to the
tasks of some protocols belong determination of routes of the message, the so-called
routing, as well as identiﬁcation of receiver’s process and its site (port, socket),
whence the message is to be fetched from and also assurance of transmission
correctness. A protocol is usually a component of a “protocol suite” realizing entire
activity of message passing. It passes the outcome of its activity to successive
protocol of the suite, for realizing next functions, etc. Such multilevel, layered
structure of the protocol suite, is presented—in action—further in this chapter. In
this section, several examples of “marshalling” function of protocols in commu-
nication between devices of different architectures is presented.
Example 1 In a computer A, an integer number is represented by a sequence of 40
bits (40 bit word) e0e1…e39 (ei 2 {0, 1}, i = 0, 1, 2, …, 39) interpreted (by the
arithmetic unit of the computer A) as the arithmetic value:
NA ¼ e0239 þ e1238 þ e2237 þ    þ e3821 þ e3920
In a computer B, an integer number is represented by a sequence of 17 bits (17
bit word) e0e1…e16 (ei 2 {0, 1}, i = 0, 1, 2, …, 16) interpreted (by the arithmetic
unit of the computer B) as the arithmetic value:
5.1
Basic Problems of Communication
121

NB ¼
e0216 þ e1215 þ    þ e1521 þ e1620
if e0 ¼ 0
 e0216 þ e1215 þ    þ e1521 þ e1620


if e0 ¼ 1

If the computer A has sent to B a sequence of bits representing number NA in the
A’s architecture, then the computer B, after reception of this sequence would
truncate some bits from NA and remaining 17 bits would interpret as a numeric
value NB—completely different than NA. To avoid this, computer A transforms the
sequence of bits representing NA onto a certain form „jointly understood” by A and
B and sends the transformed sequence to B together with information that the
sequence should be interpreted as an integer number. This „jointly understood”
intermediate form is determined by a communication protocol between A and B. In
computer A the so-called complementary arithmetic is applied, while in computer
B the so-called arithmetic of module-sign (computers of such arithmetic had been in
use indeed (Czaja 1971; Fiałkowski and Swianiewicz 1962). A little more com-
plicated is representation of real numbers and translation between them.
Example 2 In a computer C some data structures (tables, trees, stacks, queues, lists,
graphs, etc.) are represented in completely different way than in computer D. They
must be converted onto a form, properly interpreted („understood”) by both com-
puters. In the transmission channel, a data structure is transmitted in a „ﬂattened”
form, that is, as a sequence of bits, along with information what type of structure the
sequence represents. Transformation of the data onto a „ﬂat” form usually proceeds
in several stages: by successive „layers” of the communication system. All these
activities are ensured by suitable protocols.
Example 3 In computer E, a string of alphanumeric characters, e.g. a text of a
natural language, is stored in consecutive memory bytes and being encoded dif-
ferently than in computer F (and, possibly, in a distinct order). Correct reception of
this text sent from E to F requires transforming it onto a „jointly understood”
intermediate form, determined by a suitable communication protocol between E and
F.
Example 4 In a computer G, bits are represented by electric signals of completely
different voltage than in a computer H (for instance in G, bit 0 by a voltage lower
than bit 1, while in computer H—conversely). Moreover, the ﬁrst bit transmitted by
G is at the beginning of the message, whereas transmitted by H—at the end. Here,
again a certain „jointly understandable” form is needed for the correct message
reception.
Some analogies may turn out noticeable:
• The relationship between a protocol and communication in action, is similar to
the relationship between an algorithm and computation: this is a ﬁnite
description of activities;
122
5
Interprocess Communication

• The intermediate form of messages deﬁned by a communication protocol, plays
a similar role like:
– a standardized intermediate language common to various computers equip-
ped with interpreters of this language. Different compilers of a higher level
programming language, are transforming source programs onto the inter-
mediate form, independent of the individual computer architecture (diverse
processors, operating systems). This intermediate language is further inter-
preted by individual „virtual” machines. An example is the standardized
intermediate language for Java, interpreted by Java’s virtual machine, that
translates each statement of the intermediate language onto the machine code
of individual computers (equipped with the Java virtual machines), executes
it, translates the next statement, executes it, etc.
– written correspondence of Mr. Diego with Ms. Krystyna. Diego, the
Spaniard, writes a letter to Krystyna in Spanish. However he has a friend
Gulmaro, whose native language is Spanish, but with a good command of
English. Krystyna, the Pole, writes to Diego in Polish, however she has a
Polish friend Joanna with an excellent command of English.
A message transmission may be accomplished without transformation to an
intermediate form, by means of protocols using by dispatch module. The
message may be transmitted directly, as a sequence of characters written by
the sender in a programming language. In this case, an exact information on
the transmitted data structure must be attached. Such information—a
sequence of control characters—are used by protocols of the receiver’s
module, for transforming the received sequence onto a sequence representing
the data structure in the receiver’s language. For instance, in Fig. 5.1, the
intermediate English disappears if Joanna knows Spanish language, in which
messages travel through the channel. The “marshalling” and „unmarshalling”
is performed by one protocol only—Joanna. Such solution is an implemen-
tation detail.
Diego writes 
a leƩer
Krystyna 
writes a leƩer
Gulmaro
translates 
Joanna 
translates 
Spanish
English
Polish
Polish
Spanish
channel
Diego: 
Krystyna:
Fig. 5.1 Gulmaro and Joanna play a part of programs—communication protocols; a common
intermediate language is English
5.2
Tasks of Communication Protocols—Examples
123

5.3
Dispatch and Reception
There are various notational forms to initiate and carry out communication, in
languages that offer mechanisms for concurrent and distributed programming. Their
syntax and semantics concern not only message transmission itself, but a number of
some accompanying properties. It conforms to general concept and structure of a
language supporting a certain programming paradigm: imperative, object, func-
tional, in logic, event-directed, etc. The detail presentation of such mechanisms
exceeds the subject of this chapter and may be found in the respective writings as
e.g. Hoare (1985), Milner (1980), Ben-Ari (1990), OCCAM (1984), Szałas and
Warpechowska (1991), Brinch Hansen (1975), Arnold et al. (2005), Stevens
(1997), [Tanenbaum and Wetherall 2011]. The main task of the mechanisms is to
deliver a message to a certain site of reception. This takes place in effect of exe-
cuting an operation, differently named in various programming languages and
operation systems. Let us name them send and receive. In distributed systems, such
operations play a similar part like input/output operations in a stand-alone, auton-
omous computer with external devices, where suitable protocols are also applied
and message delivery sites (ports, sockets) speciﬁed. Some low-level (machine)
operations of communication: !, ?, S, R, were shown in Sects. 1.4 and 1.5 of
Chap. 1. Their parameters were name of receiver’s process in the sending process
and name of sender’s process in the receiving process, as well as respective
addresses where the message is being sent from, and delivered to. These low-level
operations represent maximally simpliﬁed synchronous and asynchronous mecha-
nism, neglecting identiﬁers of ports, sockets, channels and neglecting reaction to
exceptions like damage or loss of messages and delivery receipt, time-out, etc.
Some programming and operating systems, offer means for specifying properties of
message transmission or include means for such speciﬁcation in send/receive
operations as parameters. Here, we conﬁne ourselves to parameters specifying
messages, processes and threads, sites of dispatch and reception like ports or
sockets and to media of transmission like channels.
Messages
For the user, data transmitted between computers or processes, are collected into
structures being abstract concepts—models of real objects. For instance, a model of
city transport is a graph, a model of population census is a list (a text ﬁle, a
sequence of records), a model of family history on the male side is a tree, etc. The
essence of a data structure is a way of grouping of single (elementary) data, i.e.
rules determining their position in the structure and a way of accessing them.
Whereas in the computer memory, the data structure is stored in sequentially
addressed cells or bytes, that is—a linear object. There exist some standards of
linear representation of data structures, not being dealt with here. To a data
structure, linearly stored, a name and type is assigned (see the frame below). This is
done in programs of communication participants, by means of declaration of a
variable used as the actual parameter of the send/receive operations. This parameter
124
5
Interprocess Communication

represents a message. But allocation of named objects, i.e. assigning addresses to
them, is managed by suitable modules of distributed operating system. For the user,
such proceeding is similar to commonly known in not distributed programming,
where it is hidden (transparent) and accomplished by a compiler, interpreter or
runtime system. Addressing of a data structure in distributed systems is, however,
much more complicated. This is due to its possible storage in memory of many
different computers, as well as its possible relocation and problems of memory
consistency when using its multiple copies. Such problems are left to Chap. 8.
Every data structure has a certain type. This is a feature determining a way of
grouping of single components and informing about permissible actions on
them. For instance, a matrix of numbers has a type of two-dimensional array
with equal length of rows, equal lengths of columns and direct access to its
entries, and permission of arithmetic operations on them, but not e.g. logical.
Therefore, the type determines a schema of placement of single data in the
compound structure, rules of access and informs of permissible operations on
them. In terms of the set theory, the type is a set of all data structures, of
identical manner of grouping and handling their components.
A basic method of message transmission in network is packet switching, in
contrast to circuit switching, applied in the past telephonic systems. A message,
before dispatch, is partitioned into parts called packets, along with information how
to reach its destination and is being sent serially through one route, or concurrently
—via various routes (Sect. 5.4 where connection-oriented and connectionless
transmission is presented). A transmission may proceed incorrectly or not to act at
all. For instance, the receiver may get a corrupted message, may not get it at all or
get it many times, the sender may not get acknowledgment required by the protocol,
etc. Notice that the receiver becomes the sender when send the acknowledgment or
provides a service requested by the sender. Prevention of message corruption may
be partly obtained by usage of the check sum, a technique well known in mono-
computer systems.
Processes and threads
In the parallel and distributed programming, processes and threads (the “light
processes”, with joint address space) are declared, as well as created dynamically—
during the program run. They have names assigned and perhaps attributes, i.e.
types. Remember that in a simpliﬁed version of a model-language CSP (Chap. 1),
as parameters of operation “!” (send) and “?” (receive) were names of processes and
of location of messages and the communication was synchronous. Similarly, in
some high level programming languages (like ADA, Linda, Concurrent Pascal,
OCCAM, Modula-2, Loglan, Java, Concurrent Prolog) and operating systems (like
UNIX, Amoeba, Mach, Chorus), names of processes (in the ADA, instead of the
term “process” the “task” is used) or threads, may be transmitted in messages, thus
5.3
Dispatch and Reception
125

may appear among parameters of send/receive operations. In particular, as a
parameter may appear an identiﬁer of a remote procedure or method—see Chap. 6.
The synchrony or asynchrony of communication may be a speciﬁc feature of a
programming language (e.g. in ADA and OCCAM—synchronous communication,
whereas in Linda—asynchronous), or may be a parameter of send/receive opera-
tion. In the programming languages with rich mechanisms of interprocess com-
munication, a class declaration may contain names of processes or threads as formal
parameters. The activity is dynamic: processes and messages may be created and
may disappear in the course of distributed program run. This is accomplished by
services from execution system of a programming language and distributed oper-
ating system. Some programming and operating systems admit multicast commu-
nication: a parameter of the send operation is then a name of a group of processes.
Ports
A process may have many dispatch/reception points for message passing between
computers and various devices. Such points or sites, are referred to as „ports”, by
analogy to junction points (interfaces) in computers, for connecting external
devices, like mouse, camera, keyboard, etc. Throughout a port (“entryway”),
messages are collected in a “mailbox”, i.e. a buffer. Likewise as processes, desti-
nation ports may be named and declared or created dynamically during activity of
distributed programs and transmitted in messages directed to these ports. So, in the
send operation, among parameters representing a message and receiving process,
identiﬁers of destination ports may appear. Such mechanism, for example, is offered
by the ADA programming language, where the sending process encounters
(“shakes hand”—the synchronous communication) with the receiving process in a
port determined by the programmer. In the theoretical, model-language CCS
(Milner 1980), the port is the primary (not deﬁned) notion, understood as a junction
point of communicating processes.
Sockets
This concept originates from extended versions of operating system UNIX, called
UNIX 4.x BSD. Transfer of a message takes place from the output socket to input
socket. The sockets are created by a process, for communication with another
process, and are deﬁning points in this process, whence messages are to be dis-
patched and the points in other processes where messages are to be received.
Creation of a socket by a process (by calling procedure socket), assigns a name and
properties to this socket. The properties are encoded within parameters of the socket
procedure or in remotely called procedures. The socket mechanism is described in
the extensive book (Stevens 1997).
Channels
An example of distributed programming language where channels for message
transmission are explicitly deﬁned, is OCCAM devised for integrated circuits, the
so-called transputers (Stakem 2011). This language is a concrete realization,
126
5
Interprocess Communication

somewhat modiﬁed, of the abstract model-language CSP. The names of processes
(in CSP) have been replaced with names of channels declared in a program, which
is a parent (in OCCAM) for programs describing processes. So, the process which
sends message, delivers it (e.g. arithmetic expression) into a channel, whence it is
taken by the receiving process. The sender and receiver are communicating by
means of the same channel. The communication is synchronous: the sender waits
for readiness of the receiver to take the message, and the receiver waits for
readiness of the sender to put the message in the channel. Some distributed pro-
gramming and operating systems, apart from the send and receive operations,
contain more structured mechanisms of interprocess communication, like RPC and
RMI—Chap. 6.
Message ﬂow from the sending unit to receiving unit (basic for some pro-
gramming languages) may be presented as follows:
• process ! process
(CSP)
• process ! port ! process
(ADA, Modula-2)
• process ! channel ! process
(OCCAM)
• socket ! socket
(UNIX 4.x BSD)
5.4
Modes of Communication: Synchronous
and Asynchronous, Connection-Oriented
and Connectionless, Multicast and Broadcast, Group
Communication
Synchronous communication
A model-example where synchronous transmission is the basic communication
mode is CSP (Hoare 1978, 1985) and its realization (slightly modiﬁed by intro-
ducing the channels) as a programming language OCCAM (OCCAM 1984). An
example of extensive high-level programming language with explicit commands for
such mode of communication is ADA (Barnes 2005). In the synchronous com-
munication, the sending process, starting a send operation is suspended until the
message has been received by a receiver and the acknowledgment of delivery
arrives. The process resumes the main activity, when the dispatch and reception of
data (in general—communication session) is fully completed. This is called a
synchronous (or blocking) send operation. The receiving process, starting a receive
operation, is suspended until an expected message arrives and the acknowledgment
of delivery is dispatched to the sender. Then the process resumes activity. This is
called a synchronous (or blocking) receive operation.
Metaphorically one may say that a meeting (“randez vous”) of the sender with
receiver takes place in the period of communication session. A created transmission
channel contains, at that time, one message at most. The channel disappears on
5.3
Dispatch and Reception
127

completion of the session. Exceeding of predetermined time of waiting for the
interlocutor (the timeout) may interrupt the session and, possibly, retransmission
of the message by the sender. The synchronous transmission between processes
p1 and p2 is depicted in Fig. 5.2a, b, where events and actions marked black
represent sending, marked grey represent reception and white are other events. The
wavy arrows denote message ﬂow between processes. Their slant illustrates elapsed
time from dispatch to reaching destination by elementary signal, e.g. a single bit.
An implementation detail is, which components of the system realize the meeting:
the process directly, as in Fig. 5.2a, or the operating system on request from the
process, as in Fig. 5.2b. Here, process p2 waits for arrival of the send operation in
process p1 and during the next meeting, p1 waits for arrival of the receive operation
in p2.
Asynchronous communication
In this mode of transmission (called also non-blocking), the sending process puts a
message in its output-mailbox and during transmission of a message, is not sus-
pended, but resumes the ordinary activity without waiting for acknowledgment of
delivery. Thus, the transmission may proceed in parallel with successive process
activity. The receiving process, may either wait for an expected message or resume
external Ɵme
p1
p2
sending message 
to  p2 and 
acknowledgment
of recepƟon
receiver
suspended 
sending message 
to  p1 and 
acknowledgment
of recepƟon
sender  
suspended 
p1
p2
operaƟng  
system of p1
receiver blocked
sender blocked
sender blocked
receiver blocked
operaƟng 
system of p2
external Ɵme
sending
message to  
p2 and ack 
of recepƟon
sending
message to  
p1 and ack 
of recepƟon
call for 
sending 
(a)
(b)
Fig. 5.2 a Direct synchronous transmission b Synchronous transmission performed by call to
operating system
128
5
Interprocess Communication

the ordinary activity and fetch the message from its input-mailbox later. Thus, there
are possible two ways of asynchronous message reception: with blocking or non-
blocking of the receiver. In the blocking way, the receiver is suspended until it gets
complete message directed to it. In the non-blocking way, if the receiver has not
ordered (by operating system) a message reception, then continues the ordinary
activity, even if another process is sending a message to it. If it has ordered
reception of a message, it interrupts its ordinary activity only when fetching the
message from the input-mailbox—if not empty. Otherwise, waits for appearance of
the complete message. An example of the high-level programming language with
explicit commands for asynchronous mode of communication is LINDA (Carriero
and Gelernter 1989). A schematic asynchronous transmission with non-blocking of
sender and receiver is depicted in Fig. 5.3. The p2 process has ordered reception of
a message, its input-mailbox is empty, so p2 waits for delivery, then fetches the
message from the input-mailbox and resumes the ordinary activity. The p1 process
has ordered reception of a message, its input mailbox is not empty, so it fetches the
message and resumes the ordinary activity. A modiﬁcation of this schema to
transmission with blocking of the receiver, is straightforward.
Connection-oriented communication
It takes place when the sender and receiver established a connection channel
(logical or physical), called sometimes a “tunnel” and have made arrangement on
some details of communication prior to the communication itself, i.e. data transfer.
The channel may be used by these interlocutors only, that have established it. Like
in the telephone communication, the channel may be established for permanent
usage (as e.g. “hot line” between countries) or being created dynamically (as. e.g.
switching in telephone exchange)—then it exists only during transmission. The
logical (“virtual”) channel is created by recording it in memory of each device
(computer, router, switch) along the channel’s route, the address of the successive
external Ɵme
p1
p2
copy
message
to mailbox
of p1
call for 
sending 
operaƟng  
system of p1
operaƟng 
system of p2
send 
message
to mailbox
of p2
waiƟng for complete 
message in mailbox of p2
fetch
message
from 
mailbox
of p2
copy
message
to mailbox
of p2
send 
message
to mailbox
of p1
fetch
message
from 
mailbox
of p1
Fig. 5.3 Asynchronous transmission with non-blocking of sender and receiver
5.4
Modes of Communication …
129

device—from the sender to receiver. The data in a message are delivered in the
same order as have been sent as a sequence (“stream”) of units, like bits or bytes.
The receiver sends acknowledgment of reception. The message may be of arbitrary
length.
The
error
correction
takes
place
during
transmission,
thus
the
connection-oriented is more reliable than connectionless communication. It is
realized by various protocols, such as belonging to the popular TCP (Transport
Control Protocols) family or ATM (Asynchronous Transfer Mode) family—see
Sect. 5.5. An example of connection-oriented asynchronous transmission is
depicted in Fig. 5.4. It is, in fact, the same as in Fig. 5.3, but the communication
tunnels (established by suitable protocols located in operating systems of computers
performing processes p1 and p2) are explicitly exhibited.
Connectionless communication
It takes place when the sender and receiver do not establish any connection, but a
message along with receiver’s address is passed to the communication service for
dispatch (like in a postal service—the sender puts a letter into a mailbox). On the
sender’s side, the message is being partitioned into units called datagrams, each
equipped—independently of other datagrams—with information how to reach
destination. They may be transmitted via different routes concurrently and are being
assembled in correct order into a complete message on the receiver’s side. The
order of their delivery may differ from the order of dispatch. Neither reception
acknowledgment nor error check, as well as repeated delivery of the same datagram
takes place. So, this is not such reliable transmission like the connection-oriented—
for a price of higher efﬁciency (speed). Examples are multimedia broadcast of
picture, sound, animated scene, video conference, e-learning, ﬁlms, etc. where
disappearance or corruption of a few datagrams is imperceptible for the receiver.
external Ɵme
p1
p2
call for 
sending 
call for 
recepƟon
copy
message
to mailbox
of p1
send 
message
to mailbox
of p2
fetch
message
from 
mailbox of 
p2
copy
message
to mailbox
of p2
send 
message
to mailbox
of p1
fetch
message
from 
mailbox
of p1
waiƟng for complete 
message in mailbox of p2
operaƟng 
system of p2
operaƟng 
system of p1
Fig. 5.4 Connection-oriented asynchronous communication; the tunnels established prior to
message dispatch
130
5
Interprocess Communication

However, for applications where the high speed transmission and reliability is
indispensable, it may comply such requirements. Datagrams obtain then the unique
identiﬁcations, e.g. numbers, by which the receiver assembles the complete mes-
sage and sends acknowledgment to the sender. In case of a lost datagram (timeout
occurred!), its copy is being retransmitted, and if repeated—the duplicate removed.
The typical protocols for connectionless communication belong to the UDP (User
Datagram Protocol) and IP (Internet Protocol) family. In Sect. 5.5, functions of
various protocols making a layer structure of their set is described “in action” of
message transmission. The choice of protocols in concrete implementation depends
on objectives of a particular distributed system, that is, on its applications.
Remark Notice that the connection-oriented/connectionless and synchronous/
asynchronous modes of communication are mutually independent.
Group communication
So far in this chapter was assumed that one sender dispatches a message to one
receiver, performing the so-called point-to-point communication. Its generalization
is when one sender may dispatch a message to many receivers simultaneously. If
their set is ﬁxed, the transmission is called a multicast, or point-to points. If their set
contains all the computers in the system, the transmission is called a broadcast. The
group communication has been used in Sects. 4.1.2 and 4.3 of Chap. 4 and will be
used in Chaps. 7 and 8. The representation of a group of communication partici-
pants as a graph, where every participant may send messages to everyone, is called
a clique. A group may evolve during system activity: some participants are leaving
the group or entering it, without affecting activity of remaining computers. This
feature is the scalability of the group—a general property of distributed systems
(Sect. 2.3.4, Chap. 2). Other two properties of the group communications are:
atomicity—each message must arrive in all members of the group, or into no one of
them (it is inadmissible that some processes receive the message and some do not)
and a ﬁxed order of message reception (for instance FIFO, called a global FIFO).
Figures 5.5 and 5.6 depict communication of processes p1, p2, p3, p4 in two
groups: {p1, p2, p3} and {p1, p3, p4}. At 18:00, the process p4 is sending message
A which reaches process p3 at 19:00 and p1 at 19:30. At 18:30, the process p2 is
sending message B which reaches process p3 at 20:00 and p1 at 20:30. The FIFO
order is, thus, preserved.
p1 
p2 
p3 
p4 
18:00
19:00
20:00
18:30
20:30
19:30
A 
A 
B 
B 
Fig. 5.5 Group transmission:
p2 ! {p1, p3} and p4 ! {p1,
p3}
5.4
Modes of Communication …
131

p1
p2
p3
p4
18:00
18:30
19:00
19:30
20:00
20:30
21:00
A 
B 
B 
A 
external Ɵme
Fig. 5.6 Diagram of the global FIFO order transmission depicted in Fig. 5.5
The same transmission represented on a space-time diagram is depicted in Fig. 5.6.
The global FIFO reception order is in this example evidently described by the
formula:
x !
message
y ^ u !
message
v ^ CðxÞ\CðuÞ ) CðyÞ\CðvÞ
for all sending events x, u (black) and reception y, v (grey). C(x), C(y), C(u),
C(v) are timestamps of respective events (Sect. 4.2, Chap. 4). Here, C(x) = 18:00,
C(u) = 18:30,
C(y) = 19:00—if y is the event in p3 and C(y) = 19:30—if y is the event in p1;
C(v) = 20:00—if v is the event in p3 and C(v) = 20:30—if v is the event in p1,
Using notation introduced in Sect. 4.2, the general formula characterising necessary
and sufﬁcient condition for the global FIFO order of group communication is
expressed as:
x !
message
y ^ u !
message
v ^ xYu ) yYv
ð5:1Þ
for each pair 〈x, u〉of dispatch events and each pair 〈y, v〉of reception events (re-
member: x ⊑u is equivalent, by deﬁnition, to inequality 〈C(x), #(px)〉≼〈C(u), #(pu)〉
of global timestamps of events x and u occurring in processes px and pu respectively).
The space-time diagram in Fig. 5.7 depicts transmission in the same groups as in
Fig. 5.6, but with reception of messages not in the global FIFO order: message
B sent later than A, reaches both receivers sooner than message A reaches its
receiver p3.
Here, the conjunction x !
message y ^ u !
message v ^ x ⊑u is true and y ⊑v is false,
for dispatch x in p4 with its reception y in p3 and for dispatch u in p2 with each of
its receptions v in p3 and in p1.
Notice that the formula (5.1) is fulﬁlled also if x and u are in the same process, as
well if x = u—consider Fig. 5.8.
132
5
Interprocess Communication

5.5
Layered Structure of the Set of Communication
Protocols: OSI/RM and ATM
Messages travelling in the network are sequences of bits partitioned into fragments
called packets, datagrams, cells, etc.—depending on a communication model and
mode of transmission. Transforming a message from its syntax in a programming
language (user’s external form) onto a sequence of bits moving in the network,
proceeds usually stage by stage: through successive modules called layers, con-
taining protocols performing certain functions. Protocols from a layer convert the
message delivered by the previous layer onto a form for the next layer. Passage
from a layer to the next one proceeds via interface using an auxiliary protocol,
called sometimes „generic”. Such conversion, on the sender’s side, is called a
marshalling and on the receiver’s side—unmarshalling (Sect. 5.1). Each layer deals
with a speciﬁc aspect of communication, for instance, in the application layer,
identiﬁcation of transmission participants and determination of a mode of trans-
mission takes place. Thus it plays a role similar to compiler’s pass (like lexical
analysis, syntax analysis, etc.)—see the frame below. The layers are numbered:
p1
p2
p3
p4
18:00
18:30
19:00
19:30
20:00
20:30
21:00
A 
B 
B 
A 
external Ɵme
Fig. 5.7 Diagram showing violation of global FIFO order of transmissions
p1
p2
p3
p4
A 
B 
B 
A 
A 
B 
external Ɵme
18:00
18:30
19:00
19:30
20:00
20:30
21:00
Fig. 5.8 Notice that if x = u then all receptions of u coincide with receptions of x
5.5
Layered Structure of the Set of Communication …
133

0, 1, 2, …, n (in Fig. 5.9 n = 8) with user computers in layer 0 and the network in
layer n. On the sender’s side, the layer j > 0 takes from the layer j −1 the user
message (a “payload” suitably prepared by layer j −1) equipped with a header
containing control information necessary for the layer j (and the receiver) for further
processing of the message. The layer j converts (“marshals”) the message further,
appends a header to the one received from layer j −1 and necessary for layer j + 1
(j < n). On the receiver’s side, the layer j > 0 takes from the layer j + 1 the message
(with the headers) prepared by the sender in the layer j. Then, converts (“unmar-
shals”) it, using information from the header appended (by the sender) in the layer j,
deletes this header and passes the converted message with remaining headers to the
layer j −1. In Fig. 5.9 the layer structure of protocols is depicted, arranged in
accordance
to
the
standard
elaborated
by
ISO
(International
Standard
Organization), referred to as the OSI/RM (Open Systems Interconnection
Reference Model 1983). Table 5.1 shows this structure in action, where computer 1
is sending a message to computer 2. Various functions of the protocols in the
respective layers are given.
process A 
applicaƟon layer
presentaƟon layer
session layer
transport layer
network layer
data links layer
physical level layer
process B 
applicaƟon protocols
presentaƟon protocols
session protocols
transport protocols
network protocols
data links protocols
physical level protocols
network 
interface
interface
interface
interface
interface
interface
interface
applicaƟon layer
presentaƟon layer
session layer
transport layer
network layer
data links layer
physical level layer
interface
interface
interface
interface
interface
interface
interface
computer 1 
computer 2 
Fig. 5.9 OSI/RM layer structure of protocols; each computer may be sender or receiver
134
5
Interprocess Communication

Table 5.1 Transmission of a message from computer 1 to computer 2 through successive layers
of protocols; obviously, transmission from computer 2 to computer 1 looks the same
ApplicaƟon
layer
External  
message form
of the sender 
Intermediate
message form 1
Header for 
applicaƟon
layer
Sending message by computer 1
FuncƟon: providing a number of services to communicaƟng 
processes, like idenƟﬁcaƟon of the parƟcipants, some
synchronizaƟons, agreement upon character coding and/or type of 
data structures to be transmiƩed, etc.
Example of protocols: X.400 (for email), X.500, FTP, HTTP, Telnet, 
SMTP (for email)
PresentaƟon
layer
Header for 
presentaƟon
layer
Intermediate
message form 2
Header for 
applicaƟon
layer
FuncƟon: request for opening the session (opƟonal), converƟon of 
messages in user’s computer form to independent of parƟcular 
computer form that complies with the structure and meaning of the 
messages represented in user’s programming languages (e.g. format 
of numbers); possible data encrypƟon
Example of protocols: XDR,  ASN.1
Session 
layer
Intermediate
message form 3
Header for 
applicaƟon
layer
Header for 
session 
layer
FuncƟon: management of some aspects of the session in progress, 
like giving the users synchronizaƟon means of inserƟng check-points
if long messages are transmiƩed, error handling, etc.; applied in
connecƟon-oriented-communicaƟon 
Example of protocols: SOCKS, 
NetBIOS, devised in parƟcular  
implementaƟons 
Header for 
presentaƟon
layer
Transport  
layer
Intermediate
message form 4
Header for 
applicaƟon
layer
Header for 
session 
layer
Header for 
transport 
layer
FuncƟon:  service of message transfer between network ports by 
means of the so-called transport addresses; handling of possible
message disappearance; successful transmission acknowledgment
Example of protocols: TCP (connecƟon-oriented), UDP (connecƟonless) 
Header for 
presentaƟon
layer
Network  
layer
Intermediate
message form 5
Header for 
applicaƟon
layer
Header for 
session 
layer
Header for 
transport 
layer
Header for  
network
layer
FuncƟon: rouƟng, i.e. determining a route of the message in the wide 
area networks; also the so-called logical addressing
Example of protocols: X.25 (connecƟon-oriented), IP (connecƟonless) 
Header for 
presentaƟon
layer
Data links
layer
Intermediate
message form 6
Header for 
applicaƟon
layer
Header for 
session 
layer
Header for 
transport 
layer
Header for 
network
layer
Header for 
data links
layer
FuncƟon: grouping bits into the so-called frames and correcƟng their
faulty transmission – if it happens
Example of protocols: Ethernet HDLC: CSMA/CD, ATM
Header for 
presentaƟon
layer
Physical
layer
FuncƟon: transmission of bit sequences as electric signals
Example of protocols: RS-232-C,  X.21, USB, Bluetooth, several IEEE protocols
Network
5.5
Layered Structure of the Set of Communication …
135

Table 5.1 (continued)
Network
Physical
layer
Intermediate
message form 7
Header for 
applicaƟon
layer
Header for 
session 
layer
Header for 
transport 
layer
Header for 
network
layer
Header for 
data links
layer
Header for 
presentaƟon
layer
Receiving message by computer 2 
Intermediate
message form 8
Header for 
applicaƟon
layer
Header for 
session 
layer
Header for 
transport 
layer
Header for  
network
layer
Data links
layer
Header for 
presentaƟon
layer
Network
layer
Intermediate
message form 9
Header for 
applicaƟon
layer
Header for 
session 
layer
Header for 
transport 
layer
Header for 
presentaƟon
layer
Transport  
layer
Intermediate
message form 10
Header for 
applicaƟon
layer
Header for 
session 
layer
Header for 
presentaƟon
layer
Session  
layer
Intermediate
message form 11
Header for 
applicaƟon
layer
Header for 
presentaƟon
layer
PresentaƟon
layer
Intermediate
message form 12
Header for 
applicaƟon
layer
ApplicaƟon
layer
External
message form
of the receiver
136
5
Interprocess Communication

An analogous arrangement of some compilers is partition of the whole
compiler into successive passes. They convert—stage-by-stage—the program
during compilation, from its external (user’s) form onto the form interpreted
by runtime system (e.g. machine instructions or an interpreter, like a „virtual
machine”). Another example is a technique called “bootstrapping” in trans-
lating of one programming language to another. In mathematics, a layer
structure represents a composition of functions.
Apart from the OSI/RM model, examples of layered structure of protocols
models are:
• TCP/IP early prototypes (1975–early 1980) developed and used by Stanford
University (USA), University College (London, UK) and some other institu-
tions, then in 1982 adopted by US Dept. of Defense. In 1989 adopted for UNIX;
4 layers.
• ATM (Asynchronous Transfer Mode (1988); 5 layers—see below.
The communication OSI/RM mechanism is a conceptual schema, having various
implementation in real systems. It is a proposal of structural arrangement of pro-
tocols. It enjoys important property: the layers are mutually independent, which
allows for replacement or modiﬁcation of protocols in a layer, with no affect for
other layers. This is because any layer determines only activities that are to be
performed of a given stage of transmission, but not which speciﬁc protocols are to
be used for these activities. That is why in real implementations, various constructs
and names of protocols are used for the same function. In the early versions, the
OSI/RM model assumed synchronous and connection-oriented mode of commu-
nication. In its later versions, this feature has been treated more liberally. For
instance, although the original model assumed connection-oriented communication,
some protocols at its layers assume connectionless communication (an example is
TCP/IP—a combination of connection-oriented with connectionless—and UDP
protocols at transport and network layers); this is an extension of the RM/OSI early
versions to provide also connectionless service.
In the Table 5.1, activity of successive layers and examples of protocols for this
purpose is shown.
Another
standard
of
layered
structures
of
the
protocol
suit
is
ATM
(Asynchronous Transfer Mode) elaborated in 1988 by ANSI (American National
Standards Institute) in cooperation with ITU (International Telecommunication
Union). Since 1991, this standard in being promoted by the international industry
consortium ATM Forum. The ATM model has been devised to transmit not only
texts, but also multimedia data like voice (speech), music, pictures, paintings, ﬁlms,
animated www pages, videoconferences, etc. To this end, indispensable was
increased speed of transmission, possible at that time due to development of net-
work techniques. The increased speed was also an effect of applying protocols not
requiring acknowledgment of message delivery, as well as partition of the message
5.5
Layered Structure of the Set of Communication …
137

onto small units (48 bytes for a “cell” with a piece of message and 5 bytes for a
header) transmitted concurrently through different routes. A version of this model,
due to high speed of transmission, is also applied for mobile devices. The trans-
mission is mainly connection-oriented, but admits connectionless mode too – when
synchronization between sender and receives is not required. The general principle
of the ATM technique follows the OSI/RM model: the layered structure of protocol
suite and appending headers (on the sender’s side) and removing them (on the
receiver’s side). This layered structure of the ATM model is shown in Fig. 5.10.
The application layer plays a similar part as its counterpart in the OSI/RM
model. Functions of the „planes” layer provide various services for transmission in
networks applying the ATM technique and differ in its particular implementations.
The typical are: check-up (e.g. whether all cells reached destination) and removal of
connections, management of resources needed to perform connection, refusal of
connection because of absence of resources necessary for setting up this connection
(e.g. all the routs are occupied), signalling of timeout of connections, data recovery
from before occurrence of transmission error—these are examples of services
provided by the „planes”. Functions of the ATM adaptation layer are devised for
adapting the form of messages coming from previous layers to the form ﬁxed in the
ATM technique—as a sequence of (48 + 5)-byte cells. On the sender’s side, the
protocols of this layer accomplish partition of input packets onto these cells, while
on the receiver’s side—their assembling into suitable packets. In the ATM layer
activities allow to hide some details of transmission, such as creation of headers of
packets on the sender’s side and their usage on the receiver side, routing of packets,
multiplicity of identical packets in switches, etc.
computer 1
process A 
applicaƟon
ATM adaptaƟon
layer
ATM layer
physical layer
computer 2 
process B 
applicaƟon
„planes”: user,  
management,  
control layer
ATM layer
physical layer
applicaƟon protocols
user, management, 
control protocols
ATM adaptaƟon protocols
ATM protocols
physical protocols
network 
interface
interface
interface
interface
„planes”: user,  
management,  
control layer
ATM adaptaƟon
layer
interface
interface
interface
interface
Fig. 5.10 ATM layered model
138
5
Interprocess Communication

References
Arnold, K., Gosling, J., & Holmes, D. (2005). The java programming language (4th edn.). USA:
Addison-Wesley Professional.
Barnes, J. (2005). Programming in ada 2005. USA: Addison-Wesley.
Ben-Ari, M. (1990). Principles of concurrent and distributed programming. USA: Prentice-Hall.
Brinch Hansen, P. (1975) The programming language concurrent pascal. IEEE Transactions on
Software Engineering, 1(2), 199–207 (June).
Carriero, N., & Gelernter, D. (1989). Linda in context. Communication of the ACM, 32(4),
444–458.
Comer, D. E. (2015). Computer networks and internets (6th edn.), UK: Pearson Education
Limited.
Czaja, L. (1971). GIER ALGOL 4, (in Polish) Wydawnictwa Uniwersytetu Warszawskiego.
Dolińska, I. (2005). Sieci Komputerowe (Computer networks) (in Polish) Wydawnictwo WSE-I.
Fiałkowski, K., & Swianiewicz, J. (1962). Maszyna ZAM-2. Opis maszyny. Kompendium
programowania w języku SAS. Prace Zakładu Aparatów Matematycznych Polskiej Akademii
Nauk (ZAM-2 computer. Description of the machine. Manual of programming) (in Polish).
Hoare, C. A. R. (1978). Communicating sequential processes. Communications of the ACM, 21(8),
666–677.
Hoare, C. A. R. (1985). Communicating sequential processes. London: Prentice-Hall International.
Milner, R. (1980). A calculus of communication systems, Lecture Notes in Computer Science (Vol.
92). Berlin: Springer.
OCCAM. (1984). OCCAM programming manual. USA: Prentice-Hall. (C.A.R. Hoare Series
Editor).
Sportack, M. (2004). Sieci komputerowe. Księga eksperta, Wydawnictwo Helion, Gliwice (Polish
translation of [1998]).
Stakem, P. H. (2011). The hardware and software architecture of the transputer (Kindle Edition).
Stevens, W. R. (1997). UNIX network programming (2nd ed., Vol. 1). USA: Prentice-Hall.
Szałas, A., & Warpechowska, J. (1991). Loglan. Warszawa: WNT (in Polish).
Tanenbaum, A. S., & Wetherall, D. J. (2011). Computer networks. USA: Prentice Hall.
References
139

Chapter 6
Remote Procedure Call
6.1
Motivations, Problems, Limitations
An outline of problems the interprocess communication in distributed systems
creates, has been presented in Chap. 5. Dependently on services and means of
expression provided by operating system and programming language, communi-
cation operations require preparing various parameters carrying information nec-
essary for message transmission. These are, for instance: a mode of communication,
identiﬁers of the sender and receiver, form and type of the message, time limitations,
a way of reaction on errors and other exceptions, etc. It is, thus, necessary to perform
many actions preceding mere dispatch and reception of the message. To this end,
some functions realized by appropriate protocols for creating and removing con-
nection, directing messages to speciﬁed sockets or ports in network services pro-
gramming (Stevens 1997), marshalling and unmarshalling of transmitted data, etc.
are used (Sects. 5.1 and 5.2 in Chap. 5). Alleviation of such excessive burden of
programmers, on the one hand, and fulﬁlment of methodologic postulate to clearly
structuring programs—on the other, was the leading motive to design a mechanism
called RPC (Remote Procedure Call) (Birell and Nelson 1984) and its later object
version RMI (Remote Method Invocation) (Arnold et al. 2005). This mechanism is
to assure communication in the form of the ordinary procedure call (invocation).
This takes place as in ordinary procedural programming language, where procedure
call is a special case of communication, where the invocation statement and the
procedure body are localized inside the same environment (the same computer).
Because the aim of a distributed system is to provide impression of working on one
computer, so, the user should use procedures whose bodies are localized in other
computers in the system, in an ordinary way. Thus, the remote procedure call is of
the form (syntax) similar to the ordinary one in conventional programming lan-
guages, but the user is unaware about location in the network, of the procedure
declaration, i.e. the procedure body (transparency). In some systems, the program-
mer should precede the remote call by creation (e.g. by an application from the
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_6
141

library) an interface to procedures (or methods) offered by a server. Thence the
programmer gets information about presence or absence of the required procedure
on this server, a type of parameters, etc. However, facilitation of the user’s work in
the distributed system, brings about many problems to designers of RPC mechanism,
the problems absent in centralized systems. Let us say that a computer or process, in
which a procedure call takes place, is a client and the one where procedure body (a
declaration) is located—a server, and let us outline main such problems. By the way
notice that request for delivery of time in the Cristian’s method of clock synchro-
nization (Sect. 4.1.1 in Chap. 4) is a kind of remote call for this service.
6.1.1
Different Environments of the Client and Server
Architecture, address space, the client’s and server’s resources are usually not the
same. Transmission of actual parameters from a procedure call to formal parameters
in the procedure body requires using of communication mechanism. In conven-
tional procedural languages, various modes of actual to formal parameters passing
are encountered: by value, by result and value (ADA, (Barnes 2005; Ben-Ari
1990)), by name (the Algol family) or by reference (Pascal, PL/1, Mudula, Java, C,
C++ and others). The methods elaborated for these languages allow for sufﬁcient
efﬁciency (time and space complexity) of parameter passing, in case of one cen-
tralized environment, i.e. without their transmission through the network. Passing
parameters through the network from one environment to another, often of different
data representation, makes the activities of runtime system (a kind of “virtual
machine”), which realizes remote procedure call, fairly complicated. This sub-
stantially lowers its performance. That is why in its nowadays existing imple-
mentations, parameter passing is limited to „call by value” and sometimes to „call
by reference”. The simplest is call by value: the client sends the value of actual
parameter to the server-receiver, into a site assigned to the formal parameter. This
requires a number of actions performed by send and receive operations: trans-
forming the value from external form onto a sequence of bits in the network -
passage through layers of protocols, in particular data marshalling and unmar-
shalling. Replacement of formal parameters with actual, the execution of procedure
body and return of results to the client is accomplished by the server. As in case of
the ordinary procedure mechanism, the formal parameter in procedure body
becomes its local variable, inaccessible in the client’s process. Therefore, proce-
dures in RPC mechanism do not yield the so-called „side effects”, i.e. changing
values of variables in the calling process by the called procedure (provided that
these variables are not parameters for results returned by the procedure). This
feature is postulated by the structured programming methodology. Call by reference
consists in transmitting to the server, a pointer to a place in the client’s program,
where the variable is located, instead of its value. This allows for access from
procedure body to resource indicated by the pointer. The procedure may, in par-
ticular, change the content of this resource. The resource may be a data structure,
142
6
Remote Procedure Call

e.g. array, tree, graph, etc., which does not have to be transmitted „on the whole”, as
in case of the call by value. This is a convenient mechanism for the programmer,
but more complicated for its designers. It requires network transmissions between a
client and server, which makes it of poorer efﬁciency in terms of time and memory
space and more exposed to errors than an ordinary procedure call. It is implemented
in compilers and interpreters of the C language family, where scalar types (num-
bers, characters, truth values) are passed by value, but arrays—by reference. Also in
ADA (Barnes 2005; Ben-Ari 1990), where variables of the reference type, may be
parameters of procedures and tasks (i.e. processes). Applications offered by library
of Java, permit the remote procedure call (“Remote Method Invocation” in Java) by
the so-called „object reference”, global for the entire distributed system. Some
implementations of programming languages make possible deciding about a mode
of parameters transfer, by the programmer. Figure 6.1 illustrates activities per-
formed from remote procedure call to return of result and Fig. 6.2—a structure of
the RPC mechanism. In Table 6.1 this mechanism is demonstrated in action.
6.1.2
Conﬂicts When Using Shared Resources
Since a procedure may give access to a resource for a number of processes running
simultaneously, the system or user must assure their mutual exclusion, where it is
necessary (Sects. 3.2 and 4.3 in Chaps. 3 and 4). Some programming languages,
like Concurrent Pascal (Hansen 1975), ADA (Arnold et al. 2005), provide possi-
bility to decide which resources require protection. For this purpose, the so-called
monitors were introduced. The monitors are language constructs in a form of a
collection of procedures, each protecting a certain resource, therefore executed by at
most one process at a time. Thus, they implement critical sections (“protective
zones” as named before). Users of programming languages where the language
constructs for deﬁning critical sections have not been provided, have to apply
appropriate library procedures—if available. Otherwise they must assure the mutual
exclusion „manually” by using other language constructs.
If the server does not allow for simultaneous execution of procedures
remotely called by different processes, it puts the service requests into a queue
to take them one after one for execution—Fig. 6.2. Moreover, if the dis-
tributed system with the RPC mechanism uses only a single server working
sequentially, then conﬂicts of access to shared protected resources do not
occur. Without such limitations (unobserved in some implementations, e.g.
for the transactions—see Sect. 3.1 in Chap. 3), the RPC mechanism must
assure realization of critical section, where this is necessary (for instance in
the ANSA (1989) system assuring synchronization of threads). Obviously, in
case of the ordinary (not remote) procedures, the protection of resources
belongs to the user, e.g. by means of monitors or “manually” programmed.
6.1
Motivations, Problems, Limitations
143

6.1.3
The Stub
As said above, the RPC mechanism allows to use procedures located in environ-
ments different than their invocations (calls) in the same way as if were located on
the user’s local computer. The notation (syntax) of the procedure call is diverse in
particular programming languages, but as example notation, let us take the fol-
lowing one:
procedure identifier ðactual parametersÞ
where the list of actual parameters delivers data for the procedure and, possibly,
variables for results returned by the procedure. The ideal implementation hides a
location of procedure body: the user is unaware whether the procedure is local or
remote or taken from the library. In existing implementations, this property is partly
accomplished: some actions preparing a remote procedure call are being performed
by the user. The main tool to this end is the so-called stub, a service—subprogram
consisting in two modules: transmitting and receiving, both for the client and
server. The stub is an interface between the client and server, that transforms the
procedure call into the form required by a communication protocol for dispatch to
the server, for reproducing it on the server’s side and ﬁnally for reproducing results
on the client’s side. The stub may be created in the user’s program comprising
remote calls of procedures, prior to the mere program run (the so-called prepro-
cessing), if there are language facilities for its deﬁning, or may be generated in a
special language for deﬁning such interface (e.g. CORBA—see Sect. 2.3.1 in
transmiƫng module of stub at the client side:
(a) gets from the client’s program the procedure
statement: procedure_idenƟﬁer(actual_parameters) 
(b) converts it to a form required by a communicaƟon
protocol between the client and server – here
proceeds the so-called marshalling of actual
parameters
(c) creates a packet containing the client’s name and
converted procedure statement and sends the
packet to the server
(d) waits for the server’s reply
receiving module of stub at the client side:
(a) gets from the server a packet containing result
of the requested procedure run 
(b) converts it to a form required in the client’s program
- here unmarshalling of the result takes place
(c) returns control to the client’s program next to the
procedure statement (return from the procedure) 
receiving module of stub at the server side:
(a) gets a packet with converted procedure statement
from the client and the client name
(b) chooses the requested procedure from the set of
remote procedures kept by the server
(c) converts the received packet to the form required
by the procedure – here proceeds the so-called
unmarshalling of actual parameters
(d) passes the converted procedure statement to be
executed by the server
transmiƫng module of stub at the server side : 
(a) gets result of the procedure performed on the server
(b) converts it to a form required by a communicaƟon
protocol between the client and server – here
marshalling of the result takes place
(c) creates a packet containing the converted result
(d) sends the packet to the client that requested
execuƟon of the procedure
Fig. 6.1 Activity of the client’s and server’s stub in the cycle from invocation of remote
procedure to return of results
144
6
Remote Procedure Call

Chap. 2) and if compiler of this language is associated with compiler of the user’s
programming language. After being created, the stub resides in an operating system,
or a library, or in a runtime system of the user’s program. Actions of the stub are
shown in Fig. 6.1, and the “animated” example of three clients cooperating with
one server—in Table 6.1.
Referring to the analogy of translation between Spanish and Polish language by
assistance of two interpreters—Fig. 5.1 in Chap. 5—notice that the role of client
and server is symmetric there. Diego and Krystyna play both roles, whereas
Gulmaro and Joanna play a part of stubs.
An object-oriented version of the RPC mechanism is RMI (Remote Method
Invocation), available in Java, sometimes referred to as a distributed object
application. The client’s and server’s parts are called there a “stub” (in some
publications just „interface”) and “skeleton” respectively. Motivations and princi-
ples of RMI are the same as in case of RPC, while technical solutions and a way of
usage differ in details. For a programmer, the main difference (apart from „object
way of thinking”) is existence of an address, available for all computers in the
distributed system with RMI, referred to as an object reference. Such address may
be passed as an actual parameter of a method call, as if the parameter passing took
place in the same environment. By means of this parameter the dispatch of data, as
well as reception, can be done.
6.1.4
The Binder—Finding a Server
Point (d) in Fig. 6.1 describing the client’s stub, encompasses searching for a server
where the remotely called procedure has been declared. This is a separate service of
the RPC mechanism in concrete implementations, used by every stub. This service,
referred to as binding, is accomplished by the so-called binder, and consists in
making available a network address of a server where is the respective procedure, to
the client. The binding may be either static, i.e. with keeping this network address
during the entire period of the client’s and server’s presence in the system, or
dynamic, when the client’s stub requests the binder for a network address of a
server (possibly, a point in the server’s process, to which the stub should send the
procedure call: a port or a socket). Depending on the search outcome, the service is
performed or the client is informed about absence of needed server in the system.
After having connected to the system and login, a server registers its presence in the
binder along with data needed for the clients, then, after termination of its task—
performs logoff. The dynamic binding enables greater degree of transparency
(Sect. 2.2.3, Chap. 2) than static. In case of the static binding, replacement of a
server, change of its localization, etc., requires new compilation of some programs,
6.1
Motivations, Problems, Limitations
145

while in case of the dynamic binding—only modiﬁcation of tables comprising
mapping of names into network addresses. In the above description of the client’s
transmitting module, ﬁnding a server and sending a packet with the procedure call,
has been included into the tasks of stub, to avoid implementation details.
6.1.5
Exceptions
During the call of remote procedure, some events that prevent delivery of results to
the client may occur. A server failure (Chap. 7) or its overload with services, failure
of communication infrastructure, absence of required procedure declaration, time-
out of processing the procedure call, missing packet in the network, not matching
up parameters actual and formal (types, size of resources, exceeded range of array
indices, etc.), some errors in procedure body—these are examples of events and
situations preventing correct completion of the procedure call. They are referred to
as exceptions and require notifying the client about their cause and a suitable
reaction of the RPC mechanism or of the user (programmer). The user of pro-
gramming languages capable of exception handling (like ADA (Barnes 2005),
Modula-2, (Wirth 1987), Loglan (Szałas and Warpechowska 1991; Bartol et al.
1984; Kreczmar et al. 1990), Java (Arnold et al. 2005), C++), reacts on them in a
way personally programmed. Some implementations of RPC mechanism, ensure
exception handling automatically, implemented by system designers. The pro-
grammer, using the RPC mechanism with the automatic handling of exceptions
(like Concurrent Pascal (Hansen 1975)), receives from the system appropriate
messages about exceptions and, possibly, advices on actions that should be taken.
6.1.6
Lost and Repeated Messages
In some implementations of RPC mechanism, various strategies of exception
handling are applied, in particular, strategies concerning disappearance and repe-
tition of messages. Appropriate protocol keeps a message dispatched, until
acknowledgment of reception in a deﬁned time (before the time-out) arrives.
Otherwise, the protocol repeats dispatch of the same message. The same concerns
the acknowledgment. In concrete implementations of the RPC mechanism, various
strategies of exception handling are applied, in particular, regarding disappearance
and repetition of message. Their review may be found e.g. in Coulouris et al.
(1994), Tanenbaum (1995).
146
6
Remote Procedure Call

6.2
Example of RPC Mechanism Activity
Figure 6.2 illustrates organization of a system of computers-clients p1, p2, p3,
which use procedures located on a server. The clients are serviced in the order of
procedure invocations and are passing through three states shown in Fig. 6.2
(a state of an exception occurrence has been omitted). It is assumed that after
initiation of remote procedure call, the client waits for results, thus suspends its
activity until the service is accomplished, whereas the server executes one proce-
dure body during this time. Such mechanism is referred to as a synchronous RPC.
Obviously more efﬁcient solution is if the server runs many threads concurrently,
but the principle of the RPC mechanism remains the same.
In some distributed systems [e.g. Mercury (Liskov and Shrira 1988),
(Davidson et al. 1992)], an asynchronous RPC mechanism has been applied.
That means that, after sending to the server request for procedure execution,
the client does not wait for results, but continues activity and collects results
later, until the server completes execution of the procedure and returns them.
The Table 6.1 on the following pages, demonstrates an example of system
depicted in Fig. 6.2 in action is demonstrated.
server 
client p1 
user program with 
remote procedure calls
declaraƟons of remote procedures
receiver
module 
transmiƩer 
module 
server’s stub
queue of clients: 
client’s stub
client p2 
client p3 
local
acƟviƟes
client calls a 
procedure 
located on 
the server
client’s state: 
client waits
for results
transmiƩer 
module 
receiver
module 
client’s stub
transmiƩer 
module 
receiver
module 
client’s stub
transmiƩer 
module 
receiver
module 
user program with 
remote procedure calls
user program with 
remote procedure calls
Fig. 6.2 Exemplary structure of the RPC mechanism and states, which the clients pass through
from invocation to reception of results, when calling a remote procedure
6.2
Example of RPC Mechanism Activity
147

Table 6.1 RPC in action
(continued)
148
6
Remote Procedure Call

(continued)
Table 6.1 (continued)
6.2
Example of RPC Mechanism Activity
149

(continued)
Table 6.1 (continued)
150
6
Remote Procedure Call

(continued)
Table 6.1 (continued)
6.2
Example of RPC Mechanism Activity
151

(continued)
Table 6.1 (continued)
152
6
Remote Procedure Call

(continued)
Table 6.1 (continued)
6.2
Example of RPC Mechanism Activity
153

Table 6.1 (continued)
154
6
Remote Procedure Call

References
The Advance Network System Architecture (ANSA). (1989). Reference Manual. Castle Hill,
Cambridge England. Architecture Project Management.
Arnold, K., Gosling, J., & Holmes, D. (2005). The java programming language. Addison Wesley
Professional.
Barnes, J. (2005). Programming in Ada. Addison-Wesley.
Bartol, W. M., et al. (1984). LOGLAN’82. Report on the Loglan 82 programming language,
Warszawa-Lodz, PWN.
Ben-Ari, M. (1990). Principles of concurrent and distributed programming, Prentice-Hall.
Birell, A., & Nelson, B. J. (1984). Implementing remote procedure calls. ACM Transactions on
Computer Systems, 2(2), 39–59.
Hansen, P. B. (1975). The programming language concurrent pascal. IEEE Transactions on
Software Engineering, 1(2), 199–207 (June 1975).
Coulouris, G., Dollimore, J., & Kindberg, T. (1994). Distributed systems. Addison Wesley
Longman Limited: Concepts and Design.
Davidson, A., Drake, K., Roberts, W., Slater, M. (1992). Distributed windows system, a practical
guide to X11 and open windows, Wokingham Addison-Wesley.
Kreczmar, A., Salwicki, A., Warpechowski, M. (1990). Loglan’88—Report on the programming
language, Lecture Notes on Computer Science (Vol. 414). Springer.
Liskov, B., Shrira, L. (1988). Promises: Linguistic Support for Efﬁcient Asynchronous Procedure
Calls in Distributed Systems, Proc. ACM SIGPLAN’88 Conference on Programming
Language Design and Implementation, Atlanta, Georgia.
Stevens, W. R. (1997). UNIX Network Programming, Vol. 1, second edition, Prentice-Hall.
Szałas, A. (1991). Warpechowska J: Loglan. Warszawa: WNT. (in Polish).
Tanenbaum, A. S. (1995). Distributed operating systems, Prentice-Hall International, Inc.
Wirth, N. (1987). Modula 2, Wydanictwa Naukowo-Techniczne, Warszawa (Polish translation of
author’s book Modula-2).
References
155

Chapter 7
Failures and Damages in Distributed
Systems
7.1
Chances and Kinds of Failure, Remedial Measures,
Fault Tolerance
A crash or faulty activity of computer system happens in a single stand-alone or
centralized installation as well as in a distributed system characterized in Chap. 2, or
in arbitrary network. In the ﬁrst period of information technology, simultaneous
running of the same program on several disconnected computers (Fig. 1.7) was a
remedy to increase degree of reliability. This concerned especially real time data
processing, for instance beginnings of space ﬂights control. With emergence of real
distributed systems (end of 1970), the research and realization of more subtle
methods to deal with failure situations received a strong stimulus. Numerous
cooperating computers and applying multiple replicas of data, made the robustness
of such systems more demanded than in case of single, stand-alone machines.
Increasing of reliability by simultaneous run of the same program on several dis-
connected computers has been automated in distributed systems. It was accom-
plished also by simultaneous run of one program on several computers too but
interconnected interconnected, and exchanging data for periodical comparison of
intermediate results. So, the group (multicast) communication (Sect. 5.4) has been
applied. However the increase of reliability in this way, may reduce expected effect,
because of possible erroneous message passing between the members of the group.
Moreover, the more components of hardware and software and the longer time of
work, the greater chance of faulty behaviour of some of them. Though this is
intuitively evident, a quantitative estimation may look as follows (some mathe-
matical notions and facts needed here, are in Chap. 10):
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_7
157

7.1.1
Probability of System’s Defective Activity; Expected
Time up to a Breakdown
Suppose that on the basis of a number of tests, an estimation has been made that
during a ﬁxed time period Dt, the average probability of one component’s damage
is p (0  p  1). Then the probability of failure-free activity of the system
containing n components in the period Dt is B(n) where B(1) = 1 −p, B(n + 1) =
B(n)(1 −p), thus B(n) = (1 −p)n provided that damage of the components are
independent events. Probability of the whole system failure in the period Dt is then
A(n) = 1 −B(n). Therefore, if p > 0 then limn!1 AðnÞ ¼ 1, which corresponds to
intuition: along with increase of the system’s scale, the chance of damage of a
certain component tends to certainty. If the probabilities of individual components
damage are p1, p2,…, pn then
p ¼
Pn
i¼1 pi
n
is the average probability of damage of one component during the period Dt.
The probability of the whole system failure in the period Dt is
AðnÞ ¼ 1 
Y
n
i¼1
ð1  piÞ
Now, let us estimate an expected time up to damage of a single component in the
system. Suppose as previously, that the average probability of one component’s
damage in a period Dt is p and consider the chance of its damage during multiple of
this period. For conspicuity of reasoning, let us draw the interval Dt as a segment
‘Dta of the time axis.
So, we have:
the chance of failure-free work in the period ‘Dta is 1 −p
the chance of failure-free work in the period ‘Dt a‘Dt a is p(1 −p)1
the chance of failure-free work in the period ‘Dt a‘Dt a‘Dt a is p(1 −p)2
⋮
the chance of failure-free work in the period ‘Dt a‘Dt a‘Dt a. . .‘Dt a
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
k þ 1 periods
is
p(1 −p)k
This is the probability of the component’s damage not sooner than after elapse of
the period (k + 1)Dt.
Therefore limk!1 p 1  p
ð
Þk¼ 0. First, let us calculate the expected value (i.e.
average) of time until damage of one component (for necessary mathematical
notions see Chap. 10). Elementary events x1, x2, x3,… in this case are correct work
of the component in the periods Dt, 2Dt t, 3Dt, … respectively. To this end, the
discrete random variable as the function
158
7
Failures and Damages in Distributed Systems

X : X !
onto SX  R where X = {x1, x2, x3,…}, SX = {Dt, 2Dt, 3Dt, …}, (R—set
of real numbers), is deﬁned as X(xk) = (k + 1)Dt, k = 1, 2, 3,….
Since probability of correct work of the component in the period (k + 1)Dt (i.e.
the probability pk of assuming this value by random variable X) is p(1 −p)k, thus,
by deﬁnition of expected value E(X), the expected time up to a damage of one
component is
EðXÞ ¼
X
1
k¼0
ðk þ 1ÞDt  pð1  pÞk ¼ pDt
X
1
k¼0
ðk þ 1Þð1  pÞk
Because in case of this problem, the expected value depends only on p and Dt,
therefore instead of E(X) we will write E(p, Dt). The series P1
k¼0 ðk þ 1Þð1  pÞk is
absolutely convergent which follows from the d’Alambert criterion (Chap. 10),
because (k þ1)(1p)
k
k(1p)
k1
¼ (1 þ 1
k )(1  p) thus lim
k!1 1 þ 1
k


ð1  pÞ ¼ 1  p\1.
By Mertens theorem (example in Sect. 10.2.2) we get:
X
1
k¼0
ðk þ 1Þð1  pÞk ¼
1
1  ð1  pÞ

2
¼ 1
p2
Finally, the expected value of time up to a damage of one component is
Eðp; DtÞ ¼ Dt
p
Since the probability of a damage of the system of n-components in the period
Dt is A(n) ¼ 1  Qn
i¼1 (1  pn) and in the considered case pi = p, thus, if the
average probability of a damage of one component is p then the expected value of
time up to a damage of the n-components system is
Eðp; Dt; nÞ ¼
Dt
1  ð1  pÞn
7.1.2
Kinds of Failure and Some Mechanisms
of the Fault-Tolerant Systems
The components, like computers (containing many constituents), routers, switches,
modems, ampliﬁers, cables, devices of radio transmission, operating system mod-
ules, compilers, applicative programs, etc. may succumb failures (crash or faulty
activity) of the following kinds:
7.1
Chances and Kinds of Failure …
159

• Permanent—requires replacement (or removal) of the faulty component from
the system,
• temporary—a simple repair sufﬁces, e.g. restoring lost contact in some con-
nexions, removing viruses, etc.
• transient—disappears itself after a little while, e.g. disturbance of radio waves
as result of atmospheric phenomena, etc.
• byzantine—requires special algorithms deciding if continuation of correct
system run is possible in case of defectively acting components; if yes—the
algorithms allow for the continuation (without notiﬁcation of the user about the
failure), otherwise—they notify the user about the situation; this kind of failure
is considered in Sect. 7.2.2.
Some failures may be removed by the system itself, if it is endowed with
appropriate mechanisms. The user is not notiﬁed of this circumstance (trans-
parency). Designing such mechanisms for reliable functioning of the system is
indispensable because great number hardware and software components and long
lifetime of systems may entail faulty activity of a system as a whole. As always, the
designers face decision: the system should enjoy high degree of transparency, that
is to automatize this service for a price of lower efﬁciency, or—on the contrary—
more important is efﬁciency. In case of the latter, a user receives messages from the
system about undesirable situations and undertakes some remedial measures e.g. by
programming suitable exception handling or using library procedures. However the
primary goal is assurance of correct (consistent with speciﬁcation) system beha-
viour, also in case of erroneous activity of some hardware or software components.
A system making possible correct behaviour when some of its components become
faulty, is called the fault-tolerant. Such goal not always can be achieved. It happens
when the system behaves accidentally or undesirably stops working. No absolute
resistance against the damage exists—we say only of errors tolerable up to greater
or less degree. In Chap. 6 some exceptional situations during remote procedure calls
were described and in Chap. 9, an example of coping with messages lost during
transmission or with repeated delivery of the same message, will be shown. To
handle such cases, a number of algorithms (protocols) have been devised, which
make replication of lost packets, elimination of multiple reception and ensure
delivery in the order of dispatch. The so-called Alternating Bit Protocol (Chap. 9) is
an example of such algorithms. If a faulty behaviour appears, to hide it from the
user, a mechanism removing its outcomes is needed—if possible. Depending on a
kind of failure and a strategy of handling it, such mechanism may proceed as
follows:
• The mechanism periodically (often!) records the state of system in a permanent
memory and represents it by a certain identiﬁer (e.g. a timestamp) called a
restoration point or a checkpoint. After a fault detection, the mechanism restores
the state from before its occurrence. This is the so-called backward recovery,
applied also in operating systems of stand-alone computers, where too subtle
algorithms are not necessary. However, it may cause the so-called domino effect,
160
7
Failures and Damages in Distributed Systems

if functioning of the process depends on other processes: withdrawal of a pro-
cess state entails withdrawal of states of cooperating processes. Restoration of
the distributed system state, is much more complicated than in case of
stand-alone machines. For this purpose is needed a register keeping restoration
points stored by the local operating systems. The algorithms that use this register
must ensure the proper ordering of events: in the restored system state, for each
event of message sending, an event of this message reception exists and con-
versely, and the dispatch must precede (in the sense of relation
see Sect. 4.2
in Chap. 4) the reception. The sequence of restoration points used to restore the
system state is called a (restoration) line (Randel et al. 1978). The choice of this
line depends on a strategy of failure handling, but good algorithms choose the
latter one from before the failure. So, the backward recovery is expensive in
terms of process time and memory size.
• The mechanism modiﬁes the state of breakdown so, that the system, starting
from the modiﬁed state, would work correctly. This requires identiﬁcation of
expected effects of erroneous functioning of components, which may disturb
further correct activity of the system as a whole and preclude some decisions of
failure prevention. Such proceeding is called a forward recovery. Appropriate
algorithms are complicated and also costly in terms of process time and memory
size.
• The mechanism conveys the function of faulty components or completely
inactive to reserve (or redundant) components or to components elected by
application of special algorithms (described in Sect. 7.3), started by a process
requesting service from a faulty provider.
• The mechanism signals a crash (indivertible failure) if it cannot withdraw
defective components from the system and cannot automatically convey their
activity onto faultless components.
The mechanism removing failure outcome, should accomplish its work in time
admissible by the system users and, moreover, make it transparent. Designers of
such mechanism face a difﬁcult task that demand ingenuity in conciliation of often
contradictory tendencies. Notice that not every exception is a failure, for instance
the result of dividing by zero is an exception, but is not regarded as a failure. Notice
also that creation of backup copies in a word processor is not creation of check-
points, in the above meaning. As said above, damage of hardware or software may
be permanent, temporary or transient. Messages may disappear or be corrupted
during transmission, computers may get damaged or work randomly (out of con-
trol), some processes whose synchronization is required, may proceed without any
synchronization. Assurance of high degree of resistance against defective or acci-
dental behaviour of cooperating computers is an important tasks of failure handling.
The difﬁculty of this task results from disability of operating systems to analyse
semantic correctness of user programs: no operating system knows whether the
computer is working in accordance with the program speciﬁcation or accidently.
That is why more dangerous and hard to detect is accidental (“frantic”) activity of a
computer than to detect its crash and work stop. The security threat is more serious
7.1
Chances and Kinds of Failure …
161

in case when computers get out of control than in the case of their undesired work
termination. This is referred to as the byzantine failure. Another situation to cope
with is when a simultaneity of some actions is required: there is no algorithm
assuring the exact simultaneity. It may only be approximated. In the following
sections such issues are discussed.
7.2
Some Problems of Activity Coordination
Coordination of processes in order to perform a joint action, to reach certain state or
to protect some resources, has been considered in Chaps. 3 and 4, where mutual
exclusion, deadlock, starvation and synchronization of clocks were discussed.
Some other instances of coordination are when a group of interconnected computers
are performing the same program with the same data, so that to enhance reliability
by periodical scrutiny sameness of behaviour, when the group is to make simul-
taneity of some actions, or to reach an agreement on a joint activity and when a
group is to elect a new coordinator after a crash of the current one. The next two
subsections are concerned with simultaneous execution of some actions and with
coming to agreement on a joint activity, whereas the succeeding section—election
of a new coordinator after a crash of the current one. Notice that problems of the
simultaneity and agreement on a joint activity, are, in a sense reverse to the mutual
exclusion, in which more than one process cannot execute certain activity
simultaneously.
7.2.1
Inﬁnite Cycle of Conﬁrmations—the “Two Army”
Problem
Assume that armies A and B can communicate and should coordinate a joint action
r, (e.g. a gunﬁre), but a moment of this event is not determined. Obviously, the
armies are a metaphor of computers, so let us refer to A and B as computers. Action
r should be performed (perhaps simultaneously) by A and B, but transmission is
not instantaneous—it takes some time. The computers are working faultlessly, but
the transmission channels may be faulty (“the enemy can intercept the messen-
gers”), thus the computers require acknowledgment of delivery of each message.
The coordination actions are the following:
162
7
Failures and Damages in Distributed Systems

moment 1
A and B cannot perform action r (evident)
moment 2
A cannot perform r since does not know if B got the message
moment 3
B cannot perform r since does not know if A got the acknowledgment
moment 4
A cannot perform r since does not know if B got the acknowledgment
moment 5
B cannot perform r since does not know if A got the acknowledgment
etc. to inﬁnity if the channel is unreliable and the computers work
faultlessly.
Never the agreement on the joint action r will take place, irrespectively of
reliability of the channel (requirement of acknowledgments means that the com-
puters „do not know” whether or not the channel is reliable). This is because a
moment of the action (“gunﬁre”) has not been determined and any message cannot
reach the receiver instantaneously. The chain of communications A!B!A!B….
might be interrupted by a fault during message transmission (a message was
undelivered) and will be interrupted if a certain computer stops working. Then the
joint action r does not take effect either. If the computer A inserts a moment T of
execution of r into the message “execute r”, and time T is later than time of
dispatch of this message increased by time of transmission to B and return with
acknowledgment of delivery, then the joint action r will not take effect either, even
when:
– the local clocks of computers are well synchronized and indicate the same time
during exchange of messages;
– computer A receives acknowledgment from B before the moment T.
Why? Because B does not know if its acknowledgment reached A before T,
therefore must wait for conﬁrmation of this, etc. The action r might have been
simultaneously executed under completely unrealistic assumptions: the computers
7.2
Some Problems of Activity Coordination
163

know the time of transmission and moment of the action, their clocks are exactly
synchronized and they know that the mail does not disappear. In this case, the
acknowledgments are superﬂuous.
The above example is a reformulation of the known “two army” problem,
which originally appeared in (Akkoyunlu et al. 1975) (where instead of
armies, two gangs were acting) and has been considered in many writings,
e.g. (Tanenbaum 1995).
Although the impossibility of simultaneous action r is pretty obvious, the for-
mal proof of this may be carried out (by contradiction) as follows. Suppose there
exists a ﬁnite chain of transmissions:
A !
r B !
p1
A !
p2
B !
p3
   !
pn1
A !
pn
B
which ensures agreement between computers A and B for simultaneous execution
of r and let this chain be the shortest (i.e. any shorter does not ensure the agree-
ment), where pi denotes acknowledgment of reception of acknowledgment pi −1
(i > 1), and p1 is the acknowledgment of reception of message r from A by B.
Thus, the computers can start action r, when computer A, had sent pn. On the
other hand, if pn has not reached B, then B cannot perform action r. But if pn has
reached B then B also cannot perform r, because B knows that computer A after
having sent pn, does not know whether or not pn has reached B (because B has not
sent acknowledgment). Therefore the above chain does not ensure agreement: a
contradiction, which ends the proof.
Obviously, if the minimal ﬁnite chain ends at A, then the reasoning remains
valid. Notice that if there are not two computers involved, but A1, A2,…, Am, this
formal reasoning of impossibility of reaching agreement, requires similar reasoning
for m −1 of chains that begin from a certain computer. Computers A2,…, Am are
communicating with A1 only, but not between themselves.
Although coming to agreement on joint simultaneous action in ﬁnite time is
theoretically impossible under above assumptions, this is sometimes necessary in
some applications, for instance when approval of bank transactions is required.
Diverse methods are being then applied, e.g. dispatch of a stream of messages
instead of one and waiting for acknowledgment of everyone. In this case, a minimal
number of messages in the stream is being estimated in order to obtain high
probability of reaching agreement. A certain predictable degree of uncertainty of
transmission must be then assumed.
Another task of reaching consensus of simultaneous actions is the so-called
Firing Squad Problem, discussed in a number of publications, for instance
Waksman (1966), Moore and Langdon (1968), Balzer (1967).
164
7
Failures and Damages in Distributed Systems

7.2.2
Reaching Consensus with Fault Tolerance—the
“Byzantine Generals” Problem
In the “two army” problem it was assumed that the computers perform correctly,
but deceptive may turn out communication channels. In the problem of “Byzantine
Generals”, communication channels are reliable, thus conﬁrmations are not
required, but the computers may perform incorrectly. Their activity may be random
(get out of control), which is difﬁcult or impossible to detect. As before, the task is
to reach consensus in undertaking a simultaneous action by a group of computers.
There are a number of versions and formulations of this problem, for instance
Lamport et al. (1982), Fisher et al. (1985), Garg and Bridgman (2011), Tanenbaum
(1995), Coulouris et al. (1994), Ben-Ari (1990). Let us begin considerations close
to presented in Lamport et al. (1982), the ﬁrst where the problem has been posed
and solved. The computers („generals”) are to agree a common strategy leading to
coordination of a „military action”- one of several possible. They may also pass
information on a manpower of their strike force. In the ideal situation each com-
puter is reliable, so, sends its vote for one and the same strategy to the remaining
computers and notes down a number of votes for particular strategies received from
them, including its own vote. In this way the computers make records of votes
given to particular strategies. Each computer gets identical record of votes, because,
as reliable, sends the same vote to the remaining computers. When exactly one
strategy obtained majority of votes, the computers came to agreement, if more than
one—they failed. In Fig. 7.1a, computers G1, G2, G3, G4 (the generals) are to agree
on one of strategies a, b, c, whereas in Fig. 7.1b—on one of a, b. In the case (a) the
set of votes collected by every computer contains 2 votes for strategy a, 1 vote for
b and 1 vote for c, thus strategy a has been agreed-upon. In the case (b) the set of
votes collected by every computer contains 2 votes for strategy a and 2 votes for b;
a strategy has not been agreed-upon.
But a decision has to be made, so, what is to be done? It depends on the kind of
strategy. If the strategies a, b concern only a strike force of the armies, then nothing
G1
a
G4
G2
G3
a
b
b
b
a
a
a
c
c
c
a
G1
a
G4
G2
G3
a
b
b
b
a
a
a
b
b
b
a
a
a
b
c
a
a
b
b
(a)
(b)
Fig. 7.1 Faultless computers (“loyal generals”); (a) strategy “a” outvoted, (b) no strategy
outvoted
7.2
Some Problems of Activity Coordination
165

is to be done—such information will be used for ﬁxing a joint strategy. If, however,
they concern realization of a certain action then it is possible for instance:
• to repeat the voting;
• to convey decision to a co-ordinator (chief general), who resolves voting result;
the co-ordinator’s verdict is being broadcast to remaining generals;
• if weights are assigned to strategies (e.g. strength of the armies under command
of the generals), then the decision may depend on the weights; in some versions,
the weights may also be assigned to computers, as considered in Garg and
Bridgman (2011).
If all the computers are reliable, that is if no one behaves unforeseeably and
communicates the same vote to all remaining computers, then their decisions lead to
a common strategy. Difﬁculties occur if some computers are unreliable: they are
running but chaotically, randomly; in particular they communicate various pro-
posals of strategy to their partners or convey incidental strategies (those are not
received from the coordinator). There are a number of this problem versions,
depending on various assumptions. Apart from the reliability of communication
channels (thus when no delivery conﬁrmation is required), let us consider a version
under the following assumptions:
(i)
no computer has been appointed as a coordinator—all have equal rights;
(ii)
each computer sends messages to all others, as well as to itself;
(iii)
some computers are unreliable, so, they may send different messages to
different receivers;
(iv)
each receiver knows from whom received a message (messages are „signed”)
—an identiﬁer of the sender is attached to the message;
Let computer G3 be unreliable (“treacherous general”) and let it broadcast to
computers G1, G2, G3, G4 proposals of strategies ?1, ?2, ?3, ?4 respectively, as
shown in Fig. 7.2.
G1
a
G4
G2
G3
a
b
b
b
?2
?4
?1
c
c
c
a
a
?3
b
c
The graph shows a process of Table A creation:
G1
G2
G3
G4
G1
a       b
?1
c
G2
a       b
?2
c
G3
a       b
?3
c
G4
a       b
?4
c
sender
receiver
Table A
Fig. 7.2 The graph presents voting of computers G1, G2, G3, G4, with results in the Table A
166
7
Failures and Damages in Distributed Systems

The rows corresponding to receivers contain proposals of strategy dispatched by
senderscorrespondingtothecolumns.Everyreliablecomputersendsthesameproposal
to all receivers. The unreliable, may senddifferent proposals to different receivers. After
having created Table A, none computer may infer from this table, which computer is
unreliableandwhichstrategiesthecomputershadsentmostfrequently,becausenoneof
them knows what strategies had been received by its partners. So, every reliable
computer sends to the remaining computers (andto itself), its row of Table A, thatis, the
vector of four received proposals of strategy. The unreliable sender may send different
(incidental) vectors to different receivers. In this way Table B in Fig. 7.3 is created with
identical rows, except for (possibly) entries in columns corresponding to unreliable
computers, which may send different vectors. In the example it is the column G3, what
every receiver can see in its own row of the Table B. Therefore:
G1 sees that G3 had sent ?1, ?2, ?7, ?4 to G1, G2, G3, G4 respectively
G2 sees that G3 had sent ?1, ?2, ?11, ?4 to G1, G2, G3, G4 respectively
G3 sees that G3 had sent ?1, ?2, ?15, ?4 to G1, G2, G3, G4 respectively
G4 sees that G3 had sent ?1, ?2, ?19, ?4 to G1, G2, G3, G4 respectively
The graph in Fig. 7.4 shows process of Table B creation, that is the renewed
voting, this time for vectors of strategies.
The assumption that the computers know from whom they have received the
messages, was necessary for creation Tables A and B. Without this assumption the
computers would not be able to arrange the messages as sequences, i.e. vectors, in
which a place (component position) corresponds to one sender. Thus, it would
result in a set, not a vector.
Remembering assumptions i–iv let us sum up what information every computer
has collected in the Table B, what can be inferred from this information and how
the computers can utilize this in order to come to an agreement. Therefore:
• Each receiver has access to information contained only in its row of Table B.
• If a certain sender had not sent the same value to all receivers, then each reliable
receiver would have noticed this in its row of the Table B; thus the receiver
G1
G2
G3
G4
G1
G2
G3
G4
[a, b, ?1, c] [a, b, ?2, c] [?5, ?6, ?7, ?8]
[a, b, ?4, c]
receiver
Table B
[a, b, ?1, c] [a, b, ?2, c] [?9, ?10, ?11, ?12]
[a, b, ?4, c]
[a, b, ?1, c] [a, b, ?2, c] [?13, ?14, ?15, ?16] [a, b, ?4, c]
[a, b, ?1, c] [a, b, ?2, c] [?17, ?18, ?19, ?20] [a, b, ?4, c]
sender
Fig. 7.3 Rows G1, G2, G4 contain vectors, each being the respective row of the Table A; also row
G3, save for the vector in the column corresponding to unreliable G3; this vector has incidental
components ?13, ?14, ?15, ?16; every reliable general notices the identical voting result by reliable
generals
7.2
Some Problems of Activity Coordination
167

states that the sender is unreliable. This sufﬁces for the joint knowledge on
unreliability of the sender. However, this is not the necessary condition. Even if
none of the senders had not sent different messages to different receivers (during
creation of Table A), then nonetheless different receivers could have received
different vectors (during creation of Table B). If all computers were reliable then
all vectors in the Table B would be identical, but not always conversely. This is
a global information: no computer can ascertain this situation. Any computer
can see its own row of the Table B only. For instance, if ?1 6¼ ?2 then everyone
sees that G3 is unreliable. But also, if ?1 = ?2 = ?3 = ?4 but e.g. [?5, ?6, ?7,
?8] 6¼ [?9, ?10, ?11, ?12] (G1 i G2 are unable to ascertain this), then G3 is unre-
liable. This may happen when during creation of the Table A, the computer G3
was behaving correctly, but then got spoiled. Thus:
• A
group
of
computers
not
always
can
pinpoint
the
unreliable
(„generals-traitors”) from among themselves and, for instance, exclude them
from making decision on the basis of proposed strategies.
• Every computer can ascertain only which values (strategies) have been sent by
remaining computers most frequently: which occur most often in the received
vectors. Sending a value is understood as „giving a vote” for a certain strategy.
• Every computer sees that values a, b, c occur in the two vectors received from
two remaining computers. But every value denoted by “?” sent by G3 occurs in
one vector if differs from a, b, c and if are different among themselves. This
means that G1, G2, G4 have dominated („outvoted”) computer G3 in proposing
strategies. We say that the three computers „tolerate” G3, that is, do not exclude
it from the system but ignore its behaviour.
G1
G4
G2
G3
[a,b,?1,c]
[a,b,?1,c]
[a,b,?2,c]
[a,b,?2,c]
[?5,?6,?7,?8]
[?13,?14,?15,?16]
[a,b,?4,c]
[a,b,?4,c]
Fig. 7.4 The graph presents voting of computers G1, G2, G3, G4, with results in the Table B
168
7
Failures and Damages in Distributed Systems

• Such proceeding may lead to an agreement in choosing some values, but cannot
ensure this, because some values sent by unreliable computers may occur in
majority of vectors seen by a certain computer.
• It can be proved that such proceeding makes possible agreement only when in a
group of computers, with M unreliable, at least 2M + 1 are reliable. Thus, this is
a necessary condition for possibility of agreement by means of the presented
above method of „voting”. The seminal article, where several versions of the
Byzantine Generals problem was discussed with proofs of results is Lamport
et al. (1982). In the above example, three computers are reliable and one is
unreliable (M = 1 and 2M + 1 = 3), the agreement is possible: they agreed for
strategies a, b, c.
The reader can check how the tables A and B would have look like, if two
computers in Fig. 7.2 were unreliable, e.g. also G4. In such case, although the
reliable might be able to identify the unreliable, but making decision on the basis of
majority of votes is generally impossible: the majority may not exist. So, the
reliable computers would not be able to “tolerate” the unreliable ones.
Creating table B (Fig. 7.3) required two voting rounds. Theoretically, one may
imagine continuation of the procedure, so that a next table might be similarly
created from the table B by means of the third round, etc. Bearing in mind above
remarks, the successive rounds (though practically hardly acceptable) might detect a
“frantic” behaviour of some computers, if it had not been detected in the previous
rounds. This (potentially endless) proceedings may look as in Fig. 7.5.
etc.
G1
G2
G3
G4
G1
G2
G3
G4
G1
G2
G3
G4
G1
G2
G3
G4
G1
G2
G3
G4
a
b
?1→G1, ?2→G2, ?3 →G3, ?4 →G4
c
[a,b,?1,c]
[a,b,?2,c]
[?5,?6,?7,?8]→G1, [?9,?10,?11,?12]→G2,…
[a,b,?4,c]
[[a,b,?1,c],[a,b,?2,c],[?5,?6,?7,?8],[a,b,?4,c]]
[[a,b,?1,c],[a,b,?2,c],[?9,?10,?11,?12],[a,b,?4,c]]
[[a,b,?1,c],[a,b,?2,c],[?13,?14,?15,?16],[a,b,?4,c]]
[[a,b,?1,c],[a,b,?2,c],[?17,?18,?19,?20],[a,b,?4,c]]
[[[…],[…],…,[…]],[[…],[…],…,[…]],…,[[…],[…],…,[…]]]
[[[…],[…],…,[…]],[[…],[…],…,[…]],…,[[…],[…],…,[…]]]
[[[…],[…],…,[…]],[[…],[…],…,[…]],…,[[…],[…],…,[…]]]
[[[…],[…],…,[…]],[[…],[…],…,[…]],…,[[…],[…],…,[…]]]
first round
second round
third round
Fig. 7.5 Horizontal lines („buses”) correspond to the computers (generals); each computer
broadcasts a message (a strategy or vector of strategies) onto its line, from which the computers
take it and compose vectors for the next round. The dashed line corresponds to the unreliable
computer
7.2
Some Problems of Activity Coordination
169

So far it has been assumed that each computer knows from whom a message was
received. If this is not so, then in the Table B, will occur sets instead of vectors
(sequences). For instance, instead of vector [a, b, ?1, c] the set {a, b, ?1, c} will
appear (and if e.g. ?1 = a then the set {a, b, c}), so, it is not known which computer
has sent particular elements of this set. In such case each computer can see which
values are in the majority in the sets, but does not know who has sent them. Thus no
computer is able to conclude which computer is unreliable. If each computer knows
who was a sender of particular message, we say that the messages are „signed”.
Let us consider another version of the problem, where one computer is appointed
as a coordinator, the „General”, while others, the „Lieutenants”, depend on him. As
previously, some computers are reliable (“loyal”), some—do not (“traitors”). The
general starts the election by sending a strategy “attack” or “retreat” to all lieu-
tenants. The loyal general and lieutenants are broadcasting this strategy to all
remaining lieutenants without change, but the traitors may convey different
strategies to different lieutenants. The lieutenants are unaware who sent them a
given strategy unless this was the general. So, the strategy was “signed” only by the
general, whereas other senders are anonymous. Voting consists in sending a vote in
favor of one strategy. The lieutenants must select one strategy on the basis of
majority of votes received. If all lieutenants select the same strategy, then they reach
agreement as to the military action, otherwise—they do not. Examples of various
cases of this version are shown in Figs. 7.6a, b, 7.7c, d and 7.8e, f. We see that
though the computers cannot pinpoint the traitors, sometimes can ignore (“toler-
ate”) the traitors’ votes.
The cases (a), (b) in Figs. 7.6 and 7.7 (c) show a system with one loyal General,
two loyal Lieutenants and one traitor (black). Every loyal Lieutenant conveys the
general’s decision unchanged to remaining Lieutenants, the treacherous Lieutenant
falsiﬁes it. So, regardless of this falsiﬁcation, the voting result by all Lieutenants
would be the same—consistent with the General’s decision. In these cases M = 1,
thus 2M + 1 = 3, therefore, similarly to the previous version, the necessary
General
Lieutenant
1
Lieutenant
2
Lieutenant
3
aƩack
General
Lieutenant
1
Lieutenant
2
Lieutenant
3
aƩack
aƩack
Lieutenant 1 collects 3 × aƩack
Lieutenant 2 collects 3 × aƩack
Lieutenant 3 collects 2 × aƩack, 1 × retreat
All Lieutenants for aƩack: agreement reached
Lieutenant 1 collects 2 × aƩack, 1 × retreat
Lieutenant 2 collects 3 × aƩack
Lieutenant 3 collects 2 × aƩack, 1 × retreat
All Lieutenants for aƩack: agreement reached
aƩack
aƩack
aƩack
(a)
(b)
Fig. 7.6 (a), (b) one treacherous Lieutenant: agreement
170
7
Failures and Damages in Distributed Systems

condition for reaching agreement is fulﬁlled. In the case (d) in Fig. 7.7 the
treacherous Lieutenants have collected majority votes for “attack”, while the loyal
Lieutenant—for “retreat”, whereas in the case (e) in Fig. 7.8—conversely. In the
case (f) the General and Lieutenant 2 are traitors. The Lieutenants 2 and 3 have
collected majority of “attack”, while the Lieutenant 1—“retreat”. In these cases
M = 2, thus 2M + 1 = 5, therefore, the necessary condition for reaching agreement
is not fulﬁlled.
Lieutenant
1
Lieutenant
2
Lieutenant
3
retreat
Lieutenant
1
Lieutenant
2
retreat
retreat
Lieutenant 1 colected 2 × retreat, 1 × aƩack
Lieutenant 2 colected 3 × retreat
Lieutenant 3 colected 3 × retreat
All Lieutenants for retreat: agreement reached
Lieutenant 1 colected 2 × retreat, 1 × aƩack
Lieutenant 2 colected 1 × retreat, 2 × aƩack
Lieutenant 3 colected 3 × aƩack
Lieutenants 2, 3 for aƩack, Lieutenant 1 for retreat
agreement not reached
retreat
aƩack
aƩack
Lieutenant
3
General
General
(c)
(d)
Fig. 7.7 (c) one treacherous Lieutenant: agreement; (d) two treacherous Lieutenants: no
agreement
General
Lieutenant
1
Lieutenant
2
Lieutenant
3
retreat
General
Lieutenant
1
Lieutenant
2
retreat
aƩack
Lieutenant 1 collected 1 × retreat, 2 × aƩack
Lieutenant 2 collected 2 × retreat, 1 × aƩack
Lieutenant 3 collected 2 × retreat, 1 × aƩack
Lieutenants 2, 3 for retreat, Lieutenant 1 for aƩack
agreement not reached
Lieutenant 1 collected 2 × retreat, 1 × aƩack
Lieutenant 2 collected 1 × retreat, 2 × aƩack
Lieutenant 3 collected 1 × retreat, 2 × aƩack
Lieutenants 2, 3 for aƩack, Lieutenant 1 for retreat
agreement not reached
retreat
aƩack
aƩack
Lieutenant
3
(e)
(f)
Fig. 7.8 (e) two treacherous Lieutenants: no agreement; (f) treacherous General and one
Lieutenant; no agreement
7.2
Some Problems of Activity Coordination
171

Notice that if the Lieutenants have conveyed result of their voting also to the
General and to themselves, the ﬁnal outcome: agreement or its lack, would be the
same. Thus, for the systems in Figs. 7.6, 7.7 and 7.8, the tables A and B may be
created (but for two strategies)—as in the previous version for the system in
Fig. 7.2. The outcome of voting (thus the agreement) would be the same as in the
version with the general and lieutenants. It may be proved that the previous version
(in which all the generals enjoy equal rights and there are several possible strategies
and all senders are known to the receivers) can be reduced to the version with the
general and lieutenants.
This example, generalized to other conﬁgurations and any number of “soldiers”,
reafﬁrms validity of the general fact: under assumptions admitted above, agreement
is possible only if in a group of computers containing M traitors, at least 2M + 1 are
loyal. A formal proof, fairly long (based on a construction and analysis of several
recursive algorithms) may be found in Lamport et al. (1982). An extensive pre-
sentation of the Byzantine Fault Tolerance problem is in Cachin et al. (2006).
Examples of systems where consensus of some actions is required but some
computers
may
behave
chaotically
and
where
BFT
(Byzantine
Fault
Tolerance) algorithms are applied to tolerate their behaviour
• Some systems of ﬂight control (Airplane Information Management System) of
Boeing 777 and 787; as the real-time systems to ensure ﬂight security, they
require fast reaction to events.
• Some systems of a spacecraft (SpaceX Dragon and NASA Crew Exploration
Vehicle—in elaboration); exposed on cosmic radiation, they should assure
possibly reliable activity by fast automatic reaction and removal of disturbances.
• A system launched in 2015 for VISA card holders, a network system of
peer-to-peer fast cash remittance; requires utmost reliability against possible
disturbances, also due to criminal acts.
• Distributed measuring system where tolerance of faulty work of sensors is
required.
Summarizing the above considerations one can see that the main purpose of the
Byzantine Fault Tolerance (BFT) methods is to automatically ignore computers
behaving chaotically if it is possible (remember the necessary condition for this),
without wasting time for repairing them or removing from the system. This is
especially important in the real-time systems, where the prompt reaction on events
is demanded. If the “tolerance” is not possible, then the detected faulty units can be
excluded from the system. If this is the coordinator (the “General”), then a new
coordinator can be elected, by means of e.g. the Bully Algorithm or the Ring
Algorithm presented in the next two sections.
172
7
Failures and Damages in Distributed Systems

7.3
Election of a New Coordinator Following Detection
of the Damaged
In distributed systems, some services are being provided by one or more computers
acting as servers. Typical examples are coordination of access to shared resources,
synchronization of clocks, communication service, remote procedure call, etc.
When a service provider undergoes a failure, it is necessary to assure further system
work, by election of a new provider, which takes over tasks of the damaged one.
For the two presented here election methods, the following assumptions are
admitted:
• Every computer may take a part in the election of a computer, from among those
that are endowed with a program for coordination of the system activity, like
initiating some actions, sequencing events, reacting to failures, etc. After being
elected, it becomes a coordinator (customarily, we say „a process” instead of
„computer”).
• To every process p, a unique identiﬁcation number is assigned, denoted by
#[p] (it may be e.g. network address of a process p) and everyone knows the ID
number of the remaining processes.
• As a coordinator, a faultless process with the greatest ID number is elected. Such
arrangement allows for direct reference to the coordinator, by processes
requiring coordination of some activities.
• If a process requires a service from the coordinator, but does not receive a
response after a predetermined time (time-out) or receives a message of the
coordinator’s failure, from a failure detector, then it declares elections of a new
coordinator.
• The elections are made by algorithms, that try to localize a faultless process of
the greatest ID number and to appoint it as a coordinator.
• In the course of election, processes are sending and receiving messages among
themselves via reliable transmission channels, i.e. each message reaches a
receiver and is not falsiﬁed during transmission. However, a process may
become faulty—in such case it is not responding to messages or is ignored
(“tolerated”) if identiﬁed as such, by the BFT method (Sect. 7.2.2).
• A result of election is agreed-upon by all active processes.
Two successive subsections present methods of election of a new coordinator.
7.3.1
Bully Algorithm of Election
1. Process p which had discovered a failure of the coordinator, proclaims election.
It sends out a message „election” to the group of processes bearing greater ID
numbers than its own. Then waits for messages „reply”. The process p is
7.3
Election of a New Coordinator …
173

unaware which receiver of its message is faultless, that is why p sends „elec-
tion” not only directly to the process bearing the greatest ID number.
2. If after a lapse of time ﬁxed in the system, the process p would not receive
message „reply”, then it becomes a coordinator. The coordinator notiﬁes the
processes bearing smaller ID number about the election result, by sending
message „coordinator”.
3. If the process p, before a lapse of time ﬁxed in the system, receives the message
„reply” from all processes to which p had sent the message “election”, then
processes which responded with this message, proclaim the election and the role
of process p is over.
Remarks
– outcome of this algorithm, i.e. the winner of elections (new coordinator),
has the greatest ID number among all the faultless processes; that is why it
is called a „bully”—as a strongest that has conquered the remaining
processes;
– the processes, after having sent the message „reply” to the process which
discovered a failure of the coordinator, proclaim the election concurrently
(by sending message „election” to processes bearing greater ID number).
This speeds-up the choice of the new coordinator.
The Table 7.1 shows processes p1, p2, p3, p4, p5, p6 in the course of several
elections, proclaimed as a result of breakdown of the current coordinators. Some
processes, not being coordinators, also are breaking down during elections. The ID
numbers assigned to processes, are ordered as follows: #(p1) < #(p2) < #(p3) <
#(p4) < #(p5) < #(p6). The processes pass through the following states in the
course of elections (Fig. 7.9):
process in full order, does not proclaim the election
process in full order, proclaims the election
procsss sends a reply
faulty process but not the current coordinator
current coordinator damaged
newly elected coordinator
Fig. 7.9 States assumed by
processes during election
174
7
Failures and Damages in Distributed Systems

Table 7.1 Election of new coordinator by the Bully algorithm
States 1–7
1 
p1 
p5 
p2 
p3 
p4 
p6 
p1 
p3 
p5 
p6 
2 
elecƟon
elecƟon
elecƟon
p4 
p2 detected failure of coordinator p6, proclaims elecƟon! 
p2 
3 
reply
reply
p1 
p3 
p6 
p4 
p2 
p5 
4 
elcƟon
elecƟon
elecƟon
p1 
p5 
p6 
p4 
p2 
p3 
elecƟon
5 
reply
p1 
p3 
p5 
p6 
p4 
p2 
6 
coordinator
coordinator
coordinator
coordinator
p1 
p3 
p6 
p4 
p2 
p5 had not received reply in a predetermined Ɵme - bears the greatest number
7 
p5 – newly elected coordinator,  p6 - repaired
p1 
p3 
p6 
p4 
p2 
(continued)
7.3
Election of a New Coordinator …
175

Table 7.1 (continued)
States 8–13
8 
elecƟon
elecƟon
elecƟon
elecƟon
p1 detected failure of cordinator p5, proclaims elecƟon! 
p3 
p6 
p4 
p2 
p5 
p1 
9 
reply
reply
reply
p1 
p3 
p5 
p6 
p4 
p2 
10 
elecƟon
elecƟon
elecƟon
elecƟon
elecƟon
elecƟon
elecƟon
p1 
p5 
p6 
p4 
p2 
p3 
11 
reply
reply
p3 crashed
p1 
p3 
p5 
p4 
p2 
p6 
12 
coordinator
coordinator
coordinator
coordinator
coordinator
p6 had not received reply in a predetermined Ɵme - bears the greatest number
p1 
p3 
p5 
p4 
p2 
13 
p1 
p5 
p2 
p3 
p4 
p6 – newly elected coordinator 
176
7
Failures and Damages in Distributed Systems

7.3.2
Ring Algorithm of Election
The processes are ordered along the ring as the arrows indicate in Fig. 7.10.
The ordering of processes along the ring has nothing common with their num-
bering in the Bully algorithm: although the processes are named (hold identiﬁers)
and unique ID numbers, their ID numbers are in no relation to the succession in the
ring. There is no token in the ring. As in case of the Bully algorithm, this algorithm
aims at choosing a faultless process of the greatest ID number as a coordinator. In
the course of election every process may ﬁnd oneself at the status: participates, not
participates, faulty coordinator, newly elected coordinator. Two kinds of message
are being transmitted between processes:
• election(#(p), q) where #(p) is the ID number of process named p, which
detected the faulty coordinator and q is the name (identiﬁer) of the faulty
coordinator.
• elected(#(p), q) where #(p) is the ID number of newly elected coordinator
named p and q is the name of the hitherto faulty coordinator.
The ring algorithm is outlined as follows:
1. A process which has required a service and has detected a failure of the coor-
dinator, assumes the „participates” status and sends the message „election” to
its successor on the ring, along with its own ID number and identiﬁer of the
damaged coordinator.
2. A process, which has received the message “election”, compares its ID number
to ID number in the received message and if:
(a) the received ID number is greater than its own, then passes this message to
its successor on the ring without change and assumes the “participates”
status unless already it has this status;
(b) the received ID number is smaller than its own, and if the receiver:
• has the status “not_participates”, then sends to its successor the message
“election” with its own ID number and identiﬁer of the faulty coordi-
nator and assumes the “participates” status;
• has the status “participates”, then replaces this received smaller ID
number with the own one and sends to its successor the message
“election” with its own ID number and identiﬁer of the faulty
coordinator;
p1          p2           p3          …           pn
Fig. 7.10 Succession of
processes in the ring
7.3
Election of a New Coordinator …
177

(c) the received ID number is equal to its own, then this means it is the greatest,
so, the receiver has been elected as a new coordinator; if this receiver has the
status “participates” then it assumes the “newly_elected” status and sends to
its successor the message “elected” with its own ID number and identiﬁer of
the faulty coordinator; otherwise, end of election.
3. A process which received the message “elected”, proceeds as follows: if it has
not been elected as the new coordinator, then passes this message to its suc-
cessor on the ring and assumes the “not_participates” status; otherwise, end of
election.
Notice that this version of the ring algorithm allows carry out the elections
concurrently: two or more processes may detect failure of the same coordinator at
moments close to each other and proclaim election.
Readers who prefer to study algorithms in a ﬂow diagram form, may take a look
at Fig. 7.11 Its exemplary work, as a sequence of states, shows Table 7.2.
The Table 7.2 presents a system of processes p1, p2, p3, p4, p5, p6 in the course
of several elections proclaimed after a failure of current coordinators. The ID
numbers assigned to processes, are ordered as follows:
#(p5) < #(p3) < #(p1) < #(p6) < #(p2) < #(p4)
The processes assume the status during elections shown in Fig. 7.12, Structure of
the ring is shown Fig. 7.13.
178
7
Failures and Damages in Distributed Systems

START ELECTION
Process detected failure of coordinator. Assumes status „participates” and sends message
„election” with its own ID number and name of the faulty coordinator to the successor on the ring 
Process received message: 
„election”        „elected”
ID number in the received message as 
compared with the receiver’s ID number is:
greater
smaller
equal
The receiver has status „newely elected”
YES                                    NO
The receiver has
status „participates”
YES               NO
The receiver assumes
status „participates”
The receiver passes
the received message
without change to its
successor
The receiver has
status „participates”
YES               NO
The receiver assumes
status „participates”
The receiver replaces the 
received smaller ID with its
own ID and sends message
„election” to its successor
END ELECTION
The receiver assumes
status „not_participates”
The receiver passes
the received message
without change to its
successor
The receiver has
status „participates”
NO               YES
END ELECTION
The receiver assumes
status „newely elected”
The receiver passes the 
message „elected” with its
own ID to its successor
Fig. 7.11 Flow diagram of the ring algorithm of a coordinator election
not_participates
participates
faulty coordinator
newly elected coordinator
Fig. 7.12 Status assumed by
processes during election
p1
3
ID number of process p1
name of process p1
p2
5
p3
2
p4
6
p5
1
p6
4
Fig. 7.13 Structure of the
ring
7.3
Election of a New Coordinator …
179

Table 7.2 Election of new coordinator by the ring algorithm
States 1–6
p1
       3 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
p6
       4 
1 
p1 has detected failure of 
coordinator p4, proclaims elecƟons
elecƟon(3, p4)
p2 
       5 
p3 
       2 
p4 
       6 
p5 
       1 
p6 
       4 
2 
p1 
       3 
p3
       2 
p4
       6 
p5
       1 
p6
       4 
3 
p1
       3 
p2
       5 
p4
       6 
p5
       1 
p6
       4 
4 
p1
       3 
p2
       5 
p3
       2 
p4
       6 
p6
       4 
5 
p1
       3 
p2
       5 
p3
       2 
p5
       1 
p4
       6 
6 
elecƟon(5, p4)
p1
       3 
p2
       5 
p3
       2 
p5
       1 
p6
       4 
(continued)
180
7
Failures and Damages in Distributed Systems

Table 7.2 (continued)
States 7–12
p4
       6 
7 
Ne n
p2 elected as a new coordinator
p2
       5 
p1
       3 
p3
       2 
p5
       1 
p6
       4 
p3
       2 
p4
       6 
8 
p1
       3 
p5
       1 
p6
       4 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
9 
p1
       3 
p6
       4 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
p6
       4 
10
p1
       3 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
p6
       4 
11
p1
       3 
elected(5,p4) 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
p6
       4 
12
p1
       3 
p2
       5 
END ELECTION 
(continued)
7.3
Election of a New Coordinator …
181

Table 7.2 (continued)
States 13–18
p2
       5 
p4
       6 
p5
       1 
p6
       4 
13
p1
       3 
p3 has detected failure of 
coordinator p2, proclaims elecƟon
p3
       2 
p2
       5 
p4
       6 
p6
       4 
14
p1
       3 
p3
       2 
p5
       1 
p2
       5 
p4
       6 
15
p1
       3 
p3
       2 
p5
       1 
p6
       4 
p2
       5 
p4
       6 
16
p1
       3 
p3
       2 
p5
       1 
p6
       4 
p2
       5 
p4
       6 
17
p1
       3 
p3
       2 
p5
       1 
p6
       4 
p2
       5 
p4
       6 
18
p1
       3 
p3
       2 
p5
       1 
p6
       4 
(continued)
182
7
Failures and Damages in Distributed Systems

Table 7.2 (continued)
States 19–24
p2
       5 
p4
       6 
19
p6
       4 
newly elected
coordinator
p1
       3 
p3
       2 
p5
       1 
p2
       5 
p4
       6 
20
p1
       3 
p3
       2 
p5
       1 
p6
       4 
p2
       5 
p3
       2 
p4
       6 
21
p1
       3 
p5
       1 
p6
       4 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
22
p1
       3 
p6
       4 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
23
p1
       3 
p6
       4 
END ELECTION 
p2
       5 
p4
       6 
p5
       1 
p6
       4 
24
p1 and p3 have detected
failure of coordinator p6; 
they proclaim elecƟon
p1
       3 
p3
       2 
(continued)
7.3
Election of a New Coordinator …
183

Table 7.2 (continued)
States 25–30
p2
       5 
p4
       6 
p6
       4 
25
elecƟon(2, p6)
p1
       3 
p3
       2 
p5
       1 
p2
       5 
p4
       6 
p6
       4 
26
elecƟon(3, p6)
p1
       3 
p3
       2 
p5
       1 
p2
       5 
p4
       6 
p6
       4 
27
p1
       3 
newly elected
coordinator
p3
       2 
p5
       1 
p2
       5 
p3
       2 
p4
       6 
p6
       4 
28
elecƟon(3, p6)
p5
       1 
p1
       3 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
p6
       4 
29
elected(3, p6)
p1
       3 
p2
       5 
p3
       2 
p4
       6 
p5
       1 
p6
       4 
30
p1
       3 
END ELECTION 
184
7
Failures and Damages in Distributed Systems

References
Akkoyunlu, E. A., Ekanadham, K., Huber, R. V. (1975). Some constraints and trade-offs in the
design of network communications. In Proceedings of 5th ACM Symposium on Operating
Systems Principles (pp. 67–74).
Balzer, R. (1967). An 8-state minimal time solution to the ﬁring squad synchronization problem.
Information and Control, 10(1), 22–42.
Ben-Ari, M. (1990). Principles of concurrent and distributed programming. New Jersey:
Prentice-Hall.
Cachin, Ch., Guerraoui, R., Rodrigues, L. (2006). Introduction to reliable and secure distributed
programming (2nd Ed). Berlin: Springer.
Coulouris, G., Dollimore, J., & Kindberg, T. (1994). Distributed systems, concepts and design.
Boston: Addison Wesley Longman Limited.
Fisher, M., Lynch, N., & Paterson, M. (1985). Impossibility of distributed consensus with one
faulty process. Journal of the ACM, 32(4), 374–382.
Garg, V. K., Bridgman, J. (2011). The weighted byzantine agreement problem. In IEEE
International Parallel & Distributed Processing Symposium, Ancorage, Alaska (pp. 524–531),
May 16–20, 2011.
Lamport, L., Shostak, R., & Pease, M. (1982). The byzantine generals problem. ACM
Transactions on Programming Languages and Systems, 4(3), 382–401.
Moore, F. R., & Langdon, G. G. (1968). A generalized ﬁring squad problem. Information and
Control, 12(3), 212–220.
Randel, B., et al. (1978). Reliability issues in computing system design. Computing Surveys, 10(2),
123–165.
Tanenbaum, A. S. (1995). Distributed operating systems. New Jersey: Prentice-Hall International,
Inc.
Waksman, A. (1966). An optimum solution to the ﬁring squad synchronization problem.
Information and Control, 9(1), 66–78.
References
185

Chapter 8
Distributed Shared Memory
8.1
Structure, Motivations, Problems, Advantages,
Disadvantages
In accordance with general objectives of distributed systems, Distributed Shared
Memory (DSM) aims at making possible usage of local memory of all computers
by the programmer, as if constituted jointly a single private local memory in his/her
computer. This is to unburden the programmer from details of transmissions of data
between his/her own computer and other computers in the system. To achieve this,
a mechanism which simulates one huge address space, accessible to all computers
has been devised. Such virtual memory is, from a user viewpoint, a union of all
local memories of computers. Its construction yields problems much more com-
plicated than construction of virtual memory of a single computer (the simulated
extension of RAM by a disc), where it is implemented by means of paging or
segmentation. Figure 8.1 depicts a general structure of the distributed system
endowed with the DSM mechanism and Fig. 8.2 a view, how such system may be
perceived by the user.
DSM is a mechanism for integration of computers in distributed system, simi-
larly as mechanism of Remote Procedure Call (RPC), but on lower level: for the
user, access to memory of external computer, does not differ from access to memory
of his/her own computer. The main problem is to ensure the system’s behaviour in
accordance with desired model of memory consistency. This means that results of
activity of every computer are to be functionally close to the results of its activity in
the environment of remaining computers with a common memory for all, unique
(with no replicas) location of data and undisturbed access to the data by other
computers. A degree of this closeness depends on a model of memory consistency.
In other words, the system should behave as if it worked in accordance with its
speciﬁcation, but on a single computer with a huge memory and in the time sharing
mode for programs executing the speciﬁed common task. That is, as a multipro-
grammed centralized computer. Lack of the so-called strict consistency, is a
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_8
187

consequence of performing access to memory by means of subsystems managing
the access, that create and handle multiple copies of data and make their relocation
and transmission through the network. This takes considerably longer time than
executing a machine instruction. The memory manager may be a fragment of
operating system on every computer, or its task may be performed by an interpreter
(„virtual machine” or runtime system) of a programming language, or by library
procedures. The access to DSM, i.e. the reading and writing of data, may also be
done by one supervising manager, which receives and performs requests from
client-processes and ensures desired memory consistency model. Remember that by
“distributed system” is meant here not each possible computer network, where
realization of DSM would be not only inexpedient but impossible, for instance for
all computers in the internet. All this depends on the DSM system architecture. The
DSM mechanism is implemented for a system of autonomous computers connected
by a network, without common physical memory, managed by a distributed
operating system and, in general, is designed for a certain class of tasks. So, e.g. in
some corporate or local networks (see 2.1 in Chap. 2). Application of this
………..
processor
local memory
(physical)
processor
processor
computer 1
computer 2
computer n
Distributed Shared Memory 
(virtual)
network
local memory
(physical)
local memory
(physical)
Fig. 8.1 DSM system—general structure
Fig. 8.2 DSM system—user’s view (a union of local memories)
188
8
Distributed Shared Memory

mechanism requires new solution to some problems typical for multicomputer
systems without common memory. In particular, devising speciﬁc algorithms
(protocols) for synchronization of processes and clocks, realization of critical
sections (called sometimes protective zones) when using shared resources, Remote
Procedure Call, exception handling, etc.
In its early versions (Li and Hudak 1989), the DSM was a virtual memory,
implemented analogously to the paging system, where pages had their locations in
the memory of individual computers (work stations) connected by local networks
(LAN), in contrast to systems comprising only a single computer with disk. If a
program in a certain computer attempted to access data located on a page absent in
memory of this computer, then the paging manager was making transfer of this
page from memory of another computer, where the data is located. As always, the
problem of page replacement arises, i.e. choosing a page (or segment) that is to be
removed from RAM, if there is not enough space for a page actually needed (Czaja
1968; Madnick and Donovan 1974; Silberschatz et al. 2009; Nutt 2002; Tanenbaum
1995). However in case of distributed systems, more transmissions of pages occurs,
than between one computer and disk, since a ﬁxed store of pages does not exist in
DSM. It increases a chance of the so-called thrashing or ﬂickering—of pages, that
is, waste of time for unnecessary transmissions. In the further development of the
DSM techniques, the enhancement of efﬁciency has been obtained, e.g. by multi-
plying number of locations (data replication) of shared variables, or by creating of
virtual memory only for variables (objects) used in processes performing a certain
task. The problems of memory inconsistency then arise, when a certain variable has
a location in diverse local (and cache) memory storages, or when the variable has
been declared as a shared, in programs executed by diverse computers. A review of
some memory consistency models may be found in Mosberger (1993). Several
versions of DSM have been devised and implemented, e.g. with a singled out DSM
manager, or with a distributed manager, that is a collection of fragments of oper-
ating systems residing on individual computers.
Advantages
• distributed system with the DSM mechanism is scalable: computers may be
attached and removed, thus arbitrary large address space may be obtained;
• the user-programmer is released from communication management, that is from
using instructions send and receive, when writing or reading data located out-
side of his/her computer, as well as from data marshalling (especially of com-
plex data structures) and from entering into details such as control of
communication reliability, familiarity with protocols, etc.;
• simpler interfaces (implemented in software), cheaper than those in multipro-
cessor hardware;
• the total cost of distributed memory of all interconnected computers is lower
than the cost of a specially constructed large global memory of multiprocessor
systems, because of massively produced integrated circuits as well as publicly
available protocols of memory access are being used;
8.1
Structure, Motivations, Problems, Advantages, Disadvantages
189

• no memory buses between the processors and global memory with a complex
structure („topology”) of their interconnection, hence no bottlenecks in access to
memory;
• programs in DSM systems are portable, because of common programming
interfaces;
• the DSM system may handle big databases without burden the user with details
of this service, e.g. making copies of the databases—the system itself creates
each copy.
Disadvantages
• users have no control over trafﬁc of data between computers; this may slow
down this trafﬁc in comparison with usage of explicit message passing by means
of send and receive operations;
• users have less control over reliability of data transmission;
• users must understand (at least some) memory consistency models; the incon-
sistency arises when replicas of a certain variable, shared by programs in diverse
computers, contain different values at the same time; this results from data
replication and their transmission, which takes undetermined and unpredictable
time, as well as from various frequency of local clocks, thus different speed of
program execution by the computers.
8.2
Interleaving Model of System Activity
In Chap. 1, a number of programs running on one computer in a time sharing
(i.e. multiprogrammed) mode has been shown (Table 1.2). Some fragments of
processes were interleaved, simulating concurrent execution of the programs by
separate physical processors. We say that a true concurrency (non-interleaving) has
been simulated by indeterminism: order of the interleaved fragments is incidental—
has nothing to do with what the programs are doing! If the programs constitute one
system for solving a task, then such interleaving model makes easier a formal
analysis of its behaviour, albeit it loses the important property of concurrency:
independence of some actions and dependence on some others.
Remark The true concurrency have been presented and investigated in sev-
eral formal models, like Petri nets (Petri 1966; Reisig 1985), Mazurkiewicz
traces (Mazurkiewicz 1987; Diekert and Rozenberg 1995), Dependence
graphs (Hoogeboom and Rozenberg 1995), cause-effect structures (Czaja
2002) and in a number of periodicals.
In order to present the DSM peculiarities, ﬁrst let us consider a system of two
computers executing programs (Fig. 8.3).
190
8
Distributed Shared Memory

For the purpose of this section let us assume:
(1) the statements are atomic (indivisible), so they are the critical sections along
with reading and writing memory;
(2) the statements are executed in the order of their appearance in every program;
(3) every execution of the statements in the system is serialized: one execution can
be described as an interleaving of execution sequences of both programs;
(4) variables a, b are shared by both programs; initial values: a = 0, b = 0, x,
y—arbitrary;
(5) print(x, y) is executed when execution of other statements in both programs is
over; its execution causes fetching values of x, y from memory and their
printout;
Under these assumptions there are possible only the following interleavings:
interleaving 1: a := a + 1; b := b + 1; y := b; x := a; print(x, y)
interleaving 2: a := a + 1; y := b; b := b + 1; x := a; print(x, y)
interleaving 3: y := b; a := a + 1; b := b + 1; x := a; print(x, y)
interleaving 4: a := a + 1; y := b; x := a; b := b + 1; print(x, y)
interleaving 5: y := b; a := a + 1; x := a; b := b + 1; print(x, y)
interleaving 6: y := b; x := a; a := a + 1; b := b + 1; print(x, y)
Remarks
1. Without assumptions 2 and 5 there are 5! = 120 permutations of statements of
these processes.
2. Different interleavings yield different printouts of values of x, y, but the
inequality x > y (invariant of the system) is fulﬁlled for every of the inter-
leaving; Indeed, if x < y then the printout would be x = 0, y = 1, thus statement
x := a should be executed before a := a + 1 and statement y := b—after
b := b + 1, which is absent in interleavings 1–6, since it would contradict
execution order of statements in the programs.
3. It may be proved that the number of interleavings of n sequences, each of k1, k2,
…, kn elements, amounts to ðk1 þ k2 þ ... þ knÞ!
k1!k2! ... kn!
. Thus, there are
2 þ 2
ð
Þ!
2!2!
= 6 inter-
leavings of two sequences y := b; x := a and a := a + 1; b := b + 1 of state-
ments in above programs.
Table 8.1 shows execution of the system depicted in Fig. 8.3 in the interleaving 4.
Variables x, y are located (addressed) in the memory of computer 1 and variables a,
b in the memory of computer 2. No replication of variables takes place, instead
memory manager of computer 1 fetches values of a, b from memory of computer 2.
computer 1 performs:             computer 2 performs:
y := b;                                     a := a+1;  
x := a;
b := b+1;
print(x,y);
Fig. 8.3 There are diverse
interleavings of statements of
these programs
8.2
Interleaving Model of System Activity
191

Table 8.1 State 1—fetching value of a from memory to program, state 2—storing value of
expression a + 1 in variable a, state 3—transmission of value of b to computer 1, state 4—storing
it in variable y. state 5—transmission of value of a to computer 1, state 6—storing it in variable x,
state 7—fetching value of b from memory to program, state 8—storing value of expression b + 1
in variable b. 1 states 9, 10—fetching values of x and y to printing
subsystem managing
memory access
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
0
a
b
0
y
x
.......
1
a := a+1;
b := b+1;
executes statement a := a+1
subsystem managing
memory access
subsystem managing
memory access
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
0
y
x
.......
2
a := a+1;
b := b+1;
executes statement a := a+1
subsystem managing
memory access
3
executes statement y := b
subsystem managing
memory access
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
0
y
x
.......
a := a+1;
b := b+1;
subsystem managing
memory access
computer 1
computer 2
4
executes statement y := b
subsystem managing
memory access
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
0
y
x
.......
a := a+1;
b := b+1;
subsystem managing
memory access
0
(continued)
192
8
Distributed Shared Memory

5
executes statement x := a
subsystem managing
memory access
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
0
y
x
.......
a := a+1;
b := b+1;
subsystem managing
memory access
0
6
executes statement x := a
subsystem managing
memory access
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
0
y
x
.......
a := a+1;
b := b+1;
subsystem managing
memory access
1
0
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
0
y
x
.......
7
a := a+1;
b := b+1;
0
1
executes statement b := b+1
subsystem managing
memory access
subsystem managing
memory access
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
1
y
x
.......
8
a := a+1;
b := b+1;
0
1
executes statement b := b+1
subsystem managing
memory access
subsystem managing
memory access
Table 8.1 (continued)
(continued)
8.2
Interleaving Model of System Activity
193

Notice however, that this is practically untypical realization, since in most (all?)
known implementations pages or segment containing variables a, b are being
transmitted to computer 1 where these variables become local. A part of paging
mechanism is neglected, so that not to overshadow the main issue of this section:
simulation of concurrent execution by possible interleavings. In the Table 8.1 the
small horizontal arrow points to currently executed statement, the arrow connecting
memory with the subsystem managing memory access shows reading or writing data
from/to memory or data transmission from computer 2 to computer 1. After the
execution, the printout x = 1, y = 0 takes place. The system is truly distributed, that
is without an external manager of the DSM.
Notice that if variables a, b were located in both computers (replication) then the
result of computation would be the same, provided that the statements are indi-
visible, since every statement begins execution only if execution of the previous
statement is over. In this case, the local update of a value in memory of computer 2
is accompanied by transmission of this value to computer 1. Notice also that a
system with a central manager of DSM would behave in the same way, due to
assumptions (1–5). It is seen how the arrows showing data transfer in the Table 8.1
would go over in the case of other interleavings and what printouts would have
taken place: interleaving 1: x = 1, y = 1, interleavings 2–5: x = 1, y = 0, inter-
leaving 6: x = 0, y = 0.
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
1
y
x
.......
9
a := a+1;
b := b+1;
0
1
executes statement print(x,y)
subsystem managing
memory access
subsystem managing
memory access
computer 1
computer 2
y := b;
x := a;
print(x,y)
.......
D I S T R I B U T E D
S H A R E D
M E M O R Y
1
a
b
1
y
x
.......
10
a := a+1;
b := b+1;
0
1
executes statement print(x,y)
subsystem managing
memory access
subsystem managing
memory access
Table 8.1 (continued)
194
8
Distributed Shared Memory

In every interleaving 1–6 the following conditions are fulﬁlled:
(i) In each execution, the readout of a variable from memory fetches value
assigned to this variable before its most latter (prior to this readout) update
(write in); thus, between these two access operations no other update of this
variable takes place; here, the prepositions like „before”, “prior to”, „between”
refer to the global (external) time.
(ii) The order of execution of statements in each interleaving is the same as order
of their execution in respective programs; the readout of a variable fetches
value assigned to this variable by a write operation, preceding this readout in
this interleaving (with no other updates of this variable inbetween); so, here
the „preceding” and the „inbetween” refer to a position in the interleaving, that
is, in the sequence.
Condition (i) characterizes the strict consistency of memory, condition (ii)—the
sequential consistency (Lamport 1979). They will be formally deﬁned in Sect. 8.5.
The conditions are fulﬁlled in the previous example due to serializability of entire
statements in processes, i.e. ensuring (by the subsystems managing memory access)
their execution only in permitted interleavings—due to their indivisibility
(atomicity). Resignation of the assumptions (1–3) above, may cause violation of
conditions (i), (ii) and lack of meaning of the notions „preceding” and „between”
with respect to the global time, since a global clock is absent in distributed systems.
The global time is a concept external for the system. The notions „preceding” and
„between”, etc. may refer either to the real (external) time or to a place in a process
(i.e. in a sequence), or in the interleavings—this should be made clear when used.
We have seen that the concurrent system may behave variously even with the
same initial data: it may yield different executions with different results, but a given
execution generates unique results, i.e. memory contents and printouts. Later will
be seen that a given concurrent execution may be equivalent (i.e. with identical
results) to executions in many interleavings satisfying condition (ii). The user is
unaware which execution out of many possible, the system would choose. If he/she
is interested in some properties of results (e.g. some invariants), but not necessarily
exact values, then he/she selects (or “agrees on”) a system that ensures these
properties. Thus, the user agrees on a certain kind (model) of memory consistency,
more or less “liberal”—if more, then such one that permits for more concurrency. In
this sense, one can say metaphorically that the memory, thus in fact the user,
“concludes a contract” with the system to apply a certain kind of memory
consistency.
The next sections show some consequences of resignation from above
assumptions (1–3): the operational units (statements, memory read/write, …) in a
system will no more be atomic and not necessarily executed in the order of their
occurrence in the programs and not always can be executed sequentially with the
same result as a given concurrent execution. It will be seen that only operations of
memory access (i.e. read/write) are taken into account in description of the so-called
consistency models of DSM. The lack of their atomicity, faulty data replication (not
8.2
Interleaving Model of System Activity
195

identical copies of the same data) and latency of their transmission between com-
puters, is a cause of various types of inconsistency. The assurance of desired
consistency model is the task of subsystems managing memory access. The
problems of memory consistency will be discussed by various examples, then
formal deﬁnitions of some consistency models will be given.
Notice that by decreasing granularity of operational units, the degree of
concurrency is increased, thus performance (speed) of the system but also
probability of incorrect behaviour: collision when using shared resources, low
accuracy of clocks synchronizing, various kinds of memory inconsistency
(accepted for some tasks), etc. Notice also, that a value of a variable may be a
certain data structure or object like array, tree, etc. In examples, for simplicity,
it is assumed to be a primitive unit like a number.
8.3
Concurrency of Access Operations to Distributed
Shared Memory, Examples of Sequential and Strict
Consistency, Informal Description
Consider possible behaviours of the system {computer 1, computer 2} in Fig. 8.3,
but with the following assumptions:
1. Signiﬁcant are only operations of memory access—computation of a + 1, b + 1
is not taken into account: only memory read/write operations decide on various
kind of memory consistency. Fetching value of a variable, means a read-out of
its value from the local memory or transmission from memory of another
computer. Update of a variable, means write-in its value into memory of each
computer, where the variable has a location. So, the memory access operations
encompass inter-computer transmission of data. The subsystems managing
memory access arrange the read/write operations in a partial order. Read-out a
value a of variable x by computer j = 1, 2 is denoted by R(x, a)j and write-in—
by W(x, a)j.
2. Subsystems managing memory access where suitable protocols are performed,
can run concurrently with execution of program statements (e.g. by means of
different cores).
3. The initiation of reading or writing value of a variable takes place directly
following a request sent to the subsystem managing memory access.
Termination is not synchronized with execution of statements—a consequence
of point 2.
196
8
Distributed Shared Memory

4. Every computer terminates the reading and writing a variable with the same
value as at the initiation—the computer does not change this value during
execution of read/write.
5. Variables a, b are shared by both programs; initially a = 0, b = 0, x, y—
arbitrary.
In examples that follow, variables a, b are located in memory of both computers.
Thus, it is assumed that the paging mechanism takes care of supplying a page
containing the variable to the computer that uses this variable. And for present
considerations it does not matter whether the needed variable will be located in the
main or cache memory. Various locations of a variable are called its replicas. It is
convenient to present execution of the system as a bunch of parallel straight lines,
each line showing execution of a sequential process on the time axis. For instance,
the diagram in Fig. 8.4 shows one of possible runs of the system from Fig. 8.3,
reduced to the memory read/write operations.
This execution (run) in action is presented by Table 8.2, where the double lines
stretching out across the successive states from computer 2 to computer 1 show data
transmission pending. Notice that the states reﬂect temporal relationships between
operations, preserving property expressed in point 4 above, but not exact instants of
begin and end of operations shown in Fig. 8.4.
The system’s concurrent execution shown in Fig. 8.4 and in Table 8.2 allows to
make several remarks on memory consistency issues as well as the geometrical
presentation of some dynamic peculiarities of concurrent systems.
First, the sequence of R/W operations on one time axis, or corresponding line
segments, is called a local history of access to memory during execution of a
sequential process. The beginning “(” of a segment is the instant of initiation
(invocation) of respective operation. The end “)” of an R-segment is an instant of
termination of fetching a variable’s value from local memory to processor. The end
“)” of a W-segment is an instant of completion updating all replicas (copies) of a
variable (we will see later, that the end of a W-segment may be understood dif-
ferently: as an instant of acknowledgment of broadcast a value to all replicas of a
variable).
Second, the R/W-line segments of all processes can be arranged into a sequence,
such that executing the operations in the order as in this sequence, yields the same
computer 1:    
computer 2:    
W(a,1)2
external time
R(a,0)2
R(b,0)2
W(b,1)2
R(b,0)1
W(y,0)1
R(a,0)1
W(x,0)1
(
) (
) (
)
(
)
(
)
(
) (
(
)
)
Fig. 8.4 Exemplary run of the system shown in Fig. 8.3, reduced to the R/W operations (save for
operations relating to print-out). Allows for sequential consistency of memory
8.3
Concurrency of Access Operations to Distributed …
197

Table 8.2 Sequentially consistent execution. Operations W(a, 1)2, W(b, 1)2 initiate transmission
of value 1 to computer 1
computer 1      
computer 2
.......
0
0
a
a
b
0
b
0
y
x
.......
a := a+1;
b := b+1;
1
y := b;
x := a;
R(a,0)2
D I S T R I B U T E D    S H A R E D     M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
R(b,0)1
y := b;
x := a;
.......
1
0
a
a
b
0
b
0
y
x
.......
a := a+1;
b := b+1;
2
computer 1      
computer 2
D I S T R I B U T E D    S H A R E D     M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
W(y,0)1
0
W(a,1)2
y := b;
x := a;
.......
1
0
a
a
b
0
b
0
y
x
.......
a := a+1;
b := b+1;
3
0
computer 1      
computer 2
D I S T R I B U T E D    S H A R E D     M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
R(a,0)1
R(b,0)2
y := b;
x := a;
.......
1
1
a
a
b
0
b
1
y
x
.......
a := a+1;
b := b+1;
4
0
computer 1      
computer 2
D I S T R I B U T E D    S H A R E D     M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
W(x,0)1
0
W(b,1)2
(continued)
198
8
Distributed Shared Memory

result as the concurrent execution. For the execution shown in Fig. 8.4 one of such
possible sequences is, for instance:
R b; 0
ð
Þ1; R a; 0
ð
Þ2; W y; 0
ð
Þ1; R a; 0
ð
Þ1; W a; 1
ð
Þ2; R b; 0
ð
Þ2; W x; 0
ð
Þ1; W b; 1
ð
Þ2
This is an admissible interleaving of local histories of memory access, making
the global history of this execution. It is easily seen what are other admissible
interleavings, that is such that yield the same result as the concurrent execution (by
the way: all these equivalent—in this sense—interleavings, constitute one
Mazurkiewicz trace (Mazurkiewicz 1987; Hoogeboom and Rozenberg 1995), a
concept introduced on higher abstraction level than present description of memory
consistency). The existence of admissible interleaving of all the histories of
memory access characterizes the sequential consistency of the memory. In the
seminal paper (Lamport 1979), Leslie Lamport, who had introduced this concept,
put it as follows: “the result of any execution is the same as if the operations of all
the processors were executed in some sequential order, and the operations of each
individual processor appear in the order speciﬁed by its program”. So, the
sequential consistency is characterized by two kinds of preservation (invariance) of
some properties: preservation of the same ordering of read/write execution as in the
individual programs and preservation of memory coherence (Sect. 8.2, point (i)).
Third, to ensure sequential consistency, the subsystems managing memory
access must sometimes delay some operations, so, in geometric terms, to make shift
of a respective segments along the time axis. This happened in above example: the
W(a, 1)2 operation and its successors have been delayed, so that R(a, 0)1 precedes
the W(a, 1)2 in the global history, which ensures memory coherence.
Fourth, construction of the global history—if possible for a given concurrent
execution, that is serialization of the R/W operations—requires the operations to be
indivisible (atomic) in this history. Assurance of this belongs to the subsystems
managing memory access. Sequential consistency of memory entails preserving the
so-called Readers/Writers principle (essential e.g. for data bases): while a process is
updating a variable (all its replicas), no other process can write to or read from this
variable, but when it is reading a variable, then other processes can also read this
y := b;
x := a;
.......
1
1
a
a
b
1
b
1
y
x
.......
aplikacje
5
0
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
a := a+1;
b := b+1;
0
Table 8.2 (continued)
8.3
Concurrency of Access Operations to Distributed …
199

variable, but not write to it. The „Readers/Writers” problem (Courtois et al. 1971),
has been analysed in various versions, in a number of publications. In fact, the
sequential consistency of memory, as requiring serialization of R/W operations, is
the stronger property than the Readers/Writers principle.
Fifth, the order between some operations in a global history may be inverted
(yielding different but equivalent global history) as far as it does not inﬂuence
operation ordering in individual programs and memory coherence. In particular, the
R-operations in different local histories are independent of each other. In the global
history they are ordered relative to the respective W-operations only.
Sixth, although different executions of a concurrent system with the same initial
data may yield different results, thus not equivalent global histories, some rela-
tionships (desirable by the user) between the results should be invariant. An
example is the inequality x > y fulﬁlled after some executions of the system shown
in Fig. 8.3, e.g. the execution depicted in Fig. 8.4. It may be easily veriﬁed that this
inequality is ensured by every execution permitting the sequentially consistence of
memory. Later, an execution of this system, violating this inequality will be shown.
Seventh, the sequential consistency of memory facilitates programming as well
as makes easier reasoning on program correctness, since it simulates, in a sense,
programming on a centralized multiprocessor system. However it impairs perfor-
mance, because serializing the R/W operations lowers degree of concurrency. This
is also a price of transparency—the important feature of distributed systems.
Eighth, The special case of the sequential consistency is the strict consistency.
An example of execution of the system shown in Fig. 8.3, is given in the diagram in
Fig. 8.5 and Table 8.3.
Here, every R-operation returns value of a variable updated by a W-operation
execution preceding—in the external time—execution of this R-operation (or the
initial value) with no update of this variable between these R and W operations.
Thus, no delay of W-operations or shifting line segments along the time axis is
needed, for the global serialization of the operations, which is always possible. One
of possible serialization (a global history) may look as R(b, 0)1, R(a, 0)2, W(y, 0)1,
W(a, 1)2, R(a, 1)1, R(b, 0)2, W(x, 1)1, W(b, 1)2. Notice that in case of sequential
consistency, every R-operation returns value of a variable updated by a
W-operation execution preceding—in the global history—execution of this
R-operation (or the initial value) with no update of this variable between (in this
interleaving) these R and W operations. So, as it has been already stated in
Sect. 8.2, the prepositions “preceding”, “between”, etc. may refer to (external) time
—in case of strict consistency or space (place in a sequence) in case of sequential
computer 1:    
computer 2:    
W(a,1)2
external Ɵme
R(a,0)2
R(b,0)2
W(b,1)2
R(b,0)1
W(y,0)1
R(a,1)1
W(x,1)1
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
Fig. 8.5 This run of the system allows for strict consistency of memory
200
8
Distributed Shared Memory

Table 8.3 Strictly consistent execution (unrealistic), thus also sequentially consistent
computer 1
computer 2
.......
0
0
a
a
b
0
b
0
y
x
.......
a := a+1;
b := b+1;
1
y := b;
x := a;
R(a,0)2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
R(b,0)1
y := b;
x := a;
.......
1
1
a
a
b
0
b
0
y
x
.......
a := a+1;
b := b+1;
2
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
W(y,0)1
0
W(a,1)2
y := b;
x := a;
.......
1
1
a
a
b
0
b
0
y
x
.......
a := a+1;
b := b+1;
3
0
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
R(a,1)1
R(b,0)2
y := b;
x := a;
.......
1
1
a
a
b
1
b
1
y
x
.......
a := a+1;
b := b+1;
4
0
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
1
W(b,1)2
8.3
Concurrency of Access Operations to Distributed …
201

consistency. They are ambiguous without speciﬁcation of a context in which they
are used, since the distributed systems have no common clock. Notice that in the
geometrical presentation, the strict consistency is possible if the line segments that
represent the R/W operations, can be arranged on the global time axis in the order
of their initiations. The effect of strict consistency is as if the update of all replicas
of a variable were performed instantly—entirely unrealistic!
In the individual histories of above executions, the W-segments and R-segments
are linearly ordered, so disjoint, but between executions in different histories, there
is no ﬁxed order—respective operations are concurrent. After the global (linear)
arrangement of all these segments in the order consistent with their occurrence in
the individual histories, every segment representing the readout of variable’s value,
must be preceded (in the global history) by a nearest segment representing write of
this value to this variable—if such exists. Such a linear arrangement of all the
segments, deﬁnes an admissible—for sequential consistency—interleaving of
individual histories. In the next example (Fig. 8.6 and Table 8.4), such arrangement
is not possible. The example demonstrates another execution of the system shown
in Fig. 8.3. This execution violates sequential consistency of memory.
The sequential inconsistency results here from violating program order of
complete execution of operations by computer 2: termination of W(a, 1)2 follows
termination of W(b, 1)2. In the geometric setting—segments of both processes
cannot be arranged into an order such that respective operations executed in this
order would yield the same result as in Fig. 8.6. Before completion of W(a, 1)2,
operations R(b, 0)2 and W(b, 1)2 are being executed (a pipelining). It may happen
due to violation of conditions (1–3) in Sect. 8.2—since subsystems managing
memory run concurrently with application programs. In such case the system from
Fig. 8.3 may behave as shows Fig. 8.6 and respective Table 8.4 where the double
line grey arrows represent data transmission. In effect x = 0, y = 1 holds, what
cannot be obtained by whichever execution of the system satisfying sequential
consistency. This is so, since the R(a, 0)1 would have to be executed in external
time before W(a, 1)2 and the R(b, 1)1 after W(b, 1)2—like in the sequence, R(a, 0)2
R(a, 0)1 W(a, 1)2 R(b, 0)2 W(b, 1)2 R(b, 1)1 W(y, 1)1 W(x, 0)1, which is not an
interleaving of local histories, because R(a, 0)1 cannot precede R(b, 1)1.
computer 1:    
computer 2:    
W(a,1)2
external time
R(a,0)2
R(b,0)2
W(b,1)2
R(b,1)1
W(y,1)1
R(a,0)1
W(x,0)1
(
)
)
)
( (
(
)
(
)
)
(
(
)
(
)
Fig. 8.6 Here, the complete update of variable a by computer 2 is delayed because of
transmission duration. Does not allow for sequential consistency
202
8
Distributed Shared Memory

Table 8.4 Computer 2 after computation of a + 1 commits the subsystem managing memory
access to execute W(a, 1)2 and passes to execution of b := b + 1. The subsystem will complete W
(b, 1)2 ﬁrst, then W(a, 1)2, changing ordering of these write operations in the program. Violation of
the global FIFO order of message reception took place (Sect. 5.4 in Chap. 5). End of sequentially
inconsistent execution of the system from Fig. 8.3, presented geometrically in Fig. 8.6
computer 1
computer 2
0
0
a
a
b
0
b
0
y
x
a := a+1;
b := b+1;
1
y := b;
x := a;
R(a,0)2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
y := b;
x := a;
1
0
a
a
b
0
b
0
y
x
a := a+1;
b := b+1;
2
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
W(a,1)2
W(a,1)2
y := b;
x := a;
1
0
a
a
b
0
b
0
y
x
a := a+1;
b := b+1;
3
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
R(b,0)2
W(a,1)2
y := b;
x := a;
1
0
a
a
b
0
b
1
y
x
a := a+1;
b := b+1;
4
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
W(b,1)2
W(a,1)2
W(b,1)2
(continued)
8.3
Concurrency of Access Operations to Distributed …
203

y := b;
x := a;
1
0
a
a
b
1
b
1
y
x
5
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
a := a+1;
b := b+1;
R(b,1)1
W(a,1)2
W(b,1)2
y := b;
x := a;
1
0
a
a
b
1
b
1
y
x
6
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
a := a+1;
b := b+1;
W(y,1)1
1
W(a,1)2
y := b;
x := a;
1
0
a
a
b
1
b
1
y
x
7
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
a := a+1;
b := b+1;
R(a,0)1
1
W(a,1)2
y := b;
x := a;
1
1
a
a
b
1
b
1
y
x
8
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
a := a+1;
b := b+1;
1
W(x,1)1
0
W(a,1)2
Table 8.4 (continued)
204
8
Distributed Shared Memory

Geometrically, obtainment of sequential consistency, if possible, consists in
dislocation of R and W segments along the time axis, with preserving
memory coherence so that following this transformation, the overlapping
segments become disjoint.
A different geometrical presentation of system execution is obtained if the end of
W-segment, is understood as acknowledgment of performing respective update by
subsystems managing memory access—not as completion of updating all replicas
of a variable. So, in the successive examples, the beginning of a segment, means a
request (invocation) of respective operation, and the end means acknowledgment of
realization—in case of the write, and return (fetch) of value—in case of the read.
Between the invocation and the acknowledgment or fetch, the activity of a given
process is suspended. Under such understanding, the segments in every history are
disjoint. The invocation of write entails the broadcast of a variable’s value to all its
replicas and this value reaches them usually at different moments. Having ordered
the broadcast, a processor continues activity, while the subsystem managing
memory access acknowledges this order and is realizing it. For instance, when the
end of the write segment is understood as acknowledgment of realization, then the
diagram in Fig. 8.6 is replaced with that in Fig. 8.7, but concerns the same beha-
viour shown in Table 8.4. In this sense both geometric representations are equiv-
alent. Differentiation of the two ways of understanding the end of W-segments
changes only geometric representation of behaviour.
Two remarks on different geometric representations of memory usage during the
same execution of a system are appropriate.
Remark 1 In the representation with invocation and acknowledgment of per-
forming respective update as in Fig. 8.7, the segments could be reduced (“shrunk”)
to points labelled with respective operations, giving the same information on
memory consistency/inconsistency of a given execution.
Remark 2 The double arrows pointing to instants of the write completion, provide
excessive information in temporal diagrams presenting memory consistency/in-
consistency of a given execution. For this aspect, unimportant is exact moment of
data delivery, but only its temporal relationship to a moment of readout of this data.
This is visualized in Fig. 8.7, by a position of value delivery by W(a, 1)2 onto axis
of computer 1, relative to position of R(a, 0)1 on this axis.
In examples that follow, diagrams with invocation and acknowledgment will be
used and also—for conspicuity—double grey arrows pointing to instants of the
write completion.
Now, let us demonstrate behaviours of other (than shown in Fig. 8.3) systems, in
the aspect of memory sequential consistency/inconsistency. First, let us consider
extremely simple system shown in Fig. 8.8 and its execution in Fig. 8.9 with initial
values of variables a = 0, b = 0; the readout of the variable’s value, makes
immediate sending it to print.
8.3
Concurrency of Access Operations to Distributed …
205

Impossible is global serialization of segments with preserving the order of
execution in individual programs and memory coherence, with equivalent execution
result, i.e. with a = 1, b = 1 in memory and printout a = 0, b = 0. Indeed, the
segment R(b, 0)1 in such sequence would have to precede W(b, 1)2, and the segment
R(a, 0)2 would have to precede W(a, 1)1 as, for instance, in a sequence: R(b, 0)1
W(b, 1)2 R(a, 0)2 W(a, 1)1 or R(a, 0)2 W(a, 1)1 R(b, 0)1 W(b, 1)2, that violate the
order of execution in the local histories. Thus, sequential consistency is impossible.
This diagram accounts for execution shown as a sequence of states in the Table 8.5.
Let us modify the previous execution, replacing R(b, 0)1 with R(b, 1)1 with the
same assumptions. So, the execution diagram is as in Fig. 8.10.
The sequential consistency could be ensured: a permissible interleaving exists:
W b; 1
ð
Þ2 R a; 0
ð
Þ2 W a; 1
ð
Þ1 R b; 1
ð
Þ1
This sequence preserves the order of operations in local histories and memory
coherence. The result is the same as in the concurrent execution illustrated by the
diagram in Fig. 8.10, that is, a = 1, b = 1 in memory and a = 0, b = 1 on the
printout. The subsystems managing memory access have set all operations
R(a,0)2
W(a,1)2
R(b,0)2
W(b,1)2
R(b,1)1
W(y,1)1
R(a,0)1
W(x,0)1
external time
computer 1
computer 2
invocation and broadcast
acknowledgment
(
)
) (
(
(
(
(
)
)
)
)
(
)
()
delivery
Fig. 8.7 Different meaning of the end of W-segments than in Fig. 8.6. No interleaving of the local
histories exists without violation of operations order in processes or memory coherence. The
double line grey arrows in Fig. 8.7 point to instants (in external time) of updating replicas of a and
b in the memory of computer 1
computer 1 performs:             computer 2 performs:
a := 1;                                      b := 1;  
print(b);                                  print(a); 
Fig. 8.8 Extremely simple system
W(b,1)2
R(a,0)2
W(a,1)1
R(b,0)1
external time
computer 1
computer 2
(
)
(
(
)
)
)
(
Fig. 8.9 Sequentially inconsistent execution: local histories cannot be interleaved preserving
memory coherence
206
8
Distributed Shared Memory

Table 8.5 Sequentially inconsistent execution of the system from Fig. 8.8, presented geomet-
rically in Fig. 8.9
.......
1
a
a
.......
1
a := 1;
print(b)
b := 1;
print(a)
0
0
b
1
b
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
W(a,1)1
W(b,1)2
.......
1
a
a
.......
2
a := 1;
print(b)
b := 1;
print(a)
0
0
b
1
b
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
R(a,0)2
R(b,0)1
.......
1
a
a
.......
3
a := 1;
print(b)
1
0
b
1
b
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
b := 1;
print(a)
.......
1
a
a
.......
4
a := 1;
print(b)
1
1
b
1
b
computer 1
computer 2
D I S T R I B U T E D
S H A R E D
M E M O R Y
subsystem managing
memory access
subsystem managing
memory access
b := 1;
print(a)
8.3
Concurrency of Access Operations to Distributed …
207

sequentially, by delaying operations of computer 1, so that they be performed after
operations of computer 2. Geometrically, the segments of computer 1 have been
shifted rightwards along the external time axis. The local histories have been
interleaved preserving memory coherence. The execution shown in Fig. 8.10
cannot ensure the strict consistency: setting all operations sequentially in the order
of their execution in external time, thus W(a, 1)1 W(b, 1)2 R(b, 1)1 R(a, 0)2, violates
the memory coherence. After having written value 1 to variable a by computer 1,
the computer 2 would return value 0.
Let us modify again the previous execution, replacing R(a, 0)2 with R(a, 1)2. So,
the execution diagram is now as in Fig. 8.11.
The strict consistency (thus the sequential too) is possible: every readout of
variables returns values previously (in external time) assigned to them and the R/W
operations can be arranged into the sequence preserving their order in individual
programs without their delay:
W a; 1
ð
Þ1 W b; 1
ð
Þ2 R b; 1
ð
Þ1 R a; 1
ð
Þ2
The result is the same as in the concurrent execution illustrated by the diagram,
that is, a = 1, b = 1 in memory and on the printout.
Remark In the Tables presenting execution of exemplary concurrent sys-
tems as sequences of states, two ways of access to memory have been
applied: the remote access (Table 8.1) and replication of variables, that is
multiplication of their location (Tables 8.2, 8.3, 8.4 and 8.5), perhaps by
using cache memory. Another way called a relocation is also being applied:
change of location of a variable in one computer into its location in another
computer. For instance, when the latter computer uses this variable fre-
quently. In presenting the principles, such details are neglected.
W(b,1)2
R(a,0)2
W(a,1)1
R(b,1)1
external time
computer 1
computer 2
(
)
(
(
)
)
)
(
Fig. 8.10 Sequentially consistent execution: local histories can be interleaved preserving memory
coherence, but shifting segments of operations is necessary
W(b,1)2
R(a,1)2
W(a,1)1
R(b,1)1
external time
computer 1
computer 2
(
)
(
(
)
)
)
(
Fig. 8.11 Strictly consistent execution: local histories can be interleaved preserving memory
coherence without shifting the segments of operations
208
8
Distributed Shared Memory

Sequential and strict consistency or their inexistence for some executions of a
system, may appear also when access to one variable only takes place. The fol-
lowing examples illustrate such phenomena.
Let us consider possible behaviours of the system in Fig. 8.12 and its execution
in Fig. 8.13.
Suppose that the constants a and b are distinct, the initial value of variable x is
neither a nor b, and let readout of x make immediate sending its value to print. For
instance, execution of R(x, b)3 makes immediate printout of b by computer 3. As in
the former examples, the beginning of a segment representing an access operation
means request (invocation) of its execution, whereas the end represents acknowl-
edgment of the write and return of the readout value. The segments in each history
are, then, disjoint. Consider the execution diagram in Fig. 8.13 where, as formerly,
the double line grey arrows point to possible instants of update of replicas of x in
individual computers. This diagram accounts for execution shown as a sequence of
states in the Table 8.6.
It is seen that here impossible is the global serialization of segments by shifting
them along the time axis, so that the order of execution in individual programs and
memory coherence be retained. The result of executing the system in such order
should be the same as in Fig. 8.13, that is, the computer 3 should print ba, while
computer 4 – ab. Notice that the operations on memory are not indivisible
(atomic): before complete updating replicas of variable x in all computers by a
certain write operation, some other write operations are being executed changing
…..........
print(x); 
…..........
print(x);
…..........
computer 1 performs:
…........
x := α;
…........
…........
x := β;
…........
…..........
print(x); 
…..........
print(x);
…..........
computer 2 performs:
computer 3 performs:
computer 4 performs:
Fig. 8.12 System with one shared variable x
W(x,α)1
computer 1:
computer 2:
computer 3:
R(x,β)3
W(x,β)2
R(x,α)4
external time
R(x,α)3
R(x,β)4
computer 4:
(
)
(
)
(
)
(
)
(
)
)
(
Fig. 8.13 Sequentially inconsistent execution: local histories cannot be interleaved preserving
memory coherence
8.3
Concurrency of Access Operations to Distributed …
209

result of the former update. Therefore, without suspension of W-operations when
only one of them is being executed, not all the variable’s replicas must assume the
same value: the memory incoherence occurs. The execution shown in Fig. 8.13 is
presented in the Table 8.6 as a sequence of the system states.
Let us modify the diagram in Fig. 8.13, by replacing R(x, b)4 with R(x, a)4, thus
changing the instant of the second update of x in computer 4 e.g. as follows
(Fig. 8.14).
The sequential consistency could be ensured: a permissible interleaving exists:
Wðx; bÞ2 Rðx; bÞ3 Wðx; aÞ1 Rðx; aÞ4 Rðx; aÞ3 Rðx; aÞ4
This interleaving ensures memory coherence, since the order of R/W operations
is as in the programs and the same result is (memory content and print-outs) as
shown on the diagram in Fig. 8.14. However, the execution as on the diagram, does
not allow for the strict consistency, since arranging the segments in the order of
their appearing on the time axis, i.e. W(x, a)1 W(x, b)2 R(x, b)3 R(x, a)4 R(x, a)3
R(x, a)4, violates the memory coherence: between W(x, a)1 and R(x, a)4, the
W(x, b)2 occurs.
8.4
Events of Initiations and Terminations of Read/Write
Operations
Every access to memory lasts a certain time, which is unknown when nonlocal
memory is being accessed, that is when a remote data transmission is required. This
indeﬁniteness results from impossibility of predicting the transmission duration,
especially when many data replicas are being updated. Suspension of the data
access at each their update, lowers the system efﬁciency, but fulﬁls user’s expec-
tations, that his/her programs behave as if executed by computer with local memory
only. In particular, that the order of read/write memory operations is such as
speciﬁed by his/her program. Not important for the user is, however, the order
between execution of memory operations by different programs run concurrently
with his/her program, if memory coherence is preserved. This expectation is
W(x,α)1
computer 1:
computer 2:
computer 3:
R(x,β)3
W(x,β)2
R(x,α)4
external time
R(x,α)3
R(x,α)4
computer 4:
(
)
(
)
(
)
(
)
(
)
)
(
Fig. 8.14 Sequentially consistent execution: local histories can be interleaved preserving memory
coherence, but shifting segments of operations is necessary
210
8
Distributed Shared Memory

Table 8.6 Sequentially inconsistent execution of the system from Fig. 8.8, presented geomet-
rically in Fig. 8.13
D
I
S
T
R
I
B
U
T
E
D
S
H
A
R
E
D
M
E
M
O
R
Y
subsystem managing
memory access
x:=α
x:=β
print(x);…print(x)
x
x
x
x
α
print(x);…print(x)
computer 1
computer 2
computer 4
computer 3
subsystem managing
memory access
subsystem managing
memory access
subsystem managing
memory access
state 1
x:=α
x:=β
x
x
x
x
α
state 2
α
α
D
I
S
T
R
I
B
U
T
E
D
S
H
A
R
E
D
M
E
M
O
R
Y
subsystem managing
memory access
print(x);…print(x)
print(x);…print(x)
computer 1
computer 2
computer 4
computer 3
subsystem managing
memory access
subsystem managing
memory access
subsystem managing
memory access
x:=α
x:=β
x
x
x
x
α
state 3
β
α
D
I
S
T
R
I
B
U
T
E
D
S
H
A
R
E
D
M
E
M
O
R
Y
subsystem managing
memory access
print(x);…print(x)
print(x);…print(x)
computer 1
computer 2
computer 4
computer 3
subsystem managing
memory access
subsystem managing
memory access
subsystem managing
memory access
x:=α
x:=β
x
x
x
x
β
state 4
β
β
α
D
I
S
T
R
I
B
U
T
E
D
S
H
A
R
E
D
M
E
M
O
R
Y
subsystem managing
memory access
print(x);…print(x)
print(x);…print(x)
computer 1
computer 2
computer 4
computer 3
subsystem managing
memory access
subsystem managing
memory access
subsystem managing
memory access
x:=α
x:=β
x
x
x
x
β
β
α
state 5
α
D
I
S
T
R
I
B
U
T
E
D
S
H
A
R
E
D
M
E
M
O
R
Y
subsystem managing
memory access
print(x);…print(x)
print(x);…print(x)
computer 1
computer 2
computer 4
computer 3
subsystem managing
memory access
subsystem managing
memory access
subsystem managing
memory access
x:=α
x:=β
x
x
x
x
β
state 6
β
β
α
D
I
S
T
R
I
B
U
T
E
D
S
H
A
R
E
D
M
E
M
O
R
Y
subsystem managing
memory access
print(x);…print(x)
print(x);…print(x)
computer 1
computer 2
computer 4
computer 3
subsystem managing
memory access
subsystem managing
memory access
subsystem managing
memory access
8.4
Events of Initiations and Terminations of Read/Write Operations
211

satisﬁed by the sequential consistency, the most natural feature for the programmer.
It was seen in the previous examples that not for each concurrent execution, i.e. the
partial order of memory operations, their linear ordering is possible without res-
ignation from memory coherence and change of computation outcome (this is the
task of protocols assuring sequential consistency to prevent execution of such kind).
Therefore, the indeﬁnite time duration of memory operations (their „coarse gran-
ulation”) makes impossible exact description of arbitrary concurrent execution by
means of interleaving of sequences of these operations, especially description of
various kinds of memory consistency. The interleavings not always exist due to the
write operations long-drawn-out in time—their overlapping, even in the same
process (see Fig. 8.6). That is why the initiations and terminations of read/write
operations will be treated as the elementary events, i.e. indivisible—atomic
(„timeless”). With such „ﬁne granularity” of events concerning memory, all such
events may be ordered into global sequences, therefore being arranged in the linear
(total) order. Each execution is, then, represented by a sequence of events. In
distinct sequences representing the same execution, the concurrent (independent)
events may occur in reverse order – concurrency is modelled by nondeterminism.
Such abstraction allows for describing consistency models without referring to
terms like „process sees”, so, without metaphoric expressions—intuitive comments
to deﬁnitions of various types of consistency.
The following assumptions and denotations are admitted:
(1) The readout initiation of value a of variable x by computer j = 1, 2, …, N is
denoted by R x; a
ð
Þj and termination—by R x; a
ð
Þj and similarly for write:
W x; a
ð
Þj and W x; a
ð
Þj Events R x; a
ð
Þj, W x; a
ð
Þj are invocations of the opera-
tions. Event R x; a
ð
Þj is understood as fetching (return) value a of variable x from
memory, and W x; a
ð
Þj—as end of writing value a, to all replicas of x. Any
computer terminates readout or write-in a variable with the same value as has
initiated, but another computer may change this value, between begin and end of
this operation. For instance, it may happen that in a certain temporal sequence of
events, the following fragment appears: R x; b
ð
Þk R x; a
ð
Þj W x; a
ð
Þj R x; b
ð
Þk with
b 6¼ a, k 6¼ j. Memory coherence is violated: computer k reads different value of
variable x than was completely updated by computer j, thus sequential consis-
tency violation took place. The sequential inconsistency may also appear, when
in a given program, before termination of an operation, another operation is
starting. This is possible, since the subsystems managing memory access may
run concurrently with program statements.
(2) Sequencing of initiations and terminations of read and write (their lineariza-
tion) is accomplished by subsystems managing memory access. The initiation
of an operation must precede its termination in each sequence. Such theoretical
model clearly exhibits arrangement of access operations on the external (global)
time axis.
212
8
Distributed Shared Memory

As an example, consider the execution of system shown in Fig. 8.12, its exe-
cution in the former model shown in Fig. 8.13 and now in the model with events of
initiations (invocations) and terminations of memory operations, i.e. where
W x; a
ð
Þ1 W x; b
ð
Þ2 denote respectively, complete updates of variable’s x value in
all of its replicas, what is depicted in Fig. 8.15.
The events of read/write initiation and termination, have occurred in the fol-
lowing order (in accordance with the external time):
W x; a
ð
Þ1 W x; b
ð
Þ2 R x; b
ð
Þ3 R x; b
ð
Þ3 R x; a
ð
Þ4 W x; a
ð
Þ1 R x; a
ð
Þ4 W x; b
ð
Þ2
R x; b
ð
Þ4 R x; a
ð
Þ3 R x; b
ð
Þ4 R x; a
ð
Þ3
A permutation of this sequence, such that every read/write termination appears
next to respective initiation, yields the following sequence:
W x; a
ð
Þ1W x; a
ð
Þ1
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
W x;a
ð
Þ1
W x; b
ð
Þ2W x; b
ð
Þ2
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
W x; b
ð
Þ2
R x; b
ð
Þ3R x; b
ð
Þ3
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; b
ð
Þ3
R x; a
ð
Þ4R x; a
ð
Þ4
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; a
ð
Þ4
R x; b
ð
Þ4R x; b
ð
Þ4
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; b
ð
Þ4
R x; a
ð
Þ3R x; a
ð
Þ3
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; a
ð
Þ3
It is seen that neither this permutation nor any other, satisﬁes the two require-
ments of sequential consistency, i.e. memory coherence and the order of events
compatible with their order in individual programs. Sequential inconsistency of the
execution shown on the diagram in Fig. 8.15 follows from inexistence of such
permutation. But let us modify the diagram, by replacing events R x; b
ð
Þ4 and
R x; b
ð
Þ4 with R x; a
ð
Þ4 and R x; a
ð
Þ4, thus changing the instant of second update of
x in computer 4 as on the diagram in Fig. 8.16.
computer 1:
computer 2:
computer 3:
R(x,β)3
R(x,α)4
external time
computer 4:
(
)
)
W(x,α)1
(
)
W(x,α)1
W(x,β)2
W(x,β)2
R(x,β)3
R(x,α)4
(
)
R(x,α)3
(
R(x,α)3)
R(x,β)4
R(x,β)4
(
)
(
Fig. 8.15 The left and right brackets represent respectively, the instants of initiation and complete
termination of the R/W operations in external time. Sequentially inconsistent execution, thus
impermissible by the subsystem managing memory access
8.4
Events of Initiations and Terminations of Read/Write Operations
213

Now, the events of read/write initiation and termination, have occurred in the
order:
W x; a
ð
Þ1 W x; b
ð
Þ2 R x; b
ð
Þ3 R x; b
ð
Þ3 R x; a
ð
Þ4 W x; a
ð
Þ1 R x; a
ð
Þ4
R x; a
ð
Þ4 R x; a
ð
Þ3 R x; a
ð
Þ4 R x; a
ð
Þ3 W x; b
ð
Þ2
A permutation of this sequence, such that every read/write termination appears
next to respective initiation, yields the following sequence:
W x; b
ð
Þ2W x; b
ð
Þ2
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
W x; b
ð
Þ2
R x; b
ð
Þ3R x; b
ð
Þ3
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; b
ð
Þ3
W x; a
ð
Þ1W x; a
ð
Þ1
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
W x; a
ð
Þ1
R x; a
ð
Þ4R x; a
ð
Þ4
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; a
ð
Þ4
R x; a
ð
Þ4R x; a
ð
Þ4
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; a
ð
Þ4
R x; a
ð
Þ3R x; a
ð
Þ3
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
R x; a
ð
Þ3
It is seen that this permutation satisﬁes the two requirements of sequential
consistency, i.e. memory coherence and the ordering of events compatible with
their order in individual programs. The sequential consistency of the execution
shown on the diagram follows from existence of such permutation. Therefore,
sequential consistency of this execution is equivalent to existence of such permu-
tation. Later it will be shown in general, that existence of a suitable permutation of a
sequence of the read/write initiations and terminations generated by a concurrent
execution, is the necessary and sufﬁcient condition for sequential consistency of this
execution.
Remarks
1. In implementing protocols for sequential consistency, doing permutations
as above, entails enforcement of R/W operations to be indivisible.
2. Taking events of initiations and terminations of R/W operations as ele-
ments of a certain alphabet, it is seen that their sequences (i.e. as exe-
cutions of a system) are words in this alphabet, and behaviour (semantics)
of the system is a formal language. In such approach, protocols ensuring
computer 1:
computer 2:
computer 3:
R(x,β)3
R(x,α)4
external time
computer 4:
(
)
)
W(x,α)1
(
)
W(x,α)1
W(x,β)2
W(x,β)2
R(x,β)3
R(x,α)4
(
)
R(x,α)3
(
R(x,α)3)
R(x,α)4
R(x,α)4
(
)
(
Fig. 8.16 Sequentially consistent execution
214
8
Distributed Shared Memory

various models of memory consistency may be treated as generators of
formal languages. The model of parallel systems as formal languages over
this alphabet may be used for analysis of some semantic properties of
systems. In particular, for decision problems of mutual exclusion, dead-
lock and starvation. In Czaja (1980, 2012) the problems have been
reduced to decision problems of emptiness, and inﬁniteness of certain
formal languages over invocations and terminations of actions.
8.5
Formal Deﬁnitions of Sequential and Strict
Consistency
Representing of a real (concurrent) execution of a system as a sequence of points
(not as segments) on the external time axis, i.e. as events R x; a
ð
Þk, R x; a
ð
Þk,
W x; a
ð
Þk, W x; a
ð
Þk, makes possible selection from among all the sequences, only
those that meet requirements of sequential and strict consistency, provided such
exist. To this end, for a given sequence representing a concurrent execution, it
should be decided whether or not there exists a permutation of this sequence
satisfying conditions of a desired consistency model. If it does not exist then the
execution is refused, but if it exists—entire (complete) R/W operations are executed
in the order of their occurrence in the sequence suitably permuted.
Let us admit the following denotations:
(1) S = {P1, P2, …, PN}—a system of sequential programs with DSM, per-
forming in parallel by computers numbered 1, 2, …, N.
(2) V—set of variables used by the programs and allocated in DSM.
(3) D—set of values, the variables may assume.
(4) E is the set of events W x; a
ð
Þk, W x; a
ð
Þk, R x; a
ð
Þk, R x; a
ð
Þk with x 2 V,
a 2 D, k 2 {1, 2, …, N}; this is the set of all events of initiations and complete
terminations of R/W operations that may occur during activity of the system S.
(5) Q = q1 q2… qn 2 E* is a sequence simulating parallel activity of the system
S, if every event W x; a
ð
Þk and R x; a
ð
Þk occurring in Q is preceded, not necessarily
directly, by respective W x; a
ð
Þk and R x; a
ð
Þk in this sequence called a global
history of S. If, for every W x; a
ð
Þk and R x; a
ð
Þk exist respective W x; a
ð
Þk and
R x; a
ð
Þk farther in Q, then Q is called closed, relative to the memory access
operations. E* denotes the set of all ﬁnite sequences of events from E.
Now, we are in a position to formally deﬁne the principle of sequential and strict
consistency:
8.4
Events of Initiations and Terminations of Read/Write Operations
215

A global history Q = q1 q2… qn fulﬁls the property of sequential consistency if
Q is closed and there exists a permutation p(Q) = qp(1)qp(2)…qp(n) (precisely, p is a
permutation of the sequence 1, 2, …, n) such that:
(i)
If event W x; a
ð
Þk or R x; a
ð
Þk occurs in p(Q), then it is preceded adjacently
by respective W x; a
ð
Þk or R x; a
ð
Þk. This means that between initiation and
termination of access to a variable, no other access operation to this variable
occurs.
(ii)
Events W x; a
ð
Þk and R x; a
ð
Þk occur in the sequence p(Q) in the same order
as in the local history of program Pk; by virtue of (i), operations W(x, a)k and
R(x, a)k are performed in the system S in the same order as in the program
Pk.
(iii)
If an event R x; a
ð
Þk occurs in p(Q) then a is an initial value or this event is
preceded in the sequence p(Q) by a certain event W x; a
ð
Þj with no event
W x; b
ð
Þi inbetween, where b 6¼ a, j, i = 1, 2, …, N.
The system S obeys the principle of sequential consistency of DSM if and only if
S admits only global histories Q fulﬁlling the property of sequential consistency. In
short: the memory managed by S is sequentially consistent.
The strict consistency is obtained if (i), (ii), (iii) are satisﬁed and if events
W x; a
ð
Þk occur in p(Q) in the same order as in Q.
Remarks
1. The global history Q = q1 q2… qn 2 E* uniquely determines the memory
state (content) and printouts yielded by Q. The memory state is a set of
pairs r[Q] = {〈x, a〉: x 2 V, a 2 D}, thus a relation r[Q]  V  D (see
Chap. 10). If for each closed Q, the relation r[Q] is a function
8 x 2 V, a, b 2 D:
(x, a) 2 r[Q] ^ (x, b) 2 r[Q] ) a = b,
meaning
that values of all replicas of each variable are identical), then the memory
is coherent. Sequentially consistent memory is coherent. Memory inco-
herence (lack of memory integrity) arises e.g. in effect of parallel exe-
cution shown in Fig. 8.15. The execution yields the DSM content: in
memory of computers 1, 2, 4 the value of x is b and of computer 3 is a
(see also Table 8.6). The DSM state is then r[Q] = {〈x, a〉,〈x, b〉}, which
is not a function.
2. It is known that in general a decision whether or not a given ﬁnite exe-
cution fulﬁls the sequential consistency property is algorithmically very
complex (called “intractable”). This is evident in the model presented
here: a search for a permutation satisfying (i), (ii), (iii) is required. A good
many research tackled this task with the same answer, if not additional
information has been supplied about the system behaviour. Some exam-
ples of this research are in (Gibbons and Korach 1992; Cantin et al. 2005;
Hu et al. 2011).
216
8
Distributed Shared Memory

3. Sequential and especially strict consistency, though lessens performance
of the system, brings nearer the DSM mechanism to a multiprocessor
system endowed with one physical shared memory of direct access.
Applications where efﬁciency is more crucial than preservation of some
execution order in individual programs, may tolerate more liberal models
than sequential consistency, the natural model for users. Some of such
models will be considered in the next Section.
4. From the formal point of view, the collection of variables in the DSM is a
multiset, that is a function Rep: V ! N (N–set of natural numbers),
where Rep(x) is the number of replicas of x in the local memories. For
instance, in the execution in Fig. 8.5 and Table 8.3 in Sect. 3: V = {a, b,
x, y}, Rep(a) = 2, Rep(b) = 2, Rep(x) = 1, Rep(y) = 1.
8.6
Some Other Models of Memory Consistency
Sequential and strict memory consistency models so far considered, permit to use
programs written for multiprocessor systems with a physical memory (RAM),
common to all processors. Implementation of strict consistency makes system
performance of unacceptably low level. Implementation of sequential consistency
is, in this respect, more acceptable, however also lowers considerably efﬁciency,
compared with multiprocessor systems. Its important property is preservation of the
order of access to memory operations speciﬁed in individual programs, the feature
natural for the users. Applications in which performance is more important than
such preservation, may tolerate weaker, more liberal consistency models in cases
where order of some actions, determined by individual programs, is inessential for
the main objective and outcome of the whole parallel program. Two examples of
such more liberal models are formally deﬁned in the next subsections.
8.6.1
Causal Consistency (Hutto and Ahamad 1990)
In any execution, if effect of an update (write) operation depends on another update
(in the same or different process and of the same or different variable), then in every
process, the temporal order of readouts of the updated variables should be the same
as the temporal order of these updates. This can be formalized as follows (deno-
tation of symbols is as in Sect. 8.5). First, let us deﬁne a relation of causal
dependency in the set of events: ⇝ E  E. For events
p, q 2 E two auxiliary primary relations !
process and !
readout are admitted:
8.5
Formal Deﬁnitions of Sequential and Strict Consistency
217

1. If p precedes q in the same process (in a local history) then p !
process q (see
Sect. 4.2)
2. If event q ¼ R x; a
ð
Þj terminates reading value a of variable x and a was
assigned to x by a write operation completed with event p = W x; a
ð
Þj then
p !
readout q
Second, causal dependency ⇝is deﬁned as the least (wrt. ) relation such that:
(i) if p !
process q or p !
readout q then p ⇝q
(ii) if p ⇝q and q ⇝r then p ⇝r
If p ⇝q then p is a cause of q and q is an effect of p. The events are independent
if neither p ⇝q nor q ⇝p, written p ∥q.
Let R be the set of events R(x, a)j and W the set of events W(x, a)j, j 2{1, 2, …,
N}, x 2 V, a 2 D. Let Q = q1 q2… qn 2 E* be a closed history of execution of the
system S. Q is causally consistent iff for any qi, qj 2 W in Q with qi ⇝qj, and for
any qk, ql 2 R in Q, the following holds: if qk!
processq1 (qk and ql are in the same
process without specifying their order, i.e. qk !
process ql , qk !
process ql _ ql !
process qk)
and qi !
readout qk and qj !
readout ql then qk !
process ql; but if for some qi, qj 2 W, qk, ql 2
R
in
Q,
the
relations
qi
⇝
qj,
qi
!
readout
qk
and
qj
!
readout
ql,
ql !
process qk hold then Q is causally inconsistent. In symbols:
8qi; qj 2 W ½qi  qj ) 8qk; ql 2 R ððqk !
process ql ^ qi !
readout qk ^ qj !
readout qlÞ
) qk !
process qlÞ
The system S obeys the principle of causal consistency of DSM iff S admits only
global causally consistent histories Q. In short: the memory managed by S is
causally consistent.
Example. Let
Q ¼ Wðx; 9Þ1
|ﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄ}
q1
. . . Rðx; 9Þ2
|ﬄﬄﬄﬄ{zﬄﬄﬄﬄ}
q2
. . . Wðy; 3Þ2
|ﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄ}
q3
. . . Rðx; 9Þ3
|ﬄﬄﬄﬄ{zﬄﬄﬄﬄ}
q4
. . . Rðy; 3Þ3
|ﬄﬄﬄﬄ{zﬄﬄﬄﬄ}
q5
. . . Rðy; 3Þ4
|ﬄﬄﬄﬄ{zﬄﬄﬄﬄ}
q6
. . . Rðx; 9Þ4
|ﬄﬄﬄﬄ{zﬄﬄﬄﬄ}
q7
The underlines of symbols denoting terminations of R/W operations are omitted.
This causally inconsistent execution is presented graphically in Fig. 8.17. By
deﬁnition of causality the relation q1 ⇝q3 holds. For instance, suppose that process
P2 after having read value 9 of variable x, computes
ﬃﬃﬃ
9
2p
and writes 3 to variable
y. Also by deﬁnition of causality, the relations q1!
readout q7, q3!
readout q6, q6!
process q7
are fulﬁlled, which means that execution Q is causally inconsistent.
Conditions for causal consistency/inconsistency of this execution may be
schematically presented by diagrams in Fig. 8.18, where the zigzag line denotes the
causality relation.
218
8
Distributed Shared Memory

8.6.2
PRAM (Pipelined Random Access Memory)
Consistency (Lipton and Sandberg 1988)
In any execution, if two update (W) operations are in the same process, then in
every process, the global time order of readouts (R) of these updated variables
should be the same as of the updates. This can be formalized as follows. Let Q = q1
q2… qn 2 E* be a closed history of execution of the system S. Q is PRAM-
consistent iff for any qi, qj 2 W in Q with qi !
process qj and for any qk, ql 2 R in Q, the
following holds: if qk !
process ql and qi !
readout qk and qj !
readout ql then qk !
process ql; but
if for some qi, qj 2 W, qk, ql 2 R in Q, the relations qi !
process qj,
qk !
process ql, qi !
readout qk, qj !
readout ql are fulﬁlled, then Q is PRAM-inconsistent. In
symbols:
8 qi; qj 2 W½qi !
process qj ) 8qk; ql 2 R ððqk !
process ql ^
qi !
readout qk ^ qj !
readout qlÞ ) qk !
process qlÞ
q1
q2
q3
q4
q5
q6
q7
process
process
process
1
2
3
4
readout
external time
Fig. 8.17 System of four computers with causally consistent memory would not permit for such
execution
q1
q3
q4
q5
readout
readout
process
q1
q3
q7
q6
readout
readout
process
(a)
(b)
Fig. 8.18 a Diagram of causally consistent execution … q1… q2… q3… q4… q5. b Diagram of
causally inconsistent execution … q1… q2… q3… q4… q5… q6… q7
8.6
Some Other Models of Memory Consistency
219

The system S obeys the principle of PRAM-consistency of DSM iff S admits
only global causally consistent histories Q. In short: the memory managed by S is
PRAM-consistent.
Conditions for PRAM-consistency/inconsistency of this execution may be
schematically presented by diagrams in Fig. 8.19.
Notice that causally consistent memory is PRAM-consistent (obviously the
formula
deﬁning
causal
consistency,
implies
the
formula
deﬁning
the
PRAM-consistency), but not conversely (e.g. inconsistent interleaving Q may be
PRAM-consistent, as shown in Fig. 8.17).
Remarks
1. The term “PRAM” is being used in the theory of computational complexity in a
different meaning than in case of memory consistency investigations. In the
theory of computational complexity, it is an abbreviation of “Parallel Random
Access Machine”, a certain formal model of parallel computation, for making
proofs of complexity of algorithms partitioned onto fragments concurrently
executed.
2. Notice that the concept of memory consistency depends on adopted model of
concurrent processing and what actions have been chosen as basic for this
concept. They have been chosen here as events of initiation and complete
termination of access to memory. In this model, the concurrency is being
modelled by indeterminism: the events may occur in various temporal order,
without inﬂuence on the outcome of programs’ activity, in particular on pre-
serving adopted kind of memory consistence. In such model, closest to reality of
distributed processing, the relationships between considered above kinds of
consistency models, are easily noticed: a strictly consistent memory is
sequentially consistent, which is causally consistent, which is PRAM-consistent.
Apart from the four kinds (models) of memory consistency presented above, a
number of others have been created, even less restrictive, some of them not being in
the hierarchy with just mentioned. They have been devised for particular applica-
tions, where discordance with the “natural” order (ensuing from arrangement of
actions in individual programs) of access to memory is permitted, in favour of
system better performance. Some of them may be mentioned:
qi
qj
qk
ql
readout
readout
process
qi
qj
qk
ql
readout
readout
process
process
process
(a)
(b)
Fig. 8.19 (a) PRAM-consistency (b) PRAM-inconsistency
220
8
Distributed Shared Memory

1. weak consistency
2. entry consistency
3. release consistency
4. scope consistency
5. process consistency
6. cache consistency
7. fork consistency
Models 1, 2, 3 require usage of some operations synchronizing access to
memory, by the user. This lessens the transparency feature of distributed system
and requires additional organization activities in programs, but improves perfor-
mance. This is not exhaustive list of possible models of DSM consistency,
implemented in various research institutions. Their extensive presentation would
exceed the scope of this book, as well as other books on distributed systems. This
may be found in original papers on the subject of construction of speciﬁc systems.
8.7
Exemplary Algorithms Realizing Memory Consistency
Depending on the user needs, the algorithms are divided into two classes called
fast-read and fast-write. Computers in the parallel systems, as before, are numbered
1, 2, …, N.
Denotations:
Mi
local memory of computer number i
Mi[x]
content of a cell assigned to variable x in Mi
Actions wait and signal denote suspension and resumption activity of a process.
The grey boxes contain procedures performing operations, respectively, of
reading, group communication (broadcast) and storing a value in memory. In the
curly brackets are comments.
8.6
Some Other Models of Memory Consistency
221

8.7.1
Algorithms for Sequential Consistency
Fast-read algorithm implementing sequential consistency for computer of
number i
{Execution of a read statement R(x, Mi[x])i in computer i}
Mi[x] ! Ai {transfer value Mi[x] from memory to a register Ai}
{Execution of a write statement W(x,)i in computer i}
a !
atomic
broadcast
Mj x½  to all computers of number j where x is located
{atomic, that is indivisible broadcast (exclusive, i.e. with suspended write
operations of other computers)};
wait {waiting for permission from subsystem managing memory access to
resume activity of computer i; the permission is issued when the broadcast is
completed}
{Storing value received from computer of number j in the cell assigned
to variable x in memory Mi with conditional permission to continue run of
computer i}
Mi[x] : = a;
if j = i then signal {resumes activity of computer i}
Fast-write algorithm implementing sequential consistency for computer
number i
Denotation: numi—counter of pending (unﬁnished) write operations; initially set
to 0. Meaning of this counter is illustrated in Fig. 8.20. The counter is needed when
computer of number i repeatedly requests for writing. Any request does not wait for
its completion, but may be succeeded by a next request, etc.
p1
p2
p3
p4
nump4 = 2  in this time instant
external time
nump4 = 1 in this time instant
Fig. 8.20 Grey circles represent send operations, blank circles—reception. This is a (global) FIFO
broadcast
222
8
Distributed Shared Memory

{Execution of the read statement R(x, Mi[x])i in computer i}
if numi 6¼ 0 then wait {makes computer i suspend until the “signal” event
comes};
Mi[x] ! Ai {transfer value Mi[x] from memory to a register Ai}
{Execution of the write statement W(x, a)i in computer i}
numi : = numi + 1;
a!
FIFOatomic
broadcast
Mj x½  to all computers of number j where x is
located {for the (global) FIFO and non-FIFO broadcast, see Figs. 5.6 and
5.7 in Chap. 5}
{Storing value a received from computer of number j, in a cell assigned to
variable x in memory Mi with conditional permission to resume run of
computer i}
Mi[x] : = a;
if j = i then begin numi : = numi−1;
if numi = 0 then signal {resumes activity of computer i}
end;
8.7.2
An Algorithm Implementing Causal Consistency
for Computer of Number i
Before presenting this algorithm, let us illustrate pictorially the meaning of causal
broadcast and not causal broadcast in Figs. 8.21 and 8.22 respectively.
8.7
Exemplary Algorithms Realizing Memory Consistency
223

{Execution of a read statement R(x, Mi[x])i in computer i}
Mi[x] ! Ai {transfer value Mi[x] from memory to a register Ai}
{Execution of a write statement W(x, a)i in computer i}
a !
causal
broadcast Mj[x] to all computers of number j where x is located;
{Conditional storing value a received from computer of number j in the
cell assigned to variable x in memory Mi}
if j 6¼ i then Mi[x] : = a
p1
p2
p3
p4
A
B
A
A
B
B
W(x,α)p4
R(x,α)p2
W(y,β)p2
R(y,β)p1
R(y,β)p3
R(y,β)p4
R(y,β)p2
R(x,α)p1
R(x,α)p3
R(x,α)p4
external time
B
A
Fig. 8.21 Causal broadcast; message B is causally dependent on message A: relation W(x, a)p4
⇝W(y, b)p2 is fulﬁlled, b = f(a), where f is a certain function
p1
p2
p3
p4
A
B
A
A
B
B
W(x,α)p4
R(x,α)p2
W(y,β)p2
R(y,β)p1
R(y,β)p3
R(y,β)p4
R(y,β)p2
R(x,α)p1
R(x,α)p3
R(x,α)p4
external time
B
A
Fig. 8.22 This is not a causal broadcast: relation W(x, a)p4 ⇝W(y, b)p2 is fulﬁlled, but R(x, a)p3
occurs later than R(y, b)p3
224
8
Distributed Shared Memory

8.7.3
An Algorithm Implementing PRAM Consistency
for Computer of Number i
{Execution of a read statement R(x, Mi[x])i in computer i}
Mi[x] ! Ai {transfer value Mi[x] from memory to a register Ai}
{Execution
of
a
write
statement
W(x,
a)i
in
computer
i}
a !
FIFO
broadcastMj[x] to all computers of number j where x is located;
{Conditional storing value a received from computer of number j in the
cell assigned to variable x in memory Mi}
if j 6¼ i then Mi[x] : = a
Remark The presented algorithms for sequential, causal and PRAM consistency
comprise outlines of activity performed by subsystems managing memory access.
References
Cantin, J. F., Lipasti, M. H., & Smith, J. E. (2005). The complexity of verifying memory
coherence and consistency. IEEE Transactions on Parallel and Distributed Systems, 16(7),
651–663.
Courtois, J., Heymans, F., & Parnas, D. L. (1971). Concurrent control with “Readers” and
“Writers”. Communication of the ACM, 14(10), 667–668.
Czaja, L. (1968). Organization of segment exchange in ALGOL for ZAM 21 ALFA and ZAM 41
ALFA computers. Algorytmy, 5(9), 77–84.
Czaja, L. (1980). Deadlock and fairness in parallel schemas: A set-theoretic characterization and
decision problems. Information Processing Letters, 10(4–5), 234–239.
Czaja,
L.
(2002).
Elementary
Cause-Effect
Structures.
Wydawnictwa
Uniwersytetu
Warszawskiego (Warsaw University Publisher).
Czaja, L. (2012). Exclusive access to resources in distributed shared memory architecture.
Fundamenta Informaticae, 119(3–4), 265–280.
Diekert, V., & Rozenberg, G. (Eds.). (1995). The book of traces. World Scientiﬁc Publishing Co.
Gibbons, P. B., & Korach, E. (1992). The Complexity of Sequential Consistency. In Parallel and
Distributed Processing, 1992. Proceedings of the Fourth IEEE Symposium (pp. 317–325).
Hoogeboom, H. J., & Rozenberg, G. (1995). Dependence graphs. In The book of traces.
Singapore: World Scientiﬁc.
Hu, W., Chen, Y., Chen, T., Qian, C., & Li, L. (2011). Linear time memory consistency
veriﬁcation. IEEE Transactions on Computers, 61(4), 502–516.
Hutto, P. W., & Ahamad, M. (1990). Slow memory: Weakening consistency to enhance
concurrency in distributed shared memories. In Distributed Computing Systems, 1990.
Proceedings, 10th International Conference IEEE (pp. 302–311).
8.7
Exemplary Algorithms Realizing Memory Consistency
225

Lamport L. (1979). How to make a multiprocessor computer that correctly executes multiprocess
programs. IEEE Transactions on Computers, 28, 690–691.
Li, K., & Hudak, P. (1989). Memory coherence in shared virtual memory systems. ACM
Transaction On Computer Systems, 7(4), 321–359.
Lipton, R. J., & Sandberg, J. S. (1998). Pram: A scalable shared memory. Technical Report
CS-TR-180-88, New Jersey: Princeton University.
Madnick, S. E., & Donovan, J. J. (1974). Operating systems (Vol. 197). New York: McGraw-Hill
Book Company.
Mazurkiewicz, A. (1987). Trace theory. In W. W. Brauer et al. (Eds.), Petri Nets, Application and
Relationship to other Models of Concurrency: Vol. 255. Lecture notes in computer sciences
(pp. 279–324).
Mosberger, D. (1993). Memory consistency models. ACM SIGOPS Operating Systems Review, 27
(1), 18–26.
Nutt, G. (2002). Operating systems: A modern perspective (2nd ed.). Boston: Addison-Wesley.
Petri, C. A. (1966). Communication with automata (Report, Vol. 1 Suppl. 1 RADC TR-65-377),
Applied Data Research, Contract AF 30 Princeton N.J.
Reisig, W. (1985). Petri nets: An introduction, monographs on theoretical computer science (Vol.
4). Berlin: Springer.
Silberschatz, A., Galvin, P. B., & Gagne, G. (2009). Operating system concepts (8th ed.). New
Jersey: Wiley.
Tanenbaum, A. S. (1995). Distributed operating systems. United States: Prentice-Hall.
226
8
Distributed Shared Memory

Chapter 9
The Control Flow During Execution
of the Alternating Bit Protocol Speciﬁed
by the Cause-Effect Structure
Flow of control during activity of the Alternating Bit Protocol (ABP) (Barlett et al.
1969), will be illustrated as a ﬂow of tokens in a cause/effect (c/e) structure that
speciﬁes this control ﬂow. C/E structures (Czaja 1988, 2002) is an algebraic cal-
culus, devised for speciﬁcation and analysis of parallel processes. Basic notions and
properties of the calculus is outlined in Chap. 10. Pictorially, a c/e structure is a
graph in which nodes (places) are named. Every name of a node is endowed with a
superscript and subscript being terms called the formal polynomials, whose argu-
ments are names of predecessors (in the superscript) and successors (in the sub-
script) of this node. The operators connecting arguments are „+” and „•”, called
addition and multiplication, where „+” means nondeterministic choice and „•”
simultaneity of receiving (in case of superscript) and sending (in case of subscript)
tokens. Figure 9.1 shows possible transformations of an exemplary c/e structure
marked with tokens: a ﬂow of token initially residing in the place a. The token
moves to b, then it „splits” and moves to c and d simultaneously, then one from c to
e then back to a, while the other remains in d forever. A different sequence of
transformations occurs, when the token moves from a to b, then to e, then back to
a. Polynomial h (empty) means „no successors or predecessors exist”. Tokens ﬂow
in accordance with the rules determined by semantics of c/e structures given in
Chap. 10.
The c/e structure in Fig. 9.1 may be deﬁned as an expression, called “arrow
expression” (a ! b) + (b ! c)•(b ! d) + (b ! e) + (c ! e) + (e ! d) + (e ! a)
in accordance with algebraic composition rules and denotational conventions given
in Chap. 10. Although c/e structures and Petri nets are formalisms of equivalent
descriptive capability (Raczunas 1993), in the pictorial presentation the c/e struc-
tures do not explicitly comprise transitions, thus allow for much more concise
graphical form. The counterparts to transitions, the so-called “ﬁring components”,
are derived from the formal polynomials. That is why the c/e structures are used
here for presentation of the ABP protocol behaviour in Table 9.1. The task is to
transmit messages from sender to receiver through an unreliable channel, so that:
(a) messages reach destinations in the order of their dispatch, (b) messages lost in
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_9
227

the channel are duplicated and dispatched again, (c) any message reaches its des-
tination exactly once. A message, unless the ﬁrst, is not taken for dispatch before
acknowledgement of reception of the preceding message arrives. In the graphic
presentation, the black tokens
in nodes represent message and acknowledgment,
which along with grey tokens
in auxiliary (“technical”) nodes—make a current
state of the protocol. Some arrows are annotated by conditions and statements,
involving truth-valued (1 = true, 0 = false) variables BIT, ACK and a variable
MES for storing messages. They are external to the ABP c-e structure, so, do not
belong to the c/e structure deﬁnition and play a role of comments only. The left part
is the sending module, the right part—the reception module.
The c/e structure named ALTERNATINGBITPROTOCOL may be deﬁned by
the “arrow expression” as combination of its substructures by means of addition and
multiplication operations of c/e structures (Chap. 10). It may be done by intro-
ducing the following denotations with mnemonic names of the substructures:
MESCHAN = m ! n (channel for message)
ACKCHAN = z ! b (channel for acknowledgment)
TAKEMES = (i ! j)•(k ! j)•(l ! j)•[(e ! j) + (h ! j)]
SENDMES = (m ! l)•(m ! k)•(l ! m)•(k ! m)
MESALT = j ! m
ACKFLIPFLOP = (f ! e)•(f ! g)•(g ! f )•(g ! h)
ACKSKIP = d ! c
ACKLOST = b ! a
RECEIVEACK = (b ! d)•[(d ! e) + (d ! h)]•ACKFLIPFLOP +
ACKSKIP + ACKLOST
TRANSMIT = SENDMES•MESCHAN + MESALT + RECEIVEACK•
TAKEMES
DELIVERMES = (v ! w)•(x ! v)•(y ! v)•[(r ! v) + (u ! v)]
SENDACK = (z ! y)•(z ! x)•(y ! z)•(x ! z)
ACKALT = v ! z
MESFLIPFLOP = (t ! u)•(t ! s)•(s ! t)•(s ! r)
MESSKIP = q ! p
MESLOST = n ! o
RECEIVEMES = (n ! q)•[(q ! r) + (q ! u)]•MESFLIPFLOP +
MESSKIP +
MESLOST
RECEIVE = SENDACK•ACKCHAN + ACKALT + RECEIVEMES•DELIVERMES
ALTERNATINGBITPROTOCOL = TRANSMIT + RECEIVE
Fig. 9.1 Consecutive transformations of state of exemplary c/e structure
228
9
The Control Flow During Execution of the Alternating …

Table 9.1 State 1: a message has arrived in node i from the sender for dispatch, the time-out since
the clock reset has not elapsed, so, the control tokens in nodes h, k, l indicate readiness to its
dispatch. State 2: the message can be passed to m, the start node to the channel, nodes h, k, l are
deactivated—lose tokens. State 3: the message has passed to node m and waits for transmission,
value 0 of B changed into 1—the opposite value. State 4: the message along with value of B has
been passed to the node n in the channel, the control nodes k, l have resumed activity (tokens), the
sender’s clock is reset. State 5: the current message successfully passed to the node q in the
reception part, a new message has arrived in node i from the sender for dispatch, but cannot be
passed to node j, because neither e nor h is active. State 6: the current message has been directed to
node u by means of the ﬂip-ﬂop t ⟷s (which changes its state) and value 1 of B. State 7: the
current message passes to node v making nodes x, y inactive (at the state 6, nodes x, y indicated that
the time-out since the clock reset had not been exceeded). State 8: the current message reaches the
receiver, the acknowledgment of delivery is passed to node z and value of A has been changed to 1;
time-out of the sender’s clock elapsed—deactivation of nodes k, l takes place, and the current
message in node m waits for retransmission. State 9: the acknowledgment along with value of
A has been passed to the node b in the channel, the sender’s and receiver’s clocks are reset
(activated nodes k, l and x, y), the retransmitted current message is passed to node n in the channel.
State 10: the acknowledgment successfully passed to the node d in the sending part, the
retransmitted current message reaches node q. State 11: The acknowledgment has been directed to
node h by means of the ﬂip-ﬂop f ⟷g (which changes its state) and value 1 of A, the
retransmitted current message has passed from node q to p because B = 1 and node t of the
ﬂip-ﬂop is not active. State 12: the new message passes from node i to j—action as at the state 2,
the retransmitted current message has been deleted; time-out of the receiver’s clock elapsed—
deactivation of nodes x, y takes place, and the acknowledgment in node z waits for retransmission.
State 13: the new message has passed to node m and waits for transmission, value 1 of B has been
changed to 0—the opposite value. State 14: the new message along with value of B has been
passed to the node n in the channel, the control nodes k, l have resumed activity (tokens), the
sender’s clock is reset. State 15: the new message successfully passed to the node q in the
reception part. State 16: the new message has been directed to node r by means of the ﬂip-ﬂop
t ⟷s (which changes its state) and value 0 of B. State 17: the new message passes to node
v making nodes x, y inactive (at the state 16, nodes x, y indicated that the time-out since the clock
reset had not been exceeded). State 18: the new message reaches the receiver, the acknowledg-
ment of its delivery is passed to node z and value of bit A changed to 0
9
The Control Flow During Execution of the Alternating …
229

(continued)
Table 9.1 (continued)
230
9
The Control Flow During Execution of the Alternating …

Table 9.1 (continued)
(continued)
9
The Control Flow During Execution of the Alternating …
231

Table 9.1 (continued)
(continued)
232
9
The Control Flow During Execution of the Alternating …

Table 9.1 (continued)
(continued)
9
The Control Flow During Execution of the Alternating …
233

Table 9.1 (continued)
(continued)
234
9
The Control Flow During Execution of the Alternating …

Table 9.1 (continued)
(continued)
9
The Control Flow During Execution of the Alternating …
235

Table 9.1 (continued)
(continued)
236
9
The Control Flow During Execution of the Alternating …

Table 9.1 (continued)
(continued)
9
The Control Flow During Execution of the Alternating …
237

Table 9.1 (continued)
238
9
The Control Flow During Execution of the Alternating …

References
Barlett, K. A., Sclantlebury, R. A., & Wilkinson, P. T. (1969). A note on reliable full-duplex
transmission over half-duplex links. Communications of the ACM, 12(5), 260–261.
Czaja, L. (1988). Cause-effect structures. Information Processing Letters, 26, 313–319.
Czaja, L. (2002). Elementary cause-effect structures. Wydawnictwa Uniwersytetu Warszawskiego.
Raczunas, M. (1993). Remarks on the equivalence of c-e structures and Petri nets. Information
Processing Letters, 45, 165–169.
References
239

Chapter 10
Some Mathematical Notions Used
in the Previous Chapters
10.1
Binary Relations
A binary relation, which connects elements of a set X with elements of a set Y, is any
subset of the Cartesian product X  Y. For a relation R  X  Y, its domain is the
set domðRÞ ¼
xj9y : ðx; yÞ 2 R
f
g and its codomain (or range) is the set
codðRÞ ¼
yj9x : ðx; yÞ 2 R
f
g.
A relation reverse to R denoted by R1, is deﬁned by ðx; yÞ 2 R1 , ðy; xÞ 2 R.
A composition of relations P, R is a relation denoted by P  R deﬁned by
ðx; yÞ 2 P  R , 9z : ðx; zÞ 2 P ^ ðz; yÞ 2 R.
This
is
associative
operation:
P  ðR  SÞ ¼ ðP  RÞ  S, thus the parentheses may be omitted. The inﬁnite iteration
of R is R þ ¼ S1
k¼1 Rk [ where Rk ¼ R  R      R (k-times). Identity relation
in a set X is idX ¼ ðx; xÞjx 2 X
f
g.
Relation R is a function R : domðRÞ ! codðRÞ iff for every x, y, z the following
holds: ðx; yÞ 2 R ^ ðx; zÞ 2 R ) y ¼ z. Some elementary properties of relations
are:
(a) domðRÞ ¼ £ , cod(RÞ ¼ £ , R ¼ £ (the empty relation)
(b) ðR1Þ1 ¼ R
(c) ðP  RÞ1 ¼ R1  P1
(d) ðP [ RÞ1 ¼ P1 [ R1
(e) ðP \ RÞ1 ¼ P1 \ R1
(f) dom R1


¼ codðRÞ
(g) cod R1


¼ domðRÞ
(h) domðP  RÞ  domðPÞ
(i) codðP  RÞ  codðRÞ
(j) codðPÞ \ domðRÞ ¼ £ , P  R ¼ £
(k) domðRÞ ¼ codðRÞ ) domðRÞ ¼ domðR þ Þ ¼ codðR þ Þ
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4_10
241

(l) id1
X ¼ idX
(m) £1 ¼ £
(n) idX  R ¼ R  idX ¼ R
(o) £  R ¼ R  £ ¼ £:
10.2
Inﬁnite Series of Real Numbers
For a given inﬁnite sequence of real numbers a0; a1; a2; . . .; an; . . . let us deﬁne a
sequence called a partial sums sequence:
s0 ¼ a0; sn þ 1 ¼ sn þ an þ 1; for all n  0. The inﬁnite sequence s0; s1; s2; . . .;
sn. . . is denoted by the symbol P1
n¼0 an and is called an inﬁnite series of elements
a0; a1; a2; . . .; an; . . .
The series is convergent to a sum s iff limn!1 sn ¼ s, which is written
P1
n¼0 an ¼ s.
The series is divergent iff the limit of the sequence s0; s1; s2; . . .; sn. . . does not
exist. This series is absolutely convergent iff the series P1
n¼0 an
j
j is convergent. The
necessary condition of convergence of the series is limn!1 an ¼ 0. That is: if
P1
n¼0 an is convergent then limn!1 an ¼ 0. This is not sufﬁcient condition, for
instance, the harmonic series P1
n¼0
1
n is divergent although limn!1 1
n ¼ 0.
10.2.1
D’Alambert (Sufﬁcient) Criterion of Convergence
The series of real numbers P1
n¼0 an where an > 0, is convergent if limk!1
ak þ 1
ak \1
and divergent if limk!1
ak þ 1
ak
[ 1. If limk!1
ak þ 1
ak ¼ 1 then the series may be either
convergent or divergent.
An easy proof of this criterion may be ﬁnd in most books, where the subject
concerning series is included.
10.2.2
Mertens Theorem on Multiplication of Series
If the series P1
n¼0 an and P1
n¼0 bn are absolutely convergent then their Cauchy
product P1
n¼0 cn where
242
10
Some Mathematical Notions Used in the Previous Chapters

cn ¼
X
n
k¼0
akbnk ¼ a0bn þ a1bn1 þ a2bn2 þ    þ an1b1 þ anb0
is convergent and P1
n¼0 cn ¼ P1
n¼0 an

 P1
n¼0 bn


Proof
column 0
#
for n ¼ 0 :
c0
¼
a0b0
column 1
#
for n ¼ 1 :
c1
¼
a0b1 þ a1b0
column 2
#
for n ¼ 2 :
c2
¼
a0b2 þ a1b1 þ a2b0
column 3
#
for n ¼ 3 :
c3
¼
a0b3 þ a1b2 þ a2b1 þ a3b0
……………………………………………………..
etc.
First, adding up all elements of each inﬁnite column and taking all ai in front of
brackets, then adding up all of these products, we get:
a0 b0 þ b1 þ b2 þ   
ð
Þ þ a1 b0 þ b1 þ b2 þ   
ð
Þ þ a2 b0 þ b1 þ b2 þ   
ð
Þ þ    ¼
a0 þ a1 þ a2 þ   Þðb0 þ b1 þ b2 þ   
ð
Þ ¼
X
1
n¼0
an
 
! X
1
n¼0
bn
 
!
□
Remarks
1. Why do the „horizontal” and „vertical” inﬁnite summations yield the same
value? This follows from a theorem that the order of adding elements of
absolutely convergent series, has no inﬂuence on its value (the inﬁnite sum).
2. The original formulation of the Mertens theorem contains somewhat weaker
assumption: it sufﬁces one of the series be absolutely convergent. However the
above proof, for its straightforwardness, justiﬁes slightly stronger assumption.
Example If
P1
n¼0 an ¼ P1
n¼0 bn ¼ P1
n¼0 xn
then
P1
n¼0 an

 P1
n¼0 bn


¼
P1
n¼0 ðn þ 1Þxn because
cn ¼ x0xn þ x1xn1 þ x2xn2 þ    þ xn1x1 þ xnx0 ¼ ðn þ 1Þxn
therefore P1
n¼0 cn ¼ P1
n¼0 ðn þ 1Þxn. By virtue of the Mertens theorem:
10.2
Inﬁnite Series of Real Numbers
243

X
1
n¼0
ðn þ 1Þxn ¼
X
1
n¼0
xn
 
! X
1
n¼0
xn
 
!
If |x| < 1 then P1
n¼0 xn ¼
1
1x thus P1
n¼0 ðn þ 1Þxn ¼ P1
n¼0 xn

2¼
1
1x

2
10.3
Probability, Independent Events, Random Variable
and Its Expected Value
Let X be a set of m possible results of a certain experiment and let A be a subset of
X, called an event and containing k 	 m results of this experiment. The event A is
said to occur if and only if the experiment yields a result that belongs to A. The
classic concept of probability (introduced by Laplace in 1812) as a chance of event
A to occur in this experiment, is the quotient k
m. Such understanding of probability is
justiﬁed by the following common everyday observation. If in the n-times repeated
experiment (under unchanged conditions), event A occurred fn(A)-times, then the
frequency fnðAÞ
n
of occurrences of A gets nearer to k
m, the greater is number n. Hence
the limit limn!1
fnðAÞ
n
has also been taken as a measure of the chance of A to occur
(Mises 1931). Since both deﬁnitions are mathematically obscure (referring to vague
terms, methodological incorrect assumptions and inﬁnite repetition of experiment),
the axiomatic, precise formal deﬁnition is nowadays adopted (introduced by
Kolmogorow in 1933). It may be expressed as follows. Let X be a set of elements
called the elementary events of a certain experiment. The elements will be denoted
by x with subscripts possibly. As in the classic case, a subset of X is called an event
and we say that the event A  X occurs, if a certain element x 2 A has been chosen
in effect of a random choice of elements from X (note that this pronouncement is
merely a comment supporting intuition, not a formal deﬁnition). The entire set X is
the certain event (certainty), the empty set ∅is the impossible event. Here we
conﬁne ourselves to the enumerable (in particular ﬁnite) sets X and deﬁne a
probability of events as a function assigning to each event A a real number P
(A) satisfying the following conditions:
(1) 0 	 P(A) 	 1
(2) P(X) = 1
(3) PðA1 [ A2 [ . . .Þ ¼ P A1
ð
Þ þ P A2
ð
Þ þ    for arbitrary ﬁnite or inﬁnite sequence
of events
A1, A2,… pairwise disjoint, i.e. such that Ai \ Aj = ∅for each i and j with i 6¼ j.
The pair (X, P) is called a probabilistic space.
244
10
Some Mathematical Notions Used in the Previous Chapters

Two events A1, A2 in the probabilistic space (X, P) are called independent iff
P(A1
\
A2) = P(A1)  P(A2). Generalization onto a ﬁnite set of events
A =
A1; A2; . . .; An
f
g may be obtained as follows. Events belonging to A are
independent if for every subset S of A the equality P T
A2S A


¼ Q
A2S PðAÞ holds,
where T
A2S A is the intersection of all events from S and Q
A2S PðAÞ is the product
of probabilities of all events from S.
Random variable is any function X : X !
into R; (injective function). This is a
function „into the set R”, but not „onto the set R”, that is, not the whole set R is its
range, but a certain proper subset: SX 
 R: X: X !
onto SX (surjective function). In
general, the range SX must fulﬁl some conditions assumed in Chap. 7, where the set
X was naturally enumerable. The random variable is discrete if SX is ﬁnite or
inﬁnite but enumerable.
Expected value of discrete random variable X is a number E(X), deﬁned as
EðXÞ ¼ x1p1 þ x2p2 þ x3p3 þ    ¼ P
i xipi, where summation expands onto all
values x1; x2; x3; . . . of random variable X and pi is a probability that X assumes
value xi; this probability is denoted by P(X = xi) = pi; If there are inﬁnitely many of
addends in this sum then we assume that the series is absolutely convergent:
P
i xipi
j
j\1.
Example In performing of n tests, ni i ¼ 1; 2; . . .; k
ð
Þ times a result xi has been
obtained, thus n1 þ n2 þ    þ nk ¼ n; SX ¼ x1; x2; . . .; xk
f
g (range of random
Remarks
(a) P(∅) = 0, which follows immediately from (2) and (3).
(b) If the set X were non-enumerable, then not to all of its subsets could be
assigned a probability which satisﬁes (1), (2), (3), but only to subsets
belonging to the so-called r-family M of sets, such that X 2 M, if A, B 2
M then A – B 2 M and A1 [ A2 [ … 2 M, for countably many sets A1,
A2, … belonging to M. In this case, the probabilistic space is (X, M, P).
Obviously, for the enumerable sets X, the r-family M is the powerset of
X, i.e. the family of all its subsets. For some considerations, apart from
inﬁnite union of events, their inﬁnite intersection A1 \ A2 \ … is
required to belong to M (called then the rd-family).
(c) Evidently, the classically deﬁned probability as the quotient k
m, satisﬁes
axioms (1), (2), (3). The axiomatic deﬁnition is a deﬁnitional schema. So,
it does not enable calculation of a concrete probability, but imposes
conditions to be fulﬁlled by probability of a given event in a concrete
experiment.
(d) The events are sets, thus the calculus of sets and combinatorial analysis
(for ﬁnite events) is applicable to probability theory.
10.3
Probability, Independent Events, Random Variable and Its Expected Value
245

value X). Then P X ¼ xi
ð
Þ ¼ pi ¼ ni
n (classic deﬁnition of probability as frequency),
EðXÞ ¼ n1
n x1 þ n2
n x2 þ    þ nk
n xk ¼ n1x1 þ n2x2 þ  þ nkxk
n
.
Thus, this is a weighted average of values x1; x2; . . .; xk
with weights
n1
n ; n2
n ; . . .; nk
n.
If n1 ¼ n2 ¼    ¼ nk ¼ 1, thus when n = k then the expected value E(X) is the
arithmetic average of x1; x2; . . .; xk.
10.3.1
Basic Notions of Cause-Effect Structures
Let X be a non-empty enumerable set. Its elements, called nodes, are counterparts
of places in Petri nets [Petri 1962], (Reisig 1985). Let h 62 X be a symbol called
neutral. It will play part of neutral element for operations on formal polynomials
(terms). The nodes, symbol h, operators +, , called the addition and multiplication
respectively, and parentheses are symbols out of which polynomials are formed as
follows. Each node and symbol h is a polynomial; if K and L are polynomials then
(K + L) and (K  L) are too; no other polynomials exist. Let us say “polynomials
over X”. Their set is denoted by F[X]. Assume stronger binding of  than +; this
allows for dropping some parentheses. Addition and multiplication of polynomials
is deﬁned as follows: K ⊕L = (K + L), K ⊗L = (K  L). Let us use + and 
instead of ⊕and ⊗. It is required that the system
F X
½ ; þ ;  ; h
h
i obeys the
following equality axioms for all K, L, M 2 F[X], x 2 X:
ð þ Þ
h þ K ¼ K þ h ¼ K
ðÞ
h  K ¼ K  h ¼ K
ð þ þ Þ
K þ K ¼ K
ðÞ
x  x ¼ x
ð þ þ þ Þ
K þ L ¼ L þ K
ð  Þ
K  L ¼ L  K
ð þ þ þ þ Þ
K þ L þ M
ð
Þ ¼ K þ L
ð
Þ þ M
ð  Þ
K  L  M
ð
Þ ¼ K  L
ð
Þ  M
ð þ Þ
If L 6¼ h , M 6¼ hthen K  L þ M
ð
Þ ¼ K  L þ K  M
Algebraic system which obeys these axioms will be referred to as a near semi
ring of formal polynomials.
A cause-effect structure (c/e structure) over X is a pair U = (C, E) of functions:
C: X ! F[X] (the cause function; nodes occurring in C(x) are causes of x)
E: X ! F[X] (the effect function; nodes occurring in E(x) are effects of x)
such that x occurs in the polynomial C(y) iff y occurs in E(x). A carrier of U is the set
carðUÞ ¼ fx 2 XjCðxÞ 6¼ h _ EðxÞ 6¼ hg. U is ﬁnite iff carðUÞ
j
j\1 (|…| means
cardinality). The set of all c/e structures over X is denoted by CE[X]. Since X is a ﬁxed
set, we write simply CE—wherever this makes no confusion.
A representation of a c/e structure U = (C, E) as a set of annotated nodes is
xCðxÞ
EðxÞ
x 2 carðUÞ
n
o
. U is also presented as a directed graph with car(U) as set of
nodes labelled with objects of the form xCðxÞ
EðxÞðx 2 carðUÞÞ and there is an edge
246
10
Some Mathematical Notions Used in the Previous Chapters

(arrow) from x to y iff y occurs in the polynomial E(x). Note that in this repre-
sentation, edges, although useful for the appearance of system models, are redun-
dant: interconnection of nodes may be inferred from polynomials C(x), E(x). Since
C,E are total functions (deﬁned on the entire set X), any c/e structure comprises all
the nodes from X, also the isolated ones (with C(x) = E(x) = h), invisible in the
graphical representation. The isolated nodes make the distributivity law (+ ) to be
conditional.
Addition and multiplication of c/e structures
For c/e structures U = (CU, EU), V = (CV, EV) deﬁne:
U + V = (CU+V, EU+V) = (CU + CV, EU + EV) where
(CU + CV)(x) = CU(x) + CV(x) and (EU + EV)(x) = EU(x) + EV(x)
U  V ¼ CUV; EUV
ð
Þ ¼ CU  CV; EU  EV
ð
Þ where
CU  CV
ð
ÞðxÞ ¼ CUðxÞ  CVðxÞ and
EU  EV
ð
ÞðxÞ ¼ EUðxÞ  EVðxÞ
U is a monomial c/e structure if polynomials CU(x) and EU(x) are a monomials, i.e.
do not comprise “ + ”. C/e structure
xh
y; yx
h
n
o
is an arrow, denoted as x ! y. The
pair ðh; hÞ is a c/e structure if h is understood as a constant function hðxÞ ¼ h for
each x 2 X. From deﬁnition of addition and multiplication of c/e structures follows
that ðh; hÞ is neutral for + and . For brevity let us write h instead of ðh; hÞ.
Evidently, U + V 2 CE and U  V 2 CE that is, in the resulting c/e structures, x
occurs in CU+V(y) iff y occurs in EU+V(x) and the same for U  V. Thus, addition and
multiplication of c/e structures yield correct c/e structures. The algebraic system
CE[X], + ,  ; h
h
i is a near semi ring similar to
F[X], + ,  ; h
h
i, as states the
following fact:
Proposition
For all U, V, W 2 CE[X], x, y 2 X the following properties hold in
the algebraic system
CE X
½ ; þ ; ; h
h
i:
þ
ð
Þ
h þ U ¼ U þ h ¼ U
ðÞ
h  U ¼ U  h ¼ U
þ þ
ð
Þ
U þ U ¼ U
ðÞ
ðx ! yÞ  ðx ! yÞ ¼ x ! y
þ þ þ
ð
Þ
U þ V ¼ V þ U
ð  Þ
U  V ¼ V  U
ð þ þ þ þ Þ
U þ V þ W
ð
Þ ¼ U þ V
ð
Þ þ W
ð  Þ
U  ðV  WÞ ¼ ðU  VÞ  W
ð þ Þ
If CVðxÞ 6¼ h , CWðxÞ 6¼ h and EVðxÞ 6¼ h , EWðxÞ 6¼ h then U  ðV þ WÞ ¼ U  V þ U  W
The equations follow directly from deﬁnition of c/e structures and deﬁnitions of
adding and multiplying c/e structures.
Notice that the operations on c/e structures make possible to combine small c/e
structures into large parallel system models.
For U 2 CE, deﬁne a partial order in CE by U 	 V , V = U + V. If
U 	 V then U is a substructure of V; SUB[V] = {U| U 	 V} is the set of all
substructures of V. For A  CE:
V 2 A is minimal (w.r.t. 	 ) in A iff 8W 2 A: (W 	 V ) W = V).
10.3
Probability, Independent Events, Random Variable and Its Expected Value
247

The crucial notion for behaviour of c/e structures is ﬁring component, a coun-
terpart of transition in Petri nets. It is, however, not a primitive notion but derived
from the deﬁnition of c/e structures, and is introduced regardless of any particular
c/e structure:
A minimal in CE\{h} c/e structure Q = (CQ, EQ) is a ﬁring component iff Q is a
monomial c/e structure and CQ(x) = h , EQ(x) 6¼ h for any x 2 car(Q). The set of
all ﬁring components is denoted by FC, thus the set of all ﬁring components of U 2
CE is FC[U] = SUB[U] \ FC.
Following the standard Petri nets notation, let for Q 2 FC:
Q ¼
x 2 carðQÞjCQðxÞ ¼ h


ðpre  set of QÞ
Q
¼
x 2 carðQÞjEQðxÞ ¼ h


ðpost  set of QÞ
The state of c/e structure is a counterpart of marking in 1-safe (elementary) Petri
nets. Note however that it is not bound up to any c/e structure:
A state is a subset of the set of nodes: s  X. The set of all states: S = 2X, the
powerset of X. A node x is active in the state s if and only if x 2 s and passive
otherwise. After Petri nets phrasing we say “x holds a token” when x is active.
Semantics of c/e structures is a counterpart of simple the ﬁring rule in 1-safe
Petri nets:
For Q 2 FC[U] and s, t 2 S, let Q
½ 
½
  S  S be a binary relation deﬁned as:
(s, t) 2 Q
½ 
½
 iff Q  s and Q \ s ¼ £ and t ¼ snQ
ð
Þ [ Q
(say: Q transforms state s into t). Semantics [[U]] of U 2 CE is:
½½U¼
S
Q2FC½U
½½Q
U
½ 
½
 is its reﬂexive and transitive closure, that is, (s, t) 2 U
½ 
½
 iff s = t or there
exists a sequence of states s0; s1; . . .; sn with s ¼ s0, t = sn and (sj, sj+1) 2 U
½ 
½
 for
j = 0, 1, …, n −1. We say that t is reachable from s in semantics ½ 
½ . The sequence
s0; s1; . . .; sn is called a computation in U.
Note that U
½ 
½
¼ £ iff FC[U] = ∅. Behaviour of c/e structures in accordance
with this semantics may be imagined as a token game: if each node in a certain
ﬁring component’s pre-set holds a token and none in its post-set does, then remove
tokens from the pre-set and put them in the post-set.
A few immediate conclusions of above deﬁnitions are:
1. U1 	 V1 ^ U2 	 V2 ) U1 þ U2 	 V1 þ V2 (monotonicity of +)
2. U1 	 V1 ^ U2 	 V2 ) U1  U2 	 V1  V2 provided that ðU1 þ V1Þ  ðU2 þ V2Þ ¼
U1  U2 þ V1  V2 þ U1  V2 þ V1  U2 (conditional monotonicity of )
3. U (V + W) 	 U  V + U  W but relation 	 not always may be replaced by
equality
4. If U (V + W) = U  V + U  W then V 	 W ) U  V 	 U  W
5. U 	 V ) FC[U]  FC[V] but converse implication not always holds
6. FC[U] [ FC[V]  FC[U + V] but the inclusion not always may be replaced
by equality
248
10
Some Mathematical Notions Used in the Previous Chapters

7.
CE; 	
h
i, i.e. the set of all c/e structures partially ordered by relation 	 is a
non-distributive lattice with the least element h and with no greatest element.
8. FC[U]  FC[V] ) U
½ 
½
 V
½ 
½
 but converse implication not always holds
9.
U
½ 
½
 [ V
½ 
½
 U þ V
½

½
 but the inclusion not always may be replaced by equality
10. FC[U] [ FC[V] = FC[U + V] ) U
½ 
½
 [ V
½ 
½
 ¼ U þ V
½

½
 but converse impli-
cation not always holds. Note that equation
U
½ 
½
 [ V
½ 
½
 ¼ U þ V
½

½
 expresses
compositionality of summation for c/e structures U and V; equation FC[U] [
FC[V] = FC[U + V] states that no new ﬁring components (except for those in
U and V) are created in their sum.
Remark The deﬁnition of c/e structures along with some basic facts on them, have
been presented here for better understanding the ABP protocol, whose activity, as a
token game in a c/e structure specifying the protocol, is given in Table 9.1 in
Chap. 9. For this purpose it was sufﬁcient to present elementary c/e structures
(counterparts of elementary Petri nets, i.e. with at most one token in any place).
More general versions, like place/transitions or colour nets were investigated e.g. in
Ustimenko (1996, 1998). Equivalence of c/e structures and Petri nets has been
proved in Raczunas (1993). The deﬁnition of c/e structures quoted in this chapter,
comes from Czaja (1998, 2002). In the ﬁrst paper on the subject (Czaja 1988), an
equivalent deﬁnition but based on ﬁx-point, has been adopted.
References
Czaja, L. (January 1988). Cause-effect structures. Information Processing Letters, 26, 313–319.
Czaja,
L.
(2002).
Elementary
cause-effect
structures.
Wydawnictwa:
Uniwersytetu
Warszawskiego.
Czaja,
L.
(1998).
Cause-effect
structures—structural
and
semantic
properties
revisited.
Fundamenta Informaticae 33, 17–42, IOS Press.
Petri, C. A. (1962). Kommunikation mit Automaten. Bonn: Institut für Instrumentelle Mathematik‚
Schriften des IIM Nr. 2, 1962.
Raczunas, M. (1993). Remarks on the equivalence of c-e structures and Petri nets. Information
Processing Letters, 45, 165–169.
Reisig, W. (1985). Petri nets: An introduction, monographs on theoretical computer science.
Berlin: Springer.
Ustimenko, A. P. (1996). Algebra of two-level cause-effect structures. Information Processing
Letters, 59, 325–330.
Ustimenko, A. P. (1998). Coloured cause-effect structures. Information Processing Letters, 68(5),
219–225.
10.3
Probability, Independent Events, Random Variable and Its Expected Value
249

Final Remarks
The book concerns main principles and features of distributed systems, composed
of computers internally controlled, that is, the so-called von Neuman’s architectures
(von Neumann 1945). Presenting basic idea behind activity of such machine in
Chap. 1, details of its physical construction have been omitted. All the nowadays
realizations of the instruction execution cycle are electronic, but one may imagine,
for instance, mechanical realization, involving cogwheels, levers, etc., with pro-
gram and data supplied on punched cards as memory—as in analytical machine
built by Babbage (1864). The principle is similar, but execution duration of
arithmetic and other operations in case of present-day electronic processors is
several billions times shorter. Along with physical realizations, the von Neumann’s
machine is the human concept. However this is not the only principle of activity of
devices performing computation operations—arithmetical, logical and control.
Inspiration for searching for different principles, called computational paradigms,
are natural phenomena. Nowadays, the intensive research is being carried out on
mechanisms of biological particles activity, in particular information ﬂow among
molecular structures and on making usage of their multitude for mass of simple
operations, executed in parallel. Some computational architectures have already
been created, that operate on such principle, though not yet carried into widespread,
public usage. Such constructs are capable of solving tasks exceeding (owing to time
complexity) capability of classical sequential processors, even interconnected into
distributed systems. Computations in such experimental architectures, variously
named: molecular, biomolecular, biochemical or DNA computing, have so far
efﬁciently applied to solving some combinatorial problems, the so-called compu-
tationally hard, like ﬁnding Hamiltonian cycle in a graph (closed path crossing
every vertex exactly ones), veriﬁcation of satisﬁability of propositional formuli of
very many variables, modelling of the so-called self-organizing systems (e.g.
evolution of organisms, weather phenomena, etc.) and many more problems of high
complexity. Another natural phenomenon inspiring non classic work principle of
computational devices comes from quantum mechanics. The information unit is
there the so-called quantum bit, qubit in short, mathematically represented as a
linear combination of two states of polarization of a quantum object, e.g. photon,
where the coefﬁcients of the combination are the so-called amplitudes of probability
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4
251

of a certain state occurrence. Thus, the qubit is, in a sense, a superposition (or
composition) of two binary states, whose sequence may be simultaneously in many
states, due to the so-called quantum entanglement. This phenomenon has been used
for simultaneous execution of mass computations. Each computation is a sequence
of quantum states and a state is a sequence of n qubits, where n is their number
which the so-called quantum computer can contain. The computer may be simul-
taneously in 2n states, whereas its classic, sequential counterpart—in one only from
among 2n states at a time. The quantum architecture (Deutsch 1985), still in
experimental phase, alike the molecular one, is capable of overcoming the com-
plexity barriers of classic processors, also in distributed systems. Typical problems
of high complexity come from number theory, especially their application in
cryptography. Both aforesaid non classic paradigms of computation inspired by
natural phenomena, along with usage of natural objects—biochemical and quantum
—in their physical realization (hardware), are expected to be applied in the mas-
sively parallel computing. The principles belong to a research domain called natural
computation. This domain encompasses also imitation of phenomena and processes
encountered in the nature as problem solving techniques, but by creating algo-
rithmic models executed in the classic computer system, or in grids of many simple
and cheap sequential processors. Examples are neural computation, cellular auto-
mata, swarm intelligence (imitating behaviour of a “swarm” of objects striving to a
joint objective), evolutionary computation (imitating Darwinian evolution), mem-
brane computing (imitating of cell membrane functions), cf. Rozenberg et al.
(2012). These and other models of computation—a result of observation of natural
phenomena—are being devised for special tasks, but there are also research
attempts to create the Universal Quantum Turing Machine (Turing 1937; Deutsch
1985; Penrose 1989), a system for all the effective computations, like a classic
computer with arbitrarily large memory needed for a given class of problems. One
may also mention other systems, where parallelization and distribution of great
number of cooperating elements takes place, like the cyber-physical systems
(Lamnabhi-Lagarrigue et al. 2014) (for control of technical devices) or multi agent
systems (Russell and Norvig 2010). All them are dynamically developing scientiﬁc
and engineering explorations. This book was concerned with distributed systems
composed of computers of the classic von Neuman’s architecture, leaving to the
interested reader a closer familiarity with endeavours leading to practical applica-
tion of the above mentioned contemporary computational principles.
References
Babbage, C. (1864). The life of a philosopher. London.
Deutsch, D. (1985). Quantum theory, the church-turing principle and the universal quantum computer.
Proceedings of the Royal Society of London, A400, 97–117.
Lamnabhi-Lagarrigue, F., Di Benedetto, M. D., & Schoitsch, E. (2014). Introduction to the special theme
cyber-physical systems. Ercim News, 94, 6–7.
252
Final Remarks

Penrose, R. (1989). The emperor’s new mind. UK: Oxford University Press.
Rozenberg, G., Baeck, T., & Kok, J. (2012). Handbook of natural computing. Heidelberg.
Russell, S., & Norvig, P. (2010). Artiﬁcial intelligence. A modern approach. Englewood Cliffs, NJ:
Prentice Hall.
Turing, A. M. (1937). On computable numbers, with an application to the Entscheidungsproblem.
Proceedings of the London Mathematical Society Series 2, 42, 230–265.
von Neumann, J. (1945). First draft of a report on the EDVAC.
Final Remarks
253

Bibliography
Akl, S. G. (1997). Parallel computation: Models and methods. USA: Prentice Hall.
Bedrouni, A., Mittu, R., Abdeslem Boukhtouta, A., & Berger, J. (2009). Distributed intelligent
systems. A coordination perspective. Berlin: Springer.
Belapurkar, A., Chakrabarti, A., Ponnapalli, H., Varadarajan, N., Padmanabhuni, S., &
Sundarrajan, S. (2009). Distributed systems security. Issues, processes and solutions. USA:
Wiley.
Ben-Ari, M. (1996). Podstawy programowania współbieżnego i rozproszonego. Warszawie:
Wydawnictwa Naukowo-Techniczne 1996 (Polish translation of 1990).
Boykin, J., Kirschen, D., Langerman, A., & Loverso, S. (1993). Programming under Mach.
Reading, MA: Addison-Wesley.
Broy, M., & Stølen, K. (2001). Abracadabra protocol. In: Speciﬁcation and development of
interactive systems. Monograps in Computer Science. NY: Springer.
Comer, D. E. (1995). Internetworking with TCP/IP, Volume 1: Principles, Protocols, and
Architecture. USA: Prentice Hall.
Coulouris, G., Dollimore, J., & Kindberg, T. (1998). Systemy rozproszone, podstawy i
projektowanie. Warszawa: WNT (Polish translation of 1994).
Czaja, L. (1973). Niektóre aspekty implementacji ALGOL-u 60 dla maszyn ZAM/21 ALFA. In
Materiały Sympozjum XV-rocznicy Instytutu Maszyn Matematycznych i Roku Nauki Polskiej,
Warszawa (Some aspects of implementation of ALGOL 60, in Polish).
Czaja, L., & Szorc, P. (1967). Implementation of ALGOL for ZAM computers. Algorytmy, 4(7),
91–111.
Dahl, O.-J., Dijkstra, E. W., & Hoare, C. A. R. (1972). Structured programming. London and New
York: Academic Press.
Dasgupta, P., LeBlanc, R. J., Jr., Ahamad, M., & Ramachandran, U. (1991). The clouds distributed
operating systems. IEEE Computer, 24(11), 34–44.
Davies, D. W., Holler, E., Jensen, E. D., Kimbleton, S. R., Lampson, B. W., LeLann, G., et al.
(1983). In B. W. Lampson, M. Paul, & H. J. Siegert (Eds.), Distributed systems—Architecture
and implementation, an advanced course. Berlin: Springer.
Gabassi, M., & Dupouy, B. (1995). Przetwarzanie rozproszone w systemie UNIX. Warszawa:
Lupus (Distributed processing in UNIX, in Polish).
Gien, M. (1995). Evolution of the CHORUS open microkernel architecture: The STREAM
project. In FTDCS ’95 Proceedings of the 5th IEEE Workshop on Future Trends of Distributed
Computing Systems. USA: IEEE Computer Society.
Gościński, A. (1991). Distributed operating systems, the logical design. USA: Addison Wesley.
Haddad, S., Kordon, F., Pautet, L., & Petrucci, L. (2011). Distributed systems, design and
algorithms. USA: Wiley.
Holenderski, L., & Szałas, A. (1988). Propositional description of ﬁnite cause-effect structures.
Information Processing Letters, 27, 111–117.
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4
255

Kshemkalyani, A. D., & Singhal, M. (2011). Distributed computing: Principles, algorithms, and
systems. Cambridge: Cambridge University Press.
Milner, R. (1989). Communication and concurrency. In C. A. R. Hoare (Series Ed.). USA:
Prentice-Hall.
Shapiro, E. Y. (1987). Concurrent PROLOG: Collected papers. Cambridge MA, USA: MIT Press.
Sinha, P. K. (1997). Distributed operating systems—Concepts and design. Piscataway: IEEE
Press.
Sorin, D. J., Hill, M. D., & Wood, D. A. (2011). A premier on memory consistency and cache
coherence. In M. D. Hill (Ed.), Synthesis lectures on computer architecture. USA: Morgan and
Calypool Publishers.
Spector, A., & Gifford, D. (1984). The space shuttle primary computer system. Communications of
the ACM 27(i), 874–900.
Sportack, M. (1998). Networking essentials unleashed (1st ed.). USA: Sams Publishing.
Starke, P. (1987). Sieci petri. Warsaw: PWN (Polish translation of the author’s book in German:
Petri Netze, 1980).
Stevens, W. R. (1999). UNIX Programowanie usług sieciowych. Warszawa: WNT.
SYSTEM AUTOMATYCZNEGO KODOWANIA SAKO. (1961). Prace Zakładu Aparatów
Matematycznych PAN. Warszawa: PAN (SAKO—A system of automatic coding, in Polish).
Tanenbaum, A. S., Van Renesse, R., Van Staveren, H., Sharp, G. J., Mullender, S. J., Jansen, J.,
et al. (1990). Experience with the amoeba distributed operating system. Communication of the
ACM, 33(12), 46–63.
Tanenbaum, A. S. (1997). Rozproszone systemy operacyjne. Warsaw: PWN (Polish translation of
1995).
Tanenbaum, A. S. (2004). Sieci komputerowe. Gliwice: Wydawnictwo Helion (Polish translation
of 2003).
Tanenbaum, A. S., & Wetherall, D. J. (2011). Computer networks. USA: Prentice Hall.
Tanenbaum, A. S., & van Steen, M. (2002). Distributed systems: Principles and paradigms (2nd
ed.) UK: Pearson.
Tanenbaum, A. S., & van Steen, M. (2003). Computer networks. USA: Prentice Hall.
Tanenbaum, A. S., & van Steen, M. (2006). Systemy rozproszone, zasady i paradygmaty.
Warszawa: WNT (Polish translation of 2002).
Wierzbicki, A. (2010). Trust and fairness in open, distributed systems. Berlin: Springer.
Wirth, N. (1988). Programming in modula-2 (4th ed.), Texts and Monographs in Computer
Science. Berlin: Springer.
Wulf, W. A., & Bell, C. G. (1972). C.mmp—A multi-mini processor. In Proceedings of AFIPS,
FJCC (Vol. 41, pp. 765–777). Montvale, N.J.: AFIPS-Press.
256
Bibliography

Index
A
Accumulator, 1, 3
ADA, 20, 125–127, 142, 143, 146
Algol, 142
Algorithm, 2, 8, 35–37, 43, 53, 79, 122, 162,
172–175, 177–179, 222, 223, 225
bully, 172–174, 177
ring, 79, 172, 177–179
Alternating Bit Protocol, 160, 227
ALU, 121, 122
Amoeba, 53, 125
Architecture, 1, 43, 50, 52, 59, 60, 62, 64,
120–123, 142, 188
von Neuman, 1, 2
Arpanet, 49, 55
Asynchronous Transfer Mode (ATM), 120,
130, 133, 137, 138
B
Berkeley method, 90, 91
Binary relations, 87, 241
Binder, 145
BITNET, 49, 50
Blocking, 68, 69, 72, 74, 75, 127–129
Broadcast, 86, 91, 101, 120, 127, 130, 131,
166, 197, 205, 221–223
Busy waiting, 116
Byzantine generals, 165, 169
C
Causal broadcast, 223, 224
Causal consistency, 217, 218, 220, 223
Causal order, 217, 219, 220, 225
Centralized system, 51
c/e structures, 227, 228, 246–249
Channel, 4, 6, 12, 20, 35, 120, 122, 123, 127,
129, 163, 227–229
Checkpoint, 160
Chorus, 53, 125
Circuit switching, 49, 125
Clock, 3, 43, 52, 56, 85–91, 96–99, 102, 142,
195, 202, 229
Clouds, 53, 59
Common Object Request Broker Architecture
(CORBA), 59, 144
Communicating Sequential Processes (CSP),
19, 125, 127
Communication, 2, 4, 12, 19, 20, 35–38, 42,
50–53, 56, 57, 59, 61, 63, 64, 74, 78, 90,
94, 96, 99, 116, 119–133, 137, 141,
142, 146, 157, 165, 166, 173, 189, 221
asynchronous, 19, 37–39, 120, 121, 124,
126–131, 137
connection oriented, 120
connectionless, 120, 121, 127, 130, 131,
137, 138
group, 19, 53, 94, 126, 127, 131, 132, 157,
165, 221
synchronous, 19, 20, 35–38, 42, 120, 121,
124–128, 131, 137
Computer network, 2, 50, 188
Computer systems classiﬁcation, 47
Concurrency, 56, 60, 61, 65, 66, 71, 74, 190,
195, 196, 200, 212, 220
Concurrent Pascal, 125, 143, 146
Concurrent Prolog, 125
Consensus, 164, 165, 172
Coordinator, 162, 166, 170, 172–175, 177–179
Cristian’s method, 89–91, 94, 142
Critical section, 8, 11, 12, 67, 78, 111, 143
Crossbar, 61, 62
© Springer International Publishing AG 2018
L. Czaja, Introduction to Distributed Computer Systems, Lecture Notes in Networks
and Systems 27, https://doi.org/10.1007/978-3-319-72023-4
257

D
D’Alambert criterion, 159
Deadlock, 65, 70, 73–75, 119, 162, 215
Discrete random variable, 158, 245
Distributed Computing Environment (DCE),
53
Distributed Shared Memory (DSM), 60,
187–190, 194–196, 215–218, 220, 221
Distributed system, 1, 2, 49, 50, 52, 55, 56, 60,
74, 85, 87, 96, 108, 119, 131, 141–143,
145, 157, 161, 187–189, 221
E
Election, 91, 162, 170, 173–175, 177–179, 184
European Academicand Research Network
(EARN), 50
Event, 65, 73, 74, 85–87, 96, 97, 99, 100, 102,
116, 124, 132, 161, 162, 212, 215, 216,
218, 223, 244, 245
Exceptions, 124, 141, 146
Expected value, 158, 159, 244–246
F
Failure, 55, 66, 78, 90, 101, 112, 146,
157–162, 173, 174, 177, 178
Fast-read algorithm, 222
Fast-write algorithm, 221, 222
Fault tolerance, 55, 56, 61, 157, 165, 172
FIFO, 38, 131–133, 203, 222, 223
Flynn’s taxonomy, 47
G
Global timestamp, 100–102, 108, 109
Greatest common divisor, 20, 38
I
Independent events, 158, 244
Inhibitor arcs, 116, 117
Instruction execution cycle, 1–3, 43
Instruction register, 1, 3
Instruction set, 3, 19, 37
Interleaving, 4, 190, 191, 194, 195, 199, 200,
202, 206, 210, 212, 220
Internal control, 1
Internet, 49, 50, 54, 61, 86, 94, 131, 188
J
Java, 20, 59, 123, 125, 142, 143, 145, 146
L
LINDA, 37, 125, 126, 129
Linear order, 87, 96, 100
Lock, 66, 67, 70
Logarithmic switch, 62, 63
Logical clock, 87, 94, 97, 99, 100
Logical time, 94
LOGLAN, 125, 146
M
Mach, 53, 125
Marshalling, 120, 121, 123, 133, 141, 142, 189
Memory coherence, 199, 200, 205, 206,
208–210, 212–214
Memory consistency, 125, 187–190, 195–197,
199, 205, 212, 215, 217, 220, 221
causal, 217, 219, 220, 225
Pipelined Random Access Memory
(PRAM), 219, 220, 225
sequential, 195, 197, 199, 200, 202, 205,
212, 217, 225
strict, 187, 195, 200, 217, 220
Mertens theorem, 159, 242–244
Meta-program, 2
Modula-2, 125, 127, 146
Multicast, 120, 126, 127, 131, 157
Multiprogramming, 4
Mutual exclusion, 8, 19, 65–67, 75, 78–80, 83,
100–102, 109, 112, 116, 120, 143, 144,
162, 215
N
NASK, 50
Network Time Protocol (NTP), 91, 94, 95
Non Uniform Memory Access (NORMA), 64
NO Remote Memory Access (NUMA), 62, 63
O
OCCAM, 20, 124–127
Openness, 56, 59, 61
OSI/RM, 120, 133, 134, 137, 138
P
Partial order, 96, 100, 196, 212, 247
Petri nets, 116, 190, 227, 246, 248, 249
Physical time, 85, 87, 89, 90
PLEARN, 50
Port, 121, 126, 127, 145
Precedence, 85, 94, 96, 99
Probability, 158, 159, 164, 196, 244–246
Process, 3, 5, 8, 12, 19, 42, 52, 65–67, 70, 75,
76, 78, 79, 96–102, 108, 120, 121,
124–129, 131, 132, 142, 143, 145, 161,
162, 167, 173, 174, 177, 195, 197, 199,
205, 212, 217–219, 221
Processor, 1–4, 43, 44, 54, 61, 63, 65, 85, 87,
96, 161, 197, 199, 205
Protective zone, 67, 78, 79, 101–103, 108–112,
116
258
Index

Protocol, 52, 63, 94, 102, 108–113, 116,
120–123, 125, 131, 133, 137, 138, 144,
146, 227, 228, 249
R
Random variable, 159, 244, 245
Remote Method Invocation (RMI), 58, 127,
141, 143, 145
Remote Procedure Call (RPC), 53, 59, 127,
141–147, 187, 189
Resource, 1, 8, 11, 56–59, 66, 67, 69, 70, 75,
78, 102, 108, 119, 142–144
S
Scalability, 56, 61, 131
Semaphore, 8, 11, 12, 66, 67, 116, 120
Sequential machine, 2
Series of real numbers, 242
Socket, 53, 121, 126, 127, 145
Starvation, 65, 75, 112, 119, 162, 215
Stub, 144–146
Synchronization, 2, 19, 57, 58, 65, 74, 78,
87–91, 94, 95, 119, 121, 138, 142, 161,
162, 173, 189
T
Thread, 50, 124–126, 147
Time compensation, 94, 99, 100, 102
Timeout, 74, 128, 131, 138, 146
Timesharing, 7
Timestamp, 99, 100, 102, 108, 110, 112, 160
Timestamps vectors, 111
Token ring, 66, 78, 79, 82, 83
Transactions, 58, 65–67, 69–71, 73, 74, 87,
119, 143, 164
Transparency, 56, 60, 141, 145, 160, 200, 221
Two Army problem, 162, 164, 165
U
Uniform Memory Access (UMA), 62, 63
UNIX 4BSD, 53
Unlock, 67, 70, 72
Unmarshalling, 120, 123, 133, 141, 142
V
Vector systems, 43
W
Wait graph, 73, 74
Weak precedence, 96
Index
259

