Inverse Problem Theory 
and Methods for Model Parameter Estimation


Inverse Problem Theory 
and Methods for Model Parameter Estimation


Society for Industrial and Applied Mathematics
Philadelphia
Inverse Problem Theory 
and Methods for Model Parameter Estimation
Albert Tarantola
Institut de Physique du Globe de Paris
Université de Paris 6
Paris, France

is a registered trademark.
Copyright © 2005 by the Society for Industrial and Applied Mathematics.
10 9 8 7 6 5 4 3 2 1
All rights reserved.  Printed in the United States of America.  No part of this book
may be reproduced, stored, or transmitted in any manner without the written per-
mission of the publisher.  For information, write to the Society for Industrial and
Applied Mathematics, 3600 University City Science Center, Philadelphia, PA 19104-
2688.
Library of Congress Cataloging-in-Publication Data
Tarantola, Albert.
Inverse problem theory and methods for model parameter estimation / Albert
Tarantola.
p. cm.
Includes bibliographical references and index.
ISBN 0-89871-572-5 (pbk.)
1. Inverse problems (Differential equations)   I. Title. 
QA371.T357 2005
515’.357—dc22
2004059038

To my parents,
Joan and Fina



Contents
Preface
xi
1
The General Discrete Inverse Problem
1
1.1
Model Space and Data Space . . . . . . . . . . . . . . . . . . . . . .
1
1.2
States of Information
. . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.3
Forward Problem
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
1.4
Measurements and A Priori Information
. . . . . . . . . . . . . . . .
24
1.5
Deﬁning the Solution of the Inverse Problem . . . . . . . . . . . . . .
32
1.6
Using the Solution of the Inverse Problem
. . . . . . . . . . . . . . .
37
2
Monte Carlo Methods
41
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
2.2
The Movie Strategy for Inverse Problems . . . . . . . . . . . . . . . .
44
2.3
Sampling Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
2.4
Monte Carlo Solution to Inverse Problems . . . . . . . . . . . . . . .
51
2.5
Simulated Annealing
. . . . . . . . . . . . . . . . . . . . . . . . . .
54
3
The Least-Squares Criterion
57
3.1
Preamble: The Mathematics of Linear Spaces
. . . . . . . . . . . . .
57
3.2
The Least-Squares Problem . . . . . . . . . . . . . . . . . . . . . . .
62
3.3
Estimating Posterior Uncertainties
. . . . . . . . . . . . . . . . . . .
70
3.4
Least-Squares Gradient and Hessian
. . . . . . . . . . . . . . . . . .
75
4
Least-Absolute-Values Criterion and Minimax Criterion
81
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
4.2
Preamble: ℓp-Norms . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
4.3
The ℓp-Norm Problem . . . . . . . . . . . . . . . . . . . . . . . . . .
86
4.4
The ℓ1-Norm Criterion for Inverse Problems . . . . . . . . . . . . . .
89
4.5
The ℓ∞-Norm Criterion for Inverse Problems . . . . . . . . . . . . . .
96
5
Functional Inverse Problems
101
5.1
Random Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
5.2
Solution of General Inverse Problems . . . . . . . . . . . . . . . . . . 108
5.3
Introduction to Functional Least Squares . . . . . . . . . . . . . . . . 108
5.4
Derivative and Transpose Operators in Functional Spaces . . . . . . . 119
vii

viii
Contents
5.5
General Least-Squares Inversion
. . . . . . . . . . . . . . . . . . . . 133
5.6
Example: X-Ray Tomography as an Inverse Problem
. . . . . . . . . 140
5.7
Example: Travel-Time Tomography
. . . . . . . . . . . . . . . . . . 143
5.8
Example: Nonlinear Inversion of Elastic Waveforms . . . . . . . . . . 144
6
Appendices
159
6.1
Volumetric Probability and Probability Density . . . . . . . . . . . . . 159
6.2
Homogeneous Probability Distributions . . . . . . . . . . . . . . . . . 160
6.3
Homogeneous Distribution for Elastic Parameters . . . . . . . . . . . 164
6.4
Homogeneous Distribution for Second-Rank Tensors
. . . . . . . . . 170
6.5
Central Estimators and Estimators of Dispersion . . . . . . . . . . . . 170
6.6
Generalized Gaussian . . . . . . . . . . . . . . . . . . . . . . . . . . 174
6.7
Log-Normal Probability Density
. . . . . . . . . . . . . . . . . . . . 175
6.8
Chi-Squared Probability Density
. . . . . . . . . . . . . . . . . . . . 177
6.9
Monte Carlo Method of Numerical Integration . . . . . . . . . . . . . 179
6.10
Sequential Random Realization . . . . . . . . . . . . . . . . . . . . . 181
6.11
Cascaded Metropolis Algorithm . . . . . . . . . . . . . . . . . . . . . 182
6.12
Distance and Norm
. . . . . . . . . . . . . . . . . . . . . . . . . . . 183
6.13
The Different Meanings of the Word Kernel
. . . . . . . . . . . . . . 183
6.14
Transpose and Adjoint of a Differential Operator . . . . . . . . . . . . 184
6.15
The Bayesian Viewpoint of Backus (1970) . . . . . . . . . . . . . . . 190
6.16
The Method of Backus and Gilbert . . . . . . . . . . . . . . . . . . . 191
6.17
Disjunction and Conjunction of Probabilities . . . . . . . . . . . . . . 195
6.18
Partition of Data into Subsets . . . . . . . . . . . . . . . . . . . . . . 197
6.19
Marginalizing in Linear Least Squares
. . . . . . . . . . . . . . . . . 200
6.20
Relative Information of Two Gaussians . . . . . . . . . . . . . . . . . 201
6.21
Convolution of Two Gaussians
. . . . . . . . . . . . . . . . . . . . . 202
6.22
Gradient-Based Optimization Algorithms . . . . . . . . . . . . . . . . 203
6.23
Elements of Linear Programming . . . . . . . . . . . . . . . . . . . . 223
6.24
Spaces and Operators . . . . . . . . . . . . . . . . . . . . . . . . . . 230
6.25
Usual Functional Spaces . . . . . . . . . . . . . . . . . . . . . . . . . 242
6.26
Maximum Entropy Probability Density . . . . . . . . . . . . . . . . . 245
6.27
Two Properties of ℓp-Norms . . . . . . . . . . . . . . . . . . . . . . . 246
6.28
Discrete Derivative Operator
. . . . . . . . . . . . . . . . . . . . . . 247
6.29
Lagrange Parameters
. . . . . . . . . . . . . . . . . . . . . . . . . . 249
6.30
Matrix Identities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
6.31
Inverse of a Partitioned Matrix
. . . . . . . . . . . . . . . . . . . . . 250
6.32
Norm of the Generalized Gaussian
. . . . . . . . . . . . . . . . . . . 250
7
Problems
253
7.1
Estimation of the Epicentral Coordinates of a Seismic Event . . . . . . 253
7.2
Measuring the Acceleration of Gravity . . . . . . . . . . . . . . . . . 256
7.3
Elementary Approach to Tomography . . . . . . . . . . . . . . . . . . 259
7.4
Linear Regression with Rounding Errors . . . . . . . . . . . . . . . . 266
7.5
Usual Least-Squares Regression . . . . . . . . . . . . . . . . . . . . . 269
7.6
Least-Squares Regression with Uncertainties in Both Axes
. . . . . . 273

Contents
ix
7.7
Linear Regression with an Outlier . . . . . . . . . . . . . . . . . . . . 275
7.8
Condition Number and A Posteriori Uncertainties . . . . . . . . . . . 279
7.9
Conjunction of Two Probability Distributions . . . . . . . . . . . . . . 285
7.10
Adjoint of a Covariance Operator . . . . . . . . . . . . . . . . . . . . 288
7.11
Problem 7.1 Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . 289
7.12
Problem 7.3 Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . 289
7.13
An Example of Partial Derivatives
. . . . . . . . . . . . . . . . . . . 290
7.14
Shapes of the ℓp-Norm Misﬁt Functions
. . . . . . . . . . . . . . . . 290
7.15
Using the Simplex Method
. . . . . . . . . . . . . . . . . . . . . . . 293
7.16
Problem 7.7 Revisited . . . . . . . . . . . . . . . . . . . . . . . . . . 295
7.17
Geodetic Adjustment with Outliers . . . . . . . . . . . . . . . . . . . 296
7.18
Inversion of Acoustic Waveforms . . . . . . . . . . . . . . . . . . . . 297
7.19
Using the Backus and Gilbert Method . . . . . . . . . . . . . . . . . . 304
7.20
The Coefﬁcients in the Backus and Gilbert Method . . . . . . . . . . . 308
7.21
The Norm Associated with the 1D Exponential Covariance
. . . . . . 308
7.22
The Norm Associated with the 1D Random Walk
. . . . . . . . . . . 311
7.23
The Norm Associated with the 3D Exponential Covariance
. . . . . . 313
References and References for General Reading
317
Index
333


Preface
Physical theories allow us to make predictions: given a complete description of a physical
system, we can predict the outcome of some measurements. This problem of predicting
the result of measurements is called the modelization problem, the simulation problem,
or the forward problem. The inverse problem consists of using the actual result of some
measurements to infer the values of the parameters that characterize the system.
While the forward problem has (in deterministic physics) a unique solution, the inverse
problem does not. As an example, consider measurements of the gravity ﬁeld around a
planet: given the distribution of mass inside the planet, we can uniquely predict the values
of the gravity ﬁeld around the planet (forward problem), but there are different distributions
of mass that give exactly the same gravity ﬁeld in the space outside the planet. Therefore,
the inverse problem — of inferring the mass distribution from observations of the gravity
ﬁeld — has multiple solutions (in fact, an inﬁnite number).
Becauseofthis, intheinverseproblem, oneneedstomakeexplicitanyavailableapriori
information on the model parameters. One also needs to be careful in the representation of
the data uncertainties.
The most general (and simple) theory is obtained when using a probabilistic point of
view, where the a priori information on the model parameters is represented by a probability
distribution over the ‘model space.’ The theory developed here explains how this a priori
probability distribution is transformed into the a posteriori probability distribution, by incor-
porating a physical theory (relating the model parameters to some observable parameters)
and the actual result of the observations (with their uncertainties).
To develop the theory, we shall need to examine the different types of parameters that
appear in physics and to be able to understand what a total absence of a priori information
on a given parameter may mean.
Although the notion of the inverse problem could be based on conditional probabilities
and Bayes’s theorem, I choose to introduce a more general notion, that of the ‘combination
of states of information,’ that is, in principle, free from the special difﬁculties appearing in
the use of conditional probability densities (like the well-known Borel paradox).
The general theory has a simple (probabilistic) formulation and applies to any kind of
inverse problem, including linear as well as strongly nonlinear problems. Except for very
simple examples, the probabilistic formulation of the inverse problem requires a resolution
in terms of ‘samples’ of the a posteriori probability distribution in the model space. This,
in particular, means that the solution of an inverse problem is not a model but a collection
of models (that are consistent with both the data and the a priori information). This is
xi

xii
Preface
why Monte Carlo (i.e., random) techniques are examined in this text. With the increasing
availability of computer power, Monte Carlo techniques are being increasingly used.
Some special problems, where nonlinearities are weak, can be solved using special,
very efﬁcient techniques that do not differ essentially from those used, for instance, by
Laplace in 1799, who introduced the ‘least-absolute-values’ and the ‘minimax’ criteria for
obtaining the best solution, or by Legendre in 1801 and Gauss in 1809, who introduced the
‘least-squares’ criterion.
The ﬁrst part of this book deals exclusively with discrete inverse problems with a
ﬁnite number of parameters. Some real problems are naturally discrete, while others contain
functions of a continuous variable and can be discretized if the functions under consideration
are smooth enough compared to the sampling length, or if the functions can conveniently be
described by their development on a truncated basis. The advantage of a discretized point of
view for problems involving functions is that the mathematics is easier. The disadvantage is
that some simpliﬁcations arising in a general approach can be hidden when using a discrete
formulation. (Discretizing the forward problem and setting a discrete inverse problem is
not always equivalent to setting a general inverse problem and discretizing for the practical
computations.)
The second part of the book deals with general inverse problems, which may contain
such functions as data or unknowns. As this general approach contains the discrete case in
particular, the separation into two parts corresponds only to a didactical purpose.
Although this book contains a lot of mathematics, it is not a mathematical book. It
tries to explain how a method of acquisition of information can be applied to the actual
world, and many of the arguments are heuristic.
This book is an entirely rewritten version of a book I published long ago (Tarantola,
1987). Developments in inverse theory in recent years suggest that a new text be proposed,
but that it should be organized in essentially the same way as my previous book. In this new
version, I have clariﬁed some notions, have underplayed the role of optimization techniques,
and have taken Monte Carlo methods much more seriously.
I am very indebted to my colleagues (Bartolomé Coll, Georges Jobert, Klaus
Mosegaard, Miguel Bosch, Guillaume Évrard, John Scales, Christophe Barnes, Frédéric
Parrenin, and Bernard Valette) for illuminating discussions. I am also grateful to my col-
laborators at what was the Tomography Group at the Institut de Physique du Globe de
Paris.
Albert Tarantola
Paris, June 2004

Chapter 1
The General Discrete
Inverse Problem
Far better an approximate answer to the right question,
which is often vague,
than an exact answer to the wrong question,
which can always be made precise.
John W. Tukey, 1962
Central to this chapter is the concept of the ‘state of information’ over a parameter
set. It is postulated that the most general way to describe such a state of information
is to deﬁne a probability density over the parameter space. It follows that the results of
the measurements of the observable parameters (data), the a priori information on model
parameters, and the information on the physical correlations between observable parameters
and model parameters can all be described using probability densities. The general inverse
problem can then be set as a problem of ‘combining’ all of this information. Using the point
of view developed here, the solution of inverse problems, and the analysis of uncertainty
(sometimes called ‘error and resolution analysis’), can be performed in a fully nonlinear
way (but perhaps with a large amount of computing time). In all usual cases, the results
obtained with this method reduce to those obtained from more conventional approaches.
1.1
Model Space and Data Space
Let S be the physical system under study. For instance, S can be a galaxy for an astro-
physicist, Earth for a geophysicist, or a quantum particle for a quantum physicist.
The scientiﬁc procedure for the study of a physical system can be (rather arbitrarily)
divided into the following three steps.
i) Parameterization of the system: discovery of a minimal set of model parameters
whose values completely characterize the system (from a given point of view).
1

2
Chapter 1. The General Discrete Inverse Problem
ii) Forward modeling: discovery of the physical laws allowing us, for given values of
the model parameters, to make predictions on the results of measurements on some
observable parameters.
iii) Inverse modeling: use of the actual results of some measurements of the observable
parameters to infer the actual values of the model parameters.
Strong feedback exists between these steps, and a dramatic advance in one of them
is usually followed by advances in the other two. While the ﬁrst two steps are mainly
inductive, the third step is deductive. This means that the rules of thinking that we follow
in the ﬁrst two steps are difﬁcult to make explicit. On the contrary, the mathematical theory
of logic (completed with probability theory) seems to apply quite well to the third step, to
which this book is devoted.
1.1.1
Model Space
The choice of the model parameters to be used to describe a system is generally not unique.
Example 1.1. An anisotropic elastic sample S is analyzed in the laboratory. To describe
its elastic properties, it is possible to use the tensor cij kℓ(x) of elastic stiffnesses relating
stress, σ ij(x) , to strain, εij(x) , at each point x of the solid:
σ ij(x) = cij
kℓ(x) εkℓ(x)
.
(1.1)
Alternatively, it is possible to use the tensor sij kℓ(x) of elastic compliances relating strain
to stress,
εij(x) = sij
kℓ(x) σ kℓ(x)
,
(1.2)
where the tensor s is the inverse of c , cij kℓskℓmn = δi
m δj
n . The use of stiffnesses or of
compliances is completely equivalent, and there is no ‘natural’ choice.
A particular choice of model parameters is a parameterization of the system. Two
different parameterizations are equivalent if they are related by a bijection (one-to-one
mapping).
Independently of any particular parameterization, it is possible to introduce an abstract
space of points, a manifold,1 each point of which represents a conceivable model of the
system. This manifold is named the model space and is denoted M . Individual models are
points of the model space manifold and could be denoted M1 , M2 , . . . (but we shall use
another, more common, notation).
For quantitative discussions on the system, a particular parameterization has to be
chosen. To deﬁne a parameterization means to deﬁne a set of experimental procedures
allowing, at least in principle, us to measure a set of physical quantities that characterize
the system. Once a particular parameterization has been chosen, with each point M of the
1The reader interested in the theory of differentiable manifolds may refer, for instance, to Lang (1962),
Narasimhan (1968), or Boothby (1975).

1.1. Model Space and Data Space
3
model space M a set of numerical values {m1, . . . , mn} is associated. This corresponds
to the deﬁnition of a system of coordinates over the model manifold M .
Example 1.2. If the elastic sample mentioned in Example 1.1 is, in fact, isotropic and ho-
mogeneous, the model manifold M is two-dimensional (as such a medium is characterized
by two elastic constants). As parameters to characterize the sample, one may choose, for
instance, {m1, m2} = { Young modulus , Poisson ratio } or {m1, m2} = { bulk modulus ,
shear modulus } . These two possible choices deﬁne two different coordinate systems over
the model manifold M .
Each point M of M is named a model, and, to conform to usual notation, we may
represent it using the symbol m . By no means is m to be understood as a vector, i.e., as
an element of a linear space. For the manifold M may be linear or not, and even when
the model space M is linear, the coordinates being used may not be a set of Cartesian
coordinates.
Example 1.3. Let us choose to characterize the elastic samples mentioned in Example 1.2
using the bulk modulus and the shear modulus, {m1, m2} = {κ, µ} . A convenient2 deﬁnition
of the distance between two elastic media is
d =
 
log κ2
κ1
2
+

log µ2
µ1
2
.
(1.3)
This clearly shows that the two coordinates {m1, m2} = {κ, µ} are not Cartesian. Intro-
ducing the logarithmic bulk modulus κ∗= log(κ/κ0) and the logarithmic shear modulus
µ∗= log(µ/µ0) (where κ0 and µ0 are arbitrary constants) gives
d =

(κ∗
2 −κ∗
1)2 + (µ∗
2 −µ∗
1)2
.
(1.4)
The logarithmic bulk modulus and the logarithmic shear modulus are Cartesian coordinates
over the model manifold M .
The number of model parameters needed to completely describe a system may be
either ﬁnite or inﬁnite. This number is inﬁnite, for instance, when we are interested in a
property { m(x) ; x ∈V } that depends on the position x inside some volume V .
The theory of inﬁnite-dimensional manifolds needs a greater technical vocabulary
than the theory of ﬁnite-dimensional manifolds. In what follows, and in all of the ﬁrst
part of this book, I assume that the model space is ﬁnite dimensional. This limitation to
systems with a ﬁnite number of parameters may be severe from a mathematical point of
view. For instance, passing from a continuous ﬁeld m(x) to a discrete set of quantities
mα = m(xα) by discretizing the space will only make sense if the considered ﬁelds are
smooth. If this is indeed the case, then there will be no practical difference between the
numerical results given by functional approaches and those given by discrete approaches to
2This deﬁnition of distance is invariant of form when changing these positive elastic parameters by their inverses,
or when multiplying the values of the elastic parameters by a constant. See Appendix 6.3 for details.

4
Chapter 1. The General Discrete Inverse Problem
inverse problem theory (although the numerical algorithms may differ considerably, as can
be seen by comparing the continuous formulation in sections 5.6 and 5.7 and the discrete
formulation in Problem 7.3).
Once we agree, in the ﬁrst part of this book, to deal only with a ﬁnite number of
parameters, it remains to decide if the parameters may take continuous or discrete values
(i.e., in fact, if the quantities are real numbers or integer numbers). For instance, if a
parameter mα represents the mass of the Sun, we can assume that it can take any value
from zero to inﬁnity; if mα represents the spin of a quantum particle, we can assume a priori
that it can only take discrete values. As the use of ‘delta functions’ allows us to consider
parameters taking discrete values as a special case of parameters taking continuous values,
we shall, to simplify the discussion, use the terminology corresponding to the assumption
that all the parameters under consideration take their values in a continuous set. If this is not
the case in a particular problem, the reader will easily make the corresponding modiﬁcations.
When a particular parameterization of the system has been chosen, each point of M
(i.e., each model) can be represented by a particular set of values for the model parameters
m = { mα } , where the index α belongs to some discrete ﬁnite index set. As we have
interpreted any particular parameterization of the physical system S as a choice of coor-
dinates over the manifold M , the variables mα can be named the coordinates of m , but
not the ‘components’ of m , unless a linear space can be introduced. But, more often than
not, the model space is not linear. For instance, when trying to estimate the geographical
coordinates {θ, ϕ} of the (center of the) meteoritic impact that killed the dinosaurs, the
model space M is the surface of Earth, which is intrinsically curved.
When it can be demonstrated that the model manifold M has no curvature, to intro-
duce a linear (vector) space still requires a proper deﬁnition of the ‘components’ of vectors.
When such a structure of linear space has been introduced, then we can talk about the linear
model space, denoted M , and, by deﬁnition, the sum of two models, m1 and m2 , corre-
sponds to the sum of their components, and the multiplication of a model by a real number
corresponds to the multiplication of all its components:3
(m1 + m2)α = m1
α + m2
α
,
( λ m )α = λ mα
.
(1.5)
Example1.4. Forinstance, intheelasticsolidconsideredinExample 1.3, tohaveastructure
of linear (vector) space, one must select an arbitrary point of the manifold {κ0, µ0} and
deﬁne the vector m = {m1, m2} whose components are
m1 = log(κ/κ0)
,
m2 = log(µ/µ0)
.
(1.6)
Then, the distance between two models, as deﬁned in Example 1.3, equals ∥m2 −m1 ∥,
the norm here being understood in its ordinary sense (for vectors in a Euclidean space).
One must keep in mind, however, that the basic deﬁnitions of the theory developed
here will not depend in any way on the assumption of the linearity of the model space. We
are about to see that the only mathematical objects to be deﬁned in order to deal with the most
general formulation of inverse problems are probability distributions over the model space
3The index α in equation (1.5) may just be a shorthand notation for a multidimensional index (see an example
in Problem 7.3). For details of array algebra see Snay (1978) or Rauhala (2002).

1.1. Model Space and Data Space
5
manifold. A probability over M is a mapping that, with any subset A of M , associates
a nonnegative real number, P(A) , named the probability of A , with P(M) = 1 . Such
probability distributions can be deﬁned over any ﬁnite-dimensional manifold M (curved
or linear) and irrespective of any particular parameterization of M , i.e., independently of
any particular choice of coordinates. But if a particular coordinate system {mα} has been
chosen, it is then possible to describe a probability distribution using a probability density
(and we will make extensive use of this possibility).
1.1.2
Data Space
To obtain information on model parameters, we have to perform some observations dur-
ing a physical experiment, i.e., we have to perform a measurement of some observable
parameters.4
Example 1.5. For a nuclear physicist interested in the structure of an atomic particle,
observations may consist in a measurement of the ﬂux of particles diffused at different
angles for a given incident particle ﬂux, while for a geophysicist interested in understanding
Earth’s deep structure, observations may consist in recording a set of seismograms at
Earth’s surface.
We can thus arrive at the abstract idea of a data space, which can be deﬁned as the
space of all conceivable instrumental responses. This corresponds to another manifold, the
data manifold (or data space), which we may represent by the symbol D . Any conceiv-
able (exact) result of the measurements then corresponds to a particular point D on the
manifold D .
As was the case with the model manifold, it shall sometimes be possible to endow the
data space with the structure of a linear manifold. When this is the case, then we can talk
about the linear data space, denoted by D ; the coordinates d = { di } (where i belongs
to some discrete and ﬁnite index set) are then components,5 and, as usual,
(d1 + d2)i = d1
i + d2
i
,
( r d )i = r di
.
(1.7)
Each possible realization of d is then named a data vector.
1.1.3
Joint Manifold
The separation suggested above between the model parameters {mα} and the data parame-
ters {di} is sometimes clear-cut. In other circumstances, this may require some argumen-
tation, or may not even be desirable. It is then possible to introduce one single manifold
X that represents all the parameters of the problem. A point of the manifold X can be
represented by the symbol X and a system of coordinates by {xA} .
4The task of experimenters is difﬁcult not only because they have to perform measurements as accurately
as possible, but, more essentially, because they have to imagine new experimental procedures allowing them to
measure observable parameters that carry a maximum of information on the model parameters.
5As mentioned above for the model space, the index i here may just be a shorthand notation for a multidimen-
sional index (see an example in Problem 7.3).

6
Chapter 1. The General Discrete Inverse Problem
As the quantities {di} were termed observable parameters and the quantities {mα}
were termed model parameters, we can call {xA} the physical parameters or simply the
parameters. The manifold X is then named the parameter manifold .
1.2
States of Information
The probability theory developed here is self-sufﬁcient. For good textbooks with some
points in common with the present text, see Jeffreys (1939) and Jaynes (2003).
1.2.1
Deﬁnition of Probability
We are going to work with a ﬁnite-dimensional manifold X (for instance, the model or
the data space) and the ﬁeld of all its subsets A , B, . . . . These subsets can be individual
points, disjoint collections of points, or contiguous collections of points (whole regions of
the manifold X ). As is traditional in probability theory, a subset A ⊆X is called an event.
The union and the intersection of two events A and B are respectively denoted A∪B and
A ∩B .
The ﬁeld of events is called, in technical terms, a σ-ﬁeld, meaning that the complement
of an event is also an event. The notion of a σ-ﬁeld could allow us to introduce probability
theory with great generality, but we limit ourselves here to probabilities deﬁned over a
ﬁnite-dimensional manifold.
By deﬁnition, a measure over the manifold X is an application P( · ) that with any
event A of X associates a real positive number P(A) , named the measure of A , that
satisﬁes the following two properties (Kolmogorov axioms):
• If A and B are two disjoint events, then
P(A ∪B) = P(A) + P(B)
.
(1.8)
• There is continuity at zero, i.e., if a sequence A1 ⊇A2 ⊇· · · tends to the empty set,
then P (Ai) →0 .
This last condition implies that the probability of the empty event is zero,
P( ∅) = 0
,
(1.9)
and it immediately follows from condition (1.8) that if the two events A and B are not
necessarily disjoint, then
P(A ∪B) = P(A) + P(B) −P(A ∩B)
.
(1.10)
The probability of the whole manifold, P(X) , is not necessarily ﬁnite. If it is, then P
is termed a probability over X . In that case, P is usually normalized to unity: P(X) = 1 .
In what follows, the term ‘probability’ will be reserved for a value, like P(A) for the
probability of A . The function P( · ) itself will rather be called a probability distribution.
An important notion is that of a sample of a distribution, so let us give its formal
deﬁnition. A randomly generated point P ∈X is a sample of a probability distribution

1.2. States of Information
7
P ( · ) if the probability that the point P is generated inside any A ⊂X equals P(A) , the
probability of A . Two points P and Q are independent samples if (i) both are samples and
(ii) the generation of the samples is independent (i.e., if the actual place where each point
has materialized is, by construction, independent of the actual place where the other point
has materialized).6
Let P be a probability distribution over a manifold X and assume that a particular
coordinate system x = {x1, x2, . . . } has been chosen over X . For any probability distri-
bution P , there exists (Radon–Nikodym theorem) a positive function f (x) such that, for
any A ⊆X , P(A) can be obtained as the integral
P(A) =

A
dx f (x)
,
(1.11)
where

A
dx ≡

dx1

dx2 · · ·


	
over A
.
(1.12)
Then, f (x) is termed the probability density representing P (with respect to the given
coordinate system). The functions representing probability densities may, in fact, be distri-
butions, i.e., generalized functions containing in particular Dirac’s delta function.
Example 1.6. Let X be the 2D surface of the sphere endowed with a system of spherical
coordinates {θ, ϕ} . The probability density
f (θ, ϕ) = sin θ
4 π
(1.13)
associates with every region A of X a probability that is proportional to the surface of A .
Therefore, the probability density f (θ, ϕ) is ‘homogeneous’ (although the function does
not take constant values).
Example 1.7. Let X = R+ be the positive part of the real line, and let f (x) be the function
1/x . The integral P(x1 < x < x2) =

 x2
x1 dx f (x) then deﬁnes a measure over X , but
not a probability (because P(0 < x < ∞) = ∞) . The function f (x) is then a measure
density but not a probability density.
To develop our theory, we will effectively need to consider nonnormalizable measures
(i.e., measures that are not a probability). These measures cannot describe the probability
of a given event A : they can only describe the relative probability of two events A1 and
A2 . We will see that this is sufﬁcient for our needs. To simplify the discussion, we will
sometimes use the linguistic abuse of calling probability a nonnormalizable measure.
It should be noticed that, as a probability is a real number, and as the parameters
x1, x2, . . . in general have physical dimensions, the physical dimension of a probability
6Many of the algorithms used to generate samples in large-dimensional spaces (like the Gibbs sampler of the
Metropolis algorithm) do not provide independent samples.

8
Chapter 1. The General Discrete Inverse Problem
density is a density of the considered space, i.e., it has as physical dimensions the inverse
of the physical dimensions of the volume element of the considered space.
Example 1.8. Let v be a velocity and m be a mass. The respective physical dimensions
are L T −1 and M . Let f (v, m) be a probability density on (v, m) . For the probability
P ( v1 ≤v ≤v2 and m1 ≤m ≤m2 ) =
 v2
v1
dv
 m2
m1
dm f (v, m)
(1.14)
to be a real number, the physical dimensions of f have to be M−1L−1T .
Let P be a probability distribution over a manifold X and f (x) be the probability
density representing P in a given coordinate system. Let
x∗= x∗(x)
(1.15)
represent a change of coordinates over X , and let f ∗(x∗) be the probability density repre-
senting P in the new coordinates:
P(A) =

A
dx∗f ∗(x∗)
.
(1.16)
By deﬁnition of f (x) and f ∗(x∗) , for any A ⊆X ,

A
dx f (x) =

A
dx∗f ∗(x∗)
.
(1.17)
Using the elementary properties of the integral, the following important property (called the
Jacobian rule) can be deduced:
f ∗(x∗) = f (x)

∂x
∂x∗

,
(1.18)
where |∂x/∂x∗| represents the absolute value of the Jacobian of the transformation. See
Appendix 6.3 for an example of the use of the Jacobian rule.
Instead of introducing a probability density, we could have introduced a volumetric
probability that would be an invariant (not subjected to the Jacobian rule). See Appendix 6.1
for some details.
1.2.2
Interpretation of a Probability
It is possible to associate more than one intuitive meaning with any mathematical theory. For
instance, the axioms and theorems of a three-dimensional vector space can be interpreted
as describing the physical properties of the sum of forces acting on a material particle as
well as the physiological sensations produced in our brain when our retina is excited by a
light composed of a mixing of the three fundamental colors. Hofstadter (1979) gives some
examples of different valid intuitive meanings that can be associated with a given formal
system.

1.2. States of Information
9
There are two different usual intuitive interpretations of the axioms and deﬁnitions of
probability as introduced above.
The ﬁrst interpretation is purely statistical: when some physical random process takes
place, it leads to a given realization. If a great number of realizations have been observed,
these can be described in terms of probabilities, which follow the axioms above. The
physical parameter allowing us to describe the different realizations is termed a random
variable. The mathematical theory of statistics is the natural tool for analyzing the outputs
of a random process.
The second interpretation is in terms of a subjective degree of knowledge of the ‘true’
value of a given physical parameter. By subjective we mean that it represents the knowledge
of a given individual, obtained using rigorous reasoning, but that this knowledge may vary
from individual to individual because each may possess different information.
Example 1.9. What is the mass of Earth’s metallic core? Nobody knows exactly. But
with the increasing accuracy of geophysical measurements and theories, the information we
have on this parameter improves continuously. The opinion maintained in this book is that
the most general (and scientiﬁcally rigorous) answer it is possible to give at any moment
to that question consists of deﬁning the probability of the actual value of the mass m of
Earth’s core being within m1 and m2 for any couple of values m1 and m2 . That is to say,
the most general answer consists of the deﬁnition of a probability density over the physical
parameter m representing the mass of the core.
This subjective interpretation of the postulates of probability theory is usually named
Bayesian, in honor of Bayes (1763). It is not in contradiction with the statistical interpreta-
tion. It simply applies to different situations.
One of the difﬁculties of the approach is that, given a state of information on a set of
physical parameters, it is not always easy to decide which probability models it best. I hope
that the examples in this book will help to show that it is possible to use some commonsense
rules to give an adequate solution to this problem.
I set forth explicitly the following principle:
Let X be a ﬁnite-dimensional manifold representing some physical parameters. The
most general way we have to describe any state of information on X is by deﬁning a
probability distribution (or, more generally, a measure distribution) over X .
Let P ( · ) denote the probability distribution corresponding to a given state of infor-
mation over a manifold X and x →f (x) denote the associated probability density:
P(A) =

A
dx f (x)
( for any A ⊆X )
.
(1.19)
The probability distribution P( · ) or the probability density f ( · ) is said to represent the
corresponding state of information.
1.2.3
Delta Probability Distribution
Consider a manifold X and denote as x = {x1, x2, . . . } any of its points. If we deﬁnitely
know that only x = x0 is possible, we can represent this state of information by a (Dirac)

10
Chapter 1. The General Discrete Inverse Problem
delta function centered at point x0 :
f (x) = δ(x; x0)
(1.20)
(in the case where the manifold X is a linear space X , we can more simply write f (x) =
δ(x −x0) ).
This probability density gives null probability to x ̸= x0 and probability 1 to x = x0 .
In typical inference problems, the use of such a state of information does not usually make
sense in itself, because all our knowledge of the real world is subject to uncertainties, but it
is often justiﬁed when a certain type of uncertainty is negligible when compared to another
type of uncertainty (see, for instance, Examples 1.34 and 1.35, page 34).
1.2.4
Homogeneous Probability Distribution
Let us now assume that the considered manifold X has a notion of volume, i.e., that
independently of any probability deﬁned over X , we are able to associate with every domain
A ⊆X its volume V (A) . Denoting by
dV (x) = v(x) dx
(1.21)
the volume element of the manifold in the coordinates x = {x2, x2, . . . } , we can write the
volume of a region A ⊆X as
V (A) =

A
dx v(x)
.
(1.22)
The function v(x) can be called the volume density of the manifold in the coordinates
x = {x1, x2, . . . } .
Assume ﬁrst that the total volume of the manifold, say V , is ﬁnite, V =

X dx v(x) .
Then, the probability density
µ(x) = v(x) / V
(1.23)
is normalized and it associates with any region A ⊆X a probability
M(A) =

A
dx µ(x)
(1.24)
that is proportional to the volume V (A) . We shall reserve the letter M for this probability
distribution. The probability M , and the associated probability density µ(x) , shall be
calledhomogeneous . Thereadershouldalwaysrememberthatthehomogeneousprobability
density does not need to be constant (see Example 1.6 on page 7).
Once a notion of volume has been introduced over a manifold X , one usually requires
that any probability distribution P( · ) to be considered over X satisfy one consistency
requirement: that the probability P(A) of any event A ⊆X that has zero volume, V (A) =
0 , must have zero probability, P(A) = 0 . On the probability densities, this imposes at any
point x the condition
µ(x) = 0
⇒
f (x) = 0
.
(1.25)

1.2. States of Information
11
Using mathematical jargon, all the probability densities f (x) to be considered must be
absolutely continuous with respect to the homogeneous probability density µ(x) .
If the manifold under consideration has an inﬁnite volume, then equation (1.23) cannot
be used to deﬁne a probability density. In this case, we shall simply take µ(x) proportional
to v(x) , and the homogeneous probability distribution is not normalizable. As we shall
see, this generally causes no problem.
To deﬁne a notion of volume over an abstract manifold, one may use some invariance
considerations, as the following example illustrates.
Example 1.10. The elastic properties of an isotropic homogeneous medium were mentioned
in Example 1.3 using the bulk modulus (or incompressibility modulus) and the shear mod-
ulus, {κ, µ} , and a distance over the 2D manifold was proposed that is invariant of form
when changing these positive elastic parameters by their inverses, or when multiplying the
values of the elastic parameters by a constant. Associated with this deﬁnition of distance
is the (2D) volume element7 dV (κ, µ) = (dκ/κ) (dµ/µ) , i.e., the (2D) volume density
v(κ, µ) = 1/(κ µ) . Therefore, the (nonnormalizable) homogeneous probability density is
µ(κ, µ) = 1 / (κ µ)
.
(1.26)
Changing the two parameters by their inverses, γ = 1/κ and ϕ = 1/µ , and using
the Jacobian rule (equation (1.18)), we obtain the new expression for the homogeneous
probability density:
µ∗(γ, ϕ) = 1 / (γ ϕ)
.
(1.27)
Of course, the invariance of form of the distance translates into this invariance of form for
the homogeneous probability density.
In Bayesian inference for continuous parameters, the notion of ‘noninformative prob-
ability density’ is commonly introduced (see Jaynes, 1939; Box and Tiao, 1973; Rietsch,
1977; Savage, 1954, 1962), which usually results in some controversy. Here I claim that,
more often than not, a homogeneous probability density can be introduced. Selecting this
one as an a priori probability distribution to be used in a Bayesian argument is a choice
that must be debated. I acknowledge that this choice is as informative as any other, and the
‘noninformative’ terminology is, therefore, not used here.8
Example 1.10 suggests that the probability density
f (x) = 1 / x
(1.28)
plays an important role. Note that taking the logarithm of the parameter,
x∗= α log(x/x0)
,
(1.29)
transforms the probability density into a constant one,
f ∗(x∗) = const
.
(1.30)
7See Appendix 6.3 for details.
8It was used in the ﬁrst edition of this book, which was a mistake.

12
Chapter 1. The General Discrete Inverse Problem
It is shown in Appendix 6.7 that the probability density 1/x is a particular case of the log-
normal probability density. Parameters accepting probability densities like the log-normal
or its limit, the 1/x density, were discussed by Jeffreys (1957, 1968). These parameters
have the characteristic of being positive and of being as popular as their inverses. We call
them Jeffreys parameters. For more details, see Appendix 6.2.
No coherent inverse theory can be set without the introduction of the homogeneous
probability distribution. From a practical point of view, it is only in highly degenerated
inverse problems that the particular form of µ(x) plays a role.
If f (x) is a probability density and µ(x) is the homogeneous probability density,
the ratio
ϕ(x) = f (x) / µ(x)
(1.31)
plays an important role.9 The function ϕ(x) , which is not a probability density,10 shall be
called a likelihood or a volumetric probability.
1.2.5
Shannon’s Measure of Information Content
Given two normalized probability densities f1(x) and f2(x) , the relative information
content of f1 with respect to f2 is deﬁned by
I(f1; f2) =

X
dx f1(x) log f1(x)
f2(x)
.
(1.32)
When the logarithm base is 2 , the unit of information is termed a bit; if the base is e =
2.71828 . . . , the unit is the nep; if the base is 10, the unit is the digit.
When the homogeneous probability density µ(x) is normalized, one can deﬁne the
relative information content of a probability density f (x) with respect to µ(x) :
I(f; µ) =

dx f (x) log f (x)
µ(x)
.
(1.33)
We shall simply call this the information content of f (x) . This expression generalizes
Shannon’s (1948) original deﬁnition for discrete probabilities, 
i Pi log Pi , to probability
densities.11 It can be shown that the information content is always positive,
I(f; µ) ≥0
,
(1.34)
and that it is null only if f (x) ≡µ(x) , i.e., if f (x) is the homogeneous state of information.
9For instance, the maximum likelihood point is the point where ϕ(x) is maximum (see section 1.6.4), and the
Metropolis sampling method, when used to sample f (x) (see section 2.3.5), depends on the values of ϕ(x) .
10When changing variables, the ratio of two probability densities is an invariant not subject to the Jacobian rule.
11Note that the expression

X dx f (x) log f (x) could not be used as a deﬁnition. Besides the fact that the
logarithm of a dimensional quantity is not deﬁned, a bijective change of variables x∗= x∗(x) would al-
ter the information content, which is not the case with the right deﬁnition (1.33). For let f (x) be a prob-
ability density representing a given state of information on the parameters x .
The information content of
f (x) has been deﬁned by equation (1.33), where µ(x) represents the homogeneous state of information. If
instead of the parameters x we decide to use the parameters x∗
=
x∗(x) , the same state of informa-
tion is described in the new variables by (expression (1.18)), f ∗(x∗) = f (x) | ∂x / ∂x∗| , while the refer-
ence state of information is described by µ∗(x∗) = µ(x) | ∂x / ∂x∗| , where |∂x/∂x∗| denotes the absolute
value of the Jacobian of the transformation. A computation of the information content in the new variables
gives I(f∗; µ∗) =

dx∗f ∗(x∗) log( f ∗(x∗) / µ∗(x∗) ) =

dx∗| ∂x / ∂x∗| f (x) log( f (x) / µ(x) ) , and, using
dx∗| ∂x / ∂x∗| = dx , we directly obtain I(f∗; µ∗) = I(f; µ) .

1.2. States of Information
13
1.2.6
Two Basic Operations on Probability Distributions
Inference theory is usually developed by ﬁrst introducing the notion of conditional prob-
ability, then demonstrating a trivial theorem (the Bayes theorem), and then charging this
theorem with a (nontrivial) semantic content involving ‘prior’ and ‘posterior’ probabilities.
Although there is nothing wrong with that approach, I prefer here to use the alternative
route of introducing some basic structure to the space of all probability distributions (the
space characterized by the Kolmogorov axioms introduced in section 1.2.1). This structure
consists of deﬁning two basic operations among probability distributions that are a general-
ization of the logical ‘or’ and ‘and’ operations among propositions. Although this approach
is normal in the theory of fuzzy sets, it is not usual in probability theory.12
Then, letting X be a ﬁnite-dimensional manifold, and given two probability distri-
butions P1 and P2 over X , we shall deﬁne the disjunction P1 ∨P2 (to be read P1 or
P2 ) and the conjunction P1 ∧P2 (to be read P1 and P2 ). Taking inspiration from the
operations between logical propositions, we shall take as the ﬁrst set of deﬁning properties
the condition that, for any event A ⊆X ,
P1(A) ̸= 0
or
P2(A) ̸= 0
⇒
(P1 ∨P2)(A) ̸= 0
,
P1(A) = 0
or
P2(A) = 0
⇒
(P1 ∧P2)(A) = 0
.
(1.35)
In other words, for the disjunction (P1 ∨P2)(A) to be different from zero, it is enough
that any of the two (or both) P1(A) or P2(A) be different from zero. For the conjunction
(P1 ∧P2)(A) to be zero, it is enough that any of the two (or both) P1(A) or P2(A) be
zero.
The two operations must be commutative,13
P1 ∨P2 = P2 ∨P1
,
P1 ∧P2 = P2 ∧P1
,
(1.36)
and the homogeneous measure distribution M must be neutral for the conjunction operation,
i.e., for any P ,
P ∧M = P
.
(1.37)
As suggested in Appendix 6.17, if f1(x) , f2(x) , and µ(x) are the probability den-
sities representing P1 , P2 , and M , respectively,
P1(A) =

A
dx f1(x)
,
P2(A) =

A
dx f2(x)
,
M(A) =

A
dx µ(x) ,
(1.38)
and (f1 ∨f2)(x) and (f1 ∧f2)(x) are the probability densities representing respectively
P1 ∨P2 and P1 ∧P2 ,
(P1 ∨P2)(A) =

A
dx (f1 ∨f2)(x)
,
(P1 ∧P2)(A) =

A
dx (f1 ∧f2)(x) ,
(1.39)
12A fuzzy set (Zadeh, 1965) is characterized by a membership function f (x) that is similar to a probability
density, except that it takes values in the interval [0, 1] (and its interpretation is different).
13The compact writing of these equations of course means that the properties are assumed to be valid for any
A ⊆X . For instance, the expression P1 ∨P2 = P2 ∨P1 means that, for any A , (P1 ∨P2)(A) = (P2 ∨P1)(A) .

14
Chapter 1. The General Discrete Inverse Problem
then the simplest solution to the axioms above is14
(f1 ∨f2)(x) =
1
2 ( f1(x) + f2(x) )
;
(f1 ∧f2)(x) = 1
ν
f1(x) f2(x)
µ(x)
,
(1.40)
where ν is the normalization constant15 ν =

X dx f1(x) f2(x)
µ(x)
.
These two operations bear some resemblance to the union and intersection of fuzzy
sets16 and to the ‘or’ and ‘and’ operations introduced in multivalued logic,17 but are not
identical (in particular, there is nothing like µ(x) in fuzzy sets or in multivalued logic).
The notion of the conjunction of states of information is related to the problem of aggregating
expert opinions (Bordley, 1982; Genest and Zidek, 1986; Journel, 2002).
The conjunction operation is naturally associative, and one has
(f1 ∧f2 ∧· · · ∧fn)(x)
µ(x)
= 1
ν
f1(x)
µ(x)
f2(x)
µ(x) . . . f2(x)
µ(x)
,
(1.41)
where ν =

X dx f1(x)
µ(x)
f2(x)
µ(x) . . . f2(x)
µ(x) . But, under the normalized form proposed in equa-
tion (1.40), the disjunction is not associative. So, for more generality, we can take the
deﬁnition
(f1 ∨f2 ∨· · · ∨fn)(x) =
1
n ( f1(x) + f2(x) + · · · + fn(x) )
.
(1.42)
Example 1.11. Disjunction of probabilities (making histograms). Let r and ϕ be polar
coordinates on a cathodic screen. Imagine that a device projects an electron onto the screen
and we do our best to measure the (polar) coordinates of the impact point. Because of the
ﬁnite accuracy of our measuring instrument, we cannot exactly know the coordinates of the
actual impact point, but we can propose a probability density f (r, ϕ) for the coordinates of
this impact point. Now, instead of a single electron, the device sequentially (and randomly)
projects a large number of electrons, according to a probability density g(r, ϕ) that is
unknown to us. For each impact point, our measuring instrument provides a probability
density, so we have the (large) collection f1(r, ϕ) , f2(r, ϕ), . . . , fn(r, ϕ) of probability
densities. The normalized disjunction h(r, ϕ) = 1
n ( f1(r, ϕ) ∨f2(r, ϕ) ∨· · · ∨fn(r, ϕ) ) ,
i.e., the sum h(r, ϕ) = 1
n ( f1(r, ϕ) + f2(r, ϕ) + · · · + fn(r, ϕ) ) , is a rough estimation of
the unknown probability density g(r, ϕ) in much the same way as an ordinary histogram
(where the impact points are counted inside some ad hoc “boxes”) would be. In the limit
when n →∞and the functions fi(r, ϕ) tend to be inﬁnitely sharp, h(r, ϕ) →g(r, ϕ) .
Example 1.12. Conjunction of probabilities (I). An estimation of the position of a ﬂoating
object at the surface of the sea by an airplane navigator gives a probability distribution for
14The conjunction of states of information was ﬁrst introduced by Tarantola and Valette (1982a).
15This is only deﬁned if the product f1(x) f2(x) is not zero everywhere.
16If f1(x) and f2(x) arethemembershipfunctionscharacterizingtwofuzzysets, theirunion andintersection are
respectively deﬁned (Zadeh, 1965) by the membership functions max( f1(x) , f2(x) ) and min( f1(x) , f2(x) ) .
17Multivalued logic typically uses the notion of triangular conorm (associated with the “or” operation) and the
triangular norm (associated with the “and” operation). They were introduced by Schweizer and Sklar (1963).

1.2. States of Information
15
the position of the object corresponding to the probability density f (ϕ, λ) , where {ϕ, λ} are
the usual geographical coordinates (longitude and latitude). An independent, simultaneous
estimation of the position by another airplane navigator gives a probability distribution
corresponding to the probability density g(ϕ, λ) . How should the two probability densities
f (ϕ, λ) and g(ϕ, λ) be combined to obtain a resulting probability density? The answer is
given by the conjunction of the two probability densities,
(f ∧g)(ϕ, λ) = 1
ν
f (ϕ, λ) g(ϕ, λ)
µ(ϕ, λ)
,
(1.43)
where µ(ϕ, λ) = (cos λ)/(4πR2) is the homogeneous probability density on the surface
of the sphere and ν is the normalization constant ν =

 +π
−π dϕ

 +π/2
−π/2 dλ f (ϕ,λ) g(ϕ,λ)
µ(ϕ,λ)
.
Example 1.13. Conjunction of probabilities (II). Consider a situation similar to that in
Example 1.11, but where the actual probability density for the impact points g(r, ϕ) is
exactly known (or has been estimated as suggested in the example). We are interested in
knowing, as precisely as possible, the coordinates of the next impact point. Again, when
the point materializes, the ﬁnite accuracy of our measuring instrument only provides the
probability density f (r, ϕ) . How can we combine the two probability densities f (r, ϕ) and
g(r, ϕ) in order to have better information on the impact point? For the same reasons that
the notion of conditional probabilities is used to update probability distributions (see below),
here the updated version of the probability density f (r, ϕ) is the normalized conjunction
(expression at right in equation (1.40))
f ′(r, ϕ) = k f (r, ϕ) g(r, ϕ)
µ(r, ϕ)
,
(1.44)
where k is a normalization constant and µ(r, ϕ) is the homogeneous probability density
in polar coordinates18 ( µ(r, ϕ) = const. r ). A numerical illustration of this example is
developed in Problem 7.9.
While the Kolmogorov axioms deﬁne the space E of all possible probability distri-
butions (over a given manifold), these two basic operations, conjunction and disjunction,
furnish E with the structure to be used as the basis of all inference theory.
1.2.7
Conditional Probability
Rather than introduce the notion of conditional probability as a primitive notion of the theory,
I choose to obtain it here as a special case of the conjunction of probability distributions. To
make this link, we need to introduce a quite special probability distribution, the ‘probability-
event.’
An event A corresponds to a region of the manifold X . If P , Q , . . . are proba-
bility distributions over X , characterized by the probability densities f (x) , g(x) , . . . , the
probabilities P(A) =

A dx f (x) , Q(A) =

A dx g(x) , . . . are deﬁned. To any event
A ⊆X we can attach a particular probability distribution that we shall denote MA . It can
18The surface element of the Euclidean 2D space in polar coordinates is dS(r, ϕ) = r dr dϕ , from which
µ(r, ϕ) = k r follows using expression (1.23) (see also the comments following that equation).

16
Chapter 1. The General Discrete Inverse Problem
be characterized by a probability density µA(x) deﬁned as follows ( k being a possible
normalization constant):
µA(x) =

k µ(x)
if
x ∈A
,
0
otherwise
.
(1.45)
In other words, µA(x) equals zero everywhere except inside A , where it is proportional
to the homogeneous probability density µ(x) . The probability distribution MA so deﬁned
associates with any event B ⊆X the probability MA(B) =

B dx µA(x) (because µ(x)
is related to the volume element of X , the probability MA(B) is proportional to the volume
of A ∩B ). While A ⊆X is called an event, the probability distribution MA shall be
called a probability-event, or, for short, a p-event. See a one-dimensional illustration in
Figure 1.1.
Figure 1.1.
The homogeneous probability density for a Jeffreys parameter is
f (x) = 1/x (left). In the middle is the event 2 ≤x ≤4 . At the right is the probability-
event (p-event) associated with this event. While the homogeneous probability density (at
left) cannot be normalized, the p-event (at right) has been normalized to one.
We can now set the following deﬁnition.
Deﬁnition. Let B be an event of the manifold X and MB be the associated p-event.
Let P be a probability distribution over X . The conjunction of P and MA , i.e., the
probability distribution (P ∧MB) , shall be called the conditional probability distribution
of P given B .
Using the characterization (at right in equation (1.40)) for the conjunction of prob-
ability distributions, it is quite easy to ﬁnd an expression for (P ∧MB) . For the given
B ⊆X , and for any A ⊆X , one ﬁnds
(P ∧MB)(A) = P(A ∩B)
P(B)
,
(1.46)
an expression that is valid provided P(B) ̸= 0 .
The demonstration is provided as a
footnote.19
19Let us introduce the probability density f (x) representing P , the probability density µB(x) representing
MB , and the probability density g(x) representing P ∧MB . It then follows, from the expression at right in
equation (1.40), that g(x) = k f (x) µB(x) / µ(x) , i.e., because of the deﬁnition of a p-event (equation (1.45)),
g(x) = k f (x) if x ∈B and g(x) = 0 if x /∈B . The normalizing constant k is (provided the expression is ﬁnite)
k = 1/

B dx f (x) = 1/P(B) . We then have, for any A ⊆X (and for the given B ⊆X ), (P ∧MB)(A) =

A dx g(x) = k

A∩B dx f (x) = k P(A ∩B) , from which expression (1.46) follows (using the value of k just
obtained).

1.2. States of Information
17
The expression on the right-hand side is what is usually taken as the deﬁnition of
conditional probability density and is usually denoted P(A | B) :
P(A | B) ≡P(A ∩B)
P(B)
.
(1.47)
Therefore, we have arrived at the property that, for any A and B ,
(P ∧MB)(A) = P(A | B)
.
(1.48)
This shows that the notion of the conditional probability distribution is a special case of
the notion of the conjunction of probability distributions. The reverse is not true (one
cannot obtain the conjunction of probability distributions as a special case of conditional
probabilities). As suggested in Figure 1.2, while conditioning a probability distribution to a
  
Figure 1.2. In this ﬁgure, probability distributions are assumed to be deﬁned over
a two-dimensional manifold and are represented by the level lines of their probability densi-
ties. In the top row, left, is a probability distribution P( · ) that with any event A associates
the probability P(A) . In the middle is a particular event B , and at the right is the con-
ditional probability distribution P( · |B) (that with any event A associates the probability
P ( A |B) ). The probability density representing P( · |B) is the same as that representing
P ( · ) , except that values outside B are set to zero (and it has been renormalized). In the
bottom row are a probability distribution P( · ) , a second probability distribution Q( · ) ,
and their conjunction (P ∧Q)( · ) . Should we have chosen for the probability distribution
Q( · ) the p-event associated with B , the two right panels would have been identical. The
notion of the conjunction of probability distribution generalizes that of conditional proba-
bility in that the conditioning can be made using soft bounds. To generate this ﬁgure, the two
probability densities P( · ) and Q( · ) have been chosen log-normal (see Appendix 6.7).
Then, (P ∧Q)( · ) happens also to be log-normal.

18
Chapter 1. The General Discrete Inverse Problem
given event corresponds to adding some ‘hard bounds,’ the conjunction of two probability
distributions allows the possible use of ‘soft’ bounds. This better corresponds to typical
inference problems, where uncertainties may be present everywhere.
In section 1.5.1,
the conjunction of states of information is used to combine information obtained from
measurements with information provided by a physical theory and is shown to be the basis
of the inverse problem theory.
Equation (1.47) can, equivalently, be written P(A ∩B) = P(A | B) P(B) . In-
troducing the conditional probability distribution P(A | B) would lead to P(A ∩B) =
P (B | A) P(A) , and equating the two last expressions leads to the Bayes theorem
P(B | A) = P(A | B) P(B)
P(A)
.
(1.49)
It is sometimes said that this equation expresses the probability of the causes.20 Again,
although inverse theory could be based on Bayes theorem, we will use here the notion of
the conjunction of probabilities.
To be complete, let me mention here that two events A and B are said to be inde-
pendent with respect to a probability distribution P( · ) if
P(A ∩B) = P(A) P(B)
.
(1.50)
It then immediately follows that P(A | B) = P(A) and P(B | A) = P(B) : the conditional
probabilities equal the unconditional ones (hence the term “independent” for A and B ). Of
course, if A and B are independent with respect to a probability distribution P( · ) , they
will not, in general, be independent with respect to another probability distribution Q( · ) .
1.2.8
Marginal and Conditional Probability Density
Let U and V be two ﬁnite-dimensional manifolds with points respectively denoted u =
{u1, u2 , . . . } and v = {v1, v2 , . . . } , and let W = U × V be the Cartesian product
of the two manifolds, i.e., the manifold whose points are of the form w = {u, v} =
{u1, u2 , . . . , v2, v2, . . . } .
A probability over W is represented by a probability den-
sity f (w) = f (u, v) that is here assumed to be normalized,

U du

V dv f (u, v) =

V dv

U du f (u, v) = 1 .
In this situation, one can introduce the two marginal probability densities
fV(v) =

U
du f (u, v)
,
fU(u) =

V
dv f (u, v)
,
(1.51)
which are normalized via

V
dv fV(v) = 1
,

U
du fU(u) = 1
.
(1.52)
20Assume we know the (unconditional) probabilities P(A) and P(B) and the conditional probability P(A | B)
for the effect A given the cause B (these are the three terms at the right in expression (1.49)). If the effect A is
observed, the Bayes formula gives the probability P(B | A) for B being the cause of the effect A .

1.2. States of Information
19
The variables u and v are said to be independent if the joint probability density equals the
product of the two marginal probability densities:
f (u, v) = fU(u) fV(v)
.
(1.53)
The interpretation of the marginal probability densities is as follows. Assume there is a
probability density f (w) = f (u, v) from which a (potentially inﬁnite) sequence of random
points (samples) w1 = {u1, v1} , w2 = {u2, v2} , . . . is generated. By deﬁnition, this
sequence deﬁnes the two sequences u1 , u2 , . . . and v1 , v2 , . . . . Then, the ﬁrst sequence
constitutes a set of samples of the marginal probability density fU(u) , while the second
sequence constitutes a set of samples of the marginal probability density fV(v) . Note that
generating a set u1 , u2 , . . . of samples of fU(u) and (independently) a set v1 , v2 , . . .
of samples of fV(v) , and then building the sequence w1 = {u1, v1} , w2 = {u2, v2} , . . . ,
does not provide a set of samples of the joint probability density f (w) = f (u, v) unless
the two variables are independent, i.e., unless the property (1.53) holds.
To distinguish the original probability density f (u, v) from its two marginals fU(u)
and fV(v) , one usually calls f (u, v) the joint probability density.
The introduction of the notion of ‘conditional probability density’ is more subtle and
shall be done here only in a very special situation. Consider again the joint probability
density f (u, v) introduced above (in the same context), and let u →v(u) represent an
application from U into V (see Figure 1.3). The general idea is to ‘condition’ the joint
probability density f (u, v) , i.e., to forget all values of f (u, v) for which v ̸= v(u) , and
to retain only the information on the values of f (u, v) for which v = v(u) .
Figure 1.3. A conditional probability density can be
deﬁned as a limit of a conditional probability (when the region
suggested around the function v = v(u) collapses into a line).
The particular type of limit matters, as the conditional probability
density essentially depends on it. In this elementary theory, we
are only interested in the simple case where, with an acceptable
approximation, one may take fu|v=v(u)(u) =
f (u,v(u))

du f (u,v(u)) .
To do this, one starts with the general deﬁnition of conditional probability (equa-
tion (1.47)), and then one takes the limit toward the hypersurface v = v(u) . The problem
is that there are many possible ways of taking this limit, each producing a different result.
Examining the detail of this problem is outside the scope of this book (the reader is referred,
for instance, to the text by Mosegaard and Tarantola, 2002). Let us simply admit here that
the situations we shall consider are such that (i) the application v = v(u) is only mildly
nonlinear (or it is linear), and (ii) the coordinates {u1, u2, . . . } and {v1, v2, . . . } are not too
far from being ‘Cartesian coordinates’ over approximately linear manifolds. Under these
restrictive conditions, one may deﬁne the conditional probability density21
fU|V( u | v(u) ) =
f ( u , v(u) )

U du′ f ( u′ , v(u′) )
,
(1.54)
which obviously satisﬁes the normalization condition

U du fU|V( u | v(u) ) = 1 .
21We could use the simpler notation fU|V(u) for the conditional probability density, but some subsequent
notation then becomes more complicated.

20
Chapter 1. The General Discrete Inverse Problem
A special case of this deﬁnition corresponds to the case where the conditioning is not
made on a general relation v = v(u) , but on a constant value v = v0 . Then, equation (1.54)
becomes fU|V( u | v0 ) = f ( u , v0 ) /

U du′ f ( u′ , v0 ) , or, dropping the index 0 in v0 ,
fU|V( u | v ) = f ( u , v ) /

U du′ f ( u′ , v ) . We recognize in the denominator the marginal
probability density introduced in equation (1.51), so one can ﬁnally write
fU|V( u | v ) = f ( u , v )
fV(v)
.
(1.55)
This shows, in particular, that under the present hypotheses, one can write the joint
probability density as the product of the conditional and the marginal:
f ( u , v ) = fU|V( u | v ) fV(v)
.
(1.56)
Using instead the conditional of v with respect to u , we can write f ( u , v ) =
fV|U( v | u ) fU(u) , and, combining the last two equations, we arrive at the Bayes theorem,
fU|V( u | v ) = fV|U( v | u ) fU(u)
fV(v)
,
(1.57)
that allows us to write the conditional for u given v in terms of the conditional for v given
u (and the two marginals). This version of the Bayes theorem is less general (and more
problematic) than the one involving events (equation (1.49)). We shall not make any use of
this expression in this book.
1.3
Forward Problem
Experiments suggest physical theories, and physical theories predict the outcome of ex-
periments. The comparison of the predicted outcome and the observed outcome allows us
to ameliorate22 the theory. If in the ‘physical theory’ we include the physical parameters
describing the system under study, then inverse problem theory is about the quantitative
rules to be used for this comparison between predictions and observations.
Taking ﬁrst a naïve point of view, to solve a ‘forward problem’ means to predict the
error-free values of the observable parameters d that would correspond to a given model
m . This theoretical prediction can be denoted
m
→
d = g(m)
,
(1.58)
where d = g(m) is a short notation for the set of equations di = gi(m1, m2, . . . ) (i =
1, 2, . . . ) . The (usually nonlinear) operator g( · ) is called the forward operator. It ex-
presses our mathematical model of the physical system under study.
Example 1.14. A geophysicist may be interested in the coordinates {r, θ, ϕ} of the point
where an earthquake starts, as well as in its origin time T . Then, the model parameters are
m = {r, θ, ϕ, T } . The data parameters may be the arrival times d = {t1, t2, . . . , tn} of
22Or, taking an extreme Popperian point of view, to refute the theory if the disagreement is unacceptably large
(Popper, 1959).

1.3. Forward Problem
21
the elastic waves (generated by the earthquake) at some seismological observatories. If the
velocities of propagation of the elastic waves inside Earth are known, it is possible, given
the model parameters m = {r, θ, ϕ, T } , to predict the arrival times d = {t1, t2, . . . , tn} ,
which involves the use of some algorithm (a ray-based algorithm using Fermat’s principle
or a ﬁnite-differencing algorithm modeling the propagation of waves). Then, the functions
di = gi(m) are deﬁned. In some simple cases, these functions have a simple analytical
expression. Sometimes they are implicitly deﬁned through a complex algorithm. If the
velocity model is itself not perfectly known, the parameters describing it also enter the
model parameters m . To compute the arrival times at the seismological observatories, the
coordinates of the observatories must be used. If they are perfectly known, they can just
be considered as ﬁxed constants. If they are uncertain, they must also enter the parameter
set m . In fact, the set of model parameters is practically deﬁned as all the parameters we
must put on the right-hand side of the equation d = g(m) in order for this to correspond
to the usual prediction of the result of some observations — given a complete description
of a physical system.
The predicted values cannot, in general, be identical to the observed values for two
reasons: measurement uncertainties and modelization imperfections. These two very dif-
ferent sources of error generally produce uncertainties with the same order of magnitude,
because, due to the continuous progress of scientiﬁc research, as soon as new experimen-
tal methods are capable of decreasing the experimental uncertainty, new theories and new
models arise that allow us to account for the observations more accurately. For this reason,
it is generally not possible to set inverse problems properly without a careful analysis of
modelization uncertainties.
The way to describe experimental uncertainties will be studied in section 1.4; this is
mostly a well-understood matter. But the proper way of putting together measurements and
physical predictions — each with its own uncertainties — is still a matter in progress. In this
book, I propose to treat both sources of information symmetrically and to obey the postulate
mentioned above, stating that the more general way of describing any state of information
is to deﬁne a probability density. Therefore, the error-free equation (1.58) is replaced with
a probabilistic correlation between model parameters m and observable parameters d . Let
us see how this is done.
Let M be the model space manifold, with some coordinates (model parameters)
m = {mα} = {m1, m2, . . . } and with homogeneous probability density µM(m) , and
let D be the data space manifold, with some coordinates (observable parameters) d =
{d1} = {d1, d2, . . . } and with homogeneous probability density µD(d) . Let X be the joint
manifold built as the Cartesian product of the two manifolds, D × M , with coordinates
x = {d, m} = {d1, d2, . . . , m1, m2, . . . } and with homogeneous probability density that,
by deﬁnition, is µ(x) = µ(d, m) = µD(d) µM(m) .
From now on, the notation 1(d, m) is reserved for the joint probability density de-
scribing the correlations that correspond to our physical theory, together with the inherent
uncertainties of the theory (due to an imperfect parameterization or to some more funda-
mental lack of knowledge).
Example 1.15. If the data manifold D and the model manifold M are two linear spaces
(respectively denoted D and M ), then both homogeneous probability distributions are

22
Chapter 1. The General Discrete Inverse Problem
(unnormalizable) constants: µD(d) = const. , µM(m) = const. The (singular) probability
density
1(d, m) = const. δ(d −G m)
,
(1.59)
where G is a linear operator (in fact, a matrix), clearly imposes the linear constraint
g = G m between model parameters and observable parameters. The ‘theory’ is here
assumed to be exact (or, more precisely, its uncertainties are assumed negligible compared
to other sources of uncertainty). The marginal probability densities 1D(d) =

M 1(d, m)
and 1M(m) =

D 1(d, m) are constant, meaning that the theory, although it carries
information on the correlations between d and m , does not carry any information on the
d or the m themselves.
Example 1.16. In the same context of the previous example, replacing the probability density
in equation (1.59) with (Gaussian probability densities are examined in Appendix 6.5)
1(d, m) = const. exp

−1
2 (d −G m)t C −1
T
(d −G m)

(1.60)
corresponds to assuming that the theoretical relation is still linear, d ≈G m , but has ‘theo-
retical uncertainties’ that are described by a Gaussian probability density with a covariance
matrix CT . Of course, the uncertainties can be described using other probabilistic models
than the Gaussian one.
If the two examples above are easy to understand (and, I hope, to accept), nontrivial
complications arise when the relation between d and m is not linear. These complications
are those appearing when trying to properly deﬁne the notion of conditional probability
density (an explicit deﬁnition of a limit is required). I do not make any effort here to enter
that domain: the reader is referred to Mosegaard and Tarantola (2002) for a quite technical
introduction to the topic.
In many situations, one may, for every model m , do slightly better than to exactly
predict an associated value d : one may, for every model m , exhibit a probability density
for d that we may denote θ(d | m) (see Figure 1.4). A joint probability density can be
written as the product of a conditional and a marginal (equation (1.56)). Taking for the
marginal for the model parameters the homogeneous probability density then gives
1(d, m) = θ(d | m) µM(m)
.
(1.61)
But there is a major difference between this case and the two Examples 1.15 and 1.16:
while in the two examples above both marginals of 1(d, m) correspond to the homogeneous
probability distributions for d and m , respectively, expression (1.61) only ensures that the
marginal for m is homogeneous, not necessarily that the marginal for d is. This problem
is implicit in all Bayesian formulations of the inverse problem, even if it is not mentioned
explicitly. In this elementary text, I just suggest that equation (1.61) can be used in all
situations where the dependence of d on m is only mildly nonlinear.
Example 1.17. Assume that the data manifold D is, in fact, a linear space denoted D
with vectors denoted d = {d1, d2, . . . } . Because this is a linear space, the homogeneous

1.3. Forward Problem
23
m
d
m
d
d = g(m)
θ(d|m)
Figure 1.4. a) If uncertainties in the forward modelization can be neglected, a
functional relationship d = g(m) gives, for each model m , the predicted (or calculated)
data values d . b) If forward-modeling uncertainties cannot be neglected, they can be
described, giving, for each value of m , a probability density for d that we may denote
θ(d|m) . Roughly speaking, this corresponds to putting vertical uncertainty bars on the
theoretical relation d = g(m) .
probability density µD(d) is constant. Let M be an arbitrary model manifold with coordi-
nates (model parameters) denoted m = {m1, m2, . . . } and with a homogeneous probability
density µM(m) . The choice
θ(d|m) = const. exp

−1
2 (d −g(m))t C −1
T
(d −g(m))

,
(1.62)
where g(m) is a (mildly) nonlinear function of the model parameters m , imposes on
d ≈g(m) some uncertainties assumed to be Gaussian with covariance operator CT .
Equation (1.61) then leads to the joint probability density
1(d, m) = const. exp

−1
2 (d −g(m))t C −1
T
(d −g(m))

µM(m)
.
(1.63)
If the ‘theoretical uncertainties’ (as described by the covariance matrix CT ) are to be
neglected, then the limit of this probability density is
1(d, m) = δ( d −g(m) ) µM(m)
.
(1.64)
The 1(d, m) in equation (1.64) is the (singular) probability density we shall take in
this book to exactly impose the (mildly) nonlinear constraint d = g(m) . When theoretical
uncertainties cannot be neglected, the Gaussian model in equation (1.63) can be used, or
any other simple probabilistic model, or still better, a realistic account of the modelization
uncertainties.
There is a class of problems where the correlations between d and m are not pre-
dicted by a formal theory, but result from an accumulation of observations. In this case,
the joint probability density 1(d, m) appears naturally in the description of the available
information.
Example 1.18. The data parameters d = {di} may represent the current state of a vol-
cano (intensity of seismicity, rate of accumulation of strain, . . . ). The model parameters
m = {mα} may represent, for instance, the time interval to the next volcanic eruption, the

24
Chapter 1. The General Discrete Inverse Problem
magnitude of this eruption, etc. Our present knowledge of volcanoes does not allow us to
relate these parameters realistically using physical laws, so that, at present, the only scien-
tiﬁc description is statistical. Provided that in the past we were able to observe a signiﬁcant
number of eruptions of this volcano, we can construct a histogram in the space D×M that
describes all our information correlating the parameters (see Tarantola, Trygvasson, and
Nercession, 1985, for an example). This histogram can directly be identiﬁed with 1(d, m) .
Of course, the simple scheme developed here may become considerably more com-
plicated when the details concerning particular problems are introduced, as the following
example suggests.
Example 1.19. A rock may primarily be described by some petrophysical parameters m ,
like mineral content, porosity, permeability, etc. Information on these parameters can be
obtained by propagating elastic waves in the rock to generate some waveform data d , but
the theory of elastic wave propagation may only use a set µ of higher order parameters,
like bulk modulus, shear modulus, attenuation, etc. Using the deﬁnition of conditional and
marginal probability density, any joint probability density f (d, µ, m) can be decomposed
as f (d, µ, m) = f (d|µ, m) f (µ|m) f (m) . In the present problem, this suggests replacing
equation (1.61) with
1(d, µ, m) = θ(d|µ, m) θ(µ|m) µM(m)
.
(1.65)
Furthermore, if the waveform data d are assumed to depend on the petrophysical param-
eters m mainly through the higher order parameter µ , one can use the approximation
θ(d|µ, m) = θ(d|µ) , in which case we can write
1(d, µ, m) = θ(d|µ) θ(µ|m) µM(m)
.
(1.66)
Here, the conditional probability density θ(µ|m) may represent the correlations observed
in the laboratory (using a large number of different rocks) between the petrophysical param-
eters m and the higher order parameters µ , while θ(d|µ) is the prediction of waveform
data d given the higher order parameters µ . For this, one may take something as simple
as (see equation (1.64)) θ(d|µ) = δ( d −g(m) ) .
1.4
Measurements and A Priori Information
1.4.1
Results of the Measurements
All physical measurements are subjected to uncertainties. Therefore, the result of a mea-
surement act is not simply an ‘observed value’ (or a set of ‘observed values’) but a ‘state of
information’ acquired on some observable parameter. If d = {d1, d2, . . . , dn} represents
the set of observable parameters, the result of the measurement act can be represented by a
probability density ρD(d) deﬁned over the data space D .
Example 1.20. In the simplest situation, when measuring an n-dimensional data vector d
(considered an element of a linear space D ), we may obtain the observed values dobs , with

1.4. Measurements and A Priori Information
25
uncertainties assumed to be of the Gaussian type, described by a covariance matrix CD .
Then, ρD(d) is a Gaussian probability density centered at dobs :
ρD(d) = ( (2π)n det CD )−1/2 exp

−1
2 (d −dobs)t C −1
D
(d −dobs)

.
(1.67)
See also Example 1.25.
Example 1.21. Consider a measurement made to obtain the arrival time of a given seismic
wave recorded by a seismograph (see Figure 1.5). Sometimes, the seismogram is simple
enough to give a simple result, but sometimes, due to strong noise (with unknown statistics),
the measurement is not trivial. The ﬁgure suggests a situation where it is difﬁcult to obtain
a numerical value, say tobs , for the arrival time. The use of a probability density (bottom of
the ﬁgure) allows us to describe the information we actually have on the arrival time with a
sufﬁcient degree of generality (using here a bimodal probability density). With these kinds
of data, it is clear that the subjectivity of the scientist plays a major role. It is indeed the
case, whichever inverse method is used, that results obtained by different scientists from
similar data sets are different. Objectivity can only be attained if the data redundancy
is great enough that differences in data interpretation among different observers do not
signiﬁcantly alter the models obtained.
Figure 1.5.
At the top, a seismogram
showing the arrival of a wave. Due to the pres-
ence of noise, it is difﬁcult to pick the ﬁrst arrival
time of the wave. Here, in particular, one may
hesitate between the “big arrival” and the “small
arrival” before, which may or may not just be noise.
In this situation, one may give to the variable ar-
rival time a bimodal probability density (bottom).
The width of each peak represents the uncertainty
of the reading of each of the possible arrivals, the
area of each peak represents the probability for the
arrival time to be there, and the separation of the
peaks represents the overall uncertainty.
Example 1.22.
Observations are the output of an instrument with known statistics.
Let us place ourselves under the hypothesis that the data space is a linear space (so the
use of conditional probability densities is safe). To simplify the discussion, I will refer to
“the instrument” as if all the measurements could result from a single reading on a large
apparatus, although, more realistically, we generally have some readings from several
apparatuses. Assume that when making a measurement the instrument delivers a given
value of d , denoted dout . Ideally, the supplier of the apparatus should provide a statistical
analysis of the uncertainties of the instrument. The most useful and general way of giving
the results of the statistical analysis is to deﬁne the probability density for the value of
the output, dout , when the actual input is d . Let ν(dout|d) be this conditional probability

26
Chapter 1. The General Discrete Inverse Problem
density. If f (dout, d) denotesthejointprobabilitydensityfor dout and d , andifwedon’tuse
any information on the input, we have (equation (1.56)) f (dout, d) = ν(dout|d) µD(d) ,
where µD(d) is the homogeneous probability density. As the data space is linear, the
homogeneous probability density is constant, and we simply have
f (dout, d) = const. ν(dout|d)
.
(1.68)
If the actual result of a measurement is dout = dobs , then we can identify ρD(d) with the
conditional probability density for d given dout = dobs : ρD(d) = f ( d | dout = dobs ) .
This gives ρD(d) = f (dobs, d) /

D dd f (dobs, d) , i.e.,
ρD(d) = const. ν(dobs|d)
.
(1.69)
This relates the instrument characteristic ν(dout|d) , the observed value dobs , and the
probability density ρD(d) in the data space that represents the information found by the
measurement.
Example 1.23. Perfect instrument. In the context of the previous example, a perfect
instrument corresponds to ν(dout|d) = δ(dout −d) . Then, if we observe the value dobs ,
ρD(d) = δ(dobs −d) , i.e.,
ρD(d) = δ(d −dobs)
.
(1.70)
The assumption of a perfect instrument may be made when measuring uncertainties are
negligible compared to modelization uncertainties.
Example 1.24. In the context of Example 1.22, assume that the uncertainties due to the
measuring instrument are independent of the input. Assume that the output dout is related
to the input d through the simple relation
dout = d + ϵ
,
(1.71)
where ϵ is an unknown error with known statistics described by the probability density
f (ϵ) . In that case, if we observe the value dobs ,
ρD(d) = ν(dobs|d) = f (ϵ) = f (dobs −d)
.
(1.72)
This result is illustrated in Figure 1.6.
Example 1.25.
Gaussian uncertainties.
In the context of the previous example, as-
sume that the probability density for the error ϵ is Gaussian with zero mean and co-
variance CD :
f (ϵ) =
Gaussian( ϵ , 0 , CD ) . Equation (1.72) then gives ρD(d) =
Gaussian( dobs −d , 0 , CD ) , i.e., ρD(d) = Gaussian( d −dobs , 0 , CD ) . Equivalently,
ρD(d) = Gaussian( d , dobs , CD )
,
(1.73)
corresponding to the result already suggested in Example 1.20.
Example 1.26. Outliers in a data set. Some data sets contain outliers that are difﬁcult to
eliminate, in particular when the data space is highly dimensioned, because it is difﬁcult
to visualize such data sets. Problem 7.7 shows that a single outlier in a data set can lead

1.4. Measurements and A Priori Information
27
Figure 1.6.
As an illustration of Exam-
ple 1.24, consider that the statistics of the (scalar) er-
ror ε is represented by the probability density f (ε)
at the top of the ﬁgure. Imagine that the true (un-
known) value of the measured quantity is d = 7 .
This ﬁgure shows the three probability densities we
should infer for d (according to equation (1.72)) in
the three different situations where the output of the
instrument is, respectively, dobs = 6.6 , dobs = 7.1 ,
and dobs = 7.9 . Observe that the shape of the proba-
bility density ρD(d) is the mirror image of the shape
of f (ε) .
to unacceptable inverse results if the Gaussian assumption is used. That problem suggests
using long-tailed probability densities to represent uncertainties on this kind of data sets.
A simple example of a long-tailed density function is the symmetric exponential (Laplace)
function f (x) =
1
2σ exp(−|x −x0|/σ) , where σ is the mean deviation of the distribution.
Using this probability model gives (uncertainties are assumed independent)
ρD(d) =
 
i
1
2 σ i

exp

−

i
di −di
obs

σ i

.
(1.74)
Example 1.27. Assume that the only instrument we have for measuring a given observable
d is a buzzer that responds when the true value d is in the range dmin ≤d ≤dmax . We
make the measurement, and the buzzer does not respond. The corresponding probability
density is then
ρD(d) =

0
for dmin ≤d ≤dmax
,
const. µD(d)
otherwise
,
(1.75)
where µD(d) is the homogeneous probability density for the observable parameter d .
1.4.2
A Priori Information on Model Parameters
By a priori information (or prior information) we shall mean information that is obtained
independently of the results of measurements. The probability density representing this a
priori information will be denoted by ρM(m) .
Example 1.28. We have no a priori information other than the basic deﬁnition of the model
parameters. In that case,
ρM(m) = µM(m)
,
(1.76)
where µM(m) is the homogeneous probability density for model parameters, as introduced
in section 1.2.4.

28
Chapter 1. The General Discrete Inverse Problem
Example 1.29. For a given parameter mα we have only the information that it is strictly
bounded by the two values mα
min and mα
max . We can take
ρM(m) =

α∈IM
ρα(mα)
,
(1.77)
where
ρα(mα) =

const. µα(mα)
for mα
min ≤mα ≤mα
max
,
0
otherwise
,
(1.78)
and where µα(mα) represents the homogeneous probability density for mα .
30
20
50
0
100
10
0
−10
−20
Figure 1.7. Histogram of disintegration periods (half-lives) of the ﬁrst 580 atomic
nuclei in the CRC Handbook of Chemistry and Physics (1984). The horizontal axis repre-
sents the logarithm of the half-life: T ∗= log10(T/T0) , with T0 = 1 s. It is very difﬁcult
to show the histogram using a nonlogarithmic time axis, because observed disintegration
periods span 45 orders of magnitude. Note that the use of a logarithmic period axis allows
the histogram to be roughly approximated by a Gaussian probability density. This implies
a log-normal probability density for the half-lives.
Example 1.30. Figure 1.7 shows a histogram of the half-lives of the ﬁrst 580 atomic nuclei
quoted in the CRC Handbook of Chemistry and Physics (1984). Denoting by T the half-life,
the abscissa of the ﬁgure is
T ∗= log10
T
T0
(T0 = 1 s)
.
(1.79)
The logarithmic scale has been chosen for the time axis because, as the half-lives span many
orders of magnitude, it is difﬁcult to show the histogram using a linear time axis. With this
logarithmic scale, the histogram may conveniently be approximated by a Gaussian function,
f ∗(T ∗) =
1
(2π)1/2 σ ∗exp

−1
2
(T ∗−T0∗)2
(σ ∗)2

,
(1.80)
with T0∗≃3 and σ ∗≃3 . This implies a log-normal probability density (see Appendix 6.7)
for the half-life T (which is adequate for a Jeffreys quantity). If we are going to experi-
ment with one such atomic nucleus, but we ignore which one, we can use this probability
distribution to represent our a priori information on its half-life.

1.4. Measurements and A Priori Information
29
Example 1.31. The left of Figure 1.8 shows the histogram of densities of different known
minerals in Earth’s crust (independently of their relative abundance). At the right of the
ﬁgure, the same histogram is shown on a logarithmic scale. If one has some mineral on which
to perform some measurements, one may well take these (equivalent) probability densities
to represent the a priori state of information on the mass density. If you do not have this
ﬁgure in mind, the homogeneous probability density will represent your ignorance well. In
mass density, this is µ(ρ) = 1/ρ , and, in logarithmic mass density, µ∗(ρ∗) = const.
10 g/cm
20 g/cm
0
u = log10(ρ/(g/cm3))
0
0.5
1
1.5
Figure 1.8. Histogram of mass densities of the 571 different rock types quoted
by Johnson and Olhoeft (1984). The histogram is very asymmetric due to the existence of
very heavy minerals (ρ ≃20 g cm−3) . Also shown is a best-ﬁtting log-normal probability
density. The same histogram of the previous ﬁgure in a logarithmic horizontal scale has
ρ∗= log10(ρ/g cm−3) . In a logarithmic scale, it is much more symmetric. Also shown is
the best-ﬁtting normal (i.e., Gaussian) probability density.
Example 1.32. Assume that we are going to solve an inverse problem involving a one-
dimensional (layered) Earth model, with each layer describing a thickness and a value of the
mass density. We are given the a priori information that the layer thickness has the probabil-
ity density displayed at the left in Figure 1.9 and the mass density has the probability density
displayed at the right in Figure 1.9, all the variables being independent. It is then possible
(andquiteeasy, asallthevariablesareindependent)torandomlygeneratemodelsthatrepre-
sent this a priori information. Figure 1.10 shows three such models. This random generation
of models is at the basis of the strategy proposed in chapter 2 for solving inverse problems.
Example 1.33. Assume that the parameters mα represent a discretization of a continuous
function. We have reason to believe that the particular function under study is a random
realization of a Gaussian random ﬁeld, with given mean mprior and given covariance CM
(examples of realizations of such random ﬁelds are displayed in chapter 2 (Figure 2.4)
and chapter 5 (Figures 5.7 and 5.8)). This a priori information is then represented by the
Gaussian probability density
ρM(m) =

(2π)n det CM
−1/2 exp

−1
2 ( m −mprior )t C −1
M ( m −mprior )

, (1.81)

30
Chapter 1. The General Discrete Inverse Problem
Figure 1.9. When using the probability density at the left for the thickness of the
layers of a geological model and the probability density at the right for the mass density
inside each layer, one may generate random models, like the three displayed in Figure 1.10.
Figure 1.10. Three randomly generated layered models of Earth. The layer thick-
nesses are generated according to an exponential probability density and the mass densities
according to a log-normal probability density (that of Figure 1.8, page 29).
where n is the number of discretization points. This probability density gives a high proba-
bility density to models m that are close to mprior in the sense of the covariance operator
CM , i.e., models in which the difference m −mprior is small at each point (with respect to
standard deviations in CM ) and smooth (with respect to correlations in CM ). Covariance
operators are deﬁned in Appendix 6.5.
The Gaussian assumption of the previous example is quite elementary. More real-
istic assumptions are these days being used by geostatisticians23 (see, for instance, Caers,
Srinivasan, and Journel, 2000). A well-designed geophysical inverse problem should use
the concepts of geostatistics to introduce the a priori information and the equations of this
book to formulate the inverse problem.
23For some general information on geostatistics, see Journel and Huijbregts, 1978, Goovaerts, 1997, and Deutsch
and Journel, 1998.

1.4. Measurements and A Priori Information
31
The examples in this section show how it is possible to use probability densities
to describe prior information. I have never found a state of information (in the intuitive
sense) that cannot be very precisely stated using a probability density. On the other hand, it
may seem that probability densities have too many degrees of freedom to allow a deﬁnite
choice that represents a given state of information. In fact, only a few characteristics of a
probability density are usually relevant, such as, for instance, the position of the center, the
degree of asymmetry, the size of the uncertainty bounds, the correlations between different
parameters, and the behavior of the probability density far from the center.
Figure 1.11.
The random points
(xi, yi) of these diagrams have been gener-
ated using two-dimensional probability densi-
ties f1(x, y) (top) and f2(x, y) (bottom). The
two probability densities have identical mean
values and standard deviations. Only the co-
variance Cxy is different. On the top, the co-
variance is small; on the bottom, it is large.
The probability density f2(x, y) is more infor-
mative than f1(x, y) because it demarcates a
smaller region in the space. This example sug-
gests that if off-diagonal elements of a covari-
ance operator are difﬁcult to estimate, setting
them to zero corresponds to neglecting infor-
mation.
If hesitation exists in choosing the a priori uncertainty bars, it is of course best to be
overconservative and to choose them very large. A conservative choice for correlations is
to neglect them (see Figure 1.11 for an example). The behavior of the probability densities
far from the center is only crucial if outliers may exist: the choice of functions tending too
rapidly to zero (boxcar functions or even Gaussian functions) may lead to inconsistencies;
the solution to the problem (as deﬁned in the next section) may not exist, or may be senseless.
Usually the a priori states of information have the form of soft bounds; the normal or
log-normal probability densities generally apply well to that case. If the normal function
is thought to vanish too rapidly when the parameter’s value tends to inﬁnity, longer tailed
functions may be used such as, for instance, the symmetric-exponential function (see Ap-
pendix 6.6).
1.4.3
Joint Prior Information
By deﬁnition, the a priori information on model parameters is independent of observations.
The information we have in both model parameters and observable parameters can then be
described in the manifold D × M by the joint probability density (this is the independence
mentioned in equation (1.53))
ρ(d, m) = ρD(d) ρM(m)
.
(1.82)

32
Chapter 1. The General Discrete Inverse Problem
It may happen that part of the “a priori information” has been obtained from a ﬁrst,
rough, analysis of the data set. Rigorously, then, there exist correlations between d and
m in ρ(d, m) , and equation (1.82) no longer holds. For a maximum of generality, we
thus have to assume the existence of a general probability density ρ(d, m) , not necessarily
satisfying (1.82), and representing all the information we have in data and model parameters
independently of the use of any theoretical information (which is described by the probability
density 1(d, m) introduced in section 1.3).
1.5
Deﬁning the Solution of the Inverse Problem
1.5.1
Combination of Experimental, A Priori, and Theoretical
Information
We have seen in the previous section that the prior probability density ρ(d, m) , deﬁned
in the space D × M , represents both information obtained on the observable parameters
(data) d and a priori information on the model parameters m . We have also seen that
the theoretical probability density
1(d, m) represents the information on the physical
correlations between d and m , as obtained from a physical law, for instance.
These two states of information combine to produce the a posteriori state of infor-
mation. I propose that the method of the previous sections to introduce the a priori and the
theoretical states of information is such that the a posteriori state of information is given
by the conjunction of these two states of information. Using (1.40), the probability density
σ(d, m) representing the a posteriori information is then
σ(d, m) = k ρ(d, m) 1(d, m)
µ(d, m)
,
(1.83)
where µ(d, m) represents the homogeneous state of information and where k is a normal-
ization constant.
This is justiﬁed by the correctness of the consequences we shall obtain, as the rest of
this book is based on (1.83). It will be seen that the conclusions obtained from this equation,
although more general than those obtained from more traditional approaches, reduce to them
in all particular cases. Equation (1.83) ﬁrst appeared in Tarantola and Valette (1982a).
Once the a posteriori information in the D×M space has been deﬁned, the a posteriori
information in the model space is given by the marginal probability density
σM(m) =

D
dd σ(d, m)
,
(1.84)
while the a posteriori information in the data space is given by
σD(d) =

M
dm σ(d, m)
.
(1.85)
Figure 1.12 illustrates the determination of σM(m) and σD(d) from ρ(d, m) and
1(d, m) geometrically.

1.5. Deﬁning the Solution of the Inverse Problem
33
Figure 1.12.
Left: The probability densities ρD(d) and ρM(m) respectively
represent the information on observable parameters (data) and the prior information on
model parameters. As the prior information on model parameters is, by deﬁnition, inde-
pendent of the information on observable parameters (measurements), the joint probabil-
ity density in the space D × M representing both states of information is ρ(d, m) =
ρD(d) ρM(m) .
Center:
1(d, m) represents the information on the physical correla-
tions between d and m , as predicted by a (nonexact) physical theory. Right: Given
the two states of information represented by ρ(d, m) and 1(d, m) , their conjunction is
σ(d, m) = k ρ(d, m) 1(d, m) / µ(d, m) and represents the combination of the two states
of information. From σ(d, m) it is possible to obtain the marginal probability densities
σM(m) =

dd σ(d, m) and σD(d) =

dm σ(d, m) . By comparison of the posterior
probability density σM(m) with the prior one, ρM(m) , we see that some information has
been gained on the model parameters thanks to the data ρD(d) and the theoretical infor-
mation 1(d, m) .
1.5.2
Resolution of Inverse Problems
Equation(1.83)solvesaverygeneralproblem. Inverseproblemscorrespondtotheparticular
case where the spaces D and M have fundamentally different physical meaning and where
we are interested in translating information from the data space D into the model space
M . Let us make the usual assumptions in this sort of problem.
First, as discussed in section 1.3, it is assumed that a reasonable approximation for
representing the physical theory relating the model parameters m to the observable param-
eters d can be written under the form of a probability density for d given any possible m
(equation (1.61)):
1(d, m) = θ(d | m) µM(m)
,
(1.86)
where, as usual, µM(m) is the homogeneous probability density over the model space
manifold M . Second, the prior information in the joint manifold D × M takes the special
form
ρ(d, m) = ρD(d) ρM(m)
,
(1.87)
which means that information in the space of observable parameters (data) has been ob-
tained (from measurements) independently of the prior information in the model space (see
section 1.4). In particular, the homogeneous limit of this last equation is
µ(d, m) = µD(d) µM(m)
.
(1.88)

34
Chapter 1. The General Discrete Inverse Problem
Using equations (1.83)–(1.84), this gives, for the posterior information in the model space,
σM(m) = k ρM(m)

D
dd ρD(d) θ(d | m)
µD(d)
.
(1.89)
Sometimes, we shall write equation (1.89) as
σM(m) = k ρM(m) L(m)
,
(1.90)
where k is a constant and L(m) is the likelihood function
L(m) =

D
dd ρD(d) θ(d | m)
µD(d)
,
(1.91)
which gives a measure of how good a model m is in explaining the data.
Equation (1.89) gives the solution of the general inverse problem. From σM(m) it
is possible to obtain any sort of information we wish on model parameters: mean values,
median values, maximum likelihood values, uncertainty bars, etc. More importantly, from
σM(m) one may compute the probability for a model m to satisfy some characteristic (by
integrating the probability density over the region of the model manifold made by all the
models satisfying the given characteristic). Finally, from σM(m) one may obtain a sequence
m1 , m2, . . . of samples that may provide a good intuitive understanding of the information
one actually has on the model parameters. See section 1.6 for a discussion.
The existence of the solution simply means that σM(m) , as deﬁned by (1.89), is not
identically null. If this were the case, it would indicate the incompatibility of the experi-
mental results, the a priori hypothesis on model parameters, and the theoretical information,
thus showing that some uncertainty bars have been underestimated.
The uniqueness of the solution is evident when by solution we mean the probability
density σM(m) itself and is simply a consequence of the uniqueness of the conjunction
of states of information. Of course, σM(m) may be very pathological (nonnormalizable,
multimodal, etc.), but that would simply mean that such is the information we possess on
the model parameters. The information itself is uniquely deﬁned.
Example 1.34. Negligible modelization uncertainties. If (i) the data space D is a
linear space (so, in particular, the homogeneous probability density over D is constant,
µD(d) = const. ) and (ii) modelization uncertainties are negligible compared to observa-
tional uncertainties, we can take24
θ(d | m) = δ(d −g(m))
,
(1.92)
where d = g(m) denotes the (exact) resolution of the forward problem. Equation (1.89)
then gives
σM(m) = 1
ν ρM(m) ρD( g(m) )
,
(1.93)
24The hypothesis θ(d | m) = δ(d −g(m)) may be plainly wrong if the data space is not a linear space, as a
properly deﬁned delta function may not simply be a function of the difference d −g(m) .

1.5. Deﬁning the Solution of the Inverse Problem
35
where ν is the normalization constant ν =

M dm ρM(m) ρD( g(m) ) .
Although we
have obtained the result (1.93) via the notion of conjunction of states of information, we
could have arrived here by introducing the conditional probability density of ρ(d, m) =
ρD(d) ρM(m) given relation d = g(m) (using equation (1.54)). Sometimes, we shall write
equation (1.93) as
σM(m) = k ρM(m) L(m)
,
(1.94)
where k is a constant and L(m) is the likelihood function
L(m) = ρD( g(m) )
,
(1.95)
which, as in equation (1.91), gives a measure of how good a model m is in explaining the
data.
Equation (1.93) is of considerable practical importance: a majority of inverse prob-
lems can be solved using it directly (under the assumption that the data space is a linear
space25). There are three elements in the equation: (i) the a priori probability density in
the model space, ρM(m) (which can be replaced by its homogeneous limit µM(m) if no
other a priori information is available), (ii) the probability density ρD(d) describing the
result of the measurements (with the attached uncertainties), and (iii) the nonlinear function
m →g(m) solving the forward problem.
Example 1.35. Negligible observational uncertainties. Assume that the data space is a
linear space. Letting dobs denote the observed data values, the hypothesis of negligible
observational uncertainties (with respect to modelization uncertainties) is written
ρD(d) = δ(d −dobs)
.
(1.96)
Equation (1.89) then gives σM(m) = k ρM(m) θ(dobs | m) , or, under normalized form,
σM(m) =
ρM(m) θ(dobs | m)

M dm ρM(m) θ(dobs | m)
.
(1.97)
Example 1.36. Gaussian modelization and observational uncertainties. This corre-
sponds respectively to (equation (1.62) of Example 1.17)
θ(d | m) = const. exp

−1
2 (d −g(m))t C −1
T
(d −g(m))

,
(1.98)
and, provisionally using the notation Cd for the covariance matrix representing the mea-
surement uncertainties (equation (1.73) of Example 1.25),
ρD(d) = const. exp

−1
2 (d −dobs)t C −1
d
(d −dobs)

.
(1.99)
As demonstrated in Appendix 6.21, equation (1.89) then gives
σM(m) = const. ρM(m) exp

−1
2 ( g(m) −dobs )t C −1
D
( g(m) −dobs )

,
(1.100)
25For a slightly more general setting, see Mosegaard and Tarantola, 2002.

36
Chapter 1. The General Discrete Inverse Problem
where
CD = Cd + CT
.
(1.101)
This result is important because it shows that, in the Gaussian assumption, observational
uncertainties and modelization uncertainties simply combine by addition of the respective
covariance operators, even when the forward problem is nonlinear.
Example 1.37. Gaussian model. In the context of Example 1.36, further assume that the
model space is linear and that the a priori information on the model parameters is also
Gaussian:
ρM(m) = const. exp

−1
2 (m −mprior)t C −1
M (m −mprior)

.
(1.102)
Then,
σM(m) = k exp( −S(m) )
,
(1.103)
where k is a constant and where the misﬁt function S(m) is the sum of squares:
S(m) = 1
2

( g(m) −dobs )t C −1
D
( g(m) −dobs ) + ( m −mprior )t C −1
M ( m −mprior )

.
(1.104)
Example 1.38. Gaussian linear model. If the relation between model parameters and data
parameters is linear,
d = g(m) = G m
,
(1.105)
then the posterior probability density σM(m) (equation (1.103)) is also Gaussian (see
chapter 3 for details) with mean
m = ( Gt C −1
D G + C −1
M )−1 ( Gt C −1
D dobs + C −1
M mprior )
= mprior + ( Gt C −1
D G + C −1
M )−1 Gt C −1
D ( dobs −G mprior )
= mprior + CM Gt ( G CM Gt + CD )−1 (dobs −G mprior)
(1.106)
and covariance
CM = ( Gt C −1
D G + C −1
M )−1 = CM −CM Gt ( G CM Gt + CD )−1 G CM
.
(1.107)
Example 1.39. Generalized Gaussian model. In the case of independent uncertainties,
the Gaussian model of Example 1.37 can be generalized (replacing the Gaussian model of
uncertainties with the generalized Gaussian [see Appendix 6.6]). With obvious deﬁnitions,
one arrives at
σM(m) = const. exp

−1
p
 
i
| gi(m) −di
obs |p
(σ i
D)p
+

α
| mα −mα
prior |p
(σ α
M)p
 
.
(1.108)

1.6. Using the Solution of the Inverse Problem
37
In particular, for p = 1 , one has σM(m) = k exp( −S(m) ) , where the misﬁt function
S(m) is now a sum of absolute values:
S(m) =

i
| gi(m) −di
obs |
σ i
D
+

α
| mα −mα
prior |
σ α
M
.
(1.109)
1.6
Using the Solution of the Inverse Problem
1.6.1
Computing Probabilities
We have set the inverse problem as a problem of the conjunction of states of information.
Then, the solution of the inverse problem is the posterior probability distribution over the
model space manifold, represented by the probability density σM(m) . The more general
questions we may ask in an inverse problem are more basic in probability theory: which is
the probability of a certain event, i.e., the probability that a model m belongs to a given
region A ⊆M of the model space manifold?
Example 1.40. If the system under study is a galaxy and among the parameters used to
describe it are the respective masses mG and mBH of the entire galaxy and of its central
black hole, an event
A ⊆M may be mBH < 10−5 mG . The probability of the event
A : mBH < 10−5 mG is
P(A) =

A
dm σM(m)
.
(1.110)
We can then say that the probability that the mass of the central black hole is less than 10−5
times the mass of the total galaxy equals P(A) .
In chapter 2 it is explained how these probabilities can be computed in high-dimen-
sional spaces, where Monte Carlo sampling methods are often necessary.
Sometimes, the inverse problem is solved as an intermediate one in a more general
decision problem in which one has to combine information obtained from the inverse prob-
lem with economic considerations. As an example, the 30 years of production data of an oil
ﬁeld were used to obtain information on the 3D distribution of porosity and permeability,
solving in fact a huge inverse problem involving 3D simulations of ﬂuid ﬂow. The problem
was solved in a Monte Carlo way, so the solution to the problem was a large set of possible
solutions, samples of the posterior probability density in the model space, σM(m) . For each
of those samples, it was possible to run the ﬂuid ﬂow simulation forward in time to evaluate
the total future production of the oil ﬁeld. As each sampled model predicts a different total
production, one obtains a histogram that, in fact, represents the probability density of what
the total future production can be (See Figure 1.13).
In a related domain, readers interested in Bayesian decision theory can refer to Box
and Tiao (1973), Morgan (1968), Schmitt (1969), or Winkler (1972).

38
Chapter 1. The General Discrete Inverse Problem
Figure 1.13.
The his-
togram of total future oil production
of an oil ﬁeld, as obtained by solv-
ing an inverse problem (for porosity
and permeability) using as data 30
yearsofproductionontheﬁeld, from
Landa and Guyaguler (2003), with
permission (the actual values of oil
production are conﬁdential).
Cumulative Oil Production
(true scale not displayed)
300
0
100
200
0
1
2
3
1.6.2
Analysis of Uncertainties
Should the model space manifold be a linear space, and the probability density σM(m) be
reasonably close to a Gaussian distribution, the mean model ⟨m⟩may be of interest,
⟨m⟩=

M
dm m σM(m)
,
(1.111)
together with the covariance matrix
CM =

M
dm (m −⟨m⟩) (m −⟨m⟩)t σM(m)
.
(1.112)
The comparison of this posterior covariance matrix with the prior one,
CM =

M
dm (m −⟨m⟩) (m −⟨m⟩)t ρM(m)
,
(1.113)
corresponds to what is usually called the analysis of uncertainties: for each individual
parameter one may see how the initial uncertainty has been reduced.26
But it must be clear that this simple method of analyzing uncertainties will not make
sense for complex problems, where the posterior probability density may itself be complex.
Then, the direct examination of the prior and posterior probabilities of some events (as
suggested above) is the only means we may have.
1.6.3
Random Exploration of the Model Space
If the number of model parameters is very small (say, less than 10) and if the computation
of the numerical value of σM(m) for an arbitrary m is inexpensive (i.e., not consuming
too much computer time), we can deﬁne a grid over the model space, compute σM(m)
26Remember that the square root of the diagonal elements of a covariance matrix is the standard deviation.

1.6. Using the Solution of the Inverse Problem
39
everywhere in the grid, and directly use these results to discuss the information obtained
on the model parameters. This is certainly the most general way of solving the inverse
problem. Problem 7.1 gives an illustration of the method.
If the number of parameters is not small, and if the computation of σM(m) at any
point m is not expensive, the systematic exploration of the model space can advantageously
be replaced with a random (Monte Carlo) exploration. Monte Carlo methods are discussed
in chapter 2. Also, the computation of the mathematical expectation and of the posterior
covariance operator can be made by evaluating the sums (1.111) and (1.112) by a Monte
Carlo method of numerical integration.
1.6.4
Maximum Likelihood Point
Let X be a manifold with some coordinates x = {x1, x2, . . . } and with volume element
dV (x) = v(x) dx1 dx2 . . .
.
(1.114)
Let f (x) be a probability density over X . How is the maximum likelihood point to be
deﬁned? A common mistake is to ‘deﬁne’ it as the point where f (x) is maximum. This
cannot be: under a change of variables, a probability density has its values multiplied by
the Jacobian of the transformation (see equation (1.18)), so the point at which a probability
density achieves its maximum depends as much on the probability distribution per se as on
the variables being used.
The maximum likelihood point must be deﬁned as follows: considering around every
point x a small region with ﬁxed volume dV0 , which is the point x at which the probability
dP (x) is maximum? By deﬁnition of probability density, dP(x) = f (x) dx1 dx2 . . . . As
we wish ﬁxed dV0 = v(x) dx1 dx2 . . . , we can write dP(x) = ( f (x) / v(x) ) dV0 , and,
therefore, the maximum of dP(x) is obtained when
f (x)
v(x)
is maximum
.
(1.115)
The homogeneous probability density was introduced in section 1.2.4 where we arrived
(see equation (1.23) there) at the relation µ(x) = const. v(x) . Therefore, the condition
characterizing the maximum likelihood point can also be written
maximum likelihood point
:
f (x)
µ(x)
maximum
.
(1.116)
The ratio f (x)/µ(x) was called the likelihood function above (see equation (1.31)).
Example 1.41. The Fisher probability density over the surface of the sphere is (when
centered at the “North pole”), using spherical coordinates {θ, ϕ} ,
f (θ, ϕ) =
κ sin θ
4 π sinh κ exp(κ cos θ)
,
(1.117)
where the parameter 1/κ measures the dispersion of the distribution. It is normalized, as
one has

 π
0 dθ

 π
−π dϕ f (θ, ϕ) = 1 (remember that a probability density is integrated using

40
Chapter 1. The General Discrete Inverse Problem
the capacity element dθ dϕ , not using the surface element dS(θ, ϕ) ). The points where
the probability density f (θ, ϕ) reaches its maximum have no special meaning. As the
surface element on the surface of the sphere is dS(θ, ϕ) = sin θ dθ dϕ , the homogeneous
probability density is µ(θ, ϕ) =
1
4 π sin θ (it could also be obtained as the limit of f (θ, ϕ)
when κ →0 ). The maximum likelihood point is deﬁned by the condition
f (θ, ϕ)
µ(θ, ϕ)
maximum
,
(1.118)
i.e., the condition that
κ
sinh κ exp(κ cos θ) is maximum. This happens for θ = 0 as it
should.
Returning now to our inverse problems, given a model space manifold M with homo-
geneous probability density µM(m) , and given the posterior probability density σM(m) ,
we see that the point of maximum (posterior) likelihood is that satisfying
σM(m)
µM(m)
maximum
.
(1.119)
To ﬁnd the maximum likelihood point, one typically uses gradient methods.
In that respect, two major comments need to be made.
• Probability distributions tend to be bell shaped, and gradient methods tend to work
very inefﬁciently far from the maximum likelihood point. It is generally much better
to deﬁne
8(m) = log σM(m)
µM(m)
(1.120)
and to use standard gradient techniques to ﬁnd the point fulﬁlling the equivalent
condition
8(m)
maximum
.
(1.121)
The function S(m) = −8(m) corresponds to the usual misﬁt function (to be mini-
mized).
• “Gradient” is not synonymous with “direction of steepest ascent,” and an explicit
deﬁnition of distance over the model space manifold has to be introduced in order to
effectively use gradient methods. Some examples are given in chapters 3 and 4.
As σM(m) is, in general, an arbitrarily complicated function of m , there is no guar-
antee that the maximum likelihood point is unique, or that a given point that is locally
maximum is the absolute maximum. Only a full exploration of the space would give the
proof, but this is generally too expensive to make (when the number of dimensions is large).
Unless solid qualitative arguments can be made, one is only left with the possibility of more
or less extensive explorations of the model space, random or not.

Chapter 2
Monte Carlo Methods
Now and then, luck brings confusion
in the biological order established by selection.
It periodically shifts its too restrictive barriers,
and allows natural evolution to change its course.
Luck is anti-conservative.
Jacques Rufﬁé, 1982
We have seen in chapter 1 that the most general solution of an inverse problem provides
a probability distribution over the model space. It is only when the probability distribution
in the model space is very simple (for instance, when it has only one maximum) that analytic
techniques can be used to characterize it.
For more general probability distributions, one needs to perform an extensive explo-
ration of the model space. Except for problems with a very small number of dimensions, this
exploration cannot be systematic (as the number of required points grows too rapidly with
the dimension of the space). Well-designed random (or pseudorandom) explorations can
solve many complex problems. These random methods were jokingly called Monte Carlo
methods by the team at Los Alamos that was at the origin, among others, of the Metropolis
sampling algorithm, and the name “Monte Carlo” has now become established.
2.1
Introduction
That Monte Carlo (i.e., random) methods can be used for computation has been known for
centuries. For instance, one can use a Monte Carlo method to evaluate the number π : on
a regular ﬂoor, made of strips of equal width w , one throws needles of length w/2 . The
probability that a needle will intersect a groove in the ﬂoor equals 1/π (Georges Louis
Leclerc, Comte de Buffon [1707–1788]). A series of 50 observations, each with 100 trials,
made by Wolff in Zurich in 1850 led to a value for π of 3.1596 ± 0.0524 . In numerical
41

42
Chapter 2. Monte Carlo Methods
methods, the throwing of needles is replaced with a pseudorandom generation of numbers
by a computer code.
One domain where Monte Carlo computations are usual is for the numerical evaluation
ofintegralsinlarge-dimensionalspaces: thesystematicevaluationofthefunctionataregular
grid is impossible (too many points would be required), and a Monte Carlo sampling of the
function can provide an estimation of the result, together with an estimation of the error
(see Appendix 6.9 or, for more details, Kalos and Whitlock, 1986).
The use of Monte Carlo methods for the solution of inverse problems was initiated by
Keilis-Borok and Yanovskaya (1967) and Press (1968, 1971). More recent interesting works
are Anderssen and Seneta (1971, 1972), Rothman (1985a, 1985b, 1986), and Dahl-Jensen
et al. (1998).
From the perspective of this book, where probability distributions over parameter
spaces are central, we face the problem of how to use them. The deﬁnition of ‘central esti-
mators’ (like the mean or the median) and of ‘estimators of dispersion’ (like the covariance
matrix) lacks generality, as it is quite easy to ﬁnd examples (like multimodal distributions
in high-dimensional spaces) where these estimators fail to have any interesting meaning.
When a probability distribution has been deﬁned over a space of low dimension
(say, from one to four dimensions), we can directly represent the associated probability
density. This is trivial in one or two dimensions. It is easy in three dimensions, and some
tricks may allow us to represent a four-dimensional probability distribution. Moreover,
the probability of an event A can directly be evaluated by an integral, using standard
(nonrandom) numerical techniques.
Figure 2.1. The sampling of
a probability density allows us to per-
form any of the computations intro-
duced in probability theory (compu-
tation of the probability of an event,
estimation of some moments, etc.) us-
ing simple statistics.
When the model space has a large number of dimensions, representing a probability
densityisimpossible, butwecan, atleastinprinciple, dosomethingthatislargelyequivalent:
we can sample27 the probability density, as suggested in Figure 2.1. The advantage of
considering a set of samples of a probability distribution is that the individual ‘points’ can
be represented, typically as images, as those in Figure 2.2 (see also the images at the right
in Figure 2.5).
There is one problem with large-dimensional spaces that it is easy to underestimate:
they tend to be terribly empty. Figure 2.3 shows that the probability of hitting by chance the
(maximum-size) hypersphere inscribed in a hypercube rapidly decreases to zero when the
dimension of the space grows. When the goal is not to hit a large sphere, but a small region
27To sample a probability density means to generate (independent) points that are samples of it, i.e., such that
the probability of any of the points being inside any domain A equals the probability of the domain A .

2.1. Introduction
43
Figure 2.2. Nine random realizations of a probability distribution over a 36-
dimensional space. The 36 values are in fact values on a 6 × 6 array, and when the values
are represented using grades of gray, each realization is an image. Note that most of the
images present a “Greek cross” (highlighted). Also, the pixels in the two bottom rows
tend to correspond to higher values of the random variable (darker grades of gray). Given
enough of these samples, the probability of different events can be evaluated, for instance,
(i) the probability that a Greek cross may be present, (ii) the probability of a Greek cross at
the left side of the image (they tend to be at the right side), (iii) the probability of having a
Greek cross and, at the same time, low values of the variable at the bottom of the ﬁgure, etc.
Figure 2.3.
Large-dimensional
spaces tend to be terribly empty. Hitting
by chance the circle inscribed in a square
is easy. Hitting by chance the sphere in-
scribed in a cube is a little bit more difﬁcult.
When the dimension of the space grows, the
probability of hitting the hypersphere in-
scribedinahypercuberapidlytendstozero.
At the top, the volume of the hypersphere
and of the hypercube is given as a function
of the dimension n , and at the bottom the
ratio of the volumes is displayed. This ﬁg-
ure explains why the random exploration of
large-dimensional spaces is always difﬁcult
and why Brownian motion types of random
exploration are used.
of signiﬁcant probability, with not much idea of where it may be, one easily understands
that Monte Carlo methods that may work on large-dimensional spaces are far from trivial.
In fact, there are two problems in a Monte Carlo sampling of a probability distribu-
tion in a large-dimensional space: (i) locating the region(s) of signiﬁcant probability, and
(ii) sampling the whole of the region(s) densely enough. Discovering the location of the

44
Chapter 2. Monte Carlo Methods
regions is the most difﬁcult problem, and mathematics alone cannot solve it (because of the
great emptiness of large-dimensional spaces): it is the particular physics (or geometry) of
the problem at hand that may help on this. Once one has been able to come close to one of
these regions, the techniques described below (Gibbs sampler or Metropolis algorithm) are
able to perform a random walk, a sort of Brownian motion that is efﬁcient in exploring the
region, and avoid leaving it (thus entering the vast empty regions of the space).
2.2
The Movie Strategy for Inverse Problems
We have seen in chapter 1 that two typical inputs to the inverse problem are a probability
density ρM(m) , describing the a priori information on the model parameters, and a prob-
ability density ρD(d) , describing the information we have on the data parameters, gained
through some measurements. The solution to the inverse problem is given by a (posterior)
probability density σM(m) that equals the (normalized) product of the prior probability
density ρM(m) times a likelihood function L(m) :
σM(m) = k ρM(m) L(m)
.
(2.1)
The likelihood function is a measure of how good the model m is in ﬁtting the data. The
normalizing constant can be written k = 1 /

M dm ρM(m) L(m) .
In the most general setting, the relation between data and model parameters is proba-
bilistic and is represented by a conditional probability density θ(d|m) . Then, the likelihood
function is (see equations (1.89)–(1.91))
L(m) =

D
dd ρD(d) θ(d | m)
µD(d)
,
(2.2)
where µD(d) is the homogeneous probability density in the data manifold.
Sometimes, the relation between data and model parameters is functional, d = g(m) ,
and in this case the likelihood function is (see equations (1.93)–(1.95))
L(m) = ρD( g(m) )
.
(2.3)
A couple of examples of such a likelihood function are given as a footnote.28
As the methods about to be developed require the computation of the value of the
likelihood at many points, that the expression of the likelihood takes the form (2.2) or (2.3)
is far from irrelevant.
In this chapter, we are going to describe methods that allow us, ﬁrst, to obtain samples
{m1 , m2 , . . . } of the prior probability density ρM(m) , then samples {m′
1 , m′
2 , . . . } of
the posterior probability density σM(m) . As, typically, each sample (i.e., each model) can
be represented as an image, the display of many samples corresponds to the display of a
‘movie.’ Let us start discussing the generation of the ‘prior movie.’
28For instance, if di
obs represents the observed data values and σ i the estimated mean deviations, assuming
double exponentially distributed observational errors gives L(m) = exp( −
i | gi(m) −di
obs | / σ i ) . If CD
represents the covariance operator describing estimated data uncertainties and uncertainty correlations, assuming
a Gaussian distribution gives (equation (1.101)) L(m) = exp( −1
2 (g(m) −dobs)t C −1
D (g(m) −dobs) ) . Some
other examples are given in chapter 1.

2.2. The Movie Strategy for Inverse Problems
45
The display (and study) of the samples from ρM(m) allows us to verify that we are
using adequate a priori information. It may help convey to others which kind of a priori
information we have in mind (and may perhaps allow these persons to criticize the a priori
information we are trying to use). We already saw one example of three samples from an
a priori probability distribution in Example 1.32, where three layered Earth models were
displayed (Figure 1.10, page 30). Let us see another simple example.
Example 2.1. Gaussian random ﬁeld. A Gaussian random ﬁeld is characterized by its
mean ﬁeld mmean(x) and its covariance CM(x, x′) . Given these, it is possible to generate
as many random realizations of the random ﬁeld as one may wish (using, for instance, the
method suggested in Example 2.2 below). Figure 2.4 displays three random realizations
of a Gaussian random ﬁeld of zero mean and spherical covariance29 (with values coded
in a color scale). Given a large enough number of these realizations, the mean ﬁeld and
the covariance are easy to estimate (using simple statistics) so a large enough number
of realizations completely characterizes the random ﬁeld. Because the covariance of this
random ﬁeld happens to be stationary, three images already convey a good idea of the
random ﬁeld itself. More images would be needed for a more general covariance. The
display of these samples of the a priori probability distribution allows other scientists to
evaluate the correctness of the a priori information being input into the inverse problem
(that the actual (unknown) ﬁeld is a random realization of such a random ﬁeld). Displaying
the mean of the Gaussian random ﬁeld and plotting the covariance is not an alternative to
displaying a certain number of realizations, because mean and covariance do not relate in
an intuitive way to the realizations.
Figure 2.4. Three random
realizations of a 2D Gaussian ran-
dom ﬁeld. The mean ﬁeld is zero, and
the(stationary)covarianceisthesum
of a white noise plus a spherical co-
variance. (A. Boucher, pers. comm.)
When the problem of displaying samples of the prior probability density ρM(m) has
been solved (and agreement has been reached about the existence and suitability of such
a priori information), one may produce samples of the posterior probability density σM(m) .
The general methods of producing these samples of the posterior distribution are only to
be introduced in the sections below, but we can examine here a very simple example of an
inverse problem, where the generation of these samples can be done using a simple theory.
Example 2.2. Sampling a conditional Gaussian random ﬁeld. Let us brieﬂy examine
here a simple inverse problem that has a high pedagogical value. We face an unknown 2D
ﬁeld that is assumed to be a random realization of the Gaussian random ﬁeld introduced in
Example 2.1 (three random realizations of the random ﬁeld were displayed in Figure 2.4).
29The spherical covariance, a commonly used model of covariance in geostatistics, is described in Example 5.7,
page 113.

46
Chapter 2. Monte Carlo Methods
Figure 2.5. From a random realization of the Gaussian random ﬁeld described
in Figure 2.4, the 50 values shown at the top left were extracted to be used as data. The
particular random realization that was used to obtain these data is unknown to us, but
the mean and the covariance of the Gaussian random ﬁeld are given. The prior Gaussian
ﬁeld (as deﬁned by its mean and covariance) is then conditioned with the given data values
(corresponding to the solution of a simple kind of inverse problem). In this way, a posterior
Gaussian ﬁeld is deﬁned whose mean 
mmean(x) and covariance 
CM(x, x) can be expressed
(see text for details). Rather than becoming directly interested in this posterior mean and
covariance, it is much better to generate some random samples of the posterior Gaussian
random ﬁeld of which we know the mean and covariance. Nine such random realizations are
displayedintherightpartoftheﬁgure. Alltheserealizationssatisfythe50initialdatavalues.
The actual realization from which the 50 data values were extracted could have resembled
any of these realizations (in fact, it was the one at the left in Figure 2.4). These nine panels
convey a clear idea of the variability in the solution to the problem. Note that the variability
is greater in the regions where there is not much data. The statistical mean of 50 such
random realizations is displayed at the bottom left, together with the (theoretical) posterior
mean 
mmean(x) (just above the statistical mean), and they are virtually indistinguishable.
The computations here have been performed by A. Boucher (pers. comm.).
We are given, as data, the k values { m(x1) , m(x2) , . . . , m(xk) } of the unknown real-
ization m(x) at k points { x1 , x2 , . . . , xk } . If these values are assumed to be exactly
known, we can pass from the prior random ﬁeld to the posterior random ﬁeld just using the
notion of conditional probability. If the values are only known with some uncertainties, the
posterior random ﬁeld can be obtained setting an inverse problem, essentially using the third
of equations (1.106) and the second of equations (1.107) (see Example 5.25 on page 135 for
an explicit formulation of this problem). In either case we end up with a posterior Gaussian

2.2. The Movie Strategy for Inverse Problems
47
random ﬁeld, of which we can express the mean 
mmean(x) and the covariance 
CM(x, x′) .
But, again, instead of representing the mean and analyzing the covariance, it is better to
generate realizations of the random ﬁeld, which can be done as follows. Take randomly
a point xa in the space. At this point we have a Gaussian random variable with mean

mmean(xa) and variance 
CM(xa, xa) . It is then possible to generate a random realization
of this one-dimensional random variable.30 This will give some value m(xa) . We started
the problem with the values of the ﬁeld given at k points. We now have the values of the
ﬁeld given at k + 1 points. The problem can then be reformulated using the k + 1 points,
and the same method can be used to randomly generate a new value at some point xb , and
so on until we have realized the value of the random ﬁeld in as many points as we may wish.
Figure 2.5 presents an actual implementation31 of this algorithm in two space dimensions,
starting with the values of the ﬁeld given at 50 points.
From the example above, the reader should keep in mind that the solution of an inverse
problem, being a probability distribution, is never one image, but a set of images, samples of
the posterior probability density σM(m) . The common practice of plotting the ‘best image’
or the ‘mean image’ should be abandoned, even if it is accompanied by some analysis of error
and resolution. For instance, when using least-squares methods to formulate the problem
described in the example, what is called the solution is the mean of the posterior Gaussian
distribution, i.e., the smooth image in the middle of the left column of Figure 2.5. This is not
the solution; it is, rather, the mean of all possible solutions (hence its smoothness). Looking
at this mean provides much less information than looking at a movie of realizations. Note
that, by construction, each of the realizations captures the essential random ﬂuctuations of
the actual ﬁeld from which the data were extracted (at the left in Figure 2.4).
For another example of the generation of such a movie (in a geophysical context), see
Koren et al. (1991).32
When such a (hopefully large) collection of random models is available, we can also
answer quite interesting questions. For instance, in a tectonic model, one may ask, At which
depth is the subsurface structure? To answer this, we can make a histogram of the depth of
the given geological structure over the collection of random models, and the histogram is the
answer to the question. What is the probability of having a low velocity zone around a given
depth? The ratio of the number of models presenting such a low velocity zone over the total
number of models in the collection gives the answer (if the collection of models is large
enough). This is essentially what must be proposed: to look at a large number of randomly
generated models (ﬁrst, of the prior distributon, and then, of the posterior distribution) in
order to intuitively apprehend the basic properties of the probability distribution, followed
by calculation of the probabilities of all interesting events.
Sometimes, it may nevertheless be necessary to estimate some moments (mean, co-
variance, etc.) of the distribution. Of course, they can also be evaluated using the samples.
The relevant formulas are given as a footnote.33 Appendix 6.9 gives some details on Monte
Carlo methods of numerical integration.
30See, for instance, the inversion method explained in section 2.3.1.
31This implementation is based on the Gaussian sequential simulation algorithm (Goovaerts, 1997).
32The movie itself may be watched at http://www.ccr.jussieu.fr/tarantola/.
33Assume that the model space manifold is a linear space. If the posterior probability density σM(m) is not
too far from Gaussian, one may wish to compute the mean model and the covariance of the distribution (one can

48
Chapter 2. Monte Carlo Methods
The sampling method suggested in the example above (sequential random realization)
is not easy to use in general inverse problems, since it involves the consideration of one-
dimensional conditional and marginal probability distributions that are usually not available,
except for very simple problems, as when we have linear relations between data and model
parameters. We must then resort to much less efﬁcient, but much more general, methods,
like those based on the Metropolis algorithm, described later in this chapter.
2.3
Sampling Methods
2.3.1
The Inversion Method
Consider a probability density f (x) depending on only one (scalar) variable x . This
may occur when we really have one single random variable or, more often, when on a
multidimensional manifold we consider a conditional distribution along a line (along which
x is a parameter). The inversion method consists of introducing the cumulative probability
y = F(x) =
 x
xmin
dx′ f (x′)
,
(2.4)
which takes values in the interval [0, 1] , and the inverse function x = F −1(y) . It is easy
to see34 that if one randomly generates values of y with constant probability density in the
interval [0, 1] , then the values x = F −1(y) are random samples of the probability density
f (x) . Provided the function F −1 is available, the method is simple and efﬁcient.
Example 2.3. Let y1 , y2 , . . . be samples of a random variable with constant probability
density in the interval [0, 1] , and let erf−1 be the inverse error function.35 The numbers
erf−1(y1) , erf−1(y2), . . . are then normally distributed, with zero mean and unit variance
(see Figure 2.6).
Figure 2.6.
Use of the inver-
sion method to produce samples of a two-
dimensional Gaussian probability density.
compute this event for distributions that are far from Gaussian, but these estimators may not be very meaningful).
If one has K samples m1, m2, . . . , mK of σM(m) , the mean model (of σM(m) ) is approximately given by
⟨m⟩=
1
K
K
n=1 mn and the covariance matrix by C =
1
K
K
n=1( mn −⟨m⟩) ( mn −⟨m⟩)t , or, equivalently,
C = 1
K
K
n=1 mn mt
n −⟨m⟩⟨m⟩t .
34This immediately results from the Jacobian rule, as dy/dx = f (x) .
35The error function erf(x) is the integral between −∞and x of a normalized Gaussian with zero mean and
unit variance (be careful, there are different deﬁnitions). One may ﬁnd in the literature different series expressions
for erf−1 .

2.3. Sampling Methods
49
2.3.2
The Rejection Method
The rejection method starts by generating samples x1 , x2 , . . . of the homogeneous prob-
ability density µ(x) , which is usually a simple problem. Then, each sample is submitted
to the possibility of a rejection, the probability that the sample xk is accepted being taken
equal to
P = f (xk)/µ(xk)
(f/µ)max
,
(2.5)
where (f/µ)max stands for the maximum of all the values f (x)/µ(x) , or any larger number
(the larger the number, the less efﬁcient the method). It is then easy to prove that any accepted
point is a sample of the probability density f (x) .
This method works reasonably well in one dimension or two dimensions (Figure 2.1
was generated using the rejection method) and could, in principle, be applicable in any
number of dimensions. But, as was already mentioned, large-dimensional spaces tend to
be very empty, and the chances that this method accepts a point may be dramatically low
when working with multidimensional spaces.
2.3.3
Sequential Realization
In this method, one uses the property that a general n-dimensional probability density
fn(m1, m2, . . . , mn) canalwaysbedecomposedastheproductofaone-dimensionalmarginal
and a series of one-dimensional conditionals (see Appendix 6.10):
fn(m1, m2, . . . , mn)
= f1(m1) f1|1(m2|m1) f1|2(m3|m1, m2) . . . f1|n−1(mn|m1, . . . , mn−1)
.
(2.6)
All these marginal and conditional probability densities are contained in the original
n-dimensional joint probability density fn(m1, m2, . . . , mn) and can, at least in principle,
be evaluated from it using integrals. Assume that they are all known, and let us see how an
n-dimensional sample could be generated.
One starts generating a (one-dimensional) sample for the variable m1 , using the one-
dimensional marginal f1(m1) , giving a value m1
0 . With this value at hand, one generates a
(one-dimensional) sample for the variable m2 , using the conditional f1|1(m2|m1
0) , giving a
value m2
0 . Then, one generates a (one-dimensional) sample for the variable m3 , using the
conditional f1|2(m3|m1
0, m2
0) , giving a value m3
0 , and so on, until one generates a sample
for the variable mn , using the conditional f1|n−1(mn|m1
0, . . . , mn−1
0
) , giving a value mn
0 .
In this manner, a point {m1
0, m2
0, . . . , mn
0} is generated that is a sample of the original
fn(m1, m2, . . . , mn) .
2.3.4
The Gibbs Sampler
The so-called Gibbs sampler (Geman and Geman, 1984) corresponds to performing a ran-
dom walk in an n-dimensional parameter manifold that is very similar to a Metropolis
random walk, except that no rejection is used (as discussed below, this advantage is more
virtual than real). First, we must assume that the parameter space is a linear space, so that
the notion of direction at a given point makes sense.

50
Chapter 2. Monte Carlo Methods
Let f (x1
k, x2
k, . . . , xn
k ) be the probability density we wish to sample, and let xk =
{x1
k, x2
k, . . . , xn
k } be the last point visited. Deﬁne randomly36 a line in the parameter space
that passes through the current point xk . Along that line one has a one-dimensional (con-
ditional) probability density. One sample is then generated along this one-dimensional
probability distribution, giving a new point xk+1 . It can be demonstrated that iterating
this procedure actually produces a series of samples of the joint probability distribution
f (x1
k, x2
k, . . . , xn
k ) .
When an analytical, explicit expression is available for the probability density
f (x1
k, x2
k, . . . , xn
k ) , this method works well and is efﬁcient. When solving inverse prob-
lems, we wish to sample the posterior probability density in the model parameter space,
σM(m) , and except in very simple problems, the evaluation of the value of σM at a given
point m requires extensive computations. Then, the requirement of the Gibbs sampler
method, that we know the conditional probability density along given directions, is not
immediately satisﬁed. I have never been convinced that, in complex problems, the nu-
merical estimation of the conditional probability density along a given direction, plus an
exact (nonrejection) generation of a sample along that direction, gives superior results to
the Metropolis (rejection) method presented in the next section.
2.3.5
The Metropolis Algorithm
The Metropolis (or Metropolis–Hastings) algorithm was developed by Metropolis and Ulam
(1949), Metropolis et al. (1953), and Hastings (1970). It is a Markov chain Monte Carlo
(MCMC) method, i.e., it is random (Monte Carlo) and has no memory, in the sense that
each step depends only on the previous step (Markov chain).
The basic idea is to perform a random walk, a sort of Brownian motion, that, if
unmodiﬁed, would sample some initial probability distribution, then, using a probabilistic
rule, to modify the walk (some proposed moves are accepted, some are rejected) in such a
way that the modiﬁed random walk samples the target distribution. While it is quite easy to
invent probabilistic rules that would satisfy the goal, the Metropolis rule is the most efﬁcient
(it accepts the maximum of the proposed moves, reducing the computational requirements).
I follow here the presentation of the Metropolis algorithm made by Mosegaard and Tarantola
(2002).
Consider the following problem. We have two probability densities f (x) and g(x)
together with their homogeneous limit (see chapter 1) µ(x) . We have an algorithm that is
able to generate samples of f (x) . How should we modify the algorithm in order to obtain
samples of the conjunction of the two probability densities
h(x) = k f (x) g(x)
µ(x)
?
(2.7)
The criteria to be used will not depend on the values of the probability density g(x) ,
but on the values of the associated likelihood function (see equation (1.31)), so let us
introduce it explicitly:
γ (x) = g(x) / µ(x)
.
(2.8)
36Often, instead of choosing directions at random, the n directions deﬁned by the n coordinates xi are used
sequentially.

2.4. Monte Carlo Solution to Inverse Problems
51
By hypothesis, some random rules deﬁne a random walk that samples the probability
density f (x) . At a given step, the random walker is at point xi , and the application of the
rules would lead to a transition to point xj . When all such proposed transitions xi →xj
are accepted, the random walker will sample the probability density f (x) . Instead of always
accepting the proposed transition xi →xj , we reject it sometimes by using the following
rule (to decide if the random walker is allowed to move to xj or if it must stay at xi ) :
• If γ (xj) ≥γ (xi) , then accept the proposed transition to xj .
• If γ (xj) < γ (xi) , then decide randomly to move to xj , or to stay at xi , with the
following probability of accepting the move to xj :
Pi→j = γ (xj) / γ (xi)
.
(2.9)
Then one has the following theorem:37 The random walker samples the conjunction h(x)
(equation (2.7)) of the probability densities f (x) and g(x) .
We shall call the above
acceptance rule the Metropolis rule. Note that to run the algorithm, there is no need to know
the normalizing constant k in equation (2.7).
As a special case of the proposed algorithm, we can take f (x) = µ(x) , in which case
h(x) = g(x) . Then, starting with a random walk that, if left unperturbed, would sample the
homogeneous probability density µ(x) , we end up with a random walk that samples any
desired probability density g(x) .
In Appendix 6.11, the cascaded use of the algorithm is described, which allows us to
sample the conjunction
h(x) = k µ(x) f1(x)
µ(x)
f2(x)
µ(x) . . . fp(x)
µ(x)
(2.10)
of a sequence of probability densities.
2.3.6
Genetic Algorithms
One usually ﬁnds in the literature another type of Monte Carlo techniques, based on a
biological analogy, called the genetic algorithms (Goldberg, 1989). Unfortunately, genetic
algorithms lack the basic theorem of the Metropolis algorithm (“if you do this and this, then
you generate samples of the distribution, in the precise, technical sense of sample”) and are
not described here.
2.4
Monte Carlo Solution to Inverse Problems
As mentioned at the beginning of section 2.2, the a posteriori probability density in the
model manifold is expressed as
σM(m) = k ρM(m) L(m)
,
(2.11)
where the probability density ρM(m) represents the a priori information on the model
parameters and the likelihood function L(m) is a measure of the goodness of the model
m in ﬁtting the data. Two possible expressions for L(m) are given in equations (2.2)
and (2.3).
37See Mosegaard and Tarantola (2002) for the demonstration.

52
Chapter 2. Monte Carlo Methods
2.4.1
Sampling the Prior Probability Distribution
The movie strategy proposed above requires that we start by generating samples of the prior
probability density ρM(m) . In typical inverse problems, the probability density ρM(m) is
quite simple (the contrary happens with the posterior probability density σM(m) ). There-
fore, the sampling of ρM(m) can often be done using simple methods. We have seen two
examples of this (Example 1.32 on page 29 and Example 2.1 on page 45). The sampling of
the prior probability density usually involves a sequential use of one-dimensional sampling
methods, like those described above. Sometimes, a Gibbs sampler or even a Metropolis
algorithm may be needed, but these are usually simple to develop.
So, let us assume that we are able to obtain samples of the prior probability density
ρM(m) , and let us move to the difﬁcult problem of obtaining samples of the posterior
probability density σM(m) .
2.4.2
Sampling the Posterior Probability Distribution
The adaptation of the Metropolis algorithm (presented in section 2.3.5) to the problem of
sampling the posterior probability density (equation (2.11)),
σM(m) = k ρM(m) L(m)
,
(2.12)
is immediate. As just discussed, assume that we are able to obtain as many samples of the
prior probability density ρM(m) as we wish. At a given step, the random walker is at point
mi , and the application of the rules would lead to a transition to point mj . Sometimes,
we reject this proposed transition by using the following rule:
• If L(mj) ≥L(mi) , then accept the proposed transition to mj .
• If L(mj) < L(mi) , then decide randomly to move to mj , or to stay at mi , with
the following probability of accepting the move to mj :
Pi→j = L(mj)
L(mi)
.
(2.13)
Then, the random walker samples the a posteriori probability density σM(m) .
2.4.3
Designing the Random Walk
The goal is to obtain samples of the posterior probability density σM(m) that are indepen-
dent. One easy way to obtain independency of the posterior samples is to present to the
Metropolis algorithm independent samples of the prior probability density ρM(m) . Except
for problems where the model manifold has a very small number of dimensions, this will
not work, because of the emptiness of large-dimensional spaces (mentioned in section 2.1).
Therefore, the sampling of the prior probability distribution has to be done jumping from
point to point making small jumps. This kind of sampling, called a random walk, is a sort of
Brownian motion that is far from producing independent samples. Then, if the samples of
the prior distribution presented to the Metropolis algorithm are not independent, the samples
of the posterior distribution produced by the Metropolis algorithm will not be independent.

2.4. Monte Carlo Solution to Inverse Problems
53
There is only one solution to this problem: instead of taking all the samples produced
by the Metropolis algorithm, after taking one sample, wait until a sufﬁcient number of moves
have been made, so that the algorithm has “forgotten” that sample. How many moves have
we to wait, after one sample, in order to have some conﬁdence that the next sample we
consider is independent of the previous one? No general rule can be given, as this will
strongly depend on the particular problem at hand.
The second important point is the following: only a small fraction of the inﬁnitely
many random walks that would sample the prior distribution will allow the Metropolis
algorithm to have a reasonable efﬁciency.
The basic rule is the following: among the many possible random walks that can
sample the prior probability density ρM(m) , select one that, when jumping from one sample
of the prior probability density to the next, the perturbation of the likelihood function L(m)
is as small as possible (in order to increase the acceptance rate of the Metropolis rule).
To be more precise, the type of perturbations in the model space has to be such that large
perturbations (in the model space) only produce small perturbations of the predicted data.
When the type of perturbations in the model space satisﬁes this requirement, it remains to
decide the size of the perturbations to be made. There is a compromise between our wish
to move rapidly in the model space and the need for the Metropolis algorithm to ﬁnd some
of the proposed moves acceptable. So, the size of the perturbations in the model space
has to be such that the acceptance rate of the Metropolis criterion is, say, 30–50%. If the
acceptance rate is larger, we are not moving fast enough in the model space; if it is much
smaller, we are wasting computer resources to test models that are not accepted. In this
way, we strike a balance between extensive exploration of the model space (large steps but
many rejects) and careful sampling of located probability maxima (small steps, few rejects,
but slow walk).
These remarks show that considerable ingenuity is required in designing the random
walk that is to sample ρM(m) . For instance, in a problem involving a model of mass density
distribution, the data consisting of values of the gravity ﬁeld, Mosegaard and Tarantola
(1995) chose to make large perturbations of the mass density distribution but kept the total
mass approximately constant.
The last point to be examined concerns the decision to stop the random walk when
the posterior probability density σM(m) has been sufﬁciently sampled. There are two
subproblems here, an easy one and a difﬁcult one. The easy problem is to decide, when
exploring a given maximum of the probability density, that this maximum has conveniently
been sampled. The literature contains some good rules of thumb for this.38 The difﬁcult
problem, of course, is about the possibility that we may be completely missing some region
of signiﬁcant probability of σM(m) , an isolated maximum, for instance. This problem is
inherent in all Monte Carlo methods and is very acute in highly nonlinear inverse problems.39
Unfortunately, nothing can be said here that would be applicable to any large class of inverse
problems: eachproblemhasitsownphysics, andtheexperienceoftheimplementeriscrucial
here. This issue must be discussed every time an inverse problem is solved using Monte
Carlo methods.
38For instance, see Geweke (1992) or Raftery and Lewis (1992).
39In the case where one has a relation d = g(m) , this means that the function g( · ) is highly nonlinear.

54
Chapter 2. Monte Carlo Methods
A ﬁnal comment about the cost of using the Metropolis algorithm for solving inverse
problems: Each step of the algorithm requires the evaluation of L(m) . This requires the
resolution of a forward problem (in the case where the likelihood function is given by
expression (2.3)) or the evaluation of an integral (in the case where the likelihood function
is given by expression (2.2)). This may be very demanding on computational resources.
2.5
Simulated Annealing
The simulated annealing technique is designed to obtain the maximum likelihood point of
any probability density, in particular for the posterior probability density σM(m) . But at
the core of the simulated annealing there is a Metropolis algorithm that is able to sample
σM(m) . My point of view is that if we are able to sample the probability density σM(m) ,
we should not be interested in the maximum likelihood point. As any central estimator
(like the mean or the median), the maximum likelihood point is of very little interest when
dealing with complex probability distributions.
The simulated annealing technique is described here for completeness of the theory,
not because it is an important element of it.
Annealing consists of heating a solid until thermal stresses are released, then in cooling
it very slowly to the ambient temperature. Ideally, the substance is heated until it melts, and
then cooled very slowly until a perfect crystal is formed. The substance then reaches the
state of lowest energy. If the cooling is not slow enough, a metastable glass can be formed.
Simulated annealing (Kirkpatrick et al., 1983, Geman and Geman, 1984) is a numer-
ical method, using an analogy between the process of physical annealing and the mathe-
matical problem of obtaining the global minimum of a function (assimilated to an energy)
that may have local minima (metastable states). It has been introduced in the framework of
inverse theory by Rothman (1985a, 1985b, 1986).
We are about to see that simulated annealing has, at its core, a Metropolis algorithm.
And we have seen above that in using a Metropolis algorithm one may sample the probability
distribution in the model space. Distorting it until it peaks at the maximum likelihood
point (this is what simulated annealing does) is not necessarily an elegant strategy. Let us,
nevertheless, mention the basic tools here.
Let σM(m) be the (not necessarily normalized) posterior probability density in the
model space manifold, and let µM(m) be its homogeneous limit. We wish to obtain the
maximum likelihood point mML :
σM(m)
µM(m)
maximum for
m = mML
.
(2.14)
As explained in section 1.6.4, the maximum of a probability density does not (invariantly)
deﬁne a point; the maximum of the ratio of the probability density to the homogeneous
probability density does.
To locate this maximum, we may deﬁne the energy function
S(m) = −T0 log σM(m)
µM(m)
,
(2.15)

2.5. Simulated Annealing
55
where T0 is an arbitrary, but ﬁxed, real (adimensional) positive number, termed the ambient
temperature (for instance, T0 = 1 ). This gives
σM(m) = µM(m) e−S(m)/T0
.
(2.16)
Deﬁne now, for arbitrary temperature T , the new function
σM(m, T ) = µM(m) e−S(m)/T
,
(2.17)
and, for any ﬁxed value of T , start a Metropolis algorithm that produces samples of
σM(m, T ) . If, while the Metropolis algorithm is at work, one very slowly changes the
value of T toward zero, it is clear that the sampling algorithm will end up sampling only
models that are in the immediate vicinity of the maximum value of the energy function
S(m) , i.e., in the immediate vicinity of the maximum likelihood point mML .
If the temperature T is brought to zero too rapidly, then the system will converge to
a ‘metastable’ solution, i.e., to a local maximum of σM(m)/µM(m) instead of to the global
maximum.
For µM(m) = const. , equation (2.17) clearly resembles the Gibbs distribution (also
called the canonical distribution), giving the probability of a state m with energy S(m)
of a statistical system at temperature T (the Boltzmann constant k is taken here equal to
1). This justiﬁes the name “energy function” for S(m) and “temperature” for T . The
factor µM(m) slightly generalizes the Gibbs distribution: the probability density at inﬁnite
temperature is the homogeneous probability density µM(m) .
Example 2.4. In the Gaussian case examined in Example 1.37, we have arrived at the
posterior probability density
σM(m) = k exp( −S(m) )
,
(2.18)
where k is a normalization constant and S(m) is the least-squares misﬁt function
S(m) = 1
2

( g(m) −dobs )t C −1
D
( g(m) −dobs ) + ( m −mprior )t C −1
M ( m −mprior )

.
(2.19)
We see that the energy function introduced in equation (2.15) is identical here to the misﬁt
function. Changing the temperature simply means replacing equation (2.18) with (taking
T0 = 1 )
σM(m) = k exp

−S(m)
T

,
(2.20)
i.e., multiplying the misﬁt function by a constant.


Chapter 3
The Least-Squares Criterion
If we know that our individual errors and ﬂuctuations
follow the magic bell-shaped curve exactly,
then the resulting estimates are known to have
almost all the nice properties that people have been able to think of.
John W. Tukey, 1965
Least squares are popular for solving inverse problems because they lead to the easiest
computations. Their only drawback is their lack of robustness, i.e., their strong sensitivity
to a small number of large errors (outliers) in a data set.
In this book, the least-squares criterion is justiﬁed by the hypothesis that all initial
uncertainties in the problem can be modeled using Gaussian distributions. Covariance
operators play a central role in the method; the underlying mathematics is simple and
beautiful.
When the equation solving the forward problem is linear, posterior uncertainties are
also Gaussian, and an explicit expression is obtained for the posterior probability distribu-
tion. When the forward equation is nonlinear, the posterior probability isn’t Gaussian, but,
if nonlinearities are not too severe, ﬁnding the maximum likelihood point of the distribution
and estimating the shape of the distribution around this point (i.e., estimating the covariance
matrix of the distribution) may satisfactorily solve the problem.
3.1
Preamble: The Mathematics of Linear Spaces
We are about to see that least-squares methods are intimately linked to Gaussian probability
distributions. These are only deﬁned over linear spaces (which is why on the surface of the
sphere one uses the Fisher distribution, as there is no Gaussian deﬁned).
Later in this section, therefore, the model space manifold M is assumed to be a
linear space (denoted M ), and the data manifold D is also assumed to be linear (and is
denoted D ). Sums and difference of vectors and multiplication of a vector by a real number
57

58
Chapter 3. The Least-Squares Criterion
are, therefore, deﬁned. For some problems, the model parameter space is not linear, but
one may work only in a small region around some initial point. Then, one uses the linear
tangent space. Let us start by recalling some basic terminology of linear spaces.
3.1.1
Dual of a Linear Space
Let V be an n-dimensional linear space40 with vectors denoted v, w, . . . . When a basis
{e1, . . . , en} is chosen, any vector v can be decomposed as v = vi ei , deﬁning the compo-
nents {vi} of the vector. In a linear space, the sum of two elements v + w is deﬁned (and
equals the sum of the components), as is deﬁned the product of a vector by a real number:
(u + v)i = ui + vi
,
(λ v)i = λ vi
.
(3.1)
The dual of V , denoted V∗, is the space of all the linear forms over V , i.e., the
space of all the linear applications mapping V into ℜ. If ω is an element of V∗, the real
number it associates with an element v of V is denoted ⟨ω , v ⟩, so one may write
v
→
λ = ⟨ω , v ⟩
.
(3.2)
One says that ⟨ω , v ⟩is the duality product of ω by v . As Figure 3.1 suggests, a linear
form can be represented by a “mille-feuilles.”
Figure 3.1. While a vector can be rep-
resented as an “arrow,” a linear form can be
represented by a mille-feuille. The number as-
sociated by a linear form with a vector equals
the number of “feuilles” (layers) traversed by
the vector. Although only four layers are rep-
resented, there is an inﬁnity of them (and they
are inﬁnitely large).
The sum of two linear forms and the product of a form by a real number are deﬁned
through
⟨(ω + ν) , v ⟩= ⟨ω , v ⟩+ ⟨ν , v ⟩
,
⟨α ω , v ⟩= α ⟨ω , v ⟩
,
(3.3)
and it is easy to see that, with these deﬁnitions, the dual V∗of a linear space V is also a
linear space. Taking a basis {ϵ1, . . . , ϵn} in V∗allows us to write any element ω ∈V∗
as ω = ωi ϵi , deﬁning the components {ωi} of ω . The place of the indices (in the upper
or lower position) is traditional in tensor notation and allows us to use the implicit sum
40In a linear space, the sum v1 + v2 of two elements of V and the multiplication λ v of a real number by
an element of V are deﬁned and satisfy the following conditions. For any v1 and v2 , v1 + v2 = v2 + v1
(commutativity). For any v1 , v2 , and v3 , (v1 +v2)+v3 = v1 +(v2 +v3) (associativity of the sum). There is an
element 0 such that, for any v , v+0 = v (existence of zero). For any v , there exists (−v) such that v+(−v) = 0
(existence of opposite). For any v1 , v2 and any real λ , λ (v1 + v2) = λ v1 + λ v2 (ﬁrst distributivity). For any
v and any reals λ and µ , (λ + µ) v = λ v + µ v (second distributivity). For any v and any reals λ and µ ,
(λ µ) v = λ (µ v) (associativity of the product). Finally, for any v , 1 v = v .

3.1. Preamble: The Mathematics of Linear Spaces
59
convention, deﬁned as follows. In normal expressions, the sums over indices involve an
index in the lower position and an index in the upper position, as in r = 
i ωi vi or
di = 
α Giα mα . By convention, the sum sign is not written, and one simpliﬁes the
expressions into
ωi vi ≡

i
ωi vi
,
Gi
α mα ≡

α
Gi
α mα
(implicit sum convention) .
(3.4)
The bases in V and V∗can always be chosen so as to have
⟨ϵi , ej ⟩= δi
j
.
(3.5)
When this is the case, one says that the bases are mutually dual. Then, the duality product
of ω ∈V∗and v ∈V can be successively written ⟨ω , v ⟩= ⟨ωi ϵi , vj ej ⟩=
ωi vj ⟨ϵi , ej ⟩= ωi vj δi
j = ωi vi . Therefore, the duality product can simply be expressed
as (note that the implicit sum convention is being used)
⟨ω , v ⟩= ωi vi
.
(3.6)
For the same reason that when a basis {ei} is chosen over the linear space V an
element v ∈V can just be seen as a sequence of n quantities {v1, . . . , vn} , when a
basis {ϵi} is chosen over V∗, an element ω ∈V∗can just be seen as a sequence of n
quantities {ω1, . . . , ωn} . From this perspective, the dual of a linear space is just an ad
hoc space, closely resembling the original space, except that if the quantities {v1, . . . , vn}
have physical dimensions, the quantities {ω1, . . . , ωn} must have the reciprocal physical
dimensions in order for the expression λ = ωi vi to make sense.
It is useful to also introduce the notation ⟨ω , v ⟩= ωt v : if the elements v and ω
are seen as column matrices, the expression ωt v can be interpreted as a matrix product.
We then have the three equivalent expressions
⟨ω , v ⟩= ωt v = ωi vi
.
(3.7)
3.1.2
Transpose of a Linear Operator
Let M and D be two linear spaces and M∗and D∗be the respective dual spaces. The
duality product of δ ∈D∗and d ∈D (resp., of µ ∈M∗and m ∈M ) is denoted ⟨δ , d ⟩D
(resp., ⟨µ , m ⟩M ). Let G be a linear operator mapping M into D . We can write
d = G m
(3.8)
or, in terms of the components (implicit sum convention used throughout this chapter),
di = Gi
α mα
.
(3.9)
The transpose of G , denoted Gt , is a linear operator, mapping D∗into M∗, deﬁned
by the condition that, for any δ ∈D∗and any m ∈M ,
⟨Gt δ , m ⟩M = ⟨δ , G m ⟩D
.
(3.10)

60
Chapter 3. The Least-Squares Criterion
Using the pseudomatricial notation introduced above for the duality product, the
deﬁnition (3.10) can be written
(Gt δ)t m = δt (G m)
(3.11)
or, in terms of the components, (Gt δ)α mα = δi (G m)i = δi Giα mα . Writing the compo-
nents of Gt as (Gt)αi gives
(Gt)α
i δi mα = δi Gi
α mα
(3.12)
and, as this must hold for any δ and any m , we arrive at
(Gt)α
i = Gi
α
.
(3.13)
This expresses that the two operators G and Gt have the same components, except in that
they are ‘transposed’: the matrix representing the operator Gt is the transpose of the matrix
representing G (although we could have taken this as the deﬁnition of transpose of a matrix,
the deﬁnition given above generalizes, as we will see in chapter 5, to linear operators that
are not matrices).
The result just demonstrated suggests a simpliﬁcation in the notation:
Gα
i ≡(Gt)α
i
.
(3.14)
Then, while Giα maps an element of M into an element of D , as in di = Giα mα , Gαi
maps an element of D∗into an element of M∗, as in µα = Gαi δi .
In the special circumstance where a linear operator L is considered that maps a linear
space V into its dual V∗, then, by deﬁnition, the transpose Lt also maps V into V∗. If,
in that case, L = Lt , the operator is called symmetric.
3.1.3
Scalar Product
Let V be a linear space and W be a weighting operator over V , i.e., a linear, symmetric,
and positive deﬁnite41 operator mapping V into its dual V∗. Given such a weighting
operator, the scalar product of two elements of V is deﬁned — via the duality product —
as
( u , v ) = ⟨W u , v ⟩
.
(3.15)
Using matricial notations for the duality product gives ( u , v ) = (W u)t v = ut Wt v =
ut W v , i.e.,
( u , v ) = ut W v
.
(3.16)
The inverse of a weighting operator, C = W −1 , is called a covariance operator,
which is also symmetric and positive deﬁnite. (For a demonstration that the usual proba-
bilistic deﬁnition of a covariance operator deﬁnes a symmetric and positive deﬁnite operator,
41 W is positive deﬁnite if, for any v ̸= 0 , ⟨W v , v ⟩> 0 .

3.1. Preamble: The Mathematics of Linear Spaces
61
see, for instance, Pugachev, 1965.) In terms of the covariance operator, the scalar product
is written
( u , v ) = ut C −1 v
.
(3.17)
When a weighting operator W has been deﬁned, there is a bijection between a linear
space and its dual. Denoting by ˆv the element of V∗associated with v ∈V by W , we
may write
ˆv = W v
(3.18)
or, using components, ˆvi = Wij vj . When there is no ambiguity about the operator W
deﬁning this bijection, the “hat” in ˆvi is dropped, and one simply writes
vi = Wij vj
.
(3.19)
The equation W C = I deﬁning the covariance operator becomes, using components,
Wij Cjk = δk
i
,
(3.20)
and the reciprocal of equation (3.19) is
vi = Cij vj
.
(3.21)
As the position of the indices clearly designates Wij and Cij , one could use a common
letter for both (as is done in differential geometry, where the same symbol is used for the
‘covariant metric’ gij and the ‘contravariant metric’ gij ), but we shall not do this here.
Given a scalar product, the norm of a vector v is deﬁned42 as ∥v ∥= ( v , v )1/2 .
Therefore,
∥v ∥2 = ( v , v ) = vt C −1 v = vt W v = vi Wij vj
.
(3.22)
One should keep in mind that a covariance operator maps a space into its dual and
that in usual problems one must simultaneously deal with two quite different spaces.
Example 3.1. Sometimes it happens that the components of v represent digitized values
of some continuous ﬁeld (see, for instance, Example 1.33 of chapter 1). The covariance
operator C is then generally a smoothing operator (see, for instance, Pugachev, 1965),
and the elements of V are smooth (i.e., are the discretized versions of smooth functions).
The inverse C −1 is then a “roughing” operator. The elements of V∗, obtained as images
of those of V through C −1 , are “rough” functions.
3.1.4
Adjoint of a Linear Operator
When deﬁning the transpose of a linear operator, it is not assumed that the vector spaces in
consideration have a scalar product. If they do, then it is possible to deﬁne the ‘adjoint’ of
a linear operator.
42See Appendix 6.12 for the demonstration that this actually deﬁnes a norm.

62
Chapter 3. The Least-Squares Criterion
As above, let G be a linear operator mapping M into D , and let ( , )D and ( , )M
represent the scalar products in D and M , respectively. The adjoint of G is denoted by
G∗and is the linear operator mapping D into M , deﬁned by the condition that, for any
d ∈D and any m ∈M , the following property holds:
( G∗d , m )M = ( d , G m )D
.
(3.23)
Let CM and CD be the covariance operators deﬁning the respective scalar products
in M and D . Using successively the deﬁnitions of scalar product and of the transpose
of an operator, we can write ( G∗d , m )M = ( d , G m )D = ⟨C −1
D d , G m ⟩D =
⟨Gt C −1
D d , m ⟩D = ( CM Gt C −1
D d , m )M , so, as this must hold for any m and any d ,
we arrive at the relation between adjoint and transpose:
G∗= CM Gt C −1
D
.
(3.24)
Sometimes the terms adjoint and transpose are incorrectly used as synonyms. The last
equation shows that they are not.
In the special circumstance where a linear operator L is considered that maps a linear
space into itself, then, by deﬁnition, the adjoint L∗also maps the space into itself. If, in
that case, L = L∗, the operator is called self-adjoint.
Another special circumstance is when an operator maps a space into its dual, as is the
case with (the inverse of) a covariance operator. In Problem 7.10, it is demonstrated that,
while a covariance operator is symmetric, Ct = C , it is not self-adjoint. Rather, the adjoint
of a covariance operator equals its inverse, C∗= C−1 (it is anti-self-adjoint).
3.2
The Least-Squares Problem
3.2.1
Formulation of the Problem
The model space manifold and the data manifold were introduced in chapter 1. They are
here assumed to be linear spaces and are respectively denoted M and D . Expressions like
m2 + m1
,
m2 −m1
,
λ m
,
d2 + d1
,
d2 −d1
,
λ d
(3.25)
are assumed to make (invariant)43 sense.
Example 3.2. If one parameter is, say, an electric resistance R , one should not try to
deﬁne a vector having the quantity R as one of its components.
For the sum of two
electric resistances cannot be made compatible with the sum of two electric conductances
(a conductance is the inverse of a resistance). The logarithmic parameter R∗= log(R/R0) ,
where R0 is an arbitrary constant, can be used as one of the components of a vector (the sum
of logarithmic resistances is equivalent to the sum of logarithmic conductances). Note that
43Deﬁning these sums as sums of ‘coordinates’ of a nonlinear manifold would not make invariant sense, as the
sums would change meaning under a change of coordinates.

3.2. The Least-Squares Problem
63
to take a Gaussian distribution to model the a priori information on a positive parameter
is not coherent because a Gaussian function gives a nonvanishing probability to negative
values of the parameter.44
We are going to manipulate probability densities over M and D . As mentioned
in chapter 1, the homogeneous probability density over a linear space is always constant.
Therefore, everywhere in this chapter, the two homogeneous probability densities over the
model space and the data space are constant:
µM(m) = const.
,
µD(d) = const.
(3.26)
It is clear that these constant probability densities can be interpreted as the limit of the
Gaussians to be considered below when their uncertainties are taken to be inﬁnite.
Least-squares techniques arise when all the ‘input’ probability densities are assumed
to be Gaussian. Let us see this with some detail.
The elements of our problem are as follows:
• The a priori information that the (unknown) model m is a sample of a known Gaussian
probability density whose mean is mprior and whose covariance matrix is CM . The
a priori probability density over the model space M is, therefore,
ρM(m) = const. exp

−1
2 (m −mprior)t C −1
M (m −mprior)

.
(3.27)
This probability density is assumed to be a priori in the sense that it is independent of
the result of the measurements on the observable parameters d (considered below).
• A relation
d = g(m)
(3.28)
that solves the ‘forward problem,’ i.e., that predicts the values of the observable
parameters d that should correspond to the model m . This theoretical prediction is
assumed to be error free (see below for the introduction of a simple form of ‘theoretical
uncertainties’).
• Some measurements on the observable parameters d whose results can be represented
by a Gaussian probability density centered at dobs and with covariance matrix CD :
ρD(d) = const. exp

−1
2 (d −dobs)t C −1
D
(d −dobs)

.
(3.29)
The combination of these three types of information was considered in Example 1.34,
where it was shown to lead to the a posteriori probability density in the model space (equa-
tion (1.93))
σM(m) =
ρM(m) ρD( g(m) )

M dm′ ρM(m′) ρD( g(m′) )
.
(3.30)
44Sometimes, a least-squares criterion is used for such parameters, completed with a positivity constraint. This
is not the most rigorous nor the easiest way to attack this sort of problem. As suggested in section 1.2.4, these
parameters usually accept a log-normal function as a prior probability density. Taking the logarithm of the positive
parameter deﬁnes a new (unbounded) parameter whose a priori probability density is Gaussian and for which
standard least-squares techniques apply.

64
Chapter 3. The Least-Squares Criterion
This gives
σM(m) = const. exp( −S(m) )
,
(3.31)
where (twice) the misﬁt function45 S(m) is deﬁned as
2 S(m) = ∥g(m) −dobs ∥2
D + ∥m −mprior ∥2
M
= (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior) .
(3.32)
If instead of an exact theoretical prediction d = g(m) one assumes that modeliza-
tion uncertainties can be described using Gaussian statistics, with a covariance matrix CT
(see Example 1.17), then one should replace CD with CD + CT in equation (3.32) (see
Example 1.36). Thanks to the simplicity of this result, when using the Gaussian models
for uncertainties, we can forget that there are two different sources of uncertainties in the
data space. All happens as if the forward modelization were exact and the observational
uncertainties were those represented by the covariance matrix CD + CT .
If the relation d = g(m) is linear, the misﬁt function (3.32) is quadratic and the
posterior probability density σM(m) is Gaussian (this case is analyzed in section 3.2.2).
The further the relation d = g(m) is from being linear, the further the posterior probability
density σM(m) is from being a Gaussian. Figure 3.2 suggests the different ‘regimes’ of
nonlinearity usually encountered in inverse problems.
We shall see that the analysis of nonlinear problems usually involves ﬁnding the
maximum (posterior) likelihood point, i.e., the point that maximizes the posterior probability
density (3.31). Maximizing σM(m) is equivalent to minimizing the misﬁt function (3.32).
As the misﬁt function is here a sum of squares,46 this justiﬁes using the terminology ‘least-
squares’ for the kinds of problems here examined (i.e., problems based on Gaussian input
uncertainties). The ﬁrst references to the method of least squares are due to Laplace (1812)
and Gauss (ca. 1820).
Linear and nonlinear problems are separately analyzed in sections 3.2.2 and 3.2.3
below.
3.2.2
Linear Problems
If the equation d = g(m) solving the forward problem is linear, one writes, instead,
d = G m
.
(3.33)
The two equations (3.31)–(3.32) giving the posterior probability density in the model space
then become
σM(m) = const. exp( −S(m) )
,
(3.34)
45Also called the cost function, objective function, least-squares function, or chi-squared function.
46For uncorrelated uncertainties, (CD)ij = (σ i
D)2δij , (CM)αβ = (σ α
M)2δαβ , (twice) the misﬁt function S(m)
becomes 2 S(m) = 
i
(gi(m)−dobsi)2
(σ i
D)2
+ 
α
(mα−mα
prior)2
(σ α
M)2
, which is a sum of squares.

3.2. The Least-Squares Problem
65
Figure 3.2. The ﬁrst sketch is a representation of the probability density ρ(d, m)
representing both the information we have on the observable parameters d (data) and the
a priori information on the model parameters m (the marginal ρM(m) ). In the second
sketch, the forward equation d = G m is linear. The posterior probability density σM(m)
is then also Gaussian. In the third sketch, the forward equation d = g(m) can be linearized
around mprior , giving g(m) ≃g(mprior)+G(m−mprior) , where G representsthederivative
matrix with elements Giα = (∂gi / ∂mα)mprior . The posterior probability density σM(m)
is approximately Gaussian. In the fourth sketch, the forward equation d = g(m) can be
linearized around the maximum likelihood point, mML : g(m) ≃g(mML)+G(m−mML) ,
where now G represents the derivative operator with elements Giα = (∂gi / ∂mα)mML .
The point mML has to be obtained by the nonquadratic minimization of S(m) = 1
2( (g(m)−
dobs)t C −1
D (g(m)−dobs)+(m−mprior)t C −1
D (m−mprior) ) . In the ﬁfth sketch, the forward
equation d = g(m) cannot be linearized, so the a posteriori probability density may
be far from a Gaussian and special methods must be used (see text). In the last sketch,
the nonlinearities between the parameters are so strong that the methods proposed in this
elementary text cannot be used.
with
2 S(m) = ∥G m −dobs ∥2
D + ∥m −mprior ∥2
M
= (G m −dobs)t C −1
D
(G m −dobs) + (m −mprior)t C −1
M (m −mprior)
.
(3.35)
As the misﬁt function is quadratic in m , the posterior probability density σM(m) is,
in fact, a Gaussian probability density, so there must be a point m and a covariance matrix
CM such that the posterior probability density can be written
σM(m) = const. exp

−1
2 (m −m)t C −1
M (m −m)

.
(3.36)
The basic problem, in this linear case, is then the evaluation of the center m and the
covariance CM of the (Gaussian) posterior covariance probability density σM(m) .

66
Chapter 3. The Least-Squares Criterion
The demonstration shall be carried out in a moment. Let us ﬁrst give the solution: the
center of the posterior Gaussian is given by any of the three equivalent expressions
m = ( Gt C −1
D G + C −1
M )−1 ( Gt C −1
D dobs + C −1
M mprior )
= mprior + ( Gt C −1
D G + C −1
M )−1 Gt C −1
D ( dobs −G mprior )
= mprior + CM Gt ( G CM Gt + CD )−1 (dobs −G mprior)
(3.37)
and its covariance by either of the two equivalent expressions
CM = ( Gt C −1
D G + C −1
M )−1
= CM −CM Gt ( G CM Gt + CD )−1 G CM
.
(3.38)
The point m has been deﬁned here as the center of the posterior Gaussian. It could have
been deﬁned as the point realizing the minimum of the least-squares misﬁt function in
equation (3.35), hence the usual name “least-squares estimator.” From this perspective, m
is the ‘best point’ in the sense that, at the same time, it is close to the ‘prior point’ mprior ,
and the predicted data G m are close to the observed data dobs .
Demonstrating that equations (3.37)–(3.38) actually give the mean and the covari-
ance of the posterior probability density σM(m) amounts to demonstrating that the misﬁt
function (3.35) can be written
2 S(m) = (m −m)t C −1
M (m −m) + K
,
(3.39)
where K is a constant term (independent of m ) that is absorbed in the constant into
equation (3.36). This is easily veriﬁed by introducing in (3.39) the ﬁrst of expressions (3.37)
and using the ﬁrst of expressions (3.38). We are left with the problem of demonstrating the
equivalence between the three expressions in (3.37) and the two expressions in (3.38).
Using the ﬁrst of expressions (3.37) and the ﬁrst of expressions (3.38), we
can write m = CM (Gt C −1
D dobs + C −1
M mprior) = CM Gt C −1
D dobs + CM C −1
M mprior =
CM Gt C −1
D dobs + CM (Gt C −1
D G + C −1
M
−Gt C −1
D G) mprior
=
CM Gt C −1
D dobs +
CM (C −1
M
−Gt C −1
D G) mprior
=
CM Gt C −1
D dobs + (I −CM Gt C −1
D G) mprior , i.e.,
m = mprior + CM Gt C −1
D (dobs −G mprior) , that is, the second of expressions (3.37).
The remaining two expressions are then easily obtained using the matricial identity
demonstrated in Problem 6.30.
So, in the linear case d = G m , we have started with the a priori information in
the model space represented by a Gaussian centered at mprior with covariance CM and
have ended with the a posteriori information in the model space represented by a Gaussian
centered at m with covariance CM . The comparison of the posterior uncertainties (as
represented by CM ) with the prior uncertainties (as represented by CM ) shows which
parameters have been ‘resolved’ and by how much. Of course, if the posterior variance of
a parameter is identical to the prior variance, no information has been brought by the data
on this parameter per se (but its correlations with the other parameters may have changed).

3.2. The Least-Squares Problem
67
More details on the interpretation and use of the posterior covariance matrix are in
section 3.3.
Example 3.3.
In sections 5.6 and 5.7, the tomographic inverse problem is set, where
the unknowns are functions (representing a three-dimensional medium). In all rigor, the
covariance functions used there should only represent actual a priori information. One
may also decide to use smooth “a priori” covariance functions with the sole objective of
forcing the ﬁnal solution to be smooth. Note that when using smooth “a priori” covariance
functions, if the smoothness length is larger than the typical separation between the rays of
a tomographic inversion, no low-resolution holes are left between the rays.
Example 3.4. Some observable parameters d = {di} are related to some model param-
eters m = {mα} by the linear relation d = G m . The measurement of the observable
parameters has produced the (vector) value dobs , with uncertainties that can be assumed
to be Gaussian, with covariance matrix CD . Estimate the model parameters m assuming
that there is no a priori information available. The solution can be obtained47 using the
ﬁrst of equations (3.37), taking the limit C −1
M →0 (as there is no a priori information).
This gives
m = (Gt C −1
D G)−1 (Gt C −1
D dobs)
,
(3.40)
the uncertainties being given by (second of equations (3.38))
CM = (Gt C −1
D G)−1
.
(3.41)
These equations only make sense when the matrix Gt C −1
D G is invertible, which happens
when the linear system d = G m is overdetermined. If, furthermore, the number of data and
of unknowns is identical (i.e., if the matrix G is squared), the solution (3.40) simpliﬁes to
m = G−1 dobs
,
(3.42)
that is, the Cramer solution of the linear system dobs = G m .
In Appendix 6.18, equations are given that allow us to invert data sequentially, the
prior model vector and prior covariance matrix to be used in one inversion step being the
posterior model vector and posterior covariance matrix of the previous step. This bears
some resemblance to the Kalman ﬁlter, used in similar kinds of problems.
So far, we have only been interested in the posterior probability density for model
parameters. It is easy to see that the posterior probability density in the data space, as deﬁned
in equation (1.85), is a Gaussian here,
σD(d) = const. exp

−1
2 (d −d)t C −1
D
(d −d)

,
(3.43)
with
d = G m
and
CD = G CM Gt
.
(3.44)
47That the data space is a linear space is implicit in the use of a Gaussian distribution for data uncertainties.
The typical context in this type of problems makes the parameter space a linear space, so we are covered by the
hypotheses made for the use of the least-squares formulation.

68
Chapter 3. The Least-Squares Criterion
Quite often, the least-squares solution is justiﬁed using a statistical point of view. In
this case, d and m are viewed as random variables with known covariance operators CD
and CM and unknown means dtrue and mtrue . Then, dobs and mprior are interpreted as two
particular realizations of the random variables d and m , and the problem is to obtain an
estimator of mtrue , which is, in some sense, optimum. The Gauss–Markoff theorem (see,
for instance, Plackett, 1972, or Rao, 1973) shows that, for linear problems, the least-squares
estimator has minimum variance among all the estimators that are linear functions of dobs
and mprior , irrespective of the particular form of the probability density functions of the
random variables d and m . This is not as good as it may seem: minimum variance may be
a bad criterion when the probability densities are far from Gaussian, as, for instance, when a
small number of large, uncontrolled errors are present in a data set (see Problem 7.7). As the
general approach developed in chapter 1 justiﬁes the least-squares criterion only when all
uncertainties (modelization uncertainties, observational uncertainties, uncertainties in the a
priori model) are Gaussian, I urge the reader to limit the use of the techniques described in
this chapter to the cases where this assumption is not too strongly violated.
3.2.3
Nonlinear Problems
If the equation d = g(m) solving the forward problem is actually nonlinear, there is no
simpliﬁcation in equations (3.31)–(3.32) giving the posterior probability density in the
model space,
σM(m) = const. exp( −S(m) )
,
(3.45)
with
2 S(m) = ∥g(m) −dobs ∥2
D + ∥m −mprior ∥2
M
= (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior)
.
(3.46)
If g(m) is not a linear function of m , σM(m) is not Gaussian. The more nonlinear g(m)
is, the more remote is σM(m) from a Gaussian function.
The weakest case of nonlinearity arises when the function g(m) can be linearized
around mprior (third of the sketches in Figure 3.2),
g(m) ≃g(mprior) + G (m −mprior)
,
(3.47)
where
Gi
α =
 ∂gi
∂mα

mprior
.
(3.48)
The symbol ≃in equation (3.47) means precisely that second-order terms can be neglected
compared to observational and modelization uncertainties (i.e., compared with standard
deviations and correlations in CD ). Replacing (3.47) in equations (3.45)–(3.46), one sees

3.2. The Least-Squares Problem
69
that the a posteriori probability density is then approximately Gaussian, the center being
given by
m ≃mprior +

Gt C −1
D G + C −1
M
−1 Gt C −1
D

dobs −g(mprior)

= mprior + CM Gt 
G CM Gt + CD
−1 
dobs −g(mprior)

(3.49)
and the a posteriori covariance operator by
CM ≃

Gt C −1
D G + C −1
M
−1 = CM −CM Gt 
G CM Gt + CD
−1 G CM
.
(3.50)
These are basically equations (3.37)–(3.38), so we see that solving a linearizable problem
is in fact equivalent to solving a linear problem.
In the fourth of the sketches of Figure 3.2, the case is suggested where the lineariza-
tion (3.47) is no longer acceptable, but the function g(m) is still quasilinear inside the
region of the M × D space of signiﬁcant posterior probability density. The right strategy
for these problems is to use some iterative algorithm to obtain the maximum likelihood point
of σM(m) , say mML , and then to use a linearization of g(m) around mML to estimate the
a posteriori covariance operator. As the homogeneous probability density is here constant,
the maximum likelihood point mML is just the point that maximizes σM(m) (see discus-
sion in section 1.6.4). As the point maximizing σM(m) is the point minimizing the sum
of squares in equation (3.46), we face here the typical problem of ‘nonlinear least-squares’
minimization.
Using, for instance, a quasi-Newton method (see section 3.4 and Appendix 6.22 for
details on optimization techniques), the iterative algorithm
mn+1 = mn −µn

Gt
n C −1
D Gn + C −1
M
−1 
Gt
n C −1
D

dn −dobs

+ C −1
M (mn −mprior)

,
(3.51)
where dn = g(mn) , (Gn)iα = (∂gi/∂mα)mn , and µn ≲1 ,48 when initialized at an
arbitrary point m0 , converges to a local optimal point. If there is one global optimum, then
the algorithm converges to it. If not, the algorithm must be initiated at a point m0 close
enough to the global optimum. In many practical applications, the simple choice
m0 = mprior
(3.52)
is convenient. The number of iterations required for a quasi-Newton algorithm to provide
a sufﬁciently good approximation of the maximum likelihood point is typically between
one and one dozen. Once the maximum likelihood point mML has been conveniently
approached, the a posteriori covariance operator can be estimated as
CM ≃

Gt C −1
D G + C −1
M
−1 = CM −CM Gt 
G CM Gt + CD
−1G CM
,
(3.53)
48As explained in sections 3.4.1 and 3.4.2, gradient-based methods need a parameter deﬁning the length of the
‘jump’ to be performed at each step. If it is taken too small, the algorithm converges too slowly; if it is taken too
large, the algorithm may diverge. In most situations, for the quasi-Newton algorithm, one may just take µn = 1 .
In Appendix 6.22, some suggestions are made for choosing adequate values for this parameter.

70
Chapter 3. The Least-Squares Criterion
where, this time, G are the partial derivatives taken at the convergence point, (Gn)iα =
(∂gi/∂mα)mML . The main computational difference between this ‘nonlinear’ solution and
the linearized solution mentioned above is that here, g(m) , the predicted data for the current
model, has to be computed at each iteration without using any linear approximation. In
usual problems, it is more difﬁcult to compute g(m) than g(m0) + G(m −m0) : nonlinear
problems are in general more expensive to solve than linearizable problems.
Nonlinearities may be stronger and stronger. Many inverse problems correspond to
the case illustrated in the ﬁfth sketch of Figure 3.2: there may be some local maxima of the
posterior probability density σM(m) . If the number of local optima is small, all of them
can be visited, using the iterative algorithm just mentioned, and around each local optimum,
the (local) covariance matrix is to be estimated as above.
If the number of local optimal points is very large, then it is better to directly make
use of the Monte Carlo methods developed in chapter 2 (as, in that case, no advantage is
taken of the Gaussian hypothesis, we do better to drop it and use a more realistic uncertainty
modelization).
Finally, there are problems (suggested in the last sketch of Figure 3.2) where non-
linearities are so strong that some of the assumptions made here break (see the comments
made in section 1.2.8 about the deﬁnition of conditional probability density and the notion
of the ‘vertical’ uncertainty bars in the theoretical relation d = g(m) , represented in Fig-
ure 1.4). In these circumstances, more general methods, directly based on the notion of the
‘conjunction of states of information’ (see section 1.5.1) are necessary.
The quasi-Newton iterative algorithm of equation (3.51) is not the only one possible.
For instance, in section 3.4 we arrive at the steepest descent algorithm (equation (3.89))
mn+1 = mn −µn

CM Gt
n C −1
D (dn −dobs) + (mn −mprior) )
,
(3.54)
where, again, µn is an ad hoc parameter deﬁning the size of the jump to be performed.
Contrary to quasi Newton, this algorithm does not require the resolution of a linear system
at each iteration,49 but, of course, it requires more iterations to converge. The philosophy
behind the steepest descent and the Newton algorithms is explained in section 3.4 (where
the ‘variable metric methods’ are mentioned).
Concerning equation (3.54), one may note that the operator CM Gt
n C −1
D
is, in fact,
the adjoint of Gn as deﬁned in section 3.1.4,
G∗
n = CM Gt
n C −1
D
,
(3.55)
so the algorithm can be written mn+1 = mn −µn ( G∗
n (dn −dobs) + (mn −mprior) ) .
3.3
Estimating Posterior Uncertainties
3.3.1
Posterior Covariance Operator
We have seen that if the relation m →g(m) is nonlinear enough, the probability density
σM(m) , as given by equations (3.31)–(3.32), may be far from a Gaussian. It has already
49 It is well known in numerical analysis that, given the vector y and the matrix A , the computation of
x = A −1 y is not to be done by actually computing the inverse of the matrix A , but by rewriting the equation as
A x = y and using any of the many efﬁcient methods existing to solve a linear system.

3.3. Estimating Posterior Uncertainties
71
been mentioned that if the probability is multimodal, but has a small number of maxima, the
maxima can all be searched, and a covariance matrix adjusted around each optimum point.
If the number of maxima is large, the more general Monte Carlo techniques of chapter 2
must be used.
Let us assume here that σM(m) is reasonably close to a Gaussian. In that case, we
have seen that this posterior covariance matrix can be approximated by either of the two
expressions (equation (3.53))
CM ≃

Gt C −1
D G + C −1
M
−1 = CM −CM Gt 
G CM Gt + CD
−1G CM
,
(3.56)
where G is the matrix of partial derivatives taken at the convergence point, (Gn)iα =
(∂gi/∂mα)mML .
The most trivial use of the posterior covariance operator CM is to interpret the square
roots of the diagonal elements (variances) as ‘uncertainty bars’ on the posterior values of
the model parameters.
A direct examination of the off-diagonal elements (covariances) of a covariance op-
erator is not easy, and it is much better to introduce the correlations
ραβ =
Cαβ
√
Cαα √
Cββ
(no sums involved)
,
(3.57)
which have the well-known property
−1 ≤ραβ ≤+1
.
(3.58)
If the posterior correlation between parameters mα and mβ is close to zero, the posterior
uncertainties are uncorrelated (in the intuitive sense). If the correlation is close to +1
(resp., close to −1 ), the uncertainties are highly correlated (resp., anticorrelated). A strong
correlation on uncertainties means that the two parameters have not been independently
resolved by the data set and that only some linear combination of the parameters is resolved.
Sometimes, the parameters m1, m2, . . . represent the discretized values of some spa-
tial (or temporal) function. Each row (or column) of the posterior covariance operator can
then directly be interpreted in terms of spatial (or temporal) correlations. See Figure 5.17
for an example.
The human brain is not very good at interpreting covariances in high-dimensional
problems. But it is very good at comparing random samples of a probability distribu-
tion. Knowing this, the usual presentation of ‘the solution’ of a least-squares problem
(in fact, the mean of the posterior Gaussian), together with the covariances (as an ex-
pression of ‘uncertainties’ in the solution), should systematically be replaced with a bet-
ter presentation. Given the mean m and the covariance CM of the posterior Gaussian,
one should generate pseudorandom samples m1, m2, . . . , mK of the probability density
σM(m) = Gaussian( m , m , CM ) and present the samples {m1, m2, . . . , mK} instead.
How many? A quantity of models large enough to convey all the subtleties present in the
probability distribution is needed. In any case, given the samples {m1, m2, . . . , mK} , in-
formation about m could be obtained as m ≈
1
K
K
n=1 mn , and information about CM
could be obtained as CM ≈1
K
K
n=1(mn −m) (mn −m)t .
This presentation of the results of a least-squares inversion as a sequence of samples
would not only help the human observer to grasp the actual information obtained in the

72
Chapter 3. The Least-Squares Criterion
inversion process but also help in the confrontation of the results obtained by different
teams working on the same inverse problem using different data sets. It is not because one
is working inside a least-squares context that the ‘movie strategy’ presented in chapter 2
ceases to be valid.
3.3.2
Resolution Operator
In the approaches to inversion not directly based on probabilistic concepts, it is usual to
introduce the ‘resolution operator.’ In order to make the link with these methods, let me
brieﬂy introduce this concept.
Assume we face a linear problem, d = G m , and that we have the a priori informa-
tion {mprior, CM} and the observations {dobs, CD} . The least-squares solution is (third of
equations (3.37))
m = mprior + CM Gt 
G CM Gt + CD
−1 
dobs −G mprior

,
(3.59)
where (second of equations (3.38))
CM = CM −CM Gt 
G CM Gt + CD
−1 G CM
.
(3.60)
Assume that instead of using as input the the observed values dobs , which are uncertain, we
create some exact data dexact from an artiﬁcial “exact” model mexact :
dexact = G mexact
.
(3.61)
The solution m produced by the algorithm would then clearly satisfy
m −mprior = R (mexact −mprior)
,
(3.62)
where R = CM Gt
G CM Gt + CD
−1 G , or, using the expression (3.60) for the posterior
covariance operator,
R = I −CM C −1
M
.
(3.63)
Equation (3.62) suggests calling R (following Backus and Gilbert, 1968) the reso-
lution operator, as it can be interpreted as a ﬁlter: the corrections to the prior model that
we obtain, m −mprior , are both identical to the exact deviations mexact −mprior , but are
‘ﬁltered’ by R (equation (3.62)). (I don’t like this way of thinking, but let us continue with
the traditional reasoning.) If the resolution operator were the identity operator, we would
have perfectly resolved the ‘exact model.’ The farther the resolution operator is from the
identity, the worse the resolution is: we cannot see the real world; we can only see a ﬁltered
version. For more details (in linearized problems), the reader is referred to Backus and
Gilbert (1968). Examples are also given by Aki and Lee (1976) and by Aki, Christofferson,
and Husebye (1977).

3.3. Estimating Posterior Uncertainties
73
I prefer to rewrite equation (3.63) as
CM = (I −R) CM
.
(3.64)
If the resolution operator R is close to the identity, the posterior covariance is close to zero,
and we have resolved our parameters well.
Although these developments have been made for a linear problem, it is clear that
they remain approximately valid for mildly nonlinear problems.
As a ﬁnal comment, note that taking the trace of equation (3.63) gives
tr I = tr R + tr (CM C −1
M )
,
(3.65)
an equation that can be broadly interpreted as follows:

total number
of model parameters

=


number of parameters
resolved by
the data set

+


number of parameters
resolved by
the a priori information

.
(3.66)
3.3.3
Eigenvector Analysis
Strictlyspeaking, acovarianceoperatorhasnoeigenvaluesnoreigenvectors: theeigenvector-
eigenvalue decomposition is only deﬁned for a linear ‘automorphism,’ i.e., for a linear op-
erator mapping one space into itself, and we have seen that a covariance operator maps a
vector space into its dual. In practical computations where the eigenvector-eigenvalue de-
composition is carelessly applied to a covariance operator, inconsistencies with the physical
units being manipulated may appear.
So, if we have the prior covariance operator CM and the posterior covariance operator
CM , a well-formed eigenvector-eigenvalue equation is50
CM δm = λ CM δm
.
(3.67)
To interpret this equation, let us ask the following question: Among those vector
perturbations δm that have unit length when measured with respect to the prior covariance,
∥δm ∥2
0 = δmt C −1
M δm = 1
,
(3.68a)
which ones have extremal length when measured with respect to the posterior covariance:
∥δm ∥2 = δmt C −1
M δm
extremal ?
(3.68b)
Using the method of Lagrange’s multipliers (see Appendix 6.29), the problem is solved by
optimizing S(δm, λ) = δmt C −1
M δm −λ (δmt C −1
M δm −1) . The condition ∂S/∂δm = 0
directly leads to equation (3.67). Therefore, the eigenvector solution of equation (3.67)
gives the directions in the model space that have extremal ratio between the prior and the
posterior length.
50To use standard computer software, one may obviously rewrite this equation as (C −1
M CM) δm = λ δm .

74
Chapter 3. The Least-Squares Criterion
The eigenvector associated with the maximum eigenvalue is, among all vectors with a
priori length given, the one with maximum a posteriori length. This means that it is directed
along the shortest axis of the ellipsoid of uncertainties representing CM (with respect to the
metric deﬁned by CM ). It therefore corresponds to a linear combination of parameters that
is well resolved by the data. On the contrary, the eigenvector associated with the smallest
eigenvalue is directed along the largest axis of the ellipsoid. It therefore corresponds to a
linear combination of parameters that is poorly resolved by the data.
Wiggins (1972) emphasized the importance of the eigenvector-eigenvalue analysis
for the identiﬁcation of well-resolved parameters. Unfortunately, such an analysis is linear
(or linearized), and the most interesting problems concerning the choice of parameters are
nonlinear: which nonlinear change of parameters deﬁnes good parameters? The linearized
eigenvector-eigenvalue analysis does not address this problem (which is a difﬁcult problem
without a known general solution).
3.3.4
Are the Residuals Too Large?
It may happen that some of the assumptions are violated.
For instance, observational
uncertainties or modeling uncertainties may be underestimated, or too much conﬁdence
may be given to the a priori model. Often, blunders exist in the data set: the Gaussian
assumption is then not adequate, and other long-tailed distributions should have been chosen
(see chapter 4).
It is generally not very easy to check the correctness of the assumptions. The exami-
nation of the residuals dobs −g(mML) and mprior −mML may be of some help. The most
important is, of course, a qualitative examination, after a convenient display, but some easy
numerical tests can be performed (see, for instance, Draper and Smith, 1998). The easiest
concerns the value of the misﬁt function at the minimum, S(mML) .
In linear problems, it easily follows from the results exposed in Appendix 6.8 that the
the minimum of (twice) the misﬁt function
χ2 = 2 S = (G m −dobs)t C −1
D (G m −dobs) + (m −mprior)t C −1
M (m −mprior)
(3.69)
arising in linear inverse problems is distributed following a χ2 distribution with
ν = dimension of the data space D
(3.70)
degrees of freedom. As mentioned in Appendix 6.8, the value of (twice) the misﬁt function
at the minimum can be obtained by51
χ2 = 2 Smin = (G mprior −dobs)t (G CM Gt + CD) −1(G mprior −dobs)
.
(3.71)
If, in the effective resolution of an inverse problem, a too large value of χ2 is obtained
(“too large” being understood with respect to the chi-squared probability density (see Ap-
pendix 6.8)), then some violation of the hypothesis has to be feared. Also, an improbably
small value of χ2 would suggest uncertainty overestimation.
51This expression can easily be transformed using the matrix identity (G CM Gt + CD) −1 = C −1
D
−
C −1
D G (Gt C −1
D G + C −1
M ) −1 Gt C −1
D .

3.4. Least-Squares Gradient and Hessian
75
The previous result applies only to linear problems. In the quasi-linear problems
where least squares applies, the result remains approximately true but has to be used with
caution.
3.4
Least-Squares Gradient and Hessian
3.4.1
Gradient and Direction of Steepest Ascent
Let M be a manifold, m be one of its points, {mα} = {m1, m2, . . . } be the coordinates of
the point, and µ(m) be the homogeneous probability density over M . If f (m) is now an
arbitrary probability density over M , the maximum likelihood point is the point satisfying
the condition (see equation (1.116))
f (m)
µ(m)
maximum
.
(3.72)
Equivalently, deﬁning the ‘misﬁt function’
S(m) = −log f (m)
µ(m)
,
(3.73)
the condition is
S(m)
minimum
.
(3.74)
As explained above, gradient-like methods generally work much better for this second
optimization problem.
The gradient of the misﬁt function — at a given point of the manifold — is the (local)
linear form ˆγα whose components are
ˆγα =
∂S
∂mα
.
(3.75)
By itself, the gradient does not deﬁne any direction (at the considered point) in the manifold
(the difference between a vector and a form was suggested in Figure 3.1).
Should one deﬁne a metric over the manifold, i.e., should one introduce a metric
matrix gαβ such that the squared distance between the point m = {m1, m2, . . . } and the
point m + δm = {m1 + δm1, m2 + δm2, . . . } is
ds2 = gαβ dmα dmβ
,
(3.76)
then the inverse metric matrix gαβ (deﬁned by the condition gασ gσβ = δβ
α ) allows us to
deﬁne the vector
γ α = gαβ γβ
,
(3.77)
which can be shown (see Appendix 6.22) to correspond to the steepest ascent vector (char-
acterizing the maximum increase of S for a small circle [in the sense deﬁned by the metric
gαβ ] around the considered point). The steepest ascent vector is then
γ α = gαβ ∂S
∂mα
.
(3.78)

76
Chapter 3. The Least-Squares Criterion
An iterative algorithm of the form mn+1 = mN + δmn able to ﬁnd the minimum of
the function S(m) is a steepest descent algorithm if it is has the form
mn+1 = mn −µn (mn)
,
(3.79)
i.e.,
mα
n+1 = mα
n −µn gαβ(mn)
 ∂S
∂mβ

mn
,
(3.80)
where the µn are ad hoc real constants (small enough to avoid divergence of the algorithm
and large enough to allow the algorithm to actually advance).
One sometimes ﬁnds in the literature the pseudoalgorithm
mα
n+1 = mα
n −µn
 ∂S
∂mα

mn
(this is wrong)
,
(3.81)
where the inverse metric matrix gαβ is absent. This does not have the necessary math-
ematical invariances: it is dimensionally wrong (if the parameters have different physical
dimensions), and the algorithm is coordinate dependent (if it converges at all, it may typically
display a complex behavior (see Figure 3.3)).
Figure
3.3.
A
function
S(θ, ϕ) deﬁned over the sphere has to
be minimized. A naive use of the gradi-
ent method (equation (3.81)) would de-
ﬁneadirectionofsteepestdescentbased
on an ad hoc Euclidean distance over
the map, instead of using the actual no-
tion of distance over the sphere, where
the metric is ds2 = gij dxi dxj
=
dθ2 + sin2 θdϕ2 .
The algorithm in
equation (3.80) does exactly this.
3.4.2
Newton Method of Optimization
The Newton method of optimization does not use a preexisting metric over the manifold:
it uses the second derivatives of the function to be minimized to create an ad hoc metric
that is optimum for the optimization problem at hand. The Hessian matrix is the matrix of
second-order partial derivatives
Cαβ(m) =
 ∂ˆγβ
∂mα

m
=

∂2S
∂mα∂mβ

m
.
(3.82)
Itisobviouslysymmetric. Ifitispositivedeﬁnite, itcanbeusedasalocalmetric. Introducing
its inverse W = C −1 , one can deﬁne, from the same gradient ˆγα(m) as above, the new

3.4. Least-Squares Gradient and Hessian
77
steepest ascent vector (related to the Hessian metric) γ ′α = W αβ ˆγβ . The steepest descent
algorithm then takes the form
mα
n+1 = mα
n −µn γ ′α(mn)
,
(3.83)
i.e.,
mα
n+1 = mα
n −µn W αβ(mn)
 ∂S
∂mβ

mn
.
(3.84)
This is the Newton method of optimization (although it is also a steepest descent algorithm,
it is not called so). While the constants µn in the steepest descent algorithm (3.80) may take
quite large or quite small values, the constants µn of the Newton algorithm are typically of
the order of unity (because the Hessian metric already accounts for the local geometry of
the misﬁt function). In a vast majority of circumstances, the Newton algorithm is just run
setting µn = 1 .
As we are about to see, in the context of least squares, it is a variant of the Newton
method that is often used (the so-called quasi-Newton method), where some terms arising
in the computation of the Hessian (i.e., of the second-order partial derivatives of the misﬁt
function) are neglected.
It is easy to see that the Newton method corresponds to obtaining at the current point
mn the‘paraboloid’thatistangenttothefunction S(m) andthathasthesamelocalcurvature
and jumping to the point where this tangent paraboloid reaches its minimum. Figure 3.4
gives a one-dimensional illustration of this.
Figure 3.4. The Newton method pro-
vides the minimum of the parabola that is tan-
gent to the function to be minimized (and that
has the same local curvature).
For an analysis of the convergence properties of the Newton method, see, for instance,
Dahlquist and Björk, 1974.
3.4.3
Variable Metric Methods and Preconditioning
We have seen that both the steepest descent method and the Newton method are steepest
descent methods, the only difference being in the choice of metric to be applied to the
gradient (a form) to convert the form into a direction (a vector). While in the steepest
descent methods the metric is given independently of the function S(m) to be minimized,
in the Newton method the metric is deﬁned using the second derivatives of S(m) .
This suggests that many more alternatives exist for choosing a metric. Of special
practical importance are the ‘variable metric methods,’ where, typically, one starts iterating

78
Chapter 3. The Least-Squares Criterion
with the same prior metric used in the steepest descent method, and at every iteration the
metric is updated in a way that it tends, as the iterations proceed, to the Newton metric. These
variable metric methods are introduced in Appendix 6.22, where the algorithms obtained
for the solution of least-squares problems are presented.
Gradient-based methods try to ﬁnd a compromise between two somewhat contradic-
tory pieces of information. By deﬁnition, a gradient-based method uses local information
on the function to be optimized, i.e., information that makes full sense in a small vicinity
of the current point but does not necessarily reﬂect the properties of the function in a large
domain. But each iteration of a gradient-based method tries to make a jump as large as
possible, in order to accelerate convergence. For the intended ﬁnite jumps, the local infor-
mation brought by the gradient may be far from optimal. In most practical applications,
the user of a gradient-based method may use physical insight to ‘correct’ the gradient, in
order to deﬁne a direction that is much better for a ﬁnite jump. This is the idea behind the
preconditioned gradient methods that are described in Appendix 6.22.
Choosing the right method to be used in a given least-squares inverse problem is totally
problem dependent, and it is very difﬁcult to give any suggestion at the general level. For
small-sized problems, Newton methods are easy to implement and rapid to converge. For
really large-sized problems, the linear system that has to be solved in the Newton method
may be prohibitively expensive, and the choice of a simple steepest descent methods may
sometimes work well. The experience of our research team52 with the difﬁcult problem of
nonlinear waveform ﬁtting, with millions of data points and model parameters, has shown
that ‘preconditioning operators’ (i.e., metrics) can be guessed that give to simple steepest
descent methods an acceptable convergence in a few iterations.
3.4.4
Steepest Descent and Quasi-Newton Method in Least Squares
If the functions gi(m) solving the forward problem are differentiable, i.e., if the derivatives
(Gn)i
α =
 ∂gi
∂mα

mn
(3.85)
can be deﬁned at any point mn (or at “almost” any point), and if they can be computed,53
then the derivatives of S(m) can also be easily obtained, and the very powerful gradient
and Newton methods can be used for minimizing S(m) .
Equation (3.46) can be written explicitly as (using the implicit sum convention)
2 S(m) = ( gi(m) −di
obs ) (C −1
D )ij ( gj(m) −dj
obs ) + ( mα −mα
prior ) (C −1
M )αβ ( mβ −mβ
prior ) .
(3.86)
We obtain easily (using the implicit sum convention)
 ∂S
∂mα

mn
= (Gn)i
α (C −1
D )ij ( gj(mn) −dj
obs ) + (C −1
M )αβ ( mβ −mβ
prior )
,
(3.87)
52Pica, Diet, and Tarantola, 1990; Crase et al., 1990, 1992; Igel, Djikpéssé, and Tarantola, 1996; Djikpéssé
et al., 1999; Charara, Barnes, and Tarantola, 2000.
53If they are not available analytically, one may use a ﬁnite-difference approximation.

3.4. Least-Squares Gradient and Hessian
79
i.e., in compact notation,
 ∂S
∂m

n
= Gt
n C −1
D ( g(mn) −dobs ) + C −1
M ( mn −mprior )
.
(3.88)
The form obtained in (3.87) and (3.88) is the gradient of S(m) at m = mn .
We have just seen that, to use the steepest descent method, we need the metric matrix
of the space (equation (3.80)).
The only available metric here (that is independent of
the form of the misﬁt function) is the covariance matrix CM , and, with this choice, the
steepest descent algorithm (3.80) becomes, using the gradient obtained in equation (3.88)
(see Appendix 6.22 for details),
mn+1 = mn −µn ( CM Gt
n C −1
D (dn −dobs) + (mn −mprior) )
,
(3.89)
where dn = g(mn) .
If we wish, instead, to use the Newton method, we need to evaluate the Hessian, i.e.,
the matrix of second-order partial derivatives
 ∂S2
∂m2

αβ
=
∂
∂mβ
∂S
∂mα =
∂2S
∂mα∂mβ
.
(3.90)
From equation (3.87) we readily obtain
 ∂2S
∂m2 (mn)

αβ
= (Gn)i
α(C −1
D )ij(Gn)j
β + (C −1
M )αβ +
∂Giα
∂mβ

n
(C −1
D )ij (gj(mn) −dj
obs) .
(3.91)
The last term is small if (i) the residuals are small, or (ii) the nonlinearities in the for-
ward equation m →g(m) are small (as, then, the term ∂Giα / ∂mβ is small). As the
last term in equation (3.91) is, in general, small, it is difﬁcult to handle, and as descent
methods work well even if the descent direction being used is not that of steepest descent,
this last term is generally dropped off, thus giving the approximation

∂2S
∂m2 (mn)

αβ ≈
(Gn)iα (C −1
D )ij (Gn)j β + (C −1
M )αβ , or, in compact form,
 ∂S2
∂m2

mn
≃Gt
n C −1
D Gn + C −1
M
.
(3.92)
WiththisapproximationfortheHessian, theNewtonalgorithm(calledquasiNewtonbecause
of this approximation) in equation (3.84) becomes the expression already suggested in
equation (3.51):
mn+1 = mn −µn

Gt
n C −1
D Gn + C −1
M
−1 
Gt
n C −1
D

dn −dobs

+ C −1
M (mn −mprior)

.
(3.93)
Here, dn = g(mn) , and, as already mentioned, µn ≈1 .

80
Chapter 3. The Least-Squares Criterion
3.4.5
Comments on Numerical Implementation
As mentioned in footnote 49, an expression like x = A−1 y does not mean that, given A
and y , one needs to invert the matrix A in order to evaluate x . Rather, a direct method
for solving the linear system A x = y is to be used (as any book on numerical analysis will
explain; see, for instance, Ciarlet, 1982).
For instance, to implement the quasi-Newton algorithm (3.93), one should evaluate
An = Gt
n C −1
D Gn + C −1
M
,
yn = Gt
n C −1
D (dn −dobs) + C −1
M (mn −mprior)
(3.94)
and update the model mn as
mn+1 = mn −µn xn
,
(3.95)
where xn is to be evaluated by solving the linear system
An xn = yn
(3.96)
directly, without inverting An . The same comment applies to every occurrence of the
matrices C −1
D
and C −1
M : in the expressions above, the algorithm can be rewritten in such a
way that the inversion of a matrix is always replaced with the (easier) resolution of a linear
system.
At the time of writing the second edition of this book, general purpose mathematical
software54 (like Matlab or Mathematica) are becoming mature enough to be useful for the
resolution of medium-scale optimization problems. My own experience is that the resolution
of a large-scale inverse problem still requires a lot of heavy programming to develop codes
that are well adapted to the particular problem being considered.
The so-called Levenberg–Marquardt (LM) methods (due to Levenberg, 1944, and
Marquardt, 1963) are not developed here. This is because I believe that the proper in-
troduction of the a priori information, as done above, conveniently replaces the dumping
philosophy behind the LM methods. For a recent textbook containing (among other things)
a review of these methods, see Aster, Borchers, and Thurber (2003).
54Not to mention special purpose software, like Math Optimizer or Global Optimization.

Chapter 4
Least-Absolute-Values
Criterion and Minimax
Criterion
When a traveler reaches a fork in the road,
the ℓ1-norm tells him to take either one way or the other,
but the ℓ2-norm instructs him to head off into the bushes.
John F. Claerbout and Francis Muir, 1973
Because of its simplicity, the least-squares criterion ( ℓ2-norm criterion) is widely
used for the resolution of inverse problems, even if its basic underlying hypothesis (Gaussian
uncertainties) is not always satisﬁed. Between least-squares and general problems there is
a limited class of problems that remain simple to formulate: those based on an ℓp-norm
( 1 ≤p ≤∞).
As suggested in chapter 1, when outliers are suspected in a data set, long-tailed55
probability density functions should be used to model uncertainties (see Problem 7.7). A
typicallong-tailedprobabilitydensityistheLaplacefunction, i.e., thesymmetricexponential
function exp(−|x|) . It has the advantage of leading to results intimately related to the
concept of the ℓ1-norm, so that relatively simple mathematics is available for solving the
problem. The results obtained using the minimum ℓ1-norm (least-absolute-values) criterion
are known to be sufﬁciently insensitive to outliers (i.e., to be robust).
The ℓ∞-norm criterion arises when we use boxcar functions to model the probability
density for uncertainties. This assumes a strict control on errors, as for instance when they
are due to rounding the last digit used (see Problem 7.4).
4.1
Introduction
The ℓ1-norm criterion has been used by Laplace and Gauss. In the words of Gauss (1809),
“Laplace made use of another principle for the solution of linear equations, the number
55A distribution is long tailed if it tends to zero less rapidly than the Gaussian distribution when the distance
between the variable and its central value tends to inﬁnity.
81

82
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
of which is greater than the number of unknown quantities, which had been previously
proposed by Boscovich, namely that the differences themselves, but all of them taken
positively, should make up as small a sum as possible.” In modern times, Claerbout and
Muir (1973) have given a detailed discussion of the robustness of the ℓ1-norm criterion for
the resolution of inverse problems and have suggested a method of resolution related to the
linear programming techniques.
This chapter starts by recalling the deﬁnition of the ℓp-norm and by introducing a
natural bijection between an ℓp-normed space and its dual. For 1 < p < ∞, the methods
for solving inverse problems are similar to the methods used for p = 2 (chapter 3). For
p = 1 and p = ∞, linear programming methods can be used, but I choose to mention
them only in the appendices, as my experience with large-scale inverse problems shows
that gradient methods perform well (and are naturally adapted to the case where the relation
between data and parameters is nonlinear). Although the minimum ℓ1-norm and minimum
ℓ∞-norm criteria are used in almost opposite circumstances, the underlying mathematics is
very similar, justifying their inclusion in the same chapter.
4.2
Preamble: ℓp-Norms
Contrary to what was done in the previous chapter, the implicit sum convention is not used
here, as the tensor notations — characteristic of differential geometry — are not adapted to
the case where the metric is not ℓ2 .
4.2.1
Deﬁnition of the Weighted ℓp-Norm
Let x = {x1, . . . , xn} be an element of an n-dimensional linear space X (the xi being
the components of x in a given basis), and let σ i be given positive constants such that,
for any i , σ i has the same physical dimensions as xi (so that xi/σ i is an adimensional
real number). For 1 ≤p ≤∞, the (weighted) ℓp-norm of x is denoted ∥x ∥p and is
deﬁned by
∥x ∥p =
 
i
| xi |p
(σ i)p
1/p
.
(4.1)
For p = 1 , one has the ℓ1-norm
∥x ∥1 =

i
| xi |
σ i
,
(4.2)
while the ℓ∞-norm is deﬁned as the limit of expression (4.1) when p →∞, which gives
(e.g., Watson, 1980)
∥x ∥∞= maxi
| xi |
σ i
.
(4.3)

4.2. Preamble: ℓp-Norms
83
It is well known that this deﬁnition veriﬁes the usual properties of a norm:
x ̸= 0 )⇒∥x ∥p > 0
,
∥α x ∥p = | α | ∥x ∥p
,
∥x1 + x2 ∥p ≤∥x1 ∥p + ∥x2 ∥p
.
(4.4)
A (multidimensional) sphere of radius R centered at x0 is deﬁned as the set of points x
such that ∥x −x0 ∥p = R . Figure 4.1 shows some two-dimensional circles corresponding
to different ℓp-norms.
Figure 4.1. Some unit ‘circles’ in the ℓp-
norm sense. The points on the circles are such that
| x |p
(σx)p + | y |p
(σy)p = 1 and are drawn for p respectively
equal to 1 , 1.5 , 2 , 3 , and 30 .
σx
σy
p=1
1.5 2 3
30
4.2.2
Dual of an ℓp-Normed Space
In what follows, if a linear space X has an ℓp-norm deﬁned, we denote it as Xp .
Let χ denote a linear form over the linear space Xp (i.e., a linear application from
Xp into the real line R ). The space of all linear forms over Xp is named the dual of X and
is denoted X∗
q (the meaning of the index q shall become clear in a moment). The result of
the action of χ ∈X∗
q on x ∈Xp is denoted by ⟨χ , x ⟩or χt x . For any form χ over a
discrete space, it is possible to ﬁnd constants χi such that
⟨χ , x ⟩= χt x =

i
χi xi
.
(4.5)
If the elements of Xp and X∗
q are represented by column matrices, the notation χt x
corresponds to the usual matrix notation; in the case where the elements of Xp and X∗
q
haveamorecomplexstructure(inpractice, theyarerepresentedbymultidimensionalarrays),
the notation χt x is still practical for analytical developments.
The space X∗
q can be identiﬁed with a space of vectors χ whose components are
arbitrary except that the physical dimension of the ith component of χ , χi , is the inverse
of the physical dimension of the ith component of x , xi (so that χi xi is adimensional).
Given a particular ℓp-norm over a space Xp , it is useful to deﬁne a bijection between
Xp and its dual X∗
q : for 1 < p < ∞, with any given x ∈Xp , let us associate the element
of X∗
q , denoted ˆx , deﬁned by (ˆx)i = 1
p
∂
∂xi (∥x ∥p)p or, for short,
ˆx = 1
p
∂
∂x ( ∥x ∥p )p
.
(4.6)

84
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
Introducing
ˆσ i =
1
σ i
,
(4.7)
we can, for any q ( 1 < q < ∞) , deﬁne an ℓq-norm over the dual space X∗
q ,
∥ˆx ∥q =
 
i
 ˆxi
q
(ˆσi)q
1/q
.
(4.8)
Now, if this value q is related to p according to56
1
p + 1
q = 1
,
(4.9)
then the symmetric of equation (4.6) holds (see Problem 6.27.1),
x = 1
q
∂
∂ˆx ( ∥ˆx ∥q )q
,
(4.10)
and we have the following equalities (see Problem 6.27.2):
( ∥ˆx ∥q )q = ( ∥x ∥p )p = ∥ˆx ∥q ∥x ∥p = ⟨ˆx , x ⟩= ˆxt x
.
(4.11)
Once it is understood that when the norm over the linear space X is an ℓp-norm and the norm
over the dual space is the related ℓq-norm (with 1/p + 1/q = 1 ), this set of expressions
can be simpliﬁed into
∥ˆx ∥q = ∥x ∥p = ∥ˆx ∥∥x ∥= ⟨ˆx , x ⟩= ˆxt x
.
(4.12)
This set of (beautiful) identities justiﬁes the bijection deﬁned between a space and its dual
and the fact that the natural norm to be considered in the dual of an ℓp-norm space is an
ℓq-norm, p and q being related through expression (4.9). The cases where p or q takes
the values 1 or ∞are examined below.
Note that the relationship (4.6) between a space and its dual is not the usual deﬁnition
(e.g., Watson, 1980, exercise 1.27), ˆx =
∂
∂x ∥x ∥p , in which case equation (4.12) is replaced
with ∥ˆx ∥q = 1 and the relationship between Xp and X∗
q is no longer a bijection.
From equations (4.6) and (4.10), we obtain the explicit representations
ˆxi = sg(xi)
σ i

xi
σ i

p−1
and
xi = sg(ˆxi)
ˆσi

ˆxi
ˆσi

q−1
,
(4.13)
where sg(x) is the sign of x (equal to 1 , 0 or, −1 , respectively, when x > 0 , x = 0 ,
and x < 0 ). To simplify analytical computations, we may introduce the following notation:
letting u be an arbitrary scalar and r be a real positive number,
u{r} ≡sg(u) | u |r
.
(4.14)
56Equivalent expressions are p + q = p q and (p −1)(q −1) = 1 .

4.2. Preamble: ℓp-Norms
85
The usefulness of this notation comes from the following properties
u{r} = v
⇔
u = v{1/r}
;
∂
∂x u{r} = r | u |r−1 ∂u
∂x
,
∂
∂x | u |r = r u{r−1} ∂u
∂x
.
(4.15)
In particular, using equation (4.15), the bijection between Xp and X∗
q can be rewritten in
a more compact form:
ˆxi
ˆσi
=
 xi
σ i
{p−1}
,
xi
σ i =
 ˆxi
ˆσi
{q−1}
.
(4.16)
Figure 4.2 shows the function u{r} for different values of r > 0 . For positive values of u ,
it simply corresponds to the function ur . For negative values of u , it is possible to interpret
u{r} as an interpolation of the functions ur obtained when r is an odd integer.
Figure 4.2. Some examples of the function u{r} . For any r ,
it is a real function, symmetric (with respect to the origin), deﬁned for
any value of r (even for negative u), and, for given u , a continuous
function of r .
The bijection deﬁned between Xp and X∗
q is nonlinear except for p = 2 . In that
case, q = p = 2 and ˆxi/ˆσi = xi/σ i .
Let us now turn to the two special cases p = 1 and p = ∞, starting with p = 1 .
If the dual space X∗
1 is an ℓ1-normed space (then, the primal space X∞is an ℓ∞-
normed space), the relation at the right in equation (4.13) can be used in the limit p →1
and gives the vector of the primal space
xi = sg(ˆxi)
ˆσi
,
(4.17)
where one should remember that sg(0) ≡0 . This time, there is no bijection, as from the
vector x = {xi} we cannot recover the form ˆx = {ˆxi} .
If the dual space X∗
∞is, instead, an ℓ∞-normed space (then, the primal space X1 is
an ℓ1-normed space), the relation at the right in equation (4.13) cannot be used in the limit
p →∞, as it diverges, except if the form ˆx is normed to one, ∥ˆx ∥∞= 1 . For in this
case, some of the ratios ˆxi/ˆσi equal ±1 , the other ratios being smaller in absolute value.
One then obtains, for a normed ℓ∞-form ˆx , the dual vector
xi =



1
k
sg(ˆxi)
ˆσi
if

ˆxi
ˆσi
 = 1
( k such terms )
,
0
if

ˆxi
ˆσi
 < 1
.
(4.18)
Then, ∥x ∥1 = 1 . Again, the bijection between the primal and the dual case is broken here.

86
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
4.2.3
Uniqueness of the Minimization of an ℓp-Norm
The problem we are about to examine is, essentially, that of a minimization of an ℓp-norm
under a constraint. This point of view helps us to gain understanding of the uniqueness of
the minimum. Figure 4.3 suggests (as is indeed the case (Watson, 1980)) that under a linear
constraint F x = 0 the minimization of an ℓp-norm ∥x −x0 ∥p gives a unique solution
except for p = 1 and p = ∞(the unit circle is still convex, but not strictly convex), in
which cases the solution may not be unique. For a nonlinear constraint, multiple minima,
secondary minima, and saddle points may exist.
Figure 4.3. Minimization of an ℓp-norm under a linear constraint. The two-
dimensional problem illustrated in this ﬁgure is to obtain the point, constrained to lie on
a given straight line, that is the closest to a given point.
The problem can be solved
geometrically by “expanding” the unit circle until it becomes tangent to the line. In the ﬁrst
example (top), the solution is unique except for p = 1 ; in the second example (middle), it
is always unique; in the third example (bottom) it is unique except for p = ∞.
4.3
The ℓp-Norm Problem
4.3.1
Formulation of the Problem
The formulation of the ℓp-norm problem is very similar to that of the least-squares prob-
lem, as done in section 3.2.1 (for easy reference, a few basic assumptions made there are
repeated here).
The model space manifold and the data manifold were introduced in chapter 1. They
are here assumed to be linear spaces and are respectively denoted M and D . Expressions
like
m2 + m1
,
m2 −m1
,
λ m
,
d2 + d1
,
d2 −d1
,
λ d
(4.19)
are assumed to make (invariant) sense. One should remember Example 3.2, an example of
coordinates where the assumption is not (directly) satisﬁed.
We are going to manipulate probability densities over M and D . As mentioned
in chapter 1, the homogeneous probability density over a linear space is always constant.
Therefore, as was the case in chapter 3, the two homogeneous probability densities over the

4.3. The ℓp-Norm Problem
87
model space and the data space are constant here:
µM(m) = const.
,
µD(d) = const.
(4.20)
It is clear that these constant probability densities can be interpreted as the limit of the
generalized Gaussians to be considered below when their ‘uncertainties’ are taken to be
inﬁnite.
ℓp-norm techniques arise when all the ‘input’ probability densities are assumed to be
generalized Gaussians. Let us see this with some detail.
The elements of our problem are as follows:
• Some a priori information on the model parameters, represented by a generalized
Gaussian probability density of order r centered at a point {mα
prior} and with estima-
tors of dispersion (of order r ) {σ α
M} . The a priori probability density over the model
space M is, therefore,
ρM(m) = const. exp

−1
r

α
| mα −mα
prior |r
(σ α
M)r

.
(4.21)
This probability density is assumed to be a priori in the sense that it is independent of
the result of the measurements on the observable parameters d (considered below).
• A relation
d = g(m)
(4.22)
that solves the forward problem, i.e., that predicts the values of the observable pa-
rameters d that should correspond to the model m . This theoretical prediction is
assumed to be error free (see below for the introduction of a simple form of theoretical
uncertainties).
• Some measurements on the observable parameters d whose results can be represented
by a generalized Gaussian probability density of order s centered at {di
obs} and with
estimators of dispersion (of order s ) {σ i
D} :
ρD(d) = const. exp

−1
s

i
| di −di
obs |s
(σ i
D)s

.
(4.23)
The combination of these three types of information was considered in Example 1.34,
where it was shown to lead to the a posteriori probability density in the model space (equa-
tion (1.93))
σM(m) =
ρM(m) ρD( g(m) )

M dm′ ρM(m′) ρD( g(m′) )
.
(4.24)
This gives
σM(m) = const. exp( −S(m) )
,
(4.25)

88
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
where the misﬁt function S(m) is
S(m) = 1
s

i
| gi(m) −di
obs |s
(σ i
D)s
+ 1
r

α
| mα −mα
prior |r
(σ α
M)r
.
(4.26)
With the posterior probability density σM(m) so expressed, general methods can be
used to extract information from it, like the Monte Carlo methods described in chapter 2.
A much simpler goal — although much less informative — is just to obtain the
maximum likelihood model, i.e., the point at which σM(m) becomes maximum.57 Clearly,
the maximization of the probability density σM(m) is equivalent to the minimization of the
misﬁt function S(m) . For this reason, the maximum likelihood model can also be called the
‘best model’ under the minimum ℓp-norm ‘criterion.’ Note that the ℓp-norm criterion is
only justiﬁed if the assumption of uncertainties distributed following a generalized Gaussian
of order p is acceptable (here, in fact, of order r in the model space and of order s in the
data space).
The gradient of the misﬁt function is easy to obtain using the third of equations (4.15),
ˆγα ≡
∂S
∂mα =

i
1
σ i
D
Gi
α
gi −di
obs
σ i
D
{s−1}
+

α
1
σ α
M
mα −mα
prior
σ α
M
{r−1}
,
(4.27)
where, for short, the notations ˆγα and gi are respectively used for ˆγα(m) and gi(m) and
where the Giα are the partial derivatives
Gi
α(m) =
∂gi
∂mα (m)
.
(4.28)
ˆγ is a form in the model space where an ℓr-norm has been considered. As demon-
strated in Appendix 6.22.1, the associated steepest ascent vector is obtained using the duality
introduced above (equation (4.16)), giving
γ α = (σ α
M)r ( ˆγ α){r−1}
.
(4.29)
The physical dimensions of the components of the gradient being the inverse of those of the
model parameters, this equation gives for the components of the steepest ascent vector the
physical dimensions of the model parameters, as it should.
The simplest algorithm for seeking minima of the misﬁt function is, of course, the
steepest descent algorithm mn+1 = mn −µn γ n , where the µn are real numbers small
enough to avoid divergence (see details in Appendix 6.22). In terms of the components,
mα
n+1 = mα
n −µn γ α
n
.
(4.30)
The ﬁve equations (4.25), (4.26), (4.27), (4.29), and (4.30) give the four basic equa-
tions related to the formulation of ℓp-norm problems and their resolution using the steepest
descent method.
57As explained in chapter 1, the maximum likelihood point is that maximizing the probability density, because,
here, the model space is linear and, therefore, the homogeneous probability density is constant.

4.4. The ℓ1-Norm Criterion for Inverse Problems
89
Of course, more sophisticated gradient methods could be used (as suggested when
analyzing ℓ2-norm problems), but their applicability would greatly depend on the particular
problem at hand, so these methods are not examined here.
4.4
The ℓ1-Norm Criterion for Inverse Problems
4.4.1
Formulation of the Problem
If uncertainties in the observed data values dobs and uncertainties in the a priori model
mprior are assumed to be conveniently modeled using a double exponential (Laplace dis-
tribution), then the a posteriori probability density in the model space is given by (this is
equation (1.109) and a special case of equations (4.25)–(4.26))
σM(m) = const. exp( −S(m) )
,
(4.31)
where the ℓ1-norm misﬁt function S(m) is
S(m) =

i
| gi(m) −di
obs |
σ i
D
+

α
| mα −mα
prior |
σ α
M
.
(4.32)
Here, σ i
D and σ α
M respectively represent the ℓ1-norm estimators of dispersion (i.e., the
mean deviations; see Appendix 6.5) for uncertainties in observed data and the a priori
model. (In many applications, while the use of the ℓ1-norm is adequate in the data space,
to ensure robustness, one may use an ℓ2-norm in the model space; see section 4.4.3.)
Figure4.4suggeststheshapeofthefunctions σM(m) and S(m) (foratwo-dimensional
model space) when the relation d = g(m) is linear. Figure 4.5 corresponds to a nonlinear
relation d = g(m) .
As the shape of σM(m) is typically quite different from a Gaussian, there is no hope of
obtaining an easy characterization of the dispersion (like when using the posterior covariance
matrix in the ℓ2-norm formulation).
To extract information from the probability density σM(m) , as expressed by equa-
tions (4.31)–(4.32), one may use a random generation of models, as suggested in chapter 2.
Sometimes, one may just be interested in the maximum likelihood model, that is, maximiz-
ing the probability density σM(m) , or, equivalently, minimizing the misﬁt function S(m) .
For obvious reasons, this model minimizing S(m) (equation (4.32)) is called the best
model with respect to the least-absolute-values ( ℓ1-norm ) criterion.
Example 4.1. A model m = {x, y} consists of two quantities x and y about which one
has the a priori information
x = 1 ± 3
,
y = 2 ± 3
.
(4.33)
The quantity d = 2 x + y has been measured and one has obtained
d = 5 ± 2
.
(4.34)
Give the probability density for m = {x, y} , assuming that all the mentioned uncertainties
can be modeled using the double-exponential probability density. This problem is easy

90
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
to solve. A direct application of the discussion above gives the probability density
σM(x, y) = const. exp( −S(x, y) )
,
(4.35)
with
S(x, y) = | 5 −(2 x + y) |
2
+ | x −1 |
3
+ | y −2 |
3
.
(4.36)
ThismisﬁtfunctionisrepresentedinFigure4.4togetherwiththeprobabilitydensity σM(x, y) .
If, instead, one has measured the quantity d = 2 sin x + y , the misﬁt becomes S(x, y) =
| 5−(2 sin x+y) |
2
+ | x−1 |
3
+ | y−2 |
3
, represented in Figure 4.5.
Figure 4.4. Representation of the ℓ1-norm misﬁt function deﬁned in Example 4.1,
where the relation d = g(m) is linear. When the model space M is two dimensional, the
misﬁt function S(m) can be represented by a convex polyhedron in a 3D space (middle).
The function S(m) deﬁnes a partition of the model space M into convex polygons (left).
The level lines of S(m) = const. are also convex polygons. In this left panel, the level
lines indicate the gradient of S(m) at every point. The direction of steepest ascent (with
respect to the ℓ1-norm) is indicated at some selected points (arrows). The probability density
σM(m) = const. exp(−S(m)) is represented at the right.
Figure 4.5. Same as Figure 4.4, but when the re-
lation d = g(m) is nonlinear. To represent here the direc-
tions of steepest ascent, one should draw inﬁnitesimally small
circles.
Linear Problems
When the relation between data and model parameters is linear, one may write
g(m) = G m
,
(4.37)
where G represents a linear operator (in fact, a matrix).

4.4. The ℓ1-Norm Criterion for Inverse Problems
91
To ﬁx ideas, let us ﬁrst consider the case where the model space has a dimension
of two, i.e., we have only two parameters. The shape of the function S(m) has been
illustrated in Figure 4.4. It is easy to see that the surface representing S(m) is then a
convex polyhedron or, more precisely, the lower part of an inﬁnite convex polyhedron.
Each edge of the polyhedron clearly corresponds to a null residual in (4.32), i.e.,
m ∈edge
⇐⇒



(G m)i = di
obs
for a given i
or
mα = mαprior
for a given α
.
(4.38)
It is also clear that each vertex of the polyhedron corresponds to the points where at least
two residuals are null. As the minimum of the convex polyhedron is necessarily attained at
a vertex (or edge, face, . . . ), we arrive at the conclusion that at the minimum of the function
S(m) at least two of the equations
( G m )i = di
obs
,
mα = mα
prior
(4.39)
are exactly satisﬁed (and only two in most common situations).
It is helpful to have a visual image of what the representation of the misﬁt function
at the top left of Figure 4.4 becomes when the dimension of the model space is greater
than two. The three-dimensional case is illustrated in Figure 4.6. More generally, if the
model space M has N dimensions, each of the equations (4.39) deﬁnes a hyperplane of
dimension N−1 over M (a line for N = 2 , an ordinary plane for N = 3 , etc.). The whole
set of equations (4.39) deﬁnes a partition of the model space into convex N-dimensional
hyperpolyhedrons where the function S has constant gradient (convex polygons for N = 2 ,
convex polyhedrons for N = 3 , etc.). The minimum of S is then attained at one vertex
of one of these hyperpolyhedrons (or, in the case of degeneracy, at one edge, or face, etc.).
As the vertices are deﬁned by the intersection of at least N hyperplanes, we arrive at the
conclusion that, at the minimum of S , at least N of the equations (4.39) are exactly satisﬁed
(and often only N ).
Figure 4.6.
If the model space is three-
dimensional, the function S(m) deﬁnes a partition of the
space into convex polyhedrons, connected by convex poly-
gons, connected by edges, connected by vertices.
In an
N-dimensional model space, we have vertices, edges, con-
vex polygons, convex polyhedrons, convex 4D hyperpolyhe-
drons, . . . , and convex N-dimensional hyperpolyhedrons.
Linear programming (see below) deﬁnes paths along edges
and vertices.
convex face
convex
polyhedron
edge
vertex
This means that the least ℓ1-norm criterion selects among the components of di
obs
and mα
prior the N components whose posterior values will be identical to the prior ones.
The posterior values of all other components will be computed from these N values using
the linear system (4.39). The prior values of these other component values are not used
(robustness results from this), except in that they have inﬂuenced the choice of the selected
N components.

92
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
Example 4.2. At different time instants {ti} = t1 , t2 , . . . (assumed perfectly known),
the quantities yi = y(ti) having been measured, the results y1 ± σ1 , y2 ± σ2 . . . have
been produced, these uncertainties being understood as the mean deviations of double-
exponential probability densities. Under the hypothesis that the relation between yi and
ti is linear, yi = a ti + b , estimate the parameters {a, b} . This problem is solved using a
special case of equations (4.31)–(4.32), without the terms deﬁning the a priori information.
The misﬁt function is, here,
S(a, b) =

i
| (a ti + b) −yi |
σi
.
(4.40)
The general problem is illustrated in Figure 4.7. Following the previous discussion, the
best line in the ℓ1-norm sense will necessarily go through at least two points. Of course
it may happen that the minimum of S is attained at a horizontal edge or face (Figures 4.8
and 4.9). As in that case the minimum of S is not attained at a single point, the best model
in the sense of the least-absolute-values criterion is not necessarily unique.
Figure 4.7. The best straight line in the ℓ1-norm
sense minimizes 
i
| (a ti+b)−yi |
σi
(the uncertainty bars are as-
sumed to be vertical). This best line ﬁts at least two points
exactly.
y
x
y = a t + b
+3
−1
+1
0
−3
0
y
t
Figure 4.8. Even for linear problems, the best solution in the ℓ1-norm sense may
notbeunique. Thisﬁgureillustratesahighlydegeneratedproblem. Weseekthebestline y =
a t + b ﬁtting the ﬁve points. In this example, the best line in the ℓ1-norm sense minimizes
the function S(a, b) = |−a+b+1|+|−a+b−1|+|b|+|a+b−1|+|a+b+1| . S(a, b) is
represented in Figure 4.9. The minimum of S(a, b) is attained by a solution passing through
two points (as it must always be), but also for all the straight lines represented in the ﬁgure.
Figure 4.9.
The function S(a, b) corresponding to the
problem in Figure 4.8. The vertical axis is for the slope a , and
the horizontal axis is for b . The minimum of S is attained at an
edge(ofthepolyhedronrepresenting S ina3Dspace). Theminimum
value of S is S = 4 , and the level lines represented are spaced with
FS = 0.5 .
+1
−1
0
−1
+1
0
b
a

4.4. The ℓ1-Norm Criterion for Inverse Problems
93
Nonlinear Problems
For nonlinear problems, none of the properties discussed above necessarily remain true.
In Figure 3.2 of chapter 3, the concept of the quasi linearity of a problem was discussed
(which is more general than the concept of linearizability). A problem is quasi linear if
the functions g(m) can be linearized inside the region of signiﬁcant posterior probability
density (but cannot necessarily be linearized with respect to the a priori model mprior ). All
the methods to be described below will only make sense for quasi-linear problems. For
strong nonlinear problems, the more general (and expensive) methods of chapters 1 and 2
should be used.
4.4.2
ℓ1-Norm Criterion and the Method of Steepest Descent
When direct methods of minimization (like a systematic exploration of the space) are too
expensive to be used, and if the derivatives
(Gn)i
α =
 ∂gi
∂mα

mn
,
(4.41)
can be obtained, either analytically or by ﬁnite differencing, gradient methods of mini-
mization can be used. I limit the scope of this section to the steepest descent method of
minimization.
The function S(m) does not, in general, have a continuous gradient (see, for instance,
Figure 4.5), but this is not a difﬁculty: good experience exists in the use of gradient-based
methods for large-scale inverse problems (see, for instance, Djikpéssé and Tarantola, 1999).
Passing, by chance, through an edge (where the gradient is not deﬁned) is not a practical
problem: as mentioned below, the simple rule sg(0) = 0 redeﬁnes the gradient at such
a point as the average of the two facing gradients. I have never found an advantage (for
large-sized nonlinear problems) in using (non)linear programming methods.
Gradient and Direction of Steepest Ascent
From now on, the terms vertex, edge, . . . correspond to the representation of S(m) in the
model space (see Figures 4.5 and 4.6) and not to the representation of S(m) as in the top
right of Figure 4.4.
Thegradientofthemisﬁtfunction S(m) canbeobtaineddirectlyfromequation(4.32):
( ˆγ n)α =
 ∂S
∂mα

mn
=

i
(Gn)i
α
1
σ i
D
sg(gi(mn) −di
obs) + 1
σ α
M
sg(mα −mα
prior)
.
(4.42)
If one or some of the signs sg( · ) in this equation happen to be zero (i.e., if the deﬁnition
sg(0) = 0 happens to be used), this would be an indication that one is at a discontinuity of
the gradient. But the expression (4.42) can still be used, amounting to a redeﬁnition of the
gradient at a discontinuity point as the average of the two adjacent gradients.
The gradient of a function deﬁned over the model space M is an element of the dual
space ˆM . As M is here an ℓ1-norm space, ˆM is an ℓ∞-norm space. As demonstrated in

94
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
Appendix 6.22.1, to pass from the gradient (element of ˆM ) to the steepest ascent vector
(element of M ), we must evaluate the dual of the gradient.
To do this, we must use the result demonstrated at the end of section 4.2.2. The
gradient is ﬁrst normed to one (in the sense of the ℓ∞-norm58), and then equation (4.18) is
used. The result is as follows.
Among all the components ( ˆγ n)α of the gradient, we select those that attain the
maximum value of the product59 σ α
M | ( ˆγ n)α | and call them the principal components of the
gradient. Usually, this maximum value is attained for a single component, but there may
be more than one principal component. Letting k be the number of principal components,
the components of the steepest ascent vector are then
(γ n)α =

1
k σ α
M sg( ( ˆγ n)α )
for the principal components
,
0
for the other components
.
(4.43)
One has ∥γ n ∥= 1 (this is here an ℓ1-norm), as one should, because the gradient has
been normalized (with respect to the ℓ∞-norm). A look at Figure 4.10 should help us to
understand this result. Some steepest ascent directions were plotted in Figure 4.4.
Figure 4.10. A circle in an ℓ1-normed space, and the same circle with three
different linear forms over the space. The direction of steepest ascent is deﬁned by the point
on the circle that reaches the maximum value of the form. It usually points along one of the
axes, although it may also point in an intermediate direction.
Let mn represent the current point we wish to update. In the previous section, we
obtained the steepest ascent vector γ n . As usual, the steepest descent method is written
mn+1 = mn −µn γ n
,
(4.44)
where µn is an arbitrary positive real number small enough to ensure convergence. Al-
though one may easily imagine methods for choosing reasonably good values for this con-
stant,60 a direct one-dimensional search (trying different values until the minimum value of
the misﬁt along this direction is found) is often the best method.
58Remember that the standard deviations in the dual space are the inverse of the standard deviations in the primal
space (equation (4.7)).
59Remember that there is no implicit sum notation in this chapter.
60One possibility for choosing µn is as follows: a linearization of the misﬁt function S(m) in the vicinity of
mn deﬁnes a partition of the model space into convex hyperpolyhedrons. The direction −γ n is a direction of
descent at mn . It is possible (and easy) to obtain the point of the intersection of −γ n with the ﬁrst hyperface and
to take this point as the updated point mn+1 (or, in practice, a point slightly after the hyperface), thus ﬁxing the
value of µn . Let us consider in some detail how this works. Hyperfaces of the misﬁt function S(m) correspond
to changes of sign of the expressions gi(m) −di
obs and mα −mα
prior , which means that the point mn+1 will be

4.4. The ℓ1-Norm Criterion for Inverse Problems
95
4.4.3
ℓ1-Norm in Data Space and ℓ2-Norm in Model Space
As mentioned in section 4.4.1, while the use of the ℓ1-norm may be necessary in the data
space (to ensure robustness), one may use an ℓ2-norm in the model space.
In the simplest situation (no a priori covariances), the misﬁt function is then
S(m) =

i
| gi(m) −di
obs |
σ i
D
+ 1
2

α
( mα −mα
prior )2
(σ α
M)2
,
(4.45)
the gradient is
( ˆγ n)α =
 ∂S
∂mα

mn
=

i
(Gn)i
α
1
σ i
D
sg(gi(mn) −di
obs) +
1
(σ α
M)2 (mα −mα
prior)
,
(4.46)
and the associated steepest ascent vector is (because we now have an ℓ2-norm in the model
space)
(γ n)α = (σ α
M)2 
i
(Gn)i
α
1
σ i
D
sg(gi(mn) −di
obs) + (mα −mα
prior)
(4.47)
(and the steepest descent algorithm is then, again, mn+1 = mn −µn γ n ).
Djikpéssé and Tarantola (1999) demonstrate the applicability of this algorithm for
solving a large-scale ℓ1-norm inverse problem.
4.4.4
ℓ1-Norm Criterion and Linear Programming
Programming techniques have been developed to obtain the solution of the problem of
optimizing a real function S(x) when the vector variable x is subject to a given vector
constraint (x) ≤0 . Although this is not obvious at ﬁrst sight, it can be demonstrated that
an ℓ1-norm minimization problem can be recast into a programming problem (see details
in Appendix 6.23.4).
Numerous books exist on the subject of linear and nonlinear programming. The
history of programming methods can be read in Dantzig (1963), who ﬁrst proposed the
simplex method in 1947. A good textbook is, for instance, Murty (1976). The reader may
also refer to Luenberger (1973), Gass (1975), or Bradley, Hax, and Magnanti (1977).
When both the misﬁt function S(x) and the constraints (x) ≤0 are linear functions
of x , the problem is one of ‘linear programming.’ Linear programming techniques are often
used by economists (maximizing a beneﬁt for given limitations in available supplies) and
at a hyperface if gi(mn+1) −di
obs = 0 for a given i or if mα
n+1 −mα
prior = 0 for a given α . Linearizing gi(m)
around mn gives gi(mn −µn γ n) ≃gi(mn) −µn

α (Gn)iα γ α
n , and, therefore, the conditions of being at a
hyperface are written gi(mn) −di
obs = µn

α (Gn)iα γ α
n for a given i or mα
n −mα
prior = µn γ α
n for a given
α . From these equations, it is easy to compute all the values of µn for which we will have hyperfaces of the
linearized function: µi
n = ( gi(mn) −di
obs ) / ( 
α (Gn)iα γ α
n ) (for all i) and µα
n = ( mα
n −mα
prior ) / γ α
n (for all
α). As −γ n is a direction of descent, negative values of µn have to be disregarded because they would give an
increase of S . Among the positive values, it is the smallest that gives the most neighboring hyperface, and the
problem is solved. Taking a slightly larger value will, in general, avoid dropping before the true hyperface of the
nonlinearized function (the chances of dropping at the hyperface are small, due to computer arithmetic).

96
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
by the military (minimizing the time needed for invading a neighboring country for given
limitations on troop transportation).
The central problem in linear programming is always to obtain the minimum of a
convex polyhedron in a multidimensional space, and all the methods suggested for solving
the problem are very similar: ﬁrst, one has to manage to obtain a vertex of the polyhedron,
then one has to leave the current vertex following a descending edge until the next vertex.
After a ﬁnite number of moves, the minimum is necessarily attained. The different methods
only differ in the way of obtaining the ﬁrst vertex, or, for a given vertex, in the choice of the
edge by which the current vertex has to be left.
Although the most widely used method for solving linear programming problems is
the simplex method, introduced in Appendix 6.23.1, the ﬁrst-in-ﬁrst-out (FIFO) method of
Claerbout and Muir (1973) is sometimes simpler for solving inverse problems.
4.5
The ℓ∞-Norm Criterion for Inverse Problems
4.5.1
Formulation of the Problem
We have seen above that if uncertainties in the observed data values, dobs , and uncertain-
ties in the prior model, mprior , are assumed to be conveniently modeled using generalized
Gaussians, then the posterior probability density in the model space is given by (equa-
tions (4.25)–(4.26))
σM(m) = const. exp( −S(m) )
,
(4.48)
where the misﬁt function is (assuming a common value, say p , for the parameters r and s )
S(m) = 1
p
 
i
| gi(m) −di
obs |p
(σ i
D)p
+

α
| mα −mα
prior |p
(σ α
M)p

.
(4.49)
When taking the limit p →∞, the generalized Gaussian becomes a boxcar function (see
Appendix 6.6), which means that this limit corresponds to the assumption of strict error
bounds
−σ i
D ≤gi(m) −di
obs ≤+σ i
D
,
−σ α
M ≤mα −mα
prior ≤+σ α
M
.
(4.50)
When p →∞, the posterior probability density gives
σM(m) =

const.
if the bounds (4.50) are satisﬁed,
0
otherwise
.
(4.51)
It may well happen that no point of the model space satisﬁes the bounds. This means, in
general, that the theoretical equation d = g(m) does not model the real world accurately
enough, or, more often, that we have been too optimistic in setting the uncertainty bars. In
what follows, let us assume that σM(m) is deﬁned, i.e., that there exists a region M′ of the
model space satisfying the error bounds and the theoretical equation.
As σM(m) is uniform over M′ , the maximum likelihood point is not deﬁned, and one
possibly should not bother introducing such a concept inside the ℓ∞-norm criterion. But,

4.5. The ℓ∞-Norm Criterion for Inverse Problems
97
in order to allow the reader to make the link with the minimax criterion of the literature, let
us make some developments.
For sufﬁciently regular forward equations m →g(m) , the maximum likelihood
point, say mp , can be deﬁned for any value of p inside the limits 1 ≤p < ∞. Using
the results of Descloux (1963), it can be shown that the sequence mp is convergent when
p →∞. The convergence point m∞= limp→∞mp may be termed the strict ℓ∞solution.
For any ﬁnite p , the point maximizing σM(m) also minimizes the function
S(m) = 1
p

i
| gi(m) −di
obs |p
(σ i
D)p
+

α
|mα −mα
prior|p
(σ α
M)p

,
(4.52)
but minimizing S(m) is equivalent to minimizing the function
R(m) = (p S(m))1/p
,
(4.53)
i.e.,
R(m) =

i
| gi(m) −di
obs |p
(σ i
D)p
+

α
| mα −mα
prior |p
(σ α
M)p
1/p
.
(4.54)
The limit of S(m) diverges when p →∞, but this is not so for the limit of R(m) :
in the limit p →∞, one obtains
R(m) = max
 | gi(m) −di
obs |
σ i
D
,
| mα −mα
prior |
σ α
M
(all values of i and of α )

.
(4.55)
Figure 4.11 shows the functions R(m) and S(m) for a one-dimensional example.
Figure 4.11. The function Sp(m) = 1/p (|2m|p + |m −1|p) is shown for p
respectively equal to 1 , 2 , and ∞. Also shown is the function Rp(m) = ( p S(m) )1/p ,
which gives R1(m) = S1(m) = |2m| + |m −1| , R2(m) = (5m2 −2m + 1)1/2 and
R∞(m) = max(|2m| , |m −1| ).

98
Chapter 4. Least-Absolute-Values Criterion and Minimax Criterion
Equation 4.55 shows that the minimization of R(m) thus corresponds to minimizing
the maximum weighted residual. This explains the term minimax criterion, often used for
the ℓ∞-norm criterion. One may also remember that the terms minimax norm, uniform
norm, and Chebyshev norm (in honor of the mathematician who used the ℓ∞-norm in the
1850s) are used as synonyms of ℓ∞-norm.
In conclusion, when boxcar probability densities can be used to model all the ‘input
uncertainties’ in the problem (i.e., measurement uncertainties and a priori uncertainties on
the model parameters), the posterior probability density in the model space, σM(m) , is
also boxcar (equation (4.51)). It has no maximum likelihood point, but as far as a ‘center’
deﬁned by the limit p →∞may make sense, this center may be found by using a
minimax criterion, i.e., by ﬁnding the minimum of the function R(m) in equation (4.55).
Obtaining this center is not of much help for understanding the probability density σM(m)
(see Example 4.3).
4.5.2
ℓ∞-Norm Criterion and the Method of Steepest Descent
Let us face here solving a problem based on the minimax criterion, i.e., ﬁnding the model m
that minimizes the function R(m) in equation (4.55). We assume here that the derivatives
(Gn)i
α =
 ∂gi
∂mα

mn
(4.56)
can be obtained either analytically or by ﬁnite differencing, so gradient methods of mini-
mization can be tried.
As at a given point mn , the value of R(m) is controlled by the value of the maximum
weighted residual (see equation (4.55)), the gradient of R(m) will only depend on the
corresponding term. Let us distinguish two cases:
• The maximum of R(m) is attained for a data residual, say the term i = i0 . Then,
( ˆγ n)α = (Gn)i0α
1
σ i0
D
sg(gi0(mn) −di0
obs)
.
(4.57)
• The maximum of R(m) is attained for a model residual, say the term α = α0 . Then,
( ˆγ n)α = δα0
α
1
σ α0
M
sg(mα0
n −mα0
prior)
,
(4.58)
where δα0
α = 1 if α = α0 and δα0
α = 0 if α ̸= α0 .
If it happens that the maximum value is attained for more than one residual simultaneously,
we are at a point where the gradient is discontinuous, and we may redeﬁne it by taking the
average of the two contiguous gradients.
To pass from the gradient to the steepest ascent vector, we must — as already done a
few times above — evaluate the vector γ that is dual to the form ˆγ . Using equation (4.17))
we obtain
(γ n)α = σ α
M sg( ( ˆγ n)α )
.
(4.59)

4.5. The ℓ∞-Norm Criterion for Inverse Problems
99
Figure 4.12.
The probability density de-
ﬁned in Example 4.3.
Each of the three conditions
| 5 −(2 x + y) | < 2 , | x −1 | < 3 , and | y −2 | < 3
is represented in gray, and there is a region where the three
conditions are satisﬁed (the darkest area). The probabil-
ity density σM(x, y) is constant inside this darkest area
and vanishes outside.
Figure 4.13. This ﬁgure has been created with the same data as Figure 4.4, but
using here an ℓ∞-norm instead of an ℓ1-norm. What is plotted here is not the misﬁt S1(m)
(as in Figure 4.4), but R∞(m) = limp→∞( p Sp(m) )1/p . The level lines indicate the
gradient of R∞(m) at every point. The direction of steepest ascent (with respect to the
ℓ∞-norm) is indicated at some selected points (arrows).
The steepest descent algorithm then writes
mn+1 = mn −µn γ n
,
(4.60)
where the positive real numbers µn are to be chosen using a linear search.
Example 4.3. Consider the same problem as that in Example 4.1, but assume now that
the uncertainties can be modeled using boxcar probability densities. Here, then, one has
σM(x, y) = const. if | 5 −(2 x + y) | < 2 and | x −1 | < 3 and | y −2 | < 3 , and
one has σM(x, y) = 0 if any of these conditions is not satisﬁed. This probability density
is represented in Figure 4.12. The function R(x, y) deﬁned in the text is represented in
Figure 4.13.
4.5.3
ℓ∞-Norm Criterion and Linear Programming
The possible use of linear programming techniques for the resolution of inverse problems
based on the minimax criterion is not considered in this (main) text. Some details are given
in Appendix 6.23.5.


Chapter 5
Functional Inverse
Problems
When in doubt, smooth.
Sir Harold Jeffreys (Quoted by Moritz, 1980)
Many inverse problems involve functions: the data set sometimes consists of record-
ings as a function of time or space, and the main unknown in the parameter set sometimes
consists of a function of the spatial coordinates and/or of time.
Quite often, the functions can be approximated by their discretized versions, and an
inﬁnite-dimensional problem is then reduced to a ﬁnite-dimensional one. In fact, many
‘functions’ are handled and displayed by digital computers, and their discretization is im-
plicit (like, for instance, when dealing with space images of Earth).
In spite of this, there are situations where the inverse problem is better formulated
using functions (i.e., using the concepts of functional analysis). One may go quite far using
the functional formulation, even if, at the end, some sort of discretization is used for the
actual computations.
Few developments are needed for the general inverse problem (we shall see that the
very deﬁnition of random function considers successive discretizations). But in the special
case where the considered random functions are Gaussian, lots of beautiful mathematics is
available that provides efﬁcient methods of resolution.
5.1
Random Functions
5.1.1
Description of a Random Function
LookingatFigures5.1–5.2, wecanunderstandwhatisgenerallymeantbyarandomfunction.
Each of the ﬁgures represents some realizations of the considered random function, each
realization being an ordinary function.
101

102
Chapter 5. Functional Inverse Problems
Figure 5.1. Some realizations of a random func-
tion that is a one-dimensional random walk. At each time
step (abscissa), the walker randomly chooses to walk one
step up or one step down.
Figure 5.2. Four random realizations of a ran-
dom function deﬁned over a 2D space. The realizations
are continuous inside a ﬁnite number of blocks (these are,
in fact, Voronoi cells). Contrary to the example in Fig-
ure 5.1, each realization is deﬁned by a ﬁnite amount of
information: this random function is ﬁnite dimensional.
A particular realization can be seen as a point in an abstract space (named a function
space or space of functions). To completely characterize some functions, one needs an
inﬁnite number of points, like in the example of Figure 5.1, while to characterize some
other functions, a ﬁnite number of parameters is sufﬁcient: each realization in Figure 5.2 is
characterized by the coordinates of the points at the center of each domain (in fact, a Voronoi
cell). Let us concentrate here on the inﬁnite-dimensional case: if the function space is ﬁnite
dimensional, the methods developed in the previous chapters directly apply.
In the ﬁrst chapter, we saw the usefulness of the introduction of probability densities
over ﬁnite-dimensional parameter spaces. Unfortunately, no simple generalization of the
concept of probability densities exists over inﬁnite-dimensional spaces.
To ﬁx ideas, consider ﬁrst a random function x(t) , where both variables t and x
are scalars (one may, for instance, think of a scalar quantity x depending on time t ). If
t →x(t) is a random function, then, by deﬁnition, for any given t , x(t) is an ordinary
random variable61 whose probability density is denoted f (x; t) .
The knowledge of f (x; t) for all t is not sufﬁcient to characterize the random func-
tion: f (x; t) onlycarriesinformationonthemarginalprobabilitydistributionofthevariable
x at a given time t , but does not carry information on the possible dependencies (or cor-
relations) between the two random variables x(t1) and x(t2) at two instants t = t1 and
t = t2 . To characterize this, one needs the knowledge, for any two values t = t1 and
t = t2 , of the two-dimensional probability density for the two variables x1 = x(t1) and
x2 = x(t2) , a probability density that we may denote f (x1, x2; t1, t2) .
61Usually, a different notation is used for a random variable and for a realization of it. We do not need this
sophisticated notation here.

5.1. Random Functions
103
But, again, this gives information on the two-dimensional marginals but not on the
higherorderjointprobabilitydensities: foracompletecharacterizationofarandomfunction,
we need to know joint probability densities of any order. Thus,
a random function t →x(t) is characterized if the
n-dimensional probability density f (x1, . . . , xn; t1, . . . , tn)
is known for any points t1, . . . , tn and for any value of n .
Only very special random functions can be characterized by low-order marginals (for
instance, a Gaussian random function is perfectly characterized by its two-dimensional
marginals).
Notethatwhenann-dimensionalprobabilitydensityisgiven, onecandeducethelower
dimensional marginals. For instance, one may pass from a two-dimensional probability den-
sity f (x1, x2; t1, t2) to the one-dimensional marginal f (x1; t1) =

dx2 f (x1, x2; t1, t2) .
The result f (x1; t1) must actually be independent of the value t2 , imposing a constraint on
a function f (x1, x2; t1, t2) in order to accept the interpretation of being a two-dimensional
probability density of a random function. The n-dimensional version of this constraint is
obvious to formulate.
5.1.2
Computing Probabilities
Let t →x(t) represent a random function and assume that we have a perfect description
of it, i.e., that for any points t1, . . . , tn and for any n , the joint probability density f (x) ≡
f (x1, . . . , xn; t1, . . . , tn) of the random variables x(t1), . . . , x(tn) is known. We wish here
to compute the probability of a realization of the random function being within certain
limits. More precisely, for each value of t , let us introduce a numerical set E(t) . We wish
to compute the probability for x(t) to verify (see Figure 5.3)
x(t) ∈E(t)
.
(5.1)
The set of all the possible realizations of the random function verifying equation (5.1) will
be denoted by A . Following Pugachev (1965), let us ﬁrst consider the subset An of the
set of all the possible realizations of the random function for which the values associated
with the points t1, . . . , tn belong to the numerical sets E(t1), . . . , E(tn) . By deﬁnition of a
probability density, the probability of the set An is clearly
P(An) =

E(t1)
dx1 · · ·

E(tn)
dxn f (x)
.
(5.2)
Figure 5.3. Given a random function, it is
possible to compute the probability of a realization
being within given bounds (see text).

104
Chapter 5. Functional Inverse Problems
For any positive integer value of n , we now consider a partition of the range of variation
of the argument t into n subintervals such that the length of each of the n subintervals
tends to zero as n →∞. Now, from each subinterval we choose a value of t such that the
points t1, . . . , tn contain, for every n , all the points of the preceding partitions. Thus, we
get a sequence A1, A2, . . . of sets of realizations of the random function each including all
the subsequent sets. If the realizations of the random function are sufﬁciently regular, the
product of all the sets An coincides with the initial set A . The numbers P(A1), P(A2), . . .
form a monotonic nonincreasing progression of nonnegative numbers. Then, the limit
P(A) = lim
n→∞P(An)
(5.3)
exists and corresponds to the probability of a realization of the random function verifying
the condition expressed by equation (5.1).
This computation shows that even if the notion of probability density does not gener-
alize to inﬁnite-dimensional spaces (because the equivalent of the Lebesgue integral does
not exist), the actual probabilities of regions deﬁned over inﬁnite-dimensional manifolds
can be deﬁned (and computed).
When the considered functions belong to a linear (functional) space (we have not
introduced such an assumption here), more mathematics is available. Rather than a sim-
ple discretization of the functions, one then considers arbitrary (ﬁnite-dimensional) linear
subspaces. This leads to the notion of ‘cylinder measures’ (see, for instance, Balakrishnan,
1976), which are not considered here.
From a practical point of view, once one has been able to demonstrate that the limit
deﬁned in equation (5.3) exists, its actual evaluation, if performed using numerical meth-
ods, can sometimes be well approximated using a large, although ﬁnite, value of n (i.e.,
of discretization points).
This means, in fact, that the random function is sufﬁciently
characterized (from a practical point of view) by the n-dimensional probability density
f (x1, . . . , xn; t1, . . . , tn) given for, say, equally spaced points t1, . . . , tn and for a sufﬁ-
ciently high value of n (the value of n corresponds to the number of points needed for a
reasonably accurate representation of any realization of the random function). This implies,
of course, that the realizations are sufﬁciently regular. For instance, while a realization
of pure ‘white’ noise (see section 5.3.3) cannot be described by a ﬁnite number of points,
physical white noise is always somewhat ‘colored’ (i.e., has ﬁnite bandwidth) and can then
be described by a ﬁnite (sufﬁciently large) number of points.
5.1.3
General Random Processes
We have seen that at each value of t , a random function t →x(t) deﬁnes a random variable.
Sometimes, we have to consider two random functions t →x1(t) and t →x2(t) simulta-
neously. Each random function is individually characterized by a joint probability density
f 1(x1
1, . . . , x1
n; t1, . . . , tn) and f 2(x2
1, . . . , x2
m; t′
1, . . . , t′
m) , as indicated in section 5.1.1. In
addition, we need now to characterize the dependencies (correlations) between the random
variables x1(t) and x2(t) .
This is made by the joint probability density
f 12(x1
1 . . . x1
n, x2
1 . . . x2
m; t1 . . . , tn, t′
1 . . . t′
m)
,

5.1. Random Functions
105
from which the two marginal probability densities
f 1(x1
1 . . . x1
n; t1 . . . tn) =

dx2
1 · · ·

dx2
m f 12(x1
1 . . . x1
n, x2
1 . . . x2
m; t1 . . . tn, t′
1 . . . t′
m)
,
f 2(x2
1 . . . x2
m; t′
1 . . . t′
m) =

dx1
1 · · ·

dx1
n f 12(x1
1 . . . x1
n, x2
1 . . . x2
m; t1 . . . tn, t′
1 . . . t′
m)
(5.4)
can be computed.
In more general problems, instead of two random functions, we have to consider an
arbitrary number. Their variables, in turn, may be multidimensional and may be different.
We may have to consider not only random functions but simultaneously also some discrete
random variables as well. The notation may become complicated in detail, but there is no
conceptual difﬁculty.
5.1.4
Random Functions over Linear Spaces
The (inﬁnite-dimensional) function spaces we consider are not necessarily linear spaces:
the sum of two functions may not be deﬁned (or may not be useful). The reasons that forced
us in chapter 1 to consider that the parameter space is a general manifold, not necessarily
a linear one, prevail here. A typical situation is when the electric properties of a wire may
randomly depend on time: we may equivalently consider as a random function the resistance
R(t) of the wire or its conductance S(t) = 1/R(t) . The sum of two resistance functions
R1(t) + R2(t) is not equivalent to the sum of the two conductance functions S1(t) + S2(t) ,
and one may not wish to introduce one sum or the other. The functional space is here an
inﬁnite-dimensional manifold that is not (or not yet) a linear space.
We know that in this example it is possible to deﬁne a structure of linear space, but
with a sum that, instead of being the ordinary sum, is the logarithmic sum. This amounts
to introducing the logarithmic resistance ρ(t) or the logarithmic resistance σ(t) and then
introducing the ordinary sum (both sums being now equivalent). It is in this sense that the
hypothesis made below (that the function spaces considered are linear spaces, with the sum
and the multiplication by a scalar deﬁned) must be understood.
Consider, then, a random function x(t) that is an element of a linear function space,
where the sum x1(t) + x2(t) and the multiplication by a scalar λ x(t) are deﬁned (and
make physical sense).
If the one-dimensional (marginal) probability densities f (x; t) are known for any t ,
central estimators or estimators of dispersion of the random function can be computed.
For instance, the mean value of the random function is the (nonrandom) function m(t)
deﬁned by
m(t) =

dx x f (x; t)
,
(5.5)
and the standard deviation σ(t) is deﬁned by
σ(t)2 =

dx ( x −m(t) )2 f (x; t)
.
(5.6)

106
Chapter 5. Functional Inverse Problems
If the two-dimensional joint probability densities f (x1, x2; t1, t2) are also known for
any t1 and t2 , the correlations are known perfectly. The covariance function C2(t, t′) of
the random function is deﬁned as the covariance (in the usual sense) between the random
variables x(t1) and x(t2) :
C(t, t′) =

dx

dx′ ( x −m2(t) ) (x′ −m2(t′) ) f (x, x′; t, t′)
.
(5.7)
It can be shown that a covariance function is symmetric, C(t, t′) = C(t′, t) , and deﬁnite
nonnegative: for any function φ(t) , one has

 tmax
tmin dt

 tmax
tmin dt′ φ(t) C(t, t′) φ(t′) ≥0 . It
is easy to verify62 that the covariance between a point t and itself equals the variance:
C(t, t) = σ(t)2 .
Example 5.1. Gaussian random function with given mean value and covariance func-
tion. A random function t →x(t) is termed Gaussian with mean value m(t) and co-
variance function C(t, t′) if, for any points t1, . . . , tn and for any n , the joint probability
density of the random variables x(t1), . . . , x(tn) is
f (x) =
1
(2π)n/2 det1/2 C
exp

−1
2 (x −m)t C−1 (x −m)

,
(5.8)
where
x =


x(t1)
· · ·
x(tn)

, m =


m(t1)
· · ·
m(tn)

, C =


C(t1, t1)
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
· · ·
C(tn, tn)

.
(5.9)
That the covariance function, as deﬁned by equation (5.7), is the C(t, t′) appearing in
the expression (5.8) of a Gaussian function is a well-known result but is not trivial to
demonstrate.
A Gaussian random function is called stationary if the mean value m(t) is, in fact,
independent of t and if the covariance function C(t, t′) depends, in fact, only on the
distance between t and t′ . For instance, if t is a scalar variable like a time, the covariance
function C(t, t′) can be represented by a function 8(τ) as C(t, t′) = 8(t −t′) . This
simple deﬁnition of stationarity does not apply to random functions that are markedly non-
Gaussian.
If instead of one random function x(t) one has two random functions x1(t) and
x2(t) , in addition to the deﬁnitions just considered, one also deﬁnes the crosscovariance
C12(t, t′) =

dx1

dx2 ( x1 −m2
1(t) ) (x2 −m2
2(t′) ) f (x1, x2; t, t′)
.
(5.10)
One then has a matrix of covariance functions
C(t, t′) =

C11(t, t′)
C12(t, t′)
C21(t, t′)
C22(t, t′)

(5.11)
62From equation (5.7), it follows that C(t, t) =

dx

dx′ ( x −m2(t) ) (x′ −m2(t) ) f (x, x′; t, t) . Using
f (x, x′; t, t) = f (x; t) δ(x −x′) gives C(t, t) =

dx

dx′ ( x −m2(t) ) (x′ −m2(t) ) f (x; t) δ(x −x′) =

dx ( x −m2(t) )2 f (x; t) . According to equation (5.6), this is the variance σ(t)2 .

5.1. Random Functions
107
that is symmetric,
Cij(t, t′) = Cji(t′, t) ,
(5.12)
and deﬁnite nonnegative.
The successive generalizations of this (when there are more than two random functions
or when, for instance, the scalar variable t is replaced with a vector variable) are long to
expose but easy to understand. They are left to the reader.
5.1.5
Covariance Functions Do Not Characterize Random Functions
Does a covariance function give a convenient description of a random function?
In general, NO.
Pugachev (1965), for instance, shows an example of two random functions with completely
different realizations but having exactly the same mean function and covariance function.
One pseudorandom realization of each of the two random functions mentioned by Pugachev
is presented in Figures 5.4–5.5.
Figure 5.4. Pseudorandom realization of a
Gaussian random function with exponential covari-
ance. The covariance function of this Gaussian ran-
dom function is identical to that of the random function
in Figure 5.5.
Figure 5.5. Pseudorandom realization of a
random function where the steps happen at random
times (with constant probability density) and where the
steps are random normally distributed (with zero mean).
This (non-Gaussian) random function has the same co-
variance function as that in Figure 5.4, demonstrating
that the mean and the covariance are not sufﬁcient to
characterize a random function.
Thisshouldnotbesurprising, becausethisisonlytheequivalent, ininﬁnite-dimensional
spaces, of the well-known fact that one-dimensional random variables with completely dif-
ferent probability densities may well have the same mean and the same variance. The
problem is that when the number of dimensions under consideration is high, it is not easy
to obtain an intuitive idea of what the probability densities look like, and one may easily be
misled with the assumptions made.

108
Chapter 5. Functional Inverse Problems
5.2
Solution of General Inverse Problems
In chapter 1, we introduced the notion of a (ﬁnite-dimensional) parameter manifold X over
which probability distributions can be deﬁned that are characterized by probability densities.
It has been assumed that the notion of volume can be introduced over the manifold. When
some coordinates {x1, . . . , xn} are chosen over the manifold, with this deﬁnition of volume
is associated a particular probability density µ(x) that is homogeneous (with respect to the
given deﬁnition of volume).
Given the manifold X and the homogeneous probability density µ(x) , the conjunc-
tion of any two probability densities f1(x) and f2(x) has been deﬁned as (equation (1.40))
σ(x) = k f1(x) f2(x)
µ(x)
,
(5.13)
where k is a normalization constant. This was the basis of all the development in chapter 1
for the introduction of the general inverse problem.63
In section 5.1.2, we saw how actual probabilities can be computed in inﬁnite-dimen-
sional spaces (if the random functions are sufﬁciently regular). If this is the case, then
equation (5.13) makes sense for every n-dimensional discretization, deﬁning, say σn(x) .
The probability Pn(A) of any set A is computed using σn(x) , and the limit P(A) =
limn→∞Pn(A) is subsequently evaluated.
In this sense, all the results of the previous sections apply, and the only extra require-
ment, in the functional case, is to take the limit n →∞of all the probabilities computed
in n dimensions.
There are special circumstances where this limit can be considered from the beginning.
This is the case for the Gaussian random functions, where many analytical results can be
obtained, as we are about to see in the coming sections.
5.3
Introduction to Functional Least Squares
Some very general results exist concerning the solution of very special inﬁnite-dimensional
inverse problems. For instance, in a stochastic (Gaussian) context, Franklin (1970) gave
the least-squares solution to inverse problems where both the model and data space can be
inﬁnite dimensional, but where data parameters are linearly related to model parameters.
Backus (1970a,b,c) (see Appendix 6.15) gave the general Bayesian solution to problems
where, if the model space can be inﬁnite dimensional, it is assumed that the data space is
ﬁnite dimensional and that the relationship between data and model parameters is linear,
and where one is only interested in the prediction of a ﬁnite number of properties of the
model (which are also linear functions of model parameters). These papers are historically
important, but they do not provide for the inﬁnite-dimensional problem a solution with a
degree of generality comparable to that possible for ﬁnite-dimensional problems (see the
ﬁrst chapter of this book).
63Basically, the state of information describing measurements and a priori information was represented by a
probability density ρ(x) and the theoretical state of information by a probability density θ(x) . The ﬁnal state of
information, obtained by combining these two states of information, was σ(x) = k ρ(x) θ(x) / µ(x) .

5.3. Introduction to Functional Least Squares
109
In the following sections, we develop the theory of functional inverse problems in
the special case where the ‘input’ random functions are Gaussian (so the ‘output’ random
functions are not too far from Gaussian). I must again emphasize that some problems
are functional but have a ﬁnite number of degrees of freedom (like when considering the
random function displayed in Figure 5.2). These problems must be treated using the ﬁnite-
dimensional methods of the previous chapters, and, therefore, they do not suffer from the
limitation introduced by the Gaussian hypothesis.
In what follows, we assume that the functions under consideration belong to a linear
space, so the sum of two functions is deﬁned and makes physical sense (this sometimes
requires a redeﬁnition of the variables, as mentioned in section 5.1.4). The resolution of
the inverse problem implies the use of differential and integral operators. Although the
numerical results may be obtained after discretization, the functional language allows an
indispensable compactness of the discussion. For instance, when the resolution of the for-
ward problem involves differential equations, to obtain the differential equations giving the
inverse solution is easier than when trying to formulate the inverse problem based on a
discretized version of the forward problem. Once the ﬁnal (functional) equation giving the
solution of the inverse problem has been obtained, and in order to perform numerical com-
putations, then (and only then) do we have to discretize everything: the original differential
equation, its adjoint, and all the integral/differential equations obtained.
In writing a chapter like this one, it is difﬁcult to choose an adequate level of math-
ematical rigor. Many least-squares formulas have a larger domain of validity than that for
which rigorous mathematical proofs exist. In the coming pages, we shall not be preoccupied
with pure mathematical aspects: common sense will guide the physicist well in this domain,
with low probability of error. What matters to us here is to learn the intuitive meaning of a
wide enough set of concepts and of the accompanying usual language (linear and nonlinear
functionals, dual spaces, transposes of linear operators, etc.).
5.3.1
Representation of the Dual of a Linear Space
Let E be a linear space, eventually inﬁnite dimensional, and let ˆE be its dual, i.e., the space
of the linear real functionals over E (a real functional over E is an application from E
into the real line R ). If e is an element of E and f is an element of ˆE , the real number
associated with e by f is denoted ⟨f , e ⟩. It follows from Riesz’s representation theorem
(see, for instance, Taylor and Lay, 1980) that any linear functional f can be associated with
an object with the same indices or variables as the elements of E , also denoted f , and such
that if the matricial-like notation ft e represents the real (adimensional) number obtained
by summing or integrating over all the (common) variables of f and e , then
⟨f , e ⟩= ft e
.
(5.14)
Example 5.2. When analyzing an elastic sample in the laboratory, one may consider at
every point x of the medium the mass density ρ(x) and the incompressibility modulus κ(x) .
As we wish to deﬁne a space of functions where the sum of two functions would conserve
its meaning should one have considered, instead of mass density and incompressibility,
the lightness density ℓ= 1/ρ and the compressibility modulus γ = 1/κ , we introduce
the logarithmic pass density a(x) = log(ρ(x)/ρ0) and the logarithmic incompressibility

110
Chapter 5. Functional Inverse Problems
modulus b(x) = log(κ(x)/κ0) ( ρ0 and κ0 being two arbitrary constants). The elastic
sample is then deﬁned by the two functions
e =
e1(x)
e2(x)

=
a(x)
b(x)

(x ∈V)
.
(5.15)
Let us denote by E the space of all such imaginable functions. Any element of the dual space
ˆE can then be (uniquely) represented by another couple of functions (or, more generally,
distributions):
f =
f1(x)
f2(x)

=
α(x)
β(x)

(x ∈V)
,
(5.16)
such that the duality product is obtained by summing over all the variables,
⟨f , e ⟩= ft e =
2

i=1

V
dV (x) fi(x) ei(x)
,
(5.17)
i.e.,
⟨f , e ⟩= ft e =

V
dV (x) α(x) a(x) +

V
dV (x) β(x) b(x)
.
(5.18)
5.3.2
Deﬁnition of a Covariance Operator
A covariance operator over E is, by deﬁnition, a linear symmetric deﬁnite nonnegative
operator mapping ˆE into E .
Example 5.3. Let C be a covariance operator over the space E of Example 5.2, and let
us write as
e = C ˆe
(5.19)
the application from ˆE into E deﬁned by C . An explicit representation of the operator C
will be given by
a(x) =

V
dV(x) Caa(x, x′) α(x) +

V
dV(x) Cab(x, x′) β(x)
,
b(x) =

V
dV(x) Cba(x, x′) α(x) +

V
dV(x) Cbb(x, x′) β(x)
,
(5.20)
or, for short,
a
b

=
Caa
Cab
Cba
Cbb
 α
β

.
(5.21)
We see that the kernel of the operator is here a 2 × 2 matrix of (covariance) functions.

5.3. Introduction to Functional Least Squares
111
Example 5.4. Assume that we have N models of logarithmic density and logarithmic bulk
modulus (N ≫1)
a1
b1

,
a2
b2

, . . .
.
(5.22)
Using the classical deﬁnitions of statistics, the mean model
⟨a⟩
⟨b⟩

is deﬁned by
⟨a⟩(x) =
1
N
 N
i=1 ai(x)
,
⟨b⟩(x) =
1
N
 N
i=1 bi(x)
,
(5.23)
and the following covariance functions are deﬁned:
Caa(x, x′) =
1
N
 N
i=1 (ai(x) −⟨a⟩(x))(ai(x′) −⟨a⟩(x′))
,
Cab(x, x′) =
1
N
 N
i=1 (ai(x) −⟨a⟩(x))(bi(x′) −⟨b⟩(x′))
,
Cba(x, x′) =
1
N
 N
i=1 (bi(x) −⟨b⟩(x))(ai(x′) −⟨a⟩(x′))
,
Cbb(x, x′) =
1
N
 N
i=1 (bi(x) −⟨b⟩(x))(bi(x′) −⟨b⟩(x′))
.
(5.24)
A well-known result (e.g., Pugachev, 1965) is that the covariance functions are symmetric,
Caa(x, x′) = Caa(x′, x)
,
Cab(x, x′) = Cba(x′, x)
,
Cbb(x, x′) = Cbb(x′, x)
,
(5.25)
and deﬁnite nonnegative, i.e., for any functions φa(x) and φb(x) , one has

V
dV(x) φa(x) Caa(x, x′) φa(x′) +

V
dV(x) φa(x) Cab(x, x′) φb(x′)
+

V
dV(x) φb(x) Cba(x, x′) φa(x′) +

V
dV(x) φb(x) Cbb(x, x′) φb(x′) ≥0
.
(5.26)
These properties justify the abstract deﬁnition used for introducing covariance oper-
ators.
5.3.3
Covariance Functions and Associated Random Realizations
To have in mind what is exactly meant by a Gaussian random function with given mean and
given covariance functions, let us see some examples.
Example 5.5. Exponential covariance function. Let M be a linear space with functions
m(t) , where t representsaspatialortemporalvariable. Acovarianceoperatorover M will
have as kernel a covariance function C(t, t′) . One covariance function often encountered
in practical applications is the exponential covariance function
C(t, t′) = σ 2 exp( −|t −t′| / τ )
.
(5.27)

112
Chapter 5. Functional Inverse Problems
Figure 5.6 shows a (pseudo)random realization64 of a Gaussian random function with
zero expectation and such an exponential covariance. In two dimensions, the exponential
covariance function is C(x, y, x′, y′) = σ 2 exp( −
'
(x −x′)2 + (y −y′)2 / τ ) , and a
random realization is displayed in Figure 5.7.
Figure 5.6. Example of a pseudorandom
realization of a Gaussian random function with
zero mean and exponential covariance C(t, t′) =
σ 2 exp( −|t −t′| / τ ) . Notice that the function
has a discontinuous derivative at every point. The
value of the function has been computed at 40 000
points (the printer device has much less resolu-
tion).
Figure 5.7.
A pseudorandom re-
alization
of
a
2D
Gaussian
ﬁeld
with
exponential covariance
C(x, y, x′, y′)
=
σ 2 exp( −
'
(x −x′)2 + (y −y′)2 / L ) , from
Fenton (1990), with permission. The length of
the side of the square is 2.5 L .
An important classical result concerning a stationary (sufﬁciently regular) random
function is that its realizations are differentiable n times if and only if the correlation
function I(z) = C(z, 0) is differentiable at z = 0 up to the order 2n . For instance, for
the realizations to be differentiable, the second derivative of I(z) must exist at z = 0 .
This is not the case in the examples of Figures 5.6 and 5.7, so that the realizations shown
are not differentiable. On the contrary, the realizations of a random function with Gaussian
covariance are inﬁnitely differentiable (they are very smooth), as the following example
shows.
Let me mention here that, for the construction of pseudorandom realizations, like
the ones displayed here, one may use different methods. One may, for instance, use the
sequential realization method described in chapter 2. One may also convolve a Gaussian
white noise by the appropriate ﬁlter (see section 5.3.4), a convolution that can be performed
in the space domain of the Fourier domain. For details, see Fenton (1990).
64It can be demonstrated that a realization of a Gaussian random function with exponential covariance C(t, t′) =
σ 2 exp( −|t −t′|/τ ) can be generated by the algorithm x(t +Ft) = α x(t)+σ
√
1 −α2 Gaussian(0, 1) , where
α = exp(−Ft/τ) .

5.3. Introduction to Functional Least Squares
113
Example 5.6. Gaussian covariance function. Let M be a linear space with functions
m(x) , where x represents the Cartesian coordinates of a point in a Euclidean space.
Another covariance function often encountered in practical applications is the Gaussian
covariance function
C(x, x′) = σ 2 exp

−∥x −x′∥2
2 L2

.
(5.28)
The bottom of Figure 5.8 shows a pseudorandom realization of a two-dimensional Gaussian
random function with zero mean and Gaussian covariance.
Self-Similar
Exponential
Gaussian
Figure 5.8. Pseudorandom realizations of three types of two-dimensional Gaus-
sian random ﬁelds (from Frankel and Clayton, 1986, with permission). At the top, with
the Von Karman covariance function (Tatarski, 1961) C(x, y; x′, y′) = K0(D/L) , where
K0(·) is the modiﬁed Bessel function of order zero and D2 = (x −x′)2 + (y −y′)2 . At the
middle, with the exponential covariance function C(x, y; x′, y′) = σ 2 exp(−D/L) , and at
thebottom, withtheGaussiancovariancefunction C(x, y; x′, y′) = σ 2 exp(−D2/(2 L2) ) .
Example 5.7. Circular covariance function. When working with stationary random ﬁelds
in the two-dimensional Euclidean space, the circular covariance65 model is often used. The
covariance between two points separated by a distance r is
8(r) = σ 2 
1 −β + sin β
π

with
β = 2 arcsin r
D
(5.29)
for r ≤D and 8(r) = 0 for r > D .
65So called because 8(r) is proportional to the area of intersection of two discs of diameter D whose centers
are separated by the distance r .

114
Chapter 5. Functional Inverse Problems
Example 5.8. White-noise covariance function. The covariance “function”
C(t, t′) = β δ(t −t′) ,
(5.30)
where β is a ﬁnite constant and where δ(t) represents Dirac’s delta distribution, cor-
responds to white noise (see Example 5.10). Figure 5.9 suggests what a realization of a
white-noise random function looks like.
Figure 5.9. A pseudorandom realization of a pure white-noise random function
cannot be represented because the variance of the random function at any point is inﬁnite.
But white noise can be seen, for instance, as the limit of an ordinary Gaussian random
function when the correlation length L tends to zero and the variance σ 2 tends to inﬁnity,
the product L σ 2 remaining constant (see Example 5.10).
This ﬁgure illustrates such
a limit. The three functions are pseudorandom realizations of a (stationary) Gaussian
random function with zero mean value and exponential covariance function C(z, z′) =
σ 2 exp(−|z−z′|/L) . The realization in the middle is the same as in Figure 5.6, represented
here using a different vertical scale. At the top, the correlation length is 10 times larger
(and the variance 10 times smaller), and at the bottom the correlation length is 10 times
smaller (and the variance 10 times larger).
Example 5.9. Random-walk covariance function. Also interesting for practical applica-
tions is the covariance function
C(t, t′) = β min(t, t′)
(for t ≥0 and t′ ≥0)
.
(5.31)
The variance at point t is σ 2 = β t . It corresponds to a (unidimensional) random walk,
which, in turn, corresponds to the primitive of a white noise. See Figure 5.1 for some
one-dimensional random walks.
Example 5.10. The use of white noise for modeling uncertainties. A Gaussian random
function t →x(t) is named white noise if its covariance function is
C(t, t′) = w(t) δ(t −t′) ,
(5.32)
where w(t) is termed the intensity of the white noise. In particular, it should be noticed
that, for any t , the variance of the random variable x(t) is inﬁnite and that, for any t and
t′ , the random variables x(t) and x(t′) are uncorrelated. The easiest way to understand

5.3. Introduction to Functional Least Squares
115
white noise is to consider it as a limit of a Gaussian random process where the correlation
length tends to vanish. Take, for instance, a Gaussian random function with exponential
covariance
C(t, t′) = σ 2 exp

−|t −t′|
T

.
(5.33)
In the limit when T →0 , if the product σ 2 T remains ﬁnite (and so, if the variance tends
to inﬁnity), the function C(t, t′) tends to the particular white-noise distribution
C(t, t′) = 2 σ 2 T δ(t −t′)
.
(5.34)
The adjective “white” comes from the fact that a realization of such a random function has
a ﬂat frequency spectrum (i.e., ﬂat Fourier transform), like white light; the noun “noise”
comes from the fact that a sound wave with such a spectrum really sounds like noise. The
term 2 σ 2 T in the last equation can be interpreted as the area under the curve C(t, t′) :
 ∞
−∞
dt′ C(t, t′) = 2 σ 2 T
(for any t)
.
(5.35)
It is not possible to represent a realization of a true white-noise random function because the
values at any point are +∞or −∞(with probability 1 ), but it is possible to obtain a good
intuitive feeling by a direct consideration of the concept of the limit of random functions
whose correlation lengths tend to zero. Figure 5.9 shows an illustration. If instead of using
an exponential covariance function we use a Gaussian covariance function,
C(t, t′) = σ 2 exp

−1
2
(t −t′)2
T 2

,
(5.36)
then, in the limit T →0 , σ 2 →∞, T σ 2 constant,
C(t, t′) =
√
2π σ 2 T δ(t −t′)
,
(5.37)
where, again, the factor of the delta function represents the area under the covariance
function. Comparing (5.34) with (5.37), we see that the factor of δ(t −t′) differs when
obtaining white noise as the limit of different random functions. Assume that some data
d(t) consist of signal s(t) plus noise n(t) :
d(t) = s(t) + n(t)
.
(5.38)
Usually, the d(t) data are sampled. If the correlation length of the signal is much larger than
the correlation length of the noise, the last may be undersampled, and then, for all numerical
purposes, its correlation length may be taken as null. The covariance function describing
uncertainties in the observed data may then be approximated by that in equation (5.32),
where
w(t) ≃(true variance of the noise) × (true correlation length of the noise)
.
(5.39)
This justiﬁes the conventional use of white noise to represent some experimental uncer-
tainties.

116
Chapter 5. Functional Inverse Problems
Example 5.11. Experimental estimation of a covariance function for describing exper-
imental uncertainties. Figure 5.10 shows an experimentally estimated covariance function
for representing data uncertainties.
Figure 5.10. 900 s of recording of the displacement of a point on Earth’s surface
south of France (top). One can see the arrival of the seismic waves produced by the big
Chilean earthquake of March 3, 1985 (arrow). To estimate the noise contaminating the
signal after the ﬁrst wave arrival, 180 s of recording before the arrival have been selected
(thick line). The normalized autocorrelation of this part of the recording is shown at the
bottom in two different scales (in seconds). This can be taken directly as the correlation
function for representing data uncertainties. (B. Romanowicz, pers. comm.).
5.3.4
Realization with Prescribed Covariance
Let w have a Gaussian probability density with mean w0 and covariance Cw :
f (w) = const. exp

−1
2 (w −w0)t C −1
w (w −w0)

.
(5.40)
If one deﬁnes
x = L w
,
(5.41)
where L is an invertible matrix, what is the covariance matrix of x ?
The Jacobian property gives (as the Jacobian is constant) g(x) = k f (w(x)) =
k f (L−1 x) . Replacing w with L−1 x in expression (5.40) and introducing x0 = L w0

5.3. Introduction to Functional Least Squares
117
leads, after some easy rearrangements, to
g(x) = const. exp

−1
2 (x −x0)t C −1
x
(x −x0)

(5.42)
with
x0 = L w0
and
Cx = L Cw Lt
.
(5.43)
This property can be used to generate a random realization of a Gaussian process with
prescribed covariance.
To simplify the discussion, assume that we wish to generate a
random realization x of a Gaussian process with zero mean and covariance Cx . It is quite
easy to generate a random realization w of a Gaussian process with zero mean and unit
covariance Cw = I (a random realization of a Gaussian white noise). Solve the equation
Cx = L Lt for L (using, for instance, the Cholesky decomposition of Cx ), and compute
x = L w . Then, x is a realization of a Gaussian process with zero mean and covariance
L Cw Lt = L Lt = Cx .
This method has the advantage of being conceptually simple. By no means is it more
efﬁcient numerically. For a review of some efﬁcient methods, including those working in
the Fourier domain, see Fenton (1994). Frankel and Clayton (1986) show some examples
of 2D random realizations of Gaussian ﬁelds (see Figure 5.8).
5.3.5
Weighting Operators and Least-Squares Norms
By deﬁnition, a covariance operator C is deﬁnite nonnegative and maps a linear vector
space ˆE into its (anti)dual E . If C is positive deﬁnite, then its inverse C−1 exists and
maps E into ˆE .
C−1 is named the weighting operator and is often denoted by W .
The expression
( e1 , e2 ) = et
1 C−1 e2
(5.44)
can be shown to deﬁne a scalar product over E (see equation (6.24)). The expression
∥e ∥= ( e , e )1/2 = (et C−1 e)1/2
(5.45)
then deﬁnes a norm over E . It is sometimes called an L2-norm, although this terminology
is improper (see Example 5.13). The name “least-squares norm” is more familiar, although
a proper terminology would be “covariance-related norm.”
A space E furnished with a scalar product is named a Hilbert space (in fact, it is only
a pre-Hilbert space because it is not necessarily complete (see (6.24)), but for all interesting
choices of covariance functions it will be (see, for instance, Example 5.13)).
Example 5.12. Let E be the space of all functions e = {e(t)} and let ˆe be an element of
ˆE , dual of E , related to an element e of E through
e = C ˆe
,
(5.46)
where C is a covariance operator over E with integral kernel (i.e., covariance function)
C(t, t′) :
e(t) =

dt′ C(t, t′) ˆe(t′)
.
(5.47)

118
Chapter 5. Functional Inverse Problems
By deﬁnition of the weighting operator C−1
,
ˆe = C−1 e
.
(5.48)
Formally, the integral kernel of the weighting operator C−1 can be introduced by
ˆe(t) =

dt′ C−1(t, t′) e(t′)
.
(5.49)
This gives the formal equation

dt

dt′ C(t, t′) C−1(t′, t′′) = δ(t −t′′)
.
(5.50)
In fact, usual covariance functions are smooth functions, and the linear operator deﬁned
by equations (5.46)–(5.48) is a true integral operator. Its inverse is then a differential
operator, and its integral representation (5.49) makes sense only if we interpret C−1(t, t′)
as a distribution (see Example 5.13). Nevertheless, by linguistic abuse, C−1(t, t′) is named
the weighting function.
Example 5.13. Let C(t, t′) be the covariance function considered in Example 5.5:
C(t, t′) = σ 2 exp

−|t −t′|
T

.
(5.51)
σ 2 is the variance of the random function; T is the correlation length and if the ran-
dom process is Gaussian, it corresponds to the length along which successive values of
any realization are correlated. The covariance operator C corresponding to the integral
kernel (5.51) with any function ˆe(t) associates the function
e(t) =
 t2
t1
dt′ C(t, t′) ˆe(t′)
.
(5.52)
As shown in Problem 7.21, we have
C−1(t, t′) =
1
2σ 2
 1
T δ(t −t′) −T δ′′(t −t′)

,
(5.53)
where the deﬁnition of the derivative of a distribution has been used.66 For the norm of an
element e , this gives (see Problem 7.21), disregarding possible boundary terms,
∥e ∥2 =
1
2 σ 2
 1
T
 t2
t1
dt [e(t)]2 + T
 t2
t1
dt
(de
dt (t)
)2
.
(5.54)
This corresponds to the usual norm in the Sobolev space H 1 (see Appendix 6.25), which
equals the sum of the usual L2-norm of the function and the L2-norm of its derivative. See
Problem 7.21 for details.
66In particular, for Dirac’s delta function,

dt′ δ(n)(t −t′) µ(t′) = (−1)n dn
dtn µ(t) .

5.4. Derivative and Transpose Operators in Functional Spaces
119
Example 5.14. For 0 ≤t ≤T , let C(t, t′) be the covariance function
C(t, t′) = β min(t, t′)
(5.55)
already considered in Example 5.9. The covariance operator C whose kernel is this co-
variance function associates with any function ˆe(t) the function
e(t) =
 L
0
dt′ C(t, t′) ˆe(t′)
.
(5.56)
As shown in Problem 7.22,
C−1(t, t′) = −1
β δ′′(t −t′)
.
(5.57)
For the norm of an element e = {e(t)} , this gives (see Problem 7.22)
∥e ∥2 = 1
β
 T
0
dt
de
dt (t)
2
,
(5.58)
that is, the ordinary L2-norm of the derivative of the function.
Example 5.15. The covariance function
C(t, t′) = w(t) δ(t −t′)
(5.59)
represents white noise (see Example 5.10). w(t) is termed the intensity of the white noise. It
is easy to see that if e(t) =

dt′ C(t, t′) δˆe(t′) , then ˆe(t) =
1
w(t) e(t) . This corresponds to
the kernel C−1(t, t′) =
1
w(t) δ(t −t′) . The associated norm is the usual weighted L2-norm
∥e ∥2 =

dt e(t)2
w(t)
.
(5.60)
5.4
Derivative and Transpose Operators in
Functional Spaces
5.4.1
The Derivative Operator
When a manifold X is considered that is not necessarily a linear space, endowed with some
coordinates x = {x1, x2, . . . } , with every point x0 ∈X one may associate a linear space
X0 , which is tangent to the manifold at the given point x0 . A generic vector of X0 may be
denoted δx . When such a vector δx = {δx1, δx2, . . . } is small enough, it can be interpreted
as the line going from point x0 = {x1
0, x2
0, . . . } to point x0+δx = {x1
0 +δx1, x2
0 +δx2, . . . } .
Let M and D respectively be the model parameter manifold and the observable
parameter manifold, not necessarily assumed to be linear spaces. The parameters {mα} and

120
Chapter 5. Functional Inverse Problems
{di} are interpreted as coordinates over the manifolds. Consider the (possibly nonlinear)
operator m →d = g(m) associating with any point m of the model space M a point
d = g(m) of the data space D . The tangent linear application to g at a point m = m0
is a linear operator, denoted G0 , that maps the linear tangent space to M at point m0
into the linear tangent space to D at point d0 = g(m0) , and is deﬁned by the ﬁrst-order
development
g(m0 + δm) = g(m0) + G0 δm + · · ·
.
(5.61)
When applied to a scalar function x →g(x) of a one-dimensional variable, this
expression deﬁnes the tangent (in the usual geometrical sense) to the graph (x, g(x)) at
x0 (see Figure 5.11), thus justifying the terminology. When M and/or D are functional
spaces, the tangent linear application G0 is usually named the Fréchet derivative (or simply
the derivative) of g at point m0 . Note that this terminology may be misleading, because
for a one-dimensional scalar function x →g(x) , what is generally termed the derivative
at a given point is the slope of the tangent (i.e., a number), not the tangent itself (i.e., an
application).
Example 5.16. If M and D are discrete,
di = gi(m1, m2, . . . )
(i = 1, 2, . . . )
.
(5.62)
From the deﬁnition (5.61), it follows that the kernel of the operator G0 is a matrix. Its
elements are
(G0)i
α =
∂gi
∂mα

m0
.
(5.63)
Figure5.11. Thetangentlinearapplicationtothe
nonlinear application y = g(x) at the point (x0, g(x0))
is the linear application whereby any δx is associated
with δy = G0δx , where G0 is the slope of the curve
y = g(x) at x0 . This deﬁnition generalizes to a non-
linear application y = g(x) between functional spaces
(see text). The kernel of the tangent linear application is
then called the Fréchet derivative or simply the derivative
at m0 .
y = g(x)
δy = G0 δx
( x0 , g(x0) )
δy
δx
Example 5.17. Let M be a space of functions z →m(z) for 0 ≤z ≤Z , D be a discrete
N -dimensional manifold, and m →g(m) be the nonlinear operator from M into D that
with the function z →m(z) associates the following element of D :
di = gi(m) =
 Z
0
dz βi(z) (m(z))2
(i = 1, 2, . . . , N)
,
(5.64)

5.4. Derivative and Transpose Operators in Functional Spaces
121
where βi(z) are given functions. If z →m0(z) is a particular element of M , denoted
m0 , let us compute the derivative of g at the point m0 . We have
gi(m0 + δm) =
 Z
0
dz βi(z) (m0(z) + δm(z))2
=
 Z
0
dz βi(z) ((m0(z))2 + 2 m0(z) δm(z) + (δm(z))2)
= gi(m0) + 2
 Z
0
dz βi(z) m0(z) δm(z) + · · ·
,
(5.65)
so, using the deﬁnition (5.61),
δdi = (G0 δm)i = 2
 Z
0
dz βi(z) m0(z) δm(z)
.
(5.66)
In words, the derivative at the point m = m0 of the nonlinear operator m →g(m) is the
linear operator that with any function δm (i.e., any function z →δm(z) ) associates the
vector given by (5.66). Introducing an integral representation of G0 ,
(G0 δm)i =
 Z
0
dz G0
i(z) δm(z)
,
(5.67)
gives the (integral) kernel of G0 :
G0
i(z) = 2 βi(z) m0(z)
.
(5.68)
Example 5.18. The Fréchet derivatives in X-ray tomography. A useful technique for
obtaining images of the interior of a human body is (computerized) X-ray tomography.
As the etymology of the word indicates, tomography consists of obtaining graphics of a
section of a body. Typically, X-rays are sent between a point source and a point receiver
that counts the number of photons not absorbed by the medium, thus giving an indication
of the integrated attenuation coefﬁcient along that particular ray path (see Figure 5.12).
Repeating the measurement for many different ray paths, conveniently sampling the medium,
the bidimensional structure of the attenuation coefﬁcient can be inferred, and so, an image
of the medium be obtained. Ray paths of X-rays through an animal body can be assimilated
to straight lines with an excellent approximation.
More precisely, let ρi be the transmittance along the ith ray, i.e., the probability of
a photon being transmitted (approximately equal to the ratio between the emitted and the
received intensity of the X-ray beam). It can be shown (see, for instance, Herman, 1980)
that ρi is given by
ρi = exp

−

Ri
ds µ(x)

,
(5.69)
where µ(x) is the linear attenuation coefﬁcient67 at point x , Ri denotes the ray path, dsi
is the element of length along the ray path, and x denotes the current point considered in
67The attenuation coefﬁcient so deﬁned is called ‘linear’ to distinguish it from the mass attenuation coef-
ﬁcient.
Typical values for medical diagnostic X-rays are µbone = 0.480 cm−1 , µmuscle = 0.180 cm−1 ,
µblood = 0.178 cm−1 .

122
Chapter 5. Functional Inverse Problems
Figure 5.12.
Schematic representation
of an X-ray tomography experiment.
Typically,
a source sends a beam of X-rays, and the num-
ber of photons arriving at each of the receivers is
counted. With a sufﬁcient accuracy, photons can
be assumed to propagate along straight lines. In
the example in the ﬁgure, source and receivers are
slowly rotating around the medium under study.
Each particular measurement of the number of
photons arriving at a source brings information
about the integrated attenuation along a particu-
lar line across the medium. When sufﬁciently many
integrated attenuations have been measured, with
sufﬁciently different azimuths, the bidimensional
structure of the attenuation coefﬁcient can be in-
ferred, thus obtaining a tomograph (i.e., an image
of a section of the 3D medium).
the line integral along Ri . In a three-dimensional experience, a point x is represented by
the Cartesian coordinates (x, y, z) or the spherical coordinates (r, θ, φ) .
We could take here as basic parameters the transmittances {ρi} and the linear at-
tenuation coefﬁcients {µ(x)} , but, as we have in view a least-squares formulation of the
inverse problem, it is better to change the variables, deﬁning the logarithmic transmittance
di and the logarithmic linear attenuation m(x) by
di = −log ρi
and
m(x) = log µ(x)
K
,
(5.70)
where K is an arbitrary constant value of the attenuation coefﬁcient. The reason for doing
so is that positive parameters may never have Gaussian statistics (that give ﬁnite probability
to negative values of the parameter). Then, rather than complicating the problem by the
explicit introduction of log-normal statistics, it is better to use the logarithmic parameters
just introduced.68 The relation (5.69) between data and unknowns transforms into
di = K

Ri
ds exp( m(x) )
,
(5.71)
an expression that, for more compactness, we can denote by d = g(m) , with d = {di}
and m = {m(x)} . Let m0 = {m0(x)} be a particular model and let us evaluate the
Fréchet derivative of g at point m0 . To implement here the deﬁnition given in equa-
tion (5.61), we successively write di(m0(x) + δm(x)) = K

Ri ds exp(m0(x) + δm(x)) =
K

Ri ds exp(m0(x)) exp(δm(x)) = K

Ri ds exp(m0(x)) (1 + δm(x) + · · · ) , i.e.,
di( m0(x) + δm(x) ) = di( m0(x) ) + K

Ri
ds exp( m0(x) ) δm(x) + · · ·
.
(5.72)
68It is here assumed that we are in the high attenuation regime, where the ρi are closer to zero than to one. In fact,
as ρ is a probability, it takes values in the range (0, 1) and one should deﬁne the new parameter π = ± log
ρ
(1−ρ) .

5.4. Derivative and Transpose Operators in Functional Spaces
123
Therefore, the tangent linear application to the nonlinear application in equation (5.71),
evaluated for m0 = {m0(x)} , is the linear application that with any model perturbation
δm = {δm(x)} associates the ‘data perturbation’
δdi = K

Ri
ds exp( m0(x) ) δm(x)
.
(5.73)
Writing this formally as
δd = G0 δm
(5.74)
allows us to formally introduce the integral kernel (Fréchet derivative) Gi
0(x) of the tangent
linear application G0 as
δdi =

V
dV (x) Gi
0(x) δm(x)
,
(5.75)
where V is the volume under investigation. Introducing a delta-like function F(x; Ri)
that is zero everywhere in the space except along the ith ray path by the condition that, for
any function ψ(x) ,

Ri
ds ψ(x) =

V
dV (x) F(x, Ri) ψ(x)
,
(5.76)
allows us to formally express the integral kernel Gi
0(x) as
Gi
0(x) = K exp( m0(x) ) F(x; Ri)
.
(5.77)
If, according to the deﬁnition at right in equation (5.70), we introduce m0(x) = log( µ0(x) /
K ) , then the kernel of G0 can be written Gi(x) = µ0(x) F(x; Ri) .
Example 5.19. The Fréchet derivatives in travel-time tomography. To infer the velocity
structure of a medium, acoustic waves are generated by some sources, and the travel times
to some receivers are measured. The main difference (and difﬁculty) with respect to the
problem of X-ray tomography is that some media are highly heterogeneous, and the ray
paths may depend on the velocity structure (see Figure 5.13).
Here we assume that the high-frequency limit is acceptable, i.e., ray theory can be
used instead of wave theory. Let c(x) denote the celerity of the waves at point x , and let
n(x) be the slowness. The ith datum is the travel time for the ith ray and is given by either
of the two equivalent expressions
di =

Ri(c)
ds
1
c(x) =

Ri(n)
ds n(x)
,
(5.78)
where Ri denotes the ith ray path (that depends on the celerity [or slowness] of the medium).
We wish the formulation of the problem to be independent of arbitrarily choosing the celerity

124
Chapter 5. Functional Inverse Problems
Figure 5.13. Typical experiment of travel-time tomography. A source of acoustic
waves is set at different positions, and, for each source position, some receivers are placed
around the medium, which record the time of arrival of the ﬁrst wavefront. The purpose of
the experiment is to infer the acoustic structure of the medium. This problem is very similar
to that of X-ray tomography, except that the ray paths are a priori unknown, because they
depend on the actual structure of the medium.
or the slowness, but this question is automatically solved when, for the reasons exposed in
Example 5.18, one introduces the logarithmic slowness (or, equivalently, the logarithmic
velocity69)
m(x) = log n(x)
K
,
(5.79)
where K is some constant value of the slowness. Then,
di = gi(m) = K

Ri(m)
ds exp( m(x) )
(5.80)
(written, for short, d = g(m) ). This expression has two nonlinearities in it, one due to the
exponential function and another due to the fact that the ray path depends on the function
m(x) . Given a medium m = {m(x)} , the actual ray path is obtained using Fermat’s
theorem (or, equivalently, the eikonal equation) and some numerical method. Here we wish
to obtain the derivative of the nonlinear operator g at a point m0 . We have
gi(m0 + δm) = K

Ri(m0+δm)
ds exp( m0(x) + δm(x) )
.
(5.81)
The travel time being stationary along the actual ray path (Fermat’s theorem),

Ri(m0+δm)
ds exp( m0(x) + δm(x) ) =

Ri(m0)
ds exp( m0(xi) + δm(xi) ) + O(∥δm∥2)
.
(5.82)
69The logarithmic velocity is just the opposite of the logarithmic slowness.

5.4. Derivative and Transpose Operators in Functional Spaces
125
We can then make a development very similar to that in Example 5.18 to arrive at
gi(m0 + δm) = gi(m0) + K

Ri(m0)
ds exp( m0(x) ) δm(x) + · · ·
,
(5.83)
which is very similar to equation (5.73), except that the ray path here depends on m0 .
Therefore, the tangent linear application to the application deﬁned by equation (5.80),
when evaluated at m0 = {m0(x)} , is the linear application that with every perturbation
δm(x) of the logarithmic slowness associates the travel-time perturbation
δdi = K

Ri(m0)
ds exp( m0(x) ) δm(x)
.
(5.84)
Equation (5.84) is well adapted to all numerical computations involving the derivative
operator G0 , but for analytic developments it is sometimes useful to introduce the kernel
of G0 (i.e., the Fréchet derivative). Introducing, as in the previous example, a delta-like
function F(x; Ri(m)) that is zero everywhere in the space except along the ith ray path
(this time, the ray path depends on the model m = {m(x)} ) by the condition that, for any
function ψ(x) ,

Ri(m)
ds ψ(x) =

V
dV (x) F(x, Ri(m)) ψ(x)
,
(5.85)
allows us to formally express the Fréchet derivative as
Gi
0(x) = K exp( m0(x) ) F(x; Ri(m0))
,
(5.86)
or, expressing this derivative in terms of the slowness, Gi
0(x) = n0(x) F(x; Ri(n0)) . See
Example 5.18 for details.
Example 5.20. The Fréchet derivatives in the problem of inversion of acoustic wave-
forms. Consider a three-dimensional unbounded medium supporting the propagation of
acoustic waves, assumed to propagate according to the wave equation
1
κ(x)
∂2p
∂t2 (x, t) −div

1
ρ(x) grad p(x, t)

= S(x, t)
,
(5.87)
where x denotes a point of the medium, t is time, p(x, t) is the pressure perturbation at
point x and time t , S(x, t) is the source function, and ρ(x) and κ(x) are respectively
the mass density and bulk modulus at point x . The pressure perturbation ﬁeld p(x, t) is
supposed to be at rest at the initial time:
p(x, 0) = 0
,
˙p(x, 0) = 0
.
(5.88)
Assume that we have complete control of the source S(x, t) , so that we can send into
the medium any type of wave we wish (usually the source has limited spatial extension and
we send quasi-spherical waves), and that we have some sensors that are able to measure
the actual value of the pressure at arbitrary points in the medium.

126
Chapter 5. Functional Inverse Problems
Figure 5.14. Typical waveform acoustic experiment: Pressure waves are gener-
ated by some source, they interact with the medium, and the total pressure ﬁeld is recorded
by some receivers. The problem is to infer the acoustic structure of the medium.
Assume we start an experiment at t
= 0 , sending waves into the medium by an
appropriate choice of the source function S(x, t) . From t = 0 to t = T , we record the
pressure perturbation at some (ﬁnite number of) points xr (r = 1, 2, . . . ) . We wish to
use the results of our measurements to infer the actual value of the functions κ(x) and
ρ(x) characterizing the medium (see Figure 5.14). This is, of course, an inverse problem,
and will be solved in the next sections. Let us ﬁrst consider the resolution of the forward
problem.
Our (linear) data space D consists of all conceivable realizations for the results of
our measurements:
d = { p(xr, t)
for
0 ≤t ≤T
and
r = 1, 2, . . . }
.
(5.89)
Assumethatweareonlyinterestedinthebulkmodulus κ(x) (thedevelopmentisquitesimilar
for the mass density). In the context of least squares, it is better to explicitly introduce the
logarithmic bulk modulus
m(x) = log K
κ(x) = −log κ(x)
K
,
(5.90)
where K is an arbitrary constant value of κ : in this way, a priori information on the
bulk modulus is easily introduced using Gaussian random functions (this would not be the
case for a positive parameter). Our (linear) model space M consists then of all possible
models m(x) .
The original differential system becomes
exp( m(x) )
K
∂2p
∂t2 (x, t) −div

1
ρ(x) grad p(x, t)

= S(x, t)
,
t ∈[0, T ]
,
p(x, 0) = 0
,
˙p(x, 0) = 0
.
(5.91)

5.4. Derivative and Transpose Operators in Functional Spaces
127
Given a model m , to solve the forward problem means to compute the data vector d
predicted from the knowledge of m . This is denoted by
d = g(m)
.
(5.92)
The most general way of solving the forward problem is to replace the differential equation
in (5.91) with its ﬁnite-difference approximation (see, for instance, Alterman and Karal,
1968) and to compute numerically the approximated values of the pressure perturbation at
time t + Ft from the knowledge of the approximated values of the pressure perturbation
at times t and t −Ft . This gives the pressure perturbation ﬁeld everywhere. The forward
problem is solved by just picking the values obtained at the receiver locations xr .
Let m0 denote a particular model.
We wish to compute the derivative of g at
m = m0 . By deﬁnition,
g(m0 + δm) = g(m0) + G0 δm + O(∥δm ∥2)
.
(5.93)
Let us denote
δp = G0 δm
.
(5.94)
As demonstrated in Problem 7.18, δp(xr, t) is the value at xr and time t of the ﬁeld
δp(x, t) , solution of
exp( m0(x) )
K
∂2δp
∂t2 (x, t) −div

1
ρ(x) grad δp(x, t)

= −∂2p0
∂t2 (x, t) exp( m0(x) )
K
δm(x)
,
t ∈[0, T ]
,
δp(x, 0) = 0
,
δ ˙p(x, 0) = 0
,
(5.95)
where p0(x, t) is the ﬁeld propagating in the model m0 :
exp( m0(x) )
K
∂2p0
∂t2 (x, t) −div

1
ρ(x) grad p0(x, t)

= S(x, t)
,
t ∈[0, T ]
,
p0(x, 0) = 0
,
˙p0(x, 0) = 0
.
(5.96)
To compute δp(x, t) , we then essentially need to solve a forward problem (and we
have already seen how to do this) using −∂2p0
∂t2
exp m0
K
δm as source term and propagating
the waves in the unperturbed medium m0(x) . If we are able to compute δp(x, t) , then
from (5.94) we know the derivative operator G0 . In words, G0 is the linear operator
that associates the values δp(xr, t) , obtained by the resolution of (5.95), with the model
perturbation δm(x) .
Let me point out here that to estimate data g(m0 + δm) using the ﬁrst-order approx-
imation
g(m0 + δm) ≃g(m0) + G0 δm
(5.97)

128
Chapter 5. Functional Inverse Problems
corresponds to Born’s approximation. We are not using Born’s approximation here. We are
performing an exact evaluation of the Fréchet derivative.
As shown in Problem 7.18, the kernel G0(xr, t; x) introduced by the integral repre-
sentation
δp(xr, t) =

V
dV (x) G0(xr, t; x) δm(x)
(5.98)
is given by (special case of equation (7.239))
G0(xr, t; x) = −exp( m0(x) )
K
I0(xr, t; x, 0) ∗∂2p0
∂t2 (x, t)
,
(5.99)
where I0(x, t; x′, 0) is Green’s function, deﬁned as the solution of
exp( exp m0(x) )
K
∂2I0
∂t2 (x, t; x′, t′) −div

1
ρ(x) grad I0(x, t; x′, t′)

= δ(x −x′)(t −t′)
,
I0(x, t; x′, t′) = 0
for t < t′
,
∂I0
∂t (x, t; x′, t′) = 0
for t < t′
.
(5.100)
5.4.2
The Transpose Operator
Let G represent a linear operator from a linear space M into a linear space D . Its transpose,
Gt , is a linear operator mapping ˆD (the dual of D ) into ˆM (the dual of M ), deﬁned by
⟨Gt ˆd , m ⟩M = ⟨ˆd , G m ⟩D
(for any ˆd and m)
.
(5.101)
The reader should refer to Appendix 6.14 for (important) details.
Notice that the transpose of a linear operator is deﬁned independently of any particular
choice of scalar products over M and D .
Again, let G represent a linear operator from a linear space M into a linear space
D , and assume now that M and D are scalar product vector spaces with respective scalar
products
( m1 , m2 )M = ⟨C−1
M m1 , m2 ⟩M
,
( d1 , d2 )M = ⟨C−1
D d1 , d2 ⟩D
.
(5.102)
The adjoint of G , G∗, is a linear operator mapping D into M deﬁned by the equality of
scalar products
( G∗d , m )M = ( d , G m )D
(for any d and m)
.
(5.103)
As one can successively write
( G∗d , m )M = ( d , G m )D = ⟨C−1
D d , G m ⟩D
= ⟨Gt C−1
D d , m ⟩M = ( CM Gt C−1
D d , m )M
,
(5.104)

5.4. Derivative and Transpose Operators in Functional Spaces
129
one has the following relation between adjoint and transpose:
G∗= CM Gt C−1
D
.
(5.105)
By linguistic abuse, the terms adjoint and transpose are sometimes used as synonym. This
equation shows that they are not.
Let us see some examples practically illustrating the operational aspects of the deﬁ-
nition of the transpose of a linear operator. In discrete spaces, a linear equation
d1 = G m1
(5.106)
is explicitly written
(d1)i =

α
(G)i
α (m1)α
,
(5.107)
and the array Giα is termed the kernel of G . If the indexes i and α are simple integers,
then the array Giα is a usual (two-dimensional) matrix. A linear equation
ˆm2 = Gt ˆd2
(5.108)
is explicitly written
(m2)α =

i
(Gt)α
i (d2)i
,
(5.109)
and the deﬁnition (5.101) gives directly
(Gt)α
i = (G)i
α
,
(5.110)
which simply shows that the kernel of an operator and the kernel of the corresponding
transpose operator are essentially the same, modulo a ‘transposition’ of the variables. In
particular, if the kernel of the linear operator G is a matrix, the kernel of the transpose
operator is simply the transpose of the matrix. If we consider more general spaces, a linear
equation d1 = G m1 may take, for instance, the explicit form
(d1)ij...(u, v, . . . )
=

α

β
· · ·

dx

dy · · ·
(G)ij...
αβ...(u, v, . . . , x, y, . . . ) (m1)αβ...(x, y, . . . )
.
(5.111)
A linear equation ˆm2 = Gt ˆd2 is then explicitly written
( ˆm2)αβ...(x, y, . . . )
=

i

j
· · ·

du

dv · · · (Gt)αβ...
ij...(x, y, . . . , u, v, . . . ) (ˆd2)ij...(u, v, . . . )
,
(5.112)

130
Chapter 5. Functional Inverse Problems
and the deﬁnition of Gt then gives
(Gt)αβ...
ij...(x, y, . . . , u, v, . . . ) = Gij...
αβ...(u, v, . . . , x, y, . . . )
,
(5.113)
thus generalizing the notion of “variable transposition.” In words, if the kernel of a linear
operator is Gij...αβ...(u, v, . . . , x, y, . . . ) , and the application of G implies sums (or in-
tegrals) over the variables α, β, . . . , x, y, . . . , then the kernel of the transpose operator
is essentially the same, and the application of Gt implies sums over the other variables
i, j, . . . , u, v, . . . .
Asafurtherexample, considertheoperator G mappingthespace M intothespace D .
Gt then maps ˆD into ˆM . If C is a covariance operator over M , it maps ˆM into M , and
it makes sense to consider the operator
U = C Gt
(5.114)
mapping ˆD into M . Let Gij...αβ...(u, v, . . . , x, y, . . . ) and Cαβ...α′β′...(x, y, . . . , x′, y′, . . . )
be respectively the kernels of G and C . As can easily be veriﬁed, the kernel of U is then
U αβ...ij...(x, y . . . u, v, . . . ) =

α′

β′
· · ·

dx′

dy′. . .
(5.115)
× Cαβ...α′β′...(x, y, . . . , x′, y′, . . . ) Gij...
α′β′...(u, v, . . . , x′, y′, . . . )
.
In inverse problems, we always have to consider the forward equation d = g(m)
and the operator Gn , the derivative of g at some point mn . In all the formulas for least-
squares inversion, the transpose operator Gt
n appears (see next section), and, when using
gradient methods of resolution, is in fact an iterative application of Gt
n to the residuals,
which performs the data inversion (see chapter 3). The understanding of the meaning of
the transpose of a linear operator is very important for functional inverse problems. In
particular, it is important to understand that to compute a vector Gt d it is not necessary to
explicitly use the kernel of G (see Example 5.22 below).
Example 5.21. The derivative operator is antisymmetric. Let E be a space of functions
e1(t) , e2(t) , . . . , the variable t running in the interval (0, T ) , and let F be the dual of E ,
i.e., a space of functions f1(t) , f2(t) , . . . , with the variable t also running in the interval
(0, T ) , and such that for any function e ∈E and any function f ∈F the duality product
⟨f , e ⟩E = ⟨e , f ⟩F =
 T
0
dt f (t) e(t) =
 T
0
dt e(t) f (t)
(5.116)
makes sense. Let D be the derivative operator over the functions of E , i.e., the operator
that with any function e ∈E associates its derivative:
e′(t) = (D e)(t) = de
dt (t)
.
(5.117)
The transpose of D is the operator Dt deﬁned by the condition that, for any two functions
(equation (5.101)),
⟨Dt f , e ⟩E = ⟨f , D e ⟩F
.
(5.118)

5.4. Derivative and Transpose Operators in Functional Spaces
131
This condition gives

 T
0 dt (Dt f)(t) e(t) =

 T
0 dt f (t) de
dt (t) , and an integration by parts
shows that, provided that the functions satisfy the dual boundary conditions
f (T ) e(T ) = f (0) e(0)
,
(5.119)
one has (Dt f)(t) = −df
dt (t) , i.e., for short,
Dt = −D
,
(5.120)
showing that the derivative operator is antisymmetric (provided that the dual boundary
conditions in equation (5.119) are satisﬁed). Assume, for instance, that the functions in E
satisfy the initial boundary condition e(0) = 0 . Then, the functions in F must satisfy the
ﬁnal boundary condition f (T ) = 0 . If instead of the derivative operator one considers the
second derivative operator D2 , one easily sees that it is symmetric,
(D2)t = D2
,
(5.121)
and that, for a simple example, dual boundary conditions for the second derivative oper-
ator are initial conditions of rest for the functions in E , e(0) =
de
dt (0) = 0 , and ﬁnal
conditions of rest for the functions in F , f (T ) = df
dt (T ) = 0 . The existence of these dual
boundary conditions for the derivative operators contrasts with discrete (ﬁnite-difference)
formulations, where the transpose of a matrix is deﬁned unconditionally, but, as shown in
Appendix 6.28, a careful introduction of these matrix operators does produce boundary
conditions.
Example 5.22. The transpose operator in X-ray tomography. We wish here to obtain
the transpose of the linear operator G0 obtained in the problem of X-ray tomography
(Example 5.18). We have (equation (5.73))
δdi = (G0 δm)i = K

Ri
ds exp( m0(x) ) δm(x)
.
(5.122)
The deﬁnition of transpose (equation (5.101)),
⟨Gt
0 δ ˆd , δm ⟩M = ⟨δ ˆd , G0 δm ⟩D
,
(5.123)
is here written, explicitly,

V
dV (x) (Gt
0 δ ˆd)(x) δm(x) = K

i
δ ˆdi

Ri
ds exp( m0(x) ) δm(x)
.
(5.124)
We will see later (Problem 7.18) that this expression characterizes the transpose operator
sufﬁciently well for practical computations in inversion. But let us try here to obtain a
more compact representation. Using the delta-like function F(x; Ri) introduced in equa-
tion (5.85), equation (5.124) can be rewritten

V
dV (x) δm(x)

(Gt
0 δ ˆd )(x) −K

i
δ ˆdi F(x; Ri) exp( m0(x) )

= 0
,
(5.125)

132
Chapter 5. Functional Inverse Problems
and, this being satisﬁed for any δm , it follows that an expression like
δ ˆm = Gt
0 δ ˆd
(5.126)
corresponds to the explicit expression
δ ˆm(x) = K

i
δ ˆdi F(x; Ri) exp( m0(x) )
.
(5.127)
Notice that this last result could also be obtained directly from the knowledge of the
kernel of G0 (given in equation (5.77)) and the rule of variable transposition.
Example 5.23. The transpose operator in waveform inversion. In this example, we wish
to obtain the transpose of the operator G0 appearing in the problem of inversion of pressure
waveforms (Example 5.19). The kernel of G0 was (equation (5.99))
G0(xr, t; x) = −exp( m0(x) )
K
I0(xr, t; x, 0) ∗∂2p0
∂t2 (x, t)
.
(5.128)
A linear equation
δd = G0 δm
(5.129)
is written explicitly
δd(xr, t) =

V
dV (x) G0(xr, t, x) δm(x)
,
(5.130)
while an equation (not directly related to equation (5.129))
δ ˆm = Gt
0 δ ˆd
(5.131)
involving Gt
0 is written explicitly
δ ˆm(x) =

r
 T
0
dt Gt
0(x, xr, t) δ ˆp(xr, t)
(5.132)
(receiver positions are assumed discrete). Using the rule that an operator and its transpose
have the same kernels,
δ ˆm(x) =

r
 T
0
dt G0(xr, t, x) δ ˆp(xr, t)
.
(5.133)
As shown in Problem 7.18, this ﬁnally gives (equation (7.255))
δ ˆm(x) = (Gt
0 δ ˆp)(x) = −exp( m0(x) )
K
 T
0
dt ˙p0(x, t) ˙80(x, t)
,
(5.134)

5.5. General Least-Squares Inversion
133
where 80(x, t) is the ﬁeld deﬁned by
exp( m0(x) )
K
∂280
∂t2 (x, t) −div

1
ρ(x) grad80(x, t)

=

r
δ(x −xr) δ ˆp(xr, t)
,
80(x, T ) = 0
,
˙80(x, T ) = 0
,
(5.135)
where it should be noticed that there are ﬁnal (instead of initial) conditions.
We see thus that to evaluate the action of the operator Gt
0 over δ ˆp , we ﬁrst have to
solve the propagation problem deﬁned in equations (5.135) reversed in time, then compute
the time correlation expressed in equation (5.134).
5.5
General Least-Squares Inversion
5.5.1
Linear Problems
I start by recalling some results from chapter 3 for ﬁnite-dimensional problems. Assume
that the forward problem is (exactly) solved by the linear equation
d = G m
,
(5.136)
that the results of the observations are described by a Gaussian probability with mean dobs
and covariance operator CD , and that the a priori information is described by a Gaussian
probability with mean mprior and covariance operator CM . Then, the posterior probability
in the model space is also Gaussian, with mean
m = mprior + (Gt C−1
D G + C−1
M )−1 Gt C−1
D (dobs −G mprior)
= mprior + CM Gt (G CM Gt + CD)−1 (dobs −G mprior)
(5.137)
and covariance operator
CM = (Gt C−1
D G + C−1
M )−1
= CM −CM Gt (G CM Gt + CD)−1 G CM
.
(5.138)
Using the arguments of either Franklin (1970) or Backus (1970 a, b, c), it can be shown
that this result remains true for inﬁnite-dimensional problems: if priors are Gaussian and
the forward equation is linear, the posterior is Gaussian, with mean and covariance operator
as given above. This result shows that, when using adequate notation, the results obtained in
chapter 3 are valid in a much more general context (i.e., the context of functional analysis).
The major difference between ﬁnite- and inﬁnite-dimensional problems is that in
the ﬁnite-dimensional case, probability densities can be introduced, while they cannot be
introduced, as such, in the inﬁnite-dimensional case (although the notion of a Gaussian
random function is perfectly deﬁned [see Example 5.1]).

134
Chapter 5. Functional Inverse Problems
5.5.2
The Misﬁt
Consider, for an n-dimensional variable x = {x1, . . . , xn} , the discrete n-dimensional
Gaussian
f (x) = ( (2π)n det C )−1/2 exp

−1
2 (x −x0)t C −1 (x −x0)

.
(5.139)
If x is a random realization of f (x) , the random variable
χ2 = ∥x −x0 ∥2 = (x −x0)t C−1 (x −x0)
(5.140)
has a χ2 distribution (see Appendix 6.8), and its expected value is n . Clearly, when
n →∞, this expected value diverges, so the expected value of the distance between a
realization x of a Gaussian random function and its mean x0 is inﬁnite.
Nevertheless, we have seen in section 3.3.4 that, within the context of discrete least
squares, the expected value of the misﬁt
2 S(m) = (G m −dobs)t C −1
D
(G m −dobs) + (m −mprior)t C −1
M (m −mprior) (5.141)
equals the dimension of the data space D . So, in the case where the data vector d is
discrete, d = {d1, . . . , dn} , the expected value of the misﬁt S is ﬁnite, even in the case
where the model space M is inﬁnite dimensional.
In this case, it is clear that the solution given in equations (5.137) can be interpreted
as the solution of a minimization problem over an inﬁnite-dimensional linear space. Many
functional inverse problems are in this category.
If the data space is also a functional space (i.e., it is inﬁnite dimensional), then the
misﬁt expression (5.141) is purely formal, but the solution in equations (5.137)–(5.138)
still keeps its sense as deﬁning the mean function and the covariance function of a Gaussian
random function.
Example 5.24. Functional linear problem with discrete data. Assume that the medium
under study is described by a model function m(x) of the space coordinates. We are told
that the actual medium is a random realization of a Gaussian random function with mean
mprior(x) and covariance CM(x, x′) . We are able to measure some linear functionals of
the model,
di =

dV (x) Gi(x) m(x)
,
(5.142)
and we obtain the values di
obs , with uncertainties described by the covariance matrix Cij
D .
When using abstract notation, a model function m(x) is denoted m ; the center of the prior
Gaussian, mprior(x) , is denoted mprior ; and the covariance operator whose kernel is the
covariance function CM(x, x′) is denoted CM . The linear relation (5.142) is written, for
short, d = G m ; the vector of observed values is denoted dobs ; and the covariance matrix
representing the uncertainties is denoted CD . The center of the posterior Gaussian is then
expressed by the second of equations (5.137), and the covariance of the posterior Gaussian
is expressed by the second of equations (5.138). Let us write this using explicit notation
(involving the kernels). First, introducing the matrix S = G CM Gt + CD , one has
Sij =

dV (x)

dV (x′) Gi(x) CM(x, x′) Gj(x′) + Cij
D
.
(5.143)

5.5. General Least-Squares Inversion
135
Then, introducing the inverse matrix
T = S−1
(5.144)
allowsustowritethecenteroftheposteriorGaussianﬁeld, m = mprior+CM Gt (G CM Gt+
CD)−1 (dobs −G mprior) , as

m(x) = mprior(x) +

dV (x′) CM(x, x′) ψ(x′)
,
(5.145)
where the function ψ(x) is deﬁned as ψ(x) = 
i Gi(x) δ ˆdi , the weighted data residuals
δ ˆdi are deﬁned as δ ˆdi = 
j Tij δdj , and the data residuals δdi are deﬁned as δdi =
di
obs −

dV (x) Gi(x) mprior(x) . The covariance function of the posterior Gaussian ﬁeld,
CM = CM −CM Gt (G CM Gt + CD)−1 G CM , is explicitly given by

CM(x, x′) = CM(x, x′) −

i

j
8i(x) Tij 8j(x′)
,
(5.146)
where the functions 8i(x) are deﬁned as 8i(x) =

dV (x′) CM(x, x′) Gi(x′) . To under-
stand this solution, one may carefully examine the posterior mean 
m(x) and the posterior
covariance 
CM(x, x′) , or, much better, one may examine some (pseudo)random realiza-
tions of the (posterior) Gaussian random ﬁeld whose mean function is 
m(x) and whose
covariance function is 
CM(x, x′) .
The previous example corresponds, in fact, to my preferred alternative to the Backus
and Gilbert approach (see Appendix 6.16) for solving linear inverse problems.
Example 5.25. Gaussian sequential simulation. Assume that we have the a priori infor-
mation that the system under investigation is a particular realization m(x) of a Gaussian
random ﬁeld with mean mprior(x) and covariance CM(x, x′) . We then have been able to
obtain some additional data in the form of the values of m(x) at some selected points
{x1, x2, . . . } . We can write these data as
di = m(xi)
.
(5.147)
The actual measurements have provided the observed values di
obs , with uncertainties de-
scribed by the covariance matrix Cij
D . As the problem is linear, the posterior random ﬁeld is
also Gaussian, and we are going to evaluate its mean and covariance. The relation (5.147)
can be written
di =

dV (x) Gi(x) m(x)
with
Gi(x) = δ(x −xi)
,
(5.148)
introducing the kernel Gi(x) of the linear operator mapping the model into the data space.
The mean of the posterior Gaussian, as given by expression (5.145), here becomes

m(x) = mprior(x) +

i
CM(x, xi) δ ˆdi
,
(5.149)

136
Chapter 5. Functional Inverse Problems
where the weighted data residuals δ ˆdi are deﬁned as δ ˆdi = 
j Tij δdj , and the data
residuals δdi are given by δdi = di
obs −mprior(xi) . The matrix Tij is the inverse of
the matrix Sij introduced in equation (5.143), which here takes the simple expression
Sij = CM(xi, xj) + Cij
D . The covariance function of the posterior Gaussian ﬁeld, as given
by expression (5.150), becomes

CM(x, x′) = CM(x, x′) −

i

j
CM(x, xi) Tij CM(xj, x′)
.
(5.150)
Given this mean and this covariance of the posterior Gaussian random ﬁeld, one can
generate some (pseudo)random realizations of it, to well apprehend the characteristics of
the random ﬁeld. In the ﬁeld of geostatistics, an efﬁcient technique has been developed
(the Gaussian sequential simulation) to generate samples of this posterior random ﬁeld
(Goovaerts, 1997; Deutsch and Journel, 1998). The basic idea is to write the mean and the
covariance at a particular point, say xa , giving 
m(xa) = mprior(xa) + 
i CM(xa, xi) δ ˆdi
and 
CM(xa, xa) = CM(xa, xa) −
i

j CM(xa, xi) Tij CM(xj, xa) . A (pseudo)random
value m(xa) is then generated from a one-dimensional Gaussian that has this mean and this
covariance. This value is then considered as one additional datum,70 the equations (5.149)–
(5.150) are rewritten with the inclusion of this new datum, and a new value of the random
ﬁeld is generated at some other point, say xb . The iteration of this procedure will produce
values in as many points as we may wish. We then have a realization of the posterior
random ﬁeld. In the Gaussian sequential simulation technique, one is only interested in
obtaining approximate samples, and, therefore, one uses the simpliﬁcation, when generating
a (pseudo)random value at some point xa , of disregarding the data points that are far
from xa (two points x and x′ are far if the covariance CM(x, x′) is negligible). This
approximation keeps the size of the matrix Sij small. Although the point of view used in
geostatistics differs from that used here, it can be demonstrated that the mathematics is
equivalent. Figure 2.5 (page 46) shows an example of Gaussian sequential simulation.
5.5.3
Nonlinear Problems
Let us now turn to the case where the equation solving the forward problem d = g(m) is
nonlinear. If the equation is linearizable around mprior , then, as we have seen in chapter 3,
the techniques to be used are those used for linear problems. If the equation is actually
nonlinear (as explained in section 3.2.1, in the context of least squares) we only consider
mild nonlinearities.
For discrete problems, we have seen in chapter 3 that if the results of the observations
can be described by a Gaussian probability with mean vector dobs and covariance matrix
CD , the a priori information can be described by a Gaussian probability with mean vector
mprior and covariance matrix CM , and if the equation solving the forward problem is quasi
linear in the region of the model space with signiﬁcant a posteriori probability, then the a
posteriori probability in the model space is approximately Gaussian. The mean m of the
70If the value is generated with enough numerical precision, this is an error-free datum, i.e., the variance
associated with it in the matrix Cij
D is zero.

5.5. General Least-Squares Inversion
137
approximated Gaussian probability minimizes the misﬁt function
2 S(m) = ∥g(m) −dobs ∥2
D + ∥m −mprior ∥2
M
= (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior)
(5.151)
and can be obtained using an iterative process (basically, a gradient-based method of mini-
mization, like the quasi-Newton Algorithm (3.51) of the steepest descent Algorithm (3.89)).
The covariance matrix of the approximated Gaussian probability is given by
CM = (Gt
∞C−1
D G∞+ C−1
M )−1
= CM −CM Gt
∞(G∞CM Gt
∞+ CD)−1 G∞CM
,
(5.152)
where G∞denotes the derivative of the operator g at the convergence point m = m∞.
With the deﬁnitions and notation introduced in this chapter, almost all the equations
developed in chapter 3 for discrete problems make sense for functional problems. Excluding
perhaps some pathological situation, we do not need to develop the optimization algorithms
again: as the examples below show, we can directly use those developed in chapter 3.
5.5.4
Comments for Functional Problems
A question arising in the practical resolution of functional least-squares problems concerns
the operational signiﬁcance of the resolution of a linear equation. Let, for instance, δd be
a vector of data residuals. In least-squares computations, one often needs to evaluate the
weighted residuals
δ ˆd = C−1 δd
.
(5.153)
Sometimes, the covariance operator C corresponds to some simple probabilistic model,
and its inverse C−1 is known analytically (see Example 5.13 for the one-dimensional
exponential covariance, Problem 7.23 for the three-dimensional exponential covariance,
and Example 5.14 for the covariance of a one-dimensional random walk). If this is not the
case, then one can rewrite the equation as
C δ ˆd = δd
(5.154)
and solve this equation for δ ˆd using an iterative algorithm. For instance, one may use the
algorithm
δ ˆdn+1 = δ ˆdn + Q (δd −C δ ˆdn)
,
(5.155)
where Q is an arbitrary operator suitably chosen to accelerate convergence. Usually, a
good choice for Q is a diagonal operator proportional to the inverse of the variances in
C . Equation (5.155) shows that, for numerical computations, we do not explicitly need
to introduce the inverse of the operator C . Usually, a covariance operator is an integral
operator, and computing C δ ˆdn implies some numerical method, such as, for instance,
a Runge–Kutta method. Of course, any numerical method will imply a discretization of

138
Chapter 5. Functional Inverse Problems
the working space (here the data space), but it is important to realize that to discretize
the working space does not imply considering the operator C as a matrix and effectively
building the matrix in the computer’s memory (for problems other than academic this would
be practically impossible).
Another problem arising in functional least squares is the computation of
δ ˆm = Gt δ ˆd
,
(5.156)
where δ ˆd is a weighted data vector, G is a linear operator from the model into the data
space, and Gt is its transpose. We have seen in section 5.4.2 that the abstract deﬁnition
of the transpose operator leads to a physical understanding of the computations to be per-
formed: back-projection of the weighted residuals in an X-ray tomography problem, and
back-propagation of the weighted residuals plus a time correlation with the current predicted
ﬁeld in a problem of inversion of acoustic waveforms. Again, to perform these operations
numerically, some discretization of the working spaces has to be used, but the naive ap-
proach consisting of introducing a matrix representing the discretized version of G , and
interpreting (5.156) as a matrix multiplication equation, not only may destroy the physical
interpretation but forces us to effectively compute the elements of the matrix G , which is
usually prohibitive because it takes too much computer time.
5.5.5
Analysis of Uncertainties
As the least-squares method provides the posterior covariance operator in the model space,
CM , it is the analysis of CM that helps us understand the actual information that the data
has provided on the model m .
There are many ways to use the posterior covariance operator. For instance, in least-
squares problems, we start describing the a priori information on the model space assuming a
Gaussian distribution with mean mprior and covariance CM . At this level (before the inverse
problem is solved), I strongly recommend generating a few pseudorandom realizations of
such a Gaussian process (Figures 5.1, 5.6, and 5.7 are examples of this). One must verify
that the models so obtained are actually representative of the kind of a priori information
one intends to introduce. Then, one turns to the posterior Gaussian, whose center is the
‘posterior model’ m (given, for linear problems, by the explicit expression (5.137), or
obtained, for nonlinear problems, through the minimization of the misﬁt in equation (5.151))
with ‘posterior covariance’ CM (equations (5.138) and (5.152)). The generation of a large
enough collection of models of this posterior Gaussian (and subsequent comparison with the
collection obtained using the prior Gaussian) usually provides a very good understanding
of the ‘features’ of the model that are well ‘resolved’ by the data (if any).
In fact, what I suggest here is to use for the Gaussian case exactly the point of view
proposed in chapter 2 for a general Monte Carlo method. It is not because the probability
distributions are Gaussian (or approximately Gaussian) here that the ‘movie philosophy’
proposed in chapter 2 loses its interest.
It remains that a direct look at the posterior covariance function itself provides useful
information. To ﬁx ideas, assume here that we examine a problem where the model pa-
rameter is a scalar function of the spatial coordinates, x →m(x) , where x is a point in
the physical 3D space. The reader will easily generalize to the case where we need more

5.5. General Least-Squares Inversion
139
than one function to describe the model (as is, for instance, the case in the elastodynamic
waveform inversion of Problem 5.8). The kernel of the posterior covariance operator is then
a single covariance function 
CM(x, x′) . What information do we have on the true value of
the parameter m at a particular point x ? As the a posteriori probability is (approximately)
Gaussian, the marginal probability for the parameter m(x) is also Gaussian. The corre-
sponding Gaussian probability density is centered at 
m(x) , and the standard deviation is
σ(x) =


CM(x, x)
.
(5.157)
If we compute σ(x) for all points x , we may plot the estimated uncertainty σ(x) together
with the solution 
m(x) (see Figure 5.17 for an example). Better than plotting covariance
values is to remember that the posterior correlation between point x and point x′ is de-
ﬁned as
ρ(x, x′) =

CM(x, x′)
σ(x)σ(x′)
,
(5.158)
the correlation being a real number between −1 and 1. These are the correlations between
the posterior uncertainties at the two points. For a few selected positions x1 , x2 , . . . , the
correlations ρ(xi, x) can be graphically represented (this is done in the example shown in
Figure 5.17).
Sometimes, one may not be interested in the uncertainty on the a posteriori value of
the parameter m at a given point x0 , but rather in the uncertainty on the mean value of the
parameter over a given ball71 around x0 ,
ˆm(x0) =

V
dV (x) D(x0, x) 
m(x)
,
(5.159)
or, for short,
ˆm = D m
.
(5.160)
Using the deﬁnition of covariance, it follows that
ˆCM = D CM Dt
,
(5.161)
i.e., ˆCM(x, x′) =

V dV (x′′)

V dV (x′′′) D(x, x′′) 
CM(x′′, x′′′) D(x′, x′′′) . The uncertainty
on the value ˆm(x0) is then ˆσ(x0) = ( ˆCM(x0, x0))1/2 .
To conclude, let me recall that the ‘resolution’ operator, discussed in section 3.3.2,
was given by (equation (3.63))
R = I −CM C−1
M
.
(5.162)
As discussed by Backus and Gilbert (1968), the resolution operator can be interpreted as a
ﬁlter (see the comments in section 3.3.2). Instead of representing the posterior correlation
ρ(x, x′) (deﬁned in equation (5.158)), one may prefer to represent the resolution R(x, x′) .
71In functional inverse problems, it may well happen that the posterior variance at a given point is identical to
the prior variance, and the gain of information is only seen when computing average values over well-chosen balls.

140
Chapter 5. Functional Inverse Problems
5.6
Example: X-Ray Tomography as an Inverse Problem
This problem was introduced in Examples 5.18 and 5.23. As data, we have chosen to use,
instead of the transmittances {ρi} , the logarithmic transmittances di = −log ρi , and, as
parameters, instead of the linear attenuation coefﬁcient {µ(x)} , we have chosen to use the
logarithmic linear attenuation m(x) = log µ(x)
K , where K is an arbitrary constant value of
the attenuation coefﬁcient. We arrived at the following relation between data and parameters
(equation (5.71)):
di = K

Ri
ds exp( m(x) )
,
(5.163)
an expression that we can write d = g(m) , with d = {di} and m = {m(x)} .
Let di
obs (i = 1, 2, . . . ) be the observed data and Cij
D be the elements of the co-
variance matrix describing experimental uncertainties. Also, let us assume that the a priori
information we have on the actual model is represented by a Gaussian random ﬁeld72 with
mean mprior(x) and covariance function CM(x, x′) .
We have seen that with these assumptions, the posterior distribution is (as this problem
is only weakly nonlinear) approximately that of a Gaussian random ﬁeld whose center is
obtained through the minimization of the least-squares misﬁt function (equation (3.32))
2 S(m) = ∥g(m) −dobs ∥2
D + ∥m −mprior ∥2
M
= (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior) .
(5.164)
The covariance function of this posterior Gaussian ﬁeld is to be analyzed below.
Let us ﬁrst see what a simple steepest descent algorithm would do to solve this mini-
mization problem. We obtained, in equation (3.89),
mn+1 = mn −εn ( CM Gt
n C−1
D (g(mn) −dobs) + (mn −mprior) )
,
(5.165)
where Gn is the derivative operator evaluated at the current point mn and Gt
n is its trans-
pose. The real numbers εn are chosen ad hoc (as large as possible to accelerate convergence
but small enough to avoid divergence).
Splitting the algorithm into its basic computations gives
dn = g(mn)
,
(5.166)
δdn = dn −dobs
,
(5.167)
δ ˆdn = C−1
D δdn
,
(5.168)
δ ˆmn = Gt
n δ ˆdn
,
(5.169)
δmn = CM δ ˆmn
,
(5.170)
mn+1 = mn −εn (δmn + mn −mprior)
.
(5.171)
Let us make explicit each of these computational steps.
72Regardless of the physical goodness of this assumption, it makes, at least, mathematical sense, as we have
transformed the initial positive parameter (the attenuation coefﬁcient) into its logarithm.

5.6. Example: X-Ray Tomography as an Inverse Problem
141
Equation(5.166)correspondstotheresolutionoftheforwardproblem(equation(5.163))
corresponding to the current medium mn ,
di
n = K

Ri
ds exp( mn(x) )
.
(5.172)
Equation (5.167) corresponds to the computation of the data residuals
δdi
n = di
n −di
obs
.
(5.173)
Equation (5.168) corresponds to the computation of the weighted data residuals (δ ˆdn)i =
(C−1
D )ij (δdn)j . This is typically done by solving the linear system
(CD)ij (δ ˆdn)j = (δdn)i
→
δ ˆdn
.
(5.174)
Equation (5.169) corresponds to applying the operator Gt
n to the weighted data residuals
δ ˆdn . Using the result demonstrated in equations (5.126)–(5.127), this corresponds to
δ ˆmn(x) = K 
i δ ˆdi
n F(x; Ri) exp(mn(x)) . Thisexpressionisnottobeevaluated; instead
it is to be used as an input to the next computation. For, using this result, equation (5.170)
can be written δmn(x) =

V dV (x′) CM(x, x′) δ ˆmn(x) = K

V dV (x′) CM(x, x′) 
i δ ˆdi
n
F(x; Ri) exp(mn(x)) , δmn(x) = K
i δ ˆdi
n

V dV (x′) CM(x, x′) F(x′; Ri) exp(mn(x′)) ,
i.e., using the deﬁnition of the delta-like function F(x′; Ri) (equation (5.76)),
δmn(x) =

i
δ ˆdi
n αi(x)
,
(5.175)
where
αi(x) =

Ri
ds(x′) CM(x, x′) exp( mn(x′) )
.
(5.176)
Finally (equation (5.171)),
mn+1(x) = mn(x) −εn ( δmn(x) + mn(x) −mprior(x) )
.
(5.177)
The six equations (5.172)–(5.177) correspond to the actual computations to be performed
at each iteration. The only nontrivial equations are (5.172) and the pair (5.175)–(5.176).
Equation (5.172) corresponds to the resolution of the forward problem (estimation of the
transmittances along each ray for a given model of attenuation), and we do not need to
discuss it further. Equations (5.175)–(5.176) are where the inversion is made, so let us
interpret them with some detail.
First, αi(x) is a function that has negligible values everywhere in space except around
the ith ray, where, typically, it has an important value on the ray itself and smaller and smaller
values as the point x becomes more and more distant from the ith. We can call αi(x) a
“tube” around the ith ray. Then, equation (5.175) tells us that δmn(x) is made73 as a sum
73Practically, the model m(x) is numerically deﬁned on a grid of points, one point per pixel of the graphic
device used to plot the model.

142
Chapter 5. Functional Inverse Problems
Figure 5.15. The back-projection of data. Left: The true model and the data
corresponding to three different incidences. Right: Back-projection of the three different
incidences (values outside the back annulus disregarded). Iterative back-projection (of the
residuals) gives the solution of the inverse problem (see text). The ﬁrst iteration (back-
projection of the data) gives only a rough image.
oftubes, oneforeachray, eachtubebeingmultipliedbytheweightedresidual δ ˆdi
n associated
with the given ray. This corresponds to a sort of back-projection of each weighted residual
along each ray (see Figure 5.15).
This notion of back-projection is usual in algebraic
reconstruction techniques (see, for instance, Herman, 1980).
Now, a few words about ‘preconditioning.’ The steepest descent algorithm in equa-
tion(5.165)containsthesteepestascentdirection CM Gt
n C−1
D (g(mn)−dobs)+(mn−mprior) .
This direction is only optimum for inﬁnitesimal jumps, but in any practical algorithm, one
wishes to perform as large jumps as possible to accelerate convergence. It is quite easy, in
the physical sense, to apply gross corrections to this direction to obtain better ones. For
instance, in the example in Figure 5.15, the X-ray being closer in the region near the sources,
the ‘back-projection’ of the residuals along the ‘tube’ associated with each ray creates the
geometric effect that the points near the sources receive much larger values than the points
far from the sources. Preconditioning here may just amount to correcting for this effect
(possibly by just putting to zero all the values outside the inner part of the ring at the right
of Figure 5.15).
This amounts to replacing the steepest descent algorithm (5.165) with
mn+1 = mn −ψn(δmn)
,
(5.178)
where ψn( · ) is an ad hoc nonlinear function and
δmn = CM Gt
n C−1
D (g(mn) −dobs) + (mn −mprior)
.
(5.179)
With this preconditioning, the algorithm may be very rapid to converge. With a good
distribution of sources and receivers, one or two iterations may be sufﬁcient to obtain a
good solution.

5.7. Example: Travel-Time Tomography
143
Assume now that the algorithm has converged into the desired minimum, m = m∞,
and let us become interested in the computation of the posterior covariance operator, as
given by the second74 of equations (5.152),
CM = CM −CM Gt
∞(G∞CM Gt
∞+ CD)−1 G∞CM
,
(5.180)
where G∞corresponds to the derivative operator evaluated at the convergence point m∞.
I leave as an exercise to the reader to demonstrate that the explicit expression of this equa-
tion is

CM(x, x′) = CM(x, x′) −

i

j
Sij 8ij(x, x′)
,
(5.181)
where
8ij(x, x′) = K2

Ri
ds(x′′)

Rj
ds(x′′′) CM(x, x′′) exp( m(x′′) ) exp( m(x′′′) ) CM(x′′′, x′)
(5.182)
and
Sij = Cij
D + K2

Ri
ds(x)

Rj
ds(x′) exp( m(x) ) CM(x, x′) exp( m(x′) )
.
(5.183)
In these equations, m(x) is the maximum likelihood point (obtained by the convergence of
the iterative algorithm outlined above).
5.7
Example: Travel-Time Tomography
The inverse problem of travel-time tomography is formally very similar to the problem of X-
ray tomography, the only difference being that in travel-time tomography the rays cannot be
assumed to follow straight lines, but have a geometry that depends on the velocity structure
of the medium. One may, for instance, replace equations (5.71) and (5.76) in Example 5.18
with equations (5.80) and (5.86) in Example 5.20.
Therefore, all equations developed in section 5.6 for the inverse problem of X-ray
tomography remain valid here, except that all the integrals that were of the form

Ri
ds . . .
become now

Ri(mn)
ds . . .
,
indicating that the integral along the ith ray is to be performed along the ray path predicted
in the current model mn(x) .
Figures 5.16–5.17 give an illustration of the results of a tomographic (geophysical)
method. Only the mean of the posterior probability density was calculated (some random
realizations of a Gaussian distribution with the posterior mean and posterior covariance
should have been generated).
74We choose the second equation because, in this case where the data are discrete and the model is a function,
it is easier to implement.

144
Chapter 5. Functional Inverse Problems
Figure 5.16. A travel-time tomography experiment on an
old volcano in France. Acoustic waves were generated at the surface
of Earth. After reﬂection at a deep discontinuity, the travel times of
the waves were observed at an array of seismic stations ( ≃100 per
source). The observed travel times were used to infer the velocity
structure in a 3D region under the volcano (see Figure 5.17).
100 km
10 km
10 km
Figure 5.17. Tomographic results of
a travel-time experiment on a volcanic region
(Mont Dore, France), from Nercessian, Hirn,
and Tarantola, 1984. Left: Horizontal sections
of the velocity structure under the volcano, at
respective depths of 1, 2, 3, and 4 km (the hori-
zontal scale is that represented in Figure 5.16).
Light colors indicate low velocity and dark col-
ors indicate high velocity. Middle: The poste-
rior covariance function C(x0, x) , for a par-
ticular given point x0 situated near the middle
of the square, at a depth of 1 km. Light colors
indicate strong correlation. One sees that the
spatial resolution around x0 attained with this
data set is of the order of 1 km. Right: A pos-
teriori standard deviations σ(x) = C(x, x)1/2
for the horizontal section 1 km deep (scale not
shown). Central regions are best resolved.
1 km
2 km
3 km
4 km
5.8
Example: Nonlinear Inversion of Elastic Waveforms
The Problem: Elastic waves, created by some controlled source, propagate on a hetero-
geneous isotropic linearly elastic medium, and the displacements are observed at a ﬁnite
number of points (see Figure 5.18 below). Use these observations to infer the values of the
mass density, the bulk modulus, and the shear modulus at every point of the medium.
5.8.1
The Forward Problem
In what follows, given a symmetric tensor tij , its isotropic part, denoted ¯tij , and its
deviatoric part, denoted ˜tij , are deﬁned as
¯tij =
1
3 tk
k δij
,
˜tij = tij −¯tij = tij −1
3 tk
k δij
.
(5.184)
One clearly has ¯tk
k = tk
k and ˜tk
k = 0 .
Let V be the volume of the elastic medium being considered and S be its surface.
To simplify notation, a Cartesian system of coordinates x = {x1, x2, x3} is used over V .

5.8. Example: Nonlinear Inversion of Elastic Waveforms
145
Denoting by ui(x, t) the ith component of the displacement at space point xi and time
instant t , an elastic waveﬁeld can be characterized by the following system of equations:
ρ(x) ∂2ui
∂t2 (x, t) −∂σ ij
∂xj (x, t) = φi(x, t) ,
x ∈V , t ∈(0, T ) ,
(5.185)
σ ij(x, t) −3 κ(x) ¯uij(x, t) −2 µ(x) ˜uij(x, t) = ϕij(x, t) ,
x ∈V , t ∈(0, T ) ,
(5.186)
uij(x, t) = 1
2
 ∂ui
∂xj (x, t) + ∂uj
∂xi (x, t)

,
x ∈V , t ∈(0, T ) ,
(5.187)
σ ij(x, t) nj(x, t) = 0 ,
x ∈S , t ∈(0, T ) ,
(5.188)
ui(x, t) = 0 ,
x ∈V , t = 0 ,
(5.189)
∂ui
∂t (x, t) = 0 ,
x ∈V , t = 0 .
(5.190)
Here, ρ(x) , κ(x) , and µ(x) are the parameters describing the medium (mass density,
bulk modulus, and shear modulus, respectively). The sources of the waves are the volume
density of force φi(x, t) and the distribution of moments ϕij(x, t) . The ﬁelds σ ij(x, t)
and uij(x, t) are respectively the stress and the strain. The ﬁrst of these equations expresses
the fundamental dynamical equation, the second equation expresses the stress-strain relation
for an isotropic, linear elastic medium (see, for instance, Landau and Lifshitz, 1986), the
third equation expresses the strain as a function of the displacement, the fourth equation is
a spatial boundary condition expressing that the surface of the medium is considered to be
free (no tractions), and the last two equations are time-boundary (initial) conditions.
Let Gij(x, t; x′, t′) be the (causal) Green’s function of the problem, i.e., the dis-
placement ui(x, t) produced when the source is a point source of form φi(x, t) =
δi
j δ(x −x′) δ(t −t′) (the reader should easily write the precise system of equations deﬁn-
ing Gij(x, t; x′, t′) ; see Aki and Richards (1980) for details on the linear elastic problem,
Tarantola (1988) for the viscoelastic problem, and Roach (1982) or Morse and Feshbach
(1953) for general notions on Green’s functions).
Given the Green’s function, the displacement ﬁeld due to arbitrary sources φi(x, t)
and ϕij(x, t) (the solution of the equations above) can be represented as (the sums over j
and k are implicit)
ui(x, t) =

V
dV (x′)
 T
0
dt′ Gi
j(x, t; x′, t′) φj(x′, t′)
−

V
dV (x′)
 T
0
dt′ ∂Gij
∂x′k (x, t; x′, t′) ϕjk(x′, t′)
.
(5.191)
As the values of the elastic parameters of the medium are assumed not to depend on
time, it is easy to see that the Green’s function is invariant by time translation:
Gi
j(x, t; x′, t′) = Gi
j(x, t −t′; x′, 0)
.
(5.192)

146
Chapter 5. Functional Inverse Problems
Another important property of the Green’s function is (see, for instance, Aki and Richards
(1980) in the elastic context or Tarantola (1988) in the viscoelastic context) the reciprocity:
Gij(x, t; x′, t′) = Gji(x′, t; x, t′)
.
(5.193)
This means that the response at point x in the ith direction due to a source at point x′ in
the jth direction is identical to the response at point x′ in the jth direction due to a source
at point x .
5.8.2
A Comment on Parameterization
The formulation above assumes that the elastic properties of the medium are continuous
at every point of the medium, but it is easy to generalize the equations to the case where
there are discontinuities (imposing the continuity of the displacement and the stress ﬁeld
across the discontinuities). If there are discontinuities, it is preferable to enter directly the
geometrical properties of the discontinuity surfaces (positions, curvatures, etc.) as explicit
parameters in the inverse problem. For simplicity in the exposition, this is not the approach
followed below, where only the continuous ﬁelds ρ(x) , κ(x) , and µ(x) are considered. If
such an approach is followed, many discontinuities may build up as the iterative inversion
proceeds, as steep gradients, but this is not necessarily ideal.
5.8.3
Formulation of the Inverse Problem
The data of the problem are the observations of the displacement ﬁeld at some discrete
points:
uobs = {ui(xα, t)obs}
,
i = {1, 2, 3}
,
α = {1, 2 . . . N}
,
t ∈(0, T )
.
(5.194)
The model parameters are the bulk modulus κ(x) , the shear modulus µ(x) , and the mass
density ρ(x) . As we are going to use the Gaussian assumption for the description of a
priori information on the model parameters, it is better to replace these parameters with
their logarithmic versions:
K(x) = log κ(x)
κ0
,
M(x) = log µ(x)
µ0
,
R(x) = log ρ(x)
ρ0
,
(5.195)
where the denominators are arbitrary ﬁxed values of the parameters.
Uncertainties in the data are assumed to be Gaussian, described using a general covari-
ancefunction Cij(xα, t; xβ, t′) . Wealsointroducetheweightingfunction Wij(xα, t; xβ, t′) ,
the inverse of the covariance function. The two functions75 are related through (the sum
over j is implicit)
N

β=1
 T
0
dt′ Cij(xα, t; xβ, t′) Wjk(xβ, t′; xγ , t′′) = δi
k δαγ δ(t −t′′)
.
(5.196)
75Wij(xα, t; xβ, t′) is typically a generalized function (i.e., a distribution).

5.8. Example: Nonlinear Inversion of Elastic Waveforms
147
The a priori information on the model parameters is also assumed to be representable
by a Gaussian distribution. More precisely, we assume that the actual elastic medium is a
pseudorandom realization of a Gaussian random function (with three components) whose
center and covariance are known. The centers of the Gaussian distributions are (respectively
for the logarithmic bulk modulus, logarithmic shear modulus, and logarithmic mass density)
Kprior = {K(x)prior} , Mprior = {M(x)prior} , Rprior = {R(x)prior} , x ∈V ,
(5.197)
and the covariance functions are
CKK(x, x′)
,
CKM(x, x′)
,
CKR(x, x′)
,
CMK(x, x′)
,
CMM(x, x′)
,
CMR(x, x′)
,
CRK(x, x′)
,
CRM(x, x′)
,
CRR(x, x′)
.
(5.198)
To simplify the discussion, let us assume that the crosscovariances are zero. We are then
only left with the three covariance functions
CKK(x, x′)
,
CMM(x, x′)
,
CRR(x, x′)
(5.199)
and their inverses, the three weighting functions
WKK(x, x′)
,
WMM(x, x′)
,
WRR(x, x′)
,
(5.200)
each related to its associated covariance function by a relation like

V dV (x′)C(x, x′)
W(x′, x′′) = δ(x −x′′) .
The least-squares maximum likelihood model is the medium
m = {K , M , R}
(5.201)
deﬁned through the minimization of the expression
2 S(K, M, R) = ∥u(K, M, R) = uobs ∥2
u
+ ∥K −Kprior ∥2
K + ∥M −Mprior ∥2
M + ∥R −Rprior ∥2
R
.
(5.202)
Here, u(K, M, R) denotes the displacements (at the observation points) predicted (using
elastic theory) from the model m = {K , M , R} . Explicitly (the sums over i and j are
implicit),
2 S(K, M, R) =
N

α=1
N

β=1
 T
0
dt
 T
0
dt′ δui(xα, t) Wij(xα, t; xβ, t′) δuj(xβ, t′)
+

V
dV (x)

V
dV (x′) δK(x) WKK(x; x′) δK(x′)
+

V
dV (x)

V
dV (x′) δM(x) WMM(x; x′) δM(x′)
+

V
dV (x)

V
dV (x′) δR(x) WRR(x; x′) δR(x′)
,
(5.203)

148
Chapter 5. Functional Inverse Problems
where (writing ucal for u(K, M, R) )
δui(xα, t) = ui(xα, t)cal −ui(xα, t)obs
,
δK(x) = K(x) −K(x)prior = log
κ(x)
κ(x)prior
,
δM(x) = M(x) −M(x)prior = log
µ(x)
µ(x)prior
,
δR(x) = R(x) −R(x)prior = log
ρ(x)
ρ(x)prior
.
(5.204)
When so deﬁned, the problem is fully nonlinear (the best model is deﬁned without
invoking any linear approximation of the basic equations, like a Born approximation). As the
computed seismograms are nonlinear functionals of the model parameters, the functional
in equations (5.202)–(5.203) is a nonquadratic function of the model parameters.
5.8.4
The Fréchet Derivative
When the medium parameters are m = {K , M , R} , the displacement (solution of the
basic differential system) is u . When the medium parameters are perturbed into m+δm =
{K + δK , M + δM , R + δR} , the displacement becomes u + δu . We are interested here
in evaluating the ﬁrst order of the perturbation δu .
Writing the unperturbed system (5.185)–(5.190) together with the perturbed system
with the replacements76 ui →ui + δui , K →K + δK , M →K + δM , R →K + δR ,
keeping only the terms that are ﬁrst order, and using the unperturbed system to simplify
the perturbed system, one arrives at the conclusion that the ﬁrst-order perturbation δui is a
solution of the system
ρ(x) ∂2δui
∂t2 (x, t) −∂δσ ij
∂xj (x, t) = δφi(x, t) ,
x ∈V , t ∈(0, T ) ,
(5.205)
δσ ij(x, t) −3 κ(x) δ ¯uij(x, t) −2 µ(x) δ ˜uij(x, t) = ϕij(x, t) ,
x ∈V , t ∈(0, T ) ,
(5.206)
δuij(x, t) = 1
2
∂δui
∂xj (x, t) + ∂δuj
∂xi (x, t)

,
x ∈V , t ∈(0, T ) ,
(5.207)
δσ ij(x, t) nj(x, t) = 0 ,
x ∈S , t ∈(0, T ) ,
(5.208)
δui(x, t) = 0 ,
x ∈V , t = 0 ,
(5.209)
∂δui
∂t (x, t) = 0 ,
x ∈V , t = 0 ,
(5.210)
76One must replace any original positive parameter O with its logarithmic counterpart ω = log(O/O0) , use
the perturbation ω →ω + δω , and use the property O0 exp(ω + δω) = O0 exp ω exp δω = O exp δω =
O (1 + δω + · · · ) = O + O δω + · · · .

5.8. Example: Nonlinear Inversion of Elastic Waveforms
149
with the ‘secondary Born sources’
δφi(x, t) = −ρ(x) ∂2ui
∂t2 (x, t) δR(x)
,
δϕij(x, t) = 3 κ(x) ¯uij(x, t) δK(x) + 2 µ(x) ˜uij(x, t) δM(x)
.
(5.211)
We therefore see that the ‘perturbation ﬁeld’ δui propagates in the unperturbed
medium (i.e., the medium characterized by {ρ, κ, µ} ) and is excited by a double system of
forces: at every point where the (logarithmic) mass density has been perturbed, there is a
volume force −ρ ¨ui δR , and at every point where the (logarithmic) bulk and shear modulus
have been perturbed, there is a moment source κ uk
k δK + 2 µ (uij −(1/3) uk
k) δM .
The representation theorem in equation (5.191) immediately allows us to write δui as
δui(x, t) =

V
dV (x′)Xi(x, t, x′) δR(x′) +

V
dV (x′)Y i(x, t, x′) δK(x′)
+

V
dV (x′)Zi(x, t, x′) δM(x′)
,
(5.212)
where (the sums over j and k are implicit)
Xi(x, t, x′) = −ρ(x′)
 T
0
dt′ Gi
j(x, t; x′, t′) ∂2uj
∂t′2 (x′, t′)
,
Y i(x, t, x′) = −3 κ(x′)
 T
0
dt′ ∂Gij
∂x′k (x, t; x′, t′) ¯ujk(x′, t′)
,
Zi(x, t, x′) = −2 µ(x′)
 T
0
dt′ ∂Gij
∂x′k (x, t; x′, t′) ˜ujk(x′, t′)
(5.213)
and where Gij(x, t; x′, t′) is the Green’s function of the unperturbed medium.
We have thus obtained the three integral kernels Xi(x, t, x′) , Y i(x, t, x′) , and
Zi(x, t, x′) corresponding respectively to the Fréchet derivatives of the displacement ﬁeld
with respect to the logarithmic mass density, the logarithmic bulk modulus, and the loga-
rithmic shear modulus.
For the resolution of the inverse problem, what we need are the Fréchet derivatives of
the calculated data, i.e., the displacements at some selected points xα for α = 1, 2, . . . , N .
We easily particularize to obtain
δui(xα, t) =

V
dV (x)Xi(xα, t, x) δR(x) +

V
dV (x)Y i(xα, t, x) δK(x)
+

V
dV (x)Zi(xα, t, x) δM(x)
.
(5.214)

150
Chapter 5. Functional Inverse Problems
5.8.5
The Transpose of the Fréchet Derivative Operator
By deﬁnition, the transpose of the operator just obtained is the operator that with any
δ ˆui(xα, t) associates δ ˆR(x) , δ ˆK(x) , and δ ˆM(x) given by (the sum over i is implicit)
δ ˆR(x) =
N

α=1
 T
0
dt′ Xi(xα, t′, x) δ ˆui(xα, t′)
,
δ ˆK(x) =
N

α=1
 T
0
dt′ Y i(xα, t′, x) δ ˆui(xα, t′)
,
δ ˆM(x) =
N

α=1
 T
0
dt′ Zi(xα, t′, x) δ ˆui(xα, t′)
,
(5.215)
where the kernels Xi , Y i , and Zi are those in equations (5.213). As we have seen, a linear
operator and its transpose have the same kernels, the only difference arising in the variables
of sum/integration, which are complementary.
This gives, after some rearranging (sum over i implicit),
δ ˆR(x) = −
 T
0
dt

ρ(x) ∂2uj
∂t2 (x, t)

N

α=1
 T
0
dt′ Gi
j(xα, t′; x, t) δ ˆui(xα, t′)
,
δ ˆK(x) = −
 T
0
dt

3 κ(x) ¯ujk(x, t)

N

α=1
 T
0
dt′ ∂Gij
∂xk (xα, t′; x, t) δ ˆui(xα, t′)
,
δ ˆM(x) = −
 T
0
dt

2 µ(x) ˜ujk(x, t)

N

α=1
 T
0
dt′ ∂Gij
∂xk (xα, t′; x, t) δ ˆui(xα, t′)
.
(5.216)
Deﬁning (sum over i implicit)
ωj(x, t) =
N

α=1
 T
0
dt′ Gi
j(xα, t′; x, t) δ ˆui(xα, t′)
,
(5.217)
this can be written77
δ ˆR(x) = −ρ(x)
 T
0
dt ∂2ui
∂t2 (x, t) ωi(x, t)
,
δ ˆK(x) = −3 κ(x)
 T
0
dt ¯uij(x, t) ¯ωij(x, t)
,
δ ˆM(x) = −2 µ(x)
 T
0
dt ˜uij(x, t) ˜ωij(x, t)
,
(5.218)
77The fact that uij is a symmetric tensor has been used as well as the fact that ˆuij is isotropic and ˜uij is
traceless.

5.8. Example: Nonlinear Inversion of Elastic Waveforms
151
where ωij(x, t) = 1
2
 ∂ωi
∂xj (x, t) + ∂ωj
∂xi (x, t)

and, as usual, ¯ωij and ˜ω are, respectively, the
isotropic part and traceless part of ωij .
To obtain a more symmetric expression, let us integrate the ﬁrst sum by parts. One
has
 T
0
dt ∂2uj
∂t2 (x, t) ωj(x, t) =
*∂uj
∂t (x, T ) ωj(x, T )
+T
0 −
 T
0
dt ∂uj
∂t (x, t) ∂ωj
∂t (x, t)
.
(5.219)
As the ﬁeld ui(x, t) satisﬁes initial conditions of rest, ui(x, 0) = 0 . We are about to see
that the ﬁeld ωi(x, t) satisﬁes ﬁnal conditions of rest, ω(x, T ) = 0 . Therefore,
 T
0
dt ∂2uj
∂t2 (x, t) ωj(x, t) = −
 T
0
dt ∂uj
∂t (x, t) ∂ωj
∂t (x, t)
,
(5.220)
and equations (5.218) ﬁnally become (denoting by a dot the time derivative)
δ ˆR(x) = + ρ(x)
 T
0
dt ˙ui(x, t) ˙ωi(x, t)
,
δ ˆK(x) = −3 κ(x)
 T
0
dt ¯uij(x, t) ¯ωij(x, t)
,
δ ˆM(x) = −2 µ(x)
 T
0
dt ˜uij(x, t) ˜ωij(x, t)
.
(5.221)
The reader may easily verify that the physical dimensions of these three equations are
consistent (the three give pure real numbers). We shall come back to them in a moment.
Let us ﬁrst obtain the interpretation of the ﬁeld ωi(x, t) deﬁned in equation (5.217).
This equation (5.217) is very close to the representation equation (5.191), except
that the time variable is reversed and the source is a sum of point sources.
It can be
demonstrated78 that the reversal of the time corresponds to a propagation problem with
ﬁnal, instead of initial, time conditions. Therefore, the ﬁeld ωi(x, t) is the solution of the
78To demonstrate this, we have two routes.
The direct one is to introduce the wave equation operator
L (writing the elastic wave equation (5.185)–(5.190) formally as L u = φ ), to deﬁne the transpose op-
erator through ⟨ˆφ , L u ⟩φ = ⟨Lt ˆφ , u ⟩u , and to verify that the operator Lt satisﬁes time-boundary
conditions that are dual to those satisﬁed by L (i.e., ﬁnal conditions of rest instead of initial conditions of
rest), much as was done in Example 5.21.
The second route is to write an equation like (5.217) ﬁrst as
ωi(x, t) =

V dV (x)

 T
0 dt′ Gji(x′, t′; x, t) δ ˆuj(x′, t′) , then, using the reciprocity property in equation (5.193),
to obtain ωi(x, t) =

V dV (x)

 T
0 dt′ Gij(x, t′; x′, t) δ ˆuj(x′, t′) , or, using an anticausal (instead of a causal)
Green’s function, ωi(x, t) =

V dV (x)

 T
0 dt′ ←−
G ij(x, t; x′, t′) δ ˆuj(x′, t′) . Therefore, ωi(x, t) is the solution of
a wave-propagation problem, where the sources are the δ ˆui(x, t) , which satisﬁes the ﬁnal conditions of rest.

152
Chapter 5. Functional Inverse Problems
following system of equations:
ρ(x) ∂2ωi
∂t2 (x, t) −∂σ ij
∂xj (x, t) =
N

α=1
δ(x −xα) δ ˆui(xα, t) ,
x ∈V , t ∈(0, T ) ,
(5.222)
σ ij(x, t) −3 κ(x) ¯ωij(x, t) −2 µ(x) ˜ωij(x, t) = 0 ,
x ∈V , t ∈(0, T ) ,
(5.223)
ωij(x, t) = 1
2
∂ωi
∂xj (x, t) + ∂ωj
∂xi (x, t)

,
x ∈V , t ∈(0, T ) ,
(5.224)
σ ij(x, t) nj(x, t) = 0 ,
x ∈S , t ∈(0, T ) ,
(5.225)
ωi(x, t) = 0 ,
x ∈V ; t = T ,
(5.226)
∂ωi
∂t (x, t) = 0 ,
x ∈V , t = T ,
(5.227)
where the ﬁnal conditions of rest should be noted.
We see that the sources of the ﬁeld ωi(x, t) are discrete force sources, one at every
point xα where there is a receiver, radiating the value δ ˆui(xα, t) .
5.8.6
A Comment on the Optimization Algorithm
Provided that the hypothesis of Gaussian uncertainties in the observed displacements and
Gaussian a priori uncertainties in model parameters is realistic, the minimization of the
misﬁt function deﬁned in equations (5.202)–(5.203) will actually deﬁne a good model.
But there are two difﬁculties: (i) the relation between a wave amplitude and the elastic
parameters deﬁning a medium is essentially nonlinear, and (ii) in highly heterogeneous
media the elastic waveﬁeld may become extremely complex. Because of this, ﬁnding the
minimum of the misﬁt function may be a difﬁcult task.
There are no general rules, as the elastic waveform inverse problem may be applied
to many problems, from the trivial to the impossible (using present-day computing power).
Many problems require the combined use of a Monte Carlo search and local (steepest
descent) optimization algorithms (as in the example shown in section 5.8.8 below). That I
concentrate here on the description of a gradient-based algorithm does not mean that it is
a panacea, but only that it will be a part of any realistic algorithm. It is only for problems
whereelasticwavespropagateinasmoothmediumpresentingsomediffractors(andpossibly
presenting multiscattering) that a gradient-based algorithm alone may produce the minimum
of the misﬁt function.
5.8.7
The Inversion Algorithm (Steepest Descent)
Our problem here is to obtain the minimum of the misﬁt function deﬁned in equation (5.202).
Let us develop here the equations corresponding to a simple steepest descent algorithm. We
obtained (equation (3.89))
mn+1 = mn −εn ( CM Gt
n C−1
D (g(mn) −dobs) + (mn −mprior) )
,
(5.228)

5.8. Example: Nonlinear Inversion of Elastic Waveforms
153
where Gn is the derivative operator evaluated at the current point mn and Gt
m is its
transpose.
The real numbers εn are chosen ad hoc (as large as possible to accelerate
convergence but small enough to avoid divergence).
Splitting the algorithm into its basic computations gives
dn = g(mn)
,
(5.229)
δdn = dn −dobs
,
(5.230)
δ ˆdn = C−1
D δdn
,
(5.231)
δ ˆmn = Gt
n δ ˆdn
,
(5.232)
δmn = CM δ ˆmn
,
(5.233)
mn+1 = mn −εn (δmn + mn −mprior)
,
(5.234)
and, as a model m is made here by {R, K, M} , we can write, with more detail,
dn = g(Rn, Kn, Mn)
,
(5.235)
δdn = dn −dobs
,
(5.236)
δ ˆdn = C−1
D δdn
,
(5.237)
δ ˆRn = Xt
n δ ˆdn
,
δ ˆKn = Yt
n δ ˆdn
,
δ ˆMn = Zt
n δ ˆdn
,
(5.238)
δRn = CRR δ ˆRn
,
δKn = CKK δ ˆKn
,
δKn = CMM δ ˆMn
,
(5.239)
Rn+1 = Rn −εn (δRn + Rn −Rprior)
,
(5.240)
Kn+1 = Kn −εn (δKn + Kn −Kprior)
,
(5.241)
Mn+1 = Mn −εn (δMn + Mn −Mprior)
.
(5.242)
Here, the special structure assumed in equation (5.199) for the covariance operator has been
used, as well as the transpose operators Xt , Yt , and Zt introduced in equation (5.215).
Let us comment on this set of equations. The algorithm is initialized at some arbitrary
model, perhaps the prior model {Rprior , Kprior , Mprior} introduced in equation (5.197).
Assume that a few iterations have been performed and that the current model is now
{Rn, Kn, Mn} .
Equation (5.235) corresponds to the resolution of the forward problem, i.e., the res-
olution of the propagation problem deﬁned in equations (5.185)–(5.190) for the current
model {Rn, Kn, Mn} , and subsequent consideration of the displacement ﬁeld ui(x, t) are
thus obtained at the points x = xα where receivers were placed. This gives ui(xα, t)n .
Equation (5.236) corresponds to the computation of the residuals δui(xα, t)n =
ui(xα, t)n −ui(xα, t)obs .
Equation (5.237) corresponds to the computation of the weighted residuals. For in-
stance, when using the weighting function Wij(xα, t; xβ, t′) introduced in equation (5.196),
this gives (sum over j implicit)
δ ˆui(xα, t)n =
N

β=1
 T
0
dt′ Wij(xα, t; xβ, t′) δuj(xβ, t′)n
.
(5.243)

154
Chapter 5. Functional Inverse Problems
If the weighting function Wij(xα, t; xβ, t′) is too difﬁcult to obtain, one can use instead the
covariance function Cij(xα, t; xβ, t′) and solve the linear system
δui(xα, t)n =
N

β=1
 T
0
dt′ Cij(xα, t; xβ, t′) δ ˆuj(xβ, t′)n
(5.244)
in order to obtain δ ˆui(xα, t)n .
Figure 5.18. A source generates elastic waves that propagate on a solid, and the
displacements are measured at some points (left panel). These observations are used to
infer the elastic structure of the medium. A steepest descent algorithm requires that each
receiver act as a source, radiating the residual (calculated minus observed) displacements
(right panel). The time correlation of the two propagating ﬁelds produces the updating of
elastic model parameters.
Equations (5.238) are the basic equations of the algorithm. They correspond to the
computations demonstrated in equations (5.221),
δ ˆR(x)n = + ρ(x)n
 T
0
dt ˙ui(x, t)n ˙ωi(x, t)n
,
δ ˆK(x)n = −3 κ(x)n
 T
0
dt ¯uij(x, t)n ¯ωij(x, t)n
,
δ ˆM(xn) = −2 µ(x)n
 T
0
dt ˜uij(x, t)n ˜ωij(x, t)n
,
(5.245)
where ui(x, t)n is the ﬁeld propagating in the current model {Rn, Kn, Rn} (excited by the
actual sources and with initial conditions of rest) and ωi(x, t)n is the ﬁeld also propagating
in the current medium {Rn, Kn, Rn} , but whose ﬁctive sources79 are the weighted residuals
δ ˆui(xα, t)n , satisfying ﬁnal (instead of initial) conditions of rest (see Figure 5.18). The ﬁeld
ωi(x, t)n is precisely deﬁned by the set of equations (5.222)–(5.227) (using the current
medium).
79It has been considered here that the points where the displacements are observed are points inside the medium.
In this case, the ﬁctive sources are forces inside the medium. If the displacements are observed at points at the
surface of the medium, it can be demonstrated that the ﬁctive sources are surface tractions.

5.8. Example: Nonlinear Inversion of Elastic Waveforms
155
Equations (5.239) correspond to the application of the covariance functions introduced
in equation (5.199):
δR(x)n =

V
dV (x′) CRR(x, x′) δ ˆR(x′)n
,
δK(x)n =

V
dV (x′) CKK(x, x′) δ ˆK(x′)n
,
δM(x)n =

V
dV (x′) CMM(x, x′) δ ˆM(x′)n
.
(5.246)
Finally, equations (5.240)–(5.242) correspond to the model updatings
R(x)n+1 = R(x)n −εn (δR(x)n + R(x)n −R(x)prior)
,
K(x)n+1 = K(x)n −εn (δK(x)n + K(x)n −K(x)prior)
,
M(x)n+1 = M(x)n −εn (δM(x)n + M(x)n −M(x)prior)
.
(5.247)
A steepest descent algorithm, as the one presented here, never has to be used scrupu-
lously: the steepest descent direction is only optimal for inﬁnitesimally small steps, but
nobody wants to perform inﬁnitesimally small steps. The steepest descent direction can
easily be ameliorated using some preconditioning. First, instead of the unique constant
εn in the three equations (5.247), one may use three different constants, or even make a
local optimization in the three-dimensional space deﬁned by the three directions δR(x)n +
R(x)n −R(x)prior , δK(x)n + K(x)n −K(x)prior , and δM(x)n + M(x)n −M(x)prior . Still
better, one may apply any nonlinear operator to these three directions that not only still gives
a direction of descent for the misﬁt function but deﬁnes a much better direction (for a ﬁnite
jump).
As a ﬁnal comment, although I have chosen here to work with mass density, bulk
modulus, and shear modulus, the special geometry of the problem at hand may suggest the
use of other parameters.
Figure 5.19. One source is used to excite elastic waves
that propagate into a geological medium. Inside a well, situated
at a distance of 2 km from the source, three-component receivers
were installed between 2 km and 4 km in depth. The medium a
priori is known to present strong vertical gradients and milder
horizontal ones. One is interested in imaging both of them.

156
Chapter 5. Functional Inverse Problems
5.8.8
A Geological Example
As an example of the use of the methods just discussed, I choose to present here a result
obtained by my team when working in a geophysical context.
Figure 5.20.
Ob-
served seismograms.
Hor-
izontal component displayed
(vertical component also used
in the inversion).
Observe
the complexity of the elastic
ﬁeld, with refractions, reﬂec-
tions, and reverberations. The
color code displays the in-
stantaneous polarization of the
wave.
See Charara, Barnes,
and Tarantola (1996, 2000)
and Barnes,
Charara,
and
Tarantola (1998).
10
20
30
40
50
60
70
Traces
1000
1500
2000
2500
3000
3500
4000
Time (ms)
Observed seismograms (x component)
The problem was to use waveform data measured inside a well (Figure 5.19) to infer
the elastic structure of the medium. The data were three-component seismograms obtained
at different positions between 2 and 4 km in depth. Of the three components of data recorded,
the horizontal component inside the plane of Figure 5.19 is represented in Figure 5.20.
The inverse problem was essentially set following the methods presented earlier in this
section, except that the parameters chosen here were the velocity of the longitudinal waves,
the velocity of the transverse waves, the mass density, and the attenuation (too important in
this example to be neglected).
The numerical simulation of the propagation of elastic waves was performed using
a ﬁnite-difference approximation to the viscoelastic wave equation. It was assumed (quite
unrealistically) that the medium presented a symmetry of revolution around the source (so a
two-dimensional simulation could be used, instead of the more expensive three-dimensional
simulation).
An extensive Monte Carlo search of the model space was performed (see Barnes,
Charara, and Tarantola, 1998) until a model that was able to ﬁt most of the arrival times
of the packets of elastic energy was found. From this point on, a few tens of iterations of
a preconditioned steepest descent algorithm were able to provide a model whose predicted
seismograms ﬁt the observations well (see Charara, Barnes, and Tarantola, 1996, 2000).
The obtained model is presented in Figure 5.21 (velocities are in m/s , mass density
is in g/cm3 , and attenuation is in logarithmic units), the seismograms predicted from this
model (using the viscoelastic wave equation) are presented in Figure 5.22, and the residual
seismograms are presented in Figure 5.23.
In this problem, the estimation of uncertainties was basically obtained during the ﬁrst
phase of a Monte Carlo search. No special effort was made to compute the covariance
operator during the gradient-based optimization phase.

5.8. Example: Nonlinear Inversion of Elastic Waveforms
157
Figure 5.21. The best model of seismic velocities, mass density, and attenuation.
Figure 5.22.
Cal-
culated seismograms from the
model in Figure 5.21, using
the viscoelastic wave equation.
Compare with the observed
seismograms in Figure 5.20.
Calculated seismograms (x component)
10
20
30
40
50
60
70
Traces
1000
1500
2000
2500
3000
3500
4000
Time (ms)
Figure 5.23.
Resid-
ual seismograms (difference
between the observations in
Figure 5.20 and the calcula-
tions in Figure 5.22). Note that
most of the remaining energy is
incoherent.
10
20
30
40
50
60
70
Traces
1000
1500
2000
2500
3000
3500
4000
Time (ms)
Residual seismograms (x component)

158
Chapter 5. Functional Inverse Problems
In spite of some serious limitations (the actual three-dimensionality of the problem
was only approximately taken into account and only one source location was available),
this example shows that quite complex seismic waveforms can be ﬁtted. As the initial
models available here predicted seismograms that were quite different from those actually
observed, gradient-based methods could not be applied from the start, and the Monte Carlo
initial search phase was essential.
Among other things, this example suggested that there is not much to be gained when
changing a simple preconditioned steepest descent algorithm to a more sophisticated quasi-
Newton algorithm: with a good preconditioning (suggested by physical intuition), the extra
computational effort required by a quasi-Newton algorithm is better spent (in this example)
on extra iterations of the steepest descent algorithm.

Chapter 6
Appendices
6.1
Volumetric Probability and Probability Density
A probability distribution A →P(A) over a manifold can be represented by a volumetric
probability F(x) , deﬁned through
P(A) =

A
dV (x) F(x)
,
(6.1)
or by a probability density f (x) , deﬁned through
P(A) =

A
dx f (x)
,
(6.2)
where dx = dx1 dx2 . . . . While, under a change of variables, a probability density behaves
as a density (i.e., its value at a point gets multiplied by the Jacobian of the transformation),
a volumetric probability is a scalar (i.e., its value at a point remains invariant: it is deﬁned
independently of any coordinate system).
Deﬁning the volume density through
V (A) =

A
dx v(x)
(6.3)
and considering the expression V (A) =

A dV (x) , we obtain
dV (x) = v(x) dx
.
(6.4)
It follows that the relation between volumetric probability and probability density is
f (x) = v(x) F(x)
.
(6.5)
While the homogeneous probability distribution (the one assigning equal probabilities
toequalvolumesofthespace)is, ingeneral, not representedbyaconstantprobabilitydensity,
it is always represented by a constant volumetric probability.
Although I prefer, in my own work, to use volumetric probabilities, I have chosen in
this text to use probability densities (for pedagogical reasons).
159

160
Chapter 6. Appendices
6.2
Homogeneous Probability Distributions
This appendix is reproduced from Mosegaard and Tarantola, 2002.
In some parameter spaces, there is an obvious deﬁnition of distance between points,
and therefore of volume. For instance, in the 3D Euclidean space, the distance between two
points is just the Euclidean distance (which is invariant under translations and rotations).
Should we choose to parameterize the position of a point by its Cartesian coordinates
{x, y, z} , the volume element in the space would be dV (x, y, z) = dx dy dz , while if
we chose to use geographical coordinates, the volume element would be dV (r, θ, ϕ) =
r2 sin θdr dϑ dϕ .
Deﬁnition. The homogeneous probability distribution is the probability distribution that
assigns to each region of the space a probability proportional to the volume of the region.
Then, which probability density represents such a homogeneous probability distribu-
tion? Let us give the answer in three steps.
• If we use Cartesian coordinates {x, y, z} , as we have dV (x, y, z) = dx dy dz , the
probability density representing the homogeneous probability distribution is constant:
f (x, y, z) = k .
• If we use geographical coordinates {r, θ, ϕ} , as we have dV (r, θ, ϕ) = r2 sin θ
dr dθ dϕ , the probability density representing the homogeneous probability distri-
bution is g(r, θ, ϕ) = k r2 sin θ .
• Finally, if we use an arbitrary system of coordinates {u, v, w} , in which the vol-
ume element of the space is dV (u, v, w) = v(u, v, w) du dv dw , the homoge-
neous probability distribution is represented by the probability density h(u, v, w) =
k v(u, v, w) .
This is obviously true, since if we calculate the probability of a region A of the space, with
volume V (A) , we get a number proportional to V (A) .
From these observations, we can arrive at conclusions that are of general validity.
First, the homogeneous probability distribution over some space is represented by a constant
probability density only if the space is ﬂat (in which case rectilinear systems of coordinates
exist) and if we use Cartesian (or rectilinear) coordinates. The other conclusions can be
stated as rules.
Rule 6.1. The probability density representing the homogeneous probability distribution is
easilyobtainediftheexpressionofthevolumeelement dV (u1, u2, . . . ) = v(u1, u2, . . . ) du1
du2 . . . of the space is known, as it is then given by h(u1, u2, . . . ) = k v(u1, u2, . . . ) , where
k is a proportionality constant (that may have physical dimensions).
Rule 6.2. If there is a metric gij(u1, u2, . . . ) in the space, then the volume element is given
by dV (u1, u2, . . . ) = √det g(u1, u2, . . . ) du1 du2 . . . , i.e., we have v(u1, u2, . . . ) =
√det g(u1, u2, . . . ) . The probability density representing the homogeneous probability
distribution is, then, h(u1, u2, . . . ) = k√det g(u1, u2, . . . ) .

6.2. Homogeneous Probability Distributions
161
Rule 6.3. If the expression of the probability density representing the homogeneous proba-
bility distribution is known in one system of coordinates, then it is known in any other system
of coordinates through the Jacobian rule (equation (1.18)).
Indeed, in the expression above, g(r, θ, ϕ) = k r2 sin θ , we recognize the Jacobian
between the geographical and the Cartesian coordinates (where the probability density is
constant).
For short, when we say the homogeneous probability density, we mean the probability
density representing the homogeneous probability distribution. One should remember that,
in general, the homogeneous probability density is not constant.
Let us now examine positive parameters, like a temperature, a period, or a seismic
wave propagation velocity. One of the properties of the parameters we have in mind is that
they occur in pairs of mutually reciprocal parameters:
Period
T = 1/ν
,
Frequency
ν = 1/T ;
Resistivity
ρ = 1/σ
,
Conductivity
σ = 1/ρ ;
Temperature
T = 1/(kβ)
,
Thermodynamic parameter
β = 1/(kT ) ;
Mass density
ρ = 1/ℓ
,
Lightness
ℓ= 1/ρ ;
Compressibility
γ = 1/κ
,
Bulk modulus (incompress.)
κ = 1/γ
;
Wave velocity
c = 1/n
,
Wave slowness
n = 1/c .
When working with physical theories, one may freely choose one of these parameters or its
reciprocal.
Sometimes, these pairs of equivalent parameters come from a deﬁnition, like when
we deﬁne frequency ν as a function of the period T by ν = 1/T . Sometimes, these
parameters arise when analyzing an idealized physical system. For instance, Hooke’s law,
relating stress σij to strain εij , can be expressed as σij = cij kℓεkℓ, thus introducing the
stiffness tensor cijkℓ, or as εij = dij kℓσkℓ, thus introducing the compliance tensor dijkℓ,
the inverse of the stiffness tensor. Then, the respective eigenvalues of these two tensors
belong to the class of scalars analyzed here.
Let us take, as an example, the pair conductivity-resistivity (this may be thermal,
electric, etc.). Assume we have two samples in the laboratory, S1 and S2 , whose resistivities
are respectively ρ1 and ρ2 . Correspondingly, their conductivities are σ1 = 1/ρ1 and
σ2 = 1/ρ2 . How should we deﬁne the distance between the electrical properties of the two
samples? As we have |ρ2 −ρ1| ̸= |σ2 −σ1| , choosing one of the two expressions as the
distance would be arbitrary. Consider the following deﬁnition of distance between the two
samples:
D(S1, S2) =
 log ρ2
ρ1
 =
 log σ2
σ1

.
(6.6)
This deﬁnition (i) treats symmetrically the two equivalent parameters ρ and σ and, more
importantly, (ii) has an invariance of scale (what matters is how many octaves we have
between the two values, not the plain difference between the values). In fact, it is the only
deﬁnition of distance between the two samples S1 and S2 that has an invariance of scale
and is additive (i.e., D(S1, S2) + D(S2, S3) = D(S1, S3) ).

162
Chapter 6. Appendices
Example 6.1. We have just considered two samples. Can we deﬁne the mean sample?
The mean sample should be deﬁned as the sample that is equidistant from the two given
samples. Using the distance in equation (6.6), one easily ﬁnds80 that the resistivity of the
mean sample is
ρ = √ρ1 ρ2
.
(6.7)
Equivalently, the conductivity of the mean sample is
σ = √σ1 σ2
.
(6.8)
Note that (i) these two expressions are formally identical, and (ii) the conductivity of the
mean sample equals the inverse of the resistivity of the mean sample (while the arithmetic
mean of the resistivities is not the inverse of the arithmetic mean of the conductivities).
Associated with the distance D(x1, x2) = | log (x2/x1) | is the distance element
(differential form of the distance)
dL(x) = dx/x
.
(6.9)
This being a one-dimensional volume, we can apply now Rule 6.1 above to get the expression
of the homogeneous probability density for such a positive parameter:
f (x) = k/x
.
(6.10)
Deﬁning the reciprocal parameter y = 1/x and using the Jacobian rule, we arrive at the
homogeneous probability density for y :
g(y) = k/y
.
(6.11)
These two probability densities have the same form: the two reciprocal parameters are
treated symmetrically. Introducing the logarithmic parameters
x∗= log(x/x0)
,
y∗= log(y/y0)
,
(6.12)
where x0 and y0 are arbitrary positive constants, and using the Jacobian rule, we arrive at
the homogeneous probability densities
f ′(x∗) = k
,
g′(y∗) = k
.
(6.13)
This shows that the logarithm of a positive parameter (of the type considered above) is
a Cartesian parameter. In fact, it is the consideration of equations (6.13), together with
the Jacobian rule, that allows full understanding of the (homogeneous) probability densi-
ties (6.10)–(6.11).
The association of the probability density f (u) = k/u with positive parameters was
ﬁrst made by Jeffreys (1939). To honor him, I propose to use the term Jeffreys parameters for
80Using, for instance, the resistivity, the equidistance condition is written log(ρ1/ρ) = log(ρ/ρ2) , i.e., ρ2 =
ρ1 ρ2 .

6.2. Homogeneous Probability Distributions
163
all the parameters of the type considered above. The 1/u probability density was advocated
by Jaynes (1968), and a nontrivial use of it was made by Rietsch (1977) in the context of
inverse problems.
Rule 6.4. The homogeneous probability density for a Jeffreys quantity u is f (u) = k/u .
Rule 6.5. The homogeneous probability density for a Cartesian parameter u (like the
logarithm of a Jeffreys parameter, an actual Cartesian coordinate in an Euclidean space,
or the Newtonian time coordinate) is f (u) = k . The homogeneous probability density for
an angle describing the position of a point in a circle is also constant.
If a parameter u is a Jeffreys parameter with the homogeneous probability density
f (u) = k/u , then its inverse, its square, and, in general, any power of the parameter is also
a Jeffreys parameter, as can easily be seen using the Jacobian rule.
Rule 6.6. Any power of a Jeffreys quantity (including its inverse) is a Jeffreys quantity.
It is important to recognize when we do not face a Jeffreys parameter. Among the
many parameters used in the literature to describe an isotropic linear elastic medium, we
ﬁnd parameters like Lamé’s coefﬁcients λ and µ , the bulk modulus κ , the Poisson ratio
σ , etc. A simple inspection of the theoretical range of variation of these parameters shows
that the ﬁrst Lamé parameter λ and the Poisson ratio σ may take negative values, so they
are certainly not Jeffreys parameters. In contrast, Hooke’s law σij = cijkℓεkℓ, deﬁning a
linearity between stress σij and strain εij , deﬁnes the positive deﬁnite stiffness tensor cijkℓ
or, if we write εij = dijkℓσ kℓ, deﬁnes its inverse, the compliance tensor dijkℓ. The two
reciprocal tensors cijkℓand dijkℓare Jeffreys tensors. This is a notion whose development
is beyond the scope of this book, but we can give the following rule.
Rule 6.7. The eigenvalues of a Jeffreys tensor are Jeffreys quantities.81
As the two (different) eigenvalues of the stiffness tensor cijkℓare λκ = 3κ (with mul-
tiplicity 1) and λµ = 2µ (with multiplicity 5) , we see that the incompressibility modulus
κ and the shear modulus µ are Jeffreys parameters82 (as is any parameter proportional to
them, or any power of them, including the inverses). If for some reason, instead of working
with κ and µ , we wish to work with other elastic parameters, like for instance the Young
modulus Y and the Poisson ratio σ , or the two elastic wave velocities, then the homoge-
neous probability distribution must be found using the Jacobian of the transformation (see
Appendix 6.3).
81This solves the complete problem for isotropic tensors only. It is beyond the scope of this text to propose rules
valid for general anisotropic tensors: the necessary mathematics has not yet been developed.
82The deﬁnition of the elastic constants was made before the tensorial structure of the theory was understood.
Seismologists today should not use, at a theoretical level, parameters like the ﬁrst Lamé coefﬁcient λ or the
Poisson ratio σ. Instead, they should use κ and µ (and their inverses). In fact, our suggestion is to use the true
eigenvalues of the stiffness tensor, λκ = 3κ and λµ = 2µ , which we propose to call the eigen-bulk-modulus and
the eigen-shear-modulus, respectively.

164
Chapter 6. Appendices
Some probability densities have conspicuous ‘dispersion parameters,’ like the σ’s
in the normal probability density f (x) = k exp

−(x−x0)2
2 σ 2

, in the log-normal probabil-
ity g(X) =
k
X exp

−(log X/X0)2
2 σ 2

, or in the Fischer probability density (Fischer, 1953)
h(ϑ, ϕ) = k sin θ exp

cos θ / σ 2
. A consistent probability model requires that when
the dispersion parameter σ tends to inﬁnity, the probability density tends to the homoge-
neous probability distribution. For instance, in the three examples just given, f (x) →k ,
g(X) →k/X , and h(θ, ϕ) →k sin θ , which are the respective homogeneous probability
densities for a Cartesian quantity, a Jeffreys quantity, and the geographical coordinates on
the surface of the sphere. We can state the following rule.
Rule 6.8. If a probability density has some dispersion parameters, then, in the limit where
the dispersion parameters tend to inﬁnity, the probability density must tend to the homoge-
neous one.
As an example, using the normal probability density f (x) = k exp

−(x−x0)2
2 σ 2

for a
Jeffreys parameter is not consistent. Note that it would assign a ﬁnite probability to negative
values of a parameter that, by deﬁnition, is positive. More technically, this would violate
the condition that all probability densities be absolutely continuous with respect to the
homogeneous probability density. Using the log-normal probability density for a Jeffreys
parameter is perfectly acceptable.
There is a problem of terminology in the Bayesian literature. The homogeneous
probability distribution is a very special distribution. When the problem of selecting a
‘prior’ probability distribution arises in the absence of any information, except the funda-
mental symmetries of the problem, one may select as a prior probability distribution the
homogeneous distribution. But enthusiastic Bayesians do not call it ‘homogeneous,’ but
‘noninformative.’ I cannot recommend using this terminology. The homogeneous prob-
ability distribution is as informative as any other distribution, it is just the homogeneous one.
In general, each time we consider an abstract parameter space, each point being rep-
resented by some parameters x = {x1, x2, . . . , xn} , we will start by solving the (sometimes
nontrivial) problem of deﬁning a distance between points that respects the necessary sym-
metries of the problem. Only exceptionally will this distance be a quadratic expression
of the parameters (coordinates) being used (i.e., only exceptionally will our parameters
correspond to Cartesian coordinates in the space). From this distance, a volume element
dV (x) = v(x) dx will be deduced, from which the expression f (x) = k v(x) of the ho-
mogeneous probability density will follow. Sometimes, we can directly deﬁne the volume
element without the need of a distance. We emphasize the need of deﬁning a distance — or
a volume element — in the parameter space, from which the notion of homogeneity will fol-
low. With this point of view, we slightly depart from the original work by Jeffreys and Jaynes.
6.3
Homogeneous Distribution for Elastic Parameters
Consider an ideally elastic, homogeneous (although perhaps anisotropic) medium. Hooke’s
law relating stress σ ij to strain εkℓcan be written
σ ij = cij
kℓεkℓ
,
(6.14)

6.3. Homogeneous Distribution for Elastic Parameters
165
where cij kℓis the tensor of elastic stiffnesses. Alternatively, one can write
εij = sij
kℓσ kℓ
,
(6.15)
where cij kℓis the tensor of elastic compliances. The stiffness and compliance tensors are
mutually inverse, and both are positive deﬁnite. In our language, they are Jeffreys tensors.
Because of the different symmetries among their components, there are only 21 degrees
of freedom to represent an ideally elastic medium. There are many possible choices for
the 21 quantities needed to represent an elastic medium. But whatever our choice for
these quantities, there is one general answer to the problem of obtaining the associated
homogeneous probability density.
In the 21-dimensional abstract space where each point represents one elastic medium,
there is only one choice of distance between two points (i.e., between two elastic media)
that has all the necessary invariances (it must satisfy the axioms of a distance, the expression
has to be the same when using stiffness or compliance, there must be invariance of scale).
The distance between the elastic medium M1 (represented by the stiffness tensor c1 or the
compliance tensor s1 ) and the elastic medium M2 (represented by the stiffness tensor c2
or the compliance tensor s2 ) is
D(M1, M2) = ∥log(c2 c−1
1 ) ∥= ∥log(s2 s−1
1 ) ∥
.
(6.16)
One should remember here that the logarithm of a tensor can be deﬁned using a Tay-
lor development. Equivalently, the logarithm of a (positive deﬁnite) tensor has the same
eigendirection as the original tensor but its eigenvalues are the logarithm of the original
eigenvalues. The norm of a tensor is deﬁned as usual.83
Once a deﬁnition of distance (a metric) has been introduced in a manifold, it is just a
matter of simple (although lengthy) computations to deduce an expression for the volume
element of the space (using the given coordinates). And once the volume element has been
expressed, the expression for the homogeneous probability density immediately follows, as
explained in Appendix 6.2.
Rather than developing the general theory here, let us concentrate on the much simpler
example where the elastic medium is isotropic. Then, only two quantities are required, for
instance, the incompressibility modulus and the shear modulus. These are a pair of Jeffreys
parameters (as they are eigenvalues of the stiffness tensor cij kℓ). It is quite elementary to
obtain the homogeneous probability density for these two parameters. Then, the expression
of the homogeneous probability density for other sets of elastic parameters, like the set
{Young’s modulus, Poisson ratio} or the set {Longitudinal wave velocity, Tranverse wave
velocity} is obtained using the Jacobian rule.
Let us develop this elementary theory.
6.3.1
Incompressibility Modulus and Shear Modulus
TheCartesianparametersofelastictheoryarethelogarithmoftheincompressibilitymodulus
and the logarithm of the shear modulus,
κ∗= log(κ/κ0)
,
µ∗= log(µ/µ0)
,
(6.17)
83For instance, the squared norm of a tensor ψij kℓis ∥ψ ∥2 = gip gjq gkr gℓs ψij kℓψpq rs , where gij are
the components of the metric tensor in the given coordinates.

166
Chapter 6. Appendices
where κ0 and µ0 are two arbitrary constants. The homogeneous probability density is
constant for these parameters (a constant that we set arbitrarily to one):
fκ∗µ∗(κ∗, µ∗) = 1
.
(6.18)
As is often the case for homogeneous ‘probability’ densities, fκ∗µ∗(κ∗, µ∗) is not normal-
izable. Using the Jacobian rule, it is easy to transform this probability density into the
equivalent one for the positive parameters themselves:
fκµ(κ, µ) = 1/(κ µ)
.
(6.19)
This 1/x form of the probability density remains invariant if we take any power of κ and
of µ . In particular, if instead of using the incompressibility κ we use the compressibility
γ = 1/κ , the Jacobian rule simply gives fγ µ(γ, µ) = 1/(γ µ) .
Associated with the probability density (6.18) is the Euclidean deﬁnition of distance
ds2 = (dκ∗)2 + (dµ∗)2
,
(6.20)
which corresponds, in the variables (κ, µ) , to
ds2 = (dκ/κ)2 + (dµ/µ)2
,
(6.21)
i.e., to the metric
gκκ
gκµ
gµκ
gµµ

=
1/κ2
0
0
1/µ2

.
(6.22)
6.3.2
Young Modulus and Poisson Ratio
The Young modulus Y and the Poisson ratio σ can be expressed as a function of the
incompressibility modulus and the shear modulus as
Y =
9 κ µ
3 κ + µ
,
σ = 1
2
3 κ −2µ
3 κ + µ
(6.23)
or, reciprocally,
κ =
Y
3 (1 −2σ)
,
µ =
Y
2 (1 + σ)
.
(6.24)
The absolute value of the Jacobian of the transformation is easily computed,
J =
Y
2 (1 + σ)2 (1 −2σ)2
,
(6.25)
and the Jacobian rule transforms the probability density (6.19) into
fYσ(Y, σ) =
1
κ µ J =
3
Y (1 + σ) (1 −2σ)
,
(6.26)

6.3. Homogeneous Distribution for Elastic Parameters
167
which is the probability density representing the homogeneous probability distribution for
elastic parameters using the variables (Y, σ) . This probability density is the product of the
probability density 1/Y for the Young modulus and the probability density
g(σ) =
3
Y (1 + σ) (1 −2σ)
(6.27)
for the Poisson ratio. This probability density is represented in Figure 6.1. From the
deﬁnition of σ
it can be demonstrated that its values must range in the interval −1 <
σ < 1/2 , and we see that the homogeneous probability density is singular at these points.
Although most rocks have positive values of the Poisson ratio, there are materials where σ
is negative (e.g., Yeganeh-Haeri et al., 1992).
Figure 6.1. The homogeneous probabil-
ity density for the Poisson ratio, as deduced from
the condition that the incompressibility and the
shear modulus are Jeffreys parameters.
It may be surprising that the probability density in Figure 6.1 corresponds to a homo-
geneous distribution. If we have many samples of elastic materials, and if their logarithmic
incompressibility modulus κ∗and their logarithmic shear modulus µ∗have a constant
probability density (which is the deﬁnition of homogeneous distribution of elastic materi-
als), then σ will be distributed according to the g(σ) of the ﬁgure.
To be complete, let me mention that with a change of variables xi ⇌xI , a metric
gij changes to
gIJ = TI
i TJ
j gij = ∂xi
∂xI
∂xj
∂xJ gij
.
(6.28)
The metric (6.21) then transforms into
gYY
gYσ
gσY
gσσ

=

2
Y 2
2
(1−2 σ) Y −
1
(1+σ) Y
2
(1−2 σ) Y −
1
(1+σ) Y
4
(1−2 σ)2 +
1
(1+σ)2

.
(6.29)
The surface element is
dSYσ(Y, σ) =
'
det g dY dσ =
3 dY dσ
Y (1 + σ)(1 −2σ)
,
(6.30)
a result from which expression (6.26) can be inferred.
Although the Poisson ratio has historical interest, it is not a simple parameter, as shown
byitstheoreticalbounds −1 < σ < 1/2 ortheformofthehomogeneousprobabilitydensity

168
Chapter 6. Appendices
(Figure 6.1). In fact, the Poisson ratio σ depends only on the ratio κ/µ (incompressibility
modulus over shear modulus), as we have
1 + σ
1 −2 σ = 3
2
κ
µ
.
(6.31)
The ratio J = κ/µ of two Jeffreys parameters being a Jeffreys parameter, a useful pair
of Jeffreys parameters may be {κ, J} . The ratio J = κ/µ has an easy to grasp physical
interpretation (as the ratio between the incompressibility and the shear modulus) and should
be preferred, in theoretical developments, to the Poisson ratio, as it has simpler theoretical
properties. As the name of the nearest metro station to the university of the author is Jussieu,
we accordingly call J the Jussieu ratio.
6.3.3
Longitudinal and Transverse Wave Velocities
Equation (6.19) gives the probability density representing the homogeneous probability
distribution of elastic media, when parameterized by the incompressibility modulus and the
shear modulus:
fκµ(κ, µ) = 1/(κ µ)
.
(6.32)
Should we have been interested, in addition, in the mass density ρ , then we would have
arrived (as ρ is another Jeffreys parameter) at the probability density
fκµρ(κ, µ, ρ) = 1/(κ µ ρ)
.
(6.33)
This is the starting point for this section.
What about the probability density representing the homogeneous probability distri-
bution of elastic materials when we use as parameters the mass density and the two wave
velocities? The longitudinal wave velocity α and the shear wave velocity β are related to
the incompressibility modulus κ and the shear modulus µ through
α =
'
(κ + 4µ/3)/ρ
,
β =
'
µ/ρ ,
(6.34)
and a direct use of the Jacobian rule transforms the probability density (6.33) into
fαβρ(α, β, ρ) =
1
ρ α β

3
4 −β2
α2

,
(6.35)
which is the answer to our question.
That this function becomes singular for α = 2 β/
√
3 is due to the fact that the
boundary α = 2 β/
√
3 cannot be crossed: the fundamental inequalities κ > 0 , µ > 0
impose that the two velocities are linked by the inequality constraint
α > 2 β/
√
3
.
(6.36)
Let us focus for a moment on the homogeneous probability density for the two wave
velocities (α, β) existing in an elastic solid (disregard here the mass density ρ ). We have
fαβ(α, β) =
1
α β

3
4 −β2
α2

.
(6.37)
This is displayed in Figure 6.2.

6.3. Homogeneous Distribution for Elastic Parameters
169
Figure 6.2. The joint homogeneous probabil-
ity density for the velocities (α, β) of the longitudinal
and transverse waves propagating in an elastic solid.
Contrary to the incompressibility modulus and the shear
modulus, which are independent parameters, the longi-
tudinal wave velocity and the transversal wave velocity
are not independent (see text for an explanation). The
scales for the velocities are unimportant: it is possible
to multiply the two velocity scales by any factor with-
out modifying the form of the probability (which is itself
deﬁned up to a multiplicative constant).
β
α
0
Let us demonstrate that the marginal probability density for both α and β is of the
form 1/x . For we have to compute
fα(α) =
 √
3 α/2
0
dβ f (α, β)
(6.38)
and
fβ(β) =
 +∞
2 β/
√
3
dα f (α, β)
(6.39)
(the bounds of integration can easily be understood by a look at Figure 6.2). These integrals
can be evaluated as
fα(α) = lim
ε→0
 √
1−ε
√
3 α/2
√ε
√
3 α/2
dβ f (α, β) = lim
ε→0
4
3 log 1 −ε
ε
 1
α
(6.40)
and
fβ(β) = lim
ε→0
 2 β/(√ε
√
3)
√
1+ε 2 β/
√
3
dα f (α, β) = lim
ε→0
2
3 log 1/ε −1
ε
 1
β
.
(6.41)
The numerical factors tend to inﬁnity, but this is only one more manifestation of the fact that
the homogeneous probability densities are usually improper (not normalizable). Dropping
these numerical factors gives
fα(α) = 1/α
(6.42)
and
fβ(β) = 1/β
.
(6.43)
It is interesting to note that we have here an example where two parameters look like Jeffreys
parameters, but are not, because they are not independent (the homogeneous joint probability
density is not the product of the homogeneous marginal probability densities).

170
Chapter 6. Appendices
It is also worth knowing that using slownesses instead of velocities ( n = 1/α, η =
1/β ) leads, as one would expect, to
fnηρ(n, η, ρ) =
1
ρ n η

3
4 −n2
η2

.
(6.44)
6.4
Homogeneous Distribution for Second-Rank Tensors
The usual deﬁnition of the norm of a tensor provides the only natural deﬁnition of distance
in the space of all possible tensors. This shows that, when using a Cartesian system of
coordinates, the components of a tensor are the Cartesian coordinates in the 6D space
of symmetric tensors. The homogeneous distribution is then represented by a constant
(nonnormalizable) probability density:
f (σxx, σyy, σzz, σxy, σyz, σzx) = k
.
(6.45)
Instead of using the components, we may use the three eigenvalues {λ1, λ2, λ3} of the tensor
and the three Euler angles {ψ, θ, ϕ} deﬁning the orientation of the eigendirections in the
space. As the Jacobian of the transformation
{σxx, σyy, σzz, σxy, σyz, σzx} ⇌{λ1, λ2, λ3, ψ, θ, ϕ}
(6.46)
is

∂(σxx, σyy, σzz, σxy, σyz, σzx)
∂(λ1, λ2, λ3, ψ, θ, ϕ)
 = (λ1 −λ2)(λ2 −λ3)(λ3 −λ1) sin θ
,
(6.47)
the homogeneous probability density (6.45) transforms into
g(λ1, λ2, λ3, ψ, θ, ϕ) = k (λ1 −λ2)(λ2 −λ3)(λ3 −λ1) sin θ
.
(6.48)
Although this is not obvious, this probability density is isotropic in spatial directions (i.e.,
the 3D referentials deﬁned by the three Euler angles are isotropically distributed). In this
sense, we recover isotropy as a special case of homogeneity.
Rule 6.8, imposing that any probability density of the variables {λ1, λ2, λ3, ψ, θ, ϕ}
has to tend to the homogeneous probability density (6.48) when the dispersion parameters
tend to inﬁnity imposes a strong constraint on the form of acceptable probability densities
that is, generally, overlooked.
For instance, a Gaussian model for the variables {σxx, σyy, σzz, σxy, σyz, σzx} is con-
sistent (as the limit of a Gaussian is constant).
This induces, via the Jacobian rule, a
probability density for the variables {λ1, λ2, λ3, ψ, θ, ϕ} , a probability density that is not
simple, but consistent. A Gaussian model for the parameters {λ1, λ2, λ3, ψ, θ, ϕ} would
not be consistent.
6.5
Central Estimators and Estimators of Dispersion
Probability densities are, in general, deﬁned over manifolds, and the deﬁnitions of the
‘center’ and of the ‘dispersion’ of the probability distribution are technically difﬁcult. In

6.5. Central Estimators and Estimators of Dispersion
171
the case where the probability density is deﬁned over a linear space (i.e., over a space where
sum and multiplication by a scalar make clear sense), the theory is very simple (as shown
below).
One-Dimensional Case
Given a normalized one-dimensional probability density function f (x) , deﬁned over a
variable x for which the expression | x2 −x1 | is an acceptable deﬁnition of distance,
consider the expression
sp(m) =
  +∞
−∞
dx | x −m |p f (x)
1/p
.
(6.49)
For given p , the value of m that makes sp minimum is termed the center of f (x) in the
ℓp-norm sense and is denoted by mp . The value m1 is termed the median, m2 is the mean
(or mathematical expectation), and m∞is the midrange. The following properties hold.
• Median (minimum ℓ1-norm):
 +∞
−∞
dx |x −m1| f (x)
minimum
⇔
 m1
−∞
dx f (x) =
 +∞
m1
dx f (x) = 1
2 .
(6.50)
• Mean (minimum ℓ2-norm):
 +∞
−∞
dx (x −m2)2 f (x)
minimum
⇔
m2 =
 +∞
−∞
dx x f (x)
. (6.51)
• Midrange (minimum ℓ∞-norm):
lim
p→∞
 +∞
−∞
dx |x −m∞|p f (x)
minimum
⇔
m∞= xmax + xmin
2
,
(6.52)
where xmax (resp., xmin ) is the maximum (resp., minimum) value of x for which
f (x) ̸= 0 .
The value of sp(m) at the minimum is termed the dispersion of f (x) in the ℓp-norm
sense and is denoted σp :
σp = sp(mp)
.
(6.53)
The value σ1 is termed the mean deviation , σ2 is the standard deviation, and σ∞is
the half-range. The following properties hold.
• Mean deviation (minimum ℓ1-norm):
σ1 =
 +∞
−∞
dx |x −m1| f (x)
⇔
σ1 =
 +∞
m1
dx x f (x) −
 m1
−∞
dx x f (x)
.
(6.54)

172
Chapter 6. Appendices
• Standard deviation (minimum ℓ2-norm):
σ2
2 =
 +∞
−∞
dx (x −m2)2 f (x)
⇔
σ2
2 =
 +∞
−∞
dx x2 f (x) −m2
2
.
(6.55)
• Half-range (minimum ℓ∞-norm):
σ∞=
lim
p→∞
  +∞
−∞
dx |x −m∞|p f (x)
1/p
⇔
σ∞= xsup −xinf
2
.
(6.56)
Multidimensional Case
Given a probability density function f (x) deﬁned for the vector variable x (element of
a linear space where the Euclidean norm of a vector makes sense), consider the operator
C(m) deﬁned by its components,
Cij(m) =

dx (xi −mi) (xj −mj) f (x)
.
(6.57)
The vector m that minimizes the determinant of C(m) is termed the mean (or mathematical
expectation) of x in the ℓ2-norm sense. It is given by
m2 =

dx x f (x)
.
(6.58)
The value at m = m2 of the operator in equation (6.57) is termed the covariance of x in
the ℓ2-norm sense, and is simply denoted by C :
C = C(m2)
.
(6.59)
The diagonal elements of C clearly equal the variances (square of standard deviations)
previously deﬁned:
Cii = (σ i)2
.
(6.60)
The covariance operator in the ℓ2-norm sense (or ordinary covariance operator) has the
following properties (see, for instance, Pugachev, 1965):
1. C is symmetric:
Cij = Cji
.
(6.61)
2. C is deﬁnite nonnegative: for any vector x ,
xt C−1 x ≥0
.
(6.62)

6.5. Central Estimators and Estimators of Dispersion
173
3. If C is positive deﬁnite, then, for any vector x , the quantity
∥x ∥= ( xt C−1 x )1/2
(6.63)
has the properties of a norm. It is termed the weighted ℓ2-norm of the vector x .
4. The correlation coefﬁcients ρij deﬁned by
ρij =
Cij
σ i σ j
(6.64)
have the property
−1 ≤ρij ≤+1
.
(6.65)
5. The probability density
f (x) = ( (2π)N det C )−1/2 exp

−1
2 (x −x0)t C−1 (x −x0)

,
(6.66)
where N is the dimension of the vector x , is normalized, with a mean value x0 and
covariance operator C (e.g., Dubes, 1968). From the results of problem (6.26), it
follows that among all the probability densities with given ℓ2-norm covariance oper-
ator, the Gaussian function has minimum information content (i.e., it has maximum
‘spreading’).
Intuitive estimation of the numerical value of a covariance is not easy, while it is
very easy to intuitively estimate the value of a correlation. In 2D, when the two standard
deviations and the correlation are estimated, equation (6.64) can be used to estimate the
covariance. See Figures 6.3–6.4.
Figure 6.3. A two-dimensional Gaussian plotted using three standard deviations
in each of the two axes for different values of the coefﬁcient of correlation.
Two variables for which ρ = 0 are called uncorrelated. The reader should keep
in mind that while the notion of independent variables is general (see section 1.2.8), the
notion of uncorrelated variables is not, and should only be used if the probability density
under consideration is approximately Gaussian. While (independent) ⇒(uncorrelated),
(uncorrelated) ⇏(independent), as illustrated in Figure 6.5.
The discussion of the multidimensional spaces has been limited to the ℓ2-norm case.
It is not easy to generalize these concepts to the general ℓp-norm case.

174
Chapter 6. Appendices
Figure 6.4. The gross intuitive es-
timation of the mean values and of the stan-
dard deviations of a two-dimensional prob-
ability density is easy, but this is not so for
the covariance. The covariance is better es-
timated by ﬁrst estimating the correlation,
then using equation (6.64).
Figure 6.5. The correlation ρ is a meaningful param-
eter only if the probability density under consideration is not too
far from a Gaussian. A circular probability density, for instance,
has zero correlation, but the variables are far from being inde-
pendent.
6.6
Generalized Gaussian
As shown in problem (6.26), among all the normalized probability densities f (x) with
ﬁxed ℓp-norm estimator of dispersion,
 +∞
−∞
dx |x −x0|p f (x) = (σp)p
,
(6.67)
the one with minimum information content (i.e., with maximum ‘spreading’) is given by
fp(x) =
p1−1/p
2 σp I(1/p) exp

−1
p
|x −x0|p
(σp)p

,
(6.68)
where I( · ) denotes the gamma function.
Figure 6.6 shows some examples with p respectively equal to 1 , 1.5 , 2 , 3 , and
10 . For p = 1 ,
f1(x) =
1
2 σ1
exp

−|x −x0|
σ1

,
(6.69)
and f1(x) is a symmetric exponential, centered at x = x0 with mean deviation equal to
σ1 . For p = 2 ,
f2(x) =
1
√
2 π σ2
exp

−1
2
( x −x0 )2
σ22

,
(6.70)
and f2(x) is a Gaussian function, centered at x = x0 with standard deviation equal to σ2 .
For p →∞,
f∞(x) =

1/(2 σ∞)
for x0 −σ∞≤x ≤x0 + σ∞
,
0
otherwise
,
(6.71)

6.7. Log-Normal Probability Density
175
Figure 6.6. Generalized Gaussians
of order p (centered at zero). The value p =
1 gives a double exponential, p = 2 gives
an ordinary Gaussian, and p = ∞gives a
boxcar function. The parameter σ of the ﬁgure
is the σp of the text.
and f∞(x) is a box function, centered at x = x0 with midrange equal to σ∞. Prob-
lem (6.32) shows that fp(x) is normalized to unity.
The function fp(x) deﬁned in equation (6.68) can be termed a generalized Gaussian,
because it generates a family of well-behaved functions containing the Gaussian function
as a particular case. Symmetric exponentials, Gaussian functions, and boxcar functions are
often used to model error distribution. The deﬁnition of a generalized Gaussian slightly
widens the possibility of choice.
6.7
Log-Normal Probability Density
The log-normal probability density is deﬁned by
f (x) =
1
(2π)1/2 s
1
x exp

−
1
2 s2

log x
x0
2 
.
(6.72)
Figure 6.7 shows some examples of this probability density.
Figure 6.7. The log-normal probability density
(equation (6.72)). Note that when the dispersion param-
eter s tends to ∞, the probability density tends to the
function 1/x , the homogeneous probability density for a
Jeffreys quantity.
The log-normal probability density is so called because the logarithm of the variable
has a normal (Gaussian) probability density. For the change of variables
x∗= β log(x/γ )
,
x = γ exp(x∗/β)
(6.73)
transforms f (x) into
f ∗(x∗) =
1
(2π)1/2 σ exp

−1
2
(x∗−x0∗)2
σ 2

,
(6.74)
with σ = s β , s = σ/β , and
x0
∗= β log(x0/γ )
,
x0 = γ exp(x0
∗/β)
.
(6.75)

176
Chapter 6. Appendices
In (6.73), the constant β is often loge 10 , which corresponds to deﬁning x∗=
log10( x/γ ) .
The constant γ often corresponds to the physical unit used for x (see
Example 1.30). Alternatively, the particular choice
x∗= 1
s log
 x
x0

,
x = x0 exp(s x∗)
(6.76)
leads to a Gaussian density with zero mean and unit standard deviation:
f ∗(x∗) =
1
(2π)1/2 exp

−(x∗)2
2

.
(6.77)
Figure 6.7 suggests that, for given x0 , when the dispersion s is very small, the log-
normal probability density tends to a Gaussian function. This is indeed the case. For,
when s →0 , f (x) takes signiﬁcant value only in the vicinity of x0 , and f (x) =
1
(2π)1/2 s
1
x0 exp(−1
2 s2 (−1 + x
x0 −· · · )2) , i.e.,
f (x) ≃
1
(2π)1/2 (s x0) exp

−1
2
(x −x0)2
(s x0)2

.
(6.78)
If, for given x0 , the dispersion s is very large, the log-normal probability density
tends to a log-uniform probability density (i.e., proportional to 1/x ; see section 1.2.4). For
any x not too close to the origin, the argument of the exponential in (6.72) can be taken as
null, thus showing that, at the limit s →∞,
f (x) ≃
1
(2π)1/2 s
1
x
.
(6.79)
The convergence of (6.72) into (6.79) is not a uniform convergence, in the sense that while
the function (6.79) tends to inﬁnity when x tends to 0 , the log-normal (6.72) takes the
value 0 at the origin. But for values of x of the same order of magnitude as x0 , the
approximation (6.79) is adequate (for instance, for the values x0 = 1 , s = 10 , the log-
normal function and the log-uniform function are indistinguishable in Figure 6.7).
As suggested in section 1.2.4, the log-normal probability density is often adequate
to represent probability distributions for variables that by deﬁnition are constrained to be
positive. The reader will easily verify that if a variable x has a log-normal distribution, the
variable y = 1/x has the same distribution.
The function
f (x) =
p1−1/p
2 s I(1/p)
1
x exp

−
1
p sp
 log x
x0

p
(6.80)
transforms, under the change of variables (6.73), into the generalized Gaussian
f ∗(x∗) =
p1−1/p
2 σ I(1/p) exp

−1
p
x∗−x∗
0
p
σ p

,
(6.81)
where σ and x0∗are given by (6). This suggests that 6.80 can be referred to as the
generalized log-normal in the ℓp-norm sense.

6.8. Chi-Squared Probability Density
177
6.8
Chi-Squared Probability Density
The probability density
fν(u) =
1
2ν/2 I(ν/2) u
ν
2 −1 e−u
2
(6.82)
is called the χ2 probability density with parameter ν (one usually says with ν degrees
of freedom). Sometimes, the variable u in equation (6.82) is denoted χ2 (leading to
ambiguous notations).
Figure 6.8 displays the χ2 probability density for some selected values of ν . Note
that, for ν = 1 , the value at the origin is inﬁnite, and that for ν = 2 , one has the Laplace
probability density (exponential law). For large values of ν , the χ2 probability density
can be roughly approximated (near its maximum) by a Gaussian probability density with
mean value ν and standard deviation
√
2ν .
Figure 6.8. The χ2 probability density for some selected values of ν .
First Property
Let y = {y1, . . . , yp} be a p-dimensional Gaussian random vector with mean value m
and covariance matrix C . With each random realization y0 of the vector y associate the
number
χ2 = (y0 −m)t C−1 (y0 −m)
.
(6.83)
Then, this random variable is distributed according to the χ2 probability density with p
degrees of freedom (see Rao, 1973, or Aﬁﬁand Azen, 1979).
Second Property
Let y be a p-dimensional Gaussian random vector with unspeciﬁed mean and with covari-
ance matrix C . Let A be a p × q matrix, with p ≥q , the matrix A having full rank
(so that, given y , the system y = A x is not underdetermined for x ). With each random
realization y0 of y associate the vector x0 deﬁned by the minimization of
χ2(x) = (A x −y0)t C−1 (A x −y0)
.
(6.84)
Then, the random variable χ2(x0) is distributed according to the χ2 probability density
with
ν = dim(y) −rank(A) = p −q
(6.85)
degrees of freedom (Rao, 1973).

178
Chapter 6. Appendices
We may note that, as the solution of the minimization problem is (this is a special case
of the ﬁrst of equations (3.37))
x0 = (At C−1 A)−1 At C−1 y0
,
(6.86)
we obtain, after some easy simpliﬁcations,
χ2(x0) = yt
0 (C−1 −C−1 A (At C−1 A)−1 At C−1) y0
.
(6.87)
Third Property
Setting
x = m , y =
d
m

, y0 =
 dobs
mprior

, C =
CD
0
0
CM

, A =
G
I

(6.88)
in the equations above, the theorem translates as follows.
Let y beann-dimensionalGaussianvectorwithunspeciﬁedmeanandwithcovariance
matrix CM . Let m be an m-dimensional Gaussian vector with unspeciﬁed mean and with
covariance matrix CM . Let G be an n × m matrix (of arbitrary rank). With each random
realization dobs of d and each random realization mprior of m associate the vector m0
deﬁned by the minimization of
χ2(m) = (G m −dobs)t C −1
D (G m −dobs) + (m −mprior)t C −1
M (m −mprior)
. (6.89)
Then, the random variable χ2(m0) is distributed according to the χ2 probability density
with
ν = dim(d) = n
(6.90)
degrees of freedom.
As above, we may note that, as the solution of the minimization problem is (ﬁrst of
equations (3.37))
m0 =

Gt C −1
D G + C −1
M
−1 
Gt C −1
D dobs + C −1
M mprior

,
(6.91)
one obtains, after some simpliﬁcations,
χ2(m0) = (G mprior −dobs)t (G CM Gt + C)−1 (G mprior −dobs)
.
(6.92)
Fourth Property
Let x be a random variable that may take the values {x1, x2, . . . , xn} with the probabilities
pi . The probabilities pi are assumed to be known a priori and are normed: n
i=1 pi = 1 .
A large number of realizations of the variable x have given the experimental frequen-
cies fi . As we must satisfy the constraint n
i=1 fi = 1 , the number of values fi that are
independent (i.e., the degrees of freedom) is n −1 .

6.9. Monte Carlo Method of Numerical Integration
179
Then, the random variable
χ2 =
n

i=1
(fi −pi)2
pi
(6.93)
is distributed according to the χ2 probability density with n−1 degrees of freedom. If the
probability distribution pi is not given a priori, but k parameters of the law are estimated
from the experimental frequencies (for instance, the mean and the variance), then the random
variable deﬁned by equation (6.93) is distributed according to the χ2 probability density
with n −k −1 degrees of freedom.
This is, of course, the basis of the well-known goodness-of-ﬁt test: one knows that
the variable χ2 in the sum (6.93) has a chi-squared distribution, so if the actually obtained
value of χ2 is too large (with respect to the values one may expect to randomly get from
the chi-squared distribution), the theoretical probabilities pi are not consistent with the
experimental frequencies fi .
Fifth Property
If x and y are two independent random variables distributed according to the χ2 law with,
respectively, nx and ny degrees of freedom, then the sum z = x + y is a random variable
distributed according to the χ2 law with nz = nx + ny degrees of freedom.
6.9
Monte Carlo Method of Numerical Integration
Consider an s -dimensional manifold M with coordinates {m1, . . . , ms} . For a point of
the manifold, we use the notation m ∈M .
Let φ(m) be an arbitrary scalar function deﬁned over M and assume that we need
to evaluate the sum
I =

M
dm φ(m) =

dm1 · · ·

dms


	
M
φ(m1, . . . , ms)
.
(6.94)
If M has ﬁnite volume, the simplest method of evaluating I numerically is to deﬁne a
regular grid of points in M , to compute φ(m) at each point of the grid, and to approximate
the integral in equation (6.94) by a discrete sum. But as the number of points in a regular
grid is a rapidly increasing function of the dimension of the space ( N proportional to
a constant raised to the power s ), the method becomes impractical for large-dimensional
spaces (say s ≥4 ). The Monte Carlo method of numerical integration consists of replacing
the regular grid of points with a pseudorandom grid generated by a computer code based
on a pseudorandom-number generator. Although it is not possible to give any general rule
for the number of points needed for an accurate evaluation of the sum (because this number
is very much dependent on the form of φ(m) ), it turns out in practical applications that,
for well-behaved functions, φ(m) can be smaller, by some orders of magnitude, than the
number of points needed in a regular grid.
Let p(m) be an arbitrary normed (

dm p(m) = 1) probability density over M that
we choose to use to generate pseudorandom points over M (the homogeneous probability

180
Chapter 6. Appendices
density is the simplest choice,84 but using a probability density that samples preferentially
the regions of the space where φ(m) has signiﬁcant values improves the efﬁciency of the
algorithm).
Deﬁning ψ(m) = φ(m)
p(m) , the sum we wish to evaluate can be written
I =

M
dm p(m) ψ(m)
.
(6.95)
Let m1, . . . , mN be a suite of N points collectively independent and randomly distributed
over M with a probability density p(m) . Deﬁning
ψn = ψ(mn)
,
IN =
1
N
N

n=1
ψn
,
VN =
N
N + 1
 1
N
N

n=1
ψ2
n −I 2
N

,
(6.96)
it can easily be seen that the mathematical expectation of IN is
⟨IN ⟩=

M
dm p(m) ψ(m) = I
,
(6.97)
so that IN is an unbiased estimate of I . Using the central limit theorem, it can be shown
(see, for instance, Bakhvalov, 1977) that, for large N , the probability that the relative error
| IN −I |/| I | is bounded as
| IN −I |
| I |
≤
k
√
V
| I |
√
N
,
(6.98)
where V is the (unknown) variance of ψ(m) , is asymptotically equal to
P(k) = 1 −
2
√
2π
 +∞
k
dt exp

−t2
2

.
(6.99)
For large N , a useful estimate of the right-hand side of equation (6.98) is
k
√
V
| I |
√
N
≃
k √VN
| IN |
√
N
,
(6.100)
where IN and VN are deﬁned in equations (6.96).
This method of numerical integration is used as follows: ﬁrst, one selects the value
of the conﬁdence level, P(k) , at which the bound equation (6.98) is required to hold (for
instance, P (k) = 0.99 ). The corresponding value of k is easily deduced using equa-
tion (6.99) and the error-function tables (k ≃3 for P(k) = 0.99) . A pseudorandom-
number generator is then used to obtain the points m1, m2, . . . distributed with the prob-
ability p(m) , and, for each new point, the right-hand side of equation (6.98) is estimated
using equation (6.100). The computations are stopped when this number equals the relative
accuracy desired (for instance, 10−3 ). The typical statement that can then be made is as
follows: The value of I can be estimated by IN , with a probability of P(k) (e.g., 99%)
for the relative error being smaller than ϵ (e.g., 10−3 ).
For more details, see, for instance, Hammersley and Handscomb (1964).
84This requires, in fact, that the manifold M have ﬁnite volume.

6.10. Sequential Random Realization
181
6.10
Sequential Random Realization
Let us write here the details of the decomposition of a joint probability density as a product
of one-dimensional marginals and conditionals.
Let us apply a ﬁrst time the partition of a joint probability density as the product of a
marginal and a conditional. Deﬁning
f1(x1) =

dx2 . . .

dxn fn(x1, x2, . . . , xn)
(6.101)
and
fn−1|1(x2, . . . , xn|x1) =
fn(x1, x2, . . . , xn)

dx2 . . .

dxn fn(x1, x2, . . . , xn) = fn(x1, x2, . . . , xn)
f1(x1)
(6.102)
gives
fn(x1, x2, . . . , xn) = f1(x1) fn−1|1(x2, . . . , xn|x1)
.
(6.103)
Let us apply the partition again. Deﬁning
f1|1(x2|x1) =

dx3 . . .

dxn fn−1|1(x2, . . . , xn|x1)
(6.104)
and
fn−2|2(x3, . . . , xn|x1, x2) =
fn−1|1(x2, . . . , xn|x1)

dx3 . . .

dxn fn−1|1(x2, . . . , xn|x1)
= fn−1|1(x2, . . . , xn|x1)
f1|1(x2|x1)
(6.105)
gives
fn−1|1(x2, . . . , xn|x1) = f1|1(x2|x1) fn−2|2(x3, . . . , xn|x1, x2)
,
(6.106)
and, with this, equation (6.103) can be written
fn(x1, x2, . . . , xn) = f1(x1) f1|1(x2|x1) fn−2|2(x3, . . . , xn|x1, x2)
.
(6.107)
Continuing this procedure, one arrives at
fn(x1, x2, . . . , xn) = f1(x1) f1|1(x2|x1) f1|2(x3|x1, x2) f1|3(x4|x1, x2, x3)
× · · · × f1|n−1(xn|x1, x2, . . . , xn−1)
,
(6.108)
expressing the joint probability density as a product of different conditional probability
densities.
This immediately suggests a method for generating a random point that only uses
one-dimensional random generations. One ﬁrst generates a random value for x1 using
the unconditional (marginal) density f1(x1) . This gives some value, say x1
0 . Given this
value, one then generates a random value for x2 using the conditional probability density
f1|1(x2|x1
0) . This gives some value, say x2
0 . Then, one generates a random value for
x3 using f1|2(x3|x1
0, x2
0) , and so on until one generates a random value for xn using
f1|n−1(xn|x1
0, x2
0, . . . , xn−1
0
) .

182
Chapter 6. Appendices
6.11
Cascaded Metropolis Algorithm
Let µ(x) be the homogeneous probability density and f1(x) , f2(x), . . . , fp(x) be p prob-
ability densities. Our goal here is to develop a Metropolis random walk that samples the
conjunction
h(x) = k µ(x) f1(x)
µ(x)
f2(x)
µ(x) . . . fp(x)
µ(x)
.
(6.109)
We need to deﬁne the likelihood functions (or volumetric probabilities)
ϕi(x) = fi(x) / µ(x)
.
(6.110)
Assume that some random rules deﬁne a random walk that samples a probability
density f1(x) . At a given step, the random walker is at point xi , and the application of the
rules would lead to a transition to point xj . When all such proposed transitions xi →xj
are accepted, the random walker will sample the probability density f1(x) . Instead of
always accepting the proposed transition xi →xj , we reject it sometimes by using the
following rules (to decide if the random walker is allowed to move to xj or if it must stay
at xi ) :
(a) If ϕ2(xj) ≥ϕ2(xi) , then go to step (c).
(b) If ϕ2(xj) < ϕ2(xi) , then decide randomly to go to step (c) or to reject the proposed
move, with the following probability of going to step (c):
P = ϕ2(xj) / ϕ2(xi)
.
(6.111)
(c) If ϕ3(xj) ≥ϕ3(xi) , then go to step (e).
(d) If ϕ3(xj) < ϕ3(xi) , then decide randomly to go to step (e) or to reject the proposed
move, with the following probability of going to step (e):
P = ϕ3(xj) / ϕ3(xi)
.
(6.112)
(e) If . . . , then go to . . . .
(f) If . . . , then decide randomly . . . .
(w) If ϕp−1(xj) ≥ϕp−1(xi) , then go to step (y).
(x) If ϕp−1(xj) < ϕp−1(xi) , then decide randomly to go to step (y) or to reject the
proposed move, with the following probability of going to step (y):
P = ϕp−1(xj) / ϕp−1(xi)
.
(6.113)
(y) If ϕp(xj) ≥ϕp(xi) , then accept the proposed transition to xj .
(z) If ϕp(xj) < ϕp(xi) , then decide randomly to move to xj or to stay at xi , with the
following probability of accepting the move to xj :
Pi→j = ϕp(xj) / ϕp(xi)
.
(6.114)
Then, the random walk samples the conjunction h(x) (equation (6.109)) of the probability
densities f1(x) , f2(x), . . . , fp(x) . This property immediately results from the validity of
the rule for the conjunction of two probability densities.

6.12. Distance and Norm
183
6.12
Distance and Norm
Let M be a space of points, with points denoted P1, P2, . . . . A distance over E associates
a real number with any pair of points (P1, P2) of E . This distance is denoted D(P1, P2)
and has the properties
D(P1, P2) = 0
⇔
P1 = P2
for any P1 and P2
,
D(P1, P2) = D(P2, P1)
for any P1 and P2
,
D(P1, P3) ≤D(P1, P2) + D(P2, P3)
for any P1, P2 , and P3 ,
(6.115)
the last property being called the triangular inequality (the length of one side of a triangle
is less than or equal to the sum of the lengths of the other two sides). When such a distance
has been deﬁned, M is termed a metric space.
Let V be a linear space. A norm over V associates a positive real number with any
element v of V . This norm is denoted ∥v∥and has the properties (parallel to those in
equations (6.115))
∥v∥= 0
⇔
v = 0
for any v
,
∥λv∥= |λ| ∥v∥
for any v and any real λ
,
∥v1 + v2∥≤∥v1∥+ ∥v2∥
for any v1 and v2
.
(6.116)
A linear space furnished with a norm is termed a normed linear space.
Let ( v1 , v2 ) denote a scalar product (see section 3.1.3).
From 0 ≤( v1 −
λv2 , v1 −λv2 ) = ( v1 , v1 ) −2 λ ( v1 , v2 ) + λ2 ( v2 , v2 ) , there follows, taking
λ = ( v1 , v2 )/( v2 , v2 ) ,
| ( v1 , v2 ) | ≤( v1 , v1 )1/2( v2 , v2 )1/2
(Cauchy–Schwarz inequality)
.
(6.117)
The expression
∥v ∥= ( v , v )1/2
(6.118)
deﬁnes a norm. Only the triangular property needs to be proved. We successively have
∥v1 + v2 ∥2
= ( v1 + v2 , v1 + v2 ) = ( v1 , v1 ) + 2 ( v1 , v2 ) + ( v2 , v2 ) =
∥v1 ∥2 + 2 ( v1 , v2 ) + ∥v2 ∥2 ≤∥v1 ∥2 + 2 | ( v1 , v2 ) | + ∥v2 ∥2 . Using the Cauchy–
Schwarzinequality(equation(6.117))gives ∥v1+v2 ∥2 ≤∥v1 ∥2+2 ∥v1 ∥∥v2 ∥+∥v2 ∥2 =
( ∥v1 ∥+ ∥v2 ∥)2 , from which the triangular inequality follows.
6.13
The Different Meanings of the Word Kernel
There are different mathematical meanings for the term ‘kernel.’ Let us recall the two main
ones.
a) A kernel may be a subspace. Let M and D be two linear spaces and G be a linear
operator mapping vectors of M into vectors of D : m →d = G m . The linear subspace
M0 ⊂M of elements m such that
G m = 0
(6.119)

184
Chapter 6. Appendices
is termed the kernel of G (or the null space of G0 ). If the kernel of a linear operator is not
reduced to the zero element, the operator is not invertible.
b) A kernel may be the representation of a linear operator. Let M and D be two
linear spaces and G be a linear operator mapping M into D . According to whether M or
D is a discrete or a continuous space, the abstract linear equation
d = G m
(6.120)
may take one of the following explicit representations:
di =

α
Giα mα
(α ∈IM , i ∈ID)
,
d(y) =

α
Gα(y) mα
(y ∈Vy , α ∈IM)
,
di =

Vx
dx Gi(x) m(x)
(i ∈ID , x ∈Vx)
,
d(y) =

Vx
dx G(y, x) m(x)
(y ∈Vy , x ∈Vx)
.
(6.121)
The matrix Giα , the arrays of functions Gα(y) or Gi(x) , and the function G(y, x) are
termed the kernel of the linear operator G .
6.14
Transpose and Adjoint of a Differential Operator
Let M and D represent two linear spaces and M∗and D∗be their respective duals. The
duality product of ˆd1 ∈D∗and d2 ∈D (resp., of ˆm1 ∈M∗and m2 ∈M ) is denoted
⟨ˆd1 , d2 ⟩D (resp., ⟨ˆm1 , m2 ⟩M ).
Let G be a linear operator mapping M into D . If the spaces M and D are ﬁnite-
dimensional discrete spaces, or if G is an ordinary integral operator between functional
spaces, the deﬁnitions of transpose and adjoint are as in section 3.1.2 (page 59) and sec-
tion 3.1.4 (page 61).
If G is a differential operator between functional spaces, these
deﬁnitions need some generalization.
Let G be a differential operator mapping the functional space M into the functional
space D , x = (x1, x2, x3, . . . ) be the (common) variables of these functional spaces,
V be the (generalized) volume under consideration, S be its boundary, and ni(x) be the
(contravariant)componentsoftheoutwardnormalunitvectoron S . Theformaltransposeof
G , Gt , is the unique operator mapping D∗into M∗such that the difference ⟨ˆd , Gm ⟩D −
⟨Gt ˆd , m ⟩M equals the volume integral of the divergence of a certain bilinear (vector)
form P(ˆd, m) ,
⟨ˆd , Gm ⟩D −⟨Gt ˆd , m⟩M =

V
dV (x) ( ∇iP i(ˆd, m) )(x)
,
(6.122)
where an implicit sum over i is assumed. Using Green’s theorem, this difference can be
written as the boundary integral of the ﬂux of the bilinear form:
⟨ˆd , Gm ⟩D −⟨Gt ˆd , m ⟩M =

S
dS(x) ni(x) P i(ˆd, m)(x)
.
(6.123)

6.14. Transpose and Adjoint of a Differential Operator
185
Although Gt is uniquely deﬁned by (6.122) or (6.123), the vector P[· , ·] is deﬁned except
for the possible addition of a divergence-free vector.
Example 6.2. The transpose of the gradient operator is the negative of the divergence
operator. Let V denote a volume in the physical (Euclidean) 3D space, bounded by a
surface S , and let (x, y, z) denote Cartesian coordinates. We consider a space of functions
m(x, y, z) deﬁned inside (and at the surface of) V . The gradient operator
∇=


∂/∂x
∂/∂y
∂/∂z


(6.124)
associates with a scalar function m(x, y, z) its gradient
d = ∇m =


∂m/∂x
∂m/∂y
∂m/∂z


.
(6.125)
Let us verify that the transpose of the gradient operator equals the divergence operator
with reversed sign:
∇t =
,
∂/∂x ∂/∂y ∂/∂z
-
= −∇
.
(6.126)
For any ˆd ∈D∗and m ∈M , we have
⟨ˆd , ∇m ⟩D −⟨∇t ˆd , m ⟩M
=

V
dV (x) ˆdi(x) ∂m
∂xi (x) +

V
dV (x) ∂ˆdi
∂xi (x) m(x)
=

V
dV (x) ∂
∂xi ( ˆdi(x) m(x) ) =

S
dS(x) ni(x) ˆdi(x) m(x)
,
(6.127)
and the components of the bilinear form are
P i(ˆd, m)(x) = ˆdi(x) m(x)
.
(6.128)
Example 6.3. Demonstration of (A B)t = Bt At . Let B : E →F and A : F →G .
Then, A B : E →G . From
⟨ˆg , A f ⟩G −⟨At ˆg , f ⟩F =

dV Di ai
,
⟨ˆf , B e ⟩F −⟨At ˆf , e ⟩E =

dV Di bi
,
(6.129)
it follows, setting f = B e and ˆf = At ˆg , that
⟨ˆg , A B e ⟩G −⟨At ˆg , B e ⟩F =

dV Di ai
,
⟨At ˆg , B e ⟩F −⟨Bt At ˆe , e ⟩E =

dV Di bi
,
(6.130)

186
Chapter 6. Appendices
and
⟨ˆg , A B e ⟩G −⟨Bt At ˆe , e ⟩eE =

dV Di (ai + bi)
,
(6.131)
i.e.,
(A B)t = Bt At
.
(6.132)
If the right-hand sides of (6.122)–(6.123) vanish for any m and ˆd ,

V
dV (x) ( ∇iP i(ˆd, m) )(x) =

S
dS(x) ni(x) P i(ˆd, m)(x) = 0
,
(6.133)
then the formal transpose is simply termed the transpose, and we have
⟨ˆd , Gm ⟩D = ⟨Gt ˆd , m ⟩M
.
(6.134)
In that case, we can harmlessly use all the equations involving transpositions as if we were
dealing with discrete spaces.
Usually, the domains of deﬁnition of G and Gt are restricted so as to satisfy (6.133).
It is then said that these domains of deﬁnition satisfy dual boundary conditions. See below
for an example.
In the special case where a linear operator W maps a space E into its dual E∗, then
Wt also maps E into ˆE . In that case, it may happen that Wt = W , and the operator W
is symmetric. Let us come to this deﬁnition with some care.
Assume that a linear operator W maps E0 ⊂E into Y , and deﬁne its transpose
Wt as mapping Y∗
1 ⊂Y∗into E∗. If the subspaces E0 and Y∗
1 satisfy dual boundary
conditions (see above), then
∀e0 ∈E0
,
∀ˆy1 ∈Y∗
1
,
⟨ˆy1 , W e0 ⟩Y = ⟨Wt ˆy1 , e0 ⟩E
.
(6.135)
If Y = E∗and we identify the bidual of E to E , then W : E0 →E∗and Wt : E1 →E∗,
and, by deﬁnition of transpose,
∀e0 ∈E0
,
∀e1 ∈E1
,
⟨e1 , W e0 ⟩E∗= ⟨Wt e1 , e0 ⟩E
.
(6.136)
Now, if
∀e0 ∈E0 ∩E1
,
∀e′ ∈E0 ∩E1
,
⟨W e , e′ ⟩E = ⟨Wt e , e′ ⟩E
,
(6.137)
the operator W is termed symmetric, the notation
W = Wt
(6.138)
is used, and the identities
⟨e , Wte′ ⟩E∗= ⟨W e , e′ ⟩E = ⟨Wt e , e′ ⟩E = ⟨e , We′ ⟩E∗
(6.139)
hold ∀e, e′ ∈E0 ∩E1 .

6.14. Transpose and Adjoint of a Differential Operator
187
In deﬁning the transpose of a linear operator, it is not assumed that the linear spaces
under consideration have a scalar product. If they do, then it is possible to deﬁne the adjoint
of a linear operator.
Let M and D represent two scalar product linear spaces. The scalar product of d1
and d2 (resp., of m1 and m2 ) is denoted (d1, d2)D (resp., (m1, m2)M ).
Using the same notation as above, the formal adjoint of G , G∗, is the unique operator
mapping D into M such that
( d , G m )D −( G∗d , m )M =

V
dV (x) ( ∇iP i(d, m) )(x)
,
(6.140)
or, using Green’s theorem,
( d , G m )D −( G∗d , m )M =

S
dS(x) ni(x) P i(d, m)(x)
.
(6.141)
Again, although G∗is uniquely deﬁned by (6.140) or (6.141), the vector P(·, ·) is deﬁned
for the addition of a divergence-free vector.
Let CM and CD be the covariance operators deﬁning the scalar products over M
and D , respectively (and, thus, the natural isomorphisms between M and D and their
respective duals):
(d1, d2)D = ⟨C −1
D d1 , d2 ⟩D
,
(6.142)
(m1, m2)M = ⟨C −1
M m1 , m2 ⟩M
.
(6.143)
Using, for instance, (6.122), we obtain
( d , G m )D −( CM Gt C −1
D d , m )M =

V
dV (x)DP i[d, m]
DXi
(x)
,
(6.144)
or, for short,
G∗= CM Gt C −1
D
.
(6.145)
The reader will easily give sense to and demonstrate the property
(A B)∗= B∗A∗
.
(6.146)
If the right-hand side of (6.140)–(6.141) vanishes for any m and d ,

V
dV (x) ( ∇iP i(d, m) )(x) =

S
dS(x) ni(x) P i(d, m)(x) = 0
,
(6.147)
then the formal adjoint is simply termed the adjoint, and we have
( d , Gm )D = ( G∗d , m )M
.
(6.148)
In the special case where a linear operator L maps a space E into itself, then the
adjoint operator L∗also maps E into itself. In that case, it may happen that L∗= L ,

188
Chapter 6. Appendices
and the operator L is self-adjoint. Let us replace duality products with scalar products in
the equations above.
Assume that a linear operator W maps E0 ⊂E into Y , and deﬁne its adjoint W∗as
mapping Y1 ⊂Y into E . If the subspaces E0 and Y1 satisfy dual boundary conditions
(see above), then
∀e0 ∈E0
,
∀y1 ∈Y1
,
(y1, We0)Y = (W∗y1, e0)E
.
(6.149)
If Y = E , then W : E0 →E and W∗: E1 →E , and, by deﬁnition of adjoint,
∀e0 ∈E0
,
∀e1 ∈E1
,
(e1, W e0)E = (W∗e1, e0)E
.
(6.150)
Now, if
∀e0 ∈E0 ∩E1
,
∀e′ ∈E0 ∩E1
,
(W e, e′)E = (W∗e, e′)E
,
(6.151)
the operator W is termed self-adjoint, the notation
W = W∗
(6.152)
is used, and the identities
(e, W∗e′)E = (We, e′)E = (W∗e, e′)E = (e, We′)E
(6.153)
hold ∀e, e′ ∈E0 ∩E1 .
It is easy to see that identities (6.153) deﬁne a scalar product, denoted W(e, e′) :
W(e, e′) = (e, W∗e′)E = (W e, e′)E = (W∗e, e′)E = (e, We′)E
.
(6.154)
If W is the operator deﬁning the original scalar product over E ,
W(e, e′) = (e, e′)E
,
(6.155)
it is named the weighting operator over E , or the inverse of the covariance operator over
E , and the following notation is used:
W(e, e′) = (e, e′)E = et W e′
.
(6.156)
Example 6.4. The transpose of the elastodynamics operator. Let L denote the elastic
waveequationoperatorthatwithadisplacementﬁeld µ(x , t) associatesitssource φ(x , t)
(volume density of external forces):
L µ = φ
.
(6.157)
Explicitly, using tensor notation,
ρ(x) ∂2ui
∂t2 (x, t) −
∂
∂xj

cijkl(x) ∂uk
∂xl (x, t)

= φi(x, t)
.
(6.158)

6.14. Transpose and Adjoint of a Differential Operator
189
Let µ ∈U and φ ∈F . Each source vector φ can be considered as a linear form
over the space of displacements:
⟨φ , µ ⟩=

V
dV (x) φi(x, t) ui(x, t) =

V
dV (x) φi(x, t) ui(x, t)
.
(6.159)
The physical dimension of ⟨φ , µ ⟩U is an action. Equation (6.139) allows us to identify
F as U∗, the dual of U . Furthermore, identifying the bidual of U with U , we see that L
and Lt both map U = F∗into F = U∗. We will now check under which conditions the
wave equation operator is symmetric:
Lt = L
.
(6.160)
For any ˆφ ∈F∗= U and any u ∈U = F∗,
⟨ˆφ , L µ ⟩F −⟨Lt ˆφ , µ ⟩U =

V
dV (x)
 t1
t0
dt ˆφi
.
ρ ∂2ui
∂t2 −
∂
∂xj

cijkl ∂uk
∂xl
/
−

V
dV (x)
 t1
t0
dt

ρ ∂2φi
∂t2 −
∂
∂xj

cijkl
∂ˆφk
∂xl
0
ui
=

V
dV (x)
 t1
t0
dt ∂
∂t

ρ

ˆφi
∂ui
∂t −∂ˆφi
∂t ui 0
−

V
dV (x)
 t1
t0
dt
∂
∂xj

cijkl 
ˆφi ∂uk
∂xl −∂ˆφk
∂xl ui 0
,
(6.161)
and the (time-space) components of the bilinear form are
P t( ˆφ, u)(x, t) = ρ(x)

ˆφi(x, t)∂ui
∂t (x, t) −∂ˆφi
∂t (x, t) ui(x, t)

,
(6.162)
P j( ˆφ, u)(x, t) = cijkl(x)
∂ˆφk
∂xl (x, t)ui(x, t) −ˆφi(x, t) ∂uk
∂xl (x, t)

.
(6.163)
Using Green’s theorem, we obtain
⟨ˆφ , L u ⟩F −⟨Lt ˆφ , u ⟩U
=

V
dV (x) ρ

ˆφi
∂ui
∂t −∂ˆφi
∂t ui
t1
t0
−
 t1
t0
dt

S
dS(x) nj cijkl 
ˆφi ∂uk
∂∂xl −∂ˆφk
∂xl ui 
.
(6.164)

190
Chapter 6. Appendices
Assume, for instance, that the ﬁelds µ(x, t) and ˆφ(x, t) satisfy the boundary condi-
tions
ui(x, t0) = 0
,
∂ui
∂t (x, t0) = 0
,
ˆφi(x, t1) = 0
,
∂ˆφi
∂t (x, t1) = 0
,
nj(x) cijkl(x) ∂uk
∂xℓ(x, t) = 0
,
nj(x) cijkl(x)∂ˆφk
∂xℓ(x, t) = 0
.
(6.165)
As expression (6.164) then vanishes, these are dual boundary conditions. If we only
consider ﬁelds µ(x, t) and ˆφ(x, t) satisfying these conditions, then
⟨ˆφ , L u ⟩F = ⟨Lt ˆφ , u ⟩U
,
(6.166)
and the symmetry property (6.160) holds. As we saw in section 5.8.7, when solving usual
inverse problems, we are actually faced with wave ﬁelds satisfying dual boundary conditions.
Notice that the usual textbooks (Morse and Feshbach, 1953; Courant and Hilbert,
1966; Dautray and Lions, 1984) talk about the “self-adjointness” of the wave equation
operator. This assumes that a scalar product can be deﬁned over U , which is not necessarily
the case (for instance, U may be a general Banach space). Only the symmetry of the wave
equation operator is needed, not the self-adjointness.
6.15
The Bayesian Viewpoint of Backus (1970)
In his paper “Inference from inadequate and inaccurate data,” Backus (1970a,b,c) made
the ﬁrst effort to formalize the probabilistic approach to inverse problems. Although indi-
gestible, the paper is historically important. The essentials of the theory are as follows.
The inﬁnite-dimensional linear model space M is assumed to be a Hilbert space with
scalar product denoted by (· , · ) . The true (unknown) model is denoted by mtrue .
n
measurements of physical properties of mtrue give the n real quantities d1, d2, . . . , dn ,
which are assumed linearly related with mtrue . Then, there exist n vectors g1, g2, . . . , gn
of M , called ‘data vectors,’ such that if m was mtrue , we could predict the n real quantities
d1, d2, . . . , dn by the scalar products
d1 = (g1, m)
,
d2 = (g2, m)
,
dn = (gn, m)
.
(6.167)
(In fact, introducing g1, g2, . . . , gn as elements of the dual of M , and considering duality
products instead of scalar products, allows us to drop the assumption that M is a Hilbert
space, which seems unnecessary.)
The n actual measurements give the values d1
obs, d2
obs, . . . , dn
obs , as well as an estima-
tion of the probabilistic distribution of experimental errors.
Backus is not interested in the description of mtrue itself, but only in the prediction
of m numerical properties of mtrue , which are also assumed to be linear functions of the
model:
δ1 = (γ 1, m)
,
δ2 = (γ 2, m)
,
· · ·
,
δm = (γ m, m)
,
(6.168)
where γ 1, γ 2, . . . , γ m are the ‘prediction vectors.’

6.16. The Method of Backus and Gilbert
191
The following ﬁnite-dimensional spaces are introduced:
• G : The n-dimensional linear space generated by the data vectors g1, g2, . . . , gn . It
is a subspace of M .
• D : The n-dimensional linear space where the measurements d1, . . . , dn may take
their values (in fact, ℜn ).
•  : The m-dimensionallinearspacegeneratedbythepredictionvectors γ 1, γ 2, . . . , γ m .
It is a subspace of M .
•  : The m-dimensional linear space where the predictions δ1, . . . , δm may take their
values (in fact, ℜm ).
• S : An arbitrary ﬁnite-dimensional subspace of M containing G and  as subspaces.
The n measurements only give information on the projection of mtrue over G . As
we are only interested in the m predictions, we only need information on the projection of
mtrue over  . We can then drop the inﬁnite-dimensional model space M from our attention
and only consider the ﬁnite-dimensional space S , which contains the projections of mtrue
overboth G and  . As S isﬁnitedimensional, thestandardBayesianinferencecanbeused.
For instance, let us denote by s a generic element of S . We can introduce the
probability density ρmeas(d | s) over D representing the density of probability of obtaining
d as the result of our measurements if (the projection of) the true model is s . This probability
density is practically obtained from the knowledge of the data vectors g1, g2, . . . , gm and
the error statistics of our measuring instruments (see, for instance, chapter 1). The a priori
information over S is described using a probability density ρprior(s) . The Bayes rule then
gives the posterior probability density over S ,
ρpost(s | dobs) = k ρmeas(dobs | s) ρprior(s)
,
(6.169)
where k is a normalization constant.
Once this posterior probability has been deﬁned over S , the corresponding prob-
ability over  is obtained as a marginal probability. As we know how to associate the
m-dimensional vector δ1, . . . , δm with any elements of  (equation (6.168)), it is then
easy to deduce the corresponding posterior probability over  , the space of predictions.
The conceptually important result proved by Backus (Theorem 29 on page 54 of
his paper) is that if Mprior is a cylinder measure over M , and for each choice of the
ﬁnite-dimensional space S the a priori probability over S is the corresponding marginal
probability of the cylinder measure Mprior , then all the posterior probability distributions
over S obtained from the Bayesian solution are marginal distributions of a single cylinder
measure Mpost over M . The results are then independent of the particular choice of S .
The simplest results are obtained for the smallest S , i.e., S = G +  .
This theory can be applied to linearized inverse problems, but does not generalize to
true nonlinear problems.
6.16
The Method of Backus and Gilbert
In a famous paper, Backus and Gilbert (1970) gave a conceptually simple philosophy for
dealing with linear, essentially underdetermined, problems.

192
Chapter 6. Appendices
Assume that a model is described by a function, m(r) , and that we consider a ﬁnite
amount of discrete data, d1, d2, . . . , dn , which are linear functionals of m(r) through
kernels Gi(r) :
di =

dr Gi(r) m(r)
.
(6.170)
The kernels Gi(r) are assumed regular enough for equation (6.170) to be an ordinary
integral equation.
The true (unknown) model is denoted mtrue(r) . The observed data are denoted di
obs
and are assumed error free. Then,
di
obs =

dr Gi(r) mtrue(r)
.
(6.171)
The problem is to obtain a good estimator of mtrue(r) at a given point r = r0 . Let
us denote this estimator by mest(r0) . As the forward problem is linear, Backus and Gilbert
impose that the value mest(r0) be a linear function of the observed data, i.e., they assume
the form
mest(r0) =

i
Qi(r0) di
obs
,
(6.172)
where, at a given point r0 , Qi(r0) are some constants. The problem now is to obtain the
best constants Qi(r0) . Inserting (6.171) into (6.172) gives
mest(r0) =

i
Qi(r0)

dr Gi(r) mtrue(r)
,
(6.173)
and deﬁning
R(r0, r) =

i
Qi(r0) Gi(r)
(6.174)
gives
mest(r0) =

dr R(r0, r) mtrue(r)
.
(6.175)
This last equation shows that the estimate at r
=
r0 will be a ﬁltered version of the
true value, with ﬁlter R(r0, r) . This ﬁlter is called the resolving kernel. We are only
able to see the true world through this ﬁlter. The sharper the ﬁlter is around r0 , the better
our estimate (see Figure 7.34). One can arbitrarily choose the coefﬁcients Qi(r0) . The
deltaness criterion consists of choosing these coefﬁcients in such a way that the resulting
resolving kernel is the closest to a delta function,
R(r0, r) ≃δ(r0 −r)
,
(6.176)
in which case
mest(r0) ≃mtrue(r0)
.
(6.177)

6.16. The Method of Backus and Gilbert
193
Using, for instance, a least-squares deltaness criterion

dr

R(r0, r) −δ(r0 −r)
2
minimum
(6.178)
gives (see Problem 7.20)
Qi(r0) =

i
(S−1)ijGi(r0)
,
(6.179)
where
Sij =

dr Gi(r) Gj(r)
.
(6.180)
This gives
mest(r0) =

i

j
Gi(r0) (S−1)ij dj
obs
,
(6.181)
which corresponds to the Backus and Gilbert solution for the estimation problem (the reader
will easily verify that the matrix S is regular if the Gj(r) are linearly independent, i.e.,
each datum depends differently on model parameters). Using (6.179), the resolving kernel
is given by
R(r0, r) =

i

j
Gi(r0) (S−1)ij Gj(r)
.
(6.182)
It is easy to see that the data predicted from mest(r) exactly verify the observations:
di
cal =

dr Gi(r) mest(r) =

j

k
Sij (S−1)jk dk
obs = di
obs
.
(6.183)
Using more compact notation, all previous equations can be rewritten as follows:
d = G m
,
dobs = G mtrue
,
mest = Qt dobs
,
R = Qt G
,
mest = R mtrue
,
R ≃I
,
mest ≃mtrue
,
∥R −I ∥2
minimum
,
Q = (G Gt)−1 G
,
mest = Gt (G Gt)−1 dobs
,
and
R = Gt (G Gt)−1 G
.
(6.184)

194
Chapter 6. Appendices
Of course, there is no reason for the estimate mest to equal the true model mtrue ,
which is generally not attainable with a ﬁnite amount of data. But as Backus and Gilbert
assume exact data, it is easy to show that the true model is necessarily of the form
m = mest + (I −R) m0
,
(6.185)
where m0 is an arbitrary model.
For it is sufﬁcient to verify, using the last of equa-
tions (6.184), that (I −R) m0 belongs to the null space of G , i.e., it is such that
G ( (I −R) m0 ) = 0
.
(6.186)
Then,
G m = G mest = G mtrue = dobs
.
(6.187)
For Backus and Gilbert, the solution mest = Gt (G Gt)−1 dobs gives a particular solution
of the inverse problem, while m = mest + (I −R) m0 gives the general solution.
Let us make the comparison between Backus and Gilbert’s philosophy and the prob-
abilistic approach. For Backus and Gilbert, mest is the best estimate of mtrue and turns
out to be a ﬁltered version of it. From a probabilistic point of view, we have some a priori
information on mtrue described through the a priori model mprior and the a priori covari-
ance operator CM . Observations dobs have estimated errors described by CD . If a priori
information and observational errors are adequately described using the Gaussian hypoth-
esis, then the posterior probability in the model space is also Gaussian, with mathematical
expectation (third of equations (3.37))
m = mprior + CM Gt 
G CM Gt + CD
−1 
dobs −G mprior

(6.188)
and posterior covariance operator (second of equations (3.38))
CM = CM −CM Gt 
G CM Gt + CD
−1 G CM
.
(6.189)
Backus and Gilbert do not use a priori information in the model space. This corresponds
in a probabilistic context to the particular assumption of white noise (inﬁnite variance and
null correlations):
CM ≃k I
(k →∞)
.
(6.190)
Equations (6.188)–(6.189) give then, respectively,
m = Gt (G Gt)−1 dobs + (I −R) mprior
,
CM = (I −R) CM
.
(6.191)
The ﬁrst of these equations is identical to equation (6.185), where mprior replaces the
arbitrary m0 . Note that if R ≃I , in the Backus and Gilbert context mest ≃mtrue , while
in the probabilistic context, CM ≃0 (no error in the a posteriori solution), which means
the same thing. I believe that the probabilistic approach is richer than the mathematical
approach of Backus and Gilbert, but they probably feel the opposite way.
Please also read Example 5.24.

6.17. Disjunction and Conjunction of Probabilities
195
6.17
Disjunction and Conjunction of Probabilities
6.17.1
Conjunction of Probabilities
Let X be the ﬁnite-dimensional manifold where we assume our probability distributions are
deﬁned. In section 1.2.6, the conjunction P1 ∧P2 of two probability distributions P1 and
P2 was introduced. Let us ﬁnd an explicit expression for this operation using probability
densities. Let f1(x) , f2(x) , and µ(x) be the probability densities deﬁned by the condition
that, for any A ⊂X ,
P1(A) =

A
dx f1(x)
,
P2(A) =

A
dx f2(x)
,
M(A) =

A
dx µ(x) ,
(6.192)
where M is the homogeneous probability distribution. We seek the probability density
(f1 ∧f2)(x) deﬁned by the condition that, for any A ,
(P1 ∧P2)(A) =

A
dx (f1 ∧f2)(x)
.
(6.193)
One of the conditions deﬁning P1 ∧P2 is that, for any A ,
P1(A) = 0
⇒
(P1 ∧P2)(A) = 0
.
(6.194)
In mathematical terminology, this condition means that the probability (P1 ∧P2) is abso-
lutely continuous with respect to the probability P1 . The Radon–Nikodym theorem (e.g.,
Taylor, 1966) then states that there exists a unique positive function φ1(x) such that, for any
A ⊆X , (P1 ∧P2)(A) =

A dx f1(x) φ1(x) . Of course, this function φ1 may depend on
f1 , f2 , and µ , so we may, more explicitly, use the notation φ(x; f1, f2, µ) for it.85 Then,
for any A ,
(P1 ∧P2)(A) =

A
dx f1(x) φ1(x; f1, f2, µ)
.
(6.195)
Similarly, the condition P2(A) = 0 ⇒(P1 ∧P2)(A) = 0 implies that there exists a
positive function φ2(x; f2, f1, µ) such that, for any A ,
(P1 ∧P2)(A) =

A
dx f2(x) φ2(x; f2, f1, µ)
.
(6.196)
As the conjunction operation is commutative, one can permute f1 and f2 in these
equations, from which it follows that φ2 = φ1 . Denoting this unique function by φ allows
us to write
(P1 ∧P2)(A) =

A
dx f1(x) φ(x; f1, f2, µ) =

A
dx f2(x) φ(x; f2, f1, µ)
. (6.197)
85To understand this possible dependence of φ1 on both f1 and f2 , consider one possible solution
to the condition (6.194), (P1 ∧P2)(A) =

A dx min( f1(x) , f2(x) ) , in which case φ1(x; f1, f2, µ) =
min( f1(x) , f2(x) ) / f1(x) .

196
Chapter 6. Appendices
To introduce more symmetric notation, rather than using the function φ , let us intro-
duce the function ω deﬁned, for any probability densities f and g , through
φ(x; f, g, µ) =
g(x)
ω(x; f, g, µ)
.
(6.198)
Then,
(P1 ∧P2)(A) =

A
dx
f1(x) f2(x)
ω(x; f1, f2, µ) =

A
dx
f1(x) f2(x)
ω(x; f2, f1, µ)
,
(6.199)
demonstrating that the function ω is symmetric in f1 and f2 ,
ω(x; f1, f2, µ) = ω(x; f2, f1, µ)
.
(6.200)
The condition that, for any probability distribution P , P ∧M = M ∧P = P ,
imposes that, for any f ,
ω(x; f, µ, µ) = ω(x; µ, f, µ) = µ(x)
.
(6.201)
The simplest solution is obtained when taking ω(x; f1, f2, µ) independent of f1 and
f2 , ω(x; f1, f2, µ) = ν µ(x) , where ν is a constant. Then, the probability density (f1 ∧
f2)(x) representing the conjunction P1 ∧P2 is
(f1 ∧f2)(x) = 1
ν
f1(x) f2(x)
µ(x)
,
(6.202)
where ν is the normalization constant ν =

X dx f1(x) f2(x)
µ(x)
.
6.17.2
Disjunction of Probabilities
Let us now turn our attention to the disjunction P1 ∨P2 , using the notation introduced
above. We seek here the probability density (f1 ∨f2)(x) deﬁned by the condition that, for
any A ,
(P1 ∨P2)(A) =

A
dx (f1 ∨f2)(x)
.
(6.203)
One of the conditions deﬁning P1 ∨P2 is that, for any A ,
P1(A) ̸= 0
⇒
(P1 ∨P2)(A) ̸= 0
.
(6.204)
Using a line of reasoning quite similar to that used above, we arrive at the expression
(P1 ∨P2)(A) = k

A
dx ( f1(x) + f2(x) + ω(x; f1, f2, µ) )
,
(6.205)
where k is a constant and ω is an arbitrary nonnegative function symmetric in f1 and f2 :
ω(x; f1, f2, µ) = ω(x; f2, f1, µ)
.
(6.206)

6.18. Partition of Data into Subsets
197
The simplest solution is obtained when taking ω(x; f, µ, µ) equal to zero. In that
case, the measure density (f1 ∨f2)(x) representing the disjunction P1 ∨P2 is
(f1 ∨f2)(x) =
1
2 ( f1(x) + f2(x) )
.
(6.207)
6.18
Partition of Data into Subsets
In a linear least-squares problem, if a data set can be divided into two subsets such that the
covariances between the different subsets are zero,
dobs =


d1
d2
d3
...


,
CD =


K1
0
0
· · ·
0
K2
0
· · ·
0
0
K3
· · ·
...
...
...
...


,
(6.208)
then solving one global inverse problem is equivalent to solving a series of smaller problems,
introducing the data sets one by one, and using the posterior solution of each partial problem
(model and covariance matrix) as prior information for the next.
We need to introduce the partitioned matrix
G =


G1
G2
G3
...


,
(6.209)
and, for more clarity in the notation, let us modify the notation introduced in chapter 3,
writing
m0 ≡mprior
,
CM ≡C0
.
(6.210)
Then, asdemonstratedbelow, solvingthegloballinearproblemusingequations(3.37)–
(3.38) of chapter 3 is equivalent to solving a series of partial problems according to the
algorithm
mi+1 = mi + Ci Gt
i+1 (Ki+1 + Gi+1 Ci Gt
i+1)−1 (di+1 −Gi+1 mi)
,
Ci+1 = Ci −Ci Gt
i+1 (Ki+1 + Gi+1 Ci Gt
i+1)−1 Gi+1 Ci
.
(6.211)
Equivalently, using the matrix identities given in Appendix 6.30,
mi+1 = mi + (Gt
i+1 K−1
i+1 Gi+1 + C−1
i )−1 Gt
i+1 K−1
i+1 (di+1 −Gi+1 mi)
,
Ci+1 = (Gt
i+1 K−1
i+1 Gi+1 + C−1
i )−1
.
(6.212)
When the last data set has been taken into account in this way, we get exactly the same
solution (model vector and covariance matrix) as we would have obtained using equa-
tions (3.37)–(3.38) (see demonstration below).

198
Chapter 6. Appendices
We see that, at each step, to integrate the data set di+1 , the previous model mi and
the previous covariance matrix Ci must be used. This way of solving a linear least-squares
problem is reminiscent of the Kalman ﬁlter (Kalman, 1960), which applies to a slightly
different problem.
In the form proposed in equations (6.211), the matrix to be inverted at each step has the
dimension of the data subset being integrated. If all the data have independent uncertainties
(i.e., if the original matrix CD is diagonal), then we can integrate the data one by one, and
there is no matrix to be inverted any more, as the term Ki+1 + Gi+1 Ci Gt
i+1 degenerates
into a scalar.
The reader is invited to verify that the following very simple computer code solves
the least-squares linear inverse problem in the special case where data uncertainties are
uncorrelated.
subroutine oneone(nd,nm,d0,cd,m0,cm,g,q)
dimension d0(nd),cd(nd),m0(nm),cm(nm,nm),g(nd,nm),q(nm)
do k = l,nd
v = d0(k)
do i = 1,nm
v = v - g(k,i)*m0(i)
q(i) = 0.
do j = l,nm
q(i) = q(i) + cm(i,j)*g(k,j)
end do
end do
a = cd(k)
do i = l,nm
a = a + g(k,i)*q(i)
end do
do i = l,nm
m0(i) = m0(i) + q(i)*v/a
do j = 1,nm
cm(i,j) = cm(i,j) - q(i)*q(j)/a
end do
end do
end do
return
end
Let us now move to the demonstration. It is done when only two data subsets are
considered, but the generalization is obvious.
The least-squares solution is (see section 3.2.2)
m = mprior +

Gt C −1
D G + C −1
M

−1Gt C −1
D (dobs −G mprior)
,
CM =

Gt C −1
D G + C −1
M
−1
.
(6.213)

6.18. Partition of Data into Subsets
199
Introducing
d1
d2

=
G1
G2

m
,
(6.214)
we have
m = mprior +
(*
Gt
1
Gt
2
+ C−1
1
0
0
C−1
2
 G1
G2

+ C −1
M
)−1 *
Gt
1 Gt
2
+
×
C−1
1
0
0
C−1
2
 ( d1
d2

−
G1
G2

mprior
)
= mprior + (S0 + S1 + S2)−1
Gt
1 C−1
1 (d1 −G1 mprior) + Gt
2 C−1
2 (d2 −G2 mprior

,
(6.215)
where
S0 = C −1
M
,
S1 = Gt
1 C−1
1 G1
,
S2 = Gt
2 C−1
2 G2
.
(6.216)
The following identity holds:
(S0 + S1 + S2)−1 = (S0 + S1 + S2)−1
(S0 + S1 + S2) −S2

(S0 + S1)−1
= (S0 + S1 + S2)−1(S0 + S1 + S2)

I −(S0 + S1 + S2)−1 S2

(S0 + S1)−1
=

I −(S0 + S1 + S2)−1 S2

(S0 + S1)−1
= (S0 + S1)−1 −(S0 + S1 + S2)−1 S2 (S0 + S1)−1
.
(6.217)
This gives
m = mA +

Gt
2 C−1
2 G2 + C−1
A

−1Gt
2 C−1
2 (d2 −G2 mA)
(6.218)
and
CM =

Gt
2 C−1
2 G2 + C−1
A

−1
,
(6.219)
where
mA = mprior +

Gt
1 C−1
1 G1 + C −1
M

−1Gt
1 C−1
1 (d1 −G1 mprior)
(6.220)
and
CA =

Gt
1 C−1
1 G1 + C −1
M

−1
.
(6.221)

200
Chapter 6. Appendices
6.19
Marginalizing in Linear Least Squares
Let d = G m be the equation solving the forward problem, and let dobs , CD , mprior , and
CM be as usual in least-squares problems. The solution in the least-squares sense is given,
for instance, by (see section 3.2.2)
m = mprior +

Gt C −1
D G + C −1
M

−1Gt C −1
D (dobs −G mprior)
,
(6.222)
and the posterior covariance operator is given, for instance, by
CM =

Gt C −1
D G + C −1
M

−1
.
(6.223)
Assume that we can partition the model vector into
m =
m1
m2

,
with
CM =
C1
0
0
C2

,
(6.224)
and that we are only interested in m1 . Let us derive the corresponding formulas.
Introducing
Fd = dobs −G mprior
,
Fm = m −mprior
,
G =
,
G1 G2
-
,
(6.225)
we obtain
Fm1
Fm2

=
S11
S12
S21
S22
−1 Gt
1
Gt
2

C −1
D Fd
,
(6.226)
where
S11 = Gt
1 C −1
D G1 + C−1
1
, S22 = Gt
2 C −1
D G2 + C−1
2
, S12 = Gt
1 C −1
D G2 , S12 = St
12 .
(6.227)
Using an inversion per block (see Appendix 6.31) gives
Fm1
Fm2

=
A
B
C
D
 Gt
1
Gt
2

C −1
D Fd
,
(6.228)
where
A = (S11 −S12 S−1
22 St
12)−1 ,
D = (S22 −St
12 S−1
11 S12)−1 ,
B = −A S12 S−1
22 ,
C = Bt .
(6.229)
For Fm1 we obtain
Fm1 = (A Gt
1 + B Gt
2) C −1
D Fd
.
(6.230)
This gives
Fm1 = (S11 −Gt
1 T22G1)−1Gt
1 (C −1
D −T22) Fd
,
(6.231)

6.20. Relative Information of Two Gaussians
201
where
T22 = C −1
D G2 S22
−1 Gt
2 C −1
D
.
(6.232)
The a posteriori covariance operator for m1 clearly equals A .
The previous formulas allow us to take into consideration model parameters that,
although not interesting in themselves, are poorly known, and they introduce uncertainties
that cannot be ignored.
6.20
Relative Information of Two Gaussians
Let f1(x) and f0(x) represent two normalized probability density functions. The relative
information on f1 with respect to f0 is deﬁned by
I(f1; f0) =

dx f1(x) log f1(x)
f0(x)
.
(6.233)
Let us demonstrate that if f1 and f0 are Gaussian probability densities with mathematical
expectations respectively equal to x1 and x0 and covariance operators respectively equal
to C1 and C0 , then
I(f1; f0) = log det1/2 C0
det1/2 C1
+ 1
2 (x1 −x0)t C−1
0 (x1 −x0) + 1
2 trace(C1 C−1
0
−I)
.
(6.234)
By deﬁnition,
f1(x) =
1
(2π)n/2 det1/2 C1
exp

−1
2 (x −x1)t C−1
1 (x −x1)

(6.235)
and
f0(x) =
1
(2π)n/2 det1/2 C0
exp

−1
2 (x −x0)t C−1
0 (x −x0)

.
(6.236)
Inserting these expressions in equation (6.233) gives
I(f1; f0) = log
det1/2 C0
det1/2 C1

−1
2 E1

(x −x1)t C−1
1 (x −x1)

+ 1
2 E1

(x −x0)t C−1
0 (x −x0)

,
(6.237)
where E1(·) denotes the mathematical expectation with respect to f1 :
E1(8(x)) ≡

dx f1(x) 8(x)
.
(6.238)
From the deﬁnition of covariance operator, and using the linearity of the mathematical
expectation, we obtain C1 = E1( (x −x1)(x −x1)t ) = E1( x xt −2 x1 xt + x1 x1t ) =

202
Chapter 6. Appendices
E1(x xt) −2 x1 E1(xt) + x1 x1t = E1(x xt) −x1 x1t , whence, using a tensor notation, we
deduce
E1(xα xβ) = C1
αβ + x1
α x1
β
.
(6.239)
Wehave E1( (x −x1)t C−1
1 (x−x1) )=· · · =E1(xt C−1
1 x)−xt
1 C−1
1 x1 =(C−1
1 )
αβ E1(xα xβ)
−(C−1
1 )
αβ x1α x1β , whence, using equation (6.239), we deduce
E1

(x −x1)t C−1
1 (x −x1)

= (C−1
1 )
αβ C1
αβ = trace I
.
(6.240)
We also have E1( (x −x0)t C−1
0 (x−x0) ) = · · · = E1(xt C−1
0 x)−2 x0t C−1
0 x1+x0t C−1
0 x0
= (C−1
0 )
αβ E1(xα xβ) −2 (C−1
0 )
αβ x0α x1β + (C−1
0 )
αβ x0α x0β , whence, using equation
(6.239), we deduce
E1

(x −x0)t C−1
0 (x −x0)

= (C−1
0 )
αβ (C−1
0 )
αβ + (C−1
0 )
αβ (x1
α −x0
α)(x1
β −x0
β)
= trace (C−1
0 C1) + (x1 −x0)t C−1
0 (x1 −x0)
.
(6.241)
Inserting (6.240) and (6.241) into (6.237), result (6.234) follows.
Notice that the factor det1/2 C represents the (hyper)volume of the hyperellipsoid
representing the covariance operator C .
6.21
Convolution of Two Gaussians
Let us evaluate the sum
I =

dd exp

−1
2

(d −d0)t C −1
d
(d −d0) + (d −g(m))t C −1
T
(d −g(m))
 
.
(6.242)
The separation of the quadratic terms from the linear terms leads to
I =

dd exp

−1
2 (dt A d −2 bt d + c)

,
(6.243)
where
A = C −1
d
+ C −1
T
,
bt = d0
t C −1
d
+ g(m)t C −1
T
,
c = d0
t C −1
d
d0 + g(m)t C −1
T
g(m)
.
(6.244)
Since A is positive deﬁnite, it follows that
I =

dd exp

−1
2

(d −A−1 b)
t A (d −A−1 b) + (c −bt A−1 b)
 
= exp

−1
2 (c −bt A−1 b)
 
dd exp

−1
2 (d −A−1 b)
t A (d −A−1 b)

= (2π)n/2 (det A)−1/2 exp

−1
2 (c −bt A−1 b)

.
(6.245)

6.22. Gradient-Based Optimization Algorithms
203
By substitution we obtain
c −bt A−1 b = d0
t 
C −1
d
−C −1
d (C −1
d
+ C −1
T )−1 C −1
d

d0
+ g(m)t 
C −1
T
−C −1
T (C −1
d
+ C −1
T )−1 C −1
T

g(m)
−2 g(m)t C −1
T
(C −1
d
+ C −1
T )−1 C −1
d
d0
.
(6.246)
Thus, by using the two identities demonstrated in Appendix 6.30, we get
c −bt A−1 b = dt
0 (Cd + CT)−1 d0 + g(m)t (Cd + CT)−1 g(m) −2 g(m)t (Cd + CT)−1 d0
= (d0 −g(m))t (Cd + CT)−1 (d0 −g(m))
.
(6.247)
Finally,
I = (2π)n/2 det (C −1
d
+ C −1
T )
-1/2 exp

−1
2 (d0 −g(m))t (Cd + CT)−1 (d0 −g(m))

.
(6.248)
6.22
Gradient-Based Optimization Algorithms
There are two fundamentally different methods of optimization, those based on the local
computation of the function to be optimized and those based on a random search. We are
interested here in the ﬁrst class of methods. The advantage of the gradient-based method is
that, when it works, it may be very efﬁcient. The disadvantage is that the local properties of
the function to be optimized may be of little interest — if the function is complex enough.
Gradient methods may have increasing levels of sophistication. The simplest meth-
ods just use the local direction of steepest ascent (or descent). Or this direction may be
preconditioned using different operators (ranging from ad hoc ﬁxed operators to variable
metric operators, passing by the Newton methods).
Some of the results given below are applicable when an ℓp-norm is used in the model
space, and some results are only valid for least-squares (ℓ2-norm) problems. My own
experienceisthatwhilesophisticatedmethodsmayworkwellforleast-squaresproblems, the
simpler (steepest descent) methods are preferable for general ℓp-norm problems: although
many techniques are presented as valid for nonquadratic optimization problems, ℓp-norm
optimization problems may be so strongly nonquadratic that they may fail. Figure 6.9
shows a function used as an example by Gill, Murray, and Wright (1981). It is obviously a
nonquadratic function, but it is not strongly nonquadratic.
There are many good books on gradient methods.
English books (Walsh, 1975;
Fletcher, 1980; Powell, 1981; Scales, 1985) are excellent for their empirical taste. French
books (Céa, 1971; Ciarlet, 1982) are good at generality.
6.22.1
Gradient, Hessian, Steepest Ascent, Curvature
Gradient and Hessian of a Scalar Function
Let m →ψ(m) be a nonlinear form (i.e., an application into ℜ) over a ﬁnite-dimensional
linear space M (this linear space is not (yet) assumed to be normed).

204
Chapter 6. Appendices
Figure 6.9. The Rosenbrock function S(x, y) = 100(y −x2)2 + (1 −x)2 , often
used to test optimization algorithms. It has a unique minimum at point (x, y) = (1, 1) . Gill,
Murray, and Wright (1981) show the minimization paths obtained with different algorithms,
all initialized at (x, y) = (−1.2, 1.0) . Top left: Steepest descent algorithm. Note that the
algorithm would have failed in the vicinity of the point (x, y) = (−0.3, 0.1) but for the fact
that the linear search found, by chance, the second minimum along the search direction.
Several hundred iterations were performed close to the new point without any perceptible
change. Top right: Conjugate directions algorithm. Although the method is not intended
for problems with such a small number of parameters, the ﬁgure is useful in illustrating
the cyclic nature of the algorithm. Bottom left: Modiﬁed Newton’s algorithm. The method
follows the base of the valley in an almost optimal number of steps. Bottom right: Variable
metric algorithm. Like Newton’s method, the algorithm makes good progress at points
remote from the solution.
A series development of ψ(m) around a point m0 can be written, using different
notation, as
ψ(m0 + δm) = ψ(m0) + ⟨ˆγ 0 , δm ⟩+ 1
2 ⟨ˆH0 δm , δm ⟩+ O(3)
= ψ(m0) + ˆγ t
0 δm + 1
2 ( ˆH0 δm)t δm + O(3)
= ψ(m0) + ( ˆγ 0)α δmα + 1
2 ( ˆH0)αβ δmα δmβ + O(3)
,
(6.249)
where ˆγ 0 is the gradient of ψ at point m0 and ˆH0 is the Hessian:
( ˆγ 0)α =
 ∂ψ
∂mα

m0
,
( ˆH0)αβ =
 ∂ˆγα
∂mβ

m0 =

∂2ψ
∂mα∂mβ

m0
.
(6.250)
Here, O(3) denotes a term that tends to zero more rapidly than the second-order term
when δm →0 (this is independent of the particular norm being used). In the third of
expressions (6.249), the convention of implicit sum over repeated indices is used.
These equations show that the gradient ˆγ at a given point deﬁnes a linear application
from M into the real line ℜ: the gradient is a form, i.e., an element of M∗, the dual of
M . The Hessian ˆH is a linear operator mapping M into M∗.

6.22. Gradient-Based Optimization Algorithms
205
Gradient of the Misﬁt Function
In nonlinear least squares, the function of interest is the misﬁt function given by (equa-
tion (3.46))
2 S(m) = ∥g(m) −dobs ∥2
D + ∥m −mprior ∥2
M
= (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior)
.
(6.251)
The gradient of S at a point m0 is (equation (3.88))
ˆγ 0 = Gt
0 C −1
D (g(m0) −dobs) + C −1
M (m0 −mprior)
.
(6.252)
Here, G0 stands for the matrix of partial derivatives
(G0)i
α =
 ∂gi
∂mα

m0
.
(6.253)
In ℓp-norm problems, where the misﬁt function is (equation (4.26))
S(m) = 1
s

i
|gi(m) −di
obs|s
(σ i
D)s
+ 1
r

α
|mα −mα
prior|r
(σ α
M)r
,
(6.254)
the gradient of S at a point m0 is (equation (4.27))
( ˆγ 0)α =

i
1
σ i
D
(G0)i
α
gi(m0) −di
obs
σ i
D
{s−1}
+

α
1
σ α
M
mα
0 −mα
prior
σ α
M
{r−1}
.
(6.255)
Hessian of the Least-Squares Misﬁt Function
The Hessian associated with the least-squares misﬁt function (6.251) is (equation (3.91))
( ˆH0)αβ = (G0)i
α(C −1
D )ij(G0)j
β + (C −1
M )αβ +
∂Giα
∂mβ

m0(C −1
D )ij(gj(m0) −dj
obs)
,
(6.256)
or, with the usual approximation of dropping the second derivatives (equation (3.92)),
ˆH0 ≃Gt
0 C −1
D G0 + C −1
M
.
(6.257)
Note that in equation (6.256) the implicit sum convention is used.
Gradient Versus Steepest Ascent Vector
Some elementary texts tend to use the terms gradient and steepest ascent vector as almost
synonymous. In fact, they correspond to two very different concepts (and, numerically, to
two very different quantities).

206
Chapter 6. Appendices
Let M be a linear space, with vectors denoted m, m′, . . . , and m →ψ(m) be a
(scalar) function to be maximized. The gradient, as introduced above, is a linear form. In
fact, it can be understood as the linear86 function over M that is tangent to the function
ψ(m) (at the point m0 where the gradient is evaluated). The gradient is deﬁned irrespective
of any possible deﬁnition of norm over M .
To deﬁne the direction of steepest ascent (at the given point m0 ), one must deﬁne
a norm (for instance an ℓ1- or an ℓ2-norm). When a norm is given, one may consider an
inﬁnitesimally small circle (deﬁned according to the given norm) around the point m0 . The
direction of steepest ascent is deﬁned by the point on the circle where the function ψ(m)
reaches the maximum value.
Changing the norm changes the circle, and the direction of steepest ascent, as sug-
gested in Figure 6.10.
Figure 6.10. In the ﬁrst panel, the level lines of a real function S(m) in a 2D space
and the mille-feuilles representing the gradient of S at a given point are shown. The three
other panels represent a small circle (deﬁned using different deﬁnitions of norm) around the
given point and the respective direction of steepest ascent. This direction is deﬁned by the
point on the small circle where the gradient takes its maximum value. In the second panel,
the circle is deﬁned in the ℓ1-norm sense. In the third panel, it is deﬁned using an ℓ2-norm
(with covariances). In the last panel, it is deﬁned using an ℓ∞-norm. Notice that, while the
gradient of the function S(m) at a given point is deﬁned irrespective of any deﬁnition of
norm, the direction of steepest ascent fundamentally depends on the norm being used.
Given a function m →ψ(m) , the evaluation of the gradient just involves taking
partial derivatives (equation at left in (6.250)). To evaluate the direction of steepest ascent,
one may take an inﬁnitesimal circle, as explained above, and seek the maximum of the
function ψ(m) or, equivalently, take a ﬁnite circle and seek the maximum of the linear
tangent application (as deﬁned by the gradient).
The result of this computation is simple enough. Let ˆγ 0 denote the gradient of the
function ψ(m) at a point m0 . By deﬁnition, it is an element of M∗, the dual of M . The
steepest ascent vector, say γ 0 , is the vector of M that is related to ˆγ 0 through the usual
duality relation between vectors and forms. Before demonstrating this result, let us make it
more explicit.
86To speak properly, an afﬁne function.

6.22. Gradient-Based Optimization Algorithms
207
Given a function m →ψ(m) , the gradient at a given point is the form whose
components are
ˆγα =
∂ψ
∂mα
.
(6.258)
• When using an ℓp-norm over M ,
∥m ∥=
 
α
| mα |p
(σ α)p
1/p
,
(6.259)
it makes sense to consider the ℓq-norm over M∗,
∥ˆm ∥=
 
α
 ˆmα
q
(ˆσα)q
1/q
,
(6.260)
where
1
p + 1
q = 1
,
ˆσα =
1
σ α
.
(6.261)
The vector of M associated with the gradient ˆγ by the basic duality between M∗
and M is (see equations (4.13) and (4.16) in the main text)
γ α =
1
ˆσα
sg( ˆγα)

ˆγα
ˆσα

q−1
=
1
ˆσα
 ˆγα
ˆσα
{q−1}
,
(6.262)
and the norms of ˆγ and γ are related as (equation (4.12))
∥γ ∥p = ∥ˆγ ∥q
.
(6.263)
In this situation, the vector γ in equation (6.262) is the steepest ascent vector asso-
ciated with the gradient ˆγ in equation (6.258).
• When using an ℓ2-norm over M ,
∥m ∥=

mt C−1 m
1/2
,
(6.264)
( C being a covariance matrix), it makes sense to consider the ℓ2-norm over M∗,
∥ˆm ∥=
 ˆmt ˆC−1 ˆm
1/2
,
(6.265)
where
ˆC = C −1
.
(6.266)
The vector of M associated with the gradient ˆγ by the basic duality between M∗
and M is (see equation (3.18) in the main text)
γ = C ˆγ
,
(6.267)
and the norms of ˆγ and γ are obviously related as
∥γ ∥= ∥ˆγ ∥
.
(6.268)
In this situation, the vector γ in equation (6.267) is the steepest ascent vector asso-
ciated with the gradient ˆγ in equation (6.258).

208
Chapter 6. Appendices
The demonstration is very similar for the ℓp- and ℓ2-norm cases, but, as the ℓ2-norm
case is not a special case of the ℓp-norm case (because of the covariances considered in ℓ2 ),
let us make two separate demonstrations, starting with the ℓp case.
At a given point m0 , we seek the direction d0 such that in the limit ε →0 we obtain
the minimum of ψ(m0 + ε d0) . As
ψ(m0 + ε d0) = ψ(m0) + ε ⟨ˆγ 0 , d0 ⟩+ · · ·
,
(6.269)
where ˆγ 0 is the gradient of ψ(m) at point m0 , we see that we can formulate the problem
as follows:

ﬁnd the d0 that maximizes ⟨ˆγ 0 , d0 ⟩
under the constraint ∥d0 ∥= const. = k
.
(6.270)
Introducing the Lagrange parameters (see Appendix 6.29), this problem of constrained
maximization can be transformed into a problem of unconstrained maximization:

ﬁnd the d0 and the λ that maximize the function
8(d0, λ) = ⟨ˆγ 0 , d0 ⟩−λ
p

∥d0 ∥p −Kp 
.
(6.271)
More explicitly,
8(d0, λ) =

α
( ˆγ 0)α (d0)α −λ
p
 
α
| (d0)α |p
(σ α)p
−Kp 
.
(6.272)
The condition ∂8/∂λ = 0 gives ∥d0 ∥= K , as it should. The condition ∂8/∂(d0)α = 0
gives
( ˆγ 0)α
ˆσα
= λ
(d0)α
σ α
{p−1}
,
(6.273)
where ˆσα = 1/σ α and where the symbol u{r} has been deﬁned in equation (4.14). Using
the relations (4.16) gives
(d0)α
σ α
= 1
λ
( ˆγ 0)α
ˆσα
{q−1}
,
(6.274)
where 1/p + 1/q = 1 . The value of λ is so far arbitrary. Taking the value λ = 1 makes
d0 the element dual to γ 0 (equation (4.16)), and then (equation (4.12))
∥d0 ∥p = ∥ˆγ 0 ∥q
.
(6.275)
When passing from the ℓp to the ℓ2 case, the unconstrained optimization problem
in equation (6.271) becomes

ﬁnd the d0 and the λ that maximize the function
8(d0, λ) = ⟨ˆγ 0 , d0 ⟩−λ
2

∥d0 ∥2 −K2 
.
(6.276)

6.22. Gradient-Based Optimization Algorithms
209
Here, explicitly,
8(d0, λ) =

α
( ˆγ 0)α (d0)α −λ
2
 
α

β
(d0)α (C −1)αβ (d0)β −K2 
.
(6.277)
The condition ∂8/∂λ = 0 gives ∥d0 ∥= K , as it should. The condition ∂8/∂(d0)α = 0
gives
d0 = 1
λ C ˆγ 0
,
(6.278)
the value of λ being arbitrary. Taking the value λ = 1 makes d0 the element dual to γ 0
(equation (3.18)), and then
∥d0 ∥= ∥ˆγ 0 ∥
.
(6.279)
This concludes the demonstrations.
Norm of the Gradient
Let m →ψ(m) be a nonlinear form over a linear space M and ˆγ 0 be the gradient of ψ
at a point m0 . By deﬁnition of gradient, for any δm ,
ψ(m0 + δm) = ψ(m0) + ⟨ˆγ 0 , δm ⟩+ O(2)
.
(6.280)
Let γ 0 be the dual of ˆγ 0 (we have seen that γ 0 represents the steepest ascent vector for
ψ at m0 ). From the equation above, it follows that
ψ

m0 +
1
∥γ 0 ∥γ 0

= ψ(m0) +
1
∥γ 0 ∥⟨ˆγ 0 , γ 0 ⟩+ O(2)
,
(6.281)
and, using the property ⟨ˆγ 0 , γ 0 ⟩= ∥ˆγ 0 ∥∥γ 0 ∥(equation (4.12)),
ψ

m0 +
1
∥γ 0 ∥γ 0

= ψ(m0) + ∥ˆγ 0 ∥+ O(2)
.
(6.282)
This shows that the norm of γ 0 represents the variation of the linear application tangent
to ψ(m) at m0 per unit norm-length of variation of m in the direction of steepest ascent,
i.e., the norm of γ 0 represents the slope of ψ at m0 .
Curvature
Let M be a ﬁnite-dimensional linear space and m →ψ(m) be a nonlinear form over
M . We have seen that the gradient of ψ at a point m (which we have denoted ˆγ 0 ) is a
form over M , i.e., it is an element of M∗dual to M . When introducing a norm over M ,
we have seen that we have a bijection between M and M∗. Also, the element γ 0 of M
associated with the form ˆγ 0 corresponds to the direction of ascent of ψ at point m0 .

210
Chapter 6. Appendices
When using an ℓ2-norm associated with a covariance operator C through the expres-
sion ∥m ∥2 = ⟨C −1 m , m ⟩= mt C −1 m , the relation between ˆγ 0 and γ 0 is γ 0 = C ˆγ 0 ,
so, in ℓ2-norm problems, the terminology is as follows:
ˆγ 0 =
∂ψ
∂m

m0
:
gradient of ψ at m0
,
γ 0 = C ˆγ 0
:
steepest ascent vector for ψ at m0
.
(6.283)
The Hessian of ψ(m) at a given point m0 is a linear operator ˆH0 mapping M
into M∗(see, for instance, the ﬁrst of equations (6.249)). The curvature operator H0 is
deﬁned as
(H0)α
β =
 ∂γ α
∂mβ

m0
,
(6.284)
which should be compared to that deﬁning the Hessian:
( ˆH0)αβ =
 ∂ˆγα
∂mβ

m0
(6.285)
(while the Hessian is the derivative of the gradient, the curvature is the derivative of the
steepest ascent vector).
In least squares, where the relation between the primal space M and the dual space
M∗is linear, it follows directly from γ = C ˆγ that the relation between curvature and
Hessian is H0 = C ˆH0 . Therefore, in ℓ2-norm problems, the terminology is as follows:
ˆH0 =
∂2ψ
∂2m

m0 =
 ∂ˆγ
∂m

m0
:
Hessian of ψ at m0
,
H0 = C ˆH0 =
 ∂γ
∂m

m0
:
curvature of ψ at m0
.
(6.286)
γ 0 is sometimes abusively called the gradient, while H0 is sometimes called the Hessian.
This terminology can be misleading because although these elements are isomorphic, they
are by no means identical.
For instance, while in least-squares problems the Hessian operator is (approximately)
given by (equation (6.257))
ˆH ≃C −1
M + Gt C −1
D G
,
(6.287)
the curvature operator is
H = I + CM Gt C −1
D G
.
(6.288)
Introducing the adjoint of G , one has H = I + G∗G . Note that while the Hessian is
symmetric, the curvature is self-adjoint.
6.22.2
Newton Method for ℓp-Norms
Let M be a linear space and ψ(m) be a nonlinear form over M . Introducing the gradient
and Hessian of ψ , we can write the two series developments
ψ(m) = ψ(m0) + ⟨ˆγ 0 , m −m0 ⟩+ 1
2 ⟨ˆH0 (m −m0) , m −m0 ⟩+ · · ·
,
ˆγ (m) = ˆγ 0 + ˆH0 (m −m0) + · · ·
.
(6.289)

6.22. Gradient-Based Optimization Algorithms
211
Locating the point m where ψ has an optimum (maximum or minimum) is equivalent
to locating a point where the gradient ˆγ (m) vanishes. Imposing ˆγ (m) = 0 gives, using
the second of equations (6.289),
m ≈m0 −ˆH −1
0
ˆγ 0
.
(6.290)
Should the function ψ be strictly quadratic, the Newton method would converge in only
one iteration. If the function ψ is not too far from being quadratic, the Newton algorithm
mn+1 ≈mn −ˆH −1
n
ˆγ n
(6.291)
converges well.
But it converges well only when the function ψ is not too far from being quadratic.
The typical functions encountered when working with inverse problems that are based on
ℓp-norms are usually not close to being quadratic. A minor modiﬁcation of the Newton
algorithm provides a much better convergence.
To see this, examine a one-dimensional minimization problem where the function to
be minimized is S(x) = | x |p . Instead of trying the Newton algorithm xn+1 = xn−S′
n/S′′
n ,
one may try the algorithm xn+1 = xn−k S′
n/S′′
n , where k is a constant to be determined. An
easy computation shows that the choice k = p −1 makes this iterative algorithm converge
in only one iteration, whatever the value of p is. Therefore, when dealing with ℓp-norm
optimization problems, the right version of the Newton algorithm is
mn+1 ≈mn −(p −1) ˆH −1
n
ˆγ n
.
(6.292)
When p = 2 , we obtain the standard version of the algorithm. In the two limit cases
p →1 and p →∞, the algorithm becomes undetermined.
6.22.3
Minimization Along a Given Direction
Let us face now the problem of one-dimensional optimization. Although in inverse problems
one is typically faced with the need to ﬁnd the minimum of a misﬁt function S(m) , let us
examine here the problem of ﬁnding the maximum of a function ψ(m) (this simpliﬁes
language and notation, and the adaptations are trivial).
So, let us consider a ﬁnite-dimensional linear space M and a nonlinear form ψ(m)
deﬁned over M . We assume we are given a particular point m0 and a direction φ0 at m0 .
This direction may be the steepest ascent direction for ψ , or any other direction. We wish
to perform a jump along the direction deﬁned by φ0 (i.e., we wish to move from point m0
to a point m = m0 + µ φ0 ) such that the new value of ψ takes its minimum value along
that direction. In other words, which value should we give to the scalar µ in order to obtain
the minimum value of ψ(m0 + µ φ0) ?
Usual methods for obtaining adequate values for µ are, for instance, trial and error
and parabolic interpolation (the value of ψ is computed for three values of µ , a parabola
is ﬁtted to these three points, and the value of µ giving the minimum of the parabola is
chosen). These methods, although robust, need the computation of ψ at some points, and,
for large-dimensional problems, this can be too expensive.

212
Chapter 6. Appendices
If the functional ψ is sufﬁciently well behaved, a useful approximation for µ can
be obtained by considering not ψ but its second-order approximation around m0 . By
deﬁnition of gradient and Hessian, we can write
ψ(m0 + µ φ0) = ψ(m0) + µ ⟨ˆγ 0 , φ0 ⟩+ µ2
2 ⟨ˆH0 φ0 , φ0 ⟩+ O(3)
.
(6.293)
The condition ∂ψ/∂µ = 0 then gives
µ ≃
⟨ˆγ 0 , φ0 ⟩
⟨ˆH0 φ0 , φ0 ⟩
.
(6.294)
This, in fact, results from an application of a one-dimensional version of the Newton algo-
rithm. But we have seen above that when the function to be optimized is deﬁned via the
use of an ℓp-norm, it is better to use a modiﬁed version of the Newton algorithm. Then, a
better value for the scalar µ is (see equation (6.292))
µ ≃(p −1)
⟨ˆγ 0 , φ0 ⟩
⟨ˆH0 φ0 , φ0 ⟩
.
(6.295)
When working with ℓ2-norms, p −1 = 1 , and the usual expression is found.
Obviously, this only gives a reasonable estimate of the step length to be used. One
has to check that, with such a step length, the function ψ actually takes better values. If
not, the value of µ has to be diminished until the condition is met.
6.22.4
Steepest Descent
Let M be the model space and S(m) be the misﬁt function (whose minimum is sought).
The model space is assumed to be a linear space and is assumed to be endowed with a norm
m →∥m ∥(typically an ℓp-norm). The steepest descent algorithm corresponds to taking
the steepest descent direction as the direction of search.
The gradient of the misﬁt function, an element of M∗, is
ˆγα(m) =
∂S
∂mα (m)
,
(6.296)
and, as we have seen, the steepest ascent vector is the vector γ of M that is related to ˆγ
via the duality relation.
The steepest descent algorithm is, then,
mn+1 = mn −µn γ n
(6.297)
(the minus sign is because we want a direction of descent). The right value of the scalar µn
is to be obtained by linear search. As we have seen (equation (6.295)), for a smooth enough
misﬁt function, a reasonable value may be
µn ≃(p −1)
⟨ˆγ n , γ n ⟩
⟨ˆHn γ n , γ n ⟩
,
(6.298)

6.22. Gradient-Based Optimization Algorithms
213
where ˆH is the Hessian of the misﬁt function,
ˆHαβ(m) = ∂ˆγα
∂mβ (m) =
∂2S
∂mαmβ (m)
,
(6.299)
and where the factor (p −1) is there because it is assumed that the misﬁt function has been
derived using an ℓp-norm.
Steepest Descent in ℓp-Norm Inverse Problems
In the ℓp-norm formulation of inverse problems, the misﬁt function is (equation (6.254))
S(m) = 1
s

i
|gi(m) −di
obs|s
(σ i
D)s
+ 1
r

α
|mα −mα
prior|r
(σ α
M)r
,
(6.300)
where an ℓs-norm is used in the data space and an ℓr-norm is used in the model space. The
gradient of S is (equation (6.255))
ˆγ α(m) =

i
1
σ i
D
Gi
α(m)
gi(m) −di
obs
σ i
D
{s−1}
+

α
1
σ α
M
mα −mα
prior
σ α
M
{r−1}
,
(6.301)
where the Giα are the partial derivatives Giα = ∂gi/∂mα .
The steepest ascent vector is (see equation (6.262))
γ α(m) = σ α 
σ α ˆγα(m)
{q−1}
,
(6.302)
where the parameter q is related to the parameter r (deﬁning an ℓr-norm in the model
space) via
1
r + 1
q = 1
.
(6.303)
The steepest descent algorithm is then
mn+1 = mn −µn γ (mn)
,
(6.304)
where the real number µn is to be obtained by linear search (or one may try to use the
approximation proposed by equation (6.298)).
Steepest Descent in Least-Squares Inverse Problems
In the least-squares formulation of inverse problems, the misﬁt function S is given by
(equation (6.251))
2 S(m) = (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior)
,
(6.305)

214
Chapter 6. Appendices
the gradient of S at a point m being (equation (6.252))
ˆγ (m) = Gt(m) C −1
D (g(m) −dobs) + C −1
M (m −mprior)
,
(6.306)
where G stands for the matrix of partial derivatives Giα = ∂gi/∂mα .
In this ℓ2-norm formulation, the steepest ascent vector, γ , is related to the gradient
ˆγ via (equation (6.262)) γ = CM ˆγ . Therefore,
γ (m) = CM Gt(m) C −1
D (g(m) −dobs) + (m −mprior)
.
(6.307)
The steepest descent algorithm mn+1 = mn −µn γ (mn) here becomes
mn+1 = mn −µn

CM Gt
n C −1
D (gn −dobs) + (mn −mprior)

,
(6.308)
where, for short, the notation gn = g(mn) and Gn = G(mn) has been used.
The real number µn is to be obtained by linear search. Using, instead, the approxi-
mation proposed in equation (6.298), one has (at p = 2 ) µn ≃⟨ˆγ n , γ n ⟩/ ⟨ˆHn γ n , γ n ⟩.
These duality products being in the model space, one has ⟨a , b ⟩= at C −1
M b . Using the
approximation for the Hessian proposed in equation (6.257), one ﬁnally obtains
µn ≃
γ t
n C −1
M γ n
γ tn C −1
M γ n + btn C −1
D bn
,
where
bn = Gn γ n
.
(6.309)
6.22.5
Preconditioned Steepest Descent
The steepest descent direction is an optimal local descent direction. As the property is local,
one should only use the direction of steepest descent if one wants to perform inﬁnitesimally
small jumps. In practical algorithms of optimization, one wishes, on the contrary, to perform
as large jumps as possible, to achieve convergence in as small a number of iterations as
possible. Instead of using the direction of steepest descent, one could, for instance, use
the direction that for a given (ﬁnite) size of the jump gives the smallest value of the misﬁt
function.
Instead, what one usually does is to compute the direction of steepest ascent (as
accurately as possible), then to use physical common sense to modify this direction at will.
It is impossible to give any rule valid for all inverse problems. For instance, in the problem
of X-ray tomography, the direction of steepest descent tends to give too much weight to
perturbations in the model that are close to the source. Then one may (brutally) damp these
perturbations in the steepest descent vector. Doing this, one passes from the steepest descent
vector γ n to another direction (hopefully better for ﬁnite jumps)
φn = f(γ n)
,
(6.310)
and one says that the steepest descent direction has been preconditioned. The function f( · )
can be any nonlinear function, with the sole requirement that the direction it generates is
still a direction of descent for the misﬁt S .

6.22. Gradient-Based Optimization Algorithms
215
Sometimes, one only considers linear preconditioning operators,87 in which case
φn = Fn γ n
,
(6.311)
where the linear operator may depend on mn (hence the index in Fn ).
As there is not much to be added for the ℓp-norm inverse problem, let us directly
analyze the least-squares problem.
Whatever the preconditioning one chooses to do (linear or nonlinear), one starts by
computing the steepest ascent vector (equation (6.307))
γ n = CM Gt
n C −1
D (gn −dobs) + (m −mprior)
(6.312)
and obtains from it a (preconditioned) direction of search φn = f(γ n) , and the precondi-
tioned steepest descent algorithm is
mn+1 = mn −µn φn
,
(6.313)
where the real number µn is to be obtained by linear search. Using the approximation
suggested in equation (6.295), one obtains
µn ≃
γ t
n C −1
M φn
φt
n C −1
M φn + btn C −1
D bn
,
where
bn = Gn φn
.
(6.314)
When limiting the choice to linear preconditioning operators, φn = Fn γ n , it is good
to have in mind the quasi-Newton algorithm (see section 6.22.6 below), which can be written
mn+1 = mn −( I + CM Gt
n C −1
D Gn )−1 γ n . This suggests using as linear preconditioning
operator any operator Fn that can be an approximation of the operator appearing in the
quasi-Newton algorithm, i.e.,
Fn ≈

I + CM Gt
n C −1
D Gn
−1
.
(6.315)
Even very crude approximations may work well.
In Algorithm (6.313), the starting point m0 is arbitrary, the simplest choice being
m0 = mprior . The use of different starting points may help to check the existence of
secondary minima.
6.22.6
Quasi-Newton Method
To obtain the quasi-Newton algorithm for the iterative resolution of the least-squares inverse
problem, we just need to collect here some of the expressions written above.
The misﬁt function S is given by (equation (6.251))
2 S(m) = (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior)
,
(6.316)
87The name preconditioning operator takes its source in the theory of the resolution of linear systems: letting
A x = y represent a system to be solved, and F ≃A−1 , the system F A x = F y is equivalent to the ﬁrst, but if F
is astutely chosen, it has a lower condition number (see Problem 7.8), so its numerical resolution is more stable:
the system has been preconditioned.

216
Chapter 6. Appendices
its gradient is (equation (6.252))
ˆγ (m) = Gt(m) C −1
D (g(m) −dobs) + C −1
M (m −mprior)
,
(6.317)
and the (usual approximation of the) Hessian is (equation (6.257))
ˆH(m) ≃C −1
M + Gt(m) C −1
D G(m)
.
(6.318)
In these equations, Giα = ∂gi/∂mα .
The Newton algorithm (equation (6.291)) then gives88
mn+1 = mn −νn

C −1
M + Gt
n C −1
D Gn
−1 
Gt
n C −1
D (gn −dobs) + C −1
M (mn −mprior)

,
(6.319)
where Gn = G(mn) , gn = g(mn) , and νn is a real number to be obtained by linear search
(but that, in most common situations, is of the order of one).
This expression uses the gradient and the Hessian of the misﬁt. An equivalent algo-
rithm is obtained when using the steepest ascent vector and the curvature:
mn+1 = mn −νn

I + G∗
n Gn
−1 
G∗
n (gn −dobs) + (mn −mprior)

,
(6.320)
where G∗
n , the adjoint of Gn , is (see section 3.1.4)
G∗
n = CM Gt
n C −1
D
.
(6.321)
As usual, the starting point m0 is arbitrary, the simplest choice is m0 = mprior , but
the use of different starting points helps to check the existence of secondary minima.
6.22.7
Conjugate Directions
The conjugate directions method for the maximization of a function Y is based on the
following idea: Let m0 be the starting point and γ 0 be the steepest ascent vector at m0 .
The point m1 is deﬁned as in the steepest ascent method. Let γ 1 be the steepest ascent
vector at m1 . The point m2 is not deﬁned as the point maximizing Y in the direction
given by γ 1 , but as the point maximizing Y in the subspace generated by γ 0 and γ 1 .
The point m3 is deﬁned as the point maximizing Y in the subspace generated by γ 0 ,
γ 1 , and γ 3 , and so on until convergence. To precondition the conjugate directions method
means, as above, to replace the γ n with some other direction of ascent (hopefully better
for the ﬁnite jumps intended).
It can be shown (see, for instance, Fletcher, 1980) that this method generally converges
at the same rate as the variable metric method (it has quadratic convergence for linear
problems). The miracle is that the computations needed to perform this method are not
more difﬁcult than those needed in using the steepest ascent method.
For least-squares problems, the choice between conjugate directions and variable
metric has to be made by considering that the ﬁrst needs less computer memory, but the
second gives a direct approximation to the posterior covariance operator.
88These formulas were ﬁrst derived by Rodgers (1976) and rediscovered by Tarantola and Valette (1982b).

6.22. Gradient-Based Optimization Algorithms
217
Conjugate Directions in Normed Spaces
Here, we wish to minimize the misﬁt function S(m) deﬁned in equation (6.300). The
gradient of S(m) (given in equation (6.301)) is denoted by ˆγ (m) and the Hessian is
denoted by ˆH(m) . The steepest ascent vector γ (m) (given in equation (6.302)) is the
vector dual to the gradient.
The general algorithm for the method of conjugate directions is (see Céa, 1971; Walsh,
1975; Fletcher, 1980; Powell, 1981; Ciarlet, 1982; or Scales, 1985)
λn = F0 γ n
,
φn = λn + αn φn−1

αn deﬁned below

,
mn+1 = mn −µn φn
(obtain µn by linear search) .
(6.322)
Thealgorithmisinitializedatanarbitrarypoint m0 , F0 isanarbitrarypreconditioning
operator, and the vector φn is initialized at φ0 = λ0 .
Different expressions can be obtained for αn :
αn =
⟨ˆγ n , λn ⟩
⟨ˆγ n−1 , λn−1 ⟩
(Fletcher and Reeves, 1964)
,
αn = ⟨ˆγ n −ˆγ n−1 , λn ⟩
⟨ˆγ n−1 , λn−1 ⟩
(Polak and Ribière, 1969)
,
αn =
⟨ˆγ n −ˆγ n−1 , λn ⟩
⟨ˆγ n −ˆγ n−1 , φn−1 ⟩
(Hestenes and Stiefel, 1952)
.
(6.323)
Although these expressions are perfectly equivalent for quadratic functions, they are not for
general problems. The Fletcher–Reeves formula is still probably the most widely used. Nev-
ertheless, Powell (1977) has suggested that in some situations, the Polak–Ribière formula
may give superior results.89
For quadratic problems, it can be shown that if N iterations are effectively performed,
the actual minimum is attained, where N is the dimension of the model space M .
It remains to ﬁx a value for the real numbers µn . Ideally, one should use a linear
search. If not, using the approximation given in equation (6.295) gives
µn ≃(p −1)
⟨ˆγ n , φn ⟩
⟨ˆHn φn , φn ⟩
.
(6.324)
Conjugate Directions for Least Squares
The formulas for least-squares problems are very similar to those just written, except that
the misﬁt function is now (equation (6.305))
2 S(m) = (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior)
,
(6.325)
89For instance, in nonquadratic minimizations, it may happen that φn becomes almost orthogonal to the steepest
descent vector λn . In that case, mn+1 ≃mn , ˆγ n+1 ≃ˆγ n , and λn+1 ≃λn . The Fletcher–Reeves formula then
gives αn+1 ≃1 and φn+1 ≃λn+1 + φn , while the Polak–Ribière formula gives αn ≃0 and φn+1 ≃λn+1 .
This shows that in critical situations, when a small advance can be made, the Polak–Ribière method is more robust
because it has a tendency to take the steepest descent direction as a direction of search.

218
Chapter 6. Appendices
the gradient is (equation (6.306))
ˆγ (m) = Gt(m) C −1
D (g(m) −dobs) + C −1
M (m −mprior)
,
(6.326)
and the (approximate) Hessian is (equation (6.257))
ˆH0 ≃Gt
0 C −1
D G0 + C −1
M
.
(6.327)
Finally, the steepest ascent vector is (equation (6.307))
γ (m) = CM Gt(m) C −1
D (g(m) −dobs) + (m −mprior)
.
(6.328)
This gives the algorithm
γ n = CM Gt
n C −1
D (gn −dobs) + (mn −mprior)
,
λn = F0 γ n
,
φn = λn + αn φn−1

αn deﬁned below

,
mn+1 = mn −µn φn
(obtain µn by linear search) .
(6.329)
The starting point m0 is arbitrary, the simplest choice being m0 = mprior , although
the use of different starting points helps to check the existence of secondary solutions.
The simplest choice for the preconditioning operator F0 is F0 = I . Usually, some
approximation of the initial curvature
F0 ≃

I + CM G0
t C −1
D G0
−1
(6.330)
gives good results. The vector φn is initialized at φ0 = λ0 .
Using, for instance, the Polak–Ribière formula gives
αn = ωn −γ n−1
t C −1
M λn
ωn−1
,
(6.331)
where
ωn = γ n
t C −1
M λn
.
(6.332)
The value µn has to be obtained by linear search. Alternatively, a linearization of
g(m) around g(mn) gives
µn ≃
γ n
t C −1
M φn
φn
t C −1
M φn + bnt C −1
D bn
,
where
bn = Gn φn
.
(6.333)
Notice that the numerator can be written
γ n
t C −1
M φn = γ n
−1 C −1
M λn −αn γ n
t C −1
M φn−1
.
(6.334)
If the linear searches are accurate, the steepest ascent vector γ n is approximately orthogonal
to the previous search direction φn−1 ,
γ n
t C −1
M φn−1 ≃0
,
(6.335)
and the following simpliﬁcation can be used:
µn ≃
ωn
φn
t C −1
M φn + bnt C −1
D bn
,
where
bn = Gn φn
.
(6.336)

6.22. Gradient-Based Optimization Algorithms
219
6.22.8
Variable Metric Methods
Variable Metric in General
Let M be a ﬁnite-dimensional linear space, S(m) be the real function to be minimized,
ˆγ (m) be the gradient of S , and ˆH(m) be the Hessian of S .
The central idea of variable metric methods is to allow the preconditioning operator
(discussed in the previous sections) to vary from iteration to iteration and to ﬁnd an updating
formula
ˆFn+1 = ˆFn + δ ˆFn
(6.337)
such that, as the iterations proceed, the preconditioning operator tends to the inverse Hessian,
ˆFn →ˆH−1
n
,
(6.338)
so that a variable metric method will start behaving like a steepest descent method, but
will ﬁnish behaving like a Newton method (with its rapid termination). The name variable
metric makes sense, as the inverse Hessian can be interpreted as a metric over the space M .
In the previous sections, the preconditioning operator was denoted by F . If I denote
it here with a hat, ˆF , it is because the preconditioning operator was assumed above to be
of the same type as the inverse of the curvature operator, while here it is assumed to be of
the same type as the inverse of the Hessian operator (to ﬁx ideas, in the context of least
squares, where Hessian and curvature are given by the two equations (6.287)–(6.288), one
has ˆF = F CM ).
Let ˆF0 be an arbitrary symmetric positive deﬁnite operator, hopefully a good approx-
imation of the inverse of the initial Hessian
ˆF0 ≃ˆH−1
0
.
(6.339)
The general structure of a variable metric method is (see Céa, 1971; Walsh, 1975;
Fletcher, 1980; Powell, 1981; Ciarlet, 1982; Scales, 1985)
φn = ˆFn ˆγ n
,
mn+1 = mn −µn φn
(obtain µn by linear search)
,
ˆFn+1 = ˆFn + δ ˆFn
(δ ˆFn deﬁned below)
.
(6.340)
In numerical applications, the kernels of the operators ˆF1, ˆF2, . . . do not need to be
explicitly computed. All that is needed is the possibility of computing the result of the action
of the operators on arbitrary vectors. In the following, ˆFn( · ) represents the result of the
application of ˆFn over a generic vector represented by “ · .” Also, the following notations
are used:
δmn = mn+1 −mn
,
δ ˆγ n = ˆγ n+1 −ˆγ n
,
vn = ˆFn δ ˆγ n
,
un = δmn −vn
.
(6.341)

220
Chapter 6. Appendices
Many different formulas exist for the updating of ˆFn , for instance, the symmetric
rank-one formula (due to Davidon, 1959)
ˆFn+1( · ) = ˆFn( · ) +
⟨· , un ⟩
⟨δ ˆγ n , un ⟩un
,
(6.342)
the DFP formula (due to Davidon, 1959, and to Fletcher and Powell, 1963)
ˆFn+1( · ) = ˆFn( · ) +
⟨· , δmn ⟩
⟨δ ˆγ n , δmn ⟩δmn −
⟨· , vn ⟩
⟨δ ˆγ n , vn ⟩vn
,
(6.343)
and the BFGS formula (due to Broyden, 1967, Fletcher, 1980, Goldfarb, 1976, and Shannon,
1948)
ˆFn+1( · ) = ˆFn( · ) + βn ⟨· , δmn ⟩δmn −⟨δ ˆγ n , ˆFn( · ) ⟩δmn −⟨· , δmn ⟩vn
⟨δ ˆγ n , δmn ⟩
,
(6.344)
where
βn = 1 + ⟨δ ˆγ n , vn ⟩
⟨δ ˆγ n , δmn ⟩
.
(6.345)
Although it is easy to see that all the operators ˆFn thus deﬁned are positive deﬁnite,
they may become numerically singular. It seems that the BFGS formula has a greater
tendency to keep the deﬁniteness of ˆFn . Maybe this is the reason why it is today the most
widely used updating formula.
Let N denote the dimension of the space M . When using these formulas for quadratic
problems, it can be shown that if N iterations are effectively performed, the actual minimum
is attained, and
ˆFN = ˆH−1
,
(6.346)
where ˆH is the (constant) Hessian of ˆF . For large-dimensional problems, good approxi-
mations of the minimum are sometimes obtained after a few iterations. Of course, the better
ˆF0 approximates ˆH−1
0 , the better the convergence is in general.
As previously indicated, to operate with ˆFn , we do not need to build the kernel of the
operator, we only need to store in the computer’s memory some vectors and scalars. For
instance, letting ˆχ be an arbitrary vector, we have, for the rank-one formula,
ˆFn ˆχ = ˆF0 ˆχ +
n−1

k=0
⟨ˆχ , uk ⟩
νk
uk
,
(6.347)
where νk are the real numbers
νk = ⟨δ ˆγ k , uk ⟩
,
(6.348)
which shows that, in order to operate with ˆFn , we only have to store in the computer’s
memory the vectors u0, . . . , un and the scalars ν0, . . . , νn .

6.22. Gradient-Based Optimization Algorithms
221
For small-sized problems, it is nevertheless possible explicitly to compute the kernels
of ˆFn . Using the notation ⟨ˆχ , u ⟩= ˆχt u for the duality product, the formulas (6.342)–
(6.344) can be written
ˆFn+1 = ˆFn + un unt
δ ˆγ t
n un
,
(6.349)
ˆFn+1 = ˆFn + δmn δmnt
δ ˆγ t δmn
−vn vnt
δ ˆγ t
n vn
,
(6.350)
ˆFn+1 =

I −δmn δ ˆγ t
n
δ ˆγ t
n δmn

ˆFn

I −δmn δ ˆγ t
n
δ ˆγ t
n δmn
t
+ δmn δmnt
δ ˆγ t δmn
.
(6.351)
Using the approximation (6.295) for µn gives
µn ≃(p −1)
⟨ˆγ n , φn ⟩
⟨ˆHn φn , φn ⟩
.
(6.352)
Variable Metric for Least Squares
To obtain the formulas of the variable metric method for least squares, we only need to
particularize the formulas of the previous section (although it is better here to use steepest
descent vector and curvature instead of gradient and Hessian).
The preconditioning operator F is initialized as an arbitrary approximation of the
initial curvature H−1
0 ,
F0 ≃H−1
0
≃

I + CM G0
t C −1
D G0
−1,
(6.353)
and the variable metric method updates it in such a way that, at least for linear functions
g(m) (i.e., for quadratic misﬁt functions S(m) ),
Fn
→
H−1
n
.
(6.354)
There are two advantages in this. First, as already noted, although the method starts out
by behaving like a preconditioned steepest descent, it ends up by behaving like the Newton
method, with its rapid termination. Second, as we have seen in chapter 3, the ﬁnal value
of the inverse Hessian equals the posterior covariance operator CM , so the variable metric
method directly provides the posterior covariance operator without any need to invert a
matrix (see below).
We obtain the following algorithm (initialized at an arbitrary m0 )
γ n = CM Gn
t C −1
D

g(mn) −dobs

+ (mn −mprior)
,
φn = Fn γ n
,
mn+1 = mn −µn φn
(obtain µn by linear search)
,
Fn+1 = Fn + δFn
( δFn deﬁned below)
.
(6.355)

222
Chapter 6. Appendices
Then the rank-one formula gives
Fn+1 = Fn + un ut
n C −1
M
utn C −1
M δγ tn
,
(6.356)
the DFP formula gives
Fn+1 = Fn + δmn δmt
n C −1
M
δmtn C −1
M δγ n
−vn vt
n C −1
M
vtn C −1
M δγ n
,
(6.357)
and the BFGS formula gives
Fn+1 =

I −δmn δγ t
n C −1
M
δγ tn C −1
M δmn

Fn

I −δmn δγ t
n C −1
M
δγ tn C −1
M δmn

+ δmn δmt
n C −1
M
δγ tn C −1
M δmn
.
(6.358)
In these equations, δmn = mn+1 −mn , δγ n = γ n+1 −γ n , vn = Fn δγ n , and un =
δmn −vn . As mentioned above, the kernels (matrices) representing the operators Fn
should only be explicitly computed for small-sized problems. For large-sized problems, it
should be noticed that all that we need is to be able to compute the result of the action of
Fn on an arbitrary model vector f . Using, for instance, the rank-one formula, we have
Fn f = F0 F +
n−1

k=0
ukt C −1
M f
νk
uk
,
(6.359)
where νk are the real numbers
νk = uk
t C −1
M δγ k
.
(6.360)
This shows that, in order to operate with Fn , we only have to store in the computer memory
the vectors u0, . . . , un and the scalars ν0, . . . , νn .
This remark also applies for the estimation of the posterior covariance operator in
large-sized problems. We have seen that one interesting property of the variable metric
method is that it allows, at least in principle, an inexpensive estimate of the posterior co-
variance operator: the property
Fn →

I + CM Gn
t C −1
D Gn
−1
(6.361)
gives
CM ≃FK CM
,
(6.362)
where the index K represents the value of n for which iterations are stopped. Using, for
instance, the rank-one formula, gives (using equation (6.356)),
CM
αβ ≈

FK CM
αβ =

F0CM
αβ +
K−1

n=0
unα unβ
φn
.
(6.363)

6.23. Elements of Linear Programming
223
For large-sized problems, good approximations of the solution are usually obtained
after a few iterations. Unfortunately, very little is known about the accuracy of the covariance
operator obtained after a few iterations of a variable metric method.
It remains to ﬁx a value to the real number µn . Ideally, we should perform a linear
search. Alternatively, a linearization of g(m) around g(mn) gives
µn ≃
δn
t C −1
M φn
φn
t C −1
M φn + bnt C −1
D bn
,
where
bn = Gn φn
.
(6.364)
6.23
Elements of Linear Programming
6.23.1
Simplex Method of Linear Programming
Let the following be given:
M
:
(n × m) rectangular matrix,
ˆχ
:
(m × 1) column matrix,
y
:
(n × 1) column matrix.
(6.365)
We wish to obtain an (m × 1) column matrix x to solve the problem
minimize
ˆχt x
(6.366)
subject to the constraints
M x = y
,
x ≥0
,
(6.367)
where by x ≥0 we mean that all the components of x are nonnegative. In the application
we will consider, the matrix M will have the following properties:
m > n
(more columns than rows)
,
M is full rank
(rows are linearly independent)
,
there is no row with all elements but one null .
(6.368)
The ﬁrst of conditions (6.367) deﬁnes a hyperplane with dimension m −n . The ﬁrst
two conditions of (6.368) assure that this hyperplane is not empty and is not reduced to
a single point. The third of conditions (6.368) ensures that the hyperplane is not parallel
to one of the coordinate axes. The set of constraints (6.367) then always has an inﬁnity
of solutions. The set of solutions can easily be seen to constitute a nonempty convex set
(convex means that the straight segment joining two arbitrary points of the set belongs to
the set). The problem then reduces to one of obtaining the point x of the convex set that
minimizes the scalar function ˆχt x deﬁned by (6.366). As ˆχt x is a linear function of x ,
the minimum of ˆχt x is attained at a vertex of the convex set (or at an edge, if the solution
is not unique).
The idea of the simplex method for obtaining the solution is to start at an arbitrary
vertex of the convex polyhedron and to follow the steepest descending edge to the next
vertex. It is clear that the minimum will be attained in a ﬁnite number of steps. It can be

224
Chapter 6. Appendices
shown that the vector x solution of (6.366)–(6.367) has at most n components different
from zero. We can then limit ourselves to looking for the solution in a subspace with n
eventually nonnull components.
We start by arbitrarily choosing n components (called the basic components) among
the m components of x (remember that m > n ). Setting all the other components to
zero and using the ﬁrst of equations (6.367) allows us to compute the values of the basic
components. This gives a vertex of the polyhedron. If, by chance, we have the minimum
of ˆχt x , we stop the computations; if not, we drop one of the basic components and replace
it with another component. This gives a new vertex connected to the old one by an edge.
The simplex method chooses as a new vertex the one for which the corresponding edge has
maximum (descending) slope. Let us see how this can be done.
Assumethatonehaschosenthestarting n componentsof x arbitrarily. Forsimplicity,
assume that the components of x are classed in such a way that the basic components appear
in the ﬁrst n places of the column matrix representing x :
x =
xB
xN

=


x1
x2
· · ·
xn
xn+1
· · ·
xm


=


basic
components
other
components


.
(6.369)
The matrix M can then be written in partitioned form:
M =
MB
MN
.
(6.370)
As we have assumed that M has full rank, we can always choose our basic components in
such a way that MB is regular. The equation M x = y can now be rewritten
MB
MN xB
xN

= y
,
(6.371)
i.e., MB xB = y −MN xN , which gives
xB = (MB)−1(y −MN xN)
.
(6.372)
As we have not yet used the positivity constraint x ≥0 , we have no reason to have xB ≥0 .
We then have to change the choice of basic components until this condition is fulﬁlled. When
it is, we can pass to the study of ˆχt x . We have
ˆχt x =
 ˆχB
ˆχN
t xB
xB

= ( ˆχB)t xN + ( ˆχN)t xN
(6.373)
and, using (6.372)
ˆχt x = ( ˆχB)t (MB)−1 y + (γ N)t xN
,
(6.374)

6.23. Elements of Linear Programming
225
where
(γ N)t = ( ˆχN)t −( ˆχB)t (MB)−1 MN
.
(6.375)
If all the components of γ N are greater than or equal to 0, ˆχt x is clearly minimized for
xN = 0 , and then the solution obtained using (6.372),
x =
xB
xN

=
(MB)−1 y
0

,
(6.376)
is the solution of the problem. If some of the components of γ N are negative, one chooses
the most negative. Denote as xk the corresponding component of x (which is not in
the basic components). If one gives increasingly positive values to xk and computes the
corresponding values for xB using (6.372), one of the basic components, say xj , will
vanish. It can be seen that replacing xj with xk in the basic components corresponds to a
move from one vertex to the neighboring vertex whose direction is the steepest one.
Iterating this procedure, one ends at a vertex for which all the components of γ N are
positive, and the solution is attained.
For important questions concerning implementation, the reader may refer to Cuer
(1984) or to the references there quoted. For algorithmic questions, see references in the
footnote.90
6.23.2
Dual Problems in Linear Programming
Let X and Y be two abstract linear spaces and M be a linear operator mapping X into
Y . Assume that the dimension of X is greater than the dimension of Y and that M is full
rank. Let y denote a given vector of Y and ˆχ be a given form over X , i.e., an element of
X∗, dual of X . The problem of obtaining the vector x of X satisfying the conditions
minimize
ˆχt x
subject to the constraints
M x = y
,
x ≥0
,
(6.377)
is called the standard problem of linear programming. As usual, x ≥0 means that all the
components of x are not less than 0.
Let M , y , and ˆχ be the same as above. As M maps X into Y , by deﬁnition of the
transpose operator (see section 3.1.2), Mt maps Y∗, dual of Y , into X∗, dual of X . The
element y of Y deﬁnes a linear form over Y∗. The problem of obtaining the vector ˆυ of
Y∗satisfying the conditions
maximize
yt ˆυ
subject to the constraints
Mt ˆυ ≤ˆχ
(6.378)
is called the canonical problem of linear programming.
The inputs of the two problems are the same ( M , y , and ˆχ ). While the unknown
of the ﬁrst (standard) problem is an element of X , the unknown of the second (canonical)
90Klee and Minty, 1972; Jeroslow, 1973; Hacijan, 1979; Gacs and Lovasc, 1981; Kônig and Pallaschke, 1981;
Cottle and Dantzig, 1968; Bartels, 1971; Mangasarian, 1981, 1983; Ciarlet and Thomas, 1982; Censor and Elfving,
1982; Cimino, 1938; Magnanti, 1976; Nazareth, 1984; McCall, 1982; Ecker and Kupferschmid, 1985; Karmarkar,
1984; de Ghellinck and Vial, 1985, 1986; Nash and Sofer, 1996.

226
Chapter 6. Appendices
problem is an element of Y∗, dual of Y . Any of the two problems is termed the dual of
the other problem, then called primal. This deﬁnition is useful because the solution of one
problem also gives the solution to the associated dual problem.
The basic duality theorem (Dantzig, 1963; Gass, 1975) is as follows: if feasible
solutions to both the primal and dual problems exist, there exists an optimum solution to
both problems, and
minimum of ˆχt x = maximum of yt ˆυ
.
(6.379)
The solution of the standard problem (6.377) can be written (see Appendix 6.23.1)
xsol =
xB
xL

=
(MB)−1y
0

,
(6.380)
where xB is the column matrix of basic components and MB is the basic submatrix of M .
Let
ˆχ =
 ˆχB
ˆχN

(6.381)
represent the partition of ˆχ into basic and nonbasic components. It can be shown (see, for
instance, Gass, 1975) that the solution of the dual problem (6.381) is then given by
ˆυsol = (MB)−t ˆχB
,
(6.382)
where (MB)−t denotes the transpose of the inverse of MB . The property (6.379) is then
easily veriﬁed:
ˆχt xsol = ( ˆχB)t xB = ( ˆχB)t (MB)−1 y = yt (MB)−t ˆχB = yt ˆυsol
.
(6.383)
The standard problem has been arbitrarily assumed to be a minimization problem. The
dual of a maximization problem can be obtained simply by changing the signs of M , y ,
and ˆχ . This gives the primal problem
maximize
ˆχt x
subject to the constraints
M x = y
,
x ≥0
,
(6.384)
and the dual problem
minimize
yt ˆυ
subject to the constraints
Mt ˆυ ≥ˆχ
.
(6.385)
6.23.3
Slack Variables in Linear Programming
The most general form of a linear programming problem is
minimize (resp., maximize)
at b
(6.386)
under the constraints
L1 b = c1
,
L2 b ≥c2
,
L3 b ≤c3
,
(6.387)
where b is the unknown vector, a , c1 , c2 , and c3 are given vectors, and L1 , L2 , and
L3 are given linear operators.

6.23. Elements of Linear Programming
227
The particular choice a = ˆχ , b = x , L1 = M , c1 = y , L2 = I , c2 = 0 , L3 = 0 ,
and c3 = 0 leads to the problem
minimize (resp., maximize)
ˆχt x
subject to the constraints
M x = y
,
x ≥0 ,
(6.388)
which is the standard problem of Appendix 6.23.2.
The particular choice a = −y , b = ˆυ , L1 = 0 , c1 = 0 , L2 = 0 , c2 = 0 , L3 =
Mt , and c3 = ˆχ leads to the problem
maximize (resp., minimize)
yt ˆυ
subject to the constraints
Mt ˆυ ≤ˆχ
,
(6.389)
which is the canonical problem of Appendix 6.23.2.
We see that the standard and canonical problems are special cases of (6.386)–(6.387).
We will now see that the reciprocal is also true.
Problem (6.386)–(6.387) can be written
minimize (resp., maximize)
at b
(6.390)
under the constraints
L1 b ≤c1
,
−L1 b ≤−c1
,
−L2 b ≤−c2
,
L3 b ≤c3 ,
(6.391)
and using
a = −y , b = ˆυ , Mt =


L1
−L1
−L2
L3

, ˆχ =


c1
−c1
−c2
c3


leads to the canonical form (6.389).
Introducing the slack variables b′ ≥0 , b′′ ≥0 , c2′ ≥0 , and c3′ ≥0 , and writing
b = b′ −b′′ , the problem (6.386)–(6.387) becomes
minimize (resp., maximize)
at (b′ −b′′)
(6.392)
under the constraints
L1 (b′ −b′′) = c1
,
L2 (b′ −b′′) −c2
′ = c2
,
L3 (b′ −b′′) + c3
′ = c3
,
b′ ≥0
,
b′′ ≥0
,
c2
′ ≥0
,
c3
′ ≥0 ,
(6.393)
and using
x =


b′
b′′
c2′
c3′

, ˆχ =


a
−a
0
0

, y =


c1
c2
c3

, and M =


L1
−L1
0
0
L2
−L2
−I
0
L3
−L3
0
I


leads to the standard form (6.388).

228
Chapter 6. Appendices
6.23.4
ℓ1-Norm Minimization Using Linear Programming
Below, the index i is assumed to belong to some set ID and the index α is assumed to belong
to some set IM . Assume the constants {di
obs} , {σ i
D} , {mα
prior} , {σ α
M} , {Giα} are given, and
consider the problem of obtaining the unknowns {ui} , {vi} , {aα} , {bα} , solution of the
following problem of constrained minimization:
minimize S =

i
ui + vi
σ i
D
+

α
aα + bα
σ α
M
subject to

G (a −b) −(u −v) = dobs −G mprior
,
u, v, a, b ≥0
.
(6.394)
Deﬁning
wi
D = 1/σ i
D
,
wα
M = 1/σ α
M
,
(6.395)
and setting
x =


a
u
b
v

,
ˆχ =


wM
wD
wM
wD

, M =
G
−I
−G
I
, y = dobs −G mprior ,
(6.396)
equations (6.394) can be written
minimize
ˆχt x
subject to
M x = y
,
x ≥0
,
(6.397)
which corresponds to the standard form of the linear programming problem.
To see the equivalence between this problem and the unconstrained ℓ1-norm mini-
mization problem, let us deﬁne m by
a −b = m −mprior
.
(6.398)
The second of conditions (6.394) then becomes
u −v = G m −dobs
.
(6.399)
It can be shown that in each vertex of the convex polyhedron deﬁned by (6.394), and due
to the particular structure of the linear system there, for any α , both aα and bα cannot be
̸= 0 simultaneously, and for any i , both ui and vi cannot be ̸= 0 simultaneously. Then,
at each vertex,
ui + vi = |ui −vi|
,
aα + bα = |aα −bα|
,
(6.400)
so that the S appearing in the ﬁrst of equations (6.394) can be written
S =

i
 (G m)i −di
obs

σ i
D
+

α
 mα −mα
prior

σ i
M
,
(6.401)

6.23. Elements of Linear Programming
229
which corresponds to the standard cost function for the ℓ1-norm criterion for the resolution
of linear problems. We have thus seen that the minimization of the S appearing in the
ﬁrst of equations (6.394) under the constraints expressed there (what constitutes a linear
programming problem) is equivalent to the usual unconstrained ℓ1-norm minimization.
In numerical analysis, ℓ1-norm minimization problems have been studied in approxi-
mation theory (Barrodale and Young, 1996; Barrodale, 1970; Barrodale and Roberts, 1973,
1974; Bartels, Conn, and Sinclair, 1978; Armstrong and Golfrey, 1979; Watson, 1980).
A useful package of routines has been developed by Cuer and Bayer (1980a,b). They
apply to the general problem
minimize

A∈Ix
|xA −xA
prior|
σ A
under the constraints

A x = b
,
0 ≤x ≤xmax
,
(6.402)
where xprior , xmax , A , and b are given, and where some of the constants σ A may be
inﬁnite. These algorithms allow the resolution of the standard linear programming problem.
6.23.5
ℓ∞-Norm Minimization Using Linear Programming
The following is adapted from Watson (1980). The problem of minimizing R as deﬁned
by equation (4.55) is equivalent to the problem of minimizing R subject to the constraints
−R ≤(G m −dobs)i
σ i
D
≤+R
,
−R ≤(m −mprior)α
σ α
M
≤+R
,
(6.403)
which can be rewritten as
(G m)i + σ i
D R ≤di
obs
,
(G m)i −σ i
D R ≥di
obs
,
mα + σ α
M R ≤mα
prior
,
mα + σ α
M R ≥mα
prior
.
(6.404)
The problem can then be written, in matricial form, as
minimize
0
1
t m
R

subject to


G
σ D
I
σ M
−G
σ D
−I
σ M


m
R

≥


dobs
mprior
−dobs
−mprior


,
(6.405)
where 0 denotes a vector of zeros and σ D and σ M are vectors containing data uncertainties
and a priori model uncertainties:
σ D =
3
σ i
D
(i ∈ID)
4
,
σ M =
3
σ α
M
(α ∈IM)
4
.
(6.406)
The problem (6.405) is the linear programming problem we have found in equation (6.385).
It cannot be solved by direct application of the simplex method, but the dual problem can

230
Chapter 6. Appendices
be written (see equation (6.384)) as
maximize


dobs
mprior
−dobs
−mprior


t 

ˆd1
ˆm1
ˆd2
ˆm2


subject to





G
σ D
I
σ M
−G
σ D
−I
σ M


t 

ˆd1
ˆm1
ˆd2
ˆm2

=

0
1

ˆd1 , ˆm1 , ˆd2 , ˆm2 ≥0
.
,
(6.407)
This last formulation corresponds to the standard form of the linear programming problem
and can be solved using the standard version of the simplex method. Once the solution of
the problem in the dual variables ˆd1 , ˆm1 , ˆd2 , and ˆm2 has been obtained, the values of
the variables m and R can be obtained using the equations of Appendix 6.23.2.
Using more compact notation, the problem (6.407) can be written
maximize
(dobs)t (ˆd1 −ˆd2) + (mprior)t ( ˆm1 −ˆm2)
subject to



Gt (ˆd1 −ˆd2) + ( ˆm1 −ˆm2) = 0
,
σ t
D (ˆd1 + ˆd2) + σ t
M ( ˆm1 + ˆm2) = 1
,
ˆd1 , ˆm1 , ˆd2 , ˆm2 ≥0
.
(6.408)
Barrodale and Phillips (1975a,b) give a modiﬁcation of the standard simplex method
that is well adapted to the special structure of this problem. For more details, see Watson
(1980).
6.24
Spaces and Operators
This appendix brings together the very basic deﬁnitions and properties the reader should
know if intending to explore the literature. Useful textbooks are Taylor and Lay (1980) and
Dautray and Lions (1984).
6.24.1
Basic Terminology
Let S0 and T be arbitrary sets, and let S be a subset of S0 . A rule that associates each
s in S with a unique element ϕ(s) in T is termed a function from S into T . Such a
function is properly denoted by ϕ , or by the expression s →ϕ(s) , although we often say
“the function ϕ(s) . ”
To allow suppleness in the discussions, the terms mapping, application, transforma-
tion, and operator are used as synonyms of function.
The subset S of S0 is the domain of deﬁnition of ϕ . If A is a subset of S , the set
ϕ(A) (i.e., the subset of T that can be attained by ϕ from elements of A ) is termed the
image of A (through ϕ ). The image of S , ϕ(S) , is called the range of ϕ .
If for each t in ϕ(S) there exists only one s ∈S such that ϕ(s) = t , the function
ϕ is one-to-one or injective. We then write s = ϕ−1(t) , thus deﬁning the inverse of ϕ on
ϕ(S) . If ϕ(S) = T , ϕ is termed surjective; it is also said that ϕ maps S onto T . When
ϕ is both injective and surjective, it is named bijective; then, ϕ−1(T) = S .

6.24. Spaces and Operators
231
If S and T are linear spaces (see below) and if, for any s1 and s2 , ϕ(λ s1 + µ s2 =
λ ϕ(s1)+µ ϕ(s2) , where λ and µ are arbitrary real numbers, ϕ is linear. A linear bijection
between linear spaces is an isomorphism. If there exists an isomorphism between two linear
spaces, they are termed isomorphic.
6.24.2
Topological Space
A topological space is a space S in which a collection of subsets of S has been deﬁned,
called the open subsets of S , verifying that
• ∅(the empty subset) and S are open subsets,
• any union of open subsets is an open subset,
• any ﬁnite intersection of open subsets is an open subset.
Example 6.5. Let ℜbe the real line and a < b . An open interval (a, b) is deﬁned as the
subset of real numbers r verifying a < r < b . Any reunion of open intervals is named an
open subset. This deﬁnes a topology over ℜ.
Let S be a topological space and A be an open subset of S . A subset of the form
S −A is called a closed subset.
Example 6.6. Let ℜbe the real line. For a < b , a closed interval [a, b] is deﬁned as the
subset of real numbers r verifying a ≤r ≤b . A closed interval is a closed subset.
Let S be a topological space. The following properties can be demonstrated:
• ∅and S are closed subsets,
• any intersection of closed subsets is a closed subset,
• any ﬁnite reunion of closed subsets is a closed subset.
In particular, we see that the sets ∅and S are at the same time open and closed. This is
exceptional: in general, a subset is neither open nor closed, and if it is open, it is not closed,
and vice versa.
Let S be a topological space and s be an element of S . A neighborhood of s is
an open subset containing s .
Let S be a topological space and (s1, s2, . . . ) be a sequence of elements of S . This
sequence tends to s if, for any neighborhood A of s in S , there exists an integer N such
that
n ≥N
⇒
sn ∈A
.
(6.409)
In that case, either of the two following notations is used:
sn →s
,
lim
n→∞sn = s
.
(6.410)

232
Chapter 6. Appendices
Let S and T be two topological spaces and ϕ be an application from S into T . ϕ is
called continuous at s0 if
lim
s→s0 ϕ(s) = ϕ(s0)
,
(6.411)
i.e., if, for any neighborhood B of ϕ(s0) in T , there exists a neighborhood A in T such
that
ϕ(A) ⊂B
.
(6.412)
6.24.3
Manifold
Let M be a topological space, and let M1, M2, . . . be a collection of open subsets of
M such that they cover all M . Any bijection φi from one of the Mi into a space Kn ,
isomorphic to ℜn , is termed a chart of Mi . A collection of charts deﬁned for each of the
Mi is called an atlas of M . If, for any {i, j} , the image of the open subset Mi ∩Mj is an
open subset of Kn , and if the images of Mi ∩Mj obtained respectively by φi and φj are
related by an isomorphism, then it is said that the set M is an (n-dimensional) manifold.
If the isomorphism is p times differentiable, it is named a Cp-manifold .
6.24.4
Metric Space
Let M be an arbitrary set. A distance over M associates any couple (M1, M2) of elements
of M with a positive real number denoted D(M1, M2) verifying the following conditions:
D(M1, M2) = 0
⇔
M1 = M2
,
(6.413a)
D(M1, M2) = D(M2, M1)
for any M1 and M2
,
(6.413b)
D(M1, M3) ≤D(M1, M2) + D(M2, M3)
for any M1, M2, and M3
.
(6.413c)
A set endowed with a distance is termed a metric space. Each element of a metric space
M is called a point of M .
Example 6.7. Let M be the surface of a sphere in a Euclidean space. A distance between
two points of the sphere can, for instance, be deﬁned as the length of the (smaller) arc of
the great circle passing through the points. Alternatively, the distance can be deﬁned as
the length of the straight segment joining the two points. With any of these deﬁnitions, the
surface of a sphere is a metric space.
Example 6.8. Let M be a space of n-dimensional column matrices,
m ∈M
⇒
m =


m1
m2
· · ·
mn


,
(6.414)

6.24. Spaces and Operators
233
each component representing a physical parameter with its own physical dimensions, and
σ 1, σ 2, . . . , σ n be some positive error bars. For any m1 and m2 , the expression
D(m1, m2) =

n

α = 1
|mα
1 −mα
2|p
(σ α)p
1/p
(6.415)
deﬁnes a real number. It is a distance over M . In fact, M is a linear space, which can be
normed by (see below)
∥m ∥= D(m, 0)
.
(6.416)
Example 6.9. Let E3 be the usual three-dimensional Euclidean space. Let x represent a
generic point of E3 and let x →m(x) be a function from E3 into a space of scalars K .
For instance, x may represent the Cartesian coordinates of a point inside a star, and m(x)
may represent the logarithmic temperature at the point x . Let M0 be the space of all such
functions. Letting m0(x) be a particular function of M0 , a new, smaller space M can be
deﬁned by the condition

E3 dV (x) | m(x) −m0(x) |p
s(x)p
is ﬁnite
,
(6.417)
where s(x) represents a positive function with physical dimensions ensuring the adimen-
sionality of the previous expression. Let m1 and m2 be two elements of M . The expression
D(m1, m2) =
 
E3
dV (x) | m1(x) −m2(x) |p
s(x)p
1/p
(6.418)
deﬁnes a distance over M , and then M is a metric space.
Let M be a metric space and (m1, m2, . . . ) be a sequence of points of M . This
sequence tends to the point m of M if
D(mn, m) →0
when
n →∞
,
(6.419)
i.e., if, for any ϵ > 0 , there exists an integer N such that
n ≥N
⇒
D(mn, m) ≤ϵ
.
(6.420)
Let M be a metric space and (m1, m2, . . . ) be a sequence of points of M . This sequence
is called a Cauchy sequence if, for any ϵ > 0 , there exists an integer N such that
n ≥N
and
m ≥N
⇒
D(mn, mm) ≤ϵ
.
(6.421)
Example 6.10. Let Q be the set of rational numbers. The sequence (1., 1.4, 1.41, 1.414,
1.4142, . . . ) (deﬁned by the decimal development of the number
√
2 ) is a Cauchy sequence.
Let M be a metric space. If the limit of every Cauchy sequence of points of M
belongs to M , the metric space M is said to be complete.

234
Chapter 6. Appendices
Example 6.11. The sequence in Example 6.10 does not converge to an element of Q : the
set of rational numbers is not complete. The real line ℜ(deﬁned in fact by the completion
of Q ) is complete.
Let M and D be metric spaces and g be an operator from M into D . We say that
g(m) tends to d0 when m tends to m0 if, for any ϵ > 0 , there exists a real number r
such that
D(m, m0) ≤r
⇒
D(g(m), d0) ≤ϵ
.
(6.422)
Let M and D be metric spaces and g be an operator from M into D . We say that
g is continuous at m0 if the limit of g(m) when m →m0 equals g(m0) .
Let M be a metric space. Then, a subset A of S is a metric open subset if, for any
point m0 ∈A , there exists ϵ > 0 such that every point m of M verifying D(m, m0) < ϵ
belongs to A . These metric open subsets verify the axioms of the (topological) open subsets
as deﬁned above: a metric space is always a topological space. It is said that a metric induces
a topology. The topology induced by the metric is termed the natural topology.
It can be shown that the concepts of limit and continuity deﬁned by the metric or by
the natural topology are equivalent.
Let M be a (topological) metric space. It can be shown that if A ⊂M is a closed
subset, then every point of M that is the limit of a sequence of points of A belongs to A .
6.24.5
Linear Space
Let M be a set, and let m denote a generic element of M . If we can deﬁne the sum
m1 + m2 of two elements of M and the multiplication λ m of an element of M by a real
number, verifying the following conditions:
m1 + m2 = m2 + m1
,
(m1 + m2) + m3 = m1 + (m2 + m3)
,
there exists 0 ∈M such that m + 0 = m
for any m
,
to each m there corresponds (−m) such that m + (−m) = 0
,
λ (m1 + m2) = λ m1 + λ m2
,
(λ + µ) m = λ m + µ m
,
(λ µ) m = λ (µ m)
,
1 m = m
,
(6.423)
then M is called a (real) linear vector space, or vector space, or linear space . The elements
of M are called vectors.
Example 6.12. Let E3 be the usual Euclidean space, x be a generic point of E3 , and
x →m(x) represent a function from E3 into an space of scalars K . If the deﬁnitions
(m1 + m2)(x) = m1(x) + m2(x)
,
(6.424a)
(λ m)(x) = λ m(x)
(6.424b)

6.24. Spaces and Operators
235
make sense, the set of all such functions is a linear space, denoted F . The subspace of F
formed by the continuous functions is also a linear space, denoted C . The subspace of F
formed by n-times differentiable functions is also a linear space, denoted Cn .
Let M be a linear space. It is a topological linear space if it is furnished with a
topological structure compatible with the structure of a linear space, i.e., such that the
applications (m1, m2) →m1 + m2 and (λ, m) →λ m are continuous (with respect to
the topology).
Let M be a linear space. A norm over M associates any element m of M with a
positive real number denoted ∥m ∥verifying the following conditions
∥m ∥= 0
⇔
m = 0
,
∥λ m ∥= |λ| ∥m ∥
for any λ and m
,
∥m + n ∥≤∥m ∥+ ∥n ∥
for any m and n
.
(6.425)
A linear space furnished with a norm is named a normed linear space.
Example 6.13. Let us consider a linear space F of functions x →m(x) from E3 into K ,
and, for 1 ≤p < ∞, the subspace of functions of F , for which the expression
∥m ∥=
 
E3 dV (x) | m(x) |p
s(x)p
1/p
(6.426)
makes sense and is ﬁnite, where 1/s(x)p is a given weight function (ensuring in particular
the physical adimensionality of ∥m ∥). This subspace is also a linear space, and ∥· ∥
deﬁnes a norm. This linear space is denoted Lp and plays an important role in mathematical
physics (more precisely, an element of the space Lp is not a function, but is of the class of
functions that are identical almost everywhere, i.e., such that the norm of their difference
is null).
Example 6.14. For p = 2 , the previous deﬁnition can be generalized. Let C(x, x′) be a
symmetric and positive deﬁnite function, i.e., a function such that, for any φ(x) and any
V ⊂E3 , the sum

V
dV (x)

V
dV (x′) φ(x) C(x, x′) φ(x′)
(6.427)
is deﬁned and is ﬁnite. A distribution (see Appendix 6.25) C−1(x, x′) can then be deﬁned
by

V
dV (x′) C(x, x′) C−1(x′, x′′) = δ(x −x′′)
,
(6.428)
and a linear space M can be deﬁned as the set of functions x →m(x) for which the
integral sum
∥m ∥=
 
V
dV (x)

V
dV (x′) m(x) C−1(x, x′) m(x′)
1/2
(6.429)

236
Chapter 6. Appendices
is deﬁned and is ﬁnite. It is easy to show that ∥· ∥deﬁnes a norm called a least-squares
norm. This space M is not L2 , but can be shown to be isomorphic with L2 (introduce
the positive deﬁnite operator C whose kernel is C(x, x′) , deﬁne the square root of C ,
verifying C =  t , and introduce a new space by
M′ = −1 M
;
(6.430)
this deﬁnes an isomorphism and induces the L2-norm over M′ ).
Example 6.15. It has been mentioned in Example 5.13 in the main text that the covariance
function
C(t, t′) = σ 2 exp

−|t −t′|
L

(6.431)
induces the Sobolev H1-norm.
It is easy to see that the expression
D(m1, m2) = ∥m1 −m2 ∥
(6.432)
deﬁnes a distance over M : a normed linear space is always a metric space. In particular,
this allows us to deﬁne a Cauchy sequence of vectors. If every Cauchy sequence of vectors
of M converges into an element of M , M is complete. A complete linear space is termed
a Banach space.
Example 6.16. The spaces Lp are Banach spaces (i.e., they are complete). The Sobolev
spaces HP (see Appendix 6.25) are complete.
Let M be a real linear space. A subset S of M is called a linear subspace if the
following conditions are satisﬁed:
m1 , m2 ∈S
⇒
m1 + m2 ∈S
,
m ∈S
⇒
λ m ∈S
.
(6.433)
It is easy to see that a linear subspace is itself a linear space.
Example 6.17. The space of continuous functions is a linear subspace of a linear space of
functions.
6.24.6
Dimension of a Linear Space, Basis of a Linear Space
Let M be a linear space and m1, m2, . . . be a ﬁnite or inﬁnite set of elements of M . If
none of the mi can be obtained as a linear combination of the others, the mi are linearly
independent.
Let M be a linear space. If there is some positive integer N such that M contains a
set of N vectors that are linearly independent, while every set of N +1 vectors are linearly

6.24. Spaces and Operators
237
dependent, then M is called ﬁnite dimensional and N is called the dimension of M . If
M is not ﬁnite dimensional, then it is called inﬁnite dimensional.
A set of vectors of a linear space M is called a basis if it is linearly independent and
if it can generate the whole M by linear combination.
Example 6.18. Let M be the space of periodical [ m(t + 2π) = m(t) ] , symmetrical
[ m(−t) = m(t) ] functions. As this space is inﬁnite dimensional, any basis has an inﬁnite
number of elements. A ﬁrst example is the countable basis
bn(t) = cos nt
,
n = 0, 1, . . .
.
(6.434)
Using the well-known Fourier decomposition, any function of M can be written
m(t) =
∞

n = 0
cn bn(t)
,
(6.435)
with c0 =
1
2π

 2π
0
dt m(t) and cn = 1
π

 2π
0
dt m(t) cos nt
(n = 1, 2, . . . ) . By linguistic
abuse, an (uncountable) basis (of distributions) can be considered,
b(ν, t) = δ(ν −t)
,
−∞< ν < +∞
,
(6.436)
where δ represents Dirac’s delta function. Any function m(t) can be developed into that
basis:
m(t) =
 ∞
−∞
dν c(ν) b(ν, t)
,
(6.437)
with
c(ν) = m(ν)
.
(6.438)
6.24.7
Linear Operator
Let M and D be two topological linear spaces and m →G(m) be an operator from M
into D . G is linear if
G(m1 + m2) = G(m1) + G(m2)
,
G(λ m) = λ G(m)
(6.439)
whenever λ is a scalar and m , m1 , m2 are vectors of M . Usually, linear operators are
represented by capital letters. If G is linear, the notation Gm is preferred to G(m) :
G(m) = G m
.
(6.440)
The linear operator G is called continuous if m →m0 (in the topology of M ) implies
G m →G m0 (in the topology of D ).
A linear operator deﬁned over a ﬁnite-dimensional space is always continuous. A
linear operator over an inﬁnite-dimensional space may be discontinuous.

238
Chapter 6. Appendices
Example 6.19. The derivative operator is linear. The derivative of the null function is the
null function. But it is easy to deﬁne a sequence of functions tending to the null function but
such that the limit of their derivatives does not tend to the null function. This implies that
the derivative operator, although linear, is not continuous.
The space of all continuous linear operators from M into D is denoted by L(M, D) .
Deﬁning the sum of two operators and the multiplication of an operator by a scalar by
(G1 + G2)(m) = G1 m + G2 m
,
(λ G)(m) = λ G m
,
(6.441)
the space L(M, D) is a linear space.
Let M and D be two normed linear spaces and G be a linear operator from M into
D . It can be shown that G is continuous if and only if there exists a constant c > 0 such
that, for any m ∈M ,
∥G m ∥≤c ∥m ∥
.
(6.442)
Then, the norm of a continuous operator can be deﬁned by
∥G ∥= supm∈M , m̸=0
∥G m ∥
∥m ∥
.
(6.443)
Let M1 and M2 be two Banach spaces and L be a continuous linear operator from M1
into M2 . If L is a bijection, then L−1 is also a continuous linear operator.
A bijection between the vector linear spaces M1 and M2 is said to be an isomorphism
of M1 onto M2 . Two linear spaces M1 and M2 are said to be isomorphic if there exists
an isomorphism of M1 onto M2 .
Let G be a linear operator from M into D . The linear subspace K of M for which
m ∈K
⇒
G m = 0
(6.444)
is called the kernel, or the null space, of G .
Let G be a linear operator from M into D . The dimension of G M (image of M
through G ) is called the rank of G . It can be shown that it equals the difference between
the dimension of M and the dimension of the kernel of G .
A sequence of linear operators H1, H2, . . . is called uniformly convergent if it con-
verges in norm, i.e., if
lim
n→∞∥Hn −H ∥= 0
.
(6.445)
Let H be a continuous linear operator from the Banach space M into itself. Then,
the limit
r(H) = lim
n→∞∥Hn ∥1/n
(6.446)
exists and is called the spectral radius of H . If the spectral radius of H is less than one,
then (I −H)−1 exists and is a continuous linear operator, and
(I −H)−1 =
∞

n=0
Hn
(Neumann series)
.
(6.447)

6.24. Spaces and Operators
239
6.24.8
Dual of a Linear Space
Let M be a real topological linear space. A form over M is an operator from M into the
real line ℜ. A linear form is a linear operator from M into ℜ.
The space of all continuous linear forms over M is termed the (topological) dual
space of M and is denoted by M∗. A generic element of M∗is denoted by ˆm . The result
of the action of ˆm ∈M∗over an m ∈M is denoted by either of the two notations
⟨ˆm , m ⟩= ˆmt m
.
(6.448)
The second notation is useful for numerical computations, because it recalls matricial no-
tation.
Let ˆm ∈M∗. The expression
∥ˆm ∥= supm∈M , m̸=0
 ⟨ˆm , m ⟩

∥m ∥
(6.449)
deﬁnes a norm over M∗. It can be shown that with such a norm, ˆm is a Banach space (i.e.,
it is complete).
Example 6.20. For 1 < p < ∞, the dual of Lp is Lq , with 1/p + 1/q = 1 .
Let M be a normed linear space and M∗be its dual. It can be shown that, for any
nonnull m ∈M , there exists ˆm ∈M∗verifying
∥ˆm ∥= ∥m ∥
,
⟨ˆm , m ⟩= ∥m ∥2 = ∥ˆm ∥2
.
(6.450)
Let M be a normed linear space and (M∗)∗be its bidual (dual of the dual). Then,
there exists a continuous linear application J from M into its bidual such that
(i)
J is injective
,
(ii)
∥J m ∥= ∥m ∥
for any m ∈M
.
(6.451)
It is then possible to identify M and its image J M ⊂(M∗)∗. We will see later (Riesz
theorem) that in Hilbert spaces, there exists a bijection between a space M and its dual
M∗. But they remain fundamentally different spaces, and the identiﬁcation of a space and
its dual, although perhaps useful for pure mathematical developments, is of no interest for
practical applications. On the contrary, the identiﬁcation between a space and (a subset of)
its bidual is always useful (for the purposes of inverse theory). If M equals its bidual, we
say that M is reﬂexive.
Example 6.21. For 1 < p < ∞, Lp is a reﬂexive Banach space. The dual of L1 is L∞,
but L1 is not reﬂexive. The Sobolev spaces Wp
m (see Appendix 6.25) are reﬂexive Banach
spaces (for 1 < p < ∞).
Let M be a topological linear space and M∗be its dual. The sequence m1, m2, . . .
of elements of M converges weakly to m ∈M if
lim
n→∞⟨ˆm , mn ⟩= ⟨ˆm , m ⟩
for any
ˆm ∈M∗
.
(6.452)

240
Chapter 6. Appendices
It converges strongly if
lim
n→∞∥mn −m ∥= 0
.
(6.453)
It can be shown that if M has ﬁnite dimension, then M∗has the same dimension.
6.24.9
Transpose Operator
Let M and D be two linear spaces and G be a linear operator from M into D . The
transpose of G is denoted Gt and is the linear operator from D∗into M∗deﬁned by
⟨Gt ˆd , m ⟩M = ⟨ˆd , G m ⟩D
,
(6.454a)
or, using the notation of equation (6.448),
(Gt ˆd)t m = ˆdt G m
.
(6.454b)
The reader will easily give sense to and demonstrate the equivalences
(G1 + G2)t = G1
t + G2
t , (G1 G2)t = G2
tG1
t , (Gt)−1 = (G−1)t , (Gt)t = G .
(6.455)
For more details, see Appendix 6.14.
6.24.10
Hilbert Spaces
Let M be a real linear space. A bilinear form over M is an application (m1, m2) →
W(m1, m2) from M × M into ℜsuch that
W(m1 + m2, m) = W(m1, m) + W(m2, m)
,
W(m, m1 + m2) = W(m, m1) + W(m, m2)
,
W(λ m1, m2) = W(m1, λ m2) = λ W(m1, m2)
.
(6.456)
A bilinear form is symmetric if
W(m1, m2) = W(m2, m1)
.
(6.457)
For a symmetric bilinear form, the following notation is used:
W(m1, m2) = m1
t W m2 = m2
t W m1
.
(6.458)
A bilinear form is positive deﬁnite if
m ̸= 0
⇒
mt W m > 0
.
(6.459)
It can be shown that if a bilinear form is positive deﬁnite, then it is also symmetric. It
can also be shown that if W is positive deﬁnite, then the expression
∥m ∥= (mt W m)1/2
(6.460)
is a norm over M .

6.24. Spaces and Operators
241
Let M be a real linear space and W be a positive deﬁnite bilinear form over M .
The pair (M, W) is called a real pre-Hilbert space. A pre-Hilbert space that is complete is
termed a Hilbert space. If (M, W) is a Hilbert space, the application m1t W m2 is called
a scalar product over M (and is sometimes denoted (m1, m2) ).
Let M be a Banach space. It can be shown that if the norm over M veriﬁes
∥m1 ∥2 + ∥m2 ∥2 = 1
2

∥m1 + m2 ∥2 + ∥m1 −m2 ∥2
,
(6.461)
then M isaHilbertspace(i.e., thenormcanbedeﬁnedfromascalarproductthrough(6.460)).
Then, conversely,
m1
t W m2 = 1
4

∥m1 + m2 ∥2 −∥m1 −m2∥2 
.
(6.462)
Example 6.22. L2 is a Hilbert space. The Sobolev space H2m is a Hilbert space (see
Appendix 6.25).
Property 6.1. Riesz Theorem. Let M be a Hilbert space and M∗be its dual. Let
ˆm ∈M∗. Then, there exists a unique m ∈M such that
ˆmt m′ = mt W m′
for any m′ ∈M
,
∥ˆm ∥= ∥m ∥
.
(6.463)
The reciprocal also holds: letting m ∈M , there exists a unique ˆm ∈M∗:
ˆmt m′ = mt W m′
for any m′ ∈M
,
∥ˆm ∥= ∥m ∥
.
(6.464)
The Riesz theorem shows that there exists an isometric isomorphism between M and its
dual M∗. Nevertheless, as in inverse problem theory a space and its dual play very different
roles, they should never be identiﬁed.
It can be shown that a Hilbert space is a reﬂexive Banach space.
Example 6.23. Let M be the L2 space of functions deﬁned over ℜn and D be the L2
space of functions deﬁned over ℜm . Let G(y, x) be a function from ℜm ×ℜn into ℜsuch
that

ℜm dy

ℜn dx
 G(y, x)
2 < ∞
.
(6.465)
Then, the operator G from M into D deﬁned by
d(y) =

ℜn dx G(y, x) m(x)
(6.466)
is a continuous linear operator.

242
Chapter 6. Appendices
6.24.11
Adjoint Operator
Let M and D be two Hilbert spaces with scalar products denoted respectively Wm(· , ·)
and Wd(· , ·) and let G be a linear operator from M into D . The adjoint of G is denoted
G∗and is the linear operator from D into M deﬁned by
Wm(G∗d , m) = Wd(d , G m)
.
(6.467)
Using the notation of (6.458) and the deﬁnition (6.454) of transpose operator, it follows
that
G∗= Wm
−1 Gt Wm
.
(6.468)
It should be emphasized that the terms ‘adjoint’ and ‘transpose’ are not synonymous. The
transpose operator is deﬁned for arbitrary linear spaces, irrespective of the existence of any
scalar product (think, for instance, of the transpose of a matrix), while the adjoint operator
is deﬁned only for scalar product (Hilbert) spaces.
6.25
Usual Functional Spaces
In the following, x denotes a point of a Euclidean n-dimensional space E with Cartesian
coordinates x = (x1, x2, . . . ) ; x →f (x) denotes a function from an open subset V of
E into ℜ. The symbol

dx denotes the volume integral over V , where dx denotes the
volume element.
The space Lp (1 ≤p ≤∞) : The space of functions such that the expression
∥f ∥=
 
dx | f (x) |p
s(x)p
1/p
(6.469)
is deﬁned and is ﬁnite, where 1/s(x) is a given positive weighting function, is called the
space Lp . Two functions f1 and f2 , such that ∥f1 −f2 ∥= 0 , are said to be equal almost
everywhere and are identiﬁed.
The space L∞is the space of functions for which the expression
∥f ∥= sup| f (x) |
s(x)
(6.470)
is ﬁnite.
When two functions that are equal almost everywhere are identiﬁed, the previous
expressions deﬁne a norm over Lp . With such a norm, the Lp spaces are Banach spaces
(i.e., they are complete).
The space L2 : In the particular case p = 2 , a scalar product can be introduced by
( f , g ) =

dx f (x) g(x)
s(x)2
.
(6.471)
Then,
∥f ∥= ( f , f )1/2
.
(6.472)
L2 is a Hilbert space (i.e., it is complete).

6.25. Usual Functional Spaces
243
If f (x) is, in fact, a vector-valued function f(x) (i.e., if it takes values in ℜn ), it has
components f 1(x) , f 2(x), . . . . Then, the scalar product is deﬁned by
( f , g ) =

i

dx f i(x) gi(x)
si(x)2
.
(6.473)
The corresponding space is a Hilbert space and is also denoted L2 .
The Sobolev space Hm : By deﬁnition, Hm is the space of L2 functions whose partial
derivatives up to order m are L2 functions. For instance, H0 is L2 , H1 is the space of
functions f ∈L2 such that ∂f/∂xi ∈L2 (for any i ), etc. Formally, Hm is the space of
functions such that
∂α1+···+αnf
∂(x1)α1 · · · ∂(xn)αn ∈L2
for 0 ≤(α1 + · · · + αn) ≤m
.
(6.474)
Let f and g be two functions of Hm . A scalar product is deﬁned by
( f , g ) =

0≤(α1+···+αn)≤m

dx
∂α1+···+αnf
∂(x1)α1 · · · ∂(xn)αn
∂α1+···+αng
∂(x1)α1 · · · ∂(xn)αn
(6.475)
(to shorten the notation, weighting factors have been omitted). With such a scalar product,
the Sobolev spaces Hm are complete.
The associated (squared) norm is given by
∥f ∥2 =

0≤(α1+···+αn)≤m

dx

∂α1+···+αn f
∂(x1)α1 · · · ∂(xn)αn
2
.
(6.476)
Example 6.24. Let x →f (x) be a one-dimensional function of a one-dimensional vari-
able. The corresponding H1 space is the space of L2 functions such that ∂f/∂x is L2 .
The scalar product is
( f , g ) =

dx f (x) g(x) +

dx ∂f
∂x
∂g
∂x
,
(6.477)
and the (squared) norm is given by
∥f ∥2 =

dx f (x)2 +

dx
∂f
∂x
2
.
(6.478)
The space H2 is the space of L2 functions such that ∂f/∂x and ∂2f/∂x2 are L2 . The
scalar product is
( f , g ) =

dx f (x) g(x) +

dx ∂f
∂x (x) ∂g
∂x (x) +

dx ∂2f
∂x2 (x) ∂2g
∂x2 (x)
,
(6.479)
and the (squared) norm is given by
∥f ∥2 =

dx f (x)2 +

dx
∂f
∂x (x)
2
+

dx
∂2f
∂x2 (x)
2
.
(6.480)

244
Chapter 6. Appendices
Example 6.25. Let (x, y) →f (x, y) be a one-dimensional function of a two-dimensional
variable. H0 is the space L2 . The space H1 is the space of L2 functions such that ∂f/∂x
and ∂f/∂y are L2 . The scalar product is
( f , g ) =

dx

dyf (x, y) g(x, y) +

dx

dy ∂f
∂x (x, y) ∂g
∂x )(x, y)
+

dx

dy ∂f
∂y (x, y) ∂g
∂y (x, y)
=

dx

dy f (x, y) g(x, y)
+

dx

dy gradf (x, y) · gradg(x, y)
.
(6.481)
The (squared) norm is given by
∥f ∥2 =

dx

dy

f (x, y)
2 +

dx

dy
∂f
∂x (x, y)
2
+

dx

dy
∂f
∂y (x, y)
2
=

dx

dy (f (x, y))2 +

dx

dy

gradf (x, y)
2
.
(6.482)
The space H2 is the space of L2 functions such that ∂f/∂x , ∂f/∂y , ∂2f/∂x∂y ,
∂2f/∂x2 , and ∂2f/∂y2 are L2 . The scalar product is
( f , g ) =

dx

dy f (x, y) g(x, y) +

dx

dy ∂f
∂x (x, y) ∂g
∂x (x, y)
+

dx

dy ∂f
∂y (x, y) ∂g
∂y (x, y) +

dx

dy ∂2f
∂x∂y (x, y) ∂2g
∂x∂y (x, y)
+

dx

dy ∂2f
∂x2 (x, y) ∂2g
∂x2 (x, y) +

dx

dy ∂2f
∂y2 (x, y) ∂2g
∂y2 (x, y)
.
(6.483)
TheSobolevspace Wp
m : Wp
m isthespaceof Lp functionswhosepartialderivatives
up to order m are Lp functions. For instance, W2
m is Hm , Wp
0 is Lp , and Wp
1 is the
space of functions f ∈Lp such that ∂f/∂xi ∈Lp (for i = 1, . . . , n ). Formally, Wp
m is
the space of functions such that
∂α1+···+αnf
∂(x1)α1 · · · ∂(xn)αn ∈Lp
for 0 ≤(α1 + · · · + αn) ≤m
.
(6.484)
The spaces Wp
m are Banach spaces with the norm
∥f ∥=


0 ≤(α1+···+αn) ≤m

dx

∂α1+···+αnf
∂(x1)α1 · · · ∂(xn)αn

p 1/p
.
(6.485)

6.26. Maximum Entropy Probability Density
245
6.26
Maximum Entropy Probability Density
Let V(x) be an arbitrary given vector function of a vector x . Let us demonstrate that among
all probability densities f (x) for which the mathematical expectation for V(x) equals V0 ,

dx V(x) f (x) = V0
,
(6.486)
the one that has minimum information (maximum entropy) with respect to a given probability
density µ(x) ,

dx f (x) log f (x)
µ(x)
minimum
,
(6.487)
necessarily has the form
f (x) = k µ(x) exp(−Wt V(x))
,
(6.488)
where k and W are constants (independent of x ).
The problem is to
minimize
S′(f (·)) =

dx f (x) log f (x)
µ(x)
(6.489)
under the constraints

dx f (x) = 1
,

dx V(x) f (x) = V0
.
(6.490)
This is a problem of constrained minimization, which is atypical in the sense that the variable
is a function (i.e., a variable in an inﬁnite-dimensional space). Nevertheless, the problem
can be solved using the classical method of Lagrange’s parameters (see Appendix 6.29). The
problem of minimization of S′ under the constraints (6.490) is equivalent to the problem
of unconstrained minimization of
S(f (·) , U , W) =

dx f (x) log f (x)
µ(x) −U

1 −

dx f (x)

−Wt

V0 −

dx V(x) f (x)

,
(6.491)
becausetheconditions ∂S/∂U = 0 and ∂S/∂W = 0 directlyimposetheconstraints(6.490).
We have
S(f (·) + δf (·) , U , W) −S(f (·) , U , W) =

dx (f (x) + δf (x)) log f (x) + δf (x)
µ(x)
−

dx f (x) log f (x)
µx + U

dx δf (x) + Wt

dx V(x) δf (x)
,
(6.492)
and using the ﬁrst-order development log(1+u) = u+O(u2) gives, everywhere f (x) ̸= 0 ,
log f (x) + δf (x)
µ(x)
= log f (x)
µ(x) + δf (x)
f (x) + O(δf 2)
,
(6.493)

246
Chapter 6. Appendices
and then,
S(f (·) + δf (·) , U , W) −S(f (·) , U , W)
=

dx

log f (x)
µ(x) + 1 + U + Wt V(x)

δf (x) + O(δf2)
.
(6.494)
The condition of minimum of S with respect to f (x) causes the factor of δf (x) on the
right of (6.494) to vanish, from which result (6.488) follows.
6.27
Two Properties of ℓp-Norms
6.27.1
First Property
Let us demonstrate the equivalence
ˆx = 1
p
∂
∂x ∥x ∥p
p
⇐⇒
x = 1
q
∂
∂ˆx ∥ˆx ∥q
q
,
(6.495)
where
1
p + 1
q = 1
.
(6.496)
The norm ∥x ∥p is deﬁned by
∥x ∥p =

i
|xi|p
(σ i)p
1/p
.
(6.497)
From
ˆxi = 1
p
 ∂
∂xi ∥x ∥p
p

,
(6.498)
it follows that
ˆxi = sg(xi) |xi|p−1
(σ i)p
,
(6.499)
equivalent to the two equations
sg(ˆxi) = sg(xi)
,
|ˆxi| = |xi|p−1
(σ i)p
.
(6.500)
From the second of these equations it follows that
|xi| = (σ i)p/(p−1) |ˆxi|1/(p−1) = (σ i)q |ˆxi|q−1
,
(6.501)
and, using the ﬁrst of (6.500),
xi = sg(ˆxi) |ˆxi|q−1
(ˆσ i)q
,
where
ˆσ i =
1
σ i
.
(6.502)

6.28. Discrete Derivative Operator
247
Now, deﬁning
∥ˆx ∥q =

i
|ˆxi|p
(ˆσ i)q
1/q
(6.503)
gives
xi = 1
q
 ∂
∂ˆxi ∥ˆx ∥q
q

.
(6.504)
6.27.2
Second Property
Let us here demonstrate the identities
ˆxt x = ∥x ∥p · ∥ˆx ∥q = ∥x ∥p
p = ∥ˆx ∥q
q
.
(6.505)
From equation (6.499), it directly follows that
ˆxt x =

i
ˆxi xi = ∥x ∥p
p
,
(6.506)
and, from the ﬁrst of equations (6.502),
ˆxt x = ∥ˆx ∥q
q
.
(6.507)
From the identity
∥x ∥p
p = ∥ˆx ∥q
q
(6.508)
already demonstrated, it follows that
∥ˆx ∥q = ∥x ∥q
p/q = ∥x ∥p
p−1
,
(6.509)
i.e.,
∥ˆx ∥q · ∥x ∥p = ∥x ∥p
p
.
(6.510)
6.28
Discrete Derivative Operator
We have seen in section 5.4.2 that there is a boundary condition to be satisﬁed if we wish
the derivative operator to be antisymmetric. This contrasts with matrix formulations, where
the transpose matrix is deﬁned unconditionally. Let us compare here the functional and the
discrete formulation of the derivative of a function.
In what follows, let us denote
x2 = x1 + Fx
,
x3 = x2 + Fx
,
. . .
,
(6.511)

248
Chapter 6. Appendices
and, to simplify notation, let us discretize functions using only ﬁve points. To ﬁnd a precise
ﬁniterepresentationofthederivativeoperator, itisbettertostartwiththeintegrationoperator.
The equation


F(x1)
F(x2)
F(x3)
F(x4)
F(x5)


= Fx


1
0
0
0
0
1
1
0
0
0
1
1
1
0
0
1
1
1
1
0
1
1
1
1
1




f (x1)
f (x2)
f (x3)
f (x4)
f (x5)


(6.512)
gives
F(x1) = Fx f (x1)
,
F(x2) = Fx ( f (x1) + f (x2) )
,
F(x3) = Fx ( f (x1) + f (x2) + f (x3) )
,
F(x4) = Fx ( f (x1) + f (x2) + f (x3) + f (x4) )
,
F(x5) = Fx ( f (x1) + f (x2) + f (x3) + f (x4) + f (x5) )
,
(6.513)
clearly a discrete approximation to the functional relation
F(x) =
 x
x1
dx′ f (x′)
.
(6.514)
The inverse of this relation is
f (x) = dF
dx (x)
,
(6.515)
anditsdiscreteversionisobtainedbycomputingtheinverseofthematrixinequation(6.512),


f (x1)
f (x2)
f (x3)
f (x4)
f (x5)


=
1
Fx


1
0
0
0
0
−1
1
0
0
0
0
−1
1
0
0
0
0
−1
1
0
0
0
0
−1
1




F(x1)
F(x2)
F(x3)
F(x4)
F(x5)


,
(6.516)
giving the discrete derivative operator. One obtains
f (x1) = F(x1)
Fx
,
f (x2) = F(x2) −F(x1)
Fx
,
f (x3) = F(x3) −F(x2)
Fx
,
f (x4) = F(x4) −F(x3)
Fx
,
f (x5) = F(x5) −F(x4)
Fx
,
(6.517)
and we see that this matrix operator has a built-in initial condition.
An equation using the transpose matrix is


ϕ(x1)
ϕ(x2)
ϕ(x3)
ϕ(x4)
ϕ(x5)


=
1
Fx


1
−1
0
0
0
0
1
−1
0
0
0
0
1
−1
0
0
0
0
1
−1
0
0
0
0
1




Z(x1)
Z(x2)
Z(x3)
Z(x4)
Z(x5)


,
(6.518)

6.29. Lagrange Parameters
249
which gives
ϕ(x1) = Z(x1) −Z(x2)
Fx
,
ϕ(x2) = Z(x2) −Z(x3)
Fx
,
ϕ(x3) = Z(x3) −Z(x4)
Fx
,
ϕ(x4) = Z(x4) −Z(x5)
Fx
,
ϕ(x5) = Z(x5)
Fx
.
(6.519)
We recognize here the opposite of the derivative operator, this time with a built-in ﬁnal
condition.
6.29
Lagrange Parameters
Let the problem be that of minimizing the real functional
S = S

xα

α ∈I

(6.520)
under the nonlinear constraints
8i
xα
= 0

i ∈J

,
(6.521)
where I and J represent discrete index sets.
The Lagrange method consists of introducing unknown parameters λi and deﬁning
a new functional S′(xα, λi) by
S′
xα, λi

= S

xα
−

i∈J
λi 8i
xα
.
(6.522)
The conditions ∂S′/∂λi = 0 give
8i
xα
= 0

i ∈J

,
(6.523)
while the conditions ∂S′/∂xα = 0 give
∂S
∂xα −

i∈J
λi
∂8i
∂xα = 0

α ∈I

.
(6.524)
Equations (6.523) show that at the minimum, the constraints (6.521) will be satisﬁed. It
follows that the constrained minimization of (6.520) is equivalent to the unconstrained
minimization of (6.522).
The system (6.523)–(6.524) has as many equations as unknowns (the xα and the λi ).
Its resolution gives the solution of the problem.
6.30
Matrix Identities
Letting G be an arbitrary linear operator from a linear space M into a linear space D and
CM and CD be two covariance operators acting respectively on M and D (i.e., two linear,

250
Chapter 6. Appendices
symmetric, positive deﬁnite operators), let us demonstrate the two identities

Gt C −1
D G + C −1
M

−1 Gt C −1
D
= CM Gt 
CD + G CM Gt
−1
,

Gt C −1
D G + C −1
M

−1 = CM −CM Gt 
CD + G CM Gt
−1 G CM
.
(6.525)
The ﬁrst equation follows from the following obvious identities:
Gt + Gt C −1
D G CM Gt = Gt C −1
D

CD + G CM Gt
=

Gt C −1
D G + C −1
M

CM Gt
,
(6.526)
since Gt C −1
D G + C −1
M
and CD + G CM Gt are positive deﬁnite and thus regular matrices.
Furthermore,
CM −CM Gt
CD + G CM Gt−1
G CM = CM −

Gt C −1
D G + C −1
M
−1
Gt C −1
D G CM
=

Gt C −1
D G + C −1
M
−1 
Gt C −1
D G + C −1
M

CM −Gt C −1
D G CM

=

Gt C −1
D G + C −1
M
−1
.
(6.527)
6.31
Inverse of a Partitioned Matrix
By direct substitution, one easily veriﬁes the identity (valid if the inverted matrices are
invertible)
B
Ct
C
D
−1
=
E
Ft
F
G

,
(6.528)
where
E = (B −Ct D−1 C)−1 , G = (D −C B−1 Ct)−1 , F = −G C B−1 = −D−1 C E .
(6.529)
6.32
Norm of the Generalized Gaussian
The generalized Gaussian of order p is deﬁned by
fp(x) =
p1−1/p
2 σ I(1/p) exp

−1
p
|x −x0|p
σ p

.
(6.530)
Let us demonstrate that it is normalized and let us perform a direct computation of its
ℓp-norm estimator of dispersion.
We have
Ip =
 +∞
−∞
dx fp(x) =
 +∞
−∞
dx fp(x + x0) = 2
 ∞
0
dx fp(x + x0)
=
p1−1/p
σ I(1/p)
 ∞
0
dx exp

−1
p
xp
σ p

.
(6.531)

6.32. Norm of the Generalized Gaussian
251
Introducing the variable u =
xp
p xp−1 , we successively have du = xp−1 dx
σ p
, dx =
σ p
xp−1 du =
σ u1−1/p
p1−1/p du , and
Ip =
1
I(1/p)
 ∞
0
du u1−1/p e−u
.
(6.532)
Using the deﬁnition of the gamma function, I(t) =

 ∞
0 du u1−t e−u , we directly obtain
Ip =
 +∞
−∞
dx fp(x) = 1
.
(6.533)
By deﬁnition, the estimator of dispersion in norm ℓp is (see Appendix 6.5)
σp =
  +∞
−∞
dx |x −x0|p fp(x)
1/p
.
(6.534)
We successively have
σp =
  +∞
−∞
dx |x|p fp(x + x0)
1/p
=

2
 ∞
0
dx |x|p fp(x + x0)
1/p
=
 p1−1/p
σ I(1/p)
 ∞
0
dx xp exp

−1
p
xp
σ p
1/p
,
(6.535)
and, using again the change of variables previously deﬁned,
σp =
 p σp
I(1/p)
 ∞
0
du u1−(1+1/p) e−u
1/p
=
p σ p I(1 + 1/p)
I(1/p)
1/p
.
(6.536)
Finally, using the property I(1 + t) = t I(t) , we obtain
σp = σ
.
(6.537)


Chapter 7
Problems
7.1
Estimation of the Epicentral Coordinates of a
Seismic Event
A seismic source was activated at time T = 0 in an unknown location at the surface of
Earth. The seismic waves produced by the explosion have been recorded at a network of
six seismic stations whose coordinates in a rectangular system are
(x1, y1) = (3 km , 15 km)
,
(x2, y2) = (3 km , 16 km)
,
(x3, y3) = (4 km , 15 km)
,
(x4, y4) = (4 km , 16 km)
,
(x5, y5) = (5 km , 15 km)
,
(x6, y6) = (5 km , 16 km)
.
(7.1)
The observed arrival times of the seismic waves at these stations are
t1
obs = 3.12 s ± σ
,
t2
obs = 3.26 s ± σ
,
t3
obs = 2.98 s ± σ
,
t4
obs = 3.12 s ± σ
,
t5
obs = 2.84 s ± σ
,
t6
obs = 2.98 s ± σ
,
(7.2)
where σ = 0.10 s, the symbol ±σ being a short notation indicating that experimental
uncertainties are independent and can be modeled using a Gaussian probability density
with a standard deviation equal to σ .
Estimate the epicentral coordinates (X, Y) of the explosion, assuming a velocity of
v = 5 km/s for the seismic waves. Use the approximation of a ﬂat Earth surface, and
consider that the coordinates in equation (7.1) are Cartesian.
Discuss the generalization of the problem to the case where the time of the explosion,
the locations of the seismic observatories, or the velocity of the seismic waves are not
perfectly known, and to the case of a realistic Earth.
Solution:
The model parameters are the coordinates of the epicenter of the explosion,
m = (X, Y)
,
(7.3)
253

254
Chapter 7. Problems
and the data parameters are the arrival times at the seismic network,
d = (t1, t2, t3, t4, t5, t6)
,
(7.4)
while the coordinates of the seismic stations and the velocity of the seismic waves are
assumed perfectly known (i.e., known with uncertainties that are negligible with respect to
the uncertainties in the observed arrival times).
For a given (X, Y) , the arrival times of the seismic wave at the seismic stations can
be computed using the (exact) equation
ti = gi(X, Y) = 1
v

xi −X
2 +

yi −Y
2
(i = 1, . . . , 6)
,
(7.5)
which solves the forward problem d = g(m) .
As we are not given any a priori information on the epicentral coordinates, we take a
uniform a priori probability density, i.e., because we are using Cartesian coordinates,
ρM(X, Y) = const. ,
(7.6)
assigning equal a priori probabilities to equal volumes.
As data uncertainties are Gaussian and independent, the probability density represent-
ing the information we have on the true values of the arrival times is
ρD(t1, t2, t3, t4, t5, t6) = const. exp

−1
2
6

i=1
(ti −ti
obs)2
σ 2

.
(7.7)
With the three pieces of information in equations (7.5)–(7.7), we can directly pass
to the resolution of the inverse problem. The posterior probability density in the model space,
combiningthethreepiecesofinformation, is(equation(1.93)) σM(m) = k ρM(m) ρD( g(m) ) ,
i.e., particularizing the notation to the present problem,
σM(X, Y) = k ρM(X, Y) ρD( g(X, Y) )
,
(7.8)
where k is a normalization constant. Explicitly, using equations (7.5)–(7.7),
σM(X, Y) = k′ exp

−1
2 σ 2
6

i=1
(ti
cal(X, Y) −ti
obs)2

,
(7.9)
where k′ is a new normalization constant and
ti
cal(X, Y) = 1
v
'
(xi −X)2 + (yi −Y)2
.
(7.10)
The probability density σM(X, Y) describes all the a posteriori information we have
on the epicentral coordinates. As we only have two parameters, the simplest (and most
general) way of studying this information is to plot the values of σM(X, Y) directly in the
region of the plane where it takes signiﬁcant values. Figure 7.1 shows the result obtained
in this way.

7.1. Estimation of the Epicentral Coordinates of a Seismic Event
255
Figure 7.1. Probability density for the epi-
central coordinates of the seismic event, obtained us-
ing as data the arrival times of the seismic wave at six
seismic stations (points at the top of the ﬁgure). The
gray scale is linear, between zero and the maximum
value of the probability density. The crescent-shape
of the region of signiﬁcant probability density cannot
be described using a few numbers (mean values, vari-
ances, covariances, . . . ), as commonly done.
We see that the zone of nonvanishing probability density is crescent-shaped. This
can be interpreted as follows. The arrival times of the seismic wave at the seismic network
(top left of the ﬁgure) are of the order of 3 s , and as we know that the explosion took place
at time T = 0 , and the velocity of the seismic wave is 5 km/s , this gives the reliable
information that the explosion took place at a distance of approximately 15 km from the
seismic network. But as the observational uncertainties (±0.1 s) in the arrival times are of
the order of the travel times of the seismic wave between the stations, the azimuth of the
epicenter is not well resolved. As the distance is well determined but not the azimuth, it is
natural to obtain a probability density with a crescent shape.
From the values shown in Figure 7.1 it is possible to obtain any estimator of the epicen-
tral coordinates one may wish, such as, for instance, the median, the mean, or the maximum
likelihood values. But the general solution of the inverse problem is the probability density
itself. Notice in particular that a computation of the covariance between X and Y will
miss the circular aspect of the correlation.
If the time of the explosion were not known, or the coordinates of the seismic sta-
tions were not perfectly known, or if the velocity of the seismic waves were only known
approximately, the model vector would contain all these parameters:
m = (X, Y, T, x1, y1, . . . , x6, y6, v)
.
(7.11)
After properly introducing the a priori information on T (if any), on (xi, yi) , and on v ,
the posterior probability density σM(X, Y, T, x1, y1, . . . , x6, y6, v) should be deﬁned as
before, from which the marginal probability density on the epicentral coordinates (X, Y)
could be obtained as
σX,Y(X, Y) =
 ∞
−∞
dT
 ∞
−∞
dx1 · · ·
 ∞
−∞
dy6
 ∞
0
dv σM(X, Y, T, x1, y1, . . . , x6, y6, v)
(7.12)
and the posterior probability density on the time T of the explosion as
σT (T ) =
 ∞
−∞
dX
 ∞
−∞
dY
 ∞
−∞
dx1 · · ·
 ∞
−∞
dy6
 ∞
0
dv σM(X, Y, T, x1, y1, . . . , x6, y6, v)
.
(7.13)
As computations rapidly become heavy, it may be necessary to make some simplifying
assumptions. The most drastic one is to neglect uncertainties on (xi, yi) and v , artiﬁcially

256
Chapter 7. Problems
increasing the nominal uncertainties in the observed arrival times, to approximately com-
pensate for the simpliﬁcation.
A realistic Earth is three-dimensional and heterogeneous. It is generally simpler to
use spherical coordinates (r, θ, ϕ) . Then, the homogeneous probability density is no longer
constant (see Example 1.6).
Also, for a realistic three-dimensional Earth, errors made in computing the travel
times of seismic waves may not be negligible compared to uncertainties in the observation
of arrival times at the seismic stations. Instead of using equation (1.93) of the main text as
a starting point, we may use equation (1.89) instead,
σM(m) = k ρM(m)

D
dd ρD(d) θ(d | m)
µD(d)
,
(7.14)
where θ(d | m) , the conditional probability density for the arrival time given the model
parameters, allows us to describe uncertainties in the computation of arrival times. As a
simple (simplistic?) example, one could take
θ(d | r, θ, ϕ, T ) = exp

−1
2 ( d −g(r, θ, ϕ, T ) )t C−1
T ( d −g(r, θ, ϕ, T ) )

,
(7.15)
where CT is an ad hoc covariance matrix approximately describing the errors made in
estimating arrival times theoretically. For more details, the reader may refer to Tarantola
and Valette (1982a).
7.2
Measuring the Acceleration of Gravity
An absolute gravimeter uses the free fall of a mass in vacuo to measure the value of the
acceleration g due to gravity. A mass is sent upward with some initial velocity v0 , and
the positions z1, z2, . . . of the mass are (very precisely) measured at different instants
t1, t2, . . . . In vacuo (orienting the z axis upward),
z(t) = v0 t −1
2 g t2
.
(7.16)
The measured values of the zi and the ti can be used to infer the values of v0 and g . The
measurements made during a free-fall experiment have provided the values (see Figure 7.2)
t1 = 0.20 s ± 0.01 s
,
z1 = 0.62 m ± 0.02 m
,
t2 = 0.40 s ± 0.01 s
,
z2 = 0.88 m ± 0.02 m
,
t3 = 0.60 s ± 0.01 s
,
z3 = 0.70 m ± 0.02 m
,
t4 = 0.80 s ± 0.01 s
,
z4 = 0.15 m ± 0.02 m
,
(7.17)
where the uncertainties91 in the times are of the boxcar type and the uncertainties in the
positions are of the double exponential type (the mean deviations having the value 0.02 m ).
Using these data, estimate the values v0 and g (although we are interested in the value of
g only), assuming that there is no particular a priori information on these two values.
91See Appendix 6.5 for the deﬁnition of the most common estimators of dispersion.

7.2. Measuring the Acceleration of Gravity
257
Figure 7.2.
At the left, the data for the estimation of the value g (gravity’s
acceleration), and, at the right, a suggested parabolic ﬁt. Note that this example solves the
problem of ﬁtting a series of points with uncertainties in the two axes. Uncertainty bars are
not to scale.
Solution:
Let us introduce the vector m with components
m = {v0, g, t1, t2, t3, t4}
(7.18)
and the vector d with components
d = {z1, z2, z3, z4}
.
(7.19)
Using expression (7.16) we can write the theoretical relations
z1 = v0 t1 −1
2 g t2
1
,
z2 = v0 t2 −1
2 g t2
2
,
z3 = v0 t3 −1
2 g t2
3
,
z4 = v0 t4 −1
2 g t2
4
(7.20)
that correspond to the usual relation d = g(m) (see the main text). Although we may
call m the model parameters and d the data parameters, we see that there are observed
quantities both in d and in m .
The prior information we have on m is to be represented by a probability density
ρM(m) = ρM(v0, g, t1, t2, t3, t4)
.
(7.21)
As we do not wish to include any special a priori information on the parameters {v0, g} , we
shall take a probability density that is constant on these parameters. The prior information
we have on the other four parameters, {t1, t2, t3, t4} , is to be represented using boxcar
probability densities. Then,
ρM(v0, g, t1, t2, t3, t4) =



k
if



tobs
1
−s1 ≤t1 < tobs
1
+ s1
and
tobs
2
−s2 ≤t2 < tobs
2
+ s2
and
tobs
3
−s3 ≤t3 < tobs
3
+ s3
and
tobs
4
−s4 ≤t4 < tobs
4
+ s4
,
0
otherwise
,
(7.22)
where tobs
1
= 0.20 s , tobs
2
= 0.40 s , tobs
3
= 0.60 s , tobs
4
= 0.80 s , and s1 = s2 = s3 =
s4 = 0.01 s .

258
Chapter 7. Problems
The information we have on d is to be represented by a probability density
ρD(d) = ρD(z1, z2, z3, z4)
.
(7.23)
Using the double exponential to model uncertainties gives
ρD(z1, z2, z3, z4)
= k exp

−
| z1 −zobs
1
|
σ1
+ | z2 −zobs
2
|
σ2
+ | z3 −zobs
3
|
σ3
+ | z4 −zobs
4
|
σ4
 
,
(7.24)
where zobs
1
= 0.62 m , zobs
2
= 0.88 m , zobs
3
= 0.70 m , zobs
4
= 0.15 m , and σ1 = σ2 =
σ3 = σ4 = 0.02 m .
We are here inside the context of Example 1.34: the posterior probability density of
the parameters m is given by (equation (1.93))
σM(m) = k ρM(m) ρD( g(m) )
,
(7.25)
where k is a normalization constant.
Collecting the partial results just obtained gives
σM(v0, g, t1, t2, t3, t4)
=



k exp( −S(v0, g, t1, t2, t3, t4))
if



tobs
1
−s1 ≤t1 < tobs
1
+ s1
and
tobs
2
−s2 ≤t2 < tobs
2
+ s2
and
tobs
3
−s3 ≤t3 < tobs
3
+ s3
and
tobs
4
−s4 ≤t4 < tobs
4
+ s4
,
0
otherwise
,
(7.26)
where
S(v0, g, t1, t2, t3, t4) = | (v0 t1 −1
2 g t2
1) −zobs
1
|
σ1
+ | (v0 t2 −1
2 g t2
2) −zobs
2
|
σ2
+ | (v0 t3 −1
2 g t2
3) −zobs
3
|
σ3
+ | (v0 t4 −1
2 g t2
4) −zobs
4
|
σ4
.
(7.27)
The information we have on the two parameters {v0, g} is that represented by the
marginal probability density
φ(v0, g) =
 +∞
−∞
dt1
 +∞
−∞
dt2
 +∞
−∞
dt3
 +∞
−∞
dt4 σM(v0, g, t1, t2, t3, t4)
,
(7.28)
i.e.,
φ(v0, g) = k
 tobs
1 +s1
tobs
1 −s1
dt1
 tobs
2 +s2
tobs
2 −s2
dt2
 tobs
3 +s3
tobs
3 −s3
dt3
 tobs
4 +s4
tobs
4 −s4
dt4 exp( −S(v0, g, t1, t2, t3, t4) )
,
(7.29)

7.3. Elementary Approach to Tomography
259
and the information we have on the parameter g itself is represented by
ϕ(g) =
 +∞
−∞
dv0 φ(v0, g)
.
(7.30)
Simple as they may seem, these integrations do not lead to an analytic expression (at
least, my favorite mathematical software was not able to obtain an explicit solution). Here,
the probability density φ(v0, g) has been evaluated using a numerical integration, and the
result (for the numerical data presented above) is displayed in Figure 7.3.
Figure 7.3. The data provided by an absolute gravime-
ter have been used to estimate both the initial velocity of the free-
falling mass and the acceleration of gravity. The numerical data
given in the text were generated using the values v0 = 4.12 m/s
and g = 9.81 m/s2 , and some noise was added to the zi values.
7.3
Elementary Approach to Tomography
Figure 7.4 shows an object composed of nine homogeneous portions. The values indicated
correspond to the linear attenuation coefﬁcients (relative to some reference medium, for
instance, water) for X-rays (in given units). An X-ray experiment using the geometry shown
in Figure 7.5 allows us to measure the transmittance ρij along each ray, which is given by
ρij = exp

−

Rij dsij m( x(sij) )

,
(7.31)
where m(x) represents the linear attenuation coefﬁcient at point x , Rij represents the
ray between source i and receiver j , and dsij is the element of length along the ray Rij .
Assume that instead of measuring ρij we measure
dij = −log ρij =

Rij dsij m( x(sij) )
,
(7.32)
which is termed the integrated attenuation.
Figure 7.4. A bidimensional medium is
composed of 3×3 homogeneous blocks. Indicated
are the true values of the linear attenuation coef-
ﬁcient for X-rays (with respect to the surrounding
medium).
L = 2
50.
60.
50.
60.
58.
60.
50.
60.
50.

260
Chapter 7. Problems
L = 2
R1
S2
S1
R6
R1
R6
Figure 7.5. In order to infer the true (unknown) values of the linear attenuation co-
efﬁcient, an X-ray transmission tomographic experiment is performed. Each block measures
L = 2 units of length, and the ﬁgure is to scale (the angular separation between rays is 4 de-
grees). S1 and S2 represent the two source locations, and R1, . . . , R6 represent the six re-
ceivers used. Let m(x) represent the linear attenuation coefﬁcient at point x of the medium
under study, Rij the ray between source 1 and receiver j , sij the position along ray Rij ,
and dij the integrated attenuation along ray Rij : dij =

dsij m( x(sij) ) (along Rij) .
The measured values of the integrated attenuation along each ray are, in order for each re-
ceiver, 341.9±0.1, 353.1±0.1, 356.2±0.1, 356.2±0.1, 353.1±0.1, and 341.9±9±0.1
for source 1 and 341.9 ± 0.1, 353.1 ± 0.1, 356.2 ± 0.1, 356.2 ± 0.1, 353.1 ± 0.1, and
341.9 ± 9 ± 0.1 for source 2 (these values correspond in fact to the actual values as they
can be computed from the true linear attenuation values of Figure 7.4, plus a Gaussian
noise with standard deviation 0.1 , and are rounded to the ﬁrst decimal). These values are
assumed to be corrected for the effect of the propagation outside the 3×3 model, so that the
linear attenuation coefﬁcient outside the model can be taken as null. The inverse problem
consists of using these observed values of integrated attenuation to infer the actual model
values. Remark that the upper-left block is explored with very short ray lengths, and owing
to the relatively high noise in the data, the actual value of this block will probably be poorly
resolved.
If the medium is a priori assumed to be composed of the nine homogeneous portions
of Figure 7.4, any model of the medium may be represented using the notation
m =


m11
m12
m13
m21
m22
m23
m31
m32
m33


,
(7.33)
where the ﬁrst index represents the column and the second index represents the row. Any
possible set of numerical values in equation (7.33) is a model vector. For instance, the true

7.3. Elementary Approach to Tomography
261
model is (Figure 7.4)


m11
m12
m13
m21
m22
m23
m31
m32
m33

=


50
60
50
60
58
60
50
60
50


.
(7.34)
A data vector is represented by
d =
d11
d12
dl3
d14
d15
d16
d21
d22
d23
d24
d25
d26

,
(7.35)
where the ﬁrst index denotes the source number and the second index denotes the receiver
number. Equation (7.32) then simpliﬁes to the discrete equation
dij =
3

α=1
3

β=1
Gij
αβ mαβ
for i = 1, 2
,
j = 1, 2, 3, 4, 5, 6
,
(7.36)
where Gij αβ representsthelengthoftheray ij insidetheblock αβ . Anactualmeasurement
of the integrated attenuation gives the values
d11
d12
dl3
d14
d15
d16
d21
d22
d23
d24
d25
d26

(7.37)
=
341.9 ± 0.1 353.1 ± 0.1 356.2 ± 0.1 356.2 ± 0.1 353.1 ± 0.1 341.9 ± 0.1
341.9 ± 0.1 353.1 ± 0.1 356.2 ± 0.1 356.2 ± 0.1 353.1 ± 0.1 341.9 ± 0.1

,
where ±0.1 indicates the standard deviation of the estimated (Gaussian) uncertainty.
Assume that you have the a priori information that the model values of the linear
attenuation coefﬁcients equal 55 ± 15 (Figure 7.6). Give a better estimation of them using
the data (7.37) and the least-squares theory. Discuss.
Figure 7.6. We have the a priori informa-
tion that the true linear attenuation coefﬁcients are
55±15 . It is assumed that a Gaussian probability
density well represents this a priori information (in
particular, ±15 represent soft limits, which can be
outpassed with a probability corresponding to the
Gaussian density function).
L = 2
55.
±15.
55.
±15.
55.
±15.
55.
±15.
55.
±15.
55.
±15.
55.
±15.
55.
±15.
55.
±15.

262
Chapter 7. Problems
Solution:
We wish here to obtain the model m minimizing
S(m) = 1
2

(G m −dobs)t C −1
D (G m −dobs) + (m −mprior)t C −1
M (m −mprior)

,
(7.38)
where
dobs =
341.9
353.1
356.2
356.2
353.1
341.9
341.9
353.1
356.2
356.2
353.1
341.9

, (CD)ijkl = 0.12 δik δjl
,
mprior =


55
55
55
55
55
55
55
55
55


,
(CM)αβγ δ = 152 δαγ δβδ
,
(7.39)
and where the elements of the kernel of the linear operator G can be obtained from Figure 7.5
using a simple geometrical computation:


G1111
G1112
G1113
G1121
G1122
G1123
G1131
G1132
G1133

=


0.3338
1.6971
0.0000
2.0309
0.0000
0.0000
2.0309
0.0000
0.0000


,


G1211
G1212
G1213
G1221
G1222
G1223
G1231
G1232
G1233

=


0.0000
2.0110
0.0000
0.0000
2.0110
0.0000
0.4883
1.5227
0.0000


,


G1311
G1312
G1313
G1321
G1322
G1323
G1331
G1332
G1333

=


0.0000
2.0012
0.0000
0.0000
2.0012
0.0000
0.0000
2.0012
0.0000


,


G1411
G1412
G1413
G1421
G1422
G1423
G1431
G1432
G1433

=


0.0000
2.0012
0.0000
0.0000
2.0012
0.0000
0.0000
2.0012
0.0000


,


G1511
G1512
G1513
G1521
G1522
G1523
G1531
G1532
G1533

=


0.0000
2.0110
0.0000
0.0000
2.0110
0.0000
0.0000
1.5227
0.4883


,


G1611
G1612
G1613
G1621
G1622
G1623
G1631
G1632
G1633

=


0.0000
1.6971
0.3338
0.0000
0.0000
2.0309
0.0000
0.0000
2.0309


,


G2111
G2112
G2113
G2121
G2122
G2123
G2131
G2132
G2133

=


0.0000
0.0000
0.0000
1.6971
0.0000
0.0000
0.3338
2.0309
2.0309


,
(7.40)

7.3. Elementary Approach to Tomography
263


G2211
G2212
G2213
G2221
G2222
G2223
G2231
G2232
G2233

=


0.0000
0.0000
0.0000
2.0110
2.0110
1.5227
0.0000
0.0000
0.4883


,


G2311
G2312
G2313
G2321
G2322
G2323
G2331
G2332
G2333

=


0.0000
0.0000
0.0000
2.0012
2.0012
2.0012
0.0000
0.0000
0.0000


,


G2411
G2412
G2413
G2421
G2422
G2423
G2431
G2432
G2433

=


0.0000
0.0000
0.0000
2.0012
2.0012
2.0012
0.0000
0.0000
0.0000


,


G2511
G2512
G2513
G2521
G2522
G2523
G2531
G2532
G2533

=


0.0000
0.0000
0.4883
2.0110
2.0110
1.5227
0.0000
0.0000
0.0000


,
and


G2611
G2612
G2613
G2621
G2622
G2623
G2631
G2632
G2633

=


0.3338
2.0309
2.0309
1.6971
0.0000
0.0000
0.0000
0.0000
0.0000


.
The minimum of expression (7.38) can, for instance, be obtained using the second of
equations 3.37 (page 66) of the main text:
m = mprior + (Gt C −1
D G + C −1
M )−1 Gt C −1
D (dobs −G mprior)
.
(7.41)
This gives
m =


55.9
59.3
50.3
59.3
58.4
60.2
50.3
60.2
50.3


.
(7.42)
The covariance operator describing a posteriori uncertainties in the model parameters
is (equation (3.38) of the text)
CM = (Gt C −1
D G + C −1
M )−1
.
(7.43)
Instead of representing variances and covariances of CM , it is more useful to represent
standard deviations and correlations (see Appendix 6.5). This gives the standard deviations
σM =


14.7
1.7
0.7
1.7
1.0
0.7
0.7
0.7
0.6


(7.44)

264
Chapter 7. Problems
and the coefﬁcients of correlation


R1111
R1112
R1113
R1121
R1122
R1123
R1131
R1132
R1133

=


1.0000
−0.9977
0.9536
−0.9977
0.9958
0.9874
0.9536
0.9874
0.9901


,


R1211
R1212
R1213
R1221
R1222
R1223
R1231
R1232
R1233

=


−0.9977
1.0000
−0.9710
0.9977
−0.9972
−0.9897
−0.9708
−0.9902
−0.9896


,


R1311
R1312
R1313
R1321
R1322
R1323
R1331
R1332
R1333

=


0.9536
−0.9710
1.0000
−0.9708
0.9657
0.9624
0.9948
0.9632
0.9515


,


R2111
R2112
R2113
R2121
R2122
R2123
R2131
R2132
R2133

=


−0.9977
0.9997
−0.9708
1.0000
−0.9972
−0.9902
−0.9710
−0.9897
−0.9896


,


R2211
R2212
R2213
R2221
R2222
R2223
R2231
R2232
R2233

=


0.9958
−0.9972
0.9657
−0.9972
1.0000
0.9776
0.9657
0.9776
0.9963


,


R2311
R2312
R2313
R2321
R2322
R2323
R2331
R2332
R2333

=


0.9874
−0.9897
0.9624
−0.9902
0.9776
1.0000
0.9632
0.9977
0.9622


,


R3111
R3112
R3113
R3121
R3122
R3123
R3131
R3132
R3133

=


0.9536
−0.9708
0.9948
−0.9710
0.9657
0.9632
1.0000
0.9624
0.9515


,


R3211
R3212
R3213
R3221
R3222
R3223
R3231
R3232
R3233

=


0.9874
−0.9902
0.9632
−0.9897
0.9776
0.9977
0.9624
1.0000
0.9622


,
(7.45)
and


R3311
R3312
R3313
R3321
R3322
R3323
R3331
R3332
R3333

=


0.9901
−0.9896
0.9515
−0.9896
0.9963
0.9622
0.9515
0.9622
1.0000


.
The solution (7.42) with the uncertainties (7.44) is represented in Figure 7.7 (to be
compared with Figure 7.4 and Figure 7.6). The a priori information was that the values
in each block were 55 ± 15 . We see that the a posteriori uncertainties are much smaller
except in block (1 , 1) , where the solution, 55.9 ± 14.7 , practically coincides with the a
priori information. As can be seen in Figure 7.5, this block contains very short lengths of

7.3. Elementary Approach to Tomography
265
Figure 7.7. The a posteriori solution ob-
tained by inversion of the available data. Note
that the value of the upper-left block has not been
resolved (a posteriori value and estimated uncer-
tainty almost identical to a priori values). The val-
ues of all other blocks have been estimated with a
relative uncertainty of less than 3%.
L = 2
55.9
±14.7
59.3
±1.7
50.3
±0.7
59.3
±1.7
58.4
±1.0
60.2
±0.7
50.3
±0.7
60.2
±0.7
50.3
±0.6
rays, so that it has practically not been explored by our data; the value of the attenuation
coefﬁcient is practically not resolved by the data set used. If a least-squares inversion were
performed with the data (7.37) but without using a priori information, that block would
certainly take very arbitrary values, thus polluting the values of the attenuation coefﬁcient
in all the other blocks. More dramatically, numerical instabilities could arise (because
the operator Gt C −1
D G could become numerically not positive deﬁnite due to computer
rounding errors) and the used computer code would crash with a “zero divide” diagnostic.
Except for the unresolved block m11 , the values obtained are close to the true values
and within the estimated error bar. Of course, as the data used were noise corrupted, the
obtained values cannot be identical to the true values. Using more rays would give a more
precise solution.
The data values recalculated from the solution (7.42) are
dobs =
341.92
353.10
356.20
356.20
353.10
341.90
341.89
353.10
356.20
356.20
353.10
341.92

,
(7.46)
which are almost identical to the observed values (7.39).
The coefﬁcients of correlation as shown in equation (7.45) are all very close to unity.
This is due to the fact that there is no independent information (all rays traverse at least three
blocks), and there is not much data redundancy.
Remark 7.1. Assume that a new experiment produces one new datum, corresponding to
a new ray (equal to or different from the previous rays). In order to incorporate this new
information, we can either take the a priori model (7.39) and perform an inversion using the
(7.40) data, or, more simply, we can take the a posteriori solution (7.42)-(7.44)-(7.45) as an
a priori solution for an inverse problem with a single datum (the new one). As demonstrated
in chapter 3, this gives exactly the same solution (thus showing the coherence of the a priori
information approach).
Remark 7.2. Usual computer codes consider that vectors (i.e., elements of a linear space)
are necessarily represented using column matrices and that the kernels of linear operators
are then represented using two-dimensional matrices. It may then be simpler for numerical

266
Chapter 7. Problems
computations to replace the previous notation with the matricial notation
dobs
=

341.9 353.1 356.2 356.2 353.1 341.9 341.9 353.1 356.2 356.2 353.1 341.9
t
,
(7.47)
(CD)ij = 0.12 δij ,
(7.48)
mprior =

55 55 55 55 55 55 55 55 55
t
,
(7.49)
(CM)αβ = 152 δαβ
,
(7.50)
and
G =


0.3338 1.6971 0.0000 2.0309 0.0000 0.0000 2.0309 0.0000 0.0000
0.0000 2.0110 0.0000 0.0000 2.0110 0.0000 0.4883 1.5227 0.0000
0.0000 2.0012 0.0000 0.0000 2.0012 0.0000 0.0000 2.0012 0.0000
0.0000 2.0012 0.0000 0.0000 2.0012 0.0000 0.0000 2.0012 0.0000
0.0000 2.0110 0.0000 0.0000 2.0110 0.0000 0.0000 1.5227 0.4883
0.0000 1.6971 0.3338 0.0000 0.0000 2.0309 0.0000 0.0000 2.0309
0.0000 0.0000 0.0000 1.6971 0.0000 0.0000 0.3338 2.0309 2.0309
0.0000 0.0000 0.0000 2.0110 2.0110 1.5227 0.0000 0.0000 0.4883
0.0000 0.0000 0.0000 2.0012 2.0012 2.0012 0.0000 0.0000 0.0000
0.0000 0.0000 0.0000 2.0012 2.0012 2.0012 0.0000 0.0000 0.0000
0.0000 0.0000 0.4883 2.0110 2.0110 1.5227 0.0000 0.0000 0.0000
0.3338 2.0309 2.0309 1.6971 0.0000 0.0000 0.0000 0.0000 0.0000


.
(7.51)
Equations (7.38) and (7.41) are then usual matricial equations.
7.4
Linear Regression with Rounding Errors
A physical quantity d is related to the physical quantity x through the equation
d = m1 + m2x
,
(7.52)
where m1 and m2 are unknown parameters. Equation (7.52) represents a straight line on
theplane (d, x) . Inordertoestimate m1 and m2 , theparameter d hasbeenexperimentally
measured for some selected values of x , and the following results have been obtained
(Figure 7.8):
x1 = 03.500
,
d1
obs = 2.0 ± 0.5
,
x2 = 05.000
,
d2
obs = 2.0 ± 0.5
,
x3 = 07.000
,
d3
obs = 3.0 ± 0.5
,
x4 = 07.500
,
d4
obs = 3.0 ± 0.5
,
x5 = 10.000
,
d5
obs = 4.0 ± 0.5
,
(7.53)

7.4. Linear Regression with Rounding Errors
267
Figure 7.8.
Some experimental
points. Uncertainty bars represent rounding
errors to the nearest integer. Solve the general
problem of estimating a regression line.
5
0
0
5
10
d
x
where ±0.5 denotes rounding errors (to the nearest integer). Estimate m1 and m2 . (Note:
this problem is nonclassical in the sense that experimental uncertainties are not Gaussian
and the usual least-squares regression is not adopted.)
Solution:
Let an arbitrary set (d1, d2, d3, d4, d5) be called a data vector and be denoted by d
and let an arbitrary set (m1, m2) be called a parameter vector and be denoted by m . Let
d = g(m)
(7.54)
denote the (linear) relationship
d1 = m1 + m2 x1
,
d2 = m1 + m2 x2
,
d3 = m1 + m2 x3
,
d4 = m1 + m2 x4
,
d5 = m1 + m2 x5
.
(7.55)
Let
ρM(m) = ρM(m1, m2)
(7.56)
be the probability density representing the a priori information (if any) on model parameters.
Let
ρD(d) = ρD(d1, d2, d3, d4, d5)
(7.57)
be the probability density describing the experimental uncertainties (see main text). As
rounding uncertainties are mutually independent,
ρD(d) = ρD(d1, d2, d3, d4, d5) = ρ1
D(d1) ρ2
D(d2) ρ3
D(d3) ρ4
D(d4) ρ5
D(d5)
,
(7.58)
where ρi
D(di) denotes the probability density describing the experimental uncertainty for
the observed data di . As the uncertainties are only rounding uncertainties, they can be
conveniently modeled using boxcar probability density functions:
ρi
D(di) =

const.
if di
obs −0.5 < di < di
obs + 0.5
,
0
otherwise
.
(7.59)

268
Chapter 7. Problems
This gives
ρD(d) =



const.
if



1.5 < d1 < 2.5
and
1.5 < d2 < 2.5
and
2.5 < d3 < 3.5
and
2.5 < d4 < 3.5
and
3.5 < d5 < 4.5
,
0
otherwise
.
(7.60)
The general solution of an inverse problem is obtained when the posterior probability
density in the model space has been deﬁned. It is given by equation (1.93) of the main
text:92
σM(m) = const. ρM(m) ρD( g(m) )
.
(7.61)
Equations (7.60) and (7.61) solve the problem.
For instance, if we accept a priori all pairs (m1, m2) as equally probable, and the
quantities {m1, m2} are Cartesian (see main text),
ρM(m) = ρM(m1, m2) = const.
,
(7.62)
then we obtain
σM(m) = σM(m1, m2) =



const.
if



1.5 < m1 + m2 x1 < 2.5
and
1.5 < m1 + m2 x2 < 2.5
and
2.5 < m1 + m2 x3 < 3.5
and
2.5 < m1 + m2 x4 < 3.5
and
3.5 < m1 + m2 x5 < 4.5
,
0
otherwise
.
(7.63)
Figure 7.9. The general solution of
the problem is given by the probability density
σM(m1, m2) for the parameters of the regres-
sion line. It is constant inside the dark region
and null outside. The dark region represents
the domain of admissible solutions. There is
no best line: all pairs (m1, m2) inside the re-
gion are equally likely.
0
-1
2
1
0.25
0.50
0.00
A
B
m1
m2
This result is represented graphically in Figure 7.9. The gray region has a positive
(constant) probability density. All pairs (m1, m2) inside this region have equal probability
density, and all pairs (m1, m2) outside it are impossible, so that this region represents the
domain of admissible solutions. Which is the best regression line? There is no such thing:
all lines inside the domain are equally good. Figure 7.10 shows two particular solutions
(giving extremal values for m1 and m2 ).
92Assuming here that the data space is a linear space, i.e., in fact, that the simple difference between the data
quantities di can be interpreted as a distance.

7.5. Usual Least-Squares Regression
269
Figure7.10. Twoparticularsolutions
(A and B in Figure 7.9), corresponding to ex-
tremal values of m1 and m2 . Notice that they
touch the extremities of the error bars (circles).
5
0
0
5
10
d
x
for m1 = -1 to 2 step 0.002
for m2 = 0 to 0.5 step 0.002
d1 = m1 + 3.5 m2
if ( d1 < 1.5 ) or ( d1 > 2.5 ) then next m2
d2 = m1 + 5.0 m2
if ( d2 < 1.5 ) or ( d2 > 2.5 ) then next m2
d3 = m1 + 7.0 m2
if ( d3 < 2.5 ) or ( d3 > 3.5 ) then next m2
d4 = m1 + 7.5 m2
if ( d4 < 2.5 ) or ( d4 > 3.5 ) then next m2
d5 = m1 + 10. m2
if ( d5 < 3.5 ) or ( d5 > 4.5 ) then next m2
draw point (m1,m2)
next m2
next m1
Figure 7.11. Computer code effectively used to obtain the result in Figure 7.9. The
limits for m1 and m2 in the ﬁrst two lines were chosen after trial and error. The step value
0.002 was chosen small enough not to be visible on the graphic device used to generate
Figure 7.9. The command draw point simply plots a point on the graphic device at the
given coordinates.
Figure 7.11 shows the computer code effectively used to obtain the general solution
shown in Figure 7.9. For problems with few model parameters (two in this example), the
full exploration of the model space is, in general, the easiest strategy (it takes approximately
2 min to go from the statement of the problem to the result in Figure 7.9).
7.5
Usual Least-Squares Regression
Find the best regression line for the experimental points in Figure 7.12, assuming Gaussian
uncertainties.
Solution:
Figure 7.12 suggests that uncertainties in the ti are negligible, while uncertainties in
the yi are uncorrelated. Let us introduce
m =
a
b

,
d =


y1
y2
· · ·
yn


,
G =


t1
1
t2
1
· · ·
· · ·
tn
1


(7.64)

270
Chapter 7. Problems
Figure 7.12. The physical parame-
ter y is related to the physical parameter t
through the equation y = a t + b , where the
parameters a and b are unknown. The ex-
perimental points in the ﬁgure have to be used
to estimate the best values for a and b in the
least-squares sense.
(the superscript numbers in y1, y2, . . . , t1, t2, . . . are indices, not powers). The equations
yi = a ti + b
(i = 1, 2, . . . , n)
(7.65)
can be written
d = G m
.
(7.66)
The matrix G is assumed perfectly known. We have some information on the true
values of d , and we wish to estimate the true value of m .
As it is assumed that uncertainties in the yi are uncorrelated Gaussian, the information
we have on the true value of d can be represented using a Gaussian probability density with
mathematical expectation
dobs =


(y0)1
(y0)2
· · ·
(y0)n


(7.67)
and covariance matrix
CD =


(σ 1)2
0
0
· · ·
0
(σ 2)2
0
· · ·
0
0
(σ 3)2
· · ·
· · ·
· · ·
· · ·
· · ·


.
(7.68)
We now need to introduce the a priori information (if any) on the parameters m . The
simplest results are obtained when using a Gaussian probability density in the model space
with mathematical expectation
mprior =
a0
b0

(7.69)
and covariance matrix
CM =
 σ 2a
ρ σa σb
ρ σa σb
σ 2b

.
(7.70)
As the information on both data and model parameters is Gaussian, we are under the
hypothesis of chapter 3. The a posteriori information on the model parameters is then also

7.5. Usual Least-Squares Regression
271
Gaussian, with mathematical expectation given by (equation (3.37))
m = mprior + ( Gt C −1
D G + C −1
M )−1 Gt C −1
D (dobs −G mprior)
= mprior + CM Gt ( G CM Gt + CD )−1 (dobs −G mprior)
(7.71)
and covariance matrix given by (equation (3.38))
CM = ( Gt C −1
D G + C −1
M )−1
= CM −CM Gt( G CM Gt + CD )−1G CM
.
(7.72)
The a posteriori (i.e., recalculated) data values are then (equation at left in (3.44))
d = G mpost
,
(7.73)
and the a posteriori data uncertainties are given by (equation at right in (3.44))
CD = G CM Gt
.
(7.74)
As we have only two model parameters, the ﬁrst equation in each of the expres-
sions (7.71)–(7.72) should be preferred. An easy computation gives the a posteriori values
of a and b ,
a = a0 + A P −C Q
A B −C2
,
b = b0 + B Q −C P
A B −C2
,
(7.75)
and the a posteriori standard deviations and correlation,
σa =
1
'
B −C2/A
,
σb =
1
'
A −C2/B
,
ρ =
−1
'
AB/C2
,
(7.76)
where
A =

i
1
(σ i)2 +
1
(1 −ρ2) σb2
,
B =

i
(ti)2
(σ i)2 +
1
(1 −ρ2) σa2
,
C =

i
ti
(σ i)2 −
ρ
(1 −ρ2) σa σb
,
P =

i
ti
(σ i)2

(y0)i −(a0 ti + b0)

,
(7.77)
and
Q =

i
1
(σ i)2

(y0)i −(a0 ti + b0)

.
(7.78)
Usually, a priori uncertainties on model parameters are uncorrelated. Then,
ρ = 0
.
(7.79)

272
Chapter 7. Problems
This gives
A =

i
1
(σ i)2 + 1
σb2
,
B =

i
(ti)2
(σ i)2 + 1
σa2
,
C =

i
ti
(σ i)2
.
(7.80)
If there is no a priori information on model parameters,
σa →∞
,
σb →∞
.
(7.81)
Instead of taking these limits in the last equations, it is simpler to use
C −1
M
= 0
(7.82)
in equations (7.71) and (7.72). This gives
mpost = ( Gt C −1
D G )−1Gt C −1
D dobs
(7.83)
and
CM′ = ( Gt C −1
D G )−1
.
(7.84)
Equations (7.75) then become
a = A P −C Q
A B −C2
,
b = B Q −C P
A B −C2
,
(7.85)
while the constants A , B , C , P , and Q simplify to
A =

i
1
(σ i)2
,
B =

i
(ti)2
(σ i)2
,
C =

i
ti
(σ i)2
,
P =

i
ti (y0)i
(σ i)2
,
Q =

i
(y0)i
(σ i)2
.
(7.86)
If all data uncertainties are identical,
σ i = σ
,
(7.87)
then
A =
n
σ 2
,
B =
1
σ 2

i
(ti)2
,
C =
1
σ 2

i
ti
,
P =
1
σ 2

i
ti (y0)i
,
Q =
1
σ 2

i
(y0)i
.
(7.88)

7.6. Least-Squares Regression with Uncertainties in Both Axes
273
Figure 7.13. The physical parame-
ter y is related to the physical parameter t
through the equation y = a t + b , where the
parameters a and b are unknown. The ex-
perimental points in the ﬁgure have to be used
to estimate the best values for a and b in the
least-squares sense. This problem is nonclas-
sical in the sense that uncertainties are present
in both coordinates. The numerical values on
the axes are not indicated.
7.6
Least-Squares Regression with Uncertainties in
Both Axes
Find the best regression line for the experimental points in Figure 7.13, assuming Gaussian
uncertainties.
Solution:
There are some equivalent ways of properly setting this problem.
The approach
followed here has the advantage of giving a symmetrical treatment to both axes.
As the statement of the problem refers to a regression line, a linear relationship has
to be assumed between the variables y and t :
α y + β t = 1
.
(7.89)
We have measured some pairs (xi, yi) and wish to estimate the true values of α and β .
Let us introduce a parameter vector m that contains the yi , the ti, α , and β :
m =

y t u
t =

y1 y2 · · · t1 t2 · · · α β
t
,
(7.90)
and, for each conceivable value of m , let us deﬁne a vector
d =

d1 d2 · · ·
t
(7.91)
by
di = gi(m) = α yi + β ti
(i = 1, 2, . . . )
.
(7.92)
Deﬁning the observed value of d and the a priori value of m respectively as
dobs =

1 1 1 · · ·
t
,
mprior =

y1
0 y2
0 · · · t1
0 t2
0 · · · α0 β0
t
,
(7.93)
where y0 and t0 are the experimental values, and α0 and β0 are the a priori values of α
and β , the inverse problem can now be set as the problem of obtaining a vector m such
that g(m) is close (or identical) to dobs and m is close to mprior . We see thus that this
relabeling of the variables allows an immediate use of the standard equations. Nevertheless,

274
Chapter 7. Problems
this problem is less simple than the previous problem of one-axis regression, because here
we have twice the number of points + 2 unknowns instead of 2, and the forward equation
d = g(m) is nonlinear (because it contains the mutual product of parameters).
More precisely, we assume that the a priori information on m can be described using
a Gaussian probability density with mathematical expectation mprior and covariance matrix
CM =


Cy
0
0
0
0
Ct
0
0
0
0
σ 2
α
0
0
0
0
σ 2
β


,
(7.94)
where independence of uncertainties has been assumed only to simplify the notation. The
a priori information on d is also assumed to be Gaussian, with mathematical expectation
dobs and covariance matrix CD . Later, we may take CD = 0 , so that the observed values
dobs may be ﬁtted exactly by the a posteriori solution. Instead, we may keep CD ﬁnite to
allow for uncertainties in the hypothesis of a strictly linear relationship between y and t .
Now we are exactly under the hypothesis of section 3.2.3. The a posteriori probability
density for m is (equations (3.45)–(3.46))
σM(m) = const. exp( −S(m) )
,
(7.95)
with
2 S(m) = (g(m) −dobs)t C −1
D
(g(m) −dobs) + (m −mprior)t C −1
M (m −mprior)
.
(7.96)
Owing to the nonlinearity of g(m) , this is not a Gaussian probability density. The maximum
likelihood value of m can be obtained using, for instance, the iterative algorithm
mn+1 = mprior −CM Gn
t( Gn CM Gn
t + CD )−1 
(g(mn) −dobs) −Gn(mn −mprior)

.
(7.97)
We have
Gn =

∂g
∂y

mn

∂g
∂t

mn

∂g
∂α

mn

∂g
∂β

mn

,
(7.98)
which gives
Gn =
αn I
βn I
yn
tn

,
(7.99)
CM Gn
t =


αn Cy
βn2 Ct
σ 2
α ynt
σ 2
β tnt


,
(7.100)
Gn CM Gn
t + CD = σ 2
α yn yn
t + σ 2
β tn tn
t + αn
2 Cy + βn
2 Ct + CD
,
(7.101)

7.7. Linear Regression with an Outlier
275
and
g(mn) −dobs −Gn (mn −mprior) = (α0 −αn) yn + (β0 −βn) tn −dobs + αn y0 + βn t0
.
(7.102)
Denoting
δ ˆdn = ( Gn CM Gn
t + CD )−1 
(g(mn) −dobs) −Gn (mn −mprior)

,
(7.103)
the iterative algorithm (7.97) can be written
yn+1 = y0 −αn Cy δ ˆdn
,
tn+1 = t0 −βn Ct δ ˆdn
,
αn+1 = α0 −σ 2
α yn
t δ ˆdn
,
(7.104)
and
βn+1 = β0 −σ 2
β tn
t δ ˆdn
.
(7.105)
The algorithm usually converges in a few iterations (≃3) . The values α∞and
β∞are the estimated values of the parameters deﬁning the regression line, and the values
(ti
∞, yi
∞) (i = 1, 2, . . . ) are the a posteriori values of the experimental points. If CD = 0 ,
the a posteriori points belong to the straight line.
7.7
Linear Regression with an Outlier
Two variables y and t are related through a linear relationship
y = a t + b
.
(7.106)
In order to estimate the parameters a and b , the 11 experimental points (yi, ti) shown in
Figure 7.14 have been obtained. It is clear that if the linear relationship (7.106) applies,
then the point indicated with an arrow must be an outlier. Suppress that point and solve the
problem of estimating a and b under the hypothesis of Gaussian uncertainties. Does the
solution change very much if the outlier is included? Assume now that uncertainties can be
modeled using an exponential probability density, and solve the problem again. Discuss the
relative robustness of the Gaussian and exponential hypotheses with respect to the existence
of outliers in a data set.
Figure 7.14. Two variables y and
t are related by the relationship y = a t +
b , where a and b are unknown parameters.
In order to estimate a and b , an experiment
has been performed that has furnished the 11
experimental points shown in the ﬁgure. The
exact meaning of the error bars is not indicated.

276
Chapter 7. Problems
Solution:
Let
m = (a, b)
(7.107)
denote a model vector and
d = (d1, d2, . . . )
(7.108)
denote a data vector. The (exact) theoretical relationship between d and m is linear,
di = a ti + b
,
(7.109a)
or, for short,
d = G m
,
(7.109b)
where G is a linear operator.
Assume that the homogeneous probability density on model parameters is
µM(a, b) = const.
(7.110)
and that we do not have a priori information on model parameters,
ρM(a, b) = µM(a, b) = const.
(7.111)
Assume that the homogeneous probability density on data parameters is
µD(d1, d2, . . . ) = const.
(7.112)
If ρD(d1, d2, . . . ) is the probability density representing the information on the true
values of (d1, d2, . . . ) as obtained through the measurements, then the Gaussian hypothesis
gives (for independent uncertainties)
ρD(d1, d2, . . . ) = exp

−1
2

i

di −di
obs
2
σ 2

,
(7.113)
where dobs is the vector of observed values
dobs =

10. , 11. , 11. , 12. , 13. , 14. , 14. , 15. , 15. , 16. , 2.

(7.114)
and where, if we interpret the error bars in Figure 7.14 as standard deviations,
σ = 2.
(7.115)
We are here in the context of Example 1.34 (page 34).
Therefore, the posterior
probability density on the model parameters is (equation (1.93))
σM(m) = k ρM(m) ρD( g(m) )
.
(7.116)

7.7. Linear Regression with an Outlier
277
Figure 7.15. The probability density for the pa-
rameters (a, b) obtained using the Gaussian hypothesis
for experimental uncertainties and without using the out-
lier.
5
10
15
20
-0.4
-0.5
-0.6
b
a
Figure 7.16.
The maximum likeli-
hood line for the probability density in Fig-
ure 7.15.
y
t
10
20
30
30
10
5
Figure 7.17. Same as Figure 7.15, but the 11 ex-
perimental points have been used. The outlier has trans-
lated the probability density. This shows that the Gaussian
hypothesis is not very robust with respect to the existence
of a small number of outliers in a data set.
5
10
15
20
-0.4
-0.5
-0.6
b
a
Introducing the results above, we obtain
σM(a, b) = exp

−1
2

i

di
obs −di
cal(a, b)
2
σ 2

,
(7.117)
where
di
cal(a, b) = a ti + b
.
(7.118)
As this problem only has two model parameters, the simplest way to analyze the
a posteriori information we have on model parameters is to directly compute the values
σM(a, b) in a given grid and to plot the results. Figure 7.15 shows the corresponding result
if the outlier is suppressed from the data set (only 10 points have been used). This probability
density is Gaussian, and the line corresponding to its center is shown in Figure 7.16. If the
outlier is not suppressed, so that the 11 points are used, the probability density σM(a, b)
obtained is shown in Figure 7.17. The probability density has been essentially translated
by the outlier. The line corresponding to the center of the probability density is shown in
Figure 7.18. Figures 7.17 and 7.18 show that the Gaussian assumption gives results that

278
Chapter 7. Problems
Figure 7.18.
The maximum likeli-
hood line for the probability density in Fig-
ure 7.17.
Figure7.19. Theexponentialhypothesisfordata
uncertainties has been used instead of the Gaussian hy-
pothesis. Here the outlier has not been used. The solution
looks similar to the solution corresponding to the Gaus-
sian hypothesis in Figure 7.15.
5
10
15
20
-0.4
-0.5
-0.6
b
a
Figure 7.20.
The maximum likeli-
hood line for the probability density in Fig-
ure 7.19.
y
t
10
20
30
30
10
5
Figure 7.21. The probability density using all
11 experimental points in the exponential hypothesis. By
comparison with Figure 7.19, we see that the introduction
of the outlier does not completely distort the solution. This
shows that the exponential hypothesis is more robust than
the Gaussian hypothesis with respect to the existence of a
few outliers in a data set.
5
10
15
20
-0.4
-0.5
-0.6
b
a
Figure 7.22.
The maximum likeli-
hood line for the probability density in Fig-
ure 7.21.

7.8. Condition Number and A Posteriori Uncertainties
279
are not robust with respect to the existence of outliers in a data set. This may be annoying,
because in multidimensional problems it is not always easy to detect outliers.
If instead of assuming an uncorrelated Gaussian, we assume uncorrelated exponential
uncertainties, equation (7.113) is replaced with
ρD(d1, d2, . . . ) = exp

−

i
di −di
obs

σ

.
(7.119)
The a posteriori probability density is then
σM(a, b) = exp

−

i
di
obs −di
cal(a, b)

σ

.
(7.120)
This probability density is shown in Figure 7.19 for all points but the outlier, and in
Figure 7.21 for all 11 points. The corresponding maximum likelihood lines are shown in
Figures 7.20 and 7.22. We see that the introduction of the outlier deforms the posterior prob-
ability density, but it does not translate it. The exponential hypothesis for data uncertainties
is more robust than the Gaussian hypothesis.
It should be noticed that the question of which probability density may truly represent
the experimental uncertainties for the data in Figure 7.14 has not been addressed. Obviously,
it is not Gaussian, because the probability of a outlier like the one present in the ﬁgure is
extremely low. But the probability of such an outlier is also very low in the exponential
hypothesis. A careful examination of the experimental conditions can, in principle, suggest
a realistic choice of probability density for representing uncertainties, but this is not always
easy. The conclusion of this numerical example is that if a probability density adequately
representing experimental uncertainties is unknown, but we suspect a small number of large
errors, we should not take the Gaussian probability density, but a more long-tailed one.
7.8
Condition Number and A Posteriori Uncertainties
The (Cramer’s) solution of the system


10
7
8
7
7
5
6
5
8
6
10
9
7
5
9
10




m1
m2
m3
m4

=


32.0
23.0
33.0
31.0


(7.121)
is


m1
m2
m3
m4

=


1.0
1.0
1.0
1.0


,
(7.122)
while the solution of the system


10
7
8
7
7
5
6
5
8
6
10
9
7
5
9
10




m1
m2
m3
m4

=


32.1
22.9
33.1
30.9


,
(7.123)

280
Chapter 7. Problems
where the right-hand side has been slightly modiﬁed, is completely different:


m1
m2
m3
m4

=


9.2
−12.6
4.5
−1.1


.
(7.124)
This result may be surprising, because the determinant of the matrix of the system is
not small (it equals one), and the inverse matrix looks as ordinary as the original one:


10
7
8
7
7
5
6
5
8
6
10
9
7
5
9
10


−1
=


25
−41
10
−6
−41
68
−17
10
10
−17
5
−3
−6
10
−3
2


.
(7.125)
This nice example is due to R.S. Wilson, and is quoted by Ciarlet (1982). Clearly,
the matrix in the example has some special property, which it is important to identify. In
classical numerical analysis, it is usual to introduce the concept of the condition number of
a matrix. It is deﬁned by
cond(A) = ∥A ∥∥A−1 ∥
,
(7.126)
where ∥A ∥denotes a given matricial norm. For instance, the ℓp matricial norms can be
deﬁned by
∥A ∥1 = sup ∥A v ∥1
∥v ∥1
,
∥A ∥2 = sup ∥A v ∥2
∥v ∥2
,
∥A ∥∞= sup ∥A v ∥∞
∥v ∥∞
,
(7.127)
and verify (e.g., Ciarlet, 1982)
∥A ∥1 = max

i
|Aij| , ∥A ∥2 =
'
max λi(A∗A) , ∥A ∥∞= max

j
|Aij| ,
(7.128)
where λi(A) denotes the eigenvalues of the matrix A and A∗denotes the adjoint of A
(the difference between adjoint and transpose is explained elsewhere in this text; for this
example, let us simply admit that we only consider Euclidean scalar products, and adjoint
and transpose coincide).
The interpretation of the condition number is obtained as follows. Let A and d
respectively represent a given regular matrix and a given vector, and let m represent the
solution of A m = d ,
m = A−1 d
.
(7.129)
Let now m + δm represent the solution of the perturbed system
A(m + δm) = d + δd
.
(7.130)

7.8. Condition Number and A Posteriori Uncertainties
281
From d = A m and δm = A−1 δd , it can be deduced that
∥d ∥≤∥A ∥∥m ∥
,
∥δm ∥≤∥A−1 ∥∥δd ∥
,
(7.131)
i.e.,
∥δm ∥
∥m ∥≤∥A ∥∥A−1 ∥∥δd ∥
∥d ∥
,
(7.132)
which, using the deﬁnition of condition number, can be written
∥δm ∥
∥m ∥≤cond(A) ∥δd ∥
∥d ∥
.
(7.133)
This equation shows that, for a given relative data error ∥δd ∥/ ∥d ∥, the relative solution
error ∥δm ∥/ ∥m ∥may be large if the condition number is large. As it can be shown that
1 ≤cond(A) ≤∞
,
(7.134)
a linear system for which cond(A) ≃1 is called well conditioned; a linear system for which
cond(A) ≫1 is called ill conditioned.
The following properties, which are sometimes useful, can be demonstrated (Ciarlet,
1982):
cond(A) = cond(A−1)
,
cond2(A) =
√max λi(A∗A)
√min λi(A∗A)
,
A∗A = M2 ⇒cond2(A) = max |λi(M)|
min |λi(M)|
.
(7.135)
Coming back to the numerical example, the eigenvalues of A are
λ1 ≃0.010
,
λ2 ≃0.843
,
λ3 ≃3.858
,
λ4 ≃30.289
,
(7.136)
and using, for instance, the third equation in (7.135), gives
cond2(A) = λ4
λ1
≃3 × 103
,
(7.137)
which shows that the system is ill conditioned, and the relative error of the solution may
amount to ≃3 × 103 times the relative data error (as is almost the case in the example).
In fact, the introduction of the concept of condition number is only useful when a
simplistic approach is used for the resolution of linear systems. More generally, the reader
is asked to solve the following problem.
The observable values d = (d1, d2, d3, d4) are known to depend on the model values
m = (m1, m2, m3, m4) through the (exact) equation


d1
d2
d3
d4

=


10
7
8
7
7
5
6
5
8
6
10
9
7
5
9
10




m1
m2
m3
m3


,
(7.138)

282
Chapter 7. Problems
or, for short, d = G m . A measurement of the observable values gives


d1
d2
d3
d4

=


32.0
±
0.1
23.0
±
0.1
33.0
±
0.1
31.0
±
0.1


.
(7.139)
Use the least-squares theory to solve the inverse problem and discuss error and resolution.
Solution:
The best solution (in the least-squares sense) for a linear problem is (equations (3.37)–
(3.38), page 66)
m =

Gt C −1
D G + C −1
M
−1 
Gt C −1
D dobs + C −1
M mprior

,
(7.140)
CM =

Gt C −1
D G + C −1
M
−1
.
(7.141)
If there is no a priori information, CM →∞I , and
m =

Gt C −1
D G

−1 Gt C−1
D dobs
,
(7.142)
CM =

Gt C −1
D G

−1
.
(7.143)
In our numerical example,
dobs =


32.0
23.0
33.0
31.0


,
CD = σ 2 I = 0.01 I
,
G =


10
7
8
7
7
5
6
5
8
6
10
9
7
5
9
10


.
(7.144)
As in this particular example, G is squared and regular, we successively have
m =

Gt C −1
D G

−1Gt C −1
D dobs = G−1 CD (Gt)−1 Gt C −1
D dobs = G−1 dobs
,
(7.145)
i.e.,
m =


1.0
1.0
1.0
1.0


.
(7.146)
The posterior covariance operator is given by
CM =

Gt C −1
D G

−1 = G−1 CD (Gt)−1 = σ 2 G−1 (Gt)−1
,
(7.147)

7.8. Condition Number and A Posteriori Uncertainties
283
and, as G is symmetric,
CM = σ 2 G−1 G−1
,
(7.148)
i.e.,
CM = 0.01


2442
−4043
1015
−602
−4043
6694
−1681
997
1015
−1681
423
−251
−602
997
−251
149


.
(7.149)
From CM it is easy to obtain the standard deviations of model parameters,
σ 1
M = 4.94
,
σ 2
M = 8.18
,
σ 3
M = 2.06
,
σ 4
M = 1.22
,
(7.150)
and the correlation matrix (see Appendix 6.5)
R =


1
−0.99997
+0.99867
−0.99800
−0.99997
1
−0.99898
+0.99830
+0.99867
−0.99898
1
−0.99979
−0.99800
+0.99830
−0.99979
1


.
(7.151)
The overall information on the solution can thus be expressed by this correlation matrix and
the short notation
m =


1.00
±
4.94
1.00
±
8.18
1.00
±
2.06
1.00
±
1.22


.
(7.152)
The interpretation of these results is as follows.
The least-squares approach is only fully justiﬁed if uncertainties (in this example, data
uncertainties) are modeled using Gaussian probability densities. For a linear problem, the
a posteriori uncertainties are then also Gaussian. Taking, for instance, twice the standard
deviation, the probability of the true value of the parameter m1true verifying the inequality
−8.88 ≤m1
true ≤+10.88
(7.153a)
is about 95%, independent of the respective values of m2true , m3true , m4true . Similarly, the
probability of the true values of each of the parameters m2true , m3true , and m4true verifying
the inequalities
−15.36 ≤m2
true ≤+17.36
,
−3.12 ≤m3
true ≤+5.12
,
−1.44 ≤m4
true ≤+3.44
(7.153b)
is also about 95% .

284
Chapter 7. Problems
This gives information on the true value of each parameter, considered independently,
but the correlation matrix gives additional information on error correlation. For instance,
the correlation of m1 with m2 is −0.99997 . This means that if the estimated value for m1
is in error (with respect to the true unknown value), it is almost certain that the estimated
value for m2 will also be in error (because the absolute value of the correlation is close to 1),
and the sign of the error will be opposite to that of the error in m1 (because the correlation
is negative).
The easiest way to understand this is to consider the a posteriori probability density
in the parameter space (equation (3.36)):
σM(m) = const. exp

−1
2 (m −m)t C −1
M (m −m)

.
(7.154)
To simplify the discussion, let us ﬁrst analyze the two parameters m1 and m2 . Their
marginal probability density is
σ12(m1, m2) = (2π det C12)−1/2
exp

−1
2
m1 −1.0
m2 −1.0
t  24.42
−40.43
−40.43
66.94
−1 m1 −1.0
m2 −1.0
 
.
(7.155)
(It is well known [e.g. Dubes, 1968] that marginal probability densities corresponding to a
multidimensional Gaussian are simply obtained by picking the corresponding covariances
in the joint covariance operator.) Figures 7.23 and 7.24 illustrate this probability density.
The correlation between m1 and m2 is so strong in this numerical example that the 95%
conﬁdence ellipsoid is indistinguishable from a segment. This means that, although the data
Figure 7.23. Marginal probability density for the
parameters m1 and m2 . Uncertainties are so strongly cor-
related that it is difﬁcult to distinguish the ellipsoid of un-
certainties from a very thin segment. Although the standard
deviation for each of the parameters is large, we have much
information on these parameters, because their true values
must lie on the line. The next ﬁgure shows a zoom of the
central region.
x = -15
y = -20
y = 20
x = 15
Figure 7.24. Same as the previous ﬁgure, with ﬁner detail.
x = 0
y = 0
y = 2
x = 2

7.9. Conjunction of Two Probability Distributions
285
set used in this example is not able to give an accurate location for the true value of m1 or
m2 independently, it imposes that these true values must lie on the segment of the ﬁgure.
As the volume of the allowed region is almost null, this gives, in fact, a lot of information.
Similarly, the four-dimensional probability density σM(m) deﬁnes a 95% conﬁdence
ellipsoid on the parameter space that corresponds to the extra-long “cigar” joining the point
( −8.88 , +17.36 , −3.12 , +3.44 ) to the point ( +10.88 , −15.36 , +5.12 , −1.44 ). The
reader will easily verify that the two solutions of the linear system obtained using Cramer’s
method for two slightly different data vectors correspond to two points on the cigar.
It should be noticed that if a further experiment gives accurate information on the
true value of one of the parameters, the values of the other three parameters can readily be
deduced, with very small uncertainties. This example has shown the following:
i) A careful analysis of the a posteriori covariance operator must always be made when
solving least-squares inverse problems.
ii) The information given by the condition number is very rough compared with the
information given by the covariance operator (it only gives information about the
ratio between the largest and shortest diameters of the ellipsoid of uncertainties in the
model space).
7.9
Conjunction of Two Probability Distributions
Let x and y be Cartesian coordinates on a cathodic screen. A random device projects
electrons on the screen with a known probability density,
θ(x, y) =

const. r (2 −r)
if 0 ≤r ≤2
,
0
if r > 2
,
(7.156)
where r =
'
x2 + y2 .
We are interested in the coordinates (x, y) at which a particular electron will hit the
screen, and we build an experimental device to measure them. The measuring instrument is
not perfect, and when we perform the experiment we can only get the information that the
true coordinates of the impact point have the (Gaussian) probability density
ρ(x, y) = const. exp

−1
2
x −x0
y −y0
t  σ 2
ρσ 2
ρσ 2
σ 2
−1 x −x0
y −y0
 
,
(7.157)
with (x0, y0) = (0, 0) , σ = 2 , and ρ = 0.99 . Combine this experimental information
with the previous knowledge of the random device, and obtain a better estimate of the impact
point.
Solve the problem again, using polar coordinates instead of Cartesian coordinates.
Solution:
As x and y are Cartesian coordinates, the homogeneous probability density for the
impact point is
µ(x, y) = const.
(7.158)

286
Chapter 7. Problems
The information represented by θ(x, y) and ρ(x, y) is independent in the sense discussed
in section 1.2.6. Combination of these data then corresponds to the conjunction (equa-
tion (1.83), page 32)
σ(x, y) = ρ(x, y) θ(x, y)
µ(x, y)
,
(7.159)
which is plotted in Figure 7.25.
Figure 7.25.
A random device
has been built that projects electrons on a
cathodic screen with the probability den-
sity shown at the top left. Coordinates are
Cartesian.
Independently of this proba-
bility, a measurement of the impact point
of a particular electron gives the informa-
tion represented by the probability density
shown at the top right. The homogeneous
probability density (which is uniform and
has been represented in arbitrary color) is
shown at the bottom left. It is then possible
to combine all these states of information
to obtain the posterior probability density,
shown at the bottom right.
x = -3
x = 3
x = -3
x = 3
y = -3
y = 3
y = -3
y = 3
The polar coordinates verify
r = (x2 + y2)
1/2
,
tan ϕ = y
x
,
(7.160)
so that the Jacobian of the transformation is
J(r, ϕ) =

∂r
∂x
∂r
∂y
∂ϕ
∂x
∂ϕ
∂y

= 1
r
.
(7.161)
Let f (x, y) be a probability density in Cartesian coordinates. To any surface S of the
plane it assigns the probability
P(S) =

S
dx dy f (x, y)
.
(7.162)
Let
˜f (r, ϕ) be a probability density in polar coordinates. If we wish
˜f (r, ϕ) to assign to
S the same probability as f (x, y) ,
P(S) =

S
dr dϕ f (r, ϕ)
,
(7.163)

7.9. Conjunction of Two Probability Distributions
287
then necessarily
˜f (r, ϕ) = f (x(r, ϕ) , y(r, ϕ)) |J(r, ϕ)|
.
(7.164)
This is the usual formula for the change of variables in a probability density. In our case,
˜f (r, ϕ) = r f ( r sin ϕ , r cos ϕ )
.
(7.165)
This gives
˜θ(x, y) =

const. r2 (1 −r)
if 0 ≤r ≤2
,
0
if r > 2
,
(7.166)
˜ρ(r, ϕ) = const. r exp
(
−r2(1 −2 ρ sin ϕ cos ϕ)
2 σ 2(1 −ρ2)
)
,
(7.167)
and
˜µ(r, ϕ) = const. r
.
(7.168)
The combination of θ(r, ϕ) with ˜ρ(r, ϕ) is given by the conjunction (equation (1.83),
page 32)
˜σ(r, ϕ) =
˜ρ(r, ϕ) ˜θ(r, ϕ)
˜µ(r, ϕ)
(7.169)
and is shown in Figure 7.26.
Figure 7.26.
It is also possible
to solve the problem using polar coordi-
nates throughout. The top left represents
the probability density of an impact on the
screen, as imposed by the experimental de-
vice.
The probability density is constant
for given r . The top right shows the re-
sult of the measurement. At the bottom left,
the homogeneous probability density in po-
lar coordinates is shown. It assigns equal
probability to equal surfaces of the screen.
The combination of these states of informa-
tion gives the posterior probability density
shown at the bottom right. This probability
is completely equivalent to the probability
density at the bottom right of the previous
ﬁgure, as they can be deduced from one an-
other through the usual formula of change
of variables between Cartesian and polar
coordinates ˜σ(θ, ϕ) = r σ(x, y) .
r = 0
r = 3
r = 0
r = 3
φ = 0
φ = 2π
φ = 0
φ = 2π

288
Chapter 7. Problems
It should be noticed that the probability density representing the homogeneous proba-
bility is not constant in polar coordinates: the probability density in equation (7.168) assigns
equal probabilities to equal volumes, as it must.
The solution obtained for this problem using Cartesian coordinates (Figure 7.25) and
the solution obtained using polar coordinates (Figure 7.26) are coherent: Figure 7.25 can
be deduced from Figure 7.26 using the Jacobian rule in equation (7.164), and vice versa.
Using more elementary approaches, this problem may present some pathologies. In
particular, the result cannot be expressed using a single estimator of the impact point because
the probability density is bimodal. The mean value and median value are meaningless, and
only the two maximum likelihood points make clear sense.
7.10
Adjoint of a Covariance Operator
Let S be a linear space and CS be the (symmetric) covariance operator deﬁning a scalar
product over S :
( s1 , s2 )S = st
1 C−1
S s2
.
(7.170)
Demonstrate that the adjoint of CS equals its inverse:
C∗
S = C−1
S .
(7.171)
Solution:
In section 3.1.4 (page 61), we saw that if A is a linear operator mapping a linear space
E , with scalar product
( e1 , e2 )E = et
1 C−1
E e2
,
(7.172)
into a linear space F , with scalar product
( f1 , f2 )F = ft
1 C−1
F f2
,
(7.173)
the adjoint of A is (equation (3.24))
A∗= CE At C−1
F
,
(7.174)
where At is the transpose of A .
We have also seen that a covariance operator CS over a linear space S is a linear
operator mapping S∗(dual of S ) into S . To evaluate the adjoint of a covariance operator,
we must then identify, in the formulas above, the space E with S∗and the space F with S .
Equation (7.174) then gives C∗
S = CS∗Ct
S C−1
S . As a covariance operator is symmetric,
Ct
S = CS
,
(7.175)
this gives C∗
S = CS∗CS C−1
S , i.e., C∗
S = CS∗: the adjoint of a covariance operator over a
space S is the operator deﬁning the scalar product over the dual space S∗. And we know
that this is the inverse of the original operator (see section 3.1.3): CS∗= C−1
S . Therefore,
C∗
S = C−1
S
.
(7.176)
Lesson: Covariance operators are symmetric, but they are not self-adjoint!

7.11. Problem 7.1 Revisited
289
7.11
Problem 7.1 Revisited
Solve Problem 7.1 (estimation of the epicentral coordinates of a seismic event) using the
Newton method, the steepest descent method, the conjugate directions method, and the
variable metric method. Consider different kinds of a priori information. Examine the
evolution of posterior uncertainties when eliminating some data.
Use only one datum
(arrival time) and the a priori information that the x coordinate of the epicenter is 15 km ±
5 km .
Note: As the forward problem is solved by the equation
di = gi(X, Y) = 1
v
'
(X −xi)2 + (Y −yi)2 ,
(7.177)
if we order arrival times in a column matrix, the matrix of partial derivatives is
Gn =



∂g1
∂X

n

∂g1
∂Y

n

∂g2
∂X

n

∂g2
∂Y

n
...
...


,
(7.178)
where
∂gi
∂X

n
=
Xn −xi
v
'
(Xn −xi)2 + (Yn −yi)2
(7.179)
and
∂gi
∂Y

n
=
Yn −xi
v
'
(Xn −xi)2 + (Yn −yi)2
.
(7.180)
7.12
Problem 7.3 Revisited
Solve Problem 7.3 (elementary approach to tomography) using the Newton method, the
steepest descent method, the conjugate directions method, and the variable metric method.
Consider different kinds of a priori information. Examine the evolution of posterior uncer-
tainties when adding much more data. Solve a problem with NX×NY blocks, where NX
and NY are the number of pixels of the color output of your computer (there is no problem
in having many more unknowns than data, if the a priori covariance matrix imposes that
the least-squares solution must be smooth).
Once you master the resolution of this problem using a discrete formulation, have
a look a chapter 5 (Functional Inverse Problems), or read the article by Tarantola and
Nercessian (1984).

290
Chapter 7. Problems
7.13
An Example of Partial Derivatives
Let us consider the problem of locating a point in space using a system like the global
positioning system (GPS), where some sources (satellites) send waves to a receiver, which
measures the travel times. Let us use Cartesian coordinates, denoting by (xi, yi, zi) the
position of the ith source and by (xR, yR, zR) the position of the receiver. Simplify the
problem here by assuming that the medium where the waves propagate is homogeneous, so
the velocity of the waves is constant (say v ) and the rays are straight lines. Then, the travel
time from the ith source to the receiver is
ti = gi(xR, yR, zR, v) =
'
(xR −xi)2 + (yR −yi)2 + (zR −zi)2
v
.
(7.181)
The dependence of ti on the variables describing the source positions (xi, yi, zi) is not
explicitly considered, as the typical GPS problem consists of assuming the position of the
sources exactly known and of estimating the receiver position (xR, yR, zR) . At no extra
cost, we can also try to estimate the velocity of the propagation of waves v . The partial
derivatives of the problem are then


∂g1
∂xR
∂g1
∂yR
∂g1
∂zR
∂g1
∂v
∂g2
∂xR
∂g2
∂yR
∂g2
∂zR
∂g2
∂v
...
...
...
...
∂gi
∂xR
∂gi
∂yR
∂gi
∂zR
∂gi
∂v
...
...
...
...


=


xR−x1
v D1
yR−y1
v D1
zR−z1
v D1
−Di
v2
xR−x2
v D2
yR−y2
v D2
zR−z2
v D2
−Di
v2
...
...
...
...
xR−xi
v Di
yR−yi
v Di
zR−zi
v Di
−Di
v2
...
...
...
...


,
(7.182)
where Di is a short notation for the distance:
Di =
'
(xR −xi)2 + (yR −yi)2 + (zR −zi)2 .
(7.183)
In order to keep notation simple, it has not been explicitly indicated that these partial
derivatives are functions of the variables of the problem, i.e., functions of (xR, yR, zR, v)
(remember that the locations of the satellites, (xi, yi, zi), are assumed exactly known,
so they are not ‘variables’). Assigning particular values to the variables (xR, yR, zR, v)
gives particular values for the travel times ti (through equation (7.181)) and for the partial
derivatives (through equation (7.182)).
7.14
Shapes of the ℓp-Norm Misﬁt Functions
Consider a schematic problem with two model parameters m1 and m2 and a single datum
d1 . The datum is theoretically related to the model parameters through the linear equation
d1 = g1(m1, m2) = m1 −m2
.
(7.184)
Its observed value is
d1
obs = 0 ± 1
.
(7.185)

7.14. Shapes of the ℓp-Norm Misﬁt Functions
291
The a priori values of the model parameters are
m1
prior = 3 ± 1
and
m2
prior = 1 ± 2
.
(7.186)
Represent the misﬁt function S(m1, m2) in the following three cases:
i) The symbols ± in (7.185)–(7.186) represent ℓ1-norm uncertainty bars.
ii) The symbols ± in (7.185)–(7.186) represent ℓ2-norm uncertainty bars.
iii) The symbols ± in (7.185)–(7.186) represent ℓ∞-norm uncertainty bars.
Solution for the ℓ1-norm:
Using an ℓp-norm, the misﬁt function is (equation (1.108))
S(m) = 1
p
 
i
| gi(m) −di
obs |p
(σ i
D)p
+

α
| mα −mα
prior |p
(σ α
M)p

.
(7.187)
In particular, for p = 1 , one has a sum of absolute values (equation (1.109)),
S(m) =

i
| gi(m) −di
obs |
σ i
D
+

α
| mα −mα
prior |
σ α
M
.
(7.188)
For a reason that will become apparent in the case p →∞, instead of S(m) , let us
introduce the function
R(m) = (p S(m))1/p =
 
i
| gi(m) −di
obs |p
(σ i
D)p
+

α
| mα −mα
prior |p
(σ α
M)p
1/p
.
(7.189)
Of course, for p = 1 , R(m) = S(m) .
In our present example, we have
R(m1, m2) = |m1 −m2| + |m1 −3| + |m2 −1|
2
.
(7.190)
This function is represented at the left of Figure 7.27. The level lines are polygons. In a 3D
space with axes (m1, m2, R) , the function R(m1, m2) is clearly a convex polyhedron.
The minimum of R is attained at (m1, m2) = (3, 3) . Some ℓ1-norm circles of radius
1/8 have been drawn.
Solution for the ℓ2,-norm:
We have
R(m1, m2) =

(m1 −m2)2 + (m1 −3)2 + (m2 −1)2
4
1/2
.
(7.191)

292
Chapter 7. Problems
Figure 7.27. Representation of the function R(m) deﬁned by equation (7.189).
The constants σMα allow the introduction of a natural deﬁnition of distance over the model
space, based on the norm ∥m ∥p = 
α |mα −mα
prior|p / (σ α
M)p . For p = 1 , the function
R is that expressed in equation (7.190), and ∥m ∥= 
α |mα −mα
prior| / σ α
M . The ﬁgure at
the left shows the function R(m1, m2) deﬁned by the data given in the text. The level lines
are polygons. In a 3D space with axes (m1, m2, R) , the function R(m1, m2) is a convex
polyhedron. Some ℓ1 circles of radius 1/8 are shown, together with the direction of steepest
descent. Middle: Same but for p = 2 , with the function R expressed by equation (7.191).
The circles here correspond to the ℓ2-norm ∥m ∥=

α(mα −mα
prior)2 / σ 2
M . Right:
Same as above, but for p = ∞. This gives the function R expressed in equation (7.193).
Some circles for the distance ∥m ∥= max

|mα −mα
prior| / σ α
M (all α )

are shown. In
this last situation, the direction of steepest descent is not uniquely deﬁned everywhere.
This function is represented in the middle of Figure 7.27.
Its minimum is attained at
(m1, m2) = (8/3, 7/3) .
Solution for the ℓ∞-norm:
For p →∞, we have (see main text)
R(m) = max
  |gi(m) −di
obs|
σ i
D
(all i)

,
 |mα −mα
prior|
σ α
M
(all α)
 
. (7.192)
In our present example, this gives
R(m1, m2) = max

|m1 −m2| , |m1 −3| , |m2 −1|
2

.
(7.193)
This function is represented at the right of Figure 7.27. As for the ℓ1 case, the level lines of
R(m1, m2) are polygons, and in a 3D space with axes (m1, m2, R) , the function R(m1, m2)
is a convex polyhedron.
The minimum of R is attained at (m1, m2) = (5/2, 2) . Some ℓ∞-norm circles of
radius 1/8 have been drawn. The associated directions of steepest descent are not uniquely
deﬁned in all the polyhedron faces.

7.15. Using the Simplex Method
293
7.15
Using the Simplex Method
Use the simplex method of Appendix 6.23.1 to obtain the minimum of the function
ϕ(x1, x2, x3) = 2 x1 + x2 + 2x3
(7.194a)
under the constraints
x1 + x2 + x3 = 5
,
x1 + 2 x2 = 3
,
(7.194b)
and
x1 > 0
,
x2 > 0
,
x3 > 0
.
(7.194c)
Solution:
In the following, the notation of Appendix 6.23.1 is used. In compact notation, the
problem is to minimize
ϕ(x) = ˆχt x
(7.195)
under the constraints
M x = y
,
x ≥0
,
(7.196)
where
x =


x1
x2
x3


,
ˆχ =


2
1
2


,
M =
1
1
1
1
2
0

,
y =
5
3

.
(7.197)
In this problem, a basis contains two parameters. We have three different possibilities for
choosing the basic parameters:
First possible choice:
xB =
x1
x2

xN = [x3]
;
Second possible choice:
xB =
x2
x3

xN = [x1]
;
Third possible choice:
xB =
x1
x3

xN = [x2]
.
(7.198)
As discussed in Appendix 6.23.1, we will try to take the nonbasic parameters as null.
Let us arbitrarily take the ﬁrst of the three possible choices. This gives
MB =
1
1
1
2

,
MN =
1
0

.
(7.199)
We must ﬁrst check that in taking the nonbasic parameters as null, the positivity constraints
for the basic parameters are satisﬁed. From equation (6.372) of Appendix 6.23.1,
xB = M−1
B y =
 7
−2

.
(7.200)
As the positivity constraints are not satisﬁed, this choice is not acceptable.

294
Chapter 7. Problems
Turning to the second possible choice, we have
MB =
1
1
2
0

,
MN =
1
1

,
(7.201)
which gives
xB = M−1
B y =
3/2
7/2

.
(7.202)
As the positivity constraints are satisﬁed, we can now check if this possible solution is the
optimum solution. We have
cB =
1
2

,
cN = [2]
,
(7.203)
and, using equation (6.375) of Appendix 6.23.1,
γ N = cN −Mt
N M−t
B cB = [1/2]
.
(7.204)
As all the components of γ N (we only have one) are positive, the function ϕ is effectively
minimized taking xN = 0 , and (7.202) is the solution of the problem.
The problem is now completely solved, but let us see what happens when we use the
third of the possible choices. This gives
MB =
1
1
1
0

,
MN =
1
2

,
(7.205)
and
xB = M−1
B y =
3
2

,
(7.206)
which is acceptable. We have
cB =
2
2

,
cN = [1]
,
(7.207)
and, using equation (6.375) of Appendix 6.23.1,
γ N = cN −Mt
N M−t
B cB = [−1]
.
(7.208)
As all the components of γ N are not positive, equation (7.206) is not the solution of the
problem. The parameter associated with the most negative component of γ N must leave
the basis (as we only have the parameter x2 in xN , this is the parameter). Equation (7.197)
of Appendix 6.23.1 gives
xB = M−1
B ( y −MN xN) =
3 −2x2
2 + x2

.
(7.209)
As the ﬁrst component of xB , x1 , ﬁrst becomes negative when increasing x2 , it is the
parameter x1 that must replace x2 in the basis. This leads directly to the second choice,
which has already been explored (and which gives the solution).

7.16. Problem 7.7 Revisited
295
7.16
Problem 7.7 Revisited
Two variables y and t are related through a linear relationship
y = a t + b
.
(7.210)
In order to estimate the parameters a and b , the 11 experimental points (yi, ti) , (10, 1) ,
(11, 3) , (11, 5) , (12, 7) , (13, 10) , (14, 12) , (14, 13) , (15, 15) , (15, 16) , (16, 18) ,
(2, 31) , shown in Figure 7.28, have been obtained. Find the straight line that best ﬁts the
points in the ℓ1-norm sense.
Solution:
We wish to minimize
S(a, b) =
i=11

i=1
|yi
cal −yi
obs|
σ i
,
(7.211)
where
yi
cal = a ti + b
(7.212)
and σ i = σ = 2 .
Figure 7.29 shows the projection on the plane (a, b) of the convex polyhedron repre-
senting S(a, b) . Figure 7.30 zooms in on the region of interest. The level lines S(a, b) =
12.5 and S(a, b) = 25 are shown in Figure 7.29 and the level line S(a, b) = 12.5 is
shown in Figure 7.30.
Figure 7.28. We wish to ﬁnd the straight line
ﬁtting these 11 points (same as Figure 7.14). Notice
the outlier.
Figure 7.29. Projection on the parameter
space (a, b) of the convex polyhedron representing
the misﬁt function S(a, b) . The level lines S = 12.5
and S = 25 are shown.
10
20
-1
0
1
30
0
Figure 7.30. Zoom of Figure 7.29. The so-
lution path is shown (see text).
0.2
0.3
0.4
11
10
9
12

296
Chapter 7. Problems
Each of the straight lines corresponds to an experimental point. For instance, the most
horizontal line corresponds to the (probable outlier) point (2, 31). The minimum of S is
necessarily attained at a vertex of the polyhedron, i.e., at a knot in the mesh in Figures 7.29
and 7.30. At least two experimental points are exactly ﬁtted at each knot.
To solve the problem using linear programming techniques, we ﬁrst choose one knot,
i.e., two of the equations
yi
obs = a ti + b
,
(7.213)
for instance, the ﬁrst two. This gives the point (0.5, 9.5) . To leave the knot, we have to drop
one of the basis equations. The FIFO method drops the oldest equation. At the ﬁrst round,
equations have arbitrary ages. Take, for instance, ages decreasing from the ﬁrst to the last
equation. Dropping the ﬁrst equation gives the line shown in Figure 7.30. The minimum
along the line is attained at the point (0.308, 10.08) , where the ninth equation enters the
basis. Dropping the oldest equation (the second), we get a minimum at the point (0.333,
9.67) , where the ﬁrst, fourth, and seventh equations are exactly satisﬁed and they can all
enter the basis. Whatever the choice we make, it leaves the basis again, because we cannot
make S diminish: we are at the minimum.
7.17
Geodetic Adjustment with Outliers
Figure 7.31 shows ﬁve points on a Euclidean plane. Ten different distances between these
points have been measured experimentally. The results are as follows.
Observed distance
Estimated uncertainty
True (unknown) error
D0 =
9 486.843 0 m
±2 cm
+1 cm
D1 =
15 000.010 0 m
±2 cm
+1 cm
D2 =
12 727.902 1 m
±2 cm
−2 cm
D3 =
6 708.203 9 m
±2 cm
0 cm
D4 =
6 708.193 9 m
±2 cm
−1 cm
D5 =
11 998.000 0 m
±2 cm
−200 cm
D6 =
6 708.193 9 m
±2 cm
−1 cm
D7 =
10 816.653 8 m
±2 cm
0 cm
D8 =
9 486.853 0 m
±2 cm
+2 cm
D9 =
6 708.223 9 m
±2 cm
+2 cm
Observe that estimated uncertainties are uniform, σ i = 2 cm , and that distance D5
is an outlier.
To deﬁne the geometric ﬁgure perfectly, only 7 distances are needed, but, as is usual
in geodetic measurements, some redundant measurements have been made in order to min-
imize posterior true uncertainties. Due to the observational uncertainties, the 10 distances
obtained are not compatible with the geometric constraints. Obtain the new set of distances
Di , compatible with these geometric constraints, minimizing the ℓ1-norm
S1 =
i=9

i=0
|Di −Di
obs|
σ i
.
(7.214)

7.18. Inversion of Acoustic Waveforms
297
Figure 7.31. Between 5 points of a Eu-
clidean plane, the 10 distances shown in the ﬁgure
have been measured. One is an outlier (see text).
Estimate the true distances between the points.
1 km2
D4
D0
D6
D1
D5
D7
D9
D8
D3
D2
Compare with the solution of the minimization of the ℓ2-norm
S2 =
i=9

i=0
(Di −Di
obs)2
(σ i)2
.
(7.215)
Solution:
As the expected corrections are small, the problem can be linearized. The ℓ1-norm
minimization problem can be solved using the linear programming methods, and the ℓ2-
norm minimization problem can be solved using Newton’s method. The following table
compares the true errors with the corrections predicted by the two methods.
True errors
ℓ1-norm correction
ℓ2-norm correction
+1.00 cm
0.00 cm
+14.22 cm
+1.00 cm
−0.89 cm
−19.21 cm
−2.00 cm
0.00 cm
+4.64 cm
0.00 cm
0.00 cm
+2.72 cm
−1.00 cm
0.00 cm
+39.79 cm
−200.00 cm
−195.70 cm
−66.49 cm
−1.00 cm
0.00 cm
+49.41 cm
0.00 cm
0.00 cm
+35.94 cm
+2.00 cm
0.00 cm
−38.28 cm
+2.00 cm
+4.31 cm
+37.24 cm
Notice that the ℓ1-norm solution exactly satisﬁes seven distances (the number of
independent data). As expected, the ℓ1-norm criterion allows an easy identiﬁcation of the
outlier, while the ℓ2-norm criterion smears the error across the whole geodetic network.
7.18
Inversion of Acoustic Waveforms
An acoustic medium can be described using the mass density ρ(x) and the bulk modulus
κ(x) . For simplicity, assume that the mass density is known. The problem is then to evaluate
κ(x) . At some shot points xs (s = 1, 2, . . . , NS) , we generate acoustic waves, which are

298
Chapter 7. Problems
recorded at some receiver positions xr (r = 1, 2, . . . , NR) . Let t be a time variable
reset to zero at each new run. The pressure perturbation at the receiver location xr , at
time t , for a source located at point xs , is denoted p(xr, t; xr) . Let p(xr, t; xr)obs denote
the particular measured (observed) values. For a particular model κ(x) , p(xr, t; xr)cal
denotes the predicted values. Formulate the inverse problem of evaluating the bulk modulus
κ(x) from the measurements p(xr, t; xr) .
Solution:
We assume the source of the acoustic waves to be exactly known (if not, it must be
part of the inverse problem). In order for the Gaussian statistics to be acceptable, instead of
the bulk modulus κ(x) we shall use the logarithmic bulk modulus
m(x) = log K
κ(x) = −log κ(x)
K
,
(7.216)
where K is an arbitrary constant value of κ . For compactness, a logarithmic bulk modulus
model is denoted m and a data set is denoted p . The computation of the waveforms
corresponding to the model m is written
p = g(m)
,
(7.217)
where the operator g linking the model of logarithmic bulk modulus to the pressure pertur-
bations is, of course, nonlinear.
Let pobs represent the observed data set and Cp be the covariance operator describing
experimental uncertainties. In what follows, the kernel of the covariance operator is assumed
to be diagonal,
Cp(xr, t; xs; xr′, t′; xs′) = σ 2(xr, t; xs) δrr′ δ(t −t′) δss′
,
(7.218)
so that the expression
δp = Cp δ ˆp
(7.219)
is written, explicitly,
δp(xr, t; xs) =

s′
 T
0
dt′ 
r′
Cp(xr, t; xs; xr′, t′; xs′) δ ˆp(xr′, t′; xs′)
= σ 2(xr, t; xs) δ ˆp(xr, t; xs)
.
(7.220)
Then, the reciprocal relation
δ ˆp = C−1
p δp
(7.221)
simply gives
δ ˆp(xr, t; xs) = δp(xr, t; xs)
σ 2(xr, t; xs)
.
(7.222)

7.18. Inversion of Acoustic Waveforms
299
The best model (in the least-squares sense) is deﬁned by the minimization of the squared
norm
S(m) =
1
2 ∥g(m) −dobs ∥2
,
(7.223)
where, if we use the notation
⟨δ ˆp1 , δp2 ⟩= δ ˆp1
t δp2 =

s
 T
0
dt

r
δ ˆp(xr, t; xs)1 δp(xr, t; xs)2
,
(7.224)
the norm ∥δp ∥is deﬁned by
∥δp ∥2 = ⟨C−1
p δp , δp ⟩= δpt C−1
p δp
.
(7.225)
One then usually writes
S(m) = (g(m) −dobs)t C−1
p (g(m) −dobs)
.
(7.226)
To simplify the exposition here, I do not explicitly introduce the a priori information in the
model space: gradient methods are naturally robust (if the minimum of (7.226) is a subspace
rather than a single point, they converge to the point that is the closest to the starting point),
and, in any case, many examples of the introduction of the a priori information are given in
other parts of this book.
The Fréchet derivative of the nonlinear operator g at a point mn of the model space is
the linear operator Gn that associates any model perturbation δm with the data perturbation
Gn δm deﬁned by the ﬁrst-order development
g(mn + δm) = g(mn) + Gn δm + higher order terms
.
(7.227)
Introducing notation equivalent to that given by (7.224) in the model space,
⟨δ ˆm1 , δm2 ⟩= δ ˆm1
t δm2 = δm2
t δ ˆm1 =

V
dV (x) δ ˆm(x)1 δm(x)2
,
(7.228)
and given a linear operator Gn , the transpose operator Gt
n is deﬁned by the identity (see
main text)
⟨δ ˆp , Gn δm ⟩= ⟨Gt
n δ ˆp , δm ⟩
for any δ ˆp and δm
.
(7.229)
The least-squares minimization problem can then be solved using, for instance, a precondi-
tioned steepest descent algorithm (see chapter 3). This gives
mn+1 = mn −µn ˆS0 Gt
n C−1
p (g(mn) −dobs)
,
(7.230)
where ˆS0 is an arbitrary positive deﬁnite operator called the preconditioning operator, which
is suitably chosen to accelerate the convergence (see below).
Let us now turn to the computation of the Fréchet derivatives corresponding to this
problem. The solution of the forward problem is deﬁned by the differential system (using

300
Chapter 7. Problems
the logarithmic bulk modulus deﬁned in equation (7.216))
exp( m(x) )
K
∂2p
∂t2 (x, t; xs) −div

1
ρ(x)grad p(x, t; xs)

= S(x, t·xs)
,
p(x, t; xs) = 0
( for x ∈S)
,
p(x, 0; xs) = 0
,
˙p(x, 0; xs) = 0
.
(7.231)
Here S(x, t; xs) is the function describing the source and S denotes the surface of the
medium. Practically, this differential system can, for instance, be solved using a ﬁnite-
difference algorithm (see, for instance, Alterman and Karal, 1968).
The Green’s function I(x, t; xs, t′) is deﬁned by
exp( m(x) )
K
∂2I
∂t2 (x, t; x′, t′) −div

1
ρ(x) grad I(x, t; x′, t′)

= δ(x −xs) δ(t −t′)
,
I(x, t; x′, t′) = 0
(for x ∈S)
,
I(x, t; x′, t′) = 0
(for t < t′)
,
˙I(x, t; x′, t′) = 0
(for t < t′)
,
(7.232)
and we have the integral representation (see, for instance, Morse and Feshbach, 1953)
p(x, t; xs) =

V
dV (x′) I(x, t; x′, 0) ∗S(x′, t; xs)
.
(7.233)
In order to obtain the Fréchet derivative of the displacements with respect to the
bulk modulus (as deﬁned by equation (7.227)), let us introduce the waveﬁeld pn(x, t; xs) ,
propagating in the medium mn(x) ,
exp( m(x)n )
K
∂2pn(x, t; xs)
∂t2
−div

1
ρ(x) grad pn(x, t; xs)

= S(x, t; xs)
,
pn(x, t; xs) = 0
(for x ∈S)
,
pn(x, 0; xs) = 0
,
˙pn(x, 0; xs) = 0
,
(7.234)
and the corresponding Green’s function
exp( m(x)n )
K
∂2In(x, t; x′, t′)
∂t2
−div

1
ρ(x) grad In(x, t; x′, t′)

= δ(x −xs) δ(t −t′)
,
In(x, t; x′, t′) = 0
(for x ∈S)
,
In(x, t; x′, t′) = 0
(for t < t′)
,
˙In(x, t; x′, t′) = 0
(for t < t′)
.
(7.235)

7.18. Inversion of Acoustic Waveforms
301
A perturbation of the logarithmic bulk modulus mn(x) →mn(x) + δm(x) will produce a
ﬁeld pn(x, t; xs) + δp(x, t; xs) deﬁned by
exp( mn(x) + δm(x) )
K
∂2(pn(x, t; xs) + δp(x, t; xs))
∂t2
−div

1
ρ(x) grad (pn(x, t; xs) + δp(x, t; xs))

= S(x, t; xs)
,
pn(x, t; xs) + δp(x, t; xs) = 0
(for x ∈S)
,
pn(x, 0; xs) + δp(x, 0; xs) = 0
,
˙pn(x, 0; xs) + δ ˙p(x, 0; xs) = 0
.
(7.236)
This gives, after simpliﬁcation,
exp( mn(x) )
K
∂2δp(x, t; xs)
∂t2
−div

1
ρ(x) grad δp(x, t; xs)

= −∂2pn(x, t; xs)
∂t2
exp( mn(x) )
K
δm(x) + O(∥δm ∥2)
,
δp(x, t; xs) = 0
(for x ∈S)
,
δp(x, 0; xs) = 0
,
δ ˙p(x, 0; xs) = 0
,
(7.237)
and, using theorem (7.233),
δp(xr, t; xs) = −

V
dV (x) In(xr, t; x, 0) ∗∂2pn
∂t2 (x, t; xs)exp( mn(x) )
K
δm(x)
+ O(∥δm ∥2)
.
(7.238)
The Fréchet derivative operator Gn introduced in (7.227) is then characterized by
(Gn δm)(xr, t; xs) = −

V
dV (x) In(xr, t; x, 0) ∗∂2pn
∂t2 (x, t; xs) exp( mn(x) )
K
δm(x) ,
(7.239)
where In(x, t; x′, t′) is the Green’s function corresponding to the medium mn(x) (deﬁned
by equation (7.235)) and pn(x, t; xs) is the waveﬁeld also corresponding to mn(x) (deﬁned
by equation (7.234)).
We now turn to the characterization of the transpose operator. We have just deﬁned
the Fréchet derivative operator Gn . Its transpose Gt
n was deﬁned by equation (7.229):
⟨δ ˆp , Gn δm ⟩= ⟨Gt
n δ ˆp , δm ⟩
for any δ ˆp and δm
.
(7.240)
To solve the inverse problem, we need to be able to compute Gt
n δ ˆp for arbitrary δ ˆp . Using
the notation introduced in (7.224) and (7.228), equation (7.229) is written

s
 T
0
dt

r
δ ˆp(xr, t; xs)(Gn δm)(xr, t; xs) =

V
dV (x) (Gt
n δ ˆp)(x) δm(x)
,
(7.241)

302
Chapter 7. Problems
and, using (7.239),

s
 T
0
dt

r
δ ˆp(xr, t; xs)

V
dV (x) In(xr, t; x, 0) ∗∂2pn(x, t; xs)
∂t2
exp( mn(x) )
K
δm(x)
= −

V
dV (x) (Gt
n δ ˆp)(x) δm(x)
,
(7.242)
i.e.,

V
dV (x) δm(x)
.
(Gn
t δ ˆp)(x) + exp( mn(x) )
K

s
 T
0
dt

r
In(xr, t; x, 0)
∗∂2pn
∂t2 (x, t; xs) δ ˆp(xr, t; xs)
/
= 0
.
(7.243)
As this has to be valid for any δm(x) , we obtain
(Gt
n δ ˆp)(x) = −exp( mn(x) )
K

s
 T
0
dt

r
In(xr, t; x, 0) ∗∂2pn
∂t2 (x, t; xs) δ ˆp(xr, t; xs)
.
(7.244)
Let us introduce a ﬁeld 8n(x, t; xs) deﬁned by the differential system
exp( mn(x) )
K
∂28n(x, t; xs)
∂t2
−div

1
ρ(x) grad 8n(x, t; xs)

= Z(x, t; xs)
,
8n(x, t; xs) = 0
( for x ∈S)
,
8n(x, T ; xs) = 0
,
˙8n(x, T ; xs) = 0
,
(7.245)
where
Z(x, t; xs) =

r
δ(x −xr) δ ˆp(xr, t; xs)
.
(7.246)
Notice that the ﬁeld 8 satisﬁes ﬁnal (instead of initial) conditions. Using the property
In(x, t; xr, t′) = In(x, t + τ, xr, t′ + τ)
(7.247)
and reversing time in theorem (7.233), one obtains
8n(x, t; xs) =

r
 T
0
dt′ In(x, 0; xr, t −t′) δ ˆp(xr, t′; xs)
.
(7.248)
One has
˙8(x, t; xs) =

r
 T
0
dt′ ∂
∂t I(x, 0; xr, t −t′) δ ˆp(xr, t′; xs)
=

r
 T
0
dt′ ∂
∂t I(x, t′ −t; xr, 0) δ ˆp(xr, t′; xs)
= −

r
 T
0
dt′ ˙I(x, t′ −t; xr, 0) δ ˆp(xr, t′; xs)
,
(7.249)

7.18. Inversion of Acoustic Waveforms
303
where
˙I(x, t; x′, t′) =
∂
∂t I(x, t; x′, t′)
.
(7.250)
Using integration by parts gives
I(xr, t; x, 0) ∗∂2p
∂t2 (x, t; xs) =
 T
0
dt′ I(xr, t −t′; x, 0) ∂2p
∂t2 (x, t′; xs)
= I(xr, t −T ; x, 0) ˙p(x, T ; xs) −I(xr, t; x, 0) ˙p(x, 0; xs)
−
 T
0
dt′ ˙I(xr, t −t′; x, 0) ˙p(x, t′; xs)
,
(7.251)
and, using the last two initial conditions in equations (7.235),
I(xr, t; x, 0) ∗∂2p
∂t2 (x, t; xs) = −˙I(xr, t; x, 0) ∗˙p(x, t; xs)
.
(7.252)
Using the last equation gives

s
 T
0
dt

r
I(xr, t; x, 0) ∗∂2p
∂t2 (x, t; xs) δ ˆp(xr, t; xs)
= −

s
 T
0
dt

r
˙I(xr, t; x, 0) ∗˙p(x, t; xs) δ ˆp(xr, t; xs)
= −

s
 T
0
dt
 T
0
dt′ 
r
˙I(xr, t −t′; x, 0) ˙p(x, t′; xs) δ ˆp(xr, t; xs)
,
(7.253)
whence, using (7.249), we obtain

s
 T
0
dt

r
I(xr, t; x, 0) ∗∂2p
∂t2 (x, t; xs) δ ˆp(xr, t; xs)
=

s
 T
0
dt ˙p(x, t; xs) ˙8(x, t; xs)
.
(7.254)
From equation (7.244), we then ﬁnally obtain the result characterizing the transpose
operator:
(Gt
n δ ˆp)(x) = −exp( mn(x) )
K

s
 T
0
dt ˙pn(x, t; xs) ˙8n(x, t; xs)
.
(7.255)
The preconditioned steepest descent algorithm (7.230) is written, step by step,
δpn = g(mn) −dobs
,
δ ˆpn = C−1
p δpn
,
ˆγ n = Gt
n δ ˆpn
,
dn = ˆS0 ˆγn
,
(7.256)
and
mn+1 = mn −µn dn
.
(7.257)

304
Chapter 7. Problems
To compute the residuals (7.256) we need to compute g(mn) , i.e., we need to solve
the forward problem (using any numerical method). The weighted residuals δ ˆpn are easily
obtained using (7.222).
ˆγ n is computed using (7.255), where the ﬁeld 8(x, t; xs)n is
obtained by solving the system (7.245) (using, for instance, the same method used to solve
the forward problem). To obtain dn , we have to apply the preconditioning operator ˆS0
to ˆγ n . It may simply consist of some ad hoc geometrical correction (see, for instance,
Gauthier, Virieux, and Tarantola, 1986). To end one iteration, we have to estimate µn in
(7.257). A linearized estimation of µn can be obtained as follows.
For given mn , we have
S(mn −µndn) = 1
2

(g(mn −µn dn) −pobs)t C−1
p (g(mn −µn dn) −pobs)

.
(7.258)
If µn is small enough, using the deﬁnition of Fréchet derivatives, we have
g(mn −µn dn) ≃g(mn) −µn Gn dn
,
(7.259)
which gives
S(mn −µn dn) ≃S(mn) −µn(Gn dn)t C−1
p (g(mn) −pobs)
+ 1
2 µn
2(Gn dn)t C−1
p (Gn dn)
.
(7.260)
The condition ∂S/∂µn = 0 gives
µn ≃
(Gn dn)t C−1
p (g(mn) −pobs)
(Gn dn)t C−1
p (Gn dn)
,
(7.261)
and, using the deﬁnition of the transpose operator (equation (7.229)), we ﬁnally obtain
µn ≃
dnt Gt
n C−1
p (g(mn) −pobs)
(Gn dn)t C−1
p (Gn dn)
=
dnt ˆγ n
(Gn dn)t C−1
p (Gn dn)
.
(7.262)
To compute Gn dn , we could use the result (7.239), but it is more practical to use directly
the deﬁnition of derivative operator and a ﬁnite-difference approximation. We may then use
Gn dn ≃1
ϵ

g(mn + ϵdn) −g(mn)

(7.263)
with a sufﬁciently small value of ϵ .
The physical interpretation of the obtained results is as in section 5.8.7.
7.19
Using the Backus and Gilbert Method
Figure 7.32 represents a borehole in which we are able to introduce a sensor. For three
different depths z1, z2, z3 , we have measured the travel times t1, t2, t3 of acoustic waves

7.19. Using the Backus and Gilbert Method
305
Figure 7.32. Acoustic waves traveling
down in the Earth are use to infer the velocity-
versus-depth dependence (using the Backus and
Gilbert method).
receiver
z
n(z)
from the top of the borehole to the sensor. We obtain the following results:
z1 = 2.3 m
,
t1 = 2.0 ms
,
z2 = 8.1 m
,
t2 = 8.1 ms
,
z3 = 10.1 m
,
t3 = 10.2 ms
(7.264)
(ms denotes millisecond). Use the Backus and Gilbert method to estimate the slowness
(inverse of velocity) n(z) of the acoustic waves in the medium. Represent the resolving
kernel R(z, z′) for z = 10 m and 0 ≤z′ ≤∞.
Solution:
Let n represent a model of slowness (i.e., a particular function z →n(z) ) and d
represent the column matrix of travel times predicted from the model n . Formally,
d = G n
,
(7.265)
where G is the linear operator deﬁned by
di =
 zi
0
dz n(z)
.
(7.266)
The kernels of the operator G are introduced by
di =
 ∞
0
dz Gi(z) n(z)
.
(7.267)
This gives
G1(z) =

1 for 0 ≤z < z1
,
0 for z1 ≤z < ∞
,
G2(z) =

1 for 0 ≤z < z2
,
0 for z2 ≤z < ∞
,
G3(z) =

1 for 0 ≤z < z3
,
0 for z3 ≤z < ∞.
(7.268)
Let dobs be the column matrix of observed travel times:
dobs =


2.0 ms
8.1 ms
10.2 ms


.
(7.269)

306
Chapter 7. Problems
The Backus and Gilbert solution of the problem of estimating the model is (see equa-
tions (6.184) of Appendix 6.16)
m = Gt (G Gt)−1 dobs = Gt(S)−1 dobs
,
(7.270)
where
S = G Gt
.
(7.271)
Explicitly,
n(z) =

i
Gi(z) 8i
,
(7.272)
where
8i =

j
(S−1)ij dobs
j
(7.273)
and
Sij =
 ∞
0
dz Gi(z) Gj(z)
.
(7.274)
Using (7.268) we obtain
S =


2.3
2.3
2.3
2.3
8.1
8.1
2.3
8.1
10.1


,
S−1 =
1
26.68


16.2
−4.6
0
−4.6
17.94
−13.34
0
−13.34
13.34


.
(7.275)
From (7.269) and (7.273), we then obtain
 = S−1 dobs =


−0.182
+0.002
+1.050


.
(7.276)
Equation (7.272) ﬁnally gives the Backus and Gilbert estimate
n(z) = −0.182 G1(z) + 0.002 G2(z) + 1.050 G3(z)
,
(7.277)
which is represented in Figure 7.33.
Figure 7.33. The velocity-versus-
depth
dependence
obtained
using
the
Backus and Gilbert method.
10 m
5 m
0 m
1 s/km
0.5 s/km
0 s/km
15 m

7.19. Using the Backus and Gilbert Method
307
The resolving operator is given by (equation (6.184) of Appendix 6.16)
R = Gt (G Gt)−1 G = Gt S−1 G
.
(7.278)
Explicitly, the resolving kernel is given by
R(z, z′) =

i

j
Gi(z)(S−1)ij Gj(z′)
.
(7.279)
We are asked for the values of R(z, z′) for z = 10 m . We have the following:
for
0.0 ≤z′ < 2.3 : R(10.0 m, z′) = (S−1)31 + (S−1)32 + (S−1)33 = 0.0
;
for
2.3 ≤z′ < 8.1 : R(10.0 m, z′) = (S−1)32 + (S−1)33 = 0.0
;
for
8.1 ≤z′ < 10.1 : R(10.0 m, z′) = (S−1)33 = 0.5
;
for
10.1 ≤z′ < ∞: R(10.0 m, z′) = 0.0
.
(7.280)
The corresponding result is represented in Figure 7.34.
Figure 7.34.
The Backus and
Gilbert resolving kernel.
10 m
5 m
0 m
0.5
0
15 m
Discussion:
The solution shown in Figure 7.33 is the simplest solution predicting the observed
travel times exactly. The kernel shown in Figure 7.34 says that the value of slowness
estimated at z = 10 m is the mean of the true value for 8.1 m < z < 10.1 m . This
can be physically understood: the values of the slowness for z ≤8.1 m are ﬁxed by the
ﬁrst and second observed travel times; it is the third travel time that gives information for
8.1 m < z < 10.1 m , and it only gives information on the integrated slowness, i.e., on the
mean value between z = 8.1 m and z = 10.1 m .
The method gives a null value for the slowness for z > 10.1 m . This is of course
unphysical, but this value is totally unresolved. In fact, the essence of the Backus and Gilbert
method is better obtained when the unknown is a correction to some current model: where
there are no data, there is no correction.
Note that this is a strict application of the Backus and Gilbert method. The methods
proposed in this book suggest that the logarithmic slowness should be used, transforming
this formally linear problem into a nonlinear one (but then deﬁning a truly linear model
space).

308
Chapter 7. Problems
7.20
The Coefﬁcients in the Backus and Gilbert Method
In the Backus and Gilbert method, the problem arises of obtaining the coefﬁcients Qi(r0)
that minimize the expression
J(r0) =

dt

R(r0, r) −δ(r0 −r)
2
,
(7.281)
where (using the sum convention over repeated indices)
R(r0, r) = Qi(r0) Gi(r)
(7.282)
and where the Gi(r) are given functions. Show that the coefﬁcients Qi(r0) are given by
Qi(r0) = (S−1)ij Gj(r0)
,
(7.283)
where
Sij =

dr Gi(r) Gj(r)
.
(7.284)
Solution:
One has
J(r0) =

dr

Qi(r0) Gi(r) −δ(r0 −r)
2
=

dr

Qi(r0) Gi(r) Qj(r0) Gj(r) −2 Qi(r0) Gi(r) δ(r0 −r) + δ2(r0 −r)

= Qi(r0) Sij Qj(r0) −2 Qi(r0) Gi(r0) + δ(0)
,
(7.285)
where
Sij =

dr Gi(r) Gj(r)
(7.286)
and where the inﬁnite value δ(0) can formally be handled as a constant. At the minimum
of J(r0) ,
∂J(r0)
∂Qi(r0) = 0
⇒
Sij Qj(r0) = Gi(r0)
,
(7.287)
from which the result follows (the matrix Sij is regular if the Gi(r) are linearly independent
functions).
7.21
The Norm Associated with the 1D Exponential
Covariance
Let C(t, t′) be the covariance function considered in Examples 5.5 and 5.13:
C(t, t′) = σ 2 exp

−|t −t′|
T

.
(7.288)

7.21. The Norm Associated with the 1D Exponential Covariance
309
The covariance operator C corresponding to the integral kernel 7.288 associates any
function ˆe(t) with the function
e(t) =
 t2
t1
dt′ C(t, t′) ˆe(t′)
,
t ∈[t1, t2]
.
(7.289)
Obtain the inverse operator and the associated scalar product and norm.
Solution:
Noticing that if
ϕ(t) = σ 2 exp

−| t |
T

,
(7.290)
then
∂ϕ
∂t (t) = −1
T sg(t) ϕ(t)
(7.291)
and
∂2ϕ
∂t2 (t) =
1
T 2 ϕ(t) −2 σ 2
T
δ(t)
,
(7.292)
we easily obtain
∂e
∂t (t) = −1
T
 t2
t1
dt′ sg(t −t′) C(t, t′) ˆe(t′)
(7.293)
and
∂2e
∂t2 (t) =
1
T 2 e(t) −2 σ 2
T
ˆe(t)
.
(7.294)
Using (7.289), equation (7.293) shows that the values at t = t1 and t = t2 of e(t) and
∂e/∂t(t) are not independent:
∂e
∂t (t1) = 1
T e(t1)
,
∂e
∂t (t2) = −1
T e(t2)
.
(7.295)
Equation (7.294) then gives
ˆe(t) =
1
2 σ 2 T e(t) −
T
2 σ 2
∂2e
∂t2 (t)
,
t ∈[t1, t2]
.
(7.296)
We see thus that the domain of deﬁnition of the operator C−1 is the set of functions
verifying the conditions (7.295). With any such function, the operator C−1 associates the
function given by 7.296.
Using for C−1 the integral representation
ˆe(t) =
 t2
t1
dt′ C−1(t, t′) e(t′)
(7.297)

310
Chapter 7. Problems
gives
C−1(t, t′) =
1
2 σ 2
 1
T δ(t −t′) −T δ2(t −t′)

,
(7.298)
where I have used the deﬁnition of the derivative of Dirac’s delta distribution:

dt′ δ(n)(t −t′) µ(t′) = (−1)n dn
dtn µ(t)
.
(7.299)
The scalar product of two functions e1 and e2 may be deﬁned by
(e1, e2) = e1
t C−1e2 =
 t2
t1
dt e1(t)
 1
T e2(t) −T ∂2 e2
∂t2 (t)

.
(7.300)
Integrating by parts gives
(e1, e2) = 1
T
 t2
t1
dt e1(t) e2(t) + T
 t2
t1
dt ∂e1
∂t (t) ∂e2
∂t (t) + T
∂e1
∂t (t) e2(t)
 
t2
t1
.
(7.301)
Similarly,
(e2, e1) = 1
T
 t2
t1
dt e2(t) e1(t) + T
 t2
t1
dt ∂e2
∂t (t)∂e1
∂t (t) + T
∂e2
∂t (t) e1(t)
 
t2
t1
,
(7.302)
and we see that the scalar product is symmetric,
(e1, e2) = (e2, e1),
(7.303)
only if the functions e1 and e2 satisfy the dual boundary conditions
∂e1
∂t (t) e2(t) −e2(t) ∂e2
∂t (t)
 
t2
t1
= 0
.
(7.304)
The norm of an element e can be computed by
∥e ∥2 = (e, e) = et C−1 e =
 t2
t1
dt ˆe(t) e(t)
,
(7.305)
where
ˆe = C−1 e
.
(7.306)
We have
∥e ∥2 =
 t2
t1
dt
1
2 σ 2
 1
T e(t) −T ∂2e
∂t2 (t)

e(t)
=
1
2 σ 2
 1
T
 t2
t1
dt e(t)2 −T
 t2
t1
dt ∂e2
∂t2 (t) e(t)

,
(7.307)

7.22. The Norm Associated with the 1D Random Walk
311
and, integrating by parts,
∥e ∥2 =
1
2 σ 2
 1
T
 t2
t1
dt [e(t)]2 + T
 t2
t1
( ∂e
∂t2
)2
+ T ∂e
∂t (t1) e(t1) −T ∂e
∂t (t2) e(t2)

,
(7.308)
which, using equations (7.295), can be rewritten in either of the following two forms:
∥e ∥2 =
1
2 σ 2
 1
T
 t2
t1
dt [e(t)]2 + T
 t2
t1
dt
(∂e
∂t (t)
)2
+ [e(t1)]2 + [e(t2)]2

,
(7.309)
∥e ∥2 =
1
2 σ 2
 1
T
 t2
t1
dt [e(t)]2 + T
 t2
t1
dt
(∂e
∂t (t)
)2
+ T 2
(∂e
∂t (t1)
)2
+ T 2
(∂e
∂t (t2)
)2 
.
(7.310)
As these expressions are sums of squares and vanish only for a null function, we verify
a posteriori that the covariance operator deﬁned by the covariance function C(t, t′) is a
positive deﬁnite operator.
In many applications, the ﬁrst two terms in (7.309) and (7.310) are approximately
proportional to t2 −t1 , and, as usually t2 −t1 ≫T , the last two terms can be dropped,
thus giving
∥e ∥2 ≃
1
2 σ 2

1
T
 t2
t1
dt [e(t)]2 + T
 t2
t1
dt
(∂e
∂t (t)
)2
.
(7.311)
This corresponds to the usual norm in the Sobolev space H 1 (see Appendix 6.25), which
is the sum of the usual L2 -norm of the function and the L2 -norm of its derivative.
7.22
The Norm Associated with the 1D Random Walk
For 0 ≤t ≤T , let C(t, t′) be the covariance function
C(t, t′) = β min(t, t′)
.
(7.312)
As mentioned in Example 5.9, this is the covariance function of a one-dimensional random
walk. Notice that the variance at the point t is σ 2 = C(t, t) = β t . With any function ˆe(t) ,
the covariance operator C , whose kernel is the covariance function (7.312), associates the
function
e(t) =
 T
0
dt′ C(t, t′) ˆe(t′)
.
(7.313)
Obtain the inverse operator and the associated norm.

312
Chapter 7. Problems
Solution:
We have
e(t) = β
 t
0
dt′ t′ ˆe(t′) + t
 T
t
dt′ ˆe(t′)

.
(7.314)
Using
∂
∂t

 T
t dt′ f (t′) = −f (t) gives
∂e
∂t (t) = β
 T
t
dt′ ˆe(t′)
(7.315)
and
∂2e
∂t2 (t) = −β ˆe(t)
.
(7.316)
Equation (7.314) gives the condition
e(0) = 0
,
(7.317)
while (7.315) gives the condition
∂e
∂t (T ) = 0
.
(7.318)
Equation (7.316) gives
ˆe(t) = −1
β
∂2e
∂t2 (t)
.
(7.319)
The domain of deﬁnition of the operator C−1 is the set of functions verifying the
conditions (7.317)–(7.318). Any such function is associated by the operator C−1 with the
function given by (7.319).
A formal introduction of the integral kernel of C−1 gives
ˆe(t) =
 T
0
dt′ C−1(t, t′) e(t′)
,
(7.320)
and, by comparison with (7.319), we directly obtain
C−1(t, t′) = −1
β δ2(t −t′)
.
(7.321)
The norm of an element can be computed by
∥e ∥2 = et C−1e = ⟨ˆe , e ⟩=
 T
0
dt ˆe(t) e(t)
,
(7.322)
where ˆe = C−1 e . We have
∥e ∥2 = −1
β
 T
0
dt e(t) ∂2e
∂t2 (t)
,
(7.323)

7.23. The Norm Associated with the 3D Exponential Covariance
313
and, integrating by parts,
∥e ∥2 = 1
β
 T
0
dt
(∂e
∂t (t)
)2
−e(t)∂e
∂t (t)

T
0

.
(7.324)
Using conditions (7.317)–(7.318) gives the ﬁnal result:
∥e ∥2 = 1
β
 T
0
dt
(∂e
∂t (t)
)2
.
(7.325)
In particular, this demonstrates that C(t, t′) is a positive deﬁnite function.93 This result is
interesting, because we see that a least-squares norm criterion associated with the covariance
function (7.312) imposes that the derivative of the function is small (and not the function
itself).
Notice that the condition (7.317) (i.e., that the function will vanish for t = 0 ) could
be predicted directly from the fact that the variance at t = 0 is null.
7.23
The Norm Associated with the 3D Exponential
Covariance
Let x denote a point in the Euclidean three-dimensional space and let C(x, x′) be the
covariance function
C(x, x′) = σ 2 exp

−∥x −x′ ∥
L

,
(7.326)
where ∥x −x′ ∥denotes the Euclidean distance between points x and x′ . The corre-
sponding covariance operator associates any function ˆφ(x) with the function
φ(x) =

V
dV (x′) C(x, x′) ˆφ(x′)
.
(7.327)
Demonstrate that the inverse operator gives
ˆφ(x) ≃
1
8πσ 2
 1
L3 φ(x) −2
L Fφ(x) + L FFφ(x)

.
(7.328)
The least-squares norm associated with the covariance function, ∥φ ∥2 = φt C−1 φ , is
∥φ ∥2 =

V
dV (x) φ(x) ˆφ(x)
.
(7.329)
Demonstrate that this gives
∥φ ∥2 ≃
1
8πσ 2
. 1
L3

V
dV (x)
,
φ(x)
-2 + 2
L

V
dV (x)
,
grad φ(x)
-2
+ L

V
dV (x)
,
Fφ(x)
-2
/
.
(7.330)
93Because ∥e ∥is nonnegative for any e , if ∥e ∥is null, then e(t) must be constant (almost everywhere),
and then it follows from equations (7.317)–(7.318) that the constant is necessarily zero.

314
Chapter 7. Problems
Solution (from Georges Jobert, pers. comm.):
First, we have to solve the following equation for ˆφ(x) :
φ(x) = σ 2

V
dV (x′) exp

−∥x −x′ ∥
L

ˆφ(x′)
.
(7.331)
Let
g(x) = σ 2 exp

−∥x ∥
L

(7.332)
and let Z(k) , ˆZ(k) , and G(k) be the Fourier transforms of φ(x) , ˆφ(x) , and g(x) ,
respectively. As equation (7.331) is clearly a spatial convolution,
φ(x) = g(x) ∗ˆφ(x)
,
(7.333)
it becomes, in the Fourier domain,
Z(k) = G(k) ˆZ(k)
.
(7.334)
This gives
ˆZ(k) = H(k) φ(K)
,
(7.335)
where
H(k) =
1
G(k)
.
(7.336)
Letting h(x) be the inverse Fourier transform of H(k) gives
ˆφ(x) = h(x) ∗φ(x)
,
(7.337)
which formally solves the problem. The task now is to compute G(k) and h(x) .
Letting k = ∥k ∥, we have
G(k) = σ 2

V
dV (x) e−∥x ∥/L+i k·x
,
(7.338)
and, taking spherical coordinates with the polar axis collinear with k ,
G(k) = σ 2
 π
0
dθ
 2π
0
dϕ
 ∞
0
dr r2 sin θ e−r/L + i ∥k ∥r cos θ
= 2πσ 2
 +1
−1
du
 ∞
0
dr r2e−r/L + i ∥k ∥r u
,
(7.339)
where u = cos θ . As

 +1
−1 du e2 i π ∥k ∥r u = 2 sin r ∥k ∥
r ∥k ∥, we have
G(k) = 4πσ 2
 ∞
0
dr r2 e−r/L
sin(2 π r ∥k ∥)
r ∥k ∥
= 4πσ 2
∥k ∥
 ∞
0
dr r sin(r ∥k ∥) e−r/L .
(7.340)

7.23. The Norm Associated with the 3D Exponential Covariance
315
Using
I(p) =
 ∞
0
dt t sint e−pt =
2 p
(1 + p2)2
,
(7.341)
with p =
1
L ∥k ∥and t = r ∥k ∥, gives
G(k) =
8πσ 2L3
(1 + L2 ∥k ∥2)2
.
(7.342)
Then,
H(k) =
1
8πσ 2
 1
L3 + 2
L ∥k ∥2 + L ∥k ∥4

.
(7.343)
As the Fourier transform of δ(x) is 1 , that of Fδ(x) is −∥k ∥2 , and that of FFδ(x) is
∥k ∥4 , we directly obtain
h(x) =
1
8πσ 2
 1
L3 δ(x) −2
L Fδ(x) + L FFδ(x)

.
(7.344)
This gives
ˆφ(x) =

V
dV (x) h(x −x′) φ(x′)
=
1
8πσ 2
. 1
L3

V
dV (x′) δ(x −x′) φ(x′) −2
L

V
dV (x′) Fδ(x −x′) φ(x′)
+ L

V
dV (x′) FFδ(x −x′) φ(x′)
/
=
1
8πσ 2
 1
L3 φ(x) −2
L Fφ(x) + L FFφ(x)

,
(7.345)
which demonstrates equation (7.328).
The (squared) norm of a function is then given by
∥φ ∥2 =

V
dV (x) φ(x) ˆφ(x)
=
1
8πσ 2
. 1
L3

V
dV (x)
,
φ(x)
-2 −2
L

V
dV (x) φ(x)Fφ(x)
+ L

V
dV (x) φ(x) FFφ(x)
/
.
(7.346)
Using −φ Fφ = [grad φ]2 −div(φ grad φ) gives
−

V
dV (x) φ(x) Fφ(x) =

V
dV (x) [grad φ(x)]2 −

V
dV (x) div(φ(x) grad φ(x))
=

V
dV (x)
,
grad φ(x)
-2 −

∂V
dS(x) φ(x) n(x) · grad φ(x)
,
(7.347)

316
Chapter 7. Problems
where ∂V denotes the boundary of V , n(x) is the unit normal to the boundary, and dS(x) is
theelementofareaontheboundary. Using φ FFφ = −gradφ·gradFφ+div(φ grad Fφ) =
(Fφ)2 −div (Fφ grad φ) + div (φ grad Fφ) gives

V
dV (x) φ(x) FFφ(x)
=

V
dV (x)
,
Fφ(x)
-2 +

V
dV (x) div(φ(x) gradFφ(x)) −

V
dV (x) div(Fφ(x) grad φ(x))
=

V
dV (x) [Fφ(x)]2 +

∂S
dS(x) φ(x) n(x) · grad Fφ(x)
−

∂S
dS(x) Fφ(x) n(x) · grad φ(x) .
(7.348)
In most practical applications, the boundary terms can be dropped. One obtains
∥φ ∥2 ≃
1
8πσ 2
. 1
L3

V
dV (x)
,
φ(x)
-2 + 2
L

V
dV (x)
,
grad φ(x)
-2 + L

V
dV (x)
,
Fφ(x)
-2
/
,
(7.349)
demonstrating equation (7.330).

References and References for
General Reading
Abdelmadek, N., 1977. Computing the strict Chebyshev solution of overdetermined linear
equations, Math. Comput., 31, 974–983.
Abramowitz, M., and Stegun, I. A. (editors), 1970. Handbook of mathematical functions.
Dover Publications Inc., New York.
Aﬁﬁ, A. A., and Azen, S. P., 1979. Statistical analysis: A computer oriented approach,
Academic Press, New York.
Aki, K., Christofferson, A., andHusebye, E.S., 1977. Determinationofthethree-dimensional
seismic structure of the lithosphere, J. Geophys. Res., 82, 277–296.
Aki, K., and Lee, W. H. K., 1976. Determination of three-dimensional velocity anoma-
lies under a seismic array using ﬁrst P arrival times from local earthquakes. 1. A
homogeneous initial model, J. Geophys. Res., 81, 4381–4399.
Aki, K., and Richards, P. G., 1980. Quantitative seismology (2 volumes), Freeman and Co.,
San Francisco.
Alterman, Z. S., and Karal, F. C., Jr., 1968. Propagation of elastic waves in layered media
by ﬁnite difference methods, Bull. Seismological Soc. America, 58, 367–398.
Anderssen, R. S., and Seneta, E., 1971. A simple statistical estimation procedure for Monte-
Carlo inversion in geophysics, Pure Appl. Geophys., 91, 5–13.
Anderssen, R. S., and Seneta, E., 1972.
A simple statistical estimation procedure for
Monte-Carlo inversion in geophysics. II: Efﬁciency and Hempel’s paradox, Pure Appl.
Geophys., 96, 5–14.
Angelier, J., Tarantola, A., Valette, B., and Manoussis, S., 1982. Inversion of ﬁeld data
in fault tectonics to obtain the regional stress, Geophys. J. Royal Astron. Soc., 69,
607–621.
Armstrong, R. D., and Golfrey, J. P., 1979. Two linear programming algorithms for the
linear L1 norm problem, Math. Comput., 33, 145, 289–300.
Aster, A., Borchers, B., and Thurber, C., 2003. Parameter estimation and inverse problems,
in press, Academic Press, New York.
Avriel, M., 1976. Non linear programming: Analysis and methods, Prentice–Hall, Series
in Automatic Computation, London.
Azlarov, T. A., and Volodin, N. A., 1982. Kharaterizatsionnye Zadachi, Sviazannye S
Pokazatel’nym Raspredeleniem, Taschkent, Izdatel’stvo Fan Uzbekckoi CCR. English
317

318
References and References for General Reading
translation: Characterization problems associated with the exponential distribution,
Springer-Verlag, New York, 1986.
Backus, G., 1970a. Inference from inadequate and inaccurate data: I, Proc. Nat. Acad.
Sci., 65, 1, l–105.
Backus, G., 1970b. Inference from inadequate and inaccurate data: II, Proc. Nat. Acad.
Sci., 65, 2, 281–287.
Backus, G., 1970c. Inference from inadequate and inaccurate data: III, Proc. Nat. Acad.
Sci., 67, 1, 282–289.
Backus, G., 1971. Inference from inadequate and inaccurate data, Mathematical problems
in the geophysical sciences: Lectures in Applied Mathematics, 14, American Mathe-
matical Society, Providence, RI.
Backus, G., and Gilbert, F., 1967. Numerical applications of a formalism for geophysical
inverse problems, Geophys. J. Royal Astron. Soc., 13, 247–276.
Backus, G., and Gilbert, F., 1968. The resolving power of gross Earth data, Geophys. J.
Royal Astron. Soc., 16, 169–205.
Backus, G., and Gilbert, F., 1970. Uniqueness in the inversion of inaccurate gross Earth
data, Philos. Trans. Royal Soc. London, 266, 123–192.
Bakhvalov, N. S., 1977. Numerical methods, Mir Publishers, Moscow.
Balakrishnan, A. V., 1976. Applied functional analysis, Springer-Verlag, New York.
Bamberger, A., Chavent, G, Hemon, Ch., and Lailly, P., 1982. Inversion of normal incidence
seismograms, Geophys., 47, 757–770.
Barnes, C., Charara, M., and Tarantola, A., 1998. Monte Carlo inversion of arrival times
for multiple phases in OSVP data, 68th Ann. Internat. Mtg. Soc. Expl. Geophys.,
pp. 1871–1874.
Barrodale I., 1970. On computing best L1 approximations, in: Approximation theory,
edited by A. Talbot, Academic Press, New York.
Barrodale, I., and Phillips, C., 1975a. An improved algorithm for discrete Chebyshev
linear approximation, in: Proceedings of the Fourth Manitoba Conference on Numer-
ical Mathematics, edited by B. L. Hartnell and H. C. Williams, Utilitas Mathematics
Publishing.
Barrodale, I., and Phillips, C., 1975b. Algorithm 495: Solution of an overdetermined
system of linear equations in the Chebyshev norm, A.C.M. Trans. Math. Software, 1,
264–270.
Barrodale, I., and Roberts, F. D. K., 1973. An improved algorithm for discrete L1 linear
approximation, SIAM J. Numer. Anal., 10, 839–848.
Barrodale, I., and Roberts, F. D. K., 1974. Algorithm 478: Solution of an overdetermined
system of equations in the ℓ1 norm, Corn. ACM, 14, 319–320.
Barrodale, I., and Young, A., 1966. Algorithms for best L1 and L∞linear approximations
on a discrete set, Numer. Math., 8, 295–306.
Bartels, R. H., 1971. A stabilisation of the simplex method, Numer. Math., 16, 414–434.
Bartels, R. H., 1980. A penalty linear programming method using reduced gradient basis
exchanges techniques, Linear Algebra Appl., 29, 17–32.
Bartels, R. H., and Conn, A. R., 1981. An approach to nonlinear ℓ1 data ﬁtting, in: Pro-
ceedings of the third Mexican workshop on numerical analysis, J. P. Hennart (editor),
Springer-Verlag, New York.

References and References for General Reading
319
Bartels, R. H., Conn, A. R., and Charalambous, C., 1978. On Cline’s direct method for
solving overdetermined linear systems in the ℓ∞sense, SIAM J. Numer. Anal., 15,
255–270.
Bartels, R. H., Conn, A. R., and Sinclair, J. W., 1978. Minimization techniques for piecewise
differentiable functions: The ℓ1 solution to an overdetermined linear system, SIAM J.
Numer. Anal., 15, 224–241.
Bartels, R. H., and Golub, G. H., 1969. The simplex method of linear programming using
LU decomposition, Corn. ACM, 12, 206–268.
Bartels, R. H., Stoer, J., and Zenger, C. H., 1971. A realization of the simplex method
based on triangular decomposition, in: Handbook for automatic computation, J. H.
Wilkinson and C. Reinsch (editors), Springer-Verlag, New York.
Bayer, R., and Cuer, M., 1981. Inversion tri-dimensionnelle des donnees aéromagnétiques
sur le massif volcanique du Mont-Dore: Implications structurales et géothermiques,
Ann. Géophys., t. 37, fasc. 2, 347–365.
Bayes, Thomas (Reverend), (1702–1761), 1958. Essay towards solving a problem in the
doctrine of chances, 1763, republished in Biometrika, 45, 298–315.
Ben-Menahem, A., and Singh, S. J., 1981. Seismic waves and sources, Springer-Verlag,
New York.
Bender, C. M., and Orszag, S. A., 1978. Advanced mathematical methods for scientists and
engineers, McGraw-Hill, New York.
Berkhout, A. J., 1980. Seismic migration: Imaging of acoustic energy by wave ﬁeld ex-
trapolation, Elsevier, Amsterdam.
Beydoun, W., 1985. Asymptotic Wave Methods in Heterogeneous Media, Ph.D Thesis,
Massachusetts Institute of Technology.
Bierman, G. J., 1977. Factorization methods for discrete sequential estimation, Academic
Press, New York.
Binder, K. (editor), 1979. Monte Carlo methods in statistical physics, Springer-Verlag,
Berlin.
Binder, K., 1984. Applications of the Monte Carlo method in statistical physics, Springer-
Verlag, Berlin.
Bland, R. G., 1976. New Finite Pivoting Rules for the Simplex Method, CORE-research
paper 7612.
Bleistein, N., 1984. Mathematical methods for wave phenomena, Academic Press, New
York.
Bloomﬁeld, P., and Steiger, W. L., 1980. Least absolute deviations curve-ﬁtting, SIAM J.
Sci. Statist. Comput., 1, 290–301.
Bloomﬁeld, P., and Steiger, W. L., 1983. Least absolute deviations, theory, applications,
and algorithms, Birkhäuser, Boston.
Boothby, W. M., 1975. An introduction to differentiable manifolds and Riemannian geom-
etry, Academic Press, New York.
Bordley, R. F., 1982. A multiplicative formula for aggregating probability assessments,
Manag. Sci., 28, 1137–1148.
Box, G. E. P., Leonard, T., and Chien-Fu Wu (editors), 1983. Scientiﬁc inference, data
analysis, and robustness, Academic Press, New York.
Box, G. E. P., and Tiao, G. C., 1973. Bayesian inference in statistical analysis, Addison–
Wesley, Reading, MA.

320
References and References for General Reading
Bradley, S. P., Hax, A. C., and Magnanti, T. L., 1977. Applied mathematical programming,
Addison–Wesley, Reading, MA.
Brecis, H., 1983. Analyse fonctionnelle, théorie et applications, Masson, Paris.
Brillouin, L., 1962. Science and information theory, Academic Press, New York.
Broyden, C. G., 1967. Quasi-Newton methods and their application to function minimiza-
tion, Math. Comput., 21, 368–381.
Bunch, J. R., and Rose, D. J. (editors), 1976. Sparse matrix computations, Academic Press,
New York.
Caers, J. K., Srinivasan, S., and Journel, A. G., 2000.
Geostatistical quantiﬁcation of
geological information for a ﬂuvial-type North Sea reservoir, Society of Petroleum
Engineers, Reservoir Evaluation and Engineering, 3, 5, 457–467.
Campbell, S. L., Meyer, C. D., and Rosi, N. J., 1981. Results of an informal survey on the
use of linear algebra in industry and government, Linear Algebra Appl., 38, 289–294.
Cao, D., Beydoun, W. D., Singh, S. C., and Tarantola, A., 1990. A simultaneous inversion
for background velocity and impedance maps. Geophys., 55, 458–469.
Carroll, Lewis (Rev. Charles Lutwidge Dodgson) (1832–1898), 1871. Alice’s adventures
in Wonderland, Macmillan, London. I recommend to the reader The annotated Alice,
by Martin Gardner, Penguin Books, 1970.
Cartan, H., 1967. Cours de calcul différentiel, Hermann, Paris.
Céa, J., 1971. Optimisation, théorie et algorithmes, Dunod, Paris.
Censor, Y., and Elfving, T., 1982. New methods for linear inequalities, Linear Algebra
Appl., 42, 199–211.
Censor, Y., and Herman, G. T., 1979. Row-generation methods for feasibility and opti-
mization problems involving sparse matrices and their applications, in: Sparse matrix
proceedings 1978, I. S. Duff and G. W. Stewart (editors), SIAM, Philadelphia.
Chapman, N. R., and Barrodale, I., 1983. Deconvolution of marine seismic data using L1
norm, Geophys. J. Royal Astr. Soc., 72, 93–100.
Charara, M., Barnes, C., and Tarantola, A., 1996. The state of affairs in inversion of seismic
data: An OVSP example, 66th Ann. Internat. Mtg. Soc. Expl. Geophys., pp. 1999–
2002.
Charara, M., Barnes, C., and Tarantola, A., 2000. Full waveform inversion of seismic data
for a visco-elastic medium, in: Methods and Applications of Inversion, Lecture Notes
in Earth Sciences, 92, Springer-Verlag, New York.
Chernov, L. A., 1960. Wave propagation in a random medium, Dover Publications Inc.,
New York.
Ciarlet, P. G., 1982. Introduction à l’analyse numérique matrcielle et à l’optimisation,
Masson, Paris.
Ciarlet, P. G., and Thomas, J. M., 1982. Exercices d’analyse numérique matricielle et
d’optimisation, Masson, Paris.
Cimino, G., 1938. Calcolo approximato per le solusioni del sistemi di equazioni lineari, La
Ricerca Scientiﬁca, Roma XVI, Ser. II, Anno IX, Vol. 1, 326–333.
Claerbout, J. F., 1971. Toward a uniﬁed theory of reﬂector mapping, Geophys., 36, 467–481.
Claerbout, J. F., 1976. Fundamentals of geophysical data processing, McGraw-Hill, New
York.
Claerbout, J. F., 1985. Imaging the Earth’s interior, Blackwell, Oxford, U.K.

References and References for General Reading
321
Claerbout, J. F., and Muir, F., 1973. Robust modelling with erratic data, Geophys., 38,
826–844.
Cottle, R. W., and Dantzig, G. B., 1968. Complementary pivot theory of mathematical
programming, Linear Anal. Appl., 1, 103–125.
Courant, R., and Hilbert, D., 1966. Methods of mathematical physics, Interscience Pub-
lishers, New York.
Crase, E., Pica, A., Noble, M., McDonald, J., and Tarantola, A., 1990. Robust elastic
nonlinear waveform inversion: Application to real data. Geophys., 55, 527–538.
Crase, E., Wideman, Ch., Noble, M., and Tarantola, A., 1992. Nonlinear elastic waveform
inversion of land seismic reﬂection data. J. Geophys. Res., 97, 4685–4703.
Cuer, M., 1984. Des questions bien posées dans des problèmes inverses de gravimétrie
et géomagnétisme. Une nouvelle application de la programmation linéaire, Thesis,
Université des Sciences et Techniques du Languedoc, UER de Mathématiques, 34060
Montpellier, France.
Cuer, M., and Bayer, R., 1980a. A package of routines for linear inverse problems, Cahiers
Mathématiques, Université des Sciences et Techniques du Languedoc, UER de Mathé-
matiques, 34060 Montpellier, France.
Cuer, M., and Bayer, R., 1980b. Fortran routines for linear inverse problems, Geophys., 45,
1706–1779.
Dahl-Jensen, D., Mosegaard, K., Gundestrup, N., Clow, G. D., Johnsen, S. J., Hansen, A.
W., and Balling, N., 1998. Past temperatures directly from the Greenland Ice Sheet,
Science, Oct. 9, 268–271.
Dahlquist, B., and Björk, Å., 1974. Numerical methods, Prentice–Hall, Englewood Cliffs,
NJ.
Dantzig, G. B., 1963. Linear programming and extensions, Princeton University Press,
Princeton, NJ.
Dautray, R., and Lions, J. L., 1984 and 1985. Analyse mathématique et calcul numérique
pour les sciences et les techniques (3 volumes), Masson, Paris.
Davidon, W. C., 1959. Variable Metric Method for Minimization, AEC Res. and Dev.,
Report ANL–5990 (revised).
Davidon, W. C., 1968. Variance algorithms for minimization, Comput. J., 10, 406–410.
de Ghellinck, G., and Vial, J. Ph., 1985. An Extension of Karmarkar’s Algorithm for
Solving a System of Linear Homogeneous Equations on the Simplex (preprint), ISSN
0771–3894.
de Ghellinck, G., and Vial, J. Ph., 1986. A Polynomial Newton Method for Linear Pro-
gramming (preprint), CORE, Universite de Louvain.
Denel, J., Fiorot, J. C., and Huard, P., 1981. The steepest ascent method for linear program-
ming problems, RAIRO Analyse Numérique, 15, 3, 195–200.
Descloux, J., 1963. Approximations in Lp and Chebyshev approximations, J. Soc. Indust.
Appl. Math. 11, 1017–1026.
Deutsch, C. V., and Journel, A. G., 1998. GSLIB, Geostatistical software library and user’s
guide, Oxford University Press, New York.
Devaney, A. J., 1984. Geophysical diffraction tomography, IEEE Trans. Geos. Remote
Sensing, GE-22, 3–13.
Dickson, J. C., and Frederick, F. P., 1960. A decision rule for improved efﬁciency in solving
linear problems with the simplex algorithm, Comm. ACM, 3, 509–512.

322
References and References for General Reading
Dietrich, C. F., 1991. Uncertainty, calibration and probability — the statistics of scientiﬁc
and industrial measurement, Adam Hilger, Bristol, U.K.
Dixmier, J., 1969. Cours de mathématiques du premier cycle (2 volumes), Gauthier-Villars,
Paris.
Dixon, L. C. W. (editor), 1976. Optimization in action, Academic Press, London.
Djikpéssé, H.A., and Tarantola, A., 1999. Multiparameter ℓ1 norm waveform ﬁting: Inter-
pretation of Gulf of Mexico reﬂection seismograms. Geophys., 64, 1023–1035.
Draper, N, and Smith, H., 1998. Applied regression analysis (third edition), Wiley, New
York.
Dubes, R. C., 1968. The theory of applied probability, Prentice-Hall, Englewood Cliffs, NJ.
Duijndam, A. J. W., 1987. Detailed Inversion of Seismic Data, Ph.D. Thesis, Delft Univer-
sity of Technology, 1987.
Ecker, J. G., and Kupferschmid, M., 1985. A computational comparison of the ellipsoid
algorithm with several nonlinear programming algorithms, SIAM J. Control Optim.,
23, 657–674.
Edgeworth, F. Y., 1887. A new method of reducing observations relating to several quanti-
ties, Philos. Mag. (5th Ser.), 24, 222–223.
Edgeworth, F. Y., 1888. On a new method of reducing observations relating to several
quantities, Phil. Mag. (5th. Ser.), 25, 184–191.
Ekblom, H., 1973. Calculation of linear best Lp approximations, BIT, 13, 292–300.
Fenton, G.A., 1990. Simulation and Analysis of Random Fields. Ph.D. thesis, Department
of Civil Engineering and Operations Research, Princeton University.
Fenton, G. A., 1994. Error evaluation of three random ﬁeld generators, ASCE J. Engineering
Mech., 120(12), 2478–2497.
Fiacco, A. V., and McCormick, G. P., 1968. Nonlinear programming, Wiley, New York.
Fisher, R. A., 1953. Disperson on a sphere, Proc. R. Soc. London, A127, 295–305.
Fletcher, R., 1980. Practical methods of optimization, Volume 1: Unconstrained optimiza-
tion, Wiley, New York.
Fletcher, R., 1981. Practical methods of optimization, Volume 2: Constrained optimization,
Wiley, New York.
Fletcher, R., and Powell, M. J. D., 1963. A rapidly convergent descent method for mini-
mization, Comput. J., 6, 163–168.
Fletcher, R., and Reeves, C. M., 1964. Function minimization by conjugate gradients,
Comput. J., 7, 149–154.
Fox, L., 1964. An introduction to numerical linear algebra, Clarendon Press, Oxford, U.K.
Frankel, A., and Clayton, R. W., 1986. Finite-difference simulations of seismic scattering,
J. Geophys. Res., 91 B, 6465–6489.
Franklin, J. N., 1970. Well posed stochastic extensions of ill posed linear problems, J. Math.
Anal. Appl., 31, 682–716.
Gacs, P., and Lovasz, L., 1981. Khachiyan’s algorithm for linear programming, in: Mathe-
maticalprogrammingstudy, H.Konig, B.Korte, andK.Ritter(editors), North–Holland,
Amsterdam.
Gale, D., 1960. The theory of linear economic models, McGraw-Hill, New York.
Gass, S. I., 1975. Linear programming, methods and applications, fourth edition, McGraw–
Hill, New York.

References and References for General Reading
323
Gauthier, O., Virieux, J., and Tarantola, A., 1986. Two-dimensional inversion of seismic
waveforms: Numerical results, Geophys., 51, 1387–1403.
Gauss, Carl Friedrich (1777–1855), 1809. Theoria Motus Corporum Coelestium.
Gauss, Carl Friedrich (1777–1855), ca. 1820. Theory of the combination of observations
least subject to errors. English translation, Classics Appl. Math. 11, SIAM, Philadel-
phia, 1995.
Gel’fand I. M., and Levitan, B. M., 1955. On the determination of a differential equation by
its spectral function, Amer. Math. Soc. Transl., 1, Ser. 2, 253–304 (translated from
the Russian paper of 1951).
Geman, S., and Geman, D., 1984.
Stochastic relaxation, Gibbs distributions, and the
Bayesian restoration of images, IEEE Trans. Pattern Anal. Machine Intelligence,
6, 721–741.
Genest, C., and Zidek, J. V., 1986. Combining probability distributions: A critique and an
annotated bibliography, Stat. Sci., 1, 114–148.
Genet, J., 1976. Mesure et intégration, théorie élémentaire, Vuibert, Paris.
Geweke, J., 1992. Evaluating the accuracy of sampling-based approaches to the calculation
of posterior moments, in: Bayesian Statistics, 4, Bernardo, J. M., Berger, J. O., Dawid,
A. P., and Smith, A. F. M. (editors), Oxford University Press, Oxford, U.K., 169–193.
Gill, P. E., and Murray, W., 1973. A numerical stable form of the simplex algorithm, Linear
Algebra Appl., 7, 99–138.
Gill, P. E., Murray, W., Saunders, M. A., and Wright, M. H., 1984. Trends in nonlinear
programming software, Europ. J. Oper. Res., 17, 141–149.
Gill, P. E., Murray, W., and Wright, M. H., 1981. Practical optimization, Academic Press,
London.
Glashoff, K., and Gustafson, S. A., 1983. Linear optimization and approximation, An intro-
duction to the theoretical analysis and numerical treatment of semi-inﬁnite programs,
Springer-Verlag, New York.
Goldberg, D. E., 1989. Genetic algorithms in search, optimization and machine learning,
Addison–Wesley, Reading, MA.
Goldfarb, D., 1976. Using the steepest edge simplex algorithm to solve linear programs, in:
Sparse matrix computations, Bunch, J. R., and Rose, D. J. (editors), Academic Press,
New York.
Goovaerts, P., 1997. Geostatistics for natural resources evaluation, Oxford University Press,
New York.
Grasso, J. R., Cuer, M., and Pascal, G., 1983. Use of two inverse techniques. Application
to a local structure in the New Hebrides island arc, Geophys. J. Royal Astr. Soc., 75,
437–472.
Groetsch, C. W., 1999.
Inverse Problems, The Mathematical Association of America,
Washington, DC.
Gutenberg, B., and Richter, C. F., 1939. On seismic waves, G. Beitr., 54, 94–136.
Guyon, R., 1963. Calcul tensoriel, Vuibert, Paris.
Hacijan, L. G., 1979. A polynomial algorithm in linear programming, Soviet Math. Dokl.,
20, 1, 191–194.
Hadamard, J., 1902. Sur les problèmes aux dérivées partielles et leur signiﬁcation physique,
Princeton University Bulletin, 49–52.

324
References and References for General Reading
Hadamard, J., 1932. Le problème de Cauchy et les équations aux dérivées partielles linéaires
hyperboliques, Hermann, Paris.
Hadley, G., 1965. Linear programming, Addison–Wesley, Reading, MA.
Hampel, F. R., 1978. Modern trends in the theory of robustness, Math. Oper. Stat., Ser.
Stat., 9, 3, 425–442.
Hammersley, J. M., and Handscomb, D. C., 1964. Monte-Carlo methods, Chapman and
Hall, London.
Hanson, R. J., and Wisnieski, J. A., 1979. A mathematical programming updating method
using modiﬁed Givens transformations and applied to LP problems, Comm. ACM,
22, 245–250.
Harris, P. M. J., 1975. Pivot selection methods of the Devex LP code, in: Mathematical
programming study 4, M. L. Balinski and E. Hellerman (editors), North–Holland,
Amsterdam.
Hastings, W. K., 1970. Monte Carlo sampling methods using Markov Chains and their
applications, Biometrika, 57, 97–109.
Herman, G. T., 1980. Image reconstruction from projections, the fundamentals of comput-
erized tomography, Academic Press, San Francisco.
Hestenes, M. R., and Stiefel, E. L., 1952. Methods of conjugate gradients for solving linear
systems, J. Res. Nat. Bur. Standards, sect. 5, vol. 49, 409–436.
Hirn, A., Jobert, G., Wittlinger, G., Xu Zhong-Xin, and Gao En-Yuan, 1984. Main features
of the upper lithosphere in the unit between the high Himalayas and the Yarlung Zangbo
Jiang suture, Ann. Geophys., 2, 113–118.
Ho, J. K., 1978. Pricing for sparsity in the revised simplex method, RAIRO, 12, 3, 285–290.
Hoel, P. G., 1947. Introduction to mathematical statistics, Wiley, New York.
Hofstadter, D., 1979. Gödel, Escher, Bach: An eternal golden braid, Basic Books, New
York.
Huard, P., 1979. La methode simplex sans inverse explicite, Bull. Dir. Etud. Rech. EDF,
Série C, 79–98.
Huard, P., 1980. Complements concernant la méthode des paramètres, Bull. Dir. Etud.
Rech. EDF, Série Math. Info., 2, 63–67.
Huber, P. J., 1977. Robust statistical procedures, CBMS-NSF Regional Conf. Ser. in Appl.
Math. 27, SIAM, Philadelphia.
Huber, P. J., 1981. Robust statistics, Wiley, New York.
Igel, H., Djikpéssé, H., and Tarantola, A., 1996. Waveform inversion of marine reﬂection
seismograms for P impedance and Poisson’s ratio. Geophys. J. Int., 124, 363–371.
Ikelle, L. T., Diet, J. P., and Tarantola, A., 1986. Linearized inversion of multi offset seismic
reﬂection data in the ω-k domain, Geophys., 51, 1266–1276.
Jackson, D. D., 1972. Interpretation of inaccurate, insufﬁcient and inconsistent data, Geo-
phys. J. Royal Astr. Soc., 28, 97–110.
Jackson, D. D., 1979. The use of a priori data to resolve nonuniqueness in linear inversion,
Geophys. J. Royal Astr. Soc., 57, 137–157.
Jackson, D. D., and Matsu’ura, M., 1985. A Bayesian approach to nonlinear inversion, J.
Geophys. Res., 90, Bl, 581–591.
Jaynes, E. T., 1968. Prior probabilities, IEEE Trans. Systems Sci. Cybernetics, SSC-4, 3,
227–241.

References and References for General Reading
325
Jaynes, E. T., 2003. Probability theory, the logic of science. Cambridge University Press,
Cambridge, U.K.
Jeffreys, H., 1939. Theory of probability, Oxford University Press, Oxford, U.K.
Jeffreys, H., 1957. Scientiﬁc inference, Cambridge University Press, London.
Jeroslow, R. G., 1973. The simplex algorithm with the pivot rule of maximizing criterion
improvement, Discrete Math. 4, 367–378.
Jerrum, M., 1994. The Computational Complexity of Counting, LFCS report, ECS-LFCS-
94-296. Available at http://www.dcs.ed.ac.uk/home/mrj/.
Johnson, G. R., and Olhoeft, G. R., 1984. Density of rocks and minerals, in: CRC handbook
of physical properties of rocks, edited by Carmichael, R. S., CRC, Boca Raton, FL.
Journel, A. G., 2002. Combining knowledge from diverse sources: An alternative to tradi-
tional data independence hypotheses, Math. Geol., 34, 5, 573–596.
Journel, A. G., and Huijbregts, Ch. J., 1978. Mining geostatistics, Academic Press, London.
Kagan, A. M., Linnink, Yu.
V., and Rao, C. R., 1973.
Characterization problems in
mathematical statistics, Wiley, New York.
Kalman, R. E., 1960. A new approach to linear ﬁltering and prediction problems, Trans.
ASME–J. Basic Engineering, 82, D, 35–45.
Kalos, M. H., and Whitlock, P. A., 1986. Monte Carlo methods, John Wiley & Sons, New
York.
Kantorovitch, L., and Akilov, G., 1977. Functional analysis, Vol. 1 and Vol. 2 (in Russian),
Nauka, Moscow.
Karmarkar, N., 1984. A new polynomial-time algorithm for linear programming, Combin-
natorica, Vol. 4, No. 4, 373–395.
Kauffman, A., 1977. Introduction à la théorie des sous-ensembles ﬂous, Masson, Paris.
Keilis-Borok, V. J., 1971. The inverse problem of seismology, Proceedings of the Inter-
national School of Physics Enrico Fermi, Course L, Mantle and Core in Planetary
Physics, J. Coulomb and M. Caputo (editors), Academic Press, New York.
Keilis-Borok, V. J., Levshin, A., and Valus, V., 1968. S-wave velocities in the upper mantle
in Europe; report on the IV International Symposium on Geophysical Theory and
Computers 1967, Dokladi Akademii Nauk SSSR, 185, 3, 564.
Keilis-Borok, V. J., and Yanovskaya, T. B., 1967. Inverse problems of seismology (structural
review), Geophys. J. Royal Astr. Soc., 13, 223–234.
Keller, J. B., 1978. Rays, waves, and asymptotics, Bull. AMS, 54, 5, 727–750.
Kennett, B., and Nolet, G., 1978. Resolution analysis for discrete systems, Geophys. J.
Royal Astr. Soc., 53, 413–425.
Kennett, B. L. N., 1978. Some aspects of non-linearity in inversion, Geophys. J. Royal
Astr. Soc., 55, 373–391.
Kirkpatrick, S., Gelatt, C. D., Jr., and Vecchi, M. P., 1983. Optimization by simulated
annealing, Science, 220, 671–680.
Klee V., and Minty, G. J., 1972. How good is the simplex algorithm?, in: Inequalities III,
Shisha, O. (editor), Academic Press, New York.
Kolmogoroff, A. N., 1956. Foundations of the theory of probability, Chelsea, New York.
Kônig, H., and Pallaschke, D., 1981. On Krachian’s algorithm and minimal ellipsoids,
Numer. Math., 36, 211–223.

326
References and References for General Reading
Koren, Z., Mosegaard, K., Landa, E., Thore, P. and Tarantola, A., 1991. Monte Carlo
estimation and resolution analysis of seismic background velocities, J. Geophys. Res.,
96, B12, 20289–20299.
Kuhn, H. W., and Quandt, R. E., 1962. An experimantal study of the simplex method, Proc.
15th Symp. Applied Mathematics of the American Mathematical Society, 107–124.
Kullback, S., 1959. Information theory and statistics, Wiley, New York.
Kullback, S., 1967. The two concepts of information, J. Amer. Stat. Assoc., 62, 685–686.
Lanczos C., 1957. Applied analysis, Prentice–Hall, Englewood Cliffs, NJ.
Landa, J. L., and Guyaguler, B., 2003. A Methodology for History Matching and the
Assessment of Uncertainties Associated with Flow Prediction, paper SPE 84465, SPE
Annual Technical Conference & Exhibition (5–8 October 2003), Denver, CO.
Landau, L. D., and Lifshitz, E. M., 1986. Theory of elasticity (3rd. edition), Pergamon
Press, Oxford, U.K.
Lang, S., 1962. Introduction to differentiable manifolds, Interscience Publishers, New York.
Laplace, Pierre Simon (Marquis de), 1799. Mécanique céleste, Tome III, No. 39.
Laplace, Pierre Simon (Marquis de), 1812. Théorie analytique des probabilités, livre 2.
Lavrent’ev, M. M., Romanov, V. G., and Sisatskij, S. P., 1980. Nekorrektnye zadachi matem-
aticheskoi ﬁsiki i analisa (Ill posed problems in mathematical physics and analysis) (in
Russian), Nauka, Moscow. Translated in Italian: Pubblicazioni dell’Istituto di Analisi
Globale e Applicazioni, Firenze, 1983.
Lawson, Ch. L., and Hanson, R. J., 1974. Solving least squares problems, Prentice–Hall,
Englewood Cliffs, NJ.
Levenberg, K., 1944. A method for the solution of certain nonlinear problems in least
squares, Quart. Appl. Math., 2, 164–168.
Levitan, B. M., 1962. Generalized translation operators and their applications (in Russian),
Fiz. Mat. Gosudarstv. Izdat., Moscow.
Licknerowicz, A., 1960. Eléments de Calcul Tensoriel, Armand Collin, Paris.
Lions, J. L., 1968. Contrôle optimal de systèmes gouvernés par des équations aux dérivées
partielles, Dunod, Paris. English translation: Optimal control of systems governed by
partial differential equations, Springer-Verlag, Berlin, 1971.
Lions, J. L., 1974. Sur la théorie du contrôle, Actes du Congrès International des Mathé-
maticiens, Vancouver, 2, 139–154.
Luenberger, D. G., 1969. Optimization methods by vector space methods, Wiley, New
York.
Luenberger, D. G., 1973. Introduction to linear and nonlinear programming, Addison–
Wesley, Reading, MA.
Magnanti, T. L., 1976. Optimization for sparse systems, in: Sparse matrix computations,
Bunch, J. R., and Rose, D. J. (editors), Academic Press, New York.
Mandelbaum, A., 1984. Linear estimators and measurable linear transformations on a
Hilbert space, Z. Wahrscheinlichkeitstheorie verw. Gebiete, 65, 385–397.
Mandelbrot, B. B., 1977a. Fractals: Form, chance, and dimension, Freeman, San Francisco.
Mandelbrot, B. B., 1977b. The Fractal geometry of nature, Freeman, San Francisco.
Mangasarian, O. L., 1981. Iterative solution of linear programs, SIAM J. Numer. Anal.,
18, 606–614.
Mangasarian, O. L., 1983. Least norm linear programming solution as an unconstrained
minimization problem, J. Math. Anal. Appl., 92, 240–251.

References and References for General Reading
327
Marcenko, V. A., 1978. Sturm-Liouville operators and their applications (in Russian),
Naukova Dumka, Kiev.
Marquardt, D. W., 1963. An algorithm for least-squares estimation of nonlinear parameters,
J. Soc. Indust. Appl. Math., 11, 431–441.
Marquardt, D. W., 1970. Generalized inverses, ridge regression, biased linear estimation
and non-linear estimation, Technometrics, 12, 591–612.
Martz, H. F., and Wailer, R. A., 1982. Bayesian reliability analysis, Wiley, New York.
Matsu’ura, M., and Hirata, N., 1982. Generalized least-squares solutions to quasi-linear
inverse problems with a priori information, J. Phys. Earth, 30, 451–468.
McCall, E. H., 1982. Performance results of the simplex algorithm for a set of real world
linear programming models, Comm. ACM, 25, 3, 207–212.
McNutt, M. K., and Royden, L., 1987. Extremal bounds on geotherms in eroding mountain
belts from metamorphic pressure-temperature conditions, Geophys. J. Royal Astr.
Soc., 88, 81–95.
McNutt, M. K., 1987. Temperature Beneath Midplate Swells: The Inverse Problem, sub-
mitted to Seamounts, Islands, and Atolls, Geophys. Monogr. Ser., 43, American
Geophysical Union, Washington, DC.
Meissl, P., 1976. Hilbert spaces and their applications to geodetic leastsquares problems,
Boll. Geod. Sci. Afﬁni, 35, 49–80.
Menke, W., 1989. Geophysical data analysis: Discrete inverse theory, Academic Press, San
Diego.
Meschkowsky, H., 1962. Hilbertsche räume mit kernfunction, Springer, Berlin.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., and Teller, E., 1953. Equation
of state calculations by fast computing machines, J. Chem. Phys., 21, 1081–1092.
Metropolis, N., and Ulam, S., 1949, The Monte Carlo method, J. Amer. Stat. Assoc., 44,
335–341.
Miller, D. (editor), 1985. Popper selections, Princeton University Press, Princeton, NJ.
Milne, R. D., 1980. Applied functional analysis, Pitman Advanced Publishing Program,
Boston.
Minster, J. B., and Jordan, T. M., 1978. Present-day plate motions, J. Geophys. Res., 83,
5331–5354.
Minster, J. B., Jordan, T. H., Molnar, P., and Haines, E., 1974. Numerical modelling of
instantaneous plate tectonics, Geophys. J. Royal Astr. Soc., 36, 541–576.
Misner, Ch. W., Thorne, K. S., and Wheeler, J. A., 1973. Gravitation, Freeman, San
Francisco.
Morgan, B. W., 1968. An introduction to Bayesian statistical decision processes, Prentice–
Hall, Englewood Cliffs, NJ.
Moritz, H., 1980. Advanced physical geodesy, Herbert Wichmann Verlag, Karlsruhe, Aba-
cus Press, Tunbridge Wells, Kent.
Moritz, H., and Sünkel, H., 1978. Approximation methods in geodesy, H. Wichmann,
Karlsruhe.
Morse, P. M., and Feshbach, H., 1953. Methods of theoretical physics, McGraw–Hill, New
York.
Mosegaard, K., and Tarantola, A., 1995. Monte Carlo sampling of solutions to inverse
problems. J. Geophys. Res., 100, B7, 12431–12447.

328
References and References for General Reading
Mosegaard, K., and Tarantola, A., 2002. Probabilistic approach to inverse problems, In-
ternational Handbook of Earthquake & Engineering Seismology, Part A, Academic
Press, New York, pp. 237–265.
Müller, G., and Kind, R., 1976. Observed and computed seismogram sections for the whole
Earth, Geophys. J. Royal Astr. Soc., 44, 699–716.
Murtagh, B. A., and Sargent, R. W. H., 1969. A constrained minimization method with
quadraticconvergence, in: Optimization, Fletcher, R.(editor), AcademicPress, London.
Murty, K., 1976. Linear and combinatorial programming, Wiley, New York.
Narasimhan, R., 1968. Analysis on real and complex manifolds, Masson, Paris; North–
Holland, Amsterdam.
Nash, S. G., and Sofer, A., 1996. Linear and nonlinear programming, McGraw–Hill, New
York.
Nazareth, L., 1984. Numerical behaviour of LP algorithms based upon the decomposition
principle, Linear Algebra Appl., 57, 181–189.
Nercessian, A., Hirn, A., and Tarantola, A., 1984. Three-dimensional seismic transmission
prospecting of the Mont-Dore volcano, France, Geophys. J. Royal Astr. Soc., 76, 307–
315.
Nering E. D., 1970. Linear algebra and matrix theory (second edition), Wiley, New York.
Nolet, G., 1981. Linearized inversion of (teleseismic) data, in: The solution of the inverse
problem in geophysical interpretation, R. Cassinis (editor), Plenum Press, New York,
pp. 9–37.
Nolet, G., 1985. Solvingorresolvinginadequateandnoisytomographicsystems, J.Comput.
Phys., 61, 463–482.
Oppenheim, A. V. (editor) 1978. Applications of digital signal processing, Prentice–Hall,
Englewood Cliffs, NJ.
Oran Brigham, E., 1974. The fast Fourier transform, Prentice–Hall, Englewood Cliffs, NJ.
Parker, R. L., 1975. The theory of ideal bodies for gravity interpretation, Geophys. J. Royal
Astron. Soc., 42, 315–334.
Parker, R. L., 1977. Understanding inverse theory, Ann. Rev. Earth Plan. Sci., 5, 35–64.
Parker, R. L., 1994. Geophysical inverse theory, Princeton University Press, Princeton, NJ.
Parzen, E., 1959. Statistical inference on time series by Hilbert space methods, I, reprinted
in Time Series Analysis Papers, Holden-Day, San Francisco, pp. 251–282.
Pica, A., Diet, J. P., and Tarantola, A., 1990. Nonlinear inversion of seismic reﬂection data
in a laterally invariant medium, Geophys., 55, 284–292.
Plackett, R. L., 1972. Studies in the history of probability and statistics; chapter 29, The
discovery of the method of least squares, Biometrika, 59, 239–251.
Poincaré, H., 1929. La Science et l’Hypothèse, Flammarion, Paris.
Polack, E., and Ribière, G., 1969. Note sur la convergence de méthodes de directions
conjuguées, Revue Fr. Inf. Rech. Oper., 16–R1, 35–43.
Popper, K., 1959. The logic of scientiﬁc discovery (translation of Logik der Forschung),
Hutchinson, London.
Powell, M. J. D., 1977. Restart procedures for the conjugate gradient method, Mathematical
Programming, 12, 241–254.
Powell, M. J. D., 1981. Approximation theory and methods, Cambridge University Press,
Cambridge, U.K.

References and References for General Reading
329
Press, F., 1968. Earth models obtained by Monte-Carlo inversion, J. Geophys. Res., 73, 16,
5223–5234.
Press, F., 1971. An introduction to Earth structure and seismotectonics, Proceedings of the
International School of Physics Enrico Fermi, Course L, Mantle and Core in Planetary
Physics, Coulomb, J., and Caputo, M. (editors), Academic Press, New York.
Press, W. H., Flannery, B. P., Teutolsky, S. A., and Vetterling, W. T., 1986. Numerical
recipes: The art of scientiﬁc computing, Cambridge University Press, Cambridge,
U.K. (See also Vetterling et al., 1986).
Price, W. L., 1977. A controlled random search procedure for global optimization, Comput.
J., 20, 367–370.
Pugachev, V. S., 1965. Theory of random functions and its application to control problems,
Pergamon Press, Oxford, U.K. (translation of the original Russian Teoriya sluchainykh
funktsii (second edition), Fizmatgiz, Moscow, 1962).
Raftery, A.E., andLewis, S., 1992. HowmanyiterationsintheGibbssampler?, in: Bayesian
statistics, 4, Bernardo, J. M., Berger, J. O., Dawid, A. P., and Smith, A. F. M. (editors),
763–773, Oxford University Press, Oxford, U.K.
Rand Corporation, 1955. A million random digits with 100,000 normal deviates, The Free
Press, Glencoe, IL.
Rao, C. R., 1973. Linear statistical inference and its applications, Wiley, New York.
Rauhala, U. A., 2002. Array algebra expansion of matrix and tensor calculus (parts 1 and
2), SIAM J. Matrix Anal. Appl., 24, 490–528.
Ray Smith, C., and Grandy, W. T., Jr. (editors), 1985. Maximum-entropy and Bayesian
methods in inverse problems, Reidel, Boston.
Rebbi, C., 1984. Monte Carlo calculations in lattice gauge theories, in: Applications of the
Monte Carlo method, Binder, K. (editor), Springer-Verlag, Berlin, pp. 277–298.
Reid, J. K., 1977. Sparse matrix, in: The state of the art in numerical analysis, Jacobs, D.
(editor), Academic Press, London.
Richard, V., Bayer, R., and Cuer, M., 1984. An attempt to formulate wellposed questions
in gravity: Application of linear inverse techniques to mining exploration, Geophys.,
49, 1781–1793.
Richter, C. F., 1958. Elementary seismology, Freeman, San Francisco.
Rietsch, E., 1977. The maximum entropy approach to inverse problems, J. Geophys., 42,
489–506.
Roach, G. F., 1982. Green’s functions, Cambridge University Press, Cambridge, U.K.
Robinson, E. A., 1981. Least squares regression analysis in terms of linear algebra, Goose
Pond Press, Houston, TX.
Robinson, E. A., and Treitel, S., 1980. Geophysical signal analysis, Prentice–Hall, Engle-
wood Cliffs, NJ.
Rockafellar, R. T., 1974. Augmented Lagrange multiplier functions and duality in noncon-
vex programming, SIAM J. Control, 12, 268–285.
Rodgers, C. D., 1976. Retrieval of atmospheric temperature and composition from remote
measurements of thermal radiation, Rev. Geophys. Space Phys., 14, 4, 609–624.
Rothman, D. H., 1985a. Large Near-surface Anomalies, Seismic Reﬂection Data, and
Simulated Annealing (Ph.D. Thesis), Stanford University.
Rothman, D. H., 1985b. Nonlinear inversion, statistical mechanics, and residual statics
estimation, Geophys., 50, 2797–2807.

330
References and References for General Reading
Rothman, D. H., 1986. Automatic estimation of large residual statics corrections, Geophys.,
51, 332–346.
Rufﬁé, J., 1982. Traité du vivant, Fayard, Paris.
Sabatier, P. C., 1977a. On geophysical inverse problems and constraints, J. Geophys., 43,
115–137.
Sabatier, P. C., 1977b. Positivity constraints in linear inverse problems: I) General theory,
Geophys. J. Royal Astr. Soc., 48, 415–441.
Sabatier, P. C., 1977c. Positivity constraints in linear inverse problems: II) Applications,
Geophys. J. Royal Astr. Soc., 48, 443–459.
Safon, C., Vasseur, G., and Cuer, M., 1977. Some applications of linear programming to
the inverse gravity problem, Geophys., 42, 1215–1229.
Savage, L. J., 1954. The foundations of statistics, Wiley, New York.
Savage, L. J., 1962. The foundations of statistical inference, Methuen, London.
Scales, L. E., 1985. Introduction to non-linear optimization, Springer-Verlag, New York.
Schmitt, S. A., 1969. Measuring uncertainty: An elementary introduction to Bayesian
statistics, Addison–Wesley, Reading, MA.
Schwartz, L., 1965. Méthodes mathématiques pour les sciences physiques, Hermann, Paris.
Schwartz, L., 1966. Théorie des distributions, Hermann, Paris.
Schwartz, L., 1970. Analyse (topologie générnle et analyse fontionelle), Hermann, Paris.
Schweizer, B., and Sklar, A., 1963. Associative functions and abstract semigroups, Publ.
Math. Debrecen, 10, 69–81.
Shannon, C. E., 1948. A mathematical theory of communication, Bell System Tech. J., 27,
379–423.
Snay, R. A., 1978. Applicability of array algebra, Rev. Geophys. Space Phys., 16, 459–464.
Sobczyk, K., 1985. Stochastic wave propagation, Elsevier, Amsterdam.
Spyropoulos, K., Kiountouzis, E., and Young, A., 1973. Discrete approximation in the L1
norm, Comput. J., 16, 180–186.
Tanimoto, A., 1985. The Backus-Gilbert approach to the three-dimensional structure in the
upper mantle. I. Lateral variation of surface wave phase velocity with its error and
resolution, Geophys. J. Royal Astr. Soc., 82, 105–123.
Tarantola, A., 1981. Essai d’une approche générale du problème inverse, Thèse de doctorat
d’Etat, Universite de Paris VI.
Tarantola, A., 1984a. Linearized inversion of seismic reﬂection data, Geophys. Prospecting,
32, 998–1015.
Tarantola, A., 1984b. Inversion of seismic reﬂection data in the acoustic approximation,
Geophys., 49, 1259–1266.
Tarantola, A., 1984c. The seismic reﬂection inverse problem, in: Inverse problems of
acoustic and elastic waves, Santosa, F., Pao, Y.-H., Symes, W., and Holland, Ch.
(editors), SIAM, Philadelphia.
Tarantola, A., 1986. A strategy for nonlinear elastic inversion of seismic reﬂection data,
Geophys., 51, 10, 1893–1903.
Tarantola, A., 1987a. Inverse problem theory, methods for data ﬁtting and model parameter
estimation, Elsevier, Amsterdam.
Tarantola, A., 1987b. Inversion of travel time and seismic waveforms, in: Seismic tomog-
raphy, Nolet, G. (editor), Reidel, Boston.

References and References for General Reading
331
Tarantola, A., 1988. Theoretical background for the inversion of seismic waveforms, in-
cluding elasticity and attenuation, Pure Appl. Geophys., 128, 365–399.
Tarantola, A., 1993.
Tomography using waveform ﬁtting of body-waves, in: Seismic
Tomography, Iyer, H. M. (editor), Chapman and Hall, London.
Tarantola, A., Jobert, G., Trézéguet, D., and Denelle, E., 1988. The non-linear inversion of
seismic waveforms can be performed either by time extrapolation or by depth extrap-
olation. Geophys. Prospecting, 36, 383–416.
Tarantola, A., and Nercessian, A., 1984.
Three-dimensional inversion without blocks,
Geophys. J. Royal Astr. Soc., 76, 299–306.
Tarantola, A., Ruegg, J. C., and Lépine, J. C., 1979. Geodetic evidence for rifting in Afar:
A brittle-elastic model of the behaviour of the lithosphere, Earth Planet. Sci. Lett., 45,
435–444.
Tarantola, A., Ruegg, J. C., and Lépine, J. C., 1980. Geodetic evidence for rifting in Afar.
2: Vertical displacements, Earth Planet. Sci. Lett., 48, 363–370.
Tarantola, A., Trygvasson, E., and Nercessian, A., 1985. Volcanic or seismic prediction as
an inverse problem, Ann. Geophys., 1, 6, 443–450.
Tarantola, A., and Valette, B., 1982a. Inverse problems = quest for information, J. Geophys.,
50, 159–170.
Tarantola, A., and Valette, B., 1982b. Generalized nonlinear inverse problems solved using
the least-squares criterion, Rev. Geophys. Space Phys., 20, 2, 219–232.
Tatarski, V. I., 1961. Wave Propagation in a Turbulent Medium, McGraw-Hill, New York.
Taylor, A. E., and Lay, D. C., 1980. Introduction to functional analysis, Wiley, New York.
Taylor, J. R., 1982. An introduction to error analysis, University Science Books, Mill Valley,
CA.
Taylor, S. J., 1966. Introduction to measure and integration, Cambridge University Press,
Cambridge, U.K.
Teo, K. L., and Wu, Z. S., 1984. Computational methods for optimizing distributed systems,
Academic Press, Orlando, FL.
Tikhonov, A. N., 1963. Resolution of ill-posed problems and the regularization method (in
Russian), Dokl. Akad. Nauk SSSR, 151, 501–504.
Tikhonov, A. N., and Arsenine, V., 1974. Methods of resolution of ill-posed problems (in
Russian), Nauka, Moscow. French translation: Méthodes. de résolution de problèmes
mal posés, Mir, Moscow, 1976.
Tolla, P., 1984. Amélioration de la stabilité numérique d’algorithmes de résolution de pro-
grammes linéaires à matrices de contraintes clairsemées, RAIRO Recherche Opéra-
tionelle, 18, 1, 19–42.
Tscherning, C. C., 1978. Introduction to functional analysis with a view to its applications in
approximation theory, in: Approximation methods in geodesy, Moritz H., and Sünkel,
H. (editors), H. Wichmann, Karlsruhe.
Tukey, J. W., 1960. A survey of sampling from contaminated distributions, in: Contributions
to probability and statistics, Olkin, I. (editor), Stanford University Press, Stanford.
Tukey, J. W., 1962. The future of data analysis, Ann. Math. Stat., 33, 1–67.
Tukey, J. W., 1965. Data analysis and the frontiers of geophysics, Science, 148, 3675,
1283–1289.

332
References and References for General Reading
Twomey, S., 1977. Introduction to the mathematics of inversion in remote sensing and indi-
rect measurements, Developments in geomathematics 3, Elsevier Scientiﬁc Publishing,
Amsterdam.
Van Campenhout, J. M., and Cover, T. M., 1981. Maximum entropy and conditional prob-
ability, IEEE Trans. Information Theory, IT-27, 483–489.
Vetterling, W. T., Teutolsky, S. A., Press, W. H., and Flannery, B. P., 1986. Numerical
recipes: Example book, Cambridge University Press, Cambridge, U.K. (See also Press
et al., 1986).
Von Dam, W. B., and Tilanus, C. B., 1984. Mathematical programming in the Netherlands,
Europ. J. Oper. Res., 18, 315–321.
Von Newmann, J., and Morgenstern, O., 1947. Theory of games and economic behaviour
(second editor), Princeton University Press, Princeton, NJ.
Walsh, G. R., 1975. Methods of optimization, Wiley, New York.
Watson, G. A., 1980. Approximation theory and numerical methods, Wiley, New York.
Wiggins, R. A., 1972. The general inverse problem: Implication of surface waves and free
oscillations for Earth structure, Rev. Geophys. Space Phys., 10, 251–285.
Williamson, J. H., 1968. Least squares ﬁtting of a straight line, Canadian J. Phys., 46,
1845–1848.
Winkler, R. L., 1972. Introduction to Bayesian inference & decision, Holt, Rinehart &
Winston, New York.
Wold, H., 1948. Random normal deviates, Tracts for computers 25, Cambridge University
Press, Cambridge, U.K.
Wolfe, J. M., 1979. On the convergence of an algorithm for discrete Lp approximation,
Numer. Math., 32, 439–459.
Woodhouse, J. H., and Dziewonski, A. M., 1984. Mapping the upper mantle: Three-
dimensional modeling of Earth structure by inversion of seismic waveforms, J. Geo-
phys. Res., 89, B7, 5953–5986.
Yeganeh-Haeri, A., Weidner, D. J., and Parise, J. B., 1992. Elasticity of *-cristobalite: A
silicon dioxide with a negative Poisson’s ratio, Science, 257, 650–652.
York, 1969. Least squares ﬁtting of a straight line with correlated errors, Earth Planet. Sci.
Lett., 5, 320–324.
Zadeh, L. A., 1965. Fuzzy sets, Information and control, 8, 338–353.

Index
L2-norm, 236
ℓ1-norm, 81, 82
criterion, 89
criterion (and the method of steepest
descent), 93
linear programming, 228
misﬁt function, 89
ℓ∞-norm, 82
criterion, 96
criterion (and linear programming),
99
criterion (and the method of steepest
descent), 98
minimization (using linear program-
ming), 229
ℓp-norm, 82
criterion, 88
misﬁt function, 290
properties, 246
σ-ﬁeld, 6
circle in the ℓp-norm sense, 83
a posteriori
covariance operator, 69
probabilities, 37
probability density, 34
state of information, 32
a priori information, 27
absolutely continuous, 11
acoustic waveforms
inversion, 144, 297
action, 189
additive noise, 26
adjoint, 187
of a differential operator, 184
formal, 187
operator, 62, 242
relation with transpose, 62
Aﬁﬁ, 177
Aki, 72, 145, 146
Alterman, 300
analysis of uncertainties, 38
Anderssen, 42
application, 230
Armstrong, 229
Aster, 80
atlas, 232
Azen, 177
back-projection, 142
Backus, 72, 108, 133, 135, 190, 191
Backus and Gilbert method, 191
coefﬁcients, 308
example, 304
Bakhvalov, 180
Balakrishnan, 104
Banach space, 236
Barnes, 156
Barrodale, 229, 230
Bartels, 225
basis of a linear space, 237
Bayer, 229
Bayes, 9
Bayes theorem, 18, 20
Bayesian, 9
bijective, 230
bilinear form, 240
bit, 12
Björk, 77
Boothby, 2
Bordley, 14
Borel, xi
Born approximation, 128
Boscovich, 82
333

334
Index
Boucher, 45, 46
Box, 11, 37
Bradley, 95
Brownian motion, 44, 52
Broyden, 220
Buffon, 41
bulk modulus, 11
Céa, 203, 217, 219
canonicalproblem(oflinearprogramming),
225
Cartesian parameter, 163
cascaded Metropolis algorithm, 51, 182
Cauchy sequence, 233
Cauchy–Schwarz inequality, 183
Censor, 225
center, 171
central estimator, 170
change of coordinates, 8
characterizationofarandomfunction, 102
Charara, 156
chart, 232
Chebyshev norm, 98
chi-squared
function, 64, 178
probability density, 177
Christofferson, 72
Ciarlet, 80, 203, 217, 219, 225
Cimino, 225
circle in the ℓp-norm sense, 83
circular covariance, 113
Claerbout, 81, 82, 96
Clayton, 113, 117
closed
interval, 231
subset, 231
combination of states of information, 13,
32
complete, 233
compliance, 2, 165
components
of a model, 4
computing probabilities, 47
condition number, 215, 279
conditional
probability, 16
probability density, 19
conjugate directions, 216
conjunction
of probability densities, 195, 285
of states of information, 13, 14
conjunction of probabilities
airplane navigator, 14
impact on a screen, 15
Conn, 229
continuous
function, 232
linear operator, 237, 241
operator, 234
contravariant metric, 61
convergence of quasi-Newton, 69
convolution of two Gaussians, 202
coordinates, 4
Cartesian, 3
over the model manifold, 3
correlation, 71
coefﬁcient, 173
length, 118
cost function, 64
Cottle, 225
Courant, 190
covariance, 172
neglected, 31
posterior, 66, 70
covariance function, 106
circular, 113
exponential, 111
Gaussian, 113
random walk, 114
white noise, 114
covariance operator, 60, 110
adjoint, 288
covariant metric, 61
Cuer, 225, 229
curvature, 210
cylinder measure, 191
Dahlquist, 77
Dantzig, 95, 225, 226
data
components, 5
manifold, 5

Index
335
space, 5
space (linear), 5
vector, 5
Dautray, 190
Davidon, 220
De Ghellinck, 225
delta function, 9
deltaness criterion, 192
densities of rocks, 29
density, 8
density of volume, 10
derivative operator, 119
discrete, 247
Deutsch, 30
differential operator, 184
digit, 12
dimension of a linear space, 237
discretization of a function, 29
disjunction of states of information, 13,
14
dispersion, 171
distance, 183, 232
Djikpéssé, 93, 95
domain of deﬁnition, 230
Draper, 74
dual
bases, 59
boundary conditions, 186
of a linear space, 109
of an ℓp-normed space, 83
problems, 225
space, 58, 239
duality
product, 58
theorem, 226
Dubes, 173
dumped least-squares, 80
Ecker, 225
efﬁciency of Metropolis algorithm, 53
eigenvector analysis, 73
elastic waveforms
inversion, 144
elasticity, 2–4
Elfving, 225
emptinessoflarge-dimensionalspaces, 42
energy function, 54
epicentral estimation, 253, 289
equivalent parameterizations, 2
estimation of uncertainties, 70
estimator of dispersion, 170
event, 6
existenceofthesolutionofaninverseprob-
lem, 34
exponential
3D covariance (norm), 313
covariance function, 111
covariance function and associated
norm, 118
covariance (norm), 308, 311
norm, 308
norm (3D), 313
Fenton, 112, 117
Feshbach, 145, 190
ﬁelds
smooth, 3
FIFO method, 96
ﬁnite-dimensional linear space, 237
Fisher probability density, 39
Fletcher, 203, 216, 217, 219, 220
form, 239
forward
modeling, 2
operator, 20
problem, 20
Fréchet derivative, 120, 299
acoustic waveforms, 148
elastic waveforms, 148
inversion of waveforms, 125
travel-time tomography, 123
X-ray tomography, 121
Frankel, 113, 117
Franklin, 108, 133
function, 230
functional least squares, 108
functional linear problem, 134
functions
smooth, 3
fuzzy sets, 14
intersection, 14
union, 14

336
Index
Gacs, 225
Gass, 95, 226
Gauss, xii, 64, 81
Gauss–Markoff theorem, 68
Gaussian
covariance function, 113
generalized, 174
linear model for inverse problems,
36
model for inverse problems, 36
random ﬁeld, 45
random function, 106
sequential simulation, 135
uncertainties, 26, 35
Geman, 49, 54
generalized
Gaussian, 174
Gaussianmodelforinverseproblems,
36
Genest, 14
genetic algorithms, 51
geodetic adjustment (with outlier), 296
geostatistics, 30
Gibbs sampler, 49
Gilbert, 72, 135, 191
Gill, 203
global optimization (software), 80
global optimum, 69
Goldberg, 51
Goldfarb, 220
Golfrey, 229
goodness of ﬁt, 179
Goovaerts, 30
gradient, 204
least squares, 75
norm, 209
versus steepest vector, 205
gradient-based optimization algorithms,
203
gravity’s acceleration (measure of), 256
Green
function, 145
theorem, 184, 187, 189
Guyaguler, 38
Hacijan, 225
half-life
of a nucleus, 28
half-range, 171
Hammersley, 180
Handscomb, 180
Hastings, 50
Hax, 95
Herman, 121, 142
Hessian, 204
least squares, 75
matrix, 76
of the least-squares misﬁt function,
205
Hestenes, 217
Hilbert, 190
Hilbert space, 117, 190, 241
histograms
the making of, 14
Hofstadter, 8
homogeneous
probability density, 7, 10
probability density (invariance), 11
probability density (for second rank
tensors), 170
probability distributions, 160
probability (for seismic velocities),
168
Hooke’s law, 164
Huijbregts, 30
Husebye, 72
hypocentral estimation, 253, 289
image, 230
implicit sum convention, 59
incompressibility modulus, 11, 165
independent
events, 18
samples, 7, 52
variables, 19
inﬁnite-dimensional linear space, 237
information
perfect, 9
information content, 12
injective, 230
instrument
with additive noise, 26

Index
337
with known statistics, 25
perfect, 26
integral operator, 184
intersection, 6
of fuzzy sets, 14
invariance
homogeneousprobabilitydensity, 11
inverse, 230
modeling, 2
of a partitioned matrix, 250
of the covariance, 188
problem (solution), 32, 33
inversion
of acoustic waveforms, 297
of elastic waveforms, 144
inversion sampling method, 48
isometric isomorphism, 241
isomorphic
linear spaces, 238
spaces, 231
isomorphism, 231, 238
isometric, 241
Jacobian rule, 8
Jaynes, 6, 11, 163
Jeffreys, 6, 12, 101, 162
parameter, 12, 162
parameter (power), 163
tensor, 165
Jeroslow, 225
joint probability density, 19
Journel, 14, 30
Kônig, 225
Kalman ﬁlter, 67, 198
Kalos, 42
Karal, 300
Karmarkar, 225
Keilis-Borok, 42
kernel, 238
operator, 184
subspace, 184
Kirkpatrick, 54
Klee, 225
Kolmogorov axioms, 6
Koren, 47
Kupferschmid, 225
Lagrange parameters, 73, 249
Landa, 38
Landau, 145
Lang, 2
Laplace, xii, 64, 81
Laplace distribution, 89
Laplace function, 81
large residuals, 74
laws
physical, 2
Lay, 109
least-absolute-values
criterion, 81, 89
least squares, 57, 62
function, 64
norm, 236
Lee, 72
Legendre, xii
Levenberg, 80
Levenberg–Marquardt, 80
Lifshitz, 145
likelihood, 12
function, 34, 35, 39
linear, 231
form, 58, 239
operator, 237
operator (continuous), 241
problem, 64
programming, 95, 223
programming (dual problems), 225
programming (ℓ1-norm), 228
regression(withanoutlier), 275, 295
regression(withroundingerrors), 266
regression(uncertaintiesinbothaxes),
273
regression (usual least-squares), 269
space, 58, 234
space (normed), 183
subspace, 236
linearly independent, 236
Lions, 190
local optimum, 69
log-normal probability density, 175
long-tailed distribution, 81

338
Index
Lovasc, 225
Luenberger, 95
Magnanti, 95, 225
Mangasarian, 225
manifold, 2, 232
mapping, 230
marginal probability density, 18
marginalizing in linear least squares, 200
Markov chain Monte Carlo, 50
Marquardt, 80
mass of Earth’s core, 9
math optimizer (software), 80
Mathematica, 80
mathematical expectation, 171, 172
Matlab, 80
matrix identities, 249
maximumentropyprobabilitydensity, 245
maximum likelihood point, 39
McCall, 225
MCMC, 50
mean, 171, 172
deviation, 89, 171, 174
sample, 162
value (of a random function), 105
measure, 6
density, 7
measurement uncertainties, 21
measurements, 24
measuring travel times, 25
median, 171
metric
on a manifold, 160
open subset, 234
space, 183, 232
Metropolis, 50
algorithm, 41, 50
algorithm (cascaded), 51
Metropolis–Hastings algorithm, 50
midrange, 171, 175
mille-feuille, 58, 206
minimax
criterion, 98
norm, 98
Minty, 225
misﬁt function
in least-squares, 64
in ℓp-norm problems, 88
for nonlinear least-squares, 68
model, 3
parameters, 1
model parameters
a priori information, 27
model space
ﬁnite-dimensional, 3
linear, 4
manifold, 2
random exploration, 38
modelization
imperfections, 21
uncertainties (negligible), 34
models
multiplication, 4
sum, 4
Monte Carlo
methods, 41
Monte Carlo method
of numerical integration, 179
Morgan, 37
Moritz, 101
Morse, 145, 190
Mosegaard, 19, 22, 35, 50, 51, 53
movie strategy, 44
Muir, 81, 82, 96
Murray, 203
Murty, 95
Narasimhan, 2
Nash, 225
natural topology, 234
Nazareth, 225
neglecting covariances, 31
negligible
modelization uncertainties, 34
observational uncertainties, 35
neighborhood, 231
nep, 12
Nercessian, 144, 289
Neumann series, 238
Newton
algorithm, 211
method, 76, 210

Index
339
method (for ℓp-norms), 210
noise
additive, 26
noninformative
probability density, 11
nonlinear
regression, 256
nonlinear least-squares, 68
nonlinear problem, 64
norm, 61, 117, 183, 235
associated with exponential 3D co-
variance, 313
associated with exponential covari-
ance, 308
associated with random walk, 311
of a continuous operator, 238
of the generalized Gaussian, 250
of the gradient, 209
properties, 83
triangular, 14
normed linear space, 235
null space, 184, 238
number
of iterations, 69
of parameters resolved, 73
objective function, 64
observable parameters, 2
observational uncertainties
negligible, 35
one-to-one, 230
onto, 230
open subset, 231
operator, 230
outlier, 26, 81
outlier (example in geodetic adjustment),
296
overdetermined, 67
p-event, 16
Pallaschke, 225
parameter manifold, 6
parameterization, 1, 2
equivalent, 2
of a system, 2
parameters, 6
partial derivatives, 68
partition of data into subsets, 197
partitioned matrix
inverse, 250
perfect information, 9
petrophysical parameters, 24
Phillips, 230
physical
dimensions of a probability density,
8
laws, 2
system, 1
Plackett, 68
point, 232
Poisson ratio, 163, 166
homogeneousprobabilitydensity, 167
negative values, 167
Polak, 217
Popper, 20
positive deﬁnite bilinear form, 240
posterior covariance, 66, 70
Powell, 203, 217, 219, 220
pre-Hilbert space, 241
preconditioned
gradient methods, 78
steepest descent, 214
prescribed covariance, 116
Press, 42
principal components of the gradient, 94
prior probability density, 32
probability, 6
of causes, 18
density, 7
distribution, 6
relative, 7
volumetric, 8
probability density, 5, 7, 159
a priori, 32
conditional, 19
homogeneous, 7, 10
joint, 19
marginal, 18
noninformative, 11
physical dimensions, 8
theoretical, 32
probability distribution, 4

340
Index
probability-event, 16
product of probability densities, 285
Pugachev, 61, 103, 107, 111, 172
quasi-Newton
algorithm, 79
in least squares, 78
method, 69, 215
random
function, 101
function (characterization), 102
function (realization), 111
variable, 9
walk, 52, 102
random exploration of the model space,
38
random walk
covariance function, 114
norm, 311
range, 230
rank of a linear operator, 238
Rao, 68, 177
Rauhala, 4
reciprocity, 146
Reeves, 217
reﬂexive space, 239
refutation of a theory, 20
rejection sampling method, 49
relative information (of two Gaussians),
201
residuals
large, 74
resolution operator, 72
resolving kernel, 192
Ribière, 217
Richards, 145, 146
Riesz
representation theorem, 109, 241
Rietsch, 11, 163
Roach, 145
Roberts, 229
robust method, 81
Rodgers, 216
Rosenbrock function, 204
Rothman, 42, 54
roughing operator, 61
rounding error, 81
Rufﬁé, 41
sample, 6, 34
sampling
methods, 48
theposteriorprobabilitydistribution,
52
the prior probability distribution, 52
Savage, 11
scalar product, 60, 117, 241, 243
Scales, 203, 217, 219
Schmitt, 37
Schweizer, 14
self-adjoint, 188
wave equation operator, 190
self-adjoint operator, 62
Seneta, 42
sequential random realization, 181
sequential realization method, 49
series development, 204
Shannon, 12, 220
shear modulus, 11, 165
simplex method, 95, 96, 223
example, 293
simulated annealing, 54
Sinclair, 229
Sklar, 14
slack variables, 226, 227
slope, 209
Smith, 74
smooth functions, 61
smoothing operator, 61
smoothing the solution, 67
Snay, 4
Sobolev norm, 236
Sobolev space, 243, 244
Sofer, 225
solution
of the general inverse problem, 34
of an inverse problem, 34
of linear least-squares, 66
space
L2, 242
Lp, 242

Index
341
Sobolev, 243
spectral radius, 238
sphere in the ℓp-norm sense, 83
standard deviation, 171, 174
state of information, 9
a posteriori, 32
states of information
conjunction, 14
disjunction, 14
stationary random function, 106
steepest
ascent (in ℓp-norm problems), 88
ascent vector, 75, 205
descent algorithm, 70, 76, 77, 212
descent (in least-squares), 78
descentinℓp-norminverseproblems,
213
descent (preconditioned), 214
Stiefel, 217
stiffness, 2, 165
strong
convergence, 240
nonlinearities, 70
strongly nonlinear problem, 64
subjective knowledge, 9
surjective, 230
symmetric
bilinear form, 240
operator, 60, 186
wave equation operator, 190
system
physical, 1
tangent linear application, 120
Tarantola, 14, 19, 22, 24, 32, 35, 50, 51,
53, 93, 95, 145, 146, 216, 256,
289
Tatarski, 113
Taylor, 109
tends to, 233
The transpose of, 185, 188
theoretical probability density, 32
Thomas, 225
Tiao, 11, 37
tomography, 259, 289
topological space, 231, 235
transformation, 230
transpose, 186
of a differential operator, 184
of the elastodynamics operator, 188
formal, 184
of the gradient, 185
operator, 59, 119, 240
operator (in functional spaces), 128
operator(inwaveforminversion), 132
operator (in X-ray tomography), 131
relation with adjoint, 62
travel-time tomography, 143
travel times
measurement, 25
triangular
conorm, 14
inequality, 183
norm, 14
Tukey, 1, 57
Ulam, 50
uncertainties
analysis, 38
uncorrelated variables, 173
uniform norm, 98
uniformly convergent sequence of linear
operators, 238
union, 6
union of fuzzy sets, 14
uniqueness of the solution of an inverse
problem, 34
Valette, 14, 32, 216, 256
variable
metric, 219
metric (for least squares), 221
metric method, 77
variance, 172
vector, 234
vector space, 234
Vial, 225
volcanic eruption, 23
volume density, 10, 159
volumetric probability, 8, 12, 159
Voronoi cells, 102
Walsh, 203, 217, 219

342
Index
Watson, 82, 84, 86, 229, 230
weak
convergence, 239
nonlinearity, 68
weakly nonlinear problem, 64
weighting
function, 118
operator, 60, 117, 188
white noise covariance function, 114
Whitlock, 42
Wiggins, 74
Winkler, 37
Wolff, 41
Wright, 203
X-ray tomography, 140
Yanovskaya, 42
Yeganeh-Haeri, 167
Young, 229
Young modulus, 163, 166
Zadeh, 13, 14
Zidek, 14



