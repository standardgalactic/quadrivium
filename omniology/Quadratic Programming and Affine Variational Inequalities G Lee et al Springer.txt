- 
QUADRATIC PROGRAMMING 
AND AFFINE VARIATIONAL 
INEQUALITIES 
A Qualitative Study 

Nonconvex Optimization and Its Applications 
VOLUME 78 
Managing Editor: 
Panos Pardalos 
University of Florida, U.S.A. 
Advisory Board: 
J. R. Birge 
University of Michigan, U.S.A. 
Ding-Zhu Du 
University of Minnesota, U.S.A. 
C. A. Floudas 
Princeton University, U.S.A. 
J. Mockus 
Lithuanian Academy of Sciences, Lithuania 
H. D. Sherali 
Virginia Polytechnic Institute and State University, U.S.A. 
G. Stavroulakis 
Technical University Braunschweig, Germany 
H. Tuy 
National Centre for Natural Science and Technology, Vietnam 

-- 
- 
QUADRATIC PROGRAMMING 
AND AFFINE VARIATIONAL 
INEQUALITIES 
A Qualitative Study 
GUE MYUNG LEE 
Pukyong National University, Republic of Korea 
NGUYEN NANG TAM 
Hanoi Pedagogical Institute No. 2, Vietnam 
NGUYEN DONG YEN 
Vietnamese Academy of Science and Technology, Vietnam 
Springer 
- 

Library of Congress Catalogingin-Publication Data 
A C.I.P. record for this book is available from the Library of Congress. 
ISBN 0-387-24277-5 
e-ISBN 0-387-24278-3 
Printed on acid-free paper. 
O 2005 Springer Science+Business Media, Inc. 
All rights reserved. This work may not be translated or copied in whole or in part without the 
written permission of the publisher (Springer Science+Business Media, Inc., 233 Spring Street, 
New York, NY 10013, USA), except for brief excerpts in connection with reviews or scholarly 
analysis. Use in connection with any form of information storage and retrieval, electronic 
adaptation, computer software, or by similar or dissimilar methodology now know or hereafter 
developed is forbidden. 
The use in this publication of trade names, trademarks, service marks and similar terms, even if 
the are not identified as such, is not to be taken as an expression of opinion as to whether or not 
they are subject to proprietary rights. 
Printed in the United States of America. 
9 8 7 6 5 4 3 2 1  
SPIN 11375562 

Contents 
Preface 
ix 
Notations and Abbreviations 
xi 
Quadratic Programming Problems 
1 
1.1 Mathematical Programming 
. . . . . . . . . . . . . . . . . . . . . . . . .  
Problems 
1 
1.2 Convex Programs and Nonconvex Programs . . . . .  4 
1.3 Smooth Programs and Nonsmooth Programs . . . . .  14 
1.4 Linear Programs and Nonlinear Programs . . . . . .  19 
. . . . . . . . . . . . . . . . . .  
1.5 Quadratic Programs 
21 
. . . . . . . . . . . . . . . . . . . . . .  
1.6 Commentaries 
27 
2 Existence Theorems for Quadratic Programs 
29 
. . . . . . . . . . . . . . .  
2.1 The Frank-Wolfe Theorem 
29 
. . . . . . . . . . . . . . . . . . .  
2.2 The Eaves Theorem 
36 
2.3 Commentaries . . . . . . . . . . . . . . . . . . . . . .  43 
3 Necessary and Sufficient Optimality Conditions for 
Quadratic Programs 
45 
3.1 First-Order Optimality Conditions . . . . . . . . . .  45 
3.2 Second-Order Optimality 
. . . . . . . . . . . . . . . . . . . . . . . .  
Conditions 
50 
. . . . . . . . . . . . . . . . . . . . . .  
3.3 Commentaries 
62 
4 Properties of the Solution Sets of Quadratic Pro- 
grams 
6 5 
4.1 Characterizations of the Unboundedness of the Solu- 
. . . . . . . . . . . . . . . . . . . . . . . . .  
tionsets 
65 
. . . . . . . . . . . .  
4.2 Closedness of the Solution Sets 
76 
4.3 A Property of the Bounded Infinite Solution Sets . . 77 

. . . . . . . . . . . . .  
4.4 Finiteness of the Solution Sets 
79 
. . . . . . . . . . . . . . . . . . . . . .  
4.5 Commentaries 
84 
5 Affine Variational Inequalities 
8 5 
. . . . . . . . . . . . . . . . .  
5.1 Variational Inequalities 
85 
. . . . . . . . . . . . . .  
5.2 Complementarity Problems 
91 
. . . . . . . . . . . . .  
5.3 Affine Variational Inequalities 
91 
. . . . . . . . . . .  
5.4 Linear Complementarity Problems 
99 
. . . . . . . . . . . . . . . . . . . . . .  
5.5 Commentaries 
101 
6 Solution Existence for Affine Variational Inequalities 103 
. . . . . . . .  
6.1 Solution Existence under Monotonicity 
103 
. . . . . . . . .  
6.2 Solution Existence under Copositivity 
109 
. . . . . . . . . . . . . . . . . . . . . .  
6.3 Commentaries 
118 
7 Upper-Lipschitz Continuity of the Solution Map in 
Affine Variational Inequalities 
119 
. . . . . . . . . . . . . .  
7.1 The Walkup-Wets Theorem 
119 
7.2 Upper-Lipschitz Continuity with respect to Linear 
. . . . . . . . . . . . . . . . . . . . . . . . .  
Variables 
122 
7.3 Upper-Lipschitz Continuity with respect to all Vari- 
. . . . . . . . . . . . . . . . . . . . . . . . . . .  
ables 
129 
. . . . . . . . . . . . . . . . . . . . . .  
7.4 Commentaries 
141 
8 Linear Fractional Vector Optimization Problems 
143 
. . . . . . . . . . . . . . . . . . . . .  
8.1 LFVO Problems 
143 
. . . . . . . . . .  
8.2 Connectedness of the Solution Sets 
148 
. . . . . . . . . . . . . .  
8.3 Stability of the Solution Sets 
152 
. . . . . . . . . . . . . . . . . . . . . .  
8.4 Commentaries 
153 
9 The Traffic Equilibrium Problem 
155 
. . . . . . . . . . . . . . .  
9.1 Traffic Networks Equilibria 
155 
9.2 Reduction of the Network Equilibrium Problem to a 
. . . . . . . . . . . . . . .  
Complementarity Problem 
158 
9.3 Reduction of the Network Equilibrium Problem to a 
. . . . . . . . . . . . . . . . . .  
Variational Inequality 
159 
. . . . . . . . . . . . . . . . . . . . . .  
9.4 Commentaries 
162 
10 Upper Semicontinuity of the KKT Point Set Map- 
ping 
163 
. . . .  
10.1 KKT Point Set of the Canonical QP Problems 
163 
10.2 A Necessary Condition for the usc Property of S(.) . 165 

vii 
. . . . . . . . . . . . . . . . . . . . .  
10.3 A Special Case 
168 
10.4 Sufficient Conditions for the usc Property of S(.) . . 174 
. . . . . . . . . . . . . . . .  
10.5 Corollaries and Examples 
179 
. . . . . . .  
10.6 USC Property of S(.). The General Case 
182 
. . . . . . . . . . . . . . . . . . . . . .  
10.7 Commentaries 
193 
11 Lower Semicontinuity of the KKT Point Set Map- 
ping 
195 
. . . . . . . . .  
11.1 The Case of Canonical QP Problems 
195 
. . . . . . . . . .  
11.2 The Case of Standard QP Problems 
199 
. . . . . . . . . . . . . . . . . . . . . .  
11.3 Commentaries 
211 
12 Continuity of the Solution Map in Quadratic Pro- 
gramming 
213 
. . . . . . . . . .  
12.1 USC Property of the Solution Map 
213 
. . . . . . . . . . . .  
12.2 LSC Property the Solution Map 
216 
. . . . . . . . . . . . . . . . . . . . . .  
12.3 Commentaries 
222 
13 Continuity of the Optimal Value Function in Quadratic 
Programming 
223 
. . . . . .  
13.1 Continuity of the Optimal Value Function 
223 
13.2 Semicontinuity of the Optimal Value Function . . . .  233 
. . . . . . . . . . . . . . . . . . . . . .  
13.3 Commentaries 
237 
14 Directional Differentiability of the Optimal Value Func- 
tion 
239 
. . . . . . . . . . . . . . . . . . . . . . . . .  
14.1 Lemmas 
239 
. . . . . . . . . . . . . . . . . . . . . .  
14.2 Condition (G) 
246 
. . . . . . . . . .  
14.3 Directional Differentiability of cp(.) 
250 
. . . . . . . . . . . . . . . . . . . . . .  
14.4 Commentaries 
257 
15 Quadratic Programming under Linear Perturbations: 
I . Continuity of the Solution Maps 
259 
. . .  
15.1 Lower Semicontinuity of the Local Solution Map 
260 
. . . . . .  
15.2 Lower Semicontinuity of the Solution Map 
261 
. . . . . . . . . . . . . . . . . . . . . .  
15.3 Commentaries 
268 
16 Quadratic Programming under Linear Perturbations: 
I1 . Properties of the Optimal Value Function 
269 
. . . . . . . . . . . . . . . . . . . .  
16.1 Auxiliary Results 
269 
. . . . . . . . . . . . . .  
16.2 Directional Differentiability 
274 
. . . . . . . . .  
16.3 Piecewise Linear-Quadratic Property 
278 

. . . 
Vlll 
16.4 Proof of Proposition 16.2 . . . . . . . . . . . . . . . . 287 
16.5 Commentaries . . . . . . . . . . . . . . . . . . . . . . 289 
17 Quadratic Programming under Linear Perturbations: 
111. The Convex Case 
291 
17.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . 291 
17.2 Projection onto a Moving Polyhedral Convex Set . . 293 
17.3 Application to Variational Inequalities . . . . . . . . 297 
17.4 Application to a Network Equilibrium Problem . . . 300 
17.5 Commentaries . . . . . . . . . . . . . . . . . . . . . . 305 
18 Continuity of the Solution Map in Affine Variational 
Inequalities 
307 
18.1 USC Property of the Solution Map . . . . . . . . . . 307 
18.2 LSC Property of the Solution Map . . . . . . . . . . 321 
18.3 Commentaries . . . . . . . . . . . . . . . . . . . . . . 327 
References 
329 
Index 
343 

Preface 
Quadratic programs and affine variational inequalities represent 
two fundamental, closely-related classes of problems in the t,heories 
of mathematical programming and variational inequalities, respec- 
tively. This book develops a unified theory on qualitative aspects of 
nonconvex quadratic programming and affine variational inequal- 
ities. The first seven chapters introduce the reader step-by-step 
to the central issues concerning a quadratic program or an affine 
variational inequality, such as the solution existence, necessary and 
sufficient conditions for a point to belong to the solution set, and 
properties of the solution set. The subsequent two chapters discuss 
briefly two concrete nlodels (linear fractional vector optimization 
and the traffic equilibrium problem) whose analysis can benefit a lot 
from using the results on quadratic programs and affine variational 
inequalities. There are six chapters devoted to the study of continu- 
ity and/or differentiability properties of the characteristic maps and 
functions in quadratic programs and in affine variational inequali- 
ties where all the components of the problem data are subject to 
perturbation. Quadratic programs and affine variational inequali- 
ties under linear perturbations are studied in three other chapters. 
One special feature of the presentation is that when a certain prop- 
erty of a characteristic map or function is investigated, we always 
try first to establish necessary conditions for it to hold, then we 
go on to study whether the obtained necessary conditions are suffi- 
cient ones. This helps to clarify the structures of the two classes of 
problems under consideration. The qualitative results can be used 
for dealing with algorithms and applications related to quadratic 
programming problems and affine variational inequalities. 
This book can be useful for postgraduate students in applied 
mathematics and for researchers in the field of nonlinear program- 
ming and equilibrium problems. It can be used for some advanced 
courses on nonconvex quadratic programming and affine variational 
inequalities. 
Among many references in the field discussed in this monograph, 
we would like to mention the following well-known books: "Linear 
and Combinatorial Programming" by K. G. Murty (1976), "Non- 
Linear Parametric Optimization" by B. Bank, J. Guddat, D. Klatt,e, 
B. Kummer and K. Tammer (1982), and "The Linear Complemen- 
tarity Problem" by R. W. Cottle, J.-S. Pang and R. E. Stone (1992). 

As for prerequisites, the reader is expected to be familiar with 
the basic facts of Linear Algebra, Functional Analysis, and Convex 
Analysis. 
We started writing this book in Pusan (Korea) and completed 
our writing in Hanoi (Vietnam). This book would not be possible 
without the financial support from the Korea Research Foundation 
(Grant KRF 2000-015-DP0044), the Korean Science and Engineer- 
ing Foundation (through the APEC Postdoctoral Fellowship Pro- 
gram and the Brain Pool Program), the National Program in Basic 
Sciences (Vietnam). 
We would like to ask the international publishers who have pub- 
lished some of our research papers in their journals or proceedings 
volumes for letting us to use a re-edited form of these papers for 
this book. We thank them a lot for their kind permission. 
We would like to express our sincere thanks to the following 
experts for their kind help or generous encouragement at different, 
times in our research related to this book: Prof. Y. J. Cho, Dr. 
N. H. Dien, Prof. P. H. Dien, Prof. F. Giannessi, Prof. J. S. Jung, 
Prof. P. Q. Khanh, Prof. D. S. Kim, Prof. J. K. Kim, Prof. 
S. Kum, Prof. M. Kwapisz, Prof. B. S. Lee, Prof. D. T. Luc, 
Prof. K. Malanowski, Prof. C. Malivert, Prof. A. Maugeri, Prof. 
L. D. Muu, Prof. A. Nowakowski, Prof. S. Park, Prof. J.-P. Penot, 
Prof. V. N. Phat, Prof. H. X. Phu, Dr. T. D. Phuong, Prof. 
B. Ricceri, Prof. P. H. Sach, Prof. N. K. Son, Prof. M. Studniarski, 
Prof. M. Thdra, Prof. T. D. Van. Also, it is our pleasant duty to 
thank Mr. N. Q. Huy for his efficient cooperation in polishing some 
arguments in the proof of Theorem 8.1. 
The late Professor W. Oettli had a great influence on our re- 
search on quadratic programs and affine variational inequalities. 
We always remember him with sympathy and gratefulness. 
We would like to thank Professor P. M. Pardalos for supporting 
our plan of writing this monograph. 
This book is dedicated to our parents. We thank our families 
for patience and encouragement. 
Any comment on this book will be accepted with sincere thanks. 
May 2004 
Gue Myung Lee, Nguyen Nang Tam, and Nguyen Dong Yen 

Notations and Abbreviations 
Rn 
R", 
0 
xl' 
llxll 
(x, Y) 
A' 
rankA 
l l  All 
Rmxn 
BRn 
into 
- 
R 
bdR 
coR 
dist (x, S2) 
coneM 
riA 
affA 
extrA 
O+A 
T A ( ~  
N A ( ~  
M L  
the set of the positive integers 
the real line 
the extended real line 
the n-dimensional Euclidean space 
the nonnegative orthant in Rn 
the empty set 
the transpose of vector x 
the norm of vector x 
the scalar product of x and y 
the transpose of matrix A 
the rank of matrix A 
the norm of matrix A 
the set of the m x n-matrices 
the set of the symmetric n x n-matrices 
the determinant of a square matrix A 
the unit matrix in RnXn 
the open ball centered at x with radius 6 
the closed ball centered at x 
with radius 6 
the closed unit ball in Rn 
the interior of R 
the closure of R 
the boundary of R 
the convex hull of R 
the distance from x to R 
the cone generated by M 
the relative interior of a convex set A 
the affine hull of A 
the set of the extreme points of A 
the recession cone of A 
the tangent cone to A at 3 
the normal cone to A at 3 
the linear subspace of Rn orthogonal to 
M c Rn 
PK(.) the metric projection from Rn 
onto a closed convex subset K C Rn 

xii 
the effective domain of function f 
the directional derivative of f at Z 
in direction v 
the Clarke generalized directional 
derivative of f at 3 in direction v 
the subdifferential of a convex function 
f at 3, or the Clarke generalized gradient 
of a locally Lipschitz function f at 3 
the gradient of f at Z 
the Hessian matrix of f at Z 
the solution set of problem (P) 
the local solution set of problem ( P )  
the KKT point set of problem ( P )  
the optimal value of problem ( P )  
quadratic programming 
quadratic program defined by matrices 
D, A and vectors c, b 
the K K T  point set 
of a quadratic program 
the solution set of 
a quadratic program 
the solution set of a quadratic program 
the optimal value function of 
a quadratic program 
variational inequality 
the local-solution set of a quadratic 
program 
the VI defined by operator q5 and set A 
affine variational inequality 
the solution set of VI(6, A) 
the AVI defined by matrix M ,  vector q, 
and set A 
the solution set of AVI(M, q, A )  
the solution set of AVI(M, q, A) where 
A = {x : Ax > b )  
linear complementarity 
the LCP problem defined by matrix M 
and vector q 
the solution set of LCP(M, q) 

... 
Xlll 
NCP 
NCP(4, A) 
LFVO 
VVI 
Sol(VP) 
Sol (VP)" 
lsc 
lsc property 
USC 
usc property 
OD-pair 
plq 
PVI 
nonlinear complementarity 
the NCP problem defined by 4 and A 
linear fractional vector optimization 
vector variational inequality 
the efficient solution set 
of the LFVO problem (VP) 
the weakly efficient solution set 
of the LFVO problem (VP) 
lower semicontinuous 
lower semicontinuity property 
upper semicontinuous 
upper semicontinuity property 
origin-destination pair 
piecewise linear-quadratic 
parametric variational inequality 


Chapter 1 
Quadratic Programming 
Problems 
Quadratic programming problems constitute a special class of non- 
linear mathematical programming problems. This chapter presents 
some preliminaries related to mathematical programming problems 
including the quadratic programming problems. The subsequent 
three chapters will provide a detailed exposition of the basic facts 
on quadratic programming problems, such as the solution existence, 
first-order optimality conditions, second-order optimality conditions, 
and properties of the solution sets. 
1.1 Mathematical Programming 
Problems 
Many practical and theoretical problems can be modeled in the form 
(PI 
Minimize f (x) subject to x E A, 
where f : Rn -t R is a given function, A c Rn is a given subset. 
Here and subsequently, R = [-cm, +cm] = R U {-cm) 
U {fcm) 
denotes the extended real line, Rn stands for the n-dimensional 
Euclidean space with the norm 

2 
1. Quadratic Programming Problems 
for all x = (xl, . . . , x,) E Rn and the scalar product 
for all x = (31,. . . , x,), y = (yl,. . . , y,) E Rn. Here and subse- 
, I  
quently, the apex 
denotes the matrix transposition. In the text, 
vectors are expressed as rows of real numbers; while in the ma- 
trix computations they are understood as columns of real numbers. 
The open ball in Rn centered at x with radius 6 > 0 is denoted by 
B(x, 6). The corresponding closed ball is denoted by B(x, 6). Thus 
The unit ball ~ ( 0 ,  
1) will be frequently denoted by BRn. For a set 
R c Rn, the notations into, a and bdR, respectively, are used 
to denote the topological interior, the topological closure and the 
boundary of R. Thus fi is the smallest closed subset in Rn containing 
R, and 
We say that U C Rn is a neighborhood of x E Rn if there exists 
E > 0 such that B(x,E) c U .  Sometimes instead of (P) we write 
the following 
min{f(x) : x E A}. 
Definition 1.1. We call (P) a mathematical programming problem. 
We call f the objective function and A the constraint set (also the 
feasible region) of (P). Elements of A are said to be the feasible 
vectors of (P). If A = Rn then we say that (P) is an unconstrained 
problem. Otherwise (P) is called a constrained problem. 
Definition 1.2 (cf. Rockafellar and Wets (1998), p. 4) A feasible 
vector 3 E A is called a (global) solution of (P) if f (3) # +oo and 
f(x) 2 f(2) for all x E A. We say that 3 7: A is a local solution 
of (P) if f (3) # +oo and there exists a neighborhood U of 
such 
that 
f (x) 2 f (3) for all x E A n U. 
(1.1) 
The set of all the solutions (resp., the local solutions) of (P) is 
denoted by Sol(P) (resp., loc(P)). We say that two mathematical 
programming problems are equivalent if the solution set of the first 
problem coincides with that of the second one. 

1.1 Mathematical Programming Problems 
3 
Definition 1.3. The optimal value v(P) of (P) is defined by setting 
v(P) = inf{f(x) : x E A). 
(1.2) 
If A = 0 then, by convention, v(P) = +oo. 
Remark 1.1. It is clear that Sol(P) c loc(P). It is also obvious 
that 
SO~(P) = {X E a : f ( ~ )  
# +w, f ( ~ )  
= v(P)). 
Remark 1.2. It may happen that loc(P) \ Sol(P) # 0. For ex- 
ample, if we choose A = [-I, +oo) and f (x) = 2x3 - 3x2 + 1 then 
3 = 1 is a local solution of (P) which is not a global solution. 
Remark 1.3. Instead of the minimization problem (P), one may 
encounter with the following maximization problem 
(PI 1 
Maximize f (x) subject to x E A. 
A point Z E A is said to be a (global) solution of (PI) iff (3) # -W 
and f (x) 5 f (3) for all x E A. We say that Z E A is a local solution 
of (PI) if f (3) # -oo and there exists a neighborhood U of Z such 
that f (x) 5 f (3) for all x E A n U. It is clear that 3 is a solution 
(resp., a local solution) of (PI) if and only if 3 is a solution (resp., 
a local solution) of the following minimization problem 
Minimize - f (x) subject to x E A. 
Thus any maximization problem of the form (PI) can be reduced 
to a minimization problem of the form (P). 
Remark 1.4. Even in the case v(P) is a finite real number, it may 
happen that Sol(P) = 0. For example, if A = [l, +w) c R and 
f (4 = 
for x # 0 
+oo 
for x = 0 
then v(P) = 0, while Sol(P) = 0. 
There are different ways to classify mathematical programming 
problems: 
0 
Convex vs. Nonconvex 
Smooth vs. Nonsmooth 
Linear vs. Nonlinear. 

4 
1. Quadratic Programming Problems 
1.2 Convex Programs and Nonconvex 
Programs 
Definition 1.4. We say that A c Rn is a convex set if 
t x +  (1 - t ) y  E A for every x E A, y E A and t E (0,l). (1.3) 
The smallest convex set containing a set R C Rn is called the convex 
hull of 52 and it is denoted by coR. 
Definition 1.5. A function f : Rn 4 
R is said to be convex if its 
epigraph 
epif : = { ( x , a )  : X E  Rn, a €  R, a >  f ( x ) )  
(I.4) 
is a convex subset of the product space Rn x R. A convex function 
f is said to be proper if f ( x )  < +m for at least one x E Rn and 
f ( x )  > -m for all x E Rn. A function f : Rn 4 
is said to be 
concave if the function - f defined by the formula (- f ) ( x )  = - f ( x )  
is convex. 
By the usual convention (see Rockafellar (1970), p. 24), 
a + ( + m ) = ( + m ) + a = + m  
for - o o < a < + m ,  
a + ( - - m ) = ( - m ) + a = - m  
for - o o < a < + m ,  
a(+m) = (+m)a = +m, a(-oo) = (-m)a = -m, 
for O < a <  +m, 
a(+oo) = (+m)a = -m, a ( - m )  = (-m)a = +m, 
for - m < a < O ,  
O(+m) = (+m)O = 0 = O(-m) = (-m)O, 
-(-m) = +oo, inf 0 = +a, sup0 = -m. 
The combinations (+m) + (-m) and (-oo) + (+m) have no mean- 
ing and will be avoided. 
Note that a function f : Rn 4 
R U { + m )  is convex if and only 
if 
f (tx+(l-t)y) i t f  (x)+(l-t) f (y), Vx, y E Rn, Yt E (0,l). (1.5) 
Indeed, by definition, f is convex if and only if the set epi f defined 
in (1.4) is convex. This means that 

1.2 Convex Programs and Nonconvex Programs 
5 
for all t E (0,l) and for all x, y E Rn, a, ,B E R satisfying a 2 
f(x), ,B 2 f (y). It is a simple matter to show that the latter is 
equivalent to (1.5). 
More generally, a function f : Rn -+ R U {+m) is convex if and 
only if 
f ( X I X I +  . .+Xkxk) < Xl f (xl)+. . ++Ak f (xk) (Jensen's Inequality) 
whenever 21,. . . , xk E Rn and X1 2 0, . . . , Xk 2 0, X1 + . . . + Xk = 1. 
(See Rockafellar (1970), Theorem 4.3). 
Definition 1.6. We say that (P) is a convex program (a convex 
mathematical programming problem) if A is a convex set and f is 
a convex function. 
Proposition 1.1. If (P) is a convex program then 
Proof. It suffices to show that loc(P) C Sol(P) whenever (P) is 
a convex program. Let 3 E loc(P) and let U be a neighborhood 
of 3 such that (1.1) holds. If Z $ Sol(P) then there must exist 
2 E A such that f (2) < f (3). Since f (z) # +m, this implies that 
f (2) E R U {-m). 
We first consider the case f (2) # -m. For any t E (0, I), we 
have 
Since t i  + (1 - t ) ~  
= 3 + t(2 - 3) belongs to A n U for sufficiently 
small t E (0, I), (1.7) contradicts (1.1). 
We now consider the case f (2) = -m. Fix any t E (0,l). For 
every a E R, since (2, a) E epi f and (3, f (3)) E epi f , we have 
t(2,a) + (1 - t)(3, f(3)) E epif. 
Hence f (t2 + (1 - t ) ~ )  
< t a  + (1 - t) f (3) for all a E R. This implies 
that f (t2 + (1 - t ) ~ )  
= -m. Since the last equality is valid for all 
t E (0,l) and t2 + (1 - t)3 E A n U if t E (0,l) is sufficiently small, 
(1.1) cannot hold. We have arrived at a contradiction. 
Definition 1.7. If A is nonconvex (= not convex) or f is non- 
convex then we say that (P) is a nonconvex program (a nonconvex 
mathematical programming problem). 

6 
1. Quadratic Programming Problems 
Example 1.1. Consider the problem 
min{f (x) = (21 - c
~
)
~
 
+ ( 2 2  - ~
2
)
~
 
: x E A), 
(1.8) 
whereA={x=(x1,x2):x1 ~ O ) ~ { x = ( x ~ , x ~ ) : x ~ ~ 0 ) a n d c =  
(cl,c2) = (-2, -1). Note that f is convex, while A is nonconvex. 
It is clear that (1.8) is equivalent to the following problem 
min{llx - ell : x E A). 
(1.9) 
On can easily verify that the solution set of (1.8) and (1.9) consists 
of only one point (-2, O), and the local solution set contains two 
points: (-2,O) and (0, - 1). 
3 
Example 1.2. Let fl(x) = -x+2, f2(x) = x + -, x E R. Define 
2 
f (x) = min{ fl (x), f2(x)) and choose A = [O, 21 c R. For these f 
and A, we have 
Note that in this example f is a nonconvex function, while A is a 
convex set. 
Convex functions have many nice properties. For example, a 
convex function is continuous at any interior point of its effective 
domain and it is directionally differentiable at any point in the do- 
main. 
Definition 1.8. For a function f : Rn --t z, 
the set 
domf := {x E Rn : -oo < f(x) < +oo) 
(1.10) 
is called the eflective domain of f .  For a point 5 E domf and a 
vector v E Rn, if the limit 
fl(Z; v) := lim f (Z + tv) - f (3) 
tL0 
t 
(which may have the values +oo and -GO) exists then f is said to be 
directionally diflerentiable at Z in direction v and the value f1(5; v) 
is called the directional derivative of f at 3 in direction v. If f ' ( ~ ;  
v) 
exists for all v E Rn then f is said to be directionally differentiable 
at Z. 
In the next two theorems, f : Rn t R U {+oo) is a proper 
convex function. 

1.2 Convex Programs and Nonconvex Programs 
7 
Theorem 1.1. (See Rockafellar (1970), Theorem 10.1) If 3 E Rn 
and 6 > 0 are such that the open ball B(3, S )  is contained in dom f ,  
then the restriction o f f  to B(3,S) is a continuous real function. 
Theorem 1.2. (See Rockafellar ( I W ' O ) ,  Theorem 23.1) If 3 E dom f 
then for any v E Rn the limit 
f'(3; v) := lim f (3 + tv) - f (3) 
ti0 
t 
exists, and one has 
f '(3; v )  = inf f (3 + tv) - f (3) 
t>O 
t 
Definition 1.9. The normal cone Nn(3) to a convex set A C Rn 
at a point 3 E Rn is defined by the formula 
{x* E Rn : (x*,x - 3) 5 0 for all x E A )  if 3 E A 
Nn(" = { @  
i f  6 A. 
(1.12) 
Definition 1.10. The subdiflerential d f (3) of a convex function 
f : Rn -+ R at a point 3 E Rn is defined by setting 
d f ( 3 )  = {x* E Rn : f(z) + (x*,x -3) 5 f(x) for every x E Rn). 
(1.13) 
Definition 1.11. A subset M c Rn is called an afine set if tx + 
(1 - t)y E M for every x E M, y E M and t E R. For a convex 
set A c Rn, the afzne hull affA of A is the smallest affine set 
containing A. The relative interior of A is defined by the formula 
riA = { x  E A : 36 > 0 such that B(x, 6 )  n a f f A  C A). 
The following statement describes the relation between the di- 
rectional derivative and the subdifferential of convex functions. 
Theorem 1.3. (See Rockafellar (1970), Theorem 23.4) Let f be a 
proper convex function on Rn. If x 6 dom f then df ( x )  is empty. 
If x E ri(dom f )  then d f ( x )  is nonempty and 
Besides, df ( x )  is a nonempty bounded set if and only zf 
x E int(dom f ) ,  

8 
1. Quadratic Programming Problems 
in which case f'(x; v) is finite for every v E Rn. 
The following result is called the Moreau-Rockafellar Theorem. 
Theorem 1.4. (See Rockafellar (1970), Theorem 23.8) Let f = 
f l  + . . . + f k ,  where f l  , . . . , fk are proper convex functions on Rn. If 
First-order necessary and sufficient optimality conditions for con- 
vex programs can be stated as follows. 
Theorem 1.5. (See Rockafellar (1970), Theorem 27.4) Suppose that 
f is a proper convex function on Rn and A C Rn is a nonempty 
convex set. If the inclusion 
holds for some 2 E Rn, then 3 is a solution of (P). Conversely, if 
then (1.14) is a necessary and suficient condition for 3 l: Rn to be 
a solution of (P). In particular, if A = Rn then 3 is a solution of 
(P) if and only i f 0  E af(3). 
Inclusion (1.14) means that there exist x* E df(2) and u* E 
NA(z) such that 0 = x* + u*. Note that (1.15) is a regularity 
condition for convex programs of the type (P). 
The facts stated in Proposition 1.1 and Theorem 1.5 are the 
most characteristic properties of convex mathematical programming 
problems. 
Theorem 1.5 can be used for solving effectively many convex 
programs. For illustration, let us consider the following example. 
Example 1.3. (The Fermat point) Let A, B, C be three points 
in the two-dimensional space R2 with the coordinates 
respectively. Assume that there exists no straight line containing all 
the three points. The problem consists of finding a point M in R2 

1.2 Convex Programs and Nonconvex Programs 
9 
with the coordinates z = (zl, 
3 2 )  such that the sum of the distances 
from M to A, B and C is minimal. This amounts to saying that 3 
is a solution of the following unconstrained convex program: 
In Lemma 1.1 below it will be proved that problem (1.16) has solu- 
tions and the solution set is a singleton. Note that f = fi + f2 + f3, 
where f i b )  = IIx - all, f 2 ( 4  = llx - bll, f 3 ( 4  = 115 - 41. BY 
Theorem 1.5, Z is a solution of (1.16) if and only if 0 E d f (3). As 
dom fi = R2 (i = 1,2,3), using Theorem 1.4 we can write the last 
inclusion in the following equivalent form 
We first consider the case where 3 coincides with one of the three 
vectors a, b, c. Let Z = a, i.e. M r A. In this case, 
a - b  
a - c  
~
3
)
 
= on., af2(z) = 
, ah(?) = 
} 
a - bll 
a - cll 
Hence (1.17) is equivalent to saying that there exists u* E BR2 such 
that 
0 = U* -v* - w*, 
(1.18) 
where v* := (b - a)/llb - all, w* := (c - a)/llc - all. From (1.18) it 
follows that 
1 2  1 1 ~ * 1 1 ~  = (u*,u*) 
= (v* + w*, v* + w*) 
= 
+ I
I
w
*
~
~
~
 + 2(v*, w*). 
1 
As 11v*11 = 1 and IIw*ll = 1, this yields (v*, w*) < --. Denoting by 
2 
a the geometric angle between the vectors v* and w* (which is equal 
to angle A of the triangle ABC), we deduce from the last inequality 
that 
Hence 
COS Q = (v*, w*) 
1 
= (v*,w*) < --. 
Ilv* 1 1  IIw* I l  
2 
(The case a = T is excluded because there exists no straight line 
containing A, B and C.) It is easy to show that (1.19) implies that 

10 
1. Quadratic Programming Problems 
? := v* + w* belongs to ~
~
2
.
 
Thus (1.19) is equivalent to (1.17). 
This means that (1.19) holds if and only if Z = a is a solution of 
(1.16). 
We now turn to the case where 5 # a, 3 # b and 3 # c, i.e. M 
does not coincide with anyone from the three vertexes A, B, C of 
the triangle ABC. In this case, as 
= { ' 
- a } , af2(i) = { '- } , af3(z) = { '- } , 
11% - all 
11% - bll 
llZ - cll 
(1.17) is equivalent to the equality 
where U* := (a - Z)/lla - 311, v* := (b - Z)/llb - 311 and w* := 
(C - Z)/[[C - 311. By (1.20), 
1 
Since 11v*11 = 1 and IIw*ll = 1, this implies that (v*,w*) = --. 2 
Hence the geometric angle a between v* and w* is 2 ~ 1 3 .  Similarly, 
we deduce from (1.20) that the geometric angle ,B (resp., y) between 
U* and w* (resp., between u* and v*) is equal to 2x13. (Geometri- 
cally, we have shown that M sees the edges BC, AC and AB of the 
triangle ABC under the same angle 120°.) It is easily seen that if 
then (1.20) is satisfied; hence (1.17) is valid and 5 is a solution of 
(1.16). 
Summarizing all the above in the language of Euclidean Geom- 
etry, we have the following conclusions: 
(i) If one of the three angles of the triangle ABC, say A, 
is larger 
than or equal to 120°, then M r A is the unique solution of 
our problem. 
(ii) If all the three angles of the triangle ABC are smaller than 
120°, then the unique solution of our problem is the point 
M seeing the edges BC, AC and AB of the triangle ABC 

1.2 Convex Programs and Nonconvex Programs 
11 
under the same angle 120". (This special point M is called 
the Fermat point or the Torricelli point (see Weisstein (1999)). 
It can be proved that the Fermat point belongs to the interior 
of the triangle ABC.) 
If the necessary and sufficient optimality condition stated in 
Theorem 1.5 yields a unique point Z which can be expressed explic- 
itly via the data of the optimization problem (see, for instance, the 
situation in Example 1.6 below) then the problem has solutions and 
the solution set is a singleton. In the other case, information about 
the solution existence and uniqueness can be obtained by analyzing 
furthermore the structure of the problem under consideration. 
For the illustrative problem described in Example 1.3, the fol- 
lowing statement is valid. 
Lemma 1.1. Let a = (al, a2), b = (bl , b2), c = (cl , c2) be given 
points in R2 such that there exists no straight line containing all the 
three points. Then problem (1.16) has solutions and the solution set 
is a singleton. 
Proof. In order to show that (1.16) has solutions, we observe that 
Therefore 
lim f (x) = +m. Fix any z E R2 and put y = f (2). 
II+++~ 
Let Q E [11z11, +oo) be such that 
f(x) > y for every x E R~ \ B(o,Q). 
By the Weierstrass Theorem, the restriction of the continuous func- 
tion f (x) on the compact set ~ ( 0 ,  
Q) achieves minimum at some 
point J: E ~ ( 0 ,  
Q) , that is f (2) 5 f (y) for every y E B(O, Q). Since 
f ( ~ )  
5 f(x) = r <  
f(x) for all xZ:E R ~ \ B ( o , Q ) ,  
it follows that Z is a solution of (1.16). 
We now prove that f(x) is a strictly convex function, that is 
for all x, y in R2 with x # y and for all t E (0,l). Given any 
x = (x1,x2), y = (y1,y2) in R2 with x # y and t E (0,1), we 
consider the following vector systems 
{x - a, y - a), 
{x - b, y - b), 
{ x  - c, y - c). 
(1.21) 

12 
1. Quadratic Programming Problems 
We claim that at least one of the three systems is linearly indepen- 
dent. Suppose the claim were false. Then we would have 
det ( x l  - 
y1 - 
= 0, det ( 
X l  - bl 
Yl - bl 
2 2  - a2 
Y2 - a2 
2 2  - b2 
Y2 - b2 
det ( x1-Cl 
Y1-Cl 
X 2 - C 2  
Y2-C2 
where det Z denotes the determinant of a square matrix 2. These 
equalities imply that 
Since x # y, we have (xl - y1)2 + (x2 - y2)2 # 0. SO the set 
is a straight line in R2. By (1.22), L contains all the points a ,  b, c. 
This contradicts our assumption. We have thus proved that at least 
one of the three vector systems in (1.21) is linearly independent. 
Without loss of generality, we can assume that the system {x-a, y- 
a )  is linearly independent. Then the system {t(x- a ) ,  ( 1  - t ) ( y  - a ) )  
is also linearly independent. This implies that 
So we have 
The strict convexity of f has been established. From this property it 
follows immediately that (1.16) cannot have more than one solution. 

1.2 Convex Programs and Nonconvex Programs 
13 
Indeed, if there were two different solutions x and y of the problem, 
then by the strict convexity of f we would have 
This contradicts the fact that x is a solution of (1.16). The proof 
of the lemma is complete. 
0 
Remark 1.5. It follows from the above results that (1.16) admits 
a unique solution belonging to the convex hull of the set {a, b, c). 
Hence (1.16) is equivalent to the following constrained convex pro- 
gram 
min{llx - all + IIx - bll + IIx - c I I  
: x E co{a, b, c)). 
In problem (P), if A is the solution set of a system of inequalities 
and equalities then first-order optimality conditions can be written 
in a form involving some Lagrange multipliers. 
Let us consider problem (P) under the assumptions that f : 
Rn + R is a convex function and 
where gi : Rn + R for i = 1,. . . , m is a convex function, hj : 
Rn --i 
R for j = 1,. . . , s is an afine function, i.e. there exist 
a j  E Rn and aj E R such that hj(x) = (aj, x) + aj for every 
x E Rn. It is admitted that the equality constraints (resp., the 
equality constraints) can be absent in (1.23). For abbreviation, we 
use the formal writing m = 0 (resp., s = 0) to indicate that all the 
inequality constraints (resp., all the equality constraints) in (1.23) 
are absent. 
Theorem 1.6. (Kuhn-Tucker Theorem for convex programs; see 
Rockafellar (1970), p. 283) Let (P) be a convex program where A is 
given by (1.23). Let the above assumptions on f, gi (i = 1,. . . , m )  
and hj (j = 1 , .  . . s) be satisfied. Assume that there exists a vector 
z E Rn such that 
gi(z) < O  for i =  1 ,..., m 
and hj(z) = O  for j =  1 ,..., s. 
(1.24) 
Then 3 is a solution of (P) if and only if there exist m +  s real num- 
bers X I , .  . . , A,, 
p1,. . . , p,, which are called the Langrange multipli- 
ers corresponding to 3, such that the following Kuhn-Tucker condi- 
tions are fulfilled: 

14 
1. Quadratic Programming Problems 
(a) Xi 2 0, gi(z) 5 0 and Xifi(%) = 0 fori = 1 ,... ,m, 
(b) hj(.) 
= 0 f o r j  = 1,. . . ,s, 
(c) O E a f (3) + CE1 Xiagi(3) + C;=, p j a j  
Note that (1.24) is a constraint qualification for convex pro- 
grams. If s = 0 then it becomes 
32 E Rn s.t. gi(x) < 0 for i = 1,. . . , m. (The Slater condition) 
If m = 0 then (1.24) is equivalent to the requirement that A is 
nonempty. Actually, in that case condition (1.24) can be omitted 
in the formulation of Theorem 1.6. 
1.3 Smooth Programs and Nonsmooth 
Programs 
For brevity, if f : Rn -+ R is a continuously Frhchet differentiable 
function then we shall say that f is a C1-function. Similarly, if f is 
twice continuously Fr6chet differentiable function then we shall say 
that f is a C2-function. The vector 
where - 
af 
for i = 1,. . . , n denotes the partial derivative of f at 
ax; 
3 with respect to xi, is called the gradient of f at Z. The matrix 
a2f ('I denotes the second-order partial derivative of f at 
where - 
axidxi 
3 w.r.t. kj and xi, is called the Hessian matrix of f at 3. It is 

1.3 Smooth Programs and Nonsmooth Programs 
15 
well-known that if f is a C1-function on Rn then f is directionally 
differentiable on Rn (see Definition 1.8) and 
for every J: E Rn and v = (vl, . . . , v,) E Rn. 
Definition 1.12. We say that (P) is a smooth program (a smooth 
mathematical programming problem) iff : Rn -+ R is a C1-function 
and A can be represented in the form (1.23) where gi : Rn -+ R 
(i = 1,. . . , m) and hj : Rn -t R ( j  = 1,. . . , s) are C1-functions. 
Otherwise, (P) is called a nonsmooth program. 
We have considered problem (1.16) of finding the Fermat point. 
It is an example of nonsmooth programs. Function f(x) in (1.16) 
is not a C1-function. However, it is a Lipschitz function because 
Definition 1.13. A function f : Rn -+ R is said to be a locally 
Lipschitz near f E Rn if there exist a constant ! 
2 0 and a neigh- 
borhood U of 3 such that 
I f(xl) - f(x)l 5 ![[XI - $11 
for all x, XI in U 
If f is locally Lipschitz near every point in Rn then f is said to 
be a locally Lipschitz function on Rn. If f is locally Lipschitz near 
5 then the generalized directional derivative of f at Z in direction 
v E Rn is defined by 
f0(3;v) := limsup f (3 + tv) - f (4) 
x+Z, tL0 
t 
= sup{( E R : 3 sequences xk -+ 3 and tk --+ O+ 
such that ( = lim f (xk + t k ~ )  - f ( ~ k )  
k++w 
tk 
1. 
The Clarke generalized gradient of f at n: is given by 
af(z) := {x* E Rn : fO(?;v) > (x*,v) for all v E Rn). 
Theorem 1.7. (See Clarke (1983), Propositions 2.1.2, 2.2.4, 2.2.6 
and 2.2.7) Let f : Rn -t R be a real function. Then the following 
assertions hold: 

16 
1. Quadratic Programming Problems 
(a) I f f  is locally Lipschitz near 5 E Rn then 
for every v E Rn 
(b) I f f  is a C1-function then f is a locally Lipschitz function and 
af(3) = { o f ( ? ) ) ,  fO(%;v) = ( V f ( ~ ) , v )  
for all 5 E Rn and 
v E Rn. 
(c) If f is convex then f is a locally Lipschitz function and, for 
every 5 E Rn, the Clarke generalized gradient 8 f (5) coincides 
with the subdiflerential of f at 5 defined by formula (1.13). 
Besides, f ' ( 5 ;  v )  = f '(5; v )  for every v E Rn. 
As concerning the above assertion (c), we note that the direc- 
tional derivative f'(5; v )  exists according to Theorem 1.2. 
Definition 1.14. Let C c Rn be a nonempty subset. The Clarke 
tangent cone Tc(x) to C at x E C is the set of all v E Rn satisfying 
d:(x;v) = 0, where d;(x;v) denotes the generalized directional 
derivative of the Lipschitzian function dc(z) := inf { 11 y - 211 : y E 
C )  at x in direction v. The Clarke normal cone Nc(x) t o  C at x is 
defined as the dual cone of Tc(x), i.e. 
Nc(x) = {x* E Rn : (x* , v) 5 0 for all v E Tc(x)). 
Theorem 1.8. (See Clarke (1983), Propositions 2.4.3, 2.4.4 and 
2.4.5) For any nonempty subset C C Rn and any point x E C, the 
following assertions hold: 
( b )  If C is convex then Nc(x) coincides with the normal cone to C 
at x defined by formula (1.12), and Tc(x) coincides with the 
topological closure of the set cone(C - x )  := {tz : t > 0, z E 
c - x}. 
(c) The inclusion v E Tc(x) is valid if and only if, for every se- 
quence xk in C converging to x and sequence tk in (0, +oo) 
converging to 0, there exists a sequence vk in Rn converging 
to v such that xk + tkvk E C for all k .  

1.3 Smooth Programs and Nonsmooth Programs 
17 
We now consider problem ( P )  under the assumptions that f : 
Rn --t R is a locally Lipschitz function and 
where C c Rn is a nonempty subset, gi : Rn --t R (i = 1,. . . , m) 
and h j  : Rn -+ R ( j  = 1 , . . . , s )  are locally Lipschitz functions. 
Theorem 1.9. (See Clarke (1983), Theorem 6.1.1 and Remark 
6.1.2) If 3 is a local solution of ( P )  then there exist m + s + 1 real 
numbers Xo 2 0, X 1  2 0,. . . ,Am 2 0, p l , .  . . ,p,, not all zero, such 
that 
and 
Xigi(3)=0 forall i = 1 , 2  ,..., m. 
(1.27) 
The preceding theorem expresses the first-order necessary opti- 
mality condition for a class of nonsmooth programs in the Fritz- John 
form. Under some suitable constraint qualifications, the multiplier 
Xo corresponding to the objective function f is positive. In that 
case, dividing both sides of the inclusion in (1.26) and the equalities 
- 
in (1.27) by Xo and setting Xi = X i / X o  for i = 1,. . . ,m, Pj = pj/Xo 
for j = 1,. . . ,s, we obtain 
and 
- 
Xigi(3) = 0 for all i = 1,2 ,..., m. 
(1.29) 
Similarly as in the case of convex programs (see Theorem 1.6), if 
- 
(1.28) and (1.29) are fulfilled then the numbers x1 2 0, . . . , Am 2 
0, P1 E R, . . . , jYs E R are called the Lagrange multipliers corre- 
sponding to 3. 
It is a simple matter to obtain the following two Lagrange mul- 
tiplier rules from Theorem 1.9. (See Clarke (1983), pp. 234-236). 

18 
1. Quadratic Programming Problems 
Corollary 1.1. If 3 is a local solution of ( P )  and if the constraint 
qualiification 
[o E Czl Xidgi (3) + Cg=l pjdhj (3) + N c ( 2 )  
A 1 2 0  ,..., X m 2 0 ,  p 1 E R  ,..., p , E R ;  
Xigi(5) = 0 for i = 1,. . . ' ml 
X 1 =  . . . =  X m = O ,  
p l =  . . . = p s =  01 
[ 
holds, then there exist Lagrange multipliers X I  2 0 , .  . . , Am 2 0, p1 E 
R, . . . , p, E R such that Xigi(3) = 0 for i = 1,2,. . . , m, and 
Corollary 1.2. Assume that 3 is a local solution of a smooth 
program ( P )  where A is given by formula (1.23). If the following 
Mangasarian-Fromovitz constraint qualification 
The vectors { V h j ( 2 )  : j = 1,. . . , s )  are linearly independent, 
and there exists v E Rn such that ( V h j ( 3 ) ,  v) = 0 
for j = 1,. . . , S ,  and (Vgi(3), v) < 0 
for every i = 1, . . . , m satisfying gi(3) = 0 
is satisfied, then there exist Lagrange multipliers X 1  2 0,. . . , A, 2 
0, p1 E R,. . . ,,us E R such that Xigi(5) = 0 for i = 1,2,. . . ,m, and 
From Theorem 1.9 we can derive the basic Lagrange multiplier 
rule for convex programs stated in Theorem 1.6. Indeed, sup- 
pose that the assumptions of Theorem 1.6 are satisfied and 3 is 
a solution of ( P ) .  Consider separately the following two cases: 
(i) The vectors {aj : j = 1,. . . , s )  are linearly independent; 
(ii) The vectors {aj : j = 1, . . . , s )  are linearly dependent. In 
the first case, Theorem 1.9 shows that there exist real numbers 
Xo 2 0, X 1  2 0 , .  . . ,Am 2 0, P I , .  . . , p s ,  not all zero, such that 
(1.26) and (1.27) are satisfied. Condition (1.24) forces Xo > 0. 
Hence there exist Lagrange multipliers satisfying the Kuhn-Tucker 
conditions. In the second case, when aj = 0 for j = 1,. . . , s, we 

1.4 Linear Programs and Nonlinear Programs 
19 
can obtain the desired result; when aj # 0 for some j = 1,. . . , s, we 
choose a maximal linearly independent subsystem, say {al, . . . , ak), 
of the vector system {al,. . . , a,). Then we consider the problem 
min{f(x) : gl(x) 
0,. . . ,gm(x) < 0, hl(x) = 0,. . . , hk(x) = 0). 
(1.30) 
It is easy to show that the constraint set of this problem coincides 
with A. Hence % is a solution of (1.30). Applying Theorem 1.9 
to problem (1.30) and using condition (1.24) we can find a set of 
Lagrange multipliers satisfying the Kuhn-Tucker conditions. 
1.4 Linear Programs and Nonlinear Pro- 
grams 
Definition 1.15. A subset A c Rn is called a polyhedral convex set 
if A can be represented as the intersection of finitely many closed 
half spaces of Rn; that is, there exist nonzero vectors al, . . . ,am E 
Rn and real numbers Dl, . . . , Dm such that 
A = {x E Rn : (ai, x) 2 pi for i = 1,. . . , m). 
(1.31) 
In other words, A is the solution set of a system of finitely many lin- 
ear inequalities. (We admit that the intersection any empty family 
of closed half spaces of Rn is Rn. Hence A = Rn is also a polyhe- 
dral convex set.) A point x E A is called an extreme point of A if 
there is no way to express x in the form x = ty + (1 - t)z where 
y E A, z E A, y # z, and t E (0,l). The set of all the extreme 
points of A is denoted by extrA. 
Let A be the m x n-matrix with the elements aij (i = 1,. . . , m, 
j = 1, . . . , n), where aij stands for the j-th component of ai. Set 
b = (Dl,. . . ,Dm) E Rm. Then (1.31) can be rewritten as 
A = {x E Rn : Ax 2 b). 
Here and subsequently, for any two vectors y = (yl, . . . , y,) 
E Rm 
and z = (21,. . . , z,) 
E Rm, we write y > z if yi > zi for all 
i = 1,. . . , m. We shall write y > z if yi > xi for all i = 1,. . . ,m. 
Since 

20 
1. Quadratic Programming Problems 
it follows that {x E Rn : Ax = b) is a polyhedral convex set. 
Definition 1.16. Problem (P) is called a linear program (a linear 
programming problem) if f is an affine function and A is a polyhe- 
dral convex set. Otherwise, (P) is said to be a nonlinear program. 
There are three typical forms for describing linear programs 
min{f(x) = (c,x) : x E Rn, Ax 2 b), 
min{f(x)=(c,x) : x c R n ,  Ax=b, xLO), 
min{f (x) = (c, x) : x E Rn, Ax 2 b, Cx = d) 
which are called the standard form, the canonical form and the 
general form, respectively. Here A E RmXn, C E RSXn are given 
matrices, c E Rn, b E Rm and d E RS are given vectors. 
Example 1.4. Consider the following linear program of the stan- 
dard form: 
It is easy to check that Sol(P) = {(0,1)). Note that the constraint 
set 
A = {X E R~ : XI + x2 2 1, XI 2 0, x2 2 0) 
has two extreme points, namely extrA = {(I, O), (0,l)). One of 
these points is the solution of our problem. 
Definition 1.17. The dual problems of linear programs of the stan- 
dard, canonical and general forms, respectively, are the following 
linear programs: 
max{(b, y) : y E Rm, ATy = c, y 2 01, 
max{(b, y) : y E Rm, ATy 5 c), 
max{(b, y) + (d, z) : (y, z) E Rm x RS, ATy + CTz = C, y 2 0). 
Of course, linear programs are convex mathematical program- 
ming problems. Hence they enjoy all the properties of the class of 
convex programs. Besides, linear programs have many other special 
properties. 
Theorem 1.10. (See Dantzig (1963)) Let (P) be a linear program 
in one of the three typical forms. The following properties hold true: 
(i) If the constraint set is nonempty and if v(P) > -00, then 
Sol(P) is a nonempty polyhedral convex set. 

1.5 Quadratic Programs 
21 
(ii) If both the sets extrA and Sol(P) are nonempty, then the in- 
tersection extrA n Sol(P) is also nonempty. 
(iii) If rankA = n and the set A := {x E Rn : Ax = b, x 2 0 )  is 
nonernpty, then A must have an extreme point. 
(iv) The optimal value v(P) of (P) and the optimal value v(Pf) 
of the dual problem (Pf) of (P) are equal, provided that the 
constraint set of at least one of these problems is nonempty. 
Note that the five problems considered in Remarks 1.2, 1.4 and 
Examples 1.1-1.3 are all nonlinear. 
We now consider one important class of nonlinear programs, 
which contains the class of linear programs as a special subclass. 
1.5 Quadratic Programs 
Definition 1.18. We say that f : Rn t R is a linear-quadratic 
function if there exist a matrix D E Rnxn, a vector c E Rn and a 
real number a such that 
1 
f(x) = -X*DX + z x  + a 
1 
(1.32) 
= -(x, Dx) + (c,x) + a  
2 
for all x E Rn. 
If 
then (1.32) means that 
f (x) = I (x x 
dijxixj) + 
qxi + a. 
j=l i=1 
i=l 
1 
Since xTDx = - x T ( ~  + D ~ ) X  for every x E Rn, representation 
2 
1 
(1.32) remains valid if we replace D by the symmetric matrix -(D+ 
2 
D ~ ) .  For this reason, we will assume that the square matrix in 

22 
1. Quadratic Programming Problems 
the representation of a linear-quadratic function is symmetric. The 
space of the symmetric n x n-matrices will be denoted by RgXn. 
Definition 1.19. Problem (P) is called a linear-quadratic mathe- 
matical programming problem (or a quadratic program, for brevity) 
if f is a linear-quadratic function and A is a polyhedral convex set. 
In (1.32), if D is the zero matrix then f is an affine func- 
tion. Thus the class of linear programs is a subclass of the class 
of quadratic programs. In general, quadratic programs are noncon- 
vex mathematical programming problems. 
Example 1.5. The following quadratic program is nonconvex: 
It is obvious that f is a nonconvex function. One can verify that 
Sol(P) = {(1,3)) and v(P) = -8. 
It is clear that if we delete the constant a in the representation 
(1.32) of f then we do not change the solution set of the problem 
min{ f (x) : x t A), where A c Rn is a polyhedral convex set. 
Therefore, instead of (1.32) we will usually use the simplified form 
1 1 
f (x) = -xTDx + cTx of the objective function. 
2 
Modifying the terminology used for linear programs, we call the 
following forms of quadratic programs 
1 
- I ~ D X + ~ X  : x t Rn, Ax 2 b}, 
2 
1 
-xTDx + cTx : x E Rn, Ax 2 b, 
x 2 0) , 
2 
1 
-xTDx + cTx : x E Rn, Ax 2 b, Cx = d 
2 
the standard form, the canonical form and the general form, re- 
spectively. (The meaning of A, C, b and d is the same as in the 
description of the typical forms of linear programs.) Note that the 
representation of the constraint set of canonical quadratic programs 
is slightly different from that of canonical linear programs. The 
above definition of canonical quadratic programs is adopted because 
quadratic programs of this type have a very tight connection with 
linear complementarity problems (see, for instance, Murty (1976) 
and Cottle et al. (1992)). In Chapter 5 we will clarify this point. 
The relation between the general quadratic programs and afme 
variational inequalities will be studied in the same chapter. 

1.5 Quadratic Programs 
23 
Definition 1.20. A matrix D E Rnxn is said to be positive definite 
(resp., negative definite) if vTDv > 0 (resp., vTDv < 0) for every 
v E Rn \ (0). If vTDv 2 0 (resp., vTDv < 0) for every v E Rn then 
D is said to be positive semidefinite (resp., negative semidefinite). 
1 
Proposition 1.2. Let f (x) = -xTDx + cTx + Q where D E 
2 
RgXn, c E Rn and Q E R. If D is a positive semidefinite matrix, 
then f is a convex function. 
Proof. Since x H irx + a is a convex function and the sum of 
two convex functions is a convex function, it suffices to show that 
r ,  
fl(x) := XI Dx is a convex function. As D is a positive semidefinite 
matrix, for every u E Rn and v E Rn we have 
This implies that 
vTDv < uT DU - 2vT D(U - v). 
(1.33) 
Given any x E Rn, y E Rn and t E (0, I), we set z = tx + (1 - t)y. 
Taking account of (1.33) we have 
xTDz < yTDY - 2zTD(y - x), 
zTDx I 
xTDx - 2zTD(x - 2). 
Since y - z = t(y - x) and x - z = (1 - t)(x - y), from the last two 
inequalities we deduce that 
hence 
Thus fl is a convex function. 
If D is negative semidefinite, then the function f given by (1.32) 
is concave, i.e. 
for every x E Rn, y E Rn and t E (0,l). In the case where matrix 
D is neither assumed to be positive semidefinite nor assumed to 

24 
1. Quadratic Programming Problems 
1 
be negative semidefinite, we say that f (x) = - x T ~ x  + cTx, where 
2 
c E Rn, is an indefinite linear-quadratic function. Quadratic pro- 
gramming problems with indefinite linear-quadratic objective func- 
tions are called indefinite quadratic programs. 
Remark 1.6. It is clear that if f is given by (1.32), where D E 
RzXn, then V2 f (x) = D for every x E Rn. Therefore, the fact stated 
in Proposition 1.2 is a direct consequence of the following theorem 
(see Rockafellar (1970), Theorem 4.5): "If f : Rn + R is a C2- 
function and if the Hessian matrix V2 f (x) is positive semidefinite 
for every x E Rn, then f is a convex function." 
By using Proposition 1.2 one can verify whether a given quadratic 
program is convex or not. 
Let us consider a simple example of convex quadratic programs. 
Example 1.6. Given k points all a2, . . . , ak in Rn, we want to 
find a point x E Rn at which the sum 
attains its minimal value. Observe that 
is a convex linear-quadratic function. By Theorem 1.5, 5 is a solu- 
tion of our problem if and only if V f (5) = 0. Since 
one can write the condition 0 = V f (3) equivalently as 
1 
k 
Thus 3 = - Eni is the 
k a=1 
cia1 point 3 is called the 
unique solution of our problem. That spe- 
barycenter of the system {al, az, . . . , ak). 

1.5 Quadratic Programs 
25 
Observe that there is a simple algorithm for constructing the barycen- 
1 
1 
ter. Namely, first we define zl = l a l  + l a 2 .  Then we put 
2 
2 
By induction it is not difficult to show that 5 := zk-l is the barycen- 
ter of the system {al, a2, . . . , ak}. For performing a sequential 
construction of the barycenter of a system of points in R2, it is con- 
venient to use the following equivalent vector form of the formula 
defining zi: 
1 
z Z = -  + "-la: 
(for every i 2 2). 
The following geometrical example leads to a (nonconvex) qua- 
dratic program of the general form. 
Example 1.7. Let A = {x E Rn : Ax 2 b, Cx = d}, where 
A E Rmxn, C E RSXn, b E Rm and d E RS. (The equality Cx = d 
can be absent in that formula. Likewise, the inequality Ax 2 b - 
can 
be absent too.) Let ai (i = 1,. . . , n), Zi (i = 1,. . . , n), ,8 and ,8 be 
a family of 2n + 2 real numbers satisfying the conditions 
and 
- 
n 
M = { X E  Rn : x ~ i x i + p = 0 }  
i=l 
are two hyperplanes in Rn. The task is to find x E A 
function 
f (x) = (dist(x, M ) ) ~  
- (dist(x, G))2, 
(1.34) 
such that the 
where dist(x, 0) = inf{llx - zll : z E fl} is the distance from x to a 
subset R c Rn, achieves its minimum. We have 

26 
1. Quadratic Programming Problems 
In order to prove this formula we consider the following convex 
program 
min{cp(z) = 112 - z1I2 : z E M). 
(1.36) 
By Theorem 1.6, 2 = (zl, . . . ,Zn) E M is a solution of (1.36) if and 
only if there exists p E R such that 
0 E acp(z) + &l,. . . , a,). 
Since dcp(2) = {Vcp(~)) = {-2(x - z)), this inclusion is valid if and 
only if 
2(x - 2) = p(al,. . . ,an). 
P 
This implies 2 = x - -a, where a := (al,. . .an). As 2 E M, we 
2 
must have 
Taking account of (1.34), we obtain p = 2((a, x) + P). Therefore 
hence (1.35) holds. Similarly, 
Consequently, 
From this we conclude that f (x) is a linear-quadratic function; so 
the optimization problem under consideration is a quadratic pro- 
gram of the general form. 
It is easy to verify that if we choose 

1.6 Commentaries 
- 
a =  ( l , O ) ,  
P=O, 
6=(0,1), p = 0 ,  
then the preceding problem, where the equation Cx = d is absent, 
becomes the one discussed in Example 1.5. - In this case, we have 
M = {X = ( ~ 1 ~ x 2 )  
: XI = 0, 2 2  E R), M = {x = (x1,x2) : XI E 
- 
R, x2 = 0), dist(x,M) = Ixl/ and dist(x, dl) = Ix21. 
1.6 Commentaries 
Mathematical Programming is one important branch of Optimiza- 
tion Theory. Other branches with many interesting problems and 
results are known under the names The Calculus of Variations and 
Optimal Control Theory. Of course, the informal division of Opti- 
mization Theory into such branches is only for convenience. In fact, 
research problems and methods of the three branches are actively 
interacted. The classical work of Ioffe and Tihomirov (1979) is an 
excellent textbook addressing all the three branches of Optimization 
Theory. 
Convex Analysis and Convex Programming theory can be stud- 
ied by using the books of Rockafellar (1970) and of Ioffe and Ti- 
homirov (1979). The book of Mangasarian (1969) gives a nice in- 
troductory course to Mathematical Programming. 
Linear Programming can be learned by using the books of Dant- 
zig (1963)) Murty (1976), and many other nice books. 
Nonsmooth Analysis and Nonsmooth Optimization can be lear- 
ned by the books of Clarke (1983), Rockafellar and Wets (1998), 
and many other excellent books. In addition to these books, one 
can study Mordukhovich (1988, 1993, 1994) to be familiar with a 
powerful approach to Nonsmooth Analysis and Nonsmooth Opti- 
mization which has been developed intensively in recent years. 
Some theoretical results on (Nonconvex) Quadratic Program- 
ming are available in the books of Murty (l976), Bank et al. (l982), 
Cottle et al. (1992), and other books. The next three chapters 
of this book are intended to cover the basic facts on (Nonconvex) 
Quadratic Programming, such as the solution existence, necessary 
and sufficient optimality conditions, and structure of the solution 
sets. Eight other chapters (Chapters 10-17) establish various results 
on stability and sensitivity of parametric quadratic programs. 
The geometric problem described in Example 1.3 is called Fer- 
mat's problem or Steiner's problem. It was proposed by Fermat to 

28 
1. Quadratic Programming Problems 
Torricelli. Torricelli's solution was published in 1659 by his pupil 
Viviani (see Weisstein (1999), p. 623). 

Chapter 2 
Existence Theorems for 
Quadratic Programs 
In this chapter we shall discuss the Frank-Wolfe Theorem and the 
Eaves Theorem, which are two fundamental existence theorems for 
quadratic programming problems. 
2.1 The Frank-Wolfe Theorem 
Consider a quadratic program of the standard form 
1 
Minimize j(x) := -X*DX + cTx 
2 
subject to x E Rn, Ax 2 b, 
where D E RzXn, A E Rmxn, c E Rn and b E Rm. For the con- 
straint set. and the optimal value of (2.1) we shall use the following 
abbreviations: 
A(A, 
- 
b) = {x E Rn : Ax 2 b), 
0 = inf{j(x) : x E A(A, b)). 
If A(A, b) = 0 then 8 = +oo by convention. If A(A, b) # 0 then 
there are two situations: (i) 0 E R, (ii) 8 = -m. If (ii) occurs 
then, surely, (2.1) has no solutions. It is natural to ask: Whether 
the problem always has solutions when (i) occurs? 
Note that optimization problems with non-quadratic objective 
functions may have no solutions even in the case the optimal value 
is finite. For example, the problem min 

30 
2. Existence Theorems for Quadratic Programs 
solutions, while the optimal value 8 = inf - : x E R, x 2 1 = 0 
is finite. 
i: 
1 
The following result was published by Frank and Wolfe in 1956. 
Theorem 2.1. (The Frank-Wolfe Theorem; See Frank and Wolfe 
(1956), p. 108) If $ = inf{ f (x) : x E A(A, b)) is a finite real 
number then problem (2.1) has a solution. 
Proof. We shall follow the analytical proof proposed by Blum and 
Oettli (1972). The assumption 
E R implies that A(A, b) # 8. 
Select a point x0 E A(A, b). Let p > 0 be given arbitrarily. Define 
A, = A(A, b) n B(xO, p). 
Note that A, is a convex, nonempty, compact set. Consider the 
following problem 
min{f(x) : x E A,). 
(2.2) 
By the Weierstrass Theorem, there exists some y E A, such that 
f (y) = q, := min{ f (x) : x E A,). Since the solution set of (2.2) is 
nonempty and compact, there exists y, E A, such that 
We claim that there exists ,i? 
> 0 such that 
Indeed, if the claim were false then we would find an increasing 
sequence pk 4 +m such that for every k there exists y,, 
E A,, 
such that 
f(yPk)=qpk, l l ~ p ~ - ~ O l l = ~ k .  
(2.4) 
For simplicity of notation, we write yqnstead of y,,. 
Since yk E 
A(A, b), we must have Aiy" 
bi for i = 1,. . . , m, where Ai denotes 
the i-th row of A and bi denotes the i-th component of b. 
For 
i = 1, since the sequence {Alyk) is bounded below, one can choose 
a subsequence {k') c {Ic) such that lim A~ZJ" exists. (It may 
kl+w 
happen that lim ~ ~ y ' " '  
= +oo.) Without restriction of generality 
kl+w 
we can assume that {k') = {k), that is the sequence {Alyk) itself 
is convergent. Similarly, for i = 2 there exists a subsequence {k') c 
{k) such that lim A~~~~ exists. Without loss of generality we can 
kl+w 

2.1 The Frank- Wolfe Theorem 
31 
assume that {kt) - {k). Continue the process until i = m to find 
a subsequence {kt) c {k) such that all the limits 
lirn A
~
~
~
'
 
(i = 1, . . . , m) 
k'+w 
exist. For simplicity of notation, we will assume that {kt) - {k). 
Let I = (1 ,..., m}, I. = {i E I : lirn 
bi) and 
k+oo 
II = I\Io = {i E I : lirn 
> bi). 
k+oo 
Of course, there exists e > 0 such that 
lim ~ i y ' "  
2 bi + E 
for every i E Il. 
k+oo 
By (2.4), 11 (yL xO)lpk 
11 = 1 for every k. Since the unit sphere in 
Rn is a compact set, there is no loss of generality in assuming that 
the sequence 
{y'} 
converges to some 5 E Rn as k -+ 
oo. Clearly, 1 1 ~ 1 1  = 1. AS 
PIC + +oo, for every i E lo we have 
k 
0 = lim (Ai - bi) 
k+m 
AixO - bi 
+ jil( 
pk ) = Ai5. 
Similarly, for every i E II we have 
= lirn inf 
k+m 
+ 
k'oo 
Therefore 
Ar5 = 0 for every i E lo, A$ > 0 for every i E 11. 
(2.5) 
From this we can conclude that 5 is a direction of recession of the 
polyhedral convex set A(A, b). Recall (Rockafellar (1970), p. 61) 

32 
2. Existence Theorems for Quadratic Programs 
that a nonzero vector v E Rn is said to be a direction of recession 
of a nonempty convex set R C Rn if 
x + tv E R for every t > 0 and x E fl. 
Recall also that the set composed by 0 E Rn and all the directions 
v E Rn satisfying the last condition, is called the recession cone of 
S2. In our case, from (2.5) we deduce immediately that 
y+ttv E A(A,b) for every t > 0 and y E A(A,b). 
(2.6) 
Since 
f (Yk) = f ( Y P d  = qp, 
= min{f(x) : x E AP,} 
= min{f (x) : x E A(A, b) n ~(x0,pk)) 
and the increasing sequence {pk} converges to +GO, we see that the 
sequence { f (yk)} is non-increasing and f (yk) -+ 8. Consequently, 
for k sufficiently large, we have 
Using the formula of f we can rewrite these inequalities as follows 
Dividing these expressions by pi and taking the limits as k -t oo, 
we get 0 < ltvTDtv < 0. Hence 
2 
yk + ttv E A(A, b) 
for every t > 0 and k E N, 
where N stands for the set of the positive integers. On account of 
(2.7), we have 
1 
T
k
 
f (yk + t g  = -(y% tqTD(y% ttv) + c (y + tv) 
? 
= 5 ( ~ k ) T ~ ~ %  
cTyk + t ( ( ~ ~ ) ~ ~ t v  
+ cTtv). 

2.1 The Frank- Wolfe Theorem 
33 
Note that 
(ykITDtv + cTtv ) 0 for every k E N. 
(2.8) 
Indeed, if (2.8) were false then we would have f (yk + ttv) 4 -oo as 
t t -too, which contradicts the assumption 8 E R. 
yk - xO 
Since (tv, tv) = 1 and - 
t 
tv, there exists k1 E N such that 
Pk 
k (5, 
t v )  > 0 for all k ) kl. For any fixed index k ) k l ,  we 
. 
. 
have (yk - iO, 
tv) > 0. Therefore 
k 
0 
1 1  y - x - t q 2  = l l y k  - x01I2 - 2t(yk - xO, tv) + t211tv112 < l l y k  - x01I2 
for t > 0 small enough. By (2.5), 
(2.9) 
~ ~ ( y ~ - t t v ) = ~ ~ y ' "  
2 bi 
for alli E Io. 
Since lim 
2 bi + E for every i E 11, there exists k2 E N, 
k-tco 
& 
k2 2 k l ,  such that Aiyk 2 bi + - for every k ) k2 and i E Il. Fix 
2 
& 
an index k 2 k2 and choose bk > 0 as small as tAitv 5 , 
for every 
L 
i E Il and t E (0, bk). (Of course, this choice is made only in the 
case Il # 0.) Then we have 
for all i E Il and t E (0, bk). From what has already been proved, 
it may be concluded that 
yk-ttv E A ( A , b )  for all t E (O,bk). 
Combining this with (2.9) we see that yk - ttv E A(A, b) and 
for all t E (0, bk) small enough. By (2.7) and (2.8), we have 
So yk - ttv is a solution of the problem 

34 
2. Existence Theorems for Quadratic Programs 
From the inequality 1 1  (yk - tfi) - xO 
1 1  < 11 yk - xO 1 1  in (2.10) it follows 
that yk cannot be a solution of (2.11) with the minimal distance to 
xO, a contradiction. 
We have shown that there exists 6 > 0 such that (2.3) holds. 
We proceed to show that 
there exists p > 6 such that q, = 8. 
(2.12) 
As q, = min{f ( x )  : x E A,), it is easily seen that the conclusion 
of the theorem follows from (2.12). In order to obtain (2.12), we 
assume on the contrary that 
% > # for all p 2 6. 
(2.13) 
Note that q, 2 q,~ whenever p' 2 p. Note also that Q --) e as p + 
+oo. Hence from (2.13) it follows that there exist pi E (6, +oo) (i = 
1,2) such that pl < p2 and q,, > q,,. 
Since p2 > 6, by (2.3) we have 
Since q,, > q,,, 
we must have pl < 11 y,, - xO1l. (Indeed, if pl 2 
Ilyp2 - xO1l then YP, E A,, and f(y,,) = q,, < q,, = f(y,,). 
This 
contradicts the choice of y,, .) Setting p3 = 1 1  yp2 - xO1l we have 
PI < p3 < p2. Since p3 > 6 and pz > 6, from (2.3) it follows that 
Since p2 > p3, we have 
If f (y,,) = f (y,,) then from (2.14) we see that y,, 
is a feasible 
vector of the problem 
min{ f ( x )  : x E A,,} 
(2.15) 
at which the objective function attains its optimal value q,, 
= 
f (yp2). Hence yP3 is a solution of (2.15). By (2.14), 
This implies that y,, cannot be a solution of (2.15) with the minimal 
distance to xO, a contradiction. So we must have f(y,,) > f(yP2). 
Since lly,,, - xO1l = p3, we deduce that y,, 
is a feasible vector of the 

2.1 The Frank- Wolfe Theorem 
35 
problem mini f (x) : x E A,,). Then the inequality f (y,,) > f (y,,) 
contradicts the fact that y,, is a solution of this optimization prob- 
lem. We have established property (2.12). The proof is complete. 
0 
In Theorem 2.1, it is assumed that f is a linear-quadratic func- 
tion and A is a polyhedral convex set. From Definition 1.15 it 
follows immediately that for any polyhedral convex set A C Rn 
there exists an integer m E N, a matrix A E Rmxn and a vector 
b E Rm such that A = {x E Rn : Ax 2 b). This means that 
the Frank-Wolfe Theorem can be stated as follows: "If a linear- 
quadratic function is bounded from below on a nonempty polyhedral 
convex set, then the problem of minimizing this function on the set 
must have a solution." 
If f is a linear-quadratic function but A is not assumed to be a 
polyhedral convex set, then the conclusion of Theorem 2.1 may not 
hold. 
Example 2.1. Let f (x) = xl for every x = (xl , x2) E R2. Let 
A = {x = (x1,x2) E R2 : 21x2 2 1, x1 2 0, x2 2 0). We have 
:= inf{f (x) : x E A) = 0, but the problem min{f (x) : x E A) 
has no solutions. 
If A is a polyhedral convex set but f is not assumed to be a 
linear-quadratic function, then the conclusion of Theorem 2.1 may 
not hold. In the following example, f is a polynomial function of 
degree 4 of the variables XI and x2. 
Example 2.2. (See Frank and Wolfe (l956), p. 109) 
Let f (x) = 
x:+ (1 
for every x = (xl, x2) E R2. Let A = {x = (xl, x2) E 
R2 : x1 2 0, x2 2 0). Observe that f(x) 2 0 for every x E R2. 
Choosing xk := 
1 + k , tk E N, we have 
(5, ) 
This implies that 
It is a simple matter to show that both the problems min{f (x) : 
x E A) and min{f (x) : x E R2) have no solutions. 
In Frank and Wolfe (1956), the authors informed that Irving 
Kaplansky has pointed out that the problem of minimizing a poly- 
nomial function of degree greater than 2 on a nonempty polyhedral 

36 
2. Existence Theorems for Quadratic Programs 
convex set may not have solutions even in the case the function is 
bounded from below on the set. 
Given a linear-quadratic function and a polyhedral convex set, 
verifying whether the function is bounded from below on the set is 
a rather difficult task. In the next section we will discuss another 
fundamental existence theorem for quadratic programming which 
gives us a tool for dealing with the task. 
2.2 The Eaves Theorem 
The following result was published by Eaves in 1971. 
Theorem 2.2. (The Eaves Theorem; See Eaves (1971), Theorem 
3 and Corollary 4, p. 702) Problem (2.1) has solutions if and only 
if the following three conditions are satisfied: 
(i) A(A, b) is nonempty; 
(ii) If u E Rn and Av 2 0 then U?'DU 2 0; 
(iii) If u E Rn and x E Rn are such that Av 2 0, vTDu = 0 and 
Ax > b, then (Dx + C ) ~ V  2 0. 
Proof. Necessity: Suppose that (2.1) has a solution 3. Since 3 E 
A(A, b), condition (i) is satisfied. Given any u E Rn with Av 2 
0, since A(z + tu) = AZ + tAu > b for every t 2 0, we have 
3 + tu E A(A, b) for every t 2 0. Hence f (3 + tu) 2 f (3) for 
1 2 T  
every t 2 0. It follows that -t u Du + ~ ( D z  + C ) ~ U  2 0 for every 
2 
t 2 0, hence uTDu > 0. This shows that condition (ii) is satisfied. 
We now suppose that there are given any v E Rn and x E Rn 
with the properties that Av 2 0, uTDu = 0 and Ax 2 b. Since 
x + tu E A(A, b) for every t 2 0 and 3 is a solution of (2.1), we 
have f (x + tv) 2 f (3) for every t 2 0. From this and the condition 
1 
uTDu = 0 we deduce that t(Dx + C ) ~ V  + f x T ~ s  
+ cTx > f (3) for 
.& 
every t 2 0. This implies that ( D X + C ) ~ V  
2 0. We have thus shown 
that condition (iii) is satisfied. 
Suficiency: Assume that conditions (i), (ii) and (iii) are satis- 
fied. Define 0 = inf{f(x) : x E Rn, Ax > b). As A(A,b) # 0, we 
have 8 # +oo. If 8 E R then the assertion of the theorem follows 
from the Frank-Wolfe Theorem. Hence we only need to show that 

2.2 The Eaves Theorem 
37 
the situation e = -oo cannot occur. To obtain a contradiction, 
suppose that e = -oo. 
We can now proceed analogously to the 
proof of Theorem 2.1. 
Fix a point xO E A(A, b). For every p > 0, define A, = A(A, b)n 
B(xO, p) and consider the minimization problem min{f (x) : x E 
A,}. Denote by q, the optimal value of this problem. Let y, E A, 
be such that f (y,) = q, and 
We claim that there exists @ > 0 such that 11 y,-xOll < p for a11 p 2 
6. Suppose the claim were false. Then we would find an increasing 
sequence pk + +oo such that for every k there exists y,, 
E A,, 
such that 
f ( ~ P k ) = q ~ k l  ~ ~ Y P ~ - x O I I = P ~ '  
For simplicity of notation, we write yk instead of y,,. 
Since yk E 
A(A, b), we must have Aiy" 
bi for i = 1,. . . , m. Analysis sim- 
ilar to that in the proof of Theorem 2.1 shows that there exists a 
subsequence {kt} c {k} such that all the limits 
lirn ~
~
y
"
 
(i = I , . .  . ,m) 
kl+oo 
exist. Without restriction of generality we can assume that {kt) r 
{k). Let I = (1, . . . , m), I. = {i E I : lirn Aiy" 
bi) and 
k+oo 
II = I \ I. = {i E I : lirn 
bi). 
k-00 
Let E > 0 be such that 
lim ~i y" 
bi + E 
for every i E II . 
k+oo 
Since II(yk - xO)lPkll = 1 for every k, there is no loss of generality 
in assuming that the sequence 
converges to some V E Rn, llfill = 1, as k -t m. Since pk -+ +a, 
for every i E lo we have 
0 = lirn ( A ~  
yk - bi) 
k+oo 
Ai yk - bi 
= lirn 

38 
2. Existence Theorems for Quadratic Programs 
Similarly, for every i E II we have 
AiYk - bi 
0 5 lim inf 
k+m 
Pk 
( A ,  ;A, 
AixO - bi 
= lim inf 
k-+m 
+ 
Pk 
( "iX 
) + lim AixO - bi 
= lim 
Ai- 
= A@. 
k+m 
k ' ~  
Pk 
Therefore 
A$ = 0 for every i E lo, A$ 2 0 for every i E Il. 
From this we deduce that 
Since 
f ( Y k )  = f ( y p , )  
= q p ,  
= min{f (x) : x  E A,,) 
= min{f (x) : x  E A(A, b) n B(xo,pk)) 
and the increasing sequence { p k )  converges to +oo, we see that the 
sequence { f (y"} is non-increasing and f (y" + $ = -m. Hence 
f ( y k )  < 0 for all k sufficiently large. Using the formula of f we can 
rewrite the last inequality as follows 
Dividing this inequality by pi and taking the limits as k -t oo, we 
get vTDv 5 0. Since A@ > 0, from condition (ii) it follows that 
vTDi 2 0. Hence 
V ~ D V  
= 0. 
(2.17) 
y%tV 
E A(A,b) for every t 2 0 and k E N. 
By virtue of (2.17), we have 

2.2 The Eaves Theorem 
39 
Since yk E A(A, b), Afi > 0 and iiTDv = 0 ,  by condition (iii) we 
have 
+ cTfi = (Dy% clTv 2 0 for every k E N .  
(2.18) 
yk - xO 
Since ( G ,  v) = 1 and - 
-+ v, there exists k1 E N such that 
Pk 
k (5, 
G )  > 0 for all k 2 kl. For any fixed index k 2 61, we 
have (yk - xO, G )  > 0. Therefore 
I l y L  
xO - tfll12 = l l y k  - 
- 2t(yk - xO, 2l) + t2118112 < l l y k  - x01I2 
(2.19) 
for t > 0 small enough. We have 
(yk - tfi) = 
bbi for all i E lo. 
Since lim 
bi + E for every i E 11, there exists k2 E N ,  
k+w 
& 
k2 2 k l ,  such that Aiyk > bi + - for every k 2 k2 and i E I1. Fix 
2 
& 
an index k 2 k2 and choose br, > 0 as small as tAiv 5 - for every 
2 
i E II and t E (0, bc). Then we have 
for all i E Il and t E (0, 6'). From what has already been proved, 
we deduce that 
yLttv 
E A ( A , b )  for all t E (O,bk). 
Combining this with (2.19) we see that yk - ttv E A(A, b) and 
k 
0 
Il(y - tv) - x 1 1  = I I Y k  - x0 - tvll < l l y k  - xOll = pk 
(2.20) 
for all t E (0, bk) small enough. By (2.17) and (2.18), we have 
f (yk - t@) = f ( y k )  - t ( ( y Y T ~ @  
+ cT6) 5 f ( y k ) .  
So yk - t.is is a solution of the problem 
From the inequality Il(y" 
t$ - xOII < I l y k  - xOII in (2.20) it follows 
that yk cannot be a solution of (2.21) with the minimal distance to 
xO, a contradiction. 

40 
2. Existence Theorems for Quadratic Programs 
We have shown that there exists ,6 > 0 such that 
lly, - xOll < p for all p 2 ,6. 
(2.22) 
- 
Note that q, 2 q,, whenever p' 2 p. Note also that q, --t 0 = -00 
as p --t +oo. Hence there must exist pi E (J, +oo) (i = 1,2) such 
that pl < p2 and q,, > q,,. 
Since pa > ,6, by (2.22) we have 
Since qpl > qp2, we must have pl < 1 1  yp2 - xOII. (Indeed, if pl 2 
l l ~ P 2  - x0 1 1  then Y,, 
E A,, and f (Y,,) 
= q,, < q,, = f (Y,,). This 
contradicts the choice of y,,.) 
Setting p3 = Ily,, - zOll we have 
pl < p3 < p2. Since p3 > ,6 and pa > ,6, from (2.22) it follows that 
Since pz > p3, we have 
If f(~,,) 
= f (y,,) 
then from (2.23) we see that y,, 
is a feasible 
vector of the problem 
min{f(x) : x E A,,) 
(2.24) 
at which the objective function attains its optimal value q,, 
= 
f (y,,). Hence y,, 
is a solution of (2.24). By (2.23), 
This implies that y,, cannot be a solution of (2.24) with the minimal 
distance to xO, a contradiction. So we must have f(y,,) > f (y,,). 
Since llyp2 - xO1l = p ~ ,  
we deduce that y,, is a feasible vector of the 
problem min{ f ( x )  : x E A,,). Then the inequality f (y,,) > f (y,,) 
shows that yP3 cannot be a solution of this optimization problem, a 
contradiction. The proof is complete. 
Here are several important consequences of the Eaves Theorem. 
Corollary 2.1. Assume that D is a positive semidefinite matrix. 
Then problem (2.1) has solutions if and only i f  A(A, b) is nonempty 
and the following condition is satisfied: 

2.2 The Eaves Theorem 
41 
Proof. Note that condition (ii) in Theorem 2.2 is satisfied because, 
by our assumption, vTDu 2 0 for every v E Rn. Therefore the 
conclusion follows from Theorem 2.2. 
Corollary 2.2. Assume that D is a negative semidefinite matrix. 
Then problem (2.1) has solutions if and only if A(A, b) is nonernpty 
and the following conditions are satisfied: 
(i) (v E Rn, Av 2 0) + v T ~ v  
= 0; 
(ii) (v E Rn, x E Rn, Av 2 0, Ax 2 b) + ( D X + C ) ~ V  
2 0. 
Proof. Since vTDv 5 0 for every v E Rn by our assumption, we see 
that condition (ii) in Theorem 2.2 is can be rewritten as condition 
(i) in this corollary. Besides, since Av 2 0 implies vTDu = 0, 
condition (iii) in Theorem 2.2 can be rewritten as condition (ii) in 
this corollary. Therefore the conclusion follows from Theorem 2.2. 
0 
Corollary 2.3. If D is a positive definite matrix, then problem (2.1) 
has solutions if and only if A(A, b) is nonempty. 
Proof. Since D is a positive definite matrix, the equality uTDu = 0 
implies that v = 0. Then the assertion follows from Corollary 2.1 
because condition (2.25) is satisfied. 
0 
Corollary 2.4. If D is a negative definite matrix, then problem 
(2.1) has solutions if and only if A(A, b) is nonernpty and compact. 
Proof. Since D is a negative definite matrix, conditions (i) and (ii) 
in Corollary 2.2 are fulfilled if and only if the set L := {v E Rn : 
Av 2 0) contains just one element v = 0. Since L is the recession 
cone of the polyhedral convex set A(A, b) = {x E Rn : Ax 2 b) (see 
Rockafellar (1970), p. 62), the condition L = (0) is equivalent to 
the compactness of A(A, b) (see Rockafellar ( l V O ) ,  Theorem 8.4). 
Hence the assertion follows from Corollary 2.2. 
Theorem 2.2 allows one to verify the existence of solutions of a 
quadratic program of the form (2.1) through analyzing its data set 
{Dl A, c, b). If any one from the three conditions (i), (ii) and (iii) 
in the theorem is violated, then the problem cannot have solutions. 
Formally, the Eaves Theorem formulated above allows one to 
deal only with quadratic programs of the standard form. It is a 
simple matter to derive existence results for quadratic programs of 
the canonical and the general forms from Theorem 2.2. 

42 
2. Existence Theorems for Quadratic Programs 
Corollary 2.5. Let D E R:'", 
A E Rmxn, c E Rn and b E Rm. 
The quadratic program 
1 
min { j x T ~ x  + cTx : x E Rn, Ax 2 b, x 2 0 }  
(2.26) 
has solutions if and only if the following three conditions are satis- 
fied: 
(i) The constraint set { x  E Rn : Ax 2 b, x 2 0 )  is nonempty; 
(ii) If v E Rn, Av 2 0 and v 2 0, then V*DV 2 0; 
(iii) If v E Rn and x E Rn are such that Av 2 0, v 2 0, vTDv = 0, 
Ax 2 b and x 2 0, then (Dx + C ) ~ V  2 0. 
Proof. Define 
E R ( ~ + ~ ) ~ ~  
and b E Rm+n by setting 
where E denotes the unit matrix in RnXn and 0 stands for the zero 
vector in Rn. It is clear that (2.26) can be rewritten in the following 
form 
min  ID^ + cTx : x E R". Xz 2 b} . 
Applying Theorem 2.2 to this quadratic program we obtain the 
desired result. 
0 
Corollary 2.6. Let D E RzXn, A E Rmxn, C E RSXn, 
c E Rn, b E 
Rm and d E RS. The quadratic program 
min { a x T ~ x  
+ cTx : x E Rnl AX 2 6, cx = d } 
(2.27) 
has solutions if and only if the following three conditions are satis- 
fied: 
(i) The constraint set { x  E Rn : Ax 2 b, C x  = d) is nonempty; 
(ii) If v E Rn, Av 2 0 and Cv = 0, then vTDv 2 0; 
(iii) If v E Rn and x E Rn are such that Av 2 0, C v  = 0, 
vTDv = 0, Ax > b and C x  = d, then ( D x  + C ) ~ V  2 0. 

2.3 Commentaries 
Proof. Define 
E R ( ~ + ~ ~ ) ~ ~  
and b E Rm+2S by setting 
It is clear that (2.27) can be rewritten in following form 
1 
min {
i
~
r
~
~
 
+ C'X 
: x E RD, X r  2 %) 
. 
Applying Theorem 2.2 to this quadratic program we obtain the 
desired result. 
2.3 Commentaries 
The Frank-Wolfe Theorem has various applications. For example, 
in (Cottle et al. (1992), Chapter 3) it has been used as the main 
tool for obtaining many existence results for linear complementar- 
ity problems. Usually, existence theorems for optimization problems 
and for variational problems give only suficient conditions to as- 
sure that the problem under consideration has solutions. Here we 
see that the Frank-Wolfe Theorem and the Eaves Theorem provide 
some criteria (both the necessary and sufficient conditions) for the 
solution existence. This is possible because the quadratic programs 
have a relatively simple structure. 
We realized the importance of the Eaves Theorem when we stud- 
ied a paper by Klatte (1985) and applied the theorem to investi- 
gate the lower semicontinuity of the solution map in parametric 
quadratic programs (see Chapter 15 of this book), the directional 
differentiability and the piecewise linear-quadratic property of the 
optimal value function in quadratic programs under linear pertur- 
bations (see Chapter 16 of this book). We believe that the theorem 
is really very useful and important. 
The proof of the Frank-Wolfe Theorem given in Section 2.1 fol- 
lows exactly the scheme proposed in Blum and Oettli (1972). For 
the convenience of the reader, all the arguments of Blum and Oettli 
are described in detail. Two other proofs of the theorem can be 
found in Frank and Wolfe (1956) and Eaves (1971). 
The proof of the Eaves Theorem given in Section 2.2 is rather 
different from the original proof given in Eaves (1971). The repeti- 
tion of one part of the arguments used for proving the Frank-Wolfe 

44 
2. Existence Theorems for Quadratic Programs 
Theorem is intended to show the close interrelations between the 
two existence theorems. 

Chapter 3 
Necessary and Sufficient 
Optimality Conditions for 
Quadratic Programs 
This chapter is devoted to a discussion on first-order optimality 
conditions and second-order optimality conditions for quadratic pro- 
gramming problems. 
3.1 First-Order Optimality Conditions 
In this section we will establish first-order necessary and sufficient 
optimality conditions for quadratic programs. Second-order neces- 
sary and sufficient optimality conditions for these problems will be 
obtained in the next section. 
The first assertion of the following proposition states the Fermat 
rule, which is a basic first-order necessary optimality condition for 
mathematical programming problems, for quadratic programs. The 
second assertion states the so-called first-order suficient optimality 
condition for quadratic programs and its consequence. 
Theorem 3.1. Let Z be a feasible vector of the quadratic program 
where D E R2Xn, c E Rn, and A c Rn is a polyhedral convex set. 
(i) If Z is a local solution of this problem, then 
(Dz 
+ c, x - 2) > 0 for every x E A. 
(3.2) 

46 
3. Necessary and Sufficient Optimali ty Conditions 
(ii) If 
( D z +  c , x  - 5) > 0 for every x E A \  { z ) ,  
(3.3) 
then 5 is a local solution of (3.1) and, moreover, there exist 
E > 0 and Q > 0 such that 
f ( x )  - f(5) 2 ellx-?ll 
for every x E A n  B ( ~ , E ) .  (3.4) 
Proof. (i) Let 5 E A be a local solution of (3.1). Choose p > 0 so 
that 
f ( Y )  L f (3, 'dy E A n B F ,  1-1). 
Given any x E A \ ( 3 ) )  we observe that there exists 6 > 0 such that 
5 + t ( x  - 5 )  belongs to A n B ( z ,  p) whenever t E (0,d). Therefore 
0 5 lim f (3 + t ( x  - 5 ) )  - f (3) = f ' ( 5 ; x - f )  
tl0 
t 
= (0 f ( 5 ) )  x - 3) 
= ( D z + c , x  - 5). 
Property (3.2) has been established. 
(ii) It suffices to show that if (3.3) holds then there exist E > 0 
and Q > 0 such that (3.4) is satisfied. To obtain a contradiction, 
suppose that (3.3) holds but for every E > 0 and Q > 0 there 
exists x E A n  B ( ~ , E )  
such that f ( x )  - f ( j . )  < Qllx - 511. Then 
there exists a sequence { x k )  in Rn such that, for every k E N, we 
1 
1 
have xk E A n B ( 5 ,  -) and f ( x k )  - f (j.) < 
llxk - f 1 1 .  There is 
k 
no loss of generality in assuming that the sequence of unit vectors 
{ ( x k  - 5)/llxk - 311) converges to some unit vector @ E Rn. Since 
Dividing the last inequality by llxk - j.11 and taking the limits as 
k + oo, we obtain 
( D 5  + ~ ) ~ i j  
5 0. 
(3.5) 
Since A is a polyhedral convex set, there exist m E N, al, . . . , a, in 
Rn and Pl,. . . , P, in R such that A has the representation (1.31). 
Let I. = {i : (ai, 5 )  = Pi), Il = { i  : (ai, 3) > Pi}. For each 
i E lo, we have (ai, xk - 5) = (ai, x k )  - Pi 2 0. Therefore (ai, @) = 
lim (ai, (xk - z)/ 1 1  xk - 5 1 1 )  2 0. Obviously, there exists dl > 0 such 
k+oo 

3.1 First-Order Optimality Conditions 
47 
that (ai, + tv) > pi for every i E Il and t E (0, &). Consequently, 
2 + tv E A for every t E (0, 61). Substituting x = 2 + tv, where 
t is a value from (0, J1), into (3.3) gives (Dz + C ) ~ G  > 0, which 
contradicts (3.5). The proof is complete. 
For obtaining a first-order necessary optimality condition for 
quadratic programs in the form of a Lagrange multiplier rule, we 
shall need the following basic result concerning linear inequalities. 
Theorem 3.2. (Farkas' Lemma; See Rockafellar (1970), p. 200) 
Let ao, al, . . . , ah be vectors from Rn. The inequality (ao, x) 5 0 is 
a consequence of the system 
if and only if there exist nonnegative real numbers XI,. . . , Xk such 
that 
k 
&ai = ao. 
i= 1 
Theorem 3.3. (See, for instance, Cottle et al. (1992), p. 118) If 
Z E Rn is a local solution of problem (2.1) then there exists X = 
(XI,. . . ,Am) E Rm such that 
Proof. Denote by Ai the i-th row of A, and set ai = AT. Denote 
by bi the i-th component of vector b. Set A = A(A, b) = {x E Rn : 
Ax 2 b). Let Z be a local solution of (2.1). By Theorem 3.l(i), 
property (3.2) holds. Set I = (1,. . . , m), I. = {i E I : (ai, 3) = bi) 
and Il = {i E I : (ai, 2) > bi). For any v E Rn satisfying 
(ai,v) 2 0 for everyi E lo, 
analysis similar to that in the proof of Theorem 3.l(ii) shows that 
there exists 61 > 0 such that (ai, Z + tv) 2 bi for every i E I and 
t E (0, &). Substituting x = Z + tv, where t is a value from (0, S1), 
to (3.2) yields (Dz + c, v) 2 0. We have thus shown that 

48 
3. Necessary and Sufficient Optimali ty Conditions 
for any v E Rn satisfying 
(-ai, v) < 0 for every i E I. 
By Theorem 3.2, there exist nonnegative real numbers Xi (i E Io) 
such that 
Put Xi = 0 for all i E Il and X = (A1, . . . , A,). 
Since ai = AT for 
every i E I, from (3.7) we obtain the first equality in (3.6). Since 
2 E A(A, b) and Xi(Ai2 - bi) = 0 for each i E I, the other conditions 
in (3.6) are satisfied too. The proof is complete. 
From Theorem 3.3 we can derive the following Lagrange multi- 
plier rules for quadratic programs of the canonical and the general 
forms. 
Corollary 3.1. (See, for instance, Murty (1972)) If 2 is a local 
solution of problem (2.26), then there exist X = (A1,. . . , A,) 
E Rm 
such that 
Proof. Define matrix A E R ( ~ + ~ ) ~ ~  
and vector b E Rm+n as in the 
proof of Corollary 2.5 and note that problem (2.26) can be rewritten 
in the form 
Applying Theorem 3.3 to this quadratic program we deduce that 
there exists X = (h, 
. . . , Am+,) 
E Rm+n such that 
Taking X = (A1,. . . ,A,), 
we can obtain the properties stated in 
(3.8) from the last ones. 
Corollary 3.2. If Z is a local solution of problem (2.27), then there 
exist X = (A1,. . . , Am) E Rm and p = (pl,. . . , ps) E RS such that 

3.1 First-Order Optimali ty Conditions 
49 
Proof. Define A E 
a nd 2; E Rmf2' as in the proof of 
Corollary 2.6 and note that problem (2.27) can be rewritten in the 
form 
1 
min { Z x T ~ x  + cTx : x E Rn, Ax 2 61, 
Applying Theorem 3.3 to this quadratic program we see that there 
exists 
= (A1,. . . , Am+2n) E Rm+2n such that 
Taking A = (A1,. . . ,Am) and p = (pl,. . . ,ps), where pj = Am+j - 
for j = 1,. . . , s, we can obtain the properties stated in (3.9) 
from the last ones. 
Definition 3.1. If (5, A) E Rn x Rm is such a pair that (3.6) 
(resp., (3.8)) holds, then we say that (3, A) is a Karush-Kuhn- 
Tucker pair (KKT pair for short) of the standard quadratic pro- 
gram (2.1) (resp., of the canonical quadratic program (2.26)). The 
point % is called a Karush-Kuhn- Tucker point (KKT point for short), 
and the real numbers XI,. . . ,Am are called the Lagrange multipli- 
ers corresponding to 5. Similarly, if (5, A, p) E Rn x Rm x RS is 
such a triple that (3.9) is satisfied then % is called a Karush-Kuhn- 
Tucker point of the general quadratic program (2.27), and the real 
numbers XI,. . . , A,, 
p1,. . . , p, are called the Lagrange multipliers 
corresponding to 3. Sometimes the vectors A = (A1,. . . , A,) 
and 
p = (pl,. . . , p,) are also called the Lagrange multipliers correspond- 
ing to %. 
In the sequel, by abuse of notation, we will abbreviate both the 
KKT point sets of (2.1) and (2.26) to S(D, A, c, b). Likewise, both 
the solution sets (resp., both the local-solution sets) of (2.1) and 
(2.26) are abbreviated to Sol(D, A, c, b) (resp., to loc(D, A, c, b)). 
From Theorem 3.3 and Corollary 3.1 it follows that 
Sol(D, A, c, b) c loc(D, A, c, b) c S(D, A, c, b). 
(3.10) 
Later on, we will encounter with examples where the three sets 
figured in (3.10) are different each from others. 

50 
3. Necessary and Sufficient Optimality Conditions 
3.2 
Second-Order Optimality 
Conditions 
This section provides a detailed exposition of second-order neces- 
sary and sufficient optimality conditions for quadratic programming 
problems. The main result in this direction was published by Ma- 
jthay in 1971. It is stated in Theorem 3.4 below. The proof given 
by Majthay contains one inaccurate argument (see Contesse (1980), 
p. 331). The first rigorous proof of this result belongs to Contesse 
(1980). 
Theorem 3.4. (See Majthay (1971) and Contesse (1980), Thkorkme 
I )  The necessary and sujJicient condition for a point 3 E Rn to be a 
local solution of problem (2.27) is that there exists a pair of vectors 
( X ,  ,G) = ( X I , .  . . , X,, 
, G I , .  . . , ,G,) 
E Rm x RS 
such that 
(i) the system 
D Z - A ~ X - C ~ ~ + C = O ,  
A % -  b > 0, C z  = d ,  
X 2 0, 
(3.11) 
X T ( ~ z  
- b) = 0. 
is satisfied, and 
(ii) z f v  E Rn \ ( 0 )  is such that AI,v = 0, AI2v > 0, C v  = 0, where 
- 
I I = { i  : Ai3=bbi, Xi>O), 
1 2 = { i  : Aiz=bi, Xi=O), 
(3.12) 
then vTDv > 0. 
Consider problem (2.27) and set 
Denote the objective function of (2.27) by f ( x ) .  Let the symbol 
(V f (x))'- stand for the linear subspace of Rn orthogonal to B f ( x ) ,  
that is 
(of(.))' = {V E Rn : ( V f ( x ) , v )  = 0 ) .  
For proving Theorem 3.4 we shall need the following fact. 

3.2 Second- Order Optimality Conditions 
5 1 
Lemma 3.1. Let 3 E Rn, X E Rm and p E RS be such that the 
system (3.11) is satisfied. Let II and I2 be as in (3.12). Then 
{V E Rn : AIlv = 0, A12v 2 0, CV = 0) 
= {v E Rn : AI,v 2 0, CV = 0) n (of ( z ) ) ~  
= TAW n (of (W, 
where I. := Il U I2 = {i : Ai3 = bi), and TA(Z) denotes the tangent 
cone to A at 3. 
Proof. Using Theorem 1.8 (b), it is a simple matter to show that 
So it suffices to prove the first equality in the assertion of the lemma. 
Suppose that v E Rn, AI,v = 0, A12v 2 0, Cv = 0. Define 
I = {1,2,. . . ,m). By (3.11) we have 
Hence v E (V f (E))'. It follows that 
{V E Rn : AIlv = 0, AI2v 2 0, CV = 0) 
c {V E Rn : AI0v 2 0, CV = 0) n (Vf ( z ) ) ~ .  
To obtain the reverse inclusion, suppose that v E Rn, AIov 2 
0, Cv = 0, v E (Vf(5))'-. We need only to show that AIlv = 0. 
From (3.11) we deduce that 
Hence AIlv = 0, and the proof is complete. 
0 
Note that Theorem 3.4 can be reformulated in the following 
- 
equivalent form which does not require the use of Lagrange multi- 
pliers. 
Theorem 3.5. (See Cottle et al. (1992), p. 116) The necessary 
and suficient condition for a point 3 E Rn to be a local solution of 
problem (2.27) is that the next two properties are valid: 

5 2 
3. Necessary and Sufficient Optimali ty Conditions 
(i) (Vf(Z),v) = (Dz + C ) ~ V  2 0 for every v E Tn(Z) = {v E Rn : 
AIov > 0, Cv = 0), where I. = {i : Ai? = bi); 
(ii) vTDv > 0 for every v E Ta(Z) n (V f (?))l, where (V f (Z))' = 
{V E Rn : ( V f ( ~ ) , v )  
= 0). 
The fact that the first property is equivalent to the existence of 
a pair (X, p) E Rm x RS satisfying system (3.11) can be established 
by using the Farkas Lemma (see Theorem 3.2) and some arguments 
similar to those in the proof of Lemma 3.1. The equivalence between 
property (ii) in Theorem 3.5 and property (ii) in Theorem 3.4, which 
is formulated via a Lagrange multipliers set (A, p) E Rm x RS, fol- 
lows from Lemma 3.1. Hence Theorem 3.5 is an equivalent form of 
Theorem 3.4. 
Proof of Theorem 3.4. 
Necessity: Suppose that 3 is a local solution of (2.27). Then 
there exists E > 0 such that 
According to Corollary 3.2, there exists ( x , ~ )  
E Rm x Rn such 
that condition (i) is satisfied. Let II and I2 be defined as in (3.12). 
Suppose that property (ii) were false. Then we could find 
E 
Rn \ (0) such that 
By Lemma 3.1, (DZ + c)?'ij = (V f (?), ZI) = 0. Consequently, for 
each t E (0,l) we have 
As 3 + tij E A n B(z, E) for all t E (0,l) sufficiently small, the last 
fact contradicts (3.14). Thus (ii) must hold true. 
Suficiency: Suppose that Z E Rn is such that there exists 
(X, p) E Rm x Rn such that conditions (i) and (ii) are satisfied. We 
shall prove that 3 is a local solution of (2.27). The main idea of the 
proof is to decompose the tangent cone Ta(?) into the sum of a sub- 
space and a pointed polyhedral convex cone. Set I = {1,2, . . . , m), 
I. = {i E I : AiZ = bi), and observe that I. = I1 U 1 2 .  Define 
M = {V E Rn : AIov=O, Cv=O), 
M'- = {v E Rn : (v,u) = 0 Vu E M). 

3.2 Second-Order Optimali ty Conditions 
Let 
K = {v E M'- : v = z - u  for some z E TA(3) and u E M )  
= P ~ M I  
(TA(z)), 
where P r M ~ ( + )  
denotes the orthogonal projection of Rn onto M1. 
Since K = PrML (Ta(3)) and M c TA(Z), it follows that 
We have 
K = MI n TA(iE). 
(3.16) 
Indeed, if v E K then v E M'- and v = z - u for some z E Tn(3) 
and u E M. Hence 
Therefore 
AI0v = AI0z - AI,u = AI0x 2 0, 
C v = C z - c u = o .  
So v E M1 n TA (3). It follows that K c M I  f l  Tn(if). For proving 
the reverse inclusion, it suffices to note that each v E M I  n TA(3) 
admits the representation v = v - 0 where v E T&), 0 E M. 
We next show that K is a pointed polyhedral convex cone. Re- 
call that a cone K c Rn is said to be pointed if K n (-K) = (0). 
From (3.16) it follows that K is a polyhedral convex cone. So we 
need only to show that K is pointed. If it were true that K is not 
pointed, there would be v E K \ (0) such that -v E K. On one 
hand, from (3.13) and (3.16) it follows that 
This implies that AI0v = 0 and Cv = 0. So v E M. On the other 
hand, since v E K ,  by (3.16) we have v E M1. Thus v E M n ML = 
(0) , a contradiction. 
Define KO = {v E K : (V f (3),v) = 0). Since K is a pointed 
polyhedral convex cone, we see that KO is also a pointed polyhedral 
convex cone. 
From (i) it follows that 
(Vf(iE),v) 2 0 'dv E Ta(5). 
(3.17) 

54 
3. Necessary and Sufficient Optimali ty Conditions 
Indeed, let v E TA(z). By (i) and (3.13), 
Since M C T@) and -v E M whenever v E M, it follows that 
From (3.17) and the definition of KO we have 
Since K is a polyhedral convex cone, according to Theorem 19.1 in 
Rockafellar (1970), K is a finitely generated cone. The latter means 
that there exists a finite system of nonzero vectors {zl,. . . , z"), 
called the generators of K ,  such that 
4 
K =  { v = x t j z 3  : tj 2 0  for all j =  1, ...,q). 
(3.20) 
j=1 
If KO # (0) then some of the vectors xi ( j  = 1,. . . , q) must belong 
to KO. To prove this, suppose, contrary to our claim, that KO # (0) 
and all the generators zj ( j  = 1,. . . , q) belong to K \ KO. Let 
ir = C:=, tjzj, where tj > 0 for all j, be a nonzero vector from KO. 
Since at least one of the values tj must be nonzero, from (3.19) we 
deduce that 
This contradicts our assumption that ir E KO. If KO # {0), there 
is no loss of generality in assuming that the first qo generators 
zj (j = 1,. . . , qo) belong to KO, and the other generators zj (j = go+ 
1,. . . ,q) belong to K \ KO. Thus ( V f ( ~ ) , z j )  
= 0 for j = 1,. . . ,qo, 
(V f (3)) zj) > 0 for j = qo + 1, . . . , q, and qo E (1, . . . , q). 
We are now in a position to prove the following claim: 
CLAIM. 
Z is a local solution of (2.27). 
If 3 were not a local solution of (2.27), we would find a sequence 
{xk) c A such that xk + Z, and 

3.2 Second-Order Op timality Conditions 
For each k E N, on account of (3.15), we have 
Combining this with (3.20) we deduce that there exist t! 2 0 ( j  = 
1,. . . ,q) and uk E M such that 
k 
k
k
k
 
x - Z = u  + u  + w .  
(3.22) 
It is understood that vk (resp., w" is absent in the last represen- 
tation if KO = (0) (resp., K \ KO = 0). There are two possible 
cases: 
0 Case 1: There exists a subsequence {kt) C {k) such that wk' = 0 
for all kt. (If K \ KO = 0, then w q s  vacuous for all k E N. 
Such situation is also included in this case.) 
Case 2: There exists a number k, E N such that wk # 0 for 
every k 2 k,. 
If Case 1 occurs, then without restriction of generality we can 
assume that {kt) = {k). Since xk - 3 = uk + vk, from (3.18) we 
have 
Therefore 
Hence 
(x" 
Z)T D(X" 
3) < 0 tjk E N. 
(3.23) 
Since xk - Z Z TA(3) and (Vf(3),xk - 3) = 0, we have xk - 
Z E T&) n (V f (3))'. 
Consequently, from Lemma 3.1 and from 

56 
3. Necessary and Sufficient Optimali ty Conditions 
assumption (ii) we obtain (x" 
3 ) T ~ ( x k  
- 3) c) 0, contrary to 
(3.23). 
If Case 2 happens, then there is no loss of generality in assuming 
that wk # 0 for all k E N. For each k ,  since t: 
( j  = qo + 1,. . . , q) 
are nonnegative and not all zero, there must exists some j(k) E 
{go + 1, . . . , q) such that 
t:ckl = max{t: 
: j E {go + 1,. . . , q)) > 0. 
It is clear that there must exist an index j, E {go + 1,. . . , q) and a 
subsequence {k') c { k )  such that j(kl) = j, for every k'. Without 
loss of generality we can assume that {k') = {k). On account of 
(3.21) and (3.22), we have 
In these transformations, we have used the inequality 
which is a consequence of Lemma 3.1 and condition (ii). From what 
has already been proved, it follows that 
9 
T 
k
k
 
0 > 
tj ( u  +vk)~D.'i: 
(Di+c)'zj* + i ( 2 t:lj) 
Dwk. 
j=go+l 
=go+l 
(3.24) 
Dividing (3.24) by t:*, noting that 0 < t:/ti < 1 for every j = 
qo + 1,. . . , q, letting k + oo and using the following 
FACT. If xk + 5 then uk + 0, vk + 0, and wk + 0, 

3.2 Second-Order Optimality Conditions 
57 
we get 
0 2 ( D z  + ~ ) ~ z j * ,  
(3.25) 
a contradiction. This finishes the proof our Claim. 
What is left is to show that the Fact is true. For proving it, we 
first observe that 
k 
k 
llx" 
% [ I 2  = (x" 
z7xk - 3) = (uk + vk + w , u + vk + wk) 
= (
I
~
~
1
1
~
 
+ llvk + wy2. 
Since llxk - -11 
-+ 0, it follows that uk -+ 0 and 21% 
wk -+ 0. We 
have 
a 
It suffices to prove that, for any j E (1,. . . , q), t; + 0 as k + oo. 
On the contrary, suppose that there exists jl E (1,. . . , q) such that 
the sequence { t i )  does not converge to 0 as k + oo. Then there 
exist E > 0 and a subsequence {kt) C {k) such that t;: 
2 E for 
every k' Since x;=, t? 2 t# 2 E for every kt, we can write 
Replace {kt) by a subsequence if necessary, we can assume that, for 
every j E {I,. . . ,q), 
tk' 
for some ;i, E [O,l]. It is clear that Cj4=1 7. 
-3 = 1. We must have 
C? 
]=I ijzj # 0. Indeed, if it were true that C:=,ijJ # 0, there 
would be some jo E (1,. . . , q) such that Tjo # 0. Then 
This implies that -ijOzjO E K ,  TjozjO E K ,  ijOzjO # 0. Hence 
the cone K is not pointed, a contradiction. We have thus proved 
that i := XI=, 
ijzj is a nonzero vector. If the sequence {C;=, t;') 
is bounded, then without loss of generality we can assume that it 
converges to some limit .i 2 E. Letting kt + oo, from (3.26) we 
deduce that 0 = .ii, a contradiction. If the sequence {C:=, trl) is 

58 
3. Necessary and Sufficient Optimali t y  Conditions 
unbounded, then without loss of generality we can assume that it 
converges to +m. From (3.26) it follows that 
Letting k' -+ m we obtain 0 = +mll~II, 
an absurd. 
0 
Definition 3.2. (See Mangasarian (1980), p. 201) A point Z E A is 
called a locally unique solution of the problem min{f (x) : x E A), 
where f : Rn -t R is a real function and A c Rn is a given subset, 
if there exists E > 0 such that 
f(x) > f(z) vx E ( A n  El(?,&)) \{?I. 
Of course, if Z is a locally unique solution of a minimization 
problem then it is a local solution of that problem. The converse is 
not true in general. 
The following theorem describes the (second-order) necessary 
and sufficient condition for a point to be a locally unique solution 
of a quadratic program. 
Theorem 3.6. (See Mangasarian (1980), Theorem 2.1, and Con- 
tesse (1980), Thhorkme 1) The necessary and suficient condition 
for a point Z E Rn to be a locally unique solution of problem (2.27) 
is that there exists a pair of vectors 
such that 
(i) The system (3.11) is satisfied, and 
(ii) If v E Rn \ (0) is such that AI,v = 0, AI2v 2 0, Cv = 0, where 
then vTDv > 0. 
Proof. Necessity: Suppose that Z is a locally unique solution of 
(2.27). Then there exists E > 0 such that 
f(x) - f(5) > 0 VX E ( A n  B(z,&)) \ {z). 
(3.27) 

3.2 Second- Order Op timali ty Conditions 
59 
According to Corollary 3.2, there exists ( 5 , ~ )  
E Rm x Rn such 
that condition (i) is satisfied. Suppose that property (ii) were false. 
Then we could find 
E Rn \ (0) such that 
By Lemma 3.1, (D3 + c)*v = (V f (3), Z) = 0. Consequently, for 
each t E (0,l) we have 
t2 -T 
1 
f (3 + tv) - f (3) = t(D3 + c)% + -v 
Dv = -t2VTDV < 0. 
2 
2 
As 3 + t@ E A n B(3, E )  for all t E (0,l) sufficiently small, the last 
fact contradicts (3.27). Thus (ii) must hold true. 
Suficiency: Suppose that 3 E Rn is such that there exists 
(i, 
p) E Rm x Rn such that (i) and (ii) are satisfied. We shall show 
that 3 is a locally unique solution of (2.27). Set I = {1,2, . . . , m), 
I. = {i E I : AiZ = bi). Let M, M 
1 
I, K ,  KO, z , . . . ,zq, and 
q0 be defined as in the proof of Theorem 3.4. Then the properties 
(3.15)-(3.20) are valid. 
If 3 were not a locally unique solution of (2.27), we would find 
a sequence {x" C A such that xk + 3, and 
For each k E N, on account of (3.15), we have 
Combining this with (3.20) we conclude that there exist t,fi > 0 ( j  = 
1,. . . , q) and u% M such that (3.21) holds. Setting vk = CqO 
3=1 tkzj 
3 
and wk = C&+, $23 we have (3.22). As before, if KO = 10) 
(resp., K \ KO = 8) then it is understood that v"resp., 
wk) is 
absent in the representation (3.22). We consider separately the 
following two cases: 
Case 1: There exists a subsequence { K )  C {k) such that wk' = 0 
for all kt. (If K \ KO = 0, then w q s  vacuous for all k E N. 
Such situation is also included in this case.) 
Case 2: There exists a number k, E N such that wk # 0 for 
every k > k,. 

60 
3. Necessary and Sufficient Optimality Conditions 
If Case 1 occurs, then without restriction of generality we can 
assume that {k') = {k). Arguing similarly as in the analysis of 
Case 1 in the preceding proof, we obtain 
Since x" 
5 E TA (5) and (V f (3) , x" 
5) = 0, we have x" 
3 E 
TA(Z) fl (V f (5))'. 
Hence from Lemma 3.1 and from assumption 
(ii) it follows that (xk - z)~D(x" Z) > 0, contrary to (3.28). 
If Case 2 happens then there is no loss of generality in assuming 
that wk # 0 for all k E N. Construct the sequence {j(k)) (k E N) 
as in the proof of Theorem 3.4. Then there must exist an index j, E 
{qo + 1, . . . , q) and a subsequence {k') c {k) such that j(kl) = j, for 
every k'. Without loss of generality we can assume that {k') r {k). 
Analysis similar to that in the proof of Theorem 3.4 shows that 
(3.29) 
Dividing (3.29) by t$*, noting that 0 < tilt; < 1 for every j = 
q0 + 1, . . . , q, letting k -+ oo and using the Fact established in 
the preceding proof, we get (3.25). This contradicts (3.19) because 
zj* E K\ KO. We have thus proved that 3 is a locally unique solution 
of(2.27). 
0 
Note that Theorem 3.6 can be reformulated in the following 
equivalent form which does not require the use of Lagrange multi- 
pliers. 
Theorem 3.7. The necessary and sufficient condition for a point 
3 E Rn to be a locally unique solution of problem (2.27) is that the 
next two properties are valid: 
(i) (V f (z), v) = (Dz + C ) ~ V  2 0 for every v E TA(3) = {v E Rn : 
AI0v 2 0, Cv = 0), where I. = {i : Ai3 = b,); 
(ii) vTDv > 0 for every nonzero vector v E TA(3) fl (Vf (z))', 
where (Vf(3))' = {v E Rn : (Vf(3),v) = 0). 
As it has been noted after the formulation of Theorem 3.5, the 
first property is equivalent to the existence of a pair (1, 
ji) E Rm x RS 
satisfying system (3.11). The equivalence between property (ii) in 
Theorem 3.7 and property (ii) in Theorem 3.6, which is formulated 

3.2 Second-Order Op timali ty Conditions 
61 
via a Lagrange multipliers set (A, p) E Rm x RS, follows from Lemma 
3.1. Hence Theorem 3.7 is an equivalent form of Theorem 3.6. 
It is interesting to observe that if Z is a locally unique solution 
of a quadratic program then a property similar to (3.4) holds. 
Theorem 3.8. If Z E Rn is a locally unique solution of problem 
(2.27) then there exist E > 0 and Q > 0 such that 
where A = {x E Rn : Ax 2 b, Cx = d )  is the constraint set of 
(2.27). 
Proof. Let Z E Rn be a locally unique solution of (2.27). By 
Theorem 3.6, there exists a pair of vectors 
such that 
(i)' The system (3.11) is satisfied, and 
(ii)' If v E Rn\ (0) is such that AI,v = 0, AI,v 2 0, Cv = 0, where 
then vTDv > 0. 
As it has been noted in the proof of Theorem 3.4, from (i)' it follows 
that (3.17) is valid. 
To obtain a contradiction, suppose that one cannot find any pair 
of positive numbers (E, Q) satisfying (3.30). Then, for each k E N, 
1 
1 
there exists xk E E such that Ilxk - 311 5 - and 
k 
The last inequality implies that $9 
3. Without loss of generality 
we can assume that the sequence {(xk - Z)/llxk - 211) converges to 
some fl E Rn with llVll = 1. By (3.31), we have 
I 
1 
- I I x ~ - z [ [ ~  
> f (xk)- f (3) = - ( X ~ - Z ) ~ D ( X ~ - Z ) + ( D Z + C ) ? ' ( X ~ - Z ) .  
k 
2 
(3.32) 
Dividing this expression by I(xk - 311 and letting k + oo we get 
0 > (Dz + c)'~. Since x" 
3 E TA(Z) for every k E N ,  we must 

62 
3. Necessary and Sufficient Optimality Conditions 
have 2r E Ta(Z). By (3.17), (Dz + ~ ) ~ 2 r  
> 0. Thus (V f (z), 2r) = 
(DZ + c)?'2r = 0. As xk - E TA(Z) for every k E N, according to 
(3.17) we have (DZ + c)~(x" 3) 2 0. Combining this with (3.32) 
yields 
Dividing the last inequality by / x k  - % [ I 2  
and letting k --+ oo we 
obtain 0 > VTDc. Since E T~ (3) n (V f (3))' , from Lemma 3.1 and 
(ii)' it follows that V*D?~ > 0. We have arrived at a contradiction. 
The proof is complete. 
3.3 Commentaries 
First-order necessary and sufficient optimality conditions for (non- 
convex) quadratic programs are proved in several textbooks. Mean- 
while, to our knowledge, the paper of Contesse (1980) is the only 
place where one can find a satisfactory proof of the second-order 
necessary and sufficient optimality condition for quadratic programs 
which was noted firstly by Majthay in 1971 and which has many 
interesting applications (see, for instance, Cottle et al. (1992) and 
Chapters 4, 10, 14 of this book). The reason might be that the proof 
is rather long and complicated. The proof described in this chapter 
is essentially that one of Contesse. For the benefit of the reader, 
we have proposed a series of minor modifications in the presenta- 
tion. The formulation given in Theorem 3.4 can be used effectively 
in performing practical calculations to find the local solution set, 
while the formulation given in Theorem 3.5 is very convenient for 
theoretical investigations concerning the solution sets of quadratic 
programs (see the next chapter). 
The necessary and sufficient condition for locally unique solu- 
tions of quadratic programs described in Theorem 3.6 and Theorem 
3.7 is also a good criterion for the stability of the local solutions. 
The result formulated in Theorem 3.6 was obtained independently 
by Mangasarian (1980) and Contesse (1980). The proof given in 
this chapter follows the scheme proposed by Contesse. Another 
nice proof of the "Necessity" part of Theorem 3.6 can be found 
in Mangasarian (1980). In Mangasarian (1980) it was noted that 
the "Sufficiency" part of the result stated in Theorem 3.6 follows 
from the general second-order sufficient optimality condition for 

3.3 Commentaries 
63 
smooth mathematical programming problems established by Mc- 
Cormick (see McCormick (1967), Theorem 6). Actually, the stud- 
ies of Majthay (1971)) Mangasarian (1980)) and Contesse (1980) 
on second-order optimality conditions for quadratic programs have 
been originated from that work of McCormick. 
In mathematical programming theory, it is well known that the 
estimation like the one in (3.4) (resp., in (3.30)) is a consequence of 
a strict first-order sufficient optimality condition (resp., of a strong 
second-order sufficient optimality condition). In this chapter, the 
two estimations are obtained by simple direct proofs. 


Chapter 4 
Properties of the Solution 
Sets of Quadratic Programs 
This chapter investigates the structure of the solution sets of quadratic 
programming problems. We consider the problem 
1 
(P) 
min{f(x)=-xT~x+cTx : x € R n ,  A x > b ,  C x = d ) ,  
2 
where D E Rgxn, A E Rmxn, C E RSXn, c E Rn, b E Rm, d E RS 
Let 
A = {X E Rn : AX 2 b, CX = d), I = (1,. . . ,m), J = (1,. . . , s). 
Denote by Sol(P), loc(P) and S(P), respectively, the solution set, 
the local-solution set and the KKT point set of (P). Our aim is to 
study such properties of the solution sets Sol(P), loc(P) and S(P) 
as boundedness, closedness and finiteness. Note that sometimes the 
elements of S(P) are called the Karush-Kuhn- Tucker solutions of 
(P). The above notations will be kept throughout this chapter. 
4.1 
Characterizations of the Unbound- 
edness of the Solution Sets 
Denote by Sol(Po) the solution set of the following homogeneous 
quadratic program associated with (P): 

66 
4. Properties of the Solution Sets 
Definition 4.1. A half-line w = (3 + t3 : t 2 0), where 
E 
Rn \ {0), which is a subset of Sol(P) (resp., loc(P), S(P)), 
is called 
a solution ray (resp., a local-solution ray, a K K T  point ray) of (P). 
Theorem 4.1. The set Sol(P) is unbounded if and only if (P) has 
a solution ray. A necessary and suficient condition for Sol(P) to 
be unbounded is that there exist 
E Sol(P) and 
E Sol(Po) \ (0) 
such that 
(Dz + C ) ~ V  = 0. 
(4.1) 
The following fact follows directly from the above theorem. 
Corollary 4.1. If the solution set Sol(Po) is empty or it consists 
of just one element 0 then, for any (c, b, d )  E Rn x Rm x RS, the 
solution set Sol(P) is bounded. I n  the case where Sol(Po) contains 
a nonzero element, if 
(Dz + C ) ~ G  > o 'dz E Sol(P), 'dv E SO~(P~) 
\ (01, 
then Sol(P) is bounded. 
Proof of Theorem 4.1. 
Suppose that Sol(P) is unbounded. Then there exists a sequence 
{xk) in Sol(P) such that llxkll 
+m as k -f m .  Without loss of 
xk 
generality we can assume that xk # 0 for all k and - 
-+ 
with 
Ilxk l l  
I ~ . u I I  = 1. We will show that fi E Sol(Po). Since x" 
Sol(P), we 
xk 
b 
have Ax" 
b and Cx" 
d. This implies that A- 
> - 
11x"I - llxkll and 
xk - 
C--- 
d . Letting k -t m we obtain Afi 2 0 and Cv = 0. 
Ilxkll 
Ilxkll 
Hence G is a feasible vector of (Po). Since Sol(P) # 0, 
by the Eaves 
Theorem (see Corollary 2.6), vTDv 2 0 for every v E Rn satisfying 
Av 2 0, Cv = 0. In particular, vTDfi 2 0. Fix a point 2 E A. 
Since xk E Sol(P), we have 
1 
- ( x ~ ) ~ D x ~  
+ cTxk 5 f (2) ('dk E N). 
2 
Dividing this inequality by 11x"12 and letting k t m, we obtain 
fil'Dfi < 0. Hence 
V ~ D G  
= 0. 
(4.2) 
Let v E Rn be any feasible vector of (Po), that is Av > 0 and 
Cv = 0. On account of a preceding remark, we have vTDv > 0. 
Combining this with (4.2) we deduce that v E Sol(Po) \ (0). 

4.1 Unboundedness of the Solution Sets 
67 
We now show that there exists 2 z: Sol(P) satisfying (4.1). 
Since Axk 2 b for every k E N ,  arguing similarly as in the proof 
of Theorem 2.1 we can find a subsequence {k') c { k )  such that 
for each i E I the limit lirn Aixkl exists (it may happen that 
kl'cu 
lirn Aixkl = +m). Obviously, 
kl'cu 
lirn A~X" 2 bb, (Vi E I )  
k"C0 
and 
lirn C ~ X "  
= dj (Vj E J). 
kt-403 
Without restriction of generality we can assume that {k') r {k). 
Let 
I. = {i E I : lirn Aixk = bi), II = {i E I : lirn 
> bi). 
k-cc 
k+cu 
It is clear that there exist e > 0 and ko E N such that 
We have 
and 
xk 
bi + E 
Aiv = lim Ai- 
> lim - 
- 
- 0 (Vi 
11). 
k---cu 
Ilxkll - k+cu Ilxkll 
Let xk(t) = xk - t?j, where t > 0 and k 2 ko. We have 
Aixk(t) = Aixk - tAiU > bi + E - tAiU 
(Vi E 1 1 ) .  
Fix an index k > ko. From what has been said it follows that there 
exists 6 > 0 such that, for every t E (0, d), 
It is obvious that Cjxk(t) = dj for all j E J. Hence xk(t) E A for 
every t E (O,6). Since 
0 5 f ( x k ( t ) )  - f ( x k )  
1 
T
k
 
= -(xk(t) - X ' ) ~ D ( X ~ ( ~ )  
- xk) + (Dxk + C) ( x  ( t )  - xk), 
2 

68 
4. Properties of the Solution Sets 
we have 
Combining this with (4.2) we get 
On the other hand, applying Corollary 2.6 we can assert that (Dxk+ 
c ) " ~  2 0. Hence (Dxk + c ) " ~  = 0. Taking It: = x h e  see that (4.1) 
is satisfied. 
Let us prove that if there exist 3 E Sol(P) and v E Sol(Po) \ (0) 
such that (4.1) holds, then w := {Z + tv : t 2 0) is a solution ray 
of (P). For each t > 0, since 3 E Sol(P) and 
E Sol(PO), we have 
A(z + tv) = Az + tAv 2 b, 
C ( Z + t t i j = C z + t C v = d .  
Hence 17: + tG E A. Since v E Sol(Po) and 0 is a feasible vector 
of (Po), we have .i~"Di 5 0. If vTD@ < 0 then we check at once 
that (Po) have no solutions, which is impossible. Thus vTD3 = 0. 
Combining this with (4.1) we deduce that 
1 
f (z + tv) = -(Z + tq7'D(z + tv) + cyz + tv) 
2, 
i 
Since 3 E Sol(P), we conclude that 3 + tv E Sol(P) for all t 2 0. 
We have thus shown that if Sol(P) is unbounded then there exists 
Z E Sol(P) and .Ij E Sol(Po) \ (0) satisfying (4.1) and w = (17: + tv : 
t 2 0) is a solution ray of (P). 
The claim that if (P) has a solution ray then Sol(P) is un- 
bounded is obvious. The proof is complete. 
Theorem 4.2. The set loc(P) is unbounded zf and only zf (P) has 
a local-solution ray. 
Proof. It suffices to prove that if loc(P) is unbounded then (P) 
has a local-solution ray. Suppose that there is a sequence {xk) in 
loc(P) satisfying the condition IIxklI I 
+m. Let a C I be an index 
set. The set 

4.1 Unboundedness of the Solution Sets 
69 
(which may be empty) is called a pseudo-face (see, for instance, 
Bank et al. (1982)) p. 102) of A corresponding to a .  Recall (Rock- 
afellar (1970)) p. 162) that a face of a convex set X c Rn is a convex 
subset F of X such that every closed line segment in X with a rela- 
tive interior point in F has both endpoints in F .  In agreement with 
this definition, the sets F of the form 
F = {X E Rn : A,x = b,, 
AI\,x >_ bl\,, CX = d) 
are the faces of the polyhedral convex set A under our consideration. 
Thus pseudo-faces are not faces in the sense of Rockafellar (1970). 
However, the closures of pseudo-faces are faces in that sense. It is 
clear that 
A = ~ { F , :  acI) 
and 
Fa n Far = 0 whenever a # a'. 
It is a simple matter to show that for any a c I and for any Z E F, 
it holds 
TA(3) = {V E Rn : A,v 2 0, CV = 0). 
Thus the tangent cone TA(z) does not change when Z varies inside 
a given pseudo-face Fa. 
Since the number of pseudo-faces of A is finite, we conclude 
that there exist an index set a, C I and a subsequence {k') C {k) 
such that xkr E Fa* for every k'. There is no loss of generality in 
assuming that {k') r {k). 
We shall apply the construction due to Contesse which helped 
us to prove Theorem 3.4. 
Since xk E Fa for all k E N, we deduce that 
TA(X" 
= {v E Rn : A,,v > 0, Cv=O) 
(Yk E N). 
Let 
M = {v E Rn : A,,v=O, 
Cv=O). 
Then M is a linear subspace and M C Tn(xk). Let M1 = {v E 
Rn : (v, u) = 0 for every u E M) and let 
where PrMl(.) denotes the orthogonal projection of Rn onto the 
subspace M1. 
We have 

70 
4. Properties of the Solution Sets 
and T ~ ( X ~ )  
= M + K. Let 
From the inclusion xk E loc(P) and from Theorem 3.5 it follows 
that (V f (xk) 
), u) = 0 for every u E M and (V f (xk), v) 2 0 for 
every v E K. This implies that Kt is a face of K. 
Since the polyhedral convex cone K has only a finite number of 
faces, there must exist a face KO of K and a subsequence {kl) C {k) 
such that 
K? = KO Y1E N. 
Xk1 - Xkl 
Consider the sequence of unit vectors { 
). Without loss 
Ilxk1 - xk1 11 
of generality we can assume that 
Set w = {xkl + ttz : t 2 0). 
CLAIM 1. w c S(P). 
Let x = xkl + tz, t > 0. For every v E M + 
cl 1 E N, since 
M + K = T*(xkL) and xk% loc(P), by Theorem 3.5 we have 
Letting k 
oo we deduce that 
(D.z)~v 2 o (YV E M + K). 
(4.3) 
Since M + K = Ta(xkl) and xkl 1 loc(P), by Theorem 3.5 we have 
(DX" + clTv = (V f (xkl), v) 2 0 (Yv E M + K). 
(4.4) 
Combining (4.4) with (4.3) gives 
(of 
(x), V) = (DX + C ) ~ V  
= ( D X ~ ~  
+ C ) ~ V  
+ ~ ( D z ) ~ v  
2 o 
(4.5) 
for all v E M + K. We have x E Fa,. Indeed, since xkl 1 Fa, for 
every 1 E N, it follows that 
AiXk1 - ~
.
~
k
l
 
Aix = Ai(xkl + $2) = Aixkl + t lim 
= bi ('di E a,). 
l-+m IIxkl - xk' 11 

4.1 Unboundedness of the Solution Sets 
For every i E I, we have 
Letting 1 + oo yields 
Aitx 2 0 (b'i E I). 
Consequently, 
Aix = A ~ ( x ~ ~  
+ ttz) = ~~x~~ + tAiZ > bi 
(Vi E I \ a*). 
The equality Cx = d can be established without any difficulty. 
From what has already been proved, we deduce that x E Fa,. This 
implies that TA(x) = M + K. Hence from (4.5) it follows that 
(V f (x) , V) = (Dx + C ) ~ V  2 0 (b'v E TA(x)). 
This shows that x E S(P). (Recall that property (i) in Theorem 3.5 
is equivalent to the existence of a pair (X, p) E Rm x RS satisfying 
system (3.11) .) 
CLAIM 2. w c loc(P). 
Let x = xkl + ttx, t > 0. By Claim 1, x E S(P), that is 
We want to show that 
For each 1 E N, we have 
So, for every v E KO, it holds (Dxkl + c)?'v = (V f (xkl), v) = 0 for 
all 1 E N. Therefore 
Letting k + oo we deduce that 
( D Z ) ~ V  = 0 (Vv E KO). 

72 
4. Properties of the Solution Sets 
Hence 
( V f ( x ) , v )  = ( V f ( x k l ) , v )  
+ t ( ~ z ) ~ v = O  
(Yv E KO). 
This shows that KO C K ~ ( v  
f (2))'. To prove the reverse inclusion, 
let us fix any v E K fl (V f (x))'. On account of (4.3) and (4.4), we 
have 
0 = ( V f ( x ) , v )  = ( V f ( x k l ) , v )  + ~ ( D z ) ~ v ,  
This clearly forces ( V f ( x h ) , v )  = 0. So v E KO whenever v E 
K n (V f (x))'. The equality (4.7) has been established. We now 
show that 
V ~ D V  2 o 
YV E T ~ ( x )  
n (V f (x))'. 
(4.8) 
In the proof of Claim 1, it has been shown that Tn(x) = M + K = 
TA(xk1). 
Besides, from (4.6) we deduce that M c (V f (x))'. Hence, 
from (4.7) and the construction of the sequence {xkl} it follows that 
Since xh E loc(P), Theorem 3.5 shows that 
Combining this with (4.9) we get (4.8). From (4.6), (4.8) and The- 
orem 3.5, we deduce that x E loc(P). This completes the proof of 
Claim 2 and the proof of our theorem. 
Theorem 4.3. The set S ( P )  is unbounded i f  and only if ( P )  has a 
KKT point ray. 
Proof. By definition, x E S ( P )  if and only if there exists ( A ,  p) E 
Rm x R8 such that 
Given a point x E S(P), we set I. = {i E I : Aix = bi), II = 
I \ I. = {i E I : Aix > bi). From the last equality in (4.10) we get 

4.1 Unboundedness of the Solution Sets 
Hence (x, A, p) satisfies the following system 
Fix any I. c I and denote by QIo the set of all (x, A, p) satisfying 
(4.11). It is obvious that QIo is a polyhedral convex set. From what 
has been said it follows that 
where PrRn(x, A, p) := x. Since PrRn(.) : Rn x Rm x RS + Rn is a 
linear operator, PrRn(QIo) is a polyhedral convex set for every I. C 
I .  Indeed, as QIo is a polyhedral convex set, it is finitely generated, 
i.e., there exist vectors xl, . . . , xk, wl, . . . , w1 in Rn x Rm x Rs such 
that 
k 
QIo = {Z = x i = 1  tixi + 
QjwJ : ti > 0 for all i, 
8, > 0 for all j, and Eel ti = 1) 
(see Rockafellar (1970), Theorem 19.1). Then, by the linearity of 
the operator PrRn(.), we have 
Prp(QIo) = {x = c;=, tixi + x i = ,  Qjvj : ti 2 0 for all i, 
0, 2 0 for all j, and c:=, 
ti = 1), 
where xi = PrRTL 
(xi) for a11 i and vi = PrRn (wj) for all j. This shows 
that the set PrRn (QIo) is finitely generated, hence it is a polyhedral 
convex set (see Rockafellar (l97O), Theorem 19.1). 
If S(P) is unbounded then from (4.12) it follows that there exists 
an index set I. c I such that RIo := PrRn(QIo) is an unbounded 
set. Since RIo is a polyhedral convex set, it is an unbounded closed 
convex set. By Theorem 8.4 in Rockafellar (1970)) RIo admits a 
direction of recession; that is there exists a E Rn \ (0) such that 
Taking any 3 E RIo we deduce from (4.12) and (4.13) that 3 + ta E 
S(P) for all t 2 0. Thus we have proved that (P) admits a KKT 
point ray. Conversely, it is obvious that if (P) admits a KKT point 
ray then S(P) is unbounded. 

74 
4. Properties of the Solution Sets 
Remark 4.1. Formula (4.12) shows that S(P) is a union of finitely 
many polyhedral convex sets. 
Let us derive another formula for the KKT point set of (P). For 
each index set a C I, denote by Fa the pseudo-face of A corre- 
sponding to a; that is 
Fa = {x E Rn : A,x = b,, 
Aq,x > bq,, 
Cx = d). 
Since A = u{F, : a C I), we deduce that 
S(P) = U{S(P) n Fa : a c I ) .  
(4.14) 
Lemma 4.1. For every a c I, S(P) n Fa is a convex set. 
Proof. Let a C I be any index set. From the definition of S(P) it 
follows that x E S(P)n Fa if and only if there exist (A, p) E Rm x RS 
such that 
D X - A ~ A - C ~ ~ + C =  
0, 
A,$= b,, 
A, 2 0, 
(4.15) 
&\ax > b~\ff, XI\, = 0, 
Cx = d. 
Let 2, denote the set of all the points (x, A,p) E Rn x Rm x RS 
satisfying the system (4.15). It is clear that 2, is a convex set. From 
what has already been said it follows that S(P) n Fa = PrR"(Zff), 
where PrRn (x, A, p) := x. Since PrRn 
( a )  is a linear operator, we 
conclude that S(P) n Fa is a convex set. 
0 
Note that, in general, the convex sets S(P) n Fa, a c I, in the 
representation (4.14) may not be closed. 
We know that Sol(D, A, c, b) C loc(D, A, c, b) C S(D, Ale, b) 
(see (3.10)). We have characterized the unboundedness of these 
solution sets. The following questions arise: 
QUESTION 1: Is it true that Sol(P) is unbounded whenever loc(P) 
is unbounded? 
QUESTION 2: Is it true that loc(P) is unbounded whenever S(P) 
is unbounded? 
The following example gives a negative answer to Question 1. 
Example 4.1. Consider the problem 
2 
(PI) 
min{ f (x) = -x2 + 2x2 : x = (XI, x2), XI 2 0, x2 2 0). 

4.1 Unboundedness of the Solution Sets 
Denote by A the feasible region of (PI). We have 
Thus loc(Pl) is unbounded, but Sol(Pl) = 0. In order to establish 
the above results, one can argue as follows. Since I = {1,2), the 
constraint set of (PI) is composed by four pseudo-faces: 
Since V f (x) = (0, -2(x2 - I)), by solving four KKT systems of the 
form (4.15) where C ,  d are vacuous, 
we obtain 
From formula (4.14) it follows that 
Since 
lim f(0,x2) = -00 and, for each 2 2  2 0, x = (0,x2) is 
xz-++co 
a feasible vector for (PI), we conclude that Sol(Pl) = 8. For any 
x = (xl, 1) E S(Pl) n FO, we have TA(x) = R2, ( ~ f ( x ) ) '  = R2. 
Then the condition 
which is equivalent to the condition 
cannot be satisfied. By Theorem 3.5, x $! 
loc(Pl). Now, for any 
x = (xl, 0) E S(P1) n F{2}, we have 

76 
4. Properties of the Solution Sets 
(V f (x))' = {V = (v1,v2) E R~ : v2 = 0). 
Condition (4.16), which is now equivalent to the requirement 
is satisfied. Applying Theorem 3.5 we can assert that x E loc(Pl). 
In the same manner we can see that the unique point x = (0,l) of 
the set S(Pl) n Fill does not belong to loc(Pl), while the unique 
point x = (0,O) of the set S(Pl) n 
belongs to loc(Pl). Thus 
we have shown that loc(Pl) = {x E R2 : x1 2 0, x2 = 0). 
The following example gives a negative answer to Question 2. 
Example 4.2. Consider the problem 
Analysis similar to that in the preceding example shows that 
4.2 Closedness of the Solution Sets 
Since S(P) is a union of finitely many polyhedral convex set (see 
(4.12)), it is a closed set. The set Sol(P) is also closed. Indeed, we 
have 
Sol(P) = {x E A : f (x) = v(P)), 
where v(P) = inf{f(x) : x E A). If v(P) is finite then from 
the closedness of A, the continuity of f ,  and the above formula, it 
follows that Sol(P) is closed. If v(P) = +oo then A = 8, hence 
Sol(P) = 8. If v(P) = -oo then it is obvious that Sol(P) = 8. 
Thus we conclude that Sol(P) is always a closed set. 
The following question arises: 
QUESTION 
3: Is it true that loc(P) is always a closed set? 
The following example gives a negative answer to Question 3. 
Example 4.3. Consider the problem 
2 
min{f (x) = -2, + x1x2 : x = (XI, x2), XI L 0, x2 2 0). 
(P3) 
Analysis similar to that in Example 4.1 shows that 
Our next aim is to study the situation where Sol(P) (resp., 
loc(P), S(P)) is a bounded set having infinitely many elements. 

4.3 Bounded Infinite Solution Sets 
77 
4.3 A Property of the Bounded Infinite 
Solution Sets 
Definition 4.2. A line segment wg = {Z + tZ : t t [0, d)), where 
G E Rn \ (0) and 6 > 0, which is a subset of Sol(P) (resp., loc(P), 
S(P)), is called a solution interval (resp., a local-solution interval, 
a KKT point interval) of (P). 
Proposition 4.1. If the set Sol(P) is bounded and infinite, then 
(P) has a solution interval. 
Proof. For each index set a C I, denote by Fa the pseudo-face of 
A corresponding to a. As Sol(P) c A has infinitely many elements 
and A = u{F, : a c I), there must exists some a, C I such that 
the intersection Sol(P) n Fa, has infinitely many elements. For each 
x E Sol(P) n Fa, we have TA(x) = {v E Rn : A,,v 2 0, Cv = 0) 
and, by Theorem 3.5, (V f (x) , v) 2 0 for every v E TA(x). Hence 
T := T*(X) is a constant polyhedral convex cone which does not 
depend on the position of x in the pseudo-face Fa, of A, and 
is a face of T. Since the number of faces of T is finite, from what 
has already been said it follows that there must exist two different 
points x and y of Sol(P) n Fa, such that T," = T;. 
Set To = T,". By 
Lemma 4.1, the intersection S(P) n Fa* is convex. Since x E Sol(P), 
y E Sol(P) and Sol(P) c S(P), it follows that zt := (1 - t)x + t y  
belongs to S(P) n Fa, for every t E [0, 11 . By the remark following 
Theorem 3.5, for every t E (0, I), we have 
Therefore 
Since x E Sol(P) and TA(x) n (V f (x))' = To, from Theorem 3.5 it 
follows that 
v T ~ v 2 0  VvETo. 

78 
4. Properties of the Solution Sets 
We have shown that, for every t E (0, I), zt E S(P) and 
Combining these facts and applying Theorem 3.5 we deduce that 
zt E loc(P). Consider the function cp : [O, 11 -+ R defined by setting 
'p(t) = f (zt) for all t E [0, 11. It is clear that cp is a continuous 
function which is differentiable at each t E (0,l). Since xt is a 
local solution of (P), cp attains a local minimum at every t E (0,l). 
Hence cpl(t) = 0 for every t E (0,l). Consequently, cp(t) is a constant 
function. Since x E Sol(P), we see that zt E Sol(P) for all t E [O,l]. 
Thus [x, y) := ((1 - t)x + ty : t E [ O , l ) )  is a solution interval of 
(P). 
Proposition 4.2. (See Phu and Yen (2001), Theorem 3) If the set 
loc(P) is bounded and infinite, then (P) has a local-solution interval. 
Proof. For each index set a C I, denote by Fa the pseudo-face 
of A corresponding to a. As loc(P) c A is an infinite set and 
A = u{F, : a c I), there must exists some a, c I such that 
the intersection loc(P) n Fa, has infinitely many elements. For each 
x E loc(P) n Fa, we have TA(x) = {v E Rn : Aa,v 2 0, Cv = 0) 
and, by Theorem 3.5, (V f (x) , v) 2 0 for every v E TA (x). Hence 
T := TA(x) is a constant polyhedral convex cone which does not 
depend on the position of x in the pseudo-face Fa, of A, and 
is a face of T. Since the number of faces of T is finite, it follows that 
there must exist two different point x and y of loc(P) n Fa, such that 
T," = T,Y. Set To = T,". By Lemma 4.1, the intersection S(P) n Fa* 
is convex. Since x E loc(P), y E loc(P) and loc(P) c S(P), it 
follows that zt := (1 - t)x + ty belongs to S(P) n Fa, for every 
t E [0, 11. According to the remark following Theorem 3.5, for every 
t E (0,l) we have 
As in the proof of Proposition 4.1, we have 
Since x E loc(P) and TA(x) n (V f (x))' = To, from Theorem 3.5 it 
follows that 
v T ~ v > O  VvETo. 

4.4 Finiteness of the Solution Sets 
Therefore, for every t E (0, I), xt E S(P) and 
On account of these facts and of Theorem 3.5, we conclude that zt 
is a local solution of (P). Thus [x, y) is a local-solution interval of 
(PI. 
Proposition 4.3. If the set S(P) is bounded and infinite, then (P) 
has a KKT point interval. 
Proof. For each index set a c I ,  denote by Fa the pseudo-face 
of A corresponding to a. As S(P) c A is an infinite set and 
A = u{F, : a C I ) ,  there must exists some a, C I such that the 
intersection S(P) n Fa* has infinitely many elements. Hence there 
must exist two different point x and y of S(P) n Fa,. By Lemma 
4.1, the intersection S(P) n Fa, is convex. This implies that [x, y) 
is a KKT point interval of (P). 
0 
4.4 
Finiteness of the Solution Sets 
Theorem 4.4. The following assertions are valid: 
(i) If D is a positive definite matrix and A is nonempty, then (P) 
has a unique solution and it holds Sol(P) = loc(P) = S(P). 
(ii) If D is a negative definite matrix then each local solution of 
(P) is an extreme point of A. In this case, Sol(P) C loc(P) C 
extrA. Hence, if D is a negative definite matrix then the num- 
ber of solutions of (P) (resp., the number of local solutions of 
(P)) is always less than or equal to the number of extreme 
points of A. Besides, if Sol(P) is nonempty then A is a com- 
pact polyhedral convex set. 
(iii) If D is a positive semidefinite matrix then Sol(P) is a closed 
convex set and it holds Sol(P) = loc(P) = S(P). Hence, if 
D is a positive semidefinite matrix then Sol(P) is finite if and 
only if it is a singleton or it is empty. 
Proof. (i) Suppose that the symmetric matrix D is positive definite 
and the set A := { x  E Rn : A x  2 b, C x  = d )  is nonempty. Setting 

80 
4. Properties of the Solution Sets 
we deduce that xTDx 2 ellx[12 for every x E Rn. Fix any xO E A. 
Note that 
1 
f (x) - f (xo) = -(x - x')~D(x - xO) + (DX' + c ) ~ ( x  - xO) 
3 
t 2~11x - xo1I2 - llDxO + cllllx - xO1l. 
The last expression tends to +m as Ilx - xOll -+ +m. Hence there 
exists y > 0 such that 
From (4.17) it follows that (P) cannot have solutions in A\B(xO, y). 
Since A n B(xO, y) # 0 the problem min{ f (x) : x E A n B(xO, 7)) 
possesses a solution 3. By (4.17), 3 E Sol(P). Assume, contrary 
to our claim, that there are two different solutions 3 and jj of (P). 
Since jj - 3 E Ta(3) and 3 E Sol(P), by Theorem 3.1 we have 
(D3 + ~ ) ~ ( j j  
- 3) 2 0. As y # 3 and D is positive definite, we have 
(jj - z ) ~ D ( ~  
- 3) > 0. It follows that 
a contradiction. The equalities Sol(P) = loc(P) = S(P) follow from 
the fact that, under our assumptions, f is a convex function (see 
Proposition 1.2). 
(ii) Let D be a negative definite matrix and 3 x: loc(P). If 
3 $ extra then there exist x E A, y E A, x # y, and t E (0,l) 
such that 3 = (1 - t)x + ty. Since 3 E A, x - 3 E TA(3), y - 3 E 
1 - t  
TA(3), and y - 3 = - - 
(x - 3) , applying Theorem 3.5 we get 
t 
(V f (3) , x - 3) 2 0 and 
Therefore (V f (z), x - 3) = 0. This equality and the assumption 
3 E loc(P) allows us to apply Theorem 3.5 to obtain (x - z ) ~ D ( x  - 
3) 2 0. This contradicts the fact that matrix D is negative definite. 
We have thus proved that loc(P) c extra. Consequently, Sol(P) c 
loc(P) C extrA. We now suppose that Sol(P) # 8. By Corollary 
2.6, 
(v E Rn, Av > 0, Cv = 0) + 
vTDv 2 0. 

4.4 Finiteness of the Solution Sets 
8 1 
Combining this with the negative definiteness of D we conclude that 
Hence A has no directions of recession. By Theorem 8.4 in Rock- 
afellar (1970)) A is a compact set. 
(iii) Let D be a positive semidefinite matrix. By Proposition 
1.2, f is a convex function. Hence Sol(P) is a closed convex set and 
it holds Sol(P) = loc(P) = S(P). 
0 
Example 4.4. Consider problem (P) of the following form 
The matrix D = (i2 
!2) 
corresponding to this problem is neg- 
ative definite. It is easily seen that 
Sol(P) = loc(P) = {(I, 1), (1, -I), (-1, I), (-1, -I)), 
S(P) = S W )  lJ 
{(O,O), 
O)7 ('1 I), (-1, O)1(07 -1)). 
Theorem 4.5. If Sol(P) (resp., S(P), loc(P)) is a finite set, then 
each pseudo-face of A cannot contain more than one element of 
Sol(P) (resp., S(P), loc(P)). Hence, if Sol(P) (resp., S(P), loc(P)) 
is a finite set, then Sol(P) (resp., S(P), loc(P)) cannot have more 
than 2m elements, where m is the number of inequality constraints 
of (PI. 
Before proving this theorem let us establish the following two 
auxiliary results. 
Proposition 4.4. Assume that x E loc(P) n F,, y E S(P) n Fa, 
y # x, where F, is a pseudo-face of A. Then there exists S > 0 such 
that, for every t E (0, S), a(t) := (1 - t)x + t y  is a local solution of 
(PI. 
Proof. Let x E loc(P) n F,, y E S(P) n Fa, y # x ,  where a, c I = 
{I,. . . ,m) and F, = {x E Rn : A,x = b,, Aq,x > b+, 
Cx = d). 
Since x E Fa, we have Ta(x) = {v E Rn : A,v 2 0, Cv = 0). Let 
Then M is a linear subspace and M C Tn(x). Let M1 = {v E Rn 
(v, u) = 0 for every u E M) and let 

82 
4. Properties of the Solution Sets 
where PrM1(.) denotes the orthogonal projection of Rn onto the 
subspace M1. We have 
and Tn(x) = M + K. Since K is a pointed polyhedral convex cone 
(see the proof of Theorem 3.4), according to Theorem 19.1 in Rock- 
afellar (1970), there exists a finite system of generators { z l ,  . . . , 2 9 1  
of K. By convention, if K = (0) then the system is vacuous. In 
the case where that system is not vacuous, we have 
4 
K = { v  = x t j z j  : t j  2 0 for all j = 1,. . . ,q) 
j=1 
Let Q =  (1, ...,q), 
Qo = { j  E Q : ( O f ( x ) , z j )  = 0), Q1 = { j  E Q : ( V f ( x ) , z j )  > 0). 
(4.18) 
Since x E loc(P), we must have 
From this we deduce that Q = Qo U Q1. For every a E F,, let 
Kt = { v  E K : ( O f ( a ) , v )  = 0). For every t E [0,1], we set 
a(t) = (1 - t ) x  + ty. Since x E Fa and y E Fa, it follows that 
a(t) E F, for every t E [0, 11. Consequently, 
TA(a(t)) = Tn(x) = { v  E Rn : A,v 2 0, C v  = 0 )  = M + K. 
(4.19) 
It follows from (4.18) that there exists 6 E ( 0 , l )  such that 
(Of(a(t)),zj) > 0 'dt E ( O , S ) ,  'dj E Q1. 
(4.20) 
For any t E (0, S ) ,  by Lemma 4.1 we have a(t) E S ( P ) .  Therefore 
( O f  (a(t)), v )  2 0 for every v E Tn(a(t)). Combining this with 
(4.20) we deduce that 
K,"'~' C K,T = { v  = 
tjzj : t3 2 0 for all j E QO). 
(4.21) 
j€Qo 
We claim that a(t) E loc(P) for every t E (0,S). Indeed, since 
( O f  (a(t)), 
V )  2 0 for every v E T ~ ( a ( t ) ) ,  
we get 
( O f ( a ( t ) ) , v )  
= 0 'dv E M ,  'dt E (Old). 

4.4 Finiteness of the Solution Sets 
83 
By (4.19) and (4.21), 
As x E loc(P), by Theorem 3.5 we have 
Combining this with (4.22) yields 
Since a(t) E S(P), from the last fact and Theorem 3.5 we conclude 
thata(t)Eloc(P). 
0 
Proposition 4.5. Assume that x and y are two different Karush- 
Kuhn-Tucker points of (P) belonging to the same pseudo-face of A. 
Then the function cp(t) := f ((1 - t)x + ty) is constant on [ O , l ] .  
Proof. Let a c I, x E S(P) n F,, y E S(P) n F,, x # y. For 
every t E [0, I], we define a(t) = (1 - t)x + ty. Since a(t) E F,, it 
follows that TA(a(t)) = {v E Rn : A,v 2 0, Cv = 0). By Lemma 
4.1, a(t) E S(P). Hence (V f (a(t)), v) 2 0 for every v E TA(a(t)). 
Combining these facts we see that (V f (a(t)), v) = 0 for every v E 
M := {v E Rn : A,v = 0, Cv = 0). It is easy to check that 
y - x E M. So we have (V f (a(t)) , y - x) = 0. From this and the 
obvious relation 
we deduce that the function cp is constant on [O,l], as desired. 
Proof of Theorem 4.5. 
We first consider the case where Sol(P) is a finite set. Suppose, 
contrary to our claim, that there exists a pseudo-face F, of A con- 
taining two different elements x, y of Sol(P). By Proposition 4.5, 
the function cp(t) := f ((1 - t)x + ty) is constant on [0, 11. From 
this and the inclusion x E Sol(P) we conclude that whole the seg- 
ment [x, y] is contained in Sol(P). This contradicts the finiteness of 
Sol(P). 
The fact that if S(P) is finite then each pseudo-face of A cannot 
contain more than one element of S(P) follows immediately from 
Lemma 4.1. 

84 
4. Properties of the Solution Sets 
The fact that if loc(P) is finite then each pseudo-face of A cannot 
contain more than one element of loc(P) is a direct consequence of 
Proposition 4.4. 
Actually, in the course of the preceding proof we have established 
the following useful fact. 
Proposition 4.6. If the intersection Sol(P) f l  F, of the solution 
set of (P) with a pseudo-face of A is nonempty, then S(P) n F, = 
Sol(P) CI Fa. 
Combining the last proposition with Lemma 4.1 we obtain the 
following statement. 
Proposition 4.7. The intersection Sol(P)nF, of the solution set of 
(P) with a pseudo-face of A is always a convex set (may be empty). 
In connection with Propositions 4.4 and 4.7, t,he following two 
open questions seem to be interesting: 
QUESTION 4: Let x E loc(P) n Fa, y E S(P) f l  Fa, y # x, where 
Fa is a pseudo-face of A and F, denotes the topological closure of 
Fa. Is it true that there must exist some 6 > 0 such that, for every 
t E (O,6), a ( t )  := (1 - t)x + ty is a local solution of (P)? 
QUESTION 5: Is it true that the intersection loc(P) n F, of the 
local-solution set of (P) with a pseudo-face of A is always a convex 
set? 
4.5 
Commentaries 
The notion of solution ray has proved to be very efficient for study- 
ing the structure of the solution set of linear complementarity prob- 
lems (see, for instance, Cottle et al. (1992)) and affine variational 
inequalities (see, for instance, Gowda and Pang (1994a)). 
This chapter shows that the notions of solution ray and solution 
interval interval are also useful for studying the structure of the 
solution sets of (nonconvex) quadratic programs. 
Lemma 4.1, Propositions 4.2 and 4.3, and Theorems 4.3 and 4.4 
are well known facts. Other results might be new. 

Chapter 5 
Affine Variational 
Inequalities 
In this chapter, the notions of affine variational inequality and lin- 
ear complementarity problem are discussed in a broader context 
of variational inequalities and complementarity problems. Besides, 
a characterization of the solutions of affine variational inequalities 
via Lagrange multipliers and a basic formula for representing the 
solution sets will be given. 
5.1 Variational Inequalities 
Variational inequality problems arise in a natural way in the frame- 
work of optimization problems. 
Let f : Rn -+ 
R be a C1-function and A c Rn a nonempty, 
closed, convex set. 
Proposition 5.1. If 3 is a local solution of the optimization prob- 
lem 
min{f(x) : x E A} 
(5.1) 
then 
( V f ( Z ) , y - 3 ) 2 0  YyEA. 
Proof. Similar to the proof of Theorem 3.1 (i). 

86 
5. Affine Variational Inequalities 
Setting 
we see that (5.2) can be rewritten as 
(4(z),y-Z) 2 0 b'y E A. 
(5.4) 
Definition 5.1. If A C Rn is a nonempty, closed, convex subset 
and 4 : A t Rn is a given operator (mapping) then the problem of 
finding some 3 E A satisfying (5.4) is called a variational inequality 
problem or, simply, a variational inequality (VI, for brevity). It is 
denoted by VI(4, A). The solution set Sol(VI(q5, A)) of VI(q5, A) is 
the set of all 3 E A satisfying (5.4). 
It is easy to check that 3 E Sol(VI(q5, A)) if and only if the 
inclusion 
0 E 4(3) + N A ( ~ ,  
where NA(3) denotes the normal cone to A at Z (see Definition 1.9), 
is satisfied. 
Proposition 5.1 shows how smooth optimization problems can 
lead to variational inequalities. A natural question arises: Given a 
variational inequality VI($, A) with a continuous operator q5 : Rn + 
Rn, can one find a C1-function f : Rn + R such that VI(q5, A) can 
be obtained from optimization problem (5.1) by the above-described 
procedure or not? If such a function f exists, we must have 
$(x) = of(.) 
b'x E A. 
(5.5) 
One can observe that if f is a C2-function then the operator 
q5 : Rn + Rn defined by (5.3) has a symmetric Jacobian matrix. 
Recall that if a vector-valued function q5 : Rn --t Rn has smooth 
components $1, . . . , &  then the Jacobian matrix of q5 at x is defined 
by the formula 
J4W = 

5.1 Variational Inequalities 
8 7 
Since f is assumed to be a C2-function, from (5.3) we deduce that 
for all i, j. This shows that Jq5(x) is a symmetric matrix. 
Proposition 5.2. (See, for instance, Nagurney (1993)) Let A C Rn 
be a nonempty, closed, convex set. If q5 : Rn -t Rn is such a vector- 
aq5i(4 - aq5.d~) for 
valued function with smooth components that - 
- - 
axi 
axi 
all i and j (a smooth symmetric operator), then there exists a C2- 
function f : Rn -t R such that the relation (5.5) is satisfied. This 
means that the variational inequality problem VI($, A) can be re- 
garded as the first-order necessary optimality condition of the opti- 
mization problem (5.1). 
So, we have seen that C2-smooth optimization problems corre- 
spond to variational inequalities with smooth symmetric operators. 
However, when one studies the VI model, one can consider also 
VI problems with asymmetric discontinuous operators. Thus the 
VI model is a mathematical subject which is treated independently 
from its original interpretation as the first-order necessary optimal- 
ity condition of a smooth optimization problem. 
The following simple statement shows that, unlike the solutions 
of mathematical programming problems, solutions of VI problems 
have a local character. From this point of view, VI problems should 
be regarded as generalized equations (see, for instance, Robinson 
(1979, 1981)), but not as something similar to optimization prob- 
lems. 
Proposition 5.3. Let Z E A. If there exists e > 0 such that 
then Z E Sol(VI(q5, A)). 
Proof. Suppose that e > 0 satisfies (5.6). Obviously, for each 
y E A there exists t = t(y) E (0,l) such that y(t) := Z + t(y - Z) 
belongs to AnB(Z,e). By (5.6), 0 5 (+(Z),y(t)-Z) = t($(Z),y-3). 
This implies that (q5(Z), y - 3) 2 0 for every y E A. Hence Z E 
Sol(VI(q5, A)). 
Problem VI(q5, A) depends on two data: the set A and the op- 
erator 4. Structure of the solution set Sol(VI(q5, A)) is decided by 
the properties of the set and the operator. In variational inequality 

88 
5. Affine Variational Inequalities 
theory, the following topics are fundamental: solution existence and 
uniqueness, stability and sensitivity of the solution sets with respect 
to perturbations of the problem data, algorithms for finding all the 
solutions or one part of the solution set. 
The following Hartman-Stampacchia Theorem is a fundamen- 
tal existence theorem for VI problems. It is proved by using the 
Brouwer fixed point theorem. 
Theorem 5.1. (See Hartman and Stampacchia (l966), Kinder- 
lehrer and Stampacchia (1980), Theorem 3.1 in Chapter 1) If A C 
Rn is nonempty, compact, convex and q5 : A -t Rn is continuous, 
then problem VI($, A) has a solution. 
Under suitable coercivity conditions, one can have existence the- 
orems for problems on noncompact convex sets. For example, the 
following result is valid. 
Theorem 5.2. (See Kinderlehrer and Stampacchia (1980), p. 14) 
Let A c Rn be a nonempty, closed, convex set and q5 : A -t Rn a 
continuous operator. If there exists xO E A such that 
MY) - 4(x0), Y - xO) llY - xO1l + +00 as llY l l  -$ +00, Y E A, 
(5.7) 
then problem VI(4, A) has a solution. 
The exact meaning of (5.7) is as follows: Given any y > 0 one 
can find p > 0 such that 
('(') 
- 4(x0)1 - 'O) 
2 y for every y E A satisfying llyll > p. 
IlY - xOll 
It is obvious that if A is compact then, for any xO E A, (5.7) 
is valid. If there exists xO E A such that (5.7) holds then one 
says that the coercivity condition is satisfied. Coercivity conditions 
play an important role in the study of variational inequalities on 
noncompact constraint sets. Note that (5.7) is only one of the most 
well-known forms of coercivity conditions. 
If there exists xO E A and a > 0 such that 
then, surely, (5.7) holds. It is clear that there exists a > 0 such 
that 

5.1 Variational Inequalities 
89 
then (5.8) is satisfied. 
Definition 5.2. If there exists a > 0 such that (5.9) holds then 
q5 is said to be strongly monotone on A. If the following weaker 
conditions 
and 
MY) - $(x),Y - 4 2 0 YX E A, YY E A, 
(5.11) 
hold, then q5 is said to be strictly monotone on .A and monotone on 
A, respectively. 
Example 5.1. Let A c Rn is a nonempty, closed, convex set. Let 
D E Rnxn and c E Rn. If matrix D is positive definite then the 
operator q5 : A + Rn defined by q5(x) = D x  + c, x E A, is strongly 
monotone on A. In this case, it is easily verified that a > 0 required 
for the fulfilment of (5.9) can be defined by setting 
Likewise, if D is positive semidefinite then the formula $(x) = Dx+ 
c, x E A, defines a monotone operator. 
Proposition 5.4. The following statements are valid: 
(i) If q5 is strictly monotone on A then problem VI(q5, A) cannot 
have more than one solution; 
(ii) If q5 is continuous and monotone on A then the solution set of 
problem VI(q5, A) is closed and convex (possibly empty). 
For proving the second statement in the preceding proposition 
we shall need the following useful fact about monotone VI problems. 
Lemma 5.1. (The Minty Lemma; Kinderlehrer and Stampacchia 
(1980), Lemma 1.5 in Chapter 3) If A C Rn is a closed, convex 
set and q5 : A -t Rn is a continuous, monotone operator, then 
3 E Sol(VI((q5, A)) zf and only if 3 E A and 
Proof. Necessity: Let 3 E Sol(VI((q5, A)). By the monotonicity of 
q5, we have 
MY) - q5(%Y - 3) 2 0 YY E A. 

90 
5. Affine Variational Inequalities 
Combining this with (5.4) yields 
Property (5.12) has been established. 
Suficiency: Suppose that IF. E A and (5.12) is satisfied. Fix any 
y E A. By the convexity of A, y(t) := Z + t(y - 3) belongs to A for 
every t E (0,l). Substituting y = y(t) into (5.12) gives 
This implies that 
($(3 + t(y - 3),y - 3) 2 0 'vt E (0,l). 
Letting t --t 0, by the continuity of q5 we obtain (q5(3), y - Z) 2 0. 
Since the last inequality holds for every y E A, we conclude that 
z E Sol(VI((q5, A)). 
Proof of Proposition 5.4. 
(i) Suppose, contrary to our claim, that q5 is strictly monotone 
on A but problem VI(q5, A) has two different solutions 3 and y. 
Then (q5(~), 
jj - Z) 2 0 and (q5(jj), 3 - y) 2 0. Combining these 
inequalities we get ($(Z) - q5(jj), y - 3) 2 0. The last inequality 
contradicts the fact that ($(y) - $(Z), y - Z) > 0. 
(ii) Assume that q5 is continuous and monotone on A. For every 
y E A, denote by fl(y) the set of all 3 E A satisfying the inequality 
($(y), y - Z) 2 0. It is clear that fl(y) is closed and convex. From 
Lemma 5.1 it follows that 
Hence Sol(VI((q5, A)) is closed and convex (possibly empty). 
From Theorem 5.2 and Proposition 5.4(i) it follows that if A 
is nonempty and q5 : A --t Rn is a continuous, strongly monotone 
operator then problem VI($, A) has a unique solution. 
In the next section, we will consider variational inequality prob- 
lems in the case where the constraint set A is a cone. 

5.2 Complementarity Problems 
91 
5.2 
Complementarity Problems 
The following fact paves a way to the notion of (nonlinear) comple- 
mentarity problem. 
Proposition 5.5. 
If A is a closed convex cone, then problem 
VI($, A) can be rewritten equivalently as follows 
where A+ = { J  E Rn : (c, v) 2 0 Vv E A) denotes the positive 
dual cone of A. 
Proof. Let 5 be a solution of (5.4). For any v E A, since A is a 
convex cone, we have 3 + v E A. From (5.4) we deduce that 
1 
So $(z) E A+. Furthermore, since -5 E A and 23 E A, by (5.4) 
2 
we have 
1 
1 
0 5 ($(2), -5 - 5) = --($(3), 2) 
2 
2 
and 
0 5 ($(2), 22 - 5) = (q5(z), 3). 
Hence ($(z), 5) = 0. We have proved that (5.13) is satisfied. 
Now, let 3 be such that (5.13) holds. For every y E A, since 
($(5), 3) = 0 and $(3) E A+, we have 
This shows that 2 E Sol(VI((q5, A)). 
0 
Definition 5.3. Problem (5.13) where A C Rn is a closed convex 
cone and $ : Rn -t Rn, is denoted by NCP(q5, A) and is called the 
(nonlinear) complementarity problem defined by q5 and A. 
Since complementarity problems are variational inequality prob- 
lems of a special type, existence theorems for VI problems can be 
applied to them. 
5.3 Affine Variational Inequalities 
By Theorem 3.1, if 3 is a local solution of the quadratic program 

92 
5. Affine Variational Inequalities 
where M E RzXn, q E Rn, and A c Rn is a polyhedral convex set, 
then (MZ + q, y - 2) 2 0 for every y E A. This implies that Z is a 
solution of the problem VI(q5, A) where $(x) = Mx + q is an aSfine 
operator having the constant symmetric Jacobian matrix M. 
Definition 5.4. Let M E RnXn, q E Rn. Let A c Rn be a 
polyhedral convex set. The variational inequality problem 
Find Z E A such that (MZ + q, y - 3) 2 0 Yy E A 
(5.15) 
is called the aSfine variational inequality (AVI, for brevity) problem 
defined by the data set {M, q, A) and is denoted by AVI(M, q, A). 
The solution set of this problem is abbreviated to Sol(AVI(M, q, A)). 
The remarks given at the beginning of this section show that 
quadratic programs lead to symmetric AVI problems. Later on, in 
the study of AVI problems we will not restrict ourselves only to the 
case of the symmetric problems. 
The following theorem shows that solutions of an AVI problem 
can be characterized by using some Lagrange multipliers. 
Theorem 5.3. (See, for instance, Gowda and Pang (1994b), p. 
834) Vector Z E Rn is a solution of (5.15) where A is given by the 
formula 
A = {x E Rn : Ax > b) 
(5.16) 
with A E Rmxn, b E Rm, if and only if there exists X = (I1,. . . , 5,) 
E 
Rm such that 
M Z - A ~ X + ~ = O ,  
AZ 2 b, 5 2 0, 
(5.17) 
J T ( ~ Z  
- b) = 0. 
Proof. The necessity part of this proof is very similar to the proof 
of Theorem 3.3. As in the preceding chapters, we denote by Ai the 
i-th row of A and by bi the i-th component of vector b. We set 
ai = AT for every i = 1,. . . , m. Let 3 E Sol(AVI(M, q, A)). Define 
I = (1 ,..., m), I. = {i E I : (ai,%) = bi) a n d I I  = {i E I : 
(ai, 2) > bi). For any v E Rn satisfying 
(ai, v) 2 0 for every i E 10, 
it is easily seen that there exists 61 > 0 such that (ai, Z + tv) 2 bi 
for every i E I and t E (0, &). Substituting y = Z + tv, where 
t E (0, dl), into (5.15) gives (Mz + q, v) 2 0. Thus 

5.3 Affine Variational Inequalities 
for any v E Rn satisfying 
(-ai, v) 5 0 for every i E lo. 
By the Farkas Lemma (see Theorem 3.2), there exist non-negative 
real numbers Xi (i E Io) such that 
Put Xi = 0 for all i E II and X = (XI,. . . , X,). 
Since ai = AT for 
every i E I, from (5.18) we obtain the first equality in (5.17). Since 
Z E E(A, b) and X i ( ~ i ~ -  
bi) = 0 for each i E I, the other conditions 
in (5.17) are also satisfied. 
In order to prove the sufficiency part, suppose that there exists 
5 = (XI,. . . , Am) E Rm such that (5.17) holds. Then, for any y E A, 
one has 
(Mz + q, y - 3) = (ATX, - Z) = (1, (Ay - b) - (A2 - b)) 
= X T ( ~ y  
- b) + X T ( ~ 5  
- b) 
= XT(Ay - b) 2 0. 
This shows that 3 is a solution of (5.15). The proof is complete. 
0 
One can derive from Theorem 5.3 the following two corollaries, 
one of which is applicable to the situation where A has the repre- 
sent at ion 
A = { x g R n :  A z > b ,  ~ 2 0 )  
(5.19) 
and the other is applicable to the situation where A has the repre- 
sentation 
A = {x E Rn : Ax 2 b, Cx = d). 
(5.20) 
Here A E Rmxn, b E Rm, C E RSXn, and d E RS 
Corollary 5.1. Vector 1 E Rn is a solution of (5.15) where A is 
given by (5.19) if and only if there exists X = (XI,. . . , im) 
E Rm 
such that 

94 
5. Affine Variational Inequalities 
Proof. Define matrix A E  R ( ~ + ~ ) ~ ~  
and vector b E  Rm+n as in the 
proof of Corollary 2.5. Then problem (5.15), where A is given by 
(5.19), is equivalent to the problem 
Find x: E A := { x  E  Rn : A x  > b) such that 
( ~ x :  
+ q, y - Z )  2 0 Vy E A. 
Applying Theorem 5.3 to this AVI problem we deduce that Z is a 
solution of the latter if and only if there exists ;\ = (XI,. . . , Am+,) E 
Rm+n such that 
Taking 1 = ( X I ,  . . . , Xm) where Xi = Xi for every i E  {I, . . . , m), we 
can obtain the desired properties in (5.21) from the last ones. 
Corollary 5.2. Vector 
E Rn is a solution of (5.15) where A is 
given by (5.20) if and only if there exist X = (Xl,. . . , Xm) E Rm and 
p = ( p l ,  . . . , ps) E RS such that 
M Z - A ~ X - C ~ ~ + ~ = O ,  
Ax: 2 b, Cz= dl 
X > 0 ,  
(5.22) 
X T ( ~ z  
- b) = 0. 
Proof. Define I?. E R("+~")~" and b E Rm+2S as in the proof of 
Corollary 2.6. Then problem (5.15), where A is given by (5.20), is 
equivalent to the problem 
Find Z E  := { x  E Rn : A x  2 b) such that 
( M x : + q , y - 3 )  2 0  V ~ E A .  
Applying Theorem 5.3 to this AVI problem we deduce that 5 is a 
solution of the latter if and only if there exists ;\ = ( X I , .  . . , 
E 
Rm+2S such that 
Taking X = ( X l , .  . . , Xm) and p = ( P I , .  . . , ps) where Xi = Xi for ev- 
ery i E { I , .  . . , m) and & = Xm+j - Xm+s+j for every j E  ( 1 , .  . . , s ) ,  
we can obtain the properties stated in (5.22) from the last ones. 
0 
Unlike the solution set and the local solution set of a nonconvex 
quadratic program, the solution set of an AVI problem has a rather 
simple structure. 

5.3 Affine Variational Inequalities 
95 
Theorem 5.4. The solution set of any afine variational inequality 
problem is the union of finitely many polyhedral convex sets. 
Proof. This proof follows the idea of the proof of formula (4.12). 
Consider a general AVI problem in the form (5.15). Since A is a 
polyhedral convex set, there exists m E N, A E RmXn, b E Rm such 
that A = {x E Rn : Ax 2 b}. According to Theorem 5.3, x E 
Sol(AVI(M, q, A)) if and only if there exists X = (XI,. . . , Am) E Rm 
such that 
M X - A ~ X + ~ = O ,  
Ax 
b, 
X 2 0, 
(5.23) 
X ~ ( A X  
- b) = 0. 
Let I = {I,. . . , m). Given a point x E Sol(AVI(M, q, A)), we set 
I. = {i E I : Aix = bi), Il = I \ I. = {i E I : Aix > bi). From the 
last equality in (5.23) we get 
Hence (x, A) satisfies the system 
Fix any subset I. c I and denote by QIo the set of all (x, A) satisfy- 
ing (5.24). It is obvious that QIo is a polyhedral convex set. From 
what has been said it follows that 
where PrRn (x, A) := x. Since PrRn (.) : Rn x Rm + Rn is a linear 
operator, for every I. C I, PrRn(QIo) is a polyhedral convex set. 
From (5.25) it follows that Sol(AVI(M, q, A)) is the union of finitely 
many polyhedral convex sets. 
Definition 5.5. A half-line w = {Z + tij : t 2 O}, where 3 E 
Rn \ {0}, which is a subset of Sol(AVI(M, q, A)), is called a solution 
ray of problem (5.15). 
Definition 5.6. A line segment (JJ = {Z + tij : t E [0, S)), where 
ij E Rn \ (0) and S > 0, which is a subset of Sol(AVI(M, q, A)), is 
called a solution interval of problem (5.15). 
Corollary 5.3. The following statements hold: 

96 
5. Affine Variational Inequalities 
(i) The solution set of any afine variational inequality is a closed 
set (possibly empty); 
(ii) If the solution set of an afine variational inequality is un- 
bounded, then the problem has a solution ray; 
(iii) If the solution set of an afine variational inequality is infinite, 
then the problem has a solution interval. 
Proof. Statement (i) follows directly from formula (5.25) because, 
for any I. C I, the set PrRn (QIo), being polyhedral convex, is closed. 
If Sol(AVI(M, q, A)) is unbounded then from (5.25) it follows that 
there exists an index set I. c I such that 
is an unbounded set. Since StIo is a polyhedral convex set, it is 
an unbounded closed convex set. By Theorem 8.4 in Rockafellar 
(1970), StIo admits a direction of recession; that is there exists .lj E 
Rn \ (0) such that 
x + tU E RIo'dx E StIo, 'dt 2 0. 
(5.27) 
Taking any 3 E StIo we deduce from (5.25) and (5.27) that Z + tU E 
Sol(AVI(M, q, A)) for all t 2 0. Thus we have proved that problem 
(5.15) has a solution ray. If Sol(AVI(M, q, A)) is infinite then from 
(5.25) we deduce that there is an index set I. C I such that the 
polyhedral convex set StIo defined by (5.26) is infinite. Then there 
must exist two different points x E StIo and y E StI0. It is clear that 
the set [x, y) := {x + t(y - x) : t E [0, 1)) is a solution interval of 
(5.15). 
0 
Using Theorem 5.4 one can obtain a complete characterization 
for the unboundedness property of the solution set of an AVI prob- 
lem. Let us consider problem (5.15) where A is given by (5.16) and 
introduce the following notations: 
S(A) = {v E Rn : Av 2 0), 
S(A)+ = {x E Rn : xTv 2 0 'dv E S(A)), 
[(M) = {x E Rn : xTMx = 0). 
Note that 6(A) and {v E Rn : Av E 6(A)+) are polyhedral convex 
cones, while Q(M) is, in general, a nonconvex closed cone. Note also 
that 6(A) = Of A and S(A)+ = (O+A)+. 

5.3 Affine Variational Inequalities 
97 
Theorem 5.5 (cf. Gowda and Pang (1994a)). The solution set 
of (5.15) is unbounded if and only if there exzsts a pair (v,uO) E 
Rn x Rn, v # 0, u0 E Sol(AVI(M, q, A)), such that 
(i) v E 6(A), Mv E b(A)+, v E t(M); 
(ii) (Mu0 + q ) T ~  
= 0; 
(iii) (Mu, y - uO) 2 0 'dy E A. 
Proof. Suficiency: Suppose that there is a pair (v, uO) E Rn x Rn, 
v # 0, u0 E Sol(AVI(M, q, A)), such that (i)-(iii) are fulfilled. Let 
xt = u0 + tv, t > 0. Given any y E A, we deduce from (i)-(iii) that 
This implies that xt E Sol(AVI(M, q, A)) for every t > 0. Hence the 
solution set is unbounded. 
Necessity: Suppose that the set Sol(AVI(M, q, A)) is unbounded. 
By (5.25), there exists I. C I such that the set R1,, defined by (5.26) 
is unbounded. Applying Theorem 8.4 from Rockafellar (1970), we 
can assert that there exist v E Rn, v # 0, and u0 E RI, such that 
u0 + tv E RIo c Sol(AVI(M, q, A)) 'dt > 0. 
(5.28) 
Since A(uO + tv) 2 b for every t > 0, we can deduce that Av 2 0. 
This means that v E b(A). By (5.28), we have 
(M(u' + tv) + q, y - (uO + tv)) 2 0 'dy E A. 
(5.29) 
Fixing any y E A, we deduce from (5.29) that 
Therefore 
(Mu, -v) > 0. 

98 
5. Affine Variational Inequalities 
Substituting y = u0 + t2v, where t > 1, into (5.29) and dividing the 
inequality by t(t2 - t ) ,  we obtain 
Letting t + +oo yields (Mu, v )  2 0. Combining this with (5.30) 
we get 
(Mu, v )  = 0. 
(5.31) 
This shows that v E l ( M ) .  Substituting y = u0 into (5.29) and 
taking account of (5.31) we have (Mu0 + q,v) 5 0. Substituting 
y = u0 + t2v, where t > 1, into (5.29) and using (5.31) we can deduce 
that (Mu0 + q, v )  2 0. This and the preceding inequality shows that 
(ii) is satisfied. By (5.29), (5.31) and (ii), for every y E A we have 
for all t > 0. This implies that the inequality (Mu, - uO) < 0 must 
be false. So we have 
Substituting y = u0 + w, where w E 6(A), into the inequality in 
(5.32) we deduce that (Mu, w) 2 0 for every w E &(A). This means 
that M v  E 6(A)+. We have thus shown that all the three inclusions 
in (i) are valid. The proof is complete. 
Several simple sufficient conditions for (5.15) to have a compact 
solution set can be obtained directly from the preceding theorem. 
Corollary 5.4. Problem (5.15) has a compact solution set (possibly 
empty) if one of the following conditions is satisfied: 
(71) the cone l ( M )  consists of only one element 0; 
( 7 2 )  the intersection of the cones l ( M )  and {v E Rn : Mv E 
S(A)+) consists of only one element 0; 
(y3) the intersection of the cones l ( M ) ,  {v E Rn : M v  E S(A)+) 
and 6(A), consists of only one element 0. 
Examples given in the next section will show how the above 
sufficient conditions can be used in practice. 

5.4 Linear Complementarity Problems 
99 
5.4 Linear Complementarity Problems 
We now consider a special case of the model (5.13) which plays a 
very important role in theory of finite-dimensional variational in- 
equalities and complementarity problems (see, for instance, Harker 
and Pang (1990) and Cottle et al. (1992)). 
Definition 5.7. Problem (5.13) with A = Rn+ and $(x) = Mx + q 
where M E Rnxn and q E Rn, is denoted by LCP(M,q) and is 
called the linear complementarity problem defined by M and q. The 
solution set of this problem is denoted by Sol(M, q). 
We can write LCP(M, q) as follows 
Thus LCP problem is a special case of the NCP problem where 
A = Rn+ and q5 is an affine operator. 
If 3 is a local solution of quadratic program (3.1) where A = R;, 
then 5 E R3 and, by Theorem 3.1, 
This amounts to saying that 3 is a solution of the linear comple- 
mentarity problem LCP(D, c) defined D and c. 
By Corollary 3.1, if 3 is a local solution of the quadratic program 
(2.26) then there exists X = (XI,. . . , Am) E Rm such that (3.8) holds. 
Setting 
M =  
we have M 
verified that 
E ~(n+m) 
x (n+m) , q E Rn+m, 2 E Rn+m. It is easily 
(3.8) is equivalent to the system 
Thus (3.8) can be interpreted as a LCP problem. 
Definition 5.8. If A is a polyhedral convex cone and there exist 
M E Rnxn, q E Rn, such that $(x) = Mx + q for every z E A, then 
(5.13) is said to be a generalized linear complementarity problem. It 
is denoted by GLCP(M, q, A). 
From the above definition we see that generalized linear comple- 
mentarity problems are the AVI problems of a special type. Com- 
paring Definition 5.8 with Definition 5.7 we see at once that the 

100 
5. Affine Variational Inequalities 
structure of GLCP problems is very similar to that of LCP prob- 
lems. This explains why many results concerning LCP problems 
can be extended to GLCP problems. 
It is easily seen that if in (5.15) one chooses A = R1;: then 
one obtains the linear complementarity problem LCP(M, q). Hence 
linear complementarity problems are the AVI problems of a special 
type. In this book, as a rule, we try first to prove theorems (on the 
solution existence, on the solution stability, etc.) for AVI problems 
then apply them to LCP problems. 
Theorem 5.5 can be specialized for LCP problems as follows. 
Proposition 5.6. (See Yen and Hung (2001), Theorem 2) The 
solution set of (5.33) is unbounded if and only if there exists a pair 
(v, uO) E Rn x Rn, v # 0, u0 E Sol(M, q), such that 
(ii) (Mu0 + q)'v 
= 0; 
(iii) (Mu, uO) = 0. 
Corollary 5.4 is specialized for LCP problems as follows. 
Corollary 5.5. Problem (5.33) has a compact solution set (possibly 
empty) if one of the following conditions is satisfied: 
(yl) the cone Q(M) consists of only one element 0; 
(y2) the intersection of the cones Q(M) and {v E Rn : Mv 2 0) 
consists of only one element 0; 
(y3) the intersection of the cones Q(M), {v E Rn : Mv 2 0) and 
R"+ consists of only one element 0. 
Example 5.2. (See Yen and Hung (2001)) Consider problem (5.33) 
A direct computation shows that the intersection of the cones Q(M), 
{v : Mv > 0) and {v : v > 0), consists of only 0. By Corollary 
5.5, Sol(M, q) is a compact set. 
Observe that M in the above example is a nondegenerate matrix, 
so from the theory in Chapter 3 of Cottle et al. (1982), it follows 
that Sol(M, q) is a finite set. By definition, M = (aij) is said to be 

5.5 Commentaries 
101 
a nondegenerate matrix if, for any nonempty subset a C (1, . . . , n), 
the determinant of the principal submatrix Ma, consisting of the 
elements aij (i E a, j E a) of M is nonzero. 
Example 5.3. (See Yen and Hung (2001)) Consider problem (5.13) 
with 
A direct computation shows that the intersection of the cones Q(M), 
{v : Mv 2 0) and {v : v 2 O), is.the set {v = (0,v2) E R2 : v2 L 
0). For verifying condition (ii) in Proposition 5.6, there is no loss 
of generality in assuming that v = (0,l). It is easy to show that 
there is no u0 > 0 such that (Mu0 + q ) T ~  
= 0 and (Mu, uO) = 0. 
By Proposition 5.6, Sol(M, q) is a compact set. 
Example 5.4. (See Yen and Hung (2001)) Consider problem (5.13) 
with 
The intersection of the cones Q(M), {v : Mv 2 0) and {v : v 2 
0), is the set {v = (0, v2) E R2 : v2 2 0). It is easy to show 
that conditions (i)-(iii) in Proposition 5.6 are satisfied if we choose 
v = (0,l) and u0 = (1,O). By Proposition 5.6, Sol(M,q) is an 
unbounded set. 
5.5 
Commentaries 
Problem (5.4) is finite-dimensional. Infinite-dimensional VI prob- 
lems are not studied in this book. Systematic studies on infinite- 
dimensional VI problems with applications to mathematical physics 
(obstacle problems, etc.) can be found, for example, in Kinderlehrer 
and Stampacchia (l98O), Rodrigues (1987). 
The important role of finite-dimensional VI problems and com- 
plementarity problems in mathematics and in mathematical appli- 
cations is well known (see, for instance, Harker and Pang (1990), 
Nagurney (1993), and Patriksson (1999)). 
A comprehensive theory on LCP problems was given by Cottle, 
Pang and Stone (1992). Several key results on LCP problems have 
been extended to the case of AVI problems. 

5. Affine Variational Inequalities 
The first volume of the book by Facchinei and Pang (2003) de- 
scribes the basic theory on finite-dimensional VI problems and com- 
plementarity problems, while its second volume concentrates on it,- 
erative algorithms for solving these problems. The book aims at 
being an enduring reference on the subject and at providing the 
foundation for its continued growth. 
Robinson (see Robinson (l979), Theorem 2, and Robinson (l98l), 
Proposition 1) obtained two fundamental theorems on Lipschitz 
continuity of the solution map in general AVI problems, which he 
called the linear generalized equations. In Chapter 7 we will study 
these theorems. 

Chapter 6 
Solution Existence for 
Affine Variational 
Inequalities 
In this chapter, some basic theorems on the solution existence of 
affine variational inequalities will be proved. Different conditions 
on monotonicity of the linear operator represented by matrix M 
and the relative position of vector q with respect to the constraint 
set A and the recession cone O+A will be used in these theorems. 
As in the preceding chapter, we denote the problem 
Find Z E A  suchthat ( M Z + q , y - Z ) 2 0  V y E A  
(6.1) 
by AVI(M, q, A). Here M E Rnxn, q E Rn, and A is a nonempty 
polyhedral convex set in Rn. 
6.1 Solution Existence under Monoto- 
nicity 
Consider problem (6.1). Since A is a polyhedral convex set, there 
exist m E N, A E Rmxn and b E Rm such that 
Theorem 6.1. (See Gowda and Pang (1994a), p. 432) If the 
following two conditions are satisfied 
(i) there exists Z E A such that ( M Z + q ) T ~  
2 0 for every v E O+A; 

104 
6. Solution Existence for AVIs 
(ii) ( y  - X ) ~ M ( ~  
- x )  2 0 for all x E A and y E A ;  
then the solution set Sol(AVI(M, q, A)) is nonempty. 
Let 
where I denotes the unit matrix in RmXm. Let 
where 
Consider the following auxiliary quadratic program 
Lemma 6.1. The set A is nonernpty if and only if there exists 
Z E A such that (MZ + q)Tv 2 0 for every v E O+A. 
Proof. Necessity: If b # 0 then there exists f = (t) E Rn+" 
such that 
M Z - A ~ ~ + ~ = O ,  
A Z Z : ~ ,  
X 2 0 .  
(6.4) 
Let v E Ot A. By (6.2), we have Av 2 0. From (6.4) we deduce that 
Hence (MZ + q ) T ~  
= xTAv 2 0. 
Suficiency: Suppose that there exists Z E A such that ( M z  + 
q ) T ~  2 0 for every v E O f  A = 6(A). Consider the following linear 
program 
min{cTy : y E A ) ,  
(6.5) 
where c := MZ + q. From our assumption it follows that A # 0 and 
( M z  + q ) T ~  2 0 whenever v E Rn, Av 2 0. By Theorem 2.2, (6.5) 

6.1 Solution Existence under Monotonicity 
105 
has a solution. According to Theorem 3.3, there exists X t Rm such 
that 
- A ~ X + C = O ,  
X 2 0 .  
(6.6) 
Since It. E A, we have AZ 2 b. Combining this with (6.6) we deduce 
that i := (;) 
belongs to 6. 
So 6 # 0. 
0 
Lemma 6.2. If there exists Z E A such that (M2 + q)Tv 2 0 
for every v E O+A then the auxiliary quadratic program (6.3) has a 
solution. 
Proof. By Lemma 6.1, from the assumption it follows that 6 is 
nonempty. Let z = (;) 
t 6 We have 
So f (z) is bounded from below on 6. 
By the Frank-Wolfe Theorem 
(see Theorem 2.1), (6.3) has a solution. 
0 
Proof of Theorem 6.1. 
By assumption (i) and by Lemma 6.2, the auxiliary quadratic 
problem (6.3) has a solution i = ( )  
Hence, by Corollary 3.2 
there exist Lagrange multipliers 0 = (::) 
t RZm and 
t Rn such 

106 
that 
6. Solution Existence for AVIs 
\
,
 
A 0 
( o  I )  (F) 2 (;), 0 2 0 ,  
OT [(t Y )  (t ) - (;)I 
= O. 
This system can be written as the following one 
MT AT 
(Y -iF) (t) 
+ ( - A  
0 ) (F) - (tT ;) (;t) 
-(s).+ 
(a) 
= o  
Ax: > b, X > 0, o1 2 0, o2 2 0, 
(01)T(A5 - b) = 0 ,  (02)TX = 0. 
In its turn, the latter is equivalent to the system (6.7)-(6.10) below: 
From (6.7) and the inclusion 2 = (:) 
E i\ it follows that 
M T ( %  - p) = AT(# - X ) .  
(6.11) 
From (6.8) it follows that 
A(z - p) = Ax: - e2 - b. 
(6.12) 
=o + ( o ~ ) ~ X  
- X T ( ~ z  - b) 
+ 
=o 
= 
- X T ( ~ z  
- b). 

6.1 Solution Existence under Monotonicity 
107 
Hence, by virtue of (6.9), we have 
(3 - p,)?'MT(z - p,) = -(01)'02 - X T ( ~ l t :  - b) < 0. 
(6.13) 
From (6.8) it follows that 
So p, E A. Since 3 E A, we can deduce from assumption (ii) that 
(%-- p,)?'MT (3 - p,) > 0. Combining this with (6.9) and (6.13) gives 
XT(~z 
- b) = 0. Since (f) E 6, 
MP - A ~ X  
+ q = 0. Thus we have 
shown that 
M ~ - A ~ X + ~ = O ,  
A3 2 bb, X 2 0, 
X'(A3 - b) = 0. 
Then, according to Theorem 5.3, 5 E Sol(AVI(M, q, A)). 
0 
Assumption (ii) is crucial for the validity of the conclusion of 
the above theorem. It is easily seen that (ii) is equivalent to the 
requirement that the operator q5 : A + Rn defined by setting $(x) = 
Mx + q is monotone on A (see Definition 5.2). 
Definition 6.1 (cf. Cottle et al. (1992), p. 176). By abuse of 
terminology, we say that matrix M E Rnxn is monotone on a closed 
convex set A c Rn if the linear operator corresponding to M is 
monotone on A, that is 
Matrix M is said to be copositive on A if 
If M is copositive on R v h e n  one simply says that M is a copositive 
matrix. Matrix M is said to be strictly copositive on A if 
Remark 6.1. Monotonicity implies copositivity. But the reverse 
implication, in general, is false. Indeed, if (6.14) holds and if A is 
nonempty then, for any 3 E A and v E O+A, we have 

108 
6. Soh tion Existence for AVIs 
Hence M is copositive on A. To show that in general copositivity 
does not imply monotonicity, we consider the following example. 
Let 
For every v E O'A 
= R: 
we have V ~ M V  2 0. So M is copositive 
on A. But M is not monotone on A. Indeed, choosing x = (0,l) 
and y = ( l , O ) ,  we see that 
Remark 6.2. If intA # 0 then matrix M is monotone on A if 
and only if M is positive semidefinite. Indeed, it is clear that if 
M E Rnxn is a positive semidefinite matrix then, for any nonempty 
closed convex set A c Rn, M is copositive on A. On the other 
hand, if intA # 0 then there exists 3 E A and E > 0 such that 
B(3, E) C A. For every z t Rn there exists t > 0 such that y := 
17: + tz t B(3, E) C A. Then we have 
Hence zTMz 2 0 for every z t Rn 
Remark 6.3. It is clear that if M is strictly copositive on A then 
it is copositive on A. The converse is not true in general. For 
example, if A = R: 
and M = ( i) , then M is copositive but 
not strictly copositive on A. Indeed, choosing = (0,l) we see that 
v E O+A \ (0) = R: \ (0) but vTMv = 0. 
We now consider a simple example to see how Theorem 6.1 can 
be used. 
Example 6.1. Let 
Theorem 6.1 can be applied to this problem. Indeed, since M is 
monotone on A, it suffices to show that there exists 3 E A such 
that (M3 + q ) T ~  
2 0 for every v E O+A. If q1 < 0 then ? = 
(-ql, 0) satisfies the last condition. If ql > 0 then 3 = (0,O) satisfies 

6.2 Solution Existence under Coposi tivi ty 
109 
that condition. Further investigation on the problem shows that 
Sol(AVI(M, q, A)) = {(-ql,O)) if ql < 0 and Sol(AVI(M, q, A)) = 
((0,O)) if 91 2 0. 
From Theorem 6.1 it is easy to deduce the following result. 
Theorem 6.2. (See Gowda and Pang (1994a), Theorem 1) If M 
is a positive semidefinite matrix and there exists Z L: A such that 
(MZ + q ) T ~  2 0 for every v L: O+A, then problem (6.1) has a 
solution. 
Corollary 6.1. (See Cottle et al. (1982), Theorem 3.1.2) Suppose 
that M is a positive semidefinite matrix. Then the linear comple- 
mentarity problem LCP(M,q) has a solution if and only i f  there 
exists 5 such that 
5 2 0 ,  MZ+q>O. 
(6.17) 
Proof. Put A = Rn+. Note that (M5 + q)Tv 2 0 for every v L: 
O+A = Rn+ for some 3 L: A if and only if there exists 3 satisfying 
(6.17). Applying Theorem 6.2 we obtain the desired conclusion. 
0 
In the terminology of Cottle et al. (1992), if there exists 3 L: Rn 
satisfying (6.17) then problem LCP(M, q) is said to be feasible. The 
set of all 3 L: En satisfying (6.17) is called the feasible region of 
that problem. Corollary 6.1 asserts that a linear complementarity 
problem with a positive semidefinite matrix M is solvable if and only 
it is feasible. 
6.2 
Solution Existence under Copositiv- 
ity 
In this section we obtain some existence theorems for the AVI prob- 
lem (6.1) where M is not assumed to be monotone on A. It is 
assumed only that M is copositive on A. 
We first establish an existence theorem under strict copositivity. 
Theorem 6.3. If matrix M is strictly copositive on a nonempty 
polyhedral convex set A then, for any q E Rn, problem AVI(M, q, A) 
has a solution. 
The following auxiliary fact shows that the strict copositivity as- 
sumption in the above theorem is, in fact, equivalent to a coercivity 
condition of the form (5.7). 

110 
6. Solution Existence for AVIs 
Lemma 6.3. Matrix M E RnXn is strictly copositive on a nonempty 
polyhedral convex set A C Rn zf and only if there exists xO E A such 
that 
(My - MxO, y - xO) 
-+ 
+oo as llyll -f +m, y E A. 
(6.18) 
I I Y  - xOll 
Proof. Necessity: Suppose that A is nonempty and M is strictly 
copositive on A. If O+A = (0) then, according to Theorem 8.4 
in Rockafellar (1970), A is compact. So, for an arbitrarily chosen 
xO E A, condition (6.18) is satisfied. Now consider the case where 
O+A # (0). select any xO E A. We claim that (6.18) is valid. On 
the contrary, suppose that (6.18) is false. Then there must exist 
y > 0 and a sequence iy" C A such that lly"I 
+ +oo and 
Since A is a nonempty polyhedral convex set, by Theorems 19.1 and 
19.5 from Rockafellar (1970) one can find a compact set K C A such 
that 
A = K + O+A. 
Hence, for each k E N there exist uk E K and vk E O+A such that 
y" 
uk + vk. It is easily seen that llvk 11 1 +m. Therefore, without 
loss of generality we can assume that 
for some ?i 
E A and v E O+A with I ~ z I I  = 1. From (6.19) it follows 
that 
for all k E N. Letting k t oo, from the above inequality we obtain 
which contradicts the assumed strict copositivity of M on A. We 
have thus proved that (6.18) is valid. 
Suficiency: Suppose that there exists xO E A such that (6.18) 
is fulfilled. Let v E O+A \ (0) be given arbitrarily. Since y(t) := 

6.2 Solution Existence under Copositivity 
111 
xO + tv E A for every t > 0 and IIy(t)ll + +m as t -f +m, 
substituting y = y(t) into (6.18) gives 
This implies that vTMv = (Mu, v) > 0. We have thus shown that 
M is strictly copositive on A. 
0. 
Proof of Theorem 6.3. 
Suppose that M is strictly copositive on A and q E Rn is an 
arbitrarily given vector. Consider the affine operator 4(x) = Mx + 
q. Applying Lemma 6.3 we can assert that there exists xO E A 
such that the coercivity condition (5.17) is satisfied. According to 
Theorem 5.2, problem VI(4, A) has solutions. Since the latter is 
exactly the problem AVI(M, q, A), the desired conclusion follows. 
0 
One can derive Theorem 6.3 directly from Theorem 5.1 without 
appealing to Theorem 5.2 and Lemma 6.3. 
Another proof of Theorem 6.3. 
Suppose that A # 0, M is strictly copositive on A, and q E Rn 
is given arbitrarily. Let m E N, A E RmXn and b E Rm be such that 
A has the representation (6.2). Then O+A = {v E Rn : Av 2 0) 
(see Rockafellar (1970), p. 62). Select a point xO E A. For each 
k E N, we set 
A, 
= A n { x = ( x l ,  ..., X,)E Rn : x p - k ~ x ~ ~ x p + k  
for every i = 1,2,. . . , n). 
(6.20) 
It is clear that, for every k E N, .Ak is a nonempty, compact, poly- 
hedral convex set. Given any k E N, we consider the problem 
AVI(M, q, A,). According to the Hartman-Stampacchia Theorem 
(see Theorem 5.1), Sol(AVI(M,q,Ak)) # 0. For each k E N, se- 
lect a point xk e Sol(AVI(M, q, Ak)). We claim that the sequence 
{xk) is bounded. To obtain a contradiction, suppose that {xk) is 
unbounded. Without restriction of generality we can assume that 
xk # 0 for all k, IlxkII t +m as k --+ m ,  and there exists 
E Rn 
such that 

112 
6. Solution Existence for AVIs 
Since xO E Ak for every k E N, we have 
or, equivalently, 
Dividing the inequality in (6.21) by 1
1
~
~
1
1
~
 
and letting k -+ oo we 
get 
0 > ( M D , ~ ) .  
(6.22) 
Since xk E A, we have Axk > b. Dividing the last inequality by 
IIx"I and taking the limit as k -+ oo we obtain A3 > 0. This shows 
that v E O+A. Since 1 1 ~ 1 1  = 1, (6.22) contradicts the assumed strict 
copositivity of M on A. We have thus proved that the sequence 
{xk} is bounded. There is no loss of generality in assuming that 
xk -+ 3 for some 3 E A. For each x E A one can find and index 
k, E N such that x E Ak for all k > k,. Consequently, for every 
k > k,, it holds 
(Mxk + q,x - xk) > 0. 
Letting k -+ oo we obtain 
Since the last inequality is valid for any x E A, we conclude that 
3 E Sol(AVI(M, q, A)). The proof is complete. 
Example 6.2. Let 
In Remark 6.1 we have observed that M is not monotone on A. 
However, M is strictly copositive on A. Indeed, since A is a cone, 
we have O+A = A. For any nonzero vector v = (vl, v2) E O+A = R: 
it holds 
V ~ M V  = v; + 4v1v2 + vi > 0. 
This shows that M is strictly copositive on A. According to The- 
orem 6.3, for any q E R2, problem AVI(M, q, A) is solvable. Note 
that Theorem 6.1 cannot be applied to this problem because M is 
not monotone on A. 

6.2 Solution Existence under Coposi tivi ty 
113 
In the following existence theorem we need not to assume that 
the matrix M strictly copositive on A. Instead of the strict copos- 
itivity, a weaker assumption is employed. 
Theorem 6.4. If matrix M is copositive on a nonempty polyhedral 
convex set A and there exists no v E Rn \ (0) such that 
then, for any q E Rn, problem AVI(M, q, A) has a solution. 
Proof. Suppose that A # 0, M is copositive on A and there exists 
no fl E Rn \ (0) satisfying (6.23). Suppose that q E Rn is given 
arbitrarily. Let m E N, A E RmXn and b E Rm be such that A has 
the representation (6.2). Then O+A = {v E Rn : Av 2 0). Let 
xO E A. For each k E N, we define 
A, = A n B(xO, k). 
(6.24) 
Note that, for every k E N, Ak is a nonempty, compact, convex set. 
Given any k E N, we consider the VI problem 
Find x E A, such that (Mx + q, y - x) 2 0 b'y E Ak 
and denote its solution set by Sol(VI((M, q, A,)). 
By Theorem 
5.1, Sol(VI((M, q, Ak)) # 0. For each k E N, select a point 2% 
Sol(VI((M, q, A,)). We claim that the sequence {xk) is bounded. 
Suppose, contrary to our claim, that 1x9 is unbounded. There is 
no loss of generality in assuming that xk # 0 for all k, llxkll -+ +a 
as k --+ co, and there exists .Ij E Rn such that 
Since xO E A, for every k E N, we have 
As in the second proof of Theorem 6.3, from the last property we 
deduce that 
0 2 (Mfl,~). 

114 
6. Solution Existence for AVIs 
Since xk E A, we have Axk 2 b for every k E N. This implies 
As 2 0. So .rj E O+A. Since M is copositive on A, from what has 
already been said it follows that 
For any w E Of A \ {0), from (6.24) and the fact that xO + t w  E A 
for every t > 0 we deduce that 
Since xk E Sol(VI((M, q, Ak)), we have 
Dividing this inequality by 11xkl12, letting k --t oo and noting that 
lim 'Ixk - x0 
-+ 1, by virtue of (6.25) we obtain Ms, - 
llxk ll 
( 
11:11) ' 
O. 
Hence (Mv, w) 2 0 for every w E OfA. This means that MG E 
(O+A)+. We see that vector .is E Rn \ (0) satisfies all the three 
conditions described in (6.23). This contradicts our assumption. 
We have thus proved that the sequence {x" 
is bounded. Without 
loss of generality we can assume that x
b
 
3 for some Z E A. For 
each x E A there exists k, E N such that x E Ak for all k 2 k,. 
Consequently, for every k 2 k,, we have (Mx" 
q, x - xk) 2 0. 
Letting k --t oo we obtain (MZ + q, x - 3) 2 0. Since this inequality 
holds for any x E A, we can assert that Z E Sol(AVI(M, q, A)). The 
proof is complete. 
Example 6.3. Let M and A be the same as in Example 6.1. It is a 
simple matter to verify that there exists no fl E Rn \ (0) satisfying 
the three conditions in (6.23). Since M is copositive on A, Theorem 
6.4 asserts that, for any q = (ql, q2) E R2, problem AVI(M, q, A) 
has a solution. 
In the sequel, sometimes we shall use the following simple fact. 
Lemma 6.4. Let K c Rn be a nonempty closed cone. Let q E Rn. 
Then q E intK+, where intKf denotes the interior of the positive 
dual cone Kf of K ,  zf and only if 

6.2 Soh tion Existence under Copositivity 
115 
Proof. Suppose that q E intK+. If there exists ?j E K \ (0) such 
that ?jTq 5 0 then aTq = 0 because the condition q E K+ implies 
that vTq 2 0 for every v E K. From this we see that the linear 
functional J -t ?jTJ achieves its global minimum on K+ at q. As 
q E intK+, there exists e > 0 such that B(q, E )  c K+. Then 
This implies that ?j = 0, a contradiction. We have thus proved that 
if q E intK+ then (6.26) is valid. 
Conversely, assume that (6.26) holds. To obtain a contradiction, 
suppose that q @ intK+. Then there exists a sequence {q" 
in 
Rn \ K +  such that qk 4 q. Consequently, for each k E N there 
exists v" 
K such that ( ~ " ~ q "  0. Without loss of generality we 
vk 
can assume that - 
t 
?j with 112111 = 1. We have 
llvk 11 
Taking the limits as k + oo we obtain vTq 5 0 and ?j E K ,  contrary 
to (6.26). 
In the case where A is a cone, we have the following existence 
theorem. 
Theorem 6.5. Assume that A is a polyhedral convex cone. If 
matrix M is copositive on A and 
then problem AVI(M, q, A) has a solution. 
Note that AVI(M, q, A) is a generalized linear complementarity 
problem (see Definition 5.8). From the definition it follows that 
v E Sol(AVI(M, 0, A)) if and only if 
Hence, applying Lemma 6.4 to the cone K : = Sol(AVI(M, 0, A)) we 
see that condition (6.27) is equivalent to the requirement that there 
exists no ?j E Rn \ (0) such that 

116 
6. Solution Existence for AVIs 
Proof of Theorem 6.5. 
Suppose that A is a polyhedral convex cone, M is copositive on 
A, and q is such that (6.27) holds. For each k E N ,  we set 
Ak = A n {x E Rn : -k 
xi 5 k for every i = 1,2,. . . ,n). 
It is clear that, for each k E N, 0 E Ak and Ak is a compact, 
polyhedral convex set. Consider the problem AVI(M, q, Ak). By 
Theorem 5.1, we can find a point xk E Sol(AVI((M, q, Ak)). If the 
sequence {xk} is unbounded then without loss of generality we can 
assume that xk # 0 for all k, IIx"I I +w as k -f w, and there 
exists .iS E Rn such that 
Since 0 E Ak, we have 
Hence 
-qTx'" 2 ( x ~ ) ~ M x ~  
(Vk E N). 
(6.29) 
Dividing the inequality in (6.29) by 1 1 ~ ~ 1 1 ~  
and taking limits as k -+ 
oo we get 
0 2 V ~ M E .  
(6.30) 
It is clear that ij E A. Since M is copositive on A, we have vTMv > 
0 for every v E A. Combining this fact with (6.30) yields 
From (6.29) and the copositivity of M on A it follows that -qTxk ) 
0 for every k E N. This implies that 
Fix any w E A \ (0). It is evident that 
Since x'" E Sol(AVI(M, q, Ak)), we have 

6.2 Soh tion Existence under Coposi tivi ty 
117 
From this and (6.31) we deduce that (Ma, w) > 0. Since the last 
inequality is valid for every w E A \ {0), we see that Ma E A+. 
Combining this with (6.31) and (6.32) we can assert that (6.28) is 
satisfied. Then (6.27) is false. We have arrived at a contradiction. 
Thus the sequence {xk} must be bounded. Analysis similar to that 
in the final part of the proof of Theorem 6.4 shows that problem 
AVI(M, q, A) has a solution. 
0 
Example 6.4. Let 
Theorem 6.5 can be applied to the problem AVI(M, q, A). Indeed, 
we have 
T MU = U; - U; = o WJ E o+n = A. 
This shows that M is copositive on A. Furthermore, we have 
Therefore 
qTv = v1 + 212 > 0 Vv = (vl, v2) E Sol(AVI(M, 0, A)) \ (0). 
So (6.27) is satisfied. By Theorem 6.5, problem AVI(M, q, A) is 
solvable. In fact, we have 
It is worth pointing that, since M is not strictly copositive on A, 
Theorem 6.3 cannot be applied to this problem. Since all the three 
conditions described in (6.23) are satisfied if one chooses 8 = (1,l) E 
R2 \ {0), Theorem 6.4 also cannot be applied to this problem. 
Remark 6.4. In the case where A is a polyhedral convex cone, 
the conclusion of Theorem 6.4 follows from Theorem 6.5. Indeed, 
in this case, under the assumption of Theorem 6.4 we have 
Sol(AVI(M, 0, A)) = (0). 
Hence [Sol(AVI(M, 0, A))]+ = Rn. So (6.27) is satisfied for any 
q E Rn. By Theorem 6.5, problem AVI(M, q, A) is solvable. 

118 
6. Solution Existence for AVIs 
Applying Theorem 6.5 to LCP problems we obtain the following 
corollary. 
Corollary 6.2. If M is a copositive matrix and 
q E int([Sol(M, O)]'), 
(6.33) 
then the problem LCP(M, q) has a solution. 
Note that condition (6.33) is stronger than condition (6.34) in 
the following existence theorem for LCP problems. 
Theorem 6.6. (See Cottle et al. (1992), Theorem 3.8.6) If M is a 
copositive matrix and 
4 E [Sol(M, 0)1+, 
(6.34) 
then problem LCP(M, q) has a solution. 
It is clear that (6.34) can be rewritten in the following form: 
Meanwhile, by Lemma 6.4, condition (6.33) is equivalent to the 
following one: 
[ V E  Rn\{O), v 2 0 ,  M U L O ,  v T ~ v = O ]  
[qT~>O]. 
In connection with Theorems 6.5, the following open question 
seems to be interesting. 
QUESTION: 
Whether the conclusion of Theorem 6.5 is still valid if 
in the place of (6.27) one uses the following weaker condition 
Note that the last inclusion can be rewritten in the form: 
6.3 Commentaries 
In this chapter, we have considered a variety of solution existence 
theorems for affine variational inequalities. Here the compactness 
of the constraint set A is not assumed. But we have to employ a 
monotonicity property of the matrix M with respect to A. Namely, 
we have had deal with the monotonicity, the strict monotonicity, 
and the copositivity of M w.r.t. A. 
The interested reader is referred to Gowda and Pang (1994a) for 
an insightful study on existence theorems for AVI problems. 

Chapter 7 
Upper-Lipschitz Continuity 
of the Solution Map in 
Affine Variational 
Inequalities 
In this chapter we shall discuss two fundamental theorems due to 
Robinson (1979, 1981) on the upper-Lipschitz continuity of the so- 
lution map in affine variational inequality problems. The theorem 
on the upper-Lipschitz continuity of the solution map in linear com- 
plementarity problems due to Cottle et al. (1992) is also studied 
in this chapter. The Walkup-Wets Theorem (see Walkup and Wets 
(1969)), which we analyze in Section 7.1, is the basis for obtaining 
these results. 
7.1 The Walkup-Wets Theorem 
Let A c Rn be a nonempty subset. Let T : Rn --t Rm be an affine 
operator; that is there exist a linear operator A : Rn -t Rm and a 
vector b E Rm such that T(X) = Ax + b for every x E Rn. Define 
Definition 7.1. (See Walkup and Wets (1969), Definition 1) A 
subset A C Rn is said to have property Cj if for every affine operator 
T : Rn --t Rm, m E N, with dim(ker(r)) = j ,  the inverse mapping 

120 
7. Upper-Lipschitz Continuity of the Solution Map 
y + A(y) is Lipschitz on its effective domain. This means that 
there exists a constant ! 
> 0 such that 
A(Y') C A(Y) + lll~' 
- yllB~n whenever A(y) # 0, A(yf) # 0. 
(7.2) 
. 
. 
In the above definition, dim(ker(r)) denotes the dimension of 
the affine set 
ker(r) = { x  E Rn : T(X) = 0). 
The following theorem is a key tool for proving other results in 
this chapter. 
Theorem 7.1 (The Walkup-Wets Theorem; see Walkup and Wets 
(1969), Theorem 1). Let A c Rn be a nonempty closed convex set 
and let j E N ,  1 5 j 5 n - 1. Then A is a polyhedral convex set if 
and only if it has property Cj. 
In the sequel, we will use only one assertion of this theorem: If A 
is a polyhedral convex set, then it has property Cj. A detailed proof 
of this assertion can be found in Mangasarian and Shiau (1987). 
Corollary 7.1. If A C Rn is a polyhedral convex set and if T : 
Rn t Rm is an afine operator, then there exists a constant ! 
> 0 
such that (7.2), where A(y) is defined by (7.1) for all y E Rn, holds. 
Proof. If j := dim(ker(r)) satisfies the condition 1 5 j 5 n - 1, 
then the conclusion is immediate from Theorem 7.1. If dim(ker(r)) = 
n then ker(r) = Rn, and we have 
This shows that (7.2) is fulfilled with any ! 
> 0. We now suppose 
that dim(ker(7)) = 0. Let T(X) = Ax + b, where A : Rn + Rm 
is a linear operator and b E Rm. Since T is an injective mapping, 
Y := r(Rn) is an affine set in Rm with dimY = n, and that n 5 m. 
Likewise, the set & := A(Rn) is a linear subspace of Rm with 
dim& = n. Let 2 : Rn + Yo be the linear operator defined by 
setting x x  = Ax for every x E Rn. It is easily shown that 
for every y E Y and y' E Y. From this we deduce that (7.2) is 
satisfied with ! 
:= 112-' 
11. 
0 
Remark 7.1. Under the assumptions of Corollary 7.1, for every 
y E Rm, A(y) is a polyhedral convex set (possibly empty). 

7.1 The Walkup- Wets Theorem 
121 
Remark 7.2. The conclusion of Theorem 7.1 is not true if one 
chooses j = 0. Namely, the arguments described in the final part of 
the proof of Corollary 7.1 show that any nonempty set A C Rn has 
property Lo Similarly, the conclusion of Theorem 7.1 is not valid 
if j = n. 
Corollary 7.2. For any nonempty polyhedral convex set A C Rn 
and any matrix C E RSXn there exists a constant ! 
> 0 such that 
A(C, d") C A(C, dl) + ![Id" - d'll BRn 
whenever A(C, dl) and A(C, dl1) are nonempty; where 
for every d E RS. 
Proof. Set T(X) = Cx. Since 
where A(y) is defined by (7.1), applying Corollary 7.1 we can find 
! 
> 0 such that the Lipschitz continuity property stated in (7.3) is 
satisfied. 
0 
Corollary 7.3. For any nonempty polyhedral convex set A C Rn, 
any matrix A E Rmxn and matrix C E RSXn there exists a constant 
! 
> 0 such that 
A(A, C, b", d") C A(A, C, b', dl) + !(llbU - blII + [Id" - dlII)BRn (7.4) 
whenever A(A, C, b', d') and A(A, C, b", dl') are nonempty; where 
for every b E Rm and d E RS. 
Proof. Define 
where E denotes the unit matrix in RmXm and 0 denotes the null 
in RSXm. 
Let 

122 
7. Upper-Lipschitz Continuity of the Solution Map 
By Corollary 7.2, there exists ! 
> 0 such that 
- - 
- - 
whenever A(C, b', dl) # 8 and A(C, b", d") # 0, where 
Since 
A(A,C,b,d) = { x E A :  
- - 3 w e R m ,  ~ 2 0 ,  
A X - w = b ,  C x = d )  
= PrRn (A(C, b, d)) 
where Prp(x, W) = x for every (x, w) E Rn x Rm, we see at once 
that (7.5) implies (7.4). 
7.2 Upper-Lipschitz Continuity with re- 
spect to Linear Variables 
The notion of polyhedral multifunction was proposed by Robinson 
(see Robinson (1979, 1981). We now study several basic facts con- 
cerning polyhedral multifunctions. 
Definition 7.2. If @ : Rn + 2Rm is a multifunction then its graph 
and effective domain are defined, respectively, by setting 
Definition 7.3. A set-valued mapping @ : Rn + 2Rm is called a 
polyhedral multifunction if its graph can be represented as the union 
of finitely many polyhedral convex sets in Rn x Rm. 
The following statement shows that the normal-cone operator 
corresponding to a polyhedral convex set is a polyhedral multifunc- 
tion. 
Proposition 7.1. (See Robinson (1981)) Suppose that A c Rn is 
a nonempty polyhedral convex set. Then the formula 
@(x) = NA (x) (x E Rn) 
defines a polyhedral multifunction @ : Rn + 2Rn 

7.2 Upper-Lipschi tz Continuity w.r. t. Linear Variables 
123 
Proof. Let m E N, A E RnXn and b E Rm be such that A = {x E 
Rn : Ax 2 b). Set I = (1,. . . ,m). Let 
F, = {x E Rn : A,x = b,, 
AI\,x > bq,) 
be the pseudo-face of A corresponding to an index set a, C I. For 
every x E F, we have 
(See the proof of Theorem 4.2.) Since 
NA (x) = {J E Rn : (J, V )  I 0 'dv E Tn (x) ) , 
we have J E Na(x) if and only if the inequality (J, v) < 0 is a con- 
sequence of the inequality system A,v > 0. Consequently, applying 
Farkas' Lemma (see Theorem 3.2) we deduce that J E Na(x) if and 
only if there exist XI 2 0,. . . , A, 
2 0 such that 
where Ai denotes the i-th row of matrix A. (Note that if a = 8 
and x E Fa, then x E intA; hence J = 0 for every J E NA(x).) 
Define 
Obviously, R, C graph@. Note that 
R, 
= {(x, J) E Rn x Rn : A,x = b,, 
AI\,X > b1\,, 
( = C,,, &(-AT) for some A, E R?'}. 
is a convex set. Here la1 denotes the number of elements in a. It 
is easily seen that the topological closure 2, of R, is given by the 
formula 
where PrRnxRn (x, J, A,) = (x, J). It is clear that the set in the last 
curly brackets is a polyhedral convex set. From this fact, the above 

124 
7. Upper-Lipschitz Continuity of the Solution Map 
formula for n, and Theorem 19.1 in Rockafellar (1970) we deduce 
that 2, is a polyhedral convex set (see the proof of Theorem 4.3). 
Since A = UacI Fa, we have 
Observe that graph@ is a closed set. Indeed, suppose that {(xk, Jk)) 
k
k
 
is a sequence satisfying (xk, Jk) 4 (3, f) E Rn x Rn, and (x , J ) E 
graph@ for every k E N. On account of formula (1.12), we have 
Fixing any y E A and taking limit as k t 
oo, from the last inequal- 
ity we obtain (f, y - Z) < 0. Since this inequality holds for each 
y E A, we see that f E NA(3). Hence (3, f) E graph@. We have 
thus proved that the set graph@ is closed. On account of this fact, 
from (7.6) we deduce that 
This shows that graph@ can be represented as the union of finitely 
many polyhedral convex sets. The proof is complete. 0 
The following statement shows that the solution map of a para- 
metric affine variational inequality problem is a polyhedral multi- 
function (on the linear variables of the problem). 
Proposition 7.2. Suppose that M E RnXn, A E Rmxn and C E 
RSXn are given matrices. Then the fomnula 
where (q, b, d) E Rn x Rm x RS, A(b, d) := {x E Rn : Ax > b, Cx = 
d) and Sol(AVI(M, q, A(b, d))) denotes the solution set of problem 
(6.1) with A = A(b, d), defines a polyhedral multifunction 
Proof. According to Corollary 5.2, x E Sol(AVI(M, q, A(b, d))) if 
and only if there exist X = (A1, . . . , Am) E Rm and p = (pl, . . . , p,) E 
RS such that 
M X - A ~ A - C ~ ~ + ~ = O ,  
Ax 2 b, Cx = d, X > 0, 
(7.7) 
XT(AX - b) = 0. 

7.2 Upper-Lipschitz Continuity w.r.t. Linear Variables 
125 
Let I = {I,. . . , m). For each index set a c I, we define 
where 
Pr1(x, q,b, d, A, p) = (x, 9, b, d) 
for all (x, q, b, d, A, p) E Rn x Rn x Rm x RS x Rm x RS. Hence Q, 
is a polyhedral convex set. Note that 
graph@ = u Q,. 
a C I  
Indeed, for each (x, q, b, d) E graph@ we have 
x E Sol(AVI(M, q, A(b, d))). 
So there exist A = (A1,. . . ,Am) E Rm and p = (pl,. . . ,ps) E RS 
satisfying (7.7). Let a = {i E I : Aix = bi). For every i E I \ a, we 
have Aix > bi. Then from the equality Ai(Aix - bi) = 0 we deduce 
that Xi = 0 for every i E I \ a. On account of this remark, we see 
that (x, q, b, d, A, p) satisfies all the conditions described in the curly 
braces in formula (7.8). This implies that (x, q, b, d) E Q,. We thus 
get 
graph@ C U Qa. 
a C I  
Since the reverse inclusion is obvious, we obtain formula (7.9), which 
shows that graph@ can be represented as the union of finitely many 
polyhedral convex sets. 
Theorem 7.2. (See Robinson (l98l), Proposition 1) If Q, : Rn -t 
2Rm is a polyhedral multifunction, then there exists a constant e > 0 
such that for every 3 t. Rn there is a neighborhood U3 of 3 satisfying 
Definition 7.4. (See Robinson (1981)) Suppose that @ : Rn -t 
2Rm is a multifunction and 3 z: Rn is a given point. If there exist 
e > 0 and a neighborhood Uz of Z such that property (7.10) is valid, 

126 
7. Upper-Lipschitz Continuity of the Solution Map 
then @ is said to be locally upper-Lipschitz at 3 with the Lipschitz 
constant !. 
The locally upper-Lipschitz property is weaker than the locally 
Lipschitz property which is described as follows. 
Definition 7.5. A multifunction @ : Rn t 2Rrn is said to be 
locally Lipschitx at 3 E Rn if there exist a constant ! 
> 0 and a 
neighborhood Uz of Z such that 
@(x) C @(u) +!llx 
'dx E U,,Vu E U,. 
If there exists a constant ! 
> 0 such that 
for all x and u from a subset R C Rn, then @ is said to be Lipschitz 
on 0. 
From Theorem 7.2 it follows that if @ is a polyhedral multi- 
function then it is locally upper-Lipschitz at any point in Rn with 
the same Lipschitz constant. Note that the diameter diamUZ := 
sup{ll y - xll : x E U,, y E U,} of neighborhood UZ depends on 3 
and it can change greatly from one point to another. 
Proof of Theorem 7.2. 
Since @ is a polyhedral multifunction, there exist nonempty 
polyhedral convex sets Qj C Rn x Rm (j = 1,. . . , k) such that 
where J = (1, . . . , k). For each j E J we consider the multifunction 
Qj : Rn -+ 
2Rrn defined by setting 
Obviously, graphaj = Qj. From (7.11) and (7.12) we deduce that 
graph@ = u graph@j, @(a) = U Oj 
(x). 
j€ J 
j€ J 
CLAIM 1. For each j E J there exists a constant tj > 0 such that 

7.2 Upper-Lipschi tz Continuity w.r. t. Linear Variables 
127 
whenever Qj(x) # 0 and Qj(u) # 0. (This means that Qj is Lips- 
chitz on its eflective domain.) 
For proving the claim, consider the linear operator T : Rn x 
Rm t Rn defined by setting T(X, y) = x for every (x, y) E Rn x Rm. 
Let 
Qj(x) = {Z E Qj : T(.z)=x). 
(7.14) 
By Corollary 7.1, there exists -ej > 0 such that 
whenever Qj(x) # 0 and Qj(u) # 0. From (7.12) and (7.14) it 
follows that 
Qj (x) = {x) x Qj (x) YX E Rn. 
(7.16) 
In particular, Qj (x) # 0 if and only if (Pj (x) # 0. Given any x E Rn, 
u E Rn and y E (Pj (x), from (7.15) and (7.16) we see that there exist 
v E Q(u) such that 
Since II(x, y) - (u, v)ll = (111 - u1I2 + Ily - V I I ~ ) ~ ' ~ ,  
the last inequality 
implies that (1 y - vll 5 tj llx - ulI. From what has already been 
proved, it may be concluded that (7.13) holds whenever aj(x) # 0 
and (Pj(u) # 0. 
We set e = max{lj : j E J ) .  The proof will be completed if we 
can establish the following fact. 
CLAIM 2. For each 5 E Rn there exists a neighborhood U5 of 3 such 
that (7.10) holds. 
Let f E Rn be given arbitrarily. Define 
Since domQj = r(Qj), where T is the linear operator defined above, 
we see that domQj is a polyhedral convex set. This implies that 
the set UjEJ1 dom(Pj is closed. (Note that if J1 = 0 then this set is 
empty.) As f $ UjEJl domQj, there must exist E > 0 such that the 
neighborhood U5 := B(3, E) of 3 does not intersect the set 

128 
7. Upper-Lipschi tz Continuity o f  the Solution Map 
Let x E Uz. If x $! UjtJodomQj, then 
So the inclusion (7.10) is valid. If x E Uj, Jo domQj, then we have 
where JA = {j E Jo : x E domQj). For each j E JL, according to 
Claim 1, we have 
Claim 2 has been proved. 
Remark 7.3. From the proof of Theorem 7.2 it is easily seen that 
Q is Lipschitz on the set njE domQj with the Lipschitz constant Q. 
Combining Theorem 7.2 with Proposition 7.2 we obtain the next 
result on upper-Lipschitz continuity of the solution map in a general 
AVI problem where the linear variables are subject to perturbation. 
Theorem 7.3. Suppose that M E RnXn, A E RmXn and C E RsXn 
are given matrices. Then there exists a constant Q > 0 such that the 
multzfunction Q : Rn x Rm x RS -+ 2Rn defined by the formula 
where (q, b,d) E Rn x Rm x RS and A(b,d) := {x E Rn : Ax 2 
b, Cx = d), is locally upper-Lipschitz at any point (q, z, d) E Rn x 
Rm x Rs with the Lipschitz constant Q. 
Applying Theorem 7.3 to the case where the constraint set A(b, d) 
of the problem AVI(M, q, A (b, d ) )  is fixed (i.e., the pair (b, d )  is not 
subject to perturbations), we have the following result. 
Corollary 7.4. Suppose that M E RnXn is a given matrix and 
A c Rn is a nonempty polyhedral convex set. Then there exists a 
constant Q > 0 such that the multifunction Q : Rn -+ 2Rn defined by 
the formula 
Q(9) = Sol(AVI(M q, A)), 
where q E Rn, is locally upper-Lipschitz at any point tj E Rn with 
the Lipschitz constant Q. 

7.3 Upper-Lipschitz Continuity w.r. t. all Variables 
129 
7.3 Upper-Lipschitz Continuity with re- 
spect to all Variables 
Our aim in this section is to study some results on locally upper- 
Lipschitz continuity of the multifunction @ : RnXn x Rn --t 2Rn 
defined by the formula 
where Sol(AVI(M, q, A)) denotes the solution set of the problem 
(6.1). First we consider the case where A is a polyhedral convex 
cone. Then we consider the case where A is an arbitrary nonempty 
polyhedral convex set. 
The following theorem specializes to Theorem 7.5.1 in Cottle et 
al. (1992) about the solution map in parametric linear complemen- 
tarity problems if A = R:. 
Theorem 7.4. Suppose that A C Rn is a polyhedral convex cone. 
Suppose that M E Rnxn is a given matrix and q E Rn is a given 
vector. If M is copositive on A and 
q E int ([SO~(AVI(M, 
0, A))]+) , 
(7.17) 
then there exist constants e > 0, 6 > 0 and ! 
> 0 such that if 
( z ,  9 E RnXn x Rn, R 
is copositive on A, and if 
then the set s ~ ~ ( A v I ( G ,  
F, A)) is nonempty, 
s O ~ ( A V I ( ~ ,  
F7 A)) C 6 8 ~ .  , 
(7.19) 
and 
SO~(AVI(Z, 
F, A)) c Sol(AVI(M, q1 A))+e(llW-~11 + ~ l ~ - q l l ) ~ ~ n .  
(7.20) 
Proof. Suppose that M is copositive on A and (7.17) is satisfied. 
- 
Since A is a polyhedral convex cone, we see that for every (M, 
E 
RnXn x Rn the problem AVI(%, ?,9 A) is an GLCP. In particular, 
AVI(M, 0, A) is a GLCP problem and we have 

130 
7. Upper-Lipschi t z  Continuity of the Solution Map 
Since Sol(AVI(M, 0, A)) is a closed cone, Lemma 6.4 shows that 
(7.17) is equivalent to the following condition 
q T ~  
> 0 'dv E Sol(AVI(M, 0, A)) \ (0). 
(7.21) 
CLAIM 1. There exists s > 0 such that if ( z ,  9 E RnXn 
x Rn, 
is 
copositive on A, and if (7.18) holds, then the set S O ~ ( A V I ( ~ ,  
F, A)) 
is nonempty. 
Suppose Claim 1 were false. Then we could find a sequence 
{(Mk, qk)) in Rnxn x Rn such that M%S copositive on A for every 
k E N, (M" qk) t (M, q) as k -t oo, and sol(Av1(Mk7 qk, A)) = 0 
for every k E N. According to Theorem 6.5, we must have 
qk $ int ([so~(AvI(M~,o,A))]+) 'dk E N. 
Applying Lemma 6.4 we can assert that for each k E N there exists 
vk E Sol(AVI(Mk, 0, A)) \ (0) such that (q"T~k < 0. Then we have 
for every k E N. Without loss of generality we can assume that 
From (7.22) it follows that 
Taking limits as k t oo we obtain 
Zi E A, MU E A', 
(Mz, 6) = 0. 
k
T
 k 
This shows that ij E Sol(AVI(M, 0, A)). Since (q ) v 5 0, we see 
v lc < 0 for every k E N. Letting k t 
oo yields qTv 5 0. 
that ( q V T j q  - 
Since Zi E Sol(AVI(M, 0, A)) \ (01, the last inequality contradicts 
(7.21). We have thus justified Claim 1. 
CLAIM 2. There exist E > 0 and b > 0 such that if ( W , a  E 
Rnxn x Rn, z is copositive on A, and if (7.18) holds, then inclusion 
(7.19) is satisfied. 

7.3 Upper-Lipschitz Continuity w.r. t, all Variables 
131 
To obtain a contradiction, suppose that there exist a sequence 
{(Mk, qk)) in Rnxn x Rn and a sequence {xk) in Rn such that Mk 
is copositive on A for every k E N, xk E Sol(AVI(Mk, qk,A)) for 
every k E N, (Mk,q" + (M,q) as k + oo, and Ilxkll + +oo as 
k + oo. Since xk E SO~(AVI(M" qk, A)), we see that 
for every k E N. There is no loss of generality in assuming that 
From (7.23) it follows that 
From this we conclude that fl E Sol(AVI(M, 0, A)). Since 
and since Of A = A and Mk is copositive on A, we have 
Then 
This contradicts (7.21). Claim 2 has been proved. 
Now we are in a position to show that there exist e > 0, S > 0 
and e > 0 such that if (G, 3 E RnXn x Rn, 
is copositive on A, 
and if (7.18) holds, then SO~(AVI(G, 
F, A)) # 0 and (7. lg), (7.20) 
are satisfied. 
Combining Claim 1 with Claim 2 we see that there exist e > 0 
and 6 > 0 such that if ( G , $  E Rnxn x Rn, 
is copositive on 
A, and if (7.18) holds, then SOI(AVI(G, F, A)) # 0 and (7.19) is 
satisfied. According to Corollary 7.4, for the given matrix M and 
vector q, there exist a constant eM > 0 and a neighborhood U, of q 
such that 

132 
7. Upper-Lipschi tz Continuity of the Solution Map 
for every q' E U,. 
Let ( z ,  ?j) 
E RnXn x Rn be such that 
is 
copositive on A and (7.18) holds. Select any 5 E S O ~ ( A V I ( ~ ,  
A)). 
Setting 
q = c + ( z - ~ ) ~  
(7.25) 
we will show that 
i E Sol(AVI(M, q, A)). 
(7.26) 
Since 
( Z Z + ~ , X - ~ ) > O  
V X E A ,  
using (7.25) we deduce that 
for every x E A. This shows that (7.26) is valid. From (7.18), (7.19) 
and (7.25) it follows that 
Consequently, choosing a smaller E > 0 if necessary, we can assert 
that g E U, whenever (MI, 3 E RnXn x Rn, &? is copositive on A, 
(7.18) holds. Hence from (7.24) and (7.26) we deduce that there 
exists x E Sol(AVI(M, q, A)) such that 
where Q = max{QM, 6QM). We have thus obtained (7.20). The proof 
is complete. 
Our next goal is to establish the following interesting result on 
AVI problems with positive semidefinite matrices. 
Theorem 7.5. (See Robinson (1979), Theorem 2) Let M E Rnxn be 
a positive semidefinite matrix, A a nonempty polyhedral convex set 
in Rn, and q E Rn. Then the following two properties are equivalent: 
(i) The solution set Sol(AVI(M, q, A)) is nonempty and bounded; 

7.3 Upper-Lipschitz Continuity w.r.t, all Variables 
133 
(ii) There exists E > 0 such that for each G E RnXn and each 
8 
E Rn with 
the set S O ~ ( A V I ( ~ ,  
A)) is nonempty. 
For proving the above theorem we shall need the following three 
auxiliary lemmas in which it is assumed that M E RnXn is a positive 
semidefinite matrix, A C Rn is a nonempty polyhedral convex set, 
and q E Rn. We set MA = {Mx : x E A). 
Lemma 7.1. (See, for instance, Best and Chakravarti (1992)) For 
any fi E Rn, if ifTM# = 0 then ( M  + MT)fi = 0. 
Proof. Consider the unconstrained quadratic program 
min f ( x )  := I x T ( ~  
+ M ~ ) X  : x E R ~ J .  
I 
2 
From our assumptions it follows that 
for every x E Rn. Hence fi is a global solution of the above problem. 
By Theorem 3.1 we have 
which completes the proof. 
0 
Lemma 7.2. The inclusion 
q E int((Of A)' - MA) 
holds if and only if 
Vv E 0' A \ (0) 3x E A such that (Mx + q, v) > 0. 
(7.29) 
Proof. Necessity: Suppose that (7.28) holds. Then there exists 
E > 0 such that 
B(q, E) c (OfA)' - MA. 
(7.30) 

134 
7. Upper-Lipschitz Continuity of the Solution Map 
To obtain a contradiction, suppose that there exists a E O+A \ (0) 
such that 
( M X + ~ , ~  
5 0  ~ x E A .  
By (7.30), for every q' E B(q, E )  there exist w E (O+A)+ and x E A 
such that q' = w - Mx. So we have 
This clearly forces fi = 0, which is impossible. 
Sufficiency: On the contrary, suppose that (7.29) is valid, but 
(7.28) is false. Then there exists a sequence {qk) c Rn such that 
qk $ (Of A)+ -MA for all k E N, and qk + q. From this we deduce 
that 
( M A + ~ " ~ ( o + A ) +  
= 0 vk E N. 
Since MA + q%nd (O+A)+ are two disjoint polyhedral convex sets, 
by Theorem 11.3 from Rockafellar (1970) there exists a hyperplane 
separating these sets properly. Since (O+A)+ is a cone, by Theorem 
11.7 from Rockafellar (1970) there exists a hyperplane which sepa- 
rates the above two sets properly and passes through the origin. So 
there exists vk E Rn with llvkll = 1 such that 
(v" Mx + qk) 5 0 5 (vk, w) tlx E A, tlw E (Of A)'. 
(7.31) 
(Actually, the above-mentioned hyperplane is defined by the for- 
mula H = {x E Rn : (vk, Z )  = 0)). Without loss of generality we 
can assume that vk 4 V E Rn, 1 1 ~ 1 1  = 1. From (7.31) it follows that 
and 
(8, w) 2 0 vw E (O+A)+. 
(7.33) 
By Theorem 14.1 from Rockafellar (1970), from (7.33) it follows 
that fi E O+A. Combining this with (7.32) we see that (7.29) is 
false, which is impossible. 
Lemma 7.3. (See Gowda-Pang (1994a), Theorem 7) The solution 
set Sol(AVI(M, q, A)) is nonernpty and bounded if and only if (7.28) 
holds. 
Proof. Necessity: To obtain a contradiction, suppose that the set 
Sol(AVI(M, q, A)) is nonempty and bounded, but (7.28) does not 
hold. Then, by Lemma 7.2 there exists V E O+A \ (0) such that 

7.3 Upper-Lipschitz Continuity w.r.t. all Variables 
135 
(7.32) holds. Select a point xO E Sol(AVI(M, q, A)). For each t > 0, 
we set xt = xO + tG. Since fl E O+A, we have xt E A for every t > 0. 
Substituting xt for x in (7.32) we get 
This implies that (a, M5) 5 0. Besides, since M is positive semidef- 
inite, we have (5, MU) 2 0. So 
(5, MU) = 0. 
(7.34) 
By Lemma 7.1, from (7.34) we obtain 
Fix any x E A. On account of (7.32), (7.34), (7.35) and the fact 
that xO E Sol(AVI(M, q, A)), we have 
50 
-t ((M + ~ ~ 1 5 ,  
xO) - 
Since this holds for every x E A, xt E Sol(AVI(M, q, A)). As the last 
inclusion is valid for each t > 0, we conclude that Sol(AVI(M, q, A)) 
is unbounded, a contradiction. 
Suficiency: Suppose that (7.28) holds. We have to show that 
the set Sol(AVI(M, q, A)) is nonempty and bounded. By (7.28), 
q E (O+A)+ - MA. 
Hence there exist w E (O+A)+ and 3 E A such that q = w - MZ. 
Since MZ + q = w E (Of A)+, for every v E O+A it holds 
Since M is a positive semidefinite matrix, we see that both con- 
ditions (i) and (ii) in Theorem 6.1 are satisfied. Hence the set 

136 
7. Upper-Lipschi tz Continuity of the Solution Map 
Sol(AVI(M, q, A)) is nonempty. To show that Sol(AVI(M, q, A)) is 
bounded we suppose, contrary to our claim, that there exists a se- 
quence {x" in Sol(AVI(M, q, A)) such that 11x"1 1 +m. There is 
no loss of generality in assuming that xk # 0 for each k E N, and 
Let m E N, A E Rmxn and b E Rm be such that A = {x E Rn : 
Ax 2 b}. Since Axk 2 b for every k E N, dividing the inequality 
by Ilxkll and letting k --+ oo we obtain A i  2 0. This shows that 
8 E O+A. We have 
Hence 
k
k
 
( M X ~  + q, x) 2 (Mx , x ) + (q, xk) 'dx E A 'dk E N. 
(7.36) 
Dividing the last inequality by 11x"12 and letting k -+ oo we get 
0 2 (Mi, v) . Since M is positive semidefinite, from this we see that 
(Mi, i) = 0. Thus, by Lemma 7.1 we have 
Fix a point x E A. Since (MX',X~) 2 0 for every k E N, (7.36) 
implies that 
( M X ~  
+ q, x) 2 (q, x" 
'dk E N. 
Dividing the last inequality by IlxkII and letting k -+ oo we obtain 
Combining this with (7.37) we can assert that 
Since i E (OtA) \ {O}, from the last fact and Lemma 7.2 it follows 
that (7.28) does not hold. We have thus arrived at a contradiction. 
The proof is complete. 
Proof of Theorem 7.5. 
We first prove the implication (i) * (ii). To obtain a contradic- 
tion, suppose that Sol(AVI(M, q, A)) is nonempty and bounded, 

7.3 Upper-Lipschitz Continuity w.r.t, all Variables 
137 
while there exists a sequence (Mk,qk) E Rnxn x Rn such that 
(Mk7 qk) + (M7 q) and 
Since A is nonempty, for j E N large enough, the set 
is nonempty. Without restriction of generality we can assume that 
Aj # 0 for every j E N. By the Hartman-Stampacchia Theorem 
(Theorem 5.1) we can find a point, denoted by xkj, in the solution 
set SO~(AVI(M"~~",~)). 
We have 
Note that 
llxkliIl = j 
'dj E N. 
(7.40) 
Indeed, if IlxhiII < j then there exists p > 0 such that B(xhj, p) C 
B(0, j). Hence from (7.39) it follows that 
By Proposition 5.3, this implies that x"j E Sol(AVI(Mk, qk, A)), 
which is impossible because (7.38) holds. Fixing an index j E N 
we consider the sequence { x ~ T ~ ) ~ ~ N .  
From (7.40) we deduce that 
this sequence has a convergent subsequence. There is no loss of 
generality in assuming that 
lim xkj = xj, xj E Rn, llxj 11 = j. 
k+CG 
(7.41) 
Letting k -+ rn we deduce from (7.39) that 
( M X ~  
+q,x -xj) > 0 'dx E .Aj. 
(7.42) 
On account of (7.41), without loss of generality we can assume that 
Let us fix a point x E A. It is clear that there exists an index 
j, E N such that x E Aj for every j > j,. F'rom (7.42) we deduce 
that 
(Mxi + q,x - xj) > 0 'dj > jz. 

138 
7. Upper-Lipschi tz Continuity of the Solution Map 
Hence 
As in the last part of the proof of Lemma 7.3, we can show that 
E (O+A) \ (0) and deduce from (7.43) the following inequality 
(Mx + q, 5) I 0. 
Since the latter holds for every x E A, applying Lemma 7.2 we see 
that the inclusion (7.28) cannot hold. According to Lemma 7.3, the 
last fact implies that the set Sol(AVI(M, q, A)) cannot be nonempty 
and bounded. This contradicts our assumption. 
We now prove the implication (ii) + (i). Suppose that there 
exists E > 0 such that if matrix W E RnXn and vector 
E Rn sat- 
isfy condition (7.27) then the set SO~(AVI(%, ?? A)) is nonempty. 
Consequently, for any 
E Rn satisfying 
- qll < E ,  the set 
Sol(AVI(M, F, A)) is nonempty. Let Z t. Sol(AVI(M, if, A)). For 
any v E O+A we have 
Hence MZ + E (O+A)+. So we have q E (O+A)+ - MA. Since 
this inclusion is valid for each F satisfying [IF- qll < el we conclude 
that 
q E int((0'A)' 
- MA). 
By Lemma 7.3, the set Sol(AVI(M, q, A)) is nonempty and bounded. 
The proof is complete. 
Let us consider three illustrative examples. 
Example 7.1. Setting A = [O, +oo) c R1, M = (-I), and q = 
0, we have Sol(AVI(M, q, A)) = (0). Note that matrix M is not 
- 
positive semidefinite. Taking M = M and if = -0, where 8 > 0, 
we check at once that S O ~ ( A V I ( ~ ,  
F, A)) = 0. So, for this AVI 
problem, property (i) in Theorem 7.5 holds, but property (ii) does 
not hold. This example shows that, in Theorem 7.5, one cannot 
omit the assumption that M is a positive semidefinite matrix. 
Example 7.2. SettingA = (-oo,+oo) = R1, M = (O), andq=O, 
we have Sol(AVI(M, q, A)) = A. So property (i) in Theorem 7.5 
does not hold for this example. Taking MI = (0) and lf = 8, where 
0 > 0, we have S O ~ ( A V I ( ~ , ~ ~ ,  
A)) = 0. This shows that, for the 

7.3 Upper-Lipschitz Continuity w.r. t. all Variables 
139 
AVI problem under consideration, property (ii) in Theorem 7.5 fails 
to hold. 
Example 7.3. Setting A = [l,+oo) c R1, M = (O), and q = 0, 
- 
we have Sol(AVI(M, q, A)) = A. Taking M = M and F = 0, where 
6 > 0, we see that S O ~ ( A V I ( ~ ,  
6 
A)) = {I). But taking a = (-0) 
and y = 0, where 6 > 0, we see that S O ~ ( A V I ( ~ ,  
F, A)) = 0. So, for 
this problem, both the properties (i) and (ii) in Theorem 7.5 do not 
hold. 
In connection with Theorem 7.5, it is natural to raise the fol- 
lowing open question. 
QUESTION: 
IS it true that property (i) in Theorem 7.5 implies that 
there exists E > 0 such that if matrix a E Rnxn and vector 
E Rn 
satisfy condition (7.27) then the set sO~(AVI(W, F, A)) is bounded 
(may be empty)? 
The next example shows that property (i) in Theorem 7.5 does 
not imply that the solution sets S O ~ ( A V I ( ~ ,  
F, A)), where (z, 
lj) is 
taken from a neighborhood of (M, q), are uniformly bounded. 
Example 7.4. (See Robinson (1979), pp. 139-140) Let A = 
[0, +oo) C R1, M = (0)) and q = 1. It is clear that 
Sol(AVI(M, q, A)) = (0) 
- 
Taking M = (-,u) and F= 1, where ,u > 0, we have 
From this we conclude that there exist no E > 0 and S > 0 such 
that if matrix 
E RIX1 and vector 
E R1 satisfy condition (7.27) 
then s ~ ~ ( A v I ( ; ~ ~ ,  
A)) c 6 ~ ~ 1 .  
The following theorem is one of the main results on solution 
stability of AVI problems. One can observe that this theorem and 
Theorem 7.4 are independent results. 
Theorem 7.6. (See Robinson (1979), Theorem 2) Suppose that 
A c Rn is a nonempty polyhedral convex set. Suppose that M E 
RnXn is a given matrix and q E Rn is a given vector. If M is a posi- 
tive semidefinite matrix and i f  the solution set Sol(AVI(M, q, A)) is 
nonempty and bounded, then there exist constants E > 0, 6 > 0 and 
! 
> 0 such that if ( a ,  E RnXn x Rn, 
is positive semidefinite, 
and i f  
m a x m -  MIL [IF-911) < E .  
(7.44) 

140 
7. Upper-Lipschitz Continuity of the Solution Map 
then the set s~~(AvI(W, A)) is nonempty, 
SO~(AVI(%, if, A)) c 6 8p, 
(7.45) 
and 
SO~(AVI(;~~, 
if, A)) c sol(AVI(M, q, a))+e(llF- 
+ I I F ~ I I ) B R ~ .  
(7.46) 
Proof. Since M is positive semidefinite and Sol(AVI(M, q, A)) is 
nonempty and bounded, by Lemmas 7.2 and 7.3 we have 
b'v E O'A \ (0) 32 E A such that (Mx + q, v) > 0. 
(7.47) 
Moreover, according to Theorem 7.5, there exists EO > 0 such that 
for each matrix 
E RnXn and each if E Rn satisfying 
the set S O ~ ( A V I ( ~ ,  
if, A)) is nonempty. We claim that there exist 
constants E > 0 and 6 > 0 such that (7.45) holds for every ( F ,  @) E 
A *  
Rnxn x Rn satisfying condition (7.44) and the requirement that M 
is a positive semidefinite matrix. Indeed, if the claim were false 
we would find a sequence {(Mk, q"} 
in RnXn x Rn and a sequence 
{xk) in Rn such that Mk is positive semidefinite for every k E, 
k 
k 
( M  ,q ) -+ (M,q), xk E S O ~ ( A V I ( M ~ , ~ ~ , A ) )  
for every k E N, and 
lIxkll -+ +m as k + 00. For each x E A, we have 
Without loss of generality we can assume that xk # 0 for every 
k E N, and 
It is easily seen that B E (Of A)+. From (7.48) it follows that 
Dividing the last inequality by llxk112 and letting k -t oo we get 
0 2 (Mfi, Z). Since M is positive semidefinite, from this we see that 
(MB,Z) = 0. By Lemma 7.1 we have 

7.4 Commentaries 
141 
Fix a point x E A. Since Mk is positive semidefinite, we have 
(Mkxk, x" ) 0 for every k E N. Hence (7.49) implies that 
Dividing the last inequality by llxkll and letting k + oo we obtain 
Combining this with (7.50) we get 
(Mx + q, 8 )  5 0 'dx E A. 
Since 8  E (O+A)+ \ (01, the last fact contradicts (7.47). Our claim 
has been proved. We can now proceed analogously to the proof of 
Claim 3 in the proof of Theorem 7.4 to find the required constants 
E > O ,  S>Oand!>O. 
0 
7.4 Commentaries 
As it has been noted in Robinson (1981), p. 206, the class of poly- 
hedral multifunctions is closed under finite addition, scalar multi- 
plication, and finite composition. This means that if @ : Rn -t 2Rm, 
Q : Rm + 2RS, aj : Rn + 2Rm ( j  = 1,. . . ,m) are some given poly- 
hedral multifuntions and X E R is a given scalar, then the formulae 
(X@)(x) = X@(x) (trx E Rn), 
create new polyhedral multifunctions which are denoted by A@, al+ 
. . . + @,+ and Q o @, respectively. 
The proof of Theorem 7.4 is similar in spirit to the proof of 
Theorem 7.5.1 in Cottle et al. (1992). 
The 'elementary' proof of the results of Robinson (see Theorems 
7.5 and 7.6) on the solution stability of AVI problems with positive 
semidefinite matrices given in this chapter is new. We hope that 
it can expose furthermore the beauty of these results. The original 
proof of Robinson is based on a general solution stability theorem 

142 
7. Upper-Lipschi tz Continuity of the Solution Map 
for variational inequalities in Banach spaces (see Robinson (1979), 
Theorem 1). 
Results presented in this chapter deal only with upper-Lipschitz 
continuity properties of the solution map of parametric AVI prob- 
lems. For multifunctions, the lower semicontinuity, the upper semi- 
continuity, the openness, the Aubin property, the metric regular- 
ity, and the single-valuedness are other interesting properties which 
have many applications (see Aubin and Frankowska (1990), Mor- 
dukhovich (1993), Rockafellar and Wets (1998), and references 
therein). It is of interest to characterize these properties of the 
solution map in parametric AVI problems (in particular, of the so- 
lution map in parametric LCP problems). Some results in this 
direction have been obtained (see, for instance, Jansen and Tijs 
(l987), Gowda (l992), Donchev and Rockafellar (l996), Oettli and 
Yen (1995), Gowda and Sznajder (1996)). We will study the lower 
semicontinuity and the upper semicontinuity the solution map of 
parametric AVI problems in Chapter 18. 

Chapter 8 
Linear Fractional Vector 
Optimization Problems 
Linear Fractional Vector Optimization (LFVO) is an interesting 
area in the wider theory of vector optimization (see, for exam- 
ple, Choo and Atkins (1982, 1983), Malivert (1995), Malivert and 
Popovici (2000), and Steuer (1986)). LFVO problems have applica- 
tions in finance and production management (see Steuer (1986)). In 
a LFVO problem, any point satisfying the first-oder necessary opti- 
mality condition is a solution. Therefore, solving a LFVO problem 
is to solve a monotone affine Vector Variational Inequality (VVI). 
The original concept of VVI was proposed by Giannessi (1980). In 
this chapter we will apply the results of the preceding two chapters 
to establish some facts about connectedness and stability of the so- 
lution sets in LFVO problems. In particular, we will prove that the 
efficient solution set of a LFVO problem with a bounded constraint 
set is connected. 
8.1 LFVO Problems 
Let fi : Rn --t R (i = 1,2, . . . , m) be m linear fractional functions, 
that is 
for some ai E Rn, bi E Rn, ai E R, and pi E R. Let A = {x E Rn : 
Cx I d), where C E RrXn and d E Rr, be a nonempty polyhedral 
convex set. We assume that bTx + pi > 0 for a11 i E (1, . . , m) and 

144 
8. Linear Fkac tional Vector Optimization 
for all x E A. Define 
a =  ( a l , . . . , ~ r n ) ,  P =  (Pl,...,Prn), W =  (A,B,a,P). 
Thus A and B are n x m-matrices, a and ,O are vectors of Rm, and w 
is a parameter containing all the data related to the vector function 
f .  
Consider the following vector optimization problem 
(VP) 
Minimize f ( x )  subject to x E A. 
Definition 8.1. One says that x E A is an eficient solution of (VP) 
if there exists no y E A such that f (y) 5 f ( x )  and f (y) # f (x). 
If there exists no y E A such that f (y) < f ( x ) ,  then one says that 
x E A is a weakly eficient solution of (VP). 
Let us denote the eficient solution set and the weakly eficient 
solution set) of (VP) by Sol(VP) and SolW(VP), respectively. 
The following lemma will be useful for obtaining necessary and 
sufficient optimality conditions for (VP). 
Lemma 8.1. (See Malivert (1995)) Let cp(x) = (aTx+a)/(bTx+P) 
be a linear fractional function. Suppose that bTx + ,8 # 0 for every 
x E A. Then for any x, y E A, it holds 
where Vcp(x) denotes the gradient of cp at x. 
Proof. By the definition of gradient, 
(Vcp(x)7 Y - 4 
1 
= lim- [cp(x+ t(y - x)) - cp(x)] 
tL0 t 
a T ( x + t ( y - x ) ) + a  
aTx+a 
= lim - 
- 
bT(x+t(y-x))+P 
bTx+p 
- 
- 
I 
x)(bTx + ,O) - bT(y - x)(aTx + a )  
(bTx + ,8)2 
Hence we obtain 

8.1 LFVO Problems 
which completes the proof. 
0 
Given any x, y E A, x # y, we consider two points belonging to 
the line segment [x, y]: 
zt = x + t ( y  - x), zt1 = x + t y y  - x) (t E [O,l], t' E [O,t)). 
this we 
< c p ( 4  
> c p ( 4  
can conclude that: (i) If (Vcp(x), y - x) > 0 then 
for every t' E [0, t); (ii) If (Vcp(x), y - x) < 0 then 
for every t' E [0, t); (iii) If (Vcp(x), y - x) = 0 then 
cp(zt1) = cp(zt) for every t' E [0, t). Hence the function cp is mono- 
tonic on every line segment or ray contained in A. 
By definition, a function cp : A + R is quasiconcave on A if 
We say that cp is semistrictly quasiconcave on A if cp is quasiconcave 
on A and the inequality in (8.2) is strict whenever cp(x) # cp(y). If cp 
is quasiconcave on A and the inequality in (8.2) is strict whenever 
x # y, then we say that cp is strictly quasiconcave on A. Func- 
tion cp is said to be quasiconvex (resp., semistrictly quaszconvex, 
strictly quasiconcave)on A if the function -cp is quasiconcave (resp., 
semistrictly quasiconcave, strictly quasiconcave) on A. 
From the above-mentioned monotonicity of linear fractional func- 
tions it follows that if cp : A + R is a linear fractional function then 
it is, at the same time, semistrictly quasiconcave and semistrictly 
quasiconvex on A. In general, linear fractional functions are not 
strictly quasiconcave on their effective domain. Indeed, for any 
p E R, t E (0, I), and xl, x2 from the set 
we have cp((1 - t)xl + tx2) = min{cp(xl), cp(x2)). 

146 
8. Linear Fractional Vector Optimization 
Let 
m 
Then 
m 
riA = {A E R;" : EXi = 1, Xi > 0 for all i ) .  
i=l 
Theorem 8.1. (See Malivert (1995)) Let x E A. The following 
assertions hold: 
(i) x E Sol(VP) if and only if there exists X = ( X I ,  . . . , Am) E rih 
such that 
(ii) x E Solw(VP) if and only if there exists X = ( X I , .  . . ,Am) E A 
such that (8.3) holds. 
(iii) Condition (8.3) is satisfied i f  and only if there exists p = 
( p l , .  . . , p,), pj 2 0 for all j  = 1,. . . , r ,  such that 
where C j  denotes the j-th row of the matrix C and 
I($) = { j :  C j x  = dj). 
Proof. (i) W e  claim that x EE Sol(VP) if and only if 
Qx ( A  - 2 )  n ( - R;") = {o), 
where 
(bTx + ,Ol)aT - (aTx + al)bT 
Q z =  ( 
( b z x  + Pm)az - ( a g x  + am)bz 
is an (m x n)-matrix and Q x ( A  - x )  = {Qz(y - x )  : y E A). Indeed, 
x @ Sol(VP) if and only if there exist y E A and io such that 

8.1 LFVO Problems 
147 
By Lemma 8.1, the last system of inequalities is equivalent to the 
following one: 
( V f i ( x ) , ~ - x ) I O  ' d i ~ { l , . . . , r n ) ,  ( V f i o ( x ) , y - ~ ) < ~ .  
Since 
(8.6) 
we can rewrite (8.6) as follows 
Therefore, x f Sol(VP) if and only if there exists y E A such that 
QX(y -x) E -Ry 
and QX(y-x) # 0. 
Our claim has been proved. 
It is clear that D := Q,(A - x) is a polyhedral convex set. 
Hence, by Corollary 19.7.1 from Rockafellar (1970), K := coneD is 
a polyhedral convex cone. In particular, K is a closed convex cone. 
It is easily seen that (8.5) is equivalent to the property K n ( -  RT) = 
(0). Setting 
K + =  {zE Rm : (z,v) 2 0 'dv E K), 
we have K+ n intR: # 0. Indeed, on the contrary, suppose that 
K +  n intR: 
= 0. Then, by the separation theorem, there exists 
t E Rm \ (0) such that 
(<,u) I 0 5 (t,z) 'du E intRy, 'dz E Kt'. 
This implies that 
E -Ry and [ E (Kf)+ = K .  So we get 
t E K n-(- RT) = {O), a contradiction. - - 
Fix any 
E K+ n intR:. 
For X := X/(XI + . . . + i,), we have 
X E K+ n rih. Since (A, v) 2 0 for every v E K ,  we deduce that 
for every x E A. Hence (8.3) is valid. 
(ii) It is easily seen that x E SolW(VP) if and only if 

148 
8. Linear fractional Vector Optimization 
Using the separation theorem we find a multiplier X = (A1, . . . , Am) E 
A satisfying (8.3). 
(iii) It suffices to apply the Farkas Lemma, 
0 
Condition (8.3) can be rewritten in the form 
(vl) 
( M ( ~ > Y  
+ q ( 4 ,  Y - 4 2 0 
YY E A, 
where 
M(X> = (Mkj(4) 1 
ai,k and bi,x are the k-th components of ai and bi, respectively. 
It is clear that ( M ( x ) ) ~  
= - M(X). Therefore, (M(X)v, v) = 0 
for every v E Rn. In particular, M(X) is a positive semidefinite 
matrix. 
8.2 Connectedness of the Solution Sets 
Let X, Y be two topological spaces and G : X + 2Y be a multi- 
function. 
Definition 8.2. One says that G is upper semicontinuous (usc) at 
a E X if f for every open set V c Y satisfying G(a) c V there 
exists a neighborhood U of a, such that G(al) c V for all a' E U. 
One says that G is lower semicontinuous (lsc) at a E X if G(a) # 0 
and for every open set V c Y satisfying G(a) n V # 0 there exists 
a neighborhood U of a such that G(al) n V # 0 for all a' E U. 
Multifunction G is said to be continuous at a E X if it is simul- 
taneously upper semicontinuous and lower semicontinuous at that 
point. 
Definition 8.3. A topological space Z is said to be connected 
if there exists no pair (Z1, Z2) of disjoint nonempty open subsets 
Z1, Z2 of Z, such that Z = Z1UZ2. The space Z is arcwise connected 
if for any a, b E Z there exits a continuous mapping y : [O, 11 + Z 
such that y (0) = a, y (1) = b. One says that Z is contractible if there 
exist a point zO E Z and a continuous function H : Z x [O,1] + Z 
such that H(z, 0) = z and H(z, 1) = zO for every z E Z. 

8.2 Connectedness of the Solution Sets 
149 
It is clear that if Z is contractible then it is arcwise connected. 
It is also clear that if Z is arcwise connected then it is connected. 
The reverse implications are not true in general. 
The simple proof of the following result is left after the reader. 
Theorem 8.2. (See Warburton (1983), and Hirriart-Urruty (1985)) 
Assume that X is connected. If 
(i) for every x E X the set G(x) is nonempty and connected, and 
(ii) G is upper semicontinuous at every a E X (or G is lower 
semicontinuous at every a E X ) ,  
then the image set 
G(X) := U G(x), 
XEX 
which is equipped with the induced topology, is connected. 
Remark 8.1. Let X and Y be two normed spaces, G : X + 2' 
a multifunction. If G is upper-Lipschitz at a E X and G(a) is 
a compact set, then G is usc at a. So, according to Theorem 
7.6, if M is a positive semidefinite matrix and if the solution set 
Sol(AVI(M, q, A)) of (6.1) is nonempty and bounded, then the so- 
lution map Sol(AVI(., ., A) : Pn x Rn + 2Rn is usc at (M, q). Here 
the symbol P, stands for the set of all positive semidefinite n x n- 
matrices. 
We now turn our attention back to problem (VP). Denote by 
F(X) the solution set of the problem (VI)X described in Section 8.1. 
By Proposition 5.4, F(X) is closed and convex. If A is compact then, 
by Theorem 5.1, F(X) is nonempty and bounded. Consider the set- 
valued map F : A + 2Rn, X - F(X). According to Theorems 8.1 
and 8.2, 
Sol(VP) = U F(X) = F(riA), 
(8.7) 
x r i ~  
Solw(VP) = U F(X) = F(A). 
(8.8) 
XE A 
Remark 8.2. Using the results and the terminology in Lee et al. 
(1998) and Lee and Yen (2001) we can say that solving problem 
(VP) is equivalent to solve the monotone affine VVI defined by A 
and the affine functions 

150 
8. Linear fractional Vector Optimization 
Thus the first-order optimality condition of a LFVO problem can 
be treated as a special vector variational inequality. 
Theorem 8.3. (Benoist (1998), Yen and Phuong (2000)) If A is 
compact, then Sol(VP) is a connected set. 
Proof. Since riA is a convex set (so it is connected), F(X) is 
nonempty and connected for every X E riA, and the map F(.) is 
upper semicontinuous at every X E riA, Theorem 8.3 can be applied 
to the set-valued map F : riA t 2Rn. As a consequence, F(riA) is 
connected. Hence, by (8.7), Sol(VP) is connected. 
0 
Theorem 8.4. (Choo and Atkins (1983)) If A is compact then 
Solw(VP) is a connected set. 
Proof. Apply Theorem 8.3 and formula (8.8) to the set-valued map 
F : A + 2 R n .  
0 
In fact, Choo and Atkins (1983) established the following stronger 
result: If A is compact then Solw(VP) is connected by line segments. 
The latter means that for any points x, y E SolW(VP) there exists a 
finite sequence of points x0 = x, xl, . . . , xk = jj such that each line 
segment [xj, xj+1] ( j  = 0,1, . . . , k - 1) is a subset of Solw (VP). 
If A is unbounded, then Sol(VP) and S O ~ ( V P ) ~  
may be discon- 
nected. 
Example 8.1. (Choo and Atkins (1983)) Consider problem (VP) 
with 
Using Theorem 8.1, one can verify that 
Recall that a component of a topological space is a maximal 
connected subset (that is, a connected subset which is properly 
contained in no other connected subset). 
Example 8.2. (Hoa et al. (2004)) Consider problem (VP) where 
n = m , m > 2 ,  

8.2 Connectedness of' the Solution Sets 
and 
1 
-xi + - 
f&) = 
2 
3 
( i =  1, ..., m). 
c:=l 
xk - - 
4 
Using Theorem 8.1 one can show that 
Sol(VP) = SolW(VP) = {(xl, 0,. . . , o ) ~  
: x1 2 1 )  
~ ( ( 0 ,  
x2,. . . , o ) ~  
: 5 2  2 1) 
.,. . . .  ... 
~ ( ( 0 , .  
. . ,0, xJT : x .  2 1). 
Hence each of the sets Sol(VP) and Solw(VP) has exactly m com- 
ponents. 
The following question (see Yen and Phuong (2000)) remains 
open: Is it true that every component of Sol(VP) is connected by 
line segments? 
The following possible estimates have been mentioned in Hoa et 
al. (2004): 
(Sol(VP)) I min{m, n )  , x (Solw (VP)) I min{m, n )  . 
Here x(M) denotes the number of components of a subset M c Rn 
in its induced topology. So far, the above estimates have not been 
proved even for bicriteria LFVO problems. 
It is worthy to observe that the sets Sol(VP) and SolW(VP) may 
be not contractible, even in the case they are arcwise connected. 
Example 8.3. (Huy and Yen (2004b)) Consider problem (VP), 
where 
Using Theorem 8.1 one can prove that the sets Sol(VP) and Solw(VP) 
coincide with the surrounding surface of the parallelepiped A; that 
is 
SO~"(VP) = Sol(VP) = Fl U F2 U F3, 

152 
8. Linear Fractional Vector Optimization 
8.3 Stability of the Solution Sets 
Since problem (VP) depends on the parameter w = (A, B? a ,  P), in 
this section it is convenient for us to rename the sets Sol(VP) and 
Solw(VP) into E(w) and Ew(w), respectively. The solut.ion set of 
the problem (VI)x is now denoted by F (w, A). 
Theorem 8.5. If A is compact, then the multifunction w' H 
Ew(w') is upper semicontinuous at w. 
Proof. Since A is compact and nonempty, EW(d) is a nonempty 
compact subset of A. Suppose that. R C Rn is an open set contain- 
ing Ew (w). Choose b > 0 so that 
For each y E Ew(w), by Theorem 8.2 there exists A E A such that, 
y E F(w, A). By Theorem 7.6, there exist constants [(A) > 0 and 
el(A) > 0, such that l(X)el (A) < 2-lI26 and 
F(w', A') c F(w, A) + !(~)ll(~', 
A') - (w, A)llBRn 
(8.10) 
for all w' = (A', B', a', P') and A' E A satisfying 
By definition, 
llAll = max{llAvII : v E B R ~ )  
and 
Since A is compact and the family {U(X))xE~, 
where 
is an open covering of A, there exists a finite sequence A(1), . . . , A(k) E 
A such that 
A C u(x(')) U . . . U u(x("). 
(8.11) 
Let 
E = min{~l(A(~)) 
: i = 1, . . . , k). 

8.4 Commentaries 
153 
Fix any w' 
y' E Ew (w') 
there exists 
= (A', B', a', p) satisfying llw' - wI1 < E. For every 
there exists A' E A such that y' E F(wl, A'). By (8.11), 
io E {I,. . . , k )  such that A' E u(x(~o)). 
By (%.lo), 
Combining this with (8.9) we can deduce that E(w1) c S2 for every 
w' sat,isfying I(w' - wll < 6. The proof is complete. 
If one can prove that there exists a finite upper bound for the 
family 
(see the preceding proof), then the multifunction 
w' H EW(w') is upper-Lipschitz at w. 
By giving a counterexample, Kum, Lee and Yen (2004) have 
shown that, even in the case where A is a compact polyhedral con- 
vex set, the multifunction w' H 
E(w1) may be not upper semicon- 
tinuous at w. Nevertheless, from Theorem 8.5 it is easy to derive 
the following sufficient condition for the usc property of this multi- 
function. 
Theorem 8.6. If A is compact and if E(w) = Ew(w), then the 
multifunction w' I+ 
E(wt) is upper semicontinuous at w. 
8.4 Commentaries 
The material presented in this chapter is adapted from Yen and 
Phuong (2000). We have seen that the results on the solution ex- 
istence and the stability of monotone AVI problems in Chapters 
6 and 7 are very useful for studying LFVO problems on compact 
constraint sets. 
Theorem 8.3 solves a question discussed in the final part of Choo 
and Atkins (1983). This result is a special corollary of t,he theorem 
of Benoist (1998) which asserts that the efficient solution set of the 
problem of maximizing a vector function with strictly quasiconcave 
components over a convex compact set is connected. The proof 
given here is due t.o Yen and Phuong (2000). Note that Warburton 
(1983) has extended the result in Theorem 8.4 by proving that, in 
a vector maximization problem with continuous quasiconvex func- 
tions and a compact convex constraint set, the weakly efficient so- 
lution set is connected. Connectedness and contractibility of the 
efficient sets of quasiconcave vector maximization problems have 

154 
8. Linear Fractional Vector Optimization 
been discussed intensively in the literature (see Warburton (1983), 
Schaible (1983), Choo et al. (1985), Luc (1987), Hu and Sun (1993), 
Wantao and Kunping (1993), Benoist (2001), Huy and Yen (2004a, 
2004b), and the references therein). 
The reader is referred to Bednardczuck (1995) and Penot and 
Sterna-Karwat. (1986) for some general results on stability of vector 
optimization problems. Stability of the solution maps of LFVO 
problems on noncompact sets deserves further investigations. It 
seems to us that some ideas and techniques related to asymptotic 
cones and asymptotic functions from Auslender and Teboulle (2003) 
can be useful for this purpose. 

Chapter 9 
The Traffic Equilibrium 
Problem 
A traffic network can be modelled in a form of a variational in- 
equality. Solutions of the variational inequality correspond to the 
equilibrium flows on the traffic network. Variational inequality can 
be also a suitable model for studying other kinds of economic equi- 
libria. The aim of this chapter is to discuss the variational inequality 
model of the traffic equilibrium problem. Later on, in Chapter 17, 
by using some results on solution sensitivity of convex QP prob- 
lems we will establish a fact about the Lipschitz continuity of the 
equilibrium flow in a traffic network where the travel costs and the 
demands are subject to change. 
Traffic Networks Equilibria 
Consider a traffic system with several cities and many roads con- 
necting them. Suppose that the technical conditions (capacity and 
quality of roads, etc.) are established. Assume that we know the 
demands for transportation of some kind of materials or goods be- 
tween each pair of two cities. The system is well functioning if all 
these demands are satisfied. The aim of the owner of the network is 
to keep the system well functioning. The users (drivers, passengers, 
etc.) do not behave blindly. To go from A to B they will choose 
one of the roads leading them from A to B with the minimum cost. 
This natural law is known as the user-optimizing principle or the 
Wardrop principle. The traffic flow satisfying demands and this law 
is said to be an equilibrium flow of the network. By using this prin- 

156 
9. The Traffic Equilibrium Problem 
ciple, in most of the cases, the owner can compute or estimate the 
traffic flow on every road. The owner can affect on the network, for 
example, by requiring high fees from the users of the good roads to 
force them to use also some roads of lower quality. In this way, a 
new equilibrium flow, which is more suitable in the opinion of the 
owner, can be reached. 
Traffic network is an example of networks acting in accordance 
with the Wardrop equilibrium principle. Other examples can be 
telephone networks or computer networks. 
As it was proved by Smith (1979) and Dafermos (1980), a traffic 
network can be modelled in a variational inequality. 
Consider a graph G consisting of a set N of nodes and a set A of 
arcs. Every arc is a pair of two nodes. The inclusion a E A means 
that a is an arc. A path is an ordered family of arcs al, . . . , a,, 
where the second node of a, coincides with the first node of a,+l for 
s = 1, . . . , m - 1. We say that the path {al, . . . , a,) 
connects the 
first node of a1 with the second node of a,. 
Let I be a given set of the origin-destination pairs (OD-pairs, 
for brevity). Each OD-pair consists of two nodes: the origin (the 
first node of the pair) and the destination (the second node of the 
pair). Denote by P, the family of all paths connecting the origin 
with the destination of an OD-pair i E I .  Let P = Ui,, P, and let 
I PI denote the number of elements of P. 
A vector v = (v, : a E A), where v, 2 0 for all a E A, is said 
to be a flow (or flow on arcs) on the graph. Each v, indicates the 
amount of material flow on arc a. 
Let there be given a vector function 
~ ( v )  
= (ca(v) : a E A), 
where ca(v) 2 0 for all a E A. This function c(.), which maps 
RIA[ to RIAl, is called the travel cost function. Each number c,(v) 
is interpreted as the travel cost for one unit of material flow to go 
through an arc a provided that the flow v exists on the network. 
There are many examples explaining why the travel cost on one arc 
should depend on the flows on other arcs. 
The travel cost on a path p E Pi (i E I) is given by the formula 

9.1 Traffic Networks Equilibria 
157 
Let C(v) = (Cp(v) : p E P). For each i E I, define the minimum 
travel cost ui(v) for the OD-pair i by setting 
~i (v) = min{Cp(v) : p E P,). 
Obviously, Cp(v) - ui (v) 2 0 for each i E I and for each p E P,. 
Let D = (JaP) be the incidence matrix of the relations "arcs-paths"; 
that is 
for all a E A and p E P .  
It is natural to assume the fulfilment of the following flow- 
invariant law: 
va = C 6ap.p. 
(9.1) 
P E P  
Let there be given also a vector of demands g = (gi : i E I). 
Every component gi indicates the demand for an OD-pair i, that 
is the amount of the material flow going from the origin to the 
destination of the pair i. We say that a flow v on the network 
satisfies demands if 
Note that 
(the set of flows satisfying demands) is a polyhedral convex set. 
If there are given upper bounds (7, : p E P), yp > 0 for all 
p E P, for the capacities of the arcs, then the set of flows satisfying 
demands is given by the formula 
(9.4) 
In this case, A is a compact polyhedral convex set. 
Definition 9.1. A trafic network {B, I, c(v), g) consists of a graph 
G = (N,A), a set I of OD-pairs, a travel cost function c(v) = 
(ca(v) : a E A), and a vector of demands g = (gi : i E I). 

158 
9. The B-affic Equilibrium Problem 
The following user-optimizing principle was introduced by 
Wardrop (1952). This equilibrium condition explains how the equi- 
librium flow must depend on the travel cost function. 
Definition 9.2. (The Wardrop principle) A flow v on the network 
{G, I, c(v), g) is said to be an equilibrium flow if it satisfies demands 
and, for each i E I and for each p E Pi, it holds 
The above principle can be stated equivalently as follows: If 
C,(V) (the travel cost on path p E P,) is greater than ui(.tj) (the 
minimum travel cost for the OD-pair i) then ZP = 0 (the flow on 
p is zero). It is important to stress that the fact that the flow on p 
is zero does not imply that the flows on all the arcs of p are zeros! 
The problem of finding an equilibrium flow 
on the given net- 
work {GJ, c(v) , g) is called the network equilibrium problem. 
9.2 Reduction of the Network Equilib- 
rium Problem to a Complementar- 
ity Problem 
Let 
S(v) = {Cp(v) - ui(v) : p E P,, i E I). 
We see that the number of components of vector S(v) is equal to 
I PI. Since Cp(v) - ui(v) > 0 for all p E Pi and i E I, we have 
S(v) > 0. Note that v = (up : p E P) is also a nonnegative vector. 
Proposition 9.1. A flow 
E A on a network {GJ, c(v), g) is an 
equilibrium flow if and only if 
Proof. Suppose that fi = (.ii, : p E P) is a flow satisfying (9.5). 
Since v > 0 and S(v) > 0, the equality (S(v), v) = 0 is equivalent 
to 
v,(Cp(v)-ui(v)) = O  
VpE P,, 
V i E  I. 

9.3 Reduction to a Variational Inequality 
159 
Therefore, for each i E I and for each p  E P,, if GP > 0 then Cp(6) - 
ui(6) = 0. This means that the Wardrop principle is satisfied. 
Conversely, if 6 = (6, : p  E P) is an equilibrium flow then it is easy 
to show that (9.5) holds. 
0 
Note that (9.5) is a (generalized) nonlinear complementarity 
problem under a polyhedral convex set constraint of the form 
v E A, 
f (v) 2 0, 
vTf (4 = 0, 
where f (v) : = S(v) and A C RY'. 
9.3 Reduction of the Network Equilib- 
rium Problem to a Variational In- 
equality 
Consider the incidence matrix B = (Pip) of the relations "path- 
OD-pair" , where 
1 if p E Pi 
~
i
p
 
= { 0 if p f e .  
Note that a flow v satisfies demands if and only if 
Indeed, (9.6) means that (Bv)i = gi for all i E I. The latter is 
equivalent to (9.2). Let A be defined by (9.3) or (9.4). 
The next proposition, which is due to Smith (1979) and Dafer- 
mos (1980), reduces the network equilibrium problem to a varia- 
tional inequality. The proof of below is taken from De Luca and 
Maugeri (1989). 
Proposition 9.2. A flow 6 E A is an equilibrium flow of the 
network { G J ,  c(v), g} if and only if 
Proof. Necessity: Let 6 E A be an equilibrium flow. Let v E A. 
Define 
(1) - 
- { p E  Pi : Cp(6) =ui(6)}) 

160 
9. The Traffic Equilibrium Problem 
According to the Wardrop principle, we have 
So, (9.7) is valid. 
Suficiency: Let 3 E A be such that (9.7) holds. It suffices 
to show that if for an OD-pair io E I there exist two paths lj E 
Pio, j7 E Pio such that 
Cfi(v) > c&q, 
then 5,- = 0. Consider vector v = (up : p E P )  defined by 
We have v 2 0 and 

9.3 Reduction to a Variational Inequality 
161 
Indeed, if i # io then the equality is obvious. If i = io then we have 
Hence v E A. From (9.7) it follows that 
Since Cc(,) - Cc(v) > 0, we have 
= 0. 
We proceed to show that (9.7) can be expressed as a variational 
inequality on thc set of flows on arcs. 
According to (9.1), vd = Dv for every v E A. Therefore, the set 
Z of flows on arcs can be defined as follows 
Z = { z : z = D v ,  v E A )  
= { z  : z = Dv, Bv = g, v 2 0). 
(9.8) 
Proposition 9.3. A flow v~ = (v, : a E A)E Z is corresponding 
to an equilibrium flow of the network {G,I, c(v), g} if and only if 
for all V A  = (v, : a E A)E Z. 
Proof. Recall that c(v) is the vector of travel costs on arcs. By 

162 
9. The naffic Equilibrium Problem 
definition of the matrix D = (daP)> we have 
( 
A - A 
= C ca (v) (va - fa) 
The proof is completed by using (9.8), Proposition 9.2, and the 
equality 
( ~ ( e ) ,  
VA - fA) = (C(e), v - 6) 
which holds for every v E A. 
The variational inequality in (9.9), in some sense, is simpler 
than that one in (9.7). Both of them are variational inequalities on 
polyhedral convex sets, but the constraint set of (9.9) usually has 
a smaller dimension. Besides, in most of the cases we can assume 
that c(v) is a locally strongly monotone function (see Chapter 17), 
while we cannot do so for C(v). 
9.4 Commentaries 
The material of this chapter is adapted from the reports of Yen and 
Zullo (1992), Chen and Yen (1993). 
Numerical methods for solving the traffic equilibrium problem 
can be seen in Patriksson (1999). Various network equilibrium 
problems leading to finite-dimensional variational inequalities are 
discussed in Nagurney (1993). 

Chapter 10 
Upper Semicontinuity of 
the KKT Point Set 
Mapping 
We have studied QP problems in Chapters 1-4. Studying various 
stability aspects of QP programs is an interesting topic. Although 
the general stability theory in nonlinear mathematical programming 
is applicable to convex and nonconvex QP problems, the specific 
structure of the latter allows one to have more complete results. 
In this chapter we obtain some conditions which ensure that a 
small perturbation in the data of a quadratic programming prob- 
lem can yield only a small change in its Karush-Kuhn-Tucker point 
set. Convexity of the objective function and boundedness of the 
constraint set are not assumed. Obtaining necessary conditions for 
the upper semicontinuity of the KKT point set mapping will be our 
focus point. Sufficient conditions for the upper semicontinuity of 
the mapping will be developed on the framework of the obtained 
necessary conditions. 
10.1 KKT Point Set of the Canonical 
QP Problems 
Here we study QP problems of the canonical form: 
1 
Minimize f (x) := -xT DX + cTx 
2 
(10.1) 
subject to x E A(A, b) := {x E Rn : Ax t: b, x > 01, 

164 
10. Upper Semicontinuity of the KKT Point Set 
where D E RgXn, A E Rmxn, c E Rn and b E Rm are given 
data. In the sequel, sometime problem (10.1) will be referred to 
as QP(D, A, c, b). 
Recall that 3 E Rn is a Karush-Kuhn-Tucker point of (10.1) if 
there exists a vector X E Rm such that 
The set of all the Karush-Kuhn-Tucker points of (10.1) is denoted by 
S(D, A, c, b). In Chapter 3, we have seen that if 3 is a local solution 
of (10.1) then 3 E S(D, A,c, b). This fact leads to the following 
standard way to solve (10.1): Find first the set S(D, A, c, b) then 
compare the values f (x) among the points x E S(D, A, c, b). Hence, 
one may wish to have some criteria for the (semi)continuity of the 
following multifunction 
In Section 10.2 we will obtain a necessary condition for the up- 
per semicontinuity of the multifunction s(., 
., c, b) at a given point 
(D, A) E RgXnx Rmxn. In Section 10.3 we study a special class of QP 
problems for which the necessary condition obtained in this section 
is also a sufficient condition for the usc property of the multifunc- 
tion in (10.3). This class contains some nonconvex QP problems. 
Sections 10.4 and 10.5 are devoted to sufficient conditions for the 
usc property of the multifunction in (10.3). In Section 10.5 we will 
investigate some questions concerning the usc property of the KKT 
point set mapping in a general QP problem. 
Note that the upper Lipschitz property of the multifunction 
S(D, A, ., 
a )  with respect to the parameters (c, b) is a direct con- 
sequence of Theorem 7.3 in Chapter 7. 
Since (10.2) can be rewritten as a linear complementarity prob- 
lem, the study of continuity of the multifunction (10.3) is closely 
related to the study of continuity and stability of the solution map 
in linear complementarity theory (see Jansen and Tijs (1987), Cot- 
tle et al. (1992), Gowda (1992), Gowda and Pang (1992, 1994a)). 
However, when the data of (10.1) are perturbed, only some compo- 
nents of the matrix M = M(D, A) (see formula (10.18) below) are 
perturbed. So, necessary conditions for (semi)continuity and sta- 
bility of the Karush-Kuhn-Tucker point set cannot be derived from 

10.2 A Necessary Condition for the usc Property 
165 
the corresponding results in linear complementarity theory (see, for 
example, Gowda and Pang (1992)) where all the components of M 
are perturbed. 
10.2 A Necessary Condition for the usc 
Property of S(.) 
We now obtain a necessary condition for S(., 
a ,  c, b) to be upper 
semicontinuous at a given pair (D, A) E Rnsxn x Rmxn. 
Theorem 10.1. Assume that the set S(D, A, c, b) is bounded. If 
the multifunction S(., a ,  c, b) is upper semicontinuous at (D, A), then 
Proof. Arguing by contradiction, we assume that S(D, A, c, b) is 
bounded, the multifunction S(., ., c, b) is usc at (D, A), but (10.4) 
is violated. The latter means that there is a nonzero vector 2 E 
S(D, A, 0,O). Hence there exists 
E Rm such that 
2 2 0 ,  i 2 0 ,  
(10.6) 
g T ~ 2  
= 0. 
(10.7) 
Setting 
1 ,. 
1 - 
xt=-x, 
At=;A, 
f o r e v e r y t ~  (O,l), 
t 
(10.8) 
we claim that there exist matrices Dt E RgXn and At E Rmxn such 
that Dt + D, At -t A as t -t 0, and 
xt L 0, 
At 2 0, 
(10.10) 
xT(D~x~ 
- ATA~ + C) + A;(A~x~ - b) = 0. 
(10.11) 
Matrices Dt and At will be of the form 

166 
10. Upper Semicontinuity of the KKT Point Set 
where matrices Do and A. are to be constructed. Since 
and 
1 
Atxt - b = - ( A  + tAo)2 - b 
f 
= -A2 + Ao2 - b, 
t 
the following conditions, due to (10.5), imply (10.9): 
1 
1 - 
As xt = -2 and At = -A, (10.6) implies (10.10). Taking account of 
t 
t 
(10.7), we have 
1 
= - (
2
~
~
2
 
- j.T~T;\ + i T ~ 2  
+-gT (
~
~
2
 
- ~;fi 
+ C )  + : P ( A o 2  - b) 
It 
t 
= - 
t [ 2 ' ( ~ 0 2  - A;fi + c) + iT(Ao2 - b)] . 
So the following equality implies (10.11) : 
Let i = 
. . , 2,), where iii > 0 for i E I C (1,. . . , n}, and 2i = 0 
for i $ I. Since 2 # 0, I must be nonempty. Fixing an io E I ,  we 
define A. as the m x n-matrix whose io-th column is 2i1b, and 
whose other columns consist solely of zeros. For this A. we have 
Ao2 - b = 0, hence the second inequality in (10.13) is satisfied, and 
condition (10.14) becomes the following one: 

10.2 A Necessary Condition for the use Property 
167 
We have to find a matrix Do E RgXn such that this condition and 
the first inequality in (10.13) are valid. For this purpose it is enough 
to find a symmetric matrix Do such that 
where w := A?A - c E Rn. 
If w = (WI, . . . , w,), then we put Do = (dij) , 1 5 i, j 5 n, 
where 
- -1 
dii:=xi wi 
forall ~ E I ,  
dioj = djio := 2 ; ' ~ ~  for all j E {1,2,. . . , n) \ I, 
and 
dij : = 0  for other pairs (i,j), 15 i , j  5 n. 
A simple direct computation shows that this symmetric matrix Do 
satisfies (10.15). 
We have thus constructed matrices A. 
and Do such that for 
xt, At, Dt and At defined by (10.8) and (10.12), the conditions 
(10.9)-(10.11) are satisfied. As a consequence, xt E S(Dt , At, c, b). 
Since S(D, A, c, b) is a bounded set, there exists a bounded open 
set R such that S(D,A,c, b) C R. Since Dt --+ D and At 4 A as 
t 4 0, and the multifunction S(-, .,c, b) is usc at (Dl A), we have 
xt E R for all t sufficiently small. This is a contradiction, because 
1 
Observe also that, in general, (10.4) is not a sufficient condition 
for the upper semicontinuity of S(.) at (D, A, c, b). 
Example 10.1. Consider the problem QP(D, A, c, b) where 
For each t E (0, I), let At = [-t, -11. By direct computation using 
(10.2) we obtain 
Thus, for any bounded open set R c R2 containing S(D, A, c, b) , 
the inclusion 
S(D7 At, c, b) c fl 

168 
10. Upper Semicontinuity of the KKT Point Set 
fails to hold for t > 0 small enough. Since At -+ A as t + 0, S(.) 
cannot be usc at (D, A, c, b). 
In the next section we will study a special class of quadratic 
programs for which (10.4) is not only a necessary but also a suffi- 
cient condition for the upper semicontinuity of S(.) at a given point 
(D, A, c, b). 
10.3 A Special Case 
We now study those canonical QP problems for which the following 
condition (H) holds: 
(H) There exists 3 E Rn such that AZ > 0, 
3 2 0. 
Denote by 3-1 the set of all the matrices A E Rmxn satisfying 
(H). 
The next statement can be proved easily by applying Lemma 3 
from Robinson (1977) and the Farkas Lemma (Theorem 3.2). 
Lemma 10.1. Each one of the following two conditions is equiva- 
lent to (H): 
(i) There exists 6 > 0 such that, for every matrix A' satisfying 
IIA'- All < 6 and for every b E Rn, the system A'x 2 b, x 2 0 
is solvable. 
(ii) For any X E Rn, if 
then X = 0. 
Obviously, (H) implies the existence of an 2 E Rn satisfying 
A2 > 0, 2 > 0. Thus A(A, 0) has nonempty interior. Now suppose 
that (H) is fulfilled and b E Rn is an arbitrarily chosen vector. 
Since A(A, b) + A(A, 0) c A(A, b) and, by Lemma 10.1, A(A, b) 
is nonempty, we conclude that A(A, b) is an unbounded set with 
nonempty interior. Besides, it is clear that there exists Z E Rn 
satisfying 
AZ>b, 
Z > 0 .  
The latter property is a specialization of the Slater constraint qual- 
ification (Mangasarian (1969), p. 78), and the Mangasarian-Fro- 
movitz constraint qualification (called by Mangasarian the modi- 
fied Arrow-Hurwicz-Uzawa constraint qualification) (Mangasarian 

10.3 A Special Case 
169 
(1969), pp. 172-173). These well-known constraint qualifications 
play an important role in the stability analysis of nonlinear opti- 
mization problems. 
In the sequence, the inequality system Ax 2 b, where A E Rmxn 
and b E Rm, is said to be regular if there exists xO E Rn such that 
Ax0 > b. 
As it has been noted in Section 5.4, a pair (3, X) E Rn x Rm 
satisfies (10.2) if and only if 2 := (; ) is a solution to the following 
linear complementarity problem 
where 
Denoting by Sol(M, q) the solution set of (10.17), we have 
where 7l-1 : Rnfm -+ Rn is the linear operator defined by setting 
7l-1 ( ; 
) := x for every (;) 
E R~+.. 
The notion of Ro-matrix, which is originated to Garcia (1973), 
has proved to be useful in characterizing the upper semicontinuity 
property of the solution set of linear complementarity problems (see 
Jansen and Tijs (1987), Cottle et al. (1992), Gowda (1992), Gowda 
and Pang (1992), Oettli and Yen (1995, 1996a, 1996b)), and in 
studying other questions concerning these problems (see Cottle et 
al. (1992)). Ro-matrices are called also pseudo-regular matrices 
(Gowda and Pang (1 992), p. 78). 
Definition 10.1. (See Cottle et al. (1992), Definition 3.8.7) A ma- 
trix M € Rpxp is called an &-matrix if the linear complementarity 
problem 
has the unique solution x = 0. 
Theorem 10.2. Assume that A E 3-1 and that S(D, A, c, b) is 
bounded. If the multifunction S(., ., c, b) is upper semicontinuous 
at (D, A), then M(D, A) is an Ro-matrix. 

170 
10. Upper Semicontinuity of the KKT Point Set 
Proof. Since S ( D ,  A, c, b) is bounded and S(., ., c, b) is usc at 
( D ,  A), by Theorem 10.1, (10.4) holds. Let 2 = (i) 
be such 
that 
M i  2 0, i 2 0, i T ~ 2  
= 0, 
(10.20) 
where M = M ( D ,  A). This means that the system (10.5)-(10.7) is 
satisfied. Hence, 2 E S ( D ,  A, 0,O). Then 2 = 0 by (10.4), and the 
system (10.5)-(10.7) implies 
Since A E W ,  j\ = 0. Thus any f satisfying (10.20) must be zero. So 
M ( D ,  A )  is an Ro-matrix. 
Corollary 10.1. Let A E W .  If for every (c, b) E Rn x Rm the 
multifunction S ( - ,  .,c, b) is upper semicontinuous at ( D , A ) ,  then 
M ( D ,  A )  is an %-matrix. 
Proof. Consider problem (10.17), where M = M ( D ,  A )  and q are 
defined via D, A, c, b by (10.18). Lemma 1 from Oettli and Yen 
(1995) shows that there exists q E Rn+" such that Sol(M,q) is 
bounded. If (2, b) E Rn x Rm is the pair satisfying q = ($,) , 
then it follows from (10.19) that S ( D ,  A, E, b) is bounded. Since 
S(., 
a ,  E, b) is usc at ( D ,  A), M ( D ,  A )  is an &-matrix by Theorem 
10.2. 
0 
The following statement gives a sufficient condition for the usc 
property of the multifunction S(.). 
Theorem 10.3. If M ( D , A )  is an Ro-matrix, then for any (c, b) E 
Rn x Rm the set S ( D ,  A, c, b) is bounded, and the multifunction S(.) 
is upper semicontinuous at ( D ,  A, c, b). If, in addition, S ( D ,  A, c, b) 
is nonempty, then there exist constants y > 0 and 6 > 0 such that 
S(D1, A', c', b') c S ( D ,  A, c, b) 
+y(llD' - Dl1 + //A' - All + IIc' - c I I  + I/b' - bll)B~n, 
(10.21) 
for all (c', b') E Rn x Rm, D' E Rnxn and A' E Rmxn satisfying 
\ID' - Dl1 < 6, llA' - All < 6. 
Proof. Since M ( D , A )  is an Ro-matrix, by Proposition 5.1 and 
Theorem 5.6 in Jansen and Tijs (1987) and the remarks before 
Theorem 2 of in Gowda (1992), Sol(M, q) is a bounded set, and 
the solution map Sol(.) is usc at ( M ,  q). It follows from (10.19) that 

10.3 A Special Case 
171 
S(D, A, c, b) is bounded. Let R c Rn be an arbitrary open set 
containing S(D, A, b, c). By the upper semicontinuity of Sol(.) at 
(M, q), we have 
Sol(M1, q') c R x Rm, 
(10.22) 
for all (MI, q') in a neighborhood of (M, q) . Using (10.19) and (10.22) 
we get S(D', A', c', b') c R, for all (D', A', c', b') in a neighborhood 
of (D, A, c, b). 
The upper Lipschitz property described in (10.21) follows from 
a result of Gowda (1992). Indeed, since S(D, A, c, b) is nonempty, 
Sol(M, q) is nonempty. Since M is an Ro-matrix, by Theorem 9 of 
Gowda (1992) there exist yo and So such that 
for all q' E Rn+m and for all M' E R ( ~ + ~ ) ~ ( ~ + ~ )  
satisfying 11 M' - 
MI1 < So. The inclusion (10.21) follows easily from (10.23) and 
(10.19). 
0 
Combining Theorem 10.3 with Corollary 10.1 we get the follow- 
ing result. 
Corollary 10.2. If A E 3-1, then for every (c, b) E Rn x Rm the 
multifunction S(., ., c, b) is upper semicontinuous at (D, A) if and 
only if M (D, A) is an Ro-matrix. 
We now find necessary and sufficient conditions for M(D, A) to 
be an Ro-matrix. By definition, M = M(D, A) is an %-matrix if 
and only if the system 
has the unique solution (2, 1) = (0,O). 
Proposition 10.1. If M = M(D, A) is an Ro-matrix then A E 3-1 
and the following condition holds: 
Proof. If 1 E Rm is such that - ~ ~ 1  
2 0, 1 2 0, then (0, 1) is a 
solution of the system (10.24)-(10.26). If M is an %-matrix then 
we must have 
= 0. By Lemma 10.1, A E 3-1. Furthermore, for any 

172 
10. Upper Semicontinuity of the KKT Point Set 
2 E Rn satisfying D2 > 0, A2 > 0, 2 > 0 and zTD2 = 0, it is clear 
that (2,O) is a solution of (10.24)-(10.26). If M is an %-matrix 
then (2,O) = (0,O). We have thus proved (10.27). 
The above proposition shows that the inclusion A E 7-1 and the 
property (10.27) are necessary conditions for M = M(D, A) to be 
an %-matrix. Sufficient conditions for M = M(D, A) to be an Ro- 
matrix are given in the following proposition. Recall that a matrix 
is said to be nonnegative if each of its elements is a nonnegative real 
number. 
Proposition 10.2. Assume that A E 7-1. The following properties 
hold: 
(i) If A is a nonnegative matrix and D is an %-matrix then 
M (Dl A) is an Ro-matrix. 
(ii) If D a positive definite or a negative definite matrix, then 
M (Dl A) is an &-matrix. 
Proof. For proving (i), let D be an Ro-matrix and let (2, i) be 
a pair satisfying (10.24)-(10.26). Since A is a nonnegative matrix, 
the inequalities D i  - ~~i 
> 0 and i 2 0 imply D i  2 A*A 2 0. 
Hence (10.24)-(10.26) yield D2 > 0, i > 0, i T D i  = 0. Since 
D is an Ro-matrix, i = 0. This fact and (10.24)-(10.26) imply 
- ~ ~ i  
> 0, i > 0. Since A E 'Id, i = 0 by Lemma 10.1. Thus 
(2, i) = (0,O) is the unique solution of (10.24)-(10.26). Hence M 
is an Ro-matrix. We omit the easy proof of (ii). 
0 
Observe that in Proposition 10.2(i) the condition that A is a 
nonnegative matrix cannot be dropped. 
Example 10.2. Let n = 2, m = 1, D = diag(1, -I), A = (1, -1). 
It is clear that D is an Rn-matrix and the condition A E 3-t is 
satisfied with 3 = ( )  
Meanwhile, M is not an Rn-matrix. 
Indeed, one can verify that the pair (2, A), where 2 = (1,l) and 
= 1, is a solution of the system (10.24)-(10.26). 
Definition 10.2 (Murty (1972), p. 67). We say that D = (dij) E 
~ n x n  
is a nondegenerate matrix if, for any nonempty subset a c 
(1, . . . , n), the determinant of the principal submatrix D,, 
consist- 
ing of the elements dij (i € a, j E a) of D is nonzero. 
Every nondegenerate matrix is an Ro-matrix (see Cottle et al. 
(1992), p. 180). It can be proved that the set of nondegenerate 

10.3 A Special Case 
173 
n x n-matrices is open and dense in Rnxn. F'rom the following simple 
observation it follows that symmetric nondegenerate Ro-matrices 
form a dense subset in the set of all symmetric matrices. 
Proposition 10.3. For any matrix D E RnXn and for any E > 0 
there exists a nonnegative diagonal matrix U' such that D + U q s  
a nondegenerate matrix, and 1IU"II 5 E. 
Proof. The proposition is proved by induction on n. For n = 1, 
if D = [dl, d # 0, then we set UE = [O]. If D = [0] then we set 
U" 
[E]. Assume that the conclusion of the proposition is true for 
all indexes n < k - 1. Let D = (dij) be a k x Ic-matrix which is 
not nondegenerate. Denote by Dkdl the left-top submatrix of the 
order (k - 1) x (k - 1) of D. By induction, there is a diagonal 
matrix Ui-l = diag(al,.. . , a k - 1 )  such that every principal minor 
of the matrix Dk-1 + Ui-l is nonzero, and 11 Ui-, 11 5 E. The required 
matrix U" is sought in the form 
UE = diag(a1, . . . , a k - 1 ,  y), 
where y E R is a parameter. 
From the construction of U 9 t  follows that all the determinants 
of the principal submatrices of D + U" which do not contain the 
element dkk + y, are nonzero. Obviously, there are 2"' 
principal 
submatrices of D + U" containing the element dkk + y. The deter- 
minant of each one of these submatrices has the form aiy + ,&, 
1 5 i < 2"', 
where ai and pi are certain real numbers. Moreover, 
ai equals 1 or equals one of the principal minors of Dk-1 + Ui-'. 
Pi 
So ai # 0 for all i. Since the numbers --, 
1 < i < 2"', 
cannot 
ai 
cover the segment [0, €1, there exists g E [0, e] such that g # -5 
for all i. From what has already been said, we conclude that for 
U" := diag(al, . . . , ah-', y) the matrix D + U" is nondegenerate. In 
addition, it is clear that llUEll 5 E. The proof is complete. 
Remark 10.1. The property of being a nondegenerate matrix 
is not invariant under the operation of matrix conjugation. This 
means that even if D is nondegenerate and P is nonsingular, the 
matrix P-' D P  still may have zero principal minors. Examples can 
be found even in R2x2. Consequently, a linear operator with a non- 
degenerate matrix in one basis may have a degenerate matrix in 
another basis. 
It follows from Theorem 10.3 and Proposition 10.2 that the mul- 
tifunction S(.) is usc at (D, A, c, b) if A E 'FI, A is a nonnegative 

174 
10. Upper Semicontinuity of the KKT Point Set 
matrix and D is an &-matrix. 
There are many nonconvex QP 
problems fulfilling these conditions. For example, in the quadratic 
programs whose objective functions are given by the formula 
where c E Rn, 1 < s < n and pi > 0 for all i, D is an &-matrix. 
Proposition 10.3 shows that the set of symmetric Ro-matrices is 
dense in REXn. 
10.4 Sufficient Conditions for the usc 
Property of S(*) 
Consider problem (10.1) whose Karush-Kuhn-Tucker point set is 
denoted by S(D, A, c, b). A necessary condition for the usc property 
of S(.) was obtained in Section 10.2. Sufficient conditions for having 
that property were given in Section 10.3 only for a special class of 
QP problems. Our aim in this section is to find sufficient conditions 
for the usc property of the multifunction S(-) which are applicable 
for larger classes of QP problems. 
For a matrix A E Rmxn, the dual of the cone 
is denoted by (A[A])*. By definition, (A[A])* = {J E Rm : AT< 5 
0 VX E A[A]). The interior of (A[A])* is denoted by int (A[A])*. By 
Lemma 6.4, 
int (A[A])* = {J E Rm : XTJ < 0 VX E A[A] \ (0)). 
The proofs of Theorems 10.4-10.6 below are based on some ob- 
servations concerning the structure of the Karush-Kuhn-Tucker sys- 
tem (10.2). It turns out that the desired stability property of the 
set S(D, A, c, b) depends greatly on the behavior of the quadratic 
form xTDx on the recession cone of A(A, b) and also on the position 
of b with respect to the set int (A[A])*. 
One can note that in Example 10.1 the solution set Sol (D, A, 0,O) 
is empty. In the following theorem, such "abnormal" situation will 
be excluded. 

10.4 Sufficient Conditions for the usc Property 
175 
Theorem 10.4. If Sol (D, A, 0,O) = (0) and i f b  E int (A[A])* then, 
for any c E Rn, the multifunction S(.) is upper semicontinuous at 
(Dl A7 c, b). 
Proof. Suppose the theorem were false. Then we could find an 
open set 0 containing S(D, A, c, b), a sequence {(D" Ak,ck, bk)} 
converging to (Dl A, c, b) in R:'" 
x RmXn x Rn x Rm, a sequence 
{xk} with the property that xk E S(Dk,Ak,ck, 
bk) and xk @ 4 for 
every k. By the definition of KKT point, there exists a sequence 
{A" 
c Rm such that 
We first consider the case where the sequence of norms ( 1 1  ($5 A') 
1 1 )  
is bounded. As the sequences {llx"[} and {IIX"I} 
are also bounded, 
from {xk} and {A", 
respectively, one can extract converging sub- 
sequences {xh} and {Xki}. Assume that x" + xO E Rn and Xki + 
X0 E Rm as i -+ m .  From (10.28)-(10.30) it follows that 
Hence xO E S(D, A, c, b) c 0. On the other hand, since xki @ fl for 
all i and R is open, we have x0 @ R, a contradiction. 
We now turn to the case where the sequence {Il (xk, Xk) 1 1 )  is un- 
bounded. In this case, there exists a subsequence, which is denoted 
again by {Il(x" AX") [I}, 
such that 11(x" AX") 11 -+ oo and 11 (x" AX") 11 # 0 
for every k. Let 
Since llxk 11 = 1, there is a subsequence of {xk}, which is denoted 
again by {x", such that x" 
--t E Rnx Rm, 1 1 ~ 1 1  = 1. Let 2 = (5,X). 
By (10.31), 
Dividing both sides of (10.28) and (10.29) by 11 (x" Ax") 1 1 ,  both sides 
of (10.30) by Il(~{,X")11~, 
and taking limits as k + m, we obtain 

176 
10. Upper Semicontinuity of the KKT Point Set 
By (10.32) and (10.33), 3 E A(A, 0) = {x E Rn : Ax 2 0, x 2 0). 
Let us suppose for the moment that 3 # 0. It is obvious that (10.34) 
can be rewritten as Z ~ D Z  = 0. If xTDx 2 0 for all x E A(A, 0) then 
3 E Sol (D, A, O,O), contrary to the assumption Sol (D, A, 0,O) = 
(0). If there exists i E A(A, 0) such that i T D i  < 0 then 
because A(A, 0) is a cone. Thus Sol (D, A, 0,O) = 8, contrary to the 
condition Sol (D, A, 0,O) = (0). Therefore Z = 0. 
As I[(?, X)ll = 1, from (10.32) and (10.33) it follows that X E 
A[A] \ (0). The assumption b E int (A[A])* implies 
Since Il(x<,X)ll + m, 
A" 
+ X and IlXll = II(3, X)II = 1, 
11(x" Ak)II 
IIA"I 
I 
m .  Using the obvious identity (X"~(A"~A" 
(Ak)TAkxk 
we can rewrite (10.30) as the following 
k T  k k 
k T k -  
A k T b k  
( x )  D x  + ( x )  c - (  
) 
. 
(10.36) 
If the sequence {xk) is bounded, then dividing both sides of (10.36) 
by Il(xk,Ak)ll and letting k + oo we obtain XTb = 0, contrary to 
(10.35). So the sequence {xk) must be unbounded, and it has a 
subsequence, denoted again by {xk}, such that IIxkll + oo, Ilxkll # 
xk 
0 for all k, and - 
+ i with IIiII = 1. For the sequence {(Ak)Tbk} 
lIxk ll 
there are only two possibilities: 
(a) There exists an integer io such that 
for all k 2 io, and 
(0) For each i there exists an integer 
> i such that 
If case (a) arises, then (10.36) implies 
k T  k k 
k T k  
( x )  D x  + ( x )  c 5 0  
(10.39) 

10.4 Sufficient Conditions for the usc Property 
177 
for all k 2 io. Dividing both sides of (10.39) by I ~ X " ( ~  and letting 
k -+ m we get 
2 T ~ 2  
5 0. 
(10.40) 
By (10.28) and (10.29), 
Dividing both sides of each of the last two inequalities by llxklI and 
letting k --+ m we obtain 
Since 0 E Sol (D,A,O,O), by (10.40) and (10.41) we have 2 E 
Sol (D, A, O,O), contrary to the condition Sol (Dl A, 0,O) = (0). 
Thus case (a) is impossible. If case (P) happens, then by dividing 
both sides of (10.38) by Il(x", Aki)ll and letting i -+ m we obtain 
XTb 2 0, contrary to (10.35). The proof is complete, because neither 
(a) nor (P) can occur. 
Theorem 10.5. If Sol(-D,A,O,O) = (0) and b E -int(A[A])* 
then, for any c E Rn, the multifunction S(.) is upper semicontinuous 
at (D, A, c, b). 
Proof. Except for several small changes, this proof is very similar 
to the proof of Theorem 10.4. Suppose, contrary to our claim, that 
there is an open set R C Rn containing S(D, A, c, b), a sequence 
{(D" Ax", ck, bx")) converging to (D, A, c, b) in RgXn x Rmxn x Rn x 
Rm, a sequence {xk) with x% S(Dk, Ax", ck, bk) and xk @ R for ev- 
ery k. By the definition of KKT point, there is a sequence {Ak} sat- 
isfying (10.28)-(10.30). If the sequence of (11 (x" Ax") 1 1 )  is bounded 
then, arguing similarly as in the preceding proof, we will arrive at 
a contradiction. If the sequence {ll(x< Ax")II) is unbounded then, 
without any loss of generality, we can assume that the sequence 
{~:::~:1,} 
converges to a certain pair (5, 1) with ( 5 , i )  = 1. 
Dividing both sides of (10.28) and of (10.29) by 11 (x" Ax") 11, both 
sides of (10.30) by Il(xk, Ak)1I2 and letting k t m we obtain (10.32)- 
(10.34). From (10.34) we have 5T(-D)5 = 0. The assumption 
Sol (- D, A, 0,O) = (0) forces 3 = 0. Thus 
E A[A] \ (0). Since 
b E -int (A[A])*, we have 

178 
10. Upper Semicontinuity of the KKT Point Set 
Since II(xk,X"> -+ oo, 
Xk 
-+ X, and IlXll = 1, we must 
I I  (xk, Xk)lI 
have IIXklI I oo. Again, rewrite (10.30) in the form (10.36). If the 
sequence{x" 
is bounded, we can divide both sides of (10.36) by 
II(x5 Ak)II and let k -+ oo to obtain XTb = 0, which contradicts 
(10.42). Thus the sequence {xk} must be bounded, and it has a 
subsequence, denoted again by {x", such that Ilxk 11 -+ oo, IlxkII # 
xk 
0 for all k, and - 
I 
2 with IIitII = 1. 
llxk I I  
If there exists an index io such that (10.37) holds, then dividing 
both sides of (10.36) by Il(xk7 Ak)>ll and taking limit as Ic -+ oo we 
have XTb = 0, contrary to (10.42). 
Assume that for each i, there exists an integer Ici > i such that 
(10.38) holds. From (10.36) and (10.38) it follows that 
for all i. Dividing both sides of (10.43) by Ilxki112 and taking limit 
as i -+ oo we get itTD2 2 0 or, equivalently, 
By (10.28) and (10.29), Akixki 2 bki, 
xki 2 0. Dividing both 
sides of each of the last two inequalities by IlxhlI and taking limits 
we obtain (10.41). Properties (10.41), (10.44), and the inclusion 
0 E Sol (-D, A, 0,O) yield 2 i. Sol (-D, A, O,O), contrary to the 
condition Sol (-D, A, 0,O) = (0). Thus, in all possible cases we 
have arrived at a contradiction. The proof is complete. 
Our third sufficient condition for the stability of the Karush- 
Kuhn-Tucker point set can be formulated as follows. 
Theorem 10.6. If S(D,A,O,O) = (0) and A[A] = (0) then, for 
any (c, b) E Rn x Rm, the multifunction S(.) is upper semicontinuous 
at (D, A, c, b). 
Proof. Repeat the arguments in the proof of Theorem 10.4 until 
reaching the system (10.32)-(10.34). Since S(D, A, 0,O) = {O), 
we have Z = 0, hence (10.32)-(10.34) imply -ATX > 0, X 2 0. 
By llXll = I[(?, 
X)II = 1, one has X E A[A] \ {0}, contrary to the 
assumption that A[A] = (0). 
0 

10.5 Corollaries and Examples 
179 
10.5 Corollaries and Examples 
We now consider some corollaries of the results established in the 
preceding section and give several illustrative examples. 
Corollary 10.3. If A[A] = (0) and if the matrix D is a positive 
definite (or negative definite) then, for any pair (c, b) E Rn x Rm, 
the multifunction S(.) is upper semicontinuous at (D, A, c, b). 
Proof. If D is positive definite, then S(D, A, 0,O) = Sol(D, A, 0,O) = 
(0). So our assertion follows from Theorem 10.6. 
If D is negative definite, then S(D, A, 0,O) = Sol (-D, A, 0,O) = 
{O), and again the assertion follows from Theorem 10.6. 
We proceed to show that the condition b E int (A[A])* in The- 
orem 10.4 is equivalent to the regularity of the following system of 
linear inequalities 
Ax > b, 
x 2 0. 
(10.45) 
Lemma 10.2. System (10.45) is regular if and only i f  b E int (A[A])*. 
Proof. Assume (10.45) is regular, i.e. there exists xO such that 
Ax0 > b, xO > 0. Let q := Ax0 - b > 0 and let 1 be any vector from 
A[A] \ {0), that is A ~ X  
5 0, X > 0, and X # 0. Then 
Hence b E int (A[A])*. 
Conversely, assume that b E int (A[A])*. Suppose for a moment 
that (10.45) is irregular. Since the system Ax > b, x 2 0 has no 
solutions, for any sequence bk t 
b with bk > b for all k, the systems 
have no solutions. By Theorem 2.7.9 from Cottle et al. (1992), 
which is a corollary of the Farkas Lemma, there exists Xk E Rm 
such that 
-A~x" 
0, 
X" 
0, 
( ~ " ~ b "  0. 
(10.46) 
Since Xk # 0, without loss of generality, we can assume that 1IX"I = 
1 for every k, and Xk t 5 with IlXll = 1. Taking limits in (10.46) as 
k t 
oo we get 
Hence 
E A[A] \ (01, and the inequality XTb 2 0 contradicts the 
assumption b E int (A[A])*. We have thus proved that (10.45) is 
regular. 

180 
10. Upper Semicontinuity of the KKT Point Set 
Corollary 10.4. If (10.45) is regular and if A(A, b) is bounded, 
then the multifunction S(.) is upper semicontinuous at (D, A, c, b). 
Proof. Since A(A, b) is nonempty, bounded, and A(A, b)+A(A, 0) C 
A(A, b), we have A(A, 0) = (0). Since (10.45) is regular, by Lemma 
10.2 we have b E int (A[A])*. Applying Theorem 10.4 we get the 
desired result. 
0 
We have the following sufficient condition for stability of the 
KKT point set in QP problems with bounded constraint sets. 
Corollary 10.5. If A(A,O) = (0) and XTb # 0 for all X E 
A[A] \ (0) then, for any c E Rn, the multifunction S(.) is upper 
semicontinuous at (D, A, c, b). 
Proof. Obviously, the condition A(A, 0) = (0) implies 
S(D,A,O,O) = Sol(D,A,O,O) = Sol(-D,A,O,O) = A(A,O) = (0). 
(10.47) 
Since A[A] is a convex cone, the assumption XTb # 0 for all X E 
A[A] \ (0) implies that one of the following two cases must occur: 
(i) XTb < 0 for all X E A[A] \ {O), 
(ii) XTb > 0 for all X E A[A] \ (0). 
In the first case, the desired conclusion follows from (10.47) and 
Theorem 10.4. In the second case, the conclusion follows from 
(10.47) and Theorem 10.5. 
0 
The following two examples show that the obtained sufficient 
conditions for stability can be applied to nonconvex QP problems. 
Example 10.3. Consider problem (10.1) where n = 2, m = 1, 
We have A(A, 0) = {0), Sol (D, A, 0,O) = (0) and b E int (A[A])*. 
By Theorem 10.4, S(.) is usc at (D, A, c, b). 
Example 10.4. Consider problem (10.1) where n = 2, m = 1, 
An easy computation shows that 
S(D, A, 0,O) = (01, Sol (- D, A, 0,O) = (01, and b E -int (A[A])*. 

10.5 Corollaries and Examples 
181 
The multifunction S(.) is usc at (D, A, c, b) by Theorem 10.5. 
The next two examples show that when the condition b E int (A[A])* 
is violated the conclusion of Theorem 10.4 may hold or may not 
hold, as well. 
Example 10.5. Let D = [ l ] ,  A=[O], b = ( l ) ,  c=(O), At=[-t], 
where t E (0,l). It is easily seen that 
S(D, A, 0,O) = {0), 
Sol (Dl A, 0,O) = {O), 
S(D, A, c, b) = 0, 
S(D, A t  c, b) = { f } , A[A] = R+, 
b $ int (A[A])*, 
We have S(D, A, c, b) c R, where R = 0. Since At -t A and the 
inclusion S(D, At, c, b) c R cannot hold for sufficiently small t > 0, 
S(.) cannot be usc at (D, A, c, b). 
Example 10.6. Let D = [-I], A = [-I], b = (I), c = (0). It is 
easy to verify that 
S(D,A,O,O) = {0), 
Sol(D,A,O,O) = {0), 
S(D,A,c,b) = 0, 
A[A]= R+, b$int(A[A])*. 
The map S(.) is usc at (D, A, c, b). Indeed, since S(-D, A, 0,O) = 
(0) and b E -int (A[A])*, Theorem 10.5 can be applied. 
The following two examples show that if b $ -int (A[A])* then 
the conclusion of Theorem 10.5 may hold or may not hold, as well. 
Example 10.7. Let D, A, c, b be defined as in Example 10.5. In 
this case we have 
As it has been shown in Example 10.5, the map S(.) is not usc at 
(D, A, c, b). 
Example 10.8. Let D = [I], A = [- 11, b = (-I), c = (0). It is a 
simple matter to verify that 
The fact that S(.) is usc at (D, A, c, b) follows from Theorem 10.4, 
because Sol (Dl A, 0,O) = (0) and b E int (A[A])*. 

182 
10. Upper Semicontinuity of the KKT Point Set 
10.6 USC Property of S(.): The Gen- 
eral Case 
In this section we obtain necessary and sufficient conditions for the 
stability of the Karush-Kuhn-Tucker point set in a general QP prob- 
lem. 
Given matrices A E Rmxn, F E Rsxn, D E REXn, and vectors 
c E Rn, b E Rm, d E RS, we consider the following general indefinite 
QP problem QP(D, A, c, b, F, d) : 
1 
Minimize f (x) := - x T ~ z  + cTx 
2 
(10.48) 
subject to x E Rn, Ax 2 b, F x  2 d 
In what follows, the pair (F, d) is not subject to change. So the set 
A(F,d) := {x E Rn : F x  > d) is fixed. Define A(A,b) = {z E 
Rn : Ax 2 b) and recall (see Definition 3.1 and Corollary 3.2) that 
2 E A(A, b) n A(F, d) is said to be a Karush-Kuhn-'Ihcker point of 
QP(D, A, c, b, F, d) if there exists a pair (a, V) E Rm x RS such that 
The KKT point set and the solution set of (10.48) are denoted, 
respectively, by S(D, A, c, b, F, d) and Sol(D, A, c, b, F, d). 
If s = n, d = 0, and F is the unit matrix in RnXn, then problem 
(10.48) has the following canonical form (10.1). In agreement with 
the notation of the preceding sections, we write S(D, A, c, b) instead 
of S(D, A, c, b, F, d), and Sol(D, A, c, b) instead of Sol(D, A, c, b, F, d) 
if (10.48) has the canonical form. The upper semicontinuity of the 
multifunction 
has been studied in Sections 10.3-10.5. This property can be in- 
terpreted as the stability of the KKT point set S(D, A, c, b) with 
respect to the change in the problem parameters. In this section 
we are interested in finding out how the results proved in Sections 
10.3-10.5 can be extended to the case of problem (10.48). We will 

10.6 The General Case 
183 
obtain some necessary and sufficient conditions for the upper semi- 
continuity of the multifunction 
p' H 
S(pl, F,d), p' = (D',A1,c', b') E RgXn x Rmxn x Rn x Rm. 
(10.50) 
As for the canonical problem, the obtained results can be interpreted 
as the necessary and sufficient conditions for the stability of the 
Karush-Kuhn-Tucker point set S(D, A, c, b, F, d) with respect to the 
change in the problem parameters. 
Our proofs are based on several observations concerning the sys- 
tem of equalities and inequalities defining the KKT point set. It is 
worthy to stress that the proofs in the preceding sections cannot be 
applied to the case of problem (10.48). This is because, unlike the 
case of the canonical problem (10.1), A(F, d) may fail to be a cone 
with nonempty interior and the vertex 0. So we have to use some 
new arguments. Fortunately, the proof schemes in the preceding 
sections will be useful also for the case of problem (10.48). 
Theorem 10.7 below deals with the case where A(F, d) is a poly- 
hedral cone with a vertex xO, where xO E Rn is an arbitrarily given 
vector. Theorem 10.8 works for the case where A(F, d) is an ar- 
bitrary polyhedral set, but the conclusion is weaker than that of 
Theorem 10.7. 
For any M E RTXn and q E RT, the set {x E Rn : Mx 2 q) is 
denoted by A(M, q). For F E RSXn and A E Rmxn, we abbreviate 
the set 
to h[A, F]. Note that 
The next two remarks clarify some points in the assumption and 
conclusion of Theorem 10.7 below. 
Remark 10.2. If there is a point xO E Rn such that F(xO) = d 
then A(F, d) = xO + A(F, 0). Conversely, for any xO E Rn and any 
polyhedral cone K ,  there exists a positive integer s and a matrix 
F E RSXn such that xO + K = A(F,d), where d := F(xO). 
Remark 10.3. If A(F, d) and A(A, b) are nonempty, then A(F, 0) 
and A(A, 0), respectively, are the recession cones of A(F, d) and 

184 
10. Upper Semicontinuity of the KKT Point Set 
A ( A ,  b). By definition, S ( D ,  A, 0, 0, F, 0) is the Karush-Kuhn-Tucker 
point set of the following QP problem 
Minimize x T ~ x  
subject to x E Rn, Ax 2 0, F x  2 0, 
whose constraint set is the intersection A ( A ,  0) n A(F, 0). 
Theorem 10.7. Assume that the set S(p, F, d), where p = ( D ,  A, c, b), 
is bounded and there exists xO E Rn such that F(xO) = d. If the mul- 
tifunction (10.50) is upper semicontinuous at p then 
Proof. Suppose, contrary to our claim, that there is a nonzero 
vector 3 E S ( D ,  A, O , O ,  F, 0). By definition, there exists a pair 
(u, E )  E Rm x RS such that 
Az 2 0, ii 2 0, 
(10.53) 
F 3 2 0 ,  f 2 0 ,  
(10.54) 
U ~ A Z  
+ ZI*F% = 0. 
(10.55) 
For every t E (0, I), we set 
where xO is given by our assumptions. We claim that there exist 
matrices Dt E R:Xn, At E Rmxn and vectors ct E Rn, bt E Rm such 
that 
and 
Dtxt - ~ T u t  
- F
~
V
~
 
+ ct = 0, 
(10.57) 
Atxt 2 b t ,  ut 2 0 ,  
(10.58) 
Fxt 2 dl vt 2 0, 
(10.59) 
u ? ( ~ t x t  - bt) + V:(FX~ - d) = 0. 
(10.60) 
The matrices Dt, At and the vectors ct, bt will have the following 
representations 

10.6 The General Case 
185 
where the matrices Do, A. and the vectors co, bo are to be con- 
structed. First we observe that, due to (10.54) and (10.56), (10.59) 
holds au tornatically. Clearly, 
Atxt - bt = ( A  + tAo) (so + " )  - (6 + tbo) 
1 
= t(AoxO - bo) + -A2 + A0z + Ax0 - b 
t 
and 
Atxt - bt) + v,T(Fx~ - d )  
fiT 
1 
= - 
[t(A0x0 - bo) + :A3 + A02 + Ax0 - b] 
+ Ax0 - b). 
Therefore, by (10.53) and (10.55), if we have 
and 
AOxO - bO = 0, 
(10.64) 
then (10.58) and (10.60) will be fulfilled. By (10.52), 
Hence, if we have 
and 
D0x0 + co = 0, 
then (10.57) will be fulfilled. 
Let 2 = ( z ~ ,  
. . . ,z,) , where 3' # 0 for i E I and 2' = 0 for 
i $! I ,  I C (1,. . . , n). Since 3 f 0, I is nonempty. Fixing an index 

186 
10. Upper Semicontinuity of the KKT Point Set 
io E I, we define A. as the m x n-matrix in which the io - th column 
is ~ i , ' ( b  - Ax0), and the other columns consist solely of zeros. Let 
bo = AoxO. One can verify immediately that (10.63) and (10.64) are 
satisfied; hence conditions (10.58) and (10.60) are fulfilled. From 
what has been said it follows that our claim will be proved if we 
can construct a matrix Do E RzXn and a vector co satisfying (10.65) 
and (10.66). Let Do = (dij), where dij (1 5 i, j < n) are defined by 
the following formulae: 
d.. 
22 = 3:' % 
( A ~ G  - DXO - c ) ~  b% E I, 
dioj = d 320 = 3-' 
zo (Arc - DXO - c ) ~  V j  E {I,. . . ,n} \ I, 
and dij = 0 for other pairs (i, j), 1 5 i, j 5 n. Here (ATG- DxO- c>k 
denotes the k-th component of the vector ATE - DxO - c. Since Do 
is a symmetric matrix, Do E RgXn. If we define co = -DoxO then 
(10.66) is satisfied. A direct computation shows that (10.65) is also 
satisfied. 
We have thus constructed matrices Do, A. and vectors co, bo such 
that for xt, ut, vt, Dt, At, ct, bt defined by (10.56), (10.61) and 
(10.62), conditions (10.57)-(10.60) are satisfied. Consequently, xt E 
S(Dt, At, ct, bt, F, d). Since S(p, F, d) is bounded, there is a bounded 
open set R c Rn such that S(p, F, d) c R. Since 
max{llDt - Dll, llAt - All, llct - c I I ,  llbt - bll) + 0 
as t + 0 and the multifunction p' 
H S(pl, F, d) is usc at p = 
(Dl A, c, b), xt E 
for - all sufficiently small t. This is impossible, 
x 
because llxt 11 = llxO + 
11 - oa as t + 0. The proof is complete. 
0 
Remark 10.4. If d = 0 then A(F, d) is a cone with the vertex 
0. In order to verify the assumptions of Theorem 10.7, one can 
choose xO = 0. In particular, this is the case of the canonical prob- 
lem (10.1). Applying Theorem 10.7 we obtain the following nec- 
essary condition for the upper semicontinuity of the multifunction 
(10.49): If S(p), p = (D, A, c, b) is bounded and if the multifunction 
p' H 
S(pl), p1 = (D1,A',c',b'), is usc atp, then S(D,A,O,O) = (0). 
Thus Theorem 10.8 above extends Theorem 10.1 to the case where 
A(F, d) can be any polyhedral convex cone in Rn, merely the stan- 
dard cone RT. 
In the sequel, S(D,A) denotes the set of all x E Rn such that 
there exists u = u(x) E Rm satisfying the following system: 
DX - ATu = 0, AX 2 0, 
u 2 0, 
U ~ A Z  
= 0. 

10.6 The General Case 
187 
Remark 10.5. From the definition it follows that S(D, A) = 
S(D, A, O,O, F, 0), where s = n and F = 0 E Rnxn. 
Theorem 10.8. Assume that A(F, d) is nonernpty and S(p, F, d), 
where p = (D, A, c, b), is bounded. If the rnultifunction (10.50) is 
upper sernicontinuous at p then 
Remark 10.6. Observe that (10.51) implies (10.67). Indeed, sup- 
pose that (10.51) holds. The fact that 0 E S(D, A) n A(F, 0) 
is obvious. So, if (10.67) does not hold then there exists 3 E 
S(D,A) n A(F,O), 5 # 0. Taking a = u(Z), fi = 0 E RS, we 
see at once that the system (10.52)-(10.55) is satisfied. This means 
that Z E S(D, A, O,0, F, 0) \ (01, contrary to (10.51). Note that, in 
general, (10.67) does not imply (10.51). 
Remark 10.7. If there exists xO such that FxO = d then, of course, 
xO E A(F,d) = {x E Rn : F x  2: d). In particular, A(F,d) # 8. 
Thus Theorem 10.8 can be applied to a larger class of problems than 
Theorem 10.7. However, Remark 10.6 shows that the conclusion of 
Theorem 10.8 is weaker than that of Theorem 10.7. One question 
still unanswered is whether the assumptions of Theorem 10.8 always 
imply (10.51). 
Proof of Theorem 10.8. 
Assume that A(F, d) is nonempty, S(D, A, c, b, F, d) is bounded 
and the multifunction S(., F, d) is usc at p but (10.67) is violated. 
Then, there is a nonzero vector 3 E S(D, A) n A(F, 0). Hence there 
exists u E Rm such that 
A3 2 0, 
F; 0, 
(10.69) 
U ~ A Z  
= 0, 
(10.70) 
F3 F; 0. 
(10.71) 
Let xO be an arbitrary point of A(F, d). Setting 
for every t E (0, I), we claim that there exist matrices 

188 
10. Upper Semicontinuity of the KKT Point Set 
and vectors ct E Rn, bt E Rm such that 
as t --+ 0, and 
The matrices Dt, At and vectors ct, bt are defined by (10.61) and 
(10.62), where Do, Ao, co, bo are constructed as in the proof of 
Theorem 10.7. Using (10.68)-(10.71) and arguing similarly as in 
the preceding proof we shall arrive at a contradiction. 
The following theorem gives three sufficient conditions for the 
upper semicontinuity of the multifunction (10.50). These conditions 
express some requirements on the behavior of the quadratic form 
xT Dx on the cone A(A, 0) n A(F, 0) and the position of the vector 
(b, d) relatively to the set int(A[A, F])*. 
Theorem 10.9. Suppose that one of the following three pairs of 
conditions 
Sol(D, A, O,O, F, 0) = {O), 
(b, d) E int (A[A, F])* , 
(10.72) 
Sol(-D, A, O,O, F, 0) = (01, 
(b, d) E -int (A[A, F])* , (10.73) 
and 
S(D, A, O,O, F, 0) = {O), 
int (A[A, F])* = Rm x RS, 
(10.74) 
is satisfied. Then, for any c E Rn (and also for any b E Rm if 
(10.74) takes place), the multifunction p' I+ S(pl, F, d), where p' = 
(Dl, A', c', b'), is upper semicontinuous at p = (D, A, c, b). 
Proof. On the contrary, suppose that one of the three pairs of 
conditions (10.72)-(10.74) is satisfied but, for some c E Rn (and 
also for some b E Rm if (10.74) takes place), the multifunction p' I+ 
S(pl, F, d) is not usc at p = (D, A, c, b). Then there exist an open 
subset R c Rn containing S(p, F, d), a sequence pk = (D" A', c< bk) 
converging to p in RzXn x Rmxn x Rn x Rm, and a sequence {xk} 
such that, for each k, x% S(pk7 F, d) and xk @ 0. By the definition 
of KKT point, for each k there exists a pair (u" vk) E Rm x RS such 
that 
D%' - ( A ~ ~ U ' "  
- FTvk + ck = 0, 
(10.75) 

10.6 The General Case 
189 
If the sequence {(xk, uk, vk)) is bounded, then the sequences {x", 
{uk} and {vk) are also bounded. Therefore, without loss of gener- 
ality, we can assume that the sequences {x", 
{uk} and {v" 
con- 
verge, respectively, to some points xO E Rn, u0 E Rm and v0 E Rs, 
as Ic + oo. Letting k + oo, from (10.75)-(10.78) we get 
Hence xO E S(p, F, d) C R. On the other hand, since xk f R for each 
Ic, we must have xO $ R, a contradiction. We have thus shown that 
the sequence {(xk, u" vk)) must be unbounded. By considering a 
k
k
k
 
subsequence, if necessary, we can assume that 11 (x , u , v ) 11 -t oo 
and, in addition, ll(xk, u" vk)ll # 0 for all k. Since the sequence of 
vectors 
is bounded, it has a convergent subsequence. Without loss of gen- 
erality, we can assume that 
k
k
k
 
(x , U  , v  
+ ( z 7 u , ~ ) ~ R n x R m x R S ,  
~ ~ ( z , u , ~ ) ~ ~ = l .  
ll(xk, uk, vk)ll 
(10.79) 
k
k
k
 
Dividing both sides of (10.75), (10.76) and (10.77) by Il(x , u , v ) I ] ,  
both sides of (10.78) by Il(xk,uk,v")l12, and letting k + oo, by 
(10.79) we obtain 
DZ - A ~ U  
- ~
~
i
j
 
= 0, 
(10.80) 
We first consider the case where (10.72) is fulfilled. It is evident 
that (10.80)-(10.83) imply 

190 
10. Upper Semicontinuity of the KKT Point Set 
If 5 # 0 then, taking account of the fact that the constraint set 
A(A, 0) n A(F, 0) of QP(D, A, O,O, F, 0) is a cone, one can deduce 
from (10.84) that either Sol(D, A, 0, 0, F, 0) = 0 or 
This contradicts the first condition in (10.72). Thus 5 = 0. Then it 
follows from (10.80)-(10.83) that (ii, U) E A[A, F] \ ((0,O)). Since 
(b, d) E int (A[A, F])* by (10.72), 
Consider the sequence {(uk)Tbk + ( ~ " ~ d ) .  
By (10.75) and (10.78), 
If for each positive integer i there exists an integer ki such that 
ki > i and 
(ukd)Tbk + (vki)Td > 0 
(10.87) 
then, dividing both sides of (10.87) by 11 (xki, ukd, v4) 11 and letting 
i -+ m, we have 
iiTb + UTd > 0, 
contrary to (10.85). Consequently, there must exist a positive inte- 
ger io such that 
+ (vk)?'d 5 0 for every k > io. 
(10.88) 
If the sequence {x" is bounded then, dividing both sides of (10.86) 
k
k
k
 
by II(x , u , v ) I [  and letting k + m ,  we get aTb+vTd = 0, contrary 
to (10.85). Thus {xk) is unbounded. We can assume that IIxkII t 
m and Ilxkll # 0 for each k. Then {A} 
is bounded. We can 
assume that 
xk - 
-+ 2 with II2II = 1. 
llxk II 
Combining (10.86) with (10.88) gives 
T
k
 k k 
k T  k 
(X ) D x + (c ) x 5 0 for every k 2 io. 
' (10.89) 
Dividing both sides of (10.89) by 1
1
~
~
1
1
~
 
and letting k -+ oo, we 
obtain 
2 T ~ 2  
< 0. 
(10.90) 

10.6 The General Case 
By (10.76) and (10.77), 
Dividing both sides of each of the last inequalities by IIxkII and 
letting k -+ 
oo, we have 
Combining (10.90) with (10.91), we can assert that 
contrary to the first condition in (10.72). Thus we have proved the 
theorem for the case where (10.72) is fulfilled. 
Now we turn to the case where condition (10.73) is fulfilled. We 
deduce (10.84) from (10.80)-(10.83). If Z # 0 then from (10.84) we 
get Sol(- D, A, 0, 0, F, 0) # {0), which contradicts the first condi- 
tion in (10.73). Thus B = 0. From (10.80)-(10.83) it follows that 
(ti, a) E A[A, F] \ ((0,O)). By the second condition in (lO.73), 
Consider the sequence { ( ~ ~ ) ~ b ' " +  
( ~ ~ ) ~ d ) .  
We have (10.86). If there 
exists a positive integer io such that (10.88) is valid then, dividing 
both sides of (10.88) by 11 (xk, uk, vk) 11 and letting k + oo, we obtain 
tiTb + aTd 5 0, contrary to (10.92). Therefore, for each positive 
integer i, one can find an integer ki > i such that (10.87) holds. If 
the sequence {xk) is bounded then, dividing both sides of (10.86) by 
k
k
k
 
11 (x , u , v ) ) I  and letting k --+ oo, we have i'iTb+.GTd = 0, contrary to 
(10.92). Thus the sequence {xk) is unbounded. We can assume that 
Ilxkll + oo and Ilxk 11 # 0 for all k. Since the sequence {-I 
is 
well defined and bounded, without loss of generality, we can assume 
that 
xk - 
-+ 2 with II2II = 1. 
llxkll 
Combining (10.86) with (10.87) gives 
( x ~ ~ ) ~ D ~ ~ x ~ ~  
+ (
~
~
~
)
~
x
~
~
 
> 0 for all i. 
(10.93) 
Dividing both sides of (10.93) by llxki112 and letting i + oo, we 
obtain 2'D2 > 0 or, equivalently, 

192 
10. Upper Semicontinuity of the KKT Point Set 
By (10.76) and (10.77), 
Dividing both sides of each of the inequalities in (10.95) by Ilxki\\ 
and letting i t 
oo, we have 
Combining (10.94) with (10.96) yields Sol(- D, A, 0, 0, F, 0) # (01, 
contrary to the first condition in (10.73). This proves the theorem 
in the case where (10.73) is fulfilled. 
Now let us consider the last case where (10.74) is assumed. From 
(10.80)-(10.83) we have 3 E S ( D ,  A, O , O ,  F, 0). By the first condi- 
tion in (10.73), 3 = 0. Then it follows from (10.80)-(10.83) that 
Therefore, ( U ,  a) E A[A, F] \ ((0,O)). Since UTii + vTv > 0, then 
(G,@) @ int(A[A, F])*. This contradicts the second condition in 
(10.74). 
We have thus proved that if one of the pairs of conditions (10.72)- 
(10.74) is fulfilled, then the conclusion of the theorem must hold 
true. 
We now proceed to show how the sufficient conditions (10.72) 
and (10.73) look like in the case of the canonical problem (10.1). 
As in Section 10.4, for any A E Rnxn, A[A] = { A  E Rm : -ATX 2 
0, X 2 0). We have 
int (A[A])* = {J E Rm : XT[ < 0 VX E A[A] \ (0)). 
Lemma 10.3. Suppose that, in problem (10.48), s = n, d = 0, and 
F is the unit matrix in RnXn. Then the following statements hold: 
(al) If b E int (A[A])* then (b, 0) E int (A[A, F])*; 
(az) If Sol ( D ,  A, 0,O) = (0) then Sol (D, A, O,O, F, 0) = (0); 
(aJ) If b E -int (A[A])* then (b, 0) E -int (A[A, F])*; 
(a4) If Sol (-D, A, 0,O) = (0) then Sol (-Dl A, 0, 0, F, 0) = (0). 
Proof. If b E int(A[A])* 
then 
For any (u, v )  E A[A, F] \ (0) we have 

10.7 Commentaries 
This yields 
T 
-A u = v > O  
- ) 
~ 2 0 ,  
u # o ,  
hence u E A[A] \ (0). By (lO.97), bTu + OTv = bTu = uTb < 0. This 
shows that (b, 0) E int(A[A, F])*. Statement (al) has been proved. 
It is clear that (a3) follows from (al). 
For proving (az) and (a4) it suffices to note that, under our 
assumptions, 
and 
Sol(-D,A,O,O) = Sol(-D,A,O,O, F,O). 
0 
We check at once that Theorems 10.4 and 10.5 follow from The- 
orem 10.10 and Lemma 10.3. 
10.7 Commentaries 
The material of this chapter is taken from Tam and Yen (1999, 
2000), Tam (2001a). 
Several authors have made efforts in studying stability proper- 
ties of the QP problems. Daniel (1973) established some basic facts 
about the solution stability of a QP problem whose objective func- 
tion is a positive definite quadratic form. Guddat (1976) studied 
continuity properties of the solution set of a convex QP problem. 
Robinson (1979) obtained a fundamental result (see Theorem 7.6 
in Chapter 7) on the stable behavior of the solution set of a mono- 
tone affine generalized equation (an affine variational inequality in 
the terminology of Gowda and Pang (1994), which yields a fact on 
the Lipschitz continuity of the solution set of a convex QP prob- 
lem. Best and Chakravarti (1990) obtained some results on the 
continuity and differentiability of the optimal value function in a 
perturbed convex QP problem. By using the linear complemen- 
tarity theory, Cottle, Pang and Stone (1992), studied in detail the 
stability of convex QP problems. Best and Ding (1995) proved a 
result on the continuity of the optimal value function in a convex 
QP problem. Auslender and Coutat (1996) established some results 
on stability and differential stability of generalized linear-quadratic 
programs, which include convex QP problems as a special case. Sev- 
eral attempts have been made to study the stability of nonconvex 

194 
10. Upper Semicontinuity of the KKT Point Set 
QP problems (see, for instance, Klatte (1985), Tam (1999), Tam 
(2001a, 2001b, 2002)). 
The proof of Theorem 10.1 is based on a construction developed 
by Oettli and Yen (1995, 1996a) for linear complementarity prob- 
lems, homogeneous equilibrium problems, and quasi-complementarity 
problems. 

Chapter 11 
Lower Semicontinuity of the 
KKT Point Set Mapping 
Our aim in this chapter is to characterize the lower semicontinuity of 
the Karush-Kuhn-Tucker point set mapping in quadratic program- 
ming. Necessary and sufficient conditions for the lsc property of 
the KKT point set mapping in canonical QP problems are obtained 
in Section 11.1. The lsc property of the KKT point set mapping 
in standard QP problems under linear perturbations is studied in 
Section 11.2. 
11.1 The Case of Canonical QP Prob- 
lems 
Consider the canonical QP problem of the form (10.1). The follow- 
ing statement gives a necessary condition for the lower semiconti- 
nuity of the multifunction (10.3). 
Theorem 11.1. Let D E R y n  and A E Rmxn be given. If the 
multifunction S(D, A, ., 
a )  is lower semicontinuous at (c, b) E Rn x 
Rm, then the set S(D, A, c, b) is finite. 
Proof. Setting 
and s = n + m, we consider the problem of finding a vector x = 
, \ 
(:) 
E Rs satisfying 

196 
11. Lower Semicontinuity of the KKT Point Set 
For a nonempty subset a c {1,2,. . . , s), Ma, denotes the corre- 
sponding principal submatrix of M. If p E RS, then the column- 
vector with the components (pi)i,, is denoted by p,. 
Let z = (zl, 22,. . . , z,) be a nonzero solution of (11.1), and let 
J = { j .  . zj = 01, I = {i : zi > 0). Since ZJ = 0 and ( M i f q ) ~  = 0, 
we have MIIzI = -&. Therefore, if detMII # 0 then z is defined 
uniquely via q by the formulae 
If I # 0 and detMII = 0, then 
QI := {q E RS : -41 = MIIzI for some z E RS) 
is a proper subspace of Rs. By Baire's Lemma (Brezis (1987), p. 15), 
the union Q := u{QI : I c {1,2,. . . ,s), I # 0, detMII = 0) is 
nowhere dense. So there exists a sequence q" 
( :ik ) converging 
to = (:b) 
such that qk $ Q for all k. 
Fix any x E S(D, A, c, b) and let e > 0 be given arbitrarily. Since 
the multifunction S(D, A, ., .) is lsc at (c, b), there exists 6, > 0 such 
that 
x E S(D, A, c', b') 4- &BRn 
for all (c', b') satisfying max{lld - ell , 11 b' - bll) < 6,. Consequently, 
for each k sufficiently large, there exists xk E S(D, A, ck, bk) such 
that 
k 
llx - x 11 5 &. 
(11.2) 
Since rk E S(D, A, ck, bk), there exists hi such that ik := ($) is 
a solution of the LCP problem 
We put Jx = {j : z! 
= 01, Ik = {i : z! 
> 0). If Ik = 0 then 
zk = 0. If I k  # 0 then detMIkIk # 0, because qk $ Q. Hence 
Obviously, there exists a subset I C {1,2, . . . , s) and a subsequence 
{ki) of {k) such that Iki = I for all hi. Let Z denote the set of all 
z E RS such that there is a nonempty subset I C {I,. . . , s) with 

11.1 The Case of Canonical Problems 
197 
the property that detMII # 0, 21 = -Mhl(ijI) and ZJ = 0, where 
J := (1,. . . , s) \ I. It is clear that Z is finite. From (11.3) it follows 
- 
that the sequence z/:') 
converges to a point from the finite set Z := 
Z U (0). For every z = 
let prl(z) := I. Since prl(z(ki)) = x(") 
and prl(.) is a continuous function, the sequence {x(")) has a limit 
t i n  the finite set 2 := {prl(z) : z E 2). By (11.2), x E 2 +aBRn. 
As this inclusion holds for every E > 0, we have x E 5. 
Thus 
S(D, A, c, b) c 2. We have shown that S(D, A, c, b) is a finite set. 
0 
The following examples show that the finiteness of S(D, A, c, b) 
may not be sufficient for the multifunction S(.) to be lower semi- 
continuous at (D, A, c, b). 
Example 11.1. Consider the problem (P,) of minimizing the func- 
tion 
1 
on the set A = {x E R2 : x 2 0, -21 - x2 2 -2). Note that 
A is a compact set with nonempty interior. Denote by S(E) the 
KKT point set of (PC). A direct computation using (10.2) gives 
1 
3 
for E > 0 small enough. For U := {x E R2 : - < XI < -, -1 < 
2 
2 
x2 < 1) we have S(E) n U = 0 for every E > 0 small enough. 
Meanwhile, S(0) n U = {(1,0)). Hence the multifunction E I+ S(E) 
is not Isc at e = 0. 
Example 11.2. Consider the problem (FE) 
of minimizing the func- 
tion 
on the set A = {x E R2 : x 2 0, -XI - 2 2  > -2). Denote by 
S(E) 
the KKT point set of (FE). Using (10.2) we can show that 
S(0) = { ( l , O ) ,  (0, a)), and S(E) = {(0,2)) for every E > 0. For 
1 
3 
U := {x E R2 : - < x1 < -, -1 < x2 < 1) we haveS(0)nU = 
2 
2 

198 
11. Lower Semicontinuity of the KKT Point Set 
{(I, O)}, but S(E) 
n U = 0 for every E > 0. Hence the multifunction 
E Y Z(E) is not lsc at E = 0. 
In the KKT point set S(D, A, c, b) of (10.1) we distinguish three 
types of elements: (1) Local solutions of QP(D, A, c, b); (2) Lo- 
cal solutions of QP(-D, A, c, b) which are not local solutions of 
QP(D, A,c, b); (3) Points of S(D,A, c, b) which do not belong to 
the first two classes. Elements of the first type (of the second type, 
of the third type) are called, respectively, the local minima, the local 
maxima, and the saddle points of (10.1). 
In Example 11.1, (1,O) E S(0) is a local maximum of (Po) which 
lies on the boundary of A. Similarly, in Example 11.2, ( 1 , O )  E S(0) 
is a saddle point of Fo which lies on the boundary of A. If such 
situations do not happen, then the set of the KKT points is lower 
semicontinuous at the given parameter. 
Theorem 11.2. Assume that the inequality system Ax 2 b, x 2 
0 is regular. If the set S(D, A, c, b) is nonempty, finite, and in 
S(D,A, c, b) there exist no local maxima and no saddle points of 
(10.1) which are on the boundary of A(A, b), then the multifunction 
S(.) is lower semicontinuous at (D, A, c, b). 
Proof. For proving the lower semicontinuity of S(.) at (D, A, c, b) 
it suffices to show that: For any Z E S(D, A, c, b) and for any neigh- 
borhood U of 3 there exists S > 0 such that S(D1, A', c', b') n U # 0 
for every (Dl, A', c', b') satisfying 
max{llD' - Dl\, IIA' - All, 1 1 ~ '  - ell, Ilb' - bll) < S. 
First, suppose that 5 is a local minimum of (10.1). As S(D, A, c, b) 
is a finite set, 5 is an isolated local minimum. Using Theorem 3.7 
we can verify that, for any Lagrange multiplier 
of Z, the second- 
order sufficient condition in the sense of Robinson (1982) is satis- 
fied at (3, X). According to Theorem 3.1 from Robinson (1982), for 
each neighborhood U of 5 there exists 6 > 0 such that for every 
(Dl, A', c', b') satisfying 
max{IID' - DII, IIA' - All, IIc' - ell, Ilb' - bll} < 6 
there is a local minimum Z' of the problem QP(D1, A', c', b') belong- 
ing to U. Since x' E S(D1, A', c', b'), we have S(D1, A', c', b') n U # 0, 
as desired. Now, suppose that 5 is a local maximum or a saddle 
point of (10.1). By our assumption, Z belongs to the interior of 
A(A, b). Hence V f (z) = 0 2  + c = 0, or equivalently, 
D5 = -c. 
(1 1.4) 

11.2 The Case of Standard Problems 
199 
As S(D, A, c, b) is finite, Z is an isolated KKT point of (10.1). Then 
Z must be the unique solution of the linear system (11.4). Therefore, 
the matrix D is nonsingular, and 
Since the system Ax 2 b, x 2 0 is regular, using Lemma 3 from 
Robinson (1977) we can prove that there exist So > 0 and an open 
neighborhood Uo of 3 such that Uo c A(A1, b') for every (A', b') 
satisfying max{II A' - All, 11 b' - bll ) < So. For any neighborhood U of 
3, by (1 1.5) there exists 6 E (0, So) such that, for every (Dl, A', c', b') 
satisfying max{IID1-Dl(, [[A'-All, [Id-ell, IIbl-bll) < S, the matrix 
D' is nonsingular and x' := -(Dl)-lc' belongs to U n Uo. Since x' 
is an interior point A(A1, b'), this implies that x' E S(D1, A', c', b'). 
(It is easily seen that A' := 0 is a Lagrange multiplier corresponding 
to x'.) We have thus shown that, for every (Dl, A', c', b') satisfying 
max{llD'- Dl[, [[A'-All, 1 1 ~ ' - c I I ,  
Ilb'-bll) 
< 6, S(D', A', c', bl)nU # 
0. The proof is complete. 
11.2 The Case of Standard QP Prob- 
lems 
In this section we consider the following QP problem 
1 
Minimize - x T ~ x  + cTx 
2 
subject to x E A(A, b) 
where A E Rmxn and D E R;Xn are given matrices, b E Rm and 
c E Rn are given vectors, 
A ( A , ~ ) = { x E  Rn : A x 2  b). 
Recall that x E Rn is a Karush-Kuhn-Tucker point of (11.6) if 
there exists X E Rm such that 
The KKT point set (resp., the local solution set, the solution set) of 
(11.6) are denoted by S(D,A,c,b), (resp., 
loc(D,A,c,b), 
Sol(D, A, c, b)). 

200 
11. Lower Semicontinuity of the KKT Point Set 
We will study the lower semicontinuity of the multifunctions 
(Dl, A', c', b') H 
S(D1, A', c', b') 
(11.7) 
and 
(c', b') H 
S ( D ,  A, c', b'), 
(11.8) 
which will be denoted by S(.) and S ( D ,  A ,  ., .), respectively. It is 
obvious that if (11.7) is lsc at ( D ,  A, c, b) E RgXn x Rmxn x Rn x Rm 
then (11.8) is lsc at (c, b) E Rn x Rm. 
Necessary conditions for the lsc property of the multifunction 
(11.8) can be stated as follows. 
Theorem 11.3. Let ( D ,  A, c, b) E RgXn x Rmxn x Rn x Rm. If the 
multifunction S ( D ,  A, ., .) is lower semicontinuous at (c, b), then 
(a) the set S ( D ,  A, c, b) is finite, nonempty, and 
(b) the system Ax 2 b is regular 
Proof. (a) For each index set I c (1, 
, m ) ,  we define a matrix 
MI E R ( ~ +  
l ' l ) x ( n + l z l ) ,  
where 111 is the number of elements of I ,  by 
setting 
(If I = 0 then we set MI = D). Let 
Qz = { ( U , V ) E  R"X Itrn : (t) 
=MI(:) 
for some ( x ,  A) E Rn x Rm , } 
and 
Q = U { Q ~  
: I c { I , . . - , m ) ,  detMI = 0). 
If det MI = 0 then it is clear that QI is a proper linear subspace 
of Rn x Rm. Since the number of the index sets I C (1,. . . , m )  
is finite, the set Q is nowhere dense in Rn x Rm according to the 
Baire Lemma (see Brezis (1987), p. 15). So there exists a sequence 
{(ck, bk)) converging to the given point (c, b) E Rn x Rm such that 
(-ck, bk) @ Q for all k. 
Fix any It. E S ( D ,  A, c, b). Since S ( D ,  A, ., .) is lower semicon- 
tinuous at (c, b), one can find a subsequence {(ckl; bb"") of {(c" bk)) 
and a sequence {xkl) converging to It. in Rn such that 

11.2 The Case of Standard Problems 
20 1 
for all kl. As xkl E S ( D ,  A, ck1,bk", there exists X k l  E Rm such that 
For every kr, let Ik, := {i E { I , .  . . , m} : A? > 0). (It may happen 
that Ik, = 0.) Since the number of the index sets I C { I , .  . . , m} 
is finite, there must exist an index set I C (1, . . , m) such that 
Ik, = I for infinitely many kl. Without loss of generality we can 
assume that Ik, = I for all kl. From (11.9) we deduce that 
We claim that det MI # 0. Indeed, if det MI = 0 then, by (11.10) 
and by the definitions of QI and Q, we have 
contrary to the fact that (-ck, bk) $4 Q for all k. We have proved 
that det MI # 0. By (11.10), we have 
Therefore 
If I = 0 then formula (11.1 1) has the form 
lim xkl = D-I(-c). 
l+w 
From (11.11) it follows that the sequence {A?) converges to some 
X I  2 0 in ~1'1. Since the sequence {x"} converges to 3, from (11.11) 
and (11.12) it follows that 

202 
11. Lower Semicontinuity of the KKT Point Set 
(Recall that MI = D if I = 0). We set 
Z = {(x,X) E Rn x Rm : there exists J c { l , . . + , m )  
such that det M j  # 0 and ( f J )  = MY' (;:)I , 
and 
X = {x E Rn : there exists X E Rm such that (x, A) E Z) . 
F'rom the definitions of Z and X ,  we can deduce that X is a finite 
set (although Z may have infinitely many elements). We observe 
also that Z and X do not depend on the choice of 3. Actually, these 
sets depend only on the parameters (D, A, c, b). From (11.13) we 
have 3 E X. Since 5 E S(D, A, c, b) can be chosen arbitrarily and 
since X is finite, we conclude that S(D, A, c, b) is a finite set. 
(b) If Ax 2 b is irregular then there exists a sequence {bk) con- 
verging in Rn to b such that A(A, bk) is empty for all k (Robinson 
(l977), Lemma 3). Clearly, S(D, A, c, by = 0 for all k. As {bk) 
converges to b, this shows that S(D, A, a ,  
a )  cannot be lower semi- 
continuous at (c, b). The proof is complete. 
Examples 11.1 and 11.2 show that finiteness and nonemptiness 
of S(D, A, c, b) together with the regularity of the system Ax 2 b, 
in general, does not imply that S(D, A, -, .) is lower semicontinuous 
at (c, b). 
Let (D, A, c, b) E RgXn x Rmxn x Rn x Rm. Let x E S(D, A, c, b) 
and let X E Rm be a Lagrange multiplier corresponding to x. We 
define I = {1,2,. . . , m), 
and 
J = {i E I : Aix = bi, Xi = 0). 
(11.15) 
It is clear that K and J are two disjoint sets (possibly empty). 
We now obtain a sufficient condition for the Isc property of the 
multifunction S(D, A, ., -) at a given point (c, b) E Rn x Rm. 
Theorem 11.4. Let ( D ,  A, c, b) E RgXnx Rmxnx Rnx Rm. Suppose 
that 
(i) the set S(D, A, c, b) is finite, nonempty, 
(ii) the system Ax 2 b is regular, 

11.2 The Case of Standard Problems 
203 
and suppose that for every x E S(D, A, c, b) there exists a Lagrange 
multiplier X corresponding to x such that at least one of the following 
conditions holds: 
(cl) x E loc(D, A, c, b), 
(c3) J = 0, K # 0, and the system {Ai : i E K) is linearly 
independent, 
(c4) J # 0, K = 0, D is nonsingular and AJD-lA? is a positive 
definite matrix, 
where K and J are defined via (x, A) by (11.14) and (1 1.15). Then, 
the multifunction S(D, A, a ,  
a )  is lower semicontinuous at (c, b). 
Proof. Since S(D, A, c, b) is nonempty, in order to prove that 
S(D, A, ., .) is lower semicontinuous at (c, b) we only need to show 
that, for any x E S(D, A, c, b) and for any open neighborhood Vx of 
x, there exists 6 > 0 such that 
S(D, A, c', b') n V, # 0 
(11.16) 
for every (c', b') E Rn x Rm satisfying 11 (c', b') - (c, b) 11 < 6. 
Let x E S(D,A,c, b) and let Vx be an open neighborhood of 
x. By our assumptions, there exists a Lagrange multiplier X corre- 
sponding to x such that at least one of the four conditions (c1)-(c4) 
holds. 
We first examine the case where (cl) holds, that is 
x E loc(D, A, c, b). 
Since S(D, A, c, b) is finite by (i), loc(D, A, c, b) is finite. So x is 
an isolated local solution of (11.1). Using Theorem 3.7 we can 
verify that, for any Lagrange multiplier X of 3, the second-order 
sufficient condition in the sense of Robinson (1982), Definition 2.1, 
is satisfied at (z, i). 
By assumption (ii), we can apply Theorem 3.1 
from Robinson (1982) to find an 6 > 0 such that 
Ioc(D, A, c', b') n Vx # 0 
for every (c', b') E Rn x Rn with 11 (c', b') - (c, b) 11 < 6. Since 
loc(D, A, c, b) c S(D, A, c', b'), we conclude that (11.16) is valid 
for every (c', b') satisfying 11 (c', b') - (c, b) 11 < 6. 

204 
11. Lower Semicontinuity of the KKT Point Set 
Consider the case where (c2) holds, that is Aix > bi for every 
i E I. Since X is a Lagrange multiplier corresponding to x, the 
system 
is satisfied. As Ax > b, from this we deduce that X = 0. Hence the 
first equality in the above system implies that Dx = -c. Thus x is 
a solution of the linear system 
Since S(D, A, c, b) is finite, x is a locally unique KKT point of (11.6). 
Combining this with the fact that x is an interior point of A(A, b), 
we can assert that x is a unique solution of (11.17). Hence matrix 
D is nonsingular and we have 
Since Ax > b, there exist S1 > 0 and an open neighborhood U, C V, 
of x such that U, c A(A, b') for all b' E Rm satisfying Ilb' - bll < bl. 
By (11.18), there exists S2 > 0 such that if llc' - cII < S2 and 
x' = - D-lc' then x' E U,. Set S = min{S1, 62). Let (c', b') be such 
that [[(c', b') - (c, b)ll < S. Since x' := -D-lc' belongs to the open 
set U, c A(A, b'), we deduce that 
Dx' + c' = 0, Ax' > b'. 
From this it follows that x' E S(D, A, c', b'). (Observe that A' = 0 
is a Lagrange multiplier corresponding to x'.) We have thus shown 
that (11.16) is valid for every (c', b') E Rn x Rm satisfying 11 (c', b') - 
(c, b) I I  < 6. 
We now suppose that (c3) holds. First, we establish that the 
matrix MK E ~
(
~
+
l
~
l
)
~
(
~
+
l
~
I
)
 
defined by setting 
where I K I denotes the number of elements in K ,  is nonsingular. To 
obtain a contradiction, suppose that MK is singular. Then there 
exists a nonzero vector (v, w) E Rn x ~
1
~
1
 
such that 

11.2 The Case of Standard Problems 
205 
This implies that 
Since the system {Ai : i E K) is linearly independent by (c3), from 
(11.19) it follows that v # 0. As AqKx > bqK and X K  > 0, there 
exists 63 > 0 such that A q K ( x  + tv) 2 bqK and X K  + tw 2 0 for 
every t E [O, 631. By (1 1.19) , we have 
D(x + tv) - Ag(XK + tw) + c = 0, 
A ~ ( x + t v ) = b ~ ,  
X K + t w 2 0 ,  
(11.20) 
AI\K(X + tv) 2 ~ I \ K ,  
XI\K 
= 0 
for every t E [O, 631. From (11.20) we deduce that x+tv E S ( D ,  A, c, b) 
for all t E [O, 631. This contradicts the assumption that S ( D ,  A, c, b) 
is finite. We have thus proved that MK is nonsingular. From the 
definition of K it follows that 
The last system can be rewritten equivalently as follows 
As MK is nonsingular, (1 1.21) yields 
So there exists 6 > 0 such that if (c', b') E Rn x Rm is such that 
Il(c', b') - (c, b)ll < 6, then the formula 
defines a vector (x', X)K) E Rn x ~
1
~
1
 
satisfying the conditions 
We see at once that vector x' defined in this way belongs to the set 
S ( D ,  A, c', b') n Vx 

206 
11. Lower Semicontinuity of the KKT Point Set 
and A' := (A;(, XiJK), where XiJK = 0, is a Lagrange multiplier 
corresponding to x'. We have shown that (11.16) is valid for every 
(c', b') E Rn x Rm satisfying 1 1  (c', b') - (c, b) 1 1  < 6. 
Finally, suppose that (c4) holds. In this case, we have 
DX + c = 0, Ajx = b j ,  
X j  = 0, 
Aqjx > b q j ,  XI\j = 0. 
(11.22) 
To prove that there exists 6 > 0 such that (11.16) is valid for every 
(c', b') E Rn x Rm satisfying 1 1  (c', b') - (c, b) 11 < 6, we consider the 
following system of equations and inequalities of variables (2, p) E 
Rn x Rm: 
Since D is nonsingular, (11.23) is equivalent to the system 
By (11.22), AI\ JX > bI\ j. Hence there exist 64 > 0 and an open 
neighborhood Ux c V, of x such that AI\jz 2 bi\J for any z E U, 
and (c', b') E Rn x Rm satisfying 11 (c', b') - (c, b) 11 < 64. Consequently, 
for every (c', b') satisfying 11 (c', b') - (c, b) 11 < 64, the verification of 
(11.16) is reduced to the problem of finding x E Ux and p~ E RIJl 
such that (1 1.24) holds. Here I JI denotes the number of elements in 
J .  We substitute z from the first equation of (11.24) into the first 
inequality and the last equation of that system to get 
Let S := AjD-lA; 
and q' := -b', - AJD-'c'. 
We can rewrite 
(1 1.25) as follows 
SPJ + 4' 2 0, PJ 2 0, 
( p ~ ) ~ ( S p j  
+ 9') = 0. 
(11.26) 
Problem of finding p~ E ~
1
~
1
 
satisfying (11.26) is the linear comple- 
mentarity problem defined by the matrix S E RIJIXIJl and the vector 
q' E ~ 1 ~ 1 .  
By assumption (c4), S is a positive definite matrix, that 
is yTSy > 0 for every y E ~
1
~
1
 
\ (0). Then S is a P-matrix. The 
latter means that every principal minor of S is positive (see Cottle 
et al. (1992), Definition 3.3.1). According to Cottle et al. (1992), 

11.2 The Case of Standard Problems 
207 
Theorem 3.3.7, for each q' E RIJI, problem (11.26) has a unique 
solution p J E RIJI. Since D is nonsingular, from (11.22) it follows 
that 
AJD-l(-C) - bJ = 0. 
Setting q = -bJ - AJD-lc we have q = 0. Substituting q' = q = 0 
into (11.26) we find the unique solution pJ = 0 = Xj. By Theorem 
7.2.1 from Cottle et al. (1992), there exist Q > 0 and e > 0 such 
that for every q' E RIJl satisfying Ilq' - qll < e we have 
Therefore 
From this we conclude that there exists 6 E (0, S4] such that if (c', b') 
satisfies the condition 11 (c', b') - (c, b) 11 < S, then the vector 
where p J is the unique solution of (11.26), belongs to U,. From the 
definition of p~ and z we see that system (11.24), where p q j  := 0, 
is satisfied. Then x E S(D, A, c', b'). We have thus shown that, for 
any (c', b') satisfying Il(cl, b') - (c, b) 11 < S, property (11.16) is valid. 
The proof is complete. 
0 
To verify condition (cl), we can use Theorem 3.5. 
We now consider three examples to see how the conditions (c1)- 
(c4) can be verified for concrete QP problems. 
Example 11.3. (See Robinson (1980), p. 56) Let 
1
2
 1 
2 
- XI for all x = (xl, 
5 2 )  E R2. 
(11.27) 
f (x) = -XI - -x2 
Consider the QP problem 
For this problem, we have 

208 
11. Lower Semicontinuity of the KKT Point Set 
For any feasible vector x = (xl, 2 2 )  of (11.28), we have xl 2 21x21. 
Therefore 
2 
1
2
 1
2
 
2 
3 
2 
f (x) + - = -xi - -x2 - XI + - > -2; - XI + - > 0. 
(11.29) 
3 
2 
2 
3 - 8  
3 - 
4 
2 
2 
For 2 := (t, :) and i := (- --), we have f(2) = f(2) = -- 
3' 3 
3' 
Hence from (11.29) it follows that 2 and 2 are the solutions of 
(11.28). Actually, 
Setting E = (1,O) we have 2 E S(D, A, c, b) \ loc(D, A, c, b). Note 
that ?; := (0,O) is a Lagrange multiplier corresponding to 2. We 
check at once that conditions (i) and (ii) in Theorem 11.4 are sat- 
isfied and, for each KKT point x € S(D, A, c, b), either (cl) or (c2) 
is satisfied. Theorem 11.4 shows that the multifunction S(D, A, -, -) 
is lower semicontinuous at (c, b). 
Example 11.4. Let f ( a )  be defined by (1 1.27). Consider the QP 
problem 
For this problem, we have 
Let 2, i, E be the same as in the preceding example. Note that 
- 
X := (0,0,O) is a Lagrange multiplier corresponding to E. We have 
S(D, A, c, b) = {E, 2, i), Sol(D, A, c, b) = loc(D, A, c, b) = {z, 2). 
Clearly, for x = 2 and x = 2, assumption (cl) is satisfied. It is 
easily seen that, for the pair (E,X), we have K = 0, J = {3). Since 
A j  = (1 0) and D-I = D, we get AjD-lA: 
= 1. Thus (c4) is 
satisfied. By Theorem 11.4, S(D, A, ., -) is lower semicontinuous at 
(c, b). 

1 1.2 The Case of Standard Problems 
209 
Example 11.5. Let f (x) be as in (11.27). Consider the QP prob- 
lem 
For this problem, we have 
Let Z = (2, -I), 2 = (2, I), E = (2,O). Note that 1 := (0,0,1) is 
a Lagrange multiplier corresponding to E. For x = Z _and x = 2, 
we see at once that (cl) is satisfied. For the pair (Z, 
A), we have 
K = (31, J = 0. Since 
assumption (c3) is satisfied. According to Theorem 11.4, S(D, A, a ,  
a )  
is lower semicontinuous at (c, b). 
The idea of the proof of Theorem 11.4 is adapted from Robinson 
(1980), Theorem 4.1, and the proof of Theorem 11.2. In Robinson 
(1980), some results involving Schur complements were obtained. 
Let (Dl A, c, b) E R:Xn x Rmxn x Rn x Rm. Let x E S(D, A, c, b) 
and let X E Rm be a Lagrange multiplier corresponding to x. We 
define K and J by (11.14) and (11.15), respectively. Consider the 
case where both the sets K and J are nonempty. If the matrix 
is nonsingular, then we denote by Sj the Schur complement (see 
Cottle et al. (1992), p. 75) of MK in the following matrix 
D 
-A; 
-A? 
[: 
; ; ] E ~ ~ ~ + ~ ~ l + l J l ~ ~ ~ ~ + l ~ l + l J l ~ ~
This means that 
Sj = [AJ O]MG~[AJ 
o ] ~ .  
Note that Sj is a symmetric matrix (see Robinson (1980)) p. 56). 
Consider the following condition: 

210 
11. Lower Semicontinuity of the KKT Point Set 
(c5) J # 0, K  # 0, the system {Ai : i E K )  is linearly in- 
dependent, vTDv # 0 for every nonzero vector v satisfying 
AKv = 0, and SJ is positive definite. 
Modifying some arguments of the proof of Theorem 11.4 we can 
show that if J # 0, K  # 0, the system {Ai : i E K )  is linearly 
independent, and vTDv # 0 for every nonzero vector v satisfying 
AKv = 0, then MK is nonsingular. 
It can be proved that the assertion of Theorem 11.4 remains valid 
if instead of (c1)-(c4) we use (c1)-(c3) and (c5). The method of 
dealing with (c5) is similar to that of dealing with (c4) in the proof 
of Theorem 11.4. Up to now we have not found any example of 
QP problems of the form (11.1) for which there exists a pair (x, A), 
x E S(D, A, c, b) and X is a Langrange multiplier corresponding 
to x, such that (c1)-(c4) are not satisfied, but (c5) is satisfied. 
Thus the usefulness of (c5) in characterizing the 1sc property of the 
multifunction S(D, A, a ,  
a )  is to be investigated furthermore. This is 
the reason why we omit (c5) in the formulation of Theorem 11.4. 
We observe that the sufficient condition in Theorem 11.2 for the 
lsc property of the following multifunction 
(Dl, A', c', b') -+ S(D1, A', dl b'), 
(11.30) 
where (Dl, A', c', b') E RgXn x Rmxn x Rn x Rm, can be reformulated 
equivalently as follows. 
Theorem 11.5. Let (Dl A, c, b) E RgXn x Rmxn x Rn x Rm. Suppose 
that 
(i) the set S(D, A, c, b) is finite, nonempty, 
(ii) the system Ax 2 b is regular, 
and suppose that for every x E S(D, A, c, b) at least one of the 
following conditions holds: 
(cl) x E loc(D, A, c, b), 
Then, multifunction (11.30) is lower semicontinuous at (D, A, c, b). 
It is easy to check that (c2) in the above theorem is equivalent 
to (c2) in Theorem 11.4. 

1 1.3 Commentaries 
211 
11.3 Commentaries 
The material of this chapter is taken from Tam and Yen (1999) and 
Lee et al. (2002b, 2002~). 


Chapter 12 
Continuity of the Solution 
Map in Quadratic 
Programming 
In this chapter we study the lower semicontinuity and the up- 
per semicontinuity properties of the multifunction (D,A,c, b) H 
Sol(D, A, c, b), where Sol(D, A, c, b) denotes the solution set of the 
canonical quadratic programming problem. 
12.1 USC Property of the Solution Map 
Let D E R:Xn, A E Rmxn, c .E Rn, and b E Rm. Consider the 
following QP problem of the canonical form: 
1 
(PI 
Minimize f (x) := -X*DX + cTx 
2 
subject to Ax 2 b, 
x 2 0. 
Let A(A, b), Sol(D, A, c, b), and S(D, A, c, b) denote, respectively, 
the constraint set, the solution set, and the Karush-Kuhn-Tucker 
point set of (P). 
In Chapter 10 we have studied the upper semicontinuity of the 
set-valued map 
(D, A, c, b) 
S(D, A, c, b). 
In this section we will examine in detail the usc property of the 
solution map 
(D, A, c, b) H Sol(D, A, c, b). 
(12.1) 

214 
12. Solution Map in Quadratic Programming 
A complete characterization of the lsc property of the map will be 
given in the next section. 
Recall that the inequality system 
is called regular if there exists xO E Rn such that Ax0 > b, xO > 0. 
The next result is due to Nhan (1995), Theorem 3.4. 
Theorem 12.1. Assume that 
(a2) the system (12.2) is regular. 
Then, for any c E Rn, the multifunction Sol(.) is upper semicontin- 
uous at (Dl A, c, b). 
Proof. To obtain a contradiction, suppose that there is a pair 
(c, b) E Rn x Rm such that Sol(D, A, c, b) # 0 and there exist an 
open set SZ containing Sol(D, A, c, b) , a sequence {(D" A', ck, bk)) 
converging to (D, A, c, b), a sequence {xk} such that 
xk E SO~(D" A', c" bk) \ SZ 
for every k E N 
If the sequence {xk) is bounded, then there is no loss of generality 
in assuming that xk t xO for some xO E Rn. It is clear that xO E 
A(A, b). Fix any x E A(A, b). By assumption (b2), there exists a 
sequence {Fk), Fk E A(Ak, bk) for all k E N, such that lim xk = x 
k+oo 
(see Lemma 13.1 in Chapter 13). Since xk E  sol(^^, Ak, ckl bk), 
we have f (x" ) f (Fk). Letting k --t cm we get f (xO) 5 f (x). 
This shows that xO E Sol(D, A,c, b) C SZ. We have arrived at a 
contradiction, because xk f SZ for all k, and R is open. 
Now suppose that the sequence {x" is bounded. Without loss of 
generality we can assume that llx"ll-lxk t t, U E A(A, 0). Fix any 
x E A(A, b). By (a2) there exists a sequence {F", 
Jk E A(Ak, bk) 
for all k and Fk t 
x. Dividing the inequality 
by 11xkl(2 and letting k t 
cm we get tTD5 5 0. If t T D t  < 0, then 
Sol(D,A,O,O) = 0, contrary to (al). If t T D t  = 0, then we have 
t E Sol(D, A, 0, 0), which is also impossible. 

12.1 USC Property of the Solution Map 
215 
The proof is complete. 
Corollary 12.1. If the system (12.2) is regular and if the set 
A(A, b) is bounded, then Sol(.) is upper semicontinuous at (D, A, c, b). 
Proof. Since the system (12.2) is regular, A(A, b) is nonempty. 
The boundedness of A(A, b) implies that A(A, 0) = (0). Hence 
Sol(D, A, 0,O) = (01, and the desired property follows from Theo- 
rem 12.1. 
Condition (al) amounts to saying that xTDx > 0 for every x E 
A(A, 0) \ {O), i.e., the quadratic form xTDx is strictly copositive on 
the cone A(A, 0). 
The next statement is a complement to Theorem 12.1. 
Theorem 12.2. Assume that: 
(b2) the system Ax > 0, x 2 0 is regular. 
Then, for any (c, b) E Rn x Rm, the multifunction Sol(.) is upper 
semicontinuous at (D, A, c, b). 
Proof. Suppose that the assertion of the theorem is false. Then 
there is a pair (c, b) E Rn x Rm such that Sol(D, A, c, b) # 0 and 
there exist an open set R containing Sol(D, A, c, b), a sequence 
{(Dk, Ak, ck, bk)} converging to (Dl A, c, b), a sequence {xk} such 
that 
2% SO~(D" 
ck, bk) \ R for every Ic E N. 
If the sequence {x" is bounded, then we can assume that x
b
 
xO 
for some xO E Rn. We have xO E A(A,b). Fix any x E A(A,b). 
Assumption (b2) implies that system (12.2) is regular. Then there 
exists a sequence {Jk), Jk E A(A" bk) for all k E N, such that 
lim xk = x. Since f (xk) 5 f (tk), 
letting k + m we obtain f (xO) 5 
k+m 
f (i). Thus xO E Sol(D, A, c, b) c R. This contradicts the fact that 
x" 
4 for all k. 
Now assume that {xk) is unbounded. By taking a subsequence if 
necessary, we may assume that I Ixk/ 1 I 
m. Since xk E Sol(Dk, Ak, ck, bk), 
for each k there exists Xk E Rm such that 

216 
12. Solution Map in Quadratic Programming 
Since 1 1  (xkl AX") 1 1  + m, without loss of generality we can assume 
that 1 1  (xX", A91 I # 0 for all k ,  and the sequence of vectors 
converges to some (z,X) E Rn x Rm with 1 1  (5, X)ll = 1. Dividing 
both sides of (12.3) and of (12.4) by 1 1  (x" AX") 1 1 ,  dividing both sides 
of (12.5) by Il(xk, AX")1I2, and taking the limits as k + oo, we obtain 
The system (12.6)-(12.8) proves that Z E S(D,A, 0,O). By (bl), 
Z = 0. Hence 
- A ~ X  2 0, X 2 0. 
(12.9) 
Combining (12.9) and (b2) yields X = 0 (see Lemma 10.1), hence 
I I(z, 5) I I = 0, a contradiction. The proof is complete. 
0 
Remark 12.1. Since A(A, b) + A(A, 0) c A(A, b), (b2) implies 
(a2). However, (bl) does not imply (al). 
Observe that neither (al) nor (a2) is a necessary condition for 
the upper semicontinuity of the solution map Sol(.) at a given point 
(Dl A, c, b). 
Example 12.1. Let n = m =  1, D =  [0], A =  [I], c =  1, b =  1. 
It is easily verified that Sol(D, A, c, b) = (1) and the multifunction 
Sol(.) is usc at (D, A, c, b). Meanwhile, Sol(D, A, 0,O) = {x E R  : 
x 2 01, so (al) fails to hold. 
Example 12.2. Let n = m = 1, A = [-I], b = 0. If A' = [-l+ 
a], b' = p, where a and p are sufficiently small, then A(A1, b') = 
i 
X E R :  
O < x < -  -p 1 
. It is easily seen that, for arbitrarily cho- 
1-a 
sen D and c, the multifunction Sol(.) is usc at (Dl A, c, b), while 
condition (a2) does not hold. 
12.2 LSC Property the Solution Map 
By definition, multifunction Sol(+) is continuous at (D, A, c, b) if it 
is simultaneously upper semicontinuous and lower semicontinuous 
at that point. 

12.2 LSC Property the Solution Map 
217 
Our main result in this section can be stated as follows. 
Theorem 12.3. The solution map Sol(.) of (P) is lower semicon- 
tinuous at (D, A, c, b) if and only if the following three conditions 
are satisfied: 
(a) the system Ax > b, x > 0 is regular, 
(c) ISol(D, A, c, b)I = 1 
For proving Theorem 12.3 we need some lemmas. 
Lemma 12.1. If Sol(.) is lower semicontinuous at (Dl A, c, b), then 
the system Ax 2 b, x 2 0 is regular. 
Proof. If the system Ax > b, x > 0 is irregular then, according 
to Lemma 3 in Robinson (1977), there exists a sequence (Ak, by E 
RmXn x Rm tending to (A, b) such that A(Ak, by = 0 for each 5. 
Therefore, Sol(D, A" c, b" 
= 0 for each 5, contrary to the assumed 
lower semicontinuity of the solution map. 
Lemma 12.2. If the multifunction Sol(.) is lower semicontinuous 
at (D,A,c,b), then Sol(D,A,O,O) = (0). 
Proof. On the contrary, suppose that Sol(D, A, 0,O) # (0). Then 
there is a nonzero vector Z E Rn such that 
Since A(A, b) # 0, from (12.10) it follows that A(A, b) is unbounded. 
For every E > 0, we get from (12.10) that zT(D - EE)Z < 0. Hence, 
for any x E A(A, b), 
as t -+ oo. Thus, Sol(D - EE, A, c, b) = 0. This contradicts our 
assumption that Sol(.) is lower semicontinuous at (Dl A, c, b) . 
Lemma 12.3. (i) If Sol(D, A, 0,O) = (0) then, for any (c, b) E 
Rn x Rm, Sol(D, A, c, b) is a compact set. 
(ii) If Sol(D, A, 0,O) = (0) and if A(A, b) is nonempty, then 
Sol(D, A, c, b) is nonempty for every c E Rn. 
Proof. (i) Suppose that Sol(D, A, 0,O) = (01, but Sol(D, A, c, b) 
is unbounded for some (c, b). Then there is a sequence {xk} C 

218 
12. Solution Map in Quadratic Programming 
Sol(D,A,c, b) such that Ilxkll + m as k t m .  Fixing any x E 
A (A, b) , one has 
We can assume that the sequence 11~"1-~x%onver~es to some 
3 with l l ~ l l  = 1. Using (12.11) and (12.12) it is easy to show 
that zTD3 5 0, A3 2 0, 3 2 0. This contradicts the fact that 
Sol(D, A, 0,O) = (0). We have thus proved that Sol(D, A, c, b) is a 
bounded set. Then Sol(D, A, c, b) , being closed, is a compact set. 
(ii) Let Sol(D,A,O,O) = {0), A(A, b) # 8, and let c E Rn 
1 
be given arbitrarily. If the quadratic form f (x) = ; x T ~ x  + cTx 
is bounded below on the polyhedron A(A, b) then, cy the Frank- 
Wolfe Theorem (see Theorem 2. I), the solution set Sol(D, A, c, b) is 
nonempty. Now assume that there exists a sequence xk E A(A, b) 
such that f(xk) -t -m as k + oo. By taking a subsequence, if 
necessary, we can assume that 
for all k, IIx"] + m, and 
converges to some 3 as k + oo. 
It is a simple matter to show that 3 E A(A, 0). Dividing both sides 
of (12.13) by llxk112 and letting k -t m one has zTD5 5 0. As 
~~~~~=1,0negetsSol(D,A,O,0)#{O),whichisimpossible. 
0 
We omit the proof of the next lemma, because it is similar to 
the proof of Theorem 11.1. 
Lemma 12.4. If the multifunction Sol(.) is lower semicontinuous 
at (Dl A, c, b), then the set Sol(D, A, c, b) is finite. 
Lemma 12.5. The set G := {(D,A) : Sol(D,A,O, 0) = (0)) is 
open in RgXn x Rmxn. 
Proof. On the contrary, suppose that there is a sequence {(D" Ak)) 
converging to (D, A) E G such that Sol(Dk, Ak, 0,O) # (0) for all 
k. Then for each k there exists a vector x%uch that Ilxkll = 1 and 
Without loss of generality, we can assume that {xk} converges to 
some xO with llxOll = 1. Taking the limits in (12.14) as k + m, we 
obtain 
Ax0 2 0, xO 2 0, 
( x O ) ~ D X O  < 0. 

12.2 LSC Property the Solution Map 
219 
This contradicts the assumption that Sol(D, A, 0,O) = (0). The 
proof of is complete. 
For each subset a c (1,. . . , m) with the complement 6, and for 
each subset /? c {I,. . . , n) with the complement p, let 
F(a,/?) 
:= {x E Rn : (Ax), > b,, 
 AX)^ = b&, xp > 0, xp = 0). 
Note that F(a, /?) is a pseudo-face of A(A, b). Obviously, 
Besides, for every x E A(A, b) there exists a unique pair (a, P) such 
that x E F(a,/?). In addition, if (a,/?) # (at,/?') 
then F(a,/?) n 
F(at,/?') = 0. 
The following lemma is immediate from Theorem 4.5. 
Lemma 12.6. If the solution set Sol(D, A, c, b) is finite then, for 
any a c (1,. . . , m) and for any /? c (1,. . . , n), we have 
Lemma 12.7. If the multifunction Sol(.) is lower semicontinuous 
at (D, A, c, b), then 
Proof. On the contrary, suppose that in Sol(D, A, c, b) we can find 
two distinct vectors Z, y. Let J(z) = {j : Zj = 0), J(y) = {j : 
yj = 0). 
If J(z) # J(y), then there exists jo such that Zjo = 0 and yj0 > 0, 
or there exists jl such that Zj, > 0 and yj, = 0. By symmetry, it is 
enough to consider the first case. As y E Sol(D, A, c, b) and yjo > 0, 
there is an open neighborhood U of y such that f (y) 2 f (y) and 
yjo > 0 for every y E U. Fix any E > 0 and put c(e) = (ci(e)) where 
1 
Let f,(x) = f(x) +  EX^,, where, as before, f (x) = - x T ~ x  + cTx. 
2 
Consider the quadratic program 
Minimize f,(x) 
subject to x E A(A, b), 

220 
12. Soh tion Map in Quadratic Programming 
whose solution set is Sol(D, A, c(e), b). For every y E U, we have 
Hence y $ Sol(D, A, c(e), b). So 
Since E > 0 can be arbitrarily small, (12.15) contradicts our as- 
sumption that Sol(.) is lower semicontinuous at (D, A, c, b). 
We now suppose that J(z) = J(g). Let a and a' be the index 
sets such that 
E F ( a ,  Dl, y E F(a',D), 
where ,8 is the complement of J(3) = J(y) in (1, . . . , n). By Lemma 
12.4, Sol(D, A, c, b) is a finite set. Then, by Lemma 12.6, a # a'. 
Hence at least one of the sets a \ a' and a' \ a must be nonempty. 
By symmetry, it suffices to consider the first case. Let io E a \ a'. 
Then we have 
(A3)iO > bio 
(Ay)io = bio. 
(12.16) 
As Sol(D, A, c, b) is finite, one can find a neighborhood W of jj such 
that 
Sol(D, A, C, b) n W = {y). 
(12.17) 
Fix any e > 0 and put b(e) = (bi(e)), where 
By (12.16), there exists 6 > 0 such that 3 E A(A, b(e)) for every 
e E (0,S). Since A(A, b(e)) c A(A, b), we have 
Therefore, for every E E (0,6), Z E Sol(D, A, c, b(e)). Moreover, 
Sol(D, A, c, b(e)) c Sol(D, A, c, b). 
It is clear that $j $ A(A, b(e)). Then we have Sol(D, A, c, b(e)) C 
Sol(D, A, c, b) \ {y). Hence, by (12.17), Sol(D, A, c, b(e)) n W = 0 for 
every e E (0,6). This contradicts the lower semicontinuity of Sol(.) 
at (D, A, c, b). Lemma 12.7 is proved. 

12.2 LSC Property the Solution Map 
221 
Proof of Theorem 12.3. 
If Sol(.) is lower semicontinuous at (Dl A, c, b) then from Lemmas 
12.1, 12.2, and 12.7, we get (a), (b), and (c). 
Conversely, assume that the conditions (a), (b) and (c) are ful- 
filled. Let fl be an open set containing the unique solution Z E 
Sol(D,A, c, b). By (a), there exists 61 > 0 such that A(A1, b') # 0 
for every pair (A', b') satisfying max{l /A' - A[ l , I l  b' - bl 1 ) < bl (see 
Lemma 13.1 in Chapter 13). By (b) and by Lemma 12.5, there 
exists 62 > 0 such that Sol(D', A', 0,O) = (0) for every pair (D', A') 
satisfying maxi1 1 D' - Dl 1, I IA' - A1 1 )  5 62. For 6 := min{bl, S2), by 
the second assertion of Lemma 12.3 we have Sol(D1, A', c', b') # 0 
for every (Dl, A', c', b') satisfying 
By (a) and (b), it follows from Theorem 2.1 that Sol(.) is upper 
semicontinuous at (D, A, c, b). Hence Sol(D1, A', c', b') c R for every 
(Dl, A', c', b') satisfying (12.18), if 6 > 0 is small enough. For such 
a S, from what has been said it follows that Sol(D1, b', c', b') fl R # 0 
for every (D', A', c', b') satisfying (12.18). This shows that Sol(.) is 
lower semicontinuous at (Dl A, c, b). The proof is complete. 
The following fact follows directly from Theorems 12.3 and 12.1. 
Corollary 12.2. If the multifunction Sol(.) is lower semicontinuous 
at (Dl A, c, b) then it is upper semicontinuous at (Dl A, c, b), hence 
it is continuous at the point. 
Let us mention two other interesting consequences of Theorem 
12.3. 
Corollary 12.3. If D is a negative semidefinite matrix, then the 
multifunction Sol(.) is continuous at (Dl A, c, b) if and only if the 
following conditions are satisfied 
(i) the system Ax > b, x 2 0 is regular, 
(ii) A(A, b) is a compact set, and 
(iii) ISol(D, A, c, b)I = 1. 
Proof. Assume that Sol(.) is lower semicontinuous at (Dl A, c, b). 
By Theorem 12.3, conditions (i) and (iii) are satisfied. Moreover, 

222 
12. Solution Map in Quadratic Programming 
We claim that A(A, 0) = (0). Indeed, by assumption, xTDx 5 0 for 
every x E A(A, 0). If there exists no 3 E A(A, 0) with the property 
that zTD3 < 0 then Sol(D, A, 0,O) = A(A, 0), and (12.19) forces 
A(A, 0) = (0). If zT D? < 0 for some 3 E A(A, 0) then it is obvious 
that Sol(D, A, 0,O) = 0, which is impossible. Our claim is proved. 
Property (ii) follows directly from the equality A(A, 0) = (0). 
Conversely, suppose that (i), (ii) and (iii) are satisfied. As 
A (A, b) # 0 by (i) , assumption (ii) implies that A (A, 0) = (0). 
Therefore, Sol(D, A, 0,O) = (0). Since the conditions (a), (b) and 
(c) in Theorem 12.3 are satisfied, Sol(.) is lower semicontinuous at 
(D, A, c, b). The proof is complete. 
Corollary 12.4. If D is a positive definite matrix, then the multi- 
function Sol(.) is continuous at (D, A, c, b) if and only if the system 
Ax 2 b, x 2 0 is regular. 
The proof of this corollary is simple, so it is omitted. 
12.3 Commentaries 
The material of this chapter is adapted from Tam (1999). The proof 
of the 'necessity7 part of Theorem 12.3 can be shortened greatly by 
using an argument in Phu and Yen (2001). 

Chapter 13 
Continuity of the Optimal 
Value Function in 
Quadratic Programming 
In this chapter we will characterize the continuity property of the 
optimal value function in a general parametric QP problem. The 
lower semicontinuity and upper semicontinuity properties of the op- 
timal value function are studied as well. Directional differentiability 
of the optimal value function in QP problems will be addressed in 
the next chapter. 
13.1 Continuity of the Optimal Value 
Function 
Consider the following general quadratic programming problem with 
linear constraints, which will be denoted by QP(D, A, c, b), 
1 
Minimize f ( x ,  c, D) := - x T ~ x  + cTx 
2 
(13.1) 
subject to x E A(A, b) := { x  E Rn : Ax > b) 
depending on the parameter c~ = (D, A, c, b) E R, where 
The solution set of (13.1) will be denoted by Sol(D,A, c, b). The 
function cp : R + defined by 
cp(w) = inf{f (x,c, D) : x E A(A, b)). 

224 
13. Continuity of the Optimal Value Function 
is the optimal value function of the parametric problem (13.1). 
If vTDv 2 0 (resp., vTDv 5 0) for all v E Rn then f (., c, D) 
is a convex (resp., concave) function and (13.1) is a convex (resp., 
concave) QP problem. If such conditions are not required then 
(13.1) is an indefinite QP problem (see Section 1.5). 
In this section, complete characterizations of the continuity of 
the function cp at a given point are obtained. In Section 13.2, suf- 
ficient conditions for the upper and lower semicontinuity of cp at 
a given point will be established. For proving the results, we rely 
on some results due to Robinson (1975, 1977) on stability of the 
feasible region A(A, b) and the Frank-Wolfe Theorem. 
Before obtaining the desired characterizations, we state some 
lemmas. 
Lemma 13.1. Let A E Rmxn, b E Rm. The system Ax 2 b is 
regular if and only if the multifunction A(.) : RmXn x Rm - 
2Rn, 
defined by A(A1, b') = {x E Rn : A'x 2 b'), is lower semicontinuous 
at (A, b). 
Proof. Suppose that Ax 2 b is a regular system and xO E Rn is 
such that Ax0 > b. Obviously, A(A, b) is nonempty. Let V be an 
open subset in Rn satisfying A(A, b) n V # 0. Take x E A(A, b) n V. 
For every t E [0, 11, we set 
Since xt + x as t + 0, there is to > 0 such that xto E V. Since 
Axto = (1 - to)Ax + t o ~ x O  
> (1 - to)b + tob = b, 
there exists 
> 0 such that 
for all (A', b') E Rmxn x Rm satisfying 
Thus xt E A(A1, b') for every (A', b') fulfilling (13.2). Therefore A(.) 
is lower semicontinuous at (A, b). 
Conversely, if A(.) is lower semicontinuous at (A, b) then there 
exists 6 > 0 such that Ax 2 b' is solvable for every b' E Rm satisfying 
b' > b and Ilb' - bll < 6. This implies that Ax > b is solvable. Thus 
Ax 2 b is a regular system. 

13.1 Continuity of the Optimal Value Function 
225 
Remark 13.1. If the inequality system Ax 2 b is irregular then 
there exists a sequence {(Ak, bk)) in RmXn x Rm converging to (A, b) 
such that, for every k, the system Akx 2 b"as 
no solutions. This 
fact follows from the results of Robinson (1977). 
Lemma 13.2 (cf. Robinson (1977), Lemma 3). Let A E RmXn. If 
the system Ax 2 0 is regular then, for every b E Rm, the system 
Ax 2 b is regular. 
Proof. Assume that Ax 2 0 is a regular and 3 E Rn is such that 
A% > 0. Setting b = Az, we have b > 0. Let b E Rm be given 
arbitrarily. Then there exists t > 0 such that tb > b. We have 
A(t3) = tA3 = ttb. Therefore A(t3) > b, hence the system Ax 2 b 
is regular. 
0 
The set 
is open in RgXn x Rmxn. This fact can be proved similarly as Lemma 
12.5. It is worthy to stress that Lemma 12.5 is applicable only to 
canonical QP problems while, in this chapter, the standard QP 
problems are considered. 
Lemma 13.3. If A(A, b) is nonempty and if Sol(D, A, 0,O) = (0) 
then, for every c E Rn, Sol(D, A, c, b) is a nonempty compact set. 
Proof. Let A(A, b) be nonempty and Sol(D, A, 0,O) = (0). Sup- 
pose that Sol(D, A, c, b) = 0 for some c E Rn. By the Frank-Wolfe 
Theorem, there exists a sequence { x k )  such that Ax" 
b for every 
k and 
It is clear that Ilx"] -+ + m  as k -f m .  By taking a subsequence if 
necessary, we can assume that 11 xyl-'xk + -f E Rn and 
1 
f (x" c, D) = - ( x ' " ) ~ D x ~  
+ cTxk < 0 for every k. 
(13.4) 
2 
We have 
Letting k --t m, we obtain 3 E A(A, 0). Dividing both sides of the 
inequality in (13.4) by 1
1
~
~
1
1
~
 
and letting k -+ m, we get zTD3 5 0. 
Since Illt.ll = 1, we have Sol(D, A, 0,O) # (0). This contradicts the 

226 
13. Continuity of the Optimal Value Function 
assumption Sol(D, A, 0,O) = (0). Thus Sol(D, A, c, b) is nonempty 
for each c E Rn. 
Suppose, contrary to our claim, that Sol(D, A, c, b) is unbounded 
for some c E Rn. Then there exists a sequence {xk) C Sol(D, A, c, b) 
such that llxkll t 00 as k -+ oo and {Ilxkll-'xk} converges to a 
certain 3 E Rn. Taking any x E A(A, b) , we have 
AX'" 2 b. 
(13.6) 
Dividing both sides of (13.5) by llxk112, both sides of (13.6) by IIx"I, 
and letting k 
oo, we obtain 
Thus Sol(D, A, 0,O) # {0), a contradiction. We have proved that, 
for every c E Rn, the solution set Sol(D, A, c, b) is bounded. Fixing 
any 3 E Sol(D, A, c, b) one has 
Sol(D,A,c, b) = {x E A(A, b) : f(x,c, D) = f(z,c, D)). 
Hence Sol(D, A, c, b) is a closed set and, therefore, Sol(D, A, c, b) is 
a compact set. 
We are now in a position to state our first theorem on the con- 
tinuity of the optimal value function cp. This theorem gives a set of 
conditions which is necessary and sufficient for the continuity of cp 
at a point w = (Dl A, c, b) where cp has a finite value. 
Theorem 13.1. Let (Dl A, c, b) E a. Assume that cp(D, A, c, b) # 
f 
oo. Then, the optimal value function cp(.) is continuous at (Dl A, c, b) 
if and only if the following two conditions are satisfied: 
(a) the system Ax 2 b is regular, 
(b) Sol(D, A, 0,O) = (0). 
Proof. Necessity: First, suppose that cp(.) is continuous at w := 
(Dl A, c, b) and cp(w) # f 
oo. If (a) is violated then, by Remark 
13.1, there exists a sequence {(A" bk)) in RmXn x Rm converging 
to (A, b) such that, for every k ,  the system Akx 2 bk has no solu- 
tions. Consider the sequence {(Dl Ak, c, bk)}. Since A(A" bk) = 0, 

13.1 Continuity of the Optimal Value Function 
227 
'p(D,Ak,c, bk) = +oo for every k. As p(.) is continuous at w and 
{(Dl A< c, by) converges to w, we have 
lim 'p(D, Ak, c, bk) = p(D, A, c, b) # foo. 
k+co 
We have arrived at a contradiction. Thus (a) is fulfilled. 
Now we suppose that (b) fails to hold. Then there is a nonzero 
vector z E Rn such that 
1 
Consider the sequence {(D" A, c, b)), where D"= 
D- -El E is the 
k 
unit matrix in RnXn. F'rom the assumption p(w) # f 
oo it follows 
that A(A, b) is nonempty. Then from (13.7) we can deduce that 
A(A, b) is unbounded. For every k ,  by (13.7) we have 
Hence, for any x belonging to A(A, b) and for any t > 0, we have 
x + tz E A(A, b) and 
1 
f (X + tz, C, D ~ )  
= -(x + ~ z ) ~ D ~ ( x  
+ tz) + cT(x + tz) -+ -00 
2 
as t -+ oo. This implies that, for all k ,  Sol(Dk, A, c, b) = 8 and 
'p(Dk, A, c, b) = -00. We have arrived at a contradiction, because 
'p(-) is continuous at w and 'p(w) # f 
oo. We have proved that (b) 
holds true. 
Suficiency: Suppose that (a), (b) are satisfied and 
is a sequence converging to w. By Lemma 13.1, assumption (a) 
implies the existence of a positive integer ko such that A(Ak, bk) # 8 
for every k 2 ko. From assumption (b) it follows that the set G 
defined by (13.3) is open. Hence there exists a positive integer 
kl 2 ko such that Sol(Dk, Ak, 0,O) = (0) for every k 2 kl. By 
Lemma 13.3, Sol(Df A', c" bk) # 8 for every k 2 kl. Therefore, 
for every k 2 kl there exists xk E En satisfying 

228 
13. Continuity of the Optimal Value Function 
A%z" 2 bk. 
(13.9) 
Since cp(w) # f 
co, the Frank-Wolfe Theorem shows that 
Taking any xO E Sol(D, A, c, b), we have 
By Lemma 13.1, there exists a sequence {y" in Rn converging to 
xO and 
2 bk 
for every k > kl. 
(13.12) 
From (13.12) it follows that yk E A(Ak, bk) for k > kl. So 
1 k T  k k 
k
T
 k 
d D k ,  Ak, ck, bk) 5 5(Y ) D Y + (c ) Y . 
(13.13) 
From (13.13) it follows that 
k
k
k
 
~ i r n s u ~ c p ( ~ ~ , ~  
, c  , b  ) 
k+oo 
Therefore, taking account of (13.10) and (13.11), we get 
limsup cp(Dk, Ak, c" bk) < p(D, A, c, b). 
(13.14) 
k+oo 
We now claim that the sequence {x", 
k 2 kl, is bounded. Indeed, 
if it is unbounded then, by taking a subsequence if necessary, we can 
assume that llxklI + t 
as k + t 
and Jlxkll # 0 for all k > kl. Then 
the sequence { l l ~ ~ l l - ~ x ~ ) ,  
k > kl, has a convergent subsequence. 
Without loss of generality we can assume that llxk \l-lxk -+ 
2, II2II = 
1. From (13.9) we have 
Letting k + co, we obtain 

13.1 Continuity of the Optimal Value Function 
229 
By (13.8) and (13.13), 
Dividing both sides of (13.16) by llxk112 and taking limits as k + co, 
we get 
f T ~ f  
5 0. 
(13.17) 
By (13.15) and (13.17), we have Sol(D, A, 0,O) # (0). This contra- 
dicts (b). We have thus shown that the sequence {xk}, k 2 kl, 
is bounded; hence it has a convergent sequence. There is no loss of 
generality in assuming that xk -+ 2 E Rn. By (13.8) and (13.9), 
1 
lim c p ( ~ ~ ,  
A" ck, b" 
= - z T ~ 2  + cT2 = f (2, C ,  D ) ,  
(13.18) 
k-+w 
2 
A2 > b. 
(13.19) 
&om (13.19) it follows that 2 E A ( A ,  b). Hence 
Therefore, by (l3.18), 
lim c p ( ~ "  
c" bk) 2 cp(D, A, c, b). 
k'ca 
(13.20) 
Combining (13.14) with (13.20) gives 
lim c p ( ~ ~ ,  ck, bk) = cp(D, A, c, b). 
k
'
 
03 
This shows that cp is continuous at ( D ,  A, c, b). The proof is com- 
plete. 
0 
Example 13.1. Consider the problem QP(D, A, c, b) where m = 
3, n = 2, 
1
0
 
D =  [a :I, 
A =  lo 
, c = ( ; ) ,  
b= (g). 
1 -2 
It can be verified that cp(D, A, c, b) = 0, Sol(D, A, 0,O) = (01, and 
the system Ax 2 b is regular. By Theorem 13.1, cp is continuous at 
( D ,  A, c, b). 
Example 13.2. Consider the problem QP(D, A, c, b) where m = 
n = 1, D = [ I ] ,  A = [O], c = ( I ) ,  b = (0). It can be shown that 

230 
13. Continuity of the Optimal Value Function 
cp(D, A, c, b) = 0, and the system Ax 2 b is irregular. By Theorem 
13.1, cp is not continuous at (D, A, c, b). 
Remark 13.2. If A(A, b) is nonempty then A(A, 0) is the reces- 
sion cone of A(A, b). By definition, Sol(D, A, 0,O) is the solution 
set of the problem QP(D, A, 0,O). So, verifying the assumption 
Sol(D, A, 0,O) = (0) is equivalent to solving one special QP prob- 
lem. 
Now we study the continuity of the optimal value function cp(.) 
at a point where its value is infinity. Let a E {+m, -m) and 
p(D, A, c, b) = a. We say that cp(.) is continuous at (Dl A, c, b) if, 
for every sequence {(D', A< ck, by) c R converging to (D, A, c, b), 
The next theorem characterizes the continuity of cp at a point 
w = (Dl A, c, b) where cp has the value -m. 
Theorem 13.2. Let(D,A,c,b) E R andcp(D,A,c,b) = -m. 
Then, the optimal value function cp is continuous at (D, A, c, b) if 
and only if the system Ax 2 b is regular. 
Proof. Suppose that cp(D, A, c, d) = -m and cp is continuous 
at (Dl A, c, b) but the system Ax 2 b is irregular. By Remark 
13.1, there exists a sequence {(A" bk)) in RmXn x Rm converging to 
(A, b) such that, for every k, the system Akx 2 b%as no solutions. 
Since A(A< bk) = 0, cp(D, A" c, by = +m for every k. Therefore, 
lim cp(D, 
c, bk) = +m. On the other hand, since cp is continuous 
k + w  
at (D, A, c, b) and since 
we obtain 
+m = lim cp(D, A'", c, b" 
= =(Dl A, c, b) = -m, 
k--03 
a contradiction. Thus Ax 2 b must be a regular system. 
Conversely, suppose that cp(D, A, c, d) = -m and the system 
Ax 2 b is regular. Let {(Dk, Ak, ck, bk)) c R be a sequence converg- 
ing to (Dl A, c, b). By the assumption, cp(D, A, c, b) = -m, hence 
there is a sequence {xi) in Rn such that Axi 2 b and 

13.1 Continuity of the Optimal Value Function 
231 
By Lemma 13.1, for every i, there exists a sequence {yik} in Rn 
with the property that 
A~~~~ 2 bb", 
lim yik = xi. 
k+03 
From (13.23) and (13.24) it follows that 
1 
i T  
lim sup cp(Db", cb", b y  ) -(x ) Dxi + cTxi. 
2 
(13.25) 
b"-+co 
Combining (13.25) with (13.21), we obtain 
This implies that 
lim cp(Dkl A', cb", bb") = -m = p(D, A, C ,  b). 
k+cG 
Thus cp is continuous at (Dl A, c, b). The proof is complete. 
0 
The following theorem characterizes the continuity of cp at a 
point w = ( D ,  A, c, b) where cp has the value +m. 
Theorem 13.3. Let (D,A,c,b) E f2 and cp(D,A,c,b) = f m .  
Then, the optimal value function cp is continuous at (Dl A,c, b) if 
and only if Sol(D, A, 0,O) = (0). 
Proof. Suppose that cp(D, A, c, b) = +m and that cp is continuous 
at ( D ,  A, c, b) but Sol(D, A, 0,O) # (0). Then there exists a nonzero 
vector 3 E Rn such that 
Let 3 = ( z ~ ,  
. . . ,3,). We define a matrix M E RmXn by setting 
M = [mij], 
where 
Let 
1 
1 
Ic 
k
-
~
+
i
~
,
 
D ~ = D - - E ,  A - 

232 
13. Continuity of the Optimal Value Function 
where E is the unit matrix in RnXn. Consider the sequence 
A simple computation shows that 
Ak3 > 0 for every k. 
By Lemma 13.2, for every k the system A% > b is regular. Let z 
be a solution of the system Akx > b. Since A% > 0 and 
for every k, we have 
1 
T
k
 
f(z + t ? , ~ ,  
Dk) = -(z + t3) D (Z + t3) +cT(z +t3) --+ -m 
2 
as t + oo. Since z + t~ E n(Ak, b) for every k and for every 
t > 0, Sol(Dk, Ak, c, b) = 0. We have arrived at a contradiction, 
because cp is continuous at (D, A, c, b) and 
-oo = lim c p ( ~ "  Ak, c, b) = cp(D, A, c, b) = +oo. 
k-O0 
Conversely, assume that Sol(D, A, 0,O) = (0) and 
is a sequence converging to (Dl A, c, b). We shall show that 
lim inf cp(Dk , A', ck, bk) = +m. 
k-+m 
Suppose that lim inf cp(Dk, Ak, ck, bk) < +m. Without loss of gen- 
k'co 
erality we can assume that 
lim inf cp(Dk, Ak, ck, bk) = lim c p ( ~ ~ ,  
Ak, ck, bk) < +m. 
k+Cw 
k-O0 
Then, there exist a positive integer kl and a constant y 2 0 such 
that 
cp(D" Ak, ck, bk) l 
y 
for every k > kl. As Sol(D, A, 0,O) = {0), we can assume that there 
is an positive integer k2 such that Sol(Dk, Ak, 0,O) = (0) for every 
k > k2. By Lemma 13.3 we can assume that 

13.2 Semicontinuity of the Optimal Value Function 
233 
for every k 2 k2. Hence there exists a sequence {x" 
in Rn such 
that, for every k 2 k2, we have 
We now prove that {xk) is a bounded sequence. Suppose, contrary 
to our claim, that the sequence {xk) is unbounded. Without loss of 
generality we can assume that llxkll # 0 for every k and that IIx"I 4 
oo as k -+ oo. Then the sequence {Ilx"l-'x" 
has a convergent 
subsequence. We can assume that the sequence itself converges to 
a point xO E Rn with llxOll = 1. By (13.27) we have 
hence 
Ax0 2 0. 
(13.28) 
By dividing both sides of the inequality in (13.26) by 11xkl12 and 
taking the limits as k 4 oo, we get 
From (13.28) and (13.29) we deduce that Sol(D, A, 0,O) # (0). This 
contradicts our assumption. Thus the sequence {xk) is bounded, 
and it has a convergent subsequence. Without loss of generality we 
can assume that {xk) converges to 3 E Rn. Letting k -+ oo, from 
(13.27) we obtain 
Az > b. 
This means that A(A, b) # 0. We have arrived at a contradiction 
because cp(D, A, c, b) = +oo. The proof is complete. 
From Theorems 13.1-13.3 it follows that conditions (a), (b) in 
Theorem 13.1 are sufficient for the function cp(.) to be continuous 
at the given parameter value (D, A, c, b). 
13.2 Semicontinuity of the Optimal Va- 
lue Function 
As it has been shown in the preceding section, continuity of the op- 
timal value function holds under a special set of conditions. In some 

234 
13. Continuity of the Optimal Value Function 
situations, only the upper semicontinuity or the lower semicontinu- 
ity of that function is required. So we wish to have simple sufficient 
conditions for the upper semicontinuity and the lower semicontinu- 
ity of cp at a given point. Such conditions are given in this section. 
A sufficient condition for the upper semicontinuity of the func- 
tion cp(.) at a given parameter value is given in the following theo- 
rem. 
Theorem 13.4. Let (Dl A, c, b) E R. If the system Ax > b is 
regular then p(.) is upper semicontinuous at (Dl A, c, b). 
Proof. As Ax > b is regular, we have A(A, b) # 8. Hence 
Let {(Dk, A', c" bk)) c R be a sequence converging to (Dl A, c, b). 
Since cp(D, A, c, b) < +cm, there is a sequence {xi) in Rn such that 
Axi > b and 
1 
f (xi, c, D) = - ( x " ~  
Dsi + cTxi 4 
cp(D, A, c, b) 
as i 4 cm. 
2 
By Lemma 13.1 and by the regularity of the system Ax 2 b, for 
each i one can find a sequence {yik} in Rn such that Akyik 2 b h n d  
lim y" = xz 
k-+w 
Since yik E A(Ak, by, 
This implies that 
lim sup cp(Dk, A" ck, bk) L f (xi, c, D). 
k+w 
Taking limits in the last inequality as i 4 cm, we obtain 
limsupcp(~" 
ck, bk) 6 cp(D, A, c, b). 
k + w  
We have proved that p(.) is upper semicontinuous at (D, A, c, b). 
0 
The next example shows that the regularity condition in The- 
orem 13.4 does not guarantee the lower semicontinuity of cp at 
(D, A, c, b). 

13.2 Semicontinuity of the Optimal Value Function 
235 
Example 13.3. Consider the problem QP(D, A, c, b) where m = 
n = 1, D = [0], A = [ I ] ,  c = (0), b = (0). It is clear that 
Ax > Oisregular, Sol(D,A,c,b) = A(A,b) = { x  : x > 01, 
and cp(D, A, c, b) = 0. Consider the sequence {(D" A, c, b)}, where 
. We have cp(D"A,c,b) = -00 for every k ,  so 
liminf cp(~'",A, 
c, b) < cp(D, A, c, b). 
k'co 
Thus cp is not lower semicontinuous at ( D ,  A, c, b). 
The following example is designed to show that the regularity 
condition in Theorem 13.4 is sufficient but not necessary for the 
upper semicontinuity of cp at ( D ,  A, c, b). 
Example 13.4. Choose a matrix A E Rmxn and a vector b E Rm 
such that A ( A ,  b) = 0 (then the system Ax 2 b is irregular). Fix an 
arbitrary matrix D E REXn and an arbitrary vector c E Rn. Since 
cp(D, A, c, b) = +oo, for any sequence {(D" A', ck, bk)} converging 
to ( D ,  A, c, b), we have 
lirn sup cp(~5 
A', ck, b y  5 p(D, A, c, b). 
k+co 
Thus cp is upper semicontinuous at ( D ,  A, c, b). 
A sufficient condition for the lower semicontinuity of the function 
cp(.) is given in the following theorem. 
Theorem 13.5. Let ( D ,  A, c, b) E 52. If Sol(D, A, 0,O) = (0) then 
c p ( - )  is lower semicontinuous at ( D ,  A, c, b). 
Proof. Assume that Sol(D, A, 0,O) = (0). Let 
be a sequence converging to ( D ,  A, c, b). We claim that 
lirn inf cp(~5 
A', c" bk) > p(D, A, C ,  b). 
k+Cc 
Indeed, suppose that 
lim inf c p ( ~ "  A', ck, b" 
< <(D, A, c, b). 
k+x 
Without loss of generality we can assume that 
liminf c p ( ~ " ~ ~ , c " b ~ )  
= lim c p ( ~ ~ , ~ ~ , c ~ ,  
bk). 
k+cc 
k+co 

236 
13. Continuity of the Optimal Value Function 
Then there exist an index kl and a real number y such that y < 
d D ,  A, c, b) and 
y(Dk, 
ck, bk) 5 y for every k > kl. 
Since P(D{ A', ck, bk) < +w, we must have A(Ak, bk) # 0 for every 
k 2 kl. Since Sol(D, A, 0,O) = {0}, there exists an integer k2 2 kl 
such that 
SO~(D]", 
A'", 0,O) = (0) 
for every k 2 k2. As A(A5 by # 0, by Lemma 13.3 we have 
Sol(Dkl A', c< bk) # 0 for every k 2 k2. Hence there exists a se- 
quence {xk) such that we have A%' 2 bqor every k 2 k2, and 
The sequence 1 x 7  must be bounded. Indeed, if {x" is unbounded 
then, without loss of generality, we can assume that IIxkII # 0 for 
every k and Ilxkll t 
00 as k -' w .  Then the sequence {IlxkII-'xk} 
has a convergent subsequence. We can assume that this sequence 
itself converges to a vector v E Rn with llvll = 1. Since 
xk - 
bk 
>- 
for every k > 162, 
IIxkll - Ilxk ll 
we have Av > 0. On the other hand, since for each k 2 k2 it holds 
we deduce that 
vTDv I 0. 
Combining all the above we get v E Sol(D, A, 0,O) \ (01, a contra- 
diction. We have thus proved that the sequence {xk} is bounded. 
Without loss of generality we can assume that xk -+ 3 E Rn. Since 
Akxk > bk for every k, we get AZ > b. Since 
we have 
f(Z, C, D) = LTD~ 
+ cTa 5 7. 
2 

13.4 Commentaries 
237 
As y < cp(D, A, c, b), we see that f (3, 
c, D) < p(D, A, c, b). This is 
an absurd because 3 E A(A, b). We have thus proved that cp(.) is 
lower semicontinuous at ( D ,  A, c, b) . 
0 
The next example shows that the condition Sol(D, A, 0,O) = (0) 
in Theorem 13.5 does not guarantee the upper semicontinuity of cp 
at ( D ,  A, c, b). 
Example 13.5. Consider the problem QP(D, A, c, b) where m = 
n = 1, D = [I], A = [O], c = (O),b = (0). It is clear that 
Sol(D, A, 0,O) = (0). Consider the sequence { ( D ,  A, c, bk)), where 
1 
bk = (-1). We have cp(D, A, c, b) = 0 and cp(D, A, c, bk) = +m for 
k 
all k (because A ( A ,  bk) = 0 for all k). Therefore 
lim sup cp(D, A, c, bk) = +m > 0 = cp(D, A, c, b). 
k+w 
Thus cp is not upper semicontinuous at ( D ,  A, c, b). 
The condition Sol(D, A, 0,O) = (0) in Theorem 13.5 is sufficient 
but not necessary for the lower semicontinuity of cp at ( D ,  A, c, b). 
Example 13.6. Consider the problem QP(D, A, c, b) where m = 
n = 1, D = [ - I ] ,  A = [ I ] ,  c = ( l ) , b  = (0). It is clear that 
Sol(D, A, 0,O) = 0. Since p(D,A,c, b) = -m, for any sequence 
{ ( D k ,  Ak, ck, bk)) converging to ( D ,  A, c, b), we have 
k
k
k
 
lim inf c p ( ~ ' " ,  A , c , b ) 2 p(D, A ,  c, b). 
k+co 
Thus cp is lower semicontinuous at ( D l  A, c, b). 
13.3 Commentaries 
The results presented in this chapter are due to Tam (2002). 
Lemma 13.1 is a well-known fact (see, for example, Robinson 
(1975), Theorem 1, and Bank et al. (1982), Theorem 3.1.5). 
In Best and Chakravarti (1990) and Best and Ding (1995) the 
authors have considered convex quadratic programming problems 
and obtained some results on the continuity and differentiability of 
the optimal value function of the problem as a function of a parame- 
ter specifying the magnitude of the perturbation. In Auslender and 
Coutat (1996), similar questions for the case of linear-quadratic pro- 
gramming problems were investigated. Continuity and Lipschitzian 
properties of the function p(D, A, ., .) (the matrices D and A are 

238 
13. Continuity of the Optimal Value Function 
fixed) were studied in Bank et al. (1982), Bank and Hansel (1984), 
Klatte (1985), Rockafellar and Wets (1998). 
We have considered indefinite QP problems and obtained several 
results on the continuity, the upper and lower semicontinuity of the 
optimal value function cp at a given point w. In comparison with the 
preceding results of Best and Chakravarti (1990), Best and Ding 
(1995), the advantage here is that the quadratic objective function 
is allowed to be indefinite. 
The obtained results can be used for analyzing algorithms for 
solving the indefinite QP problems. 

Chapter 14 
Directional Differentiability 
of the Optimal Value 
Function 
In this chapter we establish an explicit formula for computing the 
directional derivative of the optimal value function in a general para- 
metric QP programming problem. We will consider one illustrative 
example to see how the formula works for concrete QP problems. 
In Section 14.1 we prove several lemmas. In Section 14.2 we 
introduce condition (G) and describe a general situation where (G) 
holds. Section 14.3 is devoted to proving the above-mentioned for- 
mula for computing the directional derivative of the optimal value 
function in indefinite QP problems. In the same section, the ob- 
tained result is compared with the corresponding results on differen- 
tial stability in nonlinear programming of Auslender and Cominetti 
(1990), and Minchenko and Sakolchik (1996). 
14.1 Lemmas 
Consider the general quadratic programming problem (13.1) which 
is abbreviated to QP(D, A, c, b). The problem depends on the pa- 
rameter w = (D, A, c, b) € R, where 
As in Chapter 13, the solution set of this problem will be denoted 
by Sol(D, A, c, b), and its optimal value function cp : R ---+ 
is 

240 
14. Differentiability of the Optimal Value Function 
given by 
p(w) = inf{ f ( x ,  c, D )  : x E A(A, b)}. 
The proofs of Theorem 14.1 and Theorem 14.2, the main results 
in this chapter, are based on some lemmas established in the present 
section. 
Let w = ( D l  A, c, b) and w0 = (Do, A', cO, bO) be two elements of 
R. Denote 
w + two = ( D  + tDO, A + tAO, c + tcO, b + tb0), 
cp+(w; wO) = lim sup cp(w + two) - c p ( 4  
t 
1 
t10 
If cp+(w; wO) = cp-(w; wO) then the optimal value function cp(.) is 
directionally differentiable at w in direction w0 (see Definition 1.8). 
The common value is denoted by cpl(w; wO) which is the directional 
derivative of cp at w in direction wO. We have 
For every 2 E A ( A ,  b), we set 
and define 
F ( 2 ,  w, wO) = {v E Rn : 3& > 0 such that 
2 + t v  E A ( A  + tAO,b+ tbo) for every t E [O,e]}, 
The following lemma is originated from Seeger (1988), Auslender 
and Cominetti (1990). 
Lemma 14.1. If the system A x  2 b is regular, then 
for every Z E A(A, b). 

14.1 Lemmas 
24 1 
Proof. Let 3 E A(A, b), I = a(%) = {i : (Az)~ = bi). If I = 0 
then A5 > b. Thus, for every v E Rn there is an E = ~ ( v )  
> 0 such 
that for each t E [0, E] we have 
The above inequality is equivalent to the following one 
(A + tAO)(z + tv) > b + tbO. 
Hence 3 + tv E A(A + tAO, b + tbo) for each t E [0, E]. This implies 
that F(3, w, wO) = Rn. By definition, in this case we also have 
R(5, w, wO) = Rn. Therefore 
and we have (14.1). Consider the case where I # 0. We first show 
that 
i n t ~ ( 3 ,  
w, wO) # 0. 
Since Ax > b is a regular system, there exists xO E Rn such that 
Ax0 > b. Then we have 
ArxO > bI. 
As A13 = bI and AIxO > bI, we have 
Putting 6 = xO - 3, we get 
By Lemma 13.2, the inequality system (of the unknown v) 
is regular, hence there exists .ii E Rn such that 
This proves that ii E intR(3, w, wO), therefore intR(3, w, wO) # 0. 
We now prove that 

242 
14. Differentiability of the Optimal Value Function 
Suppose that v E int R(Z, w, wO). We have 
Hence there is EI > 0 such that for each t E [0, E ~ ]  
one has 
Then, for each t E [0, E ~ ] ,  
As Ai3 > bi for every i E (1, . . . , m) \ I, one can find ~2 > 0 such 
that for each t E [0, E ~ ]  
it holds 
for every i E (1, . . . , m) \ I. Let E := min{E1, ~ 2 ) .  It follows from 
(14.2) and (14.3) that 
for every t E [0, el. This implies that 
for every t E [0, el. Hence v E F(z, w, wO), and we have 
Finally, we shall prove that 
Take any v E F (z, w, wO). By definition, there is an E > 0 such that 
for each t E [0, E] we have 
Consequently, 
AIZ + t(AIv + A ~ Z  
- by + tAO,v) > bI 
for every t E [O, E]. As A15 = bI, we have 

14.1 Lemmas 
for each t E [0, E]. Hence, for every t E (0, el, 
Letting t -+ 0, we obtain 
This shows that v E R(z, w, wO), hence F (z, w, wO) C R(z, w, wO). 
We have thus shown that the inclusions in (14.1) are valid. The 
proof is complete. 
If 3 E Sol(D, A, c, b), then there exists a Lagrange multiplier 
X E Rm such that 
The set of all the Lagrange multipliers corresponding to Z is denoted 
by A(?, w), where w = (D, A, C, b). 
The forthcoming result is well known in nonlinear programming 
(see, for instance, Gauvin (1977) and Dien (1985)). For the sake of 
completeness, we give a proof for the case of QP problems. 
Lemma 14.2. If the system Ax 2 b is regular, then for every 
3 E Sol(D, A, c, b) the set A(3, w) is compact. 
Proof. Let w = (D, A, c, b). Suppose that there is Z E Sol(D, A, c, b) 
such that A(%, w) is noncompact. Then there exists a sequence {Ak} 
in Rm such that IIAkII # 0, 
for every k ,  and 11 Xk 11 I 
cm as k -+ cm. Without loss of generality we 
can assume that {IIXklI~lAk} converges to 3 with llXll = 1. Dividing 
each expression in (14.5)-(14.7) by IIXklI and taking the limits as 
k --+ cm, we get 
Since X T ~ z  
= z ~ ( A ~ X )  
= 0, from (14.8) it follows that 

244 
14. Differentiability of the Optimal Value Function 
For every t > 0, we set bt = b +  t i .  Since XTX = llX1I2 = 1, 
Consequently, for every t > 0, X is a solution of the following system 
Hence, for every t > 0, the system Ax 2 bt has no solutions (see 
Cottle et al. (1992), Theorem 2.7.8). Since A(A, b) # 0 and 
llbt - bll = t + 0 as t + 0, the system Ax 2 b is irregular (see 
Mangasarian (l98O), Lemma 2. l), contrary to our assumption. The 
proof is complete. 
Lemma 14.3 (cf. Auslender and Cominetti (1990), Lemma 2). If 
the system Ax 2 b is regular and 3 E Sol(D, A, c, b) then 
inf 
(017: + C ) ~ V  = max (bO - A O Z ) ~ X ,  
(14.9) 
v~R(%,w,wO) 
X€A(%,w) 
where A(z, w) stands for the Lagrange multiplier set corresponding 
to 3. 
Proof. Let Z E Sol(D,A,c, b). If I = a(?) = {i : (AZ)i = bi) is 
empty then, by definition, R(z, w, wO) = Rn. As Z t. Sol(D, A, c, b) 
and AZ > b, Theorem 3.3 applied to 3 shows that (DZ + C ) ~ V  = 0 
for every v E Rn. Then we have 
inf 
(Dz + C ) ~ V  = 0. 
v € R ( %  ,w,wO) 
Again, by the just cited first-order necessary optimality condition, 
for every Z we have A(3,w) # 0. Since A3 > b, A(Z,w) = (0). 
Therefore 
max (bO - AOZ)~X 
= 0. 
~ € A ( % , w )  
Thus, in the case I = 8 the assertion of the lemma is valid. We now 
consider the case where I = a(Z) = {i : (Az)~ = bi) # 0. We have 
inf 
(Dz + C ) ~ V  = inf{(DZ + C ) ~ V  : v E Rn, AIv 2 by - AYZ). 
v€R(%,w,wO) 
Consider a pair of dual linear programs 
( P )  
(DZ + C ) ~ V  -+ min 
v E Rn, AIv 2 by - AYZ 

14.1 Lemmas 
and 
where 111 is the number of the elements of I .  From the defini- 
tion of A(z, w) it follows that if XI is a feasible point of (PI) then 
(XI, 0 J) E A(?, w), where J = (1, . . , m) \ I. Conversely, if X = 
(XI, X J) E A(Z, w) then X J = OJ. The regularity of the system 
Ax > b and Lemma 14.2 imply that A(z, w) is nonempty and com- 
pact. Therefore, by the above observation, the feasible domain of 
( P I )  is nonempty and compact. By the duality theorem in linear 
programming (see Theorem 1. lO(iv)) , the optimal values of (P) and 
(P') are both finite and equal to each other. Therefore 
Formula (14.9) is proved. 
Lemma 14.4. Suppose that wk = (Dk, A" c" bk), k E EN, is a 
sequence in R converging to w = (D, A, c, b), {xk) is a sequence in 
Rn such that xk E Sol(D5 Ak, ck, bk) for every k. If the system Ax 2 
b is regular and Sol(D, A, 0,O) = (0) then there exists a subsequence 
{xki) of {x" 
such that {x"} converges to Z E Sol(D, A, c, b) as 
i + 00. 
Proof. Suppose that Ax > b is a regular system and Sol(D, A, 0,O) = 
(0). We have 
2 bk. 
(14.10) 
Take x E A(A, b). Then there exists a sequence {y" in Rn tending 
to x such that 
> bk 
for every k 
(14.11) 
(see Lemma 13.1). The inequality in (14.11) shows that y" 
A(Ak, bk). Since xk E Sol(Dk, A', ck, bk), 
We claim that the sequence {xk) is bounded. Suppose for a while 
that {xk) is unbounded. Then, without loss of generality, we may 

246 
14. Differentiability of the Optimal Value Function 
assume that IIxk[I I oo as k I 
oo and IIxkll # 0 for every k. So 
the sequence {llxk ll-lxk} has a convergent subsequence. We may 
assume that the sequence { \ ~ x ~ I ~ - ~ x ~ }  itself converges to i E Rn 
with Ilill = 1. From (14.10) we have 
Letting k I 
oo, we obtain 
Dividing both sides of (14.12) by llxk112 and taking limit as k -+ oo, 
we obtain 
i T D i  L: 0. 
(14.14) 
Combining (14.13) and (l4.l4), we have Sol(D, A, 0,O) # {O}, con- 
trary to our assumptions. Thus the sequence {xk} is bounded and 
it has a convergent subsequence, say, {xki}. Suppose that {xki} 
converges to 3. From (14.12) we have 
From (14.10) we have 
AkiXki 2 bki. 
Taking limits in (14.15) and (14.16) as i + oo, we obtain 
As x E A(A, b) is arbitrarily chosen, (14.17) and (14.18) yield 3 E 
Sol(D, A, c, b). The lemma is proved. 
14.2 Condition (G) 
Let w = (D,A, C, b) E S2 be a given parameter value and w0 = 
(Do, AO, cO, bO) E 0 be a given direction. Consider the following 
condition which we call condition (G): 
For every sequence {tk}, tk J. 0, for every sequence {xk}, 
xk ---t Z t. Sol(D, A, c, b), 

14.2 Condition (G) 
247 
where x" 
Sol(w + t b O )  for each k ,  the following inequality is 
satis,fied 
(xk - ZlTD(xk - Z) 
lim inf 
t 
2 0. 
k + w  
Remark 14.1. If D is a positive semidefinite matrix, then con- 
dition (G) holds. Indeed, if D is positive semidefinite then (xk - 
z)~D(x'" - 2) 2 0, hence the inequality in (G) is satisfied. 
Remark 14.2. If the system Ax 2 b is regular then (G) is weaker 
than the condition saying that the (SOSC), property introduced 
in Auslender and Cominetti (1990) (applied to QP problems) holds 
at every Z E Sol(D,A,c, b). It is interesting to note that if the 
system Ax 2 b is regular then (G) is also weaker than the condition 
(H3) introduced by Minchenko and Sakolchik (1996) (applied to QP 
problems). There exist many QP problems where the conditions 
(SOSC), and (H3) do not hold but condition (G) is satisfied. A 
detailed comparison of our results with the ones in Auslender and 
Cominetti (1990) and Minchenko and Sakolchik (1996) will be given 
in Section 14.3. 
Now we describe a general situation where (G) is fulfilled. 
Theorem 14.1. If Ax 2 b is a regular system and every solution 
Z E Sol(D,A,c, b) is a locally unique solution of problem (13.1), 
then condition (G) is satisfied. 
Proof. From the statement of (G) it is obvious that the condi- 
tion is satisfied if Sol(D,A,c, b) = 0. Consider the case where 
Sol(D, A,c, b) # 0. For any given I(: E Sol(D,A, c, b) we set I = 
a(%) 
= {i :  AT)^ = bi} and 
Fz = {v E Rn : (Av)~ 2 0 for every i E I}. 
For every Z E Sol(D, A, c, b), Theorem 3.7 shows that the following 
conditions are equivalent: 
(a) 3 is a locally unique solution of problem (13.1), 
(b) for every v E F* \ {0}, if (017: + C ) ~ V  = 0 then vTDv > 0. 
We shall use the above equivalence to prove our theorem. Sup- 
pose, contrary to our claim, that (G) does not hold. Then there 
exist a sequence {tk}, tk 
0, and a sequence {x", 
xk --+ 
3 E 

248 
14. Differentiability of the Optimal Value Function 
Sol(D, A, c, b), xk E Sol(D + t q O ,  A + tkAO, c + t%O, b + tkbO) for 
every k, such that 
(xk - Z)~D(X" 3) 
lim 
t" 
< 0. 
k-+m 
By taking a subsequence if necessary, we can assume that 
(xk - 3 ) T ~ ( x k  
- 3) < 0, 
llxk - 311 # 0 for every k, 
(14.20) 
and 
lim llxk - 311 
t" 
= +cm. 
k+m 
Then the sequence {llxk - 3Il-'(x" 
3)) has a convergent subse- 
quence. Without loss of generality, we may assume that {llx" 
~11-~(x" 3)) converges to some v E Rn with llvll = 1. Divid- 
ing both sides of the inequality in (14.20) by llxk - -[I2 
and letting 
k --t GO, we get 
vTDv 5 0. 
(14.22) 
Since xk E Sol(D + tkDO, A + tkAO, c + tkcO, b + t%O), we have 
where I = {i : (Az)~ = bi). Since bI = A13, 
Dividing both sides of the inequality above by IIxk - 311, taking 
account of (14.21) and letting k -t cm, we obtain 
Now we are going to show that (Dz + C ) ~ V  = 0. We have 

14.2 Condition (G) 
249 
Since Ax 2 b is a regular system, by Lemma 14.1 we have 
Take G E F (2, w, wO). Then, for every small enough positive number 
tk, we have 
z + tka c E(A + t k ~ O ,  
b + tQO). 
Hence, for small enough t< we have 
From (14.24) and (14.25), for k large enough, we have 
Dividing both sides of (14.26) by Ilx" 
311, letting k -+ oo and 
taking account of (14.21), we get 
As 5 is a solution of (13.1) and (14.23) is valid, we have (Dz+c)'v > 
0 (see Theorem 3.5). Combining this with (14.27), we conclude that 
Properties (14.22), (14.23) and (14.28) show that (b) does not hold. 
Thus 5 cannot be a locally unique solution of (13.1), a contrary to 
our assumptions. The proof is complete. 

250 
14. Differentiability of the Optimal Value Function 
14.3 Directional Differentiability of cp(.) 
The following theorem describes a sufficient condition for p(.) to be 
directionally differentiable and gives an explicit formula for com- 
puting the directional derivative of ip(.). 
Theorem 14.2. Let w = (D, A, c, b) E R be a given point and w0 = 
(Do, AO, cO, bO) E R be a given direction. If (G) and the following 
two conditions 
(i) the system Ax 2 b is regular, 
(ii) Sol(D, A, 0,O) = (0) 
are satisfied, then the optimal value function ip is directionally dif- 
ferentiable at w = (Dl A, c, b) in direction w0 = (Do, A', cO, bO), and 
0 
y~'(w;w)= 
inf 
max 
- Z ~ D O Z  + ( c O ) ~ Z  + (bO - A O Z ) ~ X  , 
ZESO~(D,A,~,~) 
XENfw) [' 
2 
1 
(14.29) 
where A(z, w) is the Lagrange multipliers set corresponding to the 
solution Z E Sol(D, A, c, b). 
Proof. 
1) Suppose that the conditions (i) and (ii) are satisfied. Accord- 
ing to Lemma 13.3, Sol(D, A, c, b) is a nonempty compact set. Take 
any 3 E Sol(D, A, c, b). By (i) and Lemma 14.1, F (3, w, wo) # a). 
Take any v E F(z, w, wO). For t > 0 small enough, we have 
hence 
1 
p(w + two) - ip(w) < ;(z + ~ v ) ~ ( D  
+ ~D')(z + tv) 
L 
+(c+ ~ c O ) ~ ( Z  
+ tv) - (lZTDZ + cTZ) 
Multiplying the above double inequality by t-' and taking limsup 
as t + O+, we obtain 

14.3 Directional Differentiability of q( . ) 
This inequality is valid for any v E F (3, w, wO) and any 
Z x: Sol(D, A, c, b). 
Consequently, 
cp+(w; wO) 5 
inf 
+ ( c O ) ~ ?  + (Dz + C ) ~ V  . 
%€SO~(D,A,~,~) 
1 
By Lemmas 14.2 and 14.3, 
Hence 
(14.30) 
2) Let {tk} be a sequence of real numbers such that tk J 0 and 
0 
cp-(w;w ) = lim q(w + tkwO) - cp(w) 
tk 
k+oo 
Due to the assumptions (i) and (ii), taking account of Lemmas 13.1 
and 13.3 and the openness of the set G defined in (13.3) we can 
assume that 
Sol(w + tkwO) # 0 for every k. 
Let {x" be a sequence in Rn such that xk E Sol(w + tkWO) for every 
k. By Lemma 14.4, without loss of generality we can assume that 
xk -+2 E Sol(D,A,c,b) as k - t  m. We have 
Take X E A(?, w). As 
and 

252 
14. Differentiability of the Optimal Value Function 
from (14.31) we get 
1 
(p(w + tkwO) - V(W) 2 g ( ~ k ) T ( ~  
+ tkD0)~' 
1 AT 
+(c + t%O)Txk - -x D i  - cTi 
2 
+XT(Ai - b) - [(A + tkAo)xk - b - tkb0ITX 
1 
Since X E A(i, w), D i  - ATX + c = 0. Then we have 
Multiplying both sides of this inequality by (ty-l, taking lim inf as 
Ic + oo and using condition (G), we obtain 
As X E A(i, w) can be chosen arbitrarily, we conclude that 
Combining this with (14.30), we have 
and, therefore, 
1 
(p'(w; wO) = 
inf 
max [-Z~D'? + ( C ' ) ~ ?  + (bO - A'?)~x]. 
z&l(w) AENf F) 2 
The proof is complete. 
0 
We now apply Theorem 14.2 to a concrete example. 
Example 14.1. Let n = 2, m = 3, 

14.3 Directional Differentiability of cp(.) 
T 
(bO) = (0, -1, 0), c = 
w = (D, A, C, b), 
WO = (DO, AO, cO, bO). 
It is easy to verify that Ax 2 b is a regular system, Sol(D, A, 0,O) = 
(0) and 
for every t 2 0. For Z = (31, 32) E Sol(w), we have 
Suppose that xk = (xf, x;) E Sol(w + tkwO) and the sequence {xk) 
converges to 3 = (21, 3 2 )  E Sol(w). We have xf = xt and Z1 = 32. 
Then 
(xk - qTD(xk - Z) - (xf - Z1)2 - (11;; - Z2)2 
- 
tk 
t 
= 0, 
hence condition (G) is satisfied. By Theorem 14.2, 
T 
cp'(w; wO) = inf - 
1-T 0- 
max ((5x 
D x + ( C ~ ) ~ Z )  
+ P) A 
xtSol(u) XtA(5,w) 
- 
- inf,,Sol(u) 0 = 0. 
Observe that, in Example 14.1, xTDx is an indefinite quadratic 
form (the sign of the expression xTDx depends on the choice of x) 
and the solutions of the QP problem are not locally unique, so the 
assumptions of Theorem 14.1 are not satisfied. 
Consider problem (13.1) and assume that Z E Sol(D, A, c, b) is 
one of its solutions. Let u = w0 = (Do, AO, cO, bO) E il be a given 
direction. Applied to the solution 
of problem (13.1), condition 
(SOSC), in Auslender and Cominetti (1990) is stated as follows: 
For every vector v E F, \ {0), 
zf (DZ + clTv = 0 
then 
vTDv > 0, 

254 
14. Differentiability of the Optimal Value Function 
where F% is the cone of the feasible directions of A(A, b) at Z. That 
is 
F2 = {v E Rn : (Av)i 2 0 for every i satisfying 
= bi). 
Observe that, in the case of QP problems, condition (SOSC), 
is equivalent to the requirement saying that Z is a locally unique 
solution of (13.1) (see Theorem 3.7). This remark allows us to de- 
duce from Theorem 1 in Auslender and Coutat (1990) the following 
result. 
Proposition 14.1. Let w = (Dl A, c, b) E 52 be a given point and 
u = w0 = (Do, A', cO, bO) E fl be a given direction. If all the solu- 
tions of problem (13.1) are locally unique and the two conditions 
(i) the system Ax > b is regular, 
(ii) Sol(D, A, 0,O) = (0) 
are satisfied, then the optimal value function cp is directionally dif- 
ferentiable at w = ( D ,  A, c, b) in direction u = w0 = (Do, A', cO, bO), 
and formula (14.29) is valid. 
Proof. By Theorem 12.1, from the assumptions (i) and (ii) it fol- 
lows that the map Sol(.) is upper semicontinuous at (D,A, c, b). 
Besides, by Lemma 13.3, Sol(D, A, c, b) is a nonempty compact set. 
Then there exists a compact set B c Rn and a constant E > 0 such 
that 
0 # Sol(w + two) C B for every t E [0, el. 
Under the conditions of our proposition, all the assumptions of The- 
orem 1 in Auslender and Coutat (1990) are fulfilled. So the desired 
conclusion follows from applying Theorem 1 in Auslender and Cou- 
tat (1990). 
0 
Observe that Proposition 14.1 is a direct corollary of our The- 
orems 14.1 and 14.2. It is worth noting that the result stated in 
Proposition 14.1 cannot be applied to the problem described in Ex- 
ample 14.1 (because condition (SOSC),, where u := wO, does not 
hold at any solution Z t. Sol(w)). That result cannot be applied 
also to convex QP problems whose solution sets have more than 
one element. This is because, for such a problem, the solution set 
is a convex set consisting of more than one element. Using Remark 
14.1 we can conclude that Theorem 14.2 is applicable to convex QP 
problems. 

14.3 Directional Differentiability of cp(.) 
255 
Consider problem (13.1) and denote w = ( D ,  A, c, b). Suppose 
that w0 = (Do, A', cO, bO) E R is a given direction. In this case, con- 
dition (H3) in Minchenko and Sakolchik (1996) is stated as follows: 
(H3) For every sequence { t k ) ,  tk J. 0, and every sequence {x", xk + 
3 t. Sol(D, A, c, b), xk E Sol(w+tkwO) for each k ,  the following 
inequality is satisfied 
Ilxk - % [ I 2  
lim sup 
t k  
< +oo. 
k-+w 
Applying Theorem 4.1 in Minchenko and Sakolchik (1996) to 
problem (13.1) we get the following result. 
Proposition 14.2. Let w = ( D l  A, c, b) and w0 = (Do, AO, cO, bO) be 
given as in Proposition 14.1. If (H3) and the two conditions 
(i) the system A x  2 b is regular, 
(ii) there exist a compact set B C Rn and a neighborhood U 
of ( A ,  b) E Rmxn x Rm such that A(A1, b') c B for every 
(A', b') E U 
are satisfied, then the optimal value function cp is directionally dif- 
ferentiable at w = ( D ,  A, c, b) in direction u = w0 = (Do, A', cO, bO), 
and formula (14.29) is valid. 
Consider the problem described in Example 14.1. Choose t = 
(0,O) E Sol(w), tk = k-l, 
We have xk + t as k -+ -t and 
Ilxk - 3Il2 
k-i + k-4 
lim sup 
t 
= lim sup 
= +oo, 
k-+w 
k-+w 
k-l 
so (H3) does not hold and Proposition 14.2 cannot be applied to 
this QP problem. 
We have shown that Theorem 14.2 can be applied even to some 
kinds of QP problems where the existing results on differential sta- 
bility in nonlinear programming cannot be used. 
Now we want to show that, for problem (13.1), if the system 
A x  2 b is regular then (H3) implies (G). 

256 
14. Differentiability of the Optimal Value Function 
Proposition 14.3. Let w = (D, A, c, b) and w0 = (Do, A', cO, bO) be 
given as in Proposition 14.1. If the system Ax 2 b is regular, then 
condition (H3) implies condition (G) . 
Proof. Suppose that (H3) holds. Let {t", 
tk J 0, and {xk), where 
xk E Sol(w + tQO) for each k, be arbitrary sequences. If 
then, by (H3), we have 
Ilxk - 2112 
lim sup 
t 
< $00. 
k + m  
We have to prove that the inequality written in condition (G) is 
satisfied. Let {(tk')-'(2" - z)~D(x" - 3)) be a subsequence of 
{(tk)-l(xk - 2)*D(xk - 2)) satisfying 
From (14.32) it follows that the sequence {(ty-'llxk-2112) is bounded. 
Then the sequence {(tk)-'I2 llxk - 211) is bounded. Without loss of 
generality, we may assume that 
As xk E Sol(D + t q O , A  + tkAO,c+ tkcO, b +  tkbO), we have 
where I = {i : 
= bi}. Since bI = A12, 
Multiplying both sides of this inequality by (tk)-'I2 and letting k -t 
oo, due to (14.34) we can conclude that AIv 2 0. Hence v E Fz, 
where Fz is defined as in the formulation of condition (SOSC),. 
Furthermore, note that the expression (14.24) holds. As Ax 2 b is 
a regular system, by Lemma 14.1 we have F(z, w, wO) # 0. Take 
any fl E F(2, w, wO). Then, for k large enough, 

14.4 Commentaries 
257 
Therefore, for k large enough, we have (14.25). From (14.24) and 
(14.25) we have (14.26). Multiplying both sides of (14.26) by 
letting k -+ oo and taking account of (14.34), we get (14.27). As Z is 
a solution of problem (13.1) and v E F?, the situation (Dz+c)~v < 0 
cannot happen. Hence (Dz + C ) ~ V  = 0. Since It. E Sol(w), we must 
have vTDv 2 0 (see Theorem 3.5). By (14.33) and (14.34), 
lim inf (tk)-'(xk - Z)*D(xk - 2) 
k+m 
T 
= kl+co 
lim ((tk1)-112(xk1 - 5)) D ((tk1)-'/2(xk' - 5)) 
= vTDv 2 0. 
Thus (G) is satisfied. 
0 
14.4 Commentaries 
The results presented in this chapter are due to Tam (2001b). 
Best and Chakravarti (1990) considered parametric convex qua- 
dratic programming problems and obtained some results on the di- 
rectional differentiability of the optimal value function. Auslender 
and Coutat (1996) investigated similar questions for the case of 
generalized linear-quadratic programs. A survey of some results on 
stability and sensitivity of nonlinear mathematical programming 
problems can be found in Bonnans and Shapiro (1998). A compre- 
hensive theory on perturbation analysis of optimization problems 
was given by Bonnans and Shapiro (2000). 


Chapter 15 
Quadratic Programming 
under Linear Perturbat ions: 
I. Continuity of the 
Solution Maps 
Continuity of the local solution map and the solution map of QP 
problems under linear perturbations is studied in this chapter. 
Since it is impossible to give a satisfactory characterization for 
the usc property of the local solution map and since the usc property 
of the solution map can be derived from a result of Klatte (1985), 
Theorem 3, we will concentrate mainly on characterizing the lsc 
property of the local solution map and the solution map. 
Consider the QP problem 
1 
Minimize f (x) := - x T ~ x  + cTx 
2 
(15.1) 
subject to x E A(A, b) := {x E Rn : Ax 2 b) 
depending on the parameter w = (c, b) E Rn x Rm, where the 
matrices D E RgXn and A E Rmxn are not subject to change. 
The solution set, the local solution set and the KKT point set of 
this problem are denoted, respectively, by Sol(c, b), loc(c, b) and 
S(D1 A, c, b). 

260 
15. Quadratic Programming under Linear Perturbations, I 
15.1 Lower Semicontinuity of the Local 
Solution Map 
In this section we investigate the lsc property of the local solution 
map 
lot(.) : Rn x Rm -t 2Rm, (cl, bl) E Rn x Rm I+ loc(cl, b'). (15.2) 
Theorem 15.1. The multifunction (15.2) is lower semicontinuous 
at (c, b) E Rn x Rm if and only if the system Ax 2 b is regular and 
the set loc(c, b) is nonempty and finite. 
Proof. Necessity: Since the multifunction (15.2) is lower semicon- 
tinuous at (c, b), loc(c, b) is nonempty and the regularity condition 
is satisfied. We now prove that loc(c, b) is finite. Define the sets 
QI (I c {I,. . . , m)) and Q as in the proof of Theorem 11.3. Since 
Q is nowhere dense, there exists a sequence {(ck, bk)) converging to 
(c, b) in Rn x Rm such that (-ck, bk) $! 
Q for all k E N. Fix a point 
3 E loc(c, b). Since lot(.) is lower semicontinuous at (c, b), there 
exist a subsequence {(ckl, bkl)} of {(ck, bk)) and a sequence {xkl} 
converging to Z in Rn such that 
for all kl. For any kl, since loc(ckl, bkl) c S(D, A, ckl, bkl), there 
exists Xkl 1 Rm such that (11.9) is satisfied. For every kl, define 
By the same arguments as those used in the proof of Theorem 11.3, 
we obtain a subset I c (1,. . . , m) such that (11.10)-(11.13) hold. 
Next, let Z and X be defined as in the proof of Theorem 11.3. As 
before, X is a finite set and we have 3 E X. Since 3 E loc(c, b) 
can be chosen arbitrarily, we have loc(c, b) c X. Hence loc(c, b) is 
a finite set. 
Suficiency: If the regularity condition is satisfied and the set 
loc(c, b) is finite, then from Theorem 5 in Phu and Yen (2001) 
it follows that the multifunction (15.2) is lower semicontinuous at 
(c,b)E R n x  Rm. 
0 
Since loc(c, b) c S(D, A, c, b), from Theorem 15.1 we obtain the 
following corollary. 
Corollary 15.1. Let (D, A, c, b) E RzXn x Rmxn x Rn x Rm. Suppose 
that the system Ax > b is regular and the following conditions are 
satisfied: 

15.2 Lower Semicontinuity of the Solution Map 
(i) the set S(D, A, c, b) is finite, 
(ii) the set loc(c, b) is nonempty. 
Then, the multifunction (15.2) is lower semicontinuous at (c, b). 
15.2 Lower Semicontinuity of the Solu- 
tion Map 
In this section, a complete characterization for the lower semiconti- 
nuity of the solution map 
Sol(.) : Rn x Rm _t 2Rn, (c', b') H Sol(c', b' ) 
(15.3) 
of the QP problem (15.1) will be given. Before proving the result, 
we state some lemmas. 
Let (D, A, c, b) E RgXn x Rmxn x Rn x Rm. 
Lemma 15.1. If the multifunction (15.3) is lower semicontinuous 
at (c, b), then the system Ax 2 b is regular and the set Sol(c, b) is 
nonempty and finite. 
Proof. (This proof is very similar to the first part of proof of 
Theorem 15.1.) It is clear that if the multifunction (15.3) is lower 
semicontinuous at (c, b) then regularity condition is satisfied and the 
set Sol(c, b) is nonempty. In order to prove the finiteness of Sol(c, b), 
we define QI (I c (1,. . . , m}) and Q as in the proof of Theorem 
13.3. Then, there exists a sequence {(c" bk)) converging to (c, b) 
such that (-ck, by ) Q for all k. Fix any 3 E Sol(c, b). As Sol(.) is 
lower semicontinuous at (c, b), there exist a subsequence {(c", bkl)} 
of {(ck, bk)} and a sequence {x"} converging to 3 in Rn such that 
xkl E Sol(ckl , bk" for all kl. Since Sol(ckl , bkl) c S(D, A, ckl , bkl), 
there exists A" E Rm such that (11.9) is satisfied. Constructing I 
and defining Z and X as in the proof of Theorem 11.3, we have 
that X is a finite set and 3 E X. Hence the solution set Sol(c, b) is 
finite. 
0 
Lemma 15.2. If the multifunction (15.3) is lower semicontinuous 
at (c, b), then the set Sol(c, b) is a singleton. 
Proof. On the contrary, suppose that Sol(.) is lower semicontinuous 
at (c, b) but there exist 3, $j E Sol(c, b) such that 3 # 9. Choose 
co E Rn such that 
c;f(y - 3) = 1. 
(15.4) 

262 
15. Quadratic Programming under Linear Perturbations, I 
By Lemma 15.1, Sol(c, b) is a finite set. Combining this fact with 
(15.4) we see that there exists a open set U c Rn containing g such 
that 
SO~(C, 
b) n U = {g) 
and 
cz(y - Z) > 0 for all y E U. 
(15.5) 
Let 6 > 0 be given arbitrarily. Choose E > 0 so that 
Let b' = b, c' = c + E C ~ .  
We have 
We now show that 
Sol(cl, b') n U = 0. 
For any y E A(A, b') = A(A, b), since Z, y E Sol(c, b), using (15.5) 
we have 
Since 17: E A(A, b') , by (15.6) we have y @ Sol(cl, b'). Consequently, 
for the chosen neighborhood U of jj E Sol(c, b), for every 6 > 0 
there exists (c', b') E Rn x Rm satisfying ll(cl, b') - (c, b)ll < 6 and 
Sol(cl, b') n U = 0. This contradicts our assumption that Sol(.) is 
lower semicontinuous at (c, b). We have shown that Sol(c, b) cannot 
have more than one element. Since Sol(.) is lower semicontinuous 
at (c, b), we must have Sol(c, b) # 0. From what has been proved, 
we conclude that Sol(c, b) is a singleton. 
0 
Lemma 15.3. If A(A, b) is nonempty and .if we have 

15.2 Lower Semicontinuity of the Solution Map 
263 
for some v E Rn, then there exists 6 > 0 such that 
inf {vT (DX' + c') : z' E Rn, Ax' > b') 2 0 
(15.8) 
for every (c', b') E Rn x Rm satisfying Il(cl, b') - (c, b)ll < 6. (By 
convention, inf 0 = +me) 
Proof. By Corollary 7.2, for the given matrix A there exists a 
constant y(A) 2 0 such that 
A ( A ,  b') C A ( A ,  b") + y(A)llbU - b1llBRn 
(15.9) 
for all b', bl' E Rn satisfying A ( A ,  b') # 0 and A ( A ,  b") # 0. Define 
1-1 = i n f { v T ( ~ x  
+ c) : z E Rn, Ax 1 b). 
(15.10) 
By (15.7), p > 0. Choose 6 > 0 such that 
Here, as usual, llDll = max{llDxl1 : x E Rn, IIxII 5 1). Let 
(c', b') E Rn x Rm be such that IJ(c', b') - (c, b)II < 6. If A ( A ,  b') = 0 
inequality (15.8) is valid because the infimum in its left-hand-side 
equal +a. Now consider the case where A ( A ,  b') # 0. By our 
assumption, A ( A ,  b) # 0. Hence, for every x' E A ( A ,  b'), from 
(15.9) it follows that there exists x E A ( A ,  b) such that 
for some u E BRn. By (15.11) and (15.12), we have 
Combining this with (15.10), we obtain 
P 
vT(Dx' + c') > vT(Dx + c) - 7 

264 
15. Quadratic Programming under Linear Perturbations, 1 
From this we deduce that (15.8) holds for every (c', b') E Rn x Rm 
with the property that [[(c', b') - (c, b)II < 6. 
0 
Lemma 15.4. Let K denote the cone {v E Rn : Av 2 0, vTDv = 
0). Assume that the system Ax > b is regular, the set Sol(c, b) is 
nonempty, and 
for every nonzero v E K .  Then there exists p > 0 such that Sol(c', b') 
is nonempty for all (c', b') E Rn x Rm satisfying 11 (c', b') - (c, b) 11 < p. 
Proof. Since the regularity condition is satisfied, by Lemma 13.1 
there exists po > 0 such that for every b' E Rm satisfying Ilb' - bll < 
po we have 
A(A, b') # 8. 
(15.13) 
Since Sol(c, b) # 8, 
by Theorem 2.2 we have 
for all v E Rn satisfying Av 2 0. 
We now distinguish two cases. 
Case 1. K = {v E Rn : Av > 0, vTDv = 0) = (0). In this 
case, we have 
vT(Dx + c') = 0 
(15.15) 
for all v E K, x E Rn and c' E Rn. On account of Theorem 2.2 
and the properties (15.13)-(15.15), we have Sol(c1, b') # 8 for every 
(c', b') E Rn x Rm satisfying 11 (c', b') - (c, b) 11 < po. 
Case 2. K = {v E Rn : Av 2 0, vTDv = 0) # (0). In this 
case, from (15.14) it follows that K can be represented as the union 
of finitely many polyhedral convex cones (see Bank et al. (1982), 
Lemma 4.5.1). Suppose that 
where Kj ( j  = 1,2,. . . , s) are polyhedral convex cones. Fix an 
index j E {1,2,. . . , s). Let vl, v2,. . . , vkj be the generators (see 
Rockafellar (1970)) p. 170) of the cone Kj. By our assumption, for 
every vi, 1 5 i 5 I$, we have 
i n f { ( ~ ~ ) ~ ( D x  
+ c) : x E Rn, Ax: > b) > 0. 

15.2 Lower Semicontinuity of the Solution Map 
265 
By Lemma 15.3, there exists Si > 0 such that 
i n f { ( ~ ~ ) ~ ( D x  
+ c') : x E Rn, Ax 2 b') 2 0 
(15.17) 
for all (c', b') E Rn x Rm satisfying 11 (c', b') - (c, b) 11 < Si. Define 
F'rom (15.17) it follows that 
for all i = 1, . . . , kj and for all x E Rn satisfying Ax 2 b', provided 
that ll(c', b') - (c, b)ll < pj. Define pj = min{po, pj). Let (c', b') E 
RnxRm besuchthat Il(c', b')-(c,b)II < pj, x E A(A,bl) andv E Kj. 
As vl, . . . , vkj are the generators of Kj, there exist nonnegative real 
numbers a l l .  . . , anj such that v = alvl + . . . + abvkj. By (15.18), 
we have 
Set p = min{pj : j = 1,2,. . . , s). Let (c', b') E Rn x Rm be such 
that 
11 ( ~ ' 1  b') - (el b) 11 < P1 
(15.20) 
and let x E A(A, b') and v E K be given arbitrarily. By (15.16), 
thereexists j E {1,2, ..., s) such that v E Kj. Let v = a l v l + . . . +  
akjvkj, where ai 2 O for i = I, 2,. . . , kj. By virtue of (15.19), we 
have vT(Dx+c') 2 0. Hence, taking account of (15.13), (15.14), and 
applying Theorem 2.2 we have Sol(cl, b') # 0 for all (c', b') E Rn x Rm 
satisfying (15.20). The lemma is proved. 
We can now state the main result of this section. 
Theorem 15.2. The multifunction (15.3) is lower semicontinuous 
at (c, b) if and only zf the system Ax 2 b is regular and the following 
conditions are satis,fied: 
(i) for every nonzero vector 
it holds inf{vT(Dx + c) : x E Rn, Ax 2 b) > 0, 
(ii) the set Sol(c, b) is a singleton. 

266 
15. Quadratic Programming under Linear Perturbations, I 
Proof. Necessity: If Sol(.) is lower semicontinuous at (c, b) then by 
Lemmas 15.1 and 15.2, the system Ax 2 b is regular and condition 
(ii) is satisfied. Suppose that the property (i) were false. Then we 
could find a nonzero vector i3 E K = {u E Rn : Au 2 0, uTDu = 0) 
such that 
If the infimum in the left-hand-side of (15.21) is -co then it is 
obvious that there exists Z E A(A, b) satisfying vT(Dz + C) < 0. If 
that infimum is finite then, applying the Frank-Wolfe Theorem to 
the linear programming problem 
Minimize vT(Dx + C) 
subject to x E Rn, Ax > b, 
we find Z E A(A, b) such that 
So, in both cases, we can find z E A(A, b) such that 
1 
For every positive integer k, let c b =  c - -a. By (15.22), 
k 
From (15.23) we see that condition (ii) in Theorem 2.2, where 
(Dl A, c, b) := (D, A, ck, b), is violated. Hence, by Theorem 2.2 we 
have Sol(ck, b) = 8 for all k. Since ck t c as k t co, the latter fact 
shows that the multifunction (15.3) is not lower semicontinuous at 
(c, b), a contradiction. 
Suficiency: Suppose that the system Ax 2 b is regular and 
the conditions (i), (ii) are satisfied. By (ii), we can assume that 
Sol(c, b) = {Z) for some 3 E Rn. Let U be any open set containing 3. 
By the regularity assumption, by (i) and Lemma 15.4, there exists 
p > 0 such that Sol(cl, b') # 0 for all (c', b') E Rn x Rm satisfying 
[((c', b') - (c, b)II < p. By (ii) and Theorem 3 in Klatte (1985), there 
exists pl > 0 such that Sol(cl, b') c U for all (c', b') E Rn x Rm 
satisfying Il(c1, b') - (c, b)ll < pl. Hence, for pa := min{p,pl), we 
have Sol(cl, b') n U # 8 for all (c', b') E Rn x Rm satisfying Il(c', b') - 
(c, b)II < p2. From what already been proved, it may be concluded 

15.2 Lower Semicontinuity of the Solution Map 
267 
that Sol(.) is lower semicontinuous at (c, b). The proof is complete. 
0 
Let us mention two direct corollaries of Theorem 15.2. 
Corollary 15.2. For (D,A, c, b) E RzXn x Rmxn x Rn x Rm, if 
K := {v E Rn : Av > O , v T ~ v  
= 0) = (0) then the multifunction 
(15.3) is lower semicontinuous at (c, b) i f  and only if the system 
Ax 2 b is regular and the set Sol(c, b) is a singleton. 
Corollary 15.3. Let (D, A, c, b) E RzXn x Rmxn x Rn x Rm. If D 
is a positive definite matrix then the multifunction (15.3) is lower 
semicontinuous at (c, b) if and only if condition the system Ax 2 b 
is regular. 
In Theorem 15.2 we have established a complete characterization 
for the lower semicontinuity property of the solution map (15.3). Let 
us consider an example. 
Example 15.1. Let n = 2, m = 4, and 
Then we have the following QP problem 
1 
Minimize - (x: - x;) + xl 
2 
subject to 
XI - x2 2 0, x1 > 1, xl 2 0, x2 2 0. 
It is easily seen that the system Ax 2 b is regular. For any x = 
($1, 22) E A(A, b), we have 
The last two inequalities become equalities if and only if XI = 2 2  = 
1. These observations allow us to conclude that Sol(c, b) = {(1,1)). 
Clearly, 
and 

268 
15. Quadratic Programming under Linear Perturbations, I 
For any v = (p, p) E K \ (0) (p > 0) and for any x = (xl, x2) E 
A (A, b) , we have 
Since the system Ax 2 b is regular and conditions (i), (ii) in The- 
orem 15.2 are satisfied, we conclude that the multifunction (15.3) 
is lower semicontinuous at (c, b). Meanwhile, since Sol(0,O) # {O), 
from Theorem 12.3 it follows that the multifunction (Dl, A', c', b') I+ 
Sol(Df, A', c', b'), where Sol(D1, A', c', b') denotes the solution set of 
the canonical QP problem 
1 ,  1 
Minimize f (x) := -x D x + (c')~x 
2 
subject to A'x > b', 
x 2 0, 
is not lower semicontinuous at (Dl A, c,x) E R P 2  x R~~~ x R2 x R2. 
Here 
15.3 Commentaries 
The results presented in this chapter are taken from Lee et al. 
(2002b, 2002~). 
Theorem 15.2 is the main result of this chapter. Example 15.1 
shows clearly the difference between the characterization given by 
Theorem 15.2 and the one provided by Theorem 12.3. 

Chapter 16 
Quadratic Programming 
under Linear Perturbat ions: 
11. Properties of the 
Opt imal Value Function 
In this chapter, we will consider the optimal value function (c, b) H 
cp(c, b) of the parametric QP problem (15.1). It is proved that cp 
is directionally differentiable at any point zij = ( E ,  6) in its effective 
domain W := {w = (c, b) E Rn x Rm : -oo < cp(c, b) < +oo). 
Formulae for computing the directional derivative cp1(zij; z) of cp at 
zij in a direction z = (u, v) E Rn x Rm are also obtained. 
If D is positive semidefinite, then cp is piecewise linear-quadratic 
on the set W (which is a polyhedral convex cone). If D is not 
assumed to be positive semidefinite then W may be nonconvex, 
but it can be represented as the union of finitely many polyhedral 
convex cones. We present an example showing that, in general, cp 
is not piecewise linear-quadratic on W. 
16.1 Auxiliary Results 
Consider the standard QP problem (15.1) depending on the param- 
eter w = (c, b) E Rn x Rm, where D E RgXn and A E Rmxn are 
given matrices. Denote by S(c, b), Sol(c, b), loc(c, b) and cp(c, b), re- 
spectively, the set of the Karush-Kuhn-Tucker points, the set of the 
solutions, the set of the local solutions, and the optimal value of 
(15.1). Klatte (1985) established several fundamental facts on the 

270 
16. Quadratic Programming under Linear Perturbations, II 
Lipschitzian continuity of the map (c, b) H Sol(c, b) and the func- 
tion (c, b) H (P(c, b). Among other results, he proved that cp(., .) is 
Lipschitzian on every bounded subset of its effective domain 
Following Klatte (1985), we consider the next auxiliary problem 
1 
Minimize - (cTx + bTX) 
2 
subject to (x, A) E PKKT(c, b) 
where 
Elements of PKKT(c, b) are the Karush-Kuhn-Tucker pairs of (15.1). 
Let 
cpKKT(c, b) = inf 
+ bTX) : (x, A) E PKKT(c, b) 
be the optimal value of the auxiliary problem (16.2). By definition, 
Denote by S0lKKT(c, b) the solution set of (16.2). 
Lemma 16.1. (See Klatte (1985), p. 820) If Sol(c, b) is nonempty 
then S0lKKT(c, b) is nonempty, and 
d c ,  b) = (PKKT(C, 
b) , 
(16.7) 
where, by definition, TRn(x, A) = x for every (x, A) E Rn x Rm. 
Proof. Since Sol(c, b) # 8, we can select a point 5 E Sol(c, b). By 
Theorem 3.3, there exists 5 E Rm such that 
Let (x, A) be a feasible point for (l6.2), that is 

16.1 Auxiliary Results 
271 
By (16.8), x E A(A,b). Hence f(x,c) 2 f(Zlc), where f(x,c) := 
1 
-xTDx + cTx. From (16.8) it follows that 
2 
Similarly, one has 
Consequently, 
Since this inequality holds for every (x, A) E PKKT(c, b), we conclude 
that (?,I) is a solution of (16.2). Combining this with (16.4), (16.5) 
and (16.9), we obtain (16.7). In order to prove (16.6), we fix any 
x E Sol(c, b). Let X be a Lagrange multiplier corresponding to that 
x. The above arguments show that (x, A) is a solution of (16.2). 
From this it follows that x E flRn(s~lKKT(c, 
b)). NOW, let (x, A) 
be a solution of (16.2). Since (x, A) satisfies the inequality system 
described in (16.8), we have 
1 
-(cTx + bTA) = f (x, c). 
2 
Since (3, X) and (x, A) are from the solution set of (16.2), it holds 
Consequently, f (x, c) = f (5, c). Since x E A(A, b), from the last 
equality we deduce that x E Sol(c, b). The equality (16.6) has been 
proved. 
Note that the set W defined by (16.1) coincides with the effective 
domain of the multifunction Sol(., 
a ) ,  that is 
W = {(c, b) E Rn x Rm : -00 < p(c, b) < +oo) 
= {(c,b) E Rn x Rm : Sol(c,b) # 0). 
(16.10) 

272 
16. Quadratic Programming under Linear Perturbations, II 
Indeed, for any pair (c, b) E Rn x Rm, if Sol(c, b) # 0 then -m < 
cp(c, b) < +m. Conversely, if -m < cp(c, b) < +m then A(A, b) is 
nonempty and the function f (., c) is bounded below on A(A, b). By 
Theorem 2.1, Sol(c, b) # 0. 
Taking account of (16.10), we can formulate the results from 
Klatte (1985) concerning the optimal value function cp(c, b) as fol- 
lows. 
Lemma 16.2. (See Klatte (1985), Theorem 2) The eflective domain 
W of cp is the union of a finitely many polyhedral convex cones, 
i.e. there exists a finite number of polyhedral convex cones Wi C 
Rn x Rm (i = 1,2,. . . ,s) such that 
Lemma 16.3. (See Klatte (1985), Theorem 3) The function cp is 
Lipschitzian on every bounded subset Ro c W, i.e., for each bounded 
subset Ro c W there exists a constant ks2, > 0 such that 
for any (c, b), (c', b') E R0. 
For each subset I c {1,2, . . . , m), we define 
PLKT(c, b) = {(x, A) E Rn x Rm : Dx - ATX + c = 0, 
A ~ x  2 bi, ; X i  = 0 ('ti E I), 
Ajx=bj, Xj 2 0  ( ' t j g  I)), 
(16.12) 
where Ai (i E {I, . . . , m)) is the i-th row of the matrix A and bi is 
the i-th component of b. It is clear that 
Note that PLKT(c, b) is the solution set of the following system of 
linear equalities and inequalities: 

1 6.1 Auxiliary Results 
273 
where J = {1,2,. . . ,m) \ I and, as usual, A j  denotes the matrix 
composed by the rows Aj ( j  E J) of A, and XI is the vector with 
the components Xi (i E I). 
Let 
( P & ~ ~ ( C ,  
b) = inf 
+ bTX) : (x, A) E pLKT(c, b) 
Thus ( P & ~ ~ ( c ,  
b) is the optimal value of the linear programming 
1 
problem whose objective function is -(cTx + bTX) and whose con- 
2 
straints are described by (16.14). Note that the pair (c, b) represents 
the right-hand-side perturbations of the linear system (16.14). 
It turns out that, for any I c {1,2, . . . , m), the effective domain 
of 
is a polyhedral convex cone on which the function admits 
a linear-quadratic representation. Namely, using the concept of 
pseudo-matrix one can establish the following result. 
Lemma 16.4. (See Bank et al. (1982), Theorem 5.5.2) The eflec- 
tive domain 
domcpiKT = {(c, b) E Rn x Rm : -cm < &KT(c, b) < +CO} 
is a polyhedral convex cone and there exist 
for every (C, b) E dom(PLKT. 
The following useful fact follows from Lemma 16.1. 
Lemma 16.5. For any (c, b) E W, it holds 
Proof. From (16.4), (16.13) and (16.15), we deduce that 
Combining this with (16.7) we obtain (16.17). 
0 
Remark 16.1. From (16.17) it follows that, for for any (c, b) E W 
and for any I c {1,2,. . . , m), we have ( P & ~ ~ ( c ,  
b) > -00. 

274 
16. Quadratic Programming under Linear Perturbations, 11 
Remark 16.2. It may happen that for some pairs (c, b) E W the 
function 
has the value +m. Note that cpLKT(~, 
b) = +oo 
if and only if the solution set of (16.14) is empty. The example 
considered in Section 16.3 will illustrate this situation. 
Remark 16.3. If D is a positive semidefinite matrix then (15.1) 
is a convex QP problem and the equality cp:tKT(~, b) = &KT(c, b) 
holds for any index sets 11, I2 C {1,2, . . . , m) and for any point 
(c, b) E dom&,, 
fl 
The last equality is valid because 
any KKT point of a convex QP problem is a solution. 
16.2 Directional Differentiability 
In this section, we will prove that although cp is not a convex func- 
tion but it enjoys the important property of convex functions of 
being directionally differentiable at any point in its effective do- 
main. A formula for computing the directional derivative cp'(zJ; z) 
of cp at any G = (El 6) E W in direction z = (u, v) E Rn x Rm is 
also established. 
Recall (Rockafellar (l97O), p. 13) that a subset K c RP is called 
a cone if tx E K whenever x E K and t > 0. (The origin itself may 
or may not be included in K). 
Proposition 16.1. Let W be defined by (16.1), 
21 = {(c, b) E Rn x Rm : cp(c, b) = +m), 
2 2  = {(c, b) E Rn x Rm : cp(c, b) = -m), and 
L = {b E Rm : A(A, b) is nonempty). 
Then Z1 is an open cone, W is a closed cone, and Z2 is a cone which 
is relatively open in the polyhedral convex cone Rn x L c Rn x Rm. 
Moreover, it holds 
Rn x L = WUZ2, Rnx Rm = WUZ2UZl, 2, = (Rnx Rm)\(Rnx L). 
(16.18) 
The easy proof of this proposition is omitted. 
Theorem 16.1. The optimal value function cp defined in (16.5) is 
directionally differentiable on W, i.e., for any zJ = (El b) E W and 
for any z = (u, v) E Rn x Rm there exists the directional derivative 
cp(w + tz) - cp(G) 
c p ' ( ~ ;  z) := lim 
tl0 
t 

1 6.2 Directional Differen tiability 
275 
of 9 at G in direction z. 
Proof. Let G = ( E ,  6) E W and z = (u,v) E Rn x Rm be given 
arbitrarily. If z = 0 then it is obvious that cpl(G; z )  = 0. Assume 
that z # 0. We first prove that one of the following three cases 
must occur: 
(cl) There exists f > 0 such that + tz E Z1 for every t E (O,fl, 
(c2) There exists f > 0 such that G + tz E Z2 for every t E (0, fl, 
(c3) There exists f > 0 such that G + tz E W for every t E (0, fl. 
For this purpose, suppose that (c3) fails to hold. We have to 
show that, in this case, (cl) or (c2) must occur. Since (c3) is not 
valid, we can find a decreasing sequence tk --t O+ such that G+tkz 6 
W for every k E N. By (16.18), for each k E N, we must have 
G + tkz E Z1 or G + tkz E 2 2 .  Hence, there exists a subsequence 
{tki) of i t k )  such that 
G+tkiz€ Z1 
(Vi E N), 
or 
G+thz E Zz (Vi E N). 
(16.21) 
Consider the case where (16.20) is fulfilled. If there exists an t^ E 
(0, tkl ) such that 
G + ~ ^ Z E R ~ X L  
then, by the convexity of Rn x L, 
{G + tz : t E [0, t)) c Rn x L. 
By virtue of the first equality in (16.18), this yields cp(G+tz) # +oo 
for every t E [0, t), contradicting (16.20). Thus (16.20) implies that 
G + tz 4 Rn x L for every t E (0, tkl). Then, the third equality 
in (16.18) shows that G + tz E Z1 for every t E (0, tkl). Putting 
f = tkl, we see at once that (cl) holds. 
Consider the case where (16.21) is fulfilled. Since G E W C 
Rn x L and 
G+tk1z E Z2 C Rn x L, 
it follows that 
{G + tz : t E [0, tkl]) C Rn x L. 

276 
16. Quadratic Programming under Linear Perturbations, II 
Therefore, we can deduce from the first equality in (16.18) that, for 
every t E (O,tkl), W + tz E Z2 
or '27j + tz E W. If there exists i E N 
such that 
w + t z  E 22 (Vt E (O,tki)) 
(16.22) 
then (c2) is satisfied if we choose T = tki. If there is no i E N such 
that (16.22) is valid, then for every i E N there must exist some 
tii E (0, tki) such that zij + tiiz E W. By (16.11), there is an index 
j(lci) E (1, . . . , s) such that 
Without loss of generality, we can assume that 
Since j(lci) E (1, . . . , s), there must exist a pair (i, j) such that j > i 
and j(kj) = j(ki). By (16.23) and by the convexity of Wj(ki), we 
have 
{W + tz : t& 5 t 5 $) C Wj(ki) C W. 
(16.25) 
From (16.21) and (16.24) we get cp('27j + tki+lz) = -m and tij < 
tki+, < tii, a contradiction to (16.25). We have thus proved that if 
(16.21) is valid then (c2) must occur. 
Summarizing all the above, we conclude that one of the three 
cases (c1)-(c3) must occur. 
If (cl) occurs then, by (16.19), we have cpl(W;z) = +m. Simi- 
larly, if (c2) happens then cp'(W; z) = -m. 
Now assume that (c3) takes place. Denote by F the collection 
of the index sets I C {1,2,. . . , m) for which there exists tI E (0, f), 
where f > 0 is given by (c3), such that 
{W + tz : t E [O, tI]) c domcpiKT. 
(16.26) 
Recall that d~mcp',,~ is a closed convex set (see Lemma 16.4). If 
F = 0 then for any I c {1,2, ..., m) and for any t E (0,q one has 
cpkKT(W + tz) = +oo. By (c3), '27j + tz E W for all t E (0,q. Then, 
according to (16.18) we have 
cp('27j + tz) = min{cpiKT(W + tz) : I C {1,2, . . . , m)) = +oo 
for all t E (0, q, which is impossible. We have shown that F # 0. 
Define 
= min{tI : I E F )  > 0. 

16.2 Directional Differentiability 
277 
By virtue of (c3) and of (16.18), one has 
cp(w + tz) = min{&,,(w 
+ tz) : I E F) (Vt E [0, q). (16.27) 
It follows from (16.26) that 
w + tz E domcp;,, 
(VI E F, Yt E [O,q). 
For each I E F, let MI E R ( ~ + ~ ) ~ ( ~ + ~ )  
and ql E Rn+m be such that 
the representation (16.16) holds for all (c, b) E domcp&,,. 
Setting 
for every (c, b) E Rn x Rm, we extend 
from d~rncp&,~ 
to the 
whole space Rn x Rm. From (16.28) it follows that all the functions 
&KT(.), I E F, are smooth. According to Theorem 2.1 in Clarke 
(l975), the function 
is locally Lipschitz at 
= ( E ,  b). Moreover, + is Lipschitz regular 
(see Definition 2.3.4 in Clarke (1983)) at z3, and 
pO((zu; 
z) = p1(z3; z) = min{(&,,)'(w; 
z) : I E F), 
(16.29) 
where +'(a; z) (resp., (p1(27j; z)) denotes the Clarke generalized di- 
rectional derivative (resp., the directional derivative) of p at C in 
direction z. Since 
for all (c, b) E domcpk,,, 
from (16.27) and (16.29) it follows that 
the directional derivative cp'(z3; z) exists, and we have 
cpl(w; z) = min{(cp~,,)'(w; z) : I E F). 
(16.30) 
The proof is complete. 
0 
In the course of the above proof we have obtained some explicit 
formulae for computing the directional derivative of the function cp. 
Namely, we have proved the following result. 
Theorem 16.2. Let 2Tf E W and z = (u,v) E Rn x Rm. The 
following assertions hold: 

278 
16. Quadratic Programming under Linear Perturbations, I1 
(i) If there exists f > 0 such that 
for all t E (0, q), then cpl(fi; z) = +m. 
(ii) If there exists f > 0 such that 
for all t E (0, q), then cpl(fi; z) = -m. 
(iii) If there exists f > 0 such that 
fi + t z  E W = {(c, b) : A(A, b) # 0, cp(c, b) > -m) 
for all t E (0, q), then cpl(fi; z) can be computed by formula 
(16.30), where F is the collection of all I c {1,2,. . . , m) for 
which there exzsts some tI E (0, f) satisfying condition (16.26). 
At the end of the next section we shall use Theorem 16.2 for 
computing directional derivative of the optimal value function in a 
concrete nonconvex QP problem. 
16.3 Piecewise Linear-Quadratic Prop- 
erty 
The notion of piecewise linear-quadratic function (plq function, for 
brevity) was introduced in Rockafellar (1988). 
Definition 16.1. (See Rockafellar and Wets (1998), p. 440) A 
function $J : R1 -+ R is piecewise linear-quadratic (plq) if the set 
can be represented as the union of finitely many polyhedral convex 
sets, relative to each of which $(z) is given by an expression of the 
form 
1 
- Z ~ Q Z  + dTz + a 
2 
(16.32) 
for some a E R, d E R1, Q E R:'. 
Note that in Rockafellar and Wets (1998) instead of (16.31) one 
has the following formula 

16.3 Piecewise Linear-Quadratic Property 
279 
If there exists some 2 E R1 with $(z) = -00 then, since Z belongs 
to the set defined in (16.33), one cannot represent the latter as the 
union of finitely many polyhedral convex sets, relative to each of 
which $(z) is given by an expression of the form (16.32). Hence $ 
cannot be a plq function. This is the reason why we prefer (16.31) 
to (16.33). 
If D is a positive semidefinite matrix then, by using the Eaves 
Theorem we can prove that W is a polyhedral convex cone. Using 
Lemmas 16.4, 16.5, and Remark 16.3, it is not difficult to show that 
the optimal value function cp(c, b) = cp(c, b) of a convex QP problem 
is plq. 
Example 16.1. (See Rockafellar and Wets (1998)) Consider the 
function 
$(z)=Iz;+z;-lI, 
z=(z1,z2)E R ~ .  
We have R2 = R1 U 0 2 ,  where 
The formulae 
$(z) = -z; - 222 + 1 ('dz E 01) and $(z) = 2; + 2; - 1 (Vz E R2) 
show that $ admits a representation of the form (16.33) on each 
domain Ri (i = 1,2). Meanwhile, it can be proved that $ is not a 
plq function. 
Note that if the function cp(c, b) defined by (16.5) is plq then, for 
any b E Rm, the function cp(., b) is also plq on its effective domain. 
Indeed, assume that cp(c, b) is plq, that is W admits a representation 
of the form W = U:=, Wi, where every Wi is a polyhedral convex 
(n+m) x (n+m) 
set and there exist Qi E Rs 
, di E Rn+m and ai 
E R such 
that 
Let b E Rm be given arbitrarily. Define 
for all i = 1,. . . , s. It is obvious that W' = domcp(., b) and W' = 
U3 
2=1 Wl. Moreover, for every i E (1,. . . , s), from (16.34) it follows 
that 

280 
16. Quadratic Programming under Linear Perturbations, II 
Since the function in the right-hand-side of this formula is a linear- 
quadratic function of c and since each W,! is a polyhedral convex set 
(maybe empty), we conclude that cp(., 6) is a plq function. 
We are interested in solving the following question: Whether the 
optimal value function in a general (indefinite) parametric quadratic 
programming problem is a plq function w.r,t. the linear parameters? 
It turns out that the plq property is not available in the general 
case. 
Example 16.2. Consider the problem 
1 
Minimize f (x, c) = -(x; + 2x1x2 - xi) + clxl + ~2x2 
2 
1 
(16.35) 
subject to x = (xl, $2) E R2, 
-21 + 2 2  2 0, 
2 
x2 - x1 2 0, 
-22 2 -2, 
and denote by cp(c), c = (cl, c2) E R2 , the optimal value of this 
nonconvex QP problem. 
In the remainder of this section we will compute the values 
cp(c), c E R2. In the next section it will be shown that the func- 
tion cp(c) is not plq. Then we can conclude that the optimal value 
function p(c, b), c = (cl, c2) E R2 and b = (bl, b2, b3) E R3, of the 
following parametric QP problem is not plq: 
1 
Minimize f (x, c) = - (x; + 2x1x2 - xi) + clxl + ~2x2 
2 
1 
subject to x = (xl, x2) E R2, -xl + 2 2  2 bl, 
(16.36) 
2 
~ 2 - X I  2 b 2 ,  -x2 2: b3. 
Indeed, if cp(c, b) is plq then the arguments given after Example 16.1 
show that cp(c) = cp(c, 6 ) ,  where 6 = (0,0, -2), is a plq function, 
which is impossible. 
In order to write (16.35) in the form (15.1), we put 
Note that the feasible domain A(A, 6) of (16.36) is a triangle 
with the vertexes (0, O), (2,2) and (-4,2). Since A(A, 6) is com- 
pact, cp(c, b) E R for every c e R2. In other words, domcp(., 6) = R2. 

1 6.3 Piecewise Linear-Quadra tic Property 
28 1 
In agreement with (16.2) and (16.3), the auxiliary problem corre- 
sponding to (16.35) is the following one 
1 
1 
Minimize -(cTx + bTX) = -(clxl + c2x2) - X3 
2 
2 
subject to (x,X)=(xl,x2,X1,X2,X3) 
E R2 x R3, 
1 
2 1  + x2 - -A1 + A2 + C l  = 0, 
2 
X l  - 2 2  - X 1  - X 2  + X3 + C2 = 0, 
(16.37) 
1 
1 
- 2 1  + x2 2 0, 
A1 2 0, XI(-x1 + 2 2 )  = 0, 
2 
2 
2 2  - X I  2 0, 
X 2  2 0, X2(x2 - x l )  = 0, 
. 2 2  5 2, 
X 3  2 0, X3(2 - x2) = 0. 
We shall apply formula (16.17) to compute the values cp(c, b), c E 
R ~ ,  
b = b. To do so, we have to compute the optimal value 
( P $ K T ( ~ ,  
b) defined by (16.15), where I c {1,2,3) is an arbitrary 
subset. Since there are 8 possibilities to choose such index set I ,  we 
have to consider 8 linear subproblems of the problem (16.37). 
Case 1. I = I1 = {1,2,3). In the corresponding subproblem we 
must have X I  = (A1, X 2 ,  X 3 )  = (0,0,0). Taking account of (16.37), 
we can write that subproblem as follows 
In accordance with (16.15), we denote the optimal value of ( I l )  
by cp2KT(~, 
6). An elementary investigation on ( I l )  gives us the 
following result: 
The exact meaning of (16.38) is the following: We have 
for every c E domcp2,,(., b) and 

282 
16. Quadratic Programming under Linear Perturbations, I1 
for every c $ d ~ m & ~ ~ ( ' ,  
b). A similar interpretation applies to the 
results of the forthcoming 7 cases. 
Case 2. I = I2 = {1,2). We have X I  = ( X 1 , X 2 )  = ( O , O ) ,  X3 2 
0. The corresponding subproblem is 
-(clxl + ~2x2) - X3 -' min 
+ x2 + C l  = 0, 
X l  - 2 2  + X 3  + c2 = 0, 
( 1 2  
+ x2 2: 0, x2 - x1 2 0, 
2 2  = 2, 
X3 2 0. 
Then 
Case 3. I = I3 = {2,3). We have X I  = (A2, X 3 )  = ( O , O ) ,  X I  2 
0. The corresponding subproblem is 
Then 
Case 4. I = Id = {1,3). We have X I  = (A1, AS) = (0, O ) ,  X 2  2 
0. The corresponding subproblem is 
-(clxl + c2x2) -' min 
+ 2 2  + A2 + C1 = 0, x1 - 2 2  - X 2  + C2 = 0, 
( 1 4 )  
5 2  2 0, 
2 2  - x1 = 0, 
X 2  > 0, 
2 2  5 2. 
Then 

1 6.3 Piece wise Linear- Q uadra tic Property 
283 
Case 5. I = I5 = { I ) .  We have X 1  = 0, X 2  2 0, X3 2 0. The 
corresponding subproblem is 
1 - ( ~ 1 x 1  + ~ 2 x 2 )  - X3 4 min 
X l  + x2 + A2 + cl = 0, 
X l  - x2 - X 2  + A3 + C2 = 0, 
( 1 5 )  
-x1 + x2 2 0, 
2 2  - X l  = 0, A2 2 0, x2 = 2, 
X3 2 0. 
{ r 
Then 
9gKT(c, 5) = 2 ~ 1  + 2 ~ 2  + 4, 
d ~ m & ~ ~ ( ' ,  
6) = {c = (
~
1
 
, c2) : ci + 4 5 0, 
C l  + C2 f 4 5 0). 
(16.42) 
Case 6. I = I6 = (2). We have X 2  = 0, X 1  2 0, X3 2 0. The 
corresponding subproblem is 
Then 
Case 7. I = I7 = (3). We have X3 = 0, X 1  2 0, X 2  2 0. The 
corresponding subproblem is 

284 
16. Quadratic Programming under Linear Perturbations, I1 
Case 8. I = Is = 0. We have X 1  2 0, X 2  2 0, X3 2 0. The 
corresponding subproblem is 
1 
-(cixl + ~2x2) - X 3  + min 
2 
1 
X l  +x2 - -A1 +X2+c1= 0, XI-x2 - X 1  - X 2 + X 3 + C 2  
= 0, 
2 
1 
-x1 + 2 2  = 0, A1 2 0, 
2 2  - x1 = 0, X 2  2 0, x2 = 2, X3 2 0. 
2 
( I d  
Then 
v$KT(c, 6 )  = +oo 
for every c E R2, 
domcp$,, 
(. , b) = 0. 
(16.45) 
Consider the following polyhedral convex subsets of R2: 
Using formulae (16.17) and (16.38)-(16.45), one can show that 
y(c, 6) = cp$,,(~, 
6) = 2c1 + 2c2 + 4 for every c E ill, 
1 
cp(c, 6) = &,,(c, 
6 )  = -;(el + c
~
)
~
 
for every c E a2 u a9, 
cp(c, b) = cpZKT(c, 6 )  = 0 for every c E R3 U R4, 
cp(c, 6) = c p Z K T ( C ,  b) = -4c1 + 2c2 - 2 for every c E a5, 
and 
- 
1 2  
P(C, b) = (P2KT(~, 
b) = --el - 2c1 + 2c2 - 4 
2 
for every c E a6 U C17 U a8. 
We will pay a special attention to the behavior of cp(., 6 )  on the 
region ale. In order to compute cp(c, b) for c E Ole, we divide S210 

16.3 Piecewise Linear-Quadratic Property 
285 
into two subsets: 
For c E O;,, by (16.17) and (16.38)-(16.45) we have 
Since 
'P~KT(c, 
6) - ID$KT(c, 5) 
1 
1 
= -(-c: - 2c1c2 +c;) + -c: + 2c1 - 2c2 + 4  
4 
2 
= -(c2 - (cl +4))2 2 0 
4 
for every c E a;,, we have 
p(c, 6) = min{cp~KT(c, 
b), 
(c, 6)) 
(Yc E a',,). 
(16.46) 
For c E R;2/io, by (16.17) and (16.38)-(16.45) we have 
Since 
(P~KT(c, 
b) - (P~KT(c, 
5) 
1
2
 
= 2 4  + -c2 - 2c1c2 
1 
2 
= -(2c1 - c2)2 2 0 
2 
for every c E a;2/io, 
we have 
y(c, 6) = min{cp$KT(c, b), &,,(c, 
b)) 
(Yc E Rk). 
(16.47) 
From (16.46) and (16.47) it follows that 
for all c E Rlo = R;, U Oh. Consider the parabola 

286 
16. Quadratic Programming under Linear Perturbations, II 
By (16.48), for each c E CI10 we have 
This amounts to saying that cp(c, 6) = cpgKT(c, 6) for all the points 
c E CIlo lying above the parabola I?, and ~ ( c ,  
6) = 'P2KT(~, 
6) for all 
the points c E CI10 lying below the curve I'. 
We have thus computed the values cp(c, 6) for all c E R2. To 
have a better knowledge of the behavior of the function cp(.,6), the 
reader can draw a plane R2 with the regions CI1,. . . , Rlo and the 
parabola I?. 
Proposition 16.2. The obtained optimal value function cp(c, 6) 
(c E R2) cannot be a piecewise linear-quadratic function. 
A detailed proof of this proposition will be given in the next 
section. 
By virtue of Proposition 16.2 and the observation stated just 
after Example 16.1, we can conclude that the optimal value function 
(c, b) H 
~ ( c ,  
b) of problem (16.36) cannot be a plq function. Thus, 
if D is not assumed to be a positive semidefinite matrix then the 
optimal value function p(., .) of (15.1) can fail to be piecewise linear- 
quadratic. 
We now apply formula (16.30) to compute directional derivative 
of the function cp(., 6 )  studied in this section. 
Let c = ~ ( p )  
= (0, p), p E R. Let cpl (c) := ~ ( c ,  
z). For C ( p )  = 
( ~ ( p ) ,  
6) and 2 = ( E ,  g ) ,  where E = (1,O) E R2 and fi = (0,0,0) E 
R3, we have pt(C(p); Z )  = cpi ( ~ ( p ) ;  
a). Using formulae (16.30) and 
(16.38)-(16.45), we obtain 
Therefore 

16.4 Proof of Proposition 16.2 
287 
By Lemma 16.3, the function cpl(.) = cp(., b) is locally Lipschitz 
on R2. From Theorems 16.1 and 16.2 it follows that cpl(.) is direc- 
tionally differentiable at every c E R2 and, for every u E R2, the 
directional derivative cpl (c; u) is finite. One can expect that cpl (.) is 
regular in the sense of Clarke (1983), i.e, for every c E R2 it holds 
cpy (c; U) = 9; (c; U) , where 
cp:(c; u) : = lim sup cpl(cf + tu) - cpl(cf) 
cl+c, tlO 
t 
denotes the generalized directional derivative of cpl at c in direction 
u. Unfortunately, the function cpl(.) is not Lipschitz regular. In- 
deed, for E = (0,2) and ii = (0, I), using (16.50) it is not difficult to 
show that 
0 = cpy(c;u) > cp;(c;u) = -2. 
16.4 Proof of Proposition 16.2 
Suppose, contrary to our claim, that the function cp(., b) is plq. Then 
the set domy(., 6) = R2 can be represented in the form 
where J is a finite index set and A, (j E J) are polyhedral convex 
sets. Moreover, for every j E J, one has 
for all c E A,, where aj E R, dj E R2, Qj E R ? ~ .  Let 
A; = A, n R10 (j E J). 
Note that some 
deduce that 
of the sets A; can be empty. From (16.51) we 
Rlo = U A;. 
j6 J 
Note also that on each set A; (j E J) the function cp(-,b) has the 
linear-quadratic representation (16.52). Define 

288 
16. Quadratic Programming under Linear Perturbations, II 
It is evident that R:, 
is a convex set. Note that a:, and 0:; are 
compact sets which admit the curve I?nRlo, where I? is the parabola 
defined by (16.49), as the common boundary. The set R:, 
(resp., 
0:;) has nonempty interior. Indeed, let t := (0,3) and c := (0,l). 
Substituting the coordinates of these vectors into the inequalities 
defining R:, 
and a:;, one see at once that t E intfl:, and ?: E into:;. 
Fix any index j E J for which A; # 0. 
We first consider the case intA$ # 0. If 
then we must have A; c a:,. 
Indeed, by (16.54) there must exist 
a ball B c R2 of positive radius such that 
By (16.50), cp(c, 6) = 0 for every c E a:,. 
Then, it follows from 
(16.52) that 
1 
~ ( c ,  
6) = -cT&jc + $C + aj = O 
2 
for every c E B. This implies that Qj = 0, dj = 0 and aj = 0. 
Consequently, 
y(c,6) = o (YC E A;). 
(16.55) 
We observe from (16.50) that p(c, 6) < 0 for every c E a10 \ a:,. 
Hence (16.55) clearly forces A; c a:,. 
If 
then we must have intA; c a:;. 
Since R:; 
is closed, we conclude 
that A; c a:;. 
Therefore, if A$ n a:, # 0 then A; n R:, 
= A$ n I?. 
In this case, it is easy to show that A; n I? is a singleton. 
We now consider the case intA; = 0. Since A; is a compact 
polyhedral convex set in R2, there are only two possibilities: 
(i) A; is a singleton, 
(ii) A; is a line segment. 
In both situations, if A$ n a:, is nonempty then it is a compact 
polyhedral convex set (a point or a line segment). 
From (16.53) and from the above discussion, we can conclude 
that a!, is the union of the following finite collection of polyhedral 

16.5 Commentaries 
convex sets: 
A:, 
(j E J is such that intA> n intfl;, # 0), 
A> n r 
(j E J is such that intA; # 0, intAi n intR;, = a), 
A: n Ofo 
( j  E J is such that intaj = 0, A; n R:, # 0). 
As R:, 
is convex, it coincides with the convex hull of the above- 
named compact polyhedral convex sets. According to Theorem 
19.1 in Rockafellar (1970), this convex hull is a compact polyhe- 
dral convex set. So it has only a finite number of extreme points 
(see Rockafellar (1970), p. 162). Meanwhile, it is a simple matter 
to show that every point from the infinite set n Rlo is an extreme 
point of R;,. 
We have arrived at a contradiction. The proof is 
complete. 
16.5 Commentaries 
The results presented in this chapter are taken from Lee et al. 
(2002a). 
In this chapter we have studied a class of optimal value functions 
in parametric (nonconvex) quadratic programming. It has been 
shown that these functions are directionally differentiable at any 
point from their effective domains but, in general, they are not 
piecewise linear-quadratic and they may be not Lipschitz regular at 
some interior points in their effective domains. 
The class of plq functions has been investigated systematically 
in Rockafellar and Wets (1998). In particular, the topics like sub- 
differential calculation, dualization, and optimization involving plq 
functions, are studied in the book. 
The reader is referred to Gauvin and Tolle (1977), Gauvin and 
Dubeau (1982), Rockafellar (1982), Fiacco (1983), Clarke (1983), 
Janin (1984), Minchenko and Sakolchik (1996), Bonnans and Shapiro 
(1998,2000), Ward and Lee (2001), and references therein, for differ- 
ent approaches in the study of differential properties of the optimal 
value functions in nonlinear optimization problems. 
It would be desirable to find out what additional conditions one 
has to impose on the pair of matrices (D, A) E RgXn x Rmxn, where 
D need not be a positive semidefinite matrix, so that the optimal 
value function 
(c, b) 
dc1 b) 

290 
16. Quadratic Programming under Linear Perturbations, I1 
of the parametric problem (15.1) is piecewise linear-quadratic on 
Rn x Rm. 
Both referees of the paper Lee et al. (2001a) informed us that 
D. Klatte had constructed an example of an optimal value function 
in a linearly perturbed QP problem which is not plq. Being unaware 
of that (unpublished) example, we have constructed Example 16.2. 
One referee gave us some hints in detail on the example of Klatte. 
Namely, letting two components of the data perturbation of a QP 
problem considered by Klatte (1985) be fixed, one has the problem 
Minimize xlx2 
subject tox=(x1,x2) E R2, -1 5 x 1  < bl, b2 5 x 2  21, 
where b = (bl, b2) E R2, bl > 0 and b2 < 0, represents the pertur- 
bation of the feasible region. Denote by cp(bl, b2) the optimal value 
function of this problem. It is easy to verify that 
If bl < 0 or b2 > 0, then we put cp(bl, b2) = +oo. Arguments 
similar to those of the proof of Proposition 16.2 show that cp(bl, b2) 
is not a plq function. The main difference between this example and 
Example 16.2 is that here the feasible region is perturbed, while in 
Example 16.2 the objective function is perturbed. 

Chapter 17 
Quadratic Programming 
under Linear Perturbat ions: 
111. The Convex Case 
The problem of finding the nearest point in a polyhedral convex set 
to a given point is a convex QP problem. That nearest point is 
called the metric projection of the given point onto the polyhedral 
convex set. 
In this chapter we will see that the metric projection from a 
given point onto a moving polyhedral convex set is Lipschitz con- 
tinuous with respect to the perturbations on the right-hand-sides of 
the linear inequalities defining the set. The property leads to a sim- 
ple sufficient condition for Lipschitz continuity of a locally unique 
solution of parametric variational inequalities with a moving poly- 
hedral constraint set. Applications of these results to traffic network 
equilibrium problems will be discussed in detail. 
17.1 Preliminaries 
We will study sensitivity of solutions to a parametric variational in- 
equality (PVI, for brevity) with a parametric polyhedral constraint. 
Let 
K(X) = {x E Rn : Ax 2 A, x 2  01, 
(17.1) 
where A E RrXn 
is a given matrix. Let M c Rm be any subset and 
f : Rn x M -+ Rn be a given function. Consider the following PVI 

292 
1 7. Quadratic Programming under Linear Perturbations, III 
depending on a pair of parameters (p, A) E M x A 
Find x E K(A) such that 
(f(x,p),y-x) 2 0  for all y E K(A). 
(17.3) 
Assume that 3 is a solution of the following problem 
Find x E K(X) 
such that 
x,p),y-x) 2 0  for all Y E  K(J), 
(17.4) 
where (ji, i )  E M x A are given parameters. 
Our aim is to prove that under some appropriate conditions on f 
in a neighborhood of (z, fi) and no conditions on the matrix A, there 
exist k > 0 and neighborhoods X, U, V of Z, ji, and i, 
respectively, 
such that 
(i) For every (p, A) E (M n U )  x (An V) there is a unique solution 
x = x(p, A) of (17.3) in X ;  
(ii) For every (p, A), (p', A') E (M n U) x (A n V), 
To this aim, in Section 17.2 we obtain a property of the metric 
projection onto a moving polyhedral convex set which can be stated 
simply, as follows: For a given a matrix A E RrXn 
there exists a 
constant kl > 0  such that for all y E Rn and A, A' E A, we have 
where K(A) and A are defined by (17.1) and (17.2), PK(x)y is the 
unique point in K(A) with the minimal distance to y. (The map 
PK(X)(.) 
is said to be the metric projection onto K(A).) 
Property (17.5) is established by using a result on linear com- 
plementarity problems in Mangasarian and Shiau (1987). Then the 
scheme for proving Lemma 2.4 in Dafermos (1988) enables us to get, 
in Section 17.3, the desired sensitivity result for PVI. The latter can 
be interpreted as a condition for Lipschitz continuity of the equi- 
librium flow in a traffic network with changing costs and demands. 
This fact is considered in Section 17.4. 

1 7.2 Projection onto a Moving Polyhedral Convex Set 
293 
17.2 Projection onto a Moving Polyhe- 
dral Convex Set 
To establish property (17.5) we will consider PK(x)y as the unique 
solution of a quadratic program with parameters (y, A). By the stan- 
dard procedure (see Murty (1976)) we reduce this program to an 
equivalent linear complementarity problem. Although the assump- 
tion on uniqueness of solutions of Theorem 3.2 in Mangasarian and 
Shiau (1987) is violated in our LCP problem, we will show that the 
partition method for obtaining that theorem is well adequate for 
our purpose. 
So, let y E Rn and A E A (see (17.2)) be given. From the 
definition it follows that J := PK(x)~ 
is the unique solution of the 
problem 
Minimize Ilx - y1I2 subject to Ax 2 A, x 2 0, 
which is equivalent to the following one 
Minimize (-2yTx + xTx) subject to Ax > A, x > 0. (17.6) 
It is clear that (17.6) is a particular case of the following convex QP 
problem 
1 
Minimize - x T ~ x  + cTx subject to Ax 2 A, x > 0, 
(17.7) 
2 
where c E Rn, D is a symmetric positive semidefinite matrix. In- 
deed, (17.7) becomes (17.6) if one takes c = -2y and D = 2E, 
where E denotes the unit matrix of order n. 
The next lemma follows easily from Corollary 3.1 and the con- 
vexity of problem (17.7). 
Lemma 17.1. Vector J E Rn is a solution of (17.7) if and only if 
there exists rj E RT such that 
is a solution to the following LCP problem: 
where 
D 
-AT 
M := ( A  
) and 
g := (:A). 
(17.9) 

294 
17. Quadratic Programming under Linear Perturbations, 111 
We set s = n + r. For any subset J c (1, . , s), observe (see 
Mangasarian and Shiau (1987), p. 591) that every solution of the 
following system of 2s linear equalities and inequalities 
is a solution of (17.8). For every J c (1, . . , s), symbol Q(J) 
denotes the set of all vectors q such that (17.10) has a solution. Note 
that Q(J) is a closed convex cone which is called a complementary 
cone of (M, q) (see Murty (1976), Mangasarian and Shiau (1987)). 
The union u{Q(J) : J C (1,. . . ,s)) is the set of all q such that 
(17.8) is solvable. 
For each subset J c (1, 
, s), according to Corollary 7.3, we 
can find a constant 0 = OJ > 0 such that if z1 is a solution of (17.10) 
at q = q1 and the solution set of (17.10) at q = q2 is nonempty, then 
there exists a solution z2 of (17.10) at q = q2 such that 
Let us set 
Ice = max{OJ : J c { l , . . .  ,s)). 
(17.11) 
The next technical lemma is crucial for applying Corollary 7.3 
to linear complementarity problems. 
Lemma 17.2. (See Mangasarian and Shiau (1987), p. 591) Let 
ql, q2 E RS be two distinct vectors. Assume that for every t E [0, 11 
system (17.8) is solvable for q = q(t) := (1 - t)ql + tq2. Then there 
is a partition 0 = to < tl < . . . < te = 1 such that for every 
2 E (1,-.,Q), 
q(ti-1) E Q(Ji), 
q(ti) E Q(Ji) for some Ji c (1, . , s). 
(17.12) 
The proof of this lemma is based on the observation that the 
intersection of each complementary cone of (17.8) with the segment 
[ql, q2] is a closed interval (which may reduce to a single point or 
to the empty set). Since (17.8) is solvable for every q E [ql, q2], this 
segment is contained in the union of such intervals. Excluding some 
redundant intervals in that union and let ti be 0, 1, or a point in 
the intersection of two neighbouring intervals, we get the desired 
partition. 
The following theorem will be useful for obtaining the results in 
Section 17.3. 

17.2 Projection onto a Moving Polyhedral Convex Set 
295 
Theorem 17.1. Given a matrix A E RTXn, define the sets K(A) 
and A by (17.1) and (17.2). Then there exists a constant k1 > 0 
such that 
IIPK(x~)Y 
- PK(X)YI~ I 
k1 IIA' - All, 
(17.13) 
for all y E Rn and A, A' E A, where PK(x)y is the metric projection 
of y onto K(A). 
F'rom the discusion at the beginning of this section we see that 
Theorem 17.1 is a direct consequence of the next result. 
Theorem 17.2. (See Cottle et al. (1992), p. 696) Let A E RrXn, 
K(A) and A be defined as in (17.1) and (17.2). Let D E REXn be a 
positive definite matrix. Define M and q by (17.9), ko by (17.11). 
Then for every A, A' E A and c, c' E Rn we have 
where x(c, A) and x(c', A') are the unique solution of (17.7) at the 
parameters (c, A) and (c', A'), respectively. 
Proof. We will follow the arguments for proving Theorem 3.2 in 
Mangasarian and Shiau (1987). Let there be given vectors A, A' E A 
and c, c' E Rn. We set 
c(t) = (1 - t)c + t c', A(t) = ( 1  - t ) A  + tA', 
q(t) = (1 - t)ql + tq2 for every t E [ O , l ] .  
If A = A' and c = c', then (17.14) holds. Consider the other case 
where at least one of these equalities does not hold. Then we have 
q1 # q2. From the definition we see that A is a closed convex cone. 
Thus A(t) E A for every t E [O,l]. This means that K(A(t)) # 0 
for every t E [0, 11. Since D is assumed to be a symmetric positive 
definite matrix, for each t E [O,1] program (17.7), where (c(t), A(t)) 
are in the place of (c, A), must have a unique solution, denoted by 
<(t). Using Lemma 17.1 we find a vector q(t) E Rr such that 
is a solution of (17.8), where 

296 
17. Quadratic Programming under Linear Perturbations, III 
(Note that vector ~ ( t )  
may not be uniquely defined.) Hence, accord- 
ing to Lemma 17.2 there is a partition 0 = to < tl < . . - < te = 1 
such that for every 1 5 i 5 Q condition (17.12) holds. 
Consequently, for every 1 5 i 5 Q vectors q(ti-1) and q(ti) belong 
to the cone Q(Ji) for a subset Ji c (1, 
+ 
.
a
,
 s). Hence the systems 
of linear equalities and inequalities 
are solvable. Let 
 ti) = (;it;) 
be a solution of (17.15). According to Corollary 7.3 there exists a 
solution 
of (17.16) satisfying 
IIF(ti) - F(ti-1)II < ko (ti - ti-l)llql - q211. 
(17.17) 
Since z(ti) solves (17.15) it also solves (17.8) at q = q(ti). By 
virtue of Lemma 17.1, ((ti) is a solution of (17.7), where (c, A) = 
(c(ti), A(ti)). As the latter problem has a unique solution, we have 
c(ti) = ((ti). Similarly, since z(tiWl) solves (17.16) it also solves 
(17.8) at q = q(ti-1). Hence, ((ti-1) = [(ti-1). These facts and 
(17.17) imply 
\\((ti) - t(ti-l)ll 5 ko (ti - ti-1)Ilq1 - q211. 
Consequently, 
e 
Since ((te) = ((1) = x(c' , A') and ((to) = ((0) = x(c, A), we obtain 
IIx(~', A') - X(C, A) 11 < Ice (Ilc' - '11 + 11'' 
- 
The proof is complete. 

1 7.3 Application to Variational Inequalities 
297 
17.3 Application to Variational Inequal- 
ities 
Consider problem (17.3) and suppose that for a pair (p, 5) E M x 
A vector Z is a solution of (17.4). Following Dafermos (1988) we 
assume that there exist neighborhoods X of 3, U of p, and two 
constants a > 0,1 > 0, such that 
for all p, p' in M n U, x, x' in X, and 
for all p E M n U, x and x' in X. Without loss of generality we 
can assume that X is a polyhedral convex set and a < 1. Condi- 
tion (17.18) means that f is locally Lipschitz at (z, p). Condition 
(17.19) means that f (., p) is locally strongly monotone around Z 
with a common coefficient for all p E M n U. Using the notation of 
Dafermos (1988) we put 
where p > 0 is a fixed number and PK(x)nx 
y is the metric projection 
of y onto K(X) n X. Let us consider a number p satisfying 
For every X E A such that K(X)nX # 0, Lemma 2.2 from Dafermos 
(1988) shows that 
for all x and x' in X, p E M n U, where 
According to the Banach contractive mapping principle, there is a 
unique vector x = x(p, A) E X satisfying 

298 
17. Quadratic Programming under Linear Perturbations, III 
For the map K(X) defined by (17.1) we apply Corollary 7.3 to find 
an 0 > 0 such that if X,X1 E A and x E K(X), then there exists 
x' E K(X1) satisfying 
Since 3 E K(X), from (17.25) it follows that there is a neighborhood 
Vl of X such that 
K (A) n X # 0 for every 
X E A f7 Vl. 
(17.26) 
Since X is a polyhedral convex set we can find a matrix C of order 
rl x n and a vector b E Rrl such that X = {x E Rn : Cx 2 b). 
Therefore 
So, taking (17.26) into account we can apply Theorem 17.1 for sys- 
tem (17.27) to choose a constant kl > 0 such that 
for all y E Rn, X and A' in A n 6. 
(Note that k1 depends not only 
on A but also on C, that is, on the neighborhood X.) 
Lemma 17.3. Let (17.18) and (17.19) be fulfilled. Assume that 
kl > 0 is a constant satisfying (17.28). Then for any p > 0 satisfying 
(17.21) there exist neighborhoods U and V of j2 and 1, respectively, 
such that: 
(i) For every (p, A) E ( M  n U) x (An V) vector x(p, A) E X defined 
by (17.24) is the unique solution of (17.3) in X; 
(ii) For all p, p1 E M n 0 and A, XI E A n  V ,  
where p is defined in (17.23). 
This lemma can be proved similarly as Lemma 2.1 in Yen (1995a). 
Note that the scheme given on p. 424 in Dafermos (1988) is our 
key argument. 
Proof. Fixing any p satisfying (17.21), for every (p, A) E ( M  n 
U )  x (An Vl) we denote by x(p, A) the unique vector in X satisfying 

1 7.3 Application to Variational Inequalities 
299 
(17.24). Let (p, A), (p', A') E (M n U )  x (A f l  V,). Using (17.22) we 
have 
Formula (17.20) and the fact that the metric projection onto a fixed 
closed convex set is a nonexpansive mapping yield 
From (17.18), (17.29) and (17.30) it follows that 
I I x ( P ' ,  
A') - 4 4  411 
1 
5 -(pzll~' 
- f IIPK(A1)nX~(~,A) 
- PK(A)"xY(P, 
A)\\). 
1 - P  
(17.31) 
Now we can find neighborhoods U and V of p and 
such that (i) 
and (ii) are fulfilled. Indeed, since It. is a solution of (l7.4), it is easy 
to show that 
= p ~ ( i ) [ z  
- ff 
p)]. 
Therefore It. is the unique fixed point in X of the map G(., ,ii, 
A) 
defined by (17.20). Hence 3 = x(p, X). Using this and putting 
1J = 3 - p f (It., p), we substitute (p, A) = (p, 5 )  into (17.31) to obtain 

300 
17. Quadratic Programming under Linear Perturbations, 111 
Taking account of (17.28) we have 
for all (p',A1) E ( M  n U )  x ( A  n Vl). Due to (17.32), there exist 
neighborhoods U c U of ,!i 
and V c Vl of 1 such that x(p,A) 
belongs to the interior of X for every ( p ,  A) E ( M  n 0) 
x ( A  n V ) .  
For such a pair ( p ,  A), since the vector x(p, A) satisfies (17.24) and 
belongs to the interior of X ,  Lemma 2.1 in Dafermos (1988) shows 
that x ( p ,  A) is the unique solution of (17.3) in X. We have thus 
established the first assertion of the lemma. The second assertion 
follows easily from (17.31) and (17.28). 
Now we can formulate the main result of this section. 
Theorem 17.3. Let 3 be a solution of (17.4). If conditions (17.18) 
and (17.19) are satisfied, then there exist constants kp > 0 and 
kX > 0, neighborhoods T f  of p and V of i such that: 
(i) For every ( p ,  A) E ( M  n U )  x ( A  n V )  there exists a unique 
solution of (17.3) in X ,  denoted by x(p, A); 
(ii) For all (p',A1), ( p ,  A) E ( M  n U )  x ( A n  V ) ,  
Proof. It suffices to apply Lemma 17.3 with any p satisfying 
(17.21), and put 
17.4 Application to a Network Equilib- 
rium Problem 
Let us consider problem (17.3) with K ( A )  defined in the following 
way: 
K ( A )  = { x  E Rn : x = Z h ,  r h =  A, h 2 01, 
(17.33) 
where h E RP, A E Rr, I? is an r x p-matrix, Z is an n x pmatrix. 
This is the variational inequality model for the traffic equilibrium 
problem (see Smith (1979), Dafermos (1980), De Luca and Maugeri 

1 7.4 Application to a Network Equilibrium Problem 
30 1 
(1989), Qiu and Magnanti (1989)) which we have studied in Chapter 
9. The matrices, the vectors, and the function f (x, p) in the model 
have the following interpretations (see Qiu and Magnanti (1989), 
and Chapter 9 of this book): 
x = vector of flows on arcs, h = vector of flows on paths, 
r = the incidence matrix of the relation "paths - OD (origin- 
destination) pairs", Z = the incidence matrix of the relation 
L L a r ~ ~  
- paths", X = vector of demands for the OD pairs, 
f (x,p) = vector of the costs on arcs when the network is 
loaded with flow x, p = parameter of the perturbation of the 
costs on arcs. 
For a given pair (p, A), solutions of (17.3) are interpreted as the 
equilibrium flows on the traffic network, corresponding to vector X 
of demands an function f (., p) of the costs on arcs. 
Since K(X) is defined by (17.33) rather by (17. I), Theorem 17.1 
cannot be applied directly. However, a property like the one in 
(17.13) is valid. 
Lemma 17.4. Assume that K(X) is given by (17.33), H(X) := { h  E 
RP : I'h = A, h 2: O), A := {A E Rr : H(X) # 0). Then there 
exists a constant k > 0 such that 
for every y E Rn and A, A' E A. 
Proof. Since K(X) = Z (H(X)) := { Z h  : h E H(X)), then {A E 
RT : K(X) # 0) = {A E Rr : H(X) # 0) =A. For each X E A and 
y E Rn we consider two quadratic programming problems: 
Minimize JJy - x1I2 subject to x - Z h  = 0, r h  = A, h 2 0; 
(17.35) 
and 
Minimize lly - Zhl12 subject to r h  = A, h 2 0. 
(17.36) 
Observe that if h is a solution of (17.36) then x := Zh is a solution 
of (17.35) and, hence, x = PK(~)IJ. 
Moreover, since (17.35) has a 
unique solution, for arbitrary two solutions hl, h2 of (17.36) we 
have Zhl = Zh2, and x := Zhl = Zh2 is the unique solution 
of (17.35). Also, note that (17.36) is solvable, because (17.35) is 
solvable. 

302 
1 7. Quadratic Programming under Linear Perturbations, 111 
Since \Iy-Zhl12 = Ilyl12-2yTZh+hTZTZh, (17.36) is equivalent 
to the following problem 
1 
Minimize - h T ~ h + c T h  subject to A h 2  1, h>O, (17.37) 
2 
where c := -2ZTy, D := 2ZTZ, 
A : =  (-lry), and A:= (:A). 
It is clear that D is a symmetric positive semidefinite matrix. Hence 
the scheme for reducing a convex quadratic programming problem 
to an equivalent LCP problem, recalled in Section 17.2, is applicable 
to (17.37). In particular, Lemma 17.1 asserts that h E RP is a 
solution of (17.37) if and only if there exists rl E R2T such that 
is a solution of the LCP problem (17.8), where 
D 
-AT 
M := ( A  
) and q := (_c~). 
Let s := p + 27- and ko be the constant defined by (17.11). We are 
going to prove that k := &kOllZII is a constant satisfying (17.34). 
Indeed, let y E Rn and A, XI E A be given arbitrarily. For each 
t E [0, I] we set 
q(t) = (1 - t)ql + tq2, X(t) = (1 - t)X + tX1, i(t) = (1 - t ) i  + ti', 
(17.38) 
where 
Since (17.36) has a solution for every X E A, (17.37) is solvable for 
each 

17.4 Application to a Network Equilibrium Problem 
303 
where X E A. Consequently, for every t E [O,1] problem (17.8) is 
solvable for q = q(t), where q(t) is defined in (17.38). Applying 
Lemma 17.2 one can find a partition 0 = to < tl < . . . < te = 1 
such that for every 1 < i < Q condition (17.12) holds. Therefore, 
for each 1 5 i < Q there is a subset Ji c (1, 
a
,
 s) such that the 
vectors q(ti-1) and q(ti) belong to the cone Q(Ji). This implies that 
(17.15) and (17.16) are solvable. Let 
be a solution of (17.15). According to Corollary 7.3, there is a 
solution 
of (17.16) satisfying 
Ilx(ti) -  ti-l)II 5 eJ\Iq(ti) - q(ti-1)II = e J ( t i  - ti-l)llql - q211. 
(17.39) 
Since x(ti) solves (17.15) it also solves (17.8) at q = q(ti). Hence h(ti) 
is a solution of (17.37) at A = A(ti) and of (17.36) at X = X(ti). Thus, 
as remarked before, x := Zh(ti) is the unique solution of (17.35) at 
X = A(&). In our notation, 
Arguing similarly with the solution z(ti-1) of (17.16) we conclude 
that 
Zh(ti-1) = P K ( A ( ~ ~ - ~ ) ) Y .  
(17.41) 
As (17.39) implies 
(17.40) and (17.41) yield 

304 
17. Quadratic Programming under Linear Perturbations, III 
Since X(to) = X(0) = X,X(te) = X(1) = A' and k =.\/2k011211, the 
above estimation implies (17.34). 
0 
Now, let K(X) be defined by (17.33) and Z be a solution of (17.4). 
Let the function f (x, p) satisfy conditions (17.18) and (17.19). Again, 
we assume that X is a polyhedral convex set and a < 1. Let 
h E H ( X )  be a vector such that Z = Zh. Then (3,h) is a solution at 
parameter X = 7\ of the following system of linear inequalities and 
equalities 
X - Z h = O ,  
r h = X ,  h 2 0 .  
(17.42) 
Applying Corollary 7.3 we can find 0 > 0 such that for every X E A 
there exists a solution (x, h) of (17.42) satisfying 
This implies that x E K ( A )  and llx - z 11 5 OllX - 7\ 1 1 .  Consequently, 
there is a neighborhood Vl of 7\ such that 
K ( X ) n X  # 0 for every 
X E A n % .  
(17.43) 
Now, let C be a matrix of order rl x n and b be a vector from RT1 , 
such that X = { x  E Rn : C x  2 b). We have 
K(X) n X = { X  E Rn : x = Zh, CX 2 b, r h  = A, h 2 0 )  
= { x  E Rn : x = Zh, CZh 2 b, l7h = A, h 2 0). 
Since this set has the same structure as the one in (17.33), taking 
account of (17.43) we can apply Lemma 17.4 (see also the arguments 
for proving it) to find a constant k > 0 such that 
for all y E Rn and A, A' E A n  Vl. 
Using property (17.44) instead of (17.28) one can see that Lemma 
17.3 (with k1 being replaced by k) holds for the case where K(X) is 
given by (17.33). This fact gives us the following result. 
Theorem 17.4. Let K(X) be defined by (17.33) and Z be a solution 
of (l7.4), where ,G E M x A is a given pair of parameters. If con- 
ditions (17.18) and (17.19) are satisfied, then there exist constants 
kp > 0 and kX > 0, neighborhoods 0 of ,!i 
and V of 
such that: 
(i) For every (p, A) E (M n U )  x ( A  n V )  there exists a unique 
solution of (17.3) in X ,  denoted by x(p, A); 

1 7.5 Commentaries 
(ii) For all (p', A'), (p, A) E (M n u) x ( A n  V ) ,  
Theorem 17.4 can be interpreted by saying that: "In a trafic 
network with locally Lipschitz, locally strongly monotone function 
of costs on arcs, the equilibrium arcs flow is locally unique and is a 
locally Lipschitz function of the perturbations of costs on arcs and 
of the vector of demands." 
17.5 Commentaries 
The material of this chapter is taken from Yen (1995b). 
Stability and sensitivity analysis is a central topic in the opti- 
mization theory (see Robinson (1979), Fiacco (1983), Bank et al. 
(1983), Malanowski (1987), Levitin (1994), Bonnans and Shapiro 
(2000), and references therein). Recently, much attention has been 
devoted to stability and sensitivity analysis of variational inequali- 
ties. Although the methods here resemble those used in nonlinear 
parametric mathematical programming, specific features of varia- 
tional inequalities pose new problems. The case of PVI with a fixed 
constraint set is studied, for example, in Kyparisis (1988). The 
case of PVI whose constraint set depends on a parameter is consid- 
ered, for example, in Tobin (1986), Dafermos (1988), Harker and 
Pang (1 990), Kyparisis (1990) , Yen (l995b), Domokos (lggg), Kien 
(2001). 


Chapter 18 
Continuity of the Solution 
Map in Affine Variational 
Inequalities 
This chapter presents a systematic study of the usc and lsc proper- 
ties of the solution map in parametric AVI problems. We will follow 
some ideas of Chapters 10 and 11, where the usc and lsc proper- 
ties of the Karush-Kuhn-Tucker point set map in parametric QP 
problems were investigated. 
In Section 18.1 we obtain a necessary condition for the usc prop- 
erty of the solution map at a given point. We will show that the ob- 
tained necessary condition is not a sufficient one. Then, in the same 
section, we derive some sufficient conditions for the usc property of 
the solution map and consider several useful illustrative examples. 
The lsc property of the solution map is studied in Section 18.2. 
18.1 USC Property of the Solution Map 
Consider the following AVI problem 
Find x E A(A, b) 
such that 
(Mx + q,y - x) 2 0 for all y E A(A,b), 
(18.1) 
which depends on the parameter (M, A, q, b) E Rnxn x Rmxn x Rn x 
Rm. Here A(A, b) := {x E Rn : Ax 2 b). We will abbreviate (18.1) 
to AVI(M, A, q, b), and denote its solution set by Sol(M, A, q, b). 
The multifunction (M,A,q, b) H Sol(M,A,q, b) is called the 
solution map of (18.1) and is abbreviated to Sol(.). For a fixed 

308 
18. Continuity of the Solution Map in AVIs 
pair (q, b) E Rn x Rm, the symbol Sol(., ., q, b) stands for the mul- 
tifunction (M, A) H Sol(M, A, q, b). Similarly, for a fixed pair 
(M, A) E Rnxn x Rmxn, the symbol Sol(M, A, ., 
a )  stands for the 
multifunction (q, b) H Sol(M, A, q, b). 
According to Theorem 5.3, solutions of an AVI problem can be 
characterized via Lagrange multipliers. Namely, x E Rn is a solution 
of AVI(M, A, q, b) if and only if there exists X E Rm such that 
Mx - ATA + q = 0, Ax > b, 
X 2 0, 
(A, Ax - b) = 0. (18.2) 
Vector X E Rm satisfying (18.2) is called a Lagrange multiplier 
corresponding to x. 
The following theorem gives a necessary condition for the usc 
property of the multifunction Sol(., ., q, b) and the solution map 
Sol(.). 
Theorem 18.1. Let (M, A, q, b) E Rnxn x Rmxn x Rn x Rm. Suppose 
that the solution set Sol(M, A, q, b) is bounded. Then, the following 
statements are valid: 
(i) If the multifunction Sol(-, 
a ,  q, b) is upper semicontinuous at 
(M, A), then 
Sol(M,A,O,O) = (0). 
(18.3) 
(ii) If the solution map Sol(.) is upper semicontinuous at (M, A, q, b), 
then (18.3) is valid. 
Proof. (We shall follow the proof scheme of Theorem 10.1). Clearly, 
if Sol(.) is upper semicontinuous at (M, A, q, b) then the multifunc- 
tion Sol(., 
a ,  q, b) is upper semicontinuous at (M, A). Hence (i) im- 
plies (ii). It remains to prove (i). 
To obtain a contradiction, suppose that Sol(M, A, q, b) is bounded, 
the multifunction Sol(., ., q, b) is upper semicontinuous at (M, A), 
and 
Sol(M, A, 0, 0) # (0). 
(18.4) 
Since 0 E Sol(M, A, 0,O) , (18.4) implies that there exists a nonzero 
vector 3 E Rn such that 3 E Sol(M, A, 0,O). Hence there exists 
X E Rm such that 
M? - 
= 0, A? 2 0, 
X 2 0, 
(X, Az) = 0. 
(18.5) 
For every t E (0, I), we define 

18.1 USC Property of the Solution Map 
309 
We shall show that for every t E ( 0 , l )  there exist Mt E Rnxn and 
At E Rmxn such that 
Atxt 2 4  At 2 0 ,  
(18.8) 
(At, Atxt - b) = 0, 
(18.9) 
and (lMt - MI1 -t 0, [[At -All + O  as t -+ 0. 
We will find Mt and At in the following forms: 
where the matrices Mo E Rnxn and A. E Rmxn will be chosen 
so that they do not depend on t. If Mt and At are of the forms 
described in (18.10), then we have 
and 
(At, Atxt - b) = (t-'X, t - I  A? + AO? - b). 
On account of (18.5)) we have 
(It, Atxt - b) = (t-'T;, t-lAZ + AoZ - b) 
= (t-lr;, AoZ - b). 
It is clear that conditions (18.7)-(18.9) will be satisfied if we choose 
Mo and A. so that 
A,? - b = 0. 
(18.12) 
Let 3 = 
. . , z,) and let I = {i : Zi # 0). Since Z # 0, I is 
nonempty. Let io be any element in I. We define 

310 
18. Continuity of the Solution Map in AVIs 
where each ci (1 5 i 5 n) is a column with m components given by 
the following formula 
{fi)-lb 
for i = i o  
Ci = 
for i # io. 
We check at once that this A. satisfies (18.12). Similarly, we define 
where each di (1 5 i 5 n) is a column with n components given by 
q) 
for i = io 
for i # io. 
This Mo satisfies (18.11). So, for these matrices Mo and Ao, con- 
ditions (18.7)-(18.9) are satisfied. According to Theorem 5.3, we 
have 
xt E SO1(Mt , At , q, b) 
for every t E (0,l). Since Sol(M, A, q, b) is bounded, there exists 
a bounded open set V C Rn such that Sol(M, A, q, b) c V. Since 
Sol(., a ,  q, b) is upper semicontinuous at (M, A), there exists 6 > 0 
such that 
Sol(M1, A', q, b) c V 
for all (MI, A') E Rnxn x Rmxn satisfying II(M1, A') - (M, A)[\ < 6. 
As 11 Mt - M 11 < 2-'l26 and IJAt - All < 2-'l26 for all t > 0 small 
enough, we have Sol(Mtl At, q, b) c V for all t > 0 small enough. 
Hence xt E V for every t > 0 sufficiently small. This is impossible, 
because V is bounded and llxt 11 = t-l ll?ill -f +m as t -+ 0. The 
proof is complete. 
It is easy to verify that the solution set Sol(M, A, 0,O) of the ho- 
mogeneous AVI problem AVI(M, A, 0,O) is a closed cone. Condition 
(18.3) requires that this cone consists of only one element 0. 
We can characterize condition (18.3) as follows. 
Proposition 18.1 (cf. Proposition 3 in Gowda and Pang (1994a)). 
Condition (18.3) holds if and only zf for every (q, b) E Rn x Rm the 
set Sol(M, A, q, b) is bounded. 
Proof. Suppose that (18.3) holds. If there is a pair (q, 6) E Rn x Rm 
such that Sol(M, A, q, b) is unbounded, there exists an unbounded 
sequence {xk) such that xk E Sol(M, A, q, 6) for all k. Without loss 
of generality we can assume that IlxkII # 0 for a11 k, Ilxkll t m and 

18.1 USC Property of the Solution Map 
31 1 
+ for some 3 E Rn with l l + l l  = 1 as k -+ co. Since 
xk E Sol(M, A, q, b), for any y E A(A, b) we have 
for all k. Dividing the first inequality in (18.13) by llx"127 the second 
inequality by llxkll, and letting k + co we get 
Since A(x" 
+) = Axk + A3 2 6, we have xk + + E A(A,b). 
Substituting xk + + for y in the first inequality in (18.13), we have 
(Mxk + f 3) > 0. Dividing this inequality by llxkll and letting 
k + co we get 
(Mz, 2) 2 0. 
(18.15) 
From (18.14) and (18.15) it follows that 
Let z be any point in A(A, 0). Clearly, x" 
z E A(A, 6). Sub- 
stituting xk + z for y in the first inequality in (18.13), we have 
(Mxk + +, z) 2 0. Dividing this inequality by llxkll and letting 
k -t co we get (M+,z) 2 0. From this and (18.16) we deduce 
that (M+, z - 2) 2 0. Since z E A(A, 0) is arbitrary, we conclude 
that + E Sol(M, A, 0,O) \ (0). This contradicts our assumption that 
Sol(M, A, 0,O) = (0). 
We now suppose that Sol(M, A, q, b) is bounded for every (q, b) E 
Rn x Rm. Since the solution set Sol(M, A, 0,O) is a cone, from its 
boundedness we see that (18.3) is valid. 
0 
The following example shows that condition (18.3) and the bound- 
edness of Sol(M, A, q, b) are not sufficient for the upper semiconti- 
nuity of Sol(-) at (M, A, q, b). 
Example 18.1. Consider problem (18.1) with 
For each t E (0, I), we set 
At = 

312 
18. Continuity of the Solution Map in AVIs 
Using Theorem 5.3, we find that 
and 
Since (t-l, 0) E Sol(M, At, q, b) for all t E (0, I), for any bounded 
open subset V c R2 containing Sol(M, A, q, b) there exists bv > 0 
such that 
Sol(M, At, 4, b, \ V # 0 
for every t E (O,bv). Since llAt -All -f 0 as t -f 0, we conclude 
that Sol(-) is not upper semicontinuous at (M, A, q, b). 
Our next goal is to find some sets of conditions which guarantee 
that the solution map Sol(.) is upper semicontinuous at a given 
point (M, A, q, b) E Rnxn x Rmxn x Rn x Rm. 
In order to obtain some sufficient conditions for the usc prop- 
erty of Sol(.) to hold, we will pay attention to the behavior of the 
quadratic form (Mu, v) on the cone A(A, 0) = {v E Rn : Av 2 0) 
and to the regularity of the inequality system Ax 2 b. 
The next proposition shows that, for a given pair (M, A) E 
RnXn x Rmxn, for almost all (q, b) E Rn x Rm the set Sol(M, A, q, b) 
is bounded (may be empty). 
Proposition 18.2 (cf. Lemma 1 in Oettli and Yen (1995)). Let 
(M,A) E Rnxn x Rmxn. The set 
W = {(q, b) E Rn x Rm : Sol(M, A, q, b) is bounded) 
(18.17) 
is of full Lebesgue measure in Rn x Rm. 
Proof. The set Sol(M, A, q, b) is nonempty if and only if system 
(18.2) has a solution (x, A) E Rn x Rm. We check at once that 
(18.2) has a solution if and only if there exists a subset a C I, 
where I := {1,2,. . . ,m), such that the system 
M X - A ~ A , + ~ = o ,  
A,x = b,, 
A, 2 0, 
(18.18) 
Ahx 2 b8, 
= 0. 
has a solution (x, A,, A,), where 6 = I \ a. If a = 0 (resp., 6 = 0) 
then the terms indexed by a (resp., by 6) are absent in (18.18). 
Hence 

18.1 USC Property of the Solution Map 
313 
where 
Sol(M, A, q, b), 
:= {x E Rn : there exists A E Rm such that 
(x, A,, A,) 
is a solution of (18.18)). 
Note that the set Sol(M, A, q, b) is unbounded if and only if there 
exists a C I such that Sol(M, A, q, b), is unbounded. We denote by 
S(M, A, q, b), the set of all (x, A,) 
E Rn x ~
1
~
1
 
satisfying the system 
where la1 is the number of elements of a .  Let 
0, = {(q, b) E Rn x Rm : S(M, A, q, b), 
is unbounded). 
Obviously, if Sol(M, A, q, b), is unbounded then S(M, A, q, b), is 
unbounded. So, on account of (18.19), we have 
{(q, b) E Rn x Rm : Sol(M, A, q, b) is unbounded) 
c u { n , : a c I ) .  
(18.20) 
Clearly, 
(q, b) E Rn x Rm : det G, = 0 and there exists 
(x, A) E Rn x Rm such that G,(;a) = (L)), 
where 
- 
-M 
A2 
[A, 
0 1 .  
If det G, = 0, then the image of the linear operator 
- 
corresponding to the matrix Ma is a proper linear subspace of Rn x 
~ 1 ~ 1 .  
Hence 0, is a proper linear subspace of Rn x Rm. So the set 
0, is of Lebesgue measure 0 in Rn x Rm. Therefore, from (18.20) 
we deduce that the set 
0 := {(q, b) E Rn x Rm : Sol(M,A,q, b) is unbounded) 
is of Lebesgue measure 0 in Rn x Rm. Since W = (Rn x Rm) \ 0 
by (18.17), the desired conclusion follows. 

314 
18. Continuity of the Solution Map in AVIs 
In Example 18.1, the system Ax > 0 is irregular and Sol(.) 
is not upper semicontinuous (M, A, q, b). The following theorem 
shows that if the system Ax 2 0 is regular, then condition (18.3) is 
necessary and sufficient for the usc property of Sol(.). 
Theorem 18.2. Let (Ad, 
A, q, b) E Rnxn x Rmxn x Rn x Rm. Sup- 
pose that the system Ax 2 0 is regular. Then, (18.3) holds i f  and 
only if for every (q, b) E Rn x Rm the solution map Sol(.) is upper 
semicontinuous at (M, A, q, b). 
Proof. Suppose that (18.3) holds. We have to prove that for every 
(q, b) E Rn x Rm the solution map Sol(.) is upper semicontinuous 
at (M, A, q, b). To obtain a contradiction, suppose that there is a 
pair (q, 6 )  E Rn x Rm such that Sol(.) is not upper semicontin- 
uous at (M, A, q, b). Then there exist an open set V C Rn con- 
taining Sol(M, A, ij, b), a sequence {(Mk, A', qk, b") 
converging to 
(M, A, q, b) in RnXn x Rmxn x Rn x Rm and a sequence {xk} in Rn 
such that 
xk E S O ~ ( M ~ ,  
A ~ ,  
qk, bk) \ V. 
(18.21) 
Let y be any point in A(A, 6). Since the system Ax 2 0 is regular, 
the system Ax > 6 is regular (see Lemma 13.2). By Lemma 13.1, 
there exists a subsequence {kt} of {k) and a sequence {ykl} in Rn 
converging to y such that 
A"~" > bkl for all kt. 
(18.22) 
From (18.21) and (18.22) it follows that 
We claim that {xkt 1) is bounded. If {x"} is unbounded, then without 
loss of generality we can assume that 11xp11 # 0 for all K ,  llxklll + oo 
and Ilxklll-'xkl -t 3 for some 3 E Rn with l l ~ l l  = 1, as k' -f oo. 
Dividing the first inequality in (18.23) by IIxkl 11, the second in- 
equality in (18.23) by llxk1112, and letting k' + oo, we get 
Let v be any point in A(A, 0). As Ax 2 0 is regular, by Lemma 
13.1 there exists a subsequence {k") of {k'} and a sequence {vk") 
converging to v such that 
~~~~v~~~ 
2 0 for a11 kt'. 
(18.25) 

18.1 USC Property of the Solution Map 
By (18.23) and (18.25) we have 
A ~ " ( x ~ "  
+ vkl') 2 bk" for a11 krr 
From (18.21) it follows that 
( M ~ ' ~ X ~ "  
+ qk", y - xk") 2 0 for all y E A(A~", 
bkl'). (18.26) 
Substituting xkl' + vklt for y in (18.26), we obtain 
Dividing (18.27) by IIX"'II 
and letting k" --t oo we get (Mz, v) 2 0. 
From the last inequality and (18.26) it follows that 
(Mz, v - 5) 2 0, 
Az 2 0. 
(18.28) 
Since v is arbitrary in A(A,O), from (18.28) we deduce that 3 E 
Sol(M, A, 0,O) \ (0) , a contradiction. Thus the sequence {xk' ) is 
bounded. There is no loss of generality in assuming that xkl -t 2 
as kt --+ oo. By (18.21), 
Since xkl E Rn \ V and V is open, we have 2 E Rn \ V, which is 
impossible. We have thus proved that for every (q, b) E Rn x Rm 
the map Sol(.) is upper semicontinuous at (M, A, q, b). 
Conversely, suppose that for every (q, b) E Rn x Rm the solution 
map Sol(.) is upper semicontinuous at (M, A, q, b). By Proposi- 
tion 18.1, there exists (ij, 6) E Rn x Rm such that Sol(M, A, ij, b) is 
bounded. Therefore, according to Theorem 18.1, condition (18.3) 
is satisfied. The proof is complete. 
Theorem 18.3. Let (M, A, b) E Rnxn x Rmxn x Rm. Let 
If K- = (0) and the system Ax 2 b is regular then, for any q E Rn, 
the solution map Sol(-) is upper semicontinuous at (M, A, q, b). 
Proof. Suppose that K- = (0) and the system Ax 2 b is regular. 
Suppose that the assertion of the theorem is false. Then there exists 
q E Rn such that Sol(.) is not upper semicontinuous at (M, A, q, b). 
Thus there exist an open set V c Rn containing Sol(M, A, q, b), 

316 
18. Continuity of the Solution Map in AVIs 
a sequence {(Mk, Ak, qk, bk)} converging to (M, A, q, b) in RnXn x 
Rmxn x Rn x Rm, and a sequence {xk} in Rn such that 
x% SO~(M" A', q" bk) \ V for all k. 
(18.29) 
Let y E A(A, b). Since Ax 2 b is regular, by Lemma 13.1 there 
exist a subsequence {kt) of {k} and a sequence {y"} converging to 
y in Rn such that 
A"~" 2 bkl for all kt. 
(18.30) 
F'rom (18.29) and (18.30) it follows that 
(M"x" + qkl, ykl - xkl) 2 0 for all kt. 
(18.31) 
We claim that the sequence {xkl) is bounded. Indeed, if {x"} 
is unbounded then without loss of generality we can assume that 
IIxklII # 0 for a11 kt, IIxklII + oo and llxklll-lxkl -+ 
21 as K + oo for 
some a E Rn with llflll = 1. Dividing the inequalities in (18.31) by 
11x" [ I 2  and letting kt -+ oo, we get 
Since Axk1 2 bkl, we have A21 2 0. Since 21 # 0, from the last in- 
equality and (18.32) we deduce that K- # {0), which is impossible. 
Thus the sequence {x") is bounded; so it has a convergent subse- 
quence. Without loss of generality we can assume that {xkl} itself 
converges to some Z in Rn. F'rom (18.31) it follows that 
(MZ + q,y - 3) 2 0. 
(18.33) 
Since y is arbitrary in A(A, b) and 1 E A(A, b), from (18.33) we 
deduce that Z E Sol(M,A,q, b) c V. On the other hand, since 
xk E S01(Mk, Ak, qk7 bk) \ V for every k and V is open, it follows 
that z @ V. We have thus arrived at a contradiction. The proof is 
complete. 
Remark 18.1. It is a simple matter to show that if K- = {0} then 
(18.3) holds. 
Corollary 18.1. Let (A, b) E Rmxn x Rm. Suppose that the system 
Ax 2 b is regular and the set A(A, b) is bounded. Then, for any 
( M ,  q) E Rnxn x Rn, the solution map Sol(.) is upper semicontinuous 
at (M, A, 9, b). 

18.1 USC Property of the Solution Map 
317 
Proof. Since Ax > b is regular, A(A, b) # 0. Since A(A, b) is 
bounded, we deduce that A(A, 0) = (0). Let there be given any 
(M,q) E Rnxn x Rn. Since K- c A(A,O) and A(A,O) = {0), we 
have K- = (0). By Theorem 18.2, Sol(.) is upper semicontinuous 
at (M, A, 9, b). 
Corollary 18.2. Let (M, A, b) E RnXn x RmXn x Rm. Suppose 
that the matrix M is positive definite and the system Ax 2 b is 
regular. Then, for every q E Rn, the solution map Sol(.) is upper 
semicontinuous at (M, A, q, b). 
Proof. Since M is positive definite, we have vTMv > 0 for every 
nonzero v E Rn. Hence K- = (0). Applying Theorem 18.2 we see 
that, for every q E Rn, Sol(.) is upper semicontinuous at (M, A, q, b). 
0 
The next examples show that without the regularity condition 
imposed on the system Ax 2 b, the assertion of Theorem 18.2 may 
be false or may be true, as well. 
Example 18.2. Consider problem (18.1), where m = n = 1, M = 
[I], A = [0], q = 0, and b = 0. It is easily seen that Ax > b is 
irregular. For every t E (0, I), let At = [t2] and bt = t. We have 
Sol(M, A, q, b) = {0), 
Sol(M, At, q, bt) = {t-I). 
Fix any bounded open set V satisfying Sol(M, A, q, b) = (0) C 
V. Since t - I  E Sol(M, At, q, bt) for every t E (0, I), the inclusion 
Sol(M, At, q, bt) c V does not hold for t > 0 small enough. Since 
At t 
A, bt t 
b as t + 0, the multifunction Sol(.) cannot be upper 
semicontinuous at (M, A, q, b). 
Example 18.3. Consider problem (18. I), where n = 1, m = 2, 
In this case we have 
Obviously, the system Ax 2 b is irregular. Since Sol(M, A, q, b) c 
A(A, b) , we conclude that Sol(M, A, q, b) = 0. Moreover, we can 

318 
18. Continuity of the Solution Map in AVIs 
find 6 > 0 such that for any (A', b') E Rmxn x Rm with 11 (A', b') - 
(A, b) 11 5 6, A(A', b') = 0. Hence the multifunction Sol(.) is upper 
semicontinuous at (M, A, q, b). 
Lemma 18.1 (cf. Lemma 3 in Robinson (1977) and Lemma 10.2 
in this book). Let (A, b) E RmXn x Rm. Let 
Then, the system Ax > b is regular if and only i f  (A, b) < 0 for 
every X E Ao[A] \ (0). 
Proof. Suppose that Ax > b is regular, that is there exists xo E Rn 
such that Axo > b. Let yo = Axo - b > 0. Let X E Ao[A] \ {0), that 
is ATX= 0, X 2 0 and X # 0. We have 
Conversely, suppose that (A, b) < 0 for every X E A. [A] \ (0). If 
Ax > b is irregular then there exists a sequence {by converging to 
b in Rm such that the system Ax > bk has no solutions for all k. 
According to Theorem 22.1 from Rockafellar (1970), there exists a 
sequence {Ak) in Rm such that 
Since X" 
0, by the homogeneity of the inequalities in (18.34) we 
can assume that IIX"I 
= 1 for every k. Thus the sequence {Ak) 
has a convergent subsequence. We can suppose that the sequence 
{Ak) itself converges to some 5 with llXll = 1. Taking the limits in 
(18.34) as k -t oo we get 
Hence 5 E Ao[A] \ (0) and (5, b) > 0. We have arrived at contra- 
diction. 
0 
Theorem 18.4. Let (M, A, b) E RnXn x Rmxn x Rm. Let 
If K f  = (0) and the system Ax 2 -b is regular then, for any q E 
Rn, the solution map Sol(.) is upper semicontinuous at ( M ,  A, q, b). 
Proof. Suppose that Kt = (0) and the system Ax > -b is regular. 
Suppose that the assertion of the theorem is false. Then there exists 

18.1 USC Property of the Solution Map 
319 
q E Rn such that Sol(.) is not upper semicontinuous at (M, A, q, b). 
Thus there exist an open set V c Rn containing Sol(M, A, q, b), 
a sequence {(M" Ak, qk, bk)) converging to (M, A, q, b) in RnXn x 
Rmxn x Rn x Rm, and a sequence {xk) in Rn such that 
xk E SOI(M~, 
A" qk, bk) \ V for all k. 
(18.35) 
Since xk E  sol(^^, Ak, q< bk), there exists Ak such that 
We claim that the sequence {(xk, Ak)) is unbounded. Indeed, if 
{(xk, Ak)) is bounded then {xk) and {Ak) are bounded sequences, 
so each of them has a convergent subsequence. Without loss of 
generality we can assume that x
h
 t, Ak -+ 1 as k -+ m, where 
t E Rn and 
E Rm. From (18.36) and (18.37) we deduce that 
Hence 3 E Sol(M, A, q, b) C V. This is impossible because V is 
open and xX" E Sol(Mk,A~qX", 
b" \ V for all k. Thus {(xk, AX")) is 
unbounded. 
There is no loss of generality in assuming that (1 (x" AX") 11 # 0 for 
'7 
I( (
~
~
7
 
'IC) 
11 
''7 
where 11 (a, 5) 11 = 1. Dividing the equality in (18.36) and the first 
two inequalities in (18.37) by ll(xkl AX") 1 1 ,  the equality in (18.37) by 
11 (xk, Ak) l2 
and letting k -+ m we get 
From (18.39) it follows that (Ma, a) = 0 and A: > 0. Thus fl E K+. 
As K f  = {0), we have 
= 0. By (18.38), llXll = 1. Since a = 0, 
from (18.39) we deduce that 
E &[A]. Since Ax > -b is regular, 
by Lemma 18.1 we have (1, -b) < 0. From (18.36) and (18.37) it 
follows that 
(M~x' + qk, xk) = (Ak, bk) . 
(18.40) 

320 
18. Continuity of the Solution Map in AVIs 
If there exists an integer ko such that (A" bk) 1 0 for all k 2 ko 
then without loss of generality we can suppose that (A" bb") 5 0 for 
all k. Dividing the last inequality by 11 (x" Ak) 11 and letting k + co 
we have 
(X, b) 1 0, 
which contradicts the fact that (A, -b) < 0. So there exists a sub- 
sequence {kt} of {k} such that (Akt, bkl) > 0. From this and (18.40) 
we deduce that 
for all k'. If {xkl} is bounded then, dividing the equality in (18.41) 
by II(xk', Ak')II and letting k' + co we obtain (X, b) = 0, which 
contradicts the fact that (X, -b) < 0. Thus {xkl} is unbounded. 
Without loss of generality we can assume that IIxk'lI # 0 for all k' 
and the sequence llxktll-lxkl itself converges to some 6 E Rn with 
11611 = I. Dividing the inequality in (18.41) by 1
1
~
~
~
1
1
~
 
and letting 
k' + co we get (M6,6) 2 0. By (18.37), we have A ~ ~ X "  2 bb"' for 
all k'. Dividing the last inequality by llxklll and letting k' + co we 
get A6 2 0. From this and the inequality (M6, 6) 2 0 we see that 
6 E K+ \ {0), contrary to the assumption K+ = (0). The proof is 
complete. 
0 
Remark 18.2. It is easily verified that if K+ = (0) then (18.3) 
holds. 
Corollary 18.3. Let (A, b) E RmXn x Rm. Suppose that the system 
Ax 2 -b is regular and A(A, b) is nonempty and bounded. Then, 
for any (M, q) E Rnxn x Rn the solution map Sol(.) is upper semi- 
continuous at (M, A, q, b). 
Proof. Let (M, q) E RnXn x Rn be given arbitrarily. Since A(A, b) 
is nonempty and bounded, A(A, 0) = (0). As K+ c A(A,O), we 
have K+ = (0). Applying Theorem 18.4 we conclude that the 
solution map Sol(.) is upper semicontinuous at (M, A, q, b). 
Corollary 18.4. Let (M, A, b) E RnXn x Rmxn x Rm. If the matrix 
M is negative definite and the system Ax 2 -b is regular then, 
for any q E Rn, the solution map Sol(.) is upper semicontinuous at 
(M7 A1 9, b). 
Proof. Since M is negative definite, we have vTMv < 0 for any 
nonzero vector v E Rn. Since K+ C {v E Rn : (Mv, v) 2 01, we 
deduce that K+ = (0). Applying Theorem 18.4 we see that, for 
every q E Rn, Sol(.) is upper semicontinuous at (M, A, q, b). 

18.2 LSC Property of the Solution Map 
321 
Corollary 18.5. Let (A, b) E RmXn x Rm. Suppose that A(A, 0) = 
(0) and (A, b) # 0 for every nonzero X satisfying ATX = 0, X 2 0. 
Then, for any (M, q) E Rnxn x Rn, Sol(.) is upper semicontinuous 
at (M, A, q, b). 
Proof. Let (M, q) E RnXn 
x Rn be given arbitrarily. Since A(A, 0) = 
{0), we have K- = K+ = (0). Since A[A] = {A E Rm : ATX = 
0, X 2 O), we see that A[A] is a pointed convex cone. From the 
assumption that (A, b) # 0 for every nonzero X E A[A] we deduce 
that one and only one of the following two cases occurs: 
(i) (A, b) > 0 for every X E A[A] \ (0); 
(ii) (A, b) < 0 for every X E A[A] \ (0). 
In case (i), the system Ax 2 b is regular by Lemma 18.1. Since 
K- = {O), the desired conclusion follows from Theorem 18.2. In 
case (ii), Ax 2 - b is regular by Lemma 18.1. Since K f  = (01, the 
assertion follows from Theorem 18.4. 
The following examples show that without the regularity of the 
system Ax 2 -b, the assertion in Theorem 18.4 may be true or may 
be false, as well. 
Example 18.4. Consider problem (18.1), where n = 1, m = 2, 
We can check at once that K- = K f  = {0), A(A, b) = {x E R : 
0 5 x < 11, and A(A, -b) = 0. Note that the system Ax 2 b is 
regular and the system Ax 2 -b is irregular. The usc property of 
Sol(.) at (M, A, q, b) follows from Theorem 18.2. 
Example 18.5. Consider problem (18.1), where n = 2, m = 3 
and (M, A, q, b) is defined as in Example 18.1. For this problem we 
find that K f  = (0) and A(A, -b) = 0. In particular, the system 
Ax 2 -b is irregular. As it has been shown in Example 18.1, the 
solution map Sol(.) is not upper semicontinuous at (M, A, q, b). 
18.2 LSC Property of the Solution Map 
In this section we will find necessary and sufficient conditions for 
the lower semicontinuity of the solution map in parametric AVI 
problems. 

322 
18. Continuity of the Solution Map in AVIs 
Theorem 18.5. Let (M, A, c, b) E RnXn x Rmxn x Rn x Rm. If the 
multifunction Sol(M, A, ., .) is lower semicontinuous at (q, b) then 
(a) the set Sol(M, A, q, b) is finite, and 
(b) the system Ax 2 b is regular 
Proof. We will omit the easy proof of (b). To prove (a), for every 
index set I C (1, . , m) we define a matrix SI E R("+I'I)~(~+~I~), 
where 1 I[ is the number of elements of I, by setting 
(If I = 8 then we set SI = M). Let 
PI = { ( u , ~ )  
E Rn x Rm : (c) = SI(;*) 
for some (x, A) E Rn x Rm , 1 
and 
P = U { P I :  I c {l,...,m), detSI = 0) 
If det SI = 0 then 
is a proper linear subspace of Rn x Rm. 
Hence, by the Baire Lemma (see Brezis (1987)), P is nowhere dense 
in Rn x Rm. Then there exists a sequence {(qk, bk)) converging to 
(q, b) in Rn x Rm such that (-q< bk) $ P for all k .  
Fix any 3 E Sol(M, A, q, b). As the multifunction Sol(M, A, -, .) 
is lower semicontinuous at (q, b), there exist a subsequence {(q", bkl)} 
of {(qk, bk)) and a sequence {x"} converging in Rn to 3 such that 
xkl E Sol(M, A,qkl, bkl) for all kl. Since xk" 
 sol(^, 
b"), 
there exists Akl E Rm such that 
For every $, let Ikl = {i E {I. . . , m) : A? > 0). It is clear that 
there must exists an index set I C (1, . . . , m) such that Ik, = I for 
infinitely many kl. Without loss of generality, we may assume that 
Ik, = I for all kl. By (18.42), we have 

18.2 LSC Property of the Solution Map 
323 
We claim that SI is nonsingular. Indeed, if det SI = 0 then, by 
(18.43) and by the definitions of PI and P, we have 
which is impossible because (-qk, bk) ) P for all k. So SI is non- 
singular. From (18.43) it follows that 
Letting 1 + oo, we get 
If I = 8 then (18.44) has the following form 
lim xh = MM-I(-q). 
l+co 
By (18.44), the sequence {A:} must converge to some XI 2 0 in 
RIII. As xkl + Z, from (18.44) we obtain 
Let 
Z = { ( x , X )  E Rn x Rm : there exists such J c { l , . . . , m }  
that det SJ # 0 and (:J) 
= S;' (i:) } 
and 
X = { x  E Rn : there exists X E Rm such that ( x ,  A) E Z } .  
Similarly as in the proof of Theorem 11.3, X is a finite set. From 
(18.45) we conclude that 3 E X. We have thus proved that 
In particular, Sol(M, A ,  q, b) is a finite set. The proof is complete. 
0 

324 
18. Continuity of the Solution Map in AVIs 
The following example shows that, in general, the above condi- 
tions (a) and (b) are not sufficient for the lsc property of Sol(M, A, a ,  
a )  
at (4, b). 
Example 18.6. Consider the AVI problem (18.1) in which n = 
2, m = 3, and 
For every E > 0, we set q ( ~ )  
= (-1, -E). 
We can perform some 
computations to show that 
and Sol(M, A, q ( ~ ) ,  
b) = {(0,2)) for every E > 0. It is clear that the 
system Ax 2 b is regular. Let 
Since Sol(M, A, q, b) n V = {(1,0)) and Sol(M, A, q ( ~ ) ,  
b) n V = 0 
for every E > 0, we conclude the multifunction Sol(M, A, ., .) is not 
lower semicontinuous at (q, b) . 
Let (M, A, q, b) E Rnxnx Rmxnx Rnx Rm. Let x E Sol(M, A, q, b) 
and let X E Rm be a Lagrange multiplier corresponding to x. Let 
I = {1,2,. . . ,m), and let K and J be defined, respectively, by 
(11.14) and (11.15). We set I. = K U J. 
The following theorem gives a sufficient condition for the lsc 
property of the multifunction Sol(M, A, -, .) at a given point. By 
definition (see (Cottle et al. 1992)), a square matrix is called a 
P-matrix if the determinant of each of its principal submatrices is 
positive. 
Theorem 18.7. Let (M, A, q, b) E Rnxnx Rmxn x Rn x Rm. Suppose 
that 
(i) the set Sol(M, A, q, b) is finite, nonempty, 
(ii) the system Ax 2 b is regular, 
and suppose that for every x E Sol(M, A, q, b) there exists a Lagrange 
multiplier X corresponding to x such that at least one of the following 
conditions holds: 

18.2 LSC Property of the Solution Map 
325 
(cl) vTMv 2 0 for every v E Rn with AIov 2 0 and ( M x + ~ ) ~ v  
= 
0, 
(c3) J = 8, K # 8, and the system {Ai : i E K )  is linearly 
independent, 
(c4) J # 8, K = 8, M is nonsingular and AJM-lA$ is a P- 
matrix, 
where K and J are defined via (x, A) by (11.14) and (11.15). Then, 
the multifunction Sol(M, A, ., -) is lower semicontinuous at (q, b). 
Proof. 
Since Sol(M, A, q, b) is nonempty, in order to prove that 
Sol(M, A, a ,  .) is lower semicontinuous at (q, b) we only need to show 
that, for any x E Sol(M, A, q, b) and for any open neighborhood Vx 
of x, there exists 6 > 0 such that 
SO~(M, 
A, q', b') n V, # 0 
(18.46) 
for every (q', b') E Rn x Rm satisfying 11 (q', b') - (q, b) 11 < 6. 
Let x E Sol(M, A, q, b) and let Vx be an open neighborhood 
of x. By our assumptions, there exists a Lagrange multiplier X 
corresponding to x such that at least one of the four conditions 
(c1)-(c4) holds. 
Consider the case where (cl) holds. Since Sol(M, A, q, b) is finite 
by (i), x is an isolated solution of (18.1). By Corollary 10 in Gowda 
and Pang (1994b), from our assumptions it follows that there exists 
6 > 0 such that (18.46) is valid for every (q', b') satisfying 11 (q', b') - 
(4, b, 11 < 6. 
Analysis similar to that in the proof of Theorem 11.4 shows that 
if one of the conditions (c2)-(c4) holds then we can find 6 > 0 such 
that (18.46) is valid for every (q', b') satisfying 11 (q', b') - (q, b) 11 < 6. 
So we can conclude that the multifunction Sol(M, A, ., .) is lower 
semicontinuous at (q, b). 
0 
It is interesting to see how the conditions (c1)-(c4) in Theorem 
18.7 can be verified for concrete AVI problems. 
Writing the necessary optimality conditions for the QP problems 
in Examples 11.3-11.5 as AVI problems we obtain the following 
examples. 
Example 18.7. Consider problem (18.1) with n = 2, m = 2, 

326 
18. Continuity of the Solution Map in AVIs 
We can show that Sol(M, A, q, b) = {z,?, Z), where 3, it, Z are the 
- 
same as in Example 11.3. Note that X := (0,O) is a Lagrange multi- 
plier corresponding to 2. We observe that conditions (i) and (ii) in 
Theorem 18.7 are satisfied and, for each point x E Sol(M, A, q, b), 
either (cl) or (c2) is satisfied. More precisely, if x = Z or x = 2 then 
(cl) is satisfied; if x = Z then (c2) is satisfied. By Theorem 18.7, 
the multifunction Sol(M, A, a ,  .) is lower semicontinuous at (q, b). 
Example 18.8. Consider problem (18.1) with n = 2, m = 3, 
It is easy to verify that Sol(M, A, q, b) = (3, it, Z), where Z, 2, Z 
- 
are the same as in the preceding example. Note that X := (0,0,0) 
is a Lagrange multiplier corresponding to Z. For x = 3 and x = 2, 
assumption (cl) is satisfied. For the pair (Z,X), we have K = 0, 
J = (3). Since A j  = (1 O), M-' = M, we get AJM-lA$ = 1. 
Thus (c4) is satisfied. By Theorem 18.7, Sol(M, A, ., -) is lower 
semicontinuous at (q, b). 
Example 18.9. Consider problem (18.1) with n = 2, m = 3, 
We can show that Sol(M, A, q, b) = {z, it, Z), where z = (2, -I), it = 
(2,l) and Z = (2,O). Note that X := (0,0,1) is a Lagrange multi- 
plier corresponding to Z. For x = 3 and x = i, condition (cl) is 
satisfied. For the pair (Z,X), we have K = {3), J = 0. Since 
assumption (c3) is satisfied. According to Theorem 18.7, S(D, A, ., .) 
is lower semicontinuous at (q, b). 
Let (M, A, q, b) E Rnxn x Rmxn x Rn x Rm. Let x E Sol(M, A, q, b) 
and let X E Rm be a Lagrange multiplier corresponding to x. We 
define K and J by (11.14) and (11.15), respectively. Consider the 
case where both the sets K and J are nonempty. If the matrix 

18.3 Commentaries 
327 
is nonsingular, then we denote by Sj the Schur complement of QK 
in the following matrix 
This means that 
SJ = [AJ o]&$[AJ 0lT 
Since M is not assumed to be symmetric, Sj is not necessarily a 
symmetric matrix. Consider the following condition: 
(c5) J # 0, K  # 0, the system {Ai : i E K )  is linearly in- 
dependent, vTMv # 0 for every nonzero vector v satisfying 
AKv = 0, and Sj is a P-matrix. 
It can be shown that if J # 0, K  # 0, the system {Ai 
: i E K )  
is linearly independent, and vTMv # 0 for every nonzero vector v 
satisfying AKv = 0, then QK is nonsingular. 
It can be proved that the assertion of Theorem 18.7 remains 
valid if instead of (c1)-(c4) we use (c1)-(c3) and (c5). 
18.3 Commentaries 
The material of this chapter is taken from Lee et al. (2002b-d) 
As it has been noted in Chapter 5 ,  the affine variational in- 
equality problem is a natural and important extension of the linear 
complementarity problem. Both of the problems are closely related 
to the Karush-Kuhn-Tucker conditions in quadratic programming. 
Various continuity properties of the solution maps in parametric 
affine variational inequality problems and parametric linear com- 
plementarity problems have been investigated (see Robinson (1979, 
1981), Bank et al. (1982), Jansen and Tijs (1987), Cottle et al. 
(1992), Gowda (1992), Gowda and Pang (1994a), Oettli and Yen 
(1995), Gowda and Sznajder (1996), and the references therein). 


References 
1. J.-P. Aubin (1984): Lipschitz behavior of solutions to convex 
minimization problems, Mathematics of Operations Research, 
9, 87-111. 
2. J.-P. Aubin and H. Frankowska (1990): Set- Valued Analysis, 
Birkhauser, Berlin. 
3. A. Auslender and R. Cominetti (1990), First- and second- 
order sensitivity analysis of nonlinear programs under direc- 
tional constraint qualification conditions, Optimization, 2 1, 
351-363. 
4. A. Auslender and P. Coutat (1996): Sensitivity analysis for 
generalized linear-quadratic problems, Journal of Optimiza- 
tion Theory and Applications, 88, 541-559. 
5. A. Auslender and M. Teboulle (2003): Asymptotic Cones and 
Functions in Optimization and Variational Inequalities, 
Springer, New York, 2003. 
6. H. Attouch, H. and R.J.-B. Wets (1993): Quantitative sta- 
bility of variational systems, 11. A Framework for nonlinear 
conditioning, SIAM Journal on Optimization, 3, 359-381. 
7. B. Bank, J. Guddat, D. Klatte, B. Kummer and K. Tam- 
mer (1982): Non-Linear Parametric Optimization, Akademie- 
Verlag, Berlin. 
8. B. Bank and R. Hansel (1984): Stability of mixed-integer 
quadratic programming problems, Mathematical Programming 
Study, 21, 1-17. 
9. E. M. Bednarczuk (1995), Berge-type theorems for vector op- 
timization problems, Optimization, 32, 373-384. 
10. J. Benoist (1998): Connectedness of the efficient set for strictly 
quasiconcave sets, Journal of Optimization Theory and Appli- 
cations, 96, 627-654. 

330 
References 
11. J. Benoist (2001): Contractibility of the efficient set in strictly 
quasiconcave vector maximization, Journal of Optimization 
Theory and Applications, 110, 325-336. 
12. M. J. Best and N. Chakravarti (1990): Stability of linearly 
constrained convex quadratic programs, Journal of Optimiza- 
tion Theory and Applications, 64, 43-53. 
13. M. J. Best and B. Ding (1995): On the continuity of minimum 
in parametric quadratic programs, Journal of Optimization 
Theory and Applications, 86, 245-250. 
14. E. Blum and W. Oettli (1972): Direct proof of the existence 
theorem for quadratic programming, Operations Research, 20, 
165-167. 
15. J. F. Bonnans and A. Shapiro (1998): Optimization problems 
with perturbations: A guided tour, SIAM Reviews 40, 228- 
264. 
16. J. F. Bonnans and A. Shapiro (2000): Perturbation Analysis 
of Optimization Problems, Springer-Verlag, New York. 
17. H. Brezis (1987): Analyse fonctionnelle, 2" tirage, Masson, 
Paris. 
18. G.-Y. Chen and N. D. Yen (1993): On the variational inequal- 
ity model for network equilibrium, Preprint 3.196, Gruppo di 
Ottimizzazione e Ricerca Operativa, University of Pisa. 
19. E. U. Choo and D. R. Atkins (1982): Bicriteria linear frac- 
tional programming, Journal of Optimization Theory and Ap- 
plications, 36, 203-220. 
20. E. U. Choo and D. R. Atkins (1983): Connectedness in multi- 
ple linear fractional programming, Management Science, 29, 
250-255. 
21. E. U. Choo, S. Schaible and K. P. Chew (1985): Connect- 
edness of the efficient set in three-criteria quasiconcave pro- 
gramming, Cahiers du Centre d7Etudes de Recherche Ope'ra- 
tionnelle, 27, 213-220. 

References 
33 1 
22. F. H. Clarke (1975): Generalized gradients and applications, 
Transactions of the America1 Mathematical Society, 205, 247- 
262. 
23. F. H. Clarke (1983): Optimization and Nonsmooth Analysis, 
John Wiley & Sons, New York. 
24. L. Contesse (1980): Une caractkrisation complkte des minima 
locaux en programmation quadratique, Numerische Mathe- 
matik, 34, 315-332. 
25. R. W. Cottle, J.-S. Pang and R. E. Stone (1992): The Linear 
Complementarity Problem, Academic Press, New York. 
26. B. D. Craven (1988): Fractional Programming, Heldermann 
Verlag, Berlin, 1988. 
27. S. Dafermos (1980): Traffic equilibrium and variational in- 
equalities, Transportation Science, 14, 42-54. 
28. S. Dafermos (1988): Sensitivity analysis in variational inequal- 
ities, Mathematics of Operations Research, 13, 421-434. 
29. J. W. Daniel (1973): Stability of the solution of definite quad- 
ratic programs, Mathematical Programming, 5, 41-53. 
30. G. B. Dantzig (1963): Linear Programming and Extensions, 
Princeton University Press, Princeton. 
31. M. De Luca and A. Maugeri (1989): Quasi-variational inequal- 
ities and applications to equilibrium problems with elastic de- 
mand, In Nonsmooth Analysis and Related Topics (F. H. Clarke, 
V. F. Demyanov and F. Giannessi, Eds.), Plenum Press. 
32. P. H. Dien (1985): On the regularity condition for the ex- 
tremal problem under locally Lipschitz inclusion constraints, 
Applied Mathematics and Optimization, 13, 151-161. 
33. A. Domokos (1999): Solution sensitivity of variational in- 
equalities, Journal of Mathematical Analysis Applications, 230, 
381-389. 
34. A. L. Donchev and R. T. Rockafellar (1996): Characteriza- 
tions of strong regularity for variational inequalities over poly- 
hedral convex sets, SIAM Journal on Optimization, 6, 1087- 
1105. 

332 
References 
35. B. C. Eaves (1971): On quadratic programming, Management 
Science, 17, 698-71 1. 
36. F. Facchinei and J.-S. Pang (2003): Finite-Dimensional Vari- 
ational Inequalities and Complementarity Problems, Volumes 
I and 11, Springer, New York. 
37. A. V. Fiacco (1983): Introduction to Sensitivity and Stability 
Analysis in Nonlinear Programming, Academic Press, New 
York. 
38. A. V. Fiacco and J. Liu (1995): On the stability of general 
convex programs under Slater's condition and primal solution 
boundedness, Optimization, 32, 291-299. 
39. M. Frank and P. Wolfe (1956): An algorithm for quadratic 
programming, Naval Research Logistics Quarterly, 3, 95-110. 
40. C. B. Garcia (1973): Some classes of matrices in linear com- 
plementarity theory, Mathematical Programming, 5, 299-310. 
41. J. Gauvin (1977): A Necessary and sufficient regularity condi- 
tion to have bounded multipliers in nonconvex programming, 
Mathematical Programming, 12, 136-138. 
42. J. Gauvin and J. W. Tolle (1977): Differential stability in 
nonlinear programming, SIAM Journal on Control and Opti- 
mixation, 15, 294-31 1. 
43. J. Gauvin and F. Dubeau (1982): Differential properties of 
the marginal function in mathematical programming, Mathe- 
matical Programming Study, 19, 101-119. 
44. F. Giannessi (1980): Theorems of alternative, quadratic pro- 
grams and complementarity problems, In Variational Inequal- 
ity and Complementarity Problems (R. W. Cottle, F. Gian- 
nessi and J.-L. Lions, Eds.), Wiley, New York, pp. 151-186. 
45. M. S. Gowda (1992): On the continuity of the solution map 
in linear complementarity problems, SIAM Journal on Opti- 
mization, 2, 619-634. 
46. M. S. Gowda and J.-S. Pang (1992): On solution stability of 
the linear complementarity problem, Mathematics of Opera- 
tions Research, 17, 77-83. 

References 
333 
47. M. S. Gowda and J.-S. Pang (1994a): On the boundedness 
and stability of solutions to the affine variational inequality 
problem, SIAM Journal on Control and Optimization, 32, 
421-441. 
48. M. S. Gowda and J.-S. Pang (199413): Stability analysis of 
variational inequalities and nonlinear complementarity prob- 
lems, via the mixed linear complementarity problem and de- 
gree theory, Mathematics of Operations Research, 19, 831- 
879. 
49. M. S. Gowda and R. Sznajder (1996): On the Lipschitzian 
properties of polyhedral multifunctions, Mathematical Pro- 
gramming, 74, 267-278. 
50. J. Guddat (1976) : Stability in convex quadratic parametric 
programming, Mathematishe Operationsforschung und Statis- 
tik, 7, 223-245. 
51. P. T. Harker and J.-S. Pang (1990): Finite-dimensional varia- 
tional inequality and nonlinear complementarity problems: A 
survey of theory, algorithms and applications, Mathematical 
Programming, 48, 161-220. 
52. P. Hartman and G. Stampacchia (1966): On some non-linear 
elliptic differential-functional equations, Acta Mathernatica, 
115, 271-310. 
53. J.-B. Hiriart-Urruty (1985): Images of connected sets by semi- 
continuous multifunctions,, Journal of Mathematical Analysis 
and Applications, 11 1, 407-422. 
54. T. N. Hoa, T. D. Phuong and N. D. Yen: Linear fractional vec- 
tor optimization problems with many components in the solu- 
tion sets, Preprint 2004105, Institute of Mathematics, Hanoi. 
(Submitted) 
55. R. Horst and H. Tuy (1990): Global Optimization, Springer- 
Verlag, Berlin, 1990. 
56. Y. D. Hu and E. J. Sun (1993): Connectedness of the efficient 
set in strictly quasiconcave vector maximization, Journal of 
Optimization Theory and Applications, 78, 613-622. 

334 
References 
57. N. Q. Huy and N. D. Yen (2004a): Contractibility of the so- 
lution sets in strictly quasiconcave vector maximization on 
noncompact domains. Accepted for publication in Journal of 
Optimization Theory and Applications. 
58. N. Q. Huy and N. D. Yen (2004b): Remarks on a conjec- 
ture of J. Benoist, Preprint 2004106, Institute of Mathemat- 
ics, Hanoi. (Submitted) 
59. R. Janin (1984): Directional derivative of the marginal func- 
tion in nonlinear programming, Mathematical Programming 
Study, 21, 110-126. 
60. M. J. M. Jansen and S. H. Tijs (1987): Robustness and non- 
degenerateness for linear complementarity problems, Mathe- 
matical Programming, 37, 293-308. 
61. B. T. Kien (2001): Solution sensitivity of a generalized vari- 
ational inequality, Vietnam Journal of Mathematics, 29, 97- 
113. 
62. D. Kinderlehrer and G. Stampacchia (1980): An Introduction 
to Variational Inequalities and Their Applications, Academic 
Press, New York-London. 
63. D. Klatte (1985): On the Lipschitz behavior of optimal so- 
lutions in parametric problems of quadratic optimization and 
linear complementarity, Optimization, 16, 819-831. 
64. S. Kum, G. M. Lee and N. D. Yen (2004): Remarks on the sta- 
bility of linear fractional vector optimization problems. (Ma- 
nuscript) 
65. J. Kyparisis (1988): Perturbed solutions of variational prob- 
lems over polyhedral sets, Journal of Optimization Theory and 
Applications, 57, 295-305. 
66. J. Kyparisis (1990): Sensitivity analysis for nonlinear pro- 
grams and variational inequalities with nonunique multipliers, 
Mathematics of Operations Research, 15, 286-298. 
67. G. M. Lee, D. S. Kim, B. S. Lee and N. D. Yen (1998): Vector 
variational inequalities as a tool for studying vector optimiza- 
tion problems, Nonlinear Analysis, 34, 745-765. 

References 
335 
68. G. M. Lee, N. N. Tam and N. D. Yen (2002a): On a class of 
optimal value functions in quadratic programming. Accepted 
for publication in Journal of Global Optimization. 
69. G. M. Lee, N. N. Tam and N. D. Yen (2002b): Continuity of 
the solution map in quadratic programs under linear pertur- 
bations. (Submitted) 
70. G. M. Lee, N. N. Tam and N. D. Yen (2002~) 
: Lower semicon- 
tinuity of the solution maps in quadratic programming under 
linear perturbations, Part I: Necessary conditions. (Submit- 
t ed) 
71. G. M. Lee, N. N. Tam and N. D. Yen (2002d): Lower semicon- 
tinuity of the solution maps in quadratic programming under 
linear perturbations, Part 11: Sufficient conditions. (Submit- 
t ed) 
72. G. M. Lee and N. D. Yen (2001): A result on vector varia- 
tional inequalities with polyhedral constraint sets, Journal of 
Optimization Theory and Applications, 109, 193-197. 
73. E. S. Levitin (1994): Perturbation Theory in Mathematical 
Programming and Its Applications, John Wiley & Sons, New 
York. 
74. D. T. Luc (1987): Connectedness of the efficient set in quasi- 
concave vector maximization, Journal of Mathematical Anal- 
ysis and Applications, 122, 346-354. 
75. D. T. Luc (1989): Theory of Vector Optimization, Springer- 
Verlag, Berlin. 
76. A. Majthay (1971): Optimality conditions for quadratic pro- 
gramming, Mathematical Programming, 1, 359-365. 
77. K. Malanowski (1987): Stability of Solutions to Convex Prob- 
lems of Optimization, Springer-Verlag, Berlin-Heidelberg. 
78. C. Malivert (1995): Multicriteria fractional programming, In 
Proceedings of the 2nd Catalan Days on Apllied Mathematics 
(M. Sofonea and J. N. Corvellec, Eds.), Presses Universitaires 
de Perpinan, pp. 189-198. 

336 
References 
79. C. Malivert and N. Popovici (2000): Bicriteria linear frac- 
tional optimization, In Optimization, Lecture Notes in Eco- 
nomic and Mathematical Systems, 481, Springer, Berlin, pp. 
305-319. 
80. 0. L. Mangasarian (1969): Nonlinear Programming, McGraw- 
Hill Book Company, New York. 
81. 0 .  L. Mangasarian (1980) : Locally unique solutions of quadra- 
tic programs, linear and nonlinear complementarity problems, 
Mathematical Programming, 19, 200-212. 
82. 0 .  L. Mangasarian and T. H. Shiau (1987): Lipschitz conti- 
nuity of solutions of linear inequalities, programs and comple- 
mentarity problems, SIAM Journal on Control and Optimiza- 
tion, 25, 583-595. 
83. G. P. McCormick (1967): Second order conditions for con- 
strained minima, SIAM Journal on Applied Mathematics, 15, 
641-652. 
84. L. I. Minchenko and P. P. Sakolchik (1996): Holder behavior of 
optimal solutions and directional differentiability of marginal 
functions in nonlinear programming, Journal of Optimization 
Theory and Applications, 90, 555-580. 
85. B. Mordukhovich (1988): Approximation Methods in Prob- 
lems of Optimization and Control, Nauka, Moscow. (In Rus- 
sian) 
86. B. Mordukhovich (1993): Complete characterization of open- 
ness, metric regularity, and Lipschitzian properties of multi- 
functions, Transactions of the American Mathematical Soci- 
ety, 340, 1-35. 
87. B. Mordukhovich (1994): Generalized differential calculus for 
nonsmooth and set-valued mappings, Journal of Mathematical 
Analysis and Applications, 183, 250-288. 
88. K. G. Murty (1972): On the number of solutions to the com- 
plementarity problem and spanning properties of complemen- 
tarity cones, Linear Algebra and Applications, 5, 65-108. 

References 
337 
87. B. Mordukhovich (1994): Generalized differential calculus for 
nonsmooth and set-valued mappings, Journal of Mathematical 
Analysis and Applications, 183, 250-288. 
88. K. G. Murty (1972): On the number of solutions to the com- 
plementarity problem and spanning properties of complemen- 
tarity cones, Linear Algebra and Applications, 5, 65-108. 
89. K. G. Murty (1976): Linear and Combinatorial Programming, 
John Wiley, New York. 
90. A. Nagurney (1993): Network Economics: A Variational In- 
equality Approach, Kluwer Academic Publishers, Dordrecht. 
91. N. H. Nhan (1995): On the Stability of Linear Complementar- 
ity Problems and Quadratic Programming Problems, Master 
thesis, University of Hue, Hue, Vietnam. 
92. W. Oettli and N. D. Yen (1995): Continuity of the solution 
set of homogeneous equilibrium problems and linear comple- 
mentarity problems, In Variational Inequalities and Network 
Equilibrium Problems ( F. Giannessi and A. Maugeri, Eds.), 
Plenum Press, New York, pp. 225-234. 
93. W. Oettli and N. D. Yen (1996a): Quasicomplementarity prob- 
lems of type Ro, Journal of Optimization Theory and Appli- 
cations, 89, 467-474. 
94. W. Oettli and N. D. Yen (1996b): An example of a bad qua- 
sicomplementarity problem, Journal of Optimization Theorg 
and Applications, 90, 213-215. 
95. M. Patriksson (1999): Nonlinear Programming and Varia- 
tional Inequality Problems. A Unified Approach, Kluwer Aca- 
demic Publishers, Dordrecht. 
96. J.-P. Penot and A. Sterna-Karwat (1986): Parameterized mul- 
ticriteria optimization: Continuity and closedness of optimal 
multifunctions, Journal of Mathematical Analysis and Appli- 
cations, 120, 150-168. 
97. H. X. Phu and N. D. Yen (2001): On the stability of solutions 
to quadratic programming problems, Mathematical Program- 
ming, 89, 385-394. 

338 
References 
98. Y. Qiu and T. L. Magnanti (1989): Sensitivity analysis for 
variational inequalities defined on polyhedral sets, Mathemat- 
ics of Operations Research, 14, 410-432. 
99. S. M. Robinson (1975): Stability theory for systems of in- 
equalities, Part I: Linear systems, SIAM Journal Numerical 
Analysis, 12, 754-769. 
100. S. M. Robinson (1977): A characterization of stability in linear 
programming, Operations Research, 25, 435-477. 
101. S. M. Robinson (1979): Generalized equations and their solu- 
tions, Part I: Basic theory, Mathematical Programming Study, 
10, 128-141. 
102. S. M. Robinson (1980) : Strongly regular generalized equa- 
tions, Mathematics of Operations Research, 5, 43-62. 
103. S. M. Robinson (1981): Some continuity properties of poly- 
hedral multifunctions, Mathematical Programming Study, 14, 
206-214. 
104. S. M. Robinson (1982): Generalized equations and their solu- 
tions, Part 11: Applications to nonlinear programming, Math- 
ematical Programming Study, 19, 200-221. 
105. R. T. Rockafellar (1970): Convex Analysis, Princeton Univer- 
sity Press, Princeton, New Jersey. 
106. R. T. Rockafellar (1982): Lagrange multipliers and subderiva- 
tives of optimal value functions in nonlinear programming, 
Mathematical Programming Study, 17, 28-66. 
107. R. T. Rockafellar (1988): First- and second-order epi-differen- 
tiability in nonlinear programming, Transactions of the Amer- 
ican Mathematical Society, 307, 75-108. 
108. R. T. Rockafellar and R. J.-B. Wets (1998): Variational Anal- 
ysis, Springer, Berlin-Heidelberg, 
109. J.-F. Rodrigues (1987): Obstacle Problems in Mathematical 
Physics, North-Holland Publishing Co., Amsterdam. 
110. S. Schaible (1983): Bicriteria quasiconcave programs, Cahiers 
du Centre d%tudes de Recherche Ope'rationnelle, 25, 93-101. 

References 
339 
111. A. Seeger (1988): Second order directional derivatives in para- 
metric optimization problems, Mathematics of Operations Re- 
search, 13, 124-139. 
112. M. J. Smith (1979): The existence, uniqueness and stability of 
traffic equilibrium, Transportation Research, 13B, 295-304. 
113. R. E. Steuer (1986): Multiple Criteria Optimization: Theory, 
Computation and Application, John Wiley & Sons, New York. 
114. N. N. Tam (1999): On continuity of the solution map in 
quadratic programming, Acta Mathematica Vietnamica, 24, 
47-61. 
115. N. N. Tam (2001a): Sufficient conditions for the stability of 
the Karush-Kuhn-Tucker point set in quadratic programming, 
Optimization, 50, 45-60. 
116. N. N. Tam (2001b): Directional differentiability of the opti- 
mal value function in indefinite quadratic programming, Acta 
Mathematica Vietnamica, 26, 377-394. 
117. N. N. Tam (2002): Continuity of the optimal value function 
in indefinite quadratic programming, Journal of Global Opti- 
mization, 23, 43-61. 
118. N. N. Tam and N. D. Yen (1999): Continuity properties of 
the Karush-Kuhn-Tucker point set in quadratic programming 
problems, Mathematical Programming, 85, 193-206. 
119. N. N. Tam and N. D. Yen (2000): Stability of the Karush- 
Kuhn-Tucker point set in a general quadratic programming 
problem, Vietnam Journal of Mathematics, 28, 67-79. 
120. R. L. Tobin (1986): Sensitivity analysis for variational in- 
equalities, Journal of Optimization Theory and Applications, 
48, 191-204. 
121. D. W. Walkup and R. J.-B. Wets (1969): A Lipschitzian char- 
acterization of convex polyhedra, Proceedings of the American 
Mathematical Society, 23, 167-173. 

340 
References 
122. F. Wantao and Z. Kunping (1993): Connectedness of the ef- 
ficient solution sets for a strictly path quasiconvex program- 
ming problem, Nonlinear Analysis: Theory, Methods & Ap- 
plications, 21, 903-910. 
123. A. R. Warburton (1983): Quasiconcave vector maximization: 
Connectedness of the sets of Pareto-optimal and weak Pareto- 
optimal alternatives, Journal of Optimization Theory and Ap- 
plications, 40, 537-557. 
124. D. E. Ward and G. M. Lee (2001): Upper subderivatives 
and generalized gradients of the marginal function of a non- 
Lipschitzian program, Annals of Operations Research, 101, 
299-312. 
125. J. G. Wardrop (1952): Some theoretical aspects of road traffic 
research, Proceddings of the Institute of Civil Engineers, Part 
I1 , 325-378. 
126. E. W. Weisstein (1999): CRC Concise Encyclopedia of Math- 
ematics, CRC Press, New York. 
127. N. D. Yen (1987): Implicit function theorems for set-valued 
maps, Acta Mathematica Vietnamica, 12, No. 2, 7-28. 
128. N. D. Yen (1995a): Holder continuity of solutions to a para- 
metric variational inequality,Applied Mathematics and Opti- 
mization, 31, 245-255. 
129. N. D. Yen (199513): Lipschitz continuity of solutions of vari- 
ational inequalities with a parametric polyhedral constraint, 
Mathematics of Operations Research, 20, 695-708. 
130. N. D. Yen and N. X. Hung (2001): A criterion for the compact- 
ness of the solution set of a linear complementarity problem, 
In Fixed Point Theory and Applications Vol. 2 (Y. J. Cho, 
J. K. Kim and S. M. Kang, Eds.), Nova Science Publishers, 
New York. 
131. N. D. Yen and T. D. Phuong (2000): Connectedness and sta- 
bility of the solution set in linear fractional vector optimiza- 
tion problems, In Vector Variational Inequalities and Vector 
Equilibria (F. Giannessi, Ed.), Kluwer Academic Publishers, 
Dordrecht, pp. 479-489. 

References 
34 1 
132. N. D. Yen and L. Zullo (1992): Networks with an equilibrium 
condition, Research report, Universitk di Pisa, Pisa, Italy. 
133. E. Zeidler (1986): Nonlinear Functional Analysis and its Ap- 
plications. I: Fixed-Point Theorems, Springer, New York. 

Index 
affine hull, 7 
affine set, 7 
affine variational inequality, 92 
solution interval, 95 
solution ray, 95 
symmetric, 92 
arc, 156 
barycenter, 24 
boundary, 2 
Clarke generalized gradient, 
Clarke normal cone, 16 
Clarke tangent cone, 16 
closure, 2 
coercivity condition, 88 
complementary cone, 294 
concave function, 4 
condition (G), 246 
constrained problem, 2 
constraint set, 2 
convex function 
proper, 4, 6 
convex hull, 4 
convex program, 5 
convex set, 4 
copositivity, 109 
demand, 157 
diameter of a set, 126 
direction of recession, 32 
directional derivative, 6 
dual cone, 16 
dual problem, 20 
effective domain, 6 
epigraph, 4 
equilibrium flow, 158, 301 
Euclidean space, 1 
extreme point, 19 
face, 69 
Farkas' Lemma, 47 
feasible region, 2 
feasible vector, 2 
Fermat point, 8, 11 
flow, 156 
flow on arcs, 156 
flow-invariant law, 157 
function 
affine, 13 
convex, 4 
directionally differentiable, 
6 
linear fractional, 143 
linear-quadratic, 21 
locally Lipschitz, 15 
nonconvex, 5, 6 
piecewise linear-quadratic, 
278 
quasiconcave, 145 
quasiconvex, 145 
semistrictly quasiconcave, 
145 
semistrictly quasiconvex, 145 

Index 
strictly quasiconvex, 145 
generalized linear complemen- 
tarity problem, 99 
generalized directional deriva- 
tive, 15 
generalized equation, 87 
gradient, 14 
graph, 156 
incidence matrix, 157, 159 
inequality system 
regular, 169 
interior, 2 
Jacobian matrix, 86 
Karush-Kuhn-Tucker pair, 49 
Karush-Kuhn-Tucker point, 49, 
164 
Karush-Kuhn-Tucker solutions, 
65 
KKT pair, 49 
KKT point, 49 
KKT point interval, 77 
KKT point ray, 66 
KKT point set, 49 
Kuhn-Tucker conditions, 13, 19 
Lagrange multiplier, 13, 49 
Lagrange multiplier rule, 17 
linear complementarity prob- 
lem, 99 
linear generalized equations, 102 
linear program, 20 
canonical form, 20 
standard form, 20 
general form, 20 
local-solution interval, 77 
local-solution ray, 66 
local-solution set, 2 
locally unique solution, 58 
Mangasarian-F'romovitz constraint 
qualification, 18 
mathematical programming prob- 
lem, 2 
convex, 5 
equivalent, 2 
nonconvex, 5 
matrix 
copositive, 107 
copositive on a set, 107 
monotone on a set, 107 
negative definite, 23 
negative semidefinite, 23 
positive definite, 23 
positive semidefinite, 23 
strictly copositive on a set, 
107 
maximization problem, 3 
metric projection, 291, 292 
minimization problem , 3 
Minty Lemma, 89 
multifunction 
continuous, 148 
effective domain, 122 
graph, 122 
Lipschitz on a set, 126 
locally Lipschitz, 126 
locally upper-Lipschitz, 126 
lower semicontinuous, 148 
polyhedral, 122 
upper semicontinuous, 148 
upper-Lipschitz, 149 
neighborhood, 2 
network equilibrium problem, 
158 
node, 156 
nonconvex program, 5 
nondegenerate matrix, 101, 172 
nonlinear complementarity prob- 
lem, 91 

Index 
nonlinear program, 20 
nonsmooth program, 15 
norm, 1 
normal cone, 7 
objective function, 2 
operat or 
affine, 92 
locally strongly monotone, 
297 
monotone, 89 
strictly monotone, 89 
strongly monotone, 89 
optimal value, 3 
origin-destination pairs, 156 
parametric variational inequal- 
ity, 291 
path, 156 
polyhedral convex set, 19 
positive dual cone, 91 
principal submatrix, 101 
property Cj, 
119 
pseudo-face, 69 
QP problem 
indefinite, 224 
quadratic program, 22 
general form, 22 
indefinite, 24 
canonical form, 22 
convex, 23 
homogeneous, 65 
nonconvex, 22, 25 
standard form, 22 
recession cone, 32 
relative interior, 7 
scalar product, 2 
set 
affine, 7 
connected by line segments, 
150 
convex, 4 
polyhedral convex, 19 
Slater condition, 14 
smo0t.h program, 15 
solution 
efficient, 144 
global, 2, 3 
local, 2, 3 
weakly efficient, 144 
solution interval, 77 
solution ray, 66 
solution set, 2 
strict copositivity, 109 
strictly convex function, 11 
subdifferential, 7 
Theorem 
Eaves, 36 
Frank-Wolfe, 30 
Kuhn-Tucker, 13 
Moreau-Rockafellar , 8 
Walkup-Wets, 120 
topological space 
arcwise connected, 148 
component, 150 
connected, 148 
contractible, 148 
Torricelli point, 11 
traffic network, 157, 301 
travel cost function, 156 
unconstrained problem, 2 
user-optimizing principle, 158 
variational inequality, 86 
variational inequality problem, 
86 
vector of demands, 157 
Wardrop principle, 158 

