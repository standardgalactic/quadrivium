WILEY SERIES IN PROBABILITY AND STATISTICS
THIRD EDITION
PROBABILITY
AND STATISTICAL 
INFERENCE
MAGDALENA NIEWIADOMSKA-BUGAJ
ROBERT BARTOSZYNSKI
Wiley

PROBABILITY AND
STATISTICAL INFERENCE

WILEY SERIES IN PROBABILITY AND STATISTICS
Established by Walter A. Shewhart and Samuel S. Wilks
Editors: David J. Balding, Noel A. C. Cressie, Garrett M. Fitzmaurice, Geof H. Givens, 
Harvey Goldstein, Geert Molenberghs, David W. Scott, Adrian F. M. Smith, Ruey S. Tsay
Editors Emeriti: J. Stuart Hunter, Iain M. Johnstone, Joseph B. Kadane, Jozef L. Teugels
The Wiley Series in Probability and Statistics is well established and authoritative. It covers 
many topics of current research interest in both pure and applied statistics and probability 
theory. Written by leading statisticians and institutions, the titles span both state-of-the-art 
developments in the field and classical methods.
Reflecting the wide range of current research in statistics, the series encompasses applied, 
methodological and theoretical statistics, ranging from applications and new 
techniques made possible by advances in computerized practice to rigorous treatment of 
theoretical approaches.
This series provides essential and invaluable reading for all statisticians, whether in 
academia, industry, government, or research.
A complete list of titles in this series can be found at http://www.wiley.com/go/wsps

PROBABILITY AND
STATISTICAL INFERENCE
Third Edition
Magdalena Niewiadomska-Bugaj
Robert Bartoszynskr
Wiley

This edition first published 2021 
© 2021 John Wiley & Sons, Inc.
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted, in 
any form or by any means, electronic, mechanical, photocopying, recording or otherwise, except as permitted by 
law. Advice on how to obtain permission to reuse material from this title is available at http://www.wiley.com/go/ 
permissions.
The right of Magdalena Niewiadomska-Bugaj and Robert Bartoszynski to be identified as the authors of this 
work has been asserted in accordance with law.
Registered Office
John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, USA
Editorial Office
111 River Street, Hoboken, NJ 07030, USA
For details of our global editorial offices, customer services, and more information about Wiley products visit us 
at www.wiley.com.
Wiley also publishes its books in a variety of electronic formats and by print-on-demand. Some content that 
appears in standard print versions of this book may not be available in other formats.
Limit of Liability/Disclaimer of Warranty
While the publisher and authors have used their best efforts in preparing this work, they make no representations 
or warranties with respect to the accuracy or completeness of the contents of this work and specifically disclaim 
all warranties, including without limitation any implied warranties of merchantability or fitness for a particular 
purpose. No warranty may be created or extended by sales representatives, written sales materials or promotional 
statements for this work. The fact that an organization, website, or product is referred to in this work as a citation 
and/or potential source of further information does not mean that the publisher and authors endorse the 
information or services the organization, website, or product may provide or recommendations it may make. This 
work is sold with the understanding that the publisher is not engaged in rendering professional services. The 
advice and strategies contained herein may not be suitable for your situation. You should consult with a specialist 
where appropriate. Further, readers should be aware that websites listed in this work may have changed or 
disappeared between when this work was written and when it is read. Neither the publisher nor authors shall be 
liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, 
consequential, or other damages.
Library of Congress Cataloging-in-Publication Data
Names: Niewiadomska-Bugaj, Magdalena, author. | Bartoszynski, Robert, 
author.
Title: Probability and statistical inference / Magdalena 
Niewiadomska-Bugaj, Robert Bartoszynski.
Description: Third edition. | Hoboken, NJ : Wiley-Interscience, 2021. |
Revised edition of: Probability and statistical inference / Robert
Bartoszynski, Magdalena Niewiadomska-Bugaj. 2nd ed. c2008. | Includes 
bibliographical references and index.
Identifiers: LCCN 2020021071 (print) | LCCN 2020021072 (ebook) | ISBN
9781119243809 (cloth) | ISBN 9781119243816 (adobe pdf) | ISBN
9781119243823 (epub)
Subjects: LCSH: Probabilities. | Mathematical statistics.
Classification: LCC QA273 .B2584 2021 (print) | LCC QA273 (ebook) | DDC
519.5/4-dc23
LC record available at https://lccn.loc.gov/2020021071
LC ebook record available at https://lccn.loc.gov/2020021072
Cover Design: Wiley
Cover Images: (graph) Courtesy of Magdalena Niewiadomska-Bugaj, Colorful abstract long exposure pictures © 
Artur Debat/Getty Images
Set in 10/11.5pt TimesNewRomanMTStd by SPi Global, Chennai, India
10987654321

To my parents
- MNB

Contents
Preface to Third Edition 
xi
Preface to Second Edition 
xiii
About the Companion Website 
xvi
1 
Experiments, Sample Spaces, and Events 
1
1.1 
Introduction 
1
1.2 
Sample Space 
2
1.3 
Algebra of Events 
8
1.4 
Infinite Operations on Events 
13
2 Probability 
21
2.1 
Introduction 
21
2.2 
Probability as a Frequency 
21
2.3 
Axioms of Probability 
22
2.4 
Consequences of the Axioms 
26
2.5 
Classical Probability 
30
2.6 
Necessity of the Axioms 
31
2.7 
Subjective Probability 
35
3 Counting 
39
3.1 
Introduction 
39
3.2 
Product Sets, Orderings, and Permutations 
39
vii

viii
CONTENTS
3.3 
Binomial Coefficients 
44
3.4 
Multinomial Coefficients 
56
4 Conditional Probability, Independence, and Markov Chains 
59
4.1 
Introduction 
59
4.2 
Conditional Probability 
60
4.3 
Partitions; Total Probability Formula 
65
4.4 
Bayes’ Formula 
69
4.5 
Independence 
74
4.6 
Exchangeability; Conditional Independence 
80
4.7 
Markov Chains* 
82
5 Random Variables: Univariate Case 
93
5.1 
Introduction 
93
5.2 
Distributions of Random Variables 
94
5.3 
Discrete and Continuous Random Variables 
102
5.4 
Functions of Random Variables 
112
5.5 
Survival and Hazard Functions 
118
6 Random Variables: Multivariate Case 
123
6.1 
Bivariate Distributions 
123
6.2 
Marginal Distributions; Independence 
129
6.3 
Conditional Distributions 
140
6.4 
Bivariate Transformations 
147
6.5 
Multidimensional Distributions 
155
7 Expectation 
163
7.1 
Introduction 
163
7.2 
Expected Value 
164
7.3 
Expectation as an Integral 
171
7.4 
Properties of Expectation 
177
7.5 
Moments 
184
7.6 
Variance 
191
7.7 
Conditional Expectation 
202
7.8 
Inequalities 
206
8 Selected Families of Distributions 
211
8.1 
Bernoulli Trials and Related Distributions 
211
8.2 
Hypergeometric Distribution 
223
8.3 
Poisson Distribution and Poisson Process 
228
8.4 
Exponential, Gamma, and Related Distributions 
240
8.5 
Normal Distribution 
246
8.6 
Beta Distribution 
255

CONTENTS
ix
9
Random Samples
259
9.1
Statistics and Sampling Distributions
259
9.2
Distributions Related to Normal
261
9.3
Order Statistics
266
9.4
Generating Random Samples
272
9.5
Convergence
276
9.6
Central Limit Theorem
287
10
Introduction to Statistical Inference
295
10.1
Overview
295
10.2
Basic Models
298
10.3
Sampling
299
10.4
Measurement Scales
305
11
Estimation
309
11.1
Introduction
309
11.2
Consistency
313
11.3
Loss, Risk, and Admissibility
316
11.4
Efficiency
321
11.5
Methods of Obtaining Estimators
328
11.6
Sufficiency
345
11.7
Interval Estimation
359
12
Testing Statistical Hypotheses
373
12.1
Introduction
373
12.2
Intuitive Background
377
12.3
Most Powerful Tests
384
12.4
Uniformly Most Powerful Tests
396
12.5
Unbiased Tests
402
12.6
Generalized Likelihood Ratio Tests
405
12.7
Conditional Tests
412
12.8
Tests and Confidence Intervals
415
12.9
Review of Tests for Normal Distributions
416
12.10
Monte Carlo, Bootstrap, and Permutation Tests
424
13
Linear Models
429
13.1
Introduction
429
13.2
Regression of the First and Second Kind
431
13.3
Distributional Assumptions
436
13.4
Linear Regression in the Normal Case
438
13.5
Testing Linearity
444
13.6
Prediction
447

x
CONTENTS
13. 7 Inverse Regression 
449
13. 8 BLUE 
451
13. 9 Regression Toward the Mean 
453
13.1 0 Analysis of Variance 
455
13.1 1 One-Way Layout 
455
13.1 2 Two-Way Layout 
458
13.1 3 ANOVA Models with Interaction 
461
13.1 4 Further Extensions 
465
14 
Rank Methods 
467
14.1 
Introduction 
467
14.2 
Glivenko-Cantelli Theorem 
468
14.3 
Kolmogorov-Smirnov Tests 
471
14.4 
One-Sample Rank Tests 
478
14.5 
Two-Sample Rank Tests 
484
14.6 
Kruskal-Wallis Test 
488
15 
Analysis of Categorical Data 
491
15.1 
Introduction 
491
15.2 
Chi-Square Tests 
492
15.3 
Homogeneity and Independence 
499
15.4 
Consistency and Power 
504
15.5 
2 x 2 Contingency Tables 
509
15.6 
r x c Contingency Tables 
516
16 
Basics of Bayesian Statistics 
521
16.1 
Introduction 
521
16.2 
Prior and Posterior Distributions 
522
16.3 
Bayesian Inference 
529
16.4 
Final Comments 
543
Appendix A Supporting R Code 
545
Appendix B Statistical Tables 
551
Bibliography 
555
Answers to Odd-Numbered Problems 
559
Index
571

Preface to Third Edition
You have in front of you the third edition of the “Probability and Statistical Inference,” a 
text originally published in 1996. I have been using this book in the classroom since then, 
and it has always been interesting to see how it serves the students, how they react to it, 
and what could still be done to make it better. These reflections prompted me to prepare a 
second edition, published in 2007. But academia is changing quickly; who the students are 
is changing, and how we should teach to help them learn is changing as well. This is what 
made me consider a third edition. The response from Wiley Publishing was positive and my 
work began.
There were three main changes that I saw as necessary. First, adding a chapter on the 
basics of Bayesian statistics, as I realized that upper level undergraduate students and grad­
uate students needed an earlier introduction to Bayesian inference. Another change was to 
make the book more appropriate for the flipped classroom format. I have experimented with 
it for three years now and it is working quite well. The book introduces and illustrates con­
cepts through more than 400 examples. Preparing the material mainly at home gives students 
more time in class for questions, discussion, and for problem solving. I have also added 
over 70 new problems to make the selection easier for the instructor. A third change was 
including an appendix with an R code that would help students complete projects and home­
work assignments. My two-semester class based on this text includes three projects. The first 
one -in the fall semester-has students present applications of selected distributions, includ­
ing graphics. Two projects for the spring semester involve resampling methods. The necessary 
R code is included in the appendix.
There are many people to whom I owe my thanks. First, I would like to thank Wiley 
Editor Jon Gurstelle, who liked the idea of preparing the third edition. After Jon accepted 
another job elsewhere, the book and I came under the excellent care of the Editorial Teams of 
Mindy Okura-Mokrzycki, Kathleen Santoloci, Linda Christina, and Kimberly Monroe-Hill 
who have supported me throughout this process. I would also like to thank Carla Koretsky, 
the Dean of the College of Arts and Sciences at Western Michigan University, and WMU 
Provost, Sue Stapleton, for granting me a semester-long administrative sabbatical leave that 
significantly sped up the progress of the book.
xi

xii preface to third edition
I am indebted to several of my students for their valuable comments. I am also grateful 
to my departmental colleagues, especially Hyun Bin Kang and Duy Ngo, who used the text 
in class and gave me their valuable feedback. Hyun Bin also helped me with the format­
ting of the R code in the appendix. Finally, I thank my husband, Jerzy, for his support and 
encouragement.
MNB
November 2020

Preface to Second Edition
The first edition of this book was published in 1996. Since then, powerful computers have 
come into wide use, and it became clear that our text should be revised and material on 
computer-intensive methods of statistical inference should be added. To my delight, Steve 
Quigley, Executive Editor of John Wiley and Sons, agreed with the idea, and work on the 
second edition began.
Unfortunately, Robert Bartoszynski passed away in 1998, so I was left to carry out this 
revision by myself. I revised the content by creating a new chapter on random samples, adding 
sections on Monte Carlo methods, bootstrap estimators and tests, and permutation tests. 
More problems were added, and existing ones were reorganized. Hopefully nothing was lost 
of the “spirit” of the book which Robert liked so much and of which he was very proud.
This book is intended for seniors or first-year graduate students in statistics, mathematics, 
natural sciences, engineering, and any other major where an intensive exposure to statistics 
is necessary. The prerequisite is a calculus sequence that includes multivariate calculus. We 
provide the material for a two-semester course that starts with the necessary background in 
probability theory, followed by the theory of statistics.
What distinguishes our book from other texts is the way the material is presented and the 
aspects that are stressed. To put it succinctly, understanding “why” is prioritized over the skill 
of “how to.” Today, in an era of undreamed-of computational facilities, a reflection in an 
attempt to understand is not a luxury but a necessity.
Probability theory and statistics are presented as self-contained conceptual structures. 
Their value as a means of description and inference about real-life situations lies precisely in 
their level of abstraction—the more abstract a concept is, the wider is its applicability. The 
methodology of statistics comes out most clearly if it is introduced as an abstract system 
illustrated by a variety of real-life applications, not confined to any single domain.
Depending on the level of the course, the instructor can select topics and examples, 
both in the theory and in applications. These can range from simple illustrations of 
concepts, to introductions of whole theories typically not included in comparable textbooks 
(e.g., prediction, extrapolation, and filtration in time series as examples of use of the 
concepts of covariance and correlation). Such additional, more advanced, material (e.g., 
xiii

xiv
PREFACE TO SECOND EDITION
Chapter 5 on Markov Chains) is marked with asterisks. Other examples are the proof of 
the extension theorem (Theorem 6.2.4), showing that the cumulative distribution function 
determines the measure on the line; the construction of Lebesgue, Riemann-Stieltjes, and 
Lebesgue-Stieltjes integrals; and the explanation of the difference between double integral 
and iterated integrals (Section 8.3).
In the material that is seldom included in other textbooks on mathematical statistics, we 
stress the consequences of nonuniqueness ofa sample space and illustrate, by examples, how 
the choice of a sample space can facilitate the formulation of some problems (e.g., issues of 
selection or randomized response). We introduce the concept of conditioning with respect to 
partition (Section 4.4); we explain the Borel-Kolmogorov paradox by way of the underlying 
measurement process that provides information on the occurrence of the condition (Example 
7.22); we present the Neyman-Scott theory of outliers (Example 10.4); we give a new version 
of the proof of the relation between mean, median, and standard deviation (Theorem 8.7.3); 
we show another way of conditioning in the secretary problem (Example 4.10). Among 
examples of applications, we discuss the strategies of serves in tennis (Problem 4.2.12), and 
a series of problems (3.2.14-3.2.20) concerning combinatorial analysis of voting power. In 
Chapter 11, we discuss the renewal paradox, the effects of importance sampling (Example 
11.6), and the relevance of measurement theory for statistics (Section 11.6). Chapter 14 
provides a discussion of true regression versus linear regression and concentrates mostly on 
explaining why certain procedures (in regression analysis and ANOVA) work, rather than 
on computational details. In Chapter 15, we provide a taste of rank methods—one line of 
research starting with the Glivenko-Cantelli Theorem and leading to Kolmogorov-Smirnov 
tests, and the other line leading to Mann-Whitney and Wilcoxon tests. In this chapter, we 
also show the traps associated with multiple tests of the same hypothesis (Example 15.3). 
Finally, Chapter 16 contains information on partitioning contingency tables—the method 
that provides insight into the dependence structure. We also introduce McNemar’s test and 
various indices of association for tables with ordered categories.
The backbone of the book is the examples used to illustrate concepts, theorems, and meth­
ods. Some examples raise the possibilities of extensions and generalizations, and some simply 
point out the relevant subtleties.
Another feature that distinguishes our book from most other texts is the choice of prob­
lems. Our strategy was to integrate the knowledge students acquired thus far, rather than 
to train them in a single skill or concept. The solution to a problem in a given section may 
require using knowledge from some preceding sections, that is, reaching back into material 
already covered. Most of the problems are intended to make the students aware of facts they 
might otherwise overlook. Many of the problems were inspired by our teaching experience 
and familiarity with students’ typical errors and misconceptions.
Finally, we hope that our book will be “friendly” for students at all levels. We provide 
(hopefully) lucid and convincing explanations and motivations, pointing out the difficulties 
and pitfalls of arguments. We also do not want good students to be left alone. The material 
in starred chapters, sections, and examples can be skipped in the main part of the course, but 
used at will by interested students to complement and enhance their knowledge. The book 
can also be a useful reference, or source of examples and problems, for instructors who teach 
courses from other texts.
I am indebted to many people without whom this book would not have reached its current 
form. First, thank you to many colleagues who contributed to the first edition and whose 
names are listed there. Comments of many instructors and students who used the first edition 
were influential in this revision. I wish to express my gratitude to Samuel Kotz for referring 
me to Stigler’s (1986) article about the “right and lawful rood,” which we previously used in 
the book without reference (Example 8.40). My sincere thanks are due to Jung Chao Wang 

PREFACE TO SECOND EDITION
xv
for his help in creating the R-code for computer-intensive procedures that, together with 
additional examples, can be found on the book’s ftp site
ftp://ftp.wiley.com/public/sc_tech_med/probability_statistical.
Particular thanks are due to Katarzyna Bugaj for careful proofreading of the entire 
manuscript, bukasz Bugaj for meticulously creating all figures with the Mathematica 
software, and Agata Bugaj for her help in compiling the index. Changing all those diapers 
has finally paid off.
I wish to express my appreciation to the anonymous reviewers for supporting the book 
and providing valuable suggestions, and to Steve Quigley, Executive Editor of John Wiley & 
Sons, for all his help and guidance in carrying out the revision.
Finally, I would like to thank my family, especially my husband Jerzy, for their encour­
agement and support during the years this book was being written.
Magdalena Niewiadomska-Bugaj
October 2007

About the Companion Website
This book is accompanied by a companion website:
www.wiley.com/go/probabilityandstatisticalinference3e
The website includes the Instructor’s Solution Manual and will be live in early 2021.
xvi

CHAPTER 1
EXPERIMENTS, SAMPLE SPACES, AND 
EVENTS
1.1 INTRODUCTION
The consequences of making a decision today often depend on what will happen in the future, 
at least on the future that is relevant to the decision. The main purpose of using statistical 
methods is to help in making better decisions under uncertainty.
Judging from the failures of weather forecasts, to more spectacular prediction failures, 
such as bankruptcies of large companies and stock market crashes, it would appear that 
statistical methods do not perform very well. However, with a possible exception of weather 
forecasting, these examples are, at best, only partially statistical predictions. Moreover, 
failures tend to be better remembered than successes. Whatever the case, statistical 
methods are at present, and are likely to remain indefinitely, our best and most reliable 
prediction tools.
To make decisions under uncertainty, one usually needs to collect some data. Data may 
come from past experiences and observations, or may result from some controlled processes, 
such as laboratory or field experiments. The data are then used to hypothesize about the 
laws (often called mechanisms) that govern the fragment of reality of interest. In our book, 
we are interested in laws expressed in probabilistic terms: They specify directly, or allow us 
to compute, the chances of some events to occur. Knowledge of these chances is, in most 
cases, the best one can get with regard to prediction and decisions.
Probability theory is a domain of pure mathematics and as such, it has its own concep­
tual structure. To enable a variety of applications (typically comprising of all areas of human 
endeavor, ranging from biological, medical, social and physical sciences, to engineering, 
humanities, business, etc.), such structure must be kept on an abstract level. An application 
of probability to the particular situation analyzed requires a number of initial steps in which 
the elements of the real situation are interpreted as abstract concepts of probability theory.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
1

2
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
Such interpretation is often referred to as building a probabilistic model of the situation at 
hand. How well this is done is crucial to the success of application.
One of the main concepts here is that of an experiment—a term used in a broad sense. It 
means any process that generates data which is influenced, at least in part, by chance.
1.2 SAMPLE SPACE
In analyzing an experiment, one is primarily interested in its outcome—the concept that 
is not defined (i.e., a primitive concept) but has to be specified in every particular applica­
tion. This specification may be done in different ways, with the only requirements being that 
(1) outcomes exclude one another and (2) they exhaust the set of all logical possibilities.
■ EXAMPLE 1.1
Consider an experiment consisting of two tosses of a regular die. An outcome is most 
naturally represented by a pair of numbers that turn up on the upper faces of the die 
so that they form a pair (x, y), with x, y =1, 2, ...,6 (see Table 1.1).
Table 1.1 Outcomes on a pair of dice.
1
2
y
3
4
5
6
1
(1, 1)
(1, 2)
(1, 3)
(1, 4)
(1, 5)
(1, 6)
2
(2, 1)
(2, 2)
(2, 3)
(2, 4)
(2, 5)
(2, 6)
x3
(3, 1)
(3, 2)
(3, 3)
(3, 4)
(3, 5)
(3, 6)
4
(4, 1)
(4, 2)
(4, 3)
(4, 4)
(4, 5)
(4, 6)
5
(5, 1)
(5, 2)
(5, 3)
(5, 4)
(5, 5)
(5, 6)
6
(6, 1)
(6, 2)
(6, 3)
(6, 4)
(6, 5)
(6, 6)
In the case of an experiment of tossing a die three times, the outcomes will
be triplets ( x, y, z), with x, y, and z being integers between 1 and 6.
Since the outcome of an experiment is not known in advance, it is important to deter­
mine the set of all possible outcomes. This set, called the sample space, forms the conceptual 
framework for all further considerations of probability.
Definition 1.2.1 The sample space, denoted by S, is the set of all outcomes ofan experiment. 
The elements of the sample space are called elementary outcomes, or sample points. 
□
■ EXAMPLE 1.2
In Example 1.1, the sample space S has 62 = 36 sample points in the case of two tosses, 
and 63 = 216 points in the case of three tosses ofa die. The first statement can be veri­
fied by a direct counting of the elements of the sample space. Similar verification of the 
second claim, although possible in principle, would be cumbersome. In Chapter 3, we 
will introduce some methods of determining the sizes of sets without actually counting 
sample points.
■ EXAMPLE 1.3
Suppose that the only available information about the numbers, those that turn up on 
the upper faces of the die, is their sum. In such a case as outcomes, we take 11 possible 
values of the sum so that
S = {2,3,4,5,6,7,8,9,10,11,12}.

SAMPLE SPACE
3
For instance, all outcomes on the diagonal of Table 1.1—(6, 1), (5, 2), (4, 3), (3, 4), 
(2, 5), and (1, 6)—are represented by the same value 7.
■ EXAMPLE 1.4
If we are interested in the number of accidents that occur at a given intersection within 
a month, the sample space might be taken as the set S = {0, 1, 2, ...} consisting of all 
nonnegative integers. Realistically, there is a practical limit, say 1,000, of the monthly 
numbers of accidents at this particular intersection. Although one may think that 
it is simpler to take the sample space S = {0, 1, 2, ...,1,000}, it turns out that it is 
often much simpler to take the infinite sample space if the “practical bound” is not 
very precise.
Since outcomes can be specified in various ways (as illustrated by Examples 1.1 and 1.3), 
it follows that the same experiment can be described in terms of different sample spaces S . 
The choice of a sample space depends on the goal of description. Moreover, certain sample 
spaces for the same experiment lead to easier and simpler analysis. The choice of a “better” 
sample space requires some skill, which is usually gained through experience. The following 
two examples illustrate this point.
■ EXAMPLE 1.5
Let the experiment consist of recording the lifetime ofa piece of equipment, say a light 
bulb. An outcome here is the time until the bulb burns out. An outcome typically will 
be represented by a number t > 0 (t = 0 if the bulb is not working at the start), and 
therefore S is the nonnegative part of the real axis. In practice, t is measured with some 
precision (in hours, days, etc.), so one might instead take S = {0, 1, 2, ...}. Which of 
these choices is better depends on the type of subsequent analysis.
■ EXAMPLE 1.6
Two persons enter a cafeteria and sit at a square table, with one chair on each of its 
sides. Suppose we are interested in the event “they sit at a corner” (as opposed to sitting 
across from one another). To construct the sample space, we let A and B denote the 
two persons, and then take as S the set of outcomes represented by 12 ideograms in 
Figure 1.1. One could argue, however, that such a sample space is unnecessarily large.
BA
A
A
B
AB
Figure 1. 1 Possible seatings of persons A and B at a square table.

4
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
If we are interested only in the event “they sit at a corner,” then there is no need to 
label the persons as A and B. Accordingly, the sample space S may be reduced to the 
set of six outcomes depicted in Figure 1.2. But even this sample space can be simplified. 
Indeed, one could use the rotational symmetry of the table and argue that once the first 
person selects a chair (it does not matter which one), then the sample space consists of 
just three chairs remaining for the second person (see Figure 1.3).
xxx
x 
x x 
x
xx
Figure 1. 2 Possible seatings of any two persons at a square table.
Figure 1. 3 Possible seatings of one person if the place of the other person is fixed.
Sample spaces can be classified according to the number of sample points they contain. 
Finite sample spaces contain finitely many outcomes, and elements of infinitely countable 
sample spaces can be arranged into an infinite sequence; other sample spaces are called 
uncountable.
The next concept to be introduced is that of an event. Intuitively, an event is anything 
about which we can tell whether or not it has occurred, as soon as we know the outcome of 
the experiment. This leads to the following definition:
Definition 1.2.2 An event is a subset of the sample space 5. 
□
■ EXAMPLE 1.7
In Example 1.1 an event such as “the sum equals 7” containing six outcomes 
(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), and (6, 1) is a subset of the sample space 5.In 
Example 1.3, the same event consists of one outcome, 7.
When an experiment is performed, we observe its outcome. In the interpretation devel­
oped in this chapter, this means that we observe a point chosen randomly from the sample 
space. If this point belongs to the subset representing the event A, we say that the event A 
has occurred.
We will let events be denoted either by letters A,B,C, ... , possibly with identifiers, such 
as A1 ,Bk , ..., or by more descriptive means, such as {X =1} and {a<Z<b},whereX 

SAMPLE SPACE
5
and Z are some numerical attributes of the sample points (formally: random variables, to be 
discussed in Chapter 5). Events can also be described through verbal phrases, such as “two 
heads in a row occur before the third tail” in the experiment of repeated tosses of a coin.
In all cases considered thus far, we assumed that an outcome (a point in the sample space) 
can be observed. To put it more precisely, all sample spaces S considered so far were con­
structed in such a way that their points were observable. Thus, for any event A, we were 
always able to tell whether it occurred or not.
The following examples show experiments and corresponding sample spaces with sample 
points that are only partially observable:
■ EXAMPLE 1.8 Selection
Candidates for a certain job are characterized by their level z of skills required for the 
job. The actual value of z is not observable, though; what we observe is the candidate’s 
score x on a certain test. Thus, the sample point in S is a pair s = (z, x), and only one 
coordinate of s, x, is observable.
The objective might be to find selection thresholds z0 and x0 , such that the rule: 
“accept all candidates whose score x exceeds x0” would lead to maximizing the (unob­
servable) number of persons accepted whose true level of skill z exceeds z0 . Naturally, 
to find such a solution, one needs to understand statistical relation between observable 
x and unobservable z .
Another example when the points in the sample space are only partially observable con­
cerns studies of incidence of activities about which one may hesitate to respond truthfully, 
or even to respond at all. These are typically studies related to sexual habits or preferences, 
abortion, law and tax violation, drug use, and so on.
■ EXAMPLE 1.9 Randomized Response
Let Q be the activity analyzed, and assume that the researcher is interested in the fre­
quency of persons who ever participated in activity Q (for simplicity, we will call them 
Q-persons). It ought to be stressed that the objective is not to identify the Q-persons, 
but only to find the proportion of such persons in the population.
The direct question reduced to something like “Are you a Q-person?” is not likely to 
be answered truthfully, if at all. It is therefore necessary to make the respondent safe, 
guaranteeing that their responses will reveal nothing about them as regards Q. This 
can be accomplished as follows: The respondent is given a pair of distinguishable dice, 
for example, one green and one white. She throws them both at the same time, in such 
a way that the experimenter does not know the results of the toss (e.g., the dice are in a 
box and only the respondent looks into the box after it is shaken). The instruction is the 
following: If the green die shows an odd face (1, 3, or 5), then respond to the question 
“Are you a Q-person?” If the green die shows an even face (2, 4, or 6), then respond 
to the question, “Does the white die show an ace?” The scheme of this response is 
summarized by the flowchart in Figure 1.4.
The interviewer knows the answer “yes” or “no” but does not know whether it is 
the answer to the question about Q or the question about the white die. Here a natural 
sample space consists of points s =(i, x, y), where x and y are outcomes on green and 
white die, respectively, while i is 1 or 0 depending on whether or not the respondent is 
a Q-person. We have ф(s) = ф(i, x, y)= “yes” if i = 1 and x = 1, 3, or 5 for any y, or 
if x = 2, 4, 6, and y = 1 for any i. In all other cases, ф(s) = “no.”

6
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
Figure 1.4 Scheme of a randomized response.
One could wonder what is a possible advantage, if any, of not knowing the question 
asked and observing only the answer. This does not make sense if we need to know the 
truth about each individual respondent. However, one should remember that we are 
only after the overall frequency of Q-persons.
We are in fact “contaminating” the question by making the respondent answer 
either a Q-question or some other auxiliary question. But this is a “controlled 
contamination”: we know how often (on average) the respondents answer the 
auxiliary question, and how often their answer is “yes.” Consequently, as we will 
see in Chapter 11, we can still make an inference about the proportion of Q-persons 
based on the observed responses.
PROBLEMS
1.2.1 List all sample points in sample spaces for the following experiments: (i) We toss a 
balanced coin.1 If heads come up, we toss a die. Otherwise, we toss the coin two more 
times. (ii) A coin is tossed until the total of two tails occurs, but no more than four 
times (i.e., a coin is tossed until the second tail or fourth toss, whichever comes first).
1.2.2 Alice, Bob, Carl, and Diana enter the elevator on the first floor of a four-story build­
ing. Each of them leaves the elevator on either the second, third, or fourth floor.
(i) Describe the sample space without listing all sample points. (ii) List all sample 
points such that Carl and Diana leave the elevator on the third floor. (iii) List all 
sample points if Carl and Diana leave the elevator at the same floor.
1.2.3 An urn contains five chips, labeled 1, ...,5. Three chips are selected. List all out­
comes included in the event “the second largest number drawn was 3.”
1.2.4 In a game of craps, the player rolls a pair of dice. Ifhe gets a total of 7 or 11, he wins 
at once; if the total is 2, 3, or 12, he loses at once. Otherwise, the sum, say x, is his 
“point,” and he keeps rolling dice until either he rolls another x (in which case he 
wins) or he rolls a 7 in which case he loses. Describe the event “the player wins with 
a point of 5.”
1 Unless specifically stated, we will be assuming that all coins and/or dice tossed are fair (balanced).

SAMPLE SPACE
7
1.2.5 The experiment consists of placing six balls in three boxes. List all outcomes in the 
sample space if: (i) The balls are indistinguishable, but the boxes are distinguishable. 
(Hint: There are 28 different placements.) (ii) Neither the balls nor the boxes are dis­
tinguishable. (iii) Two balls are white and four are red; the boxes are distinguishable.
1.2.6 John and Mary plan to meet each other. Each of them is to arrive at the meeting 
place at some time between 5 p.m. and 6 p.m. John is to wait 20 minutes (or until 
6 p.m., whichever comes first), and then leave if Mary does not show up. Mary 
will wait only 5 minutes (or until 6 p.m., whichever comes first), and then leave if 
John does not show up. Letting x and y denote the arrival times of John and Mary, 
determine the sample space and describe events (i)-(viii) by drawing pictures, or by 
appropriate inequalities for x and y . If you think that the description is impossible, 
say so. (i) John arrives before Mary does. (ii) John and Mary meet. (iii) Either Mary 
comes first, or they do not meet. (iv) Mary comes first, but they do not meet. (v) 
John comes very late. (vi) They arrive less than 15 minutes apart, and they do not 
meet. (vii) Mary arrives at 5:15 p.m. and meets John, who is already there. (viii) 
They almost miss one another.
Problems 1.2.7-1.2.8 show an importance of the sample space selection.
1.2.7 Let E be the experiment consisting of tossing a coin three times, with H and T stand­
ing for heads and tails, respectively.
(i) The following set of outcomes is an incomplete list of the points of the sample 
space S of the experiment E : {HHH, HTT, TTT, HHT, HTH, THH}. Use a tree 
diagram to find the missing outcomes.
(ii) An alternative sample space 5' for the same experiment E consists of the follow­
ing four outcomes: no heads (0), one head (1), two heads (2), and three heads (3). 
Which of the following events can be described as subsets of 5 but not as subsets of 
5' = {0, 1, 2, 3 } ?
A1 = More than two heads.
A2 = Head on the second toss.
A3 = More tails than heads.
A4 = At least one tail, with head on the last toss.
A5 = At least two faces the same.
A6 = Head and tail alternate.
(iii) Still another sample space 5" for the experiment E consists of the four outcomes 
(0, 0), (0, 1), (1, 0), and (1, 1). The first coordinate is 1 if the first two tosses show the 
same face and 0 otherwise; the second coordinate is 1 if the last two tosses show 
the same face, and 0 otherwise. For instance, if we observe HHT, the outcome is 
(1, 0). List the outcomes of 5 that belong to the event A = {(1, 1), (0, 1)} of 5".
(iv) Which of the following events can be represented as subsets of 5, but cannot be 
represented as subsets of 5"?
B1 = First and third toss show the same face.
B2 = Heads on all tosses.
B3 = All faces the same.
B4 = Each face appears at least once.
B5 = More heads than tails.
1.2.8 Let E be an experiment consisting of tossing a die twice. Let 5 be the sample space 
with sample points (i,j),i,j =1, 2, ...,6, with i and j being the numbers of dots 
that appear in the first and second toss, respectively.

8
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
(i) Let 5' be the sample space for the experiment E consisting of all possible sums 
i + j so that 5' = {2, 3, ..., 12}. Which of the following events can be defined as 
subsets of 5 but not of 5'?
A1 = One face odd, the other even.
A2 = Both faces even.
A3 = Faces different.
A4 = Result on the first toss less than the result on the second.
A5 = Product greater than 10.
A6 = Product greater than 30.
(ii) Let 5" be the sample space for the experiment E consisting of all possible absolute 
values of the difference |i - j\ so that 5" = {0, 1, 2, 3, 4, 5}. Which of the following 
events can be defined as subsets of 5 but not of S"?
B1 = One face shows twice as many dots as the other,
B2 = Faces the same,
B3 = One face shows six times as many dots as the other,
B4 = One face odd, the other even,
B5 = The ratio of the numbers of dots on the faces is different from 1.
1.2.9 Referring to Example 1.9, suppose that we modify it as follows: The respondent 
tosses a green die (with the outcome unknown to the interviewer). If the outcome is 
odd, he responds to the Q-question; otherwise, he responds to the question “Were 
you born in April?” Again, the interviewer observes only the answer “yes” or “no.” 
Apart from the obvious difference in the frequency of the answer “yes” to the 
auxiliary question (on the average 1 in 12 instead of 1 in 6), are there any essential 
differences between this scheme and the scheme in Example 1.9? Explain your 
answer.
1.3 ALGEBRA OF EVENTS
Next, we introduce concepts that will allow us to form composite events out of simpler ones. 
We begin with the relations of inclusion and equality.
Definition 1.3.1 The event A is contained in the event B,orB contains A, if every sample 
point of A is also a sample point of B. Whenever this is true, we will write A C B, or equiv­
alently, B D A. 
□
An alternative terminology here is that A implies (or entails) B .
Definition 1.3.2 Two events A and B are said to be equal, A = B, if A C B and B C A. □
It follows that two events are equal if they consist of exactly the same sample points.
■ EXAMPLE 1.10
Consider two tosses ofa coin, and the corresponding sample space 5 consisting of four 
outcomes: HH, HT, TH, and TT. The event A = “heads in the first toss” = {HH, HT} 
is contained in the event B = “at least one head” = {HH, HT, TH}. The events “the 
results alternate” and “at least one head and one tail” imply one another, and hence 
are equal.

ALGEBRA OF EVENTS
9
Definition 1.3.3 The set containing no elements is called the empty set and is denoted by 0.
The event corresponding to 0 is called a null (impossible) event. 
□
■ EXAMPLE 1.11 *2
The reader may wonder whether it is correct to use the definite article in the definition 
above and speak of “the empty set,” since it would appear that there may be many 
different empty sets. For instance, the set of all kings of the United States and the set of 
all real numbers x such that x2 +1 = 0are both empty, but one consists of people and 
the other of numbers, so they cannot be equal. This is not so, however, as is shown by 
the following formal argument (to appreciate this argument, one needs some training 
in logic). Suppose that 01 and 02 are two empty sets. To prove that they are equal, one 
needs to prove that 0 1 C 02 and 02 C 0 1. Formally, the first inclusion is the implication: 
“if s belongs to 01, then s belongs to 02.” This implication is true, because its premise 
is false: there is no s that belongs to 01 . The same holds for the second implication, so 
01 = 02.
2 Asterisks denote more advanced material, as explained in the Preface to the Second Edition.
We now give the definitions of three principal operations on events: complementation, 
union, and intersection.
Definition 1.3.4 The set that contains all sample points that are not in the event A will be 
called the complement of A and denoted Ac, to be read also as “not A.” 
□
Definition 1.3.5 The set that contains all sample points belonging either to A or to B (so 
possibly to both of them) is called the union of A and B and denoted A U B, to be read as 
“A or B.” 
□
Definition 1.3.6 The set that contains all sample points belonging to both A and B is called 
the intersection of A and B and denoted A П B. 
□
An alternative notation for a complement is A or A, whereas in the case of an intersection, 
one often writes AB instead of A П B.
The operations above have the following interpretations in terms of occurrences 
of events:
1. Event Ac occurs if event A does not occur.
2. Event A U B occurs when either A or B or both events occur.
3. Event A П B occurs when both A and B occur.
■ EXAMPLE 1.12
Consider an experiment of tossing a coin three times, with the sample space 
consisting of outcomes described as HHH, HHT, and so on. Let A and B be 
the events “heads and tails alternate” and “heads on the last toss,” respectively. 
The event Ac occurs if either heads or tails occur at least twice in a row so that 
Ac = {HHH, HHT, THH, HTT, TTT, TTH}, while Bc is “tails on the last 
toss,” hence, Bc = {HHT, THT, HTT, TTT}. The union A U B is the event 
“either the results alternate or it is heads on the last toss,” meaning A U B = 
{HTH, THT, HHH, THH, TTH}. Observe that while A has two outcomes and B has 

10
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
four outcomes, their union has only five outcomes, since the outcome HTH appears 
in both events. This common part is the intersection A n B.
Some formulas can be simplified by introducing the operation of the difference of two 
events.
Definition 1.3.7 The difference, A\B, of events A and B contains all sample points that 
belong to A but not to B
A \B = A n Bc.
The symmetric difference, A ^ B, contains sample points that belong to A or to B, but not 
to both of them:
A + B = (A n Bc) U (Ac n B) = (A U B)\(A n B). 
□
■ EXAMPLE 1.13
In Example 1.12, the difference Bc\A is described as “at least two identical outcomes 
in a row and tails on the last toss,” which means the event {HHT, HTT, TTT}.
Next, we introduce the following important concept:
Definition 1.3.8 If A n B = 0, then the events A and B are called disjoint, or mutually 
exclusive. 
□
■ EXAMPLE 1.14
Based on Example 1.12, we know that the following two events are disjoint: C = “more 
heads than tails” and the intersection A n Bc = “the results alternate, ending with 
tails.”
Example 1.14 shows that to determine whether or not events are disjoint, it is not neces­
sary to list the outcomes in both events and check whether there exist common outcomes. 
Apart from the fact that such listing is not feasible when sample spaces are large, it is often 
simpler to employ logical reasoning. In the case above, if the results alternate and end with 
tails, then the outcome must be THT. Since there are more tails than heads, C does not occur.
The definitions of union and intersection can be extended to the case of a finite and even 
infinite number of events (to be discussed in the Section 1.4). Thus,
n
A i U A 2 U---U An =U Ai 
(1.1)
i=1
is the event that contains the sample points belonging to A1 or A2 or ...or An . Conse­
quently, (1.1) is the event “at least one Ai occurs.” Similarly,
n
A i n A 2 П---П An = p| Ai 
(1.2)
i=1
is the event that contains the sample points belonging to A1 and A2 and ...andAn . Conse­
quently, the event (1.2) is “all Ai ’s occur.”
■ EXAMPLE 1.15
Suppose that n shots are fired at a target, and let Ai, i =1, 2, ...,n denote the event 
“the target is hit on the ith shot.” Then, the union A 1 U • • • U An is the event “the 

ALGEBRA OF EVENTS
11
target is hit” (at least once). Its complement (A 1 U - - - U An)c is the event “the target 
is missed” (on every shot), which is the same as the intersection Ac_ H - - - H An.
A perceptive reader may note that the unions A 1 U - - - U An and intersections 
A 1 H • • • H An do not require an extension of the definition of union and intersection for 
two events. Indeed, we could consider unions such as
A 1 U (A 2 U (--- (An-2 U (An—1 U An)) ••• )),
where the union of only two events is formed in each set of parentheses. The property 
of associativity (below) shows that parentheses can be omitted so that the expression 
A1 U ••• U An is unambiguous. The same argument applies to intersections.
The operations on events defined in this section obey some laws. The most important ones 
are listed below.
Idempotence:
Double complementation:
A U A = A, A H A = A.
(Ac)c = A.
Absorption:
A U B = B ^^ A H B = A ^^ A c B. 
(1.3)
In particular,
A U0 = A, 
A US = S, 
A H 0 = 0, 
A HS = A,
which in view of (1.3) means that 0 C A c S.
Commutativity:
AU B = B UA,
Associativity:
AU (BUC)=(AUB) UC,
Distributivity:
AH (BUC)=(AHB)U (AHC),
De Morgan’s Laws:
(A 1 U-.-U An) c
(A 1 П---П An) c
AH B = BH A.
AH (BH C)=(AH B)H C.
AU (BHC)=(AUB)H (AUC).
Ac H -- - H An,
Ac U---UAn. 
(1.4)
It is often helpful to use Venn diagrams for studying relations between composite events 
in the same sample space. The sample space S is there represented by a rectangle, while its 
subsets represent events (see Figure 1.5).
The complement of event A is represented in Figure 1.5a, the union and intersection of 
the events A and B are represented in Figure 1.5b and c, respectively.
Venn diagrams can also be used to check the validity of formulas. For example, consider 
the first De Morgan’s law (1.4) for the case of two events:
(AUB)c =AcHBc.
(1.5)

12
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
Complement, union, and intersection.
Figure 1.6 The first De Morgan’s law.
Venn diagrams made separately for the left-hand side and the right-hand side of (1.5) (see 
Figure 1.6) indicate that both regions are the same. Although a picture does not constitute 
a proof, it may provide convincing evidence that the statement is true, and sometimes may 
even suggest a method of proving the statement.
PROBLEMS
For the problems below, remember that a statement (expressed as a sentence or formula) is 
true if it is true under all circumstances, and it is false if there is at least one case where it 
does not hold.
1.3.1 Answer true or false. Justify your answer. (i)IfA and B are distinct events (i.e., A = B) 
such that A and Bc are disjoint, then Ac and B are also disjoint. (ii) If A and B are 
disjoint, then Ac and Bc are also disjoint. (iii) If A and B are disjoint, and also B and 
C are disjoint, then A and C are disjoint. (iv) If A and B are both contained in C, 
then Cc c Ac n Bc. (v) If A is contained in B, C is contained in D, and B is disjoint 
from D, then A is disjoint from C. (vi) If A U Bc = Bc, then B c Ac.
1.3.2 In the statements below A, B, C,andD are events. Find those statements or formulas 
that are true. (i) If A n B = A n C, then B = C. (ii) A U (A n B) U (A n Bc) = A. 
(iii) A U (A n B) U (A n Bc) = B. (iv) If A\B = C, then A = B U C. (v) (A U B) n 
(C U D) = (A n C) U (A n D) U (B n C) U (B n D). (vi) (A n B) U (C n D) = (A U 
C) n (AUD)n (BUC) n (BUD). (vii) (AcUBcUCc)c =Ac nBcnCc. (viii) If 
A c B, and B n C = 0, then Cc n A n Bc = 0. (ix) If A n B, A n C and B n C are 
not empty, then A n B n C is not empty. (x) Show that (A ^ B) ^ C = A ^ (B ^ C).
1.3.3 Find X if: (i) A ^ X = 0. (ii) A ^ X = A. (iii) A ^ X = S. (iv) A ^ X = B.
1.3.4 In a group of 1,000 students of a certain college, 60 take French, 417 take calculus, 
and 509 take statistics. Moreover, 20 take French and calculus, 17 take French and 
statistics, and 147 take statistics and calculus. However, 196 students do not take any 

INFINITE OPERATIONS ON EVENTS
13
of these three subjects. Determine the number of students who take French, calculus, 
and statistics.
1.3.5
1.3.6
D2 = exactly one occurs.
D4 = all occur.
D6 = at most one occurs.
D8 = exactly two occur.
D10 = B occurs.
Let A, B, and C be three events. Match, where possible, events D1 through D10 with 
events E1 through E11. Matching means that the events are exactly the same; that is, 
if one occurs, so must the other and conversely (see the Definition 1.3.2). (Hint: Draw 
a Venn diagram for each event D1, ...,D10, do the same for events E1, ...,E11,and 
then compare the diagrams.)
Among events A, B , C :
D1 = two or more occur.
D3 = only A occurs.
D5 = none occurs.
D7 = at least one occurs.
D9 = no more than two occur.
E 1 = A U B U C.
E2 = (A n Bc n Cc) U (Ac n B n Cc) U (Ac n Bc n C).
E3 = ( A n B) c n (A n C) c n (B n C) c.
E4 =(AUBUC)c.
E5 = Ac n Bc n Cc .
E6 = A n B n C.
E7 = B.
E8 = A n Bc n Cc .
E9 =(AnBnCc)U (AnBcnC)U (AcnBnC).
E10 =(An B n C)c.
E11 =(AnB) U (AnC)U (BnC).
A standard deck of cards is dealt among players N,S,E,and W.LetNk,k=1, 2, 3, 4 
be the event “N has at least k aces,” and let Sk ,Ek,andWk be defined similarly. For 
each of the events below, determine the number of aces that N has. (i) N1 n S1 n E1 n 
W1. (ii) E2 n (W2 U S2). (iii) N3\N4. (iv) S3 nW1. (v)S1cnW1cnE1c. (vi) N2 nE2.
1.3.7 Five burglars, A, B, C, D, and E, divide the loot, consisting of five identical gold bars 
and four identical diamonds. Let Ajk be the event that A got at least j gold bars and 
at most k diamonds. Let Bjk, Cjk denote analogous events for burglars B, C (e.g., 
B21 is the event that B got 2, 3, 4, or 5 gold bars and 0 or 1 diamond). Determine the 
number x of gold bars and the number y of diamonds received by E if the following 
events occur (if determination of x and/or y is impossible, give the range of values): 
(i) (A20UB20UC20)nD30. (ii) E1c2. (iii)A23nB13nC13nD13. (iv)A23UB13U 
C13 U D13.
1.3.8 Let Anc be defined inductively by A0c = A, A(n+1)c = (Anc)c. Find Amc n Anc and 
Amc U Anc for m, n > 0.
1.4 INFINITE OPERATIONS ON EVENTS
As already mentioned, the operations of union and intersection can be extended to infinitely 
many events. Let A1, A2, ... be an infinite sequence of events. Then,
^ 
^
A 1 U A2 U • •• = U Ai and A 1 n A2 n •• • = Q Ai
i=1 
i=1
are events “at least one Ai occurs” and “all Ai ’s occur,” respectively.

14
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
If at least one event Ai occurs, then there is one that occurs first. This remark leads to the 
following useful decomposition of a union of events into a union of disjoint events:
оо
UA = A1 U (Ac1 П A 2) U (Ac1 П A2 П A 3) u... , 
(1.6)
i=1
where Ac П ■ ■ ■ П Ack- 1 П Ak is the event “Ak is the first event in the sequence that occurs.” 
For an infinite sequence A1 ,A2 , ... one can define two events:
оо
lim sup An = P| |J Ai 
(1.7)
k=1 i=k
and
оо
liminfAn= 
Ai, 
(1.8)
k=1 i=k
these being, respectively, the event that “infinitely many Ai’s occur” and the event that “all 
except finitely many Ai’s occur.” Here the inner union in the event (1.7) is the event “at least 
one event Ai with i > k will occur”; call this event Bk. The intersection over k means that 
the event Bk occurs for every k . No matter how large k we take, there will be at least one 
event Ai with i > k that will occur. But this is possible only if infinitely many Ai s occur.
For the event lim inf An, the argument is similar. The intersection Ak П Ak+1 П ■ ■ ■ = Ck 
occurs if all events Ai with i > k occur. The union C1 U C2 U ■ ■■ means that at least one of 
the events Ck will occur, and that means that all Ai will occur, except possibly finitely many.
If all events (except possibly finitely many) occur, then infinitely many of them must 
occur, so that lim sup An D lim inf An. If lim sup An c lim inf An, then (see the definition 
of equality of events) we say that the sequence {An} converges, and lim sup An = lim inf An.
The most important class of convergent sequences of events consists of monotone 
sequences, when A1 c A2 c ■ ■ ■ (increasing sequence) or when A1 D A2 D ■ ■ ■ (decreasing 
sequence). We have the following theorem:
Theorem 1.4.1 If the sequence A1, A2, ... is increasing, then
о 
lim An = 
An,
n=1
and in case of a decreasing sequence, we have
о
lim An = 
An.
n=1
Proof: If the sequence is increasing, then the inner union (U0=1 Ai) in lim sup An remains 
the same independently of k so that lim sup An = J0=1 Ai. On the other hand, the inner 
intersection in lim inf An equals Ak so that lim inf An = Jk=1 Ak, which is the same as 
lim sup An, as was to be shown. A similar argument holds for decreasing sequences. □
The following two examples illustrate the concept of convergence of events.
■ EXAMPLE 1.16
Let B(r) and C(r) be the sets of points on the plane (x, y) satisfying the conditions 
x2 + y2 < r2 and x2 + y2 < r2, respectively. If An = B(1 + 1 /n), then {An} is a 
decreasing sequence, and therefore lim An = p|0=1 B (1 + 1 /n)• Since x2 + y2 <

INFINITE OPERATIONS ON EVENTS
15
(1 + 1 /n)2 for all n if and only if x2 + y2 < 1, we have p|n=1 B(1 + 1 /n) = C(1).
3In view of the fact proved earlier that all monotone sequences converge, this condition means that (a) if A 1 C 
A 2 C • • • is an increasing sequence of sets in A, then UiAi G A, and (b) if A 1 D A 2 D • • • is a decreasing sequence 
of sets in A, then niAi G A.
On the other hand, if An = C(1 - 1/n), then {An} is an increasing sequence, and 
lim An = J.^=1 C(1 - 1 /n) = B(1). We leave a justification of the last equality to the 
reader.
■ EXAMPLE 1.17
Let An = B(1 + 1/n) for n odd and An = B(1/3 - 1/2n) for n even. The sequence 
{An} is now B(2), B(1/12), B(4/3), B(5/24), ...,so it is not monotone. We have here 
lim sup An = C (1), since every point (x, y) with x2 + y2 < 1 belongs to infinitely many 
An. On the other hand, lim inf An = B(1/3). For x2 + y2 < 1/9, we have x2 + y2 < 
(1/3 - 1/2n)2 ifn is large enough (and also x2 + y2 < 1+1/n for all n). However, if 
x2 + У2 > 1 /3, then (x, У) does not belong to any An with even n. Thus, lim sup An = 
lim inf An, and the sequence {An } does not converge.
Infinite operations on events play a very important role in the development of the theory, 
especially in determining limiting probabilities.
The definitions below will prepare the ground for the considerations in the following 
chapters. In Chapter 2, we will introduce probability as a number assigned to an event. For­
mally, we will be considering numerical functions defined on events, that is, on subsets of the 
sample space S. As long as S is finite or countably infinite, we can take the class of all subsets 
of S as the domain of definition of probability. In case of infinite but not countable S (e.g., 
where S is an interval, the real line, or a plane), it may not be possible to define probability 
on the class of all subsets ofS. Although the explanation lies beyond the scope of this book, 
we will show how the difficulties can be avoided by suitable restriction of the class of subsets 
of S that are taken as events. We begin with the concept of closure under some operation.
Definition 1.4.1 We say that the class A of subsets of S is closed under a given operation if 
the sets resulting from performing this operation on elements of A are also elements of A. □
Complementation Ac, finite union A 1 U • • • U An, infinite union A 1 U A2 U • • •, limits 
of sequences lim An , are few examples of such operations.
■ EXAMPLE 1.18
Let S = {0, 1, 2, ...}, and let A consist of all subsets of S that are finite. A is 
closed under finite unions and all intersections, finite or not. Indeed, if A1, ...,An 
are finite sets, then A = A1 U •••UAn is also finite. Similarly, if A1, A2, ... are 
finite, then HiAi c A 1, and hence OiAi is also finite. However, A is not closed under 
complementation: if A is finite (A A A), then Ac is not finite, and hence Ac / A. On 
the other hand, if A is the class of all subsets of S that contain some fixed element, 
say 0, then A is closed under all intersections and unions, but it is not closed under 
complementation.
The following concepts have an important role in the theory of probability.
Definition 1.4.2 A nonempty class A of subsets of S that is closed under complementation 
and all finite operations (i.e., finite union, finite intersection) is called a field. If A is closed 
under complementation and all countable operations, it is called a a-field. Finally, if A is 
closed under monotone passage to the limit,3 it is called a monotone class. 
□

16
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
Let us observe that Definition 1.4.2 can be formulated in a more efficient way. For A to 
be a field, it suffices to require that if A,B e A, then Ac e A and A П B e A (or Ac & A 
and A U B e A). Any of these two conditions implies (by induction and De Morgan’s laws) 
the closure of A under all finite operations. Consequently, for A to be a a-field, it suffices 
to require that whenever A 1, A2, ... e A, then Ac e A and p|°=1 Ai e A (or A^ e A and 
UX1 Ai e A); this follows again from De Morgan’s laws.4
4 For various relations among classes of sets defined through closure properties under operations, for example, see 
Chow and Teicher (1997) and Chung (2001).
It is important to realize that closure under countable operations is stronger than closure 
under any finite operations. This means that there exist classes of sets that are fields but not 
a-fields. This is illustrated by the following example:
■ EXAMPLE 1.19
Let S = {1, 2, 3, ...}, and let A be the class of all subsets A of S such that either A 
or Ac is finite. Then A is a field but not a a-field. First, if A eA, then Ac e A because 
the definition of A is symmetric with respect to complementation. Next, if A and B 
are both in A, so is their union. If A and B are both finite, then A U B is finite and 
hence belongs to A. On the other hand, if either Ac or Bc (or both) are finite, then 
(A U B)c = Ac П Bc is also finite because it is contained in Ac and also in Bc.
Thus, A is a field. However, A is not a a -field. Let An be the set consisting only of 
the element n (i.e., An = {n}). Clearly, An e A. Take now [J^=1 A2n = {2, 4, 6, ... }. 
This is a countable union of sets in A that is not in A since the set of all even numbers 
is not finite, nor does it have a finite complement.
Typically, it is easy to determine that a class of sets is a field, while direct verification that 
it is a a-field can be difficult. On the other hand, it is sometimes easy to verify that a class of 
sets is a monotone class.
Theorem 1.4.2 A a-field is a monotone class. Conversely, a field that is a monotone class is a 
a-field.
Proof: To prove this theorem, assume first that Ais a a-field, and let A1, A2, ... be a mono­
tone sequence of elements of A .If A 1 c A 2 C • • •, then lim An = J n=1 An e A, whereas if 
A 1 D A2 D • • • , then lim An = p|n=1 An e A. So A is a monotone class. On the other hand, 
letAbe a monotone class and a field, and let A1, A2, ... be an arbitrary sequence of elements 
of A. Put Bn = A 1 U • • • U An. Then since A is a field, and also B 1 C B2 C • • • , Bn e A for 
every n. Further, since A is a monotone class, lim Bn e A. However, lim Bn |Jn=1 Bn 
= Un=1 An, so A is a a-field, as asserted. 
□
The last in this series of concepts is that of the minimal field (or a-field, or monotone 
class) containing a given set or collection of sets. We begin with some examples.
■ EXAMPLE 1.20
Let 5 be any set. On one extreme, the class consisting of two sets, 0 and 5, is closed 
under any operation so that A = {0,5} is a field, a a -field, and a monotone class. On 
the other extreme, the class of all subsets of5 is also closed under any operations, finite 
or not, and hence is a field, a a-field, and a monotone class. These two classes of subsets 
of 5 form the smallest and the largest fields (a-field, monotone class).

INFINITE OPERATIONS ON EVENTS
17
For any event A, it is easy to check that the class A, consisting of the four events 
{0, A, Ac, 5}, is closed under any operations: unions, intersections, and complements 
of members of A are again members of A. This class is an example of a field (a-field, 
monotone class) that contains the events A and Ac, and it is the smallest such field 
(a-field, monotone class).
On the other hand, the class A, consisting of events {0, A, S}, is a monotone 
class, but neither a field nor a-field. If A and B are two events, then the smallest field 
A containing A and B must contain also the sets Ac, Bc, the intersections A n B, 
A n Bc,Ac n B, Ac П Bc, as well as their unions A U B, A U Bc,Ac U B, and Ac U Bc. 
The closure property implies that unions such as (A n B) U (A U Bc), must also 
belong to A.
We are now ready to present the final step.
Theorem 1.4.3 For any nonempty class K of subsets of 5, there exists a unique smallest field 
(a-field, monotone class) containing all sets in K. It is called the field (a-field, monotone class) 
generated by K.
Proof: We will prove the assertion for fields. Observe first that ifA1 and A2 are fields, then 
their intersection A 1 n A2 (i.e., the class of sets that belong to both A 1 and A2) is also a field. 
For instance, if A, B e Ai (i = 1, 2), then A U B e Ai because each Ai is a field, and conse­
quently A U B e A 1 nA 2 .A similar argument holds for intersections and complements.
Note that if A 1 and A2 contain the class K, then the intersection A 1 n A2 also contains 
K. The property extends to any intersection of fields containing K (not only the intersections 
of two such fields).
Now, let C be the intersection of all fields containing K. We claim that C is the minimal 
unique field containing K. We have to show that (1) C exists, (2) C is a field containing K, 
(3) C is unique, and (4) C is minimal.
For property (1) it is enough to show that there exists at least one field containing K.We 
may take here the class of all subsets of S :itisafield(aswellasaa-field and monotone 
class), and it contains all sets in K. Property (2) follows from the fact that the intersection of 
fields containing K is a field containing K. Property (3) (i.e., uniqueness of C) follows from 
the fact that the result of the operation of intersection is unique.
Finally, suppose that there exists a field C' containing K such that C G C. Then C' must 
appear as one of the factors in the intersection defining C so that C G C'. Consequently, 
C = C. This completes the proof for the case of fields. The proofs for a-fields and monotone 
classes are exactly the same, since an intersection of a-fields (or monotone classes) containing 
K is again a a -field (monotone class) containing K. 
□
One may find it disturbing that Theorem 1.4.3 asserts the existence and uniqueness 
of some objects without giving a clue as to how to practically find them. In fact, the 
nonconstructive character of the theorem, combined with its generality, is instead a great 
help. As we will see in Chapter 2, the natural objects of our interest (the domains of 
definition of probability) will be a-fields of events. Beyond the trivial situations of finite 
or countably infinite sample spaces 5, where one can always consider the maximal a-field 
consisting of all subsets of 5, one is forced to restrict consideration to classes of events 
that form a-fields generated by some “simple” events. The events in these a-fields are 
typically of a very rich structure, and one seldom has useful criteria for distinguishing 
events (elements of the a-field in question) from “nonevents,” that is, subsets of5 to which 
probabilities are not assigned. However, as shown by the two examples below, the smallest 
a-field generated by some class is richer than the smallest field generated by the same 
class.

18
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
■ EXAMPLE 1.21
A point moves randomly on the plane, and its location is recorded at some time t. The 
outcome of this experiment is the pair (x, y) of coordinates of the observed location of 
the point (e.g., imagine here the location of a particle of dust in a liquid, tossed about 
by random hits from molecules of the medium, and performing Brownian motion; 
or imagine a location of a previously marked bird at the time of its capture in a bird 
migration study or the ages of both husband and wife at the time one of them dies).
In any study of this kind (regardless of its ultimate purpose), the “natural” sample 
space S is a plane or part of the plane, (the positive quadrant, etc.). The “simple” 
events here are of the form a < x < b,c < x < d, that is, rectangles with sides parallel 
to the axes. The reason for distinguishing these events as “simple” is that, as will be 
explained in later chapters, it is often easy to assign probabilities to these events. The 
reason for the particular configuration of strict and nonstrict inequalities (i.e., north 
and east side included, south and west side excluded) will also become apparent from 
the analysis below. To simplify the language, we will call such events Rectangles, 
and use a capital letter to signify the specific assumption about which sides are 
included and which are not. Naturally, we will allow for infinite Rectangles, such as 
{a < x < ж, —ж < y < b}.
It is easy to determine the field generated by all Rectangles: These are events that 
result from finite operations on Rectangles. Clearly, the complement of a Rectangle 
is a union of at most eight disjoint (infinite) Rectangles (see Figure 1.7), whereas the 
intersection of Rectangles is again a Rectangle (or is empty). Since unions are reduced 
to intersections of complements by De Morgan’s laws, every element of the smallest 
field containing all Rectangles is the union ofa finite number of disjoint Rectangles. On 
the other hand, there exist events that do not belong to this field of events. As a simple 
example, one might be interested in the event that the point (x, y) lies within distance 
r from some fixed point (from the initial location of the particle, the point of release 
of the bird, etc.). This event is a circle on the plane, and hence a subset of S, which is 
not decomposable into a finite number of Rectangles. On the other hand, a circle does 
belong to the a-field spanned by Rectangles: it is representable as a countable union of 
Rectangles, or equivalently, as an infinite intersection of sets built up of Rectangles.
Figure 1.7 Complement of a Rectangle.
Similarly, in this example there are other events, which are not in the field generated 
by Rectangles and which could be considered, such as triangles, rectangles with sides 
not parallel to the axes, and ellipses.

PROBLEMS
19
■ EXAMPLE 1.22
Take an experiment consisting of tossing a coin infinitely many times. The “natural” 
sample space 5 is the space of all infinite sequences x = (£ 1, £2, ...), where £i = 0 
or 1 (or any other two distinct symbols representing heads and tails). The “simple” 
events here are of the form “heads on the nth toss,” that is, sets of all infinite sequences 
x = (£1,£2, ...) with the nth coordinate £n satisfying £n =0. The events in the field 
generated by the simple events are of the form “heads on tosses k1, ...,kn and tails 
on tosses r1, ...,rm,” with both m and n finite and the outcomes of all other tosses 
remaining unspecified.
An event that does not belong to this field, but does belong to the a-field generated 
by the simple events, is the event that “as the number of tosses increases, the frequency 
of heads approaches a limit.” Clearly, to determine whether or not this event occurs, it 
does not suffice to know any finite number of coordinates £n .
To generalize this example, replace the outcome of the coin tosses by the result 
of some experiment repeated infinitely many times. This way the coordinate £n 
carries more information than it does for the outcome of nth coin toss. The “simple” 
events are now of the form of sets of sequences x = (£ 1, £ 1, ...) with £i & Ai for 
i =1, ...,n, while the £i’s for i>nare unconstrained. Here A1, ...,An are events 
that occur at the first n times of observations. The “simple” events described above, 
of an obvious interest and importance both in applications and in building the 
theory, are called “cylinder” events. The smallest a-field containing all cylinder events 
comprises all events that may be of interest, including those that are obtained through 
limits of sequences of cylinder events.
PROBLEMS
1.4.1 Let B 1, B2, ... be a countable partition of 5; that is, Bi n Bj = 0 for all i = j, and 
U iBi = 5. Let An = Bn U Bn+1 и---. Find lim An.
1.4.2 Assume that John will live forever. He plays a certain game each day. Let Ai be the 
event that he wins the game on the ith day. (i) Let B be the event that John will win 
every game starting on January 1, 2035. Label the following statements as true or false: 
(a) B = lim inf An. (b) B c lim inf An. (c) B D lim sup An. (d) B = lim sup An. 
(ii) Assume now that John starts playing on a Monday. Match the following events 
C1 through C9 with events D1 through D11:
C1 = John loses infinitely many games.
C2 = When John loses on a Thursday, he wins on the following Sunday.
C3 = John never wins on three consecutive days.
C4 = John wins every Wednesday.
C5 = John wins on infinitely many Wednesdays.
C6 = John wins on a Wednesday.
C7 = John never wins on a weekend.
C8 = John wins infinitely many games and loses infinitely many games.
C9 = If John wins on some day, he never loses on the next day.
D 
TO [A 
II A , 
J 
D 
TO A
D1 = j=0[A7j+4 U A7(j+1)], 
D2 = j=0 A7j+3,
D 
TO [Ac 
n Ac 
] 
D 
-*- 
c- 
ac
D3 = j=0[A7j+6 n A7(j +1)], 
D4 = 
n=1 k=n Ak,
D5 = ni=1[Ac U Ac+1 и Ac+2], 
D6 = П.' 
U==n A7k+3,
D7 = [uj=0[A7j+6 U A7(j + 1)]] , 
D8 = Uj=0 A7j+3,

20
EXPERIMENTS, SAMPLE SPACES, AND EVENTS
OO 
n c 
O 
O 
c
D 9 U n=0 { ID i =1 Ai ] ЩП k=n +1 Ak , 
D10 
1 Di =0[ Ai П Ai +1 П Ai+2]} ,
OOc 
OO
D11 = [Пn =1 Uk=n Ak] П [Пj = 1 Um = j Am\ .
1.4.3 Let A1, ...,An be distinct subsets ofS. (i) Find the maximum number of sets (includ­
ing 5 and 0) of the smallest field containing A 1, .. .,An. (ii) Find the maximum 
number of sets in this field if An- 1 C An. (iii) Answer (ii) if A 1 C A2 C • • • C An. 
(iv) Answer (ii) if A 1 = • • • = An = 0. (v) Answer (i)-(iv) for a a-field.
1.4.4 For 0 < a < 1, let I(a) = {x :1 — a < x < 1 + a}. Consider a sequence a 1, a2, ... 
of numbers satisfying 0 < an < 1 for all n, and let An = I(an). (i) Find limsupAn 
and lim inf An . (ii) Find conditions, expressed in terms of an , under which 
lim An exists, and find this limit. (iii) Define J(a) = {x : 1 — a < x < 1 + a} and 
Bn = J(an). Answer questions (i) and (ii) for sequence {Bn}.
1.4.5 Let 5 = {0, 1, 2, ...} be the set of all integers. For A C 5, let fn(A) be the number of
elements in the intersection A П {0, 1, ..., n}. Let A be the class of all sets A for which
the limit
q(A) = lim
n—>O
fn ( A ) 
n
exists. Show that A is not a field. [Hint: Let A1 = {1, 3, 5, ...} and A2 ={ all odd 
integers between 22n and 22n+1 and all even integers between 22n+1 and 22n+2 for 
n = 0, 1, ... }. Show that both A 1 and A2 are in A but A 1 П A2 / A.]
1.4.6 Let S = (—ж, + ж). Show that the class of all finite unions of intervals of the form 
[a, b], (a, b), [a, b), and (a, b], with possibly infinite a or b (intervals of the form [a, ж), 
etc.) forms a field.

CHAPTER 2
PROBABILITY
2.1 
INTRODUCTION
The concept of probability has been an object of debate among philosophers, logicians, 
mathematicians, statisticians, physicists, and psychologists for the last couple of centuries, 
and this debate is not likely to be over in the foreseeable future. As advocated by Bertrand 
Russell in his essay on skepticism, when experts disagree, the layman would do best by 
refraining from forming a strong opinion. Accordingly, we will not enter into the discus­
sion about the nature of probability; rather, we will start from the issues and principles that 
are commonly agreed upon.
Probability is a number associated with an event that is intended to represent its 
“likelihood,” “chance of occurring,” “degree of certainty,” and so on. Probabilities can 
be obtained in several ways, the most common being (1) the frequency (or objective) 
interpretation, (2) the classical (sometimes called logical) interpretation, and (3) the 
subjective or personal interpretation of probability.
2.2 
PROBABILITY AS A FREQUENCY
According to the common interpretation, probability is the “long-run” relative frequency of 
an event. The idea connecting probability and frequency is (and had been for a long time) 
very well grounded in everyday intuition. For instance, loaded dice were on several occasions 
found in the graves of ancient Romans. That indicates that they were aware of the possibility 
of modifying long-run frequencies of outcomes, and perhaps making some profit in such 
a way.
Today, the intuition regarding relationship between probabilities and frequencies is even 
more firmly established. For instance, the phrases “there is 3% chance that an orange picked
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc. 
21

22
PROBABILITY
at random from this shipment will be rotten” and “the fraction of rotten oranges in this 
shipment is a 3%” appear almost synonymous. But on closer reflection, one realizes that the 
first phrase refers to the probability of an event “randomly selected orange will be rotten,” 
while the second phrase refers to the population of oranges.
The precise nature of the relation between probability and frequency is hard to formu­
late. But the usual explanation is as follows: Consider an experiment that can be repeated 
under identical conditions, potentially an infinite number of times. In each of these repeti­
tions, some event, say A, may occur or not. Let N(A) be the number of occurrences of A in 
the first N repetitions. The frequency principle states that the ratio N (A)/N approximates 
the probability P (A) of event A, with the accuracy of the approximation increasing as N 
increases.
Let us observe that this principle serves as a basis for estimating probabilities of various 
events in the real world, especially those probabilities that might not be attainable by any 
other means (e.g., the probability of heads in tossing a biased coin).
We start this chapter by putting a formal framework (axiom system) on a probability 
regarded as a function on the class of all events. That is, we impose some general conditions 
on a set of individual probabilities. This axiom system, due to Kolmogorov (1933), will be 
followed by the derivation of some of its immediate consequences. The latter will allow us 
to compute probabilities of some composite events given the probabilities of some other 
(“simpler”) events.
2.3 
AXIOMS OF PROBABILITY
Let S be the sample space, namely the set of all outcomes of an experiment. Formally, prob­
ability, to be denoted by P, is a function defined on the class of all events,1 satisfying the 
following conditions (usually referred to as axioms):
Axiom 1 (Nonnegativity):
P(A) > 0 for every event A.
Axiom 2 (Norming):
P(S) = 1.
Axiom 3 (Countable Additivity):
<tt
P (A i U A 2 U--- ) = £ P (Ai)
i=1
for every sequence of pairwise disjoint events A 1 ,A 2,..., (such that Ai П Aj = 0 
for all i = j). 
□
If the sample space S is finite or countable, one can define a probability function P as fol­
lows: Let f be a nonnegative function defined on 5, satisfying the condition ^2seS f (s) = 1. 
Then, P may be defined for every subset A of 5 as P(A) = seA f (s). One can easily check 
that P satisfies all three axioms.
Indeed, P(A) > 0 because f is nonnegative, and P(S) = 
seS f (s) = 1. Finally, let
A1 ,A2 , . . . be a sequence of disjoint subsets of S. Then,
P(A1)+ P(A2) + --- = p f(s)+ p f(s) + ---
C
*K'
Ai
i=1
1The nature of the class of all events will be (to a certain extent) explicated in Section 2.6. See also Section 1.4.

AXIOMS OF PROBABILITY
23
Passing from the first to the second line is allowed because A1 ,A2, ... are disjoint, so each 
term appears only once. The sum in the second line is well defined (i.e., it does not depend 
on the order of summation because the terms are nonnegative).
However, if S is not countable, one usually needs to replace summation by integration, 
P(A)= A f(s) ds. This imposes some conditions on functions f and on the class of events 
A. For a detailed discussion, the reader is referred to more advanced probability texts (e.g., 
Chung, 2001).
■ EXAMPLE 2.1 Geometric Probability
One of the first examples of an uncountable sample space is associated with “the ran­
dom choice of a point from a set.” This phrase is usually taken to mean the following: 
a point is selected at random from a certain set S in a finite-dimensional space (line, 
plane, etc.), where S has finite measure (length, area, etc.), denoted generally by |S|. 
The choice is such that if A (A c S) has measure |A|, then the probability of the chosen 
point falling into A is proportional to |A|. Identifying S with the sample space, we can 
then write P(A) = |A|/|S|.
To better see this, suppose that in shooting at a circular target S, one is certain to 
score a hit, and that the point where one hits S is assumed to be chosen at random in 
the way described above. What is the probability that the point of hit is farther from 
the center than half of the radius of the target?
From Figure 2.1, it is clear that the point of hit must lie somewhere in the shaded 
annulus A. Itsareais |A| = nR2 - n (R/ 2)2 so that P (A) = \A\/nR2 = 3 / 4.Ofcourse, 
the assumption under which this solution is obtained is not very realistic: typically sets 
closer to the center are more likely to be hit than sets of the same area located closer 
to the perimeter.
Figure 2.1 Hitting a target.
The concept of “random choice” from an uncountable set is sometimes ambiguous. This 
is illustrated by the next example.
■ EXAMPLE 2.2 Bertrand’s Paradox
A chord is chosen at random in a circle. What is the probability that the length of the 
chord will exceed the length of the side ofan equilateral triangle inscribed in the circle?

24
PROBABILITY
This problem was originally posed in 1888 by Joseph Bertrand, a French mathe­
matician, who provided three solutions, all valid, but yielding inconsistent results.
SOLUTION 1. The chord is uniquely determined by the angle a (see Figure 2.2). 
These angles are chosen at random from the interval (0, п). It is clear that the length 
of the chord exceeds the side of the equilateral triangle if a lies between п/3 and 2п/3, 
so the answer to the question is 1/3.
Figure 2.2 First solution of Bertrand’s problem.
SOLUTION 2. Let us draw a diameter QQ' (see Figure 2.3) perpendicular to the 
chord P . Then, the length of the chord exceeds the side of the equilateral triangle 
if it intersects the line QQ' between points B and B'. Elementary calculations give 
\BB'\ = \QQ'\/2, so the answer is 1 /2.
Figure 2.3 Second solution of Bertrand’s problem.
SOLUTION 3. The location of the chord is uniquely determined by the location of 
its center (except when the center coincides with the center of the circle, which is an 
event with probability zero). For the chord to be longer than the side of the equilateral 
triangle inscribed in the circle, its center must fall somewhere inside the shaded circle 
in Figure 2.4. Again, by elementary calculations, we obtain probability 1/4.

AXIOMS OF PROBABILITY
25
Figure 2.4 Third solution of Bertrand’s problem.
The discovery of Bertrand’s paradox was one of the impulses that made researchers in 
probability and statistics acutely aware of the need to clarify the foundations of the theory, 
and ultimately led to the publication of Kolmogorov’s book (1933). In the particular instance 
of the Bertrand “paradoxes,” they are explained simply by the fact that each of the solutions 
refers to a different sampling scheme: (1) choosing a point on the circumference and then 
choosing the angle between the chord and the tangent at the point selected, (2) choosing 
a diameter perpendicular to the chord and then selecting the point of intersection of the 
chord with this diameter, and (3) choosing a center of the chord. Random choice according 
to one of these schemes is not equivalent to a random choice according to the other two 
schemes.
To see why it is so, we will show that the first and second scheme are not equivalent. The 
analogous arguments for the other two possible pairs of schemes are left as an exercise.
■ EXAMPLE 2.3
Imagine different devices (physical mechanisms, computer programs, etc.) built for 
sampling random chords. One scheme chooses a point on the circumference, and 
then the angle a between the chord and the tangent to the circle at the point chosen 
(Figure 2.2). The second scheme chooses first the direction of the diameter and 
then the point B on the diameter, at which the chord perpendicular to this diameter 
intersects it (Figure 2.3). From Figure 2.5, it is seen that the angle AOB is a, and
Figure 2.5 Explanation of Bertrand’s paradox.

26
PROBABILITY
therefore y = \OB\ = cos a. Thus, dy = (sin a) da, which means that equal changes 
of a do not produce equal changes of y. In fact, these changes are smaller when a is 
small. Consequently, a device that chooses angles a at random will tend to produce 
more intersections of the diameter that are farther from the center (i.e., more chords 
will be shorter).
PROBLEMS
2.3.1 Label all statements below as true or false. (i) If A is more likely to occur than 
Ac, then P(A) > 0.5. (ii) If A occurs whenever B does, then P(B) < P(A). 
(iii) If P(A) < P (B), then whenever B occurs, A does also. (iv) If P(A) = 0.75, then 
A must occur three times out of every four. (v) The sum of probabilities of disjoint 
events A and B cannot exceed 1. (vi) IfA and B are not disjoint, the sum of their prob­
abilities exceeds 1. (vii) If P(A П B), P(A П C), and P(B П C) are all positive, then 
P (A П B П C) is also positive. (viii) If sample spaces for two experiments are identical, 
then the probability of the same event A must be the same for both experiments.
2.3.2 A bathroom floor is covered by square tiles with side length a. You drop a coin with 
diameter b,whereb<a. Find: (i) The probability that the coin will rest entirely within 
one tile. (ii) The probability that the coin will partially cover four different tiles.
2.3.3 Show that first and third, as well as second and third, schemes of sampling chords (see 
Bertrand’s paradox) are not equivalent.
2.4 CONSEQUENCES OF THE AXIOMS
The simplest consequences of the axioms of probability are as follows:
1. The probability of the impossible event is zero:
P (0) = 0.
(2.1)
This follows from the fact 1 = P(S) = P (S U 0 U 0 U • • • ) = P (S) + P(0) + P(0) + 
• • • , which is possible only if P(0) = 0. It is important to realize that the converse is not 
true: the condition P(A) = 0 does not imply that A = 0. This is shown by the following 
example:
■ EXAMPLE 2.4
Consider an experiment consisting of tossing a coin infinitely many times. The out­
comes may be represented as infinite sequences of the form HHTHTTHT ...sothat 
the sample space S contains infinitely many of such sequences. The event “heads 
only,” that is, the set consisting of just one sequence HHHH ..., is not empty. 
However, the chance of such an outcome is, at least intuitively, zero: tails should 
come up sooner or later.
2. Probability is finitely additive:
P(A1 U • • • U An ) = P (A1) + 
+ (An )
for any n =1, 2, ...,ifthe events Ai are pairwise disjoint.

CONSEQUENCES OF THE AXIOMS
27
In an infinite sequence A 1, ...,An, 0, 0, ..., events are pairwise disjoint only if 
A1, ...,An are, so Axiom 3 applies. Therefore, using (2.1), we have
P (A 1 U • • • U An U 0 U ••• ) = P (A 1) + • •• + P (An) + P (0) + • ••
= P (A 1) + 
+ P (An),
while the left-hand side is P (A 1 U • • • U An).
3. Monotonicity: If A C B then P(A) < P(B). This follows from the fact that 
B = A U (B П Ac). The events on the right-hand side are disjoint, so we have 
P (B) = P (A) + P (B П Ac) > P (A) by Axiom 1. Since A CS for every event A, we 
have 0 < P(A) < 1.
4. Probability is countably subadditive:
(
. 
\
jAj < P(A1) + P(A2) + ••• , 
(2.2)
n=1
for every sequence of events A1, A2, ..... This follows from representation (1.6) as a union
of disjoint events, and then from monotonicity. We have
(
. 
\
U An = P(A 1) + P(Ac1 П A2) + P(Ac1 П Ac П A3) + ••• 
n=1
< P(A 1)+ P(Ac)+ P(A3) + ••• .
5. Complementation:
P(Ac)=1- P (A). 
(2.3)
This follows from Axiom 2, by the fact that A and Ac are disjoint and A U Ac = S .
6. Probability of a union of events:
P(A U B)= P(A)+ P(B) - P(A П B). 
(2.4)
Indeed, since A U B = A U (Ac П B), then P(A U B)= P(A)+ P(Ac П B). On the 
other hand, B = (A П B) U (Ac П B), and hence, P(B) = P(A П B)+ P(Ac П B). 
Solving for P(Ac П B) in one equation and substituting into the other, we obtain (2.4).
A more intuitive argument may be made by using Venn diagrams (see Figure 2.6). In the 
sum P(A) + P(B), each sample point from the intersection A П B is included twice, so to 
obtain the probability of the union A U B, we must subtract the probability P (A П B).
Figure 2.6 Union of two events.
■ EXAMPLE 2.5
Suppose that P(A) = 0.4, P(Bc) = 0.6, P(Ac П B) = 0.1. Find P(A U Bc).
SOLUTION. The best strategy for solving this kind of problem is finding the 
probabilities of all the intersections (in this case, A П B, A П Bc, Ac П B, Ac П Bc).

28
PROBABILITY
The probability P(Ac П B) = 0. 1 is given. Next, (A П B) U (Ac n B) = B, and the 
events on the left are disjoint. So P(A n B) + P(Ac n B)= P(B) = 1 - P(Bc), 
which means that P(A n B) + 0.1 = 1 — 0.6, and hence, P(A П B) = 0.3. Then, using 
A =( A n B) U (A n Bc), we have 0.4 = P (A )= P (A n B) + P (A n Bc )=0.3 + 
P(A n Bc); hence, P(A n Bc) = 0.1. similarly P(Ac n Bc) = 0.5. Applying formula 
(2.3), we have P(A U Bc) = P(A) + P(Bc) — P(A n Bc) = 0.4 + 0.6 — 0.1 = 0.9.
For the case of three events: A, B, and C, the same argument based on Venn dia­
grams gives the formula
P(AUBUC)=P(A)+P(B)+P(C)
—P (A n B) — P (A n C) — P (B n C)
+P (A n B n C).
(2.5)
It can be checked at Figure 2.7 that the formula (2.5) includes each part of the union 
A U B U C exactly once.
Figure 2.7 Union of three events.
Formula (2.5) may be generalized to the case of the union of any finite number of events.
Theorem 2.4.1 For any events A1, ...,An
n
P (A1 U---U An ) = £ P (Ai) — 
P (Ai 1 n Ai 2)
i =1 
1 <ii <i2 <n
+ 
P (Ai 1 П Ai 2 П Ai 3 ) +
1 <i i <i 2 <i з <n
+ (—1)n+1 P(A1 n-.-n An). 
(2.6)
Proof: We will proceed by induction. The theorem is true for n =1. Assume now that for­
mula (2.6) holds, and write
Since
(
n +1 
\ 
П n \ 
П 
n
Ai = P 
Ai + P An+1 \ 
Ai
11 
1
(
n \ 
n 
n
An+1 n 
Ai + P An+1 \ 
Ai
11

CONSEQUENCES OF THE AXIOMS
29
we have
(
n +1 
\ 
n n \
Ai =P 
Ai +P(An+1)-P
n
U(Ai n An+1)
1
Applying formula (2.6) to P(Jn Ai) and to P [Unn(Ai n An+1)], and then combining the 
corresponding terms, we obtain (2.6) with n replaced by n +1. 
□
PROBLEMS
2.4.1 Let events A, B,andC be such that A contains B and is disjoint from C . Moreover, 
A is twice as likely as B, three times as likely as C, and half as likely as its complement 
Ac. Find P(B U C).
2.4.2 Events A, B, and C are such that A n B = A n C = 0 while B n C is not 
empty. Determine P(A U B U C) as a function of x if P(A)=P(B)=P(C)= 
3P(B n C)=x.
2.4.3 Find P(A U Bc) for events A and B such that P(A)=P(B)=1/2,and 
P(Ac n Bc) = 1/3.
2.4.4 To make the formula P [(Ac n Bc)c]=2- P (Ac) - P (Bc) - x valid, x must equal: 
(1)P(AUB).(2)P(AnB).(3)P(AcUBc). (4) None of the above.
2.4.5 Three events A, B,andC are such that C is contained in the intersection 
Ac nB,P(A)=0.6,P(AnB)=0.3,andP(C)=P(AcnBc)=0.1. Find: (i) 
P (B). (ii) The probability that exactly two of the events A, B, C will occur. (iii) The 
probability that exactly one of the events A, B, C will occur.
2.4.6 Let A, B, C, D, and E be five events such that P(A) = P(B) = • • • = P(E) = k and 
P (A n B) = P (A n C) = • • • = P(D n E) = p. Moreover, at least one of the events 
A, ...,Emust occur, and the intersection of any three events among A,B, ...,E is 
empty. (i) Find p if k = 0.3. (ii) Omit the assumption that at least one of the events 
must occur and determine all possible values of k if it is known that p = 0.01.
2.4.7 If events A1, ... A101 are such that P(A1) = • • • = P(A101) = 0.01, P(A1 n A2) = 
P (A1 n A3) = • • • = P(A100 n A101) = r, while every triple intersection is empty, 
find the smallest possible value of the probability of intersection r.
2.4.8 Before the era of cell phones (a time that most of today’s students do not remember), 
people often used public phones that operated after a coin was inserted. These phones 
were sometimes faulty and either took a coin without giving a connection or gave 
the connection but also returned the coin. (i) A faulty public phone returns the coin 
with probability 60%, it gives you the number you dial with probability 20%, and 
it takes your coin and does not give you the required connection with probability 
30%. Find the probability that you will talk with the number you dial for free. (ii) A 
certain public phone is such that it returns the coin with probability a, connects you 
with the number you dial with probability b, and it gives you the connection for free 
with probability c. Let us agree to say that the phone is individually honest if it takes 
your money if and only if it provides you with the required connection, and that it is 
socially honest if it takes, on average, as many coins asit gives correct connections (but 
perhaps from different customers). Find conditions for a, b,andc under which the 
phone is individually honest. (iii) Find conditions under which the phone is socially 
honest.

30
PROBABILITY
2.4.9 Based on a survey of undergraduate sophomores at a certain university, the 
researchers found out that 67% of students live in a dorm (D), 52% are interested 
in studying abroad (A), and 48% are planning to attend graduate school (G). Fur­
thermore, 32% live in a dorm and are planning studying abroad, 30% are planning 
to study abroad and continue their education in a graduate school, while 30% live 
in a dorm and plan to apply to graduate schools. Moreover, 20% of sophomores 
answered all three questions positively (D П A П G). What is the probability that a 
randomly selected sophomore at this university either lives in a dorm, or is thinking 
of studying abroad, or is planning to apply to a graduate school?
2.4.10 A die is loaded in such a way that the probability of j dots on the top face is propor­
tional to j,forj =1, 2, ...,6. What is the probability that in one roll of the die an 
odd number of dots will turn up?
2.5 CLASSICAL PROBABILITY
For the so-called classical or logical interpretation of probability, we will assume that the 
sample space S contains a finite number N of outcomes and all of these outcomes are equally 
probable.
Obviously, in this case, each of the outcomes has the same probability 1/N, and for every 
event A,
number of outcomes in A
P (A) =---------------N--------------- • 
(2.7)
In many real situations, the outcomes in the sample space reveal a certain symmetry, derived 
from physical laws, from logical considerations, or simply from the sampling scheme used. 
In such cases, one can often assume that the outcomes are equiprobable and use (2.7) as a 
rule for computing probabilities. Obviously, the function P in (2.7) satisfies the axioms of 
probability.
To use some very simple examples, in tossing a regular die, each face has the same proba­
bility 1/6. Then the probability of the event A = “outcome odd” is P(A) = 3/6 = 1/2, since 
there are three odd outcomes among the possible six.
The case above is rather trivial, but considerations of symmetry can sometimes lead to 
unexpectedly simple solutions of various problems.
■ EXAMPLE 2.6
Peter tosses a fair coin n times, and Paul tosses it n +1 times. What is the probability 
that Paul tosses more heads than Peter?
SOLUTION. Either Paul tosses more heads than Peter (event A) or he tosses more 
tails than Peter (event B). These two events exclude one another and exhaust all pos­
sibilities (since one cannot have ties in number of heads and number of tails). Switch­
ing the role of heads and tails transforms one of these events into the other. Thus, 
sample space becomes partitioned into two equiprobable events, and we must have 
P(A) = 1/2.
The use of (2.7) requires techniques for counting the numbers of elements in some sets. 
These topics, known under the name combinatorics, will be discussed in Chapter 3.

NECESSITY OF THE AXIOMS*
31
PROBLEMS
2.5.1 A coin is tossed seven times. Assume that each of the 27 = 128 possible outcomes 
(sequences like HTTHHTH of length 7) is equally likely. Relate each outcome to 
a binary number by replacing H by 1 and T by 0, for example, THHHTTH is 
0111001 = 57. Find the probability that a number generated in this way lies between 
64 and 95 (inclusive on both sides).
2.5.2 A number X is chosen at random from the series 4, 9, 14, 19, ..., and another number 
Y is chosen from the series 1, 5, 9, 13, .......Eachserieshas100terms.FindP(X = Y ).
2.5.3 A regular die and a die with 2, 3, 5, 6, 7, and 8 dots are tossed together, and the total 
number of dots is noted. What is the probability that the sum is greater than or equal 
to 10?
2.5.4 Use formula (2.6) to find the number of primes not exceeding 100. [Hint: Assume that 
you sample one of the numbers 1, 2, ..., 100. Let Ai be the event “the number sam­
pled is divisible by i.” Determine p = P(A2 U A3 U A5 U A7). Then the answer to the 
problem is 100(1 - p) + 3 (why?).]
2.6 NECESSITY OF THE AXIOMS*
Looking at Axiom 3, one may wonder why do we need it for the case of countable (and 
not just finite) sequences of events. Indeed, the necessity of all three axioms, with only finite 
additivity in Axiom 3, can be easily justified simply by using probability to represent the lim­
iting relative frequency of occurrences of events. Recall the symbol N (A) from Section 2.1 
for the number of occurrences of the event A in the first N experiments. The nonnegativ­
ity axiom is simply a reflection of the fact that the count N (A) cannot be negative. The 
norming axiom reflects the fact that event S is certain and must occur in every experi­
ment so that N(S) = N, and hence, N(S)/N =1. Finally, (taking the case of two disjoint 
events A and B), we have N(A U B)=N (A)+N (B), since whenever A occurs, B does 
not, and conversely. Thus, if probability is to reflect the limiting relative frequency, then 
P(A U B) should be equal to P(A)+P(B), since the frequencies satisfy the analogous con­
dition N(A U B)/N = N(A)/N + N(B)/N.
The need for countable additivity, however, cannot be explained so simply. This need is 
related to the fact that to build a sufficiently powerful theory, one needs to take limits. If 
A 1, A2, ... is a monotone sequence of events (increasing or decreasing, i.e., A 1 c A2 C • • • 
or A 1 D A2 • • •) then limP(An) = P(lim An), where the event lim An has been defined in 
Section 1.4. Upon a little reflection, one can see that such continuity is a very natural require­
ment. In fact, the same requirement has been taken for granted for over 2,000 years in a 
somewhat different context: in computing the area of a circle, one uses a sequence of poly­
gons with an increasing number of sides, all inscribed in the circle. This leads to an increasing 
sequence of sets “converging” to the circle, and therefore the area of the circle is taken to be 
the limit of the areas of approximating polygons. The validity of this idea (i.e., the assump­
tion of the continuity of the function f(A) = area ofA) was not really questioned until the 
beginning of the twentieth century. Research on the subject culminated with the results of 
Lebesgue.
To quote the relevant theorem, let us say that a function P, defined on a class of sets 
(events), is continuous from below at the set A if the conditions A 1 c A 2 c • • • and A = UAn 
imply that limP(An) = P(A). Similarly, P is continuous from above at the set A if the condi­
tions A 1 D A2 D • • • and A = nAn imply lim P (An) = P (A). A function that is continuous 

32
PROBABILITY
at every set from above or from below is simply called continuous (above or below). Conti­
nuity from below and from above is simply referred to as continuity.
We may characterize countable additivity as follows:
Theorem 2.6.1 If the probability P satisfies Axiom 3 of countable additivity, then P is contin­
uous from above and from below. Conversely, if a function P satisfies Axioms 1 and 2, is finitely 
additive, and is either continuous from below or continuous from above at the empty set ty, then 
P is countably additive.
Proof: Assume that P satisfies Axiom 3, and let A 1 c A2 C • • • be a monotone increasing 
sequence. We have
oo
U An = A 1 u (A2 n A1) u (A3 n A2) 
•
n=1
= A i u (A 2 \ A i) u (A з \ A 2) u-.. 
(2.8)
the events on the right-hand side being disjoint. Since uAn = lim An (see Section 1.5), using 
(2.8), and the assumption of countable additivity, we obtain
o
P( lim An) = P(иПп) = P(Ai) + £[P(Ai) - P(Ai—1)] 
n—>o 
' *i=2 
n
= P (Ai) + nl—imo 
[P(Ai) - P(Ai-i)]
i=2
= P(Ai) + lim [P(An)-P(Ai)]= lim P(An) 
n—o 
n—o
(passing from the first to the second line, we used the fact that the infinite series is defined 
as the limit of its partial sums). This proves continuity of P from below. To prove continuity 
from above, we pass to the complements, and proceed as above.
Let us now assume that P is finitely additive and continuous from below, and let 
A 1, A2, ... be a sequence of mutually disjoint events. Put Bn = A 1 u • • • u An so that 
B 1 C B2 C • • • is a monotone increasing sequence with uAn = UBn. We have then, using 
continuity from below and finite additivity,
P(UAn) = P(BBn) = P( lim Bn) = lim P (Bn) 
n—o 
n—o
o
= n—m [P(A 1) + • • • + P(An)] 
P(An).
n=1
again by definition of a numerical series being the limit of its partial sums. This shows that 
P is countably additive.
Finally, let us assume that P is finitely additive and continuous from above at the 
empty set ty (impossible event). Taking again a sequence of disjoint events A1, A2, ..., let 
Cn = An +1 u An+2 u • • •. We have C 1 D C2 D • • • and lim Cn = QnCn = 0. By finite 
additivity, we obtain
(
co 
\ 
n n 
\
UaJ = P U Ai u Cj = P (A 1) + ... + P (An) + P (Cn). 
(2.9)
i=1 
i=1

NECESSITY OF THE AXIOMS*
33
Since (2.9) holds for every n, we can write
P (UAi) = lim[ P (A i) + ••• + P (An) + P (Cn)]
oo
= lim[ P (A i) + ••• + P (An)] + lim P (Cn) = £ P (A).
n=1
Again, by the definition of series and the assumption that lim P(Cn) = 0, P is countably 
additive, and the proof is complete. 
□
As an illustration, we now prove the following theorem:
Theorem 2.6.2 (First Borel-Cantelli Lemma) If A 1 ,A 2, ... is a sequence of events such that
o
PA(An) < *>, 
(2.10)
n=1
then
P(limsupAn)=0.
Proof: Recall (1.7) from Chapter 1, where lim sup An = “infinitely many events Aj occur” 
= Пo=1 U°=kAi = limk—oU°=kAi (because the unions U°=kAi,k = 1,2,... form a 
decreasing sequence). Consequently, using the continuity of P, subadditivity property (2.2), 
and assumption (2.10), we have
P (lim sup An) = lim P 
k—>o
oo
UAJ < lim £P(Ai)=0.
k—o
i=k 
i=k
□
Paraphrasing the assertion of the lemma, if probabilities of events Aj decrease to zero fast 
enough to make the series converge, then with probability 1 only finitely many among events 
Aj will occur. We will prove the converse (under an additional assumption), known as the 
second Borel-Cantelli lemma, in Chapter 4.
In the remainder of this section, we will discuss some theoretical issues related to defining 
probability in practical situations. Let us start with the observation that the analysis above 
should leave some more perceptive readers disturbed. Clearly, one should not write a for­
mula without being certain that it is well defined. In particular, when writing P(• • • ) two 
things ought to be certain: (1) that what appears in the parentheses is a legitimate object of 
probability, that is, an event and (2) that the function P is defined unambiguously at this 
event.
With regard to the first point, the situation is rather simple. All reasonable questions con­
cern events such as lim An and limsupAn , and hence events obtained by taking countable 
unions, countable intersections, and complementations of the events A1 ,A2 ..... Thus, the
events whose probabilities are discussed belong to the smallest a-field containing all the 
events A1, A2, ... (see Definition 1.4.2 and Theorem 1.4.3). Consequently, to make the for­
mulas at least apparently legitimate, it is sufficient to assume that the class of all the events 
under considerations is a a-field, and that probability is a function satisfying the probability 
axioms defined on this a-field.
This assumption alone, however, is not enough to safeguard us from possible trouble. 
Let us consider the following hypothetical situation: Suppose that we do not know how 
to calculate the area of a circle. We could start from the beginning and define the areas of 
simple figures: first rectangles, then pass to right triangle, and then to arbitrary triangles, 

34
PROBABILITY
which could be reduced to sums and differences of right triangles. From there, the concept 
of area could be extended to figures that could be triangulated. It is a simple matter to show 
that the area of such a figure does not depend on how it is triangulated.
From here, we may pass to areas of more complicated figures, the first of these being the 
circle. The area of the latter could be calculated by inscribing a square in it, and then taking 
areas of regular polygons with 8, 16, 32, ... sides and passing to the limit. The result is nr2. 
The same result is obtained if we start by inscribing an equilateral triangle, and then take 
limits of the areas of regular polygons with 6, 12, 24, ... sides. The same procedure could be 
tried with an approximation from above, that is, starting with a square or equilateral triangle 
circumscribed on the circle. Still the limit is nr2. We could then be tempted to conclude that 
the area of the circle is nr2. The result is, of course, true, but how do we know that we will 
obtain the limit always equal to nr 2, regardless of the way of approximating the circle? What 
ifwe start, say, from an irregular seven-sided polygon, and then triple the number of sides in 
each step?
A similar situation occurs very often in probability: Typically, we can define probabilities 
on “simple” events, corresponding to rectangles in geometry, and we can extend this defi­
nition without ambiguity to finite unions of the simple events (“rectangles”). The existence 
and uniqueness of a probability of all the events from the minimal a-field containing the 
“rectangles” is ensured by the following theorem, which we state here without proof.
Theorem 2.6.3 IfP is a function defined on a field of events A satisfying the probability axioms 
(including countable additivity), then P can be extended in a unique way to a function satisfying 
the probability axioms, defined on the minimal a-field containing A.
This means that if the function P is defined on a field A of events and satisfies all the 
axioms of probability, and if a(A) is the smallest a-field containing all sets in A, then there 
exists exactly one function P* defined on a (A) that satisfies the probability axioms, and 
P* (A) = P (A) if A eA.
A comment that is necessary here concerns the question: What does it mean that a func­
tion P defined on a field A satisfies the axioms of probability? Specifically, the problem 
concerns the axiom of countable additivity, which asserts that if events A1 ,A2 , ... are dis­
joint, then
C
OO 
\ oo
An = 
P (An). 
(2.11)
n=1 
n=1
However, if P is defined on a field, then there is no guarantee that the left-hand side of 
formula (2.11) makes sense, since no=1 An need not belong to the field of events on which 
P is defined. The meaning of the assumption of Theorem 2.6.3 is that formula (2.11) is true 
whenever the union JO=1 An belongs to the field on which P is defined.
The way of finding the probability of some complicated event A is to represent A as a 
limit of some sequence of events whose probabilities can be computed, and then pass to the 
limit. Theorem 2.6.3 asserts that this procedure will give the same result, regardless of the 
choice of sequence of events approximating the event A.
■ EXAMPLE 2.7 Densities
A very common situation in probability theory occurs when 5 = (-ж, + ж). A prob­
ability measure P on 5 can be defined as follows: let f be a function such that f (x) > 0 
for all x and f+OO f (x) dx = 1. We will assume in addition that f is continuous and 
bounded, although those conditions can be greatly relaxed in general theory.

SUBJECTIVE PROBABILITY*
35
We now define probability on S by putting
P(A) = 
f(x) dx 
(2.12)
A
(in this case, f is referred to as a density of P). The full justification of this construction 
lies beyond the scope of this book, but we will give the main points. First, the definition 
(2.12) is applicable for all intervals A of the form (a, b), [a, b], (—ж, b), (a, ж), [a, ж), 
and so on. Then we can extend P to finite unions of disjoint intervals by additivity (the 
class of all such finite unions forms a field). We can easily check that such an extension 
is unique; that is,
P[(a,b)] = У f (x) dx = 
У f (x) dx
does not depend on the way interval (a, b) is partitioned into the finite union of 
nonoverlapping intervals Ij . This provides an extension of P to the smallest field of 
sets containing all intervals. If we show that P defined this way is continuous on the 
empty set, then we can claim that there exists an extension of P to the smallest a-field 
of sets containing all intervals.
Now, the decreasing sequences of intervals converging to the empty set are built of 
two kinds of sequences: “shrinking open sets” and “escaping sets,” exemplified as
11 D 12 D • • • with In = (a, a + tn), € 1 > б2 > • • • —0 0
and
J1 D J2 D • • • with 
Jn = (an, ж), a 1 < a2 • • • — ж.
We have here lim In = p| In = 0 and lim Jn = p| Jn = 0. In the first case, 
P(In) = fa+en f (x) dx ^ enM — 0, where M is a bound for function f. In 
the second case, P(Jn) = f0” f (x) dx =1 — j‘anx f (x) dx — 1 — J+” f (x) dx = 0.
2.7 SUBJECTIVE PROBABILITY*
Let us finally consider briefly the third interpretation of probability, namely as a degree of 
certainty, or belief, about the occurrence of an event. Most often, this probability is associ­
ated not so much with an event as with the truth of a proposition asserting the occurrence 
of this event.
The material of this section assumes some degree of familiarity with the concept of expec­
tation, formally defined only in later chapters. For the sake of completeness, in the simple 
form needed here, this concept is defined below. In the presentation, we follow more or less 
the historical development, refining gradually the conceptual structures introduced. The 
basic concept here is that of a lottery, defined by an event, say A, and two objects, say a 
and b. Such a lottery, written simply aAb, will mean that the participant (X) in the lottery 
receives object a if the event A occurs, and receives object b if the event Ac occurs.
The second concept is that of expectation associated with the lottery aAb, defined as
u(a)P(A) + u(b)P(Ac), 
(2.13)
where u(a) and u(b) are measures of how much the objects a and b are “worth” to the partic­
ipant. When a and b are sums of money (or prices of objects a and b), and we put u(x) = x, 
the quantity (2.13) is sometimes called expected value. In cases where u(a) and u(b) are val­
ues that person X attaches to a and b (at a given moment), these values do not necessarily 

36
PROBABILITY
coincide with prices. We then refer to u(a) and u(b) as utilities of a and b, and the quantity 
(2.13) is called expected utility (EU). Finally, when in the latter case, the probability P(A) 
is the subjective assessment of likelihood of the event A by X, the quantity (2.13) is called 
subjective expected utility (SEU).
First, it has been shown by Ramsey (1926) that the degree of certainty about the occur­
rence of an event (of a given person) can be measured. Consider an event A, and the following 
choice suggested to X (whose subjective probability we want to determine). X is namely given 
a choice between the following two options:
1. Sure option: receive some fixed amount $u, which is the same as lottery ($u)B($u), for 
any event B.
2. A lottery option. Receive some fixed amount, say $100, ifA occurs, and receive nothing if 
A does not occur, which is lottery ($100)A($0). One should expect that if u is very small, 
X will probably prefer the lottery. On the other hand, if u is close to $100, X may prefer 
the sure option.
Therefore, there should exist an amount u* such that X will be indifferent between the 
sure option with u* and the lottery option. With the amount of money as a representation 
of its value (or utility), the expected return from the lottery equals
0(1 - P (A)) + 100P (A) = 100P (A),
which, in turn, equals u* . Consequently, we have P (A) = u*/100. Obviously, under 
the stated assumption that utility of money is proportional to the dollar amount, 
the choice of $100 is not relevant here, and the same value for P (A) would be 
obtained if we choose another “base value” in the lottery option (this can be tested 
empirically).
This scheme of measurement may provide an assessment of the values of the (subjective) 
probabilities of a given person, for a class of events. It is of considerable interest that the 
same scheme was suggested in 1944 by von Neumann and Morgenstern (1944) as a tool 
for measuring utilities. They assumed that probabilities are known (i.e., the person whose 
utility is being assessed knows the objective probabilities of events, and his subjective and 
objective probabilities coincide). Ifa person is now indifferent between the lottery as above, 
and the sure option of receiving an object, say q, then the utility u(q) of object q must equal 
the expected value of the lottery, which is 100P (A). This allows one to measure utilities on 
the scale that has a zero set on nothing (status quo) and “unit” as the utility of $100. The 
scheme of von Neumann and Morgenstern was later improved by some authors, culminating 
with the theorem of Blackwell and Girshick (1954).
Still the disadvantages of both approaches were due to the fact that to determine utilities, 
one needed to assume knowledge of probabilities by the subject, while conversely, to deter­
mine subjective probabilities, one needed to assume knowledge of utilities. The discovery 
that one can determine both utilities and subjective probabilities of the same person is due to 
Savage (1954). We present here the basic idea of the experiment rather than formal axioms 
(to avoid obscuring the issue by technicalities).
Let A,B,C, .. . denote events, and let a, b, c, . . . denote some objects, whose probabilities 
P (A), P (B), ... and utilities u(a), u(b), ... are to be determined (keep in mind that both P 
and u refer to a particular person X, the subject of the experiment). We now accept the main 
postulate of the theory, that of the two lotteries, X will prefer the one that has higher SEU.
Suppose that we find an event A with subjective probability 1/2, so that P (A)= 
P(Ac) = 1/2. IfX prefers lottery aAb to lottery cAd, then
u(a)P (A) + u(b)P (Ac) > u(c)P(A) + u(d)P(Ac),

SUBJECTIVE PROBABILITY*
37
which means that
u(a) - u(c) > u(d) - u(b).
A number of experiments on selected objects will allow us to estimate the utilities, potentially 
with an arbitrary accuracy (taking two particular objects as zero and a unit of the utility 
scale). In turn, if we know the utilities, we can determine the subjective probability of any 
event B . That is, if X is indifferent between lotteries aBb and cBd, we have
u(a)P (B) + u(b)(1 - P(B)) = u(c)P(B) + u(d)(1 - P(B)),
which gives
P (B) = 
u (d) - u (b)
u(a) - u(b) + u(d) - u(c) .
The only problem lies in finding an event A with subjective probability 1/2. Empirically, an 
event A has subjective probability 1/2 if, for any objects a and b, the person is indifferent 
between lotteries aAb and bAa. Such an event was found experimentally (Davidson et al., 
1957). It is related to a toss of a die with three of the faces marked with the nonsense combi­
nation ZOJ, and the other three with the nonsense combination ZEJ (these combinations 
evoked the least number of associations).
Let us remark at this point that the system of Savage involves determining first an event 
with probability 1/2, then the utilities, and then the subjective probabilities. Luce and Krantz 
(1971) suggested an axiom system (leading to an appropriate scheme) that allows simulta­
neous determination of utilities and probabilities. The reader interested in these topics is 
referred to the monograph by Krantz et al. (1971).
A natural question arises: Are the three axioms of probability theory satisfied here (at least 
in their finite versions, without countable additivity)? On the one hand, this is the empirical 
question: The probabilities of various events can be determined numerically (for a given 
person), and then used to check whether the axioms hold. On the other hand, a superficial 
glance could lead one to conclude that there is no reason why person X’s probabilities should 
obey any axioms: After all, subjective probabilities that do not satisfy probability axioms are 
not logically inconsistent.
However, there is a reason why a person’s subjective probabilities should satisfy the 
axioms. For any axiom violated by the subjective probability of X (and X accepts the 
principle of SEU), one could design a bet that appears favorable to X (hence a bet that he 
will accept), but yet the bet is such that X is sure to lose.
Indeed, suppose first that the probability of some event A is negative. Consider the bet 
(lottery) (-c)A(-b), (i.e., a lottery in which X pays the sum c if A occurs and pays the sum 
b if A does not occur). We have here (identifying, for simplicity, the amounts of money with 
their utilities)
SEU = -cP (A) - bP (Ac),
so that SEU is positive for a large enough c if P(A) < 0. Thus, following the principle of 
maximizing SEU, X should accept this lottery over the status quo (no bet), but he will lose 
in any case—the amount c or the amount b.
Suppose now that P(S) < 1. Consider the bet (-c)Sb whose SEU is -cP(S) + bP(Sc). 
Since P(Sc) > 0, making b large enough, the bet appears favorable to X, yet he is bound to 
lose the amount c on every trial.
If P (S ) > 1 or if the additivity axiom is not satisfied, one can also design bets that will 
formally be favorable for X (SEU will be positive) but that X will be bound to lose. Deter­
mination of these bets is left to the reader.

38
PROBABILITY
PROBLEMS
2.7.1 Peter and Tom attend the same college. One day Tom buys a ticket for a rock concert. 
Tickets are already sold out and are in great demand. Peter, who does not have a ticket, 
agrees to play the following game with Tom. For afee of $25, Peter will toss a coin three 
times and receive the ticket if all tosses show up heads. Otherwise, for an additional fee 
of $50, Peter will toss a coin two more times and receive the ticket if both tosses show 
up heads. If not, then for an additional fee of $100, Peter will toss a coin and receive 
the ticket if the toss shows up heads. Otherwise, all money will be given to Tom, and 
he also will keep the ticket. Assuming that the coin is fair, subjective probabilities of 
various outcomes coincide with objective probabilities, and that Peter’s utility is linear 
in money, show that Peter’s utility of the ticket exceeds $200.
2.7.2 Refer to Problem 2.7.1. Tom would agree on the following conditions: Peter pays 
him $50 and tosses a coin, winning the ticket if it comes up heads, and otherwise losing 
$50. In such a situation, should they both agree that Peter buys the ticket from Tom 
for $150?
2.7.3 Suppose that Tom is confronted with the choice between two options: O1, which is 
simply to receive $1,000,000, or O2 , which is to receive $5,000,000 with probability 
0.1, receive $1,000,000 with probability 0.89, and receive $0 with the remaining proba­
bility 0.01. After some deliberation, Tom decides that O1 is better, mostly because the 
outcome $0, unlikely as it may be, is very unattractive.
Tom is also confronted with a choice between two other options, O3 and O4. In O3, he 
would receive $5,000,000 with probability 0.1 and $0 with probability 0.9. In O4, he 
would receive $1,000,000 with probability 0.11 and $0 with probability 0.89. Here Tom 
prefers O3: the “unattractive” option $0 has about the same probability in both O3 and 
O4, while the positive outcome, although slightly less probable under O3, is much more 
desirable in O3 that in O4. Show that these preferences of Tom are not compatible with 
the assumption that he has utilities A, B, and C of $5,000,000, $1,000,000, and $0, such 
that A>B > C (This is known as Allais’ paradox; Allais, 1953).

CHAPTER 3
COUNTING
3.1 
INTRODUCTION
In the classical interpretation of probability, all outcomes of the experiment are equally 
likely, and the probability of an event is obtained as the relative frequency of outcomes that 
favor this event (imply its occurrence). Simple enumeration of elements in these sets is often 
not feasible, and therefore practical implementation of this principle requires developing 
techniques for counting elements of certain sets (e.g., sets of all possible outcomes of an 
experiment). The branch of mathematics dealing with such methods is called combinatorics, 
or combinatorial analysis. In this chapter, we introduce some combinatorial principles and 
illustrate their use in computing probabilities.
A much more complete presentation of combinatorial methods and their applications to 
probability can be found in Feller (1968).
3.2 
PRODUCT SETS, ORDERINGS, AND PERMUTATIONS
Consider two operations of some sort, which can be performed one after another. Leaving 
the notion of “operation” vague at the moment, we can make two assumptions:
1. The first operation can be performed in k1 different ways.
2. For each of the ways of performing the first operation, the second operation can be per­
formed in k2 ways.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
39

40
COUNTING
We have the following theorem:
Theorem 3.2.1 Under assumptions 1 and 2, a two-step procedure consisting ofa first operation 
followed by the second operation can be performed in k1k2 distinct ways.
Proof: Observe that each way of performing the two operations can be represented as a pair 
(ai, bij) with i =1, ...,k1 and j =1, ...,k2,whereai is the ith way of performing the first 
operation and bij is the jth way of performing the second operation if the first operation was 
performed in ith way. All such pairs can be arranged in a rectangular array with k1 rows and 
k2 columns. 
□
We will now show some applications of Theorem 3.2.1.
■ EXAMPLE 3.1 Cartesian Products
One of the most common operations on sets is the Cartesian product. If A and B are 
two sets, their Cartesian product A x B is defined as the set of all ordered pairs (a,b), 
where a e A and b e B. For instance, if A consists of elements x and y, while B consists 
of the digits 1, 2, and 3, then the Cartesian product A x B = {x, y}x{1, 2, 3} contains 
the six pairs
{(x, 1), (x, 2), (x, 3), (y, 1), (y, 2), (y, 3)}. 
(3.1)
Observe that the Cartesian product A x B is an operation quite distinct from the 
set-theoretical product A П B. For instance, in the above case, A П B = 0, since A and 
B have no elements in common. Also, while A П B = B П A, for Cartesian products 
A x B = B x A in general. In cases when there is no danger of confusion, we will use 
the term product for Cartesian product.
Identifying now the first and second operation with “choice ofan element from set A” and 
“choice ofan element from set B,” we obtain the following consequence of Theorem 3.2.1:
Theorem 3.2.2 (Multiplication Rule) IfA1 and A2 are finite sets consisting, respectively, of k1 
and k2 elements, then the Cartesian product A1 x A2 consists of k1k2 elements.
Theorem 3.2.2 allows for an immediate generalization, we can define Cartesian products 
of more than two sets. Thus, if A1, ...,An are some sets, then their Cartesian product A1 x 
A 2 x • • • x An is the set of all n-tuples (a 1, a 2, ..., an) with ai e Ai, i = 1, ...,n .By easy 
induction, Theorem 3.2.2 can now be generalized as follows:
Theorem 3.2.3 If A1, ... ,An are finite, with Ai consisting of ki elements (i =1, ...,n),then 
A 1 x • • • x An contains k 1 • • • kn elements.
■ EXAMPLE 3.2
The total number of possible initials consisting of three letters (name, middle name, 
family name) is 263 . Each three-letter initial is an element of the set A x A x A, 
where A is the alphabet, so k1 = k2 = k3 =26. The total number of possible two- or 
three-letter initials is the number of the elements in the union (A x A) U (A x A x A), 
equal to 262 +263 = 18,252.

PRODUCT SETS, ORDERINGS, AND PERMUTATIONS
41
■ EXAMPLE 3.3 License Plates
Most states now use the system where a license plate has six symbols. One type (call 
it A) of such licenses has a prefix of three letters followed by a three-digit number 
(e.g., CQX 786). Other states use system (call it B) with a two-letter prefix, followed 
by a four-digit number (e.g., KN 7207). Still other states use system C, a digit and two 
letters, followed by a three digit number (e.g., 2CP 412). In addition states allow (for 
a special fee) “personalized” plates such as CATHY3 or MYCAR. Disregarding the 
personalized plates, which type of the license plate system can register most cars?
SOLUTION. Let A and D stand for the alphabet and for the set of 10 digits: 
0, 1, ...,9. Then, a license plate from system A can be regarded as an element of 
A x A x A x D x D x D, while a license plate in system B is an element of the set 
A x A x D x D x D x D. The numbers of elements in these Cartesian products are 
263 x 103 and 262 x 104. The ratio is 26/10 = 2.6, so in the state using an A system 
2.6 times more cars can be registered than in the state with a B system.
Regarding system C, the answer depends whether or not 0 is allowed in the prefix.
If the plate such as 0HY 314 is not allowed (e.g., because the digit 0 can be confused 
with the letter O), then the number of possible license plates is only 9 x 26 x 26 x 10 x 
10 x 10, which is 10% less than the number of plates possible in states using system B.
If 0 is allowed as the first character, then the numbers of plates of types B and C are 
the same.
In Examples 3.1 through 3.3 the set of ways of performing the second operations is the 
same regardless of which option was selected for the first operation. However, Theorem 3.2.1 
remains true if the sets of ways of performing the second operation depend on the choice of 
the first operation. In particular, we can think of the first and second operation as two consec­
utive choices of an element from the same set, without returning the chosen elements. If the 
set, say A,hasn elements, then the first operation (choice of an element) can be performed 
in n ways. If the chosen element is not returned, then the second choice can be performed in 
n - 1 ways only, and we have the following:
Corollary 3.2.4 The number of ordered pairs (x, y) with x = y that can be formed out of n 
distinct elements of a set of size n is n(n - 1).
Instead of thinking in terms of operations, we can still use Cartesian products here. Thus, 
A x A has n2 elements by Theorem 3.2.3, of which n are of the form (x, x). The number of 
pairs with elements distinct is n2 - n = n(n - 1).
We can generalize these considerations as follows:
Definition 3.2.1 An ordered sequence of k elements selected without replacement from a set 
of n distinct elements (n > k) is called a permutation of k out of n elements. 
□
Theorem 3.2.5 The number of permutations of k out of n, denoted Pnk, equals
Pn = n (n - 1)''' (n - k + 1).
Proof : The argument here repeatedly uses the “operation” principle: the first choice can be 
made in n ways, the second in n - 1 ways, the kth in n - (k - 1) = n - k + 1 ways. □

42
COUNTING
(3.2)
(3.3)
(3.4)
If k = n, consecutive choices form an ordering of the entire set of size n. We obtain the 
following:
Corollary 3.2.6 The set of n elements can be ordered in
РП = n (n — 1) x • • • x 2 x 1 
distinct ways.
The product (3.2) occurs often and has a special symbol: 
n!= 1 x 2 x • • • x (n — 1)n 
to be read “n factorial.” We have therefore
P fc = 
n!
n 
(n — k)!'
For a reason that will become apparent later, we adopt the convention 
0! = 1.
■ EXAMPLE 3.4
The letters I, I, I, I, M, P, P, S, S, S, S are arranged at random. What is the probability 
that the arrangement will spell MISSISSIPPI?
SOLUTION. We can solve this problem treating the choices of consecutive letters as 
“operations.” The first operation must give the letter M; hence, there is only one way 
of choosing it. The next letter (out of the remaining 10) must be an I, and it can be 
selected in four ways. Proceeding in this way, the sequence of consecutive 11 choices 
leading to the word MISSISSIPPI can be performed in 1 x 4 x 4 x 3 x 3 x 2 x 1 x 
2 x 2 x 1 x 1 ways, which equals 4!4!2!1!. On the other hand, the total number of ways 
one can perform the operations of consecutively choosing letters from the set is 11!. 
Consequently, the required probability equals
4!4!2!1! 
p
(3.5)
In this solution, the letters are regarded as distinguishable, as if we had four letters S, 
labeled S1, S2, S3, and S4, and similarly for the other letters. In this case, the numerator 
and denominator are, respectively, the number of ways one can order the set of dis­
tinguishable letters so as to form the word MISSISSIPPI and the total number of 
orderings. Alternatively, one can regard the identical letters as indistinguishable, and 
in this case, we have only one way of ordering them so as to spell the required word, 
and a total of 11!/(4!4!2!1!) distinguishable ways of ordering these letters. Indeed, 
the denominator here represents the number of ways of permuting letters so as to leave 
the arrangement invariant. Now,
- 1 11! 
p = \ 4!4!2!1!
-1
which is the same as (3.5).
■ EXAMPLE 3.5 Birthday Problem
The following problem has a long tradition and appears in many textbooks. If r ran­
domly chosen persons attend a party, what is the probability pr that none of them will 
have a birthday on the same day?

PRODUCT SETS, ORDERINGS, AND PERMUTATIONS
43
SOLUTION. Here we make the following assumption: (1) all years have 365 days (i.e., 
leap years are disregarded), (2) each day is equally likely to be a birthday of a person 
(i.e., births occur uniformly throughout the year), and (3) no twins attend the party. 
To compute pr, we must find the number of all possible ways in which birthdays can 
be allocated to r people, and the number of such allocations in which birthdays do 
not repeat. The first number is 365r (by Theorem 3.2.3), while the second number is 
P3r65 (assuming r < 365; if r > 365, we must have at least one birthday repeating, so 
pr = 0). Thus, for r < 365, we have
_ Pr65 _ 365 
365 - 1 
365 - r + 1
Pr = 365r = 365 X 365 x '" x 365
r-1 
365
1
As a first approximation, neglecting all products which have denominators of order 
3652 or higher, we can take
1 + 2 + ••• + (r — 1) i 
(r — 1) r
365 
= 
730
(3.6)
This approximation works quite well for small r. Now since log(1 - x) « -x, we have
log pr
-r(r - 1) 
730
r(r-1)
and consequently pr « e 
730 .
(3.7)
It is interesting that for r =23a repeated birthday is about as likely as no repetition. 
The smallest r for which pr is less than 0.01 is 56.
PROBLEMS
3.2.1 A certain set contains n distinct elements. Find n if the number of: (i) All possible 
permutations of length 2 equals 90. (ii) Permutations of length 3 is 10 times larger 
than the number of permutations of length 2.
3.2.2 A skyscraper is 40 stories tall. Five people enter the elevator on the first floor. Assum­
ing each person is equally likely to get off at any of the 39 floors 2, 3, ...,40, what 
is the probability that all people will get off at different floors? Find the exact value, 
and then derive and compute the approximations analogous to (3.6) and (3.7).
3.2.3 A two letter code is to be formed by selecting (without replacement) the letters 
from a given word. Find the number of possible codes if the word is: (i) CHART. 
(ii) ALOHA. (iii) STREET.
3.2.4 Determine the number of 0s at the end of 16! and 27!.
3.2.5 Seated at random in a row ofn seats are n people, among them John and Mary. Find 
the probability that: (i) John sits next to Mary. (ii) John sits next to Mary on her right. 
(iii) John sits somewhere to the right of Mary. (iv) John and Mary sit exactly two seats 
apart.
3.2.6 Seated at random at a round table with n seats are n people, among them John and 
Mary. (i) Answer questions (i)-(iv) of Problem 3.2.5. Anything peculiar about the 
answer to (iii)? (ii) Assume that n =2k. Find the probability that John and Mary sit 
facing each other (e.g., numbers 1 and 7 on the clock). (iii) Assume that n =8. Find 
the probability that good friends, Nico, Noah, and Helen, are not separated by other 
guests.

44
COUNTING
3.2.7 Five men and five women are to be seated in a row of 10 chairs. Find the number of 
possible arrangements if: (i) Men are required to sit in alternating seats. (ii) No two 
men are to be seated next to each other.
3.2.8 A total of 12 girls and 17 boys go to a dance. (i) How many possible dancing pairs 
(boy-girl) may be formed? (ii) The dance floor can accommodate at most 11 pairs at 
a time. If each dance lasts 10 minutes and is followed by a 2-minute break, how much 
time, at least, will elapse before each boy will have danced with each girl at least once? 
(iii) Answer the same question as in (ii) if the dance floor can accommodate 15 pairs 
at a time.
3.2.9 Susan has five dresses, three skirts, four blouses, three pairs of shoes, and two hats. 
She always wears shoes and either a dress or a blouse and a skirt. She may or may not 
wear a hat. (i) How many different combinations can she wear? (ii) Suppose Susan 
can afford buying either a dress or a hat (but not both). What should she buy to 
maximize the number of different combinations that she can wear? (iii) Suppose that 
Susan’s brown shoes do not match her pink or blue dress and that the blue hat does 
not match her yellow blouse. How many matching combinations can she wear?
3.2.10 A restaurant menu has 5 appetizers, 3 soups, 15 entrees, and 3 desserts. (i) Assuming 
you are going to order one item from each group, how many possible dinners can you 
order? (ii) Assume you are at the restaurant with a friend. How many different orders 
for two full dinners can you place if your friend’s choice of every item is not necessarily 
the same as yours? (iii) Answer the question in part (ii) under the constraint that you 
do not order the same entree and the same dessert as your friend (but the soup and/or 
appetizer may be the same).
3.2.11 Find the percentage of six-digit numbers that have all digits distinct.
3.2.12 A regular die is tossed n times. Find the probability that: (i) Each side turns up exactly 
once if n =6. (ii) Each side turns up at least once if n =8.
3.2.13 Find the number of three-digit integers (i.e., integers between 100 and 999) that have 
all digits distinct. How many of them are odd?
3.2.14 Let er be the probability that exactly two people in a group ofr have the same birth­
day, and let pr be the probability that everybody in the group has a different birthday. 
Show that
er = r(r-^Pr-1.
3.3 BINOMIAL COEFFICIENTS
The permutations discussed in Section 3.2 were ordered selections from a certain set. Often, 
these orders are irrelevant, as we are interested only in the total number of possible choices. 
Such choices are referred to as combinations.
Definition 3.3.1 A subset of size k selected from a set of size n (regardless of the order in 
which this subset was selected) is called a combination of k out of n. 
□
Theorem 3. 3.1 The number of combinations of k out of n, Cnk, is given by
Ckk = Pk • 
(3.8)
n 
k!

BINOMIAL COEFFICIENTS
45
Proof : By Theorem 3.2.5 we have Pnk different permutations of k out of n elements. Each 
permutation determines the set of k elements selected and their order. Consequently, k ! per­
mutations lead to the same combination, which proves (3.8). 
□
The ratio Pnk/k! appears in various contexts, and it is convenient to have a special symbol 
for it.
Definition 3.3.2 The ratio
P^ = n (n - 1) ■■■ (n - k + 1)
k! 
k! 
( 
)
is called a binomial coefficient and is denoted by (£), to be read as “n choose k.” 
□
Using (3.3), we have
( n ) = 
. 
(3.10)
k k!(n - k)!
Observe, however, that (3.10) requires n to be an integer, whereas in (3.9) n can be any real
number (k has to be an integer in both cases).
■ EXAMPLE 3.6
As an illustration, let us evaluate -1k/2 , which we will use later. We have
/-1 / 2 
-1 
-1 - 1 -1 - 21 ■■■I'—1 - k + 11
/ 1 / 2 1 = A 2 
2 
1 
2 , 2) 
\ 2 k + 1/
1 
11/ 
3 1 5 
5 1 
2 
2 k— 1 \ k 1 1 k 1 
9 x \? fOJ i\
= I -2) I -2) I ~2) ■ ■ ■ I--- = (- 1) 1 
X 3 X 5 X (2k - 1)
k! 
2k k! 
.
Multiplying the numerator and denominator by 2 X 4 X ■■■ X (2k) = 2kk!, we get
( - 1 / 2 _ (- 1)k ( 2 k
In this section, we tacitly assume that n is an integer with n > k.
Observe also that the symbol nk makes sense for k =0and k = n, in view of the con­
vention that 0! = 1. Thus, we have
Ck = (n) 
(3.12)
for all integers k and n such that n > k.Fork =0,wehaveCn0 =1, since there is only one 
empty set, and Cnn =1, since only one set of size n can be selected out of a set of size n.
Formula (3.12) gives correct values, namely
nn = n0 =1. 
(3.13)
We will now study some properties of the binomial coefficients nk . First, 
(3.14)

46
COUNTING
which follows from the symmetry in formula (3.10). One can also prove (3.14) by observing 
that choosing a set of size k is equivalent to “leaving out” a set of size n - k. The number 
of different sets of size k chosen must be equal to the number of different sets of size n - k 
“chosen” by leaving them out.
We will now prove the following theorem:
Theorem 3. 3.2 (Pascal’s Triangle) The binomial coefficients satisfy the relation
n 
n 
n+1
k + k-1 = k
(3.15)
Proof : The formula can be easily proved by expressing the left-hand side using (3.8) and 
reducing it algebraically to get the right-hand side. It is, however, more instructive to rely 
on the interpretation of the coefficients nk as Cnk. The right-hand side of (3.15) counts the 
number of sets of size k that can be chosen out of a set of size n +1. Let us take one element 
of the latter set and label it somehow. We have then a set ofn unlabeled and 1 labeled element. 
Each subset of size k is one of the following two categories: (1) subsets that contain only k 
unlabeled elements, or (2) subsets that contain k - 1 unlabeled elements and one labeled 
element. The two terms on the left-hand side of (3.15) count the numbers of subsets of the 
first category and of the second category. 
□
The name Pascal’s triangle reflects a way of obtaining the coefficients nk . We build 
Pascal’s triangle starting with the top row (counted as the zeroth row), which consists of 
the single number 1 (see Figure 3.1). Then we obtain each number in the subsequent rows 
as a sum of two numbers directly above it (as marked with arrows in the fifth row). The 
consecutive numbers in the nth row are, reading from the left, the values of
n , n 
, n ,...
0 , 1 , 2 ,...
so that, for example, 36 =20, as marked on the triangle in Figure 3.1. While the Pascal 
triangle was very useful in the past, today it is ofa historical value as statistical packages are 
used to obtain values of binomial coefficients.
1
1 
1
121
1 
3 
31
14641
1 
5 
10 
10 
5 
1
1 
6 
15 
20 
15 
6 
1
1 
7 
21 
35 
35 
21 
7 
1
Figure 3.1 Pascal’s triangle.

BINOMIAL COEFFICIENTS
47
The name binomial coefficient is connected to the following formula:
Theorem 3.3.3 (Newton’s Binomial Formula) For any positive integer n and real x, y, we have
n
(x + y)n = £ nnk}n--kyk.
k=0
(3.16)
Proof: We will prove the theorem by induction. For n = 1, the right-hand side equals 
(0) x + (J) y = x + y. Assume now that the assertion holds for some n, and multiply both 
sides of (3.16) by (x + y). Then
n
(x + y)n+1 = (x + y)£ {nk}n-kkyk 
k=0 
nn
= У Пxn+1 -kyk + У О xn-kyk+1 
kk)
k=0 
k=0
n 
n+1 / 
\
= V PW +1 — M + У( n ) xn- (k- 1)g
2^ UJx y ' k—-V x
k=0 
k=1
Separating the term for k = 0 in the first sum, and the term for k = n +1 in the last sum, 
we may write
(x + y)n +1 = xn +1
n
+ E (n) 
k=1
x (n +1) -k yk + yn +1
n+1
x ( n +1) -k yk
+
n
k
1
k=0
where the last equality is due to Theorem 3.3.2.
□
The following theorem is an immediate consequence of Theorem 3.3.3 applied to (1 + 1)n 
and (1 - 1)n, respectively.
Theorem 3.3.4 The binomial coefficients satisfy the identities
( n) + ( n ) + ••• + ( n ) =2 n 
(3.17)
01 
n
and
nnn 
n
— 
+ 
------± 
=0 
(3 18)
..
012 
n
We also have the following theorem:
Theorem 3.3.5 For every n = 1, 2, ... and every k = 0, 1, ... ,n
(n)(n)+(n 
Л)+■■■+(n)(n) = C2(V 
(3.19)
0 О / \ rv 1 
\1/ \ — — 11 
\ О 0 \ О /

48
COUNTING
Proof: Consider the product (1 + x)n(1 + x)n =(1+x)2n. Expanding the right-hand side,
we obtain
2n 2n
E ( 
) xk, 
(3.20)
k
k=0
while the left-hand side equals
ng( П ) x
n
xj
(3.21)
For k < n, comparison of the coefficients of xk in (3.20) and (3.21) gives (3.19). 
□
As a consequence of (3.19), we obtain a corollary:
Corollary 3.3.6
Proof :Takek = n in (3.19) and use the fact that
□
Below we present some examples of the use of binomial coefficient in solving various 
probability problems, some with a long history.
■ EXAMPLE 3.7
Let us consider a selection without replacement from a finite set containing two cate­
gories of objects. If n balls are to be selected from an urn containing r red and b blue 
balls, one might want to know the probability that there will be exactly k red balls 
chosen.
SOLUTION. We apply here the “classical” definition of probability. The choice of n 
objects without replacement is the same as choosing a subset of n objects from the 
set of total of r + b objects. This can be done in r+nb different ways. Since we must 
have k red balls, this choice can be made in kr ways. Similarly, n - k blue balls can 
be selected in n-b k ways. As each choice ofk red balls can be combined with each of 
the b choices of blue balls then, by Theorem 3.2.2, the total number of choices is 
n-k 
, 
,
the product (Г )( b and
k n-k
P (exactly k red balls) =
rb 
k n-k
(r+0 
'
(3.22)
The next example shows an interesting application of formula (3.22).

BINOMIAL COEFFICIENTS
49
■ EXAMPLE 3.8
Consider the problem of estimating the number of fish in a lake (the method described 
below is also used to estimate the sizes of bird or wildlife populations). The lake 
contains an unknown number N of fish. To estimate N, we first catch c fish, label
them, and release them back into the lake. We assume here that labeling does not harm
fish in any way, that the labeled fish mix with unlabeled ones in a random manner, and 
that N remains constant (in practice, these assumptions may be debatable). We now
catch k fish, and observe the number, say x, of labeled ones among them. The values
c and k are, at least partially, under the control of the experimenter. The unknown
parameter is N, while x is the value occurring at random, and providing the key to 
estimating N. Let us compute the probability PN = PN (x) of observing x labeled fish 
in the second catch if there are N fish in the lake. We may interpret fish as balls in an
urn, with labeled and unlabeled fish taking on the roles of red and blue balls. Formula
(3.22) gives
c 
N-c
x 
k-x
PN = 
(N) 
'
(3.23)
To estimate N, we can use the principle of maximum likelihood (to be explored in detail 
in Chapter 11). At present, it suffices to say that this principle suggests using as N ,an 
estimator of N, the value of N that maximizes (3.23). Let us call this value N. Let us 
call this value N . It depends on the observed value x and hence is itself random. Thus, 
N is defined by the condition
PN > PN 
for all N
and our objective is to find the maximizer of PN. Since N is a discrete variable, we can-
not use methods of finding a maximum based on derivatives. Instead, the method that
works in this case is based on the observation that if the function PN has a maximum 
(possibly local) at N*, then PN* /PN*- 1 > 1 and PN*+1 /PN* < 1. If two neighboring 
probabilities have equal values, the ratio equals 1. Consequently, we should study the
ratio PN /PN -1 and find all arguments at which this ratio crosses the threshold 1. After
some reduction, we have
PN /PN-1
(N - c)(N - k) 
N (N — c — k + x)
The above ratio always exceeds 1 if x =0, so in this case the maximum is not attained.
Assume now that x> 0. The inequality
PN /PN -1 > 1
6The integer part of a, [a], is the largest integer not exceeding a ([3.21] = 3, [-1.71] = -2, etc.).
is equivalent to
N < x
(3.24)
with the equality occurring if and only if PN /PN
attained at6
= 1. Thus, the maximum is
N=
kc
x
1
and also at kc/x - 1 if the latter value is an integer. Let us observe that the result above 
is consistent with common intuition: The proportion of labeled fish in the whole lake

50
COUNTING
is c/N, and it should be close to the proportion x/k of labeled fish in the second catch.
This gives the approximate equation c/N « x/k, with the solution N « kc/x.
■ EXAMPLE 3.9
To supplement their revenues, many states are sponsoring number games or lotteries. 
The details vary from state to state, but generally, a player who buys a lottery ticket
chooses several numbers from a specified set of numbers. We will carry the calculations
for the choice of6 out of 50 numbers 1, 2, ...,50, which is quite typical. After the sales
of tickets close, six winning numbers are chosen at random from the set 1, 2, ...,50. 
All those (if any) who chose six winning numbers share the Big Prize; if there are no
such winners, the Big Prize is added to the next week’s Big Prize. Those who have five 
winning numbers share a smaller prize, and so on. Let P (x) be the probability that 
a player has exactly x winning numbers. We will compute P (x) for x =6, 5, 4, and 3. 
The calculations would be the same if the winning numbers were chosen in advance,
but remained secret to the players. We can now represent the situation in a familiar 
scheme of an urn with 6 winning numbers and 44 losing numbers, and the choice of 
6 numbers from the urn (without replacement). This is the same problem as that of 
50 
6 
44
labeled fish. The total number of choices that can be made is , while 
is
6 , 
x 
6-x
the number of choices with exactly x winning numbers. Thus,
P(x) =
6 
44
x 
6-x
(5П 
■
For x =6,wehave
P (6)=ch
6!
50 x 49 x 48 x 47 x 46 x 45
1
15,890,700 = 6.29 x 10-8.
Similarly P(5) = 1.66 x 10-5,P (4) = 8.93 x 10-4 and P(3) = 0.016669.
Thus, the chances of winning a share in the Big Prize are about 1 in 16 million. 
It would therefore appear that there should be, on average, one big winner in every 16 
million tickets sold. The weekly numbers of tickets sold are well known, and it turns out 
that the weekly numbers of winners (of the Big Prize) vary much more than one would 
expect. For example, in weeks where the number of tickets sold is about 16 million, one 
could expect no winner, one winner, or two winners; three winners is unlikely. In reality, 
it is not at all uncommon to have five or more winning tickets in a week with 16 million 
tickets sold. These observations made some people suspicious about the honesty of the 
process of drawing the numbers, to the extent that there have been attempts to bring 
suit against the lottery (e.g., accusing the organizers of biasing the lottery balls with 
certain numbers so as to decrease their chance of being selected, thus favoring some 
other numbers).
Actually, the big variability of weekly numbers of winners is to be expected if one 
realizes that these numbers depend on two chance processes: the choice of winning 
numbers from the urn (which may be, and probably is, quite fair) and the choice of 
numbers by the players. This choice is definitely not uniform. It favors certain com­
binations, which seem more “random” to the naive persons than other choices. For 
instance, the combination 1, 2, 3, 4, 5, 6 appears less likely than (say) 5, 7, 19, 20, 31, and 
45. As a consequence some combinations are selected more often by the players than 
others. Each combination has the same chance of being the winning one, but some may 
have higher numbers of winners associated with them. This point can be illustrated by 

BINOMIAL COEFFICIENTS
51
the following analogy: Imagine that each week a first name (Mary, Susan, George, etc.) 
is chosen at random from the set of all names used, and all persons in the state with the 
selected name share the prize. The chances of being chosen are the same for John as for 
Sebastian, as they depend on the process of sampling names of winners. But if the name 
Sebastian is chosen, each Sebastian will share the prize with many fewer other winners 
than if the name John were selected. Here the numbers of winners to share the prize 
depend on another process, namely that of parents selecting names for their children.
■ EXAMPLE 3.10
We have k urns, labeled 1, ...,k,andn identical (indistinguishable) balls. In how many 
ways can these balls be distributed in k urns?
SOLUTION. There are no restrictions here on the number of balls in an urn, or the 
number of empty urns. To get the answer, let us identify each possible allocation with 
a string of k +1 bars and n circles, of the form
IOOIIOOOOIOI---OI,
with the only condition being that the string should start and end with a bar. The 
spaces between bars represent urns. Thus, in the arrangement above, the first urn con-
tains 2 balls, the second none, the third 4 balls, and so on. Clearly, the number of 
distinct arrangements equals n+nk-1 —the number of distinct arrangements of k - 1 
bars and n circles. Indeed, we have a string of n + k - 1 symbols (not counting the 
two extreme bars), and each arrangement is obtained by specifying n places for the 
symbol О.
Example 3.10 shows that the binomial coefficient can be interpreted in two ways. On the 
a+b 
a
one hand, a is the number Ca+b of distinct sets of size a that can be chosen out of 
asetofsizea + b. On the other hand, a+a b is also the number of distinct strings of a 
indistinguishable elements of one kind and b indistinguishable elements of another kind. To
see this, it suffices to think of the string as being determined by the choice of “a out of total 
of a + b” slots into which we assign elements of the first kind.
■ EXAMPLE 3.11 Matching Problem
A secretary typed n letters and addressed n envelopes. For some reason, the letters were 
put into envelopes at random. What is the probability of at least one match, that is, of 
at least one letter being put into the correct envelope?
SOLUTION. This problem appears in many textbooks under various formulations 
(e.g., of guests receiving their hats at random). One could expect the probability of at 
least one match to vary greatly with n. However, the contrary is true: this probability 
is almost independent of n. Let Ai be the event that ith letter is placed in the correct 
envelope. Using formula (2.6), we have
P(at least one Ai) = P(A 1 U • • • U An)
= £ P (Ai) - £ P (Ai П Aj) 
i<j
+ 
P (Ai П Aj П Ak) -•••i P (A 1 П---П An).
i<j<k

52
COUNTING
By symmetry, the probability of each intersection depends only on the number of events 
in the intersection,7 ,soweletpr denote the probability of the intersection of r events, 
pr = P(Air П Ai2 П • • • П Air). Clearly, the numbers of terms in the consecutive sums 
are
nnn
1 , 2 , 3 ,...
and
P(at least one Ai) = 
p 1 - p2 + 
p3 - • • • ± p (3.25)
n
1 
2 
3 
nn
To evaluate pr , we can argue as follows: Assume that the envelopes are ordered in some 
way. The total number of ways one can order n letters is n!. If specific r events, say 
Ai , . ..,Ai , are to occur (perhaps in conjunction with other events), then the letters 
number i1 , .. .,ir must be at their appropriate places in the ordering (to match their 
envelopes). The remaining n - r letters can appear in any of the (n - r)! orders. Thus,
pr
(n - r) 
n!
Consequently, the rth term in the sum (3.25) equals (up to the sign)
nr
(n - r) 
r!
1
r!
and we obtain
P (at least one match)
111 
1
1! 
2! + 3! 
■" n!.
Since
1
e
v (—1f 
k-^ k!
k=0
we have
P(at least one match) « 1 —
1
, 
e
with the accuracy increasing as n — ^. The approximation is actually quite good for 
small n. The limiting value is 0.63212056, while the exact values of the probability nn 
of at least one match for selected values of n are
n 1 = 1
n 2 = 1 — 2=0.5
n 3 = 1 - 1 + 1 = 0.6666667
n5 = 1 - | + | - i! + 1^ = 0.6333333
n4 = 1 - 2 + 1 - 24 = 0.625
1
1
1
1
1
nfi = 1 - 
+
-------- +
--------= 0.6319444
6 
2
6
24
120
720
7This property, called exchangeability of events, will be discussed in more detail in Section 4.6.

BINOMIAL COEFFICIENTS
53
■ EXAMPLE 3.12 Ballot Problem
1
1
1
1
1
1
%7 — 1 —
------— 0.6321429
7
2
6
24
120
720
5040
1
1
1
1
1
11
%o — 1 —
+ -
+
-------------------- — 0.6321181
8
2
6
24
120
720
5,040 
40,320
Suppose that in an election, candidate A receives a votes, while candidate B receives 
b votes, where a>b. Assuming that votes are counted in random order, what is the 
probability that during the whole process of counting A will be ahead of B?
SOLUTION. Note that other votes, if any, do not matter, and we may assume that 
a + b is the total number of votes. The process of counting votes is determined by 
the arrangement of the votes, that is, the arrangement of a symbols A, and b symbols 
B. Clearly, such an arrangement is uniquely determined by specifying the locations 
of the As (or, equivalently, Bs). It might be helpful to use a graphical representation: 
define the function C(k) as the net count for candidate A after inspection of k votes. 
Thus, if in the first k votes, we had r votes for A and k - r votes for B, then C(k) = 
r - (k - r)=2r - k. We can then represent the process of counting as a polygonal line 
that starts at the origin and has vertices (k, C(k)),k = 1, ...,a+ b (see Figure 3.2).
Figure 3.2 Process of counting votes.
In Figure 3.2, we have the beginning of counting, when the first five votes inspected 
are AABAB. The problem can now be formulated as finding the probability that the 
counting function C(x) lies above the x-axis for all x =1, 2, ...,a+ b. Observe that 
the first vote counted must be for A (as in Figure 3.2); this occurs with probability 
a/(a + b).
The remaining votes will give a polygonal line leading from (1, 1) to (a + b, a - b), 
and we must find the number of such lines that will never touch or cross the x-axis. The
number of such lines is equal to the total number of lines from (1, 1) to (a + b, a - b) 
minus the number of lines from (1, 1) to (a + b, a - b) which touch or cross the x-axis. 
The total number of lines leading from (1, 1) to (a + b, a - b) is a+b-1 , since each 
, 
, 
a-1 ,
such line has a - 1 steps “up” and b steps “down,” which can be ordered in any manner.
Thus, it remains to count the number of lines from (1, 1) to (a + b, a - b) that touch 
or cross the x-axis. Let V be the set of all such lines. Each line in V must touch the
x-axis for the first time at some point, say t (see Figure 3.3). If we reflect the part of

54
COUNTING
Figure 3.3 Reflection principle.
this line that lies to the left of t with respect to x-axis, we obtain a line leading from 
(1, -1) to (a + b, a - b). Moreover, different lines in V will correspond to different lines 
leading from (1, -1) to (a + b, a - b), and each line in the latter set will be obtained 
from some line in V . This means that the set V has the same number of lines as the set 
of lines leading from (1, -1) to (a + b, a - b). But the latter set contains a+ab-1 lines, 
since each such line must have a steps “up” and b - 1 steps “down.” Consequently, the 
required probability equals
p = ~^h x 
a+b
f a+b-1 A _ f a+b-1 A 
\ a-1 7 
\ a J
13 
4 
12 43
ИЩ/Ы 4
( 552 )
The next kind of hand is the one containing two pairs. Here the argument is as 
follows:
(a) The denominations of the two pairs can be selected in 123 ways.
(b) The suits of cards in these two pairs can be selected in (2) x (2) ways.
(c) The remaining card may be chosen in (111) x 4 ways (two denominations are elim­
inated).
(a+V)
a-b 
a+b.
■ EXAMPLE 3.13 Poker
We now consider the probabilities of several poker hands (some students will probably 
say that finally the book gives some useful information).
In poker, five cards are dealt to a player from a standard deck of 52 cards. The 
number of possible hands is therefore 552 = 2,598,960. The lowest type of hand is 
that containing one pair (two cards of the same denomination, plus three unmatched 
cards). To find the number of possible hands containing one pair, one can think in 
terms of consecutive choices leading to such a hand:
(a) The denomination of the cards in a pair can be chosen in 1  ways.
1 3
(b) The suits of the pair can be chosen in 2 ways.
4
(c) The choice of denominations of the remaining three cards can be made in 31 2
ways.
(d) The suits of those three cards may be chosen in 4  ways. Altogether, combining 
3
13
(a)-(d), we have
P (one pair) =

BINOMIAL COEFFICIENTS
55
Combining (a)-(c), we have
613 P2!'11) x 4
Ptwo rars = 
2 x
t w ^^a>iis) 
. 52 \ 
.
5
Finally, we calculate the probability of a straight (probabilities of remaining hands are 
left as exercise). A straight is defined as a hand containing five cards in consecutive 
denominations but not of the same suit (e.g., 9, 10, jack, queen, and king). An ace can 
appear at either end, so we could have a straight of the form ace, 2, 3, 4, 5, as well as 
10, jack, queen, king, ace.
The number of hands with a straight can be computed as follows: Each such hand is 
uniquely determined by the lowest denomination (ace, 2, 3, ...,10)in10ways.Then, 
the suits of five cards are chosen in 45 - 4 ways: 45 is the total number of choices of 
suits, and we subtract 4 selections in which all cards are of the same suit. Thus,
P(strait) = 10(45 - 4)
P (slialgUl) 5 52 x .
5
PROBLEMS
3.3.1 (i) A committee of size 50 is to be formed out of the US Senate at random. Find the 
probability that each state will be represented. (ii) If a committee of size k is to be 
formed out of the US Senate find how large must k be in order for the event “at least 
one senator from Ohio is included” to be more likely than the event “no senator from 
Ohio is included.”
3.3.2 A shipment of 30 items is received. For the quality control, three items are randomly 
selected, and if more than one of them is defective then the whole shipment is rejected. 
Find the probability that the shipment will be accepted if it has: (i) Three defective 
items (ii) Ten defective items.
3.3.3 How many ways can one order the deck of 52 cards so that all four kings are next to 
each other?
3.3.4 Peter lives at the corner of 2nd Avenue and 72nd Street. His office is in the building 
at a corner of 7th Avenue and 78th Street. The streets and avenues in the city form a 
perpendicular grid, with no streets or passages in the middle of the blocks. Peter walks 
to work along either street or avenue, always in the direction that gets him closer to 
his office. He always returns home by subway, so he walks across town only once a 
day. (i) How many different paths can Peter choose to go to work? (ii) If Peter makes 
a list of all possible paths and chooses one of them randomly every morning, how 
likely it is that he will not walk 4th Avenue between 75th and 76th streets during the 
next five working days?
3.3.5 (Poker Hands) Find the probability of each of the following hands: (i) Royal 
flush (ace, king, queen, jack, and 10 in one suit), (ii) Straight flush (five cards 
of one suit in a sequence, but not a royal flush), (iii) Flush (five cards in one 
suit, but not a straight flush nor a royal flush), (iv) Four-of-a-kind (four cards 
of the same denomination), (v) Full house (one pair and one triple of the same 
denomination), (vi) Three-of-a-kind (three cards of the same denomination plus two 
cards unmatched).
3.3.6 Find the probability that a poker hand will contain two pairs (one red and the other 
black) and one unmatched card.

56
COUNTING
3.3.7 A poker player has 3V, 7ф, 84, 9ф, QA. He discards 3V and QA and obtains 2 cards.8 
(i) What is the probability that he will have a straight? (ii) Answer the same question 
if QA is replaced by JA (i.e., he discards 3V and JA).
3.3.8 A poker player has 3V, 7ф, 8ф, 9ф, QA. She discards 3 V and QA and obtains 2 cards. 
What is the probability that she will have: (i) A straight flush. (ii) A flush, but not a 
straight flush. (iii) A straight, but not a straight flush.
3.3.9 A poker player has three-of-a-kind. He discards the two unmatched cards and 
obtains two new cards. Find the probability that he will have: (i) Three-of-a-kind. 
(ii) Four-of-a-kind. (iii) A full house.
3.3.10 (i) If n balls are put at random into n boxes, find the probability of exactly one box 
remaining empty? (ii) If n balls are randomly placed into k boxes (n > k), labeled 
1, ...,k, find the probability that no box is empty.
3.3.11 Compute probabilities P (x) of winning x numbers in lotteries, where the player 
chooses: (i) 5 out of 44 numbers. (ii) 6 out of 55 numbers.
3.3.12 Find the number of polygonal lines with vertices (x, C(x)), where C(x) is as in 
Example 3.12 and with possible edges leading from (x, C(x)) to (x +1,C(x)+1)or 
(x + 1, C(x) - 1), connecting the points: (i) (0, 0) and (10, 0). (ii) (0, 0) and (10, 5). 
iii) (3, -2) and (8, 1).
3.3.13 Find the number of polygonal lines (as in Problem 3.3.12) that join the points (2,3) 
and (16, 5) and: (i) Never touch the x-axis. (ii) Never touch the line y = 7.
3.4 MULTINOMIAL COEFFICIENTS
Choosing a subset of size k out of a set of size n is logically equivalent to partitioning the 
set of size n into two subsets, one of size k and the other of size n - k. The number of such
partitions is, by definition,
nk =
n!
k!(n - k)
The theorem below generalizes this scheme.
Theorem 3. 4.1 Let k 1, ... ,kr be positive integers such that k 1 + • • • + kr = n. The number of 
ways a set of n elements can be partitioned into r subsets of sizes k1, k2, ...,kr equals
n!
k1!k2 !• • • kr
(3.26)
Proof: A partition above can be accomplished in steps: First, we choose k1 out of n elements 
to form the first subset of the partition. Next, we choose k2 elements out of the remaining 
n — k 1 elements, and so on, until we have n — k 1 — k2 — • • • — kr-2 = kr- 1 + kr elements, 
from which we choose kr-1 to form the next-to-last subset. The remaining kr elements form 
the last subset This can be accomplished, in view of Theorem 3.2.2, in
n
n
n
n
k1
— k1
k1 — k2
k1
kr-2
k2
k3
kr-1
(3.27)
ways. Simple algebra shows that formula (3.27) is the same as formula (3.26). 
□
8The discarded cards are not mixed with the deck. Assume that the player receives the replacement of the discarded 
cards from the unused remainder of the deck.

MULTINOMIAL COEFFICIENTS
57
The ratio (3.26) is called multinomial coefficient and is denoted by
n
k1 ,k2, ...,kr
As a generalization of Newton’s binomial formula, we have
Theorem 3. 4.2 For every integer n,
(x 1 + 
+ xr) 
k k k x11 "' xrr ,
1, 2, . . . , r
(3.28)
where the summation is extended over all subsets (k1, ...,kr ) of nonnegative integers with 
k 1 + • • • + kr n n.
Proof: In the product (x 1 + • • • + xr)n, one term is taken from each factor so that the gen­
eral term of the sum has the form x11 • • • xrr with k 1 + • • • + kr n n. From Theorem 3.4.1, 
it follows that the number of times the product xk1 • • • xrr appears equals (3.26). 
□
In an analogy with a formula (3.17), the sum of all multinomial coefficients equals rn, 
which follows by substituting x 1 n • • • n xr = 1 in (3.28).
The theorem is illustrated by the following example:
■ EXAMPLE 3.14
Suppose that one needs the value of the coefficient of x2y3z4w in the expression 
(x + y + z + w)10. One could argue that in the multiplication (x + y + z + w) x 
• • • x (x + y + z + w) there are 10 factors, and each term will contain one component 
from each set of parentheses. Thus, choosing x from 2 out of 10 pairs of parentheses,
y from 3 out of 10, and so on, amounts to partitioning 10 pairs of parentheses 
into four classes, with sizes k1 =2,k2 =3,k3 =4, and k4 =1. The total number of 
ways such a partition can be accomplished is the coefficient of x2y3z4w, and equals 
( 10 n 10! n 12 600 
y2,3, 4,1J 
2!3!4!1! 
12,600.
An approximation to n! is given by the so-called Stirling’s formula.
Theorem 3. 4.3 (Stirling’s Formula) We have
n! ^ V2nnn +2 e n,
(3.29)
where the sign ~ means that the ratio of the two sides tends to 1 as n ^ ж.
We shall not give the proof here, but interested readers can find it in more advanced texts, 
for example, in Chow and Teicher (1997).
■ EXAMPLE 3.15
A group of2n boys and 2n girls is divided at random into two equal parts. What is the 
probability pn and its approximation for large n, that boys and girls are divided evenly 
between the two groups?

58
COUNTING
SOLUTION. Clearly, the number of ways a group can be divided into two equal parts 
is 4n . The number of ways 2n boys can be divided evenly is 2n and the same holds 
2n 
n
for girls. Thus,
(2П) О : 
[(2n)!]4
pn 
(4n) 
(n !)4 (4 n)!
(3.30)
which, based on (3.29), can be approximated by
2 n + 1
2n
4
For example, in the case of 16 boys and 16 girls (n = 8), the approximate chances of 
dividing both sexes evenly are about У1 /(4n) = 0.2821. The exact value is 0.2756.
PROBLEMS
3.4.1 Show that if a < b < c < n, then
(i) Use the definition of binomial coefficients as ratios of the factorials. (ii) Use directly 
the interpretation of the binomial coefficients as the number of subsets of a given size. 
(iii) How many ways can one choose an a-element subset from a b-element subset from 
a c-element subset from a d-element subset from a n element set? (where a < b < c < 
d < n).
3.4.2 Find the coefficient of the term x4y5 z3 in the expansion of (x - 2y + 3z)12.
3.4.3 Use the argument analogous to that in Theorem 3.3.2 to show that if i > 1, j > 1, and 
k > 1, then
n+1 
i, j, k
nn
i, j - 1,k i,j, k - 1
3.4.4 Use Stirling’s formula to approximate the number of ways: (i) Asetofsize2n can be 
partitioned into two equal parts. (ii) A set of size 3n can be partitioned into three equal 
parts.
3.4.5 Approximate the probability that every state will be represented in the committee in 
Problem 3.3.1 (i).

CHAPTER 4
CONDITIONAL PROBABILITY, 
INDEPENDENCE, AND MARKOV CHAINS
4.1 INTRODUCTION
Consider a situation where we want to evaluate the probability P(A) of some event A. Sup­
pose that after finding P (A), we learn that some other event, B, occurred. In many cases, 
such an information leads to a change in the assessment of the probability of the event A. 
The symbol used for this new probability will be P (A|B), to be read “conditional probability 
of A, given B,” or “probability of event A, given that B occurred.”
■ EXAMPLE 4.1
Conditional probabilities are most easily interpreted as probabilities in subpopulations. 
Consider an attribute such as color blindness, known to occur much more often among 
men than among women. IfD is the event “a randomly selected person is color blind,” 
then P (D) refers to the chance of color blindness in the whole population. Suppose 
now that the person selected is known to be a woman (event W). This information 
changes the assessment of probability of color blindness to P (D|W), which is now the 
probability of color blindness in the subpopulation of women.
Questions that might arise here are the following:
1. How to use data on probabilities of color blindness separately among men and 
women to find the overall chance of color blindness, that is, to find P (D) if we 
knowP(D|W) and P(D|M)?
2. How to find the probability that a randomly selected color blind person is a woman, 
that is, P (W |D)?
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
59

60
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
The first of these questions requires using the weighted average, usually referred to 
as the formula for total probability (Section 4.3). To answer the second question, one 
has to use the Bayes’ formula (Section 4.4).
The examples and exercises in this chapter are designed to provide practice in recognizing 
which probabilities are conditional and which are not.
PROBLEMS
4.1.1 A computer file contains data on households in a certain city. Each entry line in this 
file contains various information about one household: income, socioeconomic status, 
number of children, their ages, and so on. One data line can then be selected at random 
(each line has the same probability of being selected). Consequently, probabilities of 
various events are interpretable as relative frequencies of entries in the data file with 
the corresponding property.
Let X, Y ,andZ be, respectively, the numbers of boys, girls, and cars in the house­
holds sampled. Let A be the event that a household has a TV set, and let B be the 
event that it has a swimming pool.
(i) Interpret the probabilities below as relative frequencies of occurrence of some 
attributes in certain subpopulations. (a) P(A). (b) P(A|Z > 0). (c) P(Z > 0|A). 
(d) P(X = 0|X + Y = 3). (e) P(B\Ac). (f) P[(X + Y = 0)c\A П B]. (g) P(XY = 
0|X + Y>1).
(ii) Use symbols to express probabilities corresponding to the following relative 
frequencies: (a) Relative frequency of households with two cars. (b) Relative 
frequency of households with no children among households with at least one 
car. (c) Relative frequency of households that have both a swimming pool and a 
TV set, among those who have either a swimming pool or a TV set and have at 
least one car.
4.2 CONDITIONAL PROBABILITY
The conditional probability of event A given event B is defined as
P(A\B) = PP(BBB), 
provided P(B) > 0. 
(4.1)
The definition of conditional probability in cases when the conditioning event B has 
probability zero will be discussed in later chapters. In this chapter, it is always assumed, 
even if not stated explicitly, that the event appearing in the condition has a positive 
probability.
A motivation of the definition (4.1), based on the frequential interpretation of probability, 
is the following. As in Chapter 2, let N(•) denote the number of occurrences of the event in 
parentheses in initial N repetitions of the experiment. Then P (A|B) istobe approximated by 
the frequency of occurrence ofA among those cases where B occurred. Now that B occurred 
in N (B) cases, and the number of occurrences of A among them is N(A П B). Consequently, 
P(A\B) should be the limit of N(A П B)/N(B) = [N(A П B)/N] / [N(B)/N], and the latter 
converges to P(A П B)/P(B).
Observe that the conditional probabilities P (A|B), for a fixed event B, satisfy the axioms 
of probability from Chapter 2. Indeed, nonnegativity holds because P (A|B) is a ratio 

CONDITIONAL PROBABILITY
61
of two nonnegative numbers, P(A n B) and P(B). Next P(SIB) = P(Sn B)/P(B) = 
P(B)/P(B) = 1. Finally, if the events A1 ,A2, ... are mutually exclusive, the same is true 
for the events A1 n B, A2 n B, ... so that
P (uAkIB) = B = PB = 
P(AkB)
A simple consequence of (4.1) is the formula
P(An B) = P(A|B)P(B) = P(B|A)P(A). 
(4.2)
Notice that the first equality is equivalent to (4.1). The second equality follows from the 
observation that the left-hand side of (4.2) remains the same when we interchange the roles 
of A and B. Such an interchange applied to the middle term gives the right-hand side term.
Formula (4.1) shows how to find conditional probability if we have the corresponding 
unconditional probabilities. Formula (4.2), on the other hand, shows that one may find the 
probability of an intersection of two events as the product of the conditional probability of 
one event given the second, and the unconditional probability of the second event. These 
two ways of using conditional probability will now be illustrated by simple examples.
■ EXAMPLE 4.2
Consider families with two children. Assuming that each of the four combinations of 
sexes, BB, BG, GB, and GG, is equally likely, find the probability that a family has 
two boys, given that at least one child is a boy.
SOLUTION. We have
P ([two boys] n [at least one boy])
P (two boys I at least one boy) = 
. 
(4.3)
P (at least one boy)
Since the event “two boys” implies (is contained in) the event “at least one boy,” their 
intersection is the event “two boys.” Hence, the probability in the numerator equals 
1/4. In the denominator, we have the event {BB, BG, GB}, and its probability is 3/4. 
Thus, the answer is 1/3. Notice that
P (BB) 
1
P(two boys | older child is a boy) = —-——--------- - = . 
(4.4)
( y | 
y) 
P(BG or BB) 
2 
( )
The answers in (4.3) and (4.4) are not the same since the two probabilities refer to 
families with two boys in different subpopulations. In the first case, we consider all 
families that have at least one boy, so we eliminate families with two girls. In the second 
case, we are interested in all families whose older child is a boy, so we again eliminate 
not only families with two girls but also families with boy being the younger child 
(combination GB).
■ EXAMPLE 4.3
Assume that in some population, the ratio of the number of men to the number of 
women is r. Assume also that color blindness occurs among men with frequency p, 
while among women with frequency p2. If you choose a person at random, what is the 
probability of selecting a woman who is not color blind? (Incidentally, color blindness 
is a sex-linked attribute, and this is why the frequency of its occurrence among females 
is the square of the frequency of its occurrence among males; see Example 4.9.)

62
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
SOLUTION. Let M, W, and D denote the events “man selected,” “woman 
selected,” and “selected person is color blind.” Our objective is to find the probability 
P (W O Dc). Using (4.2), we write P (W O Dc) = P (Dc\W) P (W) = P (W\Dc) P (Dc). 
The third term is useless, since the data provide directly neither P (Dc) nor P (W |Dc). 
Now, using the middle term, we have P(Dc\W) = 1 - p2. To determine P(W), 
we note that P(M)/P(W) = [1 - P(W)]/P(W) = r, which gives the solution 
P(W) = 1 /(1 + r). Consequently, P(W O Dc) = (1 — p2)/(1 + r).
As an immediate consequence of the definition of conditional probability, we have the 
following theorem:
Theorem 4.2.1 (Chain Rule) For any events A1 ,A2 , ...,An, we have
P (A i O A 2 O^O An)
= P(Ai)P(A2|Ai)P(Aз|Ai O A2) ••• P(AJA 1 O A2 O •••O An-1), 
(4.5)
provided P (A 1 O • • • O An- 1) > 0 (which implies that all conditional probabilities appearing in 
(4.5) are well defined).
Proof : It suffices to write each of the conditional probabilities on the right-hand side as the 
corresponding ratio of unconditional probabilities according to (4.1). The product cancels 
then to the probability on the left-hand side. 
□
It might be helpful to observe that the chain rule is closely related to the counting formula 
in sampling without replacement in Section 3.2.
■ EXAMPLE 4.4
A man has N keys of which only one opens the door. For some reason, he tries them 
at random (eliminating the keys that have already been tried). What is the probability 
that he opens the door on kth attempt?
SOLUTION. Let Ai be the event “ith attempt unsuccessful.” The problem is then to 
find P(A1 O A2 O ••• O Ak-1 O Ack). Applying the chain rule, we obtain
P (A 1 O A 2 O---O Ak- 1 O Ak)
= P(A1)P(A2\A1)P(A3\A1 O A2) ••• P(Ack\A1 O ••• O Ak-1). 
(4.6)
We have here P(A1) = (N — 1)/N. Next, P(A2\A1) = (N — 2)/(N — 1), since after 
A1 occurs there are N — 1 keys to try, of which N — 2 do not open the door. Generally, 
if A1 O A2 O ••• OAj -1 occurs, then j — 1 keys have been tried and eliminated. This 
means that there are N — (j — 1) = N — j +1keys to be tried, of which one fits the 
door; hence,
P (Aj |A 1 O A 2 O...O Aj- 1) = (N — j) / (N — j + 1).
Substitution to (4.6) gives the answer 1/N. It may be surprising that the answer does 
not depend on k. A success close to the beginning or to the end of the search is as likely 
as a success closer to the middle. Let us see another solution to the problem. Trying 
the keys at random without repetition is the same as ordering the keys into a sequence 
and trying them in this order. The chances that the correct key will appear at the kth 

CONDITIONAL PROBABILITY
63
place are the same as for any other place; hence, the probability must be the same for 
success at any trial.
A convenient way of using the chain rule is related to computing probabilities through 
event trees. This technique is applicable when the outcomes in the sample space S are 
sequences of events, typically with the preceding events affecting the probabilities of the 
subsequent ones. The set of such outcomes can then be depicted as a tree, and probabilities 
of the outcomes (“branches” ofa tree) are calculated according to the chain rule as products 
of probabilities assigned to consecutive segments of the branch. This general description 
will be illustrated by an example of an urn scheme, a convenient device for analyzing many 
real-life problems.
■ EXAMPLE 4.5
An urn initially contains r red balls and g green balls. A ball is selected at random and 
returned to the urn. If the chosen ball is red, then a red and b green balls are added. If 
the chosen ball is green, then c red and d green balls are added. Next, a second ball is 
drawn, returned, and the process of adding balls is repeated. Finally, the third ball is 
drawn. Find the probabilities for each possible sequence of colors on three draws: (red, 
green, green), (red, red, red), and so on.
SOLUTION. Let us use the notation R1, G1 , R2, G2, R3, and G3 for the events that 
occur at the first, second, and third drawings. The “natural” choice of the sample space 
S is
Г R 1 П R 2 П R 3, R 1 П R 2 П G 3, R 1 П G 2 П R 3, R 1 П G 2 П G 3, 1
| G 1 П R 2 П R 3, G 1 П R 2 П G 3, G 1 П G 2 П R 3, G 1 П G 2 П G 3 ) .
We need to find the probabilities such as P(R 1 П G2 П G3). Using the chain rule, we 
obtain P(R 1 П G2 П G3) = P(R 1)P(G2\R 1)P(G3R 1 П G2). The outcomes are rep­
resented as branches of the tree in Figure 4.1, labeled with the corresponding proba­
bilities. By the chain rule, each branch has a probability equal to the product of the 
probabilities assigned to its segments, for example,
P(R 1 П G2 П G3) =
g+b+d
g+b
X —------:---- -r x
r+g+a+b r+g+a+b+c+d
r
r + g
c+d+g+r
Figure 4.1 Possible results of the two first draws in Example 4.5.

64
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
Observe that we do not make any assumptions about the signs of a, b, c, and d, 
which makes this scheme quite flexible. Therefore, if we want to consider the scheme 
where the balls sampled are not returned, and no other balls are added, we can put 
a = -1,b = c =0, and d = -1.
PROBLEMS
4.2.1 Let events A, B, and C be such that P (A) > 0,P(B) > 0, and P (C) > 0. 
Label the following statements as true or false: (i) The conditional prob­
ability P (A|B) can never exceed the unconditional probability P (A). (ii) 
If P(A|B) = P(A|C), then P(B) = P(C). (iii) If A and B are disjoint, 
then P(A\A U B) = P(A)/[P(A) + P(B)]. (iv) P(A\B) + P(Ac\B) = 1. (v) 
P(A|B) + P(A|Bc) = 1.
4.2.2 Assume that A and B are disjoint. Find P (Ac\B) and P(A U B\Ac).
4.2.3 Assume that P(A П B) > 0 and determine P(A)/[P(A) + P(B)] as a function of a, 
where a = P (B\A)/P (A\B).
4.2.4 Find P(A П B) if P(A) = 3/4, P(B) = 1 /2, P(A\B) - P(B\A) = 2/9.
4.2.5 P(A) = P(B) = 1 /2, P(A\B) = 1 /3. Find P(A П Bc).
4.2.6 Find P(A\B), ifP(Ac) = 2P(A) and P(B\Ac) = 2P(B\A) = 0.2.
4.2.7 Find P[A П B П C|(A П B) U (A П C)] if P(A) = 0.8, P(B) = 0.4, 
P(C)=0.4,P(AUB)=1,P(AUC)=0.9, andP(BUC)=0.6.
4.2.8 Events A, B , and C are such that at least one of them occurs. Moreover, 
P(A\B) = P(B\C) = P(C|A) = 1 /2,P(B П C) = 2P(A П B) =4P(C П A)/3 = 
2P(A П B П C). Find the probability that: (i) Exactly one of events A, B, and C 
occurs. (ii) Only B occurs.
4.2.9 Three distinct integers are chosen at random from the set {1, 2, ..., 15}. Find the 
probability that: (i) Their sum is odd. (ii) Their product is odd. (iii) The sum is odd if 
it is known that product is odd. (iv) The product is odd if it is known that the sum is 
odd. (v) Answer questions (i)-(iv) if three integers are selected from {1, ..., 20}. (vi) 
Generalize answers to (i)-(iv) in the case of selection from {1, ..., n}. (vii) Answer 
questions (i)-(iv) by drawing from {1, ..., n}, and passing to the limit with n ^ ж.
4.2.10 A deck of eight cards contains four jacks and four queens. A pair of cards is drawn at 
random. Find the probability that both cards are jacks if: (i) At least one of the cards 
is a jack. (ii) At least one of the cards is a red jack. (iii) One of the cards is a jack of 
hearts.
4.2.11 A fair coin is tossed until a head appears. Given that the first head appeared on an 
even-numbered toss, what is the probability that it appeared on the 2nth toss?
4.2.12 A tennis player has the right to two attempts at a serve: If he misses his first serve, 
he can try again. A serve can be played “fast” or “slow.” If a serve is played fast, the 
probability that it is good (the ball hits opponent’s court) is A; the same probability 
for a slow serve is B . Assume that 0 <A<B; that is, the fast serve is more difficult 
(but not impossible) to make.
Ifa serve is good, the ball is played, and eventually one of the players wins a point. 
Let a be the probability that the server wins the point if the serve is fast (and good), 

PARTITIONS; TOTAL PROBABILITY FORMULA
65
and let b be the same probability for a slow serve. Assume that 0 <b<a; that is, a 
fast serve gives a certain advantage to the server (the ball is harder to return, etc.).
The server has four possible strategies: FF,FS,SF, and SS, where FF is “play 
first serve fast; if missed, play second serve fast,” FSis “play first serve fast; if missed 
play second serve slow,” and so on. (i) Determine the probabilities PFF,PFS,PSF, 
and PSS of winning the point by the server under the four strategies. (ii) Show that 
the strategy SF is always inferior to the strategy FS. (Hint: Consider the difference 
PFS - PSF.) (iii) Show that if Aa > Bb, then strategy FF is better than FS. (iv) 
Show, by choosing appropriate numbers A, B, a, and b (with A<Band a>b), that 
each of the strategies FF and SS may be best among the four. Explain why such 
cases do not occur among top players, for whom the best strategy is FS.
4.2.13 Three cards are drawn without replacement from an ordinary deck of cards. Find the 
probability that: (i) The first heart occurs on the third draw. (ii) There will be more 
red than black cards drawn. (iii) No two consecutive cards will be of the same value.
4.2.14 An urn contains three red and two green balls. Ifa red ball is drawn, it is not returned, 
and one green ball is added to the urn. If a green ball is drawn, it is returned, and two 
blue balls are added. If a blue ball is drawn, it is simply returned to the urn. Find 
the probability that in three consecutive draws from the urn, there will be exactly one 
blue ball drawn.
4.3 PARTITIONS; TOTAL PROBABILITY FORMULA
In this section, we introduce some formulas, important and useful in computing certain prob­
abilities. We begin with the concept of partition (used already in Section 1.4).
Definition 4.3.1 We say that a class of events H = {H1 ,H2, ...} forms a partition (of the 
sample space S) if these events exclude one another and one of them must occur. Formally, 
this means that
Hi П Hj = 0 for all i = j 
(4.7)
and
H 1 U H2 U ... = 5. 
(4.8)
□
We say that a partition is finite or countable, depending on whether it contains a finite 
or a countably infinite number of events. In later chapters, we also consider uncountable 
partitions.
Definition 4.3.2 Given two partitions
H = {H1,H2, ...} and K = {K1,K2, ...},
we say that H is finer than K (H is contained in K) if for every event Hi in H there exists an 
event Kj in K such that Hi c Kj. 
□
■ EXAMPLE 4.6
For any event B, K = {B, Bc} is always a partition of 5. A pair of events A and 
B allows us to define a partition H into four sets: H 1 = A П B, H2 = A П Bc, 
H3 = Ac П B, and H4 = Ac П Bc. We have here H C K, as one can easily verify.

66
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
Generally, if H = {H1 ,H2, ...} and K = {K1, K2, ...} are two partitions, then the 
class of all sets Hi П Kj for Hi in H and Kj in K is a partition, called the intersection 
of H and K and denoted H x K .It is finer than both H and K.
Finer partitions correspond to more detailed (richer) information, whereas larger parti­
tions are used to represent general information.
■ EXAMPLE 4.7
Consider a data file on employees of some company. Let H = {H0, H1, ...} be the 
partition of data by level of education, and let K = {K0, K1, ...} be the partition 
of data corresponding to the number of full years of employment in the company. 
Knowledge of the category in H to which a data entry belongs gives information about 
the education level of the employee. Knowledge of the category in the intersection 
HxKgives information about both education level and number of years of employ­
ment, hence gives more information than either of H or K alone.
It will be convenient to introduce the following definition:
Definition 4.3.3 A partition H = {H1, H2, ...} is called positive, if P (Hi) > 0 for all Hi 
in H. 
□
We can now formulate the following simple theorem called the formula for total probability 
providing a valuable tool for computing probabilities.
Theorem 4.3.1 Let H = {Hj ,j =1, 2, ...} be a positive (finite or infinite) partition and let 
A be an arbitrary event. Then
P (A) = P (AH i) P (H i) + P (AH2) P (H2) + ••• + P (AH) P (Hn) 
(4.9)
in the case of a finite partition H, or
P (A) = P (AH 1) P (H1) + P (AH2) P (H2) + ... 
(4.10)
in the case of an infinite countable partition H.
Proof : Using (4.7), (4.8), and (4.1), we have
P(A) = P((A П H 1) U (A П H2) U ... ) 
= P (A П H 1) + P (A П H2) + ... 
= P(AIH1)P(H1)+P(AIH2)P(H2)+.
The summation may be finite or not, depending on whether the partition H is finite. □
One may think of the conditional probability P (AIHk) as the relative frequency of 
attribute A in the subpopulation corresponding to event Hk. Then formulas (4.9) and (4.10) 
give the overall frequency of attribute A in the whole population, expressed as the weighted 
average, with weights P(Hk),k=1, 2, ... being the contributions of the kth subpopulation 
to the whole population.
In the simplest case of a positive partition into two sets ({B, Bc}), formula (4.9) reduces to
P(A) = P(AIB)P(B) + P(AIBc)P(Bc)
= P(AIB)P(B) + P(AIBc)(1 - P(B)).

PARTITIONS; TOTAL PROBABILITY FORMULA
67
■ EXAMPLE 4.8
Recall Example 4.3. In a certain group of people the ratio of the number of men to the 
number of women is r . It is known that the incidence of color blindness among men 
is p, and the incidence of color blindness among women is p2 . What is the probability 
that a person randomly chosen from this group is color blind?
SOLUTION. We use the formula for total probability, with events M and W (choice 
of man and choice of woman) as a partition. The probability of the event D (the per­
son selected is color blind) is then P(D) = P(D|M)P(M) +P(D|W)P(W). Since 
P (M) = r/(1 + r) and P (W) = 1/(1 + r) (see Example 4.3), the answer is P (D)= 
pr/(1 + r) + p2/(1 + r)=p(p + r)/(1 + r).
■ EXAMPLE 4.9
The reason why the frequency of color blindness among females is the square of the cor­
responding frequency among males is that the gene responsible for color blindness (as 
well as the gene responsible for other sex-linked attributes, e.g., hemophilia) is located 
on the X chromosome. There are two sex chromosomes, X and Y , and every person 
has a pair of such chromosomes, with individuals of the type XX being females and 
XY being males.
The color blindness gene has two forms (alleles), say C and c, with form c being 
recessive and causing color blindness. Because every man has one X chromosome, he 
therefore is either of category C or c, the latter being color-blind. Women, having a pair 
ofX chromosomes, are of one of three categories: (1) CC, which we will call “normal;” 
(2) Cc, the so-called carriers (i.e., persons who are not color-blind but are capable of 
transmitting the color blindness gene c to their offspring), and (3) cc, women who are 
color-blind.
Let p be the relative frequency of the form c in the population of genes in ques­
tion. Then p is also the relative frequency of color-blind men (since each man carries 
one color-blindness gene, either C or c). Now, let u and v denote the relative fre­
quency of carriers and of color-blind women, respectively. To find u and v, we proceed 
as follows: So far we know that a woman is color-blind if her father is color-blind
and either (1) her mother is color-blind, or (2) her mother is a carrier and transmits
the gene c to the daughter. This gives, using the formula for total probability, the
relation
v +— u
2
v=p
(4.11)
On the other hand, a woman is a carrier if either (1) her father is color-blind, and 
her mother is “normal,” (2) her father is color-blind, and her mother is a carrier who 
transmits to her the gene C, (3) her father is “normal,” and her mother is a carrier who 
transmits gene c, or (4) her father is “normal,” and her mother is color-blind.
This gives the relation
u=p
(1 - u - v) + 2 u
+ (1 - p)
1uU + v 
2
(4.12)
The solution of the pair of equations (4.11) and (4.12) gives v = p2,u=2p(1 - p). The 
relative frequency of women who are “normal” (i.e., neither color-blind nor a carrier) 
is 1 - u - v =(1- p)2, while the relative frequency of color-blind women is p2 ,as 
asserted.

68
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
The formula for total probability can be extended to conditional probabilities as follows:
Theorem 4.3.2 LetH = {H1, H2, ...} be a positive partition of the sample space, and let A, B 
be two events with P (B) > 0. Then
P(A\B) = £ P(A\B n Hj)P(Hj IB). 
(4.13)
j
Proof : The right-hand side can be written as9
PA (A n в n Hj) 
p (в n Hj)
j p (в n Hj) 
x 
p (в)
PB p/(A n B) n U Hj
P1B) Y,P (An B n Hj)
PPABB=P (AB).
□
One can also consider “coarsening” of a partition H' by grouping its sets, thus forming a 
new partition H corresponding to a less precise information.
Theorem 4.3.3 Let H, H' be two partitions, with H being a coarsening of H'. Then for any 
event A,
k
Ph(A\Hi) = £Ph(A\H'if)P(Hj\H)),
j=1
where Hi = Hi 1 U • • • U Hj, Hi & H, and Hj & H'.
Thus, the conditional probability with respect to a coarser partition is the weighted average 
of probabilities with respect to the finer partition.
Proof: The proof is obtained by simple algebra. If {Hj, ..., Hj } is a partition of Hi, 
then
(
k
A A Hj\Hi
j=1
kk
= Y. P (A n Hj\Hi ) = £
j=1 
j=1
p (A n Hj n Hi) 
p (Hi)
А p(A n Hj) = * p(A\Hj)p(Hj) 
2-/ p (Hi) 
2^
j=1 
i 
j=1
Д , p (Hj n Hi)
P ( AHj 
PH
p(Hi)
= Yj P(A\Hj)P(Hj \H)).
j=1 
□
9Formally, the summation in (4.13) extends only over those j for which P(B П Hj) > 0, otherwise, P(A|B) is not 
defined. It does not matter here since P(B П Hj) =0 implies P(Hj IB) = 0.

BAYES’ FORMULA
69
PROBLEMS
4.3.1 An event W occurs with probability 0.4. If A occurs, then the probability of W is 0.6; 
if A does not occur but B occurs, the probability of W is 0.1. However, if neither A 
nor B occurs, the probability of W is 0.5. Finally, if A does not occur, the probability 
ofB is 0.3. Find P(A).
4.3.2 Suppose that initially the urn contains one red and two green balls. We draw a ball 
and return it to the urn, adding three red, one green, and two blue balls if a red ball 
was drawn, and three green and one blue ball if a green ball was drawn. Then a ball is 
drawn from the urn. Find the probability that both selected balls are: (i) Blue. (ii) Red. 
(iii) Green. (iv) Of the same color.
4.3.3 Suppose that in Problem 4.3.2 we return the second ball to the urn, and add new balls 
as described, with the condition that if the second ball is blue, we add one ball of 
each color. Then we draw the third ball. What is the probability that the third ball is: 
(i) Blue? (ii) Blue if the first ball was red? (iii) Blue if the second ball was red? (iv) Blue 
if no blue ball was drawn on any of the preceding draws?
4.3.4 Let A and B be two events with P(B) > 0, and let C1, C2, ... be a possible partition 
of a sample space. Prove or disprove the following formulas:
P(AIB) = £ P(A\B П Ci)P(Ci),
i
P(AIB) = £ P(AIB П Ci)P(BC)P(Ci).
i
4.3.5 (Tom Sawyer Problem) You are given a task, say painting a fence. The probability 
that the task will be completed if k friends are helping you is pk (k =0, 1, ...). If j 
friends already helped you, the probability that the (j + 1)st will also help is n (j = 
0, 1, ...). On the other hand, if the jth friend did not help, then the (j + 1)st will not 
help either. (i) Find the probability that the task will be completed. (ii) Solve part (i) if 
pk = 1 — Xk, nj = p for all j.
4.3.6 Recall Example 4.9. Find the probability that the mother is a carrier if: (i) Both father 
and son are color-blind, and the mother is not. (ii) It is known only that the son is 
color-blind. (iii) The son is color-blind, but the parents are not.
4.4 BAYES’ FORMULA
Let us consider now a following question: Ifit is known that a certain event A occurred, and 
its conditional probabilities P (AIH1), P (AIH2), ... for partition H1, H2, ... are known, 
can we determine the probability of the event Hk of the partition? The answer is contained 
in the following time-honored theorem, dating back to the eighteenth century.
Theorem 4.4.1 (Bayes’ Formula) Let H = {H1, H2, ...} be a positive partition of S, and A 
be an event with P(A) > 0. Then for any event Hk of the partition H,
P(HkIA) =
P (AIHk) P (Hk)
P (AH i) P (H i) + ••• + P (AIHn) P (Hn) 

70
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
in the case of a finite partition H, and
P (H \A) = 
P (AH) P (H)
( k ) 
P(A\H1)P(H 1) + P(A\H2)P(H2) + ...
when partition H is countably infinite.
Proof: Using formula (4.1) twice,
PH A l'(Hk П A) _ P(A\Hk)P(Hk) 
P(Hk |A) = P (A) = 
P(A) 
'
The theorem follows if one replaces the denominator on the right-hand side by the formulas 
(4.9) and (4.10). 
□
In the case of a partition (positive) into two events, H = {B, Bc}, and any event A with 
P (A) > 0, we have
P (B\A) = 
P (A\B) P (B)
( \ ) 
P(A\B)P(B) + P(A\Bc)P(Bc)'
One of the interpretations of Bayes’ theorem is when the partition H represents all possible 
mutually exclusive conditions (states of nature, hypotheses, etc.) that are logically possible. 
The probabilities P (H1), P (H2), ... represent the prior knowledge, experience, or belief 
about the likelihood of H1, H2,  AneventA is then observed, and this fact usually 
modifies the probabilities of Hi’s. Accordingly, P (Hi) and P (Hi\A) are often called prior 
and posterior probabilities of Hi .
■ EXAMPLE 4.10
Returning to Example 4.8, suppose that the person that we randomly selected is 
color-blind. Intuitively, this should increase the chance that this person is a man. 
Indeed, we have here
P (M \D) =----------- P(D\M) P(M)-------------=------1+-------= Г
v 7 
P (D\M) P (M)+ P (D\W) P (W) 
P^. + P^ 
r + p'
1+r + 1+r
a quantity close to 1 if p is small.
As mentioned above, Bayes’ theorem can be used to reassess the probabilities of “states 
of nature” or “hypotheses” based on the additional evidence. How should one reassess the 
probabilities when the evidence comes sequentially? Specifically, if the evidence comes in two 
portions, say A followed by A", should one modify the prior probabilities given A' П A", or 
should one first obtain posterior probabilities given A' and then use these posteriors as new 
priors, to be modified given A"?
The answer, as might be expected, is that it does not matter. We have the following 
theorem:
Theorem 4.4.2 (Updating the Evidence) Let H = {H 1, H2, ... } be a partition, and let A' and 
A" be two events. If P (A' П A") > 0, then for every event Hk in partition H we have
P(Hk\A П A") =
P(A' П A"\Hk)P(Hk) 
£ P(A' П A"\Hj)P(Hj)
P(A"\Hk П A)P(Hk\A') 
£ P(A"\Hj П A)P(Hj \A').
(4.14)

BAYES’ FORMULA
71
Proof : The middle term is Bayes’ formula applied to the left-hand side. We write
P(A n A"\Hi)P(Hi) = P(A n A" n Hi)
= P(A"\A' n Hi)P(A n Hi)
= P(A"\Hi n A)P(Hi\A)P(A)
to show the equality of the middle and right-hand-side terms.
□
■ EXAMPLE 4.11
An urn contains two coins: One is a regular coin, with heads and tails, while the other 
has heads on both sides. One coin is chosen at random from the urn and tossed n times. 
The results are all heads. What is the probability that the coin tossed is a two-headed 
one?
SOLUTION. Intuitively, for a large n we expect the probability that the coin selected 
has two heads to be close to 1, since it is increasingly unlikely to get n heads in a row 
with a regular coin. Let H1 and H2 be the events “regular coin was chosen” and “coin 
with two heads was chosen,” respectively. Clearly, H1 and H2 form a partition. Let the 
prior probabilities be P(H1) = P(H2) = 1/2, and let An be the event “n heads in a 
row”; our objective is to find P (H2|An). Since P(An|H2) = 1 for all n (this coin will 
only give heads), and P(An|H1) = 1/2n, by Bayes’ theorem we have
- |A ) = 
P(AnlH2)P(H2) 
= 
■’
2| n) 
P(An\H1)P(H1) + P(AnlH2)P(H2) 
2+ + 1 •
(4.15)
As expected, the probability (4.15) does approach 1 as n increases.
Suppose now that after An was observed, an additional m tosses again produced 
only heads (event Bm). Because An n Bm is the same as An+m , the posterior probabil­
ity of the two-headed coin (H2) given An+m is 2n+m/(2n+m +1), after we replace n + 
m forn in (4.15). Using the second part of formula (4.14), and the fact that P(BmlHi n 
An)=P(BmlHi),i=1,2, we obtain
P(H2lAn n Bm) = __________P (BmlH2) P (H2 An)___________
P ( Bm\H 1) P ( H1 \An )+ P ( BmlH2) P ( H2 An)
1 X A+1 
2n+m
X _1------1 1 
= 2n+m + 1 ’
2 m X 2n + 1 + x X 2n + 1
which agrees with the result of updating “all at once.”
It might seem at first that this problem is purely artificial, invented for the sole 
purpose of providing practice for students. This is not so; the problem is of impor­
tance in breeding and selection. Consider a gene with two forms (alleles) A and a. 
Assume that Ais dominant and a is recessive so that we have two phenotypes: Indi­
viduals aa can be distinguished from the others, but individuals AA and Aa cannot 
be told apart. Moreover, assume that allele a is undesirable and we want to eliminate 
it, ultimately producing a pure strain of individuals of type AA only. The problem 
then lies in eliminating individuals Aa. One of the ways to do it is to allow cross­
breeding between a tested individual (of type AA or Aa) with an individual of type 
aa (you may think here of plants that can easily be cross-pollinated). If the tested indi­
vidual is of the type AA (“coin with two heads”), all offsprings will be of type Aa.

72
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
However, if the tested individual is of the type Aa (“regular coin”), about half of the 
offspring will be of type Aa and half of type aa (corresponding to results of tosses 
being heads or tails with probability 1/2). Now, ifn offspring are of type Aa, the pos­
terior probability that the tested individual is AA can be computed as above, except 
that the prior probability need not be 1/2 (it may be assessed from the genetic theory 
and other information about the tested individual). Usually, the breeder will accept 
an individual as a pure strain AA if the posterior probability that it is AA exceeds a 
threshold such as 0.99 or so, hence, if sufficiently many offspring of type Aa have been 
observed.
■ EXAMPLE 4.12
In the famous Monty Hall problem, there are three curtains, say A, B, and C, of which 
two hide nothing while behind the third there is a Big Prize. The Big Prize is won if it is 
guessed correctly which curtain hides it. You choose one of the curtains, say A. Before 
curtain A is pulled to reveal what is behind it, the game host pulls one of the two 
other curtains, say B , and shows that there is nothing behind it. He then offers you the 
option to change your decision (from curtain A to curtain C). Should you stick to your 
original choice (A) or change to C (or does it matter)? The answer to this question is 
counterintuitive and has stirred a lot of controversy. The common conviction is that it 
does not matter: There are two closed curtains, and the chances of the Big Prize being 
behind either of them must be 50-50, so it is irrelevant whether or not you change your 
choice.
Actually, the answer is that you should switch to C; this way you double your chance 
of winning.
We assume that (1) the game host pulls one of the two curtains (B or C) that 
does not hide the Big Prize (this implies that the host knows where the Big Prize is), 
and (2) if both curtains B and C have nothing behind them, the host selects one at 
random.
Let A, B, and C be the events “Big Prize is behind curtain A” (respectively, B 
and C). We assume the original choice was curtain A, and let B* be the event “host 
shows that there is nothing behind curtain B.” We want P(AB*). By Bayes’ formula, 
taking A, B, C as a partition and assuming P(A) = P(B) = P(C) = 1/3,
P (AB) =_______________ P (B*IA)P (A)________________
( | 
) 
P (B*IA) P (A) + P (B*B) P (B)+ P (B*IC) P (C)
= 
2 x 3 
= 1
2 x3 + 0 x1 + 1x3 
3
Since P(B|B*) = 0, we must have P(C|B*) = 2/3, so the chances of finding the Big 
Prize behind curtain C (i.e., winning if one changes the original choice) is 2/3 and not 
1/2.
Here is an argument that might help convince people who claimed originally that 
the chances were 1/2. Imagine that John and Peter are going to play the game a large 
number of times, say 300 times each. Each originally chooses A, and after being given 
a choice to switch, John never switches while Peter always switches.
John wins only if his original choice was correct, which happens in about 33% times 
(we assume that the Big Prize is each time randomly located behind one of the curtains 
A, B, and C). He may expect to win about 100 times out of 300.
On the other hand, Peter wins whenever his original choice was wrong (because then 
switching is a correct choice). Consequently, he wins in about 200 cases out of 300.

BAYES’ FORMULA
73
PROBLEMS
4.4.1 Suppose that medical science has developed a test for a certain disease that is 95% 
accurate, on both those who do and those who do not have the disease. If the incidence 
rate of this disease in the population is 5%, find the probability that a person: (i) Has 
the disease when the test is positive. (ii) Does not have the disease when the test is 
negative.
4.4.2 Two different suppliers, A and B, provide the manufacturer with the same part. All 
supplies of this part are kept in a large bin. In the past 2% of all parts supplied by 
A and 4% of parts supplied by B have been defective. Moreover, A supplies three 
times as many parts as B. Suppose that you reach into the bin and select a part. (i) 
Find the probability that this part is defective. (ii) If the part is nondefective, find the 
probability that it was supplied by B?
4.4.3 An urn originally contains three blue and two green chips. A chip is chosen at random 
from the urn, returned, and four chips of the opposite color are added to the urn. 
Then a second chip is drawn. Find the probability that: (i) The second chip is blue. 
(ii) Both chips are of the same color. (iii) The first chip was green if the second chip 
is blue.
4.4.4 One box contains six red and three green balls. The second box has six red and four 
green balls. A box is chosen at random. From this box two balls are selected and 
found to be green. Find the probability that the pair was drawn from the first box if 
the draws are: (i) Without replacement. (ii) With replacement.
4.4.5 Suppose that box A contains four red and five green chips and box B contains six red 
and three green chips. A chip is chosen at random from box A and placed in box B. 
Finally, a chip is chosen at random from those now in box B. What is the probability 
that a green chip was transferred given that a red chip was drawn from box B?
4.4.6 We have three dice, each with numbers x =1, ...,6, and with probabilities as follows: 
die 1: p(x) = 1/6, die 2: p(x)=(7- x)/21, die 3: p(x) = x2/91. A die is selected at 
random, tossed, and the number 4 appears. What is the probability that it is die 2 that 
was tossed?
4.4.7 Players A and B draw balls in turn, without replacement, from an urn containing 
three red and four green balls. A draws first. The winner is the person who draws the 
first red ball. Given that A won, what is the probability that A drew a red ball on the 
first draw?
4.4.8 Twenty chips are placed in a box. On one side each chip has either red (10), blue (5), 
or green (5) color. On the other side each chip has either one or two dots: six red chips 
have one dot, while four have two dots, exactly two green and three blue chips have 
two dots. One chip was randomly selected from the box. If it has two dots, what is 
the probability that it is red on the other side?
4.4.9 A prisoner is sentenced to life in prison. One day the warden comes to him and offers 
to toss a fair coin for either getting free or being put to death. After some deliberation 
the prisoner refuses, on the ground that it is too much risk: He argues that he may 
escape, or be pardoned, and so on. The warden asks him if he would agree to play 
such a game if the odds for death were 1:9 or less. The prisoner agrees.
Here is the game: An urn contains coins, labeled with digits on both sides. There is 
one coin labeled 1 and 2. There are nine coins labeled 2 and 3, and there are 81 coins 

74
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
labeled 3 and 4. A coin is to be selected at random by the warden and tossed. The 
prisoner can see the upper face and has to guess correctly the other face of the coin.
The prisoner decides to use the following guessing strategy: if 1 shows up, he would 
guess that the other side is 2 (and win). Similarly, if 4 shows up, he would guess that 
the other side is 3, and win. If 2 shows up, he would guess that the other side is 3, 
since there is one coin with 1 against nine coins with 3 on the other side. Similarly, 
if 3 shows up, he would guess 4, since there are nine coins with 2, against 81 coins 
with 4.
A coin was chosen, tossed, and 2 appeared. The prisoner was about to say “3,” 
when the following doubts occurred to him: “Suppose that this coin has indeed 3 on 
the other side. It is therefore a 2-3 coin. But this coin, before it was tossed, had equal 
chances of showing 2 and showing 3. But if it had shown 3, I would have guessed 4, 
and be put to death. So I played a game with fifty-fifty chances for death, which I 
decided not to play at the start.”
As the story goes, the prisoner decided not to play. So he spent the rest of his life in 
prison contemplating whether or not he did the right thing. Find the probability that 
the prisoner would go free computed before a coin is selected.
4.5 INDEPENDENCE
The notion of the conditional probability P (A|B) introduced in Section 4.4 concerned the 
modification of the probability of an event A in light of the information that some other 
event B has occurred. Obviously, an important special case here when is such information 
is irrelevant: Whether or not B has occurred, the chances of A remain the same. In such a 
case, we say that the event A is independent of the event B . As we will see, the relation of 
independence defined in this way is symmetric: when A is independent of B, then B is also 
independent of A.
The essence of the idea above is that A is independent of B whenever P(A|B) = P(A). 
Using (4.1), this implies that P(A П B)/P(B) = P(A), and multiplying by P(B)—which 
we may to do, since P(B) > 0 by assumption—we obtain P(A П B) = P(A)P(B). This 
relation is symmetric in A and in B, as asserted; moreover, it holds also if one or both events 
have probability zero.
Consequently, we introduce the following definition:
Definition 4.5.1 We say that two events, A and B, are independent if their probabilities satisfy 
the multiplication rule:
P (A П B )= P (A) P (B). 
(4.16)
□
In practice, (4.16) is used in two ways. First, we can compute both sides separately and com­
pare them to check whether or not the two events are independent. More often, however, 
we assume that A and B are independent and use (4.16) for determining the probability of 
their intersection (joint occurrence). Typically, the assumption of independence is justified 
on intuitive grounds (e.g., when the events A and B do not influence each other).
■ EXAMPLE 4.13
A box contains r red and g green balls. We draw a ball at random from the box, and 
then we draw another ball. Let R1 and R2 be the events “red ball on the first (second) 
draw.” The question now is whether the events R1 and R2 are independent.

INDEPENDENCE
75
SOLUTION. The answer depends crucially on what happens after the first draw: Is 
the first ball returned to the box before the second draw or not? More generally, is the 
content of the box modified in any way by the first draw?
Suppose first that the ball drawn is returned to the box (the scheme known under 
the name sampling with replacement). Then P(R1) = P(R2) = r/(r + g); hence, 
P(R1)P(R2) = [r/(r + g)]2. To check the independence, we have to compute 
P(R 1 П R2). Recall that the two draws with replacement may produce (r + g)2 
distinct results, by the product rule of the preceding chapter. The number of ways one 
can draw two red balls is—again, by the product rule—equal to r2 . Consequently, 
P(R 1 П R2) = r2/(r + g)2, which is the same as P(R 1)P(R2). This shows that events 
R1 and R2 are independent.
If we do not return the ball to the box (sampling without replacement), we can pro­
ceed as follows: We have P(R 1 П R2) = P(R 1)P(R2\R 1) by (4.2), and P(R2\R 1) = 
(r - 1)/(r + g - 1), since if R1 occurs, there remain r + g - 1 balls in the box, 
of which r — 1 are red. Consequently, P(R 1 П R2) = r(r — 1)/(r + g)(r + g — 1). 
To verify whether or not this last quantity equals P (R1)P (R2), we need to 
evaluate P(R2 ). Observe that the probability of a red ball on the second draw 
is a random quantity depending on the outcome of the first draw. Taking events 
R1 and G1 as a partition and using the total probability formula, we can write 
P(R2) = P(R2\R1)P(R1) +P(R2\G1)P(G1), which equals r/(r + g), so that 
P(R 1 П R2) is not the same as P(R 1)P(R2). Therefore, events R 1 and R2 are 
dependent.
We will prove next an important property of independent events that will facilitate many 
calculations.
Theorem 4.5.1 If the events A and B are independent, so are the events A and Bc ,Ac , and B, 
as well as Ac and Bc.
Proof: Itis sufficient to prove only the independence ofA and Bc. Indeed, the independence 
of the second pair will follow by symmetry, and the independence of the third pair will follow 
by successive application of the two already proved statements.
Thus, assume that P(A П B) = P(A)P(B) and consider the event A П Bc. Since A = 
(A П B) U (A П Bc), we have P(A) = P(A П B) + P(A П Bc) so that
P(A П Bc) = P(A) — P(A П B) = P(A) — P(A)P(B) 
= P(A)(1 — P(B)) = P(A)P(Bc),
which had to be shown. 
□
As shown in Example 4.13, the difference between sampling with and without replace­
ment lies in the fact that the first leads to independent outcomes, while the second does not. 
However, when the population is large, this difference is negligible.
Specifically, we may regard two events A and B as “almost independent” if the difference 
between P(A П B) and P(A) P(B) is small. Let us compute the difference
Q = \P(R 1 П R2) — P(R 1)P(R2)|
in the case of sampling without replacement (obviously, for sampling with replacement, this 
difference is zero). We have here
r — 1 
r 
rg
r + g — 1 r + g 
(r + g)2(r + g — 1) ,
a quantity that is small when either r or g is large (or both are).
r+g

76
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
It appears that we might take \P(A П B) - P(A)P(B) | as a measure of degree of depen­
dence between events A and B . This is indeed the case, except that we have to take into 
account the fact that this difference may be small simply because one of the events A or B 
has small probability. Consequently, we need to “standardize” the difference. This leads to 
the following definition:
Definition 4.5.2 Assume that 0 < P(A) < 1 and 0 < P(B) < 1. The quantity
r(A, B)=
P (A П B) - P (A) P (B) 
vP(A)(1 - P(A))P(B)(1 - P(B))
(4.17)
will be called the coefficient of correlation between events A and B .
□
The coefficient of correlation is a measure of dependence in the sense specified by the 
following theorem:
Theorem 4.5.2 The coefficient of correlation r(A, B) is zero if and only ifA andB are indepen­
dent. Moreover, we have |r (A, B) | < 1, with r (A, B) = 1 if and only if A = B, and r (A, B) = 
-1 if and only ifA = Bc.
Proof: The proof is by elementary checking, except for the “only if” parts of the last two 
statements. These parts follow from the general theorem on the properties of correlation 
coefficients for random variables, to be discussed in Chapter 6. 
□
We can extend the concept of independence to the case of more than two events.
Definition 4.5.3 We say that the events A1 ,A2 , ...,An are independent if for any set of 
indices i 1, i2, .. .,ik with 1 < i 1 < i2 < • • • < ik < n, we have the following multiplication 
rule:
P (Ai i П Ai 2 П...П Aik ) = P (Ai i) P (Ai 2) • •• P (Aik)■ 
(4.18)
The events in an infinite sequence A1, A2, ... are called independent if for every n, the first 
n events of the sequence are independent. 
□
Thus, in the case of n events, we have one condition for every subset of the size k > 2, that is, 
for k =1, condition (4.18) is satisfied. Since the number of all subsets ofa set with n elements 
is 2n, the number of conditions in (4.18) is 2n - n - 1.
In the case of three events, A, B, C, the definition (4.18) represents four conditions: 
P(A П B П C) = P(A)P(B)P(C), and three conditions for pairs, P(A П B) = P(A)P(B), 
P(A П C) = P(A)P(C), and P(B П C) = P(B)P(C). In case of four events A, B, C, and 
D, the multiplication rule (4.18) must hold for the quadruplet (A, B, C, D), for four triplets 
(A, B, C), (A, B, D), (A, C, D), and (B, C, D), and for six pairs (A, B), (A, C), (A, D), 
(B, C), (B, D), and (C, D).
The question arises: Do we really need so many conditions? Taking the simplest case 
of n =3 events, it might seem that independence of all three possible pairs, namely 
(A, B), (A, C), and (B, C), should imply the condition P(A П B П C) = P(A)P(B)P(C), 
a direct analogue of the defining condition for pairs of events.
Conversely, one might expect that the multiplication rule P (A П B П C) = 
P (A)P (B)P (C) implies independence of pairs (A, B), (A, C), and (B, C), as well as 
conditions of the kind P(A П Bc П Cc) = P(A)P(Bc)P(Cc), and so on. In fact, none of 
these implications is true, as will be shown by examples.

INDEPENDENCE
77
■ EXAMPLE 4.14
Independence in pairs does not imply the multiplication rule for more events. We will use 
the case of three events A, B, and C, and show that the condition P(A П B П C) = 
P (A)P (B)P (C) need not hold, even if all three pairs of events are independent.
Suppose that we toss a die twice and let A = “odd outcome on the first toss,” 
B = “odd outcome on the second toss,” and C = “sum odd.” We have P(A) = P(B) = 
P(C) = 1 /2. By simple counting, we obtain P(A П B) = P(A П C) = P(B П C) = 
1/4, so each of the possible pairs is independent. However, P(A)P(B)P(C) = 1/8, 
while P (A П B П C) = 0, since the events A, B, and C are mutually exclusive. If A and 
B hold, then the sum of outcomes must be even so that C does not occur.
■ EXAMPLE 4.15
Multiplication rule does not imply pairwise independence. We will now show that inde­
pendence in pairs is not implied by the condition
P (A П B П C )= P (A) P (B) P (C).
We take two events A and B that are dependent, and then take C with P(C) = 0. 
Let the sample space be S = {a, b, c, d, . . . }, and let A = {a, d},B = {b, d}, and 
C = {c, d}. Moreover, let P(a)=P(b)=P(c)=p - p3, and P(d)=p3, where 
p > 0 satisfies the inequality 3(p - p3) + p3 < 1. The remaining points (if any) have 
arbitrary probabilities, subject to the usual constrain that the sum of probabilities is 
1. We have here P(A) = P(B) = P(C) = (p — p3) + p3 = p; hence, P(A П B П C) = 
P(A)P(B)P(C) = p3. However, since A П B = A П C = B П C = A П B П C, we 
have P(A П B) = p3 while P(A)P(B) = p2, and similarly for other pairs.
The possibility of events being pairwise independent, but not totally (mutually) inde­
pendent, is mainly of theoretical interest. Unless explicitly stated otherwise, whenever we 
speak of independent events, we will always mean mutual independence in the sense of 
Definition 4.5.3.
Let us state here the following analogue of Theorem 4.5.1 for the case ofn events.
Theorem 4.5.3 If the events A1 ,A2 , ...,An are independent, the same is true for events 
A'1 ,A2, ..., An, where for each k the event A'k stands for either Ak or its complement Ack.
The following theorem provides one of the most commonly used “tricks of the trade” in 
probability theory:
Theorem 4.5.4 If the events A1 ,A2 , ...,An are independent, then
P(A 1 U-.-U An) = 1 — [1 — P(A 1)][1 — P(A2)] ••• [1 — P(An)].
Proof: The proof uses the fact that can be summarized as P(at least one) = 1 - P (none). 
By De Morgan’s law, (A 1 U A2 U - - - U An)c = Af П A2 П - - - Ant. Using Theorem 4.5.3, we 
write
1 — P (A 1 U---U An )= P (A1 П A2 П---П An) 
=P(Ac1)P(Ac2)---P(Acn) 
=[1—P(A1)][1—P(A2)]---[1—P(An)],
as was to be shown. 
□

78
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
■ EXAMPLE 4.16
Consider a sequence of independent experiments such that in each of them an event A 
(usually labeled “success”) may or not occur. Let P(A)=p for every experiment, and 
let Ak be the event “success at the kth trial.” Then A 1 U • • • U An is the event “at least 
one success in n trials,” and consequently
P (at least one success in n trials) = 1 - (1 - p)n .
At the end of this section, we will prove the theorem complementing Theorem 2.6.2.
Theorem 4.5.5 (Second Borel-Cantelli Lemma) If A 1, A2, ... is a sequence of independent 
events such thatff n=1 P(An) = ж, then
P (lim sup An)=1.
Proof: We have limsup An = p|n=1 JO0=n Ak = {infinitely many Ai’s will occur}. By De 
Morgan’s law, [limsup An]c = jn=1 p| 00= n Ak. Since the intersections p|k== n Ak increase 
with n, we have
(
oo \ 
N N \
Q Ak = lim lim P Q Ak .
k n o N -o 
k
k=n 
k=n
If Ak are independent, so are Ack. Then, using the inequality 1 - x < e-x, we obtain
(
n \
П Ack = lim [1 - P(An)]... [1 - P(An)]
N -o 
k=n
< lim e-[P(An)+■■'+P(AN)] = 0
N -o
in view of the assumption that the series 
P (An) diverges. Consequently,
P([limsupAn]c) = 0,
as was to be shown.
□
PROBLEMS
4.5.1 Label the following statements as true or false: (i) The target is to be hit at least once. 
In three independent shots at the target (instead of one shot), you triple the chances 
of attaining the goal (assume each shot has the same positive chance of hitting the 
target). (ii) IfA and B are independent, then P(Ac|Bc) = 1 - P (A). (iii) IfA and B 
are independent, then they must be disjoint. (iv) IfA and B are independent, P(A) = 
P(B),andP(AUB)=1/2,thenP(A) > 1/4.
4.5.2 Let A and B be independent events. Find P(A П B) if: (i) P(A П Bc) = 1 /3 and 
P(Ac П B) = 1 /6. (ii) P(A) = kP(B), and either A or B must occur.
4.5.3 A die is tossed three times, with outcomes X1, X2, and X3. Assuming that all 
216 possible outcomes (x1, x2, x3) are equally likely, find following probabilities: 
(i) P(X1 >X2 = X3). (ii) P(X1 <X2 < X3). (iii) P[max(X1,X2,X3) = 4].
(iv) P[min(X1,X2,X3) = 3].

INDEPENDENCE
79
4.5.4 Events A and B are independent, A and C are mutually exclusive, and B and C are 
independent. Find P(A U B U C) if P(A) = 0.5,P(B) = 0.25, and P(C) = 0.125.
4.5.5 If disjoint events A and B have positive probabilities, check independence of events 
in the following pairs: 0 and A, A and B, A and 5, A and A n B, 0 and Ac.
4.5.6 Let X be the number on the chip randomly selected from a box containing 12 chips, 
labeled 1 through 12. Check pairwise independence of events A, B, and C, defined as 
X is even, X > 7, and X < 4, respectively.
4.5.7 The probability that a certain event A occurs at least once in three independent tri­
als exceeds the probability that A occurs twice in two independent trials. Find the 
possible values of P (A).
4.5.8 Suppose that a point is picked at random from the unit square 0 < x < 1, 0 < y < 1. 
Let A be the event that it falls in the triangle bounded by the lines y =0,x=1, 
and x = y , and let B be the event that it falls into the rectangle with ver­
tices (0, 0), (1, 0), (1, 1/2), and (0, 1/2). Find all statements that are true: (i) 
P(A) = P(B). (ii) P(A n B) = 3/8. (iii) P(A U B) = P(A n B). (iv) A and B are 
independent. (v) P(A|B) = 1/8.
4.5.9 Events A and B are such that 3P(A) = P(B) = p, where 0 <p<1. Find the correct 
answers in parts (i) and (ii). (i) The relation P(B|A) = 3P(A|B) is (a) True. (b) True 
only if A and B are disjoint. (c) True only if A and B are independent. (d) False. 
(ii) The relation P(A n Bc) < min(p/3, 1 - p) is (a) True. (b) False.
4.5.10 A coin is tossed six times. Find the probability that the number of heads in the first 
three trials is the same as the number of heads in the last three trials.
4.5.11 Two people take turns rolling a die. Peter rolls first, then Paul, then Peter again, and 
so on. The winner is the first to roll a six. What is the probability that Peter wins?
4.5.12 A coin with probability p of turning up heads is tossed until it comes up tails. Let 
X be the number of tosses required. You bet that X will be odd, and your opponent 
bets that X will be even. For what p is the bet advantageous to you? Is there a p such 
that the bet is fair?
4.5.13 Find the probability that in repeated tossing of a pair of dice, a sum of 7 will occur 
before a sum of 8.
4.5.14 Three people, A, B, and C, take turns rolling a die. The first one to roll 5 or 6 wins, 
and the game is ended. Find the probability that A will win.
4.5.15 Consider a die in which the probability of a face is proportional to the number of 
dots on this face. What is the probability that in six independent throws of this die 
each face appears exactly once?
4.5.16 A machine has three independent components, two that fail with probability p and 
one that fails with probability 0.5. The machine operates as long as at least two parts 
work. Find the probability that the machine will fail.
4.5.17 The French mathematician Jean D’Alembert claimed that in tossing a coin twice, we 
have only three possible outcomes: “two heads,” “one head,” and “no heads.” This 
is a legitimate sample space, of course. However, D’Alembert also claimed that each 
outcome in this space has the same probability 1/3. (i) Is it possible to have a coin 
biased in such away so as to make D’Alembert’s claim true? (ii) Is it possible to make 
two coins with different probabilities of heads to confirm D’Alembert’s claim?

80
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
4.5.18 Is it possible to bias a die in such a way that in tossing the die twice, each sum
2, 3, ...,12 has the same probability?
4.6 EXCHANGEABILITY; CONDITIONAL INDEPENDENCE
We will now introduce an important type of dependence of events.
Definition 4.6.1 Let A, B, and H be three events, and let P (H) > 0. We say that events A 
and B are conditionally independent given H ,if
P(A П BIH)= P(AH)P(BIH). 
□
Definition 4.6.2 Let H = {H1, H2, ...} be a positive partition (finite or countably infinite). 
We say that events A and B are conditionally independent given H,ifA and B are condition­
ally independent given any set Hi in partition H. 
□
■ EXAMPLE 4.17
In order to understand why events that are conditionally independent with respect to 
every set of the partition may be dependent, consider the following simple situation: 
Let the partition consist of two events, H and Hc, with P(H) = 0.6. Suppose that if 
H occurs, then both A and B are likely, say P(AIH) = 0.8,P(BIH) = 0.9, and condi­
tional independence requires that P(A П BIH) = 0.8 x 0.9 = 0.72. On the other hand, 
if Hc occurs, then both A and B are rather unlikely, say P(AIHc) = P(BIHc) = 0.1. 
Again, conditional independence requires that P(A П BIHc) = (0.1)2 = 0.01
It is easy to check that the events A and B are dependent. Indeed, P(A) = 
P(AIH)P(H)+P(AIHc)P(Hc) = 0.8 x 0.6 + 0.1 x 0.4=0.52,P(B)=P(BIH) 
P(H) + P(BIHc)P(Hc) = 0.9 x 0.6 + 0.1 x 0.4 = 0.58. On the other hand, 
P(A П B) = P(A П BIH)P(H) + P(A П BIHc)P(Hc) = 0.72 x 0.6 + 0.01 x 0.4 = 
0.436, which is not equal to P(A)P(B) = 0.3016.
What is happening here is that the occurrence or nonoccurrence of one of the events 
allows us to make rather reliable predictions about the other event. In the case under 
considerations, the events A and B are positively correlated: If one occurs, the other is 
likely to occur also, and vice versa. By Definition 4.5.2 we have
r(A, B)=
0.436 - 0.3016
V0.52 x 0.48 x 0.58 x 0.42 = 0.545.
The nature of dependence that we have here might better be visualized by a real-life 
situation. Imagine some animals, such as birds, that raise their young every year. If the 
conditions in a given year are hard (a draught, severe winter, etc.), often all the young 
die, and typically very few survive. If the conditions are favorable, the number of young 
that make it to next year is typically higher. The fates of different families in any given 
year are independent, in the sense that survival of offspring in one family does not 
depend on the survival of offspring in the other. If A and B are events occurring in 
two different families, and Hi ’s are events describing possible types of conditions in 
any given year, then A and B are conditionally independent with respect to any given 
events Hi .
Unconditionally, however, events A and B are dependent, the dependence arising 
from the fact that all families are subject to the same conditions. Thus, if one family

EXCHANGEABILITY; CONDITIONAL INDEPENDENCE
81
fares badly, then we can expect that others will also, simply because the conditions are 
likely to be hard for them all.
The definition of conditional independence given an event, and therefore also definition 
of conditional independence given a partition, extends naturally to the case of n events. The 
extension consists of first defining the conditional independence of events A1 ,A2 , ...,An 
given an event Hi . We will not give the definition here. It is a repetition of Definition 4.5.3, 
the only difference being that the unconditional probabilities in formula (4.18) are replaced 
by conditional probabilities given Hi . Definition 4.6.2 remains unchanged.
Now let A1 ,A2, ...,An be a set of events, and let N = {1, 2, ...n} be the set of their 
indices. We introduce the following definition:
Definition 4.6.3 The events A1 ,A2, ...,An are called exchangeable if for any subset K of 
{1, 2, ...,n} the probability
P In Ain n Aj)
\ieK 
j(/K 
1
of joint occurrence of all events with indices in K and nonoccurrence of all events with 
indices not in K depends only on the size of the set K. 
□
This means that for exchangeable events, the probability of occurrence of exactly m of 
the events does not depend on which events are to occur and which are not. For instance, 
in the case of three events A, B, and C, their exchangeability means that P(A n Bc n Cc) = 
P(Ac n B n Cc) = P(Ac n Bc n C) and also P(A n B n Cc) = P(A n Bc n C) = P(Ac n 
B n C).
We have the following theorem:
Theorem 4.6.1 If the events A1, A2, ...,An are conditionally independent given a partition 
H = {H1, H2, ...}, and P(Ai|Hk) = P(Aj|Hk) for all i,j, k, then they are exchangeable.
Proof:LetP(Ai|Hk)=wk (by assumption, this probability does not depend on i). The 
probability that, say, the first r events will occur and the remaining ones will not (by the law 
of total probability and conditional independence) is
P (A 1 n A 2 n • • • Ar n Ar+1 n • •• n An)
= £P(A 1 nA2 n-nAr nAr+1 n...nAniHk)P(Hk) 
k
= wr (1 - Wk)n-rP(Hk). 
(4.19)
k
Clearly, (4.19) is also the probability of occurrence of any r among the events A1, ...,An 
and nonoccurrence of the remaining ones. 
□
As can be expected, in case of conditional independence of A and A'' with respect to the 
partition H, Theorem 4.4.2 on updating the evidence will take a simpler form. We have
Theorem 4.6.2 Let H = {H 1, H2, ... } be a partition and let A', A” be two events conditionally 
independent with respect to H. If P (A' n A”) > 0, then for every event Hk in partition H we

82
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
have
P(H A n A,) _ P(A\Hk)P(A"\Hk)P(Hk)
( k \ 
) 
EjP(A\Hj)P(A"\Hj)P(Hj)
= P (A"\Hk) P (Hk\A)
E3P(A'H)P(Hj\A). 
(. )
Proof : The middle part shows how the conditional probability of Hk is computed if the 
“evidence” A n A' is taken jointly. The last part shows how the updating is done succes­
sively, if first one updates probabilities using A and then one uses A' for further modification 
of posterior probabilities.
For the first equation, observe that the middle part of (4.20) is just the middle part of 
(4.14) in the case of conditional independence.
To prove the second equation, observe that the factor P(A"\Hk n A) in the right-hand 
side of (4.14) can be written as
P(A'H n A) = P (A n A" n Hk) 
P (A П Hk)
P(A n A'H)P(Hk) 
P (A\Hk) P (Hk)
P (A'\Hk) P (A"\Hk) 
P (A'\Hk)
= P (A"\Hk).
□
PROBLEMS
4.6.1 A subset S of size t, 1 < t < N, is selected at random from the set {1, ..., N} and event 
Ai, i =1, ...,n, is defined as “Element i was among the elements selected.” If S = 
{i1, ...,it} is chosen, we say that events Ai1 , ...,Ait occur, while the remaining events 
do not. (i) Show that events A1, ...,AN are exchangeable. (ii) Find the correlation 
coefficient r = r(Ai,Aj),i= j between two events. Give an intuitive explanation why 
r<0.
4.6.2 Generalizing the scheme of Problem 4.6.1, let pt be the probability of choosing size t for 
subset St C {1, ..., N}, 1 < t < N. After choosing t, subset St is selected at random, 
and all events with indices in St occur while other events do not. (i) Argue that events 
A 1, ..., AN are exchangeable. (ii) Find probabilities P(AC) and P(A 1 n A2).
4.7 MARKOV CHAINS*
With the material introduced so far it is already possible to develop an extensive and powerful 
theory with numerous practical applications and cognitive consequences, namely the theory 
of Markov chains. While the theory of statistical processes and Markov chains, in particular, 
is beyond the scope of this book, it has numerous practical applications and therefore we 
will introduce the basic concepts here.
Generally, the term chain will denote a sequence of events, typically dependent one on 
another in some way. It will be convenient to use the terminology referring to time: we can 
think of events as occurring one after another so that the event whose occurrence is actually 
observed is the “present” event, while the events following it belong to the “future” and the 
remaining ones to the “past.” This way we obtain a description of a process of dynamic 
changes (of something that we generally call a system). Quite naturally the main problem 

MARKOV CHAINS*
83
will be to develop tools for making some inference (prediction, etc.) of the future on the 
basis of the knowledge of the past.
Specifically, consider a system that evolves in a random manner. The observations are 
taken at some fixed times 10 <t 1 <t2 < • • •, so in effect we record a sequence of states at 
which we find the system at the times of the observations. Without loss of generality, we let 
tn = n so that the observations are taken every unit of time starting at t0 =0.
The notions of “system” and “state” in the description above are left unspecified in order 
to have flexibility in applying the theory to various situations. Before proceeding any further, 
let us consider some examples that will later guide our intuition.
■ EXAMPLE 4.18
Imagine a gambler who plays a sequence of games. In each game, she may win or 
lose some amount of money. Let wn denote her net winnings in nth game (loss, if 
wn is negative). If we are interested only in the financial aspects of the situation, we 
can regard the gambler as a “system,” with the state of the system identified with the 
gambler’s fortune. Thus, the state in this case is a number. Letting s(n) be the state at 
the time immediately after nth game, and letting s(0) be the initial fortune, we have 
s (n) = s (0) + w 1 + w 2 + • • • + wn.
This scheme has to be made specific by adding appropriate assumptions. First, 
we need assumptions about the nature of the winnings wk . In the simplest case, the 
gambler may play for the same fixed amount, say $1, so that s(n) either increases or 
decreases by 1 with each game, and the outcomes of consecutive games are indepen­
dent. Another kind of assumption is that of “boundary” conditions, which specify 
what happens when the gambler becomes ruined, that is, when s(n) reaches the value 
0. For example, the game may end, with s(n) remaining 0 forever, or it may continue 
from the state s(n)=1if the gambler borrows a dollar to continue playing, and so 
forth.
Such an evolving scheme is often called a “random walk” because one can interpret 
the state s(n) as a position of a pawn that moves randomly along the x-axis, being 
shifted at the nth move by the amount wn .
The interesting question is: What is the probability that after the nth move at time t, 
the distance s(n) - s(0) from the initial location will satisfy the inequality a<s(n) - 
s(0) <b? We will return to this problem in later chapters (especially Chapter 9) as we 
develop tools for analyzing the properties of random sums of the form w 1 + • • • + wn, 
representing total displacement after n hits.
■ EXAMPLE 4.19
Consider now the evolution of an epidemic. Imagine a group of subjects, of whom some 
may be infected with the disease and therefore capable of spreading it to others (even 
though they may not yet be aware of being infectious), and some other persons may be 
susceptible. The spread of the disease is generated by the process of contact whereby 
proximity between an infective and a susceptible subject can lead to an infection. The 
state of the system can be described by a pair of numbers s(n) = [x(n),y(n)], where 
x(n) is the number of infectives at time t = n, and y(n) is the number of susceptibles 
at time t = n.
By taking a sufficiently small time between observations, one can assume that the 
only possible changes from [x(n), y(n)] to [x(n + 1), y(n + 1)] are as follows:
1. x(n +1) =x(n)+k, y(n +1) = y(n) - k (infection of a group of k susceptibles, 
k =1,2, ...).

84
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
2. x(n +1)=x(n) - 1, y(n +1)=y(n) (“removal” of an infective, which may corre­
spond to death, isolation in the hospital, recovery with immunity, etc.).
3. “Status quo,” that is, x(n +1)=x(n),y(n +1)=y(n).
The probabilities of these three types of transitions depend on the nature of the contact 
process and the mode of transmission of the given disease (in particular, the process 
simplifies somewhat if we assume that k is always 1). By specifying these probabilities, 
one may obtain models of spread of various infectious diseases.
Examples 4.18 and 4.19 show that the notions of the system and state are rather flexible 
and can be interpreted in a number of ways. Basically, system here means any fragment of 
reality that we want to model and analyze, while state is the information about the system 
that is relevant for the purpose of the study.
In this chapter, we will regard time as discrete. In general theory, one also considers sys­
tems evolving in continuous time, when changes can occur and be observed at any time. The 
theory designed to describe and analyze randomly evolving systems is called the theory of 
stochastic processes. While such a theory lies beyond the scope of the present book, we will 
occasionally introduce some elements of it.
It ought to be clear from the Examples 4.18 and 4.19 that a sample space that may be 
useful for describing the evolution of a system consists of all possible sequences of states 
at the observation times. Each such sequence represents a possible history of the process. 
Formally, let E be the set of all possible states of the system, with elements of E denoted by 
letter e, possibly with identifying subscripts or superscripts, such as e 1, e'. The sample space 
SN, which will represent the history of the system at times t =0, 1, ...,N, will consist of all 
possible sequences sN = [s(0), ..., s(N)], where s(i) is the element ofE describing the state 
of the system at time t = i.
We will assume that the set E is either finite or countably infinite. We may then label the 
states by integers so that E = {e1, e2, ...,en} or E = {e1, e2, ...}. Under this assumption 
each of the sample spaces SN is also either finite or countably infinite, and we will define 
the probabilities on individual sample points of SN by explicit formulas. At the same time, 
however, we will consider certain limiting passages, with the lengths of the sequences of states 
increasing to infinity. The space of all infinite sequences of states in E is uncountable whether 
or not E is finite. The details of the construction of probability of such spaces (although 
sketched in Chapter 2) lie beyond the scope of this book. However, we will use simple limiting 
passages with the lengths of sequences increasing to infinity, basically treating each space SN 
as a space of all beginnings of length N of infinite sequences.
The main types of events that we will consider are of the form “state e at time t = n”. In 
Chapter 1, events were identified with subsets of the sample space. Accordingly, the event 
above can be defined as
“state e at time t = n” = {s(n) = e}
= set of all sequences [ s(0), ...,s(N)] 
with s(n) equal e.
Typically, the probability of the next state depends in some way on the preceding states. 
So by the chain formula (4.5), for all n < N, we have
P [s(0) = ei0,s(1) = ei1, ...,s(n)=ein]=P[s(0) = ei0]
xP [ s (1) = ei i |s (0) = ei о ] x ••• x P [ s (n) = ein |s (n - 1) = ein-1, ...,s(0) = ei о ].
(4.21)

MARKOV CHAINS*
85
The commas in formula (4.21) signify the operation ofan intersection of events, thus replac­
ing a rather clumsy notation P[s(0) = eio П s(1) = e^ П • • • П s(n) = ein]. For convenience, 
the events in the conditions are written in the order that starts from the most recent one.
Formula (4.21) expresses the probability of a sequence of consecutive states through the 
probability of the “initial” state s(0), and conditional probabilities involving all preceding 
states, and thus encompasses longer and longer fragments of the past. By the definition 
below, such conditional probabilities for Markov chains can be simplified by reaching only 
to the most recent state.
Definition 4.7.1 The evolution of a system is said to form a Markov chain if for every n and 
every vector (ei ,ei , ...,ei - ,ei ) of states, the conditional probabilities satisfy the fol­
lowing relation, called the Markov property:
P[s(n) = ein|s(n - 1) = ein-1,s(n - 2) = ein-2,...,s(0) = ei0]
= P[s(n) = ein|s(n - 1) = ein-1]. 
(4.22)
□
We have therefore the next theorem.
Theorem 4.7.1 If the sequence of transitions between states constitutes a Markov chain, then
P [s(0) = ei0, ...,s(n)=ein]
n
= P[s(0) = ei0] 
P[s(j) = eij|s(j - 1) = eij-1]. 
(4.23)
j=1
Generally, the transition probability P[s(j) = ei |s(j - 1) = ei - ] from state ei - to 
state eij at time t = j depends on j . If this is not the case, the situation can be greatly sim­
plified, and this special case is the starting point of a theory. This theory is practically and 
cognitively useful, leads to rather deep mathematical results and fruitful generalizations, and 
is pleasantly elegant as well. Accordingly, we introduce the following definition:
Definition 4.7.2 A Markov chain will be said to have stationary transition probabilities, or be 
time homogeneous, if for all states ei ,ej the probability
P[s(t) = ej|s(t - 1) = ei]
does not depend on t. 
□
From now on, all Markov chains under consideration in this chapter will have stationary 
transition probabilities. Writing pij = P[s(t) = ej |s(t - 1) = ei] and ri = P [s(0) = ei], we 
may recast (4.23) as
P [s(0) = ei0,s(1) = ei1,...,s(n)=ein]=ri0pi0i1 ...pin-1in.
Clearly, {ri,i=1, 2, ...}, called the initial probability distribution, and the set of probabili­
ties pij , called the transition probability matrix, must satisfy the following conditions:
E r'i = 1 
(4.24)
i

86
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
and
pij =1 for every i. 
(4.25)
j
The last condition means simply that if the system is in some state ei , it must pass to one of 
the states ej (possibly remaining in the same state ei) in the next step.
Since square matrices (finite or not) with nonnegative entries and row sums equal to 1 are 
called stochastic matrices, we see—in view of (4.25)—that every transition probability matrix 
of a Markov chain is a stochastic matrix.
■ EXAMPLE 4.20 Gambler’s Ruin
Continuing Example 4.18 about the gambler, assume that each game is played for 
a unit stake, with the gambler’s probability of winning a game being p. Moreover, 
assume that the games are independent. In such a case, the sequence s(0), s(1), ... 
of the gambler’s fortunes after consecutive games is a Markov chain. Indeed, letting 
P [s(n +1)=j|s(n)=i]=pij,wehaveforallk>0,
pk,k+1 = p, pk,k-1 =1- p,
and pkj =0for all j other than k +1 or k - 1. These probabilities do not depend on 
the history s(n - 1), s(n - 2), ... preceding the nth game. The transition probabilities 
for k = 0 depend on the assumption about what happens when the gambler becomes 
ruined. For instance, if upon reaching k =0 the game stops, we can put p0j equal 
to 1 for j =0 and equal to 0 for all other j . If the process starts with the gambler 
having initial capital M , then rj equals 1 for j = M and equals 0 for all other j .It 
seems plausible (and in fact it is true) that if p<1/2 (the games are unfavorable for 
the gambler), then regardless of the initial state, the state 0 (gambler’s ruin) will sooner 
or later be reached. Less obvious, but still true, is that the same holds for the fair games 
(p = 1/2) no matter what the initial fortune is. An interesting question is to determine 
the probability of the gambler ever reaching 0 (i.e., of becoming eventually ruined) if 
she plays favorable games, that is, if p>1/2. This probability depends on the initial 
state M, and may be shown to be [(1 - p)/p]M .
The following examples illustrate the problem of absorbtion.
■ EXAMPLE 4.21 Division of Stake in Gambler’s Ruin
Two players, A and B, play a sequence of games, each game for a unit stake, 
until one of them loses all his or her money. Games are independent; in each of 
the probability of A winning is p (and the probability of A losing is 1 - p, which 
means that there are no ties). For some reason, the contest is interrupted (and is 
not going to be resumed) when A has x dollars and B has M - x dollars (so that 
the total stake is M). The question is: How can the stake M be divided between 
the players in a fair way? One of the ways (arguably just) is to divide the stake in 
proportion to the chances of eventually winning the contest if it was to continue. 
Consequently, the problem lies in determining the probabilities of eventually winning 
the contest for each of the two players. We can interpret the situation in terms of 
the gambler’s problem as follows: Let i =0, 1, ...,M represent the state of the 
system, defined as the capital of A. Then the changes of states constitute a Markov 
chain, as in Example 4.20, the only difference being that now p00 = pMM =1 
(i.e., one cannot leave states 0 and M). The objective is to determine u(x), equal 
to the probability of A ultimately winning the contest if the starting state is x.

MARKOV CHAINS*
87
To see the technique, observe that for 0 <x<Mthe probabilities u(x) must satisfy 
the equations
u(x) = pu(x +1)+(1- p)u(x - 1), 
(4.26)
with boundary conditions u(0) = 0,u(M) = 1. Actually, (4.26) is a special case of the 
total probability formula (4.9) for the event “ultimate winning by A” and the partition 
into the two events “next game won by A” and “next game lost by A.” This technique 
of using the partition obtained by considering the possible results of the next transition 
will be used again and again in the analysis of Markov chains. In the present case, a 
linear combination of solutions of (4.26) is also a solution of (4.26). Consequently, 
we need two linearly independent solutions to determine the constants in their linear 
combinations using the two boundary conditions.
Obviously, u(x)=1 is always a solution of (4.26). To find another solution, 
let u(x) = sx . This gives s = ps2 + q, where we let q =1- p. The solutions 
of the quadratic equation are [1 ± (1 - 4pq)1/2]/2p =[1±|p - q|]/2p, which 
equal 1 and q/p. Thus, if p = q (hence, p = 1/2), a general solution of (4.26) is 
u(x)=A + B(q/p)x. Using the boundary conditions, we obtain
u(x) = (q/p) x - 1
(q/p) M - 1 ■
If p = q = 1/2, the solutions u(x) = (q/p)x and u(x) = 1 coincide. In this case as 
another (linearly independent) solution, we can take u(x) = x, and the general solu­
tion of (4.26) will be u(x)=A + Bx. Using again the boundary conditions, we obtain 
u(x) = x/M as the probability of winning in the case of fair games.
■ EXAMPLE 4.22
Let us now return to Example 4.19 of an epidemic. The state of the system is repre­
sented by a pair of integers (x, y), with x being the number of infectives and y being 
the number of susceptibles. As was argued, by taking sufficiently small time intervals 
between transitions, we can assume that apart from remaining in the same state, the 
only possible transitions from (x, y) are to (x - 1, y), representing removal (death, 
isolation, recovery with immunity, etc.) of one infective, and to (x +1,y- 1), rep­
resenting infection of one susceptible. These transitions are depicted in Figure 4.2 as
y-susceptibles
A
x-infectives
Figure 4.2 Transitions in model of epidemic. 

88
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
a random walk over the integer lattice on the plane, with the two types of transitions 
being steps in the western and southeastern directions. We now have to define the tran­
sition probabilities for the two kinds of transitions above (removal and infection) so as 
to obtain a meaningful approximation to the real conditions of an epidemic. Here one 
could argue that it is reasonable to assume that the probability of the first transition 
(removal) is proportional to x, while the probability of the second transition (infection) 
is proportional to both x and y . Thus, the transition probabilities between states will 
be of the form
p[(x - 1, y)|(x, y)] = ax, p[(x +1,y- 1)|(x, y)] = bxy
for suitably chosen a and b.
The nonlinear term (proportional to the product xy) is largely responsible for the 
fact that the analysis of an epidemic process is extremely difficult. From the point of 
view of applications, two characteristics of epidemics are of major interest: first, the 
time until the termination of the epidemic, and second, its total size, that is, the total 
number of persons who will become infected (and subsequently removed).
The first characteristic may be defined formally as
N =firstn such that x(n) = 0.
Here the event N = k corresponds to x(0) > 0, x(1) > 0, ...,x(k - 1) > 0, and 
x(k) = 0. Graphically, N is the first time when the walk depicted in Figure 4.2 reaches 
the vertical axis.
The second characteristic cannot be expressed in terms of the variables introduced 
thus far. The handling of the case is an illustration of the point made repeatedly in 
Chapter 1 about the nonuniqueness of the choice of the sample space. One could sim­
ply enrich the state space by including another count that keeps track of the removals. 
Thus, one could consider the states as being described by three variables, x(n), y(n), 
and z(n), where x and y are the numbers of infectives and susceptibles as before, while 
z is the number of removals. The two kinds of transitions considered so far are replaced 
by transitions from (x, y, z) to (x - 1,y,z+1), representing the removal of an infec­
tive, and from (x, y, z) to (x +1,y- 1, z), representing anew infection. Assuming that 
the epidemic starts with z =0, the total size Z of epidemic is defined as Z = z(N), 
where N = the first n with x(n) = 0.
As mentioned above, finding the probabilities P {N = n} and P {Z = k} for given 
initial conditions of the Markov chain is extremely difficult, and we will not deal with 
this problem here.
We will now find the probability
pi(jn) = P{s(t + n) = ej|s(t) = ei} 
(4.27)
of passing from ei at time t to ej at time t + n, called the n-step transition probability. Obvi­
ously, for Markov chains with stationary transition probabilities, the quantity (4.27) does 
not depend on t. We have the following theorem:
Theorem 4.7.2 The n-step transition probabilities satisfy the relations
pi(j0) =1or 0, depending whether or not j = i, 
(4.28)
and for all m,n > 0
pi(jm+n) = 
pi(km)p(knj) . 
(4.29)
k

MARKOV CHAINS*
89
Proof : We proceed by induction. Formula (4.28) covers the case m = n =0. In zero steps 
the system cannot change, so it must remain, with probability 1, in state ei. We prove formula 
(4.29) for n =1. If the system passes from ei to ej in m + 1 steps, then in step m it must be in 
some state ek . The events “state ek after m steps” form a partition, and the total probability 
(m+) 
(m) 
()
ormua (.) g ves n ts case pij 
= 
kpik pkj , as was to e sown, snce pij = pij 
y
definition. The extension to the case of arbitrary n is immediate. 
□
In matrix notation, Theorem 4.7.2 states simply that P(m+n) = Pm+n, with P0 = I, the 
identity matrix.
One can expect that as the number of transitions increases, the system “forgets” the initial 
state; that is, the effect of the initial state on the probability of a state at time n gradually 
wears out. Formally, we can expect that the probabilities pi(jn) converge, as n increases, to 
some limits independent of the starting state ei . Let us consider the following example.
■ EXAMPLE 4.23
The weather on Markov Island is governed by the following laws. There are only three 
types of days: sunny, rainy, and cloudy, with the weather on a given day depending only 
on the weather on the preceding day. There are never two rainy days in row, and after a 
rainy day, a cloudy day is twice as likely as a sunny day. Fifty percent of days following 
a cloudy day are also cloudy, while 25% are rainy. Finally, after a sunny day, each type 
of weather is equally likely. How often, on average, is it cloudy on Markov Island?
SOLUTION. The fact that the tomorrow’s weather depends only on the weather today
makes the process of the weather change a Markov process. Using the obvious notation 
R, S, and C for the three types of weather, we have pRR =0, pRC = 2/3, pRS = 1/3, 
pCC =1/2,andpCR=pCS = 1/4. Finally, pSS =pSC =pSR = 1/3, so the transition
matrix is
P=
1
4
1
3
2 
11
3 
3
1 
1
2 
4
1 
1
3 
3-1
(4.30)
0
Let us assume that the limits of the n-step transition probabilities exist and do not 
depend on the starting state. Thus, we have three limits, uR, uS , and uC, where
nnn 
uR = lim pRR = lim pCR = lim pSR,
and similarly for uS and uC. We can then write, using (4.29) for n =1,
(m+1) 
(m) 
(m) 
(m)
pRR 
=pRRpRR+pRCpCR+pRSpSR,
(m+1) 
(m) 
(m) 
(m)
pCC 
= pCRpRC +pCCpCC+pCSpSC, 
(4.31)
(m+1) 
(m) 
(m) 
(m)
pSS 
= pSR pRS + pSC pCS + pSS pSS.
Passing to the limit in (4.31), we obtain therefore a system of three linear equations:
uR = uRpRR + uC pCR + uSpSR 
uC = uRpRC + uC pCC + uSpSC 
uS = uRpRS + uC pCS + uSpSS.

90
CONDITIONAL PROBABILITY, INDEPENDENCE, AND MARKOV CHAINS
Using the probabilities from the matrix (4.30), we obtain
-uR + uC + uS = 0 
2uR - uC + uS =0 
uR + uC - 2uS =0
(4.32)
This is a homogeneous system, so an additional equation is needed to determine the 
solution. We have here the identity
(n) 
(n) 
(n)
pRR + pRC + pRS =1, 
(4.33)
and passing to the limit with n, we get
uR + uC + uS =1.
(4.34)
The solution of (4.32) and (4.34) is uR = 9/41, uC = 20/41, and uS = 12/41, which 
means that almost 50% of days on Markov Island are cloudy.
The equations of this example are derived under the assumption that (1) the limits pi(jn) 
exist and are independent of the starting state i, and (2) the number of states is finite. The 
latter assumption allowed us to pass to the limit in the sums in (4.31) and (4.33), obtaining 
(4.32) and (4.34). The first assumption here is true under some conditions. Basically, we have 
to exclude two obvious cases when the probabilities pi(jn) either cannot converge, or if they 
do, the limits depend on the starting state i.
■ EXAMPLE 4.24
Consider a Markov chain with two states, e1 and e2 , such that p12 = p21 =1(so that 
p11 = p22 =0). Clearly, the system must alternate between states 1 and 2 in a deter­
ministic way. Consequently, p(1n1) =0or 1, depending whether n is even or odd, and 
the sequence p(1n1) does not converge.
■ EXAMPLE 4.25
Consider again a Markov chain with two states e1 and e2 . Assume now that the tran­
sition probabilities are p11 = p22 =1(so that p12 = p21 =0). In this case, the system 
must forever remain in the initial state, with p(1n1) =1and p(2n1) =0for all n. The limits 
pi(jn) exist but depend on the initial state i.
These two examples, in essence, exhaust all possibilities that may prevent the existence 
of the limits pi(jn) and their independence of the initial state i. One may summarize them as 
periodicity (in Example 4.24), and the impossibility of reaching a certain state from some other 
state or states (in Example 4.25).
PROBLEMS
4.7.1 Customers arrive at a service station (a taxi stand, a cable car lift at a skiing resort, 
etc.) and form a queue. At times t = 1,2, ... the first m customers (m > 1) in the 
queue are served (if there are that many). Let Y1 ,Y2 , ... denote the numbers of 
customers arriving during the time intervals between services, and let Xn denote the

MARKOV CHAINS*
91
number of customers in the system at the time immediately preceding the nth service. 
Argue that Xn+1 =(Xn - m)+ + Yn, where U+ = max(U, 0). Assuming that 
the events {Yn = k1}, ...,{Yn = kj} are independent for any j, k1, ...,kj and 
any distinct n1 , ...,nj , and that probabilities P {Yn = k} = pk , are independent of 
n, find P (Xn+1 = j|Xn = i) for all possible i, j =0, 1, 2, .....
4.7.2 After some time spent in a bar, Peter starts to walk home. Suppose that the streets 
form a rectangular grid. Peter always walks to the nearest corner and then decides 
on the direction of the next segment of his walk (so that he never changes direction 
in the middle of the block). Define the “state of the system” in such a way as to 
accommodate conveniently the assumption that Peter never goes directly back to the 
corner he just left.
4.7.3 (i) Modify Example 4.20 by assuming that in each game, the player may win with 
probability p, lose with probability q, or draw (so that his fortune does not change) 
with probability r, where p + q + r =1. Find the transition probability matrix in this 
case. (ii) Modify Example 4.21 same way as in (i). Write the analogue to the equation 
(4.26) for the probability of ruin and solve it.
4.7.4 Suppose the results of an election in a certain city are found to depend only on the 
results of the last two elections. Specifically, letting R and D denote Republican and 
Democratic victories, the state before any election may be RR, RD, DR, DD, the 
letters signifying, respectively, the outcomes of the next-to-last and last elections. 
Generally, assume that a, b, c,andd are the probabilities of a Republican victory 
in each of the four states listed above. Find the transition probability matrix of the 
resulting Markov chain.
4.7.5 A college professor teaches a certain course year after year. He has three favorite 
questions, and he always uses one of them in the final exam. He never uses the same 
question twice in a row. If he uses question A in one year, then the next year, he tosses 
a coin to choose between question B and C. If he uses question B, he tosses a pair 
of coins, and chooses question A if both coins show tails. Finally, if he uses question 
C, then he tosses three coins and uses question A if all of them show heads. Find the 
transition probability matrix for the resulting Markov chain.
4.7.6 (Dog Fleas, or the Ehrenfest Model of Diffusion) Consider two urns (or dogs), and N 
balls (or fleas), labeled 1, ...,N, allocated between the urns. At times t =1, 2, ..., 
a number 1 through N is chosen at random, and the ball with the selected number 
is moved to the other urn. Let s(n) be the number of balls in the first urn at time n. 
Find the transition probability matrix for the Markov chain s(n).
4.7.7 Consider a specific kind of part needed for the operation of a certain machine (e.g., 
the water pump of a car). When the part breaks down, it is replaced by a new one. 
The probability that a new part will last for exactly n days is rn ,n =1, 2, .......Letthe
state of the system be defined as the age of the part currently in the machine. Find 
the transition probability matrix of the resulting chain.
4.7.8 Find all two-step transition probabilities for: (i) The Markov chain described in Prob­
lem 4.7.4. (ii) The dog flea model of Problem 4.7.6.
4.7.9 Assume that a man’s occupation can be classified as professional, skilled laborer, or 
unskilled laborer. Assume that of the sons of professional men, a percent are pro­
fessional, the rest being equally likely to be skilled laborers or unskilled laborers. 
In the case of sons of skilled laborers, b percent are skilled laborers, the rest being 
equally likely to be professional men or unskilled laborers. Finally, in the case of

92 conditional probability, independence, and markov chains
unskilled laborers, c percent of the sons are unskilled laborers, the rest again divided 
evenly between the other two categories. Assume that every man has one son. Form 
a Markov chain by following a given family through several generations. Set up the 
matrix of transition probabilities, and find: (i) The probability that the grandson of 
an unskilled laborer is a professional man. (ii) The probability that a grandson of a 
professional man is an unskilled laborer.
4.7.10 In Problem 4.7.9, it was assumed that every man had one son. Assume now that the 
probability that a man has a son is r . Define a Markov chain with four states, where 
the first three states are as in Problem 4.7.9, and the fourth state is entered when a 
man has no son. This state cannot be left (it corresponds to a male line of the family 
dying out). Find the probability that an unskilled laborer has a grandson who is a 
professional man.

CHAPTER 5
RANDOM VARIABLES: UNIVARIATE CASE
5.1 INTRODUCTION
In the first four chapters, we introduced the concept of sample space, identified events with 
subsets of this space, and developed some techniques of evaluating probabilities of events.
Random variables, each defined as numerical function on some sample space S , will ini­
tially be regarded merely as useful tools for describing events. Then, ifX stands for a random 
variable, inequality such as X < t determines a set of all outcomes s in 5 satisfying the con­
dition X (s) < t. We will postulate10 that {X < t} is an event for each t. This way we gain a 
powerful tool for describing events in addition to the techniques used thus far, such as speci­
fying subsets of sample space S by listing their elements or by providing a verbal description.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszyinski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
(*) However, in Chapter 1, it was repeatedly stressed that the concept of sample space is, to a 
large extent, a mathematical construction, and that one can have several sample spaces, all of 
them equally acceptable for the same phenomenon. The problem then is how to reconcile the 
inherent lack of uniqueness of the sample space used to describe a given phenomenon with 
the idea ofa random variable being a function defined on the sample space. At first glance, it 
would appear that the concept of a random variable, being based on another concept (sample 
space 5) that allows subjective freedom of choice, must itself be tainted by subjectivity and 
therefore be of limited use.
10The reader may wonder why we use the term postulate here: the set {s € S : X(s) < t} is a subset of S and 
consequently, is an event. However, as explained in Section 2.4, in the case of nondenumerable sample spaces S we 
may be unable to define probability P on the class of all subsets of S . We must therefore restrict considerations 
to some class of subsets of S, forming a a -field, say A, of events. In defining random variables, we postulate that 
{s € S : X(s) < t} € A for every t. In accepted terminology, we say that random variables X are functions on S 
that are measurable with respect to the a-field A. From now on we will always tacitly assume that each set of the 
form {X < t} is an event, and therefore it is permissible to speak of its probability.
93

94
RANDOM VARIABLES: UNIVARIATE CASE
Specifically, suppose that there are several sample spaces, say 5, S', ..., with the 
associated probability measures P,P', ... that are equally acceptable for describing a given 
phenomenon of interest, and let X, X', ... be random variables defined, respectively, on 
S, S', ....
As we will explain, the random variables that are useful for analyzing a given phe­
nomenon must satisfy some “invariance” principle that make them largely independent of 
the choice of the sample space. The general idea is that a random variable is exactly what 
the name suggests: a number depending on chance. Phrases of this sort were commonly used 
as “definitions” of the concept of random variable before the probability theory was built 
on the notion of sample space. What we want to achieve is to define random variables in a 
way that makes them associated with the phenomenon studied rather than with a specific 
sample space, hence invariant under the choice of sample space. This is accomplished by 
introducing the following principle: 
(*)
Invariance Principle for Random Variables
Suppose that X' and X" are two random variables defined on two sample spaces S' and 
S" used to describe the same phenomenon. We say that these two random variables are 
equivalent if for every t the event {X' < t} occurs if and only if the event {X" < t} occurs, 
and moreover if these events have the same probability.
Clearly, the equivalence of random variables defined above satisfies the logical require­
ments for relation of equivalence: reflexivity, symmetry, and transitivity. We can therefore 
consider equivalence classes of random variables and speak of representatives of these 
classes. Random variables are particularly useful in describing and analyzing random 
phenomena: they do not depend on a particular choice of a sample space; hence they are 
free of the subjectivity and arbitrariness involved in the selection of S.
5.2 DISTRIBUTIONS OF RANDOM VARIABLES
Although formally each random variable is a numerical function on some sample space S, 
we usually suppress the dependence on elements of S in notation, referring to it only when 
needed to avoid confusion. As symbols for random variables, we will use capital letters from 
the end of the alphabet, X, Y, Z, possibly with subscripts.
With every random variable, we will associate its probability distribution, or simply 
distribution.
Definition 5.2.1 By a distribution of the random variable X we mean the assignment of prob­
abilities to all events defined in terms of this random variable, that is, events of the form 
{X e A}, where A is a set of real numbers. 
□
Formally, the event above is a subset of the sample space S. We have
{X e A} = {s e S : X (s) e A}cS.
The basic type of events that we will consider is an interval, that is, 
{a<X<b}, {a < X<b}, 
{a < X < b}, {a<X< b}, 
(5.1)
where —ж < a < b < ж.
Ifwe can compute probability of each of the events (5.1) for all a < b, then using the rules 
from Chapter 2, we can compute probabilities of more complex events. For example,
P[{a<X< b}c] = P{X < a or X>b} = P{X < a} + P{X>b}
= P{X < a} +1— P{X < b}.

DISTRIBUTIONS OF RANDOM VARIABLES
95
Similarly, for the probability of the intersection {a < X < b} П {с < X < d}, the answer 
depends on the mutual relationship between a, b, с, and d (in addition to assumptions a < b 
and с < d). If, for instance, a < с < b < d, then the event in question reduces to {с < X < b}, 
and so on.
Actually, it turns out that it is sufficient to know the probabilities of only one type of 
event (5.1) in order to determine the probabilities of remaining types. We will prove one such 
relation; the proofs of others are similar.
Theorem 5.2.1 The probabilities of the events of the form {a < X < b} for all —ж < a < b < 
ж uniquely determine the probabilities of events of the form {a < X <b}, {a < X < b}, and 
{a < X<b}.
Proof: Wehave
{a<X<b} = 
a<X< b—
n
{a < X <b} = n{ a 
n
<X<b
(5.2)
1
{a < X <b} = nu{ a— n <X <b — mm 
nm
We will prove the last of these identities. Let s be a sample point belonging to the left-hand 
side so that a < X(s) <b. Then for every n, we have a —1/n < X(s). Also, if X(s) < b, then 
X (s) < b — 1/m for some m (actually for all m sufficiently large). Thus, s belongs to the set 
n m {a - 1 /n < X < b - 1 /m}. On the other hand, if s belongs to the right-hand side of 
the last equality in (5.2), then we have
a---- < X (s) < b-------
for all n and for some m. Passing to the limit with n ^ ж, we obtain a < X(s) < b — 1 /m < 
b, which means that s belongs to the set {a < X <b}. 
□
Thus, each of the sets {a<X<b}, {a < X < b}, and {a < X<b} can be represented 
as union or intersection (or both) of a sequence of events of the form {an <X< bn}.11
11In terminology introduced in Chapter 1, we could say that each of the three types of events above belongs to the 
smallest a -field generated by the class of all events of the form {a < X < 6}. Equivalently, we could say that the 
intervals on the real line of the kinds (a, b), [ a, b), and [ a, b ] belong to the smallest a -field of sets of real numbers 
that contains all intervals of the form (a, 6].
12According to the footnote at the beginning of this chapter, the right-hand side of (5.3) is well defined for each t 
(i.e., {X < t} is an event).
Let us observe that {a<X< b} = {X < b}\{X < a}. Consequently,
P{a<X< b} = P{X < b}—P{X < a}
and the probabilities of all events of the form {a<X< b} are determined by probabili­
ties of events of the form {X < t} for —ж <t < ж. This justifies the following important 
definition:
Definition 5.2.2 For any random variable X , the function of real variable t defined as
FX(t)=P{X<t} 
(5.3)
is called the cumulative probability distribution function,12 or simply cumulative distribution 
function (cdf) of X. 
□

96
RANDOM VARIABLES: UNIVARIATE CASE
The following two examples will illustrate the concept of a cdf:
■ EXAMPLE 5.1
The experiment consists of shooting once at a circular target T of radius R. Assume 
that it is certain that the target will be hit, and that the probability of hitting a particular 
section A contained in T is given by | A\/\T |, where | • | is the area of the section. We will 
determine the cdf of a random variable X defined as the distance between the point of 
hitting and the center of the target.
SOLUTION. A natural sample space in this case is just T. Without loss of gener­
ality, we can put the center of coordinate system in the center of T so that sample 
points s = (x, y) satisfy x2 + y2 < R2. If the target is hit at point s = (x,y), then 
X = X (s) \/x2 + y2 is the distance of the point of hit from the origin. Clearly, we 
have 0 < X < R.
Now let FX(t) = P{X < t}. Obviously, ift>R,then FX(t) = 1, and ift<0, then 
FX (t)=0. For t with 0 < t < R, we have
FX(t)=P{X<t}
= P {point s falls in the circle of radius t centered at the origin}
2
Thus
nt2 
nR 2
FX (t)=
t<0
0<t<R 
t>R.
(5.4)
0
(R )2
1
The graph of FX (t) is given in Figure 5.1.
Remark A simple fact, useful in determining cdf’s of random variables, is that if the random 
variable X is bounded from above, then FX (t)=1for all t>M,whereM is the upper

DISTRIBUTIONS OF RANDOM VARIABLES
97
bound for X. Indeed, if t>M, then
Fx (t) = P{X < t}
= P{X < M} + P{M <X < t} = P{X < M} = 1.
Similarly, ifX is bounded from below, then FX (t)=0fort<m,wherem is the lower bound 
for X .
■ EXAMPLE 5.2
Let the experiment consist of three tosses ofa coin, and let X be total number of heads 
obtained. The sample space consists of the eight sample points listed below, together 
with their associated values of X :
S
X
HHH
32
HHT
2
HTH
2
THH
S
X
TTH
1
THT
1
HTT
1
TTT
0
The random variable X satisfies the condition 0 < X < 3 so that FX(t)=0ift<0 
and FX (t)=1if t>3. Moreover, since X can take on only values 0, 1, 2, and 3, we 
have P{X e A} = 0 for every set A that does not contain any of the possible values 
ofX. Finally, simple counting gives P{X =0} = P{X =3} =1/8 and P{X =1} = 
P{X =2} = 3/8. Thus for 0 < t< 1 we write
FX(t) = P{X < t} = P{X<0}+P{X =0}+P{0 <X< t}
= p {x = 0} = 8.
Similarly, if 1 < t< 2, then
FX(t)=P{X<t}
= P{X<0} + P{X =0} + P{0 <X<1} 
+P{X =1}+P{1 <X<t}
= p {X = o} + p {X = 1} = 2.
Proceeding in a similar way with 2 < t<3, we get
The graph of FX (t) is given in Figure 5.2.
Fx (t ) = <
0 
fort< 0
for 0 < t < 1
8
- 
for 1 < t < 2
7- 
for 2 < t < 3
8 
for 3 < t.
We will next investigate general properties of cdf’s in some detail.

98
RANDOM VARIABLES: UNIVARIATE CASE
л F (t)
1
7
8
1
2
1 
2 
3 
4 
t
Figure 5.2 Cdf of the number of heads in three tosses of a coin.
Theorem 5.2.2 Every cdf F has the following properties:
(a) F is nondecreasing.
(b) limt—-o F(t) = 0, limt—o F(t) =  •1
(c) F is continuous on the right.
Proof :LetF be the cdf of random variable X. To prove (a), let t1 <t2 . Then
F(t2) - F(t 1) = P{X < t2} - P{X < t 1} = P{t 1 <X < t2} > 0•
Consequently, F(t 1) < F(t2), as was to be shown.
To prove the second relation in (b), we have to show that limn—oF(tn) = 1 for any 
sequence {tn} such that tn ^ ж^ Without a loss of generality, we can assume that t1 <t2 < 
• ■ ■ ^ ж. The events {X < t 1}, {t 1 < X < t2}, {t2 < X < t3}, • • • are disjoint, and their 
union is the whole sample space S . By the second and third axioms of probability, we have
oo
1=P(S)=P{X<t1}+ 
P{tk-1<X<tk}
k=2
on
= F(t1) + 
[F(tk) - F(tk-1)] = F(t1) + lim 
[F (tk) - F (tk-1)]
n—>o < * 
k=2 
k=2
= lim {F (t1) + [F (t2) - F (t1)] + •••+[F(tn) - F(tn-1)]} 
n—o
= lim F (tn), 
n—o
as was to be shown. The proof that limt—-o F(t)=0is analogous.
To prove (c), let {tn} be a sequence such that t 1 > t2 > ■■■ ^ t* • We have to show that 
limn—o F(tn ) = F (t*) •
The events {X < tn} form a monotonically decreasing sequence, with p|n=1 {X < tn} = 
{X < t*} So, by Theorem 2.6.1, we have
F(t*) = P{X < t*} = P
o
{X < tn} 
n=1
= P [lim {X < tn} ] = lim P {X < tn} = lim F (tn) • 
n—o 
n—o 
n—o
One of the consequences of the foregoing properties of cdf’s is that for every x
P{X =x}= F(x) -F(x-0),
(5.5)

DISTRIBUTIONS OF RANDOM VARIABLES
99
where F(x - 0) = limh^0 F(x - h) is the left-hand-side limit of F at x. Indeed, we have
{X = x} = Q {x - hn <X < x} 
(5.6)
n=1
for every decreasing sequence of positive numbers hn with hn ^ 0. Since the sets in the 
product (5.6) are decreasing, by the continuity property of probability,
P{X = x} = lim P{x - hn <X< x} = lim [F (x) - F(x - hn)] 
n—>^> 
n—>^>
= F(x) - lim F(x - hn) = F(x) - F(x - 0).
Sometimes it is necessary to identify values ofa random variable corresponding to a given 
value of cdf. These values are called quantiles.
Definition 5.2.3 Let X be a random variable with cdf F, and let 0 < p < 1. The quantile of 
order p (or pth quantile) £p of X is defined as any solution of the simultaneous inequalities
P{X < x}> p, 
P{X > x} > 1 - p. 
(5.7)
The inequalities (5.7) are equivalent to
F(x) > p, 
F(x - 0) < p. 
□
To illustrate this definition, we assume now that X is a random variable with continuous 
cdf F(x). For any p with 0 < p < 1 there exists13 a point £p satisfying the relation F(£p) = 
p. This means that P {X < ^} = p .If F is continuous, then P {X > £p} = P {X > £p} = 
1 - F(£p) = 1 - p. So £p satisfies (5.7). However, £p is not always unique; F can satisfy the 
relation F(x) = p for an interval of values x, and each of them can serve as £p. For the case 
of random variables with continuous cdf, the condition (5.7) would then reduce to
13The existence of such a point follows from the continuity (hence also the Darboux property) of function F;it 
must assume every value between its lower bound 0 and upper bound 1.
P{X < & = p, 
P{X > & =1 - p, 
(5.8)
with each of the relations (5.8) implying the other.
■ EXAMPLE 5.3
For the random variable X in Example 5.1, the quantiles can be determined from the 
relation (£p/R)2 = p; hence £p = R^p. For instance, if p = 0.25, then £0.25 = R/2: 
chances of hitting the target at a distance less than 1/2 of the radius are 0.25.
The reason for using inequalities in condition (5.7) instead of the simpler condition (5.8) 
lies in the fact that the equation F(x)=p may have no solution, as illustrated by the follow­
ing example:
■ EXAMPLE 5.4
Let X assume values 1, 2, and 3 with probabilities 0.2, 0.6, and 0.2, respectively. Then, 
F(x) = 0.8 for 2 < x<3, and F(x)=1for x > 3. Thus, the equation F(x)=p is 
solvable only for p =0.2 and p = 0.8. To find, for example, a £0.5, we need to use

100
RANDOM VARIABLES: UNIVARIATE CASE
(5.7), looking for points such that P{X < x} > 0.5 and P{X > x} > 0.5. The first 
inequality gives x > 2, while the second gives 1 - F(x - 0) > 0.5. Hence x < 2, and 
both inequalities are satisfied only for x = 2. So we have £0.5 = 2.
Certain quantiles have special names. For example, £0.5 is called the median, £0.25 and £0.75 
are called lower and upper quartiles, respectively. Quantiles may also be called percentiles, pth 
quantile being the same as 100pth percentile.
We have the following theorem:
Theorem 5.2.3 If X is a random variable with continuous cdf and 0 < a < в < 1, then
P{£a < X < £в} = в - a, 
(5.9)
where £a and £e are any quantiles of order a and в, respectively.
Proof: The left-hand side of (5.9) equals F(£e) - F(£a - 0), which equals F(£e) - F(£a) 
by continuity of F, and hence equals в - a by the definition of quantiles. 
□
Some comments about the concept of cdf are now in order. First, we defined the cdf 
of a random variable X using nonstrict inequality, that is, F(t) = P{X < t}. It is equally 
permissible to define cdf by the formula F* (t) = P{X < t}. The only difference between 
F and F* is that the latter is left continuous. Such a definition of the cdf actually appears 
throughout in Russian and Eastern European statistical literature.
The second comment concerns the sufficiency of conditions (a)-(c) in Theorem 5.2.2. 
To put it differently, if a function F satisfies conditions (a)-(c), does there exist a random 
variable X such that F is the cdf of X, that is, F(t) = P{X < t}?
The following theorem provides the answer. Interested readers could find the proof in 
advanced texts on probability, for example, Chow and Teicher (1997).
Theorem 5.2.4 Any function F that satisfies conditions (a)-(c) of Theorem 5.2.2 is a cdf of 
some random variable.
The importance of this theorem (as in the case of Theorem 2.6.3) is that it guarantees that 
some phrases, such as “let F be a cdf,” make sense, with no additional assumptions about 
F besides (a)-(c) of Theorem 5.2.2.
The next question, quite naturally, is: Do cdf’s determine uniquely the random variables 
associated with them? The answer here is negative: there are many random variables (asso­
ciated with different phenomena, or even associated with the same phenomenon) that have 
the same cdf. Thus, it is a random variable that determines its cdf, and not conversely. To see 
why this is so, let us consider the following example:
■ EXAMPLE 5.5
Continuing Example 5.2, let us consider the experiment consisting of three tosses ofa 
coin, and two random variables: X = total number of heads and Y = total number of 
tails. We have here, as before,
S
X
Y
5
X
Y
HHH
3
0
TTH
1
2
HHT
2
1
THT
1
2
HTH
2
1
HTT
1
2
THH
2
1
TTT
0
3

DISTRIBUTIONS OF RANDOM VARIABLES
101
A simple count shows that P {X = k} = P {Y = k} for all k, which implies that the 
cdf’s FX (t) and FY (t) are identical.
This example illustrates the fact that there exist two distinct variables X and Y 
defined on the same sample space S , and that these two variables have the same distri­
bution function. Obviously, if X and Y are defined as above, but refer to two distinct 
triplets of tosses, their distributions will still be the same.
On the cumulative distribution function of a random variable X, recall from Defini­
tion 5.2.1 that the distribution of random variable X is defined as an assignment of prob­
abilities P{X e A}, where A is a set of real numbers. The cumulative distribution function 
FX then provides probabilities of intervals open on the left and closed on the right:
P{X e (a, b]} = P{a < X < b} = FX(b) - FX(a). 
(5.10)
The question now is: Does FX also determine the probabilities P{X e A} for sets A other 
than intervals (a, b], and if so, what is the class of these sets? Before answering, let us observe 
that the leftmost member of (5.10) can be written as P{s eS: X(s) e (a, b]}, so that the 
symbol P refers to the subsets of sample space S, as it should according to the definition of 
probability. On the other hand, the rightmost member depends only on a and b, and assigns 
a number to an interval (a, b]. We may therefore say that we are dealing with probability on 
sets of real numbers (at least on intervals). According to the footnote at the beginning of this 
chapter, the left-hand side is well defined: We know that events (sets on which P is defined) 
form a a-field, and we also know that sets {X < t} are events so that
{a<X< b} = {X < b}\{X < a}
is also an event.
The following extension theorem is given without proof.
Theorem 5.2.5 If F is a cumulative distribution function, then the function mF defined on the 
class B 0 of all intervals (a, b ], —ж < a < b < + ж, by the formula
mF(a,b]=F(b) - F(a) 
(5.11)
can be extended uniquely to a probability measure mF on the smallest a-field B containing B0.
PROBLEMS
5.2.1 In the statements below, F and G stand for cdf’s of random variables X and Y, respec­
tively. Classify each of the statements below as true or false: (i) If X is always strictly 
positive, then F(t) is strictly positive for all t. (ii) If F(37) = F (45), then P(40 <X< 
42) = P(43 <X<44). (iii) If Y = X+3, then G(t) < F(t) for all t. (iv) If G(17) - 
F (17) = 1, then both X and Y are always less than 17. (v) If G(17) - F (17) = 1, then 
Y always exceeds X. (vi) If G(17) x F(17) = 1, then P(max(X, Y) < 17) = 1. (vii) If 
G(17) x F(17) = 0, then P(min(X, Y) < 17) = 1. (viii) If \F(t) — G(t) | < e for all t, 
then |X — Y| < e. (ix) If P(X < Y) = 1, then F(t) > G(t) for all t.
5.2.2 Figure 5.3 shows the cdf of a random variable X. Find: (i) P(X = —2), P(X =0). 
(ii) P(X < 3), P(X < 3), P(X < 0.13). (iii) P(X > 2), P(X > 2.79). (iv) P(—1 < 
X < 0.7), P(—2 < X<1). (v) P(1 <|X|<2).
5.2.3 Let X be a random variable with cdf given by FX (x)=0for x<0 and FX (x)=1— 
0.3e-Xx for x > 0. Determine: (i) P(X = 0). (ii) A if P(X < 3) = 3/4. (iii) P(|X| < 5) 
using results of (ii).

102
RANDOM VARIABLES: UNIVARIATE CASE
5.2.4
Figure 5.3 Cdf of random variable X.
Determine the medians and lower and upper quartiles for random variables with the 
following cdf’s:
0
(i) FX (x)= kx3
11
forx< 0
for 0 < x < 1 / -^k. 
k > 0
for x > 1 / 3/k,
(ii) FX(x_ ae-
forx< 0
for x > 0. (consider all possible a)
5.2.5 A point is chosen at random from a square with side a.LetX be the distance from the 
selected point to the nearest corner of the square. Find and graph FX (x).
5.2.6 A coin of diameter d is dropped on a floor covered with square tiles with side length 
D>d.LetX be the number of tiles which intersect with the coin. (i) Find the distri­
bution of X . (ii) Determine the median of X as a function of D and d.
5.2.7 Prove the first part of assertion (b) of Theorem 5.2.2.
5.3 DISCRETE AND CONTINUOUS RANDOM VARIABLES
Although the cdf of a random variable X provides all the information necessary to determine 
probabilities P{X e A} for a large class of sets A, there exist wide and practically important 
classes of random variables whose distributions may be described in simpler ways. Two such 
classes will be discussed in this section. Accordingly, we introduce the following definition:
Definition 5.3.1 A random variable X will be called discrete, if there exists a finite or count­
ably infinite set of real numbers U = {x1.x2.......} such that
P{X e U} = 
P{X = xn} =1.
(5.12)
n
□
■ EXAMPLE 5.6
Let U = {1. 2........n} for some n. and let P{X = j} =1/n forj e U. Condition (5.12)
is satisfied. This example describes the selection (assumed fair) of the number of the 
winning lottery ticket, where n is the total number of tickets.
A discrete random variable with a finite set U of values, all of them having the same 
probability of occurrence, is called (discrete) uniform.

DISCRETE AND CONTINUOUS RANDOM VARIABLES
103
■ EXAMPLE 5.7 Binomial Distribution
The binomial distribution plays a central role in probability theory and statistical mod­
eling, and it will often be used throughout this book. Here, we just introduce a defini­
tion and basic formulas.
Definition 5.3.2 The binomial random variable is defined as a total number of successes in n 
independent experiments, each experiment leading to success with probability p. 
□
We have encountered special cases of binomial random variable in the preceding chapters 
(e.g., in analyzing the distribution of the “total number of heads in three tosses of a coin”). 
The set of possible values of X is {0, 1, ...,n}, since the number of successes is an integer, 
and at best equals n (the number of trials) and at worst equals 0 (if all repetitions lead to 
failure). The probability of k successes and n - k failures in any specific order SFFS...S 
equals p(1 - p)(1 - p)p...p= pk(1 - p)n-k. Since the probability of this string does not 
depend on its order, we obtain P {Sn = k} by taking pk (1 - p)n-k as many times as there 
are different orders of k letters S and n - k letters F . This number is nk , since each such 
order is completely specified by selecting the set of locations for letter S among n slots. Thus,
P{X = k} = (nk)Pk(1 -P)n-k, 
k = 0, 1, ...,n, 
(5.13)
and using the Newton binomial formula (3.16), we have
nn
P{X=k}= 
nk Pk(1-P)n-k=[P+(1-P)]n=1.
k=0 
k=0
In the sequel, we shall use the symbol BIN(n, P) to denote binomial distribution with 
parameters n and p. This way we say that X has distribution BIN(n,p) or simply X ~ 
BIN(n, P). We also let the individual probabilities in distribution BIN(n, P) be denoted by 
b(k; n, p) so that
b (k; n,P )= ( n } Pk (1 - P) n-k, 
k = 0, 1 ,...,n. 
(5.14)
In the examples above, the set U was finite, with U = {1, ...,n} in Example 5.6 and 
U = {0, 1, ...,n} in Example 5.7. In the example below, the set U is infinite.
■ EXAMPLE 5.8
Consider a sequence of independent tosses ofa die. Let X be the number of tosses until 
the first ace. Clearly, X can assume values 1, 2, 3, ..., and the event {X = k} occurs 
if the kth toss gives an ace (chances are 1/6) and the first k - 1 tosses are all different 
from an ace [chances are (5/6)k-1]. Thus
1
6
5
6
1
P{X = k} =
k=1,2, .....
(5.15)
We can easily check that
oo
P{X = k} = 
k=1
o
1У
6 k=1
=1,
5
6
k
1
1
= - X
6
1
1
5
6
so condition (5.12) is satisfied.

104
RANDOM VARIABLES: UNIVARIATE CASE
This random variable is generally described as “waiting time for the first success” 
(in this case success being an ace). Distribution (5.15) is an example of geometric dis­
tribution, denoted GEO (p), which will be discussed in detail in Chapter 8.
■ EXAMPLE 5.9 Poisson Distribution
We say that the random variable X has Poisson distribution with parameter A > 0, 
denoted POI (A), if the possible values of X are nonnegative integers 0, 1,2, ... and
P {X = k} = A~ e-x, 
k = 0, 1, 2,.... 
(5.16)
k!
The Poisson distribution is often applied in practice, so we will study its properties in 
some detail in following sections. At present, observe that (5.16) is correctly defined,
since
it P {X = k} = it Ak e- = e- it A!= e- x eA = 1. 
k=0 
k=0 
k=0
In the examples above, the set U of possible values of X consisted of integers. This is 
the most frequent case, since typically discrete random variables represent counts involved 
in observing random phenomena. In other words, discrete random variables are typically 
obtained as “the number of ...” One should remember, however, that the definition allows 
any values in the set U, and not necessarily integers.
The distribution of a discrete random variable X is determined by the set 
U = {x1, x2, ...} of its possible values, and the assignment of probabilities P{X = xi} to 
all xi e U, the only condition being (5.12) (i.e., the sum of all probabilities must be 1). The 
function pX , defined by the formula
pX (x)=
P{X = x} 
0
if x e U 
ifxe/U,
is often called the probability mass function, or the probability function of random variable 
X , or (in engineering-oriented texts) a probability density function. We will often use the 
first two of these terms. The term density can be confusing in this context, so we will reserve 
it for continuous random variables, discussed later in this section.
The cdf of a discrete random variable can now be easily determined. We have
F(t) = P{X < t} = £ P{X = xi}.
Xi<t
(5.17)
■ EXAMPLE 5.10
In the simplest cases, it is convenient to represent the distribution ofa discrete random 
variable X as a double array of elements ofU with corresponding probabilities, such as
Values
1
2
-3
5
Probability
1
2
1
3
1
6
We have here U = {-3, 1/2, 5} and P{X = -3} = 1/2,P{X = 1/2} = 1/3,P{X = 
5} = 1/6.
According to (5.17), F(t)=0for all t<-3, and for -3 < t<1/2,
F(t) = P{X < t} = P{X = — 3} = 2.

DISCRETE AND CONTINUOUS RANDOM VARIABLES
105
For 1 /2 < t < 5, we have
P{X < t} = P{X = - 3} + /x = 1} = 2 + 3 = 5
.
6
Finally, for t > 5, we have P{X < t} = P{X < 5} = 1.
It is worthwhile to point out that the cdf is defined for all real arguments, and not only 
for the possible values of the random variable. For example, one can find FX (2.27) if X is 
the result of a single toss of a regular die.
■ EXAMPLE 5.11
The random variable X in Example 5.8 was defined as the number of tosses of a die, 
up to and including the first ace. Here the cdf is as follows: First, since X > 1, we have 
F(t)=0for all t<1. Second, if k < t<k+1, where k =1, 2, ..., then we have
k 
k 1 5 j-1 
5 k
F (t ) = P {X < t} = £ P {X = j} = 
=1 -( в) .
In both examples, the cumulative distribution function is a step function, with cdf increas­
ing at every point of the set U and constant between the steps. Although this is the property 
characterizing most discrete random variables, there also exist discrete random variables 
such that their cdf’s are not constant on any interval, as shown in the example below.
■ EXAMPLE 5.12
Let U be the set of all rational numbers. It is well known that U is countable, that is, all 
elements ofU can be arranged into a sequence x1, x2, ... (but U cannot be arranged in 
a sequence x1, x2, ... with xn < xn+1 for all n). Let X be a random variable such that 
P{X = xn} =1/2n,n=1, 2,   Then, the cdfofX is not constant on any interval. 
Indeed, for t1 <t2 we have
F(12) - F(11)= £ P{X = xn}, 
(5.18)
t1<Xn<t2
and the right-hand side is positive, since there exists a rational number xn between any 
two distinct real numbers t1 and t2. Consequently, F increases between any two points.
Formula (5.18) shows how to calculate the probability of any interval (t1, t2]. Generally, 
for any set A, we have
P{X e A} = £ P{X = Xn}.
XnEA
■ EXAMPLE 5.13
The random variable X has the following distribution:
Value
- 3 
- 2 
0 
1 
2
Probability
2 
1 
„ 
2 
2
9 
9 
p 
9 
p
and we want to find P(|X +1| > 1).

106
RANDOM VARIABLES: UNIVARIATE CASE
SOLUTION. First, we use (5.12) to find the value of p. We have here
9+1+p+p 2+9=i,
which gives the equation p2 + p - 4/9=0. The solutions are p =1/3 and 
p = -4/3, of which only the first is admissible as a probability. Consequently
P{X=0} = i/3,P{X = i} = i/9 and
P{|X + i| > i}=P{X= -3}+P{X=i}+P{X=2}
_ 2 
2 
1 _ 5
= 9 + 9 + 9 = 9'
Let us now introduce another large class of random variables.
Definition 5.3.3 The random variable X will be called continuous if there exists a nonnegative 
function f, called the density of X, such that
FX(t) = 
t f(x) dx 
(5.19)
— от
for — X <t < X. 
□
■ EXAMPLE 5.14 Uniform Distribution
Let A<B,and let the density f (x) have the form:
{
0 if x < A
c if A < x < B 
(5.20)
0 ifx>B.
Ift<A,then the integrand in (5.19) is 0, so F(t) = 0. For A < t < B, we have
F (t)= f(x) dx + f (x) dx = 
0 dx + cdx= c(t - A).
— от 
A 
— от 
A
Finally, if t>B,then
F (t)= 
f (x) dx + 
f (x) dx + 
f (x) dx = 
cdx= c(B - A).
— от 
ABA
This means that F (t) is of the form presented in Figure 5.4. Clearly, since 
limt^xF(t) = 1 by Theorem 5.2.2, we must have c(B - A) = 1; hence 
c = i/(B - A). In other words, if function (5.20) is a density of a random 
variable, then c is uniquely determined by the length of the interval [A, B]. Thus, the 
density of the distribution (continuous) unif orm on [A, B], denoted U [A, B], is
0
1
f(x) =
B
A
0
ifx<A
if A < x < B
ifx>B.
(5.21)

DISCRETE AND CONTINUOUS RANDOM VARIABLES
107
Figure 5.4 Cdf of distribution uniform on [A, B].
In general, by letting t — ж in (5.19), we see that every density function f must satisfy 
the relation
Z
+TO f(x) dx =1. 
(5.22)
TO
Also, it follows from (5.19) that F (t) is a continuous function, and consequently for every x,
P(X =x)=F(x) -F(x-0) =0. 
(5.23)
Formula (5.19) combined with (5.23) leads to the following theorem:
Theorem 5.3.1 If random variable X has density f, then for all a<bwe have
P{a < X < b} = P{a <X < b} = P{a < X < b}
= P{a < X < b} = F(b) - F(a) = 
f (x) dx.
This formula implies that in dealing with continuous random variables, one can afford 
the luxury of being sloppy in handling inequalities. In particular, one can treat an event such 
as {X < a} as (equivalent to) the complement of the event {X > a}, and so on. This is in 
sharp contrast with discrete random variables, where the events {X < a} and {X<a} may 
have different probabilities.
A question arises as to the extent to which the cdfofa continuous random variable deter­
mines its density. Formula (5.19) suggests that we have
F' (t) = f (t), 
(5.24)
and consequently, since F is a nondecreasing function (by Theorem 5.2.2), we must have
f(t) > 0. 
(5.25)
In fact formulas (5.24) and (5.25) need not be valid for all points t. The reason is that the 
density f determines the probabilities of intervals through integration. This means that f is 
not defined uniquely. Indeed, the two densities f1 and f2—which differ only at a single point 
or on a finite set of points—will satisfy the condition
Z
b 
bb
f1 (x) dx = 
f2(x) dx
for all a and b. The same will be true if f1 and f2 differ on some set of measure zero.

108
RANDOM VARIABLES: UNIVARIATE CASE
Consequently, we may only claim that formulas (5.24) and (5.25) are valid almost 
everywhere, that is, except on a set of measure zero.
■ EXAMPLE 5.15
The random variable X, with density given in Example 5.14, is called uniform on inter­
val [A, B]. It is clear, however, that if we modify the definition of f at boundaries A 
and B (e.g., by putting f(A) = f(B) = 0), the cdf will remain unchanged. A particular 
consequence of this observation is as follows: in real situations, we often deal with dis­
continuous densities defined by different formulas in different intervals. In such cases, 
it does not matter how the density is defined at the endpoints.
The last remark is true in regard to calculating probabilities. One should never­
theless be careful with the interpretation of density. For example, since for Дx > 0, 
we have
P{x < X < x + Дx} = X 
f (t) dt,
x
we can approximate the last integral, for continuous densities f, by f (x)Дx. This leads to 
an “engineer’s” interpretation, according to which f(x) dx is the “probability that random 
variable X will assume the value in the infinitesimal interval (x, x + dx).” Here one has 
to be careful not to apply such an interpretation at points where f is not continuous. For 
instance, in the Example 5.14, we had f(B) = 1/(B - A); hence the probability ofX assum­
ing a value in the interval [B, B + h] for some small h>0 may be taken as h/(B - A). 
But this value is positive, whereas in fact the probability of X exceeding B by any amount 
is zero.
Let us now introduce an important type of continuous distributions called an exponential 
distribution.
Definition 5.3.4 (Exponential Distribution) The distribution with the density
( Ae—Xx 
for x > 0
f(x) = 
(5.26)
0 forx < 0,
where A > 0, will be called exponential with parameter A, denoted EXP(A). 
□
To check that (5.26) is indeed a density, we write
X 
f (x) dx = X 0 dx + X 
Ae—Xx dx = —e-Xx|^° =1.
- — <ж 
- — ^ 
0 0
According to the remark made in Example 5.15, the value of the density at x = 0 plays 
no role. Thus, we could have defined f (x) in Definition 5.3.4 as Ae—Xx for x > 0 and 0 
for x<0.
■ EXAMPLE 5.16
Let us compute P{|X — 1/2| > 1/4} for a random variable X that has EXP(2) 
distribution.

DISCRETE AND CONTINUOUS RANDOM VARIABLES
109
SOLUTION. Since the density determines probabilities through integration,
P{|X - 0.5| > 0.25} = 
f(x) dx
Z
f (x) dx + 
f (x) dx
<0.25 
x>0.75
= [ 0 dx + [ 
2e-2x dx + [ 2e-2x dx
--ж 
0 
0.75
=1-e-0.5+e-1.5 = 0.6166.
Example 5.16 should serve as a warning. It happens often that density is defined by a for­
mula consisting of several parts, like (5.26). In calculating probabilities, one has to integrate 
f over some set, and special care should be taken to use the proper part of the formula for 
f on appropriate parts of the domain of integration.
We will always choose a version of density that is “most regular.” In particular, this means 
choosing a continuous or piecewise continuous version if possible. When density is discon­
tinuous, the choice of values at breakpoints is irrelevant.
■ EXAMPLE 5.17 Normal Distribution
One of the most common distributions encountered in statistics, useful in modeling 
real-life phenomena, is the normal distribution, with density defined by
f (x) = f (x; ^,a) = -^=e—(x—p)2/2°2 
a\J 2 n
(5.27)
where ^ and a > 0 are two parameters whose interpretation will be given later. The 
distribution (5.27) is usually denoted N(p, a2). The distribution N(0, 1), with density
V(x) =
(5.28)
is called standard normal.
We will show that the function (5.27) is a density; that is, it integrates to 1. Indeed, 
letting z = (x - p,) /a, so that a dz = dx, we have
1 
a^ln
e—(x—p )2 / 2 ° ° dx =
dz.
Next, we need to prove that a standard normal density (5.28) integrates to 1.
The function e-x2/2 does not have an antiderivative that can be written in a closed 
form. Thus, to compute the integral
I=
e-x2/2 dx,
we apply a trick and compute I2 :
I2
ж
-ж
e-x2/2 d^ x(-L ++Ж e-У2/2
2 
\ V2n— ж
dy
Z
+ ж
ж
e-(x2+y2 )/2 dx dy.
(5.29)

110
RANDOM VARIABLES: UNIVARIATE CASE
Using polar coordinates (r, в), with x = r cos в,у = r sin в, we write the Jacobian of 
the transformation as
dx
dx
dr
дв
cos в
-r sin в
dy
dy
sin в
rcos в
dr
дв
Then, we change the variables in (5.29) to obtain
12 = — [ dd [ r e-2 /2 dr = 1;
2 n J 0 
0
hence I =1, as was to be shown.
As already mentioned, the density function p (x) of standard normal distribution (as well 
as any other normal density function f (x; p,, a)) does not have an antiderivative expressible 
in closed form. Therefore, to find probabilities for normal random variables, one needs to 
use available statistical software.
Suppose that we have to find
1 
(X 
(x—p )2
P{a < X < b} = ~^= J e—~~ dx, 
(5.30)
for random variable X ~ N(p, a2). In the case of any normal distribution, probabilities can 
one obtained using probabilities of the standard normal distribution. To see why, consider 
the probability (5.30) and use the change of variable z = (x - y,) /a in the integral. We have 
dx = adz; hence, after substitution to (5.30) we obtain
P{a < X < b} = -L 2 e-z2/2 dz = Ф(z2) - Ф(z 1),
2 
2 n Z z 1
where z 1 = (a - у)/a, z2 = (b - у) /a, and Ф is the cdf of the standard normal distribution. 
One may also use the fact that у(z) is symmetric about 0 so that
Ф(-z) = 1 - Ф(z). 
(5.31)
The procedure is illustrated by the following example:
■ EXAMPLE 5.18
Suppose that X ~ N( -0.7, 4) and that U is defined as an integer nearest to X. Find
P(U = -1).
SOLUTION. In this case, у = -0.7 and a2 = 4; hence a = 2. Consequently,
P(U = -1) = P (-1.5 <X<0.5)
-0.5 - (-0.7) \ 
/ -1.5 - (-0.7)
2 
- - I 2
= Ф(0.1) - Ф(-0.4).
Using (5.31) to reduce to positive arguments of Ф, we have
P(U = -1) = Ф(0.1) - (1 - Ф(0.4)) = Ф(0. 1) + Ф(0.4) - 1
= 0.5398 + 0.6554 - 1 = 0.1952,
where the numerical values are obtained from the statistical software.

DISCRETE AND CONTINUOUS RANDOM VARIABLES
111
At the end of this section, it is necessary to point out that discrete and continuous random 
variables do not exhaust all possibilities. First, we may have practical situations of random 
variables of mixed type, partially discrete and partially continuous. Second, we may also 
have random variables that are neither continuous nor discrete. This second possibility may 
appear at first as a mathematical pathology of some sort; nevertheless, there are random 
variables occurring in practice that have such pathological distributions.
■ EXAMPLE 5.19
An example ofa random variable of mixed type may be as follows. We purchase a piece 
of equipment (e.g., a light bulb). Its lifetime T is typically a continuous random vari­
able in the sense that T can assume any value from some interval; thus, any particular 
value T = t from this interval has probability zero. In addition the value T =0can be 
assumed with positive probability. In other words, the bulb may either be broken at 
the time of purchase (in which case T =0), or it may break at some future time t> 0, 
at which time the event {T = t} has probability zero. Consequently, the cdf of T is a 
function that equals 0 for all negative t, and is continuously increasing to 1 for positive 
t.Att =0the cdf is discontinuous, with F(0) > 0 being the probability of purchasing 
a broken light bulb.
Such mixtures of continuous and discrete distributions still do not exhaust all possibilities. 
This is illustrated by the following example, which is of theoretical interest:
■ EXAMPLE 5.20
We will now construct a cdf F(t) that is continuous, increases from 0 to 1, and is such 
that F'(t) = 0, except on a set of measure 0. The latter condition excludes the existence 
of density; that is, if the density exists, then it equals F' (t) almost everywhere. Thus, 
we have f (t) = 0 almost everywhere; hence, /+“ f (t) dt = 0. which means that F' is 
not a density.
The construction is based on the Cantor set. We let F (t) = 0 for t < 0 and F(t) = 
1 for t > 1. Next, we let F(t) = 1 /2 for 1 /3 < t < 2/3. On middle parts of intervals 
[0, 1/3] and [2/3, 1], that is, for 1/9 < t<2/9 and for 7/9 < t<8/9,weletF(t) = 1/4 
and F(t) = 3/4, respectively. This process is continued, and at each step, F(t) is the 
average of values on neighboring intervals in the middle one-third of the “gap.” The 
total length of intervals in [0, 1] where F is constant (hence where F' = 0) is
L =1 + 2 x 1 + 4 x — + ... = V -n = 1 x—^ = 1.
3 
9 
27 
3n+ 3n+1 
3 
1 - 2
n=0 
3
Moreover, one can easily show that F is continuous at each point. Thus, we have con­
structed a cdfofa random variable which is neither discrete nor continuous (it is called 
singular).
PROBLEMS
5.3.1 A die is biased in such a way that the probability of obtaining k dots (k =1, ...,6) 
is proportional to k2. Which number of dots is more likely: odd or even?
5.3.2 You have five coins in your pocket: two pennies, two nickels, and a dime. Three coins 
are drawn at random. Let X be the total amount drawn (in cents). Find: (i) The 
distribution ofX. (ii) P(X < 10|X < 15). (iii) The probabilities that two pennies are 
drawn, if it is known that X < 11.

112
RANDOM VARIABLES: UNIVARIATE CASE
5.3.3 Let X have the density f (x) = Ce 0•4'ж', —ж < x < + ж (such distribution is called 
Laplace or double exponential). Find C and then obtain: (i) P(X > -2). (ii) P(|X + 
0.5| < 1).
5.3.4 Let X have EXP(1) distribution. Moreover, let Y =[X] be the integer part of X, 
and let Z be the integer nearest to X. Find: (i) The distributions of Y and Z. 
(ii) P(Y = Z). (iii) P(Y =3|Z =4). (iv) P(Z =4|Y =3). (v) P(Y =4|Z =3). 
(vi) P(Z =3|Y =4).
5.3.5 Let X have EXP(A) distribution, and let Y and Z be defined as in Problem 
5.3.4. (i) Find P(Y = Z). (ii) Show that P(Y = k|Z = k+1)=P(Y = Z) for all 
k =0, 1,  (iii) Find P(Z = k +1|Y = k) for k =0, 1,  
5.3.6 Let X have EXP(A) distribution. Show that for s, t > 0 the following memoryless 
property holds: P{X>s+ t|X>s} = P{X > t}.
5.3.7 Let Xn be the difference (possibly negative) between the number of heads and the 
number of tails in n tosses of a coin. Find: (i) The distribution of X4. (ii) The cdf of X4 
at point x = -0.6. (iii) The probability that Xn is positive given that it is nonnegative 
for (a) n =4and (b) n =5.
5.3.8 Let X have the density f (x) = Cx for 0 < x < 1, f (x) = C(2 — x)/2 for 1 < x < 2, 
and f(x) = 0 otherwise. Find C and F (x). Compute the following probabilities and 
show them on the graphs of f (x) and F(x): (i) P(X > 3/2). (ii) P(|X — 1| < 1 /2). 
(Hint: The problem can be solved without integration, just using simple geometry.)
5.3.9 Let random variable X with the cdf F be uniformly distributed over the union of 
intervals (0, a) and (a +2,b). Assuming that F(4) = 0.2 and F(a +1)=0.25, find: 
(i) a and b. (ii) F (8.39). (iii) P (3.01 < X < 9.14). (iv) The probability that among 10 
values independently selected from this distribution, exactly two will be less than 4 
and exactly three will be larger than 17.
5.3.10 Light bulbs ofa certain type, manufactured by companies A, B, and C, have lifetime 
distributions EXP(1), EXP(2), and EXP(3), respectively. If bulbs are mixed in equal 
proportion in a box, find the probability that a randomly selected bulb will work for 
at least 1 year.
5.3.11 An oscillator sends the wave X(t) = A cos(2nt), where A = 1 or 2 with equal 
probabilities. We observe the value of X(t) at the point chosen at random from the 
U[n, n +1] distribution for some n. Find: (i) P(X(t) < 1). (ii) P (|X(t)| > 3/2). 
(iii) P(X(t) > 0).
5.4 FUNCTIONS OF RANDOM VARIABLES
In practical situations, we often deal with functions (or transformations) of random vari­
ables. Given the original distributions, we face the problem of determining the distributions 
of transformed random variables. The examples abound, starting from the simplest cases, 
such as a change of unit of measurement or a representation on the logarithmic scale. More 
complicated cases, discussed in Chapter 6, involve pairs of random variables such as conver­
sion of a pair of Cartesian coordinates of a random point on the plane to polar coordinates 
of this point, or ratios of coordinates. The latter case occurs, for instance, in determining the 
distribution of velocity, calculated as the ratio of distance to time, both subject to variability 
(either in the actual measured velocity or due to errors of measurements).

FUNCTIONS OF RANDOM VARIABLES
113
Another compelling reason to study transformations of random variables could be 
the generation of random numbers that follow a specific distribution. A typical method 
here involves transformations. Any statistical software (or often even pocket calculator) 
can generate random numbers from distribution uniform on [0, 1]. Then, the desired 
random variables are obtained as suitable transformations of uniform random variables. 
Obviously to apply such a method, it is necessary to develop techniques of determining the 
distributions of functions of random variables, at least of those uniformly distributed.
Finally, the third reason is related to statistics. Observations such as experimental results 
and values recorded in the sample are regarded as values of random variables. These are often 
summarized into global indices, such as the average. Each such index (generally referred to 
as a statistic) is a function of the sample values, hence a function of random variables, and 
for statistical inference it is vital to know the distributions of such indices.
We begin with the conceptually and technically simplest case of transformations of one 
discrete random variable.
Let X assume values in the set U = {x1, x2, ...}, with corresponding probabilities
pi = P {X = xi},
such that pi = 1. Then, Y = p(X), where p is a real-valued function, also has a discrete 
distribution. The following example illustrates how the distribution of Y = p(X) can be 
obtained:
■ EXAMPLE 5.21
Suppose that variable X has the following distribution
Value
- 2 
-1 
0 
1 
2
3
4
Probability
12 
111
10 
10 
10 
10 
10
2
10
2
10
If p (x) = x2, then Y = X 2, and the distribution ofY is
Value
01 
4
9
16
Probability
1 
1 । 2 
1 । 1
10 
10 + 10 
10 + 10
2
10
2
10
Function <p is not one to one, and therefore
P {Y = 4} = P {X2 =4} = P {X = 2} + P {X = - 2} = 110 + 110 •
P{Y =1} can be obtained similarly.
In general, we have
P{Y = У} = P{>(X) = У} = P{x : V(x) = У} = 
P{X = xi}
Xi: v (Xi ) = y
An analogous formula can be used for functions of two variables, that is, random variables of 
the form Z = p(X, Y), where the distribution of Z is expressed in terms of the distribution 
of X and Y. The principle here is very simple, as can be seen in the next example.
■ EXAMPLE 5.22
Let the experiment consist of two tosses of a regular die, and let X and Y be the 
result on the first and second toss, respectively. We want to find the distribution of 

114
RANDOM VARIABLES: UNIVARIATE CASE
Z = max(X, Y). Thus, the value of the function <p(x, y) equals x or y depending on 
whether x > y or y > x, and the random variable Z may be described as “the best out 
of two tosses.”
Clearly, Z may be 1, 2, ...,6, and it is simplest to find the distribution ofZ by listing all of 
the outcomes associated with each specific value of Z. Thus, Z =1only if (X, Y)=(1, 1); 
hence P{Z =1} = 1/36. Next Z =2ifthe outcome is (2, 1), (1, 2), or (2, 2) so that P{Z = 
2} = 3/36. Proceeding in this way, we get
Z
1 
2 
3 
4 
5 
6
Probability
1 
3 
5 
7 
9 
11
36 
36 
36 
36 
36 
36
It can be seen how “giving the second chance” improves the score. Larger values are much 
more likely than smaller values.
■ EXAMPLE 5.23
Let us continue Example 5.22, generalizing it to the case of n random variables (to 
be considered formally in Chapter 6). How large should n be to give a 99% or higher 
chance for the best of n tosses to equal at least 4?
SOLUTION. Let X1, X2, ...,Xn denote the result of consecutive tosses, and let Z = 
max(X1, ...,Xn). We want the smallest n with P{Z > 4} > 0.99. Let us therefore 
determine the distribution of Z, exhibiting its dependence of n. Direct enumeration 
was feasible for n =2, as in the preceding example, but it is cumbersome for a larger 
n. It is easy to find P{Z < k} for k = 1, ..., 6. First, {Z < 1} = P{Z = 1} = 1 /6n, 
since only one outcome among the total of 6n outcomes gives the maximum score of 
1. Next
{Z< 2}={max(X1,...,Xn) < 2}={X1 < 2,X2 < 2,...,Xn < 2},
and we have
P{Z < 2} = 2nn.
6n
In general,
kn
P{Z < k} = — for k = 1, ..., 6;
hence
P{Z = k} = P{Z < k}- P{Z < k - 1} = kn - (k-^n 
6n 
6n
Since P{Z > 4} > 0.99 means that
P{Z < 3} = 33^ < 0.01, 
6
we have to solve the inequality (1/2)n < 0.01. Taking n log(1/2) < log 0.01, we obtain
log 0.01 
n > MW
log 100 
log 2
= 6.64.
Thus, n = 7 tosses “practically guarantees” that at least one toss will lead to 4, 5, 
or 6.

FUNCTIONS OF RANDOM VARIABLES
115
We now consider the case of transformation of a single continuous random variable. Let 
F and f denote the cdf and density of X and let Y = p (X), where p is assumed to be at 
least piecewise differentiable.
Regardless of whether we want the cdf or the density, the best strategy is to start by finding 
the cdfofY. This method, occasionally referred to as the cdf technique, will be illustrated by 
some examples.
We begin with the simplest case, when p is a strictly monotone function. If p is increasing, 
we write for the cdf ofY:
Fy(y) = P{Y < y} = P{^(X) < y} = P{X < ф(y)} = Fx (ф(y)), 
where ф is the function inverse to ^.
The density is obtained by differentiating cdf, and consequently
fY ( у ) = d--X (Ф ( У )) = fx (Ф ( У )) Ф' ( У ) • 
(5.32)
dy
If ^ is monotonically decreasing, ф must be a decreasing function too, and
fy (У) = P{>(X) < У} = P{X > ф(У)} = 1 - Fx(ф(У))•
Therefore, 
fY (y) = -fx (ф (y)) ф' ( у ), 
(5.33)
a quantity that is positive, since now ф'(y) < 0. Together, (5.32) and (5.33) lead to the fol­
lowing theorem:
Theorem 5.4.1 If <p is a continuous differentiable function with inverse ф andX is a continuous 
random variable with density fX, then the density of Y = ^(X) is
fY (У ) = fx (ф (У))\ф' (У) |. 
(5.34)
■ EXAMPLE 5.24 Linear Transformations
Let Y = aX + b. If a > 0, we can write
y-b
Fy(y) = P{aX + b < y} = PiX < — 
= Fx
a
and
fY (y) = “ fx 
a
— b
a
y
If a<0,wehave
Fy(y) = P{aX + b < y} = Их > 
= 1 - Fx
a
and
fY (y ) = 
fx
a
— b
a
y
So for any a =0,
fY (y ) = и f4 y-—b\

116
RANDOM VARIABLES: UNIVARIATE CASE
The following transformation is important, both theoretically and practically. Let X have 
cdf F and density f, and let F be strictly increasing, so that F -1 exists. We consider the 
transformation Y = F (X). Obviously, 0 <Y <1, so the distribution of Y is concentrated 
on [0, 1]. We therefore have FY (y) = 0 for y < 0 and FY (y) = 1 for y > 1, while for 0 <y < 1 
we write
FY(y) = P{F(X) <y}=P{X < F-1(y)} = F(F-1(y)) =y.
Consequently, fY(y) = dyFY(y) = 1 on [0, 1], and we proved the next theorem.
Theorem 5.4.2 (Probability Integral Transform) If X has continuous strictly increasing cdf 
F, then the distribution of Y = F(X) is uniform on [0, 1].
This theorem may be formulated as follows: If Y has U[0, 1] distribution, then 
X = F-1 (Y ) has a distribution with the cdf F. Thus, we have obtained a method of 
generating random variables with given continuous invertible cdf F, using random variables 
uniform on [0, 1].
■ EXAMPLE 5.25
The assumption of monotonicity of ip (and hence also ф) is crucial for the validity of 
(5.34), except for the obvious remark that what is really needed is monotonicity “in 
the domain where it really matters.” Specifically, if C is the set of all points x at which 
f (x) > 0 (called the support of X), then it suffices that p is monotone only on C.
Consider the distribution with density
fx (x) = { о
for x > 0 
forx < 0,
and let p (x) = x2. Then, p is not monotone for all x, but it is monotone on the support of 
X, C = [0, ж). Thus, ф(x) = /x, ф'(x) = 1 /(2/x), and the density of Y = X2 is
fY (y)=
for y>0
for y < 0,
In the case where p is not monotone, we still have
FY(y)= P{Y < y} = P{^(X) < y},
but now p has no inverse, and the inequality p (X) < y is usually not equivalent to a single 
inequality for X . Still the right-hand side can, in most cases, be represented through the cdf 
FX evaluated at some points dependent on y. Differentiating, we can recover the density fY 
ofY.
This principle will now be illustrated by few examples.
■ EXAMPLE 5.26
Let X be a random variable with the density
fX (x)=
2.5 x4
0
for |x| < 1 
otherwise.
(5.35)

FUNCTIONS OF RANDOM VARIABLES
117
Let ^(x) = x2, so that now ^ is not monotone, and consider Y = ^(X). Since Y > 0, 
we have FY (y) =0 for y < 0, while for y > 0 we write
FY(y) = P{X2 < y} = P{-Vy < X <Vy} 
= Fx(Vy) - Fx(-Vy).
Differentiating, we get for y>0,
fY (y) = Fy(y) = [ fx(Vy) + fX (-Vy)] X TT~F,
so that (remembering that fx =0if x<-1 or x>1)
fY (y)=
2.5 y3/2
0
for 0 <y < 1 
otherwise.
■ EXAMPLE 5.27 Square of a Normal Random Variable
Let X have a normal distribution with the density
fx(x) = -1= e-x 2 / 2, 
2 2 n
and let ^(x) = x2 so that now ^ is not monotone. We have FY (y) =0 for y < 0, while 
for y>0 we write
FY(y) = P{X2 < y} = P{-Vy < X <Vy} = Fx(Vy) — Fx(—V).
Differentiating, we obtain
fY(y) = FY(y) = [fx(Vy) + fx(-Vy)] 
= -^y- 1 /2■ 
2 
(5.36)
y 
22n
for y>0,andfY (y)=0for y < 0.
This is a special case of a gamma density, given by the formula Cya-1e-by(y > 0), 
where a>0,b > 0,andC is the normalizing constant. Density (5.36) has a =1/2,b = 1/2. 
Gamma distributions with b =1/2 and a such that 2a is a positive integer form a family 
of chi-square distributions—very important in statistical inference. Both gamma and 
chi-square distributions will be discussed in more detail in following chapters.
■ EXAMPLE 5.28 Folded Normal Distribution
Let X be as in Example 5.27, and let now ^(x) = |x|. Then for y > 0,
FY(y)=P{|X|<y}=P{-y<X < y} = Fx(y) - Fx(-y),
and
fY (y ) = fx (y)+ fx (-y ) = /Л e-y 2 / 2, 
(5.37)
and fY (y)=0for y < 0. This distribution is sometimes also called half-normal.

118
RANDOM VARIABLES: UNIVARIATE CASE
PROBLEMS
5.4.1 IfX is the result of tossing a balanced die, find the distribution of: (i) Y =(X - 2)2. 
(ii) Z = |X - 2.5|.
5.4.2 Let X have the Poisson distribution with parameter A, and let Y = 2X. Find the 
distribution of Y.
5.4.3 Let X have a continuous distribution with cdf FX and density fX, such that FX (0) = 
0. Find the density of variables: (i) VX. (ii) log X. (iii) 1 /X. (iv) eX.
5.4.4 Let X be U[0, 1]. Find <p such that Y = <p(X) has EXP(A) distribution.
5.4.5 Let X haveEXP( A) distribution, and let Y = VX .Find: (i) The cdf and density of Y. 
(ii) The lower quartile ofY.
5.4.6 Assume that X has the standard normal distribution. Find the density of: (i) Y = 
X3. (ii) Y =(X - 1)3. (iii) Y = eX.
5.4.7 Find the density ofY = X(1 + X) ifX has U[0, 1] distribution.
5.4.8 Random variable X has density fX (x) = Cx4 for -2 < x < 1 and 0 otherwise. Find 
the density ofY = X2 (follow Example 5.26).
5.4.9 Let X have U[-1, 1] distribution. Find the distribution of: (i) Y = |X|. 
(ii) Z =2|X|-1. (iii) Solve (i) and (ii) if the distribution of variable X is U[-1, 2].
5.4.10 The duration (in days) of the hospital stay following a certain treatment is a ran­
dom variable Y =4+X,whereX has a density f(x) = 32/(x +4)3 for x>0. Find: 
(i) The density ofY. (ii) The probability that a randomly selected patient will stay in 
the hospital for more than 10 days following the treatment.
5.4.11 Let X have density f(x) = 2(1 - x), 0 < x < 1. Find the density of: (i) Y = 
X(1 -X). (ii) W = max(X, 1 -X).
5.4.12 Suppose that the measured radius R is a random variable with density
2 f 12x 2(1 — x) for 0 < x < 1
fR(x) = 
R 
0 
otherwise.
In a circle with radius R, find the cdf of: (i) The diameter. (ii) The area.
5.4.13 The speed ofa molecule of gas at equilibrium is a random variable X with density
f (x) = / kx2'' bx2 for x > 0
0 
otherwise,
where k is a normalizing constant andb depends on the temperature of the gas and the 
mass of the molecule. Find the probability density of the kinetic energy E = mX2/2 
of the molecule.
5.5 SURVIVAL AND HAZARD FUNCTIONS
In this section, we consider a special class of random variables that are particularly important 
in medical research (survival analysis) but also in engineering (reliability analysis) and social 
sciences.

SURVIVAL AND HAZARD FUNCTIONS
119
These variables can serve as possible models for lifetimes of living organisms or of some 
equipment. They may denote the actual lifetime (i.e., time until death or equipment failure) 
or time until some event (e.g., recovery from a disease). Such random variables, denoted 
usually by T , are continuous and nonnegative.
Let F and f denote the cdf and density of T so that for t > 0,
FT(t) = P{T < t} = t f (u) du 
(5.38)
0
[the integration starts at 0, since nonnegativity of T implies that P{T < 0} = 0, and hence 
f(t)=0for t<0]. Moreover, let
S(t) = 1 - F(t) = P{T >t} = j f (u) du 
(5.39)
be the survival distribution function (or survival function) of the random variable T.
We introduce the following definition:
Definition 5.5.1 The function
d ln S(t) 
h (t) =-----dt, 
(5.40)
defined fort>0 and S(t) > 0, is called the hazard rate (or intensity rate) function of random 
variable T. 
□
By differentiating - ln(1 - F (t)), it follows from (5.40) that at almost all points t we have 
h (t )=W) . 
(5.41)
The following theorem expresses the cdf through the hazard function:
Theorem 5.5.1 If h(t) is a hazard function of a random variable T, then its cdf equals 
F(t) = 1 - e- ft h(u) du.
Proof: The proof is immediate, by integrating (5.41) between 0 and t. 
□
The interpretation of hazard functions is as follows: h(t) dt can be approximated by 
f (t)dt 
P{t <T < t + dt}
S(t) ~ 
P{T > t} 
;
hence, by the definition of conditional probability, 
h(t)dt « P{t <T < t + dt\T > t} 
= P {lifetime ends before t + dt | lifetime is longer than t}.
In other words, h(t) is the death rate at t of those who survived until t (are “at risk” at t). 
Thus, the hazard function describes the process of aging in terms of changes of risk of death 
with current age.
■ EXAMPLE 5.29
Let the random variable X have EXP (a) distribution. Then, F(t) = 1 - e-at, S(t) = 
e-at, and 
a- 
ae-at
h (t) = 
= a.

120
RANDOM VARIABLES: UNIVARIATE CASE
Thus, the exponential distribution describes the lifetime distribution in the case of lack 
of aging, when the risk of death does not change with age.
■ EXAMPLE 5.30
Suppose that you buy a new car, and let T be the time of the first breakdown. Typically, 
h(t) is initially high, and then declines to a constant. It remains at this level for several 
years, eventually beginning to increase.
The reason is that early failures are typically caused by hidden faults of material, 
undetected in factory control. If they do not show up immediately, then there are prob­
ably no faults, and risk of failure remains constant for some time. The later increase is 
due to the wearing out of various parts.
In an engineering context, especially in problems of reliability of equipment, the hazard 
function is often called failure rate function.
Assuming that F (t) < 1 for all t (which is the most important case of interest), we can 
write
F(t)=1- e-H(t), 
(5.42)
where H(t)=- log[1 - F (t)]. On the other hand, in view of Theorem 5.5.1, we also have 
H(t) = Jo h(u) du, which gives (5.24). Since F(t) ^ 1 as t ^ ж, we must have
oO
h(u) du = ж. 
(5.43)
o
Example 5.29 shows that the exponential distribution has a constant hazard, interpreted as 
lack of aging. If hazard is increasing, we have the phenomenon of aging (“new better than 
old”), while the opposite is true in case of decreasing hazard (“old better than new”). A 
flexible model of both situations is given by the following definition:
Definition 5.5.2 A nonnegative random variable T with the hazard rate
h (t) = KtY, 
t > 0, K > 0 ,y > -1 
(5.44)
is said to have a Weibull distribution. 
□
Observe first that the condition y > —1 ensures that the relation (5.43) holds so that T is 
a genuine random variable in the sense that
lim P{T < t} = 1
t—>O
(i.e., T = ж is excluded). For reasons of tradition and convenience, one usually puts a = 
K/ (y + 1), в = Y + 1, so that the hazard rate of Weibull distribution takes the form
h(t) = aete 1, 
a> 0,в> 0,t > 0•
(5.45)
PROBLEMS
5.5.1 Find the hazard function of the U[0, 1] distribution. Explain why h(t) is unbounded.
5.5.2 Find the density and survival function of the distribution with hazard rate h(t)=a + 
bt for t > 0, a > 0, b > 0.

SURVIVAL AND HAZARD FUNCTIONS
121
5.5.3 Let X be a random variable with density
0
f (x) = < 0.5
x<0
0 < x < 1
x>1.
(i) Find q if a is known. (ii) Find hazard h(t) and survival function S(t).
5.5.4 Find the cdf and density of Weibull distribution with the hazard function (5.45).
5.5.5 Assume that the fuel pumps in a certain make of cars have lifetimes with a Weibull 
hazard rate 2/ 
(t measured in years). Find the probability that a fuel pump is still
working after 5 months.
5.5.6 Let two distributions with densities f 1 and f 2 have constant hazard rates A 1 and A2 = 
aA 1, respectively. Show that S 1(t) = S2(t)a, if S 1(t) and S2(t) are respective survival 
functions.
5.5.7 The series system is built in such a way that it operates only when all its three 
components operate (so it fails when at least one component fails). Assuming that 
the lifetime of each component has EXP (1) distribution and that the components 
operate independently, find the distribution and hazard function of the system’s 
lifetime T .
5.5.8 A cancer specialist claims that the hazard function of random variable Tc = “age at 
death due to cancer” is a bounded function which for large t has the form hc(t) = k/t2 
(where t is the age in years and k is some constant).
Assume that h(t) is the hazard of the time of death due to other reasons than cancer 
(other diseases, accidents, old age, etc.). If Tc and T are times of death with haz­
ards hc(t) and h(t), assume that the observed time of death is T* = min(Tc, T), with 
max(Tc ,T) being unobservable. To get an insight into the feasibility of the assump­
tion of the cancer specialist in question, imagine that all reasons of death other than 
cancer have been eliminated (i.e., H(t) = 0) and find the probability that a person will 
live forever.

CHAPTER 6
RANDOM VARIABLES: MULTIVARIATE 
CASE
6.1 BIVARIATE DISTRIBUTIONS
The considerations of Section 5.2 can be extended to the case of several random variables 
analyzed at once, or equivalently, to the analysis of vector-valued random variables.
In the simplest case, we have a pair of random variables (X, Y ), that is, a pair of functions 
on the sample space S.
■ EXAMPLE 6.1
Let the experiment consist of three tosses of a coin, and let X = number of heads in 
all three tosses and Y = number of tails in the last two tosses. The sample space S and 
corresponding values of X and Y are then
S
X
Y
5
X
Y
HHH
3
0
TTH
1
2
HHT
2
1
THT
1
1
HTH
2
1
HTT
1
1
THH
2
0
TTT
0
2
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
123

124
RANDOM VARIABLES: MULTIVARIATE CASE
We can summarize all the possible values of (X, Y ) and their probabilities in the 
following table:
X/Y
0
1
2
0
0
0
1
8
1
0
2
8
1
8
2
1
8
2
8
0
3
1
8
0
0
The entries in the table represent the corresponding probabilities. For instance, 
P {X =2,Y =1} =1/4 was obtained by counting the number of points s of 
the sample space such that X(s)=2 and Y (s)=1 (there are two such points: 
HHT and HTH). To simplify the notation, we will be using commas to denote the 
intersection of events. Thus, we write P {X = x, Y = y} instead of rather clumsy 
P [ {X = x}(Ж = y} ] •
In a natural way, this example leads to a definition ofa discrete bivariate random variable.
Definition 6.1.1 We say that the pair (X, Y ) of random variables has a discrete distribution 
if there exist finite or countable sets A and B such that
P{(X,Y) & A x B} = £ P{X = x,Y = y} = 1 • 
□
x- Ay B
In Example 6.1, we have A = {0, 1, 2, 3} and B = {0, 1, 2}. Obviously, P{X = x, 
Y = y} =0if any of the values x or y lie outside the set A (respectively, B), but it is also 
possible that P{X = x, Y = y} =0for some x & A and y & B. For instance, in Example 
6.1, we have P{X = 0,Y = 1} = 0• In other words, the values (x,y) that have positive 
probability can form a proper subset of A x B^
The continuous bivariate distributions, as may be expected, are defined through their den­
sities.
Definition 6.1.2 Random variables (X, Y) are jointly continuous (or have joint continuous 
distribution) if there exists a function f(x, y) such that for every rectangle
C = {(x, y) : a < x < b,c < y < d}
with —ж < a < b < ж, —ж < c < d < ж we have
P{(X,Y) &C}= 
f (x,y) dxdy^ 
(6.1)
The function f is called joint or bivariate density of (X, Y). 
□
Some comments are in order here. First, as in the univariate case, the density is defined 
only up to sets of measure zero (e.g., single points or arcs on the plane).
Second, the obvious consequences of Definition 6.1.2 are
f(x, y) dxdy =1, 
(6.2)

BIVARIATE DISTRIBUTIONS
125
where R2 is the plane, and
f (x,y) > 0 
almost everywhere.
(6.3)
These relations are obvious analogues of (5.22) and (5.25) for univariate densities.
The third comment is as follows: Formula (6.1) only covers rectangles. In the analogy with 
Theorem 5.2.5, it can be shown that probability P defined on the class of rectangles by (6.1) 
determines its unique extension to all sets in the plane that can be approximated through 
countable operations on rectangles, in particular to all figures that can be triangulated, as 
well as to circles, ellipses, and so on. In other words, formula (6.1) holds for a much wider 
class of sets C on the plane.
Conditions (6.2) and (6.3) allow us to use the Fubini theorem and replace the double 
integral (6.1) by the iterated integral, thus making actual integration possible. In particular, 
if C is the rectangle specified in Definition 6.1.2, then
P {( x,y ) e C} = У £f(x, y) dxdy
f(x, y) dy
In general, we have
Il f(х,У) dxdy = I ф(У) dy = I Ф(x) dx. 
C 
C2 
C1
Here C1 and C2 are “shadows” of C on the x-axis and y-axis, that is, C1 = {x :(x, y) e C} 
for some y and C2 = {y :(x, y) e C} for some x. Also
Ф(x) = У f(x,y) dy, 
^(У) = j f (x,y) dx
with Cx = {y :(x, y) e C} and Cy = {x :(x, y) e C} being sections of C at points x and y, 
respectively (see Figure 6.1). To understand well the difference between the double integral
f(x, y) dxdy
Figure 6.1 Shadows and sections of domain C of integration.

126
RANDOM VARIABLES: MULTIVARIATE CASE
and iterated integrals
Z
+ то у+то f(x,y) dx dy,
то -то
interpreted as
f(x, y) dx dy and
f(x, y) dy dx,
the readers are advised to consult a good calculus text for the respective definitions. The 
Fubini theorem gives conditions under which all three integrals are equal (we will discuss 
these topics in Chapter 7). It is both easy and worthwhile to explain the issues involved here, 
using a simplified situation of a series (instead of integrals). Thus, ^2TO=1 an is defined as 
limn ,TO n=1 ak, provided that this limit (of a well-defined numerical sequence) exists. By 
the same argument, the double sum TO=ТО=1 52TO=1 amn is defined unambiguously (this sum 
is an analogue of the iterated integral). However, the symbol ^2TOn=1 amn (the analogue 
of a double integral) is not well defined, since it does not specify the order in which the 
two-dimensional array {amn} is to be added. The point here is that the sum of an infinite 
sequence of numbers may depend on the order of summation. Thus, some assumptions about 
{amn} are needed to make the last sum independent of the order of summation. Under these 
assumptions (e.g., nonnegativity) the double sum and both iterated sums are either all infinite 
or all equal to the same finite number.
A similar kind of difficulty appears in the case of double and iterated integrals and is 
resolved by the Fubini theorem.
We will now illustrate the calculation of probabilities by some examples.
■ EXAMPLE 6.2
The density f (x, y) is given by the formula
f (x, y) = ( cx(x + y) if x - 0, y - 0,x + y - 1 
(6.4)
0 
otherwise.
Find P{X - 1/2}.
SOLUTION. The first objective is to determine the constant c in formula (6.4). As 
usual, the normalizing condition (6.2) provides the key here:
1=
cx(x + y ) dx dy =
c(x2 + xy) dx dy
'1-eL + <1—&U = c, 
3 
2 
8
so c =8.
Now, P{X - 1/2} is the integral of the density f(x, y) over the dark area in 
Figure 6.2. This time it is simpler to integrate over y first,
1/2 
1-x
0
P{X - 1/2} = 
8x(x + y) dx dy =8
D0
=8L 
(x2y+xy211 xx)'
1 x3 
x2 
1
=cL (■»+уy|0 Оdy=cL
= 8 [ 
x2(1 — x)+— x(1
02
7
16'
x)2 dx =

BIVARIATE DISTRIBUTIONS
127
1
y
0.5
1
Figure 6.2 Support of density f and the set {X < 1 /2}.
x
Although used not as often as in the univariate case, the cumulative distribution function 
(cdf) is still the most general way of specifying probabilities in the bivariate case, regardless 
of whether the distribution is discrete, continuous, or neither. We introduce the following 
definition:
Definition 6.1.3 The function of two real variables, defined as
F(x, У) = P{X < x,Y < y}
is called the cdf of the pair (X, Y) of random variables.
□
The relation between cdf and the probability mass function in the discrete case, or the 
density function in the continuous case, is similar to those for univariate random variables:
F(x, y)= 
P{X = xi,Y = yj}
Xi<x,yj <У
in the discrete case, and 
x y
F(x, y)= 
f(u, v) dv du
-— tt-— tt
(6.5)
in the continuous case. In particular, from (6.5) it follows that for almost all (x, y), we have
f(x, y)= d 2 F (x,y) 
dxdy
This brings us to the following analogue of Theorem 5.2.2:
Theorem 6.1.1 Every bivariate cdf F(x, y) has the following properties:
(a) lim x,y ■+x (Х,У ) = 1 •
(b) For every y, F(x, y) is nondecreasing and continuous from the right in x.
(c) For every x, F (x, y) is nondecreasing and continuous from the right in y^
(d) limx ,-xF(x, y) =0 for every y, and limy ,-xF(x,y) =0 for every x^ 
(e) For all x1 <x2 and y1 <y2,
F ( x 2 ,y 2) - F ( x 2 ,y 1) - F ( x 1 ,y 2 ) + F ( x 1 ,y 1) > 0 •
(6.6)

128
RANDOM VARIABLES: MULTIVARIATE CASE
We omit the proof here, leaving the proofs of some of the properties as exercises. The 
following comments, however, are important. While conditions (a)-(d) are direct analogue 
of the properties of univariate cdf’s, condition (e) has no counterpart. The question therefore 
arises whether conditions (a)-(d) alone characterize bivariate cdf’s. In other words, is every 
function satisfying (a)-(d) a cdf of some pair (X, Y) of random variables? The answer is 
negative, as shown by the following example:
■ EXAMPLE 6.3
Let F (x, y) be defined by the formula
F (x, y)= 1
0
if x + y > 0 
ifx + y<0.
(6.7)
It is easy to check that function (6.7) satisfies conditions (a)-(d) given above. Sup­
pose that F (x, y) is the cdf of a pair of random variables, and let us compute the 
probability (see Figure 6.3), P {-1 < X < 2, -1 <Y < 2}.
Figure 6.3 A function that is not a cdf but satisfies (a)-(d).
F(x, y) = 1
Since F (x, y) is the probability of the pair (X, Y) taking a value “southwest” of 
(x, y) [i.e., to the left and below (x, y)], we have
F(2,2) -F(-1,2)-F(2,-1)+F(-1,-1) = 1-1-1+0=-1,
so that F (x, y) cannot be a cdf.
Condition (e) is necessary, since the left-hand side of (6.6) equals P{x1 <X < x2 ,y1 < 
Y < y2 } and hence must be nonnegative.
It turns out (we omit the proof here) that (a)-(e) characterize a bivariate cdf. This means 
that any function satisfying (a)-(e) is a cdf of some pair of random variables.
PROBLEMS
6.1.1 A regular die is tossed twice. Find: (i) The joint distribution of vari­
ables X = the total of both outcomes and Y= the best of the two out­
comes. (ii) P(X < 8,Y< 5); P(X =9,Y< 2), P(4 < X < 7, 1 < Y < 3). 
(iii) P(Y =3|X =4),P(Y<6|X =7),P(4 <Y< 6|X < 8).

MARGINAL DISTRIBUTIONS; INDEPENDENCE
129
6.1.2 Let X, Y have the joint distribution given by the following table:
X/Y
2
3
4
0
1
48
0
b
1
0
5
8
48
48
2
a
0
11
48
3
5
48
12
48
0
(i) Find a and bifitisknownthatP(X = Y)=1/3. (ii) Find P(XY =0). (iii) If F 
is the cdf of (X, Y), find F (-1.5, 3), F (0.7, 2.11), and F (1.5, 18).
6.1.3 A regular die is tossed twice. Let X be the number of times that 1 came up, and 
Y be the number of times 2 came up. Find: (i) The joint distribution of X and Y . 
(ii) The correlation coefficient between events {X =1} and {Y = 2}. [Hint: See for­
mula (4.17) in Definition 4.5.2.]
6.1.4 Let the joint cdf of random variables X, Y be F(x, y) = (1/48)xy(x +2y) for 
0 < x < 2, 0 < У < 3. Find the density f (x, y).
6.1.5 The joint density of X and Y is f (x, y) = y2(xy3 + 1) on the rectangle 0 < x < k, 
0 < y < 1. Find: (i) k. (ii) P(X < Y).
6.1.6 Assume that X, Y have density f (x, y) = x + y for 0 < x < 1 and 0 < y < 1, and 
f (x,y) = 0, otherwise. Find P{Y < ^X}.
6.1.7 Assume that (X, Y) have the joint density f(x, y) = cxy2 for 0 < x < 1, 0 < y < 1, 
and f(x, y)=0, otherwise. Find: (i) c. (ii) P{X2 < Y < X}. (iii) The cdf of (X, Y).
6.1.8 Let the joint density of random variables X, Y be f(x, y) = cx3y2 for 0 < x < 1, 
x2 < y < 1 and f(x, y)=0, otherwise. Find P(X < Y).
6.1.9 Variables X and Y have the joint density f(x, y)=1/y for 0 <x<y<1 and 
f(x,y) = 0, otherwise. Find: (i)P(X+Y>0.5). (ii) P(Y > 2X).
6.2 MARGINAL DISTRIBUTIONS; INDEPENDENCE
One can naturally expect that the bivariate distribution (in the form of cdf, joint density, or 
probability mass function, as the case might be) contains more information than the uni­
variate distributions of X and Y separately. Given a bivariate distribution, we are able to 
recover both univariate distributions of X and of Y, but not conversely.
We begin with the case of discrete bivariate distributions. Let A = {x1, x2, ...} and 
B = {y1, y2, ...} be the sets of possible values ofX and Y, respectively, and let
pij =P{X=xi,Y=yj}. 
(6.8)
Our objective is to express the distributions of X and of Y through pij . Since the events 
{Y = y1}, {Y = y2}, ... form a partition (i.e., in the sense defined in Chapter 4, these events 
are mutually exclusive and one of them has to occur), we may write for every i,
{X = xi} = U[{X = xi} n {Y = yj} ] = U{X = xi,Y = yj}-

130
RANDOM VARIABLES: MULTIVARIATE CASE
Since the events on the right-hand side are disjoint, we have
P {X = xi} = P {X = xi,Y = yj } = 
Pij.
In a similar way, P{Y = yj } = 
ipij. We now introduce
Definition 6.2.1 Given the joint distribution (6.8), the distributions ofX alone and Y alone, 
calculated from the formulas
P{X = xi} = 
pij = pi+ ,P{Y = yj } = 
pij = p+j,
will be referred to as marginal distributions. 
□
Ifwe think of numbers pij as arranged into a matrix, then P{X = xi} and P{Y = yj} are 
sums of its corresponding rows (or columns). Since the sum of all pij equals 1, both marginal 
distributions satisfy the condition that the sum of their probabilities equals 1.
■ EXAMPLE 6.4
In Example 6.1, we considered three tosses of a coin, with X being the number of 
heads in all three tosses, and Y being the number of tails in the last two tosses. The 
joint distribution of X and Y is summarized by the following table:
X/Y
0
1
2
X
0
0
0
1
8
1
8
1
0
2
1
3
8
8
8
2
1
8
2
8
0
3
8
3
1
8
0
0
1
8
Y
1
4
1
2
1
4
1
In the margins, we have the row sums and column sums. The distribution of X is
P {X = 0} = P {X = 3} = 1, 
P {X = 1} = P {X = 2} = 3,
88
while the distribution of Y is
P {Y = 0} = P {Y = 2} = 4, 
P {Y =1} = 1.
The adjective marginal refers to the way in which the distribution was obtained; it implies 
nothing about the properties of the distribution. The definition of marginal distribution for 
continuous random variables is analogous, with summation replaced by integration:
Definition 6.2.2 If (X, Y) is a pair of continuous random variables with bivariate density 
f (x, y), then the functions
f1(x) = 
f(x, y) dy and f2(y) = 
f(x, y) dx
— -ж 
-—oo
are called the marginal densities of variables X and Y, respectively. 
□

MARGINAL DISTRIBUTIONS; INDEPENDENCE
131
The justification of Definition 6.2.2 consists of two parts. First, we need to show that f1 
and f2 are densities, meaning that they are nonnegative for almost all arguments (i.e., for 
all arguments, except a set of arguments of measure zero) and that f1 and f2 integrate to 1. 
These properties are immediate consequences of the fact that f (x, у) > 0 except possibly on 
a set of measure zero. Consequently, using the Fubini theorem, we can write
1= [ [ f (x,y) dx dy = [ 
[ 
f (x,y) dx
-J 
-—^{J—OQ
dy
Z
+ <X>
f2 (y) dy,
O
and similarly for f1 .
The second part of justification of Definition 6.2.2 consists of showing that, for instance,
P{a < X < b} = j fi(x) dx.
Here we can write
b
b
+O
a
a
O
f(x, y) dxdy
a aа<х<ь ,—O<y<+O
= P{a < X < b, —x < Y < + to} = P{a < X < b}.
■ EXAMPLE 6.5
A man shoots at a circular target. Assume that with his skills he is certain to hit the 
target and that the probability of hitting a particular part of the target is proportional 
to the area of this part. If X and Y be the horizontal and vertical distances from the 
center of the target to the point of impact, find the distribution of X .
SOLUTION. Without a loss of generality, we can introduce the coordinate system 
with the origin in the center of the target. Let us assume that its radius is R. Then the 
target is described as x2 + y2 < R2. From the conditions of the problem, it is seen that 
the density of the point of impact is constant on the target so that
c
f(x, y)= 
0
if x2 + y2 < R2 
otherwise.
Next, the condition 
R2 f(x, y) dx dy = 1 implies that c must be the reciprocal of
the area of the target; hence, c =1 /nR2.
If |x| > R, then f (x, у) = 0 for all у(see Figure 6.4). For lx| < R, we have f (x, у) = 
0 when x2 + у2 >R2 (hence if |y| > v^R2 — x2), and f (x,y) = 1 /nR2 when x2 + у2 < 
R2 (so y <\/R2 — x2). Consequently, for |x| < R,
R—2 — x 2
1 
w R2 — x2
nR2 dy = 
nR2
— ^ —2 —x 2
The density fi(x) has the shape given in Figure 6.4.

132
RANDOM VARIABLES: MULTIVARIATE CASE
Figure 6.4 Marginal density.
At this point, we need to comment on notation. The symbols f1(x) and f2(y) for marginal 
densities of X and Y are used in the literature together with more readable symbols such as 
fX (x) and fY (y), with the name of the variable appearing as a subscript. This latter system 
becomes cumbersome when the variables are labeled X1 and X2 instead of X and Y , since 
logically one should then use fX (x) and fX (y). We will deliberately avoid keeping rigidly 
to any fixed system of notation, and use whichever notation appears most natural in a given 
instance. Another problem concerns the use of an argument in the density or cdf. It appears 
natural to label the argument x in density or cdf of X ,labelity in density of Y, and so on. 
However, it is not possible to use such notation consistently: Indeed, if F (x) and f(x) are 
to be used as the cdf and density of X, then we have F(x) = fx^ f (u) du, and in the inte­
grand we can use almost any symbol except x, since the symbol -x\.x f (x) dx is unacceptably 
ambiguous.
We will now define the concept of independence of two random variables. We 
recall that the independence of two events A and B is defined by the product rule 
P(A П B) = P(A) P (B) (see Chapter 4). A random variable X allows us to define events of 
the form {X e A}, where A is some set of real numbers, and the same is true for the random 
variable Y . It seems natural to require that these events be independent for independent 
random variables X and Y .
Definition 6.2.3 (Intention of the Concept) We say that random variables X and Y are inde­
pendent if events {X e A} and {Y e B} are independent for all sets A, B, that is, if
P{X e A, Y e B} = P{X e A}P {Y e B}. 
(6.9)
□
This definition, as spelled out in its label, concerns the “final effect” of the concept: inde­
pendence of every pair of events in a very large class of such pairs. Clearly, using this definition 
to check independence would be very difficult if we were to verify the product rule (6.9) for 
every pair A, B . Consequently, it becomes necessary to find a condition that is verifiable and 
strong enough to imply independence in the sense of Definition 6.2.3. It turns out that it is 
sufficient to require only a seemingly weaker condition.
Definition 6.2.4 (Verifiable Definition of Independence) The random variables X and Y are 
said to be independent if their joint and marginal cdf’s satisfy the following condition: For 
every x, y we have
F(x,y) = F1(x)F2(y), 
(6.10)
where F1(x) and F2(y) are marginal cdf’s of X and Y, respectively. 
□

MARGINAL DISTRIBUTIONS; INDEPENDENCE
133
In the case of discrete random variables with pij being the probability P {X = xi ,Y = 
yj}, condition (6.10) is implied by
pij = pi+ p+j 
for every i,j. 
(6.11)
For continuous random variables, the condition implying (6.10) calls for marginal densi­
ties f1 and f2 to be such that
f(x,y) = f1(x) f2 (y) 
(6.12)
for all x, y, except possibly for a set of points (x, y) of measure zero.
The intuition behind the concept of independence of random variables (analogous to the 
intuition behind the concept of independence of events) is that the information about the 
value of one of them provides no information about the value of the other. Random variables 
for which independence conditions are not satisfied will be called dependent.
■ EXAMPLE 6.6
Let us go back to Example 6.1. In the table of joint and marginal Distribution, we had
P{X = 3,Y = 2} = 0, while P{X = 3} x P{Y = 2} = 1 x 4 = 0. This means that
X and Y are dependent random variables.
■ EXAMPLE 6.7
Let us consider again the case of three tosses of a coin. Let U be the number of heads 
in the first two tosses, and let V = be the number of tails in the last toss. The sample 
points are
S
U
V
5
U
V
HHH
2
0
HTT
1
1
HHT
2
1
THT
1
1
HTH
1
0
TTH
0
0
THH
1
0
TTT
0
1
The joint and marginal probability distributions are
U/V
0
1
U
0
1
1
1
8
8
4
1
2
2
1
8
8
2
2
1
1
1
8
8
4
V
1
2
1
2
1
A direct check shows that we have
P{U = x, V = y} = P{U = x}xP{V = y}
for every cell (x, y) in the table above. This shows that U and V are independent.
Verification that two random variables are independent requires checking the multiplica­
tive property (6.11) or (6.12) for all x and y. In the last example, this required comparing 
joint probabilities with the products of probabilities in marginal distributions for all six cells 

134
RANDOM VARIABLES: MULTIVARIATE CASE
in the joint distribution table. Such a direct verification is not feasible except for discrete 
variables with small sets of possible values. To handle more complicated cases, we typically 
must have some algebraic formula for the joint distribution from which we can calculate the 
marginal distributions and verify the product rule algebraically. On the other hand, to show 
that two variables are dependent (i.e., that they are not independent), it is enough to find one 
pair (x, y) for which the product rule does not hold.
A practical consequence here is that it is generally worthwhile to try to determine based 
on the meaning of the variables in question, whether or not we can expect them to be inde­
pendent. This determines the strategy: Do we aim at checking that variables are independent, 
or do we aim at showing that they are dependent? These two goals may require somewhat 
different types of technique.
To illustrate the point, in Example 6.6, we could have expected the variables to be depen­
dent: the more tails in the last two tosses (Y ), the lower one can expect the total number of 
heads (X) to be. In particular, we may be able to find a “pure exclusion,” such as the fact 
that one cannot have X =3and Y = 2 simultaneously, while separately each of these events 
has positive probability.
On the other hand, in Example 6.7 we could have expected U and V to be independent, 
since the values of U and V were determined by nonoverlapping sets of tosses. In particular, 
the following criterion is useful in showing that two variables are not independent.
Theorem 6.2.1 If the table of joint probabilities for (X, Y ) contains a zero entry, then X and 
Y are dependent.
Proof : Suppose that P {X = x0 ,Y = y0} =0. Since x0 and y0 have positive probabilities, 
P(X = x0) x P(Y = y0) is positive and (6.11) is not satisfied. 
□
This criterion provides a quick “visual” test for lack of independence. Of course, it works 
only in one direction: if there are no zeros in the table of joint distribution, the variables may 
or may not be dependent, and further checking is necessary.
We will now consider some examples of applications of Definition 6.2.4 for the case of 
continuous random variables.
■ EXAMPLE 6.8
The joint density of random variables X and Y is
f cxne-ax-ey 
for x > 0, y > 0
f(x, y)= 
0 otherwise.
The question is whether these random variables are independent.
SOLUTION. It is interesting that the answer here does not require any calculations. 
In particular, we do not need to calculate c. We can simply represent the joint density 
on the positive quadrant as
f (х,У) = c1xne ax x c2e ey
(6.13)
with c1 and c2 such that
c 1 ( xne-ax dx = 1
0
and 
c2 [ e ey dy = 1
0

MARGINAL DISTRIBUTIONS; INDEPENDENCE
135
(then automatically c = c1c2). The two factors on the right of (6.13) must be marginal 
densities (why?), and we showed independence of X and Y . However, for the joint 
density f (x, y) to factor into the product of two functions, each depending on one 
variable only, is not enough to warrant the independence of variables X and Y , since 
the marginal densities depend on the shape of the support of the joint density (i.e., the 
set of points where f(x, y) is positive). To see it, consider the following example.
■ EXAMPLE 6.9
Let the joint density be
{
cxy2 if x > 0, y > 0 ,x + y < 1
0 otherwise.
At first glance, the situation here is similar to that in Example 6.8, but it is not. The 
marginal distributions are not c1x and c2y2 for any c1 and c2. Indeed, (see Figure 6.2 
for limits of integration):
f i(x)= [ 
f (x,y) dy = [ 
0 dy + [ cxy2 dy + [ 
0 dy
— ж 
—ж 
0 
1 — x
cx(1 - x)3
= 
3
for 0 <x<1, and f1(x) = 0 for x>1 and x<0. Similarly, f2(y)=0if y>1 or y< 
0, and for 0 <y < 1,
f2(y) = 
f (x, y) dx = 
.
Since f(x, y) = f1(x)f2(y), the random variables are dependent.
We can now formulate
Theorem 6.2.2 Assume that the joint density f(x, y) is continuous, and let f(x,y) > 0 for 
(x, y) & A. If A is not a Cartesian product A = AX x AY, then variables X and Y are depen­
dent.
Figure 6.5 Condition for dependence.

136
RANDOM VARIABLES: MULTIVARIATE CASE
Proof : The marginal densities f1 and f2 are strictly positive in the “shadows” AX 
and AY of the set A on the x-axis and y-axis (see Figure 6.5). If A is not equal to the 
Cartesian product AX x AY, then there exists a point (x0,y0) with x0 A AX,y0 A AY, 
and (x0,y0) / A. If x0 e AX, then there exists y* such that (x0,y*) A A, and therefore 
f(x0,y*) > 0. Since f is continuous, it must be positive in some neighborhood of 
(x0, y*), and therefore, f1 (x0) = f (x0, y) dy > 0. Similarly f2(y0) > 0. Consequently, 
0 = f(x0, y0) = f1(x0)f2(y0) > 0. The continuity of f(x, y), and hence of f1(x)f2(y), 
implies now that f (x, y) = f 1 (x) f 2 (y) on a set of a positive probability. 
□
While the continuity of f(x, y) is sufficient for the criterion given by Theorem 6.2.2, it is 
not necessary. However, it ought to be mentioned here that this criterion should be applied 
with some caution if f is not continuous, since f(x, y) is defined only up to sets of mea­
sure zero.
■ EXAMPLE 6.10
In Example 6.9, the set A is a triangle with vertices (0, 0), (1, 0), and (0, 1),soitcanbe 
inferred without any calculations that X and Y are dependent.
At the end of this section, let us make the following important remark. The formulas (6.9) 
through (6.12) from Definitions 6.2.3 and 6.2.4 can be used in two ways. The first is as illus­
trated so far: to determine whether or not two variables are independent. However, a more 
frequent use of these formulas is to find the joint distribution (joint density, joint cdf, etc.) 
of independent variables X and Y .
x2
1 -
0.75 -
0.75 
1
Figure 6.6 Probability of better of two attempts exceeding 0.75.
■ EXAMPLE 6.11
An athlete makes two attempts at some goal. His performance X at the first 
attempt, measured on the scale from 0 to 1, is a random variable with density 
f1(x) = 12x2(1 - x). His performance Y at the second attempt is independent of X, 
and generally tends to be lower; its density is f2(y) = 6y(1 - y), 0 < y < 1. What is 
the probability that level 0.75 is exceeded in the better of the two attempts?

MARGINAL DISTRIBUTIONS; INDEPENDENCE
137
SOLUTION. The joint density of (X, Y) is
72x2(1 - x)y(1 - y) 
f(x, y)=
for0 < x < 1, 0 < y < 1 
otherwise.
The required probability is obtained as the integral of f (x, y) over the shaded area in 
Figure 6.6 hence equals
1 — [ 
[ 
72x2(1 — x 1)x2(1 — x2) dx 1 dx2 = 0.3771.
00
PROBLEMS
6.2.1 The joint probability function of variables X and Y is f(x, y)=c|x — y|, 
x =0,1,2,3, and y =0,1,2. Find: (i) c. (ii) P(X = Y). (iii) P(X>Y). 
(iv) P (|X — 1|<1). (v)P(X+Y < 3).
6.2.2 Two cards are drawn at random from the ordinary deck of cards. LetX be the number 
of aces and let Y be the number of hearts obtained. (i) Find the joint probability 
function of (X, Y ). (ii) Find the marginal distribution ofX and Y . (iii) Are X and Y 
independent?
6.2.3 An urn contains five balls, two of them red and three green. Three balls are drawn 
without replacement. Let X and Y denote the number of red (X) and green (Y ) balls 
drawn. (i) Find the joint distribution of (X, Y ). (ii) Find the marginal distributions 
of X and Y . (iii) Are X and Y independent? (iv) Find the joint distribution of X and 
Z=Y —X.
6.2.4 A box contains three coconut candies, five hazelnut chocolates, and two peanut but­
ter chocolates. A sample of four sweets is chosen from the box. Let X, Y, and Z be the 
number of coconut candies, hazelnut chocolates, and peanut butter chocolates in the 
sample, respectively. (i) Find the joint distribution of (X, Y ). (ii) Find the marginal 
distributions of X, Y, and Z. (iii) Are X and Y independent? Are X and Z indepen­
dent?
6.2.5 Let X and Y have the joint distribution P{X = x,Y = y} = cAx+y/(x!y!) for 
x = 0, 1, .. .,y = 0, 1, ..., and A > 0. (i) Find c. (ii) Find the marginal distribution 
of X. (iii) Are X and Y independent?
6.2.6 Random variables X and Y have joint distribution given by the following table:
X/Y
1
2
3
1
1
3
a
1
6
2
b
1
4
c
Show that X and Y are dependent, regardless of values a, b, and c.
6.2.7 Random variables have joint distribution given by the table
X/Y 
12 
3
1 
a 
2a 
3a
2 
bcd
Find a, b, c, d if X, Y are independent, and P(X =2)=2P(X =1).

138
RANDOM VARIABLES: MULTIVARIATE CASE
6.2.8 Consider a system consisting of three components connected as in Figure 6.7. Let 
Y1, Y2, Y3 be independent lifetimes of components 1, 2, and 3, respectively, each with 
EXP (a) distribution. If T is the lifetime of the whole system, find: (i) The cdf of T. 
(ii) The hazard function of T.
Figure 6.7 Three-component system.
6.2.9 Let variables X andY have joint density f(x, y)=3(x + y) for x>0,y>0,x+ y< 
1 and 0 otherwise. Obtain: (i) The density and the cdf of the marginal distribution of 
X.(ii)P(X+Y>0.5|X<0.5).
6.2.10 Let (X, Y ) have the distribution given by the table
X/Y
3
4
5
6
1
1
1
1
1
24
2
24
24
2
1
0
1
1
24
12
12
3
0
1
12
1
12
0
Find the probability distribution of independent random variables (X', Y') such that 
X' and Y' have the same marginals as X and Y.
6.2.11 Let T1, T2 be independent random variables with hazard functions h1(t) and h2(t), 
respectively. (i) Show that the variable with the hazard function h(t) = h1 (t) + h2(t) 
has the same distribution as min(T1, T2). (ii) Express P(T1 <T2) through h1 and h2.
6.2.12 Let variables X and Y be independent, with distributions GAM(1, 1) and GAM 
(2, 1), respectively. Find: (i) P(X -Y>0).(ii)P(|X -Y| < 1).
6.2.13 Let X and Y be the lifetimes of two components of a machine. Their joint distribu­
tion is given by the density f(x, y) = xe-x(1+y) for x>0,y>0 and zero, otherwise. 
(i) Find P(X > 5). (ii) Find the probability that max(X, Y) > 2. (iii) Check the inde­
pendence ofX and Y using their marginal densities.
6.2.14 Random variables X and Y have joint density
k(ax + by) 
0<x<1, 0 <y<2
0 
otherwise,
where a>0,b > 0. Find: (i) k (as a function of a and b). (ii) The marginal distribu­
tions ofX and Y. (iii) The cdf of (X, Y).
f(x, y)=

MARGINAL DISTRIBUTIONS; INDEPENDENCE
139
6.2.15 Let X and Y be the time (in hours) that a customer spends at a service counter and 
the time he is actually being served (Y<X). The joint distribution of X and Y has 
density f(x, y) = 4e-2x for 0 <y<x. Find: (i) The marginal distributions ofX and 
Y. (ii)Thecdfof(X,Y).
6.2.16 Students have to randomly select a point inside a circular region with radius R. One of 
them first samples the direction from the center of the region according to a uniform 
distribution on [0°, 360° ], and then samples the distance from the center according 
to U[0, R]. Find: (i) The density f(x, y) of the chosen points in (x, y) coordinates. (ii) 
The marginal distribution of X .
6.2.17 Assume that X and Y are independent random variables with EXP(a) and EXP(b) 
distributions, respectively. Assume that it is not possible to observe both X and Y 
but that one can observe
( 1 if X < Y
U = min(X, Y )andZ =
0 otherwise.
This kind of situation, called censoring, occurs often in medicine and engineering. 
For instance, X and Y may be the times of death due to heart failure (X) and death 
due to other causes (Y). Then U is the observed lifetime, and Z is the indicator of the 
cause of death. (i) Find the joint distribution of (U, Z). (ii) Prove that U and Z are 
independent. (Hint: Note that U is continuous, Z is discrete. It suffices to show that 
P{U < u\Z = i} is independent of i, i = 0, 1.)
6.2.18 Let X, Y be independent, continuous random variables with a symmetric (but possi­
bly different) distribution around 0. Show that Y/X and Y/\X\ have the same distri­
bution. (Hint: Compare the cdf’s of W = X/Y and V = X/\Y \.)
6.2.19 Let X and Y have distribution uniform in the shape of the letter Y (see Figure 6.8). 
Identify the shapes of the marginal densities of X and Y in Figure 6.9.
Figure 6.8 Joint distribution of X and Y .

140
RANDOM VARIABLES: MULTIVARIATE CASE
3
5
7
8
Figure 6.9 Options for marginal densities of X and Y .
6.3 CONDITIONAL DISTRIBUTIONS
A natural question concerning two random variables is how to handle situations where the 
information about the value of one of the variables affects the distribution of the other.
In symbols, the objective now is to determine the probabilities of the form
P(X e Q1 |Y = y)or P(Y e Q2 |X = x) 
(6.14)
for various Q1, Q2, x, and y.
We begin with the case of discrete random variables.
Let V = {y1, y2, ...} be the set of all possible values of Y. Then the event {Y = y} 
appearing as the condition in (6.14) has positive probability only if y e V . Here we can use 
the theory developed in Chapter 4, where we defined the conditional probability P (A|B) 
of event A given that the event B occurred as P(A\B) = P(A П B)/P(B), provided that 
P(B) > 0. IfP(B) = 0, the probability P (A|B) was left undefined. It is clear that to evalu­
ate (6.14) in the case of discrete random variables, we do not need any new concepts. If the 
condition has probability zero (i.e., ifP{Y = y} =0), we leave P {X e Q|Y = y} undefined. 
For yj e V, we have P{Y = yj } > 0, and
P(X e Q\Y = yj) = P(XQ,Y = yj). 
(6.15)
j 
P(Y = yj)
Let U = {x1, x2, ...} be the set of possible values of X. If we write p(xi,yj) or pij for 
P{X = xi ,Y = yj }, the denominator in (6.15) is the marginal probability P{Y = yj } 
= ipij = p+j , and therefore
P{X e Q 1 |Y = yj} 
i:xiEQ 1 pij.
1 
j 
p+j
An analogous formula with the role of X and Y interchanged is
P{Y e Q2 |X = xi} 
j:yjEQ2pij.
2 
i 
pi+

CONDITIONAL DISTRIBUTIONS
141
■ EXAMPLE 6.12
Let the experiment consist of two tosses of a die. We want to find conditional prob­
abilities of the result of the first toss given the absolute difference of two tosses, and 
conversely, the conditional probabilities for the absolute difference given the results of 
the first toss. Accordingly, we let X1 and X2 denote the result of the first and the second 
toss, respectively, and put Z = |X1 - X2|.
The sample space S is naturally represented by the cells of the following table (where 
the values of Z are written in the cells):
X1/X2
1
2
3
4
5
6
1
0
1
2
3
4
5
2
1
0
1
2
3
4
3
2
1
0
1
2
3
4
3
2
1
0
1
2
5
4
3
2
1
0
1
6
5
4
3
2
1
0
The joint distribution of X1 and Z is obtained by simple counting:
X1/Z
0
1
2
3
4
5
X1
1
1
1
1
1
1
1
1
36
36
36
36
36
36
6
2
1
2
1
1
1
0
1
36
36
36
36
36
6
3
1
2
2
1
0
0
1
36
36
36
36
6
4
1
2
2
1
0
0
1
36
36
36
36
6
5
1
2
1
1
1
0
1
36
36
36
36
36
6
6
1
1
1
1
1
1
1
36
36
36
36
36
36
6
z
6
10
8
6
4
2
1
36
36
36
36
36
36
We can now answer the various questions concerning conditional probabilities. For 
instance,
P(X odd Z = 5) = P{X1 = 1 ,Z = 5} = > = 1
P(X 1odd \Z = 5) = P{z = 5} 
= 36 = 2,
while
P(Z > 2|X1 =5)= P{Z = 3,X 1 = 5} , P{Z = 4,X 1 = 5}
P {X1 = 5 } 
+ 
P {X 1 = 5 }
1
3 ■
In the case of continuous random variables, determining a quantity such as, for example, 
P{X e A\Y = y} cannot rely upon the concepts of Chapter 4, since the conditioning event 
{Y = y} has probability zero. We therefore define the conditional density and then verify 
that it has all the necessary properties.

142
RANDOM VARIABLES: MULTIVARIATE CASE
Definition 6.3.1 The conditional densities g12 and g21 are defined by
g 12 (xly ) = fxy) 
(6.16)
12 
f2 (y)
provided that f2 (y ) > 0, and
g 21 (ylx ) = fx,^ 
(6.17)
21 
f1 (y)
provided that f1(x) > 0, where f(x,y) is the joint density of (X,Y ) and f1 and f2 are the
marginal densities of X and Y, respectively.
If the denominators in (6.16) or (6.17) are zero, the left-hand sides remain undefined. 
To check that formulas (6.16) and (6.17) define densities, observe first that both functions, 
which are regarded as functions of the first variable (i.e., x in g12(x|y) and y in g21(y|x)), are 
nonnegative. Moreover, we have
f ” g,2(x|y) dx = f ~ fdx =
-—ж 
— ж f 2( y)
1 
f+ж
—— f 
f (x, y) dx =
f2 (y) —ж
f2( У ) 
f2( У ) =1
and similarly for g21. To justify the definition on “semantic” grounds, assume for simplicity 
that f (x, y), and hence also f2(y), are continuous, and let us consider, for some h > 0, the 
probability P{X e A[y < Y < y + h}. For small h, we have
P{X e A[y < Y < y + h} = P{X e A,y < Y < y + h} 
P{y < Y < y + h}
JA Jy+h f (x,u) dudx ^ f A f (x,y) hdx 
Jy+h f2(u) du 
f2(y)h
= 
g12(x|y) dx.
A
This shows that g12 (x|y) is a well-defined density of X, given that Y = y. A geometric inter­
pretation of conditional density g12 (x|y) is a section of surface f(x, y) for Y = y normalized 
by a constant so that it integrates to 1.
■ EXAMPLE 6.13
Let the joint density of (X, Y) be given by
f(x, y)=
2 
cxy
0
if 0 < x < 1, 0 < y < 1, x + y > 1 
otherwise.
Thus, the density is positive on the triangle with the vertices (1, 1), (1, 0), and (0, 1); 
hence, X and Y are dependent (by the criterion for dependence of continuous random 
variables from Section 6.2). The marginal densities are as follows (we do not need to 
determine the numerical value ofc; it will cancel in densities g12 and g21): If0 <x<1, 
then
f 1(x) = [ 
f (x, y) dy = [ 
cxy2 dy = cxy
—ж 
1—x 
3
= - (3 x2 — 3 x3 + x 4).
1—
1
x

CONDITIONAL DISTRIBUTIONS
143
Similarly, for 0 <y<1,
Thus
hence,
1
cxy2 dx = cy 
1-y
21
,2 _
1-y
2 
xy2
(/2)y3(2 - y)
2У3(2 - У)•
2 x
У(2 - У);
2 x
g 12( x[y )= 
2 У - У 2
I 0
for 1 — У < x < 
otherwise •
1, 0 <y<1
g 12( 
) = 1$
For instance, if Y = 0 • 5, then for 0 • 5 < x < 1,
g 12(x10 •5) = g 12(xY = 0 •5) =
8
—x.
3
Figure 6.10 Conditional densities.
g21(y | 0.5)
0.5 
1
y
Similarly, for 1 — x < у < 1,
( | ) = f(x,y) = ___________ cxy2_______  = 
3Уy
g21 У 
f 1 (x) 
(c/ 3)(3 x2 — 3 x3 + x 4) 
x (3 — 3 x + x 2)
and equals 0 otherwise. Thus, if X = 0• 5, for 0• 5 < y < 1 the density g21(yl0• 5) =
24У2 /7 (see Figure 6.10).
In Chapter 4, we repeatedly stressed the fact that the formula P(AB) = P(A П B)/P(B) 
can be used to determine the probability P(A П B) of two events occurring jointly, given 
the probability of one of those events and the appropriate conditional probability, such as 
P(B) and P (AlB). The same situation is true in the case of conditional distributions in a 
continuous, discrete, or mixed case; given one marginal distribution and one conditional 
distribution, one can determine the joint distribution and hence also the marginal distribu­
tion of the other variable. We will illustrate this technique by three examples.

144
RANDOM VARIABLES: MULTIVARIATE CASE
■ EXAMPLE 6.14
An animal lays a certain number X of eggs, where X is random and has the Poisson 
distribution 
n
P{X = n} — —-e-X, n = 0, 1, 2, . .. 
n!
(see Example 5.9). Each egg hatches with a probability p, independent of the hatching 
of other eggs. Determine the distribution of Y = the number of eggs that hatch.
SOLUTION. Here the randomness of Y has two sources: first, the number X of eggs 
laid is random (varies from animal to animal), and second, even for animals that laid 
the same number of eggs, the randomness in the process of hatching may make the 
numbers of offspring different.
Our solution strategy is as follows: We are given the distribution of X . The two 
assumptions of the problem will allow us to determine the conditional distribution of 
Y given X. These assumptions allow us to determine the joint distribution of (X, Y ), 
and the distribution of Y will be obtained as marginal from the joint distribution of 
(X,Y).
We now need to determine the conditional distribution of Y given X, that is, P {Y = 
j\X = n}. First, it is clear that 0 < Y < X (the number of eggs that hatch is nonneg­
ative and cannot exceed the number of eggs laid). We assume that eggs hatch with 
the same probability and independently. Thus, Y must have binomial distribution if 
we regard the process of incubation as an “experiment over an egg” with “success” 
identified with hatching. Therefore,
P{Y = j\X = n} = n 
pj(1 -p)n-j, j=0, 1, ...,n.
j
By formula (6.15) the joint distribution of (X, Y) is
P{X = n,Y = j} = P{Y = j\X = n}x P{X = n}
— f n) Pj (1 - P)n-j x ^e-A, 
j 
n!
where n =0, 1, 2, ... and j =0, 1, ...,n (for all other values of n and j, the joint 
probability is zero).
We will next find the marginal probability P{Y = j} for j =0, 1, 2, ..... Clearly, for
X > Y, we have n > j. Hence,
P {Y = j} = £ P {X = n,Y = j} = £ £ e-X( n^Pj (1 - P) n-j 
n! 
j
n=j 
n=j
= it ^Пe-4n4pj (1 - P)n-j 
n=j n! j!(n - j)!
= (XP)j e-x V [a(1 - P)]n-j 
j! n=j 
(n - j)!
_ (Xp)j -x y^ [A(1 - p)]v (Xp)j -yX(i-p)
e 
e e
j! 
V=0 
v! 
j!
= (AP^)j e-Xp

CONDITIONAL DISTRIBUTIONS
145
The marginal distribution ofY is again Poisson, except that the parameter has changed 
from A to Xp.
The process that leads from X to Y in this example is sometimes called binomial thin­
ning. One can visualize it, in general, as a random process that gives the value ofX (by 
assumption, an integer), with some distribution. We can think of X as the number of 
objects of some kind that are produced, a number of elements sampled, a number of 
events of some kind that occur, and so on. The process of thinning causes some of the 
X objects (events, etc.) to disappear (not be counted), due to a certain random process 
of selection. For instance, some of the X objects produced are defective, some of the 
X elements sampled are not acceptable or have certain other characteristic, some of 
the events are unobservable, and so on. Such a process of elimination of some X sand 
the selection of others is called thinning. We say that the process of thinning is bino­
mial if the inclusions of X-elements as Y -elements are independent and occur with the 
same probability. The present example shows that binomial thinning of Poisson ran­
dom variables leads again to Poisson random variables, with appropriately modified 
parameters.
We will now consider similar situation for continuous distributions.
■ EXAMPLE 6.15
A point X is chosen at random from the interval [A, B] according to the uniform distri­
bution (see Example 5.14), and then a point Y is chosen at random, again with uniform 
distribution, from the interval [X, B]. Find the marginal distribution of Y .
SOLUTION. Since
and
1
B-A
0
g21(y|x) =
for A < x < B
otherwise
B-x
for x < y < B 
otherwise,
1
0
we have
1 
1 
1
f(x,y) = fi(x) g2i(ylx) = в - A в - x
I 0
for A < x < y < в 
otherwise.
Consequently, for fixed y (A < y < в),
y 1 
1 J 1 
, B - A
f2(y) = JA B-A B B—Xdx = B-A 1OgB-У•
The values close to B are more likely than those close to A; the density of Y is in fact 
unbounded as we approach the upper boundary B of the range of Y .
■ EXAMPLE 6.16
Finally, we will consider the case ofa mixed distribution, with X being continuous and 
Y being discrete.

146
RANDOM VARIABLES: MULTIVARIATE CASE
Assume that Y takes one of n > 2 integer values with P{Y = i} = pi and p 1 + p2 +
• • • + pn = 1. In the simplest case, n = 2, we have
p1 =P{Y=1}=p, p2 =P{Y=2}=1-p.
Next, assume that for a given Y = i, the random variable X has a continuous distri­
bution with density pi (x). Thus, we have
P{a < X < b, Y = i} = Pi j Pi (x) dx.
To find the marginal distribution of X , we can use the formula for total probability 
(4.9) from Chapter 4, with events {Y = i} as the partition. Then
P{a < X < b} = ^2 P{a < X < b\Y = i} x P{Y = i}
i=1
= 12 P4 ^i(x) dx = 
pL/PiPi(x) dx. 
(6.18)
i=1 
a 
a i=1
It follows that X is a continuous random variable with the density
n
fX (x)= 
piPi (x),
i=1
called the mixture of densities Pi with mixing coefficients pi .
If we have only two values of Y, and therefore only two densities P1 and P2 of X , 
then
fX(x) = pP1(x) + (1 - p)P2(x).
The formulas above remain valid if Y assumes one of infinitely many values 1, 2, ..., 
with probabilities p 1 ,p2, ... such that we have pi = 1. The only potential source of 
trouble is the interchange of integration and summation in the last step in (6.18). But 
this interchange is permissible because the terms of the sum are all nonnegative.
PROBLEMS
6.3.1 Suppose that three cards are drawn without replacement from an ordinary deck. Let X 
be the number of aces among the cards drawn andY be the number of red cards among 
them. Find: (i) The joint distribution of(X,Y). (ii) The conditional distribution of the 
number of aces if it is known that all three cards selected are red.
6.3.2 Let X and Y have the joint density f (x, y) = X2e-Xy for 0 < x < y and f (x, y) = 0 
otherwise. Find: (i) The joint cdf of (X, Y). (ii) The marginal densities of X and Y. 
(iii) The conditional density of Y given X .
6.3.3 Refer to Problem 6.2.15 and find: (i) The conditional density of X given Y and of Y 
given X. (ii) Probability that a randomly selected customer spent more than 30 minutes 
at the counter if he was served less than 15 minutes. (iii) Probability that customer’s 
waiting time was less than 10 minutes if he was served between 10 and 20 minutes.
6.3.4 Let variables X and Y be independent, each with U[0, 1] distribution. Find: (i) P(X + 
Y < 0.5 \ X = 0.25). (ii)P(X+Y < 0.5 \ X > 0.25). (iii) P(X > Y \ Y > 0.5).

BIVARIATE TRANSFORMATIONS
147
f(x, y)=
6.3.5 Let X and Y have joint density of the form
A (y — x)a 
for 0 < x < y < 1
0 
otherwise.
Find: (i) The values of a such that f can be a density function. (ii) The value of A for 
a specified in part (i). (iii) The marginal densities of X and Y. (iv) The conditional 
densities g12(x|y) and g21(y|x).
6.3.6 The phrase “A stick is broken at random into three pieces” can be interpreted in sev­
eral ways. Let us identify the stick with interval [0, 1] and let 0 <X<Y <1 be the 
breaking points. Some of the possible ways of generating X, Y are as follows: (i) A 
point (U, V ) is chosen from the unit square with uniform distribution, and we let 
X = min(U, V ) and Y = max(U, V ). (ii) The point U is chosen from [0, 1] with uni­
form distribution. If U<1/2, then V is chosen with uniform distribution from [U, 1], 
whereas if U > 1 /2, then V is chosen with uniform distribution on [0, U]. Then (X, Y) 
are defined as in (i). (iii) X is chosen from [0, 1] according to the uniform distribution, 
and then Y is chosen with uniform distribution on [X, 1]. (iv) U is chosen with uniform 
distribution on [0, 1]. Next, one of the intervals [0,U] or [U, 1] is chosen at random, 
with probability U and 1 — U, respectively. Then V is chosen with uniform distribution 
from the chosen interval, and again, X = min(U, V) and Y = max(U, V).
In each of the cases, (i)-(iv) find the joint density of (X, Y) and the marginal densities 
of X and Y. Which of the ways (i)-(iv) are equivalent?
6.3.7 A fast-food restaurant has a dining room and a drive-thru window. Let X and Y be the 
fractions of time (during a working day) when the dining room (X) and the drive-thru 
window (Y) are busy. Assuming that the joint density of (X, Y) is f(x, y) = k(2x2 + 
y2) for 0 < x < 1, 0 < y < 1 and f(x, y) = 0 otherwise, find: (i) k. (ii) The marginal 
densities of X and Y. (iii) The probability that the drive-thru window will be busy 
more than 75% of the time on a day when the dining room is empty less than 10% of 
the time. (iv) Do you find anything disturbing in this problem? If so, explain.
6.4 BIVARIATE TRANSFORMATIONS
In Chapter 5, we considered transformations of single random variables. Here we will 
consider functions of two continuous random variables X and Y with the joint density 
f(x, y) with support C (so that f(x, y) > 0 on C and f(x, y)=0 outside C). The 
objective is to find the density of Z = p(X, Y), where ^ is a differentiable function of 
two real arguments. By far the simplest here is the cdf technique, introduced in Section 
6.4 for the case of a single variable. It may also be applied in the multivariate case 
if we can obtain P{Z < z} = P{^(X, Y) < z} in a closed form as a function of z. 
Density can then be obtained by differentiation. This method works especially well for 
y(X,Y) = max(X, Y) and p(X, Y) = min(X, Y), when X and Y are independent. For 
example, P {max(X, Y) < z)} = P{X < z,Y < z} = FX (z)FY (z); hence, the density of 
Z = max(X, Y) is fX(z)FY (z) + FX(z)fY (z).
Now, we will present a technique that may be applied to a wider class of cases. It will 
be given in the form of an algorithm, and its use will be illustrated by several examples. A 
formal proof will not be given, since the algorithm is in fact based on a change of variables 
in two-dimensional integrals, which can be found in advanced-level calculus texts.
Determination of densities of bivariate (and multivariate) transformations is typically 
regarded by students as challenging. We hope that by presenting it as a purely mechani­
cal procedure—which it largely is—we will alleviate, or perhaps eliminate, the terror. The 
algorithm is as follows:

148
RANDOM VARIABLES: MULTIVARIATE CASE
1. Choose a “companion” function, say w = n(x, y), such that the pair of equations 
z = ^ (x,y) and w = n (x,y) 
(6.19)
can be solved, leading to
x = a(z,w) and y = в(z, w)■ 
(6.20)
2. Determine the image D of the support C of density f(x, y) in the (z, w) plane under 
transformation (6.19).
3. Find the Jacobian of transformation (6.19), that is, the determinant
da
da
J=
dz
dw
дв
дв
dz
dw
(6.21)
4. Determine the joint density g(z,w), of random variables Z = <p(X,Y), W = n(X,Y), 
given by the formula
f f f f(a(z,w),в(z,w))IJ| for (z,w) e D 
g(z, w)=
0 
for(z, w) e/ D.
5. Compute the density of Z = <p(X, Y) as the marginal density of g(z, w):
gz (z )= [ 
g (z,w) dw = [ f (a (z,w) ,в (z, w)) IJ Idw,
— ж 
Dz
where Dz = {w :(z, w) e D}.
Out of these five steps, only step 1 requires some moderate amount of thinking (or, at 
least some experience). The reason is that the choice of the companion transformation 
n affects all subsequent steps, making the calculations easy, difficult, or perhaps even 
impossible.
■ EXAMPLE 6.17 Sum of Random Variables
The operation of addition of random variables appears so often that it is worthwhile to 
derive general formulas here. For z = у(x, y) = x + y, we have a possible choice of a 
companion transformation, w = n(x, y)=x. Hence, the inverse transformation (6.20) 
is
x = w and y = z - w,
so that a(z, w) = w, and в(z, w) = z - w. Thus,
0
1
1
J=
-1
and IJI =1. If (X, Y) have joint density f(x, y), then the joint density of (Z, W) is 
f(w, z - w). The density ofZ is
gZ (z)= 
f(w, z - w) dw. 
(6.22)
—ж
Now, we have only to determine the effective limits of integration, that is, the set of 
values w (for given z) at which the integrand is positive.

BIVARIATE TRANSFORMATIONS
149
■ EXAMPLE 6.18 Sum of Exponential Random Variables
When X and Y are independent, and both have exponential distributions with the 
same parameter A, their joint density is
f (x,y ) = ( “ 2 ' 
(x+y) f, x — 0, y — 0 
(6.23)
0 
otherwise.
Consequently, the density gZ (z), as given by (6.22), is
gZ(z)= 
f (w,z — w) dw = 
a2e—az dw,
— ж 
Dz
where Dz is the set {w : w — 0, z — w — 0}. Since we must have z > 0 and 0 < w < z,
gZ (z) = a2e—az J dw = a2ze—az, z — 0 
(6.24)
and gZ (z)=0 forz<0. We recognize the density (6.24) as a gamma density with 
parameters 2 and a (see Example 5.27).
■ EXAMPLE 6.19 Sum of Two Uniform Random Variables
Let two independent variables X and Y both have U(0, 1) distributions. Their joint 
density is then
f( 
) _ ( 1 if 0 <x < 1, 0 <y < 1
x, y 0 otherwise.
Formula (6.22) gives the density of variable Z = X + Y as
gZ(z) = 
1 dw, 
(6.25)
where Dz = {w :0<w<1, 0 < z — w < 1}. Inequalities defining Dz, 0 <w<1 and 
z — 1 < w < z, can be written as
max(0, z — 1) < w < min(z, 1).
We must have 0 < z < 2, otherwise Dz is empty. For 0 < z < 1, the set Dz is the inter­
val 0 < w < z, while for 1 < z < 2, we have the interval z — 1 < w < 1. Consequently 
(6.25) gives (see Figure 6.11)
{
z 
for 0 < z < 1
2 — z for 1 < z < 2 
0 
otherwise.
This distribution is called triangular.
■ EXAMPLE 6.20
Formula (6.22) was obtained by taking a specific companion transformation 
w = n(x, y) = x. There is no compelling reason for this choice. We could, of course, 
have chosen w = n(x, y) = y, getting a very similar formula. However, we could also 
have chosen something more fancy, for example, w = n(x, y) = x/(x + 5y).

150
RANDOM VARIABLES: MULTIVARIATE CASE
Figure 6.11 Triangular density.
The system of equations
x
z = x + y, w = x + 5 y ,
has the solution
5wz 
1 - w
1 + 4 w, 
y 1 + 4 w
Consequently, the Jacobian equals
5w 
5z
1 + 4 w 
(1 + 4 w )2 
5 z
J = 
=--- :--------- —.
1 — w 
— 5 z 
(1 + 4 w )2
1 + 4 w 
(1 + 4 w )2
Thus, the density of the sum Z = X + Y can be obtained as the integral
gZ
5wz
M1+4w,
1—w
Z 1 + 4w
5 z 
(1+4 w )2 dw,
(6.26)
where again the effective range of integration depends on the support C of the joint densityf.
This example is given here to show that there is no such thing as “the” formula for 
density of sum of random variables: Once the integration is carried out, (6.22) and (6.26) 
will both lead to the same final form of gZ (z). We cannot even say that (6.22) is simpler 
than (6.26), since the simplicity of integration depends here on the form of f and of its 
support C.
■ EXAMPLE 6.21 Product of Two Random Variables
We have <p (x,y) = xy, and we want to find the density of the random variable Z = XY.
Let us again choose the companion function n(x, y) = x so that the system of 
equations (6.19) is z = xy, w = x, and its solution (6.20) is
x = a(z, w) = w,
y = в(z, w) = —. 
w
The Jacobian of this transformation is
0
1
J=
1
z
w
------ 
w w2
1
;
w

BIVARIATE TRANSFORMATIONS
151
hence |J| = 1/|w|. The joint density of (Z, W) is now
z\ 1 
f w, ;
w |w|
and the density of Z is given by
/■+TO 
z z \ 1
gz (z )= 
f[w, 
dw.
-ж 
\ wJ |w|
Again, the effective limits of integration depend on the support C of density f(x, y) 
and, consequently, the sets Dz
We will now give an example that provides an algorithm of generating random variables 
with normal distribution.
Theorem 6.4.1 If X and Y are independent, uniformly distributed on (0, 1), then the random 
variables Z and W
Z = 
—2 log X sin(2nY), 
W = 
—2 log X cos(2nY),
are independent and each has the standard normal distribution.
Proof: VariablesX and Y are independent, each with U(0, 1) distribution. Their joint den­
sity is
f ( 
) _ ( 1 if 0 < x < 1, 0 <y < 1
x, y 0 otherwise.
For z = у/—2 log x sin(2ny) and w 
——2 log x cos(2ny), we have z2 + w2 = — 2 log x, and
x = e-(z + w )/2. On the other hand, z/w = tan(2ny), which gives
y = — arctan ) .
The Jacobian equals
J=
—e-(z2+w2)/2 
—we-(z2+w2)/2
1/w —z/w2
2 n (1 + z 2 /'w 2) 2 n (1 + z 2 /w 2)
(6.27)
which, after some algebra, reduces to
1
z2/2 x
1 e-w / / /2
2 n
The unit square, equal to the support of f(x, y), is mapped into the whole plane (z, w). It 
follows that the joint density of (Z, W), equal in this case to the Jacobian (6.27), is a product 
of two normal densities. 
□
As already mentioned, the conditional densities given a specific value of a random variable 
cannot be calculated according to the principles of Chapter 4, since the conditioning event 
has probability zero. As a warning we present an example, seemingly paradoxical, where by 
following the rules as explained in this chapter, one obtains two different answers to the same 
question.

152
RANDOM VARIABLES: MULTIVARIATE CASE
■ EXAMPLE 6.22 Borel-Kolmogorov Paradox
Assume that X and Y have joint density
f (x, У) = 4xy, 0 < x < 1, 0 < У < 1,
so X and Y are independent, with the same marginal densities
fx (t) = fy(t) = 21, 0 < t < 1 •
We will try to determine the conditional density of X given the event X = Y .Aswe 
will see, the answer will depend on the representation of event X = Y ,asY - X =0 
or as Y/X =1.
SOLUTION 1. We introduce new variables, U = X, V = Y - X . Then our problem
becomes equivalent to finding the density of U,givenV =0. Thus, we have to find the
joint density h(u, v) of (U, V ) and determine the marginal density hV (v). Our answer
will be
Vx(xX = Y) =
h(u, v) 
hV (v )
h(u, 0) 
hv(0)
The transformation, u = x, v = У - x, has the inverse x = u, У = u + v , so the Jaco­
bian is
dx dx
J= Ihu &v = 1 0 = 1
dy dy 11 
•
du dv
Figure 6.12 Supports of (U, V) and (U,W).
Consequently, the joint density of (U, V) is h(u,v) = 4u(u + v) for 0 < u < 
1, -u < v < 1 - u (see Figure 6.12). The marginal density of V is
hV(v)= 
4u(u + v) du =4
0
'(1 — v)3 + v (1 — v)2_ 
3+2
2
= 3(1 — v )2(2 + v),

BIVARIATE TRANSFORMATIONS
153
for 0 < v < 1, while for — 1 < v < 0 we have
hV (v)= 
4u(u + v) du =4
1 v v3
3 + 2 — T
— 3( v + 1)2( v — 2).
Both formulas give hV (0) = 4/3. Thus, as the conditional density of U at V =0, we
obtain
h(u, 0) 
hv(0)
=3u2 ,
0<u<1.
4 u 3
-4
3
SOLUTION 2 We introduce the transformation U = X, W = Y/X. Then the condi­
tional density of X, given X = Y, is the same as the conditional density of U, given 
W =1.
The transformation u = x, w = y/x has an inverse x = u, y = uw, and the Jacobian
equals
1
w
0
u
J=
= u.
Consequently, the joint density of (U, W) is g(u, w) = 4u3w for 0 < u < 1, 0 < w < 
1/u (see Figure 6.12). The marginal density gW (w) is
gW (w)= 
4u3wdu= w for 0 < w < 1,
while for w > 1 we have
gw (w) = [ 
4 u3 w du = —.
W 
0 
w3
For w =1we have gW (1) = 1, and therefore the conditional density equals
g(u, 1) =4u3, 0 < u < 1.
Thus, we obtained two different solutions, and we may ask which of them—if either—is 
correct?
The formal answer is that both solutions are correct, and we can choose, for the 
density of X , given X = Y, any other function as well. This is simply because the con­
ditional densities ofa variable, given conditions with probability zero, can be modified 
arbitrarily on any set of conditions whose total probability is zero (in particular, on a 
single condition, or on finitely many conditions).
This answer is, however, not quite satisfactory. We also want to understand why the 
techniques of transformation lead to different answers. To explain this phenomenon, 
let us assume that we need the density of X given X = Y , but we cannot observe exactly 
whether the conditions holds. Specifically, consider two situations: (1) we can observe 
the difference X — Y, within some small error e; (2) we can observe the ratio Y/X, 
again within small error e. The “natural” approach now is to use limiting passage, 
with e ^ 0. For any fixed e, the conditioning events |X — Y| < e and \Y/X — 11 < e 
are different (see Figure 6.13), and it is not surprising that the ratio Y/X favors larger 
values of u.

154
RANDOM VARIABLES: MULTIVARIATE CASE
Figure 6.13 Approximations of two conditioning events.
PROBLEMS
6.4.1 Let X, Y be independent, each with a standard normal distribution. Find the distri­
bution of: (i) V = X/Y. (ii) U =(X - Y)2/2. (iii) W = X/|Y |.
6.4.2 Let random variables X 1 ,X2 be independent and have both EXP(A) distribution. 
(i) Find the cdf and the density of X1 - X2 . (ii) Find the cdf and the density of 
X1/X2. (iii) Show that Z1 = X1 + X2 and Z2 = X1/(X1 + X2) are independent.
6.4.3 Let X and Y be independent random variables with densities
fx (x ) = c 1 x 
1 e-x, 
fy (У ) = c 2 Ув—1 e—V
for x > 0, y > 0, a > 0, в > 0, and normalizing constants c 1, c2. Find the density of 
W = X/(X + Y ).
6.4.4 Independent random variables X and Y are uniformly distributed over intervals 
(-1, 1), and (0, 1), respectively. Find the joint distribution of variables U = XY and 
V = Y . Determine the support of the density function.
6.4.5 Random variables (X, Y ) have a joint density
, f k(ax + by) if 0 < x < 2, 0 < y < 2 
f(x,y) = 0 
otherwise,
where a>0,b >0 are given constants. Find: (i) The value ofk as a function ofa and 
b. (ii) The density of variable Z = 1 /(Y + 1)2. (Hint: Express F(t) = P{Z < t} in 
terms of the cdf of Y.)
6.4.6 Random variables X and Y have joint density f(x, y)=cx, c>0,for-x<y<x, 
0 <x<1, and zero otherwise. Find the density and the cdf of W = X - Y.
6.4.7 The joint distribution of random variables X and Y has density f(x, y)=cx2,c>0, 
for 0 <y<-x +1,x >0 and 0 otherwise. Find the distribution of W = X + Y.
6.4.8 Let R be a nonnegative random variable with density f(r). Let (X, Y) be a bivariate 
distribution obtained as follows: First, randomly choose a value ofR, and then chose 
a value of U according to its U(0, 1) distribution. Now, put
X = R cos(2 nU), 
Y = R sin(2 nU). 
(6.28)
Find: (i) The joint density of variables X and Y. (ii) P{XY > 0}. (iii) P{X > 0}. 
(iv) P{X2 + Y2 < t}. [Hint: For (i), find the joint density of (R, U) first and then use 
transformation (6.28).]

MULTIDIMENSIONAL DISTRIBUTIONS
155
6.4.9 Let f be the joint density of a pair (X, Y ) of random variables, and let a and b be two 
constants. Find the densities of (i) aX + bY . (ii) XY. (iii) X/Y . (iv) (U, V ), where 
U = aX + b, V = cY + d, and ac =0.
6.4.10 Darts are thrown at a circular target. Let variables X and Y , coordinates of the point 
of impact be independent each having N(0, a2) distribution. Find the density of D, 
the distance of the point of impact from the center of the target.
6.4.11 A current ofI amperes following through a resistance ofR ohms varies according to 
the probability distribution with density
6i(1 - i) 
0<i<1
0 
otherwise.
f(i) =
Find the density of the power W = I2R watts, if the resistance R varies independently 
of the current according to probability distribution with the density g(r) = 2r for 
0 <r<1, and zero otherwise.
6.5 MULTIDIMENSIONAL DISTRIBUTIONS
We will now extend the concepts introduced in the case of bivariate distributions to the case 
of multivariate (or multidimensional) distributions. The motivation for these concepts lies 
in the frequency of practical situations when the analysis concerns many random variables 
simultaneously.
The examples here are easy to find. First, often a description of the phenomenon studied 
(sampled objects, some process, effects of treatment, etc.) uses several attributes at once. 
Formally, we have several random variables, X1, ...,Xn, defined on a sample space, with Xi 
being the value of the ith attribute recorded for a given object. In such situations, a natural 
choice of sample space is to take the population of the objects under consideration, with 
probability P being generated by a specific scheme of selecting elements from the population.
In another context, we may think of repeated measurements of the same attribute so that 
Xi is the result of the ith measurement. Now, the probability P reflects possible dependence 
(or lack of it) in the measurement process.
Whatever the interpretation, formally, we have a vector of random variables
X=X(n) =(X1,...,Xn).
In the discrete case, the joint distribution of X consists of all probabilities of the form
PX(x)=P{X=x}=P{X1 =x1,...,Xn=xn},
where x = (x1, ...,xn). Clearly, we must have 
xPX(x) = 1, the summation extended over
all possible values x = (x1, ...,xn) of vector X.
In the continuous case, we have the joint density of the vector X, in the form ofa nonneg­
ative function f(x) = f(x1, ...,xn) ofn variables such that
P{X eQ} =
f(x1, ...,xn) dx1 . ..dxn
x EQ
with
f(x1, ...,xn) dx1 ...dxn =1.
Rn

156
RANDOM VARIABLES: MULTIVARIATE CASE
The notions of marginal and conditional distributions and densities remain very much the 
same as in the bivariate case, except that the marginal distributions may now be themselves 
multivariate, and the same applies to conditional distribution, with the additional feature 
that the conditioning event may involve several random variables.
The simplicity of concepts can easily be obscured by confusing notation. While in any 
special case, there is seldom any danger of confusion (we know the meaning of the variables, 
and it is usually clear what is needed and what has to be done), the formulas covering the gen­
eral cases may be confusing. We will use the following notation only presenting the theory; 
in Examples, we will try to simplify the notation, whenever possible.
First, in the case of marginal distribution, we need to specify the variables of interest. 
They form a subset of the variables X1 , ...,Xn.Thus,weletX =(Y, Z), where Y are the 
variables of interest and Z are the remaining variables. The question of ordering is irrelevant. 
For instance, if X =(X1 , X2, X3, X4, X5) and we are interested in the joint distribution of 
X2 and X5, then Y = (X2,X5) and Z = (X1,X3,X4). We let y and z denote the values of 
vectors Y and Z so that x =(y, z) is the partitioning ofx into the corresponding two subsets 
of coordinates. We now introduce the following definition:
Definition 6.5.1 In the discrete case, the marginal distribution of Y is given by
PY(y) = P{Y = У} = 
P{Y = У , Z = z}•
z
In the continuous case, the marginal density of Y is given by
fy (У) = j ••• f (У, z) dz,
where the integrals represent the multiple integration over all variables Xi that are in 
vector Z. 
□
Before considering examples, let us look at the corresponding definitions for the case of 
conditional distributions. As in the bivariate case, the discrete distributions present no diffi­
culty, and we will simply state that all formulas can be deduced starting from the definition 
of conditional probability for events, namely P(A\B) = P(A П B)/P(B) if P(B) > 0. In 
the continuous case, we have to partition X into three components; so we write
X=(Y,Z,W),
where Y is the set of variables of interest, Z is the set of variables that will appear in the 
condition (whose values are assumed known), and W is the set (possibly empty) of variables 
that are neither in the condition nor of interest in the given instance. We need to define the 
conditional density of Y given Z = z.
Definition 6.5.2 The conditional density of Y given Z = z is defined as
( y|z) = fy,z(y,z) _ J f (У,z,w) dw
Y1 Z y 
f z(z) 
ff f (y, z, w) dУ dw w
where the integral symbols represent multiple integration over the variables in vectors 
w and y. 
□
We illustrate that by several examples.

MULTIDIMENSIONAL DISTRIBUTIONS
157
■ EXAMPLE 6.23 Trinomial Distribution
Let us consider an experiment in which the outcome can be classified into one of three 
exclusive and exhaustive categories. We let these categories be A, B, and C , and let 
а, в, and Y be their respective probabilities. Outcomes A, B, and C form a partition of 
all outcomes so that а + в + Y = 1.
In the case of experiment on treatment effectiveness, A, B, and C could represent 
“improvement,” “relapse,” and “no change”; in cases of quality testing, the categories 
may be “acceptable,” “repairable,” “unacceptable and beyond repair,” and so on.
We can perform the experiment n times assuming that the repetitions are independent. Let 
X1, X2 stand for the counts ofA and B among n repetitions (the count of C is n - X1 - X2). 
We then have the following theorem:
Theorem 6.5.1 The joint distribution of X = (X1,X2) defined above is given by
n!
P {X1 = x 1 ,X 2 = x 2 } 
--------------- ту ax1 ex2 Yn-x1 -x2, 
(6.29)
x1!x2!(n - x1 - x2)!
where x 1, x2 are nonnegative integers such that x 1 + x2 < n.
Proof: The probability ofx1 outcomes A, x2 outcomes B, and n - x1 - x2 outcomes C in 
a specific order equals
P(A)x1P(B)x2P(C)n-x1-x2 = ax1 ex2 Yn-x1 -x2
by assumption of independence. Considering all possible
n
x1 ,x2 ,n - x1 - x2
n!
x1 !x2 !(n - x1 - x2 )
orders (see Theorem 3.4.1), we obtain (6.5.1).
□
■ EXAMPLE 6.24
Continuing Example 6.23, let us find the marginal distribution of X2 . Formally, for 
x2 =0, 1, . . . ,n, we have
pX2 (x2) = P{X2 = x2} = 
P{X1 = x1, X2 = x2, X3 = x3}.
x1,x3
However, x3 = n - x1 - x2, so
P{X1 = x1, X2 = x2, X3 = n-x1 - x2} = P{X1 = x1, X2 = x2}.

158
RANDOM VARIABLES: MULTIVARIATE CASE
Therefore, using (6.29), we write
pX2 (x2) = 
P{X1 = x1, X2 = x2}
x1=0 
n-x2
n!
V ——--------------------------  ax1 ex2 (1 - a - в)n-x 1 -x2
x =0 x1!x2!(
n 
- x1 - x2)!
!
x2!( -
в 2 (1 - в) 
x2)!
n-x2
n-x2
( - x2)
x1 ![( - x2) - x1]
ax i 
/ a Vn-x 2)-x 1
(1 - в)x 1 V - 1 - в)
x1=0
вx 2 (1 - в)n-x2
since the last sum above reduces to
n-x2
nx 1 (1
n)n-x2 -x1 =1,
x1=0
where n = a/(1 - в)■
Thus, the marginal distribution of a variable in a trinomial distribution is binomial, as 
could have been expected. It is enough to interpret an occurrence of B as a success and 
the occurrence of anything else (A or C) as failure. So the probabilities of success and fail­
ure are в and a + y = 1 - в, respectively. The number of successes, X2, has a binomial 
distribution, as it should. In the general case, suppose that the outcomes of each exper­
iment are categorized into m + 1 classes, their probabilities being n 1, n 2, ..., nm+1, with 
n 1 + n2 + • • • + nm +1 = 1. If the experiment is then repeated independently n times, and 
Xi (i =1, .. .,m) is the number of outcomes of category i among n outcomes, then for 
nonnegative integers x 1, ... ,xm with x 1 + • • • + xm < n we have
n!
P {X =x X =x } =_____________ nx 1.. -Tx1'^ П т + 1
P {X 1 
x 1 , . . . , Xm 
xm} 
| 
| 
| П 1 
Пт Пт +1 ,
x 1! ••• xm ! xm +1! 
+
where xm+1 = n - (x 1 + ■ ■ ■ + xm) and nm +1 = 1 - (n 1 + • • ■ + nm). This is the multino­
mial distribution.
Let now Y =(Xi , ...,Xi ) be a subset of variables X = (X1, ...,Xm) with a multi­
nomial distribution. Proceeding in the same way as in Example 6.24, we can show that for 
y = (yi 1, ... ,yik) with coordinates yij being nonnegative integers with yi 1 + • ■ ■ + yik < n, 
we have
n
P {Yi1 =yi1,...,Yik =yik}= yi1
yi1 
i1
■ ok nyik+1 
ik ik+1
' ' ' yik !yik+1
П
where yik+1 = n - yi 1 - • • • - yk and nik +1 = 1 - ni 1 ------ --- nik. Thus, a marginal distri­
bution in a multinomial distribution is again multinomial with lower dimensionality.

MULTIDIMENSIONAL DISTRIBUTIONS
159
■ EXAMPLE 6.25 Model of Grinding
The basic model suggested for the process of grinding rock begins with a piece of rock 
that is randomly divided into two parts. Each of these two parts is again divided ran­
domly, and so on, until in the nth “generation” we have 2n pieces of rock. Assume that 
this process continues for a large number of generations.
With the model one can obtain a distribution, as n ^ ж, of sizes of rock. Naturally, 
with each generation of grinding the actual sizes of rock will tend to zero, so that the 
sizes of 2n pieces in the nth generation will have to be multiplied by the approximate 
scaling factor.
The results allow us to predict what fraction of the initial mass of rock will be ground 
into gravel with sizes contained between specific limits a and b, and so on.
Instead of the whole process, we will study only the first two divisions and the result­
ing sizes. For simplicity, we assume that the initial size is 1, represented as interval [0, 1]. 
In the first division, a point X —with uniform distribution—partitions the unit inter­
val into two pieces of length X and 1 - X . In the next partition, length X is divided 
by point Y (with Y distributed uniformly between 0 and X), and the remainder is 
divided by point Z, distributed uniformly on [X, 1]. We therefore have four fragments 
(see Figure 6.14) of length
X1 = Y, 
X2 = X - Y, 
X3 = Z - X, 
X4 =1- Z.
X~U[0,1]
Y~U[0,X]
Z~U[X,1]
Figure 6.14 First two generations in the process of grinding.
We will start by deriving the joint trivariate density of (X, Y, Z). By assumption, X 
has density
f ( ) _ J 1 for 0 — x — 1
fX (x)= 0 otherwise.
Given X = x, variables Y and Z are independent with densities
Syix(y\x) = | x ° - y - x and gzix(z\x) = | 1 - x 
x - z - 1
I 0 otherwise 
I 0 
otherwise .
Thus, gY,Z|X(y,z|x) = gY|X(y|x)gZ|X(z|x), and the joint density is
f (x,y,z ) = ( x (1 - x) for 0 - y - x - z - 1 
(6.30)
I 0 
otherwise.

160
RANDOM VARIABLES: MULTIVARIATE CASE
The marginal joint density of Y and Z, for 0 < y < z < 1 will now be
fY,Z(y,z) = J, XildxX)
---- d dx = log у-------- + log----- y
so the marginal density of Y will be
fY (y ) = j (bgj--------+ log-----y ) dz = — log y
-z y
for 0 <y<1. Finally, we obtain the conditional density ofX given Y = y and Z = z:
gX|Y,Z(x|y,z) = f (x,y,z) 
fYZ (У, z)
1
x (1 — x) 
log 1-z + log 1—--
for 0 <y <x<z< 1.
To derive the density of (X1, X2, X3, X4), we need to derive only the density of 
(X1 ,X2 ,X3 ), since X1 + X2 + X3 + X4 =1. This can be done by applying the trans­
formation
x1 = y, 
x2 = x — y, x3 = z — x 
(6.31)
to the trivariate density (6.30).
The inverse transformation to (6.31) is
y =x1,x = x1
+ x2,
z
x1 +x2 + x3
with Jacobian
dy
dy
dy
dx 1
dx 2
dx 3
1
0
0
dx
dx
dx
J=
—
1
1
0
=1.
dx 1
dx 2
dx з
dz
dz
dz
1
1
1
dx 1
dx 2
dx 3
(6.32)
Thus, the joint density g(x1, x2, x3) of (X1, X2, X3) is obtained from (6.30) by substi­
tuting (6.32), that is,
g(x1,x2,x3) =
1
(x 1 + x 2)(1 — x 1 — x 2)
0
x1 > 0,x2 > 0,x3 > 0,
x1 + x2 + x3 < 1 
otherwise.
PROBLEMS
6.5.1 Let variables X1 and X2 be independent, such that P(Xi = —1) = P(Xi =1)=0.5, 
i =1, 2. Moreover, let X3 = X1X2. Show that variables X1, X2, X3 are not indepen­
dent but each two of them are independent (they are pairwise independent).
6.5.2 Let variables X1,X2, and X3 be independent, each having a U(0, 1) distribution. 
Find: (i) The probability that exactly two of the three variables will be larger than 0.4. 
(ii) P(X1 +X2 > X3).

MULTIDIMENSIONAL DISTRIBUTIONS
161
6.5.3 Two cards are drawn without replacement from an ordinary deck. Let X be the num­
ber of aces, Y be the number of red cards, and Z be the number of hearts. Find: (i) The 
joint distribution of (X, Y, Z). (ii) P{Y = Z}. (iii) The conditional distribution of Z 
given Y = y .
6.5.4 Suppose that X1, X2, X3 have joint density
f( 
) 
x1x2x3 for 0 <xi <c, i=1,2,3
1 , 2 , 3 
0 
otherwise.
Find: (i) c. (ii) The joint density of (Y1, Y2, Y3), where Y1 = X1, Y2 = X1X2, and 
Y3 = X1X2X3.
6.5.5 Let X, Y ,andZ have joint density f (x, y, z)=c(x + y + z) for 0 <x<y<z<1. 
Find:(i)c.(ii)P(X+Z>1).(iii)P(X+Z>1|Y = 0.5).
6.5.6 Assume that variables X, Y, and Z are jointly distributed with the density 
f(x, y, z)=x + y2 + z5 for 0 <x<1, 0 <y<1, 0 <z<1, and 0 otherwise. Find 
P(Y<X|Z=0.21/5).
6.5.7 A lifetime of some electronic unit has density f (t). Each time the unit fails, it is 
replaced by another one with the same lifetime distribution. Let X, Y, and Z be life­
times of three consecutive units independently installed one after the other failed. 
Find:(i)P(X<Y<Z).(ii)P(X<Y<Z)ifweknowthatf(t)=2te-t2 fort>0.
6.5.8 A can of Three-Bean-Salad contains beans of varieties A, B, and C (plus other ingre­
dients which are of no concern for the problem). Let X, Y, and Z denote the relative 
weights of varieties A, B, and C in a randomly selected can (so that X + Y + Z =1). 
Moreover, let the joint distribution of (X, Y) have the density f(x, y) = kx2y for 
x>0,y>0,x+ y<1, and f(x, y)=0 otherwise. Find: (i) k. (ii) Probability 
P (X > 0.5) that beans A take more than half of the total weight. (iii) P (Z > 0.5). 
(iv) Probability that none of the three varieties of beans will take more than half of 
the weight. (v) The marginal density of (X, Z) and of Z.
6.5.9 Let four observations X1, X2, X3, X4 be independently selected from the same distri­
bution with density f (x) = e-x for x>0 and 0 otherwise. Find: (i) The probability 
that exactly one of these observations is less than 1. (ii) P (X1 + X2 <X3 + X4).

CHAPTER 7
EXPECTATION
7.1 INTRODUCTION
The probabilistic concepts discussed in Chapters 5 and 6 could have also been developed 
without using random variables but in a clumsy and awkward way. Random variables 
were used there as a convenient tool of describing large classes of events. Indeed, once we 
considered events of the form {a < X < b}, it was quite natural to reduce the analysis to 
even simpler events {X < t}. Then the probability of such an event, regarded as a function 
of the argument t [i.e., the cumulative distribution function (cdf) of X) turned out to carry 
all information about the distribution ofX. And once the notion of the cdf was introduced, 
it was natural to look for classes of cdf’s that allow for simple description (hence, the 
definition of discrete and continuous random variables).
In this chapter, we introduce the notion of expectation. Expectation, or the expected value 
of a random variable, cannot be formulated without the concept of random variables.
The intuitive content of the notion of expectation is as follows: Consider a random vari­
able X, defined on some sample space S. An experiment consists of a random selection of a 
point s of S, and X(s) is interpreted as the gain (loss, ifX(s) < 0) ofa hypothetical gambler.
If the experiment is repeated n times, the sample space becomes 5n = S x • • • x S (n 
times). An outcome is s (n) = (s 1, ..., sn), with si e S ,i = 1, .. .,n. The gambler’s accu­
mulated gain becomes X(s 1) + X(s2) + • • • + X(sn), traditionally written as X 1 + X2 + 
• • • + Xn, with Xi = X (si) being the outcome of the ith trial.
The average gain per gamble now becomes (X 1 + • • • + Xn) /n. As n becomes larger, this 
average fluctuates less and less, tending to stabilize at some value, which we call the expecta­
tion of X and denote by E(X).
It is not difficult to calculate this value in case of a discrete random variable. Indeed, ifX 
assumes values x1, x2, ...,xm with probabilities pi = P{X = xi},i=1, 2, ...mand if the
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
163

164
EXPECTATION
experiment is to be repeated n times, then {X = xi} will occur ni times (i =1, ...,m), and 
n 1 + n2 + • • • + nm = n. According to the frequency interpretation of probability, the ratio 
ni/n tends to pi = P{X = xi} as the number n of repetitions of the experiments increases. 
The total gain X 1 + • • • + Xn equals x 1 n 1 + x2n2 + • • • + xmnm, and the average gain per 
experiment, 
x 1 n1 + x 2 — + ••• + xm nm 
n n 
mn
tends to
x1p1 + x2p2 + ••• + xmpm .
We will use the last quantity, that is,
E (X) = x 1 P {X = x 1} + ••• + xmP {X = xm} 
(7.1)
as a formal definition of an expected value E(X) of a discrete random variable X. The 
definition will later be extended to also cover random variables that are not discrete.
7.2 EXPECTED VALUE
For simplicity, the definition ofan expected value ofa random variable X is now formulated 
separately for the discrete and continuous random variables.
Definition 7.2.1 IfX is a discrete random variable that assumes values x1, x2, ... with prob­
abilities P{X = xi},i=1, 2, ..., then the expected value ofX is defined as
E (X ) = £ xiP {X = x} 
(7.2)
i
provided that
\xi\P{X = xi} < ж. 
(7.3)
i
IfX is a continuous random variable with the density f (x), then the expected value ofX is 
defined as 
+ ^
E(X) = 
xf(x) dx, 
(7.4)
— tt
provided that
Z
+ <x
|x| f(x) dx < ж. 
(7.5)
Definition 7.2.1 covers formula (7.1) as a special case, since if X assumes only finitely 
many values, condition (7.3) is always satisfied. Conditions (7.3) and (7.5) are necessary to 
eliminate the situation where the value ofan infinite sum depends on the order of summation 
(or integration). The absolute convergence (or absolute integrability) guarantees that the 
expected value is unambiguously defined.
The other symbols used for the expected value E(X) in probabilistic and statistical lit­
erature may be EX, pX, mX, or simply ^, m, if it is clear which random variable is being 
studied. In physics, the symbol used is [X}. Regarding terminology, the expected value is 
also called the expectation, or the mean. Moreover, the expected value is often associated 
not with X, but with its distribution. Consequently, one sometimes uses symbols such as ^F 
or mF,whereF is a cdf.
We begin with a series of examples of expectations for discrete random variables.

EXPECTED VALUE
165
■ EXAMPLE 7.1
Let A be some event, and let p = P (A). Imagine that you are to receive $1ifA occurs 
and nothing if A does not occur (i.e., if Ac occurs). Let X be the random variable 
defined as “the amount you receive.” In this case, X assumes only two values, and its 
distribution is given by the array
Value 
0 
1
Probability 1 — p p
According to formula (7.2),
E(X) = 0 x (1 — p) + 1 x p = p.
The result is quite intuitive: if you play such a game over and over, then your average 
outcome per game will equal the probability of winning, p.
Observe that X can also be described as “the number of occurrences ofA in a single 
experiment.” We will use this interpretation later.
■ EXAMPLE 7.2
Suppose now that you are to win $1ifA occurs, but lose $1 (i.e., “win” —1)ifA does 
not occur. Then the distribution ofY , the random variable describing your winnings, is
Value
—1 
1
Probability
1 — p p
and E(Y )=—1 x (1 — p)+1x p =2p — 1. Thus, E(Y ) > 0 if and only if p>0.5, 
which agrees with our intuition: the game is favorable if the probability p of winning 
exceeds 0.5.
■ EXAMPLE 7.3 Expected Value of Binomial Distribution
The binomial random variable was defined in Example 5.7 as the total number of 
successes in n independent Bernoulli trials, where the probability of a success in any 
single trial is p. The possible values of the binomial random variable are 0, 1, ...,n 
with probabilities given by (5.13). Consequently,
nn
E(X) = 
k nk pk (1 - p)n-k = k
k=0 
k=1
= np ____________(n — 1)!____ pk-1 (1 — p) n-1 - (k- 1)
p^ (k — 1)!(n — 1 — (k — 1))!p 
( 
p)
-----n!-------pk (1 — p)n-k 
k!(n k k)!p ( 
p)
n-1
= np
j=0
n -j 1 pj (1 - p)n-1-j = np,
where in the last sum we introduced the new index of summation j = k - 1. The last 
sum turns out to be a Newtonian expansion of [p +(1- p)]n-1 =1.

166
EXPECTATION
■ EXAMPLE 7.4 Expectation of Geometric Distribution
Let an event A (“success”) have probability p. We keep repeating independently the 
experiments until A occurs for the first time, with X being the number of trials up to 
and including the first success. As already mentioned (see Example 5.8), X is a random 
variable with geometric distribution and P{X = k} =(1- p)k-1p for k =1, 2, .....
Find E(X).
SOLUTION. Letting q =1- p, we write
OO 
OO 
OO 
7
e ( x ) = £ kP {x = k} = E kqk-1 p=p^dr (qk) 
k=1 
k=1 
k=1 q
r k d ( q A 
1 
1
pdq klq q 
P<q\ 1 - q) 
px (1 - q )2 
p.
The answer is intuitive. If, for example, the probability of success is p = 0.2, then on 
average, every fifth trial is a success, and Therefore, the average number of trials until 
the next success is 5, which agrees with formula (7.6).
The following theorem provides a very useful interpretation of the expected value of a 
random variable:
Theorem 7.2.1 Let x be a random variable that assumes only nonnegative integer values. Then
E (X ) = E P {X>n}. 
(7.6)
n=0
Proof : Forpn = P{x = n} we have
E (X ) = p 1 + 2p 2 + 3p 3 
+ • • •
= P1 + 
P 2 + 
P 3 
+ •••
+ p 2 + 
p 3 
+ • • •
+ 
p 3 
+ • • •
= P{X > 0} + P{X > 1} + P{X > 2} + ••• , 
where a change of order of summation is allowed, since all terms are nonnegative. □
■ EXAMPLE 7.5
Let us use formula (7.6) to find the expectation of the geometric distribution from 
Example 7.4. We have
P{X>n} = P {only failures in the first n trials} = qn,
or, if this reasoning appears suspiciously simple and one puts more trust in algebra,
O 
On
p{x > n} =5; p{x = k} = E qk-1 p=p= qn.
k=n+1 
k=n+1 
q

EXPECTED VALUE
167
Consequently,
оо
E(X) = q 
n=0
-q
1 
p.
1
1
The expected value in Example 7.5 was finite. Such situations are most common in prac­
tice, as otherwise, the very concept of expected value would make no sense. However, there 
are cases of both practical and theoretical significance, when the condition (7.3) or (7.5) is 
not met.
To be more precise, one should distinguish between two cases. We will illustrate the pos­
sibilities of condition (7.3) involving the series; the situation with an integral is analogous. 
Let us consider separately sums xiP{X = xi} involving positive and negative terms, that 
is, U + = £[max(xi, 0)] x P{X = xi} and U- = - ^[min(xi, 0)] x P{X = xi}. It is clear 
that if the series (7.3) diverges, then U+, U-, or both must be infinite, for otherwise, the series 
of absolute values (7.3), equal to U+ + U-, would be finite. If only U+ is infinite, we can say 
that E(X) = + x; similarly, if only U- is infinite, we can say that E (X) = —x. It is only 
when both U + and U- are infinite that we have the expression of the form x — x, to which 
we cannot assign any value. In the last case, we say that E(X) does not exist.
In the following example, random variable will have infinite expectation:
■ EXAMPLE 7.6 Petersburg Paradox
Suppose that you have the possibility of participating in the following game. A fair coin 
is tossed repeatedly until a head occurs. If the first head occurs at the kth toss, you win 
2k dollars. Clearly, this is a game in which you cannot lose, so the question is: What is 
the amount you should be willing to pay to participate in such game?
SOLUTION. The most common argument offered in such cases is that one should 
be willing to pay the fee as long as the expected winnings exceed or equal the fee for 
participation in the game. Then, “in the long run,” one should come even or ahead.
Let X denote the winnings in the game (not counting the fee for participation in the 
game). Then the event {X =2k} occurs if the first k - 1 tosses are tails, and the kth 
toss is heads; chances of this event are 1/2k. Consequently, we have
E(X) = 2 x 1 + 22 x 212 +23 x 213 + ••• = x.
Because the expected winnings in this game are infinite, one should be willing to pay 
an infinite fee for the right to play. However, in any particular game, the winnings will 
always be finite, so one is certain to lose.
This phenomenon, discovered in eighteenth century, was named the Petersburg 
paradox. Attempts to solve it led to the introduction of the concept of utility. Without 
going into detail, it is postulated that the utility of money—the value a person attaches 
to a given amount of money—is not constant but depends on how much money the 
person already has. This appears intuitively acceptable: $20 may seem to be a lot for 
someone who has nothing but does not seem like very much to a millionaire.
If u(x) is the utility of $x, then the above postulate implies that u(x) is not propor­
tional to x. The expected utility from participating in the game is
E[u(X)] = £ u(2k) x 211k, 
k=1

168
EXPECTATION
a quantity that may be finite for some “plausible” choices of utility function u(x). In 
particular, Bernoulli suggested u(x)=clog x.
It may be worthwhile to give the following “mechanical” interpretation of E(X). Con­
sider a discrete random variable, with possible values xi and the corresponding probabilities 
pi = P{X =xi},i=1,2,.....
Let us construct a mechanical device corresponding to the distribution ofX. Consider an 
infinitely thin and rigid wire extended from -ж to ж (this is an abstraction that physicists 
use: an ideal void, a perfectly black body, etc.). At points with coordinates x1, x2, ... we 
attach weights that are proportional to probabilities pi (see Figure 7.1 where the sizes of the 
dots symbolize the variability in weight). Then E(X) is the coordinate of the point at which 
the whole device would balance, or its center of gravity.
” * V " ’
E(X)
Figure 7.1 Interpretation of expected value of a discrete random variable.
A similar interpretation also holds for continuous random variables. In this case, we have 
to imagine that an infinitely rigid metal sheet of uniform weight is cut into the shape of 
density f (x). Then, E(X) is the coordinate of the point at which the figure will balance if 
laid flat (see Figure 7.2).
Figure 7.2 Interpretation of expected value of a continuous random variable.
We will now give some examples of expectations of continuous type random variables.
■ EXAMPLE 7.7
Let X have a distribution uniform on interval [A, B] so that (see Example 5.14)
( „1 . for A < x < B 
f (x) И 
~ ~
0 
otherwise.
According to the interpretation given above, the metal sheet figure is just a rectangle. 
Hence, it will balance if supported in the middle between A and B. Thus, we can expect 
that E(X) = (A + B)/2. Indeed, the computations give
FIY-. 
f+“ „ Y, 
fB 
x ,, B 2 - A2 
A + B
E(X) = J-^ xf(x) dx = JA B-Adx = 2(B-A) 
.

EXPECTED VALUE
169
■ EXAMPLE 7.8
We will now find the expected value of random variable X with exponential distribu­
tion with density f (x) = Xe-Xx for x > 0 and 0 otherwise.
SOLUTION. Integrating by parts, we obtain
E(X) = [ x\e-Xx dx = - 1 e-Xx 
= 1.
Jo 
^ 
0 
^
Thus, if the lifetime (in hours) of a certain type of electric bulb has a density 
0.001e-0.001t for t>0, then the expected lifetime equals (0.001)-1 = 1,000 hours.
■ EXAMPLE 7.9
Find the expectation of a normal random variable with the density
f(x) =
1 
_(x-v )2
------e=e 
2 °-2
v22n
SOLUTION. We substitute z = (x — a)/a, dx = a dz, obtaining
E(X) =
1 
++' 
- - 
1 f+ 
- - z2 ,
—== I xe 2°2 dx = ,  ( 
(a + za) e 2 dz
а22П --ж 
2^ --ж
1 1 Гж -^ . a 
Гж _z2 ,
= a X —■;= I e 2 dz +---- -:= I ze 2 dz = a.
2^ -2^ --ж
The first integral in the last line equals a (since the standard normal density integrates 
to 1), while the second integral is 0 because the integrand is an odd function. So the 
integrals over the positive and negative parts of the z-axis (each being finite) cancel 
each other. Thus, a is the expected value of the random variable with distribution 
N(a, a2).
We will next derive an analogue of formula (7.6) for an expected value of a nonnegative 
continuous random variable.
Theorem 7.2.2 Let T be a nonnegative random variable of continuous type, with density f(t) 
and cdf F (t), so that f(t)=F (t)=0for t<0.Then
E(T )= 
ж [1 - F (t)] dt.
0
Proof: Replacing t with 0 dx and changing the order of integration, we have
E(T) = 
xf (x) dx = 
dt f(x) dx = 
f(x) dx dt
0 
0 
0 
0t
= ж [1 - F (t)] dt.

170
EXPECTATION
■ EXAMPLE 7.10
Let us compute again the expectation of a random variable with EXP(A) distribution. 
We have here F(x) = 1 - e-Xx for x > 0. Using Theorem 7.2.2, we obtain E(X) =
JO e-Xx dx = 1 /A.
■ EXAMPLE 7.11
Finally, let us consider the Cauchy distribution with the density given by 
f (x) = 1 x ^-2.
n 1 + x2
It is easy to check that the function f(x) is a density of a random variable:
1 Г+' dx 
nJ —o 1 + x2
1
— arctan x
+ oo
=1.
-o
Regarding expectation, the positive part of the defining integral equals
1 f+'° x dx 
nJ 0 1 + x x2
+o
= + Ж.
0
1
П
x 1log(1 + x2)
In a similar fashion, we check that J— o xf (x)dx = —ж. Hence, the expected value of 
Cauchy distribution does not exist.
PROBLEMS
7.2.1 Variable X assumes values 0, 1, 2, and 3 with probabilities 0.3, a, 0.1, and b, respec­
tively. Find a and b if: (i) E(X) = 1.5. (ii) E(X) = m. First determine all possible 
values of m.
7.2.2 The density of the lifetime T of some part of electronic equipment is 
f (t) = A2te-xt,t > 0. Find E(T).
7.2.3 Suppose there are k = 10 types of toys (plastic animals, etc.) to be found in boxes of 
some cereal. Assume that there is a toy in every box and that each type of toy occurs 
with equal frequency. (i) Find E(X), where X is the number of boxes you must buy 
until you collect three different types of toys. (ii) Suppose that your little sister is 
collecting the cereal toys and would be happy to get the whole set of 10 different 
types. Find E(X), where X is the number of boxes you must buy until she gets a 
complete collection.
7.2.4 Find the expected value E(|X|), where X is a normal random variable with param­
eters ^ = 0 and a2 (the distribution of |X | is called folded normal or half normal).
7.2.5 Let X1, X2, ...,Xn be independent, each with the same distribution. Find 
E[min(X1, ...,Xn)] if the distribution of variables is (i) EXP(A). (ii) U[a, b]. [Hint: 
First find the cdf (or density) of the random variable whose expectation is being 
computed.]
7.2.6 Let X be a nonnegative continuous random variable with hazard rate h(t) = t. Find 
E(X).
7.2.7 Random variables X and Y are jointly distributed with density f(x, y) = 12(x - y)2 
for 0 < x <y << 1 and 0 otherwise. Find E(X) and E(Y).

EXPECTATION AS AN INTEGRAL
171
7.2.8 A point is randomly selected from the interval (0, 1). Find the expected length of the 
smaller part of the interval.
7.2.9 Show that if the expectation of a continuous type random variable X exists and 
the density f (x) of X satisfies the condition f (x) = f (2a — x) for all x > 0, then 
E(X) = a.
7.3 EXPECTATION AS AN INTEGRAL*
Definition 7.2.1 of expected value in the discrete and continuous cases covers most situations 
occurring in practice. Many textbooks do not provide the general definition, and some do 
not even mention the fact that a general definition exists.
One of the consequences of such an omission is that one could come to the conclusion 
that the symbol E(X + Y ) makes no sense ifX is discrete and Y is continuous (since X + Y 
is neither a continuous nor discrete random variable). In fact, the expectation of a random 
variable is generally defined as an integral ofa random variable, treated as a function on the 
sample space S . We will now sketch this definition.
Riemann Integral
Let us start by briefly recalling the definition of an “ordinary” (i.e., Riemann) integral 
ab g(x) dx. For the moment assume that the function g is continuous on [a, b]. We first 
choose a sequence of partitions of the interval [a, b]. To simplify the presentation, suppose 
that the nth partition divides the interval [a, b] into 2n equal parts so that the kth point of 
the nth partition is
xn,k 
a + 2n (b 
a), 
k 0,1, ..., 2 .
Let gn(-,k) be the minimum of function g in the kth interval, that is,
gn(-,k) = 
min 
g(x).
xn,k- 1 ^x^xn,k
We now form the (lower) sum approximating the integral
2n
Sn = 12 gn-k)( xn,k— xn,k-1) = 
k=1
2n
b— a (-)
2n 
gn,k .
k=1
(7.7)
The upper sum Sn is defined in the same way, with the minimum in (7.7) replaced by the 
maximum, say gn(+,k).
It is not difficult to show that Sn < Sn for all n, and that the sequences {Sn} and {Sn} are 
monotone, the first increasing and the second decreasing. If they converge to the same limit, 
say S, then this limit is called the Riemann integral of g, and it is denoted by /b g(x) dx.
This is the essence of the definition; the details may vary in two respects. First, instead of 
dividing the interval [a, b] into 2n equal parts in the nth partition, we can take any points
as long as
a = xn,0 < xn, 1 < ••• < xn,kn = b
lim max (xni — xni-1)=0
n^-ж 1 <i<kn 
, 
,
(this implies that we must have kn ^ ж).

172
EXPECTATION
Second, instead of taking the minimum and the maximum of g over the subintervals of 
partitions (which need not exist if g is not continuous), we can take the value of function g 
at a selected point in each subinterval. We then have one partial sum (instead of lower and 
upper sums), and the requirement is that the limits of these partial sums exist and are the 
same regardless of the choice of the partitions and of the intermediate points.
The main results of the theory built on this definition are very well known: continuous 
functions are integrable on closed finite intervals and if g has antiderivative G (i.e., G' = g), 
then
g(x) dx = G(b) - G(a). 
a
The Riemann integral over an infinite range, /+^ g (x) dx, is defined in the usual manner 
through a limiting passage; we omit the details, which can be found in most calculus texts.
We recall the definition of the Riemann integral in order to better stress the differences 
and also the analogy between the principles of definition of the Lebesgue and Riemann inte­
grals. The difference between the two definitions seems small and, at first, not essential. Yet 
the concept of the Lebesgue integral is of tremendous consequence, allowing us at once to 
free the concept of integral of all inessential constraints, and to stress its most crucial and 
significant features.
Lebesque Integral
Again, assume at first that the function g, defined on the interval [a, b], is continuous, and 
let A<g(x) <B. Instead of partitioning the interval [a, b] on the x-axis, let us partition the 
interval [A, B] on the y-axis. For simplicity, let us again take the partitions into 2n equal 
parts,
A = Уп,0 < Уп, 1 < ••• < Уп,2n = B,
where
k
Уп,к = A + 2П(B -A), k = 0, 1 ,•••,2n.
The lower sum approximating the integral can now be written as
sn =Y- Уп,к x l(Cn,k), 
(7.8)
к=0
where l stands for length and C\ к is the set of points x where the function g lies between 
Уп,к and Уп,к+1; more precisely,
Cn,k = {x : Уп,к < g(x) < Уп,к+i}, k = 0,1, •••,2n - 1 •
The upper sum S*n is defined in a similar way, with yn,k in (7.8) replaced by yn,k+1.
The lower sums Sn and Sn for Riemann and Lebesgue integrals of the same functions 
are illustrated as parts (R) and (L) in Figure 7.3.
The Lebesgue integral is now defined in the same way as the Riemann integral, namely 
as the common limit (if it exists) of the upper and lower sums. Again, we omit the details of 
the extension of the definition to an infinite range.
We may capture the difference in two definitions as follows: In the Riemann integral, 
when we partition the x-axis, we control the intervals on the x-axis, while the maxima and 
minima over these intervals depend on function g . In the Lebesgue integral, when we parti­
tion the y-axis, we control the values, but corresponding sets on the x-axis are determined 
by the function g. The distinction was summarized by Lebesgue, as a comparison of two

EXPECTATION AS AN INTEGRAL
173
Figure 7.3 Approximating sums for Riemann and Lebesgue integrals.
cashiers who, at the end of the day, have to count the cash in their drawers. The “Riemann” 
cashier takes the money out in the order it came in. She counts “A five-dollar bill, and a 
penny makes 5.01; then I have a quarter, which makes 5.26; then ...,” and so on. On the 
other hand, the “Lebesgue” cashier proceeds systematically: “I have n1 twenty-dollar bills, 
which makes 20n1 dollars. Then I have n2 ten-dollar bills, which together makes 20n1 + 10n2 
dollars ..., ” and so on.
One of the main results in the theory of the Lebesgue integral is that if a function is 
Riemann integrable, then it is also Lebesgue integrable, and both integrals are equal. Thus, 
we may use standard calculus to compute Lebesgue integrals, whenever it is applicable. How­
ever, it is important to point out that the class of functions that are Lebesgue integrable is 
substantially wider than the class of functions that are Riemann integrable. To see that it is 
so, consider the following example:
■ EXAMPLE 7.12
Let g be a function continuous on a closed finite interval [a, b] so that g is Riemann 
integrable. It is clear that if we modify g at a single point x0 by defining 
g* (x) = | g(x)
c
ifx = x0
if x = x0,
where c is any number such that c = g(x0), then the function g* (x) is Riemann inte­
grable and ab g(x) dx = ab g* (x) dx. We can modify in this way the function g at any 
finite set of points, and we will still have a Riemann integrable function, with the same 
integral as the original function g. However, if we modify g in such a way at a count­
able set of points, then the resulting function may not be Riemann integrable. This is 
because for a modification at finitely many points, say N , the sums approximating an 
integral of g and an integral of g* differ in, at most, N terms. The difference tends to 
zero, since the sum of lengths of intervals on which the functions g and g* differ tends 
to zero. But this is not necessarily the case where g and g* differ at countably many 
points. Thus, g* may be not integrable in the Riemann sense.
However, g* is integrable in Lebesgue sense because two sets that differ by a count­
able set of points have the same length. So the sums approximating the Lebesgue 
integral are the same for g and g* .
We will now present the two generalizations of the concept of integral introduced thus 
far. The first generalization concerns both the Riemann and Lebesgue integrals, leading in 
a natural way to the corresponding concepts of Riemann-Stieltjes and Lebesgue-Stieltjes 

174
EXPECTATION
integrals. The second generalization, more important for our purposes, will concern 
specifically the Lebesgue integral.
Riemann-Stieltjes Integral
Regarding the first generalization, let us observe that in the approximating sums Sn 
in the Riemann integral given by (7.7), we can write the terms gn(-,k) (xn,k - xn,k-1) as 
gn-kl([xn k- 1 ,xn k]), where l(•) stands for the length of the set (in this case, of a single 
interval). This is similar to the sums (7.8) approximating the Lebesgue integral.
Now, instead of the length being the difference between the coordinates of endpoints, one 
can take a “length-like” function, defined as the differences between values of some func­
tion, F, of coordinates. Thus, the terms of the approximating sums are now gn(-,k)[F (xn,k) - 
F (xn,k-1)]. Naturally, function F has to satisfy some conditions if such an extension is to 
lead to a meaningful concept of an integral.
Without striving for a general definition (which can be found in most books on advanced 
calculus), we will simply consider the case where F is a cdf, meaning a nondecreasing 
function, continuous on the right, satisfying the conditions limx ,..X_F(x) = 0 and 
lim x ,.x F (x) = 1.
The common limit (if it exists) of the two sequences
Sn = 
gn-k[ F(xn,k) - F(xn,k- 1)]
and
S n = 22 gni[ F(xn,k)- F(xn,k- 1)]
will be denoted /b g(x) dF(x), and called the Riemann-Stieltjes (R-S) integral of function 
g with respect to function F. Again, we omit the details of an extension of the concept to 
the improper integral
Z
+ TO
g(x) dF (x).
TO
■ EXAMPLE 7.13
Let us consider a special case where FX is a cdf ofa discrete random variable with the 
set of possible values x1, x2, ... and the corresponding probabilities P{X = xi} = pi. 
As we know from Chapter 5, the cdf of X is a step function that is constant between 
points xi, and its steps equal pi at points xi .
The approximating (lower) sum Sn equals
S n 22 gn ,&[ FX (xn,k ) - FX (xn,k-1)] •
Here the difference FX (xn,k) - FX (xn,k-1) of values ofFX at two consecutive points 
of the nth partition is zero if the interval (xn,k-1, xn,k] does not contain any point xi 
of the increase of FX. When the partition becomes finer as n ^ <x, the only terms in
Sn that remain will be those corresponding to intervals covering the points xi, and the
differences FX (xn,k) - FX (xn,k-1) for intervals covering point xi will converge to pi. 
Under some regularity assumptions (e.g., continuity of g), the values gn(-,k) correspond­
ing to nonzero terms will converge to corresponding values g(xi), and the limit will
be
+TO
' 
g (x) dFx (x) ^2 g(xi) pi •
(7.9)

EXPECTATION AS AN INTEGRAL
175
From formula (7.9) for the special case g(x) = x, we see that
Z
+то
xdFX (x)= 
xiP{X = xi},
то
provided that 
\xi\P{X = xi} < ж (which turns out to be the condition for existence
of the improper integral I-+™ x dFX (x)).
We have the following theorem:
Theorem 7.3.1 If X is a discrete variable with cdf FX and if E(X) exists, then
E(X) = 
+то x dFX(x).
-то
■ EXAMPLE 7.14
Consider the R-S integral in the case where the function F is a cdf of a continuous ran­
dom variable so that F' (x) = f (x), where f is the density of random variable X. In this 
case, the lower approximating sum can be written, using the mean value theorem, as
Sn 
g(-)[F(xnk) — F(xnk- 1)] 
g(-k f (unk)(xnk - xnk- 1),
n ^k^^ nr-ын ^ky^,, 
n°k1>
where unk is a point between xn k- 1 and xn k. Again, if g is continuous, the limiting 
value of Sn (and also Sn) will be the integral of g(x) f (x) between appropriate finite 
or infinite limits. Thus, in this case, the R-S integral becomes
g(x) dF(x) = 
g(x)f (x) dx.
Again, taking g(x) = x, we obtain
Theorem 7.3.2 If X is a continuous random variable with cdf FX, and if E(X) exists, then
E(X) = 
+то x dFX(x).
-то
We therefore have a single expression for an expected value of a random variable, which 
reduces to formulas (7.2) and (7.4) in the case of discrete and continuous random variables.
Lebesque-Stieltjes Integral
The Lebesgue-Stieltjes integral is defined in very much the same way as the Lebesgue inte­
gral. If g is bounded (e.g., on interval [a, b]) so that A < g(x) < B for some A and B, we use 
the sequence of partitions
A = yn о 0 < yn, 1 < ••• < yn 2 2 n = B
and take the (lower) approximating sum as
2n
S n = E yn k k If (Cn k k),
k=0

176
EXPECTATION
where 
Cn,k = {x : Уп,к < g (x) < Уп,к+1}, k = 0, 1, ..., 2n - 1, Cn, 2 n = {x : g (x) = B},
and IF is the generalized length of a set. This length is induced by the cdf F, in the sense 
explained above (see the construction of the Riemann-Stieltjes integral). The upper sum Sn 
is defined similarly, and the common limit (if it exists) of these two sequences of sums is the 
Lebesgue-Stieltjes integral
g(x) dF (x).
a
Again, we omit the details of the extension to integrals over an infinite interval.
As before, if the function g is R-S integrable with respect to F, then it is also L-S inte­
grable, and the integrals are equal. If F corresponds to a discrete distribution with masses 
pi at points xi , then
Z
+те
g(x) dF(x) = 
g(xi)pi,
-те 
i
provided that 
\g(xi) \pi < ж. If F is a cdf of continuous distribution with density f, then
Z
g(x) dF(x) = 
g(x) f (x) dx,
те 
-те
provided that f+^ \g(xi)I f (x) dx < ж.
Lebesque Integral: General Case
We now outline the second direction of generalization, applicable only to the case of the 
Lebesgue (or Lebesgue-Stieltjes) integral.
This generalization, by far the most important and profound extension of the concept of 
the Lebesgue integral, is based on the observation that approximating sums (7.8) make sense 
also for functions g that are defined on sets other than the real line. In fact, we can consider 
real-valued functions g defined on an arbitrary set (in particular, the sample space S). The 
sets Cn,k are then subsets of sample space (hence events), and we let probability P play the 
role of length l.
In a more familiar notation, let X be a random variable defined on sample space S . 
Assume first that X > 0. Similarly to (7.8), we define the approximating sums as
= nE 1 
(s : k- < X(s) <^1 ) . 
(7.10)
n 
2n 
2n 
2n
k=0
Observe that as n increases, the partitions become finer and also their range increases. 
Observe also that according to the comment made in the footnote on the opening page of 
Chapter 5, the probabilities in the sum (7.10) are well defined (i.e., arguments of probabilities 
are events, if X is a random variable).
We will omit the details of construction, which can be found in any advanced text on 
probability. Roughly, two properties are shown:
1. For every random variable X > 0, the sums Sn converge to a finite or infinite limit.
2. This limit exists and is the same if instead of yn,k = k/2n, we take any other sequence of 
partitions, provided that these partitions become finer and eventually cover the whole set 
[0, ж).
Consequently, we define the integral as the limit of sums (7.10):
XdP = lim Sn .
S

PROPERTIES OF EXPECTATION
177
The extension to arbitrary random variables (not necessarily nonnegative) now consists in 
defining
X+ = max(X, 0) and X- = max(-X, 0)
so that X = X + - X - is represented as a difference of two nonnegative functions. One 
then puts
XdP = X+ dP - 
X - dP,
provided that at least one of the integrals on the right-hand side is finite (so that only inde­
terminate case ж — ж is ruled out).
We now have, more formally, the following definition:
Definition 7.3.1 The expectation E(X) of a random variable X is defined as the Lebesgue 
integral of X:
E(X) = 
XdP,
S
provided E\X | = JS |X\dP < ж. If JSX + dP = ж while we have JSX- dP < ж, we define 
E(X) = ж (and similarly for E(X) = —ж). If JSX + dP = fSX- dP = ж, we say that 
expectation of X does not exist. 
□
The expectation of a function of two (or more than two) random variables is defined 
in a similar way. To sketch the construction, consider a nonnegative function g(X, Y ) of a 
pair of random variables (X, Y ). The sums approximating the integral E[g(X, Y )] are of the 
following form, similar to (7.10),
Sn = V —P (s : — < g(X(s),Y(s)) < k+11 • 
n 
2n2n 
, 
2n
k=0
The rest of the construction is analogous to the case of a single random variable, leading to 
the definition of the expectation E[g(X, Y)].
7.4 PROPERTIES OF EXPECTATION
The identification of the expected value ofa random variable X with Lebesgue integral ofX 
allows us to formulate the properties of the latter as the properties of the expectation. Again, 
for the proofs, we refer the reader to any advanced textbook on probability.
Theorem 7.4.1 The expectation of random variables has the following properties:
(a) Linearity. If E(X) exists, then for all а, в,
E (aX + в )= aE (X) + в- 
(7.11)
(b)Nonnegativity. If X > 0, then E(X) > 0.
(c) Modulus inequality. For any random variable X,
IE(X)| < E(|X|)•
We list here two of the most important consequences of this theorem. By putting в =0 
in (7.11), we have E (aX) = aE (X). This means, in particular, that if we change the units of 

178
EXPECTATION
measurement of X , then the expectation of X changes in the same way as X . On the other 
hand, by putting a = 0, we obtain the property E(в) = в. So the expectation of a random 
variable equal to a constant в is equal to the same constant.
In the future, we will often use the following theorem, which gives a sufficient condition 
for the existence of an expected value.
Theorem 7.4.2 If |X | < Y, where E (Y) < ж, then E (X) exists and is finite.
Thus, to prove that the expectation of a random variable exists, it suffices to find another 
random variable Y that dominates it, and whose expectation exists. The domination |X | < 
Y means that |X(s)| <Y(s) for every point s in sample space S. Similarly, the symbol 
limn —tXn = X is understood as a pointwise limit of random variables as functions on 
5, that is, limn—^Xn (s) = X (s) for every s e S.
Next, we give two principal theorems that connect expectation with convergence, allowing 
passing to the limit under the integral (expectation) sign.
Theorem 7.4.3 (Monotone Convergence Theorem) IfX1 ,X2, ... is a sequence of random 
variables such that 0 < X 1 < X2 < • • • and
lim Xn = X, 
n—>^> 
then
lim E(Xn) = E(X).
n—>^>
Theorem 7.4.4 (Dominated Convergence Theorem) LetX1,X2, ... be a sequence of random 
variables satisfying the condition
lim Xn = X.
Moreover, assume that there exists a random variable Y with E(Y) < ж such that |X |<Y 
and |Xn |<Y for n =1, 2, .....  Then
lim E(Xn) = E(X).
n—>^>
In both theorems, the assertion is that limE(Xn) =E(limXn), which means that we may 
interchange the order of integration and passage to the limit.
Instead of presenting formal proofs, we will show the necessity of the assumptions with 
examples.
■ EXAMPLE 7.15
We will now show by an example that the monotonicity alone is not enough for the 
assertion in the monotone convergence theorem; nonnegativity is essential. We let S = 
(0, 1) and let s be chosen according to the uniform distribution. We let Xn be defined as
Xn (s)=
-1/s 
0
if 0 <s< 1/n
if 1/n < s<1.
For each fixed s, the sequence {Xn(s)} is of the form
-1/s, -1/s, . .., -1/s, 0, 0, . ..,
hence is monotone, and limXn = 0. However, EXn = f01 /n(-1 / s) ds = -ж, while 
the integral of the limit random variable X = 0 is EX = 0.

PROPERTIES OF EXPECTATION
179
■ EXAMPLE 7.16
We will show that the existence of the bound Y with finite expectation is essential in 
the dominated convergence theorem. Again, let S = (0, 1), with P being uniform on 
S .Now
{
4 n 2 s
4n(1 - ns)
0
for 0 <s<1/(2n)
for 1 /(2n) < s < 1 /n
for 1 /n < s < 1.
For every fixed s, the sequence of numbers {Xn(s)} converges to 0. Again, the limiting 
random variable is X = 0, and E(X) =0. But it is easy to check that E(Xn) = 1 for 
every n so that the assertion of the theorem does not hold. This time each random 
variable Xn is bounded, but there is no integrable common bound for all of them.
It is now necessary to connect two definitions of expectation of a random variable X : 
as a Lebesgue integral of X, and as a Riemann-Stieltjes integral of function g(x) = x with 
respect to cdf of X.
One may raise a doubt: Starting with Chapter 1, we stress the fact that for the same phe­
nomenon (for the same random variable), the sample space S can be chosen in a number 
of different ways. But if we choose different sample spaces for describing the same random 
variable X, how can we guarantee that the integral ofX is the same, regardless of the choice 
ofS?
The answer lies in the next theorem, which provides methods of computing Lebesgue 
integrals by reducing them to Lebesgue-Stieltjes and Riemann-Stieltjes integrals.
Theorem 7.4.5 Let X be a random variable defined on probability space S, and let F (x) be its 
cdf. If fS |X\dP < ж, then
X XdP = + 
xdF (x). 
(7.12)
S S 
- oo
More generally, ifg is a real function such that S|g(X)|dP < ж, then
E[g(X)] = [ g(X) dP = Г~ g(x) dF(x). 
(7.13)
S 
—o
The right-hand sides of formulas (7.12) and (7.13) provide means of computing the expec­
tations. In the case of discrete and continuous random variables, formula (7.12) reduces to 
(7.2) or (7.4). Similarly, formula (7.13) reduces to
Eg (X ) = 
g (xi) P {X = xi} 
(7.14)
i
and 
+ TO
Eg(X) = 
g(x)f(x) dx. 
(7.15)
— o
■ EXAMPLE 7.17
Formulas (7.12) and (7.13) are sometimes referred to as “theorems of the unconscious 
statistician.” The reason for the name is that in calculating expectations of some ran­
dom variables, a statistician chooses either the left or right side of these formulas, often 
without being aware that using the other side may occasionally be simpler. We illustrate 
the situation by carrying out the calculations for both sides of (7.15).

180
EXPECTATION
Imagine that we have a stick of length 1, and we break it at a random point (i.e., the 
breaking point is chosen accordingly to the uniform distribution). What is the expected 
length of the longer of the two parts?
If we take the interval [0, 1] as the sample space, with measure P being uniform 
(i.e., probabilities are proportional to lengths), then the length of the longer part of the 
stick, if the break occurs at s,is
X = max(s, 1 - s).
The graph of X is presented at Figure 7.4(a). It is clear that E(X) = SXdP= 
/1 max(s, 1 - s) ds = 3/4. This can be obtained by actually computing the integral 
or by observing that the area under the curve in Figure 7.4(a) is three quarters of the 
square of side 1.
Figure 7.4 Graph of X = max(s, 1 - s) and its cdf.
We can also find the cdf ofX and, realizing that X is a continuous random variable, 
use the right-hand side of (7.15). Since 1 /2 < X < 1, we can write
P{X < x} = P{max(s, 1 — s) < x} = P{s < x, 1 — s < x}
= P{1 - x < s < x} = x - (1 - x)=2x - 1.
Consequently, 
{0 
x < 2
2 x — 1 
1 < x < 1
1 
x > 1
[see Figure 7.4(b)], and
E (X )= [ 
x dF (x )= [ x dF (x )= [ x 2 dx 
—.
--™ 
1//2 
1//2 
4
Let us now consider functions of two random variables—we will only discuss discrete and 
continuous bivariate distributions as the two most important cases. Let g(x, y) be a real func­
tion such that Elg(X, Y) | < ж. Suppose first that the distribution of (X, Y) is concentrated 
on A x B, where A = {x/, x2, ... } and B = {y/, y2, ... }. Let pjj = P{X = xi,Y = yj}. 
Then
E[g(X, Y)] = 
g(xi, yj )pij . 
(7.16)
ij

PROPERTIES OF EXPECTATION
181
Since Elg(X, Y) | 
52 lg(xi, yj) Ipij < ж, the sum (7.16) does not depend on the order of
summation. So one can choose the order that leads to simpler calculations:
E[g(X, Y)] = 
g(xi,yj)pij = 
g(xi,yj)pij
i=1 j=1 
j=1 i=1
= 
g(xr,yk-r)pr,k-r,
k=1 r=1
and so on. The choice depends on the function g and probabilities pij .
Let (X, Y) have the joint density f (x, y). We then have
Theorem 7. 4.6 If Elg(X,Y) | < ж, then
+ °
-°
+ oo
o
E[g(X, Y)] = 
g(x, y)f(x, y) dx dy
Z
+ ° 
o
Z
+ ° 
o
(7.17)
The last two expressions provide the computational formulas that can be used in practice, 
since they reduce the computation of a double (two-dimensional) integral to an iteration of 
two single (one-dimensional) integrals.
As an illustration of applicability of Theorem 7.4.6, we give the proof (in the case of 
continuous random variables) of the following theorem:
Theorem 7. 4.7 Assume that E\X| < ж and E\Y| < ж. Then
E(X+Y)=E(X)+E(Y).
Proof: Letf(x, y) be the density of (X, Y), and let fX and fY be the marginal densities of 
X and Y, respectively. Letting g(x, y)=x + y in (7.17), we have
E(X +Y)= 
(x+ y)f(x, y) dxdy
= 1+ ° 1+ ° xf (x,y) dxdy + 1+ ° 1+ ° yf (x,y) dxdy
-o 
-o 
-o 
-o
= f+° x [ f+° f (x, y) dy 1 dx + f+° y [ f+° f (x, y) dx 1 dy
-° 
-° 
-° 
-°
= [ 
xfx (x) dx + [ 
yfY (y) dy = E(X)+ E(Y).
-° 
-°
The order of integration can be changed since we assumed that f+° |x| fx(x) dx < ж, 
f+° [yfY(y) dy < ж. 
□
The property of additivity extends immediately to any finite number of random variables 
with finite expectations:

182
EXPECTATION
E ( X1 +-----+ Xn ) = E ( X1) +------ + E ( Xn ),
or, combining it with Theorem 7.4.1(a), we have
E (в 1X1 + ... + 0nXn + a ) = £ eiE (Xi) + a.
i=1
Finally, the nonnegativity property (b) in Theorem 7.4.1 implies that expectation is mono­
tone: if X and Z have finite expectations, then Y < Z implies E(Y) < E(Z). To see this, we 
write Z = Y + (Z - Y), where now Z - Y > 0. We have
E (Z) = E (Y) + E (Z - Y) > E (Y).
We have also the following important theorem:
Theorem 7. 4.8 If X and Y are independent random variables such that EIXY| < ж, then
E(XY) = E(X)E(Y).
Proof: We give the proof only for the case of continuous random variables.
E(XY) = 
xyf (x, y) dxdy = 
xyfX(x)fY (y) dxdy
= ({ 
xfx (x) dx^ x (/ 
yfY (У) dy} = E(X) E(Y).
—J 
- —J —^ 
/ 
I2J
Replacing the double integral by the iterated integrals, as well as the change of the order 
of integration (or summation), is very often taken for granted. Actually, the fact that iterated 
integrals are equal to one another is not a “law of nature,” as some are inclined to believe. 
It is a fact that is true under specific assumptions, namely under the existence of the double 
integral.
We will not provide here the precise statement of the relevant theorem (see the Fubini 
theorem or Lebesgue integration in any advanced textbook on probability). Instead, we will 
give a simple example that shows that the iterated integrals need not be equal.
■ EXAMPLE 7.18
Consider f (x,y) described in Figure 7.5. Obviously, here f™ f (x,y) dx = 0 for 
every y,
y
-1
0
0
Function f (x, y)
Figure 7.5 Nonintegrable function whose iterated integrals exist and are not equal. 

PROPERTIES OF EXPECTATION
183
so Jo” Jo” f (x, У) dx dy = 0. On the other hand, ” f (x, У) dy is 1 for 0 < x < 1 and 
0 otherwise, so ” ” f (x, y) dx dy = 1.
It ought to be clear that the reason why there is a difference between the values of 
two iterated integrals is that the double integral (the sum of infinitely many “volumes” 
+ 1 and infinitely many “volumes” -1) does not exist.
■ EXAMPLE 7.19
Consider now a function h(x, y) similar to that of Example 7.18 given in Figure 7.6.
y
x
Function h(x, y)
Figure 7.6 Nonintegrable function whose iterated integrals exist and are equal.
In this case, we have o” h(x, y) dx = o” h(x, y) dy =0, so both iterated integrals 
exist and are equal zero. Still the double integral does not exist, for the same reason as 
in Example 7.18.
Examples 7.18 and 7.19 show that if the double integral does not exist, we cannot say 
anything about equality of iterated integrals.
PROBLEMS
7.4.1 Show that E(X - E(X)) =0.
7.4.2 Assume that X has density f (x) = ax + bx3 for 0 < x < 2 and f (x) = 0 otherwise. 
FindaandbifE(X2)=2.5.
7.4.3 Find E(X),E(1/X), and E(2X) ifX =1, 2, ...,8 with equal probabilities 1/8.
7.4.4 Let X be a random variable with density f(x) = 1/2 for -1 < x < 1 and f(x)=0 
otherwise. Find: (i) E(X). (ii) E(X2). (iii) E(2X - 3)2.
7.4.5 Let X have the density
{
cx 
0 < x < 1
c(2 - x) 
1< x < 2
0 
otherwise.
Find: (i) c. (ii) E(X). (iii) E(2 - X)3. (iv) E[1/(2 - X)].

184
EXPECTATION
7.4.6 An urn contains w white and r red balls. We draw n < r balls from the urn without 
replacement, and we let X be the number of red balls drawn. Find: E(X), by defin­
ing indicator variables: (i) X 1, .. .,Xn such that X = X 1 + • • • + Xn. (ii) Y1, • • • ,Yr 
such that X = Y1 + • • • + Yr.
7.4.7 A cereal company puts a plastic bear in each box of cereal. Every fifth bear is red. 
If you have three red bears, you get a free box of the cereal. If you decide to keep 
buying this cereal until you get one box free, how many boxes would you expect to 
buy before getting a free one? [Hint: Represent the answer as E(X1 + X2 + X3), 
where Xi is the number of boxes you buy after getting the (i - 1)st red bear and 
until getting ith red bear.]
7.4.8 Show that ifX is such that P(a < X < b)=1, then E(X) exists and a < E(X) < b.
7.4.9 We say that X is stochastically smaller than Y (X <stY) if P{X < t} > P{Y < t} for 
all t. Show that ifX and Y have finite expectations and X<stY, then E(X) < E(Y). 
(Hint: Start with nonnegative X and Y and use Theorem 7.2.2. Then use the decom­
position into a positive and negative part.) Show also that the converse assertion is 
false: there exist random variables X and Y such that E(X) < E(Y) and X is not 
stochastically smaller than Y.
7.5 MOMENTS
We begin with the following definition:
Definition 7.5.1 For any random variable X, the expectation of Xn, ifit exists, will be called 
the nth ordinary moment (or the moment of order n)ofX and denoted
mn = E (Xn). 
□
The nth moment, mn, exists if E\X|n < ж. The moment of the order 0 always exists 
and equals 1, while m1 is simply the expectation of X .Ifthenth moment exists, it may be 
computed from the formula
mn = E (Xn) = + 
xn dF (x),
— TO
where F is the cdf of X; this formula is obtained by substituting g(x) = xn in (7.13). Observe 
that any bounded random variable X, that is, a random variable such that P(|X|<M)=1 
for some M < ж, has finite moments of any order. This follows at once from Theorem 7.4.2, 
and in this case, we have mn < Mn .
■ EXAMPLE 7.20
Let X have POI(A) distribution. Then
TO Ak 
A Ak- 1
m 1 = E(X) = £ kk!e- = A X a 
= A
k=0 
k=1
On the other hand,
m2 = E(X2) = '£ k2 Ake- = £[k(k — 1) + k]e— 
k=0 
k=1
TO
= a 2 E
k=2
Ak-2
(k-2)!
TO
+ A E
k=1
A A______
(k - 1)! = A2 + A,
e
A
since the second sum equals m1 = A.

MOMENTS
185
■ EXAMPLE 7.21
dx _ 1 
bn+1 — an+1
b—a n+1 b—a
Let X have the U[a, b] distribution. Then its density is f (x) = 1 / (b — a) for a < x < b 
and f(x) = 0 otherwise so that
mn = xn
When the distribution is symmetric around 0, then a = —b, and we have 
m2k = b2k/(2k + 1) while m2k+1 =0.
Before introducing the concepts which will illustrate the usefulness of the notion of 
moments, let us introduce some definitions pertaining to a variety of types of moments.
Definition 7.5.2 An absolute moment of order n is defined as
вп = E (X In) • 
□
The existence ofan absolute moment ofa given order implies the existence ofan “ordinary” 
moment mn of the same order. Note that the order of absolute moments need not be an 
integer. The same applies to ordinary moments of positive random variables.
Definition 7.5.3 Ordinary moments of the random variable Y = X — E(X)=X — m1, are 
called central moments of X so that
Yn = E [(X — m 1) n ] . 
□
Clearly, the first central moment y 1 is always equal to 0.
Definition 7.5.4 A factorial moment of X of order n is defined as
nn = E [ X (X — 1)... (X — n +1)]. 
□
We will now prove the following:
Theorem 7.5.1 If an absolute moment of order a > 0 exists, then all moments (ordinary, abso­
lute, central, and factorial) of orders r < a exist.
Proof: We will prove first that if E (|X |“) < ж, then E (|X |Г) < ж for all r <a. Clearly, if 
|X| > 1, then |X|Г < |X|“, while if |X| < 1, then |X|Г < 1. Consequently,
|X|Г < max(1, |X|“), 
(7.18)
and (see Theorem 7.4.2) it remains to show that the right-hand side of (7.18) has finite expec­
tation.
Now, if E\X|“ < ж, then
E(|X|“)= У |x|“ dF(x) + у 
|x|“ dF(x),
and it follows that I .,.> 1 |x|“ dF(x) < ж as a difference of two finite quantities. Thus, we 
can write
E(|XГ) < E{max(1, |X|“)} = У dF(x) + 
|x|“ dF(x) < ж.
It remains to prove that if E|X|“ < ж, then all other types of moments of order a exist. 
This is true for ordinary moments (by definition). Regarding central and factorial moments 
of order n, they are linear combinations of ordinary moments of order k < n, which proves 
the theorem. 
□

186
EXPECTATION
The following theorem will be given without proof:
Theorem 7.5.2 (Liapunov Inequality) If 0 < a < в < ж, then
{E(|X|“)}1 /a < {E(|XIе)}1 /e.
Note that the first part of the proof of Theorem 7.5.1 is an immediate consequence of the 
Liapunov inequality.
We will now introduce a function that will be a valuable tool in analyzing random variables 
and limiting behavior of their sums.
Definition 7.5.5 The function of real variable t defined as
mX(t) = E(etX)
is called the moment generating function (mgf) of a random variable X. 
□
For any random variable, its mgf exists for t =0.IfX is a positive random variable, and 
the mgf of X exists for some t0, then mX (t) exists for all t < t0. This fact follows from 
Theorem 7.4.2.
■ EXAMPLE 7.22
If X has the BIN(n, p) distribution, then
n
mX(t) = 
etk nk pkqn-k = (pet +q)n
k=0
so that mX (t) exists for all t.
■ EXAMPLE 7.23
If X has EXP(A) distribution, then we can write
mx (t )=^ etx x Ae-Xx dx = A^ e-(X-t)x dx =-^, 
(7.19)
provided that t < A. For t > A, the integral in (7.19) diverges.
Let us explore some of the properties of moment generating functions. First, observe that 
the concept of the mgf is connected with a distribution rather than with a random variable: 
two different random variables with the same distribution will have the same mgf.
The name “moment generating function” is related to the following theorem:
Theorem 7.5.3 Let X be a random variable with the mgf mX (t), assumed to exist in some 
neighborhood oft = 0. If E(|X|n) < ж, then for k =1, ...,n,thekth moment ofX is given 
by the formula
dk 
mk = dtk mx (t) 
.
dt 
t=0

MOMENTS
187
Proof: Differentiating formally the expression for the mgf under the sign of expectation (i.e., 
under the integral or summation sign), we obtain
m'x (t) = E (XetX), mX (t ) = E (X 2 eex),..., dk
dtk mx (t ) = E (XketX ),
for k =1, 2, ...n. Substitution oft = 0 gives the required result.
The validity of this argument depends crucially on whether or not formal differentiation 
under the integral sign is allowed. The answer is positive if the corresponding derivatives 
are absolutely integrable for t =0, which is ensured by the existence of the nth absolute 
moment. 
□
■ EXAMPLE 7.24
Since the mgf of random variable with BIN(n, p) distribution is mX (t)=(pet+ q)n, 
we have m'X(t)= n(pet + q)n-1 pet while m'X(t)= n(n — 1)(pet + q)n-2(pet)2 + 
n(et + q)n-1 pet. Thus E(X) = m'x(0) = np and E(X2) = mx(0) = n(n — 1)p2 + 
np.
■ EXAMPLE 7.25
The mgf of the U[a, b] distribution is
mX(t) = betx 
a
1 
ebt— eat
------ dx = ■—-------- .
b — a 
t(b — a)
(7.20)
Determination of the values of derivatives of mX (t) att = 0 requires repeated usage 
of the de L’Hospital rule. We can, however, expand exponentials into power series, and 
after some algebra, we obtain
mX(t)=1+
1 b2 - a2 
1 b3 — a 3 2
21.1— t+ 3 — t +
This is a Taylor expansion of mX (t) about t =0. So we must have
mn = m(Xn) (0) =
n! 
bn+1 — an +1
(n +1)! 
b — a
------- [ bn + bn-1 a + bn-2 a2 + ... + an ]. 
n+1
Next, we will prove
Theorem 7.5.4 If X is a random variable with mgf mx (t), then the random variable Y = aX + 
в has the mgf
mY (t) = eetmx (at). 
(7.21)
Proof: From the properties of the expectation,
mY(t) = E(etY) = E(e*(aX+e)) = E(e(at)X x eet) = eetmx(at).

188
EXPECTATION
■ EXAMPLE 7.26
Let us find the mgf’s of random variables U and V , with distributions U[0, 1] and 
U[-1, 1], respectively.
If variable X has a U[a, b] distribution, and hence has the mgf given by (7.20), 
then U =(X - a)/(b - a) has a distribution uniform on [0, 1]. Using formulas (7.20) 
and (7.21) for a = 1 /(b - a) and в = —a/(b — a), we obtain
mU(t) = e-at/(b-a)mX
t 
b—a
et — 1
(7.22)
t
Next, if V has a U[—1, 1] distribution, then V =2U — 1. Taking a =2and в = —1 
and using (7.22), we get
mv(t)=e tx
et — e-t 
sinh t
2t 
= t
Obviously, the expressions for these mgf’s can be obtained directly from the definition.
■ EXAMPLE 7.27
The mgf of a N(^, a2) distribution can be found by first finding the mgf of a standard 
normal random variable Z ~ N(0, 1) as
mZ(t) =1 f' etze-z2 dz = eL/L f' e-(112)(z-t)2 dz = et212.
2^--^ 
2^--^
Then, for any X ~ N(^, a2), X = ^ + aZ, and based on Theorem 7.5.4 we obtain
mX (t )= e^t+a 2 t2 / 2. 
(7.23)
We now prove
Theorem 7.5.5 If X and Y are independent random variables with mgf’s mX (t) and mY (t), 
respectively, then the mgf of X + Y is
mX+Y (t) = mX(t)mY (t).
Proof : Observe that random variables etX and etY are independent for each t,soby 
Theorem 7.4.8, we have
mX+Y (t) = E(et(X+Y)) = E(etX)E(etY ) = mX(t)mY (t).
□
Before proceeding with examples, we state one more important theorem. Its proof is 
beyond the scope of this book.
Theorem 7.5.6 If X and Y are two random variables such that their mgf’s mX (t) and mY (t) 
coincide in some neighborhood of the point t =0,thenX and Y have the same distribution.
Theorem 7.5.6 asserts that if two mgf’s agree in some neighborhood oft =0, then they 
agree for all t (for which they are defined), and that an mgf determines uniquely the distribu­
tion. In other words, random variables with different distributions must have different mgf’s.

MOMENTS
189
■ EXAMPLE 7.28
Let X and Y be independent and have Poisson distributions with means A 1 and A2, 
respectively. Let us first determine the mgf’s of X and of Y.Wehave
mx (t) = f etke-‘ = e-‘ AL AeA = 
'(e'-"
k=0 
k=0
Similarly, mY(t) = ex2(e'- 1), and by Theorem 7.5.6,
mx+Y(t) = mX(t)mY(t) = e(Л 1 +Л2)(e - 1)• 
(7.24)
We recognize (7.24) as the mgf of the Poisson distribution. In view of Theorem 7.5.6,
X + Y has a Poisson distribution with mean A1 + A2 .
The main disadvantage of mgf’s is that they may not exist for any t =0. There exist 
random variables X such that the random variable etX has no expectation for any t =0. 
This restricts the usefulness of mgf’s as a tool (to be explored in Chapter 9) for obtaining 
limit theorems. For proofs using mgf’s to be valid, they have to be confined to classes of 
random variables for which the mgf’s exist in some neighborhood oft =0. The correspond­
ing theorems, however, are typically valid without this assumption, and the proofs usually 
require nothing more than replacing the mgf’s with so-called characteristic functions (chf’s). 
Although we will not use chf’s in this book, it is worthwhile to provide their definition and 
simplest properties. The concepts below require a rudimentary knowledge of complex num­
bers.
Definition 7.5.6 Let X be a random variable with the cdf F. The function ^x of real argu­
ment t ( —ж <t< + ж ) defined as
Vx (t ) = E (eitX ) = 
eixdF (x)
(7.25)
is called the chfofX (or of the cdf F).
□
In the definition above, i is the imaginary unit (i.e., i2 = — 1). From the formula ei = 
cos £ + i sin £, we obtain
<^x (t) = E {cos( tX)} + iE {sin( tX)},
(7.26)
so <px(t) is a complex-valued function of a real argument. Since leitX | = cos2(tX) + 
sin2(tX) = 1, the expectation in (7.25) exists for all t, so the chf’s always exist.
Below we list some basic properties of chf’s; the proofs are left as exercises. In particular, 
Theorems 7.5.3, 7.5.4, and 7.5.5 carry over to the case of chf’s almost without any change. 
In the following theorems, ^X ,^Y, • •. are chf’s of random variables X,Y, • • •:
Theorem 7. 5.7 For every random variable X, its chf ^X (t) is uniformly continuous and satisfies 
the conditions
Vx (0) = 1, 
Ivx (t) | < 1, 
(7.27)
for every real t. Moreover, for any real a, b,
Vax+b (t ) = ^x (at) eil,t• 
(7.28)

190
EXPECTATION
In particular, for a = -1,b=0, using (7.26,) we obtain
t-x (t ) = ? (-t )= f(t), 
(7.29)
where z stands for the complex conjugate of z.
■ EXAMPLE 7.29
If X ~ BIN(n,p), then
Vx (t) = E(eitX) = eitk ( n ) pk qn = (peit + q)n = [(p cos t + q) + ip sin t]n. 
k=0
In this case pX (t) is a periodic function.
■ EXAMPLE 7.30
If X is uniform on [0, 1], then
Vx (t) = ^ 1 ei^x dx = it (t — 1).
If Y =2X - 1, then Y has uniform distribution on [-1, 1] and (7.28) gives
^Y (t) = V 2 X - 1( t) = ^X (2 t) e it = 2it (e 2 it — 1) e it = ~j~-
■ EXAMPLE 7.31
If X ~N(0,1), then
pX (t) =1 
[+“ eitxe—x2/2 dx = e-L/L [+“ e-(1 /2)(x-it)2 dx = e-t2/2.
XXY 
2^ -, 
2 
J-^
The addition of independent random variables corresponds to multiplications of 
their chf’s.
Theorem 7. 5.8 If random variables X and Y are independent, then
^X+Y (t ) = ^X (t ) ^Y (t ).
As in the case of mgf’s, chf’s uniquely determine the distributions:
Theorem 7. 5.9 If two cdfs F and G have the same chf then F = G.
Finally, the relationship between moments ofX and behavior of chf in the neighborhood 
of t =0is given by the following theorem:
Theorem 7.5 .10 If X is a random variable such that E(|X\k) < ж for some integer k > 1, 
then
^x (t) = 
i! mj tj + o(\t\k)
j=0 j!
in some neighborhood of t = 0. Here mj = E(Xj), and o(x) is such that limx^0 o(x)/x = 0.

VARIANCE
191
PROBLEMS
7.5.1 Find the mgf of a discrete random variable X with distribution P {X = k} = 
1/n, k =0, 1, . . . ,n - 1.
7.5.2 Let X be a nonnegative integer-valued random variable. The function gX (s) = EsX, 
defined for |s| < 1, is called a probability generating function, or simply a generating 
function, of X. Find gX (s) for random variables with: (i) Geometric distribution. 
(ii) Binomial distribution. (iii) Poisson distribution.
7.5.3 Find the fourth factorial moment of the random variable X with a POI(A) distribu­
tion.
7.5.4 Find the mgf for a random variable with a density: (i) f (x) = xe-x for x > 0. (ii) 
f (x; a2) = у/2//пe-x2/2a2 for x > 0.
7.5.5 Let X1 , ...,Xn be independent random variables with the same distribution 
N(m, a2). Find constants an and вп such that U = (X 1 + • • • + Xn - an)/ вп and 
X1 have the same distribution.
7.5.6 A continuous random variable X is called symmetric about c if its density f satisfies 
the condition f(c - x)=f(c + x) for all x. Show that: (i) IfX is symmetric about c 
and E(X) exists, then E(X) = c. (ii) IfX is symmetric about 0, then all moments of 
odd order (if they exist) are equal to 0.
7.5.7 Let X be a random variable with E(X) = m, E(X - m)2 = a2 and such that the third 
central moment y3 = E(X — M)3 exists. The ratio y3/a3 is called the coefficient of 
skewness. Find skewness of the following distributions: (i) U[0, 1]. (ii) f (x) = axa-1 
for 0 < x < 1 and f(x) = 0 otherwise (a>1). (iii) BIN(1, p). (iv) POI(A).
7.5.8 Let X be a random variable with E(X) = M, E(X - M)2 = a2 and such that y4 = 
E(X - M)4 exists. Then y4/a4 is called the coefficient of kurtosis. Find kurtosis of 
the following distributions: (i) N(0,1). (ii) N(M,a2). (iii) BIN(1,p). (iv) POI(A).
7.5.9 Let random variable X have mgf mX(t) = 0.2 + 0.4e-t + 0.1et + 0.3e2t. Use mX to 
obtain E[X (X - 1)(X - 2)]—the third factorial moment ofX.
7.5.10 Find the chf of the following distributions: (i) POI(A). (ii) GEO(p). (iii) EXP(A). (iv) 
N(M, a2).
7.5.11 A family G of distributions is said to be closed under convolution, if whenever inde­
pendent random variables X and Y have distributions in G ; the same is true for the 
random variable X + Y . Show closeness under convolution in families of: (i) Poisson 
distributions; (ii) Normal distributions.
7.5.12 Show that if p(t) is a chf, then |y>(t) 12 is also a chf.
7.5.13 Show that the distribution of X is symmetric around 0 if and only if <pX (t) is real.
7.6 VARIANCE
We will now introduce a concept that plays an extremely important role in statistical analysis.
Definition 7.6.1 If E(X2) < ж, then the second central moment ofX,
Var(X) = E[(X - m1)2],
is called the variance of X. Its positive square root is called the standard deviation of X. □

192
EXPECTATION
The other symbols used for the variance are V(X) ,ax, and a2.
We begin by listing some basic properties of the variance and providing preliminary 
examples. First, observe that
Var(X) = E(X2 - 2m1X + m12) = E(X2) - 2m1E(X) + m21
= E(X2) - [E(X)]2. 
(7.30)
Formula (7.30) gives an alternative way of calculating the variance. Note that variance 
is always nonnegative, as the expectation of a nonnegative random variable (X - m1)2. 
Consequently, E (X 2) > [ E (X )]2; that is, E (X 2)1 / 2 > IE (X) |, which is a special case of the 
Liapunov inequality given in Theorem 7.5.2.
Theorem 7.6.1 If Var(X) exists, then
Var(aX + b) = a2Var(X). 
(7.31)
Proof : Using the fact that E(aX + b)=aE(X)+b,wewrite
Var(aX +b)=E[(aX + b)2] - [aE(X) + b]2
= E[a2X2 +2abX+b2] - a2[E(X)]2 - 2abE(X) -b2
= a2[E(X2) - (E(X))2] = a2Var(X). 
□
■ EXAMPLE 7.32
Let X have the Poisson distribution with mean A. Then its mgf is mX (t) = ex(et- 1) 
(see Example 7.28). After some algebra, we obtain
m'X (t) = A (Aet + 1) ex (et- 1)+t
so that E(X2) = mX(0) = A2 + A. Now, Var(X) = (A2 + A) — A2 = A. Thus, for the 
Poisson distribution, the mean and variance coincide.
■ EXAMPLE 7.33
From Example 7.24, we know that if X has BIN(n, p) distribution, then
E(X) = np, E(X2) = n(n - 1)p2 + np. Consequently, using (7.30), we obtain
Var(X) = n(n - 1)p2 + np - (np)2 = np(1 - p) = npq. 
(7.32)
■ EXAMPLE 7.34
Let us find the variance of random variable X with a U[a, b] distribution. We have
f (x) = 1 / (b — a) for a < x < b, E (X) = (a + b) / 2, and
E(X2) = 1 x b3-a3 = 1[b2 + ab + a2], 
3 b—a 3
so Var(X) = (b — a)2/12.
■ EXAMPLE 7.35
In Example 7.23, we found that the mgf of the EXP(A) distribution is 
m(t) = A(A — t) - 1. Consequently, m' (t) = A(A — t) -2, m" (t) = 2A(A — t) -3. Then 
E(X) = 1/A, E(X2) = 2/A2 and Var(X) = 1/A2, so in the exponential distribution 
the mean and standard deviation coincide.

VARIANCE
193
To interpret the variance, let us now consider the case of a discrete random variable. The 
variance equals
Var(X) = 
(xi - m 1 )2P(X = xi). 
(7.33)
i
For the variance to be small, all terms of the sum (7.33) must be small. Hence, the values 
xi with the large difference |xi - mi | must have a low probability. Qualitatively speaking, 
a small variance means that the values of X are concentrated closely to the mean of X, so 
large deviations are unlikely. The following theorem provides another interpretation of the 
variance:
Theorem 7.6.2 The mean square deviation from £, E (X — £ )2, is minimized at £ = E (X), and 
the minimal value equals Var(X).
Proof: Since f(£) = E(X2) - 2£E(X) + £2 represents a parabola with branches directed 
upward, the minimum occurs at the point £* at which f' (£*) = 0, so £* = E(X). 
□
The function f(£) corresponds to the case where, qualitatively speaking, “small errors are 
almost negligible, large errors are very serious.” The function g(£) in Example 7.36 treats the 
seriousness of an error as proportional to its size.
■ EXAMPLE 7.36
A natural question that arises from problem posed in Theorem 7.6.2 is to determine £ 
that minimizes
g(£)=E|X-£|.
The minimization of g(£) is not as simple as that of f(£). We have to turn here to the 
following result:
Theorem 7.6.3 The mean absolute deviation from £, E|X - £|, is minimized at £ = m, where 
m is the median ofX.
Proof: We will present the proof in the case of the continuous random variable X with 
density f. It suffices to show that E(|X — m\) < E(|X — a|) for every a. Assume now that 
m<a. Then
E(|X — m|) — E(|X — a|)= 
[(m — x) — (a — x)]f (x) dx
— tt
+ 
[(x — m) — (a — x)]f (x) dx
m
+ 
[(x — m) — (x — a)]f (x) dx,
a
which simplifies to
Z
(m — a) f (x) dx + 
(2x — m — a) f (x) dx + 
(a — m) f (x) dx.
-^ 
m 
a
Since 2x — m — a < 2a — m — a = a — m for m < x < a, combining the second and third 
integral, we obtain the inequality
E(|X — ml) — E(|X — a|) < (m — a)[P(X < m) — P(X > m)].

194
EXPECTATION
Since m — a < 0 and P(X < m) — P(X > m) > 1 /2 — 1 /2 = 0, we have E(|X — m\) — 
E(|X — a|) < 0. The proof for a < m is analogous. 
□
We now explore the behavior of the variance of sums of random variables. This will nat­
urally lead us to certain new important concepts.
To make the notation more readable, we let mX = E(X) and mY = E(Y ). Then
Var(X +Y)=E(X +Y)2 — [E(X +Y)]2
=E(X2+2XY +Y2) — (mX +mY)2
= E(X2) — m2X +E(Y2) — m2Y + 2[E(XY) — mXmY]
= Var(X) + Var(Y) + 2[E(XY) — mXmY].
The last quantity appears sufficiently often to deserve a separate name.
Definition 7.6.2 The quantity
Cov(X,Y)=E(XY) — E(X)E(Y) = E[(X — mX)(Y —mY)] 
(7.34)
is called the covariance of random variables X and Y. 
□
We shall show that Cov(X, Y) exists whenever X and Y have finite second ordinary 
moments. Indeed, 0 < (X —Y)2 = X2 — 2XY+Y2,andthisgives2XY< X2 +Y2.Con- 
sequently
lXY|< X2 + Y2.
Thus, if E(X2) < ж and E(Y2) < ж, then also E(\XY|) < ж and Cov(X, Y) exists. 
We have therefore
Theorem 7.6.4 If E(X12) and E(X22) exist, then
Var(X1 + X2) = Var(X1) + Var(X2) + 2Cov(X1,X2),
and more generally, if E(Xi2 ) < ж for i =1, ...,n then
n
Var(Xi + ... + Xn) = £ Var(Xj) + ^2 
Xi, Xj).
j=1 
i<j
Definition 7.6.3 The random variables X, Y for which Cov(X, Y)=0are called uncorre­
lated or orthogonal. 
□
Observe that in view of Theorem 7.4.8, independent random variables with finite vari­
ances are uncorrelated. Consequently, we have
Theorem 7.6.5 If random variables X1 , .. .,Xn are pairwise uncorrelated, then
Var(X1 + ...+Xn)=Var(X1)+...+Var(Xn). 
(7.35)
In particular, (7.35) holds if X1, ...,Xn are independent.
Let us find the variance of a linear combination of random variables, that is, a variance 
of the sum
Y = a1X1 + a2X2 + ...+ anXn.

VARIANCE
195
Using Theorem 7.6.4, we have
n
Var(Y) = £ Var(aiXi) + 2 £ Cov(aiXi, ajXj). 
i=1 
i<j
By Theorem 7.6.1, Var(aiXi) = ai2Var(Xi), while
Cov(aiXi,ajXj) = E(aiXi x ajXj) - E(aiXi)E(ajXj)
= aiaj[E(XiXj) - E(Xi)E(Xj)] = aiajCov(Xi,Xj).
Consequently,
n
Var(Y) = 
ai2Var(Xi) + 2 
aiajCov(Xi,Xj).
i=1 
i<j
In particular, if X1, ...,Xn are uncorrelated, then
n
Var(Y) = 
ai2Var(Xi). 
(7.36)
i=1
■ EXAMPLE 7.37
For the variance of a difference of two random variables, X1 - X2 ,wetakea1 = 
1,a2 = -1, and obtain
Var(X1 - X2) = Var(X1) + Var(X2) - 2Cov(X1,X2);
hence for uncorrelated random variables
Var(X1 - X2) = Var(X1) + Var(X2). 
(7.37)
■ EXAMPLE 7.38 Averaging
If X1, ...,Xn are independent, with the same distribution, then in statistics, we call 
them a random sample and their average
X 
X1 +----------- + Xn
X n = -------------~-------------
n
is referred to as a sample mean. If Var(Xi) = a2, then using ai = 1 /n, i = 1, ... ,n in
formula (7.36), we obtain
Var( X n) = 
nn
Thus, averaging decreases the variability (as measured by the variance) by the factor 
1 /n. The standard deviation of the sample mean is therefore decreased (as compared 
to the standard deviation of a single observation) by the factor 1 / ^n.
■ EXAMPLE 7.39 A Foot
The effect of averaging on variability, computed in Example 7.38, appears to have been 
understood long before the beginning of probability and statistics. This is illustrated by 
the following law from the Middle Ages that defined the length of one foot (before you 
read any further, think for a while: How could a measure of length be defined centuries 
ago so as to be—as much as possible—uniform throughout a country?).

196
EXPECTATION
The law specified the following procedure (apparently, the standard of one foot was 
necessary only on market days—in this case on Sundays after Mass). The shoes of the 
first 16 men leaving the church (this was an attempt to get a random sample!) lined 
up, toe to heel (Figure 7.7), gave the “right and lawful rood” (e.g., see Stigler, 1996). 
Then 1/16 of it was to be used as measure of 1 foot. The number 16 was clearly chosen 
because it was easy to divide a string into 16 equal parts, by folding it four times into 
halves.
Figure 7.7 Length of 16 feet (Drawing by S. Niewiadomski).
This procedure cuts down the variability of the length of feet, as measured by the 
standard deviation, by the factor of 4.
■ EXAMPLE 7.40 Problem of Design
Suppose that you have a scale and a set of weights at your disposal. The weight of two 
objects, A and B, has to be determined as precisely as possible, with the scale used only 
twice.
SOLUTION. If you put an object on a scale and balance it with weights, you obtain 
a measurement of the true weight of the object, w, with an error. One of the possi­
ble assumptions here, met in many practical situations, is that what one observes is a 
value of a random variable, X, such that E(X) = w and Var(X) = a2, with different 
measurements (even of the same object) being independent. In other words, we have 
X = w + e, where E(e) = 0, Var(e) = a2, with a being the standard deviation of the 
error of measurement.
In our situation, it would seem that all one has to do is to put object A on the scale, 
balance it with weights, and then do the same with object B, observing two random 
variables, X and Y , with E(X) = wA,E(Y ) = wB, and Var(X) = Var(Y )=a2.
One can, however, proceed differently. Suppose that on the first weighting, one puts 
both objects A andB on one scale, and then balances the scales, observing random vari­
able XA+B = wA + wB + e 1, where e 1 is the measurement error. On the second weight­
ing, one puts A and B on opposite sides of the scale and adds weights as needed for 
balance (see Figure 7.8). Thus, on the second measurement, we observe XA-B = wA - 
wB + e2, where e2 is independent of e 1, with E(e 1) = E(e2) = 0, Var(e 1) = Var(e2) = 
a2 . We easily find that
XA+B + XA-B = 
+ e 1 + e 2
= 
= A + о
and
XA+B - XA-B = 
+ 4—62
B
We have now Var[(e 1 + e2)/2] = (1 /4)Var(e 1 + e2) = a2/2, and Var[(e 1 — e2)/2] = 
a2/2. Using the scale twice, we obtained the measurements of wA and wB, each

VARIANCE
197
Figure 7.8 Two weightings of A and B.
with standard deviation of the error equal стД/2 = 0.707a. This means an error 
reduction by about 30% obtained at no additional cost (i.e., with the same number of 
observations). This is one of the simplest examples of the effects of choosing a proper 
design of experiment.
Let us now investigate the concept of covariance more closely. First, observe that accord­
ing to formula (7.34),
Cov(X, X) = E[(X - mX)2] = Var(X).
(7.38)
So, in some sense, covariance is a generalization of variance.
Next, we have the identity describing the behavior of covariance for a linear combination 
of random variables.
Theorem 7.6.6 If X1, ... ,Xn and Y1, ...,Ym are two sets (not necessarily disjoint) of ran­
dom variables with finite second moments, then for any constants a1 , ..., an, b1, ...,bm and 
c, d,
Cov |£ ■' X + c, £ bj v + d I = £ £ aibj Cov( X^Yj). 
(7.39)
i=1 
j=1 
i=1 j=1
The proof involves straightforward checking and will be omitted.
The fact that Cov(X, Y )=0,ifX andY are independent, suggests using the covariance as 
a measure of dependence. However, to achieve comparability across various measurements 
it needs to be standardized. Accordingly, we introduce the following definition:
Definition 7.6.4 Let X and Y be two random variables with finite second moments. Then
_ 
~ 
Cov( X,Y)
P = pX,Y = ^Var( x )Var(Y)
is called the coefficient of correlation between X and Y. 
□
■ EXAMPLE 7.41
Let U, V, W be independent random variables such that Var(U) = aU2 , Var(V )=aV2 , 
and Var(W) = aW2 . Compute the coefficient of correlation between X = U + W and 
Y=V+W.
SOLUTION. We have aX2 = a2 + a2 and aY2 = a2 + a2 , whereby Cov(X, Y)= 
X U W 
Y V W, 
,
Cov(U + W,V + W)=Cov(U,V)+Cov(U,W)+Cov(W,V)+Cov(W,W)=aW2 
by (7.38). Consequently,
2
aW
PXY 
y/UaU + aW)(aV + aW)
(7.40)

198
EXPECTATION
Situations like this are quite common; variables often are related because they are 
influenced by a common other variable (W). One can think about the prices of two 
items X and Y that depend on the price W of some components, which are used in 
both X and Y. To see the effect of aW, let us write (7.40) as
1
Pxy =
(2^+ + 1) (V¥+ + 1)
\W 
2W
If aWW is large compared with both a'U and aV., then pX Y is close to 1. On the other 
hand, if aW is small compared to one (or both) of aU and aV, then pX Y is close to 0. 
These results are expected of pX,Y as a measure of dependence of random variables X 
and Y.
■ EXAMPLE 7.42
Let X, Y have a joint density uniform on the square with vertices (-1, 0), (0, 1), (1, 0), 
and (0, -1) (see Figure 7.9).
Figure 7.9 Dependent but uncorrelated random variables.
Clearly, E(X)=E(Y)=0 by the symmetry of marginal distributions. Also 
E(XY) = 0, since in the integral 
xyf (x, y) dx dy the contribution arising from
domains with xy > 0 and xy < 0 cancel one another. Thus, Cov(X, Y)=0, and 
therefore pXY = 0. Yet the random variables are dependent. This can be seen 
immediately from Theorem 6.2.2, as well as from the fact that if one knows, for 
example, that X is close to 1, then one can infer that Y must be close to zero.
This example shows that correlation, as a measure of dependence, is not perfect. 
There are dependent random variables for which pX Y = 0. To analyze the properties 
of the correlation coefficient, we need to introduce the following inequality:
Theorem 7.6.7 (Schwarz Inequality) For any variables X and Y,
[E(XY)]2 < E(X2)E(Y2)•
(7.41)

VARIANCE
199
Proof: If E(X2) or E(Y 2) is infinite, the inequality (7.41) holds. On the other hand, 
if E(X2) = 0, then P(X =0)=1, P(XY =0)=1, and E(XY)=0. Hence, again, 
inequality (7.41) holds. The same argument applies if E(Y 2)=0. So we can assume that 
0 < E(X2) < те and 0 < E(Y2) < те.
Consider now the random variable Zt = tX + Y . For every t, we have
0 < E(Zt2) = E(12X2 + 2tXY + Y2)
= t2E(X2) + 2tE(XY) + E(Y 2). 
(7.42)
The right-hand side is a quadratic function of t, which is nonnegative for all t. Thus, its 
discriminant must satisfy the condition
4[E(XY)]2 - 4E(X2)E(Y 2) < 0
which is the same as (7.41). 
□
We can now prove the following theorem, asserting the basic properties of the correlation 
coefficient:
Theorem 7.6.8 The coefficient of correlation pXY satisfies the inequality
-1 < Px,y < 1 
(7.43)
with |pX Y | = 1 if, and only if there exist constants a (a = 0) and b such that P{Y = aX + 
b} =1. ,
Moreover, |p| is invariant under linear transformation of random variables; more precisely, 
for any a, b, c, d with ac =0,
paX+b,cY+d = epX,Y 
(7.44)
with e = +1 if ac > 0 and e = — 1 if ac < 0.
Proof: By formula (7.39), we have Cov(aX + b, cY + d) = acCov(X, Y). On the other 
hand, Var(aX + b) = a2Var(X), Var(cY + d) = c2Var(Y), so that
acCov(X, Y) 
ac
paX+b,cY+d = 
a2Var(x) x cy) = |ac| x pX,Y’
which proves (7.44). We can now prove (7.43). By what is already shown in (7.39), we can 
assume that EX = EY =0,so
Px,Y = E( XY)/VE(X2)E(Y2).
The condition |pX,Y | < 1 is equivalent to the Schwarz inequality (7.41).
It remains to prove that p2 = 1 is equivalent to the existence of a linear relationship 
between X and Y. Again, we can assume that E(X)=E(Y)=0.IfY = aX with 
a =0, then E(XY) = E[X(aX)] = aE(X2) and E(X)E(Y) = a[E(X)]2. Consequently, 
Cov(X, Y) = a{E(X2) — [E(X)]2} = aVar(X), and since Var(Y) = a2Var(X), we get
a Var( X) 
a ^
= 7Var(X) x a2Var(X) = |a| = 
.
p2X,Y =1. Then (assuming E(X)=E(Y)=0)wehave 
meaning X and Y such that we have equality in (7.42).
Px,y
Conversely, assume that 
[E(XY)]2 = E(X2)E(Y 2), 
The proof of Theorem 7.6.7 shows that this occurs if the discriminant of the

200
EXPECTATION
right-hand side of (7.42) is 0, hence if there exists t* such that E(t*X + Y)2 = 0. 
But the expectation of a nonnegative random variable is 0 if, and only if, this vari­
able assumes only the value zero, so that P (t*X + Y =0)=1.Ifwehadt* =0, 
then we would have P (Y =0)=1, and hence E(Y2 )=0, a case that we elimi­
nated. This shows that t* =0 and that there is a linear relationship between X 
and Y. 
□
■ EXAMPLE 7.43
Consider the situation where the value of some random variable Z has to be predicted 
based on the values of two other variables X and Y.
The optimal solution to this problem is well known. Adapting Theorem 7.6.2 to 
the case of conditional prediction, we see that given X = x and Y = y, one should 
predict the conditional expectation £ = E(Z|X = x, Y = y). However, the practical 
implementation of this solution presupposes the knowledge of the joint distribution of 
(X, Y, Z), and—which may be analytically difficult—the conditional expectation of Z 
given (X, Y).
Quite often we simply do not have this information. If appropriate, one can then use 
here the best linear prediction, which requires the knowledge of the first two moments 
of the joint distribution of (X, Y, Z) only, that is, expectations, variances, and covari­
ances (or equivalently, correlations).
SOLUTION. Without loss of generality, we can assume that E(X) = E(Y) = 
E(Z) = 0 (since ifwe know the mean, predicting the random variable is equivalent to 
predicting its deviation from the mean). We will be looking for a predictor of the form 
£ = aX + eY that minimizes the expected square error
E(Z - £)2 = E(Z -aX - eY)2. 
(7.45)
Condition (7.45) can be expanded to
E(Z - aX - eY)2 = E(Z2) + a2E(X2) + в2E(Y2)
-2aE(XZ) - 2eE(YZ) + 2aeE(XY)
= aZ + a2 aX + в 2 aY
-2apXZaZaX - 2PPyz aZaY + 2afiPxY aXaY.
Differentiating with respect to a and в and setting the derivatives equal to zero, we 
obtain the system of linear equations:
aaX + ftpXYaY = pXZ aZ, 
apXYaX + eaY = pYZ aZ.
The solution exists if P2XY =1:
a = pXZ - pXYpYZ x Z^ and в = pYZ - Px2YPxz x aZ
1 - P2XY 
aX 
1 - P2XY 
aY
(if P2XY =1, then X = Y orX = -Y, soX and Y provide the same information). This 
solution is not very important by itself. More important is the fact that this method 
can easily be applied to determine the best linear predictor of one or more random 
variables. All that we need are the means and second order moments of all variables 
in question—those to be predicted and those serving as predictors. The next example 

VARIANCE
201
will illustrate the class of situations in which such a prediction method can be usefully 
applied.
■ EXAMPLE 7.44 Moving Averages
Consider the process {Xt } of prices of some commodity. In many cases, the process 
{Xt } is subject to seasonal variations. For example, if t is measured in months, and Xt 
represents the (average) monthly price of tomatoes, then Xt varies with the period of 
12. One of the methods of detecting trends (or prediction), which takes such periodic 
seasonal variation into account, is based on taking the averages of Xt over the most 
recent complete period. Thus, we can define
Yt = Xt + Xt-1 + 
+ Xt-11
12
Here a possible assumption about Xt may be Xt = ft + Ct, where ft is some non­
random function with period 12 (i.e., ft = ft-12 for every t) and Ct s are independent 
random variables with the same distribution (sometimes referred to as “shocks”) rep­
resenting random effects. Under these assumptions,
Yt = C + £t + £t-1 + 
+ £t-11
12
where C = 112 (ft + ft-1 + ••• + ft- 11), which is a constant independent of t. 
Clearly, we can assume, without loss of generality, that E(Ct) = 0 for all t. Let 
Var(Ct) = E(C2 = a2 > 0. Then E(Yt) = C, Var(Yt) = a2/12 and
£t + £t-1 +-----+ £t-11
Cov( Yt,Yt-m ) = Cov I ------- 12-------
Ct-m + • • • + ^t-m-11
12
= 144Cov(Ct +-----+ Ct-11 ,Ct-m + 
+ Ct-m-11) •
2
= к x ___
K X 144,
where K is the number of overlapping terms in sums Ct + Ct-1 + ••• + Ct-11 and 
Ct-m + • • • + Ct-m- 11. Obviously, the number of such terms is 0 if m > 12 and equals 
12 - m otherwise.
Consequently, we have
Cov( Yt,Yt-m ) = max (0, 12144ma 2
so that
PYt,Yt-m
1 1 - m2 
for m = 0, 1, •••, 12
I 0 
for m > 12 •
(7.46)
PROBLEMS
7.6.1 A random variable X has binomial distribution with mean 5 and standard deviation
2. Find P{X =6}.
7.6.2 Find the variance of variable X if its first ordinary moment is 3 and the second fac­
torial moment is 52.

202
EXPECTATION
7.6.3 For random variables X and Y such that E(X) = 2,E(Y ) = 1,E(X2) =
10, E(Y2) = 3, and E(XY) = c, find: (i) Var(3X - 5Y). (ii) pX,Y. (iii) The range of 
values of c for which the assumptions of the problem are consistent.
7.6.4 Find the variance of a random variable X with a cdf
F(x) =
forx< 0
for 0 < x < 1 
forx> 1.
7.6.5 Let mX(t) = p + 0.5e-t + (0.5 - p)et be a mgf of a variable X. Determine possible 
values ofp and find Var(X 27) as a function ofp.
7.6.6 Random variables X and Y are jointly distributed with the density f (x, y)= 
(24/11)y(1 - x - y) for x>0,y >0, and x + y<1. Find the Cov(X, Y).
7.6.7 Let variables X and Y be such that E(X)=E(Y)=0, Var(X) = Var(Y) = 1, and 
PX,Y = P. Find E(W), Var(W), and PW,Y if W = X — PY.
7.6.8 Find the correlation of random variables X and Y jointly uniformly distributed on: 
(i) The triangle with vertices (0, 0), (1, 0), (1, 2). (ii) The quadrangle with vertices 
(0, 0), (a, 0), (a, 2), and (2a, 2), where a > 0.
7.6.9 Let X, Y be independent, with means pX, pY and variances aX ,aY• Show that 
Var( XY) = aX aY + aX p Y + aY p X•
7.6.10 Let X 1, ...Xn be independent random variables having the same distribu­
tion with a mean p and variance a2. Let X = (X1 + ••• + Xn)/n. _Show that 
E{En=1 (Xi — X)2} = (n — 1)a2. [Hint: Since_Xi - X = (Xi - p) - (X - p), we 
have En=1 (Xi - X)2 = £n=1 (Xi - p)2 - n(X - p)2.]
7.7 CONDITIONAL EXPECTATION
The concept of conditional probability was introduced in Chapter 4 and then extended to 
the concept of conditional distribution of a random variable in Chapters 5 and 6. Now, we 
will introduce the expectation of this distribution as a number, E(X|Y = y), determined for 
every particular value Y = y, provided that it exists.
Definition 7.7.1 For two random variables X and Y, the conditional expectation E(X|Y) is 
defined as the random variable that assumes the value E (X |Y = y) when Y = y. 
□
■ EXAMPLE 7.45
Let Y have POI(A) distribution, and given Y = n, let X have BIN(n, p) distribution. We 
can think here (recall Example 6.14) ofY being the number of eggs laid by a bird and of 
X as the number of those eggs that hatch (assuming that the eggs hatch independently, 
each with probability p). This means that the expected number of eggs that hatch, if 
Y = n, is E(X|Y = n)=np.
■ EXAMPLE 7.46
Let (X, Y) have a distribution uniform on the triangle with vertices (0, 0), (0, 1), and 
(1, 1). Given Y, the distribution of X is uniform on the intersection of the line Y = y 

CONDITIONAL EXPECTATION
203
and the support of the density. Since the expectation of the uniform distribution on 
an interval is its midpoint, we have E(X |Y = y) = y/2, and similarly E(Y |X = x)= 
(1 + x) /2, where 0 < X < 1, 0 < Y < 1.
■ EXAMPLE 7.47
Consider now a case where one variable is discrete and the other is continuous. Let
P{Y = 1} = a and P{Y = 2} = 1 - a, and given Y, let X have the density
f (x|Y = y) = yxy-1, 
0 < x < 1.
In this case, if Y =1, then X is uniform on [0, 1]; hence E(X |Y =1)=1/2.IfY =2, 
then X has density f (x|Y =2)=2x on [0, 1]; hence E(X|Y =2)=2/3. On the other 
hand, given X = x, we have
P{Y=1|X =x}
a
a + 2 x (1 — a),
P{Y = 2|X =x}
2 x (1 — a) 
a + 2x(1 - a)
This is a consequence of Bayes’ formula, interpreting the values of the density f(x|Y) 
as infinitesimal probability P{X = x|Y} dx. Thus
E(Y|X = x) = 1 x P(Y = 1 |X = x) + 2 x P(Y = 2|X = x)
a + 4x(1 — a)
a + 2x(1 — a)
We will now prove
Theorem 7.7.1 For any random variables X, Y, we have
E[E(X|Y)] = E(X),
(7.47)
provided that E(X) exists.
Proof : We will present the proof only in the case of continuous random variables. Letting 
f1(x) and f2(y) denote the marginal densities of the joint density f(x, y), we have
E(X|Y = y) = x xg(x[Y = y) dx = x x^ , dx.
f2(y)
Hence, taking expectation with respect to Y = y, we obtain
xfxy) dx] f 2( y) dy =
f2 (y) 
2
xf1 (x) dx = E (X ).
The interchange of the order of integration is legitimate in view of the assumption that E(X) 
exists. 
□

204
EXPECTATION
■ EXAMPLE 7.48
In Example 7.45 we had E(X|Y )=Yp. Since Y has Poisson distribution with mean 
A, we obtain E(X) = E(Y) x p = Xp. This result also follows from the fact (see 
Example 6.14) that X has Poisson distribution with mean Xp.
■ EXAMPLE 7.49
In Example 7.46, we have E(X) = E[E(X|Y)] = E(Y/2) and E(Y) = E[E(Y |X)] = 
E[(1 + X)/2], which gives E(X) = E(Y)/2,E(Y) = 1/2 + E(X)/2. This system of 
two equations can easily be solved, leading to jx = 1 /3 and jy = 2/3.
■ EXAMPLE 7.50
Finally, in Example 7.47, we have
E(X) = E[E(XY)] = aE(XY = 1) + (1 - a)E(XY = 2) = 1a +2(1 - a).
On the other hand, since f 1 (x) = a + 2x(1 - a), we have
E(Y) = E[E(Y|X)] = [ a + 4x(1 - a) f (x) dx
1
0 a + 2x(1 - a)
= 
[a + 4x(1 - a)] dx =2- a.
0
Theorem 7.7.1 can be very helpful in determining the expectation of a random variable 
X by conditioning it with respect to some other variable (Y). The choice ofY is crucial here 
if a simplification is to be achieved.
The following theorem is an analogue of Theorem 7.7.1:
Theorem 7.7.2 For any random variables X, Y,ifE(X2) exists, then
Var(X) = E[Var(X|Y)] + Var[E(X|Y)]. 
(7.48)
Proof :LetjX = E(X). We have
Var(X) = E(X - jX)2 = E{[X - E(X|Y)] + [E(X|Y) - jX]}2 
=E{[X-E(X|Y)]2}+2E{[X-E(X|Y)]x[E(X|Y)-jX]}
+ E{[E(X|Y) - jX]2}
= A + B + C.
Using Theorem 7.7.1, we obtain
A = E{E[X - E(X|Y)]2|Y} = E[Var(X|Y)],
C = E[E(X|Y) - jX]2 = Var[E(X|Y)],
where the last equality follows from the fact that jX = E[E(X |Y)] (see (7.47)). It remains 
to prove that B =0.

CONDITIONAL EXPECTATION
205
As before, we have
B = E{[X - E(X|У)][E(X|У) - ..]}
= E(E{[X - E(X|У)] x [E(X|У) - px] |У})
= E(E[U(X,y) x V(У)|У]),
where U(X, У) = X - E(X|У) and V(У) = E(X |У) - /X is constant for every fixed value 
of У. Consequently, V(У) can be factored out, leaving
B = E{V (У) E [ U (X^) |У ]}.
But E[U(X^) |У] = E[X - E(X|У) |У] = E(X|У) - E(X|У) = 0 and therefore B = 0, 
which completes the proof. 
□
■ EXAMPLE 7.51
For an application of Theorem 7.7.2, let us return again to the Example 7.45. We have 
there X ~ BIN(Y,p), so E(X|У) = Ур, and Var(X|У) = Уpq. Consequently, since У 
has POI(A) distribution with E(У) = Var(У) = X, we obtain
Var( X) = E Var( X |У) + Var[ E (X |У)] = E (Урд) + Var( Ур)
= pqX + p1 2X = Xp,
1
У=
2
again, in agreement with our finding from Example 6.14 that the marginal distribution 
of X is Poisson with a parameter Xp.
Finally, as another example ofan application, we will prove the theorem due to Hotelling 
and Solomons (1932) that connects the mean, median, and standard deviation of any random 
variable. The present proof is a slight modification of the proof by O’Cinneide (1990).
Theorem 7.7.3 Let X be a random variable with E(X2) < ж, and let / and a be its mean and 
standard deviation, respectively. Moreover, let m be any median of X, that is, a number such 
that P (X > m) > 0.5 and P (X < m) > 0.5. Then for any random variable X,
f - m\ < a;
that is, the mean is within one standard deviation of any median.
Proof: Let n = P(X < m),n + = P(X > m), 
and n0 = P(X = m) 
so that
n + n0 > 0.5 and n0 + n + > 0.5. Let У be the random variable defined as follows:
(a) If n 0 = 0, then
ifX<m 
ifX>m.
(7.49)
(b) If n0 > 0, then in addition to (7.49), we let
P{У =1 |X = m} = 0.5 - n- and P{У = 2|X = m} = 0.5 - n +.
Clearly, P{У = 1} = P{У = 2} = 0.5.

206
EXPECTATION
For simplicity, put pi = E(X|У = i), for i = 1, 2. Then p = E(X) = E[E(X|У)] = 
0.5E(X|Y = 1) + 0.5E(X|Y = 2), that is,
p = 0.5 p i +0.5 p 2. 
(7.50)
Assume that m < p (the argument in the case of opposite inequality is analogous). Clearly, 
we have p 1 < m, which in view of (7.50) gives the inequality
p — m < p — p 1 = 0.5(p2 + p 1) — p 1 = 0.5(p2 — p 1). 
(7.51)
Using Theorem 7.7.2 we can now write
a2 = Var(X) = E[Var(X|У)] + Var[E(X|У)] > Var[E(X|У)]
2 
e^) > (p—m)2,
and a >\p — m\, as asserted. 
□
PROBLEMS
7.7.1 Variables X and У are jointly distributed with the density f (x, y) = Cx(3x +2y) for 
0 <x<y < 1, and 0 otherwise. Find: (i) C. (ii) P (X > 0.5). (iii) E (У |X = 0.3).
7.7.2 Let X and У have the joint density uniform on the triangle with vertices (0, 0), (2, 0) 
and (3, 1). Find: (i) E(X|У) and E(У|X). (ii) Var(X|У) and Var(У|X). (iii) The 
expectations and variances of X and У using formulas (7.47) and (7.48).
7.7.3 Let X, У be continuous random variables with a joint density f (x, y). Assume that 
E(У |X = x) = p for all x. Show that
Var(У) = j Var(У |X = x) fX (x) dx.
7.7.4 The number of traffic accidents that occur in a certain city in a week is a random 
variable with mean p and variance a2. The numbers of people injured in an accident 
are independent random variables, each with mean m and variance k2 . Find the mean 
and variance of the number of people injured in a week.
7.7.5 Let X1, ...,Xn be independent variables with a U[0, 1] distribution. The 
joint density of the S = min(X1, ...,Xn) and T = max(X1, ...,Xn) is 
f(s, t)=n(n — 1)(t — s)n-2 for 0 < s < t < 1 and f(s, t)=0 otherwise. Find: 
(i) E(Sm), E(Tm), and p(S, T). (ii) E(T|S).
7.8 INEQUALITIES
In this section, we will introduce three important inequalities, all involving expectations, that 
will be used in the following chapters.
Theorem 7.8.1 If V is a random variable such that E(V )=0and Var(V )=1, then for every 
t> 0,
P{|V|>t}<1/t2.
(7.52)

INEQUALITIES
207
Proof : We will give the proof in the case of continuous random variables; the proof in the 
discrete case (as well as in the general case) will require only notational changes. Letting f 
denote the density of V , we have
1 = Var(V)= E(V2) = [ 
v2f (v) dv > [ 
v2f (v) dv
—ж 
|v|>t
>t2 
f(v)dv=t2P{|V|>t},
J\v\>t
which was to be shown.
□
Clearly, inequality (7.52) is not informative for t < 1.
If X is a random variable with finite positive variance Var(X) = a2 > 0 and ц = E(X), 
we can always standardize X by defining
V = Х-ц. 
(7.53)
a
Obviously, E(V)=0and Var(V)=1; transformation ofX into V amounts to introducing 
a new scale of expressing values of X, with the origin of the scale located at E(X), and the 
unit of measurement being the standard deviation a. Applying formula (7.52) to random 
variable (7.53), we obtain the Chebyshev inequality:
Theorem 7.8.2 (Chebyshev Inequality) If Var( X) = a2 < ж, then for every t > 0,
P{|X - ri> ta}< -12 
(7.54)
t2
or for e = ta,
P{|X - p] > e}< a2. 
(7.55)
e 2
Both (7.55) and (7.54) show the role of the standard deviation and variance. We obtain 
the bounds on probabilities of random variable X deviating from its mean ц by more than 
a certain amount, which can be expressed as a multiple of a in (7.54) or in original units 
in (7.55).
■ EXAMPLE 7.52
For any random variable, the probability that it will deviate from its mean by more 
than three standard deviations is, at most, 1/9. This probability, however, can be much 
less than 1/9 for some random variables. For instance, it equals 0.0026 for a normal 
distribution; see (8.60).
Consequently, the three-sigma rule (which says that we can practically disregard 
the probability that a random variable will deviate from its mean by more than three 
standard deviations) should be used with caution. It may safely be used for random 
variables with either a normal distribution, or close to normal, but in the general case, 
the probability 1/9 can hardly be disregarded.
We will now find the bounds given by the Chebyshev inequality in the case of few selected 
distributions.

208
EXPECTATION
■ EXAMPLE 7.53
Suppose that we toss a coin 20 times. Let us estimate the probability that the number 
of heads will deviate from 10 by 3 or more (then we will have at most 7 or at least 13 
heads). Here ^ = np = 10, a2 = npq = 5 (see Examples 7.3 and 7.33). We have
P {|X - 10|> 3 }< a2 = 95=0 . 555 .
The exact probability equals 0.2632.
■ EXAMPLE 7.54
Let X have exponential distribution with density f (x) = Xe xx, x > 0. We have here 
p = a = 1 /X (see Example 7.35). Consequently,
P
X-
t
> XJ < 7-.
1 
X
For instance, ift =1we obtain a noninformative bound 1, while the probability that X 
will deviate from 1/X by more than 1/X is (remember that exponential random variable 
can assume only positive values)
P X>
= e-x (-/x) = e-2 = 0.13534.
As can be seen from these examples, the quality of bounds given by the Cheby­
shev inequality is not impressive. However, the most important thing here is that the 
Chebyshev inequality gives a universal bound, valid for all random variables with finite 
variance. In fact the bound as such cannot be improved.
Among the most important consequences of the Chebyshev inequality are the so-called 
laws of large numbers. We explore this topic in some detail in Chapter 9. Here we illustrate 
the situation by the following example:
■ EXAMPLE 7.55 Binomial Distribution
Consider the binomial random variable Sn = number of successes in n trials. We have 
then E(Sn) = np and Var(Sn) = np(1 - p) when p is the probability of success. Con­
sequently, E(Sn/n) = p, Var(Sn/n) = pq/n, and the Chebyshev inequality gives
P
> e
Sn -p
pq 
ne 2
n
Letting n — ж we obtain the following theorem:
Theorem 7.8.3 If Sn has binomial distribution with parameter p, then for every e > 0
lim P
n—>^>
Sn
n -p
This theorem appears to explain why the empirical frequency of an event, namely Sn /n, 
approaches, as the number of trials n increases, the probability p of the event. It tells us that

INEQUALITIES
209
for any positive number e it becomes increasingly unlikely that the empirical frequency will 
deviate from theoretical probability by more than e. The Chebyshev inequality assumes that 
the random variable has finite second moment. One occasionally needs a bound for a tail of 
the distribution without this assumption. In such cases, we have the following theorem:
Theorem 7.8.4 (Markov Inequality) If X is a nonnegative random variable with E(X) < ж, 
then for every t>0,
P{X>t}< EX). 
(7.56)
Proof: We give the proof for the discrete case. Let x1, x2, ... be possible values ofX. Then
E(X) = ^2 xiP (X = xi ) >52 xiP(X = xi ) 
i 
xi>t
> t 
P (X = xi ) = tP (X > t) .
xi >t
The last inequality will be given without proof:
Theorem 7.8.5 (Kolmogorov Inequality) Let independent random variables X1 ,X2, ... have 
E (Xi) = 0 and finite variances aj ,j = 1, 2, ... (in the case of nonzero means we can always 
consider new variables Xj = Xj — E(Xj) with means that equal zero). If Sj = X 1 + Xj + 
• • • + Xj, then for every t > 0,
P{ max ISj | > t}< Var^Sn) 
1<j<n j 
t7
(7.57)
PROBLEMS
7.8.1 Let X be any random variable. Show that E(X) > 0.2 if P(X > 0) = 1 and P(X > 
2) = 0.1.
7.8.2 Assume that E(X) = 12,P(X > 14) = 0.12, and P(X < 10) = 0.18. Show that 
Var(X) is at least 1.2.
7.8.3 Prove the Markov inequality when X is a continuous random variable.
7.8.4 Derive the Chebyshev inequality from the Markov inequality.
7.8.5 Show that if X has a mgf bounded by the mgf of exponential distribution (i.e., X/(A — 
t) for t < X), then for Ao 1 we have
P{X > e} < X e e-(Xe- 1).
(Hint: Use the mgf of exponential distribution to obtain the bound for P{X > e}, 
then determine its minimum.)
7.8.6 Let X have the Poisson distribution with mean X. Show that
P<X < X| < 4 and P{X > 2X} < 1.
2X 
X

210 expectation
7.8.7 Let X be a random variable such that a mgf mX (t) exists for all t. Use the same 
argument as in the proof of the Chebyshev inequality to show that P{X > y} < 
e-tymX (t), t > 0.
7.8.8 Showthatif X has the Poisson distribution with mean A ,then P (X < X/2) < (2/e)x// 
and P(X > 2X) < (e/4)л. (Hint: Use the inequality in Problem 7.8.7, and find mini­
mum of the right-hand sides for t.)

CHAPTER 8
SELECTED FAMILIES OF DISTRIBUTIONS
Several most commonly used distributions were introduced in the preceding chapters. We 
will now present them in a systematic way, adding new information while also providing 
references to preceding chapters.
8.1 BERNOULLI TRIALS AND RELATED DISTRIBUTIONS
Bernoulli trials refer to independent repetitions of some experiment in which we are inter­
ested in an event A that occurs in each trial with the same probability p. We refer to event 
A as “success,” and the event Ac as a “failure.” The decision about which event, A or Ac, 
is labeled success is arbitrary and usually implies nothing about its nature in any practical 
applications.
The Bernoulli random variable, a building block of the theory, is just a count of the num­
ber of successes in a single trial. Thus, X is 1 or 0, depending on whether A or Ac occurred, 
and consequently, the distribution of X is given by
P{X =0} =1- p, P{X =1} = p. 
(8.1)
It will be convenient to let q =1- p. The expectation and variance are then
E(X) = p, 
Var(X) = p (1 - p)=pq.
Moreover, since 0n =0and 1n =1, the Bernoulli random variable is the only (nondegener­
ate) random variable X that satisfies the relations Xn = X for all n > 1. Consequently, the 
moments of X are
mn = E(Xn)=E(X)=p
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc. 
211

212
SELECTED FAMILIES OF DISTRIBUTIONS
for all n > 1. Then, by the fact that -d-tnmx(t) |t=0 = p for all n > 1, the Taylor expansion of 
the moment generating function of X is
mx (t) = m0 + 
mn t =1+ P t =1+ P(et — 1) = pet + q.
n n! 
n!
n=1 
n=1
This result, of course, could have been obtained in a much simpler way using the distribution 
(8.1) of X.
Binomial Distribution
The binomial distribution plays the central role in probability theory and statistics, as a 
model of the total number of successes in n Bernoulli trials. In this chapter, we let Sn denote 
the binomial random variable, and we use the representation
Sn = X1 + • • • + Xn, 
(8.2)
where X1, ...,Xn are the Bernoulli random variables describing the outcomes of successive 
trials (i.e., Xi =1 or 0, depending on whether the ith trial results in success or in failure). 
We have encountered binomial random variables in the preceding chapters (e.g., in Examples 
5.7, 6.14, 7.3, and 7.33).
Its probability distribution is
P {Sn = k} = ( n ) Pk (1 - P)n-k = b (k; n,P) 
(8.3)
and from (7.32),
E(Sn) = np, 
Var(Sn) = np(1 - p).
The symbol BIN(n, p) denotes binomial distribution with parameters n andp,sowecansay 
that Sn has distribution BIN(n, p) or simply Sn ~ BIN(n, p). The Bernoulli random variable 
has the distribution BIN(1, p).
To find the most likely number of successes (the mode), we proceed as follows: We have
b(k; n,p) = 
(k) pk (1 - p)n-k 
= n - k +1 ^ p
b(k - 1; n,p) 
pk—1(1 — p)n-k +1 
k q
Since n-k+1 x p > 1 if and only if k < (n + 1)p, the probabilities b(k; n,p) initially increase 
and then decrease. If (n +1)p is not an integer, the unique maximum of probabilities 
b(k; n,p) is attained at k* = [(n + 1)p] (an integer part of (n + 1)p), while if (n + 1)p is an 
integer, the maximum is attained at two values, (n +1)p and (n +1)p - 1.
The moment generating function of binomial distribution was obtained in Example 7.22:
n
mSn(t) = E(etSn) = 
etk nk pkqn-k = (pet + q)n.
k=0
The same result can be obtained using Theorem 7.5.5 and formula (8.2) by observing that 
mS (t) = [mX(t)]n, where mX(t) is the moment generating function of the Bernoulli ran­
dom variable.
Calculating the numerical values of binomial probabilities is simple, in principle, but can 
be cumbersome, especially when—as is often the case—we need to know probabilities of the 

BERNOULLI TRIALS AND RELATED DISTRIBUTIONS
213
form P{a < Sn < b}, which require calculating the individual probabilities P{Sn = k} for 
all k between a and b.
While one could use statistical tables to obtain some binomial probabilities (especially for 
a small or moderate n), the most common today is using statistical software.
■ EXAMPLE 8.1
Assume that it is known (from past experience, research surveys, etc.) that 40% of buy­
ers of FATCOW butter buy unsalted butter, and the remaining 60% buy salted butter. 
The store expects to sell no more than 20 packages of FATCOW butter per day, so 
they put on the shelf 8 packs of unsalted, and 12 packs of salted FATCOW butter. It 
happened that only 15 persons bought FATCOW butter on a given day, each person 
buying one package. What is the probability that all buyers found the kind of butter 
they wanted?
SOLUTION. We assume that the choices made by different people are independent 
(which may be a reasonable assumption, but we advise the reader to think of a situation 
where assumption of independence is not valid). Ifwe let S15 denote the number of per­
sons (out of 15 buyers) who bought unsalted FATCOW butter, then S15 has binomial 
distribution BIN(15, 0.4). If all customers are to find the kind of butter they want, we 
must have S 15 < 8 and also 15 - S15 < 12, that is S15 > 3. Thus, we need P{3 < S15 < 
8}. Rather than computing the sum ^k =3 (15) (0.4)k (0.6)15-k, it is more convenient 
to get the required probability as P {S15 < 8} - P{S15 < 2} for n =15and p = 0.4.
■ EXAMPLE 8.2 A Warning
The probability that a Montesuma rose will blossom during the first year after planting 
is 80%. Mrs. Smith bought 20 bushes of Montesuma roses and planted them in her 
garden. What is the probability that less than 75% of her roses will blossom the first 
year?
SOLUTION. We regard the number S20 of rose bushes that will blossom in the first 
year as a random variable with distribution BIN(20, 0.8). To obtain the probability 
P{S20 < 15} = P{S20 < 14}, we introduce S20 = 20 - S20 —the number of roses 
that do not blossom. S20 has binomial distribution BIN(20, 0.2), and P{S20 < 15} = 
P{20 - S0 < 15} = P{S20 > 5} = 1 - P{S20 < 4} = 1 - 0.630 = 0.370.
The truth is, however, that the real answer to this problem simply cannot be com­
puted. Indeed, the probability 0.8 of blossoming in the first year after planting presum­
ably represents some kind of overall success average, obtained from data for various 
years, soil conditions, gardening techniques, and so on. The roses of Mrs. Smith are 
likely to be subjected to the specific conditions, such as same type of care. Conse­
quently, the probability of success for Mrs. Smith garden need not be 0.8, and—more 
important—blossoming of her roses is unlikely to be independent of one another.
A more realistic assumption here might be that probability of blossoming p 
is random. Keeping the assumption of independence for every p, this will make 
the blossoming of Mrs. Smith’s roses exchangeable (but not independent) events 
(see Chapter 4). Thus, the solution above is obtained only at the cost of accepting the 
assumption of independence and p = 0.8.
This example is placed here to make the reader aware that modeling real situations 
requires accepting some assumptions. Justification of these assumptions can sometimes 
be a complicated issue.

214
SELECTED FAMILIES OF DISTRIBUTIONS
A difficulty with tabulating binomial distribution lies in the fact that it is necessary to have 
a separate table for each pair n and p, for 0 <p < 0.5. Moreover, the tables become increas­
ingly cumbersome when n increases. As we will show in subsequent sections, the situation 
can be remedied substantially for large n. As a preparation for the approximation introduced 
later in this chapter, let us consider an example.
■ EXAMPLE 8.3
Assume that about one birth in 80 is a twin birth. What is the probability that there will 
be no twin births among the next 200 births in the maternity ward of a given hospital?
SOLUTION. Clearly, we have here a binomial situation. If S200 denotes the num­
ber of twin births among the next 200 births, we need P{S200 = 0}, where S200 ~ 
BIN(200, 1 /80). Thus, remembering that limn ,.-x_(1 - n)n = e-c, we write:
200
« e-200/80 = 0.0821.
(8.4)
The approximation works well if the probability of success p is small and number of trials 
n is large. Specifically, the error, equal to |P {Sn = 0} - e-np|, depends on the value of the 
product np. As we will see, (8.4) is an example of the Poisson approximation to the binomial 
distribution, which we will discuss later.
Geometric Distribution
Another random variable related to Bernoulli trials is the number X of failures preceding 
the first success. We earlier encountered this variable in Examples 5.8 and 7.4. Since
P{X = k} = qkp, 
k =0, 1, 2, ..., 
(8.5)
and probabilities
P{X > k} = qkp + qk+1 p + ••• = p-^ = qk 
(8.6)
1-q
are obtained by summing the geometric series, the distribution (8.5) is called geometric. 
Based on formula (8.6), one obtains the cdf formula, since
FX(k) = P(X < k)=1- qk+1.
A distribution closely associated with (8.5) is that of the number Y of trials up to and 
including the first success, which we write as
P{Y = n} = P{X = n - 1} = qn-1p, n =1,2, ..... (8.7)
Actually, both distributions, (8.5) and (8.7), are called geometric in the literature. Since 
Y = X +1, these distributions are closely related, and most results are valid under either def­
inition. We will use both definitions, specifying (in cases where it makes a difference) whether 
(8.5) or (8.7) is used. We introduce both definitions deliberately, not in order to confuse our 
readers but to make them flexible in using terminology that is not well established. We will 
also use the same symbol for both distributions, (8.5) and (8.7). In other words, we will use the 
notation GEO(p) to denote the geometric distribution with probability of success being p.

BERNOULLI TRIALS AND RELATED DISTRIBUTIONS
215
The expected value of the geometric distribution was found in Example 7.5. For the dis­
tribution (8.7), we have
E (Y) = 1, 
(8.8)
p
so for the distribution (8.5), we obtain
E(X)= E(Y - 1) = p - 1 = p. 
(8.9)
The variance of the geometric distribution is the same for both X andY (see Theorem 7.6.1),
Var( X) = Var( Y) = q.
p2
It can be derived using Theorem 7.5.3 and the mgf of the geometric distribution 
pet
1 -qet
p
mx(t) = i t and mY(t) = mx+1( t) = 
- qe
forqet < 1; hence, for t<- log q.
Let us observe that for all m =0, 1, 2, ... and n =0, 1, 2, ...
P{X > m + nX > m} = P{X > n}.
(8.10)
(8.11)
Indeed, since X > m + n implies that X > m, we can write
P{X > m + n\X > m} = P^X-^m+n} = q—n = qn = P{X > n}. 
P{X > m} 
qm
Formula (8.11) is said to express the memoryless property of geometric distribution: if waiting 
time for the first success is at least m, then the probability that it will be at least m + n is the 
same as the probability that the waiting time for the first success will be at least n.
Formula (8.11) is valid for random variable X. For the random variable Y (number of 
trials up to and including the first success), we have a formula with the strict inequalities
P{Y>m+ n|Y>m} = P{Y > n}.
(8.12)
Formula (8.11) characterizes geometric distribution (8.5); equivalently, (8.12) character­
izes distribution (8.7). We will prove
Theorem 8. 1.1 If Y is a discrete random variable that may assume values 1, 2, ... and satisfies 
(8.12), then Y has the distribution (8.7) for some p andq =1- p.
Proof: Let nk = P{Y = k} and nk = nk+1 + nk+2 + • • • = P{Y > k}. Then (8.12) means 
that we must have nm+n/nm = nn for all m, n = 1, 2, .... In particular, n2 = П2, and by 
induction, nk = nk. Consequently, nk = nk — nk+1 = nk - nk +1 = nk (1 — П 1) for all k, 
which means that Y has geometric distribution with q = n 1 = P{Y > 1}. 
□
It is sufficient to require that (8.12) holds for m =1and all n or for n =1and for all m. 
Also the Theorem 8.1.1 holds ifm is replaced by a random variable (see Srivastava, 1981).
Theorem 8. 1.2 Let U be a random variable which assumes only positive integer values. If
P{Y>U+n|Y>U} =P{Y>n}, 
(8.13)
then Y has geometric distribution (8.7) for some p and q =1- p.

216
SELECTED FAMILIES OF DISTRIBUTIONS
■ EXAMPLE 8.4
In Section 4.7 we discussed Markov chains, these being processes that describe the 
evolution of a system that may at any time be in one of a specified set of states and 
may change its state at times t =1, 2, ..... The main assumption is that if at some time
t the system is in state i, then the probability that it will pass to state j at time t +1 is 
pij , regardless of the history of transitions prior to time t. This means that given the 
present (state at time t), the future and the past are independent. Suppose now that at 
some time t the system enters state i, and let Ti be the duration of the current visit to 
state i. More precisely, we define Ti = k if the state at times t, t +1,t+2, ...,t+ k is 
i, but the state at time t + k +1 is different from i. We have then
P{Ti =k}=piki(1-pii), k=1,2,...,
and we see that the duration of a visit in state i has geometric distribution with q = pii 
and p =1- pii .
The memoryless property of geometric distribution is in fact the Markov property. 
Indeed, suppose that the system stayed in state i for m units of time prior to time 
t. Then the probability of staying there for at least n additional units is the same as 
the probability of staying in state i for at least m + n units of time. Given the present 
state, the future (in particular, the duration of remaining stay in the present state) is 
independent of the past (in particular, of how long the system has already stayed in its 
present state).
Theorem 8.1.2 asserts a seemingly identical property, but a moment of reflection 
shows that the condition is now much stronger: the “present” is not some fixed time, 
but it is a time that may be random. In particular, this randomness may be affected by 
the process itself.
To give an example, let X = Ti, the time of remaining in the state i just entered, and 
let U be the longest visit in state i recorded thus far (so that U depends on the history of 
the process up to the present time). Theorem 8.1.2 asserts, in particular, the following: 
given that the duration of the present state in state i will break the record (Ti >U), the 
probability of breaking the record by at least 3 units (i.e., Ti >U+3) is the same as 
the probability of a visit lasting longer than 3 units (Ti > 3). This property stands in 
contrast with what one observes in sport records: the consecutive improvements of the 
world record in any discipline tend to be smaller.
The property asserted in Theorem 8.1.2 is generally called strong Markov prop­
erty. It means that given the present, the future is independent of the past, even if the 
“present” is selected at random, as long as this randomness depends only on the past, 
and not on the future.
Theorems 8.1.1 and 8.1.2 are examples of characterizations of probability distributions. 
This kind of theorem singles out a certain property of a type of distribution and shows that 
this property is valid only for distributions of this type (in the case above, the memoryless 
property for the geometric distribution).
The characterization theorems are of a great practical value. As we will see in the later 
chapters, if one is interested in more than merely summarizing and presenting the statistical 
data, it is useful to regard the data (results of observations, experiments, surveys, etc.) as val­
ues of some random variables. Roughly speaking, the more we know about the distributions 
of these random variables, the better is our understanding of the phenomenon studied, as 
well as the better are our possibilities of prediction and control.
To fix the idea, imagine that a statistician’s data can be regarded as independent obser­
vations of some random variable X . It happens quite often that identification of the dis­
tribution of X is accomplished in two steps. The first step consists of identifying a class of

BERNOULLI TRIALS AND RELATED DISTRIBUTIONS
217
distributions that contains the distribution of X . The second step is the identification of the 
particular distribution in this class.
In many cases, however, determining the class of distributions that contains distribution 
of X is not so simple. In such situations, one can sometimes use a characterization theorem: 
if one knows that the distribution has some property that turns out to be characteristic for a 
given class, then the distribution must be in that class (e.g., if one knows that the distribution 
of X is memoryless, then it must be geometric).
The following example shows how the geometric distribution can be used for modeling.
■ EXAMPLE 8.5 Family Planning
Assume that the sexes of consecutive children born to the same parents are indepen­
dent, with the probability of a child being a girl equal to п. We will disregard twin 
births and consider family sizes under various plans.
Plan 1. The couple decides to stop having children as soon as their first girl is born. 
Let £ 1 be the number of children according to this plan. Then £ 1 is a geometric random 
variable with P{£ 1 = n} = (1 - п)n-1 п so that E(£ 1) = 1 /п. If the chances of a child 
being a boy are the same as those of being a girl, we have п = 0.5 and E(£ 1) = 2.
Plan 2. The couple decides to have children until they have a boy and a girl and then 
stop. Let £2 be the number of children under this plan. To determine P(£2 = n), let 
G and B denote the event “first child is a girl (boy).” Then, by the total probability 
formula (4.9), for n > 2 we have
P(£2 = n)= nP(£2 = n\G) + (1 - п)P(£2 = n\B)
= nP{YB = n - 1} + (1 - п)P{YG = n - 1}.
Here YB and YG are the numbers of children (excluding the first) that a family 
will have until the first boy (girl) is born. Clearly, YB and YG have the distribution 
given by (8.6), with probability of success being 1 - п for YB and п for YG. Thus, for 
n=2,3, ...,
P {£ 2 = n} = п [ пп—2(1 - п)] + (1 - п )[(1 - п) n—2 п ] 
= пп- 1(1 - п) + (1 - п)n-1 п.
To find the expected number of children under plan 2, we write
о 
о
E(£2) = п 
nP{YB = n - 1} + (1 - п) 
nP{YG = n - 1},
n=2 
n=2
and, putting k = n - 1, obtain
^2 nP{YB = n - 1} = ^2 [(n - 1) + 1]P{YB = n - 1}
n=2 
n=2
00 
00
= 
kP {Y B = k} + 
P {Y B = k}
k=1 
k=1
1
+1.
1 -п

218
SELECTED FAMILIES OF DISTRIBUTIONS
By symmetry, 
^=2 nP{YG = n - 1} = 1 /п + 1, and finally
e (e 2) = k( _^ + ^ + (i — п )f- + P) = -^ + 
' + i
1-п 
п 
1-п п
п (1 — п)
Again, if п = 1/2, then E(e2 )=3.
Negative Binomial Distribution
The geometric distribution allows us to make an immediate and natural extension. Rather 
than to consider the number of Bernoulli trials up to the first success, we can consider the 
number Y of Bernoulli trials up to and including the rth success. In analogy with the geo­
metric distribution, we will also consider the random variable X defined as the number of 
failures preceding the rth success.
We will start by deriving the probability distribution of the random variables X and 
Y. Clearly, the possible values of Y are integers r, r +1,r+2,   The event {Y = n} 
occurs if:
1. The nth trial results in success.
2. The first n - 1 trials give exactly r - 1 successes (and n - r failures).
Indeed, the conjunction of 1 and 2 ensures that the rth success occurs at trial n. The events 
1 and 2 are independent (since their occurrence is determined by disjoint sets of trials), and 
their probabilities are p and nr--11 pr-1qn-r, respectively. Consequently,
P{Y =n} = n- 1 prqn-r 
(8.14)
r-1
for n = r, r +1,r+2,  The number X of failures preceding the rth success is such that 
X + r = Y.So for k =0, 1, 2, ...,we have
P{X = k} = P{Y = k + r} = k + r - 1 prqk. 
(8.15)
r-1
Both random variables X and Y are referred to as having a negative binomial distributions. 
In either case, the distribution depends on two parameters, r and p. We will use the symbol 
NBIN(r, p) to denote the negative binomial distribution, whether (8.14) or (8.15).
Let us verify that (8.15) and (8.14) are probability distributions. We must show that
f (k+ r— 1) pr qk = 1 
(8.16)
r-1
k=0
Let us observe first that by formulas (3.14) and (3.9),
k+r- 1 r- 1+k
r-1 
k
(r — 1 + k)(r — 1 + k — 1) ••• (r — 1 + k — k +1) 
= 
k!
r (r +1) • • • (r + k — 1)
= 
k!
= (—1)k(—r)(—r — 1) •••(—r — k + 1) = (_ 1)k ( —r)

BERNOULLI TRIALS AND RELATED DISTRIBUTIONS
219
Thus, using Newton’s formula (3.16), we have
ОО 
ОО 
/ 
\
E
k + Г 1 
r
r-1 
prqk = pr 
(-1)k k qk=pr(1-q)-r=1.
k=0 
k=0
Obviously, the proof that
О
r
prqn
=1
is similar, and we can omit the details.
To determine the mean and variance of a random variable with negative binomial distribu­
tion, one can proceed in several ways, of which we will demonstrate two. The first uses direct 
calculations, while the second uses a representation as a sum of simpler random variables.
Observe that since Y = X + r, we have E(Y )=E(X) + r and Var(Y ) = Var(X) (the 
latter property being a consequence of Theorem 7.6.1). Thus, it suffices to study one of the 
random variables X and Y .
We begin by finding the mgf of X. Proceeding as in the proof of (8.16), we have
mX(t) = EeXt
О
= £ ek
k=0
k + r
r-
1 pr qk
r 
= pr
О E 
k=0
k + r-
r-1
(qet)k
1
r 
pr
О
=prZ (7) (-qet)k = „—W, 
k=0 
k 
(1- 
qet)r
provided that |-qet| < 1, or equivalently t < log(1/q).
Consequently, E(X) = m'X (0) = rq/p, and
E (Y) = r + E (X) = r. 
p
(8.17)
After some algebra, we also obtain
Var(X) = Var(Y) = mX(0) - [E(X)]2 = r^. 
(8.18)
p2
■ EXAMPLE 8.6
A salesman calls prospective buyers to make a sales pitch. Assume that the outcomes of 
consecutive calls are independent, and that on each call, he has 15% chance of making 
a sale. His daily goal is to make 3 sales, and he can make only 20 calls in a day. What 
is the probability that he achieves his goal in 18 trials? What is the probability that he 
does not achieve his daily goal?
SOLUTION. The “strategy” of solving a problem like this is to identify the type of 
distribution to be analyzed. Assuming that we identify the situation as Bernoulli trials 
(i.e., repeated independent trials with the same probability p of success), the problem 
most typically concerns either a binomial or negative binomial distribution. The crucial 
question here is: Is the number of trials fixed (and then the number of successes is 
random), or is the number of successes fixed (and the number of trials is random)? In 
the first case, we have the binomial distribution, and in the second case, the negative 
binomial distribution.
For our salesman, we want the probability that his third sale (success) comes at trial 
18. Thus, the number of successes r = 3 is fixed (this is the salesman’s goal), and it 

220
SELECTED FAMILIES OF DISTRIBUTIONS
is the number of calls that is random. We have p = 0.15, and we ask for P{X = 18}, 
where X is the number of trials up to and including the third success. Substitution to 
formula (8.14) gives
17
P{X =18} = 
(0.15)3(0.85)15 = 0.0401.
The second question is about the probability of the salesman not attaining his daily 
goal. Here the number of trials is fixed (n = 20,) and we can treat the problem as involv­
ing the binomial distribution. Thus, if S20 is the number of successes in 20 trials, the 
salesman does not achieve his goal if S20 < 2. The answer is therefore
P{S20 < 2} = P{S20 = 0} + P{S20 = 1} + P{S20 = 2}
= V 220(0• 15)k(0.85)20-k = 0.4049. 
k
k=0
We can also use the negative binomial distribution here. If X is the number of trials 
up to and including the third success, then the salesman does not attain his goal when 
X>20.Sotheansweris
P X > 20} = £ PX = n} = 
n- - Ц (0.15)3(0.85)n-3,
n=21 
n=21
a quantity that is much harder to evaluate numerically than P {S20 < 2}.
The example above suggests that the probabilities in binomial and negative binomial dis­
tributions with the same probability p of success are related. The following theorem provides 
a useful identity:
Theorem 8.1.3 Let Sn ~ BIN (n,p) be the number of successes in n Bernoulli trials and let 
Y(r) ~ NBIN (r,p) be the number of trials up to and including the rth success. Then, for every 
k=0,1, ...,
P{Y(r) >k} = P{Sk <r}. 
(8.19)
Proof: Observe that both sides of (8.19) refer to the probability of the same event: the wait­
ing time for the rth success exceeds k if and only if fewer than r successes occur in the first k 
trials. 
□
A word of warning: Since Y(r) and Sk are both discrete random variables, it matters 
whether or not the inequalities are strict. Thus, (8.19) can be written in any of the forms, 
such as
P{Y(r) >k} = P{Sk < r - 1}, 
P{Y(r) <k + 1} = P{Sk > r}.
An inspection of the proof of the formula (8.16) shows that the fact that r was an integer 
was never used. Formally, a negative binomial distribution is defined for any r>0 and 0 < 
p<1 (although the interpretation of the probabilities in terms of Bernoulli trials is no longer 
valid).
Let us also note that the mgf of the negative binomial distribution is the rth power of the 
mgf of the geometric distribution. For integer values of r, this fact shows that the random 
variable X(r) (respectively, Y(r))isasumofr independent geometric random variables (of 

BERNOULLI TRIALS AND RELATED DISTRIBUTIONS
221
the form X or Y , depending on whether we represent X(r) or Y (r)). This representation (e.g., 
in the case of X(r)) means that
X (r) = X 1 + ••• + Xr,
where Xi is interpreted as the number of failures falling between the (i - 1)st and ith success 
(e.g., in case of r =3, if the consecutive trials are FFFSSFFFFS, then X(3)= 7 = number 
of failures preceding the third success, with X1 =3,X2 =0,X3 = 4 being the numbers of 
failures between the three consecutive successes).
Consequently,
E (X (r )) = E (X 1) + ••• + E (Xr)
and (because of independence)
Var(X(r)) = Var(X1) + ••• + Var(Xr),
which in view of (8.8) and (8.10) gives formulas (8.17) and (8.18). The representation of 
random variables Y (r) is analogous and will be omitted.
PROBLEMS
8.1.1 Label statements below as true or false:
(i) Suppose that 6% of all cars in a given city are Toyotas. Then the probability 
that there are 4 Toyotas in a row of 12 cars parked in the municipal parking is 
(142) (0.06)4(0.94)8. (ii) Suppose that 6% of all Europeans are French. Then the 
probability that in a random sample of 12 inhabitants of a major European capital 
there are 4 Frenchmen is (142) (0.06)4(0.94)8.
8.1.2 Assume that we score Y =1for a success and Y = -1 for a failure. Express Y as a 
function of the number X of successes in a single Bernoulli trial, and find moments 
E(Yn),n=1,2,.....
8.1.3 Suppose that random variables X1, ...,Xn are independent, each with the same 
Bernoulli distribution. Given that "=1 Xi = r, find: (i) The probability that X 1 = 1. 
(ii) The covariance between Xi and Xj, 1 < i < j < n.
8.1.4 Assume that X1 and X2 are independent random variables, with BIN(n1,p) and 
BIN(n2 ,p) distributions, respectively. Find a correlation coefficient between X1 and 
X1 + X2.
8.1.5 An experiment consists of tossing a fair coin 13 times. Such an experiment is repeated 
17 times. Find the probability that in a majority of repetitions of the experiment the 
tails will be in minority.
8.1.6 Two balanced coins are tossed together independently. Find: (i) the distribution of 
the number of tosses required for both coins to show the same side; and (ii) the dis­
tribution of the number of tosses needed to get at least one head.
8.1.7 A regular die is tossed until the same side turns up twice in a row. Find: (i) the prob­
ability that it will happen in tosses 8 and 9. (ii) The probability that it will happen in 
tosses n and n +1.
8.1.8 Two players (or two teams) are negotiating the rules for determining the champi­
onship. The two possibilities are “best of five” or “best of seven.” This means that 
whoever wins three (respectively, four) games is the champion. Assume that games 
are independent and that the probability of winning a game by the first player (there 

222
SELECTED FAMILIES OF DISTRIBUTIONS
are no ties) is p. For what values of p, should the first player favor the scheme “best 
out of five”?
8.1.9 Show that if Sn is a binomial random variable, then for k =1, 2, ...,n,
P {Sn = k} = (n-k-p)) P P {Sn = k - 1 ^
8.1.10 Show that for the binomial distribution we have
P{Sn < k} = (n - k) (n) 
P xn-k- 1 (1 - x)k dx.
8.1.11 Six dice are tossed simultaneously until, for the first time, all of them show the 
same face. Find E(U) and Var(U), where U is the number of tosses until this 
happens.
8.1.12 Assume that the probability of twins being identical is в, and that the sexes of children 
are determined independently, with probability of a boy being b (possibly b = 1/2). 
Find the expected number of twin births recorded in the hospital before the first pair 
of: (i) boys, (ii) girls, and (iii) different genders. Note that identical twins must be of 
the same sex.
8.1.13 Assume that the probability that a birth is a multiple one (twins, triplets, etc.) is 
n. Given that a birth is a multiple one, probabilities a2 ,a3, . . . of twins, triplets, 
...satisfy the condition ak +1 = Yak. Find n, a 2, and y if it is known that the 
expected number of children born in 100 births is 100+ c, and the expected number 
of single births observed before recording a multiple birth is M (assume that M and 
c given).
8.1.14 A hospital needs 20 volunteers for the control group in testing the efficiency of some 
treatment. The candidates are subject to psychological and medical screening, and 
on average, only 1 in 15 candidates is found acceptable for the experiment. The cost 
of screening, whether or not a candidate is found acceptable, is $50 per person. The 
granting agency argues that one needs about 50 x 15 dollars to find one acceptable 
candidate, and therefore allows 20 x 50 x 15 = 15, 000 dollars for the cost of screen­
ing. (i) Write the formula for the probability that the allocated sum will be enough 
to find 20 acceptable candidates. (ii) Use the Chebyshev inequality to find the sum 
that gives at least a 90% chance of finding 20 acceptable candidates before the testing 
money runs out.
8.1.15 Assume that in a tennis match between A and B, the probability of winning a tennis 
set by player A isp and that the results of sets are independent. Let T be the number 
of sets played in a match. Find the distribution of T and E(T) as a function ofp, 
assuming that the match is played by: (i) men, (ii) women. (Note that men play “best 
out of five,” while women play “best out of three” sets.)
8.1.16 In the flowchart in Figure 8.1, m>0 is an integer and 0 <p<1. The block “sample 
U” means that a value of a random variable U is sampled from the U[0, 1] distribu­
tion, with consecutive samplings being independent. Find the distribution of X, and 
then calculate its mean and variance.
8.1.17 Show that ifX has a negative binomial distribution NBIN(r, p), then
E[(r - 1)/(r + X - 1)] = p.

HYPERGEOMETRIC DISTRIBUTION
223
Figure 8.1 Flowchart.
8.2 HYPERGEOMETRIC DISTRIBUTION
The distributions discussed in the previous section were based on the notion of a Bernoulli 
trial—an event that results in a “success” or a “failure.” One of the necessary assumptions of 
Bernoulli trials is that the probabilities ofa “success” (or equivalently “failure”) are the same 
in each trial. That requires either sampling from an infinite (practically very large) population 
or returning an element after it was selected (sampling with replacement). There are, however, 
situations where neither the population is large nor the replacing can be done. We then have 
sampling without replacement, with the probabilities changing after every selection and each 
time depending on the type of the element recovery as often used for statistical modeling 
(e.g., in zoology to study small animal or plant populations). We have already encountered 
hypergeometric distribution in Examples 3.7 and 3.8.
To proceed systematically, we assume that initially the population has N elements of 
which a are of one kind (“successes”) and b = N - a are of another kind (“failures”). We 
sample n elements without replacement, and we let X denote the number of successes in the 
sample. Let us first determine the range of the random variable X. Clearly, 0 < X < a, and 
a similar inequality for the number of failures is 0 < n — X < N — a. This yields
max(0, n - (N - a)) < X < min(n, a).
(8.20)
If k satisfies the constraint (8.20), then
P{X = k} =
a 
N-a
k 
n-k
(8.21)
(N) 
'
To check that the probabilities in (8.21) add up to 1, we will use a trick. Let us consider the 
identity
(1+x)N =(1+x)a(1+x)N-a
and compare the coefficients of x! on both sides. On the left-hand side the coefficient is 
N! . On the right-hand side the coefficient equals the sum of all possible terms of the form 
(a) ( N /a I, where k must satisfy the constraint (8.20). This shows that the sum of all terms 
k !-k , 
(8.21) is 1, as asserted.

224
SELECTED FAMILIES OF DISTRIBUTIONS
■ EXAMPLE 8.7
A class consists of 10 boys and 12 girls. The teacher selects 6 children at random for 
some task. Is it more likely that she chooses 3 boys and 3 girls or that she chooses 2 
boys and 4 girls?
SOLUTION. If X is the number of boys in the selected set of children, then
10 
12 
10 
12
pry __ o'! __ \ 3 / \ 3 / __ и oroo pry__ 91 __ 12/14/ __и Qner
P {^X — 3 j — . 22 \ — 0.3538, 
{^X — 2 j — / 22 \ — О‘2985.
66
So the first probability is higher than the second.
As expected, for large populations, it does not matter too much whether we sample with 
or without replacement. We shall now formulate the corresponding approximation theorem:
Theorem 8. 2.1 Let N — ж and a — ж in such a way that a/N — p, where 0 < p < 1. Then 
for every fixed n and k —0, 1, . . .,n we have
P {X — kj 
b(k; n, p)
—1
(8.22)
as N — ж. Here P{X — kj is the probability (8.21) for hypergeometric distribution, while 
b(k; n,p) is the binomial probability given by (8.3).
Proof : Letting JN denote the ratio in (8.22), we write
JN —
a 
N-a
k 
n-k
(N) (;) pk (i - p) n-k
a!(N — a)!(N — n)!
(a — k)!(N — a — n + k)!N!pk(1 — p)n-k ’
which cancels to
[a(a — 1) • • • (a — k + 1)][(N — a)(N — a — 1) • • • (N — a — n + k + 1)] 
N(N — 1) ••• (N — n +1)pk(1 — p)n-k
Multiplying and dividing by Nn , we obtain JN — AN BN /CN , where
AN — a (a —
1 
a k—1
NJ VN N J’
BN — (1— N)
a 1 
a n—k—1
\ N 
\ N 
NJ’
CN — (1— N)
(1 
N) ••• (1 
N ) p (1 p) 
.
Since n and k are fixed and moreover a/N — p, AN — pk’ BN — (1 p)n-k’ and
(1 — 1 /N) x • • • x (1 — (n — 1) /N) — 1, we have JN — 1. This proves the theorem. □

HYPERGEOMETRIC DISTRIBUTION
225
The practical use of Theorem 8.2.1 consists mostly of replacing probabilities
P{X = k} =
a 
N-a
k 
n-k
(n)
by their approximations (k)( N )fe(1 - N) n k, which are much easier to compute. The rel­
ative error of such approximation depends on all four factors, N, n, a, and k.
Let us now find the expectation and variance of the hypergeometric random variable X 
with distribution (8.21). We will use the method that we already used in the case of binomial 
and negative binomial random variables, by representing X as a sum of simpler random 
variables. We let
X = £ 1 + £ 2 + • • • + £n,
(8.23)
where £i equals 1 or 0, depending on whether the ith draw results in success or failure.
Observe that £ 1, • •• ,£n are dependent random variables. This fact will affect our calcu­
lation of the variance of X . Generally, we will use the formulas
E(X) = E(£ 1) +------ + E(£n),
Var( X) = Var( £ 1) + • • • + Var( £n) + 2 £ Cov( £i ,£j). 
i<j
Note that £i’s are Bernoulli random variables (i.e., they assume only values 0 and 1). So 
letting pi = P {£i =1}, we have
E(£i) = pi,Var(£i) = pi(1 - pi). 
(8.24)
Observe that £i£j is also a Bernoulli random variable. So letting pij = P{£i =1,£j =1} 
we have
Cov(£i,£j) = E(£i£j) - E(£i)E(£j) = P{£i£j = 1} - pipj = pij - pipj. 
(8.25)
To determine the probabilities pij, we need the joint distribution of (£i, £j). Generally, one of 
the ways of visualizing the distribution of the (£1, ...,£n) is as follows: The elements of the 
population (ofa successes and N - a failures) are ordered at random. This gives the sample 
space ofN! permutations, all of them being equally likely. The random vector (£1, ...,£n) is 
then defined at any sampled point (permutation) as the initial n elements of this permutation.
It is now clear that the joint distribution of (£i, £j) does not depend on (i, j), meaning it 
is the same as the joint distribution of (£1, £2). Indeed, the probability that (£i = x, £j = y) 
depends on the number of permutations in the sample space that have specific elements x 
and y at places i and j. By symmetry, this number is the same as the number of permutations 
that have elements x and y in the first two places (or in any other designated pair of places).
Consequently, the marginal distributions of £i are the same, and for all i, we must have
Pi = p {£i = 1} = a.
Similarly
Pij = P{£ 1 = 1 ,£2 = 1} = P{£ 1 = 1 }x P{£2 = 1 £ 1 = 1} = a X 
N 
a - 1
N - 1

226
SELECTED FAMILIES OF DISTRIBUTIONS
From (8.24) and (8.25) we get E(Zi) = a/N, Var(Zi) = (a/N)(1 - a/N) = a(N - a)/N2. 
Therefore
Cov(Zi,Zj) = E(ZiZj) - E(Zi)E(Zj) = pij - E(Zi)E(Zj)
a a — 1 
/ a\2 Na(a — 1) — a2(N — 1)
= N X N — 1 - INJ = 
N2(N — 1)
= a (N — a) = Var( Zi)
= N 2( N — 1) = N — 1 .
Thus E(X) = nE(Zi) = n(a/N). For variance, observe that the number of pairs (i, j) with 
i<jis n2 = n(n - 1)/2. Consequently,
Var(X) = n x a x N — a x 
n (n — 1)
1 
a (N — a)
X N X N (N — 1)
N-a
n-1
a
n X N X
1
N
N-1
Letting a/N = p denote the probability of success prior to selecting the first element, we 
have the following theorem:
Theorem 8. 2.2 If X has the hypergeometric distribution (8.21), then
E(X) = n x N = np,
a 
aN-n 
N-n
Var(X) = n x N x (j — N) — = np(1 — p)K. 
□
Thus, the expected number of successes in a sample of size n is np regardless of whether we 
sample with or without replacement. The variance in the case of sampling without replace­
ment is smaller than the corresponding binomial variance by the factor (N - n)/(N - 1) 
(sometimes referred to as finite population correction factor).
The behavior of the variances of binomial and hypergeometric distributions is different 
as the sample size, n, increases. In a binomial distribution, each new element of the sample 
contributes the same amount to variance, so the latter grows linearly with n. In sampling 
without replacement, variance changes in proportion to the product n(N - n); hence, it 
initially grows to reach a maximum when sampling exhausts half of the population, and 
then declines to zero when n = N (at n = N we exhaust the whole population, so there is 
no longer variability in the sample). Variance for n =1is the same as for n = N - 1. This 
is clear, since variability involved in sampling one element is the same as variability involved 
with leaving just one element unsampled.
The next theorem connects the binomial and hypergeometric distributions in the situation 
when the successes come from two sources, each following the binomial distribution, and the 
total number of successes is fixed. Thus, we will prove
Theorem 8. 2.3 Let X and Y be independent random variables with binomial distributions X ^ 
BIN(m,p) and Y ^ BIN(n,p). Then
P{X =k|X+Y=r} =
mn 
k 
r-k
(m+n) 
.
(8.26)

HYPERGEOMETRIC DISTRIBUTION
227
Proof: Since X + Y ~BIN(m + n, p), we have
P{X=k|X+Y=r}= P {X = k,X + Y = r} 
P {X + Y = r}
P{X = k}P{Y = r - k} 
P {X + Y = r}
and substitution of binomial probabilities gives (8.26).
□
The right-hand side of (8.26) is the hypergeometric probability of k successes in sampling 
r elements from a population with a total of m + n elements, of which m are successes.
The scheme of sampling without replacement can be generalized as follows: Assume that 
the population consists initially of a elements of one kind (successes) and b = N - a elements 
of the second kind (failures). Each time an element is sampled, it is returned, and c elements 
of the same kind as just sampled are added to the urn. This process continues forn samplings. 
Let X be the number of successes in the sample. This random variable X is said to have Polya 
distribution, and the sampling described above is called the Polya scheme.
The reason for designing this scheme was as follows. Adding elements of the same kind 
to the population increases the probability of selecting elements of the kind most recently 
sampled. Such effect is known to occur when one samples from a population to determine 
the fraction of persons infected with a disease. Typically, if one finds one person with the 
disease, then the chances of finding others with the same disease increase. Polya introduced 
this scheme of sampling to model such effects.
Observe that we can formally put c = -1 (elements are simply not returned). Thus, the 
special case c = -1 yields random variable X with a hypergeometric distribution. To find 
P{X = k} in the general case, let us first find the probability of sampling the elements in a 
specific order, for example, first k successes and then n - k failures. This probability, by the 
chain rule (4.5), is
a a+c
N X N + c
a+(k - 1)c 
b 
b+c b+(n-k - 1)c
N + (k — 1) c 
N + kc N + (k + 1) c N + (n — 1) c
Let us observe that the probability (8.27) remains the same regardless of the order of k suc­
cesses and n — k failures. Each time the number of elements in the population increases by 
c, the product of all denominators is N(N +1) • • • (N + (n — 1)c). Similarly, the numera­
tors corresponding to sampling successes are a, a + c, a +2c, ...,a+(k — 1)c regardless of 
when the successes are to occur, and the same holds for failures. Consequently, we have
Theorem 8. 2.4 In Polya scheme, for k =0, 1, ...,n
P{X = k} = n! p (p + y ) • • • (p + (k — 1) y ) q (q + y ) • • • (q + (n — k — 1) y ) 
k!(n — k)!(1 + y)(1 + 2y) • • • (1 + (n — 1)y)
where p = a/N, q = b/N =1 — a/N and y = c/N.
PROBLEMS
8.2.1 An urn contains nine chips, five of them red and four blue. Three chips are drawn 
without replacement. Find the distribution of X = number of red chips drawn.
8.2.2 An urn contains six chips, three red and three green. Four chips are selected without 
replacement. Find E(X) and Var(X), where X = number of red chips in the sample.

228
SELECTED FAMILIES OF DISTRIBUTIONS
8.2.3 Kim and Jason bought a package of 10 lottery tickets, knowing that each package had 
to include three winning tickets. Since Kim paid 60% of the total cost, while Jason paid 
40%, they took six and four tickets, respectively. Find the probability that: (i) Kim got 
at least one winning ticket; (ii) Jason got exactly one winning ticket; and (iii) Each of 
them got at least one winning ticket.
8.2.4 Answer (i)-(iii) in Problem 8.2.3 if instead of three winning tickets in each package, 
30% of all tickets are winning and 10 tickets for each package are selected at random.
8.2.5 Instead of (8.23), write X = n 1 + П2 + ••• + na, where nj = 1 or 0 depending 
on whether or not the jth element representing success was selected. Use this 
representation to derive formulas for the mean and variance of X as given in 
Theorem 8.2.2.
8.3 POISSON DISTRIBUTION AND POISSON PROCESS
We start from the following definition:
Definition 8.3.1 A random variable X is said to have a Poisson distribution, POI(A), if for 
some A > 0,
P{X = n} = —e‘. 
n = 0, 1, .... 
(8.28)
n! 
□
First, we want to check that the terms in (8.28) add to 1. We have
TO 
TO , n
E P{X = n} = e-X E n! = e-XeX = 1. 
n=0 
n=0
To determine the moments of the Poisson distribution, let us compute the mgf:
mX (t) = EetX = V entP{X = n} = V ent nne-x 
n!n!
n=0 
n=0
= e-x \- (AeT = e-XeXe = e>(et- 1).
n!
n=0
Thus, a moment generating function of the Poisson distribution is defined for all t and is 
differentiable an arbitrary number of times. We have
E (X )= mX (t) It=o = Ae^ex (e- 1) It=0 = A.
An easy differentiation yields E(X2) = mX(t)|t =0 = A2 + A, and therefore
Var(X) = A.
The next theorem shows that the family of Poisson distributions is closed under addition 
of independent random variables:
Theorem 8. 3.1 If X and Y are independent, with distributions POI(A1) and POI(A2), respec­
tively, then X + Y has a POI(A1 + A2) distribution.

POISSON DISTRIBUTION AND POISSON PROCESS
229
Proof: We will present a direct proof, to show the kind of calculations involved in evaluating 
the distribution of the sum. The proof using moment generating functions can be found in 
Example 7.28.
P{X + Y = n} = ^2 P{X = j,Y = n - j} = 
P{X = j} P{Y = n - j}
j=0 
j=0
n
= E
j=0
Aj1e-A1 
j!
An—je-A2 
(n - j)!
e—(A i+л 2) 
n!
nE
j=0
Aj1A2n-j
e—(A 1+ A 2)( a 1 + a 2) n 
n!
(by Newton’s formula),
which completes the proof.
□
Finally, we introduce an analogue of Theorem 8.2.3.
Theorem 8. 3.2 If X and Y are independent and X ~ POI (A 1), Y ~ POI (A2), then for 
k =0, 1, ...,n,
P{X = k\X + Y = n} = (ПA1 
} ( A2 
) 
. 
(8.29)
k A1 + A2 
A1 + A2
Thus, the conditional distribution of X given X + Y is binomial, with the number of trials 
X + Y and the probability of success p = A1/(A1 + A2).
Proof: Using Theorem 8.3.1, we have
P{X = k\X+Y= n} = P {X = k,X + Y = n} 
P {X + Y = n}
P{X = k} P{Y = n - k}
P {X + Y = n}
Y. e-A 1 dn____ e-A 2 
। 
\k\-~ k
k! e 
(n-k)! e __ n! 
Ak A2
(A 1+A2)n e-(A 1 + A2) = k!(n - k)! (a 1 + A2)n '
which reduces to the right-hand side of (8.29).
□
The following theorem explains a very important application of the Poisson 
distribution:
Theorem 8. 3.3 Ifp ^ 0 and n ^ ж in such a way that lim np = A> 0, then for k = 0, 1, ...,
lim n pk (1 - p)n-k 
n^tt k
k
— e-A 
k!
(8.30)
Proof: We will prove (8.30) under simplifying assumption np = A for all n. The proof in the 
general case is based on the same idea but obscured by some technical points. Replacing p

230
SELECTED FAMILIES OF DISTRIBUTIONS
by X/n, we have
nk pk(1 - p)n-k
n (n — 1) ••• (n k k + 1) / X X k к 
X
k ! 
n 
n
X41 — ПУ (1 — 1)••• (1 — 
) 
k !(1 — П) k
The factor (1 — X/n)n converges to e-x, while each of the remaining factors involving n 
converges to 1. Since the number of such factors does not depend on n, their product also 
tends to 1, which proves the theorem. 
□
To see the applicability of Theorem 8.3.3, observe that it can be used as an approximation 
of binomial probability of k successes in n trials, valid for small p and large n:
nk pk(1 - p)n-k
(np^) k e-np
(8.31)
■ EXAMPLE 8.8
Continuing Example 8.3, we assume that on average, one birth in 80 is a multiple birth. 
What is the probability that among 400 births that occurred in the maternity ward of 
a given hospital during the first 3 months of a year there were fewer than 4 multiple 
births?
SOLUTION. If X stands for the number of multiple births during the period ana­
lyzed, then X ~ BIN(400, 1 /80). We have
33
P{X < 4} = £ P{X = k} = W400 ) 
k=0 
k=0
1 X k
80 )
79 X
80 )
400-k
This sum can be computed directly, and the value is
0.0065 + 0.0331 + 0.0835 + 0.1402 = 0.2633.
We have here np = 400 x ^O = 5, so the approximation (8.31) by Poisson distribution 
gives
P{X < 4} « V 57e-5 = 0.0067 + 0.0337 + 0.0842 + 0. 1404 = 0.2650. 
k!
k=0
The relative errors of consecutive approximating terms are, respectively, 3.08%, 1.31%, 
0.34%, and 0.14%, while the relative error of the final answer is 0.55%. Whether or 
not this may be regarded as a good approximation depends on the goal of finding 
the probability in question. For most purposes, a relative error below 1% is quite 
acceptable. One can imagine, however, situations where it need not be so. For instance, 
an insurance company that is to cover the cost of delivery and hospital care for 
multiple births might conceivably want to know the probability of fewer than 4 
multiple births with precision better than second decimal in order to decide on the 
premium.

POISSON DISTRIBUTION AND POISSON PROCESS
231
■ EXAMPLE 8.9
Suppose that on average, one in every 100 passengers does not show up for a flight. An 
airline sold 250 tickets for a flight serviced by an airplane that has 247 seats. What is 
the probability that every person who shows up for flight will get a seat?
SOLUTION. Let X be the number of passengers who do not show up for the flight in 
question, and let us treat X as a binomial random variable with n = 250, p = 0.01, so 
that np = 2.5. The probability of the event X > 3, using Poisson approximation, is
P{X > 3} = 1 - P{X < 3} =1 - P{X = 0} - P{X = 1} - P{X = 2}
« 1 - e-2.5 - —e—2.5 - (2.5)2 e—2.5 = 0 4562
~ 1 e 1! e 
2! e — . 
,
while directly from the binomial distribution we have
P{X > 3} — 1 - 
250 ) (0.01)j(0.99)250-j — 0.4568. 
(8.32)
j=0 
j
This time the approximation by a Poisson distribution to binomial probabilities (8.32) 
has a relative error of 0.13%.
It has to be pointed out that whereas in Example 8.8 the claim that X has a binomial 
distribution was fully justified (whether or not a birth is a multiple birth is independent 
on the multiplicity of other births in the same period), the situation is not so clear in 
case of passengers missing an airline flight. The point is that people often fly together 
(typically in families or other groups). In these cases, the fact that one person misses 
the flight may affect the chances of some other persons missing the same flight. Conse­
quently, X is at best approximately binomial. Our calculations therefore give a relative 
error ofan approximation to a number that is already an approximation (to the actual 
probability).
We will now try to capture features responsible for the fact that the number of occurrences 
of some event in a given interval of time follows a Poisson distribution.
We consider the class of situations in which a certain event occurs at random points in 
time. Examples are quite common: arrivals of customers at service stations, twin births in a 
hospital, earthquakes of specified intensity occurring in a given region, fire alarms in a given 
town, and so on. To increase practical applicability, the theory focuses only on the times of 
their occurrence, disregarding other specific features of the events under consideration. The 
random variable one needs to analyze here is the number N[t ,t ] of events that occur between 
times t1 and t2 . The theory built for analyzing such processes in the most general case is 
called the theory of point processes. We will analyze only a special case of point processes, 
the Poisson process.
The assumptions underlying the Poisson processes attempt to capture the intuitive notion 
of “complete randomness.” In particular, in the Poisson process knowledge of the past pro­
vides no clue in regard to the future.
To express the properties that will imply that a given stream of events is a Poisson process, 
it will be convenient to introduce a mathematical notation, which will later be useful also in 
other contexts: The symbol o(x) denotes any function f(x) such that
lim fx — 0.

232
SELECTED FAMILIES OF DISTRIBUTIONS
■ EXAMPLE 8.10
A power function xa is o(x) ifa>1, and so is every function of the form xah(x) ifa>1 
and h is continuous at 0 (hence bounded in the neighborhood of 0). For instance, if Sn 
is a binomial random variable, then, P{Sn = k}/p = nk pk-1 (1 - p)n-k converges 
to 0 when p ^ 0 if k > 1 and so P{Sn = k} = o(p) for k > 1.
We will often use the following facts:
1. If limx t0 hxxx) = c = 0, then h(x) = cx + o(x).
2. If functions f 1, f2, ... ,fN are o(x), then f 1 + • • • + fN is also o(x).
We can now formulate the postulates of the Poisson process.
Postulate 1. The numbers of events occurring in two nonoverlapping time intervals are indepen­
dent.
Postulate 2. The probability of at least one event occurring in an interval of length Д t is X Д t + 
o(Дt) for some constant X> 0.
Postulate 3. The probability of two or more events occurring in an interval of length Д t is o (Д t).
The first postulate is the one that asserts that knowledge of the past is of no help in pre­
dicting the future. The second postulate asserts stationarity, in the sense that probability of 
an event occurring in a short time interval is (roughly) proportional to the length of this 
interval, but does not depend on the location of this interval. Finally, the third postulate 
asserts that events occur one at a time. That is chances of two events occurring within an 
interval of length Дt become negligible as Дt ^ 0.
Let us now fix the zero on time scale, and let Pn(t) denote the probability of exactly n 
events prior to t, so that Pn(t) = P{N[0,t) = n}. We will prove
Theorem 8.3.4 Under all three postulates
Pn(t) = (Xt)-e-xt, 
n = 0, 1, ... 
(8.33)
Proof: By postulates 2 and 3, for every t and Дt > 0,
P N [ t,t+д t) = 1} = X Д t + o 1(Д t),
P{N[t,t+Дt) = 0} = 1 - XДt + o2(Дt). 
(8.34)
For n =0we write, using postulate 1 and (8.34),
Po(t + Дt) = P{N[0,t) = 0, N[t,t+дt) = 0} = Pо(t)[1 - XДt + o2(Дt)]
which gives the difference ratio
P0(t + ДДt - P0(t) = -XPo(t) + Дo2(Дt)Po(t). 
(8.35)
Passing to the limit with Дt ^ 0, we obtain14
P0 (t) = -XPo( t). 
(8.36)
14The limit of the right-hand side exists and is equal to the right derivative ofP0 at t. To justify the existence of the 
left derivative in (8.35), observe that one can replace t by t — Дt in (8.35). Since o2 (Дt) does not depend on t, we 
see that P0 is continuous and that the left derivative is equal to the right derivative.

POISSON DISTRIBUTION AND POISSON PROCESS
233
The initial condition is P0(0) = 1, and the relation of (8.36) gives
Po( t) = e-Xt. 
(8.37)
Now, if n > 1, we write
n
Pn(t + Дt) = E P<N[0,t) = n - j, N[t,t+At) = j} 
j=0
n
= E Pn-j (t) P <N[ t,t+Д t) = j} 
j=0
= Pn(t)[1 - АДt + o2(Дt)] + Pn-1(t)[АДt + o 1(t)] + oз(t),
where o3 (t) is the term obtained from combining together all terms involving two or more 
events occurring between t and t + Дt.
Forming the difference ratio and passing to the limit with Дt ^ 0, we obtain the 
equations, valid for n =1, 2, ...,
Pn (t ) = -APn (t) + APn-1( t), 
(8.38)
which can be solved recursively using (8.37), with the initial conditions being Pn (0) = 0,n = 
1, 2,   Alternatively, we could use induction to check that probabilities (8.33) satisfy (8.37) 
and (8.38). 
□
We will now discuss some examples of Poisson processes.
■ EXAMPLE 8.11
The maternity ward in a certain hospital has, on average, 30 births per week. Given 
that there were 6 births on a specific day, find the probability of (a) three births on 
each of the following two days; (b) a total of six births during the following two days; 
(c) the expected number of days with exactly one birth during the month of May.
SOLUTION. We assume here that the births in the maternity ward in question form a 
Poisson process. Consequently, the number of births on a given day does not affect the 
number of births in future intervals. To answer all these questions, we must first choose 
the unit of time. This is a totally arbitrary choice, but the important point is that once 
this choice is made, we must express the parameter А in the chosen units. Then А is the 
expected number of events in the unit of time.
Let a time unit equal one day. Then А = 30/week = 4.286/day. Consequently, the 
probability of three births in a given day is (A3/3!)e-X = 0. 1806, and probability of 
such event on two consecutive days is [(A3/3!)e-X]2 = 0.0326. As regards (b), the prob­
ability of 6 births in 2 days is [(2A)6/6!]e-2X = 0.1043. For (c), the number of days 
in May when there is exactly one birth is has binomial distribution with n =31 and 
p = Ae-X = 0.0590, so the expectation equals 31 p = 1.83.
As mentioned, the postulates of Poisson process attempt to capture the idea of “complete 
randomness.” The theorems below indicate to which extent this attempt is successful.
To facilitate formulation of the theorems, we let Xt = N(0,t) denote the number of events 
occurring in (0, t), and also let T1, T2, ... denote the times of occurrence of successive events. 
Thus,
Tk=inf{t:Xt >k}.

234
SELECTED FAMILIES OF DISTRIBUTIONS
In the analogy with (8.19), we have the following identity:
Tk < t 
if and only if 
Xt > k
and consequently P{Tk < t} = P{Xt > k}. Since Xt has Poisson distribution with param­
eter Xt, we have
P {Xt > k} = f (jj e
j=k
At = 1 _ g Xje-xt 
j=0 j
Then the cdf of Tk is
k-1 (Xt)j
P{Tk < t} = P{Xt > k} = 1 
Ц)-e-At
j=0 j!
(8.39)
Now, let U1 = T1, U2 = T2 _ T1, U3 = T3 _ T2, ... be the time to the first event (U1) and 
consecutive times between events (U2, U3, ...). From (8.39) for k =1we have P{U1 < t} =
P{T1 < t} =1_ e-xt, so U1 has an exponential distribution with mean 1/X. Next
P{U2 > t\Ti = т} = P{U2 > t\Ui = т}
= P{no events in (т, t + т) \T1 = т)
= P{no events in (т, t + т)} = e-At
which means that U2 also has exponential distribution with mean 1/X and is independent 
of U 1. Since the argument can be repeated for all other U- s, we have proved the following 
theorem:
Theorem 8.3.5 In a Poisson process, the time U1 until the first event and the times U2, U3, ... 
between subsequent events are independent random variables, each with the same exponential 
distribution with mean 1/X.
Since the origin of time scale t =0was chosen arbitrarily, this theorem asserts that if we 
start observing a Poisson process at an arbitrarily selected time, fixed or randomly chosen,15 
then the waiting time for the first event has the same distribution as the times between subse­
quent events. This property is connected closely with the memoryless property of geometric 
distribution, specified in Theorem 8.1.2.
15The phrase “randomly chosen” ought to be qualified here. Suppose that the “random choice” isto start observing 
Poisson process 5 minutes before the next event. Technically, such a choice gives a random moment of beginning 
of observation (since the time of event is random), and for this choice U1 = 5 minutes. Here the qualification of 
“random choice” is that the decision depends on the past but not on the future of the process.
Theorem 8.3.6 If X is a random variable with exponential distribution, then for all s, t > 0,
P{X>s+t|X>s}=P{X>t}. 
(8.40)
Conversely, if X may assume only positive values and satisfies (8.40) for all s, t > 0, then X 
has exponential distribution.
Proof:LetX have exponential distribution. The left-hand side of (8.40) is the ratio
P{X >s +1} 
P{X > s}
e-x(s+t) 
e-As
= e-xt = P{X > t}.

POISSON DISTRIBUTION AND POISSON PROCESS
235
Conversely, (8.40) implies that the tail of the cdf of X, that is, the function ф(x) = 
P{X > x}, satisfies the equation ф(s +1) = ф(s)ф(t). One then shows (e.g., see Feller, 
1968) that any bounded solution of this equation must be of the form ф(t) = e-xt for 
some A > 0. 
□
The property of a Poisson process discussed above is one of the arguments for the claim 
that assumptions ofa Poisson process capture “maximal randomness.” While in the Poisson 
process, knowledge of the past does not give a clue to the future; it is not so for other streams 
of events. For instance, if one arrives at a bus stop just after a bus has left (knowledge of the 
past), one may expect a longer wait for the next bus.
The following theorem shows that in Poisson processes, knowledge of the number of 
events in the past gives us, in a sense, no additional information not only about the future 
but also about the past. We have the following:
Theorem 8.3.7 The events in Poisson process satisfy the following property: for every 
0 <u<t,
P{Ti < UX = 1} = u. 
(8.41)
Proof :Wehave
P,T < ,y 
P{T1 <u,Xt = 1} 
P{T1 <u,Xt = 1}
P{T1 < u\x, =1} = 
P {Xt = 1} 
=----At—t---------. 
(8.42)
Conditioning on T1, the time of occurrence of the first event, and using the fact that T1 has 
exponential distribution, the numerator in (8.42) becomes
u
P{T1 <u,Xt = 1} = / P{Xt = 1 \T1 = z}Ae-Xz dz.
0
IfT1 = z, the event Xt = 1 occurs if the time U2 between the first and second event exceeds 
t - z. So
P{Xt = 1 ITi = z} = P{U2 >t - z} = e-(t-z).
Substituting (8.40), we obtain formula (8.41). 
□
This theorem asserts that if we know that only one event occurred between 0 and t, then 
the conditional distribution of the time of occurrence of this event is uniform on (0, t). In a 
sense, then, we have no information as to when the event occurred.
Finally, let us observe that we can obtain the unconditional density ofTk by differentiating 
the cdf given by formula (8.39).
Theorem 8.3.8 The density fTk (t) of the time Tk of the kth event in Poisson process is
Ak
fTk (t) = ^ЛАГt 1 e—Xt, t> 0. 
(8.43)
k (k- 1)!
The distribution of Tk is sometimes called the Erlang distribution. As we will see later, 
(8.43) is a special case of the gamma density.
■ EXAMPLE 8.12
Fires in a certain town occur according to a Poisson process. If there were 10 fires in a 
given week, what is the probability that at least one of them occurred on Friday?

236
SELECTED FAMILIES OF DISTRIBUTIONS
SOLUTION. What is of interest here is that we do not need to know the intensity A of 
the Poisson process in question. We know that given that the number of fires was 10, 
their times of occurrence fall within a week according to the uniform distribution. The 
probability that a single fire does not fall on Friday is 6/7; hence, chances of at least 1 
of 10 fires falling on Friday is 1 - (6/7)10 = 0.7859.
■ EXAMPLE 8.13
Suppose that traffic accidents on a given intersection occur according to a Poisson 
process, with the rate on Saturdays being twice the rate on weekdays and the rate on 
Sundays being double the rate on Saturdays. The total rate is about five accidents 
per week. What is more likely: two accidents on each of two consecutive weekends 
(Saturday + Sunday), or a total of four accidents on weekdays in a given week?
SOLUTION. If A is the average number of accidents on a weekday, then it is 2A 
on a Saturday and 4A on a Sunday. Consequently, we have 5A +2A +4A =5, 
which gives A = 5/11. The number of accidents on a weekend is the sum of the 
numbers of accidents on Saturday and Sunday. These are independent Poisson 
random variables; hence, their sum (see Theorem 8.3.1) also has Poisson distribution, 
with the mean 2A +4A = 30/11. Consequently, the first probability is P {X = 2}2, 
where X ~ POI(30/11), or [(30/11)2e-30/11 /2!]2 = (0.2432)2 = 0.0592. The second 
probability is P{Y = 4}, where now Y ~ POI(5A) = pOi(25/11), which equals 
(25/11)4e-25/11/4! = 0.1145.
To continue, suppose that on a Friday (which happened to be Friday the 13th) the 
number of accidents was as high as the number of accidents on the following weekend. 
Is such an event unusual?
Let us evaluate the chances of such an occurrence without reference to any magic 
connected with Friday the 13th, that is, probability P{X = Y}, where X and Y are 
independent, X ~ POI(A) and Y ~ POI(6A) for A = 
oo
P{X =Y} = 
P{X =j}P{Y=j}
j=0
= E j'->jje-SA = X 
j=0 
j=0
= 0.0415 + 0.0515 + 0.0159 + 0.0022 + ••• = 0.1111.
As we see, the chances here are slightly over 10%; hence, such an event need not 
necessarily be regarded as highly unusual. However, as one may note, almost all of this 
probability is due to the possibility that X = Y =0or X = Y =1.
Similarly, the probability that there are more accidents on Friday the 13th than on 
the whole following weekend is still not negligible:
P(X >Y) = 
P{X = k} 12 P{Y = j} = 0.0406.
k=1 
j=0
This time most of the probability is contributed by the terms P{X = 1} x P{Y = 0} 
and P{X = 2} x [P{Y = 0} + P{Y = 1}].
The concept of a Poisson process allows a number of generalizations. First of all, note that 
the symbol t need not be interpreted as time: it may be some other attribute interpretable as a
(6A2)j
7 A
e
(j!)2

POISSON DISTRIBUTION AND POISSON PROCESS
237
linear dimension. Thus, one can regard faults on a scotch tape or misprints in a text (regarded 
as a continuous string of letters) as Poisson processes, provided that one can reasonably 
expect that the postulates of the Poisson process hold.
One of the generalizations of the Poisson process concerns the extension to a higher 
dimension. Instead of events occurring in time (i.e., random points on a line), one can con­
sider the case of points allocated at random on a plane or in space. The postulates of the 
Poisson process in such cases are analogous to the postulates in one dimension. The basic 
random variable is X(A) = number of points falling into A, where A is a set on the plane 
or in space. The main postulate asserts that the numbers of points falling into disjoint sets 
are independent. The second postulate asserts that the probability that X(A) = 1 depends 
on the size of the set A, not on its location, and equals A|A| + o(|A|), where |A| stands for 
the area or volume of the set A. Finally, the third postulate asserts that the probability that 
X(A) > 2 is of the order o(|A|). Under these postulates one can show that
P {X (A) = k} = () k e-'A, 
k = 0, 1, .... 
(8.44)
As in a one-dimensional case, A is the expected number of points falling into a region of 
unit size.
■ EXAMPLE 8.14
The data below are taken from Feller (1968) who lists them among examples of phe­
nomena fitting the Poisson distribution. The observations concerned points of hits in 
south London by flying bombs during World War II. The entire area under study was 
divided into N = 576 small areas of 0.25km2 each, and the numbers Nk of areas that 
were hit k times were counted. The total number of hits is T = kNk = 537, so the 
average number of hits per area is A = T/N = 0.9323. The fit of the Poisson distri­
bution is excellent, as can be seen from comparison of the actual numbers Nk and 
expected numbers NP{X = k} = Nk-e-x for A = 0.9323.
k
0
1
2
3
4
5 or more
Nk
| 
229
211
93
35
7
1
NP{X = k}
| 226.74
211.39
98.54
3.62
7.14
1.57
The chi-square goodness-of-fit criterion (to be discussed in further chapters) shows 
that in about 88% of cases one should expect worse agreement.
This example has become sort ofa “classic” in the sense of being reproduced in numerous 
textbooks on statistics, invariably without any comments (other than remarks that the fit is 
very good). However, the fit to the Poisson distribution was a piece of information of con­
siderable value as military intelligence: it showed the state of German technology in regard 
to the precision of their aiming devices. Perfect randomness of hits in a given large area 
indicated that it was not possible to select any specific target within this area.
Feller writes: “It is interesting to note that most people believed in a tendency of the 
points of impact to cluster. If this were true, there would be a higher frequency of areas with 
either many hits or no hit, and a deficiency in the intermediate classes. The data indicates 
perfect randomness and homogeneity of the area; we have here an instructive illustration of 
the established fact that, to the untrained eye, randomness appears as regularity or tendency 
to cluster.” It appears that Feller fully knew the reason for collecting and analyzing the data 

238
SELECTED FAMILIES OF DISTRIBUTIONS
in question but could only make a veiled allusion: his book was first published in 1950, just 
5 years after the end of World War II, when many things were still secret.
At the end, we will give an example involving the Poisson process in three dimensions.
■ EXAMPLE 8.15
The Poisson Bakery makes a special kind of cookies, called Four-Raisin cookies. 
Raisins (10,000) are added to the dough for 2,500 cookies, and after thorough mixing, 
the dough is divided into equal parts of which 2,500 cookies are formed and baked. 
What is the proportion of Four-Raisin cookies that have no raisins at all? What 
proportion will have exactly four raisins?
SOLUTION. Here we have a spatial Poisson process, with raisins playing the role of 
points located randomly in space. If we take a cookie as a unit of volume, then A = 4, as 
there are, on average, four raisins per cookie. Ifwe let X denote the number of raisins in 
a randomly selected cookie, then P{X =0} = e-4 = 0.0183, so slightly below 2% of 
all Four-Raisin cookies are raisin-less. On the other hand, P{X =4} = (44/4!)e-4 = 
0.1954.
Now, suppose that you buy a box of 200 Four-Raisin cookies. What is the 
probability that no more than two of them have no raisins? We have here a situation of 
a Poisson approximation to the binomial distribution, with “success” being a cookie 
with no raisins so that np = 200e-4 = 3.66. The number Y of raisinless cookies in 
the box has a binomial distribution BIN(200, 0.0183), which is approximated by 
the Poisson distribution with A = np = 3.66. Therefore, P{X < 2} = P{Y = 0} + 
P{Y =1} + P{Y = 2}^ (1 + 3.66 + 3.662/2)e-3■66 = 0.29; hence, P{Y > 3} is 
about 0.71, which means that 71% of all boxes will contain three or more Four-Raisin 
cookies with no raisins at all.
PROBLEMS
8.3.1 Let X have the POI(A) distribution. Find: (i) the mode of X (i.e., the most likely 
value of X); (ii) P(Xis even). (Hint: Write the Taylor expansions for ex and e-x. 
Any ideas?)
8.3.2 A book with 500 pages contains, on average, 3 misprints per 10 pages. What is the 
probability that there will be more than one page containing at least three misprints?
8.3.3 Accidents in a given plant occur at a rate of 1.5 per month. The numbers of acci­
dents in different months are independent and follow the Poisson distribution. Find 
the probability of: (i) five accidents in a period of five consecutive months; (ii) one 
accident in each of five consecutive months.
8.3.4 Suppose that the daily numbers of ships arriving to a certain port are independent, 
each with POI(3) distribution. Find: (i) the expected number of days in April when 
there are no arrivals; (ii) the expected number and variance of days during the sum­
mer months (June, July, August) with the number of arrivals equal to the mean daily 
arrival rate.
8.3.5 A certain store makes, on average, two sales per hour between 9:00 a.m. and 2:00 
p.m., and three sales per hour between 2:00 p.m. and 9:00 p.m. The numbers of sales 
in different time periods are independent and have a Poisson distribution. Find: (i) the 
probability of more than three sales between 10:00 a.m. and noon, and also between 

POISSON DISTRIBUTION AND POISSON PROCESS
239
1:00 p.m. and 3:00 p.m. (ii) the probability that the number of sales between 10:00 a.m. 
and 11:00 a.m. will be the same as number of sales between 6:00 p.m. and 7:00 p.m.
8.3.6 Weekly numbers of traffic accidents at intersections A, B, and C are independent, each 
with a Poisson distribution. It is known that, on the average, the number of accidents 
at intersection A is the same as the number of accidents at intersections B and C 
combined, while the average number of accidents at intersection B is half of that at 
intersection C. (i) If there were, in a given week, 16 accidents at intersections A, B, 
and C together, what is the probability that exactly four of them were at intersection 
C? (ii) What is the probability that there were more accidents at intersection C than 
at intersection A?
8.3.7 Find the approximate probability that in 1,000 randomly chosen persons there are 
exactly: (i) Two born on New Year and two born on Christmas. (ii) Four born on 
either Christmas or New Year.
8.3.8 (Does Nature Prefer Even Numbers?) Generalizing Problem 8.3.1 (ii), let X be 
an integer-valued random variable such that X = X1 + X2, where X1,X2 are 
independent, identically distributed integer-valued random variables. Show that 
P{X is even } > 0.5 (this property has been pointed out to us by Steve MacEachern, 
personal communication).
8.3.9 Let X be the number of failures preceding the rth success in a sequence of Bernoulli 
trials with probability of success p. Show that if q ^ 0, r ^ ж in such a way that 
rq = A> 0, then
P {X = 
^k e­
k!
for every k = 0, 1, 2, ..... This shows that the negative binomial distribution can
be, for large r and small q, approximated by a Poisson distribution. (Hint: Use an 
argument similar to that in the proof of Theorem 8.3.3.)
8.3.10 Suppose that the number of eggs X laid by a bird has a Poisson distribution. Each 
egg hatches with probability p, independently of what happens to other eggs. Let V1 
and V2, V1 + V2 = X, denote the numbers of eggs that hatch, and the number of eggs 
that do not hatch, respectively. Show that V1 and V2 are independent.
8.3.11 Traffic accidents at a given intersection occur following a Poisson process. (i) Given 
that 10 accidents occurred in June, what is the probability that the seventh accident 
occurred before June 10? (ii) If it is known that n accidents occurred in April, what 
is the expected number of accidents that occurred during the second week of that 
month?
8.3.12 Two parts of a document are typed by two typists. Let X and Y be the numbers of 
typing errors in the two parts of the paper. Assuming that X and Y are independent 
and have Poisson distributions with parameters A 1 and A2, respectively, find the prob­
ability that: (i) The paper (i.e., two combined parts) has at least two typing errors. (ii) 
The total number of typing errors is m. (iii) The first part of the paper has k typing 
errors given that there are n typing errors altogether.
8.3.13 Assume that chocolate chips are distributed within a cake according to a Poisson 
process with parameter A. A cake is divided into two parts of equal volume (disregard 
the possibility of cutting through a chocolate chip). Show that the probability that

240
SELECTED FAMILIES OF DISTRIBUTIONS
each part of the cake has the same number of chips is
оо
e-X Е
k=0
(X/2)2 k
(k !)2
8.3.14 Consider two independent Poisson processes with the same parameter X. Let 
Ni(t) ,i =1, 2 be the number of events in ith process which occurred up to time 
t, and let UT be the set of all those times t with 0< t < T at which N1(t) = N2(t). 
Find E(UT) given that: (i) N1(T) = N2(T) = 2. (ii) N1(T) = 2,N2(T) = 3. (Hint: 
Use the fact that the sum of two independent Poisson processes is a Poisson process 
and Theorem 9.8.5.)
8.4 EXPONENTIAL, GAMMA, AND RELATED DISTRIBUTIONS
We have encountered the exponential distribution on a number of occasions as the distribu­
tion of times between events in Poisson process in one dimension. To repeat the definition, 
a random variable X has exponential distribution EXP(A) if for some A > 0 and x > 0,
F(x) = P{X < x} = 1 - e-Xx, x > 0,
so that for x > 0 the density of X is f (x) = Ae-Xx, x > 0. We know that
E (X) = 1, 
Var( X) = Л,
A 
A2
and the mgf of X is
mX (s) 
д------ for s < A.
The hazard function (see Section 5.5) of exponential random variable is constant:
f (x) 
= Ae-Xx = a
1 - F(x) ~ e-Xx ~ ,
a property closely related to the memoryless property ofan exponential distribution asserted 
in Theorem 8.3.6.
Readers should be aware of the fact that the phrase “exponential distribution with param­
eter A” is ambiguous, since an exponential distribution is sometimes introduced in the form 
f(x)=(1/A)e-x/X, x>0. In this notation, E(X)=A and Var(X) = A2. Consequently, 
unless it is clear whether the parameter appears in the numerator or denominator of the expo­
nent, one could use phrases that convey the information about the mean. Thus, “exponential 
distribution with mean 6” will have density (1 /6)e-x/e, and so on.
Next, the sums of independent and exponentially distributed random variables also 
appeared in the Poisson process, as times T1, T2, ... of consecutive events. The cdf’s of 
these random variables were obtained using the identity
P{Tr >t} = P{Xt <r} = 
(kke-Xt
k=0
The density of Tr follows now by the differentiation,
An
fr(t)^---- 7vtr-1 e-Xt, 
t> 0.
r 
(r- 1)!
(8.45)

EXPONENTIAL, GAMMA, AND RELATED DISTRIBUTIONS
241
Since Tr is the sum of r independent waiting times, each with the same exponential dis­
tribution, the mgf of Tr exists for s < A and equals
r
The definition of distribution ofTr as the sum of waiting times involves using an integer 
value of r. We have a complete analogy with the binomial distribution (count of successes 
in fixed number of trials) and negative binomial distribution (count of number of trials up 
to a fixed number of successes), on the one hand, and the Poisson distribution (number of 
events until fixed time) and distribution ((8.45)) (time till fixed number of events occurs), on 
the other hand. However, unlikely as in the case of a negative binomial distribution, r need 
not be an integer, and we can define the class of distributions comprising densities (8.45) as 
a special case. To this end let us introduce the following definition:
Definition 8.4.1 For t > 0 we define the gamma function as
/•^
r(t)= 
xt-1 e-x dx.
0
(8.46) 
□
We can show that this function is well defined for all t > 0. Integration by parts gives
Г(t) = (t - 1)Г(t - 1).
(8.47)
Since Г(1) = 1, by induction, for any integer n >1, we obtain
Г(n) = (n - 1)
Consequently, a gamma function can be seen as an extension of the factorial function, which 
it “fills in” for noninteger values ofn.
Let us now show that Г( 1) = ^П. Indeed,
Г (I) = / x 1 /2- 1 e-x dx = fQ x- 1 /2e-x dx = fQ ~' y2/2y dy
= 2^П [ 
e-y2/2 dy = 2^П1 = ^П, 
(8.48)
0 2П 
2
where we used substitution x = y2/2 and the fact that the last integral equals 1/2 as a half 
of the integral of the standard normal density.
We can now introduce the following definition:
Definition 8.4.2 A random variable with density of the form
£, x f Cxa 1 e Xx for x > 0 
f(x) = 
0 
forx < 0
for some a > 0 and A > 0 is said to have a gamma distribution with shape parameter a and 
scale parameter A, GAM(a, A). C is the normalizing constant. 
□
Since
C f xa 1 e Xx dx = 1,
0

242
SELECTED FAMILIES OF DISTRIBUTIONS
by substituting Xx = z, we easily obtain from (8.46) that
a
C = 
.
Г( a)
(8.49)
We can now obtain the moments of gamma distribution. That is,
E(X) = X xf (x) dx = “—т x xae Xx dx 
о 
Г(a) J0
_ Xa 
Г(a + 1) _ a
= Г(a) X Xa+1 
= X
(8.50)
in view of (8.47). Similarly
E(X2) = [ x2 f (x) dx = ——- X xa +1 e-x dx 
о 
r(a) J0
= Г(0) x X(a+2) = 
X2 
’
_ Xa 
Г(a + 2) _ a(a + 1)
Var(X) = E(X2) - [E(X)]2 = O_.
X2
(8.51)
The moment generating function of gamma distribution can be evaluated as follows:
m(t) = -X— X etxxa- 1 e-Xx dx = X xa- 1 e-(t)x dx
( ) 
Г(a)Jо 
Г(a)Jо
Xa y Г(a) 
1
Г(a) 
(X - t)a 
(1 - t/X)a ’
provided that t<X. It is easy to show that the kth ordinary moment is
The following closure property of gamma distributions is a consequence of Theorem 7.5.2:
Г( a + k) 
= 
.
k 
Г( a) Xk
(8.52)
Theorem 8. 4.1 If X and Y are independent with X ~ GAM (a 1, X), Y ~ GAM (a2, X), then 
X + Y ~ GAM (a 1 + a2 ,X).
Since the waiting time Tk for the kth event in a Poisson process has a distribution GAM(k, X), 
Theorem 8.4.1 (for integers a1 and a2) expresses the simple fact that the waiting time Ta1+a2 
is the sum of two independent waiting times, Ta1 and Ta2 .
Let us note that exponential distribution with parameter X is the same as GAM(1, X). Also 
let us recall that in Example 5.27 we found the density of the square of standard normal 
variable [i.e., of Y = Z2, where Z ~ N(0,1)]. This density equals f (y) = ^=y- 1 /2e-y/2, 
which we recognize as GAM(1/2, 1/2). The sums of squares of independent standard normal 
variables appear so often in statistics, that the distribution of such sum bears its own name:
Definition 8.4.3 For integer v, the distribution GAM (v/2, 1 /2) is called the chi-square dis­
tribution with v degrees of freedom. A random variable with such distribution is typically 
denoted by xV. 
□

EXPONENTIAL, GAMMA, AND RELATED DISTRIBUTIONS
243
The following theorem will be very important in statistical inference; its proof is an imme­
diate consequence of Theorem 8.4.1.
Theorem 8. 4.2 If Z1, ... ,Zn are independent, each with standard normal distribution, then
X = Z 22 + ••• + zn
has chi-square distribution with n degrees of freedom.
Moreover, if X 1, ... ,Xk are independent, chi-square distributed random variables, Xi ~ 
X2i, then Y = X 1 + • • • + Xk has chi-square distribution with v degrees of freedom, where 
v = v 1 + ••• + vk ■
Another property that will be useful in further chapters devoted to statistical inference is 
provided by the next theorem:
Theorem 8.4.3 If random variable X has GAM (a, X) distribution, then Y = 2XX has 
GAM (a, 1 /2) distribution. If 2a additionally is a positive integer, then Y has x2a 
distribution.
Proof: Let Y = aX, where a > 0. Then x = y/a = ф(y) and ф'(y) = 1 /a. Consequently, 
based on (8.4.2),
fY(y) = fx(Ф(y)) x ф (У)| = 
(y)a—1 e-Xy/a x 1
Г( a )\ a; 
a
= (X/a )a ya-1 e-(X/a)y. 
(8.53)
r( a)
The density fY(y) has a GAM(a, X/a) distribution, which is the same as x2a, when a = 2X 
and 2a is a positive integer. 
□
With wide availability of statistical packages today, the values of cdf as well as percentiles 
of chi-square distributions for various numbers of degrees of freedom can be easily obtained. 
For given n and x, we can obtain P{xП < x}, as well as for given n and p, we can obtain x 
such that P{xП < x} = p.
At the end of this section, we will introduce two families of distributions somewhat related 
to the exponential family.
Definition 8.4.4 The distribution with the density function
f (x; X) = 2Xe-xlx 
(8.54)
for —ж < x < x>,X> 0, is called Laplace or a double exponential. 
□
The Laplace distribution is symmetric, and it has higher values of a kurtosis than the 
normal distributions. It can be generalized in several ways. For example, its density could
become
( 1X 1 ex 1 x 
for x < 0
f(x; X1,X2) = 
2 1
[ 2 X 2 e x 2 x for x > 0,
or even
pX1ex 1 x
(1 — p) X 2 e-X 2 2х
for x< 0
for x > 0,
f(x;p,X1,X)=
(8.55)

244
SELECTED FAMILIES OF DISTRIBUTIONS
where A 1 > 0, X 2 > 0 and 0 <p < 1. Such generalized distribution will be skewed if A 1 = 
A2 or p = 0.5. The Laplace distribution is very useful for modeling in biological sciences, 
economics, and finance. Interested readers can find more information in Kotz et al. (2001).
The moment generating function of the Laplace distribution ((8.54)) is
E(eX) = / + 
et1 Ae^'x dx = A f ex(t+x) dx + A f + ex(t-x) dx
-—ж 2 
2 —-& 
2 00
Aex (t+x) 
2( t + A)
0
+
—ж
Aex(t—x) 
2(t - A)
+ж
0
A2
A 2 - 12.
1 
1
t + A - t - A )
A
2
(8.56)
The density (8.54) of the Laplace distribution is symmetric around 0; therefore, its 
expected value is 0. The computation of other moments will be left as an exercise.
The last family of distributions to be introduced in this section is named after Waloddi 
Weibull, a Swedish engineer, scientist, and mathematician. The family of distributions that he 
introduced has a lot of flexibility and, as such, is widely used in industrial and engineering 
applications, such as reliability analysis, determination of wind spread distribution, or to 
model the dispersion of the received signals in radar systems.
Definition 8.4.5 The random variable with density of the form
f (x; k,e) = ke(xO)k—1 e—(хв))k
(8.57)
for x > 0, в > 0, k > 0 is said to have a Weibull distribution, denoted WEI(k, в); k and в are 
called its shape and scale parameters, respectively. 
□
The cdf of a Weibull distribution is
F (x) = 1 - e—(xe)k,
and consequently, its hazard function equals кв (xe)k—1. For k < 1, the hazard function 
is decreasing, and it is increasing for k>1. If k =1, the hazard function is constant and 
WEI(1, в) distribution becomes exponential.
While the moment generating function of Weibull distribution is not tractable, it can be 
shown (we leave this for the readers as an exercise) that ordinary moments, mn , equal
mn = e—nГ (1 + n) 
(8.58)
and that the mean and the variance are в—1 Г(1 + |) and в—2 [Г(1 + 2) - Г2(1 + |)], respec­
tively.
PROBLEMS
8.4.1 Show that if variable X has a GAM(n, 1) distribution, where n is a positive integer, 
then its cdf is given by the following formula:
n
1
FX (x)= Г( n) Jо
dt = 1
e—xy 'j. 
j=o j!
tn
1 e t
(Hint: Integrate by parts and use induction.)

EXPONENTIAL, GAMMA, AND RELATED DISTRIBUTIONS
245
8.4.2 A system consists of five components. Suppose that the lifetimes of the components are 
independent, with exponential distributions EXP(A 1), ..., EXP(A5). Find the cdf and 
density of variable T = time to failure of the system if the components are connected: 
(i) In series (see Figure 8.2), so that the system fails as soon as one of its components 
fails. (ii) In parallel (see Figure 8.3), so that the system works as long as at least one 
component is operating. (iii) As in Figure 8.4.
—ИЛ
£S0—CSO—CS4}
{~S5~|------
Figure 8.2 Series system.
Figure 8.3 Parallel system.
Figure 8.4 Series-parallel system.
8.4.3 In the flowchart of Figure 8.5, the block denoted “sample U” means that the com­
puter samples a value of random variable U with a distribution uniform on (0, 1), the 
samplings being independent each time the program executes this instruction.
Assume that m is a positive integer and A > 0. Find: (i) P{T < 2} if A = 2 and m = 3. 
(ii) The cdf and density ofT, E(T), and Var(T) in the general case.
8.4.4 Suppose that patients arrive to the emergency room according to Poisson distribution 
with mean A =3. What is the expected time until the 9th patient arrives? Find the 
probability that the next (10th) patient arrives 1 hour later.
8.4.5 For a variable X that has a Laplace distribution with A =1, find: (i) Interquartile range 
(the difference between the upper and lower quartile). (ii) Variance. (iii) Kurtosis.
8.4.6 For a variable X having Laplace distribution with density f(x, 0.4, 1, 2) given by (8.55), 
find: (i) Mean; (ii) Variance; (iii) Median; (iv) Interquartile range.

246
SELECTED FAMILIES OF DISTRIBUTIONS
Figure 8.5 Flowchart.
8.4.7 Find the distribution of X = в(- log U)1/k, if U ~ U(0, 1).
8.4.8 (i) Find the median and the mode of the Weibull distribution with a density (8.57). (ii) 
Prove the formula (8.58).
8.4.9 It was found that the survival time (in years) in a group of patients who went through 
a certain medical treatment and are in the similar risk group follows WEI(2, 1/3) dis­
tribution. Find: (i) The median survival time for such patients. (ii) The probability that 
a randomly selected patient will live at least five more years if he already survived 1 
year after the treatment.
8.5 NORMAL DISTRIBUTION
We have already encountered the normal distribution in Chapter 5. Let us recall that the 
univariate normal distribution with parameters f and a2, denoted N(f, a2), has density
f (x) = -—= e-(x-^) /2a , —x < x < x.
It has been shown in Example 5.17 that f is indeed a density. Moreover, if X has distri­
bution N(f, a2), then E(X) = f, Var(X) = a2, which gives a direct interpretation of the 
parameters.
The moment generating function of the normal distribution was obtained in Example 
7.27 as
m (t) = e^+' 2 t 2 / 2.
We have the following closure properties of the normal distribution:
Theorem 8.5.1 A linear transformation of a normally distributed random variable again has a 
normal distribution. In particular, if random variable X has a normal distribution N(^,a2), 
then the random variable
Z = X—f.
a
has the standard normal distribution N(0, 1).

NORMAL DISTRIBUTION
247
Proof: We have, using (7.21),
mZ (t ) = m 1 /aX-(^/a)( t ) = mX (t/CT ) e—^at = e 2 / 2 .
The right-hand side is the mgf of a standard normal random variable. 
□
The property asserted in Theorem 8.5.1 has important practical consequences. It shows 
that to determine probabilities for any normally distributed random variable, it suffices to 
have access to the probabilities for a standard normal random variable.
This property is especially important in view of the fact that the cdfofa normal distribu- 
' 
Ф(x; р.,ст2) = —-= [ e-(t-^) /2a dt
^2П —ж
cannot be integrated in closed form. Thus, it is necessary to use the tables, and Theorem 8.5.1 
implies that one table is sufficient to calculate probabilities for all normal distributions. One 
can also use any statistical software.
We will let Z denote the standard normal random variable, with density
ф(x) = e— e-x /2
л/2П
and cdf 
z
Ф(x) = 
У 
e-x /2 dx. 
(8.59)
Theorem 8. 5.1 asserts, in effect, that given the tables of function (8.59), we have, for any 
X ~ N(р.,ст2),
P{a < X < b} = P | a-^ < Z < b-^ }
= Ф f b—t - Ф ( a - » .
ст 
ст J
Since ф(x) is symmetric around 0, we have P{Z < z} = P{Z > -z}; hence, the cdf of 
standard normal distribution satisfies the relation
Ф(z) = 1 - Ф(-z).
Consequently, many statistical tables give the values of Ф(z) only for z > 0.
Using any statistical software we find Ф(3) = 0.9987. Since for z > 0 we have
P{|Z| >z}=P{Z>z}+P{Z<-z}
= 1 - Ф(z) + Ф(-z) = 2Ф(-z) = 2[1 - Ф(z)],
we see that P{IZ| > 3} = 0.0026. Using Theorem 8.5.1, we see that if X ~ N(^, ст2), then
P{|X - ^I > 3ст} = P{IZ| > 3} = 0.0026. 
(8.60)
This explains the origin of the three-sigma rule, according to which one is allowed to dis­
regard the possibility ofa random variable deviating from its mean more than three standard 
deviations.
Most tables of standard normal distribution do not give the values of Ф(z) for z > 3. If 
such values are needed, we have

248
SELECTED FAMILIES OF DISTRIBUTIONS
Theorem 8. 5.2 For z > 0 the function Ф( z) satisfies the inequality
1
z
1 \ 
z3 J
and consequently, as z ^ ж,
Ф(z) < 1 — Ф(z) < —Ф(z) 
z
(8.61)
(8.62)
1 — Ф(z) « -ф(z). 
z
Proof: We have here the obvious inequality
1
3
x 4
ф ( x ) < ф ( x ) <
A simple check shows that this inequality is equivalent to
1 ф (x) 
x
d
dx
<— d [1 — ф(x)] < — dL
Integrating (8.63) between z and ж, we obtain (8.61).
(8.63)
□
Numerically, the relation (8.62) gives 1 — Ф(4) « 3.36 x 10_5, 1 — Ф(5) « 2.97 x 10_7, 
1 — Ф(6) « 1.01 x 10_9. Such small probabilities could be of interest in estimating the 
chances of, say, an accident in a nuclear power plant.
From a practical viewpoint, the knowledge of these probabilities allows us to assume the 
normality of distribution in many cases where “logically” the distribution cannot possibly be 
normal. To illustrate the point, it is often assumed that an attribute as, say, height in human 
population is normally distributed (e.g., among men, we have mean d about 70 inches and 
standard deviation a of about 2 inches). But since a normally distributed random variable 
may always assume both positive and negative values, one could argue that height—which 
cannot be negative—cannot have a normal distribution. The chances of a random variable 
X with normal distribution N(70, 4) being negative are of the order Ф(—35) = 1 — Ф(35) « 
0.0069 x e-612. So events with such a probability can be safely disregarded, and it turns out 
that it is much easier to work with the assumption of normality than invent a distribution 
for height that does not allow negative values.
We will now prove a very useful and important property of normal distribution and illus­
trate its use.
Theorem 8.5.3 Let X and Y be independent random variables with distributions X ~ 
N (d 1 ,a2) and Y ~ N (d2,a2) and let а, в be any constants. Then the random vari­
able U = aX + eY has the distribution N (ad 1 + в^2,a2a2 + в2a2). Moreover, if 
X 1, ... ,Xk are independent random variables with distributions N(di,a2) for i = 1, ... ,k 
and if a 1, ...,ak are any constants, then random variable W = k=1 aiXi has the 
N(Ek=1 aidi, En=1 ai2a2) distribution.
Proof: We will provide the proof for k =2, the prooffork>2 is analogous. Since mX(t) = 
exp {d 11 + a2 2 }, mY (t) = exp {/л 21 + a 2 2 }, and aX, eY are independent, we have
mU (t) = maX+0Y (t) = maX (t) m 0Y (t) = mX (at) mY (et)
[ 
2 a 2 t 2
exp л 1 at + a-y——
, ^rx^2 в2tt 
d 2 at + a ^~2~
exp {(d 1 a + d2в)t + (a2a2 + a2в2)t2| .

NORMAL DISTRIBUTION
249
We recognize the right-hand side as an mgf of N(^ 1 a + ^2в,а1 a2 + a2в2) 
distribution. 
□
■ EXAMPLE 8.16
Assume that the height of men in a certain population is normal with mean ^M = 70 
inches and standard deviation aM =2 inches. The height of women is also normal, 
with mean /i.W = 68 inches and aW = 1. 5 inches.
One man and one woman are selected at random. What is the probability that the 
woman is taller than the man?
SOLUTION. Let X and Y be the heights of the randomly selected man (X) and 
woman (Y ). We need P {Y>X}.
Without Theorem 8.5.3, we could proceed as follows (this solution is applicable to 
any distribution ofX and Y , and is therefore of some general interest): IfF and G are 
cdf’s for X and Y , respectively, and f and g are their densities, then conditioning on 
values of Y, we have
P{Y>X}= P{Y>X|Y =y}g(y)dy=
F (y) g(y) dy.
P {X<y} g(y) dy
(8.64)
We also condition on values of X, obtaining
P{Y>X} = 
P{Y>X|X = x} f(x) dx = 
P{Y>x} f(x) dx
= 
[1 - G(x)] f(x) dx.
Using now the assumption of normality ofX and Y, based on (8.64), we have
+oo
y 
e —(W)2/2aw dx
2 n
J —&z: M — oo aW
x------ e—(y—^M)2/2aM dy
"■:\ 2 n
t \ 
[+° [y e—(x—70)2/8—(У—68)2/(18/4) dxdy.
2(3/2)2nJ .. —° 
У
However, by Theorem 8.5.3, we have
P{Y>X} = P{Y - X>0} = P{U > 0},
where U = Y - X has normal distribution with mean ^U = ^W - ^M = 68 - 70 = 
-2 and variance aU2 = aW2 + aM2 = (3/2)2 +22 = 25/4, hence, aU =2.5 inches (we 
use here Theorem 8.5.3 with a = -1,в=1). Consequently, since U is normally dis­
tributed,
P{Y>X}=P Z> 0 - (-2) I
2.5 
/ = P{Z > 0.8}
= 1 - Ф(0.8) = 1 - 0.7881 = 0.2119.

250
SELECTED FAMILIES OF DISTRIBUTIONS
Before we discuss the multivariate normal distribution, we will introduce two distributions 
that are related to normal: lognormal and folded normal distributions.
Definition 8.5.1 Random variable X is said to have a lognormal distribution if the variable 
Y = log X has a normal distribution. The density of a random variable X is then
f (x,P,a 2) =
1 
exp f [log(x) - »]2
/2nax P I 
2a?
where N(^, a2) is the distribution of Y.
□
The mean and the variance of the lognormal distribution are
E(X) = e^+a2 / 2 and V (X) = e2M+'2 x (ea 2 - 1),
and the general formula for mk , the kth ordinary moment, which we give without proof, is 
mk = exp | k^ +---- -— | .
The lognormal distribution has one very unique property: Even though it has finite moments 
of all orders, the moment generating function is infinite at any positive number.
The lognormal distribution is widely applicable in modeling, for example, where there is a 
multiplicative effect of several small independent factors. A typical example is the long-term 
return rate on a stock investment that can be considered as the product of the daily return 
rates.
In many experiments, measurements such as dimensions (as well as time and angles) 
are often recorded with respect to certain expected standards, where the magnitude of the 
difference, not the direction, is important. Consequently, the actual distribution of the mea­
surement, X , is replaced by a distribution of absolute measurements, Y = |X |. When the 
underlying distribution is normal, the resulting distribution is called the folded normal, or 
half-normal.
Any normal distribution N(p, a2) can be “folded” at zero, but we will discuss here only 
the simplest case with ^ = 0. So for X ~ N(0, a2), the density ofY = |X| is
f (y;a )^ix a e-y 2 / 2 ° 2
for y>0, and 0 otherwise. We will now find the expected value E(Y) and the variance 
Var(Y). Notice that a2 is no longer a variance of the distribution.
E(Y)= f + m /2 x -e-y2/(2'2) dy = a</2 f e-t dt = a</2,
Jo 
V n a 
nJ о 
n
where we used substitution t = y2/2a2. For Var(Y) we need
E(Y2) = [+' y\/2 x -e—У2/(2^2) dy = 1 [+“ x\/2 x -e-x2/(2^2) dy
о V n a 
2 J-^ V n a
^=-e--x2/(2a2) dy = e(x2) = a2, 
22 na 
since X ^ N(0, a2). Finally, we obtain
Var(Y) = a2 - fa2^ = a21 - 2^ . 
П J П 
nJ 

NORMAL DISTRIBUTION
251
Derivation of the moment generating function will be left to the reader as an exercise.
Let us now consider the multivariate normal distribution. We will start from the case of 
two dimensions. Some situations with more than two dimensions will be considered in later 
chapters.
Definition 8.5.2 The pair (X, Y ) of random variables is said to have a bivariate normal dis­
tribution, N(p 1, p2, a2 ,a2 ,p), if the joint density is of the form
f(x, y)=
1 
1 .
----------1 
e ' 1
2 na 1 a 2yj1 — p P2
(x-^ i)2
■:
2
(V-P 2)
2
(8.65)
where —ж < p 1 < ж, —те < p2 < + ж, a 1 > 0, a2 > 0, and |p| < 1.
To find marginal distributions ofX and Y and determine the interpretation of parameters, 
let us change the variables into
X — p 1 
v = Y — p 2
a 1 
, 
a 2
This amounts to substitution
x = a1u + p1, 
y= a2v + p2
with the Jacobian J = a1a2. Consequently, the joint density of (U, V) is
g (u v) = 2 n ./T—p “4 — 2(1——1 u 2 — 2 Puv + v 2]
Since u2 — 2puv + v2 =(u — pv)2 +(1— p2 ) v2, we write
g(u, v)=
{
/ 
X 2
1 u — pv
—4 V1—p2 J
where
1 
/•+TO 
J W u — pv
v2n^T—p2J-„ exp j— 2 (yr—p2
du = 1
for every v. Hence, the second factor is the marginal density ofV, while the first factor is the 
conditional density of U given V = v. Thus, V is standard normal, while U | V ^ N(pV, 1 — 
p2). By symmetry, U must also be standard normal and V\U ^N(pU, 1 — p2). Therefore, we 
have proved
Theorem 8.5.4 If (X, Y) have bivariate normal distribution given by (8.65), then both X andY 
have normal distributions, N( p1 ,a12 ) and N( p2, a22 ), respectively. Moreover, the conditional 
distributions are also normal:
X|Y ^ N (p—(Y — p2) + p 1 ,a2(1 — p2) 
a2
(8.66)
and
Y|X ^ N (p—(X — p 1) + p2,a2(1 — p2) 
a1
(8.67)
-2p x-^1 x y-^2 +
CT 
v 1 
ст 2
□

252
SELECTED FAMILIES OF DISTRIBUTIONS
Proof : Only the last two statements require some proof. The normality of the conditional 
distribution is obvious in view of the normality of conditional distributions of U given V . 
We have
E(X Y) = E(a 1U + M1 к2V + M2) = a 1E(U|a2V + M2) + M1
______ 
Y - Un
= a 1 E (U |V) + m 1 = a 1 pV + m 1 = a 1 p------- 2 + m 1 •
к2
Similarly,
Var( X |Y) = Var( a 1 U + m 1 |a 2 V + M 2) = a2Var( U |V) = a2(1 — p 2),
which proves (8.66). The proof of (8.67) is analogous.
□
Theorem 8.5.5 If X, Y have the bivariate normal distribution (8.65), then p is the coefficient 
of the correlation between X and Y.
Proof: Clearly, pX,Y = Cov(U, V) = E(UV), and we may write
E(UV) =
uv g(u, v) du dv
—U U uv exp { — 
[u2 — 2Puv + v2^ du dv
u — pv
du
dv
ve v /2pv dv = p __
2П n
1
2
1- — pp
u exp
= p^
1
V2n ^1 — p p2
□
■ EXAMPLE 8.17
Assume, as in Example 8.16, that the height of men X and the height of women Y in a 
population have N(70, 4) and N(68, 2• 25) distributions, respectively. Assume also that 
the heights of siblings are correlated with p = 0.6. If we sample a brother and a sister, 
what is the probability that the sister is taller than her brother?
SOLUTION. Proceeding as in Example 8.16, P{Y>X} = P{Y — X>0},andwe 
know that Y — X is normal, with E(Y — X) = E(Y) — E(X)=68— 70 = —2 inches. 
For the variance, we have
Var(Y —X)=Var(Y) — 2Cov(X, Y) + Var(X) = aY2 — 2paXaY +aX2 
= (1 • 5)2 — 2 x 0• 6 x 2 x 1 • 5 + 22 = 2• 65•
Consequently,
P{Y>X}=P Z
0—(—2)
> —=1 — Ф(1 • 23) = 0• 1093• 
2рш>

NORMAL DISTRIBUTION
253
To develop the intuition concerning the bivariate normal distribution and correlation 
coefficient, let us consider some possible schemes that lead to the appearance of bivariate 
normal distribution with correlated variables.
■ EXAMPLE 8.18 Sequential Formation
It is possible that one of the values, X , is formed at random, following the normal 
distribution N(^ 1, ст2). This means that some random process leads to the creation of 
an element of the population with a specific value x of an attribute X . Subsequently, 
the value of attribute Y is formed by some other random process that generates Y 
according to the normal distribution with mean p(ст2/ст 1)(x - p 1) + p2 and standard 
deviation ст2у/ 1 - p2.
Examples of such “sequential” generation of attributes are quite common: We could think 
here ofX and Y being the temperatures at noon ata specific place today and tomorrow, water 
levels on the same river at two specific times, or in two places, one downstream from another, 
the height ofa father and a son, and so on. In a sense, we have a “natural” ordering, with X 
being the first variable, whose value affects the second variable Y .
To enable a clear geometrical representation, let ст 1 = ст2 = 1 and let p 1, p2 be sufficiently 
far from the origin, to have clear plots of marginals, say p 1 = p2 = 5 (see Figure 8.6).
The conditional expectation of Y , given X (the regression of Y on X , discussed in detail 
in Chapter 14), is now, by formula (8.67),
E(Y|X)=p(X-5)+5,
which is the line y = px + 5(1 - p) with slope p, passing through the point (p 1 ,p2) = (5, 5). 
Observe that regression ofX on Y is the line E(X|Y )=p(Y - 5) + 5; that is, y = (1p)x - 
5[(1 - p)/p], which also passes through the point (5, 5) but has the slope 1/p.
After the value of X = x is sampled, the value of Y is sampled from the normal distri­
bution centered at the appropriate point on the regression line, and having variance 1 - p2 . 
Remembering that the total variance of Y is 1, we have the decomposition of Var(Y ) into 
a sum of the form p2 +(1- p2), the second term being the variance of the deviation Y - 
[pX - 5(1 - p)] ofY from the regression line. The first term, p2, is therefore the contribution 
to the variability of Y coming from the variability of X . In generally accepted terminology, 
100p2 is the “percentage of variance of Y explained by the variability of X.”

254
SELECTED FAMILIES OF DISTRIBUTIONS
A glance at Figure 8.6 reveals that if p were larger, the line would be more steep, and 
this would increase the contribution of X to the variability of Y . (Remember that X and Y 
are standardized, so their variances remain equal to 1. This explains why the regression line 
E(Y |X)—in the case of standardized variables—cannot be steeper than the diagonal. So, 
when p increases, to keep Var(Y )=1, one has to decrease the variance of deviations from 
the regression line.)
■ EXAMPLE 8.19
Another interpretation of the correlation coefficient p is related to the following situa­
tion: Suppose that we have a population of objects of some kind and that an attribute 
£ of objects in this population has a normal distribution N(p,a2). Elements of this 
population are sampled and their attribute £ is measured twice. The measurements are 
subject to error, and the errors e 1 and e2 of the two measurements are independent of £ 
and from one another, with the same normal distribution e 1 ~ N(0, af), e2 ~ N(0, af). 
The observed results of measurement are X = £ + e 1 ,Y = £ + e 2. In this case X and Y 
are normal with the same means and variances p 1 = p2 = p, a“
2 = a2 = a2 + al• The 
covariance between X and Y equals E(XY) - p2 = E(£ + e 1)(£ + e2) - p2 = a2, in 
view of the assumed independence and E (ei) = 0, we have
_ Cov(X,Y) _ 
022
p~ 
Va2a22 ~ a2+0'
Herep>0, which means that the results of measurements of the same (random) quan­
tity, subject to independent errors, are always positively correlated.
It should be pointed out here that—as opposed to Example 8.18—p (not p2) rep­
resents the fraction of variance ofX (or Y) “explained” by the variability of £. The 
situation is different from that in Example 8.18, since now we “explain” the variance 
of one variable (X), not through the variability of the second variable of the pair (Y), 
but through the variability of some other variable (£) that affects both X and Y.
PROBLEMS
In all problems of this section, Z stands for a standard normal variable, and Ф is its cdf.
8.5.1 Use the tables of normal distribution or any statistical software to deter­
mine the probabilities: (i) P(0 < Z < 1.34). (ii) P(0.14 < Z < 2.01). (iii) 
P(-0.21 < Z < -0.04). (iv) P(-0.87 < Z < 1.14). (v) P(\Z| > 1.02). (vi) 
P(Z > 1.11).
8.5.2 Determine x in the following cases: (i) Ф(x) = 0.62. (ii) Ф(x) = 0.45. (iii) P(\Z| < x) 
= 0.98. (iv) P(1.4 < Z < x)=0.12.
8.5.3 Find P (|X - 21 < 0.5) if X ~ N(1, 4).
8.5.4 Let random variable X have a N(p, a2) distribution. Find: (i) p if a2 = 2 and P(X < 
12) = 0.72. (ii) a2 if p = 2 and P(X >5) = 0.39.
8.5.5 A “100-year water,” or flood, is the water level that is exceeded once in a 100 years 
(on average). Suppose that the threatening water levels occur once a year and have 
a normal distribution. Suppose also that at some location the 100-year water means 
the level of 30 feet above average. What is the 10,000-year water level?
8.5.6 Find y3—the skewness of a lognormal distribution with parameters p and a2.

BETA DISTRIBUTION
255
8.5.7 Assume that X1 and X2 are independent, with N(3, 6) and N(-1, 2) distributions, 
respectively. Find: (i) P(3X 1 - 2X2 > 14). (ii) P(X 1 <X2).
8.5.8 Assume that variables X1, X2, X3 are independent and each has N(2, 1) distribution. 
Moreover let Y1, Y2, Y2, also be independent and each have N(2, 3) distribution. Find 
P(3X1+2X2+X3 >Y1+2Y2+Y3).
8.5.9 Assume that variables X1 and X2 have a bivariate normal distribution with 
E(X 1) = 3, E(X2) = 2, Var(X 1) = 4, Var(X2) = 1 and p = — 0.6.
Find: (i) P{X 1 < 4|X2 = 3}. (ii) P{|X2 - 1| > 1.5|X 1 = 2}.
8.5.10 Let variables X and Y be the weight and height of newborn children in the United 
States. The joint distribution of X and Y is bivariate normal with pX = 20,aX = 1.5 
inches, pY = 7.7, ay = 2 pounds, and p = 0.8. Find: (i) The expected weight of a 
newborn child with a height 21 inches. (ii) The expected height of a child whose weight 
is 6 pounds.
8.6 BETA DISTRIBUTION
The family of beta distributions defined below is known for its usefulness in modeling 
researchers’ uncertainty about the unknown probability p of some event.
Definition 8.6.1 A random variable X has beta distribution with parameters a > 0 and в > 
0, X ~ BETA(a, в), if the density of X equals
f (x) = Г(a+в) x 1(1 - x)в- 1 
(8.68)
r(a)г(в)
for 0 < x < 1 and f (x) = 0 otherwise. Here Г is the function defined by (8.46). 
□
First, we will check that (8.68) is indeed a density:
Г(a)Г(в)=(/" ua- 1 e-u du]([ ve- 1 e-v dv
00
/»ОО /»OO
= / I ua- 1 ve- 1 e-(u+v) dudv.
00
(8.69)
Introducing
u
z = u + v and x = ———,
we have 0 < x < 1, 0 < z < ж. Since u = xz and v = z (1 — x), the Jacobian equals z. Con­
sequently, after substitution to (8.69), the variables separate, and we obtain
Г(a)Г(в)= [ za- 1 ze- 1 e-zz dz [ xa- 1 (1 — x)в- 1 dx
00
= Г(a + в) I xa- 1(1 — x)в- 1 dx,
0 
as was to be shown.
Once we know that
x xa 1(1 — x)e 1 dx =
0
Г(a)Г(в) 
Г( a + в)

256
SELECTED FAMILIES OF DISTRIBUTIONS
we can easily compute the moments of the beta distribution. If X ~ BETA (а, в), then
E(Xk) = г/а + в / 1 x+a- 1(1 - x)в-1 dx 
Г( а )Г( в) о
_ Г(а + в) Г(k + а)Г(в) _ Г(а + в)Г(k + а)
= Г(а)Г(в) Х Г(k + а + в) = Г(а)Г(k + + + в)'
In particular, using formula (8.47), for k =1and k =2, we obtain
E (X) 
", and E (X 2) = ----------“(+ + 1!-----\,
а + в 
(а + в)(а + в + 1)
so that
Var(X) = 7------ 1Ч- 
(8.70)
к ( 
(а + в )2( а + в +1)
The various shapes of the beta distribution are illustrated in Figure 8.7. If а > 1, в > 1, the 
distribution is bell-shaped, with the peak becoming more narrow for larger а and/or в. For 
а = в =1, the distribution is uniform. If < < 1 and в < 1, the distribution is U-shaped, 
whereas if < < 1, в > 1 or а > 1, в < 1, the distribution is J-shaped.
и
---------------h»
a=в=1 
1
a <1 в <1 1
Figure 8.7 Shapes of beta distributions.
As mentioned, the most typical application of a beta distribution is when we consider a 
binomial distribution with an unknown p, and represent knowledge (or uncertainty) about 
p by assuming that p is random with a beta distribution.
■ EXAMPLE 8.20
In some Bernoulli trials p is random with distribution BETA(c^, в). We know that there 
were so far 3 successes in 4 trials. What is the probability of 2 successes in the next 3 
trials?

BETA DISTRIBUTION
257
The combined data and event in question is “3 successes in4 trials and 2 successes in 
the next 3 trials” (which is not the same as 5 successes in 7 trials. Why?). Conditioning 
on p, we obtain the probability
4
3 p3(1 - p)
3
2
p2 (1 - p) = 12p5 (1 - p)2.
Taking expectation with respect to p ~ BETA(а, в), we have, for the expected proba­
bility E(2, 3) of2 successes in 3 trials
E(2, 3) = Г(а +в) /1 12P5(1 - P)2P 1(1 - P)в- 1 dp 
г(а)г(в) о
= 12 x Г(а + в) x Г(5 + а)Г(2 + в)
Г( а )Г( в) 
Г(7 + а + в) '
Using formula (8.47), which asserts that Г(t) = (t — 1)Г(t — 1), we obtain, after some 
algebra,
E(2, 3) = 12 x, а(а +1) 
(а + 4)в(в +1) > •
(а + в)(а + в +1) • • • (а + в + 6)
■ EXAMPLE 8.21
To make the situation still more realistic, consider a client who comes to a statistical 
consulting center for help. It turns out that she is currently negotiating the purchase of 
a large shipment of some merchandise. Some of the items conform to the specification, 
and some do not (let us call them defective). Suppose that testing the quality of all 
items in the lot is not possible because of the prohibitive cost of such an operation, or 
because the process of testing is destructive. Some tests have been made, though, and 
the data are such that among 25 tested items 3 were found to be defective. What can 
one reasonably say about the fraction of defective items in the whole lot?
SOLUTION. Suppose that the lot in question is not the first lot purchased by the 
client. It turns out that she has been buying the same kinds of merchandise from the 
same company (or from other companies). In her experience, as judged by tests, data on 
returns, customer complaints, and so on, she estimates that on average, the percentages 
of items below specification (defectives) in various lots purchased were about 12%, with 
variability of about 2% in either direction.
The problem of the client at the statistical consulting center can be formulated as 
follows: First, we determine the chances that the fraction p of defective items in the lot 
whose purchase is presently being negotiated is below 10%. Then we evaluate P{p< 
0 • 1} in light of the tests of the lot under consideration (3 out of 25 below specification), 
using the experience accumulated in the past. If we accept the assumption that the 
fractions in various lots follow a beta distribution, we have for the mean
а
------ = 0 • 12 • 
а+в
Next, the relatively small variability (±2%) suggests that we have а>1 and в>1. 
Consequently, the density of beta distribution is bell-shaped. Using the three-sigma 
rule, we take 3a « 0• 02, and using (8.70), we obtain another equation for а and в:
ав 
_ / 0 • 02 V
(а + в)2(а + в + 1) 
\ 3 /
The solution of (8.71) and (8.72) is а* = 285, в* = 2,090.
(8.71)
(8.72)

258
SELECTED FAMILIES OF DISTRIBUTIONS
We have assumed here that the fraction p of defective items is a random variable 
whose distribution is BETA(а* ,в*). If no testing of the currently negotiated lot was 
made, the answer would be
pSv < 0 1} = Г(а + в ) [ 
xa*- 1(1 - x)e*-1 dx
Pip< 0.1} г(а* )г(в* )J0 
x (1 x) dx.
However, we have additional information, namely that event A = “three defective 
in a sample of 25” occurred. Consequently, we should integrate the conditional density 
of p given A. We have
P(AlP) = (235 ) P3(1 - P)22.
The conditional density is obtained from Bayes’ formula, with the summation 
replaced by integration. Schematically
^p(xlA) ^rP(An^rh~, 
(8.73)
p 
J P(A\u) pp (u) du
where pp(x) and pp(x\A) are the unconditional and conditional densities of p at x.
Typical reasoning is that the denominator in (8.73) is independent of x, and both 
sides represent densities in x. Collecting the terms that depend on x, and representing 
all other factors as a constant, the right-hand side of (8.73) is of the form
Cx3(1 — x)22xa - 1(1 — x)e -1, 
(8.74)
so it is a beta density with parameters а* +3 and в* + 22. This gives
Г( а* + в * +25) 
= Г(а* +З)Г(в* + 22),
and we get the answer to the original question by integrating (8.74) between 0 and 0.1.
Observe that the analysis above has some interesting consequences. We know that if the 
distribution of p is BETA(а, в) and we observe k successes in n trials (event A), then the 
conditional distribution of p given A is BETA(а + k, в + n — k)—the family of beta dis­
tributions that constitutes the conjugate priors for binomial data. We will return to those 
problems in Chapter 16.
PROBLEMS
8.6.1 Let X have a distribution BETA(а, в). Find: (i) the distribution of Y = 1 — X. (ii) 
ESXk(1 — X)m}.
8.6.2 Students are late to a particular class with probability that has BETA(2, 20) distribu­
tion. Find the probability that in a class of 25 students no more than 2 students will 
be late on a given day.
8.6.3 Let X have a symmetric beta distribution. Find а and в if the coefficient of variation 
(ratio of standard deviation and the mean) is k. Does a solution exist for any k?
8.6.4 Let X1 ,X2 , ... be iid with an exponential distribution. For any positive m and n find 
the distribution of the ratio
T = X 1 + 
+ Xm
mn 
X1 + ••• + Xm+n .

CHAPTER 9
RANDOM SAMPLES
9.1 STATISTICS AND SAMPLING DISTRIBUTIONS
In the previous chapters, we referred to independent random variables X1 , ...,Xn having 
the same distribution, as iid (independent, identically distributed) variables. In statistics, we 
say that such variables constitute a random sample, since they can be thought of as obser­
vations (measurements) independently selected from the same population, or resulting from 
analogous statistical experiments. A random sample provides an important link between the 
observed data and the distribution in the population from which it has been selected. Most 
techniques of statistical inference that will be discussed in later chapters will be based on 
certain functions of random samples. Such functions are called statistics if they depend on 
observations X1 , ...,Xn, but not on parameter(s) of the distribution. We will discuss the 
properties of the distributions of statistics (called sampling distributions).
Before we start, it should be mentioned that there are several important issues related to 
the properties of a selection process so that it does yield a random sample. There are also 
other, and sometimes more appropriate, sampling schemes besides the random sample. That 
will be discussed in more detail in Chapter 10.
Among various statistics meaningful for the purpose of statistical inference is a sample
mean
X = X1 +-----+ Xn
n
an arithmetic average of all measurements, or equivalently their sum
Tn = X1 + 
+ Xn.
Among other important statistic is sample variance
1 n 
_
S2 = — 
Xi - X)2’ 
(9.1)
i=1
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
259

260
RANDOM SAMPLES
sample standard deviation S = \fS2, min( X 1, ...,Xn) and max( X 1, ..., Xn)—the small­
est and the largest values in the data, respectively.
The following example illustrates an interesting distributional property:
■ EXAMPLE 9.1
We will determine the distribution of Tn = X 1 + • • • + Xn and of X = (1 /n) Tn in a 
random sample X 1, ..., Xn selected from an EXP( A) distribution.
SOLUTION. Based on Theorems 7.5.4 and 7.5.5, the moment generating function 
(mgf) for the sample mean X is
t
mx (t) = mTl n
mX
At
n
-n
(9.2)
1
From Theorem 7.5.6, it is clear that distributions of Tn and X are GAM(n, A) and 
GAM(n, A/n), respectively.
A similar property for the family of normal distributions will be shown in Section 9.2.
Regardless of the distribution in the sample, one can obtain expectations of some sam­
pling distributions as functions of the moments of original distributions as given in the 
following theorem:
Theorem 9.1.1 Let X 1, ..., Xn be a random sample from a distribution with E (Xi) = /л and 
Var(Xi) = a2. Then
E (X) = p,, Var( X) = —, 
(9.3)
n
and similarly
E (X 1 + ••• + Xn ) = np, 
Var( X 1 + ••• + Xn ) = na2. 
(9.4)
Moreover, E(S2 )=a2.
Proof: Formulas (9.3) and (9.4) can be found in Sections 7.4 and 7.7. The proof that 
E(S2) = a2 is very simple. Since E(W2) = Var(W) + [E(W)]2 for any random variable 
W, and £ (Xi - X)2 = £ Xi2 - n(X)2, we have
E (EXi2) - nE(X)2 = n[E(Xi2) - E(X)2]
= n [ a 2 + p,2 — (a 2/n + p,2)] = (n — 1) a2.
PROBLEMS
9.1.1 Statistic Gk, defined for k =1, 2 as
Gk =
1
n(n -
1) t tx< — Xjlk, 
i=1j=1
was proposed as a measure of variation by Jordan (1869). Show that G2 = 2S2, where 
S2 is given by formula (9.1).

DISTRIBUTIONS RELATED TO NORMAL
261
9.1.2 Let X 1, ...,Xn and Y1, ... ,Ym be two random samples from distributions with 
means p 1 and p2, respectively, and the same variance a2. (i) Find E(X - Y) and 
Var(X - Y). (ii) Assuming that p 1 = p2 and both samples are of equal size, find 
n = m such that P(|X — Y| > a/4) < 0.05.
9.1.3 Let X 1 ,X2,X3 be sample means in three independent samples of sizes n 1 ,n2,n3, 
respectively. Each sample _was o_b_tained from the N(p_a2) distribution._Find the 
distribution of V1 = (1 /3)(X 1 + X2 + X3) and V2 = w 1 X 1 + w2X2 + w3X3, where 
wi = ni/(n1 + n2 + n3).
9.1.4 Let X1_X2 be a random sample from the BIN(1_ p) distribution. Obtain the probabil­
ity that the sample mean does not exceed the sample variance.
9.2 DISTRIBUTIONS RELATED TO NORMAL
The distributions that will be introduced in this section are of special importance in statis­
tical inference. Their applications as sampling distributions of statistics obtained in random 
samples selected from the normal distribution will be discussed in later chapters. We start 
from the following theorem:
Theorem 9.2.1 Let X 1, ..., Xn be a random sample from the normal distribution N(p, a2). 
Then
X = 
1 + "n + n 
(9.5)
and 
n
U = n—1S2 — ^ £ (Xi — X)2 
(9.6)
a2 
a2 i=1
are independent random variables with distributions N( p, a2/n ) and xП- 1, respectively.
Proof: There exist several ways of proving this theorem. We will use a multidimensional 
version of the method of finding the density of a function of random variables.
Let us observe that
nn 
n
(x— xi — P )2 22 Xi - x + x - P )2 22xi - x )2 + n(x - P )2,
i=1 
i=1 
i=1
since 2 J2 П=1( xi — x)(x — p ) = 2( x — p ) ^2 П=1( xi — x) = 0. Consequently, the joint density
of (X1_..._Xn) can be written as
f (x 1, ...,xn )= an (2 n) n/ 2 exp — 202 
(xi — p) 
(9.7)
i=1
1 
1n 
n
= —;—ex exp------x 
(x — x)2-------((x — p)2
an (2n)n/2 
p 
2a2^ (i ) 
2a2 ( 
P)
i=1
- 
1 exU u lexn/ n (г /Л2\
expe exp(x p) 
.
an(2n)n/2 pl 2apl 2aP )
Using transformation
xj — x + Vj\/u_ 
j — 1, 2, ... ,n,
(9.8)

262
RANDOM SAMPLES
we obtain
vLvj = 0, 
j=1
nE j
j=1
= n,
(9.9)
which means that two of the Vj s are functions of the remaining ones. We therefore solve
(9.9) for vn 1 and vn, obtaining two solutions
A—B
vn-1 
2
or
A + B
v1 
2
where
n-2
A = — E vk, 
B = I2n—
k=1 
\
vn =
A + B
2 ,
vn =
A — B
2 ’
n-2
2 E v2 
k=1
— E E vkvj Y /2. 
k=1 l=1 
)
(9.10)
n
Thus, to each vector (v 1, ..., vn-2 ,x, u) with u > 0, there are two corresponding systems 
(x 1, . . . , xn):
x j = x + v^/U,,
j = 1, ...,n - 2
(9.11)
xn-1 = x + A - B Vй, 
xn = x + A ++ B Vй-
and
xj = x + vp/u, 
j = 1, ... ,n — 2 
(9.12)
_ A + B 
_ A — B r-
xn_ 1 = x +-------- --— Vu, 
xn = x +--------- --— uu.
n 1 
2 
n 
2
The Jacobian of transformation (9.11) is
J =
dx 1
dU 
...
dx 1
n 
...
du
dx 1
dv^ 
...
. . . 
. . .
dx 1
dxn 
dx
dxn
du
dxn 
dv 1
...
dxn 
dvn-2
. . .
1
1
1
dvn-2
1
. . .
1
v 1
v 2
vn-2
A — B 
1
A + 
1
=
Vu
Цй
. . .
0
2 Vu
0
. . .
0
... 2 vu
... 
0
. . . 
. . .
... 
Цй
2 
" 2 vu
vu / dA dB \ 
2 l^dv 1 dv 1)
vu f dA 
dB \
2 \dvn-2 dvn-2 J
2 
" 2 vu
Vu / dA dB \
2 l^dv E" dv 1)
yu / dA 
dB \
2 ldvn-2 1 dvn-2)

DISTRIBUTIONS RELATED TO NORMAL
263
Since for transformation (9.12) the Jacobian is the same, but with the last two columns inter­
changed, the absolute value of the Jacobian for transformation (9.12) is the same as for 
transformation (9.11). We have here
|J|=u(n-3)/2h(v1,...,vn-2),
(9.13)
where h is some function whose exact form is not needed for our purposes.
Substitution ofnew variables into (9.7), and multiplication by (9.13) gives the same joint 
density of vector (X, U,V1, ..., Vn-2) for transformations (9.11) and (9.11), namely
g (x,u,v!, ...,Vn—2) = -—-L— u (n-3) / 2 e-u/2 ' 2 e-(n/2 a 2)( - )2 h (v 1, ...,vn-2). (9.14) 
(ay 2 n)n
Since the density (9.14) can be written as the product of densities
c 1 u(n-1)/2-1 e-u2ff2 x c2e-(n/2'2)(x-^)2 x c3h(v 1, ...Л-2),
it is now clear that the random variables U, X, and (V1, ..,, Vn-2) are independent. An 
inspection of terms involving x and u shows that after we adjust the constants, X has a 
N(y, a2/n) distribution and U/o2 has a chi-square distribution with n — 1 degrees of free­
dom. 
□
The most remarkable fact here is that X and U are independent, even though X appears 
explicitly in the definition ofU. This independence is characteristic for a normal distribution. 
We have the following theorem, which we leave without a proof:
Theorem 9.2.2 If in a random sample X 1, ..., Xn variables X and U are independent, then 
the distribution of Xi, i =1, ...,n, is normal.
We will now introduce the following definition:
Definition 9.2.1 Let Z be a standard normal random variable, and let U be a chi-square 
distributed random variable independent of Z, with v degrees of freedom. Then the random
variable
Z
X = ^^ 
(9.15)
U/v
is said to have Student’s t distribution with v degrees of freedom.
□
The density of X will be derived following the steps outlined in Chapter 6. Starting from 
the joint density of Z and U, we add a “companion” variable Y to X, find the Jacobian of 
the transformation (z, u) ^ (x, y), and finally, find the density of X as the marginal in the 
joint density of X and Y .
By the assumption of independence, the joint density of Z and U is
f (z, u) = -1= e-z2/2 x-1/2Г(v/2)uv/2-1 e-u/2, 
u> 0.
У 2 n 
2 v/ 2
(9.16)
Selecting Y = U as a companion variable to X, we have z = x^fy/m and u = y. The Jaco­
bian equals J = д/y/m; hence the joint density of X and Y is
V (x,y) = Qy(v- 1) / 2 e-(1 / 2)(1+x 2/v)y,
(9.17)

264
RANDOM SAMPLES
where
Q=
1
/nV 2(m+1)/2Г(v/2)
(9.18)
(9.19)
The density (9.17), except for a constant, is a gamma density with parameters (m + 1)/2 and 
(1/2)(1 + x2/m). Thus, the marginal density of X is obtained by integration as
fv(x) = [~ Qy(v- 1)/2e-(1 /2)(1+x2/v)уdy 
0
■ 
QГ((V +1)/2) 
= Г((V + 1)/2) x (1+ x2/v)-(V+1)/2
[(1 /2)(1+ x2/v)](v +1)/2 
/nv Г(v/2) 
( + / ) 
.
It is evident that the density (9.19) of the tv distribution is symmetric around x =0. When 
v = 1, we have у (x) = K (1 + x2) -1, which is the density of the Cauchy distribution (see 
Example 7.11). Observe that for v =1, the Student’s t distribution has no mean (hence no 
higher moments either). For v > 1 and k < v, the kth ordinary moment of tv can be obtained 
as (see Problem 9.2.6):
E(X k) = E(Zk)(V } k/2Г V- 2 J , 
2 ' 
2 
' \2 
г V^}
Ч2/ 
Г \i)
where Z hasN(0, 1) distribution. Consequently, we have E(X) = 0 and Var(X) = v/(v — 2)
for variable X with tv distribution (v > 2).
When the number of degrees of freedom, v, increases, tv distribution approaches the stan­
dard normal distribution.
(9.20)
Theorem 9.2.3 Student’s tv distribution approaches the standard normal distribution N(0, 1) 
when the number of degrees offreedom v increases.
Proof: The density of a t distribution with v degrees of freedom is proportional to the prod-
uct
v -1/2
-1/2
x
When v — ^, the first term converges to (ex2)-1 /2 = e-x2/2, while the second term con­
verges to 1. To preserve the integrability to 1, the constants must converge to 1Д/2П, and 
the limiting density is standard normal. 
□
Let X 1, ..., Xn be a random sample from N(y, a2) distribution. By Theorem 9.2.1, X 
and EП=1 (Xi — X)2 are independent, with /n(X — y)/a and E”=t (Xi — X)2/a2 having 
standard normal and chi-square distribution with n — 1 degrees of freedom, respectively. 
Consequently, the ratio
(X — y) / (a//n) 
= /n (X — y)= X — y
~ 
1^ 
~ 
S/ \fn
J E (Xi — X)2/(n — 1)a2 
J £ (Xi — X)2/(n — 1)
i=1 
i=1
(9.21)
has a Student’s t distribution with n — 1 degrees of freedom. As we will see in Chapters 11 
and 12, the random variable (9.21) plays an important role in building schemes for inference 
on y,.
The upper quantile ta,v is defined by the relation P{X > ta v} = a, with X having 
the Student’s t distribution with v degrees of freedom (so that the upper a-quantile is a 
(1 — a)-quantile).

DISTRIBUTIONS RELATED TO NORMAL
265
The following definition introduces yet another distribution important in statistical infer­
ence:
Definition 9.2.2 If U and V are independent random variables with distributions х,г and 
X,2, respectively, then the random variable
X = U/V1, 
(9.22)
V/v 2
denoted Fv 1 v2, has Snedecor’s Fdistribution with v 1 and v2 degrees of freedom. 
□
Let us derive the density of the random variable X. The joint density ofU and V, in view 
of their independence, is
A(u v) = ^ГшuV 1 /2-1 e-u/2 X 2|'vV2/2-1 -2 
(9-23'
for u > 0, v > 0. With Y = V as a companion variable, the inverse transformation (x, y) ^ 
(u, v)isu = (v1/v2)xy, and v = y so that the Jacobian equals J = (v1/v2)y. Thus, after 
substitution to (9.23), the joint density ofX and Y is
v v i / 2
■f(х,У) = ,/2 ( + )/1 
—----------——x* 1 /2-1У(V 1 + V2)/2-1 e-(1 /2)[V 1 x/V2+1]y.
The marginal density of X equals, again using the fact that we can separate a gamma-type 
integral for y,
t™ 
I? 1 2 2 xv 1 / 2 -1
A, 1,2 (x) = [0 *(x y)dy = vv 1 / 22( v 1+V 2) / 2Г( v 1 / 2)Г( v2 / 2)
x У y ( v 1+ v 2) / 2 - 1 e-(1 / 2)[ v 1 x/v 2 + 1] y dy
0
_ 
v, 1 / 2 xv 1 / 2 - 1Г(( v 1 + v 2) / 2)2(v 1 + v 2) / 2
v, 1 / 22(v 1+ v 2) / 2Г( v 1 / 2)Г( v2 / 2)[ v 1 x/v2 + 1]( v 1 + v 2) / 2
= Г((v 1 + v2)/2)v, 1 /2v,2/2 ^ 
xv 1 /2-1
Г(v 1 /2)Г(v2/2) 
(v 1 x + v2)(v 1+v2)/2 2
PROBLEMS
9.2.1 Let X ^ tv. Show that X2 has F1 ,v distribution.
9.2.2 Show that if xa is the a-quantile of a random variable X with an Fv 1 ,v2 distribution, 
then 1 /xa is the (1 - a)-quantile of a random variable with an Fv2,v 1 distribution.
9.2.3 Let X,Y,W be independent random variables such that X ~ N(0, 1), Y ~ N(1, 1), 
and W ~ N(2, 4), respectively. Find k such that
P
X2+(Y-1)2
X2+(Y-1)2+(W-2)2/4 >k = 0.05.

266
RANDOM SAMPLES
9.2.4 Let X 1 — GAM(1, X), X2 — GAM(2, X), X3 — GAM(3, X) be independent random 
variables. Find constant a such that variable Y = aX1 /(X2 + X3) has an F distribu­
tion.
9.2.5 Show that variable aX/(1 + aX), where X — F(v 1 ,v2) and a = v 1 /v2, has a 
BETA(v 1 /2, v2 /2) distribution.
9.2.6 Derive formula (9.20). [Hint: Use formula (8.52) for the kth moment of a GAM(a, X) 
distribution and the fact that variables X and U in (9.15) are independent.]
9.2.7 Derive the formula for E(Xk), where X - F(v1, v2). (Hint: Use similar approach as 
in Problem 9.2.6).
9.3 ORDER STATISTICS
Let X1, X2, ...,Xn be a random sample from a continuous distribution with cdf F and 
density f. We will consider random variables X1:n, X2:n, ...,Xn:n,whereXi:n is the ith in 
magnitude among X1 ,X2 , ...,Xn . Thus
X 1:n < X2:n <■■■< Xn:n 
(9.24)
Since variables Xi’s are continuous, the probability of two observations being equal is zero, 
and therefore we can assume that all inequalities in (9.24) are strict.
Definition 9.3.1 The random variables (9.24) are called order statistics of the sample 
X 1, X 2, ..., Xn, and for k = 1, .. .,n, Xk: n will be referred to as the k th order statistic. □
In particular, the first order statistic, X1:n, is the minimum of the sample, while the nth 
order statistic, Xn:n , is the maximum. We will derive the joint distribution of all n order 
statistics, of two selected order statistics, and also the marginal distribution of any order 
statistic. We will start from the latter. Let Gk be the cdf of order statistic Xk:n. Then Xk:n < t 
ifat least k variables in the sample X1, X2, ...,Xn satisfy the inequality Xi < t. The number 
of observations in the sample that satisfy Xi < t has a binomial distribution with probability 
of success p = F (t)=P (Xi < t), and therefore
n
Gk(t) = P{Xk:n < t} = 
nr [F(t)]r[1 - F(t)]n-r. 
(9.25)
Two particular cases deserve attention here. If k =1, we obtain
G1(t) = P{X1:n <t}=1-P{X1 >t,...,Xn >t}=1- [1 - F(t)]n,
and if k = n, then
Gn(t) = P{Xn:n <t}=P{X1 <t,...,Xn < t} = [F(t)]n.
Differentiating with respect to t, we obtain densities
g1(t)=n[1-F(t)]n-1f(t)andgn(t)=n[F(t)]n-1f(t). 
(9.26)

ORDER STATISTICS
267
To find the density gk (t), we differentiate (9.25) obtaining
n
gk(t) = 
nr r[F(t)]r-1f(t)[1 - F(t)]n-r
r=k
- Е' (n ) [F(t)]r (n - r)[1 - F(t)]n-r-1 f (t) 
r=kn!
= E 7----- ■--------- m [F(t)]r- 1[1 — F(t)]n-r f (t)
(r - 1)!(n - r)! 
r=k
n 
n!
7----- 7w------ м [F(t)]r- 1[1 — F(t)]n-r f (t).
(r - 1)!(n - r)! 
r=k+1
All terms except one cancel in the last two sums.
Theorem 9. 3.1 The density of the k th order statistic is given by
gk (t) 
П---------F [ F (t)] k-1 [1 — F (t)] n-kf (t). 
(9.27)
(k - 1)!(n - k)!
To find distributions of more complex functions of order statistics, one should start from 
the joint distribution of all order statistics given in the following theorem:
Theorem 9. 3.2 The joint density of X1:n, X2:n, ...,Xn:n is given by
1 .....y.) = I nf(y 1y-f(yn) 
\11 <:'<yn 
(9.28)
0 
otherwise.
Instead of a formal proof let us use some heuristic argument here. A joint density in a 
random sample is g(x1,...,xn)=f(x1) f(xn). While observations X1,...,Xn can be 
arranged in n! ways, only one arrangement has observations ordered in ascending magnitude 
(Y1 <Y2 < <Yn ).
The next theorem gives the density of a joint distribution of any two order statistics.
Theorem 9. 3.3 Let X1 , . .. ,Xn be a random sample from a continuous distribution with den­
sity f and cdf F. For any k<land s<t, the joint distribution of Xk:n and Xl:n is given by 
the formula
n!
gkl(s,t) = (k — 1) !(l — k — 1) !(n - l)![F(s)]-1[F(t) — F(s)Г-1
x [1 — F (t )]n-‘f (s) f (t) 
(9.29)
and gk,l(s,t) = 0 otherwise.
Proof : The density (9.29) is obtained by direct integration of the joint density (9.28) with 
respect to all yi such that i < k, k < i < l, and i > l. 
□

268
RANDOM SAMPLES
■ EXAMPLE 9.2 Distribution of the Range
We present two different ways of deriving the distribution of a range R = Xn:n - X1:n 
of a random sample X1 , ...,Xn.
SOLUTION 1. The first solution consists of finding the joint distribution of X1:n and 
Xn:n, and then determining the distribution of Xn:n - X1:n using techniques for trans­
formations of random variables discussed in Chapter 6.
For s<t, the direct application of (9.29) gives
n!
g 1 ,n(s,t)=(0)!(n — 2)!(0)![F(t) - F(s 
2f(s)f(t)
= n(n - 1)[F(t) - F(s)]n-2f(s)f(t).
Since R = Xn:n - X1:n, we can take the transformation r = t - s and its “companion” 
w = t. Solving for t and s, we obtain s = w - r and t = w with |J| =1. Thus, the 
density of R is the marginal density for r>0,
hR(r) = 
g1,n(w - r, w)dw 
(9.30)
-ж
Z
+ж 
n(n - 1)[F (w) - F(w - r)]n—2f (w - r)f (w) dw. 
ж
SOLUTION 2. A more direct solution is to condition on one of the variables, 
say X1:n. If X1:n = s, then the probability that the range is less than r is 
{[F (s + r) - F (s)]/[1 - F (s)]}n—1, since all remaining observations must fall 
between s and s + r. The density of X1:n is given by (9.26) and therefore
P{R < r} = [+^ / [F(s + r) - F(s)]n- 11n- 1 x n[1 - F(s)]n-1 f (s)ds
P {R < r} = J | [i - F(s)]n- 1 
x n [1 
F (s)] f (s) ds
= 
+ж n[F (s + r) - F (s)]n-1f(s)ds.
-ж
Differentiation with respect to r gives the density of R.
It is clear that unlike variables X1 , ...,Xn in a random sample, order statistics 
X1:n, ...,Xn:n are dependent variables. For example, Xi:n < Xj:n for any 1 < i<j< n.
■ EXAMPLE 9.3
We will obtain correlation p of two extreme order statistics, X 1: n and Xn: n, in a random 
sample from U[0, 6] distribution.
SOLUTION. To find p, we need the first and second moments of both variables X1:n 
and Xn:n, and their covariance. Based on Example 5.14 and densities (9.26) we have
E(X 1:n) = — [ t (1 
dt = n6 I (1 — w) wn 1 dw
60 
6 
0
1
n + 1 6
(9.31)

ORDER STATISTICS
269
and
___  
. n 6 11\ n1 
1 
n
E(Xn:n) = ° J t(j j 
dt = n° J u du = n+1 °'
(9.32)
Similarly, the second moments are
6 
n 6 
( t\ n- 1
E(XL) = Jo t2g 1(t)dt = ° Jot2 1 - °) dt
= nO2 j (1 - w)2wn-1 dw =
2 ° 2
(n + 1)( n + 2)
(9.33)
and 
6 
6 t n-1 
°2
E(Xn:n) = / t2gn(t)dt = ° Jot 1dt = 
2. 
(9.34)
Consequently,
Var( X > =_______2O2__________ °— = _______ nO2_____
( 1: n) 
(n +1)( n + 2) 
(n +1)2 
(n + 1)2( n + 2)
a^ 
v rv >_ n°2 
n2°2 
n°2 
_ v (Y .
Var( Xn: n) 
n + 2 
(n +1)2 
(n +1)2 (n + 2) 
Var( X1: n).
The equality of variances should not be surprising. Since g 1(t) = gn (° - t) for 0 < 
t < °, the variability in distributions of X 1:n and Xn:n is the same.
To find Cov(X1:n , Xn:n ), we first obtain E(X1:n Xn:n ) using the joint density
g i ,n(s,t ) = n(n— 1)(t - s) n2 for 0 < s<t < °
based on formula (9.29). Then
E (X1: nXn: n) 
6 It st nn-1- (t - s) n-2 ds dt = n+2,
and consequently 
°2 
° 
n° 
°2 
______
Cov(X1:n, Xn:n) = n+2 - (n +1) x (n +1) = (n + 1)2(n + 2). 
(9.35)
Finally,
Cov(X1:n,Xn:n )
VVar( X1: n) VVar( Xn: n)
°2 
(n + 1)2 (n + 2) 
1
(n + 1)2( n + 2) 
n°2 
n
(9.36)
The obtained result is intuitive. The correlation of X1:n and Xn:n decreases when the 
number of observations in the sample (sample size) increases.

270
RANDOM SAMPLES
■ EXAMPLE 9.4 Theory of Outliers
As another illustration of the use of order statistics, we will present basic definitions 
and results of the theory of outliers proposed by Neyman and Scott (1971).
An outlier is an observation that is sufficiently far away from the remaining obser­
vations to justify the suspicion that it results from an observational or recording error, 
or perhaps from a sudden undetected change of conditions that made this particular 
observation obey different probability distributions than those obeyed by the remain­
ing observations. What we present here is a theory of right outliers. The results for left 
outliers may be obtained by obvious modification. Thus, we have a sample, x1 , ...,xn, 
with values of order statistics x1:n, ...,xn:n where xn:n is, in some sense, “too far away” 
from the rest of observations. The intuition of “being too far away” has been formal­
ized in a number of ways in various approaches to the detection of outliers, typically 
in terms of relation of xn:n to the average and standard deviation of the sample.
Neyman and Scott (1971) proposed the definition based on order statistics. In what 
follows, we will always assume that n > 3 and r > 0.
Definition 9.3.2 The sample x1, ...,xn contains an (r, n) right outlier, if
xn:n - xn-1:n > r(xn-1:n - x1:n).
(9.37)
We will simply use the term outlier for the right outlier.
□
It is clear that if only xn:n = xn-1:n, the sample contains an (r, n) outlier for all r satis­
fying the condition
xn:n - xn-1:n
r < ----------------- .
xn-1:n - x1:n
Intuitively, the outlier in the usual sense is an (r, n) outlier for r large enough.
Theorem 9.3.4 A random sample X1, ...,Xn from a continuous distribution with cdf F and 
density f will contain an (r, n) outlier with probability
n (r, n; F) = n (n —
- F(x)
n-2f(y) f(x) dy dx.
(9.38)
Proof: Indeed, ifwe condition on x1:n = x and xn:n = y>x, then the sample will contain 
an (r, n) outlier if (9.37) holds, hence if
x < Xn-1:n < y + rx
r + 1
This event, in turn, occurs if n — 2 remaining observations lie between x and (y + rx)/ 
(r +1), which occurs with probability [F ((y + rx)/(r + 1)) — F (x)]n-2. Multiplying by the 
joint density of (X 1:n, Xn:n) and integrating, we obtain (9.38). 
□
Formula (9.38) allows one to compute the probability that an (r, n) outlier will appear for 
a given F and n. One of the essential features that characterize situations in statistics is that 
the distribution F that governs the selection of the sample is not known. Typically, we know 
only that the true F belongs to a certain family F of distributions. For example, the experi­
menter may know that the sample she observes was obtained from a normal distribution but 
not know the value(s) of the parameter(s).

ORDER STATISTICS
271
Accordingly, we introduce the following definitions:
Definition 9.3.3 The family F of distributions is (r, n) outlier resistant if
sup п(r, n; F) < 1 
(9.39)
f eF
and is (r, n) outlier prone if
sup п(r, n; F) = 1. 
(9.40)
FeF
Moreover, a family F of distributions is totally outlier resistant if condition (9.39) holds for 
all r > 0 and n > 3; it is called totally outlier prone, if condition (9.40) holds for all r > 0 
and n > 3. 
□
Among other results proved by Neyman and Scott (1971), we mention two theorems. 
One of them asserts that the family of all normal distributions is totally outlier resistant. The 
other asserts that the family of all gamma distributions is totally outlier prone.16 The practical 
consequences of these two theorems are as follows: On the one hand, if we have a sample 
x1, ...,xn from a normal distribution, we can find the largest r for which this sample con­
tains an (r, n) outlier. This r is equal to the ratio r* = (xn:n — xn- 1:n)/(xn- 1:n — x 1:n). We 
can then find the quantity (9.38) for F being a family of the normal distribution and r = r*. 
If this quantity is sufficiently small, we have good reason to suspect that the element xn:n in 
the sample is a genuine outlier, in the sense of representing observations from a distribution 
other than that of the rest of the sample. This gives a practical procedure for the rejection of 
outliers.
16For further development of the suggested theory of outliers, see Green (1974, 1976).
On the other hand, if we have a sample x1, ...,xn from a gamma distribution, we can 
never reject the largest element as an outlier if our decision is to be based on the observed 
values only. To see this, suppose that we have data such as x1:4 = 0.5,x2:4 = 0.55,x3:4 =1, 
and x4:4 = 1,000,001. We cannot reject the observation 1,000,001 as an outlier, since the 
probability of a configuration with the ratio
x4:4 - x3:4 = 2,000,000
x3:4 — x1:4
or more has a probability arbitrarily close to 1 for some gamma distribution. More precisely, 
for every e > 0, there is a gamma distribution such that the probability of the configuration 
above exceeds 1 — e.
Our conclusion that in practice one should never reject any sample element as an outlier 
if the sample is known to come from some gamma distribution is actually counterintu­
itive. Such a conclusion does unexpectedly provide a powerful argument for the Bayesian 
approach to statistics (which will be discussed in Chapter 16), but the point is that it seldom, 
if ever, happens that the statistician knows only that the sample comes from a gamma distri­
bution. He usually has some idea about the parameters, based on his experience, imagination, 
understanding of the situation, and so on. Such knowledge, vague as it may be, allows the 
statistician to regard some gamma distributions in the family F as “more plausible” than 
others, and perhaps even eliminate some members ofF as impossible in the given situation. 
Now, if we restrict the family F to some gamma distributions only (by putting a bound on 
parameter a), then F is no longer totally outlier prone, and rejection of outliers becomes 
justifiable.

272
RANDOM SAMPLES
PROBLEMS
9.3.1 In a random sample X 1, ...,Xn selected from EXP( A) distribution find the density 
of: (i) X 1:n. (ii) vnx 1:n. (iii) X2:n.
9.3.2 Let X1, ...,Xn be a random sample selected from the U[0, 1] distribution. (i) Find 
the distribution of variable W = Xi:n - Xi- 1:n, 1 < i < n. (ii) Show that the distri­
bution of Xj:n is BETA(j, n - j +1)forj =1, ...,n. (ii) Find the distribution of 
a sample median Xk+1:n, and obtain its variance if n =3, 7, 15, 2k +1. Do you see 
any trend?
9.3.3 Let X1, X2 be a random sample of size 2 from a continuous distribution with a 
median в. (i) Find P(X 1:2 < в < X2:2). (ii) Generalize part (i) finding P(X 1:n < в < 
Xn:n ) in a random sample of size n.
9.3.4 Use results from Example 9.3 to determine Var(Xl:n - Xk:n), l > k, in a random 
sample X1, ...,Xn from the U[0, в] distribution.
9.3.5 Let X1, ...,Xn be a random sample from the U[0, 1] distribution. Find sample size 
n such that E(R) = 0.75, where R = Xn:n - X1:n .
9.3.6 Let X1, ...,Xn be a random sample from the U(0, в) distribution. Find: (i) E(X1m:n) 
and E(Xnm:n). (ii) E(Xn:n|X1:n). (iii) The cdf of variable V = Xn:n - X1:n. (iv) The 
probability that the interval [X1:n, Xn:n] does not include a given point x0. (v) The 
point x0 for which the probability in part (iv) is the smallest.
9.3.7 Let X1, ...,X5 be a random sample from the BETA(2, 1) distribution. (i) Find 
the density of a joint distribution of X1:5, X2:5, X4:5. (ii) Obtain E(X2:5|X4:5). 
(iii) Obtain E(X4:5|X2:5). (iv) Find the distribution of Y = X2:5/X1:5. (v) Check if 
variables X1:n/Xn:n and Xn:n are independent.
9.3.8 Let X1, X2 be a random sample from the U(0, 1) distribution. Find the probability 
that the values in the sample divide the (0, 1) interval into three parts, each of the 
length at least 0.3 (i.e., X1:2 > 0.3, X2:2 > X1:2 + 0.3, and X2:2 < 0.7).
9.3.9 Let X1, ...,Xn and Y1, ...,Yn be two independent random samples from the same 
continuous distribution with a density f. Show that P {Xi:n < t}> P{Yj:n < t} for 
every t if and only if i < j .
9.3.10 Find n (r, n; Fg) when Fg is the U[0, в] distribution. Find n (r, n; F) for the family 
F = {Fg}, в > 0.
9.4 GENERATING RANDOM SAMPLES
In various quantitative problems that are too complex to be studied mathematically, one 
can often use simulations to find an approximate solution. Such techniques of statistical 
sampling, known today as Monte Carlo methods,17 have been used in a very simple form 
(e.g., tossing dice) for centuries, but became a widely applicable formal methodology only 
with the invention of electronic computers in the middle of the twentieth century.
17 Stanislaw Ulam, a Polish born American mathematician working with John von Neuman and Nicholas Metropo­
lis on the Manhattan Project during World War II, developed computer algorithms for statistical sampling. He also 
worked on transforming deterministic problems into random ones that could be solved by simulations. In his spare 
time Ulam investigated probabilities of winning a card game of solitaire, and that is how the new methodology got 
named after a famous casino.

GENERATING RANDOM SAMPLES
273
Since then, with increasing computing power and easy access to technology, simulations 
have become an important and powerful tool of modern statistics. Today complex 
statistical problems are often investigated based on generated random samples from specific 
distributions that are easy to obtain even using available statistical software packages. We 
now introduce related concepts and explain the theory behind the Monte Carlo simulation 
process.
To generate a random sample from any distribution, we first need to generate indepen­
dent observations from the U[0, 1] distribution. Over the last 40 years, several algorithms 
have been proposed and extensively tested, so the ones that we use today are of really good 
quality. However, “random number generators” are not really generators of random num­
bers. They produce numbers that can be periodical but with periods much larger than we 
are able to detect, and therefore not affecting the quality of our simulation process. The 
interested readers should consult some additional literature, such as Ross (2006).
We will now discuss the random sample generation process, assuming that a good random 
generator of a U[0, 1] distribution is available.
The following example will show how one can generate a random sample from a simple 
discrete distribution:
■ EXAMPLE 9.5
Let X be a Bernoulli random variable such that
P(X =1)=1-P(X =0)=p=0.2.
To generate a single observation from this distribution, we must first generate U, a sin­
gle observation from the U[0, 1] distribution, and then transform it into X observation
in a following way:
1
0
if U < 0.2 
otherwise.
(9.41)
To generate a random sample of size n, we simply need to generate a random sample 
U1, ...,Un from the U[0,1] distribution and then transform each Ui into Xi in the way 
explained above. The transformation given by (9.41) is not the only one possible here. 
Other possibilities could, for example, be
( 1 if U > 0.8 
( 1 if 0.3 < U < 0.5
= 
0 otherwise or = 
0 
otherwise,
as long as P(X =1)=0.2.
To generate a random sample Y1 , . ..,Yn from the binomial distribution BIN(k, p), 
we will need k x n observations from the U[0, 1] distribution. Then, we will transform 
each of them into the BIN(1, p) according to (9.41) and obtain Y1, ...,Yn as
i x n
Yi = 
E 
Xj
ij
j = (i-1) x n+1
for i =1, ...,k. Random samples from any distribution related to Bernoulli trials can 
be generated in a similar way.
The next example shows how to generate values from other discrete distributions.
■ EXAMPLE 9.6
Let X be a random variable with a POI(A) distribution, in which P(X = x) = 
e-xAx/x! After a value of random variable U is generated from U[0, 1], the value x of

274
RANDOM SAMPLES
X is determined in a following way: x equals 0 when U < e \ otherwise x is the only 
positive integer for which the inequality
x-1
E
i=0
e-xXi
x
<U < E
i=0
e—xXi
i
holds.
To generate observations from continuous distributions with a cdf F such that F -1 has 
a closed form, we can apply Theorem 5.4.2, as illustrated by the following example:
■ EXAMPLE 9.7
To obtain a random sample X 1, ... ,Xn from the EXP(A) distribution, we have to 
generate a random sample U1 , ...,Un from U[0, 1] and for any i =1, ...,n, take
Xi = — t log(1 - U),
A
since FX 1(u) = — 1 log(1 — u) is an inverse of the cdf FX (x) = 1 — e-Xx for x > 0.
The generation that we just presented can also serve as a first step in generating 
some distributions from a gamma family. Variable Y = X 1 + • • • + Xk, where variables 
Xi’s are independent and have the same EXP(A) distribution, will, by Theorem 8.4.1, 
have a GAM(k, A) distribution. Therefore, to generate Y1, ...,Yn, we could start by 
generating a random sample Ui, ... ,Unxk from U[0, 1] and then transform it into a 
sample X 1, ..., Xnxk to finally obtain a random sample Y1, ... ,Yn, where for any 
i =1, . . . ,n, 
ixk
Yi = 
Xj .
j =( i- 1) ^k +1
Unfortunately, this approach can be used only if the shape parameter in a gamma 
distribution is a positive integer.
In general, there exist methods that can be used to generate all probability distributions 
with an invertible cdf that is not in a closed form. One of these techniques, called the 
Accept-Reject algorithm, is presented below.
The idea here is that the two observations are generated independently. One observation, 
U, is from the U[0, 1] distribution, and the other, Y, is from a selected continuous distribution, 
which is easy to generate. Ifa certain condition is satisfied, theY observation is “accepted” as 
an X observation and included in a random sample X1, ...,Xn. Otherwise, it is “rejected,” 
and the next pair (U, Y) is generated. Pairs (U, Y) continue to be generated until there are n 
observations X1 , .. .,Xn in the sample.
To introduce the condition that makes some of the Y observations become X observa­
tions, and to explain why the process is really valid, we start with finding a constant C, such 
that
f(x) < Cg(y), 
(9.42)
where f is the density ofa distribution we are interested in (a “target” distribution), andg is 
a density of an easy to generate “companion” distribution. The generated Y observation is 
“accepted” as an X observation if
U < CgYy 
'9.43)

GENERATING RANDOM SAMPLES
275
otherwise, it is “rejected.” To validate the algorithm, we have to show that the distribution 
of X is the same as a conditional distribution of Y under the condition (9.43) so that
FX (y)=FY y
U < fY\ 
- Cg ( y )
Since
+ oo
P U<
U < fy^ g (y) dy 
Cg(y)
-I Z fh g (y) dy-C 0, f (y) dy-1, 
-o 
-o
(9.44)
+o
o
g(y) dy = -
-o
we have
4 < 
< f^ =P(Y< <f 
Y ”
- c i y g (t) i f () / g () du dt 
-o 0
- C Iy ((t)7()-\ dt = Г f (t)dt = Fx (y)
-o 
Cg(t) 
-o 
X
as was to be shown.
Two questions still need to be answered here: Does it matter how the constant C is 
selected? And how many (U,Y ) pairs will have to be generated before we get X1, ...,Xn? 
From (9.44), it is clear that although any C < ж that satisfies (9.42) can be used, the 
optimal choice is C — supy fY (y)/g(y). Unfortunately, for some distributions such C < ж 
cannot be found. One could then use more advanced methods (see e.g., Ross, 2006).
PROBLEMS
9.4.1 Obtain a sample of size 6 from a POI(2) distribution based on following six indepen­
dent observations from U[0, 1] distribution: 0.090907, 0.185040, 0.124341, 0.299086, 
0.428996, 0.927245.
9.4.2 Obtain a random sample of size 4 from a Pareto distribution with a density f(x) - 
(1+ x)-2 for x>0 and 0 otherwise. Use the following random sample from U[0, 1]: 
0.187724, 0.386997, 0.182338, and 0.028113.
9.4.3 The double exponential (or Laplace) distribution has a density given by the formula 
f (x) — (X/2)e -x 1x1 for —ж < x < ж,Х > 0. Obtain a random sample from the 
Laplace distribution with X — 2 based on a random sample 0.744921 and 0.464001 
from the U[0, 1] distribution.
9.4.4 A generalized Laplace distribution has a density given by the formula
f(x) -
pX 1 e x 1 x
(1 — p) X 2 ex 2 2х
if x > 0
otherwise,
(9.45)
where X1 > 0,X2 > 0. Generate two independent observations from a generalized 
Laplace distribution with p -1/4, X1 -3,andX2 - 1/2, based on a random sample 
0.647921, 0.049055 from U[0,1] distribution.

276
RANDOM SAMPLES
9.4.5 Generate a random sample from the Gompertz distribution with survival function 
S(t) = exp{1 - exp(2t)} using the following random sample from the U[0,1] distri­
bution: 0.289365, 0.228349, 0.732889.
9.4.6 Apply an Accept/Reject method to the Laplace distribution with density 
f(x) = 1.5e-3|x| to generate observations from a standard normal distribution. List 
the obtained values and specify how many of them you were able to obtain using 
the random sample of size 5 from U[0, 1]: 0.222795, 0.516174, 0.847152, 0.466449, 
0.914370. Use the optimal choice of C.
9.4.7 The Box-Muller transformation of two independent, uniform variables into two 
independent standard normal variables was presented in Theorem 6.4.1. Another 
algorithm, proposed by Marsaglia and Bray (1964), is to generate U1 and U2 as two 
independent observations from U[-1, 1]. If V = U12 + U2 < 1, then define
Z 1 = U l/-2VgV and Z2 = U.2/^;
otherwise, start the procedure again. Show that Z1 and Z2 are independent and have 
an N(0, 1) distribution.
9.4.8 Kennedy and Gentle (1980) provide the following algorithm for generating a beta 
distribution: Generate U1 and U2—two independent observations from the U[0, 1] 
distribution. For а > 0 and в > 0 denote V1 = Ua and V2 = Ue. According to the 
Accept/Reject algorithm, let X = V1/(V1 + V2) if V1 + V2 < 1; otherwise, start the 
procedure again. (i) Determine the distribution of a random variable X . (ii) Use this 
algorithm to generate a random sample of size 3 from BETA(0.732, 1.281).
9.4.9 Genest (1987) provides the following algorithm for generating random samples from 
the so-called Frank family of bivariate distributions: (a) Generate two independent 
observations U 1 and U2 from U[0, 1]. (b) Obtain T = аи 1 + (а - aU 1)U2. (c) Let 
X = U 1 and Y = loga [T/(T + (1 - а)U2)], where а > 0, а = 1. (i) Show that the 
bivariate cdf of Frank’s distribution has the following form:
(ах - 1)(аУ - 1)
Ha (X, y) = P (X < X,Y < y )= log a 11 + (----- --1-------) j .
(ii) Generate one observation of (X, Y) based on two independent observations from 
U[0, 1]: 0.548291 and 0.179112. Use а = 4.
9.5 CONVERGENCE
Several limit theorems were already encountered in past chapters. On several occasions, we 
looked at the differences between sampling with and without replacement, and noted that 
these two schemes of sampling become closer one to another “as the population becomes 
larger.” We also proved the Poisson approximation theorem, which asserts that as n becomes 
larger and p becomes smaller, the binomial and Poisson probabilities of the same events 
become close.
The common feature of these theorems was that in each case the probabilities of certain 
events—or, more generally, distributions of certain random variables—approached some 
limits with the appropriate change of one or more parameters. Typically, the parameter is an 
index of some sequence, such as sample size n, but the case of Poisson approximation shows 
that it can also be a simultaneous change of two parameters that drives the probabilities to 
their limiting values.

CONVERGENCE
277
In addition to the limit theorem mentioned above, we have encountered a different kind 
of limit theorem, exemplified by the law of large numbers (Example 7.55). There we had 
convergence not only of the distributions but of the random variables themselves.
To grasp the difference between those two classes of situations, observe that one can study 
convergence of a sequence of distributions {Fn} without considering any random variables. 
On the other hand, if X1 ,X2 , ... is a sequence of independent random variables with the 
same distribution F, then the sequence {Fn} of their distributions clearly converges to F, 
but we cannot expect any regularity in behavior of the sequence {Xn }.
In what follows, we consider a sequence £ 1 ,£2, ... of random variables defined on the 
same sample space 5 with a -field F of events, and probability measure P on 5. Our first 
objective will be to distinguish various possible modes in which sequence {£n} can converge, 
and discuss their interrelationships. To connect the analysis with subsequent statistical con­
cepts, it is worthwhile to start from some examples of sequences {£n} that arise in statistical 
research and practice.
■ EXAMPLE 9.8
One of the most common situations in statistics is when we have simple random sam­
ples. This means that we observe the beginning of a sequence of iid random variables 
X1, X2,   Depending on the goal of analysis, given the observations X1, ...,Xn, 
the statistician computes the value of some statistic £n = H(X1, ...,Xn) and uses 
£n as means of inference. The behavior of the sequence {£n } as n increases tells the 
statistician to what extent it would be worthwhile to increase the sample size n.
We begin with the definition that captures the type of convergence encountered in the law 
of large numbers (Theorem 7.8.3).
Definition 9.5.1 The sequence {£n} converges in probability to a constant c if for every e > 0,
\ — \.P {|£n - c\> e} = 0. 
(9.46)
More generally, we say that {£n} converges in probability to a random variable £ if for every 
e > 0,
lim P{|£„ - £| > e} = 0. 
(9.47)
n—>^>
Convergence in probability, especially to a constant, is often called a stochastic convergence.
□
The meaning of (9.46) is that as n increases, it becomes less and less likely that £n will devi­
ate from c by more than e. In (9.47), the interpretation is the same, except that the constant 
c is replaced by a random quantity. So written more explicitly, (9.47) reads
lim P{s : |£n(s) - £(s) | > 4 = 0. 
n—>^>
P
We will use the symbol ^ to denote convergence in probability.
■ EXAMPLE 9.9 Laws of Large Numbers
The law of large numbers proved in Section 7.8 asserts convergence in probability of 
empirical frequencies of an event. Such theorems (asserting convergence in probability 
of averages of random variables) are called weak laws of large numbers (WLLN), to 
distinguish them from strong laws of large numbers (SLLN).

278
RANDOM SAMPLES
For instance, in the case of a Bernoulli distribution we have the following rephrasing of 
Theorem 7.8.3:
Theorem 9. 5.1 If Sn has binomial distribution BIN(n, p), then
Sn P 
----------p p. 
n
A stronger type of convergence of sequences of random variables is given in the following 
definition:
Definition 9.5.2 Let £ 1, £2, ... be a sequence of random variables defined on some 
probability space (5, F, P). If lim £n (s) = £(s) exists for all points s e U where P(U) = 1, 
then we say that £n converges to £ almost everywhere (a.e.), almost surely (a.s.), or 
with probability 1. 
□
The following theorem is given without proof:
Theorem 9. 5.2 If £n p £ a.s., then £n pP £.
The converse to Theorem 9.5.2 is not true, as illustrated by the next example.
■ EXAMPLE 9.10
Let £1, £2, ... be independent random variables, such that P{£n =1} =1/n and 
P {£n = 0} =1 - 1 /n .Thus, if 0 < e < 1,then P {|£n| > e} = P {£n = 1} = 1 /n p 0, 
which shows that the sequence {£n} converges to 0 in probability. For any sample 
point, the sequence {£n(s)} is simply a sequence of 0’s and 1’s, and in order to converge 
to 0, there must be only a finite number of terms equal 1 (i.e., all terms must be 0, 
starting from some N). But letting An = {£n = 1}, we have P(An) = 
1 /n = ж,
and by the second Borel-Cantelli lemma (Theorem 4.5.5), we know that with 
probability 1 infinitely many events An will occur. Thus, P{£n converges} =0, which 
shows that convergence in probability does not imply a.s. convergence.
Theorem 9.5.3 The sequence {£n} of random variables £ converges a.s. to a random variable £ 
if and only if for every k =1, 2, ...,
lim P < |£n — £| > f for some n > N > = 0, 
(9.48)
or equivalently,
lim pi sup |£n — £| > 11= 0.
N -^ 
n>N 
k
We will now use (9.48), together with the Kolmogorov inequality (Theorem 7.8.5), to prove 
the sufficiency part of Kolmogorov’s three series theorem. This theorem provides conditions 
for the a.s. convergence of the series °=1 Xj of independent random variables X 1, X2, ...
We will also introduce the method of truncation, a powerful technique of handling lim­
its of sequences of random variables. If X is a random variable and c>0, we define the

CONVERGENCE
279
truncation of X at c as a random variable Y , defined by
Y=
if |X | < c 
if |X| >c.
X 
0
Observe that Y is a bounded random variable, so E(Y ) and Var(Y ) both exist. We 
have
Theorem 9.5.4 (Kolmogorov Three Series Theorem) Let X1, X2, ... be a sequence of inde­
pendent random variables, and let Yn be the truncation of Xn at level c> 0. Then, ^=1 Xn 
converges a.s. if and only iffor some c>0,
(a)EX1 P{|Xn| >c} < ж
(b)E~1 e(Yn) < ж.
(c) E X1Var( Yn) < ж
Proof: As mentioned, only the sufficiency of conditions (a)-(c) will be shown; the proof of 
necessity is beyond the scope of this book.
Let us fix N, k, and n>N, and consider the sums
r
(Yj - E(Yj))
j=N
for r = N, ...,n. By the Kolmogorov inequality (7.57), we have
P max
N <r<n
r
(Yj - E(Yj)) 
j=N
n
^ 
£ Var( Yj)
> Ц < 
_______
- k < 
(1 /k)2
Letting n — ж, we have
sup
N <r
r
(Yj - E(Yj)) 
j=N
P
Ж
> k < k2 
Var(Yn) .
 
n=N
In view of (c), the right-hand side converges to 0 as N — ж for every fixed k. By 
Theorem 9.5.3, the sequence n=1( Yj - E (Yj)) ,n =1, 2,..., converges a.s. Since
Г=1 E(Yi) converges (condition b), we infer that °=1 Yi converges a.s. To complete the 
proof, observe that P {|Xn| >c} = P{Xn = Yn}. In view of condition (a) and the first 
Borel-Cantelli lemma (Theorem 2.6.2), with probability 1 only finitely many terms Yn 
will differ from terms Xn. Consequently, Xn and Yn will a.s. differ only by a finite 
quantity, and since Yn converges, so does Xn. 
□ 
■ EXAMPLE 9.11
For the harmonic series 1 + 11 + 1 + ••• = ж. With alternating signs, we have an 
alternating harmonic series 1 - 1 + 1 - 4 + • • • = log 2.18 What if the signs are 
allocated at random, by a flip ofa fair coin? In other words, we ask about convergence 
of the series
18We remind the readers that throughout this text log x = logex.
X1 + X2 + X3 + • • • , 

280
RANDOM SAMPLES
where Xn assumes values ±1/n with probability 1/2 and Xn’s are independent. Taking 
c =2,say,wehaveYn = Xn for all n, and all terms of the series (a) in Theorem 9.5.4 
are zero. Next we have E(Yn) = 0 and Var(Yn) = E(Yn2) = 1/n2. Thus, all three series 
(a)-(c) converge; hence Xn converges a.s. In other words, the probability is zero that 
random signs + and - in the harmonic series will come out so unbalanced as to make 
the series diverge.
Observe that this in not only the question of “balancing” the numbers of positive 
and negative signs. Indeed, the series 1 / Jn diverges, and the series tn/Jn, where 
en’s are independent and en = ± 1 with probability 1 /2, also diverges a.s.—since in this 
case the series (c) of variances diverges.
The third important type of convergence is the following definition:
Definition9.5.3 Let £0,£ 1 ,£2, ... be a sequence of 
Fn(t) = P{£n < t},n = 0, 1, 2, ..., be their cdf’s. The 
distribution to £0 if
lim Fn (t)=F0 (t) 
n—>^>
random variables, and let 
sequence {£n} converges in
for every t at which F0(t) is continuous. In this case, we can write £n -^d £0. Alternatively, we 
will use the symbol Fn ^ F0. 
□
Before presenting the theorems characterizing convergence in distribution, we will make 
some comments, that can help clarify the motivation and intention of this concept.
First, observe that convergence in a distribution does not imply anything about the behav­
ior of random variables. For instance, if the variables £0, £ 1, ... are iid, then Fn (t) = F0(t), 
so £n -^d £0, but we cannot expect any regularity in behavior of the observed values of random 
variables. Since we require only convergence of the distribution functions, we do not need to 
have any specific random variables £n in mind. This is the reason behind the dual notation 
in Definition 9.5.3.
The second question concerns the reasons for requiring the convergence of Fn(t) to F0(t) 
only at points of continuity of F0 (and not at all points). The explanation has to do with 
the special role played by discontinuities of cdf’s. Consider a sequence of degenerate ran­
dom variables (i.e., constants), defined as £n = 1/n, n =1, 2, ...,and£0 =0. Obviously here 
lim £n = £0 in the “usual” sense of convergence of observed values of £n to £0 .
We have here
Fn (t)= P{£n < t} =( 0 
if t< 1/n
n 
n — J [1 
if t > 1 /n
and
F0(t) = 
01
ift< 0 
ift > 0.
For any t = 0 (where F0 is continuous), we have lim Fn(t) = F0(t). However, at t =0we 
have F0(0) = 1, while Fn(0) = 0 for all n. Observe that ifwe put £n = -1/n, then Fn(t) will 
converge to F0(t) at all points t, including t =0.
The following theorems connect the three types of convergence introduced above, and 
also some criteria for convergence in a distribution.
Theorem 9.5.5 (Slutsky) If £n and nn are sequences of random variables such that £n — nn ~^ 0 
and nn -^ £, then £n ~^ £.

CONVERGENCE
281
Proof: Let F be the cdf of Z, and let Fn be the cdf of Zn. Let t be a continuity point of F, 
and let e > 0 be such that t + e and t — e are also continuity points of F. We write
Fn (t) = P{£n < t} = P{£n < t, l£n - Пп1 < 0 + P{£n < t, l£n - Пп1 > 0
< P{nn < t + 0 + P{|£n - nn\ > 0-
By similar reasoning, we obtain
P{nn < t — 0 < Fn(t) + PЖ — nnl > 4­
As n P ж, P {nn < t ± e} P F (t ± e), and P {|£n — nnl > £} P 0 by the assumption of the 
theorem. Consequently,
F(t - e) < liminf Fn(t) < limsupFn(t) < F(t + e)-
Since e > 0 is arbitrary (subject only to the condition that F is continuous at ±e), we must 
have
lim Fn (t) = F(t), 
n—>^>
as was to be shown. 
□
Taking nn = Z,n = 1, 2, - - -, we obtain the following theorem:
Theorem 9. 5.6 If Zn P Z, then Zn Pd C
Since we already know that convergence a.s. implies convergence in probability, we 
also have
Theorem 9. 5.7 If Zn P £a.s., then Zn P £.
Although, as already explained, convergence in distribution does not imply convergence 
in probability, such implication holds in the case where the convergence is to a constant. 
We have
Theorem 9. 5.8 If Zn Pd c, then Zn P c.
Proof: The condition Zn Pd c means that {Zn} converges in distribution to a random vari­
able Z such that P{Z = c} =1. Consequently, letting again Fn(t) = P{Zn < t}, we have 
Fn(x) P 0 for all x<cand Fn(x) P 1 for all x>c. But this means that P {lZn — cl > 
e} = P{Zn <c — e} + P{Zn > c + e} = Fn(c — e — 0) + [1 — Fn(c + e)] P 0 for every e > 
0, which is what was to be proved. 
□
We shall state now a theorem that shows the extent to which one is allowed to carry the 
algebraic manipulations on sequences converging in distribution and in probability.
dP
Theorem 9. 5.9 If Zn, an, and en are sequences of random variables such that Zn P Z,an P a, 
P
en P в, where a and в are finite constants, then
arfin + en P aZ + в-
In particular, we have here the following corollary:

282
RANDOM SAMPLES
Corollary 9.5.10 If £n d £, and a, b, an, bn are constants such that an d a, bn d b, then 
an tn + bn d at + b.
The following theorem, which we state without proof, will serve as one of the main tools 
in proving convergence in distribution to normally distributed random variables:
Theorem 9.5 .11 Let tn,n=1, 2, ...,andt be random variables, such that their mgfs mn(t) 
and m(t) exist. Then tn dd t if and only if mn(t) d m(t) for every t in some interval around 
the point t =0.
The actual use of Theorem 9.5.11 will be based, in most cases, on the assumption of the 
existence of moments and the corresponding Taylor expansion of the mgf’s.
Theorem 9.5 .12 Let the random variable X have mgf m(t). Assume that E(|X|k) < ж for 
some k, and let mj = E(Xj) for j =0, 1, ...,k.Then
k mjtj
m (t) = 
+ o (\t\k),
j=0 j !
(9.49)
where o(|t|k) is some function such that o(|t|k)/|t|k d 0 as t d 0.
Proof: The proof consists of using the well-known theorem from calculus on Taylor expan­
sions and recalling (Theorem 7.5.3) that
m = E (X j) = dm) 
j 
dtj
t=0
□
The following theorem states another fact known from calculus.
Theorem 9.5 .13 If {cn } is a sequence of numbers such that lim n—^cn = c, then
lim
n—>^> (1+^n=“•
As an illustration of applicability of Theorem 9.5.11, we sketch a proof of Theorem 7.8.3 
(law of large numbers in the Bernoulli case). We know from (7.22) that the mgf of the bino­
mial random variable Sn is mSn (t) = EetSn =(q + pet)n. Using the fact that mSn/n(t) = 
mSn (t/n), we have
mSn/n(t)= q + p f1 + - + t^2 + ■" ) = f1 + p~ + p-2 + ■" ) d ept
n n 
n 2n2 
n 2n2
The last step consists of using Theorem 9.5.13 with
cn = pt+ p-tn +—d pt.
We showed that the mgf of Sn /n converges to the mgf of random variable equal identically 
to p for every t (hence also in some neighborhood of t =0). Theorem 9.5.11 allows us to 
infer that Sn/ndd p, and by Theorem 9.5.7, we have Sn/ndP p.

CONVERGENCE
283
Weak Laws of Large Numbers
We will now prove some of WLLN using the Chebyshev inequality (Theorem 7.8.1).
Theorem 9.5 .14 Let X1, X2, ... be a sequence of iid random variables. Assume that E(Xi) =
M and Var(Xi) = a2 > 0. Then, for every e > 0,
lim P
n—>^>
X1 + • • • + Xn
n
=0.
(9.50)
- M
Proof: Based on the Theorem 9.1.1
X1 + • • • + Xn
n
X1 + • • • + X, 
and Var ------------------
n
a2
Applying the Chebyshev inequality to variable (X1 + ••• + Xn)/n, we obtain
X1 +------- + Xn
n
which converges to 0 as n — ^.
-M
< a 2
n ne2
(9.51)
□
P
This theorem confirms, in some sense, our belief in the “law of averages”: formula (9.51) 
tells us that ifwe take the averages (X1 + •••+ Xn)/n of larger and larger numbers of obser­
vations (of some phenomenon, described by random variable X, whose “copies” X1, X2, ... 
are being observed), then it becomes less and less likely that the average (X1 + ••• + Xn)/n 
deviates by more than e from the “true average” m = E(X)•
This assertion of Theorem 9.5.14 constitutes, to a large extent, the basis of the common 
understanding why “statistics works,” that is, why increasing the number of observations 
pays off in the form of being able to make a better inference about some quantities.
The generality of the assertion of Theorem 9.5.14 is in stark contrast with nar­
rowness of the assumptions specifying that X1, X2, ... are iid random variables. The 
importance—practical and cognitive—of assertion (9.50) makes it worthwhile to analyze to 
which extent that assumption of Theorem 9.5.14 can be relaxed.
The full answer lies beyond the scope of this book. We will, however, analyze the question 
of to what extent the assumptions can be relaxed under the present proof, based on the 
Chebyshev inequality.
First, let us observe that we did not fully utilize the assumption that Xi’s have the same 
distribution. In fact we used only a special consequence of this assumption, namely the fact 
that E(Xi) = M and Var(Xi) = a2 are the same for all i. Thus, we can drop the requirement 
that Xi’s be identically distributed, as long as we retain the stationarity of the mean and 
variance. To use the example of measurement, we could take measurements of the same 
quantity M with different measuring instruments or methods, provided that E(Xi) = M and 
Var(Xi) = a2 (such measurements are called unbiased and having the same precision).
But even the requirement that E(Xi) = M is not necessary: when E(Xi) = Mi, relation 
(9.50) can be replaced by
P f X1 + 
+ Xn - M1 + 
+ Mn
nn
> 4 — 0, 
(9.52)
which is the same as
u 1 + ••• + Un 
n
— 0,
where Ui = Xi - Mi is the deviation of the ith random variable from its own mean.

284
RANDOM SAMPLES
Next, an inspection of the proof of Theorem 9.5.14 shows that it is not necessary that 
variances all be equal. What is required is that the variance of the average (X 1 + • • • + Xn)/n 
decreases to 0 as n increases. We can therefore formulate the following version of the law of 
large numbers:
Theorem 9.5 .15 Let X 1 ,X 2, ... be iid random variables, with E (Xi) = pi and Var( Xi) = a2.
If
lim “2 
ai =0,
n>^> n2 i=1
(9.53)
then relation (9.52) holds for every e > 0.
Let us now see to what extent it is possible to relax the assumption of independence. 
Again, an inspection of the proof of Theorem 9.5.14 shows that the property which was used 
is the additivity of variance, specifically the fact that Var(X 1 + • • • + Xn) = a'1 + • • • + an. 
But this property holds under the assumption that the random variables are uncorrelated.
Theorem 9.5 .16 If random variables X1, X2, ... are uncorrelated then the condition (9.53) is 
sufficient for (1 /n) E n=i( Xi - Vi) -P 0 •
Finally, let us observe that even the latter condition can be relaxed: what we really need to 
make the proof valid is that (1 /n2)Var(X 1 + • • • + Xn) ^ 0. This in turn is implied by the 
assumption (9.53) in the case where all covariances are zero or negative. We therefore have
Theorem 9.5.17 Let X1, X2, ••• be random variables with E(Xi) = Vi and aj2 = Var(Xj), 
and such that Cov( Xi, Xj) < 0 for i = j, satisfying (9.53) as n ^ ж. Then for every e > 0,
P
1n
fD Xj - Vj)
j=1
as n ^ ж.
This is as far as we will go using the techniques of proof based on the Chebyshev inequal­
ity. It is of some interest that in the case of identical distributions, one can prove a weak law 
of large numbers without the assumption of existence of variance.
Theorem 9.5.18 Let X1, X2, ••• be a sequence of iid random variables with E(Xi) = V, and 
such that their common mgf exists in some neighborhood oft =0. Then the relation (9.50) 
holds.
Proof: From Theorem 9.5.7, it is enough to show that (X 1 + • • • + Xn)/n — p, and there­
fore (Theorem 9.5.11) that mSn/n(t) ^ e^t in some neighborhood of t = 0.
Letting m(t) = EetX, we have mSn/n = [m(t/n)]n, since Xi’s are iid. The existence of 
p = E(X) implies the existence of the derivative m', and the relation m (0) = v. Then, the 
Taylor expansion of m(t) is m(t)=1+Vt + o(|t|) (see Theorem 9.5.12) so that
msn/n(t)= (1 + 
+ o (-n.
nn 
n 
n
To complete the proof, we use Theorem 9.5.13 for cn = pt + no(\t\/n) ^ pt. 
□
Comment. Observe that the assumption of existence of an mgf is not necessary for the 
validity of the theorem. The proof of this strengthened version requires nothing more than 
replacing mgfs with characteristic functions. All the steps of the proof remain unchanged.

CONVERGENCE
285
Strong Laws of Large Numbers
The strong laws of large numbers (SLLNs) are theorems that assert almost sure conver­
gence of sequences of random variables obtained by averaging some underlying sequences 
of random variables. We will prove here two such theorems, both due to Kolmogorov.
Theorem 9.5.19 Let X 1, X2, ... be independent, with EXi = ^i, Xi = ai. If
TO о
E a
n2
n =1
< <x>,
then
1n
~ E(Xi — di) ^ 0 a.s. 
n i=1
(9.54)
Proof: To simplify notation, let Sn = ^2n=i Xi and mn 
Hn=1 di• For a fixed e > 0, let
Ck = 4 max 1 |Sn — mn | > J .
2k-1<n<2k n
To prove the theorem, it suffices to show that P(Ck) < ж, since then, by the 
Borel-Cantelli lemma (Theorem 2.6.2), only finitely many events Ck will occur a.s., which 
implies (9.54).
If Ck occurs, then at least one of the inequalities
|Sn — E (Sn) | > en > e 2 k—1, 
n = 2 k—1 + 1, ..., 2 k,
occurs. By the Kolmogorov inequality (Theorem 7.8.5), we obtain
PC x V Var( S2 k) 
P(Ck) — e2(22k—2)
4 X E2= 1 aj 
e2 
22 k
We can therefore write
TO E 
k =1
л ~ 
2 21
P (Ck) C ;? E 22k E aj 
k=1 
j=1
TO 2
16 
aj
= 322 E j2 < ж, 
j=1
TO TO 
1
- V a 2 V - 
e 2 aj Z_^ 22 k
j=1 
2k>j
since
E 21k = E 2—2 k
2k>j
2-2log2j
k >log2 j
1
1
4
□
We will now prove another strong law of large numbers, also due to Kolmogorov, that 
covers the iid case.
Theorem 9.5.20 Let X 1, X2, ... be iid random variables, and let Sn = X 1 + • • • + Xn. If ^ = 
E(Xi) exists, then Sn/n ^ ^ a.s.

286
RANDOM SAMPLES
Proof. Let us truncate the random variables {Xn}, by letting
X Xk, 
if |Xfc|< k,
0, 
if |Xk | >k.
We have
oo 
oo 
oo
PY{Yk = Xk} = £ P{IXk I >k} = £ P{|X11 >k} < ж
k=1 
k=1 
k=1
by the assumption that E(X1) < ж and since Xk has the same distribution as X1. Thus, 
the inequality Xk = Yk will occur a.s. only a finite number of times, and it suffices to prove 
that (1 /n) n=r Yk — ^ a.s. To this end, we will use Theorem 9.5.19, proved above. We let
022 = Var(Yk) < E(Yk2). Therefore, we can write
oE
k =1
ak 
k2
< О E(Yfc2) 
k 2 
k=1
o1 
= E k2 j
k=1 
-
xkdF (x)
k
k
ok
= 
x 2 dF (x)
k=1k 2 j=Jj-1 <x<t
= f! 
x2dF (x) ± k1k < £ f 
x2dF (x) X CC
j=1 j-1< x <j 
k=jk 
j=1 j-1< x <j 
j
< C [ 
|x|dF(x) = C [ |x|dF(x) < ж.
j=1 j-1< x <j 
-o
We use the estimate 1 /j2 + 1 /(j + 1)2 + • • • < C/j valid for some C. It follows that 
(1 /n) Sn=1[Yj — E(Yj)] — 0 a.s. But E(Y,) — E(X 1) = p, as j — ж; hence also 
(1 /n)[E(Y1) + • • • + E(Yn)] ^ ^. Then, we must have
1n
1 E Y, 
n j=1
—f.i a.s.,
which completes the proof.
□
PROBLEMS
9.5.1 Let X 1, ... ,Xn be a random sample from a POI( A) distribution. Show that
e-x n — p ( x 1 =o).
9.5.2 Let Z1 , ...,Zn be a random sample from N(0, 1) distribution. Find the limiting dis­
tribution of Yn = YxП=1 (Zi + 1 /n) /Vn.
9.5.3 Let X1, ...,Xn be a random sample from distribution with cdf F(x)=1- x-2 for 
1 < x < ж, and 0 otherwise. Find the cdf of limiting distribution of: (i) X 1:n. (ii) Xnn. 
(iii) xn: n/vn. 
' 
'
9.5.4 Let X1 , . ..,Xn be a random sample from continuous distribution with a cdf F such 
that F-1 exists. Find (if it exists) the limiting distribution of: (i) Un = nF (X1:n ). 
(ii) Wn =n[1 -F(Xn:n)]. (iii) Vn =nF(X3:n).

CENTRAL LIMIT THEOREM
287
9.5.5 Let X1, ...,Xn be a random sample from distribution with cdf F(x) = x2/9 for 0 < 
x < 3. Find the limiting distribution of Yn = y/n,X 1:n if it exists.
9.5.6 A random variable has a Pareto distribution with parameters a, b (a> 0,b > 0) if its 
density is
f(x; a,b )= b (1 + X/b) a+1, x> 0'
Let X1 , ...,Xn be a random sample from the Pareto distribution with density 
f(x; 1, 1). (i) Find the limiting distribution of random variable Un = nX1:n. 
[Hint: Find cdf F (x) of Xi, and then determine cdf of Un in terms of F (x).] (ii) 
Show that Vn = Xn:n does not have a proper limiting distribution; specifically, 
lim„,-*_/'’{Vn < t} = 0 for every t. (iii) Find the limiting distribution of Vn/n.
9.5.7 Let X1 , ...,Xn be a random sample from a logistic distribution with a cdf F (x)= 
1 /(1 + e-x), and let Vn = Xn:n. Then Vn — ж, but Vn - log n has a proper limiting 
distribution. Find lim„,-*_/'’{Vn - logn < 0} and lim„,-*_/'’{|Vn - logn| < 1}.
9.6 CENTRAL LIMIT THEOREM
The term central limit theorem (CLT) is a generic name used to designate any theorem that 
asserts that the sums of large numbers of random variables, after standardization (i.e., sub­
traction of the mean and division by standard deviation), have approximately a standard 
normal distribution.
As suggested by the adjective central, the search for conditions under which sums of a 
large number of components have an approximate normal distribution has been (and to a 
large extent still is) one of the leading research topics in probability theory for the last 200 
years or so. We begin with the simplest case of iid sequences.
Theorem 9.6.1 (Lindeberg and Levy) Let X 1, X2, ... be a sequence of iid random variables 
with E(Xi) = - and Var(Xi) = a2, where 0 < a2 < ж. Then, letting Sn = X 1 + • • • + Xn, 
for every x
lim P / —n—n- < x| L- [ e-t2/2 dt. 
(9.55)
' 
a\/n 
J 
V2 nJ-ж
Proof:ObservethatE(Sn)=n- and Var(Sn) = na2, so the left-hand side of (9.55) is sim­
ply the limit of the cdf’s of the standardized sums
Q* 
Sn
sn - E (Sn) 
7Var( Sn)
The right-hand side is the cdf of a standard normal random variable, denoted Ф(x). Thus, 
the theorem asserts that the cdf’s of Sn converge to Ф(x) for every x, hence at every point of 
continuity of Ф(x). Letting Z denote the standard normal random variable, Theorem 9.6.1 
asserts that Sn* -d Z.
When an the assertion is phrased in this way, it should be clear that a possible strategy 
of the proof is to use a mgf and Theorem 9.5.11. Let mX (t) be the common mgf of random 
variables Xi (assumed to exist). The existence of the first two moments suggests applying a 
Taylor expansion. We have
Xi - -
^fn
i=1
n
Sn* =

288
RANDOM SAMPLES
so that
ms* (t) = [m(X-V)/«vn(t)]n
m ( x-v )/«
=1
Now
X-
=0,
X-
(9.56)
(9.57)
so that
E
M
a
E
M
m ( x-v )/«(t) = 1 + “2 + o(t 2).
Consequently, using (9.56), we obtain
mS*
1 + tr + o 
2n
t 2 / 2 + no (t 2/n) 
n
By Theorem 9.5.13, for cn = t2 + no(tn) ^ t2 we obtain
ms* (t) ^ et /2,
which completes the proof in the special case where the underlying random variables Xi have 
mgf’s. For the general case, see the comment following the proof of Theorem 9.5.18. 
□
■ EXAMPLE 9.12
Suppose that you buy a supply of 20 household batteries to be used for some specific 
purpose, one after another when needed. Assume that unused batteries are not aging 
and that the lifetime of each such battery is a random variable with a mean oftwo weeks 
and a standard deviation ofthree days. What is the (approximate) probability that the 
supply of batteries will last more than 9 but less than 10 months? (i.e., more than 270 
and fewer than 300 days?).
SOLUTION. The question here is about the probability that S20 = X 1 + • • • + X20 
satisfies the inequality 270 < S20 < 300. We have np = 20 x 14 = 280 and a^n = 3 x 
V20 = 13.4. Thus, 270 < S20 < 300 occurs if and only if (270 - 280)/13.4 < S20 < 
(300 - 280)/13.4, (i.e., if -0.75 < S2*0 < 1.49).
For Z ~ N(0, 1), we have
P {270 < S20 < 300} « P {-0.75 <Z < 1. 49} = Ф(1. 49) - Ф( - 0.75)
= 0.9319 - 0.2266 = 0.7053.
Theorem 9. 6.1 is a generalization of the oldest central limit theorem, due to Laplace, 
covering the binomial distribution.
Theorem 9. 
6.2 Laplace If Sn has a binomial distribution BIN(n, p), then for any z1 <z2 ,
lim ^2 
P{Sn=j} = lim P{z 1 ^ Sn ^z2}
n——^ 
n—>^>
An <j<Bn
= ф(z2) - ф(z 1),
(9.58)
where An = np + z 1 ^npq, Bn = np + z2 ^npq.

CENTRAL LIMIT THEOREM
289
Proof: IfSn is the number of successes in n independent trials, each with probability of suc­
cess p, then Sn = X 1 + • • • + Xn, where P {Xi = 1} =1 - P {Xi = 0} = p, i = 1, 2, .. .,n. 
Consequently, E(Sn) = np and Var(Sn) = npq so that
Q* 
Sn
Sn - np 
y/npq
□
Suppose now that we want to find P{a < Sn < b}. According to Theorem 9.6.2, for large 
n we have
P{a < Sn < b} = P
a - np 
^npq < Sn* < b - np 
^npq
b - np a - np
Ф 
- Ф t
\ nnpq J 
\ npq>q
(9.59)
However, approximation (9.59) can be improved somewhat ifwe observe that in the present 
case Sn is an integer-valued random variable, and for integers a and b the exact expression is
P{a < Sn < b} = £P{Sn = j}.
j=a
(9.60)
Each term on the right-hand side of (9.60) can be approximated by an area under the normal 
curve between (j — 0.5 — np) /^npq and (j + 0.5 — np) / ^npq.
Adding such approximations, the terms for neighboring j cancel, and we obtain the fol­
lowing formula:
P{a < Sn < b} ~ Ф (b + 0.5 - n^ - 4 ° - 05 - np 
\ ^npq J \ 
npipq
(9.61)
for any integers a < b, known as a normal approximation with continuity correction.
■ EXAMPLE 9.13
A fair coin is tossed n = 15 times. Find the approximate probability that the number 
S15 of heads will satisfy the inequality 8<S15 < 10.
SOLUTION. Notice that 8 < S 15 < 10 is the same inequality as 8 < S 15 < 9. Since 
np =15 x 0.5 = 7.5, ^npq = 415 x 0.5 x 0.5 = 1.94, the approximation (9.58) gives
P{8 < S15
9 + 0.5 -
1.94
7.5
8 - 0.5 - 7.5
1.94
< 9} « Ф
- Ф
= Ф(1.03) - Ф(0) = 0.8485 - 0.5 = 0.3485.
The exact value is
{S15 = 8} + P{S15 = 9} = (15 ) (1Г + (15 ) (1Г 
82 
92
= 0.1964 + 0.1527 = 0.3491.

290
RANDOM SAMPLES
Generally, the quality of approximation improves as n increases, and—for the same 
n—decreases as p moves away from 1/2 in either direction.
■ EXAMPLE 9.14 Decision Problem
Suppose that we design a theater with 1,000 seats. The theater has two entrances, A 
and B, situated with respect to a parking lot, public transportation, and so on, so that 
the patrons have equal chances of choosing any of the entrances.
Suppose also that our theater is to be located in a city where the climate calls for 
patrons to wear overcoats, which they can leave in a coatroom. There are to be two 
coatrooms, each located near one of the entrances, and while it is possible to enter 
through one entrance and leave the coat in a coatroom near to the other entrance, it is 
inconvenient to do so. How many coat hangers should each coatroom have?
SOLUTION. Clearly, the problem is not precise enough as stated: We have to specify 
the criterion which we want to attain. One of the objectives is minimization of the cost 
of equipping the coatroom in hangers, racks, and so on. We do not want to staff a 
coatroom that will remain empty. On the other hand, we do not want to inconvenience 
patrons by making them go to a distant coatroom. The two extremes, each satisfying 
one of the foregoing objectives, is to equip each coatroom with 1,000 coat hangers, and 
to equip each with exactly 500 coat hangers.
A possible objective may be: We want to equip each coatroom with 500 + x hangers, 
where x is the smallest number such that (say) on 95% of nights when the theater is 
sold out, everyone will be able to leave his or her coat at the coatroom nearest to the 
entrance used.
To solve the problem, we have to make some assumptions about independence of 
choice of entrances A and B by the patrons. As the first approximation, assume that 
the patrons arrive one at a time and each chooses the entrance independent of other 
patrons. Let S1,000 be the number of patrons (among n = 1,000) who choose entrance 
A. We want to have S1 000 < 500 + x (then everyone who enters through A is not 
inconvenienced), and also 1,000 - S1 000 < 500 + x (which is the analogous condition 
for entrance B). Thus, we would like the event 500 - x < S1,000 < 500 + x to occur 
with probability 0.95 or more. Since p = 0.5, np = 1,000 x 0.5 = 500, and ^npq = 
^1,000 x 0.5 x 0.5 = 15.8, we have
P{500-x<S1,000 < 500 + x} = P
-x - 0.5
[ 
15.8
< S*
< S1,000
x +0.5
<----------->
- 15.8 J
x + 0.5 \
15.8 ) - Ф
x + 0.5 \
15.8 ) > 0.95.
Ф
Since Ф(1.96) — Ф(—1.96) = 0.95, we must therefore take x as the smallest integer for 
which (x + 0.5)/15.8 > 1.96, which gives x =31. Thus, to achieve our objective, we 
should install 532 coat hangers in each coatroom.
■ EXAMPLE 9.15
Continuing Example 9.14, a more realistic assumption is that people attend the 
theater in pairs, and both members of a pair come through the same entrance. 
We have now n = 500 pairs, and letting S500 denote the number of pairs who 
choose entrance A, we must have 2S500 < 500 + x and 1,000 - 2S500 < 500 + x. 
Now E (S500) = 500 x 0.5 = 250 and Var(S500) = 500 x 0.5 x 0.5 = 125. Therefore

CENTRAL LIMIT THEOREM
291
250 - x/2 < S500 < 250 + x/2. Using formula (9.58), we get
p{ 250 - x < S5oo < 250+ 2} = P
< S*
< S500
x +1 \
22.3 )
x +0 . 51
< 2 ,____  >
“ 12525
- Ф
x + 1
22.3
= Ф
Again, x is the smallest integer for which (x + 1)/22.3 > 1.96, so x = 43. We see that 
grouping (in this case into pairs, but the effect is the same for other groupings) a set 
of persons, with groups choosing the entrance independently, increases the variability: 
we now need to supply 543 hangers in each coatroom to meet the requirement.
The CLT proved thus far concerns the rather narrow case of independent and identi­
cally distributed components. In this case, the sum has asymptotically normal distribution, 
provided only that variance is finite. This theorem is often utilized to explain the frequent 
appearance of a normal distribution in nature. The argument typically goes along the lines 
of attribute, such as the height of a person, or an error of measurement of some quantity, 
(such as the speed of light). Whatever the case, the observed value is influenced by a large 
number of factors, some having a negative and some having a positive effect. Some such fac­
tors are known, but their effect cannot be predicted exactly, whereas other factors may not 
even be named. What matters is that all these factors operate largely independently of one 
another and each in isolation is small as compared with the total effect of all factors (i.e., 
factors that are known to have large effects are treated differently and are not included in 
these considerations). The CLT therefore asserts that the total effect of such “small” factors 
is random and has approximately a normal distribution. We already know this to be true 
in case of factors that are iid. However, independence and identical distribution can hardly 
be justified in every real situation, and can at best be regarded as approximations to reality. 
Consequently, one can expect central limit theorems to be valid in wider classes of situations 
where the iid assumption does not hold. We state below a number of theorems that provide 
conditions for asymptotic normality in case of independent random variables that are not 
identically distributed.
Theorem 9.6.3 (Liapunov) Let X1 ,X2 , ... be a sequence of random variables such that 
E(Xi) = pi Var(Xi) = a2, and Yi = E\Xi — pi\3. Moreover, put
nn 
n
mn = 52 ^, 
s n = 52 a2, 
r n = 52 Yj,
and let Sn = X 1 + X2 + • • • + Xn be the corresponding sequence of partial sums. Ifaddition- 
ally X1, X2, ... have finite third moments, then the condition
lim rn =0 
(9.62)
n—>^> s3 n
is sufficient for convergence
Sn - mn Л N(0, 1).
The proof of this theorem lies beyond the scope of this book.
As an illustration of the application of the Liapunov theorem, consider a sequence of inde­
pendent trials, such that in nth trial the probability of success is pn. We let Sn denote the num­
ber of successes in the n first trials so that Sn = X 1 + • • • + Xn, where Xi = 1 or 0 depending 

292
RANDOM SAMPLES
on whether or not the ith trial leads to a success. We then have E(Xi) = pi , Var(Xi) = piqi, 
while the third absolute central moment Yi is
Yi = EXi - pil3 = 11 — pil3P(Xi = 1) + 10 — pil3P(Xi = 0) = qipi + p3qi.
Thus Yi = piqi(p2 + qi) < piqi, and
£_ 
E n=1 piqi 
= 
1
sn < (En=ipiqi)3/2 
(En=ipiqi)1 /2.
Consequently, the Liapunov condition (9.62) holds if EП=1 piqi = ж, and we have
Theorem 9.6.4 Consider a sequence of independent trials, with the probability of success in the 
ith trial being pi. If Sn is the number of successes in the n first trials, then
Sn-^n=1 pi - N(0, 1) 
i=1 piqi
•O OO
ifX i=1 piqi = ж.
We close this chapter by stating a theorem that completed the long search for conditions 
implying limiting normality in case of independent random variables (the cases of dependent 
random variables are still the object of intense research).
Theorem 9.6.5 (Lindeberg and Feller) Let X1, X2, ... be a sequence of independent random 
variables with finite second moments. Assume that s П — ж and max1 <j<n^j /s П — 0 as n — 
ж. Then,
Sn — mn - N(0, 1) 
sn
if and only iffor every e> 0,
lim -i 
[ 
(x — pj )2 dFj (x )=0, 
(9.63)
n^° snj=1Jlx-^j [>esn
where Fj is the cdf of Xj .
The “if” part was proved by Lindeberg, so (9.63) is called the Lindeberg condition. The “only 
if” part is due to Feller.
Let us now introduce the notation useful in describing rates of convergence in probabil­
ity. Let V1, V2, ... be a sequence of random variables. The symbol oP (Vn) denotes random 
variables of order smaller than Vn for large n, in other words such that oP (Vn)/Vn -PP 0. Simi­
larly, the symbol OP (Vn) represents a sequence of variables of the same order of convergence 
as Vn, so that the sequence OP (Vn)/Vn converges in probability to a constant (OP (Vn)/ 
Vn - C).
The following theorem is a generalization of a CLT that is very useful when only the 
first two moments, and not the entire probability distribution, are known. The theorem pro­
vides an approximate distribution of the transformed random variables obtained in random 
samples.
Theorem 9.6.6 (Delta Method) Let X1 ,X2 , ... be a sequence of random variables such that
Vn(Xn — ^) - N(0,^2), 
(9.64)

CENTRAL LIMIT THEOREM
293
and let g be a function with a nonzero derivative g' (в). Then
У[g(Xn) - g(в)] ^ N(0,a2[g'(в)]2). 
(9.65)
Proof: The Taylor expansion of g(Xn) around Xn = 0 gives
g(Xn) = g(в) + g'(в)(Xn - в) + op(X - 0\). 
(9.66)
Rearranging (9.66) and multiplying by ^n, we obtain
Vn(g(Xn) - g(в)) = g'(в)vn(Xn - в)Wn op(X - в1),
n(g(g(Xn) - g(в)) = g(вУП(Xn - в) + Op(yffiXn - 0\). 
(9.67)
Based on (9.64), convergence of Xn to в in probability, and Theorem 9.5.5, we obtain
(9.65). 
□
Let us now illustrate the Delta method by an example.
■ EXAMPLE 9.16
Let Xn be a relative frequency of a success in n Bernoulli trials. Find the asymptotic 
distribution of g(Xn) = 1/Xn.
SOLUTION. Let p be the probability of success in a single trial. Then g'(p) = -1 /p2. 
Consequently, based on Theorems 9.6.5, 9.5.6, and the fact that
n(X(Xn -p) ^ N(0,p(1 - p)),
we immediately obtain
1 ) ^ N 0 0, 
p
Пп
1
Xn
(1 - p ) 
p 3
Last we would like to mention two possible extensions of the Delta method. If g' (в) = 0, 
then one can take one more term in the Taylor expansion (9.66). Such approach will yield a 
second-order Delta method (for details see e.g., Casella and Berger, 2002). Also, the Delta 
method can be easily extended to a multivariate setting (see Oehlert, 1992).
PROBLEMS
9.6.1 Let X 1, ...,Xn be a random sample fro^_the distribution with density 
f (x) = xe-x, x > 0. Find c if it is known that P{Xn > c} = 0.75 for n = 250.
9.6.2 Assume that 500 students at a certain college will graduate on a given day. Because of 
space limitations, the college offers each student two tickets for the commencement 
ceremony. From past experience, it is known that 50% of the students will invite two 
guests to attend the ceremony, 20% students will invite one guest, and the remaining 
30% will not attend at all, so they will invite no guests. How many chairs should the 
college order to have at least 95% chance that all attending guests will have seats?

294
RANDOM SAMPLES
9.6.3 Passengers on an international flight have a luggage weight limit B. The actual weight 
W of the passenger’s luggage is such that W/B has a BETA(a, b) distribution where 
a/(a + b) = 0.9. Assume that the weights of luggage of different passengers are inde­
pendent and that the plane has 220 seats. Find a and b if it is known that when the 
plane is fully booked, then there is a 5% chance that the total weight of baggage will 
exceed 200B .
9.6.4 Let X1, ...,Xn be a random sample from the BETA(4, 2) distribution. Let Sn = 
X 1 + • • • + Xn. Find the smallest n for which P{Sn > 0.75n} < 0.01.
9.6.5 A regular dodecahedron (12-sided Platonian solid) has six red and six white faces, 
with the faces of each color labeled 1, ..., 6. If you toss a face with label k you pay 
or win $k, depending on whether the color is red or white. Find the probability that 
after 50 tosses you are ahead by more than $10.
9.6.6 Let X1, ...,X360 represent the outcomes of 360 tosses of a fair die. Let 
S360 be the total score X 1 + ■■■ + X360, and for j = 1, ..., 6, let Yj be 
the total number of tosses that give outcome j . Use normal approxi­
mation to obtain: (i) P(55 <Y3 < 62). (ii) P (1,200 < S360 < 1,300). (iii) 
P (1,200 < S360 < 1,300|Y1 = 55). 
(iv) P (1,200 < S360 < 1,300|Y4 = 55). 
(v)
P(1,200 < S360 < 1,300|x 1 = X2 = • • • = X55 = 4). (vi) Check if continuity 
correction improves approximations in (i)-(v).
9.6.7 A fair coin is tossed 2n times. How large must n be ifit is known that the probability 
of the equal number of heads and tails is less than 0.1?
9.6.8 A rate at which patients arrive to an urgent care center in the evening is one per 6 
minutes. Assuming that the number of arrivals follows Poisson distribution, find the 
probability that more than 35 patients but no more than 50 will arrive to the center on 
a given day between 6 p.m. and 10 p.m. Use normal approximation with continuity 
correction.
9.6.9 Let X 1, ..., Xn be a random sample from EXP(A) distribution. Show that there exist 
normalizing constants An and Bn such that (X 1 + • • • + Xn - An)/Bn has asymp­
totically N(0, 1) distribution.
9.6.10 Referring to Example 7.39, assume that a man’s shoe has an average length of1 foot 
and a = 0.1 foot. Find the (approximate) probability that the mean of 16 lengths of 
men’s shoes exceed1 foot by more than1 inch.
9.6.11 A die is unbalanced in such a way that the probability of tossing k (k =1, ...,6)is 
proportional to k. You pay $4 for a toss, and win $k if you toss k. Find the approxi­
mate probability that you are ahead after 100 tosses.
9.6.12 Let Xn be a sample mean in a random sample X 1, ..., Xn from POI(A) distribution 
and let Tn = n=1 Xi. Use the Delta method to find the limiting distribution of: 
(i) g(Xn) = Vn(Xn — A). (ii) g(Xn) = 1 /Xn. (iii) g(Tn) = log(Tn). (iv) g(Tn) = 
TT[. [Hint: Tn/n has approximately N(A, A/n) distribution (why?).]
9.6.13 Let Xn be a relative frequency of success in n Bernoulli trials. Use the Delta 
method to find the limiting distribution of: (i) g(Xn)= Xn(1 - Xn). (ii) 
g (Xn) = ^Xn (1 - Xn). (iii) g (Xn) ^/(1 - Xn)/Xn.

CHAPTER 10
INTRODUCTION TO STATISTICAL 
INFERENCE
10.1 OVERVIEW
The first 10 chapters of the book were devoted to probabilistic foundations of the theory of 
statistics, we introduced and developed techniques useful for predicting the form of future 
observations (data). Given certain general information (e.g., about independence of some 
events), we could deduce the distributions of observed random variables and answer ques­
tions such as: How many future observations will fall into a certain set? What will be the 
average of those observations?
In statistics (more precisely, in inferential statistics), which will be now our main object of 
study, the question is: Given the data, what can we say about specific aspects of the stochas­
tic mechanisms that govern the occurrence of those data? The actual data are regarded as 
a result of a random process, in the sense that if the data collection were to be repeated, 
the outcome would most likely be different, possibly even leading to a different conclusion. 
Consequently, whatever inference we make from the actual data, it is subject to error. This 
error—the central concept of statistics—is not meant to be a “mistake” of any kind (i.e., 
something that can be avoided).
At first, one might think that this randomness will be eliminated if we increase the preci­
sion of measurement. Actually, the opposite is true. For instance, if we measure the length 
of a table in integer number of feet, the result will be the same under repetition. When we 
increase the precision, to an inch, then to half of an inch, and so on, the variability of the 
results under repetition will be increasing.
The question then arises: What inference can be drawn from data which may differ from 
sample to sample? As a theory, inferential statistics is a part of mathematics, has its own 
structure of specific concepts (motivated mostly by applications), and its own theorems.
Each such theorem asserts that some conclusions hold, provided that certain assumptions 
are satisfied. These assumptions refer to the process of data collection, or the properties of 
underlying random variables.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
295

296
INTRODUCTION TO STATISTICAL INFERENCE
The applicability of statistical methods depends crucially on the degree to which the 
assumptions are met in real situations. Sometimes this degree of validity is under the con­
trol of the experimenter (see Example 10.1); in some other cases, we simply may have no 
conclusive evidence that the assumptions are violated; there could also be situations (see 
Example 10.2) when it may feel justified to disregard the fact that the assumptions are false.
■ EXAMPLE 10.1
Suppose that we want to apply a method of statistical inference, for which we need 
an assumption that a certain random variable X is binomial. Often X represents the 
number of elements of some kind in the sample (number of defective items, number of 
patients who recovered after specific treatment, etc.). The assumption that the process 
of collecting data is really a sequence of Bernoulli trials depends on various factors, 
some of which the experimenter can control. Of these, most important is obtaining 
observations independently. In case of defective items, it may require sampling with 
replacement; in case of patients, it may require checking that the sample does not have 
identical twins or other persons whose reaction to the treatment in question may be 
similar because of some genetic reasons.
■ EXAMPLE 10.2
Imagine that we observe freshmen scores X on an aptitude test. Assuming that X has 
a normal distribution leads to sufficiently good approximations of the relevant prob­
abilities. The fact remains, however, that test scores cannot be normally distributed, 
since X must be an integer, and it also cannot assume negative values.
In cases such as above, we typically feel justified in using the theorems that rely on the 
assumption that X has a normal distribution, even if we know that this assumption is not 
satisfied. But there may be some “more serious” violations of the assumptions. Checking 
the validity of an assumption may involve using some elaborate statistical techniques. Often, 
however, it is sufficient to just have a glance at some preliminary graphical presentation of 
the data, or at the values of some crude statistics. In either case, we deal with a summary or 
reduction of the data. The methods of such initial reduction of the data belong to what is 
called descriptive statistics.
A simple summary presentation of the data can lead to the discovery of surprising and 
important consequences as shown in the three following examples.
The first example below concerns a 1854 cholera outbreak in London during the 
1846-1860 worldwide cholera pandemic.
■ EXAMPLE 10.3
Cholera is a deadly disease, its outbreaks were quite common in Europe in the past. 
The medical community of the nineteenth century London was divided on the cause 
of the disease. Some doctors were thinking that it was caused by inhaling particles of 
dirty organic matter in the air, while others were convinced that cholera was caused 
by the not yet identified germ cell. John Snow, a London physician, had a theory that 
the germ was transmitted from person to person by drinking contaminated water. He 
marked cholera incidents on a city map and noticed a cluster of cases near a Broad 
Street water pump. He then studied water samples from several pumps and found out 
that it was indeed contaminated water that allowed the spread of the disease rather 
than particles in the air. In places that switched to cleaner water sources, the disease 
ceased in few days.

OVERVIEW
297
The next two examples both concern the World War II.
■ EXAMPLE 10.4
The main route for supplying the Allied armies fighting Nazi Germany in Europe 
during World War II was through the Atlantic Ocean. The convoys were attacked 
regularly, mostly by German U-boats. As the war progressed, more and more data 
accumulated. It turned out that the average number of ships lost in an attack was 
relatively constant; in particular, it did not depend on the size of the convoy. This 
observation led to a simple conclusion: to decrease losses, make convoys as big as 
possible. Indeed, two separate convoys might expect to be detected and attacked about 
twice as many times as a convoy obtained by combining them. Since the average losses 
per attack are independent of the convoy size, such joining of two convoys cuts losses 
by half. This simple idea contributed substantially to winning the war.
■ EXAMPLE 10.5
During the World War II, bombers were sent on missions over Germany. On route to 
and from, as well as over the target, they were subject to antiaircraft fire. The direct 
hits were not very frequent, but the AA shells were set to explode at specific altitudes, 
spraying the planes with shrapnel. The planes that returned from the mission were 
examined for locations of shrapnel hits, and all these locations were recorded on a 
silhouette of the plane. As more and more data became available, the silhouette was 
more densely covered with recorded locations of hits. There were, however, some areas 
that were hit less often than others.
A surprising order was then given: strengthen (by putting armor plates, etc.) those 
areas that were hit seldom. Here the argument is that the locations of shrapnel hits on 
bombers must have a uniform distribution over the silhouette of the plane. Any “white 
areas” in the data therefore indicate the locations of hits for the planes that did not 
return from missions.
We present these three examples not only because of their combination of simplicity of 
premises and unexpectedness of conclusion but also because they are all based on elementary 
ways of representing the data: marking disease incidents on a city grid, plotting average losses 
per attack against convoy size, or making a scatter diagram of shrapnel hits. Certainly it is 
not often that one gets a chance of contributing to victory in war or ceasing a pandemic 
by a visual inspection of some descriptive statistics. Nevertheless, it is worth knowing some 
simple “tricks of the trade” in presenting the data so as to exhibit certain aspects of interest, 
or in making certain patterns visible. While graphs are necessary to examine the content and 
the structure of the data it might also help checking assumptions in statistical models. It is 
also hard to overestimate importance of the graphs in communicating results of statistical 
data analysis.
In the first two editions of this text (1997 and 2008), we introduced simple (but often 
very useful) methods of presenting the data such as dot diagram, box-plot, histogram, and 
stem-and-leaf diagram often known as a numerical histogram. Today, these graphical meth­
ods are usually introduced in introductory statistics courses. However, with the constantly 
growing data sizes (in both, the number of variables and in the number of records) and more 
and more powerful computers, new graphical techniques are now becoming available. They 
can be used to see data in layers, three dimensions, to create statistical maps, to name just 
a few. One can find these graphical methods in most statistical packages, including R and 
ggplot2- its library for creating graphics. The R-code for the basic graphical methods can be 
found in Appendix at the end of the book.

298
INTRODUCTION TO STATISTICAL INFERENCE
10.2 
BASIC MODELS
Statistical methods are used to choose an action (or make decisions) in the situation of partial 
uncertainty. The uncertainty may be alleviated to some extent by taking observations and 
identifying factors that affect the consequences of possible actions.
We will introduce two approaches to statistical inference: frequentism and Bayesianism. 
While they are different and were considered competing for many years, they are becoming 
more connected in the contemporary statistical methodology.
Now let us imagine ourselves as decision makers. Using the terminology accepted in gen­
eral decision theory, we say that we are in one of the situations labeled as “world 6 1,” ..., 
“world 6n,” but we do not know which one. It is usually assumed that there is one action 
appropriate for each “world” (although this assumption is not really necessary). Thus, ifwe 
knew the “world” we are in (i.e., knew the value 6j), we would know which action is the best 
to take.
The only way to identify the actual “world 6j” is to perform some experiments and gather 
data. Let X be a generic symbol for the results of such experiments. It may be a single obser­
vation of some variable, a sequence of observations, a result of some complicated physical 
experiment, a score on a battery of tests, and so on, depending on the context. Naturally, 
to make the entire setup meaningful, there must be some relation between X and 6j . This 
is expressed by the assumption that the observation X, while being random, comes from a 
distribution that depends on 6j. The randomness here is the crucial part of the entire setup. 
It may be due to sampling variability or be inherent in the phenomenon, or both.
It may happen, of course, that observation X will allow us to identify the value 6j without 
ambiguity. This occurs when the sets of possible values of X are disjoint for different 6j ’s. 
Such cases, however, are rare in real life. Most often, we face a challenging case when the same 
outcome X is possible under several (or even all) 6j but occurs with different probabilities, 
depending on 6j .
■ EXAMPLE 10.6
The examples of situations falling under this scheme abound in science, engineering, 
management, and in everyday life. A doctor faces a patient who has a headache and 
high fever. Particular “worlds” are possible illnesses of the patient. The doctor orders 
some tests, and on the basis of their results X makes a diagnosis (identifies the illness, 
perhaps incorrectly) and chooses the best action in view of the illness diagnosed. As 
another example, take a pharmaceutical company that has developed a drug against a 
specific disease, hopefully superior to drugs used thus far. The “worlds” may be num­
bers 6 describing the relative advantage of the new drug vs. the best drug available so 
far, with 6 > 1 indicating that the new drug is better, and 6 < 1 indicating that it is no 
better (or even inferior) to the drug used thus far. Here, the observation X is a series 
of studies, specified in great detail by the U.S. Food and Drug Administration (FDA) 
standards.
Example 10.6 concerns medicine, but it is obvious that any new method is subject to the 
same scheme of tests before it is established whether or not (and to what extent) it is superior 
to some other method.
Statistical theory is concerned with the problem of inference about 6 on the basis of X. 
In the case where there is a choice of the variable that we may observe, the statistical theory 
is also concerned with choosing the “best” variable (these are called problems of design of 
experiment). Such statistical theory is known as classical or frequentism.
But there is also a different approach, known as Bayesian. While developed later than 
the classical approach, it is based on a theorem (or a “rule”) named after Reverend Thomas 

SAMPLING
299
Bayes who first provided a formula for combining the prior knowledge with the new evidence 
in his 1763 paper.
Under the Bayesian approach, we assume that it is possible that the user of statistical 
methods already has some knowledge or previous experience, about the possible “words.” 
This knowledge makes some of the “words” to appear more likely than others, before any 
observations X are taken. Such information can then be updated based on the collected data 
and used in the process of deciding about Qj on the basis of observation x (one can then 
simply compute the conditional probability of в j given X = x). For example, in the case of 
a physician seeing a patient with a headache and high fever, the possible “worlds” (in this 
case illnesses causing this particular set of symptoms) include initial stages of flu as well as 
the initial stages of the plague (Bubonic plaque). The incidence of the latter disease is so 
rare, however, that the doctor may feel perfectly justified in not ordering any test to check 
the possibility of the disease being the plaque. Here the doctor relies simply on his own and 
his colleagues’ experience about the incidence of various diseases that might start with fever 
and headache at a given time and geographic location.
Statisticians who allow probabilities of various “worlds” reflecting the researcher’s expe­
rience, intuition, “hunches,” and so on, to be used in statistical methodologies are called 
Bayesians, and the resulting statistical methodology is called Bayesian statistics (to be dis­
cussed in Chapter 16.4).
A rather strong argument for the Bayesian approach is provided by the theory of outliers 
(see Section 9.3). In a non-Bayesian setup, where в = (a, X) is the parameter in the family 
of all gamma distributions, no configuration of data values can be rejected as containing 
an outlier, even if (say) n - 1 observations fall into interval (0, 1) and the nth observation 
exceeds 106. This is because there exists a в =(a, X), for which such a configuration of data 
points is very likely to occur. This counterintuitive example suggests that a statistician should 
eliminate some domains of the parameter space as “unlikely,” using whatever information 
or experience he or she has. We will provide Bayesian solutions to various problems under 
consideration. This means that we will show how the problem is, or may be, solved if the 
prior probabilities of various Qj’s are available. While the basics of the Bayesian statistics 
will be presented in Chapter 16, a systematic presentation of the theory of Bayesian statistics 
lies, however, beyond the scope of this book.
10.3 
SAMPLING
In the theory of statistics, it is typically assumed that the data are observations of some 
random variable. The applicability of statistical methods depends therefore on how well the 
assumption of randomness and the assumption about the distribution are satisfied. In this 
section, we will show some of the possible “traps” one may encounter in implementing sta­
tistical methods in practice.
Let us start with an example.
■ EXAMPLE 10.7
Before the presidential election in 1936 , the Literary Digest (one of the most respected 
magazines of the time) conducted a poll and published a prediction that Alfred Landon 
would get 57% of the vote against Roosevelt’s 43%. Surprisingly, the actual results of 
the election were 62% for Roosevelt against 38% for Landon. The irony of the situation 
was that the Literary Digest poll was one of the largest and most expensive polls ever 
done, with a sample size of around 2.4 million people! At the same time, George Gallup 
was able to correctly predict a victory for Roosevelt using a much smaller sample of 
about 50,000 people.

300
INTRODUCTION TO STATISTICAL INFERENCE
Unfortunately, poorly designed sampling strategy cannot be improved by increasing 
the size of the sample. While in general, increasing the size of the sample increases the 
amount of information and helps to make a better inference, but only of the sample is 
representative of the population. Increasing sample cannot reduce the sampling bias, 
on the contrary might even inflate it.
The huge Literary Digest’s poll bias had two sources, one so-called : selection bias 
and the nonresponse bias. Selection bias was caused by the fact that the mailing list 
was created using telephone directories, lists of magazines’ subscribers, and club mem­
bership lists—all of which included mostly middle and upper-middle class voters (tele­
phones were the luxury at that time). Nonresponse bias was caused by the low response 
rate (about 25%). People who respond to surveys and not the same as people who 
do not.
Suppose that the objective is to estimate an unknown parameter 6 that is the average of 
some attribute in a population. It may be, for instance, the average yearly income of a family 
in a given region, the average age ofa patient receiving certain treatment, and so on. In such 
cases, one typically takes a sample of elements from the population and measures the values 
of the attribute being studied. Thus, X =(X1,...,Xn),whereE(Xi)=6 for i =1,...,n.
The following story illustrates some of the potential problems that one may encounter.
■ EXAMPLE 10.8
Three social science students, Jim, Joe, and Susan, were each assigned a task of esti­
mating the average size of a class (number of students) in a given school district. Jim 
decided to make a card for each class in each school, shuffle the cards, sample one or 
more of them and then find the number of children in each class sampled.
Joe found a somewhat simpler scheme: He decided to prepare cards with names of 
schools and first sample a school (or several schools). Then for each school chosen, he 
decided to make cards with labels of classes and take a sample of those cards, at the 
end determining the numbers of children in each class sampled.
Susan applied a still simpler scheme: She decided to take a sample of children from 
the school district and ask each child about the size of the class that he or she attends. 
The question is: Which of the three students, if any, measured the parameter “average 
size of the class in a given school district”?
Since an increase of sample size affects only the precision of the estimator, not the 
parameter that is being estimated, for simplicity we will consider only the cases where 
Jim, Joe, and Susan each take a single observation.
Suppose that there are k schools in the district in question, with the ith school having 
ni classes, of sizes Cij,i=1,...,k,j =1,...,ni. Then, the total number of classes is 
N = k=1 ni, and the average class size is
6 = N E E Cij.
i=1 j=1
The objective is to estimate 6.IfX, Y, and Z denote the random variables observed, 
respectively, by Jim, Joe, and Susan, then it is clear that X = Cij with probability 1/N 
(sampling is from the set of all classes). Thus, E(X) = 6.
For the random variable Y observed by Joe, we have Y = Cij if Joe selects ith school 
(probability 1/k) and jth class in the ith school (probability 1/ni ). Consequently, 
k ni 
k 
ni
E (Y )=EE kn Cij = -k E - E Cij
i=1 j=1 i 
i=1 i j=1

SAMPLING
301
We have E(Y) = в except in a special case when all ni ’s are equal, meaning each school 
has the same number of classes.
Finally, for the random variable Z, observed by Susan, the situation is as follows: 
Let C = k=1 n= 1 Cij be the total number of children in all classes. With probability 
Cij /C, a child from the jth class of the ith school will be selected, and then the value 
of Z will be Cij . We have therefore
k ni 
k ni 
k ni
E (Z) = ES Ci> P {Z = Ci,) = Y.Y. CuC = C ES Cj 
i=1j =1 
i=1j =1 
i=1j =1
Again, E(Z) = в unless all classes are of the same size.
Thus, it is only Jim whose method provides an estimate of the parameter в. For ran­
dom variables suggested by Joe and Susan, we generally have E(Y) = в and E(Z) = в. 
The method suggested by Joe is known as stratified sampling: The population is divided 
into strata, and one first samples strata, and then takes a sample from each stratum (in 
this case, the role of strata is played by schools).
It is worth mentioning here that if Joe decided to take a sample of schools, and then 
collect the data about all class sizes in selected schools, he would use what is known as 
cluster sampling.
With some prior information available (e.g., about relative sizes of the strata), one 
can easily adjust Joe’s estimator (by taking appropriate weighted averages) to build 
random variable Y with E(Y) = в (called an unbiased estimator of в).
The situation with the Susan’s method is not so straightforward and cannot be easily 
remedied. It is related to importance sampling, where the probability of choosing an 
element with a larger value of the attribute is higher than the probability of the element 
with a smaller value.
The bias due to the phenomenon of importance sampling occurs quite often and evades 
notice. The following example (suggested by R. F. Green, personal communication) provides 
some surprising insight into the issue.
■ EXAMPLE 10.9 Siblings
Suppose that in a certain society, the distribution of the number of children in a family 
is Poisson with mean 4. What is the average number of siblings ofa child in this society?
SOLUTION. While most intuitive answer seems to be 3, it is actually 4 if we assume 
Poisson distribution. In general, it is more than 3, except when all families have 
exactly 4 children. The situation is very much the same as with Susan’s sampling in 
Example 10.8.
Before proceeding to the solution, we should note that the distribution given in the 
problem concerns the population of families, but the question concerns the average in 
the population of children. Let p0, p1,... be the distribution of the number of children 
in the family, so that in the special case under analysis, we have pk = (Ak/k!)e-x for 
A = 4. Then, p = p 1 + 2p2 + • • • and a2 = k2pk - p2 are the mean and variance of 
the distribution {pk}. Suppose that the population consists of a large number N of 
families. Clearly, Np0 families have no children, Np1 families have one child, and so 
on. The total size of the population of children is therefore
M = Np 1 + 2 Np 2 + 3 Np 3 + • • • = Np,.

302
INTRODUCTION TO STATISTICAL INFERENCE
The probability of choosing a child from a family with k children is
kNpk = kpk 
Na a
for k =1, 2,... and such a child has k - 1 siblings. Then, the average number of sib­
lings is
Q = E (k -1) kpk =1 (e k2 Pk - t kPk 
k=1 
k=1 
k=1
= — {&2 + A — a} = --- + A — 1.
AA
As can be seen, we have Q > a — 1 with Q = A - 1 in the case where a2 =0 (i.e., 
when all families have the same number A of children). For the Poisson distribution 
a2 = a = X, so we have Q = A = 4■
A sampling bias closely related to the bias from importance sampling is connected with 
the following phenomenon, which caused some controversy before it became properly under­
stood. To explain it, we will again use an anecdotal example.
■ EXAMPLE 10.10 Renewal Paradox
An objective is to estimate the average lifetime of electric bulbs of a particular type, all 
produced by the same company. We assume that the distribution of the lifetime T is 
exponential with mean E(T) = 1 /X.
The usual procedure is to take a random sample of bulbs and observe their lifetimes 
T1 ,T2 ,...,TN . Such data can be used to estimate E(T). If testing is run in parallel, 
it takes time TN:N = max{T1,...,TN} to collect the data. One could speed up the 
procedure by observing only the k shortest lifetimes T1:N < T2:N < ''' < Tk: N and 
then interrupt the data collection, recording only that Tk +1: N > T*, where T* is some 
threshold (so that N — k lifetimes are not fully observed, but they are all known to 
exceed T*). This is called censoring of the data.
In some cases, another way can be used to collect data, that does not involve wait­
ing. Suppose that there is a large building where the maintenance personnel use only 
bulbs of the type of interest for us. Whenever a bulb fails, it is immediately replaced 
by a new bulb, and this change is recorded. As a consequence, we have access to the 
records, reaching into the past, of the time of replacement of every bulb. We might then 
select some time t* (preferably in the past) and use all lifetimes of the bulbs that were 
operating at time t* as the sample. Clearly, if t* is sufficiently far back in the past, each 
of the bulbs that operated at t* has already been replaced, and their lifetime T(t*) is 
known. Otherwise, we would have to wait for some time to observe the value of T(t* ) 
for that bulb.
Let T' be the spent lifetime at t* for the ith bulb, and similarly, let T" be the residual 
lifetime at t*. Moreover, let tp denote the current time. It is clear that iftp — t* is large 
enough, all residual times will be observable and their lifetimes will be T = T' + T", 
otherwise residuals will be at least tp — t* and consequently lifetimes will be at least 
T' + tp +1" . The sample T1 ,T2,.. .,TN of all N bulbs that were operating at t* can 
be observed and the average (1 /N) N1 Ti(t*) can serve as an estimator E(T).
The obvious question is: Is such a method of collecting data correct? It should 
be stressed that we are not concerned here with the practical implementation of the 
scheme. We assume that the time t* is chosen without the knowledge of the replacement 
records (a condition preventing conscious or unconscious bias) and disregard the fact 

SAMPLING
303
that in reality light bulbs are used only part of the time, and that at some locations 
lights are used more often or are subject to different conditions (outdoor and indoor 
lights, etc.). Since the problem concerns theory, we deliberately idealize the situation 
and assume that the data concern only bulbs that operate constantly and under the 
same conditions. This way the interreplacement times are sampled independently from 
the same exponential distribution.
To find the answer, consider a single process of changing of bulbs in one place. The 
process starts at time t = 0; the consecutive lifetimes are £ 1, £2,..., and the times of 
replacements are S0 = 0, Sn = Sn- 1 + £n for n > 1. The lifetime recorded in the sam­
ple, T(t*), is the value £n = Sn - Sn- 1 such that Sn- 1 < t* < Sn. We assume that 
£1 ,£2 , .. . are iid with exponential distribution.
The distribution of the time Sn of the nth replacement was derived in Section 8.3.
It is a gamma distribution with parameters n and A so that the density of Sn is
nn
gn(t) = , n 1 - = 7------' 1 e-xt. 
(10.1)
Г( n) 
(n — 1)!
For further use, observe that we have
~ 
~ (At) n- 1 
.
EX (t ) = *E —Tji e 
= A. 
(10.2)
To find E[T(t*)], we must first find FT(t*)(x) = P{T(t*) < x}, the cdf of T(t*). 
Assume that x<t* . Then a replacement would have occurred before time t* , 
since otherwise the original bulb would still be working at t* , and we would have 
T(t* )=£1 >t* >x.
Thus, for some n =2, 3,... we must have Sn-1 = z < t* <Sn = Sn-1 + £n. In this 
case, £n >t* - z so that t* - z<£n < x. The condition £n < x implies t* - z < x, 
which means that the time z of the (n - 1)st replacement satisfies t* - x < z < t* . 
Partitioning with respect to n =2, 3,..., conditioning on time z (time of the (n - 1)st 
replacement), and using (10.2), we obtain
TO tt*
FT(t*)(x) = P{T(t*) < x} = 52 I 
P{t*— z <£n < x}gn- 1(z) dz
n=2j t*-x
= 52 It [e-A(t*-z) - e-XX]gn- 1(z) dz 
n=2 t*-x
= I t [e-X(t*-z) — e-Xx] 52 gn- 1(z) dz 
Jt-xX 
n=2
= A j* 
[e-x(t*-z) — e-Xx] dz =1 — e-Xx — Xxe-xx.
If x>t* , the derivation above has to be modified in two ways. First, we have to add 
the probability that the first bulb is still working at t*, and that its lifetime £1 satisfies 
t* <£1 < x (see Figure 10.1). Second, if a replacement occurred before t*, the time
T(t*)
-I---------------------------- 1-------- 1-
S0 
t* 
S1
Figure 10.1 Lifetime T(t*) of a bulb.

304
INTRODUCTION TO STATISTICAL INFERENCE
Sn- 1 = z of last replacement before t* satisfies the inequality 0 < z < t*. Conse­
quently, we have
P{T(t*) < x} = -t - e-Xx + £ [t [e-(tt-z) - e-Xx]gn- 1(z) dz 
n=2 0
= 1 - e-Xx - Xt* e-Xx.
Differentiating, we obtain the density of T(t* ):
( X2xe-Xx 
for x < t*
fT(tt)(x) = I x(1 + Xt*)e-Xx 
for x > t*.
An easy integration gives the formula for E[T(t*)], and we can show that
lim E[T(t*)] = 2.
tt —>^ 
X
(10.3)
Therefore, on average, the lifetime of the bulb that is in operation at time t* is about 
twice as long as the average lifetime of other bulbs. So the described method of sampling 
is biased.
The conclusion above about sampling procedure being biased remains valid as long 
as the lifetimes £ 1, £2,... are iid. The specific assumption of exponentiality of distri­
bution implies the form (10.3) of the density, but the fact that limtt—cE[T(t*)] > 
E(£) is valid for any nondegenerate distribution of £i’s (e.g., see Karlin and Taylor, 
1975).
Since T(t*) = T' + T", meaning T(t*) is the spent lifetime at t* plus the residual 
lifetime at t*, we can try to derive our result as follows: The residual time T" is exponen­
tial, in view of the memoryless property of exponential distribution, so E(T") = 1 /X. 
For the spent lifetime T', it cannot exceed t*, and it exceeds x (where x < t*) if there 
are no replacements between t* - x and t*. Since replacements form a Poisson process, 
the latter probability is e-X(tt-x). Consequently
e-X(tt -x)
P{T' > x} = 
0
for x <t*
forx > t* .
Thus, by Theorem 7.2.2
ОС 
tt
E (T' )= f P {T' >x} dx =( e-X (tt-x) dx =1(1 - e-Xtt), 
0 
0X
and therefore E[T(t*)] = E(T') + E(T") = 2/X - (1 /X)e-Xtt. This calculation, how­
ever, relies on the assumption that the memoryless property of the exponential dis­
tribution is valid for residual waiting time counted from a randomly selected moment 
(and not only from a fixed moment).
For example, suppose that we observe the waiting time for nearest replacement from 
the moment preceding a given replacement by some fixed constant, say 5 hours. Such 
a moment is random, and yet the waiting time is at most 5 hours by definition, and 
therefore does not have exponential distribution. This simple example shows that the 
notion of a “random moment” has to be qualified: We are not allowed to know the 
future at the time we select our moment to start the observations.

MEASUREMENT SCALES
305
10.4 MEASUREMENT SCALES
Data sets can be of different types, have different characteristics, and different types require 
different statistical methods. We will now introduce some concepts related to the level of 
measurements. Consider a set of objects of some kind. Typically, for the purpose of analysis, 
statistical description, and so on, each of these objects can be represented by a number b(x) 
assigned to object x. Often that number represents the result of measurement in some units, 
but sometimes it identifies only the class to which the object belongs.
If b(x) > b(y), then x has “more ...” than y (is heavier, longer, warmer, older, etc.). 
The question we want to address is which type of statements expressed through the val­
ues of b are meaningful and which are not. To take an example, if b represents length, and 
b(x)=10,b(y)=5,wesaythatx is twice as long as y, since b(x)/b(y) = 2. This statement 
will remain valid whether we express the length in inches, centimeters, or miles: the values 
b(x) and b(y) will change, but their ratio will remain the same. However, if b represents tem­
perature and b(x)=10,b(y)=5, it makes no sense to say that x is “twice as warm” as y. 
Indeed, it is enough to express temperature on a different scale (e.g., change from Fahrenheit 
to Celsius): The ratio of temperatures will change as the scale changes. The question there­
fore is: Why are the ratios of scale values meaningful for length, duration, or weight, but not 
meaningful19 for temperature?
19Observe that the precision of measurements has nothing to do with the answer. Ratios of lengths make sense even 
if the lengths are determined imprecisely; the ratios then are simply subject to bigger errors. But the ratios of the 
temperatures make no sense even if the temperature is measured with the most precise devices available.
The full impact of such questions became apparent only when physical, mathematical, 
and statistical methods started to be used in the social sciences. Here the attributes that one 
considers are typically “soft,” and the use of certain methods can lead to conclusions that 
are illegitimate, but have the deceptive appearance of being very precise (the statement that 
a new brand of instant coffee “tastes 11.3% better” may be effective in commercials, but its 
meaning, if any, is obscure).
Itis clear that the decision which statements expressed through the values b(x) are allowed 
and which are not must lie in the analysis of the nature of a measured attribute.
The measurement is an assignment of numbers to objects in some set A (hence it is a 
function on A). This function must satisfy conditions that “mimic” the empirical relations 
R1,R2,..... If such a function exists, we say that measurement exists.
The following examples illustrate the above description.
■ EXAMPLE 10.11 Scale of Hardness
Let the objects under consideration be minerals, and let the empirical relation > be 
defined as x >- y if mineral x scratches mineral y. We will assign numbers h(x) to 
objects x in A (minerals) to represent their hardness, in the sense that h(x) > h(y) 
whenever x >- y. One such assignment gives the value 10 to diamonds and lower val­
ues to other minerals. This choice of assignment of numbers to minerals is arbitrary, 
except that the relation > between values of function h must mimic the relation > 
between arguments of h (i.e., minerals). It is precisely this degree of arbitrariness of h 
that makes it meaningless to claim that “x is twice as hard as y” if h(x)/h(y) = 2.
But even in such a simple case as above, the possibility of assigning numerical scale 
values h (x) to minerals x in A results from the fact that the relation >- (of scratch­
ing) is transitive: if x >- y and y >- z, then x >- z. Still the existence of a function h that 

306
INTRODUCTION TO STATISTICAL INFERENCE
mimics the relation >- is not obvious. Imagine that infinitely many new minerals, each of 
different hardness, are suddenly discovered. Could one still find enough distinct num­
bers to label those minerals? The answer is positive, but we will not provide the proof 
here.
■ EXAMPLE 10.12
Consider now an attribute such as length and a possible measurement system for it. We 
have here the relation of comparisons with respect to length, accomplished empirically 
by putting the objects parallel to each other, with one end lined up (like pencils). We 
then obtain a relation, , interpreted as “not shorter than.” The ultimate goal is to 
show the existence of a function b (length) defined on A, such that x y if, and only if, 
b(x) > b(y). Clearly, we must require that > satisfies some conditions (axioms), such 
as transitivity: if x > y and y > z, then x > z, and so on.
However, one relation > is not sufficient to define length as we know it, since there may 
be many functions b satisfying the requirement that agrees with the order induced by the 
values of b. Clearly, something more is needed to force all functions b to differ one from 
another only by the unit of measurement (i.e., such that if b and b* are two assignments of 
lengths, then b* = ab for some a > 0).
In this case we need a ternary relation describing the operation of concatenation, that is, 
putting the objects end to end. Letting о denote such an operation, we obtain new objects, 
such as x о y, corresponding to x and y aligned one after another. This operation can be 
identified with a relation that holds between x, y, and z, if x о y ~ z, where ~ is defined by 
a ~ b if a > b and b > a. Clearly, we want b(x оy) = b(x) + b(y), and to achieve that, the 
relations > and о jointly must satisfy a number of conditions, such as the most obvious 
ones: if x > y, then x о z y о z for every z, and (x о y) о z ~ (z о x) о y, for all x, y, z. Less 
obvious is the requirement of the Archimedean property:
For every x and y there exists n such that x ° n > y,
where x ° n = x о ••• о x (n times).
A measurement theory of length is then a relational system consisting of set A, relations 
and о, a set of conditions for and о (referred to as axioms), and a theorem asserting 
that if these axioms are satisfied, then:
1. There exists a real-valued strictly positive function b on A such that
b (x о y) = b (x) + b (y) and x > y if and only if b (x) > b (y).
2. Ifb* is any other function satisfying condition 1, then b* = ab for some a>0.
The first part of the assertion provides the existence of measurement b, and the second 
part provides information about its uniqueness. In the case of length, the measurement is 
unique up to the choice of unit of measurement, so that the ratios of lengths are invariant. 
This means that for any objects x,y the ratio b(x)/b(y) does not depend on the choice of 
function b.
Each scale has its own level of “uniqueness,” described by a condition corresponding to 
condition (2) in Example 10.12. Although theoretically there may be infinitely many types 
of scales, in practical situations one encounters only four major types of scales, as specified 
in Definition 10.4.1.
Consider a relational system, where b and b* are any two assignments of numbers 
to objects in the set A—measurement scales specified by the axioms of the relational 
system.

MEASUREMENT SCALES
307
Definition 10.4.1
(i) 
If there exists a > 0 such that b* (x) = ab(x), then the measurement is on the ratio scale. 
(ii) If there exists a > 0 and в such that b* (x) = ab(x) + в, then the measurement is on the 
interval scale.
(iii) If there exists a monotone increasing function u such that b* (x) = u[b(x)], then the 
measurement is on the ordinal scale
(iv) If there exists a one-to-one function v such that b* (x) = v[b(x)], then the measurement 
is on the nominal scale. 
□
In other words, for ratio scales (see Example 10.12), the measurement is unique up to a 
choice of unit (examples are length, duration, etc.). For interval scales, one can choose not 
only the unit but also the zero of the scale (e.g., temperature). For ordinal scales only the 
order matters. For instance, if b(x) = 10 and b(y) = 2, then all that we can say is that x is 
“more ...” than y, on an attribute designated by ..... We cannot meaningfully say that the
“difference” between x and y is 8, or that x is “five times ...”asy. The reason is that b(x) = 
10 and b(y)=2can be replaced by b* (x) = 100, b* (y)=-3,orb* (x)=1,b* (y) = 0.99, or 
any other two values, as long as the first exceeds the second.
In physical measurement, the best such scale known is that of hardness (see 
Example 10.11) when the main empirical relation is x > y if “x scratches y.” In the social 
sciences, the situation is not so clear. The relations between stimuli elicited by asking 
subjects to evaluate them “on the scale of 1 to 10” or by marking responses such as 
“strongly agree,” “agree,” and so on, are of the ordinal nature but often are incorrectly 
treated as if they are expressed on an interval or ratio scale.
The same concerns education, where grades are averaged and compared as if they were 
measured on an interval scale. Thus a student who takes six classes and gets one A and five 
B’s as the semester grades has a GPA of 3.16. Another student, who also takes six courses, 
gets four A’s, and two C’s, has a GPA that is higher (3.33). If the scoring (function b defined 
on grades A, B, C, etc.) were changed to b(A)=4,b(B)=3,b(C)=1, that student’s GPA 
would be 3.00 and his grades would be judged as worse than these of the first student.
There is nothing unique or objective in assigning the values 4, 3, and 2 to grades A, B, 
and C, considering that the process of averaging grades usually includes different subjects, 
grades by different teachers, and with criteria often formulated rather vaguely. Nevertheless, 
tradition and the practical need to assess students’ performance force one to fix the scoring 
system for grades, and regard them as a measurement on an interval scale.
Finally, the nominal scale—the weakest of the four—can hardly be regarded as measure­
ment, since the numbers serve only as labels, for the sole purpose of identification (e.g., 
numbers on jerseys of football players).
The four scales mentioned above form an order: any transformation b* (x) = ab(x), a > 0 
allowed for the ratio scale is a particular case of a transformation b* (x) = ab(x) + в, a > 0 
that defines the interval scale. This transformation is monotone, hence allowed for the ordinal 
scale, and in turn, each monotone transformation is one to one, allowed for the nominal scale. 
One can always lower the level of measurement, while to use a higher measurement level is 
incorrect.
The theory of measurement scales, as outlined above, was introduced by Stevens (1946). 
It rapidly gained popularity in psychology and the social sciences and was developed into a 
highly sophisticated theory (e.g., see Krantz et al., 1971, or Roberts, 1979). The four types 
of scales, as defined above, are most commonly encountered and popularly known.
The types of statistical methods that one can sensibly use depend on the type of the scale. 
While the mean ^ and standard deviation a are defined in both cases, one should not use 
the coefficient of variation a/p, in the case of data values measured on the interval (but not 
ratio) scale. This is because under transformation y = ax + в (a>0) the standard deviation 

308
INTRODUCTION TO STATISTICAL INFERENCE
becomes multiplied by a, while the mean becomes multiplied by a and shifted by в. Therefore 
the value a/p, depends on the choice of zero of the scale.
On the other hand, for data measured on the ordinal scale only, the mean and standard 
deviation are not invariant, and only statistics expressed through ranks (e.g., median and 
other quantiles) should be used. Finally, for data on the nominal scale, one is allowed to use 
only class frequencies.
In Chapters 11-13, it is assumed that the data represent measurements on the interval 
scale. This allows us to use such characteristics as the mean and standard deviation, and 
to assume that the data follow a normal distribution.20 Chapter 14 concerns methods of 
handling the data measured on ordinal scales only (more precisely, only when ordinal rela­
tions are taken into account). Finally, in Chapter 15 we discuss the case of categorical data, 
expressed on the nominal and/or ordinal scale with data grouped into classes.
20Strictly speaking, ifX is measured on a ratio scale, it cannot have normal distribution (since negative values are 
ruled out for ratio scales). Such level of adherence to the rules, imposed by scale types, would drastically impoverish 
the scope of statistical applications by absurdly disallowing to treat attributes such as height, weight, size, duration, 
etc., in certain populations as normally distributed, merely because these attributes cannot be represented by a 
negative number.

CHAPTER 11
ESTIMATION
Tn=T(X1,...,Xn)=
n
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
309
11.1 INTRODUCTION
Estimation is the process of extracting information about the value of a certain population 
parameter в from the data. Consecutive observations (data points) x 1, x2, ... are selected at 
random from the population being studied and are considered values of some random vari­
ables X1, X2,   So if the same experiment of taking n observations were to be repeated, 
the new data points would most likely be different. The statistical laws that govern the vari­
ability of data under repetition (actual or hypothetical) can be used to build the theory of 
statistical inference. In estimation theory, it is usually assumed that the distribution of each 
observation Xi is known, except for the value of some parameter в. An estimator of в is then 
a rule that allows us to calculate an approximation of в, based on sample X1 , ...,Xn .
■ EXAMPLE 11.1
Let X1, X2, ... represent the weights of successive trout caught at a certain location. 
We are interested in a parameter such as в = P {Xi > w0}, where w0 is some fixed 
weight, so that в is the fraction of trout whose weight exceeds a given threshold w0 .
Given the observed weights X1 , ...,Xn , we want to estimate в as
number of i such that Xi > w0
The formula above gives an obvious, and rather unsophisticated estimator of в as a 
relative frequency.
There is another method of estimating the same parameter. Assume that the 
weights of trout follow a normal distribution N(^, a2). Given the sample X 1, ..., Xn, 
we then calculate the sample mean X = (1 /n)(X 1 + • • • + Xn) and sample variance

310
ESTIMATION
S2 = [1 /(n - 1)] 
(Xi - X)2. Both X and S2 can be regarded as approximations of
/л and a2, respectively. Consequently, we estimate в as
Un = U (X1 ,...,Xn ) = 1 - ф( w0-XY 
(11.1)
S
where Ф is the cumulative distribution function (cdf) of a standard normal variable.
Here the rationale is that
в = P{X > w0} = P | Z > w0 - M } = 1 - Ф ( w0- M
which is approximated by (11.1).
The example above shows that there can be several estimators of the same parameter (i.e., 
several distinct rules of calculating an approximation of в, given the sample). Since every 
estimator, such as Tn and Un in Example 11.1, is a random variable, the obvious questions 
are:
1. How to assess the performance of estimators and to choose the best one?
2. Are there methods for obtaining estimators other than “ad hoc” methods, used to obtain 
estimators Tn and Un in Example 11.1?
A systematic attempt to answer these two questions resulted in a theory with a clear con­
ceptual structure, supported by powerful theorems. The empirical situation is such that we 
observe values of independent random variables X1, X2, ..., sampled from the same distri­
bution f(x, в), where f is a density or a probability function, depending on whether the Xi’s 
are continuous or discrete. This distribution depends on a parameter that assumes some 
value в (unknown to the observer) from a parameter space 0. The examples abound: the 
Xi ’s can be Bernoulli observations for an unknown probability of success в, or normally 
distributed observations with an unknown mean в and a known standard deviation, or with 
a known mean and an unknown standard deviation в, and so on.
To answer question 1: How to assess estimators? Let Tn = Tn(X1, ...,Xn) be the esti­
mator for a random sample of size n, namely some function of observations X1 , ...,Xn , 
selected to approximate в. The first requirement for a “good” estimator is its consistency, 
defined by the requirement that Tn ^ в. Since Tn’s are random variables, we must specify 
the type of convergence (e.g., in probability or almost surely). The need of consistency is 
obvious: estimators that are not consistent do not guarantee that one gets closer to the true 
value of the parameter by increasing the sample size.
If E(Tn) = в for every n, then estimator Tn is called unbiased. This means that if the 
estimation were to be repeated several times for different samples (but with the use of the 
same estimator), the results would be, on average, “on target.” The “quality” ofan unbiased 
estimator may then be defined as its variance. This corresponds to taking (tn - в)2 as the 
“penalty” or “loss” due to the error of accepting the value tn of Tn as the approximation 
of в. While the squared error is not the only loss function possible, it is realistic in many 
problems.
To sketch this development: First, one has a powerful Cramer-Rao inequality, which 
states that there exists a lower bound for variances of all unbiased estimators of в (for 
any fixed sample size n). This bound shows therefore the best that can be achieved in 
estimating a given parameter, in a sense of providing a yardstick by which one can tell how 
close a given estimator is to the “ideal” (i.e., to the estimator with the smallest possible 
variance).
To answer question 2: How to construct estimators? There are methods (maximum like­
lihood, moments, etc.) of finding an estimator, and there are also methods of modifying 

INTRODUCTION
311
an estimator in order to improve it (e.g., to make its variance closer to the possible mini­
mum value). One such improvement method is based on the concept of a sufficient statis­
tic that retains information in the data that is relevant for estimating parameter 6. The 
Rao-Blackwell theorem says that if T is an unbiased estimator of 6, and S is a sufficient 
statistic for 6, then T* = E(T|S) is an estimator of 6 that is better (or not worse) than T. 
Therefore, one gets a powerful tool of improving estimators: start with any unbiased estima­
tor T, and find its conditional expectation T* with respect to a sufficient statistic. If this new 
estimator T* is not the best, then continue the process, conditioning with respect to another 
sufficient statistic, and so on. Instead of such conditioning “one step at a time,” one can 
condition T with respect to the so-called minimal sufficient statistic (i.e., maximal reduction 
of the data that preserves information about 6). The estimator T* obtained by such condi­
tioning cannot be improved any further. This raises the obvious questions: Is T* the best 
possible estimator? Does the estimator T* depend on the initial starting estimator T? These 
two questions turn out to be closely related. If the family of distributions {f (x, 6), 6 e 0} 
is complete, then T* attains the lower bound given by the Cramer-Rao theorem, and also, 
T* can be obtained by conditioning any unbiased estimator of6 with respect to the minimal 
sufficient statistic.
As already mentioned, the sketch above gives a “success story with a happy ending” in 
statistical methodology. Presented in this manner it may appear easy and effortless. But one 
should remember that bringing the theory to its present form required analysis of countless 
examples, proving or disproving various conjectures, formulating weaker and weaker sets of 
assumptions under which such or other assertion is true, and this took about half a century 
of effort on the part of many statisticians.
In this chapter, we will also present some other topics and results in estimation: asymptotic 
properties of maximum likelihood estimators, Bayesian estimation, the bootstrap approach, 
and so on.
Let us begin with a simple estimation problem and a number of possible solutions. This 
will allow us to formulate various questions, as well as to suggest some natural generaliza­
tions to be discussed later in this chapter.
In many situations where statistical methods apply, one observes a simple random sample 
X1 , ...,Xn from a distribution whose functional form is known, except for the value of a 
certain parameter 6. This means that the actual observations x1, ...,xn are the values of iid 
random variables X1, ...,Xn, each with a distribution that will be denoted f(x, 6), where 
f stands either for the density or for the probability function depending on whether Xi’s are 
continuous or discrete.
We also assume that 6 is an element of some parameter space 0. In a simple scenario, 6 is 
a single number, so 0 is a subset of the real line, but in general, 0 may be a multidimensional 
space, or even a space with a more complicated structure.
In what follows, we often assume that 0 is an interval of the real line, so that we can 
employ standard optimization techniques, for example, involving the differentiation of var­
ious quantities with respect to 6.
■ EXAMPLE 11.2
A politician needs to estimate the proportion of voters who favor a certain issue. In a 
public opinion poll, n persons are sampled from the population and their responses 
X1 , ...,Xn are noted, where Xi =1 or 0, depending whether or not the ith person 
polled favors the issue in question. Letting 6 denote the proportion of voters in favor 
of the issue, we have
6 for x = 1 
f(x,6)=P{Xi=x|6}= 61-6 f
foorr xx =
= 1
0.

312
ESTIMATION
Here 0 < в < 1 (i.e., 0 = [0, 1]), and f (x, 0) can be written as:
f (x,0) = 0x (1 - в)1-x, 
x = 0, 1.
■ EXAMPLE 11.3
Measurement with error is often represented as an estimation problem. We are to mea­
sure the value of an attribute of an object (its weight, dimension, temperature, content 
of some substance, etc.). The true value of this attribute is в, but the measurements 
are subject to error. For instance, it is often assumed that the ith measurement is 
Xi = в + ei, where e 1, e2, ... are iid random variables. If moreover ei ~N(0, a2), then 
Xi ~ N(в, a2), and
f (x,0 
'., e(x— )2 / 2 a 2,
ay 2 n
where a is the standard deviation of measurements (assumed known). In this case, the 
parameter space 0 is the subset of a real line representing the possible values of the 
measured attribute.
If the standard deviation of measurement, a, is unknown, then в is a 
two-dimensional parameter в = (^, a), and we may be interested in estimating 
one or both components of в. In this case, the parameter space 0 is a subset of the 
half-plane {(^, a) : a > 0}.
Before proceeding further, a few comments about notation and terminology are in order. 
First, we will typically use a symbol such as T, to denote a statistic, even if it refers to various 
possible sample sizes. Consider, for instance, a sample mean X = (1 /n)(X 1 + • • • + Xn). In 
fact, however, we are considering here a sequence of statistics, each being a function of a 
different number of arguments. To formulate this properly, it will sometimes be convenient 
to use the notation involving the sample size. We will write Tn for the estimator based on a 
sample of size n so that Tn = Tn(X1, ...,Xn).
Second, we will call a statistic an estimator (of в), when this statistic is used to estimate в. 
Thus, formally, when sample size n is not specified, an estimator is a sequence of statistics, 
the nth one depending on observations X1, ...,Xn. The value ofan estimator, obtained for 
a particular sample, will be called an estimate of в .
Finally, in presenting the general theory, we will use the symbol в for the unknown param­
eter. However, we will also be using traditional notation, such as p for probability of success 
and a for standard deviation.
The following example will show several estimators of the same parameter:
■ EXAMPLE 11.4
Suppose that we take a random sample X1, ...,Xn from the U[0, в] distribution so 
that
1/в if 0 < x < в 
f(x, в)= 
0 otherwise.
The objective is to estimate the range в.
SOLUTION. We will suggest several estimators of в. First, we get some information 
about в from the largest element of the sample. We feel (and will justify it later) that 

CONSISTENCY
313
as the sample size increases, the largest value should get closer and closer to в. This 
suggests taking
T1 = Xn:n 
(11.2)
as an estimator of в. A disadvantage of T1 is that it always underestimates в. We can 
remedy this in a number of ways. For instance, we can argue as follows: In the sample 
of size n, observed values X1, ...,Xn partition the interval [0, в] into n + 1 intervals. 
Since X1, ...,Xn tend to be “evenly dispersed” over [0, в], each of these n + 1 intervals 
will have, on average, the same length в/(n +1). Thus, we should “push” T1 to the right 
by (1/n)T1, which suggests using the estimator
T2 =(1 + -) T1 = — Xn:n. 
(11.3)
n 
n 
n:n
Another way of “adjusting” T1 may be based on the fact that by symmetry, the 
maximal observation is, on average, at the same distance from the upper bound в as 
the minimal observation is from the lower bound 0. Thus, we can use the estimator
T3 = X1:n + Xn:n. 
(11.4)
We will also argue that the minimum of the sample allows us to estimate в. The same 
argument as above, with a partition of the range [0, в] into n + 1 parts of about equal 
length, suggests the estimator
T4 = (n + 1)X1:n. 
(11.5)
This estimator does not seem very reliable. In particular, it may happen that T4 < Xn:n, 
in which case using T4 would make no sense. Moreover, maximum and minimum of 
the sample have—by symmetry—the same variance. The estimator T4 magnifies this 
variance by the factor (n + 1)2. We will show later how this fact affects the precision 
of the estimators.
Finally, we take 
_
T5 = 2 X, 
(11.6)
arguing that the average X should be close to the midpoint в/2.
Example 11.4 shows that one can have several estimators for the same parameter. This 
poses a natural question of establishing criteria for a choice. The next few sections give cri­
teria to evaluate the performance of estimators.
Another question concerns the methods of finding estimators, especially “good” ones: 
Rather than rely on intuition and common sense, it is desirable to have a scheme that can 
produce estimators in an “automatic” fashion. We will also present some modern general­
izations and extensions of estimation procedures, especially computer-intensive techniques 
called resampling methods.
11.2 CONSISTENCY
One of the basic properties of a good estimator is that it provides more precise information 
about в with the increase of the sample size n. We introduce the following definition:
Definition 11.2.1 The estimator T = {Tn,n=1, 2, ...} of parameter в is called consistent, 
if Tn converges to в in probability, that is,
nlimF{ITn - 0|< e} = 1 
(11.7) 

314
ESTIMATION
for every e > 0. The estimator Tn will be called strongly consistent if Tn converges to в almost 
surely,
P lim Tn = в =1. 
(11.8)
n—>^>
When both kinds of consistency are considered at the same time, estimators satisfying (11.7) 
are called weakly consistent. 
□
We will now analyze the consistency of the five estimators T1 - T5 introduced in 
Example 11.4.
■ EXAMPLE 11.5
The distribution of T1 = Xn:n is easy to obtain. Indeed, since Xi’s are uniform on [0, 
в], we have
{
0 
if t < 0
t/в if о < t < в 
1 
if t > в.
We are interested only in probabilities fort between 0 and в. Since Xn:n < t if and only 
if Xi < t for all i, by independence, we have
P{T1 <t}=P{X1 <t,...,Xn <t}= П n 
в )
(11.9)
For 0 < e < в,
P{\T1 - в| < e} = P{T1 > в - e} = 1 -
Since [(в - e)/в]n P 0 as n P ж, estimator T1 is consistent. Using notation from 
Chapter 9, we may write
P
T1 P в.
■ EXAMPLE 11.6
Next, T2 = [(n + 1)/n] T1, and since (n + 1)/n P 1, we have T2 -P в.
■ EXAMPLE 11.7
Regarding the consistency of estimator T3, observe first that for 0 < e < в, 
nn 
n
P{Xhn > e} = J}P{Xi > e} = ]J[1 - F(*)] = (1 - f)” P 0, 
(11.10)
i=1 
i=1
P
which means that X1:n P 0. Consequently, since
T3=T1+X1:n P
P в,
T3 is also consistent.

CONSISTENCY
315
■ EXAMPLE 11.8
Estimator T4 seems inferior to the others, as remarked in Example 11.4. We will show 
that T4 is not consistent. For 0 < e < 6, we have
P{\T4 - 6\< 4 = P{|(n + 1)X1:n - 6\< 4 = ^n+7 < X1:n < 6 + e 
n + 1
= P X1:n <
6 + e \ 
n +1
PX
6 - e
n + 1
The cdf of X1:n can be obtained from formula (11.10). Using the fact that 
(1 + x/n)n P ex, we then have
P e-(e-t)/e - e-(e+6)/e < 1.
P{\T4 - 6I< e} = 1 - 11 
' "l n - [1 - fl 
"l n
\ 
6 (n + 1) J 
6 (n + 1) ]
=1
6 - e \ n A 
6 + e \ n
6 (n + 1)J 
\ 
6 (n + 1)J
Thus, limn ,.-x.P{\T4 - 6| > e} > 0, which shows that T4 is not a consistent estimator 
of6.
■ EXAMPLE 11.9
By the law of large numbers, we have
so
X P E (Xi ) = 2, 
(11.11)
m — P 6 
z .
T5 = 2 X P 2 x- = 6, 
(11.12)
which shows that the estimator T5 is also consistent.
PROBLEMS
11.2.1 Let X1 , . ..,Xn be a random sample from BIN(1, 6) distribution and 
let Sn = (1 /n) 
Xi. Show consistency of estimators: (i) 6 = Sn/n. (ii)
Var(X) = (Sn/n)(1 - Sn/n).
11.2.2 Let X1, ...,Xn be a random sample from the distribution with density f(x; 6)= 
e-(x-e) for x > 6, and f (x, 6) = 0 otherwise. Check if T = X 1:n is a consistent esti­
mator of 6.
11.2.3 The density of a Pareto distribution is f (x; a, 6) = a6ax-(a +1) for x > 6,6 > 0, and 
a > 0. Show that T = X 1: n is a consistent estimator of 6.
11.2.4 Assume that the observations are taken from the U[0, 6] distribution, and let Un be 
the number of observations (out of first n) that are less than 5. Show that if 6>5, 
then Tn = 5n/Un is a consistent estimator of 6.

316
ESTIMATION
11.2.5 Observations are randomly sampled from the U[0, в] distribution. After the 
sample size reaches n, the experimenter starts recording the minimum observations 
X1:n, X1:n+1,  He will continue until he gets Xn+N such that
X1: n = X1: n +1 = • • • = X1: n+N -1 > X1: n + N■
Suggest an estimator of в based on observing X1:n, ...,X1:n+N. [Hint: Find the 
probability distribution of N and express E(N) as a function of в.]
11.3 LOSS, RISK, AND ADMISSIBILITY
Assume again that n independent observations X1, ...,Xn of a random variable with dis- 
tribution21 f (x, в) are taken in order to estimate в. The closer в* and в will be, the more 
successfully will в* subsequently serve some specific purpose.
21We remind the reader that f (x, в) is either the density or the probability function.
In the simplest case, this degree of success may be a decreasing function of the error 
|в* - в | so that the smaller the error, the better. One can easily imagine, however, situations 
where the error of overestimating в (i.e., в* >в) is less serious than the error of under­
estimating it (в* <в). To build a general theory, we assume that such a situation can be 
adequately represented by specifying the loss function L(в*, в), which describes the negative 
consequences of proceeding as if the value of the parameter were в* while in reality it is в 
(we consider “loss” and negative consequences, but by changing the sign, we can convert the 
considerations to “rewards” and positive consequences).
Suppose now that the experimenter decides to use the estimator T = T(X1, ...,Xn) with 
the loss equal to L(T, в). The performance of estimator T can be evaluated as the average 
loss
Rt(в) = Ee{L(T(X1, ...,Xn),в)}, 
(11.13)
where Ee stands for expected value with respect to the distribution fn (x, в). The function R 
given by formula (11.13) above is called a risk function.
We now need to introduce two important concepts:
Definition 11.3.1 The estimator T1 is R-dominating estimator T2, or is R-better than T2, if 
for all в e 0 we have
Rti (в) < Rt2 (в),
and the inequality is strict for at least one value of в.
Moreover, an estimator T is called R - inadmissible if there exists an estimator T' that is 
R-better that T. Otherwise, T will be called R-admissible. 
□
The basis for evaluation of an estimator is the risk function R, which depends on the 
unknown parameter в. Clearly, if we have two estimators, and their risk functions are such 
that one of them is below the other (or equal to it) regardless of the value of в, we can decide 
that the corresponding estimator is better. Quite often, however, the two risk functions cross 
each other (i.e., one is below the other for some в, and above it for some other в). In such 
a case, the estimators are not comparable: Because we do not know в, and we do not know 
which risk function is smaller at the actual (true) value of в, we cannot decide which esti­
mator is better. Thus, we obtain only a partial order of estimators; estimators that are not 
dominated by any other are admissible. Within the class of admissible estimators, by defi­
nition, none dominates the others, and therefore we still need other criteria for choice. But 

LOSS, RISK, AND ADMISSIBILITY
317
at least the problem becomes reduced in the sense that all inadmissible estimators are ruled 
out. In practice, the search for the class of admissible estimators for a specific loss function 
can be difficult.
To build a general theory, it is necessary to choose a loss function that is acceptable. In 
1821, Gauss proposed a squared error
L(6*,6) = (ff* - в)2
(11.14)
as a measure of loss for its mathematical simplicity and convenience. However, the use of this 
loss function makes sense only for estimators with finite second moment (i.e., finite variance). 
We shall tacitly make this assumption. The risk of an estimator T for loss (11.14) is therefore 
Ee [T(X 1, ..., Xn) — в]2. This risk appears so frequently that it has acquired its own name.
Definition 11.3.2 The risk ofan estimator T computed for the loss function (11.14) is called 
the mean squared error (MSE) of T, and is typically denoted as
MSEg(T) = Eg[T(X 1, ...,Xn) — ff]2. 
(11.15)
Also, when no risk function is specified, admissibility will always mean admissibility with 
respect to the MSE. 
□
Another often used loss function, L(в*,в) = ff* — ff|, was suggested by Laplace at the 
beginning of the nineteenth century. It leads to a theory that is less tractable mathematically, 
and has only begun to be developed recently with powerful computers becoming widely avail­
able. While both loss functions, (в* — в)2 and \ff* — 0\, are symmetric, there are situations 
in which overestimating the parameter has different consequences than underestimating it. 
Think about coming to the airport ahead of time and having to wait or coming too late and 
missing your flight, paying your tuition in advance instead of getting a bill for late fees since 
you did not pay by the deadline.
Several different asymmetric loss functions have been proposed in the literature to deal 
with such cases, for example,
( a(e* — e)2 
if e* > e
L(ff*,ff) =
, 
(ff* — ff)2 
if ff* <ff
for some constant a, or a linear exponential (linex) loss function
L(ff*,ff) = exp{a(ff* — ff)} — a(ff* — ff) — 1,
where a =0, or a zero-one loss function
( 0 if 0* = 6 
L(ff*,ff) =
, 
1ifff* = ff.
Asymmetric loss functions are often used in various optimization procedures, for example 
in decision theory, forecasting, classification, or machine learning22 .
22One could argue, however, that an adequate loss function should reflect consequences of errors made after the 
parameter has been estimated (see Gafrikova and Niewiadomska-Bugaj, 1992). The starting point in the latter 
approach is that we use the distribution f (x, в) for some purpose, such as prediction, calculation of some proba­
bilities, and so on. Thus, the loss L(в* ,в) should depend on how much the (estimated) distribution f (х,в*) differs 
from the true distribution f(x, в). Such “difference” between distributions can be expressed through a measure of 
difficulty in discriminating between the two distributions.

318
ESTIMATION
The following definition and theorem show the important role of the first two moments 
of T in the theory based on MSE.
Definition 11.3.3 An estimator T such that
Eg (T ) = 6 
(11.16)
for every 6 will be called unbiased, and the difference
Bg (T) = Eg (T) - 6 
(11.17)
will be called the bias of estimator T. 
□
Clearly, Bg (T) = 0 if and only if T is unbiased. The estimator T will be called positively 
(or negatively) biased, depending on whether Bg(T) > 0 or Bg (T) < 0. More generally, if
lim Eg [ T (X i, ...,Xn )]= 6, 
(11.18)
n—>^>
then T will be called asymptotically unbiased.
We have the following theorem:
Theorem 11.3.1 The MSE of an estimator is the sum of its variance and square of the bias.
Proof:
MSEg(T) = Eg(T - 6)2 = Eg{[T - Eg(T)] + [Eg(T) - 6]}2
= Eg[T - Eg(T)]2 + [Eg(T) - 6]2
+ 2Eg { [T - Eg (T)] X [Eg (T) - 6] }
= Var g (T) + [ Bg ( T )]2 . 
□
Consequently, the MSE of an unbiased estimator is equal to its variance.
We will now find bias and MSE for the estimators T1 - T5 introduced in Example 11.4.
Observe first that for n =1,wehaveT1 =X1,T2 = T3 = T4 = T5 = 2X1. Next Eg(T1) = 
6/2, whereas the remaining estimators are unbiased. Finally, Var(T1) = Var(X1) = 62/12; 
hence the MSE of all of those estimators are the same, 62 /3. They are either all admissible 
or all inadmissible if there exists a better estimator. In the examples below, we assume that 
n>1.
■ EXAMPLE 11.10
Let us begin with the estimator T1 = Xn:n . Clearly, since T1 <6, the estimator is 
biased. The cdf ofT1 is given by (11.9), so the density ofT1 is
ntn-1
fT1 (t) = 
, 
0 ^ t ^ 6, 
(11.19)
and fT (t) = 0 otherwise. Thus,
Eg(T1) = n^Jg tn dt = ~^, 
(11.20)
1 
6n 0 
n +1
a result that we derived in Example 9.3 and used to justify the need to “adjust” T1 to 
obtain unbiased estimators T2 and T3 .

LOSS, RISK, AND ADMISSIBILITY
319
The bias of T1 is negative:
Be (T1) = “^ — ° =-------^. 
(11.21)
n+1 
n+1
Using the formula for Var(T1) obtained in Example 9.3, we obtain
....... 
2 e 22
MSE e (Ti) = Var e (T1) + [ Be (Ti)]2 = , 
. n 2 . 
(11.22)
(n + 1)(n +2)
■ EXAMPLE 11.11
Estimator T2 =[(n + 1)/n]T1 is unbiased. Therefore,
(n +1)2 
e2
MSE e (T2) = Var e (T2) = 
/л 
Var e (T1) = nn+2)' 
(11.23)
Comparing with MSEe(T1), we have
MSE e (T2) = n + 1 < 1
MSEe (T1) 
2n < ,
which means that the risk of T2 is, for large n, about half of the risk of T1 . This result 
shows that the estimator T1 is not admissible: There exists an estimator that is better 
for all e, namely T2 (this does not imply that T2 is admissible!).
■ EXAMPLE 11.12
Let us now consider the estimator T3 = X1:n + Xn:n. This modification of T1 is again 
intended to remove the bias so that Be (T3) = 0. Indeed, E(Xn:n) = [n/(n + 1)]e, and 
by symmetry, E(X1:n) = [1/(n + 1)]e. It was shown in Section 9.3 that
Vare(X1:n) = Vare(Xn:n) = Vare(T1).
Based on formula (9.35), we obtain
MSEe (T3 )=Vare (T3)
= Vare(X1:n) + Vare(Xn:n) + 2Cove(X1:n,Xn:n)
= 2Vare(T1) + 2Cove(X1:n,Xn:n)
_ 
2ne2 
, 
2e2
= (n + 1)2( n + 2) + (n + 1)2( n + 2)
_ 
2 e2
(n + 1)(n + 2).
(11.24)
Thus, MSEe (T3) > MSEe (T2 ); again, T3 is not admissible.
■ EXAMPLE 11.13
Estimator T4 =(n + 1)X1:n is unbiased so that
MSEe(T4) = Vare(T4) = (n + 1)2Vare(X1:n) = ne22
n + 2.

320
ESTIMATION
Compared with T2, we see that T4 is inadmissible—observe that the variance ofT4 does 
not even tend to 0.
■ EXAMPLE 11.14
For the estimator T5, since Var(Xi)= 62 /12, we have
Var(T5) = Var
2-(X1 + 
+ Xn )
nn
4 
62
= n2 « nVar( Xi) = 3П
This time, MSEe (T2)/MSEe (T5) = 3/(n + 2), which for n > 1 is less than 1, andthere- 
fore T5 is not admissible.
It follows from the examples above that for n>1, the best out of the five suggested esti­
mators is T2 : In each case, the risk is a parabola k62, with the coefficient k smallest for 
estimator T2. As we concluded, T1, T3, T4, and T5 are inadmissible. This, however, does not 
imply automatically that T2 is admissible. There may exist an estimator with a smaller risk 
than the risk of T2. To determine the admissibility of T2, let us find the coefficient a such 
that T = aXn:n = aT1 has the MSE smaller than T2. We have
and therefore
Since
Ee (T) = aE (T1)
Be (T) = -^— - 6 = 
n+1
Var e (T) = a 2Var е (T1) =
6,
an - (n + 1) 
n + 1
a2 n
6.
(n + 1)2(n + 2) 62'
we have
MSE e (T) =
a2 n 
a2 n2 — 2 an (n + 1) + (n + 1)2
+ 
(n + 1)2 
_
(n+1)2(n+2)
62
a2n +(n + 2)(a2n2 — 2an(n +1)+(n + 1)2) 
(n + 1)2 (n + 2)
62
Differentiating the numerator with respect to a, we obtain a =(n + 2)/(n +1)as the value 
that minimizes MSEe(T). For such a, the estimator
T = n+2 
(11.25)
n+1 n:n
has the risk
62 
62
MSE•(T) = (nW < 
+2 = MSE• (T2.
Thus, T2 is also inadmissible, and the best estimator (of those considered) is the estimator T 
given by (11.25).
PROBLEMS
11.3.1 Let T1 and T2 be two unbiased estimators of 6 with variances a2,a2, respectively. 
Find values a and b such that: (i) Estimator aT1 + bT2 is unbiased. (ii) Unbiased esti­
mator aT1 + bT2 has a minimum variance assuming that T1 and T2 are independent. 
(iii) Unbiased estimator aT1 + bT2 has a minimum variance if Cov(T1,T2) = C.

EFFICIENCY
321
11.3.2 Let X 1, ...,Xn be a random sample from a N( в, a 2) distribution with a2 known. 
Show that the estimator T of в, defined as T(X 1, ..., Xn) = 3 (T = 3 regardless of 
the observations), is admissible.
11.3.3 Let X 1, ..., Xn be a random sample from EXP(1 /в) distribution. Obtain the mean 
squared errors of two estimators of в: T1 = X and T2 = [n/ (n + 1)]X.
11.3.4 Let X1, ...,Xn be n Bernoulli trials with probability of success в, and let 
S = 
n=1 Xi. Compare the mean squared errors of two estimators of в: T1 = S/n
and T2 =(S + 1)/(n +2).
11.3.5 Let Y1, ...,Yn be a random sample of size n from the discrete distribution with 
probability function f (y; в) = в(1 - в)y-1 ,y = 1, .._. Compare the MSE’s of two 
estimators of т = 1 /в: T1 = Y and T2 = [n/(n + 1)]Y.
11.3.6 Let X 1, ... ,Xn be a random sample from a N(y, a2) distribution (y and a2 are 
unknown), and let
s2=1 it (Xi - X)2, 
s22 
it (Xi - X)2
n 
n-1
i=1 
i=1
be two estimators of a2 . (i) Compare the MSE’s ofS2 and S12. (ii) Consider
n
Sk = k^ (Xi - X)2
i=1
as estimators of a2 and find k for which Sk2 has smallest MSE. Explain why, in prac­
tice, the only values of k used are (suboptimal): k =1/n and k = 1/(n - 1).
11.3.7 Let U = X 1:n andJet V = Xn: n in a random sample from U[в - 1, в +1] distribu­
tion. (i) Show that X and (U + V) /2 are both unbiased estimators of в. (ii) Determine 
the MSE’s of estimators in (i).
11.3.8 Let X1 , . ..,X4 be a random sample from U[0, в] distribution. Compare the mean 
squared errors of four estimators of в: T1 = 5X1:4, T2 = (5/2)X2:4, T3 = (5/3)X3:4, 
and T4 = (5/4)X4:4.
11.3.9 Let X1 , ...,Xn be a random sample from the distribution with density f(x, в)= 
2х/в2 for 0 < x < в and 0 otherwise. Determine the MSE of в = Xn:n.
11.4 EFFICIENCY
We assume that the observations X1, X2, ... are iid random variables, with E(Xi) = в and 
Var(Xi) = a2 < ж, the latter assumed known.
The obvious choice of estimator of the mean в is T = (X 1 + • • • + Xn)/n, traditionally 
denoted by X or Xn, if we need to stress the dependence on the sample size. Since
E (X n )=1 E (X 1 + ... + Xn ) = в, 
(11.26)
nn 
n
Xn is always an unbiased estimator of the mean в. Furthermore, by the Chebyshev inequal­
ity and the fact that Var(Xn) = a2/n for every e > 0,
p{|Xn - e\ > 4 < Vare(2Xn) = nit ^ о, 
(11.27) 

322
ESTIMATION
and therefore Xn is a consistent estimator of в if only Var(Xi) < ж. In view of unbiasedness, 
the risk of Xn is equal to its variance, that is,
MSE в (Xn ) = —. 
(11.28)
nn
Let us now compare the situation with that of estimating the range в of uniform distri­
bution, by using estimators such as T1 or T2 given by (11.2) and (11.3). There are two main 
points of difference here. The first is that in the case of estimating the mean by Xn, the risk 
for a fixed n is constant—it does not depend on the estimated parameter в. In the case of 
estimators T1 and T2, the risk given by (11.22) and (11.23) is a quadratic function of в: the 
larger the value estimated is, the larger is the variance of the results.
The second difference—and much more important—is the rate at which the risk changes 
with the sample size n. In the case of estimating the mean by the sample average Xn, the 
risk changes inversely with n, whereas in estimating the range of uniform distribution by 
T1 ,orT2, it changes (approximately) inversely with n2. Naturally, the latter case is more 
desirable practically: increasing the sample size by the factor of 10 reduces the MSE by factor 
of 100—that is, to aboutP% of the MSE for the original sample size. As opposed to that, in 
estimating the mean by Xn, an increase of sample size by the factor of 10 decreases the MSE 
by the factor of 10 only—that is, to about 10% of the MSE for the original sample size.
So why do statisticians use the sample average as an estimator, if there are other estimators 
that are so much better?
The answer is that a situation such as the one with the sample mean—when the 
MSE decreases inversely with n—is much more common than the situation where the MSE 
decreases with n2. In most cases, the best estimators that one can obtain have a MSE that 
decreases in proportion to 1/n.
The concept that we will attempt to formalize is that of the average “amount of informa­
tion about в contained in a single observation of X.” Let X1, X2, ... be a random sample, 
selected from the distribution f (x, в), where в takes values in some open domain, and the 
set of points x at which f(x, в) > 0 does not depend on в. (The last assumption rules out the 
case of observations from the U[0, в] distribution, where the set of points at which f (x, в) 
is positive depends on в.) The reason for distinguishing such “regular” case is that if this 
assumption were violated, a single observation may eliminate some values of в with certainty 
(e.g., in the case of uniform distribution on (0, в], observation X = 3 rules out all в<3). 
Such elimination is typically unattainable in practical situations; hence we concentrate the 
theory on “regular” cases.
Let us start from some intuitions. Suppose one gets a message that some event A occurred. 
The amount of information in this message depends, in an obvious way, on what event A is 
and who receives the message (think here ofa message that Delta flight 503 will arrive 2 hours 
late). Apart from such semantic and personal information, there is also some information 
contained in the message (that A occurred) depending only on how likely is the event A.If 
P(A) is close to 1, the amount of information is close to 0, while for P(A) close to 0, the 
amount of information is high.
This interpretation agrees with common intuition, as well as with practice (e.g., in news­
paper publishing). The fact that Mr. Smith found a dead roach in the can of beer he drank is 
of interest and worth reporting precisely because such an event is rare; hence, its occurrence 
carries lots of information. If, on the other hand, dead roaches were commonly found in 
cans of beer, no one would care to report it.
An interesting and coherent theory is obtained if the amount of information in the occur­
rence ofan event with probability p is log(1/p) = - log p.
The situation in the case of estimation is somewhat more complicated, since we want to 
define the amount of information about в in the event X = x, where X is a random variable 
with distribution (density or pdf) f(x, в). Here f(x, в) plays the role of probability p of the

EFFICIENCY
323
event X = x. Since we are interested in information about в, it appears natural to consider 
the rate of change of log(1 /[f (x, в)]) = - log f (x, в) under varying в at the point x, that is, 
....... ............. de-   ,,.. 
- df^. 
(11,, 
дв 
J (x, в )
We eliminate the effect of the sign by considering the square of quantity (11.29) and take the 
expectation to avoid the restriction to specific value x.
These considerations lead to the following definition:
Definition 11.4.1 Let X be a random variable with distribution f(x, в), such that the set of 
points x at which f(x, в) > 0 is the same for all в. We assume that the function f(x, в) is 
twice differentiable with respect to в for every x. Then, the Fisher information about в in a 
single observation X is defined as
I (в ) = E {J (Х,в)}2, 
(11.30)
where
J(Х,в) = d- [log f (Х,в)], 
(11.31)
дв
provided that the expectation (11.30) exists. Function J(X, в) in (11.31) is called the score 
function. 
□
f (x^) dx,
Thus, in the case of a continuous random variable X, the quantity (11.30) is
I (в )= [+~ [ J (x,, )]2 f (x,,) dx = f +” f ' 
-—ж 
-—oo L
while in the discrete case integration is replaced by summation.
■ EXAMPLE 11.15
Let X have normal distribution N(в, a2). Then, 
log f (x, в) = - log(a\d:) - (x- в) 
2a2
and 
J(Х,в) = d[log f (х,в)] = X^. 
(11.32)
дв 
a2
Thus,
I(в) = E ( X - в Y = ± E(X _ в)2 = a_2 = 1
I(в) E^ a2 ) a4 E(X в) a4 a2 '
■ EXAMPLE 11.16
Consider now a single Bernoulli trial with probability в. We have P{X = 1 |в} = в and
P{X = 0|в} =1- в so that
f (x,в) = вх(1 - в)1—x, 
x = 0, 1.
(11.33)

324
ESTIMATION
Thus, log f (x,0) = x log в + (1 — x) log(1 — 0) and
ra 
V
д0 log f (x,0)
{
1
(1 — 0)2
1
02
if x =0
if x =1.
(11.34)
Taking the expectation, we obtain
I(0 ) = (1—0)2 x (1 — 0) +1 x 0 = 0^
(11.35)
■ EXAMPLE 11.17
Let us slightly modify Example 11.16: Suppose now that P{X = 1|0} = 0I 2 and 
P{X = 0|0} =1— 02; thus, we have a single Bernoulli trial, but now the probability 
of success is 02 . However, we are still interested in the amount of information about 
0 (not 02). A practical example here may be found in genetics, where 0 is a frequency 
of a recessive gene (e.g., a gene causing a person to have blue eyes) so that X =1 
corresponds to finding a person with some features caused by a recessive gene 
(requiring both parents to transmit this gene). We now have
I (0 > = (-W (1 — 02) + 4 02 
0 + 4 = 1—0
Comparison of this result with the result in Example 11.16 is quite instructive. In a 
single Bernoulli trial with probability of success 0, the average amount of information 
in a trial is a function that assumes its minimal value 4 at 0 =1/2.As0 moves away 
from 1 / 2 toward either 0 « 0 (success very rare) or 0 =1 (failure very rare), the average 
amount of information about 0 increases to infinity.
On the other hand, ifwe can only observe whether or not an event with probability 
02 has occurred, then the average amount of information about 0 is close to 4 if 0 « 0, 
and increases to infinity when 0 ^ 1. The symmetry of the preceding example is lost. 
Indeed, only when 0 is close to 1 is 02 also close to 1, so successes that are sufficiently 
frequent provide a good estimator of 02, and hence also of 0. For small 0,wehavea 
poor estimate of 02, and hence also a poor estimate of0.
f(x, 0) = (02)x(1 — 02)1-x;
hence
д log f (x, 0)1 
д0
д [2 x log 0 + (1 — x )log(1 — 0 2)] 
д0
20 (1 — x) 
1 — 0 02
4 0 0­
(1 — 02)2
4
02
if x =0
if x =1
Consequently,
(11.36)

EFFICIENCY
325
Alternative formulas for I(в) can also be derived. Observe first that
Гто Г d
E[ j(x,()] = _ - log f (x,e)
f f (x,e) 
f (x, в)
f(x, в) dx
............. r° d.............
f (x, в) dx = J 
— f (x, в) dx
d f™............. d „
= дв .1 .. f (x, в) dx = дв(1) = 0'
(11.37)
This is valid under the conditions that allow to interchange differentiation with respect to в 
and integration with respect to x. Thus, in view of (11.37),
Vare[ J(X, в)] = Ee [J(X, в)]2 - {E[J(X, в)]}2 = I(в). 
(11.38)
Still another formula for I(в) can be obtained by noting that
dj()=d '-f f (x,e) 
f (x,()
f f(x,()) - ( f f (x,())2 
fw)p
f2 f ( x,Q ) 
f (x,0)
- [J(x,0])2.
Taking expectations of both sides, we get
( d \ 
гж d2
E^ — J (x, в) j = £ -^2 f (x, в) dx - Ee [ J (X, в )]2 = -I (в),
since, assuming one can interchange integration and differentiation,
Г° d2.................. d2 Г............. d7 
„
J_x ж f (x,в)dx = 1№ ,1 „ f (x,()dx = дв2(1) = 0.
We have therefore the following theorem:
Theorem 11.4.1 If the density f (x, в) is twice differentiable in в and the equality 
f f (x, в) dx = 1 can be differentiated twice under the integral sign, we have
I(в) = Ee[ J(X, в)]2 = Vare [J(X, в)] = -Ee д d \
\xJ(x,(7 .
(11.39)
□
The following theorem determines the average information contained in a random sample 
of size n:
Theorem 11.4.2 The information In (в), in a random sample of n observations, is n times the 
information ofa single observation:
In (в ) = nI (в).
(11.40)
Proof: The density of X is f (X, в) = f (X 1, в) • • • f (Xn, в) so that
d 
d n 
n
J(X, в) = - log f (X, в) = -Y, log f (Xi, в) = E J(Xi, в). 
i=1 
i=1

326
ESTIMATION
Differentiating both sides, we have
a 
d
-j (X ,e ) = £ aJ (Xi,°). 
(11.41)
i=1 
□
The next theorem connects the amount of information about C contained in a single obser­
vation, with the variance of an estimator of C.
Theorem 11.4.3 Cramer-Rao Inequality For any estimator Tn such that Ee (Tn) = m (C), we
have 
2
Vare(Tn) > m( 
. 
(11.42)
In particular, if T is an unbiased estimator of в, then m (C) = в, m' (C) = 1, and
Vare(Tn) > n^). 
(H.43)
Proof: Let T(X) = T(X 1, ... ,Xn) be an arbitrary estimator of C, assumed to have a finite 
variance. Letting x = (x1, ...,xn), we have
dxn.
У T (x) f (x ,C) dx 1...
Consequently, assuming again that we can differentiate under the integral sign, we obtain
m
m (C )= Ee (T ) =
= 
... T(x)
=/■ 7T (x>
Г d 
1
7f (x ' ’J
T, f(x•») 
_ f (x,C)
dx1 
dxn
f (x, C) dx 1 ■ ■ ■ dxn
= f ■■ ' / T(x) J(x, C) f (x, C) dx 1 ■ ■ ■ dxn
= Ee{T(X) J(X, C)} = Cove{T(X), J(X, C)}.
(11.44)
The last equality follows from the fact that E[J(X, C)] = 0, which can be established in the 
same way as for a single random variable X , in view of the relation
n
J (X ,C ’ = £ J (Xi,C).
Now, by the Schwarz inequality (7.6.7) and (11.44), we may write
[ m (C )]2 = [Cov e (T (X), J (X ,C )]2 < Var e (T) x Var e [ J (X ,C)].
(11.45)
□
Observe that we have equality in (11.42) if and only ifwe have equality in (11.45), which 
means that the correlation coefficient between T(X) and J(X,C) satisfies the condition 
IpT(X), J(X,e) I = 1. By Theorem 7.5.6, this is equivalent to linear relationship between T(X) 
and J(X, C), that is,
T (X )= y i( C) J (X,C) + y 2( C) 
(11.46)
for some functions y 1( C) and y2 (C).
An important point here is that T is an estimator of C, so the left-hand side does not 
depend on C. Consequently, the right-hand side does not depend on C either; that is, functions

EFFICIENCY
327
Y 1 and Y2 cancel the dependence of J(X, 0) on the parameter 0. The set of conditions that 
allow all differentiations under the integral sign, combined with the condition of indepen­
dence of0 of the set ofx for which f(x, 0) > 0, will be called the regularity conditions.
We have the following definition:
Definition 11.4.2 Any unbiased estimator T that satisfies the regularity conditions and 
whose variance attains the minimum equal to the right-hand side of (11.43) is called 
efficient. The ratio nl(0) / Vare (T) is called the efficiency of T.
More generally, given two unbiased estimators T1 and T2 of0, the ratio of their variances 
Vare (T1) /Vare (T2) is called the relative efficiency of T2 with respect to T1. 
□
■ EXAMPLE 11.18
Consider the problem of estimating the mean 0 of normal distribution N(0, a2). From 
Example 11.15,we have I(0) = 1 /a2. The most obvious estimator for 0, Xn, is unbi­
ased, and Var(Xn) = a2/n. The lower bound of variances of all unbiased estimators 
of 0, based on samples of size n, is 1 / [nl(0)] = a2 fin, which shows that Xn is efficient.
■ EXAMPLE 11.19
Continuing Example 11.16, suppose that we want to estimate probability of success 
0 on the basis of n Bernoulli trials. Since I(0) = 1/[0(1 - 0)], the information in 
the sample of size n is n/ [0 (1 - 0]. For Sn = X 1 + • • • + Xn being the total number 
of successes, T = Sn /n will be an estimator of 0. S has binomial distribution;
E(T) = (1/n)E(Sn) = 0, and Var(T) = (1/n2)Var(Sn) = 0(1 - 0)/n, which shows 
that T is efficient.
■ EXAMPLE 11.20
In Section 11.2, we studied five estimators of 0 in U[0, 0] distribution. We found that 
variances of estimators T1, T2, and T3 decrease to zero like 1/n2 (and not at the rate 1/n, 
as for efficient estimators). Thus, those estimators are superefficient. This is possible 
since f(x, 0) does not satisfy the regularity conditions. The set of points x at which the 
density f (x, 0) is positive is [0, 0]; hence it depends on 0.
Under the regularity conditions, the right-hand side of the Cramer-Rao inequality 
(11.43) gives the lower bound for variances of unbiased estimators, and therefore, if an 
efficient estimator of 0 is found, it is known that a better unbiased estimator does not 
exist. It is necessary to point out, however, that the Cramer-Rao bound is not always 
attainable. It may happen that the best possible unbiased estimator has a variance larger 
than the Cramer-Rao bound. For a thorough discussion of these topics see, for example, 
Mood et al. (1974).
PROBLEMS
11.4.1 Let X2 k be the sample mean of 2k independent observations from a normal distribu­
tion with mean 0 and known variance a2. Find the efficiency of Xk (i.e., of estimator 
that uses only half of the sample).
11.4.2 Let X have EXP(A) distribution. Find the Fisher information I(X).
11.4.3 Let X 1, ... ,Xn be a random sample from EXP(X) distribution. Propose an efficient 
estimator of 1/X and determine its variance.

328
ESTIMATION
11.4.4 Find, if it exists, the Fisher information I(в) in a random sample of size n from: 
(i) The Cauchy distribution with density f (x, в) = {^[1 + (x - в)2] } 1, -ж <x < 
ж. (ii) The Rayleigh distribution with density f(х,в) = (x/в)exp{—x2/(2в)}, 
x > 0, в > 0. (iii) The Gumbel generalized extreme value distribution with density 
f (x, в) = exp{ — (x — в) + exp{ — (x — в)}}, —ж < x < ж, —ж < в < ж.
11.4.5 Let X 1, X2 be a random sample of size 2 from N(p, a2) distribution. Determine the 
amount of information about /л and about a2 contained in: (i) X 1 + X2. (ii) X 1 — X2.
11.4.6 Let X1 , . ..,Xn be a random sample from a Bernoulli distribution with an unknown 
p. Show that the variance of any unbiased estimator of (1 — p)2 must be at least 
4p(1 — p)3 /n.
11.4.7 Show that the estimator T = X satisfies relation (11.46) and determine functions y 1 
and y2 if a random sample X 1, X2, ..., Xn is selected from: (i) N(в, a2) distribution 
with a known. (ii) BIN(1, в) distribution.
11.4.8 Let X 1, ...,Xn be a random sample form the POI(A) distribution. Find 
the Cramer-Rao lower bound for variances of unbiased estimators of 
P(X < 1) = (1 + A) e-.
11.5 METHODS OF OBTAINING ESTIMATORS
Before introducing further criteria for evaluating performance of estimators (besides 
consistency, unbiasedness, and efficiency), we shall now present methods of constructing 
estimators.
Method of Moments Estimators
In this approach, estimators are obtained by equating sample quantities to the corresponding 
population quantities as functions of the parameter to be estimated. The estimator is then 
found as a solution of the resulting equation with respect to the parameter, and the general 
approach is also known as a plug-in principle.
Since the most commonly taken quantity is a moment of the random variable, this method 
of constructing estimators is generally known as method of moments.
■ EXAMPLE 11.21
Let X 1, ... ,Xn be a random sample from the EXP(в) distribution. Then, E(Xi) = 
1 /в. The sample counterpart of the first moment is the sample mean Xn = (1 /n)(X 1 + 
• • • + Xn). Equating the empirical and theoretical mean, we obtain the equation Xn = 
1 /в, which gives the estimator T1 = 1 /Xn of the parameter в.
We could, however, use the second moment as well. Then we have E(X2) = 
Var(X) + [E(X)]2 = 2/в2. The empirical counterpart of the second moment is 
(1 /n) Sn=1 Xi2. We therefore obtain the equation
11 Xi=2,
!•! i 1 p л
which, solved for в, gives an estimator
2 n
\ X .
T2 =
(11.47)

METHODS OF OBTAINING ESTIMATORS
329
Still another possibility would be to use the median m, the point at which cdf equals
1 /2, so F(m) = 1 — e IJm = 1 /2, implying m = (log 2)/0. The empirical counterpart 
of the median m is the sample median. We will assume for simplicity, that the sample 
size is odd (n =2k +1). Then the sample median is the (k + 1)st order statistic Xk+1:n. 
We therefore have still another estimator of 0,
Tз = Xp^-. 
(11.48)
Xk+1:n
Finally, suppose that we want to estimate the probability
p = P{X > 3} = e-3в.
The method of moments suggests using the estimator e-3T, where T is any estimator 
of 0. Estimators T1, T2, and T3 now give three estimators of p, namely
Р1 = exp < 
—Xn
AРз = exp
—3log2
Xk+1:n
■ EXAMPLE 11.22
Let us observe that the estimator T5 = 2Xn from Example 11.4 is also an example 
of estimator obtained by the method of moments. Since E(X )=0/2, doubling the 
sample mean gives a moment estimator of 0.
The method of moments can also be applied in the case of estimating several parameters 
at once, as illustrated by the following example:
■ EXAMPLE 11.23
Suppose that we want to estimate both m and a2 based on a random sample 
X 1, ...,Xn from some distribution with mean m and variance a 2.
SOLUTION. We could choose the following two expressions:
E (X )= m, 
E (X 2) = a2 + m2. 
(11.49)
This suggests that we compare the first and second empirical moment with m and a2 +
M2 by obtaining the equations
1n
- X2 Xi = M, 
n
1n Xi = a2 + M2.
n i=1
Solving for M and a2, we obtain
M = X and a2 = - V X2 — X2 = - V (Xi — X)2. 
(11.50)
ni 
n i
i=1 
i=1
Thus the sample mean and the sample variance (with divisor n) are method-of-moment 
estimators of the population mean and variance in the general case.

330
ESTIMATION
■ EXAMPLE 11.24
As the last example of the method-of-moment estimator, consider the problem of the 
randomized response, discussed in Section 1.2. Generally, the empirical problem con­
cerns some attribute, call it Q, that a person might be reluctant to admit having. The 
objective is to estimate the frequency в of persons in a given population whose true 
reply to a question “Are you a Q-person?” is “yes.” To collect the data on such ques­
tions one can use a questionnaire with a randomized response (see Example 1.9). 
The respondent activates two random mechanisms, one generating the event A or its 
complement Ac , the other generating the event B or its complement Bc . These two 
mechanisms operate independently. The probabilities P(A) = a and P (B) = в are 
known; however, only the respondent knows which of the events A and B occurred 
in a given instance. He is instructed to respond to the question “Are you a Q-person?” 
ifA occurs, and otherwise respond to the question “Did B occur?” The answer “yes” or 
“not” is recorded by the experimenter who does not know which question was actually 
answered.
Conditioning on the occurrence or nonoccurrence of event A, we have
P(“yes”) = P(“yes”|A)P(A) +P(“yes”|Ac)P(Ac)
= 9a + в(1 — a).
If now X respondents out of N tested replied “yes,” then X/N is an estimator of 
P (“yes”), and we have an approximate equality
N « 9a + в(1 - a),
which suggests using as an estimator of в the random variable
T = X/N - в (1 - a)
a
A problem with the estimators obtained by method of moments is that they are not 
unique, since one can take moments of various orders, or even different quantities. How­
ever, as a rule, one should take the moments of lowest orders that depend on 9, as illustrated 
by the following example:
■ EXAMPLE 11.25
Suppose that the observations are known to have U[-9, 9] distribution. Then E(X) =
0, and the first moment contains no information about 9. One may use here the fact 
that
E (X2) = - e x 2 x 219 dx=3,
which gives the estimator 
n
9=3%X2
The moment estimators are consistent under some 
strong law of large numbers for the iid case asserts 
very mild conditions. Indeed, the 
that (1 /n)(Xk + Xk + • • • + Xnk)

METHODS OF OBTAINING ESTIMATORS
331
converges with probability 1 to Ee(Xk) if only Ee(|X|k) < ж. Consequently, the empirical 
moments converge also in probability to the corresponding theoretical moments, and if 
only the parameter в is a continuous function of moments (as is usually the case), the 
consistency of method-of-moment estimators follows.
The situation is not so straightforward for estimators built on quantities other than the 
moments. Consistency has to be studied separately in each such case, by establishing whether 
or not the sample analogue of a given quantity converges in probability (or almost surely) 
to the corresponding theoretical quantity. However, the main issue with method-of-moment 
estimators is that they either coincide with estimators obtained by the maximum likelihood 
method (discussed below), or they are inferior to them.
Maximum Likelihood Estimators
Let X1 , ...,Xn be a random sample from distribution f(x, в), where f(x, в) may stand for 
the density or for the probability function. If the observed values are X1 = x1, ...,Xn = xn, 
then the probability of this sample (or the joint density) is
f (x i ,в) *•••* f (xn ,в). 
(11.51)
The product (11.51), regarded as a function of parameter в, is called the likelihood function 
of the sample, or simply the likelihood function. We will use the symbol
n
L(в) = L(в;x 1, ...,Xn) = Пf(Xi,6) = fn(X,в), 
(11.52)
i=1
where x =(x1 , ...,xn).
Definition 11.5.1 Given the sample x = (x 1, ..., xn), the value в = в(х) that maximizes the 
likelihood function (11.52), is called the maximum likelihood estimate (MLE) of в. 
□
Let us begin with some examples:
■ EXAMPLE 11.26
We will find MLE of the probability of success в, ifin five independent Bernoulli trials 
with probability of success в, three successes and two failures were observed.
We have here f (x, в) = вх (1 - в)1x where x = 0 or 1 represent failure and success, 
respectively. Thus the likelihood is
5
L(в) = П exi (1 - в)1 -xi = в3(1 - в)2, 
(11.53)
i=1
where 0 < в < 1. The information as to which trials led to successes and which to fail­
ures does not affect the likelihood and is irrelevant for the estimation of в.
To find the maximum of function (11.53) we differentiate, obtaining the equation
L(в) = 3в2(1 - в)2 - 2в3(1 - в) = в2(1 - в)[3(1 - в) - 2в]
=в2(1-в)(3-5в).
The solutions or equation в2(1 - в)(3 - 5в) = 0 are: в = 0, в = 1, and в = 3/5. An 
inspection of L (в) shows that this function attains its maximum at the last solution, 
while в = 0 and в =1 give the minima. Thus the MLE of в is в = 3/5.

332
ESTIMATION
■ EXAMPLE 11.27
Suppose that we take n = 3 observations from POI(в) distribution, obtaining values 
x1 =2,x2 =0,x3 =5. The likelihood is
в7
2!5! e
- 3 e
The derivative now is 
L(°) = 215!(7°6e-3e - 3°7e—3e)’
and L(в) = 0 for в = 0 and for в = 7/3. An inspection of L shows that the maximum 
occurs at the second solution, so the MLE of ° is now 7/3.
■ EXAMPLE 11.28
Suppose that we observe values x1 =3and x2 
likelihood now is
-2 from a N(0, 22) distribution. The
L(в) 
e—9 /2 e 2 x
k ’ 
2П^
1
„ ,—e 
2П22
—4 / 2 e 2 
1 e—13 / 2 e2
2 пв2
Since L (в) is maximized at the same point at which its logarithm is maximized, we will 
first take the logarithm and then differentiate. Taking natural logarithms, we have
13 
log L(в) = -2 log в - log(2n) --.
2 2 2
Hence
d i»g L(, ) = - 2+ 1|,
and we obtain the equation
1 
13
2 2- - в2) =0
with solution в = д/13/2. After checking that the likelihood is maximized at д/13/2, 
we obtain в = д/13/2 as the MLE of в.
Some obvious questions arise here. First, the statistical questions concerning the proper­
ties of the suggested procedure. The point is that the MLE depends on the sample, so it is 
a random quantity. Our procedure therefore defines an estimator. What are its properties, 
such as consistency, bias and efficiency?
Second, the mathematical questions: Does MLE always exist? If so, is the maximum of 
the likelihood function unique? Can it always be obtained by differentiation of likelihood or 
of its logarithm and solving the resulting equation?
There are cases when, formally speaking, MLE does not exist, but these cases can often 
be modified in a natural way so as to remedy the situation.
■ EXAMPLE 11.29
Consider the problem of estimating в based on observations from the U(0,)) distribu­
tion, with density
f 1 /в for 0 < x < в 
f (х,в )=< 0 otherwise.

METHODS OF OBTAINING ESTIMATORS
333
Given the sample x1 , ...,xn, the likelihood is
l(e) = f(xi,e) ■ ■■ f(xn,e) =
1 /en
0
if 0 <xi <e forall i 
otherwise.
Thus the likelihood function is discontinuous: it is the function depicted in 
Figure 11.1, with discontinuity at the point t = max(x1, ...,xn), and decreasing for 
e > t. However, for e = t we have L(t) = 0, so there is no point at which this function 
attains its maximum, and MLE does not exist.
Figure 11.1 Likelihood function for the range R in uniform distribution.
The cause of the trouble here is the choice of the definition of the density. If we 
define f (x, e) to be 1 /e in the closed interval 0 < x < e, the likelihood would actually 
reach its maximum at e = max(x1, ...,xn).
The example above shows a type of situation where MLE does not exist because of the 
choice of the density function. Since the density function can be modified at a single point 
(or at any finite or countable set of points), such a modification can affect the likelihood 
function. Consequently, we may (and will) always assume that the densities are defined in 
such a way that the maximum of the likelihood exists.
■ EXAMPLE 11.30
Assume that we are estimating e based on a random sample X1, ...,Xn, with Xi’s 
being distributed uniformly in the interval [e - 1/2, e + 1/2]. We have
1
0
f(x,e)=
for e — 1 < x < e + 2 
otherwise .
Consequently, L (e) = 1 if Xn:n < e + 1 /2 and X 1:n > e — 1 /2, and is equal 0 oth­
erwise. All values of L(e) in a certain interval are equal 1, and the maximum is not 
unique. All values between Xn:n — 1/2 and X1:n +1/2 are MLE’s of e.
Despite the above-mentioned shortcomings, MLEs are reasonable in most cases appear­
ing in practice. We will continue with the example of the MLE in the case of a fixed number 
of Bernoulli trials.

334
ESTIMATION
■ EXAMPLE 11.31
Let us consider, as in Example 11.26, five Bernoulli trials with probability of success 6. 
The information on which trials led to success and which led to failures is not essential: 
what matters is the total number S of successes. The likelihood function for S = s is
L(6, s) = 6s(1 - 6)5-s.
For 0 < 6 < 1, the function L (6, s) is maximized at s/5 if s = 1, 2, 3, or 4, as can be seen 
by taking derivatives and solving the equation L'(6) =0. For s = 0, we have L(6,0) = 
(1 - 6)5, and the maximum occurs at 6 =0. Similarly, for s =5, we have L(6, 5) = 65, 
and the maximum occurs at 6 =1. Thus the MLE of 6, for given s, is s/5 (although 
for s =0 and s =5 the maximum occurs at the boundary and therefore cannot be 
established by taking derivatives).
Graphically the six likelihood functions corresponding to various numbers s of suc­
cesses are presented in Figure 11.2. If we now regard s as a value of random variable 
S, then the likelihood function L(6, S) becomes random. The corresponding point 
at which L(6, 5) attains its maximum equal to S/5, is also random. Thus the MLE 
becomes a random variable, dependent on the sample (X1, ...,Xn) through the statis­
tic S = X 1 + ... + X 5.
Figure 11.2 Likelihood function for five Bernoulli trials.
We will regard the likelihood function as a random function of 6, the randomness being 
induced by the sample X 1, ..., Xn. The value 6 that maximizes the likelihood will be called 
a maximum likelihood estimator of 6 . Following tradition, we will use the same MLE sym­
bol for both the maximum likelihood estimator (random variable) and for the maximum 
likelihood estimate (its value for a particular sample).
Let us begin by stating some properties of maximum likelihood estimators. The property 
that makes these estimators quite convenient is known as invariance.
Invariance Principle If 6 is the MLE of parameter 6, then h(6) is the MLE of parameter h(6).
Let us begin with the case where the mapping h is one-to-one. Then there exists the inverse 
mapping g of 0' onto 0 such that 6' = h(6) whenever 6 = g(6'). If the likelihood L(6, x) is 
maximized at the point 6 = 6(x), then the function L(g(6'), x) is maximized when g(6') = 
6(x), and hence when 6' = h[6(x)]. Perhaps the most common application of the invariance 

METHODS OF OBTAINING ESTIMATORS
335
principle is the fact that if 6 is the MLE of the variance a 2, then vp is the MLE of the 
standard deviation a.
The invariance principle is valid in the case of multidimensional parameters, and 
one-dimensional functions of such parameters. Consider the following example:
■ EXAMPLE 11.32
Suppose that the sample is taken from a distribution f (x; л, a), where л and a are the 
mean and standard deviation (we may consider f as normal, but it is not necessary). 
Thus 6 = (л, a) is a two-dimensional parameter. Assume that the parameter space is 
0 = {л > 0, a > 0}. Suppose that we want to estimate the coefficient of variation v = 
a/л.
The invariance principle asserts that if л and a are MLE’s of л and a, then v = a/л 
is the MLE of the coefficient of variation v. It should be recognized, however, that 
this conclusion does not follow from previous reasoning, since the function that maps 
6 = (л, a) into h(6) = a/л is not one-to-one.
The argument showing that the invariance principle for the MLE’s is also valid in the 
multidimensional case is as follows: Assume that 6 = (n 1, n2, ■ ■ - ,nm) is an m-dimensional 
parameter, and let h(6) = h(n 1, n2, ■ ■ ■, nm) be a function of 6 to be estimated. Then find 
m - 1 functions h2(6) = h2(n1,n2, ...,nm), ..., hm(6) = hm(n1,n2, ...,nm) such that the 
vector
H(6)=(h(6),h2(6),...,hm(6))
is a one-to-one mapping of m-dimensional parameter space 0 into a subset 0' of the 
m-dimensional space. By the preceding argument, if6v = (nv1, ...,nvm) is the MLE of6, then
H(6v) = (h(nv1, ..., nvm), h2(nv1, ...,nvm), ...,hm(nv1, ...,nvm))
is the MLE of H(6). It follows therefore that h(nv1, ...,nvm)=h(6v) is the MLE of h(6).
The second important property of maximum likelihood estimators is that they do not 
depend on the design of the experiment. To explain the issues involved here, we start by 
formulating the likelihood principle.
Likelihood Principle Consider two sets of data, x and y, obtained from the same popula­
tion, although possibly according to different sampling plans. If the ratio of their likelihoods, 
L1(6, x)/L2(6, y), does not depend on 6, then both data sets provide the same information about 
the parameter 6 and consequently should lead to the same conclusion about 6.
Consequently, what matters are the ratios of likelihoods rather than the likelihoods them­
selves. We will explain by some examples how this principle makes the MLE’s independent 
on the design of experiment.
■ EXAMPLE 11.33
Assume that we want to estimate 6, the probability of success in Bernoulli trials. 
One experimental design consists of fixing the number n of observations and 
recording the number of successes. If we observe x successes, the likelihood is 
Li(6,x)= (X) 6x(1 - 6)n-x.
Suppose now that one decides to fix x and take observations until x successes are 
recorded. Now the probability that the observations will end on the nth trial is given 
by negative binomial distribution, so the likelihood is
n
1
1
L2 (6, n)=
6x(1 - 6)n-x
x

336
ESTIMATION
Observe that in the first case x was random and n fixed; in the second it is the other 
way around. Nevertheless, the ratio of these two likelihoods is (n) / ( n-И, which 
x 
x-1
does not depend on 0. The MLE of 6 is 0 = x/n in either case. Therefore the additional 
information that in the second case the last experiment led to success does not affect 
our estimate of 6.
■ EXAMPLE 11.34
Consider tennis players A and B who from time to time play a match against each other. 
Let us assume that the probability of A winning a set against B is p, and the results 
of sets are independent (This is a somewhat oversimplified assumption; probability p 
may change over time, and results of sets within a match may be dependent. We will, 
however, take this assumption as a starting point for analysis.) We want to estimate the 
probability p, which reflects the relative strengths of players A and B .
SOLUTION. Assume that A and B are men.23 Therefore the probability that A will 
win in 3 sets is a3 = p3. The probability that he will win in 4 sets is a4 = 3p3(1 - p), 
since he must win the last set (probability p) and two of the first three sets [probability 
23 p2(1 - p)]. Similarly the probability of winning in 5 sets is a5 = 6p3(1 - p)2. The 
analogous probabilities of winning by player B in 3, 4, and 5 sets are в3 ,в4, and в5 , 
obtained by interchanging the roles ofp and 1 - p.
23This assumption is important since men play “best out of five sets,” whereas women play “best out of three sets.”
Now assume that the sport section ofa newspaper provides data for the last year, in 
the form of six numbers (a3, a4, a5, b3, b4, b5), where ai is the number of matches won 
by A (against B)ini sets, and similarly for bi. Letting q =1- p, the likelihood of the 
data is
L (p; a з, ...,b 5) = a “3 a aa 4 a aa5 в5 3 в44 в5 5
= (p3)a3 (3p3q)a4 (6p3q2)a5 (q3)b3(3q3p)b4(6q3p2)b5
= Cp3a3 +3a4 +3a5 +b4 +2b5 q3b3 +3b4 +3b5 +a4 +2a5
= Cpaqb,
where C is a constant independent ofp, while a and b are the total numbers of sets won 
only by A and by B, respectively. We obtain
log L = log C + a log p + b log(1 - p),
and the MLE ofp can be easily found as
a number of sets won by A 
)> = ----- - = ------- --------------------- -— .
a + b number of sets played
Observe that the number of matches, equal to a3 + a4 + a5 + b3 + b4 + b5 , does not 
appear in the estimator of p. The fact that the last set in each match must be won by 
the winner of the match is not relevant here: the estimator is the same whether or not 
we fixin advance the number of sets (not matches!) to be played, and record the number 
of sets won by A.
Still another important property of maximum likelihood estimators is that they can be 
obtained from samples in which some data are only partially observable. To illustrate this 
property, we will find the MLE from a censored sample.

METHODS OF OBTAINING ESTIMATORS
337
■ EXAMPLE 11.35
Suppose that we want to estimate parameter A in the EXP(A) distribution. For con­
venience of terminology, let us interpret the observations as lifetimes of some pieces 
of equipment. A typical experiment consists here of putting n pieces of the equipment 
to test and observing the lifetimes X1 ,X2 ,   Suppose that the experiment is inter­
rupted after some time T , and some tested items are still working. The data then have 
the form of a certain number of values X1 , ...,Xm of observed lifetimes, while about 
the remaining n - m items we know only that Xm+1 > T, ...,Xn >T.
The likelihood of such a sample is obtained by multiplying the values of density 
function at points X 1, ..., Xm and the probabilities P{Xi > T} = e-XT for i = m + 
1, .. .,n. Therefore the likelihood is
L(A) = Ae-AX 1 x • • • x e- xm(e-XT)n-m = Ame-X[X 1+''' + Xm+(n-m)T].
Since
log L(A)=m log A - A[X1 + ••• + Xm +(n - m)T],
the MLE of A is easily found to be
m
= Em=1 Xi + (n - m)T. 
( .5)
Finally, we will discuss consistency, asymptotic unbiasedness, and asymptotic efficiency 
of MLE’s. We will not prove, or even formulate, the theorem, as it lies beyond the scope of 
this book. It is not difficult, however, to provide an informal explanation why MLE’s, under 
some regularity assumptions, have the properties asserted.
The main idea is as follows: In Section 11.4 we introduced the function J(X, 6) = 
d[log f (X, 6)], used to define the information I(6) and the concept of efficient esti­
mators. If X(n) = (X1, ...,Xn) is a random vector from distribution f(x, 6), then 
J(X(n),6) = П=1 J(Xi, 6), with components J(Xi,6) being iid random variables. 
We know from Section 11.4 that E[J(Xi, 6)] = 0 and VarJ(Xi,6) = I(6). Conse­
quently E[J(X(n), 6)] = 0 and Var[J(X(n), 6)] = nI(6). By the central limit theorem of 
Lindeberg-Levy (Theorem 9.6.1), we have
J(X^) ± Z, 
nI(TW)
(11.55)
where Z is the standard normal random variable.
Let T = T(X(n)) be an unbiased efficient estimator of 6 so that Ee (T) = 6 and Vare (T) = 
1/nI(6). We know also by (11.46) that
T = y 1( 6) J (X(n) ,6) + y 2( 6),
so
Ee (T )= y 1 (6) Ee [ J (X(n) ,6)]+ y 2 (6 )= Y 2( 6)
and
Vare(T) = y 2(6)E[ J(X(n), 6)]2 = y2(6)Var[J(X(n), 6)] = y2(6)nl(6).
Consequently, we must have 
y2 (6)=6,
y12 (6)=
1
n212(6),

338
ESTIMATION
which implies that 7 1 (в) = ± 1 /nI(в). It follows now that
T = ±-^x J (X( n) ,в)+ в, 
nl (в)
which means that
JX\,в) = ±Vni@(t - в). 
(11.56)
nI (в)
The left-hand side of (11.56) has an asymptotic standard normal distribution by (11.55), and 
the same must be true for the right-hand side (under any choice of sign).
Consequently, we proved the following theorem:
Theorem 11.5.1 IfT = T(X1, ...,Xn) isan efficient estimator of в based on a random sample 
from the distribution f(x, в), then the random variable
VnI (в)(T - в)
asymptotically has the standard normal distribution.
Actually, the same theorem holds if efficient estimators T are replaced by maximum likeli­
hood estimators вп of в, provided that these estimators are obtained by solving the equation
d X 
= j (X( n) ,в ) = o
дв
so that
J (X( n) ,вп )=0.
(11.57)
The proof requires imposing a number of technical assumptions, and is quite complicated, 
but the main idea is simple. We first expand the function J(X(n) ,в) about the point вn so 
that
dJ
J(X(n),в) = J(X(n),вn) + (в - On) — 
дв
о
0=On
+ •••
e=On
We want to show that the second order term converges to 0 in probability so that it can 
be neglected in the limit, and the same is true for the sum of all higher order terms. Using
(11.57), we then write
(n) 
Q A __
J (X ,в) ~ (в 
Оп ) ~
о 
e=eOn
The left-hand side is now a sum of iid components, as in the proof of Theorem 11.5.1, and 
it obeys the central limit theorem. Finally, studying the behavior of the derivatives
dJ (X( n) ,в)
we establish that Theorem 11.5.1 holds also with T replaced by estimators вn (with the same 
norming constants). This shows that вn are asymptotically unbiased, asymptotically effi­
cient, and have an asymptotic normal distribution with mean в and variance 1 /nI(вn). These 
properties make maximum likelihood estimators a preferred choice.
, 1 (а в ^2 9 2 J 
+ 2(в - оп) Ю2

METHODS OF OBTAINING ESTIMATORS
339
Least Squares Estimators
This method of estimation is dating back to Lagrange and Gauss—for an interesting account 
of its discovery see Stigler (1986). The basic setup is now different—the data are independent 
but they are not coming from the same distribution. For a given value u of some independent 
variable (random or not) U, observations (one or perhaps more) of some random variable 
Yu are taken. It is assumed that
Yu = Q (u) + e,
where Q (u) is some function of u, and e is a random variable (usually called error), such that 
E(e) = 0 and Var(e) = a2 < ж. It follows that
E (Yu) = Q (u) 
and 
Var( Yu) = a2.
The function Q(u) is usually called the regression of Y on u.
■ EXAMPLE 11.36
One of the common situations falling under the scheme above arises when we analyze 
some system that changes in time. Thus, u is the time of taking the observation of some 
attribute of the system, and Q(u) is the expected value of the observed random variable 
Yu, interpreted also as the “true” state of the system.
In some cases, we may take only one observation at any given time u; in other cases, 
we may have a number of observations made at the same time.
■ EXAMPLE 11.37
In some cases variable U can be controlled by the experimenter. For example, a chemist 
may study the rate of a certain reaction in different temperatures. He then chooses 
the temperature level u1 and observes the reaction rate one or more times. Then he 
changes the level to u2, repeats the observations, and so on. The numbers of obser­
vations need not be the same for different values u. In general, the choice of distinct 
values u1, ...,uk (as well as the choice ofk) and the choice of numbers of observations 
n1, n2, ...,nk to be made at selected points u1, ...,uk, belongs to the design of the 
experiment.
Assume now that we have the experimental data for the design that can be described by 
the set of pairs
(ui,ni), 
i=1,...,k, 
(11.58)
where ui’s are distinct values of variable U and ni’s are positive integers.
The data have form of the array {yij ,i =1, ...,k,j =1, ...,ni}, where yij is the value 
of random variable Yij , representing the jth observation for the value ui of variable U .We 
assume that all Yij ’s are independent, with
E(Yij)=Q(ui) and Var(Yij) = a2. 
(11.59)
In most typical cases, the functional form of Q is postulated and assumed to depend on 
some parameters. For instance, in the case of a linear regression model, we assume that
Q (u ) = eu + a, 
(11.60)
where в and a are the slope and intercept of the regression line. In more complicated setups, 
we may postulate a quadratic regression
Q (u) = в 2 u 2 + в i u + a,

340
ESTIMATION
or some other functional form of Q. Generally,
Q(u) = v(u;9i,92, ...,9r),
where v is a known function and 9 1, .. .,0r are some parameters to be estimated. The 
method of least squares is based on the quadratic form
S (9 1 ,...,9r )= 
£ [ yj - v (ui; 9 1, ...,9r )]2. 
(11.61)
i=1 j=1
The values 91, .. .,9 r that minimize S given by (11.61) are called least squares (LS) estimates 
of 91, ...,9r. As usual, those estimators, regarded as functions of the random variables {Yij} 
are called LS-estimators.
The usual way of finding 91, ... ,9r is by solving the set of simultaneous equations
dS n
Э9, = ,
l=1, . . . , r,
(11.62)
which in the present case take the form
E [ yij - v (ui; 9 1, ..., 9r)] £ dv (ui; 
) = 0. 
(11.63)
j=1 
i=1 
l
■ EXAMPLE 11.38 Linear Regression
Suppose that Q (u) = /Зи + a. In this case the algebra will simplify somewhat if we 
order all Yjj’s into a single sequence y 1, ..., yn, where n = 
=1 ni, and relabel the
corresponding values as u1, ...,un (n values ui of variable U, not necessarily all dis­
tinct). The quantity to be minimized is
n
S(a,e) = E (yj - eui - a)2. 
(11.64)
i=1
Differentiating with respect to a and в and setting the derivatives equal to 0, we obtain
n 
nn 
n 
n
в 
ui2 + a 
ui = 
uiyi and в ui + na = 
yi .
i=1 
i=1 
i=1 
i=1 
i=1
The solution can be written as
= = E(uiyi - u x y)
= E (ui - u)2
a = y — Ци,
(11.65)
(11.66)
provided that (ui - u))2 > 0. The latter condition is ensured if there are at least two 
distinct values of u used in the experiment, that is, if not all observations are made for 
the same value of S.
An easy check shows that (11.65) does minimize function U.
Robust Estimators
An important issue in estimation problems is to obtain estimators, generally termed robust, 
that would be relatively unaffected by deviations from the assumed model. We will now 
briefly sketch two such approaches.

METHODS OF OBTAINING ESTIMATORS
341
To grasp the main issues involved here,_consider the problem of estimating the mean ^ 
of a distribution. Then, the sample mean X is an estimator of /л, and we know that X has 
a number of desirable properties, such as consistency, unbiasedness, and efficiency. These 
properties, however, are valid under specific assumptions about the underlying distribu­
tion. If the actual distribution differs insome way from the assumed one, X may no longer 
have the same properties. We say that X is sensitive to the deviation from the model, or 
contamination. This concept is intended to describe the occurrence of outliers, that is, obser­
vations that follow a distribution different from the one assumed in the model. Most of the 
outlier distribution is usually concentrated around much larger (or smaller) values than those 
typically encountered in the model. Formally, the model assumes the distribution f (x, 6), 
where 6 is (say) the mean, while the actual sample is taken from the distribution
Ф(x, 6) = (1 - e) f (x, 6) + eg(x),
(11.67)
where most of the mass of g(x) is far away from the range of “typical” values under f(x, 6). 
The two important approaches to robust estimation are L-estimators and M -estimators.
L-Estimators L-estimators, linear functions of order statistics, provide good estimators 
of location and scale parameters.
Formally, 6 will be called a location parameter if
f(x, 6)=h(x - 6)
for some probability density (or probability mass function) h. 
Similarly, 6 is called a scale parameter if
f (x,6 )=1 ЧЮ
for some probability density (or probability mass function) h.
The mean of a distribution may or may not be its location parameter. For instance, it is 
so in the case of normal distribution. However, in the case of exponential distribution, the 
mean is a scale parameter, while in the case of a gamma distribution, the mean is neither a 
scale or a location parameter.
Let X1 , ...,Xn be a random sample from the distribution f(x, 6), and let
X1:n < X2:n <■■■< Xn:n
denote the order statistics of the sample. The L-estimator will be any statistic T of the form
n
T = E Yn,kXk:n, 
k=1
where Yn,k for k = 1, ... ,n is a double array of coefficients. The class of L-estimators con­
tains many well-known estimators: Choosing Ynk = 1 /n for k = 1, ...,n gives T = X. The 
choice Yn 1 = 1, Yn k =0 for k > 2, or yn n = 1, Yn k =0 for k <n, gives two extreme order 
statistics X1:n and Xn:n. In a similar way, one can obtain any sample quantile. Choosing 
Yn,[3n/4]+1 = 1, Yn,[n/4]+1 = — 1, Yn,k = 0 for remaining k, one obtains a sample interquar­
tile range, and so on.
Perhaps the most important L-estimators are the trimmed and Winsorized means, defined 
as follows:

342
ESTIMATION
Definition 11.5.2 Let 0 < a < 1 / 2. Then, the a - trimmed mean is
n— [ na ]
Un = -------- X _ Xk:n,
n n - 2[na] 
:n
k=[na]+1
while the a-Winsorized mean is(
n— [ na ]
[na]X[na] + 1:n + 
у Xk:n + [na]Xn— [na]:n
k=[na]+1
(11.68)
(11.69)
□
On the one hand, a-trimming consists of removing the 100a% of lowest and highest 
observations from the sample, and taking an average of the remaining ones (the middle 
100(1 - 2a)% of observations). On the other hand, a-Winsorizing consists of replacing 
each observation in the lower 100a% and in the upper 100a% of the sample by the sample 
quantile of order a and 1 - a, respectively, so that the sample size will stay unchanged. The 
Winsorized mean is then calculated as the mean of the Winsorized sample.
It is clear that the purpose of trimming (or Winsorizing) is to eliminate (or decrease) the 
effect of outliers in the sample. An important issue is to define the notion of optimality and 
then to determine the optimal level a at which the mean should be trimmed or Winsorized.
Among the main advantages of L-estimators is their asymptotic normality when the 
weights Yn k are reasonably smooth or if they are nonzero for a certain number of central 
order statistics. For more details, see Serfling (1980) and Arnold et al. (1992).
M -Estimators Another class of estimators is obtained as follows: Let h(x, u) be a func­
tion of two arguments. Given a sample x 1, x 2, ...,xn from the distribution f (x, в), take as 
an estimator of в the solution of the equation
XT h (xk ,u )=0. 
(11.70)
k=1
Such estimators are most often obtained by solving an approximate minimization prob­
lem. Suppose that we have a “distance” of some sort (not necessarily satisfying any condi­
tions for metric), say H(x, u). As an estimator of в, we choose a point u* that minimizes the 
sum
n
H(xk,u), 
(11.71)
k=1
interpreted as the sum of distances from u to all sample points. In a sense, u* is the point 
closest to the sample, with closeness being expressed by the function H. Differentiating 
(11.71) with respect to u and setting the derivative equal to 0, we obtain equation (11.70) 
with h(x, u) = dduH(x, u).
This formulation comprises two important classes of estimators, namely MLE’s 
and LS-estimators. Indeed, if we define the function H(x, u) as - log f(x; u), then 
h(x,u) = - du log f (x, u) and the M-estimator corresponding to this choice is the 
maximum likelihood estimator (the minus sign is implied by the fact that now the problem 
is formulated as a minimization problem).
By taking appropriate functions H and h, we can obtain different variants of least square 
estimators. Similarly, trimmed or Winsorized means can be obtained by appropriate choices 
of the functions H and h. For example, we may take H(x, u)=H(x - u) for some function 
H of one argument. The M-estimator then minimizes the sum n=1 H(Xi - u). For H(x) = 

METHODS OF OBTAINING ESTIMATORS
343
x2, we have the simplest least square estimator. If H(x) = x2 for |x| < k and H(x) = k2 for 
|x| >k,we obtain a form of the Winsorized mean.
As with L-estimators, the main direction of research is to study the asymptotic properties 
(e.g., normality) of M-estimators under some general assumptions on functions H or h, and 
distributions of Xi .
PROBLEMS
11.5.1 Let X 1, ...,Xn be a random sample from GAM( a, X) distribution. Find: (i) The 
MME of 9 = (a, X), using the first two moments. (ii) The MME of a when X is 
known, and the MME ofX when a is known.
11.5.2 Find the MME of parameter 9 in the distribution with density f(x, 9)= 
(9 + 1) x-(6+2), for x > 1,9 > 0.
11.5.3 Let X1, ...,Xn be a random sample from the distribution uniform on the union of 
the two intervals: [-2, -1] and [0, 9]. Find: (i) The MME of 9. (ii) The MLE of9. 
(iii) The MLE of 9 if positive Xi’s are recorded exactly, and negative Xi’s can only 
be counted. (iv) The MLE of 9 if Xi ’s cannot be observed, and one can only count 
the numbers of positive and negative ones.
11.5.4 Let X1 , . ..,Xn be a random sample from Poisson distribution with mean X. Find 
theMLEofP(X =0).
11.5.5 (Bragging Tennis Player) As in Example 11.34, consider tennis players A and B who 
from time to time play matches against each other. The probability that A wins a set 
against B is p.
Suppose now that we do not have complete data on all matches between A and B; 
we learn only of A’s victories, so we know numbers a3, a4, and a5 of matches won 
in 3, 4, and 5 sets (we do not even know whether he lost any matches with B).
Show that one can find the MLE of p, and find the MLE of the total number of 
matches and of the number of sets that A lost against B (do not attempt the algebraic 
solution).
11.5.6 Some phenomena (e.g., headway in traffic) are modeled to have a distribution of a 
sum of a constant and an exponential random variable. Then the density of X has 
the form
0forx<b
ae-“(x-b) 
for x > b,
where a>0 and b>0 are two parameters. Find: (i) The MME of9 =(a, b). (ii) The 
MLE of 9.
11.5.7 A single observation of a random variable X with a geometric distribution results 
in X = k. Find the MLE of the probability of success 9 if: (i) X is the number of 
failures preceding the first success. (ii) X is the number of trials up to and including 
the first success.
11.5.8 Find the distribution of the MLE of the probability of success 9 based on two 
Bernoulli trials.
11.5.9 Let X 1, ...,Xn be a random sample from N( 9, a 2) distribution, 9 = 0 ,a2 is 
known. Determine the asymptotic distribution of (X )1 /2 using the invariance 
property of MLEs.
f(x; a, b)=

344
ESTIMATION
11.5.10 Let X 1, ... ,Xn be a random sample from a distribution with density f (x, в) = 
3в-3x2 for 0 < x < в. (i) Find the MlE of в. (ii) Find the MME of в. (iii) Approx­
imate the distribution of T = 3X. (iv) Obtain the MSE of Ta = aX as an estimator 
of в.
11.5.11 Suppose that there were 15 successes in 24 Bernoulli trials. Find the MLE of the 
probability of success в if it is known that в < 1/2.
11.5.12 Two independent Bernoulli trials resulted in one failure and one success. What is 
the MLE of the probability of success в ifit is known that: (i) в is at most 1/4. (ii) в 
exceeds 1/4.
11.5.13 Let X 1, ..., Xn be a random sample from POI(A) distribution. Find the MLE of A 
assuming that: (i) X 1 + • • • + Xn > 0. (ii) X 1 + • • • + Xn = 0.
11.5.14 Find the MME and MLE of the standard deviation ofa Poisson distribution.
11.5.15 Let X 1, ...,Xn be a random sample from N( p, a 2) distribution, p is known. Find 
the MLE of a: (i) Directly. (ii) First finding the MLE of variance a2 and then using 
the invariance property.
11.5.16 Let X 1 ,X2 be a random sample from a N(p, a2) distribution with p and a22 
unknown. Find the MLE of a2 if the only available information is that the 
difference between observations equals 3.
11.5.17 Find the MLE of the mean of a U[в 1, в2] distribution based on a random sample of 
size n.
11.5.18 For n observations taken from the U[0, в] distribution, let Un be the number of the 
ones that are less than 3. Find the MLE of в.
11.5.19 Suppose that the median of20 observations, taken from a normal distribution with 
an unknown mean and variance, is 5 and that only one observation differs from the 
median by more than 3. Suggest an estimate of the probability that the next two 
observations will both be between 4 and 5.
11.5.20 Let X1 , .. .,Xn be a random sample from a log-normal distribution with parame­
ters p and a2 [this means that log Xi ~N(p, a2)]. Find the MLE of p and a2.
11.5.21 Let X1 , ...,Xm be a random sample from the N(p1 , a12) distribution and let 
Y1 , ...,Yn be a random sample from the N(p2 , a22) distribution, with Xi’s being 
independent from Yj’s. Find the MLE of: (i) p1, p2, a2 ifa1 = a2 = a. (ii) p, a12, a22 
where p1 = p2 = p.
11.5.22 Y1 , . . .,Yn are independent variables. Assuming that x1 , . . . ,xn are such that 
(xi - x)2 > 0, compare the MSE’s of the MLE and LS-estimators of parameter 
в > 0, if: (i) Yi ~ EXP(xi Iв). (ii) Yi ~ POI(9xi).
11.5.23 For independent variables Y1, ...,Yn with distribution N(a + fix^a2), where 
x 1, ... ,xn are fixed, show that the LS-estimator and ML-estimator of в = (a, в) 
coincide.
11.5.24 Let X 1, ... ,Xn be a random sample from U[ в, в +1] distribution. (i) Show that 
T = c(Xn:n - 1) + (1 - c)X 1:n, 0 < c < 1, is the MLE of в, and find the value of c 
that minimizes its MSE. (ii) Determine the asymptotic distribution of T if c = 0.5.
11.5.25 Let X1, ...,Xn be a random sample from a distribution with density f(x, в)= 
в(1 + x)—(1+e) and for x > 0 and 0 otherwise, в > 1. Find the MME of в.

SUFFICIENCY
345
11.5.26 Let X1 , ...,Xn be independent observations from a distribution with density 
f(х,в)=2х/в2, for 0 < x < в and 0 otherwise. Find the MME of в and 
approximate its distribution.
11.5.27 Let X 1, ..., Xn be a random sample from EXP( в) distribution. Find the MLE of 
the second factorial moment E(X(X - 1)) and determine its asymptotic distribu­
tion.
11.6 SUFFICIENCY
The considerations of this section are motivated by the following observation: each of the 
estimators analyzed in this chapter is dependent on the random sample X 1, ...,Xn through 
some statistic (e.g., X or Xn:n), that reduces the data to a single number. From a purely 
formal viewpoint, any such reduction involves some loss of information.
The concept of a sufficient statistic is intended to cover situations where the information 
lost in reducing data to the value of a statistic is not relevant for the purpose of estimating 
parameter в. Thus the definition of sufficiency ofa statistic is relative to a given parameter в.
As before, we consider a random sample X1,...,Xn from the distribution f(x, в), where 
в belongs to some parameter space 0. Again, f can be either a density or a probability 
function of a discrete distribution.
The definition below introduces a statistic that conveys the same information about в as 
the whole sample (X1,...,Xn).
Definition 11.6.1 The statistic T is said to be sufficient for в if the conditional distribution 
of X 1, ..., Xn, given T = t, does not depend on в for any value t. 
□
Before exploring the consequences of the definition let us analyze some examples.
■ EXAMPLE 11.39
Consider two independent Bernoulli trials X1, X2, with probability of success p, and 
let T = X1 + X2. The conditional distribution of (X1, X2) given T is
P{X1 =0,X2 =0|T=0}=1,
P{X1 =1,X2 =1|T=2}=1.
Since P (T =1)=P (X1 =1,X2 =0)+P (X1 =0,X2 =1)=2p(1 - p), for T =1 
we have
P{X1 =1,X2 =0|T=1}= P {X 1 = 1 ,X 2 =0 }
P (T = 1)
p (1 - p) = 1
2p (1 - p) 
2.
Thus, whatever the value ofT (0, 1, or 2), the conditional distribution of (X1, X2) does 
not depend on p.
■ EXAMPLE 11.40
Let Xt and Xs be the numbers of events in a Poisson process with intensity A, observed 
between 0 and t, and between t andt + s. We will show that U = Xt + Xs is a sufficient 
statistic for A.

346
ESTIMATION
Indeed, since Xt and Xs are independent, we have for k =0, 1, ...,n,
P{X = kX = n - kIU = n} = P{Xt = k}P{X- = n k k}
P {Xt = k,Xs = n kIU = n} = 
P {U = n}
(Xt) k -xt 
(As) n-k -Xs
_ 
k! e X (n-k)! e
[x(t+s)]n e-X(t+s) 
n!
= nk
k 
n-k
ts
t + s t + s
Thus Xt, given U = n, is binomial with parameters n and t/(t + s), and does not 
depend on A.
If the conditional distribution of observations X1, ...,Xn, given the statistic T = t, does 
not depend on the parameter в that we want to estimate, then (once we know that T = t) 
the additional knowledge of a particular configuration of X1, ...,Xn observed in the data 
is irrelevant in estimating в. For instance, in Example 11.39, T = 1 means that we had one 
success and one failure. The fact that the first trial was a failure and the second was a success 
is of no additional help in estimating p.
Since the process of determining the conditional distribution of observations given the 
value of statistic T is sometimes cumbersome, it is desirable to have another method for 
verifying that a statistic is sufficient. Such a method is given by the following theorem, due 
to Neyman:
Theorem 11.6.1 (Factorization Criterion) Let X1, ...,Xn be a random sample from the dis­
tribution f (x, в), with в & 0 .A statistic T = T (X 1, ..., Xn) is a sufficient statistic for в if 
and only iffor all x = (x 1, ...,xn) and all в & 0 the joint distribution
fn(x, в) = f (x 1,в) ••• f (хп,в )
can be written as
fn (x ,в )= u [ T (x) ,в ] v (x), 
(11.72)
where u isa nonnegative function that depends on both в andx = (x1, ...,xn), but dependence 
onx is only through the function T, andv is a function ofx = (x1, ...,xn) that does not depend 
on в.
Proof: We will give the proof in the discrete case; the proof for the continuous case requires 
careful consideration because densities are defined only up to sets of probability zero. Thus, 
we have now f (x, в) = Pe{Xi = x}, i = 1, ...,n.
Let Q(t) be the set of all x = (x1, ...,xn) such that T(x) = t. Then
Pe (T = t)= E fn (x,в).
x EQ (t)
Suppose first that T is a sufficient statistic. Then for T = t, and any point x & Q(t) the 
conditional probability Pe{X = x\T = t} does not depend on в; let us call it v(x). Letting 
u(t, в) = Pe{T = t}, we obtain, for any fixed x & Q(t),
fn(x, в) = P{X = x} = P{X = xIT = t}Pe{T = t} = v(x)u(t, в),
which is the factorization (11.72).

SUFFICIENCY
347
Conversely, suppose that fn (x, в) satisfies formula (11.72) for some functions u and v. Let 
us fix t and в e 0 and compute the conditional probability of a point x given T = t. Clearly, 
for x / Q (t), we have Pe {X = x\T = t} = 0. For x e Q (t), we have
Pe {X = x\T = t} = Pe {X = x} 
Pe {T = t}
fn (x ,в )
EyEQ (t) fn (y, в)
u (t,e) v (x) 
v (x)
Ey&Q(t) u(t,e)v (y) 
EyEQ(t) v(y) '
□
We will now apply Theorem 11.6.1 to find sufficient statistics in various families of 
distributions.
■ EXAMPLE 11.41
Consider again the Bernoulli trials with probability p of success. We have here, letting 
t = E xi,
n
fn(x1,...,xn,p)= 
pxi(1 - p)1-xi = pt(1 - p)n-t
i=1
1 -p
t
(1-p)n
p
In this case, a sufficient statistic is the total number of successes T = 
Xi , while the
function v (x 1, ..., xn) = 1.
■ EXAMPLE 11.42
In a Poisson distribution, we have, letting t = 
xi ,
n- Xх 
, 
. 
, 
1
fn (x 1, ...,Xn,X ) = П xj e 
= Xe ~! 
~! ,
i = 1 xv 
x 1’ 
xn'
which again shows that T = 
Xi is a sufficient statistic. Here u(t, X) = Xte~nX, while
v (x 1, ...,xn ) = (x 1! • • • xn !) - 1.
■ EXAMPLE 11.43
Now, let (x 1, ..., xn) be observations from a normal distribution N(p, a2) where a2 
is known. Then, the joint density of the sample can be written as
fn(x 1 ,...,xn,^) 
an (2 n) n/2 exP | 2 a 2 
(xi ^) j
= an(2n)n/2 eXp { - 202 (E x2 2 2^ E xi + 
2) }
= exp{ 02 E xi 2 n^2 } v (x 1, ...,xn ) .
Thus, 
Xi is a sufficient statistic for ^, with
v(x1,
exp{2 1 /(2a2) £ x2} 
...,xn) 
an (2 n) n//2

348
ESTIMATION
If now ^ is known, but a2 is the unknown parameter, we take v (x 1, ...,xn) = 1, 
and the sufficient statistic is 
(Xi - ^)2.
■ EXAMPLE 11.44
Consider finally the case of sampling from a U[0, в] distribution. The joint density of 
the sample is 
1n if Xn.n < в
f (x 1 ,...,xn,e ) = 
* 
n: n-
0 otherwise,
or equivalently
f (x 1 , . . . , xn , в) 
en I(в, max( x 1 , ... , xn )) ,
where I(в,с) = 1 if в > c and 0 if в < c. This shows the function u(в,Т) (with 
v(x1, ...,xn) = 1) and that Xn:n is a sufficient statistic.
Sufficient statistics are not unique. Every one-to-one transformation ofa sufficient statis­
tic is again a sufficient statistic. For instance, in Example 11.43, an alternative sufficient 
statistic to Xi is X = (1 /n) Xi.
The concept of sufficient statistic can be generalized in an obvious way to a set of jointly 
sufficient statistics to cover a multidimensional case. The intuitions motivating the concept 
are the same as in a one-dimensional case.
We will now formulate the definition using the factorization theorem, that is, use the asser­
tion of the theorem as a basis for the definition.
Definition 11.6.2 The statistics T1, ...,Tk are minimal jointly sufficient for в if the distri­
bution fn(x, в) satisfies the following condition: for every x = (x 1, ...,xn) and в e 0 we 
have
fn(x,в) = u[T1(x), ...,Tk(x),в]v(x),
where the nonnegative function v(x) does not depend on в while the function u depends on 
в, and depends on x only through the values of statistics T1, ... ,Tk. 
□
■ EXAMPLE 11.45
In a random sample X 1, ... ,Xk from a N(p, a2) distribution, where both ^ and a2 
are unknown so that в = (p,,a2), we have
fn(x,в) 
(2na2)n/2 exp { 2a2 
(xi ^) j
= a—n exp J - ?xL + ' V x - I ; 
(2n)n/2 p[ 2a2 + a2^ xi 2a2 J ’
statistics T1 = 
n=1 Xi and T2 = 
n=1 X2 are jointly sufficient for в.
If T1, .. .,Tk are jointly sufficient for в, and T*, ... ,T are obtained from T1, ... ,Tk by 
a one-to-one transformation, then T*, ... ,Tk are also jointly sufficient for в. Thus, another

SUFFICIENCY
349
n(X - m)2 1
2 a 2 
J
pair of jointly sufficient statistics in Example 11.45 is X and S2 = (1 /n) 
"=1 (Xi - X )2.
This can also be seen from the representation
fn(x,3) = (2n)-n/2(12)-n/2 exP ( -712 
(xi - M)2|
2 a2
= (2n)-n/2(a2)-n/2 exp | -21-2 
(xi - X)2 -
__ /—n-\ — n/2 2 -n/2 
n 2 
2 >2]'l
= (2n) ( (1 ) 
exp | -212 [S -(X — ^) ] J-.
Obviously, the sample (X1, ...,Xn) is always jointly sufficient. It suffices to write for­
mally Ti(X1, ...,Xn)=Xi for i =0, 1, ...,n. This is true but useless. It is also true that 
the order statistics (X1:n, X2:n , ...,Xn:n ) are jointly sufficient, since
nn
fn(x, 3) = П f(xj, e) = П f(xi:n, 3), 
j=1 i=1
where the factors of the last product are a permutation of the factors of the middle product.
Thus, a set of jointly sufficient statistics always exists, and it is natural to look for the 
maximal reduction of data that retains sufficiency. Here reduction is meant both in the 
sense of reducing the dimensionality, and in the sense of using transformations that are not 
one-to-one, such as squaring.
The definition of maximal reduction, hence minimality of sufficient statistic, is as follows:
Definition 11.6.3 A sufficient statistic T is called minimal if T is a function of any other 
sufficient statistic. 
□
The definition covers the idea of maximal reduction of the data, still leaving sufficiency 
intact. Indeed, suppose that T is minimal in the sense of Definition 11.6.3 and still can be 
reduced. This means that there exists a function h which is not one-to-one such that U = 
h(T) is a sufficient statistic. Then, T is not a function of U, which gives a contradiction.
Definition 11.6.3 extends to the case of a minimal sufficient set of statistics.
Definition 11.6.4 A set {T1, ...,Tk} of sufficient statistics is called minimal if T1, ...,Tk are 
jointly sufficient and they are functions of any other set of jointly sufficient statistics. □
The intuition here is as follows: if {T1, ...,Tm} and {T1, ... T} are both jointly suf­
ficient, and the second set is a function of the first, that is, if T' = ^i(T1, ...,Tm) for i = 
1, ... ,k and for some functions ^ 1, ..., <^k, then
( T1 ,...,Tm ) h ( T1 ,...,Tk ) ,
where is an ordering among jointly sufficient sets of statistics. The minimal jointly suf­
ficient statistics are at the “base” of this ordering, while the fact that (X1:n, ...,Xn:n) is 
always a set of jointly sufficient statistics means that the set of statistics being ordered by 
relation > is not empty. Example 11.45 shows that the minimal sufficient set of statistics is 
not unique; however, all these minimal sufficient sets are obtained as one-to-one functions 
of other minimal sufficient sets.

350
ESTIMATION
f(x; в) =
■ EXAMPLE 11.46
Let X 1, ...,Xn be a random sample from the distribution uniform on [—в, в ] so that
71 
if — в < x < в
2 v
0 otherwise.
Proceeding as in Example 11.44, we can easily show that the pair of extreme order 
statistics (X1:n, Xn:n) is jointly sufficient for в. However, this is not a minimal set: the 
statistic T (X1:n, Xn:n) = max(|X1:n|, |Xn:n|) is a single sufficient statistic for в.
Typically, the dimensionality of the minimal set of jointly sufficient statistics equals the 
number of dimensions of the parameter в. Thus, in the case of a normal distribution with 
the parameter being the pair (p, a2), the minimal sets of jointly sufficient statistics consist 
of two statistics (e.g., Xi and Xi2). However, there exist distributions that depend on a 
single parameter, and yet the only jointly sufficient statistics (hence the minimal sets of jointly 
sufficient statistics) are the order statistics (X1:n, ...,Xn:n). This is true, for instance, for the 
Cauchy distribution with density
f(x;в)= г-, . /—. 
n [1 + (x — в )2]
Consider now the role that sufficient statistics play in estimation. Observe first that the 
likelihood function is
L (в, x) = v (x) u [ T1(x), ..., Tk (x), в ], 
(11.73)
where {T1, ...,Tk} is a set of jointly sufficient statistics (minimal or not). Since the factor 
v(x) plays no role in the determination of в at which the likelihood attains its maximum, 
we can expect that the MLE в of в will be a function of T1, ...,Tk. Since the same kind of 
representation of the likelihood is valid if T1 , .. .,Tk form a minimal sufficient set, we can 
expect that в will be a function of a minimal sufficient set of statistics.
This argument is valid provided that the MLE is unique (which is usually the case). When 
the MLE is not unique (for such situations, see Example 11.30), one cannot claim that they 
are all functions of sufficient statistics, but one of them will be.
We can therefore state the following theorem:
Theorem 11.6.2 If the MLE of в exists and is unique, then it is a function of minimal sufficient 
set of statistics. If the MLE is not unique, then there exists an MLE that is a function of a 
minimal sufficient set of statistics.
The main importance of sufficient statistics is, to a large extent, related to the next 
theorem, according to which any estimator that is not based on sufficient statistic can be 
improved, and hence is not admissible (see Definition 11.3.1). The theorem is formulated in 
the case of a single sufficient statistic T. However, it can be easily generalized to the case of 
the minimal sufficient set of statistics.
Theorem 11.6.3 Rao-Blackwell Let T be a statistic sufficient for в in a family of distributions 
{f(x, в) and let W be an estimator of g(в). Statistic
W * (T ) = Ee (W IT) 
(11.74)
is also an estimator of g(в). Moreover, E(W*) = E(W) and its risk R(W*,в) = 
E{ [W* — g(в)]2} satisfies the condition
R(W *,в) < R(W, в) 
(11.75) 

SUFFICIENCY
351
for all в е 0. The inequality in (11.75) is strict for some в unless W is a function of T and is 
an unbiased estimator of g (в).
Proof: We need to show first that formula (11.74) indeed defines an estimator of g(в), that 
is, that the left-hand side does not depend on в but only on the sample X1, ...,Xn. We will 
also show that this dependence is through the value ofT only so that the obtained estimator 
is a function of the sufficient statistic T. The second part of the proof will consist of showing 
that inequality (11.75) holds for every в.
To show that formula (11.74) defines an estimator, we will carry the argument in the dis­
crete case, with f (x, в) = P{X = x\0}. Let t be a possible value of T, and let also Q(t) = 
{x:T(x)=t}.
For any fixed t and x е Q(t), the conditional distribution of X given T = t is, by the 
factorization theorem,
P{X = x\T = t в} = 
fn(x,в) 
= 
v(x)u(*,в)
{ 
\ 
, } EyGQ(t) fn(У,в) 
EyGQ(t) v(y)u(W)
= 
v(x)
Eyeq(t) v(y),
which is independent of в. On the other hand, P{X = x|T = t, в} =0if x е/ Q(t), which is 
also independent of в . Consequently, we have
ExGQ(t) W(x)v(x)
Ee (V T = t )= E W (x) P {X = x T = ^} ^x^t^^T-, 
xGQ(t) 
yGQ(t) y
which is independent of в, as asserted.
The estimator Ee (W|T) depends on the actual sample observed in the following sense: 
after observing the sample X = x*, compute T(x*) = t, and use (11.76) to obtain Ee (W \T).
Clearly, if T(x*) = T(x**) = t, then the value of the estimator Ee(W\T) is the same for 
samples x* and x**. This means that this value depends on the sample only through the value 
of the sufficient statistic T.
It remains now to prove the inequality (11.75). Based on Theorem 7.7.2,
Var(X) = EY {Var(X|Y)} + VarY {E(X|Y)}. 
(11.76)
Letting Ee(W) = k(в), the risk of estimator W is
R(W, в) = E{[W - g(в)]2} = E{([W - k(в)] + [k(в) - g(в)])2}
= E{[W - k(в)]2} +[k(в) - g(в)]2
= Var(W) + [k(в) - g(в)]2, 
(11.77)
since the cross product is easily seen to vanish. The second term is simply the square of the 
bias [recall that W is used to estimate g(в), rather than в].
We will now use the formula (11.76), taking X = W and Y = T. Thus, for every в we have
Var(W) = ET {Var(W |T)} + VarT {E(W |T)}
> VarT{E(W\T)} = Var(W*). 
(11.78)
Now, by the fact that
k (в) = E (W) = ET {E (W T))} = E (W *), 
(11.79)

352
ESTIMATION
we can write, using (11.77), (11.78), and (11.79),
R(W, 9) > Var(W*) + [k(9) - g(9)]2 = Var(W*) + [E(W*) - g(9)]2
= E[W* - g(9)]2 = R(W*,9).
It remains to determine the conditions for equality in (11.75). It is clear that the equality 
occurs if and only if k(9) = g(9) and ET{Var(W\T)} = 0. The first condition means that 
W is an unbiased estimator of g(9). The second condition means that Var(W\T) = 0. 
That is, for every value t of T, the random variable W is constant; hence, W is a 
function of T. 
□
What the Rao-Blackwell theorem says is that in order to decrease the risk of an estimator 
V , one should decrease its bias. Then, if the estimator is not a function of sufficient statistic 
(or statistics), replace it by the estimator defined as the conditional expectation of V given 
sufficient statistics.
We will now illustrate the second part of this principle. Thus, in the examples below we 
will start from some unbiased estimators and improve them by conditioning with respect to 
sufficient statistics.
■ EXAMPLE 11.47
Let X 1, ..., Xn be a random sample from POI(A) distribution. Suppose that we want 
to estimate P{X = 0} = e-A. 
__
We know (see Example 11.42) that the sufficient statistic for A is X, or equivalently, 
T = n=1 Xi, which has POI(nA) distribution. Let us estimate P{Xi = 0} = e-A = 
g(A) by W = U/n—a relative frequency of Xi’s in the sample that are equal to 0. To 
compare the risks of W and W* = E(W \T), it is enough to compare their variances, 
since it will be shown that W and W* are both unbiased estimators for g(A).
Clearly, U is binomial with parameters n and g(A), so E(W) = (1/n)E(U) = g(A). 
Thus, W is unbiased for g(A), and its risk equals
R(W,A) = Var(U/n) =
(1
e-A)
Now let W* be defined as
W * = E (W\T) = 1E (U\T). 
n
(11.80)
(11.81)
e
n
Clearly, the number of Xi’s which are equal to 0 cannot exceed n.IfT =1, then U = 
n - 1, so it remains to consider cases where T = t>1.
Let us start by determining the conditional distribution of one of the observations, 
say X 1, given T = t. We have, for j < t,
i
n
X1 = j \ 
Xi = t
i=1
P {X 1 = j,En=2 Xi = t - j} 
p {E n=1 Xi = t}
Aj e-X ,, [(n— 1) A ] t-j - (n- 1) A 
j! X (t-j)! 
e
(nA)t „-nA 
t! e
which shows that given 
Xi = t, the variable X1 is binomial with parameters t and
1/n.

SUFFICIENCY
353
Now let 
1ifXi =0
Yi = 0ifXi > 0,
so that for each Yj we have
E(Yj IT = t) = P(Xj =0IT = t) = P(X 1 =0IT = t) = (1 - 1. 
jj 
1 
n
Since U = YL +------ + Yn, we obtain
W * = n E (U IT) = n E (Y1 + ... + Yn IT)
= -Y E (Yi IT )=(1 — -L 
(11.82)
nj 
n
j=1
a result that is somewhat unexpected.
Finding the risk of W* (in order to compare it with the risk of W) requires some 
work. We know that W* must be unbiased because W = U/n was unbiased, and there­
fore, we need to compare only variances of W* and W. Recalling that T = -=1 Xi 
has POI(nX) distribution, we have
EzT = £ z x P{T = t} = £ z 
'e-n
t=0 
t=0
= e~nX eznX
(znX) t e-znX = enX ( z- 1)
<tt
E
t=0
On the other hand, E[zT]2 = E[(z2)]T = enX(z2 1). Consequently
Var(zT) = E[zT]2 - [E(zT)]2 = enX(z2- 1) - e2nX(z- 1).
The estimator W* is obtained by putting z =1- 1/n, which gives
Var( W *) = enX [((n- 1)/n )2- 1] — e 2nX [(n- 1)/n- 1]
= e-X (2 - 1/n) — e-2 X = e-2 X (eX//- — 1)
To compare the risks (variances) of the original estimator W = U/n and the improved 
estimator W*, observe that the risk of W, given by (11.80), can be written as
e-X(1
e-X)
Xe-2X + 
'X (eX — X — 1).
n
n
On the other hand, for the risk of W* we have
^-2X (eX/n — 1) = e-2X X + —- + —---+ ...
( 
) E + 2 n 2 + 6 n3 + 
)
__ Xe-2X 
e-2X /Xe2 
X3
2+6 + '
which is smaller if n is sufficiently large.

354
ESTIMATION
■ EXAMPLE 11.48
Consider now estimators T1-T5 of 6 in the U[0,6] distribution introduced in Example 
11.5. Three of them, T3, T4, and T5, are not functions ofa statistic T1 = Xn:n sufficient 
for 6 (see Example 11.44). Theorem 11.6.3 will be applied to improve estimators T3, T4, 
and T5 .
SOLUTION. The improved estimator T3 is
T* = Eg (T3 IT1) = Eg {(T1 + X 1: n) IT1} = T1 + Eg (X 1: n\T1).
Given T1 , other n - 1 observations are iid, each with a U[0, T1 ] distribution.
Conditional expectation E(X1:nIT1) is the same as the expectation of a minimum of
X1, ..., Xn- 1, each Xi being uniform on [0, T1]. This conditional expectation equals
(1/n)T1. Consequently,
T3* = T1 + 1T1 = 
3 
1 n1
n +1
n
T1,
which is equal to the estimator T2 considered in Example 11.5.
T* = Eg {(n + 1) X 1: n\T1} = (n + 1)1 T1, 
:n 
n
where we used the results obtained in determining T* . Finally, for T5 we have
2
T5* = Eg {T5\T1} = Eg{ -(X 1 + ... + Xn)\T1 J
= - E (X 1 + 
+ Xn\T1) .
nn
In this case, given T1 , the sum X1 + .. . + Xn must have one term equal to T1 , while 
the others have a uniform distribution on [0, T1 ]. So again, letting Xi be uniform on 
(0, T1 ), we have
E (X 1 +-----+ Xn\T1) = T1 + E (X1 + 
+ Xn- 1)
= t1 + (n -1) T1 = n + 1 
2
T1,
and therefore
T5*
x n+1 t1 = n+1 t1. 
2n
2
n
Observe that improving three different estimators (T3 ,T4 , and T5 ) by conditioning 
with respect to sufficient statistic T1 led in each case to the same unbiased estimator 
T2 =[(n + 1)/n]T1. The natural question arises: Was it a coincidence, or a rule? If such 
a result occurs as a rule, we could always select an unbiased estimator for which the 
conditioning would be especially simple. Thus, we would find the unique unbiased estimator 
that could not be improved any further, hence with minimal risk. We will now introduce 
one more concept that connects all the pieces together.
The situation at present may be summarized as follows: On the one hand, we have the 
Cramer-Rao inequality, which tells us how much reduction of the variance (hence of the 
risk for unbiased estimators) is possible. This bound may be effectively calculated in textbook 
cases, but in real-life situations, it can be hard or impossible to determine.

SUFFICIENCY
355
On the other hand, we have the Rao-Blackwell theorem, which tells us that unbiased 
estimators that are not based on sufficient statistics can be improved; to be more specific, 
their variance can be reduced by conditioning on sufficient statistics.
Again, the technical difficulties of such conditioning can be formidable. But here the 
situation can often be simplified. Rather than try to improve an estimator by finding its 
conditional expectation on a sufficient statistic, we can simply abandon the effort and refrain 
from using estimators that are not functions of sufficient statistics. Instead, we can try to find 
an unbiased estimator that is built only on sufficient statistics. This may still be technically 
difficult but often easier than determining conditional expectations.
Once we find an unbiased estimator that is a function ofa sufficient statistic (or a minimal 
sufficient set of statistics), the Rao-Blackwell theorem tells us that it cannot be improved any 
further (at least by conditioning). We therefore are tempted to conclude that we found the 
MVUE. Such a conclusion is justified if the estimator in question has variance equal to the 
right-hand side of the Cramer-Rao inequality. Otherwise, the reasoning on which it is based 
still has a flaw and has to be amended. Indeed, this reasoning works if there is only one unbi­
ased estimator based on a minimal sufficient statistic (or minimal sufficient set of statistics). 
But what if there are several such estimators? We know that none of the estimators can be 
improved by further conditioning, but this does not guarantee that their risks are all minimal.
This observation makes it necessary to single out the cases where such an “anomaly” 
cannot occur, that is, situations where an unbiased estimator based on a sufficient statistic is 
unique.
Accordingly, we introduce the following definition:
Definition 11.6.5 A family of distributions {f (t; в), 6 e 0} of variable T is called complete 
if for all 6 e 0 the condition Eg [u(T)] = 0 implies that u(T) = 0 with probability 1. A suf­
ficient statistic with a distribution in a complete family is said to be a complete sufficient 
statistic. 
□
We have the following theorem:
Theorem 11.6.4 If the family of distributions {f (t; 6),6e 0} is complete, then any unbiased 
estimator u(T) of parameter g(6) is unique.
Proof: Ifu1(T) and u2 (T) are unbiased estimators of g(6), then
Eg [ u 1( T )] = Eg [ u 2 (T )]= g (6),
and Ee{u 1(T) - u2(T)} = 0 for all 6 e 0. Hence Pg{u 1(T) - u2(T) = 0} = 1 for all 6, 
which means that the functions u 1 and u2 coincide. 
□
Theorem 11.6.5 Lehmann and Scheffe Let X 1, ..., Xn be a random sample from a distribu­
tion {f (x; 6),6 e 0}, and let {T1, ...,Tk} be jointly complete sufficient statistics for 6.If 
the statistic U * = U * (T1, ... ,Tk) is an unbiased estimator of g (6), then U * is the minimum 
variance unbiased estimator (MVUE) of g(6).
Proof: By completeness, any statistic U = U (T1, ...,Tk) that is unbiased for g(6) must 
satisfy the condition U = U* with probability 1 (for every 6). On the other hand, for any 
statistic W = W (X1, ...,Xn) that is unbiased for g(6) and is not a function of T1, ...,Tk, 
U = E{W |T1, ...,Tk} will also be unbiased and will be a function of T1, ...,Tk such that 
Varg (U) < Varg (W), which shows that variance of U* is minimal for each 6. 
□
The concept of completeness pertains to a family of distributions. It is usually stated in 
a phrase appealing to intuition and easy to remember: A family is complete if “there are 

356
ESTIMATION
no nontrivial unbiased estimators of zero” (a trivial unbiased estimator of zero is a random 
variable identically equal to zero). We will now give some examples of complete families.
■ EXAMPLE 11.49
Consider random sampling from a POI(A) distribution. A sufficient statistic for A, 
T = П‘=1 Xi, has POI(nA) distribution. Let u (T) be a statistic, and suppose that 
Ee [u (T)] =0 for all в. This means that
Ee[ u (T)] = 
u (n)\e-9 = ' 
u (n) \ = 0 •
n! 
n!
n=0 
n=0
Since ee = 0, we obtain g(в) = u(n)вп/n! = 0 for all в. However, since the Taylor 
expansion of g(в) is ^[g(") (0)/n!]вп, we have u(n) = g(n) (0). But the latter quantity 
is zero for all n.
Observe here that we used the fact that the family contains all Poisson distributions 
as indexed by в (or at least sufficiently many of them). Ifwe consider the family of some 
selected Poisson distributions, say for в 1, в 2, • • • ,вг, we can choose some negative and 
some positive values of u(t) so as to obtain appropriate cancelations. The simplest 
example here is to take a family consisting of just one Poisson distribution, with mean 
в = 5 (say). Then, the function u(T)=T - 5 is not identically zero, yet its expectation 
is zero for all members of the family (since there is only one distribution in the family, 
and the expectation of this distribution is 5).
■ EXAMPLE 11.50
In a U[0, в] distribution, the sufficient statistic for в is T1 = Xn:n, and its density f (t, в) 
is
ntn-1 /вп 
0 < t < в
f(t; в) = 
0 otherwise •
Suppose that we have a function u that satisfies the condition
Ee [u(T)]= [ e u(t)ntn 1 dt = 0• 
0в
This means that
e 
tn-1u(t) dt =0, 
0
and by differentiation with respect to в, we get вп-1 u(в) = 0 for all в > 0. Conse­
quently, we must have u (t) = 0, and therefore, the class of all distributions uniform on 
[0, в], в>0, is complete.
This explains why in Example 11.48, by conditioning the unbiased estimators T3, T4, 
and T5 on sufficient statistic T1 , we obtain the (unique, in view of completeness) unbi­
ased estimator [(n + 1)/n]T1 of в.
Proving completeness ofa family starting directly from the definition may not be easy. We 
will therefore present a rather general and easily verifiable sufficient condition for complete­
ness:

SUFFICIENCY
357
Definition 11.6.6 The distribution f (x, в) is in an exponential class, if
c( c( c c(в)b(x)expE = qi(в)ki(x)] 
f(x; в)=
if x e A 
otherwise,
(11.83)
where в = (в 1, ..., вт) and c(в), b(x) are strictly positive functions. It is assumed here that 
the parameter space is a generalized rectangle (possibly infinite in some dimensions) of the 
form 0 = {в : ai < Oi < bi,i = 1, ..., m}.
Moreover,
1. The set A where f(x; в) is positive does not depend on в.
2. The functions q 1(в), ..., qm (в) are continuous and functionally independent (i.e., none 
is a function of others).
3. The functions k1(x), ...,km (x) are linearly independent (i.e., no linear combination of 
them is identically zero unless all coefficients are zero), and when f(x; в) is a density ofa 
continuous random variable, they are differentiable.
□
We have the following theorem:
Theorem 11.6.6 Let X 1, ..., Xn be a random sample from a distribution {f (x, в), в e 0 } that
belongs to the exponential class (11.83). Then the set of statistics {T1, ...,Tm } such that
n
Tj(X1,...,Xn)= 
kj(Xi), forj=1,...,m
i=1
is a minimal set of complete sufficient statistics for в = (в 1, ... ,вт).
The joint sufficiency of statistics T1, ...,Tm follows immediately from (11.83). For the proof 
of completeness, see Lehmann and Romano (2005).
Distributions from most common families (e.g., binomial, Poisson, normal, or gamma) 
belong to the exponential class. We will show it for the binomial and normal distributions, 
leaving the proofs for the remaining families as exercises.
■ EXAMPLE 11.51
For the Bernoulli distribution, we have for x =0, 1
x
f (x; p) = px (1 - p )1-x = (1 - p)( —— )
1-p
= (1 — p) exp |x log —p—| .
Thus, A = {0, 1}, m = 1,q1(p) = log[p/(1 - p)], and k1(x) = x. The sufficient statistic 
is T = E k 1( xi ) = E Xi.
For a normal distribution we have, after letting в = (p, a),
■ EXAMPLE 11.52
1 
f (x - p)2 ]
f (x, в) = 
/о- exH 
9 2
2 n 
2 a 2 J
1 
(x2 - 2px + p2)
r = —7= exp s---------- tt^t----
1 aV2n I 
2 a2
1 
Г -P2 1
= o^Tn exp 2a4 eXP<
1 - 202x 2 + 0P2x },

358
ESTIMATION
so we have c(9) = (1 /a^2n)e M2/2a2,b(x) = 1, 
q 1(9) = — 1 /2a2, 
q2(9) =
p/a2,k 1(x)= x2,k2(x)= x. A minimal sufficient set of statistics is therefore 
T1 = EП=1 Xi and T2 = EП=1 хг.
There exist families of distributions in which the dimension of parameter 9 is less than 
the number of jointly sufficient statistics. Such families are called curved exponential. Most 
properties of their properties are the same as the properties of so-called full exponential 
families.
■ EXAMPLE 11.53
Let us consider a N(9, 92) distribution. Parameter 9 is now one-dimensional and the 
density is
f (x; 9) = 
1 e-(x—®)2/(222) = 
1 e-x2/(2!>2)+x/®-1 /2
Statistics T1 = Xi and T2 = 
Xi are jointly minimal sufficient for (p,a2) =
(9,92). Parameters space 0 is a parabola.
■ EXAMPLE 11.54
In this example, the family of distributions is GAM(a, 1 /a) with density
a-a 
a~a
f (x; a) = ^?x" 1 e-x/" = |^'(" 1)log x-x/a
Parameter 9 is also one-dimensional, and statistics T1 = 
log Xi2 and T2 = 
Xi are
jointly minimal sufficient for (a, X) = (a, 1 /a). Parameters space 0 is a hyperbola.
We end this section with one more concept whose notion is complementary to the notion 
of a sufficient statistic.
Definition 11.6.7 Let X1, ...,Xn be a random sample from a distribution f(x, 9).
Statistic T = T(X1, ...,Xn) is ancillary for parameter 9, if its distribution does not 
depend on 9. 
□
■ EXAMPLE 11.55
In a randomsample of size n obtained from the N(9,1) distribution, statistic T = 
"=1 (Xi — X )2 has a chi-square distribution with n — 1 degrees of freedom, so it 
is ancillary for 9.
The following theorem, due to Basu, establishes the independence of complete sufficient 
and ancillary statistics:
Theorem 11.6.7 Basu Let X1, ...,Xn be a random sample from the distribution 
{f (x, 9) ,9 & 0}. If {T1, ...,Tm} are jointly complete sufficient statistics for 9, then
{T1, ...,Tm} and any ancillary statistic V = V (X1, ...,Xn) are independent.
PROBLEMS
11.6.1 Find sufficient statistics (or show that they do not exist) for parameter 9 in the fol­
lowing distributions: (i) f (x, 9) = (x/92)e-x2/2e2 for x > 0 (Rayleigh). (ii) f (x,9) = 
(1 /29)e-xe (double exponential). (iii) BETA(9, 29). (iv) U[9, 29]. (v) GAM(9,9). 
(vi) f (x, 9) = {n[1 + (x — 9)2]}-1 (Cauchy).

INTERVAL ESTIMATION
359
11.6.2 Generalizing Example 11.39, let X1 , ...,Xn be n independent Bernoulli trials.
Show that T = "=1 Xi is sufficient for probability of success p by finding the 
joint distribution of (X1, ...,Xn ) given T = t. Find the marginal distribution 
P{X1 =1|T=t}.
11.6.3 Find a sufficient statistic for 6 if observations are uniformly distributed on the set 
of integers 0, 1, ..., 6.
11.6.4 Show that the N(0, 6) family is not complete.
11.6.5 Let X1, ...,Xn be a random sample from the distribution with a density 
f (x; X, 6) = Xe-x(x-e) for x > 6 and 0 otherwise. Determine a pair of jointly 
sufficient statistics for parameters X and 6.
11.6.6 Check if the following families of distributions are in the exponential class: (i) 
POI(X). (ii) EXP(X). (iii) NBIN(r, 6), r known. (iv) BETA(61,62). (v) WEI(k, 6), k 
known. (vi) WEI(6, /), / known.
11.6.7 Show that the family of GAM(a, X) distributions is in the exponential class, and 
find the minimal jointly sufficient statistics.
11.6.8 Suppose that a random sample is taken from a distribution with density f(x; 6)= 
2x/62 for 0 < x < 6 and f (x; 6) = 0 otherwise. Find the MLE of the median of this 
distribution, and show that this estimator is a minimal sufficient statistic.
11.6.9 Let X1 , ...,Xn be a random sample from the EXP(X) distribution. Suppose that 
only first k order statistics X1:n , ...,Xk:n are observed. Find a minimal sufficient 
statistic for X.
11.6.10 Let X1 ,X2 be a random sample of size 2 from the POI(X) distribution. Show that 
statistic T = X1 +2X2 is not sufficient for X.
11.6.11 Let X1, ...,Xn be a random sample from the U(6, 6 +1) distribution. Show that 
statistic T = Xn:n - X1:n is ancillary for 6.
11.6.12 Let X1 ,X2 be a random sample of size n =2from the EXP(X) distribution. Show 
that statistic T = X1 /X2 is ancillary for X.
11.6.13 Let X1, ...,Xn be a random sample from the U(0, 6) distribution. Show that statis­
tic T = Xn:n /X1:n is ancillary for 6.
11.7 INTERVAL ESTIMATION
Thus far, we have dealt with point estimation. An estimator was used to produce a single 
number, hopefully close to an unknown parameter. The natural question arises: What can 
be said about the distance between the value produced by the estimator and the true value 
of the parameter?
Confidence Intervals
If the value of 6 is fixed then all randomness is in the process of sampling and one cannot 
speak of “the probability that the value of parameter 6 belongs to some set.” The relevant 
statements on interval estimation are expressed through the concept of confidence intervals 
(CI).
Let X = (X1, ...,Xn ) be a random sample from the distribution f(x, 6). Let a be a fixed 
number with 0 <a<1 (typically a is a small number such as a = 0.05 or a = 0.01).

360
ESTIMATION
Definition 11.7.1 A pair of statistics L = L(X) and U = U(X) is an (1 - a)-level confidence 
interval (CI) for в if for all в e 0,
Pe{L(X) < в < U(X)} = 1 - a. 
(11.84)
Similarly, a statistic L(X) is a (1 - a)-level lower confidence bound if
P {L(X) < в} =1- a. 
(11.85)
□
The upper confidence bound U(X) is defined in a similar way.
The interval [L(X), U (X)] varies from sample to sample and is therefore random. By defi­
nition, the probability that it covers the unknown (fixed) value of в is 1 - a. This probability, 
however, refers to the process of taking the sample only. After a specific sample x has been 
observed, the observed interval [L(x), U(x)] either covers or does not cover в. All random­
ness is gone, and it makes no sense to speak of “the probability that в belongs to the interval 
[L(x), U(x)]” because this probability is now either 0 or 1. Since we do not know which is 
the case, the term confidence is used. We say that the (1 - a)-level confidence interval for 
в is [L(x), U (x)]. In frequential terms, the last statements means “the confidence interval 
L[(x), U(x)] has been obtained by a method that produces randomly generated intervals, of 
which, on average, 100(1 - a)% cover the unknown value в.”
It is perhaps regrettable that the terminology here, as it developed historically, is a lit­
tle ambiguous. The term confidence interval refers to interval L[(X), U(X)] with random 
endpoints as well as to the interval L[(x), U(x)] with endpoints obtained from the sample 
observed. Sometimes, the first interval is called the probabilityinterval, and the second is 
called the sample confidence interval. We will follow a more common tradition, referring to 
confidence intervals and sample confidence intervals.
In constructing confidence intervals, we use quantiles of some known distributions, such 
as standard normal, Student’s t, and chi-square. For typographical reasons, as well as to 
follow the tradition, we use different notation for distributions symmetric about 0 (N(0, 1) 
and Student’s t).
Thus, if Z is a standard normal random variable, then za will denote the (1 — a)-quantile 
of Z (or, upper a-quantile), that is,
P{Z < za} = 1 - a. 
(11.86)
Then, z 1 -a = -za, and P{\Z| < za/2} = 1 - a. Similarly, the (1 - a)-quantile of Student’s 
t distribution with v degrees of freedom will be denoted by t av.
For asymmetric distributions, such as chi-square, the subscript a will be used for upper 
quantiles of order a so that x2a v denotes the quantile of order 1 - a of a chi-square distri­
bution with v degrees of freedom.
■ EXAMPLE 11.56
Consider the random sample X 1, ... ,Xn from the distribution N( в, a 2), where в is the 
unknown parameter while a2 is known. Then, the interval
X -
a 
a \
za/2 ,X ,X + za/ 2 7= I 
' Пп)
is a (1 - a)-level confidence interval for в. Indeed, the inequality
X - za/2 - < в < X + za/2 —j=
dn 
' Пп
is equivalent to
в - za/2^= < X < в + za/2~/=, 
dn 
' Jn

INTERVAL ESTIMATION
361
so both inequalities have the same probabilities. Since Var(X) = a2/n, we have
P {X -Za/2 
<6<X + Za/2 
}
= Pl — zn/2 < Х-вг~ < zn/2 1 = 1 - a, 
a/2 
a/\/n 
a/2
which was to be shown.
■ EXAMPLE 11.57
Let X1 , ...,Xn be a random sample from a continuous distribution with density 
f (x, 6) depending on a one-dimensional parameter 6. Furthermore, let F(x, 6) be the 
cdf of X, and let G = 1 — F. Then, each of the random variables — 2 log F (X, 6) and 
-2 log G(X, 6) has an exponential distribution with parameter 1/2. Indeed
P{—2logF(X,6) >t} = P{F(X, 6) < e-t/2} = e-t/2,
since F(X, 6) is uniform on [0, 1]. The argument for G(X, 6) is analogous. Conse­
quently, the sums
U = — 2 
log F(Xi, 6) and W = —2 
log G(Xi,6) 
(11.87)
i=1 
i=1
have GAM(n, 1/2) distribution, which is the same as chi-square distribution with 2n 
degrees of freedom. Therefore,{
n
X22-a/2,2n < — 2l>gF(Xi,6) < XI/2,24 = 1 — a 
(11.88)
i=1
and
n
P X12-a/2,2n < —2 
log G(Xi,6) < X2a/2,2n =1—a. 
(11.89)
i=1
If the inequality that defines the event in either (11.88) or ((11.89)) can be solved to 
the form L(X1, ...,Xn) <6<U(X1, ...,Xn), we obtain, by definition, a confidence 
interval for 6 at level 1 — a.
■ EXAMPLE 11.58
Continuing Example 11.57, ifX1, ...,Xn have an exponential distribution with den­
sity 6e- rjx, then F(x, 6) = 1 — <■. ',J and G(x, 6) = <■. ',J. Formula (11.89) gives
{
n
X21-a/2,2n <26 
Xi < X2a/2,2n =1—a,
i=1
and we obtain the (1 — a)-level confidence interval
X1-a/2,2n 
Xa/2,2n
------=— <6 < —-^^.
2nX 
2 nX
(11.90)
Note that ifwe used F instead of G, we would obtain the inequality
n
X2-a/2,2n < — 2 
log(1 — e-Xi) < X0/J2,2n,
i=1 

362
ESTIMATION
which cannot easily be solved for в. Thus, even when we have an explicit formula for 
F (and hence for G), use of one of these functions often leads to simpler results than 
use of the other.
In general, how are confidence intervals obtained? For large n, the answer lies in the 
limit Theorem 11.5.1 about the asymptotic distributions of MLE’s obtained from setting 
the derivative of the likelihood equal to 0 and solving the resulting equation. Indeed, since 
Пп1 (в)(On — в) with I(в) defined by (11.27) is asymptotically standard normal (as in 
Example 11.56), we have
— za/2 < VnI(в)(®n - в) < za//2
with probability close to 1 — a. This inequality is equivalent to the inequality
z 
za/2 
в в в в , 
za/2
n r, -  -- ! 
< в < в n +-------. 
.
n 
nI(!W 
n 
J^W
(11.91)
The latter is not a confidence interval, since the bounds depend on the unknown value of в. 
However, for large n, we can replace в by вn in I(в). Consequently, we can state the following 
theorem:
Theorem 11.7.1 Let 0n be the MLE estimator of i in a problem for which MLE’s satisfy 
assumption of Theorem 11.5.1. Then for large n,
в n
za/2 
в + 
za/2
ynM) ’ n 
Ппв(en)
is an approximate (1 — a)-level confidence interval for parameter 0.
■ EXAMPLE 11.59
As an illustration, we consider the problem of estimating probability p in Bernoulli
distribution. The observations X1, X2 , ...,Xn are iid random variables indicat­
ing whether consecutive trials lead to success or failure (i.e., Xi =1 or 0 with
probabilities p and 1 — p). The sum Sn = X 1 + • • • + Xn is the total number of 
successes in n trials. The MLE of p is p = Sn/n, and (11.35) gives I(p) = 1 /p(1 — p)
so that
Var( p) = ± Var( Sn) = 
p
n2 
n n
1 
nI (p)
By the central limit theorem for the binomial distribution, the random variable
Sn — np . = VnI (p)(p — p) 
np(1 — p)
is asymptotically standard normal. Consequently, we have the approximate relation
P { — za/2 < VnI(p)(p — p) < za/2} = 1 — a 
(11.92)
The inequality on the left-hand side of (11.92) is equivalent to
Ip — pl < -a/2- Vp(1 — p) 
n

INTERVAL ESTIMATION
363
or
22
1 + ^/2] p2 - | 2p + -/£■ ) p + p2 < 0. 
nn
(11.93)
The solution of the quadratic inequality (11.93),
v+z2 /2n-z , \4pp(1 -p}+za/2/
p + za/2 / 2 n 
za/2 V 4 n
1+za / 2 in
<p< p + zl/2 /2n + za/2
44 p(1 -'p)+za / 2/n
4n 
4n
1+za / 2 /n
(11.94)
gives an approximate (1 - a)-level confidence interval for probability p.
If we disregard the terms of the order higher than 11 ^n, we obtain a more com­
monly used further approximation, namely
A 
/p(1 — p) 
, 
/p(1 — p)
p — za/2y  n  <p<p+ za/2y n 
(11.95)
which coincides with the confidence interval given in Theorem 11.7.1
The method of obtaining confidence intervals for any n is based on the pivotal variables 
defined as follows.
Definition 11.7.2 A random variable W is called pivotal for в if it depends only on the sample 
X and on unknown parameter в, while its distribution does not depend on any unknown 
parameters (including в). 
□
This means that in principle one should be able to calculate the numerical values of prob­
abilities for W. It is not enough to know that W has, for example, a normal distribution with 
one or more parameters unspecified.
If W = W(X, в) is a pivotal random variable, then the (1 - a)-level confidence interval 
can be obtained as follows: First, for given a, one determines the values q^ and qO* such that
P{q*a < W(X,в) < q?} = 1 - a, 
(11.96)
which is possible since W is pivotal.
It now remains to convert the inequality q*a < W (X, в) < q** into the form
L (X ,ql ,qa) < в < U (X ,q*a ,qa) 
(11.97)
or, more generally, into the form
в e S(X(n),q*,qa), 
(11.98)
where S is some set (not necessarily an interval). But as is often the case, if the pivotal quan­
tity W is monotone in в for every value of X, a solution of the form (11.97) is attainable, 
and then the statistics L and U provide the lower and upper endpoints of the (1 - a)-level 
confidence interval for в.
■ EXAMPLE 11.60
The random variables (11.87) from Example 11.57 are pivotal, which shows that in 
a continuous case with a one-dimensional parameter there always exist at least two 
pivotal variables.

364
ESTIMATION
The next example shows that pivotal variables can also exist in the case of multidimen­
sional parameters.
■ EXAMPLE 11.61
As in Example 11.56, assume that X1, ...,Xn is a random sample from the distribu­
tion N(в, a2), but a2 is now unknown. We are still interested in estimating the mean 6. 
In such cases, the statisticians use the term nuisance parameter for a2.
In Example 11.56, the random variable (X - 6)/(a/T—) was pivotal, since a was 
known. However, if a is unknown, we have to proceed differently. The idea is to cancel 
a in the denominator of (X — 6)/(a/T—).
Recall that when Xi ~ N(в, a2) and S2 = (1 /—) "=1 (Xi — X)2, the random vari­
able nS2 /a2 has a chi-square distribution with n — 1 degrees of freedom (Theorem 
9.2.1). Moreover, S2 is independent of X. Consequently, the ratio
(X — 6) / (a/j—) 
X — 6 .--------
—= 
= —— —— — 1
д/—S 2 /a 2( n — 1) S
= 
——1 
(11.99)
V(1 /n) £ (Xi X X)2
has the Student’s t distribution with n - 1 degrees of freedom. Thus, (11.99) is a pivotal 
random variable (observe that a is canceled). If now ta/2,n- 1 is the (1 — a/2)-quantile 
of Student’s t distribution with n - 1 degrees of freedom, then we have
P t-0-а/2 ,n-1 < -----S-----n— 1 1 < ta/2 ,n-1 | = 1 — a,
which gives
S
/ 2 ,n-1 t——r 1
S
T— -1J
X + ta/ 2 ,n-1
(11.100)
as a (1 - a)-level confidence interval for 6.
■ EXAMPLE 11.62 Confidence Intervals for Variance
Consider again a random sample with normal distribution N(m, a2), this time 
assuming that the parameter to be estimated is a2 . We distinguish two cases: when 
M is known, and when /л is unknown. To provide some motivation for considering 
these cases, consider the problem of assessing the quality of some measuring device. 
A typical procedure here consists of repeating the measurements of the same object. 
Assuming that the measurement errors are normal, the two cases above correspond to 
measurements of an object whose true value /л of the measured attribute is otherwise 
known, and measurements of an object whose true value /л of the measured attribute is 
unknown.
The pivotal random variables are respectively,
nn
U = 
(Xi - M)2/a2 and V = 
(Xi — X)2/a2.
i=1 
i=1

INTERVAL ESTIMATION
365
Since U is a sum of n independent squares of standard normal random variables, it 
has a chi-square distribution with n degrees of freedom. We know also from Theorem 
9.2.1 that V has a chi-square distribution with n - 1 degrees of freedom. Thus,
pi 2 
<Z П=1 (Xi - M )2 . 2 
1=1 - a
P Х1 — a/2 ,n < 
&2 
< Xa/2,n 1 a
and 
_
P f 2 
'i ==( (Xi - X )* 
2 
1,
■PS X1 — a/2,n — 1 < ------------^2--------------- < Xa/2,n— 1 J =1 - a
We obtain therefore the (1 - a)-level confidence intervals
En=1(xi - m)2 <a2 < EП=1 (Xi - m)2
X a 2 ,n 
X1 — a/ 2 ,n
and 
EП=1(Xi - X)2 <a2 < EП=1 (Xi - x)2.
Xc/ 2 ,n — 1 
X1 — a/ 2 ,n— 1
(11.101)
(11.102)
Two obvious questions arise that concern the intervals (11.101) and (11.102). First, 
when M is unknown, one must use the interval (11.102). But when M is known, one 
can either utilize this knowledge and use interval (11.101) or not utilize it and use 
interval (11.102). Which is the proper procedure? The answer is that a shorter interval 
is obtained, on average, if one uses the available information about the expectation M.
Second, to get the probability 1 - a of covering the unknown value of a2, it is not 
necessary to choose values x2—a/2 n and X2a/2 n, which cut equal probabilities at both 
tails of the chi-square distribution. One could choose two other points a and b such 
that the probability of a chi-square random variable assuming a value between a and 
b is 1 - a. There are infinitely many such pairs (a, b), the pair (x12—a/2,n, x2a/2,n) being 
just one of them. An obvious criterion would be to choose a pair a, b that minimizes 
the length of the confidence interval. It is easy to see that this length is proportional to 
1/a - 1/b. We have a similar discussion when M is unknown.
To solve this optimization problem, let gm be the density of the chi-square distribu­
tion with m degrees of freedom (in our case, we use either m = n or m = n - 1). Then, 
the problem can be formulated as
1
1 
b
minimize
subject to g gm(x) dx > 1 - a.
a
This problem can be solved by using Lagrange multipliers: Differentiating the function
1
a
b+л
gm (x) dx - (1 - a)
a
with respect to a, b, and X, we obtain three equations:
- a2 - Xgm(a) = 0,
b2 + Xgm ( b) 0,
(11.103)
and
b
gm (x) dx =1- a.
a
(11.104)

366
ESTIMATION
As a solution choose a, b satisfying constraint (11.104) and such that a2gm(a) = 
b2gm(b). These can be solved numerically for each m. The solution, for large m,is 
close to the “symmetric” solution, where a = x2-2/2 m,b = X2/2 m• For small sample 
sizes, it is better to use an exact solution of the optimization problem above, as it gives 
the shortest possible confidence interval.
Table B1 gives the optimal left cutoff probability a 1, and the corresponding upper 
quantiles a = xa 1 m and b = X222 m, where a2 = (1 - a) - a 1, for a = 0.1 and a = 
0.05 and various numbers of degrees of freedom. The table also gives the relative gain 
resulting from using the shortest confidence intervals (with length proportional to 
1/a - 1/b), as compared to the confidence interval with equal cutoff probabilities, 
hence with length proportional to 1/x12-a/2,m - 1/x2a/2,m.
■ EXAMPLE 11.63
Suppose that five observations from a normal distribution with unknown p and a2 are 
such that (Xi — X )2 = c. To obtain a 95%CI for a2, the usual procedure based on 
cutting off 2.5% at both ends of the chi-square distribution with 4 degrees of freedom 
uses thresholds x02.975,4 = 0.484 and x02.025,4 = 11.143. This leads to the confidence 
interval c/11.143 <a2 < c/0.484, or (0.090c, 2.066c), of length 1.976c.
The shortest 95% confidence interval involves the upper quantiles a = x12-0.0497,4 = 
0.708 and b = x21-0.0497-0.95,4 = 21.047. The confidence interval is now 0.0475c = 
c/21.047 <a2 < c/0.708 = 1.412c. The length is 1.3649c, which is 69% of the length 
of the interval based on quantiles corresponding to 2.5% probability on each end.
Two natural questions arise: Do pivotal random variables always exist, and if not, can 
one construct confidence intervals in some other way? Regarding the first question, the 
criteria for existence of pivotal random variables were given by Antle and Bain (1969). 
In analogy with examples concerning the normal distribution, we have the following 
theorem:
Theorem 11.7.2
(a) If 0 is a location parameter and 0 is MLE of 0, then 0 — 0 is pivotal.
(b) If 0 is a scale parameter, and 0 is MLE of 0, then 0/0 is pivotal.
(c) Let 11 be a location parameter and о2 be a scale parameter so that f(x,0 1,02) = 
(1 /02)h[(x — 0 1)/02] for some density h. If 01 and 02 are MLE’s of 0 1 and 02,
respectively, then (01 — 0 1)/02 is pivotal.
The answer to the second question is that even if pivotal random variables do not exist, 
we can construct confidence intervals. We will give here examples of confidence intervals for 
quantiles.
■ EXAMPLE 11.64
Let X 1, .. .,Xn be a random sample from a distribution with cdf F (t), and let X 1: n < 
X2:n < • • • < Xn:n be the order statistics of the sample. To simplify, assume that F 
is continuous and strictly increasing, and let £ 1 /2 be the median of the distribution 
F. Thus, £ 1 /2 is the unique solution of the equation F(t) = 1 /2. We will construct 
confidence intervals for £1/2. More precisely, we will consider (random) intervals of the 
form [Xa:n, Xb:n] for integers a, b satisfying the condition 1 < a<b< n and assess, for 
each of such intervals, the probability that it covers the parameter £1/2.

INTERVAL ESTIMATION
367
The event Xa:n < £ 1 / 2 occurs if and only if at least a elements in the sample are 
below the median. Similarly, the event 1 1 /2 < Xb:n occurs if and only if at least n - 
b elements in the sample are above the median. If we call an observation below the 
median a success and let S denote the number of successes in the sample, then the 
event Xn,a < £1/2 < Xn,b occurs if and only ifwe have at least a successes and at least 
n - b failures so that a < S < b. Since S has distribution BIN(n, 1/2), we obtain
1
Pix.n < £1 /2 < X;.) = £ (”) 2n. 
k=a
For instance, if n =10, then the interval [X3 10, X7 10] between the third and seventh 
order statistic is a confidence interval for the median with the confidence level
7
E
k=3
10 
k
210 
1 
2
x 2L =o.891.
On the other hand, the interval [X2 :10 ,X6 :10 ] is a confidence interval for £ 1 / 2 with 
confidence level ^k==2 (10) (1/2)10 = 0.709.
One-sided confidence bounds for £ 1 /2 are obtained in the same way: for instance, the 
order statistic Ya:. is a lower bound for £ 1 /2 with the confidence level .=a (.) (1 /2)n.
■ EXAMPLE 11.65
Continuing Example 11.64, let us now fix p and let pp be the pth quantile of the pop­
ulation distribution. Again letting S be the number of successes, where now “success” 
is an observation below pp, S has a BIN(n,p) distribution. The interval [Xa:., Xb:.] is 
a confidence interval for p with the confidence level
b
nk pk (1 - p)n-k .
Again, taking n =10, the same interval [X3:10, X7:10] can serve as a confidence interval 
for the first quartile £ 1 /4, except that now the confidence level will be
3\
4 J
10-k
= 0.526.
However, in this case, it is better to take confidence intervals based on the order statis­
tics where the indices are not equidistant from the extremes.
We complete this chapter with the critique of the concept of confidence intervals. The 
point is that while a pair of statistics L = L(X), U = U(X) may satisfy the condition
P{U <в < L) = 1 - a,
there are cases where the sample X may provide additional information, allowing one to 
claim higher probability of coverage than 1 - a. This is illustrated by the following example 
from De Groot (1986).
■ EXAMPLE 11.66
Suppose that two independent observations X1, X2 are taken from the distribution 
uniform on [в — 1 /2, в + 1 /2]. Then order statistics X 1:2 and X2:2 provide a 50% con­
fidence interval for в. Indeed, the interval [X 1:2,X2:2] covers в if and only if one of 

368
ESTIMATION
the observations is below в and the other is above в, an event with probability 1 /2. 
However, if X2:2 - X 1:2 > 1 /2, then the interval [X 1:2,X2:2] covers в with probability 
1. Still, strict adherence to the definition of confidence interval requires reporting such 
an interval as a 50% confidence interval rather than as a 100% confidence interval.
This example (as well as other examples of this type, e.g., Example 16.18) gives 
some weight to the Bayesian approach to statistical inference which will be discussed 
in Chapter 16.
Bootstrap Intervals
The bootstrap approach is a robust alternative to inference that is based on assumptions 
that may be either not valid or impossible to verify. For example, when sample sizes are too 
small, intervals based on asymptotic approximations can be inaccurate or calculations of 
standard errors can be very complex in some models. Bootstrap intervals can be obtained for 
the mean, median, proportion, correlation coefficient, regression coefficient, cdf—practically 
any population parameter. The quality of the procedure is not always the same, and therefore 
the effectiveness of the bootstrap approach has been extensively studied by carefully designed 
simulations for different parameters, types of population distributions, and sample sizes.
The idea underlying the bootstrap approach is that the sampling distribution of an esti­
mator в = в(X 1, ..., Xn) can be “imitated” by the sampling distribution of the analogous 
estimator в* = в(X(B), ..., XnB)) applied to so-called bootstrap samples.
This explains the name of the methodology which was introduced by Efron is his famous 
paper (Efron, 1979). Although “pulling yourself up by your bootstraps,” is in itself an impos­
sible task, it is an idiomatic expression used to describe situations when difficult problems 
are solved by one’s own efforts, without any external help. Although such methods were 
proposed earlier24 it was Efron who widened their applicability by utilizing modern com­
putational power and who popularized the methodology so that it became an indispensable 
tool of modern data analysis.
Let us assume that x = (x1,x2, ...,xn) is the original sample consisting ofn values ran­
domly selected from f (x, в) distribution, and let в = в(х), be a value of an estimator selected 
to estimate unknown parameter в.
The bootstrap random variable, X(B), is defined as
P {X(B) = xi} = П, 
i =1 ,...,n, 
(11.105)
and each bootstrap sample, xj*, j =1, ...,B, will be a random sample from the distribution 
(11.105) (in practice, this means that we are sampling the elements of the original sample 
with replacement). Next for each of the B bootstrap samples, we obtain the estimate
в* = в(х*), 
j = 1, ...,B.
It has to be mentioned that the number B of bootstrap samples needs to be rather large, 
usually at least a thousand.
We introduce two main kinds of bootstrap interval estimation.
Bootstrap t Conf idence I nterval This interval is especially recommended when the 
distribution of в* is close to normal, which can be verified by a Q-Q plot or any test for 
normality. The bootstrap standard error is estimated as
SEBOOT = \/(1 /B) ^(j - ввоот)2,
24References to earlier similar ideas can be found in Hall (1992).

INTERVAL ESTIMATION
369
B
where в BOOT = g 52 j=1 0*, and consequently, the (1 - a )100% bootstrap t confidence 
interval has the form
a0 ± ta/2,n- 1SEBOOT •
Bootstrap P ercentile Interval This interval does not require normality of bootstrap 
estimator 0*. Its endpoints are sample quantiles of order a/2 and 1 - a/2 obtained from 
z\ 
z\
0*, •••,0*.
One of the advantages of the bootstrap percentile interval is that it is invariant to mono­
tone transformations. If (0*-a/2, 0*a/2) is a (1 - a)100% interval for 0 then
(h (0 *-a/2) ,h (0a / 2))
is a (1 - a)100% interval for y = h(0) if h is monotone. No separate simulations need to 
be done.
The natural question now is: Is there any difference in these procedures, and if yes, then 
how to decide which one to use? We recommend that you obtain both, the bootstrap t confi­
dence interval and the bootstrap percentile interval, and compare them. If they are not close, 
then probably neither of them should be used. If the bootstrap estimate of bias, 0 - 0BOOT, 
is small, then a bootstrap percentile interval is recommended. Also, since almost all varia­
tion in the bootstrap sample is caused by the selection of the original sample (resampling 
adds very little variation), bootstrap intervals based on small samples can be unreliable. For 
statistics such as the median or quartiles, they should be used with caution even for moder­
ate samples. On the other hand, bootstrap t confidence intervals for the population mean 0, 
based on a trimmed mean as an estimator 0, can be a good choice.
In Example 11.67, we illustrate both types of bootstrap intervals.
■ EXAMPLE 11.67
We compare different confidence intervals for an unknown population mean 0 in the 
EXP(1/0) distribution. Initially, we assume a certain value of 0 and use it to generate 
a random sample of size n (we select n =20,and0 =1). A generated random sample 
will later be used to generate bootstrap samples. As an estimator 0 of a population 
mean 0 we take the sample mean 0 = X.
The generated random sample x 1, • • • ,x20 yields a sample mean 0 = 1 • 1167• 
Assuming that the information about the population distribution (exponential) is 
available, we apply formula (11.90) from Example 11.58 and obtain
x0.975,40 
1 
x0.025,40
2 x 20 x 1 • 1167 < 0 < 2 x 20 x 1 • 1167,
or equivalently 0 •7527 <0 < 1 • 828 • After generating B = 1,000 bootstrap samples, we 
obtain 0BOOT = 1 • 1083 and SEBOOT = 0• 2038. The distribution of the bootstrap esti­
mator в* does not indicate lack of normality. Consequently, we obtain 95% bootstrap t 
confidence interval as 1 • 1167 ± 2•093 x 0• 238, or (0• 6901, 1 • 5433), and the 95% boot­
strap percentile interval as (0.7478, 1.5551). All three intervals cover the true value 
0 =1, and their widths are 1.0753, 0.8532, and 0.8073, respectively. Bootstrap per­
centile interval seems to work very well here, but this should not be surprising, since, 
as mentioned, the bootstrap percentile interval should be recommended when the esti­
mated bias is small. Here 0 - 0BOOT = 1 • 1167 - 1 • 1083 = 0•0084—less than 1% of a 
true value of the parameter.
Several methods to make bootstrap intervals more accurate have been proposed in the 
literature. We will not discuss them here, but we refer readers interested in the topic to Efron 

370
ESTIMATION
and Tibshirani (1993) and Davison and Hinkley (1997). In Chapter 12, we will use bootstrap 
techniques for testing hypotheses.
PROBLEMS
11.7.1 Let X 1, ..., Xn be a random sample from the distribution with density f (x; 6) = 
6 (x + 1)-e-1 for x > 0,6 > 1. Find the exact 90% confidence interval for 6.
11.7.2 Let X1, ...,X16 and Y1, ...,Y12 be random samples from N(6, 15) and N(6, 20) 
distributions, respectively. Find the 95% CI for 6 if x = 20 and y = 18.
11.7.3 Let X1, ...,Xn be a random sample selected from the Pareto distribution with den­
sity f (x; 6) = 62ex-(e +1) for x > 2. Find: (i) The sufficient statistic for 6. (ii) An 
exact 95% CI for 6.
11.7.4 Based on a random sample 1.23, 0.36, 2.13, 0.91, 0.16, 0.12 selected from the 
GAM(2.5, 6) distribution, find an exact 95% CI for parameter 6.
11.7.5 Seven measurements of the concentration of some chemical in cans of tomato juice 
are 1.12, 1.18, 1.08, 1.13, 1.14, 1.10, 1.07. Assume that these numbers represent a 
random sample from the distribution N(6, a2). (i) Find the shortest 95% and 99% 
CI’s for 6, if a2 is unknown. (ii) Answer part (i) if a2 = 0.0004. (iii) Use the data to 
obtain a 90% CI for a2 and for a .
11.7.6 A large company wants to estimate the fraction p of its employees who participate 
in a certain health program. It has been decided that if p is below 25%, a special 
promotion campaign will be launched. In a random sample of 85 employees the 
number of those who participated in the program was 16. (i) Find a 95% CI for p 
using formulas (11.94) and (11.95). Should the campaign be launched? (ii) Answer 
the same question if the data are 340 and 64, respectively.
11.7.7 Let X 1, ...,Xn be a random sample from N(y, a2) distribution with both param­
eters unknown. Let La be the length of the shortest confidence interval for у on 
confidence level 1 - a. (i) Find E(L2a) as a function of n, a2 and a. (ii) Find the 
smallest n such that E(L2a) < a2 /2 for a given a.
11.7.8 Obtain a (1 - a)100% CI for 6 if X 1, ..., Xn is a random sample from a: (i) N(y, 6) 
distribution with у and 6 unknown. (ii) BETA(1, 6) distribution.
11.7.9 Find the probability that the length of a 95% confidence interval for the mean of 
normal distribution with unknown a is less than a, n =25.
11.7.10 Suppose that the largest observation recorded in a sample of size n =35 from a 
distribution uniform on [0, 6] is 5.17. Find a 90% CI for 6.
11.7.11 (i) Use the large sample distribution of MLE of mean A in Poisson distribution to 
construct an approximate (1 - a)-level CI for A. (ii) Assuming that the numbers of 
new cars of a given make sold per week in 15 consecutive weeks—5, 5, 6, 3, 5, 8, 1, 
4, 7, 7, 5, 4, 3, 0, 9—form a random sample from a POI(A) distribution, find a 90% 
CI for A.
11.7.12 Based on a random sample of size n selected from the WEI(4, 6) distribution, derive 
a 95% confidence interval for 6 based on X1:n.
11.7.13 Suppose that the lifetime T of a certain kind of device (e.g., a fuel pump in a car) 
has an EXP(A) distribution. The observed lifetimes of a sample of the devices are

INTERVAL ESTIMATION
371
350,727, 615,155, 962 (in days). Find a 95% CI’s for: (i) A. (ii) E(T). (iii) The stan­
dard deviation of the lifetime of the device. (iv) The probability that the two copies 
of the device that you bought will each last more than two years.
11.7.14 Based on a random sample X 1, ...,Xn from the U[0, в ] distribution find: (i) 
P{Xn•n < в < 2Xn.n}. (ii) Such k that the interval (Xn.n, kXn.n) is a (1 - a)100% 
CI for в.
11.7.15 Let X1, ...,Xn be a random sample from some continuous distribution. If the con­
fidence interval for the median M is (X1.n, Xn.n) find the smallest n such that the 
confidence level 1 - a is at least 0.95.
11.7.16 Let X1 , . ..,Xn be a random sample from EXP(A) distribution. (i) Find an exact 
100(1-a)% confidence interval for в = 1/A. (ii) Assuming that you have m such 
intervals, each based on a random sample of the same size n, find the probability 
that at least k of them (k<m) contain в.
11.7.17 Suppose that the arrivals at a checkout counter in a supermarket (i.e., times of arriv­
ing at the counter or joining the queue, whichever is earlier) form a Poisson process 
with arrival rate A. Counting from noon, the thirteenth customer arrived at 12:18 
p.m. Find a 90% CI for: (i) A. (ii) The variance of interarrival times between consec­
utive customers.
11.7.18 A sample of 200 trees in a forest has been inspected for a presence of some bugs, out 
of which 37 trees were found to be infested. (i) Assuming a binomial model, give a 
90% confidence interval for the probability p of a tree being infested. Use the exact 
and the approximate formulas. (ii) Usually, if a tree is infested, one might expect 
some of the neighboring trees to be infested too. Thus, whether the binomial model 
is adequate depends on the way the sample was selected. Describe a way of selecting 
200 trees so that the binomial model is realistic.
11.7.19 (i) Given a random sample X 1, ...,Xn obtain a 90% CI for the mean ^ and then 
obtain a 90% bootstrap t interval and a 90% percentile interval for the same param­
eter ^. In addition, obtain two bootstrap intervals (t and percentile) for ^ using 
a 10% trimmed mean as a statistic. As your sample use a data set of size n =20 
generated from the N(1, 1) distribution. Use 2,000 bootstrap samples. Compare all 
intervals. (ii) Follow the same steps as in (i) with the only difference that the data 
will now be generated from the EXP(2) distribution. (iii) Compare results obtained 
in (i) and (ii).
11.7.20 Use the data in Problem 12.10.5 to obtain 90% bootstrap intervals (t and percentile) 
for the mean width-to-tength ratio of Shoshoni handicraft. Use 2,000 bootstrap 
samples. As statistic use X and the 10% trimmed mean. Compare your results.

CHAPTER 12
TESTING STATISTICAL HYPOTHESES
12.1 INTRODUCTION
In this chapter, we present the basic concepts and results of the theory of testing statistical 
hypotheses.
Assume that a random sample X 1, X 2, ...,Xn was selected from distribution f (x, в), 
where в is an element of a parameter space 0. Unlike in the estimation problems, we are now 
not interested in approximating the true value of в . What we need to know is only whether 
в belongs to some specific subset 00 C 0. A procedure that allows us to decide whether or 
not в is in 00 C 0 is called a test of the hypothesis that в 0 00.
The problem is trivial in the case where the sets of possible values of X are disjoint for 
в e 00 and в / 00 (в e 01). However, in the more realistic cases, some (or even all) values 
of X can occur for both в e 00 and for в / 00, and there is no procedure that will always 
allow us to reach the correct decision. Indeed, it may happen that while в is in 00, we will 
observe a value of X that will lead us to the conclusion that в / 00. On the other hand, it 
may happen that в is not in 00, and we will reach the conclusion that в 00 . These two 
possibilities are called errors of type I and type II, and the objective is to choose the decision 
rule that will minimize their probabilities.
■ EXAMPLE 12.1
A consumer protection agency decides to investigate complaints that some boxes 
contain less of a product (e.g., cereal) than the amount printed on the box indicates. 
The boxes are filled and then sealed by a machine. Even with the most sophisticated 
equipment available, the weight of the cereal put into boxes will vary. Suppose that 
it is established that these amounts follow a normal distribution with some mean 
f (which can be set in the packing plant) and a standard deviation a (which is the 
attribute of the machine). For example, let f = 20 oz and a = 1.5 oz.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
373

374
TESTING STATISTICAL HYPOTHESES
If the mean ^ is set at 20 oz, then about 50% of the boxes will contain less than the 
nominal amount, and at least for buyers of these boxes, the fact that the other 50% of 
boxes contain more than the nominal amount may be of no relevance. Consequently, 
the packing company must set the average ^ at a value above the nominal weight 20 oz. 
Since no value ^ will guarantee that the content of a box will always be above 20 oz, a 
reasonable requirement may be that 99% of boxes must contain at least 20 oz of cereal. 
If X denotes the weight of the cereal in a randomly chosen box, then
0.99 = P(X > 20) = P (Z > 2°-^.A =1 - ф f 20-7,
1 
\ “ 1.5 / V 1. 5 J
and ^ = 23.5 oz. Thus, in order to satisfy the requirement, the company should set the 
average weight of the content of the box at least at a value 23.5 oz.
The agency that investigates the customers’ complaints has to determine whether or 
not the average weight content is at least 23.5 oz. Since opening all boxes and weighting 
their content is not feasible, the agency must decide how to do itin a more practical way. 
For example, one may agree (and such a decision should be made in advance, prior to 
any sampling) that n = 16 boxes of the cereal in question will be bought; the stores will 
be sampled, and in each store, one box will be chosen at random from the shelf. Then, 
the content of all 16 boxes will be weighed and the average x will be calculated. Next 
some threshold has to be established (e.g., x = 23) so that if x < 23 oz, the hypothesis 
^ > 23.5 will be rejected; otherwise, it will be accepted.
The probabilities of two types of errors can be calculated as follows: It may happen 
that ^ > 23.5, but the sample average x falls below 23 oz. We then declare the company 
to be at fault (of not putting, on average, at least 23.5 oz of cereal in boxes), although 
in fact the company is not at fault.
It may also happen that we observe x > 23 (hence we declare the company as not 
being at fault), whereas in fact ^ < 23.5. To compute the chance of these two kinds of 
errors, we will find the probability that the company is declared at fault while the true
" 
P{X <23W = ф (гВб),
which is a decreasing function of p,.
Declaring the company at fault is an error if in fact ^ > 23.5 (otherwise, it is a correct 
decision). The probability of such an error attains the smallest value for ^ = 23.5 :
ф
23 - 23.5\
1.5/716 ) = 0.09.
The chances of the other type of error—declaring the company as not at fault, when 
in fact ^ < 23.5—for any specific ^ are equal to
P{X> 23\} =1 - Ф f 23; *
1. 5/716
For instance, if ^ = 22, then the probability above is less than 0.004.
To make a decision “6 & 00” or “в / 00,” we specify a set C of points in the space of 
values of X with the instruction: if the actual observation x is in C, then decide that 6 & 00; 

INTRODUCTION
375
otherwise, decide that в 0 00. Such a set C is called a critical (or rejection) region for the 
hypothesis that в e 00.
In Example 12.1 we have X = (X1, ...,X16), and the critical region C consisting of all 
points (x 1, ..., x 16) is such that (1 /16)(x 1 + • • • + x 16) < 23.
Ideally, the best critical region C would minimize the probabilities of errors of type I and 
type II, but this principle is too general. One has to realize the following two points:
1. If в e 00, then deciding that в / 00 is the error of type I. This error occurs whenever the 
observation X falls into the critical region C. So the probability of an error of type I is
a(в) = Pe{X e C}. 
(12.1)
On the other hand, if в / 00, then deciding that в e 00 is the error of type II; this occurs 
whenever X / C .So the probability of an error of type II is
в(в) = Pe{X e C} = 1 - Pe{X e C}. 
(12.2)
Probabilities of errors are not single numbers but functions of the parameter в, both 
expressible in terms of п (в) = Pe {X e C}, called the power function of the test C. The 
minimization principle requires that power function be “as small as possible” for в 00 
and “as large as possible” for в / 00. Obviously, the best test is such that Pe{X e C} = 
0 if в e 00 and Pe {X e C} = 1 if в / 00. However, in most cases of practical impor­
tance and interest, Pe{X e C} is a continuous function of в, and such a “best” test does 
not exist.
2. Looking at formulas (12.1) and (12.2), we see that any modification of C has opposite 
effects on the probabilities of errors of type I and type II: if one of them decreases, then 
the other increases.
Example 12.2, which is a continuation of Example 12.1, provides more explanation.
■ EXAMPLE 12.2
The properties of the decision procedure as to whether the cereal-producing company 
should be declared at fault depend on the choice of the threshold (23 oz), and the sam­
ple size n. Changing the threshold up or down changes the probabilities of the two 
types of errors, with the changes always going in opposite directions. The only way to 
decrease probabilities of both types of errors at the same time is to increase the sample 
size n. The “best” test must result from a compromise between the cost of sampling, 
and the consequences of the two types of errors. In the case of boxes of cereal, the cost 
of increasing n from 16 to 100 is ofa little concern. Of course, increasing the sample size 
in other experiments might be more expensive, time-consuming, or even impossible.
The consequences of declaring the company at fault, when it is not, can again be 
expressed by the cost (the company may have to pay a fine, unnecessarily reset the 
mean to a higher value, etc.). The consequences of declaring company not at fault, 
when in fact it is, are hard to express in terms of cost; they involve many very small 
losses suffered by individual buyers.
The fact that the probabilities of errors of types I and II are negatively related, and that 
each is a function of в (defined on sets 00 and 01, respectively), makes formulation of the cri­
terion to be optimized a difficult and challenging task. The conceptual structure of the 
theory is as follows. First, the problem of optimization is solved for the simplest case, where 
00 = {в0} and 01 = {в 1}. The solution is given by the Neyman-Pearson lemma, which 

376
TESTING STATISTICAL HYPOTHESES
determines the test (i.e., critical region) with the preassigned probability of error of type I, 
and a minimal probability of error of type II (or equivalently, a maximum power at value 6 1). 
Such test is called most powerful. In some sense, the Neyman-Pearson lemma plays a role 
analogous to that of the Cramer-Rao inequality in estimation theory: both set the standard 
by showing how much can potentially be achieved.
In some classes of testing problems, in which 01 (and often also 00) consist of more than 
one element, there exists a test C that is the most powerful against any 6 e 01; such tests are 
called uniformly most powerful (UMP).
There are, however, classes of testing problems in which the UMP test does not exist. In 
such cases, the idea is to eliminate tests with some undesirable properties. The UMP test will 
often exist in the reduced class.
We discuss only one such reduction, reduction to the class of unbiased tests. The uniformly 
most powerful unbiased (UMPU) tests may not achieve maximum possible power specified 
by the Neyman-Pearson lemma, but they are uniformly most powerful among the unbiased 
tests (UMPU).
A following analogy can help one understand why such a reduction can lead to the exis­
tence of a UMP test. Suppose that we want to find the strongest athlete, in the sense of the 
strength of his right arm and strength of his left arm (considered separately). It may happen 
that there will be no strongest athlete in the group. The one with strongest right arm will have 
weak left arm, and vice versa, and no winner will be found. But one may restrict the compe­
tition to only those athletes that have equal strength in both arms. Among those, the winner 
(or winners) can always be found. Such a winner may be called the most powerful “unbiased” 
athlete.
This analogy immediately suggests another solution: Why not compare the athletes with 
respect to combined strengths of right and left arms? Or, according to the sum of appropriate 
scores, possibly different for left and right arms? (similar to deciding the winner in events such 
as the decathlon, which is based on sum of scores for different events).
While in our example the “most powerful unbiased athlete(s)” could always be found, it is 
not necessarily so with UMP tests. To understand why, suppose that the competition involves 
comparisons of strengths of right and left arms, and also right and left legs (separately). If 
no “absolute” winner (strongest on each limb) exists, one could reduce the competition to 
“unbiased” athletes, those whose strengths of right and left arms are the same, and whose 
strengths of right and left legs are the same. But now there is no guarantee that “most pow­
erful unbiased athlete” exists, since an athlete with strongest arms need not have strongest 
legs, and vice versa.
In short, UMPU tests exist in some classes of problems and do not exist in other classes, 
so some further reduction may be needed to single out the UMP tests in this reduced class. 
The best exposition of the theory can be found in the monograph of Lehmann and Romano 
(2005).
The following example shows how reality can force one to use tests that are suboptimal:
■ EXAMPLE 12.3
The testing procedure suggested in Example 12.1 declares the company at fault when 
x < 23. Such a test may well be optimal from the point of view of statistical criteria 
involving probabilities of errors, but it has a disturbing feature: it may happen that we 
declare the company at fault when all boxes tested actually contain more than the nom­
inal 20 oz amount. Such a decision may not be defensible in court, in case the company 
decides to appeal. One should then restrict the consideration to procedures, that have 
the threshold value set below the nominal value 20 oz, and such procedures may be 
suboptimal.

INTUITIVE BACKGROUND
377
12.2 INTUITIVE BACKGROUND
Let X1 ,X2 , ...,Xn be a random sample from a distribution that belongs to some family 
f (x, в) and we know that в is an element of a parameter space 0. As before, we do not know 
what is the true value of в that governs the probabilities of the sample X 1, X2, ..., Xn.
The difference between the problem of estimation and the problem of testing is that now 
we are not interested in approximating the true value of в. What we need to find out is only 
whether в belongs to some specific subset 00 C 0.
■ EXAMPLE 12.4
Consider a politician who will win or lose the election, depending whether the propor­
tion of voters who will cast their votes for him exceeds 50% or not. If в is the fraction 
of voters who favor the politician in question, then 0 < в < 1, so that the parameter 
space is 0 = [0, 1], and the set of interest is 00 = (11, 1]. A survey may give a sample 
X 1,...,Xn of random variables with Bernoulli distribution f (x, в) = вх (1 - в )1x, 
x =0, 1, and the question is how to use the observation to determine whether or not 
в е 00. A typical question may be: suppose that out of n = 400 voters sampled, only 
195 will vote for the politician in question, and 205 will vote against him. Should one 
reject the hypothesis that в>1/2? The answer depends on many factors, the most cru­
cial being: how likely is it to observe the data so much (195 vs. 205) or even more in 
favor of rejecting the claim в>1/2, ifin fact the true value of в is above 1/2?
In the generally accepted terminology, the statement that в belongs to 00 and the state­
ment that в does not belong to 00 are called hypotheses.
Let 01 =0\ 00 so that out of the two hypotheses, H0 : в е 00 and H1 : в е 01, exactly 
one must be true. Logically speaking, denying the truth of one hypothesis is equivalent to 
accepting the truth of the other. The actually observed sample x = (x1,x2, ...,xn) provides 
some evidence, typically pointing in favor of one of the two hypotheses. A decision rule is a 
rule that tells us what to do in case of observing x = (x1, ...,xn). These actions may be 
“accept H0,” “reject H0 (and therefore accept H1),” “take another observation,” or even 
“leave the matter unresolved.” A decision rule will be called a test25 (more precisely, 
a nonrandomized test) if the only actions allowed are “accept H0” and “accept H1.”
25It is important to realize that the phrases “accept H” and “reject H” are to be interpreted as decisions regarding 
future behavior rather than regarding truth or falsehood ofH. Thus, to “accept H” means (in majority of practical 
situations) to proceed “as if H were true.” In fact it would be unrealistic to expect more: our decision is based on 
observation of a random sample; hence, we are always exposed to a risk of a wrong decision, namely rejecting H 
when in reality H is true, or accepting H when in reality it is false. The best one can do is to control the probabilities 
of these errors. Instead of stating that “hypothesis H0 is accepted,” the verdict is often phrased in a more cautious 
way such as “there is not enough evidence to reject H0.”
Since only two actions are allowed in a test, we must choose one of them regardless of the 
value of x. Therefore, any decision rule is equivalent to a partition of the sample space into 
two subsets: the set of those points x at which H0 is to be accepted, and its complement, the 
set of those points x at which H0 is to be rejected (i.e., H1 accepted).
Accordingly, we designate one of the hypotheses as the null hypothesis, denoted H0, with 
the corresponding subset of parameter space denoted 00 . The complementary hypothesis 
is called the alternative hypothesis, and is usually denoted by H1 or Ha . The corresponding 
subset of parameter space is 01 =0\00.
The testing procedure is specified by the subset C of the sample space, called the critical 
region, and the rule
reject H0 if x е C.

378
TESTING STATISTICAL HYPOTHESES
Observe that in this formulation the two hypotheses, H0 and H1, are treated symmetrically, 
and the designation of one of them as the null hypothesis is arbitrary. Subsequently, this 
symmetry will be lost, and the null hypothesis will play a different role than the alternative.
To formulate the meaningful criteria that will eventually allow to choose the best test, we 
introduce some auxiliary definitions.
Definition 12.2.1 A hypothesis H: 6 e 00 is called simple if it completely specifies the distri­
bution of the sample; otherwise, it is called composite. 
□
As mentioned before, two types of error can be made as a result of our decision: a true 
null hypothesis can be rejected, or a false null hypothesis can be not rejected.
It goes without saying that we would like to minimize the probabilities of both types of 
errors. The trouble here is twofold. First, the probability of errors depends typically on the 
value of 6, so the phrase “probability of rejecting null hypothesis when it is true” does not 
have unique meaning if the null hypothesis is composite. In fact, there are many values of 6 
for which null hypothesis is true, and the probability in question depends on the particular 
value of 6. The same remark applies to the alternative hypothesis if it is composite.
The second source of difficulty lies in the fact that under any reasonable definition of 
the probability of errors, the two probabilities are inversely related. If the probability of one 
type of error decreases, then the probability of error of the other type increases. To obtain a 
convenient tool for expressing the probabilities of errors associated with a test, we introduce 
the following definition, central for the whole theory of testing statistical hypotheses:
Definition 12.2.2 If C is the critical region of a test of the null hypothesis H0 : 6 e 00, the 
function nC (6), defined on parameter space 0 as
nc(6) = Pe{X e C}, 
(12.3)
is called the power (or power function) of test C. 
□
Thus, power is the probability of rejecting the null hypothesis if the value of the parameter 
is 6. Qualitatively speaking, a good test should have high power when 6e/00, since for such 
6 the null hypothesis is not true, and rejecting it is a correct decision. On the other hand, for 
6 e 00 the power of a good test should be low, since for such 6 the null hypothesis is true, 
and rejecting it is a wrong decision. Let us now consider a few examples.
■ EXAMPLE 12.5
A supermarket buys oranges from a certain company, that claims that the fraction of 
unacceptable fruit (e.g., rotten) in each shipment does not exceed 3%. The supermarket 
is willing to accept such (but not higher) percentage of bad fruit. The procedure agreed 
upon specifies that a random sample of30 oranges will be selected from each shipment 
(the method of sampling is typically also a part of the protocol). The shipment will be 
accepted if there is no more than one unacceptable fruit in this sample, and rejected 
(or bought at a discounted price, etc.) otherwise.
First, assume that the results of sampling constitute independent Bernoulli trials 
with a probability of “success” (finding a rotten orange) equal to 6.
The range of 6 is (at least theoretically) the whole interval 0=[0, 1]. The random 
sample X1 , ...,X30 is drawn from the distribution f(x, 6) = 6x(1 - 6)1-x,x = 0, 1. 
The supplier’s claim is that 6 < 0.03. Let us take this claim as the null hypothesis so 
that 00 =[0, 0.03], while the alternative is 01 = (0.03, 1].

INTUITIVE BACKGROUND
379
The agreed procedure specifies that the supplier’s claim (null hypothesis) is rejected 
if there are two or more bad oranges in the sample, that is, if
30
S30 = E Xi > 2.
i=1
This means that the critical region is the set C = {2, 3, ...,30}. The elements in C are 
values of S30 that lead to rejection of the supplier’s claim that в e 00.
The power function of this test is
пс (в) = Pe{S30 > 2} =1 - Pe{S30 = 0} - Pe{S30 = 1}
=1- (1 - в)30 - 30в(1 - в)29 =1- (1 - в)29(1 + 29в).
Function пс (в) is strictly increasing (see Figure 12.1) from пс (0) =0 to пс (1) = 1, 
and its highest value on the set 00 (null hypothesis) is attained at в = 0.03, and equals
пс (0.03) = max пс (в) = 0.227. 
ее во
The supermarket manager would probably be content with such a procedure: if the 
alternative is true, that is, if the fraction в of unacceptable fruits exceeds 0.03, then 
he has at least a 22.7% chance of detecting it. In fact this chance increases rather fast 
with в. For instance, for в = 0.05, we have пс (в) = 0.446, and for в = 0.1, we have 
already пс (в) = 0.816.
Figure 12.1 Power functions nC (9) and пс (9).
On the other hand, the supplier will not be too happy. The chances of having a 
shipment rejected while the standard of в < 0.03 is actually met can be as high as 22.7% 
(if в is very close to 0.03).
■ EXAMPLE 12.6
Continuing Example 12.5, a possible solution to the problem of accepting orange ship­
ments is to change the procedure and reject the shipment if three or more (rather than 
two or more) fruits are unacceptable. The critical region, C1 , for rejecting the claim 
в < 0.03 is now {S30 > 3}, so
пС1 (в) = 1 - (1 - в)30 - 30в(1 - в)29 - 435в2(1 - в)28
=1- (1 - в)28(1 + 28в + 406в2).

380
TESTING STATISTICAL HYPOTHESES
Again, this is an increasing function, and (see Figure 12.1)
nC (0.03) = max nC (9) = 0.060.
11 
ее во "1
This time the supplier is happier, but the manager is not. He might feel that the chance 
of accepting a shipment with 9 = 0.1, equal to 1 - nCi (0. 1) = 0.411, is too high.
These two examples illustrate the fact that an attempt to decrease the probabilities of one 
type of error by changing the critical region leads to an increase of the probabilities of error 
of the other type. The only way to decrease both probabilities of error at the same time is to 
increase the sample size.
■ EXAMPLE 12.7 Randomization
In the case of orange shipments discussed in Examples 12.5 and 12.6, one could also 
suggest the following procedure, which does not involve any increase of the sample 
size and yet leads to a procedure that may be acceptable to both the manager and the 
supplier.
Since rejection of the shipment if S30 > 2 is too favorable for the manager, while 
rejection if S30 > 3 is too favorable for the supplier, one could suggest the follow­
ing procedure: if S30 is 0, 1, or 2, the shipment is accepted by the store; if S30 is 
4,5, ...,30,theshipmentis rejected by the store. However, if S30 =3, a coin is tossed, 
and the shipment is accepted or rejected depending on the outcome of the toss. Actu­
ally, it is not necessary to use a fair coin. One can also activate some other random 
mechanism such that the probability of the shipment being rejected if S30 =3is some 
fixed number y .
The power function n(9) = Ре{H0 is rejected} now equals
n(9) = yP{S30 = 3} + P{S30 > 4},
where 0 <y < 1, and it lies between power functions of the two procedures consid­
ered in Examples 12.5 and 12.6. It is possible that the manager and the supplier can 
negotiate a value of y that is acceptable for both of them.
The randomized procedure described in Example 12.7 is somewhat controversial. If test­
ing statistical hypotheses is regarded as a process aimed at establishing the truth or falsehood 
of some statements about the experimental situation under analysis, then indeed, declar­
ing the truth of one hypothesis on the basis of a flip of a coin may appear appalling and 
absurd. However, in testing statistical hypotheses according to the original intention of Ney­
man and Pearson (who built the foundations of this theory), the rejection and acceptance 
of the hypothesis are not statements about truth and falsehood. They are intended to be the 
guidelines for future actions. As Neyman (1950, pp. 259-260) wrote: “The terms ‘accepting’ 
and ‘rejecting’ a statistical hypothesis are very convenient and are well established. It is 
important, however, to keep their exact meaning in mind and to discard various additional 
implications which may be suggested by intuition. Thus, to accept a hypothesis H means 
only to take an action A rather than B . This does not mean that we necessarily believe that 
the hypothesis H is true. Also, if the application of the rule of inductive behavior ‘rejects’ H, 
this means only that the rule prescribes action B and does not mean that we believe that H 
is false.”
In light of this interpretation, the randomization of a decision is justifiable.
■ EXAMPLE 12.8
Let us consider a random sample from the U[0, 9] distribution, where 0 = (0, ж).
Suppose that we want to test the null hypothesis H0 : 5 < 9 < 6. The alternative 
hypothesis is H 1 : 9 < 5 or 9 > 6. Thus, 00 = [5, 6] and 01 = (0, 5) U (6, ж).

INTUITIVE BACKGROUND
381
We consider two tests and determine their power. First, we know (see 
Example 11.44) that T1 = Xn:n is the sufficient statistic for 6, and we might 
try to base the testing procedure on it. Clearly, if T1 > 6, we should reject the null 
hypothesis, since it simply cannot be true in this case. Similarly, we should reject the 
null hypothesis if T1 is too small, for example, T1 < 4.6. Finally, we may argue that 
the values of T1 slightly below 6 are also a good indication that H0 may be false, since 
we always have T1 < 6. The actual thresholds will depend on n. For the critical region
C = {(x1,...,xn): T1 < 4.6 or T1 > 5.9}, 
(12.4)
the power of the test is
nc(6)= P.{Ti < 4.6} + P.{Ti > 5.9}, 
(12.5)
where
Pe {Ti < 4.6} =
if 6 < 4.6
if 6>4.6.
1
( 446 ) n
Similarly,
Pe {Ti > 5.9} = 1 - P. {Ti < 5.9}
0if6 < 5.9 
t 1 - (9)n if 6 > 5.9.
Thus,
1
(4-6) n
(4-6) n + 1 - ( 59 ) n
nc(6) =
for6 < 4.6
for 4.6 <6< 5.9
for 6>5.9.
The graph of this power function for n = 15 is_presented in Figure 22.2.
Let us also consider a test based on statistic X. We know that E(X) = 6/2. To have 
a comparison with the test (12.4), consider now a test with the critical region
Ci = {(xi, ..., xn) : x < 2.30 or x > 2.95}. 
(12.6)
To determine the exact distribution of X, while possible in principle, is very cumber­
some, so we will rely on the approximation provided by the central limit theorem, using 
the fact that Var(Xi) = 62/12. The distribution of X is therefore approximately nor­
mal N(6/2, 62/12n), and the power of the test (12.6) is
nC1 (6) = P{X < 2.30} + P{X > 2.95}
2.30 - 6/2 
2.95 - 6/2
1 - Pl------ =^- < Z <------ =9-
l 6^/12n ~ 
“ 6^/P2n
=1-
2.5-.95 - 6/2d 
/2.30 - 6/2
, V 6/^Y2n) v 6/У12П
The graph of this function, for n =15, is presented in Figure 12.2.
As already mentioned, the expectation ofa “good” test is that it should have the power as 
low as possible for the values of 6 in the null hypothesis, and as high as possible for 6 in the

382
TESTING STATISTICAL HYPOTHESES
1
0.8
0.6
0.4
0.2
45678
9
Figure 12.2 Power functions of tests C and C1 .
alternative hypothesis. A glance at Figure 12.2 shows that the test C,_based on the sufficient 
statistic, is much better than the test C 1 based on the sample mean X.
As can be seen, for all 9 in the null hypothesis H0, we have nC(9) < nCi (9). Actually,
sup nC(9) = max(nC(5),nC(6)) = max(0.2863, 0.2414) = 0.2863.
6e 00
On the other hand,
sup nC (9) = max(nC (5), nC (6)) = max(0.4094, 0.6033) = 0.6033. 
ee0o 
1 
1 
1
For the alternative hypothesis, when we want the power to be as high as possible, 
we have nC(9) > nCi (9), except for two rather narrow ranges immediately to the left of 
9 =5and to the right of 9 =6. The test based on critical region C may be considered 
“better” than the test based on critical region C1 .
■ EXAMPLE 12.9
Finally, consider one of the classical examples, a test of hypotheses about the mean in 
a normal distribution with known variance. We assume that X1, ...,Xn is a random 
sample from the N(m, 1) distribution (assumption that a =1 is not a restriction of 
generality, as it simply amounts to choosing the appropriate unit for Xi ’s). Suppose 
that we want to test the null hypothesis H0 : m = m0 against the alternative H 1 : m = 
M0. In this case, the null hypothesis is simple while the alternative is composite.
The procedure will be based on the sample mean X. If this average deviates “too 
much” from m0, then the null hypothesis should be rejected. This means taking the 
critical region of the form
C = {(x 1 ,...,xn): |X - M 01 >k}, 
(12.7)
where k is some constant.
Recalling that Var(X) = 1 /2, the power function of this test is
пс(Л) = PM{|X - Л01 > k} = 1 - PM{|X - Л01 < k}
= 1 - P{0 - k < X < M0 + k}

INTUITIVE BACKGROUND
383
1 _ p f -k + л о - л
I 
1 /Vn
1 _ p f -k + ло - л
I 
i/Vn
< X — л < k + л о — л
1 1 \~ - 
1 Vn
< Z < k + л 0- л I.
1 /yn 
}
If H0 is true, then л = л0 and the power equals
nC (Л о) = 1 - P {\Z\ < kVn},
a quantity that depends on the chosen threshold k. Also, for any fixed k>0, we have 
nC (Л0) ^ 0 as n ^ x. On the other hand, for fixed k > 0 and n, we have nC (л) ^ 1 
when л ^ ±x .
This means that for a fixed sample size n we can choose the critical region so that 
the probability of the type I error is equal to any preassigned level. The probability 
1 — nC (л) of the type II error approaches 0 as л moves away from the null hypothesis 
(see Figure 12.3). How quickly it happens (i.e., how fast the power function approaches 
1 as 1л - л01 increases) depends on n.
The main issues raised by the examples of this section may be summarized as follows:
1. A test, being a procedure that ultimately leads to a choice between two hypotheses, is 
equivalent to specifying a critical region C in the space of observations.
2. The performance of the test C is described by the power function defined as 
n (6) = P{rejecting H0 if 6 is the true parameter value}. All criteria of choice of a 
test should ultimately be expressed in terms of the power function. Any such criterion 
should conform to the intuitive requirement that the power of a test should be as high 
as possible for 6 in the alternative hypothesis, and as low as possible for 6 in the null 
hypothesis.
3. The class of all possible tests (i.e., class of all possible critical regions C) is very rich, and 
any reduction of this class will facilitate the search for the best set (in whichever way the 
optimality is ultimately defined).
PROBLEMS
12.2.1 Let X1 ,X2 be a random sample from the U[6, 6 +1] distribution. In the test of 
H0 : 6 = 0 against H 1 : 6 > 0, H0 is rejected when X 1 + X2 > k. Find the power 
function of the test that has probability of the type I error equal 0.05.

384
TESTING STATISTICAL HYPOTHESES
12.2.2 Consider the following procedure for testing the hypothesis H0 : p > 0.5 against the 
alternative H1 : p<0.5 in BIN(10, p) distribution. We take observation X1, and 
reject H0 if X1 =0or accept H0 if X1 > 9; otherwise, we take another observation 
X2 (with the same distribution as X1 and independent of it). Then, we accept or reject 
H0 depending on whether X1 + X2 > 5 or X1 + X2 < 5. Determine and graph the 
power function of this procedure.
12.2.3 Consider three tests C1, C2, and C3 of the same hypothesis, performed independently 
(e.g., for each of these tests the decision is based on a different sample). Consider now 
the following three procedures:
A: Reject H0 only if all three tests reject it; otherwise, accept H0 ,
B: Reject H0 only if at least two tests reject it; otherwise, accept H0, 
C: Reject H0 only if at least one test rejects it; otherwise, accept H0 .
(i) Express the power functions of procedures A, B, and C through power func­
tions of tests C 1-C3. (ii) Assuming that power functions of tests C 1-C3 are the same 
(nC 1 (6) = nC2 (6) = nC3 (6) = n(6)), graph the power functions of procedures A, B, 
and C.
12.2.4 Let X1 ,X2 be a random sample of size 2 from the U[0, 6] distribution. We want to 
test H0 : 6 = 3 against H 1 : 6 = ^(observe that H0 and H 1 do not exhaust all pos­
sibilities). (i) H0 will be rejected if X < c. Find c such that the probability of a type I 
error of the test is a = 0.05 and determine its power function. (ii) Answer (i) if H0 
will be rejected when X2:2 <c. (iii) Compare the power functions of both tests.
12.2.5 An urn contains five balls, r red and 5 - r white. The null hypothesis states that all 
balls are of the same color (i.e., H0 : r =0or r =5). Suppose that we take a sample 
of size 2 and reject H0 if the balls are of different colors. Find the power of this test for 
r =0, ..., 5 if the sample is drawn: (i) Without replacement. (ii) With replacement. 
(iii) In each case find the probability of a type I error. (iv) Answer (i)-(iii) if the null 
hypothesis is now H0 : r =1or r =2, and it is rejected when all k balls selected are 
white.
12.2.6 A large box is full of chips in three colors: red, black, and green. The hypothesis to be 
tested is that chips in the box are mixed in equal proportions with the alternative that 
they are not. Four chips are to be selected with replacement and the null hypothesis 
will be rejected if at least one color of chips will be missing. Determine the power of 
the test if chips in the box are mixed in proportions 0.25 (red), 0.25 (black), and 0.5 
(green).
12.2.7 Let X 1, ... ,X 9 be a random sample from the N( p, 1) distribution. To test the hypoth­
esis H0 : p < 0 against H 1 : p> 0, one uses the test “reject H0 if 3 < X < 5.” Find 
the power function and show that this is a bad test.
12.2.8 A coin is thrown independently 40 times to test that the probability of heads 6 is 0.5 
against the alternative that it is greater than 0.5. The test rejects the null hypothesis if 
more than 24 heads are observed in these 40 tosses. (i) Use the CLT with continuity 
correction to approximate the power function formula. (ii) Obtain the size of the test, 
and the power for 6 = 0.6.
12.3 MOST POWERFUL TESTS
If in the parametric situation considered in this chapter both hypotheses, null and alternative, 
are simple, it means that we are testing H0 : 6 = 60 against H1 : 6 = 61 where 60 and 61 are 
two parameter values.

MOST POWERFUL TESTS
385
To simplify the notation, let us write f (x; в0) = f0(x) and f (x; в 1) = f 1(x). The only 
assumption about f0 and f1 is that they represent different probability distributions. In the 
discrete case, this means that P{X = x|H0} = f0(x) = f1(x) = P{X = x|H1} for some x. 
In the continuous case, f0 and f1 are densities, and it is not enough that f0 and f1 differ at 
some isolated point, or even on a countable set of points. Thus in the continuous case, we 
assume that
f0(x) dx = f1(x) dx
for some set A.
We present the motivation for steps of the proof of the randomization principle theorem 
that will be introduced later. We consider the case of a single observation, but the extension 
to the case of n observations will be obvious.
Suppose that we determined some critical region C . Thus, the test is
reject H0 if x e C. 
(12.8)
Since both hypotheses are simple, we can determine the probabilities of errors of both types. 
Thus, the probability of rejecting H0 if it is true (type I error) equals
{
JC f0(x) dx
(12.9) 
f0(x),
xEC
depending on whether we deal with a continuous or a discrete case. Similarly, the probability 
of not rejecting H0 if H1 is true (type II error) is
{
1 — C f 1 (x) dx
(12.10)
1 — 
f1 (x).
xEC
Since to decrease в we must increase the integral in (12.10), the problem is to choose C so 
as to maximize C f1(x) dx. It will be convenient to partition the set of values ofx into four 
sets A0, A1, A2, A3, depending on which of the two densities is zero and which is positive 
(see Figure 12.4).
Let us first consider the set
A1 ={x:f0(x)=0,f1(x) >0}. 
(12.11)
Figure 12.4 Partition into sets A0, A1, A2, A3.

386
TESTING STATISTICAL HYPOTHESES
If any part of this set lies outside C, then we can improve the test by including it into C , that 
is, take the test with critical region C* = C U A 1 = C U (Cc П A 1).
Indeed, for the test C* (in the continuous case), we have
a* J fo(x) dx J fo(x) dx + J 
fo(x) dx = a,
since f 0 (x) = 0 on Cc П A 1. Thus, test C* has the same probability of a type I error as test 
C. However (again for the continuous case), we have
в * = 1 — j f i( x) dx =1 — j f i( x) dx — j 
f i( x) dx
< 1 У f 1(x) dx = в,
which means that the probability ofa type II error has decreased. This argument shows that 
the set A1 should be totally contained in the critical region C.
On the other hand, consider the set
A2 ={x:f0(x) >0,f1(x)=0}. 
(12.12)
A reasoning analogous to that carried for A1 shows that the entire set A2 should lie outside 
the critical region C. Next, the set
A0 = {x : f0(x) = f1(x) = 0}
plays no role in our reasoning. The way in which this set is partitioned between C and its 
complement has no effect on a and в•
Now let
A3 = {x : f0(x) > 0andf1 (x) > 0}. 
(12.13)
The problem reduces to finding the best way of partitioning A3 between C and its comple­
ment, in order to improve C.
To simplify the argument, consider the discrete case. Suppose that we have already selected 
some set C as a candidate for a critical set, and that C D A 1 and A2 C Cc.
Let x* / C (with x* A A3), and consider the consequences of changing C by including 
x* in it. The probability of a type I error will change to
fo(x) + fo(x*) = a + f0(x*) > a.
xeo
On the other hand, the probability of a type II error will change to
1 — E f 1(x)+ f 1(x*) = в — f 1(x*) <в.
xeC
Thus, a increased by f 0(x*) while в decreased by f 1(x*).
In a similar way, suppose that x** A C and that we remove it from C. Then, a will decrease 
by f0(x**), while в will increase by f1(x**).
Consequently, if x* / C and x** A C, switching the role of these points results in the 
following change:
a changes to a + (f0(x*) — f0(x**)),
в changes to в +(f1 (x**) — f1 (x*)).

MOST POWERFUL TESTS
387
Since we want to minimize both a and в, such a change should always be carried out 
if f0(x*) - f0(x**) < 0 and f 1(x**) - f 1(x*) < 0, with at least one inequality being 
strict.
The inequalities above mean (remembering that x* and x** are in A3) that f1(x**) < 
f 1(x*) and f0(x**) > f0(x*) > 0. So since one inequality is strict
fi(x**) < fi(x*) 
fo(x**) 
fo( x*).
(12.14)
We therefore obtained the following principle:
Reduction Principle In choosing the critical regions, one should restrict the considerations 
to sets based on the likelihood ratio f1(x)/f0(x) of the form
Ck
x: f 1( x) 
fo( x) >k
(12.15)
□
Indeed, if a critical set is not of the form (12.15), then there exist points x* and x**, with 
x* / C and x** C C and such that (12.14) holds. Then, a better critical region can be 
obtained by exchanging the roles of x* and x**.
It should be noticed that we did not solve the problem of finding the best test. In fact 
we did not even specify the criterion to be optimized. The reduction principle above tells 
us only which tests should not be used—in other words—it specifies the class of tests from 
which the choice should be made, provided only that the optimality criterion is compatible 
with the general motive to decrease both probabilities of errors.
Two obvious ways of defining the criterion to be optimized are as follows:
1. Impose an upper bound on one of the probabilities of errors, and minimize the probability 
of the other kind of error.
2. Minimize a linear combination of the two error probabilities.
These two approaches are closely related, the first being used in the original 
Neyman-Pearson lemma dating back to 1933. In formulating the theorem below, we 
will consider a general situation ofa random sample X = (X1, ...,Xn) from one of the two 
distributions f0 or f1 . The null hypothesis asserts that the distribution is f0 .Fori =0, 1 we 
will write fi(x) = fi(x 1) x • • • x fi(xn). The critical regions under consideration are now 
subsets of the n-dimensional Euclidean space.
Theorem 12.3.1 (Neyman-Pearson Lemma) Let C * be a critical region that has the following 
properties: There exists a constant k>0 such that:
(a) If f 1(x)/fo(x) >k, then x C C*.
(b) If f1(x)/f0(x) < k, then x / C* with points at which f 1(x)/f0(x) = k partitioned 
between C* and its complement in some way.
Let C be any critical region. Then, a(C) < a(C*) implies в(C) > в(C*), and if a(C) < 
a(C*), then в(C) > в(C*).
Proof: Without danger of confusion, we can use the symbols A0, A1 ,A2, and A3 for the 
four sets in Rn, depending on which of the joint densities f0(x) and f1(x) is zero and which 
is strictly positive. If we assume that c/0 = ж for any c > 0, then the critical region C* in 
the lemma is such that
A 1 C C*, A2 c (C*)c. 
(12.16)
Indeed, we have f1(x)/f0(x) = ж >kon A1 and f1(x)/f0(x) = 0 < k on A2. The theorem 
follows from the argument for the one-dimensional case preceding this proof: if C does not 

388
TESTING STATISTICAL HYPOTHESES
meet conditions (12.16), then one or both of its error probabilities can be improved, as stated 
in the assertion of the Neyman-Pearson lemma.
Next, the set A0 plays no role, and the question remains about points x in A3 . In the dis­
crete case, the argument given for one-dimensional case remains valid: ifC is not of the form 
specified in the lemma, then there exist x* / C and x** C C such that (12.15) holds, and by 
switching these points we improve both error probabilities. It remains therefore to prove the 
theorem in the continuous case. Consider the sets
C* П Cc = /x : f1(x) >k, x / C I 
f0(x)
and
(C*)c П C = |x : fjx) <k, x C Ш . 
f0(x)
We have here
a(C*) - a (C) = 
* fo(x) dx - f fo(x) dx
= fc c fo(x) dx - jc {G } f0(x) dx
< Cwc.1 f-(x> dx - Cn(C).1 f 1x) ddx
=1 C..f i(x) dx - 1Cc )).fi(x) dx
= 1[в(C) - в(C*)]. 
k
The inequality between the extreme terms completes the proof: if a(C) S a(C* ), then 
the left-hand side is nonnegative and so must be the right-hand side, which means that 
в(C) > в(C*). If the left-hand side is strictly positive, so must be the right-hand side. □
We will now formulate the analogue of the Neyman-Pearson lemma in the case where the 
criterion to be minimized is a linear combination of the two error probabilities. The proof, 
which follows closely the reasoning in the proof of Neyman-Pearson lemma, will be omitted.
Theorem 12.3.2 Suppose that in testing H0 : f = f0 against H1 : f = f1, it is desired to find 
the critical region C* in n-dimensional space, such that for any other critical region C we have
Aa (C*) + Вв(C*) < Aa (C) + Вв(C),
whereA>0,B > 0 are given constants. Then C* contains all points x such that f1(x)/f0(x) > 
A/В, and its complement contains all points x such that f 1(x) / f0(x) < A/В. The points where 
f 1(x)/ f 0(x) = A/В can be allocated between C* and its complement in an arbitrary way.
Since in the case of simple hypotheses the power of the test with critical region C is 
1 - в(C), the Neyman-Pearson lemma gives us in effect a rule of constructing the mostpow- 
erful test, with the preassigned probability a(C) of type I error (as we will see, this probability 
is determined by the choice of a constant k).
We now introduce three important definitions. Let C be the critical region for testing 
the null hypothesis H0 : 6 C 0O against the alternative H 1 : 6 C 01, and let nC (6) = 
Pe {X C C} be the power of the test.

MOST POWERFUL TESTS
389
Definition 12.3.1 The size of the test C is defined as
a(C) = sup nc (в).
ее 0o 
u
Thus, the size of the test of a simple null hypothesis is the probability of a type I error, 
while for the composite null hypotheses the size is the least upper bound for all probabilities 
of type I errors.
Definition 12.3.2 Any number a satisfying the inequality a (C) < a is called the level of 
test C, and a test C satisfying a (C) < a will be called an a - level test. 
□
According to this definition, a test with a (C) = 0.01 is a 1%-level test, as well as a 5%-level 
test, and so on.
Finally, we define a significance level. This is not so much a property of a test as a con­
straint imposed by the statistician.
Definition 12.3.3 If in testing the hypothesis H0 the statistician chooses a number a0 
(0 <a0 < 1) and decides to use only those tests C whose size satisfies the inequality 
a(C) < a0, then a0 is called the significance level chosen by the user. 
□
It is often felt that a report that a given hypothesis was rejected at the significance level 
a = 0.05 is not informative enough (e.g., the hypothesis might also be rejected at the signif­
icance level a = 0.01 or even lower). Thus, it is customary to report the so called p-value, 
defined as the lowest level at which the null hypothesis would be rejected by the test. More 
intuitively, the p-value of the results actually observed is the probability that if the exper­
iment were repeated, we would obtain results that give at least as strong evidence for the 
alternative hypothesis (or equivalently, as strong evidence against the null hypothesis) as the 
present result. For instance, suppose that we use statistic T for testing, and we reject the null 
hypothesis ifT is large. The result which we observe is T = t0, say. Then, the p-value of this 
result is P{T > 10\H0}, so that the smaller is the p-value, the stronger is the evidence that 
suggests rejection of the null hypothesis.26
26Very high p-values (close to 1) might indicate that the data were manipulated so as to make them “more 
conforming” to the null hypothesis. The rationale here is as follows: Suppose that the p-value of the data is 0.999. 
This means that the “fit” to H0 is so perfect that only once in a 1,000 times we would observe a better fit. The same 
principles which lie at the foundation of testing allow us to reach the conclusion that the data were fudged to fit
In the case of two-sided tests based on statistic T with a symmetric distribution, the 
p-value of the result t0 is defined as 2P(T > \t0\). Here the rationale is that the observa­
tions more “in favor” of the alternative hypothesis are those above \t0 \ and below -\t0 \.In 
the case of tests based on a statistic that does not have a symmetric distribution, the ideas 
behind the concept of p-value become rather fuzzy, and there is no definition on which all 
statisticians agree. Consequently, one may find various “competing” definitions in different 
texts. For a review of these definitions, see Gibbons and Pratt (1975).
An important comment is needed here. A p-value is a statistical index that can be useful 
in understanding the results of data analysis, but it should be used carefully since it has 
been frequently misinterpreted or even misunderstood in quantitative research. The p-value’s 
interpretation often became just a simple comparison with a 0.05 threshold. The conclusions 
about the null hypothesis being either “true” or “false” have been made on the basis of the 
side of the 0.05 threshold on which the p-value is. It has to be understood that the p-value 
is not a statement about the null hypothesis, but rather it provides the evidence about the fit 
of the actual data to the model specified by the null hypothesis. Moreover, the p-value does
H0.

390
TESTING STATISTICAL HYPOTHESES
not measure the size or the importance of the effect being investigated since it is affected by 
the sample size. Large samples can yield a small p-value even though the effect is really little 
while one could get a large p-value when the effect is substantial only because the sample 
size might not be large enough.
The p-value, as any other single index, cannot adequately summarize the results of the 
experiment. This is why statisticians have been proposing other approaches for interpretation 
of research data, such as estimation and its confidence and prediction intervals, or Bayesian 
credibility intervals, to mention just a few. The common misuse of p-values received a lot of 
attention in recent years and finally started a vivid discussion that engaged many statistical 
experts. We refer interested readers to the American Statistical Association statement on the 
use of the p-value (Wasserstein and Lazar, 2016), and papers in the special February 2019 
issue (Supplement 1) of The American Statistician, with over 40 papers on the topic.
We will now illustrate the procedure of test selection by some examples. In the four ini­
tial examples we will also illustrate another aspect: how an empirical hypothesis becomes 
“translated” into a statistical hypothesis.
■ EXAMPLE 12.10
Suppose that a scientist believes he found the exact location where memory is stored 
in the rats’ brain and needs to confirm it by an experiment. He genetically engineers 
10 rats so that the brain region in question can be remotely inactivated by shining light 
onto the brain. The rats are then trained to find food in a maze. In running through 
the maze, the rat makes three binary choices and as a result ends in one of eight final 
locations, of which only one contains food. Then, the scientist turns on the light to 
turn off the part of the brain that—according to the researcher’s hypothesis—stores 
the acquired knowledge. The rats run the maze again, and the experimenter observes 
the number X of rats that reach the arm with food. Without any memory left, each rat 
has probability (1/2)3 = 0.125 of finding the way to the food on the first trial. Suppose 
that—according to the experimenter—if this probability is as high as 0.3, it means that 
part of the memory must be stored in another (uninhibited) region of the brain. If 
the rats run through the maze independently, and each has the same probability p of 
choosing the path leading to food, then X has a binomial distribution BIN(10, p). 
We have now two hypotheses: one asserting that p = 0.125 (if the researcher is correct 
in identifying the memory storage region of the brain), and the other asserting that 
p =0.3 (if the researcher is wrong). Suppose that from the researcher’s point of view 
the error of rejecting the hypothesis p = 0.125 (i.e., no memory is left), if in fact it is 
true, is more serious than accepting p = 0.125 if in fact p = 0.3.
In this case, we set the null hypothesis as H0 : p = 0.125 and the alternative 
is H 1 : p = 0.3. Consequently, f0(x) = (1°) (0.125)x(0.875)10x and f 1(x) = 
(1x0) (0.3)x(0.7)10-x. According to the Neyman-Pearson lemma, we should choose 
the critical region of the form {x : f 1(x)/f0 (x) > k} for some k. But
f 1( x) 
fo( x)
(0.3) x (0.7)10-x
(0.125) x (0.875)10-x = 0.107 • 3x.
The inequality {x : f 1(x)/f0(x) > k} is equivalent to the inequality x > k* for 
some k* .This means that the critical region C is formed of the right tail of the distri­
bution ofX. Since the possible values ofX are 0, 1, ..., 10, we must simply determine 
the smallest value that belongs to C. Here the choice depends on the significance level 
a0 of the test. Suppose that the experimenter decides to use a0 = 0.05. Then k* must 
be such that P{X > k*\p = 0.125} < 0.05; that is, P{X < k*\p = 0.125} > 0.95. 
We have here P{X < 4|p = 0.125} = 0.973 while P{X < 3|p = 0.125} = 0.881. It 

MOST POWERFUL TESTS
391
follows that we must reject the null hypothesis H0 : p = 0.125 if X > 4; that is, if four 
or more rats find their way to the food on the first try. This test has the probability of 
a type I error equal to 1 - 0.973 = 0.027 and the probability of a type II error equal 
P{X<4|p=0.3} = 0.649.
Some comments about this example appear to be in order. First, we see that the type II 
error has rather high probability, whereas the probability of the type I error is below the level 
of significance. A test with a critical region C = {3, 4, ..., 10 } will have a (C) = 0.119, while 
в(C) = 0.382. It is clear that among tests satisfying the assertion of the Neyman-Pearson 
lemma, none has the probability ofa type I error equal to the desired significance level 0.05. 
This is due to the discrete nature of the test statistic X .
A procedure with the probability ofa type I error a0 = 0.05 exists ifwe allow randomized 
procedures. That is, suppose that we decide to reject H0 if X > 4, accept it if X < 2, and 
activate some auxiliary random mechanism and reject H0 with probability y if X = 3. Then 
the probability of rejecting H0 if it is true is
yP{X =3|p=0.125}+P{X > 4|p = 0.125} = 0.092y + 0.027,
which equals 0.05 ify = 0.25.
A procedure that attains a significance level a0 = 0.05 is therefore as follows: If four or 
more rats reach food on their first trial, then reject H0. If three rats reach food on the first 
trial, then toss two coins and reject H0 if both show up heads. In all other cases accept H0.
As was already pointed out, such a randomized procedure may be suggested and agreed 
upon in the process of acceptance or rejection of merchandise. However, in the case of a 
decision regarding scientific hypotheses, it would be disturbing to rely on the toss of a coin.
Away out from the dilemma is to abandon the concept ofa significance level as a quantity 
imposed by the experimenter. One can then proceed to minimize a linear combination of 
errors of type I and type II as in the Theorem 12.3.2. A procedure that attains it never requires 
randomization.
■ EXAMPLE 12.11
Continuing Example 12.10, ifwe want to find a critical region C so as to minimize the 
linear combination 10a(C) + в(C), we must include in the critical region all x such 
that f1(x)/f0(x) > 10, which means that
(0.3)x (0.7)10-x
(0. 125)x (0.875)10-x > 10
or3x > 93.46; hencex > 4.13. Then, if the type I error is considered 10 times as serious 
as the type II error, the null hypothesis should be rejected only if five or more rats find 
their way to the food on the first attempt.
■ EXAMPLE 12.12
Suppose that we have a well with drinking water that is thought to be contaminated 
with bacteria. A fixed volume V of water from the well is sent to the laboratory for 
testing. Assume that the admissible norm is N bacteria ofa certain kind in volume V , 
with 5N bacteria in volume V indicating an undesirable level of contamination. Here 
N>0, so that some positive level of contamination is acceptable as safe.
The procedure in the laboratory is as follows: The water sent for analysis is 
thoroughly mixed, and then a sample of volume v is drawn from it, where v С V. 
A technician inspects the sample under the microscope and reports the number 

392
TESTING STATISTICAL HYPOTHESES
X of bacteria that she sees. It is assumed that each of the bacteria present in the 
observed sample is recorded by the technician with probability n (assumed known), 
independently of the other bacteria.
This process is repeated n times, generating reports X1, X2, ...,Xn of the num­
bers of bacteria observed in different samples. We assume that the probability 1 - n of 
overlooking a bacteria is the same for all technicians.
It is desired to test the null hypothesis that the water in the well is safe against the 
alternative that it contains an undesirable level of bacteria. To solve this problem, it is 
first necessary to determine the distributions of the observable random variables and 
translate the empirical hypotheses stated above into statistical hypotheses.
Let A0 = N/V be the density of bacteria in the well allowed by the safety standards 
so that the null hypothesis is H0 : A = A0, where A is the actual density of bacteria 
per unit volume of water in the well. The alternative hypothesis is H1 : A = 5N/V = 
5A0 = A1.
We assume now that when a sample of volume v is taken, each of the bacteria has 
the probability v/V of being included in the sample, independently of other bacteria. 
The assumption that v С V makes the probability v/V small, and from Example 6.14 
(about “thinning” of Poisson processes), it follows that in each sample of volume v the 
actual number of bacteria will have Poisson distribution with mean Mv/V, where M 
is the actual number of bacteria in volume V. Thus, under the null hypothesis H0, in 
each sample of volume v the number of bacteria will have Poisson distribution with 
mean Nv/V = A0v, whereas under the alternative, the mean will be A1v = 5A0v.
We assume also that the total volume of water inspected by technicians, v1 + v2 + 
• • • + vn, is still small as compared with V so that the Poisson approximation applies 
to the total number of bacteria in all samples. Finally, the counts X1 , ...,Xn (see 
Example 6.14) have a Poisson distribution with mean A0n under hypothesis H0 and 
mean A 1 n under the alternative hypothesis H 1.
Letting X = (X1, ...,Xn), we know that the test (whether most powerful, in the 
sense of the Neyman-Pearson lemma or minimizing the linear combination of error 
probabilities) is based on the likelihood ratio f1 (x)/f0 (x), with values larger than a 
threshold leading to rejection of the null hypothesis. Denoting Sn = X1 + •• • + Xn 
for i =0, 1, we have
n 
nx
fi (x) = П f. (Xj )= П (AvT- e П'' 
j=1 j=1 
xj!
(nv)Sn -тлХ^
П( x.!)
x ASn.
Consequently, remembering that A1 = 5A0, we obtain 
f 1(x)
f0(x)
= e-4nnX 0 v x 5Sn,
so that the null hypothesis H0 should be rejected if the total count Sn reported by all 
technicians exceeds some threshold k.
The actual value of k depends on the numerical values of the parameters. For 
instance, suppose that we take n = 50 samples to be inspected by technicians, and that 
probability n of recording bacteria by each of them is n = 0.1 (i.e., each technician 
records about 1 bacterium out of each 10 present). Furthermore, assume that the 
number of bacteria allowed is 10,000 per liter (103 cm3), with the volume v taken 
for inspection being 1/20 of a cubic centimeter. This gives A0 = 104/103 = 10 with 
v = 0.05 cm3, so
nA0v = 0.1 x 10 x 0.05 = 0.05.

MOST POWERFUL TESTS
393
Under the null hypothesis H0, the total count X 1 + • • • + X50 in all samples has a 
Poisson distribution with mean 0.05 x 50 = 2.5. Under the alternative, this count is 
still Poisson, but with mean 12.5.
If we want to test the null hypothesis at significance level a = 0.05, then k is deter­
mined by
P{S50 > k\A = 2.5} < 0.05,
where Sn has a Poisson distribution with mean 2.5. We have P{Sn < 5} = 0.9580, 
which means that P{Sn > 6} = 0.042. We may take k =6, so the probability of type 
II error of this test is в = P (S50 < 6\A = 12.5) = 0.015. Thus, the chances of raising a 
false alarm (in this case the type I error) are about 4%, whereas the chances of failing 
to notice a dangerous level of contamination are only about 1.5%.
■ EXAMPLE 12.13
Continuing Example 12.12, suppose that the laboratory is under a financial squeeze 
and decides to save on the cost of observations. The technicians are instructed to 
inspect each sample of size v and report only whether the bacteria were found. The 
saving here is that technicians stop searching the sample as soon as one bacterium is 
found (instead of continuing the search and counting). In a sample Y1, ...,Yn, Yj =1 
or 0 depending on whether bacteria are found in the jth sample. We have, for i =0, 1,
P{Yj = 1 Hi} = 1 - P{Yj = 0IH} = 1 - e-Xin.
(12.17)
Consequently, the total number of samples where bacteria were found, S = 
Y1 + • • • + Yn, has a binomial distribution, with the number of trials n and probability 
of success given by (12.17), depending on whether H0 or H1 is true. Recall that 
A 1 = 5A0, so the likelihood ratio is now
f 1(s) = 
f0( s )
P{S = s\H 1 7 
(n) (1 — e-nX 1 v)s(e-nX 1 v)n-s
P{S = s\H0} 
(n) (1 — e-nX0v)s(e-nX0v)n-s
= '1 — e—5nX0 v 44nX0 v 1 s - -4nX0 vn 
e^ 
e^ 
.
1 — e nX 0 v
Since the fraction in brackets exceeds 1, the likelihood increases with s. Again, the 
critical region is the set S > k, where k has to be determined from the fact that under 
the null hypothesis S has a binomial distribution, BIN(n, 1 - e-nX0v). In particular, 
the laboratory may now ask the question: How large should n be to ensure that the 
same significance level and the same power as in the more expensive procedure with 
technicians counting the bacteria, We have now e-nX0v = 1 — e—0•05 = 0.04 88 and 
e-nX 1 v = 1 — e-0• 2 = 0. 1813. We look for n and k such that P(S > k) < 0.05, where 
S ~ BIN(n, 0.0488), and P(S' < k) < 0.015, where S' ~ BIN(n, 0.1813). Based onthe 
central limit theorem (Theorem 9.6.2), k has to satisfy
k - 0.0488n 
p Z z > , 
\ 7(0.0488)(0.9512) n
= 0.05,

394
TESTING STATISTICAL HYPOTHESES
P Z <
k - 0.1813n
, 
= 0.015,
7(0.1813)(0.8187) n
and consequently
( k = 0.0488n +(1.645)(0.2154)^П, 
|k = 0.1813n - (2.17)(0.3852)^n.
The solution, rounded to integers, is n =81,k =7. The simplified observation proce­
dure (recording only whether or not the bacteria are present) necessitates the increase 
of the number of samples from 50 to 81.
It is clear that in the case of continuous random variables we can always find a test (critical 
region C) such that a(C) equals the desired significance level a0. Below we present examples 
concerning distributions other than normal, leaving the detailed presentation of various tests 
for the normal case to a separate section.
■ EXAMPLE 12.14
Suppose that the observations X 1, ... ,Xn form a random sample from the EXP(A) 
distribution. We want to test hypothesis H0 : A = 5 against a simple alternative 
H1 : A =8at the significance level a0 . The likelihood ratio is then
f1(x) = Пn=i(8e—8j) = (8\n -3Ex. 
f0(x) П n=i(5 e-5 x) W 
’
and the inequality f 1 (x) /f 0(x) > k is equivalent to xi < k* for some k*.
Here k* = - (1 /2)[n log(5/8) + log k], but the exact relation between k and k* is not 
needed to determine the test. What matters most is the direction of the inequality. The 
way we set the solution is that we reject H0 if the likelihood ratio f1/f0 (with alternative 
density on the top) is large. Typically, this condition reduces to an inequality for some 
statistic (such as x 1 + • • • + xn, or equivalently, x). In the present case, the rejection 
region is the left tail (i.e., values of x 1 + • • • + xn less than a certain threshold).
To continue, we need a value k* such that
P{X 1 + • •• + Xn <k*\H0} = a0.
Each Xi has exponential distribution with parameter A0, hence with the mean 
1/A0 . Consequently, 2A0Xi has an exponential distribution with mean 2, that is, a 
chi-square distribution with 2 degrees of freedom (see Theorem 8.4.3). Therefore, 2A0 
(X 1 + • • • + Xn) has a chi-square distribution with 2n degrees of freedom.
In the case under consideration, we have A0 =5; hence, the critical threshold k* can 
be obtained from the tables of chi-square distribution with 2n degrees of freedom:
P{X 1 + ... + Xn <k*\H0} = P{10(X 1 + ••• + Xn) < 10k*\H0}
= P{x2n < 10k*} = a0.
Taking, as an example, n =10 and a0 = 0.1, we obtain 10k* = x0.9 20 = 12.44, which 
gives k* = 1.244.
The probability of a type II error is
P{X 1 + ••• + Xn > 1.244\H 1} = P{16(X 1 + ••• + Xn) > 16 x 1.224\H 1} 
= P {x220 > 19.904} = 0.4637’

MOST POWERFUL TESTS
395
as obtained from statistical software. This probability seems rather high as a probability 
of error. One reason is that the difference between A = 5 and A = 8 is equivalent to a 
small difference between means (1/5 and 1/8, respectively). Another reason is that the 
small sample size (n = 10) affects the quality of the inference.
Thus far, we have considered testing the simple null hypothesis against a simple alterna­
tive in a parametric setup, where the distribution belongs to the same family f (x; 6), and 
the hypotheses are obtained by specifying H0 : 6 = 60 and H 1 : 6 = 6 1. It is important to 
realize that the Neyman-Pearson lemma applies to any two simple hypotheses. For instance, 
suppose that we have a single observation X, that comes from the U[0, 1] distribution if H0 
is true or from the EXP(3) distribution if H1 is true. The densities are
, i i 1 1 if 0 < x < 1 
3e-3x 
if x > 0
f0 (x)= 
0 otherwise 
an 
f1 (x)= 
0 
otherwise.
The likelihood ratio equals
f 1(x) = ( 3e-3x if 0 < x < 1
fo(x) 
I ™ 
if x > 1,
and it is undefined for x<0. Each critical region should contain the set {x : x>1},and 
also a set of the form 3e-3x > k, hence a set of the form {x : 0 < x < k*} for some k* < 1. 
To determine k*, we must have
P{X & C\H0} = [ f0(x) dx + [ f0(x) dx = [ f0(x) dx = k*.
010
It follows that if we choose the significance level a0 = 0.05 (say), then k* = 0.05, and we 
reject H0 if the observation is either below 0.05 or above 1. The power of this test is
1 — в = У f i(x) dx =1 — У 
3e-3x dx =1 — e-3 + e-0'15 = 0. 1891.
PROBLEMS
12.3.1 Let X1 , . ..,X10 be a random sample from a POI(6) distribution. (i) Find the best 
critical region for testing H0 : 6 =0.1 against H1 : 6 =0.5 at the significance level 
a = 0.05. (ii) Determine the size of the test in (i).
12.3.2 A single observation X is taken from a BETA(a, b) distribution. Find the most 
powerful test of the null hypothesis H0: a = b =1, against the alternative H1: 
(i) a = b =5. (ii) a =2,b=3(iii) a = b = 1/2. Use significance level a = 0.05.
12.3.3 Let X have a negative binomial distribution with parameters r and p. Find the 
most powerful test of H0 : r =2,p=1/2 against H1 : r =4,p=1/2 at signifi­
cance level a = 0.05. Find probability of type II error. Use randomized test if nec­
essary.
12.3.4 Assume that X has a N(2, a2) distribution. Find the best critical region for testing 
H0 : a2 = 2 against: (i) H 1 : a2 = 4. (ii) H 1 : a2 = 1.
12.3.5 Let X1 , .. .,Xn be a random sample from EXP(A) distribution. Null hypothesis 
H0 : A = A0 is tested against the alternative H1 : A = A1, where A1 >A0. Compare 
the power functions of the two tests: (i) the most powerful test and (ii) the most pow­
erful test based on the statistic X1:n. Assume that both tests have equal probabilities 
of a type I error.

396
TESTING STATISTICAL HYPOTHESES
12.3.6 The sample space ofa test statistic X has five values: a, b, c, d, e. Test the H0 : f = f0 
against Ha : f = f1 , where distributions f0 and f1 are given by the table
X
a
b
c
d
e
f0
0.2
0.2
0.0
0.1
0.5
f1
0.2
0.4
0.3
0.0
0.1
12.3.7 An urn contains six balls, r red and 6 - r blue. Two balls are chosen without replace­
ment. Find the most powerful test of H0 : r = 3 against the alternative H1 : r =5, 
with a size as close to a = 0.05 as possible. Find the probability of a type II error 
for all r =3.
12.3.8 A multiple-choice exam gives five answers to each of its n questions, only one being 
correct. Assume that a student who does not know the answer chooses randomly 
and is correct with probability 0.2. Let 6 be the number of questions to which the 
student knows the answers, and let X be the number of correct responses given by 
this student. (i) Determine f(x; 6)=P(X = x|6). (ii) For n = 50, find the most 
powerful test ofH0 : 6 = 30 against H1 : 6 =40at the significance level a = 0.05. 
(iii) Determine the probability of a type II error if 6 =40.
12.3.9 Let X1, ...,Xn have a joint density f(x; 6), and let U be a sufficient statistic 
for 6. Show that the most powerful test of H0 : 6 = 60 against H1 : 6 = 61 can be 
expressed in terms of U.
12.3.10 Let X 1, ... ,X 10 be a random sample from a POI(A) distribution. Find: (i) The 
critical region for the most powerful test of hypothesis that 6 =0.7 against the 
alternative that 6 = 0.2. Use significance level a = 0.05. (ii) The size of the test in 
(i) and the power for 6 = 0.2. (iii) The p-value if the data are as follows: 1, 0, 0, 2, 0, 
0, 0, 1, 0, 0. Interpret.
12.4 UNIFORMLY MOST POWERFUL TESTS
From the derivation of the most powerful tests in Examples 12.12 and 12.14, notice that the 
final form of the test is, to a large extent, independent of the choice of a specific alterna­
tive hypothesis. For instance, in Example 12.12, observations X1, ...,Xn come from one 
of the two Poisson distributions. Omitting the details on size v of the water samples and 
the probability n of recording the presence of bacteria, we could test a simple hypothesis 
H0 : E(Xi) = 60 against a simple alternative H1 : E(Xi) = 61, where 61 >60. The likeli­
hood ratio, after canceling the factorials, turns out to be
f 1(X) : (61 
Xi * / e-1
fo(X) 
6 J 
e- о
If 61 >60, then the likelihood ratio is an increasing function of Xi ; hence, the rejection 
region must be of the form
C = {(x 1, ...,xn): EXi ^ k}- 
(12.18)
Determination of value k involves only the value of 60 and a level of significance a0 ; the 
value 61 plays no role, provided that 61 >60 . We know that under the null hypothesis

UNIFORMLY MOST POWERFUL TESTS
397
Sn = n=1 Xi has a Poisson distribution with mean nd0; hence,
k = min < r : 
e-ne0 > 1 — a0 > , 
(12.19)
I 
j=0 j!
where a0 is the desired significance level.
This means that a test with the critical region given by (12.18) and (12.19) is the most 
powerful for any alternative hypothesis if only the reasoning leading to (12.18) applies. But 
the only fact about 6 1 used in the derivation is that 6 1 > 60. This inequality causes the ratio 
6 1 /60 to exceed 1, and hence the likelihood ratio to increase with the sum xi (for 6 1 < 60 
the likelihood ratio would decrease with an increase of xi and the critical region would 
comprise the left tail, i.e., we would reject H0 if xi < k).
In the continuous case, we can restrict the considerations to tests based on critical regions. 
In the discrete case, one can also consider randomized procedures, that is, procedures in 
which the rejection or acceptance of H0 depends both on the observation of X and also 
possibly on additional randomization.
Consequently, in the definitions below, we consider procedures for testing H0 ; without 
much danger of confusion, we will use letter C for a procedure, and define its power func­
tion as
nC (6) = Pg {procedure C rejects H0 }.
We will fix the significance level a0 (0 <a0 < 1), and let K(H0, a0) be the class of all pro­
cedures for testing H0 whose size is at most a0, that is, procedures C such that
sup nC (6) < a0. 
(12.20)
ее e0
Definition 12.4.1 A procedure C* e K(H0, a0), such that
nC*(6) > nC (6)
for every 6 e ©1 and for any C e K(H0, a0), will be called a UMP procedure for testing H0 
against H1 at the significance level a0 .
In the case where C* is nonrandomized (i.e., C* is the critical region of a test), we will 
speak of a UMP test of H0 against H 1 at the significance level a0. 
□
The essence of this definition lies in the fact that the same test (procedure) is most pow­
erful against all simple hypotheses in H 1. The Neyman-Pearson lemma (or its extension 
to composite null hypothesis) asserts that the most powerful test exists against any simple 
alternative, but it sometimes happens that these most powerful tests are different for different 
simple alternatives.
■ EXAMPLE 12.15
Consider the situation of testing the simple null hypothesis H0 : m = 0 against the 
composite alternative H 1 : m> 0 in case of a normal distribution N(M,a2) with 
known a2. Let us fix m 1 > 0 and consider the likelihood ratio test of H0 against 
H1 : /л = /л 1. We have
f 1(x) = exP { — (1 /2 a 2) E (xi — M 1)2} = De (д i/a 2) E xi 
f0(x) 
exP { — (1 /2a2) E x2} 
.
Since m 1 > 0, this likelihood ratio is an increasing function of xi (hence also of x), 
and the critical region of the most powerful test against M>0 is of the form 
{x = (x 1, ...,xn ) : x > k}.

398
TESTING STATISTICAL HYPOTHESES
For any given significance level a0, we determine k from the condition
P{X > k\H0} = P Z >
k
= = f a 0 
o^jn
so that k = z^o/^n, where zao is the upper a0-quantile of the standard normal 
distribution.
The only assumption about и 1 that is used here is и 1 > 0; consequently, the test 
with the critical region C,
reject H0 if X > z 1 -a0o x n
(12.21)
is UMP for the alternative H 1 : и > 0.
■ EXAMPLE 12.16
Continuing Example 12.15, observe that the test (12.21) is also UMP for the composite 
null hypothesis H0 : и < 0 against the composite alternative H 1 : m> 0. Indeed, the 
power of this test is
zx p 
o | Г X - Uza 0 (°xn) - M
nC (U ) = PH X > za 0 
? = P \~Л= > 
( I J~\
^ 
0 V n 
o^Jn 
(o/yjn)
=P Z>z
I — a 0
Consequently, for и < 0, nC (и) < P{Z > zao} = a0 = nC (0); hence the size of the 
test C is a0.
■ EXAMPLE 12.17
Example 12.16 shows that there exists no UMP test for the hypothesis H0 : U =0 
against the alternative H1 : U =0. Indeed, (12.21) is the most powerful test against 
any alternative U>0, but it performs very poorly against the alternative U<0;its 
power on such alternatives is less than a0 . On the other hand, by symmetry, the test 
with critical region C',
reject Hо if X < -Za^°=
\7 n
(12.22)
is most powerful against any alternative U<0, but performs poorly against alternatives 
M> 0. The “compromise” test, with the critical region C",
reject H0 if 
|X \> za 0 / 2 ^On,
(12.23)
performs quite well for all alternatives U =0but its power is below the power of test 
(12.21) for U>0, and below the power of test (12.22) for U<0. Soitisnot a UMP test.
We know from the examples above that UMP tests may not exist. On the other hand, 
if they do exist, they provide the best available procedures (if one takes into account only 
the error probabilities, and not extraneous aspects, such as computation costs, etc.). It is 
therefore natural to ask for conditions under which UMP tests exist. The answer is given by 
the next theorem, which we will precede by some necessary definitions.

UNIFORMLY MOST POWERFUL TESTS
399
Definition 12.4.2 We say that the family {f (x; в),в & 0} of distributions has a mono­
tone likelihood ratio in statistic T if for any two values в', в'' & 0 with в' < в'', and 
x = (x1, ...,xn), the likelihood ratio
fn (x; в")/fn(x; в')
depends on x only through the values T (x), and this ratio is an increasing function 
of T (x). 
□
We will now illustrate the introduced concept by some examples.
■ EXAMPLE 12.18
Consider the normal density depending on parameter m, with a2 known, so that
fn(x, M) = a„ (2n)n/2 exP | - 2a2 
(xi - M) j .
Let m' < m", and for typographical reason, let M = M 1 ,m" = M2 • Then,
f (x,M ) 
1
fn(x,m 1) =eXPl-2a2 £(xi - M2) -^ (xi - M 1)
= exp | -202 [-2(M2 - M 1) 
xi + n(M2 - M1)] j
= De(V2-V 1)'2 
xi,
where D > 0. Consequently, the normal distribution for a fixed a2 has a monotone 
likelihood ratio in T = 
Xi, or equivalently, in X.
■ EXAMPLE 12.19
Consider again the normal distribution, this time for known M and unknown a2 .Let 
a12 <a22 . Then,
fn(x,a2 ) _ D exn I 
1 
(x _ ,.)2 । 
1 
(x _ ,.)2 1
fn (x ,a2) D Pt 2 a2^ (xi M)+2 a2 
(xi M )J
= D expj 1 ( Л - “2 ) 
(xi M)2 !• .
2 a1 
a2
Since D>0 and 1/a12 - 1/a22 > 0, we see that now the likelihood ratio is increasing in 
statistic T = 
(Xi - m)2.
■ EXAMPLE 12.20 Bernoulli Trials
Let X1, ...,Xn be a random sample from Bernoulli distribution f(x; p)= 
px (1 - p)1-x,
x = 0, 1, and 0 < p < 1. For 0 <p <p" < 1, we have
fn(x ,P") 
fn(x ,P')
'p" (1 - p) 1 xi /1 - p" \ 
p' (1 - p") 
\ 1 - p' )
Since p" (1 - p') /p (1 - p") > 1, the Bernoulli distribution has monotone likelihood 
ratio in statistic 
Xi (total number of successes in n trials).

400
TESTING STATISTICAL HYPOTHESES
It turns out that most of the known families of distributions have monotone likelihood 
ratio in some statistics. The role of families with monotone likelihood ratio for UMP tests is 
explained by the following theorem:
Theorem 12.4.1 Let {f (x; в), в & 0} be a family of distributions with a monotone likelihood 
ratio in statistics T. Then for every a0, 0 < a0 < 1, there exists a test (possibly randomized) 
that is UMP for testing H0 : в < в0 against H 1 : в > в0 at significance level a0. This test 
satisfies the following two conditions:
(a) There exists k such that if T(x) >k, then H0 is rejected and if T(x) <k, then H0 is 
accepted.
(b) Po0 {H0 isrejected } = a0.
Similarly, for testing H0 : в > в0 against H 1 : в < в0, there exists k 1 such that H0 should be 
rejected ifT(X) <k1 and accepted ifT(X) >k1.
Proof: Observe first that condition (b) may require randomization. Indeed, in view of (a) 
and (b), letting y = P{Hо isrejected \T(X) = k}, we must have
a0 = Pe0 {T(X) >k} + yPo0 {T(X) = k}. 
(12.24)
It follows that if Po {T(X) = k} =0, then we have
a0 = Po0{T(X) > k} = Po0{T(X) >k},
and the test is nonrandomized, with critical region C = {x : T(x) > k}. If Po {T (X) >k} < 
a0 < Po0 {T (X) > k}, then by (12.24),
a0 - Pe0 {T(X) >k} 
Y 
P9 0 {T (X) = k} 
■
Clearly, we have 0 <y<1, and an auxiliary randomization with probability of success equal 
to y gives a procedure with size a0 .
Let C* denote the procedure described by the theorem, and its power be 
nC<* (в) = Po{C*leadstorejecting H0}. By condition (b), nC,t (в0) = a0.
Without loss of generality, let в 1 > в0. By the Neyman-Pearson lemma, the most pow­
erful procedure for testing the simple hypothesis H0* : в = в0 against a simple alternative 
H* : в = в 1 is based on the likelihood ratio, and rejects H0 if fn(x; в 1)/fn(x; в0) > k* for 
some k*. But by the monotonicity of the likelihood ratio, the last condition means that 
T(X) >kfor some k. Since the last condition does not depend on the choice of в1, the pro­
cedure C* described in the theorem is UMP for testing the simple hypothesis H0* : в = в0 
against the composite alternative H1 : в>в0 .
We will also show that the power function of procedure C* is nondecreasing. For any 
в' < в" (regardless of their location with respect to в0), we have nC* (в') < nC* (в''). This 
fact will be crucial for completing the proof.
Indeed, consider the class K of all procedures of testing the simple hypothesis H0 : в = в' 
against the simple alternative H1 : в = в'' at a level of significance a, say. We know from the 
Neyman-Person lemma that C* is the most powerful procedure in class K, that is, for any 
C&K,
nC. (в") > nC(в"). 
(12.25)
On the other hand, the (randomized) procedure C0: “reject H* : в = в' with probability a 
regardless of observation” satisfies the condition nCo (в) = a for all в. Clearly, C0 & K. So, 

UNIFORMLY MOST POWERFUL TESTS
401
using (12.25), we write
пС» (в") > nC0 (в”) = a = пС» (в'),
which shows monotonicity of nC, (в).
To complete the proof, we have to show that the procedure C* is UMP not only in the 
class B of all procedures C that satisfy the condition nC (в0) < a0 but also in the class B' of 
all procedures C such that supe<e0nC(в0) < a0.
Clearly, B' G B, and the monotonicity of the power function nC, (в) shows that C* is an 
element of the smaller class B': Indeed, for в < в0,
пс(в) < nC•(в0) < a0.
This completes the proof, since we already know that for every в1 >в0, the procedure C* 
maximizes the power in the larger class B, and hence also maximizes the power in the smaller 
class B'. 
□
PROBLEMS
12.4.1 Check whether the following families of distributions have a monotone likelihood 
ratio: (i) Poisson. (ii) Exponential. (iii) Gamma, for each parameter separately. (iv) 
Beta, for each parameter separately.
12.4.2 Let X1, ...,X16 be a random sample from Laplace distribution with density 
f (x; A) = (X/2) exp{—A|x|},A> 0. Find a UMP test for testing H0 : A = 1 
against H 1 : A < 1 at the significance level 0.01.
12.4.3 Let X 1, ...,Xn be a random sample from a folded normal distribution with den­
sity f (x; в) = д/2/п в exp {—в2 x2 / 2}}, for x > 0, в > 0. (i) Derive the UMP test for 
H0 : в = в0 against H1 : в>в0 . (ii) Show that the power function is increasing.
12.4.4 Suppose that the number of defects in magnetic tape of length t (yards) has POI(At) 
distribution. Assume that 2 defects were found in a piece of tape of length 500 yards. 
(i) Test the hypothesis H0 : A > 0.02 against the alternative H1 : A<0.02.Usea 
UMP test and the significance level a = 0.01. (ii) Find the p-value and interpret. 
(iii) Find the power of the test at A = 0.015.
12.4.5 The effectiveness of a standard drug in treating specific illness is 60%. A new drug 
was tested and found to be effective in 48 out of 70 cases when it was used. Spec­
ify an appropriate alternative hypothesis and perform the test at the 0.01 level of 
significance. Find the p-value.
12.4.6 Suppose that X1 , .. .,Xn is a random sample from the U[0, в] distribution. 
(i) Hypothesis H0 : в < в0 is to be tested against the alternative H1 : в>в0 . Argue 
that the UMP test rejects H0 if Xn:n >c. Find c for в0 =5,n=10, and a = 0.05. 
(ii) If the hypothesis H0 : в > в0 is tested against H1 : в<в0, show that the UMP 
test rejects H0 if Xn:n <c. Find c if в0 =5,n=10, and a = 0.05.
12.4.7 Let X1, ...,Xn be a random sample from the GAM(a, A) distribution. (i) Derive a 
UMP test for the hypothesis H0 : a < a0 against the alternative H1 : a>a0 ifA is 
known. (ii) Derive a UMP test for the hypothesis H0 : A < A0 against the alternative 
H1 : A>A0 if a is known.
12.4.8 Recall Problem 12.3.8. Assume that n =50and that a student with a score at most 
30 will fail. Does there exist a UMP test for the hypothesis H0 : в < 30? If yes, find 
the test; if no, justify your answer.

402
TESTING STATISTICAL HYPOTHESES
12.4.9 Let X 1, ...,Xn be a random sample from the distribution with f(x;в) = 
6x-1 / (в + 1) х,в> 0, x =1, 2, .... Determine a UMP test of the hypothesis 
H0 : в = в0 against the alternative H 1 : в > в0, at significance level a.
12.4.10 A reaction time to a certain stimulus (e.g., time until solving some problem) is mod­
eled as a time of completion of r processes, running one after another in a specified 
order. The times т 1, ... ,тг of completion of these processes are assumed to be iid 
exponential with mean 1 /X .If r = 3 and the observed reaction times of completion 
of these three processes (in seconds) are 15.3, 6.1, 8.5, and 9.0, test the hypothesis 
H0 : X > 0.8 against the alternative H 1 : X < 0.8. Use a = 0.05.
12.5 UNBIASED TESTS
As we already know, there are situations where the UMP tests do not exist. One example may 
be a test of hypothesis H0 : в = в0 against a two-sided alternative H1 : в = в0 (i.e., where 
в0 is not on the boundary of the parameter space 0). Since UMP tests are highly desirable, 
the theoretical efforts became directed toward a reduction of the class of tests. Such reduced 
class might already contain a UMP test.
We present an approach that requires unbiasedness. Consider the problem of testing the 
null hypothesis H0 : в e 00 against the alternative H 1 : в e 01. Let C be a testing proce­
dure with a power function nC (в). Here the parameter space 0 may be multidimensional, 
and one or both of the hypotheses H0 or H1 may be composite.
Definition 12.5.1 The test C of H0 against H1 is called unbiased if
suP пс (в) < inf пс (в) 
ее во 
ее ®x
(12.26) 
□
Since the left-hand side of (12.26) is the size of the test C,wesaythatC is unbiased if its 
power on the alternative hypothesis is never below its size. In particular, if the null hypothesis 
is simple, then the power function of an unbiased test reaches its minimum at в0 .
It turns out that in some cases where there is no UMP test in the class of all tests, there is 
a UMPU test.
■ EXAMPLE 12.21
Consider the case of testing the simple hypothesis H0 : ^ = ^0 against the alternative 
H 1 : ^ = ^ 0, where observations X 1, ...,Xn are a random sample from the N( ^, a 2) 
distribution with known a2. 
__
Intuition suggests that we take T(X) = X - ^0 as the test statistic, and reject H0 if 
either T(X) < -k' or T(X) > k" for some suitably chosen positive numbers k and k". 
To have size equal a0, we must choose k' and k" so that
1 - a о = P^ о {-k < T (X) < k"} = P^ о {-k <X - M о < k"}
= p(-k'^n <Z <k'^\, 
aa
that is,
ф k^n^ - ф --k'^f =1 - a0,
(12.27)
where Ф is the CDF of standard normal random variable.

UNBIASED TESTS
403
Let_us investigate th^power function of the test above. For the critical region 
C = {X < m0 - k'} U {X > m0 + k"}, we have
пс(M) = 1 - P/A-k' < X - M0 < + k"}
= 1 - p Г -k' + M0 - M <z<k" + M о - M1 
(12.28)
o^Jn 
oly/n
_ 1 _ ф ( k" + M 0 - M А, ф (-k' + M 0 - M A
= 1 
alVn + 
\ olVn J'
Clearly, nC (m) is a continuous differentiable function of m, and C is unbiased if
■dd-nC (m) 
= 0. We have, letting p be the density of standard normal random
M , lM=м о
variable,
dnc(m) 
kк" + m0 - m\ 
- -k' + M0 - m\ n™
dM P \ ol ^n 
J o ^ \ 
ol ^П 
J o
For M = M0, we obtain
dnc(M) 
dM
k"
- P
•P
which equals 0 (remembering that k' and k” are positive) only if k' = k”. Thus, we 
obtain an unbiased test only if the two parts of the rejection regions are located sym­
metrically with respect to the null hypothesis value M0. Formula (12.27) gives now 
k' = k" = za о / 2.
One can show that the test obtained in Example 12.21 is actually the UMPU test for 
hypothesis H0 : M = M0 against the two-sided alternative H1 : M = M0 . It is not, however, a 
UMP test against one-sided alternatives (see Figure 12.5).
Figure 12.5 Power functions of a one-sided UMP test (dashed line) and a UMPU test (solid line).
One can argue that such a specific hypothesis like H0 : M = M0 simply cannot be true. 
The chances that the mean is exactly equal to M0 are zero. This is true if the parameter M is 
a random variable, varying from situation to situation according to some continuous prior 
distribution. It is also true in most cases of Bayesian priors, where M does not vary, but the 
statistician’s experience can be expressed in terms of a (subjective) probability distribution 
on M (to be discussed in more detail in Chapter 16).
Thus, the argument goes, H0 should be rejected at once, without any testing. As explained 
at the beginning of this chapter, this conclusion misses the essential intention of the theory of 
hypotheses testing, which is to serve not as a means of establishing the truth of hypotheses, 
but of establishing good rules of inductive behavior. In this sense, “accepting H0 : 6 = 60” 
means simply that it is reasonable to act as if the parameter value were 6 0, even if in fact 6 is 
only close to 60 . This suggests testing a composite null hypothesis stating that 6 lies in some

404
TESTING STATISTICAL HYPOTHESES
interval, against the alternative that it lies outside it. We will illustrate this approach with an 
example:
■ EXAMPLE 12.22
Let again X 1, ... ,Xn be a random sample from the N(p,a) distribution with a2 
known. We want to test the null hypothesis H0 : p 1 < p < p2 against the alternative 
H 1 : p < p 1 or p > p2. To simplify the notation, let
* _ Л 1 + Л 2
p = 
2
(12.29)
denote the midpoint between the boundaries of the null hypothesis. It appears reason­
able to use the test statistic T(X) = X — p*,andreject H0 if T(X) < —k' or T(X) > k", 
where k1, k" are some positive constants. The power of this test (call it C*) is
n C* (p) = 1 — P^{—k' <X — p* < k"}
_ 1 
— —k> + p* — p k k" + p* — p
= 1— 4 V <Z< V
= 1 — Ф (k" + p*— p A + Ф (—k' + p*— p 
a/Vn a/Vn
Again, to have the test unbiased, the power curve must have a minimum at p*, which 
necessitates taking k' = k". Then, the size of the test (see Figure 12.6) equals to the 
common value of the power at the points p 1 and p2, that is, after letting k = k' = k" 
and Д = (p2 — p 1) /2),
sup
Д1 <p<p2
= 1 — Ф
nc*(p) = 1 — ф
— p 1 + k 
a/Vn
Д + k 
a/Vn
Д — k 
a/Vn
+ Ф
If we now require (for given p 1 ,p2, and a, hence given p* and Д) a test with a 
specified size a0 and a specified probability в0 of a type II error at some target value 
pt in the alternative, we can determine the threshold k and sample size n from the 
equations
Д + k 
Д — k\ л
Ф I —| — Ф I —|=1 — a 0
and
* 
p* — pt + k 
a/Vn
* 
p* — pt — k
a/Vn
= в0 .
p 1
p
P 2
Figure 12.6 Power function of an unbiased test.
— Ф

GENERALIZED LIKELIHOOD RATIO TESTS
405
The solution has to be obtained by a numerical procedure. It can be shown that the 
resulting test is UMPU.
PROBLEMS
12.5.1 Suppose that X 1, ... ,Xn is a random sample from the U[0, в] distribution. Test 
hypothesis H0 : в = в0 against the two-sided alternative H 1 : в = в0 using an unbi­
ased test that rejects H0 if Xn:n <c1 or Xn:n >c2 ,c1 <c2 . Find c1 and c2 if в0 = 
5, n = 10, and a = 0.05.
12.5.2 Let X be a single observation from a distribution with density f (x, в)= 
1 — в2(x — 0.5)3 for 0 < x < 1 and zero otherwise, — 1 < в < 1. Find a UMPU test 
of H0 : в = 0 against H1 : в =0.
12.5.3 Let X 1, .. .,Xn be a random sample from the POI( A) distribution. Find the (approx­
imate) UMPU test for the hypothesis H0 : A = A0 against the two-sided alternative 
H 1 : A = A0, where A0 is assumed to be large. [Hint: Use the fact that if X has Poisson 
distribution with mean A, then (X — A) Д/A converges (as A ^ ж) in the distribution 
to a standard normal random variable.]
12.5.4 Assume that X 1, .. .,Xn is a random sample from the N(0, a 2) distribution. For test­
ing hypothesis H0 : a = a2 against the alternative H 1 : a2 = a2 at significance level 
a, find an unbiased test with a critical region of the form “reject H0 if En=1 X? /a2 < 
C 1 or En=1 Xla2 >C2.”
12.5.5 Let X 1, ...,Xn be a random sample from the N( p, a 2) distribution with both 
parameters unknown. Find an unbiased test witha critical region of the form “reject 
H0 if EП=1 (Xi — X)2/a2 <C 1 or EП=1 (Xi - X)2O02 >C2” to test the hypothesis 
H0 : a = a02 against the alternative H1 : a2 = a02 . Use significance level a.
12.5.6 Let X1, ...,XN be a random sample from a multinomial distribution with three pos­
sible outcomes: O1, O2, O3 and their corresponding probabilities: p1, p2, 1 — p1 — p2. 
Obtain a UMPU test of a H0 : p 1 < p2 against the alternative H 1 : p 1 > p2 know­
ing that among N observation, outcomes O1, O2, and O3 were observed n1,n2, and 
N — n1 — n2 times, respectively.
12.6 GENERALIZED LIKELIHOOD RATIO TESTS
As shown by the Neyman-Pearson lemma, analysis of the likelihood ratio is a good way 
of searching for test statistics. It turns out that an extension of the likelihood ratio method, 
originally called the “lambda principle” by Neyman (1950), often leads to tests that per­
form quite well. The role and importance of these tests, called generalized likelihood ratio 
(GLR) tests, can be compared with that of maximum likelihood estimators in the estimation 
problems.
A rather common situation in statistical practice occurs when we are interested in test­
ing hypotheses about a specific parameter, but the population distribution depends also on 
some other parameters. Equivalently, we may say that в = (в 1, ... ,Or) is a multidimensional 
parameter, but we are interested in hypotheses involving one component only. One example 
here is testing a hypothesis about the population mean p in the normal distribution when 
variance a 2 is also unknown.
The parameter (or parameters) that is not constrained by the null hypothesis is called 
a nuisance parameter. The presence of nuisance parameters causes the null and alternative 

406
TESTING STATISTICAL HYPOTHESES
hypotheses to be composite. The GLR tests that will be discussed in this section can also be 
applied to testing in the presence of nuisance parameters.
Suppose that we want to test the null hypothesis H0 : 6 e 00 against the alternative 
H 1 : 6 e 0 \ 00. In most typical cases both hypotheses H0 and H 1 are composite, which 
corresponds to the sets 00 and 01 containing more than one element. In analogy with most 
powerful tests in the case of a simple null hypothesis and a simple alternative (which are 
based on the likelihood ratio), we might use the ratio
v(X) = suP ее Qi fn (X; 6)
suPеево fn(X; 6),
(12.30)
and reject the null hypothesis if the observation x gives a high value of v(x). The ratio here is 
based on the analogy with the likelihood ratio tests given by the Neyman-Pearson lemma: 
if the numerator in (12.30) greatly exceeds the denominator, then x is good evidence for the 
alternative hypothesis. On the other hand, small values of v(x) constitute good evidence for 
the null hypothesis.
An inconvenience with the use of v(x) is that it may be difficult to compute, especially 
because typically only one of the two suprema in v(x) is attained. Consequently, it is often 
easier to use the statistic defined as follows:
Definition 12.6.1 The ratio
A(X) = suPееQo fn (X;6) 
suPеев fn(X; 6)
will be called the GLR statistic.
□
Under some continuity assumptions, if 00 is a closed set, then the suprema in A(x) are 
both attained. In particular, if 60 = 60 (x) is the value of the parameter that maximizes 
fn(X; 6) over the set 00, then the numerator in A(x) becomes fn(X; 60(X)). Similarly, the 
value of 6 that gives the maximum of the denominator is simply the MLE of 6, denoted 
6 = 6(X). Thus, a useful computational formula for A(X) is
A (X) = max ее во fn (X;6) = fn (X; 60) 
maxее в fn (X;6) 
fn (X; 6) '
Clearly, A(X) < 1, since the denominator, being the maximum over a larger set, is at least as 
large as the numerator. Since A(X) does not depend on any parameter values, it is a statistic.
To see how v(X) and A(X) are related, observe that
v (X) < max[sup ее Qi fn (X;6), suP ее во fn (X;6)]
suP ее во fn (X; 6)
fn (X; 6) 
: 1
suPее во fn (X;6) 
A (X);
hence v(X)A(X) < 1. Consequently, large values of v(X) are associated with small values of 
A(X).
It happens sometimes that the distribution of A(X) under H0 does not depend on any 
parameters. In such cases, the a-size critical region is obtained from the condition
P{A(X) < k\H0} = a. 
(12.31)
The rationale here is that small values of A(X) support the alternative: it means that the 
maximum of the likelihood over 00 is much smaller than the overall maximum. Hence, it 
also means that the maximum over 0 is much higher than the maximum over 00.

GENERALIZED LIKELIHOOD RATIO TESTS
407
It may happen that exact test, using (12.31), is not available. However, it can be shown that 
if MLE has an asymptotically normal distribution (which is true under very general regu­
larity conditions), then the limiting distribution of A(X) does not involve any parameters.
We have the following theorem, which we provide without proof:
Theorem 12.6.1 Let X 1, ...,Xn be a random sample from the f (x, в) distribution with 
в = (в 1, ... ,0m). If в & 00, then statistic — 2 log A (X) has an asymptotically chi-square 
distribution with m - r degrees of freedom, where r is the number of components of в 
completely specified by the null hypothesis (r < m). Thus, the approximate а-size test is
reject H0 if - 2log A(X) > xIm-r.
We will now derive some important GLR tests as examples.
■ EXAMPLE 12.23
Let X = (X 1, ..., Xn) be a random sample from the N(d, a2) distribution with d and 
a2 unknown. For testing H0 : d = d0, a arbitrary, the parameter space 0 is the upper 
half-plane, while 00 is the ray {(d, a2) : d = d0}. We now have
f 1 n 
1
f (X; p,a2) = (2na2)-n/2 exp —£ (Xi - d)2 , 
(12.32)
2a2 i=1
and the MLE’s ofd and a2 are
d = x, 
a2 = 1 V (Xi — x )2. 
(12.33)
n i=1
After we substitute in (12.32), the denominator in A(X) becomes:
— 
( 
1 n 
1
max f (X; d, a2) = (2n)-n/2(a2)-n/2 exp —— 
(Xi — d)2
(^,a2)eeJK , 
2a2 
\
= (2ne £ (Xi — X)2/n) -n/2.
It remains to find the numerator in A(X), that is,
max f(X; d, a2) = max f(X; d0, a2)
(v,v 2) e eo 
' 2 > 0 
0
max (2na2) n/2 exp <------7 
(Xi
a2>0 
2a2 
i
— d0)2 .
Here, the maximum is attained at a02 = (1/n) 
(Xi — d0)2 and equals
Consequently,
(£) n/Ъ ( X. — d 0>2]-n/2.
A(X) = (E (x. — d 0)2 A -n/2 = ( E (x. — x )2 + n ( x — d 0)2 \ -n/2
VE (x. — X )J 
£ (X. — X )2 
J
= Л + 
(X — dpf_ \ -n/ 2 = Л +_L_12 A -n/2
< 
(1 /n) E (X. — X)^ 
< n — 
,

408
TESTING STATISTICAL HYPOTHESES
where
t (X) = 
X ^0 
_ Vn—1
(J/nIn) E (Xi X X)2
has a Student’s t distribution with n- 1 degrees of freedom; see formula (9.21). The 
inequality A(X) < k is equivalent to the inequality [t(X) | > k*.
Thus, the critical region of our test is [t (X) | > ta/2,n- 1. One can show (see Lehmann 
and Romano, 2005) that this test is UMPU .
■ EXAMPLE 12.24
Consider the GLR test for the hypotheses H0 : ^ 1 = ^2, a2 = a2 against the alterna­
tive H 1 : /л 1 = /л2, a2 = a2 (a more general case, solved in the same way, is obtained 
when we assume that a2 = YO2, where y is a known constant).
The likelihood, letting a12 = a22 = a2, has the form
f (x, y; p, 1 ,p 2 ,a 2) = (2 na 2) -(m+n)/ 2 e- 1 / 2 ' 2[E (x—1)2+E (y-^ 2)2].
By maximizing the likelihood over all (^ 1 ,^2,a2) and on the subspace (^ 1 = ^2 = 
^, a2), one can derive the GLR. The exact form of the test is given in Section 12.9. We 
omit the details of the calculations, which are similar to those in Example 12.23.
■ EXAMPLE 12.25 Paired Observations
A situation deceptively similar to that in Example 12.24 occurs when we have the data 
obtained by observing the values of some attribute of different elements of the pop­
ulation, observed “before” and “after.” A typical case would be to measure a certain 
reaction in human subjects before (Xi) and after (Yi) some treatment. The purpose is 
to decide whether or not the treatment has an effect. Since we have here the situation of 
two samples, X1, ...,Xn (values “before”) and Y1, ...,Yn (values “after”), we cannot 
apply the method of Example 12.24 for m = n.
Such a procedure would not be correct, since in the present case the values Xi ,Yi are 
not independent (as observations for the same subject). Under the following assump­
tions, however, one can use here a one-sample test: The observations need to be such 
that the differences Ui = Yi - Xi have the same normal distribution with mean ^ and 
variance a2 . Separately, Xi’s and Yi’s do not need to be normally distributed.
We may wish to test the null hypothesis H0 : /л = /л0 against a one- or two-sided 
alternative H 1 : p> ^0 or H 1 : ^ = ^0, a2 arbitrary. In most typical applications, 
we take /л0 = 0 (treatment has no effect). The form of the test is the same as in 
Example 12.24, applied to random variables Ui, and we omit the details.
■ EXAMPLE 12.26
To test the efficiency of sleeping pills, a drug company uses a sample of patients with 
insomnia. The time (in minutes) until falling asleep is observed for each person. A few 
days later, the same patients are given a sleeping pill and the time until falling asleep is 
measured again. Suppose that the data are

GENERALIZED LIKELIHOOD RATIO TESTS
409
Subject
No pill (Xi)
With pill (Yi)
1
65
45
2
35
5
3
80
61
4
40
31
5
50
20
The proper procedure is to treat the data as paired. The differences ui = xi - yi are 
then 20, 20, 19, 9, and 30 and we want to test the hypothesis E(Ui) = 0 against the 
alternative E(Ui) > 0. Since u = 19.6 and sU = (1 /5) (ui - u)2 = 44.24 we have
u ,----- -
t = —5- - 1 = 5.89.
sU
Compared with the quantiles of the Student’s t distribution with 4 degrees of freedom, 
the result has a p-value below 0.005.
However, if we treat the problem as a two-sample problem (which is incorrect), 
we obtain a different conclusion. The procedure is described in Section 12.9, but it 
is worthwhile to explain here why an analysis of the same numerical values can lead 
to two different conclusions, depending whether the values result from paired or 
unpaired data.
In essence, in both cases we are comparing two means, and trying to determine 
whether their difference is so small that it may be explained by chance variation (null 
hypothesis) or that it is large enough to be regarded as “significant.” To make such 
inference, we have to assess the amount of variability, to serve as a base for comparison.
Now the formulas for an estimate of variance are different in case where data are 
paired and in case they are not. In general, the first estimate gives a lower p-value 
simply because “a person is typically more similar to himself than to another person.” 
Thus, quantitatively speaking, the same difference between means can turn out to be 
significant when compared with a smaller variance given by the formula for paired 
data, than when compared with higher variance given by the formula for independent 
samples.
In the present case, we have x = 54, sX = 16.55, y = 32.4, and sY = 19.41, so that
2
x - У
^/5 Sx + 5 Sy
5+5
21.6
57.04 V20 = 1.69,
1 + 5
which, for 8 degrees of freedom, is not significant at the 0.05 level.
We complete this section with a discussion of the problem of reaching a decision before 
the data collection is complete.
■ EXAMPLE 12.27
A research laboratory employs two specialists, Dr. Brown and Dr. Smith. Dr. Brown 
claims that he invented a certain method that is superior to the currently used method 
of Dr. Smith. After some debate, it is decided that Dr. Brown’s method will be tested. 
Five experiments are to be run on five consecutive days, starting Monday, and the 
results X1, ...,X5 recorded.27 It is known that Xi ’s form a random sample from a 
27One may feel that important decisions, like about the superiority ofa scientific method, cannot be decided on the 
basis of only five observations. Of course, if possible, one should use a larger sample size to get a better quality of 
inference. This, however, does not change the essence of the problem.

410
TESTING STATISTICAL HYPOTHESES
normal distribution with an unknown standard deviation. It is also known that for the 
current method of Dr. Smith, the mean is 10, or perhaps less, so Dr. Brown’s method 
will be declared superior if the mean of Xi’s is higher than 10; that is, if the null hypoth­
esis H0 : ^ < 10 (asserting that Dr. Brown’s method is no better than Dr. Smith’s) is 
rejected in favor of the alternative H 1 : p> 10. The significance level, a = 0.01, is 
agreed upon during negotiations.
The observed data for the consecutive 5 weekdays are 14.8, 13.6, 13.9, 10.3, and 
11.4. We have here x = 12.8, and д/(1 /5) 
(xi - x)2 = 1.6769, which gives
t= (12.8 - 10) 
1.6769
V4 = 3.339.
This value is below the critical value t0.01,4 = 3.747, so Dr. Brown’s method is not 
declared to be superior at the significance level 0.01.
Dr. Brown, however, is not someone who easily gives up. He notices that if the 
test were run on Wednesday (after only three observations), we would have x = 14.1, 
and Vх(1 /3) (xi — x)2 = 0.51, hence t = 11.369, which exceeds the critical value 
t0.01,2 = 6.965, so the p-value would be less than 0.01.
The issues involved here are serious. Generally, when the data are collected sequen­
tially, it happens that the conclusion reached on the basis of all data values differs from 
a conclusion that is reached on the basis of some initial sequence of data points. Is 
one then justified in reaching the conclusion that is, for some reason, more convenient 
(e.g., in favor of one’s own preferred hypothesis, and likely to get one an extension of 
a grant)? In particular, can one discard part of the data?
The answer, of course, is negative, not merely because of the moral issues involved. 
It is equally important to realize that with modified or discarded data it may be hard, 
or even impossible, to assess the probabilities involved. To take the example of Dr. 
Brown, to assess the p-value of the result calculated with the use of the first three data 
points, one would have to assess the conditional probability, given the conclusion of 
all five data points, that is,28
28The analysis here is similar (but more complicated) than the ballot problem, studied in Chapter 3. There we 
calculated the probability that in the process of counting votes, the losing candidate will lead at least once during 
the counting. A moment of reflection shows that we have here a very similar situation, except that the “votes” (being 
random variables with values ± 1) are replaced by observations, that may “favor” one or the other hypothesis in 
varying degree.
P{(X 1 ,X2,X3) & Cз|(X 1, ...,X5) /C5},
where C3 and C5 are critical regions for sample sizes n =3and n =5.
Quite apart from the moral and computational issues involved, there exists a theory 
of sequential testing of hypotheses. At each new data point, one of the three decisions 
is made: “accept H0,” “accept H1,” or “take another observation.” The process stops 
on making either of the first two decisions. The criteria for making these decisions are 
chosen in such a way that (1) the probabilities of making wrong decisions (type I and 
type II errors) are bounded by preassigned numbers and (2) the number of observations 
taken (being a random variable) has finite expectation.
This theory was developed originally by A. Wald. The details can be found in many 
advanced textbooks on mathematical statistics.

GENERALIZED LIKELIHOOD RATIO TESTS
411
PROBLEMS
12.6.1 Suppose that we test the null hypothesis that ^ = 100 against the alternative that 
^ = 100. The distribution is normal with its variance unknown. We have just two 
observations, X1 = 105 and X2 = 105 + a. Find a such that the null hypothesis is 
rejected at the significance level a = 0.05?
12.6.2 The following data concerning accidents on various types of highways were obtained 
from the Ohio Department of Transportation, September 1990 (see Al-Ghamdi, 
1991):
Highway 
type
Number of 
accidents
Annual million 
vehicle miles
Accident 
rate
Scenic
3,621
1,021
3.55
Other 2-lane
36,752
11,452
3.21
Multi-lane
20,348
6,920
3.23
Interstate
10,460
9,412
1.11
From the table it appears that the accident rate on interstate highways is significantly 
lower than on other types of highways, and that on the first three types, the accident 
rates are essentially the same. Use the likelihood ratio test to verify those claims.
12.6.3 The times for the diagnosis and repair of a car with a certain type of problem are 
assumed to be normally distributed with mean ^ and standard deviation a = 15 
minutes. A mechanic serviced five cars in one day, and it took him a total of 340 
minutes. (i) Test, at the level a = 0.05, hypothesis H0 : ^ < 60 against the alter­
native H 1 : p> 60. (ii) Suppose that you doubt the information that a = 15, and 
decide to test the hypotheses in (i) without assuming anything about a . If the sum 
of squares of the five diagnose/repair times is m, how small should m be to reject 
H0 at the significance level a = 0.05?
12.6.4 Let X 1, ...,Xn be a random sample from the GAM(3,6) distribution. Derive the 
GLR test for H0 : 6 = 60 against H 1 : 6 = 60.
12.6.5 A random sample of size n was selected from the EXP(6) distribution. Perform the 
GLR test ofH0 : 6 = 2against the alternative H1 : 6 =2ifthe actual observations 
are 0.57, 0.21, 2.18, 0.85, 1.44. Use a = 0.05.
12.6.6 Derive the GLR test for H0 : 6 = 60 against H1 : 6 = 60 based on a random sample 
X1, ...,Xn selected from the BETA(1, 6) distribution. Determine an approximate 
critical value for a size a.
12.6.7 Two independent samples X1 , .. .,Xm and Y1 , .. .,Xn were selected from the 
EXP(61) and EXP(62) distributions, respectively. (i) Derive the GLR test of 
size 0.05 for H0 : 61 = 62 against H1 : 61 = 62. (ii) Perform the test at 0.05 
significance level based on observations of X : 0.81, 1.33, 2.10, 0.67, 0.23, 1.85, and 
Y : 0.04, 5.56, 1.92, 0.12, 0.94, 1.56, 2.31, 0.41.
12.6.8 Let X1 , .. .,Xm and Y1 , .. .,Xn be two independent random samples 
selected from distributions with P(X = x) = p1(1 - p1)x,x = 0, 1, ... and 
P (Y = y)=p2 (1 - p2 )y ,y =0, 1, . . . , respectively. Test H0 : p1 = p2 against 
H1 : p1 = p2 at 0.1 significance level. Assume that m =5,n=10and the actual 
data values are: 1, 0, 3, 5, 1 and 4, 2, 1, 1, 3, 7, 5, 3, 4, 0.

412
TESTING STATISTICAL HYPOTHESES
12.6.9 A survey on a proportion of population using a certain product was conducted in 
four different cities, in each 200 people were interviewed. Test the hypothesis that 
the proportion of users of the product is the same in each city if the numbers of 
people using the product were 34, 52, 41, 45, respectively. Use a = 0.10.
12.7 CONDITIONAL TESTS
As explained in the previous section, the parameter (or parameters) that are not constrained 
by the null hypothesis are called nuisance parameters. Besides the likelihood ratio tests, for 
testing in the presence of nuisance parameters one can use conditional tests.
Suppose that the distribution of X depends on a parameter 6 = (n, т), where n is the 
parameter tested and т is the nuisance parameter. Assume that we want to test the null 
hypothesis that n = n0 against the alternative that n<n0 . These are in fact composite 
hypotheses:
H0 : n = n0 ,т arbitrary against 
H1 : n<n0 ,т arbitrary.
It may happen that there exists a sufficient statistic, T, for т. In such a case, the conditional 
distribution of X given T = t does not depend on т, and it may then happen that one can 
find a test on a given level a for H0 (for each t separately).
We will first illustrate such a situation by an example.
■ EXAMPLE 12.28
Let X and Y be independent binomial random variables: X ~ BIN(n 1 ,p 1) and Y ~ 
BIN(n2 , p2). We want to test the hypothesis that p1 = p2 against one- or two-sided 
alternative. If the null hypothesis is true, then letting p = p1 = p2, we have
P{X=x|X+Y= k}= P {X = x,X + Y = k} 
P {X + Y = k}
P{X = x}P{Y = k - x} 
P {X + Y = k}
n1 pxqn1-x 
n2 pk-xqn2 -k+x
x p q 
k-x p q
(n 1+ 22 ) pkqni+ n2 — k
("1 ) (k^x '
( 11 +" 2 ) 
,
(12.34)
which is independent of the nuisance parameter p.
The question is which values of X (given X + Y = k) constitute the strongest evi­
dence against the null hypothesis, and how should one assess the p-value of the result. 
Here the argument is as follows: We can expect X/n1 to be close to p1 and Y/n2 = 
(k — X)/n2 to be close to p2. So, if H0 is true, we can expect X/n 1 « k/n2 — X/n2. 
For the two-sided alternative, the “worst” cases are where X is close to 0 or close to k
so that the critical region comprise two tails of the hypergeometric distribution (12.34).
Letting
u(j)=u(j;n1,n2,k)=
("1+"2) 
,

CONDITIONAL TESTS
413
we may define the p-value of the result X = x for two-sided test as
2min 
u(j), 
u(j)
j<X 
j>X
(12.35)
This is the Fisher’s exact test, which will be discussed in more detail in Chapter 15.
■ EXAMPLE 12.29
Let X and Y be independent observations of two Poisson random variables, with 
parameters A 1 and A2, respectively. We want to test the hypothesis H0 : A2 = 6A 1 
against the alternative H 1 : A2 > 6A 1, where 6 > 0 is some fixed constant. For 
instance, if 6 = 1, we have the hypothesis of equality of parameters in two Poisson 
distributions.
The joint distribution of (X, Y ) is here
f (x,y; A 1 ,A2) = 
x &e-(л 1+ л2)
x! 
y!
1
x!y
. A\ ) (A 1 + A2)x+ee-(x 1+л2).
A1 + A2
This suggests reparametrization with n = A2/A 1 and т = A 1 + A2, leading to the joint 
probability function
f x + y \( 1 A x ( n А т тx+y 
f (x, y; n, т) = 
e
\ x 1 + n 1 + П 
(x + У)!
(12.36)
It is now clear that T = X + Y is a sufficient statistic for т, and that given T = t, the 
random variable X has the conditional distribution that is binomial with parameters 
t and 1/(1 + n). Under the null hypothesis, we have n = 6, while under the alternative 
hypothesis, n>6.GivenT = t, we may therefore test the null hypothesis H0 : p = 
1/(1 + 6) against the alternative H1 : p<1/(1 + 6), observing the random variable 
X with the BIN(t, p) distribution.
■ EXAMPLE 12.30
Suppose that traffic engineers suggest a certain change of a traffic light sequence to
reduce the number of accidents at some type of intersections. Two intersections, far
apart to ensure independence but otherwise identical in all aspect (traffic intensity, 
road condition, etc.) are to be tested. Over a certain time, the number X of accidents
at the intersection with the new traffic light pattern is 7. During the same time, the
number of accidents at the intersection with a previous traffic light pattern is Y =13. 
At the significance level a = 0.05, does this indicate that the new traffic light pattern
decreases the probability of an accident?
We want to test the hypothesis that A1 = A2 against the alternative A1 <A2 (so that 
6 =1 and 1 /(1 + 6) = 1 /2). Sincet = x + y = 7+13 = 20andX ~BIN(20, 1 /2),the
p value is
7
P{X < 7} = Ef 20 ) 
j 
j=0 
j
20
2
= 0.1310.
A 1 A x
A 1 + A 2/
The answer is clearly negative. If the new traffic lights pattern does not affect the prob­
ability of accident at all, the outcome as obtained (13 against 7), or more extreme, has 
more than 13% chance of occurring.

414
TESTING STATISTICAL HYPOTHESES
The scheme above is an application of the following theorem:
Theorem 12.7.1 Suppose that the random sample X =(X1 , ...,Xn) has a joint distribution 
of the form
{
r
nu (x) + 52 Tj Vj (x) 
(12.37)
j=1 

for some functions a, b, u, V1, ...,Vr. Let U = u(X), and let V = (V1, ...,Vr), where 
Vj = Vj (X) for j =1, ...,r. Then for each n, variables V1, ...,Vr are jointly sufficient for 
(T1 , ...,Tr ), and the conditional distribution of U given V (x)=v depends on n but not on 
( t 1, ... ,Tr). A test with size a for testing H0 : n < П 0 against H 1 : n > n 0 is obtained by 
rejecting H0 if U (x) > q (v), where P {U > q (v) | v} = a for n = n 0.
For testing H0 : n > n0 against H 1 : n < n0 the directions of inequalities will be reversed; 
a two-tailed test is to be used in case of two-sided hypothesis H0 : n = n0 against H1 : n = n0.
Lehmann and Romano (2005) show that under some regularity conditions these tests 
are UMPU.
■ EXAMPLE 12.31
To see how the situation of Example 12.29 falls under the scheme of Theorem 12.7.1, 
observe that the distribution of X = (X1, X2) can be reduced to the form (12.37) with 
r = 1, U(X) = X 1, V(X) = X 1 + X2. This is obtained as follows: Take s = X2/X 1 ,t = 
X 1 + X2; hence X 1 = t/(1 + s), X2 = st/(1 + s)). The distribution
f (x 1 ,x2; X 1 , X2) = -LXX1 e-1 x ±XX2e-2 
x1 ! 
x2 !
reduces, after some algebra, to the form
f =( V(x)) V(x)! e t exp{ U(x)ln 1 + V(x) log t + log
s
1 + s
Introducing new parameters n = log(1/s) = log(X1/X2) and T = logt + log s/(1 + 
s) = log X2, and then expressing t in terms ofT and n, we obtain a density in the form 
(12.37).
PROBLEMS
12.7.1 Suppose that in a group of 10 randomly sampled Democrats only 2 favor a cer­
tain issue, whereas in a sample of 12 Republicans the same issue is favored by 5 
persons. At the level a = 0.05, does this result indicate that the fractions pD and pR 
of Democrats and Republicans favoring the issue in question are different? Find the 
p-value by carrying out the two-sided Fisher’s test.
12.7.2 A company A that produces batteries claims that their product lasts “at least 50% 
longer” than the batteries produced by company B . To test the claim, batteries A 
and B are used one after another in two analogue devices. That is, one device has a 
battery A installed and is left running until the battery becomes dead. It is then imme­
diately replaced by another battery A, and so on. The second device runs parallel on 
batteries B.

TESTS AND CONFIDENCE INTERVALS
415
Assume that the lifetimes of the batteries are exponential random variables, with 
densities XAe -'A and XBe-xBt. Suppose that in some time (e.g., a week) batteries A 
had to be replaced 5 times, whereas batteries B had to be replaced 9 times. Test the 
advertising claim by determining the p-value of the result. (Hint: If interarrival times 
are exponential, the process is Poisson.)
12.8 TESTS AND CONFIDENCE INTERVALS
In this section, we will briefly explain how the theory of testing statistical hypotheses is related 
to the theory of confidence intervals, discussed in Chapter 11. This connection was noticed 
by Neyman (who laid the foundations to both theories) as early as in 1938. To simplify the 
presentation, assume that X 1, ..., Xn is a random sample from a distribution f (x; 6), and 
that 6 is a one-dimensional parameter.
A confidence interval (with confidence level 1 - a) is a random interval [L, U] = 
[L(X), U(X)] such that for every 6 & 0,
Pe{L(X) < 6 < U(X)} =1 - a. 
(12.38)
Suppose that we want to test hypothesis H0 : 6 = 60 against the alternative H1 : 6 = 60 . 
The equivalence of tests and confidence intervals is based on the fact that ifwe can construct 
confidence interval (12.38), then we can also construct an a-level test ofH0 against H1, and 
conversely: given a testing procedure of level a, we can construct a confidence interval.
Indeed, condition (12.38) for 6 = 60 allows us to define the set
A = {x = (x1, ...,xn):L(x) < 60 < U (x)}.
Clearly, if we take the set A as the acceptance region of H0 (equivalently, we let C = Ac to 
be the critical region for H0), we obtain a test with level a:
P{H0 isrejected |H0 istrue } = P{60 &/ [L(X), U(X)]|6 = 60} = a.
Conversely, suppose that for every 6' we can construct an a-level test of the hypothesis 
H0 : 6 = 60. This means that for every 6' we have a critical region C&, such that
P {X /Ce, |6 = 6} = 1 - a. 
(12.39)
Define now, for every x,
B(x) = {6' : x / Ce,}. 
(12.40)
When x is the observed value of random vector X, we obtain a random set B(X). From 
(12.39) and (12.40) it follows that Pe{6 & B(X)} = 1 - a, which means that B(X) is a con­
fidence set for 6 with confidence level 1 - a.
Except for the fact that the second part of the argument provides us with confidence sets 
(not necessarily intervals), the argument shows that the two theories are essentially equiva­
lent, at least in case of one-dimensional parameters.
The main results of the theory combine optimality properties of tests and confidence inter­
vals. For instance, confidence intervals (sets) associated with UMP tests have the property 
of being the shortest possible (uniformly most accurate, or UMA confidence intervals). It 
is worth mentioning here that the theory extends also to the case of testing in presence of 
nuisance parameters, but we will not go into the details here.

416
TESTING STATISTICAL HYPOTHESES
12.9 REVIEW OF TESTS FOR NORMAL DISTRIBUTIONS
We now review the major testing procedures for parameters of normal distributions. This 
section is intended as a convenient reference for users rather than an exposition of new con­
cepts or results. If the derivations were given in the other sections, we refer to them. In other 
cases, we omit the derivations, specifying only the properties of the tests, possibly with indi­
cations of the proofs.
In all tests below, a is the significance level and 1 - в is the power, zp is the upper pth 
quantile of standard normal random variable Z, so that
P{Z > zp} = 1 - ф(zp) = P.
Similarly, t pv is the upper pth quantile of the Student’s t distribution with v degrees of free­
dom, xp,v is the upper pth quantile of the chi-square distribution with v degrees of freedom, 
and Fpv denotes an upper pth quantile of the F distribution with v 1 and v2 degrees of 
freedom.
One-Sample Procedures
Let X 1, ...,Xn be a random sample from distribution N( p, a 2).
Hypotheses About the Mean, Variance Known
The sufficient statistic is 
П=1 Xi, hence also X.
• Hypotheses:
One-sided alternatives:
(i) H0 : p = p0 (or p < p0) vs. H 1 : p > p0.
(ii) H0 : p = p0 (or p > p0) vs. H 1 : p < p0.
Two-sided alternatives:
(iii) Hо : p = pо vs. H 1 : p = po.
(iv) H0 : p 1 < p < p2 vs. H 1 : p < p 1or p > p2.
em Other cases:
(v) H0 : p < p1or p > p2 vs. H1 : p1 <p<p2 .
• Test statistics^
(i)-(iii) T1 = x-n •
(iv), (v) T2 = X-n, where p* = ^2.
• Corresponding critical regions, reject H0 if:
(i) T1 > za, (ii) T1 < z 1 — a, (iii) IT1I > za/2, (iv) IT2 I > ka,
(v) IT21 < va, where ka and va are determined from
/ Д 
Д \
M,a/^n + ka) - M,a/^n - ka) = 1- a 
and
Д \ ^( д A
Ф V a/^n + va) Ф I, a/^n 
va) = a,
with Д = (p2 - p 1) /2. Tests (i), (ii), and (v) are UMP tests; (iii) and (iv) are UMPU tests.
• Power:
(i) 
П (p) = 1 - ф( ^^^ + zO}
a/ n

REVIEW OF TESTS FOR NORMAL DISTRIBUTIONS
417
(ii) 
П ( ) ) 1 ф ^^п 
ZJ)
(Ш) П ( . ) = 1 “ $ ( l/Q. + Za/ 2) + $ ^1^/. Z Za/ 2)
(iv) n(.) = 1 - ф(^. + кЛ +ф(£—± - k\
1/ n 
1/ n
L* — LI 
LL* — LL 
\
(v) n (I1) = 1 — ф I —+ v^ 1 ф —— v^ • 
а/y/n 
tj^n 
)
• Sample size determination:
Wanted: sample size n giving power at least 1 — в at L
(i) (ii) — > (z 1 -a+z1 -в)2 а2
(i), (ii) — > (0)2 j
(iii) Solve numerically for n,
Ф ( . 0 а . ^n + z 1 -a/2 — ф ( L 0 а L jn — z 1 -a/2^ = :.
(iv) Solve numerically for n,
( .* — . , 
\ 
/. 0 — . г i\ a
ф ---------n+ + ka — Ф --------- n— — ka = в^
jj
(v) Solve numerically for n,
(.* —. A 
(.0— 
A n
-------- —+ + va — ф —------ —— — va = в^
jj
■ EXAMPLE 12.32 Generic Problem
All philogaps presently on the market have an average concentration of muzzz of at 
least 3.7 mg per philogap. A company claims to have discovered a new method of pro­
duction that will decrease the average muzzz content to the level below 3.7 mg. To test 
this claim, the muzzz content of 15 philogaps of this company are analyzed, and their 
average muzzz content is found to be 3.52 mg.
It is known that the standard deviation of the muzzz content in a philogap does 
not depend on the production process and equals 0.35 mg. It is also known that the 
muzzz content is normally distributed. At the significance level a = 0 • 01, does this 
finding indicate that the new production process decreases the concentration of muzzz 
in philogaps?
Remark You are probably curious about what are philogaps and what is muzzz 
(spelled with triple z). These words, to our best knowledge, mean nothing. If you so 
wish, substitute “objects” and “attribute A,” or “cars” and “miles per gallon,” “beer” 
and “alcohol content,” “oranges” and “sugar content of juice,” and so on, and change 
numbers and possibly, inequality directions accordingly.
We set up this problem as being of type (ii): The null hypothesis is H0 : . > 3• 7 
and the alternative is H 1 : . < 3• 7. The value of the test statistic T1 is t = [(3• 52 — 
3• 7)/0• 35^/15 = — 1 • 99. The 1% quantile of the standard normal distribution is — 2• 33, 
so the null hypothesis is not rejected. The average 3.52 or less in a sample of 15 is more 
likely than 0.01, if the mean is in fact 3.7. Therefore, the null hypothesis cannot be 
rejected at the significance level 0.01. The p-value is equal to P(Z < — 1 • 99) = 0•0233, 
or about 2.3%.

418
TESTING STATISTICAL HYPOTHESES
Suppose that we want not only the 1% level of significance but also at least 95% 
chance of detecting the improvement of the average muzzz content in philogaps by 
0.15 mg. In statistical terms, this means that we want the power to be at least 0.95 at 
^ = 3.7 - 0.15 = 3.55. Then, we need to take the sample of at least
( z 0.01 + z 0.05)2 
(3.7 - 3.55)2 (0.35)2
(2.33+ 1.96)2 
(0.15)2
(0.35)2 = 100.2,
meaning that n should be at least 101.
■ EXAMPLE 12.33
A food-packing company purchased a new machine to fill plastic containers with 
sour cream. The nominal weight, as listed on the container, is 8 oz. The dial on the 
machine can be set on average weight ...,7.98, 8.00, 8.02, 8.04, ... oz. When it is set 
on 8.00 oz (say), it puts into successive containers the amounts X1, X2, ..., which 
are normally distributed with some mean ^ and standard deviation (the same for all 
settings of the dial) a = 0.005 oz. This standard deviation reflects the unavoidable 
container-to-container variability of the amounts of sour cream about their mean /л. 
Naturally, it is impossible to build a machine that gives the average ^ exactly equal to 
the setting on the dial, be it 7.995, 8.002, and so on.
A consumer protection agency may disregard the instances where the variability will 
occasionally lead to a container with more than the nominal amount of sour cream. 
However, it might strongly object if the average ^ is even slightly less than 8 oz, as this 
constitutes a systematic theft from society. On the other hand, if ^ exceeds the nominal 
weight even slightly, it may in time constitute a sizable free gift of the company to 
society.
The company decides that it will risk getting into trouble with the consumer protec­
tion agency, or absorb the loss, if the mean p, satisfies the inequality 7.995 < p, < 8.015 
but wants to avoid both lower /л and higher /л. Careful measurements of 50 containers 
with sour cream give the average x = 8.017.
We are now in situation (iv) where the null hypothesis states that ^ lies between 
some bounds, and we may proceed as follows: We have here /л1 = 7.995 and 
^2 = 8.015, so p* = 8.005 oz and Д = 0.01. Consequently, the observed value of T2 is 
t2 = [(8.017 - 8.005)/0.005]V50 = 16.97. On the other hand, (Д/a)у/П = 14.142, 
and the equation
Ф(14.142 + ka) - Ф(14. 142 - ka) = 1 - a
reduces to Ф(14.142 - ka) = a. For a = 0.01 we must have 14.142 - ka = -2.33; 
hence, ka = 16.472. The observed value 16.97 exceeds ka, and this indicates that the 
null hypothesis should be rejected at the level 0.01.
The conclusion is that p, < 7.995 or p, > 8.015 despite the fact that the result
x = 8.017 suggests that the second of the two inequalities holds. The point is that the
null hypothesis states that 7.995 < p, < 8.015, and its rejection is logically equivalent
to the pair of inequalities.
To conclude that ^ > 8.015, we should test the null hypothesis ^ < 8.015. The test
statistic is then
t1 =
8.017 - 8.015
0.005
^/50 = 2.82,
with a corresponding p-value of about 0.0025.

REVIEW OF TESTS FOR NORMAL DISTRIBUTIONS
419
Hypotheses About the Mean, Variance Unknown
The jointly sufficient statistics are 
Xi and 
Xi2, or equivalently X and 
(Xi - X)2.
• Hypotheses:
One-sided alternative:
(i) H0 : p = pо, a > 0 (or H0 : p < p0, a > 0 ) vs. H 1 : p > p0, a > 0.
(ii) H0 : p = p0, a > 0 (or H0 : p > p0, a > 0) vs. H 1 : p < p0, a > 0. Two-sided alter­
native:
(iii) H0 : p = p0,a > 0 vs. H1 : p = p0,a > 0.
• Test statistic: 
_
t 
X — p 0^= ^--1.
У1 E n=1 (Xi — x )2
Remark Many tests use the notation t = [(X — p0)/S]Vn - 1 or t = [(X — p0)/S]^n. 
These may be confusing, since one has to bear in mind that in the first case S2 is the MLE 
of a2; that is, S2 = (1 /n) 
(Xi — X)2^In the second case, S2 is the unbiased estimator
of variance: S2 = [1 /(n — 1)] 
(Xi — X)2. The notation for S2 is not standardized across
statistical textbooks and papers.
• Corresponding critical regions, reject H0 if:
(i) t > ta,n-1.
(ii) t < —ta,n-1.
(iii) 
\t\ > ta/2,n- 1.
For each of these tests the power is the function n depending on a two-dimensional vari­
able (p, a2). We have n (p 0 ,a2) = a for all a2. However, for p = p 0, the values n (p, a2) 
depend on (unknown) a2, and are given by the noncentral Student distribution. Therefore, 
the sample size determination requires some additional information about a2 (a two-stage 
procedure, etc.). All three tests are UMPU29 tests.
■ EXAMPLE 12.34
A certain make of cars is advertised as attaining gas mileage of at least 32 miles per 
gallon. Twelve independent tests gave the results 33, 28, 31, 28, 26, 30, 31, 28, 27, 33, 
35, 29 miles per gallon. What can one say about the advertisements in light of these 
data?
Let us make the assumption that the observed mileages are normally dis­
tributed. We may then set the problem of evaluation of the advertising claim as 
that of testing the hypothesis H0 : p > 32 (claim is true) against the alternative 
H 1 : p < 32 (claim is false). We have here n =12, xi = 359, x2 = 10,823. Thus 
x = 29.92, (xi — x)2 = 82.92, so t = — 2.62. Since the critical values for 11 degrees 
of freedom are t0.025,11 = 2.201 and t0.01,11 = 2.718, the result is not significant at the 
0.01 level but significant at the 0.025 level. In other words, the p-value is between 0.01 
and 0.025.
Hypotheses About the Variance, Mean Known
The sufficient statistic is 
(Xi — p)2. The sample size can be 1.
• Hypotheses:
One-sided alternative:
29As mentioned before, two-sided UMP tests may not exist. Nevertheless, they can often be found in some restricted 
classes of tests, for example, in the class of unbiased tests.

420
TESTING STATISTICAL HYPOTHESES
(i) H0 : a2 = a2 (or H2 : a2 < a2 vs. H 1 : a2 > a2.
(ii) H2 : a2 = a2 (or H2 : a2 > a2) vs. H 1 : a2 < a2.
Two-sided alternative:
(iii) H2 : a2 = a22 vs. H1 : a2 = a22 .
• Test statistic:
n
U = E (Xi — M)2/a2•
i=1
• Corresponding critical regions, reject H2 if:
(i) U < x n
(ii) U > X1 -a,n.
(iii) U < X2 —a/2,nor U > XI/2,n.
• Power:
n (a2) = 1 - в (a2) = P 2 {U < X 2a,n} = P- 2 { E (Xi - M )2 < X In ) 
a2
_P E( Xi — M )2~2 Дп) 
П .2 X0n
Pa2 ) 
2 
< a 2 
2 F n a 0 
2
2 
a2 
a2
a2
Calculations for remaining cases are similar.
Tests (i) and (ii) are UMP. Test (iii) is asymptotically (for n ^ ж) UMPU. A UMPU 
test in case (iii) is obtained if the thresholds are equal to the endpoints of the shortest (1 - 
a)-level confidence interval for a2 (see Section 11.7).
Hypotheses About the Variance, Mean Unknown
Jointly sufficient statistics are X and 
(Xi - X)2. Tests require n > 2.
• Hypotheses:
One-sided alternative:
(i) H2 : a2 = a2 (or H2 : a2 < a2) vs. H 1 : a2 > a2; m € R.
(ii) H2 : a2 = a2 (or H2 : a2 > a2) vs. H 1 : a2 < a2; m € R.
Two-sided alternative:
(iii) H2 : a2 = a2 vs. H 1 : a2 = a2; m € R.
• Test statistic:
n
V = E( Xi — X )2/a 2.
i=1
• Corresponding critical regions, reject H2 if:
(i) V > X2a,n- 1.
(ii) V<X2-a,n- 1.
(iii) V <X2-a/2,n- 1or V >XI/2,n- 1 •
• Power:
n(m, a2) = P^a2 {H2 isrejected} is obtained in the same way as in the case above.
Test (i) is unbiased. Tests (ii) and (iii) are not UMPU.

REVIEW OF TESTS FOR NORMAL DISTRIBUTIONS
421
The following example was taken from Larsen and Marx (1986):
■ EXAMPLE 12.35
The A above middle C is the note given to an orchestra, usually by the oboe, for tuning 
purposes. Its pitch is defined to be the sound of a tuning fork vibrating at 440 hertz 
(Hz). No tuning fork, of course, will always vibrate at exactly 440 Hz; rather, the pitch, 
Y, is a random variable. Suppose that Y is normally distributed with м = 440 Hz and 
variance a2 (here the parameter a2 is a measure of quality of the tuning fork). With the 
standard manufacturing process, a2 = 1.1. A new production technique has just been 
suggested, however, and its proponents claim it will yield values of a2 significantly less 
than 1.1. To test the claim, six tuning forks are made according to the new procedure. 
The resulting vibration frequencies are 440.8, 440.3, 439.2, 439.8, 440.6, and 441.1 Hz.
We will test the hypothesis H0 : a2 =1.1 against the alternative H1 : a2 < 1.1, 
at the significance level a = 0.05. First, we accept as the fact that the new produc­
tion process gives the mean м = 440. Then u = (xi — 440)2/1.1 = 1.62. The value 
X0.05,6 = 1.635, so there is evidence in the data (at a = 0.05 significance level) that in 
the new production process the variance is less than 1.1.
Suppose that we have some doubts about whether or not м = 440. We can then use 
the method for unknown м .Now v = 2.219 ,x 2.05 5 = 1■145, and the conclusion is now 
different—the claim is not supported by the evidence in the data.
Two-Sample Procedures
Two independent random samples X1 , . ..,Xm and Y1 , . ..,Ym are selected from distribu­
tions N(м 1, a2) and N(м2, a2), respectively.
Hypotheses About the Means, Variances Known
Jointly sufficient statistics are m== 1 Xi and i=1 Yi, or X, and Y.
• Hypotheses:
One-sided alternative:
(i) Hо : M 1 = M2 (or Hо : м 1 < M2) vs. H 1 : M 1 > M2.
Two-sided alternative:
(ii) H0 : M1 = M2 vs. H1 : M1 = M2 .
Remark The opposite inequality in (i) reduces to changing the role of Xi’s and Yj ’s. The 
apparently more general hypotheses of the form м 1 = M2 - A, reduce to the ones above by 
subtracting constant A from all Yj’s.
• Test statistic: 
_  _
a12/m + a22/n
.
• Corresponding critical regions, reject H0 if:
(i) U > Za.
(ii) 
IU| > Za/2.
• Power:
(i) n(M 1, M2) = 1 - e(A) = 1 - ф za+ + A/Va2m + a2

422
TESTING STATISTICAL HYPOTHESES
(ii) п(MI, M2) = 1 - в(А) = 1 - ф zaa22 + А/ V0/т + 02/п) 
+ Ф —-а/22 + А/ 02/т + ст2/n ,
where M2 - M1 =А.
Tests (i) is UMP; test (ii) is UMPU.
Hypotheses About the Means, Variances Unknown, but a2 = Ya 1
Jointly sufficient statistics are X, Y, and E (Xi - X)2 + 1 E (Yj - Y)2.
• Hypotheses:
One-sided alternative:
(i) Hо : Mi = M2 (or Hо : Mi < M2) vs. H1 : Mi > M2; 0 > 0.
Two-sided alternative:
(ii) H0 : M1 = M2, vs. H1 : M1, = M2; 02 > 0.
Remark The opposite inequality in (i) reduces to changing the role of Xi ’s and Yj ’s. The 
apparently more general hypotheses of the form M1 = M2 +А, reduce to the ones above 
by adding a constant А to all Yj ’s.
• Test statistic:
X - 
X - Y 
Im + n - 2
~ 
(Xi - X)2 + 1E (Yj - Y)4 1 /m + Y/n'
Remark 7 = 1 if 02 = 0 2.
• Corresponding critical regions, reject H0 if:
(i) U > ta,m+n—2.
(ii) 
\U | > ta/2 ,m+n—2 .
• Power depends on M1, M2, 012 , and it is expressed through noncentral Student’s t distribu­
tion. Tests (i) and (ii) are UMPU.
Hypotheses About the Variances, Means Unknown
Jointly sufficient statistics are X, Y, E (Xi - X)2, and E (Yj - Y)2.
Hypotheses:
One-sided alternative:
(i) H0 : 02 = Y°2 (or H0 : 02 < Y°i) vs. H1 : 02 > Yo1; M1 ^ R, M2 e R.
Two-sided alternative:
(ii) H0 : 02 = Y°2 vs. H1 : 02 = Y°2; M1 ^ R, M2 ^ R.
Remark y =1if the hypothesis asserts equality of variances.
Test statistic: 
_
F = E (Yi - Y)2/Y (n - 1) 
E (Xj - X)2/(m - 1)
• Corresponding critical regions, reject H0 if:
(i) F > Fan— 1 ,m— 1.
(ii) F < F1 — a/2,n— 1 ,m— 1 = 1 /Fa/2,m— 1 ,n— 1or F > Fa/2,n— 1 ,m— 1 •
Tests (i) and (ii) are UMPU.

REVIEW OF TESTS FOR NORMAL DISTRIBUTIONS
423
Hypotheses About the Variances; One or Both Means Known
Jointly sufficient statistics are X,Y, E (Xi - X>2, E (Yj - Y>2. Whenever a mean is 
known, it replaces the sample average in ratio F, and the divisor (and number of degrees of 
freedom) changes into m (respectively, n). For instance, suppose that both m 1 and m2 are 
known. Then we test H0 : a2 = 02 vs. H 1 : a2 > a2. The testing variable is
p 
E (Y3 - M2)2/n
F = E (xi - m 1>2/m
and the null hypothesis is rejected if F > Fa,n,m.
Large Sample Tests for Binomial Distribution
If X has a BIN(n, p) distribution, then for n large, one can use either the Poisson approx­
imation theorem or the central limit theorem to obtain testing procedures for hypotheses 
about p. Thus, if n is large, but np is small, then asymptotically X ~ POI(np). The hypoth­
esis H0 : p = p0 corresponds to H0 : A = np0 in the Poisson distribution. We can use tests 
for this distribution.
If neither np nor n(1 - p) is small, then we have X/n ~N(p,p(1 - p)/n). To test the 
hypothesis H0 : p = p0 (against a one- or two-sided alternative), we use the fact that under 
H0, the distribution of the random variable
Z = 
X/n - p0
pP 0(1 - p 0) /n
is asymptotically standard normal.
For two sample situations, let X ~ BIN(n 1 ,p 1), Y ~ BIN(n2,p2), where n 1 and n2 are 
both large, and assume that we can use normal approximation. Then we have
X - Y ~ N p1 1 - p2 P 1(1 - p 1) + p2(1 - p2>
n1 
n2 
1 
2 n1 
n2
Thus under the null hypothesis H0 : p1 = p2 , we have, letting p1 = p2 = p,
X/n 1 - Y/n 4
Vp(1 - p>(1 /n 1 + 1 /n2>
~ N(0, 1>.
This statistic still involves the nuisance parameter p. However, under H0 the MLE of p is 
(X + Y>/(n1 + n2 >, so we can use the test statistic
X _ Y 
n 1 
n 2
Z=
X+Y
П1+ П 2
,
+
n1 
n2
which is asymptotically standard normal. Whether we use the one- or two-sided test depends 
on the alternative hypothesis.
■ EXAMPLE 12.36
In primary elections, 28% of the Republicans in New Hampshire voted for candidate 
A. A poll of 180 Republicans in Iowa show that 41 of them will vote for candidate A. 
Does this result indicate that the Republican support of candidate A is lower in Iowa 
than in New Hampshire?

424
TESTING STATISTICAL HYPOTHESES
SOLUTION. We have here p0 = 0.28, the known level of support for candidate A in 
New Hampshire, and we want to test the hypothesis H0 : p > 0.28 against the alterna­
tive H1 : p < 0.28, where p is the fraction of Republican voters who support candidate 
A in Iowa. The observed value of test statistic is
4 
41 /180 - 0.28
= ^(0.28 x 0.72)/180
-1.58,
which corresponds to the p-value 0.059.
■ EXAMPLE 12.37
Continuing Example 12.36, assume that 110 of the 180 persons polled were women, 
and 20 of them (as well as 21 of 70 men polled) said they would vote for the candidate 
A. Does this result indicate that the support for candidate A in Iowa is higher among 
men then among women?
SOLUTION. We now want to test the hypothesis pW = pM against the alternative 
pW <pM . The value of the test statistic is
z=
21 _ 20 
 
70 
110 
 
/ 41 1__41 
1 + T\
18 180 
180 
110 + 70/
= 1.84.
The p-value here is about 0.033, and this may serve as an indication that indeed, the 
support for A among Republican women is lower than among Republican men.
12.10 MONTE CARLO, BOOTSTRAP, AND PERMUTATION TESTS
The tests introduced so far were based either on the known distribution of a test statistic or 
on its asymptotic form applicable when the sample size is large enough. There are, however, 
problems in which the distribution of the statistic is either unknown or difficult to handle 
theoretically, or the sample is not large enough to use the asymptotic properties of a test 
statistic. In all such cases, one could apply powerful computer-intensive statistical procedures 
that recently became readily available with advances of computer technology.
■ EXAMPLE 12.38
Assume that X1 , ...,Xn is a random sample from the Laplace distribution with a 
density f (x; p, X) = (X/2) exp{ —X|x — p]}, and A is known. If we want to test the 
hypothesis H0 : p = 0 against the alternative H 1 : p> 0 at the significance level a, 
then for the large sample size, we could use the central limit theorem and reject H0 if 
x > 2Zza/X (recall that Var(X) = 2/X2). However, if the sampje size is rather small 
(e.g., n = 10), the normal approximation of the distribution of X may not be appro­
priate, and other methods should be used instead.
Monte Carlo Tests
In Monte Carlo tests, the critical values for given levels of significance, or conversely, the 
probabilities for specified thresholds, are estimated from generated samples based on the 
fact that relative frequencies can be used to estimate probabilities.

MONTE CARLO, BOOTSTRAP, AND PERMUTATION TESTS
425
■ EXAMPLE 12.39
Continuing Example 12.38, if we are testing H0 : ^ = 0 against H 1 : p> 0 at 
the_significance level a = 0. 1, then we need to find a critical value va such that 
P(X > val^ = 0) = a. For that we generate many (at least several thousand) samples 
of size n = 10 from the distribution with density f (x; p, = 0, A) = (1 /2) A exp{—A|x|}, 
and for each of them, we obtain its sample mean. Next, va is obtained as the sample 
upper 0.1 quantile in the set of all means in generated samples.
In Examples 12.38 and 12.39, the sample size was small. In other situations, where the use 
of Monte Carlo tests is recommended, distributions of statistics are difficult to track theo­
retically (e.g., when population distributions are mixed or contaminated), or the estimators 
of parameters of interest are difficult to handle theoretically (e.g., sampling distribution of 
the coefficient of skewness, kurtosis, or trimmed mean).
Bootstrap Tests
Bootstrap procedures are designed for the situations where the population distributions are 
unknown, and the actual samples provide the only available information. Consequently, the 
reference distribution for the statistic of interest is obtained from bootstrap samples. One 
may notice that bootstrap sampling is actually a Monte Carlo sampling from the distribu­
tion obtained from all n sample values, with probabilities 1/n assigned to each of them (the 
generation of bootstrap samples was described in Section 11.7). The p-values of the test are 
obtained as appropriate relative frequencies from the bootstrap distribution of the statistic 
being used.
■ EXAMPLE 12.40
Let us consider a problem in which hypothesis H0 : ^ = ^0 is tested against 
H 1 : p> ^0. The test statistic that can be used here is X, and its sampling distribution 
is imitated (as explained in Section 11.7) by the bootstrap distribution. However, 
we need to keep in mind that the p-values must be obtained as probabilities for the 
distribution determined by the null hypothesis. Since we do not know what distribu­
tion the random sample represents (with ^ = ^0 or rather p> ^0), before generating 
bootstrap samples, we need to modify sample values by taking wi = xi — x + /л0, 
where x is the mean obtained from the original sample. Then, the p-value will be 
obtained as 
_ 
_
number of w* ’s exceeding x 
p -value =------------------—-------------------,
B
where w* is the average in the ith bootstrap sample.
We can also use bootstrap tests to compare parameters in two populations. In such a case, 
we usually have two independent random samples X1, ...,Xn and Y1, ...,Ym. B bootstrap 
samples X*, .. .,X^ and Y*, .. .,Ym are then generated by sampling with replacement from 
the same set that consists of combined m + n original observations.
Permutation Tests
Permutation tests are similar to bootstrap tests as they also use only actual sample(s) to 
obtain a reference distribution based on which a p-value is determined. However, the sam­
pling process is now different.

426
TESTING STATISTICAL HYPOTHESES
Practically, all parametric tests have a corresponding permutation test that is based on the 
same test statistic as the parametric test. But the p-value is obtained from the sample-specific 
permutation distribution of that statistic rather than from the theoretical distribution using 
a parametric assumption.
We will focus here on a two-sample test that compares two population distributions; the 
H0 states that both distributions (or actually their respective parameters) are equal. An 
important assumption behind a permutation test is that the observations are exchangeable 
under the null hypothesis. The respective samples x = (x1, ...,xn) and y = (y1, ...,ym) of 
size m and n can then be combined into one set of size m + n which is then partitioned into 
two subsets of sizes m and n so that the value of the appropriate statistic can be obtained. 
This process is repeated for all possible mm+n partitions, eventually giving the reference 
distribution based on which a p-value will be determined as a measure of how “extreme” is 
the value obtained from the original samples.
■ EXAMPLE 12.41
Let x = (x1, ...,xn) and y = (y1, ...,ym) be two particular samples selected ran­
domly from distributions f (x; 60) and f (y; в 1), respectively. We want to test hypothesis 
H0 : в0 = в 1 against the alternative H 1 : в0 < в 1. Assume that the difference Д = 
в 1 - в0 is estimated by some statistic Д, and its large values provide evidence support­
ing the alternative hypothesis. To perform the permutation test, we first obtain Д0 = 
Д(х, y). Then samples x and y are combined into a set w = (x 1, ..., xn, y 1, ..., ym), 
which is next partitioned mm+n times into two subsets of sizes m and n, respectively. 
For each partition, the value of statistic Д is obtained and the p-value is determined as
p-value = number of values of Д equal to or exceeding Д0
m+n \ 
m
If sample sizes m and n are such that the number of all possible partitions mm+n is 
very large, then a smaller number of partitions can be obtained in a random (rather than 
systematic) way. The procedure is then called a randomization test.
More information on procedures introduced in this section can be found, for example, in 
Good (2005).
PROBLEMS
12.10.1 A random sample 0.38, -0.49, 0.03, 0.21, 0.12, 0.14, -0.18, -0.34, 0.46, -0.01 was 
selected from a Laplace distribution with density f (x, y) = exp{-2lx - y\}. Use 
Monte Carlo simulations to estimate the p-value for testing the hypothesis H0 : y = 
0 against the alternative H1 : y> 0.
12.10.2 A random sample 1.138, 1.103, 3.007, 1.307, 1.885, 1.153 was obtained from a dis­
tribution with density f (x, в) = 2в2x-3 for x > в and 0 otherwise. Find the MLE 
of в, and use it to test H0 : в =1 against H 1 : в > 1. Find the p-value and compare 
it with the p-value based on 2000 Monte Carlo generations.
12.10.3 Assume that the hypothesis H0 : в = 0 is to be tested against H 1 : в > 0, where в is 
a parameter in the U[в, в +1] distribution. (i) Derive the test of size a = 0.05, based 
on one observation only, and obtain its power function for в = 0.1, 0.2, ..., 0.9. 
(ii) Use Monte Carlo simulations to obtain a test with a critical region X3 > k; that 
is, estimate k. Then again use Monte Carlo simulations to estimate the power func­
tion of this test at в = 0.1,0.2, ...,0.9. Use the same size a = 0.05. (iii) Compare 
the power functions of both tests.

MONTE CARLO, BOOTSTRAP, AND PERMUTATION TESTS
427
12.10.4 Use the bootstrap test for testing H0 : p, = 2 against H 1 : ^ > 2, based on the ran­
dom sample: 3.49, 2.21, 1.07, 3.04, 2.57, 2.43, 2.18, 1.10, 1.04, 1.92, 0.99, 3.13, 0.92, 
2.72, 4.03.
12.10.5 (Shoshoni Rectangles) The following problem is taken from Larsen and Marx (1986). 
Since antiquity, societies have expressed esthetic preferences for rectangles having a 
certain width (w) to length (l) ratio. For instance, Plato wrote that rectangles formed 
of two halves of an equilateral triangle are especially pleasing (for such rectangles 
w/l = 1 /л/3). Another standard, adopted by the Greeks, is the golden rectangle. It 
is defined by the condition that the ratio of its width to length must be the same 
to that of the part remaining after cutting off a square with the side equal to its 
width (i.e., the shaded area in Figure 12.7 is similar to the whole rectangle). Thus, 
a golden rectangle must have w/l = (l - w)/w, which gives w/l = w/i — 1; hence 
w/l =( V5 — 1) / 2 = 0 • 618.
Both the Greeks and the Egyptians used golden rectangles in their architecture. 
Even today, the golden rectangle remains an architectural and artistic standard (e.g., 
items such as drivers’ licenses, business cards or picture frames often have w/l ratios 
close to 0.618).
The data below show width-to-length ratios of beaded rectangles used by Shoshoni 
Indians to decorate their leather goods. Use the bootstrap test to check whether the 
golden rectangle can be considered an esthetic standard for the Shoshonis.
Width-to-length ratios for 20 rectangles found on Shoshoni handicraft:
0.693 0.749 
0.654 
0.670 
0.662 
0.672 
0.615 
0.606 
0.690 
0.628
0.668 
0.611 
0.606 
0.609 
0.601 
0.553 
0.570 
0.844 
0.576 
0.933
12.10.6 A study of pollution was carried out in two lakes, A and B . The level of a specific 
pollutant was measured using a certain instrument, and the results for the lake A 
were 3.17, 4.22, 2.58, 4.01, and 3.79. In the lake B, the measurements (made with the 
same instrument) were 4.04, 4.32, and 4.12. Test the hypothesis that pollution levels 
are the same in both lakes, against the alternative that the pollution level in lake B 
is higher using: (i) The bootstrap test. (ii) The permutation test. (iii) Compare both 
results.
12.10.7 Two random samples 4.49, 7.68, 5.97, 0.97, 6.88, 6.07, 3.08, 4.02, 3.83, 6.35, and 
4.59, 3.39, 3.79, 6.89, 5.07, 7.41, 0.44, 2.47, 4.80, 7.23 were obtained independently 
from distributions with the same mean. Perform a permutation test to test the
w
l-w
w
l
Figure 12.7 Golden rectangles.

428 testing statistical hypotheses
hypothesis that the variability in both populations is the same against the alternative 
that it is larger in the second population. As a test statistic use: (i) The difference of 
sample ranges. (ii) The ratio of sample variances. (iii) Compare both results.
12.10.8 The following bivariate data show 16 independent observation of variables (X, Y).
X
0.95
1.30
2.55
1.60
2.70
2.77
2.85
1.37
Y
110
135
320
160
288
316
131
144
X
2.70
3.60
1.40
2.85
2.60
2.17
1.85
0.93
Y
279
340
191
301
280
302
258
125
Perform the bootstrap test to investigate if X and Y are associated. Use sample 
correlation as a test statistics.

CHAPTER 13
LINEAR MODELS
13.1 INTRODUCTION
This chapter is devoted to statistical problems arising in situations where the observed val­
ues (called “dependent variable,” “response,” etc.) are influenced by some other variable 
(referred to as “independent variable,” “explanatory variable,” “treatment,” “factor,” etc.). 
In this chapter, we consider the case where only expected values are affected, while other 
characteristics (as well as the type of distribution) remain the same.
The theories that we present depend on the assumptions about the independent variable: 
Can its value be observed or not? If yes, can it be controlled by the experimenter? If no, can 
it be regarded as random? Depending on the answer to these questions, we have a regression 
analysis or different analysis of variance (ANOVA) models (one-factor, two-factor, with or 
without interaction, with fixed or random effects, etc.).
Many models (theories) are available in the general setup considered in this chapter. The 
basic ideas and solutions we present cover a few of the most representative cases. We hope 
that the information we provide is enough information to motivate users of various statistical 
packages to try to identify conditions where a specific procedure is not the only one available. 
A thorough and exhaustive presentation of any of these theories can be found in any of 
numerous books devoted to regression analysis or ANOVA (e.g., see Montgomery et al., 
2006; Stapleton, 1995; Myers and Milton, 1991; Myers, 1986).
In this chapter, we outline some of the most common ways of analysis of data measured 
on a scale ofat least interval type. We discuss the methods of detecting and measuring effects 
expressed through the mean of the observed random variable. However, we present only the 
most common of such methods, regression analysis and ANOVA.
■ EXAMPLE 13.1
In a simple case of linear regression analysis, we observe a random variable Y such 
that Y = aX + в + £, where X is some variable (random or not, possibly controlled 
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
429

430
LINEAR MODELS
by the experimenter) and £ is the “error,” meaning a random variable with E(£) = 
0, Var(£) = а2 < ж. Both X and Y are assumed to be measured on an interval (or 
possibly even ratio) scale.
Specific examples may be obtained by taking Y to be the time to completion of 
some chemical reaction, and X being the temperature; Y may be some substance that 
accumulates linearly (up to random fluctuations) in human bones throughout life, and 
X may be the age of the person at death, and so on.
Typically, we have data in the form of pairs (Xi, Yi), i =1, ...,n, possibly with 
some Xi’s repeating. The problems are to estimate a, в, and а2 (or to test hypotheses 
about these parameters) and predict the value of Y to be observed for some X0 ,orto 
estimate X corresponding to some observed value of Y.
Obvious generalizations involve a model with more than one variable X, for 
instance, when Y = a 1 X 1 + a2X2 + в + £, where X 1 and X2 are some variables. 
We may have nonlinear models, such as Y = aX2 + eX + Y + £ (quadratic 
regression), etc.
■ EXAMPLE 13.2 Analysis of Variance or ANOVA
ANOVA applies to situations where variables Xi are nominal. We typically speak of 
“factors” that operate on some levels.30 For instance, we might have data (measure­
ments of some “response”) taken from populations classified according to some criteria 
such as sex (male and female) and smoking status (never smoked, former smoker, and 
current smoker). We want to find out whether any of these factors (sex and smoking 
status) has an effect on Y (e.g., response to some drugs).
30The use of the word “level” in the context of ANOVA does not imply any specific ordering of the levels of factors 
such as “sex,” F (female) and M (male).
The data can be summarized in a table:
1
Never smoked
2
Former smoker
3
Current smoker
1
Male
Y11
Y12
Y13
2
Female
Y21
Y22
Y23
Here Yij is the response of a subject from group (i, j), where we have one observation 
in each cell. The model is
Yij = M + ai + ej + £ij,
for which we can assume а1 + а2 =0,в1 + в2 + в3 =0,and£ij to be the error term 
satisfying £j ~N(0, а2). We may wish to test the hypotheses H0 : a 1 = a2 =0 and 
H0 : в 1 = в2 = в3 = 0 (no sex effect, and no smoking effect) against the alternatives 
H 1 : a 1 = a2 and H1 : вк = в1 for some k, l = 1, 2, 3, k = l.
The scheme of Example 13.2 can be modified in a number of ways, of which we will discuss 
some. The main issue we note here is that comparing the results within each pair separately 
(until either a pair of “significantly different” results is found or until all pairs are checked 
and found not to differ significantly) is not a correct method. Indeed, for many pairs the 
probability of finding a pair with a large difference becomes quite likely because of chance 
fluctuations, even where the null hypothesis is in fact true. The correct method requires test­
ing all pairs at once, which is accomplished by the ANOVA methodology.

REGRESSION OF THE FIRST AND SECOND KIND
431
13.2 REGRESSION OF THE FIRST AND SECOND KIND
Let Y denote a dependent variable (assumed to be one-dimensional) and X (or X) denote an 
independent variable. In most cases X will be one-dimensional, but the considerations can 
usually be extended to m-dimensional vectors X = (X1, ...,Xm), where m>1.
A few comments about the nature of X and some illustrative examples are in order here. 
We start with the case where the values of the independent variable (or variables) can be 
observed. Depending on how the values of X are chosen, X may be random, either one- or 
multidimensional, nonrandom, or even under the experimenter’s control. Typical cases of 
such situations are exemplified below.
■ EXAMPLE 13.3
In some genetic theories one studies a characteristic Y of offspring, such as height, 
which depends on characteristics X = (X1, X2) of a father and a mother (X1, X2 may 
be heights, but it is also possible to study some other features affecting the offspring’s 
height Y ).
■ EXAMPLE 13.4
Sometimes the randomness of Y for a given X = x has to be postulated, since it is not 
possible to observe more than one Y for the same x. This happens, for instance, if x is 
the calendar time, and we observe the stock market index Yx at the end of the day x. 
Here we treat Yx as random, since we cannot predict its value with complete precision. 
We only have the conviction that “if such and such events had occurred, the value Yx 
would be different from that being observed.” But for each x only one single value is 
recorded, and we have no empirical access to the distribution unless we make some 
assumptions about the nature of randomness of Yx across different times x.
■ EXAMPLE 13.5
It may happen that X is not random. For instance (in the case of one dimension), we 
may study the relation between some developmental characteristic Y of a child, say 
height or size of vocabulary, as dependent on age X . The randomness concerns values 
of Y for the same X = x, since in the population of children of age x there is some 
variability of values of Y .
■ EXAMPLE 13.6
It may even happen that the values of X are totally under the experimenter’s con­
trol. For instance, a chemist may be interested in some characteristic Y of a chemical 
reaction (e.g., its duration) depending on temperature X. Then X can be determined 
arbitrarily by the experimenter, and for a given temperature X = x, the randomness 
of Y may be due to measurement error, or to some other factors.
In each of the cases under consideration, the data have the form of a set of pairs (xi, yi), 
i =1, 2, ...,n, where values of xi can repeat. Even if the xi’s are not random, the formulas 
are identical with those obtained under the assumption that X has discrete uniform distri­
bution over the set {x1 , ...,xn}, with probabilities appropriately increased in the case of 
repeated values. Thus, we will proceed as if X (respectively, X) were a random variable. We 
will assume throughout this chapter that X and Y have finite variances, hence also finite 
expectations.

432
LINEAR MODELS
Let us begin by recalling some facts from Chapter 7. Suppose that we know the value of 
X , X = x, and we want to predict the value of Y . The best prediction of Y (in the sense of 
mean square error) is given by the conditional expectation
u(x) = E(Y |X = x). 
(13.1)
In other words, we have
mmE[(Y - £)2|X = x] = E[(Y - u(x))2|X = x].
Accordingly, we introduce the following definition:
Definition 13.2.1 The conditional expectation of Y given X = x, that is, the function 
u(x) given by (13.1), will be called the true regression, or regression of the first kind, of Y 
on X. 
□
In the case ofa continuous random variable X, it may happen that the regression function 
u (x) is defined only for almost all x, that is, on a set A such that P{X G A} = 1. However, in 
all cases that are encountered in statistics, there is typically a function u(x) that is “natural” 
in a given problem. We will select such a function and comment on the nonuniqueness of a 
regression function only when such a comment is essential for the problem.
The usefulness of the regression function u(x) is not restricted to the prediction ofY.To 
mention just one other use of it, suppose that we do not know how X and Y are related; we 
only formulated the hypothesis that the true regression function is equal to some function 
u0. In other words, the null hypothesis is H0 : E(Y|X = x) = u0(x) for all x. If we know 
something about the conditional distribution of Y given X , we may test this hypothesis, 
rejecting it if the value of Y observed for given X = x is “far” from u0(x).
Finding the true regression u(x) requires the knowledge of the joint distribution of (X, Y) 
or, more precisely, the conditional distribution ofY given X = x. Such knowledge can come 
from a sufficiently deep understanding of the stochastic mechanisms that connect X and Y, 
or from very extensive data on pairs (Xi, Yi). There are many practical cases when neither is 
available. Moreover, even if we do know the joint distribution of (X, Y), determining u(x) 
may present formidable difficulties.
To cover such situations, another type of regression has been introduced. Starting again 
from problem of prediction, suppose that we want to find the best predictor of Y that is 
linear in X . It will have the form Yp = a + bX, and we will have to find such a and b that Yp 
is the best predictor of Y which will minimize the mean square error E(Y - Yp)2. We have 
here
E(Y - Yp)2 = E[Y- (a + bX)]2
= E(Y2+a2+b2X2 -2aY-2bXY+2abX)
= E(Y2) + a2 + b2E(X2) - 2aE(Y) - 2bE(XY) + 2abE(X).
By differentiating with respect to a and b and setting the derivatives to be 0, we obtain the 
normal equations:
a+bE(X)=E(Y), 
aE(X) + bE(X2) = E(XY).
Multiplying the first equation by E(X) and subtracting it from the second, we obtain
_ E(XY) - E(X) E(Y) _ aY 
b 
о 
p °X
(13.2)
°x

REGRESSION OF THE FIRST AND SECOND KIND
433
and consequently
a = E(Y) - p^YE(X). 
(13.3)
aX
Thus coefficients a and b require only means, variances, and covariances of X, Y.Wenow 
introduce the following definition:
Definition 13.2.2 The relation
Y = a + bX = E(Y) + p^Y [X - E(X)] 
aX
(13.4)
is called the linear regression, or regression of the second kind, of Y on X. 
□
■ EXAMPLE 13.7
Let us consider the situation where the true regression is the function
x
u (x) = 
1
2
for 0 < x < 2
for 1 < x < 1.
Such a regression can occur for various conditional distributions ofY. To fix the idea, 
suppose that given x, the random variable Y is distributed uniformly on an interval 
whose leftmost point is 0. Thus, for 0 < x < 2, random variable Yx is uniform on 
[0, 2x], whereas for 2 < x < 1, random variable Yx is uniform on [0, 1]. The situation is 
presented in Figure 13.1. The shaded area shows all possible points (X, Y). The polyg­
onal line OAB is the graph of the true regression u(x). For use in the next example, 
note that we have here
(13.5)
for 0 < x < 2
for 1 < x < 1.
Var(Y|X = x) = j x3
12
Figure 13.1 True regression.
■ EXAMPLE 13.8
In Example 13.7, the distribution ofX did not play a role in determining regression. In 
fact X could have been nonrandom. On the other hand, to determine the linear regres­
sion of Y on X , it is necessary to know the marginal distribution of X . The intuitive

434
LINEAR MODELS
Figure 13.2 Linear regression for uniform distribution of (X, Y ).
justification here is that in linear regression the objective is to find the best approxi­
mation of Y by a straight line. Thus, it matters which values of X occur more often 
and which occur less often. Suppose that the joint distribution of the vector (X, Y) is 
uniform on the shaded area in Figure 13.2. To determine the linear regression, we need 
the expectations and variances of X and Y as well as their covariance. We have here, 
using simple geometry, for the marginals of X and Y :
0 < x < 2
1 < x < 1.
fX (x)=
cx
c
2
for 
for
(13.6)
The value of c is determined from the condition
13
1 = у fx (x)dx = 8c;
hence c = 8/3. Consequently,
E (X )=xfx (x) dx=18.
After simple integration we obtain E(X2) = 31/72, hence Var(X) = 37/648. 
Similarly, fY(y) = (4/3)(1 - y/2) for 0 < y < 1, and consequently E(Y) = 4/9, and 
Var(Y) = 13/162.
Finally, the joint density f(x, y) is constant, equal to 4/3 on the shaded area in
Figure 13.2. Thus, E(XY) = 7/24, and using (13.4), we obtain the equation for linear
regression (see Figure 13.2):
Y=4+24.
It is of some interest to compare the average square error of prediction of Y on the 
basis of X if we use true and linear regressions. For prediction under true regression, 
we find the average square error, using (13.5) and (13.6):
Ex [Var(Y|X)] = I Var(Y|X = x)fx (x) dx
0
= [ 
— x - x dx + [ — x — x dx = — = 0.0694.
к 
3 
3 
1//2 12 
3 
72

REGRESSION OF THE FIRST AND SECOND KIND
435
For prediction with the use of linear regression, we have the error
X 72 
1 
72 
1
<Y — 4 — 24) = E(Y2) + 16E(X2) + \й) — 2E( X )
71
— 7^ E (Y) + 
E (X) = 0 • 0738 •
Thus, in this case, the mean square error of the linear prediction is about 5.5% higher 
than the corresponding error of prediction based on the true regression. Whether a 
5.5% difference is important or negligible depends on the context. The point is that 
the mean square error of a linear prediction is always at least as large as the error of 
prediction based on a true regression. Also one can easily construct examples where 
the ratio of these two errors is as large as one wishes. In the extreme case, if Y = g(X), 
where g is a deterministic nonlinear function, g is the true regression and there is no 
error involved in a prediction of Y using g(X) as the predictor. But there is an error 
involved if a nonlinear function g is approximated by a linear function a + bX .
Example 13.8 shows that the issue of prediction errors in comparison of two types of 
regression is only partially statistical. One component is due to the randomness of Y for a 
given X = x, and the other is due to replacing the true regression u(x) by a straight line.
The situation may be improved by considering a regression of the second order, where the 
predictor is of the form Yp = a + bX + cX2, or a regression of some other special form, and 
as Yp = a + b sin(cX), and so on. The point is that none of these regressions can give the 
mean square error lower than that based on true regression.
PROBLEMS
13.2.1 Let X and Y have a joint distribution uniform on a parallelogram with vertices at 
points (-1, -1), (0, -1), (1, 1), and (0, 1). Find the true and linear regression of: (i) 
X on Y. (ii) Y on X .
13.2.2 Find an example of random variables (X, Y) such that their true and linear regres­
sions of Y on X coincide, but (X, Y) do not have a joint normal distribution.
13.2.3 Suppose that the true regression of Y on X is not linear in X . Is it possible that the 
marginal distribution of X is such that the expected square error of the best linear 
predictor of Y is the same as the expected square error of predictor based on the true 
regression u?
13.2.4 Let (xi, yj), i =1, •••,nbe the data where at least one value of xi is not zero. Find 
an estimate of the slope parameter b if it is known that a = 0 [i.e., find the best fit of 
the model E(Y |x) = bx].
13.2.5 Suppose that X = (X1,X2). Find coefficients a, b1, b2 such that Yp = a + b1X1 + 
b2 X2 is the best linear predictor of Y given X.
13.2.6 Find true regression Y on X if X and Y have a joint trinomial distribution
P{X = x.Y = y} = x 
n -!x 
pXpУ(1 - p 1 - p2)n-x-y
x y n-x -y
for x = 0, 1 • • • ,n,y = 0, 1, •••,—, and 0 < x + y < n.
13.2.7 The number of eggs in nests of a certain species of birds is one, two, or three, with 
two eggs found in about 80% of nests, and one or three eggs in about 10% of nests

436
LINEAR MODELS
each. In one-egg nests, the egg hatches successfully in 75% of cases. In two-egg nests, 
the probabilities for the number of offspring are 0-20%, 1-30%, 2-50%, whereas 
in three-egg nests, these probabilities are 0-10%, 1-20%, 2-60%, 3-10%. Find the 
best linear predictor ofY being the number of offspring based on the observation of 
X—the number of eggs in the nest.
13.3 DISTRIBUTIONAL ASSUMPTIONS
In addition to the classification of regression models with respect to the two types of regres­
sion, a meaningful and useful classification is obtained when one considers typical assump­
tions about the distribution of the response Y for a given value of X .
The oldest methods that can be included in regression theory dates back to the beginning 
of the nineteenth century and the works of Legendre. He found a method of best approxima­
tion ofa set of points by a straight line. The word “best” was understood in the sense of least 
squares. In other words, Legendre found, for a set of data points (xi , yi), the coefficients 
a and b such that the sum i [yi - (a + bxi)]2 attained its minimum. In this formulation, 
no assumptions about randomness are needed: the best-fitting line always exists, even if 
the “best” fit does not mean a “good” fit. The extension to the best linear fit in two (or k) 
dimensions—finding a 1, a2,b to minimize the sum [yi — (a + b 1 x(1) + b2x(2) )]2—is now 
straightforward. Similarly, the theory extends naturally to other forms of relations, such as 
quadratic or periodic functions obtained by minimizing the sums i[yi — (a + bxi + ex2)]2 
or Ei [yi — a cos(bxi + e)]2•
Viewed in this way, regression theory belongs properly to the domain of numerical anal­
ysis. However, to allow statistical inference, one usually makes some assumptions about the 
randomness inherent in the model. One of the standard assumptions is that for every x we 
have Y = p(x) + e, where p is some deterministic function and e is the “error” random vari­
able, such that:
(i) 
E (e )=0.
(ii) Var(e) = a2 > 0.
(iii) The errors e, e', e", • • •, corresponding to different observations of Y (for the same, or 
for distinct values of x are uncorrelated.31
31The assumption that variance is independent of x is often called homoscedasticity, as opposed to heteroscedas- 
ticity.
Under these assumptions, <p(x) is the true regression of Y on X. If one now imposes some 
parametric model on p, one can set up the least square equations for parameters of p and 
the parameter a2.
If the assumptions (i)-(ii) are replaced by
(iv) The errors e,e', • • •, have a N(0,a2) distribution,
then the errors are independent. The independence of errors and knowledge of the distribu­
tion, have profound theoretical consequences: we can write the likelihood of the data and 
find the maximum likelihood estimators of the parameters.
One can easily see that in this case the maximum likelihood estimate (MLE’s) coincide 
with least square estimators, so it might appear that nothing is gained by replacing (i)-(iii) 
with (iii) and (iv). However, under (iv) we know the sampling distribution of the estima­
tors, and we are therefore able to use the results from estimation and testing theory to build 
confidence intervals, tests of various hypotheses, and so on.

DISTRIBUTIONAL ASSUMPTIONS
437
Finally, let us mention, that if in addition to (i), (ii), and (iv) we can assume that
(v) у(x) = a + bx,
(vi) X has a normal distribution,
then the joint distribution of (X, Y ) is bivariate normal. The converse is also true, as shown 
in Theorem 8.5.4. We may summarize these facts as the following:
Theorem 13.3.1 In case of bivariate normal distribution (X, Y ), the true and linear regression 
coincide.
A comment appears necessary here in regards to assumptions (iii) and (iv), and their 
implementation in practical situations. To illustrate potential difficulties, suppose that we 
collect data on a regression where x is the age of a child, and Y is some response, such as 
reaction time to a specific stimulus. Suppose that we need two observations for the same age 
x. Then it is not correct to measure the reaction time Y twice for the same child of age x, even 
if such observations can be regarded as independent. The correct procedure is to take two 
children of the same age x and observe their reaction times. The reason is that variability ofY 
has two components: the between-children variability and the within-child variability. Tak­
ing two measurements for the same child will involve only the second component, whereas 
other observations will involve both components, violating (among others) the assumption 
of homoscedasticity.
Assumptions (i)-(vi) are by no means the only sensible assumptions one can make in 
regression analysis. The linearity assumption E(Yx) = a + bx is often acceptable as an 
approximation or in some narrow range. A typical case of this kind is illustrated by the 
following example:
■ EXAMPLE 13.9 Logistic Regression
Assume that the response variable Yx is of the binary character (e.g., success or failure).
We can always take the possible values of Yx as 0 and 1 so that E(Yx) = P{Yx =1} = 
n(x). We will assume that x is a numerical variable (random or not, depending on the 
situation under study), and that n (x) is the true regression of Y on x. The assumption 
n (x) = a + bx can be realistic only in a narrow range of values of x, since we must 
have 0 < n (x) < 1 for all x. Still the inference about the shape of function n (x) is of 
considerable interest, and linearity is a powerful assumption (in the sense of allowing 
many analytical results). To realistically utilize such an assumption, we consider the 
odds ratio n(x)/ [1 - n(x)], with range (0, ж), and its logarithm, with range (-ж, ж). 
Thus, we consider the model
, 
п (x) 
. ,
log ------- — = a + bx,
1 — n (x)
or equivalently,
a+bx
n(x) = 1 + ea+bx . 
(13.7)
The right-hand side of (13.7) is called the logistic function (and is a cdf of a logistic 
distribution ifb>0), which explains the name logistic regression. The problem now is 
to estimate parameters a and b given the data (xi,ni,Ni),i=1, ...,m,where xi’s are 
the values of the independent variable at which observations are taken, while ni and 
Ni are the number of successes and the number of trials at value xi, respectively. The

438
LINEAR MODELS
likelihood is therefore
L = П 
[ п (Xi)] ni [1 - n (xi)] Ni-ni
n
i=1 
i
ea £ ni+b £ xini
П”=1 (1 + ea+bxi) Ni.
Determining a and b that maximize L requires using numerical iterations.
PROBLEMS 
13.3.1 The random variable Yx has the density
f, । v _ 1 1 for a + bx — 1 < y < a + bx + 2 
y X 0 otherwise.
Find the MLE’s of a and b given the sample: (-1, 1.3), (0, 1.4), (1, 0.1), (2, -0.4), 
(3, -0.1). Compare the MLE’s with the LS estimates.
13.3.2 Let (X, Y ) have the distribution uniform on the quadrangle with vertices (0, 0), 
(1, 1), (0, 2), and (0.5, 1). Find: (i) The true regression of Y on X and of X on Y . 
(ii) Var(X|Y) and Var(Y |X).
13.3.3 Assume that the total number X of eggs laid by a bird has a Poisson distribution with 
parameter A, and that each egg hatches with probability p, independent of other eggs. 
Find the regression of the number Y of eggs hatched on X. Let Xi, Yi be the number 
of eggs laid and hatched by the ith bird. Derive the likelihood of the data for n birds, 
and the equation for estimating A and p. Find the MLE’s of A and p.
13.3.4 Answer Problem 13.3.3 assuming a more realistic model, where Xi’s have a Poisson 
distribution conditional on a positive value, that is, for k =1, 2, ...,
P {Xi = k} = (Ak/k!) e-
1 - e-x
13.4 LINEAR REGRESSION IN THE NORMAL CASE
In this section, we will present the main results in the case where for any given x, the response 
Y is of the form
Y = a + bx + e
for e ~ N(0, a2). Moreover, we will assume that the errors e for different observations of Y 
(for the same as well as for a distinct x) are independent.
We will assume that the data have the form
(xi,yi), 
i=1, ...,n,
(13.8)
where y1 , . ..,yn are independent observations. We will use the notation
x = 1n
n Й xi,
y=- is yi 
n
and assume that not all xi ’s are identical.

LINEAR REGRESSION IN THE NORMAL CASE
439
The estimates of parameters a, b, and a2 are easy to obtain. The likelihood function of 
the sample (13.8) is
n
L = П
i=1
1
( yi-a-bxi )2 / 2 a 2
1n
= a - (2n) -n/2 exp ^-2^2 (yi — a — bxi )2 
2a2 i=1
hence
n 
1n
log L = C — ^ log(a2) ^-2^2 (yi — a — bxi)2•
2 
2a2
i=1
Differentiating with respect to a and b, we obtain a pair of equations (in which a2 cancels out) 
that are the same as the equations for the least squares estimates ofa and b. The solutions can 
be obtained from formulas (13.2) and (13.3) by treating X as a random variable uniformly 
distributed on x1 , •••,xn. Thus
b = E( x^ — x)(yi—— y) 
and — = y — bx 
(13.9)
E( xi — x )2
The denominator in the expression for b is not zero in view of the assumption that not all 
xi’s are equal.
Differentiating log L with respect to a2 and setting the derivative equal to 0, we obtain 
the MLE of a2: 
n
a 2 = 1 
(yi — — — bxi )2 • 
(13.10)
n i=1
To determine the sampling distribution of estimators (under variability of yj’s only, for fixed 
xj’s), let us regard yj as a value of the random variable Yx . Then the estimators ofb, a, and 
a2 are, respectively,
U = E( xi — x)(Y — Y) 
E (xi — x )2
V = Y — Ux 
(13.11)
T2 = 1 Y (E- — V — Uxi )2 • 
n 
xi 
i
i=1
Notice that the randomness ofU, V, and T2 is related only to the variability of the dependent 
variable Yx about its mean a + bx. The values xi may be nonrandom, and even if they are 
arising from the sampling, U, V, and T2 involve only a conditional distribution of Y given 
X = x.
It follows from (13.11) that U, as a linear combination of normally distributed random 
variables, has itself a normal distribution. To determine the mean, observe that
E(Y) = 1 
E(YXi ) = 1 ^(a + bxi ) = a + bx
n 
xi 
n
i=1 
i=1
Consequently, we have
E(U = E( xi — x) E(Yxz — Y) = E( xi — x)[ a + bxi —(a + bx)] = b 
( ) 
E (xi — x)2 
E (xi — x)2 
•

440
LINEAR MODELS
To find the variance of U , we write
E(xi -x)YXi - YE(xi -x) = E(xi - x)Yx„ 
E (xi - x)2 
E (xi - x)2 '
Consequently, by assumption of homoscedasticity,
a 2
U
Var [E(xi - x)YXi 1
I E (xi - x)2 J
E (xi - x)2Var(Yx,) 
[E (xi - x)2]2
(13.12)
(x,( xi — x)2'
Next the estimator V given by (13.11) is also a linear combination of the normal random 
variables, so it has a normal distribution. Here
E (V) = E (Y) - E (U) x = a + bx - bx = a
so that U and V are unbiased estimators of b and a.
The derivation of the variance of estimator V is somewhat messy. We have
aV = Var(Y) + x2 Var(U) - 2x Cov(U, Y)
= Var (_ \' Y A + x2a2 _ 2x Cov |~E(xi — x))Yx. £ \ ' Y
V V n^Yxi) + U 2 x COV[ £ ('xi - x )2 ,n^Yxj_
= - + x2^ z a—------\ 2x—Cov Г^(xi - x)Yx-, 
Yx .1 •
n 
(xi(xi - x)2 
^2 (xi - x)2 
i x 
xjj
In the last term, all covariances corresponding to i = j vanish while all others are equal a2 . 
Consequently
COV [^(xi - x)Yx„ , 
YXj ] = ^(xi - x)a2 =0•
After some algebra we obtain
2 
E xi2
V E (xi - x)2 •
(13.13)
In a similar manner, we can show that
Cov( U,V ) = -a 2--------2 
(13.14)
E(xi - x)2
(we leave the proof as an exercise).
These results suggest that (U, V) has a bivariate normal distribution. In fact the following 
theorem holds:
Theorem 13.4.1 The estimators (V, U, T2 ) are jointly sufficient for the parameter 
в = (a,b,a2). Moreover, (U, V) have a bivariate normal distribution with means, variances, 
and covariance given by (13.12) through (13.14). Finally, T 2 is independent of (U, V), and 
nT 2 /a22 has a chi-square distribution with n - 2 degrees of freedom.
Proof : We can use the joint moment generating function
m (11 ,t 2 ,t 3) = E (e1U+t2 V+t3 T 2) •
Substituting the expression for U, V,andT2, and integrating with respect to the joint density 
of (Y1, • • • ,Yn), we can show (after considerable algebra) that m(11 ,t2,t3) = m 1 (11 ,t2) x 
m2(t3), which proves the independence of (U, V) and T2. The form of functions m1 and m2

LINEAR REGRESSION IN THE NORMAL CASE
441
will then show that claims about the distributions of (U, V ) and T2 are also valid. We omit 
the details. 
□
We will now illustrate the applications of Theorem 13.4.1 with some examples on the 
construction of confidence intervals and tests for parameters of the regression model.
■ EXAMPLE 13.10 Is It Good to Be a Royal Prince?
Poland had altogether 13 kings whose fathers were also Polish kings (starting from 
the fifteenth century, Polish kings were elected, and the election of a late king’s son, 
although often likely, was by no means ensured). In one pair, the son died young in 
battle; deaths in the remaining 12 pairs came from natural causes. The ages at death of 
fathers (xi) and sons (yi) are listed below.
Father
xi
Son
yi
Mieszko I
62
Boleslaw the Brave
59
Boleslaw the Brave
59
Mieszko II
44
Casimir I the Restorer
42
Boleslaw the Bold
42
Wladyslaw I the Short
73
Casimir III the Great
60
Wladyslaw II Jagiello
83
Casimir IV Jagiellonian
65
Casimir IV Jagiellonian
65
John I Albert
42
Casimir IV Jagiellonian
65
Alexander Jagiellonian
45
Casimir IV Jagiellonian
65
Sigismund the Old
81
Sigismund I the Old
81
Sigismund II Augustus
52
Sigismund III Vasa
66
Wladyslaw IV Vasa
53
Sigismund III Vasa
66
John II Casimir Vasa
63
Augustus II the Strong
63
Augustus III
67
As can be seen, only in 2 out of 12 pairs did the son live longer than his father. 
Can this be attributed to chance, or does it indicate some systematic trend (e.g., a 
“pampered” heir to the crown is not capable of dealing with the stress and additional 
duties demanded of him upon his accession to the crown).
We have here
x = 65.83, 
y = 56.08
which means that on average, sons lived about 10 fewer years than their fathers. For 
the regression coefficients, and their variances and covariances, we obtain
a = 29.214,
2b = 0.408,
and also £ x2 = 53,224, £ (xi - x)2 = 1, 215.67. Finally, T2 = 115.034. The 
individual points, as well as the regression line y = 29.214 + 0.408x, are presented in 
Figure 13.3 (broken line). We will return to the analysis in Example 13.11.
We begin by constructing confidence intervals for the regression intercept a and slope b. 
It is known that (U - b) /<jv has a standard normal distribution. This quantity, however, 
involves the nuisance parameter x. Since nT2 /x2 is independent of U and has a chi-square 
distribution with n - 2 degrees of freedom, the ratio
t = 
(U - b)/xU
nT 2 / [ x 2( n — 2)]
(U - bMn - 2) E (xi- x)2 
(Yxi - Uxi- V)2
(13.15)

442
LINEAR MODELS
Figure 13.3 Ages of Polish kings and their heirs at death.
has a Student’s t distribution with n - 2 degrees of freedom. Consequently, (13.15) is a piv-
j 1 
J • J С 7 / 
Г" ’ л ’ 
t t I~\\ T J J • 
* 
1 Г 1 
j j 1 
1 
1 
1 
P
otal quantity for b (see Definition 11.7.2). Letting a and b denote the observed values of
estimators V and U of intercept and slope, we obtain the (1 - y )-level confidence interval
for slope b as
tY/2 ,n-2
n - 2) E (xi - x)2
(yj - - -bxj)2.
лb ±
In a similar way, we can derive the (1 - y)-level confidence interval for the intercept a in 
regression line:
■ I . 
I 
x2 xi 
7" 
’ 
2 Y2
± ± tY/2,n—2d (n - 2) 
(xi _ x)^E (yi 
a 
bxi) ■
■ EXAMPLE 13.11
To continue Example 13.10, the 95% confidence intervals for the regression slope and 
the intercept are now, respectively,
[0■408 - 0 ■ 751;0■408 + 0 ■ 751] = [-0■ 343, 1 ■ 159]
and
[29■ 214 - 50■000; 29■ 214 + 50■000] = [-20■ 786; 79■ 214]■
Since the confidence interval for regression slope b covers the value 0, we cannot exclude 
the possibility that the true regression is a constant a. This means that the age of the 
son at death does not depend on the father’s age at death. Thus, the evidence is not 
conclusive with regard to the effect of being born to a royal family on duration of life.
Obviously, this example should not be taken too seriously. There are many factors 
affecting the length of one’s life that should also be taken into account in a real study.

LINEAR REGRESSION IN THE NORMAL CASE
443
We can even construct a simultaneous confidence set for both regression parameters using 
the F distribution. We want to show (we omit the proof) that the random variable
Q = — I"n(U — b) + 2nx(U - b)(V - a) + V x2(V - a)21
2 n 
n x 
La j | 
^x i 
^a
has the chi-square distribution with 2 degrees of freedom. Consequently, the random variable
Q/2 n - 2 
[n(U — b)+2nx(U — b)(V — a) + Ex2(V — a)2]
nT2/(n 2 2) 
2 x 
£ (Yx. — Uxi — V)2
has the F distribution with (2,n- 2) degrees of freedom. Thus, the ellipsoid in the (a, b)- 
plane,
n(b - b)2 + 2nx(b — b)(а - a) + 
x2(а - a)2 < -—-2FY,2,n-2 
(yi - a - bxi)2,
is a (1 — y)-level confidence set for the regression parameters.
Notice that the results obtained thus far can be used to build estimators and to construct 
tests of hypotheses about linear combinations of the regression coefficients a and b. We will 
illustrate the situation with an example.
■ EXAMPLE 13.12
Suppose that we need to estimate the parameter 6 = Aa + Bb, where A and B are given 
constants. A special case is obtained here ifA =1,B= x0, so that the objective is to 
estimate the mean response at X = x0, namely E(Yx )=a + bx0.
Clearly, the unbiased estimator of 6 is W = AV + BU, whose value for the sample
is 6a = Aaa + Bab. The distribution of W is normal since W is a sum of two normally 
distributed random variables. So we have
oW = A2oV + B2oU + 2ABCov(U, V)
= a2 
Г A 2 V x2 - 2 ABx + B2]
£ (xi — x )2 A A-^xi 
2 ABx + B \.
Proceeding as before, we can show that the random variable
[A(V — a) + B(U — b)] 7(n — 2) £ (xi — x)2 
У [A2 E x2 — 2ABx + B2] [£ (Y-x^ — Uxi V V)2]
has the Student’s t distribution with n - 2 degrees of freedom. This gives the (1 - 
y)-level confidence interval for 6 as
a^ 
AA2 
x2 — 2ABx + B2 /V" ( -л-i^)
6 ± tY//2,n-2d (n — 2) £ (xi — x)2 V 2jyi 
а bxi).
These results can also be used to test hypotheses about the regression coefficients a and b. 
The testing procedures (likelihood ratio tests) use the same Student-type ratios as the confi­
dence intervals above. We will give the results for the slope coefficient b, leaving the derivation 
of the tests for intercept a as exercises.
Suppose that we want to test the null hypothesis
H0 : b = b0

444
LINEAR MODELS
against a one- or two-sided alternative. Then, given H0, the random variable (U - b0)/aU 
has a standard normal distribution, and consequently the test statistic obtained upon divi­
sion by УnT2/[a2(n - 2)], that is,
t = VE (Yx. - Uxi 
V n — 2) 
(xi — x)2
has t distribution with n - 2 degrees of freedom. A one- or two-sided rejection region is then 
used depending on the alternative hypothesis.
PROBLEMS
13.4.1 Derive the test for the null hypothesis H0 : a = a0 against the one- or two-sided alter­
native.
13.4.2 The scores on an entrance exam (x) and the grade point average (GPA’s) upon grad­
uation (y) for 10 randomly selected students of a certain university are
x 
355 
361 
402 
365 
375 
404 
349 
380 
420 
395
y 
3.66 
3.49 
3.86 
3.24 
3.55 
3.92 
3.11 
3.19 
3.76 
3.75
Assume normality and homoscedasticity. (i) Compute the MLE’s ofa, b, and a2. (ii) 
Test the hypothesis that there is no relation between the grade on the entrance exam 
and the GPA, against the alternative that higher scores on the entrance exam tend 
to be associated with higher GPA’s. (iii) Find the shortest 95% confidence intervals 
for a and for b. (iv) Find the joint confidence set for (a, b) with confidence level 0.95; 
sketch it and compare with your answers to (iii).
13.4.3 Suppose that observations are taken only at two values, x1 and x2, of an independent 
variable. Let y 1 and y2 be the average observed responses for x = x 1 and for x = x2, 
respectively. Show that the estimated regression line passes through points (x 1 ,y 1) 
and (x2,y2).
13.4.4 Using the ideas given on deriving the confidence set for (a, b), derive the testing 
procedure for the null hypothesis H0 : a = a0,b = b0 against the general alternative 
H1 : H0 is false. Consider two cases: (i) a known. (ii) a unknown.
13.4.5 Suppose it is known that the true regression (assuming a normal case) has the form 
E(Yx) = bx. Derive the MLE’s for b and for a2 .
13.5 TESTING LINEARITY
In this section, we make the following two additional assumptions regarding the design of 
the experiment for collecting the data on regression parameters:
(i) There are at least three distinct values among x1 ,x2 , ...,xn .
(ii) There exist at least two repeated values among x1, ...,xn.
We will show that under (i) and (ii) it is possible to construct a test for linearity of regres­
sion, that is, a test of the null hypothesis
H0 : E(Yx) = a + bx for some a, b against 
H1 : E(Yx) = u(x),
where u(x) is not a linear function of x.

TESTING LINEARITY
445
The test for linearity will be based on construction of two independent unbiased estima­
tors of a2. One of them will estimate a2 regardless of whether or not H0 is true, and the other 
will be an unbiased estimator of a2 only under the null hypothesis.
For the considerations of the present section only, it will be convenient to change the 
labeling of the sample (xi,yi), i = 1, ... ,n, as follows: Let x'1 ,x2, .. .,xr be all those xi at 
which multiple observations were made, and let n1 , ...,nr be the numbers of observations 
made for those values. Furthermore, let the observations made for xj be yj, 1, ..., yj,n., and 
regarded as values of iid random variables Y-1 1, ..., Y,n.. Finally, the remaining values of 
independent variable will be denoted by xr+1, ..., x'm, with the corresponding observations 
yr+1, ... ,y'm being the values of random variables yr+1, ..., y'm.
We have therefore
n 1 + • • • + nr + (m — r) = n, 
(13.16)
with ni > 2, i = 1, ... ,r.
Consider now the following decomposition of the sum of the squared deviations: 
n 
r nj 
m
22 
2 
2
s = 2_^( yi - a - bxi) = ^1^( yj,t - a - bxj) ' X (yk - a - bxk) 
i=1 
j=1 t=1 
k=r+1
= 
(yj,t - yj + yj - a -axj)2 + 
(yk - a -bxk )2
j=1 t=1 
k=r+1
= 
(yj,t -yj)2 + 
nj(yj -a-axj)2 + £ (yk -a-axk)2
j=1 t=1 
j=1 
k=r+1
222 
= s1 + s2 + s3.
In passing from the third to the fourth expression, the cross-products were omitted. One can 
check that indeed they are equal to zero.
Now the sums s21, s22, and s23 are observed values of random variables
S2 = Ё lj (Yj. - Yj)2• 
j=1 t=1
r
S22 
nj (Yj - V - Uxj )2 ,
j=1 
m
S32 
(Yk - V - Uxk)2.
k=r+1
Under the assumption of normality of the distributions of Yx , the random variables S12 and 
S22 are independent; random variables s32 and S12 are independent as well. The proof of these 
facts is similar to the proof of Theorem 9.2.1, and it will be omitted.
Finally, in view of (13.16), S12/a2 has a chi-square distribution with the number of degrees 
of freedom equal to 
rr
(nj - 1) = 
nj - r = n - m,
where n - m> 0, since r > 1 and nj > 2 for all j . It is important to recognize that this 
statement about the distribution of S12 holds regardless of whether the null hypothesis H0 
about linearity of regression is true.

446
LINEAR MODELS
On the other hand, if H0 is true, then also
S22 - 2 + S2-2 - X2m-2.
Again, the number of degrees of freedom is positive, in view of the assumption that m, the 
number of distinct values of xi ,isatleast3.
To obtain the testing procedure, observe finally that any violations of the null hypothesis 
will tend to increase the expected value of the sum S2 + S2, since E(Y - £)2 is minimized 
for £ = E (Y).
Consequently,
F = (S2 + S32)/(m - 2)
S2 / (n — m)
has the F -distribution with (m - 2,n - m) degrees of freedom, provided that H0 is true, 
while any lack of fit to the linear model will tend to inflate the value of F. Thus, the testing 
procedure with size a is as follows: reject the hypothesis of linearity of regression if
[Er=1 nr(yr — — — bxr)2 + Em= r+i(y'k — — — bxk)2] /(m — 2)
Er=1 En= i (yj,t — y, )2/(n — m) 
> Fam-2,n-m.
■ EXAMPLE 13.13
To develop some sort of intuition concerning the linearity test, we will analyze the 
situation in a deliberately oversimplified case: two observations for x =0 are d and 
-d, an observation for x =1is c, and an observation for x =2is 0. We will find the 
range of values c (for fixed d), and the range of values d (for given c) when the linearity 
hypothesis should be rejected, on a level of significance a = 0.05, say.
Intuitively, for a fixed d linearity will be rejected if the middle point deviates too far 
from the x-axis in any direction, and (for fixed c =0) when d is close to 0.
We have here x = (o + O+1 + 2) / 4 = 3 / 4 and 
(xi — x )2 = 11 / 4. Moreover, y =
(d - d + c +0)/4= c/4. This gives
c c
b = 11 ’
лa= 2 c
11.
The estimated regression line is therefore a + bx = (c/11)(2 + x). To compute the F 
ratio, we have s12 =2d2 with n - m =1. For the numerator we find
s22 + s32 =2 0 — c (2 + °) 12
c—
c (2 + 1) 12
11
c(2 + 2)I2 _ 84 2
11 
= 121c ’
with m — 2=1 degree of freedom. Since Fa, 1,1 = 161.45, the hypothesis of linearity 
should be rejected if
-84 c 2 
c 2
^2v > 161.45 or ^ > 443.99 •
2d2 
d2
Since d > 0, this is equivalent to the inequality |c| > 21.56d.
PROBLEMS
13.5.1 The output ofa certain device is suspected to decrease linearly with the temperature. 
Two observations were taken for each temperature, and the data (in appropriate units) 
are as follows:

PREDICTION
447
Temperature
55
65
75
85
95
105
Observation 1
2.01
2.01
2.02
1.48
1.93
1.90
Observation 2
2.03
2.02
2.00
1.48
1.95
1.94
At the significance level 0.05, test the hypothesis that the output is a linear function 
of temperature.
13.5.2 Suppose that we have six data points in addition to those in Problem 13.4.2:
x
355
402
402
309
375
375
y
3.44
3.91
3.95
3.24
3.52
3.31
Test the hypothesis (using all 17 data values) that the regression of GPA’s on the 
scores from the entrance exam is linear.
13.5.3 Check the identity (13.17).
13.5.4 Derive, if possible, a test of linearity of regression under the assumptions of this 
section, if the individual observations for values x'r+1, ...,x'm are now unknown, and 
instead we have the data on averages y'r+1, ...,y'm, and the corresponding numbers 
of observations n'r +1, ...,n'm.
13.6 PREDICTION
Consider now the problem of prediction. As before, the data have the form of a set of pairs 
(xi,yi),i=1, ...,n,whereyi is the observed value of a random variable Yx assumed to be 
normal with mean a + bxi and standard deviation a. The random variables Yxi i, ..., Yn are 
independent, and at least two among x1 , ...,xn are distinct. The problem is to predict Yx 
as precisely as possible.
More generally, we want to predict the average of k independent observations of Yx . 
By prediction, we mean here providing an interval, as short as possible, such that the value 
of the predicte^random variable will fall into this interval with a preassigned probability, 
say 1 - y. Let Yx0 denote the average of k observations to be taken at the value x0 of the 
independent variable. We are looking for an interval [c1, c2] such that
P {c 1 < Y x 0 < c 2 } = 1 - y.
The solution will be obtained as follows. Note first that the average Yx0 has distribution 
N(a + bx0, a2/k). Consequently,
Y, — a — bx 0 ,— 
Z = xo----------------- о^д
a
is a standard normal random variable, and we have
{ — ZY/2 < Z < zy/2} = 1 - Y
A simple argument based on symmetry around 0 of normal density shows that 
(—zY/2,zY/2) is the shortest prediction interval for Z. Thus, the corresponding shortest 
prediction interval for Yx (given that the regression parameters a, b, and a2 are known) is 
a + bx0 ± z
a

448
LINEAR MODELS
and its length is 2(a^fk)zY/2. The actual prediction interval has to take into account the 
fact that the regression parameters are estimated. The construction is based on an analogue 
to the pivotal quantity. Thus, the random variable
L = Y x о - Ux о - V
has a normal distribution (being a linear combination of normal random variables), and 
E (L) =0 in view of the fact that U and V are unbiased estimators of b and a. We have, 
using the fact that Yx is independent of (U, V),
LI = Var(L) = Var(Yx) + x2 Var(U) + Var(V) + 2x0 Cov(U, V)
= °- + x0aU + aV + 2x0 Cov(U, V)
k
= 02 + x2 
a 2 
। 
a2 E x2 
- 2x 
a2x
k 0 E (xi - x)2 n E (xi - x)2 
0 E (xi - x)2
=a
1 + x2 + 1 E xi - 2x0x"I = 2 Г1 +1 + (x0 - x)2 
k E (xi - x)2 
k n E (xi - x)2
Consequently, the random variable
L = 
Yxо - Ux0 - V
LL 
<x ^/1 /k + 1 /n + (x0 - x)2/ E (xi - x)2
has a standard normal distribution. Dividing by д/nT2/ [a2(n - 2)], we obtain
t =_______________ (Yxо - Ux0 - V) V" - 2_________________
V1 /k + 1 /n + (x0 - x)2/ E (xi - x)2^E (YXо - Uxi - V)2 ,
which has the t-distribution with n - 2 degrees of freedom. Substituting the observed values 
a and b of V and U, we obtain the prediction interval for Yxo with prediction probability 
1 - y as
л 1 1 1 
a + bx 0 ± tY/2 n-2
^n - 2
1 + 1 + (x0 - x)2 ' 
k n E (xi - x)2
(yxi - a - bxi )2] •
(13.17)
Let us remark here that the prediction interval (for fixed n and k) is shortest if x0 = x (i.e., 
it is “easier” to predict values of dependent variable for x0 close to x).
Observe also that as k ^ ж, the length for prediction interval for known a, b, and a tends 
to 0. In the present case, the increase of k has much less effect, and as k ^ ж, the length 
of the prediction interval tends to a positive quantity depending on n and on the location 
of observations x1, x2 , •••,xn. This is consistent with intuition, according to which in the 
present case the uncertainty of prediction has two sources: randomness of the dependent 
variable about its estimated mean and uncertainty as to the exact location of the true mean.
PROBLEMS
13.6.1 At harvest, the weight of a certain fruit grown in a greenhouse has the N(a + bt, 22) 
distribution, where t is the average temperature. Weights in a sample of five fruits 
for t = 80◦ F are 1.02, 1.03, 0.98, 1.05, 1.02, while a sample of seven fruits for t = 
86◦ F (other conditions being equal) are 1.03, 1.03, 1.09, 1.07, 1.04, 1.02, 1.08. Give 
a 95% prediction interval for the average weight of four fruits grown: (i) In the first 
greenhouse. (ii) In the second greenhouse. (iii) In a greenhouse for t = 84◦ F.

INVERSE REGRESSION
449
13.6.2 Combine data points in Problems 13.4.2 and 13.5.2, and find the 95% prediction 
interval for the GPA of a student who scored 400 on an entrance exam.
13.6.3 Find the prediction interval with a probability 1 - y of coverage for an observation 
to be taken at the value x0 by an independent variable, given the data (xi, yi), i = 
1, ... ,n, and assuming the normal model of the form Yx = bx + e with e ~ N(0, a 2).
13.6.4 Under condition of Problem 13.6.3, find the prediction interval for the mean of k 
observations taken for value x0 of the independent variable.
13.7 INVERSE REGRESSION
Inverse regression is the problem of inference about an unknown value x0 ofan independent 
variable on the basis of a number of observations of a response for this value. The data 
consist of two groups of observations. One group is, as before, the sample
(xi,yi), i=1, ...,n,
where yi is the observed value of random variable Yi ~ N(a + bxi, a2), with the usual 
assumption of independence. The second group, (y'1, ... ,y'm), is a random sample from an 
N(a + bx0 ,a2 ) distribution, where x0 is unknown. The objective is to estimate x0, with a, b, 
and a2 being unknown.
The likelihood of the data is
L = 
e-1 /2*2(yi-a-bxi)2 JJ
a 2n 
j=1
e1 / 2 a 2( yi-a — bx 0)2 
a^2n
= C(a2)—(m+n)/2 exp / Z(yi - a - bxi)2 +^m=i (yj - a - bx0)2
Taking the logarithm and differentiating with respect to a, b, a2 , and x0 , we obtain the 
equations
nm
J2(yi- a- bxi) ■ 
yj- a- bxo) =0,
i=1 
j=1
nm
5S( yi- a- bxi) xi+x o^2(yj- a- bx o) =0,
i=1 
j=1
nm
(yi- a- bxi )2 
(yj- a- bx o)2- (m+n)a 2 =0,
i=1 
j=1
m
I2( yj- a- bx o) =0.
j=1
Letting y' = (1 /mj=1 yj, we obtain from the last equation the estimate
лxo =
y' -
(13.18)
л a
b

450
LINEAR MODELS
• 
Г 
j 1 j 7 
/ ЛЛ ПГЧ j 1 • 
1
assuming, of course, that b =0. The third equation gives
1
m+n
ла
nm
(у. — - — bxi)2 + 
(yj — У)2
i=1 
j=1
Using (13.18) in the first two equations, we can easily check that in each case the sum involv­
ing yj equals 0, which means that the expressions for a and b are given by (13.9).
These results are consistent with our intuition. Indeed, since we do not know x0 ,the 
observations y1, ... ,y'm cannot provide any information about the slope and intercept of the 
regression line. On the other hand, if only m > 1, the values y'1, ... ,y'm provide additional 
information about а2 .
To set a confidence interval for x0, we may proceed as in the case of a prediction. The 
random variable W = Y — Ux0 — V has the normal distribution with mean 0 and variance
aW = а2 1 1 
1
mn
(x0 — x)2 A 
E (x 0 — x )2J .
Consequently, W/aW has a standard normal distribution. To eliminate а, we note that the 
random variable
(m + n) a2 
1
а 2 
а 2 nm
E (Y..—Ux. — V )2+E ( yx.„ — Y' )2
i=1 
j=1
has the chi-square distribution with m + n — 3 degrees of freedom. Indeed, the two sums 
are independent, with n — 2 and m — 1 degrees of freedom, respectively. Consequently, the 
random variable
. 
W/W 
(13.19)
(m m + n) а2 /а 2( m + n — 3)
has the Student’s t distribution with m + n — 3 degrees of freedom. The observed value of 
the random variable given by (13.19) is
(y' — - — bx 0)\/ m + n — 3
/ 1 I 1 I 
(x0 —x)2 
/v-n E b i,.,. \2 । vm E 2’
m + + П + E (x0 —x)2 
.=1 =1 (yi — a — bx0) 
j=1 (yj — y )
and the confidence interval is obtained by converting the inequality
'tY//2,m+n—3 < t < ty/2 ,m+n—3
(13.20)
into an inequality for x0. Observe, however, that (13.20) is now a quadratic inequality.
■ EXAMPLE 13.14
The amounts of a chemical compound (y) that dissolve in a given amount of water at 
different temperatures (x) are given in the following table:

BLUE
451
x (◦C)
y (grams)
5
3
4
2
10
7
7
6
15
10
13
11
20
15
18
17
25
21
18
19
Two measurements for an unknown temperature x0 are 14 and 16. What can one say 
about x0?
SOLUTION. We have here n =15and m =2. The relevant quantities are
. . . ...
= = — 1.14, b = 0.853, 
x = 15,
^2 (xi - x)2 = 750,
y— Vi - a - bxi )2 =21.46 y =15 , 
(yi - y )2 =2.
Thus, the point estimate of x0 is x0 = 19.23. Since 10.05,14 = 2.145 (n + m — 3 = 14), 
to obtain a 95% confidence interval for x0, we must solve the inequality (13.20), which 
in our case takes the form
115 — 0.853x0 + 1.41 
V2 + 15 — 3
У1 + 15 + (x0 - 15)2 /750 ^21.46 + 2
< 2.145
or
1346.98 — 18.05x01
x2 — 30x0 + 650
< 2.145.
After some algebra, we obtain x02 — 38.567 + 365.499 < 0, which gives the confidence 
interval
16.96 <x0 < 21.80.
PROBLEMS
13.7.1 Five measurements of Y at x =10are 10.5, 10.6, 9.7, 11.1, and 12.3. Six measure­
ments ofY at x =20are 3.1, 3.6, 3.1, 4.0, 5.2, and 2.9. Assuming that the regression 
ofY on X is linear, estimate the value ofx if two observations made at this value are 
6.3 and 7.1.
13.7.2 Using data from Problems 13.4.2 and 13.5.2, estimate the score on an entrance exam 
of a student who graduated with a GPA equal to 3.95.
13.8 BLUE
Most of the results presented thus far rely on the assumptions that the random variable Yx 
is normally distributed with constant variance and that the observations are independent. 
These assumptions allow us to use the likelihood and provide access to the distributions of 
MLE’s. The natural question is what to do if the assumptions above are not satisfied.
First, with regard to homoscedasticity, there exist numerous variance-stabilizing trans­
formations. These transformations have been suggested by statisticians as an ad hoc remedy 

452
LINEAR MODELS
against heteroscedasticity: instead of data of the form (xi, yi), one can use the data (xi, y*), 
with y* = g (yi), where g is some suitably selected function.
One can also use transformation of y’s that depend on x’s, that is, by replacing the pair 
(xi,yi) with (xi,gxi(yi)), where gx is some function [e.g., replacing (xi,yi) by (xi,yi/xi)]. 
Which transformation should be used in a given situation can be hard to resolve, especially 
when little is known about the distribution of Yx. It is rather statistical intuition and experi­
ence that can serve as a guide.
A question interesting from a both theoretical and practical point of view is what to do 
if the distribution of Yx is not normal. Suppose, for instance, that the model analyzed is 
that of linear regression Yx = a + bx + ex, where the errors ex can be assumed to satisfy the 
conditions;
(i) E(ex) = 0 (unbiasedness).
(ii) E(ex) = a2 (homoscedasticity).
(iii) E(exex,) = 0 (orthogonality).
The least squares estimators of regression coefficients a and b (which are also the MLE’s 
in the normal case) are
b = E(xi - x)(yi - y) Exi - x)yi 
E(xi - x)2 
E(xi - x)2
and a = y — bx.
The estimator of a 2 may be based on residuals, where
1n
= n-2 £(yj - a - bxj)2
j=1
is the observed value of the estimator
(n - 2)
-2 E (Yj - V - Uxi )2• 
— 2 j=1
with U, V, and T given by (13.11). Clearly, U, V, and S2 are unbiased estimators of b, a, and 
a2, with variances and covariances obtained as before. This is true because the calculations 
of moments did not rely on the assumption of normality.
It is possible to show that under the assumption of normality, U and V are also minimum 
variance estimators of b and a (i.e., that their variances coincide with the bounds given by 
the Rao-Cramer inequality).
The question is: Is there a reason to use U and V as estimators of b and a when the 
normality assumption does not hold? The mere availability of the computational formulas in 
statistical packages is hardly a justification. Unbiasedness of U and V is a desirable property 
only ifit can be related to MSE. As we have seen, there are situations where the use of biased 
estimators is recommended, as leading to smaller mean square error.
The answer is positive and is given by the following theorem (which we state here without 
a proof).
Theorem 13.8.1 (Gauss-Markov) Consider the observations (xi, Yj), i =1, 2, ...,n, 
with Yi = a + bxi + ei, where the errors ei satisfy conditions (i)-(iii) of unbiasedness, 
homoscedasticity, and orthogonality. Let L be the class of all statistics of the form
r 1Y1 + r 2 Y2 + ... + rnYn,
where ri are constants—depending possibly on the vector (x 1, ... ,xn). Furthermore, let La c 
L, Lb c L be the subsets of L consisting of statistics that are unbiased estimators of a and of 
b. Then, the statistics V and U given by (13.11 ) have minimal variances in classes La and Lb.

REGRESSION TOWARD THE MEAN
453
The acronym used here is BLUE, which stands for the “best linear unbiased estimator.” 
Thus, V is BLUE for a, and U is BLUE for b.
Note that in view of unbiasedness, “best” estimators mean those with a minimum mean 
square error. Recall that in normal case U and V are best (in the sense of MSE) estimators of 
regression parameters in the class of all estimators, linear or not. In the present case, under 
the weaker assumption the conclusion is also weaker: U and V are best estimators in a more 
restricted class of estimators, namely those that depend linearly on the data.
PROBLEMS
13.8.1 Suppose that the number of errors in a text of length x is known to be a Poisson 
random variable with unknown mean A. We observe n texts of lengths x 1, x 2, ...,xn 
and find the numbers of errors they contain, Y1, ...,Y , satisfy E(Y ) = Var(Y )= 
Axj. Find the BLUE of A. 
1 n 
j 
j
13.8.2 Carry out the calculations in the following direct proof of the Gauss-Markov 
theorem showing that the LS estimators of a and b are BLUE. For a you need 
to determine the constants ai, i = 1, ... ,n such that the statistic T = 
П=1 aiYi
satisfies the conditions: (1) E(T) = a. (2) Variance of T is the smallest among all 
linear estimators for which condition (1) holds. Show first that condition (1) implies
E aj = 1, 
E ai Xj =0. 
(13.21)
Next use the fact that Yj’s are uncorrelated and homoscedastic, and show that Var(T) 
= a2 aj, that is, minimize aj subject to constraints (13.21). Using Lagrange 
multipliers, this means that one must minimize
aj2 - A1 
(aj - 1) - A2 
ajxj.
Take the derivatives with respect to a1, ...,an, A1, and A2, solve the resulting n +2 
equations, and check that the solution aj gives the LS estimator of a.
13.8.3 Provide the same argument as in Problem 13.8.2 for the LS estimator of b.
13.8.4 Given data (xi,yi),i = 1, ...,n, find the LS estimators of the quadratic regression 
a + bx + cx2.
13.9 REGRESSION TOWARD THE MEAN
The phenomenon known as regression toward the mean was discovered in the nineteenth cen­
tury by Galton, who studied various hereditary traits. He noticed that (e.g., in using height) 
tall fathers tend to have tall sons, but their sons tend to be closer to the average than the 
fathers. Similarly, short fathers tend to have short sons, but their sons tend to be closer to 
the average than their fathers. Galton called it a “tendency toward mediocrity.” Galton’s 
choice of the word “mediocrity” may also explain why he chose the term “regression,” a 
word with somewhat derogatory connotations.
It should be realized that regression, understood as “affecting the mean of dependent 
variable Y by independent variable X,” need not imply any casual relationship between 
the values of X and Y. One of the more common types of relations between X and Y, 
that leads to the regression phenomenon and yet does not involve any casual effects of 
X on Y, is exemplified by the following situation: Imagine some attribute of objects, for 
example, length. Suppose that a person takes two observations, typically differing somewhat 

454
LINEAR MODELS
because of a measurement error, and calls the first and second measurement of the ith object 
xi and yi.
Imagine now that points (xi ,yi) are plotted, resulting in a scatter diagram. If the mea­
surement errors are small, and/or the objects measured differ in their true lengths, we will 
observe that the points (xi, yi) have a strong linear relationship with a slope close to 1.
Such a relationship will appear stronger when the variability of lengths of measured 
objects is higher. This effect is utilized in designing some psychological questionnaires.
■ EXAMPLE 13.15 Psychological Test Scores
In the areas of psychology dealing with personality or motivation (as opposed to areas 
such as memory studies, with more quantifiable experiments), a researcher typically 
introduces some construct (“neuroticism,” “self-esteem,” etc.). Those constructs 
are then used to explain and/or predict some behavior. The explanation has the 
form of specific hypotheses, such as “persons with low self-esteem are more likely 
to be aggressive,” etc. In addition to a theoretical justification of such hypotheses, 
there arises a problem of testing them empirically. Clearly, one needs here a tool 
for measuring the level of the construct (a tool to measure the level of neuroticism, 
self-esteem, etc.).
A typical tool has the form of a questionnaire and a scoring rule. For some ques­
tions, it is the answer “yes” that contributes to the total score; for some other questions 
it is the answer “no.” This is done in order to eliminate any bias arising from a possible 
tendency toward some type of answers.
When the questionnaire is applied to a subject s, one obtains the score Xs . Upon 
repetition, the score may be different, say Xs. One of the central assumptions of the 
theory of psychological tests is that the expected scores Xs and X's are equal:
E (Xs ) = E (Xs ) = Ts.
Moreover, the deviations es = Xs - Ts and es = Xs - Ts are expected to satisfy the 
conditions
Var( es )=Var( es )= a2, 
E (ese's ) = 0.
For fixed s, the value Ts (called the true value of the measured construct for person 
s) is a constant, while es is a random variable (reflecting intra-person variability of 
response to the questionnaire, upon hypothetical repetitions of measurement).
Assume now that person s is sampled from some population according to a certain 
probability distribution. Using Theorem 7.6.4, we have
aX2 = Var(X) = Es{Var(X|T)} + Var{Es(X|T)}
= E (a2) + Var( Ts) = a2 + aT.
Clearly, aX, = 02 + aT-. Similarly,
Cov(X, X') = E(XX') - E(X)E(X') = E{(T + e)(T + e')} - [E(T)]2
= E(T2) - [E(T)]2 =aT2,
since E(eT) = Es{E(eT)} = Es{TsE(e)} = E(0) = 0, and similarly for the other 
products. Thus,
P (X,X' ) = ^-2. 
(13.22)
aT + a 2

ONE-WAY LAYOUT
455
The last ratio is called the reliability of the test, and formula (13.22) shows that reli­
ability is equal to the test-retest correlation. This correlation approaches 1 with an 
increase of a'T-, that is, with an increase of variance of the true scores of the test in the 
population under study.
The reliability ofa psychological test is (unlike of the instruments for physical mea­
surements) not intrinsic for the test only but depends also on how diverse the popula­
tion is to which the test is applied.
13.10 ANALYSIS OF VARIANCE
In the remainder of this chapter, we deal with testing for the existence of the effects of an 
independent variable X (often measured on the nominal scale) on a response Y .
The standard terminology of the ANOVA is that of levels of factors. These factors cross 
each other in the sense that every level of one factor can be combined with every level of the 
other factor.
The central assumptions of ANOVA models are very much the same as in regression 
models:
(i) 
The response variable Y has, for each level of factors, a normal distribution with the 
same (unknown) variance a2 (homoscedasticity).
(ii) The factors may affect only the mean of the response.
(iii) Distinct observations for the same or different levels of factors are independent.
We show the tests for the hypothesis that a given factor has no effect on the response 
variable against the alternative that it has some effect.
The main issue here is that these tests can be carried out for various factors on the same 
data. In fact ANOVA models originated from questions arising in agriculture, where one is 
interested in the response variable (e.g., size of harvest Y) as dependent on combinations 
of various factors (e.g., type of soil, time of planting, time of harvesting, type of cultivation, 
and use of various fertilizers). Since a typical experiment lasts for one season, it is imperative 
to find a design that will allow us to study the effects of various factors using the same data. 
We begin with the simplest case of one factor only.
13.11 
ONE-WAY LAYOUT
Consider the situation where the data are partitioned into groups, each corresponding to one 
level of a factor. Alternatively, the same setup may be described as “independent samples 
from different populations.”
We let ni denote the number of observations from the ith group, where i =1, ...,I.We 
have here I > 2 and ni > 2 for at least one i.
Let n 1 + n 2 + • • • + nI = N be the total number of observations, and let yi 1 ,yi 2, ..., yin 
be the observations corresponding to the ith level of the factor. These observations are 
regarded as the recorded values of the random variables Yi1, Yi2, ...,Yini .
According to the assumptions stated at the beginning of this section, all random variables 
Yij are independent, normally distributed, with Var(Yij) = a2. Moreover, since the effect of 
a factor is expressed only through the mean, we must have
E(Yij )= Pi 
j = 1 ,...,ni.
The objective is to test
H0 : у 1 = у2 = • • • = ^I against 
H 1 : yi = yi, for some i, i'.

456
LINEAR MODELS
It will be convenient to let
Mi = M + ai, 
i = 1, ... ,I,
where
M1 + • • • + MI
Mi =-------- T--------
(13.23)
We have therefore 
I
ai = 0,
and the hypotheses tested can be formulated as
H0 : a 1 = a2 = • • • = aI = 0 against 
H 1 : ai = 0 for at least one i.
Before we develop the testing procedure, let us observe that if I =2, we have the prob­
lem of comparing the means of two normal populations with the same (unknown) variance 
a2. This problem was solved in Chapter 12 (Section 12.9). The testing procedure used the t 
distribution with n1 + n2 - 2 degrees of freedom.
It would seem that if I>2, we can use this result for the present case by comparing pairs 
of levels of the factor until either we find a pair where the difference is significant (and then 
we reject H0) or we find no significant difference in all pairs tested (in which case we accept 
H0). The reason why such a procedure is unacceptable lies in the fact that it is impossible 
to determine its significance level because (i) the procedures for overlapping pairs of factor 
levels are not independent and (ii) even for nonoverlapping pairs, if the null hypothesis is 
true, the chances of at least one incorrect rejection of null hypothesis increases quickly with 
the number of tested pairs.
Consequently, the objective is to find a procedure that can test the null hypothesis 
of no effect of the factor with a preassigned level of significance. The construction 
here will be based on a partition of the sum of squared deviations from the mean, 
which is very much similar to the technique used for testing linearity of regression in 
Section 13.6.
In the derivation below, the subscript + will stand for averaging over the values of the 
index replaced by +. Thus
1 ni 
1 ni
Y i + = ~ 
Yij, 
yi + = n 
yij,
and
Y++ = n 
Yj = n 
ni Y i+,
i=1 j=1 
i=1
and similarly for y++.
In the identities below, we omit the cross-products. We encourage the reader to verify 
that all the cross-products are indeed zero. Using the fact that by (13.23) we have E(Yij) = 
M + ai, we decompose the sum of squared deviations of the variables from their means as 
follows:
S 2 = 
(Yj - M - ai )2 = 
(Yi^j - Y i + + Y i + - M - ai )2
i=1j=1 
i=1 j=1
= 1L 
(Yj - Yi +)2 + 
(Yi + - M - ai)2 
(13.24)
i=1j=1 
i=1

ONE-WAY LAYOUT
457
= ЕЕ (Yij - Y i +)2 + E ni (Y i + - Y ++ + Y ++ - M - ai )2
i=1 j=1 
i=1
= EE (Yij - Y i +)2 + E ni (Y i + - Y ++ - ai )2 + N(Y ++ - M )2 .
i=1 j=1 
i=1
Under the assumption that Yij are normally distributed, the three terms in the last row 
are independent random variables. Moreover, the first term, upon division by a2, has the 
chi-square distribution with the number of degrees of freedom equal (n 1 - 1) + • • • + (nI - 
1) = N - I regardless of whether or not the null hypothesis is true. The second sum, again 
upon division by a2, has the chi-square distribution with I - 1 degrees of freedom, provided 
that E(Yi + - Y++) = ai for every i. Thus, under H0, the sum
1 
_ _
_ E ni (Y i + - Y++)2 
(13.25)
i=1
has a chi-square distribution with I - 1 degrees of freedom, and any violation of H0 will 
increase the expectation of the sum (13.25). This suggests the use of an appropriate F ratio 
to test the hypothesis H0. _
Finally, if m = 0, then N(Y++)2/a2 has the chi-square distribution with one degree of 
freedom, which allows us to test hypothesis H0 : m = 0 against the alternative H 1 : m = 0. 
In terms of observations, the testing procedure is most often displayed in the form of the 
following ANOVA table:
I
SSM = N(y++)2, 
SSA = Eni(y++ - y++)2,
i=1
Source of 
variation
Degrees 
of freedom
Sum of 
squares
Mean sum 
of squares
F ratio
Mean
1
SSM
MSM = SSM
FM = MSsM
Factor
I-1
SSA
MSA = S-A
FA = MSR
Residual 
Total
N-I
N
SSR
SST
MSR = NR
where
SSR = ib t,ni(yij - Vi +)2, 
SST = E E yj.
i=1 j=1 
i=1 j=1
We reject the hypothesis H0 : a 1 = • • • = aI = 0 (at level у) if the ratio FA exceeds the 
upper quantile FY,I- 1 ,N-I. It is important to remember that in ANOVA one always uses a 
one-sided critical region (since any violation of H0 tends to increase the numerator without 
affecting the denominator).
If, for some reason, one is interested in the hypothesis H0 : m = 0, then one should reject 
it in favor of H1 : m = 0 if the ratio FM exceeds F 1 ,N-I. Such a test is useful if observa­
tions can be positive as well as negative (e.g., deviations from the required standards in a 
technological process).

458
LINEAR MODELS
PROBLEMS
13.11.1 Verify that the cross-products in (13.24) do indeed equal zero.
13.11.2 To test the mileage achieved by cars produced by different companies, but of com­
parable price, size, and so on, one make of cars was selected from among the three 
major American companies and two foreign companies. For each make selected, a 
number of new cars was chosen and their mpg (miles per gallon) recorded. The data 
(in mpg) are as follows:
n1 =5
n2 =4
n3 =5
n4 =3
n5 =6
25.1
27.1
39.9
25.4
29.2
26.2
26.4
21.4
28.2
29.3
24.9
26.8
22.2
27.1
30.4
25.3
27.2
22.5
28.5
23.9
20.8
28.9
29.2
At the significance level 0.05, test the hypothesis that the average mpg is the same 
for all makes of cars tested.
13.11.3 Suppose that we take a random sample of size n from a normal distribution 
N(p,a2). We divide the observations into k groups of sizes n 1, ...,nk, where 
ni > 2 for i = 1, ... ,k and n 1 + • • • + nk = n. Let S be the sample variance in 
the ith group. Find: (i) The distribution of [(n 1 - 1)S2 + • • • + (nk - 1)S2]/a2. (ii) 
The distribution of Sk2/S12.
13.11.4 Show that the test developed in this chapter is equivalent to the Student’s t test for 
the case when the factor operates at two levels only.
13.12 TWO-WAY LAYOUT
Assume now that we have data concerning possible effects of two factors, A and B, with I 
and J levels, respectively. Let yij be the observation for the ith level of A and the jth level of 
B . Such data can be arranged into a matrix [yij ] with I rows and J columns. For the moment 
assume that we have one observation in each of the IJ cells formed by crossing factors A 
and B. As before, we regard yij as the recorded value of a random variable Yij, assumed to 
have normal distribution Yij ~ N(^ + ai + ej ,a2), where ai and ej represent the effects of 
factors A and B . Without loss of generality, we can write
IJ
ai = 
ej =0.
i=1 
j=1
(13.26)
We want to construct a test for the hypothesis
H0A) : a 1 = • • • = aI = 0 against 
H(A) : ai = 0 for some i, 

TWO-WAY LAYOUT
459
as well as a test for
H0( B) : в 1 = • • • = в J = 0 against 
H( B) : ^j =0 for some j.
The tests are built on a partition of the sum of squares, as in the case of one factor. Omitting 
again the cross-products (which are zero), we have
S2 = 
(Yij — V — ai — вз)2
i=1 j=1
= 
(Yij — Y++ + Y++ — V — ai — ej)2
i=1 j=1
=t ib ( Yij Y ++ 
ai ej )2 + IJ ( Y++ 
V )2
i=1 j=1
= 
(Yij — Y i + — Y + j + Y++)2 + 
J(Y i + — Y++ — ai )2
i=1 j=1 
i=1
J
+ 
I(Y+ j — Y++ — ej )2 + IJ(Y ++ — ^)2 .
j=1
Substituting the observed data for random variables and letting ^ = 0, ai = ej =0 for 
all i, j, we obtain the following sums of squares:
SSM = IJ (y ++)2, 
SSA = 
J (y+ + - y ++)2,
i=1
SSB = 
I(y+j — y ++)2 , 
SSR = 
(yij — y++ — y + j + y++)2 ,
i=1 
i=1 j=1
which add up to the total sum of squares
SST=ib ib y2j.
i=1 j=1
The four terms in the last decomposition ofS2 are independent random variables. The SSR 
does not involve any parameters and (upon division by a2) has a chi-square distribution with 
the number of degrees of freedom equal to
IJ— (I— 1) — (J— 1) — 1=(I— 1)(J — 1),
regardless of whether the hypotheses are true or false. The SSA sum has a chi-square dis­
tribution if a 1 = • • • = aI =0, and a similar statement holds for SSB if в 1 = • • • = в J = 0. 
The numbers of degrees of freedom are I — 1 and J — 1, respectively. Any deviation from 
the null hypothesis tends to increase the corresponding sum of squares.

460
LINEAR MODELS
The ANOVA table is now:
Source of
Degrees
Sum of
Mean sum
variation
of freedom
squares
of squares
F ratio
Mean
1
SSM
MSM
SSM 
-
FM
MSM
= MSR
A
I-1
SSA
MSA = SSA
: 7—T
FA
MSA
= MSR
B
J-1
SSB
MSB = SSB 
: —
FB
MSB
= MSR
Residual
(I-1)(J-1)
SSR
MSR =
SSR
(I-1)(J-1)
Total
N = IJ
SST
The hypothesis H0(A) (that factor A has no effect) is rejected whenever FA > 
FY,I -1, (I—1)( J — 1), and H0 B) is rejected if FB > FY,J -1, (I-1)( J-1), where Y is the 
desired level of significance.
PROBLEMS
13.12.1 Twelve subjects participated in a study comparing the effectiveness of three 
weight-reducing diets. The subjects were grouped according to their initial weight, 
and each of three subjects from each initial weight group was randomly assigned 
to a diet. The weight loss (in pounds) at the end of the experimental period is given 
below:
Diet
Initial Weight
A
B
C
150-174
10
23
24
175-199
12
21
26
200-224
12
31
21
Over 224
20
28
33
(i) Do these data provide sufficient evidence that (after eliminating the effect of initial 
weight) the diets are different in their effectiveness? Use a = 0.01. (ii) Does the initial 
weight affect the loss of weight?
13.12.2 The nutritional value of a certain vegetable is measured on 18 specimens grown in 
two varieties in three geographical regions. The data are as follows:
Variety
Geographical Region
A
B
C
6.3
9.2
6.8
1
11.5
5.1
7.2
9.2
8.1
5.5
11.0
5.4
7.1
2
7.3
5.0
7.8
8.2
6.1
8.4

ANOVA MODELS WITH INTERACTION
461
Study the effect of variety and geographical location on the nutritional value, taking 
the average of three observations in each cell as a response. Use the significance level 
a = 0.05.
13.12.3 The model for three factors is E(Yjjk) = ^ + ai + в, + Yk, where 
ai = 
в, =
Yk. Assume that Yjjk is normally distributed with variance a2. Derive the tests 
for the hypotheses analogous to those in the case of two factors.
13.13 ANOVA MODELS WITH INTERACTION
The model considered in Section 13.12 was of the form E(Yi,) = ^ + ai + в,, by which we 
assume that the effects of the factors A and B are additive. The hypotheses H0(A) and H0(B) 
are tested within this model.
In general, the effects of A and B need not be additive, and one might wish to consider 
the case where E(Yij ) is an entirely arbitrary function ofi and j. Such a function can always 
be represented in the form
E (Yij ) = ^ + ai + в, + Yij,
where iai = ,в, = i,Yi, =0 for all i,j (we leave the proof as an exercise). 
The constants Yij are referred to as interaction terms. Testing for the presence of 
interaction is based on an idea similar to that used in testing linearity of regression. 
It requires a model-independent estimate of a2, which in turn can be achieved if we 
have more than one observation for each combination of levels of factors A and B . 
We assume therefore that the data now have the form of a three-dimensional array 
yijk ,i = 1 ,...,I; j = 1 ,...J; k =1 ,...,K, where I > 2 ,J > 2 ,K > 2. Leaving the 
details of the derivation as an exercise, we can write the decomposition of the sum of 
squared deviations of the random variables Yijk from their means as
IJK
S2 = 
(Yijk - ^ - ai - в, - Yij)2
i=1j=1 k=1
= IJK(Y+++ - M)2
IJ
+ 
JK(Yi++ - Y+++ - ai)2 + 
IK(Y+j + - Y+++ - вз)2
i=1 
j =1
+ 
K(Yij + - Yi++ - Y+j + + Y+++ - Yij)2
i=1 j=1
IJK
+EEE< j -Y j,+)2. 
(13.27)
i=1 j=1 k=1
As before, the last sum (upon division by a2) has the chi-square distribution with IJ(K - 
1) degrees of freedom, given only normality and homoscedasticity (regardless of any other 
hypotheses tested). Thus, it can serve as a denominator in all F ratios used for testing, while 
the two single sums and the double sum can be used to test the hypotheses about the effects of 
A,ofB, and of their interaction. To put it differently, each of the sums above, divided by its 
number of degrees of freedom, is an unbiased estimator of a 2 if the appropriate hypothesis 

462
LINEAR MODELS
is true (except for the last sum, for which this holds regardless of any hypothesis). Letting 
SSM = ijk (y+++)2,
SSA = 
JK(У+++ - y+++)2,
i=1
SSB = £ IK (y+j + - y+++)2,
j=1
SSAB = ib ib K(yij + yi++ y+j + + y+++)2,
i=1 j=1
SSR = lb lb lb (yjk y yj,+)2,
i=1 j=1 k=1
IJK
SST = EEE y2,k,
i=1 j=1 k=1
the corresponding ANOVA table is as follows:
■ EXAMPLE 13.16
Source of 
Variation
Degrees 
of Freedom
Sum of 
Squares
Mean Sum 
of Squares
F Ratio
Mean
1
SSM
MSM = SSM
FM = MSM
A
I-1
SSA
MSA = S—A
FA = MSR
B
J-1
SSB
MSB = S-B
FB = MSR
AB
(I - 1)(J -1) SSAB
SSI
MSAB = (i—1)( j -1)
FAB = MSR
Residual
IJ(K -1)
SSR
MSR = IJSSKR1)
Total
N = IJK
SST
A researcher studies the effects of sex and type of stimulus (“soothing” or “exciting”) 
on the aggressive behavior of parrots. Six male and six female birds of a given species 
are each placed in a separate cage isolated from other cages. The six birds of a given 
gender are randomly divided into two groups. The cages are covered for the night. 
Before uncovering the cage in the morning, the birds hear a tape. One is a “soothing” 
tape, with the voice of the experimenter talking quietly to the birds. The other tape 
contains angry voice of the experimenter. The observed value Y is the number of times 
the bird attacks the experimenter’s hand when she uncovers the cage and puts food into 

ANOVA MODELS WITH INTERACTION
463
the plate. The data are as follows (the three numbers in each cell represent the data for 
three birds):
Soothing (S) 
Angry (A)
M 
8613 
222833
F 
5106 
12149
The within-cell averages yij + and row and column averages Yi + ,y+j, as well as
y++ are
SA
M 
9 
27.67 
18.33
F 
7 
11.67 
9.33
8 
19.67 
13.83
The SSR of the squared deviations from cell means is SSR =1, 113.33. We there­
fore have the next table:
df
SS
MS
F
Mean
1
2,296.33
2,296.33
162.10
Gender
1
243.00
243.00
17.15
Stimulus
1
408.33
408.33
28.82
Interaction
1
147.00
147.00
10.38
Residuals
8
113.33
14.17
Since F0.05,1,8 = 5.318, we can conclude that both the gender of the parrot and 
the type of stimulus have an effect, and there is interaction between gender and type 
of stimulus at the 0.05 significance level. The mean response is significantly different 
than zero.
To better grasp the meaning of interaction, we will use a graphical representation. Let 
us arrange the categories of one factor, say A, along the horizontal axis (there may be no 
numerical values attached, and the categories need not have any “natural” order). Then along 
the horizontal axis, we can plot average responses yij + for various j. The effects of A, B and 
of their interaction can now be interpreted as follows (see Figure 13.4).
The effect of A means that at least one of the curves differs significantly from the hor­
izontal line (last two figures). The effect of B, but not of any interaction, means that the 
curves for various levels ofB are parallel to one another but significantly different from one 
another (Figure 13.4b and c). Finally, the interaction reveals itself by the lack of parallelism 
of the curves (Figure 13.4d).

464
LINEAR MODELS
(a)
Levels of A
(b)
Levels of A 
(c)
(d)
Figure 13.4 (a) No effects of A, B or AB . (b) No effect of A, effect of B, no interaction. (c) Effect of 
A, no effect of B, no interaction. (d) Effect of A, effect of B, effect of interaction.
PROBLEMS
13.13.1 The scores measuring the level of emotional maturity of young adult males classified 
by age and extent of use of marijuana are given below.
Age
Never
Marijuana use 
occasionally
Daily
25
18
17
15-19
28
23
24
22
19
19
28
16
18
20-24
32
24
22
30
20
20
25
14
10
25-29
35
16
8
30
15
12
Test for effects of age, extent of use, and their interaction. Use a = 0.05.
13.13.2 Use data given in Problem 13.12.2 to test for the existence of interaction between 
variety and geographical notation.
13.13.3 Show that if E (Yj) = c (i, j) = ^ + ai + ej + Yij, where i = 1, ... ,I,j = 1, .. .,J, 
then one can always find constants p,, ai, ej, and Yij such that
ai = 
ej = 
Yij = 0.
i=1 
j=1 
i=1 j=1

FURTHER EXTENSIONS
465
13.14 FURTHER EXTENSIONS
The ANOVA models presented in the last three sections can easily be extended to the case 
of more than two factors, with or without interaction, provided that we consider completely 
balanced designs. Each level of a factor can be combined with all combinations of levels of 
other factors, and in each cell we have the same number of observations. Testing for inter­
actions is possible only if the number of observations per cell is at least two. The number of 
observations needed very quickly becomes unattainable practically. For instance, with three 
factors, each on five levels, we need 53 = 125 observations, and twice that if we want to test 
for interactions.
This situation led to research in two major directions. The first was to invent experi­
mental schemes that allow testing for the presence of effects (as well as estimation of those 
effects) with as small a number of experiments as possible. If one resigns from the stringent 
requirement that every level of a factor has to appear with every combination of levels of 
other factors, there are many possibilities of experiments (e.g., forming the so-called Latin 
or Greco-Latin squares). To use a simple example, imagine that we have three factors, each 
appearing on five levels. Representing one factor as a row, the other as a column, and the 
third as letter (with levels a, b, c, d, e), we can arrange the experiment as follows:
a
b
c
d
e
b
c
d
e
a
c
d
e
a
b
d
e
a
b
c
e
a
b
c
d
Each level of the first factor (row) combines exactly once with each level of the second 
factor (column), and exactly once with the third factor (letters). The same is true for the 
other two factors. However, of 53 = 125 possible combinations, only 25 actually appear.
It is possible to include here the fourth factor (e.g., Greek letters, a, в, Y, S e) as follows:
aa
be
cy
dS
ee
be
ca
de
ey
aS
cS
de
ea
aft
by
dy
eS
ae
ba
ce
ев
ay
bS
ce
da
Now each row and each column has exactly one of the Roman letters and exactly one of 
the Greek letters, and each Roman letter is combined exactly once with each Greek letter.
One can therefore plan an agricultural experiment (say) in which in each row are plants of 
one of five varieties of seed, and in each column one of the five varieties of fertilizers. Then, 
each Roman letter would correspond to one of the five different amounts of watering, and 
each Greek letter to one of the five different times of planting.
There are seemingly countless variety of experimental designs to cover all contingencies 
that occur in practice, each design with its own testing or estimation procedures. By intro­
ducing appropriate criteria, one can search for designs that optimize these criteria.

CHAPTER 14
RANK METHODS
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
467
14.1 INTRODUCTION
This chapter is devoted to statistical tests applicable to data measured on ordinal scales only 
and more precisely, when only ordinal relations are taken into account. These methods32 fall 
under the general heading “nonparametric statistics,” and they involve techniques based on 
ranks, which offer several advantages. While the data sampled must be from a continuous 
distribution, the type of the distribution is irrelevant. Nonparametric methods are almost 
as powerful as normal theory methods. They can therefore be applied when a population 
distribution is not normal (e.g., it is skewed) or if the sample size is not large enough for 
testing normality.
■ EXAMPLE 14.1
Suppose that four observations randomly selected from some population are x1 = 
8,x2 =7,x3 =3,x4 =15, and five observations from another population are y1 = 
5,y2 =4,y3 =0,y4 =6,y5 =1. If the data are expressed on the ordinal (but not any 
higher) scale, these data contain the same information as such data as x1 = 1,000, x2 = 
32,x3 =30,x4 = 1,001,y1 =35,y2 =31,y3 = -5,y4 =36,y5 =0. In effect all rele­
vant information is contained in the sequence
YYXYYYXXX,
which tells us that the observations from the first sample occupy places 3, 7, 8, and 9 
in the ordered combined sample.
32See Hollander and Wolfe (1999) for an exhaustive presentation.

468
RANK METHODS
Methods based on ranks should be used for the data measured on an interval scale. They, 
however, can be used for the data measured on an interval or ratio scale. In other words, one 
can always use methods for a weaker scale.
The assumption of continuity is what distinguishes the methods of this chapter from the 
methods of categorical data that sometimes are also of an ordinal character (discussed in 
Chapter 15) and exemplified by questionnaire responses such as “strongly agree,” “agree,” 
“neutral,” “disagree,” “strongly disagree.” The essential difference is that under the assump­
tion of a population distribution being continuous, we can disregard ties in our theoretical 
considerations. Practically, it means that ties in the data are rather exceptional.
We begin with the study of the behavior of empirical cumulative distribution functions 
(cdf’s). The empirical cdf converges almost surely and uniformly to the cdf of the underlying 
random variable. This is a general fact, and itis true regardless of whether or not the random 
variable is continuous. If we restrict the analysis to the continuous case, we can construct a 
test for the hypothesis that the random sample X1, ...,Xn comes from a population with a 
specific continuous cdf.
Next we will consider the two-sample problem, tests of the hypothesis that two random 
samples (X1 , ...,Xm) and (Y1 , ...,Yn) come from the same continuous distribution. We 
will also introduce tests for randomness and present procedures for testing hypotheses about 
population medians in one, two, and more than two populations. Last, we will present an 
analysis of variance (ANOVA) type of inference in case of response distribution that is other 
than normal.
Fn(t)
14.2 GLIVENKO-CANTELLI THEOREM
Let Xn = (X1, ...,Xn) be a random sample from some population. Specifically, this means 
that X 1, ... ,Xn is the initial fragment of a sequence X TO = {Xi, i = 1, 2, ... } of iid ran­
dom variables. We let F denote the common cdf of Xi’s so that F (t) = P {Xi < t} .At the 
moment, we can make no assumptions about the nature of F . We only know that F is an 
arbitrary nondecreasing right-continuous function, satisfying
lim F(t) = 1, lim F(t)=0 
t—>^> 
t—> — ^
(see Chapter 5). For any n and t, we define the empirical cdf of the sample X1, ...,Xn as 
number of data values that do not exceed t
n
Thus Fn(t) is a step function that increases by 1/n (or by a multiple of 1/n) at each point 
of the sample. It is important to keep in mind that Fn (t) is a random function. It depends 
formally on the sequence XTO but in fact only on the first n observations.
Ifwe fix the value t, then nFn(t) is a random variable, equal to the number of Xi’s among 
the first n observations, satisfying the condition Xi < t. Thus nFn(t) has a binomial dis­
tribution with parameters n and p = P{Xi < t} = F (t). Consequently, by Theorem 9.5.20, 
for every t,
Fn (t) = nFn& ^ F (t) 
(14.1)
nn
with probability 1.
To appreciate the meaning of this result, and the meaning of its extension below, let us 
write explicitly Fn(t, X), where X = XTO. Since X is the element of the sample space corre­
sponding to sampling an infinite sequence of values of iid random variables, each with cdf 
F, the phrase “with probability 1” or “almost certainly” means “for all sequences X, except 
sequences in a set N with P(N) = 0.”

GLIVENKO-CANTELLI THEOREM
469
Specifically, (14.1) means that for every t there exists a set Nt of sequences X such that 
P (Nt) = 0 and if X / Nt, then
lim Fn(t,X) = F(t). 
(14.2)
n—>^>
The following theorem is an extension of this result to the convergence for all t at once, 
and uniform:
Theorem 14.2.1 (Glivenko-Cantelli) As n ^ ж, we have
sup Fn (t ) — F (t ) | ^ 0
t 
with probability 1.
Proof: The theorem means that one can find a set N of sequences X suchthatP(N)=0and 
suptIFn(t, X) - F(t)| ^ 0 as n ^ ж for all X / N. We show first that such a common set 
N exists for convergence Fn(t) to F(t) for all t (convergence being not necessarily uniform). 
Let A be the set of all points at which F is discontinuous. Since F is nondecreasing and 
continuous on the right, the condition t A A means that F (t) - F(t—) > 0, where
F (t—) = lim F (т) = sup F (т). 
T—t- 
T<t
If t A A, we define the random variables
1
Un(t) = Un(t, X) = 
0 ifXn = t 
ifXn = t,
(14.3)
so that E[Un(t)] = P{Un(t) = 1} = F(t) - F (t-). Clearly, the random variables U1 (t), 
U2 (t), ... are iid, and by Theorem 9.5.20, we have
1n
Uj (t, X) ^ F (t) — F (t-) 
n j=1
for all X A Nt, where P(Nt) = 0. Here, Nt is the “exceptional” set chosen for specific t.
Clearly, the set A is at most countable. Indeed, if Ak c A is the set of points t A A with 
F (t) — F(t—) > 1 /k, then Ak has at most k elements because of monotonicity of F and the 
condition F(ж) — F(—ж) = 1. Since A = Jk Ak, the set A is at most countable, and the 
condition (14.3) holds for all X / JtEAN*, with
P (U Nt) ^ E P (Nt ) = 0. 
t.A 
t.A
Now let Q be the set of all rational t (or any other countable dense subset of real line). 
We may assert that Fn(t) ^ F(t) for all t A Q with probability 1, since by (14.2) we have 
Fn (t, X) ^ F(t) for all t if X / U tEQNt, and again P (U tEQNt) ^ E tEQP (Nt ) = 0.
Thus we showed that with probability 1 we have Fn (t) ^ F(t) for all t Q Q and Fn (t) — 
Fn (t—) ^ F(t) — F(t—) for all t A A. We will next show that with probability 1 we also have 
Fn (t) ^ F (t) for all t / A, and that the convergence is uniform. These last statements do not 
involve any probability considerations: They are true for any X / (JtEANt) U tEQN^, 
so one may suppress the dependence on X and consider a fixed sequence of cdf’s Fn(•).
Thus let t be a continuity point of F, and let t / Q. We want to show that Fn (t) ^ F (t). 
Let e > 0, and let t 1, t2 Q Q satisfy the relations t 1 < t < t2 and
F (t 2)—F (t 1) < 2
(14.4)

470
RANK METHODS
(which is possible because t is a continuity point of F). Next we choose N such that for 
n > N,
IFn (t 1) - F (t 1) | < 2 and Fn (t 2) — F (t 2) | < 2 • 
(14.5)
This is possible because Fn (ti) — F(ti) as n — ж for i = 1, 2. By monotonicity of F we 
have F(t 1) < F(t) < F(t2); hence by (14.4),
F(t2) - 1<F(t) <F(t 1) + !•
Using (14.4), (14.5), and monotonicity of Fn(•), we can write for n > N,
F(t) < F(t2) < F(t 1) + - < (F (t 1) + -+ - < F (t) + e 
2 
1 n1 
n
F(t) > F(t2) — - > fF„(t2) — -) — - > F„(t) — e, 
2 n2 
n 
,
which gives \Fn(t) — F(t)| < e. It remains to prove that the convergence Fn(t) — F(t) is 
uniform, that is, supt\Fn (t) — F(t) | — 0 as n — ж. The proof is after Chung (2001).
Now assume the contrary. There exists e0 > 0, and sequences nk and tk such that 
\Fnk (tk) — F(tk) | > e0 for all t. Since Fn(•) and F(•) are cdf’s, we cannot have tk — + ж or 
tk — —ж; hence the sequence {tk} is bounded. Without loss of generality we can assume 
that tk —t t*.
Moreover, there exists either a subsequence of {tk } which converges to t* monotonically 
from below or monotonically from above. Similarly, since \Fnk(tk) — F(tk)| > e0, there 
exists either a subsequence at which Fnk (tk) > F(tk) + e0 or a subsequence at which 
Fnk (tk) < F(tk) — e0. Restricting the analysis to these subsequences, we distinguish four 
cases:
1. tk J t*,tk <t*,Fnk(tk) >F(tk)+ e0.
2. tk J t*,tk <t*,Fnk (tk) <F(tk) — e0.
3. tk I t*,Fnk (tk) >F(tk) + e0.
4. tk I t*,Fnk (tk) <F(tk) — e0.
We will select t', t" e Q such that t' <t* < t".
In case 1, using the monotonicity of Fn and F, we can write, for all k sufficiently large,:
60 < Fnk (tk ) — F(tk ) < Fnk (t* — ) — F (t')
< Fnk (t* —) — Fnk (t*) + Fnk (t") — F (t") + F(t") — F(t') •
If we let k — ж, the difference Fnk (t* —) — Fnk (t*) converges to —(F (t*) — F(t* —)), and 
the difference Fnk (t") — F(t") converges to 0. Letting t" ^ t*, t' J t* along values in Q, the 
last difference converges to F (t*) — F (t*—). Thus the right-hand side can be made as small 
as possible, which gives a contradiction.
In case 2, we have
e0 < F(tk) — Fnk (tk) < F(t*—) — Fnk (t') < F(t* —) — F(t') + F(t') — Fnk (t') •
Letting k — ж, we obtain F (t') — Fnk (t') — 0, and letting next t' J t*, weobtain F (t*—) — 
F(t') — 0, which gives another contradiction.
In case 3, we have
0 <Fnk (tk) — F(tk) <Fnk (t") — F(t*)
< Fnk (t") — Fnk (t') + Fnk (t') — F (t) + F(t) — F(t*) •

KOLMOGOROV-SMIRNOV TESTS
471
Now Fnk (t") - Fnk (t') ^ F(t") - F(t'), while Fnk (t') - F(t') ^ 0. We let t" ^ t* and use 
the continuity of F on the right, which results in the term F(t") — F (t') converging to 
F (t*) - F(t'). So we again have a contradiction.
Finally, in case 4, we can write
eо < F(tk) - Fnk (tk) < F (t") - Fnk (t*)
< f(t") - F(t') + F(t') - Fnk (t') + Fnk (t* -) - Fnk (t*).
As k ^ ж we have F(t') - Fnk (t') ^ 0, while Fnk (t*-) - Fnk (t*) ^ F(t*-) - F(t*). Let­
ting now t' f t* and t" ^ t*, we have F(t") - F(t') ^ F(t*) - F(t*-), which also leads to 
contradiction. 
□
PROBLEMS
14.2.1 Let F(t)=0for t<0, F(t)=p for 0 < t<1, and F(t) = 1 otherwise. Use the cen­
tral limit theorem to evaluate directly the distribution of supt|Fn(t) - F (t)|, and 
show that Fn (t) tends to F(t) almost surely and uniformly in t.
14.2.2 Let X be a random variable such that P {X = a} = 1/2,P{X = b} =1/3 and 
P {X = c} = 1/6. Let X1 ,X2 , .. .,X200 be a random sample from the distribution 
of X. Suppose that among the first 100 observation of Xi ,55wereequaltoa and 
38 were equal to b. Among the next 100 observations, 51 are equal to a, and 30 
are equal to b. Determine supt|F200(t) - F (t)| and supt|F100(t) - F (t)| in all six 
cases a<b<c, a<c<b, b<a<c, and so on, as well as in all cases such as 
b = c<a,a= b< c, ...,and a = b = c.
14.3 KOLMOGOROV-SMIRNOV TESTS
One-Sample Kolmogorov-Smirnov Test
Let
Dn = sup|Fn(t) - F (t)|. 
(14.6)
t
The distance Dn converges a.s. to zero if the Fn’s are empirical cdf’s of random samples 
drawn from distribution F. Research on the rate of this convergence, that is, finding con­
stants cn ^ ж such that the sequence of random variables {cnDn,n > 1} has a limiting 
distribution, led to a remarkable discovery, due to Kolmogorov and Smirnov: ifF is contin­
uous, then this limiting distribution exists for cn = ^n., and moreover, it does not depend on 
F.
The following theorem specifies this limiting distribution, and serves as a foundation for 
a test of the hypothesis that a random sample comes from a specific distribution. We will 
omit the proof here.
Theorem 14.3.1 (Kolmogorov and Smirnov) Let X1, X2, ... be iid random variables, with a 
continuous cdf F. Then for every z>0,
lim P[/nDn < z} = Q(z), 
n—>^>
where 
^
Q(z) = 1 - 2 
(-1)k-1 e-2k2z2. 
(14.7)
k=1

472
RANK METHODS
The function Q(z) is a cdf of a continuous distribution called a Kolmogorov distribution. 
The values of this cdf are given in Table B2.
Suppose now that we want to test the hypothesis
H0 : F = F0 
against the alternative 
H1 : F = F0 ,
where the hypothetical cdf F0 is continuous. Under the null hypothesis, for large n, the dis­
tribution of /nDn is given by Q (x). If the true distribution of Xi’s is F*, we can write
sup IFn (t) - Fo( t) | < sup {IFn (t) - F * (t) | + IF * (t) - Fo( t) I}
< sup IFn (t ) - F * (t ) | +sup IF * (t ) - F0( t ) |
= Dn + sup IF *(t) - F0(t)I. 
t
Upon multiplication by /n, the first term, /nDn, has the limiting distribution (14.7), while 
the second term /Пsupt\F*(t) - F0(t)I tends to infinity if F*(t)^F0(t).
The last property means that the test should reject H0 if the observed value of the statistic 
/nDn exceeds the critical value determined from the right tail of the distribution (14.7). 
This test has—in the limit—power 1 against any alternative.
■ EXAMPLE 14.2
A small town had 30 fires last year: on January 5 and 18, February 3, 4, 21, and 26, 
March 5, 10, and 13, April 6, May 16 and 25, June 19, July 10 and 21, August 12 and 
15, September 1, 8, and 21, November 2, 6, 7, 19, and 29, December 3, 9, 12, 17, and 24. 
Are these data consistent, on the 0.05 level, with the hypothesis that the occurrences 
of fires follow a Poisson process?
SOLUTION. One of the solutions may be based on the fact that if the fires form a Pois­
son process, then they occur throughout the year according to the uniform distribution. 
The data are summarized in Table 14.1
Since Fn (•) is a step function, it suffices to inspect only the differences 
IF(xi) - Fn(xi)I and IF(xi) - Fn(xi- 1) I. The largest difference in Table 14.1 is 
F(x21) - F30(x20)=0. 838 - 0.667 = 0.171, and /nDn = /30 x 0.171 =0.937. 
Since (see Table A2) P{/nDn > 0.9} = 1 - 0.6073 = 0.3927, there is no reason to 
reject the null hypothesis that the fires form a Poisson process.
It is important to realize that the Kolmogorov-Smirnov test applies only when the null 
hypothesis specifies completely the distribution F . The test cannot be used in cases where 
the null hypothesis specifies only the distribution type but does not provide the values of the 
parameters. If one estimates parameters from the sample to obtain a specific distribution 
F*, F *(x) is then a random cdf that depends on the sample, and consequently the limiting 
distribution of /nDn = /nsupx\Fn(x) - F*(x)I will not given by formula (14.7).
■ EXAMPLE 14.3
In this application of the Kolmogorov-Smirnov test we will regard points distributed 
uniformly on a circle. The quality of the estimation depends heavily on how good the 
method is that is used for generating random points in the circle.
Without loss of generality, we can assume that the circle is x2 + y2 < 1. Letting 
£ 1, £2 be a pair of independent random variables distributed uniformly on [0, 1], we let

KOLMOGOROV-SMIRNOV TESTS
473
Table 14.1 The data for Example 14.2.
Fire
i
Day 
xi
Fn(xi) 
= i/30
F (xi)
= xi/ 365
Fire
i
Day 
xi
Fn(xi) 
= i/30
F(xi)
= xi/ 365
1
5
0.033
0.014
16
224
0.533
0.614
2
18
0.067
0.049
17
227
0.567
0.622
3
34
0.100
0.093
18
244
0.600
0.668
4
35
0.133
0.096
19
251
0.633
0.688
5
52
0.167
0.142
20
264
0.667
0.723
6
57
0.200
0.156
21
306
0.700
0.838
7
64
0.233
0.175
22
310
0.733
0.849
8
69
0.267
0.189
23
311
0.767
0.852
9
72
0.300
0.197
24
323
0.800
0.885
10
96
0.333
0.263
25
333
0.833
0.912
11
136
0.367
0.373
26
337
0.867
0.923
12
145
0.400
0.397
27
343
0.900
0.940
13
170
0.433
0.466
28
346
0.933
0.948
14
191
0.467
0.523
29
351
0.967
0.962
15
202
0.500
0.553
30
363
1.000
0.995
x = 2£ 1 - 1, y = 2£2 — 1 and then check whether x2 + y2 < 1. If yes, the pair (x, y) is 
accepted. If not, we sample a new pair (£ 1, £2), and proceed in this way until we obtain 
an accepted pair (x, y). One can continue this process to generate as many accepted 
pairs as needed. The distribution of (x, y) is easily seen to be uniform on the circle 
with radius 1 centered at the origin, as long as £1, £2 are iid uniform on [0, 1].
To “save computer time” it was proposed that when x2 + y2 > 1, rather than reject­
ing both x and y, the value ofx is kept, and the computer generates a new £2, transforms 
it to a new y =2£2 - 1, and tests ifx2 + y2 < 1 (i.e., once x is sampled, it is retained, 
and only y is added to it).
For an estimation of the savings in the computer time, and for the distribution 
of the resulting points (x, y), see Problem 14.3.3. To test the uniformity of the dis­
tribution, n = 100 points are generated on the circle according to a “time-saving” 
scheme. Two tests are performed, both reducing the problem to a one-dimensional 
Kolmogorov-Smirnov test. First, the angles are measured from an arbitrary direction; 
the angles between this direction and the line connecting point (x, y) with the origin 
are uniformly distributed on [0, 2п]. Next, the positive x-axis is the direction chosen, 
and, counting counterclockwise, the values pi = arctan(xi/yi) + (п/2)[1 - sign(yi)] 
take on a U[0, 2п] distribution. The ordered values pi are shown in the left part of 
Table 14.2.
The empirical cdf of these values increases by 0.01 at each pi:100, while F(t) = t/2п. 
For our data, ^nDn = /n sup Fn (t) - F(t) | equals 1.136, which corresponds to a 
p-value of about 0.15 (see Table B2).
On the other hand, if the points have distribution uniform on the circle with radius 
1, the distance R of a random point from the center has a cdf FR(t) = P {R < t} = 
nt2 /п = t2 for 0 < t < 1. Thus the theoretical cdf of distance R is a parabola 12. The 
right side of Table 14.2 gives the ordered distances. We can then compute the values of 
the Kolmogorov-Smirnov statistic /nDn = /n sup Fn (t) - t21, which equals 1.737; 
the corresponding p-value (see Table B2) is less than 0.005.

474
RANK METHODS
Table 14.2
¥i :100
Ri :100
0.0537
1.7784
3.7217
0.0432
0.6757
0.8811
0.0570
1.8854
3.8933
0.1238
0.6969
0.8827
0.0571
1.8967
3.9110
0.1411
0.7045
0.8834
0.1170
1.9798
3.9215
0.1872
0.7145
0.8846
0.1242
2.0339
4.0757
0.2365
0.7168
0.9027
0.1525
2.0721
4.0778
0.2774
0.7268
0.9104
0.3353
2.1705
4.1081
0.3865
0.7312
0.9134
0.4496
2.1833
4.1494
0.4014
0.7326
0.9169
0.4866
2.2170
4.1922
0.4036
0.7365
0.9200
0.5360
2.3099
4.3407
0.4125
0.7462
0.9223
0.5655
2.3482
4.5311
0.4262
0.7547
0.9254
0.5957
2.4588
4.5437
0.4457
0.7557
0.9278
0.6237
2.4618
4.5571
0.4905
0.7833
0.9333
0.6343
2.5279
4.7786
0.4966
0.7836
0.9349
0.7253
2.5874
4.8246
0.5178
0.7924
0.9421
0.8785
2.5840
5.0184
0.5298
0.7967
0.9443
0.8945
2.8752
5.2162
0.5351
0.8175
0.9460
0.9055
2.9165
5.2770
0.5371
0.8268
0.9468
0.9839
2.9489
5.3605
0.5701
0.8290
0.9494
1.0182
2.9534
5.3661
0.5729
0.8311
0.9496
1.1167
2.9606
5.4251
0.5734
0.8337
0.9503
1.1671
2.9669
5.6105
0.5788
0.8412
0.9536
1.2113
2.9774
5.7050
0.5865
0.8453
0.9566
1.3437
3.0322
5.8654
0.5888
0.8472
0.9591
1.4048
3.0663
5.8959
0.6185
0.8476
0.9616
1.4319
3.1596
6.0020
0.6232
0.8485
0.9621
1.4435
3.2035
6.0355
0.6251
0.8491
0.9687
1.4962
3.3165
6.1418
0.6261
0.8521
0.9709
1.5223
3.3226
6.1496
0.6279
0.8632
0.9795
1.5231
3.4023
6.1781
0.6355
0.8656
0.9815
1.5716
3.4204
6.2117
0.6509
0.8669
0.9880
1.5774
3.4407
6.2705
0.6556
0.8692
0.9988
1.6020
3.4981
0.6578
0.8713
1.7543
3.5595
0.6717
0.8724

KOLMOGOROV-SMIRNOV TESTS
475
To find the correct p-value of the observed result, we can perform two tests, one 
giving nonsignificant result corresponding to a p-value 0.15 and the other giving a 
highly significant result with a p-value of 0.005.
To see what is involved here, suppose that instead of the p-value we just carry out 
two tests on significance levels a 1 and a2, respectively. We decide to reject H0 if either 
test 1 or test 2 rejects it. Consequently the probability of type 1 error equals
a = P {test 1 rejects or test 2 rejects|H0}
= P {test 1 rejects|H0} + P {test 2 rejects|H0} - P{both tests reject|H0}
= a1 + a2 - P {both tests reject|H0}.
If test 1 and test 2 are performed on two independent samples, then the attained sig­
nificance level is
a = a1 + a2 - a1 a2 . 
(14.8)
In the present case, the testing was performed on the same data set. Normally the deter­
mination of a significance level in such case is difficult because it requires knowledge 
of the joint distribution of the statistics used in both tests 1 and 2.
In the case under consideration, however, the situation is simple. Since y and R are 
independent (under null hypothesis), we can apply (14.8), which gives the result 0.154.
Two-Sample Kolmogorov-Smirnov Test
In a two-sample problem we need to determine whether or not two samples come from pop­
ulations with the same distribution. We have already encountered its special cases (e.g., in 
considering the Student’s t test for equality of two normal distributions with the same vari­
ance). We now consider this problem in its generality, under the only assumption that the 
samples are drawn from continuous distributions. Thus we let X1 , ...,Xm and Y1 , ...,Xn 
be two independent random samples from distributions with continuous cdf’s F and G, 
respectively. The objective is to test the hypothesis
H0 : F = G against H1 : F = G.
Unlike in the one-sample case of Section 14.3, the null hypothesis is now composite. The 
following theorem, also due to Kolmogorov and Smirnov, is presented without proof.
Theorem 14.3.2 Let Xm = (X1, ...,Xm) and Yn = (Y1, ...,Yn) be random samples from 
distributions with continuous cdf’s F and G, respectively, and let Fm(t) and Gn(t) be the respec­
tive empirical cdf’s. Furthermore let
Dn,m = sup|Fm(t) - Gn(t)|.
Then
lim P
m,n—>^>
mn
J Dm,n
m+n ,
< О = Q (t),
with Q(t) given by (14.7).
mn
If H0 is true, then the statistic л / m __nDm n has a limiting distribution given by the cdf 
Q(t), regardless of the particular cdf that governs the sampling of Xi’s and Yj’s. Suppose 

476
RANK METHODS
now that H0 is false. As m, n ^ ж, we have Fm (t) ^ F (t) and Gn (t) ^ G(t) almost surely 
and uniformly in t, by the Glivenko-Cantelli theorem. Then
Dm,n = sup|Fm(t) - Gn(t)|
=sup|Fm(t)-F(t)+F(t)-G(t)+G(t)-Gn(t)| 
t
< sup Fm(t) - F(t) | + sup \F(t) - G(t)| +sup |Gn(t) - G(t) |, 
t 
tt
and we can write
m^D~D<n ^Tmmsup IFm(t) - F(t)I + J-mf sup IF(t) - G(t)I 
m + + n , V 1 + nt 
V m + n t
+ JVTsu suP |Gn(t) - G(t) 1
V 1 + m t
< F+ sup IFm(t) - F(t) I + 
+++n suP IF(t) - G(t) I
+Fnsup Gn(t) - G(t)I-
The two extreme terms in the last expression have limiting distributions, while the middle 
term tends to infinity for any single hypothesis contained in the alternative. Thus, again, the 
test rejects the null hypothesis when the value of the statistic д/mn/ (m + n) Dm,n is large 
enough.
■ EXAMPLE 14.4
Is a Poisson process observed at every other event also a Poisson process?
SOLUTION. We know, of course, that the answer is negative: If we observe every 
other event in a Poisson process, then the inter-event times are sums of two exponential 
random variables and hence are not exponential. Let us verify this fact empirically. 
Table 14.3 gives m = 12 interarrival times in a Poisson process with mean 1 (where 
every event is observed) and n = 16 interarrival times for every other event in another 
Poisson process with mean 1 (so the mean interarrival times are the same).
Column Ti gives the observed interarrival times in both samples, jointly ordered, 
while the next two columns give the values of Fm (t) and Gn (t) at the observed 
points—Fm(t) increases at points from the first sample while Gn(t) increases at points 
from the second sample. It may be seen therefore that the six shortest interarrival 
times are all in a Poisson process observed at every event. Here the value Dm,n is 
0.5 and the statistic д/mn/(m + n)Dm n equals 1.309, corresponding to a p-value of 
about 0.065.
PROBLEMS
14.3.1 Let the observed values x1, ---,xn be such that 1/3 < xi < 2/3 for all i- What can be 
said about n, if the null hypothesis that the underlying distribution is U[0, 1] cannot 
be rejected by the Kolmogorov-Smirnov test at a = 0.05 level?

KOLMOGOROV-SMIRNOV TESTS
477
Table 14.3
Ti
Fm (•)
Gn (•)
Ti
Fm (•)
Gn (•)
0.049
0.083
0.000
0.942
0.750
0.375
0.198
0.166
0.000
0.969
0.750
0.437
0.237
0.250
0.000
1.033
0.833
0.437
0.259
0.333
0.000
1.094
0.833
0.500
0.310
0.416
0.000
1.375
0.833
0.562
0.352
0.500
0.000
1.392
0.833
0.625
0.381
0.500
0.062
1.555
0.833
0.687
0.546
0.500
0.125
1.625
0.833
0.750
0.547
0.500
0.187
1.697
0.833
0.812
0.569
0.583
0.187
2.019
0.916
0.812
0.801
0.583
0.250
2.065
1.000
0.812
0.803
0.666
0.250
2.114
1.000
0.875
0.878
0.750
0.250
2.244
1.000
0.937
0.895
0.750
0.312
2.534
1.000
1.000
14.3.2 Suppose that the data are as in Example 14.2, except that there were only 25 fires, 
none of them in November. Test that the fires occur according to the Poisson 
process.
14.3.3 Find the joint density of (X, Y ) resulting from the “time-saving scheme” of 
Example 14.3. Find also the expected number of random variables £i necessary to 
sample in order to obtain one pair (X, Y ) under both schemes.
14.3.4 What is the minimal possible value of the statistic Dm,n ifk values ofXi precede the 
third in the magnitude value Yj?Ifm = 100,k=30, and n = 200, is there enough 
evidence to reject (at the level a = 0.05) the null hypothesis that the distributions of 
X’s and Y’s are the same?
14.3.5 Suppose that out of 30 fires in Example 14.2 those on January 5 and 18, February 3 
and 21, March 10, April 6, May 25, June 19, December 3 were caused by arson, and 
in the remaining cases arson was excluded. Use the Kolmogorov-Smirnov statistic 
to test the hypothesis that the occurrences of “arson” and “nonarson” fires within a 
year follow the same distribution.
14.3.6 Suppose that one sample contains 2m data points while the other contains 2m + k 
data points. The first 2m and the last 2m data points in the joint sample alternate 
between samples. Thus the ordered data has the form
YX ••• YXYY ■ •• YXY — XY. 
(14.9)
2m 
k 
2m
(i) For given m find k such that the Kolmogorov-Smirnov test will reject the hypoth­
esis that both samples are drawn from the same population (a = 0.05). (ii) Solve 
this problem if the string of k consecutive Y’s occurs at the beginning of the joint 
ordering.

478
RANK METHODS
14.3.7 Assume that each of two samples contains 2m + k elements with the following 
ordering:
YX • •• YXYY ••• YXY ••• XYXX ••• X 
(14.10)
2m 
k 
2m 
k
For given m find k such that the Kolmogorov-Smirnov test will reject the hypothesis 
that both samples are drawn from the same population (a = 0.05).
14.4 ONE-SAMPLE RANK TESTS
We begin this section with the Wilcoxon signed rank test. This test, used for testing hypothe­
ses about a location parameter in symmetric distributions (median), is an excellent example 
of the simplicity and versatility of nonparametric methods.
Assume that we have a random sample X1 , .. .,Xn from a continuous, symmetric distri­
bution with a cdf F and a density f. Then there exists 6 such that for any x,
F (6 — x) = 1 — F (6 + x).
Equivalently we can say that f(6 + x)=f(6 - x) for any x.
The null hypothesis H0 : 6 = 60 will be tested against either the one-sided alternative 
H1 : 6>60 or the two-sided alternative H1 : 6 = 60 . We can use this test also for H0 : 
6 < 60 against H 1 : 6 > 60. The case of null and alternative hypotheses involving opposite 
inequalities can be obtained by an obvious change of signs. To define the test statistic, con­
sider the absolute differences V1 = |X1 — 60|, V2 = |X2 — 60|, ...,Vn = |Xn — 60|. Since the 
underlying distribution is continuous, we can assume that all Vi ’s are distinct and that none 
equals 0.
Let us arrange the Vi’s in increasing order and assign ranks R1, R2, ...,Rn to them, with 
rank 1 assigned to the smallest Vi. Furthermore let
= f +1 
if Xi > 60
ni 
t — 1 if Xi <60.
The Wilcoxon signed rank statistic is defined as
n
Sn = 12 niRi.
i=1
We construct a test for any of the hypotheses mentioned above, we need to:
1. Find the distribution (or at least, limiting distribution as n becomes large) of the statistic 
Sn under the null hypothesis.
2. Study the effect of values of6 in the alternative hypothesis on the values of Sn.
Suppose therefore that the true value of 6 is 60 . In this case the signs ni are equally likely 
to be positive or negative:
P {ni = 1} = P {ni = -1} =2.
Moreover, the random variables n1 , . ..,nn are independent (since each is determined by a 
different Xi), and also ni is independent of Ri, by symmetry of the distribution ofXi about 
60. The values R1, ...,Rn form a permutation of numbers 1, ...,n,so we write
n
Sn = 
ini .
i=1

ONE-SAMPLE RANK TESTS
479
Since E(ni) = 0 and Var(ni) = E(n2) = 1, we also have E(Sn) = 0 and
Var(S ) = V i2VarEl ) = V i2 = n(n + 1)(2n + 1)
Var( Sn) = / i i Var( ni) = / i i = 
6 
.
i=1 
i=1
It is possible, though tedious, to determine the distribution of Sn for small values of n; the 
exact distribution of Sn can be found in almost any sufficiently large collection of statis­
tical tables. For large n one can prove that Sn/у/Var(Sn) has a limiting standard normal 
distribution.
Indeed, Sn is the sum of n independent random variables n 1 + 2n2 + •• • + nnn, where 
ini = ±i with probability 1 /2 each. To apply the Lindeberg-Feller theorem (9.6.5), we 
have Var(ini) = E[(ini)2] = i2, so sn = Var(Sn) = 
n=1 i2 ~ n3. Since E(ini) = 0 for
i =1, 2, . . . , we have to show that
1n
sn H.Lsn. x2 dFi(x) ^ 0
for every e > 0, where Fi is the cdf of ini. Since sn ~ n3/2, we have esn > n for n large 
enough, and each integral equal to 0; since ini is either i or —i, we have lini | < n. This shows 
that Lindeberg-Feller condition is satisfied, and the proof is complete.
To determine now whether to use the right tail, left tail, or both tails of the distribution 
of Sn (limiting or exact), observe that if the true value of 6 exceeds 60, then
P{ni = +1} = P{Xi > 60} > P{Xi >6} = 2.
Consequently, the positive signs are more likely than negative signs, and this will tend to 
increase the value of Sn . Thus, in tests of H0 : 6 = 60 or H0 : 6 < 60 against H1 : 6>60, 
large values of Sn provide evidence for the alternative, and the right tail should be used as 
the critical region.
■ EXAMPLE 14.5
Assume that f is a density symmetric about 0; that is, it satisfies the condition f (x)= 
f (—x) for all x. Let X1, ...,Xn be a random sample from the distribution with density 
f, and suppose that we observe the values Yi = 6 + Xi ,i =1, ...,n. Thus 6 is the 
median of Yi (and also its mean, if E|Xi| < ж). Let the observed values of n = 20 
observations of Yi be 315, 493, 366, 291, 501, 503, 388, 526, 308, 410, 418, 540, 285, 
360, 426, 475, 336, 455, 301, 359. We want to test the hypothesis that the median 6 
satisfies the inequality 6 < 350, against the alternative 6>350. The consecutive values 
|Yi — 350|, the signs ni of the differences Yi — 350, and ranks Ri are listed in Table 14.4.
The value of statistic S20 equals 124. The asymptotic variance of S20 is 20 x 21 x 
41/6 = 2,870, and therefore the observed value of statistic S20/у/ Var( S 20) is 2.31. The 
corresponding p-value is 0.0129, so we have strong evidence in the data that the median 
of the population exceeds 350.
The Wilcoxon one-sample test can also be used to compare two related populations. This 
setup was already introduced in Chapter 12, in the test we developed for the mean difference 
in paired data.
■ EXAMPLE 14.6 Paired Data
When comparing the effect of two treatments A and B, part of the variation in the data 
is caused by other factors—for example in medical experiments this could be patient’s

480
RANK METHODS
Table 14.4
i
|Yi - 350|
ni
Rank
i
|Yi - 350|
ni
Rank
1
35
-1
5
11
68
+1
12
2
143
+1
16
12
190
+1
20
3
16
+1
4
13
65
-1
11
4
59
-1
9
4
10
+1
2
5
151
+1
17
15
76
+1
13
6
153
+1
18
16
525
+1
15
7
38
+1
6
17
14
-1
3
8
176
+1
19
18
105
+1
14
9
42
-1
7
19
49
-1
8
10
60
+1
10
20
9
+1
1
age, gender, health status, and so on. To eliminate, or at least significantly reduce that 
variability, the experimenter should apply treatments A and B to the same, or at least 
very similar (“almost the same”) subjects. Therefore our data will concern pairs, either 
formed naturally (e.g., twins) or carefully matched as closely as possible (age, gender, 
etc.). It is important to realize that the pairing process is not random. In fact, the 
strength of the final conclusion depends largely on how well the members of each pair 
are matched by as many factors as possible.
Next within each pair the experimenter allocates one member to treatment A, and 
the other to treatment B, this allocation being random. Let Xi and Yi denote the results 
of treatments A and B, respectively, for members of the ith pair of subjects, and let Zi = 
Xi - Yi. If the treatments do not differ, then Zi is as likely to be positive as negative (i.e., 
its median is zero). It will have a symmetric distribution because members of the pair 
are matched and treatments are allocated at random to members of the pair. Thus the 
hypothesis “treatments do not differ” and “treatment A is superior” are now expressed 
as H0 : 6 = 0 and H 1 : в > 0. The Wilcoxon signed rank procedure can be used to test 
these hypotheses.
We will present here one more procedure, called the runs test. In the case of a single sam­
ple, it can be used to test the hypothesis that the sample elements were selected randomly. In 
the case of two samples, it can be used to test the equality of two underlying distributions. 
For example, suppose that in a sample of size n =10, we observe that the first five values are 
all negative while the last five values are all positive. Is this an indication that the process of 
taking the sample was not random?
The general idea of the runs test is to partition the observations X1 , ...,Xn into two 
classes, say A and B = Ac, in such a way that the partition is induced by the values of Xi 
only, not by their order (A may be the set of observations that are positive, observations that 
exceed the hypothetical median, etc.). Formally this means that if the vector (X1, ...,Xn) 
leads to a choice of observations with indices i 1, ... ,ik to form the set A and n (1), ..., n (n") 
is a permutation of indices (1, ...,n), then the choice of set A from the permuted vector of 
observations (Xn(1), ..., Xn(n)) is the set with indices n(i 1), ... n(ik). The randomness of 
the sample, combined with the fact that with probability 1 there are no ties among the sample 
values, imply that each set of indices of appropriate size is equally likely to be the set A of 
the partition.

ONE-SAMPLE RANK TESTS
481
In the special case we could have two samples, X1, ...,Xm from a distribution F and 
Y1, .. .,Yn from a distribution G, and we would test the null hypothesis that F = G (i.e., 
samples come from the same distribution). We would then consider the joint sample of X’s 
and Y’s and the partition would correspond to the two constituent samples. In this case, if 
the null hypothesis is true, each arrangement of X’s and Y’s would be equally likely.
The test in now based on the intuitive idea that if the sampling is really random (or, in the 
two-sample case, if samples come from the same distribution), then the partition into sets A 
and B = Ac is “random.” One of the possible measures of deviations from randomness is 
to observe the number of runs. To fix the idea, imagine that we have m = 5 symbols A and 
n = 7 symbols B arranged in some order, such as
BBABAAABBABB.
A run is a string of elements of one kind, bordered either by elements of the other kind 
or by the end of the string. For instance, the string above has four runs of elements B,as 
underlined, and three runs of elements A, not underlined. The test is based on the intuitive 
expectation that a too small number of runs, such as
AAAAABBBBBBB, 
or a too large number of runs, such as
BABABABABABB,
indicates lack of randomness.
To develop the test, we need the distribution of the number of runs under the null hypoth­
esis. Let R be the total number of runs. In the sequel we will assume that m < n. Clearly, the 
smallest value ofR is 2, while the largest possible value ofR is obtained for alternating runs 
of A’s of length 1. If m<n, then the maximal value of R is 2m +1, while if m = n, then 
it is 2m.
It remains to determine the probabilities P{R = r} for all possible values of r. Consider 
first the case where r is even (r = 2k). The sequence must then contain k runs of each kind 
that alternate, starting either with arun ofA’sorwitharunofB’s. Let us imagine m elements 
A arranged in a string. Dividing the string into k runs means choosing k - 1 out of m - 1 
places separating consecutive A’s. This can be done in mk--11 ways. In a similar way the 
string of B ’s of length n can be divided into k runs in nk--11 distinct ways.
A joint string with 2k runs is now formed by dividing A’s and B’s into k runs each, as 
described above, and joining them by taking alternating runs. For instance, suppose k =3, 
m =5, and n =7. The string of five A’s can be partitioned into three runs in 24 = 6 ways:
AAA|A|A AA|AA|A AA|A|AA A|A|AAA A|AAA|A A|A|AAA.
In a similar way, a string of seven B’s can be divided into 3 strings in 26 = 15 ways. Taking 
one such partition for A’s and one for B’s, we obtain two arrangements giving r = 2 x 3 = 6 
runs. For example, taking the partition AAA|A|A and B|BBBB|BB we obtain two arrange­
ments:
AAABABBBBABB and BAAABBBBABBA.
Consequently
P(R =2k)
m-1 
n-1
2 I k-1 
k—1)
(14.11)
m+n 
m
)

482
RANK METHODS
where the denominator gives the total number of arrangements of m objects A and n objects 
B.Forr =2k +1 we must have either k runs of A’s and k +1 runs of B’s, or vice versa. 
Reasoning analogous to that used in obtaining (14.11) leads to
P(R=2k+1)=
m-1 
n-1 
m-1 
n-1
+
k-1 k 
k 
k-1
(14.12)
m+n \
m
Formulas (14.11) and (14.12) therefore give the distribution of the number of runs R.
■ EXAMPLE 14.7
A machine produces items whose nominal diameter is c. Because of inherent variabil­
ity the diameters of the items produced are random, sometimes above c and sometimes 
below it. The machine was designed in such a way that the diameter of the each item 
produced has no effect on the diameter of the next one. The diameters of 12 consec­
utively produced items were recorded and classified as “above c” (A) or “below c” 
(B). The resulting sequence was BAAAAABBBBBB, so m =5,n =7, and R =3. 
The small number of runs led to the suspicion that there may be some systematic 
low-frequency oscillation in operation of the machine, which tends to produce long 
runs of items with dimensions above c, followed by long runs of items with dimensions 
below c.
To test the hypothesis on “randomness” of dimensions of items against the alterna­
tive of “low-frequency oscillation,” we must choose the left tail of the distribution of 
R (low number of runs) as the critical region, or equivalently, determine the p-value of 
the observed result, that is, P(R < 3). In this case the calculations are straightforward: 
using formulas (14.11) and (14.12), we obtain, for m =5,n=7, and k =1,
P(R < 3) =P(R=2)+P(R=3)
< 152 >{ 2(4)(:)+
46 
46
0 
1+1 
0
2+6+4
(152)
12
792 = 0.0152.
Thus observing only three runs in this situation is a strong indication of the 
low-frequency oscillation effect.
Calculations such as in the example above are cumbersome for large m and n. Fortunately, 
we can use the normal approximation showing first that
2mn 
2mn(2mn - m - n)
E(R) = 
+ 1 and 
Var( R) = 
2 
.
m + n 
(m + n)2(m + n - 1)
We also have the following theorem:
Theorem 14.4.1 If m — ж, n — ж in such a way that m/n — n with 0 < П < ж, then
R — 2 m/(1 + n) 
д/4 nm/((1 + n )3
converges in distribution to N(0, 1).

ONE-SAMPLE RANK TESTS
483
Thus, replacing n by m/n, we can expect that the random variable
R - 2mn/(m + n) ^m+n3 
(14.13)
2mn
has approximate standard normal distribution, provided that m and n are large.
We can show that the approximation is very good for m, n > 20, and quite acceptable 
when m, n > 10.
■ EXAMPLE 14.8
7(5+ 7)3
Recall Example 14.7. Using (14.13) we have an approximation 
r R (R - 2 x 5 x 7/(5 + 7) /--------
P {R -3} = P-------- 2 
7—
xx
3 - 2 x 5 x 7/(5 + 7) 
- 
2 x 5 x 7
3-5.83
« P Z - ——— x 41.57 > = P{Z - —1.68} = 0.0465.
As compared with the exact p-value 0.0152, the approximation is not good.
This shows that for small sample sizes one should try to determine the exact p-value (by 
direct evaluation, use of special tables, or an appropriate statistical package).
PROBLEMS
14.4.1 Prove the asymptotic normality of the Wilcoxon signed rank statistic Sn using the 
Liapunov theorem.
14.4.2 Out of 15 data points one is between 0 and 1, two are between -2 and -1, three are 
between 2 and 3, four are between -4 and -3, and five are between 4 and 5. Use the 
Wilcoxon signed rank statistic to test the hypothesis that the median is: (i) 0. (ii) 1.
14.4.3 Twelve pairs of subjects, matched within each pair with respect to age, gender, health 
status, and initial weight, were put on two types of diets. The data on pounds lost 
after 5 weeks are as follows:
Pair
1
2
3
4
5
6
7
8
9
10
11
12
Diet A
15
33
21
17
14
25
25
31
18
5
46
11
Diet B
18
17
10
10
32
11
8
26
-3
19
5
8
Use the Wilcoxon signed ranked test to test the hypothesis that both diets have the 
same effect, against the alternative that diet B is more efficient than diet A. Use 
a = 0.05.
14.4.4 Some texts define the Wilcoxon signed rank statistic as Sn = 
niRi, where ni = 1 if
Xi > 60 and 0 otherwise. Determine the mean and variance of Sn, and show that tests 
based on Sn and on Sin are equivalent in the following sense: under a null hypothesis, 
Sn = Sn — S*, where Sn and S* have the same distribution.

484
RANK METHODS
14.4.5 Solve Problems 14.3.6 and 14.3.7 using a runs test. Compare the results obtained by 
different methods (use the same a = 0.05). Explain the differences, if they exist, for 
m =10and k =5.
14.4.6 A machine is set up to produce items, each with a diameter above 1 inch. The diame­
ters of 15 consecutive items produced are 1.11, 1.15, 0.98, 1.11, 1.08, 1.06, 0.97, 0.97, 
1.05, 1.02, 0.98, 0.99, 0.96, 1.03, 1.01. Use a runs test, taking 1 inch as a threshold 
to test the hypothesis that the measurements represent random deviations from the 
required standard.
14.5 TWO-SAMPLE RANK TESTS
Let X = (X1, ...,Xm) and Y = (Y1, ...,Yn) be random samples from two continuous dis­
tributions with cdf’s F and G, respectively. We want to test the null hypothesis
H0 : F = G
against some alternatives, whose form will be discussed later.
We present one of the most important of the rank tests, the Wilcoxon-Mann-Whitney 
two-sample test. The underlying idea of the test is as follows:
First, we combine both samples and then arrange all observations in an increasing order:
U1 < U2 <■■■< Um+n,
where each Ui belongs to one of the samples. Because of the assumed continuity ofF and G, 
we can disregard the possibility of ties in the joint sample, so we assume that all inequalities 
among Ui ’s are strict.
Next we assign ranks from 1 to m + n to consecutive elements Ui. If the null hypothesis 
is true, then the m ranks of elements of the first sample and the n ranks of elements of the 
second sample are mixed randomly, in the sense that each of the mm+n allocations of the 
m ranks of elements in the first sample has the same probability 1/ mm+n .
Wilcoxon suggested to use the statistic WX, defined as the sum of ranks of elements of 
the sample (X1, ...,Xm), in the joint ordering of both samples. Formally, we can write
m+n 
WX = 
iIX (Ui),
i=1
where IX(Ui) = 1 if Ui comes from sample X and is 0 otherwise.
Equivalently we can use statistic WY , being the sum of ranks of elements of the second 
sample in the joint ordering. Statistics WX and WY carry the same information. Indeed we 
have
m+n 
m+n 
m+n
WX+WY = 
iIX(Ui) + 
iIY (Ui) = 
i(IX(Ui) + IY (Ui))
i=1 
i=1 
i=1
so
m+n
E i = (m + n)(m + n - 1) 
2
WY =
(m + n)(m + n - 1) - WX .
2

TWO-SAMPLE RANK TESTS
485
Let us begin with finding the expectation and variance of WX . We have
(
m+n 
\ 
m+n 
m+n
iIX (Ui) = 
iE[IX (Ui)] = 
iP {IX (Ui) = 1}.
i=1 
i=1 
i=1
Since all allocations of the m ranks of elements of the first sample among m + n elements 
of both samples are equally likely, the probability that the ith ranking element comes from 
the first sample is P(IX(Ui) = 1) = m/(m + n). We have therefore
m+n
E(WX) = i 
i=1
m
n+m
m(m + n +1)
2
The calculations of variance is somewhat more tedious (we leave it as exercise). The result is
Var( WX )= mn(m + n +1). 
(14.14)
One could also show (we omit the proof) that as m ^ <x>,n ^ ж, the random variable
Z = W - E ( Wx ) = Wx — m (m + n +1) / 2 
m,n 
д/Var WX 
mn (m + n + 1) /12
converges in distribution to the standard normal random variable.
To design a testing procedure, it is now necessary to specify the alternative hypothesis. In 
other words, we have to determine the class of hypotheses such that if (F, G) belongs to this 
class, then the values of Zm,n will tend to be relatively large (or small, or large in absolute 
value).
One such class of alternative hypotheses is obtained by taking
H 1 : G(t) = F (t - 0) 
(14.15)
for all t and some 0. To grasp the meaning of this hypothesis and its consequence for WX, 
let us consider the case 0 > 0. Here G(t) = F(t - 0) < F(t), which means that P{Y < t} < 
P{X < t}; hence the values of X tend to be smaller than values of Y (since whatever the 
value t, the random variable X is more likely to be below t than the random variable Y). 
Consequently the observations X1 , ...,Xm will tend to be located closer to the left end and 
so have smaller ranks. Thus small values ofWx support the alternative hypothesis H1 : 0> 
0.Thecase0<0 is analogous, whereas for the alternative H1 : G(t) = F(t - 0),0=0, one 
should take the two-sided test.
Actually the class of alternatives against which the Wilcoxon statistic Wx can be used 
is larger. Recall that the random variable X is stochastically larger than Y if P{X < t}< 
P{Y < t} for all t. In the present notation, X is stochastically larger than Y if F(t) < G(t) 
for all t. Thus stochastic dominance of Y by X (or X by Y) is an alternative that will tend 
to inflate (or decrease) the statistic Wx .
About the same time as Wilcoxon introduced his statistic Wx , Mann and Whitney intro­
duced another statistic, pertaining to the same two-sample problem:
R = number of pairs (Xi, Yj) with Xi >Yj .
The statistic Wx can be written as 
m 
Wx = 
Rj ,
j=1
where Rj is the rank of Xj:m. This means that Rj equals the number of elements in the 
combined sample that do not exceed Xj:m.

486
RANK METHODS
By definition, there are j elements in the sample X1 , ...,Xm that are less or equal to 
Xj:m, so we can write
Rj = j + number of Yi with Yi < Xj:m
Consequently
m 
m(m +1)
WX = ^^[j + number of is with Yi < Xj: m ] =---------------+ R.
j=1 
2
It follows that
m(m +1) 
m(m + n +1) 
m(m +1) 
mn
E (R) = E (WX)-------------- = 
—------------- --------=----- = = —
and
Var( R ) = Var( WX )= mn(m + n + 1).
It also follows, from the asymptotic normality of WX, that as m ^ ж, n ^ ж, the statistic
R mn/2
■mmn (m+n+1) / 2
(14.16)
converges in distribution to N(0, 1). Since the tests based on WX and on R are equivalent, 
they became known as Wilcoxon-Mann-Whitney tests.
Observe now that there are mn possible pairs with elements of the pair coming from 
different samples. Consequently, R/mn is a consistent estimator of the probability P {Y< 
X}, so as m ^ ж, n ^ ж, we have
 
^ P{Y <X} = [ 
G(t)f (t)dt = [ 
[1 — F(t)]g(t)dt. 
mn------------------------ -ж 
-TO
Under the null hypothesis F = G, we have P{Y < X} = 1 /2. If P{Y < X} = £ = 1 /2, 
then, using (14.16), we can write
Z
2mn R 
1
m + n +1 mn 
2
2mn R R 
2\n 
2mn 
— 
1
m + n +1 mn 
m + n +1 
2
The first term converges in distribution to a standard normal random variable, while 
the second diverges to +ж or -ж if only £ = 1/2. This shows that in the limit as 
m ^ ж,п ^ ж, the Wilcoxon-Mann-Whitney test (based on WX or R) has asymptotic 
power 1 for all alternatives (F, G) with £ = 1/2.
■ EXAMPLE 14.9
Consider two athletes, A and B ; one of them is to be selected to represent the coun­
try in some competition. Assume that both athletes have attained some stable level of 
proficiency in their discipline. Their results (in competitions, their best daily training 
results, etc.) may be taken as random samples of some random variables, say X(A) and 
X(B). Furthermore, assume that the discipline is such that tied results are unlikely. Let 

TWO-SAMPLE RANK TESTS
487
n =15be the results ofA and n =20the results ofB, with none of the results repeat­
ing. Suppose that after arranging these results jointly from worst to the best, we obtain 
the sequence
AAABABBAAABBBBABABBABBAABBABBBABBBA
Here the three lowest results are of athlete A, the fourth is of athlete B, and so on. The 
best result belongs also to A.
We can define the “better” athlete (of a pair) as the one who has better than even 
chances of defeating the other one. Thus A is better than B if
£ = P(A beats B) >
The idea that lies at the foundation of the US system of selecting Olympic represen­
tatives is the same as that in the case under consideration: A is better than B because 
the best result ofAis better than the best result of B. Let us therefore test the hypothesis
£ = P (A beats B) = P (X >Y) < 1
(A is equal to B, or inferior to B) against the alternative that £>1/2. The Wilcoxon 
statistic (sum of ranks of A)is
WX =1+2+3+5+8+9+10+15+17+20+23+24+27+31+35=230.
For m =15,n=20we have E(WX) = 270, Var(WX) = 900, so the p-value is P{Z> 
(230 - 270)/30} = P{Z > -1.33} = 0.9082. There is therefore no reason to reject the 
null hypothesis that A is no better than B, despite the fact that the best result is attained 
by athlete A.
PROBLEMS
14.5.1 Prove formula (14.14) showing first that for i = j 
mn 
mn
V ( IAi) 
(m + n )2 and C ( IAi ,IAj) 
(m + n )2( m + n - 1).
14.5.2 Two samples of sizes m =20and n =10, respectively, are selected from two popu­
lations. Let r1, ...,r10, denoting the numbers of observations from the first sample 
that do not exceed the kth (k =1, ...,10) element in the ordered second sample, be 
1, 1, 2, 4, 4, 6, 8, 9, 11 ,d. (i) Find the value of Wilcoxon and Mann-Whitney statistic 
as a function of d. (ii) Find the value of Kolmogorov-Smirnov statistic as a function 
of d. (iii) Suggest the appropriate alternative hypothesis, and determine d for which 
the hypothesis about the same median can be rejected based on the Mann-Whitney 
or Wilcoxon test. (iv) Answer (iii) using the Kolmogorov-Smirnov test.
14.5.3 Use the runs test for the data of Problem 14.5.2.
14.5.4 Assume that n is odd and that all m elements of the first sample are below the 
median of the second sample. Find the range of the test statistics and the rejection 
region for the appropriate alternative hypothesis using: (i) The Wilcoxon test. (ii) 
The Mann-Whitney test. (iii) The runs test. (iv) The Kolmogorov-Smirnov test for 
the appropriate alternative hypothesis. (a = 0.05, n = 51, m = 20).

488
RANK METHODS
14.6 KRUSKAL-WALLIS TEST
Finally, we present the Kruskal-Wallis test, a rank-based counterpart of the one-way 
ANOVA test. We consider k random samples, of sizes n 1, n2, ... ,nk, where k > 2. We let 
Xij be the jth element (j =1, ...,ni)inith sample, and we assume that Xi,1, ...,Xi,n 
are iid random variables with a cdf given by
Fi (x ) = G (x - Oi)
for all x. Here, G is assumed to be a cdf of some continuous random variable. We want to 
test the null hypothesis
H0 : O 1 = O2 = • • • = Ok 
against 
H 1 : not all Oi s are equal.
If G is a cdf of a distribution symmetric around 0—satisfying G(-x)=1- G(x)—then 
the median and the mean (if it exists) of Fi is easily seen to be Oi , and the null hypothesis 
asserts that the medians (or means) of all populations are the same. The variance need not 
exist, but the fact that all populations have the same distribution up to a location parameter 
corresponds to the assumption of homoscedasticity in Chapter 13.
Let us order all n = n 1 + • • • + nk observations Xij from smallest to largest, and let Rij 
be the rank of observation Xij in the joint ordering. Furthermore let Ri + = "= 1 Rij be the 
sum of ranks corresponding to elements in the ith sample (if we have two populations, i.e., 
k =2, then R1 and R2 correspond to Wilcoxon statistics WX and WY from the preceding 
section).
The test of null hypothesis H0 is based on Kruskal-Wallis statistic
B=
12 у Ri+ 
n(n +1) 
n
i=1 i - 3(n + 1).
(14.17)
We have the following theorem:
Theorem 14.6.1 If H0 is true, and all sample sizes n1 ,n2, . . .,nr increase to infinity in such a 
way that ni/n ^ pi > 0 for all i, then the distribution of statistic B converges to the chi-square 
distribution with r - 1 degrees of freedom.
We will not give a full proof, but outline the argument to explain why the large values of 
the statistic B are compatible more with the alternative than with the null hypothesis.
First, under the null hypothesis,
n + 1
2
and
Var
(n + 1)(n - ni) 
12ni
(14.18)
The proof is left as an exercise. Now letting
Vi = Ri+In - E(Ri+In) 
7Var( Ri+in,)

KRUSKAL-WALLIS TEST
489
we write
rr
V(i - ni} V2 = V(i - ni)
ni 
n
i=1 
i=1
R+/ni - E (Ri+/ni) 
VVH Ri+/ni) .
r
= E
i=1
n - ni
(Ri + /ni - (n +1)/2)2 
(n + 1)(n - ni)/12ni
(14.19)
n
12 у Ri+ 
n(n + 1) 
n
i=1 i
- 3(n +1).
First, from expression (14.19) we have that any deviation from the null hypothesis will tend 
to increase B . Thus the critical region is always the right tail of the appropriate chi-square 
distribution, as in ANOVA tests under normal assumptions.
Second, we have to show that Vi converges in the distribution to a standard normal vari­
able, or equivalently that the distribution of Ri+ is asymptotically normal. Once this fact 
is established, the proof of the theorem can be completed by observing that the random 
variables R 1+, ..., Rr + are constrained by the condition r=1 Ri + = n(n + 1)/2, which 
reduces the number of degrees of freedom to r - 1. It remains to check, for instance, that 
the asymptotic mean and variance of B agree of those of chi-square distribution with r - 1 
degrees of freedom.
The proof of asymptotic normality of Ri+ lies beyond the scope of this book; it relies on 
one of the central limit theorems for the sum of exchangeable random variables.
PROBLEMS
14.6.1 Prove relations (14.18).
14.6.2 STAT 102 can only taken be taken by students who passed STAT 101. Among 15 
students in STAT 102, five took STAT 101 from instructor X , four took it from 
instructor Y , and the rest took the course from instructor Z . Ordered according to 
their performance, the students of the three instructors are
ZXZZZY XZY XY XZXY
(this means that the best student was taught by instructor Z, second best by instruc­
tor X, etc.). At the significance level а = 0.05, test the hypothesis that the perfor­
mance of students in STAT 102 class does not depend on who taught them STAT 
101.

CHAPTER 15
ANALYSIS OF CATEGORICAL DATA
15.1 
INTRODUCTION
The term categorical data refers to observations recorded either on a nominal scale or on a 
discrete ordinal scale (so ties are expected to occur often). Typical examples of the nominal 
scale occur when data represent frequencies of categories of some qualitative attribute (e.g., 
responses in a questionnaire about the state of residence or religious affiliation). The dis­
crete ordinal scale consists of a set of naturally ordered categories. For example, opinion 
on a specific issue may be classified as “favorable,” “neutral,” or “unfavorable”; educa­
tion achieved may be classified as “high school,” “junior college,” “four-year college or 
university,” “graduate school”; and so on.
A special case is played by a binary data, for example male vs. female, smoker vs. non­
smoker. There is no “natural” ordering here, but one can always assign values 0 and 1 
(or any other two values) to the categories.
The following examples illustrate some of the possible problems in the analysis of cate­
gorical data.
■ EXAMPLE 15.1
A typical case of data on a nominal scale occur in genetic experiments. Suppose that 
we have a gene with two forms, A and a, so that an individual (e.g., plant) belongs to 
one of the three categories AA, Aa, or aa. If none of the forms is dominant, the three 
genotypes can be identified (they coincide with the phenotypes). According to genetic 
theory, the probabilities of three genotypes are 62, 2 6 (1 - 6), and (1 - 6) 2, respectively, 
where 6 is the unknown frequency of allele A. Suppose that out of 200 plants we have 
100 of type AA, 89 of type Aa, and 11 of type aa. Are these data in agreement with 
genetic theory?
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
491

492
ANALYSIS OF CATEGORICAL DATA
■ EXAMPLE 15.2
Suppose that we have joint data on ethnicity and incidence of various types of cancer. 
In studying the association between these two attributes, we might search for genetic, 
dietary, or other reasons for a lack of independence.
In the last example, both variables (ethnicity and type of cancer) were of a nominal charac­
ter. When both variables are measured on an ordinal scale, we may additionally be interested 
in the strength of association between variables. Such questions are discussed later in this 
chapter, where we present selected methods of analysis of ordinal aspects of categorical data.
■ EXAMPLE 15.3
For data measured originally on an ordinal scale and later grouped into classes, the 
methods of Chapter 14 are not applicable. Suppose that we want to study a relationship 
between level of education (classified as “I, no college”; “II, some college”; and “III, at 
least four-year college/university”) and the frequency of changing jobs (again classified 
as high, moderate, or low). The data take the form
Education
Frequency 
of job change
I 
II 
II
Low 
Moderate 
High
N11 
N12 
N13
N21 
N22 
N23
N31 
N32 
N33
Here Nij is the frequency of occurrence of a given category among randomly 
selected study participants. We want to test the hypothesis that there exists an 
association (positive or negative) between the frequency of changing jobs and the level 
of education.
The theory of categorical data is a domain with a long tradition, the chi-square test being 
one of the oldest examples of statistical procedures that use only frequencies. At the same 
time, this domain has been developing rapidly over the last four decades. We will introduce 
some of the basic information on problems and methods in analysis of categorical data. An 
exhaustive presentation of the field can be found in Agresti (2002).
15.2 
CHI-SQUARE TESTS
In this section, we present one of the oldest and best known statistical tests. Beginning with 
the case of a discrete distribution with a finite number of values, we let X be a random 
variable with r possible values x1, ...,xr and the corresponding probabilities pi = P{X = 
xi}, i = 1, ...,r. For a random sample X 1, ..., Xn, counts N1, ..., Nr, where N 1 + • • • + 
Nr = n, are respective frequencies of values x1, ...,xr. The vector (N1, ...,Nr-1) (notice 
that one of the coordinates Ni is redundant), called the count vector of the sample, carries all 
the necessary information about the distribution of X . Formally, the likelihood of the data 
is
r 
r-1 xn-E E11 N
N1 N2 
Nr 
N1 N2 
Nr-1
L = CP 1 P2 ••• Pr = CP 1 P2 ••• Pr-1 
1 - / yPi 
,
i=1 

CHI-SQUARE TESTS
493
where C = n! / (N1! N2! • • • Nr!). Consequently, the count vector is a set of jointly sufficient 
statistics for the vector (p1, p2, ...,pr-1).
An important remark here is that procedures for the inference about the distribution 
(p1, p2, ...,pr-1) of X on the basis of the counts (N1, ...,Nr-1) do not depend on 
x1, ...,xr.
Suppose that we want to test the hypothesis
H0 : pi = pi0, i=1, ...,r 
(15.1)
against the general alternative
H1 : hypothesis H0 is not true.
Here, (p10, ...,pr0) is some fixed probability distribution, and we assume that pi0 > 0 for 
i =1, ...,r.
Under the null hypothesis, for each i, the marginal distribution of the count Ni is 
BIN(n, pi0). The test will be based on the following theorem.
Theorem 15.2.1 Let (N1, ...,Nr) be the count vector of random sample of size n from multi­
nomial distribution with probabilities (p0, ... ,pr), so that p0 + • • • + p0 = 1 and N 1 + • • • +
Nr
= n. Then the statistic
r
Q2 = E
j=1
(Nj - npj)2 
npj0
(15.2)
has the limiting (as n ^ ж) chi-square distribution with r — 1 degrees of freedom. The statistic 
Q2 is often referred to as Pearson’s chi-square.
Proof: A simple argument shows that the theorem is true for r =2. In this case we have, 
remembering that p02 =1 - p10 and N2 = n - N1 ,
2 = (N 1 - np0)2 + (N2 - np2)2 
np01 
np02
(N 1 — np I )2 
(N1 — np I)2
np10 
n(1 - p01 )
(N 1 — np 1)2 
(n — N1 — n (1 — p 0))2
np10 
n(1 — p01 )
N1 — np 1 
^np 0(1 — p 01)
z 2 ~ % 2.
For an arbitrary r, the algebra is more complicated: the statistic Q2 is represented as a sum 
of r — 1 squares of random variables, each converging in distribution to a standard normal 
random variable, and such that their coefficients of correlation tend to 0 as n increases. We 
omit the details. 
□
As a practical rule, one obtains a reasonable approximation of the distribution of Q2 
if expected counts npi0,i=1, ...,r, are at least 5, and the approximation is good if the 
expected counts exceed 10.
To test the null hypothesis H0 : pj = pj0,j=1, ...,r against the alternative H1 : 
“hypothesis H0 is false,” we need to determine the critical region. Since any violations of 
the null hypothesis in the chi-square test will tend to increase the value of statistic Q2, we 
should take the right tail as the critical region, with %2 r- 1 as a critical value.
■ EXAMPLE 15.4
According to genetic theory, the seeds collected from a field of pink pea should produce 
plants with white, pink, and red flowers, in the proportion 1:2:1. Of 400 plants grown 

494
ANALYSIS OF CATEGORICAL DATA
from such seeds, 93 are white, 211 are pink, and 96 are red. Does this result contradict 
genetic theory?
SOLUTION. We have here 400 observations of a three-valued random variable. 
According to the null hypothesis, we have p01 = 1/4,p20 = 1/2, and p03 = 1/4, so the 
expected counts npi0 are 100, 200, and 100. The observed value of the test statistic Q2
is
_ 
(93 - 100)2 
(211 - 200)2 
(96 - 100)2
Q = 
100 
+ 
200 
+ 
100
= 1.255.
Since we have here 2 degrees of freedom, the p-value is 0.534, and consequently, the 
data do not provide enough evidence against the null hypothesis.
As already mentioned, the chi-squared test can be used for testing the hypothesis that 
the data of a continuous type follow a specific distribution. In this case, to obtain the count 
vector (N1, ...,Nr), we partition the range of values of the observed random variable X into 
r sets, say C1 ,C2 , ...,Cr. Typically, the sets Cj are intervals, but this is not necessary; the 
sets Cj need not to be connected, and may consist of a number of noncontiguous intervals. 
The count Nj , given the sample of n observations of random variable X, is defined as a 
frequency of observations in set C. Clearly, N1 + • • • + Nr = n .If f is the density of X 
specified by the null hypothesis, then we have
p0=cjf(x)dx, j=1 ,...,r.
The test statistic Q2 depends not only on the sample but also on the choice of the parti­
tion into sets Cj . Sometimes, the choice of the partition is natural, while in other cases, the 
partition is chosen in a rather arbitrary way.
■ EXAMPLE 15.5
Fox and James (1987) give the following data about the birth signs of 851 prominent 
chess players:
Capricorn
63
Lasker, Keres, Chiburdanidze
Aquarius
79
Spassky, Bronstein
Pisces
101
Fischer, Tarrasch, Geller, Larsen
Aries
76
Smyslov, Kasparov, Korchnoi, Portisch
Taurus
77
Miles, Nunn, Steinitz
Gemini
67
Petrosian, Karpov, Short, Euwe
Cancer
54
Morphy, Anderssen
Leo
67
Botvinnik
Virgo
63
Philidor
Libra
69
Rubinstein, Fine
Scorpio
71
Capablanca, Alekhine, Nimzowitsch, Tal
Sagittarius
64
Reshevsky, Pillsbury.
It seems that Pisces have a significantly higher number of prominent chess players.
We want to test the null hypothesis that the birthday is not related to chess talent. 
In this case, we can expect that the birthdays of n = 851 prominent chess players form 
a random sample from a distribution uniform on the year (which we may conveniently 

CHI-SQUARE TESTS
495
regard as a continuous distribution). The expected count for each sign will be 851 x 
(1/12) = 70.917, and
2 
(63 - 70.917)2 
(64 - 70.917)2
Q —----------------------+ • • • +---------------------
70 
70.917 
70.917
— 21.53.
The p-value of the observed result is 0.028 which means that such a result will occur, 
on average, about once in 35 times, if the null hypothesis is true. Someone with a firm 
belief that there is some truth in astrology may use this result to support an argument. A 
sceptic who is convinced that the configuration of stars and planets at the time of one’s 
birth cannot affect this person’s talents will regard the observed result as an example 
of a type I error.
■ EXAMPLE 15.6
The left tail (indicating a good fit) of the chi-square test can be used for detecting 
whether the data were tampered with. The point is that the p-value gives the prob­
ability that in a repetition of the experiment, one would observe worse (in discrete 
case, no better) fit than the one actually observed. Thus, if the p-value is close to 1, 
say 0.99, it means that on average, only once in 100 repetitions one can expect to 
observe a better fit. That strongly suggests that the data were “improved” to make 
them conform better to the null hypothesis. An interesting example of such a type of 
inference is provided by Fisher’s analysis of data on heredity by Gregor Mendel. For a 
detailed explanation, see Freedman et al. (1992). Here, we briefly sketch the idea and 
results.
Mendel studied the laws of inheritance of various characteristics, eventually intro­
ducing the concept of a gene. In a typical experiment of Mendel, plants of genotype 
AA are crossed with plants of genotype aa. All seeds are then hybrids Aa. A number of 
such seeds are grown and the plants are cross-pollinated. According to genetic theory, 
the ratio of plants of genotypes AA, Aa, and aa are 1:2:1. IfAA and Aa cannot be dis­
tinguished, then the ratio of genotype aa to all others is 1:3, and so on. For example, in 
the last case, of 800 plants, about 200 can be expected to be aa. In all of Mendel’s exper­
iments, the observed numbers differ suspiciously little from the expected. For example, 
suppose that in the last case Mendel reported 205 plants with an aa genotype out of 
800. The chi-square fit of such a result is
(205 - 200)2 
(595 - 600)2
200 
+ 
600
— 0.167,
which corresponds to a p-value of about 90%.
A single result with so high a p-value is not unusual, but when Fisher combined all 
of Mendel’s data using the combined chi-square test, the p-value was 0.99996 (i.e., only 
four times out of 100,000 one can expect a better fit). Thus, either Mendel had some 
extraordinary luck or his data were “beautified” to conform better to his theory.
In the cases considered above, the null hypothesis is simple; that is, the hypothetical dis­
tribution is specified completely. More often the null hypothesis comprises a class of distri­
butions. We will now consider cases where the distribution of a random variable X depends 
on some parameter 6 (possibly vector valued) in a specified family of distributions. Thus, we 
will assume that X is discrete random variable, with r possible values x1, ...,xr,andsuch 
that
P{X — xj} — pj (6), 

496
ANALYSIS OF CATEGORICAL DATA
where в = (в 1, ... ,0 k) & Hk. Moreover, we will assume that the number of classes r satisfies 
the inequality r > k + 2 and that Pj (в) > 0 for all j and all в & Hk.
As before, we assume that we have a random sample of values of X, leading to the count 
vector (N1, ... ,Nr), where N 1 + • • • + Nr = n. This time we cannot form the test statistic 
(15.2) because the expected class frequencies npj (в) depend now on the unknown parameter 
в. According to Theorem 15.2.2, we must use instead the estimated expected frequencies 
obtained as functions of the maximum likelihood estimate (MLE) of в . Given the count 
(N1 ,N2 , .. .,Nr ) the likelihood of the data is
L (в; N 1, ...,N ) = [P 1( в)]N1 ... [Pr (в)]Nr. 
(15.3)
Let в = (в1, .. .,вк) denote the value of the parameter в that maximizes the likelihood (15.3). 
We have then the following theorem.
Theorem 15.2.2 The statistic
r
Q2 = £
j=1
[Nj - npj(в)]2 
nPj (в)
(15.4)
has, as n ^ ж, the limiting chi-square distribution with r — 1 — k degrees of freedom.
We omit the proof, which can be found in Cramer (1946).
■ EXAMPLE 15.7
Consider a gene with two alleles, A and a. Let the frequency of gene A in popula­
tion be в. Under random mating, the frequencies of individuals of genotypes AA, Aa, 
and aa are в2, 2в(1 — в), and (1 — в)2. To test the theory, n individuals are randomly 
selected, and the count of the three genotypes is N1, N2, N3. Then the likelihood of the 
data is
L = [ в 2] N1 [2 в (1 — в)] N2 [(1 — в )2] N3 =2 N2 в 2 N1+ N2 (1
Differentiating log L, we obtain easily the MLE of в:
в = = 2 N 1 + N2 
2 n 
.
For a numerical example, suppose that n = 200, N1 =25,N2 = 
have then в = 60/400 = 0.15, and using (15.5), we get
2_ (25 — 30)2 
(10 — 51)2 
(165 — 144.5)2
Q = 
30 
+ 
51 
+ 
144.5
Since this result exceeds x2.0005,1 = 7.879, the p-value is less than 0.005, so the evidence 
against the null hypothesis of random mating provided by such data is very strong.
— в) N2+2 N3
(15.5)
10, and N3 = 165. We
Theorem 15.2.1 asserts that if the null hypothesis is simple (specifies completely the distri­
bution), then the limiting distribution of Q2 (under null hypothesis) is chi-square with r — 1 
degrees of freedom. On the other hand, if the null hypothesis is composite, and we have to 
estimate the expected counts by finding the MLE’s of the parameters в 1, ... ,вк given the 
counts, we lose k degrees of freedom.

CHI-SQUARE TESTS
497
■ EXAMPLE 15.8
Assume that we have raw data for the numbers x1905 , x1906 , ...,x1991 of 
cloudless nights in the last n =87 years at some prospective telescope site. 
Suppose that it is known that x 1905 + x 1906 + ••• + x1991 = 21, 163 and 
x2905 + • • • + x 1991 = 5, 226, 819. However, the actual data are not available, 
and instead we have the following counts Ni of years with given numbers of cloudless 
nights:
Interval
Ni
160 or below
1
161 to 180
3
181 to 200
7
201 to 220
17
221 to 240
18
241 to 260
26
261 to 280
9
281 to 300
4
301 or above
2
We want to test the hypothesis that the number of the cloudless nights at the site is 
normally distributed.
The MLE’s of ^ and a2 computed from original data are
x = 21,163 = 243.25 and ^ = _1(5, 226, 819) _ (243.25)2 = 907.82; 
87 
87
hence a = 30.13. The estimated class probabilities are, letting X denote the number of 
cloudless nights,
P 1 = P(X < 160) = Ф
160 _ 243.25 \
30. 13 
) = Ф( _ 2.76) = 0.0029,
p2 = P(160 < X < 180) = Ф(_2. 10) _ Ф(_2.76) = 0.015,
and similarly for subsequent intervals.
The actual and expected counts for the consecutive classes are therefore
Interval
87pi
Ni
160 or below
0.252
1
161 to 180
1.305
3
181 to 200
4.959
7
201 to 220
12.676
17
221 to 240
19.192
18
241 to 260
22.281
26
261 to 280
15.356
9
281 to 300
7.056
4
301 or above
2.612
2

498
ANALYSIS OF CATEGORICAL DATA
To avoid too small expected class sizes, we combine the first three classes together as 
well as the last two classes and obtain:
Interval
87pi
Ni
200 or below
6.516
11
201 to 220
12.676
17
221 to 240
19.192
18
241 to 260
22.281
26
261 to 280
15.356
9
281 or above
9.668
6
The observed value of the statistic Q2 is now 9.278. This corresponds to the p-value 
equal 0.026 (3 df).
PROBLEMS
15.2.1 Ladislaus von Bortkiewicz, a Russian economist and statistician, is known for the 
data he collected on the number of Prussian cavalryman being killed by the kick of a 
horse. He observed 10 army corps for 20 years, obtaining 200 observations. The total 
of 122 deaths was distributed as follows:
0 
1 
2 
3456
109 
65 
22 
3 
1 
0 
0
Test the hypothesis that the number of deaths from horse kicks has Poisson distribu­
tion.
15.2.2 A certain type of toy is sold with three batteries included. The number of defective 
batteries (X) in a random sample of 200 toys are as follows:
X
0
1
2
3
Count
51
92
40
17
Test the hypothesis that the number of defective batteries in a toy has a binomial 
distribution.
15.2.3 Assume that the sexes of children in a family are independent. In a human population, 
the probability that a child is a male is very close to 0.5. Numbers of boys (X) in a 
random sample of 100 families with four children are:
X
0
1
2
3
4
Count
7
21
40
27
5
Test the hypothesis that the distribution of the number of boys in a family of four 
children is indeed BIN(4, 0.5).

HOMOGENEITY AND INDEPENDENCE
499
15.2.4 Suppose that counts of female offsprings in a certain animal species with four off­
springs are 3, 8, 28, 40, 21. Test the hypothesis that the corresponding distribution is 
binomial.
15.2.5 Given the data on numbers of hits of various areas of London by V2 rockets 
(see Example 8.14), test the hypothesis that the numbers of hits have a Poisson 
distribution.
15.3 HOMOGENEITY AND INDEPENDENCE
Chi-square tests can also be used for testing hypotheses about jointly distributed categorical 
variables. The data obtained in a random sample are summarized in a contingency table with 
r rows and c columns representing levels of respective classification variables. If n observa­
tions are taken, then Nij is the number of observations classified at the ith level of the first 
classification variable and at the jth level of the second. The counts can be arranged into a 
matrix [Nij], where we have ijNij = n.
We will postpone a more detailed analysis of types of contingency tables to subsequent 
sections. Here we will consider only the simplest case, corresponding to random sampling 
from a population whose elements are categorized according to some classification system 
(gender vs. educational level, smoking status vs. cause of death, etc.).
Let pij be the probability that a single observation belongs to the ith category in first 
classification and jth category in the second classification. The marginal probabilities here 
are
pi+ = 
pij ,p+j = 
pij ,
ji
and the most obvious null hypothesis is that of independence of the two classifications:
H0 : pij = pi+p+j for all i, j.
The alternative hypothesis is
Ha : H0 is not true.
Let now pij denote the MLE of the probability pj based on the count matrix [Nij ]. Then, 
the test statistic (15.4) takes on the form
q 2=i, ib
i=1 j=1
(Nij - npij )2 
np ij
(15.6)
This statistic, according to Theorem 15.2.2, has a limiting (as n — ^) chi-square distribution 
with rc - 1 - k degrees of freedom, where k is the number of estimated parameters.
To determine k, and also find the estimators pij, observe that under the null hypothesis 
H0, we have (by the invariance property of MLE’s) pij = pi+p+j. Now there are r values 
of the marginal probabilities pi+, and c values of marginal probabilities p+j, but in each of 
these marginal distributions, one value is a function of others, for instance,
pr + = 1 - p 1+ - p2+-------- ---- pr-1, +
and similarly
p+c = 1 - p +1 - p+2-------------p+,c-1 •

500
ANALYSIS OF CATEGORICAL DATA
Thus, the number of estimated parameters is k =(r - 1) + (c - 1), and consequently the 
number of degrees of freedom of the limiting distribution of (15.6) is
rs - 1 - (r - 1) - (c - 1) = (r - 1)(c - 1). 
(15.7)
Finally, we know that the MLE of a probability in multinomial distribution is the relative 
frequency, so
A 
N+j
P+j = —
+j n
N 
Ni+
P i + = — 
n
where
Ni+ = 
Nij ,
j
N+j = 
Nij .
i
(15.8)
Thus, pij = Ni+N+ j/n2, and substitution into (15.6) gives the following theorem.
Theorem 15.3.1 Assume that n elements of a random sample are classified according to two 
attributes with r and c categories, respectively, producing a contingency table (count matrix) 
[Nij]. For testing the hypothesis
H0 : row and column classifications are independent
against the general alternative
Ha : hypothesis H0 is false,
one can use the statistic
Q2
rc
= i=1 j=1
(Nij - Ni+N+ j/n)2 
Ni +N+j/n
(15.9)
which (under H0) has limiting chi-square distribution with (r - 1)(c - 1) degrees of freedom.
Any deviations from H0 tend to increase Q2. So the critical region contains values of Q2 
that exceed X2a,((r-1)(c-1).
■ EXAMPLE 15.9
The Special Election Issue of Newsweek (November/December 1992) gives the exit poll 
results for the 1992 presidential election. One of the tables is the following:
Clinton
Bush
Perot
White
87%
41%
38%
21%
Black
9%
82%
11%
7%
Although the conclusion seems quite clear, let us try to analyze this table and test the 
hypothesis that the preferences for the three candidates are independent of race. The 
total sample size given is n =15, 241 voters, and the margin of error is given as 1.1% 
points.
Observe first that the marginal percentages of whites and blacks do not add up to 
100%, which means that the data for 4% of the voters (e.g., Hispanics) were not taken 
into account. Thus, we can estimate the sample size for our test to be about 0.96 х 
15, 241 = 14, 631. Now the marginal totals for whites and blacks can be estimated as
Nw , = 14, 631 х ---- °'.87---- = 13, 259,
W+ 
, 
0.87 + 0.09 
, 
,
and therefore NB+ =1, 327.

HOMOGENEITY AND INDEPENDENCE
501
Next the percentages in each row add to 100%; this allows us to estimate the counts 
NW,Clinton, NW,Bush, and so on. The whole contingency table takes on the form
Clinton
Bush
Perot
White
5,436
5,039
2,784
13,259
Black
1,125
151
96
1,372
6,561
5,190
2,880
14,631
We can now compute the observed value of statistic Q2 given by formula (15.9). We 
obtain here Q2 = 845.2, which exceeds the critical value for a chi-square distribution 
with 2 degrees of freedom chosen for any reasonable level of significance a. The race 
and voting preference are definitely dependent.
Continuing this analysis, we could ask what confidence level the pollsters use in 
announcing their “margin of error.” Here it is given as ±1.1% points. We are estimating 
here the true proportion p on the basis of sample of size n =14, 631. If X is the number 
of observations of a given category, then X has a binomial distribution with param­
eters n and p; hence, X is approximately normal N(np, np(1 - p)). Consequently, 
the estimated percentage, 100p = 100X/n, has an approximate normal distribution 
with mean E(100p) = 100p and Var(100p) = 1002 Var(X/n) = 1002p(1 — p)/n. The 
(1 — a)-confidence interval for the mean 100p is 100p ± za/2^Var100p.
The fact that the error given is the same for all data (instead of depending on the 
observed percentage) suggests that an upper bound p(1 — p) < 1 /4 is used. We have 
therefore the inequality
_ J1002p (1 — p )^~ 
100
za/2 V 
n < za/2 j4 x 14, 631.
The right-hand side equals 1.1 for za/2 = 2.575, which suggests that the pollsters used 
a 99% confidence level.
The chi-square test for independence described in Theorem 15.3.1 concerns the case where 
the counts Nij arise from a cross-classification of independent and identically distributed 
observations. In experiments where one of the classification variables is not random but 
controlled by the experimenter, the data cannot be treated as a sample from a bivariate dis­
tributions.
■ EXAMPLE 15.10 Prospective and Retrospective Studies
Data summarized in contingency tables are usually used to analyze the hypothesized 
relationship between cause and effect (also referred to as stimulus and response, 
explanatory and response variable, independent and dependent variable, etc.). Let X 
and Y denote these variables, with X having r categories (also referred to as levels or 
treatments, depending on the context) and Y having c categories.
In prospective studies, one selects groups of subjects corresponding to various levels 
of X and then classifies each group separately according to levels of Y . For instance, 
in the social sciences, one may be interested in productivity (Y ) and its dependence on 
stress level (X). The data may result from selecting r groups of subjects, exposing the 
ith group to the ith stress level, and then observing levels of productivity. Consequently, 
the totals Ni+ (sizes of groups exposed to levels of stress) are not random. Similarly

502
ANALYSIS OF CATEGORICAL DATA
in medical research, one may select two groups of patients and then administer the 
treatment being studied to one group and a placebo to the other group. The response 
Y can be observed in both groups. Again, the sizes of the groups are not random but 
are under the control of the experimenter.
In retrospective studies the situation is similar, except that now the marginal counts 
N+j of the response categories are controlled by the experimenter. An example might 
be provided by typical data on smoking habits and lung cancer. A sample of subjects 
who died from lung cancer is selected and compared with a sample (possibly matched 
with respect to various attributes such as sex, age, etc.) of subjects who died from other 
causes. The sizes of these two samples are chosen largely at will. The two samples are 
then classified according to categories related to smoking.
For the analysis of contingency tables in which one of the marginal frequency vectors is 
fixed, let us first introduce the appropriate notation and then formulate the hypothesis to be 
tested.
The data form, as before, a count matrix [Nij ], with marginal counts Ni + = j. Nij 
and N+ j = iNij. The total number of observations is n = ij Nij. For the sake of 
argument, assume that the counts Ni+,i=1, ...,r, are not random. For each i, the vector 
(Ni1 , Ni2, ...,Nic) is assumed to represent the counts from Ni+ iid observations, sampled 
from the distribution corresponding to the ith level of the first attribute. The probabilities in 
this distribution will be denoted by (p 1 ii,p2ii, ... ,pcii), where p 1 ii + p2ii +---------- + pcii = 1.
Here, pj |i stands for the probability that the observation will fall into the jth class of the 
second attribute, if the sample is taken from the population of objects with the ith level of 
the first attribute. Note that pj|i is not a conditional probability as long as i is not random. 
We use, however, the symbols appropriate for conditional probabilities, since in the special 
case where i is random, we have the obvious relation
pij = pj|ipi+. 
(15.10)
The hypothesis of interest here is the hypothesis of homogeneity, which may be stated as 
follows:
H0 : distributions (p1|i, ...,pc|i) do not depend on i; 
(15.11)
that is, for each j, we have pj^ 1 = • • • = p^r = pj.
As before, we will obtain a test for H0 against the general alternative
H1 : hypothesis H0 is not true.
Despite the differences between the independence hypothesis and the homogeneity hypoth­
esis above, they are tested by the same statistic. Indeed, for any fixed i, the component of the 
chi-square sum is
(15.12)
22 \ (Nij - Ni+pjli)2
i 
j=1 
Ni+p jli 
,
where pj^i is the MLE of probability p^i. Clearly, under the null hypothesis of homogeneity 
we have
2 
2 
\ ' (Nij — Ni+pj)
i 
j=1 
Ni+pj
and pj = N+j/n (i.e., the MLE of pj is the relative frequency of the jth category). Adding 
over i, we obtain the test statistic
Q 2 = A v (Nij — Ni+N+j /n)2
Q 
=j=1. 
Ni+N+j ^n
(15.13)

HOMOGENEITY AND INDEPENDENCE
503
The number of degrees of freedom equals r(c - 1) - k, where k is the number of estimated 
parameters. Indeed, each Qi2 will have c - 1 degrees of freedom if the value pj is known. The 
parameters estimated are p1, ...,pc-1, so k = c - 1, and we obtain the following theorem:
Theorem 15.3.2 If the null hypothesis H0 (15.11) is true, and if Ni + ^ ж for i = 1, .. .,r, 
then the statistic Q2 given by (15.13) has the limiting chi-square distribution with r(c - 1) - 
(c - 1) = (r - 1)(c - 1) degrees of freedom.
Any violation of the null hypothesis will tend to increase the value of Q2 . So, again, the null 
hypothesis will be rejected if the observed value of the statistic Q2 exceeds x2a (r-1)(c- 1).
PROBLEMS
15.3.1 Show that in the case of a 2 x 2 contingency table, the statistic Q2 given by (15.9) is 
proportional to (N11N22 - N21N12)2, and find the proportionality constant.
15.3.2 For each 3 x 4 contingency table below find such k that the hypothesis about inde­
pendence of two classification variables is rejected at the 0.05 significance level.
(i) kkkk(ii) 55 
5 
5
kk0 k 
55k 5.
kkkk 
5555
15.3.3 Mrs. Smith, who teaches an elementary statistics course, classified each student in the 
class according to whether the grade on the first exam was below or above the median 
for this exam, and then did the same for the second exam. The results obtained are 
as follows:
Second exam
First exam 
Below 
Above
Below 
30 
5
Above 
5 
30
Compute Q2 and find the p-value. What legitimate conclusion can be made?
15.3.4 Professionals from various disciplines participated in a study on job-related stress. A 
random sample of size 100 was selected from each group of professionals (physicians, 
engineers, and lawyers), and each person was asked to evaluate the level of job-related 
stress as low, moderate, or high. The results of a study are given below.
L
M
H
Physicians
5
25
70
Engineers
25
25
50
Lawyers
10
30
60
Specify the hypothesis to be tested, perform the test, and make the appropriate con­
clusions.
15.3.5 A random sample of 29 university students was selected and each student was then 
classified according to their high school GPA and college GPA. Both classifications 

504
ANALYSIS OF CATEGORICAL DATA
had the same two categories: “I, below 3.0,” “II, at least 3.0.” Formulate a hypothesis 
to be tested. Perform the test and make appropriate conclusions.
High school 
GPA
College GPA
I 
II
I
II
53
12 
9
15.4 CONSISTENCY AND POWER
Chi-square tests of either independence or homogeneity serve as tests against a general alter­
native, asserting simply that the null hypothesis is false (such tests are called omnibus tests). 
If the independence hypothesis is not true, then (as the sample size increases) the probability 
of rejection of the null hypothesis tends to 1. We may rephrase this property by stating that 
power of the chi-square test for independence tends to 1 for any simple hypothesis contained 
in the alternative as the sample size increases. This property of the test is called consistency.
The situation is similar in the case of tests for homogeneity, except that now the sample 
sizes refer to rows (levels of explanatory variable), and are determined not by chance but 
by the experimenter. Again, if the null hypothesis is not true, then at least two of the rows 
of the matrix [pi|j] are different. The power of the chi-square test will tend to 1 on a simple 
alternative in which the rows labeled i0 and i0 are different, if the sample sizes Nio + and 
N + both tend to infinity.
In general, it is difficult to analyze the power of chi-square tests for independence or 
homogeneity, since it involves determining the exact or limiting distribution of a statistic 
under some distribution in the underlying population.
However, if one looks at the main motivation ofan analysis of the power ofa test, namely 
to decide “which hypothesis should be accepted if one rejects null hypothesis,” then one can 
suggest the following approach.
When the null hypothesis is not valid, it typically is due to the fact that there is a strong 
association between some specific values of the two attributes analyzed, while for other val­
ues the null hypothesis is, at least approximately, satisfied.
In symbols, the null hypothesis (of independence) asserts that all absolute differences
|pij - pi+p+j| 
(15.14)
are zero. If the null hypothesis is not valid, then there exist absolute differences that are 
positive. What typically happens in such cases is that a few of those differences are high; 
other may be close to zero (rather than all of these differences being small). In these cases, 
one would like to identify the cells for which the differences (15.14) are high.
To present the solution, let us first derive an alternative to the chi-square test, namely 
the generalized likelihood ratio (GLR) test (see Section 12.6). Consider the case of testing 
the hypothesis of independence, which states that pij = pi+p+j for all i, j. The union of 
H0 and H1 allows the probabilities pij to be arbitrary (subject only to the constraint that 
i jPij = 1). The data form the contingency table [Nij].
The likelihood of the data is (up to a multiplicative constant) equal to L = Пi Пj (Pij) Nij• 
It is maximized at pj = Nij/n, where n 
ij Nij is the total sample size. Consequently, the
denominator in the GLR, equal to the maximum over all parameter space, is
sup L = П П ^Nj = n-n П П (N.j) Nij.
Hо UH i 
n 
-
01 
ij 
ij

CONSISTENCY AND POWER
505
On the other hand, the likelihood over the null hypothesis equals (up to the same multiplica­
tive constant)
L = 
(pi+)Nij (p+j)Nij .
This is maximized at pi + = Ni+/n and p+j = N+j-/n, and we obtain
max L =
H0
i
N^ A N++
Ni+
П 
j
N i+
n
= n-2n 
(Ni+)N+i (N+j)N+j .
The GLR equals therefore
ni(Ni+)Ni + Пj(N+ j)N+j = nn (Ni+N+ jANij 
nn 
(N- •) Nij 
nN- - 
/
n i j ij 
i j n ij
(15.15)
Under the null hypothesis H0, the statistic 
G2
- 2 log A = 2 £ 
Nij log
i=1 j=1
Nij
(Ni + N+j)/n
(15.16)
has a limiting (as n — ж) chi-square distribution with a number of degrees of freedom equal 
to the difference in the number of estimated parameters in the denominator and in the numer­
ator. Thus, the number of degrees of freedom is
(rc - 1) - [(r - 1) + (c - 1)] = (r - 1)(c - 1).
Symbolically, we may write Q2 = (Nij - E(Nij))2/E(Nij), where Nij and E(Nij) 
stand for observed and expected (under null hypothesis) counts. On the other hand, using 
the fact that 
2
log(1 + x) = x + -2 +-----,
we can write
G2 = 2 E Nj log (j = 2 E Nij log (1 + jNNj ) 
i,j 
ij 
i,j 
ij
~ 2V N Nij - E (Nij) , y( Nij - E (Nij ))2 x N
~ j ij 
E (Nij) 
+ j 
E (Nij) 
E (Nij) •
Now, as n — ж, we have Nij/E(Nij) — 1 in probability, and also E[J2(Nij — E(Nij))] = 
0. This suggests that the first sum is close to 0, and the second sum is close to Q2 .
Although the argument above falls short of being a proof, it suggests that Q2 and G2 are 
close to one another for large samples. In fact one can show that Q2 - G2 — 0 in probability 
as n —ж. The idea of using the statistic G2 to investigate the power lies in the additivity 
property of the chi-square distribution. If W has xk distribution, and k = k 1 + k2 + • • • + ks 
is a sum of positive integers, then there exist independent random variables Y1 , • ••,Ys such 
that W = Y1 + • • • + Ys and Yi ~ x2ki.
In the case under consideration, we have the random variable G2 given by (15.16), which 
(under the null hypothesis) has a limiting chi-square distribution with (r - 1)(c - 1) degrees 

506
ANALYSIS OF CATEGORICAL DATA
of freedom. It may be shown that G2 can be represented as a sum of independent ran­
dom variables G12 , ...,Gs2, each corresponding to a subtable of the original contingency 
table.
The subtables are obtained by taking a part of the original table and then collapsing some 
of the categories. Goodman (1969, 1971) and Lancaster (1949, 1969) formulated following 
necessary conditions for components Gi2 in the sum
G2 = G 2 + G 2 + ••• + G2 
(15.17)
are independent:
1. The degrees of freedom for the components G12 , ...,Gs2 must sum to the number 
(r - 1)(c - 1) of the degrees of freedom of G2.
2. Each cell count Nij of the original table must appear in exactly one subtable.
3. Each of the marginal counts Ni+ and N+j of the original table must appear as marginal 
count in exactly one subtable.
If all three conditions are satisfied, then the values of statistic G2 computed for the whole 
table and for the subtables satisfy (15.17).
■ EXAMPLE 15.11
Consider a 3 x 3 contingency table
Y1
Y2
Y3
Marginals
X1
N11
N12
N13
N1+
X2
N21
N22
N23
N2+
X3
N31
N32
N33
N3+
Marginals
N+1
N+2
N+3
An example of a decomposition satisfying the three conditions of independence is as 
follows:
Subtable 1:
Y1
Y2
X1
N11
N12
N11 + N12
X2
N21
N22
N21 + N22
N11 + N21
N12 + N22
Subtable 2:
Y1 or Y2
Y3
X1
N11 + N12
N13
N1 +
X2
N21 + N22
N23
N1 +
N11 + N12 
+N21 + N22
N13 + N23

CONSISTENCY AND POWER
507
Subtable 3:
______________Y1 
Y2
X1 or X 2 N11 + N21 
N12 + N22
X 3___________ N31________ N32
N+1 
N+2
N11 +N12 
+N21 + N22 
N31 + N32
Subtable 4:
____________Y1 or Y2 
Y3______________________
X1 or X 2 N11 + N12 
N13 + N23 
N1+ + N2+
+N21 + N22
X 3_________ N31 + N32_______ N33_________N3 +
' N+1 + N+2 
N+3
The number of degrees of freedom of the original table is 4, and for each of the 
subtables it is 1, so the first condition is met.
Regarding conditions 2 and 3, we can check that they are met by simple inspection. 
In the four subtables, all entries and marginals from the original table are identified by 
boldface.
The algebraic verification that the condition (15.17) holds can be found in Lancaster 
(1949). Here we observe only that the partition of this example is not the only one 
possible for a 3 x 3 table: There are eight other partitions.
■ EXAMPLE 15.12
In a study of marijuana use in colleges, 445 students were sampled and classified 
according to a response variable (use of marijuana or other drugs) into three 
categories: “never,” “occasionally,” “regularly.” As a possible explanatory variable, 
the experimenters selected the number of parents who were alcohol or drug users 
(“neither one,” “exactly one,” “both”). The data that follow are from Devore (1991):
Student’s drug use
Parents’
drug use
Never (N)
Occasionally (O)
Regularly (R)
None
141
54
40
235
One
68
44
51
163
Both
17
11
19
47
226
109
110
445
For 3 x 3 tables, the statistic G2 has a limiting chi-square distribution with 4 degrees 
of freedom. The value for the table above is G2 = 22.254, which is highly significant 
(p-value equals 0.00018). Incidentally, for this table we have Q2 = 22.394, which illus­
trates the closeness of G2 and Q2 for large samples. Thus, we may conclude that there 
is a relationship between parental and student use of drugs.
One of the questions we could ask here is whether a positive or a negative example 
is stronger. In other words, taking for granted that the frequency of marijuana use 

508
ANALYSIS OF CATEGORICAL DATA
tends to increase with the number of parents who use alcohol or drugs, the question 
is whether the effect of a bad example of one parent tends to outweigh the good 
example of the other parent. To get an insight into this question, we consider two 
decompositions of G2 . The first decomposition correspond to the following four 
subtables:
1
2
3
4
N
O
N + O
R
N
O
N + O
R
None
141
54
195
40
At most one
209
98
307
91
One
68
44
112
51
Both
17
11
28
19
The values of G2 four these for tables are, respectively, G21 = 4.344, G22 = 
10.957, G23 = 0.616, and G24 = 6.336, and we check that G2 = G21 + G22 + G32 + G42. 
The corresponding p-values for 1 degree of freedom are, respectively, 0.037, 0.001, 
0.432, and 0.012.
An alternative decomposition is as follows:
1*
2*
3*
4*
O
R
N
O + R
N
O
N + O
R
One
44
51
68
95
Neither
54
40
141
94
Both
11
19
17
30
At least one
55
70
85
125
Now the values are G2, = 0.871 ,G2, = 0.470,G2, = 3.893, and G2, = 17.019. The 
corresponding p-values are 0.351, 0.493, 0.048, and 0.000.
These results indicate that a bad example, of just one parent, has a big influence on a 
student’s marijuana use. As subtables 1* and 2* show, if at least one parent uses drugs 
or alcohol, then it does not really matter whether the other parent does as well. On the 
other hand, as subtables 3* and 4* show, there is a significant difference where none 
of the parents use drugs or alcohol. This effect increases greatly the likelihood that 
a student will never use the marijuana, and—if he uses it—at a decreasing frequency 
of use.
The conclusions are strengthened if one analyzes also a first decomposition. Here 
the category “one” is either compared with “neither,” or category “at most one” is 
compared with category “both.” As can be seen, subtables 1, 2, and 4 show the signifi­
cant effect of a parent using alcohol or drugs. Subtable 3 shows that any positive effect 
of the other parent is limited. The presence or absence of a positive model does not 
have any significant effect on the frequency of marijuana use as long as this frequency 
is low (or zero). Subtable 4 suggests that the presence of a positive parent role model 
has only the effect of lowering the probability of a regular use of marijuana during the 
college years.
PROBLEMS
15.4.1 Find a decomposition of G2 into independent components by decomposing: (i) A 
2 x k table. (ii) A 3 x 4 table.
15.4.2 The data on the incidence of a certain disease, classified by age and gender, are as 
follows:

2 х 2 CONTINGENCY TABLES
509
<20 
20-39 
40-59 
60+
Men 
10 
15 
30 
40
Women 
20 
30 
60 
300
Find the values of statistics Q2 and G2 . Find the decomposition of G2 , and verify 
that the “source” for lack of independence is the very high incidence of this disease 
among women over 60.
15.4.3 At the beginning of the semester a random sample of 104 students was selected out of 
students in all introductory statistics classes. Students were then classified according 
to their GPA (I, “below 3.0”; II, “between 3.0 and 3.5”; and III, “above 3.5”) and their 
attitude toward the statistics course (i, “I hate to take this class but I have to”; ii, “I 
do not mind taking this class but it is not one of my favorites”; iii, “I look forward to 
taking this class”). The results of classifications are given below.
i
ii
iii
I
14
8
2
II
10
14
12
III
6
16
22
Test the hypothesis of independence of both classification variables. In the case of 
lack of independence, use decomposition to identify the cause of dependence.
15.5 2 x 2 CONTINGENCY TABLES
We begin with the simplest, but very common situation, where both variables have only two 
categories (i.e., are treated as binary variables). Denoting those levels by 1 and 2; we have then 
two distributions of the response, corresponding to the values of the explanatory variable, 
namely
(p1|1,p2|1) and 
(p1|2,p2|2),
where p2|1 =1-p1|1 and p2|2 =1-p1|2.
The null hypothesis of homogeneity reduces to
H0 : p Hi = 1
p12 2
When response 1 is in some sense undesirable (death, relapse of disease, etc.), the ratio 
p1|1 /p1|2 was often called the relative risk. This term is now used generally regardless of the 
context (similarly as “success” and “failure” in a binomial distribution).
The alternative hypothesis of a positive association asserts that a higher value of explana­
tory variable gives a higher probability of a higher value of the response variable, that is, 
p2|1 < p2|2 . The latter inequality is equivalent to 1 - p1|1 < 1 - p1|2 ; hence p1|1/p1|2 > 1. 
Similarly, a negative association means that the relative risk is less than 1.
An alternative formulation, which also suggests a testing procedure, is as follows: Con­
sider a binary distribution (n, 1 - n), where n is the probability of some event A. Then the 
ratio
П
n =1-n 
(15.18)
is called the odds (for the event A). It is clear that n determines n uniquely, namely n = 
n/(1 + n). As n increases from 0 to 1, the odds n increase from zero to infinity. The odds

510
ANALYSIS OF CATEGORICAL DATA
for the complement of the event A are 1 /n. In the case of the distributions (p 111 ,p211) and 
(p1|2 , p2|2 ), the odds (for the response 1) are
p1|1
П 1 = —— 
and
1 
p2|1
p1|2 
n 2 = —
p2|2
To formulate the null and alternative hypotheses, it appears natural to consider the odds
ratio:
в = n ■ = p 111p 212 = p 11 p 22
П 2 
P 112 P 211 
P 12 P 21,
(15.19)
where the latter expression is meaningful in the case where the explanatory variable is 
random.
The null hypothesis, of either homogeneity or independence, has the form
H0 : в =1. 
(15.20)
The alternative H1+ of positive and H1- of negative association are, respectively, 
H1+ : в>1 and 
H1- : в<1. 
(15.21)
Suppose now that the null hypothesis H0 : в =1 is to be tested against the alternative 
of positive association H+ : в > 1. The data have the form of a 2 x 2 count matrix 
(contingency table):
N11 
N12
N21 
N22
The question is: How to determine the P-value of the observed contingency table, that is, the 
probability(calculated under the assumption that the null hypothesis is true) of observing—if 
the experiment were to be repeated—a contingency table that will at least be as much in favor 
of the alternative as the contingency table actually observed.
To implement the idea of determining the P-value of the observed result, one needs to 
proceed as follows:
1. Explicate the ordering of the contingency tables according to the relation of “being more 
in favor of the alternative hypothesis.”
2. Specify the probabilities of occurrence of the various contingency tables under the null 
hypothesis. (Note that the null hypothesis of independence is composite; hence it does not 
lead directly to numerical values of probabilities.)
Regarding step 1, as a statistic, one can take a sample counterpart of the odds ratio в, replac­
ing the probabilities Pij by the corresponding relative frequencies Nij /n, where n is the total 
sample size. This leads to the statistic U, defined as
U = N11 N22
N12 N21
(and U = ж if N 12 or N21 is zero).
Thus, if the observed contingency table is [nij], then the P-value of this result is defined
formally as
N11N22 >
N12 N21 “
n 11 n 22
n 12 n 21
(15.22)
It remains to specify the probability distribution P0 on a suitably selected class of 2 x 2 
contingency tables. The main requirement is that P0 should not depend on any parameters

2 х 2 CONTINGENCY TABLES
511
so that its numerical value can be determined for every contingency table for which P0 is 
defined.
Now, ifwe take a random sample of size n from a population whose elements are classified 
according to two dichotomous classifications, then the probability of a particular contin­
gency table with its sum of entries equal n is given by the multinomial distribution
n!
P {Nij = nij ,i,j = 1, 2 } 
-----, 
-----j. P П111 P П12 P П221 P П22. 
(15.23)
j j 
n11!n12!n21!n22! 11 12 21 22
If the null hypothesis H0 is true, then Pij = Pi+P+j , and substitution into (15.23) gives
Ph о {Nij = nij ,i,j = 1, 2} = 
, n! , 
, P n++ P П++ P++1 P++2, 
(15.24)
H0 
ij ij 
n11!n12!n21!n22! 1+ 2+ +1 +2
where ni+ = ni1 + ni2 and n+j = n1j + n2j for i, j =1, 2.
It should be clear that in order to obtain the probabilities of the contingency tables that 
do not depend on the parameter, it is necessary to restrict the definition of P0 to the class 
of tables with given marginals ni+ and n+j (i, j =1, 2). This suggests taking as P0 the con­
ditional probabilities given both marginals, since the product P1n+1+ P2n+2+ Pn++11 Pn++22 will then 
cancel.
We have, for the probability of marginals being (n1+, n2+) and (n+1, n+2), the product 
of two binomial probabilities:
P{N1+ = n 1+} = ( n } Pn++ (1 - P1+)n-n 1+ = ( n } Pn++ Pn++ 
n1+ 
n1+
and
P{N+1 = n+1} = 
n 
Pn++11(1-P+1)n-n+1 = n 
Pn++11Pn++22.
n+1 
n+1
Consequently,
P{N1+ = n1+,N+1 = n+1} = P{N1+ = n1+}P{N+1 = n+1} 
(15.25)
n 
n 
n1+ n2+ n+1 n+2
= 
P1+1+P2+2+P++11P++22.
n1+ 
n+1
Dividing (15.24) by (15.25), we obtain, after rearranging the multinomial coefficients, the 
following theorem in which Nij (x) is the 2 x 2 table with given marginals and N11 = x :
Theorem 15.5.1 Under the null hypothesis H0 : в = 1, for any integers n,n 1+, n +1 satisfying 
the conditions n > 0, 0 < n 1+ < n, 0 < n +1 < n,
)
P{[Nij] = [Nij(x)]|N1+ = n1+,N+1 = n+1} =
(n+1)(n-n+1 
n1+ -x
U+)
(nr)(n-n1+ 
n+1 -x
(n+l)
(15.26)
)
Observe now that we have
n11n22 x(n - n1+ - n+1 + x) 
n 12n21 
(n 1+ - x)(n +1 - x) ’

512
ANALYSIS OF CATEGORICAL DATA
which is an increasing function ofx. This means that the ordering of contingency tables with 
the same marginal totals coincides with an ordering with respect to the element x = n11. 
Consequently, in view of Theorem 15.5.1, the p-value defined by (15.22) becomes
Е
Х>П 11
(n x+)( n-n1+ 
n+1 -x
U)
)
■ EXAMPLE 15.13
To study whether or not there exists a positive association between musical and math­
ematical abilities, a group of 12 fourth graders was classified according to their scores 
(high or low) in these subject areas. The results are as follows:
Mathematics
Music 
High 
Low
High 
4 
1 
5
Low 
2 
5 
7
6 
6 
12
Do the observed data lead to rejecting the null hypothesis of independence of musical 
and mathematical abilities in favor of the alternative of a positive association?
SOLUTION. There is only one contingency table with the same marginals as original 
one, which is more in favor of the alternative, namely
50
1 
6
6 
6
5
7
12
The p-value of the observed result is therefore the sum of probabilities of both tables; 
hence it is
57 
57
\4Z \2 
5/ \1Z _ 0 121
(162) + (62) 
0'121'
Clearly, at level 0.1 (and therefore also at any lower level), the null hypothesis should 
not be rejected: There is about a 12% chance of observing a result at least as much in 
favor of the alternative hypothesis if only due to random fluctuations (i.e., ifin fact the 
null hypothesis is true).
Let us mention here that the test as described above is applicable also to the cases of 
prospective or retrospective studies where one of the marginals is not random. Indeed, if the 
marginals n1+ and n2+ are selected by the experimenter, then the contingency table is
n11 n12
n21 
n22
n+1 n+2
a 
b
n

2 х 2 CONTINGENCY TABLES
513
(where we let a and b denote the nonrandom marginals to distinguish them from the random 
marginals). The corresponding table of conditional probabilities, under the null hypothesis 
of homogeneity, is
P111 P 211 "I = Г Y 1 - Y
_P 112 P212 
|_Y 1 - Y _ '
The likelihood of the data, under the null hypothesis, is therefore a product of two binomial 
probabilities:
a Yn11(1 - Y)n12 
b 
Yn21(1 - Y)n22
Yn+1(1 - Y)n+2. 
n+1 - n11
On the other hand, the probability of the observed column marginals is, again under H0 ,
n 
Yn+1(1 - Y)n+2
n+1
Thus, the conditional probability, given the column marginal, is free of Y, and it equals 
na11
n-a 
n+1-n11
U)
)
which agrees with (15.26).
■ EXAMPLE 15.14
Returning to Example 15.13, the P-value of the observed contingency table would be 
the same as calculated there (i.e., about 0.12) if we selected six students with high and 
six with low math scores, and then classified them according to their music scores.
■ EXAMPLE 15.15
Twenty occasional headache sufferers participated in testing a newly developed 
headache remedy. They were given the drug and later asked whether or not it was 
significantly better than the drug they usually took. In fact, however, every fourth 
subject tested received not a drug but a placebo. The data are as follows:
Significant No significant 
improvement 
improvement
Drug 
11 
4 
15
Placebo 
3 
2 
5
14 
6 
20
Do these data indicate that the new drug is better than the drugs usually taken?
SOLUTION. We are testing here the hypothesis of homogeneity against the alternative 
of a positive association between taking the new drug and beneficial effects for patients. 
To determine the P-value, observe that the count n11, given the marginals, may be only

514
ANALYSIS OF CATEGORICAL DATA
11, 12, 13, or 14 if the table is to be at least as much in favor of the alternative as the 
observed one. Tables
11 4
32
12 3
23
13 2
14
14 1
05
have probabilities
15 
5 
15 
5
1U/ УЗ/ _ 0 352 у 12/ У2/ 
/20\ 
0.352, 
200\
14 
14
= 0.117,
15 
5 
15 
5
u; = 0 014 in; = 0 0004 
/00\ 
0.014, 
20 
0.0004,
14 
14
respectively. Hence, the p-value is about 0.48, so there is no evidence to back the claim 
that the new drug is superior to the drugs used so far.
The testing procedure described above is known as the Fisher’s exact test (see Section 
12.7). In testing the null hypothesis H0 : 6 =1 against a two-sided alternative H 1 : 6 = 1, 
one encounters the usual problem of defining p-values in the case of two-sided alter­
natives. There seems to be no agreement among statisticians as to what is the proper 
procedure in such situations. In the case of continuous and symmetric distributions of 
a test statistic (e.g., Student’s t), the p-value for the observed result is usually taken as a 
doubled p-value for the one-sided alternative. In the case of an asymmetric distribution, 
there is little justification of doubling the one-sided p-value. In the case of discrete 
distributions, an additional source of difficulty is that by such a procedure one can 
obtain a value exceeding 1. Some authors suggest taking as the p-value the sum of all 
probabilities of tables that are at most as likely as the observed one (see Freeman and 
Halton, 1951).
In all situations already considered in this section, observations were classified accord­
ing to two arbitrary variables. There are, however, cases when classification variables are 
dependent, very often it is the same classification variable applied to data collected on two 
occasions. For example, one might want to study the effect of a certain medical treatment 
by comparing data from some tests collected from the same patients before and after the 
treatment was administered. If the classification variables have dichotomous response (such 
as 0 and 1, “Yes” and “No,” etc.), one can use the so-called McNemar’s test to compare 
marginal distributions. The McNemar’s test is considered a counterpart of a matched-pair 
t test discussed in Chapter 12. The data to be analyzed are summarized as in the table 
below:
Variable 2
Variable 1 
Yes 
No
Yes 
Nii 
Nio 
N1+
No 
Noi 
Noo 
No+
N+i 
N+o 
n
Marginal distributions are (pi+, p2+) and (p+i, p+2) for variable 1 and variable 2, respec­
tively. To test if marginal distributions of classification variables are the same (marginal 
homogeneity), we will be testing
H0 : pi+ = p+i against Hi : pi+ = p+i. 
(15.27)

2 х 2 CONTINGENCY TABLES
515
Hypotheses in (15.27) reduce to hypotheses
H0 : p12 = p21 and 
H1 : p12 = p21.
(15.28)
Of course we could perform the McNemar’s test against one-sided alternatives, either
H0 : p1+ = p+1 against H1 : p1+ > p+1, 
(15.29)
or
H0 : p1+ = p+1 against H1 : p1+ < p+1.
(15.30)
The measure of the difference between marginal probabilities p1+ - p+1 reduces to p12 - p21 
and its MLE is the difference of relative frequencies N12/n - N21/n. Under the H0 the distri­
bution of N12 is BIN(N*, 1 /2), where N* = N12 + N21. Since it is a symmetric distribution, 
its normal approximation N(N* /2, N* /4) can be applied for N > 10. Consequently, the test 
statistic we then take
Z = N12 - N *//2 
^N*/4
N12 - N21 
J N12 + N21
(15.31)
has approximately N(0, 1) distribution.
■ EXAMPLE 15.16
A students who was not doing well in his statistics class was offered an online tutorial to 
enhance his algebra skills. To assess the effectiveness of an online tutorial, the student 
was required to take a pre-test at the beginning and a post-test at the of the last tutorial 
session. Both, pre- and post-tests consisted of the same 30 multiple-choice questions 
so each answer was either correct or incorrect. Student’s results are summarized in the 
table below.
Post-test
Pre-test Correct Incorrect
Correct 
6 
2 
8
Incorrect 
18 
4 
22
24 
6 
30
Did the student improve his algebra skills by taking the online tutorial?
SOLUTION. Here we will be testing null hypothesis H0 : p12 = p21 of no change 
against one-sided alternative H 1 : p 12 < p21. The value of the test statistic (15.31) is 
(2 - 18)/^2 + 18 = -3.578, what corresponds to p-value equal 0.0002. The data pro­
vide strong evidence that student’s algebra skills improved by taking online tutorial.
At the end of this section, we would like to mention that similarly to all tests that were 
discussed, we could obtain confidence intervals for various statistics. Unlike the McNemar’s 
test statistic that uses only the information about the counts in different categories for two 
variables (N12 and N21), while the counts N11 and N22 are irrelevant, the formula for the 
confidence interval depends on all four counts. Interested readers are advised to check the 
texts on the analysis of categorical data, for example Agresti (2002).

516
ANALYSIS OF CATEGORICAL DATA
PROBLEMS
15.5.1 Use the data from Problem 15.3.5 to test if high school GPA’s are positively related 
to college GPA’s.
15.5.2 Two out of ten randomly selected men, and four out of ten randomly selected women 
were found to be allergic to some drug. (i) Does these data indicate that there is a 
difference between men and women in their propensity to develop an allergic reaction 
to the drug in question? (ii) Does these data indicate that men are less likely than 
women to develop an allergic reaction to the drug in question? Find corresponding 
p-values for (i) and (ii) and explain why are they different.
15.5.3 A study of change in employment status was conducted among residents of a certain 
county. A random sample of 100 adult residents was surveyed on their employment 
status, and their responses (Yes/No) were recorded. The same people were contacted 
after 12 months and asked the same question. Their answers are summarized in the 
table below. Does the employment status in the county changed significantly within 
these 12 months?
Survey 2: Employed
Survey 1: Employed 
Yes 
No
Yes 
80 
10 
90
No 
2 
8 
10
82 
18 
100
15.5.4 Fifty randomly selected college students that take courses with on-line quizzes were 
classified according to their answer on two questions: “Do you cheat taking on-line 
quizzes?” and “Do other students that you know well cheat taking on-line quizzes?” 
Explain what can be said about student’s cheating. Formulate appropriate hypotheses 
and perform the test using the data in the table below.
Other students cheat
Student 
Yes 
No
Yes 
5 
2
No 
13 
30
15.6 R x C CONTINGENCY TABLES
At the end, we will extend the results for 2 x 2 to the general case of r x c tables, in which 
the categories corresponding to rows and those corresponding to columns are ordered. The 
assumption of Theorem 15.5.1 carries over to the present case. By conditioning on both 
marginals, we obtain (under the null hypothesis of independence or homogeneity) a prob­
ability distribution defined on the class of all r x c tables with the given marginals, which 
does not involve any unknown parameters.
For the case where both marginals are random, the situation is as follows: Suppose that we 
take n independent observations, each with the same distribution, and classify them accord­
ing to two systems with r and c categories, respectively. The cell counts are Nij , and the 
marginal counts are Ni+ and N+j, where i =1, ...,r and j =1, ...,c.Wehavethenthe 
following theorem:

R x C CONTINGENCY TABLES
517
Theorem 15.6.1 Under the assumption of independence, for any contingency table [nij], i =
1, ...,r,j =1, ...,s, with i,j nij = n and with marginal counts ni+ and n+j, we have
РГГДГ If 11ДГ _ 
i= 
_ 
1 _ EL=1( ni +)!П j =1 (n+j )!
P {[ Nij ] 
[ nij ] |Ni + 
ni + ,N+ j n+j } n! n r Пc (n. .)! 
. 
(15.32)
In order to implement equation (15.22) for the p-value of an observed contingency 
table, say A0, it remains to order all r x c tables with marginals the same as those of A0, 
according to their “strength of support” for the alternative hypothesis of (say) a positive 
association.
In presenting the solution, we will use an approach different than that which we used 
for 2 x 2 tables. Instead of expressing the null hypothesis in terms ofa single parameter and 
then finding its empirical counterpart (as we did in the case of2 x 2 tables), we will introduce 
several indices (statistics, i.e., functions of the observed counts Nij). Each of these indices will 
provide, on an intuitive ground, an ordering of contingency tables according to the strength 
of support for the alternative.
Symbolically, let A0 be the observed contingency table, and let A be any contingency table 
with the same marginals as A0 . Furthermore, let t = t(A) be a real-valued function defined 
on the considered class of contingency tables. Then, the p-value of the observed table is 
defined as
P0(A). 
(15.33)
A: t (A) >t (A o)
The only problem remaining is the choice of statistic t so that its values could reflect the 
order of “strength of support” of the alternative hypothesis. The choices here are based on 
the following idea: Consider a pair of observations. Since each observation is classified as 
belonging to one of the rows and one of the columns, such a pair determines two pairs of 
coordinates, say (r', c) and (r", c').
Definition 15.6.1 The pair of observations is called concordant if
(r" - r')(cc - c) > 0;
it is called discordant if
(r" - r')(cc' - c) < 0,
and it is called tied if (r" - r')(c" - c) = 0.
□
It should be obvious that every concordant pair provides support in favor of the alterna­
tive of positive association: the differences r" - r' and c' - c are both nonzero and of the 
same sign. This means that a higher evaluation on one variable is accompanied by a higher 
evaluation on the other variable. By the same logic, every discordant pair provides a sup­
port for the alternative of a negative association: a higher classification on one variable is 
accompanied by a lower evaluation on the other variable.
Let C = number of concordant pairs, and let D = number of discordant pairs. If we can 
assume that any concordant (or discordant) pair equally supports the alternative, then the 
overall support for the alternative of (say) a positive association is a function of the difference 
C - D. Standardizing this difference, we let
C - D
C + D.
(15.34)

518
ANALYSIS OF CATEGORICAL DATA
The choice of the symbol reflects the fact that Y (the estimator of some parameter y) depends 
on the observed contingency table.
We can now define the p-value of the observed contingency table (in testing the alternative 
of positive association) as the sum of probabilities of all the tables with the same marginals 
as the one observed, and with the value of index Y at least as high as for the original table.
■ EXAMPLE 15.17
For 2 x 2 tables, the numbers of concordant and discordant pairs of observations are 
C = n11n22 and D = n12n21 , respectively; hence
7 = niin22 - n 12n21 = e-±, 
where e = niin22 .
n 11 n 22 + n 12 n 21 в +1 , 
n 12 n 21
Notice that the ordering of the values of Y coincides with the ordering according to the 
values of в.
■ EXAMPLE 15.18
For the case of marijuana use in colleges (recall Example 15.12), the categories repre­
sented by the rows and those represented by the columns were ordered by a natural way: 
by the number of parents who use drugs or alcohol and by the frequency of marijuana 
use by the student.
A concordant pair is formed by observations such that one of them is below and to 
the right of the other:
C = 141 x (44+51+11+19)+54 x (51+ 19) 
+68x (11+19)+44x 19= 24, 281,
and similarly
D =40x (68+44+17+11)+54x (68+ 17)
+51x (17+11)+44x 17= 12, 366.
Thus 7 = 0.325.
To evaluate the p-value corresponding to an observed contingency table, one should use 
a statistical software such as R or SAS.
The index Y7 utilizes only the information contained in the numbers C and D of concor­
dant and discordant pairs. The numbers of tied pairs are not used, since a pair of observations 
tied on one or both variables provides evidence neither in favor of the null hypothesis nor in 
favor of the alternative. However, one could argue that a large number of tied pairs (as com­
pared with C + D) is an indication that the difference C - D might be insignificant. This 
argument has led to the introduction of two indices that take tied pairs into account, called 
Kendall’s tau-b and Somers’ d.
The total number of all possible pairs of observations (disregarding the order) is
n2 = n(n - 1) 
2
Therefore, the total number of tied observations is n(n - 1)/2 - C - D. Let TX, TY , and 
TXY denote numbers of pairs of observations tied on the first coordinate (row), on the second 
coordinate (column), and on both coordinates (falling to the same cell), respectively.

R x C CONTINGENCY TABLES
519
Observe that the categories of ties are not disjoint: any pair tied on both coordinates is 
counted twice, in TX and in TY .
Definition 15.6.2 The statistic
C-D
Tb = , 
(15.35)
b 
[n(n1)/2TX][n(n1)/2TY]
is called Kendall’s tau-b. 
□
Definition 15.6.3 The statistic
C-D
d = ~i----- - - ( 36 
(15.36)
n(n-1)/2-TX
is called Somers’ d.
□
In the formulas above, we have
n (n - 1) 
n (n - 1)
Tx = E + 2------" 
and 
Ty = E jj--------- L ■ 
(15.37)
i=1 
j =1
■ EXAMPLE 15.19
Returning to the marijuana data (Examples 15.12 and 15.18), we have TX =41, 779 
and TY = 37, 306. The total number of all possible pairs is 445 x 444/2 = 98, 790. 
We have here ть = 0■ 201 and d = 0■209 (while 7 = 0■325).
The calculation of the p-value based on ть or d for the alternative of (say) a positive asso­
ciation again uses the sum of all probabilities of tables with the same marginals as those 
observed, and the index ть, or d, at least as high as that for the observed table.
It ought to be mentioned that the very fact ofan introduction ofan index is—to a certain 
extent—an attempt to reduce the problem to one dimension. That enables one to compare 
objects (in this case, contingency tables) and select the best. This may be, however, a deceptive 
comfort, since not all things are comparable in such a simple way. In the present case, just 
thinking in terms of an index (e.g., 7) leads to the danger of attaching significance to certain 
values of that index. For instance, one may tend to take 7=1 first as an indication of a very 
strong positive association (which it is), and then tend to attach to it a fixed significance level. 
To see this, observe that tables
220
022
and
330
022
both have D = 0; hence 7=1. The p-value for the first table equals
(4!4!)(2!4!2!)
8!2!2!2!2!
= 0 ■086,
whereas the p-value for the second table is about half of that for the first table:
(6!6!)(3!5!2!) 
10!3!2!3!2!
= 0 ■008 ■
This is simply the effect of regarding as equivalent two situations characterized by the same 
value of 7. This example shows that the values of 7 are not comparable for experiments with 
different marginal counts.

520
ANALYSIS OF CATEGORICAL DATA
Computations of the p-value become cumbersome especially when the number of row 
and/or column categories increases. When cell counts are sufficiently large, normal approxi­
mation of sampling distribution may be used (e.g., see Agresti, 2002).
PROBLEMS
15.6.1 A study reported in Science magazine investigated the relationship between sex, hand­
edness (right- or left-handed), and relative foot size (left foot bigger than right foot, 
left foot within one-half shoe size of right foot, or right foot bigger). A random sample 
of 150 adults gave the following data:
Relative foot size
Right-handed
Left-handed
Male
Female
Male
Female
L>R
2
55
6
0
L « R
10
18
6
2
L<R
28
14
0
9
Test the association between gender and handedness considering three groups of peo­
ple: these whose left foot is bigger than their right foot, these whose both feet are 
almost the same, and these whose left foot is bigger. Compare the results obtained.
15.6.2 Measure the association of GPA and attitude toward statistics courses based on the 
data from Problem 15.3.5 using Y, Tb, and d coefficients.

CHAPTER 16
BASICS OF BAYESIAN STATISTICS
16.1 INTRODUCTION
In the Basic Model introduced in Chapter 10, we pointed out that the process of making 
statistical decisions might benefit from additional information about the unknown parame­
ter available prior to collecting the data. Such, usually subjective,33 prior beliefs can then be 
updated with the (objective) information provided in the data using Bayes’ theorem (4.4.1). 
Methods of statistical inference that use such prior information are called Bayesian Statistics.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
As in methods of estimation presented in Chapter 11, observations X1, ...,Xn are 
assumed to be a random sample from the distribution f (x; 6), and the objective is to estimate 
the value of 6. This time, however, we assume that 6 is an element of some parameter space 
0, sampled according to probability distribution n(6). For instance, if 0 is the real line, and 
s is a continuous random variable with density n(6), then P{s e A} = fAn(6) d6.* The 
density n (6) is referred to as the prior density of 6.
■ EXAMPLE 16.1
A grocery store receives shipments of some merchandise (e.g., oranges). The quality of 
each shipment can be described by a certain parameter 6.
Examples of such parameters may be the percentage of spoiled fruits, the average 
diameter of a fruit, the average sugar content of the juice, and so on. Typically, it is 
not practical to determine the exact value of 6 for a given shipment, because of cost, 
or because sampling is destructive. In such cases, one takes a sample from a given 
shipment and uses it to estimate 6 for this shipment.
If the store has been buying the shipments from the same company for some time, 
it usually has accumulated some data about the variability of values of6 from different
33Subjective probability was discussed in Section 2.7.
521

522
BASICS OF BAYESIAN STATISTICS
shipments. Such historical data, in addition to the actual sample, could be used in 
assessment of the parameter 6 for a given shipment.
■ EXAMPLE 16.2
In another example consider a physician who has to diagnose a patient. The data 
are various symptoms (or their lack), results of tests, and so on. The values of the 
parameter 6 are different possible diagnoses, such as 61= common cold, 62 = tuber­
culosis, and 63 = AIDS. The physician knows the distributions f(x, 6) of the results 
x = (x1,x2, ...,xn) of n specific tests for every 6 (here x1 may be temperature, x2 
and x3 may be systolic and diastolic blood pressure, x4 may be glucose level, etc.). At 
some time, the physician reaches a diagnosis (i.e., reaches the decision, perhaps tenta­
tive, about 6 and begins treatment). He may also order further tests. The estimation 
problems we have considered thus far have dealt only quantitative and usually contin­
uous parameters. By contrasts, observe here how the discrete and qualitative nature of 
the parameter space affects the problem in the sense of a definition of error: while in 
estimation the error can be quantified as the difference T (x) - 6, in medical diagnosis 
such quantification is not possible (e.g., consider the “error” of treating a patient with 
TB as having a common cold, and vice versa, treating common cold as TB).
It is clear, however, that the experience and intuition of the diagnosing physician 
play a crucial role here. In particular, the physician may have some idea as to the prior 
probabilities n (6) of various diseases.
16.2 PRIOR AND POSTERIOR DISTRIBUTIONS
The information from the sample, x =(x1 , ...,xn) (reflected in the likelihood function), 
and prior information about the distribution of6 (which quantifies what is known about the 
parameter before observing the sample), can be combined into the conditional density of 
6 given x, referred to as the posterior density. We have
P{S e A|X = x} = У n(6|x) d6,
where
n (6| x) =
fn (x;6)n (6)
Je fn (x; u) n(u) du
(16.1)
The integral in the denominator of (16.1) is the reciprocal of the normalizing constant, 
and we often do not need to determine its value. What really matters is the fact that the 
posterior density of the parameter given the data is proportional to the likelihood of the 
data multiplied by the prior density (often referred to as a kernel):
n(6|x) = C fn(x, 6) n(6) = CL(6, x) n(6) к L(6, x) n(6).
The proportionality sign к allows us to ignore factors that do not depend on the unknown 
parameter 6.
■ EXAMPLE 16.3
Suppose that we take observations from independent Bernoulli trials with the same 
probability of success 6, where 6 follows a beta distribution with parameters a and в, 
that is,
n(6)= C6a- 1(1 - 6)e-1, 
0 < 6 < 1,
(16.2)

PRIOR AND POSTERIOR DISTRIBUTIONS
523
where C is the normalizing constant, given in (8.68). Letting s = 
xi, we have
fn(x,в) = П^i(1 _ в)1 x = es(1 _ в)n-s.
i=1
Consequently, the posterior density of в, given x, is
п(в|x) x es(1 - в)n-sea-1 (1 - в)e-1 = ва+s- 1(1 - в)n+e-s-1, 
which we recognize as a BETA(a + s, в + n - s) distribution.
■ EXAMPLE 16.4
Assume now that the observations X 1, X 2, ...,Xn are independent, each with POI( в) 
distribution, while в has a GAM(a, X) distribution so that
п(в) = Сва-1 e-x0, в> 0, 
(16.3)
where C is the normalizing constant given in (8.49). Letting s = 
xi, the posterior
density of в is
п (в| x) =
Сва-1 e-x0 = Кв8+a-1 e-(n+x)0
(16.4)
Here the constant К also incorporates factorials x 1! ••• xn! (in general, we only 
need to keep track of the terms involving в). We recognize (16.4) as a density of a 
GAM(a + s, X + n) distribution.
■ EXAMPLE 16.5
Suppose that X 1, ... ,Xn is a random sample from a N(в, a2) distribution with a2 
known and that в has a prior normal distribution N(p, т2). We will find the posterior 
distribution of в, given the sample.
SOLUTION. The likelihood function can be transformed as follows:
fn(x,в) = a (2п)n/2 eXp { - 202 
(xi - в) }
x exp{- 202 £(xi- xn )2+n(в - xn )2]}
x exP{ -202(в - xn)2} .
The sign x means proportionality. The ignored factors are a-n (2п)-n/2 in the 
first proportionality, and exp{- (n/2a2)(xi - xn) 2} in the second proportionality. The 
posterior density п (в1 x) is therefore proportional to
n1 
exP1 “TT(в - xn) Г x exP 1 ^“2 (в - ^) Г . 
2a2 
n 
2т2
Now we need to separate the terms involving в; all other terms will be absorbed in the 
proportionality constant. Expanding the squares and leaving only terms with в, we 
obtain, after some algebra,
п(в|x) x exp
2^(в - m)2

524
BASICS OF BAYESIAN STATISTICS
where
22 
a2 n пт - 
m a2 + пт2 ^ 1 a2 + пт2 xn 
(16.5)
and
2 
a2 т2
q = a + + пт2 . 
(16.6)
This means that the posterior density of в is again normal with mean m and variance 
q2 given by (16.5) and (16.6), respectively.
■ EXAMPLE 16.6
Suppose finally that the observations X1, ...,Xn are independent normal N(0, в2), 
with в again having a gamma distribution as in Example 16.4. We have
п (в| x) = K
ва- 1 e-xe
K *ga-n- 1e—Ae—
(16.7)
E x2
2 e 2
.
This time the density (16.7) is not a member of any known family of distributions.
The following definition is related to the situation in Examples 16.3 through 16.5 but not 
in Example 16.6:
Definition 16.2.1 A family F of distributions of parameter в is said to provide conjugate 
priors for the distribution f(x, в) of observations if, whenever the prior distribution of в is 
in F, the posterior distribution п (0\ x) also belongs to F for any sample x. 
□
The essence of Examples 16.3 through 16.5 is formulated in the following theorems:
Theorem 16 .2.1 Beta densities are conjugate priors for the binomial distribution.
Theorem 16 .2.2 Gamma densities are conjugate priors for the Poisson distribution.
Theorem 16 .2.3 Normal densities are conjugate priors for normal distribution.
Conjugate priors simplify the process of obtaining posterior distributions. Rather than 
computing integrals, one only needs to modify parameters of the prior distribution given 
the data, as will be illustrated in Examples 16.14-16.16.
In the following example, both distributions will be discrete.
■ EXAMPLE 16.7
Let us assume that random variable X attains four different values: a, b, c, d with the 
following probabilities:
X
a
b
c
d
P (X; в)
в2
в(1 - в)
в(1 - в)
(1-в)2

PRIOR AND POSTERIOR DISTRIBUTIONS
525
and that the prior distribution of в is also discrete:
в 
1/4 
1/2 
3/4
п (в) 
1 / 2 
1 / 3 
1 / /6
Suppose now that value a of variable X was observed. Since
P(a) = P(a; в = 1 /4)п(1 /4) + P(a; в = 1 /2)п(1 /2)
+ P(a; в = 1/3)п(1/3)
_ /1 V 1 
/1 \2 
1 
/ 3\2 
1 _ 10
VV X 2+127 X 3+vJ X 6 = 48,
we have
п(в =1 /4\a)= (1Y X 1 /(10) =A,
4J 4 \48/ 
20,
п(в =1 /2\a)= ( 1У X 1 /( 10) =A,
2/ 
2/ \48/ 
20,
п(в = 3/4\a)= (3У X 1 /( 10) =A,
4 
6 \ 48/ 
20
so that the posterior distribution п(0\a) is
в 
1/4 
1/2 
3/4
п(в a) 
3/20 
8/20 
9/20
Let us now assume that an additional value was sampled and it occurred to be a d. 
Using posterior distribution п(в\а) as a prior we now have
and the posterior distribution п(в\а, d) becomes
P (d )= (1 - 1) X —+ (1 - 1) X —
4) 
2^ V 
2) 
20
( 
3 V 9 
17
+ У - У X 20 = 80
в 
1/4 
1/2 
3/4
п (в|a,d) 
27/68 
32/68 
9/68
This example shows how the information is updated in a natural way. This sequential 
nature of Bayesian theorem is called recursive Bayesian learning and is the basis for all 
Bayesian modeling.
The prior distribution represents the current knowledge or the description of uncertainty 
about the model parameters. There are different types of prior distributions. Informative pri­
ors are based on either historical data or they reflect the degree of belief about the unknown 
parameters. If these priors have a large impact on posterior distributions, we say that they

526
BASICS OF BAYESIAN STATISTICS
Figure 16.1 Posterior densities (dashed line) for different prior densities (solid line) and different 
likelihood (dotted line).
dominate the likelihood. Some such priors can be seen in the top line of Figure 16.1 and in 
Examples 16.3-16.6.
Noninformative priors (also known as reference, vague, or objective) usually represent the 
lack of information about parameters in the model. Their impact on posterior distributions 
is limited as they assign equal probability (density) to all values of the parameter within a 
certain range (also infinite). However, the name “noninformative” is not always the best as 
these priors do not necessarily represent ignorance. Sometimes, for example, they support 
extreme values of the parameter.
■ EXAMPLE 16.8
In Example 16.4, prior and posterior distributions of the probability of success 6 were 
BETA(а, в) and BETA(a + s, в + n - s), respectively. For a = в = 1, the prior dis­
tribution BETA(1, 1) would have a constant density n (6) = 1 for 0 < 6 < 1 and will 
become a noninformative prior.
While BETA(1, 1) is a well defined proper distribution, some noninformative distributions 
are improper priors.
□
Definition 16.2.2 A prior n(6) is said to be improper if fen(6)d6 = ж.

PRIOR AND POSTERIOR DISTRIBUTIONS
527
An improper prior may lead to an improper posterior and no inference can be made in 
such a case. In other situations, improper priors can lead to proper posteriors, as will be 
illustrated in the following examples.
■ EXAMPLE 16.9
Let us assume that X 1, ...,Xn is a random sample from a N(в, 1) distribution and 
that —x < в < x. Moreover, let п (в) = 1, which is an improper prior. The posterior 
density п (в\ x) is then
п(в|x) x п(x|в)п(в)
xexp{ — 2 (xi —в )2}х 1 
x exp | — -(—в2 — 2в xi) | 
x exp { — — (в — x)2} .
The improper prior lead to a proper posterior distribution N(x, 1 /n).
■ EXAMPLE 16.10
Let us now have a random sample X 1, ... ,Xn from a POI(в) distribution and an 
improper prior п(в) = в- 1 for 0 < в < x. Letting s = xi, the posterior density 
п(в |x) is then proportional to
п(x|в)п(в) x
e в вх \ 
xi! )
< n вц х в- 1 
п x 1!
п
1
Х в
x e-n х ви- 1,
which is a kernel of the GAM(^ xi, n) distribution, a proper posterior.
The most often used noninformative (or reference) prior is the so-called Jeffreys prior.
Definition 16.2.3 Jeffreys prior п(в) is proportional to the square root of the Fisher infor­
mation I (в):
п(в) x \I(в) 11 /2. 
□
Jeffreys priors can be either proper or improper as will be shown in the following examples.
■ EXAMPLE 16.11
Let X1 , ... ,Xn be a random sample from a Bernoulli distribution BIN(1, в). Since 
I(в) = [в(1 — в)] -1 (see Example 11.16), Jeffreys prior is
п(в) x (тЧгУ =в- 1 /2(1 —в)- 1 /2, 
в(1 — в)
which is BETA(1/2, 1/2), a proper prior.

528
BASICS OF BAYESIAN STATISTICS
In the next example, Jeffreys prior is improper.
■ EXAMPLE 16.12
Let X 1, ..., Xn be a random sample from a POI(9) distribution. The Fisher informa­
tion is now
I(9) = 9-1
and the Jeffreys prior n (9) = 9-1 /2 is improper since
П n(9) d9 = f 9-1 /2 d9 = ж.
00
An advantage of using a Jeffreys prior is that it is invariant under different parametriza­
tions of 9.Ifh is a one-to-one function of 9 then
i (h (9»= -^^xs
(
d2 log n(x\h) 
d92
d9
dh
= I (9) x
d9
dh
(16.8)
and
I(h(9))1/2 = I(9)1/2
d9
dh
d9
dh = n (h (9)).
= n (9)
If we are unsure which prior distribution should be used, then we can consider different 
possible priors and compare the resulting posterior distributions. If the data provide a lot 
more information than the prior (the prior is dominated by the likelihood), then the poste­
rior distributions will be very similar with different priors, an example may be seen in the 
lower part of Figure 16.1. If there are multiple parameters in the model, assigned prior dis­
tributions (or probabilities) are usually different as they need to be relevant for different 
parameters.34
34More information about noninformative priors can be found in the literature, see, e.g., Kass and Wasserman 
(1989).
PROBLEMS
16.2.1 Six randomly selected adults are asked if they favor additional taxes to help fund 
more affordable health care. Four of them respond “yes.” Assuming that the prior 
distribution is BETA(1, 1), determine the posterior density and obtain the probability 
that in the population the proportion of people favoring a tax increase is between 60% 
and 70%.
16.2.2 Determine posterior distributions to show that the family of gamma distributions 
provides conjugate priors for: (i) The exponential distribution. (ii) The BETA (а, в) 
distribution with в known.

BAYESIAN INFERENCE
529
16.2.3 If random variable X has a GAM(a, X) distribution with density
f (x; a,X ) = Xf- xa-1 e-x 
r( a)
for x>0, then variable Y =1/X has a so-called inverse gamma distribution, 
IGAM(a, X), with density
f (y; a, X) = xL^y-a-1 e-Xy, 
(16.9)
r( a)
for y>0, with E(Y )=X/(a - 1) for a>1 and Var(Y ) = X2/[(a - 1)2 (a - 2)]-1 
for a > 2. The mode of IGAM( a, X) is a+. Show that the inverse gamma distribu­
tion provides a conjugate prior for parameter a2 in N(p, a2) when ^ is known.
16.3 BAYESIAN INFERENCE
Most inferential questions can be answered by appropriate analysis of the posterior dis­
tribution. Such analysis can provide point and interval estimates of parameters, predict 
distributions of future observations, and also compare hypotheses.
Predictive Distribution
Let us now assume that we have the data x, decided on a prior distribution n (6), and would 
like to obtain f(y|x)—a Bayesian predictive distribution of the future observation y. Since the 
random sample X and Y, the future observation from the same population, are conditionally 
independent given the value of 6, we have
f ( 1 ) = fn +i( z,x) 
f fn +i( y, x;6)n (6) d6
f(yl x) 
fn (x) 
f fn (x; 6 ) П ( 6 ) d6
= f f ( y,6 ) fn (x; 6 ) П ( 6 ) d6
= 
f fn (x; 6)n(6) d6
= f f(y;6) x f fn(x6n.6> 
dy
fn (x;6)n(6) d6
= ! f (y; 6)n (61 x) d6.
(16.10)
■ EXAMPLE 16.13
Suppose that X1 , .. .,Xn is a random sample from a POI(6) distribution and that 
a prior distribution of 6 is GAM(a, X). Using this information, we will predict a 
distribution of an additional observation y taken from the same population. Based on 
Example 16.4, the posterior distribution n(61 x) is GAM (^ xi + a, X + n) with the 
density
(X + n)X xi+a 6E Xi + 
1 e-(л+n)e
Г(Е xi + a) 
■

530
BASICS OF BAYESIAN STATISTICS
■гс>
Based on (16.10), the density of the predictive distribution is
y^_ х (А + n)S xi+а вЕ xi+а-1 е-(а+n)в
7о у! Г(ЕXi + а) е
= (X + n)£ xi+а Г~ y++Е xi+а +1 в(а+n +1) de 
у !Г(Е Xi + а )Jо 
•
Since the integrand is the kernel of the GAM(у + E xi + а, X + n +1) distribution, 
the integral equals
(16.11)
г( у + E xi + а)
( x + n +1) y+s xi+а
and the density of the predictive distribution is
f( , ) = (X + n)E xi+а г г(у + E xi + а)
f(у1 ) у! Г(Е xi + а) 
(X + n + 1)y+E xi+а
/ у + E xi + а — 1 A / X + n A^ xi+а / 
1 A y
у 
X + n+1 
X + n +1
(16.12)
Thus, the predictive distribution is NBIN( xi + а, 1/(X + n + 1)).
Since the choice of the prior distribution is subjective, it is to be expected that two dif­
ferent people might want to use different prior distributions. Therefore, it is worthwhile to 
conduct a sensitivity analysis—compute posterior distributions for different possible priors 
and see how different they are, i.e., how strongly the different prior opinions affect the pos­
terior (see Figure 16.1). Sensitivity in the choice of prior is not necessarily a disadvantage. 
It indicates that the data do not provide sufficient information and that perhaps additional 
observations should be collected.
Point Estimation
The choice of the estimator depends on the choice of the loss function. In general, as in 
Section 11.3, the penalty for accepting the value of the parameter as 9* (while in fact it is e) 
is expressed by the loss function L(в*, в). In the present case, we know the distribution 
of в, given the observed sample x. Thus, we should choose the value 9* that minimizes the 
expected loss
e{l(e*, s)|x} у l(e*,o) n(e|x) de. 
(16.13)
The left-hand side of (16.13) does not depend on в. It is a function of 9* and x. For each x, 
we can therefore try to minimize the expectation, that is, find a value в* (x) such that
E{L(9* (x), S) |x}< E{L(9**, S) |x}
for every 9** in 0. Such a value в* (x) is the best choice of estimate given the sample x. 
When x varies according to the distribution f (x, в), we obtain a statistic в* (X). We will now 
introduce the following definition:
Definition 16.3.1 The statistic 9* (X) that minimizes the left-hand side of (16.13) is called the 
Bayes estimator of в for the loss function L (9*, в). 
□

BAYESIAN INFERENCE
531
Minimizing (16.13) in the general case may not be easy. However, the minimizing value в* 
is well known when L(в*, в) = (в* — в)2. It is the mean of the posterior distribution of в 
given x. As in the case of other estimators, we will tacitly take the squared error as the loss 
function (unless we explicitly specify some other loss function). This is the customary choice. 
It is motivated primarily by the fact that the quadratic loss function allows further devel­
opment of the theory. Therefore, if the loss function is not explicitly specified as other than 
quadratic, then the Bayes estimator of parameter в is understood as the mean of the posterior 
distribution:
T(X) = E{S|X} =1 вп(в|X) №. 
(16.14)
The following theorem is analogous to the Theorem 11.6.2:
Theorem 16.3.1 The Bayes estimator of в is a function of the minimal sufficient set of statistics 
for в.
v (x) u (T1 ,...,Tk ,в) п (в)
Proof: If statistics T1 , . ..,Tk are jointly sufficient for в, then the posterior density of в 
given x is, for prior density п(в), is
п ( в1 x ) = fn (x ,в ) п ( в ) 
= 
J fn(x, n)п (n) dn 
v v (x) u (T1, ..., Tk ,n)п (n) dn
= u (T1 ,...,Tk ,в) п (в) 
H(T1, ...,Tk) 
.
Since the factor v(x) cancels, His a function of statistics T1, ...,Tk. Consequently, the Bayes 
estimator, equal to the mean of posterior distribution, depends on x only through statistics 
T1 ,...,Tk. 
□
■ EXAMPLE 16.14
If the observations X = (X1, ...,Xn) form a random sample from a Bernoulli distri­
bution (so that S = П=1 Xi is BIN(n, в)), and в varies according to BETA(а, в), then 
the Bayes estimator of в is 
— S) with the mean (а + S) / (а + в + n).
а+в а 
n 
S
а + в + n 
а + в а + в + n 
n'
(16.15)
(16.16)
t(x 1,...,xn)= а+S. 
n а+в +n
This follows from the fact, established in Example 16.3, that the posterior distribution 
of в is BETA(а + S, в + n 
Since
а + S 
а + в + n
where а/(а + в) is the expectation of the prior distribution and S/n is the sample 
mean, the posterior expectation can be interpreted as a weighted average of the prior 
expectation and the sample average.
■ EXAMPLE 16.15
In a similar way, we can use Theorem 11.4.1, which asserts that gamma densities are 
conjugate priors for the Poisson distribution. If X 1, ... ,Xn is a sample from POI(в) 
distribution, and в has prior distribution GAM(а, X), then the Bayes estimator of в is
T (X 1 ,...,Xn ) = а+S. 
(16.17)
n X+n

532
BASICS OF BAYESIAN STATISTICS
This follows from the fact that the mean of a gamma distribution is the ratio of the
shape parameter to the scale parameter. As in Example 16.14, the Bayes estimator can
again be expressed as a weighted average of the prior expectation a/X and the sample
mean S/n:
a+S X a n S
X+n 
X+n X 
X+n n
■ EXAMPLE 16.16
From (16.5) in Example 16.5 it follows that the Bayes estimator in the case of the 
normal distribution N(в, a2), with known a2 and normal prior N(p, т2), is
22 
a2 
пт2 
—
T = a2 + пт2 » + a2+пт2 Xn. 
(16.18)
Thus T, as in_Examples 16.14 and 16.15, is a weighted average of prior mean ^ and 
sample mean Xn. With the increase of the sample size n, the estimator puts more and 
more weight to the sample size Xn, and in the limit we have T = Xn. In other words, 
ultimately the empirical evidence always prevails over prior convictions. Finally, the 
same limiting conclusion is obtained if т2 ^ ж, that is, when the prior information 
is more vague (the prior variance т2 is interpretable as a measure of uncertainty of 
the prior information). Going toward the opposite extreme, where a2 ^ ж or т2 ^ 0 
(observations are subject to large errors, or prior knowledge has high certainty), the 
Bayes estimator of в attaches more and more weight to the prior information that the 
mean of в is ^.
The last three examples illustrate the convenience of using conjugate prior distributions. 
This convenience lies basically in the fact that we have a simple formula for the Bayes estima­
tor, and therefore we can easily adjust our estimates when new observations become available. 
To illustrate this point, we consider the following example:
■ EXAMPLE 16.17
Continuing Example 16.15, assume that we first take m observations, with the total 
number of successes S = X 1 + • • • + Xm, and then n observations, with the total num­
ber of successes S' = X1 + • • • + Xn. The prior density of в, before taking the first set 
of observations, is BETA(a, в).
The situation at the end of second series of observations can be regarded in two 
ways:
1. We have a total of S + S' successes in m + n trials, so the Bayes estimator is
a + (S + S') 
a + в +(m + n)
(16.19)
2. We have a total of S' successes in the last n trials, where the new prior distribution 
becomes a posterior distribution after we take the first m observations. The poste­
rior density is BETA(a1, в1), where a1 = a + S and в1 = в + m - S. The Bayes 
estimator is now
a 1 + S' 
a1 + в1 + n ,
the same as (16.19).

BAYESIAN INFERENCE
533
Essentially what we observed here is an instance of a general theorem on updating 
evidence (Theorem 4.4.2), which says that ifwe have two independent (sets of) observations 
x and x', we can use them either “at once,” to determine the posterior distribution of 0 
given (x, x'), or we can do it in steps. That is, we find the posterior density of 0, given one 
data set (e.g., x), and we use it as a new prior to find the posterior density of 0 given x'. The 
results will still be the same. Moreover, the order of choice between x and x' is irrelevant, 
and does not need to coincide with the order in which the data x and x' were collected.
All the examples above concern estimators for the squared error loss function. If the 
loss function is L(0*,0) = \0* - 01, then the Bayes estimator is the median of the poste­
rior distribution (see Theorem 7.6.3). For the normal case (Example 16.16), the mean and 
median coincide; hence, (16.18) is also the Bayes estimator for the absolute error loss. In 
Examples 16.14 and 16.15, the posterior distributions are beta or gamma, and their medians 
are not expressible by simple formulas in term of the parameters.
Loss functions other than the squared or absolute error are also used. Asymmetric loss 
functions (introduced in Chapter 11) are often of importance in data mining procedures.
It is clear that the class of all distributions on the parameter space 0 is always a set of con­
jugate priors for any distributions. Such a statement, however, is totally pointless. In fact, a 
class of conjugate priors is useful only ifit leads to a simple formula for the posterior density. 
This allows explicit formulas for the means and thus for Bayesian estimators against mean 
squared loss. From this perspective, the fact that, a given class of distributions is a class of 
conjugate priors is just a mathematical curiosity without much significance. Indeed, refer­
ring again to Example 16.17, we consider there a situation where observations S = Xi are 
binomial with parameter 0, while 0 has a beta distribution. The first assumption is defen­
sible: we often can make S have a binomial distribution by using an appropriate sampling 
scheme. But the law that governs the variability of 0 from case to case is beyond our control, 
and the class of situations described above, where the parameter 0 is a value of a random 
variable S with distribution n, is rather restricted. Most often, the situation that a statisti­
cian faces is “one of a kind,” characterized by an unknown value of 0. As such, it does not 
make sense to think of a prior distribution n of 0 as telling us “how often” we had analo­
gous statistical problems in which the value of the parameter satisfied the inequality of the 
form a < 0 < b.
There is a view that, even in such “one of a kind” situations, it makes sense to 
consider and use the prior distribution of the parameter. Actually, the issue of using 
prior distributions—even if they do not represent frequencies of occurrence of sit­
uations characterized by some values of 0—divides statisticians into Bayesians and 
non-Bayesians.
The philosophical points of this division are beyond the scope of this book. One could, 
however, consider the following two competing principles.
1. Statistical conclusions should depend on data only. When two statisticians analyze the 
same data using the same method, they should reach the same conclusion.
2. Statistical conclusions may depend on the experience, intuition, and insight of the statis­
tician who analyzes a given set of data.
Very roughly, statisticians who adhere strictly to principle 1 are non-Bayesians, and those 
who favor 2 are Bayesians. The latter use the prior distribution n as a means to express 
their knowledge, intuition, and so forth. In this respect, having a class of conjugate priors 
is usually of great help, primarily to express one’s own prior experience or convictions, or 
to elicit information about the analyzed problem from the practitioners whom they advise. 
However, the first example below shows something more fundamental, namely that the 
concept of prior distribution, reflecting one’s personal judgments about a “one-of-a-kind” 
case, is sometimes unavoidable. Consider the following situation, which without this concept 
appears paradoxical:

534
BASICS OF BAYESIAN STATISTICS
■ EXAMPLE 16.18
Imagine yourself playing the following game: There are two envelopes, each containing 
a check. The amount on one check is twice as big as the amount on the other. You 
choose an envelope and inspect the check. At this moment you are offered an option 
to choose the other envelope. What should you do?
SOLUTION. The standard reasoning is as follows: Let a be the amount on the check 
that was in the first envelope you selected. The other envelope then contains a check 
for either 2a or a/2, each with the same probability. Thus, if you change your decision, 
the expected outcome is
2(2a) + 2 (a) = 5a > a, 
(16.20)
2 
22 
4
which means that you should always change the envelope.
This may seem paradoxical, since money appears to be created out of nowhere, just 
by changing the decision. The explanation lies in the fact that calculation (16.20) of 
the expected value uses probabilities 0.5 that the other envelope contains checks for 2a 
or a/2. In fact, one should use here the conditional probabilities, given the observed 
value a, and these calculations involve prior probabilities.
Indeed, suppose that n (x) is the prior probability that the envelopes contain checks 
for the amounts x and 2x. Assuming that one has no clairvoyant abilities, and therefore 
always has the chance 0.5 of selecting an envelope with the lesser amount on a check, 
the unconditional probability of observing the amount a is 0.5n(a/2) + 0.5n(a). Given 
the observed amount a, the probability that the check in the other envelope is for the 
amount a/2 equals
0.5n (a/2) 
n (a/2)
0.5n (a/2) + 0.5n (a) 
n (a/2) + n (a)
The analogous probability for the amount 2a is
0.5 n (a) 
n (a)
0.5n (a/2) + 0.5n (a) 
n (a/2) + n (a)
But the condition
n (a/2) 
n (a)
n (a/2) + n (a) 
n (a/2) + n (a)
implies n(a/2) = n(a), which cannot be satisfied for all a (regardless of whether 
n represents a density or a discrete probability distribution).
This argument refers to some prior distribution n on the possible amount on the 
lesser check. Whether this distribution has any frequential interpretation (referring to 
analogous games played before), or not (if such a game is played only once) is irrelevant 
here. The only way to escape the paradox is to realize that everyone has some idea as 
to the probable range of values that may appear on the checks in the game. If the check 
in hand shows a very “small” value, then the other is probably for a higher value. If the 
check in hand shows a very “high” value, the other is probably smaller. The concepts 
“very small,” “very large,” and “probably” are subjective here and refer to the player’s 
idea about the distribution n.
This example provides one more (and rather powerful) argument for the need of the 
Bayesian approach to statistical problems.

BAYESIAN INFERENCE
535
■ EXAMPLE 16.19
A piece of rock (e.g., taken from the moon) is sent to a laboratory to determine its 
radioactivity level. Assume that the measurement is simply a Geiger count Nt, recorded 
for certain time t. The role of the number of observations n is now played by obser­
vation time t. To avoid confusion, let us assume simply that the experiment is run in 
such a way that Geiger counts X1 ,X2 , ... are recorded, where Xi is the total count of 
radioactive particles in the ith hour of observation. Then, Nt = X 1 + • • • + Xt if t is 
an integer number of hours.
We know that Nt has a Poisson distribution with mean 9t, where в is the radiation 
intensity expressed in average number of emissions per hour. Suppose that the initial 
estimate of в is needed urgently, so that observations can be carried out only for a 
limited time T. In other words, we have at our disposal a single observation of Nt. The 
likelihood function here is
(ST)NT e-от,
therefore
log L (в) = C + NT log в - ST,
and the MLE is easily seen to be
n NT 
в = T
(note that this result concerns the MLE in the case of observations running continu­
ously in time; we no longer have a sample of size n). For example, assume that a total of 
50 counts was recorded in T = 100 hours of observations so that the MLE of в is 0.5.
Suppose now that there are two physicists in the laboratory, and each has his or her 
own ideas about what the radioactivity level в of the specimen tested might be. Dr. 
Brown favors a certain theory of how the moon was formed, and how and when its 
rocks became initially radioactive. She thinks that moon rocks should have their level 
of radioactivity в about 1, but she is willing to incorporate a fair amount of uncertainty 
in her judgment, allowing the standard deviation of в to be as much as 50% of the mean.
On the contrary, Dr. Smith favors a theory which predicts that the moon should 
have uniformly low radioactivity, say в =0.4 on average, with standard deviation not 
exceeding 5% of the mean.
Let us see how these prior convictions will affect the estimates of в for the specimen 
in question. We assume that the prior densities belong to the gamma family. If the 
parameters of a gamma distribution are a (shape) and A (scale), then the mean is a/X, 
and the variance is a/X 2; see (8.50) and (8.51). Consequently, the ratio of the standard 
deviation to the mean (the so-called coefficient of variation) is
cv-Ot =
Thus, for Dr. Brown, we have
CV= -==0 • 5, 
a = 1,
which gives a = X =4. 
For Dr. Smith, we have
CV=-^=0 • 05, 
a =0 • 4,
aX

536
BASICS OF BAYESIAN STATISTICS
so a = 400, X = 1,000.
The Bayes estimator is (see Example 16.15) (a + NT)/(X + T), so that
4+50
6B = 4 4- 100 = 0 • 519 and
400 + 50
°s = 1000^00 =0 •409
35We are using here a convenient terminology based on an analogy with humans. In reality, birds cannot be expected 
to solve optimization problems, which require computers for humans (see Green, 1980). What we mean here is that 
in the process of evolution, any adaptation toward a better search strategy is likely to become established, and it is 
possible that birds use a strategy that is close to optimal.
for Dr. Brown and Dr. Smith, respectively.
We can see the effects of two factors. One is that the MLE (in this case equal 0.5) is 
being “pulled” toward the mean of the prior distribution. The amount of pull depends 
on the variance of the prior distribution, reflecting the strength of conviction in the 
prior distribution: Dr. Smith, whose prior has much smaller variance, ends up with an 
estimate much closer to his prior mean than does Dr. Brown.
The next example concerns the behavior of certain species of birds in their search for food. 
The complete theory, including optimization aspects, has been developed by Green (1980). 
We present here only a fragment concerning assessment (estimation) by a bird.
■ EXAMPLE 16.20 Are Birds Bayesians?
Assume that the species in question can find food only in “patches,” each consisting of 
a certain number of places where prey can be found. Specifically, we will think of birds 
that prey on worms that live in pine cones. We assume that a pine cone has n “holes,” 
each of them containing a prey with probability 6, independently of other holes. Thus, 
given 6, the number of prey in a cone has a BIN(n, 6) distribution. The bird has a fixed 
search pattern, so it does not search the same hole twice, and we assume that the prey 
cannot hide or escape to another hole during the search. Finally, we assume that 6, 
the frequency of occupied holes, varies between cones in such a way that 6 has beta 
distribution with parameters a and в.
Let us consider now what could be the best strategy for a bird. First, it is reasonable 
to assume that the bird is trying to optimize35 the rate of food intake per unit of time. 
Specifically, a strategy will tell the bird when to leave a cone and start searching the next 
one. The bird will optimize the rate of food intake, taking into account the average catch 
at a cone, average time spent on the cone, and the average time of flying to another cone.
Intuitively, if a and в are large, the variability of 6 is small: the variance of the beta 
distribution is aft/(a + в)2(a + в + 1). In such cases, all cones are about the same: the 
variability between the cones is due mainly to variability in the binomial distribution 
with parameters n and 6 = a/(a + в). In such cases, there is very little incentive to fly 
to the next cone before the current one is searched to the end.
However, if a and в are small, in particular, if a< 1 and в< 1, the variability of 6 
is large. Actually, in the latter case, the distribution of6 has density unbounded at 6 = 0 
and at 6 = 1. This means that most cones will be of two categories only: very rich in 
prey, when 6 is close to 1, and very poor in prey, when 6 is close to 0. The optimal 
strategy is then to assess—as quickly as possible—whether 6 is close to 1 or to 0, and 
to behave accordingly, leaving the cone in the second case.
Now, if after searching k holes the bird found x worms, its assessment of 6 is 
(a + x)/(a + в + k) (i.e., equals the Bayes estimate of6 given x successes in k trials). 
Without going into detail, the optimal strategy specifies, for each k, the threshold 
for x, below which the bird ought to leave the cone.

BAYESIAN INFERENCE
537
To determine whether or not the birds follow the optimal strategy is an empirical 
problem. The experiments involve the use of artificial cones and observation of birds’ 
behavior depending on the findings in the holes searched previously. The preliminary 
results indicate that birds follow some kind of strategy of breaking or continuing the 
search of a cone depending on the outcome of the search so far. Whether or not this is 
an optimal strategy is unclear. But the truly fascinating question here is that if the birds 
do use a Bayesian strategy, are they are capable of changing the prior distribution? In 
other words, are birds born with knowledge of a search strategy that is optimal against 
some fixed a and в that reflect infestation rate of cones over the last hundred years 
(for example), or can an individual bird change its search strategy in years of higher 
infestation of its habitat?
Let us investigate briefly the problem of consistency of Bayes estimators. First, let us 
observe that in the cases of estimators analyzed (of 6 in the binomial case with a beta prior, 
of 6 in the Poisson case with a gamma prior, and of p, in the normal distribution with a 
normal prior), as the sample size increases, the effect of prior distribution decreases to zero. 
Indeed, if Sn denotes the binomial random variable with probability of success 6, the Bayes 
estimator of 6 for a beta prior satisfies
6 = a + Sn = a/n + Sn/n jj 6 
a + в + n 
(a + в)/n +1 ’
since Sn /n converges to 6 in probability (and also almost surely).
Similarly, if X1 , ...,Xn is a random sample from the Poisson distribution with mean 6, 
and 6 has a gamma distribution with parameters a and A, then the Bayes estimator of 6 
satisfies
6 = a + £n=1 Xj = a/n + Xn j 6,
A + n 
A/n +1
by the law of large numbers, which asserts that the sample average Xn converges to 6 in 
probability (and also almost surely).
An analogous conclusion for the normal case has already been obtained in 
Example 16.16. We see therefore that Bayes estimators are consistent; in fact they 
become increasingly closer to MLE’s of the same parameters, regardless of the prior 
distribution. This property is true for Bayes estimators under some very general conditions, 
which we will not state here.
One of the problems that a statistician faces quite often is the determination of the sam­
ple size: “How big should n be in order that ...” Various conditions may appear in place 
of the dots. In the case of estimation, these conditions typically state the precision of the 
estimate, in the sense of the probability of errors of a given size. In case of Bayes estima­
tors, the situation is relatively simple. One of the criteria for determining the sample size 
may be expressed through the posterior distribution. In the most typical case, one may wish 
to have a sample size that ensures that the posterior variance is below a certain minimum 
(of course, such criteria make sense only if the estimator used is unbiased or has a small 
bias). Thus far we have dealt with point estimation. An estimator was used to produce 
a single number, hopefully close to an unknown parameter. The natural question arises: 
What can be said about the distance between the estimator value and the true value of the 
parameter?
Here the approaches are different, depending on whether or not one can regard the value 
of 6 as a realization of some random variable.

538
BASICS OF BAYESIAN STATISTICS
Bayesian Intervals
In the Bayesian scheme, the true value 6 is regarded as the observed value of a random 
variable S with prior distribution (e.g., density) n. Given the vector of observations, x, the 
posterior density of S is n(6\x), and we can assess the probability that S lies between two 
values a and b as
P{a < S < b \x} = У n(6|x) d6. 
(16.21)
■ EXAMPLE 16.21
Suppose that we observe x =2 successes in n =3 Bernoulli trials with unknown 
probability of success 6, where 6 has the prior distribution BETA(2, 2). Then the 
posterior distribution of the parameter is again beta, with parameters a + x = 4 and 
n + в - x = 3. So the posterior density is
Г(7) 
3 
2 
3 
4 
5
Г(4)Г(3)6 (1 - 6) = 606 — 1206 + 606 , 
0 < 6 < 1.
The probability that the true value of 6 lies below 0.2 equals
0.2
(6063 - 12064 + 6065)d6 = 0.017.
0
The probability that the true value of 6 lies above 0.8 equals
[ (6063 - 12064 + 6065)d6 = 0.099, 
0.8
and consequently, the true value of 6 lies between 0.2 and 0.8 with probability
1 - 0.017 - 0.099 = 0.884. The expected value of the posterior distribution is
4/7 = 0.57, which is the Bayes estimate of 6.
Figure 16.2 The 90% central credible interval (dotted line) and the 90% highest density interval (solid 
line) for the asymmetric posterior density.

BAYESIAN INFERENCE
539
Bayesian intervals are referred to as credible intervals. Similarly to the confidence intervals 
under the frequentist framework (discussed in Chapter 11), one could define many inter­
vals (L, U) such that P(L < 9 < U) = 1 — a. Among them are (1 — a)100% central credible 
intervals (L, U) in which P(9 < L) = P(9 > U) = a/2. Another important subset consists 
of the highest density intervals.
In general, the central credible interval and the highest posterior density (HPD) interval 
could differ substantially when the posterior density is skewed, as can be seen in Figure 16.2. 
If the posterior density is unimodal, then the narrowest such interval will be the HPD inter­
val. Regions that contain values with the HPD can be intervals that are symmetric around the 
mode, but they could also be asymmetric if the posterior distribution is skewed. If the pos­
terior distribution is bimodal, the regions do not even need to be intervals (see Figure 16.2).
Because credible intervals are obtained using posterior probability, it can be said that they 
contain the parameter of interest with certain (desired) probability. So the interval here is 
fixed and the parameter is random. Confidence intervals, on the other hand, use probabilities 
to express how often, in many repetitions, the formula that produces an interval will cover 
the parameter of interest. In confidence intervals, the interval is random while the parameter 
is fixed. But unfortunately for the frequentist’s approach, once data are collected and the 
interval is obtained, the probability that it covers the true value of the parameter is either 
0or1.
■ EXAMPLE 16.22
In Example 16.9, it was shown that in a sample X1, ...,Xn from N(9, 1), the improper 
prior n(9) = 1 led to a proper posterior distribution N(x, 1 /n). The distribution is a 
symmetric and unimodal, so the (1 — a)100% HPD interval for 9 will be
(x — za/2 Mn; x + za/2 / >/n) •
(16.22)
This interval is the same as the (1 — a)100% confidence interval for 9 (discussed in 
Chapter11) but it has a different interpretation.
Bayesian Hypotheses Testing
We are testing hypothesis H0 : 9 e 0O against H 1 : 9 e 01, with 0O U 01 = 0 and
0O П 01 = 0. In the Bayesian framework, prior distributions n0(9) and n 1(9) are specified 
for each of the hypotheses, and posterior distributions n0(91 x) and n 1 (9\ x) can be obtained 
after collecting observations x.
Definition 16.3.2 The Bayes factor (BF) is defined as the ratio of posterior to prior odds of 
hypothesis HO and posterior to prior odds of H1 :
no(9x)/no(9) 
n 1( 9| x)/n 1( 9)
Since
(91 ) = 
ni(x|9)ni(9)
( i| ) 
no(x 19)no(9) + n 1(x 19)n 1(9)
(16.23)
□
(16.24)
for i =0, 1, the Bayes factor (16.23) in the case of two simple hypotheses reduces to
BF= n (x Ho) 
П(x\H 1) •
(16.25)

540
BASICS OF BAYESIAN STATISTICS
(16.26)
In the general case of composite hypotheses
= Jo0no(xl£)no(£)_df 
/©1 пi(x\6)п 1(6) d6'
Interpretation of the Bayes factor is very intuitive; values larger than 1 provide support for
the hypothesis Ho and values less than 1 for hypothesis H1 .
The following example illustrates use of the Bayes factor for testing simple hypotheses.
■ EXAMPLE 16.23
Let X 1, ..., X10 be observations of Bernoulli trials with the probability of success 6 
and let the hypotheses to be tested be H0 : 6 = 60 = 0.5 and H 1 : 6 = 6 1 = 0.75. If we 
assign equal prior odds to Ho and H1 then, assuming that there were 6 successes in 
these 10 trials, the Bayes factor is
П 6xi (1 - 60)1-xi _ 0.5^ xi (1 - 0.5)10-^ xi
= П 6xi (1 - 6 1)1 -xi = 0.75X xi (1 - 0.75)10-E xi
= 00756 X 0.254 =1.4047. 
(16-27)
0. 5 x 0 .£1 5
The Bayes factor favors H0 slightly more than H1 .
The next example considers the case when one hypothesis is simple and the other is 
composite.
■ EXAMPLE 16.24
Let X1, ...,X10 be observations of Bernoulli trials with the probability of success 6 
and hypotheses to be tested be H0 : 6 = 60 =0.5 and H1 : 6 = 0.5. We will assign the 
uniform prior to values of 6 in H 1, so that n (6) = 1 for 0 < 6 < 1. Assuming that we 
also observed 6 successes in 10 trials, the Bayes factor is now
BF =
0.510
Jo1 66 (1 - 6)4 d6.
(16.28)
In the denominator of (16.28) we have
f 1 ,6(1 - 6)4 d6 = 
7 
f -ТДЪ66(1 - 6)4 d6 = 6Ц!,
Jo 
( 
) 
Г(12) J Г(7)Г(5) ( 
) 
11! ’
and finally
BF = 0.51011!
6!4!
= 2.256.
The Bayes factor favors H0 over H1
■ EXAMPLE 16.25
Continuing Example 16.24, let us now take a prior distribution BETA(7, 3) which 
favors values of6 around 0.75. Assuming the same observed data as before (6 successes 
in 10 Bernoulli trials), we now have
BF =
0.510
J01 25266(1 - 6)266(1 - 6)4 d6
(16.29)

BAYESIAN INFERENCE
541
where
252 е6(1 - е)2 = г(10) че6(1 - е)2 
( 
) 
Г(7)Г(3) 
( 
)
is the density of BETA (7, 3) distribution. In the denominator of (16.29), we now have
f 1 252е6(1 - е)2е6(1 - е)4 de = 252Г(13)Г(7) f 1 Г(20) ,-2(1 - е)6 d>,
Jo 
( 
) 
( 
) 
г(20) Л Г(13)Г(7) 
1 
) 
,
and the Bayes factor is
0.51019!
252 х 12!6! = 1.366
and it still favors H0 over H1, but less so, and not enough to make any strong conclu­
sion.
■ EXAMPLE 16.26
Continuing Examples 16.24 and 16.25, let us now assume that there are 60 successes in 
100 trials. The relative frequency of success, 0.6, is the same as in the previous examples, 
but the evidence in the data is stronger since the sample size is now larger. With the 
same hypotheses to be tested and the same prior as in Example 16.25, the Bayes factor 
now is
BF =
0.5100
f01 252 е 6(1 - е )2 е 60(1 - е )40 ж
0.5100109!
252 х 66!42! = 0.591.
(16.30)
Now the Bayes factor is less than 1; it favors hypothesis H1 over H0
The readers are encouraged to use the information in the examples above and test the 
same hypotheses using the classical likelihood ratio tests that were discussed in Chapter 12. 
The final conclusions in testing under the Bayesian and non-Bayesian framework will be 
largely consistent, although not always.
A few comments are in order here. First, the Bayes factor can be interpreted as the weight 
of evidence provided by the data. To help with its interpretation, several authors proposed 
different classification schemes for the value of the Bayes factor (e.g., Kass and Raftery, 1995; 
Jeffreys, 1961). Second, as Bayes factors update the belief in one hypothesis over the other, 
they treat both hypotheses equally. Each hypothesis can be accepted or rejected, which is dif­
ferent than in the non-Bayesian framework. In the classical approach to testing hypotheses, 
the evidence is used only to reject (or not) the so-called null hypothesis; one is not allowed to 
accept it. Next, the Bayesian factor can be seen as an analog to the likelihood ratio in the fre- 
quentist (non-Bayesian) framework as it reduces to likelihood in the case when both hypothe­
ses are simple. And finally, one should be careful when selecting prior distributions for testing 
hypotheses since the Bayes factor is undefined when prior distributions are improper.
PROBLEMS
16.3.1 Let X 1, ... ,Xn be a random sample from a N(е, 1) distribution. Using an improper 
constant prior for parameter е (see Example 16.9), show that the predictive distri­
bution of the next observation y is N(x, 1 + 1 /n).
16.3.2 A shipment of 100 batteries contains е defectives. (i) If the prior distribution п (е) 
is BIN(100, 0.03), find the posterior distribution п(е1х) knowing that one item was 
randomly selected from the shipment, and was found to not be defective. (ii) Find 
the predictive probability that the next selected item will also be nondefective.

542
BASICS OF BAYESIAN STATISTICS
16.3.3 Let X 1, ... ,Xn be a random sample from the EXP(в) distribution, and let the 
prior distribution of в be EXP(в). (i) Find the Bayes estimator of в and of ^ = 1 /в 
using the squared error loss. (ii) Obtain the 90% credible interval for в and for ^ if 
n = 6, x = 4, and в = 2.
16.3.4 A diastolic blood pressure in a certain population of patients has a N(p, 81) distri­
bution. If the blood pressure of 10 randomly selected patients is 76, 71, 82, 63, 64, 
75, 81, 78, 66, 62 and ^ has a prior distribution N(70, 1), find the predictive distri­
bution of the systolic blood pressure of the next patient randomly selected from the 
same population.
16.3.5 Five people were playing a board gave in which to start the game one had to roll 
a die and obtain either a one or a six dots. It took them respectively 5, 3, 1, 4, and 
2 rounds, to start the game. If we assume that the die that they used was fair and 
that the prior probability в of getting either one or six dots followed BETA(2, 4) 
distribution, find the Bayes estimate of в assuming the squared error loss.
16.3.6 Assume that X 1, ...,X 20 is a random sample from the N( в, 1). (i) Obtain the Bayes 
factor for testing H0 : в = 0 against H1 : в =0if the prior distribution of в under 
H 1 is N(0.5, 0.25). Use xi = 7. (ii) Test the same hypothesis in a non-Bayesian 
framework and compare both results.
16.3.7 An insurance company estimates that about 40% of travelers (with the standard 
deviation of 20%) buy insurance for their airplane tickets. If in a random sample of 
100 travelers who purchased an airplane tickets on a given day exactly 35 of them 
also purchased insurance, find the Bayes estimate of the true proportion of travelers 
buying insurance assuming the squared error loss (we assume that all travelers in 
the sample purchased their tickets independently and traveled alone).
16.3.8 Let X, .. .,Xn be a random sample from a GEO(в) distribution and let the prior 
distribution of в be BETA(2, 2). (i) Find the posterior distribution п (0\ x) and obtain 
the Bayes estimator of в assuming squared error loss. (ii) Compare the obtained 
Bayes estimator with the MLE for the same data. (iii) Obtain the 95% credible inter­
val for в.
16.3.9 Let X, ..., X 16 be a random sample from a N(в, 4) distribution and let the prior 
distribution of в be N(0, 0.25). (i) Find the Bayes estimator of в assuming squared 
error loss. (ii) Obtain a 95% credible interval for в .
16.3.10 Refer to Example 16.7. Find the Bayes estimator of в after a was observed under 
(i) Squared error loss. (ii) Absolute error loss. (iii) Repeat (i) and (ii) assuming that 
both, a and d were observed.
16.3.11 Assume that X1, ...,Xn is a random sample from a BIN(1, в) distribution and that 
the prior distribution of в is U(0,1). Find the Bayes estimator of в if the loss function 
is
L(в,в) = (в - в)2/[в(1 - в)]3/2.
16.3.12 Let X 1, .. .,Xn be a random sample from a POI( в) distribution. (i) Using Jeffreys 
prior, find the posterior distribution for в. (ii) Obtain the 95% credible interval for 
в. (iii) Obtain the HDP 95% interval for в if n =3 and the actual observations 
are 2, 5, and 0. [Hint: The (1 - a)100% highest density interval is also the shortest 
(1 - a)100% credible interval. Use Theorem 8.4.3 and statistical software.]

FINAL COMMENTS
543
16.4 FINAL COMMENTS
After years of heated fundamental debates between advocates of Bayesian and non-Bayesian 
approaches to data analysis, many researchers today have expertise in both and find it help­
ful to think about analyses from both Bayesian and non-Bayesian perspectives, depending 
on the problem. We introduced just the main concepts of prior and posterior distributions 
and provided examples to help understand their properties. We also introduced Bayesian 
tests of hypotheses and estimation procedures so that the readers could see the analogues to 
similar methods in non-Bayesian approach. We did not try, however, to introduce Bayesian 
methodology since there is not enough room in one chapter.
Bayesian inference does not require large sample theory. Asymptotic distributions are 
not needed since small sample Bayesian inference is carried out the same way as for the large 
samples. Availability of fast computing and novel computational techniques makes Bayesian 
analysis useful in most areas of quantitative research. Bayesian methodology allows building 
multivariate models (also with hierarchical structure) that require powerful computing, for 
instance for integration, for flexible posterior sampling through iterative simulations within 
Markov chains. Calculations are carried out using special algorithms, such as Metropolis, 
Metropolis-Hastings, and Gibbs sampler. Methods of empirical Bayes are used for estimating 
prior distributions from the data. Bayesian data analysis can be performed using readily 
available software packages such as WinBUGS or R.
Interested readers can find many excellent books and journal articles about Bayesian 
methodology such as Casella and George (1992), Robert and Casella (1999), Hoff (2009), 
and Gelman et al. (2013).

APPENDIX A
SUPPORTING R CODE
This chapter contains the R code that will help students in using this text for the course. 
To use basic graphics, generate data and perform statistical analysis based on resampling 
methods. The information in this chapter is organized according to when it might be needed 
first.
Chapter 3.
factorial(n) # n!
choose(n, k) #combinations
factorial(n)/factorial(n-k) #permutations
Chapter 8.
Basic distributions and related graphs. Built in distribution functions: density or probability, 
cdf, quantiles can be found in Tables A.1-A.3.
■ EXAMPLE A.1
The code below shows how to graph three density functions in one figure, using 
solid, dotted, and dashed lines, respectively (see Figure A.1). The distributions used 
(BETA(2, 5), BETA(3, 3), BETA(1, 4)) can easily be substituted by other distributions 
from Table A.1. Ranges on both axes (xlim and ylim) will need to be adjusted 
accordingly (Figure A.1).
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
545

546
SUPPORTING R CODE
Table A.1 Built in distributions
Distribution
R function
Parameters
Formula
Binomial
binom
n, p
(x) px (1 - p)n-x
Poisson
pois
lambda
p (x) = е-л^г
Uniform
unif
a, b
f (x) = 1 / (b — a) ,a < x < b
Normal
norm
№
f (x) = 
. 
e-(x-^ )2 / 2 a 2
2 2 2 
2Пna
Exponential
exp
в
f (x) = в -1 e-x/e
Gamma
gamma
а, в
f (x) = [ в-а/Г( а)] xa—1 e-x/e
Chi-square
chisq
V
f (x) = _____ 1_____ xv/2-1 e-x/2
f (x) 
Г(v/2)2v/2 x
Student’s t
t
V
rv+e (1 + x 2/V)- (v +.> / 2
Weibull
weibull
а, в
f (x) = a.exa-1 е-вх
Beta
beta
а, в
f (x) — Г(a+e) xa—1 (1 _ x)P- 1 
f (x) = Г(а)Г(e) x 
(1 x)
Table A.2 Densities/pdf’s and cdf’s of built in distributions
R function
Density/pdf at x
Cdf at x
binom
dbinom(x, n, theta)
pbinom(x, n, theta)
pois
dpois(x, lambda)
ppois(x, lambda)
unif
dunif(x, a, b)
punif(x, a, b)
norm
dnorm(x, mu, sigma)
pnorm(x, mu, sigma)
exp
dexp(x, beta)
pexp(x, beta)
gamma
dgamma(x, alpha, beta)
pgamma(x, alpha, beta)
chisq
hisq(x, nu)
pchisq(x, nu)
t
dt(x, nu)
pt(x,nu)
weibull
dweibull(x, alpha,beta)
pweibull(x, alpha, beta)
beta
dbeta(x, alpha, beta)
pbeta(x, alpha,beta)
Table A.3 Quantiles and random number generation of built in distributions
R function
Quantile of order p
Random sample, m
binom
qbinom(p, n,theta)
rbinom(m, n,theta)
pois
qpois(p, lambda)
rpois(m, lambda)
unif
qunif(p, a, b)
runif(m, a, b)
norm
qnorm(p, mu, sigma)
rnorm(m, mu, sigma)
exp
qexp(p, beta
rexp(m, beta
gamma
qgamma(p, alpha, beta)
rgamma(m, alpha, beta)
chisq
qchisq(p, nu )
rchisq(m, nu)
t
qt(p, nu)
rt(m, nu)
weibull
qweibull(p, alpha, beta)
rweibull(m, alpha, beta)
beta
qbeta(p, alpha, beta)
rbeta(m, alpha, beta)

SUPPORTING R CODE
547
Figure A.1 The densities of BETA(2, 5), BETA(3, 3), and BETA(1, 4) distributions.
plot.new()
plot.window(xlim=c(0, 1), ylim=c(0, 3))
x=seq(0, 1, length=100)
y1=dbeta(x, 2, 5)
y2=dbeta(x, 3, 3)
y3=dbeta(x, 1, 4)
lines(x, y1)
lines(x, y2, lty="dotted")
lines(x, y3, lty="dashed")
axis(1)
axis(2)
box()
legend(0.7, 2.9, legend=c("BETA(2, 5)", "BETA(3, 3)", 
"BETA(1, 4)"), lty=c(1, 3,2))
Chapter 9.
Descriptive methods and generating random numbers. In all examples, data values are 
stored in vector d (or d1 and d2). The basic statistics can be obtained using functions 
in Tables A.4 and A.5.
Table A.4 Basic statistics for data values stored in vector d
Statistic
R code
Sample mean 
Sample median 
Standard deviation 
Variance 
Trimmed mean
mean(d)
median(d)
sd(d)
var(d)
mean(d, trim = p) # the upper and lower 100p% of the data 
removed
Quantile
Interquartile range
quantile(d, p) # quantile of order p 
quantile(d, 0.75)-quantile(d, 0.25)

548
SUPPORTING R CODE
Table A.5 Basic graphical methods
Graph
R code
Boxplot
Multiple boxplots
Dot diagram
Q-Q plot
Histogram
boxplot(d)
boxplot(d1, d2)#two boxplots in one plot (for d1 and d2) 
stripchart(a, method="stack", pch=1) 
qqnorm(d) #add qqline(d) for a reference straight line 
hist(d, main= "Histogram for d")
R code for obtaining simple graphs displaying univariate data are given in Table A.3. 
For a thicker line, include lwd=2, or lwd=3. The higher the value the thicker is the 
line. For example, compare boxplot(d) with boxplot(d, lwd=3).
■ EXAMPLE A.2 Obtaining a Histogram with Fitted Normal Density
The code below produces a histogram with bins being relative frequencies rather than 
frequencies. Values of xmin and xmax should correspond to the minimum and maxi­
mum value in d (here 100 randomly generated observations). The density in Figure A.2 
is the density of the true distribution BETA(2, 3). The density in Figure A.3 is the 
normal density with the same mean and standard deviation as the sample mean and 
standard deviation in the dataset d.
Figure A.2 Histogram of the data generated from the BETA(2, 3) distribution and the BETA(2, 3) 
density.
alpha<-2
beta<-3
d<-rbeta(100, alpha, beta)
plot.window(xlim=c(0, 1), ylim=c(0, 3))
hist(d, freq=FALSE)
x<-seq(0, 1, length=100)

SUPPORTING R CODE
549
y<-dbeta(x, alpha, beta) 
lines(x, y)
or
y<-dnorm(x, mean(d), sd(d))
Figure A.3 Histogram of the data generated from the BETA(2, 3) distribution and the normal density 
with parameters same as the sample mean and variance.
Generating random data. Generating data from specific distribution requires adding r to the 
distribution’s name. For example, d<-rbeta(n, alpha,beta) will randomly generate 
n observation from the BETA(alpha, beta) distribution and store them in d. Similar func­
tions for generating observations from other distributions can be found in the last column 
of Table A.3.
Accept-reject algorithm (introduced in Section 9.4)
■ EXAMPLE A.3
We will generate 1,000 observations from the BETA(1.5, 2.5) distribution. If g(x) is a 
U(0, 1) density, then f (x)/[cg(x)] < 1.7 and the R code is:
A<- 16/(pi*1.7)
n<-1000
m<- 0 
# number of obs. accepted as BETA(1.5, 2.5)
i<- 0 
# number of iterations
y<-numeric(n) 
# stores observations BETA(1.5, 2.5)
while (m <n) {
u<-runif(1)
i<-i+1
x-runif(1)
if (A*xA 0.5*(1-x)A1.5 > u ) {
m<-m+1 
y[m]<- x 
}
}

550
SUPPORTING R CODE
Chapter 11.
Bootstrap interval. We will be using the following notation: B—number of bootstrap sam­
ples, d—an original dataset (here of size 15), the parameter of interest in the population 
mean. The R-code will yield two intervals: 90% t-interval (bootl, bootu) and 90% percentile 
interval(percl, percu).
B<- 1000 # number of bootstrap repetitions, here B=1000.
y<- 1:1000
for (i in 1:B){
resam<-sample(c, replace=T) 
y[i]<-mean(resam)
}
my<-mean(y)
se<-sqrt( mean((y-my) ' 2))
bootl<-my-qt(0.9, df=15)*se
bootu<-my+qt(0.9, df=15)*se
percl<- sort(y)[900]
percu<-sort(y)[101]
Chapter 12.
Permutation/randomization test. Permutation test is used for comparison ofa certain param­
eter in two populations. Observations in two samples are combined and then split into two 
subsets of the same sizes as the original samples (m and n). All mm+n such different pairs 
of subsets should be considered. If mm+n is too large, subsets are selected at random a 
substantial number of times (here 1,000) and the test becomes a randomization test.
■ EXAMPLE A.4 The randomization test
We are testing hypothesis that the median in population 1 (x—sample of size 10) is 
larger than the median in population 2 (y—sample of size 15), len = 1,000 number of 
replications.
len<-1000
w<-c(x, y) # pooled sample
K<-1:25
reps<- numeric(len) # stores values of the statistic 
for (i in 1:len) {
k<-sample(K, size=10, replace=False)
x1<-w[k]
y1<-w[-k]
reps[i]<-median(x1)-median(y1)
}
p<-mean(c(tzero, reps) >= tzero)

APPENDIX B
STATISTICAL TABLES
Table B.1 Quantiles for the shortest CI for <r
Table B.2 Kolmogorov distribution
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
551

552
STATISTICAL TABLES
Table B.1 Quantiles of the chi-square distribution for determining the shortest CI for a. 
Relative gain in length can be found in the “%” column
V
a = 0.10
a= 0.05
a1
Xai ,v
Xa2 ,v
%
a1
Xai ,v
Xa2 ,v
%
1
0.09998
0.016
18.189
24.92
0.04999
0.004
19.511
24.99
2
0.09988
0.211
18.056
49.02
0.04998
0.103
21.640
49.48
3
0.09948
0.582
17.647
61.21
0.04988
0.351
20.726
61.82
4
0.09882
1.056
18.100
68.50
0.04969
0.708
21.047
69.10
5
0.09800
1.594
18.907
73.41
0.04943
1.139
21.806
73.94
6
0.09708
2.175
19.871
76.95
0.04911
1.623
22.736
77.41
7
0.09612
2.788
20.927
79.65
0.04876
2.147
23.791
80.04
8
0.09516
3.426
22.041
81.77
0.04839
2.703
24.910
82.11
9
0.09420
4.084
23.182
83.48
0.04802
3.284
26.083
83.78
10
0.09328
4.758
24.352
84.90
0.04764
3.886
27.270
85.16
11
0.09238
5.447
25.530
86.09
0.04726
4.505
28.472
86.32
12
0.09152
6.147
26.719
87.11
0.04689
5.141
29.689
87.31
13
0.09070
6.858
27.915
87.98
0.04653
5.790
30.915
88.16
14
0.08990
7.579
29.109
88.75
0.04619
6.451
32.153
88.91
15
0.08916
8.308
30.313
89.42
0.04585
7.123
33.386
89.56
16
0.08844
9.045
31.514
90.02
0.04552
7.804
34.619
90.14
17
0.08774
9.788
32.711
90.55
0.04521
8.495
35.859
90.67
18
0.08710
10.539
33.916
91.03
0.04490
9.193
37.091
91.13
19
0.08648
11.295
35.117
91.46
0.04461
9.899
38.328
91.56
20
0.08588
12.056
36.315
91.85
0.04433
10.612
39.563
91.94
21
0.08530
12.823
37.510
92.21
0.04405
11.331
40.791
92.29
22
0.08476
13.595
38.708
92.54
0.04379
12.056
42.024
92.61
23
0.08424
14.371
39.903
92.84
0.04354
12.787
43.254
92.91
24
0.08374
15.151
41.095
93.12
0.04329
13.523
44.478
93.18
25
0.08326
15.935
42.286
93.37
0.04306
14.264
45.706
93.43
26
0.08278
16.723
43.471
93.61
0.04283
15.009
46.928
93.67
27
0.08234
17.514
44.659
93.83
0.04261
15.759
48.149
93.89
28
0.08192
18.310
45.846
94.04
0.04240
16.513
49.369
94.09
29
0.08150
19.108
47.027
94.23
0.04219
17.271
50.583
94.28
30
0.08110
19.909
48.208
94.41
0.04199
18.032
51.797
94.46
40
0.07780
28.063
59.927
95.75
0.04031
25.823
63.834
95.78
50
0.07536
36.418
71.499
96.57
0.03903
33.855
75.694
96.59
60
0.07346
44.918
82.949
97.13
0.03803
42.064
87.418
97.14
80
0.07066
62.232
105.571
97.83
0.03653
58.859
110.535
97.84
100
0.06866
79.847
127.915
98.25
0.03544
76.015
133.321
98.26

STATISTICAL TABLES
553
Table B.2 Tail probabilities 1 - Q(z) of the Kolmogorov distribution
z
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.3
1.0000
1.0000
0.9999
0.9999
0.9998
0.9997
0.9995
0.9992
0.9987
0.9981
0.4
0.9972
0.9960
0.9945
0.9926
0.9903
0.9874
0.9840
0.9800
0.9753
0.9700
0.5
0.9639
0.9572
0.9497
0.9415
0.9325
0.9228
0.9124
0.9013
0.8896
0.8772
0.6
0.8643
0.8508
0.8367
0.8222
0.8073
0.7920
0.7764
0.7604
0.7442
0.7278
0.7
0.7112
0.6945
0.6777
0.6609
0.6440
0.6272
0.6104
0.5936
0.5770
0.5605
0.8
0.5441
0.5280
0.5120
0.4962
0.4806
0.4653
0.4503
0.4355
0.4209
0.4067
0.9
0.3927
0.3791
0.3657
0.3527
0.3399
0.3275
0.3154
0.3036
0.2921
0.2809
1.0
0.2700
0.2594
0.2492
0.2392
0.2296
0.2202
0.2111
0.2024
0.1939
0.1857
1.1
0.1777
0.1700
0.1626
0.1555
0.1486
0.1420
0.1356
0.1294
0.1235
0.1177
1.2
0.1122
0.1070
0.1019
0.0970
0.0924
0.0879
0.0834
0.0794
0.0755
0.0717
1.3
0.0681
0.0646
0.0613
0.0582
0.0551
0.0522
0.0495
0.0469
0.0443
0.0420
1.4
0.0397
0.0375
0.0354
0.0335
0.0316
0.0298
0.0282
0.0266
0.0250
0.0236
1.5
0.0222
0.0209
0.0197
0.0185
0.0174
0.0164
0.0154
0.0145
0.0136
0.0127
1.6
0.0120
0.0112
0.0105
0.0098
0.0092
0.0086
0.0081
0.0076
0.0071
0.0066
1.7
0.0062
0.0058
0.0054
0.0050
0.0047
0.0044
0.0041
0.0038
0.0035
0.0033
1.8
0.0031
0.0029
0.0027
0.0025
0.0023
0.0021
0.0020
0.0018
0.0017
0.0016
1.9
0.0015
0.0014
0.0013
0.0012
0.0011
0.0010
0.0009
0.0009
0.0008
0.0007
2.0
0.0007
0.0006
0.0006
0.0005
0.0005
0.0004
0.0004
0.0004
0.0003
0.0003
2.1
0.0003
0.0003
0.0002
0.0002
0.0002
0.0002
0.0002
0.0002
0.0001
0.0001
2.2
0.0001
0.0001
0.0001
0.0001
0.0001
0.0001
0.0001
0.0001
0.0001
0.0001
2.3
0.0001
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000

Bibliography
Agresti, A. 2002. Categorical Data Analysis, 2nd ed. Wiley, New York.
Al-Ghamdi, A. S. 1991. The application of mathematical statistics to traffic accidents data. 
MS dissertation. Ohio State University, Columbus, OH.
Allais, M. 1953. Le comportement de l’homme rationnel devant le risque: critique des pos- 
tulats de l’ecole Americaine. Econometrica 21: 503-546.
Antle, C. E., and L. J. Bain. 1969. A property of maximum likelihood estimators of location 
and scale parameters. SIAM Review 11: 251.
Arnold, B. C., N. Balakrishnan, and H. N. Nagaraja. 1992. A First Course in Order Statistics. 
Wiley, New York.
Bartoszynski, R. 1974. On certain combinatorial identities. Colloquium Mathematicum 30 
(2): 289-293.
Blackwell, D., and M. A. Girshick. 1954. Theory of Games and Statistical Decisions. Wiley, 
New York.
Casella, G., and E. I. George. 1992. Explaining the Gibbs sampler. The American Statistician 
46: 167-174.
Casella, G., and R. L. Berger. 2002. Statistical Inference. Duxbury Press, Pacific Grove, CA.
Chernoff, H., and E. L. Lehmann. 1954. The use of the maximum likelihood estimates in x2 
tests for goodness of fit. Annals of Mathematical Statistics 25: 579-586.
Chow, Y. S., and H. Teicher. 1997. Probability Theory, 3rd ed. Springer-Verlag, New York.
Chung, K. L. 2001. A Course in Probability Theory Revised, 3rd ed. Academic Press, New 
York.
Cramer, H. 1946. Mathematical Methods of Statistics. Princeton University Press, Princeton, 
NJ.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
555

556
BIBLIOGRAPHY
Davison, A. C., and D. V. Hinkley. 1997. Bootstrap Methods and Their Applications. Cam­
bridge University Press, Cambridge, MA.
Davidson, D., P. Suppes, and S. Siegel. 1957. Decision Making: An Experimental Approach. 
Stanford University Press, Palo Alto, CA.
De Groot, M. 1986. Probability and Mathematical Statistics. Addison-Wesley. Reading, 
MA.
Dekking, F. M., C. Kraaikamp, H. P. Lopuhaa, and L. E. Meester. 2005. A Modern Intro­
duction to Probability and Statistics. Springer.
Devore, J. L. 1991. Probability and Statistics for Engineering and the Sciences, 3rd ed. Brooks 
and Cole, Pacific Grove, CA.
Efron, B. 1979. Bootstrap methods: another look at jackknife. Annals of Statistics 7: 1-26.
Efron, B., and R. J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman and Hall, 
New York.
Feller, W. 1968. An Introduction to Probability Theory and Its Applications, vol. 1. Wiley, 
New York.
Feller, W. 1971. An Introduction to Probability Theory and Its Applications, vol. 2. Wiley, 
New York.
Fox, M., and R. James. 1987. The Complete Chess Addict. Faber and Faber, London.
Freedman, D., R. Pisani, R. Purves, and A. Adhikari. 1992. Statistics. 2nd ed. Norton, New 
York.
Freeman, G. H., and J. H. Halton. 1951. Note on an exact treatment of contingency, 
goodness-of-fit and other problems of significance. Biometrika 38: 141-149.
Gafrikova, V., and M. Niewiadomska-Bugaj. 1992. Ordering and comparing estimators by 
means of Gini separation index. Probability and Mathematical Statistics 13: 215-228.
Gelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vahtari, and D. B. Rubin. 2013. 
Bayesian Data Analysis. 3rd ed. Chapman and Hall/CRC.
Genest, C. 1987. Frank’s family of bivariate distributions. Biometrika 74: 545-555.
Gibbons, J. D., and J. W. Pratt. 1975. P-values: interpretation and methodology. American 
Statistician 29 (1): 20-25.
Good, P. I. 2005. Introduction to Statistics Through Resampling Methods and R/S-Plus. 
Wiley, New York.
Goodman, L. A.. 1969. On partitioning chi-square and detecting partial association in three 
way contingency tables. Journal of the Royal Statistical Society: Series B 31: 486-498.
Goodman, L. A 1971. The partitioning of chi-square, the analysis of marginal contingency 
tables, and the estimation of expected frequencies in multidimentional contingency tables. 
JASA 66: 339-344.
Green, R. F. 1974. A note on outlier-prone families of distributions. Annals of Statistics 2: 
1293-1295.
Green R. F. 1976. Outlier-prone and outlier-resistant families of distributions. Journal of the 
American Statistical Association 71: 502-505.
Green, R. F. 1980. Bayesian birds: a simple example of Oaten’s stochastic model of optimal 
foraging. Theoretical Population Biology 18 (2): 244-256.
Hall, P. 1992. The Bootstrap and Edgeworth Expansion. Springer-Verlag, New York.
Hoff, P. D., 2009. A First Course in Bayesian Statistical Methods. Springer-Verlag, New York.
Hollander, M., and D. A. Wolfe. 1999. Nonparametric Statistical Methods. Wiley, New York.
Hotelling, H., and L. M. Solomons. 1932. The limits of a measure of skewness. Annals of 
Mathematical Statistics 3: 141-142.

BIBLIOGRAPHY
557
Jeffreys, H. 1961. The Theory of Probability, 3rd ed. Oxford University Press, Oxford.
Jordan, W. 1869. Ueber die Bestimmung der Genauigkeit mehrfach wiederholter Beobach- 
tungen einer Unbekannten. Astronomische Nachrichten 74: 209-226.
Karlin, S., and H. M. Taylor. 1975. A First Course in Stochastic Processes. Academic Press, 
New York.
Kass, R. E., and A. E. Raftery. 1995. Bayes factors. Journal of the American Statistical Asso­
ciation 90: 773-795.
Kass, R. E., and L. Wasserman. 1989. The selection of prior distributions by formal rules. 
JASA 91: 1343-1370.
Kennedy, W. J., and J. E. Gentle. 1980. Statistical Computing. Marcel Dekker, New York.
Kolmogorov, A. N. 1933. Grundbegriffe der Wahrscheinlichkeitsrechnung. Springer, Berlin 
(English transl. by N. Morrison, Foundations of the Theory of Probability. Chelsea, New 
York, 1956).
Kotz, S., T. Kozubowski, and K. Podgorski. 2001. The Laplace Distribution and Generaliza­
tions. Birkhauser, Boston, MA.
Krantz, D. H., R. D. Luce, P. Suppes, and A. Tversky. 1971. Foundations of Measurement, 
vol. 1. Academic Press, New York.
Lancaster, H. O. 1949. The derivation of and partition of x2 in certain discrete distributions. 
Biometrika 36: 117-129.
Lancaster, H. O. 1969. The Chi-Squared Distribution. Wiley, New York.
Larsen, R. J., and M. L. Marx. 1986. An Introduction to Mathematical Statistics and Its 
Applications. Prentice Hall, Englewood Cliffs, NJ.
Lehmann, E. L., and J. P. Romano. 2005. Testing Statistical Hypotheses. Springer-Verlag, 
New York.
Luce, R. D., and D. H. Krantz, 1971. Conditional expected utility. Econometrica 39: 
253-271.
Marsaglia, G., and T. A. Bray. 1964. A convenient method for generating normal variables. 
SIAM Review 6: 260-264.
Montgomery, D. C., E. A. Peck, and G. G. Vining. 2006. Introduction to Linear Regression 
Analysis, 4th ed. Wiley, New York.
Mood, A. M., F. A. Graybill, and D. C. Boes. 1974. Introduction to the Theory of Statistics. 
3rd ed. McGraw Hill, New York.
Myers, R. H. 1986. Classical and Modern Regression with Applications. Duxbury Press, 
Boston, MA.
Myers, R. H., and J. S. Milton. 1991. A First Course in the Theory of Linear Statistical Mod­
els. PWS-Kent, Boston, MA.
Neyman, J. 1950. A First Course in Probability and Statistics. Holt, New York.
Neyman, J., and E. L. Scott. 1971. Outlier proneness of phenomena and of related distribu­
tions. In: J. S. Rustagi (ed.), Optimizing Methods in Statistics. Academic Press, New York, 
pp. 413-430.
O’Cinneide, C. A. 1990. The mean is within one standard deviation of any median. American 
Statistician 44: 292-293.
Oehlert, G. W. 1992. A note on the Delta method. American Statistician 46: 27-29.
Ramsey, F. P. 1926. Truth and probability. [Reprinted in Studies in Subjective Probability, 
H. E. Kyberg and H. E. Smokler (eds.), Wiley, New York, 1964, 61-92].
Robert, C., and G. Casella. 1999. Monte Carlo Statistical Methods. Springer-Verlag, New 
York.

558
BIBLIOGRAPHY
Roberts, F. S. 1979. Measurement Theory with Applications to Decisionmaking, Utility and 
the Social Sciences. Addison-Wesley, Reading, MA.
Ross, S. 2006. Simulation. Academic Press, New York.
Savage, L. J. 1954. The Foundations of Statistics. Wiley, New York.
Sen, P. K., and J. M. Singer. 1993. Large Sample Methods in Statistics. Chapman and Hall, 
Inc.
Serfling, R. J. 1980. Approximation Theorems of Mathematical Statistics. Wiley, New York.
Srivastava, R. C. 1981. On some characterization of the geometric distribution. In: C. Taillie, 
G. P. Patil, and B. A. Baldessari (eds.), Statistical Distribution in Scientific Work. Reidel 
Publishers, Dordrecht, 349-355.
Stapleton, J. 1995. Linear Statistical Models. Wiley, New York.
Stevens, S. S. 1946. On the theory of scales of measurement. Science 103: 677-680.
Stigler, S. M. 1986. The History of Statistics. Harvard University Press, Cambridge, MA.
Stigler, S. M. 1996. Statistics and the question of standards. J. Res. Natl. Inst. Stand. Technol. 
101: 779-789.
von Neumann, J., and O. Morgenstern. 1944. Theory of Games and Economic Behavior. 
Princetown University Press, Princeton, NJ.
Wasserstein, R. L., and N. A. Lazar. 2016. The ASA?s statement on p-values: context, pro­
cess and purpose. The American Statistician 70: 129-133.

Answers to Odd-Numbered Problems
CHAPTER 1
1.2.1 (i) H1, H2, ..., H6, TTT, TTH, THT, THH; (ii) TT, HTT, THT, THHT, HTHT, 
HHTT, HHHH, THHH, HTHH, HHTH, HHHT.
1.2.3 134, 234, 135, 235.
1.2.5 (i) 600, 510, 501, 420, 411, 402, 330, 321, 312, 303, 240, 231, 222, 213, 204, 150, 141, 
132, 123, 114, 105, 060, 051, 042, 033, 024, 015, 006; (ii) 600, 510, 420, 411, 330, 
321, 222; (iii) Six allocations for two white balls: 200, 110, 101, 020, 011, 002. Fifteen 
allocations for four red balls: 400, 310, 301, 220, 211, 202, 130, 121, 112, 103, 040, 
031, 022, 013, 004. Each allocation of two white and four red balls is a combination 
of two allocations (6 x 15 = 90).
1.2.7 (i) THT; (ii) A2,A4,A6; (iii) 6.
1.2.9 Yes. If the answer is “yes” and the interviewer manages to find out that the respondent 
was not born in April, the privacy is not maintained.
1.3.1 (i) False; (ii) False; (iii) False; (iv) True; (v) True; (vi) True.
1.3.3 (i) X = A; (ii) X = 0; (iii) X = Ac; (iv) X = B - A.
1.3.5 
D1 = E11, D2 =E2,D3 =E8,D4 =E6,D5 =E4 =E5,D6 =E3,D7=E1,D8 =
E9, D9 = E10, D10 = E7.
1.3.7 (i) x = 0, y = 4; (ii) Either x = 0 or y > 3; (iii) x = 0, no inference about y possible; 
(iv) x < 4, no inference about y is possible.
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski.
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
559

560
ANSWERS TO ODD-NUMBERED PROBLEMS
1.4.1 lim An = 0.
1.4.3 (i) 22n; (ii) 23x2n-2; (iii) 2n+1; (iv) 2; (v) Answers same as for (i)-(iv).
CHAPTER 2
2.3.1 True: (i), (ii), (v); False: (iii), (iv), (vi), (vii), (viii).
2.4.1 5/18.
2.4.3 5/6.
2.4.5 (i) 0.6; (ii) 0.4; (iii) 0.5.
2.4.7 (505, 000)-1.
2.4.9 0.95.
2.5.1 0.25.
2.5.3 25.
CHAPTER 3
3.2.1 (i) 10; (ii) 12.
3.2.3 (i) 20; (ii) 13; (iii) 14.
3.2.5 (i) 2/n; (ii) 1/n; (iii) 0.5; (iv) 2(n - 3)/[n(n - 1)].
3.2.7 (i) 28,800; (ii) 86,400.
3.2.9 (i) 153; (ii) A hat; (iii)138.
3.2.11 0.256.
3.2.13 320.
3 3 1 
(i) 250 / 100 (ii) k > 30
3.3.1 (i) 2 / 50 ; (ii) k _ 30.
3.3.3 4!49!
3.3.5 (i) 4; (ii) 36; (iii) 5,108; (iv) 624; (v) 3,744; (vi) 54,912.
3.3.7 p = 0.0444. If Queen is replaced by Jack then p = 0.0204.
3.3.9 (i) 0.8964; (ii) 0.04255; (iii) 0.0611.
3.3.11 A(n, k)/kn.
3.3.13 (i) 252; (ii) 0; (iii) 5.
3.4.5 1.11 x 10 -14
CHAPTER 4
4.1.1 (ii) (a) P(Z = 2), (b) P(X + Y = 0\Z > 0), (c) P[A П B\(A U B) П (Z > 0)].

ANSWERS TO ODD-NUMBERED PROBLEMS
561
4.2.1 (i) False; (ii) False; (iii) True; (iv) True; (v) False.
4.2.3 1/(1 + a).
4.2.5 1/3.
4.2.7 1/4.
4.2.9 (i) 0.492; (ii) 0.123; (iii) 1; (iv) 1/4; (v) 0.5, 0.105, 1, 0.210; (vi) 0.25 for n 
odd, less than 0.25 for n even; (vii) P(sum odd) ^ 0.5, P(product odd) ^ 
0.125, P(product odd|sum odd) ^ 0.25.
4.2.11 3/4n.
4.2.13 (i) 0.145; (ii) 0.5; (iii) 0.005.
4.3.1 1/11.
4.3.3 (i) 0.2113; (ii) 0.2510; (iii) 0.2526; (iv) 0.2091.
4.3.5 (i) £i=1по • • • ni-1(1 - ni); (ii) 1 - (1 - p,)/(1 - X^).
4.4.1 (i) 0.5; (ii) 0.9972.
4.4.3 (i) 23/45; (ii) 13/45; (iii) 14/23.
4.4.5 15/29.
4.4.7 15/22.
4.4.9 86/91.
4.5.1 (i) False; (ii) True; (iii) False; (iv) True.
4.5.3 (i) 15/216; (ii) 20/216; (iii) 37/216; (iv) 37/216.
4.5.5 A and B are not independent—all other pairs are.
4.5.7 0 < P(A) < 1.
4.5.9 (i) True; (ii) True.
4.5.11 6/11.
4.5.13 6/11.
4.5.15 (6!)2/216 = 0.006.
4.5.17 (i) No; (ii) No.
4.6.1 (ii) -1/(N -1).
4.7.1 P (Xn+1 = j|Xn = i)=pj for i =0, ...,m.Ifi>mthen P (Xn+1 = j|Xn = i)= 
pj-i+m forj =0, 1, ...
4.7.3 (i) pjk = p ifj = k - 1, r ifj = k,andq ifj = k +1. (ii) The formulas remain valid 
ifwe replace p by p/(1 - r) and q by q/(1 - r).
4.7.5 Rows of the matrix are: (0, 1/2, 1/2), (1/4, 0, 3/4), (1/8, 7/8, 0).
4.7.7 Pi,о = ri/(ri + ri+i + ••• ), Pi,i+i = 1 - ri/(ri + ri+i + ••• )•

562
ANSWERS TO ODD-NUMBERED PROBLEMS
4.7.9 (i) p(u2p) = [(100 - C)/200](A/100) + [(100 - C)/200][(100 - B)/200] + (C/100) 
[(100 - C)/200]; (ii) p(p2u) = [(100 - A)/200](A/100) + [(100 - A)/200] 
[(100 - B)/200] + (C/100)[(100 - A)/200].
CHAPTER 5
5.2.1 (i) False; (ii) True; (iii) True; (iv) False; (v) True; (vi) True; (vii) False; (viii) False; 
(ix) True.
5.2.3 (i) 0.7; (ii) 0.0608; (iii) 0.7786.
5.2.5 0 for t < 0, n(t/a)2 for 0 < t < a/2, д/(2t/a)2 — 1 + 2(t/a)2 — [п/2 — 2 arctan 
д/(2t/a)2 — 1] for a/2 < t < a^2/2, and 1 for t > a^2/2..
5.3.1 Even (56/91).
5.3.3 (i) 0.7753; (ii) 0.3162.
5.3.5 (i) (1 — e-X/2)/(1 — e-X); (iii) (e-X/2 — e-X)/(1 — e-X) .
5.3.7 (i) 
P(X4 = —4) =P(X4 =4=1/16, P(X4 = —2) = P(X4 = —2) = 4/16,
P(X4 =0)=6/16; (ii) 5/16; (iii) P(X4 > 0|X4 > 4) = 5/11 for n =4, and 
P (X5 > 0|X5 > 0) = 1 for n =5.
5.3.9 (i) a = 5,b = 22; (ii) 0.3195; (iii) 0.2065; (iv) 0.0793.
5.3.11 (i) 5/6; (ii) 0.115; (iii) 0.5.
5.4.1 (i) P(Y = y)=1/6 for y =0,4,9,16 and P(Y =1)=1/3; (ii) P(Z = 0.5) = 
P(Z = 1.5) = 1/3, P(Z = 2.5) = P(Z = 3.5) = 1/6.
5.4.3 (i) 2tfX(t2); (ii) etfX(et); (iii) (1/t2)fX(1/t); (iv) (1/t)fX(logt).
5.4.5 g(u) = 2uXe-Xu2 for u > 0 and 0 for u < 0 (i) FY(y) = 1 — e-Xy2,fY (y) = 
2yXe-Xy for y > 0 and 0 for y < 0; (ii) д/( — 1 /X) log0.75.
5.4.7 fY (y) = 1 / ^ 1+4y for 0 < y < 2 and 0 otherwise.
5.4.9 (i) U[0, 1]; (ii) U[—1, 1]; (iii) fY(y)=2/3 for 0 <y<1, and 1/3 for 1 <y<2. 
fZ(z) = 1/3 for —1 <z<1, and 1/6 for 1 <z<3.
5.4.11 (i) g (y) = 2/^ 1 — 4y for 0 < y < 0.25 and 0 otherwise; (ii) h(w) = 2 for 0.5 < w < 1, 
and 0 otherwise.
5.4.13 g(u) = m- 3/2k^2u,e-2bu/m,u> 0.
5.5.1 h(t) = 1/(1 — t), 0 <t<1.
5.5.3 (i) q = (a/2)ea; (ii) For 0 < t < 1, S(t) = 0.5(1 — t) + 0.5 and h(t) = 1 /(2 — t). For 
0 < t < 1, S(t) = 0.5e-a(t- 1) and h(t) = a.
5.5.5 0.1876.
5.5.7 EXP(3), 3.

ANSWERS TO ODD-NUMBERED PROBLEMS
563
CHAPTER 6
6.1.1 (ii) 22/36, 0, 1/6; (iii) 2/3, 2/3, 10/26.
6.1.3 (i) P(0,0) = 16/36,P (0, 1) = P(1, 0) = 8/36,P(2, 0) = P(0,2) = 1/36,P (1, 1) = 
2/36; (ii) -0.1048.
6.1.5 (i) k =2; (ii) 5/16.
6.1.7 (i) 6; (ii) 3/20; (iii) 0 for u < 0, v < 0, u2v3 for 0 < u < 1, 0 < v < 1 ,v3 for u > 1, 0 < 
v < 1, u2 for v > 1, 0 < u < 1, and 1 for u > 1, v > 1.
6.1.9 (i) 0.6534; (ii) 0.5.
6.2.1 (i) 1/14; (ii) 0; (iii) 5/7; (iv) 4/7; (v) 11/14.
6.2.3 (i) 
P(3G,0R)=0.1,P(2G,1R)=0.6,P(1G,2R)=0.3; 
(ii) P(G=1)=
0.3,P(G=2)=0.6,P(G=3)=0.1, 
P(R=0)=0.1,P(R=1)=0.6,P(R=
2) = 0.3; (iii) no; (iv) P(X =0,Z=3)=0.1,P(X =1,Z=1)=0.6,P(X = 
2,Z = -1) = 0.3.
6.2.5 (i) 1; (ii)POI(A); (iii) Yes.
6.2.7 1/18, 1/9, 2/9, 3/9.
6.2.9 (i) fX (x) = 1.5(1 - x2), FX (x) = 0.5x(3 - x2) for 0 <x<1; (ii) 9/16.
6.2.11 (i) P (X' = a,Y' = b )= P (X = a) P (Y = b); (ii) 
f™ h 1( x )exp {- j'X [ h 1 (u) +
h2(u)] 
du} dx.
6.2.13 (i) e-5; (ii) 0.4678.
6.2.15 (i) fX (x) = 4xe-2x for x>0,fY (y) = 2e-2y for x>0; (ii) FX,Y (x, y)= 
1 - 2ye-2x - e-2y for 0 <y<x,0forx < 0ory < 0
6.2.17 (i) G' (u) = [b/(a + b)]e-(a+b)u,G1(u) = [a/(a + b)]e-(a+b)u.
6.2.19 (4) for X and(7)forY.
6.3.3 (i) f(x|y) = 2e-2(x-y) forx>y,f(y|x)=1/x for y<x; (ii) 0.4675; (iii) 1 - e-1/3 = 
0.283.
6.3.5 (i) a> -1; (ii) A = (a + 1)(a + 2); (iii) fx(x) = (a + 2)(1 - x)a+1 ,fr (y) = 
(a + 2)ya +1; (iv) g(x\y) = (a + 1)(1 - x/y)a/y,g(y\x) = (a +1)[1 /(1 - x)](y - 
x)/(1 - x)]a for 0 < x < y < 1.
6.3.7 (i) 1; (ii) 2x2 + 1/3 and y2 + 2/3; (iii) 0.3011.
6.4.1 (i) {^(z2 + 1) )• 1; (ii) eu/2/^2nu; (iii) Same as (i).
6.4.3 kwa- 1(1 - w)e- 1.
6.4.5 (i) k = 1 /[4(a + b)]; (ii) [(a - b)y/z + b]/[4(a + b)z2].
6.4.7 fW (w) = 4w3 for 0 <w<1.

564 answers to odd-numbered problems
6.4.11 6(1 — ^w)2 for 0 < w < 1.
6.5.3 (i) P(0,0,0) = 552a, P (0, 1, 0) = P(0,1,1) = 576a, P (0, 2, 2) = P(0,2,2) = 132a, 
P(0,2,1) = 288a, P (1, 0, 0) = P(1,1,0) =P(1,1,1) = 96a,P(1,2,0) =
P(1,2,2) = 24a,P(1,2,1) =48a,P(2,0,0) =P(2,2,1) = 2a,P(2,1,0) =
P(2, 1, 1) = 4a where a = 1/2652; (ii) 19/34; (iii) P(Z =0|Y =0)=1,
P(Z =1|Y =1=P(Z =0|Y =1)=0.5,P(Z =0|Y =2)=P(Z =2|Y =
2) =0.24,P(Z=1|Y =2)=0.52.
6.5.5 (i) 4; (ii) 5/48; (iii) 10/18.
6.5.7 (i) 1/6; (ii) 1/6.
6.5.9 (i) 4e-3(1 — e-1); (ii) 1/2.
CHAPTER 7
7.2.1 (i) a = 0.25, b = 0.35; (ii) a =1— m/2,b= m/2 — 0.4, 0.8 < m < 2.
7.2.3 (i) 3.36; (ii) Approximately 22.97.
7.2.5 (i) 1 / (nA); (ii) a + (b — a) / (n + 1).
7.2.7 E(X)=0.2,E(Y)=0.8.
7.4.3 511/8, 255/2,048, (1/8) X8=1 22k.
7.4.5 (i) 1; (ii) 1; (iii) 1.5; (iv) 2 log 2.
7.4.7 15.
7.5.1 (ent — 1)/[n(et — 1)] for t =1, and 1 for t =0.
7.5.3 A4.
7.5.5 an = yn(^/n — 1)ц, вп = nn.
7.5.7 (i) 0; (ii) — 2^a(a + 2)(a — 1)/[a(a + 3)]; (iii) (1 — 2p)/p(1 — p); (iv) A~1 /2 .
7.5.9 —2.4.
7.6.1 0.1633.
7.6.3 (i) 164 — 30c; (ii) (c — 2)/s^3; (iii) — 1.464 < c < 5.464.
7.6.5 Var(X27)=1— p — p2,p < 0.5.
7.6.7 0, 1 — p2, 0.
7.7.1 (i) 2; (ii) 0.625; (iii) 0.687.
7.7.5 (i) 1 / (m+ n ) , n/(m + n), 1/n; (ii) (n — 1 + s)/n.

ANSWERS TO ODD-NUMBERED PROBLEMS
565
CHAPTER 8
8.1.1 (i) True; (ii) False.
8.1.3 (i) r/n; (ii) -r(n - r)/[n2(n - 1)] .
8.1.5 0.5.
8.1.7 (i) (5/6)7 x (1 /6); (ii) (5/6)n-1 x (1 /6).
8.1.11 E(U) = 65,V ar(U) = 65(65 - 1).
8.1.13 n = M/(1 + M),A2 = 100M2/[C(M +1)2],y = 1 - 100M/[C(M + 1)].
8.1.15 (i) 3(p3 + q3) + 12pq(p2 + q2) + 30p2q2; (ii) 2(p2 + q2) + 6pq.
854 
9
.2.1 P (X = j)= 
,j =0, 1, 2, 3.
j 3-j 
3 , 
, , ,
\J / X J / /
8.2.3 (i) 29/30; (ii) 0.5; (iii) 0.8.
8.3.1 (i) [A]; (ii) 0.5(1 + e-2л) .
8.3.3 (i) 0.1094; (ii) 0.0042.
8.3.5 (i) 0.4164; (ii) 0.1677.
8.3.7 (i) 0.0588; (ii) 0.1567.
8.3.11 (i) Efc=7 (1k°) (9/30)k (21 /30)10-k; (ii) 7n/30.
8.4.3 (i)0.5665;(ii)E(T)=(m+1)/A,Var(T)=(m+1)/A2 .
8.4.5 (i) 1.3864; (ii) 2; (iii) 6.
8.4.7 WEI( k, 1 /6).
8.4.9 (i) 2.5 years; (ii) 0.189.
8.5.1 (i) 0.4099; (ii) 0.4221; (iii) 0.0672; (iv) 0.6807; (v) 0.3078; (vi) 0.1335.
8.5.3 0.1747.
8.5.5 About 48 feet above the average level.
8.5.7 (i) 0.3520; (ii) 0.0793.
8.5.9 (i) 0.7910; (ii) 0.0682.
8.6.1 (i) BETA(в, a); (ii) Г(a + в)Г(к + a)Г(m + в)/ [Г(a)Г(в)Г(к + m + a + в)].
8.6.3 a = в = (1 /к2 - 1)/2, provided |k| < 1.
CHAPTER 9 
9.1.3 N(ц, (a2/9)(1 /n 1 + 1 /n2 + 1 /n3)) and N(ц, a2/(n 1 + n2 + n3)).
9.2.3 0.9975.
9.3.1 (i) EXP(nA); (ii) EXP(,/nA); (iii) g(t) = n(n - 1)Ae-(n- 1)t (1 - e-xt).
9.3.3 (i) 1/2; (ii) 1 - (1/2)n-1.

566 answers to odd-numbered problems
9.3.5 7.
9.3.7 (i) 5!23y1y2y4(y4 - y2)2(1 - y4)2; (ii) (24/35)y4; (iii) (8/35)(3y24 + 9y23 + 11y22 + 
9y2 + 3)/(1 + y2)3; (iv) f(w) = 2w-3 for 0 <w<1.
9.4.1 0, 1,0, 1,2,4.
9.4.3 0.336517, -0.037361.
9.4.5 0.146930, 0.115247, 0.420803.
9.4.9 (ii) (0.548291, 0.304935).
9.5.3 (i) 1 — y-2n for y > 1; (ii) 1 — y-2 for y > 1; (iii) e-1 /y2 for y > 0.
9.5.5 WEI(2, 1/3).
9.5.7 0.3679, 0.6262.
9.6.1 c = 1.939.
9.6.3 a=11.16,b=1.24.
9.6.5 0.36.
9.6.7 n > 32.
9.6.11 0.9875.
9.6.13 (i)N(p(1 — p),p(1 — p)(1 — 2p)2); (ii) N(^p(1 — p), (1 — 2p)2/4); (iii)N(0, 1/(4p2)).
CHAPTER 11
11.2.5 T = NX1:n.
11.3.1 (i) a + b = 1; (ii) b =1 — a, a = a2/(a1 + a2); (iii) a = (a2 — C)/(a2 + a2 — 2C).
11.3.3 в 2/n,e 2 / (n + 1).
11.3.5 (1 — в)/(пв2), (1 — в)(n + 1 — в)/[в2(n + 1)2].
11.3.7 (ii) 1/(3n), 2/[(n + 1)(n + 2)].
11.3.9 в2 / [(n + 1)(2 n +1)].
11.4.1 0.5.
11.4.3 1 / (A2 n).
11.4.5 (i) 2/a2,1/(2a4); (ii) 0, 1/(2a4).
П.4.7 (i) y i = a 2 /n,Y 2 = M; (ii) Y1 = p(1 — p)/n,Y 2 = p .
11.5.1 (i) 
_Ta = (X )2/ [(1 /n) £ Xi — (X )2 ], Tb = X/ [(1 /n) £ Xi — (X )2]; 
(ii)
Ta = bX,Tb = a/X.
11.5.3 (i) T = X + (X2 + 2X + 3)1 /2; (ii) Xn:n; (iii) Same as in (ii) except that it cannot 
be observed when Xn:n < — 1; (iv) в = (n — Un)/Un if Un > 0.
11.5.7 (i)k/(k+1);(ii)(k— 1)/k.

ANSWERS TO ODD-NUMBERED PROBLEMS
567
11.5.9 N (Vd,a 2 / (4 nd)).
11.5.11 0.5.
11.5.13 (i) X. (ii) MLE does not exist.
11.5.15 (i) /(1 /n) £ (Xi - M)2; (ii) /(1 /n) £ (Xi - M)2.
11.5.17 (X1:n + Xn:n)/2.
11.5.19 0.0587.
HA21 (i) fa = X^- =Y,a2 = [E (Xi - X)2 + E (Yj - Y)2]/(m + n).;
mXc2+ nY a2 
2 
2 
2 2 
\2 2 
2 
\2
(ii) V = ma 2+ na 2 1 ,a 2 = (1 /m ^( Xi — V )2 ,a 2 = (1 /n )E( Yi — V )2 .
11.5.25 (X +1) /X.
11.5.27 X(2X — 1), N((2 - в)/в2, (в — 4)2/404).
11.6.1 (i) EXi;(ii) E X2;(iii) log ПXi(1 - Xi)2; (iv) Xi:n, and Xn■.n; (v) ПXi and 
E Xi are jointly sufficient for в; (vi) (X 1, ..., Xn).
11.6.3 Xn:n.
11.6.5 E Xi and X 1:n.
11.6.7 T1 = П Xi,T2 = E Xi are minimal jointly sufficient.
11.6.9 Ek-l Xi:n + (n - k + 1)Xk:n.
11/7.1 (x2.95,2n/[2 E log(Xi + 1)],x0.05,2n/[2 E log(Xi + 1)]).
11.7.3 (i) П Xi; (ii) 
(1 ± zai2//n).
11.7.5 (i) 1.117± 0.035 and 1.117 ± 0.053; (ii) 1.117 ± 0.016 and 1.117± 0.020; (iii) 
[0.00068, 0.00520] and [0.026, 0.072].
11.7.7 (i) E(La) = 422[ta/2,n-1]2/n; (ii) n > 8[ta/2,n-1]2.
11.7.9 P{x24 < 35. 179}.
11.7.11 (i) x ± za/2 fax/n; (ii) CI from part (i) is [3.955, 5.825], the approximated CI is 4.80± 
0.9306.
11.7.13 (i) [0.00058, 0.00365]; (ii) [274.05, 1728.62]; (iii) Same as in (ii); (iv) [0.0049, 0.4294].
11.7.15 n > 6.
11.7.17 (i) [0.428, 1.081]; (ii) [0.856, 5.459].
CHAPTER 12
12.2.1 п(в) = 0.5(2в + л/ОЛ)2 for0 < в < 0.5(1 - г/071), п(в) = 1 - 0.5(2 - 2в - V01)2 
for 0.5(1 - /0.1) < в < 1 - 0.5/0.1, and п(в) = 1 for в > 1 - 0.5/01.
12.2.3 (i) па ( в ) = п 1( в ) п 2( в ) п з( в ), пь ( в ) = п 1( в ) п 2 ( в ) п з( в ) + [1 - п 1( в )] п 2( в ) п з( в ) + 
п 1(в)[1 - п2(в)]пз(в) + п 1(в)п2(в)[1 - пз(в)], пс(в) = 1 - [1 - п 1(в)][1 - 
п2(в)][1 - п3(в)].

568
ANSWERS TO ODD-NUMBERED PROBLEMS
12.2.5 (i) r(5 - r)/10; (ii) 2r(5 - r)/25; (iii) P(Type I error) = 0 in each case.
12.2.7 п(р) = Ф(3(5 — р)) — Ф(3(3 — р)), п(р) tends to 0 as р ^ ж.
12.3.1 (i) Reject H0 if £ Xi > 4; (ii) 0.019.
12.3.3 X-the number of failures preceding the rth success. Reject H0 if X > 7, accept H0 
if X < 5. For X = 6 reject H0 with prob. 0.5413, в = 0■7837.
12.3.5 Reject H0 if 2A0 £ Xi < X0.95,2n, п(A) = P{X2n < (A/A0)X2.95,2n}. Reject H0 if
X1:n < — (logo.95)/(A0n),nx 1:n = 1 — (0.95)x/x0.
12.3.7 1 —r(r — 1)/30.
12.4.3 (i) Reject H0 if £ X2 < k.
12.4.5 H1 : p > 0.6, p-value = 0.072.
12.4.7 (i) Reject H0 for large values of T1 = П Xi; (ii) Reject H0 for small values of T2 = 
E Xi.
12.4.9 Reject H0 if 
Xi > r, where r is the smallest integer such that 
X=1 в0x-1 /
(в о + 1)x > 1 — a.
12.5.1 c1 = 3.71,c2 =5.
12.5.3 Reject H0 if |X — A0\/^A00 > za/2.
12.6.1 a < 0.8543.
12.6.3 (i) Not significant at 0.05 level; (ii) m<24, 940.
12.6.5 —2 log A = 3.58 < X20.05,1 = 3.841. Do not reject H0.
12.6.7 (i) A =(m + n)m+n/[(m + nY/X)m(mX/Y + n)n].; (ii) — 2logA = 0.348 < 
X02.05,1.
12.6.9 —2 log A(X) = 5.08.
12.7.1 0.536.
CHAPTER 13
13.2.1 (i)E(X|Y=y)=y/2andX =Y;(ii)E(Y|X =x)=xandY=X.
13.2.5 a = E (Y ) — b 1E (X1) — b 2 E (X 2) ,b 1 = (pY/px )( px 1 Y — px 1 X 2 X px 2 Y ) / (1 — 
p X1 ,X 2 ), b 2 = ( pY / pX )( pX 2 ,Y — pX 1 ,X 2 X pX 1 ,Y ) / (1 — p 2X11 ,X 2 ).
13.2.7 0.335 + 0.475X.
13.3.1 Any point (a, b) such that a>0.9,b < —a/2 — 0.05, b < —a +0.6,b > a— 1.8 and 
b>—a/2—0.45.
13.3.3 A = X.p = £ Yi/£ Xi.
13.4.5 b = E xiyi/E xi2,^ = (1/n) E (yi — bxi)2.
13.5.1 Reject H0,F= 451.14 > F0.05,4,6 = 4.53.
13.6.1 (i) [0.980, 1.061]; (ii) [1.014, 1.089]; (iii) [1.006, 1.076].

ANSWERS TO ODD-NUMBERED PROBLEMS
569
13.6.3 bxо ± tY/2,n- 1V1 + x2/ Exly/E (Vi- bxi)2/Vn -1 •
13.7.1 13.646 <x0 < 17.883.
13.8.1 (E y, ) / (£ xi) •
13.11.3 (i) x2n—k ;(ii) Fnk—i ,ni -1 distribution.
13.12.1 FW = 2 • 94 < F0. 01,3,6 = 10 • 72, FD = 15 • 16 > F0 . 01,2,6 = 9 • 76 • There is no effectof 
initial weight, but the type of diet affects final results.
13.13.1 FA = 6• 325>F0.05,2,18 = 3• 55, FB = 38• 855 > F0.05,2,18 = 3• 55, 
FAB =4•970 >
F0.05,4,18 = 2 • 93 • There is significant effect of the age, marijuana use, and their 
interaction on the level of emotional maturity.
CHAPTER 14
14.3.3 The joint density is 1 /(4^1 - x2) for x2 + y2 < 1 and 0 otherwise. Expected sample 
size is 8/п = 2• 55 under the “correct” scheme and 1 + п/2 = 2• 57 under the “time 
saving” scheme.
14.3.5 Reject H0 at 0.05 level.
14.3.7 k > 1 • 85 + 1 • 36V1 • 85 + 4m2.
14.4.3 Z = 1 •647, significant at 0.1 level.
14.4.5 Z = 5•668 for Problem 15.3.6 (i) and (ii), Z = 4•808 for Problem 15.3.7. Reject H0 in 
all cases.
14.5.3 R =16 or R =17 depending on the value of d. Z =1 •095 and Z = 1 • 596, 
respectively.
CHAPTER 15
15.2.1 Q2 = 0•323 < x0.05,2 = 5• 991 • Do not reject H0.
15.2.3 Q2 = 1 •307 < x0. 1,4 = 7• 779. Do not reject H0.
15.2.5 Q2 = 1 • 019 < x2.05,3 = 7• 815. Do not reject H0.
15.3.1 4/n2.
15.3.3 Q2 = 35• 714, p-value is below 0.005.
15.3.5 Q2 = 0•069 < x0. 1,1 = 2• 706. Do not reject H0.
15.4.3 Q2 = 18• 714 > x0.05,4 = 9•488. Reject H0.
15.5.1 p-value= 0.5675.
15.5.3 Z = 2 •309, the employment status in the county has changed.
15.6.1 For variables “gender-M/F” and “handedness-R/L” the values of 7 are; -1, 
-0 • 6875, 1. p-values for the tests of negative association in the first two tables are 0 
and 0.058. p-value for testing for positive association in the last table is 0.

570 answers to odd-numbered problems
CHAPTER 16 
16.2.1 BETA(5, 2), 0.227.
16.3.3 (i) 6* = 0.269, v* = 4.333; (ii) for 6 : (0. 126, 0.455), for p, : (2.899, 5.618).
16.3.5 0.3.
16.3.7 0.352.
16.3.9 (i) X/2; (ii) X/2 ± 1.96 x V2/4.
16.3.11 6* = (£ Xi - 0.5)/(n - 1).

Index
Absorbtion law for events, 11
Absorbtion probabilities, 88
Accept-Reject algorithm, 274
Adhikari, A., 495
Agresti, A., 492, 515
Allais’s paradox 38
ANOVA, 455
one-way, 455
two-way, 458
with interaction, 461
Antle, C. E., 366
Arnold, B. C., 342
Associativity law for events, 11
Axioms of probability, 22
Bootstrap:
t CI, 368
percentile interval, 369
tests, 425
Borel-Cantelli lemma:
first, 33
second, 78, 278
Borel-Kolmogorov paradox, 152
Box-Mueller transformation, 276
Bray, T. A., 276
Brownian motion, 18
Casella, G., 293, 543
Categorical data, 308
Cdf, 5, 95, 165
Bain, L. J., 366
Ballot problem, 
Basu theorem, 258
Bayes factor, 539
Bayes estimator, 530
Bayes’ formula, 69
Bayesian statistics, 298
Bayesian intervals, 538
Berger, R. L., 293
Bernoulli trials, 211, 399
Bertrand paradox, 23
Binomial:
bivariate, 165
empirical, 468
Censoring, 179, 302
Central limit theorem, 287
Laplace, 288
Liapunov, 291
Lindeberg and Feller, 292, 479
Lindeberg and Levy, 287
Chain rule, 62
Characteristic function, 188, 190
Chebyshev inequality, 207, 283
Chi-square test, 496, 503
coefficients, 46, 47
thinning, 145
Birthday problem, 42
Blackwell, D. H., 36
of homogeneity, 502
of independence, 500
Chow, Y. S., 16, 57, 100
Chung, K. L., 16, 23, 470
Probability and Statistical Inference, Third Edition. Magdalena Niewiadomska-Bugaj and Robert Bartoszynski. 
© 2021 John Wiley & Sons, Inc. Published 2021 by John Wiley & Sons, Inc.
571

572
INDEX
Closure ofa class of events, 15, 191
Color blindness gene, 59, 67
Combinations, 44
Combinatorics, 30
Commutativity law for events, 11
Completeness, 355
Concordant pair, 517
Conditional:
density, 142
distribution, 141
expectation, 202
independence, 80
probability, 60
Confidence:
bound, 360
interval, 359, 360
Conjugate prior, 524
Consistency:
of estimators, 314
of tests, 599
Contamination, 341
Contingency table, 499, 517
Continuity correction, 289
Convergence:
a.e. (almost everywhere), 278
a.s. (almost sure), 278
in distribution, 280
in probability, 277
stochastic, 277
with probability one, 278
Correlation coefficient, 197, 199
Countable additivity, 22
Covariance, 194
Credible interval, 539
Cramer, H., 496
Cramer - Rao inequality, 310, 326, 376
Cramer- Rao lower bound, 326
Critical region, 377, 457
D’Alembert, 79
Davidson, D. H., 37
Davison, A., 370
Decision rule, 377
De Groot, M., 367
Delta method, 292
Density:
bivariate, 124
conditional, 142
joint, 124
marginal, 130, 156
posterior, 522
prior, 407
De Morgan’s laws, 11
Descriptive statistics, 296
Devore, J. L., 507
Discordant pair, 517
Distribution, 94
beta, 255, 256
binomial, 103, 208, 212, 227
bivariate, 124
Cauchy, 170
chi-square, 117, 142
conditional, 140
conjugate prior, 524
continuous, 106
discrete, 102
Erlang, 235
exponential, 108
Frank, 276
lognormal, 250
memoryless property of, 240
F, 265
folded normal, 117, 250
gamma, 241, 271
geometric, 104, 214, 215
memoryless property of, 215
Gompertz, 276
hypergeometric, 223, 226
inverse gamma, 529
joint, 157
Kolmogorov, 471
Laplace, 243
marginal, 129, 130, 156
multinomial, 158
negative binomial, 218
normal, 109, 246
bivariate, 251
multivariate, 251
standard, 109
Pareto, 275, 287
Poisson, 104,144, 192,228
Polya, 227
posterior, 522
predictive, 529
prior, 521
conjugate, 524
improper, 526
informative, 525
Jeffreys, 527, 528
noninformative, 526
probability function of, 104
Student’s t, 264
triangular, 149
trinomial, 157
uniform, 102
discrete, 106
continuous
Weibull, 120, 145, 244
Distributivity law for events, 11
Dominated convergence theorem, 178
Efficiency of an estimator, 321, 327 
relative, 327
Efron, B., 469
Ehrenfest model of diffusion, 91
Empty set, 9
Epidemic, 83
Error, 
homoscedasticity, 452, 455 
orthogonality, 452 
of type I, 375, 391 
of type II, 375, 391 
squared, 317
Estimate, 312
Estimator, 312 
admissible, 316 
asymptotically unbiased, 318
Bayes, 530
bias of, 318
biased, 318
BLUE, 451
consistency of, 313

INDEX
573
efficiency of, 327
relative, 327
inadmissible, 316
L, 341
LS (least squares), 339
M, 342
maximum likelihood, 331
method of moment, 338
R-admissible, 316
R-dominating, 316
risk function of, 317
robust, 340
sufficient, 345, 346
unbiased, 310, 318
unbiasedness of, 311
Event(s), 4, 8
complement of, 9
conditional independence of, 80
correlation between, 76
difference of, 10
disjoint, 10, 22, 32
pairwise, 22
double complementation of, 11
equality, 9
exchangeability, 52, 81
field of, 14-19
minimal, 17
impossible, 9, 26
independence of, 74, 75, 77, 132
pairwise, 77
intersection of, 17, 65
lim inf ofa sequence, 14
limit of a sequence, 14
lim sup ofa sequence, 14
monotone class of, 16, 17
monotone sequences of, 16
mutually exclusive, 10
probability of, 95
a -field of, 15, 17
minimal, 34
symmetric difference, 10
trees, 63
union of, 9, 27
Expectation, see also Expected value, 
conditional, 202
Expected value, 163, 177
Experiment, 2
outcome of, 2
Exponential class, 357
Gamma association coefficient, 518
Gamma function, 117, 241
Gauss-Markov theorem, 452
Gelman, A., 543
Genest, C., 276
Gentle, J. E., 276
George, E. I., 543
Gibbons, J. D., 389
Girshick, M. A., 36
Glivenko-Cantelli theorem, 476
Good, P. I., 426
Goodman, L. A., 506
Graybill, F. A., 327
Greco-Latin squares, 465
Green, R. F., 271, 301, 536
Gross errors, see Outliers,
Halton, J. H., 514
Hazard function, 118
Heteroscedasticity, 436
Hinkley, D., 370
Highest density interval (HDI), 539
Hoff, P. D., 543
Hollander, M., 467
Homoscedasticity, 436
Hotelling, H., 205
Hypothesis, 377
alternative, 377
composite, 377
null, 377
simple, 378
Idempotence law for events, 11
Interval scale, 307
James, R., 494
Jeffreys, H., 541
Jordan, W., 260
Kass, R. E., 541
Kendall’s Tb, 518
Kennedy, W. J., 276
Kolmogorov, A. N., 22, 286
Kolmogorov:
distribution, 472
inequality, 209, 278
strong laws of large numbers, 285, 286
Factorization criterion, 346
Failure rate, 120
Feller, W., 39, 237, 292
Field, 15-17
minimal, 17
Fisher:
three series theorem, 279
Kolmogorov-Smirnov test: 
one-sample, 471 
two-sample, 475
Kotz, S., 244
Krantz, D. H., 37, 307
information, 323
test, 413, 514
Fox, M., 494
Freedman, D., 495
Freeman, G. H., 514
Kruskal-Wallis test, 488
Kurtosis, 191
Lancaster, H. O., 506, 507
Laplace, P. S., 244
Larsen, R. J., 421, 427
Gafrikova, V., 317
Galton, F., 453
Gambler’s ruin problem, 86
Latin squares, 465
Law of large numbers, 277, 283, 285
Lazar, N., 390

574
INDEX
Lebesgue, H., 31
integral, 172
-Stieltjes integral, 174
Legendre, A. M., 436
Lehmann, E. L., 376, 414
Lehmann and Scheffe theorem, 355
Liapunov:
condition, 291
inequality, 186
Likelihood:
function, 331
principle, 335
ratio, 387
generalized, 504
monotone, 399
Lindeberg condition, 292
Loss function, 317, 530
Lottery, 35
expectation of, 35
subjective expected utility (SEU) of, 36
Luce, R. D., 37
MacEachern, S., 239
Manhattan Project, 271
Mann-Whitney test, 487
Marginal homogeneity, 514
Markov chain, 82, 85, 216
initial distribution, 85
n-step transition probabilities, 88
periodic state, 90
time-homogeneity, 85
transition probability matrix, 85
Markov inequality, 209
Markov property, 85
Marsaglia, G., 276
Marx, M. L., 421, 427
Matching problem, 51
Maximum likelihood, 49, 331
McNemar’s test, 514
Mean, see also Expected value, 205
absolute deviation, 193
squared deviation, 193
squared error, 193, 317
Measurement scales, 305, 307
Median, 193, 205
Mendel, G., 495
Method of moments, 328
Metropolis, N., 272
mgf. see Moment generating function
Milton, J. S., 429
Mixing coefficients, 146
Maximum likelihood estimators, 331, 334
invariance of, 334
Model of grinding, 159
Moment, 184
absolute, 185
central, 185
factorial, 184
generating function, 184, 282
Monotone class, 15, 16
Monotone convergence theorem, 14, 178
Monte Carlo:
simulations, 272, 273
tests, 424
Montgomery, D. C., 429
Monty Hall TV game, 72
Mood, A. M., 327
Morgenstern, O., 36
Moving averages, 201
Multinomial coefficients, 56
Multiplication rule, 40, 74
Myers, R. H., 429
Newton’s binomial formula, 47, 219, 229
Neyman, J., 270, 271, 380, 405
Neyman-Pearson lemma, 376, 387, 388
Niewiadomska-Bugaj, M., 317
Nominal scale, 307
Nonnegativity, 22
Norming, 22
Nuisance parameter, 405
O’Cinneide, C. A., 205
Odds, 509
ratio, 510
Oehlert, G. W., 293
Order statistics, 266, 267
Ordinal scale, 307
Outcome, 2, 30
Outlier, 270, 271, 341
proneness, 271
resistance, 271
Parameter:
nuisance, 405
of location, 341
of scale, 341
space, 311‘
Partitions, 65
coarsening, 68
finite, 65, 66
positive, 66
refinement of, 65
Pascal triangle, 46
Pearson, E. S., 380, 405
Pearson’s chi-square statistic, 493
Periodicity, 90
Permutations, 41
Petersburg paradox, 167
Pisani, R., 495
Plug-in-principle, 328
Poisson process, 228, 231, 233, 235
Poker, 54-56
Polya scheme, 227
Power function of a test, 378
Pratt, J. W., 389
Prediction, 447
Probability:
classical interpretation, 21, 48, 130
conditional 60
distribution, 94
frequency interpretation, 21
generating function, 191
geometric, 23
integral transform, 116
logical interpretation, 21

INDEX
575
mass function, 104
finite, 4
posterior, 70, 522
sample point, 2
prior, 70, 521, 522
uncountable, 4
subjective, 121
Sampling:
Prospective studies, 501
cluster, 301
Purves, R., 495
distribution, 259
p-value, 389
importance, 301 
stratified, 301
Quantiles, 99
without replacement, 75
with replacement, 75
Quartile:
Savage, L. J., 36
lower, 100
Schwarz inequality, 198
upper, 100
Scott, E. L., 270, 271
Selection problem, 5
Ramsey, F. P., 36
Random number generation, 272
Random sample, 194, 252, 272
Random variable(s):
Sensitivity analysis, 530
Sequential formation, 253
Sequential tests, 410
Serfling, R. J., 342
Sex-linked attributes, 61
cdf, 95, 127
ст -field of events, 16, 17
continuous, 106, 176
minimal, 34
dependent, 134
Size of a test, 389
discrete, 102, 175
Skewness, 191
independence of, 129, 132, 504 
mixed-type, 111
Slutsky theorem, 280
Smirnov, N., 471, 475
orthogonal, 194
Solomons, L. M., 205
pivotal, 363, 366
Somer’s d, 518
uncorrelated, 194
Srivastava, R. C., 215
Random walk, 83
Standard deviation, 191, 205
Randomized response, 5, 330
Randomized test, 380
Stapleton, J., 429
Statistic, 113, 345
Raftery, A., 541
Rank tests:
ancillary, 358
sufficient, 345
one-sample, 478
two-sample, 484
jointly, 348
minimal, 349
Range, 268
Rao-Blackwell theorem, 311, 350, 355
Ratio scale, 307
Regression, 339
inverse, 449
linear, 340
Stevens, S. S., 307
Stigler, S. M., 196, 339
Stirling’s formula, 57
Stochastic, 84
convergence, 277
matrix, 85
logistic, 437
of the first kind, 422
of the second kind, 433
toward the mean, 453
Sufficiency, 345 
completeness, 355 
joint, 348 
minimal, 349
true, 422
Rejection region, 375
Relative risk, 409
Reliability (in psychol. tests), 455
Suppes, P., 37
Survival function, 118
Renewal paradox, 307
Teicher, H., 57, 100
Resampling methods, 313
Tests of hypotheses, 373
Retrospective studies, 501
Riemann integral, 171, 174
-Stieltjes integral, 174
Risk function, 316
Roberts, F. S., 307
Romano, J. P., 414, 376
Ross, S., 273
Runs test, 480
Russell, B., 21
Sample space, 2, 30
countably infinite, 4
conditional, 412
GLR, 405, 504
level of, 389
most powerful, 384
permutation, 425
sequential, 410
significance level of, 389
size of, 389
UMP, 376, 396, 397, 419, 420
UMPU, 376, 419, 420 
unbiased, 402-404
Three-sigma rule, 247
Tibshirani, R., 370
elementary outcome, 2
Tied pair, 517

576 index
Total probability formula, 66
Trimmed mean, 341, 342
Truncation, 297
Tversky, A., 37
Ulam, S., 272
Updating evidence, 70
Utility, 167
Variance, 191
Venn diagram, 11, 27
von Bortkiewicz, L., 498
von Neumann, J., 36, 272
Wald, A., 410
Wasserstein, R. L., 390
Wilcoxon-Mann-Whitney test, 487
Wilcoxon signed rank test, 478, 487
Winsorized mean, 341, 342
Wolfe, D. A., 467

