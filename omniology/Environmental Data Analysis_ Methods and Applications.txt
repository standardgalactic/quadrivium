
Zhihua Zhang
Environmental Data Analysis

Also of Interest
Probability Theory and Statistical Applications.
A Profound Treatise for Self-Study
Peter Zörnig, 2016
ISBN 978-3-11-036319-7, e-ISBN 978-3-11-040283-4
An Introduction to Nonlinear Optimization Theory
Marius Durea, Radu Strugariu, 2014
ISBN 978-3-11-042603-8, e-ISBN 978-3-11-042735-6
Asymptotic Statistics.
With a View to Stochastic Processes
Reinhard Höpfner, 2014
ISBN 978-3-11-025024-4, e-ISBN 978-3-11-036778-2
Compressive Sensing.
Applications to Sensor Systems and Image Processing
Joachim Ender, 2017
ISBN 978-3-11-033531-6, e-ISBN 978-3-11-039027-8
Scientiﬁc Computing.
For Scientists and Engineers
Timo Heister, Leo G. Rebholz, 2015
ISBN 978-3-11-035940-4, e-ISBN 978-3-11-038680-6

Zhihua Zhang
Environmental
Data Analysis
|
Methods and Applications

Author
Prof. Zhihua Zhang
College of Global Change &
Earth System Science
Beijing Normal University
19 Xinjiekou Wai St.
100875 Beijing
People’s Republic of China
zhangzh@bnu.edu.cn
ISBN 978-3-11-043001-1
e-ISBN (PDF) 978-3-11-042490-4
e-ISBN (EPUB) 978-3-11-042498-0
Set-ISBN 978-3-11-042491-1
Library of Congress Cataloging-in-Publication Data
A CIP catalog record for this book has been applied for at the Library of Congress.
Bibliographic information published by the Deutsche Nationalbibliothek
The Deutsche Nationalbibliothek lists this publication in the Deutsche Nationalbibliograﬁe;
detailed bibliographic data are available on the Internet at http://dnb.dnb.de.
© 2017 Walter de Gruyter GmbH, Berlin/Boston
Cover image: Merve Sarac/iStock/thinkstock
Typesetting: PTP-Berlin, Protago-TEX-Production GmbH, Berlin
Printing and binding: CPI books GmbH, Leck
♾Printed on acid-free paper
Printed in Germany
www.degruyter.com

Preface
Environmental data provide huge amounts of information, but it is complex to process
due to the size, variety, and dynamic nature of the data. In order to develop solu-
tions to many environmental issues and make predictions to determine how resources
are best allocated, environmental researchers have spent considerable time ensur-
ing well-conducted data collection, analyzing and interpreting environmental data,
and describing environmental changes with sound and validated models. Therefore,
researchers in environmental science need to be familiar with various advanced tech-
niques for exploration, identiﬁcation and analysis of patterns in data.
This book covers the comprehensive range of topics in data analysis in space, time
and spectral domains which are necessary knowledge for environmental research.
Main topics include Models for Linear and Nonlinear Environmental Systems, Statisti-
cal and Numerical Methods, Data Envelopment Analysis, Risk Assessments, and Life
Cycle Assessments. It is a concise and accessible book suitable for anyone interested
in learning and understanding advanced methods and applications in environmental
data analysis.
DOI 10.1515/9783110424904-001


Contents
Preface | V
1
Time series analysis | 1
1.1
Stationary time series | 1
1.2
Prediction of time series | 6
1.3
Spectral analysis | 13
1.4
Autoregressive moving average models | 17
1.5
Prediction and modeling of ARMA processes | 26
1.6
Multivariate ARMA processes | 34
1.7
State-space models | 39
2
Chaos and dynamical systems | 45
2.1
Dynamical systems | 45
2.2
Henon and logistic maps | 46
2.3
Lyapunov exponents | 50
2.4
Fractal dimension | 51
2.5
Prediction | 55
2.6
Delay embedding vectors | 56
2.7
Singular spectrum analysis | 57
2.8
Recurrence networks | 58
3
Approximation | 63
3.1
Trigonometric approximation | 63
3.2
Multivariate approximation and dimensionality reduction | 72
3.3
Polynomial approximation | 76
3.4
Spline approximation and rational approximation | 82
3.5
Wavelet approximation | 86
3.6
Greedy algorithms | 98
4
Interpolation | 102
4.1
Curve ﬁtting | 102
4.2
Lagrange interpolation | 106
4.3
Hermite interpolation | 110
4.4
Spline interpolation | 112
4.5
Trigonometric interpolation and fast Fourier transform | 116
4.6
Bivariate interpolation | 118

VIII
|
Contents
5
Statistical methods | 122
5.1
Linear regression | 122
5.2
Multiple regression | 125
5.3
Case study: Tree-ring-based climate reconstructions | 128
5.4
Covariance analysis | 131
5.5
Discriminant analysis | 132
5.6
Cluster analysis | 137
5.7
Principal component analysis | 139
5.8
Canonical correlation analysis | 142
5.9
Factor analysis | 143
6
Numerical methods | 148
6.1
Numerical integration | 148
6.2
Numerical differentiation | 152
6.3
Iterative methods | 155
6.4
Difference methods | 163
6.5
Finite element methods | 167
6.6
Wavelet methods | 176
7
Optimization | 185
7.1
Newton’s method and steepest descent method | 185
7.2
The variational method | 192
7.3
The simplex method | 198
7.4
Fermat rules | 222
7.5
Karush–Kuhn–Tucker optimality conditions | 225
7.6
Primal and dual pairs of linear optimization | 233
7.7
Case studies | 240
8
Data envelopment analysis | 243
8.1
Charnes–Cooper–Rhodes DEA models | 243
8.2
Banker–Charnes–Cooper DEA models | 252
8.3
One-stage and two-stage methods | 255
8.4
Advanced DEA models | 257
8.5
Software and case studies | 264
9
Risk assessments | 267
9.1
Decision rules under uncertainty | 267
9.2
Decision trees | 271
9.3
Fractile and triangular methods | 274
9.4
The ε-constraint method | 282
9.5
The uncertainty sensitivity index method | 287
9.6
The partitioned multiobjective risk method | 291

Contents
|
IX
9.7
The multiobjective multistage impact analysis method | 294
9.8
Multiobjective risk impact analysis method | 296
9.9
The Leslie model | 304
9.10
Leontief’s and inoperability input-output models | 307
10
Life cycle assessments | 312
10.1
Classic life cycle assessment | 312
10.2
Exergetic life cycle assessment | 315
10.3
Ecologically-based life cycle assessment | 316
10.4
Case studies | 318
Index | 321


1 Time series analysis
The main objectives of environmental time series analysis are to describe environmen-
tal change, explain the mechanisms underlying these changes, predict future environ-
mental change under given perturbation and avoid undesired environmental impacts.
In environmental time series analysis, autoregressive moving average (ARMA) models
and state-space models are two most useful tools to discover the dynamical character-
istics of environmental change through ﬁtting them to environmental time series with
complex dynamics.
1.1 Stationary time series
A time series is a set of observations {xt}, where each t is a speciﬁc time. Time series are
encountered in a variety of ﬁelds such as temperature, rainfall, pollution, emissions
and population.
To draw inferences from time series, involving prediction and interrelationships,
and to understand the mechanism generating the series, one needs to establish a
probability model. The observation is postulated to be a realization of the proba-
bility model. For a complete probability model {Xt}, all of the joint distributions of
(X1, . . . , Xn)T (n ∈ℤ+) would be speciﬁed, i.e., for any n ∈ℤ+, the probabilities
P(X1 ≤x1, . . . , Xn ≤xn) are speciﬁed. If all the joint distributions are multivariate
normal, the distribution properties of the probability model would be determined
completely by the means EXt and covariances Cov(Xt+h, Xt) (t ∈ℤ+, h = 0, 1, . . . ).
Generally speaking, a complete probability model cannot be established using one
data observation. In most practical problems involving time series, only one realiza-
tion is seen. Moreover, to obtain all of the joint distributions, one needs to estimate too
many parameters. However, from a linear prediction viewpoint, the minimum mean
squared error linear prediction depends only on means and covariances. Therefore,
one characterizes time series models using the second-order properties.
A time series model for observed data is a sequence of random variables {Xt} with
mean function EXt and covariance function Cov(Xt+h, Xt). Denote
μX(t) = EXt,
γX(t + h, t) = Cov(Xt+h, Xt).
We say a time series {Xt} is stationary if its mean function μX(t) is independent of
t and the autocovariance function γX(t + h, t) is independent of t for each lag h.
DOI 10.1515/9783110424904-002

2
|
1 Time series analysis
1.1.1 Autocovariance functions
If a time series {Xt} is stationary, denote μX = μX(t), the autocovariance function of
{Xt} at lag h is γX(h) = γX(t + h, t) and the autocorrelation function at lag h is ρX(h) =
γX(h)/γX(0).
The basic properties of autocovariance function γX(h) are as follows:
–
γX(0) ≥0 and γX(h) is even, and |γX(h)| ≤γX(0) for all h;
–
the matrix (γX(i −j))i,j=1,...,n is nonnegative deﬁnite, i.e., for any real-valued vec-
tor a = (a1, . . . , an)T,
n
∑
i,j=1
aiγX(i −j)aj ≥0
(n ∈ℤ).
In fact, it is clear that
γX(0) = Cov(X0, X0) = Var(X0) ≥0,
γX(−h) = Cov(X−h, 0) = Cov(X0, Xh) = Cov(Xh, X0) = γX(h).
By the Schwarz inequality,
0 ≤|γX(h)| = |Cov(Xh, X0)| = |E[(Xh −EXh)(X0 −EX0)]|
≤(E[(Xh −EXh)2])
1
2 ⋅(E[(X0 −EX0)2])
1
2
= (Var(Xh) Var(X0))
1
2 = Var(X0) = γX(0).
Without loss of generality, assume μX = 0. Let Xn = (Xn, . . . , X1)T. Then
0 ≤Var(aTXn) = E[(aTXn)2] = E[aTXnXT
na] = aTE[XnXT
n]a =
n
∑
i,j=1
aiγX(i −j)aj,
where Var(X) means the variance of X.
A time series {Xt} is strictly stationary if (X1, . . . , Xn) and (X1+h, . . . , Xn+h) (h ∈ℤ,
n ∈ℤ+) have the same joint distributions. If {Xt} is strictly stationary, then {Xt} must
be stationary. Conversely, it is not true.
For example, consider a time series {Xt} which is obtained by tossing a penny
repeatedly and scoring +1 for each head and −1 for each tail. Its time series model
{Xt} is an independent random variable sequence with
P(Xt = 1) = 1
2 ,
P(Xt = −1) = 1
2 ,
(t ∈ℤ+).
Its mean function EXt = 0 and variance Var(Xt) = 1, and autocovariance function
γX(t + h, t) = 0 (h
̸= 0). Clearly, both μX(t) and γX(t + h, t) are independent of t. So
{Xt} is a stationary time series with mean 0 and autocovariance function γX(h) = δ0,h,
where δij is the Kronecker delta. Take
St = X1 + X2 + ⋅⋅⋅+ Xt
(t ∈ℤ+),
S0 = 0,

1.1 Stationary time series
|
3
which is called the random walk. Clearly, μS(t) = ESt = 0 and
γX(t + h, t) = Cov(St+h, St)
= Cov(St + Xt+1 + ⋅⋅⋅+ Xt+h, St) = Cov(St, St)
= E[(X1 + ⋅⋅⋅+ Xt)2] = EX2
1 + ⋅⋅⋅+ EX2
t = t.
Since γX(t + h, t) depends on t, St is not a stationary time series. Let Yt = Xt + 1
2 Xt−1.
Then μY(t) = 0 and
γX(t + h, t) =
{
{
{
{
{
{
{
{
{
5
4 ,
h = 0,
1
2 ,
h = ±1,
0,
|h| > 1,
and so the random walk is stationary with mean 0 and
γX(h) =
{
{
{
{
{
{
{
{
{
5
4 ,
h = 0,
1
2 ,
h = ±1,
0,
|h| > 1.
For example, consider a time series
Xt = A cos(ωt) + B sin(ωt)
(t ∈ℤ),
where A and B are uncorrelated random variables with mean 0 and variance 1, and
ω is a constant. The mean and covariance are, respectively,
EXt = (EA) cos(ωt) + (EB) sin(ωt) = 0,
Cov(Xt+h, Xt) = E[(A cos ω(t + h) + B sin ω(t + h))(A cos(ωt) + B sin(ωt))]
= E[A2 cos ω(t + h) cos(ωt) + AB cos ω(t + h) sin(ωt)
+ AB sin ω(t + h) cos(ωt) + B2 sin ω(t + h) sin(ωt)].
By the assumption that EA2 = EB2 = 1 and E[AB] = 0,
Cov(Xt+h, Xt) = cos ω(t + h) cos(ωt) + sin ω(t + h) sin(ωt) = cos(ωh).
Therefore, {Xt} is a stationary time series with the mean μ = 0 and autocovariance
function γ(h) = cos(ωh).
1.1.2 White noise and linear process
The simplest model for a time series is white noise which is a sequence of uncorrelated
random variables {Zt} with mean 0 and variance σ2. Denote {Zt} ∼WN(0, σ2).
Since EZt = 0 (t ∈ℤ) and Cov(Zt+h, Zt) = δh,0σ2 (t ∈ℤ), the time series {Zt} is
stationary. Its mean is μ = 0 and the covariance matrix of Z1, . . . , Zn is σ2In, where
In is the identity matrix of order n.

4
|
1 Time series analysis
White noise plays an important role as a building block for more complicated time
series. For example, consider the time series
Xt = Zt + 1
3 Zt−1,
{Zt} ∼WN(0, 1)
(t ∈ℤ).
Its mean is EXt = 0 and for all t,
E[Xt+h, Xt] =
{
{
{
{
{
{
{
{
{
10
9
if h = 0,
1
3
if h = ±1,
0
if |h| > 1.
So Xt is a stationary time series.
We say that a time series {Xt} is a linear process if
Xt = ∑j∈ℤψjZt−j,
{Zt} ∼WN(0, σ2),
where each ψj is constant and ∑j∈ℤ|ψj| < ∞. Since ∑j∈ℤ|ψj| < ∞, clearly, ∑j∈ℤψ2
j <
∞. This further deduces that ∑j∈ℤψjZt−j is convergent in the square mean. So the
linear process Xt is stationary.
In fact, from
E[Xt] = ∑j∈ℤψjE[Zt−j] = 0,
E[Xt+hXt] = ∑k∈ℤ∑j∈ℤψjψkE[Zt+h−jZt−k],
E[Zt+h−jZt−k] = δj−h,kσ2,
it follows that
γ(h) = E[Xt+hXt] = ∑
k∈ℤ
ψk+hψkσ2,
(1.1.1)
and so {Xt} is stationary.
Assume that {Xt} is a stationary time series satisfying the following:
Xt = φXt−1 + Zt,
{Zt} ∼WN(0, σ2)
(t ∈ℤ),
(1.1.2)
where |φ| < 1 and Zt is uncorrelated with Xs. Then
Xt = φXt−1 + Zt = φ(φXt−2 + Zt−1) + Zt = φ2Xt−2 + φZt−1 + Zt
=
k
∑
0
φjZt−j + φk+1Xt−k−1.

1.1 Stationary time series
|
5
Since {Xt} is stationary,
E[(Xt −
k
∑
j=0
φjZt−j)2] = φ2k+2E[X2
t−k−1] →0
(k →∞),
and so Xt = ∑∞
j=0 φjZt−j in the mean square sense. This is a linear process and ∑∞
j=0 φj <
∞. By (1.1.1),
γX(h) =
∞
∑
0
φk+hφkσ2 = σ2φh
1 −φ2
(h ≥0).
(1.1.3)
1.1.3 Sample autocorrelation function
In practical problems, we do not start with a model but with observed data {x1, x2, . . . ,
xn}. Using these observation data, we estimate the mean μ, autocovariance func-
tion γ(h), and autocorrelation function ρ(h). The sample mean of x1, . . . , xn is
̄x = 1
n ∑n
t=1 xt. The sample autocovariance function is
̂γ(h) = 1
n
n−|h|
∑
1
(xt+|h| −̄x)(xt −̄x)
(−n < h < n).
1.1.4 Classical decomposition model
When we analyze any time series, we ﬁrst plot data on a sheet of graph paper. If there
are discontinuities, we break it into homogeneous segments. If there are outlying ob-
servations, we discard them. Inspection of a graph may also suggest the possibility
of representing the data as a realization of a process. The classical decomposition
model is
Xt = mt + st + Yt,
where mt is a trend component, st is a seasonal component, and Yt is a stationary
random noise component.
We hope to estimate mt and st such that the residual Yt is stationary. First we con-
sider the nonseasonal model with trend Xt = mt + Yt (t = 1, . . . , n), where E[Yt] = 0.
The moving average is
̂mt =
1
2p + 1
p
∑
−p
Xt−j
(p −1 ≤t ≤n −p).
It provides an estimate of the trend mt.
A general classical decomposition model is
Xt = mt + st + Yt
(t = 1, . . . , n),

6
|
1 Time series analysis
where E[Yt] = 0, st+d = st, and ∑d
j=1 sj = 0. For observations {x1, . . . , xn}, if the period
d = 2p is even, then the estimate of trend
̂mt = 1
2p (1
2 xt−p + xt−p+1 + ⋅⋅⋅+ xt+p−1 + xt+p)
(p < t ≤n −p);
if the period d = 2p + 1 is odd, then the estimate of trend
̂mt =
1
2p + 1
p
∑
−p
xt−j
(p + 1 ≤t ≤n −p).
For each k = 1, . . . , d, let ωk be the average of the deviations {xk+jd −
̂mk+jd} (p <
k + jd ≤n −p) and let
̂sk = ωk −1
d
d
∑
1
ωi
(k = 1, . . . , d),
̂sk = sk−d
(k > d).
Deﬁne dt = xt −
̂st (t = 1, . . . , n). Reestimating the trend from {dt} as above, the
estimated noise series is
̂Yt = xt −
̂mt −̂st
(t = 1, . . . , n).
1.2 Prediction of time series
If a time series {Xt} is independent for different time t, we cannot make predictions.
If it is correlated, and its mean and covariance are known, we may predict Xt+h from
X0, . . . , Xt. In fact, this requires ﬁnding a linear combination τ∗of X0, . . . , Xt such
that the mean square error E[(Xt+h −τ∗)2] is minimal. The τ∗is called the best linear
approximation and is used as the forecast of Xt+h.
1.2.1 The best linear approximation
If a random variable Y is approximated by random variable X, deﬁne the mean square
error as E[(Y −X)2]. The simplest case is that if a random variable Y is approximated
by a constant, then EY is its best approximation and the minimum mean square error
is Var(Y).
Orthogonality principle
Let Y be a random variable. Denote by τn all linear combinations of 1, X1, . . . , Xn,
i.e.,
τn = {a0 +
n
∑
1
akXk,
where each ak is constant} .

1.2 Prediction of time series
|
7
For X ∈τn, deﬁne the approximation error as E[(Y −X)2]. If X∗∈τn is such that
E[(Y −X∗)Xk] = 0 (k = 0, 1, . . . , n), then X∗is the best linear approximation of Y in
τn, i.e., for all X ∈τn,
E[(Y −X∗)2] ≤E[(Y −X)2]
and the minimum mean error is
E[(Y −X∗)2] = E[Y2] −E[X∗2].
Conversely, if X∗∈τn is the best linear approximation of Y in τn, then
E[(Y −X∗)Xk] = 0
(k = 0, 1, . . . , n).
1.2.2 Prediction of stationary time series
Let {Xt} be a stationary time series with mean μ and autocovariance function γ. We
estimate Xn+h (h > 0) by the linear combination of 1, X1, . . . , Xn such that the mean
square error attains the minimal value. Denote by PnXn+h the best linear predictor and
PnXn+h = a∗
0 + a∗
1Xn + ⋅⋅⋅+ a∗
nX1,
(1.2.1)
where a∗
0, a∗
1, . . . , a∗
n are undetermined coefficients.
By the orthogonality principle, the best approximation PnXn+h of Xn+h in all lin-
ear combinations of {1, X1, . . . , Xn} satisﬁes
E[(Xn+h −PnXn+h)] = 0,
E[(Xn+h −PnXn+h)Xn+1−j] = 0
(j = 1, . . . , n).
This implies the following proposition.
Let {Xt} be a stationary time series with mean μ and autocovariance function γ.
Then
(a) the best predictor PnXn+h of Xn+h (h > 0) by the linear combinations of 1, X1, . . . ,
Xn is
PnXn+h = μ +
n
∑
1
a∗
i (Xn+1−i −μ)
and the coefficient a∗
n = (a∗
1, . . . , a∗
n)T satisﬁes the system of linear equations
{
{
{
a∗
0 = μ (1 −∑n
i=1 a∗
i ) ,
Γna∗
n = Rn(h),
(1.2.2)
where Γn = ( γ(i −j) )n×n, and Rn(h) = (γ(h), γ(h + 1), . . . , γ(h + n −1))T;
(b) the minimum mean square error E[(Xn+h −PnXn+h)2] = γ(0) −a∗T
n Rn(h).

8
|
1 Time series analysis
Consider a time series {Xt} satisfying
Xt = 1
2 Xt−1 + Zt,
{Zt} ∼WN(0, 1)
(t ∈ℤ).
The best predictor is
PnXn+1 =
n
∑
i=1
a∗
i Xn+1−i
(1.2.3)
and the coefficient a∗
n = (a∗
1, . . . , a∗
n)T satisﬁes the equation
(γ(i −j))n×n(a∗
1, . . . , a∗
n)T = (γ(1), . . . , γ(n))T.
From (1.1.3), it follows that γ(h) = 4
32−h. So
(
1
2−1
2−2
⋅⋅⋅
2−n+1
2−1
1
2−1
⋅⋅⋅
2−n+2
...
...
...
...
...
2−n+1
2−n+2
2−n+3
⋅⋅⋅
1
) (
a∗
1
a∗
2
...
a∗
n
) = (
2−1
2−2
...
2−n
)
and the solution is a∗
1 = 1
2 , a∗
2 = ⋅⋅⋅= a∗
n = 0. By (1.2.3),
PnXn+1 = 1
2 Xn.
So the minimum mean square error is
E[(Xn+1 −PnXn+1)2] = γ(0) −a∗
1γ(1) = 4
3 −2
3 a∗
1 = 1.
1.2.3 Durbin–Levinson and innovation algorithms
Generally speaking, to obtain a∗
1, . . . , a∗
n, we need to solve the system (1.2.2) of linear
equations. This is very difficult for large n. The following Durbin–Levinson algorithm
gives a simple recursive formula of coefficients of the best linear prediction for a sta-
tionary time series {Xt} with mean μ and covariance function γ(h). For convenience,
we assume that the mean μ = 0 and γ(h) →0 (h →∞).
Durbin–Levinson algorithm
Let PnXn+1 = a∗
n1Xn + ⋅⋅⋅+ a∗
nnX1. The minimum mean square error is
Un := γ(0) −(a∗
n1γ(n) + ⋅⋅⋅+ a∗
nnγ(1)).

1.2 Prediction of time series
|
9
The coefficients a∗
n1, . . . , a∗
nn can be computed recursively as follows:
a∗
nn = (γ(n) −
n−1
∑
j=1
a∗
n−1,jγ(n −j)) U−1
n−1,
Un = Un−1(1 −(a∗
nn)2),
(
a∗
n1
...
a∗
n,n−1
) = (
a∗
n−1,1
...
a∗
n−1,n−1
) −a∗
nn (
a∗
n−1,n−1
...
a∗
n−1,1
) ,
where a∗
11 = γ(1)/γ(0) and U0 = γ(0).
Now we do not consider stability. For a general time series {Xt}, if both its mean
function μX(t) = E[Xt] and covariance function γX(i, j) = Cov(Xi, Xj) are known, we
may predict Xn+h by 1, X1, . . . , Xn. Similar to the stationary case that the best linear
predictor of Xn+h is
PnXn+h = E[Xn+h] +
n
∑
i=1
ai(Xn+1−i −E[Xn+1−i])
and the coefficient a∗
n = (a∗
1, . . . , a∗
n)T satisfy the following system of linear equations
̃Γna∗
n = ̃Rn(h),
(1.2.4)
where
̃Γ = (Cov(Xn+1−i, Xn+1−j))i,j=1,...,n,
̃Rn(h) = (Cov(Xn+h, Xn), . . . , Cov(Xn+h, X1))T.
The mean square error is
E[(Xn+h −PnXn+h)2] = Var(Xn+h) −a∗T
n Rn(h).
Consider the time series {Xt} satisfying
Xt = 1
2 Xt−1 + Zt,
{Zt} ∼WN(0, 1).
Formula (1.1.3) has given the autocovariance function
γ(h) = 2−h+2
3
.
Suppose that the observations X1 and X3 are known but we miss the observation value
X2. We want to estimate X2 by the linear combination of X1 and X3. Now
̃Γ2 = (Cov(X3, X3)
Cov(X3, X1)
Cov(X1, X3)
Cov(X1, X1)) = (γ(0)
γ(2)
γ(2)
γ(0)) = (
4
3
1
3
1
3
4
3
) ,
̃R2(1) = ( Cov(X2, X3), Cov(X2, X1) )T = (γ(1), γ(1))T = ( 2
3 , 2
3)
T .

10
|
1 Time series analysis
This gives a system of equations
(
4
3
1
3
1
3
4
3
) (a1
a2
) = (
2
3
2
3
)
with solution a1 = a2 = 2
5 . Therefore, the best estimator of X2 is
P(X2 | 1, X1, X3) = E[X2] + 2
5(X3 + X1) = 2
5(X1 + X3).
The minimum mean square error is
E[X | 1, X1, X3] = Var(X2) −(a1, a2) (
2
3
2
3
) = 4
3 −8
15 = 4
5 .
From this example, we see that even if a time series is stationary, to estimate its missing
values we will use (1.2.4) but not use the Durbin–Levinson method.
To avoid solving the system of linear equations (1.2.4) for large n, one gives the
innovation algorithm. It is a simple recurrence algorithm for the best linear prediction,
but allows the time series to not be stationary.
Innovation algorithm
Assume that the mean EXt = 0 (t ∈ℤ+) and the covariance matrix ( hij )n×n is nonsin-
gular, where hij = Cov(Xi, Xj). Then the best linear prediction is
Xo
n+1 =
n
∑
j=1
αnj(Xn+1−j −Xo
n+1−j),
where Xo
n+1 = PnXn+1 (n ∈ℤ+) and Xo
0 = 0, and the coefficients αnj and mean square
errors λn satisfy
λ0 = h11,
λnn = 1
λ0
hn+1,1,
λn,n−k = 1
λk
hn+1,k+1 −1
λk
k−1
∑
j=0
αk,k−jαn,n−jλj
(k = 1, . . . , n −1),
λn = hn+1,n+1 −
n−1
∑
j=0
α2
n,n−jλj,
E[(Xn+1 −PnXn+1)2] = λn.
(1.2.5)
The use of this recursive formula is in the order λ0, α11, λ1, α22, α21, λ2, α33, α32, α31,
λ3, . . . .
For example, consider the time series
Xt = Zt + 1
2 Zt−1,
{Zt} ∼WN(0, 1).

1.2 Prediction of time series
|
11
Note that
hij = E[XiXj] = E[(Zi + 1
2 Zi−1)(Zj + 1
2 Zj−i)],
E[ZiZj] = 0
(i
̸= j),
E[Z2
i ] = 1.
Then
hii = 5
4 ,
hi,i+1 = 1
2 ,
hij = 0
(|i −j| ≥2).
Applying the innovation algorithm gives
αnj = 0
(2 ≤j ≤n),
αn1 =
1
2λn−1
,
λ0 = 5
4 ,
λn = 5
4 −
1
4λn−1
.
So the best linear prediction is
Xo
n+1 =
n
∑
1
αnj(Xn+1−j −Xo
n+1−j) = αn1(Xn −Xo
n).
For the recursive calculation of the h-step predictors, we may use the following
formula:
PnXn+h =
n+h−1
∑
j=h
αn+h−1(Xn+h−j −Xo
n+h−j),
where the coefficients αj are determined as before by the innovation algorithm and
the minimum mean square error is
E[(Xn+h −PnXn+h)2] = K(n + h, n + h) −
n+h−1
∑
j=h
α2
n+h−1Un+h−j−1.
Compare these two algorithms. In the Durbin–Levinson algorithm, the best pre-
diction is represented into a linear combination of Xn, . . . , X1
PnXn+h =
n
∑
j=1
anjXn+1−j,
where {φnj} are given recursively. The Durbin–Levinson algorithm is suited to autore-
gressive process
Xt −a1Xt−1 −⋅⋅⋅−apXt−p = Zt
since φnj = 0 for j < n −p. While in the innovation algorithm, the best prediction is
represented by another linear combination
Xo
n+1 =
n
∑
j=1
αnj(Xn+1−j −Xo
n+1−j).
When Xt is a moving average of order q, αnj = 0 (j < n −q). The innovation algorithm
is suited to moving average process
Xt = Zt + α1Zt−1 + ⋅⋅⋅+ αqZt−q.

12
|
1 Time series analysis
1.2.4 Wold decomposition
In order to introduce the Wold decomposition of a stationary process, we explain con-
cepts of convergence for a sequence of random variables.
Let {Xn}n=0,1,... be a sequence of random variables and X be a random variable.
We say that Xn →X in mean square if limn→∞E[(Xn −X)2] = 0.
Now we consider the prediction of a stationary process in terms of inﬁnitely many
past values. PmnXn+h is the best linear prediction of Xn+h (h > 0) by the linear combi-
nation of 1, Xm, . . . , X0, . . . , Xn. Deﬁne the best prediction based on the inﬁnite past
values {Xt (−∞< t ≤n)} as
̃PnXn+h =
lim
m→−∞PmnXn+h
in the mean square sense. A time series {Xt} is called deterministic if Xn =
̃Pn−1Xn for
all n.
For example, Xt = A cos(ωt) + B sin(ωt), where ω is constant and A, B are uncor-
related random variables with mean 0 and variance σ2. Note that
2 cos ωXn−1 = A(cos(ωt) + cos ω(t −2)) + B(sin(ωt) + sin ω(t −2)) = Xn + Xn−2.
Then
Xn = 2 cos ωXn−1 −Xn−2 =
̃Pn−1Xn
(n ∈ℤ+).
So {Xt} is deterministic.
Wold decomposition
If {Xt} is a nondeterministic stationary time series, then
Xt =
∞
∑
j=0
ψjZt−j + Vt,
{Zt} ∼WN(0, 1),
where ψ0 = 1, ∑∞
j=0 ψ2
j < ∞, {Vt} is deterministic, and Cov(Zt, Vt󸀠) = 0 for all t, t󸀠.
For all causal ARMA processes (see Section 1.4), the deterministic component Vt
is zero in the Wold decomposition, and so
Xt =
∞
∑
j=0
ψjZt−j.
Let {Xt} be a stationary time series with mean 0 and autocovariance function γ(h)
such that γ(k) = 0 (k > q) and γ(q)
̸= 0. Then
Xt =
q
∑
j=0
ψjZt−j,
{Zt} ∼WN(0, 1),
i.e., {Xt} is an MA process of order q, where ψ0 = 1.

1.3 Spectral analysis
|
13
1.3 Spectral analysis
The spectral representation of a stationary time series {Xt} shows that {Xt} can be
decomposed into a sum of sinusoidal components with uncorrelated random coeffi-
cients. Such spectral representation is called spectral analysis.
1.3.1 Spectral density
Suppose that {Xt} is a stationary time series with mean 0 and autocovariance function
γ(h) satisfying ∑h∈ℤ|γ(h)| < ∞. The spectral density of {Xt} is deﬁned as
f(α) = ∑
h∈ℤ
γ(h) e−ihα = γ(0) + 2
∞
∑
1
γ(h) cos(hα).
(1.3.1)
The spectral density f(α) is a nonnegative even function. Using termwise integra-
tion, the autocovariance can be expressed into the following integral:
γ(h) = 1
2π
π
∫
−π
f(α) eihα dα =
π
∫
−π
cos(hα)f(α) dα.
Since f(α) is an even function,
γ(h) = 1
2π
π
∫
−π
f(−α) e−ihα dα = 1
2π
π
∫
−π
f(α) e−ihα dα.
This implies that the autocovariance function γ(h) is Fourier coefficient of the spectral
density f(α).
The deﬁnition of spectral density is generalized as follows. For a stationary time
series {Xt} with autocovariance function γ(h), if f(α) is a 2π-periodic nonnegative
function and γ(h) is its Fourier coefficient, then f(α) is called the spectral density of
{Xt}.
For example, suppose that {Xt} is a stationary time series satisfying
Xt = φXt−1 + Zt,
{Zt} ∼WN(0, 1)
(t ∈ℤ),
where |φ| < 1. By (1.1.3),
γ(h) =
1
1 −φ2 φ|h|.

14
|
1 Time series analysis
So {Xt} has the spectral density
f(α) = ∑
h
e−ihαγ(h) =
1
1 −φ2 ∑
h
φ|h|e−iαh
=
1
1 −φ2 (1 +
∞
∑
h=1
φhe−iαh +
∞
∑
h=1
φheiαh)
=
1
1 −φ2 (1 +
φe−iα
1 −φe−iα +
φeiα
1 −φeiα ) =
1
1 −2φ cos α + φ2 .
For another time series
Xt = Zt + θZt−1,
Zt ∼WN(0, 1)
with mean μ = 0 and autocovariance function
γ(h) =
{
{
{
{
{
{
{
{
{
1 + θ2,
h = 0,
θ,
h = ±1,
0,
|h| > 1,
the spectral density is
f(α) = γ(0) + γ(−1) eiα + γ(1) e−iα = 1 + θ2 + θ(eiα + e−iα) = 1 + 2θ cos α + α2.
1.3.2 Spectral estimation
Consider a stationary time series {Xt} with mean 0 and autocovariance function γ(h).
In applications, we only know ﬁnitely many observations x0, . . . , xN−1. Since
̄x =
1
N ∑N−1
k=0 xk ≈0, the γ(h) is estimated by
̂γ(h) = 1
N
N−1
∑
n=0
xnxn+h.
(1.3.2)
The corresponding spectral density f(α) is estimated by ̂f(α) = ∑k∈ℤ̂γ(k)e−ikα. Denote
x(n) =
{
{
{
xn,
0 < n ≤N −1,
0,
otherwise.
So
̂γ(h) = 1
N ∑n∈ℤx(n + h)x(n)
and the spectral density is estimated by
̂f(α) = ∑h∈ℤ̂γ(h) e−ihα = 1
N ∑n∈ℤx(n) (∑h∈ℤx(n + h) e−ihα)
= 1
N (∑n∈ℤx(n) einα) (∑m∈ℤx(m) e−imα) = 1
N
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
N−1
∑
0
xne−inα
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
2
.

1.3 Spectral analysis
|
15
For each N ∈ℤ+, deﬁne
fN(α) = 1
N E [
[
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
N−1
∑
0
Xne−inα
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
2
]
]
= 1
N E [
N−1
∑
n=0
Xne−inα
N−1
∑
m=0
Xmeimα]
= 1
N ∑|h|<N(N −|h|) e−ihαγ(h).
This implies that
fN(α) →f(α)
(N →∞).
So an asymptotic unbiased estimator of the spectral density f(α) is
1
N E[|u(α)|2],
where u(α) =
N−1
∑
n=0
Xne−inα.
1.3.3 Fourier power spectra
Suppose that {Xt} is a time series. Consider the discrete Fourier transform of X =
{Xk}k=0,...,N−1
ak = 1
N
N−1
∑
0
Xne−in 2πk
N
(k = 0, . . . , N −1).
The inverse discrete Fourier transform is
Xn =
N−1
∑
0
akeik 2πn
N
(n = 0, . . . , N −1).
The Fourier power spectrum of X is deﬁned as |ak|2 in Fourier frequent 2πk
N .
Now we consider a simple model for red noise AR (1)
X0 = 0,
Xn = αXn−1 + Zn
(n ∈ℤ+, 0 < α < 1),
(1.3.3)
which is often used in applications, where {Zn} is a Gaussian white noise
E[Z0] = 0,
Var(Zn) = σ2,
E[ZnZm] = 0
(n
̸= m)
and each Zn is a Gaussian random variable.
Suppose that a red noise model {Xn} satisﬁes (1.3.3) with parameters α and σ2,
and the discrete Fourier transforms of X0, . . . , XN−1 are a0, . . . , aN−1. Then the
Fourier power spectrum |ak|2 in Fourier frequency 2πk
N
satisﬁes the following condi-
tion:
N|ak|2
σ2
is distributed as
1
2(1 −2α cos 2πk
N + α2)
χ2
2,
where χ2
2 is the chi-square distribution with two degrees of freedom.

16
|
1 Time series analysis
1.3.4 Time-invariant linear ﬁlters
Suppose that {Xt} is a time series. We say the time series {Yt} is the output of a time-
invariant linear ﬁlter {ψk} applied to the input {Xt} if
Yt = ∑
k∈ℤ
ψt−kXk = ∑
k∈ℤ
ψkXt−k.
We say the time-invariant ﬁlter {ψk} is causal if ψj = 0 for j < 0. In this case,
Yt =
∞
∑
0
ψkXt−k,
i.e., Yt is represented only by Xl (l ≤t).
Suppose that Xt is a stationary time series with mean 0, autocovariance function
γ and ∑k∈ℤ|ψk| < ∞. Then the time series Yt = ∑k∈ℤψkXt−k is stationary with mean 0
and
(a) its autocovariance function is γY(h) = ∑k∈ℤ∑l∈ℤψkψlγX(h −k + l);
(b) its spectral density is
fY(α) = |ψ(e−α)|2 fX(α),
(1.3.4)
where ψ(e−iα) = ∑k∈ℤψke−ikα.
In fact, from E[Xt] = 0, it follows that E[Yt] = ∑k ψkE[Xt−k] = 0 and
γY(h) = Cov(Yt+h, Yt) = E[Yt+hYt] = E [(∑k∈ℤψkXt+h−k) (∑l∈ℤψlXt−l)]
= ∑
k∈ℤ
∑
l∈ℤ
ψkψlE[Xt+h−kXt−l] = ∑
k∈ℤ
∑
l∈ℤ
ψkψlγX(h −k + l).
(1.3.5)
Therefore, the time series {Yt} is stationary with mean 0. Its autocovariance function
can be expressed as the Fourier coefficient of the spectral density
γX(h −k + l) = 1
2π
π
∫
−π
fX(α) ei(h−k+l)α dα.
From this and (1.3.5), it follows that
γY(h) = 1
2π ∑
k∈ℤ
∑
l∈ℤ
ψkψl
π
∫
−π
fX(α) ei(h−k+l)α dα
= 1
2π
π
∫
−π
(∑k∈ℤψke−ikα) (∑l∈ℤψleilα) fX(α) eihα dα
= 1
2π
π
∫
−π
󵄨󵄨󵄨󵄨󵄨∑k∈ℤψke−ikα󵄨󵄨󵄨󵄨󵄨
2 fX(α) eihα dα.

1.4 Autoregressive moving average models
|
17
Note that
γY(h) = 1
2π
π
∫
−π
fY(α) eihα dα.
Comparing these two formulas, the spectral density of Y is
fY(α) = 󵄨󵄨󵄨󵄨󵄨∑k ψke−ikα󵄨󵄨󵄨󵄨󵄨
2 fX(α).
Let ψk =
1
2m+1 (|k| ≤m) and ψk = 0 (|k| > m), then Yt is a simple moving average
and
Yt =
1
2m + 1
m
∑
−m
ψkXt−k,
ψ(e−iα) =
1
2m + 1
m
∑
−m
e−ikα.
By the sum formula of geometric series,
ψ(e−iα) =
eimα −e−i(m+1)α
(2m + 1)(1 −e−iα) = ei(m+ 1
2 )α −e−i(m+ 1
2 )α
(2m + 1)(ei α
2 −e−i α
2 )
=
sin(m + 1
2)α
(2m + 1) sin α
2
(α
̸= 0),
ψ(e−iα) = 1
(α = 0).
So, by (a) and (b)
γY(h) =
1
(2m + 1)2
m
∑
k=−m
m
∑
l=−m
γX(h −k + l),
fY(α) =
sin2(m + 1
2)α
(2m + 1)2 sin2 α
2
fX(α)
(α
̸= 0),
fY(α) = fX(α),
(α = 0).
1.4 Autoregressive moving average models
Autoregressive moving average (ARMA) models are the most important class of sta-
tionary time series. Here we discuss their basic properties and give Yule–Walker
equations. We also introduce partial autocorrelation function and spectral densities
of ARMA.
1.4.1 ARMA Models
Let {Zt} ∼WN(0, σ2). If {Xt} is stationary and for each t,
Xt −
p
∑
1
φkXt−k = Zt +
q
∑
1
θlZt−l,
(1.4.1)

18
|
1 Time series analysis
where φk, θl are constants, then {Xt} is called an ARMA (p, q) process and (1.4.1) is
called an ARMA equation. If φ1 = ⋅⋅⋅= φp = 0, then {Xt} is called an MA (q) process.
If θ1 = ⋅⋅⋅= θq = 0, then {Xt} is called an AR (p) process.
Let {Xt} be a stationary time series. Deﬁne a time shift operator B as BXt = Xt−1.
So, for any l ∈ℤ+,
BlXt = Xt−l.
Denote
φ(z) = 1 −
p
∑
1
φkzk,
θ(z) = 1 +
q
∑
1
θlzl.
(1.4.2)
They are polynomials of complex variable z of degree ≤p and degree ≤q, respectively.
Assume that φ(z) and θ(z) have no common root. Denote the operator polynomials
φ(B) = 1 −
p
∑
1
φkBk,
θ(B) = 1 +
q
∑
1
θlBl.
Since
φ(B)Xt = Xt −
p
∑
1
φkBkXt = Xt −
p
∑
1
φkXt−k,
θ(B)Zt = Zt +
q
∑
1
θlBlXt = Zt +
q
∑
1
θlXt−l,
the ARMA equation is written into φ(B)Xt = θ(B)Zt. The AR equation is written into
Φ(B)Xt = Zt and the MA equation is written into Xt = θ(B)Zt.
Suppose that the polynomial φ(z) = 1 −∑p
k=1 φkzk
̸= 0 (|z| = 1), where |z| = 1 is
the unit circle. Then ARMA equation (1.4.1) has a unique solution
Xt = ∑
j∈ℤ
ψjzt−j
(t ∈ℤ)
(1.4.3)
in the mean square sense, where the coefficients ψj (j ∈ℤ) are determined by
ψ(z) = θ(z)
φ(z) = ∑
j∈ℤ
ψjzj
(|z| = 1),
(1.4.4)
where θ(z) = 1 + ∑q
l=1 θlzl.
If the unique solution is Xt = ∑∞
j=0 ψjZt−j, then the ARMA (p, q) process is called
causal.
For example, consider ARMA equation
Xt −10
3 Xt−1 + Xt−2 = Zt
or
φ(B)Xt = Zt,

1.4 Autoregressive moving average models
|
19
where φ(z) = 1 −10
3 z + z2 and θ(z) = 1. Since φ(z) = 0 has two roots z = 3 and z = 1
3
and φ(z)
̸= 0 on |z| = 1, the ARMA equation has a unique solution. Note that
ψ(z) =
1
φ(z) = 3
8 (
1
z −3 −
1
z −1
3
) = −1
8
∞
∑
0
( z
3)
j
+ 9
8
−1
∑
−∞
(3z)j
(|z| = 1),
i.e., ψ(z) = ∑j∈ℤψo
j zj, where ψo
j = −1
3j8 (j ≥0) and ψo
j = 3j9
8 (j ≤−1). By (1.4.3), the
solution is
Xt = ∑
j∈ℤ
ψo
j Zt−j.
Generally, the solution is ψ(z) = θ(z)
φ(z) which is a rational function. When φ(z)
̸= 0
(|z| = 1), the function ψ(z) can be expanded into (1.4.4). In fact, if φ(z) has p different
roots α1, . . . , αp, then
ψ(z) =
β1
z −α1
+
β2
z −α2
+ ⋅⋅⋅+
βp
z −αp
+ Q(z),
(1.4.5)
where Q(z) is a polynomial of z and βμ = limz→αμ ψ(z)(z −αμ) (μ = 1, . . . , p). If |αμ| >
1, then
βμ
z−αμ can be expanded into a power series on |z| = 1; if |αμ| < 1, then it can be
expanded into a negative power series. From this and(1.4.5), we get ψ(z) = ∑j∈ℤψjzj
(|z| = 1).
Causal solution
An ARMA (p, q) process is causal if and only if φ(z)
̸= 0 (|z| ≤1), where φ(z) is stated
in (1.4.2).
In fact, if φ(z) = 1 −φ1z −⋅⋅⋅−φpzp
̸= 0 (|z| ≤1), then all roots of φ(z) lie
outside the unit disk. So each fraction
βj
z−αj in (1.4.5) is expanded into a power series.
This implies that
ψ(z) = θ(z)
φ(z) =
∞
∑
0
ψjzj,
i.e., the ARMA (p, q) process is causal. Conversely, it is also true.
Another method for ﬁnding the coefficients {ψj} is as follows.
From ψ(z) = θ(z)
φ(z) , it follows that
(1 −φ1z −⋅⋅⋅−φpzp)(ψ0 + ψ1z + ⋅⋅⋅) = 1 + θ1z + ⋅⋅⋅+ θqzq.
Equating the coefficients of zj (j = 0, 1, . . . ), we get
ψ0 = θ0 + 1,
ψ1 = θ1 + φ1,
ψ2 = θ2 + φ2 + θ1φ1 + φ2
1,

20
|
1 Time series analysis
In general,
ψl = θl +
l
∑
k=1
φkψl−k = θl
(l ∈ℤ+),
where θl = 0 (l > q) and φk = 0 (k > p).
Using the above similar argument, we get the following:
Invertible solution
An ARMA (p, q) process is invertible if and only if θ(z)
̸= 0 (|z| ≤1), where θ(z) is
stated in (1.4.2).
For example, consider an ARMA (1, 1) process
Xt −φXt−1 = Zt + θZt−1
(|φ| < 1, |θ| < 1, φ + θ
̸= 0).
It is clear that for all |z| ≤1,
φ(z) = 1 −φz
̸= 0,
θ(z) = 1 + θz
̸= 0.
Since |φz| < 1 on |z| = 1, the ARMA process is causal. Note that
ψ(z) = 1 + θz
1 −φz = 1 +
∞
∑
1
φj−1(φ + θ)zj.
So ψ0 = 1 and ψj = φj−1(φ + θ) (j = 1, 2, . . . ), and
Xt = Zt + (φ + θ)
∞
∑
1
φj−1Zt−j.
Since |θz| < 1 (|z| = 1), the ARMA process is invertible. Note that
ζ(z) = 1 −φz
1 + θz = (1 −φz)
∞
∑
0
(−1)jθjzj = 1 +
∞
∑
j=1
(−1)jθj−1(φ + θ)zj.
So
Zt = Xt + (φ + θ)
∞
∑
1
(−1)jθj−1Xt−j,
i.e., the ARMA process is invertible.
1.4.2 Yule–Walker equation
The Yule–Walker equation explains the relation between the parameters of an ARMA
process φ1, . . . , φp; θ1, . . . , θq; σ2, and its autocovariance function γ(t).

1.4 Autoregressive moving average models
|
21
Suppose that {Xt} is a causal AR (p) process, Xt −∑p
ν=1 φνXt−ν = Zt. Multiplying
both sides by Xt−k and then taking the mean on both sides,
E[XtXt−k] −
p
∑
1
φνE[Xt−kXt−ν] = E[ZtXt−k].
Since {Xt} is causal, Xt = ∑∞
j=0 ψjZt−j (t ∈ℤ). So, for k = 0, 1, . . . ,
E[ZtXt−k] =
∞
∑
0
ψjE[ZtZt−k−j] = σ2
∞
∑
0
ψjδ0,k+j = σ2
∞
∑
j=k
ψj−kδ0,j =
{
{
{
σ2
(k = 0),
0
(k
̸= 0).
From this and E[XtXt−k] = γ(k), and E[Xt−kXt−ν] = γ(k −ν), it follows that the Yule–
Walker equation
γ(k) −
p
∑
1
φνγ(k −ν) =
{
{
{
σ2
(k = 0),
0
(k
̸= 0).
Its matrix form is
γ(0) −φTγp = σ2,
Γp φ = γp,
where Γp = (γ(i −j))i,j=1,...,p, γp = (γ(1), . . . , γ(p))T, and φ = (φ1, . . . , φp)T.
For example, consider an AR (2) process
Xt −3
4 Xt−1 + 1
8 Xt−2 = Zt,
{Zt} ∼WN(0, 1).
By Yule–Walker equation, the autocovariance function γ(h) satisﬁes
(a) γ(0) −3
4 γ(1) + 1
8 γ(2) = 1,
(b) −3
4 γ(0) + 9
8 γ(1) = 0,
(c) γ(k) −3
4 γ(k −1) + 1
8 γ(k −2) = 0 (k ≥2).
Note that the polynomial φ(z) = 1 −3
4 z + 1
8 z2 has two zero points z1 = 2 and z2 = 4,
the homogeneous linear difference equation (c) has a general solution γ(h) = a12−h +
a24−h (h ≥0), where a1 and a2 are arbitrary constants. Substituting it into (a) and (b),
we get
84a1 + 105a2 = 128,
42a1 + 105a2 = 0.
So a1 = 64
21 and a2 = −128
105 . This implies γ(h) = 128( 2−h
42 −4−h
105) (h ≥0).
More conveniently, take k = 2 in (c). The solution is
γ(0) = 64
35 ,
γ(1) = 128
105 ,
γ(2) = 24
35 ,
and then γ(3), γ(4), . . . can be found from (c) successively. This is an especially con-
venient method for numerical determination of autocovariances γ(h).

22
|
1 Time series analysis
For an AR (p) process, from the ﬁrst p + 1 Yule–Walker equations
γ(0) −
p
∑
1
φνγ(ν) = σ2,
γ(k) −
p
∑
1
φνγ(k −ν) = 0
(k = 1, . . . , p),
we may ﬁnd out γ(0), γ(1), . . . , γ(p) and then ﬁnd out γ(p + 1), γ(p + 2), . . . succes-
sively using equations
γ(k) −
p
∑
1
φνγ(k −ν) = 0
(k = p + 1, . . . ).
More generally, if {Xt} is a causal ARMA process
Xt −
p
∑
1
φkXt−k = Zt +
q
∑
1
θlZt−l,
Xt =
∞
∑
0
ψjZt−j,
the relation between φk, θl, σ2 and γ(t) is given by using a similar method as follows:
γ(k) −
p
∑
1
φνγ(k −ν) = σ2
q
∑
j=k
θjψj−k
(0 ≤k < m),
(1.4.6)
γ(k) −
p
∑
1
φνγ(k −ν) = 0
(k ≥m),
(1.4.7)
where m = max{ p, q + 1 } and θj = 0 (j ≥q + 1).
The homogeneous linear difference equation (1.4.7) with constant coefficients has
a solution
γ(h) =
p
∑
1
alξ−h
l
(h ≥m −p),
(1.4.8)
where a1, . . . , ap are arbitrary constants and ξ1, . . . , ξp are different roots of the
polynomials
φ(z) = 1 −
p
∑
k=1
φkzk.
In fact, substituting γ(h) = ξ−h
l
(l = 1, . . . , p; h > m −p) into the left-hand side of
the equation (1.4.7),
γ(k) −
p
∑
1
φνγ(k −ν) = ξ−k
l
(1 −∑
p
1 φνξ ν
l ) = ξ−k
l φ(ξl) = 0

1.4 Autoregressive moving average models
|
23
since ξl is a root of φ(z). Note that (1.4.7) is a homogeneous linear difference equation.
The linear combination (1.4.8) of ξ−h
1 , . . . , ξ−h
p
is the general solution of (1.4.7). Sub-
stituting (1.4.8) into (1.4.7), we obtain a system of m linear equations that determine
the constants a1, . . . , ap and autocovariances γ(0), . . . , γ(m −p −1).
For example, consider the ARMA (1, 1) process
Xt −φXt−1 = Zt + θZt−1
(|φ| < 1),
{Zt} ∼WN(0, σ2).
Since |φ| < 1, it has a causal solution
Xt = 1 +
∞
∑
1
ψnZt−n,
where ψn = (φ + θ)φn−1 (n ≥1). By (1.4.7) and (1.4.8), we get
γ(0) −φγ(1) = σ2(1 + (φ + θ)θ),
γ(1) −φγ(0) = σ2θ.
By (1.4.7), the homogeneous equation
γ(k) −φγ(k −1) = 0
(k ≥2)
has the solution γ(h) = aφh (h ≥1). Substituting this solution into the above equa-
tions, we get
γ(0) −aφ2 = σ2(1 + θ(φ + θ)),
−φγ(0) + aφ = σ2θ.
Their solution is
a = (φ + θ)(1 + φθ)
φ(1 −φ2)
σ2,
γ(0) = (1 + (φ + θ)2
1 −φ2 ) σ2.
(1.4.9)
So
γ(h) = aφh = (φ + θ)(1 + φθ)
1 −φ2
φh−1σ2
(h ≥1).
(1.4.10)
1.4.3 Partial autocorrelation function and spectral densities
Suppose that {Xt} is a stationary time series with mean 0 and autocorrelation function
γ(t). Denote the matrix Γh = (γ(i −j))i,j=1,...,h and the vector γh = (γ(1), . . . , γ(h))T.
Let
Φh = Γ−1
h γh,
Φh = (Φi1, . . . , Φhh)T.

24
|
1 Time series analysis
The partial autocorrelation function β(h) is deﬁned as
β(0) = 1,
β(h) = Φhh
(h ≥1).
Consider the MA (1) process
Xt = Zt + θZt−1,
{Zt} ∼WN(0, σ2).
By γ(0) = (1 + θ2)σ2 and γ(1) = θσ2, it follows that
Φ1 = Γ−1
1 γ1 = γ(1)
γ(0) =
θ
1 + θ2 .
So β(1) = Φ11 =
θ
1+θ2 .
By γ(0) = (1 + θ2)σ2, γ(1) = θσ2, and γ(2) = 0, it follows that
Φ2 = Γ−1
2 γ2 = (γ(0)
γ(1)
γ(1)
γ(0))
−1
(γ(1)
γ(2))
=
1
γ2(0) −γ2(1) ( γ(0)
−γ(1)
−γ(1)
γ(0) ) (γ(1)
0 )
=
1
γ2(0) −γ2(1) (γ(1)γ(0)
−γ2(1) ) .
So β(2) = Φ22 =
−γ2(1)
γ2(0)−γ2(1) =
−θ2
1+θ2+θ4 .
By γ(0) = (1 + θ2)σ2, γ(1) = θσ2, γ(2) = γ(3) = 0, and
Γ3 = (
γ(0)
γ(1)
0
γ(1)
γ(0)
γ(1)
0
γ(1)
γ(0)
) ,
and γ3 = (γ(1), 0, 0)T, it follows that
Γ−1
3
= (γ3(0) −2γ2(1)γ(0))−1 (
γ2(0) −γ2(1)
−γ(0)γ(1)
γ2(1)
−γ(0)γ(1)
γ2(0)
−γ(0)γ(1)
γ2(1)
−γ(0)γ(1)
γ2(0) −γ2(1)
) ,
Φ3 = Γ−1
3 γ3 =
γ(1)
γ3(0) −2γ2(1)γ(0) (
γ2(0) −γ2(1)
−γ(0)γ(1)
γ2(1)
) .
So β(3) = Φ33 =
γ3(1)
γ3(0)−2γ2(1)γ(0) =
θ3
1+θ2+θ4+θ6 .
In general,
β(h) = Φhh =
(−1)h+1θh
1 + θ2 + ⋅⋅⋅+ θ2h
(h ≥1).

1.4 Autoregressive moving average models
|
25
Consider the AR (p) process
Xt −φ1Xt−1 −⋅⋅⋅−φpXt−p = Zt,
{Zt} ∼WN(0, σ2).
The Yule–Walker equation is φ = Γ−1
p γp, where
φ = (φ1, . . . , φp),
Γp = ( γ(i −j) )i,j=1,...,p,
γp = (γ1, . . . , γp)T.
Comparing it with the deﬁnition of the partial autocorrelation function,
Φp = φ,
β(p) = Φpp = φp,
β(h) = 0
(h > p).
For h < p, β(h) can easily be computed by the deﬁnition.
Now we turn to introducing the spectral density.
Suppose that {Xt} is a causal ARMA (p, q) process
φ(B)Xt = θ(B)Zt,
{Zt} ∼WN(0, σ2).
So
Xt =
∞
∑
0
ψjZt−j,
φ(z)
̸= 0
(|z| ≤1),
where {ψj} satisfy ψ(z) = θ(z)
φ(z) = ∑∞
0 ψjzj and ∑∞
0 |ψj| < ∞. By (1.3.4), the spectral
density is
fX(α) = |ψ(eiα)|2fZ(α) =
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
θ(eiα)
φ(eiα)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
2
fZ(α).
However, for white noise {Zt},
E[Zt] = 0,
γ(0) = E[Z2
t ] = σ2,
γ(α) = E[Zt+|α|Zt] = 0
(α ∈ℤ+),
and its spectral density is
fZ(α) = ∑
h
γ(h) e−ihα = γ(0) = σ2.
Thus the spectral density of the causal ARMA (p, q) process {Xt} is
fX(α) = σ2 |θ(eiα)|2
|φ(e−iα)|2 .

26
|
1 Time series analysis
For example, in the causal ARMA (1, 2) process
Xt −φ1Xt−1 = Zt + θ1zt−1 + θ2zt−2,
where
θ(z) = 1 + θ1z + θ2z2,
φ(z) = 1 −φ1z.
So the spectral density of the causal ARMA (1, 2) process is
fX(α) = σ2 |θ(eiα)|2
|φ(e−iα)|2 = σ2 1 + θ2
1 −2θ2 + θ2
2 + 2(θ1θ2 + θ1) cos α + 4θ2 cos2 α
1 + φ2
1 −2φ1 cos α
.
1.5 Prediction and modeling of ARMA processes
The innovation algorithm of the linear prediction of time series has been discussed
in Section 1.2. For ARMA processes, one can simplify the innovation algorithm. Based
on an observed stationary time series, one can determine an appropriate ARMA model
ﬁtting it.
1.5.1 Prediction
For a causal ARMA process
Xt −φ1Xt−1 −⋅⋅⋅−φpXt−p = Zt + θ1Zt−1 + ⋅⋅⋅+ θqZt−q,
{Zt} ∼WN(0, σ2),
we use the innovation algorithm to predict Xo
n+1 from Xn+1.
To simplify the algorithm, let m = max{ p, q } and
St = σ−1Xt
(t = 1, . . . , m),
St = σ−1(Xt −φ1Xt−1 −⋅⋅⋅−φpXt−p)
(t > m).
(1.5.1)
The autocovariances hij = E[SiSj]. A direct computation shows that for 1 ≤i, j ≤m,
since {Xt} is stationary,
hij = σ−2E[XiXj] = σ−2γ(i −j),
where γ is autocovariance function of {Xt} which can be calculated as in Section 1.4.2.
For 1 ≤i ≤m and m ≤j ≤2m,
hij = σ−2E[Xi(Xj −φ1Xj−1 −⋅⋅⋅−φpXj−p)]
= σ−2(γ(j −i) −φ1γ(j −1 −i) −⋅⋅⋅−φpγ(j −p −i)).

1.5 Prediction and modeling of ARMA processes
|
27
For 1 ≤i ≤m and j > 2m, hij = 0.
For 1 ≤j ≤m and m < i ≤2m, hij = σ−2(γ(i −j) −φ1γ(i −1 −j) −⋅⋅⋅−φpγ(i −p −j)).
For 1 ≤j ≤m and i > 2m, hij = 0.
For i > m and j > m,
hij = σ−2E[(Xi −φ1Xi−1 −⋅⋅⋅−φpXi−p)(Xj −φ1Xj−1 −⋅⋅⋅−φpXj−p)]
= σ−2E[(Zi −θ1Zi−1 + ⋅⋅⋅+ θqZi−q)(Zj + θ1Zj−1 + ⋅⋅⋅+ θqZj−q)].
By the autocovariance function formula (1.1.1) of a linear process,
hij =
{
{
{
θ0θj−i + θ1θ1+j−i + ⋅⋅⋅+ θqθq+j−i
(j > i),
θ0θi−j + θ1θ1+i−j + ⋅⋅⋅+ θqθq+i−j
(i > j),
where θ0 = 1. Therefore, the autocovariances {hij} are as follows:
hij =
{
{
{
{
{
{
{
{
{
{
{
{
{
σ−2γ(i −j)
(1 ≤i, j ≤m),
σ−2 (γ(i −j) −∑p
l=1 φlγ(l −|i −j|))
(min{ i, j } ≤m < max{ i, j } ≤2m),
∑q
l=0 θlθl+|i−j|
(min{ i, j } > m),
0,
otherwise.
(1.5.2)
By using the innovation algorithm to {St}, the best linear predictor of Sn+1 in terms of
{1, S1, . . . , Sn} is
So
n+1 =
{
{
{
∑n
1 αnj(Sn+1−j −So
n+1−j)
(1 ≤n < m),
∑q
1 αnj(Sn+1−j −So
n+1−j)
(n ≥m),
(1.5.3)
where the coefficients {αnj} are found from recurrence formula (1.2.5) in the innovation
algorithm.
Denote by Xo
k the best linear predictor of Xk in terms of { 1, X1, . . . , Xk−1 }. Notic-
ing that the linearity of prediction operator, by (1.5.1), we get
So
k =
{
{
{
σ−1Xo
k
(k = 1, . . . , m),
σ−1(Xo
k −φ1Xk−1 −⋅⋅⋅−φpXk−p)
(k > m),
Sk −So
k = σ−1(Xk −Xo
k)
(k ∈ℤ+).
From this and (1.5.3), it follows that
Xo
n+1 =
{
{
{
∑n
j=1 αnj(Xn+1−j −Xo
n+1−j)
(1 ≤n < m),
φ1Xn + ⋅⋅⋅+ φpXn+1−p + ∑q
j=1 αnj(Xn+1−j −Xo
n+1−j)
(n ≥m),
(1.5.4)
and the mean squared errors
Vn+1 = E[(Xn+1 −Xo
n+1)2] = σ2(Sn+1 −So
n+1)2 = σ2λn,
(1.5.5)

28
|
1 Time series analysis
where αnj and λn are obtained from the innovation algorithm with hij which are stated
in (1.5.2).
Especially, the predictions of the AR (p) and MA (q) processes are easier. By
(1.5.4), the prediction of the AR (p) process is
Xo
n+1 = φ1Xn + ⋅⋅⋅+ φpXn+1−p
(n ≥p)
and the prediction of the MA (q) process is
Xo
n+1 =
min{ p,q }
∑
j=1
αnj(Xn+1−j −Xo
n+1−j)
(n ≥1),
where αnj = σ−2γ(n −j) = ∑q−|n−j|
l=0
θlθl+|n−j|.
In general, the algorithm of the best linear prediction for an ARMA (p, q) process
is as follows.
Step 1. Use the method given in Section 1.4.2 to compute the autocovariance func-
tion γ.
Step 2. Compute {hij}i,j∈ℤby (1.5.2).
Step 3. Use the recurrence formula of the innovation algorithm to ﬁnd αnj and λn by
(1.2.5).
Step 4. The predictor Xo
n+1 and the mean squared error are given by the formulas
(1.5.4) and (1.5.5).
For example, consider the prediction of an ARMA (1, 1) process
Xt −φXt−1 = Zt + θZt−1,
{Zt} ∼WN(0, σ),
where |φ| < 1. Now m = p = q = 1. Let
St = σ−1Xt
(t = 1),
St = σ−1(Xt −φXt−1)
(t > 1).
By (1.5.2) and hij = E[SiSj], we get
h11 = σ−2γ(0) = 1 + (φ + θ)2
1 −φ2
(by (1.4.9)),
h12 = h21 = σ−2(γ(1) −φγ(0)) = θ
(by (1.4.10)),
hi+1,i = hi,i+1 = θ0θ1 + θ1θ2 = θ0θ1 = θ
(i > 1),
hii = θ2
0 + θ2
1 = 1 + θ2
(i ≥2),
hij = θ0θ|i−j| + θ1θ1+|i−j| = 0
otherwise.
By (1.5.4), the best linear predictor of Xn+1 is
Xo
n+1 = φXn + αn1(Xn −Xo
n)
(n ≥1).

1.5 Prediction and modeling of ARMA processes
|
29
By the recurrence formula of the innovation algorithm, successively compute λ0, α11,
λ1, α22, α21, λ2, α33, α32, α31, … as follows:
λ0 = h11 = 1 + φ + θ
1 −φ2 ,
α11 = h21
λ0
= θ
λ0
,
λ1 = h22 −α2
11λ0 = 1 + θ2 −θ2
λ0
,
α22 = h31
λ0
= 0,
α21 = h32 −α11α22λ0
λ1
= θ
λ1
,
λ2 = 1 + θ2 −θ2
λ1
,
α33 = h41
λ0
= 0,
α32 = h42 −α11α33
λ1
= 0,
α31 = h43
λ2
= θ
λ2
,
...
αn1 =
θ
λn−1
.
So the best linear predictor of Xn+1 satisﬁes
Xo
n+1 = φXn +
θ
λn−1
(Xn −Xo
n)
(n ≥1),
where
λn = 1 + θ2 −θ2/λn−1
(n ≥1),
λ0 = 1 + (φ + θ)/(1 −φ2),
and the mean squared error satisﬁes
E[(Xn+1 −Xo
n+1)2] = σ2λn.
Now we consider the h-step prediction of an ARMA (p, q) process {Xt}.
Denote by PnXn+h the best linear predictor of Xn+h in terms of 1, X1, . . . , Xn. For
n > m = max{ p, q }, we ﬁnd predictors Xo
1, . . . , Xo
n and then ﬁnd recursively predictors
PnXn+1, PnXn+2, . . . using the formula
PnXn+h =
p
∑
l=1
φlPnXn+h−l +
q
∑
l=h
αn+h−1,l(Xn+h−l −Xo
n+h−l)
(h ≥1)
and the mean squared error is
E[(Xn+h −PnXn+h)2] = σ2
h−1
∑
l=0
(
l
∑
k=0
χkαn+h−k−1,l−k)
2
λn+h−j−1,
where
χk =
min{ p,k }
∑
ν=1
φνχk−ν
(χ0 = 1).
If {Xt} is a causal ARMA (p, q) process with Gaussian white noise
Zt ∼WN(0, σ2),
Zt ∼N(0, σ2),

30
|
1 Time series analysis
then the prediction error is
E[(Xn+h −PnXn+h)2] = σ2
h−1
∑
l=0
ψ2
l ,
where ψl (l = 0, 1, . . . ) satisﬁes θ(z)/φ(z) = ∑∞
l=0 ψlzl.
1.5.2 Modeling
We will estimate the coefficients φ1, . . . , φp, θ1, . . . , θq and the white noise variance
σ2 such that the autocovariance γX of the corresponding ARMA process approximates
to the autocovariance function γ of the observation time series.
(a) The ﬁtted AR model
From a causal AR (p) process
Xt −
p
∑
k=1
φkXt−k = Zt,
the Yule–Walker equation given in Section 1.4.2 is as follows:
γ(0) −ΦTγp = σ2,
ΓpΦ = γp,
where
Γp = (γ(i −j))i,j=1,...,p,
γp = (γ(1), . . . , γ(p))T,
Φ = (φ1, . . . , φp)T.
In applications, we only know ﬁnitely many observations x0, . . . , xN−1. Since
̄x =
1
n ∑N−1
k=0 xk ≈0, the γ(h) is estimated by
̂γ(h) = 1
N
N−1
∑
0
xnxn+h.
In the Yule–Walker equation, replacing γ(ν) by the sample covariance
̂γ(ν), Φ =
(φ1, . . . , φp)T by its estimator
̂Φ = ( ̂φ1, . . . ,
̂φp)T, and σ by its estimator
̂σ, we get
̂σ2 =
̂γ(0) −
̂ΦT ̂γp,
̂Γp ̂Φ =
̂γp.
(1.5.6)
This is the Yule–Walker equation of estimators, where
̂Γp = ( ̂γ(i −j))i,j=1,...,p,
̂γp = ( ̂γ(1), . . . , ̂γ(p))T.
(1.5.7)

1.5 Prediction and modeling of ARMA processes
|
31
If
̂γ(0) > 0, then
̂Γp is nonsingular. From this and (1.5.6),
̂Φ = ( ̂φ1, . . . ,
̂φp)T =
̂Γ−1
p
̂γp.
Clearly, 1 −
̂φ1z −⋅⋅⋅−
̂φpzp
̸= 0 (|z| ≤1). So the ﬁtted model
Xt −
̂φ1Xt−1 −⋅⋅⋅−
̂φpXt−p = Zt,
{Zt} ∼WN(0, ̂σ2)
(1.5.8)
is a causal AR (p) process. Therefore, its autocovariance function γF(h) satisﬁes the
Yule–Walker equation
γF(h) −
̂φ1γF(h −1) −⋅⋅⋅−
̂φpγF(h −p) =
{
{
{
0
(h = 1, . . . , p),
̂σ2
(h = 0).
(1.5.9)
Comparing this and (1.5.6),
γF(h) =
̂γ(h)
(h = 0, . . . , p).
From this, it is seen that the autocovariances of the ﬁtted model (1.5.8) at lags 0, 1,
. . . , p coincide with the sample autocovariances.
For a causal AR (p) process {Xt}
Xt −
p
∑
1
φkXt−k = Zt,
{Zt} ∼WN(0, σ2),
the large-sample distribution of Yule–Walker estimator is
̂Φ = ( ̂φ1, . . . ,
̂φp)T =
̂Γ−1
p
̂γp
and the distribution is
̂Φ ≈N(Φ, n−1σ2Γ−1
p ), where Φ = (φ1, . . . , φp)T.
How do we select the order p? The partial autocorrelation function (PACF) is given
in Section 1.4.3. The sample PACF is deﬁned as
̂β(0) = 1,
̂β(m) =
̂Φmm
(m ∈ℤ+),
where
̂Φmm is the last component of
̂Φm = ̂Γ−1
m
̂γm. If the sample PACF ̂β(m) (0 ≤m ≤p)
is signiﬁcantly different from zero and
̂β(m) ≈0 (m > p). Precisely speaking, if
̂β(m) > 1.96n−1
2
(0 ≤m ≤p),
̂β(m) < 1.96n−1
2
(m > p),
then a p-order AR model can ﬁt the observation data.

32
|
1 Time series analysis
(b) The ﬁtted MA model
Given the observed data {x1, . . . , xn}, denote by ̂γ(h) its sample autocovariance func-
tion. The sample covariance matrix is ( ̂γ(i −j))i,j=1,...,n. We can ﬁt moving average
models
Xt = Zt + ̂αm1Zt−1 + ⋅⋅⋅+ ̂αmmZt−m
(m ∈ℤ+),
{Zt} ∼WN(0,
̂Vm)
(m ∈ℤ+),
and
̂αm1, . . . , ̂αmm,
̂Vm are obtained by using the innovation algorithm with the au-
tocovariance function matrix (γ(i −j))i,j=1,...,n replaced by the sample autocovariance
function matrix ( ̂γ(i −j))i,j=1,...,n. Since we know that for a zero-mean stationary pro-
cess, if its autocovariance function (ACVF) γ(h) = 0 for h > q, then this process can
be represented as a moving average process of order q or less. Therefore, if its sam-
ple ACVF
̂γ(h) satisﬁes the condition that
̂γ(h) is signiﬁcantly different from zero for
0 ≤h ≤q and
̂γ(h) ≈0 for h > q, precisely speaking, if
̂γ(h) > 1.96n−1
2
(0 ≤h ≤q),
̂γ(h) < 1.96n−1
2
(h > q),
then a q-order MA model can ﬁt the observation data.
(c) The ﬁtted ARMA model
We use m-order Yule–Walker estimates
Xt −
̂φm1Xt−1 −⋅⋅⋅−
̂φmmXt−m = Zt,
{Zt} ∼WN(0, ̂σm)
to ﬁt observed data {x1, . . . , xn}, where m > max{ p, q }. Then the Hannam–Rissanen
algorithm is divided into three steps.
Step 1. Let
̂Zt = Xt −
̂φm1Xt−1 −⋅⋅⋅−
̂φmmXt−m (t = m + 1, . . . , n).
Step 2. Choose β = (φ1, . . . , φp, θ1, . . . , θq) such that the following sum of squares
S(β) =
n
∑
t=m+1+q
(Xt −φ1Xt−1 −⋅⋅⋅−φpXt−p −θ1 ̂Zt−1 −⋅⋅⋅−θq ̂Zt−q)2
attains the minimal value. Let
̂β = (HTH)−1HTXn, where Xn = (Xm+1+q, . . . , Xn)T
and H = (H1|H2), and
H1 = (
Xm+q
Xm+q−1
⋅⋅⋅
Xm+q+1−p
Xm+q+1
Xm+q
⋅⋅⋅
Xm+q+2−p
...
...
⋅⋅⋅
...
Xn−1
Xn−2
⋅⋅⋅
Xn−p
) ,

1.5 Prediction and modeling of ARMA processes
|
33
H2 = (
̂Zm+q
̂Zm+q−1
⋅⋅⋅
̂Zm+1
̂Zm+q+1
̂Zm+q
⋅⋅⋅
̂Zm+2
...
...
⋅⋅⋅
...
̂Zn−1
̂Zn−2
⋅⋅⋅
̂Zn−p
) .
It can be shown that
̂β = ( ̂φ1, . . . ,
̂φp, ̂θ1, . . . , ̂θq) such that S( ̂β) attains the min-
imal value.
Step 3. For t ≤max{ p, q }, let
̃Zt = 0, Vt = 0, and Wt = 0. For max{ p, q } < t ≤n, let
̃Zt = Xt −
p
∑
1
̂φjXt−j −
q
∑
1
̂θj ̃Zt−j,
Vt =
p
∑
1
̂φjVt−j +
̃Zt,
Wt = −
p
∑
1
̂θjWt−j +
̃Zt.
Take β =
̂β+ such that
S+(β) =
n
∑
t=max{ p,q }+1
( ̃Zt −
p
∑
1
βjVt−j −
q
∑
1
βk+pWt−k)
2
attains the minimal value. The ̃β = ̂β+ + ̂β is a good estimator. Let ̃β = ( ̃φ1, . . . , ̃φp,
̃θ1, . . . , ̃θq). Then the ARMA (p, q) process
Xt −
̃φ1Xt−1 −⋅⋅⋅−
̃φpXt−p = Zt + ̃θ1Zt−1 + ⋅⋅⋅+ ̃θqZt−q.
can ﬁt the observed data.
(d) Maximum likelihood estimation
Suppose that {Xt} is a zero-mean Gaussian time series and the covariance matrix Γn
of X1, . . . , Xn is nonsingular. The likelihood of Xn is
L(Γn) = (2π)−n
2 (det Γn)−1
2 exp (−1
2 XT
nΓ−1
n Xn) .
It can be rewritten in the form
L(Γn) = ((2π)nV0 ⋅⋅⋅Vn−1)−1
2 exp (−1
2
n
∑
1
(Xj −Xo
j )2
Vj−1
) ,
(1.5.10)
where Xo
j is the best linear prediction in terms of Xj−1, . . . , X1 and Vj is the corre-
sponding mean squared error. If {Xt} is not Gaussian, we always say (1.5.10) is the
Gaussian likelihood of X1, . . . , Xn.

34
|
1 Time series analysis
Suppose that data {Xt} are from an ARMA (p, q) process. The one-step predictors
Xo
n+1 and the mean squared errors Vn+1 are stated in (1.5.4) and (1.5.5). Therefore, Xo
j
are the functions of φ1, . . . , φp, θ1, . . . , θq and the Gaussian likelihood for an ARMA
process is
L(φ, θ, σ2) = ((2πσ2)nλ0 ⋅⋅⋅λn−1)−1
2 exp (−1
2σ2
n
∑
1
(Xj −Xo
j )2
λj−1
) ,
where φ = (φ1, . . . , φp) and θ = (θ1, . . . , θq). Note that
∂
∂σ2 log(φ, θ, σ2) = −n
2σ2 +
1
2σ4
n
∑
1
(Xj −Xo
j )2
λj−1
.
Then L(φ, θ, σ2) attains the minimal value when σ2 =
̂σ2 = 1
n ∑n
j=1
(Xj−Xo
j )2
λj−1
. Denote
H(φ, θ) =
n
∑
1
(Xj −Xo
j )2
λj−1
.
Take φ =
̂φ and θ =
̂θ such that
l(φ, θ) = log H(φ, θ)
n
+ 1
n
n
∑
1
log λj−1
attains the minimal value and the estimate of σ2 is
̂σ2 =
1
n −p −q H( ̂φ, ̂θ).
In this way, for an ARMA (p, q) process, we can give the estimators of parameters
̂φ1, . . . ,
̂φp, ̂θ1, . . . , ̂θq and
̂σ2. The ﬁtted ARMA (p, q) model is
Xt −
̂φ1Xt−1 −⋅⋅⋅−
̂φpXt−p = Zt + ̂θ1Zt−1 + ⋅⋅⋅+ ̂θqZt−q,
{Zt} ∼WN(0, ̂σ2).
The selection of the orders p and q for general ARMA models is done by using the
AICC statistic
AICC = −2L (φp, θq, H(φp, θq)
n
) + 2(p + q + 1)n
n −p −q −2 .
Choose p, q, φp, θq such that AICC attains the minimal value.
1.6 Multivariate ARMA processes
Consider the k-dimensional time series Yt = (Yt1, . . . , Ytk)T. The purpose of multi-
variate time series analysis is to understand the relationship among the component

1.6 Multivariate ARMA processes
|
35
time series. If Yt has a constant mean vector μ = (μ1, . . . , μk)T for all t and its cross-
covariance matrix R(Yt, YT
t+l) = Γ(l) only depends on l, then the k-dimensional time
series Yt is called a stationary vector process, where R(Yt, YT
t+l) = (E[YtiYt+l,j])i,j=1,...,k
and each E[YtiYt+l,j] is independent of t. Denote
γij(l) = E[YtiYt+l,j],
Γ(l) = (γij(l))i,j=1,...,k.
If {Yt} is a k-dimensional zero-mean stationary vector process and
Yt −
p
∑
1
ΦjYt−j = Zt +
q
∑
1
ΘjZt−j,
(1.6.1)
then Yt is called a vector ARMA process, where Φj, Θj are both k × k matrixes inde-
pendent of t and Zt is a k-dimensional white noise satisfying
E[Zt] = 0,
E[ZtZT
t ] = Σ,
E[ZtZT
t+l] = 0
(l
̸= 0).
(1.6.2)
Here Σ is a k × k constant matrix. Denote {Zt} ∼WN(0, Σ). Especially, if Φj = 0 (j =
1, . . . , p), then Yt is called a vector MA process. If Θj = 0 (j = 1, . . . , q), then Yt is
called a vector AR process.
Introduce two matrix-valued polynomials
Φ(z) = I −Φ1z −⋅⋅⋅−Φpzp,
Θ(z) = I + Θ1z + ⋅⋅⋅+ Θqzq,
where I is the k × k identity matrix, z is a complex variable, and each component
of matrices Φ(z), Θ(z) is a polynomial of degree p and q with matrix coefficients,
respectively. Denote
Φj = (φ(j)
mn)k×k
(j = 0, 1, . . . , p),
Φ0 = I,
Θj = (θ(j)
mn)k×k
(j = 0, 1, . . . , q),
Θ0 = I.
Then
Φ(z) = (
p
∑
j=0
φ(j)
mnzj)
k×k
Θ(z) = (
q
∑
j=0
θ(j)
mnzj)
k×k
Let B be backward shift operator. Then
BYt = Yt−1,
BjYt = Yt−j,
and so
Φ(B)Yt = (I −Φ1B −⋅⋅⋅−ΦpBp)Yt = Yt −Φ1Yt−1 −⋅⋅⋅−ΦpYt−p,
Θ(B)Zt = (I + Θ1B + ⋅⋅⋅+ ΘpBp)Zt = Zt + Θ1Zt−1 + ⋅⋅⋅+ ΘqZt−p.
Equation (1.6.1) can be rewritten in the form Φ(B)Yt = Θ(B)Zt, where {Zt} ∼WN(0, Σ).

36
|
1 Time series analysis
1.6.1 Vector MA processes
Let Yt be an MA (q) process
Yt = Zt +
q
∑
1
ΘjZt−j = Θ(B)Zt.
If the determinant of the matrix Θ(z) satisﬁes det Θ(z)
̸= 0 (|z| ≤1), then the inverse
matrix Θ−1(z) exists on |z| ≤1 and
Θ−1(z) = (det Θ(z))−1Θ∗(z)
(|z| ≤1),
where Θ∗(z) is the associated matrix of Θ(z). Both each component hij(z) of Θ∗(z) and
det Θ(z) are polynomials of z and det Θ(z)
̸= 0 (|z| ≤1). Therefore, hij(z)/det Θ(z) can
be expanded into a power series and Θ−1(z) can be expanded into the power series
with matrix coefficients Θ−1(z) = ∑∞
j=0 πjzj (|z| ≤1). It is easy to show that π0 = I.
Replacing z by B,
Θ−1(B) = I +
∞
∑
1
πjBj
since ‖B‖ = 1. From this and (1.6.3), it follows that
Zt = Θ−1(B)Yt = Yt +
∞
∑
j=1
πjYt−j.
For a vector MA process, the cross-covariance matrix Γ(l) is equal to
Γ(l) = Cov(Yt, Yt+l) = E[YtYT
t+l] = E [
[
(Zt −
q
∑
1
ΘjZt−j) (Zt+l −
q
∑
1
ΘjZt+l−j)
T
]
]
= E [
[
(
q
∑
0
ΘjZt−j) (
q
∑
0
ΘjZt+l−j)
T
]
]
=
q
∑
k=0
q
∑
j=0
ΘjE[Zt−jZT
t+l−k]ΘT
k,
where Θ0 = I. Again, by (1.6.2) and Θj = 0 (k > q),
E[Zt−jZT
t+l−k] = δj,k−lΣ,
and so
Γ(l) =
q−l
∑
0
ΘkΣΘT
k+l
(l = 0, 1, . . . , q).
Conversely, if the cross-covariance matrix is known, the MA coefficients Θk and Σ can
be found by this formula.
For example, consider a bivariate MA (1) model Yt = Zt + Θ1Zt−1, where
Yt = (Y1t, Y2t)T,
Θ1 = (α11
α12
α21
α22
) .

1.6 Multivariate ARMA processes
|
37
Let Zt = (Z1t, Z2t)T and Yt = Θ(B)Zt, and
Θ(B) = I + Θ1B = (1 + α11B
α12B
α21B
1 + α22B) .
Then
det(Θ(B)) = (1 + α11B)(1 + α22B) −α12α21B2.
(1.6.3)
The inverse matrix
Θ−1(B) =
1
det(Θ(B)) (1 + α22B
−α12B
−α21B
1 + α11B) .
This implies Θ−1(B)Yt = Zt, and so
(1 + α22B
−α12B
−α21B
1 + α11B) Yt = Zt det(Θ(B))
or
(1 + α22B)Y1t = α12BY2t + det(Θ(B))Z1t,
(1 + α11B)Y2t = α21BY1t + det(Θ(B))Z2t.
Its solution is
Y1t = α12B(1 + α22B)−1Y2t + det(Θ(B))(1 + α22B)−1Z1t,
Y2t = α21B(1 + α11B)−1Y1t + det(Θ(B))(1 + α11B)−1Z2t.
Such structure is called a joint transfer function structure. For convenience, assume
that α12 = 0. Then by (1.6.3) these equations can be rewritten in the form
Y1t = det(Θ(B))(1 + α22B)−1Z1t = (1 + α11B)Z1t,
Y2t = a21B(1 + α11B)−1Y1t + (1 + α22B)Z2t.
(1.6.4)
Even if α12
̸= 0, the equations of a form similar to (1.6.4) could still be arrived at. From
this it is seen that future values of the process Y2t depend on the past of both Y1t and
Y2t, whereas future values of Y1t only depend on its own past and not on the past of
Y2t. In applications, the equations (1.6.4) often represent the model structure of most
interest.
1.6.2 Vector AR processes
Let Yt be an AR (p) process
Yt −
p
∑
1
ΦjYt−j = Zt
or
Φ(B)Yt = Zt,
(1.6.5)

38
|
1 Time series analysis
where Φ(z) = I −Φ1z −⋅⋅⋅−Φpzp. If the determinant of Φ(z) satisﬁes det(Φ(z))
̸= 0
(|z| ≤1), then the inverse matrix Φ−1(z) exists and can be expanded into a power
series with matrix coefficients
Φ−1(z) =
∞
∑
0
Ψjzj
(|z| ≤1).
Since Yt is stationary and ‖B‖ = 1,
Φ−1(B) =
∞
∑
j=0
ΨjBj.
From this and (1.6.5),
Yt = Φ−1(B)Zt =
∞
∑
0
ΨjBj(Zt) =
∞
∑
0
ΨjZt−j,
Ψ0 = I.
Especially, for AR (1) model
Yt = ΦYt−1 + Zt,
(1.6.6)
the condition det(Φ(z)) = det(I −Φz)
̸= 0 (|z| ≤1) is equivalent to det(z−1I −Φ)
̸= 0
(|z| ≤1), i.e., the absolute values of all eigenvalues of the matrix Φ are greater than
or equal to 1. Repeatedly using (1.6.6), we get
Yt =
n
∑
0
ΦjZt−j + Φn+1Yt−n−1.
From this, it is seen that when the initial value Yn−1 is known, the value of an AR (1)
process Yt can be deduced from the above formula.
From Yt−l = Zt−l + ∑∞
j=0 ΦjZt−l−j and E[Yt−lZT
t ] = 0 (l > 0), it implies the Yule–
Walker equations
Γ(0) =
p
∑
1
Γ(−j)ΦT
j + Σ,
Γ(l) = E[Yt−lYT
t ] =
p
∑
1
Γ(l −j)ΦT
j
(l = 1, . . . , p).
The AR (p) process can always be expressed in the form of a kp-dimensional vec-
tor AR (1) model
Wt = (YT
t , . . . , YT
t−p+1)T,
where Wt = ΦWt−1 + Zt with Zt = (ZT
t , 0T, . . . , 0T)T and
Φ =
(
(
(
(
Φ1
Φ2
⋅⋅⋅
⋅⋅⋅
⋅⋅⋅
⋅⋅⋅
Φp
I
0
⋅⋅⋅
⋅⋅⋅
⋅⋅⋅
⋅⋅⋅
0
0
I
0
⋅⋅⋅
⋅⋅⋅
⋅⋅⋅
...
...
...
...
...
⋅⋅⋅
⋅⋅⋅
...
0
⋅⋅⋅
0
I
0
⋅⋅⋅
0
)
)
)
)
is a kp × kp matrix associated with Φ(B).

1.7 State-space models
|
39
1.6.3 Multivariate ARMA (p, q) processes
Let {Yt}t∈ℤbe a k-variate ARMA (p, q) model stated in (1.6.1) and (1.6.2). If det Φ(z) ̸= 0
(|z| ≤1), then the matrix Φ(z) is nonsingular and its inverse matrix Φ−1(z) exists.
Multiplying both sides by Φ−1(B),
Yt = Φ−1(B)Θ(B)Zt = Ψ(B)Zt,
(1.6.7)
where Ψ(B) = Φ−1(B)Θ(B). Expand it into a power series in z with matrix coefficients
Ψ(z) =
∞
∑
0
Ψjzj
(|z| ≤1),
where Ψj is a k × k matrix. The corresponding operator is
Ψ(B) =
∞
∑
j=0
ΨjBj.
By (1.6.7),
∞
∑
0
Θjzj = (I −
p
∑
1
Φjzj) (I +
q
∑
1
Ψjzj)
= I + (Ψ1 −Φ1)z + ⋅⋅⋅+ (Ψj −Φ1Ψj−1 −⋅⋅⋅−ΦpΨj−p)zj + ⋅⋅⋅.
Equating coefficient matrixes of various powers zj, we get
Ψ0 = 1,
Θj = Ψj −Φ1Ψj−1 −⋅⋅⋅−ΦpΨj−p
(j = 1, . . . , p).
From this and (1.6.7),
Yt = Ψ(B)Zt =
∞
∑
0
ΨjBjZt =
∞
∑
0
ΨjZt−j.
1.7 State-space models
1.7.1 State-space representation
A state-space model for an m-dimensional time series {Yt} consists of two equations.
The ﬁrst equation
Yt = KtXt + Wt
(t ∈ℤ+).
(1.7.1)
is called the observation equation and the second equation
Xt+1 = LtXt + Vt
(t ∈ℤ+),
(1.7.2)

40
|
1 Time series analysis
is called the state equation, where Kt is an m × n matrix and Lt is an n × n matrix,
and
{Wt} ∼WN(0, Rt),
{Vt} ∼WN(0, Qt).
(1.7.3)
Here Rt is an m × m matrix and Qt is an n × n matrix.
Assume that
E[WtVT
s ] = 0,
E[X1WT
s ] = 0,
E[X1VT
s ] = 0
(s, t ∈ℤ+).
By (1.7.1) and (1.7.2),
Xt = (Lt−1, . . . , L1)X1 + (Lt−1, . . . , L2)V1 + ⋅⋅⋅+ Lt−1Vt−2 + Vt−1,
Yt = (Kt, . . . , K1)X1 + (Kt, . . . , K2)W1 + ⋅⋅⋅+ KtWt−1 + Wt.
This implies that for 1 ≤s ≤t,
E[VtXT
s] = 0,
E[VtYT
s ] = 0,
E[WtXT
s] = 0,
E[WtYT
s ] = 0.
The state-space model is the extension of the ARMA model.
For example, if {Yt} is a causal and invertible ARMA (1, 1) model
Yt −φYt−1 = Zt + θZt−1,
{Zt} ∼WN(0, σ2).
The corresponding observation equation is Yt = (θ, 1)Xt, where Xt = (Xt−1, Xt)T, and
the state equation is
Xt+1 = (0
1
0
φ) Xt + Vt,
where Vt = (0, Zt+1)T and
X1 = (
∞
∑
k=0
φkZ−k,
∞
∑
k=0
φkZ1−k)
T
.
If {Yt} is a causal ARMA (p, q) model,
Yt −φ1Yt−1 −⋅⋅⋅−φpYt−p = Zt + θ1Zt−1 + ⋅⋅⋅+ θqZt−q.
Denote r = max{p, q + 1}, φj = 0 (j > p), θj = 0 (j > q), and θ0 = 1. Then the observation
equation is
Yt = (θr−1, . . . , θ0)Xt,
Xt = (Ut−r+1, . . . , Ut)T,
where {Ut} satisﬁes the causal AR (p) equation
Ut −φ1Ut−1 −⋅⋅⋅−φpUt−p = Zt

1.7 State-space models
|
41
and the state equation is
Xt+1 = (
(
(
0
1
0
⋅⋅⋅
0
0
0
1
⋅⋅⋅
0
...
...
...
...
0
0
0
0
⋅⋅⋅
1
φr
φr−1
φr−2
⋅⋅⋅
φ1
)
)
)
Xt + (
(
(
0
0
...
0
1
)
)
)
Zt+1
(t ∈ℤ).
We extend ARMA models to ARIMA models which are nonstationary time series
and are highly efficient in short-time forecasting. For d = 0, 1, . . . , let
̃Yn = (1 −B)dYn =
d
∑
k=0
(−1)k
d!
k!(d −k)! Yn−k.
If { ̃Yn}n∈ℤis a causal ARMA (p, q) process, we say {Yn}n∈ℤis an ARIMA (p, d, q) pro-
cess.
Let {Yt} be an ARIMA model
(1 −φB)(1 −B)Yt = (1 + θB)Zt,
{Zt} ∼WN(0, σ2).
Then the observation equation is
Yt = (θ, 1, 1)(Xt−1, Xt, Yt−1)T,
where
(
X0
X1
Y0
) = (
∑∞
0 φjZ−j
∑∞
0 φjZ1−j
Y0
) ,
(
Xt
Xt+1
Yt
) = (
0
1
0
0
φ
0
θ
1
1
) (
Xt−1
Xt
Yt−1
) + (
0
Zt+1
0
)
(t ∈ℤ+).
For a general ARIMA process, a state-space representation can be found.
Consider a randomly varying trend with noise. Let Y1 be a random variable and
{Vt} ∼WN(0, σ2),
E[VtY1] = 0
(t ∈ℤ+).
Deﬁne a process {Yt} as
Yt+1 = Yt + α + Vt = Y1 + αt + V1 + ⋅⋅⋅+ Vt,
where α is a constant. Let Xt = (Yt, α)T and Xt satisfy the state equation
Xt+1 = (1
1
0
1) Xt + Vt
(t ∈ℤ),
where Vt = (Vt, 0)T. The process {Yt} can be determined by the observation equation
Yt = (1, 0)Xt.

42
|
1 Time series analysis
1.7.2 Kalman prediction
Let {Yt}t∈ℤbe a state-space model whose observation equation and state equation are
stated in (1.7.1) and (1.7.2), respectively. We want to ﬁnd the best linear prediction of the
state Xt by the observation Y1, . . . , Yt−1 and a random vector Y0 satisfying Y0 ⊥Vt
and Y0 ⊥Wt for all t. In many cases, choose Y0 = (1, 1, . . . , 1)T.
Let Xt = (Xt1, . . . , Xtn)T be an n-dimensional random vector. The best one-step
linear predictor Xo
t = (Xo
t1, . . . , Xo
tn)T of Xt in terms of t vectors
Y0 = (Y01, . . . , Y0n), . . . , Yt−1 = (Yt−1,1, . . . , Yt−1,n)
is deﬁned as each Xo
tk is the best linear predictor of Xtk in terms of all the components
Y01, . . . , Y0n, Y11, . . . , Y1n, . . . , Yt−1,1, . . . , Yt−1,n
of t vectors Y0, . . . , Yt−1. By the orthogonality principle, we get
Xo
tk =
n
∑
l=1
α(0)
kl Y0l +
n
∑
l=1
α(1)
kl Y1l + ⋅⋅⋅+
n
∑
l=1
α(t−1)
kl
Yt−1,l
(k = 1, . . . , n)
and E[(Xtk −Xo
tk)Yμν] = 0.
Kalman prediction
For the state-space models (1.7.1) and (1.7.2), denote by Xo
t the best one-step linear
predictor of Xt in terms of t observation vectors Y0, . . . , Yt−1 and denote by Ωt the co-
variance matrix E[(Xt −Xo
t )(Xt −Xo
t )T] of the error Xt −Xo
t . Then the linear predictor
Xt is determined uniquely by initial conditions Xo
1 and Ω1 = E[(X1 −Xo
1)(X1 −Xo
1)T],
and
Xo
t+1 = LtXo
t + Θt∆−1
t (Yt −KtXo
t )
(t ∈ℤ+),
Ωt+1 = LtΩtLT
t + Qt −Θt∆−1
t ΘT
t
(t ∈ℤ+),
where Θt = LtΩtKT
t and ∆t = KtΩtKT
t + Rt, and ∆−1
t
is the inverse of ∆t. Here matrixes
Lt, Kt, Rt, and Qt are stated in (1.7.1), (1.7.2), and (1.7.3).
1.7.3 Kalman ﬁltering and Kalman ﬁxed point smoothing
For a state-space model, we ﬁnd the estimator of the state vector Xt in terms of
Y0, . . . , Yt. This estimator is called the Kalman ﬁlter, denoted by ̃Xt.

Further reading
|
43
Kalman ﬁltering
Let Xo
t , Ωt, and ∆−1
t
be stated as in the Kalman prediction. Then
(a) the ﬁltered estimate ̃Xt is
Xo
t + ΩtKT
t ∆−1
t (Yt −LtXo
t );
(b) the error covariance matrix is
E[(Xt −̃Xt)(Xt −̃Xt)T] = Ωt −ΩtKT
t ∆−1
t ΩT
t .
For a state-space model, we ﬁnd the estimator of the state vector Xt in terms of
Y0, . . . , Yt, . . . , Ys. This estimator is called the Kalman smoothing, denoted by Xs
t .
Kalman smoothing
Let Xo
t and ∆−1
t
be stated as in the Kalman prediction. Then
(a) the smoothed estimate Xs
t is determined by initial conditions Xo
t and Ωtt = Ωt,
and
Xs
t = Xs−1
t
+ ΩtsGT
s ∆−1
s (Ys −GsXo
s )
(s = t, t + 1, . . . ),
where Ωt,s+1 = Ωts(Ls −Θs∆−1
s Ks)T;
(b) the error covariance matrix E[(Xt −Xs
t )(Xt −Xs
t )T] = Ωs
t is determined by the re-
cursive formula
Ωs
t = Ωs−1
t
−ΩtsKT
s ∆−1
s KsΩT
ts.
Further reading
[1]
Bao C, Hao H, Li ZX. Integrated ARMA model method for damage detection of subsea pipeline
system. Engineering Structures. 2013(48):176–192.
[2]
Boularouk Y, Djeddour K. New approximation for ARMA parameters estimate. Mathematics and
Computers in Simulation. 2015(118):116–122.
[3]
David M, Ramahatana F, Trombe PJ, Lauret P. Probabilistic forecasting of the solar irradiance
with recursive ARMA and GARCH models. Solar Energy. 2016(133):55–72.
[4]
Flores JJ, Graff M, Rodriguez H. Evolutive design of ARMA and ANN models for time series fore-
casting. Renewable Energy. 2012(44):225–230.
[5]
Galiana-Merino JJ, Pla C, Fernandez-Cortes A, Cuezva S, Ortiz J, Benavente D. Environmental
wavelet tool: Continuous and discrete wavelet analysis and ﬁltering for environmental time
series. Computer Physics Communications. 2014(185):2758–2770.
[6]
Ip RHL, Li WK, Leung KMY. Seemingly unrelated intervention time series models for effective-
ness evaluation of large scale environmental remediation. Marine Pollution Bulletin. 2013(74):
56–65.
[7]
Liu J, Deng Z. Information fusion Kalman predictor for two-sensor multichannel ARMA signal
system with time-delayed measurements. Procedia Engineering. 2012(29):623–629.
[8]
Liu Y, Wu J, Liu Y, Hu BX, Hao Y, Huo X, Fan Y, Yeh TJ, Wang ZL. Analyzing effects of climate
change on streamﬂow in a glacier mountain catchment using an ARMA model. Quaternary
International. 2015(358):137–145.

44
|
1 Time series analysis
[9]
Macciotta NPP, Vicario D, Pulina G, Cappio-Borlino A. Test day and lactation yield predictions in
Italian Simmental cows by ARMA methods. Journal of Dairy Science. 2002(85):3107–3114.
[10] Kadri F, Harrou F, Chaabane S, Sun Y, Tahon C. Seasonal ARMA-based SPC charts for anomaly
detection: Application to emergency department systems. Neurocomputing. 2016(173):
2102–2114.
[11] Kapetanios G. A note on an iterative least-squares estimation method for ARMA and VARMA
models. Economics Letters. 2003(79):305–312.
[12] Krasnov H, Katra I, Friger M. Increase in dust storm related PM10 concentrations: A time series
analysis of 2001–2015. Environmental Pollution. 2016(213):36–42.
[13] Piston N, Schob C, Armas C, Prieto I, Pugnaire FI. Contribution of co-occurring shrub species to
community richness and phylogenetic diversity along an environmental gradient. Perspectives
in Plant Ecology, Evolution and Systematics. 2016(19):30–39.
[14] Ran C, Deng Z. Self-tuning distributed measurement fusion Kalman estimator for the multi-
channel ARMA signal. Signal Processing. 2011(91):2028–2041.
[15] Soni K, Parmar KS, Kapoor S, Kumar N. Statistical variability comparison in MODIS and
AERONET derived aerosol optical depth over Indo-Gangetic Plains using time series model-
ing. Science of the Total Environment. 2016(553):258–265.
[16] Takemura A. Exponential decay rate of partial autocorrelation coefficients of ARMA and short-
memory processes. Statistics & Probability Letters. 2016(110):207–210.
[17] Tulbure MG, Broich M, Stehman SV, Kommareddy A. Surface water extent dynamics from three
decades of seasonally continuous Landsat time series at subcontinental scale in a semi-arid
region. Remote Sensing of Environment. 2016(178):142–157.
[18] Valipour M, Banihabib ME, Behbahani SMR. Comparison of the ARMA, ARIMA, and the au-
toregressive artiﬁcial neural network models in forecasting the monthly inﬂow of Dez Dam
Reservoir. Journal of Hydrology. 2013(476):433–441.
[19] Voyant C, Muselli M, Paoli C, Nivet ML. Numerical weather prediction (NWP) and hybrid
ARMA/ANN model to predict global radiation. Energy. 2012(39):341–355.
[20] Xu W, Gu R, Liu Y, Dai Y. Forecasting energy consumption using a new GM-ARMA model based
on HP ﬁlter: The case of Guangdong Province of China. Economic Modelling. 2015(45):127–135.
[21] Zhang P, Qi W, Deng Z. Multi-channel ARMA signal covariance intersection fusion Kalman pre-
dictor. Procedia Engineering. 2012(29):609–615.

2 Chaos and dynamical systems
Complex dynamical systems exist widely in nature. In 1961, Edward Lorenz ran a nu-
merical computer model to make a weather prediction. When he entered the initial
condition 0.506 instead of 0.506127, the result was a completely different weather
scenario. Later on, when Lorenz presented this result at the 139th meeting of the Amer-
ican Association for the Advancement of Science in 1972, Philip Merilees concocted
“Does the ﬂap of a butterﬂy’s wings in Brazil set off a tornado in Texas” as the title
of Lorenz’s talk. This is the so-called butterﬂy effect. In general, for any complex dy-
namical system in environmental science, its trajectory often sensitively depends on
initial conditions. If two initial conditions have a small difference and their trajectories
after some time are exponential separation, such a system is called a chaotic dynam-
ical system. If a set of initial conditions, after some time, is attracted to some subset
which is invariant under dynamical evolution, such an invariant subset is called an
attractor of the system. Attractors of chaotic dynamical systems often exhibit an un-
usual kind of self-similarity and have fractal dimension. The sensitivity dependence
on initial conditions and the fractal dimension of attractors are two of the most impor-
tant characteristics of dynamical systems. In environmental science, the equations
underlying a dynamical system are often unknown. Using the delay-coordinate em-
bedding technique, the dynamical system can be reconstructed from the trajectories
which originate from a dynamical system.
2.1 Dynamical systems
In theory, a dynamical system is deﬁned as a ﬁrst-order differential equation acting on
a phase space ℝm
d
dt x(t) = F(t, x(t))
(t ∈ℝ),
(2.1.1)
where x = (x(1), . . . , x(m)) and F = (F1, . . . , Fm). In the discrete case, deﬁne a dynam-
ical system as an m-dimensional map
xn+1 = F(xn)
(n ∈ℤ),
(2.1.2)
where xk = (x(1)
k , . . . , x(m)
k
). If F is not depend explicitly on t, i.e.,
d
dt x(t) = F(x(t))
(t ∈ℝ),
(2.1.3)
then the system is called autonomous. If F satisﬁes the Lipschitz condition
‖F(x) −F(x󸀠)‖ ≤K ‖x −x󸀠‖α
(0 < α ≤1),
DOI 10.1515/9783110424904-003

46
|
2 Chaos and dynamical systems
where x, x󸀠∈ℝm, K > 0 is a constant, and ‖ ⋅‖ is the norm of ℝm, then the initial
value problem
{
{
{
d
dt x(t) = F(x(t))
(t ∈ℝ),
x(0) = a
has a unique solution. Let F = (F1, . . . , Fm). Suppose that divergence of F in (2.1.3) is
less than zero,
div F = ∇⋅F = ∂F1
∂x1
+ ∂F2
∂x2
+ ⋅⋅⋅+ ∂Fm
∂xm
< 0.
Then the system is called a dissipative system. In this case, a set of initial conditions
is contracted under the dynamical evolution. This set is attracted to some invariant
subset which is called an attractor of the system.
For the discrete dynamical system (2.1.2), consider the Jacobian matrix of F,
JF = ( ∂Fi
∂x(j) )
m×m
= (
∂F1
∂x(1)
⋅⋅⋅
∂F1
∂x(m)
...
...
...
∂Fm
∂x(1)
⋅⋅⋅
∂Fm
∂x(m)
) ,
if the absolute value of the determinant of JF satisﬁes
|det JF| < 1,
then a set of initial conditions is contracted to an invariant subset which is called an
attractor.
2.2 Henon and logistic maps
Simple dynamical systems can exhibit a completely unpredictable behavior. Here we
give some examples, including the famous Henon and logistic maps.
2.2.1 Circular motion
For a dynamical system
dx1
dt = −ωx2,
dx2
dt = ωx1,
(2.2.1)
where ω is a constant, we have d2x1
dt2 = −ω dx2
dt = −ω2x1 or d2x1
dt2 + ω2x1 = 0. The solution
of this second-order differential equation
x1 = a cos ω(t −t0),
x2 = a sin ω(t −t0)

2.2 Henon and logistic maps
|
47
is a trajectory of the dynamical system (2.2.1), where a, t0 ∈ℝ. Rewrite (2.2.1) into the
vector form
dx
dt = F(x) = Ax,
where x = (x1, x2)T and F = (F1, F2) = (−ωx2, ωx1) and A = ( 0 −ω
ω
0 ). The divergence
of F is
∇⋅F = ∂F1
∂x1
+ ∂F2
∂x2
= ∂(−ωx2)
∂x1
+ ∂(ωx1)
∂x2
= 0.
So the system has bounded solutions and is not dissipative.
2.2.2 Henon map
For the Henon map xn+1 = F(xn) (n ∈ℤ), where xn = (x(1)
n , x(2)
n ), F = (F1, F2)T, and
F1(xn) = a −(x(1)
n )2 + bx(2)
n ,
F2(xn) = x(1)
n ,
and a, b are constants, its Jacobian matrix is
JF = (
∂F1
∂x(1)
∂F1
∂x(2)
∂F2
∂x(1)
∂F2
∂x(2)
) = (−2x(1)
b
1
0)
and the determinant |det JF| = |b|. If |b| < 1, then the system is dissipative.
2.2.3 Fixed point
Let xn+1 = F(xn), where F : ℝm →ℝm is a map satisfying ‖F(s) −F(t)‖ ≤q‖s −t‖
(0 ≤q < 1). Here ‖ ⋅‖ is the norm of the space ℝm. For any x1 ∈ℝm,
{
{
{
{
{
{
{
{
{
x2 = F(x1),
...
xn+1 = F(xn),
and so
‖xn+1 −xn‖ = ‖F(xn) −F(xn+1)‖ ≤q ‖xn −xn−1‖ ≤⋅⋅⋅≤qn−1‖x2 −x1‖.
This implies that {xn} is convergent. In fact,
‖xn+p −xn‖ ≤‖xn+p −xn+p−1‖ + ⋅⋅⋅+ ‖xn+1 −xn‖
≤(qn+p−2 + ⋅⋅⋅+ qn−1)‖x2 −x1‖
≤
qn
1 −q ‖x2 −x1‖ →0
(n →∞).

48
|
2 Chaos and dynamical systems
Thus, there is a point x∗∈ℝm such that xn →x∗(n →∞).
Finally, we prove the uniqueness of x∗, i.e., x∗is independent of the choice of the
initial value.
Since F is continuous, clearly, from xn+1 = F(xn) and xn →x∗, it follows that
x∗= F(x∗). If there is an
̄x
̸= x∗such that
̄x = F( ̄x), then
0 < ‖x∗−̄x‖ = ‖F(x∗) −F( ̄x)‖ ≤q ‖x∗−̄x‖ < ‖x∗−̄x‖.
This is a contradiction. So x∗= ̄x.
From this, it is seen that sometimes the solution of a dynamical equation tends
to a point which is independent of the choice of the initial value. This point is just an
attractor of this system.
2.2.4 Linear mapping
Consider the dynamical system
xn+1 = αxn + β
(n ∈ℤ),
(2.2.2)
where xn, α, β ∈ℝand α, β are constants. Let xn = γyn + δ. Then (2.2.2) becomes
γyn+1 + δ = αγyn + αδ + β.
Choose δ such that δ = αδ + β, i.e., δ =
β
1−α . So
yn+1 = αyn
(n ∈ℤ),
(2.2.3)
i.e., yn+1 = F(yn), where F(y) = αy.
By (2.2.3), yn = y0αn. If |α| < 1, then {yn} is exponentially decaying wherever y0
is any number. Clearly, yn →0 (n →∞). Thus, the trajectory is attracted to the ﬁxed
point y0 = 0, i.e., y0 is an attractor. If |α| > 1, then {yn} is exponentially increasing.
If α = −1, then it is an oscillatory system between two values.
For a dynamical system xn+1 = F(xn) (n ∈ℤ), its ﬁxed points are the solutions of
x = F(x). Start from a point x0 in a small neighborhood of a ﬁxed point x∗, deﬁne a
small number εn such that xn = x∗+ εn. So
x∗+ εn+1 = xn+1 = F(x∗+ εn) ≈F(x∗) + F󸀠(x∗)εn.
Note that x∗= F(x∗). Then
εn+1 = F󸀠(x∗)εn.
(2.2.4)
Furthermore, when |F󸀠(x∗)| < 1, xn →x∗(n →∞). This means that x∗is an attractor.

2.2 Henon and logistic maps
|
49
2.2.5 Logistic map
The logistic map is xn+1 = F(xn) = Axn(1 −xn), where A is a constant.
Consider a ﬁxed point x∗
1 = 0. Then
F󸀠(x∗
1) = A(1 −2x∗
1) = A,
and so |F󸀠(x∗
1)| < 1 if and only if |A| < 1. This means that x∗
1 = 0 is an attractor when
−1 < A < 1. For another ﬁxed point x∗
2 = 1 −1
A ,
F󸀠(x∗
2) = A(1 −2(1 −A−1)) = −A + 2,
and so |F󸀠(x∗
2)| < 1 if and only if 1 < A < 3. This means that x∗
2 = 1 −A−1 is an attractor
when 1 < A < 3.
Now consider the case A = 3. When A = 3, F󸀠(x∗
2) = −1. By (2.2.4),
εn+1 = −εn,
εn+2 = εn
(n ∈ℤ),
i.e., xn+2 = xn. So {xn} is an oscillatory trajectory between two values under a small
perturbation.
To obtain such an oscillatory trajectory, consider the map T2(x) := F(F(x)) and
ﬁnd its ﬁxed point through the system of equations
y2 = F(y1) = Ay1(1 −y1),
y1 = F(y2) = Ay2(1 −y2).
(2.2.5)
Its solution is
y∗
1 = A + 1 + √(A + 1)(A −3)
2A
,
y∗
2 = A + 1 −√(A + 1)(A −3)
2A
.
(2.2.6)
Clearly, if A ≥3, the solution exists. Then y∗
1 and y∗
2 are ﬁxed points of the map F2.
From this and (2.2.5), it follows that
(F2)󸀠(y∗
1) = F󸀠(F(y∗
1))F󸀠(y∗
1) = F󸀠(y∗
2)F󸀠(y∗
1) = A2(1 −2y∗
1)(1 −2y∗
2).
By (2.2.6),
y∗
1 + y∗
2 = 1 + A−1,
y∗
1y∗
2 =
1
4A2 ((A + 1)2 −(A + 1)(A −3)) = A + 1
A2 .
So (F2)󸀠(y∗
1) = 1 −(A + 1)(A −3).
Similarly, (F2)󸀠(y∗
2) = (F2)󸀠(y∗
1) = 1 −(A + 1)(A −3).
From
(F2)󸀠(y∗
1) = (F2)󸀠(y∗
2) = 1
when A = 3,
(F2)󸀠(y∗
1) = (F2)󸀠(y∗
2) = −1
when A = 1 + √6,

50
|
2 Chaos and dynamical systems
similar to the case A = 3, it is easily shown that when A = 1 + √6, the trajectories are
oscillatory among four values.
Therefore, when A increases from 3, the trajectories are oscillatory among two
values, then four values, eight values, …. When A approximates the value 3.56995,
periods of oscillations tend to inﬁnity. When the parameter A > 3.56995, the system
begins to exhibit chaotic behavior and have the following characteristics:
–
sensitively depend on initial conditions;
–
nonperiodicity;
–
the attractors have fractal structures (i.e. strange attractors).
The interval [3.56995, 4] for the parameter A is often called the chaotic domain.
2.3 Lyapunov exponents
For a dynamical system, if two initial conditions have a small difference δx and their
difference after time t becomes δxeλt, then λ is called the Lyapunov exponent. Numer-
ically, one can calculate the maximal Lyapunov exponent λmax as follows. Choose two
very close initial points and let their distance be d0 ≪1. After time ti, their difference
will become di (i ∈ℤ+). Then the maximal Lyapunov exponent can be computed by
λmax = lim
N→∞
N
∑
1
log di
d0
N
∑
1
ti
.
Negative Lyapunov exponents are characteristic of dissipative or nonconservative
systems. Such systems exhibit asymptotic stability; the more negative the exponent,
the greater the stability. A positive Lyapunov exponent is characteristic of chaotic sys-
tems. Nearby points, no matter how close, will diverge to any arbitrary separation. In
a dynamical system there exist many different Lyapunov exponents, but the sum of
all Lyapunov exponents cannot be positive in a physically meaningful system.
Let x and y be two close trajectories for a dynamical system with dimension m
xn+1 = F(xn),
yn+1 = F(yn).
Then
yn+1 −xn+1 = F(yn) −F(xn) = Jn(xn)(yn −xn) + O(‖yn −xn‖2),
where Jn(xn) is the m × m Jacobian matrix of F at xn. Let δn = yn −xn. It is rewritten
into δn+1 = Jnδn (n ∈ℤ+), where Jn = Jn(xn). This implies that
δN+1 = JNδN = JNJN−1δN−1 = ⋅⋅⋅= UNδ1.
where UN = ∏N
n=1 Jn.

2.4 Fractal dimension
|
51
In order to compute Lyapunov exponents, we need to ﬁnd δ1 such that ‖δn+1‖
attains the maximal value under the condition ‖δ1‖ = 1 (i.e., δT
1δ1 = 1) by using the
Lagrange multipliers method. Introduce a function
H(u) = (UNu)T(UNu) −λ(uTu −1).
Note that
(UNu)T(UNu) = uTUT
NUNu = uTGNu,
where GN = UT
NUN is an m × m real symmetric positive deﬁnite matrix and u is an
m-dimensional vector and uTGNu is a quadratic form of u. So
H(u) = uTGNu −λ(uTu −1).
Let GN = ( αij )m×m and u = (u1, . . . , um). Then
H(u) =
m
∑
i=1
m
∑
j=1
αijuiuj −λ (
m
∑
1
u2
i −1) .
This implies that
∂H
∂ul
= 2
n
∑
i=1
αilui −2λul
(l = 1, . . . , m).
Since ∂H
∂ul = 0(l = 1, . . . , m) and ‖ul‖ = 1, when λ is the eigenvalue of the matrix GN and
u is the corresponding unit eigenvector, H(u) attains the minimal value. Denote its
eigenvalues by λ(N)
1
≥λ(N)
2
⋅⋅⋅≥λ(N)
m . The corresponding unit eigenvectors e(N)
1 , . . . , e(N)
m
satisfy GNe(N)
i
= λ(N)
i
e(N)
i
. Then the Lyapunov exponents are
λi = lim
N→∞
1
2N log|λ(N)
i
|
(i = 1, . . . , m).
In the one-dimensional case, the Jacobian matrix F󸀠(xn) on xn is a real number.
The corresponding Lyapunov exponent is
λ = lim
N→∞
1
N
N
∑
1
log|F󸀠(xn)|.
2.4 Fractal dimension
From an intuitive notion of dimension, a set of ﬁnite points is zero-dimensional, a
straight line is one-dimensional, a plane is two-dimensional, and a cube is three-
dimensional. One often determines the dimension by degrees of freedom. For exam-
ple, the equation with a parameter
x = x(t),
y = y(t)
(0 ≤t ≤1),

52
|
2 Chaos and dynamical systems
where x(t) and y(t) are continuous functions, is considered to be a one-dimensional
continuous curve since it only has one degree of freedom. The equation
x = x(u, υ),
y = y(u, υ)
(u, υ ∈[0, 1]2),
where x(u, υ) and y(u, υ) are continuous functions, is considered to be a two-dimen-
sional continuous surface.
However, the approach in which one uses degrees of freedom to determine dimen-
sion is not precise. In 1890, Peano constructed a continuous curve
x = xp(t),
y = yp(t)
(0 ≤t ≤1),
such that its trajectory ﬁlls the whole unit square [0, 1]2, i.e., its dimension is two.
Peano’s curve is constructed as follows.
First, the segment S = [0, 1] is divided equally into four small segments
S(1)
1
= [0, 1
4] ,
S(1)
2
= [ 1
4 , 1
2] ,
S(1)
3
= [ 1
2 , 3
4] ,
S(1)
4
= [ 3
4 , 1] .
Correspondingly, the unit square Q = [0, 1]2 is equally divided into four small squares
Q(1)
1
= [0, 1
2] × [0, 1
2] ,
Q(1)
2
= [ 1
2 , 1] × [0, 1
2] ,
Q(1)
3
= [0, 1
2] × [ 1
2 , 1] ,
Q(1)
4
= [ 1
2 , 1] × [ 1
2 , 1]
and each small segment S(1)
k
(k = 1,2,3,4) is divided equally into four small segments
S(2)
4(k−1)+1,
S(2)
4(k−1)+2,
S(2)
4(k−1)+3,
S(2)
4k
(k = 1, 2, 3, 4).
So the segment S is divided into 24 segments S(2)
1 , S(2)
2 , . . . , S(2)
16 . Correspondingly,
each Q(1)
k
(k = 1, 2, 3, 4) is divided equally into four small squares. So the square Q is
divided equally into 16 small squares.
Continuing this procedure to the n-th steps. Then the segment S is equally divided
into 4n small segments S(n)
1 , S(n)
2 , . . . , S(n)
4n and the square Q is equally divided into 4n
small squares Q(n)
1 , . . . , Q(n)
4n (n = 1, 2, . . . ).
Now we construct a continuous map from [0, 1] to [0, 1]2 one-to-one as follows.
For a point a ∈S, there is a sequence of segments S(1)
k1 , . . . , S(n)
kn such that
S(1)
k1 ⊃S(2)
k2 ⊃⋅⋅⋅⊃S(n)
kn ⊃⋅⋅⋅.
The sequence {S(n)
kn }n∈ℤ+ converges to the point a. The corresponding small square
{Q(n)
kn }n∈ℤ+ converges to a unique point b as n →∞. Let a corresponds to b, i.e., the
map φ from [0, 1] into [0, 1]2 is given by φ(a) = b.
Conversely, for any b󸀠∈[0, 1]2, there is a sequence {Q(n)
k󸀠
n }n∈ℤ+ such that
Q(1)
k󸀠
1 ⊃Q(2)
k󸀠
2 ⊃⋅⋅⋅⊃Q(n)
k󸀠
n ⊃⋅⋅⋅

2.4 Fractal dimension
|
53
and {Q(n)
k󸀠
n }n∈ℤ+ converges to b󸀠. The corresponding small segment {S(n)
k󸀠
n }n∈ℤ+ con-
verges to a unique point a󸀠, and so φ(a󸀠) = b󸀠. This implies that φ(a) = b is a
one-to-one map from [0, 1] to [0, 1]2 and φ([0, 1]) = [0, 1]2.
Finally, we prove that φ is a continuous map. Let an →a (an ∈S), bn = φ(an),
and b = φ(a). We need only to prove that bn →b.
By the above construct, there are k1 < k2 < ⋅⋅⋅such that
S(1)
k1 ⊃S(2)
k2 ⊃⋅⋅⋅⊃S(n)
kn ⊃⋅⋅⋅,
Q(1)
k1 ⊃Q(2)
k2 ⊃⋅⋅⋅⊃Q(n)
kn ⊃⋅⋅⋅,
and a ∈S(n)
kn , b ∈Q(n)
kn (n ∈ℤ+). For ε > 0, choose m ∈ℤ+ such that
√2 (4−m) < ε.
By an →a, there is a p ∈ℤ+ such that an ∈S(m)
km , bn ∈Q(m)
km (n > p). Note that b ∈Q(m)
km
and Q(m)
km is a square with the diameter √2 (4−m). Then
‖bn −b‖ ≤√2 (4−m) < ε.
So bn →b. This implies that φ(a) = b is a one-to-one continuous map from [0, 1] to
[0, 1]2. Let
φ(a) = (φ1(a), φ2(a)),
b = (b1, b2).
Then the map b = φ(a) can be rewritten into
b1 = φ1(a),
b2 = φ2(a)
(0 ≤a ≤1),
where both φ1 and φ2 are continuous. So it is a continuous curve. But it is two-
dimensional.
From this, it is seen that the notion of dimension needs to be described more pre-
cisely. There are several ways to deﬁne dimension.
2.4.1 Box-counting dimension
Cover a bounded data set A by boxes with diameter ε. Denote the minimal number of
boxes by N(ε). Then the box-counting dimension D1 is deﬁned by
D1 = lim
ε→0
log N(ε)
log 1
ε
.
By this deﬁnition, the segment [0, 1] is one-dimensional, the square [0, 1]2 is two-
dimensional, the cube [0, 1]3 is three-dimensional. This deﬁnition coincides with the
intuitive notion of dimension.

54
|
2 Chaos and dynamical systems
2.4.2 Information dimension
In the deﬁnition of box-counting dimension, it is not considered how many points of
the set lie in each box. The information dimension overcomes this shortcoming and is
deﬁned as
D2 = lim
ε→0
H(ε)
log 1
ε
,
where
H(ε) = −
N(ε)
∑
1
Pi log Pi
and Pi is the relative frequency that the point (in the set) occurs in the i-th box of the
covering.
2.4.3 Correlation dimension
In the higher dimensional case, the computations of box-counting dimension and the
information dimension are too complicated. For convenience, the correlation dimen-
sion is introduced. It is deﬁned as
D3 = lim
ε→0
log C(ε)
log ε
,
where C(ε) =
2
N(N−1) ∑N
i=1 ∑N
j=i+1 Θ(ε −‖xi −xj‖) and Θ is the Heaviside step function
Θ(x) = 0
(x ≤0),
Θ(x) = 1
(x > 0).
2.4.4 Self-similarly dimension
A segment may be divided into 2 subsegments with similarity ratio 1
2 . A square may be
divided into 4 subsquares with similarity ratio 1
2 . A cube may be divided into 8 sub-
cubes with similarity ratio 1
2 . The numbers 2, 4, and 8 can be rewritten as 21, 22,
and 23. Here the exponents 1, 2, and 3 coincide with their intuitive dimensions.
In the real world, many diagrams can be divided into b similar small diagrams
with similarity ratio 1
a , where a is a positive integer, and each small diagram can be
divided into b similar smaller diagrams with similarity ratio 1
a . If this procedure can
continue forever, then we call such a diagram self-similar and its dimension
D4 = log b
log a .
For example, the following Canton set is a self-similar set.

2.5 Prediction
|
55
First, divide [0, 1] into three parts [0, 1
3], ( 1
3 , 2
3), [ 2
3 , 1]. Remove the middle part
G1 = ( 1
3 , 2
3). The residual part is
E1 = [0, 1] \ ( 1
3 , 2
3) = [0, 1
3] ⋃[ 2
3 , 1] .
Secondly, divide [0, 1
3] and [ 2
3 , 1] into three parts, respectively,
[0, 1
9] ,
( 1
9 , 2
9) ,
[ 2
9 , 1
3] ,
[ 2
3 , 7
9] ,
( 7
9 , 8
9) ,
[ 8
9 , 1] .
Remove G2 = ( 1
9 , 2
9) ⋃( 7
9 , 8
9). The residual part is
E2 = [0, 1] \ (G1 ∪G2) = [0, 1
9] ⋃[ 2
9 , 1
3] ⋃[ 2
3 , 7
9] ⋃[ 8
9 , 1] .
Continuing this procedure, we obtain a set G∞= ⋃∞
n=1 Gn. Clearly, G∞is an open
set with measure 1. Let C = [0, 1] \ G∞. Then C is a closed set with measure 0. The
set C is called the Canton set.
The Canton set can be divided into 2 similar small sets C1 and C2 with similarity
ratio 1
3 . Both C1 and C2 can be divided into 2 similar smaller sets with similarity ratio
1
3 . This procedure can continue forever. Therefore, the Canton set C is a self-similar
set with dimension D4 = log 2
log 3 .
For the Canton set, its dimension is a fractal. Fractal dimensional diagrams are
ubiquitous in nature. For chaotic dynamical systems, its attractor is often fractal
dimensional. A fractal dimensional diagram has a complicated geometric structure.
Self-similarity is the most important characteristic of fractal diagrams.
2.5 Prediction
Consider the linear prediction. For a given time series Sn (n = 1, . . . , N) of measure-
ments, we want to predict the following measurement SN+1. The predictor So
n+1 of the
measurement Sn+1 can be expressed by a linear combination of Sn−m+1, . . . , Sn, i.e.,
So
n+1 =
m
∑
i=1
αiSn−m+i
(n = m, . . . , N),
(2.5.1)
where αi’s are m undetermined coefficients which are independent of n. Choose αi’s
such that
g(α1, . . . , αm) =
N−1
∑
n=m
(So
n+1 −Sn+1)2
(2.5.2)
attains the minimal value. By the extremum principle, it is necessary to ﬁnd the deriva-
tives ∂g
∂αi . By (2.5.1) and (2.5.2),
1
2
∂g
∂αi
=
N−1
∑
n=m
(So
n+1 −Sn+1) ∂So
n+1
∂αi
=
N−1
∑
n=m
(
m
∑
j=1
αjSn−m+j −Sn+1) Sn−m+i.

56
|
2 Chaos and dynamical systems
So ∂g
∂αi = 0(i = 1, . . . , m) are equivalent to the system of linear equations ∑m
j=1 cijαj = di
(i = 1, . . . , m), where
cij =
N−1
∑
n=m
Sn−m+jSn−m+i,
di =
N−1
∑
n=m
Sn−m+iSn+1.
The solutions are denoted by αo
1, . . . , αo
m. By (2.5.1), we get the prediction of SN+1
So
N+1 =
m
∑
i=1
αo
i SN−m+i.
For the nonlinear prediction, we consider the vector
Sn = (Sn−(m−1), Sn−(m−2), . . . , Sn−1, Sn),
where m is the embedding dimension. In order to predict SN+1, a good method is to
ﬁnd a known embedding vector RN closest to SN . Then we use RN+1 to predict SN+1.
More generally, we choose a small ε > 0 and ﬁnd L known embedding vectors
Rk
N (k = 1, . . . , L) such that ‖Rk
N −SN‖ ≤ε. The prediction of SN+1 is
̂SN+1 = 1
L
L
∑
k=1
Rk
N+1.
2.6 Delay embedding vectors
For a dynamical system, instead of measuring the actual states xn, we observe a scalar
time series depending on the states Sn = S(xn). This scalar is a projection of variables
of a system on the real axis. Due to the reduction of dimensionality and nonlinearity
of the projection process, it is difficulty to reconstruct the state space of the original
system by this scalar time series. When the attractor dimension is much smaller than
the dimension of the state space, it is enough to construct a new space such that the
attractor in the new space is equivalent to the original one.
Consider a dynamical system xn+1 = F(xn) (n = 1, . . . , N) with the attractor A. To
reconstruct the attractor A, we construct the m-dimensional vector by the scalar time
series {Sn}
Sn = (Sn−(m−1), Sn−(m−2), . . . , Sn−1, Sn)
and τ is the decay time and m is the embedding dimension.
An embedding of a compact smooth manifold M into the space ℝm is deﬁned
as a map which is a one-to-one continuously differentiable map with the nonsingular
Jacobian matrix. The following theorem shows how to choose m such that the attractor
A can embed into the space ℝm.

2.7 Singular spectrum analysis
|
57
If xn ∈A, then Sn ∈ℝ, and so Sn ∈
̃A ⊂ℝm, where
̃A is the image of A in the
embedding process. This implies d ̃A = dA, where dB is the dimension of B.
Since the embedding map is one-to-one continuously differentiable, the self-
intersection must not occur in
̃A. Otherwise, there are two directions at the self-
intersection, which will destroy the one-to-one correspondence. In an m-dimensional
space, the intersection of a d1-dimensional subspace and a d2-dimensional subspace
in general is a dl-dimensional subspace, where dl = d1 + d2 −m. When these two
subspaces do not intersect, then dl < 0. Now
̃A does not intersect with itself, so
dl = 2dA −m < 0, i.e., m > 2dA. Therefore, m > 2dA is a necessary condition that A
is embedded in ℝm.
On the other hand, we have the following theorem.
Delay embedding theorem. Let dA be the box-counting dimension of the attractor A.
If m > 2dA, then except for some special cases, the map Sn = (Sn−(m−1), . . . , Sn) from
xn ∈A into ℝm is an embedding map.
The whole embedding procedure can be visualized in the following diagram:
xn ∈A
F→
xn+1 ∈A
↓
↓
Sn ∈ℝ
Sn+1 ∈ℝ
↓
↓
Sn ∈
̃A ⊂ℝm
G→
Sn+1 ∈
̃A ∈ℝm
Since the attractor is an invariant subset, from Sn ∈
̃A, it follows that Sn+1 ∈
̃A. The
new dynamical system Sn+1 = G(Sn) is uniquely determined by xn+1 = F(xn).
A large embedding dimension requires knowledge of long time series. To reduce
the cost of calculation, one often chooses dA < m < 2dA if the self-intersection is ne-
glectable.
Finally, we choose the suitable delay time τ such that τ is large enough and Sn
and Sn+1 are rather independent, and at the same time τ is not so large that they are
completely independent in a statistical sense. Let pi be the probability that Sn is in
the i-th bin of histogram, and let pij be the probability that Sn is in the bin i and Sn+τ
is in the j-th bin. The mutual information for time delay τ is
I(τ) = ∑
i,j
pij(τ) log pij(τ) −2 ∑
i
pi log pi.
The ﬁrst minimum of the mutual information is a good candidate for time delay.
2.7 Singular spectrum analysis
Singular spectrum analysis is a technique to identify recurrent patterns and adaptively
enhance signal-to-noise ratio in a dynamical system. Consider the dynamical system

58
|
2 Chaos and dynamical systems
xn+1 = F(xn). Let Sn = S(xn) (n = 1, 2, 3, . . . , N) be an observed scalar time series
from this dynamical system. Deﬁne
Y1 = (SN−2(m−1), . . . , SN−m+1)T
. . .
Ym = (SN−(m−1), . . . , SN)T.
where m ≪N. Let Y = (Y1, . . . , Ym). Then the covariance matrix ΣYY of Y is
ΣYY = (Cov(Yi, Yj))m×m .
Since the matrix ΣYY is a real symmetric matrix, its eigenvalues are λ1 ≥λ2 ≥⋅⋅⋅≥
λm and the corresponding eigenvectors e1, e2, . . . , em form an orthonormal basis. In
general, the main recurrent patterns are just the ﬁrst several eigenvectors. Let
αk = (Y, ek)
(k = 1, . . . , m).
Then
Y =
m
∑
k=1
αkek.
(2.7.1)
Since ek is a normal eigenvector of ΣYY ,
Var(αk) = eT
k(λkek) = λk(eT
kek) = λk
(k = 1, . . . , m),
Cov(αk, αl) = eT
kΣYYel = eT
k(λlel) = 0
(k
̸= l).
(2.7.2)
By (2.7.1) and (2.7.2), it follows that the total variance of Y is
Var(Y) = E[‖Y‖2
2] = E [
m
∑
1
α2
k] =
m
∑
1
E[α2
k] =
m
∑
1
λk
and the ratio λL/ ∑m
k=1 λk is deﬁned as the contribution of eL to Y.
2.8 Recurrence networks
Recurrence networks are a new approach to analyzing the recurrence properties of
complex dynamical systems. For N observed trajectories Sn (n = 1, . . . , N) from a
dynamical system, their time delay embedding vectors
ST
n = (Sn
T−(m−1)τ, . . . , Sn
T−τ, Sn
T),
where m is the embedding dimension and τ is the delay. Deﬁne a recurrence network
associated with these delay time vectors: each Sn (n = 1, . . . , N) is considered as
a vertex. A simple approach is to introduce an edge between two vertices Si and Sj
when the correlation coefficient between ST
i and ST
j is larger than a given threshold.
Another approach is to introduce an edge between two vertices based on the distance.
For i
̸= j, if the distance between Si and Sj is less than a given threshold ε, where ε

2.8 Recurrence networks
|
59
is reasonably small (in particular, much smaller that the attractor diameter), then the
vertices Si and Sj are considered to be connected by an edge. In detail,
For a given threshold ε > 0, let
Rij = H(ε −distance(Si, Sj))
(i, j = 1, . . . , m),
where H is the Heaviside function
H(α) =
{
{
{
1
(α ≥0),
0
(α < 0)
and ‖⋅‖ is the norm of the space ℝm. If the pair i, j (i ̸= j) such that Rij = 1, it means that
Si and Sj are close. In this case, we introduce an edge between Si and Sj. If Rij(ε) = 0,
it means that Si and Sj are not close. In this case, we do not introduce an edge between
Si and Sj. The matrix (Rij(ε))m×m is called a recurrence matrix.
Let
Aij(ε) = Rij(ε) −δij
(i, j = 1, . . . , m),
(2.8.1)
where δij is the Kronecker delta, i.e., δij = 0 (i
̸= j) and δij = 1 (i = j). The matrix
(Aij)m×m is called an adjacency matrix. When i
̸= j, Aij(ε) = Rij(ε).
The topological characteristics of recurrence networks can capture the fundamen-
tal properties of dynamical systems.
2.8.1 Local recurrence rate
First, we measure the importance of a vertex in a complex network, the local recur-
rence rate of a vertex Sν (ν = 1, . . . , N) is
kν =
N
∑
i=1
Aνi
(Aνν = 0)
which is the number of vertices i
̸= ν connected directly with ν. Therefore, the local
connectivity is deﬁned as
ρν =
1
N −1
N
∑
i=1
Aνi.
Local connectivity gives the relationship between local edge density and local corre-
lation dimension.
2.8.2 Global recurrence rate (edge density)
We discuss the mean of all local recurrence rates
̄k = 1
N
N
∑
l=1
kl = 1
N
N
∑
i=1
N
∑
l=1
Ali.

60
|
2 Chaos and dynamical systems
Note that the correlation coefficients are symmetric, Rij = Rji and Rii = 1. By (2.8.1),
Ali = Ail and All = 0. This implies that
̄k = 2
N
N
∑
i=1
i−1
∑
l=1
Ail.
Deﬁne the global recurrence rate
̄ρ as
̄ρ = 1
N ∑N
l=1 ρl. Furthermore,
̄k = 1
N
N
∑
1
(N −1)ρl = (N −1) ̄ρ.
and so
̄ρ =
2
N(N −1) ∑
i<l
Ail =
2
N(N −1) ∑
i<l
(H(ε −distance(Si, Sj)) −δil) .
Let L be the total number of edges in the recurrence network. Then
L = ∑
i<l
Ail =
N
∑
i=1
i−1
∑
l=1
Ail.
This implies that ̄k = 2L
N .
2.8.3 Clustering coefficients
Let N∆
ν be the total number of triangles including vertex ν, and kν be the number of
vertices Sν (i
̸= ν) which are connected directly with Sν. Then
N∆
ν ≤1
2 kν(kν −1).
Deﬁne the local clustering coefficient as
cν =
2
kν(kν −1) N∆
ν
(kν
̸= 0, 1).
Deﬁne the global clustering coefficient as the average of all local clustering coefficients
C = 1
N ∑N
ν=1 cν. For a sufficiently large N, the global clustering coefficient is determined
by the scale ε of resolution. The C is a characteristic parameter which reﬂects the
topology of a network. Let k∗
ν =
1
kν ∑N
i=1 Aνiki, which expresses the mean density of
state in the next neighborhood.
Let ∆kν = kν −k∗
ν , where ∆kν > 0 indicates the local maxima of phase space den-
sity and ∆kν < 0 corresponds to the local density minima.

Further reading
|
61
2.8.4 Path and distance
A path from Si to Sj is an ordered sequence of the vertices {Sk1, . . . , Skτ}, where k1 = i
and kτ = j, and there is an edge between Skl and Skl+1 (l = 0, . . . , τ −1). The number
τ of edges is called the length of the path.
The distance between any two vertices Si and Sj of the network is deﬁned as the
length of the shortest path between them, denoted by lij. The average distance
̃L is
deﬁned as
̃L =
2
N(N −1) ∑
i<j
lij.
Further reading
[1]
Antoci A, Gori L, Sodini M. Nonlinear dynamics and global indeterminacy in an overlapping
generations model with environmental resources. Communications in Nonlinear Science and
Numerical Simulation. 2016(38):59–71.
[2]
Biagioni S, Krashevska V, Achnopha Y, Saad A, Sabiham S, Behling H. 8000 years of vege-
tation dynamics and environmental changes of a unique inland peat ecosystem of the Jambi
Province in Central Sumatra, Indonesia. Palaeogeography, Palaeoclimatology, Palaeoecology.
2015(440):813–829.
[3]
Chen Q, van Dam T, Sneeuw N, Collilieux X, Weigelt M, Rebischung P. Singular spectrum anal-
ysis for modeling seasonal signals from GPS time series. Journal of Geodynamics. 2013(72):
25–35.
[4]
Ding Z, Yi G, Tam VWY, Huang T. A system dynamics-based environmental performance simu-
lation of construction waste reduction management in China. Waste Management. 2016(51):
130–141.
[5]
Donner RV, Zou Y, Donges JF, Marwan N, Kurths J. Recurrence networks – A novel paradigm for
nonlinear time series analysis. New Journal of Physics. 2010(12): 033025.
[6]
Ghil M, Allen MR, Dettinger MD, Ide K, Kondrashov D, Mann ME, Robertson AW, Saunders A,
Tian Y, Varadi F, Yiou P. Advanced spectral methods for climatic time series, Review of Geo-
physics. 2002(40):1003–1043.
[7]
Hassani H, Xu Z, Zhigljavsky A. Singular spectrum analysis based on the perturbation theory.
Nonlinear Analysis: Real World Applications. 2011(12):2752–2766.
[8]
Khan MAR, Poskitt DS. Forecasting stochastic processes using singular spectrum analysis:
Aspects of the theory and application. International Journal of Forecasting. 2016: in press.
[9]
Malta T, Santos PT, Santos AMP, Ruﬁno M, Silva A. Long-term variations in Ibero-Atlantic sar-
dine (Sardina pilchardus) population dynamics: Relation to environmental conditions and
exploitation history. Fisheries Research. 2016(179):47–56.
[10] Moroz IM, Cropp R, Norbury J. Chaos in plankton models: Foraging strategy and seasonal forc-
ing. Ecological Modelling. 2016(332):103–111.
[11] Roques L, Chekroun MD. Probing chaos and biodiversity in a simple competition model. Eco-
logical Complexity. 2011(8):98–104.
[12] Palus M, Novotna D. Detecting modes with nontrivial dynamics embedded in colored noise:
enhanced Monte Carlo SSA and the case of climate oscillations. Physics Letters A. 1998(248):
191–202.

62
|
2 Chaos and dynamical systems
[13] Rose L, Bhaskaran PK. The role of environmental forcing on tidal dynamics along complex near-
shore waters off Bangladesh. Ocean Engineering. 2016(116):68–81.
[14] Sterk AE, Vitolo R, Broer HW, Simo C, Dijkstra HA. New nonlinear mechanisms of midlatitude
atmospheric low-frequency variability. Physica D: Nonlinear Phenomena. 2010(239):702–718.
[15] Sugihara G, May RM. Nonlinear forecasting as a way of distinguishing chaos from measure-
ment error in time series. Nature. 1990(344):734–741.
[16] Takens F. Detecting strange attractors in turbulence, in: Rand DA, Young LS (eds), Dynamical
Systems and Turbulence, Lecture Notes in Mathematics, vol. 898, pp. 366–381, Springer-
Verlag, 1981.
[17] Varsakelis C, Anagnostidis P. On the susceptibility of numerical methods to computational
chaos and superstability. Communications in Nonlinear Science and Numerical Simulation.
2016(33):118–132.
[18] Vitanov NK, Hoffmann NP, Wernitz B. Nonlinear time series analysis of vibration data from a
friction brake: SSA, PCA, and MFDFA. Chaos, Solitons & Fractals. 2014(69):90–99.
[19] Vitanov NK, Sakai K, Dimitrova ZI. SSA, PCA, TDPSC, ACFA: Useful combination of methods for
analysis of short and nonstationary time series. Chaos, Solitons & Fractals. 2008(37):187–202.
[20] Wang S, Huang GH, Baetz BW, Huang W. A polynomial chaos ensemble hydrologic prediction
system for efficient parameter inference and robust uncertainty assessment, Original Research
Article. Journal of Hydrology. 2015(530):716–733.
[21] Zhang F, Zhang G. Dynamics of a low-order atmospheric circulation chaotic model. Optik –
International Journal for Light and Electron Optics. 2016(127):4105–4108.
[22] Zhao Q, Silverman E, Fleming K, Boomer GS. Forecasting waterfowl population dynamics under
climate change – Does the spatial variation of density dependence and environmental effects
matter? Biological Conservation. 2016(194):80–88.

3 Approximation
Environmental data provide huge amounts of information, but it is complex to process
due to the size, variety, and dynamic nature of the data. Approximation of environ-
mental data is one efficient method for extracting meaningful information, so it is
widely applied in environmental modeling and prediction as well as decision-making
and environmental impact assessment. The fundamental problem of approximation
theory is to approximate to complicated data with one or several functions that can
be computed easily. These approximation tools include trigonometric and algebraic
polynomials, spline functions, rational functions, and wavelets. For high-dimensional
data, its approximation rate often becomes slow when the dimensionality increases.
This is the so-called dimension curse problem. In order to solve it, hyperbolic cross
approximations have received much attention in recent years.
3.1 Trigonometric approximation
We state classical results in trigonometric approximation, including Fourier expan-
sion, the decay rate of Fourier coefficients, uniform approximation and square approx-
imation. In particular, we give the Fourier sine (cosine) expansion with a polynomial
term such that we can reconstruct the original function with few Fourier sine (cosine)
coefficients. Furthermore, we also give some results on random approximation.
3.1.1 Fourier series
Let f be a 2π-periodic function on ℝand integrable on [−π, π], denoted by f ∈L2π.
The simplest approximation tool is trigonometric polynomials of degree n,
Tn(x) = a0
2 +
n
∑
1
(ak cos(kx) + bk sin(kx))
(k ∈ℤ+),
where ak and bk are real constants. The series
a0
2 +
∞
∑
1
(an cos(nx) + bn sin(nx))
is called a trigonometric series. If the trigonometric series converges to f(x) uniformly,
i.e.,
f(x) = a0
2 +
∞
∑
1
(an cos(nx) + bn sin(nx))
(3.1.1)
DOI 10.1515/9783110424904-004

64
|
3 Approximation
uniformly, then f(x) must be a 2π-periodic continuous function on ℝ, denote by f ∈
C2π. Applying termwise integration gives a0 = 1
π f(x) dx and
ak = 1
π
π
∫
−π
f(x) cos(kx) dx
(k ∈ℤ+),
bk = 1
π
π
∫
−π
f(x) sin(kx) dx
(k ∈ℤ+).
(3.1.2)
Let f ∈L2π. Then numbers a0, ak, and bk determined by (3.1.2) are called Fourier
coefficients of f . The corresponding trigonometric series (3.1.1) is called the Fourier
series of f .
If f(x) is a 2π-periodic even function, then bn = 0 (n ∈ℤ+). Its Fourier series is
a0
2 + ∑∞
n=1 an cos(nx), where an = 2
π ∫
π
0 f(x) cos(nx) dx (n = 0, 1, . . . ) are called the
Fourier cosine coefficients.
If f(x) is a 2π-periodic odd function, then a0 = 0, an = 0 (n ∈ℤ+). Its Fourier series
is ∑∞
n=1 bn sin(nx), where bn = 2
π ∫
π
0 f(x)sin(nx)dx (n ∈ℤ+) are called the Fourier sine
coefficients.
If f is a 2l-periodic function, a simple transform shows that its Fourier series is
a0
2 +
∞
∑
1
(an cos πnx
l
+ bn sin πnx
l
) ,
where a0 = 1
l ∫
l
−l f(x) dx and
an = 1
l
l
∫
−l
f(x) cos πnx
l
dx,
bn = 1
l
l
∫
−l
f(x) sin πnx
l
dx
(n ∈ℤ+).
For example, let f(x) ∈L2π. If
f(x) =
{
{
{
0,
−π ≤x < 0,
x,
0 ≤x < π,
then its Fourier series is
π
4 +
∞
∑
1
(−1)k −1
k2π
cos(kx) + (−1)k+1
k
sin(kx).
If f(x) = |x| (−π ≤x < π), then f(x) is an even function and its Fourier series is
f(x) = π
2 −4
π
∞
∑
1
cos(2n −1)x
(2n −1)2
.

3.1 Trigonometric approximation
|
65
If f(x) = π−x
2
(0 ≤x < 2π), then f(x) is an odd function and its Fourier series is
f(x) =
∞
∑
1
sin(nx)
n
.
The Riemann–Lebesgue lemma states that if f ∈L2π, then Fourier coefficients
ak →0, bk →0 (k →∞).
The decay rate of Fourier coefficients depends on the smoothness of functions,
while the smoothness of functions are descripted by the differentiability of functions
and Lipschitz indices. If f ∈C(ℝ) and
|f(y) −f(x)| ≤M|y −x|α
((x, y) ∈ℝ),
then we say f ∈lipM α (0 < α ≤1).
Let f ∈C2π and f (m) ∈lipM α. Using integration by parts, the Fourier coefficients
are estimated as
|ak| ≤(2π)αM
km+α
,
|bk| ≤(2π)αM
km+α
(k ∈ℤ+).
(3.1.3)
Denote partial sums of the Fourier series of f by sn(f; x)
sn(f; x) = a0
2 +
n
∑
1
(ak cos(kx) + bk sin(kx)).
A rough estimate of the partial sum approximation is
|f(x) −sn(f; x)| ≤2M
∞
∑
n+1
1
km+α ≤2M
∞
∫
n
1
tm+α dt =
2M
(m + α −1)nm+α−1
and the precise result is
f(x) −sn(f; x) = O ( log n
nm+α )
(x ∈ℝ)
and the bound of the term “O” has a precise estimate.
It is well known that there exists a continuous function with period 2π such that
partial sums of its Fourier series do not converge to it, but the arithmetic mean of
partial sums of its Fourier series must converge to it uniformly, i.e., the following
proposition holds.
Let f ∈C2π and sn(f; x) be the partial sums of its Fourier series. Deﬁne the Fejér
sums as
σn(f; x) = 1
n
n−1
∑
0
sν(f; x).
Then σn(f; x) converges to f(x) on ℝuniformly. This implies the Weierstrass theorem
as follows. For any f ∈C2π and ϵ > 0, there exists a trigonometric polynomial T(x)

66
|
3 Approximation
such that |f(x) −T(x)| < ϵ (x ∈ℝ). Weierstrass theorem shows that any 2π-periodic
continuous function can be uniformly approximated arbitrarily by trigonometric poly-
nomials.
The Fourier series is also expressed in a complex form. Let f ∈L2π. Its complex
Fourier coefficients are
cn = 1
2π
π
∫
−π
f(x) e−inx dx
(n ∈ℤ).
Its Fourier series is ∑n∈ℤcneinx. Comparing this with (3.1.2), we get that c0 = a0 and
ck = 1
2(ak −ibk)
(k > 0),
ck = 1
2(ak + ibk)
(k < 0).
So the partial sums sn(f; x) = ∑n
k=−n ckeikx.
3.1.2 Uniform approximation
Denote by HT
n the set of trigonometric polynomials of degree n. Let f ∈C2π. Consider
the derivation ∆(T) = max|T(x) −f(x)|, where T ∈HT
n is any trigonometric polynomial.
The greatest lower bound
En(f) = inf
T∈HT
n
{ ∆T }
is called the best approximation of f in HT
n. If T(x) is such that max|T(x) −f(x)| = En(f),
then T(x) is called the best approximation trigonometric polynomial in HT
n.
From Weierstrass theorem, it follows that the best approximations En(f) are
monotone decreasing and tend to zero as n →∞. The best approximation poly-
nomial exists and is unique. It is characterized as follows.
For f ∈C2π, En(f) and Tn(x) are its best approximation and best approximation
polynomial in Hn, respectively, if and only if there exist 2n + 2 points 0 ≤x1 < x2 <
⋅⋅⋅< x2n+2 < 2π such that
|Tn(xk) −f(xk)| = En(f)
(k = 1, . . . , 2n + 2),
Tn(xk+1) −f(xk+1) = −(Tn(xk) −f(xk))
(k = 1, . . . , 2n + 2).
So the error curve Tn(x) −f(x) is undamply oscillatory.
Jackson inequality describes the relationship between the smoothness of func-
tions and approximation rate by trigonometric polynomials as follows.
Jackson inequality
If f ∈C2π and f (p) ∈lip α (0 < α ≤1), then
En(f) = O (
1
np+α ) .

3.1 Trigonometric approximation
|
67
Finding the best approximation polynomial is difficult. But the Vallee–Poussin sum
Vn(f; x) = 1
n ∑2n−1
j=n
sj(f; x), where sn(f; x) is the partial sum of Fourier series of the
function f , satisﬁes
max|Vn(f; x) −f(x)| = O (
1
np+α ) .
3.1.3 Square approximation
If f is a 2π-periodic function and ∫
π
−π f 2(x) dx < ∞, then we say f ∈L2
2π. If f ∈L2
2π,
from |f | ≤1
2(1 + f 2), it follows that f ∈L2π. We use a trigonometric polynomial T(x) to
approximate f ∈L2
2π in the mean square sense. Deﬁne the square approximation error
as (∫
π
−π|f(x) −T(x)|2 dx)
1
2 .
Expand f ∈L2
2π into Fourier series
f(x) = a0
2 +
∞
∑
1
(an cos(nx) + bn sin(nx)).
Then, for square approximation, its partial sum
sn(f; x) = a0
2 +
n
∑
1
(ak cos(kx) + bk sin(kx))
attains the best approximation of f in HT
n, i.e., for any trigonometric polynomial Tn(x)
of degree ≤n,
π
∫
−π
(f(x) −sn(f; x))2 dx ≤
π
∫
−π
(f(x) −Tn(x))2 dx.
In applications, the Parseval identity
1
π
π
∫
−π
|f(x)|2 dx = a2
0
2 +
∞
∑
n=1
(a2
n + b2
n)
is often used. Let f be an m-order continuously differentiable function. Consider the
difference
f(x) −sn(f; x) =
∞
∑
n+1
(ak cos(kx) + bk sin(kx)).
By the Parseval identity and (3.1.3), the mean square error is estimated by
1
π
π
∫
−π
(f(x) −sn(f; x))2 dx =
∞
∑
n+1
(a2
k + b2
k) = 2L2
∞
∑
n+1
1
k2m ≤2L2
∞
∫
n
1
t2m dt =
2L2
(2m −1)n2m−1 .

68
|
3 Approximation
3.1.4 Fourier sine expansion with polynomial terms
In applications, the target functions are often smooth functions on an interval. One
periodically extends it to the whole real axis, the obtained function, in general, is
a discontinuous function on the real axis and then expands it into a Fourier series,
the Fourier coefficients decay very slow. Thus one cannot use Fourier coefficients to
compress data. To solve this problem, a Fourier sine expansion with simple polyno-
mial terms is given. Its Fourier coefficients decay fast. This gives a good approximation
tool. The main idea is as follows.
Suppose that the function f is l-order continuous and differentiable on [0, 1], i.e.,
f (l) ∈C[0, 1].
Step 1. We construct a polynomial αn(t) of degree 2n + 1 such that their derivatives
of even orders satisfy
α(2j)
n
(0) = 0,
α(2j)
n
(1) = 0
(0 ≤j ≤n −1),
α(2n)
n
(0) = 0,
α(2n)
n
(1) = 1.
Such αn(t) can be represented as follows:
α0(t) = t,
α1(t) = 1
6 t(t2 −1),
αn(t) =
1
(2n + 1)! t2n+1 +
n−1
∑
0
bkt2k+1
(n = 2, 3, . . . ),
(3.1.4)
where the coefficients {bk}k=0,...,n−1 satisfy
n−1
∑
j
(2k + 1)!
(2k −2j + 1)! bk = −
1
(2n −2j + 1)!
(j = 0, . . . , n −1).
Step 2. We give a decomposition f(t) = g(t) + h(t), where
g(t) =
[ l−1
2 ]
∑
0
(f (2i)(0)αi(1 −t) + f (2i)(1)αi(t))
(3.1.5)
is an algebraic polynomial of degree ≤l and h(t) is the residual. Moreover, it is
easily checked that h(l) ∈C[0,1] and h(2i)(0) = h(2i)(1) = 0 (i = 0,1, . . . , m), where
m = [ l−1
2 ].
Step 3. For the residual h, we do an odd extension and then do periodic extension to
get a 2-periodic odd function which is a continuously differentiable function of
order l on ℝ. We expand it into Fourier sine series
h(t) =
∞
∑
1
bn(h) sin(πnt),
where bn(h) = 2 ∫
1
0 h(t) sin(πnt) dt and bn(h) = O ( 1
nl ), and so the coefficients
decay fast.

3.1 Trigonometric approximation
|
69
Step 4. We get the Fourier expansion with a polynomial term
f(t) = g(t) +
∞
∑
1
bn(h) sin(πnt).
Its partial sum
φN(t) = g(t) +
N
∑
1
bn(h) sin(πnt)
is a good approximation tool, where g(t) is a polynomial of degree ≤l which is
determined by the derivative values of f at x = 0 and x = 1 (see (3.1.5)), and bn(h) =
O( 1
nl ).
The square approximation error is
1
∫
0
|φN(t) −f(t)|2dt = 1
2
∞
∑
N+1
b2
n(h) = O (
1
N2l−1 )
and so f can be reconstructed by the derivative values of f at ends of [0, 1] and few
Fourier coefficients.
3.1.5 Approximations for random processes
If the coefficients of a trigonometric (or algebraic) polynomial are random variables,
this polynomial is called a random trigonometric (or algebraic) polynomial. A random
process ξ(t) on [0, 1] can be well approximated by a combination of random algebraic
polynomials and random trigonometric polynomials.
(a) Calculus of random processes
Let ξ = ξ(t) (t ∈T) be a random process, t0 ∈T and Y be a random variable. If
limt→t0 E[(ξ(t) −Y)2] = 0, then ξ(t) has the limit Y at t0. If limt→t0 ξ(t) = ξ(t0), then
ξ(t) is continuous at t0. If limt→t0
ξ(t)−ξ(t0)
t−t0
= Y, then ξ(t) has the derivative Y at t0.
Write ξ󸀠(t0) = Y. Suppose that ξ(t) and η(t) are both differentiable random processes
and ζ(t) is a differentiable deterministic function. Then the following operation rules
hold:
E[ξ󸀠(t)] = (E[ξ(t)])󸀠,
(αξ(t) + βη(t))󸀠= αξ󸀠(t) + βη󸀠(t),
(ξ(t)ζ(t))󸀠= ξ󸀠(t)ζ(t) + ξ(t)ζ 󸀠(t).
Let ξ = ξ(t) (a ≤t ≤b) be a random process. Given a partition a = t0 < t1 < ⋅⋅⋅< tn = b,
arbitrarily take θk ∈[tk−1, tk] (k = 1, . . . , n). If the limit limδ→0 ∑n
k=1 ξ(θk)(tk −tk−1) = I

70
|
3 Approximation
exists, where δ = maxk|tk −tk−1|, then the random process ξ is integrable on [a, b].
Write ∫
b
a ξ(t) dt = I. If ξ(t) is integrable on [a, b], then
E [
[
b
∫
a
ξ(t) dt]
]
=
b
∫
a
E[ξ(t)] dt.
If ξ(t) is a continuously differentiable random process on [a, b], then ∫
b
a ξ󸀠(t) dt =
ξ(b) −ξ(a).
(b) A good approximation tool for random processes
Let a random process ξ(t) be l-order continuously differentiable on [0, 1]. Then the
random polynomial
η(t) =
[ l−1
2 ]
∑
0
(ξ(2i)(0)αi(1 −t) + ξ(2i)(1)αi(t))
is of degree ≤l, where αi(t) is stated in (3.1.4). So the random process can be decom-
posed into
ξ(t) = η(t) + ζ(t),
called the decomposition formula, where the residual ζ(t) is a random process satisfy-
ing ζ (l) ∈C([0, 1]) and ζ (2l)(0) = ζ (2l)(1) = 0 (i = 1, . . . , m), where m = [ l−1
2 ]. Expand
ζ(t) into Fourier sine series
ζ(t) =
∞
∑
1
cn(ζ) sin(πnt),
where the Fourier sine coefficients cn(ζ) are random variables.
When l = 2m + 1 is odd, noticing that ζ(t) = ξ(t) −η(t) and using integration by
parts l times,
cn(ζ) = 2
1
∫
0
ζ(t) sin(πnt) dt =
2
(πn)l
1
∫
0
ζ (l)(t) cos(πnt) dt
=
2
(πn)l
1
∫
0
(ξ(l)(t) −η(l)(t)) cos(πnt) dt.
Denote τ = η(2m+1)(t). Since η(t) is a random polynomial of degree 2m + 1, τ is inde-
pendent of t, and so
1
∫
0
η(2m+1)(t) cos(πnt) dt = τ
1
∫
0
cos(πnt) dt = 0.

3.1 Trigonometric approximation
|
71
So
cn(ζ) =
2
(πn)l
1
∫
0
ξ(l)(t) cos(πnt) dt.
(3.1.6)
So |E[cn(ζ)]| ≤
2
(πn)l El, where El = max0≤t≤1|El[ξ(l)(t)]|.
Note that Var(cn(ζ)) ≤E[c2
n(ζ)]. From (3.1.6), it follows that
E[c2
n(ζ)] =
4
(πn)2l
1
∫
0
1
∫
0
E[ξ(l)(t)ξ(l)(s)] cos(πnt) cos(πns) dt ds.
By the Schwarz inequality from probability theory,
|E[ξ(l)(t)ξ(l)(s)]| ≤(E[(ξ(l)(t))2]E[(ξ(l)(s))2])
1
2 ≤Vl,
and so Var(cn(ζ)) ≤
4Vl
(πn)2l , where Vl = max0≤t≤1(E[(ξ(l)(t))2]).
When l = 2m is even, the above conclusion is also valid. So, for l ∈ℤ+, the fol-
lowing proposition holds.
Let a random process ξ ∈Cl([0, 1]). Then
ξ(t) =
[ l−1
2 ]
∑
0
(ξ(2i)(0)αi(1 −t) + ξ(2i)(1)αi(t)) +
∞
∑
1
cn(ζ) sin(πnt),
(3.1.7)
E[cn(ζ)] ≤2El
(πn)l ,
Var(cn(ζ)) ≤
4Vl
(πn)2l ,
where cn(ζ) =
2
(πn)l ∫
1
0 ξ(l)(t) cos(πnt) dt, El = max0≤t≤1|E[ζ (l)(t)]|, and Vl = max0≤t≤1
(E[(ξ(l)(t))2]).
Consider the partial sum of the series in (3.1.7)
φN(ξ; t) =
[ l−1
2 ]
∑
0
(ξ(2i)(0)αi(1 −t) + ξ(2i)(1)αi(t)) +
N
∑
1
cn(ζ) sin(πnt).
The mean square error is
1
∫
0
E[(φN(t) −ξ(t))2]dt = 1
2
∞
∑
k+1
E[|cn(ζ)|2] ≤
Vl
(2l −1)(Nπ)2l−1 ,
where Vl is stated as above. The φN(ξ; t) is a good approximation tool, it is a combi-
nation of a random polynomial of degree ≤l and a random trigonometric polynomial
of degree N, where l is the order of derivative of f and N determines the size of error.

72
|
3 Approximation
3.2 Multivariate approximation and dimensionality reduction
Suppose that f is a 2π-periodic function and is integrable on [−π, π]m, denoted by
f ∈L2π(ℝm). Deﬁne its Fourier coefficients as
cn(f) =
1
(2π)m ∫
[−π,π]m f(t) e−in⋅t dt,
where n ⋅t = n1t1 + ⋅⋅⋅+ nmtm and dt = dt1 ⋅⋅⋅dtm. The series ∑n∈ℤm cn(f) ein⋅t is
called the Fourier series of f . By the Riemann–Lebesgue lemma, cn(f) →0 as ‖n‖ =
(∑m
i=1 n2
i )
1
2 →∞.
Denote
D(l1,...,lm) =
∂l1+⋅⋅⋅+lm
∂tl1
1 ⋅⋅⋅∂tlm
m
.
If f ∈L2π(ℝm) and D(l1,...,lm)f ∈C(ℝm), then Fourier coefficients satisfy
cn(f) = O(n−l1
1
⋅⋅⋅n−lm
m ).
If ∫[−π,π]m|f(t)|2 dt < ∞, then the Parseval identity
(2π)m ∫
[−π,π]m|f(t)|2 dt = ∑
n∈ℤm
|cn(f)|2
holds. For the partial sums
sN(f; t) =
N
∑
n1=−N
⋅⋅⋅
N
∑
nm=−N
cn(f) ein⋅t,
the square approximation errors satisfy
e2
N(f) = ∫
[−π,π]m|sN(f; t) −f(t)|2 dt =
1
(2π)m ( ∑
n∈ℤm
−
N
∑
n1=−N
⋅⋅⋅
N
∑
nm=−N
) |cn(f)|2.
If f ∈L2π(ℝm) and D(l,...,l)f ∈C(ℝm), then cn(f) = O ((n1 ⋅⋅⋅nm)−l). This implies that
e2
N(f) = O (
∞
∑
N
1
k2l ) = O (
1
N2l−1 ) .
Note that the number Nc of Fourier coefficients in sN(f; t) satisﬁes Nc ∼Nm. Thus
e2
N(f) = O(N
−2l−1
m
c
).
(3.2.1)
3.2.1 Dimensionality reduction
From (3.2.1), it is seen that the approximation rate becomes very slow as the dimen-
sionality increases. To explain how to solve this dimensionality curse problem, we
take a sine series as an example.

3.2 Multivariate approximation and dimensionality reduction
|
73
Let f be a 2π-periodic function on ℝm and D(l,...,l) ∈C(ℝm). If f is an odd function,
i.e.,
f(t1, . . . , ti−1, −ti, ti+1, . . . , tm)
= −f(t1, . . . , ti−1, ti, ti+1, . . . , tm)
(t = (t1, . . . , tm) ∈ℝm)
for any 1 ≤i ≤m, then f(t) can be expanded into a Fourier sine series f(t) = ∑n∈ℤm
+
cn(f)Tn(t), where
Tn(t) =
m
∏
1
sin(njtj),
cn(f) = 2m
πm ∫
[0,π]m f(t)Tn(t) dt.
The square approximation errors of partial sums sN(f; t) = ∑N
n1,...,nm=1 cn(f)Tn(t) sat-
isfy
e2
N(f) = O (
1
N
2l−1
m
c
) ,
(3.2.2)
where Nc is the number of Fourier sine coefficients in the partial sums sN(f; t).
To solve the dimensionality curse problem, we consider the hyperbolic cross trun-
cations of Fourier sine series. First, we rewrite Fourier sine series in the form
f(t) = ∑
p∈ℤm
+
∑
q∈{0,1}m
c2p+q(f)T2p+q(t),
where {0, 1}m is the set of vertices of the unit cube [0, 1]m. Deﬁne the hyperbolic cross
truncations of Fourier sine series of f as
s(h)
N (f; t) =
∑
1≤|p|≤N
1≤p1,...,pm≤N−1
∑
q∈{0,1}m
c2p+q(f)T2p+q(t),
where p = (p1, . . . , pm) and |p| = ∏m
1 pk. The square approximation errors of hyper-
bolic cross truncations are
(e(h)
N (f))2 = ∫
[0,π]m|s(h)
N (f; t) −f(t)|2 dt = O (logm−1 N
N2l−1
) .
The number Nc of Fourier sine coefficients in s(h)
N (f; t) are Nc ∼N logm−1 N, so
(e(h)
N (f))2 = O (log2l(m−1) Nc
N2l−1
c
) ,
where m is the dimensionality. Comparing this with (3.2.2), since log Nc increases very
slowly, the dimensionality curse problem is basically solved.

74
|
3 Approximation
3.2.2 Bivariate Fourier cosine expansion with simple polynomial factors
A good approximation tool to compress data has been proposed recently. Suppose that
f(t1, t2) ∈C([0, 1]2). If we do the even extension from [0, 1]2 to [−1, 1]2 such that
f(t1, t2) ∈C([−1, 1]2) and
f(t1, t2) = f(−t1, t2) = f(t1, −t2) = f(−t1, −t2)
((t1, t2) ∈[−1, 1]2)
and then do periodic extension from [−1, 1] to ℝ2, we get a 2-periodic even continu-
ous function. So f(t1, t2) can be expanded into the following Fourier cosine series:
f(t1, t2) =
∑
n1,n2∈ℤ
cn1,n2(f) cos(πn1t1) cos(πn2t2),
where
cn1,n2 = λn1,n2 ∫
[0,1]2
f(t1, t2) cos(πn1t1) cos(πn2t2) dt1 dt2
and
λn1,n2 =
{
{
{
{
{
{
{
{
{
1
(n1 = n2 = 0),
4
(n1
̸= 0, n2
̸= 0),
2
otherwise.
Suppose that f is a bivariate function on the unit square [0, 1]2 and D(3,3)f is
continuous on [0, 1]2. If we expand f into a bivariate Fourier series, by discontinuity,
the Fourier coefficients decay very slowly. To reconstruct f by the fewest Fourier co-
sine coefficients, a new approximation tool is constructed. The main idea is to give a
decomposition of bivariate functions for solving the discontinuity problem of partial
derivative functions after periodic extension and use hyperbolic cross truncation to
solve a dimension curse problem.
For D(3,3)f ∈C([0, 1]2), the algorithm is as follows:
Step 1. Based on a fundamental polynomial p(t) = 1
2 t2 −1
6 , we construct a bivariate
polynomial
q(t1, t2) = D(1,1)f(0, 0)p(1 −t1)p(1 −t2) −D(1,1)f(0, 1)p(1 −t1)p(t2)
−D(1,1)f(1, 0)p(t1)p(1 −t2) + D(1,1)f(1, 1)p(t1)p(t2).
(3.2.3)
Denote f1(t1, t2) = f(t1, t2) −q(t1, t2). Clearly,
D(1,1)f1(0, 0) = D(1,1)f1(0, 1) = D(1,1)f1(1, 0) = D(1,1)f1(1, 1) = 0.
Step 2. Deﬁne
f2(t1, t2) = −D(1,0)f1(0, t2)p(1 −t1) + D(1,0)f1(1, t2)p(t1)
−D(0,1)f1(t1, 0)p(1 −t2) + D(0,1)f1(t1, 1)p(t2).

3.2 Multivariate approximation and dimensionality reduction
|
75
Expand the ﬁrst factor of each term on the right-hand side of this formula into
Fourier cosine series
f2(t1, t2) = −(
∞
∑
0
c(1)
n cos(πnt2)) p(1 −t1) + (
∞
∑
0
c(2)
n cos(πnt2)) p(t1)
−(
∞
∑
0
c(3)
n cos(πnt1))p(1 −t2) + (
∞
∑
0
c(4)
n cos(πnt1)) p(t2).
(3.2.4)
Clearly, c(i)
n = O( 1
n3 ) (i = 1, 2, 3, 4).
Step 3. Let f3 = f1 −f2. Then we get a decomposition formula f = q + f2 + f3, where
q = q(t1, t2) is a bivariate polynomial. Clearly, D(1,1)f3(t1, t2) = 0 on the boundary
of [0, 1]2.
Step 4. Expand f3 into a bivariate Fourier cosine series
f3(t1, t2) =
∞
∑
n1,n2=0
cn1,n2(f3) cos(πn1t1) cos(πn2t2).
(3.2.5)
Clearly, |cn1,n2| = O(
1
n3
1n3
2 ). Substituting (3.2.4) and (3.2.5) into the decomposition
f = q + f2 + f3, we get a Fourier cosine expansion of f with a polynomial term
and polynomial factors. The Fourier cosine coefficients decay fast. The hyperbolic
cross truncation of this expansion is
s(h)
N (f3; t1, t2) =
N−1
∑
n1=0
cn1,0(f3) cos(πn1t2)
+
N−1
∑
n2=1
[ N−1
n2 ]−1
∑
n1=0
cn1,n2(f3) cos(πn1t1) cos(πn2t2)
which contains N + ∑N−1
n1=1[ N−1
n1 ] ∼N log N Fourier cosine coefficients.
Step 5. We construct good approximation tools
R(h)
N (f; t1, t2) = q(t1, t2) + s(b)
N (f2; t1, t2) + s(h)
N (f3; t1, t2),
(3.2.6)
where q(t1, t2) and s(h)
N (f3; t1, t2) are stated as above, while s(b)
N (f2; t1, t2) is given
by replacing ∞by N −1 in (3.2.4)
s(b)
N (f2, t1, t3) = −(
N−1
∑
0
c(1)
n cos(πnt2)) p(1 −t1) + (
N−1
∑
0
c(2)
n cos(πnt2)) p(t1)
−(
N−1
∑
0
c(3)
n cos(πnt1))p(1 −t2) + (
N−1
∑
0
c(4)
n cos(πnt1)) p(t2).
In (3.2.6), q(t1, t2) is a bivariate polynomial which is determined by derivative
values of f at (0, 0), (1, 0), (0, 1), and (1, 1), s(b)
N (f2; t1, t2) is a combination of
cosine polynomials and ﬁxed polynomial factors, and s(h)
N (f3; t1, t2) is a bivariate
cosine polynomial.

76
|
3 Approximation
Step 6. Estimate approximation error. We obtain the following estimate:
∬
ℝ2
|R(h)
N (f; t1, t2) −f(t1, t2)|2 dt1 dt2 = ‖R(h)
N (f) −f ‖2 = O (log N
N5 ) .
Denote by Nc the number of cosine coefficients in R(h)
N (f; t1, t2). So
Nc = 5N +
N−1
∑
1
[ N −1
n
] ∼N log N,
and so
‖R(h)
N (f) −f ‖2 = O (log6 Nc
N5
c
) .
If we directly expand f into Fourier cosine series
f(t1, t2) =
∞
∑
n1,n2=0
cn1,n2(f) cos(πn1t1) cos(πn2t2)
and approximate to f(t1, t2) by its partial sum
sn(f; t1, t2) =
N−1
∑
n1,n2=0
cn1,n2(f) cos(πn1t1) cos(πn2t2),
then ‖sN(f) −f ‖2 ∼N
−3
2
c , where Nc is the number of cosine coefficients in sn(f; t1, t2).
Similarly, we can construct the Fourier sine expansion with a polynomial term and
polynomial factors such that Fourier sine coefficients decay fast, and reconstruct f us-
ing fewest Fourier sine coefficients. Generally speaking, the Fourier cosine expansion
is better. Therefore, we only introduce the Fourier cosine expansion here.
3.3 Polynomial approximation
Here we discuss the approximation problem of functions on a ﬁnite interval [a, b] by
algebraic polynomials.
3.3.1 The best uniform approximation and its numerical computation
A continuous function on a closed interval can be approximated by a polynomial, pre-
cisely speaking, if f(x) ∈C([a, b]), then for any given ϵ > 0, there exists a polynomial
P(x) such that |P(x) −f(x)| < ϵ (x ∈[a, b]).
In fact, if f ∈C[−1, 1], then the sequence of Bernstein polynomials of f
(Bnf)(x) =
n
∑
0
f ( k
n )
n!
k!(n −k)! xk(1 −x)n−k
(n ∈ℤ+)
converges uniformly to f(x) on [0, 1] as n →∞.

3.3 Polynomial approximation
|
77
Let f ∈C([a, b]). Denote by Hn the set of polynomials of degree ≤n. Then the best
approximation error of f in Hn is deﬁned as
En(f) = inf
P∈Hn { max
a≤x≤b|P(x) −f(x)|} .
If
̃P ∈Hn and En(f) = maxa≤x≤b| ̃P(x) −f(x)|, then
̃P is called the best approximation
polynomial of f in Hn.
The best approximation polynomial exists and is unique. It is characterized as
follows.
Let f ∈C([a, b]). Then Q(x) is the best approximation polynomial of f in Hn if
and only if there exist n + 2 points a ≤x1 < x2 < ⋅⋅⋅< xn+2 ≤b such that
|Q(xk) −f(xk)| = max
a≤x≤b|Q(x) −f(x)|
(k = 1, . . . , n + 2),
Q(xk) −f(xk) = −(Q(xk+1) −f(xk+1))
(k = 1, . . . , n + 1).
This characterization shows that if Q(x) is the best approximation polynomial,
then the deviation Q(x) −f(x) is an undamped oscillation. It gives a numerical method
to ﬁnd out the best approximation polynomial. Suppose that f ∈C([a, b]) and its
derivative exists on [a, b], and its n-th best approximation polynomial is Pn(x) =
∑n
k=0 αkxk. Then the best approximation error En, the best approximation polynomial
Pn(x), and n + 2 deviation points y1, . . . , yn+2 should satisfy the following 2n + 4
equations:
(f(yk) −Pn(yk))2 = (En)2,
(yk −a)(yk −b)(f 󸀠(yk) −P󸀠
n(yk)) = 0
(k = 1, 2, . . . , n + 2).
(3.3.1)
To solve this system of equations, Remez gave a numerical procedure as follows.
(a) Take initial values a ≤y1 < y2 < ⋅⋅⋅< yn+2 ≤b.
(b) Solve out unknown numbers a0, a1, . . . , an and En from the system of linear
equations
a0 + a1yk + ⋅⋅⋅+ anyn
k −(−1)kEn = f(yk)
(k = 1, 2, . . . , n + 2).
So the polynomial Po
n(x) = ∑n
k=0 ao
kxk and Eo
n are obtained.
(c) Find extreme points x1, x2, . . . , xn+2 of f(x) −Pn(x), where a ≤x1 < x2 < ⋅⋅⋅<
xn+2 ≤b.
(d) Replace yk by xk in (b), solve out a1
0, a1
1, . . . , a1
n and E1
n, and then obtain the
polynomial P1
n(x). Again, take extreme points x1
1, x1
2, . . . , x1
n+2 of f(x) −P1
n(x),
where a ≤x1
1 < x1
2 < ⋅⋅⋅< x1
n+2 ≤b.
Continuing this procedure, the obtained coefficients aν
0, aν
1, . . . , aν
n and Eν
n satisfy
aν
k →αk,
Eν
n →En
(ν →∞).

78
|
3 Approximation
So the best approximation polynomial Pn(x) = ∑n
k=0 αkxk and the best approximation
error En are obtained.
Weierstrass theorem shows that for any f ∈C[a, b], the approximation error En(f)
in Hn monotonically tends to zero as n →∞. The decay rate of En(f) depends on the
smoothness of f .
Let f (p) ∈lip α (0 < α ≤1) on [a, b]. Then the best approximation of f in Hn satis-
ﬁes En(f) ≤
M
np+α , where M is a constant independent of n. The following proposition
indicates that the polynomial approximation becomes better at ends of the interval
[−1, 1].
Let f ∈C[−1,1]. Then there exists a polynomial sequence {Pn(x)} of degree n such
that for −1 ≤x ≤1,
|f(x) −Pn(x)| ≤M(∆n(x))p+α
(0 < α ≤1; p = 0, 1, . . . )
if and only if f (p) ∈lip α, where M is a constant independent of n and x, and
∆n(x) = max (
√1 −x2
n
, 1
n2 ) .
3.3.2 Orthogonal polynomials
Now we consider a polynomial Pn(x) of degree n such that ∫
b
a (f(x) −Pn(x))2 dx is
as small as possible. Such an approximation is called the square approximation of
polynomials. It is different from uniform approximation. If a sequence of polynomi-
als converges uniformly to a function, then the function is continuous. Therefore,
if a function has points of discontinuity, then the function cannot be approximated
by polynomials uniformly. However, a piecewise continuous function can be approx-
imated by polynomials in the square sense. More generally, we consider the weighted
square approximation.
The notation f ∈L2
ρ([a, b]) means that the function f on [a, b] satisﬁes
b
∫
a
ρ(x)f 2(x) dx < ∞,
where ρ(x) ≥0 and ∫
b
a ρ(x)dx = 1. Deﬁne the inner product of f, g ∈L2
ρ([a, b]) as
(f, g)ρ =
b
∫
a
ρ(x)f(x)g(x) dx.
If (f, g)ρ = 0, then f and g are orthogonal with weight ρ. Deﬁne the norm of f ∈
L2
ρ([a, b]) as ‖f ‖ρ = (f, f)1/2
ρ
.

3.3 Polynomial approximation
|
79
Let {Pn}n=0,1,... be a system of n-degree polynomials and ρ be a weight function
on [a, b]. If, for n, m = 0, 1, . . . ,
(Pn, Pm)ρ =
b
∫
a
ρ(x)Pn(x)Pm(x) dx = 0
(n
̸= m),
then {Pn} is said to be a system of orthogonal polynomials on [a, b] with weight ρ.
Again, if (Pn, Pn)ρ = 1 (n = 0, 1, . . . ), then {Pn} is said to be a system of a normal
orthogonal polynomial system.
For any weight function ρ(x) on [a, b], there is a normal orthogonal polynomial
system {ωn(x)}n=0,1,... with weight ρ(x), where ωn(x) is just a polynomial of degree n.
Any f ∈L2
ρ([a, b]) can be expanded into Fourier series with respect to the system
{ωn(x)}n=0,1,... as
f(x) =
∞
∑
0
ckωk(x),
where ck = ∫
b
a f(x)ωk(x)ρ(x) dx, and the Parseval identity holds
b
∫
a
ρ(x)f 2(x) dx =
∞
∑
k=0
c2
k.
Let sn(x) be its partial sum: sn(x) = ∑n
k=0 ckωk(x). Then
b
∫
a
ρ(x)(f(x) −sn(x))2 dx →0
(n →∞).
For any polynomial Pn(x) of degree n,
b
∫
a
ρ(x)(f(x) −Pn(x))2 dx ≤
b
∫
a
ρ(x)(f(x) −sn(x))2 dx,
(3.3.2)
i.e., sn(x) is the best square approximation polynomial in all n-degree polynomials
and the best square approximation error is En = (∑∞
k=n+1 c2
k)
1
2 .
We introduce several important orthogonal polynomials often used in applica-
tions.
(a) Chebyshev polynomials
Tn(x) = cos(n arccos x)
are orthogonal polynomials with weight (1 −x2)−1
2 on [−1, 1]. So T0(x) = 1 and
T1(x) = x, and the recurrence formula holds
Tn+1(x) = 2xTn(x) −Tn−1(x)
(n ≥1).

80
|
3 Approximation
Note that
1
∫
−1
Tn(x)Tm(x)
dx
√1 −x2 =
π
∫
0
Tn(cos θ)Tm(cos θ) dθ
=
π
∫
0
cos(nθ) cos(mθ) dθ = 0
(n
̸= m),
1
∫
−1
T2
n(x)
dx
√1 −x2 =
π
∫
0
cos2(nx) dx =
{
{
{
π
2
(n
̸= 0),
π
(n = 0).
The system
̂T0(x) =
1
√π ,
̂Tn(x) = √2
π cos(n arccos x)
(n ∈ℤ+)
is a normal orthogonal system with weight
1
√1−x2 on [−1, 1].
If ∫
1
−1
f 2(x)
√1−x2 dx < ∞, then f can be expanded into Fourier–Chebyshev series
f(x) =
∞
∑
0
cT
n ̂Tn(x),
where
cT
n =
1
∫
−1
f(x) ̂Tn(x)
dx
√1 −x2 .
Let x = cos θ. Then f(cos θ) = α0 + ∑∞
1 αn cos(nθ), where
α0 = 1
π
π
∫
0
f(cos θ) dθ,
αn = 2
π
π
∫
0
f(cos θ) cos(nθ) dθ
(n ∈ℤ+).
This is just the Fourier cosine expansion of f(cos θ). Chebyshev polynomials have the
following properties:
|Tn(x)| ≤1
(−1 ≤x ≤1),
Tn (cos kπ
n ) = (−1)k
(0 ≤k ≤n),
and their zeros are x(n)
k
= cos (2k+1)π
2n
(k = 0,1, . . . , n). In all monic polynomials Pn(x) =
xn + ∑n
k=1 akxn−k, the polynomial
1
2n−1 Tn(x) is such that max|x|≤1|Pn(x)| attains the
minimal value
1
2n−1 . If we choose the zeros of the Chebyshev polynomial as the interpo-
lation nodes, then a good interpolation approximation formula is given in Chapter 4.

3.3 Polynomial approximation
|
81
(b) Legendre polynomials
Pn(x) =
1
2nn!
dn
dxn (x2 −1)n
are orthonormal polynomials with the weight ρ(x) = 1 on [−1, 1], and P0(x) = 1,
P1(x) = x, P2(x) = 1
2(3x2 −1), and the recurrence formula holds
Pn+1(x) = 2n + 1
n + 1 xPn(x) −
n
n + 1 Pn−1(x)
(n ≥2).
The Legendre polynomial Pn(x) has n real zeros xν = cosθν, where 2ν−1
2n+1 π ≤θν ≤
2ν
2n+1 π
(ν = 1, . . . , n). If we choose zeros of a Legendre polynomial as nodes, a good numerical
integral formula is given in Chapter 6. The system
̂P0(x) = √1
2 P0(x),
̂Pn(x) = √2n + 1
2
Pn(x)
(n ∈ℤ+)
is a normal orthogonal system on [−1, 1] with the weight ρ(x) = 1. If f ∈L2([−1, 1]),
then f can be expanded into Fourier–Legendre series
f(x) =
∞
∑
0
c(P)
n
̂Pn(x),
where
c(P)
n
=
1
∫
−1
f(x) ̂Pn(x) dx.
Its partial sums s(P)
n (f; x) = ∑n
k=0 c(P)
k
̂Pk(x) satisfying
1
∫
−1
(f(x) −s(P)
n (f; x))2 dx →0
(n →∞).
From (3.3.2), it is seen that s(P)
n (f; x) is the best square approximation polynomial in
all polynomials of degree n and the best square approximation error is
en(f) = (
∞
∑
k=n+1
(c(P)
k )2)
1
2
.
(c) Jacobian polynomials
J(α,β)
n
(x) = (1 −x)−α(1 + x)−β (−1)n
2n n!
dn
dxn ((1 −x)n+α(1 + x)n+β)
are orthogonal polynomials on [−1, 1] with the weight (1 −x)α(1 + x)β (α, β > −1).
–
When α = β = 0, J(α,β)
n
(x) = Pn(x) (Legendre polynomial).
–
When α = β = −1
2 , J(α,β)
n
= Tn(x) (Chebyshev polynomial).

82
|
3 Approximation
(d) Laguerre polynomials and Hermite polynomials
Laguerre polynomials and Hermite polynomials are both orthogonal polynomials on
inﬁnite intervals. One uses them to solve the square approximation problems on inﬁ-
nite intervals. The Laguerre polynomials
Ln(x) = ex dn
dxn (xne−x)
(n = 0, 1, . . . )
are orthogonal with weight e−x on [0, ∞), and L0(x) = 1, L1(x) = −x + 1, and the
recurrence formula holds
nLn(x) = (−x + 2n −1)Ln−1(x) −(n −1)Ln−2(x)
(n ≥2).
The Hermite polynomials
Hn(x) = ex2 dn
dxn e−x2
(n = 0, 1, . . . )
are orthogonal with weight e−x2 on (−∞, ∞), and H0(x) = 1, H1(x) = 2x, and the
recurrence formula holds
Hn(x) = 2xHn−1(x) −2(n −1)Hn−2(x)
(n ≥2).
3.4 Spline approximation and rational approximation
In this section, we discuss approximation by piecewise polynomials and the ratio-
nal approximation. For the approximation by piecewise polynomials, we consider not
only the one-dimensional case but also the high-dimensional case. For functions de-
ﬁned in a domain, we use differentiability to describe the smoothness. Sobolev space
is the most important and best known smoothness space.
For 1 ≤p < ∞and r ∈ℤ+, deﬁne the Sobolev space Wr(Lp(Ω)) as the set of all
functions f on Ωwhich have all derivatives Dνf(|ν| ≤r) in Lp(Ω), i.e.,
∫
Ω
|Dνf |p dt < ∞
(|ν| ≤r),
where Dνf =
∂|ν|f
∂t
ν1
1 ⋅⋅⋅∂t
νd
d
. Here ν = (ν1, . . . , νd) and |ν| = ν1 + ⋅⋅⋅+ νd.
For p = ∞and r ∈ℤ+, deﬁne the Sobolev space Wr(L∞(Ω)) as the set of
all functions f on Ωwhose all derivatives Dνf (|ν| ≤r) are continuous on Ωand
maxt∈Ω|Dνf(t)| < ∞(|ν| ≤r), i.e., Wr(L∞(Ω)) = Cr(Ω).
3.4.1 Approximation by piecewise polynomial based on ﬁxed partitions
A partition ∆of Ωis a ﬁnite set, ∆= { C } of subdomains C (such as polyhedrons)
which are pairwise disjoint and union to Ω. Deﬁne a polynomial of degree r on each

3.4 Spline approximation and rational approximation
|
83
subdomain C to obtain a piecewise polynomial relative to the partition ∆. Denote the
set of these piecewise polynomials by Sr(∆). The approximation error of f by elements
of Sr(∆) is deﬁned as
e∆(f)p :=
inf
S∈Sr(∆) (∫
Ω
|f(t) −S(t)|p dt)
1
p
(p < ∞),
e∆(f)∞:=
inf
s∈Sr(∆) (max
t∈∆|f(t) −S(t)|) .
Let Ω= [0, 1]d and let Sr(∆) be the space of piecewise polynomials of order r
relative to ∆, where ∆= { C } is a partition of Ω. Denote diam(∆) := maxC∈∆(diam(C)).
Then, for f ∈Wr(Lp(Ω)), the approximation error e∆(f)p in the space Sr(∆) satisﬁes
e∆(f)p ≤Lr,p(diam(∆))r ∑
|ν|=r
(∫
Ω
|Dνf |p dt)
1
p ,
where Lr,p is a constant independent of f and ∆.
In the one-dimensional case, suppose that f is an r-order continuously differen-
tiable function on [0, 1], i.e., f ∈Cr([0, 1]). Let T : 0 = t0 < t1 < ⋅⋅⋅< tN = 1 be a
partition of [0, 1] and Sr(T) be the set of piecewise polynomials of order r relative to
the partition T. Then the approximation error of f by elements of Sr(T)
eT(f)∞:=
inf
S∈Sr(T) (max
0≤t≤1|f(t) −S(t)|)
satisﬁes
σT(f)∞≤Lr max
0≤t≤1|f (r)(t)|δr
T,
where δT = max0≤k<N|tk+1 −tk| and the constant Lr is independent of f and T.
Especially, suppose that T is a partitionwithequally spaced points, i.e., tk = k
N (k =
0, 1, . . . , N) and δT = 1
N . Then for an r-order continuously differentiable function on
[0, 1], the approximation error of f by piecewise polynomials of order r relative to the
partition is as follows:
σT(f)∞≤Lr max
0≤t≤1 |f (r)(t)| 1
Nr ,
(3.4.1)
where the constant Lr is independent of f and N.
If we try to approximate to f ∈Cr([0, 1]) by an algebraic polynomial P(x) such
that the approximation error satisﬁes (3.4.1), then the degree of P(x) must be greater
than or equal to N. For a large N, this is very difficult. From this, we see an advantage
of piecewise polynomial approximation.
3.4.2 Approximation by piecewise polynomial via free partitions
In approximation by piecewise polynomials, if partitions ∆are not ﬁxed, then we
freely choose partitions depending on the target function f and control the number
N of subdomains.

84
|
3 Approximation
Let r ∈ℤ+ and for each N ∈ℤ+, let ΣN,r be the space of piecewise polynomials of
order r with N pieces on Ω= [0, 1], that is, for each element S ∈ΣN,r, there exists a
partition Λ of Ωconsisting of N disjoint intervals I ⊂Ωand r-degree polynomials PI
such that S = ∑t∈Λ PIχI, where χI is the characteristic function of the interval I.
For 0 < p ≤∞, deﬁne the approximation error as
σN,r(f)p = inf
S∈ΣN,r (
1
∫
0
|f(t) −S(t)|p dt)
1
p
(0 ≤p < ∞),
σN,r(f)∞= inf
S∈ΣN,r (max
0≤t≤1|f(t) −S(t)|) .
The relationship between the approximation error and the smoothness of the target
function is given by Petrushev. The advantage is seen there.
The following example also explains the advantage of free partitions. Let f ∈
C([0, 1]) be a piecewise monotone function and ΣN be the set of piecewise constant
functions on [0, 1] with N pieces. Then there is a constant M > 0 such that the
approximation error
σN(f) = inf
S∈ΣN (max
0≤t≤1|f(t) −S(t)|)
satisﬁes σN(f) = O ( 1
N ). However, if f ∈lip α, we approximate f by piecewise polyno-
mials based on a ﬁxed equally spaced partition T with N pieces, the approximation
error eT(f) cannot attain O( 1
nα ). In applications, if f has different smoothness on each
subinterval, we may choose a partition depending on f such that there are more nodes
in which f is not smooth and fewer nodes in which f is smooth. This gives a good ap-
proximation.
Consider piecewise polynomial approximation with not only free knots but also
free degrees of the polynomial pieces. The theory for this type of approximation is far
from complete.
Let Σ∗
N denote the set of all polynomials S = ∑I∈∆PIχI, where ∆is a partition and
for each I ∈∆, there is a polynomial PI of degree rl with ∑l∈∆rl ≤N. Denote
σ∗
N(f)p = inf
S∈Σ∗
N
(
1
∫
0
|f(t) −SN(t)|p dt)
1
p
.
Clearly, σ∗
Nr(f)p ≤σN,r(f)p. For example, when f(x) = xβ (x ∈[0, 1], β > 0),
σN,r(f)p ≈1
Nr ,
σ∗
N(f)p ≤Ce−(√2−1)√N.

3.4 Spline approximation and rational approximation
|
85
3.4.3 Rational approximation
Let Rn(ℝd) denote the space of rational functions in d variables. Each R ∈Rn is a
quotient R = P/Q, where P and Q are two d variate polynomials of total degree ≤n.
Deﬁne the approximation error as
rn(f)p := inf
R∈Rn‖f −R‖Lp(Ω).
For many functions with less singularity, rational approximation is very efficient.
For example, f(t) = |t| on [0, 1] is approximated by a polynomial of degree ≤n,
the approximation error is En(f)∞≈1
n . However, Newmann showed that if it is approx-
imated by the rational function of total degree ≤n, the approximation error rn(f)∞≤
3e−√n.
In fact, let
rn(t) = t p(t) −p(−t)
p(t) + p(−t) ,
where p(t) = ∏n−1
k=1(t + e−k
√n ). A direct estimate will deduce the above result.
(a) Pade approximation
Suppose that f(x) can be expanded into a power series on [−1, 1]
f(x) = c0 + ∑
k∈ℤ+
ckxk.
We approximate to f by a rational function Rmn(x) = pm(x)/qn(x), where
pm(x) =
m
∑
0
akxk,
qn(x) =
n
∑
0
bjxj.
(3.4.2)
The coefficients {ak}k=0,...,m and {bj}j=0,...,n satisfy the system of linear equations
a0 = c0b0,
a1 = c1b0 + c0b1,
...
am = cmb0 + cm−1b1 + ⋅⋅⋅+ cm−nbn,
cm+1b0 + cmb1 + ⋅⋅⋅+ cm−n+1bn = 0,
cm+2b0 + cm+1b1 + ⋅⋅⋅+ cm−n+2bn = 0,
...
cm+nb0 + cm+n−1b1 + ⋅⋅⋅+ cmbn = 0.

86
|
3 Approximation
This is a system of m + n + 1 linear equations with m + n + 2 unknown. So this system
has a nonzero solution, say a0, a1, . . . , am, b0, b1, . . . , bn, and all its solutions are
ka0, ka1, . . . , kam, kb0, kb1, . . . , kbn for k ∈ℝ. From this and (3.4.2), the unique
rational function Rmn(x) = pm(x)/qn(x) with order (m, n) approximating to f is deter-
mined. The rational function Rmn(x) is called the Pade approximant. When m = n or
m = n + 1, the Pade approximation often gives an exact approximation.
(b) Mahley approximation
Replace the power series expansion in the Pade approximation by the Chebyshev se-
ries expansion to obtain the Mahley approximation.
Suppose that a function f(x) can be expanded into a Chebyshev series uniformly
and absolutely as follows:
f(x) =
∞
∑
0
ckTk(x),
where Tk(x) are Chebyshev polynomials, and approximate to f(x) by a rational func-
tion Rmn(x) = pm(x)/qn(x) of degree (m, n), where
pm(x) =
m
∑
0
akTk(x),
qn(x) =
n
∑
0
bjTj(x).
Then the coefficients {ak}k=0,...,m and {bj}j=0,...,n are the nonzero solution of the sys-
tem of linear equations
a0 = b0c0 + 1
2
n
∑
1
bνcν,
ak = b0ck + 1
2 bkc0 + 1
2
n
∑
ν=1
bν(cν+k + c|ν−k|)
(k = 1, 2, . . . , m + n).
Pade approximation is based on the power series expansion. It sometimes has a
good effect only in a neighborhood at the center for the power series. Comparing these
two kinds of approximations, the effect of Mahley approximation is better than that of
Pade approximation. Especially when the convergence rate of power series expansion
is slow, while the convergence rate of Chebyshev series expansion is quick, their dif-
ference is large.
3.5 Wavelet approximation
Wavelet theory provides a simple and powerful decomposition of the target function
into a series. Multiresolution approximation and the N-term approximation of wavelet
series are often used. Moreover, these algorithms can be generalized easily to the high-
dimensional case.

3.5 Wavelet approximation
|
87
3.5.1 Fourier transforms and wavelet transforms
The Fourier transform of f ∈L(ℝ) is deﬁned as
̂f(ω) = ∫
ℝ
f(t) e−itω dt
(ω ∈ℝ).
If ̂f ∈L(ℝ), the inverse transform is
f(t) = 1
2π ∫
ℝ
̂f(ω) eitω dω
(t ∈ℝ).
For example, the Fourier transform of
f(t) = χ[0,1](t)
is
̂f(ω) = 2 sin ω
ω
,
where χ[0,1] is the characteristic function of [0, 1]; the Fourier transform of
f(t) = e−t2
is
̂f(ω) = √π e−ω2
4 .
The Fourier transform has the following properties:
–
If f ∈L1(ℝ), then limω→∞̂f(ω) = 0.
–
If f (m)(t) is continuous on ℝand f (k) ∈L1(ℝ) for each k, then ̂f(ω) = O (
1
|ω|m ).
–
Operational rules
(f(t + α))∧= eiαω ̂f(ω),
(eibtf(t)∧) = ̂f(ω −b),
(f(λt))∧= 1
|λ|
̂f ( ω
λ ) .
–
Convolution formula (f ∗g)∧(ω) =
̂f(ω) ̂g(ω), where the convolution product of
f, g ∈L1(ℝ) is deﬁned as (f ∗g)(t) = ∫ℝf(t −x)g(x) dx.
The space L2(ℝ) is the set of functions f satisfying ∫ℝ|f(t)|2 dt < ∞.
In the space L2(ℝ),
–
The inner product is deﬁned as (f, g) = ∫ℝf(t) ̄g(t) dt.
–
The norm is deﬁned as ‖f ‖L2 = (∫ℝ|f(t)|2 dt)
1
2 .
If ‖fn −f ‖L2 →0 (n →∞), we say limn→∞fn = f .
–
Fourier transform is deﬁned as ̂f(ω) = limR→∞∫
R
−R f(t) e−iωt dt.
–
Parseval identity ‖ ̂f ‖L2 = ‖f ‖L2 .
Fourier transform of a signal can provide only global frequency information. To obtain
the frequency content of the signal as it evolves with time, one introduces the wavelet
transform.

88
|
3 Approximation
A wavelet is a damped function ψ ∈L2(ℝ) with zero average. The wavelet trans-
form of f ∈L2(ℝ) is deﬁned by
(Wψf)(a, b) =
1
√|a|
∫
ℝ
f(t) ̄ψ ( t −b
a
) dt
(a
̸= 0, b ∈ℝ),
where
̄ψ means the conjugate of ψ. Its inverse formula is
f(t) = 1
cψ
∬
ℝ2
(Wψf)(a, b)
1
√|a|
ψ ( t −b
a
) da
a2 db
(t ∈ℝ),
where cψ = ∫ℝ
| ̂ψ(ω)|2
|ω|
dω < ∞. In applications, Morlet wavelets ψM(t) and Mexican
hat wavelet ψH(t) are often used. They have respectively the representations
ψM(t) = π−1
4 eitθe−t2
2 ,
ψH(t) = −
1
Γ(2.5)(1 −t2) e−t2
2 ,
where θ is a parameter and Γ(t) is the gamma function.
3.5.2 Multiresolution analyses and wavelet bases
Let ψ ∈L2(ℝ). If the integral translations and dyadic dilations of a function ψ
ψmn(t) = 2
m
2 ψ(2mt −n)
(m, n ∈ℤ)
form a normal orthogonal basis for L2(ℝ), then {ψmn}m,n∈ℤis called a wavelet basis
and ψ is called a wavelet. For example, let
ψh(t) =
{
{
{
{
{
{
{
{
{
−1,
0 ≤t < 1
2 ,
1,
1
2 < t < 1,
0,
otherwise.
(3.5.1)
Then the Haar system {2
m
2 ψh(2mt −n)} (m, n ∈ℤ) is a normal orthogonal basis for
L2(ℝ). This is the simplest wavelet basis. The construction of a wavelet basis is based
on multiresolution analysis (MRA).
An MRA consists of a sequence {Vm}m∈ℤof closed subspaces in L2(ℝ) satisfying
(a) Vm ⊂Vm+1, ⋃m∈ℤVm = L2(ℝ), ⋂m∈ℤVm = { 0 };
(b) f ∈Vm if and only if f(2⋅) ∈Vm+1 (m ∈ℤ);
(c) there exists a φ ∈V0 such that {φ(t −n)}n∈ℤis a normal orthogonal basis of V0,
where φ is called a scaling function.
For example, for any m ∈ℤ, let
V(h)
m = { f : f ∈L2(ℝ) and is a constant in each interval ( n
2m , n + 1
2m ) , n ∈ℤ} .

3.5 Wavelet approximation
|
89
Then {V(h)
n }m∈ℤis an MRA with scaling function φh(t) = χ[0,1](t). Another example is
V(s)
m = { f; f ∈L2(ℝ),
̂f(ω) = 0 (|ω| > 2mπ) }
(m ∈ℤ),
where
̂f is the Fourier transform of f . Then {V(s)
m } is an MRA with scaling function
φs(t) = sin(πt)
πt
.
One uses an MRA to construct a wavelet basis as follows.
Step 1. Find the transfer function H satisfying the bi-scale equation
̂φ(2⋅) = H ̂φ, and
H is a 2π-periodic function and ∫
π
−π|H(ω)|2 dω < ∞.
Step 2. Expand H(ω) into Fourier series H(ω) = ∑n∈ℤcneinω, where cn are bi-scale
coefficients.
Step 3. Find the wavelet using the wavelet formula
ψ(t) = −2 ∑
n∈ℤ
(−1)n ̄c1−nφ(2t −n)
or
̂ψ(ω) = e−i ω
2
̄H( ω
2 + π) ̂φ( ω
2 ).
Step 4. The integral translations and dyadic dilations of ψ derive a wavelet basis
{ψm,n(t)}m,n∈ℤ, where
ψmn(t) = 2
m
2 ψ(2mt −n).
For example, from the scaling function φh(t) = χ[0,1], one constructs the Haar wavelet
ψh(t) (see (3.5.1)). Haar wavelet is a discontinuous function. From the scaling function
φs(t) = sin(πt)
πt
, one constructs the Shannon wavelet
ψ(t) = sin 2π(t −1
2) −sin π(t −1
2)
π(t −1
2)
.
Shannon wavelet is inﬁnitely many times differentiable but it decays very slowly. A lot
of good wavelets, such as Meyer wavelets, Battle–Lemarie wavelets, and Daubechies
wavelets, have been constructed.
Meyer wavelets and Battle–Lemarie wavelets have good smoothness and decay
fast. Fourier transform of Meyer wavelets ψ(t) is
̂ψ(ω) =
{
{
{
e−i ω
2 sin ( π
2 ν( 3
2π|ω| −1)) ,
2
3 π ≤|ω| ≤4
3 π,
e−i ω
2 cos ( π
2 ν( 3
4π|ω| −1)) ,
4
3 π ≤|ω| ≤8
3 π,
where ν(x) is an n-degree differentiable real-valued function and
ν(x) =
{
{
{
0
(x ≤0),
1
(x ≥1)
ν(x) + ν(1 −x) = 1
(x ∈ℝ).
Fourier transform of the Battle–Lemarie wavelet ψk(t) of degree k is
̂ψk(ω) = ( 4
iω )
k
e−i ω
2 sin2k ω
4 ( Fk( ω
2 + π)
Fk( ω
2 )Fk(ω))
1
2
,

90
|
3 Approximation
where Fk(2ω) = −sin2k ω
(2k−1)!
d2k−1(cot ω)
dω2k−1
. Especially, F1(ω) = 1 and F2(ω) = 1
3 sin2 ω
2 +
cos2 ω
2 . Daubechies wavelet has good smoothness and is compactly supported. It is
introduced in Section 6.6.
Let {ψmn}m,n∈ℤbe a wavelet basis. Then f ∈L2(ℝ) can be expanded into a wavelet
series
f(t) =
∑
m,n∈ℤ
dmnψmn(t)
in L2-sense, where
dmn = (f, ψmn) = ∫
ℝ
f(t) ̄ψmn(t) dt
are called wavelet coefficients. Another wavelet expansion formula is that for M ∈ℤ,
f(t) = ∑
n∈ℤ
cMnφMn(t) +
∞
∑
m=M
∑
n∈ℤ
dmnψmn(t),
where φ is the scaling function and
φMn(t) = 2
M
2 φ(2Mt −n),
cMn = (f, φMn).
Moreover, {φMn(t)}n∈ℤand {ψmn}m=M,M+1,...; n∈ℤare a normal orthogonal basis for
L2(ℝ).
If f has few nonnegligible wavelet coefficients dmn and scale coefficients cMn,
then f can be approximated by the sum of few terms in these expansions. This is very
useful in data compression and noise removal.
We say ψ has p vanishing moments if ∫ℝtkψ(t) dt = 0 (k = 0, . . . , p). If f is
smooth and the wavelet ψ has a high vanishing moment, the Taylor theorem shows
that wavelet coefficients of the ﬁne-scale are small.
3.5.3 High-dimensional wavelets
The notion of multiresolution analyses (MRA) is generalized easily to the high-
dimensional space L2(ℝd).
An MRA consists of a sequence {Vm}m∈ℤof closed subspaces in L2(ℝd) satisfying
(a) Vm ⊂Vm+1,
⋃m∈ℤVm = L2(ℝd),
⋂m∈ℤVm = { 0 };
(b) f ∈Vm if and only if f(2⋅) ∈Vm+1 (m ∈ℤ);
(c) there exists a φ ∈V0 such that {φ(t −n)}n∈ℤd is a normal orthogonal basis of V0,
where φ is called a scaling function.
One may use a high-dimensional MRA to construct a high-dimensional wavelet basis
as follows.

3.5 Wavelet approximation
|
91
As in the one-dimensional case, the scaling function φ satisﬁes
̂φ(2ω) = H(ω) ̂φ(ω)
(ω ∈ℝd),
where H is a 2π-periodic function in ℝd and ∫[−π,π]d|H(ω)|2 dω < ∞. Let H0 = H.
Denote by {0, 1}d the set of vertices of [0, 1]d. For example, {0, 1}2 = { (0, 0), (0, 1),
(1, 0), (1, 1)}. Take 2d −1 functions {Hμ}μ∈{0,1}d\{0} with period 2π such that the 2d ×
2d matrix (Hμ(ω + πν))μ,ν∈{0,1}d is a unitary matrix. Let {ψμ}μ∈({0,1}d\{0}) be such that
̂ψμ(2ω) = Hμ(ω) ̂φ(ω)
(μ ∈({0, 1}d \ {0})),
ψμmn(t) = 2
md
2 ψμ(2mt −n).
Then {ψμmn}μ∈({0,1}d\{0}),m∈ℤ,n∈ℤd form an normal orthogonal basis for L2(ℝd).
The following is the simplest method for constructing a high-dimensional wavelet
basis.
Suppose that φ is a univariate scaling function and ψ is the corresponding
wavelet. Denote ψ0 = φ and ψ1 = ψ. For each nonzero vertex e = (e1, . . . , ed) ∈
{0, 1}d \ {0}, deﬁne a d-variate function
ψe(t1, . . . , td) = ψe1(t1) ⋅⋅⋅ψed(td).
The set Ψ = { ψe, e ∈{0, 1}d \ {0} } is a d-variate wavelet and
ψe
mn(t) = 2
md
2 ψe(2mt −n)
(m ∈ℤ, n ∈ℤd)
is a d-dimensional wavelet basis, where t = (t1, . . . , td). Each f ∈L2(ℝd) can be ex-
panded into a wavelet series
f =
∑
e∈{0,1}d\{0}
∑
m∈ℤ
∑
n∈ℤd
ce
mnψe
mn,
where ce
mn = (f, ψe
mn) = ∫ℝd f(t)ψe
m,n(t) dt.
Especially, the two-dimensional wavelets are
ψ(1)(t) = φ(t1)ψ(t2),
ψ(2)(t) = ψ(t1)φ(t2),
ψ(3)(t) = ψ(t1)ψ(t2),
where t = (t1, t2) ∈ℝ2, and
ψ(k)
mn(t) = 2mψ(k)(2mt −n),
m ∈ℤ, n ∈ℤ2
(k = 1, 2, 3)
is a bivariate wavelet basis.

92
|
3 Approximation
3.5.4 Wavelet packet
The emergence of the concept of the wavelet packet enables us to construct many nor-
mal orthogonal bases from an MRA. Wavelet packet is deﬁned as follows.
Let {Vm} be a d-dimensional MRA with scaling function φ and 2d transfer func-
tions {Hμ}μ∈{0,1}d . The corresponding wavelets {ψμ} satisfy
̂ψμ(ω) = Hμ ( ω
2 ) ̂φ ( ω
2 ) ,
μ ∈({0, 1}d \ {0}).
Deﬁne ψν1,...,νj such that
̂ψν1,...,νj(ω) =
̂φ ( ω
2j )
j
∏
1
Hνi ( ω
2i ) ,
where each νi ∈{0, 1}d (i = 1, . . . , j). Let νi be the
̃νli -th vertex in {0, 1}d. Denote
l = ̃νl1 + 2d ̃νl2 + ⋅⋅⋅+ 2(j−1)d ̃νlj , where ̃ν1, ̃ν2, . . . , ̃ν2d are an arbitrary serial number of
{0,1}d. Then l corresponds to the set ν1, . . . , νj one-to-one. Denote ωl(t) = ψν1,...,νj(t).
The system
{ 2
md
2 ωl(2mt −k) }l,m∈ℤ∗
+,k∈ℤd
is called a wavelet packet, where ℤ∗
+ = ℤ+ ⋃{ 0 }.
Let S be the set of pairs (l, m) (l, m ∈ℤ∗
+). From a wavelet packet the question is
how to choose S such that {2
md
2 ωl(2mt −k)}(l,m)∈S,k∈ℤd form an normal orthogonal
basis for L2(ℝd)? The answer is as follows. Denote
Ilm = { τ ∈ℤ∗
+ : 2mdl ≤τ < 2md(l + 1) },
where l ∈ℤ∗
+, m ∈ℤ∗
+.
Then
{ 2
md
2 ωl(2mt −k) }(l,m)∈S,k∈ℤd
is an normal orthogonal basis for L2(ℝd) if and only if the set S ∈ℤ∗
+ × ℤ∗
+ is such that
{Ilm}(l,m)∈S forms a partition of ℤ∗
+.
For example, let τ ∈ℤ∗
+ and
S = {(l, m): (l, m) ∈([0, 2τd) × { 0 }) ⋃([ 2τd, 2(τ+1)d) × ℤ∗
+)} .
Then {Ilm}(l,m)∈S is a disjoint covering of ℤ∗
+. In fact, since Ilm ((l, m) ∈S) are disjoint,
from
⋃
2τd≤l<2(τ+1)d
Ilm = [2(τ+m)d, 2(τ+m+1)d) ⋂ℤ∗
+,
⋃
m∈ℤ∗
+
(
⋃
2τd≤l<2(τ+1)d
Ilm) = [2τd, ∞) ⋂ℤ∗
+,
it follows that ⋃(l,m)∈S Ilm = ℤ∗
+, and so
{ 2
md
2 ωl(2mt −k),
k ∈ℤd, (l, m) ∈S }

3.5 Wavelet approximation
|
93
is a normal orthogonal basis for L2(ℝd). When τ = 0, S = {(l, m): (l, m) ∈([0, 1] ×
{ 0 }) ⋃([1, 2d) × ℤ∗
+)}, and so
{ φ(t −k), 2
md
2 ωl(2mt −k), 1 ≤l < 2d, m = 0, 1, . . . , k ∈ℤd }
is a normal orthogonal basis for L2(ℝd).
For example, let S = ℤ∗
+ × { 0 }. Then Il0 = { l } and ⋃l∈ℤ∗
+ Il0 = ℤ∗
+. So { ωl(t −
k) }l∈ℤ∗
+,k∈ℤd is a normal orthogonal basis for L2(ℝd).
3.5.5 Wavelet decomposition and pyramid algorithm
Let {Vm}m∈ℤbe an MRA with scaling function φ and the corresponding wavelet ψ.
Since ⋃mVm = L2(ℝ), for f ∈L2(ℝ), one can choose a sufficiently large L such that
f ≈ProjVL f =: fL,
where ProjVL f is the projection of f on the space VL. Since Vm ⊂Vm+1 (m ∈ℤ),
Vm+1 = Vm ⨁Wm
(m ∈ℤ),
(3.5.2)
where Wm is the orthogonal complement space of Vm on Vm+1. Moreover, {φmn}n∈ℤ
and {ψmn}n∈ℤare normal orthogonal bases of Vm and Wm, respectively. Let
fm = ProjVm f,
gm = ProjWm f.
(3.5.3)
Then fm+1 = fm + gm (m ∈ℤ) and
fm+1(t) = ∑
n∈ℤ
cm+1,nφm+1,n(t),
fm(t) = ∑
n∈ℤ
cmnφmn(t),
gm(t) = ∑
n∈ℤ
dmnψmn(t).
By (3.5.2) and (3.5.3), for l < L,
VL = Vl +
L
⨁
m=l
Wm,
fL = fl +
L
∑
m=l
gm.
This gives a wavelet decomposition formula: for the sufficiently large L,
f(t) ≈fL(t) = ∑
n∈ℤ
cLnφLn(t)
= ∑
n∈ℤ
clnφln(t) +
L−1
∑
m=l
∑
n∈ℤ
dmnψmn(t)
for some l < L,

94
|
3 Approximation
where cmn = (f, φmn) and dmn = (f, ψmn). In applications, a lot of coefficients are neg-
ligible. So the series ∑n∈ℤcLnφLn(t) has only ﬁnitely many terms. From this decompo-
sition formula, one uses the following pyramid algorithm to fast compute coefficients
cln, dmn (m = l, . . . , L −1) from ﬁnite many coefficients cLn, while there is no need to
compute each coefficient by integrals.
Pyramid algorithm provides a fast algorithm that can compute coefficients {cmn}
and {dmn}. From the bi-scale equation and the wavelet formula, it follows that
φ(t) = ∑
k∈ℤ
pkφ(2t −k),
ψ(t) = ∑
k∈ℤ
qkφ(2t −k),
where pk = 2ck and qk = 2(−1)k+1 ̄c1−k, and ck are the bi-scale coefficients. The de-
composition and synthesis formulas in the pyramid algorithm are, respectively,
cmn = ∑
l∈ℤ
̄pl−2ncm+1,l,
dmn = ∑
l∈ℤ
̄ql−2ncm+1,l
and
cm+1,n = ∑
l∈ℤ
pn−2lcml + ∑
l∈ℤ
qn−2ldml.
These formulas can fast compute {cmn}n∈ℤ, {dmn}n∈ℤ, and {cm+1,n}n∈ℤ.
Consider the two-dimensional case.
Let φ and ψ be the univariate scaling function and the corresponding univariate
wavelet. Then φ(t1)φ(t2) is a bivariate scaling function and φ(t1)ψ(t2), ψ(t1)φ(t2),
ψ(t1)ψ(t2) are the corresponding bivariate wavelets. For f ∈L2(ℝ2) and sufficiently
large L,
f(t1, t2) ≈(ProjVL f)(t1, t2) =
∑
n1∈ℤ
∑
n2∈ℤ
cL
n1n2φLn1(t1)φLn2(t)
=
∑
n1∈ℤ
∑
n2∈ℤ
c(l)
n1n2φln1(t1)φln2(t2)
+
L−1
∑
m=l
∑
n1∈ℤ
∑
n2∈ℤ
d(1,m)
n1n2 φmn1(t1)ψmn2(t2)
+
L−1
∑
m=l
∑
n1∈ℤ
∑
n2∈ℤ
d(2,m)
n1n2 ψmn1(t1)φmn2(t2)
+
L−1
∑
m=l
∑
n1∈ℤ
∑
n2∈ℤ
d(3,m)
n1n2 ψmn1(t1)ψmn2(t2),
where
hmn(t) = 2
m
2 h(2mt −n)
(n = (n1, n2))

3.5 Wavelet approximation
|
95
and the coefficients are, respectively,
c(m)
n1n2 = ∫
ℝ2
f(t1, t2) ̄φMn1(t1) ̄φMn2(t2) dt1 dt2,
d(1,m)
n1n2 = ∫
ℝ2
f(t1, t2) ̄φmn1(t1) ̄ψmn2(t2) dt1 dt2,
d(2,m)
n1n2 = ∫
ℝ2
f(t1, t2) ̄ψmn1(t1) ̄φmn2(t2) dt1 dt2,
d(3,m)
n1n2 = ∫
ℝ2
f(t1, t2) ̄ψmn1(t1) ̄ψmn2(t2) dt1 dt2.
The decomposition formulas are
c(m)
n1n2 =
∑
l1,l2∈ℤ
̄pl1−2n1 ̄pl2−2n2c(m+1)
l1l2
,
d(1,m)
n1n2 =
∑
l1,l2∈ℤ
̄pl1−2n1 ̄ql2−2n2c(m+1)
l1l2
,
d(2,m)
n1n2 =
∑
l1,l2∈ℤ
̄ql1−2n1 ̄pl2−2n2c(m+1)
l1l2
,
d(3,m)
n1n2 =
∑
l1,l2∈ℤ
̄ql1−2n1 ̄ql2−2n2c(m+1)
l1l2
and the reconstruction formula is
4c(m+1)
n1n2
=
∑
l1,l2∈ℤ
̄pl1−2n1 ̄pl2−2n2c(m)
l1l2 + ∑
l1,l2∈ℤ
̄pl1−2n1 ̄ql2−2n2d(1,m)
l1l2
+ ∑
l1,l2∈ℤ
̄ql1−2n1 ̄pl2−2n2d(2,m)
l1l2
+ ∑
l1,l2∈ℤ
̄ql1−2n1 ̄ql2−2n2d(3,m)
l1l2 .
3.5.6 Multiresolution approximation
Let {Vm}m∈ℤbe an MRA of L2(ℝd) with scaling function φ. Deﬁne the best approxi-
mation of f ∈L2(ℝd) in the space Vm as
Em(f)2 = inf
s∈Vm‖f −s‖L2(ℝd).
Since ⋃mVm = L2(ℝd) and Vm ⊂Vm+1 (m ∈ℤ), then Em(f)2 →0 as m →∞.
Suppose that φ ∈Wr(L2(ℝd)) satisﬁes the Strang–Fix condition of order r ∈ℤ+
̂φ(0) = 0,
Dj ̂φ(2kπ) = 0
(k ∈ℤd \ {0}, |j| < r),
where
Dj =
∂|j|
∂tj1
1 ⋅⋅⋅∂tjd
d
,
t = (t1, . . . , td), j = (j1, . . . , jd), |j| = j1 + ⋅⋅⋅+ jd.

96
|
3 Approximation
Then
Em(f)2 ≤C2−mr ∑
|j|≤r
(∫
ℝd|Djf(t)|p dt)
1
p ,
where C is a constant independent of m, f , and s. Since the best approximation of f
in Vm is ProjVm f ,
‖f −ProjVm f ‖L2(ℝd) = O ( 1
2mr ) ,
where ‖g‖L2(ℝd) = (∫ℝd|g(t)|2 dt)
1
2 . Since φmn(t) = 2
md
2 φ(2mt −n) (n ∈ℤd) is an ortho-
normal basis of Vm, we expand ProjVm f into Fourier series
ProjVm f = ∑
n∈ℤd
cmnφmn(t),
where the coefficients
cmn = (ProjVm f, φmn) = (f, φmn) = ∫
ℝd f(t)φmn(t) dt.
If the scaling function φ(t) decays fast as t →∞, then a lot of coefficients cmn ≈0.
Therefore, few coefficients cmn are used for a good approximation.
The above approximation takes place in L2(ℝd). There is a similar result for ap-
proximation in Lp(ℝd).
3.5.7 The N-term wavelet approximation and thresholding value methods
Wavelets on intervals have been constructed and extended to those on parallelepipeds
and polyhedral domains in ℝd. However, constructing wavelets on general domains is
very difficult. For wavelet approximation in general domains, after the target function
is extended smoothly to the whole space, we consider the N-term wavelet approxima-
tion and thresholding value methods.
(a) The N-term approximation
In numerical analysis the target functions f are often deﬁned on a ﬁnite domain Ω
with boundary Lipschitz condition. If the wavelet ψe (e ∈{0, 1}d/(0, 0)) is compactly
supported, then there are a lot of (m, n) such that ψe
mn(t) = 0 (t ∈Ω). Thus, a lot of
terms in the wavelet expansion of f can be deleted. The best N-term approximation
for f can be obtained by choosing the N-terms in the wavelet expansion
N
∑
l=1
cel
ml,nlψel
ml,nl,
where |ce1
m1,n1| ≥|ce2
m2,n2| ≥⋅⋅⋅≥|ceN
mN,nN | are largest in absolute value of all coefficients
{ce
mn}.

3.5 Wavelet approximation
|
97
(b) Thresholding value methods
In numerical implementation one likes to use thresholding value methods. For con-
venience, we consider the one-dimensional case. Expand the target function f into a
wavelet series
f = ∑
mn
cmn(f)ψmn.
Let Λη(f) be the set of all pairs (m, n) satisfying |cmn(f)| > η. Denote by #(Λη(f)) the
cardinality of the set Λη(f). If f satisﬁes a condition that there exists a τ > 0 such that
for all η > 0,
#(Λη(f)) ≤Mτ
f η−τ,
where Mf is a constant depending only on f , then for a given ε > 0, the thresholding
operator
Tε(f) =
∑
(mn)∈Λε(f)
cmn(f)ψmn =
∑
|cmn|>ε
cmn(f)ψmn
satisﬁes
‖f −Tε(f)‖L2(R) ≤CM
τ
2
f ε1−τ
2 ,
where C is an absolute constant. When ε = Mf N−1
τ , #Λε(f) ≤N, and so the N-term
approximation is estimated by
‖f −Tε(f)‖L2(R) ≤CMf N
1
2 −1
τ .
This result is easily extended to Lp-approximation.
The thresholding operator has an instability. To improve it, the soft thresholding
operator sε(t) is introduced by
sε(t) :=
{
{
{
{
{
{
{
{
{
0
(|t| < ε),
2(|t| −ε) sgn t
(ε ≤|t| ≤2ε),
t
(|t| > 2ε).
The soft thresholding operator sε(t) has the same approximation properties as the
thresholding operator Tε.
(c) Data compression
In the lossy compression replacing the original data by an approximation, we choose
a multivariate scaling function φ and then expand the original data I into a series
I(t) ∼∑
n∈ℤd
cmnφ(2mt −n).
Using the decomposition formula of the pyramid algorithm, we obtain a wavelet ex-
pansion
I(t) ∼∑
n∈ℤd
c0nφ(t −n) +
m−1
∑
k=0
∑
e∈{0,1}d\{0}
∑
n∈ℤd
de
knψe
kn(t)

98
|
3 Approximation
and then we use thresholding to give a compressed ﬁle { ̃de
kn} of wavelet coefficients.
The compressed coefficient ﬁle is further compressed using a lossless encoder. From
the encoded compressed ﬁle of wavelet coefficients, we use a decoder and then use
the synthesis formula of the pyramid algorithm to give the reconstructed data.
3.6 Greedy algorithms
In this section we regard Hilbert space H as L2(ℝd). An arbitrary subset of the Hilbert
space is called a dictionary. In applications, one considers the N-term approximation
from the dictionary D, i.e., the approximation to f ∈H by a linear combination of
N-terms in the dictionary D.
In time frequency analysis, the translations of Gabor functions gα,β(t) := eiαte−βt2
generate a dictionary D in L2(ℝ), i.e.,
D := { gα,β(t −γ): α, β, γ ∈ℝ}.
In an MRA of L2(ℝd), the wavelet packet {ωl}l=0,1,... has been constructed in Sec-
tion 3.5. The integral translations and dyadic dilations of the wavelet packet generate
a dictionary D in L2(ℝd), i.e.,
D := { ωl,m,n(t) = 2
m
2 ωl(2mt −n), l = 0, 1, . . . ; m, n ∈ℤ}.
For a general dictionary D and any τ > 0, M > 0, deﬁne K0
τ(D, M) as the set of
functions f satisfying
f = ∑
g∈Λ
cg g
(Λ ⊂D, #Λ < ∞),
∑
g∈Λ
|cg|τ ≤Mτ,
where #Λ represents the cardinality of Λ. Let Kτ(D, M) be the closure of K0
τ(D, M) in
H, and let
Kτ(D) = ⋃
M>0
Kτ(D, M).
Deﬁne
|f |Kτ(D) = inf{ M: f ∈Kτ(D, M) }.
(3.6.1)
Greedy algorithms are often used in numerical analysis. Most often greedy algo-
rithms are as follows.
3.6.1 Pure greedy algorithm
The advantage of this algorithm is its simplicity. Let f ∈H. The algorithm is as follow.
Let h = h(f) ∈D be such that
(f, h(f)) = sup
h∈D
(f, h)

3.6 Greedy algorithms
|
99
where (f, g) = ∫ℝd f(t) ̄g(t) dt. Deﬁne
U1(f) = (f, h(f))h(f),
R1(f) = f −U1(f),
U2(f) = U1(f) + U1(R1(f)),
R2(f) = f −U2(f).
For each m ≥2, inductively deﬁne
Um(f) = Um−1(f) + U1(Rm−1(f)),
Rm(f) = f −Um(f).
Because at each iteration of the algorithm it approximates to the residual Rm(f) as best
possible by a single function from the dictionary D, this algorithm is called the pure
greedy algorithm.
If the dictionary D is generated by an orthonormal basis, then Um(f) is a best m-
term approximation of f from D, i.e.,
σm(f; D) := inf
s∈Σm‖f −s‖ = ‖f −Um‖,
where Σm is the set of linear combinations s = ∑h∈Λ ch h (Λ ⊂D, #Λ ≤m). However,
for a general dictionary, the pure greedy algorithm only gives an estimate as follows.
For f ∈K1(D),
‖f −Um(f)‖ ≤|f |K1(D)m−1
6
(m ∈ℤ+),
where |f |K1(D) is stated in (3.6.1).
3.6.2 Relaxed greedy algorithm
The relaxed greedy algorithm is an improvement of the pure greedy algorithm. Let
f ∈H and D be any dictionary of H. The relaxed greedy algorithm is follows.
Deﬁne
U(r)
0 (f) = 0,
R(r)
0 (f) = f,
U(r)
1 (f) = U1(f),
R(r)
1 (f) = R1(f),
where U1(f) and R1(f) are stated in Section 3.6.1.
For a function g ∈H, let h = h(g) ∈D be such that (g, h) = supτ∈D(g, τ). Inductively
deﬁne
U(r)
m (f) = (1 −1
m) U(r)
m−1(f) + 1
m h(R(r)
m−1(f)),
R(r)
m (f) = f −U(r)
m (f).
The relaxed greedy algorithm give an estimate as follows. For f ∈K1(D),
‖f −U(r)
m (f)‖ ≤Cm−1
2
(m ∈ℤ+),
where C is a constant. In this estimate, the approximation order is m−1
2 . From this, it
is seen that it has better approximation properties than the pure greedy algorithm.

100
|
3 Approximation
3.6.3 Orthogonal greedy algorithm
The orthogonal greedy algorithm is also an improvement of the pure greedy algorithm.
Let H0 be a ﬁnite-dimensional subspace of the Hilbert space H. The orthogonal
greedy algorithm is as follows. Deﬁne
U(0)
0 (f) = 0,
R(0)
0 (f) = f.
For m ≥1, inductively deﬁne
Hm = span{ h(R(0)
0 )(f), . . . , h(R(0)
m−1)(f) },
U(0)
m (f) = PHm(f),
R(0)
m (f) = f −U(0)
m (f),
where h(g) is stated in Section 3.6.2 and PHm is the best approximation to f in Hm.
The orthogonal greedy algorithm has the following estimate:
‖f −U(0)
m (f)‖ ≤|f |K1(D)m−1
2
(m ∈ℤ+).
(3.6.2)
In this estimate, the approximation order is m−1
2 . From this, it is seen that it has better
approximation properties than the pure greedy algorithm. But in this algorithm, the
computation of the projection PHm is more expensive.
Based on the estimate (3.6.2), the m-term approximation from a dictionary has a
good result as follows.
If f ∈Kτ(D) and 1
τ = α + 1
2 , and α ≥1
2 , then
σm(f; D) := inf
s∈Σm‖f −s‖ ≤C |f |Kτ(D)m−α
(m ∈ℤ+),
where C depends on τ if τ is small and each s ∈Σm can be written in the form s =
∑h∈Λ ch h (Λ ⊂D, #Λ ≤m).
Further reading
[1]
Alhasan A, White DJ, De Brabanterb K. Continuous wavelet analysis of pavement proﬁles. Au-
tomation in Construction. 2016(63):134–143.
[2]
Bolten M, Huckle TK, Kravvaritis CD. Sparse matrix approximations for multigrid methods.
Linear Algebra and its Applications. 2016(502):58–76.
[3]
Fang J, Lin S, Xu Z. Learning and approximation capabilities of orthogonal super greedy algo-
rithm. Knowledge-Based Systems. 2016(95):86–98.
[4]
Liu D, Yan P, Wei Q. Data-based analysis of discrete-time linear systems in noisy environment:
Controllability and observability. Information Sciences. 2014(288):314–329.
[5]
Morkisz PM, Plaskota L. Approximation of piecewise Holder functions from inexact information.
Journal of Complexity. 2016(32):122–136.
[6]
Moteki N. Discrete dipole approximation for black carbon-containing aerosols in arbitrary mix-
ing state: A hybrid discretization scheme. Journal of Quantitative Spectroscopy and Radiative
Transfer. 2016(178):306–314.

Further reading
|
101
[7]
Safarinejadian B, Estahbanati ME. A novel distributed variational approximation method for
density estimation in sensor networks. Measurement. 2016(89):78–86.
[8]
Sharma V, Yang D, Walsh W, Reindl T. Short term solar irradiance forecasting using a mixed
wavelet neural network. Renewable Energy. 2016(90):481–492.
[9]
Yi H, Shu H. The improvement of the Morlet wavelet for multi-period analysis of climate data.
Comptes Rendus Geoscience. 2012(344):483–497.
[10] Zhang Z. Fourier expansions with polynomial terms for random processes. Journal of Function
Spaces. 2015:1–13. doi:10.1155/2015/763075.
[11] Zhang Z. Hyperbolic cross truncations for stochastic Fourier cosine series. The Scientiﬁc World
Journal. 2014:1–13. doi:10.1155/2014/265031.
[12] Zhang Z, Saito N. PHLST with adaptive tiling and its application to Antarctic remote sensing
image approximation. Inverse Problems and Imaging. 2014(8):321–337.
[13] Zhang Z, Jorgensen P. Modulated Haar wavelet analysis of climatic background noise. Acta
Appl Math. 2015(140):71–93.
[14] Zhu X, Gisbrecht A, Schleif FM, Hammer B. Approximation techniques for clustering dissimilar-
ity data. Neurocomputing. 2012(90):72–84.
[15] Zou CX, Shen XD, Li HY, Li XZ, Li ZJ. Wavelet analysis of spring climate characteristics in arid ae-
olian area of agro-pastoral ecotone in China. Water Science and Engineering. 2012(5):269–277.

4 Interpolation
Data records with equidistant time intervals are fundamental prerequisites for the de-
velopment of environmental modeling, simulation and impact assessment. Usually
long-term environmental time series contain missing data or data with different sam-
pling intervals. Interpolation can be used to handle missing environmental data or
ﬁll the intervals between two grid points so that series of measurements with small
intervals are kept. In this chapter we will discuss curve ﬁtting, Lagrange and Hermite
interpolations, spline interpolation, trigonometric interpolation, and bivariate inter-
polation.
4.1 Curve ﬁtting
Given observation data (xk, yk)(k = 1, . . . , M), we will ﬁnd a polynomial P(x) of degree
N (N < M) such that the sum ∑M
k=1(P(xk) −yk)2 attains the minimal value. This is the
so-called curve ﬁtting problem.
4.1.1 Polynomial ﬁtting
Let (xk, yk) (k = 1, . . . , M) be the observation data. Take a polynomial with unknown
a0, a1, . . . , aN
f(x) = a0 + a1x + ⋅⋅⋅+ aNxN
(N < M)
to ﬁt these data. Denote
F(a0, a1, . . . , aN) =
M
∑
1
(f(xk) −yk)2 =
M
∑
1
(a0 + a1xk + ⋅⋅⋅+ aNxN
k −yk)2.
For ν = 0, . . . , N, let ∂F
∂aν = 0. Then
M
∑
1
(a0 + a1xk + a2x2
k + ⋅⋅⋅+ aNxN
k −yk)xν
k = 0.
Denote Rl = ∑M
k=1 xl
k and Sν = ∑M
k=1 ykxν
k. Then
Rνa0 + Rν+1a1 + Rν+2a2 + ⋅⋅⋅+ Rν+NaN = Sν
(ν = 0, 1, . . . , N)
or
N
∑
i=0
Rν+iai = Sν
(ν = 0, 1, . . . , N).
This is a system of N + 1 linear equations with N + 1 unknown, and so it has a unique
solution a∗
0, a∗
1, . . . , a∗
N .
DOI 10.1515/9783110424904-005

4.1 Curve ﬁtting
|
103
Proposition 4.1.1. If a∗
0, a∗
1, . . . , a∗
N is the solution of the system of linear equations
N
∑
i=0
Rν+iai = Sν
(ν = 0, 1, . . . , N),
then the polynomial ﬁtting of data { xk, yk }k=1,...,M is f(x) = ∑N
ν=0 a∗
ν xν.
It is more convenient to choose a linear combination of orthogonal polynomials to ﬁt
data. For the given observation data (xk, yk) (k = 1, . . . , M), assume that {xk} sat-
isfy −1 = x1 < x2 < ⋅⋅⋅< xM = 1 and are equally spaced. Choose the following linear
combination of normal Legendre polynomials
̂Pn(x) (see (3.3.1)) to ﬁt the data
f(x) = a0 ̂P0(x) + a1 ̂P1(x) + ⋅⋅⋅+ aN ̂PN(x).
Let
F(a0, a1, . . . , aN) =
M
∑
k=1
(f(xk) −yk)2 =
M
∑
k=1
(
N
∑
μ=0
aμ ̂Pμ(xk) −yk)
2
.
Then ∂F
∂aν = 0 (ν = 0, 1, . . . , N) is equivalent to
M
∑
k=1
(
N
∑
μ=0
aμ ̂Pμ(xk) −yk) ̂Pν(xk) = 0
(ν = 0, 1, . . . , N).
The left-hand side is equal to ∑N
μ=0 (∑M
k=1
̂Pμ(xk) ̂Pν(xk)) aμ −∑M
k=1 yk ̂Pν(xk). So
N
∑
μ=0
αμ,νaμ −βν = 0
(ν = 0, 1, . . . , N),
(4.1.1)
where
αμ,ν =
M
∑
k=1
̂Pμ(xk) ̂Pν(xk),
βν =
M
∑
k=1
yk ̂Pν(xk).
(4.1.2)
Since x1, . . . , xM are equally spaced nodes on [−1, 1] and normal Legendre polyno-
mials satisfy
1
∫
−1
̂Pν(x) ̂Pμ(x) dx = δνμ,
where δνμ is the Kronecker delta, we get
αμ,ν =
M
∑
k=1
̂Pμ(xk) ̂Pν(xk) ≈0
(μ
̸= ν),
αν,ν =
M
∑
k=1
̂P2
ν(xk) ≈M −1
2
.
From this and (4.1.1), aν ≈
2βν
M−1 (ν = 0, 1, . . . , N), where βν are stated in (4.1.2).

104
|
4 Interpolation
Proposition 4.1.2. Let −1 = x0 < x1 < ⋅⋅⋅< xM = 1 and let them be equally spaced,
and data (xk, yk) (k = 0, 1, . . . , M) be given. Then the polynomial ﬁtting data is f(x) =
∑N
ν=0 βν ̂Pν(x), where βν ≈
2
M−1 ∑M
k=1 yk ̂Pν(xk) and
̂Pν(x) is the ν-th normal Legendre
polynomial.
Now we consider the orthogonal polynomial with weight function to ﬁt the given data.
Given data (xk, yk) (k = 1, . . . , M) satisfying a = x1 < x2 < ⋅⋅⋅< xM = b, the
normal orthogonal polynomials P(ρ)
ν (x) (ν = 0, 1, . . . ) on [a, b] with weight function
ρ(x) satisfy
b
∫
a
P(ρ)
μ (x)P(ρ)
ν (x)ρ(x) dx = δμ,ν,
where δμ,ν is the Kronecker delta. Then the polynomial ﬁtting data is
f(x) =
N
∑
μ=0
β(ρ)
μ P(ρ)
μ (x),
where
β(ρ)
μ
≈
2
M −1
M
∑
k=1
ykP(ρ)
μ (xk)ρ(xk).
4.1.2 Orthogonality method
In ﬁtting data using the orthogonality method, the BC-decomposition of matrices is
crucial.
BC-decomposition
Let A be an M × N matrix with rank r, where M ≥N. Then the matrix A can be de-
composed into A = BC, where B is an M × r matrix, C is an r × N matrix, and ranks
of B and C are both r.
In fact, let A = (αij)M×N and aj = (α1j, . . . , αMj)T (j = 1, . . . , N) be its j-th col-
umn vector. Since rank(A) = r, there are r linearly independent column vectors. Say,
a1, a2, . . . , ar are the r linearly independent column vectors. We construct an ortho-
normal basis e1, e2, . . . , eM on ℝM such that for any s = 2, . . . , M,
es ⊥aj
(j = 1, . . . , s −1).
Let P = (e1|e2| ⋅⋅⋅|eM). Then P is an orthogonal matrix of order M. Deﬁne U = PTA.
Since PT = P−1,
A = PU.
Let U = (ukl)M×N , where ukl = (ek, al). Since a1, a2, . . . , ar are linearly indepen-
dent, al = ∑r
j=1 cjlaj (l > r). From this and es ⊥aj, it follows that ukl = (ek, al) =

4.1 Curve ﬁtting
|
105
∑r
j=1 cjl(ek, aj) = 0 (k > r). Denote
̃B = (ukl)k,l=1,...,r and
̃C = (ukl)k=1,...,r; l=r+1,...,N . So
U = (
̃B
̃C
0
0)
and the product PU only depends on the ﬁrst r columns of P and the ﬁrst r rows of
U, and A = PU = BC, where B = (e1|e2| ⋅⋅⋅|er) and C = ( ̃B| ̃C).
Consider a general system of linear independent functions φ1(x), φ2(x), . . . ,
φN(x). We use their linear combination F(x) to ﬁt observation data (xi, yi) (i =
1, . . . , M), where M ≫N, such that
γ2 :=
M
∑
i=1
(
N
∑
j=1
βjφj(xi) −yi)
2
attains the minimal value. Some often used function systems are the power function
system {xi}, the trigonometric function system sin(ix), and the exponential function
system { eλix }.
Let ∂F
∂βj = 0. Then
M
∑
i=1
φj(xi) (
N
∑
j=1
βjφj(xi) −yi) = 0
(i = 1, . . . , M).
(4.1.3)
This is a system of linear equations. The matrix form is AT(Aβ −y) = 0, where
A = (αij)M×N,
β = (β1, . . . , βN)T,
y = (y1, . . . , yM)T,
and αij = φj(xi) (i = 1, . . . , M; j = 1, . . . , N). Denote by β∗= (β∗
1, . . . , β∗
N) the solution
of (4.1.3). Then the combination ﬁtting data is ∑N
j=1 β∗
j φj(x). We solve out β = β∗below.
Replacing A by its BC-decomposition in the matrix form of (4.1.3),
CTBTBCβ = CTBTy.
Multiplying both sides by C,
(CCT)(BTB)Cβ = (CCT)BTy.
Both CCT and BTB are r × r nonsingular matrices and rank(B) = rank(C) = r, so
Cβ = W,
where W = (BTB)−1BTy.
This implies that CT(CCT)−1Cβ = CT(CCT)−1W. Note that CT(CCT)−1C = I. The desired
solution is
β∗= CT(CCT)−1W = CT(CCT)−1(BTB)−1BTy.
Write β∗= (β∗
1, . . . , β∗
N). So the combination F(x) ﬁtting data is ∑N
j=1 β∗
j φj(x).

106
|
4 Interpolation
4.2 Lagrange interpolation
Given a real sequence yk (k = 1, . . . , n) and nodes xk (k = 1, . . . , n), where x1 < x2 <
⋅⋅⋅< xn, we construct a Lagrange interpolation polynomial Ln(x) of degree n −1 such
that Ln(xk) = yk (k = 1, . . . , n). Moreover, we introduce the uniform convergence and
mean convergence of the Lagrange interpolation polynomial sequences.
4.2.1 Fundamental polynomials
Let ωn(x) be the product of n factors (x −xk) (k = 1, . . . , n), i.e.,
ωn(x) = (x −x1)(x −x2) ⋅⋅⋅(x −xn).
Then ωn(x) is a polynomial of degree n and ωn(xk) = 0 (k = 1, . . . , n), and
ω󸀠
n(xk) = (xk −x1) ⋅⋅⋅(xk −xk−1)(xk −xk+1) ⋅⋅⋅(xk −xn)
(k = 1, . . . , n).
Deﬁne fundamental polynomials as
lk(x) =
ωn(x)
ω󸀠n(xk)(x −xk)
(k = 1, . . . , n).
(4.2.1)
Then lk(x) is a polynomial of degree n −1 and lk(xj) = δjk for j, k = 1, . . . , n, where
δjk is the Kronecker delta.
Let P(x) be any polynomial of degree n −1. Then P(x) = ∑n
k=1 P(xk)lk(x). In fact,
let
Q(x) =
n
∑
1
P(xk)lk(x).
Then Q(x) is a polynomial of degree n −1 and Q(xk) = P(xk) (k = 1, . . . , n). These n
pairs of values determine that P(x) = Q(x), i.e., P(x) = ∑n
k=1 P(xk)lk(x).
4.2.2 Lagrange interpolation polynomials
Lagrange interpolation polynomial of degree n −1 is deﬁned as
Ln(x) =
n
∑
1
yk lk(x) =
n
∑
1
yk
ωn(x)
ω󸀠n(xk)(x −xk) .
(4.2.2)
Clearly, Ln(xj) = yj (j = 1, . . . , n). Formula (4.2.2) is called the Lagrange interpolation
formula. For convenience of computation, it is rewritten in the form
Ln(x) = c0 + c1(x −x1) + c2(x −x1)(x −x2) + ⋅⋅⋅
+ cn−1(x −x1)(x −x2) ⋅⋅⋅(x −xn−1).
(4.2.3)

4.2 Lagrange interpolation
|
107
This form is called the Newton interpolation formula. The coefficients {ck} are com-
puted as follows.
c0 = y1,
c1 = y2 −c0
x2 −x1
,
...
ck−1 = yk −c0 −∑k−2
l=1 cl(xk −x1) ⋅⋅⋅(xk −xl)
(xk −x1) ⋅⋅⋅(xk −xk−1)
(k = 3, . . . , n).
The combination of Lagrange and Newton interpolation formulas gives
ck−1 =
k
∑
ν=1
yν
ω󸀠
k(xν)
(k = 1, . . . , n).
(4.2.4)
When we add a node, if we use the Lagrange interpolation formula, this again
necessitates computing each fundamental polynomial li(x); if we use the Newton in-
terpolation formula, the coefficients already computed do not have to be changed.
Therefore, in numerical computations, it is best to use the Newton interpolation for-
mula.
Let f ∈Cn([a, b]) and a ≤x1 < ⋅⋅⋅< xn ≤b, and Ln(x) be the Lagrange interpolation
polynomial of degree n −1. Then the error between the interpolation polynomial and
the original function is
f(x) −Ln(x) = 1
n! f (n)(ξx)ωn(x)
(a < ξx < b),
(4.2.5)
and so
max
a≤x≤b |f(x) −Ln(x)| ≤1
n! max
a≤x≤b |f (n)(x)|(b −a)n.
4.2.3 Equally spaced nodes and Chebyshev nodes
Consider equally spaced nodes
x1 = a,
x2 = a + h,
...
xn = a + (n −1)h.
Then
ω󸀠
k(xν) = (xν −x1) ⋅⋅⋅(xν −xν−1)(xν −xν+1) ⋅⋅⋅(xν −xk)
= (−1)k−νhk−1(ν −1)!(k −ν)! .

108
|
4 Interpolation
From this and (4.2.4),
ck−1 =
1
hk−1
k
∑
ν=1
(−1)k−ν
(ν −1)!(k −ν)! yν =
∆k−1y1
hk−1(k −1)! ,
where ∆k−1y1 is the (k −1)-th difference. From this and (4.2.3), it follows that
Ln(x) = y1 +
n−1
∑
ν=1
(x −a)(x −a −h) ⋅⋅⋅(x −a −(ν −1)h)
ν! hν
∆νy1.
This formula is called the Newton interpolation formula with equally spaced nodes.
Consider the equally spaced nodes x(n)
k
= −1 + 2k
n (k = 0, 1, . . . , n). The Lagrange
interpolation polynomials of f(x) = |x| (−1 ≤x ≤1) do not converge to f(x) as n →∞
except x = −1, 0, 1. Therefore, we need to look for other nodes.
Consider Chebyshev nodes xk = cos (2k−1)π
2n
(k = 1, . . . , n), i.e., the zeros of Cheby-
shev polynomial Tn(x) = cos(narccosx). The term of highest degree of Tn(x) is 2n−1xn.
So
ωn(x) =
1
2n−1 Tn(x) =
1
2n−1 cos(n arccos x),
(4.2.6)
ω󸀠
n(x) =
n
2n−1
√1 −T2n(x)
√1 −x2
,
ω󸀠
n(xk) =
n
2n−1√1 −x2
k
.
By (4.2.1),
lk(x) =
Tn(x)
n(x −xk)
√1 −x2
k
and the Lagrange interpolation formula with Chebyshev nodes is
Ln(x) = Tn(x)
n
n
∑
1
yk
x −xk
√1 −x2
k.
By (4.2.6), |ωn(x)| ≤
1
2n−1 (|x| ≤1). From this and the error formula (4.2.5), it follows
that for the Chebyshev nodes x1, . . . , xn, the interpolation error is
|f(x) −Ln(x)| =
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
1
n! f (n)(ξx)ωn(x)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
≤
1
2n−1n! max
|t|≤1 |f (n)(t)|.
From this, it is seen that Chebyshev nodes are optimal nodes since |ωn(x)| ≤
1
2n−1
(|x| ≤1) holds if and only if the nodes x1, . . . , xn are Chebyshev nodes.
4.2.4 Convergence of interpolation polynomials
Given a continuous function f , if Pn is an interpolation polynomial of f with n nodes,
we expect that {Pn} converges to f as n →∞. Consider the triangular matrix of nodes

4.2 Lagrange interpolation
|
109
on [a, b]
x(1)
1
x(2)
1 ,
x(2)
2
...
...
x(n)
1 ,
x(n)
2 ,
. . . ,
x(n)
n .
The sequence of Lagrange interpolation polynomials of f ∈C([a, b]) is
Ln(x) =
n
∑
k=1
f(x(n)
k )l(n)
k (x)
(n ∈ℤ+),
where l(n)
k (x) (k = 1, . . . , n) are fundamental polynomials based on nodes x(n)
k
(k =
1, . . . , n)
l(n)
k (x) =
ωn(x)
ω󸀠n(x(n)
k )(x −x(n)
k )
,
where ωn(x) = ∏n
k=1(x −x(n)
k ).
Proposition 4.2.1. Let f ∈C([a, b]) and its best approximation by polynomials of de-
gree n be En, and let
λn(x) =
n
∑
k=1
|l(n)
k (x)|,
λn = max
a≤x≤b |λn(x)|.
If limn→∞λnEn−1 = 0, then the Lagrange interpolation polynomial Ln(x) converges to
f(x) on [a, b] uniformly.
For Chebyshev nodes x(n)
k
= cos (2k−1)π
2n
(k = 1, . . . , n),
λn = max
0≤x≤1 λn(x) ≤8 + 4
π log n.
If f ∈C([−1, 1]) and f is a piecewise differentiable function on [−1, 1], then f ∈lip 1.
From this and the Jackson inequality in Section 3.1, En = O( 1
n), and so
lim
n→∞λnEn−1 = 0.
By Proposition 4.2.1, the interpolation polynomial Ln(x) with Chebyshev nodes con-
verges uniformly to f(x) on [−1, 1].
There exists a continuous function f(x) on [−1, 1] such that its Lagrange inter-
polation polynomial with Chebyshev nodes diverges everywhere. But, in fact, for any
triangular matrix {x(n)
k }k=1,...,n, there exists a continuous function such that its La-
grange interpolation polynomials do not converge to itself uniformly.

110
|
4 Interpolation
4.2.5 Mean convergence
From Section 3.3, we see that Legendre polynomials are orthogonal polynomials with
weight 1. They have n different zeros on [−1, 1]. It is convenient to choose the zeros of
Legendre polynomials as nodes for mean convergence, and the following proposition
holds.
Let nodes {x(n)
k }k=1,...,n be zeros of the n-th Legendre polynomial. If f ∈C([−1, 1]),
then its Lagrange interpolation polynomial Ln(x) converges to f(x) in the mean square
sense, i.e.,
lim
n→∞
1
∫
−1
(Ln(x) −f(x))2 dx = 0.
For orthogonal polynomials on [a, b] with weight ρ(x), their zeros {x(n)
k }k=1,...,n
are all simple zeros and a < x(n)
1
< x(n)
2
< ⋅⋅⋅< x(n)
n
= b, and can be estimated precisely.
The product
ωn(x) = (x −x(n)
1 )(x −x(n)
2 ) ⋅⋅⋅(x −x(n)
n )
is an orthogonal polynomial with the ﬁrst term coefficient 1 and has a simple and
clear representation, and its derivative ω󸀠
n(x(n)
k ) is estimated easily. Take these zeros
x(n)
k
(k = 1, . . . , n) as nodes. For f ∈C([a, b]), the Lagrange interpolation polynomials
Ln(x) with nodes x(n)
k
(k = 1, . . . , n) converges to f(x) in the mean square sense
lim
n→∞
b
∫
a
(Ln(x) −f(x))2ρ(x) dx = 0.
Especially, for f ∈C([−1, 1]), the Lagrange interpolation polynomial with Chebyshev
nodes xk = cos (2k−1)π
2n
(k = 1, . . . , n) satisﬁes
lim
n→∞
1
∫
−1
(Ln(x) −f(x))2
1
√1 −x2 dx = 0.
4.3 Hermite interpolation
For nodes xk (k = 1, . . . , n) satisfying x1 < x2 < ⋅⋅⋅< xn, we will ﬁnd the lowest
polynomial H(x) such that H(l)(xk) = y(l)
k (k = 1, . . . , n; l = 0, 1, . . . , αk −1), i.e.,
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
H(xk) = yk,
H󸀠(xk) = y󸀠
k,
...
H(αk−1)(xk) = y(αk−1)
k
(k = 1, . . . , n).

4.3 Hermite interpolation
|
111
Such a polynomial exists and is unique. The polynomial H(x) is called the Hermite
interpolation polynomial.
If α1 = α2 = ⋅⋅⋅= αn = 1, the Hermite interpolation polynomial is reduced to the
Lagrange interpolation polynomial. If n = 1, the Hermite interpolation polynomial is
reduced to the Taylor polynomial
H(x) = y1 + y󸀠
1
1! (x −x1) + ⋅⋅⋅+
yα1−1
1
(α1 −1)!(x −x1)α1−1.
4.3.1 Hermite interpolation formula with remainder term
Assume that f ∈Cm([a, b]), where m = α1 + ⋅⋅⋅+ αn, and nodes xk ⊂[a, b] (k =
1, . . . , n), and its Hermite interpolation polynomial H(x) satisfying H(l)(xk) = f (l)(xk)
(k = 1, . . . , n; l = 0, 1, . . . , αk −1). Then the error formula is as follows:
f(x) = H(x) + f (m)(ξ)
m!
Ω(x)
(a < ξ < b),
where Ω(x) = (x −x1)α1(x −x2)α2 ⋅⋅⋅(x −xn)αn and m = α1 + α2 + ⋅⋅⋅+ αn.
4.3.2 Interpolation polynomial with double points
When α1 = ⋅⋅⋅= αn = 2, the problem is reduced to ﬁnding a polynomial H(x) of degree
2n −1 satisfying
H(xk) = yk,
H󸀠(xk) = y󸀠
k
(k = 1, . . . , n).
The polynomial H(x) is called the interpolation polynomial with double points.
Let
P2n−1(x) =
n
∑
1
yk (1 −ω󸀠󸀠
n (xk)
ω󸀠n(xk) (x −xk)) l2
k(x),
Q2n−1(x) =
n
∑
1
y󸀠
k(x −xk)l2
k(x).
where ωn(x) = (x −x1) ⋅⋅⋅(x −xn) and lk(x) are fundamental polynomials stated in
Section 4.2. Then
P2n−1(xk) = yk,
P󸀠
2n−1(xk) = 0,
Q2n−1(xk) = 0,
Q󸀠
2n−1(xk) = y󸀠
k
(k = 1, . . . , n).
Both P2n−1(x) and Q2n−1(x) are polynomials of degree 2n −1. The following propo-
sition holds.

112
|
4 Interpolation
Given two real number sequences yk, y󸀠
k (k = 1, . . . , n) and nodes xk (k =
1, . . . , n), where x1 < ⋅⋅⋅< xn, the Hermite interpolation polynomial H2n−1(x) satis-
fying
H2n−1(xk) = yk,
H󸀠
2n−1(xk) = y󸀠
k
(k = 1, . . . , n)
can be decomposed in the form
H2n−1(x) = P2n−1(x) + Q2n−1(x).
Especially, for the case n = 2, given real numbers y1, y2 and y󸀠
1, y󸀠
2, and nodes
x1, x2, the Hermite interpolation polynomial H3(x) satisfying
H3(x1) = y1,
H3(x2) = y2,
H󸀠
3(x1) = y󸀠
1,
H󸀠
3(x2) = y󸀠
2
can be decomposed into
H3(x) = P3(x) + Q3(x),
where
P3(x) = y1 (1 −
2
(x1 −x2)(x −x1)) ( x −x2
x1 −x2
)
2
+ y2 (1 −
2
(x2 −x1)(x −x2)) ( x −x1
x2 −x1
)
2
,
Q3(x) = y󸀠
1(x −x1) ( x −x2
x1 −x2
)
2
+ y󸀠
2(x −x2) ( x −x1
x2 −x1
)
2
.
(4.3.1)
Let f ∈C([−1, 1]) and x(n)
k
= cos (2k−1)π
2n
(k = 1, . . . , n) be Chebyshev nodes.
If H2n−1(x) is a polynomial of degree 2n −1 satisfying H2n−1(x(n)
k ) = f(x(n)
k ) and
H󸀠
2n−1(x(n)
k ) = 0, then the polynomial H2n−1(x) converges to f(x) on [−1, 1] uniformly.
Such an interpolation method is called the Féjer interpolation method.
4.4 Spline interpolation
Spline interpolation is to replace polynomials by piecewise polynomials as interpola-
tion functions and requires that piecewise polynomials are smooth at each node.
4.4.1 Spline functions
Given nodes a = x0 < x1 < ⋅⋅⋅< xn = b, if s(x) is a constant on each interval [xk, xk+1]
(k = 0, . . . , n −1), then s(x) is called a spline function of degree 0 with nodes xk
(k = 0, . . . , n). If s(x) is a liner function on each interval [xk, xk+1] and s ∈C([a, b]),
then s(x) is called a spline function of degree 1. In general, if s(x) is a polynomial of

4.4 Spline interpolation
|
113
degree m on each interval [xk, xk+1] and s ∈Cm−1([a, b]), then s(x) is called a spline
function of degree m.
For a spline function s(x) of degree m, let dk = s(m)(xk + 0) −s(m)(xk −0), and let
smk be the restriction of s(x) on [xk, xk+1], i.e., smk = s|[xk,xk+1). Then
smk(x) = sm,k−1(x) + R(x),
where R(x) is a polynomial of degree m. From s(x) ∈Cm−1([a, b]), it follows that
R(l)(xk) = 0
(l = 0, 1, . . . , m −1),
R(m)(xk) = dk.
So
smk(x) = sm,k−1(x) +
dk
(m −1)!(x −xk)m−1.
Introduce two notations x+ = max(0, x) and xm−1
+
= (x+)m−1 (m ≥2). Then
s(x) = s|[x0,x1)(x) +
n−1
∑
k=1
dk
(m −1)!(x −xk)m−1
+
.
The general structure of spline functions is as follows.
Proposition 4.4.1. Let s(x) be a spline function of degree m with nodes x0 < x1 < ⋅⋅⋅<
xn. Then there exist c0, . . . , cm and d1, . . . , dn−1 such that
s(x) = c0 + c1x + ⋅⋅⋅+ cmxm +
n−1
∑
k=1
dk
(m −1)!(x −xk)m−1
+
.
4.4.2 Spline interpolation
Given nodes a = x0 < x1 < ⋅⋅⋅< xn = b and numerical values y0, y1, . . . , yn, if a function
s(x) satisﬁes
(a) s(x) is a polynomial of degree ≤3 on each subinterval [xk−1, xk) (k = 1, . . . , n),
(b) s(xk) = yk (k = 0, 1, . . . , n) and s(x) ∈C2([a, b]),
then s(x) is called a cubic spline function on [a, b].
Let s(x) be a cubic spline function on [a, b]. Then s(x) satisﬁes on each interval
[xk, xk+1)
s(xk) = yk,
s(xk+1) = yk+1.
Denote
s󸀠(xk) = μk,
s󸀠(xk+1) = μk+1,

114
|
4 Interpolation
where {μk}k=1,...,n are unknown. By (4.3.1),
s(x) = (1 + 2 x −xk
δk
) ( x −xk+1
δk
)
2
yk + (1 −2 x −xk+1
δk
) ( x −xk
δk
)
2
yk+1
+ (x −xk) ( x −xk+1
δk
)
2
μk + (x −xk+1) ( x −xk
δk
)
2
μk+1,
(4.4.1)
where δk = xk+1 −xk. This implies that
s󸀠󸀠(x) = ( 6
δ2
k
−12
δ3
k
(xk+1 −x)) yk + ( 6
δ2
k
−12
δ3
k
(x −xk)) yk+1
+ ( 6
δk
−6
δk
(xk+1 −x)) μk −( 2
δk
−6
δ2
k
(x −xk)) μk+1.
(4.4.2)
Thus, the right-derivative and the left-derivative are, respectively,
s󸀠󸀠(x+
k) = −6
δ2
k
yk + 6
δ2
k
yk+1 −4
δk
μk −2
δk
μk+1
(k = 0, 1, . . . , n −1),
s󸀠󸀠(x−
k) =
6
δ2
k−1
yk−1 −
6
δ2
k−1
yk +
2
δk−1
μk−1 +
4
δk−1
μk
(k = 0, 1, . . . , n −1).
Since s󸀠󸀠(x+
k) = s󸀠󸀠(x−
k) (k = 1, . . . , n −1),
2
δk−1
μk−1 + 4 ( 1
δk−1
+ 1
δk
) μk + 2
δk
μk+1
= −6
δ2
k−1
yk−1 + ( 6
δk−1
−6
δ2
k
) yk + 6
δ2
k
yk+1
(k = 1, . . . , n −1).
Finding unknown μ0, μ1, . . . , μn meets three kinds of boundary conditions. The
ﬁrst kind is
s󸀠(x0) = μ0,
s󸀠(xn) = μn.
The second kind is
s󸀠󸀠(x0) = 0,
s󸀠󸀠(xn) = 0.
From this and (4.4.2), it follows that
2μ0 + μ1 = 3
δ0
(y1 −y0),
μn−1 + 2μn =
3
δn−1
(yn −yn−1).
The third kind is that s(x) is a periodic function with period xn −x0, in this case,
y0 = yn, and
s󸀠(x0) = s󸀠(xn),
s󸀠󸀠(x0) = s󸀠󸀠(x0).

4.4 Spline interpolation
|
115
From this and (4.4.2), it follows that μ0 = μn and
3
δ2
0
(y1 −y0) −1
δ0
(2μ0 + μ1) =
3
δ2
n−1
(yn−1 −yn) +
1
δn−1
(μn−1 −2μn).
Each kind of boundary condition gives n + 1 linear equations with n + 1 unknown
numbers. Solve these equations to ﬁnd μ0, μ1, . . . , μn.
Proposition 4.4.2. Let f ∈C4([a, b]), and let s(x) be the cubic spline function on [a, b]
corresponding to nodes a = x0 < x1 < ⋅⋅⋅< xn = b. Denote λ = max0≤k≤n+1|xk+1 −xk|.
Then
|f (i)(x) −s(i)(x)| ≤Cλ4−i
(i = 1, 2, 3),
where C is a constant.
4.4.3 B-splines
Let N1(x) = χ[0,1](x), where χ[0,1](x) is the characteristic function of [0, 1] and
N2(x) =
1
∫
0
N1(x −t) dt,
...
Nm(x) =
1
∫
0
Nm−1(x −t) dt.
The Nm(x) is called the B-spline of degree m −1. B-spline Nm has the following prop-
erties:
Nm(x) > 0
(0 < x < m),
supp Nm(x) = [0, m],
∑
l∈ℤ
Nm(x −l) = 1
(x ∈ℝ).
Let sm ∈L2(ℝ) be a spline function of degree m with nodes ℤ. Then
sm(x) = ∑
k∈ℤ
ckNm(x −k)
in the L2(ℝ) sense. Especially, if supp sm(x) = [N1, N2] (N1, N2 ∈ℤ), then sm(x) is a
sum of ﬁnitely many terms.

116
|
4 Interpolation
4.5 Trigonometric interpolation and fast Fourier transform
Given N points x0, x1, . . . , xN−1, deﬁne the discrete Fourier transform as
Xk = 1
N
N−1
∑
n=0
xn e−in 2πk
N
(k = 0, . . . , N −1).
Using the formula
N−1
∑
j=0
e−ik 2πj
N eim 2πj
N = δkm
(0 ≤k, m ≤N −1),
where δkm is the Kronecker delta, the inverse discrete Fourier transform is
xn =
n
∑
k=0
Xk eik 2πn
N
(n = 0, 1, . . . , N −1).
This implies the following formula.
Trigonometric interpolation formula
Let f(x) be deﬁned on [0, 1] and xj = j
N (j = 0, 1, . . . , N −1) be N nodes. Denote
ck = 1
N
N−1
∑
j=0
f(xj) e−2πikxj
(k = 0, . . . , N −1).
Then the trigonometric polynomial P(x) = ∑N−1
k=0 ck e2πikx satisﬁes P(xk) = f(xk).
Fast Fourier transform
Fast Fourier transform is a fast algorithm computing discrete Fourier transform by the
halving trick.
Given a 2N -point time series x = (x0, x1, . . . , x2N−1), its discrete Fourier transform
is
Xk = 1
2N
2N−1
∑
n=0
xne−in 2πk
2N
(k = 0, 1, . . . , 2N −1).
(4.5.1)
Now we halve Xk by the halving trick.
First, we compute the ﬁrst half X0, X1, . . . , X2N−1−1. Decompose the given 2N -
point time series x into two 2N−1-point time series
u = (x0, x2, . . . , x2N−2) =: (u0, u1, . . . , u2N−1−1),
υ = (x1, x3, . . . , x2N−1) =: (υ0, υ1, . . . , υ2N−1−1),

4.5 Trigonometric interpolation and fast Fourier transform
|
117
i.e., u is an even sample and υ is an odd sample of x. From (4.5.1), it follows that
Xk = 1
2N
2N−1−1
∑
n=0
une−2ni 2πk
2N + 1
2N
2N−1−1
∑
n=0
υne−(2n+1)i 2πk
2N ,
and so
Xk = 1
2(Uk + e−i 2πk
2N Vk)
(k = 0, 1, . . . , 2N−1 −1),
where
Uk =
1
2N−1
2N−1−1
∑
n=0
une−in 2πk
2N−1 ,
Vk =
1
2N−1
2N−1−1
∑
n=0
υne−in 2πk
2N−1
(k = 0, 1, . . . , 2N−1 −1).
Similarly, the second half X2N−1, X2N−1+1, . . . , X2N−1 is computed as follows:
Xk+2N−1 = 1
2(Uk −e−i 2πk
2N Vk)
(k = 0, 1, . . . , 2N−1 −1).
where Uk and Vk are stated as above.
We continue to halve the obtained Uk and Vk by the halving trick.
Halving Uk (k = 0, 1, . . . , 2N−1 −1), this gives that
Uk = 1
2 (U󸀠
k + e−i 2πk
2N−1 U󸀠󸀠
k ) ,
Uk+2N−2 = 1
2 (U󸀠
k −e−i 2πk
2N−1 U󸀠󸀠
k )
(k = 0, 1, . . . , 2N−2 −1),
where U󸀠
k and U󸀠󸀠
k are the discrete Fourier transforms of two 2N−2-point time series
which consist of even samples and odd samples of u, respectively.
Halving Vk (k = 0, 1, . . . , 2N−1 −1), this gives that
Vk = 1
2 (V󸀠
k + e−i 2πk
2N−1 V󸀠󸀠
k ) ,
Vk+2N−2 = 1
2 (V󸀠
k −e−i 2πk
2N−1 V󸀠󸀠
k )
(k = 0, 1, . . . , 2N−2 −1),
where V󸀠
k and V󸀠󸀠
k are the discrete Fourier transforms of two 2N−2-point time series
which consist of even samples and odd samples of υ, respectively.
Continue this procedure until a one-point time series.
Using the fast Fourier transform algorithm, the total number of multiplication
operations is equal to N2N−1. While using the original discrete Fourier transform al-
gorithm, the total number of multiplication operations is equal to 22N . This means
that the fast Fourier transform has better computationally efficiency.

118
|
4 Interpolation
4.6 Bivariate interpolation
Given a set of nodes in the xy-plane (x1, y1), (x2, y2), . . . , (xn, yn), where each node
(xi, yi) is associated with a real number ci, we ﬁnd a smooth and easily computed
function F such that F(xi, yi) = ci (1 ≤i ≤n).
4.6.1 Cartesian product and grids
Assume that the set of nodes is a Cartesian product N = {x1, x2, . . . , xp} × {y1, y2,
. . . , yq}, i.e., grids
N = { (xi, yj): 1 ≤i ≤p, 1 ≤j ≤q }.
Let ui(x) (i = 1, . . . , p) be univariate real functions such that ui(xj) = δij (1 ≤i, j ≤p),
where δij is the Kronecker delta. For example, ui(x) may be the fundamental polyno-
mials in the Lagrange interpolation formula (see (4.2.1)). Let f be a bivariate function.
Deﬁne an operator P as
(Pf)(x, y) =
p
∑
1
f(xi, y)ui(x).
The operator Pf is a bivariate function that interpolates f on vertical lines Li: {(xi, y):
−∞< y < ∞} (i = 1, . . . , p). Deﬁne another operator Q as
(Qf)(x, y) =
q
∑
1
f(x, yj)υj(y),
where υj(yi) = δij (1 ≤i, j ≤q). The operator Qf is a bivariate function that interpolates
f on horizontal lines Lj: {(x, yj): −∞< x < ∞} (j = 1, . . . , q). Then P(Qf) is a function
that interpolates f at the nodes (xi, yj) (i = 1, . . . , p; j = 1, . . . , q).
In fact, from
P(Qf)(x, y) = P (
q
∑
1
f(x, yj)υj(y)) =
p
∑
i=1
q
∑
j=1
f(xi, yj)ui(x)υj(y),
it follows that P(Qf)(xi, yj) = f(xi, yj) (i = 1, . . . , p; j = 1, . . . , q).
4.6.2 Tensor product
A function ∑0≤i+j≤k cijxiyj is called a bivariate polynomial of degree ≤k, where cij are
constants. The space of all bivariate polynomials of degree at most k is denoted by
∏k(ℝ2). The set { xiyj }0≤i+j≤k is the basis of ∏k(ℝ2). So the dimension of ∏k(ℝ2) is
1
2(k + 1)(k + 2).

4.6 Bivariate interpolation
|
119
For a node set N, we ask whether the interpolation is possible on N. The following
results are known:
(a) Assume that the set N consists of nodes (x1, y1), (x2, y2), . . . , (x ̃k, y ̃k), where
̃k = 1
2(k + 1)(k + 2), and these nodes lie on lines L0, L1, . . . , Lk, and for each i, the
line Li contains just i + 1 nodes. Then, for arbitrary associated data c1, c2, . . . , c ̃k,
there is a polynomial p ∈∏k(ℝ2) such that p(xl, yl) = cl (l = 1, 2, . . . , ̃k).
(b) For any set of k + 1 distinct nodes (x1, y1), (x2, y2), . . . , (xk+1, yk+1) and data
c1, c2, . . . , ck+1, there is a p ∈∏k(ℝ2) such that p(xl, yl) = cl (l = 1, . . . , k + 1).
4.6.3 Shepard interpolation
Let n nodes pi = (xi, yi) (i = 1, . . . , n). We select a real-valued function φ on ℝ2 × ℝ2
such that φ(p, q) = 0 if and only if p = q. Deﬁne cardinality functions
ui(p) =
∏
j=1,...,n
j ̸=i
φ(p, pj)
φ(pi, pj)
(1 ≤i ≤n).
This leads to an interpolation formula of a function f at the given nodes pi as follows:
F =
n
∑
1
f(pi)ui.
Especially, if
φ(p, pj) = ‖p −pj‖2 = (x −xj)2 + (y −yj)2,
where p = (x, y) and pj = (xj, yj), then the interpolation formula is
F(x, y) =
n
∑
i=1
f(xi, yi) ∏
j=1,...,n
j ̸=i
(x −xj)2 + (y −yj)2
(xi −xj)2 + (yi −yj)2 .
4.6.4 Triangulation
Triangulation is another method for interpolation problems.
If a set of triangles ∆1, ∆2, . . . , ∆m satisﬁes the following three conditions:
–
each node is the vertex of some triangle ∆s;
–
each vertex of a triangle in the set is a node;
–
if a node belongs to a triangle, then the node must be a vertex of that triangle,
then this set is called a triangulation.
In a triangle ∆s, deﬁne a linear function as
ls(x, y) = αsx + βsy + γs,
(x, y) ∈∆s.

120
|
4 Interpolation
Choose αs, βs, and γs such that each linear function ls(x, y) (s = 1, 2, . . . , m) takes
the prescribed values ci, cj, and ck at vertices (xi, yi), (xj, yj), and (xk, yk), i.e.,
ls(xi, yi) = ci,
ls(xj, yj) = cj,
ls(xk, yk) = ck
(s = 1, 2, . . . , m).
Then the obtained pieces linear function is continuous on the union ⋃m
s=1 ∆s.
Further reading
[1]
Agudelo OM, Viaene P, De Moor B. Improving the PM10 estimates of the air quality model AU-
RORA by using Optimal Interpolation. IFAC-PapersOnLine. 2015(48):1154–1159.
[2]
Arun PV. A comparative analysis of different DEM interpolation methods. The Egyptian Journal
of Remote Sensing and Space Science. 2013(16):133–139.
[3]
Chaplot V, Darboux F, Bourennane H, Legedois S, Silvera N, Phachomphon K. Accuracy of inter-
polation techniques for the derivation of digital elevation models in relation to landform types
and data density. Geomorphology. 2006(77):126–141.
[4]
Chudinov AV, Gao W, Huang Z, Cai W, Zhou Z, Raznikov VV, Kozlovski VI, Sulimenkov IV. Interpo-
lational and smoothing cubic spline for mass spectrometry data analysis. International Journal
of Mass Spectrometry. 2016(396):42–47.
[5]
Duran-Rosal AM, Heras-Martinez C, Tallon-Ballesteros AJ, Martinez-Estudillo AC, Salcedo-Sanz
S. Massive missing data reconstruction in ocean buoys with evolutionary product unit neural
networks. Ocean Engineering. 2016(117):292–301.
[6]
Janssen S, Dumont G, Fierens F, Mensink C. Spatial interpolation of air pollution measurements
using CORINE land cover data. Atmospheric Environment 2008(42):4884–4903.
[7]
Jeong SYY, Choi YJ, Park P. Parametric interpolation using sampled data. Computer-Aided De-
sign. 2006(38):39–47.
[8]
Kilibarda M, Tadi MP, Hengl T, Lukovic J, Bajat B. Global geographic and feature space cov-
erage of temperature data in the context of spatio-temporal interpolation. Spatial Statistics.
2015(14):22–38.
[9]
Krivoruchko K, Gribov A, Krause E. Multivariate areal interpolation for continuous and count
data. Procedia Environmental Sciences. 2011(3):14–19.
[10] Li Q, Dehler SA. Inverse spatial principal component analysis for geophysical survey data inter-
polation. Journal of Applied Geophysics. 2015(115):79–91.
[11] Lin J, Cromley PG. Evaluating geo-located Twitter data as a control layer for areal interpolation
of population. Applied Geography. 2015(58):41–47.
[12] Liu R, Chen Y, Sun C, Zhang P, Wang J, Yu W, Shen Z. Uncertainty analysis of total phosphorus
spatial-temporal variations in the Yangtze River Estuary using different interpolation methods.
Marine Pollution Bulletin. 2014(86):68–75.
[13] Liu S, Wang CCL. Quasi-interpolation for surface reconstruction from scattered data with radial
basis function. Computer Aided Geometric Design. 2015(29):435–447.
[14] Mendez D, Labrador M, Ramachandran K. Data interpolation for participatory sensing systems.
Pervasive and Mobile Computing. 2013(9):132–148.
[15] Nardelli BB, Droghei R, Santoleri R. Multi-dimensional interpolation of SMOS sea surface salin-
ity with surface temperature and in situ salinity data. Remote Sensing of Environment. 2016: in
press.

Further reading
|
121
[16] Nardelli BB, Pisano A, Tronconi C, Santoleri R. Evaluation of different covariance models for the
operational interpolation of high resolution satellite Sea Surface Temperature data over the
Mediterranean Sea. Remote Sensing of Environment. 2015(164):334–343.
[17] Plouffe CCF, Robertson C, Chandrapala L. Comparing interpolation techniques for monthly
rainfall mapping using multiple evaluation criteria and auxiliary data sources: A case study of
Sri Lanka. Environmental Modelling & Software. 2015(67):57–71.
[18] Scudiero E, Corwin DL, Morari F, Anderson RG, Skaggs TH. Spatial interpolation quality assess-
ment for soil sensor transect datasets. Computers and Electronics in Agriculture. 2016(123):
74–79.
[19] Singh SK, McMillan H, Bardossy A. Use of the data depth function to differentiate between
case of interpolation and extrapolation in hydrological model prediction. Journal of Hydrology.
2013(477):213–228.
[20] Slattery SR. Mesh-free data transfer algorithms for partitioned multiphysics problems: Conser-
vation, accuracy, and parallelism. Journal of Computational Physics. 2016(307):164–188.
[21] Steinbuch L, Brus DJ, van Bussel LGJ, Heuvelink GBM. Geostatistical interpolation and aggrega-
tion of crop growth model outputs. European Journal of Agronomy. 2016(77):111–121.
[22] Su T, Cao Z, Lv Z, Liu C, Li X. Multi-dimensional visualization of large-scale marine hydrological
environmental data. Advances in Engineering Software. 2016(95):7–15.
[23] Tokumitsu M, Hasegawa K, Ishida Y. Toward resilient sensor networks with spatiotemporal
interpolation of missing data: An example of space weather forecasting. Procedia Computer
Science. 2015(60):1585–1594.
[24] Urquhart EA, Hoffman MJ, Murphy RR, Zaitchik BF. Geospatial interpolation of MODIS-derived
salinity and temperature in the Chesapeake Bay. Remote Sensing of Environment. 2013(135):
167–177.
[25] Wagner PD, Fiener P, Wilken F, Kumar S, Schneider K. Comparison and evaluation of spa-
tial interpolation schemes for daily rainfall in data scarce regions. Journal of Hydrology.
2012(464–465):388–400.
[26] Wang Q, Shi W, Atkinson PM. Sub-pixel mapping of remote sensing images based on radial
basis function interpolation. ISPRS Journal of Photogrammetry and Remote Sensing. 2014(92):
1–15.
[27] Yang Z, Liu Y, Li C. Interpolation of missing wind data based on ANFIS. Renewable Energy.
2011(36):993–998.

5 Statistical methods
In order to handle various environmental issues well, it is crucial to apply statistical
methodology to ensure well-conducted data collection, analyze and interpret environ-
mental data, and describe environmental changes with sound and validated models.
In this chapter, we will provides comprehensive coverage of the methodology used
in the statistical investigation of environmental issues, including regression analysis,
principal component analysis, discriminant analysis, cluster analysis, factor analysis,
and canonical correlation analysis. All these statistical methods can be easily imple-
mented by popular software packages such as SPSS, SAS, and R.
5.1 Linear regression
Linear regression analysis is the most widely used among all statistical techniques. It
is used to model the relationship between two variables by ﬁtting a linear equation to
observed data. One variable is considered to be an explanatory variable, and the other
is considered to be a dependent variable. The simplest linear regression model is
Y = β0 + β1x + ε
(ε ∼N(0, σ2)),
(5.1.1)
where Y is a dependent variable, x is an explanatory variable, and ε is the random
error. If the data is a sample { Yi, xi }i=1,...,n, by (5.1.1),
Yi = β0 + β1xi + εi
(i = 1, . . . , n).
(5.1.2)
Common assumptions are that ε1, . . . , εn are independent, E[εi] = 0 (i = 1, . . . , n)
and Var(εi) = σ2 (i = 1, . . . , n), and ε1, . . . , εn are normal distributed.
5.1.1 Estimate of regression coefficients β0 and β1
Let
̂Yi be the estimate of Yi, i.e.,
̂Yi = β0 + β1xi
(i = 1, . . . , n).
(5.1.3)
Use the method of least squares to estimate β0 and β1.
Let
Q(β0, β1) :=
n
∑
1
(Yi −
̂Yi)2 =
n
∑
1
(Yi −β0 −β1xi)2.
(5.1.4)
We need to choose
̂β0, ̂β1 such that Q( ̂β0, ̂β1) attains the minimal value. This means
solving two equations
∂Q
∂β0
= 0,
∂Q
∂β1
= 0.
DOI 10.1515/9783110424904-006

5.1 Linear regression
|
123
Let ̄x = 1
n ∑n
i=1 xi and
̄Y = 1
n ∑n
i=1 Yi. By (5.1.4),
∂Q
∂β0
= −2
n
∑
1
(Yi −β0 −β1xi) = −2(n ̄Y −nβ0 −n ̄xβ1).
Since ∂Q
∂β0 = 0,
β0 =
̄Y −β1 ̄x.
(5.1.5)
Denote
̃xi = xi −̄x and
̃Yi = Yi −
̄Y. By (5.1.4) and (5.1.5), we get
∂Q
∂β1
= −2
n
∑
1
(Yi −(β0 + β1xi))xi = −2
n
∑
1
( ̃Yi +
̄Y −(β0 + β1xi))xi
= −2
n
∑
1
( ̃Yi + (β0 + β1 ̄x) −(β0 + β1xi))xi
= −2
n
∑
1
( ̃Yi −β1 ̃xi) ̃xi = −2SxY + 2β1Sxx,
where SxY = ∑n
i=1 ̃xi ̃Yi and Sxx = ∑n
i=1( ̃xi)2. Since ∂Q
∂β1 = 0,
β1Sxx = SxY.
From this and (5.1.5), the regression coefficients β0, β1 are estimated
̂β1 = SxY
Sxx
= ∑n
1 ̃xi ̃Yi
∑n
1( ̃xi)2 = ∑n
1(xi −̄x)(Yi −
̄Y)
∑n
1(xi −̄x)2
,
̂β0 =
̄Y −̂β1 ̄x.
The equation
̂Y =
̂β0 + ̂β1x is called the regression equation.
5.1.2 Estimate of σ2
By (5.1.1), E[(Y −(β0 + β1x))2] = E[ε2] = σ2. Now we estimate σ2 using the sample
(Yi, xi)i=1,...,n.
By
̂β1 = SxY/Sxx, the sum of squares
n
∑
i=1
(Yi −̂β0 −̂β1xi)2 =
n
∑
1
(Yi −
̄Y −̂β1(xi −̄x))2
=
n
∑
1
(Yi −
̄Y)2 −2 ̂β1
n
∑
1
(Yi −
̄Y)(xi −̄x) + ( ̂β1)2
n
∑
1
(xi −̄x)2
= SYY −̂β1SxY.
The corresponding statistic is Q = SYY −̂β1SxY . It can be proved that Q
σ2 ∼χ2(n −2).
So E[Q/(n −2)] = σ2. This implies that the unbiased estimator
̂σ2 =
Q
n −2 = SYY −̂β1SxY
n −2
.

124
|
5 Statistical methods
5.1.3 Decomposition formula
Since
n
∑
1
(Yi −
̄Y)2 =
n
∑
1
(Yi −
̂Yi +
̂Yi −
̄Y)2
=
n
∑
1
(Yi −
̂Y)2 + 2
n
∑
1
(Yi −
̂Yi)( ̂Yi −
̄Y) +
n
∑
1
( ̂Yi −
̄Y)2.
From
̃Yi = Yi −
̄Y and
̂Yi =
̄Y +
̂β1 ̃xi and
̃xi = xi −̄x, and (5.1.5), the second term on
the right-hand side
n
∑
i=1
(Yi −
̂Yi)( ̂Yi −
̄Y) =
n
∑
i=1
( ̃Yi −̂β1 ̃xi) ̂β1 ̃xi =
̂β0 ̂β1
n
∑
1
̃xi = 0.
Thus the sum of squares of deviation Yi −
̄Y is decomposed as follows:
n
∑
1
(Yi −
̄Y)2 =
n
∑
1
(Yi −
̂Yi)2 +
n
∑
1
( ̂Yi −
̄Y)2,
(5.1.6)
where
̂Yi =
̂β0 + ̂β1xi.
In (5.1.6), the sum Q := ∑n
i=1(Yi −̂Yi)2 is called the residual sum of squares; the sum
U := ∑n
i=1( ̂Yi −
̄Y)2 is called the regression sum of squares. So (5.1.6) can be rewritten
as SYY = Q + U. Since residuals Yi −
̂Yi represent the differences between the ﬁtted
values and the observed values, they can be used to check if the assumed model ﬁts
the data well or not. Deﬁne
R2 =
U
SYY
= 1 −
Q
SYY
= 1 −∑n
1( ̂Yi −Yi)2
∑n
1(Yi −
̄Y)2 .
Here R2 is called the coefficient of determination which indicates the usefulness of the
regression model. If R approximates 1, the regression model is very useful.
5.1.4 Extensions
Many more complicated regressions may be reduced to linear regression problems.
Here we give some examples which may be reduced to linear regression.
For the model G(Y) = β0 + β1g(x) + ε and ε ∼N(0, σ2), where β0, β1, and σ2 are
independent of x, its samples are { xi, Yi }i=1,...,n. Let Y∗= G(Y) and x∗= g(x). Then
Y∗= β0 + β1x∗+ ε,
ε ∼N(0, σ2)
is a linear regression model and the samples are { g(xi), G(Yi) }i=1,...,n. By using the
least square method, the regression coefficients
̂β0 and
̂β1 can be estimated and the
regression model is G(Y) =
̂β0 + ̂β1g(x) + ε.

5.2 Multiple regression
|
125
For the model Y = aebxε and log ε ∼N(0, σ2) and the model Y = axbε and log ε ∼
N(0, σ2), where a, b, and ε are independent of x, taking logarithms on both sides,
these two models are transformed into two linear regression models, respectively.
5.1.5 Nonlinear regression models
In general, the univariate regression model is
Y = μ(x; β1, . . . , βp) + ε,
ε ∼N(0, σ2),
where β1, . . . , βp, and σ2 are independent of x. If μ is a linear function of β1, . . . , βp,
then μ is called a linear regression model, otherwise, it is called a nonlinear regression
model.
Let { xi, Yi }i=1,...,n (n > p) be a known sample. A general nonlinear regression
model can be written as
Yi = μ(xi; β1, . . . , βp) + εi
(i = 1, . . . , n).
For a nonlinear regression model, the assumption of random errors εi’s are the same
as those for a linear model. Use least squares to estimate β1, . . . , βp. Let
Q(β1, . . . , βp) =
n
∑
1
(Yi −μ(xi; β1, . . . , βp))2 .
Differentiating both sides of the equation with respect to βk gives
∂Q
∂βk
= 2
n
∑
1
(Yi −μ(xi; β1, . . . , βp)) ∂μ
∂βk
(xi; β1, . . . , βp) = 0
(k = 1, . . . , p).
One often solves these equations using the Newton–Rapson iterative algorithm (see
Chapter 7) and obtains the estimates
̂βk’s of βk’s (k = 1, . . . , p). Finally, the estimate
of Y is Y ≈μ(x; ̂β1, . . . , ̂βp).
5.2 Multiple regression
In this section, we discuss multivariate linear regression models with one or multiple
dependent variables. The multivariate regression model incorporates the correlation
between the responses. So it may provide more efficient inference than separate uni-
variate regression models but it is more complicated and is more different to handle.

126
|
5 Statistical methods
5.2.1 A dependent variable case
In multivariate analysis, we choose Y as a response and variables x1, . . . , xp as pa-
rameters, and a sample {Yi;xi1, . . . , xip }i=1,...,n. Multivariate linear regression models
attempt to ﬁnd an approximate relationship
Y =
p
∑
0
βkxk + ε
(ε ∼N(0, σ2I)),
x0 = 1.
(5.2.1)
This implies that
Yi =
p
∑
k=0
βkxik + εi
(εi ∼N(0, σ2)),
xi0 = 1
(i = 1, . . . , n)
and {εi} are independent. The matrix form is Y = Xβ + ε where Y = (Y1, . . . , Yn)T,
ε = (ε1, . . . , εn)T, β = (β0, β1, . . . , βp)T, and
X = (
1
x11
⋅⋅⋅
x1p
...
...
...
...
1
xn1
⋅⋅⋅
xnp
) .
(a) Estimate of regression coefficients β = (β0, . . . , βp)
Choose {βk}k=1,...,p such that the following sum of squares attains the minimal value
Q(β) =
n
∑
i=1
(Yi −
p
∑
k=0
βkxik)2 = (Y −Xβ)T(Y −Xβ).
(5.2.2)
Let ∂Q
∂βj = 0 (j = 1, . . . , n). Then ∑n
i=1(Yi −∑p
k=0 βkxik)xij = 0. This is equivalent to
p
∑
k=0
(
n
∑
i=1
xikxij) βk =
n
∑
i=1
Yixij
(j = 1, . . . , n).
Its matrix form is XTXβ = XTY. So
̂β = (XTX)−1XTY is the least square estimate of β.
Moreover, it is an unbiased estimate of β. It can be proved that
̂β ∼N(β, σ2(XTX)−1).
From this and (5.2.2), it follows that
Q( ̂β) =
n
∑
i=1
(Yi −
p
∑
k=0
̂βkxik)
2
= YTY −YTX ̂β,
̂σ2 =
Q( ̂β)
n −p −1 =
1
n −p −1
n
∑
1
(Yi −
̂Yi)2,
where
̂Yi = ∑p
k=0 ̂βkxik (i = 1, . . . , n) and ̂σ2 is a unbiased estimate of σ2. The following
proposition holds.

5.2 Multiple regression
|
127
For the model (5.2.1),
̂β ∼N(β, σ2(XTX)−1),
Q( ̂β)
σ2
∼χ2
n−p−1.
If β1 = ⋅⋅⋅= βp = 0, then V/σ2 ∼χ2
p, where V = ∑n
i=1( ̂Yi −
̄Y)2.
Deﬁne a test statistic F =
V/p
Q/(n−p−1) . If β1 = ⋅⋅⋅= βp = 0, then F ∼F(p, n −p −1). By
the known sample, we compute the value of F and signiﬁcant probability ̃p. If ̃p is less
than signiﬁcance level α, then we reject hypothesis H0. Otherwise, the hypothesis H0
holds.
(b) Model selection
If in a regression model, some variable does not have a signiﬁcant effect on the re-
sponse, then we may remove it from this model. In general, a simple model is better
than a complex model.
In a linear regression model, if the ﬁrst model chosen by us is
Y =
p
∑
0
βkxk + ε1
(β0 = 1),
̂Y(1)
i
=
p
∑
0
̂βkxk
( ̂β0 = 1)
and the second model chosen by us is
Y =
q
∑
0
bkxk + ε2
(b0 = 1),
̂Y(2)
i
=
q
∑
0
̂bkxk
( ̂b0 = 1),
where p > q. Denote
R1 =
n
∑
1
(Y(1)
i
−
̂Y(1)
i )2,
R2 =
n
∑
1
(Y(2)
i
−
̂Y(2)
i )2.
If
F = (R2 −R1)/(p −q)
R1/(n −p)
> Fα(p −q, n −p),
then we choose the ﬁrst model. Otherwise, we choose the second model.

128
|
5 Statistical methods
5.2.2 Multiple dependent variable case
Suppose that there are p dependent variables Y1, . . . , Yp and m independent vari-
ables x1, . . . , xm, and data matrixes are X = (xij)n×m and Y = (Yij)n×p. If
Yij = β0j +
m
∑
k=1
βkjxik + εij
(i = 1, . . . , n; j = 1, . . . , p)
then Y = (In|X)β + E = Cβ + E, where
In = (1, 1, . . . , 1)T,
C = (In|X),
β = (βij)m×p,
E = (εij)n×p.
Assume that εi = (εi1, . . . , εip)T (i = 1, . . . , n) are independent, E[εi] = 0, εi’s have the
same covariance matrix Σ, and εi ∼Np(0, Σ) (i = 1, . . . , n). The model Y = (In|X)β + E =
Cβ + E is called a multivariate linear regression model of multiple dependent variables,
where Y, E are random matrices and C = (In|X).
Similar to the dependent variable case, the parameter matrix β and covariance
matrix Σ are estimated using the least square method as follows:
̂β = (CTC)−1CTY =: (bij)(m+1)×p.
So the regression equation with p dependent variables is
̂Yj = b0j + b1jx1 + ⋅⋅⋅+ bmjxm
(j = 1, . . . , p).
5.3 Case study: Tree-ring-based climate reconstructions
Due to the lack of reliable long-term meteorological records, it is hard to understand
past climate change. Reconstructions of past climate conditions may be derived from
various paleoclimatology proxies. Compared with other proxies, tree-ring-based
reconstructions have many advantages, including wide spatial distribution, high
climate sensitivity, high annual resolution and calendar-exact dating. Currently, the
world’s longest tree-ring chronology extends over more than 7000 years.
5.3.1 Collection of tree-ring data
Since tree radial growth is always subject to climatic inﬂuences, one can use various
parameters from sample tree-rings to reconstruct historicaltemperature and precipita-
tion. In order to reconstruct past temperature, the sample sites of tree-ring data should
be in upper-elevation tree-line locations and cold mountain valley environments. In
order to reconstruct past precipitation, sample sites should be in a steep rocky, south

5.3 Case study: Tree-ring-based climate reconstructions
|
129
facing slope. In each sample site, after removing a cylinder of wood 5 mm in diameter
along the radius of a tree, core samples are collected at breast height from trees.
Core samples are air dried and polished, then tree-ring widths are measured with a
precision of 0.01 mm by using the LINTAB system or a similar system. After eliminating
age-related growth trends, tree-ring width data need be standardized using the pro-
gram ARSTAN in order to get tree-ring width chronologies. Except for tree-ring widths,
tree-ring isotopic data can also be used to reconstruct past climate. Each ring of tree
core samples is cut by using a scalpel blade and cellulose is extracted, δ18O and δ13C
values of cellulose are measured by using a stable isotope radio mass spectrometer.
5.3.2 Tree-ring-based climate reconstruction
Main tree-ring related parameters include
a1 tree-ring width;
a2 (δ18O);
a3 (δ13C),
a4 mean latewood density.
Main reconstructed climate parameters include
b1 temperature,
b2 precipitation,
b3 runoff,
b4 drought,
b5 CO2 concentration Ca.
Correlation analysis is used to examine the relationship between tree-ring related pa-
rameters ai and climate parameters bj. Suppose that X(1)
i , . . . , X(n)
i
is the tree-ring
chronology for parameter ai and Y(1)
j , . . . , Y(n)
j
is the observation of climate parame-
ter bj. Then the estimate of the correlation coefficient is
rij =
∑n
l=1(X(l)
i
−̄Xi)(Y(l)
j
−
̄Yj)
√∑n
l=1(X(l)
i
−
̄Xi)2 √∑n
l=1(Y(l)
j
−
̄Yj)2
,
where
̄Xi = 1
n ∑n
l=1 X(l)
i
and
̄Yj = 1
n ∑n
l=1 Y(l)
j . If {ri,j} is large, we can use the tree-ring
parameter ai to reconstruct the climate parameter bj. Finally, with the help of linear
regression formula, we can reconstruct the climate factor bj from climate parameter
ai as follows:
bj = β + β1ai + εi,j
(εi,j ∼N(0, σ2)),
where β, β1, and σ2 are estimated well by samples of ai and bj (see Section 5.1).
Below we give some results on tree-ring-based reconstruction of climate.

130
|
5 Statistical methods
The Hulunbuir region between 47–53° N and 115–126° E is extremely sensitive to
climate changes. Therefore, it is an ideal region to carry out tree-ring research. Y. Liu
et al. (2009) collected tree core samples and found that tree-ring width (TRW) is highly
correlated with precipitation P76 for previous July to current June with the correlation
coefficient r = 0.711. They give the following linear regression formula:
P76 = 222.408 TRW −133.115
to reconstruct P76 since 1865. During the calibration period 1952–2003, total precipita-
tion reconstructed by Liu et al. tracked the observation very well. In 2012, G. Bao et al.
further reconstructed April–September mean maximum temperature (MMT49) from
1868 to 2008 by tree-ring width chronologies by using the following linear regression
formula:
MMT49 = −2.807 TRW + 21.288.
Moreover, Bao et al. (2012) further found signiﬁcant correlations between the recon-
structed MMT and Paciﬁc Decadal Oscillation/Nino. This explains the inﬂuences of
large-scale atmospheric-oceanic variability on regional temperature and droughts in
the Hulubuir grassland.
The Luoshan Mountains are in the south part of the Tengger Desert of China and
are surrounded by land subject to desertiﬁcation. Palmer Drought Severity Index
(PDSI) is a standardized measure of surface moisture conditions. In 2013, Y. Wang
et al. used tree-ring width to reconstruct annual PDSI in Tengger Desert for the period
1897–2007 as follows:
PDSI = 4.90 + 4.15 TRW.
In the West Tianmu Mountains of China, X. Zhao et al. (2006) collected tree-ring
samples and reconstructed atmospheric CO2 concentration Ca by using tree-ring δ13C
values
Ca = 8598 + 810.922 δ13C + 19.748 (δ13C)2.
This is a curvilinear regression formula. Their results show that in 1685–1840, the eval-
uated atmospheric CO2 concentration was stable, but after 1840 it exhibited a rapid
increase.
In the Wuyi Mountains of China, F. Chen et al. (2012) used tree-ring width of cur-
rent and pervious years to reconstruct July–October minimum temperature MT710 in
1803–2008 as follows:
MT710(t) = 22.662 −150 TRW(t) −1.567 TRW(t −1).
This is a nonlinear regression formula. From this, they showed that there is a strong
relationship between the reconstruction and Summer Asian-Paciﬁc Oscillation which
suggest linkages of regional temperature variability with the Asian-Paciﬁc climate
system.

5.4 Covariance analysis
|
131
5.4 Covariance analysis
The analysis of covariance is used to adjust or control for differences between groups.
Consider several independent random variables that have normal distribution with
unknown means and unknown but common variance. A test of the equality of several
means is called analysis of variance.
Suppose that X1, . . . , Xm are independent and each Xk ∼N(μk, σ2) (k = 1, . . . , m).
Let (X1k, . . . , Xnk) be a sample of each Xk. We test the hypothesis H0 : μ1 = μ2 = ⋅⋅⋅=
μm = μ. Denote
X⋅k = 1
n
n
∑
j=1
Xjk,
X⋅⋅=
1
mn
n
∑
j=1
m
∑
k=1
Xjk.
It is easily deduced that the sum of squares
mnS2 =
n
∑
j=1
m
∑
k=1
(Xjk −
̄X⋅⋅)2
has the decomposition formula
mnS2 =
n
∑
j=1
m
∑
k=1
(Xjk −̄X⋅k)2 + n
m
∑
k=1
( ̄X⋅k −̄X⋅⋅)2 =: Q1 + Q2.
Note that the sample variance of Xk : S2
k =
1
n−1 ∑n
j=1(Xjk −
̄X⋅k)2 and E[S2
k] =
Var(Xk) = σ2. Then
E[Q1] =
m
∑
k=1
E[(n −1)S2
k] = (n −1)mσ2.
(5.4.1)
Denote μ = 1
m ∑m
k=1 μk and δk = μk −μ (k = 1, . . . , m). By the independence of Xjk
(j = 1, . . . , m; k = 1, . . . , n),
̄X⋅k ∼N (μk, σ2
n ) ,
̄X⋅⋅∼N(μ, σ2
nm ),
and so the expectations of their squares are, respectively,
E[ ̄X2
⋅k] = Var( ̄X⋅k) + μ2
k = σ2
n + (μ + δk)2,
E[ ̄X2
⋅⋅] = Var( ̄X⋅⋅) + μ2 = σ2
nm + μ2.
Since
̄X⋅k = 1
n ∑n
j=1 Xjk,
Q2 = n
m
∑
k=1
( ̄X⋅k −
̄X⋅⋅)2 = n
m
∑
k=1
( ̄X2
⋅k +
̄X2
⋅⋅−2 ̄X⋅k ̄X⋅⋅) = n
m
∑
k=1
̄X2
⋅k −nm ̄X2
⋅⋅.

132
|
5 Statistical methods
Note that ∑m
k=1 δk = ∑m
k=1 μk −mμ = 0. Then,
E[Q2] = n
m
∑
1
E [ ̄X2
⋅k] −nmE [ ̄X2
⋅⋅] = n
m
∑
1
( σ2
n + (μ + δk)2) −nm ( σ2
nm + μ2)
= (m −1)σ2 + 2nμ
m
∑
1
δk + n
m
∑
1
δ2
k = (m −1)σ2 + n
m
∑
1
δ2
k.
Comparing this with (5.4.1),
E[Q2/(m −1)]
E[Q1/(m(n −1))] ≥1,
(5.4.2)
and the equality of (5.4.2) holds if and only if H0 is true since δk = 0 (k = 1, . . . , m).
The other test method is as follows. It is easy to prove that Q1
σ2 ∼χ2(m(n −1)) and
Q2
σ2 ∼χ2(m −1). Since Q1 and Q2 are independent,
Q2/(m −1)
Q1/(m(n −1)) ∼F(m −1, m(n −1)).
This implies that H0 is not true if and only if
Q2/(m−1)
Q1/(m(n−1)) ≥Fα(m −1, m(n −1)), where
α is a given signiﬁcance level.
5.5 Discriminant analysis
Discriminant analysis is used to separate individuals into different populations based
on given multivariate data. Suppose that there are k m-dimensional populations
G1, . . . , Gk. For a given sample X = (x1, . . . , xm)T, how to decide X ∈Gl?
5.5.1 Mahalanobis distance method
Let G be an m-variate population with mean value vector μ = (μ1, . . . , μm)T and co-
variance matrix Σ. The Mahalanobis distance between an individual X = (x1, . . . , xm)T
and the population G is deﬁned as
d2(X, G) = (X −μ)TΣ−1(X −μ).
For example, let G be a univariate population with mean μ and variance σ2, and
let X be a sample. Then the Mahalanobis distance is
d2(X, G) = (X −μ)2/σ2.
Let G be a bivariate population with mean value vector μ and covariance matrix Σ
μ = (μ1, μ2)T,
Σ = (τ11
τ12
τ21
τ22
) ,

5.5 Discriminant analysis
|
133
and let X = (x1, x2)T be a sample. Then the Mahalanobis distance is
d2(X, G) = (x1 −μ1, x2 −μ2) (τ11
τ12
τ21
τ22
)
−1
(x1 −μ1
x2 −μ2
) .
Suppose that there are two populations Gi (i = 1, 2) which have samples X(i)
1 , . . . ,
X(i)
ni (i = 1, 2). Then the estimates of the mean μi and covariance matrix Σi for Gi are,
respectively,
̄Xi = 1
ni
ni
∑
k=1
X(i)
k ,
(i = 1, 2).
Si =
1
ni −1
ni
∑
k=1
(X(i)
k −
̄Xi)(X(i)
k −
̄Xi)T,
(i = 1, 2).
(5.5.1)
The Mahalanobis distance is estimated as
d2(X, Gi) = (X −
̄Xi)TS−1
i (X −
̄Xi)
(i = 1, 2).
We say X ∈G1 if d2(X, G1) < d2(X, G2), and we say X ∈G2 if d2(X, G1) ≥d2(X, G2).
For example, for two one-dimensional populations Gi with mean μi and variance
σ2
i (i = 1, 2). We say x0 ∈G1 if d2(x, G1) < d2(x, G2), i.e.,
(x0 −μ(1))2
σ2
1
< (x0 −μ(2))2
σ2
2
,
which is equivalent to μ∗< x0 < μ∗, and we say x0 ∈G2 if d2(x, G1) ≥d2(x, G2), i.e.,
(x0 −μ(1))2
σ2
1
≥(x0 −μ(2))2
σ2
2
,
which is equivalent to x0 ≤μ∗or x0 ≥μ∗, where
μ∗= μ(1)σ2 −μ(2)σ1
σ2 −σ1
,
μ∗= μ(1)σ2 + μ(2)σ1
σ2 + σ1
.
When Σ1 = Σ2 =: Σ, the estimate of the covariance matrix Σ is
S =
1
n1 + n2 −2
2
∑
i=1
ni
∑
k=1
(X(i)
k −
̄Xi)(X(i)
k −̄Xi)T.
(5.5.2)
The Mahalanobis distance is estimated as follows:
d2(X, Gi) = (X −̄Xi)TS−1(X −̄Xi)
= XTS−1X −( ̄Xi)TS−1X −XTS−1 ̄Xi + ( ̄Xi)TS−1 ̄Xi
(i = 1, 2),
where S is stated in (5.5.2) which is the estimate of the covariance matrix Σ. Since S is
a symmetric matrix and XTS−1 ̄Xi is a 1 × 1 matrix,
(XTS−1 ̄Xi)T = ( ̄Xi)TS−1X,
d2(X, Gi) = XTS−1X −2Ti(X),

134
|
5 Statistical methods
where
Ti(X) = ( ̄Xi)TS−1X −1
2( ̄Xi)TS−1 ̄Xi
(i = 1, 2)
(5.5.3)
is a linear function. In fact, denote
( ̄Xi)TS−1 = (α(i)
1 , . . . , α(i)
n ),
( ̄Xi)TS−1 ̄Xi = bi.
Then, for X = (x1, . . . , xm)T,
( ̄Xi)TS−1X =
m
∑
k=1
α(i)
k xk,
and so
Ti(X) =
m
∑
k=1
α(i)
k xk −bi
2 ,
where α(i)
k and bi are constants, i.e., Ti(x) is a linear function. The Ti(X) is called a
linear discriminant function. The difference of two Mahalanobis distances is
d2(X, G1) −d2(X, G2) = 2(T2(X) −T1(X)).
If T1(X) ≥T2(X), then x ∈G1, otherwise x ∈G2.
More generally, suppose that there are k m-variate populations {Gi}i=1,...,k. For a
given sample X = (x1, . . . , xm), if d2
l (X) = mini=1,...,k { d2
i (X) }, then X ∈Gl.
5.5.2 Fisher method
Suppose that there are k m-dimensional populations {Gi}i=1,...,k with means μi and
the same covariance matrix Σ, and Gi has ni samples Xi1, . . . , Xini (i = 1, . . . , k). Let
̂μi =
̄Xi = 1
ni
ni
∑
j=1
Xij,
̄X = 1
n
k
∑
i=1
ni
∑
j=1
Xij = 1
n
k
∑
i=1
ni ̂μi,
where n = n1 + ⋅⋅⋅+ nk.
Denote C = (A + B)−1A, where
A =
k
∑
i=1
ni( ̄Xi −
̄X)( ̄Xi −
̄X)T,
B =
k
∑
i=1
ni
∑
j=1
(Xij −
̄Xi)(Xij −
̄Xi)T.

5.5 Discriminant analysis
|
135
Let λ1 be the largest eigenvalue of the matrix C and υ1 be the corresponding eigen-
vector. Then, for a given observation X = (x1, . . . , xm)T, a linear discriminant function
is z1 = υT
1X.
Suppose that
̂μ1, . . . ,
̂μk lie on a straight line. We compute k distances in the
straight line
di = |υT
1X −υT
1 ̂μi|
(i = 1, . . . , k).
Let dl = mini=1,...,k{di}. Then X ∈Gl.
Suppose that
̂μ1, . . . , ̂μk do not lie on a straight line but on a plane. Let λ2 be the
second largest eigenvalue of the matrix C and υ2 be the corresponding eigenvector.
Then, for a given observation X = (x1, . . . , xm)T, two discriminant functions are y1 =
υT
1X and y2 = υT
2X. We compute k distances in the plane
d2
i = (υT
1X −υT
1 ̂μi)2 + (υT
2X −υT
2 ̂μi)2
(i = 1, . . . , k).
Let d2
l = mini=1,...,k{ d2
i }. Then X ∈Gl. If necessary, three discriminant functions are
computed but usually two discriminant functions are sufficient by experience.
5.5.3 Bayes method
In the Mahalanobis distance method and Fisher method, we do not consider the prior
probability and the losses of mistaken decisions. Bayes method solves these two prob-
lems.
Prior probability
Suppose that there are k populations G1, . . . , Gk with given probabilities q1, . . . , qk,
where each qi > 0 and ∑k
i=1 qi = 1. Let X = (x1, . . . , xm) be an individual. Deﬁne a
generalized square distance from X to a population Gi as
D2(X, Gi) = d2
i (X) + h1(i) + h2(i)
(i = 1, . . . , k),
where d2
i (X) is the Mahalanobis distance between X and Gi and
h1(i) =
{
{
{
0
if Σ1 = ⋅⋅⋅= Σk,
log|Si|
otherwise,
h2(i) =
{
{
{
0
if q1 = ⋅⋅⋅= qk,
−2 log |qi|
otherwise.
Here Σi is the covariance matrix of Gi and Si is an estimate of Σi.
The decision method of generalized square distance is X ∈Gl if D2(X, Gl) =
mini=1,...,k D2(X, Gi).

136
|
5 Statistical methods
Posterior probability
When an individual X is known, we compute the probability P(X ∈Gi)
P(X ∈Gi) =
qifi(x)
∑k
1 qjfj(x)
(i = 1, . . . , k),
where fj(x) is the probability density of Gj and qj is the given probability associated
with Gj.
If each Gi is a normal population, then its density function is
fi(x) = (2π)−m
2 |Σ1|−1
2 e−1
2 d2
i (x)
and
P(X ∈Gi) =
e−1
2 d2
i (x)
∑k
1 e−1
2 d2
j (x) ,
where d2
i (x) = d2(X, Gi). The decision is X ∈Gi if P(X ∈Gi) = maxj=1,...,k P(x ∈Gj).
Suppose that there are k populations G1, . . . , Gk with prior probabilities q1, . . . ,
qk. A discriminant criterion D means that a partition of Rm
Rm = D1 ⋃D2 ⋃⋅⋅⋅⋃Dk
is given, where D1, . . . , Dk are mutually disjoint. For an individual X ∈Gi, we use
the criterion D to decide X ∈Gj (j
̸= i) and we may get a mistaken decision. Denote
the probability of making such a mistaken decision by P(j|i, D). Let the probability
density function of the proposition Gi be fi(x1, . . . , xm). Then
P(j|i, D) = ∫⋅⋅⋅∫
Dj
fi(x1, . . . , xm) dx1 ⋅⋅⋅dxm = ∫
Dj
fi(X) dX
(j
̸= i).
(5.5.4)
Let L(j|i, D) be the loss of a mistaken decision and L(j|i, D) be determined by
experience. Deﬁne the mean loss of mistaken decision as
g(D) =
k
∑
l=1
ql
k
∑
j=1
P(j|l, D)L(j|l, D).
(5.5.5)
If a discriminant method D∗is such that g(D∗) = minall D g(D), we say D∗conforms
to the Bayes criterion.
Bayes criterion
Suppose that there are k populations with joint density function f1(X), . . . , fk(X),
prior probabilities q1, . . . , qk, and the losses of mistaken decisions L(j|i, D). Then
D∗= (D∗
1, . . . , D∗
k) conforms to the Bayes criterion, where
D∗
i = { X | hi(X) < hj(X)
(j
̸= i, j = 1, . . . , k) },
hj(X) =
k
∑
l=1
qlL(j|l, D)fl(X).
(5.5.6)

5.6 Cluster analysis
|
137
In fact, by (5.5.4), (5.5.5), and (5.5.6),
g(D∗) =
k
∑
l=1
ql
k
∑
j=1
(∫
D∗j
fl(X) dX) L(j|l, D∗)
=
k
∑
j=1
∫
D∗
j
(
k
∑
l=1
qlfl(X)L(j|l, D∗)) dX =
k
∑
j=1
∫
D∗
j
hj(X) dX.
If D = (D1, . . . , Dk) is any partition on ℝm, then the mean loss caused by them is
g(D) = ∑k
l=1 ∫Dl hl(X)dX. So
g(D∗) −g(D) =
k
∑
j=1
∫
D∗
j
hj(X) dX −
k
∑
l=1
∫
Dl
hl(X) dX
=
k
∑
l=1
k
∑
j=1
∫
D∗
j ⋂Dl
(hj(X) −hl(X)) dX.
By (5.5.6), g(D∗) ≤g(D), i.e., D∗conforms the Bayes criterion.
5.6 Cluster analysis
Cluster analysis is to partition all individuals into subgroups such that individuals in
the same subgroup have similar characteristics. This necessitates devising a rule to
measure the similarity between two individuals.
Let X1, . . . , Xn be n individuals of m-dimensional random vectors. Ordinarily,
one measures the similarity by the distance between Xi and Xj. When the distance is
small, we say Xi and Xj are similar.
Now we deﬁne the distances between two individuals and between two sub-
groups.
Let Xi = (xi1, . . . , xim) (i = 1, . . . , n). To ensure that all individuals have a similar
scale, one uses the standardized data of individuals. Denote the individual mean vec-
tor by
̄X = ( ̄X1, . . . , ̄Xn)T and the individual covariance matrix by S = (Sij)m×m. Then
the standardized transform is deﬁned as
x∗
ij = xij −
̄Xj
Sj
(i = 1, . . . , n; j = 1, . . . , m),
where S2
j =
1
n−1 ∑n
i=1(xij −
̄Xj)2 (j = 1, . . . , m).
5.6.1 Distance between individuals Xi and Xj
–
Minkowski distance is deﬁned as
dij(p) = (
m
∑
k=1
|xik −xjk|p)
1
p
(i, j = 1, . . . , n; 0 ≤p ≤∞).

138
|
5 Statistical methods
Specially, the following distance measures are called
absolute value distance:
dij(1) =
m
∑
k=1
|xik −xjk|;
Euclidean distance:
dij(2) = (
m
∑
k=1
|xik −xjk|2)
1
2
;
Euclidean distance with variance weight:
d∗
ij(2) = (
m
∑
k=1
|xik −xjk|2
Sk
)
1
2
;
Chebyshev distance:
dij(∞) =
max
k=1,...,m|xik −xjk|.
–
Mahalanobis distance is deﬁned as
dij(M) = (Xi −Xj)TS−1(Xi −Xj).
–
The distance is deﬁned as d2
ij = 1 −c2
ij, where cij is equal to cosine of angle αij
between m-dimensional vectors (xi1, . . . , xim) and (xj1, . . . , xjm)
cij = cos αij =
∑m
k=1 xikxjk
(∑m
k=1 x2
ik)
1
2 (∑m
k=1 x2
jk)
1
2
(i, j = 1, . . . , n).
The cij is called the similarity coefficient between Xi and Xj.
5.6.2 Distance between subgroups Gp and Gq
Denote by Dpq the distance between Gp and Gq.
–
Single linkage: Dpq = minXi∈Gp,Xj∈Gq dij.
–
Complete method: Dpq = maxXi∈Gp,Xj∈Gq dij.
–
Gentraid method: Let Gr = Gp ⋃Gq, and np and nr be cardinal numbers of Gp
and Gq, respectively, and
̄Xp and
̄Xq be mean values of Gp and Gq, respectively.
Then the mean value of Gr is
̄Xr = 1
nr
(np ̄Xp + nq ̄Xq)
(nr = np + nq).
For a subgroup Gk (k
̸= p, q) with the mean value
̄Xk, the distance Drk between
Gr and Gk is Drk = d( ̄Xr, ̄Xk), where d is the Euclidean distance.
–
Average linkage: Let np, nq be a cardinal number of Gp, Gq, respectively. Deﬁne
the distance as
Dpq =
1
npnq
∑
Xi∈Gp, Xj∈Gq
d2
ij.

5.7 Principal component analysis
|
139
5.6.3 Hierarchical cluster method
Suppose that there are n individuals and each individual has m indices.
Step 1. Start from n clusters with each cluster containing only one individual. Com-
pute the distance between any two individuals to obtain a matrix of distances.
Step 2. Combine two nearest pair of clusters.
Step 3. Compute the distances between the newly formed clusters to obtain a new
matrix of distances.
Step 4. Repeat steps 2 and 3 until there is one cluster left.
Step 5. Determine the number of clusters and members of each cluster.
5.7 Principal component analysis
In multivariate statistical analysis, many variables may be highly correlated and the
covariance matrix is of high dimension. For statistical inference, there may be too
many parameters. Therefore, one hopes to reduce the number of variables without
much loss of information.
5.7.1 Principle component decomposition
The main idea of principal component analysis (PCA) is to transform the set of vari-
ables X1, . . . , Xm with mean 0 and covariance matrix Σ into a smaller set of un-
correlated new variables Y1, . . . , Yk (k < m) without much loss of information and
Y1, . . . , Yk are a linear combination of original variables X1, . . . , Xm.
Consider a linear combination
Yi =
m
∑
j=1
aijXj
(i = 1, . . . , m).
The matrix form is Y = AX, where
A = (aij)i,j=1,...,m,
X = (X1, . . . , Xm)T,
Y = (Y1, . . . , Ym)T.
Denote the i-th row vector of A by Ai, i.e., Ai = (Ai1, . . . , Aim). The covariance matrix
of Y is
E[YYT] = E[AXXTAT] = AE[XXT]AT.
Since Σ = E[XXT], E[YYT] = AΣAT, and so
Var(Yi) = AiΣAT
i ,
Cov(Yi, Yj) = AiΣAT
j
(i, j = 1, . . . , m).

140
|
5 Statistical methods
Since the covariance matrix Σ is a real symmetric matrix and is nonnegative deﬁnite,
all eigenvalues are nonnegative real numbers satisfying λ1 ≥λ2 ≥⋅⋅⋅≥λm ≥0 and
the corresponding eigenvectors a∗
1, . . . , a∗
m with unit length are linear independent.
Denote a∗
i = (a∗
1i, . . . , a∗
mi)T (i = 1, . . . , m). Deﬁne
Y∗
i =
m
∑
j=1
a∗
ijXj.
(5.7.1)
Then
Var(Y∗
i ) = (a∗
i )TΣa∗
i = λi
(i, j = 1, . . . , m),
Cov(Y∗
i , Y∗
j ) = 0
(i
̸= j; i, j = 1, . . . , m).
(5.7.2)
These new variables Y∗
1 , . . . , Y∗
m are obtained by linear combination of original
variables X1, . . . , Xm. These new variables are called principal components. The goal
of principal component analysis is to replace the original set of variables by the ﬁrst
few principal components if the ﬁrst few principal components can explain most
variability.
We rewrite (5.7.1) into the matrix form Y∗= A∗X, where
Y∗= (Y∗
1 , . . . , Y∗
m)T,
X = (X1, . . . , Xm)T,
A∗= (a∗
ij)i,j=1,...,m
and A∗is an orthogonal matrix whose column vectors are m eigenvectors A∗=
(a∗
1, . . . , a∗
m). So
X = (A∗)−1Y∗= (A∗)TY∗.
Since A∗= (a∗
1, . . . , a∗
m) and Y∗= (Y∗
1 , . . . , Y∗
m)T,
X =
m
∑
1
Y∗
i a∗
i .
(5.7.3)
Since the total variation of X = (X1, . . . , Xm)T is equal to Tr(Σ) (i.e., the trace of
covariance matrix Σ). The trace Tr(Σ) is equal to the sum of eigenvalues Tr(Σ) = λ1 +
⋅⋅⋅+ λm. By (5.7.2), the importance of the j-th principal component can be measured by
the ratio λj/Tr(Σ) (j = 1, . . . , m). So the importance of the ﬁrst k principal components
can be measured by the ratio
k
∑
1
λj/ Tr(Σ).
If we use two principal components to replace the original m variables without much
loss of information, we can obtain better parameter estimates and better use of graph-
ical tools.

5.7 Principal component analysis
|
141
In practice, the covariance matrix Σ of X is unknown. We should use samples
to estimate it. Suppose that there is a sample {xj}j=1,...,n, where xj = (x1j, . . . , xmj)T
(j = 1, . . . , n) are the m-dimensional vectors. The covariance matrix Σ has an estimate
̂Σ = (αij)i,j=1,...,m, where αij = 1
n ∑n
k=1 xkixkj (i, j = 1, . . . , m). The accuracy of these
estimates depends on the sample size n. Since results of principal component analysis
depend on units of variables, it is desirable that the original data has a similar scale.
Therefore, one often performs PCA on the standardized data zij = xij/ ̂σj, where
̂σj is
the estimate of variance of xj.
Let ̂λ1 ≥̂λ2 ≥⋅⋅⋅≥̂λm be the eigenvalues of
̂Σ and the corresponding eigenvectors
with unit length be
̂a∗
1, . . . , ̂a∗
m. Denote
̂a∗
i = ( ̂a∗
1i, . . . , ̂a∗
mi)T (i = 1, . . . , m). Deﬁne
̂y∗
i =
m
∑
j=1
̂a∗
ijxj
(i = 1, . . . , m).
Let
̂y∗
i = ( ̂y∗
i1, . . . , ̂y∗
in)T. Then
̂y∗
il =
m
∑
j=1
̂a∗
ijxjl
(i = 1, . . . , m; l = 1, . . . , n).
These new data { ̂y∗
il}m×n are called principal component scores and are used for further
analysis.
5.7.2 Rotation of principal components
Assume that for m random variables X1, . . . , Xm with mean 0, we ﬁnd k princi-
pal components Y1, . . . , Yk without much loss of information. Each variable Xi has
practical meaning but each Yi does not always have practical meaning. Take a k × k
orthogonal matrix G. Deﬁne
Z = GY,
where Z = (z1, . . . , zk)T and Y = (Y1, . . . , Yk)T. The z1, . . . , zk are called the rotated
principal components. They are some new linear combination of X1, . . . , Xm and pos-
sess the following two properties:
–
the total variance is invariant, i.e.,
k
∑
1
Var(zi) =
k
∑
1
Var(Yi) =
k
∑
1
λi,
where λ1, . . . , λk are the ﬁrst k eigenvalues of covariance matrix of X;
–
z1, . . . , zk are correlated, i.e., Cov(zi, zj)
̸= 0 (i
̸= j).

142
|
5 Statistical methods
5.8 Canonical correlation analysis
Canonical correlation analysis is a kind of statistical method to study the rela-
tionship between two random vectors X and Y, where X = (X1, . . . , Xp)T and
Y = (Y1, . . . , Yq)T. Assume that the means of X and Y are both 0. We hope to
choose a p-dimensional vector f1 = (f11, . . . , f1p)T and a q-dimensional vector
g1 = (g11, . . . , g1q)T such that α1 = ∑p
k=1 f1kXk and β1 = ∑q
l=1 g1lYl satisfy the following
two conditions:
(a) the correlation coefficients of α1 and β1 attain the maximal value;
(b) Var(α1) = Var(β1) = 1.
To ﬁnd f1 and g1, we ﬁrst state the concepts of the square roots and singular values
of matrices.
Let A be a real symmetric nonnegative deﬁnite matrix. Then there is an orthogonal
matrix Γ such that
A = Γ diag(λ1, . . . , λm)ΓT,
where λ1 ≥λ2 ≥⋅⋅⋅≥λm > 0. Deﬁne the square root of A as
A
1
2 = Γ diag(√λ1, . . . , √λm)ΓT.
It is easy to prove that A
1
2 A
1
2 = A.
Let B be an m × n matrix with rank r. Then there exists an m × m orthogonal
matrix C and an n × n orthogonal matrix D such that
B = C (G
0
0
0) DT,
where G = diag(μ1, . . . , μr) (r ≤min{ m, n }) and μ1 ≥μ2 ≥⋅⋅⋅≥μr ≥0. Each μk is
called a singular value. The k-th column vector Ck of the matrix C is called the left
singular vector of B. The k-th column vector Dk of the matrix D is called the right
singular vector of D.
Using the Lagrange multiplier method, the following f1 and g1
f1 = Σ
−1
2
XXC1,
g1 = Σ
−1
2
YYD1
satisfy the above conditions (a) and (b), where ΣXX and ΣYY are covariance matrices of
X and Y, respectively, and C1 and D1 are the left and right singular vectors of matrix
S = Σ
−1
2
XXΣXYΣ
−1
2
YY corresponding to the maximal singular values μ1 of S, and ΣXY is the
covariance matrix of X and Y. Moreover,
Cov(α1, β1) = √μ1.

5.9 Factor analysis
|
143
Assume that S has r nonzero singular values μ1 ≥μ2 ≥⋅⋅⋅≥μr > 0. We further ﬁnd
fk and gk (k = 1, . . . , r) such that αk = f T
k X and βk = gT
kY (k = 1, . . . , r) satisfy
Var(αk) = Var(βk) = 1,
Cov(αk, βk) = √μk,
(fk, fl) = (gk, gl) = 0
(k
̸= l),
(fk, gl) = δkl
(k, l = 1, . . . , r),
where δij is the Kronecker delta.
5.9 Factor analysis
Factor analysis is to remove redundancy from a set of correlated statistical variables
and represent these variables with a smaller set of new statistical variables.
5.9.1 The factor analysis model
Let X = (X1, . . . , Xp)T be a random vector with mean 0. The factor analysis model can
be written as
Xk =
m
∑
i=1
λkifi + εk
(k = 1, . . . , p, m ≤p),
where fi’s are called factors and λki is called a loading of the k-th variable on the i-th
factor, which reﬂects the relative importance of the i-th factor for the k-th variable,
and εk’s are random errors. The matrix form of the factor analysis model is
X = ΛF + ϵ,
(5.9.1)
where Λ = (λkl)p×m is the factor loading matrix, F = (f1, . . . , fm)T is the common factor
vector, and ϵ = (ε1, . . . , εm)T.
The assumptions for factor analysis are
–
factors fk’s are independently and identically distributed with mean 0 and vari-
ance 1;
–
random errors εk’s are independent with mean 0 and variance ψk;
–
fk and εj are independent for any k and j.
5.9.2 The factor analysis equation
Let X be a random vector with mean 0. Then the covariance matrix of X is
Σ = E[XXT] = E[(ΛF)(ΛF)T] + E[ϵ(ΛF)T] + E[(ΛF)ϵT] + E[ϵϵT] = A + B + C + D

144
|
5 Statistical methods
and by the assumption,
A = E[ΛFFTΛT] = ΛE[FFT]ΛT = ΛΛT,
B = E[ϵFT]ΛT = 0,
C = ΛE[FϵT] = 0,
D = E[ϵϵT] = diag(ψ1, . . . , ψp) =: Ψ.
So
Σ = ΛΛT + Ψ,
(5.9.2)
where Ψ = diag(ψ1, . . . , ψp). This equation (5.9.2) is called a factor analysis equation.
Let Σ = (σkl)p×m. Then the variance of Xk is
σkk =
m
∑
j=1
λ2
kj + ψk
(k = 1, . . . , p).
Therefore, the proportion of variance of Xk explained by factors f1, . . . , fm is ∑m
j=1 λ2
kj/
σkk. The the factor loading matrix Λ is not unique.
5.9.3 Parameter estimate method
The goal of factor analysis is to describe the structure of covariance of p variables by
only a few factors. So this needs estimate factor loadings {λki} and variances ψk of
errors.
Maximal likelihood method
If factors f 󸀠
ks and errors ϵ󸀠
ks follow normal distributions, the maximal likelihood esti-
mates of the loading matrix and random error can be obtained. By the factor analysis
equation, the sample likelihood function is
L( ̄X, Σ) = L( ̄X, ΛΛT + Ψ) =: φ(Λ, Ψ).
We choose Λ0 and Ψ0 such that φ(Λ, Ψ) attains the maximal value. It can be proved
that Λ0 and Ψ0 satisfy the system of equations
{
{
{
SΨ−1
0 Λ0 = Λ0(I + ΛTΨ−1
0 Λ0),
Λ0 = diag(S −Λ0ΛT
0),
(5.9.3)
where S = 1
n ∑n
k=1(Xk −
̄X)(Xk −
̄X)T is the sample covariance matrix.
To ensure that the system of equations (5.9.3) has a unique solution, Bayes sug-
gested to add a condition that ΛT
0Ψ−1
0 Λ0 is a diagonal matrix. The system of equations
is solved using the iteration method.

5.9 Factor analysis
|
145
Principal component method
Let the eigenvalues of the sample covariance matrix Σ be λ1 ≥⋅⋅⋅≥λp ≥0 and the
corresponding unit orthogonal eigenvectors be l1, l2, . . . , lp, i.e.,
lSlT = diag(λ1, . . . , λp),
S = lT diag(λ1, . . . , λp)l =
p
∑
1
λililT
i =
m
∑
1
λililT
i +
p
∑
m+1
λililT
i ,
where l = (l1, . . . , lp). This formula is called spectral decomposition. When the eigen-
values λm+1, . . . , λp are small, S may decompose approximately into
S ≈(√λ1 l1, . . . , √λm lm) (
√λ1 lT
1
...
√λm lT
m
) + diag(ψ1, . . . , ψp) = ΛΛT + Ψ,
where
Λ = (√λ1 l1, . . . , √λm lm) =: (λki)p×m,
Ψ = diag(ψ1, . . . , ψp),
ψk = Skk −
m
∑
i=1
λ2
ki
(k = 1, . . . , p).
This gives a solution of the factor analysis equation. The j-th column of the loading
matrix is √λj times the j-th principal component of X. Denote the error
S −(ΛΛT + Ψ) = (ηij)p×p.
It can be proved that ∑p
i,j=1 η2
ij ≤∑p
m+1 λ2
j . Therefore, we may choose m such that the
error is very small. One often chooses m such that
m
∑
1
λj
p
∑
1
λj
≥0.7.
5.9.4 Rotation of a loading matrix
The goal of factor analysis is not only to ﬁnd common factors but also to know the
practical meaning of each common factor. In Section 5.9.3 we found the initial com-
mon factor using the maximal likelihood method and principal component method.
In order to ensure that each common factor has practical meaning, we should choose
an orthogonal matrix Q such that Λ∗:= ΛQ is also a loading matrix, and the new
common factors have practical meaning.
In fact, since Q is an orthogonal matrix, QQT = I and Λ∗(Λ∗)T = ΛQQTΛt = ΛΛT,
and so
Σ = Λ∗(Λ∗)T + Ψ,
X = ΛF + ϵ = ΛQ(QTF) + ϵ = Λ∗Z + ϵ,

146
|
5 Statistical methods
where Z = QTF and the covariance matrix of Z is ΣZ = E[ZZT] = E[QTFFTQ] = I and
Cov(Z, ϵ) = Cov(QTF, ϵ) = QT Cov(F, ϵ) = 0.
It is seen that if F is the common factor vector of the factor model, then, for any or-
thogonal matrix Q, Z = QTF is also the common factor vector and ΛQ is the loading
matrix of the common factor Q. We should use rotation repeatedly such that many
factor loadings tend to zero and maximize other factor loadings. So this lets us focus
on those factors with large loadings. This method is called the orthogonal rotation of
factor axes.
Suppose that the factor analysis model is X = ΛF + ϵ and Λ = (λij)p×m. Let h2
i =
∑m
j=1 λ2
ij (i = 1, . . . , p). Then h2
i is called communality of the variable Xi. Let
d2
ij =
λ2
ij
h2
i
(i = 1, . . . , p; j = 1, . . . , m),
D =
(
(
(
(
d11
⋅⋅⋅
d1j
⋅⋅⋅
d1m
...
...
...
...
...
di1
⋅⋅⋅
dij
⋅⋅⋅
dim
...
...
...
...
...
dp1
⋅⋅⋅
dpj
⋅⋅⋅
dpn
)
)
)
)
.
The variance of p data in the j-th column of D is deﬁned as
Vj = 1
p
p
∑
i=1
(d2
ij −̄d2
j ),
where
̄dj = 1
p ∑p
i=1 d2
ij (j = 1, . . . , m). This implies that
Vj = 1
p
p
∑
i=1
(
λ4
ij
h4
i
−1
p2 (
p
∑
μ=1
λ2
μj
h2μ
)
2
) .
The variance of the factor loading matrix Λ is
V =
m
∑
j=1
Vj = 1
p2
m
∑
j=1
(p
p
∑
i=1
λ4
ij
h4
i
−(
p
∑
μ=1
λ2
μj
h2μ
)
2
) .
Through a rotation of a loading matrix, we expect that the variance V is large such
that the loading values tend to 1 or tend to 0. In this way, the corresponding common
factors have a simpliﬁed structure.

Further reading
|
147
Further reading
[1]
Bao G, Liu Y, Linderholm HW. April-September mean maximum temperature inferred from Hailar
pine tree rings in the Hulunbuir region, Inner Mongolia, back to 1868 AD. Palaeogeogr Palaeo-
climatol Palaeoecol. 2012(313–314):162–172.
[2]
Chen F, Yuan Y, Wei W, Yu S, Zhang T. Reconstructed temperature for Yongan, Fujian, Southeast
China: Linkages to the Paciﬁc Ocean climate variability. Global Planet Change. 2012(86–87):
11–19.
[3]
Gao J, Shi Z, Xu L, Yang X, Jia Z, Lu S, Feng C, Shang J. Precipitation variability in Hulunbuir,
northeastern China since 1829 AD reconstructed from tree-rings and its linkage with remote
oceans. J Arid Environ. 2013(95):14–21.
[4]
Gregg D, Rolfe J. The value of environment across efficiency quantiles: A conditional regres-
sion quantiles analysis of rangelands beef production in North Eastern Australia. Ecological
Economics. 2016(128):44–54.
[5]
Fernandez P, Mourato S, Moreira M, Pereira L. A new approach for computing a ﬂood vulner-
ability index using cluster analysis. Physics and Chemistry of the Earth, Parts A/B/C. 2016:
in press.
[6]
Jones M, Randell D, Ewans K, Jonathan P. Statistics of extreme ocean environments: Non-
stationary inference for directionality and other covariate effects. Ocean Engineering.
2016(119):30–46.
[7]
Liu Y, Bao G, Song H, Cai Q, Sun J. Precipitation reconstruction from Hailar pine tree rings in the
Hailar region, Inner Mongolia, China back to 1865 AD. Palaeogeogr Palaeoclimatol Palaeoecol.
2009(282):81–87.
[8]
Parinet J, Julien M, Nun P, Robins RJ, Remaud G, Hohener P. Predicting equilibrium vapour
pressure isotope effects by using artiﬁcial neural networks or multi-linear regression – A quan-
titative structure property relationship approach. Chemosphere. 2015(134):521–527.
[9]
Parente J, Pereira MG, Tonini M. Space-time clustering analysis of wildﬁres: The inﬂuence of
dataset characteristics, ﬁre prevention policy decisions, weather and climate. Science of the
Total Environment. 2016(559):151–165.
[10] Roberts-Jones J, Bovis K, Martin MJ, McLaren A. Estimating background error covariance pa-
rameters and assessing their impact in the OSTIA system. Remote Sensing of Environment.
2016(176):117–138.
[11] Singh S, Prakash A, Chakraborty NR, Wheeler C, Agarwal PK, Ghosh A. Trait selection by path
and principal component analysis in Jatropha curcas for enhanced oil yield. Industrial Crops
and Products. 2016(86):173–179.
[12] Tan KC, Lim HS, Jafri MZM. Prediction of column ozone concentrations using multiple re-
gression analysis and principal component analysis techniques: A case study in peninsular
Malaysia. Atmospheric Pollution Research. 2016: in press.
[13] Wang Y, Lu R, Ma Y, Sang Y, Meng H, Gao S. Annual variation in PDSI since 1897 AD in the Teng-
ger Desert, Inner Mongolia, China, as recorded by tree-ring data. J Arid Environ. 2013(98):
20–26.
[14] Weichenthal S, Ryswyk KV, Goldstein A, Bagg S, Shekkarizfard M, Hatzopoulou M. A land use
regression model for ambient ultraﬁne particles in Montreal, Canada: A comparison of linear
regression and a machine learning approach. Environmental Research. 2016(146):65–72.
[15] Zhang Z. Tree-Rings, a key ecological indicator of environment and climate change. Ecological
Indicators. 2015(51):107–116.
[16] Zhao X, Qian J, Wang J, He Q, Wang Z, Chen C. Using a tree ring δ13C annual series to recon-
struct atmospheric CO2concentration over the past 300 years. Pedosphere. 2006(16):371–79.

6 Numerical methods
Numerical methods are widely used in each branch of environmental science. While
environmental simulation, prediction and impact assessment depend on mathemati-
cal models, numerical methods provide a practical approach in quickly computing the
solution of these models. In this chapter, we will introduce numerical integration and
differentiation, numerical linear algebra, and numerical solution of ordinary differen-
tial equations and partial differential equations by using iterative method, difference
method, ﬁnite element method, and wavelet method.
6.1 Numerical integration
Let xk ∈[a, b] (k = 1, . . . , n). If a function f is a continuous function on [a, b] and
f(xk) (k = 1, . . . , n) are known, the quadrature formula for the integral ∫
b
a f(x) dx is
b
∫
a
f(x) dx ≐
n
∑
1
Akf(xk),
where xk are called nodes and Ak are called quadrature coefficients.
Throughout this chapter, the notation A ≐B means that A is equal approximately
to B.
One wants to choose suitable nodes xk and coefficients Ak such that the error
en(f) =
b
∫
a
f(x) dx −
n
∑
k=1
Akf(xk)
is as small as possible.
6.1.1 Interpolation-type quadrature formulas
Assume that f is a continuous function on [a, b] and a ≤x1 ≤x2 ≤⋅⋅⋅≤xn ≤b. Let
ωn(x) = (x −x1)(x −x2) ⋅⋅⋅(x −xn),
lk(x) =
ωn(x)
ω󸀠n(xk)(x −xk)
(k = 1, . . . , n).
The Lagrange interpolation polynomial for f is L(x) = ∑n
k=1 f(xk)lk(x) (see Section 4.2).
Since f(x) ≐L(x),
b
∫
a
f(x) dx ≐
b
∫
a
(
n
∑
1
f(xk)lk(x)) dx =
n
∑
1
Akf(xk),
(6.1.1)
DOI 10.1515/9783110424904-007

6.1 Numerical integration
|
149
where Ak = ∫
b
a lk(x) dx (k = 1, . . . , n). Assume further that f ∈Cn([a, b]). Then the
error is estimated by
|en(f)| =
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
1
n!
b
∫
a
f (n)(ξx)ωn(x) dx
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
≤C
n! max
a≤x≤b |f (n)(x)|,
where C = ∫
b
a |ωn(x)| dx. If f is a polynomial of degree ≤n −1, then f(x) ≡L(x). So
(6.1.1) is exact, i.e.,
b
∫
a
f(x) dx =
n
∑
1
Ak f(xk).
Let n = 2, x1 = a, x2 = b in (6.1.1). The trapezoidal formula is
b
∫
a
f(x) dx ≐b −a
2
(f(a) + f(b)).
Let n = 3, x1 = a, x2 = a+b
2 , x3 = b in (6.1.1), then the Simpson formula is
b
∫
a
f(x) dx ≐b −a
6
(f(a) + 4f ( a + b
2
) + f(b)) .
Let h = b−a
n
and xk = a + kh(k = 0, . . . , n). Applying the trapezoidal formula on
each interval [xk, xk+1] (k = 0, . . . , n −1), the complicated trapezoidal formula is given
by
b
∫
a
f(x) dx ≐h
2 (f(a) + 2
n−1
∑
1
f(a + kh) + f(b)) .
If f ∈C2([a, b]), the error is
en(f) = −(b −a)3
12n2
f 󸀠󸀠(η1)
(a ≤η1 ≤b).
Let h = b−a
2m and xk = a + kh (k = 0, . . . , 2m). Applying the Simpson formula on
each interval [x2k−2, x2k] (k = 1, . . . , m), the complicated Simpson formula is given by
b
∫
a
f(x) dx ≐h
3 (f(a) + 4
m
∑
1
f(x2k−1) + 2
m−1
∑
1
f(x2k) + f(b)) .
If f ∈C4([a, b]), the error is
en(f) = −(b −a)5
2880m4 f (4)(η2)
(0 ≤η2 ≤b).

150
|
6 Numerical methods
6.1.2 Gauss quadrature formula
One expects to choose nodes such that the quadrature formula becomes more precise.
The zeros of Legendre polynomials play such a role. It is well known that Legendre
polynomials
Pn(x) =
1
2nn!
dn(x2 −1)n
dxn
(n = 0, 1, . . . )
are orthogonal polynomials on [−1,1] with weight 1. Its n zeros x(n)
k
satisfy −1 < x(n)
1 <
⋅⋅⋅< x(n)
n
< 1. If the interpolation nodes are zeros of the Legendre polynomial, then the
Gauss–Legendre quadrature formula is
1
∫
−1
f(x) dx ≐
n
∑
1
A(n)
k f(x(n)
k ),
where
A(n)
k
= 2(1 −(x(n)
k )2)
n2P2
n−1(x(n)
k )
.
This formula is also the classical Gauss quadrature formula. For f ∈C2n([−1, 1]), the
error is
en(f) =
22n+1(n!)4
(2n + 1)((2n)!)3 f (2n)(ξ)
(−1 < ξ < 1).
If f is a polynomial of degree ≤2n −1, then the Gauss–Legendre quadrature formula
is exact, i.e.,
1
∫
−1
f(x) dx =
n
∑
1
A(n)
k f(x(n)
k ).
More generally, assume that { ωn(x)} is a monic orthogonal polynomial system on
[a, b] with weight ρ(x). Take zeros {x(n)
k }k=1,...,n of ωn(x) as nodes. The general Gauss
quadrature formula is
b
∫
a
f(x)ρ(x) dx ≐
n
∑
1
A(n)
k f(x(n)
k ),
where
A(n)
k
=
b
∫
a
ρ(x)ωn(x)
(x −x(n)
k )ω󸀠n(x(n)
k )
dx.
Assume further that f ∈C2n([a, b]). The error is
en(f) =
b
∫
a
f(x)ρ(x) dx −
n
∑
1
A(n)
k f(x(n)
k ) = f (2n)(ξ)
(2n)!
b
∫
a
ρ(x)ω2
n(x) dx
(a < ξ < b).

6.1 Numerical integration
|
151
If f is a polynomial of degree ≤2n −1, the general Gauss quadrature formula is exact,
i.e.,
b
∫
a
f(x)ρ(x) dx =
n
∑
1
A(n)
k f(x(n)
k ).
As a special case, the monic Chebyshev polynomials
̃Tn(x) = cos(n arccos x)
2n−1
(n = 0, 1, . . . )
are an orthogonal polynomial on [−1, 1] with weight ρ(x) =
1
√1−x2 . Taking its zeros
xk = cos 2k−1
2n π (k = 1, . . . , n) as nodes, the general Gauss quadrature formula is
1
∫
−1
f(x)
√1 −x2 dx = π
n
n
∑
1
f (cos 2k −1
2n
π) +
π
(2n)!22n−1 f (2n)(ξ)
(−1 < ξ ≤1).
This formula is also called the Hermite formula.
6.1.3 Gauss quadrature formula on inﬁnite intervals
Laguerre polynomials
Ln(x) = ex dn
dxn (e−xxn)
(n = 0, 1, . . . )
are orthogonal polynomials on [0, ∞) with weight ρ(x) = e−x. Its n zeros x(n)
k
satisfy
0 < x(n)
1
< ⋅⋅⋅< x(n)
n
< ∞. Take these zeros as interpolation nodes. The Gauss–Laguerre
quadrature formula is
∞
∫
0
e−xf(x) dx ≐
n
∑
1
A(n)
k f(x(n)
k ),
where
A(n)
k
=
(n!)2
x(n)
k (L󸀠n(x(n)
k ))2 .
Assume that f ∈C2n([0, ∞)). Then the error is
en(f) = (n!)2
(2n)! f (2n)(ξ)
(0 < ξ < ∞).
Hermite polynomials
Hn(x) = (−1)nex2 dn
dxn (e−x2)
(n = 0, 1, . . . )

152
|
6 Numerical methods
are orthogonal polynomials on (−∞, ∞) with weight ρ(x) = e−x2 . Take its zeros as
interpolation nodes. The Gauss–Hermite quadrature formula is
∫
ℝ
e−x2f(x) dx ≐
n
∑
1
A(n)
k f(xk),
where
A(n)
k
= 2n+1n!√π
(H󸀠n(x(n)
k ))2 .
Assume that f ∈C2n(ℝ). The error is
en(f) =
n!√π
2n(2n)! f (2n)(ξ)
(ξ ∈ℝ).
If f is a polynomial of degree ≤2n −1, then the Gauss–Laguerre quadrature formula
and the Gauss–Hermite quadrature formula are both exact.
6.2 Numerical differentiation
Assume that a function is smooth on a closed interval and its values at some points on
the closed interval are known. The numerical differentiation algorithm is to estimate
its derivative by its values at these points.
6.2.1 Differentiation via polynomial interpolation
Let f(x) be a smooth function on [a, b] and a =< x1 < ⋅⋅⋅< xn = b. We use the deriva-
tive of the Lagrange interpolation polynomial Ln(x) to estimate the derivative of f as
follows:
f 󸀠(xk) ≐L󸀠
n(xk)
(k = 1, . . . , n).
By (4.2.5),
f(x) −Ln(x) = 1
n! f (n)(ξx) ωn(x)
(a < ξx < b),
where ωn(x) = (x −x1) ⋅⋅⋅(x −xn). Differentiating both sides gives
f 󸀠(x) −L󸀠
n(x) = f (n)(ξx)
n!
dωn(x)
dx
+ ωn(x)
n!
df (n)(ξx)
dx
.
Let x = xk. Note that ωn(xk) = 0. Then
f 󸀠(xk) −L󸀠
n(xk) = f (n)(ξx)
n!
ω󸀠
n(xk).
This derives the numerical differentiation formulas often used as follows.
Let xk+1 −xk = h (k = 1, . . . , n −1) and yk = f(xk) (k = 1, . . . , n).

6.2 Numerical differentiation
|
153
(a) Two-point form
L1(x) = x −x1
h
y2 −x −x2
h
y1
is the interpolation function with nodes x1 and x2. So
f 󸀠(x1) ≐L󸀠
1(x1) = y2 −y1
h
,
f 󸀠(x2) ≐L󸀠
1(x2) = y2 −y1
h
.
(b) Three-point form
L2(x) = (x −x2)(x −x3)
2h2
y1 −(x −x1)(x −x3)
h2
y2 + (x −x1)(x −x2)
2h2
y3
is the interpolation function with nodes x1, x2, x3. So the three-point form is
f 󸀠(x1) ≐L󸀠
2(x1) = −3y1 + 4y2 −y3
2h
,
f 󸀠(x2) ≐L󸀠
2(x2) = y3 −y1
2h
,
f 󸀠(x3) ≐L󸀠
2(x3) = y1 −4y2 + 3y3
2h
.
From L2(x), the second-order numerical differentiation formula is
f 󸀠󸀠(x1) = f 󸀠󸀠(x2) = f 󸀠󸀠(x3) = y1 −2y2 + y3
h2
.
In general, when Ln(x) converges to f(x), L󸀠
n(x) does not necessarily converge to
f 󸀠(x). To avoid this problem, we may use the spline interpolation function to ﬁnd dif-
ferentiation.
6.2.2 Differentiation via spline interpolation
Let f ∈C4([a, b]) and s(x) be its cube spline interpolation function associated with
partition a = x0 < x1 < ⋅⋅⋅< xn = b. When λ = max0≤k≤n−1|xk+1 −xk| →0, by Propo-
sition 4.4.2,
s(x) →f(x),
s󸀠(x) →f 󸀠(x),
s󸀠󸀠(x) →f 󸀠󸀠(x)
uniformly and the errors are estimated as
|f (i)(x) −s(i)(x)| ≤Cλ4−i
(i = 0, 1, 2),
where C is independent of x, and the partition and the representation of s(x) is stated
in Section 4.4.2.

154
|
6 Numerical methods
Find the derivative of ﬁrst order on [xk, xk+1] (k = 0, . . . , n −1), by (4.4.1), we get
s󸀠(x) = 6
δ2
k
( 1
δk
(x −xk+1)2 + (x −xk+1)) yk+1
+ 6
δ2
k
((x −xk) + 1
δk
(x −xk)2) yk
+ 1
δk
( 1
δ3
k
(x −xk+1)2 + 2(x −xk+1)) μk
−1
δk
(2(x −xk+1) −3
δk
(x −xk)2) μk+1.
So f 󸀠(x) ≈s󸀠(x). Especially, f 󸀠(xk) = μk (k = 0, . . . , n).
The representation of s󸀠󸀠(x) is stated as in (4.4.2). So f 󸀠󸀠(x) ≐s󸀠󸀠(x).
6.2.3 Richardson extrapolation
By the Taylor formula, it follows that for small h,
f(x + h) −f(x −h) = 2hf 󸀠(x) + 2
3! h3f 󸀠󸀠󸀠(x) + 2
5! h5f (5)(x) + ⋅⋅⋅.
or
f(x + h) −f(x −h)
2h
= f 󸀠(x) + 1
3! h2f 󸀠󸀠󸀠(x) + 1
5! h4f (5)(x) + ⋅⋅⋅.
Denote a2 = −f 󸀠󸀠󸀠(x)
3!
, a4 = −f (5)(x)
5!
,… . This equality becomes that for any small h,
f 󸀠(x) = φ(h) + a2h2 + a4h4 + a6h6 + ⋅⋅⋅=: L(h).
where
φ(h) = f(x + h) −f(x −h)
2h
.
(6.2.1)
This leads to
L(h) = L(h/2) = L(h/4) = ⋅⋅⋅.
So
4L(h) = 4L ( h
2) = 4φ ( h
2) + a2h2 + a4
h4
4 + a6
h6
16 + ⋅⋅⋅,
f 󸀠(x) = L(h) = 4
3 φ ( h
2) −1
3 φ(h) −1
4 a4h4 −5
16 a6h6 + ⋅⋅⋅,
(6.2.2)
and so
f 󸀠(x) = 4
3 φ ( h
2) −1
3 φ(h) + O(h4),
L(h) = g(h) + b4h4 + b6h6 + ⋅⋅⋅.

6.3 Iterative methods
|
155
where b4 = −a4
4 , b6 = −5a6
16 , and
g(h) = 4
3 φ ( h
2) −1
3 φ(h).
(6.2.3)
Note that L(h) = L( h
2). Then
16L(h) = 16g ( h
2) + b4h4 + b6
h6
4 + ⋅⋅⋅.
The combination of this with (6.2.2) gives
f 󸀠(x) = L(h) = 16
15 g ( h
2) −1
15 g(h) −b6h6
20
+ ⋅⋅⋅,
where b6 = −5
16 a6 =
5
16
f (7)(x)
7!
. From this and (6.2.1)–(6.2.3), it is seen that a simple
combination of φ(h), φ( h
2), and φ( h
4) furnishes an estimate of f 󸀠(x) with accuracy
O(h6).
Continue this procedure to give the more precise results.
6.3 Iterative methods
Iterative methods are used to solve nonlinear equations, systems of linear equations,
ordinary differential equations, and the matrix eigenvalue problem.
6.3.1 Fixed point principle
Given an equation f(x) = 0, where f is continuous, its equivalent form is x = φ(x),
where φ(x) = x + f(x). Starting with an initial value x0, we get the iterative sequence
{xn} as follows:
x1 = φ(x0),
x2 = φ(x1),
...
xn = φ(xn−1),
...
If {xn} converges to ξ , then ξ = φ(ξ). So ξ is a solution of f(x) = 0.
Fixed point principle
Assume that a function φ(x) satisﬁes
|φ(y1) −φ(y2)| ≤M |y1 −y2|
(y1, y2 ∈[a, b]),

156
|
6 Numerical methods
where 0 < M < 1 is a constant independent of y1 and y2. Take an initial value x0 ∈
(a, b). Then
–
the iterative sequence {xn} satisfying xn = φ(xn−1) converges.
Denote ξ = limn→∞xn.
–
ξ = φ(ξ), i.e., the ξ is the ﬁxed point of φ(x); and
–
the rate of convergence is |xn −ξ| ≤
Mn
1−M |x1 −x0|.
In fact, by the assumption, for any k ∈ℤ+,
|xk+1 −xk| = |φ(xk) −φ(xk+1)| ≤M |xk −xk+1| ≤⋅⋅⋅≤Mk|x1 −x0|.
This implies that
|xn+p −xn| ≤|xn+p −xn+p−1| + |xn+p−1 −xn+p−2| + ⋅⋅⋅+ |xn+1 −xn|
≤(Mn+p−1 + Mn+p−2 + ⋅⋅⋅+ Mn) |x1 −x0| = Mn(1 −Mp)
1 −M
|x1 −x0|. (6.3.1)
Since 0 < M < 1, limn→∞|xn+p −xn| = 0. Cauchy criterion indicates the iterative se-
quence {xn} converges. Denote ξ = limn→∞xn. From this and xn = φ(xn−1), it follows
that ξ = φ(ξ), i.e., ξ is the ﬁxed point of φ(x). Letting p →∞in (6.3.1), since xn+p →ξ
and Mp →0, we get the desired rate of convergence.
6.3.2 Iterative methods of univariate nonlinear equations
Let f ∈C2([a, b]), ξ be a zero of f , and x be an approximation to ξ . By Taylor’s formula,
0 = f(ξ) = f(x + h) = f(x) + hf 󸀠(x) + O(h2) ≈f(x) + hf 󸀠(x),
where h = ξ −x. This implies h ≐−f 󸀠(x)/f(x). Since x is an approximation to ξ , the
better approximation to ξ should be x −f(x)/f 󸀠(x).
Starting with an estimate x0 of ξ , Newton’s iterative method deﬁnes inductively
xn+1 = xn −f(xn)/f 󸀠(xn)
(n = 0, 1, . . . ).
If x0 is close to a zero of f , then the sequence {xn} converges to ξ . Especially, if f ∈
C2(ℝ) is an increasing and convex function and has only a zero, then the Newton it-
eration sequence {xn} converges to the zero of f from any stating point.
Since
f 󸀠(xn) ≐f(xn) −f(xn−1)
xn −xn−1
,
replacing f 󸀠(xn) by
f(xn) −f(xn−1)
xn −xn−1

6.3 Iterative methods
|
157
in the above Newton formula, the iteration formula becomes
xn+1 = xn −f(xn) [
(xn −xn−1)
f(xn) −f(xn−1)]
(n = 0, 1, . . . ).
This iterative method is simpler than the Newton iterative method but its convergence
rate is slower.
A polynomial of degree n
p(x) = anxn + an−1xn−1 + ⋅⋅⋅+ a0
has exactly n complex roots and its all roots lie in the disk with center 0 and radius
ρ = 1 + |an|−1 max0≤k≤n|ak|.
Horner’s algorithm can give the values of a polynomial and its derivatives simul-
taneously. Deﬁne αk and βk for k = 0, 1, . . . , n as follows:
αn = an,
βn = 0,
αn−1 = an−1 + xαn,
βn−1 = αn + xβn,
αn−2 = an−2 + xαn−1,
βn−2 = αn−1 + xβn−1,
...
...
α0 = a0 + xα1,
β0 = α1 + xβ1.
Then α0 = p(x) and β0 = p󸀠(x).
Using Horner’s algorithm, one can rapidly compute p(xk)/p󸀠(xk) to obtain xk+1 =
xk −p(xk)/p󸀠(xk) from xk in Newton’s method. This iterative process yields a root ξ of
p(x).
Let q(x) = p(x)/(x −ξ). Then q(x) is a polynomial of degree n −1. Denote
q(x) = bn−1xn−1 + bn−2xn−2 + ⋅⋅⋅+ b0.
We will ﬁnd bn−1, . . . , b0. From p(x) = (x −ξ)q(x), it follows that
anxn + an−1xn−1 + ⋅⋅⋅+ a0 = (x −ξ)(bn−1xn−1 + bn−2xn−2 + ⋅⋅⋅+ b0).
Comparing coefficients on both sides, we get
bn−1 = an,
bn−2 = an−1 + ξbn−1,
...
b0 = a1 + ξb1.
i.e., we get q(x). All roots of q(x) are the remaining (n −1) roots of p(x).
Repeating the above procedure in which p(x) is replaced by q(x), we get another
root of p(x). Continuing the procedure, ﬁnally, we get all roots of p(x).

158
|
6 Numerical methods
6.3.3 Iterative method of systems of bivariate nonlinear equations
Consider a system of nonlinear equations
{
{
{
f1(x, y) = 0,
f2(x, y) = 0,
where f1 and f2 are both continuously differentiable functions. A pair of initial values
(x0, y0) are given. Expanding f1, f2 in the neighborhood of (x0, y0) into Taylor series
using the Taylor theorem and taking their linear principal parts, respectively, we get
the following system of equations:
{
{
{
{
{
f1(x0, y0) + ∂f1
∂x (x0, y0)(x −x0) + ∂f1
∂y (x0, y0)(y −y0) = 0,
f2(x0, y0) + ∂f2
∂x (x0, y0)(x −x0) + ∂f2
∂y (x0, y0)(y −y0) = 0.
If the Jacobian determinant
J0 =
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
∂f1
∂x (x0, y0)
∂f1
∂y (x0, y0)
∂f2
∂x (x0, y0)
∂f2
∂y (x0, y0)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
̸= 0,
then the solution is
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
x1 = x0 −J−1
0
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
∂f1
∂y (x0, y0)
f1(x0, y0)
∂f2
∂y (x0, y0)
f2(x0, y0)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
,
y1 = y0 −J−1
0
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
f1(x0, y0)
∂f1
∂x (x0, y0)
f2(x0, y0)
∂f2
∂x (x0, y0)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
.
Continue this procedure, in general, starting from (xk, yk), if
Jk =
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
∂f1
∂x (xk, yk)
∂f1
∂y (xk, yk)
∂f2
∂x (xk, yk)
∂f2
∂y (xk, yk)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
̸= 0
(k ∈ℤ+),
the solution is
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
xk+1 = xk −J−1
k
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
∂f1
∂y (xk, yk)
f1(xk, yk)
∂f2
∂y (xk, yk)
f2(xk, yk)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
,
yk+1 = yk −J−1
k
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
f1(xk, yk)
∂f1
∂x (xk, yk)
f2(xk, yk)
∂f2
∂x (xk, yk)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
.
This gives the iterative process.
If max{ |xN+1 −xN|, |yN+1 −yN| } < ε. Then (xN+1, yN+1) is a desired solution.

6.3 Iterative methods
|
159
6.3.4 Iterative method to solve systems of linear equations
Consider a system of linear equations
n
∑
j=1
aijxj = bi
(i = 1, . . . , n).
(6.3.2)
The matrix form is Ax = b, where A = (aij)n×n, x = (x1, . . . , xn)T, and b = (b1, . . . , bn)T.
(a) Jacobian iterative method
The system of linear equations (6.3.2) can be rewritten in the form
xi =
n
∑
j=1
cijxj + di
(i = 1, . . . , n).
Take x(0)
1 , . . . , x(0)
n
as initial values. Applying the iterative formula, we get
x(k)
i
=
n
∑
j=1
cijx(k−1)
j
+ di
(i = 1, . . . , n),
which is called the Jacobian iterative formula. We ﬁnd the k-th approximate solution
such that
max
1≤i≤n|x(k)
i
−x(k−1)
i
| < ε,
where ε is a predictive error. So (x(k)
1 , . . . , x(k)
n ) is an approximate solution of (6.3.2)
with predictive error ε.
Let (x∗
1, . . . , x∗
n) be the exact solution. If μ = max1≤i≤n ∑n
j=1|cij| < 1, then the error
is estimated by
max
1≤i≤n |x(k)
i
−x∗
i | ≤
μk
1 −μ max
1≤i≤n |x(1)
i
−x∗
i |.
If ν = max1≤j≤n ∑n
i=1|cij| < 1, then the error is estimated by
n
∑
i=1
|x(k)
i
−x∗
i | ≤
νk
1 −ν
n
∑
i=1
|x(1)
i
−x∗
i |.
If p = ∑n
i,j=1 c2
ij < 1, then the error is estimated by
(
n
∑
i=1
(x(k)
i
−x∗
i )2)
1
2
≤
p
k
2
1 −p
1
2
(
n
∑
i=1
(x(1)
i
−x∗
i )2)
1
2
.

160
|
6 Numerical methods
(b) Seldel iterative method
The Jacobian iterative formula can be rewritten in the form
x(k)
i
=
i−1
∑
j=1
cijx(k)
j
+
n
∑
j=i+1
cijx(k−1)
j
+ di,
which is called the Seldel iterative formula, then the convergence rate of the iterative
process is quicker.
If max1≤i≤n ∑n
j=1|cij| < 1, then the error is estimated by
max
1≤i≤n |x(k)
i
−x(0)
i
| ≤
μk
1 −μ max
1≤i≤n |x(1)
i
−x(0)
i
|,
where
μ = max
1≤i≤n
{
{
{
∑n
j=1|cij|
1 −∑i−1
j=1|cij|
}
}
}
.
(c) Relaxation iterative method
The Seldel iterative formula is rewritten in the form
x(k)
i
= ω (
i−1
∑
j=1
cijx(k)
j
+
n
∑
j=i+1
cijx(k−1)
j
+ di) + (1 −ω)x(k−1)
i
,
where ω is a constant which is called a relaxation factor. This formula is called the
relaxation iterative formula. We may choose ω such that the convergence rate of the
iterative process becomes quicker.
6.3.5 Maximum eigenvalues for matrixes
Let A be an n × n matrix. Suppose that the eigenvalues λ1, . . . , λn of A satisfy |λ1| >
⋅⋅⋅> |λn| and the corresponding eigenvectors υ1, . . . , υn satisfy ‖υ1‖ = ⋅⋅⋅= ‖υn‖ = 1.
If these eigenvectors constitute a basis for the n-dimensional space, then an initial
vector x0 can be expressed into a linear combination of eigenvectors, i.e.,
x0 = a1υ1 + a2υ2 + ⋅⋅⋅+ anυn =
n
∑
1
aiυi.
Deﬁne xk = Axk−1 (k ∈ℤ+). Since Aυi = λiυi,
x1 = Ax0 =
n
∑
1
ai(Aυi) =
n
∑
1
λiaiυi;
x2 = Ax1 =
n
∑
1
λiai(Aυi) =
n
∑
1
λ2
i aiυi.

6.3 Iterative methods
|
161
In general,
xk = Axk−1 =
n
∑
1
λk
i aiυi
(k ∈ℤ+).
For a1
̸= 0, since |λi/λ1| < 1 (i ≥2), when k is sufficiently large,
xk = λk
1 (a1υ1 + a2 ( λ2
λ1
)
k
υ2 + ⋅⋅⋅+ an ( λn
λ1
)
k
υn) = λk
1(a1υ1 + εk),
where εk = o(1), i.e.,
xk ≐λk
1a1υ1,
xk+1 ≐λk+1
1
a1υ1
Let xk = (xk1, . . . , xkn) (k ∈ℤ+) and υ1 = (υ11, . . . , υ1n). Then
xki ≐λk
1a1υ1i,
xk+1,i ≐λk+1
1
a1υ1i.
This implies that
xk+1,i
xki
≐λk+1
1
a1υ1i
λk
1a1υ1i
= λ1.
6.3.6 Iterative method of ordinary differential equations
Consider the initial value problem of the ordinary differential equation of order 1
{
{
{
y󸀠= f(x, y),
y(x0) = y0.
(6.3.3)
In the numerical solution of differential equations, we want to ﬁnd the values of y(x)
on a sequence of points on the interval [a, b]
xn = a + nh
(n = 0, 1, . . . , N),
where h = b−a
N
is called the step length. Denote y(xn) ≐yn (n = 1, . . . , N).
(a) Euler method
The derivative may be represented by the difference quotient, i.e., y󸀠(x) ≐1
h(y(x + h) −
y(x)). So
y󸀠(xn) ≐y(xn + h) −y(xn)
h
= y(xn+1) −y(xn)
h
≐yn+1 −yn
h
.
By (6.3.3),
y󸀠(xn) = f(xn, y(xn)) ≐f(xn, yn),
y(x0) = y0.

162
|
6 Numerical methods
These equalities give an iterative formula as follows:
y0 = y(x0),
yn+1 ≐yn + hf(xn, yn)
(n = 0, 1, . . . , N −1).
(6.3.4)
This iterative process gives the values of yn (n = 0, 1, . . . , N).
If f(x, y) is smooth on [a, b], then the solution of (6.3.3) is smooth. By the Taylor
formula
y(xn+1) = y(xn + h) = y(xn) + hf(xn, y(xn)) + 1
2 h2y󸀠󸀠(ξ) ≐yn+1 + 1
2 h2y󸀠󸀠(ξ),
where xn < ξ < xn+1. Denote M = maxa≤x≤b |y󸀠󸀠(x)|. The local truncation error is
|y(xn+1) −yn+1| ≤M
2 h2
(n = 0, 1, . . . , N −1).
The accumulation of all the local truncation errors gives the global truncation error
O(h).
(b) Trapezoidal method
Integrating both sides of (6.3.3) from xn to xn+1,
y(xn+1) −y(xn) =
xn+1
∫
xn
f(t, y(t)) dt.
The integral on the right-hand side is computed by trapezoidal formula as follows:
xn+1
∫
xn
f(t, y(t)) dt = h
2(f(xn, yn) + f(xn+1, yn+1)).
Thus,
yn+1 = yn + h
2(f(xn, yn) + f(xn+1, yn+1)).
(6.3.5)
This is an implied format. We use (6.3.4) in the Euler method to ﬁnd initial values y(0)
n+1
y(0)
n+1 ≐yn + hf(xn, yn),
and then use (6.3.5) to give an implied iterative formula
y(k+1)
n+1
= y0 + h
2(f(xn, yn) + f(xn+1, y(k)
n+1))
(k = 0, 1, . . . ).
This implies that
|y(k+1)
n+1 −y(k)
n+1| ≤M1h
2
|y(k)
n+1 −y(k−1)
n+1 |.
A similar argument of the ﬁxed point principle implies that if 0 < M1h
2
< 1, then { y(k)
n+1 }
converges as k →∞.
For the trapezoidal method, the global truncation error is O(h2).

6.4 Difference methods
|
163
(c) System of ordinary differential equations
{
{
{
y󸀠(x) = f(x, y, z),
y(x0) = y0,
z󸀠(x) = f(x, y, z),
z(x0) = z0.
Its Euler formula is
yn+1 = yn + hf(xn, yn, zn),
y(x0) = y0,
zn+1 = zn + hg(xn, yn, zn),
z(x0) = z0.
6.4 Difference methods
The difference method is a fundamental method for solving differential equations. In
this method, the derivatives in a differential equation are replaced by difference quo-
tients.
6.4.1 The difference method of ordinary differential equations
Consider an ordinary differential equation with the ﬁrst boundary condition
{
{
{
y󸀠󸀠−p(x)y = q(x),
q(x) > 0
(a ≤x ≤b),
y(a) = α,
y(b) = β.
(6.4.1)
Take a partition xk = a + kh (k = 0, . . . , n), where h = b−a
n . Let y = y(x) be the solution
of the problem (6.4.1). We ﬁnd the approximation value yi of y(xi) (i = 0, . . . , n). For
i = 1, . . . , n −1, the second-order derivative y󸀠󸀠(xi) is expressed approximately by the
second-order central difference quotient, i.e.,
y󸀠󸀠(xi) ≐yi+1 −2yi + yi−1
h2
.
From this and (6.4.1), the difference equation is given by
yi+1 −2yi + yi−1
h2
−piyi ≐qi
(i = 1, . . . , n −1),
where pi = p(xi) and qi = q(xi). Combining this with the boundary conditions y0 = α
and yn = β, the problem (6.4.1) is reduced to the following system of linear equations
{
{
{
{
{
yi+1 −2yi + yi−1
h2
−piyi ≐qi
(i = 1, . . . , n −1),
y0 = α,
yn = β.
Solving the system of linear equations, the numerical solution yi (i = 0, . . . , n) of the
problem (6.4.1) is obtained.

164
|
6 Numerical methods
Consider an ordinary differential equation with the second boundary condition
{
{
{
y󸀠󸀠−p(x)y = q(x),
q(x) > 0
(a ≤x ≤b),
y󸀠(a) = α,
y󸀠(b) = β.
Using the three-point form of the numerical differentiation formula (see Section 6.2)
y󸀠
0 ≐−y2 + 4y1 −3y0
2h
,
y󸀠
n ≐3yn −4yn−1 + yn−2
2h
,
the corresponding system of linear equations is given by
{
{
{
{
{
yi+1 −2yi + yi−1 −piyi ≐qi
(i = 1, . . . , n −1),
−y2 + 4y1 −3y0
2h
≐α,
3yn −4yn−1 + yn−2
2h
≐β.
Solving the system of linear equations, the numerical solution is obtained.
Consider an ordinary differential equation with the third boundary condition
{
{
{
y󸀠󸀠−p(x)y = q(x),
q(x) > 0
(a ≤x ≤b),
y󸀠(a) −α0y(a) = α1,
y󸀠(b) + β0y(b) = β1,
where α0 ≥0, β0 ≥0, and α0 + β0 > 0. The corresponding system of linear equations
is given by
{
{
{
{
{
{
{
yi+1 −2yi + yi−1
h2
−piyi ≐qi
(i = 1, . . . , n −1),
−y2 + 4y1 −3y0
2h
−α0y0 ≐α1,
3yn −4yn−1 + yn−2
2h
+ β0yn ≐β1.
Solving the system of linear equations, the numerical solution is obtained.
6.4.2 The difference method of elliptic equations
Consider an elliptic equation with the ﬁrst boundary condition
{
{
{
{
{
∆u := ∂2u
∂x2 + ∂2u
∂y2 = 0
((x, y) ∈G),
u(x, y) = φ(x, y)
((x, y) ∈Γ),
(6.4.2)
where G is a bounded domain and Γ is the boundary of G.
Let xi = ih, yj = jτ (i, j ∈ℤ), where h > 0, τ > 0. The point (ih, jτ) is called a
grid, denoted by (i, j). If (i, j) ∈G and all four neighborhood points (i −1, j), (i + 1, j),
(i, j −1), and (i, j + 1) belong to G + Γ, then (i, j) is called an interior point. If (i, j) ∈G

6.4 Difference methods
|
165
and there is a neighborhood point that does not belong to G, then (i, j) is called a
boundary point.
Replacing the second-order partial derivative in (6.4.2) by the second-order central
difference quotient, we obtain the corresponding difference equation on each interior
point
ui+1,j −2ui,j + ui−1,j
h2
+ ui,j+1 −2ui,j + ui,j−1
τ2
≐0,
where ui,j = u(xi, yj). This equation is called a ﬁve-point scheme.
Consider the simplest case that h = τ and G is a rectangle
G: { 0 ≤x ≤L, 0 ≤y ≤M }.
and all boundary nodes lie on the boundary. Let l = [L/h] and m = [M/h]. The bound-
ary condition becomes
ui,j = φ(ih, jh)
((i = 0, l; j = 0, . . . , m) or (i = 0, . . . , l; j = 0, m)).
So the problem (6.4.2) is reduced to the following system of m + 1 equations with l + 1
unknown
{
{
{
ui,j = 1
4(ui+1,j + ui−1,j + ui,j+1 + ui,j−1)
(i = 1, . . . , l −1; j = 1, . . . , m −1),
ui,j = φ(ih, jh)
((i = 0, l, j = 0, . . . , m) or (i = 0, . . . , l; j = 0, m)).
It can be proved that this system of difference equations has a unique solution by
the extremum principle. One may use the direct method and the iteration method to
solve this system of linear equations.
6.4.3 The difference method of parabolic equations
Consider a parabolic equation with an initial condition and boundary conditions
{
{
{
{
{
{
{
{
{
Lu := ∂u
∂t −∂2u
∂x2 = 0
(0 < x < 1, 0 < t ≤T),
u(0, x) = φ(x)
(0 ≤x ≤1),
u(t, 0) = μ1(t),
u(t, 1) = μ2(t)
(0 ≤t ≤T),
(6.4.3)
where φ(0) = μ1(0) and φ(1) = μ2(0).
Establish the following grids (xk, tj), where
xk = kh
(k = 1, . . . , N),
Nh = 1,
tj = jτ
(j = 0, . . . , m0),
m0 = [T/τ].
Using the numerical differential formula, we obtain
∂u
∂t (xk, tj) ≐u(xk, tj+1) −u(xk, tj)
τ
,
∂2u
∂x2 (xk, tj) ≐u(xk+1, tj) −2u(xk, tj) + u(xk−1, tj)
h2
.

166
|
6 Numerical methods
By (6.4.3), it follows that
uk,j+1 −uk,j
τ
−uk+1,j −2uk,j + uk−1,j
h2
≐0.
Denote r = τ/h2, this equality becomes
uk,j+1 ≐(1 −2r)uk,j + r(uk+1,j + uk−1,j)
(k = 1, . . . , N −1; j = 0, . . . , m0 −1).
The corresponding initial condition and boundary condition are
uk,0 ≐φ(kh)
(k = 0, . . . , N),
u0,j ≐μ1(jτ),
μN,j ≐μ2(jτ)
(j = 0, . . . , m0).
From this, the problem (6.4.3) is reduced to the following system of linear equations:
{
{
{
{
{
{
{
{
{
uk,j+1 ≐(1 −2r)uk,j + r(uk+1,j + uk−1,j)
(k = 1, . . . , N −1; j = 0, . . . , m0 −1),
uk,0 ≐φ(kh)
(k = 0, . . . , N),
u0,j ≐μ1(jτ),
μN,j ≐μ2(jτ)
(j = 0, . . . , m0).
6.4.4 The difference method of hyperbolic equations
Consider a hyperbolic equation problem with boundary conditions
{
{
{
{
{
{
{
{
{
∂2u
∂x2 −∂2u
∂t2 = f(x, t)
(0 < x < 1, 0 < t ≤T),
u(0, x) = φ(x),
∂u
∂t (0, x) = ψ(x)
(0 ≤x ≤1),
u(t, 0) = Φ0(t),
u(t, 1) = Φ1(t)
(0 ≤t ≤T).
(6.4.4)
Take grids (xk, tj), where
xk = kh
(k = 0, . . . , N),
tj = jτ
(j = 0, . . . , m0),
where h = 1
N and m0 = [T/τ]. Using the numerical differential formula, we get
∂2u
∂x2 (xk, tj) ≐u(xk+1, tj) −2u(xk, tj) + u(xk−1, tj)
h2
.
∂2u
∂t2 (xk, tj) ≐u(xk, tj+1) −2u(xk, tj) + u(xk, tj−1)
τ2
.
By (6.4.4), it follows that
uk+1,j −2uk,j + uk−1,j
h2
−uk,j+1 −2uk,j + uk,j−1
τ2
≐fk,j

6.5 Finite element methods
|
167
where u(xk, yj) = uk,j and f(xk, yj) = fk,j. Denote s = τ/h. This equation becomes
uk,j+1 ≐s2(uk+1,j + uk−1,j) + 2(1 −s2)uk,j −uk,j−1 −s2h2fk,j
(k = 1, . . . , N −1; j = 1, . . . , m0 −1).
So the problem (6.4.4) is reduced to the following system of linear equations
{
{
{
{
{
{
{
{
{
{
{
{
{
uk,j+1 ≐s2(uk+1,j + uk−1,j) + 2(1 −s2)ui,j
−uk,j−1 −s2h2fk,j
(k = 1, . . . , N −1; j = 1, . . . , m0 −1),
uk,0 ≐φk,
uk,1 ≐φk + τψk
(k = 0, . . . , N),
u0,j ≐Φ0(jτ) = Φ0j,
uN,j ≐Φ1(jτ) = Φ1j
(j = 0, . . . , m0).
This is an explicit difference scheme. Solving the system of linear equations, the nu-
merical solution is obtained.
6.5 Finite element methods
The ﬁnite element method is another numerical method for solving differential equa-
tions. Its basic idea is to transfer a differential equation into an integral equation,
partition the integral domain into ﬁnite subdomains (e.g. triangulation), then con-
struct an interpolation polynomial of the generalized solution with nodes (e.g. vertices
of triangle), and ﬁnally yield a system of linear equations in each subdomain.
6.5.1 The one-dimensional ﬁnite element method
Consider the boundary value problem of a second-order ordinary differential equation
{
{
{
−(p(x)u󸀠(x))󸀠+ q(x)u(x) = f(x)
(0 ≤x ≤b),
u(0) = 0,
p(b)u󸀠(b) + αu(b) = g,
(6.5.1)
where p(x), q(x) are both continuous functions on [0, b] and p(x) ≥p0 > 0, q(x) >
0(0 ≤x ≤b), α > 0, and g is a constant. Its solution in the space C1([0, b])⋂C2((0, b))
is called the classical solution.
(a) Generalized solution
We want to ﬁnd the generalized solution of the problem (6.5.1) in the space C1([0, b]).
Let φ(x) be a continuously differentiable function on [0, b] and satisfy the bound-
ary condition φ(0) = 0. Multiplying both sides of the second-order ordinary equation
in (6.5.1) by φ(x), and then integrating both sides from 0 to b, we get
b
∫
0
(−(p(x)u󸀠(x))󸀠+ q(x)u(x))φ(x) dx =
b
∫
0
f(x)φ(x) dx.
(6.5.2)

168
|
6 Numerical methods
Note that φ(0) = 0 and the boundary condition p(b)u󸀠(b) + αu(b) = g. Using the in-
tegration by parts gives
b
∫
0
(p(x)u󸀠(x))󸀠φ(x) dx = p(b)u󸀠(b)φ(b) −
b
∫
0
p(x)u󸀠(x)φ󸀠(x) dx
= (g −αu(b))φ(b) −
b
∫
0
p(x)u󸀠(x)φ󸀠(x) dx.
From this and (6.5.2), it follows that
b
∫
0
(p(x)φ󸀠(x)u󸀠(x) + q(x)φ(x)u(x)) dx + αu(b)φ(b) =
b
∫
0
f(x)φ(x) dx + gφ(b).
(6.5.3)
If u ∈C1([0, b]) satisfying u(0) = 0 and ∫
b
0 ((u󸀠(x))2 + (u(x))2)dx < ∞, and (6.5.3) holds
for any φ ∈C1([0, b]) satisfying φ(0) = 0, the function u(x) is called a generalized
solution of the problem (6.5.1).
(b) Discretization
Take a partition of the interval [0, b]: 0 ≤x0 < x1 < ⋅⋅⋅< xn = b. For i = 0, . . . , n −1, de-
note by ηi each subinterval [xi, xi+1] and denote by ui the value of u(x) at the node xi.
From [0, b] = ⋃n−1
i=0 [xi, xi+1] = ⋃n−1
i=0 ηi, it follows by (6.5.3) that
n−1
∑
0
Ui + αu(b)φ(b) =
n−1
∑
0
Vi + gφ(b),
(6.5.4)
where
Ui = ∫
ηi
(p(x)φ󸀠(x)u󸀠(x) + q(x)φ(x)u(x)) dx,
Vi = ∫
ηi
f(x)φ(x) dx.
(c) Interpolation function
Introduce the linear interpolations of u(x) and φ(x) on ηi (i = 0, . . . , n −1) as follows:
u(x) ≐Ai(x)ui + Bi(x)ui+1,
φ(x) ≐Ai(x)φi + Bi(x)φi+1
(x ∈ηi),
where Ai(x) = xi+1−x
Mi
and Bi(x) = x−xi
Mi and Mi = xi+1 −xi, and
u󸀠(x) ≐A󸀠
i(x)ui + B󸀠
i(x)ui+1,
φ󸀠(x) ≐A󸀠
i(x)φi + B󸀠
i(x)φi+1
(x ∈ηi),
where A󸀠
i(x) = −1
Mi , B󸀠
i(x) =
1
Mi .

6.5 Finite element methods
|
169
(d) Unit stiffness matrix and unit carrier vector
Introduce two 2-dimensional vectors Ji, J∗
i and two 1 × 2 matrices Ki(x), Hi(x) as
follows:
Ji = (ui, ui+1)T,
J∗
i = (φi, φi+1)T,
Ki(x) = (Ai(x), Bi(x)),
Hi(x) = (A󸀠
i(x), B󸀠
i(x))
(i = 0, . . . , n).
(6.5.5)
So
u(x) = KiJi,
φ(x) = KiJ∗
i ,
u󸀠(x) = HiJi,
φ󸀠(x) = HiJ∗
i .
Note that
HiJ∗
i = (HiJ∗
i )T = (J∗
i )THT
i ,
KiJ∗
i = (KiJ∗
i )T = (J∗
i )TKT
i .
So
φ󸀠(x)u󸀠(x) = (J∗
i )THT
i HiJi,
φ(x)u(x) = (J∗
i )TKT
i KiJi
and
Ui = ∫
ηi
(p(x)φ󸀠(x)u󸀠(x) + q(x)φ(x)u(x)) dx
≐∫
ηi
p(x)(J∗
i )THT
i HiJi dx + ∫
ηi
q(x)(J∗
i )TKT
i KiJi dx.
Since Ji and J∗
i are independent of x,
Ui ≐(J∗
i )T (∫
ηi
p(x)HT
i Hi dx + ∫
ηi
q(x)KT
i Ki dx) Ji.
Let Gηi = ∫ηi(p(x)HT
i Hi + q(x)KT
i Ki) dx (i = 0, . . . , n −1). Then
Ui ≐(J∗
i )TGηiJi
(i = 0, . . . , n −1).
(6.5.6)
Note that
HT
i Hi = (
1
M2
i
−1
M2
i
−1
M2
i
1
M2
i
) ,
KT
i (x)Ki(x) = (
A2
i (x)
Ai(x)Bi(x)
Ai(x)Bi(x)
B2
i (x)
) .
For i = 0, . . . , n −1,
Gηi = ∫
ηi
(p(x)HT
i Hi + q(x)KT
i (x)Ki(x)) dx
≐(
1
M2
i
−1
M2
i
−1
M2
i
1
M2
i
) pi + ∫
ηi
q(x) (
A2
i (x)
Ai(x)Bi(x)
Ai(x)Bi(x)
B2
i (x)
) dx
= (
Gηi
i,i
Gηi
i,i+1
Gηi
i+1,i
Gηi
i+1,i+1
)

170
|
6 Numerical methods
where pi ≐∫ηi p(x) dx and
Gηi
i,i = pi
M2
i
+ ∫
ηi
q(x)A2
i (x) dx,
Gηi
i,i+1 = Gηi
i+1,i = −pi
M2
i
+ ∫
ηi
q(x)Ai(x)Bi(x) dx,
Gηi
i+1,i+1 = pi
M2
i
+ ∫
ηi
q(x)B2
i (x) dx
(i = 0, . . . , n −1).
The matrix
(
Gηi
i,i
Gηi
i,i+1
Gηi
i+1,i
Gηi
i+1,i+1
)
is called the unit stiffness matrix. It is a positive deﬁnite and symmetric matrix.
Substituting (6.5.6) into (6.5.4),
n−1
∑
0
(J∗
i )TGηiJi + αu(b)φ(b) =
n−1
∑
0
Vi + gφ(b).
(6.5.7)
By (6.5.5),
(J∗
n−1)T (0
0
0
α) Jn−1 = (φn−1, φn) (0
0
0
α) (un−1
un
) = αφnun = αu(b)φ(b),
(J∗
n−1)T (0
g) = (φn−1, φn) (0
g) = gφn = gφ(b).
From this and (6.5.7), it follows that
n−1
∑
0
(J∗
i )TGηiJi + (J∗
n−1)T (0
0
0
α) Jn−1 =
n−1
∑
0
Vi + (J∗
n−1)T (0
g) .
(6.5.8)
Since J∗
i is independent of x, by (6.5.5), we get
Vi = ∫
ηi
f(x)φ(x) dx ≐∫
ηi
(J∗
i )TKT
i (x)f(x) dx = (J∗
i )T ∫
ηi
(Ai(x)
Bi(x)) f(x) dx = (J∗
i )TFei,
where
Fei = (∫
ηi
Ai(x)f(x) dx, ∫
ηi
Bi(x)f(x) dx)
T
.
The Fei is called a unit carrier vector. By (6.5.8), it follows that
n−1
∑
0
(J∗
i )TGηiJi + (J∗
n−1)T (0
0
0
α) Jn−1 =
n−1
∑
0
(J∗
i )TFei + (J∗
n−1)T (0
g) .
(6.5.9)
Let
̃Gηi = Gηi,
̃Fei = Fei
(i = 0, 1, . . . , n −2),
̃Gηn−1 = Gηn−1 + (0
0
0
α) ,
̃Fen−1 = Fen−1 + (0
g) .

6.5 Finite element methods
|
171
Then (6.5.9) becomes
n−1
∑
0
(J∗
i )T ̃GηiJi =
n−1
∑
0
(J∗
i )T ̃Fei.
(6.5.10)
(e) Global stiffness matrix and global carrier vector
Let J = (u0, u1, . . . , un)T and J∗= (φ0, φ1, . . . , φn)T, and let
̃Fei = (α0, α1, . . . , αn)T,
where
αi = ∫
ηi
Ai(x)f(x) dx,
αi+1 = ∫
ηi
Bi(x)f(x) dx,
αν = 0
(ν
̸= i, i + 1),
and let
̂Gηi = (βμ,ν)μ,ν=0,...,n (i = 0, . . . , n −1), where
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
βi,i =
̃Gηi
i,i,
βi,i+1 = βi+1,i =
̃Gηi
i,i+1,
βi+1,i+1 =
̃Gηi
i+1,i+1,
βn,n =
̃Gηn−1
n,n + α,
βμ,ν=0
(otherwise).
By (6.5.10),
(J∗)T (
n−1
∑
0
̂Gηi) Ji = (J∗)T (
n−1
∑
0
Fei) .
Let G = ∑n−1
i=0
̂Gηi and F = ∑n−1
i=0
̃Fei . Then
(J∗)T(GJi −F) = 0,
(6.5.11)
where G is called a global stiffness matrix and F is called a global carrier vector. The
matrix G is a positive deﬁnite and symmetric matrix.
(f) Constraint condition
Deﬁne
̃F = (0, Fe1, . . . , Fen−1), ̃J = (0, u1, . . . , un)T, and ̃J∗= (0, φ1, . . . , φn)T, and
̃G = (
1
0
⋅⋅⋅
0
0
β11
⋅⋅⋅
β1n
...
...
...
...
0
βn1
⋅⋅⋅
βnn
) .
From (6.5.11) and φ(0) = 0, and u(0) = 0, it follows that
̃J∗( ̃G ̃J −
̃F) = 0.

172
|
6 Numerical methods
This equality holds for any function φ satisfying φ ∈C1([0, b]) and φ(0) = 0. So,
deleting ̃J∗, we get
̃G ̃J =
̃F.
(6.5.12)
Note that
̃G is a positive deﬁnite and symmetric matrix, the solution (0, u1, . . . , un)
of the equation (6.5.12) has a unique solution. The u1, . . . , un are approximate values
of the solution of the problem (6.5.1) at nodes x1, . . . , xn.
6.5.2 The two-dimensional ﬁnite element method
Consider the two-dimensional boundary value problem of the Poisson equation
{
{
{
−∆u = f(x, y)
((x, y) ∈Ω),
u|∂Ω= u0(x, y),
(6.5.13)
where ∆=
∂2
∂x2 + ∂2
∂y2 is the Laplace operator and Ωis a bounded domain in the plane.
(a) Generalized solution
Take φ(x, y) ∈C2(Ω) ⋂C1( ̄Ω) and φ(x, y) = 0 on ∂Ω. Multiplying both sides of the
Poisson equation in (6.5.13) by φ(x, y), and then integrating both sides over Ω, we get
−∬
Ω
(∆u)φ dx dy = ∬
Ω
fφ dx dy.
By the Green formula and φ(x, y) = 0 on ∂Ω, the left-hand side is
−∬
Ω
(∆u)φ dx dy = ∬
Ω
( ∂u
∂x
∂φ
∂x + ∂u
∂y
∂φ
∂y ) dx dy −∮
∂Ω
φ ∂u
∂n dS
= ∬
Ω
( ∂u
∂x
∂φ
∂x + ∂u
∂y
∂φ
∂y ) dx dy.
So
∬
Ω
( ∂u
∂x
∂φ
∂x + ∂u
∂y
∂φ
∂y ) dx dy = ∬
Ω
fφ dx dy.
(6.5.14)
If u(x, y) is such that ∬Ω(u2 + ∆u) dx dy < ∞and (6.5.14) holds for any φ ∈C1( ̄Ω)
satisfying φ(x, y) = 0 on ∂Ω, then u(x, y) is called a generalized solution of the problem
(6.5.13).
(b) Discretization
Partition the integral domain Ωinto a combination of triangle units ek (k = 1, . . . , Ne).
The vertices pi(xi, yi) (i = 1, . . . , Ne) of triangles are called nodes. Each node cannot
be an interior point of sides of other triangles.

6.5 Finite element methods
|
173
Let u(xi, yi) = ui (i = 1, . . . , Ne). Take a triangle unit e whose three vertices are
Pi, Pj, Pm (anticlockwise order). Choose three constants a, b, c such that the function
̃u(x, y) = ax + by + c
(6.5.15)
attains values ui, uj, and um, respectively, i.e., a, b, and c satisfy the following equa-
tions:
{
{
{
{
{
{
{
{
{
axi + byi + c = ui,
axj + byj + c = uj,
axm + bym + c = um.
Its solution is
a =
1
2∆e
((yj −ym)ui + (ym −yi)uj + (yi −yj)um),
b = −1
2∆e
((xi −xm)ui + (xm −xi)uj + (xi −xj)um),
c =
1
2∆e
((xjym −xmyj)ui + (xmyi −xiym)uj + (xiyj −xjyi)um),
where
∆e = 1
2
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
xi
yi
1
xj
yj
1
xm
ym
1
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
.
Since the order of Pi, Pj, Pm is anticlockwise, ∆e is the area of the triangle unit e =
∆PiPjPm. From this and (6.5.15), the interpolation function is
̃u(x, y) = Ni(x, y)ui + Nj(x, y)uj + Nm(x, y)um,
where
Ni(x, y) =
1
2∆e
((yj −ym)x −(xj −xm)y + (xjym −xmyj)) ,
Nj(x, y) =
1
2∆e
((ym −yi)x −(xm −xi)y + (xmyi −xiym)) ,
Nm(x, y) =
1
2∆e
((yi −yj)x −(xi −xj)y + (xiyj −xjyi)) .
Here Ni(x, y), Nj(x, y), and Nm(x, y) are all polynomials of degree 1 and satisfy
Ns(xt, yt) = δs,t (s, t = i, j, m), where δs,t is the Kronecker delta. These three functions
are called primary functions of linear interpolation on the triangle unit e.
Denote
Je = (ui, uj, um)T,
N = (Ni, Nj, Nm)T.
So
̃u = NTJe.

174
|
6 Numerical methods
The gradient vector of
̃u is
∇̃u = (
∂̃u
∂x
∂̃u
∂y
) = (
∂Ni
∂x
∂Nj
∂x
∂Nm
∂x
∂Ni
∂y
∂Nj
∂y
∂Nm
∂y
) (
ui
uj
um
) .
Note that
∂Ni
∂x =
1
2∆e
(yj −ym),
∂Ni
∂y = −1
2∆e
(xj −xm),
∂Nj
∂x =
1
2∆e
(ym −yi),
∂Nj
∂y = −1
2∆e
(xm −xi),
∂Nm
∂x
=
1
2∆e
(yi −yj),
∂Nm
∂y
= −1
2∆e
(xi −xj).
Then ∇̃u = BJe, where
B =
1
2∆e
(yj −ym
ym −yi
yi −yj
xm −xj
xi −xm
xj −xi
) .
(6.5.16)
(c) Unit stiffness matrix and unit carrier vector
Let
̃φ(x, y) be the interpolation function of φ on the triangle unit e. Then
̃φ(x, y) = Ni(x, y)φi + Nj(x, y)φj + Nm(x, y)φm = NTJ∗
e ,
where
J∗
e = (φi, φj, φm)T,
N = (Ni, Nj, Nm)TN = (Ni, Nj, Nm)T,
φi = φ(xi, yi),
φj = φ(xj, yj),
φm = φ(xm, ym).
Similar to the argument of ∇̃u, we get
∇̃φ = BJ∗
e ,
where B is stated in (6.5.16).
Replacing u and φ by the interpolation functions ̃u and
̃φ in (6.5.14), respectively,
noticing that ∑Ne
n=1 en = Ω, we get
Ne
∑
n=1
∬
en
( ∂̃u
∂x
∂̃φ
∂x + ∂̃u
∂y
∂̃φ
∂y ) dx dy =
Ne
∑
n=1
∬
en
fφ dx dy.
(6.5.17)
By ∇̃u = BJe and ∇̃φ = BJ∗
e , each term on the left-hand side of (6.5.17) is
∬
e
( ∂̃u
∂x
∂̃φ
∂x + ∂̃u
∂y
∂̃φ
∂y ) dx dy = ∬
e
(∇̃φ)T(∇̃u) dx dy
= ∬
e
(J∗
e )TBTBJe dx dy = (J∗
e )TKeJe,
(6.5.18)

6.5 Finite element methods
|
175
where Ke = ∬e BTB dx dy is called a unit stiffness matrix.
Since B is a constant matrix and the area of e is ∆e,
Ke = ∆eBTB = (
Ke
ii
Ke
ij
Ke
im
Ke
ji
Ke
jj
Ke
jm
Ke
mi
Ke
mj
Ke
mm
) ,
where
Ke
st = ∆e ( ∂Ns
∂x
∂Nt
∂x + ∂Ns
∂y
∂Nt
∂y ) =
1
4∆e
(asat + bsbt)
(s, t = i, j, m)
and
ai = yj −ym,
aj = ym −yi,
am = yi −yj,
bi = xm −xj,
bj = xi −xm,
bm = xj −xi.
Note that fφ = φTf = (J∗
e )TNf . Since J∗
e is independent of x and y, each term on
the right-hand side of (6.5.17) is
∬
e
fφ dx dy = ∬
e
(J∗
e )TNf dx dy = (J∗
e )TFe,
where
Fe = ∬
e
Nf dx dy = (Fe
i , Fe
j , Fe
m)T.
The vector Fe is called a unit carrier vector and Fe
s = ∬e Nsf dx dy (s = i, j, m).
(d) Global stiffness matrix and global carrier vector
Substituting representations of unit stiffness matrix and unit carrier vector into
(6.5.17). For the convenience superposition, each Ke is extended to an Ne × Ne
matrix
̃Ke, each Fe is extended to Ne-dimensional vectors
̃Fe, and J∗
e and Je are
extended to J∗and J, respectively. So
(J∗)T (
Ne
∑
1
̃Ken) J = (J∗)T (
Ne
∑
1
̃Fen) .
This equality holds for arbitrary J∗. Deleting (J∗)T, we get
(
Ne
∑
1
̃Ken) J = (
Ne
∑
1
̃Fen) .
Let K = ∑Ne
n=1 Ken and F = ∑Ne
n=1 Fen . Then KJ = F. This is a system of linear equations
and the matrices K and F are called a global stiffness matrix and a global carrier vector,
respectively. Rewriting this system of linear equations using constraint conditions, the
desired solution can be obtained.

176
|
6 Numerical methods
6.6 Wavelet methods
Starting from the classical Galerkin method and Daubechies wavelets, we introduce
the wavelet-Galerkin method for solving differential and integral equations.
6.6.1 Classical Galerkin method
Consider a problem of linear differential equations
Lu = f,
(6.6.1)
where L is a linear differential operator, f is a known function, and u is a undeter-
mined function. Choosing a set of test functions u1, . . . , un, we try to approximate to
u by a linear combination u = ∑n
k=1 ckuk of these test functions. Since L is a linear
operator,
Lu =
n
∑
1
ckLuk.
Choose coefficients ck (k = 1, . . . , n) such that some norm
‖Lu −f ‖ =
󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩
n
∑
1
ckLuk −f
󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩
attains the minimal value. The function u is an approximation solution of (6.6.1). The
norm may be the norm of C([a, b]) or the norm of L2([a, b]), i.e.,
‖f ‖ = max
a≤x≤b |f(x)|
or
‖f ‖ = (
b
∫
a
|f(x)|2 dx)
1/2
.
The interpolation form of the Galerkin method is
n
∑
k=1
ck(Luk)(xi) = f(xi)
(i = 1, . . . , n),
i.e., choose c1, . . . , cn such that Lu is an interpolation function. The function
u(x) =
n
∑
1
ckuk(x)
is an approximation solution of (6.6.1) in the interpolation sense.
The weak form of the Galerkin method is often used. Choose ck (k = 1, . . . , n)
such that
(ul, Lu)L2 = (ul, f)L2
(l = 1, . . . , n),
(6.6.2)

6.6 Wavelet methods
|
177
i.e.,
n
∑
1
ck(ul, Luk)L2 = (ul, f)L2
(l = 1, . . . , n).
Denote (fl, . . . , fn)T and glk = (ul, Luk)L2 . From the system of linear equations
n
∑
k=1
glkck = fl,
we solve out ck (k = 1, . . . , n). The function u = ∑n
k=1 ckuk satisﬁes (6.6.2).
For example, consider the Dirichlet problem
{
{
{
∆u = 0
in Ω,
u(x, y) = g
on ∂Ω.
or write as
Lu = f ,
where Lu = (∆u, u|∂Ω)T and f = (0, g)T.
Let uk be the real part of zk. Then uk (k = 1, . . . , n) are harmonic functions and their
linear combination u = ∑n
k=1 ckuk is also a harmonic function. So ∆u = 0. Take m
points (xl, yl) (l = 1, . . . , m) distributed on ∂Ωuniformly, where m > n, and then use
the Remez algorithm (see Section 3.3) to ﬁnd ck (k = 1, . . . , n) such that
max
1≤l≤m
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
n
∑
k=1
ckuk(xl, yl) −g(xl, yl)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
attains the minimal value. So this linear combination u is an approximation solution
of the Dirichlet problem.
In Galerkin method, one often takes a subset of a normal orthogonal basis as test
functions such that their linear combination approximates to the solution. Moreover,
when the cardinal numbers of subsets increase to ∞, the approximate solutions tend
to the exact solution.
Wavelet bases have many nice properties such as compact support, smoothness,
and vanishing moment. Therefore, the wavelet-Galerkin method has been develop-
ing recently. To give the wavelet-Galerkin method, we ﬁrst state the construction of
compactly supported wavelets.
6.6.2 Compactly supported wavelets
If ψ is an orthogonal wavelet with p vanishing moments, then it has a support of size
larger than or equal to 2p −1. Daubechies wavelet has a minimum size support in
these wavelets.
Given a trigonometric polynomial H(ω) satisfying
|H(ω)|2 = 2
󵄨󵄨󵄨󵄨󵄨󵄨󵄨cos ω
2
󵄨󵄨󵄨󵄨󵄨󵄨󵄨
2p
P (sin2 ω
2 ) ,

178
|
6 Numerical methods
where
P(y) =
p−1
∑
k=0
Ck
p−1+kyk,
Ck
p−1+k = (p −1 + k)!
k! (p −1)! ,
one uses the Riesz lemma to construct a minimum degree polynomial R(z) by factor-
ization method such that
|R(e−iω)|2 = P (sin2 ω
2 ) ,
and let
H(ω) = √2 e−i(p−1)ω (1 + e−iω
2
)
p
R(e−iω) =
2p−1
∑
0
cke−ikω.
The bi-scale equation based on the coefficient ck
1
2 φ(t) =
2p−1
∑
0
ckφ(2t −k)
(6.6.3)
can be solved by the ordinary iteration method as follows.
Deﬁne an operator T as
T(φ(t)) = 2
2p−1
∑
0
ckφ(2t −k).
Take a compactly supported function φ0(t) such as
φ0(t) = N2(t) =
{
{
{
{
{
{
{
{
{
t
(0 ≤t < 1),
2 −t
(1 ≤t < 2),
0
otherwise,
where N2(t) is a two-order B spline (see Section 4.4). Let
φn(t) = T(φn−1(t))
(n ∈ℤ+).
Then φk(t) converges as k →∞, the limit is φ∗(t), and φ∗(t) is a continuous solution
of (6.6.3) with compact support [0, 2p −1]. Under the additional condition
2p−1
∑
k=0
φ∗(k) = 1,
the values of the scaling function φ∗(t) at dyadic decimal k/2m are given. The corre-
sponding wavelet function ψ∗is given by
ψ∗(t) = −2
1
∑
2−2p
(−1)kc1−kφ(2t −k)
(see Section 3.5). The function ψ∗is called a Daubechies wavelet. It has p vanish-
ing moments and support [−p + 1, p]. The larger p is, the smoother the Daubechies
wavelet is.

6.6 Wavelet methods
|
179
6.6.3 Wavelet-Galerkin method
Consider the problem of one-dimensional differential equation with Dirichlet bound-
ary condition
{
{
{
Lu(x) = f(x)
(0 ≤x ≤1),
u(0) = u(1) = 0,
(6.6.4)
where f is a real-valued and continuous function on [0, 1] and L is a uniformly elliptic
differential operator.
Let ψmn(x) = 2
m
2 ψ(2mx −n) be a wavelet basis for L2([0, 1]) with boundary con-
dition
ψmn(0) = ψmn(1) = 0.
Let Λ be a set of indices (m, n). For each (m, n) ∈Λ, ψmn is a two-order continuously
differentiable function and
ψmn(x) = 0
if
󵄨󵄨󵄨󵄨󵄨󵄨󵄨x −n
2m
󵄨󵄨󵄨󵄨󵄨󵄨󵄨> 1
2m .
(6.6.5)
Let the approximation solution of (6.6.4) be
up =
∑
(m,n)∈Λ
cmnψmn,
where cmn ((m, n) ∈Λ) are undetermined coefficients. Select cmn ((m, n) ∈Λ) such
that
(Lup, ψjk) = (f, ψjk)
((j, k) ∈Λ).
This implies that
∑
(m,n)∈Λ
(Lψmn, ψjk) cmn = (f, ψjk)
((j, k) ∈Λ).
(6.6.6)
Denote
αmnjk = (Lψmn, ψjk),
yjk = (f, ψjk),
A = (αmnjk)(j,k),(m,n)∈Λ,
C = (cmn)(m,n)∈Λ,
Y = (Yjk)(j,k)∈Λ,
where (m, n) and (j, k) represent the rows and columns of A, respectively. So (6.6.6)
is reduced to the following system of linear equations with unknown cmn
∑
(m,n)∈Λ
αmnjkcmn = yjk
((j, k) ∈Λ)
which is equivalent to AC = Y. From (6.6.5), it is seen that A is a sparse matrix. If the
condition number of A is high, choose a matrix B such that the system AC = Y is
replaced by the equivalent system BAC = BY, where BA has low condition number.
Denote
BA = M,
BY = V.
The system of the linear equation MC = V is stable. From this, the undetermined co-
efficients cmn are solved. So we get the approximation solution up.

180
|
6 Numerical methods
6.6.4 Numerical solution of integral equations
Numerical calculation of integral operators plays a key role in solving integral equa-
tions. Consider a linear integral operator
Tf(x) = ∫
ℝ
K(x, y)f(y) dy
and K(x, y) = 0 for (x, y) ∈ℝ2 \ [0, 1]2. Take N points (xi, yi) (i = 1, . . . , N), where
0 = x1 < x2 < ⋅⋅⋅< xN = 1,
0 = y1 < y2 < ⋅⋅⋅< yN = 1.
Then
Tf(xi) =
N
∑
1
K(xi, yi)f(yi)∆yi
(∆yi = yi −yi−1).
From this, the calculation of Tf(x) is reduced to a product of an N × N matrix and an
N-dimensional vector. So the number of multiply operations is O(N2). This number is
very large.
When T is a convolution operator, i.e.,
(Tf)(x) = ∫
ℝ
K(x −y)f(y) dy,
taking Fourier transform,
( ̂Tf)(ω) =
̂K(ω) ̂f(ω).
Its discrete form is
( ̂Tf)(ωi) =
̂K(ωi) ̂f(ωi)
(i = 1, . . . , N).
The corresponding number of operations decreases from O(N2) to O(N log N).
When the linear operator is not in a convolution form, the Fourier transform ap-
proach does not work. Since Daubechies wavelet expansion enables the discretization
matrix corresponding to the integral operator T to be reduced to a sparse matrix, the
number of operations is only O(N log N) for wavelet-based numerical computation of
integral operators.
Take a slightly modiﬁed Daubechies wavelet with M −1 vanishing moments, its
scaling function φ and wavelet ψ satisfy
φ(x) = 2
2M−1
∑
0
hk+1φ(2x −k),
ψ(x) = 2
2M−1
∑
0
gk+1φ(2x −k),
where gk = (−1)k−1h2M−k+1 (k = 1, . . . , 2M).

6.6 Wavelet methods
|
181
(a) Wavelet expansion of K(x, y)
The bivariate Daubechies wavelets are φ(x)ψ(y), ψ(x)φ(y), ψ(x)ψ(y), where φ(x) and
ψ(x) are the Daubechies scaling function and the corresponding wavelet. The bivari-
ate Daubechies wavelet basis is
{ φjm(x)ψjn(y),
ψjm(x)φjn(y),
ψjm(x)ψjn(y) }j,m,n∈ℤ.
Expand the kernel function K(x, y) into a series with respect to this basis
K(x, y) = ∑
j,k,l
αjklφjk(x)ψjl(y) + ∑
j,k,l
βjklψjk(x)φjl(y) + ∑
j,k,l
γjklψjk(x)ψjl(y),
(6.6.7)
where the wavelet coefficients are
αjkl = ∬
ℝ2
K(x, y)φjk(x)ψjl(y) dx dy,
βjkl = ∬
ℝ2
K(x, y)ψjk(x)φjl(y) dx dy,
γjkl = ∬
ℝ2
K(x, y)ψjk(x)ψjl(y) dx dy.
(b) Wavelet expansion of Tf(x)
By Tf(x) = ∫ℝK(x, y)f(y) dy and (6.6.7), it follows that
Tf(x) = ∑
j,k,l
αjkldjlφjk(x) + ∑
j,k,l
βjklcjlψjk(x) + ∑
j,k,l
γjkldjlψjk(x),
(6.6.8)
where
djl = ∫
ℝ
f(y)ψjl(y) dy,
cjl = ∫
ℝ
f(y)φjl(y) dy.
Deﬁne three matrices αj, βj, γj and two vectors
̃dj,
̃cj as
αj = (αjkl)k,l,
βj = (βjkl)k,l,
γj = (γjkl)k,l,
̃dj = γjdj + βjcj,
̃cj = αjdj,
(6.6.9)
where dj = (djl)l and cj = (cjl)l are vectors. From this and (6.6.8),
Tf(x) = ∑
j
∑
k
( ̃dj
kψjk(x) + ̃cj
kφjk(x)) .

182
|
6 Numerical methods
(c) Numerical calculation of Tf(x)
Let N = 2n. Take c0
k (k = 1, . . . , N) as N samples which are regarded as the average of
f on dyadic intervals with length 2−n and { c0
k } is a 2n-periodic sequence. So we get a
(2N −2)-dimensional vector
̃f = (d11, . . . , d1 N
2 , c11, . . . , c1 N
2 , d21, . . . , d2, N
4 , c21, . . . , c2 N
4 , . . . , dn1cn1)T.
Take
TNf(x) =
n
∑
j=1
2n−j
∑
k=1
( ̃dj
kψjk(x) + ̃cj
kφjk(x)) .
(6.6.10)
Then Tf(x) ≐TNf(x). We only need compute TNf(x).
Formula (6.6.9) can be represented by a product of the matrix A and the vector ̃f ,
where
A = (
A1
...
An
) ,
Aj = (γj
βj
αj
0) ,
(6.6.11)
and
αj = (αjkl)k,l=1,...,2n−j, j=1,...,n,
βj = (βjkl)k,l=1,...,2n−j, j=1,...,n,
γj = (γjkl)k,l=1,...,2n−j, j=1,...,n.
(d) Calderon–Zygmund operators
Calderon–Zygmund operators are most important integral operators which are widely
applied in integral equations. Let T be a Calderon–Zygmund operator whose kernel
function satisﬁes the following three conditions:
|K(x, y)| ≤C(|x −y|−1),
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
∂M
∂x K(x, y)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
+
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
∂M
∂y K(x, y)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
≤C(|x −y|−1−M),
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
∫
I×I
K(x, y) dx dy
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
≤C|I|
for any dyadic interval I,
where C is a constant and M ≥1. Then the wavelet coefficients of K(x, y) satisfy
|αjkl| + |βjkl| + |γjkl| = O ((1 + |k −l|)−1−M) .
(e) Modiﬁed integral operators
Given ε > 0, take
B ≥( C
ε log2 N)
1
M
.

Further reading
|
183
Let A = (Aμν) be stated in (6.6.11). Deﬁne A(B) = (A(B)
μν ), where
A(B)
μν =
{
{
{
Aμν,
|μ −ν| ≤B,
0,
|μ −ν| > B.
Let αjB, βjB, γjB be obtained from αj, βj, γj, respectively, by replacing A by A(B) and
̃djB,
̃cjB be obtained by replacing αj, βj, γj by αjB, βjB, γjB in (6.6.9), respectively. De-
note
djB = (djB
1 , . . . , djB
2n−j)T,
cjB = (cjB
1 , . . . , cjB
2n−j)T.
The modiﬁed integral operator is deﬁned as
TNBf(x) =
n
∑
j=1
2n−j
∑
k=1
(̃
djB
k ψjk(x) + ̃
cjB
k φjk(x)) .
Then
‖TNBf −TN(f)‖L2 ≤D
BM log2 N ‖f ‖L2 ≤ε,
where TN is stated in (6.6.10). So we only need compute (TNBf)(x). The corresponding
total number of operations is just O(N log N). From this, we can see that the numerical
solution of integral equations Tf(x) = g(x) via wavelet methods is fast.
Further reading
[1]
Goyal K, Mehra M. Fast diffusion wavelet method for partial differential equations. Applied
Mathematical Modelling. 2016(40):5000–5025.
[2]
Nguyen K, Dabdub D. Two-level time-marching scheme using splines for solving the advection
equation. Atmospheric Environment. 2001(35):1627–1637.
[3]
Garcin M, Guegan D. Wavelet shrinkage of a noisy dynamical system with non-linear noise
impact. Physica D: Nonlinear Phenomena. 2016(325):126–145.
[4]
Ravansalar M, Rajaee T, Zounemat-Kermani M. A wavelet-linear genetic programming model for
sodium (Na+) concentration forecasting in rivers. Journal of Hydrology. 2016(537):398–407.
[5]
Lateb M, Meroney RM, Yataghene M, Fellouah H, Saleh F, Boufadel MC. On the use of numerical
modelling for near-ﬁeld pollutant dispersion in urban environments? A review. Environmental
Pollution. 2016(208):271–283.
[6]
Tan Z, Dong J, Xiao Y, Tu J. Numerical simulation of diurnally varying thermal environment in a
street canyon under haze-fog conditions. Atmospheric Environment. 2015(119):95–106.
[7]
Taghinia J, Rahman MM, Siikonen T. Numerical simulation of airﬂow and temperature ﬁelds
around an occupant in indoor environment. Energy and Buildings. 2015(104):199–207.
[8]
Zhang S, Xia Z, Wang T. A real-time interactive simulation framework for watershed decision
making using numerical models and virtual environment. Journal of Hydrology. 2013(493):
95–104.
[9]
Yu W, Chen XJ, Wu GH, Liu J, Hearn GE. A fast numerical method for trimaran wave resistance
prediction. Ocean Engineering. 2015(107):70–84.

184
|
6 Numerical methods
[10] Rai AC, Lin CH, Chen Q. Numerical modeling of particle generation from ozone reactions with
human-worn clothing in indoor environments. Atmospheric Environment. 2015(102):145–155.
[11] Lefebvre A, Paarlberg AJ, Ernstsen VB, Winter C. Flow separation and roughness lengths over
large bedforms in a tidal environment: A numerical investigation. Continental Shelf Research.
2014(91):57–69.
[12] Felde VA, Bjune AE, Grytnes JA, Birks HJB. A comparison of novel and traditional numerical
methods for the analysis of modern pollen assemblages from major vegetation-landform
types. Review of Palaeobotany and Palynology. 2014(210):22–36.
[13] Sarbu I, Pacurar C. Experimental and numerical research to assess indoor environment quality
and schoolwork performance in university classrooms. Building and Environment. 2015(93):
141–154.
[14] Chen H, Janbakhsh S, Larsson U, Moshfegh B. Numerical investigation of ventilation perfor-
mance of different air supply devices in an office environment. Building and Environment.
2015(90):37–50.
[15] Pennell KG, Scammell MK, McClean MD, Suuberg EM, Roghani AMM, Ames J, Friguglietti L,
Indeglia PA, Shen R, Yao Y, Heiger-Bernays WJ. Field data and numerical modeling: A multiple
lines of evidence approach for assessing vapor intrusion exposure risks. Science of the Total
Environment. 2016(556):291–301.

7 Optimization
Optimization problems arise in almost all areas of environmental science. Optimiza-
tion can be used to reduce overall product cost, minimize negative environment
impacts and maximize the probability of making a correct decision. Many numerical
methods can solve these optimization problems quickly with/without some con-
straints, especially, linear and nonlinear optimization problems. In this chapter we
will introduce main optimization techniques, including Newton’s method, steepest
descent method, Newton–Raphson method, variational method, simplex method,
Fermat method, KKT optimality conditions and primal/dual pairs.
7.1 Newton’s method and steepest descent method
Newton’s algorithm is one of the known methods for solving unconstrained optimiza-
tion problems. We start from the one-dimensional version.
Let f : ℝ→ℝbe an objective function and we will minimize f , i.e., solve the equa-
tion f 󸀠(x) = 0. At ﬁrst, x0 ∈ℝis taken as an initial point. If f 󸀠(x0) = 0, the algorithm
stops. Otherwise, f 󸀠(x0)
̸= 0. Ignoring all nonlinear terms in the Taylor series of f 󸀠(x)
at x0
f 󸀠(x) = f 󸀠(x0) + (x −x0)f 󸀠󸀠(x0) + (x −x0)2 f 󸀠󸀠󸀠(x0)
2!
+ (x −x0)3 f (4)(x0)
3!
+ ⋅⋅⋅,
the nonlinear equation f 󸀠(x) = 0 can be approximated by the linear equation f 󸀠(x0) +
(x −x0)f 󸀠󸀠(x0) = 0. Since f 󸀠󸀠(x0) > 0, the equation yields the ﬁrst iterate
x1 = x0 −f 󸀠(x0)
f 󸀠󸀠(x0)
(f 󸀠(x0)
̸= 0).
The process is repeated at x1, leading to a new iterate x2, and repeatedly to a new
iterate xn. The generic recurrence equation is given by
xk+1 = xk −f 󸀠(xk)
f 󸀠󸀠(xk)
(f 󸀠(xk)
̸= 0, f 󸀠󸀠(xk) > 0).
The one-dimensional classical Newton’s algorithm has a local convergence prop-
erty as follows.
Let f : ℝ→ℝbe twice smooth with f 󸀠(x∗) = 0 and f 󸀠󸀠(x∗) > 0, where x∗∈ℝ.
Denote M∗= f 󸀠󸀠(x∗). If there are r > 0 and M > 0 such that for any x󸀠, x󸀠󸀠∈(x∗−
r, x∗+ r),
|f 󸀠󸀠(x󸀠) −f 󸀠󸀠(x󸀠󸀠)| ≤M |x󸀠−x󸀠󸀠|,
(7.1.1)
then the iterates {xk}k=0,1,... ∈(x∗−r, x∗+ r) converge to x∗quadratically, i.e., |xk+1 −
x∗| ≤C|xk −x∗|2, where C =
M
M∗−Mr (r < M∗
M ).
DOI 10.1515/9783110424904-008

186
|
7 Optimization
In fact, by (7.1.1) and Mr < M∗, it follows that for x ∈(x∗−r, x∗+ r),
|f 󸀠󸀠(x)| = |f 󸀠󸀠(x∗) + f 󸀠󸀠(x) −f 󸀠󸀠(x∗)| ≥|f 󸀠󸀠(x∗)| −|f 󸀠󸀠(x) −f 󸀠󸀠(x∗)| ≥M∗−Mr.
(7.1.2)
Since f(x) is twice smooth, the Lagrange form of the Taylor expansion is
f 󸀠(xk) = f 󸀠(x∗) + (xk −x∗)f 󸀠󸀠( ̄x),
where ̄x ∈(xk, x∗) or ̄x ∈(x∗, xk). From this and f 󸀠(x∗)
f 󸀠󸀠(xk) = 0 (since f 󸀠(x∗) = 0), it follows
that
xk+1 −x∗= (xk −f 󸀠(xk)
f 󸀠󸀠(xk)) −x∗+ f 󸀠(x∗)
f 󸀠󸀠(xk)
= (xk −x∗)f 󸀠󸀠(xk) −(f 󸀠(xk) −f 󸀠(x∗))
f 󸀠󸀠(xk)
= (xk −x∗)(f 󸀠󸀠(xk) −f 󸀠󸀠( ̄x))
f 󸀠󸀠(xk)
.
Therefore, by (7.1.1) and (7.1.2), for xk ∈(x∗−r, x∗+ r),
|xk+1 −x∗| = |xk −x∗| |f 󸀠󸀠( ̄x) −f 󸀠󸀠(xk)|
|f 󸀠󸀠(xk)|
≤C|xk −x∗| | ̄x −xk|,
where C =
M
M∗−Mr . Note that ̄x ∈(xk, x∗) or ̄x ∈(x∗, xk). Clearly, | ̄x −xk| ≤|xk −x∗|. So
|xk+1 −x∗| ≤C|xk −x∗|2,
i.e., the iterates {xk}k=0,1,... converge to x∗quadratically.
Classical Newton’s method
Let f : ℝn →ℝbe a twice smooth function and its Hessian matrix
∇2f(x) = (
(
(
∂2f(x)
∂x2
1
∂2f(x)
∂x1∂x2
⋅⋅⋅
∂2f(x)
∂x1∂xn
∂2f(x)
∂x2∂x1
∂2f(x)
∂x2
2
⋅⋅⋅
∂2f(x)
∂x2∂xn
...
...
...
...
∂2f(x)
∂xn∂x1
∂2f(x)
∂xn∂x2
⋅⋅⋅
∂2f(x)
∂x2
n
)
)
)
be positive deﬁnite, where x = (x1, . . . , xn). The classical Newton’s algorithm involves
the following three steps:
Step 1. Start from an initial point x0 ∈ℝn.
Step 2. Stop if ∇f(xk) = 0, where xk ∈ℝn. Otherwise, the Newton direction
dk = −∇f(xk)(∇2f(xk))−1
(dk ∈ℝn),
where (∇2f(x))−1 is the inverse matrix of the Hessian matrix.

7.1 Newton’s method and steepest descent method
|
187
Step 3. The next iterate xk+1 = xk + dk. Return to Step 2, the process is repeated at
xk+1.
The classic Newton method is related closely to the concept of the descent direction.
Deﬁnition 7.1.1. Let f : ℝn →ℝbe a smooth function. The derivative of f at x in di-
rection d is deﬁned as
∂f(x)
∂d
= lim
λ→0
f(x + λd) −f(x)
λ
,
where x, d ∈ℝn and λ ∈ℝ. If
∂f(x)
∂d
< 0,
then d is said to be a descent direction for f at x.
Note that
f(x + λd) −f(x)
λ
= f(x1 + λd1, x2 + λd2, x3 + λd3, . . . , xn + λdn) −f(x1, x2, x3, . . . , xn)
λ
= f(x1 + λd1, x2 + λd2, x3 + λd3, . . . , xn + λdn) −f(x1, x2 + λd2, x3 + λd3, . . . , xn + λdn)
λ
+ f(x1, x2 + λd2, x3 + λd3, . . . , xn + λdn) −f(x1, x2, x3 + λd3, . . . , xn + λdn)
λ
+ ⋅⋅⋅
+ f(x1, x2, . . . , xn−1, xn + λdn) −f(x1, x2, . . . , xn−1, xn)
λ
.
Let λ →0. Then
∂f(x)
∂d
= d1
∂f(x)
∂x1
+ d2
∂f(x)
∂x2
+ ⋅⋅⋅+ dn
∂f(x)
∂xn
= ⟨∇f(x), d⟩,
where
∇f(x) = ( ∂f(x)
∂x1
, . . . , ∂f(x)
∂xn
)
is the gradient of f at x. From this and Deﬁnition 7.1.1, it is seen that if f is smooth,
then every direction d satisfying ⟨∇f(x), d⟩< 0 is a descent direction at x.
Since the Hessian matrix ∇2f(x) is positive deﬁnite, its inverse matrix (∇2f(x))−1
exists and is also positive deﬁnite, and for all ∇f(xk)
̸= 0,
⟨∇f(xk), ∇f(xk)(∇2f(xk))−1⟩> 0
or ⟨∇f(xk), dk⟩< 0. By Deﬁnition 7.1.1, the Newton direction dk is a descent direction.
The classical Newton’s algorithm has a local convergence property as follows.
Let f : ℝn →ℝbe twice smooth with ∇f(x∗) = 0 and ∇2f(x∗) be positive deﬁnite.
If there are r > 0 and M > 0 such that the Hessian matrix satisﬁes the locally Lipschitz
condition, i.e., for any x󸀠, x󸀠󸀠∈B(x∗, r),
‖∇2f(x󸀠) −∇2f(x󸀠󸀠)‖ ≤M |x󸀠−x󸀠󸀠|,
(7.1.3)

188
|
7 Optimization
where B(x∗, r) is a ball with the center x∗and radius r, then the iterates xk ∈B(x∗, r)
(k = 0, 1, . . . ) converge to x∗quadratically, i.e., |xk+1 −x∗| ≤C|xk −x∗|2, where
C =
M‖I‖
M∗−Mr (r < M∗
M ) and M∗= ‖∇2f(x∗)‖.
In fact, by (7.1.3) and Mr < M∗, it follows that for x ∈B(x∗, r),
‖∇2f(x)‖ = ‖∇2f(x∗) + ∇2f(x) −∇2f(x∗)‖
≥‖∇2f(x∗)‖ −‖∇2f(x) −∇2f(x∗)‖
≥M∗−Mr.
Since ∇2f(x)(∇2f(x))−1 = I, where I is the unit matrix and (∇2f(x))−1 is the inverse
matrix of ∇2f(x), for x ∈B(x∗, r),
‖(∇2f(x))−1‖ =
‖I‖
‖∇2f(x)‖ ≤
‖I‖
M∗−Mr .
(7.1.4)
Since ∇f(x) is a continuously differentiable function, the Lagrange form of its Taylor
expansion is
∇f(xk) = ∇f(x∗) + (xk −x∗)∇2f( ̄x),
where ̄x ∈(xk, x∗) or ̄x ∈(x∗, x). From this and ∇f(x∗)(∇2f(xk))−1 = 0 (since ∇f(x∗) = 0),
it follows that
xk+1 −x∗= (xk −∇f(xk)(∇2f(xk))−1) −x∗+ ∇f(x∗)(∇2f(xk))−1
= (xk −x∗)∇2f(xk)(∇2f(xk))−1 −(∇f(xk) −∇f(x∗))(∇2f(xk))−1
= (xk −x∗)(∇2f(xk) −∇2f( ̄x))(∇2f(xk))−1.
By (7.1.3) and (7.1.4), it follows that for xk ∈B(x∗, r),
|xk+1 −x∗| = |xk −x∗| ‖∇2f(xk) −∇2f( ̄x)‖ ‖(∇2f(xk))−1‖
≤C|xk −x∗| |xk −̄x|,
where C =
M‖I‖
M∗−Mr . Note that
̄x ∈(xk, x∗) or
̄x ∈(x∗, xk). Clearly, |xk −̄x| ≤|xk −x∗|.
So
|xk+1 −x∗| ≤C|xk −x∗|2,
i.e., the iterates {xk}k=0,1,... ∈B(x∗, r) converge to x∗quadratically.
The steepest descent method was introduced by Cauchy. Different to the classical
Newton’s method, steepest descent method chooses a descent direction such that f
decreases most quickly and includes a line minimization step.
Steepest descent method
Let f : ℝn →ℝbe a smooth function. The steepest descent algorithm involves the
following three steps:

7.1 Newton’s method and steepest descent method
|
189
Step 1. Start at an initial point x0 ∈ℝn.
Step 2. Stop if ∇f(xk) = 0, where xk ∈ℝn. Otherwise, the descent direction is
dk = −∇f(xk)
(dk ∈ℝn).
Step 3. The next iterate xk+1 = xk + μkdk, where the step size μk > 0 minimizes the
function f(xk + μdk) with respect to μ on [0, ∞). Return to Step 2, the process is
repeated at xk+1.
The steepest descent algorithm possesses the following convergence property:
The steepest descent algorithm stops after a ﬁnite number of steps at a point
xk where ∇f(xk) = 0. Otherwise, the algorithm generates an inﬁnite sequence of
points {xk}k=0,1,.... According to Bolzano–Weierstrass theorem, the inﬁnite sequence
{xk}k=0,1,... must have at least one convergent subsequence. Without loss of generality,
we still denote this convergent subsequence by {xk}k=0,1,.... Let x∗be its limit point.
Now we prove ∇f(x∗) = 0.
If ∇f(x∗)
̸= 0, then d∗= −∇f(x∗) is a descent direction, i.e., there is a μ∗> 0 so
that f(x∗+ μd∗) < f(x∗) for any μ ∈(0, μ∗). Note that
dk = −∇f(xk),
d∗= −∇f(x∗)
̸= 0.
Since f(x) is a smooth function,
dk →d∗
̸= 0.
Combining this with xk →x∗, it follows from xk+1 = xk + μkdk that μk →0. This
implies μk ∈(0, μ∗).
By the assumption that μk minimizes the function f(xk + μdk) with respect to μ on
[0, ∞), since f(xk) is independent of μ, it is clear that μk also minimizes the function
f(xk + μdk) −f(xk) with respect to μ on [0, ∞). So, for any μk ∈(0, μ∗) and μ ∈(0, μ∗),
f(xk + μkdk) −f(xk) ≤f(xk + μdk) −f(xk).
(7.1.5)
Since f(x) is smooth and xk →x∗, and μk →0, the left-hand side of (7.1.5) is
f(xk + μkdk) −f(xk) →0.
Since f(x) is a smooth function and dk = −∇f(xk), the right-hand side of (7.1.5) is
f(xk + μdk) −f(xk) = ⟨μdk, ∇f(xk)⟩+ o(μ) = −μ⟨∇f(xk), ∇f(xk)⟩+ o(μ),
where o(μ)
|μ| →0 as μ →0. Let k →∞in (7.1.5) and choose μ close enough to 0. Note
that μ > 0 and the assumption ⟨∇f(x∗), ∇f(x∗)⟩> 0. Then
0 ≤−μ⟨∇f(x∗), ∇f(x∗)⟩< 0.
This is a contradiction. Thus ∇f(x∗) = 0.
Newton’s method includes a minimization step and a step size. It is a development
of the classical Newton’s method and is a variant of the steepest descent method.

190
|
7 Optimization
Newton’s method
Let f : ℝn →ℝbe a twice smooth function and its Hessian matrix
∇2f(x) = (
(
(
∂2f(x)
∂x2
1
∂2f(x)
∂x1∂x2
⋅⋅⋅
∂2f(x)
∂x1∂xn
∂2f(x)
∂x2∂x1
∂2f(x)
∂x2
2
⋅⋅⋅
∂2f(x)
∂x2∂xn
...
...
...
. . .
∂2f(x)
∂xn∂x1
∂2f(x)
∂xn∂x2
⋅⋅⋅
∂2f(x)
∂x2
n
)
)
)
be positive deﬁnite, where x = (x1, . . . , xn). Newton’s algorithm involves the following
three steps:
Step 1. Start from an initial point x0 ∈ℝn.
Step 2. Stop if ∇f(xk) = 0, where xk ∈ℝn. Otherwise, the Newton direction is
dk = −∇f(xk)(∇2f(xk))−1
(dk ∈ℝn),
where (∇2f(x))−1 is the inverse matrix of the Hessian matrix.
Step 3. The next iterate xk+1 = xk + μkdk, where the step size μk > 0 minimizes the
function f(xk + μdk) with respect to μ on [0, ∞). Return to Step 2, the process is
repeated at xk+1.
Newton’s algorithm has the same convergence as the steepest descent algorithm.
It stops after a ﬁnite number of steps at a point xk, where ∇f(xk) = 0. Other-
wise, the algorithm generates an inﬁnite sequence of points {xk}k=0,1,.... By the
Bolzano–Weierstrass theorem, the inﬁnite sequence {xk}k=0,1,... must have at least
one convergent subsequence. Without loss of generality, we still denote this conver-
gent subsequence by {xk}k=0,1,.... Let x∗be its limit point. Now we prove ∇f(x∗) = 0.
If ∇f(x∗)
̸= 0, since the Hessian matrix is positive deﬁnite, it is invertible and its
inverse matrix is also positive deﬁnite. By the deﬁnition of positive deﬁnite, the inverse
matrix satisﬁes that
⟨∇f(x∗), ∇f(x∗)(∇2f(x∗))−1⟩> 0,
(7.1.6)
or ⟨∇f(x∗), dk⟩< 0. By Deﬁnition 7.1.1, d∗= −∇f(x∗)(∇2f(x∗))−1 is also a descent di-
rection. So, there is a μ∗> 0 so that f(x∗+ μd∗) < f(x∗) for any μ ∈(0, μ∗). Note
that
dk = −∇f(xk)(∇2f(xk))−1,
d∗= −∇f(x∗)(∇2f(x∗))−1
̸= 0.
Since f : ℝn →ℝis a twice smooth function and xk →x∗,
dk →d∗
̸= 0.
Combining this with xk →x∗, it follows from xk+1 = xk + μkdk that μk →0. This
implies μk ∈(0, μ∗).

7.1 Newton’s method and steepest descent method
|
191
By the assumption that μk minimizes the function f(xk + μdk) with respect to μ
on [0, ∞), but f(xk) is independent of μ, so μk also minimizes the function f(xk +
μdk) −f(xk) with respect to μ on [0, ∞). This implies that for any μk ∈(0, μ∗) and
μ ∈(0, μ∗),
f(xk + μkdk) −f(xk) ≤f(xk + μdk) −f(xk).
(7.1.7)
Since f(x) is smooth and xk →x∗, and μk →0, the left-hand side of (7.1.7) is
f(xk + μkdk) −f(xk) →0.
Since f(x) is smooth and dk = −∇f(xk)(∇2f(xk))−1, the right-hand side of (7.1.7) is
f(xk + μdk) −f(xk) = ⟨∇f(xk), μdk⟩+ o(μ) = −μ⟨∇f(xk), ∇f(xk)(∇2f(xk))−1⟩+ o(μ),
where o(μ)
|μ| →0 as μ →0. Let k →∞in (7.1.7) and choose μ close enough to 0. Note
that μ > 0 and (7.1.6). It is clear that
0 ≤−μ⟨∇f(x∗), ∇f(x∗)(∇2f(x∗))−1⟩< 0.
This is a contradiction. Thus ∇f(x∗) = 0.
Denote G(x) = ∇f(x) and Gk(x) = ∂f(x)
∂xk . The Newton method is viewed as systems
of n linear/nonlinear equations in n unknown variables
G(x) = (
G1(x)
...
Gn(x)
) = (
0
...
0
)
with the Jacobian matrix
∇G(x) = (
∂G1(x)
∂x1
⋅⋅⋅
∂G1(x)
∂xn ,
...
...
...
∂Gn(x)
∂x1
⋅⋅⋅
∂Gn(x)
∂xn
)
and Newton’s algorithm involves a line minimization. Inspired by it, we have the fol-
lowing method.
Newton–Raphson method
Assume that ∇G(x) is invertible. The algorithm involves three steps:
Step 1. Start from an initial point x0 ∈ℝn.
Step 2. Stop if G(xk) = 0, where xk ∈ℝn. Otherwise, the Newton–Raphson direction
dk = −G(xk)(∇G(xk))−1
(dk ∈ℝn),
where (∇G(x))−1 is the inverse matrix of the Jacobian matrix ∇G(x).

192
|
7 Optimization
Step 3. The next iterate xk+1 = xk + dk. Return to Step 2, the process is repeated at
xk+1.
The Newton–Raphson method has the same local convergence property as the classi-
cal Newton method
Let G: ℝn →ℝn be a twice smooth function with G(x∗) = 0 and ∇G(x∗) invertible.
If there are r > 0 and M ≥0 such that for any x󸀠, x󸀠󸀠∈B(x∗, r),
‖∇G(x󸀠) −∇G(x󸀠󸀠)‖ ≤M |x󸀠−x󸀠󸀠|,
then the iterates {xk}k=0,1,... ∈B(x∗, r) converge to x∗quadratically, i.e., |xk+1 −x∗| ≤
C|xk −x∗|2, where C =
M‖I‖
M∗−Mr (r < M∗
M ) and M∗= ‖∇G(x∗)‖.
In fact, similar to the argument of (7.1.4), for x ∈B(x∗, r),
‖(∇G(x))−1‖ =
‖I‖
‖∇G(x)‖ ≤
‖I‖
M∗−Mr .
Since G(x) is continuously differentiable, the Lagrange form of the Taylor expansion
shows that for xk ∈B(x∗, r),
G(xk) = G(x∗) + (xk −x∗)∇G( ̄x),
where ̄x ∈(xk, x∗) or ̄x ∈(x∗, xk). From this and G(x∗)(∇G(xk))−1 = 0 (since G(x∗) = 0),
it follows that
xk+1 −x∗= xk + dk −x∗+ G(x∗)(∇G(xk))−1
= xk −G(xk)(∇G(xk))−1 −x∗+ G(x∗)(∇G(xk))−1
= (xk −x∗)(∇G(xk) −∇G( ̄x))(∇G(xk))−1,
and so
|xk+1 −x∗| = |xk −x∗| ‖∇G(xk) −∇G( ̄x)‖ ‖(∇G(xk))−1‖
≤C|xk −x∗|2,
where C =
M‖I‖
M∗−Mr , i.e., the iterates {xk}k=0,1,... ∈B(x∗, r) converge to x∗quadratically.
7.2 The variational method
The variational method is a useful method for solving the optimization problem of
functionals, i.e., for ﬁnding a function f such that the functional υ(f) with boundary
conditions attains the minimal value
min υ(f)
subject to
{
{
{
υ(f) = ∫
b
a F(x, f(x), f 󸀠(x)) dx,
f(a) = y0,
f(b) = y1
(boundary conditions),
(7.2.1)

7.2 The variational method
|
193
where F is a second-order differentiable function and f is a second-order continuously
differentiable function. For the optimization problem (7.2.1), if the functional υ(f) at-
tains the minimal value, then f must satisfy the Euler equation
Ff −d
dx Ff 󸀠= 0.
In fact, for a small parameter α, let
I(α) =
b
∫
a
F (x, f(x) + αη(x), f 󸀠(x) + αη󸀠(x)) dx,
where η is any differentiable function and η(a) = η(b) = 0. Clearly, I(0) = υ(f). Differ-
entiating both sides,
I󸀠(α) =
b
∫
a
(Ff+αηη(x) + Ff 󸀠+αη󸀠η󸀠(x)) dx.
Let α = 0. Then
I󸀠(0) =
b
∫
a
(Ff η(x) + Ff 󸀠η󸀠(x)) dx =
b
∫
a
Ff η(x) dx +
b
∫
a
Ff 󸀠η󸀠(x) dx.
By integration by parts, the second integral on the right-hand side is
b
∫
a
Ff 󸀠η󸀠(x) dx = Ff 󸀠η(x)󵄨󵄨󵄨󵄨
b
a −
b
∫
a
( d
dx Ff 󸀠) η(x) dx = −
b
∫
a
( d
dx Ff 󸀠) η(x) dx.
Therefore,
I󸀠(0) =
b
∫
a
Ff η(x) dx −
b
∫
a
( d
dx Ff 󸀠) η(x) dx =
b
∫
a
(Ff −d
dx Ff 󸀠) η(x) dx.
If υ(f) attains the minimal value, then I󸀠(0) = 0, i.e.,
b
∫
a
η(x) (Ff −d
dx Ff 󸀠) dx = 0.
Since η(x) is arbitrary, this implies that f must satisfy Ff −d
dx Ff 󸀠= 0.
The generalization of the optimization problem (7.2.1) is as follows:
min υ(f)
subject to
{
{
{
υ(f) = ∫
b
a F (x, f1(x), . . . , fn(x), f 󸀠
1(x), . . . , f 󸀠
n(x)) dx,
fi(a) = yi0,
fi(b) = yi1
(i = 1, . . . , n)
(boundary conditions),

194
|
7 Optimization
where F is a second-order differentiable function and fi (i = 1, . . . , n) are second-
order continuously differentiable functions. Similarly, for the generalized optimiza-
tion problem, if the functional υ(f) attains the minimal value, then fi must satisfy the
Euler equation
Ffi −d
dx Ff 󸀠
i = 0
(i = 1, . . . , n).
The conditional optimization problem of functionals is to ﬁnd f, g such that the
functional υ(f, g) with an additional condition and boundary conditions attains the
minimal value, i.e., to solve the following conditional optimization problem:
min υ(f, g)
subject to
{
{
{
{
{
{
{
{
{
υ(f, g) = ∫
b
a F(x, f, f 󸀠, g, g󸀠) dx,
G(x, f, g) = 0,
f(a) = y0, f(b) = y1,
g(a) = z0, g(b) = z1,
where G(x, f, g) = 0 is the additional condition and f(a) = y0, f(b) = y1, g(a) = z0 and
g(b) = z1 are boundary conditions. If the functional υ(f, g) attains the minimal value,
then f and g must satisfy
d
dx F∗
f 󸀠−F∗
f = 0,
d
dx F∗
g󸀠−F∗
g = 0,
where F∗= F + λ(x)G and
λ(x) =
d
dx Ff 󸀠−Ff
Gf
=
d
dx Fg󸀠−Fg
Gg
.
In fact, the additional condition G(x, f, g) = 0 determines that g is a function of x
and f , say, g = φ(x, f). So
F(x, f, f 󸀠, g, g󸀠) = F(x, f, f 󸀠, φ, φx + φf f 󸀠) =:
̃F(x, f, f 󸀠),
υ(f, g) = υ(f, φ(x, f)) =:
̃υ(f),
φ(a, y0) = z0,
φ(b, y1) = z1.
Then the conditional optimization problem of functionals is reduced to the optimiza-
tion problem (7.2.1), i.e.,
min ̃υ(f)
subject to
{
{
{
̃υ(f) = ∫
b
a
̃F(x, f, f 󸀠) dx,
f(a) = y0,
f(b) = y1.
If the functional υ(f, g) attains the minimal value, i.e.,
̃υ(f) attains the minimal value,
then the Euler equation
d
dx
̃Ff 󸀠−̃Ff = 0

7.2 The variational method
|
195
holds. Note that
̃Ff = Ff + Fgφf + Fg󸀠(φxf + φff f 󸀠),
̃Ff 󸀠= Ff 󸀠+ Fg󸀠φf ,
d
dx
̃Ff 󸀠= d
dx Ff 󸀠+ φf
d
dx Fg󸀠+ Fg󸀠(φfx + φff f 󸀠).
The Euler equation becomes that
d
dx Ff 󸀠−Ff + φf ( d
dx Fg󸀠−Fg) = 0.
On the other hand, differentiating the equation G(x, f, g) = 0 with respect to f ,
Gf + Ggφf = 0,
or φf = −Gf/Gg. So the Euler equation further becomes that
d
dx Ff 󸀠−Ff −Gf
Gg
( d
dx Fg󸀠−Fg) = 0,
i.e.,
d
dx Ff 󸀠−Ff
Gf
=
d
dx Fg󸀠−Fg
Gg
= λ(x)
which is equivalent to
d
dx Ff 󸀠−(Ff + λ(x)Gf) = 0,
d
dx Fg󸀠−(Fg + λ(x)Gg) = 0.
(7.2.2)
Let F∗= F + λ(x)G. Note that
d
dx F∗
f 󸀠= d
dx Ff 󸀠,
F∗
f = Ff + λ(x)Gf ,
d
dx F∗
g󸀠= d
dx Fg󸀠
F∗
g = Fg + λ(x)Gg.
Then, the conditions (7.2.2) are further equivalent to the following conditions:
d
dx F∗
f 󸀠−F∗
f = 0,
d
dx F∗
g󸀠−F∗
g = 0.
The variational method is frequently used in data compression by combining with
dyadic wavelet transform. Denote by θ(t) the Gauss function, i.e.,
θ(t) =
1
√2πα
e−t2
2α
(α > 0).

196
|
7 Optimization
It is clear that
∫
ℝ
θ(t) dt =
1
√π
∞
∫
−∞
1
√2α
e−t2
2α = 1.
Let θλ(t) = 1
λ θ( t
λ) (λ > 0). Using change of variables t = λu gives
∫
ℝ
θλ(t) dt =
∞
∫
−∞
1
λ θ ( t
λ ) dt =
∞
∫
−∞
θ(u) du = 1.
Let f be a one-dimensional signal. The convolution of f and θλ is a mean with weight
θλ,
(f ∗θλ)(t) = ∫
ℝ
f(τ)θλ(t −τ) dτ,
and is an inﬁnitely differentiable function. Note that θ2−m(t) = 2mθ(2mt). Then
d
dt (f ∗θ2−m)(t) = 2m d
dt (∫
ℝ
f(τ)θ(2m(t −τ)) dτ) = 22m ∫
ℝ
f(τ)θ󸀠(2m(t −τ)) dτ.
Let ψ(t) = −θ󸀠(t). Its Fourier transform satisﬁes A ≤∑m∈ℤ| ̂ψ( ω
2m )|2 ≤B (stability con-
dition), where A and B are positive constants. Since θ(t) is an even function, ψ is an
odd function and
d
dt (f ∗θ2−m)(t) = 2m(Wm
ψ f)(t)
(m ∈ℤ),
where Wm
ψ f is the dyadic wavelet transform.
Assume that |(Wm
ψ f)(t)| attains the maximal values on points { tm
n }n,m∈ℤ. Denote
by { Xm
n }m,n∈ℤthese maximal values on points { tm
n }n,m∈ℤ. Once Wm
ψ f (m ∈ℤ) are
found by data {tm
n , Xm
n }m,n∈ℤ, the signal f is obtained immediately using the inversion
formula of dyadic wavelet transform. Thus, it remains to reconstruct Wm
ψ f by data
{ tm
n , Xm
n }n,m∈ℤ. This is reduced to ﬁnding h(t) satisfying the following:
(Wm
ψ h)(tm
n ) = Xm
n
(m, n ∈ℤ),
∫
ℝ
2mh(t)ψ (2m(t −tm
n )) dt = Xm
n .
(7.2.3)
Since the values of |Wm
n h| at tm
n are known, the ﬁrst equation of (7.2.3) can be replaced
approximately by ﬁnding h such that the integral
‖Wm
ψ h‖2
2 = ∫
ℝ
|(Wm
ψ h)(t)|2 dt
(m ∈ℤ)
is as small as possible, and the integral
󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩
d
dt Wm
ψ h
󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩
2
2
= ∫
ℝ
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
d
dt (Wm
ψ h)(t)
󵄨󵄨󵄨󵄨󵄨󵄨󵄨󵄨
2
dt

7.2 The variational method
|
197
is also required to be as small as possible to avoid that new extreme points occur. Both
require that
‖h‖2
∗= ∑
n
(󵄩󵄩󵄩󵄩󵄩Wm
ψ h󵄩󵄩󵄩󵄩󵄩
2
2 + 2−2m 󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩
d
dt Wm
ψ h
󵄩󵄩󵄩󵄩󵄩󵄩󵄩󵄩
2
2
)
attains the minimal value. It is easy to prove that ‖h‖∗< ∞for f ∈L2(ℝ).
Let the space K consist of all differentiable function sequences F = {Fm}m∈ℤsat-
isfying
∑
m
(‖Fm‖2
2 + 2−2m‖F󸀠
m‖2
2) < ∞.
For {Fm}m∈ℤ∈K, deﬁne a boundary linear operator W−1
ψ from K to L2(ℝ) by
W−1
ψ (F) = 1
2π ∑
m
Fm ∗H∗
m,
where H∗
m = 2mψ∗(2mt) and ψ∗is the dyadic dual wavelet of ψ. Let Γ be the closed
subset of F = {Fm}m∈ℤ∈K satisfying the condition Fm(tm
n ) = Xm
n (m, n ∈ℤ), and let V
denote the space of dyadic wavelet transform Wψf , where f ∈L2(ℝ). Then it is desired
to ﬁnd h ∈V ⋂Γ such that ‖h‖K attains the minimal value.
Deﬁne a linear bounded operator from K to V as PV = Wψ ∘W−1
ψ . When F ∈V,
PVF = F. Since ψ is a real-valued odd function, it can be proved that PV is an orthog-
onal project operator from K to V.
Now we ﬁnd the project of F ∈K to the closed subset Γ.
Let PΓ(F) = h. Then ‖F −h∗‖2
K (h∗∈Γ) attains the minimal value at h∗= h =
{h∗
m}m∈ℤ. Let
εm(t) = Fm(t) −h∗
m(t).
(7.2.4)
Then
‖F −h∗‖2
K = ∑
m
(‖εm‖2
2 + 2−2m‖ε󸀠
m‖2
2) .
When h∗
m = hm, this formula attains the minimal value. Note that
εm(tm
n ) = Fm(tm
n ) −Xm
n ,
εm(tm
n+1) = Fm(tm
n+1) −Xm
n+1.
(7.2.5)
When h∗
m = hm, the integral
tm
n+1
∫
tm
n
(|εm(t)|2 + 2−2m|ε󸀠
m(t)|2) dt
(7.2.6)
attains the minimal value. Let y = εm(t). Take H = y2 + 2−2m(y󸀠)2. Then
Hy = 2εm(t),
d
dt Hy󸀠= d
dt (2−2m+1y󸀠) = 2−2m+1ε󸀠󸀠
m(t),

198
|
7 Optimization
and
tm
n+1
∫
tm
n
(|εn(t)|2 + 2−2m|ε󸀠
m(t)|2) dt =
tm
n+1
∫
tm
n
H(y(t), y󸀠(t)) dt.
The variational method says that if y satisﬁes the Euler equation Hy −d
dt Hy󸀠= 0, then
the integral
tm
n+1
∫
tm
n
H(y(t), y󸀠(t)) dt
attains the minimal value. Thus, if εm(t) satisﬁes the Euler equation
εm(t) −2−2mε󸀠󸀠
m(t) = 0
(tm
n ≤t ≤tm
n+1)
(7.2.7)
and (7.2.5), then the integral (7.2.6) attains the minimal value. The solution of (7.2.7) is
εm(t) = αm,ne2mt + βm,ne−2mt
(tm
n ≤t ≤tm
n+1),
where αm,n and βm,n are determined by (7.2.5). This implies from PΓ(F) = h and (7.2.4)
that
PΓ({Fm}) = hm(t) = Fm(t) −(αm,ne2mt + βm,ne−2mt)
(tm
n ≤t ≤tm
n+1, n ∈ℤ).
Finally, denote P = PV ∘PΓ . Let F be a sequence of null functions. Then Wm
ψ f (m ∈ℤ)
are reconstructed by data { tm
n , Xm
n }n,m∈ℤas follows:
{(Wm
ψ f)(t)} ≈lim
ν→∞P(ψ) ∘P(ψ) ∘⋅⋅⋅∘P(ψ),
where ν is the number of P(ψ).
Finally, the signal f is reconstructed immediately by using the inversion formula of
dyadic wavelet transform.
7.3 The simplex method
The simplex method is applied for solving linear optimization models. Linear opti-
mization models may have an objective function that is either to be maximized or to
be minimized; they may have variables that are either nonnegative or free; and they
may have constraints that are either equalities or inequalities.
7.3.1 Pivot operations
Pivot operations are used for solving systems of linear equations or for solving linear
optimization models. Here consider a system of m linear equations with n unknown

7.3 The simplex method
|
199
variables
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn = b1,
a21x1 + a22x2 + ⋅⋅⋅+ a2nxn = b2,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn = bm.
Any entry (i, j) consists of the row index i and the column index j. The chosen en-
try (i, j) in order to obtain a new system of linear equations from the current system
is called a pivot entry. The resulting calculation of the new system from the current
system is called a pivot operation. An indexing function ϕ of the row indices into the
column indices records that for each row k (k = 1, . . . , m), the ϕ(k)-th column has co-
efficient 1 in the entry (k, ϕ(k)) and coefficient 0 in the entries (i, ϕ(k)) (i = 1, . . . , m,
i
̸= k).
Consider the k-th equation of the current system
ak1x1 + ak2x2 + ⋅⋅⋅+ aknxn = bk.
There are three cases.
Case 1. akj = 0 for all j = 1, . . . , n and bk = 0. Then any values x1, . . . , xn satisfy
the k-th equation. The k-th equation is vacuous. In this case, deﬁne the indexing
function as ϕ(k) = 0.
Case 2. akj = 0 for all j = 1, . . . , n but bk
̸= 0. In this case, the k-th equation has no
solution.
Case 3. There are several nonzero coefficients akj. The gradient rule advises to choose
the column index l so that the absolute value of akl (akl
̸= 0) is as large as possible.
In this case, the (k, l) entry is chosen as a pivot entry (i.e., ϕ(k) = l), and then a
pivot operation is performed by Gauss–Jordan elimination. This produces a new
linear system from the current system. The process is as follows.
Divide the k-th equation by akl to produce the new k-th equation, where the coeffi-
cient of xl is 1,
a(1)
k1 x1 + ⋅⋅⋅+ a(1)
k,l−1xl−1 + xl + a(1)
k,l+1xl+1 + ⋅⋅⋅+ a(1)
kn xn = b(1)
k ,
ϕ(k) = l,
where
a(1)
kj = akj
akl
(j = 1, . . . , n),
b(1)
k
= bk
akl
.
Multiply the new k-th equation by ail (i = 1, . . . , m; i
̸= k) so that the coefficient of
xl becomes ail, and then subtract this equation from the i-th equation of the current
system. This produces the new i-th equation, where the coefficient of xl is 0,
a(1)
i1 x1 + ⋅⋅⋅+ a(1)
i,l−1xl−1 + 0xl + a(1)
k,l+1xl+1 + ⋅⋅⋅+ a(1)
in xn = b(1)
i
,

200
|
7 Optimization
where for i = 1, . . . , m, i
̸= k,
a(1)
ij
= aij −akj
akl
ail
(j = 1, . . . , n),
b(1)
i
= bi −bk
akl
ail.
Therefore, the resulting new system from the current system by a pivot operation is
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
a(1)
11 x1 + ⋅⋅⋅+ a(1)
1,l−1xl−1 + 0 + a(1)
1,l+1xl+1 + ⋅⋅⋅+ a(1)
1n xn = b(1)
1 ,
...
a(1)
k1 x1 + ⋅⋅⋅+ a(1)
k,l−1xl−1 + xl + a(1)
k,l+1xl+1 + ⋅⋅⋅+ a(1)
kn xn = b(1)
k ,
...
a(1)
m1x1 + ⋅⋅⋅+ a(1)
m,l−1xl−1 + 0 + a(1)
m,l+1xl+1 + ⋅⋅⋅+ a(1)
mnxn = b(1)
m ,
ϕ(k) = l,
where
a(1)
kj = akj
akl
(j = 1, . . . , n),
b(1)
k
= bk
akl
,
and for i = 1, . . . , m, i
̸= l,
a(1)
ij
= aij −akj
akl
ail
(j = 1, . . . , n),
b(1)
i
= bi −bk
akl
ail,
which are called pivoting formulas. These formulas are extremely important for solving
linear system and linear optimization models. It can be veriﬁed that the new system
and the current system are equivalent.
7.3.2 Basic variables and nonbasic variables
The standard linear optimization model with equality constraints and nonnegative
variables is the form
(L): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + c2x2 + ⋅⋅⋅+ cnxn = d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn = b1,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn = bm,
x1 ≥0, x2 ≥0, . . . , xn ≥0,

7.3 The simplex method
|
201
where bi, cj have any values. Assume that for each k (k = 1, . . . , m), the coefficients
of the ϕ(k)-th column satisfy
akϕ(k) = 1,
aiϕ(k) = 0,
cϕ(k) = 0,
(i = 1, . . . , m, i
̸= k),
where ϕ is an indexing function of row indices into column indices. Then the corre-
sponding variables xϕ(k) are called basic variables and the remaining variables are
called nonbasic variables. The solution
{
{
{
xϕ(k) = bk
(k = 1, . . . , m),
xj = 0
otherwise
is called the basic solution of the model (L). The objective function of the model (L) is
rewritten as
y = −c1x1 −⋅⋅⋅−cnxn + d.
Under the above assumption condition, the coefficients of basic variables are equal to
zero, i.e., cϕ(k) = 0. Since nonbasic variables themselves in the basic solution of the
model (L) are equal to zero, i.e., xj = 0 (j
̸= ϕ(k)), the value of the objective function
is reduced to y = d.
Deﬁnition 7.3.1. Under the above assumption condition,
–
if bi ≥0 for all i = 1, . . . , m and all cj have any values, the model (L) is said to
be in basic form;
–
if cj ≥0 for all j = 1, . . . , n and all bi have any values, the model (L) is said to be
in dual basic form.
7.3.3 The simplex algorithm
The discovery of the simplex method is due to George Dantzig. This method is ap-
plied for solving the standard linear optimization models with equality constraints
and nonnegative variables in basic form.
Given a standard linear optimization model with equality constraints and non-
negative variables in basic form as follows:
(Lb)
max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + c2x2 + ⋅⋅⋅+ cnxn = d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn = b1,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn = bm,
x1 ≥0, x2 ≥0, . . . , xn ≥0,

202
|
7 Optimization
where bi ≥0 for all i = 1, . . . , m and all cj have any values, its matrix form is that
(Lb): max y
subject to
{
{
{
{
{
{
{
{
{
y + ⟨c, x⟩= d,
AxT = bT,
x ∈ℝn
+,
where b = (b1, . . . , bm) ≥0 and c = (c1, . . . , cn) have any values, and ℝn
+ = [0, ∞)n,
and
A = (
a11
⋅⋅⋅
a1n
...
...
...
am1
⋅⋅⋅
amn
) .
The simplex algorithm consists of three cases.
Case 1. cj ≥0 for all j = 1, . . . , n. Then the basic solution of the model (Lb) is optimal
and the corresponding value of the objective function is d. The algorithm stops.
In fact, if x∗
1, x∗
2, . . . , x∗
n is the basic solution of the model (Lb), then
y(x∗
1, x∗
2, . . . , x∗
n) = d.
On the other hand, for any solution x1, x2, . . . , xn, since cj, xj ≥0 (j = 1, . . . , n),
the objective function
y(x1, . . . , xn) = −c1x1 −⋅⋅⋅−cnxn + d ≤d.
Thus, the basic solution is optimal.
Case 2. There is a column l so that cl < 0 and ail ≤0 for all i = 1, . . . , m. Then the
model (Lb) has no feasible solution. The algorithm stops.
In fact, since cl < 0, xl must be a nonbasic variable. It is known that for basic
variables,
akϕ(k) = 1,
aiϕ(k) = 0
(i
̸= k),
cϕ(k) = 0,
and for nonbasic variables, xj = 0 (j
̸= l). So the k-th equation of the model (Lb)
reduces to
xϕ(k) + aklxl = bk
or
xϕ(k) = bk −aklxl,
where bk ≥0 and akl ≤0, and the objective function of the model (Lb) reduces to
y = −clxl + d,
where cl < 0. Thus, y can be made arbitrarily large by choosing xl sufficiently
large.

7.3 The simplex method
|
203
Case 3. There is a column l so that cl < 0 and ail > 0 for some i = 1, . . . , m. If there
are several columns l so that cl < 0, then the gradient rule advises to choose the
column l so that cl is the most negative, and then choose the row index k so that
{
{
{
akl > 0,
bk
akl = min1≤i≤m { bi
ail : ail > 0} .
Pivoting on the (k, l) entry, this produces a new model (Lb
1) from the model (Lb)
by a pivot operation
(Lb
1)
max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c(1)
1 x1 + ⋅⋅⋅+ c(1)
l−1xl−1 + 0 + c(1)
l+1xl+1 + ⋅⋅⋅+ c(1)
n xn = d(1),
a(1)
11 x1 + ⋅⋅⋅+ a(1)
1,l−1xl−1 + 0 + a(1)
1,l+1xl+1 + ⋅⋅⋅+ a(1)
1n xn = b(1)
1 ,
...
a(1)
k1 x1 + ⋅⋅⋅+ a(1)
k,l−1xl−1 + xl + a(1)
k,l+1xl+1 + ⋅⋅⋅+ a(1)
kn xn = b(1)
k ,
ϕ(k) = l,
...
a(1)
m1x1 + ⋅⋅⋅+ a(1)
m,l−1xl−1 + 0 + a(1)
m,l+1xl + ⋅⋅⋅+ a(1)
mnxn = b(1)
m ,
x1 ≥0, x2 ≥0, . . . , xn ≥0,
where the new coefficients are given by the pivoting formulas
a(1)
kj = akj
akl
(j = 1, . . . , n),
b(1)
k
= bk
akl
,
and the pivoting formulas for i = 1, . . . , m, i
̸= k,
a(1)
ij
= aij −akj
akl
ail
(j = 1, . . . , n),
b(1)
i
= bi −bk
akl
ail,
c(1)
j
= cj −akj
akl
cl
(j = 1, . . . , n),
d(1) = d −bk
akl
cl.
Repeat the above process with (Lb
1) until a newer model is in Case 1 or Case 2.
7.3.4 The dual simplex method
The dual simplex method is used for solving the standard linear optimization models
with equality constraints and nonnegative variables in dual basic form. Given a stan-
dard linear optimization model with equality constraints and nonnegative variables

204
|
7 Optimization
in dual basic form as follows:
(Ld): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + ⋅⋅⋅+ cnxn = d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn = b1,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn = bm,
x1 ≥0,
x2 ≥0,
...,
xn ≥0,
where cj ≥0 for all j = 1, . . . , n and all bi have any values. Its matrix form is that
(Ld): max y
subject to
{
{
{
{
{
{
{
{
{
y + ⟨c, x⟩= d,
AxT = bT,
x ∈ℝn
+,
where c = (c1, . . . , cn) ≥0 and b = (b1, . . . , bm) have any values, and x = (x1, . . . , xn),
and
A = (
a11
⋅⋅⋅
a1n
...
...
...
am1
⋅⋅⋅
amn
) .
The dual simplex algorithm consists of three cases.
Case 1. bi ≥0 for all i = 1, . . . , m. This is just Case 1 of the above simplex algorithm.
Thus, the basic solution of the model (Ld) is optimal and the corresponding value
of the objective function is d. The algorithm stops.
Case 2. There is a row k so that bk < 0 and akl ≥0 for all l = 1, . . . , n. Then the model
(Ld) has no feasible solution. The algorithm stops.
In fact, for any x1 ≥0, . . . , xn ≥0, since akl ≥0 for all l = 1, . . . , n,
ak1x1 + ⋅⋅⋅+ aknxn ≥0.
But bk < 0. So x1, . . . , xn cannot satisfy the k-th equation, and so the model (Ld)
has no feasible solution.
Case 3. There is a row k so that bk < 0 and akl < 0 for some l = 1, . . . , n. If there are
several rows k so that bk < 0, then the dual gradient rule advises to choose the
row index k so that bk is the most negative, and then choose the column index l
so that
{
{
{
akl < 0,
cl
akl = max1≤j≤n { cj
akj : akj < 0} .
Pivoting on the (k, l) entry, this produces a new model (Ld
1) from the current model
(Ld) by a pivot operation. Repeat the above process with (Ld
1) until a newer model
is in Case 1 or Case 2.

7.3 The simplex method
|
205
7.3.5 Slack variables
Any linear optimization model with inequality constraints and nonnegative variables
can be converted into an equivalent standard linear optimization model with equality
constraints and nonnegative variables by introducing new variables. The introduced
new variables are called slack variables. This is a major creative idea in the develop-
ment of the simplex method. The types often used are as follows.
Type 1
The model is a linear optimization model with inequality constraints and nonnegative
variables as follows:
(L)
max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + c2x2 + ⋅⋅⋅+ cnxn = d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn ≤b1,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn ≤bm,
x1 ≥0, x2 ≥0, . . . , xn ≥0,
where bi ≥0 for all i = 1, . . . , m and all cj have any values. Its matrix form is that
(L): max y
subject to
{
{
{
{
{
{
{
{
{
y + ⟨c, x⟩= d,
AxT ≤bT,
x ∈ℝn
+,
where b = (b1, . . . , bm) ≥0 and c = (c1, . . . , cn) have any values, and x = (x1, . . . , xn),
and
A = (
a11
⋅⋅⋅
a1n
...
...
...
am1
⋅⋅⋅
amn
) .
Introduce m new variables xn+i (i = 1, . . . , m) (i.e., m slack variables) to convert
inequality constraints to equality constraints. This produces a standard linear opti-
mization model with equality constraints and nonnegative variables in basic form as
follows:

206
|
7 Optimization
(Lb)
max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + ⋅⋅⋅+ cnxn + 0 + 0 + 0 + ⋅⋅⋅+ 0 = d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn + xn+1 + 0 + 0 + ⋅⋅⋅+ 0 = b1,
ϕ(1) = n + 1,
a21x1 + a22x2 + ⋅⋅⋅+ a2nxn + 0 + xn+2 + 0 + ⋅⋅⋅+ 0 = b2,
ϕ(2) = n + 2,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn + 0 + 0 + ⋅⋅⋅+ 0 + xn+m = bm,
ϕ(m) = n + m,
x1 ≥0, x2 ≥0, . . . , xn+m ≥0,
where bi ≥0 for all i = 1, . . . , m and all cj have any values. Here ϕ is an indexing
function of row indices into column indices and xn+i ≥0 (i = 1, . . . , m). It is seen that
when ϕ(k) = n + k (k = 1, . . . , m),
akϕ(k) = 1,
aiϕ(k) = 0
(i = 1, . . . , m, i
̸= k),
cϕ(k) = 0.
Thus, the slack variables xn+k (k = 1, . . . , m) are basic variables and the original
variables xj (j = 1, . . . , n) are nonbasic variables. Let the nonbasic variables xj = 0
(j = 1, . . . , n). Then xn+i = bi (i = 1, . . . , m). So
xj = 0
(j = 1, . . . , n),
xn+i = bi
(i = 1, . . . , m)
is the basic solution of the model (Lb).
Applying the simplex method to the model (Lb), we will obtain the optimal solu-
tion and the corresponding value of the objective function.
Example 7.3.2. Given a linear optimization model with inequality constraints and
nonnegative variables,
(L): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y −4x1 −5x2 = 25,
x1 + 2x2 ≤12,
x1 + x2 ≤9,
4x1 + 5x2 ≤40,
x1 ≤0, x2 ≥0,
try to solve it by the simplex method.
Solution. It is clear that the set of feasible solutions of the model (L) is a polygonal
region with vertices (0, 0), (0, 6), (6, 3), and (9, 0).

7.3 The simplex method
|
207
Introduce three slack variables x3, x4, x5 to convert inequality to equality con-
straints. This produces a standard linear optimization model with equality constraints
and nonnegative variables in basic form as follows:
(Lb): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y −4x1 −5x2 + 0 + 0 + 0 = 25,
x1 + 2x2 + x3 + 0 + 0 = 12,
ϕ(1) = 3,
x1 + x2 + 0 + x4 + 0 = 9,
ϕ(2) = 4,
4x1 + 5x2 + 0 + 0 + x5 = 40,
ϕ(3) = 5,
x1 ≤0, x2 ≥0, x3 ≥0, x4 ≥0, x5 ≥0,
where ϕ is an indexing function of row indices into column indices. It is seen that
the basic variables of the model (Lb) are x3, x4, x5 and the nonbasic variables of the
model (Lb) are x1, x2. Let nonbasic variables x1 = x2 = 0. Then x3 = 12, x4 = 9,
x5 = 40. So the basic solution of the model (Lb) is
x1 = 0,
x2 = 0,
x3 = 12,
x4 = 9,
x5 = 40
and the corresponding value of the objective function is y(0, 0) = 25 (see Table 7.1).
Tab. 7.1: First simplex tableau.
Basic
Variables
Equation
Number
Coefficient of
Right Side
of Equation
y
x1
x2
x3
x4
x5
y
0
1
−4
−5
0
0
0
25
x3
1
0
1
2
1
0
0
12
x4
2
0
1
1
0
1
0
9
x5
3
0
4
5
0
0
1
40
Here the point (0, 0) is the ﬁrst vertex of the set of feasible solutions of the model (L).
Since c1 = −4 and c2 = −5, the model (Lb) is not in Case 1 of the simplex algorithm.
So the basic solution is not optimal.
In the model (Lb), c1 = −4, and c2 = −5. The gradient rule advises to choose the
column index l = 2 since c2 = −5 is the most negative. In this column,
a12 = 2 > 0,
a22 = 1 > 0,
a32 = 5 > 0,
so the model (Lb) is in Case 3 of the simplex algorithm. Choose the row index k = 1
since a12 > 0 and
bk
ak2
= min { b1
a12
, b2
a22
, b3
a32
} = min{ 6, 9, 8 } = 6 = b1
a12
.

208
|
7 Optimization
Pivoting on the (1, 2) entry, this produces a new model (Lb
1) from the model (Lb) by
the ﬁrst pivot operation
(Lb
1): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y −3
2 x1 + 0 + 5
2 x3 + 0 + 0 = 55,
1
2 x1 + x2 + 1
2 x3 + 0 + 0 = 6,
ϕ(1) = 2,
1
2 x1 + 0 −1
2 x3 + x4 + 0 = 3,
ϕ(2) = 4,
3
2 x1 + 0 −5
2 x3 + 0 + x5 = 10,
ϕ(3) = 5,
x1 ≤0, x2 ≥0, x3 ≥0, x4 ≥0, x5 ≥0.
It is seen that the basic variables of the model (Lb
1) are x2, x4, x5 and the nonbasic
variables of the model (Lb
1) are x1, x3. Let nonbasic variables x1 = x3 = 0. Then x2 = 6,
x4 = 3, x5 = 10. So the basic solution of the model (Lb
1) is
x1 = 0,
x2 = 6,
x3 = 0,
x4 = 3,
x5 = 10
and the corresponding value of the objective function is y(0, 6) = 55 (see Table 7.2).
Here the point (0, 6) is the second vertex of the set of feasible solutions of the model
(L). Since c1 = −3
2 , the model (Lb
1) is not in Case 1 of the simplex algorithm. So the
basic solution is not optimal.
Tab. 7.2: Second simplex tableau.
Basic
Variables
Equation
Number
Coefficient of
Right Side
of Equation
y
x1
x2
x3
x4
x5
y
0
1
−3
2
0
5
2
0
0
55
x2
1
0
1
2
1
1
2
0
0
6
x4
2
0
1
2
0
−1
2
1
0
3
x5
3
0
3
2
0
−5
2
0
1
10
In the model (Lb
1), c1 = −3
2 . The chosen column index is l = 1. In this column, a11 =
1
2 > 0, a21 = 1
2 > 0, and a31 = 3
2 > 0, so the model (Lb
1) is in Case 3 of the simplex
algorithm. Choose the row index k = 2 since a21 > 0 and
bk
ak1
= min { b1
a11
, b2
a21
, b3
a31
} = min {12, 6, 20
3 } = 6 = b2
a21
.

7.3 The simplex method
|
209
Pivoting on the (2, 1) entry, this produces a new model (Lb
2) from the model (Lb
1) by
the second pivot operation
(Lb
2): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 0 + 0 + x3 + 3x4 + 0 = 64,
0 + x2 + x3 −x4 + 0 = 3,
ϕ(1) = 2,
x1 + 0 −x3 + 2x4 + 0 = 6,
ϕ(2) = 1,
0 + 0 −x3 −3x4 + x5 = 1,
ϕ(3) = 5,
x1 ≤0, x2 ≥0, x3 ≥0, x4 ≥0, x5 ≥0.
It is seen that the basic variables of the model (Lb
2) are x1, x2, x5 and the nonbasic
variables of the model (Lb
2) are x3, x4. Let nonbasic variables x3 = x4 = 0. Then x1 = 6,
x2 = 3, x5 = 1. In the model (Lb
2), cj ≥0 for all j = 1, 2, 3, 4, 5. So the model (Lb
2) is
in Case 1 of the simplex algorithm. The basic solution of the model (Lb
2)
x1 = 6,
x2 = 3,
x3 = 0,
x4 = 0,
x5 = 1
is the optimal solution of the model (L) and the corresponding value of the objective
function is y(6, 3) = 64. Here the point (6, 3) is the third vertex of the set of feasible
solutions of the model (L) (see Table 7.3).
Tab. 7.3: Third simplex tableau.
Basic
Variables
Equation
Number
Coefficient of
Right Side
of Equation
y
x1
x2
x3
x4
x5
y
0
1
0
0
1
3
0
64
x1
1
0
0
1
1
−1
0
3
x2
2
0
1
0
−1
2
0
6
x5
3
0
0
0
−1
−3
1
1
From Example 7.3.2, it is seen that the calculations applying the simplex method to
solve the standard linear optimization model in basic form are to journey from one
vertex of the set of feasible solutions of the given linear optimization model with in-
equality constraints and nonnegative variables to another such vertex by the pivot
operations.

210
|
7 Optimization
Type 2
The model is a linear optimization model with inequality constraints and nonnegative
variables
(L)
min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
z = c1x1 + c2x2 + ⋅⋅⋅+ cnxn + d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn ≥b1,
a21x1 + a22x2 + ⋅⋅⋅+ a2nxn ≥b2,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn ≥bm,
x1 ≥0, x2 ≥0, , . . . , xn ≥0,
where cj ≥0 for all j = 1, . . . , n and all bi have any values. Its matrix form is that
(L): min z
subject to
{
{
{
z = ⟨c, x⟩+ d,
AxT ≥bT, x ∈ℝn
+,
where c = (c1, . . . , cn) ≥0 and b = (b1, . . . , bm) have any values, and x = (x1, . . . , xn),
and
A = (
a11
⋅⋅⋅
a1n
...
...
...
am1
⋅⋅⋅
amn
) .
Let y = −z. In the model (L), converting minimization of z to maximization of
y, and then multiplying the inequalities by −1, produces a linear optimization model
(L∗) with inequality constraints and nonnegative variables from the current model (L)
as follows:
(L∗)
max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
−y = c1x1 + c2x2 + ⋅⋅⋅+ cnxn + d,
−a11x1 −a12x2 −⋅⋅⋅−a1nxn ≤−b1,
...
−am1x1 −am2x2 −⋅⋅⋅−amnxn ≤−bm,
x1 ≥0, x2 ≥0, . . . , xn ≥0,
where cj ≥0 for all j = 1, . . . , n and all bi have any values.
Introducing m slack variables xn+i (i = 1, . . . , m), the model (L∗) is further con-
verted to a standard linear optimization model with equality constraints and nonneg-
ative variables in dual basic form as follows:

7.3 The simplex method
|
211
(Ld): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + c2x2 + ⋅⋅⋅+ cnxn + 0 + 0 + ⋅⋅⋅+ 0 = −d,
−a11x1 −a12x2 −⋅⋅⋅−a1nxn + xn+1 + 0 + ⋅⋅⋅+ 0 = −b1,
ϕ(1) = n + 1,
−a21x1 −a22x2 −⋅⋅⋅−a2nxn + 0 + xn+2 + ⋅⋅⋅+ 0 = −b2,
ϕ(2) = n + 2,
...
−am1x1 −am2x2 −⋅⋅⋅−amnxn + 0 + 0 + ⋅⋅⋅+ 0 + xn+m = −bm,
ϕ(m) = n + m,
x1 ≥0, x2 ≥0, . . . , xn+m ≥0,
where cj ≥0 for all j = 1, . . . , n and all bi have any values. Here xn+i ≥0 (i = 1, . . . , m).
Applying the dual simplex method to the model (Ld), we will obtain the optimal
solution of the model (Ld) and the corresponding value of the objective function.
Example 7.3.3. Given a linear optimization model with inequality constraints and
nonnegative variables
(L): min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
z = 3x1 + 4x2,
4x1 + 2x2 ≥18,
2x1 + 5x2 ≥25,
2x1 + 3x2 ≥19,
where x1 ≥0 and x2 ≥0, try to solve the model (L) by the dual simplex method.
Solution. Let y = −z. Converting minimization of z to maximization of y, multiplying
the inequalities by −1, and then introducing three slack variables x3, x4, x5, produces
a standard linear optimization model with equality constraints and nonnegative vari-
ables in dual basic form as follows:
(Ld): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 3x1 + 4x2 + 0 + 0 + 0 = 0,
−4x1 −2x2 + x3 + 0 + 0 = −18,
ϕ(1) = 3,
−2x1 −5x2 + 0 + x4 + 0 = −25,
ϕ(2) = 4,
−2x1 −3x2 + 0 + 0 + x5 = −19,
ϕ(3) = 5,
x1 ≥0, x2 ≥0.
where c1 = 3 and c2 = 4 are both nonnegative.
Since b1 = −18 < 0, b2 = −25 < 0, and b3 = −19 < 0, the dual gradient rule
advises to choose the second row k = 2 since b2 = −25 is the most negative. In this
row, a21 = −2 < 0 and a22 = −5 < 0. So the model (Ld) is in Case 3 of the dual simplex

212
|
7 Optimization
algorithm. Note that c1 = 3 and c2 = 4. Choose the column l = 2 since
{
{
{
a22 < 0,
cl
a2l = max { c1
a21 , c2
a22 } = max {−3
2 , −4
5} = −4
5 =
c2
a22 .
Pivoting on the (2, 2) entry, this produces a newer model (Ld
1) from the model (Ld) by
the ﬁrst pivot operation
(Ld
1): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 7
5 x1 + 0 + 0 + 4
5 x4 + 0 = −20,
−16
5 x1 + 0 + x3 −2
5 x4 + 0 = −8,
ϕ(1) = 3,
2
5 x1 + x2 + 0 −1
5 x4 + 0 = 5,
ϕ(2) = 2,
−4
5 x1 + 0 + 0 −3
5 x4 + x5 = −4,
ϕ(3) = 5,
x1 ≥0, x2 ≥0,
where c1 = 7
5 and c4 = 4
5 are both nonnegative. It is seen that basic variables of the
model (Ld
1) are x2, x3, x5 and nonbasic variables of the model (Ld
1) are x1, x4. Let
nonbasic variables x1 = x4 = 0. Then x2 = 5, x3 = −8, x5 = −4. So the basic solution
of the model (Ld
1) is
x1 = 0,
x2 = 5,
x3 = −8,
x4 = 0,
x5 = −4
and the corresponding value of the objective function is y(0, 5) = −20 (see Table 7.4).
Since b1 = −8 and b3 = −4, the model (Ld
1) is not in Case 1 of the dual simplex algo-
rithm. So the solution is not the optimal one.
Tab. 7.4: First dual simplex tableau.
Basic
Variables
Equation
Number
Coefficient of
Right Side
of Equation
y
x1
x2
x3
x4
x5
y
0
1
7
5
0
0
4
5
0
−20
x2
1
0
−16
5
0
1
−2
5
0
−8
x3
2
0
2
5
1
0
−2
5
0
5
x5
3
0
−4
5
0
0
−3
5
1
−4
In the model (Ld
1), since b1 = −8 and b3 = −4, the dual gradient rule advises to choose
the row k = 1 since b1 = −8 is the most negative. In this row, b1 = −8, and a11 = −16
5 < 0
and a14 = −2
5 < 0, so the model (Ld
1) is in Case 3 of the dual simplex algorithm.

7.3 The simplex method
|
213
Note that c1 = 7
5 and c4 = 4
5 . Choose the column l = 1 since
{
{
{
a11 < 0,
cl
a1l = max { c1
a11 , c4
a14 } = max {−7
16 , −2} = −7
16 =
c1
a11 .
Pivoting on the (1, 1) entry, this produces a newer model (Ld
2) from the model (Ld
1) by
the second pivot operation
(Ld
2): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 0 + 0 + 7
16 x3 + 5
8 x4 + 0 = −47
2 ,
x1 + 0 −5
16 x3 + 1
8 x4 + 0 = 5
2 ,
ϕ(1) = 1,
0 + x2 + 1
8 x3 −1
4 x4 + 0 = 4,
ϕ(2) = 2,
0 + 0 −1
4 x3 −1
2 x4 + x5 = −2,
ϕ(3) = 5,
x1 ≥0, x2 ≥0,
where c3 = 7
16 and c4 = 5
8 are nonnegative. It is seen that basic variables of the model
(Ld
2) are x1, x2, x5 and nonbasic variables of the model (Ld
2) are x3, x4. Let nonbasic
variables x3 = x4 = 0. Then x1 = 5
2 , x2 = 4, x5 = −2. So the basic solution of the model
(Ld
2) is
x1 = 5
2 ,
x2 = 4,
x3 = 0,
x4 = 0,
x5 = −2
and the corresponding value of the objective function is y( 5
2 , 4) = −47
2 (see Table 7.5).
Since b3 = −2 < 0, the model (Ld
2) is not in Case 1 of the dual simplex algorithm, and
so the solution is not optimal.
In the model (Ld
2), choose the row k = 3 since b3 = −2 is the only negative value.
In this row, a33 = −1
4 < 0 and a34 = −1
2 < 0. So the model (Ld
1) is in Case 3 of the dual
simplex algorithm. Note that c3 =
7
16 and c4 = 5
8 . Choose the column l = 4 since
{
{
{
a34 < 0,
cl
a3l = max { c3
a33 , c4
a34 } = max {−7
4 , −5
4} = −5
4 =
c4
a34 .
Tab. 7.5: Second dual simplex tableau.
Basic
Variables
Equation
Number
Coefficient of
Right Side
of Equation
y
x1
x2
x3
x4
x5
y
0
1
0
0
7
16
5
8
0
−47
2
x1
1
0
1
0
−5
16
1
8
0
5
2
x2
2
0
0
1
1
8
−1
4
0
4
x5
3
0
0
0
−1
4
−1
2
1
−2

214
|
7 Optimization
Pivoting on the (3, 4) entry, this produces a newer model (Ld
3) from the model (Ld
2) by
the third pivot operation
(Ld
3): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 0 + 0 + 1
8 x3 + 0 + 5
4 x5 = −26,
x1 + 0 −3
8 x3 + 0 + 1
4 x5 = 2,
ϕ(1) = 1,
0 + x2 + 1
4 x3 + 0 −1
2 x5 = 5,
ϕ(2) = 2,
0 + 0 + 1
2 x3 + x4 −2x5 = 4,
ϕ(3) = 4,
x1 ≥0, x2 ≥0,
where c3 = 1
8 and c4 = 5
4 are both nonnegative. It is seen that the basic variables of
the model (Ld
3) are x1, x2, x4 and nonbasic variables of the model (Ld
3) are x3, x5. Let
x3 = x5 = 0. Then x1 = 2, x2 = 5, x4 = 4. Note that bi > 0 for all i = 1, 2, 3 in the
model (Ld
3). So the model (Ld
3) is in Case 1 of the dual simplex algorithm. So the basic
solution of the model (Ld
3)
x1 = 2,
x2 = 5,
x3 = 0,
x4 = 4,
x5 = 0.
is the optimal solution of the model (L) and the corresponding value of the objective
function is y(2, 5) = −26 (see Table 7.6). Here (2, 5) is a vertex of the set of feasible
solutions of the model (L).
Tab. 7.6: Third dual simplex tableau.
Basic
Variables
Equation
Number
Coefficient of
Right Side
of Equation
y
x1
x2
x3
x4
x5
y
0
1
0
0
1
8
0
5
4
−26
x1
1
0
1
0
−3
8
0
1
4
2
x2
2
0
0
1
1
4
0
−1
2
5
x4
3
0
0
0
1
2
1
−2
4
Note that min z = −max(−z) = −max y and max y = −26. Then min z = 26.
Consider the following standard linear optimization model, satisfying the assumption
condition given in Section 7.3.2, with equality constraints and nonnegative variables:

7.3 The simplex method
|
215
(L): min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
z = c1x1 + c2x2 + ⋅⋅⋅+ cnxn + d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn = b1,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn = bm,
x1 ≥0, x2 ≥0, . . . , xn ≥0,
where the ﬁrst h −1 right-hand sides bi ≥0 (i = 1, . . . , h −1), bi (i = h, . . . , m), and
cj (j = 1, . . . , n) have any values. The model (L) will be converted to a model in basic
form.
For convenience, without loss of generality, assume that in the model (L), the ﬁrst
m −1 right-hand side bi ≥0 (i = 1, . . . , m −1) and bm has any value. Then the model
(L) is converted to a model in basic form below.
Focusing on the m-th row of the model (L), there are three cases.
Case 1. bm ≥0. Then the model (L) is the desired model. The algorithm stops.
Case 2. bm < 0 and amj ≥0 for all j. Then am1x1 + ⋅⋅⋅+ amnxn ≥0 for any solution
xj ≥0 (j = 1, . . . , n) but bm < 0. Thus the m-th equation has no solution. The
algorithm stops.
Case 3. bm < 0 and aml < 0 for some l. Then the chosen column index is l. Regard the
ﬁrst (m −1) rows as the constraints and the m-th row as the objective row. There
are two alternatives.
–
If ail ≤0 for all i = 1, . . . , m −1, then the chosen row index is m. So the
(m, l) entry in the objective row is chosen as the pivot entry, this produces a
new model (L1) with coefficients c(1)
j
, a(1)
ij , b(1)
i
, where
{
{
{
b(1)
m = bm
aml > 0,
b(1)
i
= bi −bm
aml ail ≥0
(i = 1, . . . , m −1)
since bi ≥0 (i = 1, . . . , m −1). Thus the model (L1) is in basic form. The
algorithm stops.
–
If ail > 0 for some i (1 ≤i ≤m −1), then the model (L) is in Case 3 of the
simplex algorithm. So the chosen row index k is such that akl > 0 and
bk
akl
=
min
1≤j≤m−1 { bj
ajl
: ajl > 0} .
Pivoting on the (k, l) entry, this produces a new model (L1) from the model (L). If the
new model (L1) is in basic form, then the algorithm stops. Otherwise, repeat the above
process with the model (L1) until a newer model is in basic form.

216
|
7 Optimization
Type 3
The model is a linear optimization model with nonnegative variables, μ inequality
constraints and m −μ equality constraints as follows:
(L)
min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
z = c1x1 + c2x2 + ⋅⋅⋅+ cnxn + d,
a11x1 + a12x2 + ⋅⋅⋅+ a1nxn ≥b1,
...
aμ1x1 + aμ2x2 + ⋅⋅⋅+ aμnxn ≥bμ,
aμ󸀠1x1 + aμ󸀠2x2 + ⋅⋅⋅+ aμ󸀠nxn = bμ󸀠,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn = bm,
x1 ≥0, x2 ≥0, . . . , xn ≥0,
where cj and bi have any values and μ󸀠= μ + 1. Its matrix form is
(L): min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
z = ⟨c, x⟩+ d,
A1xT ≥bT
1,
A2xT = bT
2,
x ∈ℝn
+,
where b1 = (b1, . . . , bμ), b2 = (bμ󸀠, . . . , bm), c = (c1, . . . , cn), x = (x1, . . . , xn), and
A1 = (
a11
⋅⋅⋅
a1n
...
...
...
aμ1
⋅⋅⋅
aμn
) ,
A2 = (
aμ󸀠1
⋅⋅⋅
aμ󸀠n
...
...
...
am1
⋅⋅⋅
amn
) .
Let y = −z. Converting minimization of z to maximization of y and multiplying
the inequalities by −1, and then introducing μ slack variables xn+i (i = 1, . . . , μ),
produces a standard linear optimization model (L∗), satisfying the assumption given
in Section 7.3.2, with equality constraints and n + μ nonnegative variables as follows:

7.3 The simplex method
|
217
(L∗)
max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + c2x2 + ⋅⋅⋅+ cnxn + 0 + 0 + ⋅⋅⋅+ 0 = −d,
−a11x1 −a12x2 −⋅⋅⋅−a1nxn + xn+1 + 0 + 0 + ⋅⋅⋅+ 0 = −b1,
−a21x1 −a22x2 −⋅⋅⋅−a2nxn + 0 + xn+2 + 0 + ⋅⋅⋅+ 0 = −b2,
...
−aμ1x1 −aμ2x2 −⋅⋅⋅−aμnxn + 0 + 0 + ⋅⋅⋅+ 0 + xn+μ = −bμ,
aμ󸀠1x1 + aμ󸀠2x2 + ⋅⋅⋅+ aμ󸀠nxn = bμ󸀠,
...
am1x1 + am2x2 + ⋅⋅⋅+ amnxn = bm,
x1 ≥0, x2 ≥0, . . . , xn ≥0, xn+1 ≥0, . . . , xn+μ ≥0
where cj and bi have any values. Applying the above method, the model (L∗) can
be converted to a standard linear optimization model with equality constraints and
nonnegative variables in basic form.
Example 7.3.4. Solve the following linear optimization model:
(L): min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
z + x1 + 2x2 −2x3 = 0,
x1 −2x2 + 2x3 ≥2,
2x1 −x2 + x3 ≥2,
−2x1 −x2 + x3 ≥4,
x1 ≥0, x2 ≥0, x3 ≥0.
Solution. Let y = −z. Converting minimization to maximization, multiplying the in-
equalities by −1, and then introducing slack variables x4, x5, x6, produces a standard
linear optimization model (L∗) with equality constraints and nonnegative variables as
follows:
(L∗): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y −x1 −2x2 + 2x3 + 0 + 0 + 0 = 0,
−x1 + 2x2 −2x3 + x4 + 0 + 0 = −2,
−2x1 + x2 −x3 + 0 + x5 + 0 = −2,
2x1 + x2 −x3 + 0 + 0 + x6 = −4,
x1 ≥0, x2 ≥0, x3 ≥0, x4 ≥0, x5 ≥0, x6 ≥0.
Looking at the ﬁrst row of (L∗), b1 = −2 < 0 and a11 = −1, a13 = −2. Choose the
column index l = 3 as the column index of the pivot entry. Pivoting on the (1, 3) entry
produces a model (L1) from the model (L∗)

218
|
7 Optimization
(L1): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y −x1 −2x2 + 2x3 + 0 + 0 + 0 = 0,
1
2 x1 −x2 + x3 −1
2 x4 + 0 + 0 = 1,
−3
2 x1 + 0 + 0 −1
2 x4 + x5 + 0 = −1,
5
2 x1 + 0 + 0 −1
2 x4 + 0 + x6 = −3,
x1 ≥0, x2 ≥0, x3 ≥0, x4 ≥0, x5 ≥0, x6 ≥0.
Looking at the ﬁrst row of the model (L1), b1 = 1 > 0. The model (L1) is in Case 1.
So we turn to look at its second row. Since b2 = −1 < 0, a21 = −3
2 < 0, and a24 = −1
2 < 0,
the model (L1) is in Case 3. Choose the column index l = 1. Regard the ﬁrst row as the
only constraint and the second row as the objective row. Only a11 = 1
2 > 0, the chosen
row index is k = 1.
Pivoting on the (1, 1) entry, this produces a model (L2) from (L1)
(L2): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 0 −4x2 + 4x3 −x4 + 0 + 0 = 2,
x1 −2x2 + 2x3 −x4 + 0 + 0 = 2,
0 −3x2 + 3x3 −2x4 + x5 + 0 = 2,
0 + 5x2 −5x3 + 2x4 + 0 + x6 = −8,
x1 ≥0, x2 ≥0, x3 ≥0, x4 ≥0, x5 ≥0, x6 ≥0.
Looking at the second row of the model (L2), b2 = 2 > 0, the model (L2) is in Case 1.
So we turn to look at its third row. Since b3 = −8 < 0 and a33 = −5 < 0, the model (L2)
is in Case 3. The chosen column index is l = 3. Regard the ﬁrst and second rows as the
constraints and the third row as the objective row. Since a13 = 2 > 0 and a23 = 3 > 0,
the model (L2) is in the second alternative of Case 3. From a13 = 2 > 0 and a23 = 3 > 0,
it follows that
bk
akl
= min { b1
a13
, b2
a23
} = min {1, 2
3} = 2
3 = b2
a23
,
and so the chosen row index is k = 2.
Pivoting on the (2, 3) entry produces a model (L3) from (L2)
(L3): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 0 + 0 + 0 + 5
3 x4 −4
3 x5 + 0 = −2
3 ,
x1 + 0 + 0 + 1
3 x4 −2
3 x5 + 0 = 2
3 ,
0 −x2 + x3 −2
3 x4 + 1
3 x5 + 0 = 2
3 ,
0 + 0 + 0 −4
3 x4 + 5
3 x5 + x6 = −14
3 ,
x1 ≥0, x2 ≥0, x3 ≥0, x4 ≥0.

7.3 The simplex method
|
219
Looking at the third row of the model (L3), b3 = −14
3 < 0, a34 = −4
3 < 0, the model
(L3) is in Case 3. So the chosen column index l = 4. Regard the ﬁrst and second rows as
the constraints and the third row as the objective row. Only a14 = 1
3 > 0, so the chosen
row index k = 1.
Pivoting on the (1, 4) entry produces a model (L4) from the model (L3)
(L4): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y −5x1 + 0 + 0 + 0 + 2x5 + 0 = −4,
3x1 + 0 + 0 + x4 −2x5 + 0 = 2,
2x1 −x2 + x3 + 0 −x5 + 0 = 2,
4x1 + 0 + 0 + 0 −x5 + x6 = −2,
x1 ≥0, x2 ≥0, x3 ≥0, x4 ≥0.
Looking at the third row of the model (L4), b3 = −2 < 0 and a35 = −1 < 0, the
model (L4) is in Case 3. The chosen column index l = 5. Regard the ﬁrst and second
rows as the constraints and the third row as the objective row. All a15 = −2 < 0 and
a25 = −1 < 0, so the model (L4) is in the ﬁrst alternative of Case 3, and so the chosen
row index k = 3.
Pivoting on the (3, 5) entry in the objective row produces a model (L5) from the
model (L4)
(L5): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + 3x1 + 0 + 0 + 0 + 0 + 2x6 = −8,
−5x1 + 0 + 0 + x4 + 0 −2x6 = 6,
−2x1 −x2 + x3 + 0 + 0 −x6 = 4,
−4x1 + 0 + 0 + 0 + x5 −x6 = 2,
x1 ≥0, x2 ≥0, x3 ≥0, x4 ≥0,
where b1 = 6, b2 = 4, b3 = 2. So the model (L5) is in basic form.
Note that
c1 = 3,
c2 = c3 = c4 = c5 = 0,
c6 = 2.
The model (L5) is in Case 1 of the simplex algorithm, and basic variables of the model
(L5) are x3, x4, x5 and nonbasic variables are x1, x2, x6. Let nonbasic variables x1 =
x2 = x6 = 0. Then x3 = 4, x4 = 6, x5 = 2. So the basic solution of the model (L5)
x1 = 0,
x2 = 0,
x3 = 4,
x4 = 6,
x5 = 2,
x6 = 0
is the optimal solution of the model (L∗) and the corresponding value of objective
function is y(00) = −8. Note that min z = −max y. Then min z = 8.

220
|
7 Optimization
Type 4
The model is a general linear optimization model with ν nonnegative variables and
n −ν free variables subject to μ inequality constraints and m −μ equality constraints
as follows:
(L): min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
z = c1x1 + ⋅⋅⋅+ cνxν + cν󸀠xν󸀠+ ⋅⋅⋅+ cnxn + d,
a11x1 + ⋅⋅⋅+ a1νxν + a1ν󸀠xν󸀠+ ⋅⋅⋅+ a1nxn ≥b1,
...
aμ1x1 + ⋅⋅⋅+ aμνxν + aμν󸀠xν󸀠+ ⋅⋅⋅+ aμnxn ≥bμ,
aμ󸀠1x1 + ⋅⋅⋅+ aμ󸀠νxν + aμ󸀠ν󸀠xν󸀠+ ⋅⋅⋅+ aμ󸀠nxn = bμ󸀠,
...
am1x1 + ⋅⋅⋅+ amνxν + aμ󸀠ν󸀠xν󸀠+ ⋅⋅⋅+ amnxn = bm,
x1 ≥0, . . . , xν ≥0,
xν󸀠free, . . . , xn free,
where cj and bi have any values and μ󸀠= μ + 1 and ν󸀠= ν + 1. Its matrix form is
(L): min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
z = ⟨c, x⟩+ d,
A1xT ≥bT
1,
A2xT = bT
2,
x ∈ℝν
+ × ℝn−ν,
where b1 = (b1, . . . , bμ), b2 = (bμ󸀠, . . . , bm), c = (c1, . . . , cn), x = (x1, . . . , xn), d ∈ℝ,
and
A1 = (
a11
⋅⋅⋅
a1n
...
...
...
aμ1
⋅⋅⋅
aμn
) ,
A2 = (
aμ󸀠1
⋅⋅⋅
aμ󸀠n
...
...
...
am1
⋅⋅⋅
amn
) .
For each free variable xj (j = ν󸀠, . . . , n), let
x+
j = xj,
x−
j = 0
if xj ≥0,
x+
j = 0,
x−
j = −xj
if xj ≤0.
Then x+
j and x−
j are nonnegative and xj = x+
j −x−
j (j = ν󸀠, . . . , n).
Let y = −z. Converting minimization of z to maximization of y and multiplying the
inequalities by −1, substituting xj (j = ν󸀠, . . . , n) by the difference of two nonnegative
variable, xn = x+
n −x−
n, where x+
n ≥0 and x−
n ≥0, and then introducing μ slack vari-
ables xn+i (i = 1, . . . , μ), produces a standard linear optimization model, satisfying

7.3 The simplex method
|
221
the assumption condition given in Section 7.3.2, with 2n −ν + μ nonnegative variables
subject to m equality constraints as follows:
(L∗)
max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y + c1x1 + ⋅⋅⋅+ cνxν + cν󸀠x+
ν󸀠−cν󸀠x−
ν󸀠+ ⋅⋅⋅+ cnx+
n −cnx−
n + 0 + 0 + ⋅⋅⋅+ 0 = −d,
−a11x1 −⋅⋅⋅−a1νxν −a1ν󸀠x+
ν󸀠+ a1ν󸀠x−
ν󸀠−⋅⋅⋅−a1nx+
n + a1nx−
n + xn+1 + 0 + ⋅⋅⋅+ 0 = −b1,
...
−aμ1x1 −⋅⋅⋅−aμνxν −aμν󸀠x+
ν󸀠+ aμν󸀠x−
ν󸀠−⋅⋅⋅−aμnx+
n + aμnx−
n + 0 + ⋅⋅⋅+ 0 + xn+μ = −bμ,
aμ󸀠1x1 + ⋅⋅⋅+ aμ󸀠νxν + aμ󸀠ν󸀠x+
ν󸀠−aμ󸀠ν󸀠x−
ν󸀠+ ⋅⋅⋅+ aμ󸀠nx+
n −aμ󸀠nx−
n = bμ󸀠,
...
am1x1 + ⋅⋅⋅+ amνxν + amν󸀠x+
ν󸀠−amν󸀠x−
ν󸀠+ ⋅⋅⋅+ amnx+
n −amnx−
n = bm,
x1 ≥0, . . . , xν ≥0, x+
ν󸀠≥0, x−
ν󸀠≥0, . . . , x+
n ≥0, x−
n ≥0, xn+1 ≥0, . . . , xn+μ ≥0,
where cj and bi have any values, and μ󸀠= μ + 1 and ν󸀠= ν + 1. Applying the ap-
proach of Type 3, this produces a standard linear optimization model with equality
constraints and nonnegative variables in basic form.
Example 7.3.5. Reduce the following linear optimization model:
(L): min z
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
z = −3x1 + x2 + x3,
−4x1 + x2 + 2x3 ≤3,
x1 −2x2 + x3 ≤11,
−2x1 + 2x3 = 1,
x1 ≥0, x2 ≥0, x3 free
to a standard linear optimization model with equality constraints and nonnegative
variables.
Solution. Let y = −z. Converting minimization to maximization and substituting the
variable x3 by x+
3 −x−
3, where x+
3 ≥0 and x−
3 ≥0, and then introducing two slack
variables x4, x5, produces a standard linear optimization model with three equality
constraints and six nonnegative variables as follows:
(L∗): max y
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y −3x1 + x2 + x+
3 −x−
3 + 0 + 0 = 0,
−4x1 + x2 + 2x+
3 −2x−
3 + x4 + 0 = 3,
x1 −2x2 + x+
3 −x−
3 + 0 + x5 = 11,
−2x1 + 0 + 2x+
3 −2x−
3 + 0 + 0 = 1,
x1 ≥0, x2 ≥0, x+
3 ≥0, x−
3 ≥0, x4 ≥0, x5 ≥0.
The model (L∗) is the desired model.

222
|
7 Optimization
7.4 Fermat rules
Let f : ℝ→ℝbe a function deﬁned on ℝand with values on ℝ. If f(x∗) ≤f(x) for all
x ∈[x∗−ε, x∗+ ε] (ε > 0), then we say x∗minimizes f on the interval [x∗−ε, x∗+ ε].
Fermat rule I
Let f : ℝ→ℝbe a smooth function. If x∗minimizes f on the interval [x∗−ε, x∗+ ε]
(ε > 0), then f 󸀠(x∗) = 0.
The meaning of Fermat rule I is that the tangent to the graph of the smooth func-
tion f at the point (x∗, f(x∗)) is parallel to the real axis.
Now let f : ℝn →ℝbe a function deﬁned on ℝn and with values on ℝ. If f(x∗) ≤
f(x) for all x ∈B(x∗, ε), where B(x∗, ε) is a closed ball of radius ε > 0 centered at
x∗∈ℝn, then we say x∗minimizes f on B(x∗, ε). Relying on this concept, Fermat
rule I is extended to functions deﬁned on the n-dimensional space ℝn.
Fermat rule II
Let f : ℝn →ℝbe a smooth function. If x∗minimizes f on B(x∗, ε) (ε > 0), then
∇f(x∗) = ( ∂f(x∗)
∂x1
, . . . , ∂f(x∗)
∂xn
) = 0,
i.e., the gradient of f(x) at x∗is equal to zero, where x = (x1, . . . , xn) and x∗=
(x∗
1, . . . , x∗
n).
The extension of Fermat rule to convex functions needs the following concepts.
Let X be a subset of ℝn. If, for any x1, x2 ∈X, the line segment [x1, x2] ⊂X, i.e.,
xτ = (1 −τ)x1 + τx2 ∈X
(0 ≤τ ≤1),
then the set X is said to be a convex set of ℝn. It is clear by the deﬁnition of convex
sets that
(a) a set consisting of a single point is a convex set;
(b) the empty set is a convex set;
(c) if X ⊂ℝn is a convex set, then the set S = {ax + b | x ∈X, a, b ∈ℝ} is a convex set.
Convex cones are a particularly important subclass of convex sets. For example, {0},
ℝn
+ = [0, ∞)n, ℝn, and closed half-spaces are all convex cones.
Let f : ℝn →ℝand X ⊂ℝn be a convex set. If, for any x1, x2 ∈X,
f ((1 −τ)x1 + τx2) ≤(1 −τ)f(x1) + τf(x2)
(0 ≤τ ≤1),
then f is said to be a convex function on X. If, for any x1, x2 ∈X,
f ((1 −τ)x1 + τx2) < (1 −τ)f(x1) + τf(x2)
(0 ≤τ ≤1),

7.4 Fermat rules
|
223
then f is said to be a strictly convex function on X. If f is a convex function on X, then
g = −f is said to be a concave function on X. Clearly, the linear function f(x) = ⟨a, x⟩
is both a convex function and a concave function.
The subderivative and the set of subgradients of convex functions are two funda-
mental concepts of subdifferential calculus. They are deﬁned as follows.
Deﬁnition 7.4.1. Let f : ℝn →ℝbe convex and its effective domain be dom f = {x ∈
ℝn | f(x) < ∞}. The subderivative of f at x∗∈dom f in direction w is deﬁned as
∂+f(x∗)
∂w
= lim
λ→0+
f(x∗+ λw) −f(x∗)
λ
for any w ∈ℝn.
The set of subgradients of f at x∗∈dom f is deﬁned as
∂f(x∗) = { y ∈ℝn | f(x) ≥f(x∗) + ⟨y, x −x∗⟩for any x ∈ℝn } .
(7.4.1)
The set of subgradients depends on the subderivatives. If we set x −x∗= λw (λ > 0)
in (7.4.1), then the inequality f(x) ≥f(x∗) + ⟨y, x −x∗⟩is equivalent to
f(x∗+ λw) −f(x∗)
λ
≥⟨y, w⟩.
Since f is convex, the ratio on the left-hand side is monotonically nonincreasing, and
tends to ∂+f(x∗)
∂w
(λ →0+). Let λ →0+ on both sides of the above inequality. Then
∂+f(x∗)
∂w
≥⟨y, w⟩.
So (7.4.1) has an equivalent form as follows:
∂f(x∗) = { y ∈ℝ| ∂+f(x∗)
∂w
≥⟨y, w⟩for any w ∈ℝn } .
(7.4.2)
From this, it is seen that the set of subgradients depends on the subderivatives.
The Fermat rule for convex functions deﬁned on ℝn is as follows.
Fermat rule III
Let f : ℝn →ℝbe a convex function. Then x∗∈ℝn minimizes f on B(x∗, ε) (ε > 0) if
and only if 0 ∈∂f(x∗).
Proof. By the deﬁnition, x∗minimizes f on B(x∗, ε) if and only if f(x) ≥f(x∗) for
any x ∈B(x∗, ε). Let x = x∗+ λw, where w ∈ℝn and λ > 0. Then f(x) ≥f(x∗) for any
x ∈B(x∗, ε) if and only if f(x∗+ λw) ≥f(x∗) + λ⟨0, w⟩. By Deﬁnition 7.4.1, f(x∗+ λw) ≥
f(x∗) + λ⟨0, w⟩if and only if ∂+f(x∗)
∂w
≥⟨0, w⟩(w ∈ℝn). Finally, by (7.4.2), it follows that
∂+f(x∗)
∂w
≥⟨0, w⟩(w ∈ℝn) if and only if 0 ∈∂f(x∗).
In order to vary Fermat rule III, the following two concepts are required.

224
|
7 Optimization
Deﬁnition 7.4.2. Let Ωbe a set and
iΩ(x) =
{
{
{
0
if x ∈Ω,
∞
otherwise.
Then iΩ(x) is said to be the indicator function of the set Ω.
It is clear by Deﬁnition 7.4.2 that the indicator function iΩ(x) is convex if and only if
the set Ωis convex.
Deﬁnition 7.4.3. Let Ω⊂ℝn be a nonempty closed convex set and x∗∈Ω. If ⟨υ, x −
x∗⟩≤0, where υ ∈ℝn and for all x ∈Ω, then the vector υ is said to be normal to Ωat
x∗, denoted by υ ∈NΩ(x∗), where NΩ(x∗) is said to be the normal cone to Ωat x∗.
Assume that Ω⊂ℝn is a nonempty closed convex set and x∗∈Ω. Then the set of
subgradients of the indicator function of Ωis just the normal cone to Ω, i.e.,
∂iΩ(x∗) = NΩ(x∗).
(7.4.3)
In fact, from Deﬁnition 7.4.3, it follows that
NΩ(x∗) = ⋂
x∈Ω
{ υ ∈ℝn | ⟨υ, x −x∗⟩≤0 },
(7.4.4)
i.e., NΩ(x∗) is the intersection of closed half-spaces. Since x∗∈Ωand x ∈Ω, it is clear
by Deﬁnition 7.4.2 that
iΩ(x∗) = 0,
iΩ(x) = 0.
From this and (7.4.1), the set of subgradients of iΩ(x) (x ∈Ω) at x∗is
∂iΩ(x∗) = { υ ∈ℝn | iΩ(x) ≥iΩ(x∗) + ⟨υ, x −x∗⟩for any x ∈Ω}
= { υ ∈ℝn | ⟨υ, x −x∗⟩≤0 for any x ∈Ω}
= ⋂
x∈Ω
{ υ ∈ℝn | ⟨υ, x −x∗⟩≤0 }.
The combination of this and (7.4.4) gives (7.4.3).
The following rule is a variant of Fermat rule III.
Fermat rule IV
Let f : ℝn →ℝbe a convex function and Ω⊂ℝn be a nonempty closed convex set.
Then x∗minimizes f(x) on Ωif and only if 0 ∈(∂f(x∗) + NΩ(x∗)), and this is further
equivalent to that there is a υ ∈∂f(x∗) such that −υ ∈NΩ(x∗).

7.5 Karush–Kuhn–Tucker optimality conditions
|
225
Proof. By Deﬁnition 7.4.2, iΩ(x) is constant. Since x∗minimizes f(x) on Ω, it also
minimizes f(x) + iΩ(x) on Ω. By Fermat rule III, x∗minimizes f(x) + iΩ(x) on Ωif
and only if 0 ∈∂(f + iΩ)(x∗). By Deﬁnition 7.4.1 and (7.4.3), it follows that
∂(f + iΩ)(x∗) = ∂f(x∗) + ∂iΩ(x∗) = ∂f(x∗) + NΩ(x∗).
Therefore, x∗minimizes f(x) on Ωif and only if 0 ∈(∂f(x∗) + NΩ(x∗)), and this is
further equivalent to that there is a υ ∈∂f(x∗) such that −υ ∈NΩ(x∗).
An application of Fermat rules is to solve the nonnegative constrained convex opti-
mization model
(Lnc): min
x
f(x)
subject to x ∈ℝn
+,
where the function f : ℝn →ℝis convex and ℝn
+ = [0, ∞)n is the n-dimensional non-
negative orthant. The following result is given.
Let x∗= (x∗
1, . . . , x∗
n) ∈ℝn
+. Then x∗is an optimal solution of the model (Lnc) if
and only if there is a υ ∈∂f(x∗) such that
υi ≥0
(i = 1, . . . , n),
υix∗
i = 0
(i = 1, . . . , n),
where υ = (υ1, . . . , υn).
In fact, according to Fermat rule IV, x∗is an optimal solution of the model (Lnc)
if and only if there is a υ ∈∂f(x∗) such that −υ ∈Nℝn
+(x∗).
However, −υ ∈Nℝn
+(x∗) if and only if −υi ∈Nℝ+(x∗
i ) (i = 1, . . . , n), where
υ = (υ1, . . . , υn),
x∗= (x∗
1, . . . , x∗
n),
ℝn
+ = [0, ∞)n,
ℝ+ = [0, ∞).
By Deﬁnition 7.4.3, a direct computation shows that for i = 1, . . . , n,
Nℝ+(x∗
i ) =
{
{
{
ℝ−
if x∗
i = 0,
0
if 0 < x∗
i < ∞,
where ℝ−= (−∞, 0). So −υi ∈Nℝ+(x∗
i ) (i = 1, . . . , n) if and only if υi ≥0 and υix∗
i = 0
(i = 1, . . . , n). Therefore, x∗is an optimal solution of the model (Lnc) if and only if
there is a υ ∈∂f(x∗) such that
υi ≥0
(i = 1, . . . , n),
υix∗
i = 0
(i = 1, . . . , n).
7.5 Karush–Kuhn–Tucker optimality conditions
Karush–Kuhn–Tucker (KKT) conditions are the optimality conditions for solving the
optimization models. These conditions are related to KKT multipliers. In order to give
the KKT conditions, we ﬁrst introduce some propositions.

226
|
7 Optimization
Proposition 7.5.1. Let Ωbe a hyperplane and
Ω= { x ∈ℝn | ⟨a, x⟩= b }
(0
̸= a ∈ℝn, b ∈ℝ).
Then, for x∗∈Ω, the vector −υ ∈NΩ(x∗) if and only if there is a λ∗∈ℝsuch that
υ = λ∗a.
Proof. Let U = Ω−x∗. For each x ∈U, there is a x󸀠∈Ωsuch that x = x󸀠−x∗. Note
that
⟨a, x󸀠⟩= b
(x󸀠∈Ω),
⟨a, x∗⟩= b
(x∗∈Ω).
It follows that for each x ∈U,
⟨a, x⟩= ⟨a, x󸀠−x∗⟩= ⟨a, x󸀠⟩−⟨a, x∗⟩= 0.
So U = { x | ⟨a, x⟩= 0 }.
Let V = { λa | λ ∈ℝ}. For any x ∈U and any λa ∈V, ⟨λa, x⟩= λ⟨a, x⟩= 0.
So U ⊥V.
Now we prove that NΩ(x∗) = V.
If υ ∈V, then υ = λa. For all x ∈Ω,
⟨υ, x −x∗⟩= ⟨λa, x −x∗⟩= λ(⟨a, x⟩−⟨a, x∗⟩) = λ(b −b) = 0.
By Deﬁnition 7.4.3, it follows that υ ∈NΩ(x∗). So V ⊂NΩ(x∗).
Conversely, if υ ∈NΩ(x∗), then υ ∈V.
If υ
̸∈V, since U ⊥V, υ = λa + ̂υ for some λ ∈ℝand 0
̸=
̂υ ∈U. On the one hand,
since
̂υ
̸= 0,
⟨̂υ, ̂υ⟩> 0.
(7.5.1)
On the other hand, since
̂υ ∈U, there is a
̂x ∈Ωsuch that
̂υ =
̂x −x∗. Again, by the
assumption υ ∈NΩ(x∗), it follows by Deﬁnition 7.4.3 that
⟨υ, ̂x −x∗⟩≤0.
(7.5.2)
The left-hand side of (7.5.2) becomes
⟨υ, ̂x −x∗⟩= ⟨λa +
̂υ, ̂x −x∗⟩
= λ(⟨a, ̂x⟩−⟨a, x∗⟩) + ⟨̂υ, ̂x −x∗⟩
= λ(b −b) + ⟨̂υ, ̂x −x∗⟩
= ⟨̂υ, ̂υ⟩,
and so ⟨̂υ, ̂υ⟩≤0. This is in contradiction with (7.5.1). Thus, υ ∈V. So NΩ(x∗) ⊂V.
Hence NΩ(x∗) = V. This implies that −υ ∈NΩ(x∗) if and only if −υ ∈V. Note that
V = {λa | λ ∈ℝ}. Then, −υ ∈V if and only if there is a λ∗∈ℝsuch that υ = λ∗a. So
Proposition 7.5.1 follows.

7.5 Karush–Kuhn–Tucker optimality conditions
|
227
Proposition 7.5.2. Let Ωbe a closed half-space and
Ω= { x ∈ℝn | ⟨a, x⟩≥b }
(0
̸= a ∈ℝn, b ∈ℝ).
Then, for x∗∈Ω, the vector −υ ∈NΩ(x∗) if and only if there is a λ∗≥0 such that
λ∗(⟨a, x∗⟩−b) = 0,
υ = λ∗a.
Proof. There are two cases.
Case 1. ⟨a, x∗⟩> b. Then x∗is an interior point of Ω. So NΩ(x∗) = { 0 }. The con-
clusion holds clearly.
Case 2. ⟨a, x∗⟩= b. Let
Ω1 = { x ∈ℝn | ⟨a, x⟩> b },
Ω2 = { x ∈ℝn | ⟨a, x⟩= b },
where 0
̸= a ∈ℝn and b ∈ℝ. Then Ω= Ω1 ⋃Ω2 and x∗∈Ω2.
Let U = Ω2 −x∗. A similar argument of Proposition 7.5.1 implies that
U = { x ∈ℝn | ⟨a, x⟩= 0 }.
Let V = { λa | λ ≤0 }. For any x ∈U and any λa ∈V, ⟨λa, x⟩= λ⟨a, x⟩= 0. So U ⊥V.
Now we prove NΩ(x∗) = V.
First, we prove that if υ ∈NΩ(x∗), then υ ∈V.
If υ ∉V, since U ⊥V, υ = λa + ̂υ for some λ ≤0 and 0
̸=
̂υ ∈U. On the one hand,
since
̂υ
̸= 0,
⟨̂υ, ̂υ⟩> 0.
(7.5.3)
On the other hand, since
̂υ ∈U, there is an
̂x ∈Ω2 such that
̂υ =
̂x −x∗. Since
Ω= Ω1 ⋃Ω2, clearly,
̂x ∈Ω. Again, by the assumption that υ ∈NΩ(x∗), it follows
by Deﬁnition 7.4.3 that
⟨υ, ̂x −x∗⟩≤0.
(7.5.4)
Since υ = λa +
̂υ, where
̂υ =
̂x −x∗and
̂x ∈Ω2, the left-hand side of (7.5.4) becomes
⟨υ, ̂x −x∗⟩= ⟨λa +
̂υ, ̂x −x∗⟩
= λ(⟨a, ̂x⟩−⟨a, x∗⟩) + ⟨̂υ, ̂x −x∗⟩
= λ(b −b) + ⟨̂υ, ̂υ⟩
= ⟨̂υ, ̂υ⟩,
and so ⟨̂υ, ̂υ⟩≤0. This is in contradiction with (7.5.3). Thus, υ ∈V. So NΩ(x∗) ⊂V.
Next, we prove V ⊂NΩ(x∗).
Let υ ∈V. Then υ = λa, where λ ≤0. Note that x∗∈Ω2. For all x ∈Ω,
⟨υ, x −x∗⟩= ⟨λa, x −x∗⟩= λ(⟨a, x⟩−⟨a, x∗⟩) = λ(⟨a, x⟩−b) ≤0.
By Deﬁnition 7.4.3, υ ∈NΩ(x∗). So V ⊂NΩ(x∗).

228
|
7 Optimization
Hence V = NΩ(x∗). This implies that −υ ∈NΩ(x∗) if and only if −υ ∈V. Note that
V = { λa | λ ≤0 }. Then, −υ ∈V if and only if there is a λ∗≥0 such that υ = λ∗a and
λ∗(⟨a, x∗⟩−b) = 0 since the assumption in Case 2 is ⟨a, x∗⟩= b. So Proposition 7.5.2
follows.
Propositions 7.5.1 and 7.5.2 can be generalized as follows.
Proposition 7.5.3. Let Ωbe a nonempty polyhedral set and
Ω= { x ∈ℝn | ⟨ai, x⟩≥bi (i = 1, . . . , s), ⟨ai, x⟩= bi (i = s + 1, . . . , m) } ,
where 0
̸= ai ∈ℝn and bi ∈ℝ. Then for x∗∈Ω, the vector −υ ∈NΩ(x∗) if and only if
there are λ∗
i ≥0 (i = 1, . . . , s) and λ∗
i ∈ℝ(i = s + 1, . . . , m) such that
λ∗
i (⟨ai, x∗⟩−bi) = 0
(i = 1, . . . , s),
υ = λ∗
1a1 + ⋅⋅⋅+ λ∗
s as + λ∗
s+1as+1 + ⋅⋅⋅+ λ∗
mam.
Proof. Let
Ωi
1 = { x ∈ℝn | ⟨ai, x⟩≥bi }
(i = 1, . . . , s),
Ωi
2 = { x ∈ℝn | ⟨ai, x⟩= bi }
(i = s + 1, . . . , m).
and
Ω1 =
s
⋂
1
Ωi
1,
Ω2 =
m
⋂
s+1
Ωi
2.
Then both Ω1 and Ω2 are polyhedral sets. Let Ω= Ω1 ⋂Ω2. Then Ωis also a polyhe-
dral set. It is well known that the normal cones of polyhedral sets have the following
property:
NΩ(x∗) = NΩ1(x∗) + NΩ2(x∗) = NΩ1
1(x∗) + ⋅⋅⋅+ NΩs
1(x∗) + NΩs+1
2 (x∗) + ⋅⋅⋅+ NΩm
2 (x∗).
So −υ ∈NΩ(x∗) if and only if there exist υi
1 (i = 1, . . . , s) and υi
2 (i = s + 1, . . . , m)
such that
−υi
1 ∈NΩi
1(x∗)
(i = 1, . . . , s),
−υi
2 ∈NΩi
2(x∗)
(i = s + 1, . . . , m),
where υ = υ1
1 + ⋅⋅⋅+ υs
1 + υs+1
2
+ ⋅⋅⋅+ υm
2 .
By Proposition 7.5.2, −υi
1 ∈NΩi
1(x∗) (i = 1, . . . , s) if and only if there is a λ∗
i ≥0
(i = 1, . . . , s) such that
λ∗
i (⟨ai, x∗⟩−b) = 0
(i = 1, . . . , s),
υi
1 = λ∗
i ai
(i = 1, . . . , s).
By Proposition 7.5.1, −υi
2 ∈NΩi
2(x∗) (i = s + 1, . . . , m) if and only if there is a λ∗
i ∈ℝ(i =
s + 1, . . . , m) such that
υi
2 = λ∗
i ai
(i = s + 1, . . . , m).

7.5 Karush–Kuhn–Tucker optimality conditions
|
229
Therefore, −υ ∈NΩ(x∗) if and only if there are λ∗
i ≥0 (i = 1, . . . , s) and λ∗
i ∈ℝ(i =
s + 1, . . . , m) such that
λ∗
i (⟨ai, x∗⟩−b) = 0
(i = 1, . . . , s),
υ = λ∗
1a1 + ⋅⋅⋅+ λ∗
s as + λ∗
s+1as+1 + ⋅⋅⋅+ λ∗
mam.
Now we solve the convex optimization models by Propositions 7.5.1, 7.5.2, and 7.5.3.
The simplest convex optimization model with an equality constraint is the form
(Lce): min
x
f(x)
subject to
⟨a, x⟩= b,
where f : ℝn →ℝis convex and 0
̸= a ∈ℝn, x ∈ℝn, b ∈ℝ. Its feasible set is
Ωce = { x ∈ℝn | ⟨a, x⟩= b }.
Theorem 7.5.4. x∗∈Ωce is the optimal solution of the model (Lce) if and only if there
is a λ∗∈ℝsuch that λ∗a ∈∂f(x∗), where ⟨a, x∗⟩= b.
Proof. It is seen that the feasible set Ωce is a hyperplane and x∗minimizes f on Ωce,
where ⟨a, x∗⟩= b. Fermat rule IV shows that x∗minimizes f on Ωce if and only if
there is a υ ∈∂f(x∗) such that −υ ∈NΩce(x∗). Proposition 7.5.1 shows that when the
feasible set Ωce is a hyperplane, −υ ∈NΩce(x∗) if and only if there is a λ∗∈ℝsuch that
υ = λ∗a. Note that υ ∈∂f(x∗). Therefore, x∗∈Ωce is the optimal solution of the model
(Lce) if and only if there is a λ∗∈ℝsuch that λ∗a ∈∂f(x∗), where ⟨a, x∗⟩= b.
The simplest convex optimization model with an inequality constraint is the form
(Lci): min
x
f(x)
subject to
⟨a, x⟩≥b,
where f : ℝn →ℝis convex and 0
̸= a ∈ℝn, x ∈ℝn, b ∈ℝ. Its feasible set is
Ωci = { x ∈ℝn | ⟨a, x⟩≥b }.
Theorem 7.5.5. x∗∈Ωci is the optimal solution of the model (Lci) if and only if there is
a λ∗≥0 such that λ∗a ∈∂f(x∗) and λ∗(⟨a, x∗⟩−b) = 0, where ⟨a, x∗⟩≥b.
Proof. It is seen that the feasible set Ωci is a half-space and x∗minimizes f on Ωci,
where ⟨a, x∗⟩≥b. Fermat rule IV says that x∗minimizes f on Ωci if and only if there
is a υ ∈∂f(x∗) such that −υ ∈NΩci(x∗). Proposition 7.5.2 says that when the feasible
set Ωci is a half-space, −υ ∈NΩci(x∗) if and only if there is a λ∗≥0 such that
λ∗(⟨a, x∗⟩−b) = 0,
υ = λ∗a.
From this and υ ∈∂f(x∗), it follows that x∗is the optimal solution of the model (Lci)
if and only if there is a λ∗≥0 such that λ∗(⟨a, x∗⟩−b) = 0 and λ∗a ∈∂f(x∗).

230
|
7 Optimization
The linearly constrained convex optimization model is the form
(Llc): min
x
f(x)
subject to
inequality constraints:
⟨ai, x⟩≥bi
(i = 1, . . . , s),
and equality constraints:
⟨ai, x⟩= bi
(i = s + 1, . . . , m),
and the restriction:
x ∈X ⊂ℝn,
where f : ℝn →ℝis convex and X is a polyhedral set, and ai, x ∈ℝn, bi ∈ℝ(i =
1, . . . , m). Let
Xlc = { x ∈ℝn | ⟨ai, x⟩≥bi (i = 1, . . . , s); ⟨ai, x⟩= bi (i = s + 1, . . . , m) }.
Its feasible set is
Ωlc = Xlc ⋂X.
Both X and Xlc are polyhedral sets, so is Ωlc. The assumption that the function
f : ℝn →ℝis convex and the set X is a polyhedral set is called the blanket assump-
tion. The convex property of the function ensures that the function is continuous.
Theorem 7.5.6. x∗∈Ωlc is the optimal solution of the model (Llc) if and only if the
following three conditions hold:
(a) ⟨ai, x∗⟩≥bi (i = 1, . . . , s) and ⟨ai, x∗⟩= bi (i = s + 1, . . . , m);
(b) there are m multipliers λ∗
1, . . . , λ∗
m such that
λ∗
i ≥0
(i = 1, . . . , s),
λ∗
i ∈ℝ
(i = s + 1, . . . , m),
λ∗
i (⟨ai, x∗⟩−bi) = 0
(i = 1, . . . , s);
(c) x∗minimizes f(x) + ⟨λ∗
1a1 + ⋅⋅⋅+ λ∗
mam, x⟩on X.
Here (c) is equivalent to that there is a υ ∈∂f(x∗) such that −(υ + λ∗
1a1 + ⋅⋅⋅+ λ∗
mam) ∈
NX(x∗).
The multipliers λ∗
1, . . . , λ∗
m in Theorem 7.5.6 are called KKT multipliers of the lin-
early constrained convex optimization model. The conditions (a)–(c) in Theorem 7.5.6
are called KKT-optimality conditions of the linearly constrained convex optimization
model.
Proof. By x∗∈Ωlc, it is clear that
⟨ai, x∗⟩≥bi
(i = 1, . . . , s),
⟨ai, x∗⟩= bi
(i = s + 1, . . . , m).
By Fermat rule IV, x∗minimizes f on Ωlc if and only if 0 ∈(∂f(x∗) + NΩlc(x∗)). Note
that
Ωlc = Xlc ⋂X.

7.5 Karush–Kuhn–Tucker optimality conditions
|
231
It is well known that normal cones of polyhedral sets have the following property:
NΩlc(x∗) = NXlc(x∗) + NX(x∗).
So 0 ∈(∂f(x∗) + NΩlc(x∗)) if and only if
0 ∈(∂f(x∗) + NXlc(x∗) + NX(x∗)) .
(7.5.5)
By Fermat rule IV, this is further equivalent to that there is a υ ∈(∂f(x∗) + NX(x∗))
such that −υ ∈NXlc(x∗). By Proposition 7.5.3, −υ ∈NXlc(x∗) if and only if there are
λ∗
i ≥0 (i = 1, . . . , s) and λ∗
i ∈ℝ(i = s + 1, . . . , m) such that
λ∗
i (⟨ai, x∗⟩−bi) = 0
(i = 1, . . . , s),
υ = λ∗
1a1 + ⋅⋅⋅+ λ∗
mam.
Note that υ ∈(∂f(x∗) + NX(x∗)). Then (λ∗
1a1 + ⋅⋅⋅+ λ∗
mam) ∈(∂f(x∗) + NX(x∗)) or
0 ∈(∂f(x∗) + NX(x∗) −λ∗
1a1 −⋅⋅⋅−λ∗
mam).
(7.5.6)
Note that ∂⟨λ∗
i ai, x∗⟩= λ∗
i ai (i = 1, . . . , m). Then 0 ∈(∂f(x∗) + NX(x∗) −∂⟨λ∗
1a1 +
⋅⋅⋅+ λ∗
mam, x∗⟩) or
0 ∈(∂[ f(x∗) −⟨λ∗
1a1 + ⋅⋅⋅+ λ∗
mam, x∗⟩] + NX(x∗)) .
(7.5.7)
By Fermat rule IV, (7.5.7) holds if and only if x∗minimizes f(x) −⟨λ∗
1a1 + ⋅⋅⋅+ λ∗
mam, x⟩
on X, and (7.5.6) holds if and only if there is υ ∈∂f(x∗) such that (−υ + λ∗
1a1 + ⋅⋅⋅+
λ∗
mam) ∈NX(x∗).
In the linearly constrained convex optimization model, if X = ℝr
+ × ℝn−r, the cor-
responding optimization model is called a linearly nonnegative constrained convex
optimization model. Again, if f(x) = ⟨c, x⟩, where c is an n-dimensional constant vec-
tor, the corresponding optimization model is a linear optimization model. For these
two models, two corollaries of Theorem 7.5.6 are given as follows.
Corollary 7.5.7. Let X = ℝr
+ × ℝn−r. Then x∗∈Ωlc is an optimal solution of the linearly
nonnegative constrained convex optimization model if and only if the following KKT-
optimality conditions (a)–(d) hold:
(a) x∗
j ≥0 (j = 1, . . . , r) and x∗
j ∈ℝ(j = r + 1, . . . , n), where x∗= (x∗
1, . . . , x∗
n);
(b) ⟨ai, x∗⟩≥bi (i = 1, . . . , s) and ⟨ai, x∗⟩= bi (i = s + 1, . . . , m), where ai =
(ai1, . . . , ain);
(c) there are m KKT multipliers λ∗
1, . . . , λ∗
m such that
λ∗
i ≥0
(i = 1, . . . , s),
λ∗
i ∈ℝ
(i = s + 1, . . . , m),
λ∗
i (⟨ai, x∗⟩−bi) = 0
(i = 1, . . . , s);

232
|
7 Optimization
(d) there is a υ ∈∂f(x∗) such that
υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj ≥0
(j = 1, . . . , r),
(υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj) x∗
j = 0
(j = 1, . . . , r),
υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj = 0
(j = r + 1, . . . , n),
where υ = (υ1, . . . , υn).
Proof. Theorem 7.5.6 gives that x∗∈Ωlc is the optimal solution of the model (Llc) if
and only if the following KKT-optimality conditions (a)–(c) hold:
(a) ⟨ai, x∗⟩≥bi (i = 1, . . . , s) and ⟨ai, x∗⟩= bi (i = s + 1, . . . , m);
(b) there are m KKT multipliers λ∗
1, . . . , λ∗
m such that
λ∗
i ≥0
(i = 1, . . . , s),
λ∗
i ∈ℝ
(i = s + 1, . . . , m),
λ∗
i (⟨ai, x∗⟩−bi) = 0
(i = 1, . . . , s);
(c) there is a υ ∈∂f(x∗) such that (−υ + λ∗
1a1 + ⋅⋅⋅+ λ∗
mam) ∈Nℝr
+×ℝn−r(x∗).
Let υ = (υ1, . . . , υn) and ai = (ai1, . . . , ain) (i = 1, . . . , m) in the KKT-optimality
condition (c). Then
(−υ + λ∗
1a1 + ⋅⋅⋅+ λ∗
mam) ∈Nℝr
+×ℝn−r(x∗)
if and only if
(−υj + λ∗
1a1j + ⋅⋅⋅+ λ∗
mamj) ∈Nℝ+(x∗
j )
(j = 1, . . . , r),
(−υj + λ∗
1a1j + ⋅⋅⋅+ λ∗
mamj) ∈Nℝ(x∗
j )
(j = r + 1, . . . , n).
(7.5.8)
By Deﬁnition 7.4.3, for j = 1, . . . , r,
Nℝ+(x∗
j ) =
{
{
{
ℝ−
if x∗
j = 0,
0
if 0 < x∗
j < ∞,
where ℝ+ = [0, ∞) and ℝ−= (−∞, 0), and for j = r + 1, . . . , n,
Nℝ(x∗
j ) = { 0 }.
From this and (7.5.8), it is seen that the following (a) and (b) hold:
(−υj + λ∗
1a1j + ⋅⋅⋅+ λ∗
mamj) ∈Nℝ+(x∗
j )
(j = 1, . . . , r)
(a)
if and only if
υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj ≥0
(j = 1, . . . , r),
(υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj) x∗
j = 0
(j = 1, . . . , r);

7.6 Primal and dual pairs of linear optimization
|
233
(−υj + λ∗
1a1j + ⋅⋅⋅+ λ∗
mamj) ∈Nℝ(x∗
j )
(j = r + 1, . . . , n)
(b)
if and only if
υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj = 0
(j = r + 1, . . . , n).
Therefore (−υ + λ∗
1a1 + ⋅⋅⋅+ λ∗
mam) ∈Nℝr
+×ℝn−r(x∗) if and only if
υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj ≥0
(j = 1, . . . , r),
(υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj) x∗
j = 0
(j = 1, . . . , r),
υj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj = 0
(j = r + 1, . . . , n).
Corollary 7.5.7 follows.
Corollary 7.5.8. Let X = ℝr
+ × ℝn−r and f(x) = ⟨c, x⟩. Then x∗∈Ωlc is the optimal
solution of the linear optimization model if and only if the following KKT-optimality con-
ditions hold:
(a) x∗
j ≥0 (j = 1, . . . , r) and x∗
j ∈ℝ(j = r + 1, . . . , n), where x∗= (x∗
1, . . . , x∗
n);
(b) ⟨ai, x∗⟩≥bi (i = 1, . . . , s) and ⟨ai, x∗⟩= bi (i = s + 1, . . . , m), where ai =
(ai1, . . . , ain);
(c) there are m KKT multipliers λ∗
1, . . . , λ∗
m such that
λ∗
i ≥0
(i = 1, . . . , s),
λ∗
i ∈ℝ
(i = s + 1, . . . , m),
λ∗
i (⟨ai, x∗⟩−bi) = 0
(i = 1, . . . , s);
(d) for c = (c1, . . . , cn),
cj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj ≥0
(j = 1, . . . , r),
(cj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj) x∗
j = 0
(j = 1, . . . , r),
cj −λ∗
1a1j −⋅⋅⋅−λ∗
mamj = 0
(j = r + 1, . . . , n).
Proof. Corollary 7.5.8 follows immediately from Corollary 7.5.7 and ∂f(x∗) = {c}.
7.6 Primal and dual pairs of linear optimization
Assume that a bivariate function S(x, y) deﬁned on ℝn × ℝm is a convex-concave bi-
variate function, i.e.,
–
for all y ∈ℝm, the function S(x, y) is convex with respect to x ∈ℝn,
–
for all x ∈ℝn, the function S(x, y) is concave with respect to y ∈ℝm,
then S(x, y) is called a saddle function on ℝn × ℝm. Assume further that there is a
point (x∗, y∗) such that y∗maximizes S(x∗, y) on ℝm and x∗minimizes S(x, y∗) on
ℝn. Then the point (x∗, y∗) is called a saddle point of the saddle function S(x, y).

234
|
7 Optimization
Since y∗maximizes S(x∗, y) on ℝm and x∗minimizes S(x, y∗) on ℝn,
S(x∗, y) ≤S(x∗, y∗),
S(x, y∗) ≥S(x∗, y∗).
From these two inequalities, it follows that if (x∗, y∗) is a saddle point of a saddle
function S(x, y), then
S(x∗, y) ≤S(x∗, y∗) ≤S(x, y∗).
Deﬁnition 7.6.1. The following two optimization models:
(Lp): min
x∈ℝn sup
y∈ℝm S(x, y),
(Ld): max
y∈ℝm inf
x∈ℝn S(x, y)
are called a primal/dual pair, where the model (Lp) is called the primal model and the
model (Ld) is called the dual model.
Let
f(x) = sup
y∈ℝm S(x, y),
g(y) = inf
x∈ℝn S(x, y).
By the convex-concave property of the saddle function S(x, y), it is easy to deduce that
f(x) is a convex function and g(y) is a concave function.
Dual theorem. The following two conditions are equivalent:
(a) (x∗, y∗) is a saddle point of the saddle function S(x, y),
(b) x∗solves the primal model (Lp) and y∗solves the dual model (Ld), and f(x∗) =
g(y∗), and the optimal values of the primal model (Lp) and the dual model (Ld) are
both equal to S(x∗, y∗).
Now consider the linearly constrained convex optimization model (L) given in Sec-
tion 7.5
min
x
f(x)
subject to
inequality constraints:
⟨ai, x⟩≥bi
(i = 1, . . . , s),
and equality constraints:
⟨ai, x⟩= bi
(i = s + 1, . . . , m),
and the restriction:
x ∈X ⊂ℝn,
where f : ℝn →ℝis convex and X is a polyhedral set. Deﬁne its Lagrangian function
as
L(x, λ) =
{
{
{
{
{
{
{
{
{
f(x) +
m
∑
1
λi(bi −⟨ai, x⟩)
if x ∈X, λ ∈S,
∞
if x
̸∈X,
−∞
if x ∈X, λ
̸∈S,
where S = ℝs
+ × ℝm−s and λ = (λ1, . . . , λm).

7.6 Primal and dual pairs of linear optimization
|
235
7.6.1 Saddle function
It is clear that the Lagrangian function L(x, λ) is a bivariate function on ℝn × ℝm. We
will prove that L(x, λ) is a convex-concave bivariate function on ℝn × ℝm.
Without loss of generality, consider x ∈X and λ ∈S. Then
L(x, λ) = f(x) +
m
∑
1
λi(bi −⟨ai, x⟩).
On the one hand, for all λ ∈S and any x1, x2 ∈X,
L((1 −τ)x1 + τx2, λ)
= f((1 −τ)x1 + τx2) +
m
∑
1
λi (bi −⟨ai, (1 −τ)x1 + τx2⟩)
(0 ≤τ ≤1).
Since f is a convex function and bi = (1 −τ)bi + τbi, it follows that
f((1 −τ)x1 + τx2) ≤(1 −τ)f(x1) + τf(x2),
bi −⟨ai, (1 −τ)x1 + τx2⟩= (1 −τ)(bi −⟨ai, x1⟩) + τ(bi −⟨ai, x2⟩).
Substituting them into the above equality gives
L((1 −τ)x1 + τx2, λ) ≤(1 −τ) (f(x1) +
m
∑
1
λi(bi −⟨ai, x1⟩))
+ τ (f(x2) +
m
∑
1
λi(bi −⟨ai, x2⟩))
= (1 −τ)L(x1, λ) + τL(x2, λ)
(0 ≤τ ≤1),
i.e., for all λ ∈S, the Lagrangian function is convex with respect to x ∈X.
On the other hand, for all x ∈X and any λ(1)
i
, λ(2)
i
∈S,
L(x, (1 −τ)λ(1)
i
+ τλ(2)
i ) = f(x) +
m
∑
1
((1 −τ)λ(1)
i
+ τλ(2)
i ) (bi −⟨ai, x⟩)
(0 ≤τ ≤1).
Note that f(x) = (1 −τ)f(x) + τf(x). Substituting it into the above equality, we get
L(x, (1 −τ)λ(1)
i
+ τλ(2)
i ) = (1 −τ) (f(x) +
m
∑
1
λ(1)
i
(bi −⟨ai, x⟩))
+ τ (f(x) +
m
∑
1
λ(2)
i
(bi −⟨ai, x⟩))
= (1 −τ)L(x, λ(1)) + τL(x, λ(2))
(0 ≤τ ≤1),
i.e., for all x ∈X, the Lagrangian function is concave with respect to λ ∈S.
Thus Lagrangian function L(x, λ) is a saddle function.

236
|
7 Optimization
7.6.2 Saddle point
Consider the KKT-optimization conditions in Theorem 7.5.6. Let
ai = (ai1, . . . , ain)
(i = 1, . . . , m),
x = (x1, . . . , xn).
Then
⟨λ∗
1a1 + λ∗
2a2 + ⋅⋅⋅+ λ∗
mam, x⟩= (λ∗
1a11 + λ∗
2a21 + ⋅⋅⋅+ λ∗
mam1)x1
+ ⋅⋅⋅+ (λ∗
1a1n + λ∗
2a2n + ⋅⋅⋅+ λ∗
mamn)xn
= λ∗
1(a11x1 + ⋅⋅⋅+ a1nxn) + λ∗
2(a21x1 + ⋅⋅⋅+ a2nxn)
+ ⋅⋅⋅+ λ∗
m(am1x1 + ⋅⋅⋅+ amnxn)
=
m
∑
1
λ∗
i (ai1x1 + ⋅⋅⋅+ ainxn) =
m
∑
1
λ∗
i ⟨ai, x⟩,
and so
f(x) −⟨λ∗
1a1 + ⋅⋅⋅+ λ∗
mam, x⟩= f(x) −
m
∑
1
λ∗
i ⟨ai, x⟩.
Note that ∑m
i=1 λibi is constant. Therefore, the KKT-optimization condition (c) of The-
orem 7.5.6 means that x∗minimizes L(x, λ∗).
The KKT-optimization conditions (a) and (b) in Theorem 7.5.6 imply that
m
∑
i=1
λ∗
i (bi −⟨ai, x∗⟩) = 0.
On the other hand, since λ = (λ1, . . . , λm) ∈ℝs
+ × ℝm−s, it is clear that λi ≥0 (i =
1, . . . , s). Note that
⟨ai, x⟩≥bi
(i = 1, . . . , s),
⟨ai, x⟩= bi
(i = s + 1, . . . , m).
Then
m
∑
1
λi(bi −⟨ai, x⟩) =
s
∑
1
λi(bi −⟨ai, x⟩) +
m
∑
s+1
λi(bi −⟨ai, x⟩) ≤0.
So λ∗maximizes L(x∗, λ).
Thus, (x∗, λ∗) is a saddle point of the Lagrange function L(x, λ) for the model (L).

7.6 Primal and dual pairs of linear optimization
|
237
7.6.3 Dual pair
Theorem 7.6.2. Let
c = (c1, . . . , cn),
x = (x1, . . . , xn),
ai = (ai1, . . . , ain)
(i = 1, . . . , m),
b = (b1, . . . , bm),
λ = (λ1, . . . , λm),
aj = (a1j, . . . , amj)
(j = 1, . . . , n).
Then the linear optimization model
(Lp): min
x ⟨c, x⟩
subject to
the inequality constraints:
⟨ai, x⟩≥bi
(i = 1, . . . , s)
and the equality constraints:
⟨ai, x⟩= bi
(i = s + 1, . . . , m),
and the restriction:
x ∈ℝr
+ × ℝn−r
and the linear optimization model
(Ld): max
λ ⟨b, λ⟩
subject to
the inequality constraints:
⟨aj, λ⟩≤cj
(j = 1, . . . , r)
and the equality constraints:
⟨aj, λ⟩= cj
(j = r + 1, . . . , n),
and the restriction:
λ ∈ℝs
+ × ℝm−s
are a primal/dual pair.
Proof. In fact, let
X = ℝr
+ × ℝn−r,
S = ℝs
+ × ℝm−s.
Then the Lagrangian function associated with the primal model (Lp) is given by
L(x, λ) =
{
{
{
{
{
{
{
{
{
⟨c, x⟩+
m
∑
1
λi(bi −⟨ai, x⟩)
if x ∈X, λ ∈S,
∞
if x
̸∈X,
−∞
if x ∈X, λ
̸∈S,
where λ = (λ1, . . . , λm). Note that for x ∈X and λ ∈S,
L(x, λ) = ⟨c, x⟩+
m
∑
1
λi(bi −⟨ai, x⟩).
(7.6.1)
The right-hand side of (7.6.1) is computed as follows:
⟨c, x⟩+
m
∑
1
λi(bi −⟨ai, x⟩) = ⟨c, x⟩+
m
∑
1
biλi −
m
∑
1
λi⟨ai, x⟩
=
n
∑
1
cjxj + ⟨b, λ⟩−
m
∑
1
λi⟨ai, x⟩.

238
|
7 Optimization
However,
m
∑
1
λi⟨ai, x⟩=
m
∑
1
λi(ai1x1 + ⋅⋅⋅+ ainxn)
= λ1(a11x1 + ⋅⋅⋅+ a1nxn) + ⋅⋅⋅+ λm(am1x1 + ⋅⋅⋅+ amnxn)
= (λ1a11 + ⋅⋅⋅+ λmam1)x1 + ⋅⋅⋅+ (λ1a1n + ⋅⋅⋅+ λmamn)xn
= ⟨a1, λ⟩x1 + ⋅⋅⋅+ ⟨an, λ⟩xn
=
n
∑
1
⟨aj, λ⟩xj
and
n
∑
1
cjxj + ⟨b, λ⟩−
m
∑
1
λi⟨ai, x⟩= ⟨b, λ⟩+
n
∑
1
cjxj −
n
∑
1
⟨aj, λ⟩xj
= ⟨b, λ⟩+
n
∑
1
(cj −⟨aj, λ⟩)xj.
From this and (7.6.1), it follows that for x ∈X and λ ∈S,
L(x, λ) = ⟨b, λ⟩+
n
∑
1
(cj −⟨aj, λ⟩) xj.
(7.6.2)
The combination of (7.6.1) and (7.6.2) gives
L(x, λ) = ⟨c, x⟩+
m
∑
1
λi(bi −⟨ai, x⟩) = ⟨b, λ⟩+
n
∑
1
(cj −⟨aj, λ⟩) xj.
From this, by Deﬁnition 7.6.1 of primal/dual pairs, it follows that
(Lp): min
x∈X sup
λ∈S
L(x, λ) = min
x∈X sup
λ∈S
(⟨c, x⟩+
m
∑
1
λi(bi −⟨ai, x⟩))
= min
x∈X (⟨c, x⟩+ sup
λ∈S
m
∑
1
λi(bi −⟨ai, x⟩)) ,
(7.6.3)
(Ld): max
λ∈S inf
x∈X L(x, λ) = max
λ∈S inf
x∈X (⟨b, λ⟩+
n
∑
1
(cj −⟨aj, λ⟩) xj)
= max
λ∈S (⟨b, λ⟩+ inf
x∈X
n
∑
1
(cj −⟨aj, λ⟩) xj) .
(7.6.4)
Note that
x = (x1, . . . , xn) ∈X = ℝr × ℝn−r,
λ = (λ1, . . . , λm) ∈S = ℝs × ℝm−s.
It is seen that
x1 ≥0,
. . . ,
xr ≥0,
xr+1, . . . , xn ∈ℝ,
λ1 ≥0,
. . . ,
λs ≥0,
λs+1, . . . , λm ∈ℝ.
(7.6.5)

7.6 Primal and dual pairs of linear optimization
|
239
By the assumption that ⟨ai, x⟩≥bi (i = 1, . . . , s) and ⟨ai, x⟩= bi (i = s + 1, . . . , m),
and (7.6.5),
m
∑
1
λi (bi −⟨ai, x⟩) =
s
∑
1
λi (bi −⟨ai, x⟩) ≤0.
By the assumption that ⟨aj, λ⟩≤cj (j = 1, . . . , r) and ⟨aj, λ⟩= cj (j = r + 1, . . . , n),
and (7.6.5),
n
∑
1
(cj −⟨aj, λ⟩) xj =
r
∑
1
(cj −⟨aj, λ⟩) xj ≥0.
Thus,
sup
λ∈S
m
∑
1
λi(bi −⟨ai, x⟩) = 0,
inf
x∈X
n
∑
1
(cj −⟨aj, λ⟩) xj = 0.
From this and (7.6.3), and (7.6.4), it follows that
(Lp): min
x∈X sup
λ∈S
L(x, λ) = min
x∈X ⟨c, x⟩,
(Ld): max
λ∈S inf
x∈X L(x, λ) = max
λ∈S ⟨b, λ⟩.
Therefore, the linear optimization models (Lp) and (Ld) are a primal/dual pair.
Theorem 7.6.2 shows that two linear optimization models (Lp) and (Ld) are a primal/
dual pair. This result will be applied in Chapter 8.
Example 7.6.3. The linear optimization model
(Lp): min{ f(x1, x2, x3) = 5x1 −6x2 + 8x3 }
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
2x1 + 3x2 + 2x3 ≥2,
4x1 + 4x2 + 3x3 ≥1,
5x1 −8x2 + x3 = −3,
7x1 + 9x2 −7x3 = 1,
x1 ≥0,
x2 ≥0,
x3 ∈ℝ.
and the linear optimization model
(Ld): max{ g(λ1, λ2, λ3, λ4) = 2λ1 + λ2 −3λ3 + λ4 }
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
2λ1 + 4λ2 + 5λ3 + 7λ4 ≤5,
3λ1 + 4λ2 −8λ3 + 9λ4 ≤−6,
2λ1 + 3λ2 + λ3 −7λ4 = 8,
λ1 ≥0,
λ2 ≥0,
λ3 ∈ℝ,
λ4 ∈ℝ
are a primal/dual pair, and the model (Lp) is the primal model and the model (Ld) is
the dual model.

240
|
7 Optimization
7.7 Case studies
Optimization problems arise in almost all areas of environmental science. Optimiza-
tion can used to reduce overall product cost, minimize negative environment impacts
and maximize the probability of making a correct decision. Here we give some case
studies to explain how the algorithms in this chapter are applied in environmental
science.
7.7.1 Building design
Buildings have considerable impacts on the environment and it has become neces-
sary to pay more attention to environmental performance in building design. Recent
progress in the design of greener buildings advances the research and applications of
various optimization methods in the building sector. In these optimization problems,
main variables include building orientation, window type, window-to-wall ratio, roof
type, etc. The lower and upper boundary values of each variable are viewed as con-
straints. The objective is to achieve cost-effective green building design under these
constraints.
7.7.2 Supply chain planning
The efficiency of a company can often be constrained by the efficiency of its supply
chain management procedures. The supply chain planning problem consists of deter-
mining the optimal production, storage, backorder, subcontracting and distribution
variables associated with a supply chain network, where the objective is to achieve
minimization of the overall total cost, carbon emissions, total delivery time, tardiness,
or maximization of the beneﬁt, etc. and the main constraints includes mass balances,
capacities (production, distribution, budget, storage), time restrictions, etc.
7.7.3 Coal mining
Signiﬁcant quantities of groundwater are discharged in underground coal mining. It
brings further damage to local water environment. Xu et al. (2016) developed an equi-
librium strategy-based optimization method to solve the coal-water conﬂict in China.
Each colliery pursues the largest possible proﬁt and minimizes the cost which consists
of production costs, sewage treatment costs and punitive fees. The main constraints
include production capacity, mining quota limitations, and environmental protection
constraints. At the leader level, the government has the obligation to promote ﬁnancial

Further reading
|
241
revenue so as to ensure an environmental self-repair capacity. In this case, ﬁnancial
revenue is set to the objective function and environmental protection is the constraint.
7.7.4 Iron and steel industry
The rapid development of the iron and steel industry directly needs large amount
of energy. Because energy shortages and environmental degradation problems have
become increasingly prominent, energy conservation and emission reduction have
become more important. The objective function of the optimization is the energy in-
tensity in the iron and steel industry, while the constraints include production unit
ferrite balance, process ferrite balance, market order as well as production capacity.
7.7.5 Electric energy generating systems
Economic operation of electric energy generating systems is one of the prevailing
problems in energy systems. The objective function includes cost reduction, voltage
proﬁle improvement, voltage stability enhancement, emission reduction, as well as
their combinations. The constraints can be classiﬁed into equality and inequality
constraints. Equality constraints consist of real power constraints and reactive power
constraints. Inequality constraints consists of generator constraints, transformer
constraints, shunt VAR compensator constraints, and security constraints.
Further reading
[1]
Ahmadi P, Dincer I, Rosen MA. Multi-objective optimization of an ocean thermal energy con-
version system for hydrogen production. International Journal of Hydrogen Energy. 2015(40):
7601–7608.
[2]
Cauchy A. Methode génerale pour la résolution des systéms d’equations simultanées, C R Acad
Sci Paris. 1847(25):536–538.
[3]
Chaib AE, Bouchekara HREH, Mehasni R, Abido MA. Optimal power ﬂow with emission and non-
smooth cost functions using backtracking search optimization algorithm. International Journal
of Electrical Power & Energy Systems. 2016(81):64–77.
[4]
Cooper FC, Zanna L. Optimisation of an idealised ocean model, stochastic parameterisation of
sub-grid eddies. Ocean Modelling. 2015(88):38–53.
[5]
Feng L, Mears L, Beaufort C, Schulte J. Energy, economy, and environment analysis and opti-
mization on manufacturing plant energy supply system. Energy Conversion and Management.
2016(117):454–465.
[6]
Fergani Z, Touil D, Morosuk T. Multi-criteria exergy based optimization of an organic rankine
cycle for waste heat recovery in the cement industry. Energy Conversion and Management.
2016(112):81–90.
[7]
Harver CM. Operations Research: An Introduction to Linear Optimization and Decision Analysis,
Elsevier North Holland, Inc., New York, 1979.

242
|
7 Optimization
[8]
Kucukmehmetoglu M, Geymen A. Optimization models for urban land readjustment practices
in Turkey. Habitat International. 2016(53):517–533.
[9]
Kuhn HW, Tucker AW. Nonlinear Programming. Proceedings of Second Berkeley Symposium on
Mathematical Statistics and Probability, pp. 481–492, University of California Press, Berkeley,
CA, 1950.
[10] Lemke CE. The dual method of solving a linear programming problem. Naval Res Logistics Q.
1954(1):48–54.
[11] Lendering KT, Jonkman SN, van Gelder PHAJM, Peters DJ. Risk-based optimization of land recla-
mation. Reliability Engineering & System Safety. 2015(144):193–203.
[12] Ma D, Wang S, Zhang Z. Hybrid algorithm of minimum relative entropy-particle swarm opti-
mization with adjustment parameters for gas source term identiﬁcation in atmosphere.
Atmospheric Environment. 2014(94):637–646.
[13] Nguyen AT, Reiter S, Rigo P. A review on simulation-based optimization methods applied to
building performance analysis. Applied Energy. 2014(113):1043–1058.
[14] Wang W, Zmeureanu R, Rivard H. Applying multi-objective genetic algorithms in green building
design optimization. Building and Environment. 2005(40):1512–1525.
[15] Xu J, Lv C, Zhang M, Yao L, Zeng Z. Equilibrium strategy-based optimization method for
the coal-water conﬂict: A perspective from China. Journal of Environmental Management.
2015(160):312–323.
[16] Zamarripa MA, Aguirre AM, Mendez CA, Espuna A. Mathematical programming and game
theory optimization-based tool for supply chain planning in cooperative/competitive envi-
ronments. Chemical Engineering Research and Design. 2013(91):1588–1600.

8 Data envelopment analysis
Data Envelopment Analysis (DEA) is a very powerful service management and bench-
marking technique to evaluate organizations (i.e. so-called Decision Making Units
(DMUs)) such as companies, schools, hospitals, shops, bank branches and similar
instances where there is a relatively homogeneous set of units. Each DMU has a vary-
ing level of inputs and gives a varying level of outputs. DEA uses a linear optimiza-
tion technique to measure the relative performance of DMUs where the presence of
multiple inputs and outputs makes comparisons difficult. The main DEA models can
be classiﬁed in three groups according to orientation, returns to scale, and distance
function. The oriented models include input-oriented, output-oriented, and nonori-
ented envelopment models. The returns to scale models include constant, variable,
nonincreasing, nondecreasing, and generalized returns to scale models. The distance
function models include traditional radial DEA, nonradial slack-based measure, and
radial and hybrid slack based measure models. In this chapter we will introduce these
models.
8.1 Charnes–Cooper–Rhodes DEA models
The Charnes–Cooper–Rhodes (CCR) DEA model is the origin of DEA models. The CCR
DEA model is referred to as the Constant Returns to Scale (CRS) model or the synthetic
technical efficiency model.
Assume that there are n DMUs to be evaluated, denoted by DMUj (j = 1, . . . , n).
For each DMUj, the input xj has m components and the output yj has q components
xj = (x1j, x2j, . . . , xmj),
yj = (y1j, y2j, . . . , yqj)
and each DMUj consumes amount xij of input i (i = 1, . . . , m) and produces amount
yrj of output r (r = 1, . . . , q). Assume that xij ≥0 and yrj ≥0 and that each DMUj
has at least one positive input value and one positive output value. For the particular
DMU0 being evaluated, its input and output are, respectively,
x0 = (x10, x20, . . . , xm0),
y0 = (y10, y20, . . . , yq0),
and it consumes amounts xi0 of input i (i = 1, . . . , m) and produces amount yr0 of
output r (r = 1, . . . , q). Assume that xi0 ≥0 and yr0 ≥0.
8.1.1 Input-oriented CCR DEA models
Let
u = (u1, . . . , uq),
υ = (υ1, . . . , υm).
DOI 10.1515/9783110424904-009

244
|
8 Data envelopment analysis
The ratio of outputs y0 with weight u to inputs x0 with weight υ forms the objective
function
⟨u, y0⟩
⟨υ, x0⟩= u1y10 + u2y20 + ⋅⋅⋅+ uqyq0
υ1x10 + υ2x20 + ⋅⋅⋅+ υmxm0
,
where both u ≥0 and υ ≥0 are variables, and x0, y0 are the observed input and output
values, respectively. The objective function is a measure of efficiency. An additional
constraint is to guarantee that the efficiency of a DMU must be less than or equal to
unity, i.e.,
⟨u, yj⟩
⟨υ, xj⟩= u1y1j + u2y2j + ⋅⋅⋅+ uqyqj
υ1x1j + υ2x2j + ⋅⋅⋅+ υmxmj
≤1
(j = 1, . . . , n).
The ﬁrst input-oriented CCR DEA model presented by Charnes, Cooper, and Rhodes is
the form
(Lip
CCR): max {⟨u, y0⟩
⟨υ, x0⟩}
subject to
{
{
{
⟨u,yj⟩
⟨υ,xj⟩≤1
(j = 1, . . . , n),
u ≥0,
υ ≥0.
If (u∗, υ∗) is the optimal solution of the model (Lip
CCR), then (tu∗, tυ∗) (t > 0)
is also its optimal solution. Hence, the above ratio form yields an inﬁnite number of
solutions. Using the Charnes–Cooper transformation
t =
1
⟨υ, x0⟩
or
⟨tυ, x0⟩= 1,
(8.1.1)
the objective function becomes
⟨u, y0⟩
⟨υ, x0⟩= t⟨u, y0⟩= ⟨tu, y0⟩
(8.1.2)
and the additional constraint becomes
⟨u, yj⟩
⟨υ, xj⟩= t⟨u, yj⟩
t⟨υ, xj⟩= ⟨tu, yj⟩
⟨tυ, xj⟩≤1
(j = 1, . . . , n).
By the assumption, ⟨tυ, xj⟩= t⟨υ, xj⟩> 0. So the additional constraint is equivalent
to ⟨tu, yj⟩≤⟨tυ, xj⟩or
⟨tu, yj⟩−⟨tυ, xj⟩≤0.
(8.1.3)
Let
μ = (μ1, . . . , μq),
ν = (ν1, . . . , νm).
Using change of variables μ = tu and ν = tυ in (8.1.1), (8.1.2), and (8.1.3), the input-
oriented CCR DEA model has the following equivalent form
(Lip
CCR): max⟨μ, y0⟩
subject to
{
{
{
{
{
{
{
{
{
⟨μ, yj⟩−⟨ν, xj⟩≤0
(j = 1, . . . , n),
⟨ν, x0⟩= 1,
μ ≥0, ν ≥0.

8.1 Charnes–Cooper–Rhodes DEA models
|
245
The input-oriented CCR DEA model is also called the multiplier model since μ and ν
are multipliers.
Example 8.1.1. Assume that there are three DMUs with two inputs x1, x2 and one out-
put y to be evaluated. The data for the input-oriented CCR DEA model are listed in the
following table:
DMU
x1
x2
y
x1/y
x2/y
DMU1
15
25
10
1.50
2.50
DMU2
32
24
16
2.00
1.50
DMU3
50
60
20
2.50
3.00
Using the model (Lip
CCR), three input-oriented CCR DEA models are used to assess
DMUs, respectively
DMU1 : max 10 Wy
subject to
10 Wy −15 Wx1 −25 Wx2 ≤0
16 Wy −32 Wx1 −24 Wx2 ≤0
20 Wy −50 Wx1 −60 Wx2 ≤0
15 Wx1 + 25 Wx2 = 1.
DMU2 : max 16 Wy
subject to
10 Wy −15 Wx1 −25 Wx2 ≤0
16 Wy −32 Wx1 −24 Wx2 ≤0
20 Wy −50 Wx1 −60 Wx2 ≤0
32 Wx1 + 24 Wx2 = 1.
DMU3 : max 20 Wy
subject to
10 Wy −15 Wx1 −25 Wx2 ≤0
16 Wy −32 Wx1 −24 Wx2 ≤0
20 Wy −50 Wx1 −60 Wx2 ≤0
50 Wx1 + 60 Wx2 = 1.
The three evaluated DMUs may be represented by the following three points, respec-
tively,
D1(1.5, 2.5),
D2(2, 1.5),
D3(2.5, 3).
Set a rectangular coordinate system with the origin O(0, 0) and horizontal axis x1/y,
and vertical axis x2/y on a sheet of graph paper and plot these three points D1, D2,
and D3. The curve through points D1, D2, and its extension is called the frontier curve
which looks like a convex envelopment towards the origin and envelops these three

246
|
8 Data envelopment analysis
points. Denote by D󸀠
i the intersection point of the straight line ODi and the frontier
curve. The intersection point D󸀠
i is called the projection from the point Di to the frontier
curve. Deﬁne the efficiency value of Di as OD󸀠
i
ODi . Clearly,
OD󸀠
1
OD1
= 1,
OD󸀠
2
OD2
= 1,
OD󸀠
3
OD3
< 1,
i.e., the efficiency values of D1 and D2 are both 1, and the efficiency value of D3 is
less than 1.
The detailed version of the input-oriented CCR DEA model is
(Lip
CCR): max { y10μ1 + y20μ2 + ⋅⋅⋅+ yq0μq }
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y11μ1 + y21μ2 + ⋅⋅⋅+ yq1μq −x11ν1 −x21ν2 −⋅⋅⋅−xm1νm ≤0,
...
y1nμ1 + y2nμ2 + ⋅⋅⋅+ yqnμq −x1nν1 −x2nν2 −⋅⋅⋅−xmnνn ≤0,
x10ν1 + x20ν2 + ⋅⋅⋅+ xm0νm = 1,
μ1 ≥0, . . . , μq ≥0,
ν1 ≥0, . . . , νm ≥0.
By Theorem 7.6.2, the dual model of the input-oriented CCR DEA model is
(Lid
CCR): min θ
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y11λ1 + y12λ2 + ⋅⋅⋅+ y1nλn ≥y10,
...
yq1λ1 + yq2λ2 + ⋅⋅⋅+ yqnλn ≥yq0,
−x11λ1 −x12λ2 −⋅⋅⋅−x1nλn + θ x10 ≥0,
...
−xm1λ1 −xm2λ2 −⋅⋅⋅−xmnλn + θ xm0 ≥0,
λ1 ≥0, λ2 ≥0, . . . , λn ≥0.
Note that
x11λ1 + x12λ2 + ⋅⋅⋅+ x1nλn ≤θ x10.
From x11λ1 + x12λ2 + ⋅⋅⋅+ x1nλn > 0 and x10 ≥0, it follows that θ > 0.
Let λ = (λ1, . . . , λn) and
xi = (xi1, . . . , xin)
(i = 1, . . . , m),
yr = (yr1, . . . , yrn)
(r = 1, . . . , q).

8.1 Charnes–Cooper–Rhodes DEA models
|
247
Then the contraction of the dual model is as follows:
(Lid
CCR): min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩≥yr0
(r = 1, . . . , q),
⟨λ, xi⟩≤θxi0
(i = 1, . . . , m),
λ ≥0, θ > 0.
If the input-oriented CCR DEA model has the optimal solution z∗and its dual
model has the optimal solution θ∗, the dual theorem says that z∗= θ∗. Thus, the prob-
lem of ﬁnding the optimal solution of the input-oriented CCR DEA model is reduced to
the problem of ﬁnding the optimal solution of the dual model. One can solve the dual
model to obtain the optimal solution because when θ = 1, λ0 = λk = 1, and all other
λj = 0, the constraints of the dual model hold. So the solution satisﬁes θ∗= min θ ≤1.
So the optimal solution of the dual model satisﬁes that 0 < θ∗≤1. A DMU is efficient
if the optimal solution θ∗= 1 and the optimal multipliers μ∗
r > 0 and ν∗
i > 0. All
efficient points representing DMUs lie on the frontier curve which looks like a concave
envelopment towards the origin and envelops all DMUs. So the dual model is called
the envelopment model.
Example 8.1.2. Assume that there are ﬁve DMUs. Each DMU consumes a single input
to produce a single output. The data are given in the following table:
DMUs
DMU1
DMU2
DMU3
DMU4
DMU5
Input
x11 = 2
x12 = 3
x13 = 6
x14 = 9
x15 = 5
Output
y11 = 1
y12 = 4
y13 = 6
y14 = 7
y15 = 3
and the observed input and output values are, respectively, x10 = x15 = 5 and y10 =
y15 = 3. To evaluate the efficiency of DMU5, by the dual theorem, we solve the follow-
ing dual model:
(Lid
CCR): min θ
subject to
{
{
{
{
{
{
{
{
{
2λ1 + 3λ2 + 6λ3 + 9λ4 + 5λ5 ≤5θ
λ1 + 4λ2 + 6λ3 + 7λ4 + 3λ5 ≥3
λ1 ≥0, λ2 ≥0, λ3 ≥0, λ4 ≥0, λ5 ≥0, θ > 0.
Let θ = −ξ . Converting minimization of θ to maximization of ξ , and then intro-
ducing two slack variables s1 ≥0 and s2 ≥0, this produces a new model (L0) from
the dual model (Lid
CCR)

248
|
8 Data envelopment analysis
(L0): max ξ
subject to
{
{
{
{
{
{
{
{
{
5ξ −2λ1 −3λ2 −6λ3 −9λ4 −5λ5 + s1 = 0,
λ1 + 4λ2 + 6λ3 + 7λ4 + 3λ5 + s2 = 3
λ1 ≥0, λ2 ≥0, λ3 ≥0, λ4 ≥0, λ5 ≥0.
Consider the ﬁrst row as the objective and the second row as the only constraint,
we will solve the above dual model (L0) using the simplex method given in Section 7.3.
There is only one constraint, so the computation process becomes very simple.
Pivoting on the (1, 1) entry, this produces a model (L1) from the model (L0)
(L1): max ξ
subject to
{
{
{
{
{
{
{
{
{
5ξ + 5λ2 + 6λ3 + 5λ4 + λ5 + s1 + 2s2 = 6,
λ1 + 4λ2 + 6λ3 + 7λ4 + 3λ5 + s2 = 3
ϕ(1) = 1,
λ1 ≥0, λ2 ≥0, λ3 ≥0, λ4 ≥0, λ5 ≥0.
The basic variable is λ1. Other variables are nonbasic variables. Let λi = 0 (i
̸= 1) and
si = 0 (i = 1, 2). Then λ1 = 3 and ξ = −6
5 .
Pivoting on the (1, 2) entry, this produces a model (L2) from the model (L0)
(L2): max ξ
subject to
{
{
{
{
{
{
{
{
{
5ξ + 5
4 λ1 + 3
2 λ3 + 15
4 λ4 + 11
4 λ5 −s1 −3
4 s2 = −9
4 ,
1
4 λ1 + λ2 + 3
2 λ3 + 7
4 λ4 + 3
4 λ5 + 1
4 s2 = 3
4 ,
ϕ(1) = 2,
λ1 ≥0, λ2 ≥0, λ3 ≥0, λ4 ≥0, λ5 ≥0.
The basic variable is λ2. Other variables are nonbasic variables. Let λi = 0 (i
̸= 2) and
si = 0 (i = 1, 2). Then λ2 = 3
4 and ξ = −9
20 .
Pivoting on the (1, 3) entry, this produces a model (L3) from the model (L0)
(L3): max ξ
subject to
{
{
{
{
{
{
{
{
{
5ξ + λ1 −λ2 + 2λ4 + 2λ5 −s1 −s2 = −3,
1
6 λ1 + 2
3 λ2 + λ3 + 7
6 λ4 + 1
2 λ5 + 1
6 s2 = 1
2 ,
ϕ(1) = 3,
λ1 ≥0, λ2 ≥0, λ3 ≥0, λ4 ≥0, λ5 ≥0.
The basic variable is λ3. Other variables are nonbasic variables. Let λi = 0 (i
̸= 3) and
si = 0 (i = 1, 2). Then λ3 = 1
2 and ξ = −3
5 .
Pivoting on the (1, 4) entry, this produces a model (L4) from the model (L0)
(L4): max ξ
subject to
{
{
{
{
{
{
{
{
{
5
9 ξ + 5
63 λ1 −15
63 λ2 −12
63 λ3 + 8
63 λ5 −1
9 s1 −1
7 s2 = −3
7 ,
1
7 λ1 + 4
7 λ2 + 6
7 λ3 + λ4 + 3
7 λ5 + 1
7 s2 = 3
7 ,
ϕ(1) = 4,
λ1 ≥0, λ2 ≥0, λ3 ≥0, λ4 ≥0, λ5 ≥0.

8.1 Charnes–Cooper–Rhodes DEA models
|
249
The basic variable is λ4. Other variables are nonbasic variables. Let λi = 0 (i
̸= 4) and
si = 0 (i = 1, 2). Then λ4 = 3
7 and ξ = −27
35 .
Pivoting on the (1, 5) entry, this produces a model (L5) from the model (L0)
(L5): max ξ
subject to
{
{
{
{
{
{
{
{
{
ξ + 1
15 λ1 −11
15 λ2 −4
5 λ3 −8
15 λ4 −1
5 s1 −1
3 s2 = −1,
1
3 λ1 + 4
3 λ2 + 2λ3 + 7
3 λ4 + λ5 + 1
3 s2 = 1,
ϕ(1) = 5,
λ1 ≥0, λ2 ≥0, λ3 ≥0, λ4 ≥0, λ5 ≥0.
The basic variable is λ5. Other variables are nonbasic variables. Let λi = 0 (i
̸= 5) and
si = 0 (i = 1, 2). Then λ5 = 1 and ξ = −1.
Therefore,
max ξ = max {−6
5 , −9
20 , −3
5 , −27
35 , −1} = −9
20
and the corresponding λ2 = 3
4 and λi = 0 (i
̸= 2).
Note that min θ = −max ξ . So when λ2 = 3
4 and λi = 0 (i
̸= 2), min θ = −max ξ = 9
20 .
8.1.2 Output-oriented CCR DEA models
Let x0, y0, xj, yj (j = 1, . . . , n), u, υ, and μ, ν be stated as in Section 8.1.1, i.e.,
x0 = (x10, . . . , xm0),
y0 = (y10, . . . , yq0),
xj = (x1j, . . . , xmj),
yj = (y1j, . . . , yqj)
(j = 1, . . . , n),
u = (u1, . . . , uq),
υ = (υ1, . . . , υm),
μ = (μ1, . . . , μq),
ν = (ν1, . . . , νm).
The ratio of inputs x0 with weight υ to outputs y0 with weight u forms the objective
function
⟨υ, x0⟩
⟨u, y0⟩= υ1x10 + υ2x20 + ⋅⋅⋅+ υmxm0
u1y10 + u2y20 + ⋅⋅⋅+ uqyq0
,
where u ≥0 and υ ≥0 are variables, and x0, y0 are the observed input and output
values, respectively. Using the Charnes–Cooper transformation
t =
1
⟨u, y0⟩
or
⟨tu, y0⟩= 1,
(8.1.4)
the objective function becomes
⟨υ, x0⟩
⟨u, y0⟩= t⟨υ, x0⟩= ⟨tυ, x0⟩.
(8.1.5)
An additional constraint is to guarantee that the efficiency of DMU must be less than
or equal to unity, i.e.,
⟨u, yj⟩
⟨υ, xj⟩= t⟨u, yj⟩
t⟨υ, xj⟩= ⟨tu, yj⟩
⟨tυ, xj⟩≤1
(j = 1, . . . , n).
(8.1.6)

250
|
8 Data envelopment analysis
Using change of variable μ = tu and ν = tυ in (8.1.4), (8.1.5), and (8.1.6), the output-
oriented CCR DEA model becomes the following form
(Lop
CCR): min⟨ν, x0⟩
subject to
{
{
{
{
{
{
{
{
{
⟨ν, xj⟩−⟨μ, yj⟩≥0
(j = 1, . . . , n),
⟨μ, y0⟩= 1,
ν ≥0,
μ ≥0.
Example 8.1.3. Assume that there are three DMUs with two outputs y1, y2 and one
input x to be evaluated. The data for the output-oriented CCR DEA model are listed in
the following table:
DMU
y1
y2
x
y1/x
y2/x
DMU1
10
40
10
1.00
4.00
DMU2
20
40
20
1.00
2.00
DMU3
25
35
10
2.50
3.50
Using the model (Lop
CCR), three output-oriented CCR DEA models are used to assess
DMUs, respectively
DMU1 : max 10 Wx
subject to
10 Wx −10 Wy1 −40 Wy2 ≥0
20 Wx −20 Wy1 −40 Wy2 ≥0
10 Wx −25 Wy1 −35 Wy2 ≥0
10 Wy1 + 40 Wy2 = 1.
DMU2 : max 20 Wx
subject to
10 Wx −10 Wy1 −40 Wy2 ≥0
20 Wx −20 Wy1 −40 Wy2 ≥0
10 Wx −25 Wy1 −35 Wy2 ≥0
20 Wy1 + 40 Wy2 = 1.
DMU3 : max 10 Wx
subject to
10 Wx −10 Wy1 −40 Wy2 ≥0
20 Wx −20 Wy1 −40 Wy2 ≥0
10 Wx −25 Wy1 −35 Wy2 ≥0
25 Wy1 + 35 Wy2 = 1.
The three evaluated DMUs may be represented by the following three points, respec-
tively,
D1(1, 4),
D2(1, 2),
D3(2.5, 3.5).

8.1 Charnes–Cooper–Rhodes DEA models
|
251
Set a rectangular coordinate system with the origin O(0, 0), horizontal axis y1/x, and
vertical axis y2/x on a sheet of graph paper and plot these three points D1, D2, D3.
The curve through points D1, D3, and its extension is called the frontier curve which
looks like a concave envelopment towards the origin and envelops these three points.
Denote by D󸀠
i the intersection point of the straight line ODi and the frontier curve. The
intersection point D󸀠
i is called the projection from the point Di to the frontier curve.
Deﬁne the efficiency value of Di as ODi
OD󸀠
i . Clearly,
OD1
OD󸀠
1
= 1,
OD2
OD󸀠
2
< 1,
OD3
OD󸀠
3
= 1,
i.e., the efficiency values of D1 and D3 are both 1, and the efficiency values of D2 is
less than 1.
The detailed version of the output-oriented CCR DEA model is
(Lop
CCR): min { x10ν1 + x20ν2 + ⋅⋅⋅+ xm0νm }
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
x11ν1 + x21ν2 + ⋅⋅⋅+ xm1νm −y11μ1 −y21μ2 −⋅⋅⋅−yq1μq ≥0,
x12ν1 + x22ν2 + ⋅⋅⋅+ xm2νm −y12μ1 −y22μ2 −⋅⋅⋅−yq2μq ≥0,
...
x1nν1 + x2nν2 + ⋅⋅⋅+ xmnνn −y1nμ1 −y2nμ2 −⋅⋅⋅−yqnμq ≥0,
y10μ1 + y20μ2 + ⋅⋅⋅+ yq0μq = 1,
ν1 ≥0, . . . , νm ≥0,
μ1 ≥0, . . . , μq ≥0.
By Theorem 7.6.2, the dual model of the output-oriented CCR DEA model is
(Lod
CCR): max φ
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
x11λ1 + x12λ2 + ⋅⋅⋅+ x1nλn ≤x10,
...
xm1λ1 + xm2λ2 + ⋅⋅⋅+ xmnλn ≤xm0,
−y11λ1 −y12λ2 −⋅⋅⋅−y1nλn + y10φ ≤0,
...
−yq1λ1 −yq2λ2 −⋅⋅⋅−yqnλn + yq0φ ≤0,
λ1 ≥0, λ2 ≥0, . . . , λn ≥0.
Let xi, yr, and λ be stated as in Section 8.1.1, i.e.,
xi = (xi1, . . . , xin)
(i = 1, . . . , m),
yr = (yr1, . . . , yrn)
(r = 1, . . . , q),
λ = (λ1, . . . , λn).

252
|
8 Data envelopment analysis
The contraction of the dual model of the output-oriented CCR DEA model is as follows:
(Lod
CCR): max φ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩≥φyr0
(r = 1, . . . , q),
λ ≥0.
8.2 Banker–Charnes–Cooper DEA models
The Banker–Charnes–Cooper (BCC) DEA model was presented by Banker, Charnes,
and Cooper in 1984. This model is referred to as the Variable Returns to Scale (VRS)
model or the pure technical efficiency model. BCC DEA models are constructed by
adding an additional constraint to the dual models (Lid
CCR) and (Lod
CCR).
8.2.1 Input-oriented BCC DEA models
Consider the dual model (Lid
CCR) introduced in Section 8.1.1. Adding an additional con-
straint
λ1 + ⋅⋅⋅+ λn = 1
(λ ≥0)
to the dual model (Lid
CCR) yields the input-oriented BCC DEA model (Lip
BCC).
The detailed version of the input-oriented BCC DEA model (Lip
BCC) is as follows
(Lip
BCC): min θ
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y11λ1 + y12λ2 + ⋅⋅⋅+ y1nλn ≥y10,
...
yq1λ1 + yq2λ2 + ⋅⋅⋅+ yqnλn ≥yq0,
−x11λ1 −x12λ2 −⋅⋅⋅−x1nλn + θx10 ≥0,
...
−xm1λ1 −xm2λ2 −⋅⋅⋅−xmnλn + θxm0 ≥0,
λ1 + λ2 + ⋅⋅⋅+ λn = 1,
λ1 ≥0, λ2 ≥0, . . . , λn ≥0,
where θ > 0.

8.2 Banker–Charnes–Cooper DEA models
|
253
By Theorem 7.6.2, the dual model (Lid
BCC) of the input-oriented BCC DEA model
(Lip
BCC) is
(Lid
BCC): max { y10μ1 + y20μ2 + ⋅⋅⋅+ yq0μq + μ0 }
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
y11μ1 + y21μ2 + ⋅⋅⋅+ yq1μq −x11ν1 −x21ν2 −⋅⋅⋅−xm1νm + μ0 ≤0,
...
y1nμ1 + y2nμ2 + ⋅⋅⋅+ yqnμq −x1nν1 −x2nν2 −⋅⋅⋅−xmnνm + μ0 ≤0,
x10ν1 + x20ν2 + ⋅⋅⋅+ xm0νm = 1,
μ1 ≥0, . . . , μn ≥0,
ν1 ≥0, . . . , νm ≥0,
μ0 ∈ℝ.
Let x0, y0, xj, yj, xi, yr, and μ, ν, λ be stated in Section 8.1, and let e =
(1, 1, . . . , 1). The contraction of the input-oriented BCC DEA model is the form
(Lip
BCC): min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩≥yr0
(r = 1, . . . , q),
⟨λ, xi⟩≤θxi0
(i = 1, . . . , m),
⟨e, λ⟩= 1, λ ≥0, θ > 0,
and the contraction of the dual model of the input-oriented BCC DEA model is the form
(Lid
BCC): max{ ⟨μ, y0⟩+ μ0 }
subject to
{
{
{
{
{
{
{
{
{
⟨μ, yj⟩−⟨ν, xj⟩+ μ0 ≤0
(j = 1, . . . , n),
⟨ν, x0⟩= 1,
μ ≥0, ν ≥0, μ0 ∈ℝ,
where μ0 is a free variable.
It has been seen that the added constraint in the input-oriented BCC DEA model
introduces an additional variable μ0 in its dual model. This extra variable μ0 makes
it possible to effect returns-to-scale evaluations. Thus the input-oriented BCC DEA
model is refereed to as the Variable Returns to Scale (VRS) model.
8.2.2 Output-oriented BCC DEA models
Similarly, adding the additional constraint λ1 + λ2 + ⋅⋅⋅+ λn = 1 (λ ≥0) to the dual
model (Lod
CCR) yields the output-oriented BCC DEA model. Its detail version is as follows:

254
|
8 Data envelopment analysis
(Lop
BCC): max φ
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
x11λ1 + x12λ2 + ⋅⋅⋅+ x1nλn ≤x10,
...
xm1λ1 + xm2λ2 + ⋅⋅⋅+ xmnλn ≤xm0,
−y11λ1 −y12λ2 −⋅⋅⋅−y1nλn + y10φ ≤0,
...
−yq1λ1 −yq2λ2 −⋅⋅⋅−yqnλn + yq0φ ≤0,
λ1 + λ2 + ⋅⋅⋅+ λn = 1,
λ1 ≥0, λ2 ≥0, . . . , λn ≥0.
By Theorem 7.6.2, its dual model (Lod
BCC) is as follows:
(Lod
BCC): max { x10ν1 + x20ν2 + ⋅⋅⋅+ xm0νm + ν0 }
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
x11ν1 + x21ν2 + ⋅⋅⋅+ xm1νm −y11μ1 −y21μ2 −⋅⋅⋅−yq1μq + ν0 ≥0,
...
x1nν1 + x2nν2 + ⋅⋅⋅+ xmnνm −y1nμ1 −y2nμ2 −⋅⋅⋅−yqnμq + ν0 ≥0,
y10μ1 + y20μ2 + ⋅⋅⋅+ yq0μq = 1,
ν1 ≥0, . . . , νm ≥0,
μ1 ≥0, . . . , μq ≥0,
ν0 ∈ℝ,
where ν0 is a free variable.
Let x0, y0, xj, yj, xi, yr, and μ, ν, λ be stated in Section 8.1 and e = (1, 1, . . . , 1).
The contraction of the output-oriented BCC DEA model is as follows:
(Lop
BCC): min φ
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩≥φyr0
(r = 1, . . . , q),
⟨e, λ⟩= 1,
λ ≥0.
The contraction of its dual model is as follows:
(Lod
BCC): max{ ⟨ν, x0⟩+ ν0 }
subject to
{
{
{
{
{
{
{
{
{
⟨μ, yj⟩−⟨ν, xj⟩+ ν0 ≤0
(j = 1, . . . , n),
⟨μ, y0⟩= 1,
ν ≥0, μ ≥0, ν0 ∈ℝ,
where ν0 is a free variable. Similarly, the added constraint ⟨e, λ⟩= 1 introduces an
extra variable ν0.

8.3 One-stage and two-stage methods
|
255
8.3 One-stage and two-stage methods
The one-stage and two stage methods are used for solving optimization models. Cite
the dual model (Lid
CCR) of the input-oriented CCR DEA model to introduce these two
methods.
8.3.1 One-stage method
Slack variables are used to convert the inequalities in the model (Lid
CCR) to equivalent
equations. The one-stage method is to add only slack variables to constraints. The dual
model (Lid
CCR) is the form
(Lid
CCR): min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩≥yr0
(r = 1, . . . , q),
⟨λ, xi⟩≤θxi0
(i = 1, . . . , m),
λ ≥0, θ > 0.
Introducing slack variables to constraints, the dual model has the following equiva-
lent form
(Lid
CCR): min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s−
r = yr0,
s−
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩+ s+
i = θxi0,
s+
i ≥0
(i = 1, . . . , m),
λ ≥0, θ > 0.
In the previous Section 8.1.1, the one-stage method was used for solving Example 8.1.2.
8.3.2 Two-stage method
Nonzero slacks will be such that some boundary points may be weakly efficient which
is deﬁned as follows.
Deﬁnition 8.3.1. Let the particular DMU0 being evaluated consume amounts xi0 of
input i (i = 1, . . . , m) and produce amounts yr0 of output r (r = 1, . . . , q), and let θ∗
be the optimal solution of the dual model (Lid
CCR). Then
(a) DMU0 is efficient if and only if θ∗= 1 and the slack variables s−∗
i
= s+∗
r
= 0 for all
i and r.
(b) DMU0 is weakly efficient if and only if θ∗= 1 and the slack variables s−∗
i
̸= 0
and/or s+∗
r
̸= 0 for some i and r.

256
|
8 Data envelopment analysis
To avoid weak efficiency, the two-stage method is to add the slack variables to both
constraints and the objective, i.e.,
(Lid
CCR): min { θ −ε (
m
∑
1
s−
i +
q
∑
1
s+
r ) }
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s−
r = yr0,
s−
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩+ s+
i = θxi0,
s+
i ≥0
(i = 1, . . . , m),
λ ≥0, θ > 0, ε > 0,
where ε is a so-called non-Archimedean element deﬁned to be smaller than any pos-
itive real number.
This model is solved in two stages.
The ﬁrst stage is to ﬁnd the optimal solution θ∗of the dual model (Lid
CCR)
(Lid
CCR): min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩≥yr0
(r = 1, . . . , q),
⟨λ, xi⟩≤θxi0
(i = 1, . . . , m),
λ ≥0, θ > 0
or its equivalent model
(Lid
CCR): min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s−
r = yr0,
s−
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩+ s+
i = θxi0,
s+
i ≥0
(i = 1, . . . , m),
λ ≥0, θ > 0.
The second stage is to solve the following model:
max {
m
∑
1
s−
i +
q
∑
1
s+
r }
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s−
r = yr0
(r = 1, . . . , q),
⟨λ, xi⟩+ s+
i = θ∗xi0
(i = 1, . . . , m),
λ ≥0,
where θ∗is the optimal solution obtained in the ﬁrst stage.

8.4 Advanced DEA models
|
257
8.4 Advanced DEA models
Let x0, y0, xj, yj, xi, yr and μ, ν, λ be stated in Section 8.1, and let e = (1, 1, . . . , 1).
8.4.1 Free disposal hull DEA models
The Free Disposal Hull (FDH) DEA model presented by Tulkens (1993) is a mixed integer
linear programming model. The FDH DEA model is obtained by changing the constraint
λ ≥0 into λ = (λ1, . . . , λn) and λj = 0 or 1 (j = 1, . . . , n) in DEA models. The input-
oriented FDH DEA model is the form
min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩≥yr0
(r = 1, . . . , q),
⟨λ, xi⟩≤θxi0
(i = 1, . . . , m),
⟨e, λ⟩= 1
(λj = 0 or 1 (j = 1, . . . , n)), θ > 0.
8.4.2 Slack-based measure DEA models
Slack-Based Measure (SBM) DEA models were presented by Tone (2001). The SBM
DEA models include the input-oriented, the output-oriented, and the nonoriented
SBM DEA model.
–
The input-oriented SBM DEA model is the form
min {1 −1
m
m
∑
1
s−
i
xi0
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩≥yr0
(r = 1, . . . , q),
⟨λ, xi⟩+ s−
i = xi0,
s−
i ≥0
(i = 1, . . . , m),
λ ≥0,
where s−
i (i = 1, . . . , m) are m slack variables.
–
The output-oriented SBM DEA model is the form
min
{
{
{
1
1 + 1
q ∑q
1
s+
r
yr0
}
}
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s+
r = yr0,
s+
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩≤xi0
(i = 1, . . . , m),
λ ≥0,
where s+
r (r = 1, . . . , q) are q slack variables.

258
|
8 Data envelopment analysis
–
The nonoriented SBM DEA model is the form
min
{
{
{
1 −1
m ∑m
1
s−
i
xi0
1 + 1
q ∑q
1
s+
r
yr0
}
}
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s+
r = yr0,
s+
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩+ s−
i = xi0,
s−
i ≥0
(i = 1, . . . , m),
λ ≥0,
where s−
i (i = 1, . . . , m) and s+
r (r = 1, . . . , q) are m + q slack variables.
The above input-oriented, output-oriented, and nonoriented SBM models are referred
to as CRS models. If the additional constraint ⟨e, λ⟩= 1 is added to the above models,
the obtained models are referred to as VRS models. If the additional constraints
⟨e, λ⟩≥1,
⟨e, λ⟩≤1,
L ≤⟨e, λ⟩≤U,
are added, respectively, to the above models, the obtained models are referred to
as Non-Decreasing Returns to Scale (NDRS) models, Non-Increasing Returns to Scale
(NIRS) models, and Generalized Returns to Scale (GRS) models, respectively.
8.4.3 MSBM, WSBM, and WMSBM DEA models
–
The Modiﬁed Slack-Based Measure (MSBM) model was presented by Sharp et al.
(2007). Its form is
min
{
{
{
1 −1
m ∑m
1
s−
i
Ri0
1 + 1
q ∑q
1
s+
r
Rr0
}
}
}
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s+
r = yr0,
s+
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩+ s−
i = xi0,
s−
i ≥0
(i = 1, . . . , m),
⟨e, λ⟩= 1,
λ ≥0,
where s+
r (r = 1, . . . , q) and s−
i (i = 1, . . . , m) are slack variables, and
Ri0 = xi0 −min
1≤j≤n{ xij },
Rr0 = max
1≤j≤n{ yrj } −yr0.

8.4 Advanced DEA models
|
259
–
The nonoriented Weighted Slack-Based Measure (WSBM) model is the form
min
{
{
{
{
{
1 −
1
∑m
1 wI
i ∑m
1
wI
i s−
i
xi0
1 +
1
∑q
1 wo
r ∑q
1
wo
r s+
r
yr0
}
}
}
}
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s+
r = yr0,
s+
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩+ s−
i = xi0,
s−
i ≥0
(i = 1, . . . , m),
λ ≥0,
where wI
i (i = 1, . . . , m) and wo
r (r = 1, . . . , q) are the input weights and the
output weights, respectively.
–
The Weighted Modiﬁed Slack-Based Measure (WMSBM) model is the form
min
{
{
{
{
{
1 −
1
∑m
1 wI
i ∑m
1
wI
i s−
i
Ri0
1 +
1
∑q
1 wo
r ∑q
1
wo
r s+
r
Rr0
}
}
}
}
}
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s+
r = yr0,
s+
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩+ s−
i = xi0,
s−
i ≥0
(i = 1, . . . , m),
⟨e, λ⟩= 1,
λ ≥0,
where s+
r , s−
i , wI
i , wo
r , Ri0, and Rr0 are stated as above.
8.4.4 Hybrid distance function DEA models
The main hybrid distance function DEA models include two groups. The ﬁrst group
was presented by Tone and Tsutsui (2010). Due to the parameter ε, Tone and Tsutsui
call the ﬁrst group Epsilon-Based Measure (EBM) models. The second group was pre-
sented by Cooper, Seiford, and Tone (2007). Due to the mix of the radial model and
SBM model, Cooper, Seiford, and Tone call the second group Hybrid Models.

260
|
8 Data envelopment analysis
(a) EBM models
–
The input-oriented EBM model is the form
min {θ −
ε−
∑m
1 w−
i
m
∑
1
w−
i s−
i
xi0
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩+ s−
i = θxi0,
s−
i ≥0
(i = 1, . . . , m),
⟨λ, yr⟩≥yr0
(r = 1, . . . , q),
λ ≥0,
where s−
i and w−
i are stated as above, and ε−∈[0, 1].
–
The output-oriented EBM model is the form
min
{
{
{
{
{
1
φ +
ε+
∑q
1 w+
r ∑q
1
w+
r s+
r
yr0
}
}
}
}
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, yr⟩−s+
r = φyr0,
s+
r ≥0
(r = 1, . . . , q),
⟨λ, xi⟩≤xi0
(i = 1, . . . , m),
λ ≥0,
where s+
r and w+
r are stated as above, and ε+ ∈[0, 1].
–
The non-oriented EBM model is the form
min
{
{
{
{
{
θ −
ε−
∑m
1 w−
i ∑m
1
w−
i s−
i
xi0
φ +
ε+
∑q
1 w+
r ∑q
1
w+
r s+
r
yr0
}
}
}
}
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩+ s−
i = θxi0,
s−
i ≥0
(i = 1, . . . , m),
⟨λ, yr⟩−s+
r = φyr0,
s+
r ≥0
(r = 1, . . . , q),
λ ≥0,
where s−
i , s+
r , w−
i , w+
r are stated as above, and ε−, ε+ ∈[0, 1]. If ε−= ε+ = 0 and
φ = 1, the EBM model is just the dual model of the input-oriented CCR DEA model.
If ε−= ε+ = 1 and θ = φ = 1, the EBM model is just the nonoriented weighted SBM
model.

8.4 Advanced DEA models
|
261
(b) Hybrid models
–
The input-oriented hybrid model is the form
min {1 −m1
m (1 −θ) −1
m
m2
∑
1
sN−
i
xN
i0
}
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, xi
R⟩+ sR−
i
= θxR
i0,
sR−
i
≥0
(i = 1, . . . , m),
⟨λ, xi
N⟩+ sN−
i
= xN
i0,
sN−
i
≥0
(i = 1, . . . , m),
⟨λ, yr
N⟩≥yN
r0
(r = 1, . . . , q),
λ ≥0,
where R is radial and N is nonradial, and m is the input, where m1 is the radial
input and m2 is the nonradial input.
–
The output-oriented hybrid model is the form
min
{
{
{
1
1 −q1
q (φ −1) + 1
q ∑q2
1
sN+
r
yN
i0
}
}
}
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, yr
R⟩−sR+
r
= φyR
r0,
sR+
r
≥0
(r = 1, . . . , q),
⟨λ, yr
N⟩−sN+
r
= yN
r0,
sN+
r
≥0
(r = 1, . . . , q),
⟨λ, xi
N⟩≤xN
i0
(i = 1, . . . , m),
λ ≥0,
where R is radial and N is nonradial, and q is the output, where q1 is the radial
output and q2 is the nonradial output.
–
Hybrid model mixing the radial and SMB models is the form
min
{
{
{
{
{
1 −m1
m (1 −θ) −1
m ∑m2
1
sN−
i
xN
i0
1 + q1
q (φ −1) + 1
q ∑q2
1
sN+
r
yN
r0
}
}
}
}
}
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, xi
R⟩+ sR−
i
= θxR
i0,
sR−
i
≥0
(i = 1, . . . , m),
⟨λ, yr
R⟩−sR+
r
= φyR
r0,
sR+
r
≥0
(r = 1, . . . , q),
⟨λ, xi
N⟩+ sN−
i
= xN
i0,
sN−
i
≥0
(i = 1, . . . , m),
⟨λ, yr
N⟩−sN+
r
= yN
r0,
sN+
r
≥0
(r = 1, . . . , q),
λ ≥0,
where R is radial and N is nonradial, m is the input and q is the output, where
m1 is the radial input and m2 is the nonradial input, and q1 is the radial output
and q2 is the nonradial output.

262
|
8 Data envelopment analysis
8.4.5 Super efficiency models
The main super efficiency models include three groups. The ﬁrst group is the radial
super efficiency models presented by Andersen and Petersen (1993). The second group
is the directional distance function super efficiency models presented by Ray (2008).
The third group is the SMB super efficiency models presented by Tone (2002).
(a) Radial super efficiency models
–
The input-oriented CRS radial super efficiency model is the form
min θ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik ≤θxi0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk ≥yr0
(r = 1, . . . , q),
λ ≥0, θ > 0.
–
The output-oriented CRS radial super efficiency model is the form
max φ
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik ≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk ≥φyr0
(r = 1, . . . , q),
λ ≥0.
–
The input-oriented VRS radial super efficiency model is the form
min θ
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik ≤θxi0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk ≥yr0
(r = 1, . . . , q),
⟨e, λ⟩−λk = 1,
λ ≥0, θ > 0.
–
The output-oriented VRS radial super efficiency model is the form
max φ
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik ≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk ≥φyr0
(r = 1, . . . , q),
⟨e, λ⟩−λk = 1,
λ ≥0.

8.4 Advanced DEA models
|
263
(b) Directional distance function super efficiency models
–
The form is as follows:
max β
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik + βgi
x ≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk −βgr
y ≥yr0
(r = 1, . . . , q),
⟨λ, bt⟩−λkbtk −βgt
y ≤bt0,
λ ≥0,
where bt = (bt1, . . . , btn).
(c) SBM super efficiency models
–
The input-oriented SBM super efficiency model is the form
min {1 + 1
m
m
∑
1
s−
i
xi0
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik + s−
i = xi0,
s−
i ≥0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk ≥yr0
(r = 1, . . . , q),
λ ≥0.
–
The output-oriented SBM super efficiency model is the form
min
{
{
{
1
1 −1
q ∑q
1
s+
r
yr0
}
}
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik ≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk −s+
r = yr0,
s+
r ≥0
(r = 1, . . . , q),
λ ≥0.
–
The nonoriented SBM super efficiency model is the form
max
{
{
{
1 + 1
m ∑m
1
s−
i
xi0
1 −1
q ∑q
1
s+
r
yr0
}
}
}
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩−λkxik + s−
i = xi0,
s−
i ≥0
(i = 1, . . . , m),
⟨λ, yr⟩−λkyrk −s+
r = yr0,
s+
r ≥0
(r = 1, . . . , q),
λ ≥0.

264
|
8 Data envelopment analysis
8.4.6 Directional distance function models
The Directional Distance Function (DDF) model was presented by Chung et al. in 1997.
–
Directional distance function CRS model is
max β
subject to
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩+ βgi
x ≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩+ βgr
y ≥yr0
(r = 1, . . . , q),
λ ≥0,
where gx = (g1
x, . . . , gm
x ) and gy = (g1
y, . . . , gq
y). By Theorem 7.6.2, its dual model
is
min(⟨ν, x0⟩−⟨μ, y0⟩)
subject to
{
{
{
{
{
{
{
{
{
⟨ν, xj⟩−⟨μ, yj⟩≤0
(j = 1, . . . , n),
⟨ν, gx⟩−⟨μ, gy⟩= 1,
ν ≥0, μ ≥0.
–
Directional distance function VRS model is
max β
subject to
{
{
{
{
{
{
{
{
{
{
{
{
{
⟨λ, xi⟩+ βgi
x ≤xi0
(i = 1, . . . , m),
⟨λ, yr⟩+ βgr
y ≥yr0
(r = 1, . . . , q),
⟨e, λ⟩= 1,
λ ≥0,
where gx = (g1
x, . . . , gm
x ) and gy = (g1
y, . . . , gq
y). By Theorem 7.6.2, its dual model
is
min{ ⟨ν, x0⟩−⟨μ, y0⟩+ μ0 }
subject to
{
{
{
{
{
{
{
{
{
⟨ν, xj⟩−⟨μ, yj⟩+ μ0 ≤0
(j = 1, . . . , n),
⟨ν, gx⟩−⟨μ, gy⟩= 1,
ν ≥0, μ ≥0, μ0 ∈ℝ.
8.5 Software and case studies
Data Envelopment Analysis (DEA) is a very powerful service management and bench-
marking technique to evaluate organizations. MaxDEA is an easy-to-use DEA software
and can be downloaded from http://www.maxdea.cn/. MaxDEA includes most DEA
models and can import data from Excel, Access, and text ﬁles. Below we give some
case studies that use DEA algorithms.

Further reading
|
265
8.5.1 Carbon emissions reduction
DEA can be used to make environmental efficiency analysis of several regional indus-
tries. Capital stock, population and energy consumption are three main inputs, GDP
is a single desirable output and carbon emissions are an undesirable output. Miao
et al. (2016) use DEA to quantify the efficient allocation of carbon emissions between
different provinces using China’s provincial data in 2006–2010. Results showed that
the actual carbon emissions in some provinces were higher than their maximal carbon
emission allowances calculated from the DEA model, indicating that these provinces
are facing great pressures on carbon emission reduction.
8.5.2 Coal mining industry
For the coal mining industry, the main inputs are capital and labour, as well as fossil-
fuels; the main output is coal production and some undesirable outputs such as waste
water, gas and solids. With the help of DEA, Liu et al. compared two major coal pro-
ducing areas in China, Shanxi and Inner Mongolia provinces, and showed that the
market-oriented policy package performs better than the nationalization regulations,
because not only can the former policy instruments reduce the economic shock on
industry productivity, but also improve to a larger extent the uniﬁed environmental
and operational efficiency.
8.5.3 Coal-ﬁred power plants
DEA can be used to assess energy efficiency of coal-ﬁred plants. Song et al. (2015) use
input-oriented CCR/BCC DEA models to measure overall technical efficiency and pure
technical efficiency of 34 coal-ﬁred power plants in China. The generalized energy
efficiency is calculated based on four input parameters: coal consumption, oil con-
sumption, water consumption and auxiliary power consumption by power units. The
special energy efficiency is only based on two input parameters: coal consumption and
auxiliary power consumption. Results showed that electricity saving potential exists
for 14 out of 34 power plants.
Further reading
[1]
Andersen P, Petersen NC. A procedure for ranking efficient units in data envelopment analysis.
Management Science. 1993(39):1261–1265.
[2]
Banker RD, Charnes A, Cooper WW. Some models for estimating technical and scale inefficien-
cies in data envelopment analysis. Management Science. 1984(30):1078–1092.

266
|
8 Data envelopment analysis
[3]
Cauchy A. Methode génerale pour la résolution des systéms d’equations simultanées. C R Acad
Sci Paris. 1847(25):536–538.
[4]
Charnes A , Cooper WW, Rhodes E. Measuring the efficiency of decision making units. Euro-
pean Journal of Operational Research. 1978(2):429–444.
[5]
Chen L, Jia G. Environmental efficiency analysis of China’s regional industry: a data envelop-
ment analysis (DEA) based approach. Journal of Cleaner Production. 2016: in press.
[6]
Cooper WW, Seiford LM, Tone K. Data Envelopment Analysis. A comprehensive text with mod-
els, applications, references and DEA-solver software, Kluwer Academic Publishers, Boston,
2000.
[7]
Cooper WW, Seiford LM, Tone K. Data Envelopment Analysis. A comprehensive text with mod-
els, applications, references and DEA-Solver software, 2nd ed. New York: Springer Science &
Business Media, 2007.
[8]
Chung YH, Färe R, Grosskopf S. Productivity and undesirable outputs: A directional distance
function approach. Journal of Environmental Management. 1997(51):229–240.
[9]
Harver CM. Operations Research: An Introduction to Linear Optimization and Decision Analysis,
Elsevier North Holland, Inc., New York, 1979.
[10] Kuhn HW, Tucker AW. Nonlinear Programming. Proceedings of Second Berkeley Symposium on
Mathematical Statistics and Probability, pp. 481–492, University of California Press, Berkeley,
CA, 1950.
[11] Lemke CE. The dual method of solving a linear programming problem. Naval Res Logistics Q.
1954(1):48–54.
[12] Liu J, Liu H, Yao XL, Liu Y. Evaluating the sustainability impact of consolidation policy in China’s
coal mining industry: A data envelopment analysis. Journal of Cleaner Production. 2016(112):
2969–2976.
[13] Miao Z, Geng Y, Sheng J. Efficient allocation of CO2 emissions in China: A zero sum gains data
envelopment model. Journal of Cleaner Production. 2016(112):4144–4150.
[14] Ray SC. The directional distance function and measurement of super-efficiency: An application
to airlines data. Journal of the Operational Research Society. 2008(59):788–797.
[15] Sharp JA, Meng W, Liu W. A modiﬁed slacks-based measure model for data envelopment anal-
ysis with natural negative outputs and inputs. Journal of the Operational Research Society.
2007(58):1672–1677.
[16] Song C, Li M, Zhang F, He YL, Tao WQ. A data envelopment analysis for energy efficiency of
coal-ﬁred power units in China. Energy Conversion and Management. 2015(102):121–130.
[17] Tone K. A slacks-based measure of efficiency in data envelopment analysis. European Journal
of Operational Research. 2001(130):498–509.
[18] Tone K. A slacks-based measure of super-efficiency in data envelopment analysis. European
Journal of Operational Research. 2002(143):32–41.
[19] Tone K. Variations on the theme of slacks-based measure of efficiency in DEA. European Jour-
nal of Operational Research. 2010(200):901–907.
[20] Tulkens H. On FDH efficiency analysis: Some methodological issues and applications to retail
banking, courts, and urban transit. Journal of Productivity Analysis. 1993(4):183–210.

9 Risk assessments
Risk assessment provides a systematic procedure for estimating the probability of
harm to, or from, the environment, the severity of harm, and uncertainty. Lowrance
deﬁned a risk is a measure of the probability and severity of adverse effects. This def-
inition is harmonious with the mathematical formula used to calculate the expected
value of risk. Later, Haimes showed that a risk assessment is a process consisting
of a set of logical, systematic, and well-deﬁned activities that provide the decision
maker with a sound identiﬁcation, measurement, quantiﬁcation, and evaluation
of the risk associated with certain natural phenomena or man-made activities. The
main process of risk assessment includes formulating the problem; assessment of
the risk; appraising various management options; and determining the optimal risk
management strategy. In this chapter we will introduce fundamental methods in risk
assessment processes.
9.1 Decision rules under uncertainty
Denote by ai (i = 1, . . . , I) the i-th decision adopted by the decision maker and denote
by sj (j = 1, . . . , J) the j-th scenario, and denote by Pij (i = 1, . . . , I; j = 1, . . . , J) the
payoff associated with the pair (ai, sj).
The common decision rules include the pessimistic rule, the optimistic rule, and
the Hurwitz rule. The pessimistic rule includes both the maximin criteria and the min-
imax criterion. The optimistic rule is a maximax criterion. The Hurwitz rule is a linear
combination between the maximin and the maximax criteria.
The pessimistic rule
The rule includes two criteria as follows.
–
Let Pij represent a payoff. The maximin criteria is represented by
max
1≤i≤I (min
1≤j≤J Pij) .
–
Let Pij represent a loss or a risk. The minimax criterion is represented by
min
1≤i≤I (max
1≤j≤J Pij) .
The pessimistic rule is also called the maximin criterion or the minimax criterion. This
rule ensures that the decision makers will at least realize the minimum gain or avoid
maximum loss.
DOI 10.1515/9783110424904-010

268
|
9 Risk assessments
The optimistic rule
The rule is represented mathematically by
max
1≤i≤I (max
1≤j≤J Pij) .
The decision maker is most optimistic and seeks to maximize the maximum gain
using the optimistic rule. The optimistic rule is sometimes called the maximax crite-
rion.
The Hurwitz rule
The rule is represented mathematically by
max
1≤i≤I Pi(α) = max
1≤i≤I (α min
1≤j≤J Pij + (1 −α) max
1≤j≤J Pij)
(0 ≤α ≤1).
From the Hurwitz rule, it is seen that max1≤i≤I Pi(0) is the maximax criterion and
max1≤i≤I Pi(1) is the maximin criterion. Therefore, the Hurwitz rule is a compromise
between two extreme criteria through an α-index and the decision maker’s degree of
optimism is speciﬁed by the parameter α.
Example 9.1.1. Assume that ai (i = 1, 2) are two kinds of carbon-emission-reduction
technology adopted potentially by the decision maker and sj (j = 1, 2, 3) are three
scenarios for future carbon price, the corresponding payoff Pij (i = 1, 2; j = 1, 2, 3)
for production with value $ 1000 associated with pair (ai, sj) (i = 1, 2; j = 1, 2, 3) is
(P11
P12
P13
P21
P22
P23
) = (200
110
−15
100
50
5 ) .
Try to ﬁnd the optimal decision by using the pessimistic rule, the optimistic rule, and
the Hurwitz rule, respectively.
Solution. First, consider the pessimistic rule. From
min
1≤j≤3 P1j = min(P11, P12, P13) = min(200, 110, −15) = −15
for decision a1,
min
1≤j≤3 P2j = min(P21, P22, P23) = min(100, 50, 5) = 5
for decision a2,
it follows that
max
1≤i≤2 (min
1≤j≤3 Pij) = max (min
1≤j≤3 P1j, min
1≤j≤3 P2j) = max(−15, 5) = 5,
i.e., the maximin criterion implies a gain of at least $ 5 and the corresponding decision
is a2.

9.1 Decision rules under uncertainty
|
269
Secondly, consider the optimistic rule. Since
max
1≤j≤3 P1j = max(P11, P12, P13) = max(200, 110, −15) = 200
for decision a1,
max
1≤j≤3 P2j = max(P21, P22, P23) = max(100, 50, 5) = 100
for decision a2,
it follows that
max
1≤i≤2 (max
1≤j≤3 Pij) = max (max
1≤j≤3 P1j, max
1≤j≤3 P2j) = max(200, 100) = 200,
i.e., the optimistic rule implies a gain of at most $ 200 and the corresponding decision
is a1.
Third, consider the Hurwitz rule
max
1≤i≤2 Pi(α) = max
1≤i≤2 (α min
1≤j≤3 Pij + (1 −α) max
1≤j≤3 Pij) .
From
min
1≤j≤3 P1j = min(P11, P12, P13) = min(200, 110, −15) = −15,
max
1≤j≤3 P1j = max(P11, P12, P13) = max(200, 110, −15) = 200,
min
1≤j≤3 P2j = min(P21, P22, P23) = min(100, 50, 5) = 5,
max
1≤j≤3 P2j = max(P21, P22, P23) = max(100, 50, 5) = 100,
it follows that for 0 ≤α ≤1,
P1(α) = α min
1≤j≤3 P1j + (1 −α) max
1≤j≤3 P1j
= −15α + 200(1 −α) = 200 −215α
for decision a1,
P2(α) = α min
1≤j≤3 P2j + (1 −α) max
1≤j≤3 P2j
= 5α + 100(1 −α) = 100 −95α
for decision a2.
In order to ﬁnd max1≤i≤2 Pi(α) = max(P1(α), P2(α)), it is only necessary to solve the
equation
200 −215α = 100 −95α.
The solution is α = 5
6 . It is clear that
200 −215α < 100 −95α
if
0 ≤α < 5
6;
200 −215α > 100 −95α
if
5
6 < α ≤1;
200 −215α = 100 −95α
if
α = 5
6 .
Therefore, if 0 ≤α ≤5
6 , then the optimal decision is a1; if 5
6 ≤α ≤1, then the optimal
decision is a2; if α = 5
6 , both a1 and a2 are the optimal decision.

270
|
9 Risk assessments
Example 9.1.2. A computer company knows the sales potential for low-performance,
medium-performance, and high-performance computers. The company wishes to de-
cide on the best development plan based on minimizing risk of ﬁnancial loss and/or
maximizing the expected proﬁt. The sales potential ($ 1000) of the company is given
by the following table:
s1
s2
s3
a1
150
50
−20
a2
300
175
−100
a3
450
150
−150
where the decisions a1, a2, and a3 are the low-performance computer, the medium-
performance computer, and the high-performance computer, respectively, and the
scenarios s1, s2, and s3 are the excellent computer system, the good computer sys-
tem, and the poor computer system, respectively.
Solution. Consider the Hurwitz rule
max
1≤i≤3 {Pi(α) = α min
1≤j≤3 Pij + (1 −α) max
1≤j≤3 Pij}
(0 ≤α ≤1).
From
min
1≤j≤3 P1j = min(150, 50, −20) = −20,
max
1≤j≤3 P1j = max(150, 50, −20) = 150,
min
1≤j≤3 P2j = min(300, 175, −100) = −100,
max
1≤j≤3 P2j = max(300, 175, −100) = 300,
min
1≤j≤3 P3j = min(450, 150, −150) = −150,
max
1≤j≤3 P3j = max(450, 150, −150) = 450,
it follows that
P1(α) = −20α + 150(1 −α) = 150 −170α
for decision a1,
P2(α) = −100α + 300(1 −α) = 300 −400α
for decision a2,
P3(α) = −150α + 450(1 −α) = 450 −600α
for decision a3
which represent three straight lines. It is clear that the second straight line and the
third straight line are parallel and the second straight line is dominated by the third
straight line. Therefore, in order to ﬁnd max1≤i≤3 Pi(α), it is only necessary to solve
the equation
450 −600α = 150 −170α.
The solution is α = 30
43 ≈0.698. This indicates that if α < 30
43 , the high-performance
computer should be produced and sold; if α > 30
43 , the low-performance computer
should be produced and sold.

9.2 Decision trees
|
271
9.2 Decision trees
The decision tree is the most commonly used tool in risk-based decision-making. It
possesses the ability to represent and analyze multiple stages in the decision-making
process. This is an attractive feature of decision trees. The single-objective decision
tree consists of the following basic components.
Decision node. Decision nodes are designated by a square ( ). Branches emanating
from a decision node represent the various decisions to be investigated. Each al-
ternative choice is designated by ai and identify each branch with that decision
choice.
Chance node. Chance nodes are designated by a circle (
). Branches emanating from
a chance node represent the various scenarios with their associated probabilities.
Consequences. The value of the consequences is written at the end of each branch.
The consequence associated with the i-th decision and j-th scenario is designated
by Pij.
To determine the optimal manufacturing scenario, the following three measures are
used for calculating the expected value of proﬁts for each of the alternative decision
options.
Let ai (i = 1, . . . , I) be the i-th decision. Denote by E[ai] the expected value of
proﬁts associated with the i-th decision ai. Let sj (j = 1, . . . , J) be the j-th scenario.
Denote by p(sj) the probability associated with the j-th scenario sj and denote by Pij
the payoff associated with the decision/scenario pair (ai, sj). Assume that p(sj) and
Pij are known.
The Expected Monetary Value (EMV) measure is deﬁned as
EMV = max
1≤i≤I
J
∑
j=1
p(sj)Pij = max
1≤i≤I E[ai].
The Expected Value of Opportunity Loss (EOL) measure is deﬁned as
EOL = min
1≤i≤I
J
∑
j=1
p(sj)(Mj −Pij),
where Mj = max1≤i≤I Pij (j = 1, . . . , J). The EOL measure is essentially a modiﬁcation
of the EMV measure.
The Most Likely Value (MLV) measure is not commonly used because the opti-
mal results are very sensitive to the number of scenarios. In the MLV, one selects the
outcome with the highest probability for each scenario and then maximizes the corre-
sponding Pij.
Example 9.2.1. Consider the payoff matrix ($ 1000) in Example 9.1.1
(P11
P12
P13
P21
P22
P23
) = (200
110
−15
100
50
5 )

272
|
9 Risk assessments
where the payoff Pij is associated with the pair (ai, sj) (i = 1, 2; j = 1, 2, 3). The deci-
sion tree is represented by
Decision
Chance
Consequence
a1
a2
s1
s2
s3
s1
s2
s3
P11 = 200
P12 = 110
P13 = −15
P21 = 100
P22 = 50
P23 = 5.
Assume that p(s1) = 0.4, p(s2) = 0.5, and p(s3) = 0.1.
Consider the EMV measure. The expected values of proﬁts for a1 and a2 are, re-
spectively,
E[a1] =
3
∑
j=1
p(sj)P1j
= 0.4 × 200 + 0.5 × 110 + 0.1 × (−15)
= 80 + 55 −1.5 = 133.5;
E[a2] =
3
∑
j=1
p(sj)P2j
= 0.4 × 100 + 0.5 × 50 + 0.1 × 5
= 40 + 25 + 0.5 = 65.5.
Thus, the EMV measure is
EMV = max
1≤i≤2
3
∑
j=1
p(sj)Pij = max(E[a1], E[a2]) = max(133, 500, 65, 000) = 133, 500.
The decision tree with expected value of proﬁts is represented by
Decision
Chance
Consequence
a1
a2
s1
s2
s3
s1
s2
s3
0.4 × 200
+0.5 × 110
+0.1 × (−15) = 133.5
0.4 × 100
+0.5 × 50
+0.1 × 5 = 65.5.

9.2 Decision trees
|
273
Consider EOL measure. By Mj = max1≤i≤2{Pij} (j = 1, 2, 3), we get
M1 = max
1≤i≤2(P11, P21) = max(200, 100) = 200,
M2 = max
1≤i≤2(P12, P22) = max(110, 50) = 110,
M3 = max
1≤i≤2(P13, P23) = max(−15, 5) = 5.
By using ∑3
j=1 p(sj)(Mj −Pij) (i = 1, 2), we get
3
∑
j=1
p(sj)(Mj −P1j) = 0.4 × (200 −200) + 0.5 × (110 −110) + 0.1 × (5 −(−15))
= 0.4 × 0 + 0.5 × 0 + 0.1 × 20
= 0 + 0 + 2 = 2
for i = 1;
3
∑
j=1
p(sj)(Mj −P2j) = 0.4 × (200 −100) + 0.5 × (110 −50) + 0.1 × (5 −5)
= 0.4 × 100 + 0.5 × 60 + 0.1 × 0
= 40 + 30 + 0 = 70
for i = 2.
Thus, the EOL measure is
EOL = min
1≤i≤2
3
∑
j=1
p(sj)(Mj −Pij) = min(2, 70) = 2.
The decision tree with EOL measure is represented by
Decision
Chance
Consequence
a1
a2
s1
s2
s3
s1
s2
s3
0.4 × 0
+0.5 × 0
+0.1 × 20 = 2
0.4 × 100
+0.5 × 60
+0.1 × 0 = 70.
Consider the MLV measure.
For i = 1, the highest probability is max1≤j≤3 p(sj) = 0.5. The corresponding proﬁt is
P12 = 110.
For i = 2, the highest probability is max1≤j≤3 p(sj) = 0.5. The corresponding proﬁt is
P22 = 50.
Thus, the measure is MLV = max(110, 50) = 110.

274
|
9 Risk assessments
9.3 Fractile and triangular methods
The fractile method is used for assessing probability distributions.
A probability distribution can be represented by a cumulative distribution func-
tion (cdf) given by
F(x) =
x
∫
a
f(t) dt
(a < x < b),
where f(t) is a density function and the interval (a, b) is often chosen as one of the
three intervals (0, 1), (0, ∞), and (−∞, ∞). It is seen from this representation that if
the density function is continuous on the interval [a, b] and f(t) > 0 (a < t < b), then
the cdf F(x) is a smooth, positive, strictly increasing function, and the cdf tends to 0
as x tends to a and the cdf tends to 1 as x tends to b. It is well known that the values
of the cdf can be interpreted as the probabilities of events
F(x) = P(a < θ < x)
(a < x < b).
The probabilities on the intervals a ≤θ < x, a < θ ≤x, a ≤θ ≤x, and a < θ < x are
the same, i.e.,
P(a < θ < x) = P(a ≤θ < x) = P(a < θ ≤x) = P(a ≤θ ≤x).
Deﬁnition 9.3.1. Given a probability p (0 ≤p ≤1), let xp denote that value of x so
that
F(xp) = P(a < θ < xp) =
xp
∫
a
f(t) dt = p.
The value xp is called the p-th fractile of θ.
Assume that f(t) > 0 (a < t < b). Then
F(a) = P(θ = a) = P(a < θ < a) =
a
∫
a
f(t) dt = 0,
F(b) = P(a < θ < b) =
b
∫
a
f(t) dt = 1,
and according to the strictly increasing property of the cdf, the value xp is uniquely
deﬁned.
Especially, the 0.5-th fractile x0.5 is called the median of θ; the 0.25-th fractile
x0.25 is called the lower quartile of θ; and the 0.75-th fractile x0.75 is called the upper
quartile of θ.

9.3 Fractile and triangular methods
|
275
For these three fractiles x0.25, x0.5, x0.75, noticing that ∫
b
a f(t) dt = 1, it follows from
Deﬁnition 9.3.1 that
P(a < θ < x0.5) =
x0.5
∫
a
f(t) dt = 0.5,
P(x0.5 < θ < b) =
b
∫
x0.5
f(t) dt =
b
∫
a
f(t) dt −
x0.5
∫
a
f(t) dt = 1 −0.5 = 0.5,
P(a < x < x0.25) =
x0.25
∫
a
f(t) dt = 0.25,
P(x0.25 < θ < x0.5) =
x0.5
∫
x0.25
f(t) dt =
x0.5
∫
a
f(t) dt −
x0.25
∫
a
f(t) dt = 0.5 −0.25 = 0.25,
P(x0.5 < x < x0.75) =
x0.75
∫
x0.5
f(t) dt =
x0.75
∫
a
f(t) dt −
x0.5
∫
a
f(t) dt = 0.75 −0.5 = 0.25,
P(x0.75 < θ < b) =
b
∫
x0.75
f(t) dt =
b
∫
a
f(t) dt −
x0.75
∫
a
f(t) dt = 1 −0.75 = 0.25.
So the three fractiles x0.25, x0.5, x0.75 have the following probability property:
P(a < θ < x0.5) = P(x0.5 < θ < b),
P(a < x < x0.25) = P(x0.25 < θ < x0.5) = P(x0.5 < x < x0.75) = P(x0.75 < θ < b).
These equalities are such that the decision maker often directly assesses these three
fractiles and the cdf will have the assessed fractiles, i.e., F(x0.25) = 0.25, F(x0.5) = 0.5,
F(x0.75) = 0.75.
The graphical method
Assume that the decision maker has assessed these three fractiles and the points
(x0.25, 0.25) and (x0.5, 0.5), and (x0.75, 0.75) are speciﬁed. The question is now,
how to determine a cdf F(x) whose graph passes through the given points.
Establish an oxp-rectangular coordinate system on a sheet of graph paper, where
the vertical op-axis is the probability axis and the horizontal ox-axis is the frac-
tile axis. In the oxp-rectangular coordinate system, plot the three assessed points
(x0.25, 0.25), (x0.5, 0.5), (x0.75, 0.75) and two end points (a, 0), (b, 1), and then use
the cdf’s smooth property and strictly increasing property to draw a graph through
the plotted points. The cdf F(x) is obtained graphically.

276
|
9 Risk assessments
The analytical method
In this method, the decision maker assumes that the considered probability distribu-
tion belongs to some parametric family of distributions, and then the decision maker
chooses values for the parameters so that the resulting cdf will have the assessed
fractiles.
9.3.1 Assessing a normal distribution
The decision maker ﬁrst assumes that the considered probability distribution belongs
to the family of normal distributions. Denote by fN(t) a normal density function with
parameters μ and σ2
fN(t) =
1
√2πσ2 e−(t−μ)2
2σ2 ,
where μ is the expected value and σ2 is the variance.
Secondly, the decision maker chooses values for parameters μ and σ2 so that the
resulting normal cdf
FN(x) =
x
∫
−∞
1
√2πσ2 e−(t−μ)2
2σ2 dt
satisﬁes FN(x0.25) = 0.25, FN(x0.5) = 0.5, and FN(x0.75) = 0.75.
It follows from Deﬁnition 9.3.1 that
FN(x0.5) = P(−∞< θ < x0.5) =
x0.5
∫
−∞
1
√2πσ2 e−(t−μ)2
2σ2 dt = 0.5.
Note that
∞
∫
x0.5
1
√2πσ2 e−(t−μ)2
2σ2 dt =
∞
∫
−∞
1
√2πσ2 e−(t−μ)2
2σ2 dt −
x0.5
∫
−∞
1
√2πσ2 e−(t−μ)2
2σ2 dt.
= 1 −0.5 = 0.5.
So
x0.5
∫
−∞
1
√2πσ2 e−(t−μ)2
2σ2 dt =
∞
∫
x0.5
1
√2πσ2 e−(t−μ)2
2σ2 dt.
By the change of variables u = t−μ
σ , this implies that
x0.5−μ
σ
∫
−∞
1
√2π
e−u2
2 du =
∞
∫
x0.5−μ
σ
1
√2π
e−u2
2 du.

9.3 Fractile and triangular methods
|
277
Since the integrand e−u2
2 is an even function,
x0.5 −μ
σ
= 0
or
μ = x0.5,
i.e., the parameter μ (i.e., the expected value) is chosen to be the 0.5-th fractile x0.5.
It follows from Deﬁnition 9.3.1 and μ = x0.5 that
FN(x0.75) = P(−∞< θ < x0.75) =
x0.75
∫
−∞
1
√2πσ2 e−(t−x0.5)2
2σ2
dt = 0.75.
By the change of variables u = t−x0.5
σ
, this implies that
x0.75
∫
−∞
1
√2πσ2 e−(t−x0.5)2
2σ2
dt =
x0.75−x0.5
σ
∫
−∞
1
√2π
e−u2
2 du.
and so
x0.75−x0.5
σ
∫
−∞
1
√2π
e−u2
2 du = 0.75.
(9.3.1)
The integrand e−u2
2
is the standard normal density function. However the upper
quartile of the standard normal density function can be found in a statistical table to
be 0.674. So
x0.75 −x0.5
σ
= 0.674
or
σ2 = (x0.75 −x0.5)2
(0.674)2
= 2.20 (x0.75 −x0.5)2.
i.e., the parameter σ2 (i.e., the variance) is chosen to be 2.20 times the square of the
difference between the 0.75-th fractile and the 0.5-th fractile.
It follows from Deﬁnition 9.3.1 and μ = x0.5 that
FN(x0.25) = P(−∞< θ < x0.25) =
x0.25
∫
−∞
1
√2πσ2 e−(t−x0.5)2
2σ2
dt = 0.25.
By the change of variables u = x0.5−t
σ
, this implies that
x0.25
∫
−∞
1
√2πσ2 e−(t−x0.5)2
2σ2
dt =
∞
∫
x0.5−x0.25
σ
1
√2π
e−u2
2 du,
and so
∞
∫
x0.5−x0.25
σ
1
√2π
e−u2
2 du = 0.25.
(9.3.2)

278
|
9 Risk assessments
On the other hand, by (9.3.1) and ∫
∞
−∞
1
√2π e−u2
2 du = 1,
∞
∫
x0.75−x0.5
σ
1
√2π
e−u2
2 du =
∞
∫
−∞
1
√2π
e−u2
2 du −
x0.75−x0.5
σ
∫
−∞
1
√2π
e−u2
2 du = 0.25.
From this and (9.3.2),
∞
∫
x0.5−x0.25
σ
1
√2π
e−u2
2 du =
∞
∫
x0.75−x0.5
σ
1
√2π
e−u2
2 du.
So
x0.5 −x0.25 = x0.75 −x0.5,
i.e., the distance between the 0.5-th fractile and the 0.25-th fractile, x0.5 −x0.25, is
equal to the distance between the 0.75-th fractile and the 0.5-th fractile, x0.75 −x0.5.
So the parameter σ2 (i.e., the variance) may be also chosen to be 2.20 times the square
of the difference between the 0.5-th fractile and the 0.25-th fractile
σ2 = 2.20 (x0.5 −x0.25)2.
9.3.2 Assessing a beta prior distribution
The decision maker assumes ﬁrst that the considered probability distribution belongs
to the beta family of distributions. Denote by fβ(t) the beta density function with pa-
rameters r0 and n0
fβ(t) =
1
B(r0, n0) tr0−1(1 −t)n0−r0−1
(0 ≤t ≤1),
where r0 > 0 and n0 > 0 and B(r0, n0) is a beta function
B(r0, n0) =
1
∫
0
tr0−1(1 −t)n0−r0−1 dt.
Secondly, the decision maker chooses values for parameters r0 and n0 so that the
resulting beta cdf
Fβ(x) =
x
∫
0
fβ(t) dt = B(r0, n0)−1
x
∫
0
tr0−1(1 −t)n0−r0−1 dt
(0 ≤x ≤1)
satisﬁes Fβ(x0.25) = 0.25, Fβ(x0.5) = 0.5, and Fβ(x0.75) = 0.75. Generally speaking,
this will not be possible. To satisfy them approximately, the decision maker considers
the error function
E(r0, n0) = (Fβ(x0.25) −0.25)2 + (Fβ(x0.5) −0.5)2 + (Fβ(x0.75) −0.75)2
and uses a computer code to calculate values r0 and n0 that minimize E(r0, n0).

9.3 Fractile and triangular methods
|
279
The triangular distribution method is another ideal method. This method qualiﬁes
a triangle as a probability density function.
Let the area of the triangle be equal to 1. Denote by a and b the lowest and high-
est values of the outcome, respectively, and denote by c the most likely value of the
outcome. The base of the triangle is equal to b −a and its height is the frequency p(c)
of the most likely value. So
1
2(b −a)p(c) = 1,
and so the frequency of the most likely value of the outcome is given by
p(c) =
2
b −a .
Law and Kelton presented that the cdf P(x) and pdf p(x) of the triangular distribution
for a continuous random variable X are as follows:
P(x) = P(X ≤x) =
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
0
(x < a),
(x−a)2
(b−a)(c−a)
(a ≤x ≤c),
1 −
(b−x)2
(b−a)(b−c)
(c < x ≤b),
1
(x > b)
and
p(x) =
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
0
(x < a),
2(x−a)
(b−a)(c−a)
(a ≤x ≤c),
2(b−x)
(b−a)(b−c)
(c < x ≤b),
0
(x > b),
where p(x) =
d
dx P(x).
The expected value of the triangular distribution is
E[X] = a + b + c
3
.
In fact, by the deﬁnition, the expected value of the triangular distribution is
E[x] =
∞
∫
−∞
xp(x) dx
=
2
(b −a)(c −a)
c
∫
a
(x2 −ax) dx +
2
(b −a)(b −c)
b
∫
c
(bx −x2) dx.
However,
c
∫
a
(x2 −ax) dx = c3 −a3
3
−a(c2 −a2)
2
,
b
∫
c
(bx −x2) dx = b3 −bc2
2
−b3 −c3
3
.

280
|
9 Risk assessments
Therefore, the expected value of the triangular distribution is
E[x] =
2
(b −a)(c −a) ( c3 −a3
3
−a(c2 −a2)
2
)
+
2
(b −a)(b −c) ( b3 −bc2
2
−b3 −c3
3
)
= 2c2 −ac −a2
3(b −a)
+ b2 + bc −2c2
3(b −a)
= a + b + c
3
.
The variance of the triangular distribution is
Var(X) = a2 + b2 + c2 −ab −ac −bc
18
.
In fact, by the deﬁnition, the variance of the triangular distribution is
Var(X) = E[(x −E[X])2]
=
∞
∫
−∞
(x2 −2xE[X] + (E[X])2)p(x) dx
=
∞
∫
−∞
x2p(x) dx −2E[X]
∞
∫
−∞
xp(x) dx + (E[X])2
∞
∫
−∞
p(x) dx
= I1 −2E[X]I2 + (E[X])2I3.
(9.3.3)
These three integrals I1, I2, and I3 are computed as follows:
I1 =
∞
∫
−∞
x2p(x) dx
=
2
(b −a)(c −a)
c
∫
a
(x3 −ax2) dx +
2
(b −a)(b −c)
b
∫
c
(bx2 −x3) dx
=
2
(b −a)(c −a) ( c4 −a4
4
−a(c3 −a3)
3
) +
2
(b −a)(b −c) ( b(b3 −c3)
3
−b4 −c4
4
)
=
2
b −a ( a3 −b3 + c(a2 −b2) + c2(a −b)
4
+ b3 −a3 + c(b2 −a2) + c2(b −a)
3
)
= a2 + b2 + c2 + ab + bc + ac
6
,

9.3 Fractile and triangular methods
|
281
I2 =
∞
∫
−∞
xp(x) dx
=
c
∫
a
2
(b −a)(c −a)(x2 −ax) dx +
b
∫
c
2
(b −a)(b −c)(bx −x2) dx
=
2
(b −a)(c −a) ( c3 −a3
3
−a(c2 −a2)
2
) +
2
(b −a)(b −c) ( b(b2 −c2)
2
−b3 −c3
3
)
=
2
b −a ( a2 −b2 + c(a −b)
3
+ (b2 −a2) + c(b −a)
2
)
= a + b + c
3
,
and
I3 =
∞
∫
−∞
p(x) dx
=
c
∫
a
2
(b −a)(c −a)(x −a) dx +
b
∫
c
2
(b −a)(b −c)(b −x) dx
=
2
(b −a)(c −a) ( c2 −a2
2
−a(c −a)) +
2
(b −a)(b −c) (b(b −c) −b2 −c2
2
)
=
2
b −a ( c + a
2
−a) +
2
b −a (b −b + c
2
)
=
2
b −a ( c −a
2
+ b −c
2
) = 1.
Note that E[X] = a+b+c
3
. By (9.3.3), the variance of the triangular distribution is
Var(X) = I1 −2E[X]I2 + (E[X])2I3
= a2 + b2 + c2 + ab + bc + ac
6
−2E[X] ( a + b + c
3
) + (E[X])2
= a2 + b2 + c2 + ab + bc + ac
6
−2(a + b + c)2
9
+ (a + b + c)2
9
= a2 + b2 + c2 −ab −ac −bc
18
.
Example 9.3.2. Given the pdf p(x) of the triangular distribution as above, compute
the value of the conditional expected risk functions
g( ⋅) =
∫
b
β xp(x) dx
∫
b
β p(x) dx
,
where β > c.

282
|
9 Risk assessments
Solution. Since β > c, p(x) =
2(b−x)
(b−a)(b−c) , and so
g(⋅) =
∫
b
β xp(x) dx
∫
b
β p(x) dx
=
∫
b
β x(b −x) dx
∫
b
β (b −x) dx
.
The numerator is
b
∫
β
x(b −x) dx = b3 −bβ2
2
−b3 −β3
3
and the denominator is
b
∫
β
(b −x) dx = b2 −bβ −b2 −β2
2
.
Thus, the conditional expected risk functions are
g( ⋅) =
b3−bβ2
2
−b3−β3
3
b2 −bβ −b2−β2
2
=
b(b+β)
2
−b2+bβ+β2
3
b −b+β
2
= b2 −β2 + bβ −β2
3(b −β)
= b + 2β
3
.
9.4 The ε-constraint method
Let fi : ℝn →ℝ(i = 1, . . . , N) and ci : ℝn →ℝ(i = 1, . . . , m) all be continuously
differentiable functions. The model of the form
min
x { f1(x), . . . , fN(x) }
subject to
ci(x) ≤0
(i = 1, . . . , m)
(9.4.1)
is called an multiobjective optimization model. Haimes et al. presented the ε-constraint
method and showed that the model (9.4.1) is equivalent to the ε-constraint optimiza-
tion model of the form
min
x∈X fi(x)
subject to
fj(x) ≤εj
(j
̸= i; j = 1, 2, . . . , N),
(9.4.2)
where εj (j
̸= i, j = 1, . . . , N) are variables and
X = { x ∈ℝn | ci(x) ≤0 (i = 1, . . . , m) },
εj = min
x∈X fj(x) + ϵj,
ϵj > 0
(j
̸= i; j = 1, . . . , N).
From (9.4.2), it is seen that the ε-constraint optimization model replaces N −1 ob-
jective functions in (9.4.1) by N −1 constraints, i.e., one objective fi(x) is the principal
objective, all others fj(x) (j
̸= i; j = 1, . . . , N) are the constraining objectives.

9.4 The ε-constraint method
|
283
The generalized Lagrange function corresponding to the ε-constraint optimiza-
tion model is given by
L(x; λ) = fi(x) + ∑
j ̸=i
i,j=1,...,N
λij(fj(x) −εj),
where λij are called generalized Lagrange multipliers and the positive Lagrange multi-
plies λij are called the trade-off functions between the principal objective fi(x) and the
constraining objective fj(x) (j
̸= i; i, j = 1, . . . , N). The trade-off function corresponds
to the noninferior set of solutions, so this concept is very important.
Example 9.4.1. Let
f1(x1, x2) = (x1 −1)2 + (x2 −2)2 + 1,
f2(x1, x2) = (x1 −4)2 + (x2 −5)2 + 4.
Consider a biobjective optimization model
min
(x1,x2){ f1(x1, x2), f2(x1, x2) },
subject to
the restriction:
x1 ≥0, x2 ≥0.
Let f1(x1, x2) be the principal objective and f2(x1, x2) the constraining objective. Then
this model is equivalent to the following ε-constraint optimization model:
min
(x1,x2)∈X f1(x1, x2)
subject to
f2(x1, x2) ≤ε2
((x1, x2) ∈X),
where X = { (x1, x2) | x1 ≥0, x2 ≥0 }.
The corresponding generalized Lagrange function is given by
L(x1, x2; λ12) = f1(x1, x2) + λ12(f2(x1, x2) −ε2)
= (x1 −1)2 + (x2 −2)2 + 1 + λ12((x1 −4)2 + (x2 −5)2 + 4 −ε2).
Differentiating both sides with respect to x1 and x2, respectively,
∂L
∂x1
= 2(x1 −1) + 2λ12(x1 −4),
∂L
∂x2
= 2(x2 −2) + 2λ12(x2 −5).
Let ∂L
∂xi = 0 (i = 1, 2). Then
2(x1 −1) + 2λ12(x1 −4) = 0,
2(x2 −2) + 2λ12(x2 −5) = 0.
This implies that the trade-off function λ12 between f1(x1, x2) and f2(x1, x2) satisﬁes
λ12 = x1 −1
4 −x1
,
λ12 = x2 −2
5 −x2
.
(9.4.3)

284
|
9 Risk assessments
From (9.4.3) and λ12 > 0, it follows that the decision variables x1 and x2 satisfy
1 < x1 < 4,
2 < x2 < 5.
Several noninferior solutions and trade-off values of the biobjective optimization
model are listed in the following table.
x1
x2
f1(x1, x2)
f2(x1, x2)
λ12
1.5
2.5
1.5
16.5
0.2
2
3
3
12
0.5
2.5
3.5
5.5
8.5
1
3
4
9
6
2
3.5
4.5
13.5
4.5
5
From (9.4.3), it follows that x2 = x1 + 1. So the Pareto-optimal solutions in the decision
space are determined by the equation x2 = x1 + 1 (1 < x1 < 4), i.e., a line segment
jointing two points (1, 2) and (4, 5).
Example 9.4.2. Let
f1(x1, x2) = (x1 −1)2 + (x2 −2)2 + 1,
f2(x1, x2) = (x1 −4)2 + (x2 −5)2 + 4,
f3(x1, x2) = (x1 −6)2 + (x2 −10)2 + 1.
A three-objective optimization model is given as
min
(x1,x2) { f1(x1, x2), f2(x1, x2), f3(x1, x2) },
subject to
x1 ≥0, x2 ≥0.
Let f1(x1, x2) be the principal objective and f2(x1, x2), f3(x1, x2) the constraining
objectives. This model is equivalent to the following ε-constraint optimization model:
min
(x1,x2)∈X f1(x1, x2)
subject to
f2(x1, x2) ≤ε2,
f3(x1, x2) ≤ε3
((x1, x2) ∈X),
where X = {(x1, x2) | x1 ≥0, x2 ≥0}. The corresponding generalized Lagrange function
is given by
L(x1, x2; λ12, λ13) = f1(x1, x2) + λ12(f2(x1, x2) −ε2) + λ13(f3(x1, x2) −ε3)
= (x1 −1)2 + (x2 −2)2 + 1 + λ12((x1 −4)2 + (x2 −5)2 + 4 −ε2)
+ λ13((x1 −6)2 + (x2 −10)2 + 1 −ε3).

9.4 The ε-constraint method
|
285
Differentiating both sides with respect to x1 and x2, respectively,
∂L
∂x1
= 2(x1 −1) + 2λ12(x1 −4) + 2λ13(x1 −6),
∂L
∂x2
= 2(x2 −2) + 2λ12(x2 −5) + 2λ13(x2 −10).
Let ∂L
∂xi = 0 (i = 1, 2). Then
2(x1 −1) + 2λ12(x1 −4) + 2λ13(x1 −6) = 0,
2(x2 −2) + 2λ12(x2 −5) + 2λ13(x2 −10) = 0.
This implies that the trade-off functions λ12 and λ13 satisfy
λ12 = −8x1 + 5x2 −2
5x1 −2x2 −10 ,
λ13 = 3x1 −3x2 + 3
5x1 −2x2 −10 .
(9.4.4)
Secondly, let f2(x1, x2) be the principal objective and f1(x1, x2), f3(x1, x2) be
the constraining objectives. Then the given three-objective optimization model is also
equivalent to the following ε-constraint optimization model:
min
(x1,x2)∈X f2(x1, x2)
subject to
f1(x1, x2) ≤ε1,
f3(x1, x2) ≤ε3
((x1, x2) ∈X).
The corresponding generalized Lagrange function is given by
L(x1, x2; λ21, λ23) = f2(x1, x2) + λ21(f1(x1, x2) −ε1) + λ23(f3(x1, x2) −ε3)
= (x1 −4)2 + (x2 −5)2 + 4 + λ21((x1 −1)2 + (x2 −2)2 + 1 −ε1)
+ λ23((x1 −6)2 + (x2 −10)2 + 1 −ε3).
Let ∂L
∂xi = 0 (i = 1, 2). Then
2(x1 −4) + 2λ21(x1 −1) + 2λ23(x1 −6) = 0,
2(x2 −5) + 2λ21(x2 −2) + 2λ23(x2 −10) = 0.
This implies that the trade-off functions λ21 and λ23 satisfy
λ21 = 5x1 −2x2 −10
−8x1 + 5x2 −2 ,
λ23 = 3x1 −3x2 + 3
−8x1 + 5x2 −2 .
(9.4.5)

286
|
9 Risk assessments
Third, let f3(x1, x2) be the principal objective and f1(x1, x2), f2(x1, x2) the con-
straining objectives. Then the given three-objective optimization model is also equiv-
alent to the following ε-constraint optimization model:
min
(x1,x2)∈X f3(x1, x2)
subject to
f1(x1, x2) ≤ε1,
f2(x1, x2) ≤ε2
((x1, x2) ∈X).
The corresponding generalized Lagrange function is given by
L(x1, x2; λ31, λ32) = f3(x1, x2) + λ31(f1(x1, x2) −ε1) + λ32(f2(x1, x2) −ε2)
= (x1 −6)2 + (x2 −10)2 + 1 + λ31((x1 −1)2 + (x2 −2)2 + 1 −ε1)
+ λ32((x1 −4)2 + (x2 −5)2 + 4 −ε2).
Let ∂L
∂xi = 0 (i = 1, 2). Then
2(x1 −6) + 2λ31(x1 −1) + 2λ32(x1 −4) = 0,
2(x2 −10) + 2λ31(x2 −2) + 2λ32(x2 −5) = 0.
This implies that the trade-off functions λ31 and λ32 satisfy
λ31 = 5x1 −2x2 −10
3x1 −3x2 + 3 ,
λ32 = −8x1 + 5x2 −2
3x1 −3x2 + 3 .
(9.4.6)
The combination of (9.4.4) and (9.4.5), and (9.4.6) gives
λ12 =
1
λ21
,
λ13 =
1
λ31
,
λ23 =
1
λ32
,
λ13 = λ12λ23,
λ23 = λ21λ13.
Several noninferior solutions and trade-off values of the given three-objective opti-
mization model are listed in the following table.
x1
x2
f1
f2
f3
λ12
λ13
λ21
λ23
λ31
λ32
2
3.2
3.44
11.24
63.24
0.31
0.09
3.2
0.3
10.67
3.33
3
5
14
5
35
0.2
0.6
5
3
1.67
0.33
4
6
26
5
21
2
1.5
0.5
0.75
0.67
1.33
5
8
53
14
6
2
6
0.5
3
0.17
0.33
From (9.4.4), (9.4.5), and (9.4.6), the Pareto-optimal solution in the decision space is a
triangle determined by the system of inequalities

9.5 The uncertainty sensitivity index method
|
287
{
{
{
{
{
{
{
{
{
x2 > x1 + 1,
x2 > 5
2 x1 −5,
x2 < 8
5 x1 + 2
5 ,
i.e., a triangle with three vertices (1, 2), (4, 5), and (6, 10).
Examples 9.4.1 and 9.4.2 indicate that they both have two common objective functions,
but by adding the third objective function in Example 9.4.2, a large number of Pareto-
optimal solutions have been added.
9.5 The uncertainty sensitivity index method
Uncertainty and sensitivity are two characteristics of systems. Uncertainty is deﬁned
as the inability to determine the true state of affairs of a system. It is caused by
stochastic variability and incomplete knowledge. Taylor shows that the variability
uncertainty arises from temporal, spatial, and individually heterogeneous variability.
Finkel shows that knowledge about uncertainty comes from model, parameter, and
decision uncertainty. Sensitivity is deﬁned as the relation between changes in the
system’s performance index and possible variations in decision variables, constraint
levels, and uncontrolled parameters. The Uncertainty Sensitivity Index Method (USIM)
presented by Li and Haimes is a uncertainty-sensitivity analysis method. This method
represents the uncertainty associated with potential variations of the system’s param-
eter by a system’s output sensitivity index. The USIM is intrinsic to considering a joint
optimality and sensitivity multiobjective model.
Let
y = h(x; α)
be the system’s output response, where x is a vector consisting of n decision control
variables and α is a vector consisting of m uncertain random system parameters
x = (x1, . . . , xn),
α = (α1, . . . , αm),
and y ∈ℝis differentiable with respect to x and α. Let
f(x; y; α) = f(x; h(x; α); α)
be the system’s objective function.
Denote the nominal value of α by
̂α = ( ̂α1, . . . , ̂αm). The nominal values
̂αi (i =
1, . . . , m) may be determined by any system’s identiﬁcation procedure. Assume that
the m uncertain random system parameters α1, . . . , αm vary in the neighborhood of
their nominal value ( ̂α1, . . . , ̂αm). The Taylor theorem shows that
h(x; ̂α1 + ∆̂α1, . . . , ̂αm + ∆̂αm) ≈h(x; ̂α1, . . . , ̂αm) +
m
∑
1
∂h(x; ̂α1, . . . , ̂αm)
∂̂αi
∆̂αi,

288
|
9 Risk assessments
where ∆̂αi is a small variation in the nominal value
̂αi. Thus, associated with varia-
tions in the parameters, the variation of the system’s output is equal approximately
to
m
∑
1
∂h(x; ̂α1, . . . , ̂αm)
∂̂αi
∆̂αi.
and the square of the variation satisﬁes the Cauchy–Schwarz inequality
(
m
∑
1
∂h(x; ̂α1, . . . , ̂αm)
∂̂αi
∆̂αi)
2
≤
m
∑
1
( ∂h(x; ̂α1, . . . , ̂αm)
∂̂αi
)
2
⋅
m
∑
1
(∆̂αi)2 .
In order to reduce this variation, a control scenario x is chosen such that
m
∑
1
( ∂h(x; ̂α1, . . . , ̂αm)
∂̂αi
)
2
is minimal. Deﬁne a sensitivity index function as
s(x; ̂α) =
m
∑
1
( ∂h(x; ̂α1, . . . , ̂αm)
∂̂αi
)
2
.
The multiobjective optimization model of the form
min
x { f(x; h(x; ̂α); ̂α), s(x; ̂α) }
is called a joint optimality and sensitivity multiobjective model. Let f(x; h(x;
̂α);
̂α)
be the principal objective and s(x;
̂α) be the constraining objective. Using the ε-
constraint method, the joint optimality and sensitivity multiobjective optimization
model is equivalent to the ε-constraint optimization model of the form
min
x f(x; h(x; ̂α); ̂α)
subject to
s(x; ̂α) ≤ε.
The corresponding generalized Lagrangian function is given by
L(x; ̂α; λfs) = f(x; h(x; ̂α); ̂α) + λfs(s(x; ̂α) −ε),
where λfs is the generalized Lagrange multiplier. Differentiating both sides with re-
spect to xi,
∂L
∂xi
= ∂f(x; h(x; ̂α); ̂α)
∂xi
+ λfs
∂s(x; ̂α)
∂xi
(i = 1, . . . , n),
(9.5.1)
where x = (x1, . . . , xn) and λfs is the trade-off function between the system’s objective
function f(x; h(x; ̂α); ̂α) and the sensitivity index function s(x; ̂α). Let
∂L
∂xi = 0 (i =
1, . . . , n). Then
∂f(x; h(x; ̂α); ̂α)
∂xi
+ λfs
∂s(x; ̂α)
∂xi
= 0
(i = 1, . . . , n)

9.5 The uncertainty sensitivity index method
|
289
or
λfs = −
( ∂f(x;h(x; ̂α); ̂α)
∂xi
)
( ∂s(x; ̂α)
∂xi
)
(i = 1, . . . , n).
From this and λfs > 0, the set of noninferior solutions can be determined by the sys-
tems of inequalities
{
{
{
∂f(x;h(x; ̂α); ̂α)
∂xi
> 0,
∂s(x; ̂α)
∂xi
< 0
or
{
{
{
∂f(x;h(x; ̂α); ̂α)
∂xi
< 0,
∂s(x; ̂α)
∂xi
> 0.
Let x∗be a decision variable which minimizes the system’s objective function
f(x; h(x; ̂α); ̂α), i.e.,
f(x∗; h(x∗; ̂α); ̂α) = min
x
f(x; h(x; ̂α); ̂α),
and let
̂x be another decision variable which minimizes the sensitivity index function
s(x; ̂α), i.e.,
s( ̂x; ̂α) = min
x
s(x; ̂α).
The most conservative policy
̂x provides a very stable solution, whereas the conven-
tional solution x∗suffers the highest deviation. Based on the preference of the deci-
sion maker, the best compromise solution may be selected from the noninferior solu-
tion set { ̂x ≤x ≤x∗}.
Example 9.5.1. Consider a system that has the following output response and objec-
tive function:
h(x; α) = (α2
1 + α2
2 + α2
3 + α2
4)x,
f(x; h(x; α); α) = x2 −2(α1α2
2 + α1α2
3 + α1α2
4 + α2α2
3 + α2α2
4 + α3α2
4)x
+ α2
1α2 + α2
1α3 + α2
1α4 + α2
2α3 + α2
2α4 + α2
3α4,
where x is the one-dimensional decision variable and α is a vector consisting of four
uncertain random system parameters α1, α2, α3, α4. The system’s sensitivity index
function is
s(x; α) =
4
∑
1
( ∂h(x; α1, α2, α3, α4)
∂αi
)
2
= 4 (α2
1 + α2
2 + α2
3 + α2
4)x.
Assume that the nominal values
̂α1, ̂α2, ̂α3, ̂α4 of the system’s parameters α1, α2, α3,
α4 are, respectively,
̂α1 = 1,
̂α2 = 2,
̂α3 = 1,
̂α4 = 2.

290
|
9 Risk assessments
Then
h(x; ̂α1, ̂α2, ̂α3, ̂α4) = h(x; 1, 2, 1, 2) = 10x,
f(x; h(x; ̂α1, ̂α2, ̂α3, ̂α4); ̂α1, ̂α2, ̂α3, ̂α4) = f(x; h(x; 1, 2, 1, 2); 1, 2, 1, 2)
= x2 −23x + 19
s(x; ̂α1, ̂α2, ̂α3, ̂α4) = s(x; 1, 2, 1, 2) = 40x2.
(9.5.2)
When the nominal values
̂α1, ̂α2, ̂α3, ̂α4 are perturbed by ∆̂α1, ∆̂α2, ∆̂α3, ∆̂α4 and
∆̂α1 = ∆̂α2 = ∆̂α3 = ∆̂α4 = 0.1,
the variation of the system’s output response is
∆h = (
4
∑
1
( ̂αi + ∆̂αi)2) x −(
4
∑
1
α2
i ) x =
4
∑
1
(2 ̂αi∆̂αi + (∆̂αi)2) x = 1.24 x.
(9.5.3)
The joint optimality and sensitivity multiobjective model is the form
min
x
{
{
{
f(x; h(x; ̂α1, ̂α2, ̂α3, ̂α4); ̂α1, ̂α2, ̂α3, ̂α4) = x2 −23x + 19
s(x; ̂α1, ̂α2, ̂α3, ̂α4) = 40x2
Using the ε-constraint method, this model is equivalent to the following ε-constraint
optimization model:
min
x { f(x; h(x; ̂α1, ̂α2, ̂α3, ̂α4); ̂α1, ̂α2, ̂α3, ̂α4) = x2 −23x + 19 }
subject to the ε −constraint:
s(x; ̂α1, ̂α2, ̂α3, ̂α4) = 40x2 ≤ε.
The corresponding generalized Lagrangian function is given by
L(x, ̂α1, ̂α2, ̂α3, ̂α4, λfs) = f(x; h(x; ̂α1, ̂α2, ̂α3, ̂α4); ̂α1, ̂α2, ̂α3, ̂α4)
+ λfs(s(x; ̂α1, ̂α2, ̂α3, ̂α4) −ε)
= (x2 −23x + 19) + λ12(40x2 −ε),
where λfs is the trade-off between the system’s objective function and system’s sensi-
tivity index function. Let ∂L
∂x = 0. Then 2x −23 + λfs80x = 0, i.e.,
λfs = −2x −23
80x
.
From this and λfs > 0, it follows that
{
{
{
2x −23 > 0,
80x < 0
or
{
{
{
2x −23 < 0,
80x > 0.
So the set of noninferior solutions is 0 ≤x ≤11.5.

9.6 The partitioned multiobjective risk method
|
291
By (9.5.2) and (9.5.3), a sample of noninferior solutions of the joint optimality and
sensitivity model, the corresponding values of the system’s objective function f , the
system’s sensitivity index function s, the trade-off λfs, the system’s output response
h, and its variation ∆h are listed in the following table.
x
0
4
8
10
11.5
f
19
−57
−101
−111
−113.25
s
0
640
2560
4000
5290
λfs
∞
0.0456
0.0109
0.00375
0
h
0
40
80
100
115
∆h
0
4.96
9.92
12.4
14.26
Let x∗be a decision variable which minimizes f(x, h(x; ̂α1, . . . , ̂αn); ̂α1, . . . , ̂αn), and
let
̂x be another decision variable which minimizes s(x; ̂α1, . . . , ̂αn), i.e.,
f(x∗; h(x∗; ̂α1, ̂α2, ̂α3, ̂α4); ̂α1, ̂α2, ̂α3, ̂α4) = min
x
f(x; h(x; ̂α1, . . . , ̂αn); ̂α1, ̂α2, ̂α3, ̂α4),
s( ̂x; ̂α1, ̂α2, ̂α3, ̂α4) = min
x
s(x; ̂α1, ̂α2, ̂α3, ̂α4).
(9.5.4)
From (9.5.2), it follows that
f(x, h(x, ̂α1, ̂α2, ̂α3, ̂α4); ̂α1, ̂α2, ̂α3, ̂α4) = x2 −23x + 19 = (x −11.5)2 −113.25,
s(x; ̂α1, ̂α2, ̂α3, ̂α4) = 40x2.
The combination of this with (9.5.4) gives
x∗= 11.5,
̂x = 0.
Thus, the best compromise solution can be selected from the noninferior solution set
{ 0 ≤x ≤11.5 }.
9.6 The partitioned multiobjective risk method
The Partitioned Multiobjective Risk (PMR) method is a risk analysis method. In the PMR
method, the concept of the traditional expected value of damage is extended to gen-
erate a number of conditional expected value functions (or conditional expected risk
functions), each associated with a particular range of exceedance probabilities (or the
corresponding range of damage severities). The resulting conditional expected risk
functions, together with the traditional expected value of damage, provide a family of
risk measures associated with a particular policy.

292
|
9 Risk assessments
Let a damage severity associated with a particular policy sj (j = 1, . . . , m) be rep-
resented by the continuous random variable Xj (j = 1, . . . , m), and Pj(x) and pj(x)
denote the cdf and the pdf of damage, respectively. Let 1 −αi (i = 1, . . . , n) denote
n exceedance probabilities, where 0 < α1 < ⋅⋅⋅< αn < 1. For the policy sj, there is
a unique damage βj
i (i = 1, . . . , n) on the damage axis that corresponds to the ex-
ceedance probability 1 −αi (i = 1, . . . , n) on the probability axis. Thus, the partition
of the probability axis
[0, 1 −αn],
[1 −αn, 1 −αn−1],
. . . ,
[1 −α1, 1]
corresponds the partition of the damage axis
[βj
0, βj
1],
[βj
1, βj
2],
. . . ,
[βj
n, βj
n+1],
where βj
0 and βj
n+1 are the lower bound and upper bound of damage, respectively. The
policies sj, the exceedance probabilities 1 −αi, and the bounds βj
i of damage ranges
satisfy the relationship
Pj(βj
1) = 1 −α1,
...
Pj(βj
n) = 1 −αn.
If the inverse P−1
j (x) exists, then
P−1
j (1 −α1) = βj
1,
...
P−1
j (1 −αn) = βj
n.
The conditional expected risk functions fi(sj) (i = 2, . . . , n + 2) of the damage are
given by
f2(sj) = E[ Xj | pj(x), x ∈[βj
0, βj
1] ] =
∫
βj
1
βj
0
xpj(x) dx
∫
βj
1
βj
0
pj(x) dx
,
f3(sj) = E[ Xj | pj(x), x ∈[βj
3, βj
4] ] =
∫
βj
2
βj
1
xpj(x) dx
∫
βj
2
βj
1
pj(x) dx
,
...
fn+2(sj) = E[ Xj | pj(x), x ∈[βj
n, βj
n+1] ] =
∫
βj
n+1
βj
n
xpj(x) dx
∫
βj
n+1
βj
n
pj(x) dx
.

9.6 The partitioned multiobjective risk method
|
293
The unconditional excepted risk function fn+3(sj) of the damage is given by
fn+3(sj) = E[Xj] =
∫
βj
n+1
βj
0
xpj(x) dx
∫
βj
n+1
βj
0
pj(x) dx
.
Since the total probability of the damage is equal to 1, i.e.,
∫
βj
n+1
βj
0
pj(x) dx = 1,
the unconditional excepted risk function of the damage is
fn+3(sj) = ∫
βj
n+1
βj
0
xpj(x) dx.
Denote their denominators by qi (i = 2, . . . , n + 2), respectively, i.e.,
q2 = ∫
βj
1
β0j
pj(x) dx,
q3 = ∫
βj
2
βj
1
pj(x) dx,
...
qn+2 = ∫
βj
n+1
βj
n
pj(x) dx,
where qi > 0 (i = 2, . . . , n + 2) and q2 + ⋅⋅⋅+ qn+2 = 1. So the conditional expected
risk functions fi (i = 2, . . . , n + 2) and the unconditional expected risk function fn+3
satisfy the balance relationship
fn+3(sj) = q2f2(sj) + q3f3(sj) + ⋅⋅⋅+ qn+2fn+2(sj) =
n+2
∑
2
qifi(sj).
Let f1(sj) denote the cost objective function.
Combining any one of the conditional expected risk functions or the uncondi-
tional excepted risk function with the cost objective function constitutes a set of biob-
jective optimization models, i.e.,
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
min{ f1(sj), f2(sj) },
...
min{ f1(sj), fn+2(sj) },
min{ f1(sj), fn+3(sj) }.

294
|
9 Risk assessments
These n + 2 biobjective optimization models can offer more information about the
probabilistic behavior than the single biobjective optimization model min{ f1(sj),
fn+3(sj) }.
Let f1(sj) be the principal objective and fi(sj) (i = 2, . . . , n + 2) the constrain-
ing objective. The above n + 2 biobjective optimization models can be transformed
into the n + 2 equivalent ε-constraint optimization models and the trade-offs λ1i (i =
2, . . . , n + 3) between the cost function f1 and risk functions fi (i = 2, . . . , n + 3)
satisfy
1
λ1,n+3
= q2
λ12
+ q3
λ13
+ ⋅⋅⋅+ qn+2
λ1,n+2
=
n+2
∑
2
qi
λ1i
,
where λ1i = −∂f1
∂fi (i = 2, . . . , n + 3) and qi (i = 2, . . . , n + 2) are stated as above.
9.7 The multiobjective multistage impact analysis method
A general deﬁnition of impact is the effect of one thing upon another. For impact anal-
ysis in a multiobjective framework, Gomide developed a theoretical basis. He formu-
lated a multiobjective multistage optimization model and presented the Multiobjective
Multistage Impact Analysis (MMIA) method.
Let g: ℝn × ℝr →ℝn be a continuously differentiable function. Assume that the
evolution of a system in stages can be represented by a multistage process
x(0) = x0,
x(k + 1) = g(x(k), u(k); k)
(k = 0, . . . , T −1),
where x(k) ∈ℝn is the system’s state at stage k and u(k) ∈ℝr is the decision at stage
k, and T is the horizon of interest to the system’s decision maker. Denote by F the
universe of objectives of interest to the system
F = { f k
i (x(k), u(k); k),
i = 1, 2, . . . , Nk; k = 0, . . . , T −1 },
where Nk is the number of objectives considered as important for stage k, and f k
i are
continuously differentiable functions. Assume further that Ωk (k = 0, . . . , T) are spec-
iﬁed by a system of inequality constraints
Ωk = { (x(k), u(k)): h(x(k), u(k); k) ≤0 }
(k = 0, . . . , T −1),
ΩT = { x(T): h(x(T); T) ≤0 },
where h(x(k), u(k); k) : ℝn × ℝr →ℝmk (k = 0, . . . , T −1) and h(x(k); T) : ℝn →ℝmT
are both continuously differentiable functions. The Multiobjective Multistage Impact
Analysis (MMIA) model is the form

9.7 The multiobjective multistage impact analysis method
|
295
min
u
{
{
{
{
{
{
{
f 0
1 (x, u; 0)
...
f k
N0(x, u; 0)
}
}
}
}
}
}
}
,
. . . ,
min
u
{
{
{
{
{
{
{
f T−1
1
(x, u; T −1)
...
f k
NT−1(x, u; T −1)
}
}
}
}
}
}
}
subject to
x(0) = x0,
x(k + 1) = g(x(k), u(k); k)
(k = 0, . . . , T −1),
where
(x(k), u(k)) ∈Ωk ⊂ℝn × ℝr
(k = 0, . . . , T −1),
x(T) ∈ΩT ⊂ℝn.
From this, it is seen that the meaning of the MMIA model is to solve a sequence of static
or single-stage multiobjective optimization models where decisions made at stage k
affect stages k + 1, k + 2, . . . , T −1.
Gomide and Haimes characterized noninferior policy decisions for the MMIA
model. To obtain noninferior solutions, the MMIA model is converted into a series of
single-objective models using the ε-constraint method as follows.
Let
X = (x(0), . . . , x(T)),
U = (u(0), . . . , u(T −1))
and
𝕂= { 0, . . . , T −1 },
ℕk = { 1, . . . , Nk }
(k = 0, . . . , T −1)
and let Ω= ⋃T
k=0 Ωk. Using the ε-constraint method, the MMIA model is represented
as
min
U f t
s(x(t), u(t); t)
subject to
(X, U) ∈(Ω⋂(Γt
s(ε) ⋃Γτ
s,t(ε)) ⋂V) ,
where
Γt
s(ε) = { (X, U): f t
i (x(t), u(t); t) ≤εt
i
for all i ∈ℕt (i
̸= s), t ∈𝕂},
Γτ
s,t(ε) = { (X, U): f τ
i (x(τ), u(τ); τ) ≤ετ
i
for all i ∈ℕτ,
for all τ ∈𝕂(τ
̸= t) },
V = { (X, U): x(k + 1) = g(x(k), u(k); k) (k = 0, . . . , T −1), x(0) = x0 }
and ε ∈Ys with
ε = { ε0
1, . . . , ε0
N0, . . . , εt−1
1
, . . . , εt−1
Nt−1, εt
1, . . . , εt
s−1εt
s+1, . . . , εt
Nt, . . . ,
εt+1
1
, . . . , εt+1
Nt+1, . . . , εT−1
1
, . . . , εT−1
NT−1 },
Ys = { ε: (Γt
s(ε) ⋃Γτ
s,t(ε))
̸= 0 }.
Gomide and Haimes proved that if a policy decision is the unique solution of the
ε-constraint problem, then it is a noninferior policy decision. Conversely, any non-
inferior policy decision solves the ε-constraint problem.

296
|
9 Risk assessments
9.8 Multiobjective risk impact analysis method
The PMR method is a risk analysis method. The MMIA method is an impact analysis
method. The Multiobjective Risk Impact Analysis (MRIA) method is a combination of
the MMIA method with the PMR method.
Let x(k) and y(k) be two normally distributed random variables. Assume that x(k)
represents the system’s state and y(k) represents the system’s output, both at stage k,
and
x(k + 1) = Ax(k) + Bu(k) + w(k),
x(0) = x0,
y(k) = Cx(k) + υ(k)
(k = 0, . . . , T −1),
(9.8.1)
where A, B, C are system parameters, u(k) is the decision, and w(k), υ(k) are two nor-
mally distributed, purely random sequences. Assume further that the system satisﬁes
the following statistical properties:
for 0 ≤k, l ≤T −1,
{
{
{
{
{
{
{
{
{
{
{
{
{
E[x(0)] = x0,
E[(x(0) −x0)2] = X0,
E[(x(0) −x0)υ(k)] = 0,
E[(x(0) −x0)w(k)] = 0
and
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
E[υ(k)] = 0,
E[w(k)] = 0,
E[υ2(k)] = Q(k) = Q,
E[w2(k)] = P(k) = P,
E[υ(k)υ(l)] = 0
(k
̸= l),
E[w(k)w(l)] = 0
(k
̸= l),
E[w(k)υ(l)] = 0.
Proposition 9.8.1. Under the above assumption, the mean of y(k) satisﬁes that
E[y(k)] = CAkx0 +
k−1
∑
i=0
CAiBu(k −1 −i).
Proof. Note that E(w(k)) = 0 and E(υ(k)) = 0. Since u(k) is constant, it follows by
(9.8.1) that
E[x(k + 1)] = E[Ax(k) + Bu(k) + w(k)]
= AE[x(k)] + BE[u(k)] + E[w(k)] = AE[x(k)] + Bu(k),
E[y(k)] = E[Cx(k) + υ(k)] = CE[x(k)] + E[υ(k)] = CE[x(k)].
(9.8.2)

9.8 Multiobjective risk impact analysis method
|
297
Now we prove by induction that the mean of x(k) satisﬁes that
E[x(k)] = Akx0 +
k−1
∑
i=0
AiBu(k −1 −i).
(9.8.3)
In the case k = 0. By (9.8.2) and E[x(0)] = x0, it follows that
E[x(1)] = AE[x(0)] + Bu(0) = Ax0 + Bu(0),
i.e., (9.8.3) holds clearly for k = 0.
Assume for k that
E[x(k)] = Akx0 +
k−1
∑
i=0
AiBu(k −1 −i).
(9.8.4)
Prove that (9.8.3) holds for k + 1.
By (9.8.2) and (9.8.4), it follows that
E[x(k + 1)] = AE[x(k)] + Bu(k)
= A (Akx0 +
k−1
∑
i=0
AiBu(k −1 −i)) + Bu(k)
= Ak+1x0 +
k−1
∑
i=0
Ai+1Bu(k −1 −i) + Bu(k).
Let j = 1 + i. Note that Bu(k) = A0Bu(k −0) since A0 = 1 and B(k) = B(k −0). Then
E[x(k + 1)] = Ak+1x0 +
k
∑
j=1
AjBu(k −j) + Bu(k) = Ak+1x0 +
k
∑
j=0
AjBu(k −j),
i.e., (9.8.3) holds for k + 1.
Finally, by (9.8.2) and (9.8.3), a direct computation deduces that
E[y(k)] = CE[x(k)] = CAkx0 +
k−1
∑
i=0
CAiBu(k −1 −i).
Proposition 9.8.2. Under the above assumption, the variances of y(k) satisfy that
Var(y(k)) = C2A2kX0 +
k−1
∑
i=0
C2A2iP + Q.
Proof. It is clear by (9.8.1) that
Var(y(k)) = Var(Cx(k)) + Var(υ(k)).
A direct computation shows that
Var(Cx(k)) = E[C2x2(k)] −(E[Cx(k)])2 = C2 (E[x2(k)] −(E[x(k)])2) = C2 Var(x(k)).

298
|
9 Risk assessments
By E[υ2(k)] = Q and E[υ(k)] = 0, it follows that Var(υ(k)) = E(υ2(k)) −(E[υ(k)])2 = Q.
Thus,
Var(y(k)) = C2 Var(x(k)) + Q.
(9.8.5)
Similarly, by (9.8.1), it is clear that
Var(x(k + 1)) = Var(Ax(k)) + Var(Bu(k)) + Var(w(k)).
A direct computation shows that
Var(Ax(k)) = E[A2x2(k)] −(E[Ax(k)])2 = A2(E[x2(k)] −(E[x(k)])2) = A2 Var(x(k)).
Since B and u(k) are constants,
Var(Bu(k)) = E[B2u2(k)] −(E[Bu(k)])2 = B2u2(k) −(Bu(k))2 = 0.
By E[w(k)] = 0 and E[w2(k)] = P, it follows that Var(w(k)) = E[w2(k)] −(E[w(k)])2 = P.
Thus,
Var(x(k + 1)) = A2 Var(x(k)) + P.
(9.8.6)
Now we prove by induction that the variance of x(k) satisﬁes that
Var(x(k)) = A2kX0 +
k−1
∑
i=0
A2iP.
(9.8.7)
In the case k = 0. From (9.8.6), it follows that
Var(x(1)) = A2 Var(x(0)) + P = A2 (E[x2(0)] −(E[x(0)])2) + P.
By E[(x(0) −x0)2] = X0 and E[x(0)] = x0, and E[x2
0] = x2
0, it follows that
E[x2(0)] = E[((x(0) −x0)2 + 2x(0)x0 −x2
0)]
= E[(x(0) −x0)2] + 2x0E[x(0)] −E[x2
0] = X0 + x2
0,
(E[x(0)])2 = x2
0.
Thus,
Var(x(1)) = A2(X0 + x2
0 −x2
0) + P = A2X0 + P,
i.e., (9.8.7) holds for k = 0.
Assume for k that
Var(x(k)) = A2kX0 +
k−1
∑
i=0
A2iP.
(9.8.8)
Prove that (9.8.7) holds for k + 1.
By (9.8.6) and (9.8.8), it follows that
Var(x(k + 1)) = A2 Var(x(k)) + P
= A2 (A2kX0 +
k−1
∑
i=0
A2iP) + P
= A2(k+1)X0 +
k−1
∑
i=0
A2(i+1)P + P.

9.8 Multiobjective risk impact analysis method
|
299
Let j = 1 + i. Then
Var(x(k + 1)) = A2(k+1)X0 +
k
∑
j=1
A2jP + P = A2(k+1)X0 +
k
∑
j=0
A2jP,
i.e., (9.8.7) holds for k + 1.
Finally, by (9.8.5) and (9.8.8), a direct computation shows that
Var(y(k)) = C2A2kX0 +
k−1
∑
i=0
C2A2iP + Q.
From Propositions 9.8.1 and 9.8.2, it is seen that E[y(k)] is dependent on k and u,
while Var(y(k)) is only dependent on k. Thus, E[y(k)] and Var(y(k)) may be denoted
by μy(k, u) and σ2
y(k), respectively, i.e.,
μy(k, u) := E[y(k)],
σ2
y(k) := Var(y(k)).
Let y(k) be the damage and its pdf p(y) be the normal distribution
p(y) := p(y(k)) =
1
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
),
where σy(k) is the positive square root of Var(y(k)). Correspondingly,
–
f k
1(u) represents the cost objective function of y(k) at stage k;
–
f k
j (u) (j = 2, . . . , Nk + 2) represents the j-th conditional expected risk function of
y(k) at stage k and
f k
j (u) =
∫
βk
j−1
βk
j−2 y(k)p(y(k)) dy(k)
∫
βk
j−1
βk
j−2 p(y(k)) dy(k)
=
∫
βk
j−1
βk
j−2
y(k)
√2πσy(k) exp (−1
2 ( y(k)−μy(k,u)
σy(k)
)
2
) dy(k)
∫
βk
j−1
βk
j−2
1
√2πσy(k) exp (−1
2 ( y(k)−μy(k,u)
σy(k)
)
2
) dy(k)
;
(9.8.9)
–
f k
Nk+3(u) represents the unconditional excepted risk function of y(k) at stage k
and
f k
Nk+3(u) =
∫
βk
Nk+1
βk
0
y(k)p(y(k)) dy(k)
∫
βk
Nk+1
βk
0
p(y(k)) dy(k)
=
∫
βk
Nk+1
βk
0
y(k)
√2πσy(k) exp (−1
2 ( y(k)−μy(k,u)
σy(k)
)
2
) dy(k)
∫
βk
Nk+1
βk
0
1
√2πσy(k) exp (−1
2 ( y(k)−μy(k,u)
σy(k)
)
2
) dy(k)
,
(9.8.10)
where Nk is the number of partitions for the probability exceedance axis at stage
k, βk
0 = −∞and βk
Nk+1 = ∞are the lower and upper bounds of the damage at stage
k, respectively, and βk
j (j = 1, . . . , Nk) are the partitioned points of the damage at
stage k. Denote the dominator of (9.8.9) by qk
j , i.e.,
qk
j = ∫
βk
j−1
βk
j−2
1
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k)
(j = 2, . . . , Nk + 2).

300
|
9 Risk assessments
By (9.8.9) and (9.8.10), it follows that
f k
Nk+3(u) = qk
2f k
2(u) + ⋅⋅⋅+ qk
Nk+2f k
Nk+2(u) =
Nk+2
∑
j=2
qk
j f k
j (u),
where qk
j > 0 and qk
2 + ⋅⋅⋅+ qk
Nk+2 = ∑Nk+2
j=2
qk
j = 1.
The f k
j (u) (j = 2, . . . , Nk + 2) is computed as follows.
Note that y(k) = μy(k, u) + (y(k) −μy(k, u)). The numerator of (9.8.9) becomes
∫
βk
j−1
βk
j−2
y(k)
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k)
= ∫
βk
j−1
βk
j−2
μy(k, u)
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k)
+ ∫
βk
j−1
βk
j−2
y(k) −μy(k, u)
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k).
Let τ = y(k)−μy(k,u)
σy(k)
and dτ = dy(k)
σy(k) . Then
∫
βk
j−1
βk
j−2
μy(k, u)
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k) = μy(k, u) ∫
αk
j−1
αk
j−2
1
√2π
e−τ2
2 dτ,
∫
βk
j−1
βk
j−2
(y(k) −μy(k, u))
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k) = σy(k) ∫
αk
j−1
αk
j−2
τ
√2π
e−τ2
2 dτ,
where
αk
j−i =
βk
j−i −μy(k, u)
σy(k)
(j = 2, . . . , Nk + 2; i = 1, 2),
(9.8.11)
and so the numerator of (9.8.9) becomes
∫
βk
j−1
βk
j−2
y(k)
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k)
= μy(k, u) ∫
αk
j−1
αk
j−2
1
√2π
e−τ2
2 dτ + σy(k) ∫
αk
j−1
αk
j−2
τ
√2π
e−τ2
2 dτ.
Similarly, the denominator of (9.8.9) becomes
∫
βk
j−1
βk
j−2
1
√2π σy(k)
exp (−1
2 ( y(k) −μy(k, u)
σy(k)
)
2
) dy(k) = ∫
αk
j−1
αk
j−2
1
√2π
e−τ2
2 dτ.
Therefore, the j-th conditional expected risk function of the damage at stage k be-
comes
f k
j (u) = μy(k, u) + σy(k)bk
j
(j = 2, . . . , Nk + 2),
(9.8.12)

9.8 Multiobjective risk impact analysis method
|
301
where
bk
j =
∫
αk
j−1
αk
j−2 τe−τ2
2 dτ
∫
αk
j−1
αk
j−2 e−τ2
2 dτ
(j = 2, . . . , Nk + 2)
(9.8.13)
and αk
j−i is stated in (9.8.11).
Similarly, the f k
Nk+3(u) is computed as follows:
f k
Nk+3(u) =
μy(k, u) ∫
βk
Nk+1
βk
0
1
√2π e−τ2
2 dτ + σy(k) ∫
βk
Nk+1
βk
0
τ
√2π e−τ2
2 dτ
∫
βk
Nk+1
βk
0
1
√2π e−τ2
2 dτ
.
Note that βk
0 = −∞and βk
Nk+1 = ∞. Since e−τ2
2 is an even function and τe−τ2
2 is an odd
function,
∞
∫
−∞
1
√2π
e−τ2
2 dτ = 1,
∞
∫
−∞
τ
√2π
e−τ2
2 dτ = 0,
and so
f k
Nk+3(u) =
μy(k, u) ∫
∞
−∞
1
√2π e−τ2
2 dτ + σy(k) ∫
∞
−∞
τ
√2π e−τ2
2 dτ
∫
∞
−∞
1
√2π e−τ2
2 dτ
= μy(k, u),
(9.8.14)
i.e., the unconditional excepted risk function of the damage at stage k is equal to the
mean of the damage.
Note that σy(k) is independent of u and bk
j (j = 2, . . . , Nk + 2) is constant. Then
min
u { f k
j (u) } = min
u { μy(k, u) + bk
j σy(k) }
= bk
j σy(k) + min
u { μy(k, u) }
(j = 2, . . . , Nk + 2),
i.e., the minimizing of any one of the conditional excepted risk functions is reduced
to minimizing the mean of the damage.
Combining the cost objective function with any one of the risk functions (the con-
ditional or the unconditional) constitutes a set of biobjective optimization problems
at stage k, i.e.,
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
min{ f k
1(u), f k
2(u) },
...
min{ f k
1(u), f k
Nk+2(u) },
min{ f k
1(u), f k
Nk+3(u) }.

302
|
9 Risk assessments
These biobjective optimization problems can be solved using the ε-constraint method.
The trade-off functions λk
1j between the cost objective function f k
1(u) and the risk func-
tion f k
j (u) both at stage k are given by
λk
1j = −∂f k
1
∂f k
j
(j = 2, . . . , Nk + 3).
For j = 2, . . . , Nk + 2, since σy(k) is independent of u and bk
j is constant, by (9.8.12),
it follows that
∂f k
j (u) = ∂(μy(k, u) + σy(k) bk
j ) = ∂μy(k, u),
and for j = Nk + 3, by (9.8.14), it is clear that
∂f k
Nk+3(u) = ∂μy(k, u).
Thus, the trade-off functions λk
1j between the cost function f k
1(u) and the risk function
f k
j (u) at stage k are
λk
1j = −∂f k
1
∂μy
(j = 2, . . . , Nk + 3),
i.e., all trade-offs for the given stage k are equal. Therefore, for the normal distribution,
the risk functions of the damage at stage k are parallel curves. This greatly simpliﬁes
the multiobjective optimization.
Example 9.8.3. Let Nk = 2 and αk
0 = −∞, αk
1 = −1, αk
2 = 1, αk
3 = ∞in (9.8.11). Denote
Φ(x) :=
1
√2π
x
∫
−∞
e−τ2
2 dτ.
By (9.8.13),
bk
2 =
∫
−1
−∞τe−τ2
2 dτ
√2π Φ(−1)
= −
e−1
2
√2π Φ(−1)
= −0.24197
0.158655 = −1.52514,
bk
3 =
∫
1
−1 τe−τ2
2 dτ
√2π (Φ(1) −Φ(−1))
= 0,
bk
4 =
∫
∞
1 τe−τ2
2 dτ
√2π(1 −Φ(1))
=
e−1
2
√2πΦ(−1)
= 0.24197
0.158655 = 1.52514.
Then, by (9.8.12), the conditional expected risk functions at stage k are
f k
2(u) = μy(k, u) + σy(k)bk
2 = μy(k, u) −1.52514 σy(k),
f k
3(u) = μy(k, u) + σy(k)bk
3 = μy(k, u),
f k
4(u) = μy(k, u) + σy(k)bk
4 = μy(k, u) + 1.52514 σy(k),
(9.8.15)

9.8 Multiobjective risk impact analysis method
|
303
where σy(k) is the positive square root of σ2
y(k). By Propositions 9.8.1 and 9.8.2,
μy(k, u) and σ2
y(k) satisfy the following:
μy(k, u) = CAkx0 +
k−1
∑
i=0
CAiBu(k −1 −i),
σ2
y(k) = C2A2kX0 +
k−1
∑
i=0
C2A2iP + R.
(9.8.16)
Assume that for one scenario,
A = 1.02,
B = −0.01,
C = 1,
P = 200,
R = 0,
x0 = 100,
X0 = 100,
u(0) = 200,
u(1) = 150.
We will ﬁnd the values of conditional expected risk functions at stage k (k = 1, 2).
For k = 1, by (9.8.16),
μy(1, u) = (1.02)1(100) −(1.02)0(0.01)(200) = 100,
σ2
y(1) = (1.02)2(100) + (1.02)0(200) = 304.04,
σy(1) = √304.04 = 17.4.
From this and (9.8.15), we get
f 1
2 (u) = 100 −(1.52514)(17.4) = 73.46
f 1
3 (u) = 100,
f 1
4 (u) = 100 + (1.52514)(17.4) = 126.54.
For k = 2, by (9.8.16),
μy(2, u) = (1.02)2(100) −(1.02)0(0.01)(150) −(1.02)(0.01)(200) = 100.5,
σ2
y(2) = (1.02)4(100) + (1.02)0(200) + (1.02)2(200) = 516.32,
σy(2) = √516.32 = 22.7.
From this and (9.8.15), we get
f 2
2 (u) = 100.5 −(1.52514)(22.7) = 65.88
f 2
3 (u) = 100.5,
f 2
4 (u) = 100.5 + (1.52514)(22.7) = 135.12.
These values are summarized in the following table.
Scenario
k = 1
k = 2
f k
2
73.46
65.88
f k
3
100
100.5
f k
4
126.54
135.12

304
|
9 Risk assessments
9.9 The Leslie model
In the simplest population dynamics model of a state variable, let
–
p(t) represent the level of population at time t (t = 0, 1, . . . );
–
B and D be the numbers of births and deaths in any one year, respectively;
–
b(t) and d(t) represent birth and death rates for the time between t and t + 1 (t =
0, 1, . . . ), respectively.
Clearly,
B = b(t)p(t),
D = d(t)p(t).
Assume that the population level p(0) is known, and that the birth and death rates do
not change with time, i.e., b(t) = b and d(t) = d. Then population growth from t to
t + 1 is balanced as follows:
p(t + 1) = p(t) + B −D = p(t)r,
(9.9.1)
where r = 1 + b −d is the overall growth rate. Meyer calls it the Malthusian parameter.
For any t (t ∈ℤ+), it follows from (9.9.1) that
p(t) = p(t −1)r = p(t −2)r2 = ⋅⋅⋅= p(0)rt,
(9.9.2)
i.e., the growth rate of the population can be represented by an exponential function,
thus the simplest population dynamics model of a state variable is called an exponen-
tial model.
Example 9.9.1. Assume that the current worker population in a small factory is
70 workers, and that the rate of increasing due to new hiring has been 0.04 and
the rate of leaving the factory has been 0.02. How many workers will be at that
factory in 5 years? How many years will it take for the number of workers to double?
Solution. By the assumption, p(0) = 70, b = 0.04, d = 0.02, and r = 1 + b −d = 1.02.
By (9.9.2),
p(5) = p(0)r5 = (70)(1.02)5 ≈(70)(1.104) ≈77.
Thus the number of workers in 5 years is about 77. Let t be the number of years until
doubling. Then p(t) = 2p(0). From this and (9.9.2),
p(0)rt = 2p(0)
or
2 = (1.02)t.
The solution is t = ln2/ln(1.02) ≈35, i.e., the number of years of doubling is about 35.

9.9 The Leslie model
|
305
The simpliﬁed version of the Leslie model adapted by Meyer is as follows. In the Leslie
model, only the female population is considered and the female population is divided
into n age categories
[0, ∆),
[∆, 2∆),
. . . ,
[(n −1)∆, n∆),
where ∆is the width of each age interval of the population, and deﬁne
–
Fi(t) is the number of females in the age interval [i∆, (i + 1)∆),
–
mi is the ∆-year maternity rate for the age interval [i∆, (i + 1)∆),
–
pi is the survival rate in the age interval [i∆, (i + 1)∆),
where i = 0, 1, . . . , n −1.
The female population of the i-th age group at the next t + ∆period is given by
Fi+1(t + ∆) = piFi(t)
(t = 0, ∆, 2∆, . . . ).
The number of newborns at the lowest age group at time (t + ∆) is given by
F0(t + ∆) =
n−1
∑
0
miFi(t).
The combination of these two equations gives
(
(
(
F0(t + ∆)
F1(t + ∆)
F2(t + ∆)
...
Fn−1(t + ∆)
)
)
)
= (
(
(
m0
m1
m2
⋅⋅⋅
⋅⋅⋅
mn−1
p0
0
0
⋅⋅⋅
⋅⋅⋅
0
0
p1
0
⋅⋅⋅
⋅⋅⋅
0
...
...
...
⋅⋅⋅
⋅⋅⋅
...
0
0
0
⋅⋅⋅
pn−2
0
)
)
)
(
(
(
F0(t)
F1(t)
F2(t)
...
Fn−1(t)
)
)
)
.
Its matrix form is
F(t + ∆) = MF(t),
(9.9.3)
where
F(t) = (
(
(
F0(t)
F1(t)
F2(t)
...
Fn−1(t)
)
)
)
M = (
(
(
m0
m1
m2
⋅⋅⋅
⋅⋅⋅
mn−1
p0
0
0
⋅⋅⋅
⋅⋅⋅
0
0
p1
0
⋅⋅⋅
⋅⋅⋅
0
...
...
...
⋅⋅⋅
⋅⋅⋅
...
0
0
0
⋅⋅⋅
pn−2
0
)
)
)
.
The vector F is called the age distribution vector and the n × n matrix M is called the
Leslie matrix.
For any k (k ∈ℤ+), it follows from (9.9.3) that
F(k∆) = MF((k −1)∆) = ⋅⋅⋅= MkF(0)
(k ∈ℤ+).

306
|
9 Risk assessments
Example 9.9.2. Based on an observation, the population, the maternity rate, and the
survival rate of female birds are given by the following:
F0(0) = 100,
F1(0) = 60,
F2(0) = 40,
m0 = 0,
m1 = 3,
m2 = 1,
p0 = 1
2 ,
p1 = 3
4 ,
p2 = 0.
Find the age distribution vectors F(∆) and F(2∆).
Solution. The initial vector and the Leslie matrix are, respectively,
F(0) = (
F0(0)
F1(0)
F2(0)
) = (
100
60
40
) ,
M = (
0
3
1
1
2
0
0
0
3
4
0
) .
To ﬁnd F(∆), by F(∆) = MF(0), we get
F(∆) = M (
F0(0)
F1(0)
F2(0)
) = (
0
3
1
1
2
0
0
0
3
4
0
) (
100
60
40
) = (
220
50
45
) ,
To ﬁnd F(2∆), by F(2∆) = MF(∆), we get
F(2∆) = (
0
3
1
1
2
0
0
0
3
4
0
) (
220
50
45
) = (
195
110
37.5
)
or by F(2∆) = M2F(0), noticing that
M2 = (
0
3
1
1
2
0
0
0
3
4
0
)
2
= (
3
2
3
4
0
0
3
2
1
2
3
8
0
0
) ,
we get
F(2∆) = (
3
2
3
4
0
0
3
2
1
2
3
8
0
0
) (
100
60
40
) = (
195
110
37.5
) .
Example 9.9.3. Suppose that the numbers of females, the maternity rates, and the
survival rates in the age intervals are given as follows:
F0(0) = 50,
F1(0) = 30,
F2(0) = 20,
F3(0) = 10,
m0 = 0,
m1 = 1,
m2 = 2,
m3 = 3
p0 = 3
4 ,
p1 = 1
2 ,
p2 = 1
2 .
Find the age distribution vectors F(∆) and F(2∆).

9.10 Leontief’s and inoperability input-output models
|
307
Solution. The initial vector and the Leslie matrix are, respectively,
F(0) = (
F0(0)
F1(0)
F2(0)
F3(0)
) = (
50
30
20
10
) ,
M = (
0
1
2
3
3
4
0
0
0
0
1
2
0
0
0
0
1
2
0
) .
To ﬁnd F(∆), by F(∆) = MF(0), we get
F(∆) = M (
F0(0)
F1(0)
F2(0)
F3(0)
) = (
0
1
2
3
3
4
0
0
0
0
1
2
0
0
0
0
1
2
0
) (
50
30
20
10
) = (
100
37.5
15
10
) ,
To ﬁnd F(2∆), by F(2∆) = MF(∆), we get
F(2∆) = (
0
1
2
3
3
4
0
0
0
0
1
2
0
0
0
0
1
2
0
) (
100
37.5
15
10
) = (
97.5
75
18.75
7.5
) ,
or by F(2∆) = M2F(0), noticing that
M2 = (
0
1
2
3
3
4
0
0
0
0
1
2
0
0
0
0
1
2
0
)
2
= (
3
4
1
3
2
0
0
3
4
3
2
9
4
3
8
0
0
0
0
1
4
0
0
) ,
we get
F(2∆) = (
3
4
1
3
2
0
0
3
4
3
2
9
4
3
8
0
0
0
0
1
4
0
0
) (
50
30
20
10
) = (
97.5
75
18.75
7.5
) .
9.10 Leontief’s and inoperability input-output models
Leontief’s input-output model studies the equilibrium state of an economy consisting
of a number of individual economic sectors. The inoperability input-output model pre-
sented by Haimes and Jiang studies the equilibrium state of a system consisting of n
critical complex intra- and interconnected infrastructures. Although the equations of
these two models are the same, they connote different meanings.
In Leontief’s input-output model, deﬁne the following notations:
–
xi is the output (for the total economy) of the i-th goods, i = 1, . . . , n;
–
rk is the input (for the total economy) of the k-th resource, k = 1, . . . , m;

308
|
9 Risk assessments
–
xij is the amount of the i-th goods used in the production of the j-th goods;
–
rkj is the amount of the k-th resource input used in the production of the j-th
goods;
–
ci is the i-th input for the production of other commodities, i = 1, . . . , n;
Assume that the inputs of both goods and resources required to produce any commod-
ity are proportional to the output of that commodity, i.e.,
xij = aijxj
(i, j = 1, . . . , n),
rkj = bkjxj
(k = 1, . . . , m; j = 1, . . . , n).
These two equations are called Leontief’s proportionality equations of goods and re-
source, respectively. The equation
xi =
n
∑
j=1
xij + ci
(i = 1, . . . , n).
is called the Leontief-based equation. The combination of the proportionality equation
of goods with the Leontief-based equation gives the following Leontief equation:
xi =
n
∑
j=1
aijxj + ci
(i = 1, . . . , n)
which is written in a matrix form x = Ax + c, where x = (x1, . . . , xn)T and c =
(c1, . . . , cn)T, and
A = (
a11
⋅⋅⋅
a1n
...
...
...
an1
⋅⋅⋅
ann
) .
Similarly, applying the proportionality assumption of the resources gives
n
∑
j=1
rkj =
n
∑
j=1
bkjxj
(k = 1, . . . , m).
Since the demand for the k-th resource cannot exceed its supply, then
n
∑
j=1
bkjxj ≤rk,
rk ≥0
(k = 1, . . . , m).
In the Inoperability Input-Output Model (IIM), deﬁne the following notations:
–
xi is the overall risk of inoperability of the i-th intra- and interconnected infras-
tructure that can be triggered by one or multiple failures caused by accidents or
acts of terrorism, i = 1, . . . , n;
–
xij is the degree of inoperability triggered by one or multiple failures that the j-th
infrastructure can contribute to the i-th infrastructure due to their complex intra-
and interconnectedness, i, j = 1, . . . , n;

9.10 Leontief’s and inoperability input-output models
|
309
–
aij is the probability of inoperability that the j-th infrastructure contributes to the
i-th infrastructure;
–
ci is the natural or man-made perturbation into the i-th critical infrastructure,
i = 1, . . . , n;
and assume that
xij = aijxj
(i, j = 1, . . . , n).
This equation is called the proportionality equation of IIM. The equation
xi =
n
∑
j=1
xij + ci
(i = 1, . . . , n).
is called the balance equation of IIM. The combination of the proportionality equation
with the balance equation gives that
xi =
n
∑
j=1
aijxj + ci
(i = 1, . . . , n)
which is called the inoperability equation of IIM. Its matrix form is x = Ax + c, where
x = (x1, . . . , xn)T, c = (c1, . . . , cn)T, and the A-matrix is
A = (
a11
⋅⋅⋅
a1n
...
...
...
an1
⋅⋅⋅
ann
) .
Example 9.10.1. Assume that a system consists of three subsystems. Denote by x1, x2,
x3 the inoperability of these three subsystems. If Subsystem 1 fails completely, then
Subsystems 2 and 3 can perform to only 40 % and 75 %, respectively, of their function-
ality. If Subsystem 2 fails completely, then Subsystems 1 and 3 can perform to only
20 % and 10 %, respectively, of their functionality. Assume that the inoperability of
three subsystems has no impact on each other. Thus, the A-matrix for the system is
A = (
0
0.8
0
0.6
0
0
0.25
0.9
0
) .
Assume that Subsystem 2 loses 40 % of its functionality due to an external perturba-
tion. The inoperability equation of IIM is
(
x1
x2
x3
) = (
0
0.8
0
0.6
0
0
0.25
0.9
0
) (
x1
x2
x3
) + (
0
0.4
0
) = (
0.8x2
0.6x1 + 0.4
0.25x1 + 0.9x2
)
or
{
{
{
{
{
{
{
{
{
x1 = 0.8x2,
x2 = 0.6x1 + 0.4,
x3 = 0.25x1 + 0.9x2.

310
|
9 Risk assessments
Solving this set of equations gives
x1 = 8
13 ≈0.615,
x2 = 10
13 ≈0.769,
x3 = 11
13 ≈0.846.
This means that the inoperability of Subsystems 1, 2, and 3 is 0.615, 0.769, and
0.846, respectively.
Assume h × 100% of the operability of Subsystem 2 is lost due to the attack alone.
Then the inoperability equation of IIM is
(
x1
x2
x3
) = (
0
0.8
0
0.6
0
0
0.25
0.9
0
) (
x1
x2
x3
) + (
0
h
0
) = (
0.8x2
0.6x1 + h
0.25x1 + 0.9x2
)
or
{
{
{
{
{
{
{
{
{
x1 = 0.8x2,
x2 = 0.6x1 + h,
x3 = 0.25x1 + 0.9x2.
Note that the constraint 0 ≤x1, x2, x2 ≤1. Solving the set of equations, the solution
is
x1 = 20
13 h,
x2 = 25
13 h,
x3 = 55
26 h
for 0 ≤h ≤0.47,
x1 = 8
11 ≈0.727,
x2 = 10
11 ≈0.909,
x3 = 1
for 0.47 < h ≤1.
Subsystem 3 fails completely when the external attack brings down 47 % of its oper-
ability. The remaining 53 % is taken away by its dependency on Subsystems 1 and 2.
Further reading
[1]
Asbeck E, Haimes YY. The partitioned multiobjective risk method. Large Scale Systems.
1984(6):13–38.
[2]
Aven T. Risk assessment and risk management: Review of recent advances on their foundation.
European Journal of Operational Research. 2016(253):1–13.
[3]
Browning J, Thomas N. An assessment of the tsunami risk in Muscat and Salalah, Oman, based
on estimations of probable maximum loss. International Journal of Disaster Risk Reduction.
2016(16):75–87.
[4]
Chankong V. Multiobjective decision making analysis: The interactive surrogate worth trade-off
method, PhD dissertation, Systems Engineering Department, Case Western Reserve, Cleve-
land, OH, 1977.
[5]
de Carvalho AL, Antunes CH, Freire F, Henriques CO. A multi-objective interactive approach to
assess economic-energy-environment trade-offs in Brazil. Renewable and Sustainable Energy
Reviews. 2016(54):1429–1442.

Further reading
|
311
[6]
Finkel A. Confronting Uncertainty in Risk Management: A guide for Decision-Makers. Resources
for the Future, Center for Risk Management, Washington, DC., 1990.
[7]
Gomide F, Haimes YY. The multiobjective, multistage impact analysis method, theoretical ba-
sis. IEEE Transactions on System, Man, and Cybernetics SMC. 1984(14):88–98.
[8]
Haimes YY, Lasdon LS, Wismer DA. On the bicriterion formulation of the integrated system
identiﬁcation and systems optimization. IEEE Transactions on Systems, Man, and Cybernetics
SMC. 1971(1):296–297.
[9]
Haimes YY, Lambert JH, Li D. Risk of extreme events in a multiobjective framework. Water Re-
sources Research. 1992(28):201–209.
[10] Hamdy M, Nguyen AT, Hensen JLM. A performance comparison of multi-objective optimization
algorithms for solving nearly-zero-energy-building design problems. Energy and Buildings.
2016(121):57–71.
[11] He W, He Q, Zhou J. Soil weathering-water environment-ecological risks in Hanjiang River
Basin, China. Quaternary International. 2015(380–381):297–304.
[12] Kankara RS, Arockiaraj S, Prabhu K. Environmental sensitivity mapping and risk assessment
for oil spill along the Chennai Coast in India. Marine Pollution Bulletin. 2016(106):95–103.
[13] Kennedy WV. The directive on environmental impact assessment. Environmental Policy and
Law. 1982(8):84–95.
[14] Law AM, Kelton WD. Simulation Modeling and Analysis. McGraw-Hill, New York, 1991.
[15] Leach MR. Risk and impact analysis in a multiobjective framework, MSc thesis, Systems Engi-
neering Department, Case Western Reserve University, Cleveland, OH, 1984.
[16] Leontief WW. The Structure of the American Economy, 1919–1939. Second edition, Oxford Uni-
versity Press, New York, 1951.
[17] Leontief WW. Input-Output Economics. Second edition, Oxford University Press, New York,
1986.
[18] Li C, Sun L, Jia J, Cai Y, Wang X. Risk assessment of water pollution sources based on an inte-
grated k-means clustering and set pair analysis method in the region of Shiyan, China. Science
of the Total Environment. 2016(557–558):307–316.
[19] Li D, Haimes YY. The uncertainty sensitivity index method and its extension. Naval Research
Logistic. 1988(35):655–672.
[20] Mohamad N, Latif MT, Khan MF. Source apportionment and health risk assessment of PM10
in a naturally ventilated school in a tropical environment. Ecotoxicology and Environmental
Safety. 2016(124):351–362.
[21] Morgan G, Henrion M. Uncertainty. Cambridge University Press, Cambridge, 1990.
[22] Naidu R, Espana VAA, Liu Y, Jit J. Emerging contaminants in the environment: Risk-based analy-
sis for better management. Chemosphere. 2016(154):350–357.
[23] Oxley T, Simon HM. Space, time and nesting Integrated Assessment Models. Environmental
Modelling & Software. 2007(22):1732–1749.
[24] Senapati N, Jansson PE, Smith P, Chabbi A. Modelling heat, water and carbon ﬂuxes in mown
grassland under multi-objective and multi-criteria constraints. Environmental Modelling &
Software. 2016(80):201–224.
[25] Shrestha S, Semkuyu DJ, Pandey VP. Assessment of groundwater vulnerability and risk to pol-
lution in Kathmandu Valley, Nepal. Science of the Total Environment. 2016(556):23–35.

10 Life cycle assessments
Life cycle means the entire life cycle of a product system from the raw material acqui-
sition, manufacture, use/reuse/maintenance, and recycle/waste management, to its
ﬁnal disposal of a product, process or system. The concept of life cycle was mentioned
ﬁrst by Novick in 1959. At that time, a main application was the cost of weapon sys-
tems including the cost of purchase, development, and end-of-life operations. When
environmental policy became a major issue in all industrialized societies, the life cy-
cle concept was fully developed. Currently, life cycle assessment (LCA) has become a
major instrument to assess the ecological burdens and impacts throughout the con-
secutive and interlinked stages of a product system, from raw material acquisition or
generation from natural resources, through production and use to ﬁnal disposal.
10.1 Classic life cycle assessment
Life Cycle Assessment (LCA) is a cradle-to-grave approach for assessing industrial sys-
tems. It begins with the initial gathering of raw materials from the earth to create the
product and ends at the point when all residuals are returned to the earth. LCA is
used for identifying, quantifying, and decreasing the overall environmental impact of
a product, process, or system. The International Standards Organization (ISO) docu-
ments on LCA include the following several parts:
–
ISO-14040, Life Cycle Assessment – Principles and Framework (ISO, 1997)
–
ISO-14041, Life Cycle Assessment – Goal and Scope Deﬁnition and Inventory Anal-
ysis (ISO, 1998)
–
ISO-14042, Life Cycle Assessment – Life Cycle Impact Assessment (ISO, 2000)
–
ISO-14043, Life Cycle Assessment – Life Cycle Interpretation (ISO, 2000)
–
ISO-14044, Life Cycle Assessment – Requirements and Guidelines (ISO, 2006)
The LCA process is a systematic, phased approach. An LCA consists of the following
four interrelated phases:
–
goal and scope deﬁnition,
–
life cycle inventory analysis (or inventory analysis for short),
–
life cycle impact assessment (or impact assessment for short),
–
life cycle interpretation (or interpretation for short).
The framework of LCA is shown in Figure 10.1. Arrows indicate that all phases are
linked to each other, the life cycle interpretation is also linked to all phases, and the
LCA has direct applications including product development and improvement, strate-
gic planning, public policy making, marketing, and so on.
DOI 10.1515/9783110424904-011

10.1 Classic life cycle assessment
|
313
Goal and scope deﬁnition
Inventory analysis
Interpretation
Direct applications
Impact assessment
Fig. 10.1: The framework of LCA.
10.1.1 Goal and scope deﬁnition
There is no explicit ISO deﬁnition of this phase of LCA. But it obviously centers around
formulating the question and stating the context of answering this question. In this
phase, no data is collected and no results are calculated. Rather, it is a place where the
plan of the LCA study is deﬁned as clearly and unambiguously as possible such that
one can quickly ﬁnd out the precise question addressed and main principles chosen.
The goal of LCAs deals with the following topics:
–
the intended application;
–
reasons for carrying out the study;
–
the intended audience;
–
whether the results will be used as the basis for public comparative assertions.
The scope deﬁnition makes a number of major choices. For instance, the product sys-
tem or systems to be studied, the function the system delivers, and the functional unit.
The scope deﬁnition further sets the main outline on a number of subjects that are
discussed and further reﬁned in more detail in the later phases. For instance, system
boundaries, impact categories, and treatment of uncertainty.
10.1.2 Life cycle inventory analysis
Life Cycle Inventory Analysis (LCI) is the second phase of LCA. ISO deﬁnes it as the
phase of LCA involving the compilation and quantiﬁcation of inputs and outputs for a
product throughout its life cycle. In this phase, quantiﬁcation is an important aspect
and numbers (data and calculations) are of central concern.
Unit processes are the central element of inventory analysis. A unit process in ISO
14040 is deﬁned as the smallest element considered in the LCI. Examples of unit pro-
cess are coal mining, steel production, reﬁning of oil, recycling of waste paper, and
transport by lorry. In LCA a unit process is considered commonly as a black box that
converts a bundle of inputs into a bundle of outputs. LCA studies can connect different
unit process into a system in simple upstream-downstream connections or more com-
plicated connections. In the present era of digital databases, LCA studies can easily
connect several thousands of unit processes.

314
|
10 Life cycle assessments
In the LCI, all unit processes have to be quantiﬁed. This means that the sizes of
the inﬂows and outﬂows per unit process have to be speciﬁed. In scaling the unit
processes, the web-like nature of the system quickly creates complications. Two com-
plications are mentioned as follows:
–
upstream or downstream processes of some products may be difficult to quantify;
–
some unit processes produce several co-products such that the balance equations
become impossible.
The ﬁrst issue can be solved by a procedure known as cut-off. The second issue can
be solved by co-product allocation. After appropriate cut-off and allocation, the ﬁnal
inventory results can be calculated.
The key steps of LCI are to develop a ﬂow diagram and an LCI data collection plan,
collect data of inputs and outputs, and evaluate and document the LCI results.
10.1.3 Life cycle impact assessment
Life Cycle Impact Assessment (LCIA) is the third phase of LCA aimed at understand-
ing and evaluating the magnitude and signiﬁcance of the potential environmental
impacts for a product system throughout the life cycle of the product. According to
ISO 14042, LCIA is divided into mandatory and optional steps.
The mandatory steps are as follows.
–
Selection of impact categories. The impact category is the central element in life
cycle impact assessment. ISO deﬁnes the impact category as a class represent-
ing environmental issues of concern to which LCI results may be assigned. Im-
pact categories and the corresponding category indicators can be organized at a
midpoint level and at an endpoint level along the cause-effect chain. Important
environmental impact categories are Acidiﬁcation Potential (AP), Eutrophication
Potential (EP), Global Warming Potential (GWP), and Ozone Depletion Potential
(ODP).
–
Classiﬁcation. ISO deﬁnes it as the assignment of LCI results to the selected impact
categories.
–
Characterization. This step converts the results of LCI into a common metric and
aggregates the converted LCI results. The result from characterization is a list of
numbers. ISO calls these numbers category indicator results (score).
Many LCIA studies stop at the characterization.
The optional steps are as follows.
–
Normalization. This refers to calculating the magnitude of category indicator re-
sults relative to reference information. It fulﬁlls several functions that it provides
insight into the meaning of the impact indicator results, it helps to check for er-
rors, and it prepares for a possible weighting step.

10.2 Exergetic life cycle assessment
|
315
–
Grouping. This is seldom seen in LCA studies. ISO deﬁnes it as the assignment
of impact categories into one or more sets. ISO mentions two ways: sorting on a
nominal basis and ranking on an ordinal basis.
–
Weighting. This starts with the characterization (or normalization) results. Weight-
ing factors are applied to the characterization indicator results or their normalized
version. Weighting produces one ﬁnal number by
W = ∑
c
WFc × Ic,
where Ic is the impact score and WFc is the weighting factor, both for the impact
category c, and W is the weighted result.
–
Data quality analysis. This develops a better understanding of the reliability of the
indicator results in the LCIA proﬁle.
10.1.4 Life cycle interpretation
Life cycle interpretation is the ﬁnal phase of LCA. It integrates the LCI and LCIA results
to develop conclusions and recommendations that relate to the goal and scope of the
study. ISO 2006a deﬁnes two objectives of interpretation:
–
Analyze results, reach conclusion, explain limitations, and provide recommenda-
tions based on the ﬁndings of the preceding phases, and report the results of the
interpretation in a transparent manner.
–
Provide a readily understandable, complete, and consistent presentation of the
results of an LCA study in accordance with the goal and scope of the study.
LCA is best used as an iterative approach. It is especially important to determine that if
the result of the impact assessment or the underlying inventory data are incomplete or
unacceptable for drawing conclusions and making recommendations, then the previ-
ous steps must be repeated until the results can support the original goals of the study.
10.2 Exergetic life cycle assessment
Exergy is a thermodynamic quantity. The exergy of a system is deﬁned as the maxi-
mum shaft work that can be attained when it is in a reference environment. Exergy
is conserved only when all processes occurring in a system and its surroundings are
reversible. Exergy is destroyed whenever an irreversible process occurs. Like energy,
exergy can also be transferred across the boundary of a system. There is an exergy
transfer corresponding to each type of energy transfer. The exergy transfer associated
with shaft work is equal to the shaft work, while the exergy transfer associated with
heat transfer depends on the temperature of the reference environment. A system in
complete equilibrium with its environment has no exergy.

316
|
10 Life cycle assessments
Exergy analysis is based on the second law of thermodynamics. An exergy balance
for a process or system is the following:
Accumulated exergy = Input exergy −Output exergy −Destroyed exergy.
The exergy quantities in an exergy balance include the exergy of a matter ﬂow, a ther-
mal energy transfer, and electricity. The exergy of a matter ﬂow is equal to the sum
of physical, chemical, kinetic, and potential components. The exergy associated with
a thermal energy transfer relates to system and reference environment temperatures.
The exergy associated with electricity is equal to the energy.
Reducing exergy losses or increasing exergy efficiencies can often decrease envi-
ronmental impacts associated with systems or processes. Exergy losses occur during
the lifetime of a product or process. Reducing exergy losses helps improve sustainabil-
ity. As exergy efficiency approaches ideality, environmental impacts approach zero.
As exergy efficiency approaches zero, sustainability approaches zero. The exergy and
environmental impact occur generally during all phases of the life cycle. Their main
connections are waste exergy emissions, resource degradation, and order destruction
and chaos creation.
Exergetic life cycle assessment (ExLCA) is a different approach from LCA. Like
LCA, it is also a useful analytical tool to identify, quantify, and decrease the overall
environmental impact of a process or a system. The general methodological frame-
work of ExLCA is similar to that of LCA. The main differences are the following:
(a) The inventory analysis of ExLCA is more detailed than that of LCA. All inputs and
outputs must be identiﬁed and quantiﬁed. The material and energy balances have
to be closed.
(b) The impact assessment of ExLCA focuses on the determination of the exergies of
the ﬂow, the exergy destructions, and exergy efficiencies of the overall process
and its subprocesses.
(c) The improvement analysis in ExLCA is intended to reduce its life cycle irreversibil-
ities. The summation of all exergy destructions in the life cycle identiﬁes the life
cycle irreversibility of the product or process.
Throughout ExLCA, the calculation of exergy values requires that the conditions and
composition of the reference environment are speciﬁed.
10.3 Ecologically-based life cycle assessment
Ecosystem goods and services, such as fresh water, soil, and pollination, are essen-
tial to all human activity. These goods and services can be divided into the following
categories:

10.3 Ecologically-based life cycle assessment
|
317
–
provisioning services that supply goods;
–
regulating services that provide beneﬁts by controlling ecosystem processes;
–
cultural services that are all of the intangible beneﬁts;
–
supporting services that are required for all of the other ecosystem services to take
place.
Twenty-four different ecosystem services relating to provisioning, regulating, and cul-
tural services are included in the Millennium Ecosystem Assessment (MEA). Of these
twenty-four services, scientists have found that in the last ﬁfty years, ﬁfteen ecosys-
tem services have globally degraded, another ﬁve ecosystem services have mixed re-
sults, and the remaining four ecosystem services have enhanced performance. If these
trends continue, the earth may no longer be able to sustain human life. This motivates
scientists to put these ecosystem services into the life cycle assessment methodology.
Ecologically-based Life Cycle Assessment (Eco-LCA) is a hybrid LCA method. In a
hybrid study, the most important parts of the process are modeled using Process-based
LCA (Process LCA), the less important parts are modeled using Economic Input-Output
LCA (EIO-LCA). Process LCA and EIO-LCA are two methods used routinely to perform
the assessment of products and processes by LCA practitioners. Eco-LCA has both the
precision of Process LCA and the completeness of EIO-LCA.
Eco-LCA contains twenty different ecosystem services in which many provisioning
and regulating services were assessed in the MEA, some supporting services were not
included in the MEA.
Many engineering analyses undervalue or completely ignore the role of ecosys-
tems, i.e., energy consumption and emissions. It is well known that the second law
of thermodynamics has profound implications on the capability of man-made tech-
nology in meeting sustainability goals. The second law says that decreasing entropy
in an open system must result in a greater increasing entropy in the surroundings.
This increase manifests as environmental impact since the surrounding environment
must dissipate the local increasing entropy. Eco-LCA can quantify the role of ecosys-
tem goods and services in the life cycle. Different goods and services have different
units that cannot be added together. To compare various ecosystem services Eco-LCA
converts many different units of ecosystem goods and services to a common basis of
thermodynamic work using exergy and emergy. Exergy allows the comparison of the
different resources on a common basis of Joules of work. Emergy is also a basis of com-
parison. Emergy’s unit is the solar emergy Joule (seJ). The seJ allows the difference in
energy quality to be accounted for in different resources. The factors that are used to
convert from the original energy unit to seJ are called transformities (units: seJ/J) or,
more generally, Unit Emergy Value (UEV, units: seJ/unit). Transformity indicates how
many seJ are required to get a single Joule of the product.

318
|
10 Life cycle assessments
10.4 Case studies
Life cycle assessment (LCA) has become a major instrument to assess ecological bur-
dens and impacts throughout the consecutive and interlinked stages of a product sys-
tem, from raw material acquisition or generation from natural resources, through pro-
duction and use to ﬁnal disposal. Here we give some case studies as examples.
10.4.1 Energy crops
The need to tackle climate change has pushed the cultivation of energy crops for the
production of bio-fuels to the top of the global agenda. Christoforou et al. (2016) use
LCA to quantify the environmental impact of ﬁrst generation energy crops in Cyprus
which include maize, sweet sorghum, winter wheat, sugar-beets, potato and winter
barley. The goal of the study was to evaluate the environmental impact of different
energy crop systems. Life cycle inventory are classiﬁed as pre-farm activities (e.g. fuel
consumption, electricity consumption, seed, fertilizers and pesticides transportation)
and on-farm activities (e.g. land preparation, fertilizer and pesticides application, ir-
rigation and harvesting). Main impact assessment includes global warming potential,
acidiﬁcation potential, eutrophication potential, ozone depletion potential and abi-
otic depletion potential. The results show that barley, potato, and wheat crop pre-
sented the highest environment impact in Cyprus.
10.4.2 Wastewater treatment
Wastewater treatment plays a key role in assuring the continued utility of ecosys-
tems. The three main inputs needed to treat wastewater are electricity, chlorine, and
transportation services for the solid and sludge waste products. Morrison et al. (2016)
investigated a wastewater treatment plant (WWTP) at a university campus. Their anal-
ysis began at the point where raw wastewater from individual buildings on the cam-
pus deposits into the central wastewater collection system and is gravity fed to the
wastewater inlet port at the WWTP and extends to the point that it has been treated to
discharge standards. Based on LCA, Morrison et al. (2016) predicted the total energy
consumption and CO2 emissions over the lifetime of the WWTP.
10.4.3 Livestock production
Commercial livestock production has signiﬁcant impacts on the environment. Pig pro-
duction is a highly complex global system which involves the production of fertilizers
and pesticides for crop production, land transformation, transportation to and from

Further reading
|
319
farms, energy for light and heat, water for animal consumption and farmyard wash-
ing, and waste management. LCA can be used to measure the potential environmental
performance of pig production, including acidiﬁcation potential, eutrophication po-
tential and global warming potential (Graham et al. 2016).
Further reading
[1]
Bare JC. Developing a Consistent Decision-Making Framework by using U.S. EPA’s TRACI. Na-
tional Risk Management Research Laboratory, US Environmental Protection Agency, Cincinnati,
OH, 2002.
[2]
Bare JC, Gloria TP. Critical analysis of the mathematical relationships and comprehensiveness
of life cycle impact assessment approaches. Environmental Science & Technology. 2006(40):
1104–1113.
[3]
Brand G, Braunschweig A et al. Weighting in Ecobalances with the Ecoscarcity Method – Eco-
factors. Environment Series, No.297, Bern, Switzerland, Swiss Agency for the Environment,
Forests, and Landscape (SAEFL), 1997.
[4]
BUS. Ökobilanzen von Packstoffen. Schriftenreihe Umweltschutz Nr. 24. Bern, Switzerland,
Bundesamt für Umweltschutz, 1984.
[5]
Christoforou E, Fokaides PA, Koroneos CJ, Recchia L. Life Cycle Assessment of ﬁrst generation
energy crops in arid isolated island states: The case of Cyprus. Sustainable Energy Technolo-
gies and Assessments. 2016(14):1–8.
[6]
Daniel JJ, Rosen MA. Exergetic environmental assessment of life cycle emissions for various
automobiles and fuels. Exergy, an International Journal. 2002(2):283–294.
[7]
Dincer I. Thermodynamics, exergy and environmental impact. Energy Sources. 2000(22)
723–732.
[8]
Dincer I, Rosen MA. Exergy: Energy, Environment and Sustainable Development. Elsevier, UK,
2007.
[9]
EC-JRC. Framework and Requirements for Life Cycle Impact Assessment (LCIA) Models
and Indicators. ILCD Handbook-International Reference Life Cycle Data System, European
Commission-Joint Research Center, 2010.
[10] EC-JRC. An Analysis of existing Environmental Impact Assessment Methodologies for use in Life
Cycle Assessment-Background Document. ILCD Handbook-International Reference Life Cycle
Data System, European Commission-Joint Research Center, 2010.
[11] EC-JRC. General Guide for Life Cycle Assessment-Detailed Practice. ILCD Handbook-Inter-
national Reference Life Cycle Data System, European Commission-Joint Research Center, 2010.
[12] Goedkoop M, Demmers M, Collignon M. The Eco-indicator 95 Manual for Designers. National
Reuse of Waste Research Programme, The Netherlands, 1996.
[13] Guinée JB, Gorrée M et al. Handbook on Life Cycle Assessment, Operational guide to the ISO
Standards. I: LCA in perspective, IIa: Guide, IIb: Operational annex, III: Scientiﬁc background.
Kluwer Academic Publishers, Dordrecht, 2002.
[14] Heijungs R, Guinee J et al. Environment Life Cycle Assessment of Products: Guide and Back-
ground. CML, Leiden, The Netherlands, 1992.
[15] Heijungs R, Kleijn R. Numerical approaches to life-cycle interpretation, ﬁve examples. Interna-
tional Journal of Life Cycle Assessment. 2001(6):141–148.
[16] Heijungs R, Suh S. The Computational Structure of Life Cycle Assessment. Kluwer Academic
Publishers, Dordrecht, 2002.

320
|
10 Life cycle assessments
[17] Hendrickson CT, Lave LB, Matthews HS. Environmental Life Cycle Assessment of Goods and
Services. Washington DC, REF Press, 2006.
[18] Hermann WA. Quantifying global exergy resources. Energy. 2006(31):1349–1366.
[19] Huesemann MH. The limits of technological solutions to sustainable development. Clean Tech-
nologies and Environmental Policy. 2003(5):21–34.
[20] Huijbregts MA, Norris G, Bretz R, Ciroth A, Maurice B, von Bahr B et al. Framework for mod-
elling data uncertainty in life cycle inventories. International Journal of Life Cycle Assessment.
2001(6):127–132.
[21] ISO. Environmental Management – Life Cycle Assessment – Requirements and Guidelines
(ISO 14044). International Organization for Standardization, Geneva, 2006.
[22] Jolliet O, Margni M, Charles R, Humbert S, Payet J, Rebitzer G, Rosenbaum R. IMPACT 2002+:
A new life cycle impact assessment methodology. International Journal of Life Cycle Assess-
ment. 2003(8):324–330.
[23] Kotas TJ. The Exergy Method of Thermal Plant Analysis. Kriger: Malabar, Florida, 1995.
[24] McAuliffe GA, Chapman DV, Sage CL. A thematic review of life cycle assessment (LCA) applied
to pig production. Environmental Impact Assessment Review. 2016(56):12–22.
[25] Millennium Ecosystem Assessment Board. Living Beyond Our Means: Natural Assets and Hu-
man Well-being, 2005.
[26] Moran MJ. Availability Analysis: A Guide to Efficient Energy Use. American Society of Mechani-
cal Engineers, New York, 1989.
[27] Morrison M, Srinivasan RS, Ries R. Complementary life cycle assessment of wastewater treat-
ment plants: An integrated approach to comprehensive upstream and downstream impact
assessments and its extension to building-level wastewater generation. Sustainable Cities and
Society. 2016(23):37–49.
[28] Novick D. The Federal Budget as an Indicator of Government Intentions and the Implications of
Intentions. Santa Monica, CA: Rand Corporation, 1959, P-1803.
[29] Parry ML, Canziani OF, Palutikof JP, van der Linden PJ, Hanson CE. Contribution of Working
Group II to the Fourth Assessment Report of the Intergovernmental Panel on Climate Change.
Cambridge Univ. Press, Cambridge, UK, 2007.
[30] Rosen MA, Dincer I. On exergy and environmental impact. International Journal of Energy Re-
search. 1997(21):643–654.
[31] Rosen MA, Dincer I. Exergy as the conﬂuence of energy, environment and sustainable develop-
ment. Exergy, an International Journal. 2001(1) 3–13.
[32] Steen B. A systematic approach to environmental priority strategies in product development
(EPS), Version 2000-General system characteristics. CPM report 1999: 4, Center for Environ-
mental Assessment, Chalmers Univ. of Technology, Gothenburg, Sweden, 1999.
[33] Ultiati S. Energy quality, emergy, and transformity: H.T. Odum’s contributions to quantifying
and understanding systems. Ecological Modelling. 2004(178):201–213.
[34] Zhang Y, Baral A, Bakshi BR. Accounting for ecosystem services in life cycle assessment,
Part II, Toward an ecologically based LCA. Environmental Science & Technology. 2010(44):
2624–2631.
[35] Zhang Y, Singh S, Bakshi BR. Accounting for ecosystem services in life cycle assessment,
Part I: A critical review. Environmental Science & Technology. 2010(44):2232–2242.

Index
adjacency matrix 59
analysis of covariance 131
analysis of variance 131
approximation 63
approximation error 84
approximation for random processes 69
AR model 30
ARMA model 1, 17, 32
attractor 46
autocorrelation function 2
autocovariance function 2
autoregressive moving average 1, 17
B-spline 115
Banker–Charnes–Cooper (BCC) DEA model 252
Battle–Lemarie wavelet 89
Bayes method 135
best approximation 66
bivariate interpolation 118
bivariate nonlinear equation 158
box-counting dimension 53
building design 240
butterﬂy effect 45
Calderon–Zygmund operator 182
canonical correlation analysis 142
carbon emissions reduction 265
chance node 271
chaotic domain 50
Charnes–Cooper–Rhodes (CCR) DEA model 243
Chebyshev distance 138
Chebyshev polynomial 79
circular motion 46
classic life cycle assessment 312
classical Galerkin method 176
climate reconstruction 128
cluster analysis 137
clustering coefficient 60
coal mining 240, 265
coal-ﬁred power plant 265
complicated Simpson formula 149
complicated trapezoidal formula 149
consequence 271
correlation dimension 54
covariance function 1
data compression 97
data envelopment analysis 243
Daubechies wavelet 89
DEA 243
decision node 271
decision rule 267
decision tree 271
delay embedding theorem 57
delay embedding vector 56
difference method 163
dimension curse 63
dimensionality reduction 72
directional distance function model 264
directional distance function super efficiency
model 263
discrete Fourier transform 116
discriminant analysis 132
dissipative system 46
distance 61
dual simplex method 203
Durbin–Levinson algorithm 8
dynamical system 45
ε-constraint method 282
ecologically-based life cycle assessment
(Eco-LCA) 317
electric energy generating system 241
elliptic equation 164
energy crops 318
epsilon-based measure (EBM) model 259, 260
Euclidean distance 138
Euler method 161
exergetic life cycle assessment (ExLCA) 315, 316
exergy 315
expected monetary value (EMV) 271
expected value of opportunity loss (EOL) 271
factor analysis 143
fast Fourier transform 116
Fermat rule 222
ﬁnite element method 167
Fisher method 134
ﬁxed point 47
ﬁxed point principle 155
Fourier power spectrum 15
Fourier series 63

322
|
Index
Fourier transform 87
fractal dimension 51
fractal structure 50
fractile method 274
free disposal hull DEA model 257
Gauss–Legendre quadrature formula 150
generalized Lagrange multiplier 283
global clustering coefficient 60
global recurrence rate 59
greedy algorithm 98
Haar wavelet 89
Henon map 47
Hermite interpolation 110
Hermite polynomial 82
high-dimensional wavelet 90
Hurwitz rule 268
hybrid model 261
hyperbolic equation 166
information dimension 54
innovation algorithm 10
inoperability input-output model 307
input-oriented BCC DEA model 252
input-oriented CCR DEA model 243
integral equation 180
interpolation 102
iron and steel industry 241
iterative method 155
Jacobian iterative method 159
Jacobian polynomial 81
joint optimality and sensitivity multiobjective
model 288
Kalman ﬁltering 43
Kalman prediction 42
Kalman smoothing 43
Karush–Kuhn–Tucker (KKT) condition 225
Lagrange interpolation 106
Lagrange interpolation formula 106
Laguerre polynomial 82
LCA 312
LCI 313
LCIA 314
Legendre polynomial 81
Leontief’s input-output model 307
Leslie model 304
life cycle assessment (LCA) 312
life cycle impact assessment 312, 314
life cycle interpretation 312, 315
life cycle inventory analysis 312, 313
linear mapping 48
linear process 4
linear regression 122
linearly constrained convex optimization
model 230
linearly nonnegative constrained convex
optimization model 231
livestock production 318
local clustering coefficient 60
local recurrence rate 59
logistic map 49
Lyapunov exponent 50
MA model 32
Mahalanobis distance 138
Mahalanobis distance method 132
Mahley approximation 86
MaxDEA 264
maximum likelihood estimation 33
mean function 1
Meyer wavelet 89
Minkowski distance 137
modeling 30
modiﬁed slack-based measure (MSBM)
model 258
most likely value (MLV) 271
MRA 88
multiobjective multistage impact analysis
(MMIA) method 294
multiobjective optimization model 282
multiobjective risk impact analysis (MRIA)
method 296
multiple regression 125
multiresolution analysis 88
multiresolution approximation 95
multivariate approximation 72
multivariate ARMA process 34
N-term approximation 96
Newton interpolation formula 107, 108
Newton’s method 185
Newton–Raphson method 191
nonlinear regression model 125

Index
|
323
numerical differentiation 152
numerical integration 148
observed trajectory 58
optimistic rule 268
ordinary differential equation 161, 163
orthogonal greedy algorithm 100
output-oriented BCC DEA model 253
output-oriented CCR DEA model 249
Pade approximation 85
parabolic equation 165
partial autocorrelation function 24
partitioned multiobjective risk (PMR) 291
path 61
pessimistic rule 267
polynomial approximation 76
polynomial ﬁtting 102
prediction 6, 26, 55
primal and dual pairs of linear optimization 233
principal component analysis 139
pure greedy algorithm 98
radial super efficiency model 262
random walk 3
rational approximation 82, 85
recurrence matrix 59
recurrence network 58
relaxation iterative method 160
relaxed greedy algorithm 99
Richardson extrapolation 154
risk assessment 267
saddle function 233
saddle point 236
sample autocovariance function 5
SBM super efficiency model 263
scaling function 88
Seldel iterative method 160
self-similarly dimension 54
Shepard interpolation 119
simplex method 198
Simpson formula 149
singular spectrum analysis 57
slack-based measure DEA model 257
spectral analysis 13
spectral density 13, 25
spectral estimation 14
spline approximation 82
spline interpolation 112
state-space model 39
stationary 1
stationary vector process 35
steepest descent method 185
strange attractor 50
strictly stationary 2
super efficiency model 262
supply chain planning 240
system of linear equations 159
system of ordinary differential equations 163
thresholding value method 97
time series 1
time series analysis 1
time-invariant linear ﬁlter 16
trade-off function 283
trapezoidal formula 149
trapezoidal method 162
triangular distribution method 279
trigonometric approximation 63
trigonometric interpolation 116
uncertainty sensitivity index method (USIM) 287
univariate nonlinear equation 156
variational method 192
vector AR process 37
vector ARMA process 35
vector MA process 36
wastewater treatment 318
wavelet 88
wavelet approximation 86
wavelet basis 88
wavelet coefficient 90
wavelet decomposition formula 93
wavelet packet 92
wavelet-Galerkin method 176
weighted modiﬁed slack-based measure
(WMSBM) model 259
weighted slack-based measure (WSBM)
model 259
white noise 3
Wold decomposition 12
Yule–Walker equation 20, 38


