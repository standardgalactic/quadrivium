Volume: 05 | Issue: 09 | Pages: 108 | June 2017
ISSN-2456-4885
` 120
Programming IPv6 Protocols 
Using Contiki And Cooja
The Future Of Indian E-governance 
Begins With OpenForge 
CONNECTED DEVICES
IoT:  A New World Of
A Peek At Four 
JavaScript 
Based Libraries 
For The Internet 
Of Things
SiteWhere: An 
Open Platform 
For Connected 
Devices
Kaa: An Easy-
to-Use Platform 
For Building IoT 
Solutions
Case Study: Andhra Pradesh 
Rolls Out An Electronic Public 
Distribution System Using Open Source
An Interview With Will Norris, 
Engineering Manager At Google’s  
Open Source Programs Office



Admin
21 
DevOps Series Ansible 
Deployment of RabbitMQ
Developers
29  Zetta: An API-First IoT Platform
35  Developing a Basic GUI 
Application Using JavaFX 
in Eclipse
38  Conda: The Soul of Anaconda
44 
Smart Attendance Register 
in App Inventor 2
56 
The Minor Differences 
Between C and C++
60  Programming IPv6 Protocols 
Using Contiki and Cooja
64 
A Peek at Four JavaScript 
Based Libraries for the 
Internet of Things
70 
Writing Custom Add-ons 
for NodeRED
FOR U & ME
91  PolSARpro: Wonderful FOSS  
for Synthetic Aperture Radar 
Data Processing 
93 
The Role of Open Source in IoT
102 A Few More Tips on Vi/Vim 
Editor for Linux Newbies
Open Gurus
74  Kaa: An Easy-to-Use Platform 
for Building IoT Solutions
76  SiteWhere: An Open Platform 
for Connected Devices
81  An Introduction to 
Raspberry Pi GPIO 
Programming Using Python
85  Internet of Things: The 
Protocols Landscape
News ++
88  The Future of Indian 
E-governance Begins 
with OpenForge
REGULAR FEATURES
06 
FOSSBytes
  14  New Products
  104  Tips & Tricks
51
25
Web Robots: The Worker Bees  
of the Internet
Sign Up with Ubidots to  
Power Your IoT App
ISSN-2456-4885
4 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

Linux for Internet 
of Things (IoT)
Ubuntu Core for 
Raspberry Pi 2 
and 3
Fedora 25 LXDE 
for ARM
KALI LINUX 
2017.1 
Kali Linux (formerly known as BackTrack) is a 
Debian-based Linux distribution aimed at advanced 
penetration testing and security auditing
JUNE 2017
CD 
Tea
m e-
mail
: cd
tea
m@
efy.i
n
Rec
omm
end
ed S
yste
m Re
quir
eme
nts: 
P4, 
1GB
 RA
M, D
VD-R
OM 
Driv
e
In c
ase 
this
 DV
D do
es n
ot w
ork 
prop
erly,
 wri
te t
o us
 at s
upp
ort@
efy.i
n fo
r a f
ree 
repl
ace
men
t.
Secure your environment 
with this version of Kali Linux.
DVD OF THE MONTH
• Kali Linux 2017.1 (64-bit live)
• Linux for Internet of Things (IoT)
106
Will Norris, engineering manager at 
Google’s Open Source Programs Office
“Open source 
development 
at Google 
is both very 
diverse and 
distributed”
18
98
The Synergy between Big Data and  
the Internet of Things
Columns
13 
Exploring Software: Sugarizer: 
The Taste of Sugar on Any Device
16 
CodeSport
Case Study
68 
Andhra Pradesh Rolls Out an 
Electronic Public Distribution 
System Using Open Source
EDITOR
RAHUL CHOPRA
EDITORIAL, SUBSCRIPTIONS & ADVERTISING
DELHI (HQ)
D-87/1, Okhla Industrial Area, Phase I, New Delhi 110020
Ph: (011) 26810602, 26810603; Fax: 26817563
E-mail: info@efy.in
MISSING ISSUES
E-mail: support@efy.in
BACK ISSUES
Kits ‘n’ Spares
New Delhi 110020 
Ph: (011) 26371661,  26371662
E-mail: info@kitsnspares.com
NEWSSTAND DISTRIBUTION
Ph: 011-40596600
E-mail: efycirc@efy.in 
ADVERTISEMENTS 
MUMBAI
Ph: (022) 24950047, 24928520 
E-mail: efymum@efy.in
BENGALURU
Ph: (080) 25260394, 25260023 
E-mail: efyblr@efy.in
PUNE
Ph: 08800295610/ 09870682995 
E-mail: efypune@efy.in
GUJARAT
Ph: (079) 61344948 
E-mail: efyahd@efy.in
CHINA
Power Pioneer Group Inc.  
Ph: (86 755) 83729797, (86) 13923802595 
E-mail: powerpioneer@efy.in
JAPAN
Tandem Inc., Ph: 81-3-3541-4166 
E-mail: tandem@efy.in
SINGAPORE
Publicitas Singapore Pte Ltd 
Ph: +65-6836 2272 
E-mail: publicitas@efy.in
TAIWAN 
J.K. Media, Ph: 886-2-87726780 ext. 10 
E-mail: jkmedia@efy.in
UNITED STATES
E & Tech Media 
Ph: +1 860 536 6677 
E-mail: veroniquelamarque@gmail.com
Printed, published and owned by Ramesh Chopra. Printed at Tara 
Art Printers Pvt Ltd, A-46,47, Sec-5, Noida, on 28th of the previous 
month, and published from D-87/1, Okhla Industrial Area, Phase I, New 
Delhi 110020. Copyright © 2017. All articles in this issue, except for 
interviews, verbatim quotes, or unless otherwise explicitly mentioned, 
will be released under Creative Commons Attribution-NonCommercial 
3.0 Unported License a month after the date of publication. Refer to 
http://creativecommons.org/licenses/by-nc/3.0/  for a copy of the 
licence. Although every effort is made to ensure accuracy, no responsi-
bility whatsoever is taken for any loss due to publishing errors. Articles 
that cannot be used are returned to the authors if accompanied by a 
self-addressed and sufficiently stamped envelope. But no responsibility 
is taken for any loss or delay in returning the material. Disputes, if any, 
will be settled in a New Delhi court only.
SUBSCRIPTION RATES 
Year 
Newstand Price 
You Pay 
Overseas
 
(`) 
(`)
Five 
7200 
4320 
—
Three 
4320 
3030 
—
One 
1440 
1150  
US$ 120
Kindly add ` 50/- for outside Delhi cheques.
Please send payments only in favour of EFY Enterprises Pvt Ltd.
Non-receipt of copies may be reported to support@efy.in—do mention 
your subscription number.
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 5

Compiled by: 
Jagmeet Singh
Linux Foundation develops 
EdgeX Foundry to 
standardise IoT
The Linux Foundation, along 
with 50 other companies, 
is all set to standardise the 
Internet of Things (IoT) 
with its EdgeX Foundry. 
The new project unifies the 
marketplace around a new 
common open framework 
and builds an ecosystem of 
companies with interoperable 
plug-and-play components.
Security has been a major 
issue with all IoT projects. The Linux Foundation-backed EdgeX Foundry aims to 
secure the experience by standardising the IoT edge computing model. The new 
move also eases the growing concern across industry that IoT has been fragmented 
and suffers from slower growth due to the lack of a common framework.
“EdgeX Foundry is aligning market leaders around a common framework, 
which will drive IoT adoption and enable businesses to focus on developing 
innovative use cases that impact the bottom line,” said Jim Zemlin, executive 
director, The Linux Foundation.
The EdgeX development is expected to solve the complexity caused by IoT’s 
wide components range by simplifying the creation of IoT edge solutions. Using 
interoperable plug-and-play components, the framework will ease IoT product or 
solution creation for developers. The built-in components can run on any hardware 
or operating system.
The interoperability between connected devices, services and applications will 
simplify the creation of IoT projects. Moreover, the open source will give a dynamic 
nature to the projects, letting end customers adapt to changing business needs.
Dell is helping EdgeX Foundry with early stage FUSE source code under 
Apache 2.0. The FUSE project is a layer builder between messaging protocols used 
by sensor networks and cloud server layers.
Organisations like Advance Micro Devices, Bayshore Networks, Linaro, Dell, 
Canonical, VMware and NetFoundry are the founding members of the EdgeX Foundry.
OpenSUSE Tumbleweed users receive snapshot updates
OpenSUSE has received the latest set of updates and fixes. OpenSUSE Tumbleweed 
users stand to gain with this move because of the use of advanced technologies like 
KDE Plasma 5.9.5 and the GNOME 3.24.1 environment.
Douglas DeMaio from the OpenSUSE project announced the new updates. He 
highlighted the presence of the Thunderbird 52.1.0 email client, the KDE frameworks 
5.33.0, the Vim 8.0.566 editor, the Mesa 17.0.4 3D graphics library and the Zypper 
1.13.24 package manager, in addition to the fresh 
environments. These latest updates also include important 
security fixes for numerous packages in Tumbleweed.
Additionally, the open source community has 
received the OpenSUSE Leap 42.3 Build 0184 release 
FOSSBYTES
GitHub open sources its DNS 
records management tool
GitHub has open sourced its tool 
for managing DNS records. Called 
OctoDNS, the new development has 
notable features that make it easier to 
create redundancy.
DNS systems have become a 
critical focus for cyber attackers since 
the last year. Therefore, GitHub has 
developed OctoDNS and started using 
its presence internally, ahead of open 
sourcing the code.
GitHub has leveraged OctoDNS 
to keep all its records across the 
various domains in sync with 
multiple providers. If a DNS 
provider has an issue, there is an 
alternate DNS to serve user requests. 
This gives a reason to the code-
sharing platform to use the tool for 
numerous domains.
“OctoDNS has allowed us to 
revamp our DNS workflow. Our zones 
and records 
are laid out 
in config files 
stored in a 
Git repo,” 
GitHub’s 
infrastructure 
engineer Ross 
McFarland said in a statement.
The open source availability of 
OctoDNS allows anyone to submit 
pull requests to make changes in 
any of the zones and records. If 
particular team members know 
the name that they want, they can 
directly enter the URL and make  
the appropriate changes in any 
particular file. Previously, you 
were required to make such 
changes manually.
GitHub’s OctoDNS supports 
commercial providers such as 
Cloudflare, Dynect, DNSimple, 
PowerDNS and Route53. You can also 
manually select sources and providers 
from the available directories on the 
GitHub repository.
6 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

FOSSBYTES
Canonical, NetApp partner 
to deliver OpenStack-based 
solutions
Canonical has collaborated with NetApp 
to build unique open cloud solutions. 
The new partnership is set to leverage 
Ubuntu OpenStack and NetApp storage 
technologies, resulting in advanced cloud-
centric developments.
The integration of NetApp with 
Ubuntu OpenStack will ease the efforts for 
Canonical’s 
customers. 
OpenStack 
is currently being deployed as an IaaS 
(Infrastructure-as-a-Service). But the 
new collaborative services will integrate 
top-notch technologies like SolidFire and 
ONTAP into OpenStack releases.
“Together we are making it easier 
for enterprises to adopt OpenStack by 
taking the guesswork out of deploying 
and managing it,” said John Zannos, 
vice president of the cloud platform and 
alliances, Canonical, in a statement.
Canonical has been largely focusing 
on the growth across the IoT (Internet of 
Things) and cloud areas. The latest deal 
enables it to accelerate its growth in the 
cloud space.
“We are excited to be a part of 
Canonical’s OpenStack Technical 
Partner Program and are committed to 
the continued development of integrated 
cloud solutions to simplify IT delivery 
and rapidly advance new ideas from 
concept to production,” said Anthony 
Lye, senior vice president of the cloud 
business unit, NetApp.
Based in San Francisco, USA, 
NetApp recently joined the Canonical 
Cloud Partner Program. 
The Canonical-NetApp partnership 
will help organisations build automated, 
reliable and easily manageable hybrid 
as well as private clouds. Customers can 
simply deploy NetApp storage solutions 
and OpenStack using Juju. This efficiency 
will ensure organisations have to put 
minimal effort to deploy and manage 
OpenStack.
that includes all the changes implemented in the new snapshots.
Tumbleweed users have received more than seven snapshot updates recently. 
The project has received the latest versions of many widely-used applications.
Wipro joins block chain-centric Ethereum Alliance 
Wipro has joined the Enterprise Ethereum Alliance (EEA) as a founding member. 
The EEA has been founded to promote, develop and implement enterprise grade 
Ethereum-based block chain applications.
Bengaluru-headquartered Wipro has been actively contributing to Ethereum. 
The open source platform features block chain-based computing with smart contract 
functionality. “We are excited to be a part of the founding team of the Enterprise 
Ethereum Alliance and contribute towards key aspects such as security, privacy and 
scalability as these will be the key determinants in accelerating block chain adoption 
within enterprises,” said Krishnakumar 
N. Menon, vice president of service 
transformation, Wipro Limited, in a joint 
statement.
Wipro’s research and development on 
Ethereum will enable the development 
of block chain-based industry solutions 
such as Delivery versus Payments (DvP) 
settlement for securities and capital markets, skip-trace consortia for banking, peer-
to-peer (P2P) insurance for the sharing economy, and anti-counterfeit solutions for 
supply chain traceability.
“It is great to have Wipro as a founding member of the Enterprise Ethereum 
Alliance,” said Marley Gray, principal block chain architect, Microsoft. In addition 
to the in-house developments, Ethereum is being used by Wipro client companies. 
The Indian IT giant has also established the Blockchain Innovation Lab as part of its 
Blockchain COE (Centre of Excellence) to support the advanced developments. The 
lab has been founded to build use-case specific block chain solutions.
Facebook’s Oculus to plan its future around open source
Facebook-owned Oculus is set to shut down its virtual reality (VR) division, Oculus 
Story Studio. The new move is aimed to support developments around immersive 
experiences using the open source model.
Oculus’ VP of content, Jason Rubin, has announced that the shutdown of 
its Story Studio is part of the shift that will result in the company offering 
support for external production. “After careful consideration, we have decided 
to shift our focus away from internal content creation to support more external 
production,” Rubin writes in a blog post, adding, “As part of that shift, we will 
be winding down Story Studio.”
Founded in 2014, Oculus Story Studio was designed to produce original 
cinematic content for the company. Initially, 
it brought out some VR shorts to persuade 
traditional filmmakers to enter the new world of 
entertainment. However, Oculus’ team is now 
apparently seeking to build its future around open 
source.
Oculus will provide resources and programmes to help creators and third-
party developers begin with their VR solutions. At the Oculus Connect developer 
conference in October, Facebook CEO Mark Zuckerberg highlighted the investment 
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 7

FOSSBYTES
of more than US$ 250 million for building original VR content. Oculus has now 
set aside US$ 50 million from the proposed funding amount to invest exclusively 
on non-gaming, experimental VR content. “This money will go directly to artists to 
help jumpstart the most innovative and groundbreaking VR ideas,” Rubin stated.
This is not the first time that VR is exploring open source options. Platforms like 
StreamVR and Google’s Daydream VR have also opted for community moves to 
gain in the market. Last month, Facebook even launched its JavaScript framework, 
React VR, to boost the progress around simulation and immersive experiences.
Cinnamon 3.4 debuts with notable changes
After much anticipation, Cinnamon 3.4 has finally been released. The latest desktop 
environment includes changes that will be included by default within the Linux 
Mint 18.2.
Cinnamon 3.4 comes with over 160 new changes. You can expect a few more 
bug fixes and patches before the desktop environment arrives in the stable channels 
of various Linux distros.
The latest version offers a cinnamon-stap-monitor utility and better panel 
intellihide. A noteworthy addition is the ability to manage the systemd services 
in the distro. Another notable tweak is a ‘Run now’ button that appears while you 
select a row in Cinnamon’s Settings module. It eases the management of startup 
applications.
Besides, the desktop environment will no longer display the applets that do not 
offer vertical panels. You can also easily configure the LightDM login manager 
using lightdm-settings in the Cinnamon Settings module.
The new Cinnamon release displays critical notifications in full-screen mode. 
The team has also fixed the panel launcher animation, and users can control the 
acceleration and sensitivity of the mouse pointer.
GNU Compiler Collection gets anniversary update
GNU Compiler Collection (GCC) has received an update to 7.1.0. The new version 
marks the 30th anniversary of GCC.
The GCC 7.1.0 update is a major 
release for the open source community as 
it comes with several new functionalities. 
“This year, we celebrated the 30th 
anniversary of the first GCC beta release, 
and this month we will celebrate 30 
years since the GCC 1.0 release,” GCC 
developer Jakub Jelinek wrote in an 
official announcement.
The latest version brings experimental 
support for the C++17 draft library in the C++ frontend. There are also a few 
additions in the libstdc++ library. The GCC team has included the std=gnu++1z and 
-std=c++1z options as well.
Further, GCC 7.1 gets support for Address Sanitizer to report the use of 
variables. There are also improved versions of the optimisers to add new 
functionality in the link time optimisations.
Alongside the major tweaks and changes, the GCC update has the ability to 
configure OpenMP 4.5 offloading for Nvidia PTX GPUs. Tools like stink wrapping, 
code hosting and loop splitting have also been enhanced in the new version.
You can download the official source tarball of GCC 7.1.0 and compile the 
Canonical brings Kubernetes 
1.6.2 support to Ubuntu and 
Mac OS
Canonical has announced the support 
for Kubernetes 1.6.2. The latest 
development is designed specifically 
for the Canonical distribution of 
Kubernetes and the Kubernetes 
Charms.
In the latest release, Canonical 
has improved Kubernetes Charms 
and added support for Snaps to 
the kubernetes-e2e Charm. The 
Kubernetes-master layer has also 
received newly added namespace-
{list, create, delete} actions. Also, 
the Microsoft Azure cloud computing 
platform now has the clifs-utils 
package in kubernetes-worker. “This 
is the pure upstream distribution 
of Kubernetes, built with operators 
in mind,” Canonical engineering 
manager Marco Ceppi wrote in the 
official release note.
The release allows operators 
to deploy, manage and operate 
Kubernetes on a public cloud, on-
premise, on bare metal as well as on 
developer systems. There are also 
bug fixes and patches to deliver an 
improved operational experience.
Alongside the fixes, Canonical 
has enhanced the Kubernetes 
performance through a fresh Juju 
status update. There is also an added 
option of ‘-delete-local-data’ to pause. 
Besides, the new Kubernetes version 
has updated readme files in the 
kubernetes-master.
8 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

FOSSBYTES
Google patches critical flaws 
in Android through May 
update
Google has finally released its May 
security update for Android. The 
new update addresses more than 100 
vulnerabilities.
The security fixes are split into two 
patch levels—2017-05-01 and 2017-05-
05. The latest Android update addresses 
29 critical flaws in hardware-specific 
drivers, media processing servers and 
similar components.
In the list of patches and fixes, 
the 2017-05-01 version covers bugs 
and vulnerabilities that are common 
across all Android devices while the 
2017-05-05 patch level has fixes for 
vulnerabilities in hardware-specific 
drivers and components. Notably, 
the May update has patched as many 
as six critical vulnerabilities in 
Mediaserver.
Mediaserver has been full of 
flaws for many years. Though Google 
attempted to patch it several times 
in the last few years, it was until 
now relatively easy to trick users 
to download vulnerable media files 
and then exploit their devices using 
Mediaserver flaws. Attackers were 
even able to gain remote access to the 
device for code execution using the 
Mediaserver process.
Ultimately, Google has disabled 
many channels that could help attackers 
exploit the Mediaserver offering.
Google has primarily released the 
May update package for its flagship 
Pixel and Nexus devices. The 
relevant patches for Android Open 
Source Project (AOSP) are available. 
Further, Users need to wait until 
manufacturers compile the update for 
their devices.
version for your Linux distro. The stable repository for the respective distros will be 
available soon.
India IT infrastructure spending to reach US$ 2.2 billion in 
2017: Gartner
The expenditure on IT infrastructure in India is expected to reach US$ 2.2 billion in 
2017, according to research firm Gartner. Segments like enterprise networking and 
storage are expected to register growth while the spending on server equipment is 
expected to decline.
Gartner predicts that the overall IT infrastructure spending in the country will 
increase by 1.5 per cent 
over 2016. The prime 
factor behind the growth 
is touted to be the digital 
transformation that was 
kickstarted right from 
the government level — 
with the launch of public 
initiatives like ‘Digital 
India’ and ‘Make in India’.
“Digital transformation is bringing in new sets of challenges and opportunities 
for Indian infrastructure leaders,” said Naveen Mishra, research director at Gartner, 
in a statement. “They have the unique opportunity of being at the helm of this shift 
within their organisation, provided they align with the imperatives of the digital 
world,” he added.
Swift increase in the demand for cloud computing has made enterprise 
networking the ‘biggest segment’ within the entire Indian IT infrastructure market. 
The firm predicts that revenue from the enterprise networking segment will reach 
US$ 1.1 billion in 2017.
After enterprise networking comes the storage segment that is expected to reach 
US$ 352 million. Gartner believes that the small increase in revenue from US$ 
346 million in 2016 will be primarily driven by technology alternatives such as 
software-defined storage (SDS) and Flash-based storage.
In the entire Indian IT infrastructure market, server spending is predicted to fall. 
Gartner expects that the spending on server equipment will decline from US$ 765 
million in 2016 to US$ 727 million in 2017.
Despite the decline in 2017, server spending is likely to receive a marginal boost 
in 2018 and reach US$ 768 million. New developments like the advanced Linux 
distributions are expected to play a vital role over time.
Google develops a DIY kit to make Raspberry Pi smarter
Raspberry Pi Foundation has partnered with Google to launch a special DIY kit that 
comes bundled with the MagPi 57 magazine, and is designed to enable Raspberry Pi 
to build solutions around Amazon Echo and Google Home.
Called the ‘Artificial Intelligent Yourself’ (AIY), the kit comes with a Google 
Voice Hardware Attached on Top (HAT) 
accessory board and includes components such 
as a stereo microphone, large arcade button and 
a selection of wires. Google has also provided 
its iconic cardboard case that houses the entire kit in a neat and clean form — 
similar to Google Cardboard.
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 9

FOSSBYTES
“The folks at Google, along with us at the MagPi, are really excited to see 
what projects you can create (or enhance) with this kit -- whether you are creating 
a voice-controlled robot or a voice interface that answers all your questions,” said 
Rob Zwetsloot, features editor for the MagPi magazine.
You need to use your Raspberry Pi 3 to begin the action with the AIY kit. 
Also, Google has provided access to the recently developed Google Assistant 
SDK and Google Cloud Speech API to let you easily build the next Amazon 
Echo or Google Home.
Microsoft’s Imagine Cup (2017) India round winners declared
Microsoft recently announced the India winners of its Imagine Cup 2017 at a 
conference in New Delhi. The winners will represent the country at the worldwide 
finals in July 
at Seattle to 
compete against 
global talent for a 
prize worth US$ 
100,000.
The team, 
Content Holmes 
from BITS Pilani 
has emerged as the winning team among the 27 finalists from the Indian region. It 
developed a one-click artificial intelligence (AI) based online parenting solution to 
help parents keep children secure from cyber bullying.
Started back in 2003, the 15th edition of Imagine Cup attracted participation 
from more than 1,600 colleges across the country. “We had got entries from 500-
600 institutes last year, but over 1,600 colleges have participated this time,” said 
Narendra Bhandari, general manager of the developer experience and evangelism, 
Microsoft India.
Bhandari, who leads the growth of developer engagements by Microsoft in the 
country, told Open Source For You that of the 27 participating teams, 11 were led by 
women. “This is definitely heartening, if not surprising,” he said.
Microsoft had four judging panels to pick the winners. Each of the panels 
comprised different jury members, including engineers, venture capitalists/
accelerators, startup founders and academicians. And there was only one Microsoft 
employee in the panels.
“We have expanded the juries. They bring a different perspective when judging 
the ideas, and each of the widened jury panels is giving participants’ feedback to 
improve,” said Bhandari.
The aim of the Imagine Cup is not just to create startups but also to encourage 
thinking skills. Instead of focusing primarily on a proprietary solution, Microsoft 
is open to considering developments irrespective of the platform. “The message 
we give to people through the Imagine Cup is—any developer, any app and any 
platform,” Bhandari stated.
When asked about what message developers need to receive from a programme 
like Imagine Cup, Bhandari told Open Source For You that this is the best time to 
innovate. “You have all kinds of mentorship available,” he added.
Apart from Content Holmes, Mi-amigos of Chameli Group of Institutes, 
PocketConfident AI of IIT, Hyderabad, and White Cane of IIT, Kharagpur have 
emerged as the three runner-ups. Three of the four outstanding projects are based on 
AI technologies.
Google develops a 
framework to bring C++ 
closer to Python
Google has built an intrinsic open 
source project to let developers create 
C++ wrapper generators for Python. 
Called CLIF, the new framework 
automatically generates C++ library 
bindings for multiple languages, though 
it initially supports Python 2 and 3.
CLIF consists of four different 
parts, namely parser, matcher, generator 
and runtime. It leverages the LLVM 
compiler framework to convert a 
language-friendly C++ API description 
into the language-agnostic internal 
format. For collecting any typed 
information, the framework parses 
selected C++ headers with Clang.
Apart from parsing and matching 
the typed data, CLIF is capable of 
emitting C++ source code for a wrapper 
by using its generator component. 
The same wrapper is then used in the 
runtime to perform type conversions.
Google has provided elements 
such as its protobuf (for inter-
process communication between 
the CLIF front-end and back-end) 
and the CMake build system. Going 
forward, the framework is likely to 
become smarter with features such 
as inheritance. A feature to map 
exceptions in two languages is also 
expected to be added in a later version.
Meanwhile, you can access the 
CLIF code from a GitHub repository. 
The online listing explicitly mentions 
that the project has no formal link 
with Google.
10 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

advertising 
mantras
Advertising Mantras • Advertising Mantras  • Advertising Mantras • Advertising Mantras • Advertising Mantras • Advertising Mantras  • Advertising Mantras • Advertising Mantras
Advertising Mantras • Advertising Mantras  • Advertising Mantras • Advertising Mantras • Advertising Mantras • Advertising Mantras  • Advertising Mantras • Advertising Mantras  • Advertising Mantras  • Advertising Mantras • Advertising Mantras  
Advertising Mantras • Advertising Mantras  • Advertising Mantras • Advertising Mantras • Advertising Mantras • Advertising Mantras  • Advertising Mantras • Advertising Mantras  • Advertising Mantras  • Advertising Mantras • Advertising Mantras  
Advertising, if done properly, can do wonders for 
any business. Here are 10 guru mantras to help 
you understand the impact of advertising and 
more importantly—how to do it right. Wish you 
speedy growth this year.
ELECTRONICS FOR YOU
ELECTRONICS BAZAAR
OPEN SOURCE FOR YOU
For more advertising mantras, visit: http://efy.in/advertising-mantras
- Mary Wells Lawrence
The best 
advertising should 
make you nervous 
about what you 
are not buying.
- Mark Twain
Many a small
thing has been
made large by
the right kind 
of advertising.
- Derby Brown
The Business That 
Considers Itself Immune 
to The Necessity for 
Advertising Sooner or 
Later Finds Itself
Immune to Business.
Branding is 
what people 
say about you 
when you are 
not in the room.
- Jef L. Richards
Creative without 
strategy is called 
ART. Creative with 
strategy is called 
ADVERTISING.
- William Bernbach
If your 
advertising goes 
UNNOTICED 
everything else
is ACADEMIC.
- David Ogilvy
A good 
advertisement 
is one which sells 
the product 
without drawing 
attention to itself.
Good advertising 
does not circulate 
information. 
It penetrates the 
public mind with 
desires and belief.
- David Ogilvy
If it 
doesn’t sell, 
it isn’t
creative.
- Stuart H. Britt
Doing Business
Without Advertising is 
Like Dancing in The 
Dark. You Know What 
You're Doing, But 
Nobody Else Does.
- William Bernbach

FOSSBYTES
Mozilla’s JavaScript framework can understand Web pages 
just like people do
Mozilla is taking the Firefox browser to the next level with the Fathom 
JavaScript framework. The framework is helping the browser maker to extract 
the meaning out of Web pages.
Fathom is known as a mini-language for writing semantic extractors. As 
its name indicates, the Fathom framework picks out page descriptions, images 
and other items. The JavaScript framework is helping Firefox to understand 
the content and structure of a Web page. It is being used in the Activity Stream 
traffic tracker of Firefox.
Fathom can be 
implemented in a 
browser, in extensions 
and even server-side 
software. It is a data-
flow language like 
Prolog.
Mozilla’s developers 
have designed Fathom 
to calculate DOM nodes 
based on user-specified conditions, annotations and a system of types. This process 
helps the framework to extract meaning from parts like address forms, previous/
next buttons and textual content found on the website.
According to Mozilla’s senior staff software architect, Erik Rose, the 
framework is still in the early stage of development. It nevertheless enables the 
browser to identify meaningful parts on a page and show the summary.
Rule sets in Fathom are JavaScript function calls that make annotations 
in the syntax tree version. These rule sets are capable of giving automatic 
tuning of score constants. Maybe future releases will learn and generate rules 
automatically.
Raspberry Pi starts supporting Snaps
Months after they received support on multiple Linux distributions, Snaps are 
finally making way for Raspberry Pi. A Snapd build—specifically designed for 
Raspbian —has emerged to deliver the advanced experience.
Snaps were initially a part of the Ubuntu platform. But last June, the self-
contained, read-only images debuted on multiple Linux platforms to offer 
a secure solution for delivering system components and applications. That 
development had brought the Snappy technologies to distros such as Arch Linux, 
Debian, Gentoo Linux, Fedora, OpenSUSE and Yocto, among others.
Canonical developer Simon Fels has unofficially announced the availability 
of Snaps on Raspbian. Though Fels has managed to bring Snapd to the 
Raspberry Pi platform, it is yet to gain full support.
“I have initial packages for this available now and want to invite more 
people to help test these packages on their Raspbian package on their Raspbian 
systems,” Fels wrote in a forum post on Snapcraft.
Notably, the latest development is of no use if you have the first-generation 
Raspberry Pi or the Raspberry Pi Zero. The work-in-progress is also not meant 
for any production system.
Google Assistant gets native 
SDK to attract developers
Google has planned the expansion of 
the Google Assistant by launching 
its SDK. The latest move by the 
search giant is aimed at building an 
artificial intelligence (AI) powered 
ecosystem that is not just limited to 
Google apps and services and is also 
open to all developers.
“With this SDK, you can now 
start building your own hardware 
prototypes that include the Google 
Assistant, like a self-built robot or a 
voice-enabled smart mirror,” wrote 
Chris Ramsdale, product manager of 
Google Assistant, in a blog post.
The SDK comes bundled with a 
gRPC API, a Python-based open source 
client that handles 
authentication 
and access to the 
API, samples and 
documentation. 
Also, there are 
bindings for languages such as Java, 
Python, C#, Node.js and Ruby.
The cross-language support 
empowers the Google Assistant SDK 
to enable prototyping on hardware 
ranging from a smartphone or 
tablet to a Raspberry Pi 3.
Although Google has precisely 
provided most of the major features 
of the Assistant through the SDK, it 
still does not have the core hot word 
support. The engineering team at 
Google is also in development to bring 
about companion app integration.
Having said that, the initial 
SDK release is enough to influence 
developers to build new experiences 
for the Google Assistant. It could 
counter Apple’s Siri and Microsoft’s 
Cortana, over time.
You can check the features on the 
developer preview by downloading 
the Google Assistant SDK. A GitHub 
repository has also emerged to let you 
start developing your projects using 
the new offering.
For more news, visit www.opensourceforu.com
12 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

Guest Column
Exploring Software
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 13
two-year-old, low-end tablet. Hence, you may easily put your 
old tablet to good use by gifting it to a child after installing 
Sugarizer on it. In this way, you could even rationalise your 
desire to buy the replacement tablet you have been eyeing.
Does it work?
My children are too old and grandchildren too young. 
Reason tells me that it should work. Experience also tells 
me that it will most likely NOT improve school grades. I 
did not like school. I was bored most of the time. If I was 
studying in today’s schools, I would have had ulcers or a 
nervous breakdown!
When I think of schools, I recall the frustration of a child 
long ago (just 20 years) who got an answer wrong. The book 
and the teacher said that a mouse has two buttons. The mouse 
he used at home had three!
So, can you risk leaving the education of children you 
care about to the schools? Think about the skills you may be 
using today. Could these have been taught at schools a mere 
five years ago?
I never took JavaScript seriously and never made an 
effort to learn it. Today, I see Sugarizer and Snap! (a clone 
of Scratch in JavaScript) and am acutely aware of my 
foolishness. However, having learnt programming outside 
the classroom, I am confident that I can learn to program in 
JavaScript, should the need arise. 
The intention at the start was to write about the activities 
in Sugarizer and, maybe, explore the source code. My 
favourite activities include TamTam, Turtle Blocks, Maze, etc. 
From the food chain activity, I discovered that some animals 
that I had believed to be carnivores, were not. I have also seen 
children get excited by the Speak activity. 
However, once I started writing after the heading ‘Does 
it work?’, my mind took a radical turn. Now, I am convinced 
that Sugarizer will work only if you try it out. 
Sugar is a learning platform that was initially developed for 
the OLPC project. The Sugar Learning Environment can be 
downloaded and installed on any Linux-compatible hardware. 
Sugarizer mimics the UI of Sugar using HTML5 and CSS3.
Sugarizer: The Taste of 
Sugar on Any Device
T
he One Laptop Per Child (OLPC) project was launched 
less than 12 years ago. The goal of bringing down the 
cost of a laptop to US$ 100 was never really achieved. 
The project also did not turn out to be as much of a success 
as anticipated. However, the goal was not really about the 
laptop, but to educate as many children as possible. 
The interactive learning environment of the OLPC 
project was equally critical. This became a separate 
project under Sugar Labs, https://wiki.sugarlabs.org/, and 
continues to be active. The Sugar Learning Environment 
is available as a Fedora spin, and can be downloaded and 
installed on any Linux-compatible hardware. It would be 
a good option to install it on an old system, which could 
then be donated. The US$ 90 Pinebook, https://www.
pine64.org/, with Sugar installed on it would also make a 
memorable and useful gift. 
The Sugar Environment can happily coexist with other 
desktop environments on Linux. So, the computer does not 
have to be dedicated to Sugar. On Fedora, you may add it to 
your existing desktop as follows:
$ sudo dnf group install ‘Sugar Desktop Environment’
I have not tried it on Ubuntu. However, the following 
command should work:
$ sudo apt install sucrose
However, Sugar remains, by and large, an unknown entity. 
This is especially disappointing considering that the need to 
learn to learn has never been greater.
Hence, the release of Sugarizer is a pleasant surprise. It 
allows you to use the Sugar environment on any device, with 
the help of Web technologies. Sugarizer mimics the UI of 
Sugar using HTML5 and CSS3. It runs activities that have been 
written in HTML5/JavaScript. The current release includes a 
number of Sugar activities written initially in Python, which 
have been ported to HTML5/JavaScript.
You may try the new release at sugarizer.org. Better 
still, install it from Google Play on your Android tablet or 
from App Store on an Apple device. It works well even on a 
Anil Seth
By: Dr Anil Seth
The author has earned the right to do what interests him. You 
can find him online at http://sethanil.com, http://sethanil.
blogspot.com, and reach him via email at anil@sethanil.com.

Leading audio company, Sennheiser, 
has launched its versatile and vibrant 
headphones, the HD 4.50 BTNC. The 
powerful Bluetooth headphones offer 
great sound, durability and comfort. 
The detailed design is elegantly 
minimalistic yet robust. NoiseGard – an 
active noise cancellation system, helps 
users to enjoy music in peace.
The headphones come with state-
of-art wireless technology and audio 
codec for reliable transmission and 
true wireless Hi-Fi sound. The NFC 
enabled headphones are designed with 
the intuitive ear cup mounted controls 
for making calls, changing tracks 
or adjusting volume. The company 
claims the headphones offer up to 19 
NEW PRODUCTS
Sennheiser 
headphones 
with NoiseGard 
launched
Extra bass Bluetooth speaker 
from Ambrane
hours of music playback.
The HD 4.50 headphones have 
a sleek frame made of high quality 
material and a foldable headband 
design that can be easily carried in a 
protective case.
The Sennheiser HD 4.50 BTNC 
headphones can be bought at the 
company’s website.
Address: Sennheiser Electronics 
India Pvt Ltd, 104 A, B, C, First Floor, 
Time Tower, M.G. Road, Sector 28, 
Gurugram, Haryana – 122002
Multi-featured, 
sophisticated 
Webcam from 
Logitech
Personal computer and mobile 
accessories manufacturer, Logitech, 
has unveiled its latest Webcam – the 
Brio 4K Pro with support for Logitech 
RightLIght 3 along with 4K video 
quality and 5x zoom.
The device is suitable for 
businesses, home office users, 
streamers, vloggers, etc, as it delivers a 
high quality desktop video experience, 
and offers users the choice between 65, 
78 and 90 degree fields of view. The 
company claims it is the first Webcam 
with HDR (high dynamic range) and 
with support for Windows Hello and 
other infrared-based facial recognition 
applications.
The device comes with Logitech’s 
advanced lens technology with auto-
focus that offers quality videos with 
good resolution, speed, fluidity, colour 
balance and detail.
The Webcam is compatible with 
nearly all laptops and PCs as well as 
with all Logitech cloud video partners 
such as BlueJeans, BroadSoft, Vidyo 
and Zoom.
The Logitech Brio is available via 
online and retail stores.
Leading computer peripherals and 
mobile accessories brand, Ambrane, 
has introduced the compact 
Bluetooth speaker ‘BT 8000’. The 
speaker integrates powerful, high 
quality sound with a music-synced 
light show, simulating the fun and 
energy of the club experience to 
users on the go. The device includes 
precisely positioned drivers to 
provide a large, consistent sound 
field for outdoor listening.
The oval shaped speaker has the 
power and sound fidelity that was 
previously available in speakers twice 
its size, claims the company, and 
enables users to enjoy seven hours 
of non-stop music with its 3600mAh 
rechargeable battery. The BT 8000 
has a range of 10 metres and a 
speaker output of 10W.
Address: Ambrane India Pvt Ltd, A-93, 
Wazirpur Industrial Area, Wazirpur, 
New Delhi – 110052; Ph: 08588806582
It offers wireless connectivity 
with smart devices and can also be 
used to make or receive calls via 
Bluetooth enabled mobile phones at 
the press of a button.
Designed in shades of black, with 
the music-synced light show in blue 
and white, the speaker is available at 
leading online and retail stores.
Price:  
 ` 3,199
Price:  
 ` 14,990
Address: Logitech Electronics India 
Pvt Ltd, 601, Raja House, 30-31, 
Nehru Place, New Delhi – 110019;  
Ph: 011-47306600
Price:  
 ` 24,995
14 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

shooters. The dual SIM smartphone 
accepts Nano SIM and offers 
connectivity options like Wi-Fi, GPS, 
Bluetooth, NFC, USB OTG, 3G and 
4G along with sensors, including 
compass magnetometer, proximity 
sensor, accelerometer, etc.
The prices, features and specifications are based on information provided to us, or as available on various 
websites and portals. OSFY cannot vouch for their accuracy. 
HTC’s new smartphone has a liquid 
surface and is easy to hold
Compiled by: Aashima Sharma
Global networking company, Netgear, 
has launched a new Wi-Fi system called 
‘Orbi’, which it claims delivers the 
latest way to experience Wi-Fi using 
its Tri-band mesh network. The system 
helps users to enjoy high speed Internet 
even in the remote corners of a building, 
including in the attic, by the pool and 
even in the basement of a home or office.
The strong Wi-Fi coverage provides 
bandwidth even outside the home or 
office and across many floors, and the 
Internet speed stays intact even when 
more devices are added to the network.
The kit includes two pre-paired 
devices—a router and a satellite—for an 
easy out-of-the-box set-up. The system is 
capable of providing high performance 
Enjoy high speed Internet with the Tri-band 
Wi-Fi system from Netgear 
Leading Taiwanese consumer 
electronics company, HTC, has 
launched its latest smartphone, the 
HTC U Play. The smartphone has 
a 13.2cm (5.2 inch) screen with a 
resolution of 1080x1920 pixels, a new 
and sophisticated liquid surface, and a 
size that fits perfectly in your hands.
It features the HTC Sense 
companion with voice recognition, 
HTC U Sonic and 3D curved glass. It 
is powered by a 1.98GHz octa-core 
MediaTek Helio P10 processor and 
runs Android 6.0 Marshmallow.
The HTC U Play has a 4GB 
RAM and 64GB internal storage 
that can be further expanded up to 
2TB via microSD card. The device 
is powered by a 2500mAh non-
removable battery.
It comes with a 16 megapixel 
camera for both primary and front 
Price:  
 ` 29,990 
The HTC U Play is available in 
sapphire blue and brilliant black colours, 
and is available via online stores.
Address: HTC Corporation, G-4, 
BPTP Park Avenue, Sector 30, Near 
NH-8, Gurugram – 122002
Wi-Fi coverage up to 371.61 sqm (4000 
sq ft) with 802.11ac AC 3000 Wi-Fi 
speed up to 3Gbps. The Tri-band Wi-Fi 
system comes with a dedicated 5GHz 
quad stream wireless back haul between 
the Orbi router and satellite.
The Netgear Orbi Wi-Fi system is 
available via online stores.
Address: Netgear Inc., 21, 
Paharpur Business Centre, Nehru 
Place, New Delhi - 110019
Price:  
 ` 32,500 
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 15

CODE
SPORT
Sandya Mannarswamy
16 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
L
ast month, we had discussed a bunch of 
interview questions on machine learning. 
While I had received answers to some of the 
questions from our readers, I also got feedback 
that the questions were complex and hence, it 
would be good to discuss the background of 
some of the topics related to these questions. This 
will enable readers to answer the more difficult 
questions. So, in this month’s column, we will 
discuss some of the underlying concepts related 
to these questions without providing the canned 
solutions to them.
In last month’s column, we had featured a 
couple of questions on auto-encoders. As you 
know, auto-encoders are a form of unsupervised 
learning technique. They are used to learn a 
representation of the input, which can then be 
fed to other tasks. This is typically known as pre-
training, a topic that we will discuss later.  Auto-
encoders are typically used to compress a given 
input into a lower dimensional space, which can 
then be fed to a classification task. As in the case 
of PCA, auto-encoders are based on the premise 
that there is a certain correlation between some 
of the input dimensions, and so we can compress 
the input data into a fewer number of dimensions. 
However, if there is no correlation between the 
input dimensions, then compression into lower 
dimensions would not be possible and, hence, 
auto-encoders would not be able to learn a good 
compressed representation of the input.  
A simple auto-encoder network is typically 
three-layered, with an input layer, a hidden layer 
whose dimensions are smaller than the input 
layer, and an output layer. Recall that the output 
from an auto-encoder is expected to be a faithful 
reproduction of the input. Here is a question to 
our readers: What is the dimensionality of the 
output layer? Well, as you may have guessed, it is 
the same as the input layer. Let us assume that we 
have an input image whose dimensions are 10x10 
(100 pixels). Now, if we build an auto-encoder 
with an intermediate hidden layer of 50 units, the 
output of the hidden layer is a vector of dimension 
50, which is a compressed version of the input.  
Basically, the auto-encoder understands the 
structure of the data (the correlated dimensions) 
and builds a representation of smaller dimensions. 
On the other hand, let us assume that we 
have chosen a hidden layer of size 200.  Would 
it still be possible to build a better representation 
of the input? The answer is: “Yes”. If there is 
some interesting structural correlation in the 
data, by imposing certain constraints on the 
learnt representation, it is possible to get an 
improved representation, though it is of higher 
dimensions. For instance, one constraint that 
typically gets imposed is the sparsity constraint. 
We had discussed the idea behind sparse auto-
encoders in one of our earlier columns. For more 
details, the reader can refer to the discussion in 
http://ufldl.stanford.edu/tutorial/unsupervised/
Autoencoders/.
Last month’s column had also raised the 
issue of whether to use Principal Component 
Analysis (PCA) for dimensionality reduction 
or use an auto-encoder for dimensionality 
reduction. The reader was asked to reason why 
one would use auto-encoder rather than PCA 
for dimensionality reduction. Let us assume that 
the non-linear activation function in the auto-
encoder neural network was replaced by means of 
a linear function.  Now consider the compressed 
representations created by PCA and auto-encoder, 
and whether they would be in a similar sub-space 
or not.  Once you replace the linear activation 
function with a non-linear activation function 
in the auto-encoders, the input representations 
In this month’s column, we discuss some of the answers to last 
month’s questions on machine learning. 

Guest Column
CodeSport
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 17
By: Sandya Mannarswamy
The author is an expert in systems software and is currently 
working as a research scientist at Conduent Labs India 
(formerly Xerox India Research Centre). Her interests include 
compilers, programming languages, file systems and natural 
language processing. If you are preparing for systems 
software interviews, you may find it useful to visit Sandya’s 
LinkedIn group ‘Computer Science Interview Training India’ at 
http://www.linkedin.com/groups?home=&gid=2339182
discovered by them of course become very different, 
falling in different sub-spaces. 
Now let us move on to other questions from last 
month’s column. As you know, one of the biggest 
challenges in applying deep learning techniques to any 
classification is the need for huge amounts of training 
data.   Let us assume that you have been asked to 
classify each sentence in a large corpus of sentences as 
positive, negative or neutral, which is the well known 
sentiment classification task.  Now you have the choice 
of using a standard machine learning technique such 
as Support Vector Machines using a Bag of Words 
feature vector. This definitely seems simple and 
straightforward.  
Let us also assume that given your recent interest 
in deep learning, you want to see if you can use a 
neural network such as a feed forward neural network.  
In that case, the first question you need to answer is 
whether you have adequate data to train your neural 
network.  You have two choices: (a) You can either go 
with a simple feed forward neural network with two 
hidden layers of dimension X or, (b) you can opt for a 
deep forward neural network with five hidden layers 
of dimension X.  Would the same labelled data set size 
suffice for both cases?  As you may have guessed, the 
deeper the neural network, the more labelled data it 
needs for training it without overfitting. While there are 
different techniques such as drop-out, shared weights, 
etc, which avoid over-fitting, one of the simplest ways 
to do this is to have adequate amounts of training 
data. Since you have been given a set of labelled data 
samples, in last month’s column readers were asked to 
come up with techniques which could help increase the 
size of labelled data.  
If the input data is in the form of images, one of the 
simplest ways of increasing the labelled data set’s size 
is by applying label-invariant transformations such as 
scaling, rotation, etc, to obtain a new image to which 
we can apply the same label.  If you are instead given 
a labelled set of sentences for sentiment classification, 
as in our example above, how would you increase the 
size of the training data? Well, one of our readers had 
pointed out that we could use a lexicon based approach 
to create new labelled samples, wherein we can replace 
individual words with their equivalent words from the 
lexicon. This is a good answer. Can you think of other 
ways by which you can generate multiple different 
sentences from the same sentence, without changing its 
target sentiment? 
By now, the attentive reader would have figured out 
that we did not really answer the question on how much 
training data would suffice for training a neural network 
without overfitting. Well, there is no single right answer 
in this case.  It would depend on how many parameters 
you have in the network, which in turn depends on the 
number of hidden layers and the dimensions of each layer.  
One often-quoted number is 100,000 instances of labelled 
data distributed across all the categories that you are trying 
to classify. But please take this number with a pinch of 
salt. While a smaller number may suffice for a shallower 
network, you may need a larger number of labelled 
instances for a much deeper network. I have not found 
any good rule which explains, quantitatively, how much 
training data would be sufficient, given a fixed deep neural 
network architecture. Also, you need to think about the 
quality of your labelled data. For instance, let us assume 
that you are doing sentiment classification and you have the 
following two sentences:
(a) This movie was awfully bad, it was a waste of money.
(b)  This restaurant was awfully bad, just waste of money.
Though these two sentences may be two separate 
labelled instances, the second sentence does not allow 
the model to learn anything new as it is very similar to 
the first sentence. Hence, it is not just the quantity of 
the labelled data, but also the quality that matters when 
deciding the performance of your approach. Ultimately, 
it is the performance of your algorithm on the test data 
that matters. Hence, one way of making sure that your 
network is not overfitting is to measure the training 
error and test error on your data set. If you find that 
by increasing the training data size, your test error  
reduces, the model is learning new information from the 
augmented training data, which allows it to generalise 
well on the unseen test data. On the other hand, if 
you find that only the training error reduces, but the 
augmented training data does not improve the test error, 
you are better off without augmenting the training data.  
There is a detailed discussion on how much training 
data is sufficient for training a deep neural net on Quora, 
which you may want to look at:  https://www.quora.
com/How-much-data-is-enough-to-train-a-deep-NN-
model.
If you have any favourite programming questions/
software topics that you would like to discuss on this 
forum, please send them to me, along with your solutions 
and feedback, at sandyasm_AT_yahoo_DOT_com. Till 
we meet again next month, wishing all our readers a 
wonderful and productive month ahead!  

Will Norris, engineering manager at 
Google’s Open Source Programs Office
Everyone knows that Google is a leader in the open source world. But what is it that 
makes it a distinct player in the fast-growing developer community? Will Norris, the 
engineering manager at Google’s Open Source Programs Office, reveals some 
secrets in an exclusive talk with Jagmeet Singh of OSFY. Edited excerpts...
“Open source development at
is both very diverse
and distributed”
Q 
What is the development 
model for open source 
technologies at Google?
Open source development at Google 
is both very diverse and distributed. 
The larger projects that we release 
generally have dedicated teams 
developing and supporting the project, 
working with their external developer 
communities and providing internal 
support to other Googlers. Many of 
the smaller projects include just one or 
two engineers working on something 
experimental or just a fun, side 
project. While we do have a central 
Open Source Programs Office (the 
group I manage), it is relatively small 
compared to the size of the company. 
Instead, the actual development 
happens throughout the company, with 
hundreds of teams and thousands of 
engineers, tech writers, designers and 
product managers contributing to open 
source in some way.
For U & Me
Interview
Interview

Q 
What is the process 
that Google follows to 
identify a project as an open 
source release?
Most often, the decision to open source 
a project at Google comes from the 
product team members themselves. 
There are a lot of different reasons why 
they might do this. TensorFlow is a 
good example of us having worked 
on machine learning within Google 
for many years, and then seeing an 
opportunity to push the entire industry 
forward by releasing the work that we 
had done. Because open source has 
been a part of Google’s culture for so 
long, its benefits are generally well 
understood throughout the company 
and so releasing a given project 
is very natural.
Q 
Apart from releasing 
projects for developers, how 
does Google deploy open source 
internally to develop innovations?
Internally, most of the source code 
for all Google products is stored in 
one monolithic repository. So in many 
ways, it is like a big open source 
project where just about everyone 
can see everyone else’s code. This 
allows Googlers to read others’ code 
to learn from it. It also means that 
they can submit patches to other 
teams’ projects to help improve them. 
The new buzzword for this is ‘inner 
source’, but for us, it is just how we 
have always operated.
Beyond that, we also make it really 
easy for Googlers to bring outside 
open source code into the company. In 
terms of comparing just the number of  
lines of code, we have nearly as much 
external open source code as we have of 
code that we’ve authored ourselves.
Q 
What are all the leading open 
source projects that Google 
leverages to build new solutions?
There is probably not a single Google 
product that is not touched by open 
source in some way—whether it is a 
library used directly by the product, 
our build and testing tools, or our 
data centres that they run in. Big 
projects like Linux can also be found 
in our data centres and at the heart of 
products like Android and Chrome OS. 
Likewise, LLVM is used extensively 
as part of the build toolchain, and most 
of the development languages we use 
are all open source.
Q 
How do open source 
engineers at Google plan 
project life cycles?
We have never had a ‘one size fits all’ 
approach to open source. Instead, we 
are comfortable with project heads 
making the decisions. Most of our 
projects are developed completely 
in the open, with very little internal-
only discussion or planning. There are 
certainly cases where development or 
planning happens internally, and there 
are different reasons for that. There 
is a real cost to that style of project 
management, particularly in terms of 
community development, so we do 
our best to help educate teams on the 
trade-offs and then let them make the 
decision that is right for their project.
Q 
What is the average 
time frame at Google for 
moving a project from its alpha 
stage to beta?
Some projects are public right from 
when the very first line of code is 
written, while others have been 
developed internally for quite some 
time before being released publicly. 
So projects may be in very different 
stages of development when they are 
announced. One thing we are trying to 
do better is making it more clear what 
stage a project is in.
Q 
How do Google engineers 
test an open source project 
before its public release?
Some of the bigger releases we have 
done in the last few years were based 
on technologies that have existed within 
Google for many years. For example, 
TensorFlow was based on our internal 
machine learning platform called Brain; 
GRPC is based on our internal RPC 
system called Stubby; Bazel was called 
Blaze internally before it was released 
online; and Kubernetes was the result 
of our years of experience with our 
internal job scheduler called Borg. So, 
in many respects, these projects were 
tested in the most rigorous manner by 
first powering Google products and 
infrastructure.
Now that is not true of all (or maybe 
even most) of our open source projects. 
The small- to medium-sized projects go 
through the same ‘dogfooding’ trials as 
Google products, where they are tested 
internally by fellow Googlers prior to 
public release.
Q 
How does Google enable 
community engagements 
around its various open 
source projects?
We generally use the same tools as the 
rest of the open source community, 
which includes GitHub, IRC or Slack, 
Stack Overflow, mailing lists and 
meetups, among others. Also, we have 
a strong presence at many open source 
conferences, and so engage with the 
community members there or wherever 
else they happen to be.
We have an extensive network of 
Google Developer Groups around the 
world, and these are also a great place 
for community engagements.
Q 
How does the Open Source 
Programs Office develop 
new policies related to open 
source projects?
Google’s Open Source Programs 
Office has been around for almost 13 
years. So our policies have developed 
somewhat organically over the years 
as the company has grown and new 
For U & Me
Interview
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 19

challenges have emerged. Last month, 
we actually published all of our policies 
and documentation on our new open 
source-centred site (opensource.google.
com). These docs are based on all the 
lessons we have learned from working 
with open source at a large technology 
company for many years. We know that 
the way we do things may not be right 
for everyone else, but we published 
these docs under an open licence so 
others can adapt them to whatever 
makes sense at their company.
Q 
Is it the commercialised 
open source or FOSS (free 
and open source software) that 
gets more interest from Google?
Many successful free and open source 
projects have corporate sponsorship 
in varying forms, even if that simply 
means that they have employees whose 
full-time jobs are to work on the 
project. This is probably the biggest 
way that Google supports many open 
source projects. For instance, we do 
give money to the foundations behind 
Linux, LLVM, Git and Samba. But, 
more importantly, we employ engineers 
whose sole job is to contribute to and 
help maintain those projects because 
they’re very important to us.
Q 
What do you think are 
the major challenges 
in releasing an open source 
solution nowadays?
Once you get past whatever technical 
problem a given project is trying to 
address, one of the biggest challenges 
almost inevitably ends up being 
community management. But this is 
when people mess up, but also not be 
afraid to pull out the weeds when they are 
choking out the flowers.
We know we do not always hit that 
mark, but that is what I aim for.
Q 
In addition to your current 
role at Google, you are 
apparently a huge supporter of 
WordPress. What do you feel 
makes WordPress a platform that 
has democratised publishing?
Particularly as WordPress is self-hosted 
on a personal domain name, anyone can 
download the software, load it up on 
their server or any hosting platform and 
publish on the Internet without having to 
ask anyone for permission. There are no  
use policies that need to be ‘accepted’ 
specifying what you can and cannot post, 
and there are no terms and conditions to 
agree to. Today, countless platforms are 
enabling you to do this, but that was not 
as true 10 to 15 years ago.
Q 
What do you think are the 
major common factors 
between Google and WordPress?
Both believe, at the most fundamental 
level, that the Internet must be an open 
platform for innovation.
Q 
Finally, how do you see 
the future of open source, 
moving beyond Google and 
WordPress?
There is far more open source code 
yet to be written than everything that 
exists today. So really, we are still only 
at the beginning of the open source 
growth curve. We all have to look 
forward to it. 
not unique to open source; it is also true 
inside any engineering organisation. 
People are complicated and messy. 
They can have very strong opinions, 
they often do not care about the same 
things you care about, and they have 
lives outside of your project that will 
at some point bleed into their work in 
unexpected and inexplicable ways.
Managing people, whether that 
means a formal employee relationship 
or just as a part of an open source 
community, is incredibly hard. But it 
can be so incredibly rewarding.
I believe helping facilitate a group 
of diverse people with a common 
goal and working together to build 
something is greater than the sum of 
their individual contributions. That is at 
least why I love what I do.
Q 
How does Google resolve 
those challenges?
That is really the key question! It starts 
with trying to create an environment 
where people feel welcome to participate, 
and where they really can contribute on 
an equal footing. It also means being 
honest about the fact that conflict will 
arise and being prepared to handle it 
when it does. All this means fostering an 
environment where grace can be extended 
We have never 
had a ‘one size fits 
all’ approach to 
open source.
Your favourite Magazine on Open 
Source is now on the Web, too.
OpenSourceForU.com
Follow us on Twitter@LinuxForYou
For U & Me
Interview
20 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 21
Admin
How To
I
n this fourth article in the DevOps series, we will learn to 
install RabbitMQ using Ansible. RabbitMQ is a free and 
open source message broker system that supports a number 
of protocols such as the Advanced Message Queuing Protocol 
(AMQP), Streaming Text Oriented Messaging Protocol 
(STOMP) and Message Queue Telemetry Transport (MQTT). 
The software has support for a large number of client libraries 
for different programming languages. RabbitMQ is written 
using the Erlang programming language and is released under 
the Mozilla Public License.
Setting it up 
A CentOS 6.8 virtual machine (VM) running on KVM is used 
for the installation. Do make sure that the VM has access to 
the Internet. The Ansible version used on the host (Parabola 
GNU/Linux-libre x86_64) is 2.2.1.0. The ansible/folder 
contains the following files: 
ansible/inventory/kvm/inventory
ansible/playbooks/configuration/rabbitmq.yml
ansible/playbooks/admin/uninstall-rabbitmq.yml
The IP address of the guest CentOS 6.8 VM is added to 
the inventory file as shown below: 
rabbitmq ansible_host=192.168.122.161 ansible_connection=ssh 
ansible_user=root ansible_password=password
Also, add an entry for the rabbitmq host in the /etc/hosts 
file as indicated below: 
192.168.122.161 rabbitmq
Installation 
RabbitMQ requires the Erlang environment, and uses the Open 
Telecom Platform (OTP) framework. There are multiple sources 
for installing Erlang — the EPEL repository, Erlang Solutions, 
and the zero-dependency Erlang provided by RabbitMQ. In this 
article, we will use the EPEL repository for installing Erlang. 
---
- name: Install RabbitMQ server
  hosts: rabbitmq
  gather_facts: true
  tags: [server]
  tasks:
    - name: Import EPEL GPG key
      rpm_key:
        key: http://dl.fedoraproject.org/pub/epel/RPM-GPG-
KEY-EPEL-6
        state: present
    - name: Add YUM repo
      yum_repository:
DevOps Series  
Ansible Deployment of RabbitMQ 
RabbitMQ, which is free and open source, is the world’s most 
widely deployed message broker. It is used by several big 
companies like Ford, Instagram, Cisco, etc. Being easy to 
deploy, it can be used in situ or on the cloud. 

22 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Admin
How To
Figure 1: RabbitMQ login 
Figure 2: RabbitMQ overview 
        name: epel
        description: EPEL YUM repo
        baseurl: https://dl.fedoraproject.org/pub/
epel/$releasever/$basearch/
        gpgcheck: yes
    - name: Update the software package repository
      yum:
        name: ‘*’
        update_cache: yes
    - name: Install RabbitMQ server
      package:
        name: “{{ item }}”
        state: latest
      with_items:
        - rabbitmq-server
    - name: Start the RabbitMQ server
      service:
        name: rabbitmq-server
        state: started
    - wait_for:
        port: 5672
After importing the EPEL GPG key and adding the 
EPEL repository to the system, the yum update command is 
executed. The RabbitMQ server and its dependencies are then 
installed. We wait for the RabbitMQ server to start and listen 
on port 5672. The above playbook can be invoked as follows: 
$ ansible-playbook -i inventory/kvm/inventory playbooks/
configuration/rabbitmq.yml --tags “server”
Dashboard 
The RabbitMQ management user interface (UI) is 
available through plugins. 
- name: Start RabbitMQ Management UI
  hosts: rabbitmq
  gather_facts: true
  tags: [ui]
  tasks:
    - name: Start management UI
      command: /usr/lib/rabbitmq/bin/rabbitmq-plugins enable 
rabbitmq_management
    - name: Restart RabbitMQ server
      service:
        name: rabbitmq-server
        state: restarted
    - wait_for:
        port: 15672
    - name: Allow port 15672
      shell: iptables -I INPUT 5 -p tcp --dport 15672 -m 
state --state NEW,ESTABLISHED -j ACCEPT
After enabling the management plugin, the server needs 
to be restarted. Since we are running it inside the VM, we 
need to allow the management user interface (UI) port 
15672 through the firewall. The playbook invocation to set 
up the management UI is given below: 
$ ansible-playbook -i inventory/kvm/inventory playbooks/
configuration/rabbitmq.yml --tags “ui”
The default user name and password for the dashboard 
are ‘guest:guest’. From your host system, you can start 
a browser and open http://192.168.122.161:15672 to 
view the login page as shown in Figure 1. The default 
‘Overview’ page is shown in Figure 2. 
Username:
Password:
Login

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 23
Admin
How To
Ruby 
We will use a Ruby client example to demonstrate that 
our installation of RabbitMQ is working fine. The Ruby 
Version Manager (RVM) will be used to install Ruby as 
shown below: 
- name: Ruby client
  hosts: rabbitmq
  gather_facts: true
  tags: [ruby]
  tasks:
    - name: Import key
      command: gpg2 --keyserver hkp://keys.gnupg.net --recv-
keys 409B6B1796C275462A1703113804BB82D39DC0E3
    - name: Install RVM
      shell: curl -sSL https://get.rvm.io | bash -s stable
    - name: Install Ruby
      shell: source /etc/profile.d/rvm.sh && rvm install ruby-
2.2.6
    - name: Set default Ruby
      command: rvm alias create default ruby-2.2.6
    - name: Install bunny client
      shell: gem install bunny --version “>= 2.6.4”
After importing the required GPG keys, RVM and Ruby 
2.2.6 are installed on the CentOS 6.8 VM. The bunny Ruby 
client for RabbitMQ is then installed. The Ansible playbook 
to set up Ruby is given below: 
$ ansible-playbook -i inventory/kvm/inventory playbooks/
configuration/rabbitmq.yml --tags “ruby”
We shall create a ‘temperature’ queue to send the values in 
Celsius. The consumer.rb code to receive the values from the 
queue is given below: 
#!/usr/bin/env ruby
require “bunny”
conn = Bunny.new(:automatically_recover => false)
conn.start
chan  = conn.create_channel
queue = chan.queue(“temperature”)
begin
  puts “ ... waiting. CTRL+C to exit”
  queue.subscribe(:block => true) do |info, properties, body|
    puts “ Received #{body}”
  end
rescue Interrupt => _
  conn.close
  exit(0)
end
The producer.rb code to send a sample of five values in 
degree Celsius is as follows: 
#!/usr/bin/env ruby
require “bunny”
conn = Bunny.new(:automatically_recover => false)
conn.start
chan   = conn.create_channel
queue   = chan.queue(“temperature”)
values = [“33.5”, “35.2”, “36.7”, “37.0”, “36.4”]
values.each do |v|
  chan.default_exchange.publish(v, :routing_key => queue.
name)
end
puts “Sent five temperature values.”
conn.close
As soon as you start the consumer, you will get the 
following output: 
$ ruby consumer.rb 
 ... waiting. CTRL+C to exit
You can then run the producer.rb script that writes the 
values to the queue: 
$ ruby producer.rb
Sent five temperature values.
The received values at the consumer side are printed out 
as shown below: 
$ ruby consumer.rb 
 ... waiting. CTRL+C to exit
 Received 33.5
 Received 35.2
 Received 36.7

24 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Admin
How To
By: Shakthi Kannan
The author is a free software enthusiast and blogs at 
shakthimaan.com.
 Received 37.0
 Received 36.4
We can observe the available connections and the 
created queue in the management user interface as shown in 
Figure 3 and Figure 4, respectively. 
Uninstall 
It is good to have an uninstall script to remove the 
RabbitMQ server for administrative purposes. The Ansible 
playbook for the same is available in the playbooks/admin 
folder and is shown below: 
---
- name: Uninstall RabbitMQ server
  hosts: rabbitmq
  gather_facts: true
  tags: [remove]
  tasks:
    - name: Stop the RabbitMQ server
      service:
        name: rabbitmq-server
 Figure 3: RabbitMQ connections 
 Figure 4: RabbitMQ queues 
        state: stopped
    - name: Uninstall rabbitmq
      package:
        name: “{{ item }}”
        state: absent
      with_items:
        - rabbitmq-server
The script can be invoked as follows: 
$ ansible-playbook -i inventory/kvm/inventory playbooks/
admin/uninstall-rabbitmq.yml
You are encouraged to read the detailed documentation at 
https://www.rabbitmq.com/documentation.html to know more 
about the usage, configuration, client libraries and plugins 
available for RabbitMQ. 

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 25
Developers
Let’s Try
I
n this article, we will take a look at the Ubidots platform 
and understand the process of signing up, ingesting our 
sensor data into the platform and visualising it. 
Features
The platform is available as a service and offers the 
following features:
 
APIs to ingest your sensor data from any device.
 
Support for both HTTP and MQTT protocols for data 
ingestion. 
 
Dashboards to help you visualise your IoT data.
 
Alerts for your users/applications based on your 
sensor data.
 
Integration with more than 20 devices (Adafruit, 
Arduino, Particle, Tessel and others) to help jumpstart 
moving your IoT data to the Ubidots platform.
 
Free to get started with education and business pricing 
plans, based on your requirements.
Getting started
The first step in using the Ubidot platform is to sign up 
for its service. Signing up is free and provides you with 
the ‘Education plan’, which is sufficient to get started 
on small projects or proof-of-concept applications. 
The signup page is located at https://app.ubidots.com/
accounts/signup/ and after successfully signing up, you 
will head to the Ubidots home page, where you can see 
that you have been provided 5000 credits to use. We will 
refer to this home page as the Web portal.
Obtaining the Ubidots API Token
One of the important things to do upfront is to note down 
your API token. This will be required later in the article 
when we use the HTTP API as a primary mechanism to 
ingest our sensor data into the Ubidots platform. The API 
token is available when you click on your account name on 
the top right corner of the Web portal and then on the API 
Sign Up with Ubidots to 
Power Your IoT App
Ubidots is a hosted IoT platform in the cloud that can help to jumpstart your IoT application. 
It was created in a startup accelerator, and has since powered hundreds of IoT applications 
across multiple sectors like healthcare, energy, etc, in more than 40 countries. 

26 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
credentials, as shown in Figure 1.
This will lead to a page where you 
will be shown an API key and a default 
API token. Carefully note down the API 
token and store it. From now, we will 
refer to this as the API_TOKEN. 
Setting up the device
The first thing that we should do is 
to set up our devices in Ubidots. The 
‘Free Plan’ comes with support for 
20 devices. Think of these devices 
as those that collect sensor data like 
temperature. So let’s assume that 
we have deployed a device named 
D1, from which we are capturing 
temperature data via a standard 
temperature sensor. You can have up to 
20 devices uniquely configured, which 
will help you filter, track and measure 
the data that is coming from various 
devices, by identifying them via the 
device’s label.
So let’s go ahead and set up a device 
named D1. Follow the steps given below.
1. From the Web portal, visit the 
Devices link at the top. By default, 
when you go to the Devices page, it 
will show that a default device has 
been configured. I suggest that you 
delete it, so that we can start with a 
clean slate as shown in Figure 2.
2. Click on the Add Device icon. Name 
the device D1, as shown in Figure 3.
3. Click on device D1. This will 
lead you to a detailed page, as 
shown in Figure 4.
4. Now, we need to add a variable. 
This variable can be the sensor data 
that we are tracking — for example, 
temperature. We can capture more 
than one variable or sensor data 
coming from a single device. Click 
on the Add Variable icon shown in 
Figure 4. Select Default and then 
name the variable as Temperature, 
as shown in Figure 5.
We have successfully created 
a device D1 that will provide us 
temperature values, which we will track 
via the temperature variable that we 
created and associate with this device. 
Let us now look at how we can get our 
sensor values into the system.
The HTTP API
Ubidots supports both the HTTP and 
MQTT protocols as a way to ingest 
data into the system. In this article, 
Log out
Docs
My Proﬁle
API Credentials
romin
Add Device
My Devices
Dashboards
Devices
Events
Figure 1: API credentials
Figure 3: Details about the device
Figure 5: Temperature variable
Figure 2: Adding a new device
D1
No Last Activity
0 Variables
we will focus on the HTTP API, and 
demonstrate how you can ingest data 
into your application. In our case, 
we will assume that the sensor data 
is being generated by device D1 and 
the sensor data is a temperature that is 
being recorded.
The API endpoint is available 
at https://things.ubidots.com/api/
v1.6/ and we will need to use the 
API_TOKEN as well as our device and 
variable that we have created to push 
data into the system.
To send values into the system for 
a specific device and variable, we need 
to do a HTTP POST to the HTTPs 
URL, the format of which is given 
below: http://things.ubidots.com/api/
v1.6/devices/{LABEL_DEVICE}/
{VARIABLE_LABEL}/values
So for our device D1, the 
{LABEL_DEVICE} will have the 
value ‘D1’ and for the {VARIABLE_
LABEL}, we shall use the value 
‘temperature’. In addition, we will 
need to append the API_TOKEN value 
to the URL as a request parameter. 
No last activity
temperature
Last Activity
Figure 4: Add a variable for the device
Your Device doesn’t have a location
D1
Description
API Label
Tags
Last Activity
ID
You can add a location to your Device by clicking here
Click here to add a description
590969fd7625421b6ce1a68e
Add Variable
No last activity
Add tags
d1

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 27
Developers
Let’s Try
The variable name to be used for the 
API_TOKEN is token.
Sample request
For example, if we wish to push 
the value of 29.5 as the temperature 
value for device D1, we will need to 
do a HTTP POST, as follows: https://
things.ubidots.com/api/v1.6/devices/
D1/temperature/values/?token =API_
TOKEN
…with the POST body as follows:
{“value”:”29.5”} 
We can also provide the context 
and timestamp variables that are 
optional but can be useful for tracking 
the location of the device, and also the 
timestamp at which the sensor value 
was recorded. The data that will be 
passed in the HTTP POST request body 
will then be as follows:
{“value”:29.5”,”timestamp”:146466136900
0,”context”:{“lat”:19.07,”lon”:72.87}}. 
When you send the context, the 
Ubidots dashboard that we saw earlier 
will recognise it as a GeoPoint and will 
plot it on the map.
Sample transactions
We can use the curl utility to do a 
few sample HTTP POST requests to 
our endpoint, so that we can see how 
we can then visualise the data in the 
Ubidots dashboard. 
Here is a sample curl request for 
inserting temperature sensor data read 
at device D1:
$ curl -X POST -H “Content-Type: 
application/json” -d ‘{“value”:29.7, 
“context
“:{“lat”:19.07, “lng”:72.87}, 
“timestamp”:1493817120}’ http://things.
ubidots.com/api/v1.6/devices/D1/
temperature/values?token=
u31S5yB1GaKnD64DwOJsKWYEcje9nv
{“url”: “http://things.ubidots.com/
api/v1.6/values/5909899e7625421b6
8f86883”, “value”: 29.7, “timestamp”: 
Figure 6: Sample temperature value
Figure 7: Temperature data
Figure 8: Temperature dashboard
2 minutes ago
Last Activity
temperature
29.70
temperature
30
30
30
29
70/01/18 12:26:57
29.7
Description
API Label
Allowed range
ID
Clink here to add a description
min - max
temperature
59098c347625421b6926afc2
temperature
Statistic
temperature 29.7
:57.120
temperature
temperature
29.70
29.50
29.6
:57.150
:57.200
1493817120, “context”: {“lat”: 19.07, 
“lng”: 72.87}, “created_at”: “2017-05-
03T07:41:18.226”}
Similarly, create a few more 
values with different timestamps and 
temperature values to simulate data 
being received from the sensor.
If you visit the Web portal and click 
on Devices, you will find the value has 
got recorded, as shown in Figure 6.
You can even click on the 
variable, i.e., temperature, to see the 
details in the graph (Figure 7).
Dashboard
The Ubidots dashboard allows 
you to create dashboards where 
you can add graphical widgets 
to visualise your sensor data 
from various devices. To create 
a dashboard, you can go to the 
Web portal and then click on 
Dashboard. Simply add a new 
dashboard, select a chart type 
from one of the many options 
offered (for example LineChart), 
and then select the device and the 
variable. In our case, it is device 
D1 and the variable Temperature.
Once you have added that to the 
dashboard, you can see it as shown 
in Figure 8.

28 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
By: Romin Irani
The author has been working in the software industry for 20+ years. His 
passion is to read, write and teach about technology and make developers 
successful. He blogs at www.rominirani.com.
[1] Ubidots Home: https://ubidots.com/ 
[2] Ubidots developer portal: https://ubidots.com/docs 
[3] Ubidots pricing page: https://ubidots.com/pricing 
[4] Ubidots sample projects: https://www.hackster.io/ubidots/projects 
[5] Ubidots academy: https://www.youtube.com/playlist?list=PLlZkMpUnBb2
b33bANxC4uY3iBNJaXB5J3 
[6] Ubidots API clients: https://ubidots.com/docs/api-clients/index.html
References
Events
A powerful feature of the Ubidots 
platform is to set alerts on your sensor 
data. For example, we can raise an alert 
in case the temperature goes over 30°C. 
If that condition is met, we can deliver 
the alert via email or SMS, invoke a 
Webhook, etc. 
To configure a sample event, you 
can go to the Web portal and click on 
Events. Then add a new event, select 
the device and variable, and define 
the condition as shown in Figure 9. 
For example, we have selected the 
temperature variable for device D1 and 
set a condition of > 30°C (greater than 
30 degrees Centigrade). The graphical 
configuration is shown in Figure 9.
Click on Continue and you will be 
asked to select the medium via which 
the alert can be sent. The list of delivery 
channels is shown in Figure 10.
Click on Finish to create the event, 
and then the alert will be raised on any 
sensor value for a temperature that is 
above 30°C from device D1. 
Client libraries
You can integrate the API calls for 
ingesting data into the system via 
various client libraries that are made 
available in Ubidots. Client libraries 
are available for multiple popular 
languages like Python, Java, Node.js, 
Ruby, Android and others. This makes 
the task of collecting any sensor data 
from an application straightforward, 
removing the burden of dealing directly 
with HTTP request/response handling 
in your code.
The API methods are not just to 
save values but also for creating data 
sources (devices), creating variables, 
getting values of variables and for the 
bulk import of variable values.
A sample code in Python for 
ingesting values is given below:
from ubidots import ApiClient
api = ApiClient(token=’<API_TOKEN>’)
# Get Temperature Variable
my_variable = api.get_
variable(‘<VARIABLE_ID’)
# Save Temperature Variable
new_value = my_variable.save_
value({‘value’: 29.5})
Ubidots’ pricing
Ubidots has flexible pricing. There 
Figure 9: Event condition configuration
Figure 10: Event notification channel configuration
are two plans available: 
Education and Business. 
The Education plan is free 
and lets you connect up to 
a maximum of 20 devices, 
allows data retention for 
30 days and a maximum 
sensor data ingestion 
rate of 60 per minute. 
This should be sufficient 
for most hobbyists and 
enthusiasts who want 
to get started with the 
platform. The Business 
plan caters to a greater 
number of devices, an 
on-demand ingestion rate 
and a management suite. 
The pricing is available 
on call. You can find out 
more about the differences 
between the Education 
and Business plans on the 
pricing page. 
Ubidots is a powerful 
hosted IoT platform that 
provides features to ingest, 
process and visualise your 
IoT application data. It is 
quick to get started with, 
and provides easy-to-use 
REST APIs to help you decouple your 
sensor infrastructure and focus on 
pushing the data out to the platform, 
where you can transform it to a higher 
level application domain. It is an 
excellent platform to build your IoT 
proof-of-concept application and take 
your idea to a wider audience. 
Send e-mail Send SMS
Send
Telegram
WebHook
Set a variable
Add number
Phone number
Message
United States +1
Finsh
Phone number
Hi romin, variable temperature is greater than 30
Select a Device
Filter Devices
Filter Variables
temperature
D1
temperature
less
greater less or equal greater or 
equal
30
than
if
equal
Value
Select a Variable

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 29
Developers
Let’s Try
Runs everywhere; enables us to API everything, code with joy, stream Big Data 
and build big apps—that’s what Zetta does for us.
T
he Internet of Things is one of the hottest topics in 
the tech industry. By using IoT, we can easily connect 
with different objects and interact with them, like the 
way we are engaging with current smart technologies. It will 
change how we live, significantly. IoT offers tremendous 
opportunities, but there are substantial risks too. In this 
article, we will look at how we can leverage the advantages 
of Zetta, an API platform in IoT.
What is Zetta?
Zetta is an open source platform for IoT on which we can 
build APIs for device interaction. The platform is built on 
Node.js. People who are familiar with Node.js can easily get 
started with Zetta but, for beginners, a basic understanding of 
Node.js is required. 
Let’s understand the Zetta platform and its 
characteristics
 
Zetta is an open source platform, so anyone can use it 
free of cost. If you are passionate about Node.js (https://
nodejs.org/), then you can contribute to this open source 
project. Currently, the community is small, but it’s 
growing. Basically, it’s a tool that will help to generate 
APIs which we can use to communicate between devices.
 
Node.js is basically a server-side JavaScript. Developers 
can define devices as state machines using JavaScript. 
It is also cross-platform and is easily deployable in 
multiple cloud platforms.
 
Zetta is an API driven platform. Every call is API based 
so that we can use these APIs for any other purpose like 
sending data to other analytics platforms.
Zetta: An API-First 
IoT Platform  

30 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
 
Zetta exposes Websocket endpoints to stream real-
time events. This model of merging Hypermedia with 
Websocket streaming is acknowledged as Reactive 
Hypermedia.
 
It can support almost all device protocols, and mediate 
them to HTTP. Connections between servers are also 
persistent, so that we can use the seamless services 
between servers in the cloud.
 
We can create stateless applications in Zetta servers. 
Applications can be useful to connect devices, run 
different queries and interact between them. We can also 
write queries and triggers so that whenever new devices 
are attached, we will be notified. 
Zetta architecture
The Zetta server: The Zetta server is the main component of 
Zetta, which contains different sub-components like drivers, 
scouts, server extensions and apps. A Zetta server will run on 
a hardware hub such as BeagleBone Black, Raspberry Pi or 
Intel Edison. The server manages interactions between all the 
sub-components in order to communicate with devices and 
generate APIs, by which consumers can interact.
Scouts: Scouts provide a discovery mechanism for devices 
on the networks or to those which require system resources to 
understand and communicate with a specific type of protocol. 
Scouts help Zetta to search for devices based on a 
particular protocol. They also fetch specific information about 
devices and whether those devices have already interacted 
with Zetta or not.  They maintain security credentials and 
related details while communicating.
Drivers: Drivers are used to represent the devices in a 
state machine format. They are used for modelling devices 
and physical interaction between devices. Device models are 
used to generate different API calls.
Server extensions: These are used for extending 
functionalities. They are in a pluggable mode, and deal with 
API management, adding additional securities, etc. 
Registry: This is a database for the Zetta server, which 
stores information about the devices connected to the server. 
It is a persistence layer.
Secure linking: We can establish secure and encrypted 
tunnelling between different servers while communicating. 
This takes care of firewalls and network settings. 
Apps: Apps that are used for different interactions 
between devices or to fetch and process some data are created 
in JavaScript. Apps can be created based on sensor streams or 
changes in devices. They can be used to track certain kinds of 
events that happen in systems.
Zetta deployment
Now let us explore the deployment of Zetta.
1. The Zetta server runs on a hardware hub, which can be 
Raspberry Pi, Intel Edison or BeagleBone Black.
2. The hub is connected to devices, and they communicate via 
HTTP to the specific protocols used in the deployment.
3. Another similar server runs in the cloud, which has the 
same Node.js packages that are available on the Zetta 
server in the hub. Both the servers are connected.
4. Zetta provides an API at the cloud endpoint so that 
consumers can use it.
Hardware requirements: Zetta runs with 
approximately six connected devices per hub, which is the 
ideal scenario suggested by it. Hardware requirements are 
dependent upon the number of devices, the load of each 
device and the type of data flowing between them. The 
ideal minimum requirement is a 500MHz CPU, 500MB 
RAM and storage of 1GB-2GB. Zetta requires 500MB to 
be able to run. It supports all common operating systems 
with 32-bit and 64-bit versions.
Zetta installation and demo project
Now let’s take a look at installing Zetta and a ‘Hello world’ 
version of the Zetta sample project. Before starting Zetta, 
here’s a brief introduction to Node.js.
Figure 1: Zetta architecture
Figure 2: Zetta deployment
Zetta Server
HUB
ZS
Device
Device
Device
Device
Zetta Server
Scouts
Drivers
HTTP API
Z2Z Connections
Server 
Extensions
Registry

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 31
Developers
Let’s Try
Node.js
This is built on Chrome’s JavaScript runtime for building 
scalable and faster applications. It uses an event-driven, non-
blocking IO model. It is popular and very efficient for real-time 
applications running across distributed systems. Basically, it’s 
a server-side JavaScript.
Go to the official site https://nodejs.org and from the 
Downloads section, download the appropriate installer file 
based on the operating system. More details about creating 
projects in Node.js are described in the following steps.
Zetta installation 
For Zetta installation, the first thing required is Node.js. 
As discussed, download the Node.js installer on to your 
system. This will install both Node.js and npm (node package 
manager). So we don’t need to install anything separately; it’s 
a complete package. We can verify the versions by using the 
commands shown in Figure 3.
Creating a Zetta project
1. Create a new directory to save the project, e.g., demo-zetta.
2. Now cd to that directory. Here, it’s cd demo-zetta.
3. To create a new Node.js project, run the command 
given below:
npm init
4. You will be asked for basic information about the project. 
By default, it will choose the value if you press Enter. If 
you want to change the value, then do so and press Enter 
several times and finish the installation. Basically, it will 
create a package.json file, which contains meta data about 
the project and its dependencies.
5. Now we will install the Zetta Node.js module. Here, 
the -save option adds Zetta to the package.json 
dependencies list.
npm install zetta -save
After all these steps, we have a basic Zetta project, which 
contains a package.json file and a node_modules directory. 
Next, let’s configure the Zetta server.
Zetta server configuration
We can install the Zetta server locally as a Zetta hub or in 
the cloud. We can link both the servers to access it from 
everywhere. Here we will install it locally for demo purposes. 
1. Go to the demo-zetta directory.
2. Create a new file called index.js, and copy the code 
given below into it:
var zetta = require(‘zetta’);
zetta()
  .name(‘Zetta Demo’)
Figure 3: Node.js version
Figure 4: Creating the Node.js project
Figure 5: Installing the Zetta Node.js module
Figure 6: Node.js Zetta server status

Earn up to 
₹1,00,000 
per hour 
 
Curious? Mail us at 
contact@loonycorn.com 
 
 Step 1: You work with us to create a course proposal 
for a 2-10 hour course 
 
 Step 2: We pay you an advance of ₹ 5,000/hour upon 
course approval 
 
 Step 3: You build the course, we help 
 
 Step 4: We grade your work and pay according to the 
rate card below (rates per hour) 
Grade A:  ₹100,000 | B:  ₹50,000 | C:   ₹25,000  | F:  ₹5,000     

Loonycorn 
Our Content: 
 
 The Complete Machine Learning Bundle 
 
10 courses |  63 hours |  $39 
 
 The Complete Computer Science Bundle 
8 courses  |  78 hours |  $39 
 
 The Big Data Bundle 
9 courses  |  64 hours |  $45 
 
 The Complete Web Programming Bundle 
 
8 courses  |  61 hours |  $41 
 
 The Complete Finance & Economics Bundle 
9 courses  |  56 hours |  $49 
 
 The Scientific Essentials Bundle 
 
7 courses  |  41 hours |  $35 
 
 ~20 courses on Pluralsight  
 
~70 on StackSocial 
~65 on Udemy 
 
About Us: 
 
 ex-Google | Stanford | IIM-Ahmedabad | INSEAD 
 50,000+ students  

34 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
  .listen(1337, function(){
     console.log(‘Zetta is running at 
http://127.0.0.1:1337’);
});
 3. Now save and close the file. 
After performing the steps given above, we have 
configured a basic Zetta server hub.
Starting the server
In the demo-zetta directory, enter the command given below:
node index.js
Figure 6 demonstrates the output of the above command. 
It shows the status of a running server.
Calling the Zetta API
Now, let’s call the Zetta API. We need to call the server’s 
root URL for that. Here we can use the  curl command with 
http://127.0.0.1:1337 or any REST client tools.  I am using 
the Rest Web Service Client. I have shared the download link 
in the References section at the end of the article. 
In the URL section of the REST client, enter 
http://127.0.0.1:1337 and submit the request. 
Now, in the response (formatted) section, you can see the 
response (see Figure 7). Check it for more information.
The Zetta server returns a JSON object that describes the 
root class of the API. The response demonstrates the current 
API state and links to resources given by the API. This is the 
By: Maulik Parekh
The author has an M. Tech degree in cloud computing 
from VIT University, Chennai. He can be reached at 
maulikparekh2@gmail.com. Website: https://www.
linkedin.com/in/maulikparekh2.
[1] Node.js official website: https://nodejs.org
[2] Zetta official website: http://www.zettajs.org/
[3] Rest Web service client installation link: https://chrome.
google.com/webstore/detail/rest-web-service-client
[4] GitHub link for Zetta: https://github.com/zettajs/zetta/wiki
References
Figure 7: The Zetta API call response
Figure 8: Demo Zetta server API response
basic API, which is not doing anything much as we don’t 
have devices attached. Once we add the devices, the API 
will show more information.
Zetta API follows the Siren hypermedia 
specification. For more information on that, you can visit 
https://github.com/kevinswiber/siren.
Zetta API is a built-in feature of Zetta, which 
automatically generates APIs for devices. We can deploy 
these APIs in the cloud, which allows any authorised 
user to communicate with these devices from anywhere.
Everything is API based.  All the information 
is stored in JSON format, so that we can use it on 
different platforms and take advantage of it. We 
can use the link http://localhost:1337/servers/
Zetta%20Demo to check the API response for the 
demo Zetta server.  

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 35
Developers
Let’s Try
This tutorial takes readers through the process of developing a basic GUI application 
using JavaFX in Eclipse, and is simple enough for even a beginner to follow.  
Developing a Basic GUI Application 
Using JavaFX in Eclipse
A 
graphical user interface or GUI is a computer 
program that makes it easy to talk to your device. 
GUIs are used in almost every electronic device 
worldwide owing to their ease of use, interactive designs and 
higher accessibility. Even the OS installed in your computer 
is an example of a GUI. In this tutorial, we will look at 
developing a basic GUI in Java using the JavaFX library. The 
only pre-requisite for this tutorial is that you need a basic 
understanding of the Java language and of the Eclipse IDE. 
But before that, let’s take an overview of JavaFX.
JavaFX: The future
Oracle defines JavaFX as “…the next step in the evolution 
of Java as a rich client platform.” JavaFX was first launched 
by Sun Microsystems in 2007 and JavaFX 1.0 was released 
in December 2008. The latest release is JavaFX 8 and it 
comes bundled with JRE/JDK for Java 8; hence, the name. It 
is widely regarded as the future in developing sophisticated 
applications – whether Web based, desktop based or for the 
mobile – and is rapidly replacing Swing owing to its various 
advantages. These include being lightweight, having CSS 
styling, sleek design controls, and the use of FXML and 
Scene Builder.
Scene Builder and its role in GUI development
Oracle.com defines Scene Builder as “… a visual layout 
tool that lets users quickly design JavaFX application user 
interfaces, without coding.” That’s right—you can actually 
design different controls in your application, like textboxes, 
dropdowns, labels, buttons, etc, without actually coding them 
in your favourite integrated development environment (IDE). 
Isn’t that easy and time saving? This is a standalone tool, 
which can be embedded in your IDE workspace for rapid 
development. A drag-and-drop feature is available (the same 

36 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
as in the current version of Visual Studio), in which users can 
select their required controls and add them to their respective 
work area, modify them and design them by applying CSS 
stylesheets. An FXML file gets generated automatically in the 
project you are working on, which is the essence of JavaFX.
After Java 8 update 40, Oracle has stopped providing 
installers for Scene Builder. They will be provided only as 
source code. But users need not worry, since an organisation 
named Gluon has taken up the task of helping the developer 
community by managing and updating the Scene Builder 
project. You only have to download it from the Gluon website 
http://gluonhq.com/products/scene-builder/ free of cost, and 
the installer will install it on your machine.
Configuring JavaFX in Eclipse IDE
In this tutorial, I will use the Eclipse IDE version Neon 
(4.6) for compiling and running my code, but you can use 
any version above 3.4. Before we go into the actual coding 
process with JavaFX, let’s see how we can install the JavaFX 
plugin in Eclipse because the latter doesn’t provide support 
for JavaFX, by default. The requisite for this is that you 
should have Eclipse downloaded on your system and Java 8 
installed, because we will use the latest JavaFX 8 to develop 
our application. If you don’t have Eclipse, you can download 
it from http://www.eclipse.org/downloads/ and you can 
also download Java 8 from Oracle’s official website. Once 
downloaded, start Eclipse and set your workspace for your 
project. There are two ways in which you can provide support 
for JavaFX in your project. One is by adding a ‘.jar’ file to 
your Java project and the other is by installing the JavaFX 
plugin. Going forward, we will explore both ways.
Adding a JavaFX jar
1. Create a new Java project in your workspace by going to 
File menu > New and giving the appropriate name.
2. Right-click on your created project and go to the 
Properties option.
3. Select Java Build Path in the Properties dialogue box.
4. Select the Libraries tab and check whether your JRE 
system library corresponds to Java version 8. If not, add it.
5. Now click on the Add Library button on the right side and 
select User Library from the dialogue box that appears. 
Click Next.
6. Click on the User Libraries button on the Add Library 
dialogue box and the Preferences window will open.
7. Click New, provide a suitable name for your library and 
then click OK.
8. Your library will be added to the libraries list as shown in 
Figure 1. Select that library and click on the Add External 
JARs button.
9.  Now browse the folder where your Java 8 is installed, 
generally in your C: drive, and select the file jfxswt.jar by 
going into the folder structure as jdk 1.08_101 > jre > lib.
10. Check the library that you have created and click OK or 
Apply, wherever applied.
After this, you can start developing your applications in 
JavaFX. Now, we will take a look at the second way in which 
we can associate JavaFX with Eclipse. By using this method, 
you can directly define a JavaFX project, unlike the first 
method in which we first defined a normal Java project and 
blended it into JavaFX using the JavaFX JARs.
Installing the JavaFX plugin
1. In the Eclipse IDE, click on the Help menu on the 
menu bar.
2. Under the Help menu, click on the option to Install 
New Software.
3. A dialogue box to install new software will open. In 
Work with textbox, type the URL http://download.
eclipse.org/efxclipse/updates-released/2.4.0/site and 
Figure 1: JavaFX user library will be created
Figure 3: First JavaFX application
Click me to reveal the above text
Click me to reveal the above text
Figure 4: Output of the application
Figure 2: JavaFX project with all the necessary files and JDKs attached
User Libraries
User libraries can be added to a Java Build path and bundle a number of extern 
archives. System libraries will be added to the boot class path when launched.
Defined user libraries:
JavaFX
New...
Edit...
Trial
src
application
Main.java
application.css
JRE System Library [JavaSE-1.8]
JavaFX SDK
build.fxbuild
Problems
Javadoc
Declaration
Entered text is This is exciting world of JawaFX
<terminated> driverClass [Java Application] C:\Program Files\Java\jre1.8/0
Console

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 37
Developers
Let’s Try
click on the Add button.
4. The Add Repository dialogue box will open. Give any 
related name to the repository, and in the location textbox 
copy the above URL again and click OK.
5. Click on Select All to select all the components and click Next.
6. Again click on Next on the next window of the dialogue box.
7. The Review License window will open. Click the I accept 
terms… radio button or you can also go through the licence 
agreement if you wish to. Now click the Finish button.
8. It will take some time to install the plugin.
9. After the progress bar shows that Eclipse has completed 
its installation of the plugin, it will ask you to restart the 
Eclipse IDE. Click Yes to restart it.
After Eclipse has been restarted, you can verify your 
installation by creating a new JavaFX project. For this, go to 
File > New > Project and scroll down to the JavaFX option 
available in the New Project dialogue box. Expand it, select 
the JavaFX project and click Next. Give your project an 
appropriate name, click Next and then Finish. Now you can 
view a newly created JavaFX project as shown in Figure 2 
and you can start working on it.
After having installed the JavaFX plugin and JAR in the 
Eclipse IDE, we will start off with the coding of our first 
JavaFX application. This will be a basic GUI with a textbox 
that will accept any text and a button, which on clicking, will 
print whatever text you have entered in the textbox. I know 
it’s a pretty basic implementation, but this will help you to 
understand how the code works and the different components 
necessary for the development of multi-tier applications.
Coding your first JavaFX GUI application
I know you must be excited to code your first JavaFX 
application. You probably know by now that there are two 
ways to create a project. The first way is to create a normal Java 
project and associate the necessary JARs with it. The second 
way is to directly create a JavaFX project. We will use the 
second method in this tutorial but to develop your application, 
you can choose any method, based on your convenience. To 
start off, open the Eclipse IDE, set an appropriate workspace and 
create a new JavaFX project as mentioned above. 
1. After you have created your project, you can view it in 
your Package Explorer. Expand your project and you will 
be able to view the src folder and other necessary files, like 
the JRE system library and the JavaFX SDK attached to it.
2. Expand the src folder and delete the auto-generated 
package application by choosing the Delete option and 
right-clicking on it.
3. Now right-click on the src folder and add one package 
to it.
4. After your defined package has been created, create a 
new driverClass.java class under that package. Now we 
can start with the code.
5. Write the code given below in your Java class. This 
code is without exception handling and I will explain it 
after running it.
import javafx.application.Application;
import javafx.event.ActionEvent;
import javafx.event.EventHandler;
import javafx.geometry.Insets;
import javafx.scene.Scene;
import javafx.scene.control.Button;
import javafx.scene.control.TextField;
import javafx.scene.layout.BorderPane;
import javafx.scene.layout.VBox;
import javafx.stage.Stage;
public class driverClass extends Application{
 
public static void main(String[] args) {
 
 // TODO Auto-generated method stub
 
 launch(args);
 
}
 
@Override
 
public void start(Stage primaryStage) throws Exception 
{
 
 // TODO Auto-generated method stub
 
 primaryStage.setTitle("Open Source For You - First 
program");
 
 TextField textField  = new TextField();
 
 Button btn = new Button("Click me to reveal the 
above text");
 
 btn.setOnAction(new EventHandler<ActionEvent>() {
 
  
 
  
@Override
 
  
public void handle(ActionEvent event) {
 
  
 
// TODO Auto-generated method stub
 
  
 
System.out.println("Entered text is " +   
  
   
 
 
 
 
 
 
 
textField.getText());
 
  
 
textField.clear();
 
  
}
 
 });
 
 BorderPane pane = new BorderPane();
 
 pane.setPadding(new Insets(70));
 
 VBox paneCenter = new VBox();
 
 paneCenter.setSpacing(10);
 
 pane.setCenter(paneCenter);
 
 paneCenter.getChildren().add(textField);
 
 paneCenter.getChildren().add(btn);
 
 Scene scene= new Scene(pane, 400, 200);
 
 primaryStage.setScene(scene);
 
 primaryStage.show();
 
}
}
Continued on Page 43...

38 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
Conda, which is included in Anaconda and Miniconda, is an open source package 
management system and environment management system for installing multiple 
versions of software packages and their dependencies, and switching easily between 
them. It is multiplatform, working on Linux, OS X and Windows, and was created for 
Python programs but can package and distribute any software.
R
emember ‘Anaconda’, that horror movie with the tag 
line “You can’t scream if you can’t breathe.”? Well, a 
few years ago, Python had an encounter with Anaconda, 
and today, it acts as the backbone of Anaconda. Confused? I 
am now referring to Anaconda, the Python distribution that acts 
both as a package manager and an environment manager. But 
before we talk a bit more about this Anaconda, here’s a brief 
introduction to package managers. 
Package management 
Some applications cannot stand alone. They need the support 
of other applications to work. The applications that need 
to be installed for the proper working of an application are 
considered its dependencies, e.g., IPython needs python-
decorator and python-simplegeneric to be installed in a 
system to work properly. 
You can install packages either manually or by using 
some package managers. If you install a package manually, 
that package alone will be installed. Its dependencies 
should, therefore, be installed separately. As the number 
of dependencies increases, it becomes difficult to install 
all the packages manually. A package manager deals with 
this problem. According to Wikipedia, a package manager 
is a collection of software tools that automates installation, 
updation, configuration and removal of software in a 
consistent manner. Thus, a package manager resolves all the 
dependencies of a given software. 
The following are some of the package managers 
available for Linux distributions.
1. dpkg: A low level package management system, it 
uses the Debian repository to install packages that 
come in the .deb format. All the dependencies of the 
package to be installed will be contained within the 
.deb file. The command…
dpkg -i <package-name>
…can be used to install a package.
Conda: The Soul of Anaconda

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 39
Developers
Let’s Try
2. apt-get: A more advanced package management system, 
it makes use of the topological sorting technique to 
resolve dependencies of the packages, and calls dpkg 
at the appropriate times for installation or deletion of 
packages. It uses archives of Ubuntu and Canonical as 
repositories. The command…
sudo apt-get install <package-name>
…will install the package. sudo is used since package 
installation requires administrative rights. 
3. Aptitude: This provides a graphical interface for apt. 
4.    pip: pip stands for Pip Installs Packages. It is a Python 
package manager. Any Python package available in the 
PyPI repository can be installed using pip. The command 
for installing this package is: 
pip install <package-name>
Though package managers like pip can deal with almost 
all Python packages, they neglect non-Python packages, 
which are dependencies of our package of interest. 
Package dependencies may differ because package 
managers differ. This is because different package managers 
refer to different repositories. Some repositories may contain 
a lot of packages, and package managers referring to these 
repositories will install the necessary packages and all the 
dependencies in that repository.  
Figure 1, Figure 2 and Figure 3 illustrate the scenario 
when I tried to install IPython using apt-get, conda and pip. 
We can see that the list of dependencies is different. Just 
remember that when more packages are used in a program, 
they may occupy more space. 
Anaconda and Miniconda
A distribution is a collection of pre-compiled and pre-
configured packages that work together. Anaconda and 
Miniconda are free Python distributions that provide both 
an environment manager and a package manager. They are 
helpful when you are into deep learning or for data science 
applications, but are not limited to these domains. Other than 
the package manager Conda, Conda-build, Python and over 
150 packages are automatically downloaded with Anaconda. 
Miniconda includes Conda, Python and its dependencies only.
The power of Anaconda can be explained with the 
help of the following example. If you are into deep 
learning, you may need many packages. Applications 
using ResNet may require packages like pillow, Keras 
and Theano for proper working. If you install Anaconda, 
all these packages are automatically installed. Installation 
of Miniconda may require us to install many packages 
as and when required. 
According to Continuum Analytics, Conda is an open 
source environment management system and package 
Figure 1: IPython using apt-get
Figure 2: IPython using conda
Figure 3: Ipython dependencies when installed using pip
management system for installing multiple versions of 
packages and its dependencies. It was first developed in 2012.
Conda installation 
Conda can be installed along with Anaconda or Miniconda. 
You can also purchase an Anaconda subscription to install 
Conda. The choice between Anaconda and Miniconda 
depends on the time available and the disk space. If you have 
minimum 3GB disk space to spare, and need all the options 
of Conda, download Anaconda. If you have low disk space 
and you just need a start with Conda, a minimal version of 
Anaconda called Miniconda will be the best option, as it takes 
only 400MB of space. You can download a 32-bit or 64-bit 

40 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
installer. Both the packages are available in Python 2 base 
and Python 3 base. Installation steps for different operating 
systems are given below. 
Installation in Windows: Download the exe installer for 
Anaconda or Miniconda. Run the file to get it installed. To 
open it in a terminal, go to Start button and click on Run, then 
open the command prompt (cmd). 
Installation in Linux: Download the bash installer for 
Anaconda or Miniconda. Type the following command in a 
terminal to install 64-bit Python 3 based Miniconda:
bash Miniconda3-latest-Linux-x86_64.sh
…where Miniconda3-latest-Linux-x86_64 is the name of 
the file you have downloaded. 
Once the installation is completed, close the terminal 
before using Conda. This is done to make sure that the 
changes made are saved. 
Installation in macOS: Anaconda provides a command-
line installer and GUI installer for macOS users. If you 
choose the GUI installer, double click on the .pkg file 
downloaded, and follow the instructions to get it installed in 
your system. The GUI installer may take more time. So if you 
are comfortable with the command-line installer, go for it. 
If you download the command-line installer, follow 
the same procedure as for installation in Linux. You must 
remember that even if you are not using the bash shell, you 
must include the bash command for installation. 
Miniconda installation is the same as the command-line 
installation of Anaconda. 
Conda without Anaconda or Miniconda: Conda can 
also be installed using pip, with the following command:
pip install conda
This command will install Conda without Anaconda or 
Miniconda.  This method can be adopted easily in Linux. But 
it is difficult to install pip in Windows. pip comes along with 
Python 2.7.9 and above.
To update Conda, type the following command 
in the terminal:
 conda update conda 
In Windows, Conda can be uninstalled by following the 
steps given below:
1. Go to Control Panel.
2. Select Add or Remove Program.
3. Select Python 3.4(Miniconda) and uninstall it.
In Linux and macOS, use the following command to 
uninstall the Miniconda directory:
rm -rf ~/miniconda
The Miniconda install directory will now be deleted. 
But you may still be able to access the packages. To 
delete Miniconda completely from the system, edit 
~/.bash_profile and remove the Miniconda directory from 
the PATH variable.  You will no longer have access to 
Conda packages. 
To verify the installation of Conda, type:
conda list 
This command will display the installed packages in the 
terminal if the Conda installation is successful. Otherwise, 
a message that ‘Conda is not recognised as an internal or 
external command, operable program or batch file’ will be 
displayed on the screen.
Why do we need Conda?
Continuum Analytics has developed Conda with a view 
to supporting data analysis and scientific computing 
applications. Scientific applications handle huge amounts of 
data. And a variety of packages may be needed to process 
such large volumes of data. Conda uses the rich repository 
of Anaconda, which contains almost all the necessary 
packages for scientific programming. It is an alternative to 
the above mentioned package managers.
Another important use of Conda is in creating a 
virtual environment. You can use virtual box to create a 
virtual environment. In that case, you are using a separate 
platform which needs separate resources. But a Conda 
generated virtual environment doesn’t need a separate 
platform. It is very easy to get into the environment and 
to get out of it. You may be familiar with virtualenv, 
which is a tool similar to Conda. A comparison of 
both can be found in the link https://conda.io/docs/_
downloads/conda-pip-virtualenv-translator.html
Conda allows you to install different versions of 
the same package on the same machine but in different 
environments. Suppose you need Matplotlib 1.4 to run 
an application and Matplotlib 1.5 is needed for another 
application. A single environment cannot accommodate 
both these versions at the same time. Since Matplotlib 1.5 is 
the upgraded version of Matplotlib 1.4, you can use Conda 
to create different environments and install the different 
versions in them; you can then run the applications in their 
respective environments without any trouble.
Everything related to an environment is localised. If you 
install a package in a root directory, its dependencies and 
related information will be dispersed in different directories 
in the system and hence deletion may not be possible by 
using a single command. In case of virtual environments, 
everything related to an environment will be stored in 
a single directory. So once the environment is deleted, 
everything related to that will also be automatically deleted. 

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 41
Developers
Let’s Try
Working with Conda
Conda, being a powerful tool, can create environments 
and can deal with packages. Hence, it is called both an 
environment manager and a package manager. The general 
syntax of a Conda command is as follows:
conda [-h] [-V] command.....
… where -h is help and –V gives the Conda version 
installed in our system.
The following is a list of Conda commands. 
 
info: Displays current Conda install details including 
platform, Conda version, Python version, root 
environment, environment directories, channel URLs 
and configuration file.
 
list: Displays the list of installed packages in a Conda 
environment.
 
help: Shows the list of Conda commands and their 
options. For example: 
conda list -h
…displays the options available for the list command. 
 
search: Displays a list of packages matching the search 
string. 
 
create: Creates a virtual environment for the user to 
work with.
 
install: Installs the specified packages to the Conda 
environment. 
 
upgrade: Updates the installed packages to the latest 
compatible versions.
 
remove: Removes the specified packages from the 
Conda environment.
 
config: .condarc can be modified using this command.
 
clean: Removes unused packages and caches.
Creating an environment 
When you want to experiment with packages, but don’t 
know their side effects on the system configuration, or you 
have an application that needs a package version different 
from the version you have already installed in your system 
(and the already installed version is needed for working of 
some other applications), you can create an environment 
other than the root environment. Such an environment will 
be virtual, and will work using the existing resources of the 
platform on which it is created. 
The following command will create an environment env_
name with no specific packages installed in that environment:
conda create --name env_name
You can alternatively use -n for --name. You can install 
packages in the environment at the time of creation by 
modifying the above command as follows:
conda create -n env_name list_of_packages
If you want to install a specific version of a package, you 
can specify a version number along with the package name. 
For example, Python 3.4.6 and numpy 1.2 can be installed in 
an environment named ‘py’ at the time of its creation using 
the following command:
conda create -n py python=3.4.6 numpy=1.2
It is worth noting that the environment created using 
Conda is isolated, but not in every sense. Consider the 
following scenario. You have installed Python 2.7.12 
based Miniconda in your system. You are creating a virtual 
environment without specifying any packages. You may 
think that, in this condition, a newly created environment 
cannot serve any purpose because it does not contain any 
packages. But while installing Miniconda, packages like 
Python and its dependencies are automatically installed, 
and the Conda environment created has access to these 
packages. It has access to the root directory also. In this 
scenario, if you want to install any other version of Python 
in the virtual environment, it is advisable to install the 
package at the time of the creation of the environment 
itself. The same is true about any package being installed 
with Miniconda.
Once a virtual environment is created, the command to 
activate that environment will be automatically displayed in 
the terminal. In Linux based systems, you can activate it using 
the following command:
source activate env_name
Installation of packages
Being a package manager, Conda can be used to install or 
uninstall packages. Packages can be installed in the current 
environment using the following command:
conda install package_list
If you want to install packages in an environment other 
than the current environment, use the following command:
conda install -n env_name package_list
As stated earlier, versions can be specified along with the 
package name.
Other package managers like apt-get and pip can also be 
used to install packages in a Conda environment. At times, 
when Conda fails, pip may succeed. This is because some 
Python packages not available in the Conda repository are 

42 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Let’s Try
available in the PyPI repository.
The following command will uninstall the package and its 
dependencies from the environment, env_name:
conda remove --name env_name package
The following command will deactivate the environment 
in Linux based systems:
source deactivate
 
At the time of creation of an environment, the command to 
deactivate it will also be displayed to the user. It is unnecessary 
to specify the name of the environment; the current environment 
will be automatically deactivated by this command.
The following command will delete the environment and 
the packages associated with it: 
conda remove --name env_name --all
List of packages in an environment 
To list the packages installed in a particular environment, use 
the following command:
conda list --name env_name
If you omit --name env_name, packages in the current 
environment will be listed.
List of environments
Two commands can be used to get the list of 
environments. These are:
conda info --env
…or:
conda env list
The current environment is distinguished from other 
environments with a ‘*’ as shown in Figure 4.
Copy an environment 
It is possible to copy an environment from one system to 
another. We can export the configuration of the current 
environment into a .yml file using the following command:
conda env export > file_name.yml
The yml file generated can be copied to any number of 
systems. The following code shows the content of a yml file 
generated when the configuration of an environment f1, which 
does not have any packages installed in it, is exported to a file:
name: f1
channels:
- defaults
prefix: C:\Users\admin\Miniconda3\envs\f1
The configuration of another environment in which pip is 
installed looks as follows:
name: n1
channels:
- defaults
dependencies:
- pip=9.0.1=py36_1
- python=3.6.1=0
- setuptools=27.2.0=py36_1
- vs2015_runtime=14.0.25123=0
- wheel=0.29.0=py36_0
prefix: C:\Users\admin\Miniconda3\envs\n1
Packages other than pip in the dependencies list are the 
dependencies of pip that are automatically installed. Once the 
file is copied to the destination system, execute the following 
command to create an environment exactly similar to the one 
in the source system:
conda env create -f file_name.yml
A folder named n1, which is the name of the environment 
as specified in the environment file, will be created in the 
destination system in the path miniconda3/envs. When you 
execute the above command in the destination system, make 
sure that your current directory is Miniconda3. 
YML file
YAML is an Ansible configuration management language. Every 
YML file is organised as a list or record containing one or more 
members. All the members in a list will begin with a ‘-’ (hyphen 
followed by a single space). A dictionary will be arranged as 
a ‘key: value’ pair (the colon must be followed by a space). 
Members of the same list or record will be arranged with the 
same indentation. This much detail is enough for creating an 
environment file. More details about YAML syntax can be found 
at http://docs.ansible.com/ansible/YAMLSyntax.html.
Figure 4: List of environments 

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 43
Developers
Let’s Try
Creating an environment from a file
Just as the configuration of an environment can be 
copied to a file, it is possible for users to create an 
environment file themselves. The Conda environment 
file may contain the following records: name, 
channels and dependencies. To create an environment 
using a yml file, the file should contain the name of 
the environment at least. Channels contain the list of 
paths or URLs of repositories where Conda should 
look for the packages to be installed. ‘defaults’ in 
the channel list indicates that Conda should search 
in the default repositories while installing packages.  
Users are allowed to give their priorities for selecting 
channels. The following code shows a configuration 
file, in which it is specified that numpy must be 
installed from the Anaconda repository:
name: e1
channels: 
- https://anaconda.org/conda-forge/numpy
dependencies: 
- numpy
Dependencies list the packages to be installed 
in the environment. It is okay if we do not know the 
dependencies of a particular package.  Conda, while 
By: Sharon Sunny
The author is an assistant professor at Amaljyothi College of 
Engineering, Kerala. She can be reached at ssharon099@gmail.com.
[1] https://conda.io
[2] http://docs.ansible.com/ansible/YAMLSyntax.html
References
creating an environment from the file, will check for the 
dependencies of the packages specified in the file and 
resolve them. 
Configuration file
The .condarc file is generated by the command: 
conda config
This configuration file will help advanced users 
to set their preferences for Channels, configure proxy 
servers, set package managers, and much more. 
Thus, Conda that comes with Anaconda or 
Miniconda opens up the magic world of packages for 
data science applications. It is a powerful alternative 
to many package managers as well as environment 
managers. 
6. Now the coding is complete for your first JavaFX 
application. Run your project and you will see the 
window shown in Figure 3.
7. Check your application by typing some text and clicking 
the button. The output will be printed on the console.
Having coded your application and successfully run it, 
let’s take a look at the code and how it works.
Every JavaFX application must extend the Application 
class as done above, and will consist of a Stage which will 
contain Scene, which will, in turn, contain Layout. Layout 
will contain all the widgets or controls like buttons, text 
fields, etc, of your application. 
 
In the above code, in the Main method, we have called the 
Launch method, which will launch your application. In the 
overridden Start method, we have designed our GUI. 
 
First, we have defined two controls—one text field 
and one button. To the button, we have added an 
event handler, which performs the action when we 
click the button.
 
Then we have defined a layout, which is BorderPane 
in this case; next, we have defined and added VBox 
By: Vinayak Vaid
The author works as an automation engineer at Infosys 
Limited, Pune. He has worked on different testing technologies 
and automation tools like QTP, Selenium and Coded UI. He can 
be contacted at vinayakvaid91@gmail.com.
to our border pane (through the pane.setCenter() 
method), which will help us to keep our controls 
vertically below each other.
 
Then, we have added controls to our VBox (through the 
getChildren() method).
 
We have then defined Scene as explained earlier and 
added our BorderPane to it. Finally, we have added Scene 
to the Stage, and then we have displayed the Stage using 
the show() method.
This concludes our tutorial for a basic JavaFX GUI 
application development through Eclipse. I hope you have 
got a fair idea about the different components of JavaFX and 
how to implement them in application development. If you 
have any doubts, you can reach me at my email. 
Continued from Page 37...

Developers How To
44 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
App Inventor is a visual block-building language for creating 
Android apps. Over the past few months, we have been 
developing simple Android apps through a series of articles, each 
covering a particular aspect of App Inventor. Read on for the 
latest addition to this series…
tutorial, I would like to revise things 
quickly. In our application we are going 
to use Firebase, a Google provided 
cloud database, which is open source 
and freely available for use.
Features of Firebase
1. Firebase uses a GUI based data 
centre so that you can visually see 
all the entries and can manage them.
2. Being on the cloud, it is accessible 
to any device, on the go.
3. Smart authentication provides 
secure access.
4. Its real-time database reflects 
changes as soon as the data is 
updated.
5. It allows the addition of 
collaborators so that multiple people 
A
ndroid devices are beginning 
to play a larger role in our 
lives. Whether it is accessing 
entertainment websites, networking on 
social media,  watching videos over the 
Internet, chatting with relatives, making 
reservations/bookings or performing 
banking transactions, Android has 
become a crucial need.
Tech enthusiasts like you keep 
thinking up ways to make Android 
even smarter by developing useful 
apps.  App Inventor is a great tool for 
this purpose. So let’s proceed in our 
quest of mastering App Inventor by 
creating a more complex and useful 
Android application. 
The theme of the application
Taking attendance is a teacher’s first 
task. The class attendance register and 
pen are the only tools to accomplish 
this task. What if we provide a digital 
solution to handle this task? Sounds 
interesting, right? So let’s try to build 
a smart attendance register for our 
class so that the teacher need not note 
these details on a piece of paper and 
then update them onto computers. 
Our application will be smart enough 
to capture attendance and update the 
records on the database, which will be 
persistent till we wish to clear it.
In an earlier tutorial on App 
Inventor, we had explored how to  
create a Web database using an open 
source cloud enabled Firebase database. 
In this tutorial, we will use all the 
expertise we’ve acquired to deliver a 
fully working application. 
For those who’ve missed the last 
Smart Attendance Register 
in App Inventor 2
can manage the database.
6. No coding is required for fetching 
and storing data.
Creating a project in the 
Firebase database
1. To use Firebase, you must have a 
working Google account. The same 
will be needed to run App Inventor.
2. Type https://console.firebase.google.
com/ in the address bar of the 
browser you are using and hit Enter.
3. If asked for login credentials, give 
your Google account credentials 
and proceed.
4. Follow the on-screen instructions 
which are generally about accepting 
the terms of usage, etc.
5. Once everything is done, you will 

Developers
How To
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 45
Figure 1: Firebase dashboard
Figure 2: Create a new project 
Figure 3: Demo project in the Firebase dashboard
Figure 4: Reading and writing rules with authentication
Figure 5: Rules with read and write permissions
see the screen shown in Figure 1.
6. Click on ‘Create New Project’.
7. Give the name of the project and 
specify the country/region, as 
shown in Figure 2.
8. Once your project is created, you 
will see the dashboard of your 
application. It will be similar to 
that displayed in Figure 3.
9. Now select Database from the 
left-hand palette and then ‘Rules’ 
from the next page, which will 
display something like what’s 
shown in Figure 4.
10. This time, we want to give all 
users access of the database; 
hence, we need to change the 
rules. You can manually do this 
by typing values as shown in 
Figure 5. Once done, click on 
the Publish button.
So you have now successfully 
created an empty space for your 
project in the Firebase database, and 
given read and write permissions to all 
the users who have the URL.
If you are new to this Android 
journey, do go through a few of the 
articles in this series, targeted at 
beginners, to familiarise yourself 
with App Inventor.  
GUI requirements
For every application, we have a 
graphical user interface or GUI, 
which helps the user to interact with 
the on-screen components. How each 
component responds to user actions is 
defined in the block editor section. In 
this application, we will have multiple 
screens and will define the look and feel 
for each of them.
There are two GUI screens and 
their names are:
1. Screen1
2. StudentAddScreen
GUI requirements for Screen1
1. Label: Labels are the static text 
components which are used to 
display some headings or markings 
on the screen. 
2. Button: A button will let you 
trigger the event and is a very 
essential component.

Developers How To
46 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
3. Text Box: This is the input field 
where the user can type. The typed 
value will be used later in the 
application through the block editor.
4. Horizontal arrangement: These 
are special components which keep 
all child components within them 
aligned horizontally. 
5. Notifier: This is used to display some 
instructions or give controls over 
your existing components. You will 
discover more about its functionality 
as we implement it in our app.
6. Firebase DB: As you already know, 
this is the cloud based database 
utility from Google. We will use it to 
store the user’s data over the cloud.
7. Tiny DB: This is the database 
component for a local database on 
your device. Generally, this is where 
application related records are saved 
in the phone.
8. Barcode scanner: This is an 
advanced component to read and 
interpret barcode/QR code. It will 
use the existing barcode application 
or camera from your device.
9. Clock: The clock component will 
help in all time instance related 
actions.
Table 1 gives the components that 
we will need for this application, which 
will be dragged onto the designer from 
the left-hand side palette. 
1. Drag and drop the components 
mentioned in Table 1 to the viewer.
Table 1
Component’s name  
   Purpose 
         
 Location
1 
Label
To display a label
Palette-->User interface-->Label
2 
Button
To trigger events
Palette-->User interface-->Button
3 
Text box
To take user input
Palette-->User interface-->Text Box
4 
Horizontal arrangement
To arrange the child components
Palette-->Layout-->Horizontal arrangement
5        Notifier
To display on-screen information
Palette-->User interface-->Notifier
6 
Firebase DB
To store data persistently
Palette-->experimental-->Firebase DB
7 
TinyDB
To store data locally to phone
Palette-->Storage-->TinyDB
8 
Barcode scanner
To read barcode/QR code
Palette-->Sensors-->Barcode scanner
9 
Clock
To get time instances
Palette-->Sensors-->Clock
2. Visible components can be seen by 
you while the non-visible components 
will be located beneath the viewer 
under the tag ‘Non-visible’.
3. Labels, along with their respective 
text boxes, need to be put within the 
‘Horizontal arrangement’ so as to 
keep them aligned horizontally.
4. If you have dragged and placed 
everything, the layout will 
look something like what’s 
shown in Figure 6.
5. Make the necessary property 
changes like we did when changing 
the text property for the label and 
button components.
6. Renaming the components helps to 
identify them in the block editor.
7. Your graphical user interface is 
now ready. Figure 6 shows how 
the application will look after 
the installation. Non-visible 
components will not be visible.
8. Shown in Figure 7 is the hierarchy 
of the components that we have 
dragged to the designer.
GUI requirements for 
StudentAddScreen
In a similar fashion, we will list 
down the components required on 
the second screen (Table 2). The 
Figure 6: Designer screen
Figure 7: Components view
Label1
Button2
Components
Button1
FirebaseDB1
BarcodeScanner1
Notifier1
Rename
Screen1
Delete
TinyDB1
Clock1

Developers
How To
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 47
purpose of the second screen is to 
add the students’ names so that their 
attendance can be verified.
1. Drag and drop the components 
mentioned in Table 2 to the viewer.
2. If you have dragged and placed 
everything, the layout will 
look something like what’s 
shown in Figure 8.
We need to configure the Firebase 
component to connect to the demo 
project we created using the steps 
mentioned above. For that, just 
assign the URL of your project to the 
Firebase URL property of the Firebase 
component in the designer.
Now we will head towards the 
block editor to define the various types 
of behaviour; so let’s discuss the actual 
functionality that we expect from our 
application.
1. From the very first screen, the user 
should be able to scan the barcode.
2. The barcode will consist of the 
student’s name and roll number, 
separated by a comma.
3. If the student’s name from the 
barcode doesn’t match with the 
database, the user needs to add that 
particular student by going to the 
second screen.
4. Once the barcode is scanned, 
the result will be stored into the 
Firebase DB with the date on which 
this task was performed.
5. The project bucket will be named 
after the month, so that each month, 
a new folder will be created and 
attendance records will be separated 
for each date.
So let’s move on and add these 
types of behaviour using the block 
Table 2
Component’s name
Purpose
Location
1
Label                     
To display a label
Palette-->User interface-->Label
2
Button 
                           
To trigger events                    
Palette-->User interface-->Button
3
Text box
To take user input
Palette-->User interface-->Text
4
Horizontal arrangement
To arrange the child components
Palette-->Layout-->Horizontal arrangement
5
Notifier 
To display on screen information
Palette-->User interface-->Notifier
6
TinyDB 
To store data locally to phone
Palette-->Storage-->TinyDB
Figure 8: Designer screen for the second screen
Figure 9: URL of the project
Figure 10: Set the URL to the Firebase component
editor. I hope you remember how to 
switch from the designer to the block 
editor. There is a button available right 
above the Properties pane to do this.
Block editor blocks
I have already prepared the blocks for 
you. All you need to do is drag the 
relevant blocks from the left side palette 
and drop them on the viewer. Arrange 
the blocks the same way you see them 
in the image. I will explain what each 
block does and how it is called.
A description of the block 
 
All the lines in the block are easy to 
understand.
 
As soon as the Add button is clicked, 
it will check whether the text box 
is empty. If it is, the user will be 
prompted to provide some value.
 
If the value of the text box is not 
empty, then the name will be added 
to the student list and the same 
list will be saved into the phone 
database so that the next time the 
application is opened, the list will 
be the same.
Application code
 
It was not possible to snap each 
and every block of the logic so I 



Developers How To
50 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
By: Meghraj Singh Beniwal
The author has a B. Tech in electronics and communication. He is a freelance writer 
and an Android App developer, and is currently working as an automation engineer 
in Virginia in the US. He can be contacted at meghrajsingh01@rediffmail.com or 
meghrajwithandroid@gmail.com.
am providing the complete code 
as barcode. Scan QRCode 1 given 
below to obtain the ‘.aia’ file, 
which you can upload to your 
projects in the App Inventor 2 and 
view the complete code.
 
If you want to see how 
the application looks after 
installation, scan QRCode 2 to 
get the application .apk.
Now you are done with the block 
editor too. Next, let’s download and 
install the app on your phone to check 
how it is working. Figure 12 gives the 
database view.
Packaging and testing
To test the app, you need to get it 
on your phone. First, you have to 
download the application to your 
computer and then move it to your 
phone via Bluetooth or USB cable. 
I’ll tell you how to download it.
1. On the top row, click on the 
‘Build’ button. It will show you 
the option to download the apk to 
your computer.
2. The progress of the downloading 
can be seen and once that’s 
successful, the application will 
be placed in the Download folder 
of your directory or the preferred 
location you have set for it.
3. Now you need to get this apk file 
to your mobile phone either via 
Bluetooth or USB cable. 
Once you have placed the apk file 
on your SD card, you need to install 
it. Follow the on-screen instructions 
to install it. You might get some 
notification or warning saying, ‘Install 
from untrusted source’. Allow this 
from the settings and after successful 
installation you will see the icon of 
your application in the menu of your 
mobile. What you see is the default 
icon, which can be changed and I will 
tell you how to do this as we move 
ahead in this course.
I hope your application is working 
exactly as per your requirements. 
Now, depending upon your usage 
requirements, you can customise 
various things like the image, sound 
and behaviour, too.
Debugging the application
We have just created the prototype 
of the application with very basic 
functionality, but what else might the 
user be interested in? Now consider 
various use cases that you might be 
required to address so as not to annoy 
the user. Your app should be able to 
handle the following use cases:
1. Wouldn’t it be good to add an 
option to delete a student’s name 
from the list? 
2. How about pulling the attendance 
records within the application and 
generating a dashboard?
3. Can we make student profiles more 
attractive by adding profile photos 
and other related details?
These are some of the scenarios 
that might occur and users will be 
pretty happy if your app handles such 
situations. Think about all the ways your 
app can  integrate features to address 
these scenarios. Do ask me if you fail to 
address any of the above cases.
You have successfully built another 
useful Android app for yourself. 
Happy inventing!
A note to readers: Dear readers, 
I would like to know more about your 
interests and ideas on making Android 
applications. If you have any specific 
ideas that you want me to write about, 
do send me an email. I will surely try 
to help you convert your idea into a 
working application. 
Figure 11: Block editor Image 1
Figure 12:  Database view
QRCode 1:  Project source code file (.aia)
QRCode 2: Application install file (.apk)

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 51
Developers
How To
Web robots, also known as Web crawlers and Web spiders, traverse the Internet 
to extract various types of information. Web robots can be used for legitimate as 
well as malicious purposes. Read more about them and make a simple robot of 
your own by following the directions given in this article.
W
hen we come across the term ‘robot’, most of us 
think about the hardware robots that are replacing 
humans in doing various tasks at an alarming 
rate. Some of us may even have this vision of robots 
playing badminton, serving food, etc. According to software 
entrepreneur and futurist, Martin Ford, it is estimated that 
around 75 per cent of the work carried out by humans 
nowadays will be taken over by robots or machines by the end 
of this century. I am sure many of us have probably seen all 
that robots can do in Terminator and other such Hollywood 
movies. So if robots can carry out all such physical activities, 
then can a robot click on a Web button, Web check box or 
enter different input values in an input box? Certainly, it 
can perform all such tasks as well, and we call such robots 
Internet bots or Web robots.
A Web robot is simply a software application (or a set of 
programs) that traverses any Web application and performs 
various automated tasks. Though these robots can perform 
various tasks over a Web application, they are widely used 
to perform repetitive tasks, which they do much faster than 
if performed manually. Web robots, also referred to as Web 
spiders or Web crawlers, are nothing but scripts which 
retrieve information from different Web servers, analyse 
them and then file them at a speed that is many times faster 
than the rate humans would perform the same task. We 
should not be surprised to learn that more than half (52 per 
cent, according to Imperva) of all the Web traffic is actually 
enabled by Web robots, as most visitors to websites are not 
humans but Web bots. They are referred to as the worker bees 
of the Internet. Some of the Web bots help in refreshing your 
Facebook feeds continuously whereas some, like Googlebots, 
help us in figuring out how to rank different Google search 
results. Web bots make use of scripts to interact with different 
Web applications. Hence, we can develop Web robots using 
different open source scripting or programming languages 
like Perl, Python, C, PHP, etc. 
All of these languages allow Web bot developers to write 
scripts that can actually perform different procedural tasks such 
as Web scanning, Web indexing, etc. Web bots can be made to 
perform many other different types of tasks with the help of 
these scripts and, hence, they are categorised based on the kind 
of actions performed by them on any Web application. There 
are malicious Web robots as well, which are used by hackers 
to perform diverse tasks on the Internet by installing some 
Web Robots:  
The Worker Bees of the Internet

52 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers How To
malicious files. Web robots make use of instant messaging, 
Internet Relay Chat or other Web interfaces to communicate 
with other users of Internet-based services. Internet Relay Chats 
also provide help services for any new user by lurking in the 
background of any conversation channel and commenting on 
some of the phrases uttered by users (based on pattern matching).
Different types of Web bots and how they are used
Web bots can be used to perform both legitimate and 
malicious tasks. Depending on the application for which a 
Web bot is used, it is classified into the following categories.
Legitimate Web robots: These perform legitimate actions 
on a Web application. They save a lot of time and effort 
for users. If the same task was performed manually, then it 
would have taken much longer time. These types of Web bots 
actually serve a purpose and act as time savers for different 
applications. They are broadly categorised as follows:
1. Spider Web robots: These are used by different 
search engines to explore different Web pages for 
organisation, content and linking. They have got certain 
criteria for indexing, based on which they determine 
the ranking of different Web pages within the search 
results. Such types of Web robots are used by Google 
and are called Googlebots.
2. Trading Web robots: These traverse or ‘spider’ different 
online auction sites in order to locate the best deals on any 
specific product or service. In such scenarios, a trading 
Web robot is used for commercial gain. These robots 
are also helpful in doing a complete analysis of different 
online commercial applications and provide users the best 
deals. Trivago, an online hotel booking Web application, 
uses such bots to display the best hotel deals. 
3. Media Web robots: These are used to provide the latest 
news updates, weather conditions, sports news, currency 
exchange rates, etc. They are also used as censors 
in different applications that run instant messenger 
programs and chat rooms. Such Web bots are widely 
used by different online messenger applications like 
eBuddy, IMO, etc.
Malicious Web robots: Malicious Web robots are a 
collection of such bots, used in different ways to perform 
some malicious act or network security breaches. Such bots 
are widely used by hackers all across the globe.
1. Spam Web robots: These collect different data from 
various forms that are filled online. They are also used 
for spreading advertisements with the help of pop-
ups. Different advertisement firms also use them for 
collecting email addresses of people to spam them 
with advertisements.
2. Hacker Web robots: Hackers use these to crawl around 
the Internet and thus find the vulnerabilities in different 
websites and online applications so that they can be 
exploited for malicious purposes.
3. Botnets:  These are actually the networks that different 
hackers set up online by using zombie computers in order to 
perform various malicious acts such as the denial of service 
attacks. Zombie computers are those that have been taken 
over by a hacker without the owner’s knowledge.
4. Download Web robots: These are used to forcibly 
download any specific Web page that the hacker wants the 
surfer to see instead of the one that the surfer requested. 
Figure 1: Flow diagram of a traditional Web crawler (Source: googleimages.com)
Figure 3: Web scraping done by malicious Web robots (Source: googleimages.com)  
Init
Web
Repo
Download
resource
Extract
URLs
HT’06
Seed URLs
Traditional Web Crawler
Visited URLs
Forntier
Figure 2: Architecture of a Web crawler (Source: googleimages.com)
one document
newly-crawled
document (s)
entire index
Web 
Index
Web 
traverse
links
insert
trash
prices, promotions, offers
search bots
targeted industries
CAPTCHAs
tools
tools

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 53
Developers
How To
We all have experienced a scenario in which we are left 
with no other option but to click on a link so that the 
particular Web page gets downloaded. 
What should be considered before 
creating a Web robot
Before developing a Web robot, we need to carefully 
analyse the task we want it to perform.  Here are a few 
general considerations that need to the looked at before 
developing a Web robot. 
1. Analysis of the task or set of tasks that we want Web 
robots to perform for us. It’s good to use Web bots for 
repetitive tasks or anything that takes a lot of time when 
done manually, compared to when it’s done automatically.
2. The sequence of steps that the Web robot needs to take so 
that the task is completed in the minimum amount of time 
needs to be well planned. It helps to obtain an efficient, 
error-free and effective program.
3. Check if the Web bot requires manual intervention or if 
the task can be fully automated.
4. Properly analyse the scripting or programming language 
that best suits the development of the Web bot, which 
can perform the specific task in the least time and with 
minimum cost and effort.
5. Check if the Web bot’s requests, edits or any other actions 
need to be logged. 
6. Check if the Web bot needs to run inside a Web browser 
or just be a standalone program.
7. If the Web bot runs on a remote server, check if it is 
possible for other editors to operate it.
Developing a small Web bot, free of cost
After we have made our considerations, we are good to go ahead 
with the development of the Web bot. Let’s develop a small one, 
using Python scripting in order to scan a specific Web page. 
You need to have the following installed on your system:
 
Python 3.x or above
 
Any text-editing application such as Notepad, etc
Now follow these steps:
 
Open any plain text editing application, like Notepad, 
which is included with Microsoft Windows, where a Python 
script for the Web robot application can be written.
 
Initiate the Python script by including the lines of code 
given below; the reason for including specific lines in the 
code has also been mentioned as ‘comments’.
# importing required library files
 from html.parser import HTMLParser  
 from urllib.request import urlopen  
 from urllib import parse
# Creating a class called LinkParser that inherits some 
methods from HTMLParser
 class LinkParser(HTMLParser):
# adding some more functionality to HTMLParser
 def handle_starttag(self, tag, attrs):
# checking for the beginning of a link as they are normally 
present in <a> tag
       if tag == ‘a’:
            for (key, value) in attrs:
                if key == ‘href’:
# grabbing new URL and adding the base URL to it so that it 
can be added to collection of links
                    newUrl = parse.urljoin(self.baseUrl, 
value)
                    self.links = self.links + [newUrl]
# Function to get links that spider() function will call
    def getLinks(self, url):
        self.links = []
        self.baseUrl = url
# Using the urlopen function from the standard Python 3 
library
        response = urlopen(url)
        if response.getheader(‘Content-Type’)==’text/html’:
            htmlBytes = response.read()
            htmlString = htmlBytes.decode(“utf-8”)
            self.feed(htmlString)
            return htmlString, self.links
        else:
            return “”,[]
# spider() function which takes in an URL, a word to find, and 
no. of pages to search through 
        def spider(url, word, maxPages):  
             pagesToVisit = [url]
             numberVisited = 0
             foundWord = False
 # Creating a LinkParser to get all links on the page.
    while numberVisited < maxPages and pagesToVisit != [] and 
not foundWord:
        numberVisited = numberVisited +1
 # starting from the first page of the collection:
        url = pagesToVisit[0]
        pagesToVisit = pagesToVisit[1:]
        try:
            print(numberVisited, “Visiting:”, url)
            parser = LinkParser()
            data, links = parser.getLinks(url)
            if data.find(word)>-1:
                foundWord = True
                pagesToVisit = pagesToVisit + links
                print(“ **Success!**”)
        except:
            print(“ **Failed!**”)
    if foundWord:
        print(“The word”, word, “was found at”, url)
    else:
        print(“Word never found”)

54 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers How To
The many applications of Web robots
1. Chatterbots allow people to ask questions and formulate a 
proper response. 
2. Web bots help in handling many tasks such as reporting 
weather, sports scores, zip-code information, etc.
3. They are used to develop different messengers like 
SmarterChild on AOL Instant Messenger, etc.
4. They are widely used for Web page scanning and indexing.
5. They can report real-time vehicle locations for the 
trucking industry.
6. They can also mimic the tasks performed by a 
psychiatrist, if loaded with many responses.
7. They report air quality.
8. Gaming bots are used for many gaming 
applications as well.
9. Auction-site Web robots make the process of 
auctioning easier.
Advantages and disadvantages of bots
Advantages:
1. Help in performing different actions on Web 
applications at a much faster rate than when the same 
task is done manually.
2. Help in retrieving the data required from large sets in the 
least possible time.
3. Can be quite helpful for different site owners to create 
additional traffic if the site is being included for some index.
4. Web robots are always more reliable and efficient in the 
actions that they perform as compared to when the same 
task is done manually. 
Disadvantages:
1.  There are temporary denials of service, at times, to other 
visitors reaching a site, which is caused by heavy bursts of 
page downloading. Visitors may not be able to access site 
pages at normal speed, or in some extreme cases, not at 
all, since a robot is busy downloading the pages in a heavy 
burst and consuming most of the Web server resources.
2. The use of Web robots also results in wastage of 
bandwidth, as some of the contents that these bots 
download may not be useful to a person at a later time; 
hence, the chances of downloading content and then 
throwing it away is higher. This can ultimately add to 
bandwidth loss.
3. Different malicious web bots are used by hackers to check 
for vulnerabilities in the Web system, and they exploit the 
same for different malicious activities.
4. Malicious Web robots are also used to spam emails of 
users in order to retrieve user information.
Preventing the problems associated with Web bots
We can prevent some of the issues that arise from using Web 
bots by taking the following precautionary measures.
1. Check if we are actually being visited by Web robots often 
enough before taking any other measures: We can check if 
robots are visiting our pages by examining our Web server 
log files. We can look in the user agent field for unusual 
names, the frequency of their visits and also for the type 
of files that are being retrieved. 
2. Use the meta tags, robots.txt file and other ways to 
suggest to robots how your site should be indexed or not 
indexed: Try suggesting to the robots as to how you would 
like your site to be indexed or downloaded. 
3. Convert all time-consuming scripts to the static pages if 
possible: It takes longer for any Web server to execute 
the scripts that generate Web pages than to serve different 
static HTML pages. Hence, it is less likely that your 
server would get a denial-of-service when Web robots 
download static files in heavy bursts. 
4. Check if a possible Web robot requested the script before 
performing any time-consuming functions: If you have 
to use scripts on your website, check if any possible 
unfriendly Web bot called the script before going into 
time-consuming parts of the scripts.
Figure 4: Impact of Web bots on website security (Source: googleimages.com)  
Figure 5: Breakdown of Web traffic on the basis of visitor type during 2012-2015 
(Source: googleimages.com)  

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 55
Developers
How To
addresses is causing problems to your Web server, then 
try contacting the owners of such Internet connections. 
If all this fails, you may consider excluding such 
addresses from your Web server.
6. Use different server-specific components: If you still 
have severe problems in avoiding unfriendly Web 
robots, write server-specific components. This is where 
you write an extension to your Web server which 
would dynamically verify different properties of calling 
programs to check for possible Web bots. 
Figure 6: Web robot traffic report 2016 (Source: googleimages.com)  
Figure 7: Googlebot impostors perform different types of activities 
(Source: googleimages.com)  
A few facts
•   8.5 per cent of the total content of Wikipedia has 
been written by Web robots.
•  The most active helper-bot online is ‘feed fetcher’, 
which helps refresh an individual’s Facebook feed 
on the site’s mobile application. Facebook’s feed 
fetcher alone accounts for around 4.4 per cent of 
all website traffic.
•   Web bot operators interpret the bot’s results 
and then make what is called the ALTA report, 
which is available on their website for paid sub-
scribers. ALTA stands for Asymmetric Language 
Trend Analysis.           
By: Vivek Ratan 
The author has completed his B. Tech in electronics and 
instrumentation engineering. He is currently working as an 
automation test engineer at Infosys, Pune. He can be reached 
at ratanvivek14@gmail.com.
[1] http://www.wikipedia.org/
[2]  https://www.techwalla.com/
[3]  http://www.chami.com/
References
5. If any particular IP address is continuously causing 
problems in spite of taking the above steps, then 
consider limiting access to the server: If we have 
positive proof that any particular IP address or class of 
MONTH
THEME
March 2017
Open Source Firewall, Network security and Monitoring
April 2017
Databases management and Optimisation
May 2017
Open Source Programming (Languages and tools)
June 2017
Open Source and IoT
July 2017
Mobile App Development and Optimisation
August 2017
Docker and Containers
September 2017
Web and desktop app Development
October 2017
Artificial Intelligence, Deep learning and Machine Learning
November 2017
Open Source on Windows
December 2017
BigData, Hadoop, PaaS, SaaS, Iaas and Cloud
January 2018
Data Security, Storage and Backup
February 2018
Best in the world of Open Source (Tools and Services)
OSFY Magazine Attractions During 2017-18

56 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
This article discusses the subtle and minute differences 
between C and C++.
A
n article titled ‘Major Differences Between C 
and C++’ would have been quite ridiculous 
because everybody knows that C and C++ are 
two independent programming languages, both backed by 
communities that are quite fanatical in their support for 
their respective preference. There will probably be a small 
group of novice programmers who still post questions in 
StackOverflow with the tag ‘C/ C++’ and will get panned 
universally by professional programmers belonging to both 
the camps. In this article, I plan to point out a few subtle 
differences between C and C++, altogether avoiding the major 
differences like C being an imperative programming language 
whereas C++ is an object-oriented programming language. 
This article tries to point out that even though text books often 
define C++ as a superset of C, even that part of C++ that is a 
subset of C is slightly different from traditional C.
I will try to prove the existence of such minute differences 
between C and C++ that often escape the notice of even 
seasoned programmers with a small example. This is a 
question I have asked recently in a programming competition: 
“Write an error-free C program that will give an error when 
compiled as a C++ program.” Since the classical definition of 
C++ says that it is a superset of C, every C program should 
also compile as a C++ program without any errors. This 
might be the case theoretically though not so practically. The 
following program Example 1 fails when compiled with the 
g++ compiler as a C++ program, but when compiled as a C 
program with the gcc compiler, it compiles successfully. 
#include<stdio.h>
int main()
{
    int class;
}
Example 1
What is the reason for the error when compiled as a C++ 
program? That’s very simple—the keyword class in C++ can be 
used as a variable name in C. But to crown it all, the first prize 
went to a programming whizz-kid who knew that anonymous 
structures are okay in C but will lead to an error in C++. The 
program Example 2 with an anonymous structure will compile 
as a C program with a warning, whereas in C++ the program will 
result in an error. All the programs in this article are compiled as 
C programs with gcc and as C++ programs with g++. 
#include<stdio.h>
struct
{
 
int a;
};
Developers Insight
The Minor Differences Between 
C and C++

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 57
Developers
Insight
   
int main()
{
}
Example 2
There are many such examples where C and C++ show 
their differences in the least expected places. For example, 
the program Example 3 will display different outputs on the 
screen when compiled as C and C++ programs.    
#include<stdio.h>
int main()
{
  
int i,j;
  
i=sizeof(‘a’);
  
i=--i/3*32+65;
  
for(j=i;j<i+26;j++)
  
{
       printf(“%c  “,j);
   
}
   
printf(“\n”);
}
Example 3
The program when compiled as a C program will output the 
lower case letters, and the same program will output upper case 
letters when compiled as a C++ program. This is due to the 
fact that the size of a character literal is 4 bytes in C and 1 byte 
in C++, because C treats a character literal as integer type and 
C++ treats a character literal as character type. Figure 1 shows 
the output of the program execution as C and as C++.
int main()
{
    fun();
}
Example 4
In C, an empty function prototype tells the compiler 
that the function can have any number of arguments. But in 
C++, it means the function cannot take any arguments. For 
example, the function declaration int fun( );  in C can receive 
zero or more arguments, whereas in C++, this function has 
zero arguments. The program Example 5 shows an error when 
compiled as a C++ program. 
#include<stdio.h>
int fun();
int main()
{
 
fun(123);
}
int fun(int n)
{
 
printf(“\n Number is %d\n”,n);
}
Example 5
The unary increment and decrement operators in C++ 
return an lvalue. But in C, they return an rvalue. So (++i)++; 
is valid in C++ but it will lead to an error in C. The program 
Example 6 will show the error message ‘lvalue required’ in C 
whereas in C++, the program will successfully compile and 
show the output as ‘i = 3’.
#include<stdio.h>
int main()
{
 
int i=1;
 
(++i)++;
 
printf("\ni = %d\n",i);
}
Example 6
In C, we cannot get the address of a register variable. But 
in C++, it is possible to get the address of a register variable. 
The program Example 7 is not an error-free C program but 
when compiled as C++, the program runs without any errors. 
#include<stdio.h>
int main()
Figure 1: C and C++ outputs
In C, by default, the return type of a function is an integer. 
But this default to the int rule is not valid in C++. You have to 
mention the return type as integer explicitly. Due to this, the 
program Example 4 will show an error when compiled as a 
C++ program. 
#include<stdio.h>
fun()
{
}

58 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Insight
{
 
register int x=123;
 
printf(“\n Address of x = %u\n”,&x);  
}
Example 7
In C and C++, static variable initialisation is different. In 
C, static variables can only be initialised with constant values 
whereas in C++, this is not necessary. The program Example 8 
will not compile as a C program but it is valid when compiled 
with g++ as a C++ program. 
#include<stdio.h>
int main()
{
 
int x=123;
 
static int y=x;
 
printf(“\ny = %d\n”,y);
}
Example 8
The way case labels are treated in C and C++ is different. 
C++ allows constant integer variables as case labels, whereas 
C will give you an error. The program Example 9 will give 
an error as a C program but as a C++ program, it compiles 
without any errors. 
#include<stdio.h>
int main()
{
    int i=1;
    const int j=1;
    switch(i)
    {
        case j:
            printf(“\nWorks for C++\n”);
            break;
        case 2:
            printf(“\nError for C\n”);
            break;
        default:
            printf(“\nCheck by compiling\n”);
    }
}
Example 9
In C, uninitialised constant variables are just fine but 
these will lead to an error in the case of C++. For example, a 
program with the line of code const int a; will compile fine as 
a C program, whereas it will show a compile time error when 
compiled as C++ and display the error message uninitialized 
const. Another difference arises when the keyword typedef 
is used in C and C++. C++ treats the names of struct, union, 
enum, etc, as implicit typedef names. This is not the case with 
C, so program Example 10 is a valid C program, whereas if 
compiled as a C++ program, you will get the error message 
using typedef-name ‘type’ after ‘struct’.
#include<stdio.h>
typedef int type;
struct type
{
    type a;                     
};
struct type sv;
int main()
{
}
Example 10
In C, a pointer of type void is automatically cast into 
the target pointer type when assigned to a pointer of any 
other type. So, there is no need for explicit type-casting in 
C. Whereas in C++, explicit type-casting is required when a 
void pointer is assigned to a pointer of another type. So, the 
line int *ptr = malloc(sizeof(int)); is fine in C, whereas in 
C++, you will get the compile time error message: invalid 
conversion from ‘void*’ to ‘int*’. You can download this 
and all the other programs discussed in this article from 
opensourceforu.com/article_source_code/june17cPlus.zip. 
To save some space, I haven’t used any code other than the 
feature being discussed in many of the programs. But you 
can add any valid C or C++ code in all these programs.
K & R style function definitions are still valid in C. But this 
will lead to an error in case of C++. So, the program Example 
11 is a valid C program but it is not a valid C++ program. 
#include<stdio.h>
void fun(a, b)
int a; 
int b;
{
 
printf(“\na = %d \nb = %d\n”,a,b); 
}
int main()
{
    fun(11,22);
}
Example 11


60 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Insight
C
urrently, technology has developed to the extent 
that various devices and gadgets are able to interact 
with each other, without human interference. This 
communication technology is today known as the Internet of 
Things (IoT). IoT based communication is used in a number of 
applications, including defence equipment, smart cities, smart 
offices, highway patrolling, smart toll collection, business 
communications, satellite televisions, and traffic systems or 
interconnected Web cams for security. IoT is also known and 
associated with other terms, including ubiquitous computing 
(UbiComp), pervasive computing or ambient computing, using 
which a number of devices and objects are virtually connected 
for remote monitoring and decision making.
The security aspects of the Internet of Things (IoT)
As so many devices and so much equipment are 
interconnected via a virtual environment, there are serious 
issues related to security, privacy and the overall performance 
of IoT networks. These networks are becoming increasingly 
vulnerable to attacks from assorted sources.
Different types of attacks are used to control and damage 
the IoT environment at different layers. The attackers can 
damage and control the IoT network by sending malicious 
packets and signals, and infrastructure can be virtually 
destroyed. Such attacks are the most worrisome, as they affect 
the entire network. 
Denial of Service (DoS) attacks: In a DoS attack, 
network availability is jammed by the attacker node 
or malicious packets, by capturing the bandwidth or 
communication channel. Here, authentic and legitimate 
users are not able to access the network services. This is a 
notorious attack that works on the network layer of an IoT 
based scenario, and gets more dangerous when it becomes 
a Distributed Denial of Service (DDoS) attack, whereby the 
attacker or malicious node attacks a network from multiple 
and different locations.
The Sybil attack: This affects the network layer of a 
vehicular network a lot. In this attack, the identity of the nodes 
is manipulated. The malicious node attempts to fabricate its 
identity by pretending to be a registered or original source 
node. In a Sybil attack, the attacker node creates assorted 
vehicles or nodes of the same identity by replication, and forces 
Programming IPv6 Protocols 
Using Contiki and Cooja
Contiki is a widely used IoT enabled operating system that is free and open source. Cooja 
is the Contiki network simulator and is also used to program sensor devices. Read on to 
learn how IPv6 protocols can be programmed with Contiki and Cooja.

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 61
Developers
Insight
other nodes to leave or move off the network faster. These 
attacks can be detected with resource testing, based on the 
assumption that vehicles have limited resources. Sybil attacks 
can be addressed using public key cryptography, where public 
keys are used to authenticate vehicles.
A node imitation attack: In this type of attack, messages 
can be transmitted by a malicious node that has imitated 
another authentic one, by mimicking the latter’s identity. 
In this way, the imitating attacker can send out malicious 
messages to any node by changing its own identity. The IoT 
node that has disguised its identity in this attack can capture 
authentic and secured packets, which can be disastrous for the 
entire network.
An application level attack: This type of attack in the 
IoT environment tampers with the messages and retransmits 
them to an untrusted non-secure destination. For example, in 
Internet of Vehicles (IoV) based implementations, the high-
traffic lane could get maliciously broadcast as a ‘congestion-
free lane’, leading to chaos during rush hour. 
The importance of IPv6 in IoT
Security and integrity are the main issues in an IoT based 
network environment where interception-free secured 
communication is required. To enforce and integrate higher 
degrees of security, there is a need to implement IPv6 for 
IoT scenarios, with dynamic hybrid cryptography in key-
generation and authentication. The IPv6 based approach 
can be enabled with fully secured algorithms, which 
are not vulnerable to interception. With the increasing 
implementation of IoT in diverse domains, it becomes 
necessary to work out the security aspects of IoT, by ensuring 
the secured routing of packets to prevent intrusions and 
ensure all transmissions can be fully secured. 
RPL (Routing Protocol for Low-power and 
Lossy networks)
RPL is the IPv6 based protocol for IoT. It is primarily 
integrated for IPv6 over low-power wireless personal area 
networks (6LowPAN). It works with the dynamic creation of 
Destination-Oriented Directed Acyclic Graph (DODAG), and 
has unidirectional as well as bidirectional communication. 
It has multiple instances with localised behaviour for higher 
optimisation. RPL enables each node in the framework to 
choose whether packets are to be sent upwards to their root or 
downwards to their child nodes.
Programming RPL with IPv6 in Cooja
Contiki is one of the widely used IoT enabled operating 
systems under free and open source distribution and is 
available at http://www.contiki-os.org. Contiki is equipped 
with the Cooja simulator, which is used for simulation 
as well as the programming of sensor devices. It offers 
enormous options to program the IoT nodes for real 
life implementations. The Cooja simulator enables the 
programmer to import and program enormous types of 
IoT motes, and to get the results from different algorithms. 
To program, control and monitor the remote IoT devices, 
the backend C programs and related header files can be 
customised and recompiled to get the desired results. Contiki 
works on IPv4 as well as IPv6 networking with the integration 
of lightweight protocols, so that low power chips and radio 
frequency chips can be connected without performance issues.
Figure 1 depicts the simulation of multiple IoT motes 
in the Cooja simulator with the integration of dynamic 
cryptography. The simulation results can be analysed from the 
Mote Output in which there is an option to fetch the execution 
logs. All the data communication and signals are logged in 
Mote Output which can be further investigated using different 
types of graphs.
Once the simulation is complete, the network log files are 
analysed. This includes the source and destination motes, the 
time and the overall activities performed during simulation. 
In the Mote Output window, the log data can be copied and 
further analysed using data mining and machine learning tools 
for predictive analytics.
Figure 2 represents the Collect View in the Cooja 
simulator. It analyses the individual IoT mote. The IoT mote 
analytics can be viewed from the Tools menu of Cooja. 
From Collect View, any of the IoT motes can be analysed 
on multiple parameters including latency, temperature, time 
and other important parameters, which contributes to better 
performance evaluation.
Figure 1: Fetching the data and messages for plotting graphs
Figure 2: Collect View activation for detailed logs

62 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Insight
the developer in examining the effect of customised code 
on real-time sensors.
Plotting results in the form of graphs
As depicted in Figure 7, there are a vast number of 
parameters, including LPM, CPU, Radio Listen and Radio 
Transmit, which need to be looked at during the IoT 
simulation. The results in the above cited graph are consistent 
and low-power mode is in the integrity mode. In addition, the 
Radio Listen parameter is also consistent.
Figure 6: Serial Console to validate the results and key exchange
Figure 7: Average power consumption in the motes
Figure 3: Network graph option in Cooja
Figure 4: View of the network graph for dynamic topology
Figure 5: Node information with related parameters
Figure 3 depicts the different options by which IoT 
simulation can be analysed and predictions on various parameters 
can be made. The network graph tab in the Collect View of 
Cooja enables the researcher to view the dynamic topology and 
connections of sensor nodes, as shown in Figure 4.
Figure 5 shows the results and parameter based analysis 
of different nodes in tabular format. It enables the IoT 
programmer to inspect individual nodes as well as many or all 
of them in groups, to analyse multiple factors.
The Serial Console tab seen in Figure 6 shows the 
data transmission log, along with the results related to 
authentication. In Figure 6, the implementation of the 
attack and authentication process is depicted, which assists 
Network analysis using Foren6
Foren6 (http://cetic.github.io/foren6/) is a powerful tool with 
a free and open source library. It is used for the analysis of 
6LoWPAN networks. It is integrated with the sniffing modules, 
besides being able to plot the results in assorted formats 
including text or graphs. Foren6 makes use of integrated 
sniffers for capturing and analysing the traffic associated with 
6LoWPAN in a graphical user interface (GUI). It is powerful 
enough to record and plot the RPL information with the deep 
analytics of packets in network transmission.

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 63
Developers
Insight
By: Dr Gaurav Kumar
The author is the MD of Magma Research and Consultancy 
Pvt Ltd, Ambala. He is associated with various academic and 
research institutes, where he delivers lectures and conducts 
technical workshops on the latest technologies and tools. 
You can contact him at kumargaurav.in@gmail.com. Website: 
www.gauravkumarindia.com. 
Figure 8: Temperature evaluation in Celsius at the motes
Figure 9: Foren6 as a 6LoWPAN analyser
$ git clone https://github.com/cetic/contiki
$ cd contiki
$ git checkout sniffer
$ make TARGET=sky savetarget sniffer.upload
Scope of IoT based research simulations 
using Cooja
The Internet of Things is an emerging domain of research 
at various academic as well as corporate establishments. 
Because of the increasing number of devices currently 
connected under the IoT, there are vast areas for research 
in this domain.
The following are some of the approaches with 
which novel and effectual algorithms can be devised and 
implemented using Cooja:
 
Interoperability and cross-protocol compatibility
 
Development of energy-aware IoT scenarios
 
Power aware scheduling and routing
 
Prediction and avoidance of energy consumption attacks
 
Lifetime analytics for robust IoT environments
 
Reproducible and multi-interface implementations 
Installation of Foren6 with Contiki
To configure the dependencies, type:
$ sudo apt-get install -y qt4-qmake libqt4-dev make 
libexpat1-dev cmake libpcap0.8-dev libc6-dev tshark gcc g++
To get the source code with GIT, type:
$ git clone https://github.com/cetic/foren6.git
Use the following commands to install Foren6:
$ cd foren6
$ make
$ sudo make install
Configuration of Sniffer to activate  
real-time capturing
To access and work on USB serial devices, the Linux Group 
‘dialout’ is used. Initially, Foren6 is launched as the root user. 
If any other user account is used, then the user should be 
assigned the Linux Group ‘dialout’ to use USB.
$ sudo adduser <username> dialout
Sniffer Programming
Your favourite Magazine on Open 
Source is now on the Web, too.
OpenSourceForU.com
Follow us on Twitter@LinuxForYou

64 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Insight
T
he Internet has definitely changed the way we 
carry out our day to day activities, be it something 
as simple as communicating with a friend, or the 
more critical applications such as banking and healthcare. 
The benefits of connecting more and more devices to the 
Internet, popularly known as the Internet of Things (IoT), 
are manifold. As an example, your keychain can broadcast 
its location, helping you to find the key you lost by clicking 
on an app on your smartphone. 
However, as more and more things get connected, 
there are new requirements in network protocols, security, 
programmability, etc. 
JavaScript and IoT
JavaScript has become the de-facto client-side scripting 
language of the Web. One can call JavaScript the ‘C of 
the Web’. There are millions of Web developers with 
JavaScript skills who can migrate with relative ease to 
IoT. Moreover, with the exponential growth in IoT, there 
are specialised JavaScript frameworks that can use the 
potential of connected devices. 
JavaScript can be utilised for IoT in the following 
different ways (Figure 1):
 
One of the approaches is to run JavaScript in the host 
computer and send the signals to the client (things). 
This mode is optimal for scenarios in which the actual 
‘things’ don’t have the potential to run even the slimmest 
JavaScript codebase. 
 
Another approach is to execute the JavaScript code 
through memory optimised engines in the device 
itself. Frameworks such as JerryScript may be used to 
run the devices. 
A Peek at Four JavaScript 
Based Libraries  
for the Internet of Things
Connecting every ‘thing’  is the latest trend in the world of IT. A prime challenge 
in connecting heterogeneous things is the need for interoperable development 
tools. This article introduces readers to a few important JavaScript based libraries, 
frameworks and platforms associated with IoT development. 

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 65
Developers
Insight
 
In scenarios where single board computers can be used, 
JavaScript or Node.js code is executed in these devices 
without any issues. 
JavaScript is suitable for devices because of its ability 
to react to events and asynchronous code execution. It 
could be a great option for quick prototyping as well. 
The ability of JavaScript to provide a uniform interface 
across heterogeneous devices is also a key factor in 
choosing it for IoT. 
There are plenty of JavaScript based frameworks/libraries 
available for IoT and other related domains (Figure 2). 
This article introduces four of these tools, which are listed 
below:
 
Favor
 
JerryScript
 
IoT.js
 
Cyclon.js
Favor
Favor is a simple and powerful library for IoT, which 
hides the complex and inconsistent interfaces provided by 
heterogeneous devices, from the app developer. The single 
API provided to access these devices makes it simple for the 
developer to control various devices.
As narrated in the official documentation (https://github.
com/favor/it), if you wish to have a function like reading 
temperature from various heterogeneous devices without 
considering their hardware differences, using commands 
similar to what’s shown below, then Favor is the library 
that will assist you.
$$(‘temperature’).get(function(temp) { 
      console.log(‘The temperature is ‘, temp) 
};
The Favor documentation uses the term hardware 
agnostic, which implies that developers can write the business 
logic of the app without thinking about the actual hardware in 
which the code is going to get executed. 
Presently, Favor supports devices of Linux origin such as 
Raspberry Pi, Beaglebone, etc. However, any Linux device 
with the ability to run Node.js can be used. 
Favor is able to achieve the hardware agnostic feature 
by maintaining a configuration file. This consists of 
details describing the structure of the hardware. Favor 
queries this configuration file when communicating with 
the actual device. This functionality could be compared 
with how jQuery parses and interacts with the DOM of 
a Web page. Once the parsing is done, then jQuery is 
capable of accessing any DOM element with the simple 
$ functionality. Similarly, Favor is able to exhibit jQuery 
style functionality in accessing the devices. As narrated 
earlier, any device with a temperature sensor will interact 
with the code segment shown below: 
$$(‘temperature’).get(callback)
The advantages of using Favor are: 
 
Uniform and simple API for communicating across 
various devices/protocols. 
 
Clear demarcation between hardware and software, which 
increases the modularity of the application. It separates 
the business logic from the hardware. 
 
The ‘Write Once - Run Anywhere’ feature makes it more 
suitable for a variety of application scenarios. 
Favor can be installed easily with Node.js, using the 
following command: 
npm install favor
A simple but effective demo of a sample application 
with Favor is available at https://www.youtube.com/
watch?v=ujHa-I3ZRUM. 
Figure 1: JavaScript on devices
Figure 2: JavaScript for IoT
Figure 3: JerryScript features
JavaScript on Devices
Host – Client Approach
Embedded JavaScrips
JS on SBC
JerryScript
IoT.js
Favor
Cyclon.js
JavaScript for IoT
KinomaJS
Resin
Onoff
Pijs.IO
Optimized for Memory
Supports Resource poor devices
Active Development
ECMAScript 5.1 Standards
JerryScript Features
C99 for Maximum portability

66 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers Insight
By: Dr K.S. Kuppusamy 
The author is an assistant professor of computer science at 
Pondicherry Central University. He has 11+ years of teaching 
and research experience in academia and industry. He can be 
reached at kskuppu@gmail.com. 
[1] https://www.postscapes.com/javascript-and-the-
internet-of-things/
[2]  https://github.com/favor/it
[3]  http://iotjs.net/
[4]  https://github.com/Samsung/iotjs
[5]  https://github.com/jerryscript-project/jerryscript
[6]  https://cylonjs.com/ 
[7]  ‘JavaScript on Things’, a book by L.D. Gardner
References
If you want to explore Favor in detail, then visit the 
official Favor wiki at https://github.com/favor/it/wiki.
JerryScript
JerryScript is a lightweight engine for JavaScript. Its prime 
advantage is its ability to run in resource-constrained devices. 
JerryScript can run on devices with less than 64KB of RAM. 
It even supports devices with less than 200KB of Flash 
memory (https://github.com/jerryscript-project/jerryscript). 
The major highlights of JerryScript are listed 
below (Figure 3):
 
Optimised for microcontrollers.
 
Code is actively updated at frequent intervals.
 
 JerryScript is ECMAScript 5.1 standards compliant. 
 
Ability to precompile the JavaScript source code 
to byte code. 
 
Highly optimised for low memory consumption. 
 
JerryScript is open source and available with the Apache 
License 2.0.
 
Written in C99 for maximum portability.
JerryScript was developed from scratch by the Samsung 
Open Source Group. 
Detailed instructions regarding pre-requisites and setting 
up are provided at https://github.com/jerryscript-project/
jerryscript/blob/master/docs/01.GETTING-STARTED.md.
IoT.js
IoT.js is also targeted towards resource-poor devices; it is 
built on top of JerryScript. Its features are:
 
The IoT.js platform uses JerryScript to execute JavaScript. 
 
It uses libuv for asynchronous input and output (https://
github.com/Samsung/libuv). libuv is a multi-platform 
support library to enable asynchronous I/O.
 
Presently, IoT.js supports Linux and NuttX. The latter is a 
real-time operating system. 
 
The API provides features to handle buffers, events, 
consoles, GPIO, streams, timers, etc. 
Detailed information regarding app development using 
IoT.js is available at https://github.com/Samsung/iotjs.
Cyclon
Cyclon.js is a JavaScript framework to support robotics, 
physical computing and IoT. One of its major advantages is the 
support for various platforms. As per the official documentation 
(https://cylonjs.com/) it supports 43 different platforms. 
Getting started with Cyclon.js is straightforward. Just 
install the npm module, as follows:
npm install cyclon
A sample code snippet to toggle an LED every three 
seconds is shown below:
var Cylon = require(“cylon”);  
// Initialize the robot 
Cylon.robot({   
// Change the port to the correct port for your Arduino.   
connections: {     
arduino: { adaptor: ‘firmata’, port: ‘/dev/ttyACM0’ }
}, 
devices: {     
   led: { driver: ‘led’, pin: 13 }   
},  
work: function(my) {     
        every((3).second(), function() {       
               my.led.toggle();     
       });   
} 
}).start();
To run the code, type: 
$ npm install cylon-firmata cylon-gpio cylon-i2c 
$ node script.js
Cyclon.js can be executed from a browser with the help of 
the browserify module of npm. 
Figure 4: IoT.js
Based on JerryScript
Libuv for ASync I/O
Supports Linux & Nuttx
Supports less powerful devices
IoT.js


Totally based on biometric authentication, the electronic public distribution system 
project initiated and implemented by the state government of Andhra Pradesh has been 
developed on PostgreSQL, the open source database.
Andhra Pradesh Rolls 
Out an Electronic Public 
Distribution System
Using Open Source
I
t was in 2014 that the Andhra Pradesh government decided 
to go digital and opted for an electronic solution for its  
PDS (public distribution system). While the initial model 
was tested in a few small regions, the final release can handle 
as many as four million transactions per day during peak time 
across all the 13 districts in the state—all this powered by 
PostgreSQL, the open source database.
The Andhra Pradesh (AP) government gave the task of 
transforming its public distribution system to a team at the 
National Informatics Centre (NIC). Led by civil supplies 
commissioner and state informatics officer (SIO) of Andhra 
Pradesh, K. Rajasekhar, the NIC team preferred US-based 
Facts about AP’s iconic ePDS project 
• Delivers benefits to around 30,000 concurrent 
users in the state
• Handles over four million transactions per 
day during peak time
• 100 per cent Aadhaar-enabled system with 
biometric authentication
• More than 28,000 ePOS devices and many electronic 
weighing machines are in use
EnterpriseDB to build a progressive ePDS (electronic 
public distribution system) model, in order to improve 
the transparency, efficiency and effectiveness of the 
system. The arrival of the ePDS in the region has also 
set the stage for next-generation solutions, including 
eSCM (electronic supply chain management) and ePOS 
(electronic point of sale). All these developments have 
led to hyper-scalability, high-availability, reliability and 
high-concurrency to the entire process of delivering civil 
supplies in the state, along with low latency.
ePDS: a mission critical application
The Postgres database, which currently holds nearly 38 
million records, was deployed right at the beginning of 
the project. This open source database helped to enable 
Aadhaar-based biometric authentication in real-time, and 
offer cashless as well as cardless transactions.
“The application that we have developed with the 
support of NIC and EnterpriseDB for distributing rations 
in the region is very mission critical and citizen-centric,” 
Rajasekhar told Open Source For You.
The latest Postgres release (version 9.6), which has 
been powering the distribution system, can be scaled to 
more than 1.5 million transactions per second (TPS). 
However, the team is working on parallel data processing 
features to achieve a higher TPS.
N. Chandrababu Naidu,
chief minister,
Andhra Pradesh
For U & Me CaseStudy
68 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

The ePDS project: Maintaining humongous public distribution records in a digital form
The early challenges 
Like with any other large scale project, 
the development of a huge ePDS 
also faced some challenges initially. 
As Ashish Nauriyal, a lead solutions 
consultant at EnterpriseDB, explained 
in a conversation with Open Source 
For You, the major challenges  were 
designing, deploying and maintaining 
Postgres for a mission critical, 
statewide ePDS. “Some of the specific 
challenges faced were appropriate 
Postgres versions and project-relevant 
features, database and server-level 
tuning, expert guidance, implementation 
of best practices, tools required to 
achieve desired database-level tasks 
such as diagnosis of performance 
issues, monitoring, high-availability, 
maintenance operations, and ongoing 
database server and application level 
changes,” recalls Nauriyal.
The engineers leveraged their 
extensive experience in the database 
management space to overcome these 
challenges. The engineering team 
provided support for disaster recovery, 
security controls, performance tuning, 
and backups and upgrades in addition 
to designing and implementing systems. 
Also, the NIC team was allowed to 
change the management for the database 
with minimal or even no production 
database service disruption.
For the team at NIC, the major 
obstacle was the execution of tasks 
like biometric authentication,  the 
Aadhaar-enabled payment interface and 
hyper-scaling. “With the appropriate 
architecture and optimisation through 
the efforts of EnterpriseDB, the solution 
worked out flawlessly,” says Rajasekhar.
However, as the state government 
was committed to improving 
transparency and efficiency, no major 
administrative challenges were faced in 
opting for the advanced ePDS model.
Linux as a software stack
The NIC engineers used Linux as 
the software stack for the Postgres 
deployment. This mix is considered to 
be the real icing on the cake. “Postgres 
and Linux originate from a like-minded 
How EnterpriseDB helped in the 
deployment of the ePDS model
“EnterpriseDB included low-CAPEX 
and OPEX in the solution they gave 
us,” says Rajasekhar. EnterpriseDB’s 
engineers helped NIC pilot the ePDS 
model for a district for two months, 
and subsequently scaled this up to 
the entire state. Application server 
clusters with disaster recovery 
(DR) and business continuity (BC) 
architecture were used to run the 
Postgres database on a private cloud.
Techniques used to secure data in EnterprisesDB Postgres 
• Authentication: Implementation of advanced levels of authentication such as SSPI, 
LDAP and Kerberos
• Authorisation: Object level privileges to allow or revoke user access
• Auditing: Tracking and analysing database activities to ensure data security
• Encryption: Password storage encryption, encrypted columns, password protection 
on data across networks and SSL host authentication
• Prevention from SQL injection attacks: SQL/Protect deployed to provide a layer 
of security to give control back to the database administrator whenever potentially 
dangerous queries are received
By: Jagmeet Singh
The author is an assistant editor at EFY.
community. This community essence 
makes Linux an optimal platform for 
running Postgres,” says Nauriyal.
The presence of Linux enables 
experts like Nauriyal to control the 
database with ease. It also provides the 
flexibility to choose from multiple file 
systems to enable satisfactory results. 
“Control and visibility of a platform, 
along with the flexibility to choose from 
multiple file systems, help database 
administrators to manage a Postgres 
database that is performing well,” 
says Ramakrishna Malempati, senior 
database consultant, EnterpriseDB.
Other open source deployments
Apart from PostgreSQL, the NIC 
team also deployed Cassandra and 
MongoDB as the database solutions 
to make its ePDS, eSCM and ePOS 
successful in the state.  The use of all 
these open source solutions has reduced 
the CAPEX and OPEX of this project 
to zero.
The success of AP’s ePDS model 
has led to other states planning for 
its replication, with Rajasthan and 
Maharashtra being the first two 
states to do so. 
For U & Me
CaseStudy
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 69

70 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers How To
N
ode-RED is a visual wiring tool initially designed 
for IoT needs, but is more of a general-purpose tool 
these days. It can be used for interfacing sensor data, 
wired/wireless communication, cloud connectivity, data 
base connectivity, social media alerts, data analysis, system 
monitoring and, of course, any Node.js functionality. IBM 
Bluemix, SenseTecnic FRED, AT&T Flow and RedConnect.
io are some of the options for getting an instance on the cloud 
with customised nodes and enterprise grade support. Node-
RED forms a part of the Intel IoT gateways as a bridging 
solution. And it also powers IBM Watson Services.
Installation and initial steps
Node-RED can be installed on top of any Node.js runtime 
using the npm package manager, but certain nodes are 
platform-specific (say, with dependencies in Linux), and 
some are precisely targeted at boards like RaspberryPi 
for physical computing purposes. More nodes can also 
be added using npm. Node-RED can be easily managed 
using pm2, a process manager for Node.js for starting 
and stopping the instance. It can even run on Android 
using Termux support, and talk to Arduino-type of 
microcontrollers through the Firmata protocol. Node-RED 
can be deployed on any cloud environment with Node.js 
runtime. Node-RED can also be run in a Docker container, 
as documented in nodered.org/docs/platforms/docker. It 
pulls the image the first time and runs in a container. You 
can add all necessary add-ons to make a custom bundle, as 
mentioned in the Customising section.
Once Node-RED has started, follow the Getting Started 
section of the documentation and create simple flows using 
the UI editor available on Port No. 1880 of the host. Data 
flows across the nodes through input, output connectors in 
the form of JavaScript objects named msg, with msg.payload 
as the key property; function nodes can be used to provide 
custom logic in between with minimal JavaScript coding.
Here are some nodes of interest for prototyping 
IoT solutions:
 
MQTT out, MQTT in for publish and subscribe.
 
Http-request for invoking REST APIs.
 
JSON node for stringification or parsing.
 
Trigger, delay nodes to control the message flow.
Writing Custom Add-ons 
for Node-RED
If you are planning to kickstart your IoT development plans but aren’t comfortable with 
any particular programming environment, Node-RED could prove to be just right for you. 
You can use it to start developing applications with zero or minimal programming effort, 
and focus more on actual computing, interfacing and communication.
Node-RED

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 71
Developers
How To
 
Twitter nodes for sending or receiving tweets.
 
Tcp, udp, Websocket nodes for custom communication.
Here is a list of some more interesting nodes available 
through add-ons, for prototyping or building powerful 
bridging solutions:
 
Dashboard nodes through the node-red-dashboard add-on 
for quick UI development, which can render the view 
well in desktop or mobile browsers for monitoring and 
controlling services.
 
Nodes for discovering and accessing CoAP resources 
through coap-request node.
 
Nodes for peripheral access in Raspberry Pi, BeagleBone 
Black, Intel Edison, Arduino, etc.
 
Nodes for social media access to platforms like Hangouts, 
Telegram Bot, Facebook, etc.
 
Nodes for BLE motes, beacons like TI Sensortag, 
Eddystone, the Physical Web, etc.
 
Nodes for database connectivity with MySQL, 
MongoDB, InfluxDB, etc.
 
Nodes for platform connectivity like IBM Bluemix, 
Thingspeak, Emoncms, ThingWorx, etc.
 
Nodes for cloud services like Azure, AWS, Watson 
services and Kafka messaging.
 
Nodes for communicating with OpenHAB, 
SiteWhere frameworks.
 
Nodes for industrial and automotive needs like Modbus, 
CANBus, OPC UA, etc.
 This is just a sub-set of the available nodes; so stay tuned 
at flows.nodered.org, which gives the catalogue of custom 
nodes (around 1500 nodes, at present) and example flows, 
contributed from time to time.  Node-RED can be considered 
for elegant gateway designs and edge computing with this 
rich library support. You can identify user contributed nodes 
with the naming convention of node-red-contrib-xxxx and 
nodes developed by the Node-RED team with the naming 
convention of node-red-node-xxxx.
An example: Publishing sensor data 
to the IoT platforms
For better understanding of Node-RED capabilities, let’s look 
at an example of publishing sensor data from a Raspberry Pi 
attached with SenseHAT to OpenSensors.io with zero coding 
effort. SenseHAT is add-on hardware for Raspberry Pi introduced 
by the Astro Pi mission, which comes with the following 
peripherals and the Python library built on top of RTIMULib, 
officially maintained by the Raspberry Pi Foundation.
 
Temperature, humidity and pressure sensors for 
environment monitoring 
 
Accelerometer, gyroscope, magnetometer for motion 
sensing with 9 degrees of freedom
 
Five-button joy stick
 
8x8 LED matrix with RGB support
The recent Raspbian images come with Node.js and 
Node-RED pre-installed and fortunately, SenseHAT nodes are 
Figure 2: OpenSensors.io portal – devices and topics 
Figure 1: SenseHAT hardware and simulator UI
also pre-installed in Raspbian, through the add-on node-red-
node-pi-sense-hat developed by the Node-RED team.
 Note: You can follow these steps even if you don’t have 
a Raspberry Pi or SenseHAT. You can try all these steps 
on a desktop machine by installing the simulator nodes 
developed by the same team through the add-on node-red-
node-pi-sense-hat-simulator, and access the UI through the 
link hostname:1880/sensehat-simulator, except for motion 
events which can’t be simulated at present.
OpenSensors.io is an IoT platform through which 
devices can send the data using MQTT publish or HTTP 
post, and data can be retrieved using MQTT subscribe 
or Realtime REST API support. To get started, create an 
account under publisher.opensensors.io/login, go to the 
Devices section, create a new device with a suitable name 
(say, rpisense), the applicable tags and, optionally, geo 
coordinates for the device location. Note down the generated 
client ID and device password. Go to the user profile section 
and request for a new API key, and note down the generated 
one. You need not use a portal login password for further 
data management; this device password and/or generated 
API key are useful for authorisation.
All messages are organised according to topics as 
per MQTT influence. A topic can be created on-the-fly 
based on published messages or can be created explicitly 
under the Topics section. To avoid collisions, topic names 
start with /users/xxxx/, where xxxx is the user name in 
the account credentials. A topic is public, by default, as 
this platform comes with good support for Open Data 
policies, so that any one can access the data from this topic 
without authorisation. But only an authenticated user can 
OSFY Demo
Organisations (Invitations)
Bookmarks
rpisense (Client ID: 6208)
New device password:
Please, keep this device password somewhere safe as it is only displayed for new devices!
Topics
Devices
Home
RaspberryPi examples

72 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
Developers How To
update the data. Topics and devices can also be brought in 
under organisations for better collaborative applications, 
where applicable public topics can be kept under suitable 
organisations. Refer to the API docs once, for the available 
REST APIs to access real-time and historical data.
Create a new flow, drag the SenseHAT input node (or 
simulator node) from the Raspberry Pi category and connect 
it to a MQTT out node as well as to a debug node, as shown in 
Figure 3, via  trigger and JSON nodes. Configure the SenseHAT 
node to generate only environment events by deselecting motion 
and joystick events. By default, this node emits the msg.payload 
for certain periodic intervals with properties like temperature, 
humidity and pressure; and message topics such as environment, 
as per the selection. Since the data rate is very high, add a trigger 
node in between, with the configuration of Send nothing, then 
wait for 10 seconds and then send the original msg.payload.  
You may add a JSON node from the function category after the 
trigger node to publish data in the JSON format instead of the 
JavaScript object.
Configure MQTT output node with the following 
parameters. Under the Connection tab, fill mqtt.opensensors.
io as the server host name, 1883 as the port number, and 
the device ID generated earlier as the client ID. Under the 
Security tab, fill in the user name and the password generated 
on device creation, and fill the topic name as /users/xxxx/
rpisense/weather by replacing xxxx with your user name.
Simulator node works well with the same steps, except 
that you keep changing the sensor values manually under the 
UI tab, i.e., localhost:1880/sensehat-simulator.
Hit the deploy option and 
monitor the sensor values 
locally under the Debug tab, 
as well as published messages 
in the Topics section of the 
OpenSensors portal. You can 
also monitor these messages 
with MQTT subscribe from 
other devices with a similar 
configuration and topic, as this 
platform supports only one 
MQTT connection per device.
Local dashboard
You can also build a simple 
dashboard for local access, 
apart from publishing to the 
cloud. For this, connect the SenseHAT node to a function 
node, increase the number of outputs to three and fill the 
following code: 
var msg1={}, msg2={}, msg3={};
msg1.payload=msg.payload.temperature;
msg2.payload=msg.payload.humidity;
msg3.payload=msg.payload.pressure;
return [ msg1,msg2,msg3 ];
Now, each output connector of this node can be connected 
to suitable dashboard nodes like gauge, chart, text, etc. 
Configure the dashboard nodes with RaspberryPi as the group 
name, SenseHAT as the tab name and give a suitable label and 
value range. Hit  Deploy and open the link hostname:1880/ui 
to see the sensor values locally, as shown in Figure 4.
 Note: The trigger node added earlier can only send the 
oldest or latest message by skipping the remaining ones. 
To get some consolidation like the mean, minimum and 
maximum of all the payloads, install the node-red-contrib-
aggregator add-on, and add an aggregator node instead of a 
trigger node to see the desired values with applied statistics.
Writing custom nodes
It’s time to prove that you can also contribute to Node-RED 
with your own additions. Any Node.js code can be easily 
wrapped into a custom node with a HTML frontend. For a 
simple example, let’s try to make a node for retrieving data 
published to the topic in the above section. For this, real-time 
APIs are offered, which open a Server Side Events (SSE) 
stream for a given topic, and an API key is needed (if the 
topic is not public), which is generated in the Profile section. 
Given below is the console based Node.js code to watch a 
public topic with SSE client support.
var EventSource = require(‘eventsource’);
var url=require(‘url’);
var topic=”/users/xxxx/rpisense/weather”;
var urlopts=url.parse(“https://realtime.opensensors.io/v1/  
 
  
 
 
 
  
 
 public/events/topics/”+topic);
var eventUrl = new EventSource(urlopts);
eventUrl.onmessage = function(event) {
  console.log(event.data);
}
Let’s follow the steps given below to wrap the above code 
into a Node-RED node.
1. Create a new directory node-red-contrib-osfydemo under 
NODE_PATH, i.e., <topdir-of-nodejs>/lib/node_modules.
2. From NODE_PATH/node-red/nodes, copy 99-sample.
js.demo, 99-sample.html.demo as opensensors.
js, opensensors.html in a sub-directory with name 
opensensors under node-red-contrib-osfydemo
Figure 4: Local dashboard
Figure 3: Connected nodes and MQTT configuration
Sense HAT Sim
msg.payload
Delete
Server
Topic
QoS
Name
Tip: Leave topic, qos or retain blank if you want to set them via 
msg properties.
mqtt publish
Retain
false
0
/users/rajeshsola/rpisense
6204@mqtt.opensensors.io:1883
Cancel
mqtt publish
trigger 10s
json

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 73
Developers
How To
By: Rajesh Sola
The author is a faculty member of C-DAC’s Advanced 
Computing Training School, and an evangelist in the 
embedded systems and IoT domains. You can reach him at 
rajeshsola@gmail.com.
[1] nodered.org/docs/, flows.nodered.org
[2]  nodered.org/docs/creating-nodes/
[3]  opensensors.io
References
Add suitable initial values under defaults section in html file
apikey: { value:”xxxx”},
ispublic : {value:true, required:true}
Note that a comma must be added at the end of the first 
line of the above code. Now, in js, type the following code in 
the local copy section:
this.apikey = n.apikey;
this.ispublic = n.ispublic;
Next, form the url as follows:
if(this.ispublic)
url=myurl.parse(“https://realtime.opensensors.io
 
  
/v1/public/events/topics/”+this.topic);
else
url=myurl.parse(“https://realtime.opensensors.io/v1/events
 
  
/topics/”+this.topic+”?api-key=”+this.apikey);
You can compare your code with the example code 
node-red-contrib-osfydemo under github.com/rajeshsola/
node-red-addons. I am planning to add a few more nodes for 
the historical data of opensensors.io, which can be found in 
the above repository.
A few tips before you start to write custom nodes
1. Do a simple search in flows.nodered.org to avoid 
overlapping or duplication. You can merge your changes 
into existing nodes instead of adding new ones, unless 
your node has some distinguishing features or coding 
compared to the existing ones.
2. If not many configuration changes are required compared 
to available nodes, you can create example flows or sub-
flows, e.g., most of the REST APIs and MQTT operations 
are possible with existing http-request and MQTT nodes 
(instead of adding new ones), or a simple function node 
may be good enough in between.
3. Once the new node is published to npm, new nodes will be 
pulled periodically and will be visible in the above library. 
Announce your contribution in the Node-RED mailing list 
for suggestions and feedback from the community. 
3. Create the manifest file based on the package.json as 
per the guidelines in nodered.org/docs/creating-nodes/
packaging.html. Then add eventsource as a dependency 
and replace “sample”: “sample/sample.js” with 
“opensensors” : “opensensors/opensensors.js”.
4. Edit opensensors.html as follows. Under RED.nodes.
registerType, make zero inputs and one output, as this 
node doesn’t receive any inputs and only generates 
payloads whenever server side events are triggered.
 
 inputs: 0, output:1
We’ll consider the pre-existing topic field as the opensensors 
topic, and the name is the default field kept for all nodes.
5. Edit opensensors.js as follows. Add the following lines in 
the beginning, in place of the foo entry:
 
var EventSource = require(“eventsource”);
 
var myurl=require(‘url’);
After respond to inputs....remove the this.on (‘input’, .....); 
and add the following code:
 
var  url=myurl.parse(“https://realtime.opensensors.io/
 
  
 
 
v1/public/events/topics/”+this.topic);
 
var eventUrl = new EventSource(url);
 
var msg={};
 
eventUrl.on(‘message’,function(event) {
 
 msg.payload=event.data;
 
 node.send(msg);
 
}); //or use any callback style of node.js
Rename SampleNode as OpenSensorsNode and replace 
all occurrences of sample with opensensors in both JavaScript 
and HTML files.
That’s it—the custom node is ready to use now. Restart 
Node-RED and refresh the browser page. You can find the new 
node under the input category, drag it and connect it to the debug 
node. Fill a suitable topic name in the Edit panel and deploy the 
flow. You will observe that all the published messages on this 
topic are captured by this node. If you are not planning to create 
an account initially, try the same with /orgs/osfydemo/rpisense/
weather, a public topic created for this example.
 Note: If you want to modify this node for private topics, 
add another text box for the API key with the entry node-
input-apikey (similar coding of topic, name fields), and a 
checkbox with the entry node-input-ispublic along with the 
following code: 
<div class=”form-row”>
<label for=”node-input-ispublic”> 
<input id=”node-input-ispublic” type=”checkbox”>  
 
  
 
public topic </label> </div>

74 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
OpenGurus Let’s Try
Kaa: An Easy-to-Use Platform 
for Building IoT Solutions
K
aa is a 100 per cent open source middleware platform 
for building end-to-end IoT solutions, connected 
applications and products. The Kaa IoT platform is 
licensed under Apache 2.0. Kaa takes care of all the backend 
heavy lifting and allows vendors to concentrate on maximising 
their product’s unique value. It is horizontally scalable, fault-
tolerant, and provides a broad set of features. Kaa was created 
for IoT companies and individuals interested in retaining 
ownership of the entire technological stack that they create.
An overview of Kaa
Kaa is a multi-purpose middleware platform for the IoT 
that allows you to create complete and smart applications. 
The Kaa platform provides an open, feature-rich toolkit for 
the IoT product development process and thus dramatically 
reduces the associated costs, risks and time-to market. It 
offers a set of out-of-the-box enterprise-grade IoT tools 
that can be easily plugged in and implemented in a large 
majority of the IoT use cases.
There are numerous architectural specifics that make IoT 
development with Kaa fast and easy. First, Kaa is hardware-
agnostic and thus compatible with virtually any type of 
linked device, sensor and gateway. It also provides a clear 
construction of IoT features and extensions for different 
types of IoT applications. These can be used almost as 
plug-and-play modules with minimal addition of code on 
the developer’s part. Kaa introduces standardised methods 
that enable integration and interoperation across connected 
products. And it is designed to be robust, flexible, and 
easy-to-use and deploy.
Kaa’s features
Some features of Kaa that enable key IoT capabilities 
are listed below:
1.  Analyses user behaviour and delivers targeted 
notifications.
2. Manages an unlimited number of connected devices.
3. Performs real-time device monitoring.
4. Performs remote device provisioning and configuration.
5. Creates cloud services for smart products.
6. Sets up cross-device interoperability.
7. Distributes over-the-air firmware updates.
8. Collects and analyses sensor data.
9. Performs A/B service testing.
How it works
Kaa enables data management for connected objects and 
the backend infrastructure by providing the server and 
endpoint SDK components. The SDKs get embedded 
into your connected device and implement real-time 
bi-directional data exchange with the server. Kaa SDKs 
are capable of being integrated with virtually any type of 
connected device or microchip.
The Kaa server provides all the backend 
functionality needed to operate even large scale 
and mission-critical IoT solutions. It handles all the 
Kaa is a multi-purpose middleware platform for the Internet of Things that allows building 
complete end-to-end IoT solutions, connected applications, and smart products. 

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 75
OpenGurus
Let’s Try
communication across connected objects, including data 
consistency and security, device interoperability and 
failure-proof connectivity.
The Kaa server features well-established interfaces for 
integration with data management and analytics systems, 
as well as with product-specific services.  It acts as a 
foundation for the backend system that you are free to 
expand and customise to meet the specific requirements of 
your product.
Why use Kaa?
The following features make Kaa different from other 
middleware platforms used to build IoT solutions:
1. 100 per cent open source and free.
2. Reduces the development time from months to weeks.
IoT PaaS
Kaa IoT
Code control
Proprietary and opaque
Open source and transparent
Cost
Annual fee + usage fee + service + 
support
Service + support
Scalability and security
Limited visibility and control 
Full visibility and control
Talent attraction
Challenging due to the proprietary 
nature of the platform
Straightforward on account of being 
open source and the reuse of proven 
and widely adopted open source 
components
Professional services
Expensive, shared, on-demand re-
sources
Dedicated team; proven and cost-
efficient offshore methodology
Differences between commercial loT PaaS platforms and Kaa
By: Neetesh Mehrotra
The author works at TCS as a systems engineer. His areas of 
interest are Java development and automation testing. You 
can contact him at mehrotra.neetesh@gmail.com.
3. Is rapidly evolving, with new features being added for free.
4. Pre-integrated with data management systems.
5. No single point of failure.
6. Easily tailored for any business application.
7. Minimises the costs and risks of application development.
8. Straightforward hardware integration procedure.
9. Handles millions of devices and scales elastically.     
10. Significantly reduces development time by providing an 
advanced, out-of-the-box IoT features set. 
Would You
Like More
DIY Circuits?

76 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
OpenGurus Let’s Try
SiteWhere delivers a complete management system to help users avoid per 
device charges by SaaS operators. It connects devices using MQTT, AMQP, 
STOMP and other protocols, and devices can be added through self-registration, 
REST services or in batches. It can also control large numbers of devices using 
batch command operations. 
SiteWhere: An Open Platform 
for Connected Devices
S
iteWhere is an open platform for monitoring and 
controlling IoT devices and storing device data. It is 
licensed under CPAL 1.0 and can be deployed as an 
on-premise solution with complete freedom and scalability, 
which eliminates the per device or per data pricing by SaaS 
providers. It can also be deployed in a bare metal cloud 
environment for public access. It comes with advanced 
multiple tenant architecture to run various IoT applications 
in a single server instance. It integrates with proven 
software and services for the enhanced enterprise needs of 
connected devices. This article familiarises you with the 
platform, focusing on device communication using JSON 
payloads over MQTT and on availing platform services 
using REST APIs.
Architecture and features
The core platform of the server is based on Spring Boot 
from v1.7.0 and comes with an embedded Tomcat server in 
recent versions, but you can still build the Web Application 
Archive (WAR) file from sources, and deploy it in a custom 
or vanilla version of the Tomcat server. It comes with multi-
tenancy support from v1.2.0, each tenant engine is isolated, 
having its own data storage and processing channels. It uses 
MongoDB for the default data store, with SiteWhere as the 
core database and isolated databases for each of the tenants, 
with tenant-xxxx naming. Devices can communicate using 
the JSON format or Google Protocol Buffers (Protobuf) 
over MQTT transport, and REST APIs are offered to avail 
platform services.
Each tenant device is placed in a collection, known as 
a site, to cluster the location-aware devices. This enables 
monitoring of all events at the site level as well as the device 
level. On bootstrap, a default tenant engine is created with 
Construction Site, initially. Devices can be kept under device 
groups as logical units; these can associate with device 
specifications as per common hardware features, and associate 
with assets for real world mapping.
Components and integration
SiteWhere makes use of the following popular open 

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 77
OpenGurus
Let’s Try
source solutions and external services— a few for internal 
components and some for enriched integration support with 
inbound and outbound event processing.
 
MongoDB as the default data store
 
Mosquitto as the MQTT broker (even though HiveMQ is 
mentioned in the documentation)
 
ActiveMQ, RabbitMQ for rich protocol support like 
AMQP, STOMP, etc.
 
Eclipse Californium for CoAP messaging
 
InfluxDB for time series data and Grafana for visualisation
 
HBase for distributed clustering support for device events 
 
Hazlecast, an in-memory data grid for external event 
processing
 
Mulesoft Any Point Platform for ESB functionality
 
Azure Event Hub and Amazon SQS client libraries for 
event forwarding
 
WSO2 Siddhi for Complex Event Processing (CEP)
 
WSO2 Identity Server for asset management
 
Apache Spark for streaming analytics
 
Apache Solr for indexing and searching device events
 
Twilio client for SMS alerts over the cloud
 
Mapping devices with Magento products as assets through 
the community edition
It can also communicate with external cloud services 
like dweet.io for external messaging and InitialState for 
advanced data visualisation. It comes with an add-on for 
OpenHAB persistence support and for controlling back 
devices via outbound events.
Installation
Installation of SiteWhere is very simple, with few 
dependencies. Install OpenJDK 1.8, MongoDB and any MQTT 
broker like HiveMQ or Mosquitto as dependencies. Start 
MongoDB and MQTT broker. Download the tarball of the 
latest stable release (v1.9.0 at present), extract it to a suitable 
location, say /opt, then switch to the extracted directory, 
i.e., /opt/sitehwhere-server-1.9.0 and execute the script bin/
startup.sh. To customise the server port, edit conf/application.
properties and uncomment the line server.port=8080.
Building from sources
If you want to build SiteWhere from sources, check out the 
latest branch, say SiteWhere-1.10.0 or master from github.
com/sitewhere/sitewhere.git and run the following commands.
To create a Web application archive (WAR) file, which 
can be deployed on a Tomcat-like server, type:
gradle clean war
To generate a standalone archive with an embedded 
server, similar to the downloaded tarball, use the 
following command:
gradle clean serverTar
Collect the generated WAR file or tar file from the build/
distributions sub-directory.
Running SiteWhere in a Docker container
You can even run SiteWhere in a Docker container, for which 
you can check out the source code of any recent version, navigate 
to sitewhere-docker/standalone/1.8.0, and replace the Ubuntu 
version 14.04 with 16.04 in Dockerfile for better package support. 
Run the following command to build the image:
docker build -t sitewhere/standalone:1.8.0 .
To launch the container for the built image, use the 
following command:
docker run -p 8080:8080 -p 1883:1883 -p 61623:61623\ 
 
 --name mysitewhere sitewhere/standalone:1.8.0
To customise the port, launch the shell using the following 
command, switch to /opt/sitewhere/conf and edit application.
properties as mentioned above:
docker exec -it mysitewhere /bin/bash
If SiteWhere doesn’t start manually, launch the 
server as follows:
docker exec -it mysitewhere /opt/sitewhere/bin/startup.sh
SiteWhere can also be deployed on cloud environments 
like Amazon EC2 and Microsoft Azure for public access.
 Note: There is a problem in downloading images from 
specified repositories in the Docker hub. I suggest you build 
your own from available Docker script.
The first steps
You can access the HTML5 based Admin interface on the 
URL path /sitewhere/admin of the chosen host and port. An 
interactive REST interface based on Swagger is available on 
the path /sitewhere. For example, if the server is installed on 
Figure 1: Architecture and integration of SiteWhere
SiteWhere Admin Application
Big Data Storage
Apache HBase
MongoDB
Asset Modules
Identity Management
Asset Management
Location Management
SiteWhere Tenant Engine
Device Management
Communication Engine
Inbound 
Pipeline
MQTT, AMQP, 
Stomp, etc.
Data from Devices
Commands to Devices
MQTT, AMQP, 
Stomp, etc.
Event Sources
Outbound 
Pipeline
Command 
Destinations
REST APIs
Data Storage SPIs
Asset SPIs
Integration
Third Party Applications
SiteWhere Java Client
Microsoft Azure EventHub
Twilio Cloud Communication
Apache Solr
MuleSoft AnyPoint Platform

78 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
OpenGurus Let’s Try
the same machine and running on port 8080, access the admin 
interface by using localhost:8080/sitewhere/admin and the 
REST interface using localhost:8080/sitewhere. The default 
credential for both the interfaces is admin:password.
Device events
SiteWhere supports the following device events through the 
MQTT protocol using JSON or Google’s Protobuf format. In 
this article we’ll use the JSON format and publish the payloads 
to the MQTT topic SiteWhere/input/json as per the tenant 
configuration.
Registration: Any device should be registered initially by 
publishing the following JSON payload: 
{
 
“hardwareId”: “123-MyRpiSense-4567890”,
 
“type”: “RegisterDevice”,
 
“request”: {
 
 “hardwareId”: “123-RpiSense-4567890”,  
 
 
 
 
 
 “specificationToken”: “xxx-xx-xx-xx-xxxxxx”,  
 
 “siteToken”: “xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx”
 
}
};
Here hardwareId can be any unique value; siteToken 
identifies the preferred site, say construction site, and 
specificationToken identifies Raspberry Pi from the device 
specifications through the Admin interface.
You can identify the new devices under the Admin UI 
in the Devices section and Site view section. You can also 
register a device manually here.
Location update: This helps in geo mapping your device 
initially or whenever the device is moved for better location 
awareness in an associated site. To do this, publish the 
following payload with the suitable parameters:
{
 
“hardwareId”: “123-MyRpiSense-4567890”,
 
“type”:”DeviceLocation”,
 
“request”: {
 
 “latitude”: “18.5204”,
 
 “longitude”: “73.8567”,
 
 “elevation”: “560”,
 
 “updateState”: false,
 
 “eventDate”: “2017-06-01T12:00:00.390Z”
 
}
}
Sending measurements: To send measured values 
from a device like Raspberry Pi, let’s look at  publishing 
system metrics like the load average of the CPU and 
memory usage, periodically. In Node.js and NodeRED 
environments, these can be calculated with the following 
code, considering avg1 and avg5 as the load average for 
the last 1 minute and 5 minutes, respectively, and pmem as 
memory utilisation. You may also add the average of the 
last 15 minutes as one more property.
const os=require(‘os’);
var avg1 = os.loadavg()[0];
var avg5 = os.loadavg()[1];
var pmem=(100 - (os.freemem()/os.totalmem())*100).toFixed(2);
Now form the payload in the following format, and 
publish periodically or on an event basis.
{
 
“hardwareId“: “123-MyRpiSense-4567890”,
 
“type“: “DeviceMeasurements”,
 
“request“: {
 
 “measurements“: { 
 
         “rpi.loadavg1”: avg1,
 
         “rpi.loadavg5”: avg5,
 
         “rpi.usagemem”: pmem,
        },
        “updateState“: true,
        “eventDate“: now
 }
};
If you have a suitable target board and 
sensors, you can send better payloads, say, 
weather metrics like temperature, humidity, 
pressure, etc, or motion sensing metrics like 
roll, pitch and yaw from an accelerometer’s 
or gyroscope’s inputs. The SenseHAT add-
on board for Raspberry Pi is a good choice 
for these sensors.
Sending alerts: A device can send 
alerts when anomalies are detected 
in measured values by publishing the 
following payload:
Figure 2: Admin interface – site information and registered devices

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 79
OpenGurus
Let’s Try
{
    “hardwareId”: “123-MyRpiSense-4567890”,
    “type”:”DeviceAlert”,
    “request”: {
        “type”: “rpi.cpuoverload”,
        “level”: “Warning”,
        “message”: “CPU Loadavg is very high!!”,
        “updateState”: false,
        “eventDate”: now,
        “metadata”: { 
            “loadavg”: avg,
            “method”: “uptime”
        }
    }
}
Delivering commands: SiteWhere can send 
commands to devices through its outbound processors 
in Protobuf or JSON formats. Devices can receive them 
through the MQTT Subscribe operation using the topic 
name /SiteWhere/system/<hardwareId> for system 
generated commands on an event basis and /SiteWhere/
commands/<hardwareId> for custom commands. You can 
register a groovy script to trigger custom commands when 
anomalies are detected in the device measurements as 
described in http://documentation.sitewhere.org/tutorials/
raspberry-pi.html. You can also invoke custom commands 
manually under the Devices section. Commands can 
also be delivered via the Twilio service or CoAP library. 
Custom commands need to be added in the Admin UI under 
Device specifications. We can find the triggered command 
by parsing the received payload. 
Acknowledging commands: The device can 
acknowledge delivered commands by publishing a suitable 
payload, by quoting back the original event ID and device 
response as described in documentation.sitewhere.org/
userguide/sending-data.html. You can observe all these 
events by browsing the target device or associated site in 
the admin interface. You can also list the events through 
various REST APIs on the specified path with the GET 
method and suitable tokens.
REST API
Most of the platform’s functionality is available through 
various REST APIs, apart from the Admin interface, and any 
external entity can avail these services. For simple, interactive 
usage of these APIs, a Swagger UI is added to make suitable 
requests and check the response in JSON format. 
Here are some examples of REST calls with the following 
common headers for authentication purposes.
Headers: 
{
 
 Authorization: Basic
 
 Credentials: admin:password
•  www.lulu.com
•  www.magzter.com
•  Createspace.com
•  www.readwhere.com

80 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
OpenGurus Let’s Try
Figure 4: The Swagger interface for REST API
By: Rajesh Sola
The author is a faculty member of C-DAC’s Advanced 
Computing Training School, and an evangelist in 
embedded systems and IoT domains. You can reach him 
at rajeshsola@gmail.com.
[1] sitewhere.org/architecture.html
[2] github.com/sitewhere
References
events, and can be wired to a regular MQTT publish node. 
Similarly, a MQTT subscriber node can be wired with a 
command node for parsing. If you are using Raspberry 
Pi, you can wire a DHT node or a SenseHAT node with a 
measurement node for the desired sensor values. Raspberry 
Pi’s integration tutorial mentioned earlier gives insights into 
using NodeRED to generate the above payloads and parsing 
commands. You can find detailed examples written in Node.
js and NodeRED flows for the communication through 
MQTT and REST, in the Sitewhere-examples sub-directory 
of github.com/rajeshsola/iot-examples.
Java agent
A Java agent is available under github.com/sitewhere/
sitewhere-tools, which provides a command line client for 
custom communication with the platform. You can edit 
the config /config.properties  and run the pre-built JAR file 
for initial testing. You can also edit the example code for 
custom communication or integrate this agent with any Java 
code base easily.
Mobile apps
An Android SDK is available under github.com/sitewhere/
sitewhere-android-sdk, which provides SiteWhereActivity 
and SiteWhereProtobufActivity for base functionality and 
communication services like MQTT and REST for client 
implementation. Android apps can be easily built using 
this SDK. You may refer to the sample application before 
proceeding, which sends location events and accelerometer 
readings as measurements.
Acknowledgement: Figure 1 is taken from http://
documentation.sitewhere.org/architecture.html.  
Login:
sites: Operations related to SiteWhere sites.
Show/Hide
/sites
Create new site
List sites matching criteria
Delete site by unique token
Get site by unique token
Update existing site
POST
GET
GET
PUT
DELETE
/sites/{siteToken}
/sites/{siteToken}
/sites/{siteToken}
/sites
List Operations
Expand Operations
Raw
admin
Password:
Tenant: sitewhere1234567890
 
  
‘X-Sitewhere-Tenant’: ‘sitewhere1234567890’
}
For a listing of all available sites:
GET  /sitewhere/api/sites
For a listing of a particular site:
GET /sitewhere/api/sites/{siteToken}
For a listing of the associated devices’ locations on a site:
GET /sitewhere/api/sites/{siteToken}/locations
For a listing of site measurements:
GET /sitewhere/api/sites/{siteToken}/measurements
For a listing of alerts on a particular site:
GET /sitewhere/api/sites/{siteToken}/alerts
For a listing of command invocations:
GET /sitewhere/api/sites/{siteToken}/responses
For a listing of command responses:
GET /sitewhere/api/sites/{siteToken}/responses
To obtain server runtime information:
GET /sitewhere/api/system/runtime
To obtain the version of SiteWhere:
GET /sitewhere/api/system/version
You can explore the Swagger UI or documentation.
sitewhere.org/rest/single.html for a complete listing.
NodeRED support
An add-on for NodeRED is available with the name 
node-red-contrib-sitewhere. It provides a few nodes that 
generate JSON payloads for device registration, location 
updates, measurements, alerts as well as acknowledgement 
Figure 3: Device measurements in Admin UI

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 81
OpenGurus
Let’s Try
R
aspberry Pi is a sensational single-board computer 
(SBC) and development board, which is heavily used 
for the prototyping of IoT based products. It is the 
best-selling British computer ever, with more than 10 million 
pieces sold already. Contrary to common belief, Raspberry 
Pi is not entirely open source. Yet, it has been used in many 
open source projects. In this article, we will learn to use it 
as a development board. For all the programs and circuits 
discussed here, I have used Raspberry Pi 3. Unless explicitly 
specified otherwise, from now onwards, the name Pi refers to 
Raspberry Pi 2 Model B, 3 Model B or Zero.
Raspberry Pi pinout
What makes Raspberry Pi suitable for making IoT projects 
is its 40-pin expansion header. Pins are arranged in a 2x20 
fashion. Figure 1 is a pinout diagram, taken from Wikipedia. 
Please visit https://pinout.xyz for a detailed live pinout diagram. 
Numbering systems
Raspberry Pi pins are numbered in two different ways— 
physical numbering and Broadcom numbering (BCM). In 
the first case, the pins are numbered sequentially from one 
to 40. In the figure, this is shown as Pin#. And the image 
represents what is seen when the Pi is held with the USB 
ports facing downwards. That is, Pin 2 is the pin in the 
corner. The Broadcom numbering system is the default option 
for the SoC (System-on-Chip). Raspberry Pi uses a SoC 
developed by Broadcom Limited. Raspberry Pi 2 and Zero 
use BCM2836 and BCM2835, while the Pi 2 version 1.2 and 
3 use BCM2837. This is also known as GPIO numbering and 
is shown as GPIO# in the figure. 
As you have probably guessed already, all the pins are not 
programmable. There are eight ground pins and two +5V pins 
and three +3.3V pins, which are not programmable. There are 
other dedicated pins too. Most of the pins have alternative 
functions, as shown in the figure. A majority of the pins are 
directly connected to the SoC; so while connecting circuits 
or components, one should be careful to avoid wrong wiring 
and short circuits. It is always good to have a descriptive 
pinout diagram printed out for quick reference as well as a 
multimeter on the work desk. 
Programming the pins
Armed with some understanding about the pins, let us move 
to programming. The Python package used for Raspberry Pi 
GPIO programming is RPi.GPIO. It is already installed in 
Raspbian, the default operating system for Pi. 
If you are using any other operating system, the package 
can be installed by using the following command: 
$  sudo pip install RPi.GPIO
Now, fire up IDLE or the Python console and type the 
following commands:
import RPi.GPIO as GPIO
print(GPIO.RPI_INFO)
You will get some basic information about your Pi printed as 
the output. So the ‘Hello world’ of GPIO programming is done!
The GPIO programming workflow
Let us discuss the steps involved in writing a GPIO Python 
script, in general.
Step 1: Import the RPi.GPIO package.
Step 2: Set the numbering style to be used. We use the 
method GPIO.setmode() for this. It takes either GPIO.
BOARD or GPIO.BCM as the parameter. GPIO.BOARD 
stands for physical numbering and GPIO.BCM stands for 
Broadcom numbering. In order to keep things simple, we will 
An Introduction to Raspberry Pi 
GPIO Programming Using Python
This article uses the RPi.GPIO Python package to introduce Raspberry Pi GPIO 
programming. The GPIO package bundled with Raspbian is aimed at Raspberry Pi beginners 
who are familiar with Python and interested in designing IoT products.

82 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
OpenGurus Let’s Try
mypin = 8
GPIO.setup(mypin, GPIO.OUT, initial = 0)
Now, to change the state of the pin, type:
GPIO.output(pin, state) 
The value of state can be either 1 or GPIO.HIGH or True 
for the ON state and 0 or GPIO.LOW or False for OFF.
Figure 1: Raspberry Pi pinout diagram
use only GPIO.BOARD here.
Step 3: Set up the necessary input and output pins.
Step 4: Read inputs and give outputs.
(Steps 3 and 4 are extensively explained in the 
following sections.)
Step 5: Clean up GPIO and exit.
You must clean up the pin set-ups before your program exits 
otherwise those pin settings will persist, and that might cause 
trouble when you use the same pins in another program. The Pi 
‘expresses its displeasure’ with a warning. To clean up the entire 
set of pins, invoke GPIO.cleanup(). If you want only a few pins 
to be cleaned up, then the pin numbers should be provided as 
GPIO.cleanup(channel_list). Anyway, you can suppress the 
warning messages by calling GPIO.setwarnings(False).
Setting up an output pin
To set a pin as an output pin, we have to call the method 
GPIO.setup(pin, GPIO.OUT). Here, pin is the pin number of 
the pin. You can set the initial state to be ON(1) or OFF(0) by 
using the initial parameter. So, to set Pin 8 as an output pin 
with the initial state as OFF, use the following code: 
import RPi.GPIO as GPIO 
GPIO.setmode(GPIO.BOARD)
Figure 2: Circuit1
Practice circuit 1
For all the practice circuits, use a breadboard and jumper wires. 
Now, take a regular 5mm LED, connect the anode (long 
leg) to any GPIO pin, say Pin 8, using a series resistor of 270Ω. 
Connect the cathode (short leg) to any ground pin, say Pin 6. 
The series resistor makes sure that the LED will not 
draw too much current. The GPIO pins provide 3.3V, with 
the maximum permitted current draw of 50mA. Roughly 
speaking, for 3v3, any resistor less than or equal to 1K can 
be used as the series resistor, and lower the resistance to the 
appropriate value if the LED is too dim. The exact value can 
be calculated using the formula:
 Resistor value = ( 3.3 – VLED ) / ILED. 
For more information, you can visit http://www.
electricaltechnology.org/2013/08/how-to-calculate-value-of-
resistor-for-LED-circuits.html
After the connections have been made properly, power 
up the Pi and open IDLE or any text editor. Then type the 
following code:
import RPi.GPIO as GPIO
#for the sleep method
import time
led = 8
#set numbering mode for the program 
GPIO.setmode(GPIO.BOARD)
#setup led(pin 8) as output pin
GPIO.setup(led, GPIO.OUT,initial=0)
try:
 
#turn on and off the led in intervals of 1 second
 
while(True):
 
  
 
#turn on, set as HIGH or 1
Pin 8
Pin 6
270Ω

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 83
OpenGurus
Let’s Try
 
  
 
GPIO.output(led,GPIO.HIGH)
 
  
 
print(“ON”)
 
  
 
time.sleep(1)
 
  
 
#turn off, set as LOW or 0
 
  
 
GPIO.output(led, GPIO.LOW)
 
  
 
print(“OFF”)
 
  
 
time.sleep(1)
except KeyboardInterrupt:
 
#cleanup GPIO settings before exiting
 
GPIO.cleanup()
 
print(“Exiting...”)
This code will print ON and OFF alternatively on the 
screen, in sync with when the LED is turned on and off. 
The Ctrl+C key combination can be used to terminate the 
execution of the program. The except KeyboardInterrupt: 
mechanism is used to detect the Ctrl+C keypress. The Sleep 
method will make the process wait for the given amount of 
time, which is one second here.
Setting up an input pin
Just like a ground pin was used to complete the circuit of the 
output pin, the circuit of an input pin should be completed 
using a ground pin or 3v3 pin. A lone input pin in a circuit 
is said to be ‘floating’. Since its voltage can be of any value 
between 0 and 3.3V, it cannot be used. That should be avoided 
by using a 3v3 pin or a ground pin and an in-built pull up or 
pull down resistor. 
A pin can be set as input as follows: 
GPIO.setup(channel, GPIO.IN, PUD)
Here, the channel is the pin number. PUD can be either 
GPIO.PUD_DOWN or GPIO.PUD_UP. It tells you whether 
to use the inbuilt pull up or the pull down resistor. If the 
3v3 pin is used, we have to use GPIO.PUD_DOWN (pull 
down resistor), and for the ground pin, we need to use GPIO.
PUD_UP (pull up resistor). The choice of 3v3 or ground 
is up to you. The only difference is the value read from an 
open circuit and closed circuit. For the 3v3 pin (GPIO.PUD_
DOWN), the input value of the open circuit will be 0 and of a 
closed circuit will be 1. For a ground pin (GPIO.PUD_UP), 
open circuit is 1 and closed circuit is 0.
The value can be read from an input pin using the method 
GPIO.input(channel), usually read into a variable.
Practice circuit 2
Fix a two-legged button switch on the breadboard. Now, 
connect one leg of the switch to any GPIO pin, say Pin 7, and 
connect the other to any 3.3V pin. 
#!/usr/bin/python3
import RPi.GPIO as GPIO
import time
Figure 3: Circuit 2
cnl = 7
GPIO.setmode(GPIO.BOARD)
# PIN 7 AND 3.3V
# normally 0 when connected 1
GPIO.setup(cnl, GPIO.IN, GPIO.PUD_DOWN)
try:
 
while(True):
 
  
 
print(GPIO.input(cnl))
 
  
 
time.sleep(1)
except KeyboardInterrupt:
 
GPIO.cleanup()
 
print(“Exiting”)
When this program is run, it will print 0 continuously, and 
when the switch is pressed down (when the circuit is closed) 
the output will be 1.
Now change the circuit a little. Remove the connection 
from the 3v3 pin and connect it to any ground pin. Change the 
program by replacing GPIO.PUD_DOWN with GPIO.PUD_
UP. Now run the program, and 1 will be printed continuously. 
When the switch is pressed down, the output will be 0.
Interrupts
There is a problem with simple input pins, which is that 
the programmer has to constantly check the input data. To 
overcome this, we have interrupts known as ‘event-detect’ 
and a pin can be made to listen to events by calling: 
GPIO.add_event_detect(channel, event, callback = my_callback, 
bouncetime = timeinmilliseconds) 
Channel should be an input pin. The various events 
available are GPIO.RISING for the rising edge (when the 
signal changes to HIGH from LOW), GPIO.FALLING for the 
falling edge (when the signal changes from HIGH to LOW), 
and GPIO.BOTH for both rising and falling edges. The 
my_callback method contains the interrupt handling code, 
and will be executed as a separate thread. bouncetime is the 
minimum amount of time required between two events. If two 
events occur in succession, within the bouncetime limit, then 
the second event will be ignored.
Pin 7
Pin 1
Push Button Switch

84 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
OpenGurus Let’s Try
Practice circuit 3
This is just a combination of the previous circuits, without 
any change. The program will be changed in a way that when 
the switch is pressed, it will toggle the state of the LED.
#!/usr/bin/python3
import RPi.GPIO as GPIO
import time
led = 8
ledstate = True
#this method will be invoked when the event occurs
def switchledstate(channel):
 
global ledstate
 
global led
 
ledstate = not(ledstate)
 
GPIO.output(led,ledstate)
swtch = 7
GPIO.setmode(GPIO.BOARD)
GPIO.setup(swtch,GPIO.IN, GPIO.PUD_DOWN)
GPIO.setup(led,GPIO.OUT,initial=ledstate)
# adding event detect to the switch pin
GPIO.add_event_detect(swtch, GPIO.BOTH, switchledstate, 600)
try:
 
while(True):
 
  
 
#to avoid 100% CPU usage
 
  
 
time.sleep(1)
except KeyboardInterrupt:
 
#cleanup GPIO settings before exiting
 
GPIO.cleanup()
Pulse width modulation for analogue output
Pulse width modulation is a means to generate analogue 
signals from digital signal sources. In other words, PWM can 
fake analogue signals. PWM has two main characteristics – 
duty cycle and frequency. The duty cycle is the amount of 
time a signal is in the high state in one cycle. It is expressed 
in terms of a per cent measure. The frequency determines how 
fast the PWM completes a cycle. When the state of a digital 
signal toggles rapidly with changing duty cycle values, we 
feel that we get analogue signals.
There are two PWM pins in Raspberry Pi—PWM0 and 
PWM1. The onboard analogue audio output uses both PWM 
channels. So it is advised not to use both simultaneously. In 
any case, the RPi.GPIO package facilitates only software 
PWM, which can be implemented on any GPIO pin. For this, 
the desired pin should be set as an output pin first. Then use: 
pwm = GPIO.PWM(channel, frequency)
…where channel is the output pin and frequency is 
the frequency of your choice. Then start pwm with pwm.
start(dutycycle) (the duty cycle value should be provided 
here). The duty cycle value can be changed using pwm.
ChangeDutyCycle(dutycycle) and the frequency can be 
changed using pwm.ChangeFrequency(frequency). At the end, 
stop pwm by using pwm.stop().
Practice circuit 4
Let’s brighten and dim an LED. The circuit is the same as 
Practice circuit 1.
import time
import RPi.GPIO as GPIO
GPIO.setmode(GPIO.BOARD)
led=8
GPIO.setup(led, GPIO.OUT)
#starting with frequency 100
pwm = GPIO.PWM(led, 100)
#stating with 0, that is off state
pwm.start(0)
try:
 
while 1:
 
  
 
#duty cycle from 0% to 100%
 
  
 
for dc in range(0, 101, 5):
 
  
 
pwm.ChangeDutyCycle(dc)
 
  
 
time.sleep(0.1)
 
  
 
#duty cycle from 100% to 0%
 
  
 
for dc in range(100, -1, -5):
 
  
 
pwm.ChangeDutyCycle(dc)
 
  
 
time.sleep(0.1)
except KeyboardInterrupt:
 
pwm.stop()
 
GPIO.cleanup()
This article would not be complete without mentioning 
analog inputs. Since Raspberry Pi is a digital device without 
any built-in ADC (analogue-to-digital converter), reading 
analogue data from sensors or circuits requires an external 
ADC. The commonly used ADC is MCP3008. Discussing this 
ADC and its SPI communication protocol is beyond the scope 
of this article. Raspberry Pi supports SPI, I2C and UART 
protocols. I have found UART with Arduino as the ADC to be 
the simplest option of the three.
RPi.GPIO is just one package for GPIO programming. 
There are other packages like gpiozero available. Have fun 
making things!
All the programs discussed here are available at gitlab.
com/noblephilip/rpi. 
By: Noble Philip
The author is a free software enthusiast and a Raspberry 
Pi developer. He has more than 10 years of programming 
experience. At present, he works at Amal Jyothi 
College of Engineering, Kerala. He can be contacted at 
noblephilip(at)outlook(dot)com.

T
he next era of computing is the Internet of Things (IoT), 
also known as the Internet of Objects. IoT refers to the 
networked interconnection of everyday objects, which 
are equipped with ubiquitous intelligence. A recent report by 
McKinsey Global Institute reported that the number of connected 
machines has increased by 300 per cent over the past few years. 
By 2025, the economic impact of IoT is estimated to range from 
US$ 2.7 trillion to US$ 6.2 trillion. Wikibon predicts that the 
value created from the Internet will be about US$ 1279 billion in 
2020, growing annually at a rate of 14 per cent. 
The International Telecommunication Union (ITU) has 
defined the Internet of Things as, “A global infrastructure 
for the information society, enabling advanced services 
by interconnecting (physical and virtual) things based 
on existing and evolving interoperable information and 
communication technologies.”
The scope of the Internet of Things is increasing in diverse 
ways, as IoT based solutions are extending to virtually all 
areas of everyday life, from smart homes to smart industrial 
production. And the evolution of Industry 4.0 has begun. 
The term ‘Internet of Things’ consists of two words - Internet 
and things. The term ‘Things’ refers to various IoT devices 
with unique identities, which have the capabilities to perform 
remote sensing, actuating and live monitoring of certain sorts of 
data. IoT devices are also enabled for the live exchange of data 
with other connected devices and applications, either directly or 
indirectly, or collecting data from other devices, processing it and 
sending it to various servers. The other term,‘Internet’, is defined 
as a global communication network connecting trillions of 
computers across the planet, enabling the sharing of information.
IoT architecture
As the IoT is capable of connecting billions of heterogeneous 
objects via the Internet, there is an emerging requirement for 
a dynamic layered architecture. Figure 1 represents a standard 
IoT layered architecture.
Objects layer: The first layer (perception layer) 
represents physical sensors of IoT to sense, collect and 
process the information. 
Object abstraction layer: This transfers the data acquired 
by the object layer to the service management layer via secure 
channels. Data can be transferred via different technologies like 
Internet of Things: 
The Protocols Landscape
The Internet of Things (IoT) extends from a single constrained device to a whole 
range of cloud systems, all connected by a set of protocols that allow devices and 
servers to talk to one another. Let’s take a look at a few IoT protocols.
OpenGurus
Insight
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 85

86 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
OpenGurus Insight
3G, 4G, GSM, UMTS, Wi-Fi, Bluetooth, ZigBee, etc.
Service management layer: This layer enables IoT 
application programmers to work with heterogeneous objects, 
irrespective of the hardware platform.
Application layer: This enables high-quality smart 
services to fetch what the customers need, as per their 
requirements. It covers smart homes, smart production 
units, transportation, smart health care based biosensor 
equipment, etc.
Business layer: This layer manages the overall IoT 
system’s activities and services. It is responsible for building 
the business model, graphs and flowcharts on the basis of data 
acquired at the application layer. 
IoT protocols
IEEE (Institute of Electrical and Electronics Engineers) and 
ETSI (European Telecommunications Standards Institute) 
have defined some of the most important protocols for IoT. 
These are listed below.
CoAP (Constrained Application Protocol): This was 
created by the IETF Constrained RESTful Environments 
(CoRE) working group. CoAP is an Internet application 
protocol for constrained devices. It is designed to be used 
between devices on the same constrained network, between 
devices and general nodes on the Internet, and between 
devices on different constrained networks—both joined on the 
Internet. This protocol is especially designed for IoT systems 
based on HTTP protocols. CoAP makes use of the UDP 
protocol for lightweight implementation. It also makes use 
of RESTful architecture, which is very similar to the HTTP 
protocol. It is used within mobiles and social network based 
applications and eliminates ambiguity by using the HTTP 
get, post, put and delete methods. Apart from communicating 
IoT data, CoAP has been developed along with DTLS for the 
secure exchange of messages. It uses DTLS for the secure 
transfer of data in the transport layer.
MQTT Protocol: MQTT (Message Queue Telemetry 
Transport), a messaging protocol, was developed by Andy 
Stanford-Clark of IBM and Arlen Nipper of Arcom in 1999. It 
is mostly used for remote monitoring in IoT. Its primary task 
is to acquire data from many devices and transport it to the 
IT infrastructure. MQTT connects devices and networks with 
applications and middleware. A hub-and-spoke architecture 
is natural for MQTT. All the devices connect to data 
concentrator servers like IBM’s new MessageSight appliance. 
MQTT protocols work on top of TCP to provide simple and 
reliable streams of data.
MQTT Protocol consists of three main components: 
subscriber, publisher and broker. The publisher generates the 
data and transmits the information to subscribers through the 
broker. The broker ensures security by cross-checking the 
authorisation of publishers and subscribers.
MQTT Protocol is the preferred option for IoT based 
devices, and is able to provide efficient information-routing 
functions to small, cheap, low-memory and power-consuming 
devices in vulnerable and low bandwidth based networks.
XMPP (Extensible Messaging and Presence Protocol): 
This is a communication IoT protocol for message-oriented 
middleware based on the XML language. It enables the real-
time exchange of structured yet extensible data between any 
two or more network entities. The protocol was developed by 
the Jabber open source community in 1999, basically for real-
time messaging, presence information, and the maintenance 
of contact lists. XMPP enables messaging applications to 
attain authentication, access control, hop-by-hop and end-
to-end encryption. Being a secure protocol, it sits on top of 
core IoT protocols and connects the client to the server via 
a stream of XML stanzas. The XML stanza has three main 
components: message, presence and IQ. 
AMQP (Advanced Message Queuing Protocol): 
This was developed by John O’Hara at JPMorgan Chase in 
London. AMQP is an application layer protocol for message-
oriented middleware environments. It supports reliable 
communication via message delivery assurance primitives 
Figure 1: IoT layered architecture
Figure 2: How CoAP works
Figure 3: MQTT Protocol architecture
Application Layer
Network Layer
Perception Layer
Existed alone 
Application 
System
Access 
Layer
Edge 
Technology
Application Layer
Middleware Layer
Coordination Layer
Backbone  
Network Layer
Application
Business Layer
Application 
Layer
Service 
Management
Object Abstraction
Objects
Objects
Objects  
Abstraction
Service 
Management
Service 
Composition
Publishers
Subscribers
Subscribe
Subscribe
Topics
Publish
Publish
Publish
Broker
REST Internet
CoAP Communication
CoAP Environment
CoAP Server
CoAP Clients
REST-CoAP 
Proxy
HTTP Communication

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 87
OpenGurus
Insight
like at-most once, atleast once and exactly once delivery. The 
AMQP protocol consists of a set of components that route 
and store messages within a broker service, with a set of rules 
for wiring the components together. The AMQP protocol 
enables client applications to talk to the broker and interact 
with the AMQP model. This model has the following three 
components, which are connected into processing chains in 
the server to create the desired functionality.
 
Exchange: Receives messages from publisher based 
applications and routes them to ‘message queues’.
 
Message queue: Stores messages until they can be safely 
processed by the consuming client application.
 
Binding: States the relationship between the message 
queue and the exchange.
Data Distribution Service (DDS): This IoT protocol for 
real-time machine-to-machine communication was developed 
by the Object Management Group (OMG). It enables scalable, 
real-time, dependable, high-performance and interoperable 
data exchange via the publish-subscribe methodology. As 
compared to MQTT and CoAP IoT protocols, DDS makes 
use of brokerless architecture and of multicasting to bring 
high quality QoS to applications. DDS can be deployed in 
platforms ranging from low-footprint devices to the cloud, 
and supports efficient bandwidth usage as well as the agile 
orchestration of system components.
The DDS protocol has two main layers: Data Centric 
Publish-Subscribe (DCPS) and Data-Local Reconstruction 
Layer (DLRL). DCPS performs the task of delivering the 
information to subscribers, and the DLRL layer provides an 
interface to DCPS functionalities, enabling the sharing of 
distributed data among IoT enabled objects.
STOMP (Simple Text Oriented Messaging Protocol): 
This text based protocol was developed to work with 
message-oriented middleware. It provides an interoperable 
wire format that enables STOMP clients to communicate with 
any STOMP message broker to enable easy and widespread 
messaging interoperability among many languages, platforms 
and brokers. Like AMQP, STOMP provides the message 
header with properties and a frame body. 
STOMP does not, however, deal in queues and topics—it 
uses a SEND semantic with a ‘destination’ string. The broker 
must map it onto something that it understands internally, 
such as a topic, queue, or exchange. Consumers then 
SUBSCRIBE to those destinations. Since those destinations 
are not mandated in the specifications, different brokers 
may support different flavours of the destination. So, it’s not 
always straightforward to port code between brokers.
However, STOMP is simple and lightweight (although 
somewhat verbose on the wire), with a wide range of 
language bindings. It also provides some transactional 
semantics. One of the most interesting examples is with 
RabbitMQ Web Stomp, which allows you to expose 
messaging in a browser through Websockets.
Figure 4: XMPP architecture
Figure 5: AMQP architecture
Client
Internet
Gateway
Client
Client
Server
Server
Publisher
Publisher
Publisher
Exchange
AMQP Broker
Queues
Subscriber
Subscriber
Subscriber
Figure 7: STOMP architecture
Figure 6: DDS protocol architecture
response
request
broker
channel
channel
SimpAnnotationMethod
StompBrokerRelay
MessageHandler
MessageHandler
channel
MESSAGE
SEND
SEND
MESSAGE
destination:/topic/a
destination:/topic/a
WebSocket client messages
“/topic”
“/topic”
STOMP 
TCP
Message 
Broker
“/app”
...
...
Application 1
Application 2
DLRL
DDS Domain
Topic
Topic
data values
data values
data values
Data Object
Receiver
Network
Sender
Subscriber
Subscriber
Publisher
DataWriter
dissemination
DDS
DataReader
DataReader
Receiver
Application 3
Continued on Page 90...

The Future of Indian E-governance 
Begins with OpenForge
The Ministry of Electronics and IT (MeitY) assigned 
the OpenForge project to the NeGD team that is responsible 
for having introduced the nation’s digital locker system, 
DigiLocker, last year. Not only has the OpenForge platform 
been designed to support open source, but it also happens to 
be an open source project on its own.
Open source technologies: Behind the scenes
The NeGD team has used the open source collaboration 
platform Tuleap to build the repository solution. Under 
the hood, there is the LAMP (Linux, Apache, MySQL 
and PHP) stack.
“To jumpstart the process, we wanted to select an existing 
open source application rather than build one from scratch. 
We evaluated various applications on multiple parameters,” 
says Amit Savant, technical product manager, NeGD.
There were two main challenges for the NeGD team 
in developing OpenForge as a successful open source 
C
ollaboration and sharing are the two ancient practices 
among Indians. But when it comes to opening up 
the source code of government applications, you 
will rarely find state departments evincing much interest. 
A large number of multinational corporations, on the 
other hand, actively support community efforts today and 
participate in significant open source developments to attain 
technical superiority. This is why the government has now 
launched OpenForge.
“The objective of OpenForge is to promote the reuse of 
existing applications,” explains Radha Chauhan, president and 
CEO, National e-Governance Division (NeGD). “Open source 
code will help in developing successful, scalable, high-quality 
e-governance applications in a collaborative manner. It will also 
encourage creativity in the application development process by 
encouraging collaborative development between government 
departments and agencies as well as private organisations, 
developers and citizens,” she says.
News ++
In March this year, the government of India launched openforge.gov.in as an official platform 
to promote the ‘open, share and collaborate’ philosophy among its various departments. 
With a GitHub-like model, hosted within the country, the new platform is aimed at preserving 
and reusing the software assets in e-governance applications in the country.
The team that developed OpenForge
88 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

News ++
offering. First, the platform should not be a mere version 
control tool but must offer rich collaboration features for 
software development teams. These should include issue 
tracking, forums, email lists, documentation and releases. 
Second, the application must be very customisable. It 
must also have a vibrant community with frequent releases 
to ensure that NeGD got timely support for any issues. 
Such support, updates or bug fixes also needed to be well 
documented if NeGD planned to customise and own them. 
Last, but not the least, NeGD wanted to select a platform 
built using tools and technologies that its technical team 
was conversant with.
Evaluating SourceForge, GitLab and Tuleap
To achieve what was planned, the NeGD team evaluated 
and experimented with SourceForge, GitLab and Tuleap. 
But Tuleap emerged as the ‘more suitable’ in the list. "We 
evaluated and experimented with SourceForge, GitLab and 
Tuleap. And, finally, we found Tuleap the most suitable as per 
our evaluation criteria," Savant says.
Attracting 70 projects in less than 100 days
OpenForge currently hosts over 70 active projects on its 
platform, and over 60 per cent of the total projects are 
in the public domain. Some of the important projects by 
the Ministry of Electronics and IT (MeitY) and NeGD, 
including DigiLocker and Government eMarket, are already 
using this platform. Besides, the OpenForge project itself is 
hosted on the online platform.
Systematic change
Debabrata Nayak, project director of open source 
collaboration at NeGD, considers OpenForge as a systematic 
change that required the support of the administration. Nayak, 
who also leads the technical team of the DigiLocker project, 
highlights that his team received complete support from the 
MeitY and NeGD.
Apart from the departmental support, it was the open 
source policy of the government that helped the development 
of OpenForge. As part of the Digital India initiative, 
the Indian government had released the policy titled 
‘Collaborative Application Development by Opening the 
Source Code of Government Applications’ back in 2015. “The 
policy provided a solid foundation for OpenForge. It listed 
the basic principles and elements for building the envisioned 
platform, and provided a clear idea of what the result ought to 
be,” states Nayak.
Administrative challenges before the launch
While the open source policy enabled the speedy process 
of building OpenForge, it was difficult to highlight the 
significance of the initiative in order to create a buy-in from 
other government departments. “The main challenge was that 
the idea itself is of a very technical nature and fails to resonate 
with most of the decision makers,” recalls Chauhan.
The technical team very often fails to explain the tangible 
benefits of such an initiative. Therefore, the team used a 
sample figure by quoting the software applications developed 
within NeGD using an open source stack. “Once we showed 
the benefits in terms of the money saved, it was very easy to 
highlight the importance of the initiative,” Chauhan told Open 
Source For You.
Once the launch was planned, the team began the internal 
testing phase for OpenForge. The prime objective was to  “create 
a simple product without compromising on rich features.”
“We wanted OpenForge to be simple for novice users yet 
provide flexibility to all project teams to achieve what they want,” 
says Amit Ranjan, project architect for OpenForge, NeGD.
How it differs from GitHub
One question raised by the Indian open source community is: 
What makes OpenForge different from GitHub?
The open source policy by the government encourages 
the use of open source in as many e-governance applications 
as possible. But not every e-governance project is going 
to be open source. Some may remain private. OpenForge 
has thus been created to provide a collaboration platform 
for both these public and private projects. The open source 
projects can very well be posted on GitHub, but enterprise 
level private repositories are not free on GitHub; they are 
available at a cost. Moreover, the team wanted the repositories 
of private projects to be hosted within India. It has therefore 
leveraged the state-run data centre provided by National 
Informatics Centre (NIC), which may not have been possible 
with GitHub. This is the prime purpose of not using GitHub 
and creating a separate platform.
“Feature wise, GitHub is more a code sharing and 
version control platform. It keeps on receiving new features 
continuously. Compared to GitHub, OpenForge supports more 
rich collaboration features such as various trackers to track 
bugs and requirements, documentation, forums, mailing lists 
and release management,” Ranjan emphasises.
What OpenForge takes from the government’s open 
source policy
• Collaboration: The platform must support a rich set 
of collaboration features for various roles within a 
software team.
• Code repository and version control:  Since the platform 
will be used by various government organisations to 
host existing projects, OpenForge must support the most 
common version control tools like Git and SVN.
• Support for public and private repositories: Since the 
policy anticipated that not every project can be open 
source, the platform must support public as well as 
private repositories.
• Community: The platform must also support the 
contributions from the community, academia and industry.
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 89

News ++
By: Jagmeet Singh
The author is an assistant editor at EFY.
Multifarious efforts to get contributions
NeGD has planned some key initiatives to encourage 
various IT teams and the community to share their code on 
OpenForge. Nayak says that his team is looking at internal 
evangelism for state level contributions as well as developing 
a systematic and constructive process to receive contributions 
from the community. “We want to promote a culture of 
treating the software code as an asset. This will need internal 
evangelism,” Nayak told Open Source For You.
The team is also planning to add credibility to the project 
by featuring some of the high profile projects done by the 
government. “We will especially try to highlight work done 
by the bigger government departments and the well-known 
applications,” Nayak adds.
For a successful open source based future
Alongside community contribution, the main focus of the 
platform is to introduce the philosophy of ‘open, share and 
collaborate’ to government departments.
“There is no dearth of young and enthusiastic talented 
people in academia and industry who are willing to contribute 
to government applications. Therefore, we sincerely hope that 
OpenForge will bridge this gap between e-governance and 
open source, bringing the community and the government 
together," Chauhan concludes.
Security measures taken for OpenForge
• Standard practices: NeGD follows the standard software 
development practices of uniform coding standards, 
guidelines and reviews. It complies with OWASP (Open 
Web Application Security Project) security standards and 
guidelines. Every product release is reviewed and tested 
internally for security vulnerabilities before it is deployed.
• 256-bit SSL encryption: OpenForge uses 256-bit 
secure socket layer (SSL) encryption for information 
transmitted during any activity.
• ISO 27001 certified data centre: The application is 
hosted in an ISO 27001 security certified data centre.
• Data redundancy: Data is backed up in a secure 
environment with proper redundancy.
• Security audit: The application has been audited by a 
recognised third party audit agency for security and 
vulnerability, after which a security audit certificate has 
been obtained.
By: Prof. Anand Nayyar
The author is an assistant professor in the department of 
computer applications and IT at KCL Institute of Management 
and Technology, Jalandhar, Punjab. He loves to work and 
research on open source technologies, cloud computing, 
sensor networks, hacking and network security. He can be 
reached at anand_nayyar@yahoo.co.in. You can watch his 
YouTube videos at Youtube.com/anandnayyar.
[1] http://coap.technology/
[2] http://mqtt.org/
[3] https://xmpp.org/
[4] https://www.amqp.org/
[5] http://portals.omg.org/dds/
[6] https://stomp.github.io/
[7] http://www.vscp.org/
References
Figure 8: VSCP operations
VSCP (Very Simple Control Protocol): This is more a 
framework than a protocol. VSCP is highly scalable, has a low 
footprint and is a free-cum-open source solution for device 
discovery and identification, device configuration, autonomous 
device functionality and secure firmware updates. VSCP makes 
things interact at the application layer. It makes use of CAN, 
RS-232, Ethernet, TCP/IP, MQTT and 6LowPan.
VSCP uses an event format and supports global unique 
identifiers for nodes, thus making a node identifiable no 
matter where it is installed in the world. Besides, it includes 
a register model in order to provide a flexible common 
interface for node configuration and a model for controlling 
the functionality of each node. VSCP does not make any 
assumptions regarding the lower level system used to realise 
the physical interconnection with the node; therefore, it works 
with different transport mechanisms such as Ethernet, TCP/IP, 
wireless, Zigbee, Bluetooth, CAN, GPRS, RS-232 and USB.
VSCP is event-based. Every time an event occurs, it is 
broadcast to all other nodes on the network. From there on, 
each node decides on its own if the event received needs 
to be processed or not. The final decision depends on the 
node’s decision matrix, which is made up of a number of 
‘if condition> then action> lines’, where the condition> is 
evaluated based on the fields present in the VSCP datagram 
broadcast to the network.  
Button 1
Event
Bus
DM
DM
Lamp 1
Lamp 2
Node 3
Node 2
Node 1
Continued from Page 87...
90 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 91
For U & Me
Overview
D
eveloped under a contract with ESA (European Space 
Agency)-ESRIN (ESA Centre for Space Observation), 
PolSARpro is a polarimetric Synthetic Aperture Radar 
(SAR) data processing and education tool. Most of the SAR 
sensors provide data at two different levels. Level 1 is complex raw 
data and needs a lot of mathematical and physical understanding of 
the phenomenon before it can be used. Level 2, on the other hand, 
is calibrated, geo-referenced data and a majority of the processing 
is image processing. In this article, we demonstrate Level 1 SAR 
processing through FOSS PolSARpro ver 5.1.
PolSARpro supports data processing of both airborne 
and space-borne radars. Table 1 lists the airborne and space-
borne satellites launched by the national space exploration 
programmes of various countries.
Table 1
Airborne satellites
Space-borne satellites
• 
Airsar
• 
Alos-1-Palsar
• 
Convair
• 
Alos-2-Palsar
• 
Emisar
• 
Cosmo-Skymed
• 
E-Sar
• 
Envisat-Asar
• 
F-Sar
• 
Radarsat2
• 
Sethi
• 
Risat
• 
Uavsar 
       
• 
Sentinel-1
• 
SIR-C
• 
TerraSAR X
Among the above mentioned satellites, data of Sentinel-1a, 
Sentinel-1b, Uavsar and Alos Palsar is freely available and can 
be found from the link https://vertex.daac.asf.alaska.edu/?
Processing capabilities of PolSARpro
PolSARpro is packed with tools for the smoothening of images 
and for speckle removal. Many filters, such as An-Yang filter, 
Box-car filter, Box-car Edge filter, Gaussian filter, IDAN filter, 
Lee Refined filter, Lee Sigma filter, Lopex filter, Mean-Shift 
filter, Non-local Means filter, etc, are available at your fingertips 
while working with this FOSS solution.
For visual appeal, you will find the Refined Lee filter 
applied on a SAR image in Figure 2.
There are significant decomposition algorithms available 
for quadrature polarimetric data, dual polarimetric data as well 
as compact polarimetric data. These decomposition algorithms 
help the study of particular features like ship detection, oil spill 
detection, agricultural applications, etc. A rich set of popular 
decomposition algorithms is available with PolSARpro. A few 
of them are listed in Table 2.
A step-by-step decomposition of SAR data through PolSARpro 
version 5.1 is shown via the home screen of this version.
Figure 1: Image without speckle filtering
Figure 2: Image with speckle filtering
PolSARpro: Wonderful FOSS  
for Synthetic Aperture Radar Data 
Processing
Synthetic Aperture Radar 
(SAR) is used to create 2D 
or 3D images of an object. 
Processing of SAR data 
can help to show how such 
imagery is formed. This 
article on the free and open 
source PolSARpro will interest 
students, researchers, and 
those interested in becoming 
remote sensing specialists or 
SAR system designers.

92 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
For U & Me Overview
different sensors. It will take time 
to process depending on the user’s 
hardware and the size of the data. 
After importing data, select Import 
→ Extract PolSAR images. This 
will give you the option to create 
a covariance matrix. If it is quad 
pole data, then multiple options 
like T3, C3, C2, Sinclair, etc, will 
be shown. These matrices are the 
‘BASE’ for further processing 
of the same data, and are now 
keys for further processing like 
decomposition, classification, 
etc. All the tabs will now be 
activated, including ‘Process’ (No. 
4 in Figure 1). Make sure that the 
matrix you are working on appears at the bottom left, as shown in 
Figure 5. Whatever process one selects will be applied to the matrix 
mentioned in the box (C2, in this example).
When you press the ‘Process’ tab, all the possible speckle 
filtering algorithms, decomposition algorithms, classification 
algorithms, etc, will be visible. Now, from here it’s up to you! 
You can try as many decompositions, filters and classifications 
that interest you or are relevant to your field.
One of the features of PolSARpro is that it creates a KML file 
which can be seen on the Google Earth application. The Google 
Earth app can also be linked with PolSARpro software during 
installation. This KML file shows the highlighted location of the 
SAR image on Google Earth. A sample of the highlighted image is 
shown in Figure 6.
A few segmentation algorithms are listed in Table 3.
Scatter plots can also be generated using any two entities 
such as the X-axis and Y-axis. 
In short, there is a lot more that you can do with PolSARpro, 
which is not possible to cover in this article. The more you 
explore, the more functionalities you will discover. Have a happy 
time exploring PolSARpro! 
The first step is to select the environment. The first active 
tab shown in Figure 3 gives options to select a single data set, 
dual data set or multi-data set. Select the single data set if you 
want to process only a single scene or a single SAR image. 
Select an appropriate folder location. The environment folder 
selection depends on a particular satellite that one wants to 
work with. Let’s take the example of Sentinel-1 SAR SLC 
level 1 data (Sentinel data is freely available as discussed 
earlier). After selecting the environment, the import tab (No. 2 
in Figure 3) will be activated. For Sentinel-1, select Import → 
Spaceborne Sensors → Sentinel-1 → Unzipped data product. 
Select the swath number, as Sentinel data contains three 
swaths in a single data set. This window differs according to 
Figure 3: PolSARpro home screen
Figure 4: Sentinel window
Figure 5: Showing C2 matrix
Figure 6: KML file (This snapshot is 
taken from Google Earth software 
developed by Google Inc.)
Table 2: A few popular decomposition algorithms
H / A / Alpha
Huynen
Barnes
Cloude
Holm
An & Yang
Bhattacharya & Ferry
Freeman
Neumann
Arri 
Van Zyl
Singh 4
Yamaguchi
L. Zhang
Touzi 
   
RVoG 
    
Raney
Entropy
Anisotropy
EigenValues
Aghababaee
Table 3: A few segmentation algorithms
H / A / Alpha classification
H / u / v classification
H / A / Alpha - Wishart classification
Unified Huynen classification
G.P.F. Supervised classifica-
tion
Fuzzy - H / Alpha
classification
Classification Rule-based Hierarchi-
cal classification
SVM Supervised classification
By: Pooja Shah and Dr Tanish Zaveri
Pooja Shah is an assistant professor in the computer engineering 
department at the Institute of Technology, Nirma University.
Dr Zaveri is a professor in the electronics and communication 
department at the Institute of Technology, Nirma University.

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 93
For U & Me
Overview
IoT allows different objects to be sensed or controlled remotely across the existing network 
infrastructure. It also helps to integrate objects from the physical world with computer-
based systems and, hence, results in improved accuracy, efficiency and economic benefits, 
as well as reduced human intervention in their operation.
H
urrying for a party, we may forget to switch off the fans 
and lights at home. And remember that lapse only half 
way through the party. Returning home to switch off the 
fans and lights is simply not an option. Wouldn’t it be useful if 
we could switch off the gadgets and lights at home even when 
away? What if we could switch on our air conditioners even 
before entering our homes so that we don’t have to wait for the 
room to become cooler? Around 20 years ago, this would have 
just been a pipe dream but, today, this is a reality because of 
IoT or the Internet of Things, which amalgamates software with 
different physical hardware devices.
Wikipedia defines IoT as the internetworking of 
physical devices (also called smart devices and connected 
devices), vehicles, buildings and anything else embedded 
with electronics,  sensors, actuators, software and network 
connectivity, which further enables these objects to collect 
and exchange data. In simple words, the Internet of Things 
refers to the vast world of different interconnected devices 
that have embedded sensors, which are capable of providing 
data and also being controlled through the Internet. 
So now, even when not at home, we can switch off the 
fans and lights of our rooms using the Internet. Other common 
examples include different home automation devices, like 
remotely controllable lighting fixtures and thermostats. Then 
there are traffic sensors, water quality meters, smart electric 
grids and components that track manufactured goods, all of 
which work with the help of IoT. 
The core concept of the Internet of Things became popular 
in 1999, through the Auto-ID Centre at MIT in the US. Since 
then, there has been rapid growth in the IoT space, with the 
emergence of a number of competing standards, projects, tools, 
frameworks, policies and organisations, which work towards 
defining how different connected devices communicate in the 
current era. Different open source tools and open standards are 
important and will continue to be so in the future, in order to 
ensure that all these devices are able to interconnect properly. 
These open source tools will also be responsible for the back-
end tasks of processing the large volumes of Big Data that all 
of these devices will generate in the future.
IoT allows different objects to be sensed or controlled 
remotely across the existing network infrastructure. It also 
helps in creating different opportunities for objects in the 
physical world to directly integrate with computer-based 
systems, resulting in improved accuracy, efficiency and 
economic benefits as well as reduced human intervention. 
According to the estimates of several experts, IoT will 
consist of around 30 billion objects by 2020. It is expected 
to offer highly advanced connectivity to different devices, 
systems and services that will actually go beyond machine-
to-machine (M2M) communication, covering a variety of 
domains, protocols and applications. The interconnection of 
such embedded devices is expected to usher in automation 
ubiquitously, and also enable various advanced applications 
like smart grids to expand to areas such as smart cities.

94 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
For U & Me Overview
The challenges of IoT
Though IoT usage is growing in different fields, there are a 
few challenges that require our attention and action so that it 
can be efficiently leveraged in areas where it is not yet being 
used. Let’s have a look at some of these challenges.
Data storage and analytics: One of the challenges for 
developers of IoT applications is to clean, process and then 
interpret the large amounts of data gathered by different 
sensors. The proposed solution for this is to use wireless 
sensor networks. These networks share all the data that is 
gathered by sensor nodes, which is then sent to a distributed 
system for analytics. Another challenge is the storage of such 
large volumes of data. 
Platform fragmentation: IoT also suffers from platform 
fragmentation (the inability to support a large number 
of platforms) and lack of common technical standards. 
Currently, a wide variety of IoT devices (in terms of both 
hardware and the differences in the software running on them) 
makes the task of developing different applications that work 
consistently across different inconsistent technical systems, 
difficult. Customers may be a bit hesitant to bet their IoT 
future on proprietary software or different hardware devices 
that use proprietary protocols in the fear that these may 
become obsolete or be difficult to customise.
Privacy, autonomy and control: Although IoT 
has immense potential to empower citizens by making 
governments transparent and by broadening information 
access, there are also serious threats to a citizen’s privacy 
and the scope for political manipulation by the state. Such 
concerns  have led many to conclude that different Big Data 
infrastructures like the kind required for the Internet of Things 
and for data mining are incompatible with privacy.
Security: There have been many concerns raised that 
IoT is being developed rapidly without much thought being 
given to the profound security challenges associated with it 
and the different regulatory changes that might be necessary. 
When we talk of security concerns related to IoT, we refer to 
securing servers and workstations. The common measures 
like firewalling or security updates are unsuitable for much 
smaller IoT devices.
Design: The design and management of IoT must be 
sustainable and secure. The design of IoT devices must factor 
in uncertain futures with respect to their management, without 
risking physical failure. We cannot consider IoT devices to be 
successful without giving due consideration to the interface’s 
usability as well as the technology. The interfaces need to be 
not just user friendly but also better integrated. 
Complexity and unclear value propositions: According 
to the feedback of several users, IoT solutions are either 
too complex or lack a clear use case for different end users. 
Experts also say that the IoT industry is currently heavily 
focused on gadgets, and is not making those gadgets relevant 
to particular business verticals. There are many who are just 
not able to pinpoint what value IoT offers them.
Traditional governance structures: There is a clash 
between IoT and the companies’ traditional governance 
structures, as IoT still presents both uncertainties and the 
lack of historical precedence. Definite processes are needed 
to capture the IoT opportunity. This will help to improve the 
organisational design processes and to test the new innovation 
management practices. 
Role of open source in handling the challenges 
and other aspects of IoT
The impact of IoT will be felt across a wide range of 
industries and applications, including agriculture, medical, 
manufacturing, electronics, consumer, transportation 
and energy. Just like the Internet, the emerging IoT will 
also rely upon and promote the adoption of different 
open source technologies and standards, as without the 
adoption of open standards and protocols, our devices 
may not be able to communicate with one another. While 
many of the IoT devices ultimately connect back to the 
Internet, the different methods they use to communicate 
with one another and with the local control hubs are 
Figure 1: Characteristics of IoT (Image source: googleimages.com)
Programmability
Interconnection
Characteristics of IoT
Ubiquity
Unique Identity
Internet of 
Things
Self-
Configurability
Interoperable
Interaction
Sensing &
Actuation
Internet 
connection
Figure 2: IoT node types and the data paths (Image source: googleimages.com)
IoT 
End Points
IoT 
Infrastructure
Internet 
Infrastructure
Cloud/Data 
Center
Analytics
Management
Provisioning
Storage
End-User 
Applications
Client 
Devices
NEXT
PREV
Sensors
Actuators
Aggregators
IoT Routers 
& Gateways
LAN/Edge 
Routers

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 95
For U & Me
Overview
often proprietary and even poorly documented. There 
are possibilities that without a common foundation for 
communication, we may be locked into just a single vendor 
for all of our devices, and worse, we may be left stranded 
with a pile of different non-functional hardware if the 
company which makes our devices goes defunct or decides 
to no longer support our devices. 
There is no doubt that open source dominates large swaths 
of the intelligent networking and cloud platform software. 
And for that to translate into IoT dominance, developers will 
have to fill all possible gaps and implement technologies 
which are essential for IoT. Let’s have a look at the role 
of open source in IoT and how it can help in handling the 
different challenges.
1. We are all aware that when we use different open source 
IoT frameworks,  we spend no money since they are free 
for use. With costs not a barrier, everyone will implement 
IoT without any hesitation.
2. If we decide to adopt an open source IoT framework, 
we are not only drawing on the skills of the developers 
working on this but the whole open source community. 
Additionally, this wider support base often leads to 
developers getting inspired to build newer applications, 
which they might not have dreamt of when working in a 
closed, proprietary environment.
3. The success of the IoT market greatly lies in the 
connectivity of devices, which more often than not, 
share different hardware and operating systems. This is 
a serious obstacle to the very connectivity we are aiming 
for. If open source APIs are used for IoT, then we can get 
rid of this obstacle. This is because open source APIs offer 
a uniform gate for different software, hardware and the 
systems to communicate with one another.
4. If one chooses an open source IoT framework, then 
developers will be able to build different products, 
which will be interoperable across different OSs such as 
Android, Windows, iOS and Linux.
5. An open source IoT framework injects the software 
development life cycle with innovation and agility, which 
different proprietary models fail to match, since it offers a 
wide range of libraries, SDKs and open source hardware 
like Raspberry Pi and Arduino. With the help of an open 
source IoT framework, developers ensure that companies 
remain on the cutting-edge of  technology by using 
different open sourced tools to customise IoT platforms to 
suit their needs. 
6. If we look at the privacy challenge presented by IoT, 
open source software can protect individuals’ data by 
implementing really strong encryption for the use of 
the general public (SSH, SSL, PGP, etc), and hence 
supply the building blocks for mobile security and the 
protection of data.
7. The history of open source software and security has 
been a roller coaster ride. After long years of debate, 
IT professionals finally began to appreciate the ‘many 
eyes’ approach of open source software communities, 
when it comes to detecting and addressing the security 
risks. The low defect rate of open source software 
code has been proved by independent studies such as 
Coverity Scans.
8. Huge amounts of data are produced by different 
hardware sensors integrated with IoT, and it becomes 
quite a challenge to handle this data and process it. This 
data does not just require a different scale of storage 
and processing, but it also requires new techniques 
like machine learning, artificial intelligence and data 
mining. These allow us to find patterns in the data that 
would not be obvious to different traditional analytics 
methods. Different open source Big Data tools make 
such analysis possible.
Security of IoT
 According to a recent IOActive IoT security survey,  less than 
10 per cent of all IoT devices have adequate security. The 
most daunting threat to IoT is the ability of different hackers to 
Figure 3: IoT open source - heat map (Image source: googleimages.com)
Figure 4: Threats to IoT (Image source: googleimages.com)

96 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
For U & Me Overview
infiltrate and then control a network of devices. Try to recollect 
what happened last year when different hackers breached the 
Uconnect system of Jeep Cherokee, and controlled everything, 
right from the car’s air conditioning system to its accelerator. 
If we have a perfect match between IoT and open source, such 
threats can be limited to a great extent. 
 
In order to ensure adequate levels of security before we 
embark on our IoT journey, we must define our security 
guidelines to cover cross-authentication-methods 
between devices and servers communicating with these 
devices as well as proactive malignant code detection. 
However, such security risks are unfortunately made 
worse by the often opaque security vulnerabilities 
within the open source software. It is essential that we 
give our developers easily accessible open source usage 
and vulnerability information continuously throughout 
our software development life cycles so that they can 
continuously keep a vulnerability check.
 
Almost every device that is capable of connecting to a 
network runs at least a primitive operating system (along 
with the code) which makes it function. If we have an 
open source code base for this, then it allows the security 
of the device to be inspected, tested and when required, 
easily patched to help keep the intruders out. Different 
secure operating systems, such as the Linux kernel, can be 
optimised for the embedded devices to help keep data as 
well as devices safe.
Applications of IoT
1. IoT helps in energy management by integrating the 
sensing and actuation systems connected to the Internet.
2. The IoT intelligent systems help in the rapid manufacture 
of new products, dynamically responding to different 
product demands. They enable the real-time optimisation 
of the manufacturing and supply chain networks, by 
networking sensors, machinery and the control systems.
3. IoT typically makes use of sensors to assist in  
environmental protection by monitoring air or water 
quality, soil or atmospheric conditions, and can even 
include different areas like monitoring the movement of 
wildlife as well as their habitat.
4. IoT devices can also be used to monitor and control the 
electrical, mechanical and electronic systems used in 
various types of buildings.
5. IoT is capable of monitoring and controlling infrastructure 
like railway tracks, bridges, on- and offshore wind farms, etc.
6. IoT can also be used to enable emergency notification 
systems and remote health monitoring. Health monitoring 
devices can range from heart rate and blood pressure 
monitors to other advanced devices capable of monitoring 
specialised implants.
7. IoT can assist us in integrating communications, controls 
and information processing across various transportation 
systems as well.
By: Vivek Ratan 
The author is a B. Tech in electronics and instrumentation 
engineering. He is currently employed as an automation 
test engineer at Infosys, Pune. He can be reached at 
ratanvivek14@gmail.com for any suggestions or queries.
8. A large number of IoT devices such as wearables, 
connected cars, residences, entertainment and smart 
homes are being developed for consumer use as well.
9. The IoT system is also very useful in reaching out to 
targeted sections of a population in order to convey 
a message that’s important for them instead of using 
various older methods such as newspapers. 
[1] http://www.wikipedia.org/
[2]  http://www.guru99.com/
[3]  http://linuxpundit.com/
References
Figure 5: Growth in human population and IoT connected devices (Data source: Cisco)
Figure 6: Quick facts about IoT (Image source: googleimages.com)


98 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
For U & Me Overview
The Internet of Things generates fast streams of useful data. The challenge 
before enterprises is to store the vast amounts of data and to make the best 
use of it. This is where Big Data plays an important role.
A
n increasing number of gadgets now use smart 
technologies to generate data through embedded 
sensors. A car with smart apps installed in it, a smart 
home device that monitors the temperature indoors, a fitness 
tracker that sends the steps of a workout routine to your phone’s 
app—all these are examples of the Internet of Things (IoT). 
These devices are connected to the Internet. It is estimated that 
by 2020, there will be 24 billion IoT devices across the world, 
which would naturally result in the generation of massive 
volumes of data. The digital universe is set to reach 40 zetta 
bytes by 2020. So, IoT delivers the information while Big Data 
acts on it to derive insights that will render these devices the 
precursors of a new technological age.
What is IoT?
IoT (Internet of Things) is a network of interconnected 
devices such as computers, cars, smartphones, kitchen 
appliances, heart monitors, etc. As technology advances, even 
gadgets with the most basic functions like a watch, heart 
pacemakers, remote controls, etc, will have embedded sensors 
capable of collecting and exchanging data over the Internet. 
These can be controlled by a remote device. The sensors and 
chips generally gather data but don’t process it. They send 
it to another place for analysis. Data on the performance 
of smart gadgets and customer usage patterns is generally 
gathered and analysed.
Components of IoT
IoT ecosystem: The IoT ecosystem includes all the elements 
such as a dashboard, remote, gateways, the network, security 
and storage, which allow devices to be connected to their 
users—businesses, government and consumers.
Entity: These are the users such as businesses, 
government and consumers, who use the devices and generate 
The Synergy between Big Data 
and the Internet of Things

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 99
For U & Me
Overview
the data. They comprise the group that can potentially benefit 
from the analysis of the data.
Physical layer: This layer consists of the physical hardware 
of the IoT ecosystem. This includes the devices, embedded 
sensors, networking gear, physical gateways/switches, etc.
Network layer: This layer is mainly responsible for 
transferring the data generated and collected at the physical 
layer, to other devices.
Application layer: This layer is mainly intangible as it 
holds the protocols used for sharing data across heterogeneous 
devices. It also consists of the interface that helps different 
devices identify and communicate with each other efficiently. 
Remote: The remote allows entities to control and connect 
to their IoT devices through a dashboard such as an app. 
Examples of remotes are PCs, smartwatches, connected TVs, 
tablets, smartphones, etc.
Dashboard: The dashboard is included in the remote, where 
it allows the entities to control and manage the IoT ecosystem.
What is Big Data?
Big Data refers to the large volume of both structured and 
unstructured data. Big Data can be mined for insights and 
information. Data these days runs into exabytes. There are ‘5 
Vs’ of Big Data.
Volume: This refers to the amount of data that is generated 
all over the world. Ninety per cent of the world’s data has 
been generated in the last two years.
Velocity: This is the speed at which the data is generated 
as well as the speed at which it travels. For example, the New 
York Stock Exchange creates over 1TB of data daily.
Variety: This refers to the different forms of data generated 
including structured, unstructured and semi-structured data. 
Eighty per cent of the world’s data is unstructured.
Veracity: This refers to the accuracy and reliability 
of the data. Uncertainty in data due to inconsistency and 
incompleteness leads to losses to companies that can add up 
to millions of dollars.
Value: Value signifies the yield and advantage that the 
data provides to businesses in the form of insights provided 
by analysing and mining the massive data.
The intersection of Big Data and IoT
As there are multitudinous sensors and smart devices all over 
the globe, IoT triggers an inundation of data or Big Data. 
Only Big Data technologies and frameworks can handle 
such colossal data volumes that are streaming varied types 
of information. The more the IoT grows quantitatively, the 
more Big Data techniques will be required. Within this space, 
organisations need to shift focus to the rich data, which is 
easily accessible in real-time. Such data  affects the customer 
base and can generate meaningful conclusions though mining.  
Data from sensors should be processed to find patterns and 
insights in real-time to advance business goals. Existing Big 
Data technologies can effectively harness the incoming sensor 
data, store it and later analyse it efficiently using artificial 
intelligence. Effectively, for IoT processing, Big Data is the 
fuel and artificial intelligence is the brain. 
Benefits from the intersection of IoT and Big Data
In the present day, over half of all IoT activity is in the 
fields of transport, manufacturing, user applications, smart 
cities, etc. IoT will create new business opportunities in the 
following ways.
New business models: Companies could create value 
streams for clients, speed time to market and react quickly to 
client demands.
Real-time information on mission-critical systems: 
Companies can collect data about products and processes 
quickly, and improve market agility.
Diversification of revenue streams: Enterprises can 
monetise more services in addition to the conventional 
business services.
Global visibility: Enterprises can have better insights into 
their business, like tracing the path of a component from one 
extreme of a supply chain to another, which reduces the cost 
of business in distant localities.
Efficient, intelligent operations: Information from 
independent endpoints can be accessed by companies to make 
impromptu decisions on sales, logistics, etc. 
Data storage solutions: PaaS
As the continuous streams of machine data from IoT require 
huge physical storage, organisations are migrating to PaaS 
(Platform-as-a-Service). This eliminates the need for companies 
to have their own storage infrastructure, which would need 
continuous expansion to accommodate the increasing data. 
PaaS provides easy scalability, compliance, flexibility and 
a sophisticated architecture that is specially customised to 
handle IoT data. Moreover, one can opt for private, public or 
hybrid cloud platforms. Private platforms cater to only a single 
Figure 1: The IoT ecosystem
Analytics 
The Internet of things Ecosystem
Data Storage
Remote
Command/RFI
Gateway
Internet Network
IoT Devices
Data
Data
Analysis
Analysis

100 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
For U & Me Overview
organisation, so the data doesn’t share a physical border with 
external data. Public platforms cater to many organisations and 
have logical separation of storage space on a single physical 
storage entity. Hybrid platforms are also shared like public 
platforms, but the sharing parties usually belong to the same 
field of business, which allows them to avail the advantages of 
a customised architecture that benefits their domain.
Big Data technologies of IoT
The first phase consists of receiving events from IoT 
connected devices. Wi-Fi, Bluetooth, etc, can be used to 
connect the devices to receivers. The messages notifying 
users about events must be sent via an efficient protocol to 
a broker. MQTT (Message Queue Telemetry Transport) is a 
popular protocol for transfers among the agents. Mosquitto is 
a widely used version of a MQTT broker.
In the second phase, upon receiving data, Hadoop and 
Hive are commonly used to store the data. Apache CouchDB 
is a NoSQL database which is highly suited for IoT due 
to its low latency and high throughput. The schema-less 
database helps with the varying machine data. Apache Storm 
is preferred for real-time processing and Apache Kafka for 
intermediate message brokering.
General architecture of IoT Big Data
Context data layer: This collects the external non-IoT data 
used for IoT data processing later on as extra context/meta 
data, e.g., start/stop data feeds.
IoT service layer: This handles the interactions between 
the devices to collect data from IoT devices and also send 
control commands to them. Bi-directional communication is 
handled by this layer.
Data/protocol mediator: This is responsible for keeping 
data in harmonised data entities before it gets published 
by the data and control layer. This layer is standalone and 
ensures uniformity.
Data/control broker: This allows third party applications 
to fire a query or API for accessing harmonised data entities. 
It also controls requests from the application layer.
Peer API access management: This interacts with peer 
enterprises to publish relevant context data.
Developer API access management: This controls the 
permissions for harmonised data entities (both context 
and IoT) and helps control services provided to third 
party applications. Access control, authentication and 
authorisation are managed here. Privacy and security are its 
main responsibilities.
IoT/Big Data store: This provides short to medium 
data storage capabilities under the control of the data and 
control broker. Insights are to be found amongst the ad 
hoc data relations. Apache Hadoop, Apache Cassandra, 
MongoDB, etc, are commonly used. Neo4J and Tital are 
graph databases that are increasingly being used for social 
media related data.
IoT/Big Data processing: Analytics and business 
intelligence procedures are carried out here. Analytics 
includes conventional methods of exploring statistical 
relationships and the use of analytical engines to produce 
output though a predefined process. Intelligence signifies 
usage of artificial intelligence and machine learning to create 
adaptable algorithms for a match between predicted and 
desired outcomes. Apache Spark, Apache TinkerPop3, Apache 
Mahout and TensorFlow are widely used.
Use cases of Big Data and IoT
Fleet management: Many transportation companies carry 
sensors that monitor drivers’ behaviour and a vehicle’s 
location. Good driving skills and on-road safe behaviour 
get rewarded by insurance companies. IoT gives telematics 
an advantage by providing detailed machine log data of all 
the mechanical and electrical components. UPS, the global 
logistics firm, widely uses this technology to monitor the 
speed, mileage, break stops, fuel consumption, engine usage, 
etc, of the vehicles in its fleet. The company hence reduces 
harmful emissions and fuel consumption.
Healthcare: Wearable fitness tracker and healthcare apps 
help people monitor their health. Data from these devices can 
be used to track parameters like blood pressure, sugar levels, 
etc, as well as to get a prognosis for possible vulnerability to 
diseases. The Preventice company integrates apps, mobiles, 
laptops, tablets, the cloud, etc, for remote patient monitoring. 
The firm allows the customers’ doctors to monitor their health 
online to avoid regular check-ups. Proteus is a startup which 
has sensors in the pills it makes, which can be used to check if 
patients are following their prescriptions.
Agriculture: John Deere is a multinational company 
selling farm equipment. It monitors various parameters like 
the soil moisture levels, etc. The data goes to a centralised 
managing platform where, based on the moisture levels, 
the farmers can be alerted when to irrigate. This prevents 
unnecessary irrigation and avoids the concentration of water 
resources in particular areas.
Figure 2: Architecture of IoT Big Data

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 101
For U & Me
Overview
Hurdles in the widespread usage of 
Big Data and IoT
Standards: For efficient working of the IoT, there should be a 
predefined framework followed by devices and applications 
to exchange data safely over wireless or wired networks. 
OneM2M is an organisation which publishes the preferred 
standards set by the major technology giants. Sources in the 
firm insist that there should be interoperability among varied 
industries such that a common platform connects smart 
meters, cars, watches, pacemakers, etc.
Security and privacy: Security in some sensitive applications 
like a biological sensor recording the human vital signs should 
be protected against breach of privacy. National infrastructure 
related data is critical for the country’s security and should 
have appropriate  safeguards against hackers. Smart home lock 
systems, industrial security sensors, etc, all need protection 
against malicious users who can trespass illegally. IoT is 
advantageous since it can be operated over the Internet, but it is 
very risky on account of that very reason. The Internet can be 
breached by intruders and the devices can be wrongfully used.
Network and data centre infrastructure: Data centres and 
infrastructure will be under duress due to the incoming data 
deluge. The flows can be in bursts or continuous, primarily 
between the applications and sensors.
Analytics tools: IoT management is complicated and to 
build analytics for insights is no easy task. Various platforms 
use different languages and professionals have to be trained to 
deal with each of them.
By: Preet Gandhi
The author is an avid Big Data and data science enthusiast. 
She can be reached at gandhipreet1995@gmail.com.
[1] https://www.sas.com/en_us/insights/articles/big-data/
big-data-and-IoT-two-sides-of-the-same-coin.html
[2]  http://www.huffingtonpost.com/philip-kushmaro/the-
IoT-and-big-data-maki_b_12116608.html
[3]  http://www.information-age.com/10-predictions-
internet-things-big-data-2017-123463379/
[4]  http://www.wikipedia.com
References
Skills: IoT and Big Data are multi-disciplinary, and 
professionals require a working knowledge of both fields. 
As the topics are relatively new, old-school technological 
workers need to be trained and acquainted with the new 
technologies. Business analysts are required to frame the 
questions that will best extract the data and present the 
outcomes to the clients. Data scientists are required to use 
analytical tools to derive insights and do the technical work. 
Big Data and IoT complement each other to bring out 
the advantages of each. The technological world has realised 
their significance and the Big Data + IoT industry is set to 
become a multi-billion dollar business, with researchers and 
IT firms starting to realise the potential behind the hype. This 
alliance is the future of technology and will fundamentally 
change the world around us. 

102 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
For U & Me Let’s Try
For Linux newbies and other typical users, here is the second set of tips on 
using Vi/Vim editor efficiently and productively. 
T
his is a continuation of my previous article titled, ‘A 
Few Tips on Vi/Vim Editor for Linux Newbies’ which 
can be accessed at http://opensourceforu.com/2017/01/
tips-vivim-editor-linux-newbies/. I have compiled a few more 
Vi editor tips that are very simple but help to increase 
productivity tremendously.
Going to any line
In a large-sized file, going to a particular line 
directly is extremely useful and saves a lot 
of time. This can be done by going to the 
command mode and typing the following:
:50
…assuming that 50 is the line at which you want the 
cursor to be positioned. The other way is to type:
50G
…in the command mode to get the same result.
Typing just G in the command mode takes the cursor to 
the last line of the file and typing 1G takes the cursor to the 
beginning of the file.
Incrementing or decrementing a number
You can increment or decrement a number easily. Go to the 
command mode, position the cursor below the number and type 
the following:
Ctrl-a
This increments the number. Similarly, you can type the following 
to decrement the number on which the cursor is positioned:
Ctrl-x
Changing the case of letters
Without the shortcuts, changing the case of letters, words and 
sentences whenever required is a tedious procedure. With the 
shortcuts given below, it can be done very easily.
To toggle the case of the character below which the cursor 
is positioned, type  ~
To change the case of the current line to upper case, type gUU
To change the case of the current line to lower case, type guu
To toggle the case of the current line, type g~~
To toggle the case of all characters from the cursor position 
to the end of the line, type g~$
Sorting within Vi
Sorting within Vi editor can be achieved without using the external 
sort command by typing the following in the command mode:
:sort
The above command is to sort the text.
:sort u
The above command can be used to sort lines and 
remove duplicate lines.
Executing a filter command
You can execute a filter command on a part of the current file from 
within the Vi editor and replace the portion with the output of the 
command. Any command that reads from a standard input and 
sends the output to a standard output can be used as a filter within 
Vi. To illustrate this, we use the sort command. Type the following 
in the command mode of the Vi editor:
:1,$!sort
This sorts the file from the first line to the last line and 
replaces these lines with the sorted output. (Just a reminder: 
The ‘!’ symbol is used within the command line of the Vi editor 
to execute an external program from within a Vi editor.)
The -u option with sort will keep only the unique lines and 
remove the duplicate lines.
:1,$!sort -u
The line number 1 and the $ symbol in the above command 
can be replaced with any portion of the file with the numbers of 
the starting line and ending line of the particular portion. The 
portion selected for input will be replaced by the output of the 
sort command. To sort the lines starting from the contents of 
line number 5 to 15, give the following command:
:5,15! Sort
Using tr within Vi
The following command will convert all the letters in the line 
numbers 10 to 20 to upper case:
:10,20 ! tr a-z A-Z
A Few More Tips on  
Vi/Vim Editor for Linux Newbies 

www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 103
For U & Me
Let’s Try
Writing a portion of a file being edited
The command to write a portion of the current file being 
edited to a new file is as follows:
:20,50 w > newfile.txt
As a result, the lines from 20 to 50 are written in a new 
file named newfile.txt. The above facility of processing parts 
of the text and substituting the original content with the 
output makes the Vi editor very powerful.
Inserting the output of a command executed 
within the Vi editor
Most users are familiar with the method to execute a shell 
command within the Vi editor. For example:
:! ls
Less known is the fact that you can insert the output of the 
command given within the Vi editor by placing a ‘.’ (period) 
before the exclamation mark. For example, the following 
command will insert the current date into the file being edited, 
which can be used for documentation.
:.! date
Cursor movements
Vi editor has powerful cursor movement commands which, if 
mastered, can make editing faster.
H  The cursor is positioned at the first line of the screen
M   The cursor is positioned at the middle line of the screen
L   The cursor is positioned at the last line of the screen
Scrolling through a file
The following commands can be used to scroll through a file.
Ctrl-f      Scroll down by one screen
Ctrl-b     Scroll up by one screen
Ctrl-u     Scroll up by half a screen
Ctlr-d     Scroll down by half a screen
zz            Scroll the screen so that the current line appears at  
 
 
the middle of the screen.
The last one, zz, is very useful for viewing the block of 
code associated with the current line.
Editing a file opened without sudo
Let’s assume that you are editing a file which requires root 
access and, as a result, you are unable to save it as you 
have not opened Vi editor in the sudo mode. So instead 
of saving the file by taking many steps, including saving 
it in a temporary file and copying it later, you can save it 
straight away by using a combination of the tee and sudo 
commands, as follows:
:w !sudo tee %1
You can refer to the link http://www.geekyboy.com/
archives/629 for details on how the above command works. 
Powerful delete commands
Apart from the commonly used commands for deleting, the 
ones I found very useful are the following.
di(      Deletes all characters within the parentheses
di”      Deletes all characters within the quotes
Shortcut to save and quit
Generally, we type :wq in the command mode to save the 
file and go to the command prompt. A shortcut for the same 
is as follows:
:x
Recovering a file
Lastly, the following command will help you to recover a file 
after a crash, from the swap file of the file being edited:
$vi -r filename
Practising these Vi tips will help you to increase your 
efficiency, and the side effect could be that you postpone the 
onset of RSI (repetitive stress injury)! 
Figure 1: Vi editor before sort
Figure 2: Vi editor after sort
By: S. Sathyanarayanan
The author works as the information scientist in the Sri Sathya 
Sai Institute of Higher Learning, Brindavan Campus, Bengaluru, 
and also heads the computer centre of the campus. He has 
more than 25 years of experience in systems administration 
and in teaching IT courses. He is an enthusiastic promoter of 
FOSS and can be reached at sathyanarayanan_s@yahoo.com/
ssathyanarayanan@sssihl.edu.in.

TIPS
TRICKS
&
The process tree
pstree is a small tool that prints the tree of the 
processes that are running. It gives you a clear picture of 
the processes on the system. Basically, the output of pstree 
is the same as the command ps but with a nice view of the 
tree with its branches.
While debugging, it is often useful to know which is the 
parent of a given process. This can be done with ps but you 
need to keep track of ppid. With the tree of processes, it is 
much easier to find this out.
pstree starts with the first process, that is init with PID 
1, unless otherwise specified. It has very good options to 
sort and show PIDs, along with names, etc.
rahul@rahul-Aspire-4736Z:~$ pstree
init─┬─NetworkManager─┬─dnsmasq
     │                ├─pppd
     │                └─3*[{NetworkManager}]
     ├─accounts-daemon───2*[{accounts-daemon}]
     ├─acpid
     ├─avahi-daemon───avahi-daemon
     ├─bluetoothd
     ├─colord───2*[{colord}]
     ├─cron
     ├─cups-browsed
     ├─cupsd
     ├─dbus-daemon
     ├─6*[getty]
     ├─gnome-keyring-d───5*[{gnome-keyring-d}]
     ├─lightdm─┬─Xorg───2*[{Xorg}]
Output snipped
     ├─upstart-file-br
     ├─upstart-socket-
     ├─upstart-udev-br
     └─whoopsie───2*[{whoopsie}]
For more information, do check out the man page. 
—Rahul Bedarkar,
 rahulbedarkar89@gmail.com
Auto-correction of typos
Typing on the command line isn’t easy. First, it takes 
a lot of time to learn how all the commands work. Then, 
even after that, you need to be very precise with your file 
and directory names, otherwise you’ll have to keep trying 
again and again.
But there’s a way out. Bash has a built-in command 
called shopt that lets you set various command-line options. 
For example, running the following command: 
#shopt -s cdspell
…enables automatic typo correction for directory 
names, so that when you type the following:
#cd /hom/hudzila
…you will get to the nearest match /home/hudzila if 
hudzila is not present.
You can also use the command given below: 
#shopt -s nocaseglob 
…so that when you type part of a file name and press 
Tab it will auto-complete. 
—Sachith H.M., 
sachith@smartbrainsinfotech.com
Download files directly from Web pages
Given below is a command for downloading an mp3 
file directly from a Web page:
wget -r -l1 -H -t1 -nd -N -np -A.mp3 -erobots=off [url of 
website]
The complete description of this command is as follows:
-r     
Recursive
-l1        Maximum recursion depth (1= use only this  
 
 
 
directory)
-H   
Span hosts (visit other hosts in the recursion)
-t1   
Number of retries
104 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com

Share Your Linux Recipes!
The joy of using Linux is in finding ways to get around 
problems—take them head on, defeat them! We invite you 
to share your tips and tricks with us for publication in OSFY 
so that they can reach a wider audience. Your tips could be 
related to administration, programming, troubleshooting or 
general tweaking. Submit them at www.opensourceforu.
com. The sender of each published tip will get a T-shirt.
-nd          Don’t make new directories; put downloaded   
 
 
files in this one
-N           Turn on timestamping
-A.mp3   Download only mp3s 
-erobots=off   Execute robots.off as if it were 
a part of .wgetrc 
—Vinu K., 
kevy.vinu@gmail.com
Display shell command history with date 
and time under Linux
Here is a small tip to display the history of a command 
with the date and time of execution of the command. To 
display this, you need to define the environment variable 
as follows:
# HISTTIMEFORMAT=”%d/%m/%y %T “
…or as:
echo ‘export HISTTIMEFORMAT=”%d/%m/%y %T “’ >> ~/.bash_profile
Here, %d is the day, %m is the month, %y is the year, 
and %T is the time. 
— Munish Kumar, 
munishtotech@gmail.com
Copy a file to multiple directories in Linux
You can deploy the echo command, a pipe and xargs 
command together with the cp command, as shown below, 
to copy a file to multiple directories in Linux:
$ echo /home/remin/Videos/ /home/remin/Downloads/ | xargs -n 1 
cp -v /home/remin/test.txt
‘/home/remin/test.txt’ -> ‘/thome/remin/Videos/test.txt’
‘/home/remin/test.txt’ -> ‘/thome/remin/Downloads/test.txt’ 
— Remin Raphael, 
remin13@gmail.com
Git commands for beginners
With multiple people working on a software 
project, co-ordination sometimes becomes difficult. Git 
is a version control system (VCS) for tracking changes 
in computer files and coordinating work on these files. 
Given below are a few commands that can be commonly 
used while using this VCS.
1. Clone remote repo:
    git clone [repository-url] 
2. Refresh repo for the latest from remote repo:
     git pull 
3. List all branches:
     git branch -a
4. Switch branch:
     git checkout [branch-name]
5. Check the status for the current repository:
     git status
6. Add new files:
     git add filename
7. Browse past commit information:
     git log
Browse past commit information by using the  
 
 
one line option:
    git log --oneline
8. Check-in changes:
     git commit -m “Message to commit this file or directory” 
[directory-or-filename]
9. Compare file with past revision:
     git diff cf39cd1 filename
10. Reset current branch head (HEAD) to the 
specified state:
        git reset <paths> 
— Sandhya Bankar, 
bankarsandhya512@gmail.com
www.OpenSourceForU.com | OPEN SOURCE FOR YOU | JUNE 2017 | 105

106 | JUNE 2017 | OPEN SOURCE FOR YOU | www.OpenSourceForU.com
DVD OF THE MONTH
Secure your environment with this version of Kali Linux.
Linux for Internet 
of Things (IoT)
Ubuntu Core for 
Raspberry Pi 2 
and 3
Fedora 25 LXDE 
for ARM
KALI LINUX 
2017.1 
Kali Linux (formerly known as BackTrack) is a 
Debian-based Linux distribution aimed at advanced 
penetration testing and security auditing
JUNE 2017
CD 
Tea
m e-
mail
: cd
tea
m@
efy.i
n
Rec
omm
end
ed S
yste
m Re
quir
eme
nts: 
P4, 
1GB
 RA
M, D
VD-R
OM 
Driv
e
In c
ase 
this
 DV
D do
es n
ot w
ork 
prop
erly,
 wri
te t
o us
 at s
upp
ort@
efy.i
n fo
r a f
ree 
repl
ace
men
t.
What is a live DVD?
A live CD/DVD or live disk contains a bootable 
operating system, the core program of any computer, 
which is designed to run all your programs and manage 
all your hardware and software. Live CDs/DVDs have 
the ability to run a complete, modern OS on a computer 
even without secondary storage, such as a hard disk 
drive. The CD/DVD directly runs the OS and other 
applications from the DVD drive itself. Thus, a live disk 
allows you to try the OS before you install it, without 
erasing or installing anything on your current system. 
Such disks are used to demonstrate features or try 
out a release. They are also used for testing hardware 
functionality, before actual installation. To run a live 
DVD, you need to boot your computer using the disk 
in the ROM drive.  You should configure your BIOS to 
use legacy mode. To know how to set a boot device in 
BIOS, please refer to the hardware documentation for 
your computer/laptop.
OSFY DVD
Kali Linux 2017.1 (64-bit live)
Kali Linux (formerly known as BackTrack) is a Debian-based 
Linux distribution aimed at advanced penetration testing and 
security auditing. Kali contains several hundred tools, which 
are geared towards various information security tasks, such as 
penetration testing, security research, computer forensics and 
reverse engineering. The latest release comes with updated 
packages, and an updated kernel that provides more and better 
hardware support. You can find complete documentation and the 
usage guide for this live DVD at http://docs.kali.org/.
Note: User name for the live DVD: root, password: toor
Linux for Internet of Things (IoT)
This month, since the focus of the magazine is on IoT, we have 
bundled a few Linux OSs with this DVD, which can be installed on 
ARM based computers and can be used for IoT devices.  
Ubuntu Core for Raspberry Pi 2 and 3: Ubuntu Core is a tiny, 
transactional version of Ubuntu for IoT devices and large container 
deployments. It runs a new breed of super-secure, remotely 
upgradeable Linux app packages known as ‘snaps’, and it’s trusted 
by leading IoT players — ranging from chipset vendors to device 
makers and system integrators. Ubuntu Core is different from 
classic Ubuntu distributions. It is a purposely lightweight and 
transactionally updated system, with security at its heart. The image 
files are in the other_isos folder on the root of the bundled DVD.
Fedora 25 LXDE for ARM: Fedora is an easy-to-use operating 
system for laptop and desktop computers, with a complete set of 
tools for developers and makers of all kinds. The bundled image is 
for ARM-based media centres, kiosks, laptops and other ARM-
powered devices where a graphical interface is desired. It comes 
with the Lightweight X11 desktop environment. The image file is in 
the other_isos folder on the root of the bundled DVD.


Earn up to 
₹1,00,000 
per hour 
 
Curious? Mail us at 
contact@loonycorn.com 
 
 Step 1: You work with us to create a course proposal 
for a 2-10 hour course 
 
 Step 2: We pay you an advance of ₹ 5,000/hour upon 
course approval 
 
 Step 3: You build the course, we help 
 
 Step 4: We grade your work and pay according to the 
rate card below (rates per hour) 
Grade A:  ₹100,000 | B:  ₹50,000 | C:   ₹25,000  | F:  ₹5,000     

