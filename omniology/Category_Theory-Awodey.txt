Category Theory
STEVE AWODEY
Carnegie Mellon University
CLARENDON PRESS
• OXFORD
2006

3
Great Clarendon Street, Oxford OX2 6DP
Oxford University Press is a department of the University of Oxford.
It furthers the University’s objective of excellence in research, scholarship,
and education by publishing worldwide in
Oxford New York
Auckland Cape Town Dar es Salaam Hong Kong Karachi
Kuala Lumpur Madrid Melbourne Mexico City Nairobi
New Delhi Shanghai Taipei Toronto
With oﬃces in
Argentina Austria Brazil Chile Czech Republic France Greece
Guatemala Hungary Italy Japan Poland Portugal Singapore
South Korea Switzerland Thailand Turkey Ukraine Vietnam
Oxford is a registered trade mark of Oxford University Press
in the UK and in certain other countries
Published in the United States
by Oxford University Press Inc., New York
c
⃝Steve Awodey, 2006
The moral rights of the author have been asserted
Database right Oxford University Press (maker)
First published 2006
All rights reserved. No part of this publication may be reproduced,
stored in a retrieval system, or transmitted, in any form or by any means,
without the prior permission in writing of Oxford University Press,
or as expressly permitted by law, or under terms agreed with the appropriate
reprographics rights organization. Enquiries concerning reproduction
outside the scope of the above should be sent to the Rights Department,
Oxford University Press, at the address above
You must not circulate this book in any other binding or cover
and you must impose the same condition on any acquirer
British Library Cataloguing in Publication Data
Data available
Library of Congress Cataloging in Publication Data
Data available
Typeset by Newgen Imaging Systems (P) Ltd., Chennai, India
Printed in Great Britain
on acid-free paper by
Biddles Ltd., King’s Lynn, Norfolk
ISBN 0–19–856861–4
978–0–19–856861–2
1 3 5 7 9 10 8 6 4 2

in memoriam
Saunders Mac Lane

PREFACE
Why write a new textbook on Category Theory, when we already have Mac
Lane’s Categories for the Working Mathematician? Simply put, because Mac
Lane’s book is for the working (and aspiring) mathematician. What is needed
now, after 30 years of spreading into various other disciplines and places in the
curriculum, is a book for everyone else.
This book has grown from my courses on Category Theory at Carnegie Mellon
University over the last 10 years. In that time, I have given numerous lecture
courses and advanced seminars to undergraduate and graduate students in Com-
puter Science, Mathematics, and Logic. The lecture course based on the material
in this book consists of two, 90-minute lectures a week for 15 weeks. The germ
of these lectures was my own graduate student notes from a course on Category
Theory given by Mac Lane at the University of Chicago. In teaching my own
course, I soon discovered that the mixed group of students at Carnegie Mellon
had very diﬀerent needs than the Mathematics graduate students at Chicago and
my search for a suitable textbook to meet these needs revealed a serious gap in
the literature. My lecture notes evolved over a time to ﬁll this gap, supplementing
and eventually replacing the various texts I tried using.
The students in my courses often have little background in Mathematics bey-
ond a course in Discrete Math and some Calculus or Linear Algebra or a course
or two in Logic. Nonetheless, eventually, as researchers in Computer Science or
Logic, many will need to be familiar with the basic notions of Category Theory,
without the beneﬁt of much further mathematical training. The Mathematics
undergraduates are in a similar boat: mathematically talented, motivated to
learn the subject by its evident relevance to their further studies, yet unable to
follow Mac Lane because they still lack the mathematical prerequisites. Most
of my students do not know what a free group is (yet), and so they are not
illuminated to learn that it is an example of an adjoint.
This, then, is intended as a text and reference book on Category Theory,
not only for students of Mathematics, but also for researchers and students in
Computer Science, Logic, Linguistics, Cognitive Science, Philosophy, and any of
the other ﬁelds that now make use of it. The challenge for me was to make the
basic deﬁnitions, theorems, and proof techniques understandable to this reader-
ship, and thus without presuming familiarity with the main (or at least original)
applications in algebra and topology. It will not do, however, to develop the
subject in a vacuum, simply skipping the examples and applications. Material
at this level of abstraction is simply incomprehensible without the applications
and examples that bring it to life.
Faced with this dilemma, I have adopted the strategy of developing a few
basic examples from scratch and in detail—namely posets and monoids—and

PREFACE
vii
then carrying them along and using them throughout the book. This has several
didactic advantages worth mentioning: both posets and monoids are themselves
special kinds of categories, which in a certain sense represent the two “dimen-
sions” (objects and arrows) that a general category has. Many phenomena
occurring in categories can best be understood as generalizations from posets
or monoids. On the other hand, the categories of posets (and monotone maps)
and monoids (and homomorphisms) provide two further, quite diﬀerent examples
of categories in which to consider various concepts. The notion of a limit,
for instance, can be considered both in a given poset and in the category of
posets.
Of course, many other examples besides posets and monoids are treated as
well. For example, the chapter on groups and categories develops the ﬁrst steps of
Group Theory up to kernels, quotient groups, and the homomorphism theorem,
as an example of equalizers and coequalizers. Here, and occasionally elsewhere
(e.g. in connection with Stone duality), I have included a bit more Mathematics
than is strictly necessary to illustrate the concepts at hand. My thinking is that
this may be the closest some students will ever get to a higher Mathematics
course, so they should beneﬁt from the labor of learning Category Theory by
reaping some of the nearby fruits.
Although the mathematical prerequisites are substantially lighter than for
Mac Lane, the standard of rigor has (I hope) not been compromised. Full proofs
of all important propositions and theorems are given, and only occasional routine
lemmas are left as exercises (and these are then usually listed as such at the
end of the chapter). The selection of material was easy. There is a standard core
that must be included: categories; functors; natural transformations; equivalence;
limits and colimits; functor categories; representables; Yoneda’s Lemma; adjoints;
and monads. That nearly ﬁlls a course. The only “optional” topic included here
is cartesian closed categories and the lambda-calculus, which is a must for com-
puter scientists, logicians, and linguists. Several other obvious further topics were
purposely not included: 2-categories, toposes (in any depth), and monoidal cat-
egories. These topics are treated in Mac Lane, which the student should be able
to read after having completed the course.
Finally, I take this opportunity to thank Wilfried Sieg for his exceptional
support of this project; Peter Johnstone and Dana Scott for helpful suggestions
and support; Andr´e Carus for advice and encouragement; Bill Lawvere for many
very useful comments on the text; and the many students in my courses who
have suggested improvements to the text, clariﬁed the content with their ques-
tions, tested all of the exercises, and caught countless errors and typos. For the
latter, I also thank the many readers who took the trouble to collect and send
helpful corrections, particularly Brighten Godfrey, Peter Gumm, Bob Lubarsky
and Dave Perkinson. Andrej Bauer and Kohei Kishida are to be thanked for
providing Figures 9.1 and 8.1, respectively. Of course, Paul Taylor’s macros for
commutative diagrams must also be acknowledged. And my dear Karin deserves
thanks for too many things to mention. Finally, I wish to record here my debt of

viii
PREFACE
gratitude to my mentor Saunders Mac Lane, not only for teaching me category
theory, and trying to teach me how to write, but also for helping me to ﬁnd my
place in Mathematics. I dedicate this book to his memory.
Steve Awodey
Pittsburgh
September 2005

CONTENTS
Preface
vi
1
Categories
1
1.1
Introduction
1
1.2
Functions of sets
3
1.3
Deﬁnition of a category
4
1.4
Examples of categories
5
1.5
Isomorphisms
11
1.6
Constructions on categories
13
1.7
Free categories
16
1.8
Foundations: large, small, and locally small
21
1.9
Exercises
23
2
Abstract structures
25
2.1
Epis and monos
25
2.2
Initial and terminal objects
28
2.3
Generalized elements
29
2.4
Sections and retractions
33
2.5
Products
34
2.6
Examples of products
36
2.7
Categories with products
41
2.8
Hom-sets
42
2.9
Exercises
45
3
Duality
47
3.1
The duality principle
47
3.2
Coproducts
49
3.3
Equalizers
54
3.4
Coequalizers
57
3.5
Exercises
63
4
Groups and categories
65
4.1
Groups in a category
65
4.2
The category of groups
68
4.3
Groups as categories
70
4.4
Finitely presented categories
73
4.5
Exercises
74
5
Limits and colimits
77
5.1
Subobjects
77
5.2
Pullbacks
80

x
CONTENTS
5.3
Properties of pullbacks
84
5.4
Limits
89
5.5
Preservation of limits
94
5.6
Colimits
95
5.7
Exercises
102
6
Exponentials
105
6.1
Exponential in a category
105
6.2
Cartesian closed categories
108
6.3
Heyting algebras
113
6.4
Equational deﬁnition
118
6.5
λ-calculus
119
6.6
Exercises
123
7
Functors and naturality
125
7.1
Category of categories
125
7.2
Representable structure
127
7.3
Stone duality
131
7.4
Naturality
133
7.5
Examples of natural transformations
135
7.6
Exponentials of categories
139
7.7
Functor categories
142
7.8
Equivalence of categories
146
7.9
Examples of equivalence
150
7.10 Exercises
155
8
Categories of diagrams
159
8.1
Set-valued functor categories
159
8.2
The Yoneda embedding
160
8.3
The Yoneda Lemma
162
8.4
Applications of the Yoneda Lemma
166
8.5
Limits in categories of diagrams
167
8.6
Colimits in categories of diagrams
168
8.7
Exponentials in categories of diagrams
172
8.8
Topoi
174
8.9
Exercises
176
9
Adjoints
179
9.1
Preliminary deﬁnition
179
9.2
Hom-set deﬁnition
183
9.3
Examples of adjoints
187
9.4
Order adjoints
191
9.5
Quantiﬁers as adjoints
193
9.6
RAPL
197
9.7
Locally cartesian closed categories
202

CONTENTS
xi
9.8
Adjoint functor theorem
210
9.9
Exercises
219
10 Monads and algebras
223
10.1 The triangle identities
223
10.2 Monads and adjoints
225
10.3 Algebras for a monad
229
10.4 Comonads and coalgebras
234
10.5 Algebras for endofunctors
236
10.6 Exercises
244
References
249
Index
251

This page intentionally left blank 

1
CATEGORIES
1.1
Introduction
What is category theory? As a ﬁrst approximation, one could say that category
theory is the mathematical study of (abstract) algebras of functions. Just as
group theory is the abstraction of the idea of a system of permutations of a set
or symmetries of a geometric object, category theory arises from the idea of a
system of functions among some objects.
A
f
- B
@
@
@
@
@
@
g ◦f
RC
g
?
We think of the composition g ◦f as a sort of “product” of the functions f
and g, and consider abstract “algebras” of the sort arising from collections of
functions. A category is just such an “algebra,” consisting of objects A, B, C, . . .
and arrows f : A →B, g : B →C, . . . , that are closed under composition
and satisfy certain conditions typical of the composition of functions. A precise
deﬁnition is given later in this chapter.
A branch of abstract algebra, category theory was invented in the tradition
of Felix Klein’s Erlanger Programm, as a way of studying and characterizing
diﬀerent kinds of mathematical structures in terms of their “admissible trans-
formations.” The general notion of a category provides a characterization of the
notion of a “structure-preserving transformation,” and thereby of a species of
structures admitting such transformations.
The historical development of the subject has been, very roughly, as follows:
1945 Eilenberg and Mac Lane’s “General theory of natural equivalences” was
the original paper, in which the theory was ﬁrst formulated.
late 1940s The main applications were originally in the ﬁelds of algebraic
topology, particularly homology theory, and abstract algebra.

2
CATEGORIES
1950s A. Grothendieck et al. began using category theory with great success in
algebraic geometry.
1960s F.W. Lawvere and others began applying categories to logic, revealing
some deep and surprising connections.
1970s Applications were already appearing in computer science, linguistics,
cognitive science, philosophy, and many other areas.
One very striking thing about the ﬁeld is that it has such wide-ranging applic-
ations. In fact, it turns out to be a kind of universal mathematical language like
set theory. As a result of these various applications, category theory also tends
to reveal certain connections between diﬀerent ﬁelds—like logic and geometry.
For example, the important notion of an adjoint functor occurs in logic as the
existential quantiﬁer and in topology as the image operation along a continuous
function. From a categorical point of view these turn out to be essentially the
same operation.
The concept of adjoint functor is in fact one of the main things that the reader
should take away from the study of this book. It is a strictly category-theoretical
notion that has turned out to be a conceptual tool of the ﬁrst magnitude—on
par with the idea of a continuous function.
In fact, just as the idea of a topological space arose in connection with con-
tinuous functions, so also the notion of a category arose in order to deﬁne that
of a functor, at least according to one of the inventors. The notion of a functor
arose—so the story goes on—in order to deﬁne natural transformations. One
might as well continue that natural transformations serve to deﬁne adjoints:
Category
Functor
Natural transformation
Adjunction
Indeed, that gives a pretty good outline of this book.
Before getting down to business, let us ask why it should be that category
theory has such far-reaching applications. Well, we said that it is the abstract
theory of functions, so the answer is simply this:
Functions are everywhere!
And everywhere that functions are, there are categories. Indeed, the subject
might better have been called abstract function theory, or, perhaps even better:
archery.

FUNCTIONS OF SETS
3
1.2
Functions of sets
We begin by considering functions between sets. I am not going to say here what
a function is, anymore than what a set is. Instead, we will assume a working
knowledge of these terms. They can in fact be deﬁned using category theory, but
that is not our purpose here.
Let f be a function from a set A to another set B, we write
f : A →B.
To be explicit, this means that f is deﬁned on all of A and all the values of f
are in B. In set theoretic terms,
range(f) ⊆B.
Now suppose we also have a function g : B →C,
A
f
- B
..................
g ◦f
RC
g
?
then there is a composite function g ◦f : A →C, given by
(g ◦f)(a) = g(f(a))
a ∈A.
(1.1)
Now this operation “◦” of composition of functions is associative, as follows. If
we have a further function h : C →D
A
f
- B
@
@
@
@
@
@
g ◦f
R
@
@
@
@
@
@
h ◦g
R
C
g
?
h
- D
and form h◦g and g◦f then we can compare (h◦g)◦f and h◦(g◦f) as indicated
in the above diagram. It turns out that these two functions are always identical,
(h ◦g) ◦f = h ◦(g ◦f)
since for any a ∈A, we have
((h ◦g) ◦f)(a) = h(g(f(a))) = (h ◦(g ◦f))(a)
using (1.1).
By the way, this is of course what it means for two functions to be equal: for
every argument, they have the same value.

4
CATEGORIES
Finally, note that every set A has an identity function
1A : A →A
given by
1A(a) = a.
These identity functions act as “units” for the operation ◦of composition, in
the sense of abstract algebra. That is to say,
f ◦1A = f = 1B ◦f
for any f : A →B.
These are all the properties of set functions that we want to consider for the
abstract notion of function—composition and identities. Thus, we now want to
“abstract away” everything else, so to speak. That is what is accomplished by
the following deﬁnition.
1.3
Deﬁnition of a category
Deﬁnition 1.1. A category consists of the following data:
• Objects: A, B, C, . . .
• Arrows: f, g, h, . . .
• For each arrow f there are given objects:
dom(f),
cod(f)
called the domain and codomain of f. We write:
f : A →B
to indicate that A = dom(f) and B = cod(f).
• Given arrows f : A →B and g : B →C, that is, with:
cod(f) = dom(g)
there is given an arrow:
g ◦f : A →C
called the composite of f and g.
• For each object A there is given an arrow:
1A : A →A
called the identity arrow of A.

EXAMPLES OF CATEGORIES
5
These data are required to satisfy the following laws:
• Associativity:
h ◦(g ◦f) = (h ◦g) ◦f
for all f : A →B, g : B →C, h : C →D.
• Unit:
f ◦1A = f = 1B ◦f
for all f : A →B.
A category is anything that satisﬁes this deﬁnition—and we will have plenty of
examples very soon. For now I want to emphasize that, unlike in the previous
section, the objects do not have to be sets and the arrows need not be functions. In
this sense, a category is an abstract algebra of functions, or “arrows” (sometimes
also called “morphisms”), with the composition operation “◦” as primitive. If you
are familiar with groups, you may think of a category as a sort of generalized group.
1.4
Examples of categories
1. We have already encountered the category Sets of sets and functions.
There is also the category
Setsﬁn
of all ﬁnite sets and functions between them.
Indeed, there are many categories like this, given by restricting the sets
that are to be the objects and the functions that are to be the arrows. For
example, take ﬁnite sets as objects and injective (i.e., “1 to 1”) func-
tions as arrows. Since injective functions compose to give an injective
function, and since the identity functions are injective, this also gives
a category.
What if we take sets as objects and as arrows, those f : A →B such
that for all b ∈B, the subset
f −1(b) ⊆A
has at most two elements (rather than one)? Is this still a category? What
if we take the functions such that f −1(b) is ﬁnite? inﬁnite? There are lots
of such restricted categories of sets and functions.
2. Another kind of example one often sees in mathematics is categories
of structured sets, that is, sets with some further “structure” and func-
tions which “preserve it,” where these notions are determined in some
independent way. Examples of this kind you may be familiar with are:
• groups and group homomorphisms,

6
CATEGORIES
• vector spaces and linear mappings,
• graphs and graph homomorphisms,
• the real numbers R and continuous functions R →R,
• open subsets U ⊆R and continuous functions f : U →V ⊆R deﬁned
on them,
• topological spaces and continuous mappings,
• diﬀerentiable manifolds and smooth mappings,
• the natural numbers N and all recursive functions N →N, or as in
the example of continuous functions, one can take partial recursive
functions deﬁned on subsets U ⊆N.
• posets and monotone functions.
Do not worry if some of these examples are unfamiliar to you. Later on,
we will take a closer look at some of them. For now, let us just consider
the last of the above examples in more detail.
3. A partially ordered set or poset is a set A equipped with a binary relation
a ≤A b such that the following conditions hold for all a, b, c ∈A:
reﬂexivity: a ≤A a,
transitivity: if a ≤A b and b ≤A c, then a ≤A c,
antisymmetry: if a ≤A b and b ≤A a, then a = b.
For example, the real numbers R with their usual ordering x ≤y form a
poset that is also linearly ordered: either x ≤y or y ≤x for any x, y.
An arrow from a poset A to a poset B is a function
m : A →B
that is monotone, in the sense that, for all a, a′ ∈A,
a ≤A a′
implies
m(a) ≤B m(a′).
What does it take for this to be a category? We need to know that 1A :
A →A is monotone, but that is clear since a ≤A a′ implies a ≤A a′.
We also need to know that if f : A →B and g : B →C are monotone,
then g ◦f : A →C is monotone. This also holds, since a ≤a′ implies
f(a) ≤f(a′) implies g(f(a)) ≤g(f(a′)) implies (g ◦f)(a) ≤(g ◦f)(a′). So
we have the category Pos of posets and monotone functions.
4. The categories that we have been considering so far are examples of what
are sometimes called concrete categories. Informally, these are categories
in which the objects are sets, possibly equipped with some structure, and
the arrows are certain, possibly structure-preserving, functions (we shall
see later on that this notion is not entirely coherent; see Remark 1.7). Let’s
now take a look at a few examples that are not of this sort.

EXAMPLES OF CATEGORIES
7
Let Rel be the following category: take sets as objects and take binary
relations as arrows. That is, an arrow f : A →B is a subset f ⊆A × B.
The identity arrow on a set A is the identity relation.
1A = {(a, a) ∈A × A | a ∈A} ⊆A × A.
Given R ⊆A × B and S ⊆B × C, deﬁne composition S ◦R by
(a, c) ∈S ◦R
iﬀ
∃b. (a, b) ∈R & (b, c) ∈S
that is, the “relative product” of S and R. We leave it as an exercise to
show that Rel is in fact a category. (What needs to be done?)
For another example of a category in which the arrows are not “func-
tions,” let the objects be ﬁnite sets A, B, C and an arrow F : A →B is a
rectangular matrix F = (nij)i<a,j<b of natural numbers with a = |A| and
b = |B|, where |C| is the number of elements in a set C. The composition
of arrows is by the usual matrix multiplication, and the identity arrows
are the usual unit matrices.
5. Finite categories
Of course, the objects of a category do not have to be sets, either. Here
are some very simple examples:
• The category 1 looks like this:
∗
It has one object and its identity arrow, which we do not draw.
• The category 2 looks like this:
∗
- ⋆
It has two objects, their required identity arrows, and exactly one
arrow between the objects.
• The category 3 looks like this:
∗
- ⋆
@
@
@
@
@
@
R •
?
It has three objects, their required identity arrows, exactly one arrow
from the ﬁrst to the second object, exactly one arrow from the second
to the third object, and exactly one arrow from the ﬁrst to the third
object (which is therefore the composite of the other two).
• The category 0 looks like this:
It has no objects or arrows.

8
CATEGORIES
As above, we will omit the identity arrows in drawing categories from
now on.
It is fairly easy to specify ﬁnite categories—just take some objects and
start putting arrows between them, but make sure to put in the necessary
identities and composites, as required by the axioms for a category. Also,
if there are any loops, then they need to be cut oﬀby equations to keep
the category ﬁnite. For example, consider the following speciﬁcation:
A
f
-

g
B
Unless we stipulate an equation like gf = 1A, we will end up with inﬁnitely
many arrows gf, gfgf, gfgfgf, . . . . This is still a category, of course,
but it is not a ﬁnite category. We will come back to this situation when
we discuss free categories later in this chapter.
6. One important slogan of category theory is,
It’s the arrows that really matter!
So we should also look at the arrows or “mappings” between categories. A
“homomorphism of categories” is called a functor.
Deﬁnition 1.2. A functor
F : C →D
between categories C and D is a mapping of objects to objects and arrows
to arrows, in such a way that:
(a) F(f : A →B) = F(f) : F(A) →F(B),
(b) F(g ◦f) = F(g) ◦F(f),
(c) F(1A) = 1F (A).
Now, one can check that functors compose in the expected way, and that
every category C has an identity functor 1C : C →C. So we have another
example of a category, namely Cat, the category of all categories and
functors.
7. A preorder is a set P equipped with a binary relation p ≤q that is both
reﬂexive and transitive: a ≤a, and if a ≤b and b ≤c, then a ≤c. Any
preorder P can be regarded as a category by taking the objects to be the
elements of P and taking a unique arrow,
a →b
if and only if
a ≤b.
(1.2)
The reﬂexive and transitive conditions on ≤ensure that this is a category.

EXAMPLES OF CATEGORIES
9
Going in the other direction, any category with at most one arrow between
any two objects determines a preorder, simply by deﬁning a binary rela-
tion ≤on the objects by (1.2).
8. A poset is evidently a preorder satisfying the additional condition of anti-
symmetry: if a ≤b and b ≤a, then a = b. So, in particular, a poset is
also a category. Such poset categories are very common; for example, for
any set X, the powerset P(X) is a poset under the usual inclusion relation
U ⊆V between the subsets U, V of X.
What is a functor F : P →Q between poset categories P and Q? It
must satisfy the identity and composition laws . . . . Clearly, these are just
the monotone functions already considered above.
It is often useful to think of a category as a kind of generalized poset,
one with “more structure” than just p ≤q. Thus, one can also think of a
functor as a generalized monotone map.
9. An example from logic: Given a deductive system of logic, there’s an
associated category, where the objects are formulas:
ϕ, ψ, . . .
An arrow from ϕ to ψ is a deduction of ψ from the assumption ϕ. Compos-
ition of arrows is given by putting together deductions in the obvious way,
which is clearly associative. (What are the identity arrows 1ϕ?) Observe
that there can be many diﬀerent arrows
p : ϕ →ψ
since there may be many diﬀerent proofs. This category turns out to have
a very rich structure, which we will consider later in connection with the
lambda-calculus.
10. An example from computer science: Given a functional programming lan-
guage L, there is an associated category, where the objects are the data
types of L, and the arrows are the computable functions of L (“pro-
cesses,” “procedures,” “programs”). The composition of two such programs
X
f→Y
g→Z is given by applying g to the output of f, sometimes also
written
g ◦f = f; g.
The identity is the “do nothing” program.
Categories such as this are basic to the idea of denotational semantics of
programming languages. For example, if C(L) is the category just deﬁned,
then the denotational semantics of the language L in a category D of, say,
Scott domains is simply a functor
S : C(L) →D

10
CATEGORIES
since S assigns domains to the types of L and continuous functions to
the programs. Both this example and the previous one are related to the
notion of “cartesian closed category” that is considered later.
11. Let X be a set. We can regard X as a category Dis(X) by taking the
objects to be the elements of X and taking the arrows to be just the
identity arrows, one for each x ∈X. Such categories are called discrete.
Note that discrete categories are just very special posets.
12. A monoid (sometimes called a semigroup with unit) is a set M equipped
with a binary operation · : M × M →M and a distinguished “unit”
element u ∈M such that for all x, y, z ∈M,
x · (y · z) = (x · y) · z
and
u · x = x = x · u.
Equivalently, a monoid is a category with just one object. The arrows of
the category are the elements of the monoid. In particular, the identity
arrow is the unit element u. Composition of arrows is the binary operation
m · n of the monoid.
Monoids are very common: there are the monoids of numbers like N, Q
or R with addition and 0, or multiplication and 1. But also for any set X,
the set of functions from X to X, written
HomSets(X, X)
is a monoid under the operation of composition. More generally, for any
object C in any category C, the set of arrows from C to C, written as
HomC(C, C), is a monoid under the composition operation of C.
Since monoids are structured sets, there is a category Mon whose
objects are monoids and whose arrows are functions that preserve the mon-
oid structure. In detail, a homomorphism from a monoid M to a monoid
N is a function h : M →N such that for all m, n ∈M,
h(m ·M n) = h(m) ·N h(n)
and
h(uM) = uN.
The reader should check that a monoid homomorphism from M to N is
the same thing as a functor from M regarded as a category to N regarded
as a category. In this sense, categories are also generalized monoids, and
functors are generalized homomorphisms.

ISOMORPHISMS
11
1.5
Isomorphisms
Deﬁnition 1.3. In any category C, an arrow f
: A →B is called an
isomorphism if there is an arrow g : B →A in C such that
g ◦f = 1A
and
f ◦g = 1B.
Since inverses are unique (proof!), we write g = f −1. We say that A is isomorphic
to B, written A ∼= B, if there exists an isomorphism between them.
The deﬁnition of isomorphism is our ﬁrst example of an abstract, category the-
oretic deﬁnition of an important notion. It is abstract in the sense that it makes
use only of the category theoretic notions, rather than some additional inform-
ation about the objects and arrows. It has the advantage over other possible
deﬁnitions that it applies in any category. For example, one sometimes deﬁnes
an isomorphism of sets (groups, etc.) as a bijective function (resp. homomorph-
ism), that is, one that is “1-1 and onto.” This is equivalent to our deﬁnition in
some cases. But note that, for example in Pos, the category theoretic deﬁnition
gives the right notion, while there are “bijective homomorphisms” between non-
isomorphic posets. Moreover, in many cases only the abstract deﬁnition makes
sense, for example, in the case of a monoid.
Deﬁnition 1.4. A group G is a monoid with an inverse g−1 for every element g.
Thus G is a category with one object, in which every arrow is an isomorphism.
The natural numbers N do not form a group under either addition or multi-
plication, but the integers Z and the positive rationals Q+, respectively, do. For
any set X, we have the group Aut(X) of automorphisms (or “permutations”) of
X, that is, isomorphisms f : X →X. (Question: why is this closed under “◦”?)
A group of permutations is a subgroup G ⊆Aut(X) for some set X, that is, a
group of automorphisms of X. Thus G must satisfy the following:
1. 1X ∈G.
2. If g, g′ ∈G, then g ◦g′ ∈G.
3. If g ∈G, then g−1 ∈G.
A homomorphism of groups h : G →H is just a homomorphism of monoids,
which then necessarily also preserves the inverses (proof!).
Theorem (Cayley). Every group G is isomorphic to a group of permutations.
Proof. (sketch)
1. First, deﬁne the Cayley representation ¯G of G to be the following group of
permutations: the underlying set of ¯G is just G, and for each g ∈G, we
have the permutation ¯g, deﬁned for all h ∈G by:
¯g(h) = g · h.

12
CATEGORIES
Now check that ¯g = ¯h implies g = h.
2. Next deﬁne homomorphisms i : G →¯G by i(g) = ¯g, and j : ¯G →G by
j(¯g) = g.
3. Finally show that i ◦j = 1 ¯
G and j ◦i = 1G.
Warning 1.5. Note the two diﬀerent levels of isomorphisms that occur in the
proof of Cayley’s theorem. There are permutations of the set of elements of G,
which are isomorphisms in Sets, and there is the isomorphism between G and
¯G, which is in the category Groups of groups and group homomorphisms.
Cayley’s theorem says that any abstract group can be represented as a “con-
crete” one, that is, a group of permutations of a set. The theorem can in fact be
generalized to show that any category that is not “too big” can be represented
as one that is “concrete,” that is, a category of sets and functions. (There is a
technical sense of not being “too big” that will be introduced in Section 1.8.)
Theorem 1.6. Every category C with a set of arrows is isomorphic to one in
which the objects are sets and the arrows are functions.
Proof. (sketch) Deﬁne the Cayley representation ¯C of C to be the following
concrete category:
• objects are sets of the form
¯C = {f ∈C | cod(f) = C}
for all C ∈C,
• arrows are functions
¯g : ¯C →¯D
for g : C →D in C, deﬁned by ¯g(f) = g ◦f.
Remark 1.7. This shows us what is wrong with the naive notion of a “concrete”
category of sets and functions: while not every category has special sets and
functions as its objects and arrows, every category is isomorphic to such a one.
Thus, the only special properties such categories can possess are ones that are
categorically irrelevant, such as features of the objects that do not aﬀect the
arrows in any way (like the diﬀerence between the real numbers constructed
as Dedekind cuts or as Cauchy sequences). A better attempt to capture what
is intended by the rather vague idea of a “concrete” category is that arbitrary
arrows f : C →D are completely determined by their composites with arrows
x : T →C from some “test object” T, in the sense that fx = gx for all such
x implies f = g. This amounts to considering a particular representation of the
category, determined by T. A category is then said to be “concrete” when this

CONSTRUCTIONS ON CATEGORIES
13
condition holds for T a “terminal object,” in the sense of Section 2.2; but there
are also good reasons for considering other objects T, as we see in the next
chapter.
Note that the condition that C have a set of arrows is needed to ensure that
the collections {f ∈C | cod(f) = C} really are sets—we return to this point in
Section 1.8.
1.6
Constructions on categories
Now that we have a stock of categories to work with, we consider some
constructions that produce new categories from old.
1. The product of two categories C and D, written
C × D
has objects of the form (C, D), for C ∈C and D ∈D, and arrows of the
form
(f, g) : (C, D) →(C′, D′)
for f : C →C′ ∈C and g : D →D′ ∈D. Composition and units are
deﬁned componentwise; that is,
(f ′, g′) ◦(f, g) = (f ′ ◦f, g′ ◦g)
1(C,D) = (1C, 1D).
There are two obvious projection functors
C  π1
C × D
π2 - D
deﬁned by π1(C, D) = C and π1(f, g) = f, and similarly for π2.
The reader familiar with groups will recognize that for groups G and H,
the product category G × H is the usual (direct) product of groups.
2. The opposite (or “dual”) category Cop of a category C has the same objects
as C, and an arrow f : C →D in Cop is an arrow f : D →C in C. That
is Cop is just C with all of the arrows formally turned around.
It is convenient to have a notation to distinguish an object (resp. arrow)
in C from the same one in Cop. Thus, let us write
¯f : ¯D →¯C
in Cop for f : C →D in C. With this notation we can deﬁne composition
and units in Cop in terms of the corresponding operations in C, namely,
1 ¯
C = ¯
1C
¯f ◦¯g =
¯
g ◦f.

14
CATEGORIES
Thus, a diagram in C
A
f
- B
@
@
@
@
@
@
g ◦f
RC
g
?
looks like this in Cop
¯A 
¯f
¯B
I
@
@
@
@
@
@
¯f ◦¯g
¯C
¯g
6
Many “duality” theorems of mathematics express the fact that one category
is (a subcategory of) the opposite of another. An example of this sort which
we will prove later is that Sets is dual to the category of complete, atomic
Boolean algebras.
3. The arrow category C→of a category C has the arrows of C as objects,
and an arrow g from f : A →B to f ′ : A′ →B′ in C→is a “commutative
square”
A
g1 - A′
B
f
?
g2
- B′
f ′
?
where g1 and g2 are arrows in C. That is, such an arrow is a pair of arrows
g = (g1, g2) in C such that
g2 ◦f = f ′ ◦g1.
The identity arrow 1f on an object f : A →B is the pair (1A, 1B).
Composition of arrows is done componentwise:
(h1, h2) ◦(g1, g2) = (h1 ◦g1, h2 ◦g2)
The reader should verify that this works out by drawing the appropriate
commutative diagram.
Observe that there are two functors:
C dom
C→
cod- C

CONSTRUCTIONS ON CATEGORIES
15
4. The slice category C/C of a category C over an object C ∈C has:
• objects: all arrows f ∈C such that cod(f) = C,
• arrows: g from f : X →C to f ′ : X′ →C is an arrow g : X →X′ in C
such that f ′ ◦g = f, as indicated in
X
g
- X′
@
@
@
@
@
@
f
R

	
	
	
	
	
	
f ′
C
We leave it to the reader to work out the identity arrows and composites.
If C = P is a poset category and p ∈P, then
P/p ∼= ↓(p)
the slice category P/p is just the “principal ideal” ↓(p) of elements q ∈P
with q ≤p. We will have more examples of slice categories soon.
There is an obvious functor U : C/C →C that “forgets about the base
object C.” Can you ﬁnd a functor F : C/C →C→such that dom◦F = U?
The coslice category C/C of a category C under an object C of C has
as objects all arrows f of C such that dom(f) = C, and an arrow from
f : C →X to f ′ : C →X′ is an arrow h : X →X′ such that h ◦f = f ′.
The reader should now carry out the rest of the deﬁnition of the coslice
category by analogy with the deﬁnition of the slice category.
How can the coslice category be deﬁned in terms of the slice category and
the opposite construction?
Example 1.8. The category Sets∗of pointed sets consists of sets A with a distin-
guished element a ∈A, and arrows f : (A, a) →(B, b) are functions f : A →B
that preserves the “points,” f(a) = b. This is isomorphic to the coslice category,
Sets∗∼= 1\Sets
of Sets “under” any singleton 1 = {∗}. Indeed, functions a : 1 →A correspond
uniquely to elements, a(∗) = a ∈A, and arrows f : (A, a) →(B, b) correspond
exactly to commutative triangles:
1
a
- A
@
@
@
@
@
@
b
RB
f
?

16
CATEGORIES
1.7
Free categories
Free monoid. Start with an “alphabet” A of “letters” (a set)
A = {a, b, c, . . .}.
A word over A is a ﬁnite sequence of letters:
thisword,
categoriesarefun,
asddjbnzzfj, . . .
We write “-” for the empty word. The “Kleene closure” of A is deﬁned to be
the set
A∗= {words over A}.
Deﬁne a binary operation “∗” on A∗deﬁned for w, w′ ∈A∗by w ∗w′ = ww′.
Thus, “∗” is just concatenation. The operation “∗” is associative, and the empty
word “-” is a unit. Thus, A∗is a monoid—called the free monoid on the set A.
The elements a ∈A can be regarded as words of length one, so we have a function
i : A →A∗
deﬁned by i(a) = a, and called the “insertion of generators.” The elements of A
“generate” the free monoid, in the sense that every w ∈A∗is a ∗-product of a’s,
that is, w = a1 ∗a2 ∗· · · ∗an for some a1, a2, ..., an in A.
Now what does “free” mean here? Any guesses?
One sometimes sees deﬁnitions in “baby algebra” books along the following
lines:
A monoid M is freely generated by a subset A of M, if the following conditions
hold.
1. Every element m ∈M can be written as a product of elements of A
m = a1 ·M . . . ·M an ,
ai ∈A.
2. No “nontrivial” relations hold in M, that is, if a1 . . . aj = a′
1 . . . a′
k, then
this is required by the axioms for monoids.
The ﬁrst condition is sometimes called “no junk,” while the second condition is
sometimes called “no noise.” Thus, the free monoid on A is a monoid containing
A and having no junk and no noise. What do you think of this deﬁnition of a
free monoid?
I would object to the reference in the second condition to “provability,” or
something. This must be made more precise for this to succeed as a deﬁnition. In
category theory, we give a precise deﬁnition of “free”—capturing what is meant
in the above—which avoids such vagueness.
First, every monoid N has an underlying set |N|, and every monoid homo-
morphism f : N →M has an underlying function |f| : |N| →|M|. It is easy to
see that this is a functor, called the “forgetful functor.” The free monoid M(A)

FREE CATEGORIES
17
on a set A is by deﬁnition “the” monoid with the following so called universal
mapping property, or UMP!
Universal Mapping Property of M(A)
There is a function i : A →|M(A)|, and given any monoid N and any function
f : A →|N|, there is a unique monoid homomorphism ¯f : M(A) →N such that
| ¯f| ◦i = f, all as indicated in the following diagram:
in Mon:
M(A) ...............
¯f - N
in Sets:
|M(A)|
| ¯f|- |N|
	
	
	
	
	
	
f

A
i
6
Proposition 1.9. A∗has the UMP of the free monoid on A.
Proof. Given f : A →|N|, deﬁne ¯f : M(A) →N by
¯f(−) = uN,
the unit of N
¯f(a1 . . . ai) = f(a1) ·N . . . ·N f(ai).
Then ¯f is clearly a homomorphism with
¯f(a) = f(a)
for all a ∈A.
If g : M(A) →N also satisﬁes g(a) = f(a) for all a ∈A, then for all a1 . . . ai ∈A∗:
g(a1 . . . ai) = g(a1) ·N . . . ·N g(ai)
= f(a1) ·N . . . ·N f(ai)
= ¯f(a1) ·N . . . ·N ¯f(ai)
= ¯f(a1 . . . ai).
So, g = ¯f, as required.
Think about why the above UMP captures precisely what is meant by “no junk”
and “no noise.” Speciﬁcally, the existence part of the UMP captures the vague
notion of “no noise,” while the uniqueness part makes precise the “no junk” idea.
Using the UMP, it is easy to show that the free monoid M(A) is determined
uniquely up to isomorphism, in the following sense.

18
CATEGORIES
Proposition 1.10. Given monoids M and N with functions i : A →|M| and
j : A →|N|, each with the UMP of the free monoid on A, there is a (unique)
monoid isomorphism h : M ∼= N such that |h|i = j and |h−1|j = i.
Proof. From j and the UMP of M, we have ¯j : M →N with |¯j|i = j and from
i and the UMP of N, we have ¯i : N →M with |¯i|j = i. Composing gives a
homomorphism ¯i ◦¯j : M →M such that |¯i ◦¯j|i = i. Since 1M : M →M also
has this property, by the uniqueness part of the UMP of M, we have ¯i ◦¯j = 1M.
Exchanging the roles of M and N shows ¯j ◦¯i = 1N;
in Mon:
M ...................
¯j
- N ...................
¯i
- M
in Sets:
|M|
|¯j| - |N|
|¯i| - |M|
I
@
@
@
@
@
@
i
	
	
	
	
	
	
i

A
j
6
For example, the free monoid on a set with a single element is isomorphic to
the monoid of natural numbers N under addition (the “generator” is 1). Thus,
as a monoid, N is uniquely determined up to isomorphism by the UMP of free
monoids.
Free category. Now, we want to do the same thing for categories in general
(not just monoids). Instead of underlying sets, categories have underlying graphs,
so let us review these ﬁrst.
A directed graph consists of vertices and edges, each of which is directed, that
is, each edge has a “source” and a “target” vertex.
A
z
- B
@
@
@
@
@
@
u
R
C
x
6
D
y
6
We draw graphs just like categories, but there is no composition of edges, and
there are no identities.
A graph thus consists of two sets, E (edges) and V (vertices), and two
functions, s: E →V (source) and t: E →V (target).
Now, every graph G “generates” a category C(G), the free category on G. It
is deﬁned by taking the vertices of G as objects, and the paths in G as arrows,

FREE CATEGORIES
19
where a path is a ﬁnite sequence of edges e1, . . . , en such that t(ei) = s(ei+1),
for all i = 1 . . . n. We’ll write the arrows of C(G) in the form enen−1 . . . e1.
Put
dom(en . . . e1) = s(e1)
cod(en . . . e1) = t(en)
and deﬁne composition by concatenation:
en . . . e1 ◦e′
m . . . e′
1 = en . . . e1e′
m . . . e′
1.
For each vertex v, we have an “empty path” denoted 1v, which is to be the
identity arrow at v.
Note that if G has only one vertex, then C(G) is just the free monoid on the
set of edges of G. Also note that if G has only vertices (no edges), then C(G) is
the discrete category on the set of vertices of G.
Later on, we will have a general deﬁnition of “free.” For now, let us see that
C(G) also has a UMP.
First, deﬁne a “forgetful functor”
U : Cat →Graphs
in the obvious way: the underlying graph of a category C has as edges the arrows
of C, and as vertices the objects, with s = dom and t = cod. The action of U on
functors is equally clear, or at least it will be, once we have deﬁned the arrows
in Graphs.
A homomorphism of graphs is of course a “functor without the conditions on
identities and composition,” that is, a mapping of edges to edges and vertices to
vertices that preserves sources and targets. We will describe this from a slightly
diﬀerent point of view, that will be useful later on. First, observe that we can
describe a category C with a diagram like this:
C2
◦- C1
cod -

i
dom
- C0
where C0 is the collection of objects of C, C1 the arrows, and C2 is the collection
{(f, g) ∈C1 × C1 : cod(f) = dom(g)}.
Then a functor F : C →D from C to another category D is a pair of
functions
F0 : C0 →D0
F1 : C1 →D1

20
CATEGORIES
such that each similarly labeled square in the following diagram commutes:
C2
◦- C1
cod -

i
dom
- C0
D2
F2
?
◦
- D1
F1
?
cod -

i
dom
- D0
F0
?
where F2(f, g) = (F1(f), F1(g)).
Now let us describe a homomorphism of graphs,
h : G →H.
We need a pair of functions h0 : G0 →H0, h1 : G1 →H1 making the two squares
(once with t’s, once with s’s) in the following diagram commute:
G1
t -
s
- G0
H1
h1
?
t -
s
- H0
h0
?
In these terms, we can easily describe the forgetful functor,
U : Cat →Graphs
as sending the category
C2
◦- C1
cod -

i
dom
- C0
to the underlying graph:
C1
cod -
dom
- C0
And similarly for functors, the eﬀect of U is described by erasing some parts of
the diagrams (which is easier to demonstrate with chalk!).
The free category on a graph has the following UMP:
Universal Mapping Property of C(G)
There is a graph homomorphism i : G →|C(G)|, and given any category D and
any graph homomorphism h : G →|D|, there is a unique functor ¯h : C(G) →D
with |¯h| ◦i = h.

FOUNDATIONS: LARGE, SMALL, AND LOCALLY SMALL
21
in Cat:
C(G) ................
¯h - D
in Graph:
|C(G)|
|¯h|- |D|
	
	
	
	
	
	
h

G
i
6
The free category on a graph with just one vertex is just a free monoid on
the set of edges. The free category on a graph with two vertices and one edge
between them is the ﬁnite category 2. The free category on a graph of the form:
A
e
-

f
B
has (in addition to the identity arrows) the inﬁnitely many arrows:
e, f, ef, fe, efe, fef, efef, ...
1.8
Foundations: large, small, and locally small
Let us begin by distinguishing between the following things:
categorical foundations for mathematics,
mathematical foundations for category theory.
As for the ﬁrst: one sometimes hears it said that category theory can be
used to provide “foundations for mathematics,” as an alternative to set theory.
That is in fact the case, but it is not what we are doing here. In set theory,
one often begins with existential axioms such as “every set has a powerset” and
derives further sets, building up a universe of mathematical objects (namely
sets), which in principle suﬃce for “all of mathematics.” Our axiom that every
arrow has a domain and a codomain is not to be understood in the same way
as set theory’s axiom that every set has a powerset! The diﬀerence is that in set
theory—at least as usually conceived—the axioms are to be regarded as referring
to (or determining) a single universe of sets. In category theory, by contrast, the
axioms are a deﬁnition of something, namely of categories. This is just like in
group theory or topology, where the axioms serve to deﬁne the objects under
investigation. These, in turn, are assumed to exist in some “background” or
“foundational” system, like set theory. That theory of sets could itself, in turn,
be determined using category theory, or in some other way.

22
CATEGORIES
This brings us to the second point: we assume that our categories are com-
prised of sets and functions, in one way or another, like most mathematical
objects, and taking into account the remarks just made about the possibility of
categorical foundations. But in category theory, we sometimes run into diﬃculties
with set theory as usually practiced. Mostly these are questions of size; some cat-
egories are “too big” to be handled comfortably in conventional set theory. We
already encountered this issue when we considered the Cayley representation in
Section 1.5. There we had to require that the category under consideration had
(no more than) a set of arrows. We would certainly not want to impose this
restriction in general, however (as one usually does for, say, groups); for then
even the “category” Sets would fail to be a proper category, as would many
other categories that we deﬁnitely want to study.
There are various formal devices for addressing these issues, and they are
discussed in the book by Mac Lane. For our immediate purposes, the following
distinction will be useful:
Deﬁnition 1.11. A category C is called small if both the collection C0 of
objects of C and the collection C1 of arrows of C are sets. Otherwise, C is
called large.
For example, all ﬁnite categories are clearly small, as is the category Setsﬁn of
ﬁnite sets and functions. On the other hand, the category Pos of posets, the
category Groups of groups, and the category Sets of sets are all large. We let
Cat be the category of all small categories, which itself is a large category. In
particular, then, Cat is not an object of itself, which may come as a relief to
some readers.
This does not really solve all of our diﬃculties. Even for large categories like
Groups and Sets we will want to also consider constructions like the category
of all functors from one to the other (we will deﬁne this “functor category”
later). But if these are not small, conventional set theory does not provide the
means to do this directly (these categories would be “too large”). So, one needs
a more elaborate theory of “classes” to handle such constructions. We will not
worry about this when it is just a matter of technical foundations (Mac Lane I.6
addresses this issue). However, one very useful notion in this connection is the
following:
Deﬁnition 1.12. A category C is called locally small if for all objects X, Y
in C, the collection HomC(X, Y ) = {f ∈C1| f : X →Y } is a set (called a
hom-set).
Many of the large categories we want to consider are in fact locally small. Sets
is locally small since HomSets(X, Y ) = Y X, the set of all functions from X to Y .
Similarly, Pos, Top, and Group are all locally small (is Cat?), and, of course,
any small category is locally small.

EXERCISES
23
1.9
Exercises
1. The objects of Rel are sets, and an arrow f : A →B is a relation from A
to B, that is, f ⊆A × B. The identity relation {⟨a, a⟩∈A × A| a ∈A} is
the identity arrow on a set A. Composition in Rel is to be given by
g ◦f = {⟨a, c⟩∈A × C | ∃b (⟨a, b⟩∈f & ⟨b, c⟩∈g)}
for f ⊆A × B and g ⊆B × C.
Show that Rel is a category.
2. Consider
the
following
isomorphisms
of
categories
and
determine
which hold.
(a) Rel ∼= Relop
(b) Sets ∼= Setsop
(c) For a ﬁxed set X with powerset P(X), as poset categories P(X) ∼=
P(X)op (the arrows in P(X) are subset inclusions A
⊆
B for
A, B ⊆X).
3. (a) Show that in Sets, the isomorphisms are exactly the bijections.
(b) Show that in Monoids, the isomorphisms are exactly the bijective
homomorphisms.
(c) Show that in Posets, the isomorphisms are not the same as the
bijective homomorphisms.
4. Construct the “coslice category” C/C of a category C under an object C
from the slice category C/C and the “dual category” operation −op.
5. How many free categories on graphs are there which have exactly six arrows?
Draw the graphs that generate these categories.
6. Prove the UMP for free categories on graphs:
Let C(G) be the free category on the graph G and i : G →U(C(G)) the
graph homomorphism taking vertices and edges to themselves, regarded as
objects and arrows in C(G). For any category D and graph homomorphism
f : G →U(D), there is a unique functor
¯h : C(G) →D
with
U(¯h) ◦i = h,
where U : Cat →Graph is the underlying graph functor.

This page intentionally left blank 

2
ABSTRACT STRUCTURES
Let me begin with some remarks about category-theoretical deﬁnitions. By this I
mean characterizations of properties of objects and arrows in a category in terms
of other objects and arrows only, that is, in the language of category theory.
Such deﬁnitions may be said to be abstract, structural, operational, relational,
or external (as opposed to internal). The idea is that objects and arrows are
determined by the role they play in the category via their relations to other
objects and arrows, that is, by their position in a structure and not by what
they “are” or “are made of” in some absolute sense. We will see many more
examples of this kind of thing later; for now we start with some very simple
ones. Let me call them abstract characterizations. We will see that one of the
basic ways of giving such an abstract characterization is via a Universal Mapping
Property or UMP.
2.1
Epis and monos
Recall that in Sets, a function f : A →B is called
injective if f(a) = f(a′) implies a = a′ for all a, a′ ∈A,
surjective if for all b ∈B there is some a ∈A with f(a) = b.
We have the following abstract characterizations of these properties:
Deﬁnition 2.1. In any category C, an arrow
f : A →B
is called a
monomorphism, if given any g, h : C →A, fg = fh implies g = h,
C
g
-
h
- A
f
- B
epimorphism, if given any i, j : B →D, if = jf implies i = j,
A
f
- B
i
-
j
- D

26
ABSTRACT STRUCTURES
We often write f : A ↣B if f is a monomorphism and f : A ↠B if f is an
epimorphism.
Proposition 2.2. A function f : A →B between sets is monic just in case it
is injective.
Proof. Suppose f : A ↣B. Let a, a′ ∈A such that a ̸= a′, and let {x} be any
given one-element set. Consider the functions
¯a, ¯a′ : {x} →A
where
¯a(x) = a,
¯a′(x) = a′.
Since ¯a ̸= ¯a′, it follows, since f is a monomorphism, that f¯a ̸= f ¯a′. Thus,
f(a) = (f¯a)(x) ̸= (f ¯a′)(x) = f(a′). Whence f is injective.
Conversely, if f is injective and g, h : C →A are functions such that g ̸= h,
then for some c ∈C, g(c) ̸= h(c). Since f is injective, it follows that f(g(c)) ̸=
f(h(c)), whence fg ̸= fh.
Example 2.3. In many categories of “structured sets” like monoids, the monos
are exactly the “injective homomorphisms.” More precisely, a homomorphism
h : M →N of monoids is monic just if the underlying function |h| : |M| →
|N| is monic, that is, injective by the foregoing. To prove this, suppose h is
monic and take two diﬀerent “elements” m, m′ : 1 →|M|, where 1 = {∗} is
any one-element set. By the UMP of the free monoid M(∗) there are distinct
corresponding homomorphisms ¯m, ¯
m′ : M(∗) →M, with distinct composites
h ◦¯m, h ◦¯
m′ : M(∗) →M →N, since h is monic. Thus, the corresponding
“elements” hm, hm′ : 1 →N of N are also distinct, again by the UMP of
M(∗). Conversely, if |h| : |M| →|N| is monic and f, g : X →M are any
distinct homomorphisms, then |f|, |g| : |X| →|M| are distinct functions, and so
|h|◦|f|, |h|◦|g| : |X| →|M| →|N| are distinct, since |h| is monic. Since therefore
|h ◦f| = |h| ◦|f| ̸= |h| ◦|g| = |h ◦g|, we also must have h ◦f ̸= h ◦g.
A completely analogous situation holds, for example, for groups, rings, vector
spaces, and posets. We shall see that this fact follows from the presence, in each
of these categories, of certain objects like the free monoid M(∗).
Example 2.4. In a ﬁxed poset P, every arrow p ≤q is both monic and epic.
Why?
While the epis in Sets are exactly the surjective functions (exercise!), epis
in other categories are not always surjective homomorphisms, as the following
example shows.
Example 2.5. In the category Mon of monoids and monoid homomorphisms,
there is a monic homomorphism
N ↣Z

EPIS AND MONOS
27
where N is the additive monoid (N, +, 0) of natural numbers and Z is the additive
monoid (Z, +, 0) of integers. We will show that this map, given by the inclusion
N ⊂Z of sets, is also epi in Mon by showing that the following holds:
Given any monoid homomorphisms f, g : (Z, +, 0) →(M, ∗, u), if the
restrictions to N are equal, f |N= g |N, then f = g.
Note ﬁrst that:
f(−n) = f((−1)1 + (−1)2 + · · · + (−1)n)
= f(−1)1 ∗f(−1)2 ∗· · · ∗f(−1)n
and similarly for g. It therefore suﬃces to show that f(−1) = g(−1). But
f(−1) = f(−1) ∗u
= f(−1) ∗g(0)
= f(−1) ∗g(1 −1)
= f(−1) ∗g(1) ∗g(−1)
= f(−1) ∗f(1) ∗g(−1)
= f(−1 + 1) ∗g(−1)
= f(0) ∗g(−1)
= u ∗g(−1)
= g(−1).
Note that a morphism e is epi if and only if e cancels on the right: xe = ye
implies x = y. Dually, m is mono if and only if m cancels on the left: mx = my
implies x = y.
Proposition 2.6. Every iso is mono and epi.
Proof. Consider the following diagram:
A
x
-
y
- B
m - C
@
@
@
@
@
@
1
RB
e
?
-
- E
If m is an isomorphism with inverse e, then mx = my implies x = emx =
emy = y. Thus, m is monic. Similarly, e cancels on the right, and thus e is epic.
In Sets the converse of the foregoing also holds: every mono-epi is iso. But this
is not in general true, as shown by the example in monoids above.

28
ABSTRACT STRUCTURES
2.2
Initial and terminal objects
We now consider abstract characterizations of the empty set and the one-
element sets in the category Sets and structurally similar objects in general
categories.
Deﬁnition 2.7. In any category C, an object
0 is initial if for any object C there is a unique morphism
0 →C,
1 is terminal if for any object C there is a unique morphism
C →1.
As in the case of monos and epis, note that there is a kind of “duality” in
these deﬁnitions. Precisely, a terminal object in C is exactly an initial object in
Cop. We will consider this duality systematically later.
Since the notions of initial and terminal object are simple UMPs, such objects
are uniquely determined up to isomorphism, just like the free monoids were.
Proposition 2.8. Initial (terminal) objects are unique up to isomorphism.
Proof. In fact, if C and C′ are both initial (terminal), then there is a unique
isomorphism C →C′.
Suppose that 0 and 0′ are both initial objects, the following diagram makes
it clear that 0 and 0′ are uniquely isomorphic.
0
u
- 0′
@
@
@
@
@
@
10
R
@
@
@
@
@
@
10′
R
0
v
?
u
- 0′
For terminal objects, apply the foregoing to Cop.
Example 2.9.
1. In Sets the empty set is initial and any singleton set is terminal. Observe
that Sets has just one initial object but many terminal objects (answering
the question of whether Sets ∼= Setsop).
2. In Cat the category 0 (no objects and no arrows) is initial and the category
1 (one object and its identity arrow) is terminal.

GENERALIZED ELEMENTS
29
3. In Groups, the one-element group is both initial and terminal (similarly
for the category of vector spaces and linear transformations, as well as the
category of monoids and monoid homomorphisms). But in Rings (com-
mutative with unit), the ring Z of integers is initial (the one-element ring
with 0 = 1 is still terminal).
4. A Boolean algebra is a poset B equipped with distinguished elements 0, 1,
binary operations a∨b of “join” and a∧b of “meet,” and a unary operation
¬b of “complementation.” These are required to satisfy the conditions
0 ≤a
a ≤1
a ≤c
and
b ≤c
iﬀ
a ∨b ≤c
c ≤a
and
c ≤b
iﬀ
c ≤a ∧b
a ≤¬b
iﬀ
a ∧b = 0
¬¬a = a
There is also an equivalent, fully equational characterization not involving
the ordering. A typical example of a Boolean algebra is the powerset
P(X) of all subsets A ⊆X of a set X, ordered by inclusion A ⊆B,
and with the Boolean operations being the empty set 0 = ∅, the whole
set 1 = X, union and intersection of subsets as join and meet, and the rel-
ative complement X −A as ¬A. A familiar special case is the two-element
Boolean algebra 2 = {0, 1}, sometimes also regarded as “truth values”
with the logical operations of disjunction, conjunction, and negation as
the Boolean operations. It is an initial object in the category of Boolean
algebras, which has as arrows the Boolean homomorphisms. These are func-
tors h : B →B′ that preserve the additional structure, in the sense that
h(0) = 0, h(a ∨b) = h(a) ∨h(b), etc. The one-element Boolean algebra is
terminal.
5. In a poset, an object is plainly initial iﬀit is the least element, and terminal
iﬀit is the greatest element. Clearly, a category need not have either an
initial object or a terminal object, for example, the poset (Z, ≤) has neither
an initial object nor a terminal object.
6. For any category C and any object X ∈C, the identity arrow 1X : X →X
is a terminal object in C/X and an initial object in X/C.
2.3
Generalized elements
Let us consider arrows into and out of initial and terminal objects. Clearly only
certain of these will be of interest, but those are often especially signiﬁcant.

30
ABSTRACT STRUCTURES
A set A has an arrow into the initial object A →0 just if it is itself empty
and the same is true for posets. In monoids and groups, by contrast, every object
has a unique arrow to the initial object, since it is also terminal.
In the category Bool of Boolean algebras, however, the situation is quite
diﬀerent. The maps p : B →2 into the initial Boolean algebra 2 correspond
uniquely to the so-called ultraﬁlters U in B. A ﬁlter in a Boolean algebra B is a
nonempty subset F ⊆B that is closed upward and under meets:
a ∈F and a ≤b
implies
b ∈F
a ∈F and b ∈F
implies
a ∧b ∈F
A ﬁlter F is maximal if the only strictly larger ﬁlter F ⊂F ′ is all of B. An
ultraﬁlter is a maximal ﬁlter. It is not hard to see that a ﬁlter F is an ultraﬁlter
just if for every element b ∈B, either b ∈F or ¬b ∈F, and not both (exercise!).
Now if p : B →2, let Up = p−1(1) to get an ultraﬁlter Up ⊂B. And given an
ultraﬁlter U ⊂B, deﬁne pU(b) = 1 iﬀb ∈U to get a Boolean homomorphism
pU : B →2. This is easy to check, as is the fact that these operations are
mutually inverse. Boolean homomorphisms B →2 are also used in forming the
“truth tables” one meets in logic. Indeed, a row of a truth table corresponds to
such a homomorphism on a Boolean algebra of formulas.
Ring homomorphisms A →Z into the initial ring Z play an analogous and
equally important role in algebraic geometry.
Now let us consider arrows from terminal objects. For any set X, for instance,
we have an isomorphism
X ∼= HomSets(1, X)
between elements x ∈X and arrows ¯x : 1 →X, determined by ¯x(∗) = x, from
a terminal object 1 = {∗}. We have already used this correspondence several
times. A similar situation holds in posets (and in topological spaces), where the
arrows 1 →P correspond to elements of the underlying set of a poset (or space)
P. In any category with a terminal object 1, such arrows 1 →A are called
global elements, or points, or constants of A. In sets, posets, and spaces, the
general arrows A →B are determined by what they do to the points of A, in
the sense that two arrows f, g : A →B are equal if for every point a : 1 →A the
composites are equal, fa = ga.
But be careful; this is not always the case! How many points are there of an
object M in the category of monoids? That is, how many arrows of the form
1 →M for a given monoid M? Just one! And how many points does a Boolean
algebra have?
Because, in general, an object is not determined by its points it is convenient
to introduce the device of generalized elements. These are arbitrary arrows,
x : X →A

GENERALIZED ELEMENTS
31
(any domain X), which can be regarded as generalized or variable elements of A.
Computer scientists and logicians sometimes think of arrows 1 →A as constants
or closed terms and general arrows X →A as (arbitrary) terms.
Example 2.10.
1. Consider arrows f, g : X →Y in Pos. Then f = g iﬀfor all x : 1 →X, we
have fx = gx. In this sense, posets “have enough points” to separate the
arrows.
2. By contrast, in Mon, for homomorphisms h, j : M →N we always have
hx = jx, for all x : 1 →M, since there’s just one such point x. Thus
monoids do not “have enough points.”
3. But in any category C, and for any arrows f, g : C →C′, we always have
f = g iﬀfor all x : D →C, it holds that fx = gx (why?). Thus, every
object has enough generalized elements.
4. In fact, it often happens that it is enough to consider generalized elements
of just a certain form T →A, that is, for certain “test” objects T. We shall
consider this presently.
Generalized elements are also good for “testing” for various conditions. Consider,
for instance, the following diagram.
X
x
-
x′ - A
f
- B
The arrow f is monic iﬀx ̸= x′ implies fx ̸= fx′, that is, just if f is “injective
on generalized elements.”
Similarly, in any category C, to test whether a square commutes
A
f
- B
D
g
?
β
- C
α
?
we shall have αf = βg just if αfx = βgx for all generalized elements x : X →A
(just take x = 1A : A →A !).
Example 2.11. Generalized elements can be used to “reveal more structure” than
do the constant elements. For example, consider the following posets X and A:
A = {a ≤b ≤c}
X = {x ≤y, x ≤z}

32
ABSTRACT STRUCTURES
There is an order-preserving bijection f : X →A deﬁned by
f(x) = a,
f(y) = b,
f(z) = c.
It is easy to see that f is both monic and epic in the category Pos; however, it is
clearly not an iso. One would like to say that X and A are “diﬀerent structures,”
and indeed, their being non-isomorphic says just this. But now, how to prove that
they are not isomorphic (say, via some other X →A)? In general, this can be
quite diﬃcult.
One way to prove that two objects are not isomorphic is to use “invariants”:
attributes that are preserved by isomorphisms. If two objects diﬀer by an invari-
ant they cannot be isomorphic. Generalized elements provide an easy way to
deﬁne invariants. For instance, the number of global elements of X and A is the
same, namely the three elements of the sets. But consider instead the 2-elements
2 →X. Then X has 5 such, and A has 6. Since these numbers are invariants,
the posets cannot be isomorphic. In more detail, we can deﬁne for any poset P
the numerical invariant
| Hom(2, P)|
=
number of elements of Hom(2, P).
Then if P ∼= Q, it is easy to see that | Hom(2, P)| = | Hom(2, Q)|, since any
isomorphism
P
f
-

g
Q
also gives an iso
Hom(2, P)
f∗-

g∗
Hom(2, Q)
by composition:
f∗(h) = fh
g∗(k) = gk
for all h : 2 →P and k : 2 →Q.
Example 2.12. As in the foregoing example, it is often the case that generalized
elements t : T →A “based at” certain objects T are especially “revealing.”
We can think of such elements geometrically as “ﬁgures of shape T in A,” just
as an arrow 2 →P in posets is a ﬁgure of shape p ≤p′ in P. For instance,
as we have already seen, in the category of monoids, the arrows from the ter-
minal monoid 1 are entirely uninformative, but those from the free monoid M(∗)
on one generator suﬃce to distinguish homomorphisms, in the sense that two
homomorphisms f, g : M →N are equal if their composites with all such arrows
are equal. In fact, for monoids the underlying set |M| is plainly (isomorphic to)
HomMon(M(∗), M).

SECTIONS AND RETRACTIONS
33
2.4
Sections and retractions
We already noted that any iso is both monic and epic. More generally, if an
arrow
f : A →B
has a left inverse
g : B →A,
gf = 1A
then f must be monic and g epic, by an easy exercise.
Deﬁnition 2.13. A split mono (epi) is an arrow with a left (right) inverse.
Terminology: Given arrows e : X →A and s : A →X such that es = 1A, then s
is called a section or splitting of e, and e is called a retraction of s. The object
A is called a retract of X.
Remark 2.14. Since functors preserve identities, they also preserve split epis and
split monos. Compare the example above in Mon where the forgetful functor
Mon →Set
did not preserve the epi N →Z.
Example 2.15. In Sets, every mono splits except those of the form
∅↣A.
The condition that every epi splits is the categorical version of the axiom of
choice. Indeed, consider an epi
e : E ↠X.
We have the family of nonempty sets
Ex = e−1{x},
x ∈X.
A splitting of e is exactly a choice function for this family (Ex)x∈X, that is, a
function s : X →E such that es = 1X, since this means that s(x) ∈Ex for all
x ∈X.
Conversely, given a family of nonempty sets,
(Ex)x∈X
take E = {(x, y) | x ∈X, y ∈Ex} and deﬁne the epi e : E ↠X by (x, y) →x.
A splitting s of e then determines a choice function for the family.
The idea that a “family of objects” (Ex)x∈X can be represented by a single
arrow e : E →X by using the “ﬁbers” e−1(x) has much wider application than
this, and will be considered further in Section 7.9.
A notion related to the existence of “choice functions” is that of being “project-
ive”: an object P is said to be projective if for any epi e : E ↠X and arrow

34
ABSTRACT STRUCTURES
f : P →X there is some (not necessarily unique) arrow ¯f : P →E such that
e ◦¯f = f, as indicated in the following diagram:
E
..................
¯f
P
f
- X
e
?
?
One says that f lifts across e. Projective objects may be thought of as having
“less structure,” thus permitting “more arrows.”
The axiom of choice implies that all sets are projective, and it follows that
free objects in many (but not all!) categories of algebras then are also projective.
The reader should show that, in any category, any retract of a projective object
is also projective.
2.5
Products
Next we are going to see the categorical deﬁnition of a product of two objects in a
category. This was ﬁrst given by Mac Lane in 1950, and it is probably the earliest
example of category theory being used to deﬁne a fundamental mathematical
notion.
By “deﬁne” here I mean an abstract characterization, in the sense already
used, in terms of objects and arrows in a category. And as before, we do this
by giving a UMP, which determines the structure at issue up to isomorphism,
as usual in category theory. Later in this chapter, we will have several other
examples of such characterizations.
Let us begin by considering products of sets. Given sets A and B the cartesian
product of A and B is the set of ordered pairs
A × B = {(a, b) | a ∈A, b ∈B}.
Observe that there are two “coordinate projections”
A  π1
A × B
π2 - B
with
π1(a, b) = a,
π2(a, b) = b.
And indeed, given any element c ∈A × B we have
c = (π1c, π2c).

PRODUCTS
35
The situation is captured concisely in the following diagram:
1

	
	
	
	
	
	
a
@
@
@
@
@
@
b
R
A 
π1
A × B
(a,b)
?
.................
π2
- B
Replacing elements by generalized elements, we get the following deﬁnition.
Deﬁnition 2.16. In any category C, a product diagram for the objects A and
B consists of an object P and arrows
A  p1
P
p2 - B
satisfying the following UMP:
Given any diagram of the form
A  x1
X
x2 - B
there exists a unique u : X →P, making the diagram
X

	
	
	
	
	
	
x1
@
@
@
@
@
@
x2
R
A 
p1
P
u
?
.................
p2
- B
commute, that is, such that x1 = p1u and x2 = p2u.
Remark 2.17. As in other UMPs, there are two parts:
Existence: There is some u : X →U such that x1 = p1u and x2 = p2u.
Uniqueness: Given any v : X →U, if p1v = x1 and p2v = x2, then v = u.
Proposition 2.18. Products are unique up to isomorphism.
Proof. Suppose
A  p1
P
p2 - B
and
A 
q1
Q
q2 - B
are products of A and B. Then there is a unique i : P →Q such that q1 ◦i = p1
and q2 ◦i = p2. Similarly, there is a unique j : Q →P such that p1 ◦j = q1

36
ABSTRACT STRUCTURES
and p2 ◦j = q2. Thus, p1 ◦j ◦i = p1 and p2 ◦j ◦i = p2. Since p1 ◦1P = p1 and
p2 ◦1P = p2, it follows from the uniqueness condition that j ◦i = 1P . Similarly,
i ◦j = 1Q. Thus, i : P →Q is an isomorphism.
If A and B have a product, we write
A  p1
A × B
p2 - B
for one such product. Then given X, x1, x2 as in the deﬁnition, we write
⟨x1, x2⟩for u : X →A × B.
Note, however, that a pair of objects may have many diﬀerent products in a
category. For example, given a product A×B, p1, p2, and any iso h : A×B →Q,
the diagram Q, p1 ◦h, p2 ◦h is also a product of A and B.
Now an arrow into a product
f : X →A × B
is “the same thing” as a pair of arrows
f1 : X →A,
f2 : X →B.
So we can essentially forget about such arrows, in that they are uniquely determ-
ined by pairs of arrows. But something useful is gained if a category has products;
namely, consider arrows out of the product,
g : A × B →Y.
Such a g is a “function in two variables”; given any two generalized elements
f1 : X →A and f2 : X →B, we have an element g⟨f1, f2⟩: X →Y . Such arrows
g : A × B →Y are not “reducible” to anything more basic, the way arrows into
products were (to be sure, they are related to the notion of an “exponential”
Y B, via “currying” λf : A →Y B; we discuss this further in chapter 6).
2.6
Examples of products
1. We have already seen cartesian products of sets. Note that if we choose a
diﬀerent deﬁnition of ordered pairs ⟨a, b⟩we get diﬀerent sets
A × B
and
A ×′ B
each of which is (part of) a product, and so are isomorphic. For instance,
we could set:
⟨a, b⟩= {{a}, {a, b}}
⟨a, b⟩′ = ⟨a, ⟨a, b⟩⟩

EXAMPLES OF PRODUCTS
37
2. Products of “structured sets” like monoids or groups can often be construc-
ted as products of the underlying sets with componentwise operations: If G
and H are groups, for instance, G × H can be constructed by taking the
underlying set of G × H to be the set {⟨g, h⟩| g ∈G, h ∈H} and deﬁning
the binary operation by
⟨g, h⟩· ⟨g′, h′⟩= ⟨g · g′, h · h′⟩
the unit by
u = ⟨uG, uH⟩
and inverses by
⟨a, b⟩−1 = ⟨a−1, b−1⟩.
The projection homomorphisms G × H →G (or H) are the evident ones
⟨g, h⟩→g (or h).
3. Similarly, for categories C and D, we already deﬁned the category of pairs
of objects and arrows,
C × D.
Together with the evident projection functors, this is indeed a product in
Cat (when C and D are small).
As a special case, we also get products of posets and of monoids as
products of categories.
4. Let P be a poset and consider a product of elements p, q ∈P. We must
have projections
p × q ≤p
p × q ≤q
and if for any element x,
x ≤p,
and
x ≤q
then we need
x ≤p × q.
Do you recognize this operation p × q ? It is just what is usually called the
greatest lower bound: p × q = p ∧q. Many other order-theoretic notions are
also special cases of categorical ones, as we shall see later.
5. (For those who know something about Topology.) Let us show that the
product of two topological spaces X, Y , as usually deﬁned, really is a product

38
ABSTRACT STRUCTURES
in Top, the category of spaces and continuous functions. Thus suppose we
have spaces X and Y and the product spaces X × Y with its projections
X
p1
←−X × Y
p2
−→Y
Recall that O(X × Y ) is generated by basic open sets of the form U × V
where U ∈O(X) and V ∈O(Y ), so every W ∈O(X ×Y ) is a union of such
basic opens.
• Clearly p1 is continuous, since p−1
1 U = U × Y .
• Given any continuous f1 : Z →X, f2 : Z →Y, let f : Z →X × Y be
the function f = ⟨f1, f2⟩. We just need to see that f is continuous.
• Given any W = 
i(Ui × Vi) ∈O(X × Y ), f −1(W) = 
i f −1(Ui × Vi),
so it suﬃces to show f −1(U × V ) is open. But
f −1(U × V ) = f −1((U × Y ) ∩(X × V ))
= f −1(U × Y ) ∩f −1(X × V )
= f −1 ◦p−1
1 (U) ∩f −1 ◦p−1
2 (V )
= (f1)−1(U) ∩(f2)−1(V )
where (f1)−1(U) and (f2)−1(V ) are open, since f1 and f2 are
continuous.
The following diagram concisely captures the situation at hand:
O(Z)
	
	
	
	
	
	
f −1
1

I
@
@
@
@
@
@
f −1
2
O(X) p−1
1
- O(X × Y )
f −1
6
.................

p−1
2
O(Y )
6. (For those familiar with type theory.) Let us consider the category of types
of the (simply typed) λ-calculus. The λ–calculus is a formalism for the
speciﬁcation and manipulation of functions, based on the notions of “bind-
ing of variables” and functional evaluation. For example, given the real
polynomial expression x2 + 2y, in the λ-calculus one writes λy.x2 + 2y for
the function y →x2 + 2y (for each ﬁxed value x), and λxλy.x2 + 2y for
the function-valued function x →(y →x2 + 2y).
Formally, the λ-calculus consists of:
• Types: A × B, A →B, . . . (generated from some basic types)
• Terms:
x, y, z, . . . : A
(variables for each type A)
a : A, b : B, . . .
(possibly some typed constants)

EXAMPLES OF PRODUCTS
39
⟨a, b⟩: A × B
(a : A, b : B)
fst(c) : A
(c : A × B)
snd(c) : B
(c : A × B)
ca : B
(c : A →B, a : A)
λx.b : A →B
(x : A, b : B)
• Equations:
fst(⟨a, b⟩) = a
snd(⟨a, b⟩) = b
⟨fst(c), snd(c)⟩= c
(λx.b)a = b[a/x]
λx.cx = c
(no x in c)
The relation a ∼b (usually called βη-equivalence) on terms is deﬁned to be
the equivalence relation generated by the equations, and renaming of bound
variables:
λx.b = λy.b[y/x]
(no y in b)
The category of types C(λ) is now deﬁned as follows:
• objects: the types,
• arrows A →B: closed terms c : A →B, identiﬁed if c ∼c′,
• identities: 1A = λx.x (where x : A),
• composition: c ◦b = λx.c(bx).
Let us verify that this is a well-deﬁned category:
Unit laws:
c ◦1B = λx(c((λy.y)x)) = λx(cx) = c
1C ◦c = λx((λy.y)(cx)) = λx(cx) = c
Associativity:
c ◦(b ◦a) = λx(c((b ◦a)x))
= λx(c((λy.b(ay))x))
= λx(c(b(ax)))
= λx(λy(c(by))(ax))
= λx((c ◦b)(ax))
= (c ◦b) ◦a

40
ABSTRACT STRUCTURES
This category has binary products. Indeed, given types A and B, let
p1 = λz.fst(z),
p2 = λz.snd(z)
(z : A × B).
And given a and b as in
X

	
	
	
	
	
	
a
@
@
@
@
@
@
b
R
A 
p1
A × B
(a, b)
?
.................
p2
- B
let
(a, b) = λx.⟨ax, bx⟩.
Then
p1 ◦(a, b) = λx(p1((λy.⟨ay, by⟩)x))
= λx(p1⟨ax, bx⟩)
= λx(ax)
= a.
Similarly, p2 ◦(a, b) = b.
Finally, if c : X →A × B also has
p1 ◦c = a,
p2 ◦c = b
then
(a, b) = λx.⟨ax, bx⟩
= λx.⟨(p1 ◦c)x, (p2 ◦c)x⟩
= λx.⟨(λy(p1(cy)))x, (λy(p2(cy)))x⟩
= λx.⟨(λy((λz.fst(z))(cy)))x, (λy((λz.snd(z))(cy)))x⟩
= λx.⟨λy(fst(cy))x, λy(snd(cy))x⟩
= λx.⟨fst(cx), snd(cx)⟩
= λx.(cx)
= c.

CATEGORIES WITH PRODUCTS
41
2.7
Categories with products
Let C be a category that has a product diagram for every pair of objects. Suppose
we have objects and arrows
A  p1
A × A′
p2- A′
B
f
?

q1
B × B′
q2
- B′
f ′
?
with indicated products. Then we write
f × f ′ : A × A′ →B × B′
for f ×f ′ = ⟨f ◦p1, f ′◦p2⟩. Thus, both squares in the following diagram commute.
A  p1
A × A′
p2- A′
B
f
?

q1
B × B′
f × f ′
?
................
q2
- B′
f ′
?
In this way, if we choose a product for each pair of objects, we get a functor
× : C × C →C
as the reader can easily check, using the UMP of the product. A category which
has a product for every pair of objects is said to have binary products.
We can also deﬁne ternary products
A1 × A2 × A3
with an analogous UMP (there are three projections pi : A1 × A2 × A3 →Ai,
and for any object X and three arrows xi : X →Ai, there is a unique arrow
u : X →A1 × A2 × A3 such that piu = xi for each of the three i’s.) Plainly, such
a condition can be formulated for any number of factors.
It is clear, however, that if a category has binary products, then it has all
ﬁnite products with two or more factors; for instance, one could set
A × B × C = (A × B) × C
to satisfy the UMP for ternary products. On the other hand, one could instead
have taken A×(B×C) just as well. This shows that the binary product operation

42
ABSTRACT STRUCTURES
A × B is associative up to isomorphism, for we must have
(A × B) × C ∼= A × (B × C)
by the UMP of ternary products.
Observe also that a terminal object is a “null-ary” product, that is, a product
of no objects:
Given no objects, there is an object 1 with no maps, and given any other
object X and no maps, there is a unique arrow
! : X →1
making nothing further commute.
Similarly, any object A is the unary product of A with itself one time.
Finally, one can also deﬁne the product of a family of objects (Ci)i∈I indexed
by any set I, by giving a UMP for “I-ary products” analogous to those for
nullary, unary, binary, and n-ary products. We leave the precise formulation of
this UMP as an exercise.
Deﬁnition 2.19. A category C is said to have all ﬁnite products if it has a
terminal object and all binary products (and therewith products of any ﬁnite
cardinality). The category C has all (small) products if every set of objects in C
has a product.
2.8
Hom-sets
In this section, we assume that all categories are locally small.
Recall that in any category C, given any objects A and B, we write
Hom(A, B) = {f ∈C | f : A →B}
and call such a set of arrows a Hom-set. Note that any arrow g : B →B′ in C
induces a function:
Hom(A, g) : Hom(A, B) →Hom(A, B′)
(f : A →B) →(g ◦f : A →B →B′)
Thus, Hom(A, g) = g ◦f; one sometimes writes g∗instead of Hom(A, g), so
g∗(f) = g ◦f.
Let us show that this determines a functor
Hom(A, −) : C →Sets
called the (covariant) representable functor of A.

HOM-SETS
43
We need to show that
Hom(A, 1X) = 1Hom(A,X)
and that
Hom(A, g ◦f) = Hom(A, g) ◦Hom(A, f).
Taking an argument x : A →X, we clearly have
Hom(A, 1X)(x) = 1X ◦x
= x
= 1Hom(A,X)(x)
and
Hom(A, g ◦f)(x) = (g ◦f) ◦x
= g ◦(f ◦x)
= Hom(A, g)(Hom(A, f)(x)).
We will study such representable functors much more carefully later. For
now we just want to see how one can use Hom-sets to give another deﬁnition of
products.
An object P with arrows p1 : P →A and p2 : P →B is an element (p1, p2)
of the set
Hom(P, A) × Hom(P, B).
And similarly for any set X in place of P. Now, given any arrow
x : X →P
composing with p1 and p2 gives a pair of arrows x1 = p1 ◦x : X →A and
x2 = p2 ◦x : X →B, as indicated in the following diagram.
X

	
	
	
	
	
	
x1
@
@
@
@
@
@
x2
R
A 
p1
P
x
?
p2
- B
In this way, we have a function
ϑX = ⟨Hom(X, p1), Hom(X, p2)⟩: Hom(X, P) →Hom(X, A) × Hom(X, B)
deﬁned by
ϑX(x) = (x1, x2)
(2.1)

44
ABSTRACT STRUCTURES
This function ϑX can be used to express concisely the condition of being a
product as follows.
Proposition 2.20. A diagram of the form
A 
p1
P
p2
- B
is a product for A and B iﬀfor every object X, the canonical function ϑX given
in (2.1) is an isomorphism,
ϑX : Hom(X, P) ∼= Hom(X, A) × Hom(X, B).
Proof. Examine the UMP of the product: it says exactly that for every element
(x1, x2) ∈Hom(X, A) × Hom(X, B), there is a unique x ∈Hom(X, P) such that
ϑX(x) = (x1, x2), that is, ϑX is bijective.
Deﬁnition 2.21. Let C, D be categories with binary products. A functor F :
C →D is said to preserve binary products if it takes every product diagram
A 
p1
A × B
p2
- B
in C
to a product diagram
FA 
Fp1
F(A × B)
Fp2
- FB
in D.
It follows that F preserves products just if
F(A × B) ∼= FA × FB
(canonically)
that is, iﬀthe canonical “comparison arrow”
⟨Fp1, Fp2⟩: F(A × B) →FA × FB
is an iso.
For example, the forgetful functor U : Mon →Sets preserves binary products.
Corollary 2.22. For any object X in a category C with products, the (covari-
ant) representable functor
HomC(X, −) : C →Sets
preserves products.
Proof. For any A, B ∈C, the foregoing proposition says that there is a canonical
isomorphism:
HomC(X, A × B) ∼= HomC(X, A) × HomC(X, B)

EXERCISES
45
2.9
Exercises
1. Show that a function between sets is surjective if it is an epimorphism
in Sets.
2. With regard to a commutative triangle,
A
f
- B
@
@
@
@
@
@
h
RC
g
?
in any category C, show
a. if f and g are isos (resp. monos, resp. epis), so is h;
b. if h is monic, so is f;
c. if h is epic, so is g;
d. (by example) if h is monic, g need not be.
3. Show that all sets are projective (use the axiom of choice). Show that the
epis among posets are the surjections (on objects), and that the one-element
poset 1 is projective. Finally, show that in any category, any retract of a
projective object is also projective.
4. Let A be a set. Deﬁne an A-monoid to be a monoid M equipped with
a function m : A →U(M) (to the underlying set of M). A morphism
h : (M, m) →(N, n) of A-monoids is to be a monoid homomorphism h :
M →N such that U(h) ◦m = n (a commutative triangle). Together with
the evident identities and composites, this deﬁnes a category A −Mon of
A-monoids.
Show that an initial object in A-Mon is the same thing as a free monoid
M(A) on A. (Hint: compare their respective UMPs.)
5. Show that for any Boolean algebra B, Boolean homomorphisms h : B →2
correspond exactly to ultraﬁlters in B.
6. In any category with binary products, show directly that:
A × (B × C) ∼= (A × B) × C.
7.
(a) For any index set I, deﬁne the product 
i∈I Xi of an I-indexed family
of objects (Xi)i∈I in a category, by giving a UMP generalizing that for
binary products (the case I = 2).
(b) Show that in Sets, for any set X the set XI of all functions f : I →X
has this UMP, with respect to the “constant family” where Xi = X
for all i ∈I, and thus
XI ∼=

i∈I
X

This page intentionally left blank 

3
DUALITY
We have seen a few examples of deﬁnitions and statements which exhibit a kind
of “duality,” like initial and terminal object and epimorphisms and monomorph-
isms. We now want to consider this duality more systematically. Despite its
rather trivial ﬁrst impression, it is indeed a deep and powerful aspect of the
categorical approach.
3.1
The duality principle
First, let us look again at the formal deﬁnition of a category: There are two kinds
of things, objects A, B, C and . . . , arrows f, g, h, . . . ; four operations dom(f),
cod(f), 1A, g ◦f; and these satisfy the following seven axioms:
dom(1A) = A,
cod(1A) = A
f ◦1dom(f) = f,
1cod(f) ◦f = f
dom(g ◦f) = dom(f),
cod(g ◦f) = cod(g)
h ◦(g ◦f) = (h ◦g) ◦f
The operation “g ◦f” is only deﬁned where
dom(g) = cod(f),
so a suitable form of this should occur as a condition on each equation containing
◦, as in dom(g) = cod(f) ⇒dom(g ◦f) = dom(f).
Now, given any sentence Σ in the elementary language of category theory, we
can form the “dual statement” Σ∗by making the following replacements:
g ◦f
for
f ◦g
cod
for
dom
dom
for
cod.
It is easy to see that then Σ∗will also be a well-formed sentence. Next, suppose
we have shown a statement Σ to entail one ∆, without using any of the category
axioms, then clearly Σ∗⊢∆∗, since the substituted terms are treated as mere

48
DUALITY
undeﬁned constants. But now observe that the axioms for category theory CT
are themselves “self-dual,” in the sense that we have:
CT∗= CT
We therefore have the following duality principle:
Proposition 3.1 (Formal duality). For any statement Σ in the language of
category theory, if Σ follows from the axioms for categories, then so does Σ∗:
CT ⊢Σ implies CT ⊢Σ∗
Taking a more conceptual point of view, note that if Σ involves some diagram
of objects and arrows,
A
f
- B
@
@
@
@
@
@
g ◦f
RC
g
?
then Σ∗involves the diagram obtained from it by reversing direction and the
order of compositions of arrows.
A 
f
B
I
@
@
@
@
@
@
f ◦g
C
g
6
Recalling the opposite category Cop of a category C, we see that an inter-
pretation of a statement Σ in C automatically gives an interpretation of Σ∗
in Cop.
Now, since for every category C,
(Cop)op = C
(3.1)
the conceptual form of the duality principle then results similarly in
Proposition 3.2 (Conceptual duality). For any statement Σ about categories,
if Σ holds for all categories, then so does the dual statement Σ∗.
Proof. If Σ holds for all categories C, then it also holds in all categories Cop,
but then Σ∗holds in all categories (Cop)op, thus in all categories C.
It may seem that only very simple or trivial properties such as “having a terminal
object” are going to be subject to this sort of duality, but in fact this is far from

COPRODUCTS
49
being so. Categorical duality turns out to be a very powerful and far-reaching
phenomenon, as we shall see later. One way this occurs is that, rather than
considering statements about all categories, we can also consider the dual of
an abstract deﬁnition or property of objects and arrows, like “being a product
diagram.” The dual property is arrived at by reversing the order of composition
and the words “dom” and “cod.” Equivalently, it results from interpreting the
original property in the opposite category. The next section provides an example
of this procedure.
3.2
Coproducts
Let us consider the example of products and see what the dual notion must be.
First, recall the deﬁnition of a product.
Deﬁnition 3.3. A diagram A
p1
←P
p2
→B is a product of A and B, if for any Z
and A
z1
←Z
z2
→B there is a unique u : Z →P with pi ◦u = zi, all as indicated in
Z

	
	
	
	
	
	
z1
@
@
@
@
@
@
z2
R
A 
p1
P
u
?
.................
p2
- B
Now what is the dual statement?
A diagram A
q1
→Q
q2
←B is a “dual-product” of A and B if for any Z and
A
z1
→Z
z2
←B there is a unique u : Q →Z with u ◦qi = zi, all as indicated in
Z
	
	
	
	
	
	
z1

I
@
@
@
@
@
@
z2
A
q1
- Q
u
6
.................

q2
B
Actually, these are called coproducts; the convention is to use the preﬁx “co-” to
indicate the dual notion. We usually write A
i1→A + B
i2←B for the coproduct
and [f, g] for the uniquely determined arrow u : A + B →Z. The “coprojections”
i1 : A →A + B and i2 : B →A + B are usually called injections, even though
they need not be “injective” in any sense.
A coproduct of two objects is therefore exactly their product in the opposite
category. Of course, this immediately gives lots of examples of coproducts. But
what about some more familiar ones?

50
DUALITY
Example 3.4. In Sets, the coproduct A + B of two sets is their disjoint union,
A + B = {(a, 1) | a ∈A} ∪{(b, 2) | b ∈B}
with evident coproduct injections
i1(a) = (a, 1),
i2(b) = (b, 2).
Given any functions f and g as in:
Z
	
	
	
	
	
	
f

I
@
@
@
@
@
@
g
A
i1
- A + B
[f, g]
6
.................

i2
B
we deﬁne
[f, g](x, δ) =

f(x)
δ = 1
g(x)
δ = 2.
If, in addition, h ◦i1 = f and h ◦i2 = g, then for any (x, δ) ∈A + B, we must
have
h(x, δ) = [f, g](x, δ)
as can be easily calculated.
Note that in Sets, every ﬁnite set A is a coproduct:
A ∼= 1 + 1 + · · · + 1 (n-times)
for n = card(A). This is because a function f : A →Z is uniquely determined
by its values f(a) for all a ∈A. So we have
A ∼= {a1} + {an} + · · · + {an}
∼= 1 + 1 + · · · + 1 (n-times).
In this spirit, we often write simply 2 = 1 + 1, 3 = 1 + 1 + 1, etc.
Example 3.5. If M(A) and M(B) are free monoids on sets A and B, then in
Mon we can construct their coproduct as
M(A) + M(B) ∼= M(A + B).

COPRODUCTS
51
One can see this directly by considering words over A + B, but it also follows
abstractly by using the diagram
N
	
	
	
	
	
	

I
@
@
@
@
@
@
M(A)
- M(A + B)
6
.................

M(B)
A
ηA
6
- A + B
ηA+B
6

B
ηB
6
in which the η’s are the respective insertions of generators. The UMPs of M(A),
M(B), A + B, and M(A + B) then imply that the last of these has the required
UMP of M(A) + M(B).
It follows that the free monoid functor M : Sets →Mon preserves coprod-
ucts. This is an instance of a much more general phenomenon, which we will
consider later, related to the fact we have already seen that the forgetful functor
U : Mon →Sets is representable and so preserves products.
Example 3.6. In Top the coproduct of two spaces
X + Y
is their disjoint union with the topology O(X + Y ) ∼= O(X) × O(Y ). Note that
this follows the pattern of discrete spaces, for which O(X) = P(X) ∼= 2X. Thus,
for discrete spaces we indeed have
O(X + Y ) ∼= 2X+Y ∼= 2X × 2Y ∼= O(X) × O(Y ).
Coproducts of posets are similarly constructed from the coproducts of the under-
lying sets, by “putting them side by side.” What about “rooted” posets, that
is, posets with a distinguished initial element 0? In the category Pos0 of such
posets and monotone maps that preserve 0, one constructs the coproduct of two
such posets A and B from the coproduct A + B in the category Pos of posets,
by identifying the two diﬀerent 0s,
A + Pos0B = (A + PosB)/(0A = 0B).
Example 3.7. In a ﬁxed poset P, what is a coproduct of two elements p, q ∈P ?
We have
p ≤p + q
and
q ≤p + q
and if
p ≤z
and
q ≤z

52
DUALITY
then
p + q ≤z.
So p + q = p ∨q is the join, or “least upper bound,” of p and q.
Example 3.8. Sum types in the λ-calculus as usually formulated using case terms
are coproducts in the category of types deﬁned in subsection 2.6.
Example 3.9. Coproduct of monoids
Two monoids A, B have a coproduct of the form
A + B = M(|A| + |B|)/ ∼
where, as before, the free monoid M(|A| + |B|) is strings (words) over the dis-
joint union |A| + |B| of the underlying sets—the elements of A and B—and the
equivalence relation v ∼w is the least one containing the following equations
uA = (−) = uB
(. . . aa′ . . .) = (. . . a · a′ . . .)
(. . . bb′ . . .) = (. . . b · b′ . . .).
(If you need a refresher on quotienting a set by an equivalence relation, skip
ahead and read the beginning of Section 3.4 now.) The unit is of course the
equivalence class [−] of the empty word. Multiplication of equivalence classes is
also as expected, namely
[x . . . y] · [x′ . . . y′] = [x . . . yx′ . . . y′].
The coproduct injections iA : A →A + B and iB : B →A + B are simply:
iA(a) = [a],
iB(b) = [b].
Given any homomorphism f : A →M and g : B →M into a monoid M, the
unique homomorphism
[f, g] : A + B −→M
is deﬁned by ﬁrst lifting the function [|f|, |g|] : |A| + |B| →|M| to the free
monoid M(|A| + |B|), and then observing that if v ∼w in M(|A| + |B|), then
[|f|, |g|](v) = [|f|, |g|](w). Why is this homomorphism the unique one
h : M(|A| + |B|)/∼−→M
with hiA = f and hiB = g ?
This construction also works to give coproducts in Groups, where it is
usually called the free product of A and B and written A ⊕B.
Example 3.10. For abelian groups A, B, the free product A ⊕B need not be
abelian. One could, of course, take a quotient of A ⊕B to get a coproduct in the

COPRODUCTS
53
category Ab of abelian groups, but there is a more convenient (and important)
presentation, which we now consider.
Since the words in the free product A⊕B must be forced to satisfy the further
commutativity conditions
(a1b1b2a2 . . .) ∼(a1a2 . . . b1b2 . . .)
we can shuﬄe all the a’s to the front, and the b’s to the back, of the words. But,
furthermore, we already have
(a1a2 . . . b1b2 . . .) ∼(a1 + a2 + · · · + b1 + b2 + · · · ).
Thus, we in eﬀect have pairs of elements (a, b). So we take the product set as
the underlying set of the coproduct
|A + B| = |A × B|.
As inclusions, we use the homomorphisms
iA(a) = (a, 0B)
iB(b) = (0A, b).
Then given any homomorphisms A
f→X
g←B, we let [f, g] : A + B →X be
deﬁned by
[f, g](a, b) = f(a) +X g(b)
which can easily be seen to do the trick (exercise!).
Proposition 3.11. In the category Ab of abelian groups, there is a canonical
isomorphism between the binary coproduct and product,
A + B ∼= A × B.
Proof. To deﬁne an arrow ϑ : A + B →A × B we need one A →A × B (and one
B →A × B), so we need arrows A →A and A →B (and B →A and B →B).
For these we take 1A : A →A and the zero homomorphism 0B : A →B (and
0A : B →A and 1B : B →B). Thus, all together we get
ϑ = [⟨1A, 0B⟩, ⟨0A, 1B⟩] : A + B →A × B.
Then given any (a, b) ∈A + B, we have
ϑ(a, b) = [⟨1A, 0B⟩, ⟨0A, 1B⟩](a, b)
= ⟨1A, 0B⟩(a) + ⟨0A, 1B⟩(b)
= (1A(a), 0B(a)) + (0A(b), 1B(b))
= (a, 0B) + (0A, b)
= (a + 0A, 0B + b)
= (a, b).

54
DUALITY
This fact was ﬁrst observed by Mac Lane, and it was shown to lead to a
binary operation of addition on parallel arrows f, g : A →B between abelian
groups (and related structures like modules and vector spaces). In fact, the group
structure of a particular abelian group A can be recovered from this operation
on arrows into A. More generally, the existence of such an addition operation on
arrows can be used as the basis of an abstract description of categories like Ab,
called “abelian categories,” which are suitable for axiomatic homology theory.
Just as with products, one can consider the empty coproduct, which is an
initial object 0, as well as coproducts of several factors, and the coproduct of
two arrows,
f + f ′ : A + A′ →B + B′
which leads to a coproduct functor + : C × C →C on categories C with binary
coproducts. All of these facts follows simply by duality; that is, by consider-
ing the dual notions in the opposite category. Similarly, we have the following
proposition.
Proposition 3.12. Coproducts are unique up to isomorphism.
Proof. Use duality and the fact that the dual of “isomorphism” is “isomorphism.”
In just the same way, one shows that binary coproducts are associative up to
isomorphism, (A + B) + C ∼= A + (B + C).
In this way, in the future it will thus suﬃce to introduce new notions and
then simply observe that the dual notions have analogous (but dual) properties.
The next two sections give another example of this sort.
3.3
Equalizers
In this section, we consider another abstract characterization; this time a gener-
alization of the idea of the kernel of a homomorphism or an equationally deﬁned
“variety,” like the set of zeros of a real-valued function.
Deﬁnition 3.13. In any category C, given parallel arrows
A
f
-
g
- B
an equalizer of f and g consists of E and e : E →A, universal such that
f ◦e = g ◦e.

EQUALIZERS
55
That is, given z : Z →A with f ◦z = g ◦z there is a unique u : Z →E with
e ◦u = z, all as in the diagram
E
e
- A
f
-
g
- B
	
	
	
	
	
	
z

Z
u
6
.................
Let us consider some simple examples.
Example 3.14. In Sets, given functions f, g : A ⇒B, their equalizer is the
inclusion into A of the equationally deﬁned subset
i : {x ∈A|f(x) = g(x)} →A.
Since if fh(z) = gh(z) for some h : Z →A, then h(z) ∈{x ∈A|f(x) = g(x)} for
all z ∈Z, whence h “factors through” the inclusion function i, in the sense that
there is a function ¯h : Z →{x ∈A|f(x) = g(x)} such that i ◦¯h = h. Observe
that ¯h is necessarily unique with this property, since i is monic.
Let us pause here to note that in fact, every subset U ⊆A is of this “equa-
tional” form, that is, is an equalizer for some pair of functions. Indeed, one can
do this in a very canonical way; ﬁrst let us put
2 = {⊤, ⊥}.
Then consider the characteristic function
χU : A →2
deﬁned for x ∈A by
χU(x) =

⊤
x ∈U
⊥
x /∈U.
Thus we have
U = {x ∈A | χU(x) = ⊤}.
So the following is an equalizer
U
- A
⊤! -
χU
- 2
where ⊤! = ⊤◦! : U
!→1
⊤
→2.
Moreover, for every function,
ϕ : A →2

56
DUALITY
we can form the “variety” (i.e. equational subset)
Vϕ = {x ∈A | ϕ(x) = ⊤}
as an equalizer, in the same way.
Now, it is easy to see that these operations χU and Vϕ are mutually inverse:
VχU = {x ∈A|χU(x) = ⊤}
= {x ∈A|x ∈U}
= U
and given ϕ : A →2,
χVϕ(x) =

⊤
x ∈Vϕ
⊥
x /∈Vϕ
=

⊤
ϕ(x) = ⊤
⊥
ϕ(x) = ⊥
= ϕ(x).
Therefore, we have an isomorphism
Hom(A, 2) ∼= P(A)
via the maps V and χ.
The fact that equalizers of functions can be taken as subsets is a special case of
a more general phenomenon:
Proposition 3.15. In any category, if e : E →A is an equalizer of some pair
of arrows, then e is monic.
Proof. Consider the diagram:
E
e
- A
f
-
g
- B
	
	
	
	
	
	
z

Z
x
6
y
6
in which we assume e is the equalizer of f and g. Supposing ex = ey, we want
to show x = y. Put z = ex = ey. Then fz = fex = gex = gz, so there is a
unique u : Z →E such that eu = z. But from ex = z and ey = z, it follows that
x = u = y.
Example 3.16. In many other categories, such as posets and monoids, the equal-
izer of a parallel pair of arrows f, g : A ⇒B can be constructed by taking the
equalizer of the underlying functions as above, that is, the subset A(f = g) ⊆A

COEQUALIZERS
57
of elements x ∈A where f and g agree, f(x) = g(x), and then restricting the
structure of A to A(f = g). For instance, in posets one takes the ordering from
A restricted to this subset A(f = g), and in topological spaces one takes the
subspace topology.
In monoids, the subset A(f = g) is then also a monoid with the operations
from A, and the inclusion is therefore a homomorphism, because f(uA) = uB =
g(uA), and if f(a) = g(a) and f(a′) = g(a′), then f(a · a′) = f(a) · f(a′) =
g(a) · g(a′) = g(a · a′).
In abelian groups, one has an alternate description of the equalizer, using the
fact that,
f(x) = g(x)
iﬀ
(f −g)(x) = 0.
Thus the equalizer of f and g is the same as that of the homomorphism (f −g)
and the zero homomorphism 0 : A →B, so it suﬃces to consider equalizers
of the special form A(h, 0) ↣A for arbitrary homomorphisms h : A →B.
This subgroup of A is called the kernel of h, written ker(h). Thus we have the
equalizer:
ker(f −g) ⊂
- A
f
-
g
- B
The kernel of a homomorphism is of fundamental importance in the study of
groups.
3.4
Coequalizers
A coequalizer is a generalization of a quotient by an equivalence relation, so let
us begin by reviewing that notion. Recall ﬁrst that an equivalence relation on a
set X is a binary relation x ∼y which is
reﬂexive: x ∼x,
symmetric: x ∼y implies y ∼x,
transitive: x ∼y and y ∼z implies x ∼z.
Given such a relation, deﬁne the equivalence class [x] of an element x ∈X by
[x] = {y ∈X| x ∼y}.
The various diﬀerent equivalence classes [x] then form a partition of X, in the
sense that every element y is in exactly one of them, namely [y] (prove this!).
One sometimes thinks of an equivalence relation as arising from the equivalent
elements having some property in common (like being the same color). One can
then regard the equivalence classes [x] as the properties and in that sense as
“abstract objects” (the colors red, blue, etc., themselves). This is sometimes
known as “deﬁnition by abstraction,” and it describes the way that the real

58
DUALITY
numbers can be constructed from Cauchy sequences of rationals or the ﬁnite
cardinal numbers from ﬁnite sets.
The set of all equivalence classes
X/∼= {[x] | x ∈X}
may be called the quotient of X by ∼. It is used in place of X when one wants to
“abstract away” the diﬀerence between equivalent elements x ∼y, in the sense
that in X/∼such elements (and only such) are identiﬁed, since
[x] = [y]
iﬀ
x ∼y.
Now let us consider the notion dual to that of equalizer, namely that of a
coequalizer.
Deﬁnition 3.17. For any parallel arrows f, g : A →B in a category C, a
coequalizer consists of Q and q : B →Q, universal with the property qf = qg,
as in:
A
f
-
g
- B
q
- Q
@
@
@
@
@
@
z
RZ
u
?
................
That is, given any Z and z : B →Z, if zf = zg, then there exists a unique
u : Q →Z such that uq = z.
First observe that by duality, we know that such a coequalizer q in a category
C is an equalizer in Cop, hence monic by the last proposition, and so q is epic
in C.
Proposition 3.18. If q : B →Q is a coequalizer of some pair of arrows, then
q is epic.
Example 3.19. Let R ⊆X×X be an equivalence relation on a set X, and consider
the diagram
R
r1 -
r2
- X

COEQUALIZERS
59
where the r’s are the two projections of the inclusion i : R ⊆X ×X, as indicated
in the diagram
R ⊂
i - X × X
@
@
@
@
@
@
rk
R
X
pk
?
The canonical projection
π : X −→X/R
deﬁned by x →[x] is then a coequalizer of r1 and r2. For given an f : X →Y
as in:
R
r1 -
r2
- X
π - X/R
@
@
@
@
@
@
f
R
Y
¯f
?
..................
there exists a function ¯f such that
¯fπ(x) = f(x)
just in case f “respects R” in the sense that
(x, x′) ∈R
implies
f(x) = f(x′).
But this condition just says that fr1 = fr2, since fr1(x, x′) = f(x) and
fr2(x, x′) = f(x′) for all (x, x′) ∈R. Moreover, such a function ¯f, if it exists, is
then necessarily unique, since π is an epimorphism.
The coequalizer in Sets of an arbitrary parallel pair of functions f, g : A ⇒B
can be constructed by quotienting B by the equivalence relation generated by
the equations f(x) = g(x) for all x ∈A. We leave the details as an exercise.
Example 3.20. Presentations of algebras
Consider a category of “algebras”—say, monoids or groups—that has free algeb-
ras for all sets and coequalizers for all parallel pairs of arrows (see the exercises
for a proof that monoids have coequalizers). We can use these to determine the
notion of a presentation of an algebra by generators and relations.

60
DUALITY
For example, suppose we are given:
Generators: x, y, z
Relations: xy = z, y2 = 1
To build an algebra on these generators and satisfying these relations, start
with
F(3) = F(x, y, z)
and then “force” the relation xy = z by taking a coequalizer of the maps
F(1)
xy-
z
- F(3)
q - Q
We use the fact that maps F(1) →A correspond to elements a ∈A by v →a,
where v is the single generator of F(1). Now similarly, for the equation y2 = 1,
take the coequalizer:
F(1)
q(y2)-
q(1)
- Q
- Q′
These two steps can actually be done simultaneously; let
F(2) = F(1) + F(1)
F(2)
f -
g
- F(3)
where f = [xy, y2] and g = [z, 1]. The coequalizer q : F(3) →Q of f and g then
“forces” both equations to hold, in the sense that in Q we have
q(x)q(y) = q(z),
q(y)2 = 1.
Moreover, no other relations among the generators hold in Q except those
required to hold by the stipulated equations. For, given any algebra A and any
three elements a, b, c ∈A such that ab = c and b2 = 1, by the UMP of Q there
is a unique homomorphism u : Q →A such that
u(x) = a,
u(y) = b,
u(z) = c.
Thus any other equation that holds among the generators will also hold in any
other algebra in which the stipulated equations hold, since the homomorphism
u also preserves equations. In this sense, Q is the “universal” algebra with three
generators satisfying the stipulated equations; as may be written suggestively in
the form
Q ∼= F(x, y, z)/(xy = z, y2 = 1).

COEQUALIZERS
61
Generally, given a ﬁnite presentation:
Generators: g1, . . . , gn
Relations: l1 = r1, . . . , lm = rm
the algebra with that presentation is the coequalizer
F(m)
l -
r
- F(n)
- Q = F(n)/(l = r)
where l = [l1, . . . , lm] and r = [r1, . . . , rm]. Such algebras are said to be ﬁnitely
presented.
Warning 3.21. Presentations are not unique. One may well have two diﬀerent
presentations F(n)/(l = r) and F(n′)/(l′ = r′) by generators and relations of
the same algebra,
F(n)/(l = r) ∼= F(n′)/(l′ = r′).
For instance, given F(n)/(l = r) add a new generator gn+1 and the new rela-
tion gn = gn+1. In general, there are many diﬀerent ways of presenting a given
algebra, just like there are many ways of axiomatizing a logical theory.
We did not really make use of the ﬁniteness condition in the foregoing consider-
ations. Indeed, any sets of generators G and relations R give rise to an algebra
in the same way, by taking the coequalizer
F(R)
r1-
r2
- F(G)
- F(G)/(r1 = r2).
In fact, every “algebra” can be “presented” by generators and relations in
this way, given a suitable notion of an “algebra.” More precisely, we have the
following proposition for monoids, an analogous version of which also holds for
groups, and many related structures.
Proposition 3.22. For every monoid M there are sets G and R and a
coequalizer diagram,
F(R)
r1-
r2
- F(G)
- M
with F(G) and F(R) free, thus M ∼= F(G)/(r1 = r2).
Proof. For any monoid N, let us write TN = M(|N|) for the free monoid on
the set of elements of N (and note that T is therefore a functor). There is a
homomorphism,
π : TN →N
π(x1, . . . , xn) = x1 · . . . · xn
induced by the identity 1|N| : |N| →|N| on the generators. (Here we are writing
the elements of TN as tuples (x1, . . . , xn) rather than strings x1 . . . xn for clarity.)

62
DUALITY
Applying this construction twice to a monoid M results in the arrows π and ε
in the following diagram,
T 2M
ε -
µ
- TM
π
- M
(3.2)
where T 2M
= TTM and µ = Tπ. Explicitly, the elements of T 2M are
tuples of tuples of elements of M, say ((x1, . . . , xn), . . . , (z1, . . . , zm)), and the
homomorphisms ε and µ have the eﬀect:
ε((x1, . . . , xn), . . . , (z1, . . . , zm)) = (x1, . . . , xn, . . . , z1, . . . , zm)
µ((x1, . . . , xn), . . . , (z1, . . . , zm)) = (x1 · . . . · xn, . . . , z1 · . . . · zm)
Brieﬂy, ε uses the multiplication in TM and µ uses that in M.
We claim that (3.2) is a coequalizer of monoids. To that end, suppose we
have a monoid N and a homomorphism h : TM →N with hε = hµ. Then for
any tuple (x, . . . , z) we have
h(x, . . . , z) = hε((x, . . . , z))
= hµ((x, . . . , z))
= h(x · · · · · z).
(3.3)
Now deﬁne ¯h = h ◦i, where i : |M| →|TM| is the insertion of generators as
indicated in the following:
T 2
ε -
µ
- TM
π -
.......
i
......... M
@
@
@
@
@
@
h
R
N
h ◦i
?
We then have:
¯hπ(x, . . . , z) = hiπ(x, . . . , z)
= h(x · . . . · z)
= h(x, . . . , z)
by (3.3)
We leave it as an easy exercise for the reader to show that ¯h is a
homomorphism.

EXERCISES
63
3.5
Exercises
1.
(a) In any category C, show that
A
c1
- C 
c2
B
is a coproduct diagram just if for every object Z, the map
Hom(C, Z) −→Hom(A, Z) × Hom(B, Z)
f −→
⟨f ◦c1, f ◦c2⟩
is an isomorphism. If you do this by using duality, you may take the
corresponding fact about products as given.
(b) If you proved the ﬁrst part directly, prove the corresponding fact about
products by using duality.
2. Show that the category Ab of abelian groups (xy = yx) has all equalizers.
3. In the proof of Proposition 3.22 in the text it is shown that any monoid
M has a speciﬁc presentation T 2M ⇒TM →M as a coequalizer of free
monoids. Show that coequalizers of this particular form are preserved by
the forgetful functor Mon →Sets.
4. Prove that Sets has all coequalizers by constructing the coequalizer of a
parallel pair of functions,
A
f
-
g
- B
- Q = B/(f = g)
by quotienting B by a suitable equivalence relation R on B, generated by
the pairs (f(x), g(x)) for all x ∈A. (Deﬁne R to be the intersection of all
equivalence relations on B containing all such pairs.)
5. Show that the category of monoids has all coequalizers.
6. Consider the category of sets.
(a) Given a function f : A →B, describe the equalizer of the functions
f ◦p1, f ◦p2 : A × A →B as a (binary) relation on A and show that
it is an equivalence relation (called the kernel of f).
(b) Show that the kernel of the quotient A →A/R by an equivalence
relation R is R itself.

64
DUALITY
(c) Given any binary relation R ⊆A × A, let ⟨R⟩be the equivalence
relation on A generated by R (the least equivalence relation on A
containing R). Show that the quotient A →A/⟨R⟩is the coequalizer
of the two projections R ⇒A.
(d) Using the foregoing, show that for any binary relation R on a set A,
one can characterize the equivalence relation ⟨R⟩generated by R as
the kernel of the coequalizer of the two projections of R.

4
GROUPS AND CATEGORIES
This chapter is devoted to some of the various connections between groups and
categories. If you already know the basic group theory covered here, then this
will give you some insight into the categorical constructions we have learned so
far; and if you do not know it yet, then you will learn it now as an application
of category theory. We will focus on three diﬀerent aspects of the relationship
between categories and groups:
1. groups in a category,
2. the category of groups,
3. groups as categories.
4.1
Groups in a category
As we have already seen, the notion of a group arises as an abstraction of the
automorphisms of an object. In a speciﬁc, concrete case, a group G may thus
consist of certain arrows g : X →X for some object X in a category C,
G ⊆HomC(X, X)
But the abstract group concept can also described directly as an object in a
category, equipped with a certain structure. This more subtle notion of a “group
in a category” also proves to be quite useful.
Let C be a category with ﬁnite products. The notion of a group in C
essentially generalizes the usual notion of a group in Sets.
Deﬁnition 4.1. A group in C consists of objects and arrows as so:
G × G
m - G 
i
G
1
u
6

66
GROUPS AND CATEGORIES
satisfying the following conditions:
1. m is associative, that is, the following commutes:
(G × G) × G
∼=
- G × (G × G)
G × G
m × 1
?
G × G
1 × m
?
@
@
@
@
@
@
m
R

	
	
	
	
	
	
m
G
where ∼= is the canonical associativity isomorphism for products.
2. u is a unit for m, that is, both triangles in the following commute:
G
⟨u, 1G⟩- G × G
@
@
@
@
@
@
1G
R
G × G
⟨1G, u⟩
?
m
- G
m
?
where we write u for the “constant arrow” u! : G
!→1
u→G.
3. i is an inverse with respect to m, that is, both sides of this commute:
G × G  ∆
G
∆- G × G
G × G
1G × i
?
m
- G
u
?

m
G × G
i × 1G
?
where ∆= ⟨1G, 1G⟩.
Note that the requirement that these diagrams commute is equivalent to the
more familiar condition that, for all (generalized) elements,
x, y, z : Z →G
the following equations hold:
m(m(x, y), z) = m(x, m(y, z))
m(x, u) = x = m(u, x)
m(x, ix) = u = m(ix, x)

GROUPS IN A CATEGORY
67
Deﬁnition 4.2. A homomorphism h : G →H of groups in C consists of an
arrow in C,
h : G →H
such that
1. h preserves m:
G × G h × h
- H × H
G
m
?
h
- H
m
?
2. h preserves u:
G
h
- H
	
	
	
	
	
	
u

1
u
6
3. h preserves i:
G
h
- H
G
i
?
h
- H
i
?
With the evident identities and composites, we thus have a category of groups
in C, denoted:
Group(C)
Example 4.3. The idea of a group in a category captures the familiar notion of
a group with additional structure.
• A group in the usual sense is a group in the category Sets.
• A topological group is a group in Top, the category of topological spaces.
• A (partially) ordered group is a group in the category Pos of posets (in
this case the inverse operation is usually required to be order-reversing, that
is, of the form i : Gop →G).

68
GROUPS AND CATEGORIES
For example, the real numbers R under addition are a topological and an
ordered group, since the operations of addition x + y and additive inverse −x
are continuous and order-preserving (resp. reversing). They are a topological
“semigroup” under multiplication x · y as well, but the multiplicative inverse
operation 1/x is not continuous (or even deﬁned!) at 0.
In logical terms, according to this point of view one can “model the theory
of groups” in any category with ﬁnite products, not just Sets. Of course the
same is true for other theories—like monoids and rings—given by operations
and equations. Thus, for instance, one can also deﬁne the notion of a group in
the lambda-calculus, since the category of types of the lambda-calculus also has
ﬁnite products. Theories involving other logical operations like quantiﬁers can be
modeled in categories having more structure than just ﬁnite products. Here we
have a glimpse of so-called categorical semantics. Such semantics can be useful
for theories that are not complete with respect to models in Sets, such as certain
theories in intuitionistic logic.
4.2
The category of groups
Let G and H be groups (in Sets), and let
h : G →H
be a group homomorphism. The kernel of h is deﬁned by the equalizer
ker(h) = {g ∈G | h(g) = u}
- G
h
-
u
- H
where, again, we write u : G →H for the constant homomorphism
u! = G
!→1
u→H.
We have already seen that this speciﬁcation makes the above an equalizer
diagram.
Observe that ker(h) is a subgroup. Indeed, it is a normal subgroup, in the
sense that for any k ∈ker(h), we have (using multiplicative notation)
g · k · g−1 ∈ker(h)
for all g ∈G.
Now if N
i↣G is any normal subgroup, we can construct the coequalizer
N
i
-
u
- G
π - G/N
sending g ∈G to u iﬀg ∈N (“killing oﬀN”), as follows: the elements of G/N
are the “cosets of N,” that is, equivalence classes of the form [g] for all g ∈G,
where we deﬁne
g ∼h
iﬀ
g · h−1 ∈N.

THE CATEGORY OF GROUPS
69
(Prove that this is an equivalence relation!) The multiplication on the factor
group G/N is then given by
[g] · [g′] = [g · g′]
which is well deﬁned since N is normal (proof!).
Let us show that the diagram above really is a coequalizer. First, it is clear
that
π ◦i = π ◦u!
since n · u = n implies [n] = [u]. Suppose we have f : G →H killing N, that is,
f(n) = u for all n ∈N. We then propose a “factorization” ¯f, as indicated in
G
f
- H
..................
¯f

G/N
π
?
to be deﬁned by
¯f[g] = f(g).
This will be well deﬁned if x ∼y implies f(x) = f(y). But, since x ∼y implies
f(x · y−1) = u, we have
f(x) = f(x · y−1 · y) = f(x · y−1) · f(y) = u · f(y) = f(y).
Moreover, ¯f is unique with π ¯f = f, since π is epic. Thus, we’ve shown most of
the following classical Homomorphism Theorem for Groups.
Theorem 4.4. Every group homomorphism h : G →H has a kernel ker(h) =
h−1(u), which is a normal subgroup of G with the property that, for any normal
subgroup N ⊆G
N ⊆ker(h)
iff there is a (necessarily unique) homomorphism ¯h : G/N →H with ¯h ◦π = h,
as indicated in:
G
h
- H
..................
¯h

G/N
π
?

70
GROUPS AND CATEGORIES
Proof. It
only
remains
to
show
that
if
such
a
factorization
¯h
exists,
then N ⊆ker(h). But this is clear, since π(N) = {[uG]}. So h(n) = ¯hπ(n) =
¯h([n]) = uH.
Finally, putting N = ker(h) in the theorem and taking any [x], [y] ∈G/ker(h),
we have
¯h[x] = ¯h[y] ⇒h(x) = h(y)
⇒h(xy−1) = u
⇒xy−1 ∈ker(h)
⇒x ∼y
⇒[x] = [y].
Thus, ¯h is injective and we have
Corollary 4.5. Every group homomorphism h : G →H factors as a quotient
followed by an injective homomorphism,
G
h
- H
	
	
	
	
	
	
¯h

G/ ker h
π
?
Thus ¯h : G/ker(h)
∼
→im(h) ⊆H is an isomorphism onto the subgroup im(h)
that is the image of h.
In particular, therefore, a homomorphism h is injective if and only if its
kernel is “trivial,” in the sense that ker(h) = {u}.
4.3
Groups as categories
First, let us recall that a group is a category. In particular, a group is a category
with one object, in which every arrow is an iso.
If G and H are groups, regarded as categories, then we can consider arbitrary
functors between them
f : G →H.
It is easy to see that a functor between groups is exactly the same thing as a
group homomorphism.
What is a functor R : G →C from a group G to another category C that is
not necessarily a group? If C is the category of vector spaces and linear trans-
formations, then such a functor is just what the group theorist calls a “linear

GROUPS AS CATEGORIES
71
representation” of G. In general, such a functor R : G →C may be regarded as
a representation of G in C.
We will now generalize the notions of kernel of a homomorphism, and quotient
or factor group by a normal subgroup, from groups to arbitrary categories, and
then give the analogous homomorphism theorem for categories.
Deﬁnition 4.6. A congruence on a category C is an equivalence relation f ∼g
on arrows such that:
1. f ∼g implies dom(f) = dom(g) and cod(f) = cod(g),
•
f
-
g
- •
2. f ∼g implies bfa ∼bga for all arrows a : A →X and b : Y →B, where
dom(f) = X = dom(g) and cod(f) = Y = cod(g),
•
a
- •
f
-
g
- •
b
- •
Let ∼be a congruence on the category C, and deﬁne the congruence
category C∼by:
(C∼)0 = C0
(C∼)1 = {⟨f, g⟩|f ∼g}
∼
1C = ⟨1C, 1C⟩
⟨f ′, g′⟩◦⟨f, g⟩= ⟨f ′f, g′g⟩
One easily checks that this composition is well deﬁned, using the congruence
conditions.
There are two evident projection functors:
C∼
p1 -
p2
- C
We build the quotient category C/∼as follows:
(C/∼)0 = C0
(C/∼)1 = (C1)/∼
The arrows have the form [f] where f ∈C1, and we can put 1[C] = [1C], and
[g] ◦[f] = [g ◦f], as is easily checked, again using the congruence conditions.
There is an evident quotient functor π : C →C/ ∼. It then makes the
following a coequalizer of categories:
C∼
p1 -
p2
- C
π - C/∼
This is proved much as for groups.

72
GROUPS AND CATEGORIES
An exercise shows how to use this construction to make coequalizers for
certain functors. Let us show how to use it to prove an analogous “homomorphism
theorem for categories.” Suppose we have categories C and D and a functor
F : C →D.
Then F determines a congruence ∼F on C by setting:
f ∼F g
iﬀ
dom(f) = dom(g), cod(f) = cod(g), F(f) = F(g)
That this is a congruence is easily checked.
Let us write
ker(F) = C∼F
-
- C
for the congruence category, and call this the kernel category of F.
The quotient category
C/∼F
then has the following UMP:
Theorem 4.7. Every functor F : C →D has a kernel category ker(F), deter-
mined by a congruence ∼F on C such that given any congruence ∼on C
one has:
f ∼g ⇒f ∼F g
if and only if there is a factorization F : C/∼−→D, as indicated in:
C
F
- D
..................
F

C/ ∼
π
?
Just as in the case of groups, applying the theorem to the case C∼= ker(F)
gives a factorization theorem:
Corollary 4.8. Every functor F : C →D factors as F = F ◦π,
C
F
- D
	
	
	
	
	
	
F

C/ ker(F)
π
?

FINITELY PRESENTED CATEGORIES
73
where π is bijective on objects and surjective on Hom-sets, and F is injective on
Hom-sets (i.e. “ faithful”):
FA,B : Hom(A, B) ↣Hom(FA, FB)
for all A, B ∈C/ ker(F)
4.4
Finitely presented categories
Finally, let us consider categories presented by generators and relations.
We begin with the free category C(G) on some ﬁnite graph G, and then
consider a ﬁnite set Σ of relations of the form
(g1 ◦. . . ◦gn) = (g′
1 ◦. . . ◦g′
m)
with all gi ∈G, and dom(gn) = dom(g′
m) and cod(g1) = cod(g′
1). Such a relation
identiﬁes two “paths” in C(G) with the same “endpoints” and “direction.” Next,
let ∼Σ be the smallest congruence ∼on C such that f ∼f ′ for each equation
g = g′ in Σ. Such a congruence exists simply because the intersection of a family
of congruences is again a congruence. Taking the quotient by this congruence we
have a notion of a ﬁnitely presented category:
C(G, Σ) = C(G)/∼Σ
This is completely analogous to the notion of a ﬁnite presentation for groups,
and indeed specializes to that notion in the case of a graph with only one vertex.
The UMP of C(G, Σ) is then an obvious variant of that already given for groups.
Speciﬁcally, in C(G, Σ) there is a “diagram of type G,” that is, a graph
homomorphism i : G →|C(G, Σ)|, satisfying all the conditions i(g) = i(g′), for
all g = g′ ∈Σ. Moreover, given any category D with a diagram of type G, say
h : G →|D|, that satisﬁes all the conditions h(g) = h(g′), for all g = g′ ∈Σ,
there is a unique functor ¯h : C(G, Σ) →D with |¯h| ◦i = h. The reader should
draw the associated diagram of graphs and categories.
Just as in the case of presentations of groups, one can describe the
construction of C(G, Σ) as a coequalizer for two functors.
Indeed, suppose we have arrows f, f ′ ∈C. Take the least congruence ∼on
C with f ∼f ′. Consider the diagram
C(2)
f -
f ′ - C
q - C/∼
where 2 is the graph with two vertices and an edge between them, f and f ′ are
the unique functors taking the generating edge to the arrows by the same names,
and q is the canonical functor to the quotient category. Then q is a coequalizer
of f and f ′. To show this, take any d : C →D with
df = df ′.

74
GROUPS AND CATEGORIES
Since C(2) is free on ·
x→·, and f(x) = f and f ′(x) = f ′, we have
d(f) = d(f(x)) = d(f ′(x)) = d(f ′).
Thus, ⟨f, f ′⟩∈ker(d), so ∼⊆ker(d) (since ∼is minimal with f ∼f ′). So there
is a functor ¯d : C/∼→D such that d = ¯d ◦q by the homomorphism theorem.
Example 4.9. The category with two uniquely isomorphic objects is not free on
any graph, since it’s ﬁnite, but has “loops” (cycles). But it is ﬁnitely presented
with graph
A
f
-

g
B
and relations
gf = 1A,
fg = 1B.
Similarly, there are ﬁnitely presented categories with just one non-identity
arrow f : · →· and either
f ◦f = 1
or
f ◦f = f.
In the ﬁrst case we have the group Z/2Z. In the second case an “idempotent”
(but not a group).
Indeed, any of the cyclic groups
Zn ∼= Z/Zn
occur in this way, with the graph
⋆
f
- ⋆
and the relation
f n = 1.
4.5
Exercises
1. Regarding a group G as a category with one object and every arrow an
isomorphism, show that a categorical congruence ∼on G is the same thing
as (the equivalence relation on G determined by) a normal subgroup N ⊆G,
that is, show that the two kinds of things are in isomorphic correspondence.
Show further that the quotient category G/ ∼and the factor group G/N
coincide. Conclude that the homomorphism theorem for groups is a special
case of the one for categories.
2. Consider the deﬁnition of a group in a category as applied to the category
Sets/I of sets sliced over a set I. Show that such a group G determines an

EXERCISES
75
I-indexed family of (ordinary) groups Gi by setting Gi = G−1(i) for each
i ∈I. Show that this determines a functor Groups(Sets/I) →GroupsI
into the category of I-indexed families of groups and I-indexed families of
homomorphisms.
3. Give four diﬀerent presentations by generators and relations of the
category 3, pictured:
1
- 2
@
@
@
@
@
@
R 3
?
Is 3 free?
4. Given a congruence ∼on a category C and arrows in C as follows,
A
f
-
f ′
- B
g
-
g′
- C
show that f ∼f ′ and g ∼g′ implies g ◦f ∼g′ ◦f ′.
5. Given functors F, G : C →D such that for all C ∈C, FC = GC, deﬁne a
congruence on D by the condition:
f ∼g
iﬀ
dom(f) = dom(g)
& cod(f) = cod(g)
& ∀E, H : D →E. HF = HG ⇒H(f) = H(g)
Prove that this is a congruence.
Prove that D/ ∼is the coequalizer of F and G.

This page intentionally left blank 

5
LIMITS AND COLIMITS
In this chapter we brieﬂy discuss some topics relating to the deﬁnitions that we
already have, rather than pushing on to new ones. This is partly in order to see
how these are used, but also because we will need this material soon enough.
After that, and after a brief look at one more elementary notion, we shall go on
to what may be called “higher category theory.”
5.1
Subobjects
We have seen that every subset U ⊆X of a set X occurs as an equalizer and
that equalizers are always monomorphisms. So it is natural to regard monos as
generalized subsets. That is, a mono in Groups can be regarded as a subgroup,
a mono in Top as a subspace, and so on.
The rough idea is this: given a monomorphism,
m : M ↣X
in a category G of structured sets of some sort—call them “gadgets”—the image
subset
{m(y) | y ∈M} ⊆X
which may be written m(M), is often a sub-gadget of X to which M is isomorphic
via m.
m : M
∼
→m(M) ⊆X
More generally, we can think of the mono m : M ↣X itself as determining a
“part” of X even in categories that do not have underlying functions.
Deﬁnition 5.1. A subobject of an object X in a category C is a mono
m : M ↣X

78
LIMITS AND COLIMITS
Given subobjects m and m′ of X, a morphism f : m →m′ is an arrow in C/X,
as in
M
f - M ′
@
@
@
@
@
@
m
RX
m′
?
Thus we have a category,
SubC(X)
of subobjects of X in C.
In this deﬁnition, since m′ is monic, there is at most one f as in the diagram
above, so that SubC(X) is a preorder category. We deﬁne the relation of inclusion
of subobjects by:
m ⊆m′
iﬀthere exists some f : m →m′
Finally, we say that m and m′ are equivalent, written m ≡m′, if and only if
they are isomorphic as subobjects, that is, m ⊆m′ and m′ ⊆m. This holds just
if there are f and f ′ making both triangles below commute.
M  f ′
f
- M ′
@
@
@
@
@
@
m
RX
m′
?
Observe that, in the above diagram, m = m′f = mf ′f, and since m is
monic, f ′f = 1M and similarly ff ′ = 1M ′. So M ∼= M ′ via f. Thus we see that
equivalent subobjects have isomorphic domains.
Remark 5.2. We sometimes abuse notation and language by calling M the
subobject when the mono m : M ↣X is clear.
Note that if M ⊆M ′ then the arrow f which makes this so in
M
f - M ′
@
@
@
@
@
@
RX
?

SUBOBJECTS
79
is also monic, so also M is a subobject of M ′. In fact, we have a functor
Sub(M ′) →Sub(X)
deﬁned by composition (since the composite of monos is monic).
In terms of generalized elements of an object X,
z : Z →X
one can deﬁne a local membership relation,
z ∈X M
between these and subobjects m : M ↣X by
z ∈X M iﬀthere exists f : Z →M such that z = mf
Since m is monic, if z factors through it then it does so uniquely.
Example 5.3. An equalizer
E
- A
f
-
g
- B
is a subobject of A with the property
z ∈A E
iﬀf(z) = g(z)
Thus, we can regard E as the subobject of generalized elements z : Z →A such
that f(z) = g(z).
E = {z ∈Z | f(z) = g(z)} ⊆A
just as was the case for global elements in Sets. In categorical logic, one develops
a way of making this intuition even more precise by giving a calculus of such
subobjects.
Remark 5.4. It is often convenient to pass from the preorder
SubC(X)
to the poset given by factoring out the equivalence relation “≡”. Then a
subobject is an equivalence class of monos under mutual inclusion.
In Sets, under this notion of subobject, one then has an isomorphism,
SubSets(X) ∼= P(X)
that is, every subobject is represented by a unique subset. We shall use
both notions of subobject, making clear when monos are intended, and when
equivalence classes thereof are intended.

80
LIMITS AND COLIMITS
5.2
Pullbacks
The notion of a pullback, like that of a product, is one that comes up very often
in mathematics and logic. It is a generalization of both intersection and inverse
image.
We begin with the deﬁnition,
Deﬁnition 5.5. In any category C, a pullback of arrows f, g with cod(f) =
cod(g)
B
A
f
- C
g
?
consists of arrows
P
p2
- B
A
p1
?
such that fp1 = gp2 and universal with this property. That is,
given any
z1 : Z →A and z2 : Z →B with fz1 = gz2, there exists a unique
u : Z →P
with z1 = p1u and z2 = p2u.
Here is the picture:
Z........u........
R
HHHHHHHHHHHH
z2
j
A
A
A
A
A
A
A
A
A
A
A
A
z1
U
P
p2
- B
A
p1
?
f
- C
g
?

PULLBACKS
81
Remark 5.6. One sometimes uses product-style notation for pullbacks.
Z
@@@
⟨z1, z2⟩
@@@
R
HHHHHHHHHHHH
j
A
A
A
A
A
A
A
A
A
A
A
AU
A ×C B
p2
- B
A
p1
?
f
- C
g
?
Pullbacks are clearly unique up to isomorphism since they are given by an
UMP (universal mapping property). Here this means that given two pullbacks
of a given pair of arrows, the uniquely determined maps between the pullbacks
are mutually inverse.
In terms of generalized elements, any z ∈A ×C B, can be written uniquely
as z = ⟨z1, z2⟩with fz1 = gz2.
Z
@@@z
@@@
R
A
A
A
A
A
A
A
A
A
A
A
A
z1
U
HHHHHHHHHHHH
z2
j
A ×C B
p2
- B
A
p1
?
f
- C
g
?
This makes
A ×C B = {⟨z1, z2⟩∈A × B | fz1 = gz2}
look like a subobject of A × B, determined as an equalizer of f ◦π1 and g ◦π2.
In fact, this is so.
Proposition 5.7. In a category with products and equalizers, given a corner of
arrows
B
A
f
- C
g
?

82
LIMITS AND COLIMITS
Consider the diagram
E
@@@e
@@@
R
HHHHHHHHHHHH
p2
j
A
A
A
A
A
A
A
A
A
A
A
A
p1
U
A × B
π2
- B
A
π1
?
f
- C
g
?
in which e is an equalizer of fπ1 and gπ2 and p1 = π1e, p2 = π2e. Then E, p1, p2
is a pullback of f and g. Conversely, if E, p1, p2 are given as such a pullback,
then the arrow
e = ⟨p1, p2⟩: E →A × B
is an equalizer of fπ1 and gπ2.
Proof. Take
Z
z2 - B
A
z1
?
with fz1 = gz2. We have ⟨z1, z2⟩: Z →A × B so
fπ1⟨z1, z2⟩= gπ2⟨z1, z2⟩.
Thus, there is a u : Z →E to the equalizer with eu = ⟨z1, z2⟩. Then
p1u = π1eu = π1⟨z1, z2⟩= z1
and
p2u = π2eu = π2⟨z1, z2⟩= z2.
If also u′ : Z →E has piu′ = zi, i = 1, 2, then πieu′ = zi so eu′ = ⟨z1, z2⟩= eu
whence u′ = u since e in monic. The converse is similar.
Corollary 5.8. If a category C has binary products and equalizers, then it has
pullbacks.

PULLBACKS
83
The foregoing gives an explicit construction of a pullback in Sets as a subset of
the product:
{⟨a, b⟩| fa = gb} = A ×C B →A × B
Example 5.9. In Sets, take a function f : A →B and a subset V ⊆B. Let, as
usual,
f −1(V ) = {a ∈A | f(a) ∈V } ⊆A
and consider
f −1(V )
¯f - V
A
j
?
f
- B
i
?
where i and j are the canonical inclusions and ¯f is the evident factorization of
the restriction of f to f −1(V ) (since a ∈f −1(V ) ⇒f(a) ∈V ).
This diagram is a pullback (observe that z ∈f −1(V ) ⇔fz ∈V for all
z : Z →A). Thus, the inverse image
f −1(V ) ⊆A
is determined uniquely up to isomorphism as a pullback.
As suggested by the previous example, we can use pullbacks to deﬁne inverse
images in categories other than Sets. Indeed, given a pullback in any category:
A ×B M
- M
A
m′
?
f
- B
m
?
if m is monic, then m′ is monic. (Exercise!)
Thus we see that, for ﬁxed f : A →B, taking pullbacks induces a map
f −1 : Sub(B) →Sub(A)
m →m′
We will show that f −1 also respects equivalence of subobjects
M ≡N ⇒f −1(M) ≡f −1(N)
by showing that f −1 is a functor; that is our next goal.

84
LIMITS AND COLIMITS
5.3
Properties of pullbacks
We start with the following simple lemma, which seems to come up all the time.
Lemma 5.10. (Two-pullbacks) Consider the commutative diagram below in a
category with pullbacks:
F
f ′
- E
g′
- D
A
h′′
?
f
- B
h′
?
g
- C
h
?
1. If the two squares are pullbacks, so is the outer rectangle. Thus,
A ×B (B ×C D) ∼= A ×C D
2. If the right square and the outer rectangle are pullbacks, so is the left square.
Proof. Diagram chase.
Corollary 5.11. The pullback of a commutative triangle is a commutative tri-
angle. Speciﬁcally, given a commutative triangle as on the right end of the
following “prism diagram”
A′
hα
- A
..................
γ′
R
@
@
@
@
@
@
γ
R
B′
hβ
- B

	
	
	
	
	
	
β′

	
	
	
	
	
	
β
C’
α′
?
h
- C
α
?
for any h : C′ →C, if one can form the pullbacks α′ and β′ as on the left end,
then there exists a unique γ′ as indicated, making the left end a commutative
triangle, and the upper face a commutative rectangle, and indeed a pullback.
Proof. Apply the two-pullbacks lemma.

PROPERTIES OF PULLBACKS
85
Proposition 5.12. Pullback is a functor. That is, for ﬁxed h : C′ →C in a
category C with pullbacks, there is a functor
h∗: C/C →C/C′
deﬁned by
(A
α→C) →(C′ ×C A
α′
→C′)
where α′ is the pullback of α along h, and the eﬀect on an arrow γ : α →β is
given by the foregoing corollary.
Proof. One must check that
h∗(1X) = 1h∗X
and
h∗(g ◦f) = h∗(g) ◦h∗(f)
These can easily be veriﬁed by repeated applications of the two-pullbacks lemma.
For example, for the ﬁrst condition, consider
A′
h′ - A
A′
1A′
?
h′ - A
1A
?
C′
α′
?
h
- C
α
?
If the lower square is a pullback, then plainly so is the outer rectangle, whence
the upper square is, too, and we have
h∗1X = 1X′ = 1h∗X.
Corollary 5.13. Let C be a category with pullbacks. For any arrow f : A →B
in C we have the following diagram of categories and functors:
Sub(A)  f −1
Sub(B)
C/A
?

f ∗
C/B
?

86
LIMITS AND COLIMITS
This commutes simply because f −1 is deﬁned to be the restriction of f ∗to the
subcategory Sub(B). Thus, in particular, f −1 is functorial:
M ⊆N ⇒f −1(M) ⊆f −1(N)
It follows that M ≡N implies f −1(M) ≡f −1(N), so that f −1 is also deﬁned
on equivalence classes.
f −1/≡: Sub(B)/≡−→Sub(A)/≡
Example 5.14. Consider a pullback in Sets:
E
f ′
- B
A
g′
?
f
- C
g
?
We saw that
E = {⟨a, b⟩| f(a) = g(b)}
can be constructed as an equalizer
E
⟨f ′, g′⟩- A × B
fπ1-
gπ2
- C
Now let B = 1, C = 2 = {⊤, ⊥}, and g = ⊤: 1 →2. Then the equalizer
E
- A × 1
fπ1-
⊤π2
- 2
is how we already described the “extension” of the “propositional function”
f : A →2. Therefore we can rephrase the correspondence between subsets

PROPERTIES OF PULLBACKS
87
U ⊆A and their characteristic functions χU : A →2 in terms of pullbacks:
U
!
- 1
A
?
χU
- 2
⊤
?
Precisely, the isomorphism,
2A ∼= P(A)
given by taking a function ϕ : A →2 to its “extension”
Vϕ = {x ∈A | ϕ(x) = ⊤}
can be described as a pullback.
Vϕ = {x ∈A | ϕ(x) = ⊤} = ϕ−1(⊤)
Now suppose we have any function
f : B →A
and consider the induced inverse image operation
f −1 : P(A) →P(B)
given by pullback, as in example 5.9 above. Taking some extension Vϕ ⊆A,
consider the two-pullback diagram
f −1(Vϕ)
- Vϕ
- 1
B
?
f
- A
?
ϕ
- 2
⊤
?
We therefore have (by the two-pullbacks lemma)
f −1(Vϕ) = f −1(ϕ−1(⊤)) = (ϕf)−1(⊤) = Vϕf
which from a logical point of view expresses the fact that the substitution of a
term f for the variable x in the propositional function ϕ is modeled by taking
the pullback along f of the corresponding extension
f −1({x ∈A | ϕ(x) = ⊤}) = {y ∈B | ϕ(f(y)) = ⊤}.

88
LIMITS AND COLIMITS
Note that we have shown that for any function f : B →A the following
square commutes
2A
∼= - P(A)
2B
2f
?
∼=
- P(B)
f −1
?
where 2f : 2A →2B is precomposition 2f(g) = g ◦f. In a situation like this, one
says that the isomorphism
2A ∼= P(A)
is natural in A, which is obviously a much stronger condition than just having
isomorphisms at each object A. We will consider such “naturality” systematically
later. It was in fact one of the phenomena that originally gave rise to category
theory.
Example 5.15. Let I be an index set, and consider an I-indexed family of sets:
(Ai)i∈I
Given any function α : J →I, there is a J-indexed family
(Aα(j))j∈J ,
obtained by “reindexing along α.” This reindexing can also be described as a
pullback. Speciﬁcally, for each set Ai take the constant, i-valued function pi :
Ai →I and consider the induced map on the coproduct
p = [pi] :

i∈I
Ai →I
The reindexed family (Aα(j))j∈J can be obtained by taking a pullback along α,
as indicated in the following diagram:

j∈J
Aα(j)
- 
i∈I
Ai
J
q
?
α
- I
p
?
where q is the indexing projection for (Aα(j))j∈J analogous to p. In other words,
we have
J ×I (

i∈I
Ai) ∼=

j∈J
Aα(j)
The reader should work out the details as an instructive exercise.

LIMITS
89
5.4
Limits
We have already seen that the notions of product, equalizer, and pullback are
not independent; the precise relation between them is this.
Proposition 5.16. A category has ﬁnite products and equalizers iﬀit has
pullbacks and a terminal object.
Proof. The “only if” direction has already been done. For the other direction,
suppose C has pullbacks and a terminal object 1.
• For any objects A, B we clearly have A × B ∼= A ×1 B, as indicated in the
following:
A × B
- B
A
?
- 1
?
• For any arrows f, g : A →B, the equalizer e : E →A is constructed as the
following pullback:
E
h
- B
A
e
?
⟨f, g⟩
- B × B
∆= ⟨1B, 1B⟩
?
In terms of generalized elements,
E = {(a, b) | ⟨f, g⟩(a) = ∆b}
where ⟨f, g⟩(a) = ⟨fa, ga⟩and ∆(b) = ⟨b, b⟩. So,
E = {⟨a, b⟩| f(a) = b = g(a)}
∼= {a | f(a) = g(a)}
which is just what we want. An easy diagram chase shows that
E
e
- A
f
-
g
- B
is indeed an equalizer.
Product, terminal object, pullback, and equalizer, are all special cases of
the general notion of a limit, which we will consider now. First, we need some
preliminary deﬁnitions.

90
LIMITS AND COLIMITS
Deﬁnition 5.17. Let J and C be categories. A diagram of type J in C is a
functor.
D : J →C.
We will write the objects in the “index category” J lower case, i, j, . . . and the
values of the functor D : J →C in the form Di, Dj, etc.
A cone to a diagram D consists of an object C in C and a family of arrows
in C,
cj : C →Dj
one for each object j ∈J, such that for each arrow α : i →j in J, the following
triangle commutes.
C
cj - Dj
	
	
	
	
	
	
Dα

Di
ci
?
A morphism of cones
ϑ : (C, cj) →(C′, c′
j)
is an arrow ϑ in C making each triangle,
C
ϑ
- C′
@
@
@
@
@
@
cj
R
Dj
c′
j
?
commute. That is, such that cj = c′
j ◦ϑ for all j ∈J. Thus, we have an apparent
category
Cone(D)
of cones to D.
We are here thinking of the diagram D as a “picture of J in C.” A cone to
such a diagram D is then imagined as a many-sided pyramid over the “base” D
and a morphism of cones is an arrow between the apexes of such pyramids. (The
reader should draw some pictures at this point!)
Deﬁnition 5.18. A limit for a diagram D : J →C is a terminal object in
Cone(D). A ﬁnite limit is a limit for a diagram on a ﬁnite index category J.

LIMITS
91
We often denote a limit in the form
pi : lim
←−
j
Dj →Di.
Spelling out the deﬁnition, the limit of a diagram D has the following UMP:
given any cone (C, cj) to D, there is a unique arrow u : C →lim
←−j Dj such that
for all j,
pj ◦u = cj.
Example 5.19. Take J = {1, 2} the discrete category with two objects and no
nonidentity arrows. A diagram D : J →C is a pair of objects D1, D2 ∈C. A
cone on D is an object of C equipped with arrows
D1  c1
C
c2 - D2.
And a limit of D is a terminal such cone, that is, a product in C of D1 and D2,
D1 p1
D1 × D2
p2- D2.
Thus, in this case,
lim
←−
j
Dj ∼= D1 × D2.
Example 5.20. Take J to be the following category:
·
α
-
β
- ·
A diagram of type J looks like
D1
Dα -
Dβ
- D2
and a cone is a pair of arrows
D1
Dα -
Dβ
- D2
	
	
	
	
	
	
c2

C
c1
6
such that Dαc1 = c2 and Dβc1 = c2; thus, Dαc1 = Dβc1. A limit for D is
therefore an equalizer for Dα, Dβ.

92
LIMITS AND COLIMITS
Example 5.21. If J is empty, there is just one diagram D : J →C, and a limit
for it is thus a terminal object in C,
lim
←−
j∈0
Dj ∼= 1.
Example 5.22. If J is the ﬁnite category
·
·
- ·
?
we see that a limit for a diagram of the form
B
A
f
- C
g
?
is just a pullback of f and g,
lim
←−
j
Dj ∼= A ×C B.
Thus, we have shown half of the following:
Proposition 5.23. A category has all ﬁnite limits iﬀit has ﬁnite products and
equalizers (resp. pullbacks and a terminal object by the last proposition).
Here a category C is said to have all ﬁnite limits if every ﬁnite diagram D : J →
C has a limit in C.
Proof. We need to show that any ﬁnite limit can be constructed from ﬁnite
products and equalizers. Take a ﬁnite diagram
D : J →C.
Consider the ﬁnite products

i∈J0
Di
and

(α:i→j)∈J1
Dj.
Deﬁne two arrows

i
Di
φ-
ψ
-

α:i→j
Dj

LIMITS
93
by taking their composites with the projections πα from the second product to
be, respectively:
πα ◦φ = φα = πcod(α)
πα ◦ψ = ψα = Dα ◦πdom(α)
where πcod(α) and πdom(α) are projections from the ﬁrst product.
Now we take the equalizer:
E
e - 
i
Di
φ-
ψ
-

α:i→j
Dj
We will show that (E, ei) is a limit for D, where ei = πi ◦e. To that end, take
any arrow c : C →
i Di, and write c = ⟨ci⟩for ci = πi ◦c. Observe that the
family of arrows (ci : C →Di) is a cone to D if and only iﬀφc = ψc. Indeed,
φ⟨ci⟩= ψ⟨ci⟩
iﬀfor all α,
παφ⟨ci⟩= παψ⟨ci⟩.
But,
παφ⟨ci⟩= φα⟨ci⟩= πcod(α)⟨ci⟩= cj
and
παψ⟨ci⟩= ψα⟨ci⟩= Dα ◦πdom(α)⟨ci⟩= Dα ◦ci.
Whence φc = ψc iﬀfor all α : i →j we have cj = Dα ◦ci thus, iﬀ(ci : C →Di)
is a cone, as claimed. It follows that (E, ei) is a cone, and that any cone (ci :
C →Di) gives an arrow ⟨ci⟩: C →
i Di with φ⟨ci⟩= ψ⟨ci⟩, thus there is a
unique factorization u : C →E of ⟨ci⟩through E, which is clearly a morphism
of cones.
The same proof yields the following:
Corollary 5.24. A category has all limits of some cardinality iﬀit has all equal-
izers and products of that cardinality, where C has limits (resp. products) of
cardinality κ iﬀC has a limit for every diagram D : J →C where card(J1) ≤κ
(resp. C has all products of κ many objects).
The notions cones and limits of course dualize to give those of cocones and
colimits. One then has the following dual theorem.
Theorem 5.25. A category C has ﬁnite colimits iﬀit has ﬁnite coproducts and
coequalizers (resp. iﬀit has pushouts and an initial object). C has all colimits of
size κ iﬀit has coequalizers and coproducts of size κ.

94
LIMITS AND COLIMITS
5.5
Preservation of limits
Here is an application of limits by products and equalizers.
Deﬁnition 5.26. A functor F : C →D is said to preserve limits of type J if,
whenever pj : L →Dj is a limit for a diagram D : J →C; the cone Fpj : FL →
FDj is then a limit for the diagram FD : J →D. Brieﬂy
F(lim
←−Dj) ∼= lim
←−F(Dj).
A functor that preserves all limits is said to be continuous.
For example, let C be locally small and recall the representable functor
HomC(C, −) : C →Sets
for any object C ∈C, taking f : X →Y to
f∗: Hom(C, X) →Hom(C, Y )
where f∗(g : C →X) = f ◦g.
Proposition 5.27. Representable functors preserve all limits.
It suﬃces to show that Hom(C, −) preserves products and equalizers.
• Suppose C has a terminal object 1. Then,
HomC(C, 1) = {!C} ∼= 1.
• Consider a binary product X × Y in C. Then we already know that,
Hom(C, X × Y ) ∼= Hom(C, X) × Hom(C, Y )
by composing any f : C →X × Y with the two product projections p1 :
X × Y →X, and p2 : X × Y →Y .
• For arbitrary products 
i∈I Xi one has analogously:
HomC(C,

i
Xi) ∼=

i
HomC(C, Xi)
• Given an equalizer in C,
E
e
- X
f
-
g
- Y
consider the resulting diagram,
Hom(C, E) e∗
- Hom(C, X)
f∗-
g∗
- Hom(C, Y ).
To show this is an equalizer in Sets, let h : C →X ∈Hom(C, X) with
f∗h = g∗h. Then fh = gh, so there is a unique u : C →E such that

COLIMITS
95
eu = h. Thus, we have a unique u ∈Hom(C, E) with e∗u = eu = h. So
e∗: Hom(C, E) →Hom(C, X) is indeed the equalizer of f∗and g∗.
Deﬁnition 5.28. A functor of the form F : Cop →D is called a contravariant
functor on C. Explicitly, such a functor takes f : A →B to F(f) : F(B) →F(A)
and F(g ◦f) = F(f) ◦F(g).
A typical example of a contravariant functor is a representable functor of the
form,
HomC(−, C) : Cop →Sets
for any C ∈C (where C is any locally small category). Such a contravariant
representable functor takes f : X →Y to
f ∗: Hom(Y, C) →Hom(X, C)
by f ∗(g : X →C) = g ◦f.
The dual version of the foregoing proposition is then this:
Corollary 5.29. Contravariant representable functors map all colimits to
limits.
For example, given a coproduct X + Y in any locally small category C, there is
a canonical isomorphism,
Hom(X + Y, C) ∼= Hom(X, C) × Hom(Y, C)
(5.1)
given by precomposing with the two coproduct inclusions.
From an example in Section 2.3 we can therefore conclude that the ultraﬁl-
ters in a coproduct A + B of Boolean algebras correspond exactly to pairs of
ultraﬁlters (U, V ), with U in A and V in B. This follows because we showed
there that the ultraﬁlter functor Ult : Boolop →Sets is representable:
Ult(B) ∼= HomBool(B, 2).
Another case of the above iso (5.1) is the familiar law of exponents for sets:
CX+Y ∼= CX × CY
The arithmetical law of exponents km+n = kn · km is actually a special case of
this!
5.6
Colimits
Let us brieﬂy discuss some special colimits, since we did not really say much
about them in the foregoing section.
First, we consider pushouts in Sets.

96
LIMITS AND COLIMITS
Suppose we have two functions
A
g
- C
B
f
?
We can construct the pushout of f and g like this. Start with the coproduct
(disjoint sum):
B
- B + C 
C
Now identify those elements b ∈B and c ∈C such that, for some a ∈A,
f(a) = b
and
g(a) = c
That is, we take the equivalence relation ∼on B+C generated by the conditions
f(a) ∼g(a) for all a ∈A.
Then we take the quotient by ∼to get the pushout
B +A C ∼= (B + C)/∼
which can be imagined as B placed next to C, with the respective parts that are
images of A overlapping. This construction follows simply by dualizing the one
for pullbacks by products and equalizers.
In general, a colimit for a diagram D : J →C is of course an initial object
in the category of cocones. Explicitly, a cocone from the base D consists of an
object C (the vertex) and arrows cj : Dj →C for each j ∈J, such that for all
α : i →j in J,
cj ◦D(α) = ci
A morphism of cocones f : (C, (cj)) →(C′, (cj′)) is an arrow f : C →C′ in C
such that f ◦cj = cj′ for all j ∈J. An initial cocone is the expected thing: one
that maps uniquely to any other cocone from D.
We write such a colimit in the form:
lim
−→
j∈J
Dj
Now let us consider some examples of a particular kind of colimit that comes
up quite often. Our ﬁrst example is what is sometimes called a direct limit of a
sequence of algebraic objects, say groups. A similar construction will work for
any sort of algebras (but non-equational conditions are not always preserved by
direct limits).
Example 5.30. Direct limit of groups. Suppose we’re given a sequence,
G0 −→
g0 G1 −→
g1 G2 −→
g2 · · ·

COLIMITS
97
of groups and homomorphisms, and we want a “colimiting” group G∞with
homomorphisms
un : Gn →G∞
satisfying un+1◦gn = un. Moreover, G∞should be “universal” with this property.
I think you can see the colimit setup here:
• the index category is the ordinal number ω = (N, ≤), regarded as a poset
category,
• the sequence
G0 −→
g0 G1 −→
g1 G2 −→
g2 · · ·
is a diagram of type ω in the category Groups,
• the colimiting group is the colimit of the sequence:
G∞∼= lim
−→
n∈ω
Gn
This group always exists, and can be constructed as follows. Begin with the
coproduct (disjoint sum) of sets

n∈ω
Gn.
Then make identiﬁcations xn ∼ym, where xn ∈Gn and ym ∈Gm, to ensure in
particular that
xn ∼gn(xn)
for all xn ∈Gn and gn : Gn →Gn+1.
This means, speciﬁcally, that the elements of G∞are equivalence classes of
the form
[xn],
xn ∈Gn
for any n, and [xn] = [ym] iﬀfor some k ≥m, n,
gn,k(xn) = gm,k(ym)
where, generally, if i ≤j, we deﬁne
gi,j : Gi →· · · →Gj
by composing consecutive g’s as in gi,j = gj−1 ◦. . . ◦gi. The reader can easily
check that this is indeed the equivalence relation generated by all the conditions
xn ∼gn(xn).
The operations on G∞are now deﬁned by
[x] · [y] = [x′ · y′]

98
LIMITS AND COLIMITS
where x ∼x′, y ∼y′, and x′, y′ ∈Gn for n suﬃciently large. The unit is just
[u0], and we take,
[x]−1 = [x−1].
One can easily check that these operations are well deﬁned, and determine a
group structure on G∞, which moreover makes all the evident functions
un : Gn →G∞,
un(x) = [x]
into homomorphisms.
The universality of G∞and the un results from the fact that the construction
is essentially a colimit in Sets, equipped with an induced group structure. Indeed,
given any group H and homomorphisms hn : Gn →H with hn+1◦gn = hn deﬁne
hω : Gω →H by gω([xn]) = gn(xn). This is easily seen to be well deﬁned and
indeed a homomorphism. Moreover, it is the unique function that commutes
with all the un.
The fact that the ω-colimit G∞of groups can be constructed as the colimit of
the underlying sets is a case of a general phenomenon, expressed by saying that
the forgetful functor U : Groups →Sets “creates ω-colimits.”
Deﬁnition 5.31. A functor F : C →D is said to create limits of type J if for
every diagram C : J →C and limit pj : L →FCj in D there is a unique cone
pj : L →Cj in C with F(L) = L and F(pj) = pj, which, furthermore, is a limit
for C. Brieﬂy, every limit in D is the image of a unique cone in C, which is a
limit there. The notion of creating colimits is deﬁned analogously.
In these terms, then, we have the following proposition, the remaining details of
which are left as an exercise.
Proposition 5.32. The forgetful functor U : Groups →Sets creates ω-
colimits. It also creates all limits.
The same fact holds quite generally for other categories of algebraic objects,
that is, sets equipped with operations satisfying some equations. Observe that
not all colimits are created in this way. For instance, we have already seen that
the coproduct of two abelian groups has their product as underlying set, since
G + H ∼= G × H.
Example 5.33. Cumulative hierarchy. Another example of this kind is the
“cumulative hierarchy” construction encountered in set theory. Let us set
V0 = ∅
V1 = P(∅)
...
Vn+1 = P(Vn)

COLIMITS
99
Then there is a sequence of subset inclusions,
∅= V0 ⊆V1 ⊆V2 ⊆· · ·
since, generally, A ⊆B implies P(A) ⊆P(B) for any sets A and B. The colimit
of the sequence
Vω = lim
−→
n
Vn
is called the cumulative hierarchy of rank ω. One can of course continue this
construction through higher ordinals ω + 1, ω + 2, . . ..
More generally, let us start with some set A (of “atoms”), and let
V0(A) = A
and then put
Vn+1(A) = A + P(Vn(A))
There is a sequence V0(A) →V1(A) →V2(A) →. . . as follows. Let
v0 : V0(A) = A →A + P(A) = V1(A)
be the left coproduct inclusion. Given vn−1 : Vn−1(A) →Vn(A), let vn : Vn(A) →
Vn+1(A) be deﬁned by
vn = 1A + P!(vn−1) : A + P(Vn−1(A)) →A + P(Vn(A))
where P! denotes the covariant powerset functor, taking a function f : X →Y
to the “image under f” operation P!(f) : P(X) →P(Y ) deﬁned by taking
U ⊆X to
P!(f)(U) = {f(u) | u ∈U} ⊆Y
The idea behind the sequence is that we start with A, then add all the subsets
of A, then add all the new subsets that can be formed from all of those, and so
on. The colimit of the sequence
Vω(A) = lim
−→
n
Vn(A)
is called the cumulative hierarchy (of rank ω) over A. Of course, Vω = Vω(∅).
Now suppose we have some function
f : A →B
Then there is a map
Vω(f) : Vω(A) →Vω(B)

100
LIMITS AND COLIMITS
determined by the colimit description of Vω, as indicated in the following
diagram.
V0(A)
- V1(A)
- V2(A)
- . . .
- Vω(A)
. . .
V0(B)
f0
?
- V1(B)
f1
?
- V2(B)
f2
?
- . . .
- Vω(B)
fω
?
Here the fn are deﬁned by
f0 = f : A →B
f1 = f + P!(f) : A + P(A) →B + P(B)
...
fn+1 = f + P!(fn) : A + P(Vn(A)) →B + P(Vn(B))
Since all the squares clearly commute, we have a cocone on the diagram Vn(A)
with vertex Vω(B), and there is thus a unique fω : Vω(A) →Vω(B) that
completes the diagram.
Thus we see that the cumulative hierarchy is functorial.
Example 5.34. ωCPOs. An ωCPO is a poset that is “ω-cocomplete,” meaning
it has all colimits of type ω = (N, ≤). Speciﬁcally, a poset D is an ωCPO if for
every diagram d : ω →D, i.e. every chain of elements of D,
d0 ≤d1 ≤d2 ≤· · ·
we have a colimit dω = lim
−→dn. This is an element such that:
1. dn ≤dω for all n ∈ω;
2. for all x ∈D; if dn ≤x for all n ∈ω, then also dω ≤x.
A monotone map of ωCPOs
h : D →E
is usually called continuous if it preserves colimits of type ω, that is,
h(lim
−→dn) = lim
−→h(dn).
An application of these notions is the following:
Proposition 5.35. If D is an ωCPO with initial element 0 and
h : D →D

COLIMITS
101
is continuous, then h has a ﬁxed point
h(x) = x
which, moreover, is least among all ﬁxed points.
Proof. We use “Newton’s method,” which can be used, for example, to ﬁnd
ﬁxed points of monotone, continuous functions f : [0, 1] →[0, 1]. Consider the
sequence d : ω →D, deﬁned by
d0 = 0
dn+1 = h(dn)
Since 0 ≤d0, repeated application of h gives dn ≤dn+1. Now take the colimit
dω = lim
−→n∈ω dn. Then
h(dω) = h(lim
−→
n∈ω
dn)
= lim
−→
n∈ω
h(dn)
= lim
−→
n∈ω
dn+1
= dω.
The last step follows because the ﬁrst term d0 = 0 of the sequence is trivial.
Moreover, if x is also a ﬁxed point, h(x) = x, then we have
d0 = 0 ≤x
d1 = h(0) ≤h(x) = x
...
dn+1 = h(dn) ≤h(x) = x.
So also dω ≤x, since dω is a colimit.
Finally, here is an example of how (co)limits depend on the ambient category;
we consider colimits of posets and ωCPOs, rather than in them.
Let us deﬁne the ﬁnite ωCPOs
ωn = {k ≤n | k ∈ω}
then we have continuous inclusion maps:
ω0 →ω1 →ω2 →· · ·
In Pos, the colimit exists, and is ω, as can be easily checked. But ω itself is
not ω-complete. Indeed, the sequence
0 ≤1 ≤2 ≤· · ·

102
LIMITS AND COLIMITS
has no colimit. So the colimit of the ωn in the category of ωCPOs, if it exists,
must be something else. In fact it is ω + 1.
0 ≤1 ≤2 ≤· · · ≤ω
For then any bounded sequence has a colimit in the bounded part and any
unbounded one has ω as colimit.
5.7
Exercises
1. Show that an arrow m : M →C in any category is monic if and only if the
diagram below is a pullback.
M
1M - M
M
1M
?
m
- X
m
?
Conclude that representable functors Hom(C, −) preserve monos.
2. Show that in any category, given a pullback square
M ′
- M
A′
m′
?
f
- A
m
?
if m is monic, then so is m′.
3. (Equalizers by pullbacks and products) Show that a category with pullbacks
and products has equalizers as follows: given arrows f, g : A →B, take the
pullback indicated below, where ∆= ⟨1B, 1B⟩:
E
- B
A
e
?
⟨f, g⟩
- B × B
∆
?
Show that e : E →A is the equalizer of f and g.

EXERCISES
103
4. (Partial maps) For any category C with pullbacks, deﬁne the category
Par(C) of partial maps in C as follows: the objects are the same as those of
C, but an arrow f : A →B is a pair (|f|, Uf) where Uf ↣A is a subobject
(an equivalence class of monomorphisms) and |f| : Uf →B (take a suitably
deﬁned equivalence class of arrows), as indicated in the diagram
Uf
|f| - B
A
?
?
Composition of (|f|, Uf) : A →B and (|g|, Ug) : B →C is given by taking
a pullback and then composing to get (|g ◦f|, |f|∗(Ug)), as suggested by the
follow diagram.
|f|∗(Ug)
- Ug
|g|
- C
Uf
?
?
|f|
- B
?
?
A
?
?
Check to see that this really does deﬁne a category.
5. (Pushouts)
(a) Dualize the deﬁnition of a pullback to deﬁne the “copullback” (usually
called the “pushout”) of two arrows with common domain.
(b) Indicate how to construct pushouts using coproducts and coequalizers
(proof “by duality”).

This page intentionally left blank 

6
EXPONENTIALS
We have now managed to unify most of the universal mapping properties (UMP)
that we have seen so far with the notion of limits (or colimits). Of course, the
free algebras are an exception to this. In fact, it will turn out that there is a
common source of UMP’s, but it lies somewhat deeper, in the notion of adjoints,
which unify free algebras, limits, and other universals of various kinds.
Next we are going to look at one more elementary universal structure, which
is also an example of a universal that is not a limit. This important structure
is called an “exponential” and it can be thought of as a categorical notion of a
“function space.” As we’ll see it subsumes much more than just that, however.
6.1
Exponential in a category
Let us start by considering a function of sets,
f(x, y) : A × B →C
written using variables x over A and y over B. If we now hold a ∈A ﬁxed, we
have a function
f(a, y) : B →C
and thus an element
f(a, y) ∈CB
of the set of all such functions.
Letting a vary over A then gives a map, which I will write like this:
˜f : A →CB
deﬁned by a →f(a, y).
The map ˜f : A →CB takes the “parameter” a to the function fa(y) : B →C.
It’s uniquely determined by the equation
˜f(a)(b) = f(a, b).
Indeed, any map
φ : A →CB

106
EXPONENTIALS
is uniquely of the form
φ = ˜f
for some f : A × B →C. For we can set
f(a, b) := φ(a)(b).
What this means, in sum, is that we have an isomorphism of Hom-sets:
HomSets(A × B, C) ∼= HomSets(A, CB)
That is, there is a bijective correspondence between functions of the form
f : A × B →C and those of the form ˜f : A →CB. Moreover, this bijec-
tion is mediated by a certain operation of evaluation, which we have indicated
in the foregoing by using variables. In order to generalize the indicated bijec-
tion to other categories, we’re going to need to make this evaluation operation
explicit, too.
In Sets, it is the function
eval : CB × B →C
deﬁned by (g, b) →g(b), that is,
eval(g, b) = g(b).
This evaluation function has the following UMP: given any set A and any
function
f : A × B →C
there is a unique function
˜f : A →CB
such that eval ◦( ˜f × 1B) = f. That is,
eval( ˜f(a), b) = f(a, b).
(6.1)
Here is the diagram:
CB
CB × B
eval- C
	
	
	
	
	
	
f

A
˜f
6
A × B
˜f × 1B
6
You can read the equation (6.1) oﬀfrom this diagram by taking a pair of
elements (a, b) ∈A × B and chasing them around both ways, using the fact that
( ˜f × 1B)(a, b) = ( ˜f(a), b).

EXPONENTIAL IN A CATEGORY
107
Now, the property just stated of the evaluation function and the set CB of
functions B →C is one that will make sense in any category having binary
products.
So, in that form, we can use it to deﬁne the notion we seek.
Deﬁnition 6.1. Let the category C have binary products. An exponential of
objects B and C of C consists of an object
CB
and an arrow
ϵ : CB × B →C
such that, for any object Z and arrow
f : Z × B →C
there is a unique arrow
˜f : Z →CB
such that
ϵ ◦( ˜f × 1B) = f
all as in the diagram
CB
CB × B
ϵ - C
	
	
	
	
	
	
f

Z
˜f
6
Z × B
˜f × 1B
6
Here is some terminology
• ϵ : CB × B →C is called evaluation.
• ˜f : Z →CB is called the (exponential) transpose of f.
• Given an arrow
g : Z →CB
we write
¯g := ϵ(g × 1B) : Z × B →C
and also call ¯g the transpose of g. By the uniqueness clause of the deﬁnition,
then
˜¯g = g

108
EXPONENTIALS
and for any f : Z × B →C,
¯˜f = f.
Brieﬂy, transposition of transposition is the identity.
Thus transposition provides the desired isomorphism,
HomC(Z × B, C) ∼= HomC(Z, CB)
where f →˜f and g →¯g.
6.2
Cartesian closed categories
Deﬁnition 6.2. A category is called cartesian closed if it has all ﬁnite products
and exponentials.
Example 6.3. We already have Sets as one example, but note that also Setsfin
is cartesian closed, since for ﬁnite sets M, N, the set of functions N M has
cardinality
|N M| = |N||M|
and so is also ﬁnite.
Example 6.4. Recall that the category Pos of posets has as arrows f : P →Q
the monotone functions, p ≤p′ implies fp ≤fp′. Given posets P and Q, the
poset P × Q has pairs (p, q) as elements, and is partially ordered by
(p, q) ≤(p′, q′)
iﬀ
p ≤p′ and q ≤q′.
Thus the evident projections
P 
π1
P × Q
π2
- Q
are monotone, as is the pairing ⟨f, g⟩: X →P × Q if f : X →P and g : X →Q
are monotone.
For the exponential QP , we take the set of monotone functions,
QP = {f : P →Q | f monotone }
ordered pointwise, that is,
f ≤g
iﬀ
fp ≤gp for all p ∈P.
The evaluation
ϵ : QP × P →Q
and transposition
˜f : X →QP

CARTESIAN CLOSED CATEGORIES
109
of a given arrow
f : X × P →Q
are the usual ones of the underlying functions. Thus we need only show that
these are monotone.
To that end, given (f, p) ≤(f ′, p′) in QP × P we have
ϵ(f, p) = f(p)
≤f(p′)
≤f ′(p′)
= ϵ(f ′, p′)
so ϵ is monotone. Now take f : X × P →Q monotone and let x ≤x′. We need
to show
˜f(x) ≤˜f(x′)
in QP
which means
˜f(x)(p) ≤˜f(x′)(p)
for all p ∈P.
But
˜f(x)(p) = f(x, p)
≤f(x′, p)
≤f ′(x′, p)
= ˜f(x′)(p).
Example 6.5. Now let us consider what happens if we restrict to the category
of ωCPOs (see example 5.34). Given two ωCPOs P and Q, we will take as an
exponential the subset,
QP = {f : P →Q | f monotone and ω-continuous}.
Then take evaluation ϵ : QP × P →Q and transposition as before, for functions.
Then, since we know that the required equations are satisﬁed, we just need to
check the following:
• QP is an ωCPO
• ϵ is ω-continuous
• ˜f is ω-continuous if f is
We leave this as an exercise!
We now derive some of the basic facts about exponentials and cartesian closed
categories. First, let us ask, what is the transpose of evaluation?
ϵ : BA × A →B

110
EXPONENTIALS
It must be an arrow ˜ϵ : BA →BA such that
ϵ(˜ϵ × 1A) = ϵ
that is, making the following diagram commute:
BA × A
ϵ - B
	
	
	
	
	
	
ϵ

BA × A
˜ϵ × 1A
6
Since 1BA × 1A = 1(BA×A) clearly has this property, we must have
˜ϵ = 1BA
and so we also know that ϵ = (1BA).
Now let us show that the operation X →XA on a CCC is functorial.
Proposition 6.6. In any cartesian closed category C, exponentiation by a ﬁxed
object A is a functor,
−A : C →C.
Toward the proof, consider ﬁrst the case of sets. Given some function
β : B →C
we put
βA : BA →CA
deﬁned by
f →β ◦f.
That is,
A
@
@
@
@
@
@
β ◦f = βA(f)
R
B
f
?
β
- C
This assignment is functorial, because: for any α : C →D
(α ◦β)A(f) = α ◦β ◦f
= α ◦βA(f)
= αA ◦βA(f).

CARTESIAN CLOSED CATEGORIES
111
Whence (α ◦β)A = αA ◦βA. Also
(1B)A(f) = 1B ◦f
= f
= 1BA(f).
So (1B)A = 1BA.
In a general CCC then, given β : B →C, we deﬁne
βA : BA →CA
by
βA := 
(β ◦ϵ).
That is, we take the transpose of the composite
BA × A
ϵ→B
β→C
giving
βA : BA →CA.
It is easier to see in the form
CA
CA × A
ϵ - C
BA
βA
6
BA × A
βA × 1A
6
ϵ
- B
β
6
Now, clearly,
(1B)A = 1BA : BA →BA
by examining
BA × A
- B
BA × A
1(BA×A) = 1BA × 1A
6
ϵ
- B
1B
6
Quite similarly, given
B
β→C
γ→D

112
EXPONENTIALS
we have
γA ◦βA = (γ ◦β)A.
This follows from considering the commutative diagram
DA × A
ϵ - D
CA × A
γA × 1A
6
ϵ
- C
γ
6
BA × A
βA × 1A
6
ϵ
- B
β
6
We use the fact that
(γA × 1A) ◦(βA × 1A) = ((γA ◦βA) × 1A).
The result follows by the uniqueness of transposes.
This suggests looking for another “universal” arrow, namely the transpose of
the identity 1A×B : A × B →A × B,
˜1A×B : A →(A × B)B.
In Sets it has the values ˜1A×B(a)(b) = (a, b). Let us denote this map by η =
˜1A×B, so that
η(a)(b) = (a, b).
The map η lets us compute ˜f from the functor −A. Indeed, given f : Z ×A →
B take
f A : (Z × A)A →BA
and precompose with η : Z →(Z × A)A, as indicated in
(Z × A)A
f A
- BA
	
	
	
	
	
	
˜f

Z
η
6
This gives the useful equation
˜f = f A ◦η
which the reader should prove.

HEYTING ALGEBRAS
113
6.3
Heyting algebras
Any Boolean algebra B, regarded as a poset category, has ﬁnite products 1 and
a ∧b. We can also deﬁne the exponential in B by
ba = (¬a ∨b)
which we will also write a ⇒b. The evaluation arrow is
(a ⇒b) ∧a ≤b.
This always holds since
(¬a ∨b) ∧a = (¬a ∧a) ∨(b ∧a) = 0 ∨(b ∧a) = b ∧a ≤b.
To show that a ⇒b is indeed an exponential in B, we just need to verify that if
a ∧b ≤c then a ≤b ⇒c, that is, transposition. But if a ∧b ≤c, then
¬b ∨(a ∧b) ≤¬b ∨c = b ⇒c.
But we also have
a ≤¬b ∨a ≤(¬b ∨a) ∧(¬b ∨b) = ¬b ∨(a ∧b).
This example suggests generalizing the notion of a Boolean algebra to that
of a cartesian closed poset. Indeed, consider ﬁrst the following useful notion.
Deﬁnition 6.7. A Heyting algebra is a poset with
1. ﬁnite meets: 1 and p ∧q,
2. ﬁnite joins: 0 and p ∨q,
3. exponentials: for each a, b, an element a ⇒b such that
a ∧b ≤c iﬀa ≤b ⇒c.
The stated condition on exponentials a ⇒b is equivalent to the UMP in the
case of posets. Indeed, given the condition, the transpose of a∧b ≤c is a ≤b ⇒c
and the evaluation (a ⇒b)∧a ≤b follows immediately from a ⇒b ≤a ⇒b (the
converse is just as simple).
Every Heyting algebra is a distributive lattice, since we have
(a ∨b) ∧c ≤z iﬀa ∨b ≤c ⇒z
iﬀa ≤c ⇒z and b ≤c ⇒z
iﬀa ∧c ≤z and b ∧c ≤z
iﬀ(a ∧c) ∨(b ∧c) ≤z.
Now pick z = (a ∨b) ∧c, respectively z = (a ∧c) ∨(b ∧c).
One may well wonder whether all distributive lattices are Heyting algebras.
The answer is in general, no; but certain ones always are.

114
EXPONENTIALS
Deﬁnition 6.8. A poset is (co)complete if it is so as a category, thus if it has
all set-indexed meets 
i∈I ai (resp. joins 	
i∈I ai). For posets, completeness and
cocompleteness are equivalent (exercise!). A lattice, Heyting algebra, Boolean
algebra, etc. is called complete if it is so as a poset.
Proposition 6.9. A complete lattice is a Heyting algebra iﬀit satisﬁes the
inﬁnite distributive law
a ∧


i
bi

=

i
(a ∧bi).
Proof. One shows that Heyting algebra implies distributivity just as in the ﬁnite
case. To show that the inﬁnite distributive law implies Heyting algebra, set
a ⇒b =

x∧a≤b
x.
Then, if
y ∧a ≤b
then y ≤	
x∧a≤b x = a ⇒b. And conversely, if y ≤a ⇒b then y ∧a ≤
(	
x∧a≤b x) ∧a = 	
x∧a≤b(x ∧a) ≤	 b = b.
Example 6.10. For any set A, the powerset P(A) is a complete Heyting algebra
with unions and intersections as joins and meets, since it satisﬁes the inﬁnite
distributive law. More generally, the lattice of open sets of a topological space is
also a Heyting algebra, since the open sets are closed under ﬁnite intersections
and arbitrary unions.
Of course, every Boolean algebra is a Heyting algebra with a ⇒b = ¬a ∨b, as
we already showed. But in general, a Heyting algebra is not Boolean. Indeed, we
can deﬁne a proposed negation by,
¬a = a ⇒0
as must be the case, since in a Boolean algebra ¬a = ¬a ∨0 = a ⇒0. Then
a ≤¬¬a since a ∧(a ⇒0) ≤0. But, conversely, ¬¬a ≤a need not hold in a
Heyting algebra. Indeed, in a topological space X, the negation ¬U of an open
subset U is the interior of the complement X −U. Thus, for example, in the
real interval [0, 1] we have ¬¬(0, 1) = [0, 1].
Moreover, the law,
1 ≤a ∨¬a
also need not hold in general. In fact, the concept of a Heyting algebra is the
algebraic equivalent of the intuitionistic propositional calculus, in the same sense
that Boolean algebras are an algebraic formulation of the classical propositional
calculus.

HEYTING ALGEBRAS
115
To make this more precise, we ﬁrst give a system of rules for the intuitionistic
propositional calculus (IPC) in terms of entailments p ⊢q between formulas
p and q:
1. ⊢is reﬂexive and transitive
2. p ⊢⊤
3. ⊥⊢p
4. p ⊢q and p ⊢r iﬀp ⊢q ∧r
5. p ⊢r and q ⊢r iﬀp ∨q ⊢r
6. p ∧q ⊢r iﬀp ⊢q ⇒r
This is a complete system for IPC, equivalent to the more standard presenta-
tions the reader may have seen. To show this, note ﬁrst that we have an
“evaluation” entailment by reﬂexivity and (6):
p ⇒q ⊢p ⇒q
(p ⇒q) ∧p ⊢q
We therefore have the rule of “modus ponens” by (4) and transitivity:
⊤⊢p ⇒q
and
⊤⊢p
⊤⊢(p ⇒q) ∧p
⊤⊢q
Moreover, by (4) there are “projections”:
p ∧q ⊢p ∧q
p ∧q ⊢p
(resp. q)
from which it follows that p ⊣⊢⊤∧p. Thus, we get one of the usual axioms for
products:
p ∧q ⊢p
⊤∧(p ∧q) ⊢p
⊤⊢(p ∧q) ⇒p
Now let us derive the usual axioms for ⇒, namely:
1. p ⇒p,
2. p ⇒(q ⇒p),
3. (p ⇒(q ⇒r)) ⇒((p ⇒q) ⇒(p ⇒r)).

116
EXPONENTIALS
The ﬁrst two are almost immediate:
p ⊢p
⊤∧p ⊢p
⊤⊢p ⇒p
p ∧q ⊢p
p ⊢q ⇒p
⊤∧p ⊢(q ⇒p)
⊤⊢p ⇒(q ⇒p)
For the third one, we shall use the fact that ⇒distributes over ∧on the
right:
a ⇒(b ∧c) ⊣⊢(a ⇒b) ∧(a ⇒c)
This is a special case of the exercise:
(B × C)A ∼= BA × CA
We also use the following simple fact, which will be recognized as a special case
of proposition 6.6:
a ⊢b
implies
p ⇒a ⊢p ⇒b
(6.2)
Then we have,
(q ⇒r) ∧q ⊢r
p ⇒((q ⇒r) ∧q) ⊢p ⇒r
(p ⇒(q ⇒r)) ∧(p ⇒q) ⊢p ⇒r
by (6.3)
(p ⇒(q ⇒r)) ⊢(p ⇒q) ⇒(p ⇒r)
⊤⊢(p ⇒(q ⇒r)) ⇒((p ⇒q) ∧(p ⇒r)).
The “positive” fragment of IPC, involving only the logical operations
⊤, ∧, ⇒
corresponds to the notion of a cartesian closed poset. We then add ⊥and dis-
junction p ∨q on the logical side and ﬁnite joins on the algebraic side to arrive
at a correspondence between IPC and Heyting algebras. The exact correspond-
ence is given by mutually inverse constructions between Heyting algebras and
intuitionistic propositional calculi. We brieﬂy indicate the interesting direction,
leaving the more routine one to the reader’s ingenuity.
Given any intuitionistic propositional calculus L, consisting of propositional
formulas p, q, r, . . . over some set of variables x, y, z, . . . together with the rules

HEYTING ALGEBRAS
117
of inference stated above, and perhaps some distinguished formulas a, b, c, . . . as
axioms, one constructs from L a Heyting algebra HA(L), called the Lindenbaum-
Tarski algebra, consisting of equivalence classes [p] of formulas p, where:
[p] = [q]
iﬀ
p ⊣⊢q
(6.3)
The ordering in HA(L) is given by:
[p] ≤[q]
iﬀ
p ⊢q
(6.4)
This is clearly well deﬁned on equivalence classes, in the sense that if p ⊢q and
[p] = [p′] then p′ ⊢q, and similarly for q. The operations in HA(L) are then
induced in the expected way by the logical operations:
1 = [⊤]
0 = [⊥]
[p] ∧[q] = [p ∧q]
[p] ∨[q] = [p ∨q]
[p] ⇒[q] = [p ⇒q]
Again, these operations are easily seen to be well deﬁned on equivalence classes,
and they satisfy the laws for a Heyting algebra because the logical rules evidently
imply them.
By (6.3) this Heyting algebra then has the property that a formula p is
provable in L just if [p] = 1. We, therefore, have the following logical completeness
theorem for IPC.
Proposition 6.11. The intuitionistic propositional calculus is complete with
respect to models in Heyting algebras.
Proof. Suppose a formula p is true in all Heyting algebras. Then in particular,
it is so in HA(L). Thus p = 1 in HA(L), and so ⊤⊢p.
In sum, then, a particular instance L of intuitionistic propositional calculus can
be regarded as a way of specifying (and reasoning about) a particular Heyting
algebra HA(L), that is, it is a presentation by generators and relations, in just
the way that we have already seen other algebraic objects like monoids have
such presentations. Indeed, the Heyting algebra HA(L) even has a UMP with
respect to L that is entirely analogous to the UMP of a monoid that is ﬁnitely
presented by generators and relations. Speciﬁcally, if, for instance, L is generated
by the two elements a, b and the single “axiom” a ∨b ⇒a ∧b, then in HA(L)
the elements [a] and [b] satisfy [a] ∨[b] ≤[a] ∧[b] (which is of course equivalent
to ([a]∨[b] ⇒[a]∧[b]) = 1), and given any Heyting algebra A with two elements
x and y satisfying x ∨y ≤x ∧y, there is a unique Heyting homomorphism
h : HA(L) →A with h([a]) = x and h([b]) = y.

118
EXPONENTIALS
6.4
Equational deﬁnition
The following description of CCCs in terms of operations and equations on a
category is sometimes useful. The proof is entirely routine and left to the reader.
Proposition 6.12. A category C is a CCC iﬀit has the following structure:
• A distinguished object 1, and for each object C there is given an arrow
!C : C →1
such that for each arrow f : C →1,
f =!C.
• For each pair of objects A, B, there is given an object A × B and arrows,
p1 : A × B →A
and
p2 : A × B →B
and for each pair of arrows f : Z →A and g : Z →B, there is given an
arrow,
⟨f, g⟩: Z →A × B
such that:
p1⟨f, g⟩= f
p2⟨f, g⟩= g
⟨p1h, p2h⟩= h
for all h : Z →A × B.
• For each pair of objects A, B, there is given an object BA and an arrow,
ϵ : BA × A →B
and for each arrow f : Z × A →B there is given an arrow
˜f : Z →BA
such that:
ϵ ◦( ˜f × 1A) = f
and
(ϵ ◦(g × 1A))= g
for all g : Z →BA, where,
g × 1A = ⟨gp1, p2⟩: Z × A →BA × A.
It is sometimes easier to check these equational conditions than to verify the
corresponding UMPs. The next section provides an example of this sort.

λ-CALCULUS
119
6.5
λ-calculus
We have seen that the notions of a cartesian closed poset with ﬁnite joins (i.e.
a Heyting algebra) and intuitionistic propositional calculus are essentially the
same,
HA ∼IPC.
These are two diﬀerent ways of describing one and the same structure; whereby,
to be sure, the logical description contains some superﬂuous data in the choice
of a particular presentation, not required by the algebraic description.
We now want to consider another, very similar, correspondence between
logic and categories, involving more general CCC’s. Indeed, the foregoing cor-
respondence was the poset case of the following general one between CCCs and
λ-calculus,
CCC ∼λ-calculus.
These notions are also essentially equivalent, in a sense that we will now sketch (a
more detailed treatment can be found in the book by Lambek and Scott). They
are two diﬀerent ways of representing the same idea, namely that of a collection
of objects and functions, with operations of pairing, projection, application, and
transposition (or “currying”).
First, recall the notion of a (typed) λ-calculus from Chapter 2. It consists
of:
• Types: A × B, A →B, . . . (and some basic types)
• Terms: x, y, z, . . . : A (variables for each type A)
a : A, b : B, . . . (possibly some typed constants)
⟨a, b⟩: A × B
(a : A, b : B)
fst(c) : A
(c : A × B)
snd(c) : B
(c : A × B)
ca : B
(c : A →B, a : A)
λx.b : A →B
(x : A, b : B)
• Equations:
fst(⟨a, b⟩) = a
snd(⟨a, b⟩) = b
⟨fst(c), snd(c)⟩= c
(λx.b)a = b[a/x]
λx.cx = c
(no x in c)

120
EXPONENTIALS
Given a particular such λ-calculus L, the associated category of types C(L)
was then deﬁned as follows:
• objects: the types,
• arrows A →B: equivalence classes of closed terms [c] : A →B, identiﬁed
according to,
[a] = [b]
iﬀL ⊢a = b
(6.5)
• identities: 1A = λx.x (where x : A),
• composition: c ◦b = λx.c(bx).
We have already seen that this is a well-deﬁned category, and that it has
binary products. It is a simple matter to add a terminal object. Now let us use
the equational characterization of CCCs to show that it is cartesian closed. Given
any objects A, B, we set BA = A →B, and as the evaluation arrow we take,
ϵ = λz.fst(z)snd(z) : BA × A →B
(z : Z).
Then for any arrow f : Z × A →B, we take as the transpose,
˜f = λzλx.f⟨z, x⟩: Z →BA
(z : Z, x : A).
It is now a straightforward λ-calculus calculation to verify the two required
equations, namely,
ϵ ◦( ˜f × 1A) = f,
(ϵ ◦(g × 1A))= g.
In detail, for the ﬁrst one recall that
α × β = λw.⟨αfst(w), βsnd(w)⟩.
So we have
ϵ ◦( ˜f × 1A) = (λz.fst(z)snd(z)) ◦[(λyλx.f⟨y, x⟩) × λu.u]
= λv.(λz.fst(z)snd(z))[(λyλx.f⟨y, x⟩) × λu.u]v
= λv.(λz.fst(z)snd(z))[λw.⟨(λyλx.f⟨y, x⟩)fst(w), (λu.u)snd(w)⟩]v
= λv.(λz.fst(z)snd(z))[λw.⟨(λx.f⟨fst(w), x⟩), snd(w)⟩]v
= λv.(λz.fst(z)snd(z))[⟨(λx.f⟨fst(v), x⟩), snd(v)⟩]
= λv.(λx.f⟨fst(v), x⟩)snd(v)
= λv.f⟨fst(v), snd(v)⟩
= λv.fv
= f.
The second equation is proved similarly.

λ-CALCULUS
121
Let us call a set of basic types and terms, together with a set of equations
between terms, a theory in the λ-calculus. Given such a theory L, the cartesian
closed category C(L) built from the λ-calculus over L is the CCC presented by
the generators and relations stated by L. Just as in the poset case of IPC and
Heyting algebras, there is a logical completeness theorem that follows from this
fact. To state it, we ﬁrst require the notion of a model of a theory L in the
λ-calculus in an arbitrary cartesian closed category C. Roughly, a model is an
assignment of the types and terms of L to objects and arrows of C:
X basic type
;
[[X]] object
b : A →B basic term
;
[[b]] : [[A]] →[[B]] arrow
This assignment is then extended to all types and terms in such a way that the
λ-calculus operations are taken to the corresponding CCC ones:
[[A × B]] = [[A]] × [[B]]
[[⟨f, g⟩]] = ⟨[[f]], [[g]]⟩
etc.
Finally, it is required that all the equations of L are satisﬁed, in the sense that:
L ⊢[a] = [b] : A →B
implies
[[a]] = [[b]] : [[A]] →[[B]]
(6.6)
This is what is sometimes called “denotational semantics” for the λ-calculus. It
is essentially the conventional, set-theoretic semantics for ﬁrst-order logic, but
extended to higher types, restricted to equational theories, and generalized to
CCCs.
For example, let L be the theory with one basic type X, two basic terms,
u : X
m : X × X →X
and the usual equations for associativity and units,
m⟨u, x⟩= x
m⟨x, u⟩= x
m⟨x, m⟨y, z⟩⟩= m⟨m⟨x, y⟩, z⟩.
Thus L is just the usual equational theory of monoids. Then a model of L in
a cartesian closed category C is nothing but a monoid in C, that is, an object
M = [[X]] equipped with a distinguished point
[[u]] : 1 →M
and a binary operation
[[m]] : M × M →M

122
EXPONENTIALS
satisfying the unit and associativity laws.
Note that by (6.5) and (6.6), there is a model of L in C(L) with the property
that [[a]] = [[b]] : X →Y if and only if a = b is provable in L. In this way, one can
prove the following CCC completeness theorem for λ-calculus.
Proposition 6.13. For any theory L in the λ-calculus, and any terms a, b in L,
L ⊢a = b
if for all models M in CCCs,
[[a]]M = [[b]]M.
This proposition says that the λ-calculus is deductively complete for models
in CCCs. It is worth emphasizing that this is not true if one restricts attention to
models in the single category Sets; indeed there are many examples of theories in
λ-calculus in which equations holding for all models in Sets are still not provable
(see the exercises for an example).
The cartesian closed category C(L) has the following UMP, analogous to the
one for any algebra presented by generators and relations. Given any model M
of L in any cartesian closed category C, there is a unique functor,
[[−]]M : C(L) →C
preserving the CCC structure, given by,
[[X]]M = M
for the basic type X, and similarly for the other basic types and terms of L. In
this precise sense, the theory L is a presentation of the cartesian closed category
C(L) by generators and relations.
Finally, let us note that the notions of λ-calculus and CCC are essentially
“equivalent,” in the sense that any cartesian closed category C also gives rise to
a λ-calculus L(C),
L ; C(L)
and this construction is essentially inverse to the one just sketched.
Brieﬂy, given C, we deﬁne L(C) by:
• basic types: the objects of C
• basic terms: a : A →B for each a : A →B in C
• equations: many equations identifying the λ-calculus operations with the
corresponding category and CCC structure on C, for example:
λx.fst(x) = p1
λx.snd(x) = p2
λy.f(x, y) = ˜f(x)
g(f(x)) = (g ◦f)(x)
λy.y = 1A

EXERCISES
123
This suﬃces to ensure that there is an isomorphism of categories,
C(L(C)) ∼= C.
Moreover, the theories L and L(C(L)) will also be “equivalent” in a suit-
able sense, involving the kinds of considerations typical of comparing diﬀerent
presentations of algebras. We refer the reader to the book by Lambek and Scott
(1986) for further details.
6.6
Exercises
1. Show that for any three objects A, B, C in a cartesian closed category, there
are isomorphisms:
(a) (A × B)C ∼= AC × BC
(b) (AB)C ∼= AB×C
2. Is the category of monoids cartesian closed?
3. Show that for any objects A, B in a cartesian closed category, there is a
bijective correspondence between points of the exponential 1 →BA and
arrows A →B.
4. Show that the category of ωCPOs is cartesian closed, but that the category
of strict ωCPOs is not (the strict ωCPOs are the ones with initial object
⊥, and the continuous maps between them are supposed to preserve ⊥).
5. In the λ-calculus, consider the theory (due to Dana Scott) of a reﬂexive
domain: there is one basic type D, two constants s and r of types s : (D →
D) →D and r : D →(D →D), and two equations,
srx = x
(x : D)
rsy = y
(y : D →D).
Prove that, up to isomorphism, this theory has only one model M in Sets,
and that every equation holds in M.

This page intentionally left blank 

7
FUNCTORS AND NATURALITY
We now want to start considering categories and functors more systematic-
ally, developing the “category theory” of category theory itself, rather than of
other mathematical objects, like groups, or formulas in a logical system. Let me
emphasize that, while some of this may look a bit like “abstract nonsense,” the
idea behind it is that when one has a particular application at hand, the theory
can then be specialized to that concrete case. The notion of a functor is a case
in point; developing its general theory makes it a clarifying, simplifying, and
powerful tool in its many instances.
7.1
Category of categories
We begin by reviewing what we know about the category Cat of categories and
functors and tying up some loose ends.
We have already seen that Cat has ﬁnite coproducts 0, C + D; and ﬁnite
products 1, C × D. It is very easy to see that there are also all small coproducts
and products, constructed analogously. We can therefore show that Cat has
all limits by constructing equalizers. Thus let categories C and D and parallel
functors F and G be given, and deﬁne the category E and functor E,
E
E
- C
F
-
G
- D
as follows (recall that for a category C, we write C0 and C1 for the collections
of objects and arrows respectively):
E0 = {C ∈C0 | F(C) = G(C)}
E1 = {f ∈C1 | F(f) = G(f)}
and let E : E →C be the evident inclusion. This is then an equalizer, as the
reader can easily check.
The category E is an example of a subcategory, that is, a monomorphism in
Cat (recall that equalizers are monic). Often, by a subcategory of a category C
one means speciﬁcally a collection U of some of the objects and arrows, U0 ⊆C0
and U1 ⊆C1), that is closed under the operations dom, cod, id, and ◦. There is

126
FUNCTORS AND NATURALITY
then an evident inclusion functor
i : U →C
which is clearly monic.
In general, coequalizers of categories are more complicated to describe—
indeed, even for posets, determining the coequalizer of a pair of monotone maps
can be quite involved, as the reader should consider.
There are various properties of functors other than being monic and epic,
which turn out to be quite useful in Cat. A few of these are given by the following:
Deﬁnition 7.1. A functor F : C →D is said to be:
• injective on objects if the object part F0 : C0 →D0 is injective, it is
surjective on objects if F0 is surjective.
• Similarly F is injective (resp. surjective) on arrows if the arrow part F1 :
C1 →D1 is injective (resp. surjective).
• F is faithful if for all A, B ∈C0, the map
FA,B : HomC(A, B) →HomD(FA, FB)
deﬁned by f →F(f) is injective.
• Similarly, F is full if FA,B is always surjective.
What is the diﬀerence between being faithful and being injective on arrows?
Consider for example the “codiagonal functor” ∇: C + C →C, as indicated in
the following:
C
- C + C 
C
@
@
@
@
@
@
1C
R

	
	
	
	
	
	
1C
C
∇
?
∇is faithful, but not injective on arrows.
A full subcategory
U ↣C
consists of some objects of C and all of the arrows between them (thus satisfying
the closure conditions for a subcategory). For example, the inclusion functor
Setsfin ↣Sets is full and faithful, but the forgetful functor Groups ↣Sets
is faithful but not full.
Example 7.2. There is another “forgetful” functor for groups, namely to the
category Cat of categories,
G : Groups →Cat.

REPRESENTABLE STRUCTURE
127
Observe that this functor is full and faithful, since a functor between groups
F : G(A) →G(B) is exactly the same thing as a group homomorphism.
And exactly the same situation holds for monoids.
For posets, too, there is a full and faithful, forgetful functor
P : Pos →Cat
again because a functor between posets F
: P(A) →P(B) is exactly a
monotone map. And the same thing holds for the “discrete category” functor
S : Sets →Cat.
Thus Cat provides a setting for comparing structures of many diﬀerent kinds.
For instance, one can have a functor R : G →C from a group G to a category
C that is not a group. If C is a poset, then any such functor must be trivial
(why?). But if C is, say, the category of ﬁnite dimensional, real vector spaces
and linear maps, then a functor R is exactly a linear representation of the group
G, representing every element of G as an invertible matrix of real numbers and
the group multiplication as matrix multiplication.
What is a functor g : P →G from a poset to a group? Since G has only one
object ∗, it will have g(p) = ∗= g(q) for all p, q ∈P. For each p ≤q, it picks an
element gp,q in such a way that
gp,p = u
(the unit of G)
gq,r · gp,q = gp,r.
For example, take P = (R, ≤) to be the ordered real numbers and G = (R, +)
the additive group of reals, then subtraction is a functor,
g : (R, ≤) →(R, +)
deﬁned by,
gx,y = (y −x).
Indeed, we have,
gx,x = (x −x) = 0
gy,z · gx,y = (z −y) + (y −x) = (z −x) = gx,z.
7.2
Representable structure
Let C be a locally small category, so that we have the representable functors,
HomC(C, −) : C →Sets
for all objects C ∈C. This function is evidently faithful if the object C has the
property that for any objects X and Y and arrows f, g : X ⇒Y , if f ̸= g there
is an arrow x : C →X such that fx ̸= gx. That is, the arrows in the category

128
FUNCTORS AND NATURALITY
are distinguished by their eﬀect on generalized elements based at C. Such an
object C is called a generator for C.
In the category of sets, for example, the terminal object 1 is a generator. In
groups, as we have already discussed, the free group F(1) on one element is a
generator. Indeed, the functor represented by F(1) is isomorphic to the forgetful
functor U : Grp →Sets,
Hom(F(1), G) ∼= U(G).
(7.1)
This isomorphism not only holds for each group G, but also respects group
homomorphisms, in the sense that for any such h : G →H there is a commutative
square,
G
Hom(F(1), G)
∼=- U(G)
H
h
?
Hom(F(1), H)
h∗
?
∼=
- U(H)
U(h)
?
One says that the isomorphism (7.1) is “natural in G.” In a certain sense, this
“explains” why the forgetful functor U preserves all limits, since representable
functors necessarily do. The related fact that the forgetful functor is faithful is
a precise way to capture the vague idea, which we initially used for motivation,
that the category of groups is “concrete.”
Recall that there are also contravariant representable functors
HomC(−, C) : Cop →Sets
taking f : A →B to f ∗: HomC(B, C) →HomC(A, C) by f ∗(h) = h ◦f for
h : B →C.
Example 7.3. Given a group G in a (locally small) category C, the contravari-
ant representable functor HomC(−, G) actually has a group structure, giving a
functor
HomC(−, G) : Cop →Grp.
In Sets, for example, for each set X we can deﬁne the operations on the group
Hom(X, G) pointwise,
u(x) = u
(the unit of G)
(f · g)(x) = f(x) · g(x)
f −1(x) = f(x)−1.
In this case, we have an isomorphism
Hom(X, G) ∼= Πx∈XG

REPRESENTABLE STRUCTURE
129
with the product group. Functoriality in X is given simply by precomposition;
thus, for any function h : Y →X, one has
h∗(f · g)(y) = (f · g)(h(y))
= f(h(y)) · g(h(y))
= h∗(f)(y) · h∗(g)(y)
= (h∗(f) · h∗(g))(y)
and similarly for inverses and the unit. Indeed, it is easy to see that this construc-
tion works just as well for any other algebraic structure deﬁned by operations
and equations.
For instance, in topology one has the ring R of real numbers and, for any
space X, the ring
C(X) = HomTop(X, R)
of real-valued, continuous functions on X. Just as in the previous case, if
h : Y →X
is any continuous function, we then get a ring homomorphism
h∗: C(X) →C(Y )
by precomposing with h. The recognition of C(X) as representable ensures that
this “ring of real-valued functions” construction is functorial,
C : Topop →Rings.
In passing from R to HomTop(X, R), all the algebraic structure of R is
retained, but properties determined by conditions that are not strictly equa-
tional are not necessarily preserved. For instance, R is not only a ring, but also
a ﬁeld, meaning that every nonzero real number r has a multiplicative inverse
r−1; formally,
∀x(x = 0 ∨∃y. y · x = 1).
To see that this condition fails in for example C(R), consider the continuous
function f(x) = x2. For any argument y ̸= 0, the multiplicative inverse must be
g(y) = 1/y2. But if this function were to be continuous, at 0 it would have to be
limy→0 1/y2 which does not exist in R.
Example 7.4. A very similar situation occurs in the category BA of Boolean
algebras. Given the Boolean algebra 2 with the usual (truth-table) operations
∧, ∨, ¬, 0, 1, for any set X, we make the set
HomSets(X, 2)

130
FUNCTORS AND NATURALITY
into a Boolean algebra with the pointwise operations:
0(x) = 0
1(x) = 1
(f ∧g)(x) = f(x) ∧g(x)
etc.
When we deﬁne the operations in this way in terms of those on 2 we see
immediately that Hom(X, 2) is a Boolean algebra too, and that precomposition
is a contravariant functor,
Hom(−, 2) : Setsop →BA
into the category BA of Boolean algebras and their homomorphisms.
Now observe that for any set X, the familiar isomorphism
Hom(X, 2) ∼= P(X)
between characteristic functions φ : X →2 and subsets Vφ = φ−1(1) ⊆X,
relates the pointwise Boolean operations in Hom(X, 2) to the subset operations
of intersection, union, etc. in P(X):
Vφ∧ψ = Vφ ∩Vψ
Vφ∨ψ = Vφ ∪Vψ
V¬φ = X −Vφ
V1 = X
V0 = ∅
In this sense, the set-theoretic Boolean operations on P(X) are induced by those
on 2, and the powerset P is seen to be a contravariant functor to the category
of Boolean algebras,
PBA : Setsop →BA.
As was the case for the covariant representable functor HomGrp(F(1), −)
and the forgetful functor U from groups to sets, here the contravariant functors
HomSets(−, 2) and PBA from sets to Boolean algebras can also be seen to be
naturally isomorphic, in the sense that for any function f : Y →X, the following
square of Boolean algebras and homomorphisms commutes:
X
Hom(X, 2)
∼=- P(X)
Y
f
6
Hom(Y, 2)
f ∗
?
∼=
- P(Y )
f −1
?

STONE DUALITY
131
7.3
Stone duality
Before considering the topic of naturality more systematically, let us take a closer
look at the foregoing example of powersets and Boolean algebras.
Recall that an ultraﬁlter in a Boolean algebra B is a proper subset U ⊂B
such that:
• 1 ∈U
• x, y ∈U implies x ∧y ∈U
• x ∈U and x ≤y implies y ∈U
• if U ⊂U ′ and U ′ is a ﬁlter, then U ′ = B
The maximality condition on U is equivalent to the condition that for every
x ∈B, either x ∈U or ¬x ∈U but not both (exercise!).
We already know that there is an isomorphism between the set Ult(B) of
ultraﬁlters on B and the Boolean homomorphisms B →2,
Ult(B) ∼= HomBA(B, 2).
This assignment Ult(B) is functorial and contravariant, and the displayed iso-
morphism above is natural in B. Indeed, given a Boolean homomorphism
h : B →B′, let
Ult(h) = h−1 : Ult(B′) →Ult(B).
Of course, we have to show that the inverse image h−1(U) ⊂B of an ultraﬁlter
U ⊂B′ is an ultraﬁlter in B. But since we know that U = χ−1
U (1) for some
χU : B′ →2, we have
Ult(h)(U) = h−1(χ−1
U (1))
= (χU ◦h)−1(1).
So Ult(h)(U) is also an ultraﬁlter. Thus, we have a contravariant functor of
ultraﬁlters
Ult : BAop →Sets
as well as the contravariant powerset functor coming back
PBA : Setsop →BA.
The constructions,
BAop  (PBA)
op
Ult
- Sets
are not mutually inverse, however. For in general, Ult(P(X)) is much larger than
X, since there are many ultraﬁlters in P(X) that are not “principal,” that is, of

132
FUNCTORS AND NATURALITY
the form {U ⊆X | x ∈U} for some x ∈X. (But what if X is ﬁnite?) Instead,
there is a more subtle relation between these functors which we consider in more
detail later; namely, these are an example of adjoint functors.
For now, consider the following observations. Let
U = Ult ◦(PBA)
op : Sets →BAop →Sets
so that,
U(X) = {U ⊆P(X) | U is an ultraﬁlter}
is a covariant functor on Sets. Now observe that for any set X there is a function,
η : X →U(X)
taking each element x ∈X to the principal ultraﬁlter
η(x) = {U ⊆X | x ∈U}.
This map is “natural” in X, that is, for any function f : X →Y , the following
diagram commutes.
X
ηX - U(X)
Y
f
?
ηY
- U(Y )
U(f)
?
This is so because, for any ultraﬁlter V in P(X),
U(f)(V) = {U ⊆Y | f −1(U) ∈V}.
So in the case of the principal ultraﬁlters η(x), we have
(U(f) ◦ηX)(x) = U(f)(ηX(x))
= {V ⊆Y | f −1(V ) ∈ηX(x)}
= {V ⊆Y | x ∈f −1(V )}
= {V ⊆Y | fx ∈V }
= ηY (fx)
= (ηY ◦f)(x).
Finally, observe that there is an analogous natural map at the “other side” of
this situation, in the category of Boolean algebras. Speciﬁcally, for every Boolean
algebra B there is a homomorphism similar to the function η,
φB : B →P(Ult(B))

NATURALITY
133
given by
φB(b) = {V ∈Ult(B) | b ∈V}.
It is not hard to see that φB is always injective. For, given any distinct
elements b, b′ ∈B, the Boolean prime ideal theorem implies that there is an
ultraﬁlter V such that b ∈V but not b′ ∈V. The Boolean algebra P(Ult(B)),
together with the homomorphism φB, is called the Stone representation of B.
It presents the arbitrary Boolean algebra B as an algebra of subsets. For the
record, we thus have the following very special case of the far-reaching Stone
Duality Theorem:
Proposition 7.5. Every Boolean algebra B is isomorphic to one consisting of
subsets of some set X, equipped with the set-theoretical Boolean operations.
7.4
Naturality
A natural transformation is a morphism of functors. That’s right: for ﬁxed cat-
egories C and D we can regard the functors C →D as the objects of a new
category, and the arrows between these objects are what we are going to call
natural transformations. They are to be thought of as diﬀerent ways of “relating”
functors to each other, in a sense that we will now explain.
Let us begin by considering a certain kind of situation that often arises: we
have some “construction” on a category C and some other “construction,” and
we observe that these two “constructions” are related to each other in a way that
is independent of the speciﬁc objects and arrows involved. That is, the relation is
really between the constructions themselves. To give a simple example, suppose
C has products and consider, for objects A, B, C ∈C,
(A × B) × C
and
A × (B × C).
Regardless of what objects A, B, and C are, we have an isomorphism
h : (A × B) × C
∼
→A × (B × C).
What does it mean that this isomorphism does not really depend on the
particular objects A, B, C? One way to explain it is this:
Given any f : A →A′, we get a commutative square
(A × B) × C
hA- A × (B × C)
(A′ × B) × C
?
hA′
- A′ × (B × C)
?

134
FUNCTORS AND NATURALITY
So what we really have is an isomorphism between the “constructions”
(−× B) × C
and
−×(B × C)
without regard to what is in the argument-place of these.
Now, by a “construction” we of course just mean a functor, and by a “relation
between constructors” we mean a morphism of functors (which is what we are
about to deﬁne). In the example, it is an isomorphism
(−× B) × C ∼= −× (B × C)
of functors C →C. In fact, we can of course consider the functors of three
arguments
F = (−1 × −2) × −3 : C3 →C
and
G = −1 × (−2 × −3) : C3 →C
and there is an analogous isomorphism
F ∼= G.
But an isomorphism is a special morphism, so let us deﬁne the general notion
ﬁrst.
Deﬁnition 7.6. For categories C, D and functors
F, G : C →D
a natural transformation ϑ : F →G is a family of arrows in D
(ϑC : FC →GC)C∈C0
such that, for any f : C →C′ in C, one has ϑC′ ◦F(f) = G(f) ◦ϑC, that is, the
following commutes:
FC
ϑC - GC
FC′
Ff
?
ϑC′
- GC′
Gf
?
Given such a natural transformation ϑ : F →G, the D-arrow ϑC : FC →GC
is called the component of ϑ at C.
If you think of a functor F : C →D as “picture” of C in D, then you can
think of a natural transformation ϑC : FC →GC as a “cylinder” with such a
picture at each end.

EXAMPLES OF NATURAL TRANSFORMATIONS
135
7.5
Examples of natural transformations
We have already seen several examples of natural transformations in previous
sections, namely the isomorphisms
HomGrp(F(1), G) ∼= U(G)
HomSets(X, 2) ∼= P(X)
HomBA(B, 2) ∼= Ult(X).
There were also the maps from Stone duality,
ηX : X →Ult(P(X))
φB : B →P(Ult(B)).
We now consider some further examples.
Example 7.7. Consider the free monoid M(X) on a set X and deﬁne a natural
transformation η : 1Sets →UM, such that each component ηX : X →UM(X) is
given by the “insertion of generators” taking every element x to itself, considered
as a word.
X
ηX- UM(X)
Y
f
?
ηY
- UM(Y )
UM(f)
?
................
This is natural, because the homomorphism M(f) on the free monoid M(X) is
completely determined by what f does to the generators.
Example 7.8. Let C be a category with products, and A ∈C ﬁxed. A natural
transformation from the functor A × −: C →C to 1C : C →C is given by
taking the component at C to be the second projection
π2 : A × C →C.
From this, together with the pairing operation ⟨−, −⟩, one can build up the
isomorphism,
h : (A × B) × C
∼
→A × (B × C).
For another such example in more detail, consider the functors
× : C2 →C
¯× : C2 →C

136
FUNCTORS AND NATURALITY
where ¯× is deﬁned on objects by
A ¯× B = B × A
and on arrows by
α ¯× β = β × α.
Deﬁne a “twist” natural transformation t : × →¯× by
t(A,B)⟨a, b⟩= ⟨b, a⟩.
To check that the following commutes,
A × B
t(A,B)- B × A
A′ × B′
α × β
?
t(A′,B′)
- B′ × A′
β × α
?
observe that for any generalized elements a : Z →A and b : Z →B,
(β × α)t(A,B)⟨a, b⟩= (β × α)⟨b, a⟩
= ⟨βb, αa⟩
= t(A′,B′)⟨αa, βb⟩
= t(A′,B′) ◦(α × β)⟨a, b⟩.
Thus t : × →¯× is natural. In fact, each component t(A,B) is an isomorphism
with inverse t(B,A). This is a simple case of an isomorphism of functors.
Deﬁnition 7.9. The functor category Fun(C, D) has
objects: functors F : C →D,
arrows: natural transformations ϑ : F →G.
For each object F, the natural transformation 1F has components
(1F )C = 1F C : FC →FC
and the composite natural transformation of F
ϑ→G
φ→H has components
(φ ◦ϑ)C = φC ◦ϑC.
Deﬁnition 7.10. A natural isomorphism is a natural transformation
ϑ : F →G
which is an isomorphism in the functor category Fun(C, D).

EXAMPLES OF NATURAL TRANSFORMATIONS
137
Lemma 7.11. A natural transformation ϑ : F →G is a natural isomorphism
iﬀeach component ϑC : FC →GC is an isomorphism.
Proof. Exercise!
In our ﬁrst example we can therefore say that the isomorphism
ϑA : (A × B) × C ∼= A × (B × C)
is natural in A, meaning that the functors
F(A) = (A × B) × C
G(A) = A × (B × C)
are naturally isomorphic.
Here is a classical example of a natural isomorphism.
Example 7.12. Consider the category
Vect(R)
of real vector spaces and linear transformations
f : V →W.
Every vector space V has a dual space
V ∗= Vect(V, R)
of linear transformations. And every linear transformation
f : V →W
gives rise to a dual linear transformation
f ∗: W ∗→V ∗
deﬁned by precomposition, f ∗(A)
=
A ◦f for A
:
W
→
R. In brief
(−)∗= Vect(−, R) : Vectop →Vect is the contravariant representable functor
endowed with vector space structure, just like the examples already considered
in Section 7.2.
As in those examples, there is a canonical linear transformation from each
vector space to its double dual,
ηV : V →V ∗∗
x →(evx : V ∗→R)
where evx(A) = A(x) for every A : V →R. This map is the component of a
natural transformation,
η : 1Vect →∗∗

138
FUNCTORS AND NATURALITY
since the following always commutes
V
ηV - V ∗∗
W
f
?
ηW
- W ∗∗
f ∗∗
?
in Vect. Indeed, given any v ∈V and A : W →R in W ∗, we have
(f ∗∗◦ηV )(v)(A) = f ∗∗(evv)(A)
= evv(f ∗(A))
= evv(A ◦f)
= (A ◦f)(v)
= A(fv)
= evfv(A)
= (ηW ◦f)(v)(A).
Now, it is a well-known fact in linear algebra that every ﬁnite dimensional
vector space V is isomorphic to its dual space V ∼= V ∗just for reasons of dimen-
sion. However, there is no “natural” way to choose such an isomorphism. On the
other hand, the natural transformation,
ηV : V →V ∗∗
is a natural isomorphism when V is ﬁnite dimensional.
Thus, the formal notion of naturality captures the informal fact that V ∼= V ∗∗
“naturally,” unlike V ∼= V ∗.
A similar situation occurs in Sets. Here we take 2 instead of R, and the dual
A∗of a set A then becomes
A∗= P(A) ∼= Sets(A, 2)
while the dual of a map f : A →B is the inverse image f ∗: P(B) →P(A).
Note that the exponential evaluation corresponds to (the characteristic
function of) the membership relation on A × P(A).
2A × A
ϵ - 2
A × P(A)
∼=
?
˜∈
- 2
id
?

EXPONENTIALS OF CATEGORIES
139
Transposing again gives a map
A
ηA- PP(A)= A∗∗
@
@
@
@
@
@
R
2P (A)
∼=
6
which is described by
ηA(a) = {U ⊆A | a ∈U}.
In Sets, one always has A strictly smaller than P(A), so ηA : A →A∗∗is
never an isomorphism. Nonetheless, η : 1Sets →∗∗is a natural transformation,
which the reader should prove.
7.6
Exponentials of categories
We now want to show that the category Cat of (small) categories and functors
is cartesian closed, by showing that any two categories C, D have an exponential
DC. Of course, we will take DC = Fun(C, D), the category of functors and nat-
ural transformations, for which we need to prove the required universal mapping
property (UMP).
Proposition 7.13. Cat is cartesian closed, with the exponentials
DC = Fun(C, D).
Before giving the proof, let us note the following. Since exponentials are unique
up to isomorphism, this gives us a way to verify that we have found the “right”
deﬁnition of a morphism of functors. For the notion of a natural transformation
is completely determined by the requirement that it makes the set Hom(C, D)
into an exponential category. This is an example of how category theory can
serve as a conceptual tool for discovering new concepts. Before giving the proof,
we need the following.
Lemma 7.14.(Bifunctor lemma). Given categories A, B and C, a map of
arrows and objects,
F0 : A0 × B0 →C0
F1 : A1 × B1 →C1
is a functor F : A × B →C iﬀ:

140
FUNCTORS AND NATURALITY
1. F is functorial in each argument: F(A, −) : B →C and F(−, B) : A →C
are functors for all A ∈A0 and B ∈B0.
2. F satisﬁes the following “interchange law:” Given α : A →A′ ∈A and
β : B →B′ ∈B, the following commutes.
F(A, B)
F(A, β)- F(A, B′)
F(A′, B)
F(α, B)
?
F(A′, β)
- F(A′, B′)
F(α, B′)
?
that is, F(A′, β) ◦F(α, B) = F(α, B′) ◦F(A, β) in C.
Proof. (of Lemma) In A × B any arrow
⟨α, β⟩: ⟨A, B⟩→⟨A′, B′⟩
factors as
⟨A, B⟩
⟨1A, β⟩- ⟨A, B′⟩
⟨A′, B⟩
⟨α, 1B⟩
?
⟨1A′, β⟩
- ⟨A′, B′⟩
⟨α, 1B′⟩
?
So (1) and (2) are clearly necessary. To show that they are also suﬃcient, we can
deﬁne the (proposed) functor:
F(⟨A, B⟩) = F(A, B)
F(⟨α, β⟩) = F(A′, β) ◦F(α, B)
The interchange law, together with functoriality in each argument, then ensures
that
F(α′, β′) ◦F(α, β) = F(⟨α′, β′⟩◦⟨α, β⟩)

EXPONENTIALS OF CATEGORIES
141
as can be read oﬀfrom the following diagram.
F(A, B)QQQQQQQQ
F(α, β)
s
F(A′, B)
F(α, B)
?
F(A′, β)
- F(A′, B′)
QQQQQQQQ
F(α′, β′)
s
F(A′, B)
F(α′, B)
?
................
...................
F(A′′, β)
- F(A′′, B′)
F(α, B′)
?
F(A′′, β′)
- F(A′′, B′′)
Proof. (of Proposition) We need to show:
1. ϵ = eval : Fun(C, D) × C →D is functorial.
2. For any category X and functor
F : X × C →D
there is a functor
˜F : X →Fun(C, D)
such that ϵ ◦( ˜F × 1C) = F.
3. Given any functor
G : X →Fun(C, D)
one has

(ϵ ◦(G × 1C)) = G.
(1) Using the bifunctor lemma, we show that ϵ is functorial.
Fix F : C →D and consider ϵ(F, −) = F : C →D. This is clearly functorial!
Next, ﬁx C ∈C0 and consider ϵ(−, C) : Fun(C, D) →D deﬁned by
(ϑ : F →G) →(ϑC : FC →GC).
This is also clearly functorial.
For the interchange law, consider any ϑ : F →G ∈Fun(C, D) and (f : C →
C′) ∈C, then we need the following to commute:
ϵ(F, C)
ϑC- ϵ(G, C)
ϵ(F, C′)
F(f)
?
ϑC′
- ϵ(G, C′)
G(f)
?

142
FUNCTORS AND NATURALITY
But this holds because ϵ(F, C) = F(C) and ϑ is a natural transformation.
The conditions (2) and (3) are now routine. For example, for (2), given
F : X × C →D
let
˜F : X →Fun(C, D)
be deﬁned by
˜F(X)(C) = F(X, C).
7.7
Functor categories
Let us consider some particular functor categories.
Example 7.15. First, clearly C1 = C for the terminal category 1. Next, what
about C2, where 2 = · →· is the single arrow category? This is just the arrow
category of C that we already know,
C2 = C→.
Consider instead the discrete category, 2 = {0, 1}. Then clearly,
C2 ∼= C × C.
Similarly for any set I (regarded as a discrete category) we have
CI ∼=

i∈I
C.
Example 7.16. “Transcendental deduction of natural transformations”
Given the possibility of functor categories DC, we can determine what the objects
and arrows therein must be as follows:
objects: these correspond uniquely to functors of the form
1 →DC
and hence to functors
C →D
arrows: by the foregoing example, these correspond uniquely to functors of the
form
1 →(DC)2

FUNCTOR CATEGORIES
143
thus to functors of the form
2 →DC
and hence to functors
C × 2 →D
respectively
C →D2.
But a functor from C into the arrow category D2 (respectively a functor into
D from the cylinder category C × 2) is exactly a natural transformation
between two functors from C into D, as the reader can see by drawing a
picture of the functor’s image in D.
Example 7.17. Recall that a (directed) graph can be regarded as a pair of sets
and a pair of functions,
G1
t -
s
- G0
where G1 is the set of edges, G0 is the set of vertices, and s and t are the source
and target operations.
A homomorphism of graphs h : G →H is a map that preserves sources and
targets. In detail, this is a pair of functions h1 : G1 →H1 and h0 : G0 →H0
such that for all edges e ∈G, we have sh1(e) = h0s(e) and similarly for t as well.
But this amounts exactly to saying that the following two diagrams commute.
G1
h1 - H1
G1
h1 - H1
G0
sG
?
h0
- H0
sH
?
G0
tG
?
h0
- H0
tH
?
Now consider the category Γ, pictured as follows:
·
-
- ·
It has exactly two objects and two distinct, parallel, non-identity arrows. A graph
G is then exactly a functor,
G : Γ →Sets
and a homomorphism of graphs h : G →H is exactly a natural transformation
between these functors. Thus, the category of graphs is a functor category,
Graphs = SetsΓ.

144
FUNCTORS AND NATURALITY
As we see later, it follows from this fact that Graphs is cartesian closed.
Example 7.18. Given a product C × D of categories, take the ﬁrst product
projection
C × D →C
and transpose it to get a functor
∆: C →CD.
For C ∈C, the functor ∆(C) is the “constant C-valued functor,”
• ∆(C)(X) = C for all X ∈D0
• ∆(x) = 1C for all x ∈D1.
Moreover, ∆(f) : ∆(C) →∆(C′) is the natural transformation, each component
of which is f.
Now suppose we have any functor
F : D →C
and a natural transformation
ϑ : ∆(C) →F.
Then the components of ϑ all look like
ϑD : C →F(D)
since ∆(C)(D) = C. Moreover, for any d : D →D′ in D, the usual naturality
square becomes a triangle, since ∆(C)(d) = 1C for all d : D →D′.
C
ϑD - FD
C
1C
?
ϑD′
- FD′
Fd
?
Thus, such a natural transformation ϑ : ∆(C) →F is exactly a cone to the
base F (with vertex C). Similarly, a map of cones ϑ →ϕ is a constant natural
transformation, that is, one of the form ∆(h) for some h : C →D, making a
commutative triangle
∆(C) ∆(h)- ∆(D)
A
A
A
A
A
A
ϑ
U 





ϕ
F

FUNCTOR CATEGORIES
145
Example 7.19. Take posets P, Q and consider the functor category,
QP .
The functors Q →P, as we know, are just monotone maps, but what is a natural
transformation?
ϑ : f →g
For each p ∈P we must have
ϑp : fp ≤gp
and if p ≤q, then there must be a commutative square involving fp ≤fq and
gp ≤gq, which, however, is automatic. Thus, the only condition is that fp ≤gp
for all p, that is, f ≤g pointwise. Since this is just the usual ordering of the
poset QP , the exponential poset agrees with the functor category. Thus, we have
the following:
Proposition 7.20. The inclusion functor,
Pos →Cat
preserves CCC structure.
Example 7.21. What happens if we take the functor category of two groups G
and H?
HG
Do we get an exponential of groups? Let us ﬁrst ask, what is a natural transforma-
tion between two group homomorphisms f, g : G →H ? Such a map ϑ : f →g
would be an element h ∈H such that for every x ∈G, we have
f(x) · h = h · g(x)
or, equivalently,
h−1 · f(x) · h = g(x).
Therefore, a natural transformation ϑ : f →g is an inner automorphism y →
h−1 · y · h of H (called conjugation by h), that takes f to g. Clearly, every such
arrow ϑ : f →g has an inverse ϑ−1 : g →f (conjugation by h−1). But HG is still
not usually a group, simply because there may be many diﬀerent homomorphisms
G →H, so the functor category HG has more than one object.
This suggests enlarging the category of groups to include also categories with
more than one object, but still having inverses for all arrows. Such categories are
called groupoids, and have been studied by topologists (they occur as the paths
between diﬀerent points in a topological space). A groupoid can thus be regarded
as a generalized group, in which the domains and codomains of elements x and
y must match up, as in any category, for the multiplication x · y to be deﬁned.

146
FUNCTORS AND NATURALITY
It is clear that if G and H are any groupoids, then the functor category HG
is also a groupoid. Thus we have the following proposition, the detailed proof of
which is left as an exercise.
Proposition 7.22. The category Grpd of groupoids is cartesian closed and the
inclusion functor
Grpd →Cat
preserves the CCC structure.
7.8
Equivalence of categories
Before examining some particular functor categories in more detail, we consider
one very special application of the idea of natural isomorphism. Consider ﬁrst
the following situation.
Example 7.23. Let Ordﬁn be the category of ﬁnite ordinal numbers. Thus, the
objects are the sets 0, 1, 2, . . . , where 0 = ∅and n = {0, . . . , n −1}, while the
arrows are all functions between these sets. Now suppose that for each ﬁnite set
A we select an ordinal |A| that is its cardinal and an isomorphism,
A ∼= |A|.
Then for each function f : A →B of ﬁnite sets we have a function |f| by
completing the square
A
∼= - |A|
B
f
?
∼=
- |B|
|f|
?
................
(7.2)
This clearly gives us a functor
| −| : Setsﬁn →Ordﬁn.
Actually, all the maps in the above square are in Setsﬁn; so we should also make
the inclusion functor
i : Ordﬁn →Setsﬁn
explicit. Then we have the selected isos,
ϑA : A
∼
→i|A|

EQUIVALENCE OF CATEGORIES
147
and we know by (7.2) that,
i(|f|) ◦ϑA = ϑB ◦f.
This of course says that we have a natural isomorphism
ϑ : 1Setsfin →i ◦| −|
between two functors of the form
Setsﬁn →Setsﬁn.
On the other hand, if we take an ordinal and take its ordinal, we get nothing
new,
|i(−)| = 1Ordfin : Ordﬁn →Ordﬁn.
This is so because, for any cardinal n,
|i(n)| = n
and we can assume that we take ϑn = 1n : n →|i(n)|, so that also,
|i(f)| = f : n →m.
In sum, then, we have a situation where two categories are very similar; but
they are not the same and they are not even isomorphic (why?). This kind of
correspondence is what is captured by the notion of equivalence of categories.
Deﬁnition 7.24. An equivalence of categories consists of a pair of functors
E : C →D
F : D →C
and a pair of natural isomorphisms
α : 1C
∼
→F ◦E
in CC
β : 1D
∼
→E ◦F
in DD.
In this situation, the functor F is called a pseudo-inverse of E. The categories
C and D are then said to be equivalent, written C ≃D.
Observe that equivalence of categories is a generalization of isomorphism.
Indeed, two categories C, D are isomorphic if there are functors.
E : C →D
F : D →C
such that
1C = GF
1D = FG.

148
FUNCTORS AND NATURALITY
In the case of equivalence C ≃D, we replace the identity natural transformations
by natural isomorphisms.
Experience has shown that the mathematically signiﬁcant properties of
objects are those that are invariant under isomorphisms, and in category theory,
identity of objects is a much less important relation than isomorphism. So it is
really equivalence of categories that is the more important notion of “similarity”
for categories. One can think of equivalence of categories as “isomorphism up to
isomorphism.”
In the foregoing example Setsﬁn ≃Ordﬁn, we see that every set is isomorphic
to an ordinal, and the maps between ordinals are just the maps between them
as sets. Thus we have:
1. for every set A, there is some ordinal n with A ∼= i(n),
2. for any ordinals n, m, there is an isomorphism
HomOrdfin(n, m) ∼= HomSetsfin(i(n), i(m))
where i : Ordﬁn →Setsﬁn is the inclusion functor.
In fact, these conditions are characteristic of equivalences, as the following
proposition shows.
Proposition 7.25. The following conditions on a functor F : C →D are
equivalent:
1. F is (part of) an equivalence of categories.
2. F is full and faithful and “essentially surjective” on objects: for every D ∈D
there’s some C ∈C such that FC ∼= D.
Proof. (1 implies 2) Take E : D →C, and
α : 1C
∼
→EF
β : 1D
∼
→FE.
In C, for any C, we then have αC : C
∼
→EF(C), and
C
αC- EF(C)
C′
f
?
αC′
- EF(C′)
EF(f)
?
commutes for any f : C →C′.
Thus, if F(f) = F(f ′), then EF(f) = EF(f ′), so f = f ′. So F is faithful.
Note that by symmetry, E is also faithful.

EQUIVALENCE OF CATEGORIES
149
Now take any arrow
h : F(C) →F(C′) in D,
and consider
C
∼= - EF(C)
C′
f
?
∼=
- EF(C′)
E(h)
?
where f = (αC′)−1 ◦E(h) ◦αC. Then we have also F(f) : F(C) →F(C′) and
EF(f) = E(h) : EF(C) →EF(C′)
by the square
C
αC- EF(C)
C′
f
?
αC′
- EF(C′)
EF(f)
?
Since E is faithful, F(f) = h. So F is also full.
Finally, for any object D ∈D, we have
β : 1D
∼
→FE
so
βD : D ∼= F(ED),
for ED ∈C0.
(2 implies 1) We need to deﬁne E : D →C and natural transformations,
α : 1C
∼
→EF
β : 1D
∼
→FE.
Since F is essentially surjective, for each D ∈D0 we can pick some E(D) ∈C0
such that there’s some βD : D
∼
→FE(D). That gives E on objects and the
proposed components of β : 1D →FE.

150
FUNCTORS AND NATURALITY
Given h : D →D′ in D, consider
D
βD - FE(D)
D′
h
?
βD′
- FE(D′)
βD′ ◦h ◦β−1
D
?
................
Since F : C →D is full and faithful, we can ﬁnd a unique arrow
E(h) : E(D) →E(D′)
with FE(h) = βD′ ◦h ◦β−1
D . It is easy to see that then E : D →C is a functor
and β : 1D
∼
→FE is clearly a natural isomorphism.
To ﬁnd α : 1C →EF, apply F to C and consider βF C : F(C) →FEF(C).
Since F is full and faithful, the preimage of βF C is an isomorphism,
αC = F −1(βF C) : C
∼
→EF(C)
which is easily seen to be natural, since β is.
7.9
Examples of equivalence
Example 7.26. Pointed sets and partial maps
Let Par be the category of sets and partial functions. An arrow
f : A ⇁B
is a function |f| : Uf →B for some Uf ⊆A. Identities in Par are the same as
those in Sets, that is,
1A is the total identity function on A. The composite
of f : A ⇁B and g : B ⇁C is given as follows: Let U(g◦f) := f −1(Ug) ⊆A,
and |g ◦f| : U(g◦f) →C is the horizontal composite indicated in the following
diagram, in which the square is a pullback.
|f|−1(Ug)
- Ug
|g|
- C
Uf
?
?
|f|
- B
?
?
A
?
?

EXAMPLES OF EQUIVALENCE
151
It is easy to see that composition is associative and that the identities are
units.
The category of pointed sets,
Sets∗
has as objects, sets A equipped with a distinguished “point” a ∈A, that is, pairs,
(A, a) with a ∈A.
Arrows are functions that preserve the point, that is, an arrow f : (A, a) →(B, b)
is a function f : A →B such that f(a) = b.
Now we show:
Proposition 7.27. Par ∼= Sets∗
The functors establishing the equivalence are as follows:
F : Par →Sets∗
and is deﬁned on an object A by F(A) = (A ∪{∗}, ∗) where ∗is a new point
that we add to A. We also write A∗= A ∪{∗}. For arrows, given f : A ⇁B,
F(f) : A∗→B∗is deﬁned by
f∗(x) =

f(x)
if x ∈Uf
∗
otherwise.
Then clearly f∗(∗A) = ∗B, so in fact f∗: A∗→B∗as required.
Coming back, the functor
G : Sets∗→Par
is deﬁned on an object (A, a) by G(A, a) = A−{a} and for an arrow f : (A, a) →
(B, b)
G(f) : A −{a} ⇁B −{b}
is the function with domain
UG(f) = A −f −1(b)
deﬁned by G(f)(x) = f(x) for every f(x) ̸= b.
Now F ◦G is the identity on Par, because we are just adding a new point
and then throwing it away. But G ◦F is only naturally isomorphic to 1Sets∗,
since we have
(A, a) ∼= ((A −{a}) ∪{∗}, ∗).

152
FUNCTORS AND NATURALITY
These sets are not equal, since a ̸= ∗. It still needs to be checked, of course,
that F and G are functorial, and that the comparison (A, a) ∼= ((A−{a})∪{∗}, ∗)
is natural, but we leave these easy veriﬁcations to the reader.
Example 7.28. Slice categories and indexed families
For any set I, the functor category SetsI is the category of I-indexed sets.
The objects are I-indexed families of sets
(Ai)i∈I
and the arrows are I-indexed families of functions,
(fi : Ai →Bi)i∈I : (Ai)i∈I −→(Bi)i∈I.
This category has an equivalent description that is often quite useful: it is
equivalent to the slice category of Sets over I, consisting of arrows α : A →I
and “commutative triangles” over I (see Section 1.6),
SetsI ≃Sets/I.
Indeed, deﬁne functors
Φ : SetsI −→Sets/I
Ψ : Sets/I −→SetsI
on objects as follows:
Φ((Ai)i∈I) = π :

i∈I
Ai →I
(the indexing projection)
Ψ(α : A →I) = (α−1{i})i∈I
and analogously on arrows. We leave it as an exercise to show that these are
mutually pseudo-inverse functors. (Why are they not inverses?)
The equivalent description of SetsI as Sets/I has the advantage that the
slice category E/E makes sense for any object E in a general category E, where
the functor category EE usually does not (for instance, in topological spaces).
This allows the intuition of an “E-indexed family of objects of E” to be made
precise. If E has pullbacks, reindexing along an arrow f : E →F in E is then
represented by the pullback functor f ∗: E/F →E/E. This is also worked out in
the exercises.
Example 7.29. Stone duality
A class of examples of equivalences of categories are given by what are called
“dualities.” Often, classical duality theorems are not of the form C ∼= Dop (much
less C = Dop), but rather C ≃Dop, that is, C is equivalent to the opposite

EXAMPLES OF EQUIVALENCE
153
(or “dual”) category of D. This is because the duality is established by a con-
struction which returns the original thing only up to isomorphism, not “on the
nose.” Here is a simple example, which is a very special case of the far-reaching
Stone-Duality theorem.
Proposition 7.30. The category of ﬁnite Boolean algebras is equivalent to the
opposite of the category of ﬁnite sets,
BAﬁn ≃Setsop
ﬁn.
Proof. The functors involved here are the contravariant powerset functor
PBA : Setsop
ﬁn →BAﬁn
on one side (the powerset of a ﬁnite set is ﬁnite!). Going back, we will use the
functor,
A : BAop
ﬁn →Setsﬁn
taking the set of atoms of a Boolean algebra,
A(B) = {a ∈B | 0 < a and (b < a ⇒b = 0)}.
In the ﬁnite case, this is isomorphic to the ultraﬁlter functor that we have already
studied (see Section 7.3).
Lemma 7.31. For any ﬁnite Boolean algebra B, there is an isomorphism
between atoms a in B and ultraﬁlters U ⊆B, given by
U →

b∈U
b
and
a →↑(a).
Proof. If a is an atom then ↑(a) is an ultraﬁlter, since for any b either a ∧b = a
and then b ∈↑(a) or a ∧b = 0 and so ¬b ∈↑(a).
If U ⊆B is an ultraﬁlter then 0 < 
b∈U b, because, since U is ﬁnite and
closed under intersections, we must have 
b∈U b ∈U. If 0 ̸= b0 < 
b∈U b then
b0 is not in U, so ¬b0 ∈U. But then b0 < ¬b0 and so b0 = 0.
Plainly ↑(
b∈U b) ⊆U since b ∈U implies 
b∈U b ⊆b. Now let 
b∈U b ≤a
for some a not in U. Then ¬a ∈U implies that also 
b∈U b ≤¬a, and so

b∈U b ≤a ∧¬a = 0, which is impossible.
Since we know that the set of ultraﬁlters Ult(B) is contravariantly functorial (it
is represented by the Boolean algebra 2, see Section 7.3), we therefore also have
a contravariant functor of atoms A ∼= Ult. The explicit description of this functor
is this: if h : B →B′ and a′ ∈A(B′), then it follows from the lemma that there’s

154
FUNCTORS AND NATURALITY
a unique atom a ∈B such that a′ ≤h(b) iﬀa ≤b for all b ∈B. To ﬁnd this
atom a, take the intersection over the ultraﬁlter h−1(↑(a′)). Thus we can set
A(h)(a′) = a, to get a function
A(h) : A(B′) →A(B).
Of course, we must still check that this is a pseudo-inverse for PBA : Setsop
ﬁn →
BAﬁn. The required natural isomorphisms,
αX : X →A(P(X))
βB : B →P(A(B))
are explicitly described as follows.
The atoms in a ﬁnite powerset P(X) are just the singletons {x} for x ∈X,
thus αX(x) = {x} is clearly an isomorphism.
To deﬁne βB, let
βB(b) = {a ∈A(B) | a ≤b}.
To see that βB is also iso, consider the proposed inverse,
(βB)−1(B) =

a∈B
a
for B ⊆A(B).
The isomorphism then follows from the following lemma, the proof of which is
routine.
Lemma 7.32. For any ﬁnite Boolean algebra B,
1. b = 	{a ∈A(B) | a ≤b}.
2. If a is an atom and a ≤b ∨b′, then a ≤b or a ≤b′.
Of course, one must still check that α and β really are natural transforma-
tions. This is left to the reader.
Finally, we remark that the duality
BAﬁn ≃Setsop
ﬁn
extends to one between all sets on the one side and the complete, atomic Boolean
algebras, on the other,
caBA ≃Setsop.
where, a Boolean algebra B is complete if every subset U ⊆B has a join 	 U ∈B
and a complete homomorphism preserves these joins and B is atomic if every
nonzero element 0 ̸= b ∈B has some a ≤b with a an atom.
Moreover, this is just the discrete case of the full Stone Duality The-
orem, which states an equivalence between the category of all Boolean algebras

EXERCISES
155
and the opposite of a certain category of topological spaces, called “Stone
spaces,” and all continuous maps between them. See the book by Johnstone
for details.
7.10
Exercises
1. Consider the (covariant) composite functor,
F = PBA ◦Ultop : BA →Setsop →BA
taking each Boolean algebra B to the powerset algebra of sets of ultraﬁlters
in B. Note that
F(B) ∼= HomSets(HomBA(B, 2), 2)
is
a
sort
of
“double-dual”
Boolean
algebra.
There
is
always
a
homomorphism,
φB : B →F(B)
given by φB(b) = {V ∈Ult(B) | b ∈V}. Show that for any Boolean
homomorphism h : A →B, the following square commutes.
A
φA - F(A)
B
h
?
φB
- F(B)
F(h)
?
2. Consider the forgetful functors
Groups
U
−→Monoids
V
−→Sets
Say whether each is faithful, full, injective on arrows, surjective on arrows,
injective on objects, and surjective on objects.
3. Show that a natural transformation is a natural isomorphism just if
each of its components is an isomorphism. Is the same true for mono-
morphisms?
4. Prove that for any ﬁnite Boolean algebra B, the Stone representation
φ : B →PUlt(B)
is an isomorphism of Boolean algebras. Note the similarity to the case of
ﬁnite dimensional vector spaces.

156
FUNCTORS AND NATURALITY
5. Show that a functor category DC has binary products if D does (construct
the product of two functors F and G “objectwise”: (F × G)(C) = F(C) ×
G(C)).
6. Show that the map of sets
ηA : A −→PP(A)
a −→{U ⊆A|a ∈U}
is the component at A of a natural transformation η : 1Sets →PP, where
P : Setsop →Sets is the (contravariant) powerset functor.
7. Let C be a locally small category. Show that there is a functor
Hom : Cop × C →Sets
such that for each object C of C,
Hom(C, −) : C →Sets
is the covariant representable functor and
Hom(−, C) : Cop →Sets
is the contravariant one. (Hint: use the Bifunctor Lemma)
8. What sorts of properties of categories do not respect equivalence? Find
one that respects isomorphism, but not equivalence.
9. A category is skeletal if isomorphic objects are always identical. Show that
every category is equivalent to a skeletal subcategory. (Every category has
a “skeleton.”)
10. Complete the proof that, for any set I, the category of I-indexed families
of sets, regarded as the functor category SetsI, is equivalent to the slice
category Sets/I of sets over I,
SetsI ≃Sets/I.
Show that reindexing of families along a function f : J →I, given by
precomposition,
Setsf((Ai)i∈I) = (Af(j))j∈J
is represented by pullback, in the sense that the following diagram of
categories and functors commutes up to natural isomorphism.

EXERCISES
157
SetsI
≃- Sets/I
SetsJ
Setsf
?
≃
- Sets/J
f ∗
?
Here f ∗: Sets/J →Sets/I is the pullback functor along f : J →I.

This page intentionally left blank 

8
CATEGORIES OF DIAGRAMS
In this chapter we will prove a very useful technical result called the Yoneda
Lemma. It is probably the single most used result in category theory. Indeed,
it is amazing how often it comes up, especially in view of the fact that it is a
straightforward generalization of facts that we were able to show fairly easily
about monoids and posets.
8.1
Set-valued functor categories
We are going to focus on special functor categories of the form,
SetsC
where the category C is locally small. Thus the objects are set-valued functors,
P, Q : C →Sets
(sometimes called “diagrams on C”), and the arrows are natural transformations
α, β : P →Q.
Remember that, for each object C ∈C, we can evaluate any commutative
diagram in SetsC,
P
α
- Q
@
@
@
@
@
@
βα
RR
β
?
at any object C to get a commutative diagram in Sets,
PC
αC - QC
@
@
@
@
@
@
(βα)C
R
RC
βC
?
(8.1)

160
CATEGORIES OF DIAGRAMS
Thus, for each object C there is an evaluation functor
evC : SetsC →Sets.
Moreover, naturality means that if we have any arrow f : D →C, we get
a “cylinder” over the diagram (8.1) in Sets. One way of thinking about such
functor categories that was already considered in Section 7.7 is suggested by
considering the case where C is the category Γ pictured as:
1
-
- 0
Then a set-valued functor G : Γ →Sets is just a graph and a natural
transformation α : G →H is a graph homomorphism. Thus, for this case,
SetsΓ = Graphs.
This suggests regarding an arbitrary category of the form SetsC as a generalized
“category of structured sets” and their “homomorphisms”; indeed, this is a very
useful way of thinking of such functors and their natural transformations.
8.2
The Yoneda embedding
Among the objects of SetsC are certain very special ones, namely the (covariant)
representable functors,
HomC(C, −) : C →Sets.
Observe that for each h : C →D in C, we have a natural transformation
HomC(h, −) : HomC(D, −) →HomC(C, −)
(note the direction!) where the component at X is deﬁned by precomposition:
(f : D →X) →(f ◦h : C →X).
Thus, we have a contravariant functor
k : Cop →SetsC
deﬁned by k(C) = HomC(C, −). Of course, this functor k is just the exponential
transpose of the bifunctor
HomC : Cop × C →Sets
which was shown as an exercise to be functorial.
If we instead transpose HomC with respect to its other argument, we get a
covariant functor,
y : C →SetsCop

THE YONEDA EMBEDDING
161
from C to a category of contravariant set-valued functors, sometimes called
“presheaves.” (Or, what amounts to the same thing, we can put D = Cop and
apply the previous considerations to D in place of C.) More formally:
Deﬁnition 8.1. The Yoneda embedding is the functor y : C →SetsCop taking
C ∈C to the contravariant representable functor,
yC = HomC(−, C) : Cop →Sets
and taking f : C →D to the natural transformation,
yf = HomC(−, f) : HomC(−, C) →HomC(−, D).
A functor F : C →D is called an embedding if it is full, faithful, and injective
on objects. We will soon show that y really is an embedding; this is a corollary
of the Yoneda Lemma.
One should thus think of the Yoneda embedding y as a “representation” of C
in a category of set-valued functors and natural transformations on some index
category. Compared to the Cayley representation considered in Section 1.5, this
one has the virtue of being full: any map ϑ : yC →yD in SetsCop comes from
a unique map h : C →D in C as yh = ϑ. Indeed, recall that the Cayley
representation of a group G was an injective group homomorphism
G ↣Aut(|G|) ⊆|G||G|
where each g ∈G is represented as an automorphism ˜g of the set |G| of elements
(i.e. a “permutation”), by letting it “act on the left,”
g(x) = g · x
and the group multiplication is represented by composition of permutations,

g · h = ˜g ◦˜h.
We also showed a generalization of this representation to arbitrary categories.
Thus for any monoid M, there is an analogous representation
M ↣End(|M|) ⊆|M||M|
by left action, representing the elements of M as endomorphisms of |M|.
Similarly, any poset P can be represented as a poset of subsets and inclusions
by considering the poset Low(P) of “lower sets” A ⊆P, that is, subsets that are
“closed down” in the sense that a′ ≤a ∈A implies a′ ∈A, ordered by inclusion.
Taking the “principal lower set”
↓(p) = {q ∈P | q ≤p}
of each element p ∈P determines a monotone injection
↓: P ↣Low(P) ⊆P(|P|)
such that p ≤q iﬀ↓(p) ⊆↓(q).

162
CATEGORIES OF DIAGRAMS
The representation given by the Yoneda embedding is “better” than these
in that it cuts down the arrows in the codomain category to just those in the
image of the representation functor y : C →SetsCop (since y is full). Indeed,
there may be many automorphisms α : G →G of a group G that are not left
actions by an element, but if we require α to commute with all right actions
α(x · g) = α(x) · g, then α must itself be a left action. This is what the Yoneda
embedding does in general; it adds enough “structure” to the objects yA in
the image of the representation that the only “homomorphisms” ϑ : yA →yB
between those objects are the representable ones ϑ = yh for some h : A →B. In
this sense, the Yoneda embedding y represents the objects and arrows of C as
certain “structured sets” and (all of ) their “homomorphisms.”
8.3
The Yoneda Lemma
Lemma 8.2.(Yoneda). Let C be locally small. For any object C ∈C and functor
F ∈SetsCop there is an isomorphism
Hom(yC, F) ∼= FC
which, moreover, is natural in both F and C.
Here:
(1) the Hom is HomSetsCop,
(2) naturality in F means that, given any ϑ : F →G, the following diagram
commutes:
Hom(yC, F)
∼=- FC
Hom(yC, G)
Hom(yC, ϑ)
?
∼=
- GC
ϑC
?
(3) naturality in C means that, given any h : C →D, the following diagram
commutes:
Hom(yC, F)
∼=- FC
Hom(yD, F)
Hom(yh, F)
6
∼=
- FD
Fh
6

THE YONEDA LEMMA
163
Proof. To deﬁne the desired isomorphism,
ηC,F : Hom(yC, F)
∼
=
−→FC
take ϑ : yC →F and let
ηC,F (ϑ) = ϑC(1C)
which we shall also write as
xϑ = ϑC(1C)
where ϑC : C(C, C) →FC and so ϑC(1C) ∈FC.
Conversely, given any a ∈FC we deﬁne the natural transformation ϑa :
yC →F as follows. Given any C′ we deﬁne the component
(ϑa)C′ : Hom(C′, C) →FC′
by setting
(ϑa)C′(h) = F(h)(a)
for h : C′ →C.
To show that ϑa is natural, take any f : C′′ →C′ and consider the diagram:
Hom(C′′, C) (ϑa)C′′- FC′′
Hom(C′, C)
Hom(f, C)
6
(ϑa)C′
- FC′
F(f)
6
We then calculate, for any h ∈yC(C′)
(ϑa)C′′ ◦Hom(f, C)(h) = (ϑa)C′′(h ◦f)
= F(h ◦f)(a)
= F(f) ◦F(h)(a)
= F(f)(ϑa)C′(h).
So ϑa is indeed natural.
Now to show that ϑa and xϑ are mutually inverse, let us calculate ϑxϑ for
a given ϑ : yC →F. First, just from the deﬁnitions, we have that for any
h : C′ →C,
(ϑ(xϑ))C′(h) = F(h)(ϑC(1C)).

164
CATEGORIES OF DIAGRAMS
But since ϑ is natural, the following commutes:
yC(C)
ϑC- FC
yC(C′)
yC(h)
?
ϑC′
- FC′
Fh
?
So, continuing,
(ϑ(xϑ))C′(h) = F(h)(ϑC(1C))
= ϑC′ ◦yC(h)(1C)
= ϑC′(h).
Therefore ϑ(xϑ) = ϑ.
Going the other way around, for any a ∈FC we have
xϑa = (ϑa)C(1C)
= F(1C)(a)
= 1F C(a)
= a.
Thus, Hom(yC, F) ∼= FC, as required.
The naturality claims are also easy: given φ : F
→F ′, taking ϑ ∈
Hom(yC, F), and chasing around the diagram
(yC, F)
ηC,F- FC
(yC, F ′)
(yC, φ)
?
ηC,F ′
- F ′C
φC
?
we get
φC(xϑ) = φC(ϑC(1C))
= (φϑ)C(1C)
= x(φϑ)
= ηC,F ′((yC, φ)(ϑ)).

THE YONEDA LEMMA
165
For naturality in C, take some f : C′ →C. We then have
ηC′(yf)∗(ϑ) = ηC′(ϑ ◦yf)
= (ϑ ◦yf)C′(1C′)
= ϑC′ ◦(yf)C′(1C′)
= ϑC′(f ◦1C′)
= ϑC′(f)
= ϑC′(1C ◦f)
= ϑC′ ◦(yC)(f)(1C)
= F(f) ◦ϑC(1C)
= F(f)ηC(ϑ).
The penultimate equation is by the naturality square,
yC(C)
ϑC- F(C)
yC(C′)
yC(f)
?
ϑC′
- F(C′)
F(f)
?
Therefore, ηC′ ◦(yf)∗= F(f) ◦ηC.
We leave the naturality in F as an exercise.
The Yoneda Lemma is used to prove our ﬁrst “theorem.”
Theorem 8.3. The Yoneda embedding y : C →SetsCop is full and faithful.
Proof. For any objects C, D ∈C we have an isomorphism
HomC(C, D) = yD(C) ∼= HomSetsCop(yC, yD).
And this isomorphism is indeed induced by the functor y, since it takes h : C →D
to the natural transformation ϑh : yC →yD given by
(ϑh)C′(f : C′ →C) = yD(f)(h)
= HomC(f, D)(h)
= h ◦f
= (yh)C′(f).
So ϑh = y(h).

166
CATEGORIES OF DIAGRAMS
Remark 8.4. Note the following:
• If C is small, then SetsCop is locally small, and so Hom(yC, P) in SetsCop
is a set.
• If C is locally small, then SetsCop need not be locally small. In this case,
the Yoneda Lemma tells us that Hom(yC, P) is always a set.
• If C is not locally small, then y : C →SetsCop will not even be deﬁned, so
the Yoneda Lemma does not apply.
Finally, observe that the Yoneda embedding y : C →SetsCop is also injective
on objects. For, given objects A, B in C, if yA = yB then 1C ∈Hom(C, C) =
yC(C) = yD(C) = Hom(C, D) implies C = D.
8.4
Applications of the Yoneda Lemma
One frequent sort of application of the Yoneda Lemma is of the following form:
given objects A, B in a category C, to show that A ∼= B it suﬃces to show that
yA ∼= yB in SetsCop. This results from the foregoing theorem and the fact that,
if F : C →D is any full and faithful functor, then FA ∼= FB clearly implies
A ∼= B. We record this as the following.
Corollary 8.5. Given objects A and B in any locally small category C,
yA ∼= yB
implies
A ∼= B.
A typical such case is this. In any cartesian closed category C, there is an
isomorphism,
(AB)C ∼= A(B×C).
Recall how involved it was to prove this directly, using the compound universal
mapping property (UMP). Now, we just need to show that
y((AB)C) ∼= y(A(B×C)).
To that end, take any object X ∈C, then we have isomorphisms
Hom(X, (AB)C) ∼= Hom(X × C, AB)
∼= Hom((X × C) × B, A)
∼= Hom(X × (B × C), A)
∼= Hom(X, A(B×C)).
Of course, it must be checked that these isomorphisms are natural in X, but
that’s left as an easy exercise.
Let us do another example of this kind.
Proposition 8.6. If the cartesian closed category C has coproducts, then C is
“distributive,” that is, there is a canonical isomorphism,
(A × B) + (A × C) ∼= A × (B + C).

LIMITS IN CATEGORIES OF DIAGRAMS
167
Proof. As in the previous proposition, we check that
Hom(A × (B + C), X) ∼= Hom(B + C, XA)
∼= Hom(B, XA) × Hom(C, XA)
∼= Hom(A × B, X) × Hom(A × C, X)
∼= Hom((A × B) + (A × C), X).
Finally, one sees easily that these isos are all natural in X.
We have already seen a simple logical example of the Yoneda Lemma: to show
that in the propositional calculus one has ϕ ⊣⊢ψ for some formulas ϕ, ψ, it
suﬃces to show that for any formula ϑ, one has ϑ ⊢ϕ iﬀϑ ⊢ψ.
More generally, given any objects A, B in a locally small category C, to ﬁnd
an arrow h : A →B it suﬃces to give one ϑ : yA →yB in SetsCop, for then there
is a unique h with ϑ = yh. Why should it be easier to give an arrow yA →yB
than one A →B? The key diﬀerence is that in general SetsCop has much more
structure to work with than does C; as we will see, it is complete, cocomplete,
cartesian closed, and more. So one can use various “higher-order” tools, from
limits to λ-calculus; and if the result is an arrow of the form yA →yB, then
it comes from a unique one A →B—despite the fact that C may not admit
the “higher-order” constructions. In that sense, the category SetsCop is like
an extension of C by “ideal elements” that permit calculations which can not
be done in C. This is something like passing to the complex numbers to solve
equations in the reals, or adding higher types to an elementary logical theory.
8.5
Limits in categories of diagrams
Recall that a category E is said to be complete if it has all small limits; that is,
for any small category J and functor F : J →E there is a limit L = lim
←−j∈J Fj
in E and a “cone” η : ∆L →F in EJ, universal among arrows from constant
functors ∆E. Here the constant functor ∆: E →EJ is the transposed projection
E × J →E.
Proposition 8.7. For any locally small category C, the functor category
SetsCop is complete. Moreover, for every object C ∈C the evaluation functor
evC : SetsCop →Sets
preserves all limits.
Proof. Suppose we have J small and F : J →SetsCop. The limit of F, if it
exists, is an object in SetsCop, hence is a functor,
(lim
←−
i∈J
Fi) : Cop →Sets.

168
CATEGORIES OF DIAGRAMS
By the Yoneda Lemma, if we had such a functor, then for each object C ∈C
we’d have a natural isomorphism,
(lim
←−Fi)(C) ∼= Hom(yC, lim
←−Fi).
But then it would be the case that,
Hom(yC, lim
←−Fi) ∼= lim
←−Hom(yC, Fi)
in Sets
∼= lim
←−Fi(C)
in Sets.
where the ﬁrst isomorphism is because representable functors preserve limits,
and the second is Yoneda again. Thus we simply deﬁne the limit lim
←−i∈J Fi to be
(lim
←−
i∈J
Fi)(C) = lim
←−
i∈J
(FiC)
(8.2)
that is, the pointwise limit of the functors Fi. The reader can easily work out
how lim
←−Fi acts on C-arrows, and what the universal cone is. Direct veriﬁcation
shows that it is a limit in SetsCop.
Finally, the preservation of limits by evaluation functors is stated by (8.2).
8.6
Colimits in categories of diagrams
The notion of cocompleteness is of course the dual of completeness: a cat-
egory is cocomplete if it has all (small) colimits. Like the foregoing proposition
about the completeness of SetsCop, its cocompleteness actually follows simply
from the fact that Sets is cocomplete. We leave the proof of the following as an
exercise.
Proposition 8.8. Given any categories C and D, if D is cocomplete, then so
is the functor category DC, and the colimits in DC are “computed pointwise,”
in the sense that for every C ∈C, the evaluation functor
evC : DC →D
preserves colimits. Thus, for any small index category J and functor A : J →
DC, and for each C ∈C there is a canonical isomorphism,
(lim
−→
j∈J
Aj)(C) ∼= lim
−→
j∈J
(AjC).
Proof. Exercise.
Corollary 8.9. For any locally small C, the functor category SetsCop is
cocomplete, and colimits there are computed pointwise.

COLIMITS IN CATEGORIES OF DIAGRAMS
169
PC
C
C
k
h
C
C
x
x
x
Sets
P
C
PC
PC
Pk
Ph
p
Figure 8.1: Category of elements
Proposition 8.10. For any small category C, every object P in the functor
category SetsCop is a colimit of representable functors,
lim
−→
j∈J
yAj ∼= P.
More precisely, there is a canonical choice of an index category J and a functor
A : J →C such that there is a natural isomorphism lim
−→J y ◦A ∼= P.
Proof. Given P : Cop →Sets, the index category we need is the so-called
category of elements of P, written,

C
P
and deﬁned as follows.
objects: pairs (x, C) where C ∈C and x ∈PC,
arrows: an h : (x′, C′) →(x, C) is an arrow h : C′ →C in C such that
P(h)(x) = x′
(8.3)
actually, the arrows are triples of the form (h, (x′, C′), (x, C)) satisfying (8.3).
The reader can easily work out the obvious identities and composites. See
Figure 8.1.
Note that

C P is a small category since C is small. There is a “projection”
functor,
π :

C
P →C
deﬁned by π(x, C) = C and π(h, (x′, C′), (x, C)) = h.

170
CATEGORIES OF DIAGRAMS
To deﬁne the cocone of the form y ◦π →P, take an object (x, C) ∈

C P and
observe that (by the Yoneda Lemma) there is a natural, bijective correspondence
between,
x ∈P(C)
x : yC →P
which we simply identify notationally. Moreover, given any arrow h : (x′, C′) →
(x, C) naturality in C implies that there is a commutative triangle
yC
@
@
@
@
@
@
x
RP
	
	
	
	
	
	
x′

yC′
yh
6
Indeed, the category

C P is equivalent to the full subcategory
y/P ↣SetsCop/P
of the slice category over P on the objects (i.e. arrows in SetsCop) with
representable domains.
We can therefore take the component of the desired cocone yπ →P at (x, C)
to be simply x : yC →P. To see that this is a colimiting cocone, take any
cocone yπ →Q with components ϑ(x,C) : yC →Q and we require a unique
natural transformation ϑ : P →Q as indicated in the following diagram.
yC
@
@
@
@
@
@
x
R
HHHHHHHHHHHH
ϑ(x,C)
j
P ...................
ϑ
- Q
	
	
	
	
	
	
x′


ϑ(x′,C′)
*
yC′
yh
6
We can deﬁne ϑC : PC →QC by setting
ϑC(x) = ϑ(x,C)

COLIMITS IN CATEGORIES OF DIAGRAMS
171
where we again identify,
ϑ(x,C) ∈Q(C)
ϑ(x,C) : yC →Q
This assignment is easily seen to be natural in C, again by the natural isomorph-
ism of the Yoneda Lemma. We leave the remaining veriﬁcation of uniqueness to
the reader as well.
We include the following because it ﬁts naturally here, but defer the proof to
the next chapter, where a neat proof can be given using adjoint functors. The
reader may wish to prove it at this point using the materials at hand, which is
also quite doable.
Proposition 8.11. For any small category C, the Yoneda embedding
y : C →SetsCop
is the “free cocompletion” of C, in the following sense. Given any cocomplete
category E and functor F : C →E, there is a colimit preserving functor F! :
SetsCop →E, unique up to natural isomorphism with the property
F! ◦y ∼= A
as indicated in the following diagram.
SetsCop ..............
F! - E
	
	
	
	
	
	
F

C
y
6
Proof. (Sketch, see Proposition 9.16.) Given F : C →E, deﬁne F! as follows. For
any P ∈SetsCop, let
lim
−→
j∈J
yAj ∼= P
be the canonical presentation of P as a colimit of representables with J =

C P,
the category of elements of P. Then set,
F!(P) = lim
−→
j∈J
F(Aj)
which exists since E is cocomplete.

172
CATEGORIES OF DIAGRAMS
8.7
Exponentials in categories of diagrams
As an application, let us consider exponentials in categories of the form SetsCop
for small C. We will need the following lemma.
Lemma 8.12. For any small index category J, functor A : J →SetsCop and
diagram B ∈SetsCop, there is a natural isomorphism
lim
−→
j
(Aj × B) ∼= (lim
−→
j
Aj) × B.
(8.4)
Brieﬂy, the functor −× B : SetsCop →SetsCop preserves colimits.
Proof. To specify the canonical natural transformation mentioned in (8.4), start
with the cocone,
ϑj : Aj →lim
−→
j
Aj,
j ∈J
apply the functor −× B to get a cocone,
ϑj × B : Aj × B →(lim
−→
j
Aj) × B,
j ∈J
and so there is a “comparison arrow” from the colimit,
ϑ : lim
−→
j
(Aj × B) →(lim
−→
j
Aj) × B
which we claim is a natural isomorphism.
By a past exercise, it suﬃces to show that each component,
ϑC : (lim
−→
j
(Aj × B))(C) →((lim
−→
j
Aj) × B)(C)
is iso. But since the limits and colimits involved are all computed pointwise, it
therefore suﬃces to show (8.4) under the assumption that the Aj and B are just
sets. To that end, take any set X and consider the following isomorphisms in
Sets,
Hom(lim
−→
j
(Aj × B), X) ∼= lim
←−
j
Hom(Aj × B, X)
∼= lim
←−
j
Hom(Aj, XB)
(Sets is CCC)
∼= Hom(lim
−→
j
Aj, XB)
∼= Hom((lim
−→
j
Aj) × B, X).
Since these are natural in X, the claim follows by Yoneda.

EXPONENTIALS IN CATEGORIES OF DIAGRAMS
173
Now suppose we have functors P and Q and we want QP . The reader should
try to construct the exponential “pointwise,”
QP (C)
?= Q(C)P (C)
to see that it does not work (it is not functorial).
If we had such an exponential QP , we could compute its value at any object
C ∈C by Yoneda:
QP (C) ∼= Hom(yC, QP )
And if it is to be an exponential, then we must also have
Hom(yC, QP ) ∼= Hom(yC × P, Q).
But this latter set does exist. Thus, we can just deﬁne
QP (C) = Hom(yC × P, Q)
(8.5)
with the action on h : C′ →C being
QP (h) = Hom(yh × 1P , Q).
This is clearly a contravariant, set-valued functor on C. Let us now check that
it indeed gives an exponential of P and Q.
Proposition 8.13. For any objects X, P, Q in SetsCop, there is an isomorph-
ism, natural in X,
Hom(X, QP ) ∼= Hom(X × P, Q).
Proof. By Proposition 8.10, for a suitable index category J, we can write X as
a colimit of representables,
X ∼= lim
−→
j∈J
yCj.
Thus we have isomorphisms,
Hom(X, QP ) ∼= Hom(lim
−→
j
yCj, QP )
∼= lim
←−
j
Hom(yCj, QP )
∼= lim
←−
j
QP (Cj)
(by Yoneda)
∼= lim
←−Hom(yCj × P, Q)
(by 8.5)
∼= Hom(lim
−→
j
(yCj × P), Q)
∼= Hom(lim
−→
j
(yCj) × P, Q)
(Lemma 8.12)
∼= Hom(X × P, Q).

174
CATEGORIES OF DIAGRAMS
And these isos are clearly natural in X.
Theorem 8.14. For any small category C, the category of diagrams SetsCop is
cartesian closed. Moreover, the Yoneda embedding
y : C →SetsCop
preserves all products and exponentials that exist in C.
Proof. In light of the foregoing proposition, it only remains to show that y
preserves products and exponentials. We leave this as an exercise.
8.8
Topoi
Since we are now so close to it, we might as well introduce the important notion of
a “topos,” even though this is not the place to develop that theory, as appealing
as it is. First we require the following generalization of characteristic functions
of subsets.
Deﬁnition 8.15. Let E be a category with all ﬁnite limits. A subobject classiﬁer
in E consists of an object Ωtogether with an arrow t : 1 →Ωthat is a “universal
subobject,” in the following sense:
Given any object E and any subobject U ↣E, there is a unique arrow
u : E →Ωmaking the following diagram a pullback.
U
- 1
E
?
?
u
- Ω
t
?
(8.6)
The arrow u is called the classifying arrow of the subobject U ↣E; it can
be thought of as taking exactly the part of E that is U to the “point” t of Ω.
The most familiar example of a subobject classiﬁer is of course the set 2 = {0, 1}
with a selected element as t : 1 →2. The fact that every subset U ⊆S of any set
S has a unique characteristic function u : S →2 is then exactly the subobject
classiﬁer condition.
It is easy show that a subobject classiﬁer is unique up to isomorphism: the
pullback condition is clearly equivalent to requiring the contravariant subobject
functor,
SubE(−) : Eop →Sets
(which acts by pullback) to be representable,
SubE(−) ∼= HomE(−, Ω).

TOPOI
175
The required isomorphism is just the pullback condition stated in the deﬁnition
of a subobject classiﬁer.
Deﬁnition 8.16. A topos is a category E such that
1. E has all ﬁnite limits,
2. E has a subobject classiﬁer,
3. E has all exponentials.
This compact deﬁnition proves to be amazingly rich in consequences: it can
be shown for instance that topoi also have all ﬁnite colimits and that every
slice category of a topos is again a topos. We refer the reader to the books by
Mac Lane and Moerdijk, Johnstone, and McLarty for information on topoi, and
here just give an example (albeit one that covers a very large number of cases).
Proposition 8.17. For any small category C, the category of diagrams SetsCop
is a topos.
Proof. Since we already know that SetsCop has all limits, and we know that
it has exponentials by the foregoing section, we just need to ﬁnd a subobject
classiﬁer. To that end, we deﬁne a sieve on an object C of C to be a set S of
arrows f : · →C (with arbitrary domain) that is closed under precomposition,
that is, if f : D →C is in S then so is f ◦g : E →D →C for every g : E →D
(think of a sieve as a common generalization of a “lower set” in a poset and an
“ideal” in a ring). Then let
Ω(C) = {S ⊆C1 | S is a sieve on C}
and given h : D →C let
h∗: Ω(C) →Ω(D)
be deﬁned by
h∗(S) = {g : · →D | h ◦g ∈S}.
This clearly deﬁnes a presheaf Ω: Cop →Sets, with a distinguished point,
t : 1 →Ω
namely, at each C, the “total sieve”
tC = {f : · →C}.
We claim that t : 1 →Ωso deﬁned is a subobject classiﬁer for SetsCop. Indeed,
given any object E and subobject U ↣E, deﬁne u : E →Ωat any object
C ∈C by:
uC(e) = {f : D →C | f ∗(e) ∈U(D) ↣E(D)}

176
CATEGORIES OF DIAGRAMS
for any e ∈E(C). That is, uC(e) is the sieve of arrows into C that take e ∈E(C)
back into the subobject U.
The reader should verify that this speciﬁcation does indeed determine a
unique classifying morphism for U ↣E.
Remark 8.18. One of the most fascinating aspects of topoi is their relation to
logic. In virtue of the association of subobjects U ↣E with arrows u : E →Ω,
the subobject classiﬁer Ωcan be regarded as an object of “propositions” or
“truth-values,” with t = true. An arrow u : E →Ωis then a “propositional
function” of which U ↣E is the “extension.” For, by the pullback condition
(8.6), a generalized element x : X →E is “in” U (i.e. factors through U ↣E)
just if ux = true,
x ∈E U
iﬀ
ux = true
so that, again in the notation of Section 5.1,
U = {x ∈E | ux = true}.
This permits an interpretation of ﬁrst-order logic in any topos, since topoi also
have a way of modeling the logical quantiﬁers ∃and ∀as adjoints to pullbacks
(as will be described in Section 9.5).
Since topoi are also cartesian closed, they have an internal type theory
described by the λ-calculus (see Section 6.5). Combining this with the ﬁrst-order
logic and subobject classiﬁer Ωprovides a natural interpretation of higher-order
logic, essentially employing the exponential ΩE as a “power object” P(E) of
subobjects of E. This logical aspect of topoi is also treated in the books already
mentioned.
8.9
Exercises
1. If F : C →D is full and faithful, then C ∼= C′ iﬀFC ∼= FC′.
2. Let C be a locally small, cartesian closed category. Use the Yoneda
embedding to show that for any objects A, B, C in C
(A × B)C ∼= AC × BC
(cf. Problem 1., Chapter 6). If C also has binary coproducts, show that also
A(B+C) ∼= AB × AC.
3. For any locally small category C, the functor category SetsCop has binary
products F × G, and these are computed pointwise:
(F × G)(C) ∼= FC × GC
for all C ∈C0.

EXERCISES
177
4. Let C be a locally small category with binary products, and show that the
Yoneda embedding
y: C →SetsCop
preserves them. (Hint: this involves only a few lines of calculation.)
If C also has exponentials, show that y also preserves them.
5.
(a) Explicitly determine the subobject classiﬁers for the topoi Sets2 and
Setsω, where as always 2 is the poset 0 < 1 and ω is the poset of
natural numbers 0 < 1 < 2 < · · · .
(b) Show that (Setsﬁn)2 is a topos.

This page intentionally left blank 

9
ADJOINTS
This chapter represents the high point of this book, the goal toward which we
have been working steadily. The notion of adjoint functor applies everything
that we have learned up to now to unify and subsume all the diﬀerent univer-
sal mapping properties that we have encountered, from free groups to limits to
exponentials. But more importantly, it also captures an important mathematical
phenomenon that is invisible without the lens of category theory. Indeed, I will
make the admittedly provocative claim that adjointness is a concept of funda-
mental logical and mathematical importance that is not captured elsewhere in
mathematics. pt
Many of the most striking applications of category theory involve adjoints and
many important and fundamental mathematical notions are instances of adjoint
functors. As such, they share the common behavior and formal properties of
all adjoints and in many cases this fact alone accounts for all of their essential
features.
9.1
Preliminary deﬁnition
We begin by recalling the universal mapping property (UMP) of free monoids:
every monoid M has an underlying set U(M), and every set X has a free monoid
F(X), and there is a function
iX : X →UF(X)
with the following UMP.
For every monoid M and every function f : X →U(M) there is a unique
homomorphism g : F(X) →M such that f = U(g) ◦iX, all as indicated in
the diagram:
F(X) ................
g - M
UF(X) U(g)
- U(M)
	
	
	
	
	
	
f

X
iX
6

180
ADJOINTS
Now consider the following map
φ : HomMon(F(X), M) →HomSets(X, U(M))
deﬁned by
g →U(g) ◦iX.
The UMP above says exactly that φ is an isomorphism,
HomMon(F(X), M) ∼= HomSets(X, U(M)).
(9.1)
This bijection (9.1) can also be written schematically as a 2-way rule
F(X)
- M
X
- U(M)
where one gets from an arrow g of the upper form to one φ(g) of the lower form
by the recipe
φ(g) = U(g) ◦iX.
We pattern our preliminary deﬁnition of adjunction on this situation. It is
preliminary because it really only gives half of the picture, as it were; in the
next section an equivalent deﬁnition will emerge as both more convenient and
conceptually clearer.
Deﬁnition 9.1 (preliminary). An adjunction between categories C and D
consists of functors
F : C  - D : U
and a natural transformation
η : 1C →U ◦F
with the property:
(*) For any C ∈C, D ∈D, and f : C →U(D), there exists a unique
g : FC →D such that
f = U(g) ◦ηC
as indicated in
F(C) ..................
g
- D
U(F(C)) U(g)- U(D)
	
	
	
	
	
	
f

C
ηC
6

PRELIMINARY DEFINITION
181
Terminology and notation:
• F is called the left adjoint, U is called the right adjoint, and η is called the
unit of the adjunction.
• One sometimes writes F ⊣U for “F is left and U right adjoint.”
• The statement (*) is the UMP of the unit η.
Note that the situation F ⊣U is a generalization of equivalence of cat-
egories, in that a pseudo-inverse is an adjoint. In that case, however, it is the
relation between categories that one is interested in. Here, one is concerned with
the relation between speciﬁc functors. Thus, it is not the relation on categories
“there exists an adjunction,” but rather “this functor has an adjoint” that we
are concerned with.
Suppose now that we have an adjunction,
C  U
F
- D.
Then, as in the example of monoids, take C ∈C and D ∈D and consider the
operation
φ : HomD(FC, D) →HomC(C, UD)
given by φ(g) = U(g) ◦ηC. Since, by the UMP of η, every f : C →UD is φ(g)
for a unique g, just as in our example we see that φ is an isomorphism
HomD(F(C), D) ∼= HomC(C, U(D))
(9.2)
which, again, can be displayed as the two-way rule:
F(C)
- D
C
- U(D)
Example 9.2. Consider the “diagonal” functor,
∆: C →C × C
deﬁned on objects by
∆(C) = (C, C)
and on arrows by
∆(f : C →C′) = (f, f) : (C, C) →(C′, C′).
What would it mean for this functor to have a right adjoint? We would need a
functor R : C × C →C such that for all C ∈C and (X, Y ) ∈C × C, there is a
bijection:
∆C
- (X, Y )
C
- R(X, Y )

182
ADJOINTS
That is, we would have
HomC(C, R(X, Y )) ∼= HomC×C(∆C, (X, Y ))
∼= HomC(C, X) × HomC(C, Y ).
We therefore must have R(X, Y ) ∼= X × Y , suggesting that ∆has as a right
adjoint the product functor × : C × C →C,
∆⊣×.
The counit η would have the form ηC : C →C × C, so we propose the
“diagonal arrow” ηC = ⟨1C, 1C⟩, and we need to check the UMP indicated in
the following.
(C, C) ...........................
(f1, f2) - (X, Y )
C × C
f1 × f2 - X × Y

f
3
C
ηC
6
Indeed, given any f : C →X × Y , we have unique f1 and f2 with f = ⟨f1, f2⟩,
for which we then have
(f1 × f2) ◦ηC = ⟨f1π1, f2π2⟩ηC
= ⟨f1π1ηC, f2π2ηC⟩
= ⟨f1, f2⟩
= f.
Thus in sum, the functor ∆has a right adjoint if and only if C has binary
products.
Example 9.3. For an example of a diﬀerent sort, consider the category Pos of
posets and monotone maps and CPos of cocomplete posets and cocontinuous
maps. A poset C is cocomplete just if it has a join 	
i ci for every family of ele-
ments (ci)i∈I indexed by a set I, and a monotone map f : C →D is cocontinuous
if it preserves all such joins, f(	
i ci) = 	
i f(ci). There is an obvious forgetful
functor
U : CPos →Pos.
What would a left adjoint F ⊣U be? There would have to be a monotone map
η : P →UF(P) with the property: given any cocomplete poset C and monotone

HOM-SET DEFINITION
183
f : P →U(C), there exists a unique cocontinuous ¯f : F(P) →C such that
f = U( ¯f) ◦ηP , as indicated in
F(P) .................
¯f - C
UF(P) U( ¯f)- U(C)
	
	
	
	
	
	
f

P
η
6
In this precise sense, such a poset F(P) would be a “free cocompletion” of P,
and η : P →UF(P) a “best approximation” of P by a cocomplete poset.
We leave it to the reader to show that such a “cocompletion” always exists,
namely the poset of lower sets,
Low(P) = {U ⊆P | p′ ≤p ∈U implies p′ ∈U}.
9.2
Hom-set deﬁnition
The following proposition shows that the isomorphism (9.2) is in fact natural in
both C and D.
Proposition 9.4. Given categories and functors,
C 
U
F
- D
the following conditions are equivalent:
1. F is left adjoint to U; that is, there is a natural transformation
η : 1C →U ◦F
that has the UMP of the unit:
For any C ∈C, D ∈D and f : C →U(D) there exists a unique
g : FC →D such that
f = U(g) ◦ηC.
2. For any C ∈C and D ∈D there is an isomorphism,
φ : HomD(FC, D) ∼= HomC(C, UD)
that is natural in both C and D.

184
ADJOINTS
Moreover, the two conditions are related by the formulas
φ(g) = U(g) ◦ηC
ηC = φ(1F C).
Proof. (1 implies 2) The recipe for φ, given η is just the one stated and we
have already observed it to be an isomorphism, given the UMP of the unit. For
naturality in C, take h : C′ →C and consider the following diagram:
HomD(FC, D)
φC,D
∼=
- HomC(C, UD)
HomD(FC′, D)
(Fh)∗
?
∼=
φC′,D
- HomC(C′, UD)
h∗
?
Then for any f : FC →D we have
h∗(φC,D(f)) = (U(f) ◦ηC) ◦h
= U(f) ◦UF(h) ◦ηC′
= U(f ◦F(h)) ◦ηC′
= φC′,D(F(h)∗(f)).
For naturality in D, take g : D →D′ and consider the diagram
HomD(FC, D)
φC,D
∼=
- HomC(C, UD)
HomD(FC, D′)
g∗
?
∼=
φC′,D
- HomC(C, UD′)
U(g)∗
?
Then for any f : FC →D we have
U(g)∗(φC,D(f)) = U(g) ◦(U(f) ◦ηC)
= U(g ◦f) ◦ηC
= φC′,D(g ◦f) ◦ηC
= φC′,D(g∗(f)) ◦ηC.
So φ is indeed natural.
(2 implies 1) We are given a bijection φ,
F(C)
- D
C
- U(D)
(9.3)

HOM-SET DEFINITION
185
for each C, D, that is natural in C and D. In detail, this means that given a
commutative triangle
F(C)
f - D
@
@
@
@
@
@
g ◦f
R
D′
g
?
there are two ways to get an arrow of the form C →UD′, namely
C
φ(f)- UD
@
@
@
@
@
@
φ(g ◦f)
R
UD′
U(g)
?
Naturality in D means that this diagram commutes,
φ(g ◦f) = U(g) ◦φ(f).
Dually, naturality in C means that given
C′
@
@
@
@
@
@
f ◦h
R
C
h
?
f
- UD
and writing ψ = φ−1, the following commutes:
FC′
@
@
@
@
@
@
ψ(f ◦h)
R
FC
Fh
?
ψ(f)
- D
That is,
ψ(f ◦h) = ψ(f) ◦F(h).
Now, given such a natural bijection φ we want a natural transformation
η : 1C →U ◦F

186
ADJOINTS
with the UMP of the unit. To ﬁnd
ηC : C →UFC
we put FC for D and 1F C : FC →FC in the adjoint schema (9.3) to get
1F C :
FC
- FC
φ
ηC :
C
- UFC
That is, we deﬁne
ηC = φ(1F C).
Finally, to see that η has the required UMP of the unit, it clearly suﬃces to show
that for all g : FC →D, we have
φ(g) = U(g) ◦ηC
since we are assuming that φ is iso. But
Ug ◦ηC = Ug ◦φ(1F C)
= φ(g ◦1F C)
= φ(g).
Note that the second condition in the proposition is symmetric, but the ﬁrst
condition is not. This implies that we also have following dual proposition.
Corollary 9.5. Given categories and functors
C 
U
F
- D
the following conditions are equivalent:
1. For any C ∈C, D ∈D there is an isomorphism
φ : HomD(FC, D) ∼= HomC(C, UD)
that is natural in C and D.
2. There is a natural transformation
ϵ : F ◦U →1D
with the following UMP:
For any C ∈C, D ∈D and g : F(C) →D, there exists a unique
f : C →UD such that:
g = ϵD ◦F(f)

EXAMPLES OF ADJOINTS
187
as indicated in the diagram:
C .................
f - U(D)
F(C) F(f)- FU(D)
@
@
@
@
@
@
g
RD
ϵD
?
Moreover, the two conditions are related by the equations
ψ(f) = ϵD ◦F(f)
ϵD = ψ(1UD)
where ψ = φ−1.
Proof. Duality.
We take the symmetric “Hom-set” formulation as our “oﬃcial” deﬁnition of an
adjunction.
Deﬁnition 9.6 “oﬃcial”. An adjunction consists of functors
F : C  - D : U
and a natural isomorphism
φ : HomD(FC, D) ∼= HomC(C, UD) : ψ.
This deﬁnition has the virtue of being symmetric in F and U. The unit
η : 1C →U ◦F and the counit ϵ : F ◦U →1D of the adjunction are then
determined as:
ηC = φ(1F C)
ϵD = ψ(1UD)
9.3
Examples of adjoints
Example 9.7. Suppose C has binary products. Take a ﬁxed object A ∈C, and
consider the product functor
−× A : C →C
deﬁned on objects by
X →X × A

188
ADJOINTS
and on arrows by
(h : X →Y ) →(h × 1A : X × A −→Y × A).
When does −× A have a right adjoint?
We would need a functor
U : C →C
such that for all X, Y ∈C there is a natural bijection
X × A
- Y
X
- U(Y )
So let us try deﬁning U by
U(Y ) = Y A
on objects and on arrows by
U(g : Y →Z) = gA : Y A −→ZA.
Putting U(Y ) for X in the adjoint schema above then gives the counit:
Y A × A
ϵ - Y
Y A
1
- Y A
This is, therefore, an adjunction if ϵ has the following UMP:
For any f : X × A →Y , there is a unique ¯f : X →Y A such that f =
ϵ ◦( ¯f × 1A).
But this is exactly the UMP of the exponential! Thus, we do indeed have an
adjunction:
−× A ⊣−A
Example 9.8. Here is a much more simple example. For any category C, consider
the unique functor to the terminal category 1,
! : C →1.
Now we ask, when does ! have a right adjoint? This would be an object U : 1 →C
such that for any C ∈C, there is a bijective correspondence,
!C
- ∗
C
- U(∗)
Such a U would have to be a terminal object in C. So ! has a right adjoint iﬀC
has a terminal object. What do you think a left adjoint would be?

EXAMPLES OF ADJOINTS
189
This last example is a clear case of the following general fact:
Proposition 9.9. Adjoints are unique up to isomorphism. Speciﬁcally, given a
functor F : C →D and right adjoints U, V : D →C,
F ⊣U
and
F ⊣V
we then have U ∼= V .
Proof. Here is the easy way. For any D ∈D, and C ∈C we have
HomC(C, UD) ∼= HomD(FC, D)
naturally, since F ⊣U
∼= HomC(C, V D)
naturally, since F ⊣V .
Thus, by Yoneda, UD ∼= V D. But this isomorphism is natural in D, again by
adjointness.
This proposition implies that one can use the condition of being right or left
adjoint to a given functor to deﬁne (uniquely characterize up to isomorphism)
a new functor. This sort of characterization, like a UMP, determines an object
or construction “intrinsically,” in terms of its relation to some other given con-
struction. Many important constructions turn out to be adjoints to particularly
simple ones.
For example, what do you suppose would be a left adjoint to the diagonal
functor
∆: C →C × C
in the earlier example, where ∆(C) = (C, C) and we had ∆⊣× ? It would have
to be functor L(X, Y ) standing in the correspondence
L(X, Y )
- C
(X, Y )
- (C, C)
Thus, it could only be the coproduct L(X, Y ) = X + Y . Therefore, ∆has a left
adjoint if and only if C has binary coproducts, and then
+ ⊣∆.
Next, note that C × C ∼= C2 where 2 is the discrete two-object category
(i.e. any two-element set). Then ∆(C) is the constant C-valued functor for each
C ∈C. Let us now replace 2 by any small index category J and consider possible
adjoints to the corresponding diagonal functor
∆: C →CJ
with ∆(C)(j) = C for all C ∈C and j ∈J. In this case, one has left and right
adjoints
lim
−→⊣∆⊣lim
←−

190
ADJOINTS
if and only if C has colimits and limits, respectively, of type J. Thus all of the
particular limits and colimits we met earlier, such as pullbacks and coequalizers
are instances of adjoints. We leave the proof of the general fact as an exercise.
What are the units and counits of these adjunctions?
Example 9.10. Polynomial rings: Let R be a commutative ring (Z if you like) and
consider the ring R[x] of polynomials in one indeterminate x with coeﬃcients in
R. The elements of R[x] all look like this:
r0 + r1x + r2x2 + · · · + rnxn
(9.4)
with the coeﬃcients ri ∈R. Of course, there may be some identiﬁcations between
such expressions depending on the ring R.
There is an evident homomorphism η : R →R[x], taking elements r to
constant polynomials r = r0, and it has the following UMP:
Given any ring A, homomorphism α : R →A, and element a ∈A, there is
a unique homomorphism
a∗: R[x] →A
such that a∗(x) = a and a∗η = α.
R[x]
a∗
- A
	
	
	
	
	
	
α

R
η
6
Namely, for a∗we take the “formal evaluation at a”
a∗(r(x)) = α(r)(a/x)
given by applying α to the coeﬃcients ri, substituting a for x, and evaluating
the result in A,
a∗(r0 + r1x + r2x2 + · · · + rnxn) = α(r0) + α(r1)a + α(r2)a2 + · · · + α(rn)an.
To describe this in terms of adjoints, deﬁne Rings∗to be the category of
“pointed” rings, with objects of the form (A, a), where A is a ring and a ∈A,
and arrows h : (A, a) →(B, b) are homomorphisms h : A →B that preserve the
distinguished point, h(a) = b.
The UMP just given says exactly that the functor
U : Rings∗→Rings
that “forgets the point” U(A, a) = A has as left adjoint the functor
[x] : Rings →Rings∗

ORDER ADJOINTS
191
that “adjoins an indeterminate”
[x](R) = (R[x], x)
and η : R →R[x] is the unit of the adjunction. The reader should have no
diﬃculty working out the details of this example. This provides a characteriza-
tion of the polynomial ring R[x] that does not depend on the somewhat vague
description in terms of “formal polynomial expressions” like (9.4).
9.4
Order adjoints
Let P be a preordered set, that is, a category in which there is at most one arrow
x →y between any two objects. A poset is a preorder that is skeletal. We deﬁne
an ordering relation on the objects of P by
x ≤y
iﬀthere exists an arrow x →y.
Given another such preorder Q, suppose we have adjoint functors:
P
F
-

U
Q
F ⊣U
Then the correspondence Q(Fa, x) ∼= P(a, Ux) comes down to the simple con-
dition Fa ≤x iﬀa ≤Ux. Thus an adjunction on preorders consists simply of
order preserving maps F, U satisfying the two-way rule or “bicondition”:
Fa ≤x
a ≤Ux
For each p ∈P, the unit is therefore an element p ≤UFp that is least among all
x with p ≤Ux. Dually, for each q ∈Q the counit is an element FUq ≤q that is
greatest among all y with Fy ≤q.
Such a set-up on preordered sets is sometimes called a Galois connection.
Example 9.11. A basic example is the interior operation on the subsets of a
topological space X. Let O(X) be the set of open subsets of X and consider the
operations of inclusion and interior:
inc : O(X) →P(X)
int : P(X) →O(X)
For any subset A and open subset U, the valid bicondition
U ⊆A
U ⊆int(A)
means that the interior operation is right adjoint to the inclusion of the open
subsets among all the subsets:
inc ⊣int

192
ADJOINTS
The counit here is the inclusion int(A) ⊆A, valid for all subsets A. The case of
closed subsets and the closure operation is dual.
Example 9.12. A related example is the adjunction on powersets induced by any
function f : A →B, between the inverse image operation f −1 and the direct
image im(f),
P(A) f −1
im(f)
- P(B)
Here we have an adjunction im(f) ⊣f −1 as indicated by the bicondition
im(f)(U) ⊆V
U ⊆f −1(V )
which is plainly valid for all subsets U ⊆A and V ⊆B.
The inverse image operation f −1 : P(B) →P(A) also has a right adjoint,
given by
f∗(U) = {b ∈B | f −1(b) ⊆U}
which we also leave for the reader to verify.
Note that if A and B are topological spaces and f : A →B is continuous,
then f −1 restricts to the open sets f −1 : O(B) →O(A). Then the left adjoint
im(f) need not exist (on opens), but the right adjoint f∗still does.
O(A) f −1
f∗
- O(B)
Example 9.13. Suppose we have a preorder P. Then, as we know, P has meets
iﬀfor all p, q ∈P, there is an element p ∧q ∈P satisfying the bicondition
r ≤p ∧q
r ≤p and r ≤q
Dually, P has joins if there is always an element p ∨q ∈P such that
p ∨q ≤r
p ≤r and q ≤r
The Heyting implication q ⇒r is characterized as an exponential by the
bicondition
p ∧q ≤r
p ≤q ⇒r
Finally, an initial object 0 and a terminal object 1 are determined by the
conditions
0 ≤p

QUANTIFIERS AS ADJOINTS
193
and
p ≤1.
In this way, the notion of a Heyting algebra can be formulated entirely in terms of
adjoints. Equivalently, the intuitionistic propositional calculus is neatly axiomat-
ized by the “adjoint rules of inference” just given. Together with the reﬂexivity
and transitivity of entailment p ⊢q, these rules are completely suﬃcient for the
propositional logical operations. That is, they can serve as the rules of infer-
ence for a logical calculus of “sequents” p ⊢q which is equivalent to the usual
intuitionistic propositional calculus.
When we furthermore deﬁne negation by ¬p = p ⇒⊥, we then get the
derived rule
q ⊢¬p
p ∧q ≤0
Finally, the classical propositional calculus results from adding the rule
¬¬p ⊢p.
Let us now consider how this analysis can be extended to all of ﬁrst-order
logic.
9.5
Quantiﬁers as adjoints
Traditionally, the main obstacle to the further development of algebraic logic
has been the treatment of the quantiﬁers. Categorical logic solves this problem
beautifully with the recognition (due to F.W. Lawvere in the 1960s) that they,
too, are adjoint functors.
Let L be a ﬁrst-order language. For any list ¯x = x1, . . . , xn of distinct
variables let us denote the set of formulas with at most those variables free by
Form(¯x) = {φ(¯x) | φ(¯x) has at most ¯x free}.
Then Form(¯x) is a preorder under the entailment relation of ﬁrst-order logic
φ(¯x) ⊢ψ(¯x).
Now let y be a variable not in the list ¯x, and note that we have a trivial
operation
∗: Form(¯x) →Form(¯x, y)
taking each φ(¯x) to itself; this is just a matter of observing that if φ(¯x) ∈Form(¯x)
then y cannot be free in φ(¯x). Of course, ∗is a functor since,
φ(¯x) ⊢ψ(¯x)
in Form(¯x)

194
ADJOINTS
implies,
∗φ(¯x) ⊢∗ψ(¯x)
in Form(¯x, y).
Now since for any ψ(¯x, y) ∈Form(¯x, y) there is, of course, no free y in the formula
∀y.ψ(¯x, y), there is a map
∀y : Form(¯x, y) →Form(¯x).
We claim that this map is right adjoint to ∗,
∗⊣∀.
Indeed, the usual rules of universal introduction and elimination imply that the
following two-way rule of inference holds:
∗φ(¯x) ⊢ψ(¯x, y)
Form(¯x, y)
φ(¯x) ⊢∀y.ψ(¯x, y)
Form(¯x)
Observe that this derived rule, saying that the operation ∀y which binds the
variable y, is right adjoint to the trivial operation ∗, also takes account of the
usual “book-keeping” side-conditions of the quantiﬁer rules.
Conversely, we could instead take this adjoint rule as basic and derive the
customary introduction and elimination rules from it. Indeed, the counit of the
adjunction is the usual ∀-elimination “axiom”
∀y.ψ(¯x, y) ⊢ψ(¯x, y).
It is now natural to wonder about the other quantiﬁer; indeed, we have a
further adjunction
∃⊣∗⊣∀
since the following two-way rule also holds.
∃y.ψ(¯x, y) ⊢φ(¯x)
ψ(¯x, y) ⊢φ(¯x)
Here the unit is the existential introduction “axiom”
ψ(¯x, y) ⊢∃y.ψ(¯x, y).
It actually follows from these rules that ∃y and ∀y are in particular functors,
that is, that ψ ⊢φ implies ∃y.ψ ⊢∃y.φ and similarly for ∀.
The adjoint rules just given can therefore be used in place of the customary
introduction and elimination rules, to give a complete system of deduction for
quantiﬁcational logic. Many typical laws of predicate logic are just simple formal

QUANTIFIERS AS ADJOINTS
195
manipulations of adjoints. For example:
ψ(x, y) ⊢ψ(x, y)
ψ(x, y) ⊢∃y.ψ(x, y)
(unit of ∃⊣∗)
∀x.ψ(x, y) ⊢∃y.ψ(x, y)
(counit of ∗⊣∀)
∃y∀x.ψ(x, y) ⊢∃y.ψ(x, y)
(∃⊣∗)
∃y∀x.ψ(x, y) ⊢∀x∃y.ψ(x, y)
(∗⊣∀)
The recognition of the quantiﬁers as adjoints also gives rise to the following
geometric interpretation. Take any L structure M and consider a formula φ(x)
in at most one variable x. It determines a subset,
[φ(x)]M = {m ∈M | M |= φ(m)} ⊆M.
Similarly, a formula in several variables determines a subset of the cartesian
product
[ψ(x1, . . . , xn)]M = {(m1, . . . , mn) | M |= ψ(m1, . . . , mn)} ⊆M n.
For instance [x = y]M is the diagonal subset {(m, m) | m ∈M} ⊆M × M.
Let us take two variables x, y and consider the eﬀect of the ∗operation on these
subsets. The assignment ∗[φ(x)] = [∗φ(x)] determines a functor
∗: P(M) →P(M × M).
Explicitly, given [φ(x)] ∈P(M), we have
∗[φ(x)] = {(m1, m2) ∈M × M | M |= φ(m1)} = π−1([φ(x)])
where π : M × M →M is the ﬁrst projection. Thus,
∗= π−1.
Similarly, the existential quantiﬁer can be regarded as an operation on subsets
by ∃[ψ(x, y)] = [∃y.ψ(x, y)],
∃: P(M × M) →P(M).
Speciﬁcally, given [ψ(x, y)] ⊆M × M, we have
∃[ψ(x, y)] = [∃y.ψ(x, y)]
= {m | for some y, M |= ψ(m, y)}
= im(π)[ψ(x, y)].
Therefore,
∃= im(π).

196
ADJOINTS
ϕ
∀ϕ
∃ϕ
Figure 9.1: Quantiﬁers as adjoints
In this way, you can actually “see” the adjunction:
∃y.ψ(x, y) ⊢φ(x)
ψ(x, y) ⊢φ(x)
It is essentially the one already considered (example 9.12) between direct and
inverse images, applied to the case of a product projection π : M × M →M.
im(π) ⊣π−1
See Figure 9.1.
Finally, the universal quantiﬁer can also be regarded as an operation of the
form
∀: P(M × M) →P(M)
by setting ∀[ψ(x, y)] = [∀y.ψ(x, y)]. Then given [ψ(x, y)] ⊆M × M, we have
∀[ψ(x, y)] = [∀y.ψ(x, y)]
= {m | for all y, M |= ψ(m, y)}
= {m | π−1{m} ⊆[ψ(x, y)]}
= π∗([ψ(x, y)]).
Therefore,
∀= π∗
so the universal quantiﬁer is the right adjoint to pullback along the projection
π. Again, in Figure 9.1 one can see the adjunction:
φ(x) ≤ψ(x, y)
φ(x) ≤∀y.ψ(x, y)
by considering the corresponding operations induced on subsets.

RAPL
197
9.6
RAPL
In addition to the conceptual uniﬁcation achieved by recognizing constructions
as diﬀerent as existential quantiﬁers and free groups as instances of adjoints,
there is the practical beneﬁt that one then knows that these operations behave
in certain ways that are common to all adjoints. We next consider one of the
fundamental properties of adjoints: preservation of limits.
In the previous section we had a string of three adjoints,
∃⊣∗⊣∀
and it is easy to ﬁnd other such strings. For example, there is a string of four
adjoints between Cat and Sets,
V ⊣F ⊣U ⊣R
where U : Cat →Sets is the forgetful functor to the set of objects
U(C) = C0.
An obvious question in this kind of situation is “are there more?” That is, given a
functor does it have an adjoint? A useful necessary condition which shows that,
for example, the strings above stop is the following proposition, which is also
important in its own right.
Proposition 9.14. Right adjoints preserve limits (remember: “RAPL”!), and
left adjoints preserve colimits.
Proof. Here is the easy way: suppose we have an adjunction
C
F
-

U
D
F ⊣U
and we are given a diagram C : J →D such that the limit lim
←−Dj exists in D.
Then for any X ∈C, we have
HomC(X, U(lim
←−Dj)) ∼= HomD(FX, lim
←−Dj)
∼= lim
←−HomD(FX, Dj)
∼= lim
←−HomC(X, UDj)
∼= HomC(X, lim
←−UDj)
whence (by Yoneda), we have the required isomorphism
U(lim
←−Dj) ∼= lim
←−UDj.
It follows by duality that left adjoints preserve colimits.

198
ADJOINTS
It is illuminating to work out what the above argument “really means” in a
particular case, say binary products. Given a product A × B in D, consider the
following diagram, in which the part on the left is in C and that on the right
in D.
X
FX

	
	
	
	
	
	
f
@
@
@
@
@
@
g
R

	
	
	
	
	
	
¯f
@
@
@
@
@
@
¯g
R
UA 
U(A × B)
?
.................
- UB
A 
A × B
?
.................
- B
Then given any f and g as indicated, we get the required unique arrow ⟨f, g⟩
by adjointness as
⟨f, g⟩= ⟨¯f, ¯g⟩
where we write ¯f, etc., for both directions of the adjoint correspondence.
For another example, recall that in the proof that SetsCop has exponentials
we needed the following distributivity law for sets:
(lim
←−
i
Xi) × A ∼= lim
←−
i
(Xi × A)
We now see that this is a consequence of the fact that the functor (−) × A is a
left adjoint (namely to (−)A) and therefore preserves colimits.
It also follows immediately for the propositional calculus (and in any Heyting
algebra) that, for example,
p ⇒(a ∧b) ⊣⊢(p ⇒a) ∧(p ⇒b)
and
(a ∨b) ∧p ⊣⊢(a ∧p) ∨(b ∧p).
Similarly, for the quantiﬁers one has, for example,
∀x(φ(x) ∧ψ(x)) ⊣⊢∀xφ(x) ∧∀xψ(x).
Since this does not hold for ∃x, it cannot be a right adjoint to some other
“quantiﬁer.” Similarly
∃x(φ(x) ∨ψ(x)) ⊣⊢∃xφ(x) ∨∃xψ(x).
And, as above, ∀x cannot be a left adjoint, since it does not have this property.
The proposition gives an extremely important and useful property of adjoints.
As in the foregoing examples, it can be used to show that a given functor does
not have an adjoint by showing that it does not preserve (co)limits. But also, to
show that a given functor preserves all (co)limits, sometimes the easiest way to

RAPL
199
do so is to show that it has an adjoint. For example, it is very easy to recognize
that the forgetful functor U : Pos →Sets from posets to sets has a left adjoint
(what is it?). Thus, we know that limits of posets are limits of the underlying
sets (suitably ordered). Dually, you may have shown “by hand” as an exercise
that the coproduct of free monoids is the free monoid on the coproduct of their
generating sets
F(A) + F(B) ∼= F(A + B).
This now follows simply from the free ⊣forgetful adjunction.
Example 9.15. Our ﬁnal example of preservation of (co)limits by adjoints
involves the UMP of categories of diagrams SetsCop mentioned in the foregoing
chapter. For a small category C, a contravariant functor P : Cop →Sets is
often called a presheaf on C, and the functor category SetsCop is accordingly
called the category of presheaves on C, sometimes written ˆC. This cocomplete
category is the “free cocompletion” of C in the following sense.
Proposition 9.16. For any small category C, the Yoneda embedding
y : C →SetsCop
has the following universal mapping property: given any cocomplete category E
and functor F : C →E, there is a colimit preserving functor F! : SetsCop →E
such that,
F! ◦y ∼= F
(9.5)
as indicated in the following diagram.
SetsCop ..............
F! - E
	
	
	
	
	
	
F

C
y
6
Moreover, up to natural isomorphism, F! is the unique cocontinuous functor with
this property.
Proof. We will show that there are adjoint functors,
SetsCop 
F ∗
F!
- E
F! ⊣F ∗

F
3
C
y
6

200
ADJOINTS
with F! ◦y ∼= F. It then follows that F! preserves all colimits. To deﬁne F!, take
any presheaf P ∈SetsCop and write it as a canonical colimit of representables
lim
−→
j∈J
yCj ∼= P
with J =

C P the category of elements of P, as in proposition 8.10. Then set
F!(P) = lim
−→
j∈J
FCj
with the colimit taken in E, which is cocomplete. (We leave it to the reader to
determine how to deﬁne F! on arrows.) Clearly, if F! is to preserve all colimits
and satisfy (9.5), then up to isomorphism this must be its value for P. For F ∗,
take any E ∈E and C ∈C and observe that by (Yoneda and) the intended
adjunction, for F ∗(E)(C) we must have
F ∗(E)(C) ∼= Hom ˆ
C(yC, F ∗(E))
∼= HomE(F!(yC), E)
∼= HomE(FC, E).
Thus we simply set
F ∗(E)(C) = HomE(FC, E)
which is plainly a presheaf on C (we use here that E is locally small). Now let
us check that indeed F! ⊣F ∗. For any E ∈E and P ∈ˆC, we have natural
isomorphisms
Hom ˆC(P, F ∗(E)) ∼= Hom ˆC(lim
−→
j∈J
yCj , F ∗(E))
∼= lim
←−
j∈J
Hom ˆC(yCj , F ∗(E))
∼= lim
←−
j∈J
F ∗(E)(Cj)
∼= lim
←−
j∈J
HomE(FCj, E)
∼= HomE(lim
−→
j∈J
FCj, E)
∼= HomE(F!(P), E).
Finally, for any object C ∈C,
F!(yC) = lim
−→
j∈J
FCj ∼= FC
since the category of elements J of a representable yC has a terminal object,
namely the element 1C ∈HomC(C, C).

RAPL
201
Corollary 9.17. Let f : C →D be a functor between small categories. The
precomposition functor
f ∗: SetsDop →SetsCop
given by
f ∗(Q)(C) = Q(fC)
has both left and right adjoints
f! ⊢f ∗⊢f∗
Moreover, there is a natural isomorphism
f! ◦yC ∼= yD ◦f
as indicated in the following diagram.
SetsCop
-

f!
- SetsDop
C
yC
6
f
- D
yD
6
The induced functors f! and f∗are sometimes referred to in the literature as
(left and right) Kan extensions.
Proof. First, deﬁne
F = yD ◦f : C →SetsDop.
Then by the foregoing proposition we have adjoints F! and F ∗as indicated in
SetsCop  F ∗
F!
- SetsDop
C
yC
6
f
- D
yD
6
and we know that F! ◦yC ∼= yD ◦f. We claim that F ∗∼= f ∗. Indeed, by the
deﬁnition of F ∗we have
F ∗(Q)(C) = Hom ˆD(FC, Q) ∼= Hom ˆD(y(fC), Q) ∼= Q(fC) = f ∗(Q)(C).
This, therefore, gives the functors f! ⊣f ∗. For f∗, apply the proposition to the
composite
f ∗◦yD : D →SetsDop →SetsCop.

202
ADJOINTS
This gives an adjunction
(f ∗◦yD)! ⊣(f ∗◦yD)∗
so we just need to show that
(f ∗◦yD)! ∼= f ∗
in order to get the required right adjoint as f∗= (f ∗◦yD)∗. By the universal
property of SetsDop, it suﬃces to show that f ∗preserves colimits. But for any
colimit lim
−→j Qj in SetsDop
(f ∗(lim
−→
j
Qj))(C) ∼= (lim
−→
j
Qj)(fC)
∼= lim
−→
j
(Qj(fC))
∼= lim
−→
j
((f ∗Qj)(C))
∼= (lim
−→
j
(f ∗Qj))(C).
This corollary says that, in a sense, every functor has an adjoint! For, given any
f : C →D, we indeed have the right adjoint
f ∗◦yD : D →ˆC
except that its values are in the “ideal elements” of the cocompletion ˆC.
9.7
Locally cartesian closed categories
A special case of the situation described by corollary 9.17 is the change of base for
indexed families of sets along a “reindexing” function α : J →I. An arbitrary
such function between sets gives rise, by that corollary, to a triple of adjoint
functors:
SetsJ
α∗
-

α∗
α!
-
SetsI
α! ⊣α∗⊣α∗
Let us examine these functors more closely in this special case.

LOCALLY CARTESIAN CLOSED CATEGORIES
203
An object A of SetsI is an I-indexed family of sets
(Ai)i∈I.
Then α∗(A) = A ◦α is the reindexing of A along α to a J-indexed family of sets
α∗(A) = (Aα(j))j∈J.
Given a J-indexed family B, let is calculate α!(B) and α∗(B).
Consider ﬁrst the case I = 1 and α =!J : J →1. Then (!J)∗: Sets →SetsJ
is the “constant family” or diagonal functor ∆(A)(j) = A, for which we know
the adjoints:
SetsJ
Π
-

∆
Σ
-
Sets
Σ ⊣∆⊣Π
These are, namely, just the (disjoint) sum and cartesian product of the sets in
the family

j∈J
Bj,

j∈J
Bj.
For recall that we have the adjunctions:
ϑj : Bj →A
(ϑj) : 
j Bj →A ,
ϑj : A →Bj
⟨ϑj⟩: A →
j Bj
By uniqueness of adjoints, it therefore follows that (!J)! ∼= Σ and (!J)∗∼= Π.
A general reindexing α : J →I gives rise to generalized sum and product
operations along α
Σα ⊣α∗⊣Πα
deﬁned on J-indexed families (Bj) by
(Σα(Bj))i =

α(j)=i
Bj
(Πα(Bj))i =

α(j)=i
Bj.
These operations thus assign to an element i ∈I the sum, respectively the
product, over all the sets indexed by the elements j in the preimage of i under α.
Now let us recall from example 7.28 the equivalence between J-indexed
families of sets and the slice category of “sets over J”
SetsJ ≃Sets/J.

204
ADJOINTS
It takes a family (Aj)j∈J to the indexing projection p : 
j∈J Aj →J and a
map π : A →J to the family (π−1(j))j∈J. We know, moreover, from an exercise
in Chapter 7 that this equivalence respects reindexing, in the sense that for any
α : J →I the following square commutes up to natural isomorphism.
J
Sets/J
≃
- SetsJ
I
α
?
Sets/I
α♯
6
≃- SetsI
α∗
6
Here we write α♯for the pullback functor along α. Since α∗has both right and
left adjoints, we have the diagram of induced adjoints:
J
Sets/J
≃
- SetsJ
I
α
?
Sets/I
αL
?
α♯
6
α♯
? ≃- SetsI
α!
?
α∗
6
α∗
?
Proposition 9.18. For any function α : J →I, the pullback functor α♯:
Sets/I →Sets/J has both left and right adjoints:
αL ⊣α♯⊣α♯
In particular, α♯therefore preserves all limits and colimits.
Let us compute the functors explicitly. Given π : A →J, let Aj = π−1(j)
and recall that
α!(A)i =

α(j)=i
Ai.
But then we have
α!(A)i =

α(j)=i
Ai
=

i∈α−1(j)
Ai
=

i∈α−1(j)
π−1(j)
= π−1 ◦α−1(j)
= (α ◦π)−1(i).

LOCALLY CARTESIAN CLOSED CATEGORIES
205
It follows that αL(π : A →J) is simply the composite α ◦π : A →J →I,
αL(π : A →J) = (α ◦π : A →J →I).
Indeed, it is easy to check directly that composition along any function α is left
adjoint to pullback along α.
As for the right adjoint
α♯: Sets/J −→Sets/I
given π : A →J, the result α♯(π) : α♯(A) →I can be described ﬁberwise by
(α♯(A))i = {s : α−1(i) →A | “s is a partial section of π”}
where the condition “s is a partial section of π” means that the following triangle
commutes with the canonical inclusion α−1(i) ⊆J at the base.
A
	
	
	
	
	
	
s

α−1(i)
⊂
- J
π
?
Henceforth, we shall also write these “change of base” adjoints along a map
α : J →I in the form:
J
Sets/J
Σα ⊣α∗⊣Πα
I
α
?
Sets/I
Σα
?
α∗
6
Πα
?
Finally, let us reconsider the case I = 1, where these adjoints take the form:
J
Sets/J
ΣJ ⊣J∗⊣ΠJ
1
!
?
Sets
ΣJ
?
J∗
6
ΠJ
?
In this case we have
ΣJ(π : A →J) = A
J∗(A) = (p1 : J × A →J)
ΠJ(π : A →J) = {s : J →A | π ◦s = 1}

206
ADJOINTS
as the reader can easily verify. Moreover, one therefore has
ΣJJ∗(A) = J × A
ΠJJ∗(A) = AJ.
Thus the product ⊣exponential adjunction can be factored as a composite of
adjunctions as follows:
Sets
J × (−)
-

(−)J
Sets
Sets

J∗
-

ΠJ
Sets/J
ΣJ-

J∗
Sets

The following deﬁnition captures the notion of a category having this sort
of adjoint structure. In such a category E, the slice categories can be regarded
as categories of abstract indexed families of objects of E, and the reindexing of
such families can be carried out, and it has associated adjoint operations of sum
and product.
Deﬁnition 9.19. A category E is called locally cartesian closed if E has a
terminal object and for every arrow f : A →B in E, the composition functor
Σf : E/A →E/B
has a right adjoint f ∗which, in turn, has a right adjoint Πf:
Σf ⊣f ∗⊣Πf
The choice of name for such categories is explained by the following
important fact.
Proposition 9.20. For any category E with a terminal object, the following are
equivalent.
1. E is locally cartesian closed.
2. Every slice category E/A of E is cartesian closed.
Proof. Let E be locally cartesian closed. Since E has a terminal object, products
and exponentials in E can be built as:
A × B = ΣBB∗A
BA = ΠBB∗A

LOCALLY CARTESIAN CLOSED CATEGORIES
207
So E is cartesian closed. But clearly every slice category E/X is also locally
cartesian closed, since “a slice of a slice is a slice.” Thus every slice of E is
cartesian closed.
Conversely, suppose every slice of E is cartesian closed. Then E has pullbacks,
since these are just binary products in a slice. Thus, we just need to construct
the “relative product” functor Πf : E/A →E/B along a map f : A →B. First,
change notation:
F = E/B
F = f : A →B
F/F = E/A
Thus, we want to construct ΠF : F/F →F. Given an object p : X →F in F/F,
the object ΠF (p) is constructed as the following pullback,
ΠF (p)
- XF
1
?

1F
- F F
pF
?
where 
1F is the exponential transpose of the composite arrow
1 × F ∼= F
1
−→F.
We leave it to the reader to recognize that there is then a natural bijection of
the form:
Y →ΠF (p)
F ∗Y →p
Remark 9.21. The reader should be aware that some authors do not require
the existence of a terminal object in the deﬁnition of a locally cartesian closed
category.
Example 9.22 (Presheaves). For any small category C, the category SetsCop of
presheaves on C is locally cartesian closed. This is a consequence of the following
fact.
Lemma 9.23. For any object P ∈SetsCop, there is a small category D and an
equivalence of categories,
SetsDop ≃SetsCop/P.

208
ADJOINTS
Moreover, there is also a functor p : D →C such that the following diagram
commutes (up to natural isomorphism).
SetsDop
≃
- SetsCop/P
A
A
A
A
A
A
p!
U 





ΣP
SetsCop
Proof. One can take:
D =

C
P
p = π :

C
P →C
Indeed, recall that by the Yoneda lemma,

C P can be described equivalently
(isomorphically, in fact) as the category that we shall write suggestively as y/P,
described as follows:
objects pairs (C, x) where C ∈C and x : yC →P in SetsCop
arrows all arrows between such objects in the slice category over P
yC
ϑ - yC′
A
A
A
A
A
A
x
U 





x′
P
Note that by Yoneda, each such arrow is of the form ϑ = yh for a unique
h : C →D in C, which, moreover, is such that P(h)(x′) = x.
Now let I : y/P →SetsCop/P be the evident (full and faithful) inclusion
functor, and deﬁne a functor
Φ : SetsCop/P →Sets(y/P )op
by setting, for any q : Q →P and (C, x) ∈y/P
Φ(q)(C, x) = Hom ˆC/P (x, q).
In other words, Φ(q) = I∗(yq), which is plainly functorial. We leave it to the
reader as an exercise to show that this functor establishes an equivalence of
categories.

LOCALLY CARTESIAN CLOSED CATEGORIES
209
Corollary 9.24. For any small category C, the category SetsCop of presheaves
on C is locally cartesian closed.
Example 9.25 Fibrations of posets. A monotone map of posets f : X →P is a
(discrete) ﬁbration if it has the following lifting property:
For every x ∈X and p′ ≤fx there is a unique x′ ≤x such that f(x′) = p′.
One says that x “lies over” p = f(x) and that any p′ ≤p “lifts” to a unique
x′ ≤x lying over it, as indicated in the following diagram.
X
x′ ....................
≤
- x
P
f
?
p′
≤
- p
The identity morphism of a given poset P is clearly a ﬁbration, and the
composite of two ﬁbrations is easily seen to be a ﬁbration. Let Fib denote the
(non-full) subcategory of posets and ﬁbrations between them as arrows.
Lemma 9.26. For any poset P, the slice category Fib/P is cartesian closed.
Proof. The category Fib/P is equivalent to the category of presheaves on P,
Fib/P ≃SetsP op.
To get a functor Φ : Fib/P →SetsP op, take a ﬁbration q : Q →P to the
presheaf deﬁned on objects by
Φ(q)(p) = q−1(p)
for p ∈P.
The lifting property then determines the action on arrows p′ ≤p. For the other
direction Ψ : SetsP op →Fib/P take a presheaf Q : P op →Sets to (the indexing
projection of) its category of elements,
Ψ(Q) =

P
Q
π
−→P.
These are easily seen to be quasi-inverses.
The category Fib itself is almost locally cartesian closed; it only lacks a
terminal object (why?). We can “ﬁx” this simply by slicing it.
Corollary 9.27. For any poset P, the slice category Fib/P is locally cartesian
closed.
This sort of case is not uncommon, which is why the notion “locally cartesian
closed” is often formulated without requiring a terminal object.

210
ADJOINTS
9.8
Adjoint functor theorem
The question we now want to consider systematically is, when does a functor have
an adjoint? Consider ﬁrst the question, when does a functor of the form C →
Sets have a left adjoint? If U : C →Sets has F ⊣U, then U is representable
U ∼= Hom(F1, −), since U(C) ∼= Hom(1, UC) ∼= Hom(F1, C).
A related necessary condition that makes sense for categories other than
Sets is preservation of limits. Suppose that C is complete and U : C →X
preserves limits; then we can ask whether U has a left adjoint. The Adjoint
Functor Theorem (AFT) gives a necessary and suﬃcient condition for this case.
Theorem 9.28 (Freyd). Let C be locally small and complete. Given any cat-
egory X and functor
U : C →X
the following are equivalent:
1. U has a left adjoint.
2. U preserves limits, and for each X ∈X the functor U satisﬁes the following:
Solution set condition: There exists a set of objects (Ci)i∈I in C such that
for any object C ∈C and arrow f : X →UC, there exists an i ∈I and
arrows ϕ : X →UCi and ¯f : Ci →C such that:
f = U( ¯f) ◦ϕ
X
ϕ - UCi
Ci
@
@
@
@
@
@
f
R
UC
U ¯f
?
C
¯f
?
Brieﬂy: “every arrow X →UC factors through some object Ci in the
solution set.”
For the proof, we require the following.
Lemma 9.29. Let D be locally small and complete. Then the following are
equivalent:
1. D has an initial object.
2. D satisﬁes the following:
Solution set condition: There is a set of objects (Di)i∈I in D such that for
any object D ∈C there is an arrow Di →D for some i ∈I.
Proof. If D has an initial object 0, then {0} is obviously a solution set.

ADJOINT FUNCTOR THEOREM
211
Conversely, suppose we have a solution set (Di)i∈I and consider the object
W =

i∈I
Di.
Then W is “weakly initial” in the sense that for any object D there is a (not
necessarily unique) arrow W →D, namely the composite

i∈I
Di →Di →D
for a suitable product projection 
i∈I Di →Di. Now take the joint equalizer
of all endomorphisms d : W →W (which is a set, since D is locally small), as
indicated in the diagram:
V-
h
- W
∆-
⟨d⟩
-

d:W →W
W
Here the arrows ∆and ⟨d⟩have the d-projections 1W : W →W and d : W →W,
respectively. This equalizer then has the property that for any endomorphism
d : W →W,
d ◦h = h.
(9.6)
Note, moreover, that V is still weakly initial, since for any D there is an arrow
V ↣W →D. Suppose that for some D there are two arrows f, g : V →D.
Take their equalizer e : U →V , and consider the following diagram,
U-
e
- V
f
-
g
- D
W
s
6
hes
- W
h
?
?
in which the arrow s comes from W being weakly initial. So for the endomorphism
hes by (9.6) we have
hesh = h.
Since h is monic, esh = 1V . But then eshe = e, and so also she = 1U since e is
monic. Therefore U ∼= V , and so f = g. Thus V is an initial object.

212
ADJOINTS
Proof. (Theorem) If U has a left adjoint F ⊣U, then {FX} is itself a solution
set for X, since we always have a factorization,
X
η - UFX
FX
@
@
@
@
@
@
f
R
UC
U( ¯f)
?
C
¯f
?
where ¯f : FX →C is the adjoint transpose of f and η : X →UFX the unit of
the adjunction.
Conversely, consider the following so-called comma-category (X|U), with:
objects: are pairs (C, f) with f : X →UC
arrows: g : (C, f) →(C′, f ′) are arrows g : C →C′ with f ′ = U(g)f.
UC
C
X
f
*
HHHHHH
f ′
j
UC′
U(g)
?
C′
g
?
Clearly U has a left adjoint F iﬀfor each object X this category (X|U) has
an initial object, (FX, η : X →UFX), which then has the UMP of the unit.
Thus, to use the foregoing initial object lemma, we must check:
1. (X|U) is locally small.
2. (X|U) satisﬁes the solution set condition in the lemma.
3. (X|U) is complete.
For (1), we just observe that C is locally small. For (2), the solution set condition
of the theorem implies that there is a set of objects,
{(Ci, ϕ : X →UCi) | i ∈I}
such that every object (C, f : X →UC) has an arrow ¯f : (Ci, ϕ) →(C, f).
X
ϕ - UCi
Ci
@
@
@
@
@
@
f
R
UC
U ¯f
?
C
¯f
?

ADJOINT FUNCTOR THEOREM
213
Finally, to see that (X|U) is complete, one can check directly that it has
products and equalizers, because U preserves these. We leave this as an easy
exercise for the reader.
Remark 9.30. 1. The theorem simply does not apply if C is not complete. In that
case, a given functor may have an adjoint, but the AFT will not tell
us that.
2. It is essential that the solution set in the theorem be a set (and that C have
all set-sized limits).
3. On the other hand, if C is itself small and complete, then we can plainly
drop the solution set condition entirely. In that case we have the following.
Corollary 9.31. If C is a small and complete category and U : C →X is a
functor that preserves all limits, then U has a left adjoint.
Example 9.32. For complete posets P, Q, a monotone function f : P →Q has a
right adjoint g : Q →P iﬀf is cocontinuous, in the sense that f(	
i pi) = 	
i f(pi)
for any set-indexed family of elements (pi)i∈I. (Of course, here we are using the
dual formulation of the AFT.)
Indeed, we can let
g(q) =

f(x)≤q
x.
Then for any p ∈P and q ∈Q, if
p ≤g(q)
then
f(p) ≤fg(q) = f(

f(x)≤q
x) =

f(x)≤q
f(x) ≤q.
While, conversely, if
f(p) ≤q
then clearly
p ≤

f(x)≤q
x = g(q).
As a further consequence of the AFT, we have the following characterization
of representable functors on small complete categories.
Corollary 9.33. If C is a small and complete category, then for any functor
U : C →Sets the following are equivalent:
1. U preserves all limits.
2. U has a left adjoint.
3. U is representable.

214
ADJOINTS
Proof. Immediate.
These corollaries are, however, somewhat weaker than it may at ﬁrst appear,
in light of the following fact:
Proposition 9.34. If C is small and complete, then C is a preorder.
Proof. Suppose not, and take C, D ∈C with Hom(C, D) ≥2. Let J be any set,
and take the product

J
D.
There are isomorphisms:
Hom(C,

J
D) ∼=

J
Hom(C, D) ∼= Hom(C, D)J
So, for the cardinalities of these sets, we have
| Hom(C,

J
D)| = | Hom(C, C′)||J| ≥2|J| = |P(J)|.
And that is for any set J. On the other hand, clearly |C1| ≥| Hom(C, 
J D)|.
So taking J = C1 in the above gives a contradiction.
Remark 9.35. An important special case of the AFT that often occurs “in
nature” is that in which the domain category satisﬁes certain conditions that
eliminate the need for the (rather unpleasant!) solution set condition entirely.
Speciﬁcally, let A be a locally small, complete category satisfying the following
conditions:
1. A is well powered: each object A has at most a set of subobjects S ↣A.
2. A has a cogenerating set: there is a set of objects {Ai | i ∈I} (I some
index set), such that for any A, X and x ̸= y : X ⇒A in A there is some
s : A →Ai (for some i) that “separates” x and y, in the sense that sx ̸= sy.
Then any functor U : A →X that preserves limits necessarily has a left adjoint.
In this form (also originally proved by Freyd), the theorem is usually known as
the Special Adjoint Functor Theorem (“SAFT”). We refer to Mac Lane, V.8 for
the proof, and some sample applications.
Example 9.36. An important application of the AFT is that any equational the-
ory T gives rise to a free ⊣forgetful adjunction between sets and the category
of models of the theory, or “T-algebras.” In somewhat more detail, let T be a
(ﬁnitary) equational theory, consisting of ﬁnitely many operation symbols, each
of some ﬁnite arity (including 0-ary operations, that is, constant symbols), and
a set of equations between terms built from these operations and variables. For
instance, the theory of groups has a constant u (the group unit), a unary oper-
ation g−1 (the inverse), and a binary operation g · h (the group product), and

ADJOINT FUNCTOR THEOREM
215
a handful of equations such as g · u = g. The theory of rings has a further bin-
ary operation and some more equations. The theory of ﬁelds is not equational,
however, because the condition x ̸= 0 is required for an element x to have a
multiplicative inverse. A T-algebra is a set equipped with operations (of the
proper arities) corresponding to the operation symbols in T, and satisfying the
equations of T. A homomorphism of T-algebras h : A →B is a function on
the underlying sets that preserves all the operations, in the usual sense. Let T-
Alg be the category of all such algebras and their homomorphisms. There is an
evident forgetful functor
U : T-Alg →Sets
The AFT implies that this functor has a left adjoint F, the “free algebra” functor.
Proposition 9.37. For any equational theory T, the forgetful functor to Sets
has a left adjoint.
Rather than proving this general proposition (for which see Mac Lane,
chapter V), it will be more illuminating to do a simple example.
Example 9.38. Let T be the theory with one constant and one unary operation
(no axioms). A T-algebra is a set M with the structure:
1
a
−→M
f
−→M
If 1
b
−→N
g
−→N is another such algebra, a homomorphism of T-algebras
φ : (M, a, f) →(N, b, g) is a function φ : M →N that preserves the element and
the operation, in the expected sense that
φa = b
φf = gφ.
as indicated in the commutative diagram:
M
f - M
1 
a
*
HHHHHH
b
jN
φ
?
g
- N
φ
?
There is an evident forgetful functor (forget the structure):
U : T-Alg →Sets
This functor is easily seen to create all limits, as is the case for algebras for any
theory T. So in particular, T-Alg is complete and U preserves limits. Thus in
order to apply the AFT we just need to check the solution set condition.

216
ADJOINTS
To that end, let X be any set and take any function
h : X →M.
The image h(X) ⊆M generates a sub-T-model of (M, a, f) as follows. Deﬁne
the set “generated by h(X)” to be
⟨h(X)⟩= {f n(z) | n ∈N, z = a or z = h(x) for some x ∈X}.
Then a ∈⟨h(X)⟩, and f restricts to ⟨h(X)⟩to give a function f ′ : ⟨h(X)⟩→
⟨h(X)⟩. Moreover, the inclusion i : ⟨h(X)⟩→M is a T-algebra homomorphism
⟨h(X)⟩
f ′
- ⟨h(X)⟩
1 
a
*
HHHHHH
a
jM
i
?
∩
f
- M
i
?
∩
Furthermore, since h(X) ⊆⟨h(X)⟩there is a factorization h′ of h, as indicated
in the following diagram.
X
h′
- ⟨h(X)⟩
@
@
@
@
@
@
h
R
M
i
?
∩
Now observe that, given X, the cardinality |⟨h(X)⟩| is bounded, that is, for a
suﬃciently large κ independent of h and M, we have
|⟨h(X)⟩| ≤κ.
Indeed, we can take κ = (|X| + 1) × |N|.
To ﬁnd a solution set for X, let us now take one representative N of each
isomorphism class of T-algebras with cardinality at most κ. The set of all such
algebras N is then a solution set for X and U. Indeed, as we just showed, any
function h : X →M factors through an element of this set (namely an isomorphic
copy N of ⟨h(X)⟩). By the AFT, there thus exists a free functor,
F : Sets →T-Alg.
A similar argument works for any equational theory T.
Finally, let us consider the particular free model F(∅) in T-Alg. Since left
adjoints preserve colimits, this is an initial object. It follows that F(∅) is a natural
numbers object, in the following sense:

ADJOINT FUNCTOR THEOREM
217
Deﬁnition 9.39. Let C be a category with a terminal object 1. A natural
numbers object (NNO) in C is a structure of the form
1
0
−→N
s
−→N
which is initial among all such structures. Precisely, given any 1
a→X
f→X in
C there is a unique arrow φ : N →X such that the following commutes.
N
s - N
1 
0
*
HHHHHH
a
jX
φ
?
f
- X
φ
?
In other words, given any object X, a “starting point” a ∈X and an operation
x →f(x) on X, we can build up a unique φ : N →X recursively by the
equations:
φ(0) = a
φ(s(n)) = f(φ(n))
for all n ∈N
Thus, the UMP of a natural numbers object says precisely that such an object
supports recursive deﬁnitions. It is easy to show that the set N of natural numbers
with the canonical structure of 0 and the “successor function” s(n) = n+1 is an
NNO, and that any NNO in Sets is isomorphic to it. The characterization of N
in terms of the UMP of recursive deﬁnitions is therefore equivalent to the usual
logical deﬁnition using the Peano axioms in Sets. But note that the notion of
an NNO also makes sense in many categories where the Peano axioms do not
make any sense.
Let us consider some simple examples of recursively deﬁned functions using
this universal mapping property.
Example 9.40.
1. Let (N, 0, s) be an NNO in a category C. Take any point
a : 1 →N, and consider the new structure:
1
a
−→N
s
−→N
Then by the universal property of the NNO, there is a unique morphism
fa : N →N such that the following commutes.
N
s - N
1 
0
*
HHHHHH
a
jN
fa
?
s
- N
fa
?

218
ADJOINTS
Thus we have the following “recursion equations”:
fa(0) = a
fa(s(n)) = s(fa(n))
If we write fa(n) = a + n then the above equations become the familiar
recursive deﬁnition of addition:
a + 0 = a
a + (sn) = s(a + n)
2. Now take this arrow a + (−) : N →N together with 0 : 1 →N to get
another arrow ga : N →N, which is the unique one making the following
commute.
N
s
- N
1 
0
*
HHHHHH
0
jN
ga
?
a + (−)
- N
ga
?
We then have the recursion equations:
ga(0) = 0
ga(sn) = a + ga(n)
So, writing ga(n) = a·n, the above equations become the familiar recursive
deﬁnition of multiplication:
a · 0 = 0
a · (sn) = a + a · n
3. For an example of a diﬀerent sort, suppose we have a (small) category C
and an endofunctor F : C →C. Then there is a structure
1
id
−→CC F C
−→CC
where id : 1 →CC is the transpose of the identity 1C : C →C (composed
with the iso projection 1 × C ∼= C). We therefore have a unique functor
f : N →CC making the following diagram commute (we use the easy fact,

EXERCISES
219
which the reader should check, that the discrete category N is an NNO
in Cat).
N
s
- N
1
0
*
HHHHHH
id
jCC
f
?
F C- CC
f
?
Transposing gives the commutative diagram
1 × C 0 × 1C
- N × C s × 1C
- N × C
C
∼=
?
id
- C
¯f
?
F
- C
¯f
?
from which we can read oﬀthe recursion equations:
¯f(0, C) = C
¯f(sn, C) = F( ¯f(n, C))
It follows that ¯f(n, C) = F (n)(C), that is, f(n) is the nth iterate of F.
9.9
Exercises
1. Show that every monoid M admits a surjection from a free monoid
F(X) →M, by considering the counit of the free ⊣forgetful adjunction.
2. Let 2 be any two-element set and consider the “diagonal functor”
∆: C →C2
for any category C, that is, the exponential transpose of the ﬁrst product
projection
C × 2 →C.
Show that ∆has a right (resp. left) adjoint if and only if C has binary
products (resp. coproducts).
Now let C = Sets and replace 2 with an arbitrary small category J.
Determine both left and right adjoints for ∆: Sets →SetsJ. (Hint: Sets
is complete and cocomplete.)

220
ADJOINTS
3. Given a function f : A →B between sets, show that the direct image
operation im(f) : P(A) →P(B) is left adjoint to the inverse image f −1 :
P(B) →P(A).
4. Show that the contravariant powerset functor P : Setsop →Sets is self-
adjoint.
5. Given an object C in a category C when does the evident forgetful functor
from the slice category C/C
U : C/C →C
have a right adjoint? What about a left adjoint?
6. Let P be the category of propositions (i.e. the preorder category associ-
ated to the propositional calculus, say with countably many propositional
variables p, q, r, . . . , and a unique arrow p →q if and only if p ⊢q). Show
that for any ﬁxed object p, there is a functor
−∧p : P →P
and that this functor has a right adjoint. What is the counit of the
adjunction? (When) does −∧p have a left adjoint?
7. (a) Given any set I, explicitly describe the Yoneda embedding y : I →
SetsI of I into the category SetsI of I-indexed sets.
(b) Given any function f : J →I from another set J, prove directly that
the following diagram commutes up to natural isomorphism.
SetsI
f!
- SetsI
J
yJ
6
f
- I
yI
6
(c) Describe the result of composing the Yoneda embedding with the
equivalence,
SetsI ≃Sets/I.
(d) What does the commutativity of the above “change of base” square
mean in terms of the categories Sets/I and Sets/J?
(e) Consider the inclusion functor i : P(I) →Sets/I that takes a subset
U ⊆I to its inclusion function i(U) : U →I. Show that this is a
functor and that is has a left adjoint
σ : Sets/I −→P(I).

EXERCISES
221
(f) (Lawvere’s Hyperdoctrine Diagram) In Sets, given any function f :
I →J, consider the following diagram of functors.
Sets/I
Πf
-

f ∗
Σf
-
Sets/J
P(I)
σI
?
iI
6
∀f
-

f −1
∃f
-
P(J)
σJ
?
iJ
6
There are adjunctions σ ⊣i (for both I and J), as well as Σf ⊣f ∗⊣Πf
and ∃f ⊣f −1 ⊣∀f, where f ∗: Sets/J →Sets/I is pullback and
f −1 : P(J) →P(I) is inverse image.
Consider which of the many possible squares commute.
8. Use the adjoint functor theorem to prove the following facts, which were
shown by explicit constructions in Chapter 1:
(a) Free monoids on sets exist.
(b) Free categories on graphs exist.
9. Let 1 →N →N be a natural numbers object in a cartesian closed cat-
egory C. Show how to deﬁne the exponentiation operation mn as an arrow
N × N →N.

This page intentionally left blank 

10
MONADS AND ALGEBRAS
In the foregoing chapter, the adjoint functor theorem was seen to imply that the
category of algebras for an equational theory T always has a “free T-algebra”
functor, left adjoint to the forgetful functor into Sets. This adjunction describes
the notion of a T-algebra in a way that is independent of the speciﬁc syntactic
description given by the theory T, the operations and equations of which are
rather like a particular presentation of that notion. In a certain sense that we
are about to make precise, it turns out that every adjunction describes, in a
“syntax invariant” way, a notion of an “algebra” for an abstract “equational
theory.”
Toward this end, we begin with yet a third characterization of adjunctions.
This one has the virtue of being entirely equational.
10.1
The triangle identities
Suppose we are given an adjunction,
F : C
-

D : U.
with unit and counit,
η : 1C →UF
ϵ : FU →1D.
We can take any f : FC →D to φ(f) = U(f) ◦ηC : C →UD and for any
g : C →UD we have φ−1(g) = ϵD ◦F(g) : FC →D. This we know gives the
isomorphism
HomD(FC, D) ∼=φ HomC(C, UD).
Now put 1UD : UD →UD in place of g : C →UD in the foregoing. We
know that φ−1(1UD) = ϵD, and so
1UD = φ(ϵD)
= U(ϵD) ◦ηUD.

224
MONADS AND ALGEBRAS
And similarly, φ(1F C) = ηC, so
1F C = φ−1(ηC)
= ϵF C ◦F(ηC).
Thus, the two diagrams below commute.
UD
1UD
- UD
@
@
@
@
@
@
ηUD
R
	
	
	
	
	
	
UϵD

UFUD
FC
1F C
- FC
@
@
@
@
@
@
FηC
R
	
	
	
	
	
	
ϵF C

FUFC
Indeed, one has the following equations of natural transformations:
Uϵ ◦ηU = 1U
(10.1)
ϵF ◦Fη = 1F
(10.2)
These are called the “triangle identities.”
Proposition 10.1. Given categories, functors, and natural transformations
F : C
-

D : U
η : 1C →U ◦F
ϵ : F ◦U →1D
one has F ⊣U with unit η and counit ϵ iﬀthe triangle identities (10.1) and
(10.2) hold.
Proof. We have already shown one direction. For the other, we just need a natural
isomorphism,
φ : HomD(FC, D) ∼= HomC(C, UD).
As earlier, we put
φ(f : FC →D) = U(f) ◦ηC
ϑ(g : C →UD) = ϵD ◦F(g).

MONADS AND ADJOINTS
225
Then we check that these are mutually inverse:
(ϑ(g)) = φ(ϵD ◦F(g))
= U(ϵD) ◦UF(g) ◦ηC
= U(ϵD) ◦ηUD ◦g
η natural
= g
(10.1)
Similarly,
(φ(f)) = ϑ(U(f) ◦ηC)
= ϵD ◦FU(f) ◦FηC
= f ◦ϵF C ◦FηC
ϵ natural
= f
(10.2)
Moreover, this isomorphism is easily seen to be natural.
The triangle identities have the virtue of being entirely “algebraic”—no quantiﬁ-
ers, limits, Hom-sets, inﬁnite conditions, etc. Thus anything deﬁned by adjoints,
such as free groups, product spaces, quantiﬁers, . . . can be deﬁned equationally.
This is not only a matter of conceptual simpliﬁcation; it also has important
consequences for the existence and properties of the structures that are so
determined.
10.2
Monads and adjoints
Next consider an adjunction F ⊣U and the composite functor
U ◦F : C →D →C.
Given any category C and endofunctor
T : C →C
one can ask:
Question: When is T = U ◦F for some adjoint functors F ⊣U to and from
another category D?
Thus, we seek necessary and suﬃcient conditions on the given endofunctor T :
C →C for recovering a category D and adjunction F ⊣U. Of course, not every
T arises so, and we’ll see that even if T = U ◦F for some D and F ⊣U, we
cannot always recover that adjunction. Thus a better way to ask the question
would be, given an adjunction what sort of “trace” does it leave on a category
and can we recover the adjunction from this?
First, suppose we have D and F ⊣U and T is the composite functor T =
U ◦F. We have then a natural transformation,
η : 1 →T.

226
MONADS AND ALGEBRAS
And from the counit ϵ at FC,
ϵF C : FUFC →FC
we have UϵF C : UFUFC →UFC, which we’ll call,
µ : T 2 →T.
In general, then, as a ﬁrst step toward answering our question, if T arises from
an adjunction, then it should have such a structure η : 1 →T and µ : T 2 →T.
Now, what can be said about the structure (T, η, µ)? Actually, quite a bit!
Indeed, the triangle equalities give us the following commutative diagrams:
T 3
Tµ - T 2
T 2
µT
?
µ
- T
µ
?
µ ◦µT = µ ◦Tµ
(10.3)
T
ηT - T 2  Tη
T
@
@
@
@
@
@
=
R

	
	
	
	
	
	
=
T
µ
?
µ ◦ηT = 1T = µ ◦Tη
(10.4)
To prove the ﬁrst one, for any f : X →Y in D, the following square in C
commutes, just since ϵ is natural.
FUX FUf- FUY
X
ϵX
?
f
- Y
ϵY
?

MONADS AND ADJOINTS
227
Now take X = FUY and f = ϵY to get the following:
FUFUY FUϵY- FUY
FUY
ϵFUY
?
ϵY
- Y
ϵY
?
Putting FC for Y and applying U therefore gives this
UFUFUFC UFUϵF C
- UFUFC
UFUFC
UϵFUFC
?
UϵF C
- UFC
UϵF C
?
which has the required form (10.3). The equations (10.4) in the form
UFC ηUF C- UFUFC 
UFηC UFC
@
@
@
@
@
@
=
R

	
	
	
	
	
	
=
UFC
UϵF C
?
are simply the triangle identities, once taken at FC, and once under U. We
record this data in the following:
Deﬁnition 10.2. A monad on a category C consists of an endofunctor T : C →
C, and natural transformations η : 1C →T, and µ : T 2 →T satisfying the two
commutative diagrams above, that is,
µ ◦µT = µ ◦Tµ
µ ◦ηT = 1 = µ ◦Tη.
Note the formal analogy to the deﬁnition of a monoid. For this reason, the
equations are called the associativity and unit laws, respectively. It is remarkable
that the notion of a monad actually ﬁrst arose independently of adjunctions.

228
MONADS AND ALGEBRAS
We have now shown the following:
Proposition 10.3. Every adjoint pair F ⊣U with U : D →C, unit η : UF →
1C and counit ϵ : 1D →FU gives rise to a monad (T, η, µ) on C with
T = U ◦F : C →C
η : 1 →T
the unit
µ = UϵF : T 2 →T.
Example 10.4. Let P be a poset. A monad on P is a monotone function T : P →
P with x ≤Tx and T 2x ≤Tx. But then T 2 = T, that is, T is idempotent.
Such a T, that is both inﬂationary and idempotent, is sometimes called a closure
operation and written Tp = ¯p, since it acts like the closure operation on the
subsets of a topological space. The “possibility operator” ⋄p in modal logic is
another example.
In the poset case, we can easily recover an adjunction from the monad. First,
let K = im(T)(P) (the ﬁxed points of T), and let i : K →P be the inclusion.
Then let t be the factorization of T through K, as indicated in:
P
T
- P
A
A
A
A
A
A
t
U 





i

K
Observe that since TTp = Tp, for any element k ∈K we then have, for some
p ∈P, the equation itik = ititp = itp = ik, whence tik = k since i is monic. We
therefore have:
p ≤ik
implies
tp ≤tik = k
tp ≤k
implies
p ≤itp ≤ik
So indeed t ⊣i.
Example 10.5. Consider the covariant powerset functor
P : Sets →Sets
which takes each function f : X →Y to the image mapping im(f) : P(X) →
P(Y ). Let ηX : X →P(X) be the singleton operation
ηX(x) = {x}
and let µX : PP(X) →P(X) be the union operation
µX(α) =

α.
The reader should verify as an exercise that these operations are in fact natural
in X and that this deﬁnes a monad (P, {−}, ) on Sets.

ALGEBRAS FOR A MONAD
229
As we see in these examples, monads can, and often do, arise without coming
from evident adjunctions. In fact, the notion of a monad originally did occur
independently of adjunctions; they are also known as “triples,” and “standard
constructions.” Despite this, the question, when does an endofunctor T arise
from an adjunction, has the answer: just if it is the functor part of a monad.
10.3
Algebras for a monad
Proposition 10.6. Every monad arises from an adjunction. More precisely,
given a monad (T, η, µ) on the category C, there exists a category D and an
adjunction F ⊣U, η : 1 →UF, ϵ : FU →1 with U : D →C such that
T = U ◦F
η = η
(the unit)
µ = UϵF .
Proof. We will ﬁrst deﬁne the important category CT called the Eilenberg-Moore
category of T. This will be our “D.” Then we need suitable functors
F : C
-

CT : U.
And, ﬁnally, we need natural transformations η : 1 →UF and ϵ : FU →1
satisfying the triangle identities.
To begin, CT has as objects the “T-algebras,” which are pairs (A, α) of the
form α : TA →A in C, such that
1A = α ◦ηA
and
α ◦µA = α ◦Tα.
(10.5)
A
ηA - TA
T 2A
Tα- TA
@
@
@
@
@
@
1
RA
α
?
TA
µA
?
α
- A
α
?
A morphism of T-algebras,
h : (A, α) →(B, β)
is simply an arrow h : A →B in C, such that,
h ◦α = β ◦T(h)

230
MONADS AND ALGEBRAS
as indicated in the following diagram.
TA
Th - TB
A
α
?
h
- B
β
?
It is obvious that CT is a category with the expected composites and identities
coming from C, and that T is a functor.
Now deﬁne the functors,
U : CT →C
U(A, α) = A
and
F : C →CT
FC = (TC, µC).
We need to check that (TC, µC) is a T-algebra. The equations (10.5) for
T-algebras in this case become:
TC
ηT C- T 2C
T 3C
TµC- T 2C
@
@
@
@
@
@
1
R
TC
µC
?
T 2C
µT C
?
µ
- TC
µ
?
But these come directly from the deﬁnition of a monad.
To see that F is a functor, given any h : C →D in C, we have
T 2C
T 2h- T 2D
TC
µC
?
Th
- TD
µD
?
since µ is natural. But this is a T-algebra homomorphism FC →FD, so we
can put
Fh = Th : TC →TD
to get an arrow in CT .

ALGEBRAS FOR A MONAD
231
Now we’ve deﬁned the category CT and the functors
C
F -

U
CT
and we want to show that F ⊣U. Next, we need the unit and counit:
¯η : 1C →U ◦F
ϵ : F ◦U →1CT
Given C ∈C, we have
UF(C) = U(TC, µC) = TC.
So we can take ¯η = η : 1C →U ◦F, as required.
Given (A, α) ∈CT ,
FU(A, α) = (TA, µA)
and the deﬁnition of a T-algebra makes the following diagram commute:
T 2A
Tα- TA
TA
µA
?
α
- A
α
?
But this is a morphism ϵ(A,α) : (TA, µA) →(A, α) in CT . Thus we are setting
ϵ(A,α) = α.
And ϵ is natural by the deﬁnition of a morphism of T-algebras, as follows. Given
any h : (A, α) →(B, β), we need to show
h ◦ϵ(A,α) = ϵ(B,β) ◦Th.
But by the deﬁnition of ϵ, that is, h ◦α = β ◦Th, which holds since h is a
T-algebra homomorphism.
Finally, the triangle identities now read as follows:
1. For (A, α) a T-algebra
U(A, α)
- U(A, α)
@
@
@
@
@
@
ηU(A,α)
R
	
	
	
	
	
	
Uϵ(A,α)

UFU(A, α)

232
MONADS AND ALGEBRAS
which amounts to
A
- A
@
@
@
@
@
@
ηA
R
	
	
	
	
	
	
α

TA
which holds since (A, α) is T-algebra.
2. For any C ∈C
FC
- FC
@
@
@
@
@
@
FηC
R
	
	
	
	
	
	
ϵF C

FUFC
which is
TC
- TC
@
@
@
@
@
@
TηC
R
	
	
	
	
	
	
µC

T 2C
which holds by one of the unit laws for T.
Finally, note that we indeed have
T = U ◦F
η = unit of F ⊣U.
And for the multiplication,
¯µ = UϵF
we have, for any C ∈C,
¯µC = UϵF C = Uϵ(T C,µC) = UµC = µC.
So ¯µ = µ and we are done; the adjunction F ⊣U via η and ϵ gives rise to the
monad (T, η, µ).
Example 10.7. Take the free monoid adjunction,
F : Sets -

Mon : U.

ALGEBRAS FOR A MONAD
233
The monad on Sets is then T : Sets →Sets, where for any set X, T(X) =
UF(X) = “strings over X.” The unit η : X →TX is the usual “string of length
one” operation, but what is the multiplication?
µ : T 2X →TX
Here T 2X is the set of strings of strings,
[[x11, . . . , x1n], [x21, . . . , x2n], . . . , [xm1, . . . , xmn]].
And µ of such a string of strings is the string of their elements,
µ([[x11, . . . , x1n], [x21, . . . , x2n], . . . , [xm1, . . . , xmn]]) = [x11, . . . , xmn].
Now, what is a T-algebra in this case? By the equations for a T-algebra, it
is a map,
α : TA →A
from strings over A to elements of A, such that
α[a] = a
and
α(µ([[. . .], [. . .], . . . , [. . .]])) = α(α[. . .], α[. . .], . . . , α[. . .]).
If we start with a monoid, then we can get a T-algebra m : TM →M by:
m[m1, . . . , mn] = m1 · . . . · mn
This clearly satisﬁes the required conditions. Observe that we can even recover
the monoid structure from m by u = m(−) for the unit and x · y = m(x, y)
for the multiplication. Indeed every T-algebra is of this form for a unique monoid
(exercise!).
We have now given constructions back and forth between adjunctions and
monads. And we know that if we start with a monad T : C →C, and then take
the adjunction,
F T : C
-

CT : U T
then we can get the monad back by T = U T ◦F T . Thus, in particular, every
monoid arises from some adjunction. But are CT , U T , F T unique with this
property?
In general, the answer is no. There may be many diﬀerent categories D and
adjunctions F ⊣U : D →C, all giving the same monad on C. We have used
the Eilenberg-Moore category CT , but there is also something called the “Kleisli
category,” which is in general diﬀerent from CT , but also has an adjoint pair to
C giving rise to the same monad (see the exercises).

234
MONADS AND ALGEBRAS
If we start with an adjunction F ⊣U and construct CT for T = U ◦F, we
then get a comparison functor Φ : D →CT , with
U T ◦Φ ∼= U
Φ ◦F = F T
D
Φ
- CT
I
@
@
@
@
@
@
F
@
@
@
@
@
@
U
R	
	
	
	
	
	
F T


	
	
	
	
	
	
U T
C
In fact, Φ is unique with this property. A functor U : D →C is called
monadic if it has a left adjoint F ⊣U, such that this comparison functor is an
equivalence of categories,
D
Φ
∼=
- CT
for T = UF.
Typical examples of monadic forgetful functors U : C →Sets are those from
the “algebraic” categories arising as models for equational theories, like monoids,
groups, rings, etc. Indeed, one can reasonably take monadicity as the deﬁnition
of being “algebraic.”
An example of a right adjoint that is not monadic is the forgetful functor
from posets,
U : Pos →Sets.
Its left adjoint F is the discrete poset functor. For any set X, therefore, one has
as the unit the identity function X = UF(X). The reader can easily show that
the Eilenberg-Moore category for T = 1Sets is then just Sets itself.
10.4
Comonads and coalgebras
By deﬁnition, a comonad on a category C is a monad on Cop. Explicitly, this
consists of an endofunctor G : C →C and natural transformations,
ϵ : G →1
the counit
δ : G →G2
comultiplication
satisfying the duals of the equations for a monad, namely
δG ◦δ = Gδ ◦δ
ϵG ◦δ = 1G = Gϵ ◦δ.

COMONADS AND COALGEBRAS
235
We leave it as an exercise in duality for the reader to verify that an adjoint
pair F ⊣U with U : D →C and F : C →D and η : 1C →UF and ϵ : FU →1D
gives rise to a comonad (G, ϵ, δ) on D, where
G = F ◦U : D →D
ϵ : G →1
δ = FηU : G →G2.
The notions of coalgebra for a comonad, and of a comonadic functor, are
of course also precisely dual to the corresponding ones for monads. Why do we
even bother to study these notions separately, rather than just considering their
duals? As in other examples of duality, there are actually two distinct reasons:
1. We may be interested in a particular category with special properties not
had by its dual. A comonad on SetsC is of course a monad on (SetsC)
op,
but as we now know, SetsC has many special properties that its dual does
not have (e.g. it is a topos!). So we can proﬁtably consider the notion of a
comonad on such a category.
A simple example of this kind is the comonad G = ∆◦lim
←−resulting
from composing the “constant functor” functor ∆: Sets →SetsC with the
“limit” functor lim
←−: SetsC →Sets. It can be shown in general that the
coalgebras for this comonad again form a topos. In fact, they are just the
constant functors ∆(S) for sets S, and the category Sets is thus comonadic
over SetsC.
2. It may happen that both structures—monad and comonad—occur together,
and interact. Taking the opposite category will not alter this situation! This
happens for instance when a system of three adjoint functors are composed:
L ⊣U ⊣R
C
R
-

U
L
-
D
resulting in a monad T = U ◦L and a comonad G = U ◦R, both on C. In
such a case, T and U are then of course also adjoint T ⊣G.
This arises, for instance, in the foregoing example with R = lim
←−, and
U = ∆, and L = lim
−→the “colimit” functor. It also occurs in propositional
modal logic, with T = 3 “possibility” and G = □“necessity,” where the
adjointness 3 ⊣□is equivalent to the law known to modal logicians as
“S5.”
A related example is given by the open and closed subsets of a topological
space: the topological interior operation on arbitrary subsets is a comonad
and closure is a monad. We leave the details as an exercise.

236
MONADS AND ALGEBRAS
10.5
Algebras for endofunctors
Some very basic kinds of algebraic structures have a more simple description
than as algebras for a monad, and this description generalizes to structures that
are not algebras for any monad, but still have some algebra-like properties.
As a familiar example, consider ﬁrst the underlying structure of the notion of
a group. We have a set G equipped with operations as indicated in the following:
G × G
m - G 
i
G
1
u
6
We do not assume, however, that these operations satisfy the group equations
of associativity, etc. Observe that this description of what we will call a “group
structure” can plainly be compressed into a single arrow of the form:
1 + G + G × G
[u, i, m]- G
Now let us deﬁne the functor F : Sets →Sets by:
F(X) = 1 + X + X × X
Then a group structure is simply an arrow,
γ : F(G) →G.
Moreover, a homomorphism of group structures in the conventional sense
h : G →H,
h(uG) = uH
h(i(x)) = i(h(x))
h(m(x, y)) = m(h(x), h(y))
is then exactly a function h : G →H such that the following diagram commutes.
F(G) F(h)- F(H)
G
γ
?
h
- H
ϑ
?

ALGEBRAS FOR ENDOFUNCTORS
237
where ϑ : F(H) →H is the group structure on H. This observation motivates
the following deﬁnition.
Deﬁnition 10.8. Given an endofunctor P
: S →S on any category S,
a P-algebra consists of an object A of S and an arrow,
α : PA →A.
A homomorphism h : (A, α) →(B, β) of P-algebras is an arrow h : A →B in S
such that h ◦α = β ◦P(h), as indicated in the following diagram:
P(A) P(h)- P(B)
A
α
?
h
- B
β
?
The category of all such P-algebras and their homomorphisms will be denoted as:
P-Alg(S)
We will usually write more simply P-Alg when S is understood. Also, if there
is a monad present, we will need to be careful to distinguish between algebras
for the monad and algebras for the endofunctor (especially if P is the functor
part of the monad!).
Example 10.9. 1. For the functor P(X) = 1 + X + X × X on Sets we have
already seen that the category GrpStr of group structures is the same
thing as the category of P-algebras,
P-Alg = GrpStr.
2. Clearly, for any other algebraic structure of ﬁnite “signature,” that is, con-
sisting of ﬁnitely many, ﬁnitary operations, there is an analogous description
of the structures of that sort as algebras for an associated endofunctor. For
instance, a ring structure, with two nullary, one unary, and two binary
operations is given by the endofunctor
R(X) = 2 + X + 2 × X2.
In general, a functor of the form
P(X) = C0 + C1 × X + C2 × X2 + · · · + Cn × Xn
with natural number coeﬃcients Ck, is called a (ﬁnitary) polynomial
functor, for obvious reasons. These functors present exactly the ﬁnitary
structures. The same thing holds for ﬁnitary structures in any category S

238
MONADS AND ALGEBRAS
with ﬁnite products and coproducts; these can always be represented as
algebras for a suitable endofunctor.
3. In a category such as Sets that is complete and cocomplete, there is an
evident generalization to inﬁnitary signatures by using generalized or “inﬁn-
itary” polynomial functors, that is, ones with inﬁnite sets Ck as coeﬃcients
(representing inﬁnitely many operations of a given arity), inﬁnite sets Bk as
the exponents XBk (representing operations of inﬁnite arity), or inﬁnitely
many terms (representing inﬁnitely many diﬀerent arities of operations), or
some combination of these. The algebras for such an endofunctor
P(X) =

i∈I
Ci × XBi
can then be naturally viewed as generalized “algebraic structures.” Using
locally cartesian closed categories, one can even present this notion without
needing (co)completeness.
4. One can of course also consider algebras for an endofunctor P : S →S that
is not polynomial at all, such as the covariant powerset functor P : Sets →
Sets. This leads to a proper generalization of the notion of an “algebra,”
which however still shares some of the formal properties of conventional
algebras, as shall be seen below.
Let P : Sets →Sets be a polynomial functor, say
P(X) = 1 + X2
(what structure is this?). Then the notion of an initial P-algebra gives rise to a
recursion property analogous to that of the natural numbers. Speciﬁcally, let
[o, m] : 1 + I2 →I
be an initial P-algebra, that is, an initial object in the category of P-algebras.
Then, explicitly, we have the structure
o ∈I,
m : I × I →I
and for any set X with a distinguished element and a binary operation
a ∈X,
∗: X × X →X
there is a unique function u : I →X such that the following diagram commutes.
1 + I2 P(u)
- 1 + X2
I
[o, m]
?
u
- X
[a, ∗]
?

ALGEBRAS FOR ENDOFUNCTORS
239
This of course says that, for all i, j ∈I,
u(o) = a
u(m(i, j)) = u(i) ∗u(j).
which is exactly a deﬁnition by recursion of the function u : I →X. Indeed, the
usual recursion property of the natural numbers N with zero 0 ∈N and successor
s : N →N says precisely that (N, 0, s) is the initial algebra for the endofunctor,
P(X) = 1 + X : Sets →Sets
as the reader should check.
We next brieﬂy investigate the question: When does an endofunctor have an
initial algebra? The existence is constrained by the fact that initial algebras,
when they exist, must have the following noteworthy property.
Lemma 10.10.(Lambek). Given any endofunctor P : S →S on an arbitrary
category S, if i : P(I) →I is an initial P-algebra, then i is an isomorphism,
P(I) ∼= I.
We leave the proof as an easy exercise.
In this sense, the initial algebra for an endofunctor P : S →S is a “least ﬁxed
point” for P. Such algebras are often used in computer science to model “recurs-
ive datatypes” determined by so-called “ﬁxed point equations” X = P(X).
Example 10.11. 1. For the polynomial functor,
P(X) = 1 + X2
(monoid structure!), let us “unwind” the initial algebra,
[∗, @] : 1 + I × I ∼= I.
Given any element x ∈I, it is thus either of the form ∗or of the form
x1@x2 for some elements x1, x2 ∈I. Each of these xi, in turn, is either of
the form ∗or of the form xi1@xi2, and so on. Continuing in this way, we
have a representation of x as a ﬁnite, binary tree. For instance, an element
of the form x = ∗@(∗@∗) looks like:
x

	
	
	
	
	
	
@
@
@
@
@
@
R
∗
∗@∗

	
	
	
	
	
	
@
@
@
@
@
@
R
∗
∗

240
MONADS AND ALGEBRAS
We can present the monoid structure explicitly by letting
I = {t | t is a ﬁnite, binary tree}
with:
∗= “the empty tree”
@(t1, t2) = t1@t2
=
t1@t2

	
	
	
	
	
	
@
@
@
@
@
@
R
t1
t2
The isomorphism,
[∗, @] : 1 + I × I →I
here is plain to see.
2. Similarly, for any other polynomial functor,
P(X) = C0 + C1 × X + C2 × X2 + · · · + Cn × Xn
we can describe the initial algebra (in Sets),
P(I) ∼= I
as a set of trees with branching types and labels determined by P.
For instance, consider the polynomial
P(X) = 1 + A × X
for some set A. What is the initial algebra? Since,
[∗, @] : 1 + A × I ∼= I
we can unwind an element x as:
x = ∗or a1@x1
x1 = ∗or a2@x2
. . .
Thus we essentially have x = a1@a2@ · · · @an. So I can be represented as
the set A-List of (ﬁnite) lists of elements a1, a2, . . . of A, with the structure:
∗= “the empty list”
@(a, ℓ) = a@ℓ

ALGEBRAS FOR ENDOFUNCTORS
241
The usual procedure of “recursive deﬁnition” follows from initiality. For
example, the length function for lists length : A-List →N is usually
deﬁned by:
length(∗) = 0
(10.6)
length(a@ℓ) = 1 + length(ℓ)
(10.7)
We can do this by equipping N with a suitable P(X) = 1+A×X structure,
namely,
[0, m] : 1 + A × N →N
where m(a, n) = 1 + n for all n ∈N. Then by the UMP of the initial
algebra we get a unique function length : A-List →N making a commutative
square:
1 + A × A-List 1 + A × length
- 1 + A × N
A-List
[∗, @]
?
length
- N
[0, m]
?
But this commutativity is, of course, precisely equivalent to the equations
(10.6) and (10.7) above.
In virtue of Lambek’s lemma, we at least know that not all endofunctors can
have initial algebras. For, consider the covariant powerset functor P : Sets →
Sets. An initial algebra for this would give us a set I with the property that
P(I) ∼= I, which is impossible by the well-known theorem of Cantor!
The following proposition gives a useful suﬃcient condition for the existence
of an initial algebra.
Proposition 10.12. If the category S has an initial object 0 and colimits of
diagrams of type ω (call them “ω-colimits”), and the functor
P : S →S
preserves ω-colimits, then P has an initial algebra.
Proof. Note that this generalizes a very similar result for posets already given
above as Proposition 5.35. And even the proof by “Newton’s method” is
essentially the same! Take the ω-sequence
0 →P0 →P 20 →· · ·
and let I be the colimit
I = lim
−→
n
P n0.

242
MONADS AND ALGEBRAS
Then, since P preserves the colimit, there is an isomorphism
P(I) = P(lim
−→
n
P n0) ∼= lim
−→
n
P(P n0) = lim
−→
n
P n0 = I
which is seen to be an initial algebra for P by an easy diagram chase.
Since (as the reader should verify) every polynomial functor P : Sets →Sets
preserves ω-colimits, we have:
Corollary 10.13. Every polynomial functor P : Sets →Sets has an initial
algebra.
Finally, we ask, what is the relationship between algebras for endofunctors and
algebras for monads? The following proposition, which is a sort of “folk theorem”,
gives the answer.
Proposition 10.14. Let the category S have ﬁnite coproducts. Given an endo-
functor P : S →S, the following conditions are equivalent:
1. The P-algebras are the algebras for a monad. Precisely, there is a monad
(T : S →S, η, µ), and an equivalence:
P-Alg(S) ≃ST
between the category of P-algebras and the category ST of algebras for the
monad. Moreover, this equivalence preserves the respective forgetful functors
to S.
2. The forgetful functor U : P-Alg(S) →S has a left adjoint
F ⊢U.
3. For each object A of S, the endofunctor
PA(X) = A + P(X) : S →S
has an initial algebra.
Proof. That (1) implies (2) is clear.
For (2) implies (3), suppose that U has a left adjoint F : S →P-Alg and
consider the endofunctor PA(X) = A + P(X). An algebra (X, γ) is a map γ :
A + P(X) →X. But there is clearly a unique correspondence between the

ALGEBRAS FOR ENDOFUNCTORS
243
following three types of things:
γ : A + P(X) →X
P(X)
A
α
- X
β
?
α : A →U(X, β)
Thus the PA-algebras can be described equivalently as arrows of the form
α : A →U(X, β) for P-algebras (X, β). Moreover, a PA-homomorphism h :
(α, U(X, β)) →(α′, U(X′, β′)) is just a P-homomorphism h : (X, β) →(X′, β′)
making a commutative triangle with α and α′ : A →U(X′, β′). But an initial
object in this category is given by the unit η : A →UFA of the adjunction
F ⊢U, which shows (3).
Indeed, given just the forgetful functor U : P-Alg →S, the existence of initial
objects in the respective categories of arrows α : A →U(X, β), for each A, is
exactly what is needed for the existence of a left adjoint F to U. So (3) also
implies (2).
Before concluding the proof, it is illuminating to see how the free functor
F : S →P-Alg results from condition (3). For each object A in S, consider the
initial PA-algebra α : A + P(IA) →IA. In the notation of recursive type theory,
IA = µX.A + P(X)
meaning it is the (least) solution to the “ﬁxed point equation”
X = A + P(X).
Since α is a map on the coproduct A + P(IA), we have α = [α1, α2], and we
can let:
F(A) = (IA, α2 : P(IA) →IA)

244
MONADS AND ALGEBRAS
To deﬁne the action of F on an arrow f : A →B, let β : B + P(IB) →IB be
the initial PB-algebra and consider the diagram
A + P(IA) ....................
A + P(u)
- A + P(IB)
B + P(IB)
f + P(IB)
?
IA
α
?
......................................
u
- IB
β
?
The right-hand vertical composite β ◦(f + P(IB)) now makes IB into a PA-
algebra. There is thus a unique PA-homomorphism u as indicated, and we can set
F(f) = u.
Finally, to conclude, the fact that (2) implies (1) is an easy application of
Beck’s Precise Tripleability Theorem, for which we refer the reader to section
VI.7 of Mac Lane’s (1971) “Categories Work.”
10.6
Exercises
1. Let T be the equational theory with one constant symbol and one unary
function symbol (no axioms). In any category with a terminal object, a
natural numbers object (NNO) is just an initial T-model. Show that the
natural numbers
(N, 0 ∈N, n + 1 : N →N)
is a NNO in Sets, and that any NNO is uniquely isomorphic to it (as a
T-model).
Finally, show that (N, 0 ∈N, n + 1 : N →N) is uniquely characterized (up
to isomorphism) as the initial algebra for the endofunctor F(X) = X + 1.
2. (“Lambek’s Lemma”) Show that for any endofunctor T : C →C, if i :
TI →I is an initial T-algebra, then i is an isomorphism.
Hint: Consider a diagram of the following form, with suitable arrows.
TI
- T 2I
- TI
I
i
?
- TI
Ti
?
- I
?

EXERCISES
245
Conclude that for any NNO N in any category, there is an isomorph-
ism N + 1 ∼= N. Also, derive the usual recursion property of the natural
numbers from initiality.
3. Assume given categories C and D and adjoint functors
F : C ⇄D : U
with unit η : 1C →UF and counit ϵ : FU →1D. Show that every D in
D determines a T = UF algebra Uϵ : UFUD →UD, and that there is a
“comparison functor” Φ : D →CT which, moreover, commutes with the
“forgetful” functors U : D →C and U T : CT →C.
D
Φ - CT
A
A
A
A
A
A
U
U 





U T
C
4. Show that (P, s, ∪) is a monad on Sets, where
• P : Sets →Sets is the covariant powerset functor, which takes each
function f : X →Y to the image mapping
P(f) = im(f) : P(X) →P(Y )
• for each set X, the component sX : X →P(X) is the singleton
mapping, with
sX(x) = {x} ⊆X
for each x ∈X;
• for each set X, the component ∪X : PP(X) →P(X) is the union
operation, with
∪X(α) = {x ∈X | ∃U∈α. x ∈U} ⊆X
for each α ⊆P(X).
5. Consider the free ⊣forgetful adjunction
F : Sets -

Mon : U
between sets and monoids, and let (T, ηT , µT ) be the associated monad
on Sets. Show that any T-algebra α : TA →A for this monad comes
from a monoid structure on A (exhibit the monoid multiplication and unit
element).

246
MONADS AND ALGEBRAS
6.
(a) Show that an adjoint pair F ⊣U with U : D →C and η : UF →1C
and ϵ : 1D →FU also gives rise to a comonad (G, ϵ, δ) in D, with
G = F ◦U : D →D
ϵ : G →1 the counit
δ = FηU : G →G2
satisfying the duals of the equations for a monad.
(b) Deﬁne the notion of a coalgebra for a comonad, and show (by dual-
ity) that every comonad (G, ϵ, δ) on a category D “comes from” a
(not necessarily unique) adjunction F ⊣G such that G = FU and ϵ
is the counit.
(c) Let End be the category of sets equipped with an endomorphism,
e : S →S. Consider the functor G : End →End deﬁned by
G(S, e) = {x ∈S | e(n+1)(x) = e(n)(x) for some n}
equipped with the restriction of e. Show that this is the functor part
of a comonad on End.
7. Verify that the open and closed subsets of a topological space give rise to
comonad and monad, respectively, on the powerset of the underlying point-
set. Moreover, the categories of coalgebras and algebras are isomorphic.
8. (Kleisli category) Given a monad (T, η, µ) on a category C, in addition to
the Eilenberg-Moore category we can construct another category CT and
an adjunction F ⊣U, η : 1 →UF, ϵ : FU →1 with U : CT →C such
that:
T = U ◦F
η = η
(the unit)
µ = UϵF
This category CT is called the Kleisli Category of the adjunction, and is
deﬁned as follows:
• the objects are the same as those of C, but written AT , BT , . . .,
• an arrow fT : AT →BT is an arrow f : A →TB in C,
• the identity arrow 1AT : AT →AT is the arrow ηA : A →TA in C,
• for composition, given fT : AT →BT and gT : BT →CT , the
composite gT ◦fT : AT →CT is deﬁned to be
µC ◦TgT ◦fT

EXERCISES
247
as indicated in the following diagram:
A
gT ◦fT- TC
TB
fT
?
TgT
- TTC
µC
6
Verify that this indeed deﬁnes a category, and that there are adjoint func-
tors F : C →CT and U : CT →C giving rise to the monad as T = UF,
as claimed.
9. The notion of a coalgebra for an endofunctor P : S →S on an arbitrary
category S is exactly dual to that of a P-algebra. Determine the ﬁnal
coalgebra for the functor
P(X) = 1 + A × X
for a set A. (Hint: Recall that the initial algebra consisted of ﬁnite lists
a1, a2, . . . of elements of A.)

This page intentionally left blank 

REFERENCES
The following works are referred to in the text. They are also recommended for
further reading.
1. Eilenberg, S. and S. Mac Lane (1945) “General theory of natural equival-
ences,” Transactions of the American Mathematical Society 58, 231–294.
2. Johnstone, P.T. (1982) Stone Spaces, Cambridge: Cambridge University
Press.
3. Johnstone, P.T. (2002) Sketches of an Elephant: A Topos Theory Compen-
dium, 2 vols, Oxford: Oxford University Press.
4. Lambek, J. and P. Scott (1986) Introduciton to Higher-Order Categorical
Logic, Cambridge: Cambridge University Press.
5. Lawvere, F.W. (1969) “Adjointness in Foundations,” Dialectica, 23, 281–
296.
6. Mac Lane, S. (1971) Categories for the Working Mathematician, Springer:
Berlin Heidelberg New York, 2nd ed. 1998.
7. Mac Lane, S. and I. Moerdijk (1992) Sheaves in Geometry and Logic: A
First Introduction to Topos Theory, Springer: Berlin Heidelberg New York.
8. McLarty, C. (1995) Elementary Categories, Elementary Toposes, Oxford:
Oxford University Press.

This page intentionally left blank 

INDEX
0, 7
1, 7
2, 7, 129
3, 7, 75
adjoint, 179–219
and orders, 191–193
cocompletion as, 182
examples of, 187–193
existence of, 197, 210
exponential as, 187
freeness as, 179
image as, 192
left/right, 181
limit as, 188
open interior as, 191
polynomial ring as, 190
in a poset, 192
preservation of limits, 197
product as, 181
quantiﬁers as, 193
rules of inference, 194
adjoint functor, 2
Adjoint functor theorem, 210
special, 214
adjunction, 2, see adjoint
counit of, 187
Hom-set deﬁnition, 187
preliminary deﬁnition, 180
unit of, 181
AFT, see Adjoint functor theorem
algebra, 1, 4, 54
boolean, see boolean algebra
for a monad, 229
and endofunctors, 242
for an endofunctor, 236, 237
and monads, 242
heyting, see heyting algebra
initial, 238, 241
Lindenbaum-Tarski, 117
and logic, 193
presentation, 59, 61, 223
arrow, 4
classifying, 174
associative law, 5
atom
in a Boolean algebra, 153
automorphism, 11
inner, 145
BA, 129
Beck’s theorem, 244
bifunctor, 139
Boolean algebra, 14, 29, 30, 45, 113, 129, 131
ﬁnite, 153
C(X), 129
Cantor, 241
Cat, 8, 22, 28, 125, 127
cartesian closed, 139
category, 2, 4
algebraic, 234
arrow, 14
of Boolean algebras, 129
cartesian closed, 10, 108, 108–112, 145
and lambda calculus, 119
equational, 118
of categories, 8, 125
cocomplete, 168
complete, 167, 213
concrete, 6, 12, 128
congruence, 71
constructions on, 13–15
coslice, 15, 23
of diagrams, 159, 175
discrete, 10, 91, 127
dual, 13
Eilenberg-Moore, 229
of elements, 169, 208
ﬁnite, 7
ﬁnitely presented, 73–74
free, 16–21, 23
of functors, see functor category
of graphs, 144
of groups, 68–70
homomorphism of, 8
homomorphism theorem, 73
Kleisli, 233, 246
large, 22
with limits, 92
locally cartesian closed, 202, 206

252
INDEX
category (contd.)
locally small, 22
monoid, 10
opposite, 13
of partial maps, 103
pointed sets, 15, 151
poset, 9, 15
preorder, 8
product, 13
with products, 42, 41–42
of propositions, 220
quotient, 71
skeletal, 156
slice, 15, 152
and indexed families, 203
small, 13, 22
of subobjects, 78
of types, 38, 120
category theory, 1–2, 8, 11, 21, 25, 34, 47,
125
and adjoints, 179
history of, 1
Cayley’s theorem, 11–12, 161
CCC, see category, cartesian closed
change of base, 202
choice
axiom of, 33, 45
function, see function, choice
co-, 49
coalgebra
for a comonad, 235
cocompletion of a category, 199
cocone, 93
codomain, 4, 49
coequalizer, 58, 57–62
of monoids, 62
of categories, 126
of posets, 63, 126
of sets, 63
cogenerating set, 214
colimit, 93, 95–102
creation of, 98
ω-colimit, 241
colimits
of posets, 102
comonad, 234, 234–235
and adjoints, 235
component, 134
composition, 4
of functions, 3
of partial maps, 103
computer science, 2, 9, 31
concatination, 16
cone, 90
as a natural transformation, 144
congruence, 71–73, 75
constant, 30
contravariant, 95
coproduct, 49, 49–54
of categories, 125
in a CCC, 167
of groups, 52
injection, 49
of monoids, 50, 52
in a posets, 51
of posets, 51
of sets, 50, 97
of spaces, 51
covariant, 42
ωCPO, 100, 109, 123
map of, 100
strict, 123
data type, 9
deduction, 9, 115
transcendental, 142
denotational semantics, 9, 121
diagram
commutative, 3
as a functor, 159
of a group, 66
hyperdoctrine, 221
product, 35
pullback, 81
of type, 90
distributive law, 114
and adjoints, 198
domain, 4, 49
duality, 14, 47–49, 58, 63, 235
conceptual, 48
and equivalence, 152
formal, 48
principle, 47
in Sets, 138
stone, 131–133, 152
of vector spaces, 137
element
generalized, 29–32, 35, 79, 81
global, 30
variable, 31
endofunctor, 218, 225, 236–244
epi, see epimorphism
epimorphism, 25, 45, 58
of monoids, 26
split, 33
equalizer, 54, 54–57
of abelian groups, 57

INDEX
253
of functors, 125
of monoids, 57
of posets, 57
of spaces, 57
equivalence
of categories, 147, 146–155
and isomorphism, 148
and duality, 152
class, 57
relation, 57, 63, 79
equivalent categories, 147
evaluation, 107
exponent, 95
exponential, 107, 105–123
of categories, 139, 142
of ωCPOs, 109
of diagrams, 172
of graphs, 143
of groups, 145
in a poset, 113
of posets, 108
Fib, 209
and presheaves, 209
ﬁbration, 209
ﬁeld, 129
ﬁlter, 30
maximal, 30
ultra-, see ultraﬁlter
ﬁxed point, 101, 239, 243
forgetful functor, see functor, forgetful
foundations, 21–22
free, 16
category, 18
cocompletion, 171
monoid, 16, 51, 179
monad, 232
free algebra, 214
Freyd, 210, 214
Fun, 136
function, 1–3
bijective, 11
characteristic, 55, 87, 130, 174
choice, 33
continuous, 6
equality of, 3
identity, 4
injective, 5, 25
monotone, 6
recursive, 6, 217
surjective, 25, 45
functor, 2, 8, 33, 125–127
adjoint, see adjoint, see adjoint
cocontinuous, 199
codiagonal, 126
comonadic, 235
comparison for a monad, 234
composition of, 8
constant, 144, 167
continuous, 94
contravariant, 95
coproduct, 54
embedding, 161
endo-, see endofunctor
exponential, 110
factoring, 156
faithful, 126
forgetful, 15, 16, 19, 44, 126
adjoint, 215
and limits, 98
full, 126
of groups, 70
identity, 8
injective, 126
monadic, 234
morphism of, 133
polynomial, see polynomial functor
of posets, 9
precomposition, 201
product, 41
product preserving, 44
projection, 13
representable, see representable functor
set-valued, 159
functor category, 136, 142–146, 159
cocompleteness of, 168
completeness of, 167
of groups, 145
of posets, 145
Galois connection, 191
generator, 128
generators, 19, 59
for a category, 73, 75
for a CCC, 122
insertion of, 16, 135
graph, 6, 23
directed, 18
as a functor, 144, 160
underlying, 19
Graphs, 144
Grothendieck, 2
group, 5, 11, 13, 65–75, 127
abelian, 53, 63
abstract, 65
as a category, 70–74
factor, 69
homomorphism theorem, 69

254
INDEX
group (contd.)
in a category, 65–68, 75
in lambda calculus, 68
normal subgroup, 68
ordered, 67
permutation, 11
representation, 71, 127
structure, 128, 236
topological, 67
Group, 22
group theory, 1
groupoid, 145
groups
direct limit of, 97
heyting algebra, 113, 113–118
and adjoints, 193
Hom-set, 10, 42, 42–44
homomorphism
of algebras, 237
category, 8
complete, 154
graph, 19
group, 11, 67, 127
monoid, 10
ring, 30
ideal, 15
adjoint, 202
identity arrow, 4
indexed family, 152
and adjoints, 202–206

C P, 169, 208
invariant, 32
IPC, see propositional calculus, intuitionistic
isomorphic, 11
isomorphism, 11, 11–13, 17, 23, 27
natural, 136
junk, 16, 17
Kan extension, 201
kernel
of a functor, 72
of a group homomorphism, 69
Kleene closure, 16
λ-calculus, see lambda calculus
lambda calculus, 9, 38, 68, 119–123, 167
and CCC, 122
completeness theorem, 121
theory in, 121
Lambek’s lemma, 239, 244
large category, see category, large
lattice, 113
Lawvere, 2, 193, 221
LCCC, see category, locally cartesian closed
lifts, 34
lim
−→, 97
lim
←−, 91
limit, 90
creation of, 98
direct, 97
equalizer as, 91
product as, 91
pullback as, 92
terminal object as, 92
limits, 89–96
of categories, 125
of diagrams, 167
and monomorphisms, 103
preservation of, 94–96
preserved by adjoints, 197
by products and equalizers, 92
locally small category, see category, locally
small
logic, 2, 9, 31, 61, 68, 119, 167, 220
and adjoints, 193
categorical, 79
ﬁrst-order, 193
higher-order, 167, 176
intuitionistic, 114
modal, 228, 235
positive, 116
and topoi, 176
Mac Lane, 1, 34, 54
mapping, 6, 8
property, see universal mapping
property
Mon, 10
monad, 227, 223–247
algebra for, 229
and adjoints, 223, 225, 229
Eilenberg-Moore category, 229
on a poset, 228
powerset, 228
monadic, 234
mono, see monomorphism
monoid, 10, 26, 52, 61, 239
free, 17, 16–18
and monad, 227
monomorphism, 25, 45, 56, 77
as a limit, 102
pullback of, 103
split, 33

INDEX
255
morphism, 5
of cocones, 96
of cones, 90
of T-algebras, 229
natural numbers object, 217, 215–219,
239, 244
natural transformation, 2, 134, 135–139, 142
naturality, 133–134
Newton’s method, 101, 241
NNO, see natural numbers object
noise, 16, 17
nonsense
abstract, 125
numbers, 10, 11, 18, 217
ordinal, 146
object, 4
generating, see generator
initial, 28–30
natural numbers, see natural numbers
object
projective, 33, 45
terminal, 28–30
objects
family of, 33
Ord, 146
Par(C), 103
Par, 103, 150
partial map, 103, 150
Π, 203
point, 30, 151
points
enough, 31
polynomial functor, 237
generalized, 238
and trees, 240
Pos, 6, 22
not monadic, 234
poset, 6, 26, 29, 51, 127
complete, 114
ﬁbration of, 209
preorder, 8, 79, 214
presheaf, 161
product, 35, 34–42
cartesian, 34
of categories, 37, 125
of functors, 135
of monoids, 37
in a poset, 37
of posets, 37
of sets, 36
of topological spaces, 37
programming language, 9
projective, see object, projective
propositional calculus, 114–118, 167
and adjoints, 193
completeness theorem, 117
intuitionistic, 115
propositional function, 87
in a topos, 176
pseudo-inverse, 147
pullback, 80, 80–88
and characteristic functions, 87
and extensions, 87
functor, 85, 152
inverse image as, 83
by products and equalizers, 83
properties of, 84–88
and reindexing, 88
of sets, 83
two, lemma, 84
pushout, 103
of sets, 95
quantiﬁers
geometric interpretation, 195
quantiﬁers as adjoints, 176, 193–196
quotient, 57, 58
of sets, 63
RAPL, 197–202
recursion, 239, 241
reindexing, 203
Rel, 7, 23
relation, 7, 59
composition, 7
identity, 7
local membership, 79
relative product, 7
representable functor, 42, 127, 160
characterization of, 213
and colimits, 95
and limits, 94
contravariant, 95, 128
representation, 11, 161
retract, 33
retraction, 33–34
ring, 26
of functions, 129
pointed, 190
polynomial, 190
SAFT, see Adjoint functor theorem, special
Scott, Dana, 123

256
INDEX
section, 33–34
semigroup, 10
set, 3, 10, 13
function, 106
pointed, 15, 151
power, 29, 79, 114, 130, 228, 238
as an adjoint, 220
structured, 5, 10, 26, 37, 162
and functors, 160
set theory, 21
Sets∗, 15, 151
sets
cumulative hierarchy, 98
family of, 88, 96, 152, 202
Sets, 5, 22
cartesian closed, 108
SetsC, 159
and adjoint functors, 201
cartesian closed, 174
cocomplete, 168
complete, 167
locally cartesian closed, 209
slice category of, 207
topos, 175
Setsﬁn, 5, 146, 153
SetsI, 152
SetsI, 202
sieve, 175
Σ, 203
small category, see category, small
solution set, 210
space, see topological space
Stone duality, see duality, stone
Stone duality theorem, 133
Stone representation, 133
Stone space, 155
string, 233
structure, 1, 25, 31, 129, 226
ﬁnitary, 237
representable, 127–131
Sub, 78
subcategory, 125
full, 126
subobject, 77, 77–80
classiﬁer, 174, 177
for presheaves, 175
as an extension, 176
T-algebra, 214
T-algebra, 223
for a monad, 229
test object, 13, 31
Top, 22
topological space, 6, 37, 51, 114, 129, 155,
235, 246
interior, 191
topos, 175, 174–176
and logic, 176
transformation
natural, see natural transformation
transpose, 107
tree, 239, 240
triangle identities, 224, 223–225
triple, see monad
twist, 136
type theory, 38–40, 119–123, see lambda
calculus
ultraﬁlter, 30, 45, 95, 131, 153
principal, 132
UMP, see universal mapping property
unit law, 5
universal, 17, 105
subobject, 174
universal mapping property, 17, 19, 25, 34,
122
and adjoints, 180
of a congruence, 72
of coequalizers, 58
of coproducts, 49
of equalizers, 54
of exponentials, 107
of free categories, 20
of free monoids, 17
of function sets, 106
of initial objects, 28
of limits, 91
of natural numbers, 216
of polynomials, 191
of products, 35, 45
of pullbacks, 80
of terminal objects, 28
of Yoneda, 171, 199
vector space, 6, 26, 137
ﬁnite dimensional, 138
well powered, 214
word, 16, 53
empty, 16
Yoneda embedding, 161, 160–162, 165
Yoneda lemma, 162, 166, 208

