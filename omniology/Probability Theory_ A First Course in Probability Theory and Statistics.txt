
Werner Linde
Probability Theory
De Gruyter Graduate

Also of interest
Probability Theory and Statistical Applications. A Profound Treatise for
Self-Study
Peter ZÃ¶rnig, 2016
ISBN 978-3-11-036319-7, e-ISBN (PDF) 978-3-11-040271-1,
e-ISBN (EPUB) 978-3-11-040283-4
Stochastic Finance: An Introduction in Discrete Time
Hans FÃ¶llmer, Alexander Schied, 4th Edition, 2016
ISBN 978-3-11-046344-6, e-ISBN (PDF) 978-3-11-046345-3,
e-ISBN (EPUB) 978-3-11-046346-0
Asymptotic Statistics: With a View to Stochastic Processes
Reinhard HÃ¶pfner, 2014
ISBN 978-3-11-025024-4, e-ISBN (PDF) 978-3-11-025028-2,
e-ISBN (EPUB) 978-3-11-036778-2
Brownian Motion: An Introduction to Stochastic Processes
RenÃ© L.Schilling, Lothar Partzsch, 2nd Edition, 2014
ISBN 978-3-11-030729-0, e-ISBN (PDF) 978-3-11-030730-6,
e-ISBN (EPUB) 978-3-11-037398-1
Stochastics: Introduction to Probability and Statistics
Hans-Otto Georgii, 2nd Edition, 2012
ISBN 978-3-11-029254-1, e-ISBN (PDF) 978-3-11-029360-9

Werner Linde
Probability Theory
A First Course in Probability Theory and Statistics

Mathematics Subject Classiï¬cation 2010
Primary: 60-01, 62-01; Secondary: 60A05
Author
Prof. Dr. Werner Linde
Friedrich-Schiller-UniversitÃ¤t Jena
FakultÃ¤t fÃ¼r Mathematik & Informatik
Institut fÃ¼r Stochastik
Prof. fÃ¼r Stochastische Analysis
D-07737 Jena
Werner.Linde@mathematik.uni-jena.de
and
University of Delaware
Department of Mathematical Sciences
501 Ewing Hall
Newark DE, 19716
lindew@udel.edu
ISBN 978-3-11-046617-1
e-ISBN (PDF) 978-3-11-046619-5
e-ISBN (EPUB) 978-3-11-046625-6
Library of Congress Cataloging-in-Publication Data
A CIP catalog record for this book has been applied for at the Library of Congress.
Bibliographic information published by the Deutsche Nationalbibliothek
The Deutsche Nationalbibliothek lists this publication in the Deutsche Nationalbibliograï¬e; detailed
bibliographic data are available on the Internet at http://dnb.dnb.de.
Â© 2016 Walter de Gruyter GmbH, Berlin/Boston
Typesetting: Integra Software Services Pvt. Ltd.
Printing and binding: CPI books GmbH, Leck
Cover image: Werner Linde
8
âƒPrinted on acid-free paper
Printed in Germany
www.degruyter.com

To my wife Karin


Preface
This book is intended as an introductory course for students in mathematics, phys-
ical sciences, engineering, or in other related ï¬elds. It is based on the experience
of probability lectures taught during the past 25 years, where the spectrum reached
from two-hour introductory courses, over Measure Theory and advanced probability
classes, to such topics as Stochastic Processes and Mathematical Statistics. Until 2012
these lectures were delivered to students at the University of Jena (Germany), and since
2013 to those at the University of Delaware in Newark (USA).
The book is the completely revised version of the German edition â€œStochastik fÃ¼r
das Lehramt,â€ which appeared in 2014 at De Gruyter. At most universities in Germany,
there exist special classes in Probability Theory for students who want to become
teachers of mathematics in high schools. Besides basic facts about Probability Theory,
these courses are also supposed to give an introduction into Mathematical Statistics.
Thus, the original main intention for the German version was to write a book that helps
those students understand Probability Theory better. But soon the book turned out to
also be useful as introduction for students in other ï¬elds, e.g. in mathematics, phys-
ics, and so on. Thus we decided, in order to make the book applicable for a broader
audience, to provide a translation in the English language.
During numerous years of teaching I learned the following:
â€“
Probabilistic questions are usually easy to formulate, generally have a tight rela-
tion to everyday problems, and therefore attract the interest of the audience. Every
student knows the phenomena that occur when one rolls a die, plays cards, tosses
a coin, or plays a lottery. Thus, an initial interest in Probability Theory exists.
â€“
In contrast, after a short time many students have very serious difï¬culties with
understanding the presented topics. Consequently, a common opinion among
students is that Probability Theory is a very complicated topic, causing a lot of
problems and troubles.
Surely there exist several reasons for the bad image of Probability Theory among stu-
dents. But, as we believe, the most important one is as follows. In Probability Theory,
the type of problems and questions considered, as well as the way of thinking, differs
considerably from the problems, questions, and thinking in other ï¬elds of mathem-
atics, i.e., from ï¬elds with which the students became acquainted before attending a
probability course. For example, in Calculus a function has a well-described domain
of deï¬nition; mostly it is deï¬ned by a concrete formula, has certain properties as con-
tinuity, differentiability, and so on. A function is something very concrete which can
be made vivid by drawing its graph. In contrast, in Probability Theory functions are
mostly investigated as random variables. They are deï¬ned on a completely unimport-
ant, nonspeciï¬ed sample space, and they generally do not possess a concrete formula
for their deï¬nition. It may even happen that only the existence of a function (random
variable) is known. The only property of a random variable which really matters is

VIII
Preface
the distribution of its values. This and many other similar techniques make the whole
theory something mysterious and not completely comprehensible.
Considering this observation, we organized the book in a way that tries to make
probabilistic problems more understandable and that puts the focus more onto ex-
planations of the deï¬nitions, notations, and results. The tools we use to do this are
examples; we present at least one before a new deï¬nition, in order to motivate it, fol-
lowed by more examples after the deï¬nition to make it comprehensible. Here we act
upon the maxim expressed by Einsteinâ€™s quote1:
Example isnâ€™t another way to teach, it is the only way to teach.
Presenting the basic results and methods in Probability Theory without using results,
facts, and notations from Measure Theory is, in our opinion, as difï¬cult as to square
the circle. Either one restricts oneself to discrete probability measures and random
variables or one has to be unprecise. There is no other choice! In some places, it is
possible to avoid the use of measure theoretic facts, such as the Lebesgue integral, or
the existence of inï¬nite product measures, and so on, but the price is high.2 Of course,
I also struggled with the problem of missing facts from Measure Theory while writing
this book. Therefore, I tried to include some ideas and some results about 3-ï¬elds,
measures, and integrals, hoping that a few readers become interested and want to
learn more about Measure Theory. For those, we refer to the books [Coh13], [Dud02],
or [Bil12] as good sources.
In this context, let us make some remark about the veriï¬cation of the presented
results. Whenever it was possible, we tried to prove the stated results. Times have
changed; when I was a student, every theorem presented in a mathematical lecture
was proved â€“ really every one. Facts and results without proof were doubtful and
soon forgotten. And a tricky and elegant proof is sometimes more impressive than
the proven result (at least to us). Hopefully, some readers will like some of the proofs
in this book as much as we did.
One of most used applications of Probability Theory is Mathematical Statistics.
When I met former students of mine, I often asked them which kind of mathematics
they are mainly using now in their daily work. The overwhelming majority of them
answered that one of their main ï¬elds of mathematical work is statistical problems.
Therefore, we decided to include an introductory chapter about Mathematical Statist-
ics. Nowadays, due to the existence of good and fast statistical programs, it is very
easy to analyze data, to evaluate conï¬dence regions, or to test a given hypotheses.
But do those who use these programs also always know what they are doing? Since
1 See http://www.alberteinsteinsite.com/quotes/einsteinquotes.html
2 For example, several years ago, to avoid the use of the Lebesgue integral, I introduced the expected
value of a random variable as a Riemann integral via its distribution function. This is mathematically
correct, but at the end almost no students understood what the expected value really is. Try to prove
that the expected value is linear using this approach!

Preface
IX
we doubt that this is so, we stressed the focus in this chapter to the question of why
the main statistical methods work and on what mathematical background they rest.
We also investigate how precise statistical decisions are and what kinds of errors may
occur.
The organization of this book differs a little bit from those in many other ï¬rst-
course books about Probability Theory. Having Measure Theory in the back of our
minds causes us to think that probability measures are the most important ingredi-
ent of Probability Theory; random variables come in second. On the contrary, many
other authors go exactly the other way. They start with random variables, and prob-
ability measures then occur as their distribution on their range spaces (mostly R).
In this case, a standard normal probability measure does not exist, only a standard
normal distributed random variable. Both approaches have their advantages and dis-
advantages, but as we said, for us the probability measures are interesting in their own
right, and therefore we start with them in Chapter 1, followed by random variables in
Section 3.
The book also contains some facts and results that are more advanced and usually
not part of an introductory course in Probability Theory. Such topics are, for example,
the investigation of product measures, order statistics, and so on. We have assigned
those more involved sections with a star. They may be skipped at a ï¬rst reading
without loss in the following chapters.
At the end of each chapter, one ï¬nds a collection of some problems related to the
contents of the section. Here we restricted ourselves to a few problems in the actual
task; the solutions of these problems are helpful to the understanding of the presented
topics. The problems are mainly taken from our collection of homeworks and exams
during the past years. For those who want to work with more problems we refer to
many books, as e.g. [GS01a], [Gha05], [Pao06], or [Ros14], which contain a huge collec-
tion of probabilistic problems, ranging from easy to difï¬cult, from natural to artiï¬cial,
from interesting to boring.
Finally I want to express my thanks to those who supported my work at the trans-
lation and revision of the present book. Many students at the University of Delaware
helped me to improve my English and to correct wrong phrases and wrong expres-
sions. To mention all of them is impossible. But among them were a few students
who read whole chapters and, without them, the book would have never been ï¬n-
ished (or readable). In particular I want to mention Emily Wagner and Spencer Walker.
They both did really a great job. Many thanks! Let me also express my gratitude to
Colleen McInerney, Rachel Austin, Daniel Atadan, and Quentin Dubroff, all students
in Delaware and attending my classes for some time. They also read whole sections of
the book and corrected my broken English. Finally, my thanks go to Professor Anne
Leucht from the Technical University in Braunschweig (Germany); her ï¬eld of work is
Mathematical Statistics,and her hints and remarks about Chapter 8 in this book were
important to me.

X
Preface
And last but not least I want to thank the Department of Mathematical Sciences
at the University of Delaware for the excellent working conditions after my retirement
in Germany.
Newark, Delaware, June 6, 2016
Werner Linde

Contents
1
Probabilities
1
1.1
Probability Spaces
1
1.1.1
Sample Spaces
1
1.1.2
3-Fields of Events
2
1.1.3
Probability Measures
5
1.2
Basic Properties of Probability Measures
9
1.3
Discrete Probability Measures
13
1.4
Special Discrete Probability Measures
18
1.4.1
Dirac Measure
18
1.4.2
Uniform Distribution on a Finite Set
18
1.4.3
Binomial Distribution
22
1.4.4
Multinomial Distribution
24
1.4.5
Poisson Distribution
27
1.4.6
Hypergeometric Distribution
29
1.4.7
Geometric Distribution
33
1.4.8
Negative Binomial Distribution
35
1.5
Continuous Probability Measures
39
1.6
Special Continuous Distributions
43
1.6.1
Uniform Distribution on an Interval
43
1.6.2
Normal Distribution
46
1.6.3
Gamma Distribution
48
1.6.4
Exponential Distribution
51
1.6.5
Erlang Distribution
52
1.6.6
Chi-Squared Distribution
53
1.6.7
Beta Distribution
54
1.6.8
Cauchy Distribution
56
1.7
Distribution Function
57
1.8
Multivariate Continuous Distributions
64
1.8.1
Multivariate Density Functions
64
1.8.2
Multivariate Uniform Distribution
66
1.9
â‹†Products of Probability Spaces
71
1.9.1
Product 3-Fields and Measures
71
1.9.2
Product Measures: Discrete Case
74
1.9.3
Product Measures: Continuous Case
76
1.10
Problems
79
2
Conditional Probabilities and Independence
86
2.1
Conditional Probabilities
86
2.2
Independence of Events
94
2.3
Problems
101

XII
Contents
3
Random Variables and Their Distribution
105
3.1
Transformation of Random Values
105
3.2
Probability Distribution of a Random Variable
107
3.3
Special Distributed Random Variables
117
3.4
Random Vectors
119
3.5
Joint and Marginal Distributions
120
3.5.1
Marginal Distributions: Discrete Case
123
3.5.2
Marginal Distributions: Continuous Case
128
3.6
Independence of Random Variables
131
3.6.1
Independence of Discrete Random Variables
134
3.6.2
Independence of Continuous Random Variables
138
3.7
â‹†Order Statistics
141
3.8
Problems
146
4
Operations on Random Variables
149
4.1
Mappings of Random Variables
149
4.2
Linear Transformations
154
4.3
Coin Tossing versus Uniform Distribution
157
4.3.1
Binary Fractions
157
4.3.2
Binary Fractions of Random Numbers
160
4.3.3
Random Numbers Generated by Coin Tossing
162
4.4
Simulation of Random Variables
164
4.5
Addition of Random Variables
169
4.5.1
Sums of Discrete Random Variables
171
4.5.2
Sums of Continuous Random Variables
175
4.6
Sums of Certain Random Variables
177
4.7
Products and Quotients of Random Variables
189
4.7.1
Studentâ€™s t-Distribution
192
4.7.2
F-Distribution
194
4.8
Problems
196
5
Expected Value, Variance, and Covariance
200
5.1
Expected Value
200
5.1.1
Expected Value of Discrete Random Variables
200
5.1.2
Expected Value of Certain Discrete Random
Variables
203
5.1.3
Expected Value of Continuous Random Variables
208
5.1.4
Expected Value of Certain Continuous Random
Variables
211
5.1.5
Properties of the Expected Value
215
5.2
Variance
222
5.2.1
Higher Moments of Random Variables
222
5.2.2
Variance of Random Variables
226

Contents
XIII
5.2.3
Variance of Certain Random Variables
229
5.3
Covariance and Correlation
233
5.3.1
Covariance
233
5.3.2
Correlation Coefï¬cient
240
5.4
Problems
243
6
Normally Distributed Random Vectors
248
6.1
Representation and Density
248
6.2
Expected Value and Covariance Matrix
256
6.3
Problems
262
7
Limit Theorems
264
7.1
Laws of Large Numbers
264
7.1.1
Chebyshevâ€™s Inequality
264
7.1.2
â‹†Inï¬nite Sequences of Independent Random
Variables
267
7.1.3
â‹†Borelâ€“Cantelli Lemma
270
7.1.4
Weak Law of Large Numbers
276
7.1.5
Strong Law of Large Numbers
278
7.2
Central Limit Theorem
283
7.3
Problems
298
8
Mathematical Statistics
301
8.1
Statistical Models
301
8.1.1
Nonparametric Statistical Models
301
8.1.2
Parametric Statistical Models
305
8.2
Statistical Hypothesis Testing
307
8.2.1
Hypotheses and Tests
307
8.2.2
Power Function and Signiï¬cance Tests
310
8.3
Tests for Binomial Distributed Populations
315
8.4
Tests for Normally Distributed Populations
319
8.4.1
Fisherâ€™s Theorem
320
8.4.2
Quantiles
323
8.4.3
Z-Tests or Gauss Tests
326
8.4.4
t-Tests
328
8.4.5
72-Tests for the Variance
330
8.4.6
Two-Sample Z-Tests
332
8.4.7
Two-Sample t-Tests
334
8.4.8
F-Tests
336
8.5
Point Estimators
337
8.5.1
Maximum Likelihood Estimation
338
8.5.2
Unbiased Estimators
346
8.5.3
Risk Function
351

XIV
Contents
8.6
Conï¬dence Regions and Intervals
355
8.7
Problems
362
A Appendix
365
A.1
Notations
365
A.2
Elements of Set Theory
365
A.3
Combinatorics
367
A.3.1
Binomial Coefï¬cients
367
A.3.2
Drawing Balls out of an Urn
373
A.3.3
Multinomial Coefï¬cients
376
A.4
Vectors and Matrices
379
A.5
Some Analytic Tools
382
Bibliography
389
Index
391

1 Probabilities
1.1 Probability Spaces
The basic concern of Probability Theory is to model experiments involving ran-
domness, that is, experiments with nondetermined outcome, shortly called random
experiments. The Russian mathematician A.N. Kolmogorov established the mod-
ern Probability Theory in 1933 by publishing his book (cf. [Kol33]) Grundbegriffe der
Wahrscheinlichkeitsrechnung. In it, he postulated the following:
Random experiments are described by probability spaces (K, A, P)
The triple (K, A, P) comprises a sample space K, a 3-ï¬eld A of events, and a
mapping P from A to [0, 1], called probability measure or probability distribution.
Let us now explain the three different components of a probability space in detail.
We start with the sample space.
1.1.1 Sample Spaces
Deï¬nition 1.1.1. The sample space K is a nonempty set that contains (at least) all
possible outcomes of the random experiment.
Remark 1.1.2. Due to mathematical reasons sometimes it can be useful to choose K
larger than necessary. It is only important that the sample space contains all possible
results.
Example 1.1.3. When rolling a die one time the natural choice for the sample space is
K = {1, . . . , 6}. However, it would also be possible to take K = {1, 2, . . .} or even K = R.
In contrast, K = {1, . . . , 5} is not suitable for the description of the experiment.
Example 1.1.4. Roll a die until the number â€œ6â€ shows up for the ï¬rst time. Record the
number of necessary rolls until the ï¬rst appearance of â€œ6.â€ The suitable sample space
in this case is K = {1, 2, . . . }. Any ï¬nite set {1, 2, . . . , N} is not appropriate because,
even if we choose N very large, we can never be 100% sure that the ï¬rst â€œ6â€ really
appears during the ï¬rst N rolls.
Example 1.1.5. A light bulb is switched on at time zero and burns for a certain period
of time. At some random time t > 0 it burns out. To describe this experiment we have
to take into account all possible times t > 0. Therefore, a natural choice for the sample
space in this case is K = (0, âˆ), or, if we do not exclude that the bulb is defective from
the very beginning, then K = [0, âˆ).

2
1 Probabilities
Subsets of the sample space K are called events. In other words, the powerset P(K)
is the collection of all possible events. For example, when we roll a die once there are
26 = 64 possible events, as, for example,

Ã¸, {1}, . . . , {6}, {1, 2}, . . . , {1, 6}, {2, 3}, . . . , {2, 6}, . . . , {1, 2, 3, 4, 5}, K

.
Among all events there are some of special interest, the so-called elementary events.
These are events containing exactly one element. In Example 1.1.3 the elementary
events are
{1}, {2}, {3}, {4}, {5}
and
{6} .
Remark 1.1.6. Never confuse the elementary events with the points that they contain.
Look at Example 1.1.3. There we have 6 âˆˆK and for the generated elementary event
holds {6} âˆˆP(K).
Let A âŠ†K be an event. After executing the random experiment one observes a result
9 âˆˆK. Then two cases are possible.
1.
The outcome 9 belongs to A. In this case we say that the event A occurred.
2.
If 9 is not in A, that is, if 9 âˆˆAc, then the event A did A not occur.
Example 1.1.7. Roll a die once and let A = {2, 4}. Say the outcome was number â€œ6.â€
Then A did not occur. But, if we obtained number â€œ2,â€ then A occurred.
Example 1.1.8. In Example 1.1.5 the occurrence of an event A = [T, âˆ) tells us that the
light bulb burned out after time T or, in other words, at time T it still shone.
Let us formulate some easy rules for the occurrence of events.
1.
By the choice of the sample space the event K always occurs. Therefore, K is also
called the certain event.
2.
The empty set never occurs. Thus it is called the impossible event.
3.
An event A occurs if and only if the complementary event Ac does not, and vice
versa, A does not occur if and only if Ac does.
4.
If A and B are two events, then A âˆªB occurs if at least one of the two sets occurs.
Hereby we do not exclude that A and B may both occur.
5.
The event A âˆ©B occurs if and only if A and B both occur.
1.1.2 3-Fields of Events
The basic aim of Probability Theory is to assign to each event A a number P(A) in
[0, 1], which describes the likelihood of its occurrence. If the occurrence of an event A
is very likely, then P(A) should be close to 1 while P(A) close to zero suggests that the
appearance of A is very unlikely. The mapping A â†¦P(A) must possess certain natural

1.1 Probability Spaces
3
properties. Unfortunately, by mathematical reason it is not always possible to assign
to each event A a number P(A) such that A â†¦P(A) has the desired properties. The
solution is ingenious and and one of the key observations in Kolmogorovâ€™s approach:
one chooses a subset A âŠ†P(K) such that P(A) is only deï¬ned for A âˆˆA. If A âˆ‰A, then
P(A) does not exist. Of course, A should be chosen as large as possible and, moreover,
at least â€œordinaryâ€ sets should belong to A.
The collection A of events has to satisfy some algebraic conditions. More pre-
cisely, the following properties are supposed.
Deï¬nition 1.1.9. A collection A of subsets of K is called 3-ï¬eld if
(1)
Ã¸ âˆˆA,
(2)
if A âˆˆA then Ac âˆˆA,
and
(3)
for countably many A1, A2, . . . in A follows âˆ
j=1 Aj âˆˆA.
Let us verify some easy properties of 3-ï¬elds.
Proposition 1.1.10. Let A be a 3-ï¬eld of subsets of K. Then the following are valid:
(i)
K âˆˆA.
(ii)
If A1, . . . , An are ï¬nitely many sets in A, then n
j=1 Aj âˆˆA.
(iii)
If A1, A2, . . . belong to A, then so does âˆ
j=1 Aj.
(iv)
Whenever A1, . . . , An âˆˆA, then n
j=1 Aj âˆˆA.
Proof: Assertion (i) is a direct consequence of Ã¸ âˆˆA combined with property (2) of
3-ï¬elds.
To verify (ii) let A1, . . . , An be in A. Set An+1 = An+2 = â‹…â‹…â‹…= Ã¸. Then for all j = 1, 2, . . .
we have Aj âˆˆA and by property (3) of 3-ï¬elds also âˆ
j=1 Aj âˆˆA. But note that âˆ
j=1 Aj =
n
j=1 Aj, hence (ii) is valid.
To prove (iii) we ï¬rst observe that Aj âˆˆA yields Ac
j âˆˆA, hence âˆ
j=1 Ac
j âˆˆA. Another
application of (2) implies
 âˆ
j=1 Ac
j
c âˆˆA. De Morganâ€™s rule asserts
 âˆ
	
j=1
Ac
j

c
=
âˆ

j=1
Aj,
which completes the proof of (iii).
Assertion (iv) may be derived from an application of (ii) to the complementary sets
as we did in the proof of (iii). Or use the method in the proof of (ii), but this time we
choose An+1 = An+2 = â‹…â‹…â‹…= K.
âˆ
Corollary 1.1.11. If sets A and B belong to a 3-ï¬eld A, then so do A âˆªB, A âˆ©B, A\B, and
ABB.

4
1 Probabilities
The easiest examples of 3-ï¬elds are either A = {Ã¸, K} or A = P(K). However, the
former 3-ï¬eld is much too small for applications while the latter one is generally too
big, at least if the sample space is uncountably inï¬nite. We will shortly indicate how
one constructs suitable 3-ï¬elds in the case of â€œlargeâ€ sample spaces as, for example,
R or Rn.
Proposition 1.1.12. Let C be an arbitrary nonempty collection of subsets of K. Then
there is a 3-ï¬eld A possessing the following properties:
1.
It holds C âŠ†A or, verbally, each set C âˆˆC belongs to the 3-ï¬eld A.
2.
The 3-ï¬eld A is the smallest one possessing this property. That is, whenever Aâ€² is
another 3-ï¬eld with C âŠ†Aâ€², then A âŠ†Aâ€².
Proof: Let I be the collection of all 3-ï¬elds Aâ€² on K for which C âŠ†Aâ€², that is,
I := {Aâ€² âŠ†P(K) : C âŠ†Aâ€² , Aâ€² is a 3-ï¬eld} .
The collection I is nonempty because it contains at least one element, namely the
powerset of K. Of course, P(K) is a 3-ï¬eld and C âŠ†P(K) by trivial reason, hence
P(K) âˆˆI.
Next deï¬ne A by
A :=

Aâ€²âˆˆI
Aâ€² = {A âŠ†K : A âˆˆAâ€² , âˆ€Aâ€² âˆˆI} .
It is not difï¬cult to prove that A is a 3-ï¬eld with C âŠ†A. Indeed, if C âˆˆC, then C âˆˆAâ€²
for all Aâ€² âˆˆI, hence by construction of A we get C âˆˆA.
Furthermore, A is also the smallest 3-ï¬eld containing C. To see this, take an ar-
bitrary 3-ï¬eld ËœA containing C. Then ËœA âˆˆI, which implies A âŠ†
ËœA because A is the
intersection over all 3-ï¬elds in I. This completes the proof.
âˆ
Deï¬nition 1.1.13. Let C be an arbitrary nonempty collection of subsets of K. The
smallest 3-ï¬eld containing C is called the 3-ï¬eld generated by C. It is denoted
by 3(C).
Remark 1.1.14. 3(C) is characterized by the three following properties:
1.
3(C) is a 3-ï¬eld.
2.
C âŠ†3(C).
3.
If C âŠ†Aâ€² for some 3-ï¬eld Aâ€², then 3(C) âŠ†Aâ€².

1.1 Probability Spaces
5
Deï¬nition 1.1.15. Let C âŠ†P(R) be the collection of all ï¬nite closed intervals in R,
that is,
C = {[a, b] : a < b , a, b âˆˆR} .
The 3-ï¬eld generated by C is denoted by B(R) and is called Borel 3-ï¬eld. If B âˆˆ
B(R), then it is said to be a Borel set.
Remark 1.1.16. By construction every closed interval in R is a Borel set. Furthermore,
the properties of 3-ï¬elds also imply that complements of such intervals, their count-
able unions, and intersections are Borel sets. One might believe that all subsets of R
are Borel sets. This is not the case; for the construction of a non-Borel set we refer to
[Gha05], Example 1.21, or [Dud02], pages 105â€“108.
Remark 1.1.17. There exist many other systems of subsets in R generating B(R). Let
us only mention two of them:
C1 = {(â€“âˆ, b] : b âˆˆR}
or
C2 = {(a, âˆ) : a âˆˆR} .
1.1.3 Probability Measures
The occurrence of an event in a random experiment is not completely haphazardly.
Although we are not able to predict the outcome of the next trial, the occurrence or
nonoccurrence of an event follows certain rules. Some events are more likely to oc-
cur, others less. The degree of likelihood of an event A is described by a number P(A),
called the probability of the occurrence of A (in short, probability of A). The most com-
mon scale for probabilities is 0 â‰¤P(A) â‰¤1, where the larger P(A) is the more likely is
its occurrence. One could also think of other scales as 0 â‰¤P(A) â‰¤100. In fact, this is
even quite often used; in this sense a chance of 50% equals a probability of 1/2.
What does it mean that an event A has probability P(A)? For example, what does
it tell us that an event occurs with probability 1/2? Does this mean a half-occurrence
of A? Surely not.
To answer this question we have to assume that we execute an experiment not
only once1 but several, say n, times. Thereby we have to ensure that the conditions
1 It does not make sense to speak of the probability of an event that can be executed only once. For
example, it is (mathematically) absurd to ask for the probability that the Eiffel Tower will be in Paris
for yet another 100 years.

6
1 Probabilities
of the experiment do not change and that the single results do not depend on each
other. Let
an(A) := Number of trials where A occurs .
The quantity an(A) is called absolute frequency of the occurrence of A in n trials.
Observe that an(A) is a random number with 0 â‰¤an(A) â‰¤n. Next we set
rn(A) := an(A)
n
(1.1)
and name it relative frequency of the occurrence of A in n trials. This number is
random as well, but now 0 â‰¤rn(A) â‰¤1.
It is somehow intuitively clear2 that these relative frequencies converge to a
(nonrandom) number as n â†’âˆ. And this limit is exactly the desired probability of
the occurrence of the event A. Let us express this in a different way: say we execute
an experiment n times for some large n. Then, on average, we will observe n â‹…P(A) the
occurrence of A. For example, when rolling a fair die many times, an even number will
be given approximately half the cases.
Which natural properties of A â†¦P(A) may be deduced from limnâ†’âˆrn(A) = P(A)?
1.
Since 0 â‰¤rn(A) â‰¤1, we conclude 0 â‰¤P(A) â‰¤1.
2.
Because of rn(K) = 1 for each n â‰¥1 we get P(K) = 1.
3.
The property rn(Ã¸) = 0 yields P(Ã¸) = 0.
4.
Let A and B be two disjoint events. Then rn(A âˆªB) = rn(A) + rn(B), hence the limits
should satisfy a similar relation, that is,
P(A âˆªB) = P(A) + P(B) .
(1.2)
Deï¬nition 1.1.18. A mapping P fulï¬lling eq. (1.2) for disjoint A and B is called
ï¬nitely additive.
Remark 1.1.19. Applying eq. (1.2) successively leads to the following. If A1, . . . , An are
disjoint, then
P
 n
	
j=1
Aj

=
n

j=1
P(Aj) .
Finite additivity is a very useful property of probabilities, and in the case of ï¬nite
sample spaces, it completely sufï¬ces to build a fruitful theory. But as soon as the
sample space is inï¬nite it is too weak. To see this let us come back to Example 1.1.4.
2 We will discuss this question more precisely in Section 7.1.

1.1 Probability Spaces
7
Assume we want to evaluate the probability of the event A = {2, 4, 6, . . . }, that is,
the ï¬rst â€œ6â€ appears at an even number of trials. Then we have to split A into (inï¬n-
itely) many disjoint events {2}, {4}, . . . . The ï¬nite additivity of P does not sufï¬ce to get
P(A) = P({2})+P({4})+ â‹…â‹…â‹…. In order to evaluate P(A) in this way we need the following
stronger property of P.
Deï¬nition 1.1.20. A mapping P is said to be 3-additive provided that for count-
ably many disjoint A1, A2, . . . in K we get
P
 âˆ
	
j=1
Aj

=
âˆ

j=1
P(Aj)
Let us summarize what we have until now: a mapping P assigning each event its
probability should possess the following natural properties:
1.
For all A holds 0 â‰¤P(A) â‰¤1.
2.
We have P(Ã¸) = 0 and P(K) = 1.
3.
The mapping P has to be 3-additive.
Thus, given a sample space K, we look for a function P deï¬ned on P(K) satis-
fying the previous properties. But, as already mentioned, if K is uncountable, for
example, K = R, then only very special3 P with these properties exist.
To overcome these difï¬culties, in such cases we have to restrict P to a 3-ï¬eld
A âŠ†P(K).
Deï¬nition 1.1.21. Let K be a sample space and let A be a 3-ï¬eld of subsets
of K. A function P : A â†’[0, 1] is called probability measure or probability
distribution on (K, A) if
1.
P(Ã¸) = 0 and P(K) = 1.
2.
P is 3-additive, that is, for each sequence of disjoint sets Aj âˆˆA, j = 1, 2, . . . ,
follows
P
 âˆ
	
j=1
Aj

=
âˆ

j=1
P(Aj) .
(1.3)
Remark 1.1.22. Note that the left-hand side of eq. (1.3) is well-deï¬ned. Indeed, since
A is a 3-ï¬eld, Aj âˆˆA implies âˆ
j=1 Aj âˆˆA as well.
Now we are in a position to deï¬ne probability spaces in the exact way.
3 Discrete ones as we will investigate in Section 1.3.

8
1 Probabilities
Deï¬nition 1.1.23. A probability space is a triple (K, A, P), where K is a sample
space, A denotes a 3-ï¬eld consisting of subsets of K and P : A â†’[0, 1] is a
probability measure.
Remark 1.1.24. Given A âˆˆA, the number P(A) describes its probability or, more pre-
cisely, its probability of occurrence. Subsets A of K with A âˆ‰A do not possess a
probability.
Let us demonstrate a simple example on how to construct a probability space for a
given random experiment. Several other examples will follow soon.
Example 1.1.25. We ask for a probability space that describes rolling a fair die one
time. Of course, K = {1, . . . , 6} and A = P(K). The mapping P : P(K) â†’[0, 1] is
given by
P(A) = #(A)
6
,
A âŠ†{1, . . . , 6} .
Recall that #(A) denotes the cardinality of the set A.
Remark 1.1.26. Suppose we want to ï¬nd a model for some concrete random experi-
ment. How do we do this? In most cases the sample space is immediately determined
by the results we will expect. If the question about K is settled, the choice of the 3-ï¬eld
depends on the size of the sample space. Is K ï¬nite or countably ï¬nite, then we may
choose A = P(K). If K = R or even Rn, we take the corresponding Borel 3-ï¬elds. The
challenging task is the determination of the probability measure P. Here the following
approaches are possible.
1.
Theoretically considerations lead quite often to the determination of P. For ex-
ample, since the faces of a fair die are all equally likely, this already describes P
completely. Similar arguments can be used for certain games or also for lotteries.
2.
If theoretical considerations are neither possible nor available then statistically
investigations may help. This approach is based on the fact that the relative fre-
quencies rn(A) converge to P(A). Thus, one executes n trials of the experiment and
records the relative frequency of the occurrence of A. For example, one may ques-
tion n randomly chosen persons or one does n independent measurements of the
same item. Then rn(A) may be used to approximate the value of P(A).
3.
Sometimes also subjective or experience-based approaches can be used to ï¬nd
approximative probabilities. These may be erroneous, but maybe they give some
hint for the correct distribution. For example, if a new product is on the market,
the distribution of its lifetime is not yet known. At the beginning one uses data of
an already existing similar product. After some time data about the new product
become available, the probabilities can be determined more accurately.

1.2 Basic Properties of Probability Measures
9
1.2 Basic Properties of Probability Measures
Probability measures obey many useful properties. Let us summarize the most import-
ant ones in the next proposition.
Proposition 1.2.1. Let (K, A, P) be a probability space. Then the following are valid.
(1)
P is also ï¬nitely additive.
(2)
If A, B âˆˆA satisfy A âŠ†B, then P(B\A) = P(B) â€“ P(A).
(3)
We have P(Ac) = 1 â€“ P(A) for A âˆˆA.
(4)
Probability measures are monotone, that is, if A âŠ†B for some A, B âˆˆA, then
P(A) â‰¤P(B).
(5)
Probability measures are subadditive, that is, for all (not necessarily disjoint)
events Aj âˆˆA follows4
P
 âˆ
	
j=1
Aj

â‰¤
âˆ

j=1
P(Aj) .
(1.4)
(6)
Probability measures are continuous from below, that is, whenever Aj âˆˆA satisfy
A1 âŠ†A2 âŠ†â‹…â‹…â‹…, then
P
 âˆ
	
j=1
Aj

= lim
jâ†’âˆP(Aj) .
(7)
In a similar way each probability measure is continuous from above: if Aj âˆˆA
satisfy A1 âŠ‡A2 âŠ‡â‹…â‹…â‹…, then
P
 âˆ

j=1
Aj

= lim
jâ†’âˆP(Aj) .
Proof: To prove (1) choose disjoint A1, . . . , An in A and set An+1 = An+2 = â‹…â‹…â‹…= Ã¸. Then
A1, A2, . . . are inï¬nitely many disjoint events in A, hence the 3-additivity of P implies
P
 âˆ
	
j=1
Aj

=
âˆ

j=1
P(Aj) .
Observe that âˆ
j=1 Aj = n
j=1 Aj and P(Aj) = 0 if j > n, so the previous equation
reduces to
P
 n
	
j=1
Aj

=
n

j=1
P(Aj) ,
and P is ï¬nitely additive.
4 Estimate (1.4) is also known as Booleâ€™s inequality.

10
1 Probabilities
To prove (2) write B = A âˆª(B\A) and observe that this is a disjoint decomposition of B.
Hence, by the ï¬nite additivity of P we obtain
P(B) = P(A) + P(B\A) .
Relocating P(A) to the left-hand side proves (2).
An application of (2) to K and A leads to
P(Ac) = P(K\A) = P(K) â€“ P(A) = 1 â€“ P(A) ,
which proves (3).
The monotonicity is an easy consequence of (2). Indeed,
P(B) â€“ P(A) = P(B\A) â‰¥0
implies P(B) â‰¥P(A).
To prove inequality (1.4) choose arbitrary A1, A2, . . . in A. Set B1 := A1 and, if j â‰¥2,
then
Bj := Aj\(A1 âˆªâ‹…â‹…â‹…âˆªAjâ€“1) .
Then B1, B2, . . . are disjoint subsets in A with âˆ
j=1 Bj = âˆ
j=1 Aj. Furthermore, by the
construction holds Bj âŠ†Aj, hence P(Bj) â‰¤P(Aj). An application of all these properties
yields
P
 âˆ
	
j=1
Aj

= P
 âˆ
	
j=1
Bj

=
âˆ

j=1
P(Bj) â‰¤
âˆ

j=1
P(Aj) .
Thus (5) is proved.
Let us turn now to the continuity from below. Choose A1, A2, . . . in A satisfying
A1 âŠ†A2 âŠ†â‹…â‹…â‹…. With A0 := Ã¸ set
Bk := Ak\Akâ€“1 ,
k = 1, 2, . . .
The Bks are disjoint and, moreover, âˆ
k=1 Bk
= âˆ
j=1 Aj. Furthermore, because of
Akâ€“1 âŠ†Ak from (2) we get P(Bk) = P(Ak) â€“ P(Akâ€“1). When putting this all together, it
follows
P
 âˆ
	
j=1
Aj

= P
 âˆ
	
k=1
Bk

=
âˆ

k=1
P(Bk)
= lim
jâ†’âˆ
j

k=1
P(Bk) = lim
jâ†’âˆ
j

k=1
[P(Ak) â€“ P(Akâ€“1)]
= lim
jâ†’âˆ[P(Aj) â€“ P(A0)] = lim
jâ†’âˆP(Aj)
where we used P(A0) = P(Ã¸) = 0. This proves the continuity from below.

1.2 Basic Properties of Probability Measures
11
Thus it remains to prove (7). To this end choose Aj âˆˆA with A1 âŠ‡A2 âŠ‡â‹…â‹…â‹…. Then
the complementary sets satisfy Ac
1 âŠ†Ac
2 âŠ†â‹…â‹…â‹…. The continuity from below lets us
conclude that
P
 âˆ
	
j=1
Ac
j

= lim
jâ†’âˆP(Ac
j ) = lim
jâ†’âˆ[1 â€“ P(Aj)] = 1 â€“ lim
jâ†’âˆP(Aj) .
(1.5)
But
P
 âˆ
	
j=1
Ac
j

= 1 â€“ P
 âˆ
	
j=1
Ac
j

c
= 1 â€“ P
 âˆ

j=1
Aj

,
and plugging this into eq. (1.5) gives
P
 âˆ

j=1
Aj

= lim
jâ†’âˆP(Aj)
as asserted.
âˆ
Remark 1.2.2. Property (2) becomes false without the assumption A âŠ†B. But since
B\A = B\(A âˆ©B) and A âˆ©B âŠ†B, we always have
P(B\A) = P(B) â€“ P(A âˆ©B) .
(1.6)
Another useful property of probability measures is as follows.
Proposition 1.2.3. Let (K, A, P) be a probability space. Then for all A1, A2 âˆˆA it follows
P(A1 âˆªA2) = P(A1) + P(A2) â€“ P(A1 âˆ©A2) .
(1.7)
Proof: Write the union of the two sets as
A1 âˆªA2 = A1 âˆª[A2\(A1 âˆ©A2)]
and note that the two sets on the right-hand side are disjoint. Because of A1 âˆ©A2 âŠ†A2
property (2) of Proposition 1.2.1 applies and leads to
P(A1 âˆªA2) = P(A1) + P(A2\(A1 âˆ©A2)) = P(A1) + [P(A2) â€“ P(A1 âˆ©A2)] .
This completes the proof.
âˆ

12
1 Probabilities
Given A1, A2, A3 âˆˆA an application of the previous proposition to A1 and A2 âˆªA3
implies
P(A1 âˆªA2 âˆªA3) = P(A1) + P(A2 âˆªA3) â€“ P((A1 âˆ©A2) âˆª(A1 âˆ©A3)) .
Another application of eq. (1.7) to the second and to the third term in the right-hand
sum proves the following result.
Proposition 1.2.4. Let (K, A, P) be a probability space and let A1, A2, and A3 be in A.
Then
P(A1 âˆªA2 âˆªA3) = P(A1) + P(A2) + P(A3)
â€“ [P(A1 âˆ©A2) + P(A1 âˆ©A3) + P(A2 âˆ©A3)] + P(A1 âˆ©A2 âˆ©A3) .
Remark 1.2.5. A generalization of Propositions 1.2.3 and 1.2.4 from 2 or 3 to an arbit-
rary number of sets can be found in Problem 1.5. It is the so-called inclusionâ€“exclusion
formula.
First, let us explain an easy example of how the properties of probability measures
apply.
Example 1.2.6. Let (K, A, P) be a probability space. Suppose two events A and B in A
satisfy
P(A) = 0.5 ,
P(B) = 0.4
and
P(A âˆ©B) = 0.2 .
Which probabilities do A âˆªB, A\B, Ac âˆªBc, and Ac âˆ©B possess?
Answer: An application of Proposition 1.2.4 gives
P(A âˆªB) = P(A) + P(B) â€“ P(A âˆ©B) = 0.4 + 0.5 â€“ 0.2 = 0.7 .
Furthermore, by eq. (1.6) follows
P(A\B) = P(A) â€“ P(A âˆ©B) = 0.5 â€“ 0.2 = 0.3 .
Finally, by De Morganâ€™s rules and another application of eq. (1.6) we get
P(Ac âˆªBc) = 1 â€“ P(A âˆ©B) = 0.8
and
P(Ac âˆ©B) = P(B\A) = P(B) â€“ P(A âˆ©B) = 0.2 .
In summary, say one has to take two exams A and B. The probability of passing exam A
is 0.5, the probability of passing B equals 0.4, and to pass both is 0.2. Then with prob-
ability 0.7 one passes at least one of the exams, with 0.3 exam A, but not B, with 0.8
one fails at least once, and, ï¬nally, the probability to pass B but not A is 0.2.

1.3 Discrete Probability Measures
13
1.3 Discrete Probability Measures
We start with the investigation of ï¬nite sample spaces. They describe random experi-
ments where only ï¬nitely many different results may occur, as, for example, rolling a
die n times, tossing a coin ï¬nitely often, and so on. Suppose the sample space contains
N different elements. Then we may enumerate these elements as follows:
K = {91, . . . , 9N} .
As 3-ï¬eld we choose A = P(K).
Given an arbitrary probability measure P : P(K) â†’R set
pj := P({9j}) ,
j = 1, . . . , N .
(1.8)
In this way we assign to each probability measure P numbers p1, . . . , pN. Which prop-
erties do they possess? The answer to this question gives the following proposition.
Proposition 1.3.1. If P is a probability measure on P(K), then the numbers pj deï¬ned by
eq. (1.8) satisfy
0 â‰¤pj â‰¤1
and
N

j=1
pj = 1 .
(1.9)
Proof: The ï¬rst property is an immediate consequence of P(A) â‰¥0 for all A âŠ†K.
The second property of the pjs follows by
1 = P(K) = P
 N
	
j=1
{9j}

=
N

j=1
P({9j}) =
N

j=1
pj .
âˆ
Conclusion: Each probability measure P generates a sequence (pj)N
j=1 of real numbers
satisfying the properties (1.9). Moreover, if A âŠ†K, then we have
P(A) =

{j:9jâˆˆA}
pj .
(1.10)
In particular, the assignment P â†’(pj)N
j=1 is one-to-one.
Property (1.10) is an easy consequence of A = 
{j:9jâˆˆA}{9j}. Furthermore, it tells us
that P is uniquely determined by the pjs. Note that two probability measures P1 and P2
on (K, A) coincide if P1(A) = P2(A) for all A âˆˆA.
Now let us look at the reverse question. Suppose we are given an arbitrary sequence
(pj)N
j=1 of real numbers satisfying the conditions (1.9).

14
1 Probabilities
Proposition 1.3.2. Deï¬ne P on P(K) by
P(A) =

{j:9jâˆˆA}
pj .
(1.11)
Then P is a probability measure satisfying P({9j}) = pj for all j â‰¤n.
Proof: P has values in [0, 1] and P(K) = 1 by N
j=1 pj = 1. Since the summation over
the empty set equals zero, P(Ã¸) = 0.
Thus it remains to be shown that P is 3-additive. Take disjoint subsets A1, A2, . . .
of K. Since K is ï¬nite, there are at most ï¬nitely many of the Ajs nonempty. Say, for
simplicity, these are the ï¬rst n sets A1, . . . , An. Then we get
P
 âˆ
	
k=1
Ak

= P
 n
	
k=1
Ak

=

{j:9jâˆˆn
k=1 Ak}
pj
=
n

k=1

{j:9jâˆˆAk}
pj =
âˆ

k=1

{j:9jâˆˆAk}
pj =
âˆ

k=1
P(Ak) ,
hence P is 3-additive.
By the construction P({9j}) = pj, which completes the proof.
âˆ
Summary:
If K = {91, . . . , 9N}, then probability measures P on P(K) can be
identiï¬ed with sequences (pj)N
j=1 satisfying conditions (1.9).

Probability measures P on P(K)

â‡â‡’

Sequences (pj)N
j=1 with (1.9)

Hereby the assignment from the left- to the right-hand side goes via pj = P({9j}) while
in the other direction P is given by eq. (1.11).
Example 1.3.3. Assume K = {1, 2, 3}. Then each probability measure P on P(K) is
uniquely determined by the three numbers p1 = P({1}), p2 = P({2}), and p3 = P({3}).
These numbers satisfy p1, p2, p3 â‰¥0 and p1+p2+p3 = 1. Conversely, any three numbers
p1, p2, and p3 with these properties generate a probability measure on P(K) via (1.11).
For example, if A = {1, 3}, then P(A) = p1 + p3.
Next we treat countably inï¬nite sample spaces, that is, K = {91, 92, . . . }. Also
here we may take P(K) as 3-ï¬eld and as in the case of ï¬nite sample spaces, given a
probability measure P on P(K), we set
pj := P({9j}) ,
j = 1, 2, . . .

1.3 Discrete Probability Measures
15
Then (pj)âˆ
j=1 obeys the following properties:
pj â‰¥0
and
âˆ

j=1
pj = 1 .
(1.12)
The proof is the same as in the ï¬nite case. The only difference is that here we have to
use the 3-additivity of P because this time K = âˆ
j=1{9j}. By the same argument follows
for A âŠ†K that
P(A) =

{jâ‰¥1 : 9jâˆˆA}
pj .
Hence, again the pjs determine P completely.
Conversely, let (pj)âˆ
j=1 be an arbitrary sequence of real numbers with proper-
ties (1.12).
Proposition 1.3.4. The mapping P deï¬ned by
P(A) =

{jâ‰¥1 : 9jâˆˆA}
pj .
(1.13)
is a probability measure on P(K) with P({9j}) = pj, 1 â‰¤j < âˆ.
Proof: The proof is analogous to Proposition 1.3.2 with one important exception. In
the case #(K) < âˆwe used that there are at most ï¬nitely many disjoint nonempty
subsets. This is no longer valid. Thus a different argument is needed.
Given disjoint subsets A1, A2, . . . in K set
Ik = {j â‰¥1 : 9j âˆˆAk} .
Then Ik âˆ©Il = Ã¸ if k /= l,
P(Ak) =

jâˆˆIk
pj
and
P
 âˆ
	
k=1
Ak

=

jâˆˆI
pj
where I = âˆ
k=1 Ik.
Since pj â‰¥0, Remark A.5.6 applies and leads to
P
 âˆ
	
k=1
Ak

=

jâˆˆJ
pj =
âˆ

k=1

jâˆˆIk
pj =
âˆ

k=1
P(Ak) .
Thus P is 3-additive.
The equality P({9j}) = pj, 1 â‰¤j < âˆ, is again a direct consequence of the deï¬nition
of P.
âˆ

16
1 Probabilities
Summary: If K = {91, 92, . . . }, then probability measures P on P(K) can be identiï¬ed
with (inï¬nite) sequences (pj)âˆ
j=1 possessing the properties (1.12).

Probability measures P on P(K)

â‡â‡’

Sequences (pj)âˆ
j=1 with (1.12)

Again, the assignment from the left-hand to the right-hand side goes via pj = P({9j})
while the other direction rests upon eq. (1.13).
Example 1.3.5. For K = N and j â‰¥1 let pj = 2â€“j. These pjs satisfy conditions (1.12)
(check this!). The generated probability measure P on P(N) is then given by
P(A) :=

jâˆˆA
1
2j .
For example, if A = {2, 4, 6, . . . } then we get
P(A) =

jâˆˆA
1
2j =
âˆ

k=1
1
22k =
1
1 â€“ 1/4 â€“ 1 = 1
3 .
Example 1.3.6. Let K = Z\{0}, that is, K = {1, â€“1, 2, â€“2, . . . }. With c > 0 speciï¬ed later
on assume
pk = c
k2 ,
k âˆˆK .
The number c > 0 has to be chosen so that the conditions (1.12) are satisï¬ed, hence it
has to satisfy
1 = c

kâˆˆZ\{0}
1
k2 = 2 c
âˆ

k=1
1
k2 .
But as is well known5
âˆ

k=1
1
k2 = 02
6 ,
which implies c =
3
02 . Thus P on P(K) is uniquely described by
P({k}) = 3
02
1
k2 ,
k âˆˆZ\{0} .
5 We refer to [Mor16], where one can ï¬nd an easy proof of this fact. The problem to compute the value
of the sum is known as â€œBasel problem.â€ The ï¬rst solution was found in 1734 by Leonhard Euler. Note
that 
kâ‰¥1 1/k2 = &(2) with Riemannâ€™s &-function.

1.3 Discrete Probability Measures
17
For example, if A = N, then
P(A) = 3
02
âˆ

k=1
1
k2 = 3
02
02
6 = 1
2 .
Or if A = {2, 4, 6, . . . }, it follows
P(A) = 3
02
âˆ

k=1
1
(2k)2 = 1
4 P(N) = 1
8 .
For later purposes we want to combine the two cases of ï¬nite and countably inï¬nite
sample spaces and thereby introduce a slight generalization.
Let K be an arbitrary sample space. A probability measure P is said to be discrete
if there is an at most countably inï¬nite set D âŠ†K (i.e., either D is ï¬nite or countably
inï¬nite) such that P(D) = 1. Then for A âŠ†K follows
P(A) = P(A âˆ©D) =

9âˆˆD
P({9}) .
Since P(Dc) = 0, this says that P is concentrated on D. Of course, all previous results
for ï¬nite or countably inï¬nite sample space carry over to this more general setting.
Discrete probability measures P are concentrated on an at most countably inï¬nite set
D. They are uniquely determined by the values P({9}), where 9 âˆˆD.
Of course, if the sample space is either ï¬nite or countably inï¬nite, then all probab-
ility measures on this space are discrete. Nondiscrete probability measures will be
introduced and investigated in Section 1.5
Example 1.3.7. We once more model the one-time rolling of a die, but now we take as
sample space K = R. Deï¬ne P({9}) = 1
6 if 9 = 1, . . . , 6 and P({9}) = 0 otherwise. If
D = {1, . . . , 6}, then P(D) = 1, hence P is discrete. Given A âŠ†R, it follows
P(A) = #(A âˆ©D)
6
.
For example, we have P([â€“2, 2]) = 1
3 or P([3, âˆ)) = 2
3.

18
1 Probabilities
1.4 Special Discrete Probability Measures
1.4.1 Dirac Measure
The simplest discrete probability measure is the one concentrated at a single point.
That is, there exists an 90 âˆˆK such that P({90}) = 1. This probability measure is
denoted by $90. Consequently, for each A âˆˆP(K) one has
$90(A) =

1 : 90 âˆˆA
0 : 90 âˆ‰A
(1.14)
Deï¬nition 1.4.1. The probability measure $90 deï¬ned by eq. (1.14) is called Dirac
measure or point measure at 90 .
Which random experiment does (K, P(K), $90) model? It describes the experiment
where with probability one the value 90 occurs. Thus, in fact it is a deterministic
experiment, not random.
Dirac measures are useful tools to represent general discrete probability meas-
ures. Assume P is concentrated on D = {91, 92, . . . } and let pj = P({9j}). Then we may
write
P =
âˆ

j=1
pj $9j .
(1.15)
Conversely, if a measure P is represented as in eq. (1.15) with certain 9j âˆˆK and
numbers pj â‰¥0, âˆ
j=1 pj = 1, then P is discrete with P(D) = 1, where D = {91, 92, . . . }.
1.4.2 Uniform Distribution on a Finite Set
The sample space is ï¬nite, say K = {91, . . . , 9N}, and we assume that all elementary
events are equally likely, that is,
P({91}) = â‹…â‹…â‹…= P({9N}) .
A typical example is a fair die, where K = {1, . . . , 6}.
Since 1 = P(K) = N
j=1 P({9j}) we immediately get P({9j}) = 1/N for all j â‰¤N. If
A âŠ†K, an application of eq. (1.11) leads to
P(A) = #(A)
N
= #(A)
#(K) .
(1.16)

1.4 Special Discrete Probability Measures
19
Deï¬nition 1.4.2. The probability measure P deï¬ned by eq. (1.16) is called uniform
distribution or Laplace distribution on the ï¬nite set K.
The following formula may be helpful for remembrance:
P(A) = Number of cases favorable for A
Number of possible cases
Example 1.4.3. In a lottery, 6 numbers are chosen out of 49 and each number appears
only once. What is the probability that the chosen numbers are exactly the six ones on
my lottery coupon?
Answer: Let us give two different approaches to answer this question.
Approach 1: We record the chosen numbers in the order they show up. As a sample
space we may take
K := {(91, . . . , 96) : 9i âˆˆ{1, . . . , 49}, 9i /= 9j if i /= j} .
Then the number of possible cases is
#(K) = 49 â‹…48 â‹…47 â‹…46 â‹…45 â‹…44 = 49!
43! .
Let A be the event that the numbers on my lottery coupon appear. Which cardinality
does A possess?
Say, for simplicity, in our coupon are the numbers 1, 2, . . . , 6. Then it is favorable
for A if these numbers appear in this order. But it is also favorable if (2, 1, 3, . . . , 6)
shows up, that is, any permutation of 1, . . . , 6 is favorable. Hence #(A) = 6! which
leads to6
P(A) =
6!
49 â‹…â‹…â‹…44 =
1
49
6
 = 7.15112 Ã— 10â€“8 .
Approach 2: We assume that the chosen numbers are already ordered by their size (as
they are published in a newspaper). In this case our sample space is
K := {(91, . . . , 96) : 1 â‰¤91 < â‹…â‹…â‹…< 96 â‰¤49}
6 To get an impression about the size of this number assume we buy lottery coupons with all possible
choices of the six numbers. If each coupon is 0.5 mm thick, then all coupons together have a size of
6.992 km, which is about 4.3 miles. And in this row of 4.3 miles there exists exactly one coupon with
the six numbers chosen in the lottery.

20
1 Probabilities
and now
#(K) =
49
6

.
Why? Any set of six different numbers may be written exactly in one way in in-
creasing order and thus, to choose six ordered numbers is exactly the same as to
choose a (nonordered) set of six numbers. And there are
49
6

possibilities to choose
six numbers. In this setting we have #(A) = 1, thus also here we get
P(A) =
1
49
6
 .
Example 1.4.4. A fair coin is labeled with â€œ0â€ and â€œ1.â€ Toss it n times and record the
sequence of 0s and 1s in the order of their appearance. Thus,
K := {0, 1}n = {(91, . . . , 9n) : 9i âˆˆ{0, 1}} ,
and #(K) = 2n. The coin is assumed to be fair, hence each sequence of 0s and 1s is
equally likely. Therefore, whenever A âŠ†K, then
P(A) = #(A)
2n
.
Take, for example, the event A where for some ï¬xed i â‰¤n the ith toss equals â€œ0,â€
that is,
A = {(91, . . . , 9n) : 9i = 0} ,
Then #(A) = 2nâ€“1 leads to the (not surprising) result
P(A) = 2nâ€“1
2n
= 1
2 .
Or let A occur if we observe for some given k â‰¤n exactly k times the number â€œ1.â€ Then
#(A) =
n
k

and we get
P(A) =
n
k

â‹…1
2n .
Example 1.4.5. We have k particles that we distribute randomly into n boxes. All pos-
sible distributions of the particles are assumed to be equally likely. How do we get P(A)
for a given event A ?
Answer: In this formulation the question is not asked correctly because we did not
ï¬x when two distributions of particles coincide.

1.4 Special Discrete Probability Measures
21
Let us illustrate this problem in the case of two particles and two boxes. If the
particles are not distinguishable (anonymous) then there are three different ways
to distribute the particles into the two boxes. Thus, assuming that all distributions are
equally likely, each elementary event has probability 1/3.
On the other hand, if the particles are distinguishable, that is, they carry names,
then there exist four different ways of distributing them (check this!), hence each
elementary event has probability 1/4.
Let us answer the above question in the two cases (distinguishable and anonym-
ous) separately.
Distinguishable particles: Here we may enumerate the particles from 1 to k and
each distribution of particles is uniquely described by a sequence (a1, . . . , ak), where
aj âˆˆ{1, . . . , n}. For example, a1 = 3 means that particle one is in box 3. Hence, a
suitable sample space is
K = {(a1, . . . , ak) : 1 â‰¤ai â‰¤n} .
Since #(K) = nk for events A âŠ†K follows
P(A) = #(A)
nk
.
Anonymous particles: We record how many of the k particles are in box 1, how many
are in box 2 up to box n. Thus as sample space we may choose
K = {(k1, . . . , kn) : kj = 0 , . . . , k , k1 + â‹…â‹…â‹…+ kn = k} .
The sequence (k1, . . . , kn) occurs if box 1 contains k1 particles, box 2 contains k2, and
so on. From the results in case 3 of Section A.3.2 we derive
#(K) =
n + k â€“ 1
k

.
Hence, if A âŠ†K, then
P(A) = #(A)
#(K) = #(A) k! (n â€“ 1)!
(n + k â€“ 1)!
Summary: If we distribute k particles and assume that all partitions are equally
likely7, then in the case of distinguishable or of anonymous particles
P(A) = #(A)
nk
or
P(A) = #(A) k! (n â€“ 1)!
(n + k â€“ 1)!,
respectively.
7 Compare Example 1.4.16 and the following remark.

22
1 Probabilities
Let us evaluate P(A) for some concrete event A in both cases. Suppose k â‰¤n and select
k of the n boxes. Set
A := {In each of the chosen k boxes is exactly one particle}.
(1.17)
To simplify the notation assume that the ï¬rst k boxes have been chosen. The general
case is treated in a similar way. Then in the â€œdistinguishable caseâ€ the event A oc-
curs if and only if for some permutation 0 âˆˆSk the sequence (0(1), . . . , 0(k), 0 . . . , 0)
appears. Thus #(A) = k! and
P(A) = k!
nk .
(1.18)
In the â€œanonymous caseâ€ it follows #(A) = 1 (why?). Hence here we obtain
P(A) = k! (n â€“ 1)!
(n + k â€“ 1)! .
(1.19)
Additional question: For k â‰¤n deï¬ne B by
B := {Each of the n boxes contains at most 1 particle}
Find P(B) in both cases.
Answer: The event B is the (disjoint) union of the following events: the k particles
are distributed in a given collection of k boxes. The probability of this event was cal-
culated in eqs. (1.18) and (1.19), respectively. Since there are
n
k

possibilities to choose
k boxes of the n we get P(B) =
n
k

P(A) with A as deï¬ned by (1.17), that is,
P(B) =
n
k

â‹…k!
nk =
n!
(n â€“ k)! nk
and
P(B) =
n
k

â‹…k! (n â€“ 1)!
(n + k â€“ 1)! =
n! (n â€“ 1)!
(n â€“ k)! (n + k â€“ 1)!,
respectively.
1.4.3 Binomial Distribution
The sample space is K = {0, 1, . . . , n} for some n â‰¥1 and p is a real number with
0 â‰¤p â‰¤1.
Proposition 1.4.6. There exists a unique probability measure Bn,p on P(K) satisfying
Bn,p({k}) =
n
k

pk(1 â€“ p)nâ€“k ,
k = 0, . . . , n .
(1.20)

1.4 Special Discrete Probability Measures
23
Proof: In order to use Proposition 1.3.2 we have to verify Bn,p({k})
â‰¥
0 and
n
k=0 Bn,p({k}) = 1. The ï¬rst property is obvious because of 0 â‰¤p â‰¤1 and 0 â‰¤1 â€“ p â‰¤1.
To prove the second one we apply the binomial theorem (Proposition A.3.7) with a = p
and with b = 1 â€“ p. This leads to
n

k=0
Bn,p({k}) =
n

k=0
n
k

pk(1 â€“ p)nâ€“k = (p + (1 â€“ p))n = 1 .
Hence the assertion follows by Proposition 1.3.2 with pk = Bn,p({k}), k = 0, . . . , n.
âˆ
Deï¬nition 1.4.7. The probability measure Bn,p deï¬ned by eq. (1.20) is called
binomial distribution with parameters n and p.
Remark 1.4.8. Observe that Bn,p acts as follows. If A âŠ†{0, . . . , n}, then
Bn,p(A) =

kâˆˆA
n
k

pk(1 â€“ p)nâ€“k .
Furthermore, for p = 1/2 we get
Bn,1/2({k}) =
n
k
 1
2n .
As we saw in Example 1.4.4 this probability describes the k-fold occurrence of â€œ1â€ when
tossing a fair coin n times.
Which random experiment describes the binomial distribution? To answer this ques-
tion let us ï¬rst look at the case n = 1. Here we have K = {0, 1} with
Bn,p({0}) = 1 â€“ p
and
Bn,p({1}) = p .
If we identify â€œ0â€ with failure and â€œ1â€ with success, then the binomial distribution
describes an experiment where either success or failure may occur, and the success
probability is p. Now we execute the same experiment n times and every time we may
observe either failure or success. If we have k times success, then there are
n
k

ways
to obtain these k successes during the n trials. The probability for success is p and for
failure 1 â€“ p. By the independence of the single trials, the probability for the sequence
is pk(1 â€“ p)nâ€“k. By multiplying this probability with the number of different positions
of successes we ï¬nally arrive at
n
k

pk(1 â€“ p)nâ€“k, the value of Bn,p({k}).
Summary: The binomial distribution describes the following experiment. We execute
n times independently the same experiment where each time either success or failure

24
1 Probabilities
may appear. The success probability is p. Then Bn,p({k}) is the probability to observe
exactly k times success or, equivalently, n â€“ k times failure.
Example 1.4.9. An exam consists of 100 problems where each of the question may be
answered either with â€œyesâ€ or â€œno.â€ To pass the exam at least 60 questions have to be
answered correctly. Let p be the probability to answer a single question correctly. How
big has p to be in order to pass the exam with a probability greater than 75% ?
Answer: The number p has to be chosen such that the following estimate is
satisï¬ed:
100

k=60
100
k

pk(1 â€“ p)100â€“k â‰¥0.75 .
Numerical calculations show that this is valid if and only if p â‰¥0.62739.
Example 1.4.10. In an auditorium there are N students. Find the probability that at
least two of them have their birthday on April 1.
Answer: We do not take leap years into account and assume that there are no twins
among the students. Finally, we make the (probably unrealistic) assumption that all
days of a year are equally likely as birthdays. Say success occurs if a student has birth-
day on April 1. Under the above assumptions the success probability is 1/365. Hence
the number of students having birthday on April 1 is binomially distributed with para-
meters N and p = 1/365. We ask for the probability of A = {2, 3, . . . , N}. This may be
evaluated by
N

k=2
N
k
  1
365
k 364
365
Nâ€“k
= 1 â€“ BN,1/365({0}) â€“ BN,1/365({1})
= 1 â€“
364
365
N
â€“ N
365
364
365
Nâ€“1
.
For example, N = 500 this probability is approximately 0.397895.
1.4.4 Multinomial Distribution
Given natural numbers n and m, the sample space for the multinomial distribution is8
K := {(k1, . . . , km) âˆˆNm
0 : k1 + â‹…â‹…â‹…+ km = n} .
With certain non-negative real numbers p1, . . . , pm satisfying p1 + â‹…â‹…â‹…+ pm = 1 set
P({(k1, . . . , km)}) :=

n
k1, . . . , km

pk1
1
â‹…â‹…â‹…pkm
m ,
(k1, . . . , km) âˆˆK .
(1.21)
8 By case 3 in Section A.3.2 the cardinality of K is
n+mâ€“1
n

.

1.4 Special Discrete Probability Measures
25
Recall that the multinomial coefï¬cients appearing in eq. (1.21) were deï¬ned in
eq. (A.15) as

n
k1, . . . , km

=
n!
k1! â‹…â‹…â‹…km! .
The next result shows that eq. (1.21) deï¬nes a probability measure.
Proposition 1.4.11. There is a unique probability measure P on P(K) such that (1.21)
holds for all (k1, . . . , km) âˆˆK.
Proof: An application of the multinomial theorem (Proposition A.3.18) implies

(k1, ... ,km)âˆˆK
P({(k1, . . . , km)}) =

k1+ â‹…â‹…â‹…+km=n
kiâ‰¥0

n
k1, . . . , km

pk1
1
â‹…â‹…â‹…pkm
m
= (p1 + â‹…â‹…â‹…+ pm)n = 1n = 1 .
Since P({(k1, . . . , km)}) â‰¥0 the assertion follows by Proposition 1.3.2.
âˆ
In view of the preceding proposition, the following deï¬nition is justiï¬ed.
Deï¬nition 1.4.12. The probability measure P deï¬ned by eq. (1.21) is called multi-
nomial distribution with parameters n, m, and p1, . . . , pm.
Remark 1.4.13. Sometimes it is useful to regard the multinomial distribution on the
larger sample space K = Nm
0 . In this case we have to modify eq. (1.21) slightly as
follows:
P({(k1, . . . , km)}) =
 
n
k1, ... ,km

pk1
1
â‹…â‹…â‹…pkm
m : k1 + â‹…â‹…â‹…+ km = n
0
: k1 + â‹…â‹…â‹…+ km /= n
Which random experiment does the multinomial distribution describe? To answer this
question let us recall the model for the binomial distribution. In an urn are balls of two
different colors, say white and red. The proportion of the white balls is p, hence 1 â€“ p
of the red ones. If we choose n balls with replacement, then Bn,p({k}) is the probability
to observe exactly k white balls.
What happens if in the urn are balls of more than two different colors, say of m
ones, and the proportions of the colored balls are p1, . . . , pm with p1 + â‹…â‹…â‹…+ pm = 1?
As in the model for the binomial distribution we choose n balls with replacement.
Given integers kj â‰¥0 one asks now for the probability of the following event: balls
of color 1 showed up k1 times, those of color 2 k2 times, and so on. Of course, this

26
1 Probabilities
probability is zero whenever k1+ â‹…â‹…â‹…+km /= n. But if the sum is n, then pk1
1 â‹…â‹…â‹…pkm
m is the
probability for kj balls of color j in some ï¬xed order. There are

n
k1, ... ,km

ways to order
the balls without changing the frequency of the colors. Thus the desired probability
equals

n
k1, ... ,km

pk1
1
â‹…â‹…â‹…pkm
m .
Summary: Suppose in an experiment are m different results possible (e.g., m colors)
and assume that each time the jth result occurs with probability pj. If we execute the
experiment n times, then the multinomial distribution describes the probability of the
following event: the ï¬rst result occurs k1 times, the second k2 times, and so on.
Remark 1.4.14. If m = 2, then p2 = 1 â€“ p1 as well as

n
k1,k2

=

n
k1,nâ€“k1

=
 n
k1

.
Consequently, in this case the multinomial distribution coincides with the binomial
distribution Bn,p1.
Remark 1.4.15. Suppose that all m possible different outcomes of the experiment are
equally likely, that is, we have
p1 = â‹…â‹…â‹…= pm = 1
m .
Under this assumption it follows
P({(k1, . . . , km)}) =

n
k1, . . . , km
 1
mn ,
k1 + â‹…â‹…â‹…+ km = n .
(1.22)
Example 1.4.16. Suppose we have m boxes B1, . . . , Bm and n particles that we place
successively into these boxes. Thereby pj is the probability to place a single particle
into box Bj. What is the probability that after distributing all n particles there are k1
particles in the ï¬rst box, k2 in the second up to km in the last one?
Answer: This probability is given by formula (1.21), that is,
P{k1 particles are in B1, . . . , km particles are in Bm} =

n
k1, . . . , km

pk1
1
â‹…â‹…â‹…pkm
m .
Suppose now n â‰¤m and that all boxes are chosen with probability 1/m. Find the
probability that each of the ï¬rst n boxes B1, . . . , Bn contains exactly one particle.
Answer: By eq. (1.22) follows
P({(1, . . . , 1
  
n
, 0 . . . , 0)}) =

n
1, . . . , 1
  
n
, 0, . . . , 0
 1
mn = n!
mn .
(1.23)
Remark 1.4.17. From a different point of view we investigated the last problem already
in Example 1.4.5. But why do we get in eq. (1.23) the same answer as in the case of
distinguishable particles although the n distributed ones are anonymous?

1.4 Special Discrete Probability Measures
27
Answer: The crucial point is that we assumed in the anonymous case that all par-
titions of the particles are equally likely. And this is not valid when distributing the
particles successively. To see this, assume n = m = 2. Then there exist three different
ways to distribute the particles, but they have different probabilities.
P({(0, 2)}) = P({(2, 0)}) = 1
4
while
P({(1, 1)}) = 1
2 .
Thus, although the distributed particles are not distinguishable, they get names due
to the successive distribution (ï¬rst particle, second particle, etc.).
Example 1.4.18. Six people randomly enter a train with three coaches. Each person
chooses his wagon independently of the others and all coaches are equally likely to be
chosen. Find the probability that there are two people in each coach.
Answer: We have m = 3, n = 6, and p1 = p2 = p3 = 1
3. Hence the probability we are
looking for is
P({(2, 2, 2)}) =

6
2, 2, 2
 1
36 =
6!
2! 2! 2!
1
36 = 10
81 = 0.12345679 .
Example 1.4.19. In a country are 40% of the cars gray, 20% are black, and 10% are red.
The remaining cars have different colors. Now we observe by random 10 cars. What is
the probability to see two gray cars, four black, and one red?
Answer: By assumption m = 4 (gray, black, red, and others), p1 = 2/5, p2 = 1/5,
p3 = 1/10, and p4 = 3/10. Thus the probability of the vector (2, 4, 1, 3) is given by

10
2, 4, 1, 3
 2
5
2  1
5
4  1
10
1  3
10
3
=
10!
2! 4! 1! 3! â‹…22
52 â‹…1
54 â‹…1
10 â‹…33
103
= 0.00870912 .
1.4.5 Poisson Distribution
The sample space for this distribution is N0 = {0, 1, 2, . . . }. Furthermore, + > 0 is a
given parameter.
Proposition 1.4.20. There exists a unique probability measure Pois+ on P(N0) such that
Pois+({k}) = +k
k! eâ€“+ ,
k âˆˆN0 .
(1.24)
Proof: Because of eâ€“+ > 0 follows Pois+({k}) > 0. Thus it sufï¬ces to verify
âˆ

k=0
+k
k! eâ€“+ = 1 .

28
1 Probabilities
But this is a direct consequence of
âˆ

k=0
+k
k! eâ€“+ = eâ€“+
âˆ

k=0
+k
k! = eâ€“+ e+ = 1 .
âˆ
Deï¬nition 1.4.21. The probability measure Pois+ on P(N0) satisfying eq. (1.24) is
called Poisson distribution with parameter + > 0.
The Poisson distribution describes experiments where the number of trials is big, but
the single success probability is small. More precisely, the following limit theorem
holds.
Proposition 1.4.22 (Poissonâ€™s limit theorem). Let (pn)âˆ
n=1 be a sequence of numbers
with 0 < pn â‰¤1 and
lim
nâ†’âˆn pn = +
for some + > 0. Then for all k âˆˆN0 follows
lim
nâ†’âˆBn,pn({k}) = Pois+({k}) .
Proof: Write
Bn,pn({k}) =
n
k

p k
n (1 â€“ pn)nâ€“k
= 1
k!
n (n â€“ 1) â‹…â‹…â‹…(n â€“ k + 1)
nk
(n pn)k (1 â€“ pn)n (1 â€“ pn)â€“k
= 1
k!
 n
n â‹…n â€“ 1
n
â‹…â‹…â‹…n â€“ k + 1
n

(n pn)k (1 â€“ pn)n (1 â€“ pn)â€“k ,
and investigate the behavior of the different parts of the last equation separately. Each
of the fractions in the bracket tends to 1, hence the whole bracket tends to 1. By as-
sumption we have n pn â†’+, thus, limnâ†’âˆ(n pn)k = +k. Moreover, since n pn â†’+ with
+ > 0 we get pn â†’0, which implies limnâ†’âˆ(1 â€“ pn)â€“k = 1.
Thus, it remains to determine the behavior of (1 â€“ pn)n as n â†’âˆ. Proposition A.5.1
asserts that if a sequence of real numbers (xn)nâ‰¥1 converges to x âˆˆR, then
lim
nâ†’âˆ

1 + xn
n

n
= ex .

1.4 Special Discrete Probability Measures
29
Setting xn := â€“n pn by assumption xn â†’â€“+, hence
lim
nâ†’âˆ(1 â€“ pn)n = lim
nâ†’âˆ

1 + xn
n

n
= eâ€“+ .
If we combine all the different parts, then this completes the proof by
lim
nâ†’âˆBn,pn({k}) = 1
k! +k eâ€“+ = Pois+({k}) .
âˆ
The previous theorem allows two conclusions.
(1)
Whenever n is large and p is small, without hesitation one may replace Bn,p by
Pois+, where + = n p. In this way one avoids the (sometimes) difï¬cult evaluation
of the binomial coefï¬cients.
Example 1.4.23. In Example 1.4.10 we found the probability that among N students
there are at least two having their birthday on April 1. We then used the binomial distri-
bution with parameters N and p = 1/365. Hence the approximating Poisson distribution
has parameter + = N/365 and the corresponding probability is given by
Pois+({2, 3, . . . }) = 1 â€“ (1 + +)eâ€“+ = 1 â€“

1 + N
365

eâ€“N/365 .
If again N = 500, hence + = 500/365, the approximative probability equals 0.397719.
Compare this value with the â€œpreciseâ€ probability 0.397895 obtained in Example
1.4.10.
(2)
Poissonâ€™s limit theorem explains why the Poisson distribution describes experi-
ments with many trials and small success probability. For example, if we look for
a model for the number of car accidents per year, then the Poisson distribution
is a good choice. There are many cars, but the probability9 that a single driver is
involved in an accident is quite small.
Later on we will investigate other examples where the Poisson distribution appears in
a natural way.
1.4.6 Hypergeometric Distribution
Among N delivered machines are M defective. One chooses n of the N machines ran-
domly and checks them. What is the probability to observe m defective machines in
the sample of size n?
9 To call it â€œsuccessâ€ probability in this case is perhaps not quite appropriate.

30
1 Probabilities
First note that there are
N
n

ways to choose n machines for checking. In order to
observe m defective ones these have to be taken from the M defective. The remaining
n â€“ m machines are nondefective, hence they must be chosen from the N â€“ M nonde-
fective ones. There are
M
m

ways to take the defective machines and
Nâ€“M
nâ€“m

possibilities
for the nondefective ones.
Thus the following approach describes this experiment:
HN,M,n({m}) :=
M
m
 Nâ€“M
nâ€“m

N
n

,
0 â‰¤m â‰¤n .
(1.25)
Recall that in Section A.3.1 we agreed that
n
k

= 0 whenever k > n. This turns out
be useful in the deï¬nition of HN,M,n. For example, if m > M, then the probability to
observe m defective machines is of course zero.
We want to prove now that eq. (1.25) deï¬nes a probability measure.
Proposition 1.4.24. There exists a unique probability measure HN,M,n on the powerset
of {0, . . . , n} satisfying eq. (1.25).
Proof: Vandermondeâ€™s identity (cf. Proposition A.3.8) asserts that for all k, m, and n
in N0
k

j=0
n
j
 m
k â€“ j

=
n + m
k

.
(1.26)
Now replace n by M, next m by N â€“ M, then k by n, and, ï¬nally, j by m. Doing so
eq. (1.26) leads to
n

m=0
M
m
N â€“ M
n â€“ m

=
N
n

.
But this implies
n

m=0
HN,M,n({m}) =
1
N
n
 â‹…
n

m=0
M
m
N â€“ M
n â€“ m

=
1
N
n
 â‹…
N
n

= 1 .
Clearly, HN,M,n({m} â‰¥0, which completes the proof by virtue of Proposition 1.41.
âˆ
Deï¬nition 1.4.25. The probability measure HN,M,n deï¬ned by eq. (1.25) is called
hypergeometric distribution with parameters N, M, and n.

1.4 Special Discrete Probability Measures
31
Example 1.4.26. A retailer gets a delivery of 100 machines; 10 of them are defective.
He chooses by random eight machines and tests them. Find the probability that two
or more of the tested machines are defective.
Answer: The desired probability is
8

m=2
10
m
 90
8â€“m

100
8

= 0.18195 .
Remark 1.4.27. In the daily practice the reversed question is more important. The size
N of the delivery is known and, of course, also the size of the tested sample. The
number M of defective machines is unknown. Now suppose we observed m defective
machines among the n tested. Does this (random) number m lead to some information
about the number M of defective machines in the delivery? We will investigate this
problem in Proposition 8.5.15.
Example 1.4.28. In a pond are 200 ï¬sh. One day the owner of the pond catches 20 ï¬sh,
marks them, and puts them back into the pond. After a while the owner catches once
more 20 ï¬sh. Find the probability that among these ï¬sh there is exactly one marked.
Answer: We have N = 200, M = 20, and n = 20. Hence the desired probability is
H200,20,20({1}) =
20
1
180
19

200
20

= 0.26967 .
Remark 1.4.29. The previous example is not very realistic because in general the
number N of ï¬sh is unknown. Known are M and n, the (random) number m was ob-
served. Also here one may ask whether the knowledge of m leads to some information
about N. This question will be investigated later in Proposition 8.5.17.
Example 1.4.30. In a lottery 6 numbers are chosen randomly out of 49. Suppose we
bought a lottery coupon with six numbers. What is the probability that exactly k, k =
0, . . . , 6, of our numbers appear in the drawing?
Answer: There are n = 6 numbers randomly chosen out of N = 49. Among the
49 numbers are M = 6 â€œdefective.â€ These are the six numbers on our coupon, and we
ask for the probability that k of the â€œdefectiveâ€ are among the chosen six. The question
is answered by the hypergeometric distribution H49,6,6, that is, the probability of k
correct numbers on our coupon is given by
H49,6,6({k}) =
6
k
 43
6â€“k

49
6

,
k = 0, . . . , 6 .
The numerical values of these probabilities for k = 0, . . . , 6 are

32
1 Probabilities
k
Probability
0
0.435965
1
0.413019
2
0.132378
3
0.0176504
4
0.00096862
5
0.0000184499
6
7.15112 â‹…10â€“8
Remark 1.4.31. Another model for the hypergeometric distribution is as follows: in an
urn are N balls, M of them are white, the remaining N â€“ M are red. Choose n balls out
of the urn without replacing the chosen ones. Then HN,M,n({m}) is the probability to
observe m white balls among the n chosen.
If we do the same experiment, but now replacing the chosen balls, then this is
described by the binomial distribution. The success probability for a white ball is p =
M/N, hence now the probability for m white balls is given by
Bn,M/N({m}) =
n
m
 M
N
m 
1 â€“ M
N
nâ€“m
.
It is intuitively clear that for large N and M (and comparable small n) the difference
between both models (replacing and nonreplacing) is insigniï¬cant. Imagine there are
106 white and also 106 red balls in an urn. Choosing two balls it does not matter a lot
whether the ï¬rst ball was replaced or not.
The next proposition makes the previous observation more precise.
Proposition 1.4.32. If 0 â‰¤m â‰¤n and 0 â‰¤p â‰¤1, then follows
lim
N,Mâ†’âˆ
M/Nâ†’p
HN,M,n({m}) = Bn,p({m}) .
Proof: Suppose ï¬rst 0 < p < 1. Then the deï¬nition of the hypergeometric distribution
yields
lim
N,Mâ†’âˆ
M/Nâ†’p
HN,M,n({m}) =
lim
N,Mâ†’âˆ
M/Nâ†’p
M â‹…â‹…â‹…(Mâ€“m+1)
m!
(Nâ€“M) â‹…â‹…â‹…(Nâ€“Mâ€“(nâ€“m)+1)
(nâ€“m)!
N(Nâ€“1) â‹…â‹…â‹…(Nâ€“n+1)
n!
=
lim
N,Mâ†’âˆ
M/Nâ†’p
n
m

M
N â‹…â‹…â‹…( Mâ€“m+1
N
)
 
(1 â€“ M
N ) â‹…â‹…â‹…(1 â€“ Mâ€“(nâ€“m)+1
N
)

(1 â€“ 1
N ) â‹…â‹…â‹…(1 â€“ n+1
N )
(1.27)
=
n
m

pm(1 â€“ p)nâ€“m = Bn,p({m}) .

1.4 Special Discrete Probability Measures
33
Note that if either m = 0 or m = n, then the ï¬rst or the second bracket in eq. (1.27)
become 1, thus they do not appear.
The cases p = 0 and p = 1 have to be treated separately. For example, if p = 0, the
fraction in eq. (1.27) converges to zero provided that m â‰¥1. If m = 0, then
lim
N,Mâ†’âˆ
M/Nâ†’0
(1 â€“ M
N ) â‹…â‹…â‹…(1 â€“ Mâ€“n+1
N
)
(1 â€“ 1
N ) â‹…â‹…â‹…(1 â€“ n+1
N )
= 1 = Bn,0({0}) .
The case p = 1 is treated similarly. Hence, the proposition is also valid in the border
cases.
âˆ
Example 1.4.33. Suppose there are N = 200 balls in an urn, M = 80 of them are white.
Choosing n = 10 balls with or without replacement we get the following numerical
values. Note that p = M/N = 2/5.
m
HN,M,n({m})
Bn,p({m})
1
0.0372601
0.0403108
2
0.118268
0.120932
3
0.217696
0.214991
4
0.257321
0.250823
5
0.204067
0.200658
6
0.10995
0.111477
7
0.0397376
0.0424673
8
0.00921879
0.0106168
9
0.0012395
0.00157286
1.4.7 Geometric Distribution
At a ï¬rst glance the model for the geometric distribution looks as that for the binomial
distribution. In each single trial we may observe â€œ0â€ or â€œ1,â€ that is, failure or success.
Again the success probability is a ï¬xed number p. While in the case of the binomial
distribution, we executed a ï¬xed number of trials, now this number is random. More
precisely, we execute the experiment until we observe success for the ï¬rst time. Re-
corded is the number of necessary trials until this ï¬rst success shows up. Or, in other
words, a number k â‰¥1 occurs if and only if the ï¬rst k â€“ 1 trials were all failures and the
kth one success, that is, we observe the sequence (0, . . . , 0



kâ€“1
, 1). Since failure appears
with probability 1â€“p and success shows up with probability p, the following approach
is plausible:
Gp({k}) := p (1 â€“ p)kâ€“1 ,
k âˆˆN .
(1.28)
Proposition 1.4.34. If 0 < p < 1, then (1.28) deï¬nes a probability measure on P(N).

34
1 Probabilities
Proof: Because of p (1 â€“ p)kâ€“1 > 0 it sufï¬ces to verify âˆ
k=1 Gp({k}) = 1. Using the
formula for the sum of a geometric series this follows directly by
âˆ

k=1
p (1 â€“ p)kâ€“1 = p
âˆ

k=0
(1 â€“ p)k = p
1
1 â€“ (1 â€“ p) = 1 .
Observe that by assumption 1 â€“ p < 1, thus the formula for geometric series applies. âˆ
Deï¬nition 1.4.35. The probability measure Gp on P(N) deï¬ned by eq. (1.28) is
called geometric distribution with parameter p.
If p = 0, then success will never show up, thus, Gp is not a probability measure. On
the other hand, for p = 1, success appears with probability one in the ï¬rst trial, that is,
Gp = $1. Therefore, this case is of no interest.
Example 1.4.36. Given a number n âˆˆN, let An = {k âˆˆN : k > n}. Find Gp(An).
Answer: We answer this question by two different approaches.
At ï¬rst we remark that An occurs if and only if the ï¬rst occurrence of success shows
up strictly after n trials or, equivalently, if and only if the ï¬rst n trials were all failures.
But this event has probability Bn,p({0}) = (1 â€“ p)n, hence Gp(An) = (1 â€“ p)n.
In the second approach we use eq. (1.28) directly and obtain
Gp(An) =
âˆ

k=n+1
Gp({k}) = p
âˆ

k=n+1
(1 â€“ p)kâ€“1 = p (1 â€“ p)n
âˆ

k=0
(1 â€“ p)k
= p (1 â€“ p)n
1
1 â€“ (1 â€“ p) = (1 â€“ p)n .
Example 1.4.37. Roll a die until number â€œ6â€ occurs for the ï¬rst time. What is the
probability that this happens in roll k?
Answer: The success probability is 1/6, hence the probability of ï¬rst occurrence of
â€œ6â€ in the kth trial is (1/6)(5/6)kâ€“1.
k
Probability
1
0.166667
2
0.138889
3
0.115741
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
12
0.022431
13
0.018693

1.4 Special Discrete Probability Measures
35
Example 1.4.38. Roll a die until the ï¬rst â€œ6â€ shows up. What is the probability that
this happens at an even number of trials?
Answer: The ï¬rst â€œ6â€ has to appear in the second or fourth or sixth, and so on,
trial. Hence, the probability of this event is
âˆ

k=1
G1/6({2k}) = 1
6
âˆ

k=1
(5/6)2kâ€“1 = 5
36
âˆ

k=1
(5/6)2kâ€“2 = 5
36
1
1 â€“ (5/6)2 = 5
11 .
Example 1.4.39. Play a series of games where p is the chance of winning. Whenever
you put M dollars into the pool you get back 2M dollars if you win. If you lose, then
the M dollars are lost.
Apply the following strategy. After losing double the amount in the pool in the
next game. Say you start with $1 and lose, then next time put $2 into the pool, then
$4, and so on until you win for the ï¬rst time. As easily seen, in the kth game the stakes
is 2kâ€“1 dollars.
Suppose for some k â‰¥1 you lost k â€“ 1 games and won the kth one. How much
money did you lose? If k = 1, then you lost nothing, while for k â‰¥2 you spent
1 + 2 + 4 + â‹…â‹…â‹…+ 2kâ€“2 = 2kâ€“1 â€“ 1
dollars. Note that 2kâ€“1 â€“ 1 = 0 if k = 1, hence for all k â‰¥1 the total lost is 2kâ€“1 â€“ 1 dollars.
On the other hand, if you win the kth game, you gain 2kâ€“1 dollars. Consequently,
no matter what the results are, you will always win 2kâ€“1 â€“ (2kâ€“1 â€“ 1) = 1 dollars10.
Let X(k) be the amount of money needed in the case that one wins for the ï¬rst time
in the kth game. One needs 1 dollar to play the ï¬rst game, 1 + 2 = 3 dollars to play the
second, until
1 + 2 + 4 + â‹…â‹…â‹…+ 2kâ€“1 = 2k â€“ 1
to play the kth game. Thus, X(k) = 2k â€“ 1 and
P{X = 2k â€“ 1} = P{First win in game k} = p(1 â€“ p)kâ€“1 ,
k = 1, 2 . . . .
In particular, if p = 1/2 then this probability equals 2â€“k. For example, if one starts the
game with 127 = 27 â€“ 1 dollars in the pocket, then one goes bankrupt if the ï¬rst success
appears after game 7. The probability for this equals âˆ
k=8 2â€“k = 2â€“7 = 0.0078125.
1.4.8 Negative Binomial Distribution
The geometric distribution describes the probability for having the ï¬rst success in
trial k. Given a ï¬xed n â‰¥1 we ask now for the probability that in trial k success appears
10 Starting the ï¬rst game with x dollars one will always win x dollars no matter what happens.

36
1 Probabilities
not for the ï¬rst but for the nth time. Of course, this question makes only sense if k â‰¥n.
But how to determine this probability for those k?
Thus, take k â‰¥n and suppose we had success in trial k. When is this the nth one?
This is the case if and only if we had n â€“ 1 times success during the ï¬rst k â€“ 1 trials or,
equivalently, k â€“ n failures. There exist
kâ€“1
kâ€“n

possibilities to distribute the k â€“ n failures
among the ï¬rst k â€“ 1 trials. Furthermore, the probability for n times success is pn and
for k â€“ n failures it is (1 â€“ p)kâ€“n, hence the probability for observing the nth success in
trial k is given by
Bâ€“
n,p({k}) :=
k â€“ 1
k â€“ n

pn (1 â€“ p)kâ€“n ,
k = n, n + 1, . . . .
(1.29)
We still have to verify that there is a probability measure satisfying eq. (1.29).
Proposition 1.4.40. By
Bâ€“
n,p({k}) =
k â€“ 1
k â€“ n

pn (1 â€“ p)kâ€“n ,
k = n, n + 1, . . . ,
a probability measure Bâ€“
n,p on P({n, n + 1, . . . }) is deï¬ned.
Proof: Of course, Bâ€“
n,p({k}) â‰¥0. Hence it remains to show
âˆ

k=n
Bâ€“
n,p({k}) = 1
or, equivalently,
âˆ

k=0
Bâ€“
n,p({k + n}) = 1 .
(1.30)
Because of Lemma A.3.9 we get
Bâ€“
n,p({k + n}) =
n + k â€“ 1
k

pn (1 â€“ p)k
=
â€“n
k

pn (â€“1)k (1 â€“ p)k =
â€“n
k

pn (p â€“ 1)k ,
(1.31)
where the generalized binomial coefï¬cient is deï¬ned in eq. (A.13) as
â€“n
k

= â€“n(â€“n â€“ 1) â‹…â‹…â‹…(â€“n â€“ k + 1)
k!
.
In Proposition A.5.2 we proved for |x| < 1
âˆ

k=0
â€“n
k

xk =
1
(1 + x)n .
(1.32)

1.4 Special Discrete Probability Measures
37
Note that 0 < p < 1, hence eq. (1.32) applies with x = p â€“ 1 and leads to
âˆ

k=0
â€“n
k

(p â€“ 1)k = 1
pn .
(1.33)
Combining eqs. (1.31) and (1.33) implies
âˆ

k=0
Bâ€“
n,p({k + n}) = pn
âˆ

k=0
â€“n
k

(p â€“ 1)k = pn 1
pn = 1 ,
thus the equations in (1.30) are valid and this completes the proof.
âˆ
Deï¬nition 1.4.41. The probability measure Bâ€“
n,p with
Bâ€“
n,p({k}) :=
k â€“ 1
k â€“ n

pn (1 â€“ p)kâ€“n =
k â€“ 1
n â€“ 1

pn (1 â€“ p)kâ€“n ,
k = n, n + 1, . . .
is called negative binomial distribution with parameters n â‰¥1 and p âˆˆ(0, 1). Of
course, Bâ€“
1,p = Gp.
Remark 1.4.42. We saw in eq. (1.31) that
Bâ€“
n,p({k + n}) =
n + k â€“ 1
k

pn (1 â€“ p)k =
â€“n
k

pn (p â€“ 1)k .
(1.34)
Alternatively one may deï¬ne the negative binomial distribution also via eq. (1.34).
Then it describes the event that the nth success appears in trial n + k. The advantage
of this approach is that now k âˆˆN0, that is, the restriction k â‰¥n is no longer needed.
Its disadvantage is that we are interested in what happens in trial k, not in trial k + n.
Example 1.4.43. Roll a die successively. Determine the probability that in the 20th
trial number â€œ6â€ appears for the fourth time.
Answer: We have p = 1/6, n = 4, and k = 20. Therefore, the probability for this
event is given by
Bâ€“
4,1/6({20}) =
19
16
  1
6
4  5
6
16
= 0.0404407 .
Let us ask now for the probability that the fourth success appears (strictly) before
trial 21. This probability is given by
20

k=4
k â€“ 1
3
  1
6
4  5
6
kâ€“4
= 0.433454 .

38
1 Probabilities
Example 1.4.44. There are two urns, say U0 and U1, each containing N balls. Choose
one of the two urns by random and take out a ball. Hereby U0 is chosen with probab-
ility 1 â€“ p, hence U1 with probability p. Repeat the procedure until we choose the last
(the Nth) ball out of one of the urns. What is the probability that there are left m balls
in the other urn, where m = 1, . . . , N ?11
Answer: For m = 1, . . . , N let Am be the event that there are still m balls in one of
the urns when choosing the last ball out of the other. Then Am splits into the disjoint
events Am = A0
m âˆªA1
m, where
A0
m occurs if we take the last ball out of U0 and U1 contains m balls and
A1
m occurs if choosing the Nth ball out of U1 and there are m balls in U0.
Let us start with evaluating the probability of A1
m. Say success occurs if we choose
urn U1. Thus, if we take out the last ball of urn U1, then success occurred for the Nth
time. On the other hand, if there are still m balls in U0, then failure had occurred N â€“m
times. Consequently, there are still m balls left in urn U0 if and only if the Nth success
shows up in trial N + (N â€“ m) = 2N â€“ m. Therefore, we get
P(A1
m) = Bâ€“
N,p({2N â€“ m}) =
2N â€“ m â€“ 1
N â€“ m

pN (1 â€“ p)Nâ€“m .
(1.35)
The probability of A0
m may be derived from that of A1
m by interchanging p and 1 â€“ p
(success occurs now with probability 1 â€“ p). This yields
P(A0
m) = Bâ€“
N,1â€“p({2N â€“ m}) =
2N â€“ m â€“ 1
N â€“ m

pNâ€“m (1 â€“ p)N .
(1.36)
Adding eqs. (1.35) and (1.36) leads to
P(Am) =
2N â€“ m â€“ 1
N â€“ m
 
pN (1 â€“ p)Nâ€“m + pNâ€“m (1 â€“ p)N
,
m = 1, . . . , N.
If p = 1/2, that is, both urns are equally likely, the previous formula simpliï¬es to
P(Am) =
2N â€“ m â€“ 1
N â€“ m

2â€“2N+m+1 .
(1.37)
Remark 1.4.45. The case p = 1/2 in the previous problem is known as Banachâ€™s match-
box problem. In each of two matchboxes are N matches. One chooses randomly a
matchbox (both boxes are equally likely) and takes out a match. What is the prob-
ability that there are still m matches left in the other box when taking the last match
out of one of the boxes? The answer is given by eq. (1.37).
11 There exists a slightly different version of this problem. What is the probability that there are m
balls left in one of the urns when choosing for the ï¬rst time an empty one. Note that in this setting also
m = 0 may occur.

1.5 Continuous Probability Measures
39
Example 1.4.46. We continue Example 1.4.44 with 0 < p < 1 and ask the following
question: What is the probability that U1 becomes empty before U0?
Answer: This happens if and only if U0 is nonempty when choosing U1 for the Nth
time, that is, when in U0 there are m balls left for some m = 1, . . . , N. Because of
eq. (1.35), this probability is given by
N

m=1
P(A1
m) = pN
N

m=1
2N â€“ m â€“ 1
N â€“ m

(1 â€“ p)Nâ€“m
= pN
Nâ€“1

k=0
N + k â€“ 1
k

(1 â€“ p)k .
(1.38)
Remark 1.4.47. Formula (1.38) leads to an interesting (known) property of the bino-
mial coefï¬cients. Since N
m=1 P(Am) = 1 , by eqs. (1.38) and (1.36) we obtain
Nâ€“1

k=0
N + k â€“ 1
k
 
pN (1 â€“ p)k + (1 â€“ p)N pk
= 1
or, setting n = N â€“ 1, to
n

k=0
n + k
k
 
pn+1 (1 â€“ p)k + (1 â€“ p)n+1 pk
= 1 .
In particular, if p = 1/2, this yields
n

k=0
n + k
k
 1
2k = 2n
for n = 0, 1, . . . .
1.5 Continuous Probability Measures
Discrete probability measures are inappropriate for the description of random ex-
periments where uncountably many different results may appear. Typical examples
of such experiments are the lifetime of an item, the duration of a phone call, the
measuring result of workpiece, and so on.
Discrete probability measures are concentrated on a ï¬nite or countably inï¬nite
set of points. An extension to larger sets is impossible. For example, there is no12
probability measure P on [0, 1] with P({t}) > 0 for t âˆˆ[0, 1].
12 Compare Problem 1.31.

40
1 Probabilities
Consequently, in order to describe random experiments with â€œmanyâ€ possible
different outcomes another approach is needed. To explain this â€œnewâ€ approach let
us shortly recall how we evaluated P(A) in the discrete case. If K is either ï¬nite or
countably inï¬nite and if p(9) = P({9}), 9 âˆˆK, then with this p : K â†’R we have
P(A) =

9âˆˆA
p(9) .
(1.39)
If the sample space is R or Rn, then such a representation is no longer possible. In-
deed, if P is not discrete, then, we will have p(9) = 0 for all possible observations 9.
Therefore, the sum in eq. (1.39) has to be replaced by an integral over a more general
function. We start with introducing functions p, which may be used for representing
P(A) via an integral.
Deï¬nition 1.5.1. A Riemann integrable function p : R â†’R is called probability
density function or simply density function if
p(x) â‰¥0 , x âˆˆR ,
and
 âˆ
â€“âˆ
p(x) dx = 1 .
(1.40)
Remark 1.5.2. Let us more precise formulate the second condition about p in the pre-
vious deï¬nition. For all ï¬nite intervals [a, b] in R the function p is Riemann integrable
on [a, b] and, moreover,
lim
aâ†’â€“âˆ
bâ†’+âˆ
 b
a
p(x) dx = 1 .
The density functions we will use later on are either continuous or piecewise con-
tinuous, that is they are the composition of ï¬nitely many continuous functions. These
functions are Riemann integrable, hence in this case it remains to verify the two
conditions (1.40).
Example 1.5.3. Deï¬ne p on R by p(x) = 0 if x < 0 and by p(x) = eâ€“x if x â‰¥0. Then p is
piecewise continuous, p(x) â‰¥0 if x âˆˆR and satisï¬es
 âˆ
â€“âˆ
p(x)dx = lim
bâ†’âˆ
 b
0
eâ€“x dx = lim
bâ†’âˆ

â€“ eâ€“xb
0 = 1 â€“ lim
bâ†’âˆeâ€“b = 1 .
Hence, p is a density function.

1.5 Continuous Probability Measures
41
Deï¬nition 1.5.4. Let p be a probability density function. Given a ï¬nite interval
[a, b], its probability (of occurrence) is deï¬ned by
P([a, b]) :=
 b
a
p(x)dx .
A graphical presentation of the previous deï¬nition is as follows. The probability
P([a, b]) is the area under the graph of the density p, taken from a to b.
P([a,b])
a
b
0.5
1.0
1.5
2.0
0.2
0.4
0.6
0.8
1.0
Figure 1.1: Probability of the interval [a, b].
Let us illustrate Deï¬nition 1.5.4 by the density function regarded in Example 1.5.3.
Then
P([a, b]) =
 b
a
eâ€“xdx =

â€“ eâ€“xb
a = eâ€“a â€“ eâ€“b
whenever 0 â‰¤a < b < âˆ. On the other hand, if a < b < 0, then P([a, b]) = 0 while for
a < 0 â‰¤b the probability of [a, b] is calculated by
P([a, b]) = P([0, b]) = 1 â€“ eâ€“b .
Remark 1.5.5. Deï¬nition 1.5.4 of the probability measure P does not ï¬t into the scheme
presented in Section 1.1.3. Why? Probability measures are deï¬ned on 3-ï¬elds. But the
collection of ï¬nite intervals in R is not a 3-ï¬eld. It is neither closed under taking com-
plements nor is the union of intervals in general again an interval. Furthermore, it is
far from being clear in which sense P should be 3-additive.
The next result justiï¬es the approach in Deï¬nition 1.5.4. Its proof rests upon an
extension theorem in Measure Theory (cf. [Coh13] or [Dud02]).

42
1 Probabilities
Proposition 1.5.6. Let B(R) be the 3-ï¬eld of Borel sets introduced in Deï¬nition 1.1.15.
Then for each density function p there exists a unique probability measure P : B(R) â†’
[0, 1] such that
P([a, b]) =
 b
a
p(x) dx
for all
a < b .
(1.41)
Deï¬nition 1.5.7. A probability measure P on B(R) is said to be continuous13
provided that there exists a density function p such that for a < b
P([a, b]) =
 b
a
p(x) dx .
(1.42)
The function p is called density function or simply density of P.
Remark 1.5.8. Note that changing the density function at ï¬nitely many points does
not change the generated probability measure. For instance, if we deï¬ne p(x) = 0 if
x â‰¤0 and p(x) = eâ€“x if x > 0, then this density function is different from that in
Example 1.5.3 but, of course, generates the same probability measure
Moreover, observe that eq. (1.42) is valid for all a < b if and only if for each t âˆˆR
P((â€“âˆ, t]) =
 t
â€“âˆ
p(x) dx .
(1.43)
Consequently, P is continuous if and only if there is a density p with eq. (1.43) for t âˆˆR.
Proposition 1.5.9. Let P : B(R) â†’[0, 1] be a continuous probability measure with
density p. Then the following are valid:
1.
P(R) = 1.
2.
For each t âˆˆR follows P({t}) = 0. More generally, if A âŠ‚R is either ï¬nite or countably
inï¬nite, then P(A) = 0.
3.
For all a < b we have
P((a, b)) = P((a, b]) = P([a, b)) = P([a, b]) =
 b
a
p(x) dx .
Proof: Let us start with proving P(R) = 1. For n â‰¥1 set An := [â€“n, n] and note that
A1 âŠ†A2 âŠ†â‹…â‹…â‹…as well as âˆ
n=1 An = R. Thus we may use that P is continuous from
below and by the properties of the density p we obtain
13 The mathematical correct notation would be â€œabsolutely continuous.â€ But since we do not treat so-
called â€œsingularly continuousâ€ probability measures, there is no need to distinguish between them,
and we may shorten the notation to â€œcontinuous.â€

1.6 Special Continuous Distributions
43
P(R) = lim
nâ†’âˆP(An) = lim
nâ†’âˆ
 n
â€“n
p(x) dx =
 âˆ
â€“âˆ
p(x) dx = 1 .
To verify the second property ï¬x t âˆˆR and deï¬ne for n â‰¥1 intervals Bn by Bn :=

t, t + 1
n

. Now we have B1 âŠ‡B2 âŠ‡â‹…â‹…â‹…and âˆ
n=1 Bn = {t}. Use this time the continuity
from above. Then we get
P({t}) = lim
nâ†’âˆP(Bn) = lim
nâ†’âˆ
 t+ 1
n
t
p(x) dx = 0 .
If A = {t1, t2, . . . }, then the 3-additivity of P together with P({tj}) = 0 give
P(A) =
âˆ

j=1
P({tj}) = 0
as asserted.
The third property is an immediate consequence of the second one. Observe
[a, b] = (a, b) âˆª{a} âˆª{b} ,
hence P([a, b]) = P((a, b)) + P({a}) + P({b}) proving (1.42) by P({a}) = P({b}) = 0.
âˆ
Remark 1.5.10. Say a set C âŠ†R can be represented as C = âˆ
j=1 Ij with disjoint (open
or half-open or closed) intervals Ij, then
P(C) =
âˆ

j=1

Ij
p(x) dx :=

C
p(x) dx .
More generally, if a set B may be written as B = âˆ
n=1 Cn where the Cns are a union of
disjoint intervals, and satisfy C1 âŠ‡C2 âŠ‡â‹…â‹…â‹…, then
P(B) = lim
nâ†’âˆP(Cn) .
In this way, one may evaluate P(B) for a large class of subsets B âŠ†R.
1.6 Special Continuous Distributions
1.6.1 Uniform Distribution on an Interval
Let I = [!, "] be a ï¬nite interval of real numbers. Deï¬ne a function p : R â†’R by
p(x) :=

1
"â€“! : x âˆˆ[!, "]
0 : x âˆ‰[!, "]
(1.44)

44
1 Probabilities
Proposition 1.6.1. The mapping p deï¬ned by eq. (1.44) is a probability density function.
Proof: Note that p is piecewise continuous, hence Riemann integrable. Moreover,
p(x) â‰¥0 for x âˆˆR and
 âˆ
â€“âˆ
p(x) dx =
 "
!
1
" â€“ ! dx =
1
" â€“ !(" â€“ !) = 1 .
Consequently, p is a probability density.
âˆ
Deï¬nition 1.6.2. The probability measure P generated by the density in eq. (1.44)
is called uniform distribution on the interval I = [!, "].
How is P([a, b]) evaluated for some interval [a, b]? Let us ï¬rst treat the case [a, b] âŠ†I.
Then
P([a, b]) =
 b
a
1
" â€“ ! dx = b â€“ a
" â€“ ! = Length of [a, b]
Length of [!, "] .
(1.45)
This explains why P is called â€œuniform distribution.â€ The probability of an interval
[a, b] âŠ†I depends only on its length, not on its position. Shifting [a, b] inside I does
not change its probability of occurrence.
If [a, b] is arbitrary, not necessarily contained in I, then P([a, b]) can be easily
calculated by
P([a, b]) = P([a, b] âˆ©I) .
Example 1.6.3. Let P be the uniform distribution on [0, 1]. Which probabilities have
[â€“1, 0.5], [0, 0.25] âˆª[0.75, 1], (â€“âˆ, t] if t âˆˆR, and A âŠ†R, where A = âˆ
n=1

1
2n+1/2 , 1
2n

?
Answer: The ï¬rst two intervals have probability 1
2. If t âˆˆR, then
P((â€“âˆ, t]) =
â§
âªâ¨
âªâ©
0 :
t < 0
t : 0 â‰¤t â‰¤1
1 :
t > 1
Finally, observe that the intervals

1
2n+1/2 , 1
2n

are disjoint subsets of [0, 1]. Hence we get
P(A) =
âˆ

n=1
 1
2n â€“
1
2n+1/2

=

1 â€“ 2â€“1/2
 âˆ

n=1
1
2n = 1 â€“ 2â€“1/2

1.6 Special Continuous Distributions
45
Example 1.6.4. A stick of length L is randomly broken into two pieces. Find the
probability that the size of one piece is at least twice that of the other one.
Answer: This event happens if and only if the point at which the stick is broken
is either in [0, L/3] or in [2L/3, L]. Assuming that the point at which the stick is broken
is uniformly distributed on [0, L], the desired probability is 2
3. Another way to get this
result is as follows. The size of each piece is less than twice as that of the other one
if the point at which the stick is broken is in [L/3, 2L/3]. Hence, the probability of the
complementary event is 1/3 leading again to 2/3 for the desired probability.
Example 1.6.5. Let C0 := [0, 1]. Extract from C0 the interval ( 1
3, 2
3), thus it remains C1 =

0, 1
3

âˆª
 2
3, 1

. To construct C2 extract from C1 the two middle intervals
 1
9, 2
9

and
 7
9, 8
9

,
hence C2 = [0, 1
9] âˆª[ 2
9, 1
3] âˆª[ 2
3, 7
9] âˆª[ 8
9, 1].
Suppose that through this method we already got sets Cn which are the union of
2n disjoint closed intervals of length 3â€“n. In order to construct Cn+1, split each of the 2n
intervals into three intervals of length 3â€“nâ€“1 and erase the middle one of these three.
In this way we get Cn+1, which consists of 2n+1 disjoint intervals of length 3â€“nâ€“1. Finally,
one deï¬nes
C =
âˆ

n=1
Cn .
The set C is known as the Cantor set. Let P be the uniform distribution on [0, 1]. Which
value does P(C) have?
Answer: First observe that C0 âŠƒC1 âŠƒC2 âŠƒâ‹…â‹…â‹…, hence, using that P is continuous
from above, it follows
P(C) = lim
nâ†’âˆP(Cn) .
(1.46)
The sets Cn are the disjoint union of 2n intervals of length 3â€“n. Consequently, it follows
P(Cn) = 2n
3n , which by eq. (1.46) implies P(C) = 0.
One might conjecture that C = Ã¸. On the contrary, C is even uncountably inï¬nite.
To see this we have to make the construction of the Cantor set a little bit more precise.
Given n â‰¥1 let
An = {! = (!1, . . . , !n) : !1, . . . , !nâ€“1 âˆˆ{0, 2}, !n = 1} .
If ! = (!1, . . . , !n) âˆˆAn, set x! = n
k=1
!k
3k and I! =

x!, x! + 1
3n

. In this notation
I(1) =
 1
3, 2
3

,
I(0,1) =
 1
9, 2
9

,
I(2,1) =
 7
9, 8
9

and
I(0,0,1) =
 1
27, 2
27

.

46
1 Probabilities
Then, if C0 = [0, 1], for n â‰¥1 we have
Cn = Cnâ€“1\
	
!âˆˆAn
I!,
hence
C = [0, 1]\
âˆ
	
n=1
	
!âˆˆAn
I! .
Take now any sequence x1, x2, . . . with xk âˆˆ{0, 2} and set x = âˆ
k=1
xk
3k . Then x can-
not belong to any I! because otherwise at least one of the xks should satisfy xk = 1.
Thus x âˆˆC, and the number of x that may be represented by xks with xk âˆˆ{0, 2} is
uncountably inï¬nite.
1.6.2 Normal Distribution
This section is devoted to the most important probability measure, the normal
distribution. Before we can introduce it, we need the following result.
Proposition 1.6.6. We have
 âˆ
â€“âˆ
eâ€“x2/2 dx =
âˆš
2 0 .
Proof: Set
a :=
 âˆ
â€“âˆ
eâ€“x2/2 dx
and note that a > 0. Then we get
a2 =
 âˆ
â€“âˆ
eâ€“x2/2 dx
  âˆ
â€“âˆ
eâ€“y2/2 dy

=
 âˆ
â€“âˆ
 âˆ
â€“âˆ
eâ€“(x2+y2)/2 dx dy .
Change the variables in the right-hand double integral as follows: x := r cos ( and
y := r sin (, where 0 < r < âˆand 0 â‰¤( < 20. Observe that
dx dy = |D(r, ()|dr d(
with
D(r, () = det
 âˆ‚x
âˆ‚r
âˆ‚x
âˆ‚(
âˆ‚y
âˆ‚r
âˆ‚y
âˆ‚(

= det

cos ( â€“r sin (
sin (
r cos (

= r cos2 ( + r sin2 ( = r .
Using x2 + y2 = r2 cos2 ( + r2 sin2 ( = r2, this change of variables leads to
a2 =
20

0
âˆ

0
r eâ€“r2/2 dr d( =
 20
0

â€“ eâ€“r2/2âˆ
0 d( = 20 ,
which by a > 0 implies a =
âˆš
20. This completes the proof.
âˆ

1.6 Special Continuous Distributions
47
Given , âˆˆR and 3 > 0 let
p,,3(x) :=
1
âˆš
203
eâ€“(xâ€“,)2/232 ,
x âˆˆR .
(1.47)
â€“2
2
4
6
0.2
0.4
0.6
0.8
Figure 1.2: The function p,,3 with parameters , = 0, 1, 2, 3 and 3 = 0.5, 0.75, 0.9, 1.1.
Proposition 1.6.7. If , âˆˆR and 3 > 0, then p,,3 is a probability density function.
Proof: We have to verify
 âˆ
â€“âˆ
p,,3(x) dx = 1
or
 âˆ
â€“âˆ
e(xâ€“,)2/232 dx =
âˆš
20 3 .
Setting u := (x â€“ ,)/3 it follows dx = 3du, hence Proposition 1.6.6 leads to
 âˆ
â€“âˆ
e(xâ€“,)2/232 dx = 3
 âˆ
â€“âˆ
eâ€“u2/2 du = 3
âˆš
20 .
This completes the proof.
âˆ
Deï¬nition 1.6.8. The probability measure generated by p,,3 is called normal dis-
tribution with expected value , and variance 32. It is denoted by N(,, 32), that is,
for all a < b
N(,, 32)([a, b]) =
1
âˆš
203
 b
a
eâ€“(xâ€“,)2/232 dx .
Remark 1.6.9. In the moment the numbers , âˆˆR and 3 > 0 are nothing else than
parameters. Why they are called â€œexpected valueâ€ and â€œvarianceâ€ will become clear
in Section 5.

48
1 Probabilities
Deï¬nition 1.6.10. The probability measure N(0, 1) is called standard normal
distribution. It is given by
N(0, 1)([a, b]) =
1
âˆš
20
 b
a
eâ€“x2/2 dx .
Example 1.6.11. For example, we have
N(0, 1)([â€“1, 1]) =
1
âˆš
20
 1
â€“1
eâ€“x2/2 dx = 0.682689
or
N(0, 1)([2, 4]) =
1
âˆš
20
 4
2
eâ€“x2/2 dx = 0.0227185 .
1.6.3 Gamma Distribution
Eulerâ€™s gamma function is a mapping from (0, âˆ) to R deï¬ned by
A(x) :=
 âˆ
0
sxâ€“1eâ€“sds ,
x > 0 .
1
2
3
4
5
x
5
10
15
x
Figure 1.3: Graph of the gamma function.
Let us summarize the main properties of the gamma function.
Proposition 1.6.12.
1.
A maps (0, âˆ) continuously to (0, âˆ) and possesses continuous derivatives of any
order.
2.
If x > 0, then
A(x + 1) = x A(x) .
(1.48)

1.6 Special Continuous Distributions
49
3.
For n âˆˆN follows A(n) = (n â€“ 1)!. In particular, A(1) = A(2) = 1 and A(3) = 2.
4.
A(1/2) = âˆš0.
Proof: For the proof of the continuity and differentiability we refer to [Art64]
The proof of eq. (1.48) is carried out by integration by parts as follows:
A(x + 1) =
 âˆ
0
sx eâ€“sds =

â€“sx eâ€“sâˆ
0 +
 âˆ
0
x sxâ€“1eâ€“sds . = x A(x) .
Note that sx eâ€“s = 0 if s = 0 or s â†’âˆ.
From
A(1) =
 âˆ
0
eâ€“sds = 1
and eq. (1.48) follows, as claimed,
A(n) = (n â€“ 1)A(n â€“ 1) = (n â€“ 1)(n â€“ 2)A(n â€“ 2) = â‹…â‹…â‹…= (n â€“ 1) â‹…â‹…â‹…1 â‹…A(1) = (n â€“ 1)! .
To prove the fourth assertion we use Proposition 1.6.6. Because of
âˆš
20 =
 âˆ
â€“âˆ
eâ€“t2/2dt = 2
 âˆ
0
eâ€“t2/2dt
it follows that
 âˆ
0
eâ€“t2/2dt =
"0
2 .
(1.49)
Substituting s = t2/2, thus ds = t dt, by eq. (1.49) the integral for A(1/2) transforms to
A(1/2) =
 âˆ
0
sâ€“1/2eâ€“sds =
 âˆ
0
âˆš
2
t eâ€“t2/2 t dt =
âˆš
2
 âˆ
0
eâ€“t2/2dt = âˆš0 .
This completes the proof.
âˆ
If x â†’âˆ, then A(x) increases very rapidly. More precisely, the following is valid
(cf. [Art64]):
Proposition 1.6.13 (Stirlingâ€™s formula for the A-function). For x > 0 there exists a
number ( âˆˆ(0, 1) such that
A(x) =
"
20
x
x
e

x
e(/12x .
(1.50)

50
1 Probabilities
Corollary 1.6.14 (Stirlingâ€™s formula for n-factorial). In view of
n! = A(n + 1) = nA(n)
formula (1.50) leads to14
n! =
âˆš
20n
n
e

n
e(/12n
(1.51)
for some ( âˆˆ(0, 1) depending on n. In particular,
lim
nâ†’âˆ
en
nn+1/2 n! =
âˆš
20 .
Our next aim is to introduce a continuous probability measure with density tightly
related to the A-function. Given !, " > 0 deï¬ne p!," from R to R by
p!,"(x) :=
â§
â¨
â©
0
: x â‰¤0
1
!" A(") x"â€“1eâ€“x/! : x > 0
(1.52)
1
2
3
4
0.2
0.4
0.6
0.8
1.0
1.2
Figure 1.4: The functions p1," with " = 0.5, 1, 1.5, 2 and " = 2.5.
Proposition 1.6.15. For all !, " > 0 the function p!," in eq. (1.52) is a probability density.
Proof: Of course, p!,"(x) â‰¥0. Thus it remains to verify
 âˆ
â€“âˆ
p!,"(x) dx = 1 .
(1.53)
14 cf. also [Spi08], Chapter 27, Problem 19.

1.6 Special Continuous Distributions
51
By the deï¬nition of p!," we have
 âˆ
â€“âˆ
p!,"(x) dx =
1
!" A(")
 âˆ
0
x"â€“1eâ€“x/! dx .
Substituting in the right-hand integral u := x/!, thus dx = ! du, the right-hand side
becomes
1
A(")
 âˆ
0
u"â€“1eâ€“u du =
1
A(") A(") = 1 .
Hence eq. (1.53) is valid, and p!," is a probability density function.
âˆ
Deï¬nition 1.6.16. The probability measure A!," with density function p!," is called
gamma distribution with parameters ! and ". For all 0 â‰¤a < b < âˆ
A!,"([a, b]) =
1
!" A(")
 b
a
x"â€“1eâ€“x/! dx .
(1.54)
Remark 1.6.17. Since p!,"(x) = 0 for x â‰¤0 it follows that A!,"((â€“âˆ, 0]) = 0. Hence, if
a < b are arbitrary, then
A!,"([a, b]) = A!,"([0, âˆ) âˆ©[a, b]) .
Remark 1.6.18. If " âˆ‰N, then the integral in eq. (1.54) cannot be expressed by element-
ary functions. Only numerical evaluations are possible.
1.6.4 Exponential Distribution
An important special gamma distribution is the exponential distribution. This prob-
ability measure is deï¬ned as follows.
Deï¬nition 1.6.19. For + > 0 let E+ := A+â€“1,1 be the exponential distribution with
parameter + > 0.
Remark 1.6.20. The probability density function p+ of E+ is given by
p+(x) =

0
: x â‰¤0
+ eâ€“+x : x > 0

52
1 Probabilities
Consequently, if 0 â‰¤a < b < âˆ, then the probability of [a, b] can be evaluated by
E+([a, b]) = eâ€“+a â€“ eâ€“+b .
Moreover,
E+([t, âˆ)) = eâ€“+t ,
t â‰¥0 .
Remark 1.6.21. The exponential distribution plays an important role for the descrip-
tion of lifetimes. For instance, it is used to determine the probability that the lifetime
of a component part or the duration of a phone call exceeds a certain time T > 0.
Furthermore, it is applied to describe the time between the arrivals of customers at a
counter or in a shop.
Example 1.6.22. Suppose that the duration of phone calls is exponentially distributed
with parameter + = 0.1. What is the probability that a call lasts less than two time
units? Or what is the probability that it lasts between one and two units? Or more than
ï¬ve units?
Answer: These probabilities are evaluated by
E0.1([0, 2]) = 1 â€“ eâ€“0.2 = 0.181269 , E0.1([1, 2]) = eâ€“0.1 â€“ eâ€“0.2 = 0.08611 and
E0.1([5, âˆ)) = eâ€“0.5 = 0.60653 .
1.6.5 Erlang Distribution
Another important class of gamma distributions is that of Erlang distributions deï¬ned
as follows.
Deï¬nition 1.6.23. For + > 0 and n âˆˆN let E+,n := A+â€“1,n. This probability measure
is called Erlang distribution with parameters + and n.
Remark 1.6.24. The density p+,n of the Erlang distribution is
p+,n(x) =

0
: x â‰¤0
+n
(nâ€“1)! xnâ€“1 eâ€“+x : x > 0
Of course, E+,1 = E+. Thus the Erlang distribution may be viewed as generalized
exponential distribution.
An important property of the Erlang distribution is as follows.

1.6 Special Continuous Distributions
53
Proposition 1.6.25. If t > 0, then
E+,n([t, âˆ)) =
nâ€“1

j=0
(+t)j
j!
eâ€“+t .
Proof: We have to show that for t > 0
 âˆ
t
p+,n(x) dx =
+n
(n â€“ 1)!
 âˆ
t
xnâ€“1 eâ€“+x dx =
nâ€“1

j=0
(+t)j
j!
eâ€“+t .
(1.55)
This is done by induction over n.
If n = 1 then eq. (1.55) is valid by
 âˆ
t
p+,1(x) dx =
 âˆ
t
+ eâ€“+x dx = eâ€“+t .
Suppose now eq. (1.55) is proven for some n â‰¥1. Next, we have to show that it is also
valid for n + 1. Thus, we know
+n
(n â€“ 1)!
 âˆ
t
xnâ€“1 eâ€“+x dx =
nâ€“1

j=0
(+t)j
j!
eâ€“+t
(1.56)
and want
+n+1
n!
 âˆ
t
xn eâ€“+x dx =
n

j=0
(+t)j
j!
eâ€“+t .
(1.57)
Let us integrate the integral in eq. (1.57) by parts as follows. Set u := xn, hence uâ€² =
n xnâ€“1, and vâ€² = eâ€“+x, thus v = â€“+â€“1 eâ€“+x. Doing so and using eq. (1.56) the left-hand side
of eq. (1.57) becomes
+n+1
n!
 âˆ
t
xn eâ€“+x dx =

â€“+n
n! xn eâ€“+x
âˆ
t
+
+n
(n â€“ 1)!
 âˆ
t
xnâ€“1 eâ€“+x dx
= (+t)n
n!
eâ€“+t +
nâ€“1

j=0
(+t)j
j!
eâ€“+t =
n

j=0
(+t)j
j!
eâ€“+t .
This proves eq. (1.57) and, consequently, eq. (1.55) is valid for all n â‰¥1.
âˆ
1.6.6 Chi-Squared Distribution
Another important class of gamma distributions is that of 72-distributions. These
probability measures play a crucial role in Mathematical Statistics (cf. Chapter 8).

54
1 Probabilities
Deï¬nition 1.6.26. For n â‰¥1 let
72
n := A2,n/2 .
This probability measure is called 72-distribution with n degrees of freedom.
Remark 1.6.27. In the moment the integer n
â‰¥
1 in Deï¬nition 1.6.26 is only a
parameter. The notation â€œdegree of freedomâ€ will become clear when we apply the
72-distribution for statistical problems.
Remark 1.6.28. The density p of a 72
n-distribution is given by
p(x) =

0
: x â‰¤0
xn/2â€“1eâ€“x/2
2n/2A(n/2) : x > 0 ,
i.e., if 0 â‰¤a < b, then
72
n([a, b]) =
1
2n/2A(n/2)
 b
a
xn/2â€“1 eâ€“x/2 dx .
1.6.7 Beta Distribution
Tightly connected with the gamma function is Eulerâ€™s beta function B. It maps
(0, âˆ) Ã— (0, âˆ) to R and is deï¬ned by
B(x, y) :=
 1
0
sxâ€“1(1 â€“ s)yâ€“1 ds ,
x, y > 0 .
(1.58)
The link between gamma and beta function is the following important identity:
B(x, y) = A(x) â‹…A(y)
A(x + y) ,
x, y > 0 .
(1.59)
For a proof of eq. (1.59) we refer to Problem 1.27.
Further properties of the beta function are either easy to prove or follow via
eq. (1.59) by those of the gamma function.
1.
The beta function is continuous on (0, âˆ) Ã— (0, âˆ) with values in (0, âˆ).
2.
For x, y > 0 one has B(x, y) = B(y, x).
3.
If x, y > 0, then
B(x + 1, y) =
x
x + y B(x, y) .
(1.60)
4.
For x > 0 follows B(x, 1) = 1/x.

1.6 Special Continuous Distributions
55
5.
if n, m â‰¥1 are integers, then
B(n, m) = (n â€“ 1)! (m â€“ 1)!
(n + m â€“ 1)!
.
6.
B
 1
2, 1
2

= 0 .
Deï¬nition 1.6.29. Let !, " > 0. The probability measure B!," deï¬ned by
B!,"([a, b]) :=
1
B(!, ")
 b
a
x!â€“1(1 â€“ x)"â€“1 dx ,
0 â‰¤a < b â‰¤1 ,
is called beta distribution with parameters ! and ".
The density function q!," of B!," is given by
q!,"(x) =

1
B(!,") x!â€“1(1 â€“ x)"â€“1 : 0 < x < 1
0
: otherwise
0.2
0.4
0.6
0.8
1.0
0.5
1.0
1.5
2.0
2.5
3.0
Figure 1.5: Density functions of the beta distribution with
parameters (0.5, 1.5), (1.5, 2.5), (2.5, 2), (1.5, 2), (2, 1.5), and (2.5, 2.5).
Remark 1.6.30. It is easy to see that q!," is a density function.
 âˆ
â€“âˆ
q!,"(x) dx =
1
B(!, ")
 1
0
x!â€“1(1 â€“ x)"â€“1 dx = B(!, ")
B(!, ") = 1 .

56
1 Probabilities
Furthermore, since q!,"(x) = 0 if x âˆ‰[0, 1], the probability measure B!," is concentrated
on [0, 1], that is, B!,"([0, 1]) = 1 or, equivalently, B!,"(R\[0, 1]) = 0.
Example 1.6.31. Choose independently n numbers x1, . . . , xn in [0, 1] according to the
uniform distribution. Ordering these numbers by their size we get xâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤xâˆ—
n. In
Example 3.7.8 we will show that the kth largest number xâˆ—
k is Bk,nâ€“k+1-distributed. In
other words, if 0 â‰¤a < b â‰¤1, then
P{a â‰¤xâˆ—
k â‰¤b} = Bk,nâ€“k+1([a, b]) =
n!
(k â€“ 1)! (n â€“ k)!
 b
a
xkâ€“1(1 â€“ x)nâ€“k dx .
1.6.8 Cauchy Distribution
We start with the following statement.
Proposition 1.6.32. The function p deï¬ned by
p(x) = 1
0 â‹…
1
1 + x2 ,
x âˆˆR ,
(1.61)
is a probability density.
Proof: Of course, p(x) > 0 for x âˆˆR. Let us now investigate
# âˆ
â€“âˆp(x) dx. Because of
limbâ†’âˆarctan(b) = 0/2 and limaâ†’â€“âˆarctan(a) = â€“0/2 follows
 âˆ
â€“âˆ
p(x) dx = 1
0
lim
aâ†’â€“âˆlim
bâ†’âˆ
 b
a
1
1 + x2 dx = 1
0
lim
aâ†’â€“âˆlim
bâ†’âˆ

arctan x
b
a = 1 .
Thus, as asserted, p is a probability density.
âˆ
â€“6
â€“4
â€“2
2
4
6
0.05
0.10
0.15
0.20
0.25
0.30
Figure 1.6: The density function of the Cauchy distribution.

1.7 Distribution Function
57
Deï¬nition 1.6.33. The probability measure P with density p from eq. (1.61) is
called Cauchy distribution. In other words, the Cauchy distribution P is char-
acterized by
P([a, b]) = 1
0
 b
a
1
1 + x2 dx = 1
0

arctan(b) â€“ arctan(a)

.
1.7 Distribution Function
In this section we always assume that the sample space is R, even if the random ex-
periment has only ï¬nitely or countably inï¬nite many different outcomes. For example,
rolling a die once is modeled by (R, P(R), P), where P({k}) = 1/6, k = 1, . . . , 6, and
P({x}) = 0 whenever x âˆ‰{1, . . . , 6}.
Thus, let P be a probability measure either deï¬ned on B(R) (continuous case) or
on P(R) (discrete case) .
Deï¬nition 1.7.1. The function F : R â†’[0, 1] deï¬ned by
F(t) := P((â€“âˆ, t]) ,
t âˆˆR ,
is called15 (cumulative) distribution function of P.
Remark 1.7.2. If P is discrete, that is, P(D) = 1 for some D = {x1, x2, . . . }, then its
distribution function can be evaluated by
F(t) =

xjâ‰¤t
P({xj}) =

xjâ‰¤t
pj ,
where pj = P({xj}), while for continuous P with probability density p
F(t) =
 t
â€“âˆ
p(x) dx .
Example 1.7.3. Let P be the uniform distribution on {1, . . . , 6}. Then
F(t) =
â§
âªâ¨
âªâ©
0 : t < 1
k
6 : k â‰¤t < k + 1 , k âˆˆ{1, . . . , 5}
1 : t â‰¥6 .
15 To shorten the notation, mostly we will call it â€œdistribution functionâ€ instead of, as often used in
the literature, â€œcumulative distribution functionâ€ or, abbreviated, CDF.

58
1 Probabilities
Example 1.7.4. The distribution function of the binomial distribution Bn,p is given by
F(t) =

0â‰¤kâ‰¤t
n
k

pk(1 â€“ p)nâ€“k , 0 â‰¤t < âˆ,
and F(t) = 0 if t < 0.
5
10
15
20
25
0.2
0.4
0.6
0.8
1.0
Figure 1.7: Distribution function of the binomial distribution B25,0.4.
Example 1.7.5. The distribution function of the exponential distribution E+ equals
F(t) =

0
: t < 0
1 â€“ eâ€“+t : t â‰¥0
â€“4
â€“2
2
4
6
8
10
0.2
0.4
0.6
0.8
1.0
Figure 1.8: Distribution function of E0.5.
Example 1.7.6. The distribution function of the standard normal distribution is de-
noted16 by I, therefore also called Gaussian I-function.
I(t) =
1
âˆš
20
 t
â€“âˆ
eâ€“x2/2 dx ,
t âˆˆR .
(1.62)
16 Sometimes also denoted as â€œnorm(â‹…).â€

1.7 Distribution Function
59
â€“4
â€“2
2
4
0.2
0.4
0.6
0.8
1.0
Figure 1.9: Distribution function of the standard normal distribution (I-function).
Remark 1.7.7. The Gaussian I-function is tightly related to the Gaussian error func-
tion deï¬ned by
erf(t) =
2
âˆš0
 t
0
eâ€“x2dx ,
t âˆˆR .
Observe that erf(â€“t) = â€“erf(t). The link between the I and the error function is
I(t) = 1
2

1 + erf
 tâˆš
2

and
erf(t) = 2I(
âˆš
2 t) â€“ 1 ,
t âˆˆR .
(1.63)
Example 1.7.8. Let P be the uniform distribution on the interval [!, "]. Then its
distribution function is
F(t) =
â§
âªâªâ¨
âªâªâ©
0 :
t < !
tâ€“!
"â€“! : ! â‰¤t â‰¤"
1
:
t > "
In particular, for the uniform distribution on [0, 1] one obtains
F(t) =
â§
âªâªâ¨
âªâªâ©
0 :
t < 0
t : 0 â‰¤t â‰¤1
1 :
t > 1
The next proposition lists the main properties of distribution functions.

60
1 Probabilities
Proposition 1.7.9. Let F be the distribution function of a probability measure P on R,
discrete or continuous. Then F possesses the following properties.
(1)
F is nondecreasing.
(2)
F(â€“âˆ) = limtâ†’â€“âˆF(t) = 0 and F(âˆ) = limtâ†’âˆF(t) = 1.
(3)
F is continuous from the right.
Proof: Suppose s < t. This implies (â€“âˆ, s] âŠ‚(â€“âˆ, t], hence, since P is monotone, we
obtain
F(s) = P((â€“âˆ, s]) â‰¤P((â€“âˆ, t]) = F(t) .
Thus F is nondecreasing.
Take any sequence (tn)nâ‰¥1 that decreases monotonely to â€“âˆ. Set An := (â€“âˆ, tn].
Then A1 âŠ‡A2 âŠ‡â‹…â‹…â‹…as well as âˆ
n=1 An = Ã¸. Since P is continuous from above it follows
lim
nâ†’âˆF(tn) = lim
nâ†’âˆP(An) = P(Ã¸) = 0 .
This being true for any sequence (tn)nâ‰¥1 tending to â€“âˆimplies F(â€“âˆ) = 0.
The proof for F(âˆ) = 1 is very similar. Now (tn)nâ‰¥1 increases monotonely to âˆ. If
as before An := (â€“âˆ, tn], this time A1 âŠ†A2 âŠ†â‹…â‹…â‹…and âˆ
n=1 An = R. By the continuity
of P from below now we obtain
lim
nâ†’âˆF(tn) = lim
nâ†’âˆP(Bn) = P(R) = 1 .
Again, since the tns were arbitrary, F(âˆ) = 1.
Thus it remains to prove that F is continuous from the right. To do this, we take
t âˆˆR and a decreasing sequence (tn)nâ‰¥1 tending to t. We have to show that if n â†’âˆ,
then F(tn) â†’F(t).
As before set An := (â€“âˆ, tn]. Again A1 âŠ‡A2 âŠ‡â‹…â‹…â‹…, but now âˆ
n=1 An = (â€“âˆ, t].
Another application of the continuity from above implies
F(t) = P((â€“âˆ, t]) = lim
nâ†’âˆP(An) = lim
nâ†’âˆF(tn) .
This is valid for each t âˆˆR, hence F is continuous from the right.
âˆ
Properties (1), (2), and (3) in Proposition 1.7.9 characterize distribution functions. More
precisely, the following result is true. Its proof is based on an extension theorem in
Measure Theory. Therefore, we can show here only its main ideas.
Proposition 1.7.10. Let F : R â†’R be an arbitrary function possessing the properties
stated in Proposition 1.7.9. Then there exists a unique probability measure P on B(R)
such that
F(t) = P((â€“âˆ, t]) ,
t âˆˆR .

1.7 Distribution Function
61
Idea of the proof: If a < b set
P0((a, b]) := F(b) â€“ F(a) .
In this way we get a mapping P0 deï¬ned on the collection of all half-open intervals
{(a, b] : a < b}. The key point is to verify that P0 can be uniquely extended to a prob-
ability measure P on B(R). One way to do this is to introduce a so-called outer measure
Pâˆ—deï¬ned on P(R) by
Pâˆ—(B) := inf
 âˆ

i=1
P0((ai, bi]) : B âŠ†
âˆ
	
i=1
(ai, bi]
$
.
Generally, this outer measure is not 3-additive. Therefore, one restricts Pâˆ—to B(R). If
P denotes this restriction, the most difï¬cult part of the proof is to verify that P is 3-
additive. After this has been done, by the construction, P is the probability measure
possessing distribution function F.
The uniqueness of P follows by a general uniqueness theorem for probability
measures asserting the following.
Let P1 and P2 be two probability measures on (K, A) and let E âŠ†A be a collection
of events closed under taking intersections and generating A. If P1(E) = P2(E) for all
E âˆˆE, then P1 = P2. In our case E = {(â€“âˆ, t] : t âˆˆR}.
Conclusion: If the outcomes of a random experiment are real numbers, then this ex-
periment can also be described by a function F : R â†’R possessing the properties
in Proposition 1.7.9. Then F(t) is the probability to observe a result that is less than or
equal to t.
Let us state further properties of distribution functions.
Proposition 1.7.11. If F is the distribution function of a probability measure P, then for
all a < b
F(b) â€“ F(a) = P((a, b]) .
Proof: Observing that (â€“âˆ, a] âŠ†(â€“âˆ, b] this is an immediate consequence of
F(b) â€“ F(a) = P((â€“âˆ, b]) â€“ P((â€“âˆ, a]) = P

(â€“âˆ, b]\(â€“âˆ, a]

= P((a, b]) .
âˆ
Since F is nondecreasing and bounded, for each t âˆˆR the left-hand limit
F(t â€“ 0) := lim
sâ†’t
s<t
F(s)
exists and, moreover, F(t â€“ 0) â‰¤F(t). Furthermore, by the right continuity of F one has
F(t â€“ 0) = F(t) if and only if F is continuous at the point t.

62
1 Probabilities
If this is not so, then h = F(t) â€“ F(t â€“ 0) > 0, that is, F possesses at t a jump of
height h > 0. This height is directly connected with the value of P({t}).
Proposition 1.7.12. The distribution function F of a probability measure P has a jump
of height h â‰¥0 at t âˆˆR if and only if P({t}) = h.
Proof: Let (tn)nâ‰¥1 be a sequence of real numbers increasing monotonely to t. Then,
using that P is continuous from above, it follows
h = F(t) â€“ F(t â€“ 0) = lim
nâ†’âˆ[F(t) â€“ F(tn)] = lim
nâ†’âˆP((tn, t]) = P({t}) .
Observe that âˆ
n=1(tn, t] = {t}. This proves the assertion.
âˆ
Corollary 1.7.13. The function F is continuous at t âˆˆR if and only if P({t}) = 0.
Example 1.7.14. Suppose the function F is deï¬ned by
F(t) =
â§
âªâªâªâªâªâ¨
âªâªâªâªâªâ©
0 :
t < â€“1
1/3 : â€“1 â‰¤t < 0
1/2 : 0 â‰¤t < 1
2/3 : 1 â‰¤t < 2
1 :
t â‰¥2 .
Then F fulï¬ls the assumptions of Proposition 1.7.10. Hence there is a probability
measure P with F(t) = P{(â€“âˆ, t]). What does P look like?
Answer: The function F has jumps at â€“1, 0, 1, and 2 with heights 1/3, 1/6, 1/6, and
1/3. Therefore,
P({â€“1}) = 1/3 , P({0}) = 1/6 , P({1}) = 1/6 and P({2}) = 1/3,
hence P is the discrete probability measure concentrated on D = {â€“1, 0, 1, 2} with P({t}),
t âˆˆD, given above.
Suppose now that P is continuous with density function p. Recall that then
F(t) = P((â€“âˆ, t]) =
 t
â€“âˆ
p(x) dx ,
t âˆˆR .
(1.64)
In particular, since F is the function of the upper bound in an integral, it is continuous.
Next we investigate the question whether we may evaluate the density p
knowing F.
Proposition 1.7.15. Suppose p is continuous at some t âˆˆR. Then F is differentiable at
t with
Fâ€²(t) = d
dt F(t) = p(t) .

1.7 Distribution Function
63
Proof: This follows immediately by an application of the fundamental theorem of
Calculus to representation (1.64) of F.
âˆ
Remark 1.7.16. Let F be the distribution function of a probability measure P. If F is
continuous, then P({t}) = 0 for all t âˆˆR. But does this also imply that P is continuous,
that is, that P has a density? The answer is negative. There exist probability measures P
on (R, B(R)) with a continuous distribution function but without possessing a density.
Such probability measures are called singularly continuous.
To get an impression of how such probability measures look, let us shortly sketch
the construction of an example. Let C be the Cantor set introduced in Example 1.6.5.
The basic idea is to transfer the uniform distribution on [0, 1] to a probability measure
P with P(C) = 1. The transformation is done by the function f deï¬ned as follows. If
x âˆˆ[0, 1] is represented as x = âˆ
k=1
xk
2k with xk âˆˆ{0, 1}, then f(x) = âˆ
k=1
2xk
3k . Note that f
maps [0, 1] into C. If ËœP denotes the uniform distribution on [0, 1], deï¬ne the probability
measure P by
P(B) = ËœP{x âˆˆ[0, 1] : f(x) âˆˆB} .
Then for all t âˆˆR we have P({t}) = 0, but since P(C) = 1, P cannot have a density.
Indeed, such a density should vanish outside C. But, as we saw, the probability of C
with respect to the uniform distribution is zero. Hence the only possible density would
be p(t) = 0, t âˆˆR. This contradiction shows that P is not continuous in our sense.
Assuming a little bit more than the continuity of F, the corresponding probability
measure possesses a density (cf. [Coh13]).
Proposition 1.7.17. Let F be the distribution function of a probability measure P. If F is
continuous and continuously differentiable with the exception of at most ï¬nitely many
points, then P is continuous. That is, there is a density function p such that
F(t) = P((â€“âˆ, t]) =
 t
â€“âˆ
p(x) dx ,
t âˆˆR .
Remark 1.7.18. Proposition 1.7.15 implies p(t) = Fâ€²(t) for those t where Fâ€²(t) exists. If F
is not differentiable at t, deï¬ne p(t) somehow, for example, p(t) = 0.
Example 1.7.19. For some !, " > 0 deï¬ne F by
F(t) =

0
: t â‰¤0
1 â€“ eâ€“! t" : t > 0

64
1 Probabilities
It is easy to see that this function satisï¬es the properties of Proposition 1.7.9. Moreover,
it is continuous and continuously differentiable on R\{0}. By Proposition 1.7.17 the
corresponding probability measure P is continuous and since
Fâ€²(t) =

0
: t < 0
! " t"â€“1 eâ€“!t" : t > 0 .
a suitable density function is p(t) = Fâ€²(t), t /= 0, and p(0) = 0.
1.8 Multivariate Continuous Distributions
1.8.1 Multivariate Density Functions
In this section we suppose that K = Rn. A subset Q âŠ‚Rn is called a (closed,
n-dimensional) box17 provided that for some real numbers ai < bi, 1 â‰¤i â‰¤n,
Q = {(x1, . . . , xn) âˆˆRn : ai â‰¤xi â‰¤bi , 1 â‰¤i â‰¤n} .
(1.65)
Deï¬nition 1.8.1. A Riemann integrable function p : Rn â†’R is said to be an
n-dimensional probability density function or shorter n-dimensional density
function if p(x) â‰¥0 for x âˆˆRn and, furthermore,

Rn p(x) dx :=
 âˆ
â€“âˆ
â‹…â‹…â‹…
 âˆ
â€“âˆ
p(x1, . . . , xn) dxn â‹…â‹…â‹…dx1 = 1 .
Suppose a box Q is represented with certain ai < bi as in eq. (1.65). Then we set
P(Q) =

Q
p(x) dx =
 b1
a1
â‹…â‹…â‹…
 bn
an
p(x1, . . . , xn) dxn â‹…â‹…â‹…dx1.
(1.66)
In analogy to Deï¬nition 1.1.15 we introduce now the Borel 3-ï¬eld B(Rn).
Deï¬nition 1.8.2. Let C be the collection of all boxes in Rn. Then 3(C) := B(Rn) de-
notes the Borel 3-ï¬eld18. In other words, B(Rn) is the smallest 3-ï¬eld containing
all (closed) boxes in Rn. Sets in B(Rn) are called (n-dimensional) Borel sets.
17 Also called â€œhyper-rectangle.â€
18 Recall that the existence of 3(C) was proven in Proposition 1.1.12.

1.8 Multivariate Continuous Distributions
65
Remark 1.8.3. As in the univariate case there exist several other collections of subsets
in Rn generating B(Rn). For example, one may choose the collection of open boxes or
the sets, which may be written as
(â€“âˆ, t1] Ã— â‹…â‹…â‹…Ã— (â€“âˆ, tn] ,
t1, . . . , tn âˆˆR .
With the previous notations, the following multivariate extension theorem is valid.
Compare Proposition 1.5.6 for the univariate case.
Proposition 1.8.4. Let P be deï¬ned on boxes by eq. (1.66). Then P admits a unique
extension to a probability measure P on B(Rn).
Deï¬nition 1.8.5. A probability measure P on B(Rn) is called continuous provided
that there exists a probability density p : Rn â†’R such that P(Q) =
#
Q p(x) dx for
all boxes Q âŠ†Rn. The function p is said to be the density function or simply
density of P.
Remark 1.8.6. It is easy to see that the validity of eq. (1.66) for all boxes is equivalent
to the following. If tj âˆˆR and Bt1, ... ,tn := (â€“âˆ, t1] Ã— â‹…â‹…â‹…Ã— (â€“âˆ, tn], then
P(Bt1, ... ,tn) =

Bt1, ... ,tn
p(x) dx =
 t1
â€“âˆ
â‹…â‹…â‹…
 tn
â€“âˆ
p(x1, . . . , xn) dxn â‹…â‹…â‹…dx1 .
(1.67)
Thus P is continuous if and only if eq. (1.67) is satisï¬ed for all tj âˆˆR.
Let us ï¬rst give an example of a multivariate probability density function.
Example 1.8.7. Regard p : R3 â†’R deï¬ned by
p(x1, x2, x3) =

48 x1 x2 x3 : 0 â‰¤x1 â‰¤x2 â‰¤x3 â‰¤1
0
:
otherwise
Of course, p(x) â‰¥0 for x âˆˆR3. Moreover,

R3 p(x) dx = 48
 1
0
 x3
0
 x2
0
x1x2x3 dx1dx2dx3
= 48
 1
0
 x3
0
x3 x3
2
2
dx2 dx3 = 48
 1
0
x5
3
8 dx3 = 1 ,

66
1 Probabilities
hence it is a density function on R3. For example, if P is the generated probability
measure, then
P([0, 1/2]3) = 48
1/2

0
x3

0
x2

0
x1x2x3 dx1dx2dx3 = 1
26 = 1
64 .
1.8.2 Multivariate Uniform Distribution
Our next aim is the introduction and the investigation of a special multivariate distri-
bution, the uniform distribution on a set K in Rn. To do so we remember as we deï¬ned
the uniform distribution on an interval I in R. Its density p is given by
p(s) =
 1
|I| : s âˆˆI
0 : s âˆ‰I
Here |I| denotes the length of the interval I. Let now K âŠ‚Rn be bounded. In order to
introduce a similar density for the uniform distribution on K, the length of the under-
lying set has to be replaced by the n-dimensional volume, which we will denote by
voln(K). But how is this volume deï¬ned?
To answer this question let us ï¬rst investigate a box Q represented as in eq. (1.65).
It is immediately clear that its n-dimensional volume is evaluated by
voln(Q) =
n
%
i=1
(bi â€“ ai) .
If n = 1, then Q is an interval and its one-dimensional volume is nothing else as its
length. For n = 2 the box Q is the rectangle [a1, b1] Ã— [a2, b2] and
vol2(Q) = (b1 â€“ a1)(b2 â€“ a2)
coincides with the area of Q. If n = 3, then vol3(Q) is the ordinary volume of bod-
ies in R3.
For arbitrary K âŠ‚Rn the deï¬nition of its volume voln(K) is more involved. Let us
shortly sketch one way how this can be done. Setting
voln(K) := inf
â§
â¨
â©
âˆ

j=1
voln(Qj) : K âŠ†
âˆ
	
j=1
Qj , Qj box
â«
â¬
â­,
(1.68)
at least for Borel sets K âŠ†Rn a suitable volume is deï¬ned. In the case of â€œordinaryâ€
sets as balls, ellipsoids, or similar bodies this approach leads to the known values.
Background is the basic formula
voln(K) =

â‹¯

K
1 dxn â‹…â‹…â‹…dx1
(1.69)

1.8 Multivariate Continuous Distributions
67
valid for Borel sets K âŠ†Rn. For example, if K is the cube in R2 with corner points (1, 0),
(0, 1), (â€“1, 0), and (0, â€“1), then
vol2(K) =

K
1 dx2dx1 =
0

â€“1
1+x1

â€“x1â€“1
dx2dx1 +
1

0
1â€“x1

x1â€“1
dx2dx1
= 2
# 0
â€“1(x1 + 1)dx1 + 2
# 1
0(1 â€“ x1)dx1 = 2

x2
1
2 + x1
0
â€“1
+ 2

x1 â€“
x2
1
2
1
0
= 2 .
Example 1.8.8. Let Kn(r) be the n-dimensional ball of radius r > 0, that is,
Kn(r) = {x âˆˆRn : |x| â‰¤r} = {(x1, . . . , xn) âˆˆRn : x2
1 + â‹…â‹…â‹…+ x2
n â‰¤r2} .
If
Vn(r) := voln(Kn(r)) ,
r > 0 ,
denotes the n-dimensional volume of this ball, an easy change of variables implies
Vn(r) = Vn â‹…rn, where Vn = Vn(1). But for Kn = Kn(1) eq. (1.69) gives
Vn =

â‹¯

Kn
1 dxn â‹…â‹…â‹…dx1 =
 1
â€“1
)

â‹¯

{x2
2+ â‹…â‹…â‹…+x2nâ‰¤1â€“x2
1}
1 dxn â‹…â‹…â‹…dx2
*
dx1
=
 1
â€“1
Vnâ€“1
+
1 â€“ x2
1

dx1 =
 1
â€“1
Vnâ€“1
âˆš
1 â€“ s2

ds .
Hence, by Vnâ€“1(r) = rnâ€“1 Vnâ€“1(1) = rnâ€“1 Vnâ€“1 we obtain
Vn = Vnâ€“1 â‹…
 1
â€“1
(1 â€“ s2)(nâ€“1)/2 ds = 2 Vnâ€“1 â‹…
 1
0
(1 â€“ s2)(nâ€“1)/2 ds .
The change of the variables s = y1/2, thus ds = 1
2 yâ€“1/2 dy, yields
Vn = Vnâ€“1 â‹…
 1
0
yâ€“1/2(1 â€“ y)(nâ€“1)/2 dy = Vnâ€“1 B
1
2 , n + 1
2

= âˆš0 Vnâ€“1
A

n+1
2

A

n
2 + 1

 .
Hereby we used eq. (1.59) as well as A(1/2) = âˆš0. Starting with V1 = 2, a recursive
application of the last formula ï¬nally leads to
voln(Kn(r)) = Vn(r) =
0n/2
A

n
2 + 1

 rn = 2 0n/2
n A
 n
2
 rn ,
r > 0 .

68
1 Probabilities
If we distinguish between even and odd dimensions, properties of the A-function
imply
V2k(r) = 0k
k! r2k
and
V2k+1(r) =
2k+10k
(2k + 1)!! r2k+1
where (2k + 1)!! = 1 â‹…3 â‹…5 â‹…â‹…â‹…(2k â€“ 1)(2k + 1).
After the question about the volume is settled we are now in the position to introduce
the uniform distribution on bounded Borel sets in Rn. Thus let K âŠ†Rn be a bounded
Borel set in Rn with volume voln(K). Deï¬ne p : Rn â†’R by
p(x) :=

1
voln(K) : x âˆˆK
0
: x âˆ‰K .
(1.70)
Proposition 1.8.9. The function p deï¬ned by eq. (1.70) is an (n-dimensional) probability
density function.
Proof: By virtue of eq. (1.69) follows

Rn p(x) dx =

K
1
voln(K) dx =
1
voln(K)

â‹¯

K
1 dxn â‹…â‹…â‹…dx1
= voln(K)
voln(K) = 1 .
Since p(x) â‰¥0 if x âˆˆRn, as asserted, p is a probability density function.
âˆ
Deï¬nition 1.8.10. The probability measure P on (Rn, B(Rn)) with density p given
by eq. (1.70) is said to be the (multivariate) uniform distribution on K.
Let P be the uniform distribution on K. How do we get P(B) for a Borel set B? Let us
ï¬rst assume B âŠ†K. Then
P(B) =

B
p(x) dx =
1
voln(K)

â‹¯

B
1 dxn â‹…â‹…â‹…dx1 = voln(B)
voln(K) .
If B âŠ†Rn is arbitrary, that is, B is not necessarily a subset of K, by P(B) = P(B âˆ©K) it
follows that19
19 This is an alternative way to introduce the uniform distribution on K.

1.8 Multivariate Continuous Distributions
69
P(B) = voln(B âˆ©K)
voln(K)
.
If n = 1 and K is an interval the last formula coincides with eq. (1.45).
Example 1.8.11. Two friends agree to meet each other in a restaurant between 1 and
2 pm. Both friends go to the restaurant randomly during this hour. After they arrive
they wait 20 minutes each. What is the probability that they meet each other?
Answer: Let t1 be the moment where the ï¬rst of the two friends enters the restaur-
ant, while t2 is the arrival time of the second one. They arrive independently of each
other, thus we may assume that the point t := (t1, t2) is uniformly distributed in the
square Q := [1, 2]2. Observing that 20 minutes are a third of an hour, they meet each
other if and only if |t1 â€“ t2| â‰¤1/3.
Setting B := {(t1, t2) âˆˆR2 : |t1 â€“ t2| â‰¤1/3}, it is easy to see that vol2(B âˆ©Q) = 5/9.
Hence, if P is the uniform distribution on Q, because of vol2(Q) = 1 it follows P(B) =
5/9. Therefore, the probability that the friends meet each other equals 5/9.
Example 1.8.12. Suppose n particles are uniformly distributed in a ball KR of radius
R > 0. Let Kr be a smaller ball of radius r > 0 contained in KR. Find the probability that
exactly k of the n particles are inside Kr for some k = 0, . . . , n.
Answer: In a ï¬rst step we determine the probability that a single particle is in Kr.
Since we assumed that the particles are uniformly distributed in KR, this probability
equals
p := vol3(Kr)
vol3(KR) = (4/3)0r3
(4/3)0R3 =
 r
R

3
.
For each of the n particles this p is the â€œsuccessâ€ probability to be inside Kr, hence the
number of particles in Kr is Bn,p-distributed with p = (r/R)3. Thus,
P{k particles in Kr} = Bn,p({k}) =
n
k
  r
R

3k R â€“ r
R
3(nâ€“k)
, k = 0, . . . , n .
If the number n of particles is big and r is much smaller than R, then the number of
particles in Kr is approximately Pois+ distributed, where + = n p = nr3
R3 . In other words,
P{k particles in Kr} â‰ˆ1
k!
nr3
R3
k
eâ€“nr3/R3 .

70
1 Probabilities
Example 1.8.13 (Buffonâ€™s needle test). Take a needle of length a < 1 and throw it
randomly on a lined sheet of paper. Say the distance between two lines on the paper
is 1. Find the probability that the needle cuts a line.
Answer: What is random in this experiment? Choose the two lines such that
between them the midpoint of the needle lies. Let x âˆˆ[0, 1] be the distance of the
midpoint of the needle to the lower line. Furthermore, denote by ( âˆˆ[â€“0/2, 0/2] the
angle of the needle to a line perpendicularly to the lines on the paper. For example, if
( = 0, then the needle is perpendicular to the lines on the paper while for ( = Â±0/2 it
lies parallel.
Hence, to throw a needle randomly is equivalent to choosing a point ((, x)
uniformly distributed in K = [â€“0/2, 0/2] Ã— [0, 1].
The needle cuts the lower line if and only if a
2 cos ( â‰¥x and it cuts the upper line
provided that a
2 cos ( â‰¥1 â€“ x.
If
A = {((, x) âˆˆ[â€“0/2, 0/2] Ã— [0, 1] : x â‰¤a
2 cos (
or
1 â€“ x â‰¤a
2 cos (} ,
then we get
P{The needle cuts a line} = P(A) = vol2(A)
vol2(K) = vol2(A)
0
.
But it follows
vol2(A) = 2
 0/2
â€“0/2
a
2 cos ( d( = 2a ,
hence
P(A) = 2a
0 .
Remark 1.8.14. Suppose we throw the same needle n times. Let rn be the relative
frequency of the occurrence of A, that is,
rn = Number of throws where the needle cuts a line
n
.
As mentioned in Section 1.1.3, if n â†’âˆ, then rn approaches P(A) = 2a
0 . Thus for large n
we have rn â‰ˆ2a
0 or, equivalently, 0 â‰ˆ2a
rn . Consequently, throwing the needle sufï¬ciently
often, 2a
rn should be close to 0.

1.9 â‹†Products of Probability Spaces
71
1.9
â‹†Products of Probability Spaces
1.9.1 Product 3-Fields and Measures
Suppose we execute n (maybe different) random experiments so that the outcomes
do not depend on each other. In order to describe these n experiments two different
approaches are possible. Firstly, we record each single result separately, that is, we
have n (maybe different) probability spaces (K1, A1, P1) to (Kn, An, Pn) modeling the
outcomes of the ï¬rst up to the nth experiment.
A second possible approach is that we combine the n experiments into a single
one. Thus, instead of n different outcomes 91 to 9n, we observe now a vector 9 =
(91, . . . , 9n). The sample space in this approach is given by K = K1 Ã— â‹…â‹…â‹…Ã— Kn.
Example 1.9.1. When rolling a die n times the outcome is a series of n numbers 91 to
9n, each in {1, . . . , 6}. Now, imagine we have a die with 6n equally likely faces. On
these faces, all possible sequences of length n with entries from {1, . . . , 6} are written.
Roll this die once. The ï¬rst experiment may be described by n probability spaces, one
for each roll. The second experiment involves only one probability space. Neverthe-
less, both experiments lead to the same result, a random sequence of numbers from 1
to 6.
It is intuitively clear that both approaches to this experiment (rolling a die n times) are
equivalent; they differ only by the point of view. But how to come from one model
to the other? One direction is immediately clear. If the random result is a vector
9 = (91, . . . , 9n), then its coordinates may be taken as the results of the single experi-
ments20. But how about the other direction? That is, we are given n probability spaces
(K1, A1, P1), . . . , (Kn, An, Pn) and have to construct a model for the joint execution of
these experiments.
Of course, the â€œnewâ€ sample space is
K = K1 Ã— â‹…â‹…â‹…Ã— Kn ,
(1.71)
but what are A and P ? We start with the construction of the product 3-ï¬eld.
Deï¬nition 1.9.2. Let Aj be 3-ï¬elds on Kj, 1 â‰¤j â‰¤n. Set K = K1 Ã— â‹…â‹…â‹…Ã— Kn. Then
A = 3{A1 Ã— â‹…â‹…â‹…Ã— An : Aj âˆˆAj}
is called the product 3-ï¬eld of A1 to An. It is denoted by A = A1 âŠ—â‹…â‹…â‹…âŠ—An.
20 Of course, one still has to verify that the distribution of the coordinates is the same as in the single
experiments. But before we can do this we need a probability measure describing the distribution of
the vectors (cf. Proposition 1.9.8).

72
1 Probabilities
Remark 1.9.3. In other words, A is the smallest 3-ï¬eld containing measurable rect-
angle sets, that is, sets of the form A1 Ã— â‹…â‹…â‹…Ã— An with Aj âˆˆAj, 1 â‰¤j â‰¤n.
It is easy to see that P(K1) âŠ—â‹…â‹…â‹…âŠ—P(Kn) = P(K). A more complicated example is as
follows.
Proposition 1.9.4. Suppose K1 = â‹…â‹…â‹…= Kn = R, hence K = Rn. Then the 3-ï¬eld B(Rn)
of Borel sets in Rn is the n-fold product of the 3-ï¬elds B(R) of Borel sets in R, that is,
B(Rn) = B(R) âŠ—â‹…â‹…â‹…âŠ—B(R)



n times
.
Proof: We only give a sketch of the proof. Let Q be a box as in eq. (1.65). Then Q =
A1 Ã— â‹…â‹…â‹…Ã— An, where the Ajs are intervals, hence in B(R). By the construction of the
product 3-ï¬eld it follows that Q âˆˆB(R) âŠ—â‹…â‹…â‹…âŠ—B(R). But B(Rn) is the smallest 3-ï¬eld
containing all boxes, which lets us conclude
B(Rn) âŠ†B(R) âŠ—â‹…â‹…â‹…âŠ—B(R) .
The inclusion in the other direction may be proved as follows: ï¬x a2 < b2 to an < bn
and let
C1 = {C âˆˆB(R) : C Ã— [a2, b2] Ã— â‹…â‹…â‹…[an, bn] âˆˆB(Rn)} .
It is not difï¬cult to prove that C1 is a 3-ï¬eld. If C = [a1, b1], then CÃ—[a2, b2]Ã— â‹…â‹…â‹…[an, bn]
is a box, thus in B(Rn). Consequently, C1 contains closed intervals, hence, since B(R)
is the smallest 3-ï¬eld with this property, it follows C1 = B(R). This tells us that for all
B1 âˆˆB(R) and all aj < bj
B1 Ã— [a2, b2] Ã— â‹…â‹…â‹…Ã— [an, bn] âˆˆB(Rn) .
In a next step ï¬x B1 âˆˆB(R) and a3 < b3 up to an < bn and set
C2 = {C âˆˆB(R) : B1 Ã— C Ã— [a3, b3] Ã— â‹…â‹…â‹…[an, bn] âˆˆB(Rn)} .
By the same arguments as before, but now using the ï¬rst step, we get C2 = B(R),
that is,
B1 Ã— B2 Ã— [a3, b3] Ã— â‹…â‹…â‹…[an, bn] âˆˆB(Rn)
for all B1, B2 âˆˆB(R) and aj < bj.
Iterating further we ï¬nally obtain that for all Bj âˆˆB(R) it follows that
B1 Ã— â‹…â‹…â‹…Ã— Bn âˆˆB(Rn) .

1.9 â‹†Products of Probability Spaces
73
Since B(R)âŠ—â‹…â‹…â‹…âŠ—B(R) = 3{B1 Ã— â‹…â‹…â‹…Ã—Bn : Bj âˆˆB(R)} is the smallest 3-ï¬eld containing
sets B1 Ã— â‹…â‹…â‹…Ã— Bn, this implies
B(R) âŠ—â‹…â‹…â‹…âŠ—B(R) âŠ†B(Rn)
and completes the proof.
âˆ
Let us now turn to the probability measure P on (K, A) that describes the combined
experiment.
Deï¬nition 1.9.5. Let (K1, A1, P1) to (Kn, An, Pn) be n probability spaces. Deï¬ne K
by eq. (1.71) and endow it with the product 3-ï¬eld A = A1âŠ—â‹…â‹…â‹…âŠ—An. A probability
measure P on (K, A) is called the product measure of P1, . . . , Pn if
P(A1 Ã— â‹…â‹…â‹…Ã— An) = P1(A1) â‹…â‹…â‹…Pn(An)
for all
Aj âˆˆAj .
(1.72)
We write P = P1 âŠ—â‹…â‹…â‹…âŠ—Pn and if P1 = â‹…â‹…â‹…Pn = P0 set
PâŠ—n
0
:= P0 âŠ—â‹…â‹…â‹…âŠ—P0



ntimes
.
It is not clear at all whether product measures exist, and if this is so, whether condi-
tion (1.72) determines them uniquely. The next result shows that the answer to both
questions is afï¬rmative. Unfortunately, the proof is too complicated to be presented
here. The idea is quite similar to that used in the introduction of volumes in eq. (1.68).
The boxes appearing there have to be replaced by rectangle sets A1 Ã—â‹…Ã—An with Aj âˆˆAj
and the volume of the boxes by P1(A1) â‹…â‹…â‹…Pn(An). We refer to [Dur10], Section 1.7, or
[Coh13], for a detailed proof for the existence (and uniqueness) of product measures.
Proposition 1.9.6. Let (K1, A1, P1), . . . , (Kn, An, Pn) be probability spaces. Deï¬ne K by
eq. (1.71) and let A be the product 3-ï¬eld of the Aj. Then there is a unique probability
measure P on (K, A) satisfying eq. (1.72). Hence, the product measure P = P1 âŠ—â‹…â‹…â‹…âŠ—Pn
always exists and is uniquely determined by eq. (1.72).
Corollary 1.9.7. Let P1, . . . , Pn be probability measures on (R, B(R)). Then there is a
unique probability measure P on (Rn, B(Rn) such that
P(B1 Ã— â‹…â‹…â‹…Ã— Bn) = P1(B1) â‹…â‹…â‹…Pn(Bn)
for all
Bj âˆˆB(R) .
Proof: The proof is a direct consequence of Propositions 1.9.6 and 1.9.4. Indeed, take
P = P1 âŠ—â‹…â‹…â‹…âŠ—Pn and observe that B(Rn) = B(R) âŠ—â‹…â‹…â‹…âŠ—B(R).
âˆ

74
1 Probabilities
Let us shortly come back to the question asked at the beginning of this section.
Suppose we observe a vector 9 = (91, . . . , 9n). How are the coordinates distributed?
Proposition 1.9.8. Let (K, A, P) be the product probability space of (K1, A1, P1) to
(Kn, An, Pn). If j â‰¤n and A âˆˆAj, then
P{(91, . . . , 9n) âˆˆK : 9j âˆˆA} = Pj(A) .
Proof: Observe that
{(91, . . . , 9n) âˆˆK : 9j âˆˆA} = K1 Ã— â‹…â‹…â‹…Kjâ€“1 Ã— A Ã— Kj+1 Ã— â‹…â‹…â‹…Kn ,
thus eq. (1.72) implies
P{(91, . . . , 9n) âˆˆK : 9j âˆˆA} = P1(K1) â‹…â‹…â‹…Pjâ€“1(Kjâ€“1) â‹…Pj(A) â‹…â‹…â‹…Pn(Kn) = Pj(A)
as asserted.
âˆ
How do we get product measures in concrete cases? We answer this question for
discrete and continuous probability measures separately.
1.9.2 Product Measures: Discrete Case
Let K1 to Kn be either ï¬nite or countably inï¬nite sets. Given probability measures Pj
deï¬ned on P(Kj), 1 â‰¤j â‰¤n, the following result characterizes the product measure of
the Pjs.
Proposition 1.9.9. P is the product measure of P1, . . . , Pn if and only if
P({9}) = P1({91}) â‹…â‹…â‹…Pn({9n})
for all
9 = (91, . . . , 9n) âˆˆK .
(1.73)
Proof: One direction is easy. Indeed, if P = P1 âŠ—â‹…â‹…â‹…âŠ—Pn, given 9 = (91, . . . , 9n) âˆˆK
set A = {9} and Aj = {9j}. Then A = A1 Ã— â‹…â‹…â‹…Ã— An, hence
P({9}) = P(A) = P1(A1) â‹…â‹…â‹…Pn(An) = P1({91}) â‹…â‹…â‹…Pn({9n})
proving eq. (1.73).
To verify the other implication let P be a probability measure on (K, P(K)) satisfy-
ing (1.73). We have to show that P fulï¬lls eq. (1.72). Thus choose arbitrary Aj âŠ†Kj and
set A = A1 Ã— â‹…â‹…â‹…Ã— An. By applying eq. (1.73) it follows

1.9 â‹†Products of Probability Spaces
75
P(A) =

9âˆˆA
P({9}) =

(91, ... ,9n)âˆˆA
P({(91, . . . , 9n)})
=

91âˆˆA1, ... 9nâˆˆAn
P1({91}) â‹…â‹…â‹…Pn({9n})
=

91âˆˆA1
P1({91}) â‹…â‹…â‹…

9nâˆˆAn
Pn({9n}) = P1(A1) . . . Pn(An) .
This being true for all Aj âŠ†Kj shows that P = P1 âŠ—â‹…â‹…â‹…âŠ—Pn, and the proof is
complete.
âˆ
Summary: In the discrete case the product measure is characterized as follows. Given
A âŠ†K, then
(P1 âŠ—â‹…â‹…â‹…âŠ—Pn)(A) =

(91, ... ,9n)âˆˆA
P1({91}) â‹…â‹…â‹…Pn({9n}) .
Example 1.9.10. Suppose two players, say U and V, each toss simultaneously a biased
coin. At both coins appears â€œ0â€ (failure) with probability 1 â€“ p and â€œ1â€ (success)
with probability p. The pair (k, l) âˆˆN2 occurs if player U has his ï¬rst success in
trial k and player V in trial l. Each single experiment is described by the geometric
distribution Gp, hence the model for the combined experiment is (N2, P(N2), GâŠ—2
p ).
Here
GâŠ—2
p (A) =

(k,l)âˆˆA
Gp({k})Gp({l}) =

(k,l)âˆˆA
p2(1 â€“ p)k+lâ€“2 ,
A âŠ†N2 .
For example, if A = {(k, k) : k â‰¥1}, then
GâŠ—2
p (A) = p2
âˆ

k=1
(1 â€“ p)2kâ€“2 =
p2
1 â€“ (1 â€“ p)2 =
p
2 â€“ p .
Thus in the case of a fair coin, the probability that both players have their ï¬rst success
at the same time equals 1/3.
Example 1.9.11. Toss a biased coin n times. Say the coin is labeled with â€œ0â€ and â€œ1â€
and p âˆˆ[0, 1] is the probability of the occurrence of â€œ1.â€ Recording each single result
separately the describing probability spaces are ({0, 1}, P({0, 1}), Pj), 1 â‰¤j â‰¤n, with
Pj({1}) = p. Which probability space does the combined result describe?

76
1 Probabilities
Answer: Of course, the sample space is {0, 1}n with 3-ï¬eld P(K). Let 9
=
(91, . . . , 9n) be an arbitrary vector in K. Then by Proposition 1.9.9 the product measure
P of the Pjs is characterized by
P({9}) = P1({91}) â‹…â‹…â‹…Pn({9}) = pk(1 â€“ p)nâ€“k
where k = #{j â‰¤n : 9j = 1} = n
j=1 9j .
For example, tossing the coin ï¬ve times, the sequence (0, 0, 1, 1, 0) occurs with
probability p2 (1 â€“ p)3.
1.9.3 Product Measures: Continuous Case
Here we assume K1 = â‹…â‹…â‹…= Kn = R, hence the product sample space is K = Rn.
Furthermore, each Kj = R is endowed with the Borel 3-ï¬eld. Because of Proposition
1.9.4 the product 3-ï¬eld on K = Rn is given by B(Rn).
The next proposition characterizes the product measure of continuous probability
measures.
Proposition 1.9.12. Let P1, . . . , Pn be probability measures on (R, B(R)) with respect-
ive density functions p1, . . . , pn, that is,
Pj([a, b]) =
 b
a
pj(x)dx ,
1 â‰¤j â‰¤n .
Deï¬ne p : Rn â†’[0, âˆ) by
p(x) = p1(x1) â‹…â‹…â‹…pn(xn) ,
x = (x1, . . . , xn) âˆˆRn .
(1.74)
The product measure P1 âŠ—â‹…â‹…â‹…âŠ—Pn is continuous with (n-dimensional) density p deï¬ned
by (1.74). In other words, for each Borel set A âŠ†Rn holds
(P1 âŠ—â‹…â‹…â‹…âŠ—Pn)(A) =

â‹…â‹…â‹…




A
p1(x1) â‹…â‹…â‹…pn(xn) dxn â‹…â‹…â‹…dx1 =

A
p(x) dx .
Proof: First note that p is a density of the product measure P1 âŠ—â‹…â‹…â‹…âŠ—Pn if
(P1 âŠ—â‹…â‹…â‹…âŠ—Pn)(Q) =

Q
p(x) dx

1.9 â‹†Products of Probability Spaces
77
for all boxes Q = [a1, b1] Ã— â‹…â‹…â‹…Ã— [an, bn]. But this is an immediate consequence of

Q
p(x) dx =
 b1
a1
â‹…â‹…â‹…
 bn
an
p1(x1) â‹…â‹…â‹…pn(xn) dxn â‹…â‹…â‹…dx1
=
 b1
a1
p1(x1) dx1

â‹…â‹…â‹…
 bn
an
pn(xn) dxn

= P1([a1, b1]) â‹…â‹…â‹…Pn([an, bn])
= (P1 âŠ—â‹…â‹…â‹…âŠ—Pn)([a1, b1] Ã— â‹…â‹…â‹…Ã— [an, bn]) = (P1 âŠ—â‹…â‹…â‹…âŠ—Pn)(Q) .
This completes the proof.
âˆ
Because of its importance let us explain through several examples how Proposition
1.9.12 applies. Further applications, for example, the characterization of independent
random variables, will follow in Sections 3 and 8.
Example 1.9.13. Let the probability measures Pj, 1 â‰¤j â‰¤n, be uniform distributions
on [!j, "j]. Thus
pj(x) =

1
"jâ€“!j : !j â‰¤x â‰¤"j
0
: otherwise
henceforth, if x = (x1, . . . , xn), then
p(x) = p1(x1) â‹…â‹…â‹…pn(xn) =

1
,
jâ‰¤n("jâ€“!j) :
x âˆˆK
0
: otherwise
Here K âŠ†Rn is the box [!1, "1] Ã— â‹…â‹…â‹…Ã— [!n, "n]. Since ,
jâ‰¤n("j â€“ !j) = voln(K), it follows
that the product measure P1 âŠ—â‹…â‹…â‹…âŠ—Pn is nothing else as the (n-dimensional) uniform
distribution on K as introduced in21 Deï¬nition 1.8.10.
Summary: The product measure of n uniform distributions on intervals [!j, "j] is the
uniform distribution on the box [!1, "1] Ã— â‹…â‹…â‹…Ã— [!n, "n].
Example 1.9.14. Assume now P1 = â‹…â‹…â‹…= Pn = E+, that is, we want to describe the
product of n exponential distributions with parameter + > 0. Since pj(s) = +eâ€“+s if
s â‰¥0 and pj(s) = 0 if s < 0, their product EâŠ—n
+
possesses the density
p(s1, . . . , sn) =

+n eâ€“+(s1+ â‹…â‹…â‹…+sn) : s1, . . . , sn â‰¥0
0
:
otherwise
Which random experiment does EâŠ—n
+
describe? Suppose we have n light bulbs of the
same type with lifetime distributed according to E+. Switch on all n bulbs at once and
21 This result was already used in Example 1.8.11. Indeed, the arrival times t1 and t2 were described
by the uniform distributions on [1, 2], thus the pair t = (t1, ts) is distributed according to the product
measure, which is the uniform distribution on [1, 2] Ã— [1, 2].

78
1 Probabilities
record the times t1, . . . , tn where the ï¬rst bulb, the second, and so on burns out. If
t = (t1, . . . , tn) âˆˆRn denotes the generated vector of these times, then for Borel sets
A âŠ†[0, âˆ)n,
P{t âˆˆA} = EâŠ—n
+ (A) = +n

A
eâ€“+(s1+ â‹…â‹…â‹…+sn)ds1 . . . dsn .
For example, if we want to compute the probability for
A := {(t1, . . . , tn) : 0 â‰¤t1 â‰¤â‹…â‹…â‹…â‰¤tn} ,
that is, the second bulb burns longer than the ï¬rst one, the third longer than the
second, and so on, then
EâŠ—n
+ (A) = +n
âˆ

0
eâ€“+sn
sn

0
eâ€“+snâ€“1
snâ€“1

0
â‹…â‹…â‹…
s3

0
eâ€“+s2
s2

0
eâ€“+s1 ds1 . . . dsn .
Iterative integration leads to EâŠ—n
+ (A) = 1/n!. This is more or less obvious by the follow-
ing observation. Each order of the times of failure is equally likely. And since there are
n! different ways to order these times, each order has probability 1/n!. In particular,
this is true for the order t1 â‰¤â‹…â‹…â‹…â‰¤tn.
Next is given another example of a product measure that will play a crucial role in
Sections 6 and 8.
Example 1.9.15. Let P1, . . . , Pn be standard normal distributions. The corresponding
densities are
pj(xj) =
1
âˆš
20
eâ€“x2
j /2 ,
1 â‰¤j â‰¤n .
Thus, by eq. (1.74) the density p of their product N(0, 1)âŠ—n coincides with
p(x) =
1
(20)n/2 eâ€“ n
j=1 x2
j /2 =
1
(20)n/2 eâ€“|x|2/2 ,
where |x| =
 n
j=1 x2
j

1/2
denotes the Euclidean distance of the vector x to 0 (compare
Section A.4).
Deï¬nition 1.9.16. The probability measure N(0, 1)âŠ—n on B(Rn) is called the n-
dimensional or multivariate standard normal distribution. It is described by
N(0, 1)âŠ—n(B) =
1
(20)n/2

B
eâ€“|x|2/2 dx .

1.10 Problems
79
2
1
0
â€“1
â€“2
2
1
0
â€“1
â€“2
Figure 1.10: The density of the two-dimensional standard normal distribution.
Example 1.9.17. Finally we describe the n-fold product measure of the normal distri-
bution N(,, 32) with , âˆˆR and 32 > 0. The densities are
pj(xj) =
1
âˆš
20 3
eâ€“(xjâ€“,)2/232 ,
hence, as in Example 1.9.15, setting with âƒ—, = (,, . . . , ,) âˆˆRn, the product N(,, 32)âŠ—n
may be represented as
N(,, 32)âŠ—n(B) =
1
(20)n/23n

B
eâ€“|xâ€“âƒ—,|2/232 dx ,
B âˆˆB(Rn) .
(1.75)
1.10 Problems
Problem 1.1. Let A, B, and C be three events in a sample space K. Express the following
events in terms of these sets:
â€¢ Only A occurs.
â€¢ At least one of the three events occurs.
â€¢ At most one of the three events occurs.
â€¢ Exactly two of the events occur.
â€¢ A and B occur, but C does not.
â€¢ At least two of the events occur.
â€¢ None of the events occurs.
â€¢ Not more than two of the events occur.
Problem 1.2. Suppose an urn contains black and white balls. Successively one draws
n balls out of the urn. The event Aj occurs if the ball drawn in the jth trial is white.
Hereby 1 â‰¤j â‰¤n. Express the following events B1, . . . , B4 in terms of the Ajs:

80
1 Probabilities
B1 = {All drawn balls are white}
B2 = {At least one of the balls is white}
B3 = {Exactly one of the drawn balls is white}
B4 = {All n balls possess the same color}
Determine the cardinalities #(Bj), j = 1, . . . , 4.
Problem 1.3. Let P be a probability measure on (K, A). Given A , B âˆˆA show that
P(ABB) = P(A) + P(B) â€“ 2P(A âˆ©B) .
Problem 1.4. The events A and B possess the probabilities P(A) = 1/3 and P(B) = 1/4.
Moreover, we know that P(A âˆ©B) = 1/6. Compute P(Ac), P(Ac âˆªB), P(A âˆªBc), P(A âˆ©Bc),
P(ABB), and P(Ac âˆªBc).
Problem 1.5 (Inclusionâ€“exclusion formula). Let (K, A, P) be a probability space and
let A1, . . . , An âˆˆA be some (not necessarily disjoint) events. Prove that
P
 n
	
j=1
Aj

=
n

k=1
(â€“1)k+1

1â‰¤j1< â‹…â‹…â‹…<jkâ‰¤n
P(Aj1 âˆ©â‹…â‹…â‹…âˆ©Ajk) .
Hint: One way to prove this is by induction over n, thereby using Proposition 1.2.3.
Problem 1.6. Use Problem 1.5 to investigate the following question: The numbers
from 1 to n are ordered randomly. All orderings are equally likely. What is the prob-
ability that there exists an integer m â‰¤n so that m is at position m of the ordering?
Determine the limit of this probability as n â†’âˆ.
Still another version of this problem. Suppose n persons attend a Christmas party.
Each of the n participants brings a present with him. These presents are collected,
mixed, and then randomly distributed among the guests. Compute the probability that
at least one of the participants gets his own present.
Problem 1.7. Suppose in an urn are N balls; k are white, l are red, and m are black.
Thus, k + l + m = N. Choose n balls out of the urn. Find a formula for the probability
that among the n chosen balls are those of all three colors. Investigate this problem if
1.
the chosen ball is always replaced and
2.
if n â‰¤N and the balls are not replaced.
Hint: If A is the event that all three colors appear then compute P(Ac). To this end write
Ac = A1 âˆªA2 âˆªA3 with suitable Ajs and apply Proposition 1.2.4.

1.10 Problems
81
Problem 1.8. Suppose events A and B occur both with probability 1/2. Prove that then
P(A âˆªB) = P(Ac âˆªBc) .
(1.76)
Does (1.76) remain valid assuming P(A) + P(B) = 1 instead of P(A) = P(B) = 1
2 ?
Problem 1.9. Three men and three women sit down randomly on six chairs in a row.
Find the probability that the three men and the three women sit side by side. What is
the probability that next to each woman sits a man (to the right or to the left)?
Problem 1.10. Let (K, A, P) be a probability space. Prove the following: Whenever
events A1, A2, . . . in A satisfy P(A1) = P(A2) = â‹…â‹…â‹…= 1, then this implies
P
 âˆ

j=1
Aj

= 1 .
Problem 1.11. (Paradox of Chevalier de MÃ©rÃ©). Chevalier de MÃ©rÃ© mentioned that
when rolling three fair nondistinguishable dice there are 6 different possibilities for
obtaining either 11 or 12 as the sum. Thus he concluded that both events (sum equals
11 or sum equals 12) should be equally likely. But experiments showed that this is not
the case. Why he was wrong and what are the correct probabilities for both events?
Problem 1.12. A man has forgotten an important phone number. He only remembers
that the seven-digit number contained three times â€œ1â€ and â€œ4â€ and â€œ6â€ twice each.
He dials the seven numbers in random order. Find the probability that he dialed the
correct one.
Problem 1.13. In an urn are n black and m red balls. One draws successively all n + m
balls (without replacement). What is the probability that the ball chosen last is red?
Problem 1.14. A man has in his pocket n keys to open a door. Only one of the keys
ï¬ts. He tries the keys one after the other until he has chosen the correct one. Given an
integer k compute the probability that the correct key is the one chosen in the kth trial.
Evaluate this probability in each of the two following cases:
â€“ The man always discards wrong keys.
â€“ The man does not discard them, that is, he puts back wrong keys.
Problem 1.15 (Monty Hall problem). At the end of a quiz the winner has the choice
between three doors, say A, B, and C. Behind two of the doors there is a goat, behind
the third one a car. His prize is what is behind the chosen door.
Say the winner has chosen door A. Then the quizmaster (who knows what is be-
hind each of the three doors) opens one of the two remaining doors (in our case either

82
1 Probabilities
door B or door C) and shows that there is a goat behind it. After that the quizmaster
asks the candidate whether or not he wants to revise his decision, that is, for example,
if B was opened, to switch from A to C, or if he furthermore chooses door A.
Find the probabilities to win the car in both cases (switching or nonswitching).
Problem 1.16. In a lecture room are N students. Evaluate the probability that at least
two of the students were born at the same day of a year (day and month of their
births are the same, but not necessarily the year). Hereby disregard leap years and
assume that all days in a year are equally likely. How big must N be in order that this
probability is greater than 1/2 ?
Problem 1.17. In an urn are balls labeled from 0 to 6 so that all numbers are equally
likely. Choose successively and with replacement three balls. Find the probability that
the three observed numbers sum up to 6.
Problem 1.18. When sending messages from A to B on average 3% are transmitted
falsely. Suppose 300 messages are sent. What is the probability that at least three mes-
sages are transmitted falsely? Evaluate the exact probability by using the binomial
distribution as well as the approximate probability by using the Poisson distribu-
tion. Compute the probability (exact and approximative one) that all messages arrive
correctly.
Problem 1.19. The number of accidents in a city per week is assumed to be Poisson
distributed with parameter 5. Find the probability that next week there will be either
two or three accidents. How likely is that there will be no accidents?
Problem 1.20. In a room are 12 men and 8 women. One randomly chooses 5 of the
20 persons. Given k âˆˆ{0, . . . , 5}, what is the probability that among the ï¬ve chosen
are exactly k women? How likely is it that among the ï¬ve persons are more women
than men?
Problem 1.21. Two players A and B take turns rolling a die. The ï¬rst to roll a â€œ6â€ wins.
Player A starts. Find the probability that A wins. Suppose now there is a third player C
and the order of rolling the die is given by ABCABCA â‹…â‹…â‹…. Find each players probability
of winning.
Problem 1.22. Two players, say A and B, toss a biased coin where â€œheadâ€ appears with
probability 0 < p < 1. Winner is who gets the ï¬rst â€œheadâ€. A starts, then B tosses twice,
then again A once, B twice, and so on. Determine the number p for which the game is
fair, that is, the probability that A (or B) wins is 1/2.
Problem 1.23. In an urn are 50 white and 200 red balls.

1.10 Problems
83
(1)
Take out 10 balls with replacement. What is the probability to observe four
white balls? Give the exact value via the binomial distribution as well as the
approximated one using the related Poisson distribution.
(2)
Next choose 10 balls without replacement. What is the probability to get four
white balls in this case?
(3)
The number of balls in the urn is as above. But now we choose the balls with
replacement until for the ï¬rst time a white ball shows up. Find the probability of
the following events:
(a) The ï¬rst white ball shows up in the fourth trial.
(b) The ï¬rst white ball appears strictly after the third trial.
(c) The ï¬rst white ball is observed in an even number of trials, that is, in the
second or in the fourth or in the sixth, and so on trial.
Problem 1.24. Place successively and independently four particles into ï¬ve boxes.
Thereby each box is equally likely. Find the probabilities of the following events:
A := {Each box contains at most one particle} and B := {All 4 particles are in the
same box}.
Problem 1.25. Investigate the following generalization of Example 1.4.44: in urn U0
are M balls and in urn U1 are N balls for some N, M â‰¥1. Choose U0 with probability 1â€“p
and U1 with probability p, and take out a ball from the chosen urn. Given 1 â‰¤m â‰¤M,
ï¬nd the probability that there are m balls left in U0 when choosing the last ball out
of U1. How do these probabilities change when 1 â‰¤m â‰¤N, and we assume that there
are m balls in U1 when choosing the last ball from U0 ?
Problem 1.26. Use properties of the A-function to compute for n âˆˆN
 âˆ
0
x2n eâ€“x2/2 dx
and
 âˆ
0
x2n+1 eâ€“x2/2 dx .
Problem 1.27. Prove formula (1.59) that relates the beta and the A-function.
Hint: Start with
A(x)A(y) =
âˆ

0
âˆ

0
uxâ€“1vyâ€“1eâ€“uâ€“v dudv
and change the variables as follows: u = f(z, t) = z t and v = g(z, t) = z (1 â€“ t), where
0 â‰¤z < âˆand 0 â‰¤t â‰¤1.
Problem 1.28. Prove that for 0 â‰¤k â‰¤n
n
k

=
1
(n + 1)B(n â€“ k + 1, k + 1)
where B(â‹…, â‹…) denotes Eulerâ€™s beta function (cf. formula (1.58)).

84
1 Probabilities
Problem 1.29. Write x âˆˆ[0, 1) as decimal fraction x = 0.x1x2 â‹…â‹…â‹…with xj âˆˆ{0, . . . , 9}.
Let
Aj = {x âˆˆ[0, 1) : xj = 1} .
If P denotes the uniform distribution on [0, 1], compute P(Aj) as well as P
âˆ
j=1 Aj

.
Compute the same probabilities if Aj = {x âˆˆ[0, 1) : xj = m} for some ï¬xed m âˆˆ
{0, . . . 9}.
Problem 1.30. Compute the distribution function of the Cauchy distribution (cf. Deï¬n-
ition 1.6.33).
Problem 1.31. Let F : R â†’[0, 1] be the distribution function of a probability measure.
Show that F possesses at most countably many points of discontinuity. Conclude from
this and Proposition 1.7.12 the following: If P is a probability measure on B(R), then
there are at most countably inï¬nite many t âˆˆR such that P({t}) > 0.
Problem 1.32. Let I be the distribution function of the standard normal distribution
introduced in eq. (1.62). Show the following properties of I.
1.
For t âˆˆR holds I(â€“t) = 1 â€“ I(t).
2.
If a > 0, then
N(0, 1)([â€“a, a]) = 2 I(a) â€“ 1 .
3.
Prove formulas (1.63), that is,
I(t) = 1
2

1 + erf
 tâˆš
2

and
erf(t) = 2I(
âˆš
2 t) â€“ 1 ,
t âˆˆR .
4.
Compute
lim
tâ†’âˆ
1 â€“ I(t)
tâ€“1eâ€“t2/2 .
Hint: Use lâ€™HÃ´pitaleâ€™s rule.
Problem 1.33 (Bertrand paradox). Consider an equilateral triangle inscribed in a
circle of radius r > 0. Suppose a chord of the circle is chosen at random. What is the
probability that the chord is longer than a side of the triangle?
In this form the problem allows different answers. Why? Because we did not deï¬ne
in which way the random chord is chosen.
1.
The â€œrandom endpointsâ€ method: Choose independently two uniformly distrib-
uted random points on the circumference of the circle and draw the chord joining
them.

1.10 Problems
85
2.
The â€œrandom radiusâ€ method: Choose a radius of the circle, that is, choose a ran-
dom angle in [0, 20], choose independently a point on the radius according to
the uniform distribution on [0, r], and construct the chord through this point and
perpendicular to the radius.
3.
The â€œrandom midpointâ€ method: Choose a point within the circle according to the
uniform distribution on the circle and construct a chord with the chosen point as
its midpoint.
Answer the above question about the length of the chord in each of the three cases.
Problem 1.34. A stick of length L > 0 is randomly broken into three pieces. Hereby we
assume that both points of break are uniformly distributed on [0, L] and independent
of each other. What is the probability that these three parts piece together to a triangle?

2 Conditional Probabilities and Independence
2.1 Conditional Probabilities
In order to motivate the deï¬nition of conditional probabilities, let us start with the
following easy example.
Example 2.1.1. Roll a fair die twice. The probability of the event â€œsum of both rolls
equals 5â€ is 1/9. Suppose now we were told that the ï¬rst roll was an even number.
Does this additional information make the event â€œsum equals 5â€ more likely? Or does
it even diminish the probability of its occurrence? To answer this question, we apply
the so-called technique of â€œrestricting the sample space.â€ Since we know that the
event B = {First roll is even} had occurred, we may rule out elements in Bc and re-
strict our sample space. Choose B as new sample space. Its cardinality is 18. Moreover,
under this condition, an event A occurs if and only if A âˆ©B does so. Hence, the â€œnewâ€
probability of A under condition B, written P(A|B), is given by
P(A|B) = #(A âˆ©B)
#(B)
= #(A âˆ©B)
18
.
(2.1)
In the question above, we asked for P(A|B), where
A = {Sum of both rolls equals 5} = {(1, 4), (2, 3), (3, 2), (4, 1)} .
Since A âˆ©B = {(2, 3), (4, 1)}, we obtain P(A|B) = 2/18 = 1/9. Consequently, in this case,
condition B does not change the probability of the occurrence of A.
Deï¬ne now A as a set of pairs adding to 6. Then P(A) = 5/36, while the condi-
tional probability remains 1/9. Note that now A âˆ©B = {(2, 4), (4, 2)}. Thus, in this case,
condition B makes the occurrence of A less likely.
Before we state the deï¬nition of conditional probabilities in the general case, let us
rewrite eq. (2.1) as follows:
P(A|B) = #(A âˆ©B)
#(B)
= #(A âˆ©B)/36
#(B)/36
= P(A âˆ©B)
P(B)
.
(2.2)
Equation (2.2) gives us a hint to introduce conditional probabilities in the general
setting.
Deï¬nition 2.1.2. Let (K, A, P) be a probability space. Given events A, B âˆˆA with
P(B) > 0, the probability of A under condition B is deï¬ned by
P(A|B) = P(A âˆ©B)
P(B)
.
(2.3)

2.1 Conditional Probabilities
87
Remark 2.1.3. If we know the values of P(Aâˆ©B) and P(B), then formula (2.3) allows us
to evaluate P(A|B). Sometimes, it happens that we know the values of P(B) and P(A|B)
and want to calculate P(A âˆ©B). In order to do this, we rewrite eq. (2.3) as
P(A âˆ©B) = P(B) P(A|B) .
(2.4)
In this way, we get the desired value of P(A âˆ©B). Formula (2.4) is called the law of
multiplication.
The next two examples show how this law applies.
Example 2.1.4. In an urn are two white and two black balls. Choose two balls without
replacing the ï¬rst one. We want to evaluate the probability of occurrence of a black
ball in the ï¬rst draw and of a white in the second one. Let us ï¬rst ï¬nd a suitable
mathematical model that describes this experiment. The sample space is given by
K = {(b, b), (b, w), (w, b), (w, w)}, and we regard the events
A : = {Second ball is white} = {(b, w), (w, w)}
as well as
B : = {First ball is black} = {(b, b), (b, w)} .
The event of interest is then A âˆ©B = {(b, w)}.
Which probabilities can be directly determined? Of course, the probability of oc-
currence of B equals 1/2 because the number of white and black balls is the same.
Furthermore, if B occurred, then in the urn remained two white balls and one black
ball. Under this condition, event A occurs with probability 2/3, that is, P(A|B) = 2/3.
Using eq. (2.4), we obtain
P({(b, w)}) = P(A âˆ©B) = P(B) â‹…P(A|B) = 1
2 â‹…2
3 = 1
3 .
Example 2.1.5. Among three non-distinguishable coins are two fair and one is biased.
Tossing the biased coin â€œheadâ€ appears with probability 1/3, hence â€œtailâ€ appears
with probability 2/3. We choose by random one of the three coins and toss it. Find
the probability to observe â€œtailâ€ at the biased coin.
To solve this problem, let us ï¬rst mention that the sample space K = {H, T} is not
adequate to describe that experiment. Why? Because the event {H} may have different
probabilities depending on occurrence at a biased or at a fair coin. We have to dis-
tinguish between the appearance of â€œheadâ€ or â€œtailâ€ at the different types of coins.
Hence, an adequate choice of the sample space is
K := {(H, B), (T, B), (H, F), (T, F)} .

88
2 Conditional Probabilities and Independence
Here, B stands for biased and F assigns that the coin was fair. The event of interest is
{(T, B)}. Set
T := {(T, B), (T, F)}
as well as
B := {(H, B), (T, B)} .
Then T occurs if â€œtailâ€ appears regardless of the type of the coin while B occurs if we
have chosen the biased coin. Of course, it follows that {(T, B)} = T âˆ©B. Since only one
of the three coins is biased, we have P(B) = 1/3. By assumption P(T|B) = 2/3, hence an
application of eq. (2.4) leads to
P({(T, B)}) = P(B) P(T|B) = 1
3 â‹…2
3 = 2
9 .
Next, we present two examples where formula (2.3) applies directly.
Example 2.1.6. Roll a die twice. One already knows that the ï¬rst number is not â€œ6.â€
What is the probability that the sum of both rolls is greater than or equal to â€œ10?â€
Answer: The model for this experiment is K = {1, . . . , 6}2 endowed with the uni-
form distribution P on P(K). The event B := {First result is not â€œ6â€} contains the 30
elements
{(1, 1), . . . , (5, 1), . . . , (1, 6), . . . , (5, 6)},
and if A consists of pairs with sum equal to or larger than 10, then
A = {(4, 6), (5, 6), (6, 6), (5, 5), (6, 5), (6, 4)} , hence A âˆ©B = {(4, 6), (5, 6), (5, 5)} .
Therefore, it follows
P(A|B) = P(A âˆ©B)
P(B)
= 3/36
30/36 = 1
10 .
In the case that all elementary events are equally likely, there exists a more direct way
to evaluate P(A|B). We reduce the sample space as we already did in Example 2.1.1.
Proposition 2.1.7 (Reduction of the sample space). Suppose the sample space K is ï¬-
nite and let P be the uniform distribution on P(K). Then for all events A and non-empty
B in K, we have
P(A|B) = #(A âˆ©B)
#(B)
.
(2.5)
Proof: This easily follows from
P(A|B) = P(A âˆ©B)
P(B)
= #(A âˆ©B)
-
#(K)
#(B)
-
#(K)
= #(A âˆ©B)
#(B)
.
âˆ

2.1 Conditional Probabilities
89
Example 2.1.8. We want to investigate Example 2.1.6 once more, this time using
formula (2.5) directly. Since #(A âˆ©B) = 3 and #(B) = 30, we get as before
P(A|B) = #(A âˆ©B)
#(B)
= 3
30 = 1
10 .
Remark 2.1.9. It is important to state that Proposition 2.1.7 becomes false for general
probabilities P on P(K). Formula (2.5) is only valid in the case that P is the uniform
distribution on P(K).
Example 2.1.10. The duration of a telephone call is exponentially distributed with
parameter + > 0. Find the probability that a call does not last more than 5 minutes
provided it already lasted 2 minutes.
Solution: Let A be the event that the call does not last more than 5 minutes, that is,
A = [0, 5]. We know it already lasted 2 minutes, hence event B = [2, âˆ) has occurred.
Thus, under condition B, it follows
E+(A|B) = E+(A âˆ©B)
E+(B)
= E+([2, 5])
E+([2, âˆ)) = eâ€“2+ â€“ eâ€“5+
eâ€“2+
= 1 â€“ eâ€“3+ .
Note the interesting fact that this conditional probability equals E+([0, 3]). What does
this tell us? It says that the probability that a call lasts no more than another 3 minutes
is independent of the fact that it already lasted 2 minutes. This means that the dura-
tion of a call did not â€œbecome older.â€ Independent of the fact that it already lasted 2
minutes, the probability for talking no more than another 3 minutes remains the same.
Let us come back to the general case. Fix an event B âˆˆA with P(B) > 0. Then
A â†¦P(A|B) ,
A âˆˆA ,
is a well-deï¬ned mapping from A to [0, 1]. Its main properties are summarized in the
next proposition.
Proposition 2.1.11. Let (K, A, P) be an arbitrary probability space. Then for each B âˆˆA
with P(B) > 0, the mapping A â†¦P(A|B) is a probability measure on A. It is concentrated
on B, that is,
P(B|B) = 1
or, equivalently,
P(Bc|B) = 0 .
Proof: Of course, one has
P(Ã¸|B) = P(Ã¸ âˆ©B)/P(B) = 0 and P(K|B) = P(K âˆ©B)/P(B) = P(B)/P(B) = 1 .
Thus, it remains to prove that P(â‹…|B) is 3-additive. To this end, choose disjoint
A1, A2, . . . in A. Then also A1 âˆ©B, A2 âˆ©B, . . . are disjoint and using the 3-additivity
of P leads to

90
2 Conditional Probabilities and Independence
P
 âˆ
	
j=1
Aj
..B

=
P
 âˆ
j=1 Aj

âˆ©B

P(B)
=
P
 âˆ
j=1(Aj âˆ©B)

P(B)
=
âˆ
j=1 P(Aj âˆ©B)
P(B)
=
âˆ

j=1
P(Aj âˆ©B)
P(B)
=
âˆ

j=1
P(Aj|B) .
Consequently, as asserted, P( â‹…|B) is a probability. Since the identity P(B|B) = 1 is
obvious, this ends the proof.
âˆ
Deï¬nition 2.1.12. The mapping P( â‹…|B) is called conditional probability or also
conditional distribution (under condition B).
Remark 2.1.13. The main advantage of Proposition 2.1.11 is that it implies that con-
ditional probabilities share all the properties of â€œordinaryâ€ probability measures. For
example, it holds
P(A2\A1|B) = P(A2|B) â€“ P(A1|B)
provided that
A1 âŠ†A2
or
P(A1 âˆªA2|B) = P(A1|B) + P(A2|B) â€“ P(A1 âˆ©A2|B) .
We come now to the so-called law of total probability. It allows us to evaluate the
probability of an event A knowing only its conditional probabilities P(A|Bj) for certain
Bj âˆˆA. More precisely, the following is valid.
Proposition 2.1.14 (Law of total probability). Let (K, A, P) be a probability space and
let B1, . . . , Bn in A be disjoint with P(Bj) > 0 and n
j=1 Bj = K. Then for each A âˆˆA holds
P(A) =
n

j=1
P(Bj) P(A|Bj) .
(2.6)
Proof: Let us start with the investigation of the right-hand side of eq. (2.6). By the
deï¬nition of the conditional probability, this expression may be rewritten as
n

j=1
P(Bj) P(A|Bj) =
n

j=1
P(Bj) P(A âˆ©Bj)
P(Bj)
=
n

j=1
P(A âˆ©Bj) .
(2.7)

2.1 Conditional Probabilities
91
The sets B1, . . . , Bn are disjoint, hence so are A âˆ©B1, . . . , A âˆ©Bn. Thus, the ï¬nite
additivity of P implies
n

j=1
P(A âˆ©Bj) = P
 n
	
j=1
(A âˆ©Bj)

= P
 n
	
j=1
Bj

âˆ©A)

= P(K âˆ©A) = P(A) .
Together with eq. (2.7), this proves eq. (2.6).
âˆ
Example 2.1.15. A fair coin is tossed four times. Suppose we observe exactly k times
â€œheadsâ€ for some k = 0, . . . , 4. According to the observed k, we take k dice and roll
them. Find the probability that number â€œ6â€ does not appear. Note that k = 0 means
that we do not roll a die, hence in this case â€œ6â€ cannot appear.
Solution: As sample space, we choose K = {(k, Y), (k, N) : k = 0, . . . , 4}, where
(k, Y) means that we rolled k dice and at least at one of them we got a â€œ6.â€ In the
same way (k, N) stands for k dice and no â€œ6.â€ Let N = {(0, N), . . . , (4, N)} and Bk =
{(k, Y), (k, N)}, k = 0, . . . , 4. Then Bk occurs if we observed k â€œheads.â€ The conditional
probabilities equal
P(N|B0) = 1 , P(N|B1) = 5/6 , . . . , P(N|B4) = (5/6)4 ,
while
P(Bk) =
4
k
 1
24 ,
k = 0, . . . , 4 .
The events B0, . . . , B4 satisfy the assumptions of Proposition 2.1.14, thus eq. (2.6)
applies and leads to
P(A) = 1
24
4

k=0
4
k

(5/6)k = 1
24
 5
6 + 1

4
=
11
12
4
= 0.706066743 .
Example 2.1.16. Three different machines, M1, M2 and M3, produce light bulbs. In a
single day, M1 produces 500 bulbs, M2 200 and M3 100. The quality of the produced
bulbs depends on the machines: Among the light bulbs produced by M1 are 5% de-
fective, M2 10% and M3 only 2%. At the end of a day, a controller chooses by random
one of the 800 produced light bulbs and tests it. Determine the probability that the
checked bulb is defective.
Solution: The probabilities that the checked bulb was produced by M1, M2 or M3
are 5/8, 1/4 and 1/8, respectively. The conditional probabilities for choosing a defective
bulb produced by M1, M2 or M3 were given as 1/20, 1/10 and 1/50, respectively. If D is
the event that the tested bulb was defective, then the law of total probability yields
P(D) = 5
8 â‹…1
20 + 1
4 â‹…1
10 + 1
8 â‹…1
50 = 47
800 = 0.05875 .

92
2 Conditional Probabilities and Independence
Let us look at Example 2.1.16 from a different point of view. When choosing a light
bulb out of the 800 produced, there were certain ï¬xed probabilities whether it was
produced by M1, M2 or M3, namely with probabilities 5/8, 1/4 and 1/8. These are the
probabilities before checking a bulb. Therefore, they are called a priori probabilities.
After checking a bulb, we obtained the additional information that it was defective.
Does this additional information change the probabilities which of the M1, M2 or M3
produced it? More precisely, if as above D occurs if the tested bulb is defective, then
we now ask for the conditional probabilities P(M1|D), P(M2|D) and P(M3|D). To under-
stand that these probabilities may differ considerably from the a priori probabilities,
imagine that, for example, M1 produces almost no defective bulbs. Then it will be very
unlikely that the tested bulb has been produced by M1, although P(M1) may be big.
Because P(M1|D), P(M2|D) and P(M3|D) are the probabilities after executing the
random experiment (choosing and testing the bulb), they are called a posteriori
probabilities.
Let us now introduce the exact and general deï¬nition of a priori and a posteriori
probabilities.
Deï¬nition 2.1.17. Suppose there is a probability space (K, A, P) and there are dis-
joint events B1, . . . , Bn âˆˆA satisfying K = n
j=1 Bj. Then we call P(B1), . . . , P(Bn)
the a priori probabilities of B1, . . . , Bn. Let A âˆˆA with P(A) > 0 be given. Then
the conditional probabilities P(B1|A), . . . , P(Bn|A) are said to be the a posteriori
probabilities, that is, those after the occurrence of A.
To calculate the a posteriori probabilities, the next proposition turns out to be very
useful.
Proposition 2.1.18 (Bayesâ€™ formula). Suppose we are given disjoint events B1 to Bn sat-
isfying n
j=1 Bj = K and P(Bj) > 0. Let A be an event with P(A) > 0. Then for each j â‰¤n
the following equation holds:
P(Bj|A) =
P(Bj) P(A|Bj)
n
i=1 P(Bi)P(A|Bi) .
(2.8)
Proof: Proposition 2.1.14 implies
n

i=1
P(Bi)P(A|Bi) = P(A) .
Hence, the right-hand side of eq. (2.8) may also be written as
P(Bj)P(A|Bj)
P(A)
=
P(Bj)
P(Aâˆ©Bj)
P(Bj)
P(A)
= P(A âˆ©Bj)
P(A)
= P(Bj|A)
and the proposition is proven.
âˆ

2.1 Conditional Probabilities
93
Remark 2.1.19. In the case P(A) is already known, Bayesâ€™ formula simpliï¬es to
P(Bj|A) = P(Bj)P(A|Bj)
P(A)
,
j = 1, . . . , n .
(2.9)
Remark 2.1.20. Let us treat the special case of two sets partitioning K. If B1 = B, then
necessarily B2 = Bc, hence K = B âˆªBc. Then formula (2.8) looks as follows:
P(B|A) =
P(B)P(A|B)
P(B)P(A|B) + P(Bc)P(A|Bc)
(2.10)
and
P(Bc|A) =
P(Bc)P(A|Bc)
P(B)P(A|B) + P(Bc)P(A|Bc) .
(2.11)
Again, if the probability of A is known, the denominators in eqs. (2.10) and (2.11) may
be replaced by P(A).
Example 2.1.21. Let us use Bayesâ€™ formula to calculate the a posteriori probabilities
in Example 2.1.16. Recall that D occurred if the tested bulb was defective. We already
know P(D) = 47/800, hence we may apply eq. (2.9). Doing so, we get
P(M1|D) = P(M1)P(D|M1)
P(D)
= 5/8 â‹…1/20
47/800
= 25/47
P(M2|D) = P(M2)P(D|M2)
P(D)
= 1/4 â‹…1/10
47/800 = 20/47
P(M3|D) = P(M3)P(D|M3)
P(D)
= 1/8 â‹…1/50
47/800
= 2/47 .
By assignment of the problem, the a priori probabilities were given by P(M1) = 5/8,
P(M2) = 1/4 and P(M3) = 1/8. In the case that the tested light bulb was defective,
these probabilities change to 25/47, 20/47 and 2/47. This tells us that it becomes less
likely that the tested bulb was produced by M1 or M3; their probabilities diminish
by 0.0930851 and 0.0824468, respectively. On the other hand, the probability of M2
increases by 0.175532.
Finally, note that Proposition 2.1.11 implies that the sum of the a posteriori
probabilities has to be 1. Because of 25/47 + 20/47 + 2/47 = 1, this is true in that example.
Example 2.1.22. In order to ï¬gure out whether or not a person suffers from a certain
disease, say disease X, a test is assumed to give a clue. If the tested person is sick,
then the test is positive in 96% of cases. If the person is well, then with 94% accuracy
the test will be negative. Furthermore, it is known that 0.4% of the population suffers
from X.
Now a person, chosen by random, is tested. Suppose the result was positive. Find
the probability that this person really suffers from X.

94
2 Conditional Probabilities and Independence
Solution: As sample space, we may choose K = {(X, p), (X, n), (Xc, p), (Xc, n)},
where, for example, (X, n) means the person suffers from X and the test was negative.
Set A := {(X, p), (Xc, p)}. Then A occurs if and only if the test turned out to be positive.
Furthermore, event B := {(X, p), (X, n)} occurs in the case that the tested person suffers
from X. Known are
P(A|B) = 0.96 , P(A|Bc) = 0.06
and
P(B) = 0.004 ,
hence
P(Bc) = 0.996 .
Therefore, by eq. (2.10), the probability we asked for can be calculated as follows:
P(B|A) =
P(B)P(A|B)
P(B)P(A|B) + P(Bc)P(A|Bc)
=
0.004 â‹…0.96
0.004 â‹…0.96 + 0.996 â‹…0.06 = 0.00384
0.0636 = 0.0603774 .
That tells us that it is quite unlikely that a randomly chosen person with A positive test
is really sick. The chance for this being true is only about 6%.
2.2 Independence of Events
What does it mean that two events are independent or, more precisely, that they occur
independently of each other? To get an idea, let us look at the following example.
Example 2.2.1. Roll a fair die twice. Event B occurs if the ï¬rst number is even while
event A consists of all pairs (x1, x2), where x2 = 5 or x2 = 6. It is intuitively clear
that these two events occur independently of each other. But how to express this
mathematically? To answer this question, think about the probability of A under the
condition B. The fact whether or not B occurred has no inï¬‚uence on the occurrence
of A. For the occurrence or nonoccurrence of A, it is completely insigniï¬cant what
happened in the ï¬rst roll. Mathematically this means that P(A|B) = P(A). Let us check
whether this is true in this concrete case. Indeed, it holds P(A) = 1/3 as well as
P(A|B) = P(A âˆ©B)
P(B)
= 6/36
1/2 = 1/3 .
The previous example suggests that independence of A of B could be described by
P(A) = P(A|B) = P(A âˆ©B)
P(B)
.
(2.12)
But formula (2.12) has a disadvantage, namely we have to assume P(B) > 0 to ensure
that P(A|B) exists. To overcome this problem, rewrite eq. (2.12) as
P(A âˆ©B) = P(A) P(B) .
(2.13)
In this form, we may take eq. (2.13) as a basis for the deï¬nition of independence.

2.2 Independence of Events
95
Deï¬nition 2.2.2. Let (K, A, P) be a probability space. Two events A and B in A are
said to be (stochastically) independent provided that
P(A âˆ©B) = P(A) â‹…P(B) .
(2.14)
In the case that eq. (2.14) does not hold, the events A and B are called (stochastic-
ally) dependent.
Remark 2.2.3. In the sequel, we use the notations â€œindependentâ€ and â€œdependentâ€
without adding the word â€œstochastically.â€ Since we will not use other versions of
independence, there should be no confusion.
Example 2.2.4. A fair die is rolled twice. Event A occurs if the ï¬rst roll is either â€œ1â€ or
â€œ2â€ while B occurs if the sum of both rolls equals 7. Are A and B independent?
Answer: It holds P(A) = 1/3, P(B) = 1/6 as well as P(A âˆ©B) = 2/36 = 1/18. Hence, we
get P(A âˆ©B) = P(A) â‹…P(B) and A and B are independent.
Question: Are A and B also independent if A is as before and B is deï¬ned as a set
of pairs with sum 4?
Example 2.2.5. In an urn, there are n, n â‰¥2, white balls and also n black balls. One
chooses two balls without replacing the ï¬rst one. Let A be the event that the second
ball is black while B occurs if the ï¬rst ball was white. Are A and B independent?
Answer: The probability of B equals 1/2. To calculate P(A), we use Proposition
2.1.14. Then we get
P(A) = P(B)P(A|B) + P(Bc)P(A|Bc) = 1
2 â‹…
n
2n â€“ 1 + 1
2 â‹…n â€“ 1
2n â€“ 1 = 1
2 ,
hence, P(A) â‹…P(B) = 1/4.
On the other hand, we have
P(A âˆ©B) = P(B)P(A|B) = 1
2 â‹…
n
2n â€“ 1 =
n
4n â€“ 2 /= 1
4 .
Consequently, A and B are dependent.
Remark 2.2.6. Note that, if n â†’âˆ, then
P(A âˆ©B) =
n
4n â€“ 2 â†’1
4 = P(A) P(B) .
This tells us the following: if n is big, then A and B are â€œalmostâ€ independent or,
equivalently, the degree of dependence between A and B is very small. This question

96
2 Conditional Probabilities and Independence
will be investigated more thoroughly in Chapter 5 when a measure for the degree of
dependence is available.
Next, we prove some properties of independent events.
Proposition 2.2.7. Let (K, A, P) be a probability space.
1.
For any A âˆˆA, the events A and Ã¸ as well as A and K are independent1.
2.
If A and B are independent, then so are A and Bc as well as Ac and Bc.
Proof: We have
P(A âˆ©Ã¸) = P(Ã¸) = 0 = P(A) â‹…0 = P(A) â‹…P(Ã¸) ,
hence, A and Ã¸ are independent.
In the same way follows the independence of A and K by
P(A âˆ©K) = P(A) = P(A) â‹…1 = P(A) â‹…P(K) .
To prove the second part, assume that A and B are independent. Our aim is to show
that A and Bc are independent as well. We know that
P(A âˆ©B) = P(A) P(B)
and we want to show that
P(A âˆ©Bc) = P(A) P(Bc) .
Let us start with the right-hand side of the last equation. Using the independence of A
and B and A âˆ©B âŠ†B, it follows that
P(A) P(Bc) = P(A)

1 â€“ P(B)

= P(A) â€“ P(A) â‹…P(B)
= P(A) â€“ P(A âˆ©B) = P

A\(A âˆ©B)

.
(2.15)
Since A\(A âˆ©B) = A\B = A âˆ©Bc from eq. (2.15), we derive
P(A) â‹…P(Bc) = P(A âˆ©Bc) .
Consequently, as asserted, A and Bc are independent.
If A and B are independent, then so are B and A, and as seen above, so are B
and Ac. Another application of the ï¬rst step, this time with Ac and B shows that also
Ac and Bc are independent. This completes the proof.
âˆ
Suppose we are given n events A1, . . . , An in A. We want to ï¬gure out when they are
independent. A ï¬rst possible approach could be as follows.
1 For a more general result, compare Problem 2.10.

2.2 Independence of Events
97
Deï¬nition 2.2.8. Events A1, . . . , An are said to be pairwise independent if,
whenever i /= j, then
P(Ai âˆ©Aj) = P(Ai) â‹…P(Aj) .
In other words, for all 1 â‰¤i < j â‰¤1 the events Ai and Aj are independent.
Unfortunately, for many purposes, the property of pairwise independence is too weak.
For example, as we will see next, in general it does not imply the important equation
P(A1 âˆ©â‹¯âˆ©An) = P(A1) â‹¯P(An) .
(2.16)
Example 2.2.9. Roll a die twice and deï¬ne events A1, A2 and A3 as follows:
A1 := {2, 4, 6} Ã— {1, . . . , 6}
A2 := {1, . . . , 6} Ã— {1, 3, 5}
A3 := {2, 4, 6} Ã— {1, 3, 5} âˆª{1, 3, 5} Ã— {2, 4, 6} .
Verbally this says that A1 occurs if the ï¬rst roll is even, A2 occurs if the second one is
odd and A3 occurs if either the ï¬rst number is odd and the second is even or vice versa.
Direct calculations give P(A1) = P(A2) = P(A3) = 1/2 as well as
P(A1 âˆ©A2) = P(A1 âˆ©A3) = P(A2 âˆ©A3) = 1
4 .
Hence, A1, A2 and A3 are pairwise independent.
Since
A1 âˆ©A2 âˆ©A3 = A1 âˆ©A2
it follows
P(A1 âˆ©A2 âˆ©A3) = P(A1 âˆ©A2) = 1
4 /= 1
8 = P(A1) â‹…P(A2) â‹…P(A3) .
So, we found three pairwise independent events for which eq. (2.16) is not valid.
After mentioning that pairwise independence of A1, . . . , An does not imply
P(A1 âˆ©â‹¯âˆ©An) = P(A1) â‹¯P(An),
(2.17)
it makes sense to ask whether or not pairwise independence can be derived from
eq. (2.17). The next example shows that, in general, this is also not true.

98
2 Conditional Probabilities and Independence
Example 2.2.10. Let K = {1, . . . , 12} be endowed with the uniform distribution P, that
is, for any A âŠ†K we have P(A) = #(A)/12. Deï¬ne events A1, A2 and A3 as A1 := {1, . . . , 9},
A2 := {6, 7, 8, 9} and A3 := {9, 10, 11, 12}. Direct calculations give
P(A1) = 9
12 = 3
4 , P(A2) = 4
12 = 1
3
and
P(A3) = 4
12 = 1
3 .
Moreover, we have
P(A1 âˆ©A2 âˆ©A3) = P({9}) = 1
12 = 3
4 â‹…1
3 â‹…1
3 = P(A1) â‹…P(A2) â‹…P(A3) ,
hence eq. (2.17) is valid. But, because of
P(A1 âˆ©A2) = P(A2) = 1
3 /= 1
4 = P(A1) â‹…P(A2) ,
the events A1, A2 and A3 are not pairwise independent.
Remark 2.2.11. Summing up, Examples 2.2.9 and 2.2.10 show that neither pairwise
independence nor eq. (2.17) are suitable to deï¬ne the independence of more than two
events. Why? On the one hand, independence should yield eq. (2.17) and, on the other
hand, whenever A1, . . . , An are independent, then so should be any subcollection of
them. In particular, independence should imply pairwise independence.
A reasonable deï¬nition of independence of n events is as follows.
Deï¬nition 2.2.12. The events A1, . . . , An are said to be independent provided
that for each subset I âŠ†{1, . . . , n} we have
P
 
iâˆˆI
Ai

=
%
iâˆˆI
P(Ai) .
(2.18)
Remark 2.2.13. Of course, it sufï¬ces that eq. (2.18) is valid for sets I âŠ†{1, . . . , n}
satisfying #(I) â‰¥2. Indeed, if #(I) = 1, then eq. (2.18) holds by trivial reason.
Remark 2.2.14. Another way to introduce independence is as follows: For all m â‰¥2
and all 1 â‰¤i1 < â‹¯< im â‰¤n, it follows
P(Ai1 âˆ©â‹¯âˆ©Aim) = P(Ai1) â‹¯P(Aim) .
Identify I with {i1, . . . , im} to see that both deï¬nitions are equivalent.

2.2 Independence of Events
99
At a ï¬rst glance, Deï¬nition 2.2.12 looks complicated; in fact, it is not. To see this,
let us once more investigate the case n = 3. Here exist exactly four different subsets
I âŠ†{1, 2, 3} with #(I) â‰¥2. These are I = {1, 2}, I = {1, 3}, I = {2, 3} and I = {1, 2, 3}. Con-
sequently, three events A1, A2 and A3 are independent if and only if the four following
conditions hold at once:
P(A1 âˆ©A2) = P(A1) â‹…P(A2)
P(A1 âˆ©A3) = P(A1) â‹…P(A3)
P(A2 âˆ©A3) = P(A2) â‹…P(A3)
as well as
P(A1 âˆ©A2 âˆ©A3) = P(A1) â‹…P(A2) â‹…P(A3) .
Examples 2.2.9 and 2.2.10 show that all four equations are really necessary. None of
them is a consequence of the other three ones.
Independence of n events possesses the following properties:
Proposition 2.2.15.
1.
Let A1, . . . , An be independent. For any J âŠ†{1, . . . n}, the events {Aj : j âˆˆJ} are
independent as well. In particular, independence implies pairwise independence.
2.
For each permutation 0 of {1, . . . , n}, the independence of A1, . . . , An implies that of2
A0(1), . . . , A0(n).
3.
Suppose for each 1 â‰¤j â‰¤n holds either Bj = Aj or Bj = Ac
j . Then the independence of
A1, . . . , An implies that of B1, . . . , Bn.
Proof: The ï¬rst two properties are an immediate consequence of the deï¬nition of
independence.
To prove the third assertion, reorder A1, . . . , An such that3 B1 = Ac
1. In a ï¬rst step,
we show that Ac
1, A2, . . . , An are independent as well, that is, we have B1 = Ac
1, B2 = A2
and so on. Given I âŠ†{1, . . . , n}, it has to hold
P
 
iâˆˆI
Bi

=
%
iâˆˆI
P(Bi) .
In the case 1 âˆ‰I, this follows by the independence of A1, . . . , An. If 1 âˆˆI, we apply
Proposition 2.2.7 with4 A1 and C = 
iâˆˆI\{1} Ai = 
iâˆˆI\{1} Bi. Then Ac
1 = B1 and C are
independent as well. Hence, by the independence of A2, . . . , An, we get
P
 
iâˆˆI
Bi

= P(B1 âˆ©C) = P(B1) â‹…P(C) = P(B1) â‹…
%
iâˆˆI\{1}
P(Bi) =
%
iâˆˆI
P(Bi) .
2 For example, in the case n = 3 with A1, A2, A3 also A3, A2, A1 or A2, A3, A1 are independent.
3 If all Bj = Aj, there is nothing to prove.
4 Why are A1 and C independent? Give a short proof.

100
2 Conditional Probabilities and Independence
The general case then follows by reordering the Ajs and by an iterative application
of the ï¬rst step. This is exactly the procedure we did in the proof of Proposition 2.2.7
when verifying the independence of Ac and Bc for independent A and B.
âˆ
The next two examples show how independence of more than two events appears in
a natural way.
Example 2.2.16. Toss a fair coin n times. Let us assume that the coin is labeled with
â€œ0â€ and â€œ1.â€ Choose a ï¬xed sequence (aj)n
j=1 of numbers in {0, 1} and suppose that the
event Aj occurs if in the jth trial aj comes up.
We claim now that A1, . . . , An are independent. To verify this, choose a subset I âŠ†
{1, . . . , n} with #(I) = k for some k = 2, . . . , n. The cardinality of 
iâˆˆI Ai equals 2nâ€“k.
Why? At k positions the values of the tosses are ï¬xed; at n â€“ k positions, they still may
be either â€œ0â€ or â€œ1.â€ Consequently,
P

iâˆˆI
Ai

= 2nâ€“k
2n
= 2â€“k .
(2.19)
The same argument as before gives #(Aj) = 2nâ€“1, hence P(Aj) = 1/2, 1 â‰¤j â‰¤n.
Consequently, it follows
%
iâˆˆI
P(Ai) =
1
2
#(I)
= 2â€“k .
(2.20)
Combining eqs. (2.19) and (2.20) gives
P

iâˆˆI
Ai

=
%
iâˆˆI
P(Ai) ,
and since I was arbitrary, the sets A1, . . . , An are independent.
Remark 2.2.17. Even the simple Example 2.2.16 shows that it might be rather com-
plicated to verify the independence of n given events. For example, if we modify the
previous example by taking a biased coin, then the Ajs remain independent, but the
proof becomes more complicated.
Example 2.2.18. A machine consists of n components. These components break down
with certain probabilities p1, . . . , pn. Moreover, we assume that they break down inde-
pendently of each other. Find the probability that a chosen machine stops working.
Before answering this question, we have to determine the conditions.

2.3 Problems
101
Case 1: The machine stops working provided at least one component breaks down.
Let M be the event that the machine stops working. If j â‰¤n, assume Aj occurs if
component j breaks down. By assumption, P(Aj) = pj. Since
M =
n
	
j=1
Aj ,
by the independence5 it follows that
P(M) = 1 â€“ P(Mc) = 1 â€“ P
â›
â
n

j=1
Ac
j
â
â = 1 â€“
n
%
j=1
P(Ac
j ) = 1 â€“
n
%
j=1
(1 â€“ pj) .
(2.21)
Case 2: The machine stops working provided all n components break down.
Using the same notation as in case 1, we now have
M =
n

j=1
Aj .
Hence, by the independence we obtain
P(M) = P
â›
â
n

j=1
Aj
â
â =
n
%
j=1
pj .
(2.22)
Remark 2.2.19. Formula (2.21) tells us the following: If among the n components there
is one of bad quality, say the component j0, then pj0 is close to one; hence, 1 â€“ pj0 is
close to zero, and so is ,n
j=1(1 â€“ pj). Because of eq. (2.21), P(M) is large, and so the
machine breaks down with large probability.
In the second case, the conclusion is as follows: if among the n components there
is one of high quality, say component j0, then pj0 is small and so is ,n
j=1 pj. By eq. (2.22),
P(M) is also small, hence it is very unlikely that the machine stops working.
2.3 Problems
Problem 2.1. The chance to win a certain game is 50%. One plays six games. Find the
probability to win exactly four games. Evaluate the probability of this event under the
condition to win at least two games. Suppose one had won exactly one of the two ï¬rst
games. Which probability has the event â€œwinning 4 gamesâ€ under this condition?
5 In fact, we also have to use Proposition 2.2.15.

102
2 Conditional Probabilities and Independence
Problem 2.2. Toss a fair coin six times. Deï¬ne events A and B as follows:
A = {â€œHeadâ€ appears exactly 3 times}
B = {The ï¬rst and the second toss are â€œheadâ€}
Evaluate P(A), P(A|B) and P(A|Bc).
Problem 2.3. Let A and B be as in Problem 1.24, that is, A occurs if each box contains
at most one particle while B occurs if all four particles are in the same box.
Find now P(A|C) and P(B|C) with C = {The ï¬rst box remains empty}.
Problem 2.4. Justify why Propositions 2.1.14 and 2.1.18 (Law of total probability and
Bayesâ€™ formula) remain valid for inï¬nitely many disjoint sets B1, B2, . . . satisfying
P(Bj) > 0 and âˆ
j=1 Bj = K.
Prove that Proposition 2.1.14 also holds without assuming n
j=1 Bj = K. But then
we have to suppose A âŠ†n
j=1 Bj.
Problem 2.5. To go to work, a man can either use the train, the bus or his car. He
chooses the train 50%, the bus 30% and the car 20% of work days. If he takes the
train, he arrives on time with probability 0.95. By bus, he is on time with probability
0.8, and by car with probability 0.7.
1.
Evaluate the probability that the man is at work on time.
2.
How big is this probability given the man does not use the car?
3.
Assume the man arrived at work on time. What are then the probabilities that he
came by train, bus or car?
Problem 2.6. Let U1, U2 and U3 be three urns containing each ï¬ve balls. Urn U1 con-
tains four white balls and one black ball, U2 has three white balls and two black balls
and, ï¬nally, U3 contains two white balls and three black balls. Choose one urn by ran-
dom (each urn is equally likely) and without replacing the ï¬rst ball take two balls out
of the chosen urn.
1.
Give a suitable sample space for this random experiment.
2.
Find the probability to observe two balls of different color.
3.
Assume the chosen balls were of different color. What are the probabilities that
the balls were taken out of U1, U2 or U3?
Problem 2.7. Suppose we have three nondistinguishable dice. Two of them are fair,
the other one is biased. There the number â€œ6â€ appears with probability 1/5 while all
other numbers have probability 4/25. We choose by random one of the dice and roll it.
1.
Find a suitable sample space for the description of this experiment.
2.
Give the probability of occurrence of {1} to {6} in that experiment.
3.
Suppose we have observed the number â€œ2â€ on the chosen die. Find the probability
that this die was the biased one.

2.3 Problems
103
Problem 2.8.
1.
Let (K, A, P) be a probability space. Given events A1, . . . , An prove the following
chain rule for conditional probabilities:
P(A1 âˆ©â‹¯âˆ©An) = P(A1)P(A2|A1) â‹¯P(An|A1 âˆ©A2 âˆ©â‹¯âˆ©Anâ€“1) .
Hereby, we assume that all conditional probabilities are well deï¬ned.
2.
Choose by random three numbers out of 1 to 10 without replacement. Find the
probability that the ï¬rst number is even, the second one is odd and the third one
is again even.
3.
Compare this probability with that of the following event: among three randomly
chosen numbers in {1, . . . , 10} are exactly two even and one odd.
Problem 2.9. Three persons, say X, Y and Z, stand randomly in a row. All ordering
are assumed to be equally likely. Event A occurs if Y stands on the right-hand side of
X while B occurs in the case that Z is on the right-hand side of X. Hereby, we do not
suppose that Y and X nor that Z and X stand directly next to each other. Are events A
and B independent or dependent?
Problem 2.10. Prove the following generalization of part 1 in Proposition 2.2.7. Let A âˆˆ
A be an event with either P(A) = 0 or P(A) = 1. Then for any B âˆˆA, the events A and B
are independent.
Problem 2.11. Let (K, A, P) be a probability space. Given independent events
A1, . . . , An in A prove that
P
 n
	
j=1
Aj

= 1 â€“
n
%
j=1

1 â€“ P(Aj)

.
(2.23)
Use 1 â€“ x â‰¤eâ€“x, x â‰¥0, to derive from eq. (2.23) the following:
If independent events6 A1, A2, . . . satisfy âˆ
j=1 P(Aj) = âˆ, then P
âˆ
j=1 Aj

= 1 .
A
C
D
B
6 Compare Deï¬nition 7.1.17: for each n âˆˆN, the events A1, . . . , An are independent.

104
2 Conditional Probabilities and Independence
Problem 2.12. An electric circuit (see the above ï¬gure) contains four switches A, B, C
and D. Each of the switches is independently open or closed (then electricity ï¬‚ows).
The switches are open with probability 1 â€“ p and closed with probability p. Here, 0 â‰¤
p â‰¤1 is given. Find the probability that electricity ï¬‚ows from the left-hand side to the
right-hand one.
Problem 2.13. Let (K, A, P) be a probability space. Suppose A and B are disjoint events
with P(A) > 0 and P(B) >0. Is it possible that A and B are independent?
Problem 2.14. Let A, B and C be three independent events.
1.
Show that A âˆ©B and C are independent as well.
2.
Even more, show that the independence of A, B and C implies that of A âˆªB and C.
Problem 2.15.
1.
Suppose that A and C as well as B and C are independent. Furthermore, assume
A âˆ©B = Ã¸. Show that A âˆªB and C are independent as well.
2.
Give an example that shows that the preceding assertion becomes false without
the assumption A âˆ©B = Ã¸.
Remark: To construct such an example, because of Problem 2.14, the events A, B and
C cannot be chosen to be independent. Therefore, the sets deï¬ned in Example 2.2.9
are natural candidates for such an example.
Problem 2.16. Suppose P(A|B) = P(A|Bc) for some events A and B with 0 < P(B) < 1.
Does this imply that A and B are independent?
Problem 2.17. Is it possible that an event A is independent of itself? If yes, which
events A have this property? Similarly, which A are independent of Ac ?
Problem 2.18. Let A, B and C be three independent events with
P(A) = P(B) = P(C) = 1
3 .
Evaluate
P

(A âˆ©B) âˆª(A âˆ©C)

.

3 Random Variables and Their Distribution
3.1 Transformation of Random Values
Assume the probability space (K, A, P) describes a certain random experiment, for
example, rolling a die or tossing a coin. If the experiment is executed, a random result
9 âˆˆK shows up. In a second step we transform this observed result via a mapping
X : K â†’R. In this way we obtain a (random) real number X(9). Let us point out that X
is a ï¬xed, nonrandom function from K into R; the randomness of X(9) stems from the
input 9 âˆˆK.
Example 3.1.1. Toss a fair coin, labeled on one side with â€œ0â€ and on the other side
with â€œ1â€, exactly n times. The appropriate probability space is (K, P(K), P), where K =
{0, 1}n and P is the uniform distribution on K. The result of the experiment is a vector
9 = (91, . . . , 9n) with 9j = 0 or 9j = 1. Let X from K â†’R be deï¬ned by
X(9) = X(91, . . . , 9n) = 91 + â‹…â‹…â‹…+ 9n .
Then X(9) tells us how often â€œ1â€ occurred, but we do no longer know in which order
this happened. Of course, X(9) is random because, if one tosses the coin another n
times, it is very likely that X attains a value different from that in the ï¬rst trial.
Here we state the most important question in this topic: how are the values of X
distributed? In our case X attains the values k â‰¤n with probabilities
n
k

2â€“n.
Example 3.1.2. Roll a fair die twice. The sample space describing this experiment
consists of pairs 9 = (91, 92), where 91, 92 âˆˆ{1, . . . , 6}. Now deï¬ne the mapping
X : K â†’R by X(9) := max{91, 92}. Thus, instead of recording the values of both rolls,
we are only interested in the larger one.
Other possible transformations are, for example, X1(9) := min{91, 92} or also
X2(91, 92) := 91 + 92.
Let A âˆˆA be an event. Recall that this event A occurs if and only if we observe an
9 âˆˆA. Suppose now X : K â†’R is a given mapping from K into R and let B âŠ†R be
some event. When do we observe an 9 âˆˆK for which we have X(9) âˆˆB or, equivalently,
when does the event
{X âˆˆB} := {9 âˆˆK : X(9) âˆˆB}
occur? To answer this question, let us recall the deï¬nition of the preimage of B with
respect to X as given in eq. (A.1):
Xâ€“1(B) := {9 âˆˆK : X(9) âˆˆB} .

106
3 Random Variables and Their Distribution
We observe an 9 âˆˆK for which X(9) âˆˆB if and only if 9 âˆˆXâ€“1(B). In other words,
the event {X âˆˆB} occurs if and only if Xâ€“1(B) does so. Consequently, the probability to
observe an 9 âˆˆK with X(9) âˆˆB should be P(Xâ€“1(B)). But to this end, we have to know
that Xâ€“1(B) âˆˆA; otherwise P(Xâ€“1(B)) is not deï¬ned at all. Thus, a natural condition
for X is Xâ€“1(B) âˆˆA for â€œsufï¬ciently manyâ€ subsets B âŠ†R. The precise mathematical
condition reads as follows.
Deï¬nition 3.1.3. Let (K, A, P) be a probability space. A mapping X : K â†’R
is called a (real-valued) random variable (sometimes also called random real
number), provided that it satisï¬es the following condition:
B âˆˆB(R)
â‡’
Xâ€“1(B) âˆˆA .
(3.1)
Verbally, this condition says that for each Borel set B âŠ†R, its preimage Xâ€“1(B) has
to be an element of the 3-ï¬eld A.
Remark 3.1.4. Condition (3.1) is purely technical and will not be important later on.
But, in general, it cannot be avoided, at least if A /= P(K). On the contrary, if A = P(K),
for example, if either K is ï¬nite or countably inï¬nite, then every mapping X : K â†’R
is a random variable. Indeed, by trivial reason, in this case the condition Xâ€“1(B) âˆˆA is
always satisï¬ed.
Remark 3.1.5. In order to verify that a given mapping X : K â†’R is a random variable,
it is not necessary to show Xâ€“1(B) âˆˆA for all Borel sets B âŠ†R. It sufï¬ces to prove this
only for some special Borel sets B. More precisely, the following proposition holds.
Proposition 3.1.6. A function X : K â†’R is a random variable if and only if, for all t âˆˆR,
we have
Xâ€“1
(â€“âˆ, t]

= {9 âˆˆK : X(9) â‰¤t} âˆˆA .
(3.2)
The assertion remains valid when we replace the intervals (â€“âˆ, t] with intervals of the
form (â€“âˆ, t), or we may take intervals [t, âˆ) and also (t, âˆ).
Proof: Suppose ï¬rst that X is a random variable. Given t âˆˆR, the interval (â€“âˆ, t] is a
Borel set, hence Xâ€“1
(â€“âˆ, t]

âˆˆA. Thus, each random variable satisï¬es condition (3.2).
To prove the converse implication, let X be a mapping from K to R satisfying
condition (3.2) for each t âˆˆR. Set
C := {C âˆˆB(R) : Xâ€“1(C) âˆˆA}.

3.2 Probability Distribution of a Random Variable
107
In a ï¬rst step, one proves1 that C is a 3-ï¬eld. Moreover, property (3.2) implies (â€“âˆ, t] âˆˆ
C for each t âˆˆR. But B(R) is the smallest 3-ï¬eld containing all these intervals. Since C
is another 3-ï¬eld containing the intervals (â€“âˆ, t], it has to be larger2 than the smallest
one, that is, we have C âŠ‡B(R). In other words, every Borel set belongs to C or, equival-
ently, for all B âˆˆB(R) it follows Xâ€“1(B) âˆˆA. Thus, as asserted, X is a random variable.
The proof for intervals of the other types goes along the same line. Here one has to use
that these intervals generate the 3-ï¬eld of Borel sets as well.
âˆ
3.2 Probability Distribution of a Random Variable
Suppose we are given a random variable X : K â†’R. We deï¬ne now a mapping PX
from B(R) to [0, 1] as follows:
PX (B) := P

Xâ€“1(B)

= P{9 âˆˆK : X(9) âˆˆB} ,
B âˆˆB(R) .
Observe that PX is well-deï¬ned. Indeed, since X is a random variable, for all Borel sets
B âŠ†R we have Xâ€“1(B) âˆˆA, hence P

Xâ€“1(B)

makes sense.
To simplify the notation, given B âˆˆB(R), we will often write
P{X âˆˆB} = P{9 âˆˆK : X(9) âˆˆB} .
That is generally used and does not lead to any confusion. Having said this we may
now deï¬ne PX also by
PX(B) = P{X âˆˆB} .
A ï¬rst easy example shows how PX is calculated in concrete cases. Other, more
interesting examples will follow after some necessary preliminary considerations.
Example 3.2.1. Toss a fair coin, labeled on one side by â€œ0â€ and on the other side
by â€œ1,â€ three times. The sample space is K = {0, 1}3 with the uniform distribution P
describing probability measure. Let the random variable X on K be deï¬ned by
X(9) := 91 + 92 + 93
whenever
9 = (91, 92, 93) âˆˆK .
1 Use Proposition A.2.1 to verify this.
2 By the construction of C, it even coincides with B(R).

108
3 Random Variables and Their Distribution
It follows
PX({0}) = P{X = 0} = P({(0, 0, 0)}) = 1
8
PX({1}) = P{X = 1} = P({(1, 0, 0), (0, 1, 0), (0, 0, 1)}) = 3
8
PX({2}) = P{X = 2} = P({(1, 1, 0), (0, 1, 1), (1, 0, 1)}) = 3
8
PX({3}) = P{X = 3} = P({(1, 1, 1)}) = 1
8 .
Of course, these values describe the distribution of X completely. Indeed, whenever
B âŠ†R, then
PX(B) =
3

k=0
kâˆˆB
PX({k}) .
The proof of the next result heavily depends on properties of the preimage proved in
Proposition A.2.1.
Proposition 3.2.2. Let (K, A, P) be a probability space. For each random variable X :
K â†’R the mapping PX : B(R) â†’[0, 1] is a probability measure.
Proof: Using property (1) in Proposition A.2.1 one easily gets
PX(Ã˜) = P(Xâ€“1(Ã˜)) = P(Ã˜) = 0
as well as
PX(R) = P(Xâ€“1(R)) = P(K) = 1 .
Thus it remains to verify the 3-additivity of PX. Take any sequence of disjoint Borel
sets B1, B2, . . . in R. Then also Xâ€“1(B1), Xâ€“1(B2), . . . are disjoint subsets of K. To see
this apply Proposition A.2.1, which, if i /= j, implies
Xâ€“1(Bi) âˆ©Xâ€“1(Bj) = Xâ€“1(Bi âˆ©Bj) = Xâ€“1(Ã˜) = Ã˜ .
Another application of Proposition A.2.1 and of the 3-additivity of P ï¬nally gives
PX
 âˆ
	
j=1
Bj

= P

Xâ€“1 âˆ
	
j=1
Bj


= P
 âˆ
	
j=1
Xâ€“1(Bj)

=
âˆ

j=1
P

Xâ€“1(Bj)

=
âˆ

j=1
PX(Bj) .
Hence, PX is a probability measure as asserted.
âˆ

3.2 Probability Distribution of a Random Variable
109
Deï¬nition 3.2.3. The probability measure PX on (R, B(R)) deï¬ned by
PX(B) := P

Xâ€“1(B)

= P{9 âˆˆK : X(9) âˆˆB} = P{X âˆˆB} ,
B âˆˆB(R),
is called probability distribution of X (with respect to P) or, in short, only
distribution of X.
Remark 3.2.4. The distribution PX is the most important characteristic of a random
variable X. In general, it is completely unimportant how a random variable is deï¬ned
analytically; only its distribution matters. Thus, two random variables with identical
distributions may be regarded as equivalent because they describe the same random
experiment.
Remark 3.2.4 leads us to the following deï¬nition:
Deï¬nition 3.2.5. Two random variables X1 and X2 are said to be identically dis-
tributed provided that PX1 = PX2. Hereby, it is not necessary that X1 and X2 are
deï¬ned on the same sample space. Only their distributions have to coincide. In
the case of identically distributed X1 and X2 one writes X1
d= X2 .
Example 3.2.6. Toss a fair coin, labeled on each side by â€œ0â€ or â€œ1,â€ twice. Let X1 be
the value of the ï¬rst toss and X2 that of the second one. Then
P{X1 = 0} = P{X2 = 0} = 1
2 = P{X1 = 1} = P{X2 = 1} .
Hence, X1 and X2 are identically distributed or X1
d= X2 . Both random variables de-
scribe the same experiment, namely to toss a fair coin one time. Now, toss the coin a
third time and let X3 be the result of the third trial. Then we also have X1
d= X3, but note
that X1 and X3 are deï¬ned on different sample spaces.
Next, we state and prove some general rules for evaluating the probability distribution
of a given random variable. Here we have to distinguish between two different types
of random variables, namely between discrete and continuous ones. Let us start with
the discrete case.
Deï¬nition 3.2.7. A random variable X is discrete provided there exists an at most
countably inï¬nite set D âŠ‚R such that X : K â†’D .
In other words, a random variable is discrete if it attains at most countably
inï¬nite many different values.

110
3 Random Variables and Their Distribution
Remark 3.2.8. If a random variable X is discrete with values in D âŠ‚R, then, of course,
PX(D) = P{X âˆˆD} = 1 .
Consequently, in this case its probability distribution PX is a discrete probability
measure on R. In general, the converse is not valid as the next example shows.
Example 3.2.9. We model the experiment of rolling a fair die by the probability space
(R, P(R), P), where P({1}) = â‹…â‹…â‹…= P({6}) = 1/6 and P({x}) = 0 whenever x /= 1, . . . , 6.
If X : R â†’R is deï¬ned by X(s) = s2 then, of course, PX is discrete. Indeed, we have
PX(D) = 1, where D = {1, 4, 9, 16, 25, 36}. On the other hand, X does not attain values in
a countably inï¬nite set; its range is [0, âˆ).
Remark 3.2.10. If we look at Example 3.2.9 more thoroughly, then it becomes immedi-
ately clear that the values of X outside of {1, . . . , 6} are completely irrelevant. With a
small change of X, it will attain values in D. More precisely, let ËœX(9) = 1 if 9 /= 1, . . . , 6
and ËœX(k) = k2, k = 1, . . . , 6; then X
d= ËœX and ËœX has values in {1, 4, 9, 16, 25, 36}.
This procedure is also possible in general: if PX is discrete with PX(D) = 1 for some
countable set D, then we may change X to ËœX such that X
d= ËœX and ËœX : K â†’D. Indeed,
choose some ï¬xed d0 âˆˆD and set ËœX(9) = X(9) if 9 âˆˆXâ€“1(D) and ËœX(9) = d0 otherwise.
Then PX = P ËœX and ËœX has values in D.
Convention 3.1. Without losing generality we may always assume the following: if a
random variable X has a discrete probability distribution, that is, P{X âˆˆD} = 1 for some
ï¬nite or countably inï¬nite set D, then X attains values in D.
The second type of random variables we investigate is that of continuous ones.3
Deï¬nition 3.2.11. A random variable X is said to be continuous provided that
its distribution PX is a continuous probability measure. That is, PX possesses a
density p. This function p is called the density function or, in short, density of
the random variable X.
Remark 3.2.12. One should not confuse the continuity of a random variable with the
continuity of a function as taught in Calculus. The latter is an (analytic) property of a
function, while the former is a property of its distribution. Moreover, whether or not
3 The precise notation would be â€œabsolutely continuousâ€; but for simplicity let us call them
â€œcontinuous.â€

3.2 Probability Distribution of a Random Variable
111
a random variable X is continuous depends not only on X, but also on the underlying
probability space.
Remark 3.2.13. Another way to express that a random variable is continuous is as
follows: there exists a function p : R â†’[0, âˆ) (the density of X) such that
P{9 âˆˆK : X(9) â‰¤t} = P{X â‰¤t} =
t

â€“âˆ
p(x) dx ,
t âˆˆR ,
or, equivalently, for all real numbers a < b,
P{9 âˆˆK : a â‰¤X(9) â‰¤b} = P{a â‰¤X â‰¤b} =
b

a
p(x) dx .
How do we determine the probability distribution of a given random variable? To
answer this question, let us ï¬rst consider the case of discrete random variables.
Thus, let X be discrete with values in D = {x1, x2, . . . } âŠ‚R. Then, as observed
above, it follows PX(D) = 1, and, consequently, PX is uniquely determined by the
numbers
pj := PX({xj}) = P{X = xj} = P{9 âˆˆK : X(9) = xj} ,
j = 1, 2, . . . .
(3.3)
Moreover, for any B âŠ†R it follows that
P{9 âˆˆK : X(9) âˆˆB} = PX(B) =

xjâˆˆB
pj .
Consequently, in order to determine PX for discrete X it completely sufï¬ces to determ-
ine the pjs deï¬ned by eq. (3.3). If we know (pj)jâ‰¥1, then the probability distribution PX
of X is completely described.
Remark 3.2.14. In the literature, quite often, one ï¬nds a slightly different approach
for the description of PX. Deï¬ne p : R â†’[0, 1] by
p(x) = P{X = x} ,
x âˆˆR .
(3.4)
This function p is then called the probability mass function of X. Note that p(x) = 0
whenever x âˆ‰D. This function p satisï¬es p(x) â‰¥0, 
xâˆˆR p(x) = 1 and
P{X âˆˆB} =

xâˆˆB
p(x) .
In this setting, the numbers pj in eq. (3.3) coincide with p(xj).

112
3 Random Variables and Their Distribution
Example 3.2.15. Roll a fair die twice. Let X on {1, . . . , 6}2 be deï¬ned by
X(9) = X(91, 92) := 91 + 92 ,
9 = (91, 92) .
Which distribution does X possess?
Answer: The very ï¬rst question one has to answer is always about the possible
values of X. In our case, X attains values in D = {2, . . . , 12}, thus it sufï¬ces to
determine
PX({k}) = P{X = k} = P{(91, 92) âˆˆK : X(91, 92) = k} , k = 2, . . . , 12 .
One easily gets
PX({2}) = P{(91, 92) : 91 + 92 = 2} = #({(1, 1)})
36
= 1
36
PX({3}) = P{(91, 92) : 91 + 92 = 3} = #({(1, 2), (2, 1)})
36
= 2
36
â‹…
â‹…
PX({7}) = P{(91, 92) : 91 + 92 = 7} = #({(1, 6), . . . , (6, 1)})
36
= 6
36
â‹…
â‹…
PX({12}) = P{(91, 92) : 91 + 92 = 12} = #({(6, 6)})
36
= 1
36 ,
hence PX is completely described. For example, it follows that
P{X â‰¤4} = PX((â€“âˆ, 4]) = PX({2}) + PX({3}) + PX({4}) = 1
36 + 2
36 + 3
36 = 1
6 .
Example 3.2.16. A coin is labeled on one side by by â€œ0â€ and and on the other side by
â€œ1â€ and biased as follows: for some p âˆˆ[0, 1], number â€œ1â€ shows up with probability
p, thus â€œ0â€ with probability 1 â€“ p. We toss the coin n times. The result is a sequence
9 = (91, . . . , 9n), where 9i âˆˆ{0, 1}, hence the describing sample space is
K = {0, 1}n = {9 = (91, . . . , 9n) : 9i âˆˆ{0, 1}} .
For i â‰¤n let Xi : K â†’R be deï¬ned by Xi(9) := 9i. That is, Xi(9) is the value of the ith
trial. What distribution does Xi possess?
Answer: In Example 1.9.11 we determined the probability measure P on P(K),
which describes the n-fold tossing of a biased coin. This probability measure was
given by
P({9}) = pk (1 â€“ p)nâ€“k ,
k =
n

j=1
9j
where
9 = (91, . . . , 9n) .
(3.5)

3.2 Probability Distribution of a Random Variable
113
The random variable Xi only attains the values â€œ0â€ and â€œ1.â€ Thus, in order to determine
PXi it sufï¬ces to evaluate PXi({0}) = P{9 âˆˆK : 9i = 0}. Let 9 âˆˆK be a sequence with
9i = 0. Then it may contain the value â€œ1â€ at most n â€“ 1 times. Given k â‰¤n â€“ 1, there are
exactly
nâ€“1
k

such sequences 9 with 9i = 0 and with k times â€œ1.â€ Therefore, we obtain
PXi({0}) = P{9 âˆˆK : 9i = 0} =
nâ€“1

k=0
P{9 âˆˆK : 9i = 0 , 91 + â‹…â‹…â‹…+ 9n = k}
=
nâ€“1

k=0
n â€“ 1
k

pk (1 â€“ p)nâ€“k = (1 â€“ p)
nâ€“1

k=0
n â€“ 1
k

pk (1 â€“ p)nâ€“1â€“k
= (1 â€“ p)[p + (1 â€“ p)]nâ€“1 = 1 â€“ p .
Of course, this also implies PXi({1}) = p.
Remark 3.2.17. Note that all X1, . . . , Xn possess the same distribution, that is,
X1
d= â‹…â‹…â‹…
d= Xn .
Summary: Let X : K â†’R be a discrete random variable. In order to describe its
distribution PX, two things have to be done:
(1) Determine the ï¬nite or countably inï¬nite set D âŠ‚R for which X : K â†’D.
(2) For each x âˆˆD evaluate
PX({x}) = P{X = x} = P{9 âˆˆK : X(9) = x} .
If B âŠ†R, then it follows
P{X âˆˆB} =

xâˆˆBâˆ©D
PX({x}) =

xâˆˆBâˆ©D
P{X = x} .
How do we determine the probability distribution of a random variable if it is con-
tinuous? For each x âˆˆR, P{X = x} = 0, hence the values of P{X = x} cannot be used
to describe PX as they did in the discrete case. Consequently, a different approach is
needed, and this approach is based on the use of distribution functions.
Deï¬nition 3.2.18. Let X be a random variable, either discrete or continuous. Then
its (cumulative) distribution function FX : R â†’[0, 1] is deï¬ned by
FX(t) := PX((â€“âˆ, t]) = P{X â‰¤t} ,
t âˆˆR .
(3.6)

114
3 Random Variables and Their Distribution
Remark 3.2.19. Observe that for discrete and continuous random variables the distri-
bution function equals
FX(t) =

xjâ‰¤t
pj
and
FX(t) =
t

â€“âˆ
p(x) dx,
respectively. Here, in the discrete case, the xjs and pjs are as in eq. (3.3), while p
denotes the density of X in the continuous case.
Furthermore, note that FX is nothing else than the distribution function of the
probability measure PX, as it was introduced in Deï¬nition 1.7.1. Consequently, it pos-
sesses all properties of a â€œusualâ€ distribution function as stated in Proposition 1.7.9.
Proposition 3.2.20. Let FX be deï¬ned by eq. (3.6). Then it possesses the following
properties.
(1)
FX is nondecreasing.
(2)
It follows FX(â€“âˆ) = 0 as well as FX(âˆ) = 1.
(3)
FX is continuous from the right.
Furthermore, if t âˆˆR, then
P{X = t} = FX(t) â€“ FX(t â€“ 0) .
In particular, if X is continuous, then FX is a continuous function from R to [0, 1].
Remark 3.2.21. Note that the converse of the last implication does not hold. Indeed,
there exist random variables X for which FX is continuous, but X does not possess
a density. Such random variables are said to be singularly continuous. These are
exactly those random variables for which the probability measure PX is singularly
continuous in the sense of Remark 1.7.16.
The next result shows that under slightly stronger conditions about FX a density of X
exists.
Proposition 3.2.22. Let FX be continuous and continuously differentiable with the ex-
ception of at most ï¬nitely many points. Then X is continuous with density p(t) = d
dt FX(t).
Hereby the values of p may be chosen arbitrarily at points where the derivative does not
exist; for example, set p(t) = 0 for those points.
Proof: The proof follows from the corresponding properties of distribution functions
for probability measures. Recall that FX is the distribution function of PX.
âˆ

3.2 Probability Distribution of a Random Variable
115
The previous proposition provides us with a method to determine the density of a
given random variable X. Determine the distribution function FX and differentiate it.
The obtained derivative is the density function we are looking for.
The next three examples demonstrate how this method applies.
Example 3.2.23. Let P be the uniform distribution on a sphere K of radius 1. That is,
for each Borel set B âˆˆB(R2) we have
P(B) = vol2(B âˆ©K)
vol2(K)
= vol2(B âˆ©K)
0
.
Deï¬ne the random variable X : R2 â†’R by X(x1, x2) := x1. Of course, we have FX(t) = 0
whenever t < â€“1 and FX(t) = 1 when t > 1. Thus, it sufï¬ces to determine FX(t) if
â€“1 â‰¤t â‰¤1. For those t âˆˆR we obtain
FX(t) = vol2(St âˆ©K)
0
where St is the half-space {(x1, x2) âˆˆR2 : x1 â‰¤t}.
K
S_t
â€“1.0
â€“0.5
0.5
1.0
â€“1.0
â€“0.5
0.5
1.0
Figure 3.1: The intersecting set between K and the half-space St.
If |t| â‰¤1, then
vol2(St âˆ©K) = 2
t

â€“1
âˆš
1 â€“ x2 dx ,
hence,
FX(t) = 2
0
t

â€“1
âˆš
1 â€“ x2 dx ,
and by the fundamental theorem of Calculus, we ï¬nally get
p(t) = d
dt FX(t) = 2
0
âˆš
1 â€“ t2 ,
|t| â‰¤1 .

116
3 Random Variables and Their Distribution
Summing up, the random variable X has the density p with
p(t) =

2
0
âˆš
1 â€“ t2 : |t| â‰¤1
0
: |t| > 1 .
(3.7)
Example 3.2.24. The probability space is the same as in Example 3.2.23, but this time
we deï¬ne X by
X(x1, x2) :=
+
x2
1 + x2
2 ,
(x1, x2) âˆˆR2 .
Of course, it follows FX(t) = 0 if t < 0 while FX(t) = 1 if t > 1. Take t âˆˆ[0, 1]. Then
FX(t) = vol2(K(t))
vol2(K(1)) = t20
0 = t2 ,
where K(t) denotes a sphere of radius t. Differentiating FX with respect to t gives the
density
p(t) =

2 t : 0 â‰¤t â‰¤1
0 : otherwise
Example 3.2.25. Let P be the uniform distribution on [0, 1] and deï¬ne the random
variable X by X(s) = min{s, 1 â€“ s}, s âˆˆR. Find the probability distribution of X.
Answer: It is not difï¬cult to see that
P{X â‰¤t} = 0 if t < 0
and
P{X â‰¤t} = 1 if t > 1/2 .
Thus it remains to evaluate FX(t) for 0 â‰¤t â‰¤1/2. Here we obtain
FX(t) = P{X â‰¤t} = P{s âˆˆ[0, 1] : 0 â‰¤s â‰¤t or 1 â€“ t â‰¤s â‰¤1}
= P{s âˆˆ[0, 1] : 0 â‰¤s â‰¤t} + P{s âˆˆ[0, 1] : 1 â€“ t â‰¤s â‰¤1} = 2t .
Differentiating gives Fâ€²
X(t) = 2 if 0 â‰¤t â‰¤1/2 and FX(t) = 0 otherwise. Hence PX is the
uniform distribution on [0, 1/2].
Summary: To determine the density of a continuous random variable, proceed as
follows:
(1)
Determine FX(t) = P{X â‰¤t}.
(2)
Differentiate FX. Then the derivative p(t) = Fâ€²
X(t) is the desired density.

3.3 Special Distributed Random Variables
117
3.3 Special Distributed Random Variables
We agree upon the following notation: a random variable X is said to be ABC-
distributed (or distributed according to ABC) if its probability distribution is a prob-
ability measure of type ABC. For example, a random variable is Bn,p-distributed (or
distributed according to Bn,p) if PX = Bn,p, that is, if
P{X = k} =
n
k

pk(1 â€“ p)nâ€“k ,
k = 0, . . . , n .
In this way we deï¬ne the following random variables of special type: X is
1.
uniformly distributed on {x1, . . . , xN} if
P{X = x1} = â‹…â‹…â‹…= P{X = xN} = 1
N ,
2.
Poisson distributed or Pois+-distributed if
P{X = k} = +k
k! eâ€“+ ,
k = 0, 1, . . .
3.
hypergeometric distributed if
P{X = m} =
M
m
 Nâ€“M
nâ€“m

N
n

,
m = 0, . . . , n ,
4.
Gp-distributed or geometric distributed if
P{X = k} = p (1 â€“ p)kâ€“1 ,
k = 1, 2, . . . ,
5.
Bâ€“
n,p-distributed or negatively binomial distributed if
P{X = k} =
k â€“ 1
k â€“ n

pn(1 â€“ p)kâ€“n =
k â€“ 1
n â€“ 1

pn(1 â€“ p)kâ€“n ,
k = n, n + 1, . . . .
Remark 3.3.1. In view of Convention 3.1 we may suppose that all random variables
of the preceding type are discrete. More precisely, we even may assume that X has
values in the (at most countably inï¬nite) set D with PX(D) = 1. For example, if X is
Bn,p-distributed we may suppose that X has values in {0, . . . , n}.
In quite similar way we denote special distributed continuous random variables. A
real-valued random variable X is said to be

118
3 Random Variables and Their Distribution
1.
uniformly distributed on [!, "] if PX is the uniform distribution on [!, "]. That is,
if [a, b] âŠ†[!, "], then
P{a â‰¤X â‰¤b} = b â€“ a
" â€“ ! ,
2.
normally distributed or N(,, 32)-distributed if
P{a â‰¤X â‰¤b} =
1
âˆš
203
b

a
eâ€“(xâ€“,)2/232 dx ,
3.
standard normally distributed if it is N(0, 1)-distributed, that is,
P{a â‰¤X â‰¤b} =
1
âˆš
20
b

a
eâ€“x2/2 dx ,
4.
gamma distributed or A!,"-distributed if for 0 â‰¤a < b < âˆ
P{a â‰¤X â‰¤b} =
1
!" A(")
b

a
x"â€“1 eâ€“x/! dx ,
5.
E+,n-distributed or Erlang distributed if it is A+â€“1,n-distributed, that is, for 0 â‰¤a <
b < âˆ
P{a â‰¤X â‰¤b} =
+n
(n â€“ 1)!
b

a
xnâ€“1 eâ€“+x dx ,
6.
E+-distributed or exponentially distributed if for 0 â‰¤a < b < âˆ
P{a â‰¤X â‰¤b} = +
b

a
eâ€“+x dx = eâ€“+a â€“ eâ€“+b ,
7.
Cauchy distributed if
P{a â‰¤X â‰¤b} = 1
0
b

a
dx
1 + x2 = 1
0 [arctan b â€“ arctan a] .
Remark 3.3.2. If a random variable X possesses a special distribution, then all prop-
erties of PX carry over to X. For example, in this language we may now formulate
Poissonâ€™s limit theorem (Proposition 1.4.22) as follows.
Let Xn be Bn,pn-distributed and suppose that n pn â†’+ > 0 as n â†’âˆ. Then
lim
nâ†’âˆP{Xn = k} = P{X = k} ,
k = 0, 1, . . . ,
where X is Pois+-distributed.
Or if X is gamma distributed, then P{X > 0} = PX((0, âˆ)) = 1, and so on.

3.4 Random Vectors
119
Remark 3.3.3. A common question is how does one get a random variable X pos-
sessing a certain given distribution. For example, how do we construct a binomial
or a normally distributed random variable? Suppose we want to model the rolling of
a die by a random variable X, which is uniformly distributed on {1, . . . , 6}. The easi-
est solution is to take K = {1, . . . , 6} endowed with the uniform distribution P and
deï¬ne X by X(9) = 9. But this is not the only way to get such a random variable. One
may also roll the die n times and choose X as the value of the ï¬rst (or of the second,
etc.) roll. In a similar way random variables with other probability distribution may
be constructed. Further possibilities to model random variables will be investigated in
Section 4.4.
Summary: There are two ways to model a random experiment. The classical ap-
proach is to construct a probability space that describes this experiment. For
example, if we toss a fair coin n times and record the number of â€œheads,â€ then this
may be described by the sample space {0, . . . , n} endowed with the probability meas-
ure Bn,1/2. Another way to model a certain random experiment is to choose a random
variable X so that the probability of the occurrence of an event B âŠ†R equals P{X âˆˆB}.
For example, the above experiment of tossing a coin may also be described by a
binomial distributed random variable X (with parameters n and 1/2). The great ad-
vantage of the second approach is that random variables allow algebraic operations.
For example, they can be added, multiplied, or linearly combined. We will use this
advantage extensively in the following sections.
3.4 Random Vectors
Suppose we are given n random variables X1, . . . , Xn deï¬ned on a sample space K.
Our objective is to combine these n variables into a single variable. More precisely, we
will investigate the following type of vector-valued mappings.
Deï¬nition 3.4.1. Let âƒ—X be a mapping from K â†’Rn represented as
âƒ—X(9) =

X1(9), . . . , Xn(9)

,
9 âˆˆK.
Then, âƒ—X is said to be an (n-dimensional) random vector or vector valued ran-
dom variable, provided that each of the Xjs is a (real-valued) random variable.
The random variables Xj, 1 â‰¤j â‰¤n, are called coordinate mappings of âƒ—X.
Instead of âƒ—X, we may also write (X1, . . . , Xn), that is,
(X1, . . . , Xn)(9) = (X1(9), . . . , Xn(9)) ,
9 âˆˆK .

120
3 Random Variables and Their Distribution
A random vector âƒ—X maps K into Rn, that is, we assign to each observed 9 âˆˆK a vector
âƒ—X(9). The mapping âƒ—X is again ï¬xed and nonrandom. The randomness of âƒ—X(9) is caused
by the input.
Example 3.4.2. Roll a die two times. Let X1 be the maximum value, X2 the minimum
and X3 the sum of both rolls. The three-dimensional vector âƒ—X = (X1, X2, X3) maps
K = {1, . . . , 6}2 into R3. For example, the pair (2, 5) is mapped to (5, 2, 7) or (5, 6)
to (6, 5, 11).
Example 3.4.3. Suppose there are N people in an auditorium. Enumerate them from 1
to N and choose one person according to the uniform distribution on {1, . . . , N}. Say
we have chosen person k. Let X1(k) be the height of this person and X2(k) his or her
weight. As a result, we get a random two-dimensional vector (X1(k), X2(k)).
Example 3.4.4. We place n balls into m urns successively. Hereby, each urn is equally
likely. If Xj denotes the number of balls in urn j, then we get an m-dimensional vec-
tor âƒ—X = (X1, . . . , Xm). Observe that the values of âƒ—X lie in the set D = {(k1, . . . , km) :
k1 + â‹…â‹…â‹…+ km = n} âŠ‚Nm
0 .
Remark 3.4.5. The preceding examples suggest that the values of the coordinate map-
pings depend on each other. For instance, in Example 3.4.3 larger values of X1 make
also those of X2 more likely and vice versa. A basic aim of the following sections is to
conï¬rm this guess, that is, we want to ï¬nd a mathematical formulation that describes
whether or not two or more random variables are dependent or independent.
3.5 Joint and Marginal Distributions
The values of the vector âƒ—X are randomly distributed in Rn. Consequently, as in the case
of random variables, events of the form {âƒ—X âˆˆB} occur with certain probabilities. But,
in contrast to the case of random variables, the event B is now a subset of Rn, not
of R as before. More precisely, for events B âŠ†Rn we are interested in the following
quantity4:
P{9 âˆˆK : âƒ—X(9) âˆˆB} = P{9 âˆˆK :

X1(9), . . . , Xn(9)

âˆˆB} .
(3.8)
The next proposition gives the exact formulation of the problem.
4 For random vectors âƒ—X and B âˆˆB(Rn) it follows that âƒ—Xâ€“1(B) âˆˆA. This can be proved by similar
methods as we used in the proof of Proposition 3.1.6. Thus, if B âˆˆB(Rn), then eq. (3.8) and also eq. (3.9)
are well-deï¬ned.

3.5 Joint and Marginal Distributions
121
Deï¬nition 3.5.1. Let âƒ—X : K â†’Rn be a random vector with coordinate mappings
X1, . . . , Xn. For each Borel set B âˆˆB(Rn) we set
Pâƒ—X(B) = P(X1, ... ,Xn)(B) = P{âƒ—X âˆˆB} .
(3.9)
The mapping Pâƒ—X from B(Rn) into [0, 1] is said to be the probability distribution,
or, in short, the distribution of âƒ—X. Often, Pâƒ—X = P(X1, ... ,Xn) will also be called the
joint distribution of X1, . . . , Xn.
In eq. (3.9) we used the shorter expression
P{âƒ—X âˆˆB} = P{9 âˆˆK : âƒ—X(9) âˆˆB} .
As for random variables the following is also valid in the case of random vectors.
Proposition 3.5.2. The mapping Pâƒ—X is a probability measure deï¬ned on B(Rn).
Proof: The proof is completely analogous to that of Proposition 3.2.2. Therefore, we
decide not to present it here.
âˆ
Let us evaluate Pâƒ—X(B) for special Borel sets B âŠ†Rn. If Q is a box in Rn as in eq. (1.65),
that is, for certain real numbers ai < bi we have
Q = [a1, b1] Ã— â‹…â‹…â‹…Ã— [an, bn] ,
then it follows that
Pâƒ—X(Q) = P{âƒ—X âˆˆQ} = P{9 âˆˆK : a1 â‰¤X1(9) â‰¤b1, . . . , an â‰¤Xn(9) â‰¤bn} .
The last expression may also be written as
P{a1 â‰¤X1 â‰¤b1, . . . , an â‰¤Xn â‰¤bn} .
Hence, for each box Q = [a1, b1] Ã— â‹…â‹…â‹…Ã— [an, bn], we obtain
Pâƒ—X(Q) = P{a1 â‰¤X1 â‰¤b1, . . . , an â‰¤Xn â‰¤bn} .

122
3 Random Variables and Their Distribution
Thus the quantity Pâƒ—X(Q) is the probability of the occurrence of the following event: X1
attains a value in [a1, b1], and at the same time X2 attains a value in [a2, b2], and so
on up to Xn attains a value in [an, bn].
Example 3.5.3. Roll a fair die three times. Let X1, X2, and X3 be the observed values in
the ï¬rst, second, and third roll. If Q = [1, 2] Ã— [0, 1] Ã— [3, 4], then it follows
Pâƒ—X(Q) = P{X1 âˆˆ{1, 2}, X2 = 1, X3 âˆˆ{3, 4}} = 1
54 .
Remark 3.5.4. The previous considerations can easily be generalized to sets B âŠ†Rn of
the form B = B1 Ã— â‹…â‹…â‹…Ã— Bn with Bj âˆˆB(R). Then
Pâƒ—X(B) = P{X1 âˆˆB1, . . . , Xn âˆˆBn}
(3.10)
Next we introduce the notion of marginal distributions of a random vector.
Deï¬nition 3.5.5. Let âƒ—X = (X1, . . . , Xn) be a random vector. The n probability
measures PX1 to PXn are called the marginal distributions of âƒ—X.
Observe that each marginal distribution PXj is a probability measure on B(R), while
the joint distribution P(X1, ... ,Xn) is a probability measure deï¬ned on B(Rn).
In this context, the following important question arises: does the joint distribution
determine the marginal distributions and/or can the joint distribution be derived from
the marginal ones?
The next proposition gives the ï¬rst answer.
Proposition 3.5.6. Let âƒ—X = (X1, . . . , Xn) be a random vector. If 1 â‰¤j â‰¤n and B âˆˆB(R),
then it follows
PXj(B) = P(X1, ... ,Xn)(R Ã— â‹…â‹…â‹…Ã—
B

j
Ã— â‹…â‹…â‹…Ã—R) .
In particular, the joint distribution determines the marginal ones.
Proof: The proof is a direct consequence of formula (3.10). Let us apply it to Bi = R if
i /= j and to Bj = B. Then, as asserted,
P(X1, ... ,Xn)(R Ã— â‹…â‹…â‹…Ã—
B

j
Ã— â‹…â‹…â‹…Ã—R)
= P{X1 âˆˆR, . . . , Xj âˆˆB, . . . , Xn âˆˆR} = P{Xj âˆˆB} = PXj(B) .
âˆ
The question whether or not the marginal distributions determine the joint distribu-
tion is postponed for a moment. It will be investigated in Example 3.5.8 and, more

3.5 Joint and Marginal Distributions
123
thoroughly, in Section 3.6. Before investigating this problem, let us derive some con-
crete formulas to evaluate the marginal distributions. Here we consider the two cases
of discrete and continuous random variables separately.
3.5.1 Marginal Distributions: Discrete Case
To make the results in this subsection easier to understand, we only consider the case
of two-dimensional vectors. That is, we investigate two random variables and show
how their distributions may be derived from their joint one. We indicate later on how
this approach extends to more than two random variables.
In order to avoid confusing notations with many indices, given a two-dimensional
random vector, we denote its coordinate mappings by X and Y and not by X1 and X2.
This should not lead to mix-ups. Thus, we investigate the random vector (X, Y) with
joint distribution P(X,Y) and marginal distributions PX and PY. This vector acts as
(X, Y)(9) = (X(9), Y(9)) ,
9 âˆˆK .
Suppose now that X and Y are discrete. Then, there are ï¬nite or countably inï¬nite sets
D = {x1, x2, . . . } and E = {y1, y2, . . . } such that X : K â†’D as well as Y : K â†’E. Con-
sequently, the vector (X, Y) maps K into the (at most countably inï¬nite) set D Ã— E âŠ‚R2.
Observe that
D Ã— E = {(xi, yj) : i, j = 1, 2, . . . } ,
hence P(X,Y) is discrete as well and uniquely described by the numbers
pij := P(X,Y)({(xi, yj)}) = P(X = xi, Y = yj} ,
i, j = 1, 2, . . . .
(3.11)
More precisely, given B âŠ†R2, then
P(X,Y)(B) = P{(X, Y) âˆˆB} =

{(i,j):(xi,yj)âˆˆB}
pij .
We turn now to the description of the marginal distributions PX and PY. These are
uniquely determined by the numbers
qi := PX({xi}) = P{X = xi}
and
rj := PY({yj}) = P{Y = yj} .
(3.12)
In other words, if B, C âŠ†R, then it follows
PX(B) = P{X âˆˆB} =

{i:xiâˆˆB}
qi
and
PY(C) = P{Y âˆˆC} =

{j:yjâˆˆC}
rj .

124
3 Random Variables and Their Distribution
The next proposition is nothing else than a reformulation of Proposition 3.5.6 in the
case of discrete random variables.
Proposition 3.5.7. Let the probabilities pij, qi, and rj be deï¬ned by eqs. (3.11) and (3.12),
respectively. Then the qis and rjs may be evaluated by the following equations:
qi =
âˆ

j=1
pij
for i = 1, 2, . . .
and
rj =
âˆ

i=1
pij
for j = 1, 2, . . . .
Proof: As already mentioned, Proposition 3.5.7 is a direct consequence of Proposition
3.5.6. But for better understanding we prefer to give a direct proof.
By virtue of the 3-additivity of P it follows
qi = P{X = xi} = P{X = xi, Y âˆˆE} = P

X = xi, Y âˆˆ
âˆ
	
j=1
{yj}

=
âˆ

j=1
P

X = xi, Y âˆˆ{yj}

=
âˆ

j=1
P

X = xi, Y = yj

=
âˆ

j=1
pij .
This proves the ï¬rst part. The proof for the rjs follows exactly along the same line.
Here, one uses
rj = P{Y = yj} = P{X âˆˆD, Y = yj} =
âˆ

i=1
P{X = xi, Y = yj} =
âˆ

i=1
pij .
This completes the proof.
âˆ
The equations in Proposition 3.5.7 may be represented in table form as follows:
Y\X x1
x2
x3
â‹…
â‹…
y1
p11
p21
p31
â‹…
â‹…r1
y2
p12
p22
p32
â‹…
â‹…r2
y3
p13
p23
p33
â‹…
â‹…r3
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…â‹…
q1
q2
q3
â‹…
â‹…1
The entries in the above matrix are the corresponding probabilities. For example, the
entry p32 is put into the row marked by x3 and into the column where one ï¬nds y2 at the
left-hand side. This tells us p32 is the probability that X attains the value x3 and, at the

3.5 Joint and Marginal Distributions
125
same time, Y equals y2. At the right and at the lower margins,5 one ï¬nds the corres-
ponding sums of the columns and of the rows, respectively. These numbers describe
the marginal distributions (that of X at the bottom and that of Y at the right margin).
Finally, the number â€œ1â€ at the right lower corner says that both the right column and
bottom row have to add up to â€œ1.â€
Example 3.5.8. There are four balls in an urn, two labeled with â€œ0â€ and another
two labeled with â€œ1.â€ Choose two balls without replacing the ï¬rst one. Let X be the
value of the ï¬rst ball and Y that of the second. Direct calculations (use the law of
multiplication) lead to
P{X = 0, Y = 0} = 1
6 ,
P{X = 0, Y = 1} = 1
3
P{X = 1, Y = 0} = 1
3 ,
P{X = 1, Y = 1} = 1
6
In tabular form this result reads as follows:
Y\X 0
1
0
1
6
1
3
1
2
1
1
3
1
6
1
2
1
2
1
2 1
Now suppose that we replace the ï¬rst ball. This time we denote the values of the
ï¬rst and second ball by Xâ€² and Yâ€², respectively. The corresponding table may now be
written as follows:
Yâ€²\Xâ€² 0
1
0
1
4
1
4
1
2
1
1
4
1
4
1
2
1
2
1
2
1
Let us look at Example 3.5.8 more thoroughly. In both cases (nonreplacing and repla-
cing) the marginal distributions coincide, that is, PX = PXâ€² and PY = PYâ€². But, on the
other hand, the joint distributions are different, that is, we have P(X,Y) /= P(Xâ€²,Yâ€²).
Conclusion: The marginal distributions do not, in general, determine the joint dis-
tribution. Recall that Proposition 3.5.6 asserts the converse implication: The marginal
distributions can be derived from the joint distribution.
5 This explains the name â€œmarginalâ€ for the distribution of the coordinate mappings.

126
3 Random Variables and Their Distribution
Example 3.5.9. Roll a fair die twice. Let X be the minimum value of both rolls and Y
the maximum. Then, if k, l = 1, . . . , 6, it is easy to see that
P{X = k, Y = l} =
â§
âªâªâªâ¨
âªâªâªâ©
0
:
k > l
1
36
:
k = l
1
18
:
k < l
Hence, the joint distribution in table form looks as follows:
Y\X
1
2
3
4
5
6
1
1
36
0
0
0
0
0
1
36
2
1
18
1
36
0
0
0
0
3
36
3
1
18
1
18
1
36
0
0
0
5
36
4
1
18
1
18
1
18
1
36
0
0
7
36
5
1
18
1
18
1
18
1
18
1
36
0
9
36
6
1
18
1
18
1
18
1
18
1
18
1
36
11
36
11
36
9
36
7
36
5
36
3
36
1
36
1
If, for example, B = {(4, 5), (5, 4), (6, 5), (5, 6)}, then the values in the table imply
P(X,Y)(B) = 1/9. In the same way, one gets P{2 â‰¤X â‰¤4} = (9 + 7+ 5)/36 = 7/12.
To ï¬nish, we shortly go into the case of more than two discrete random variables.
Thus, let X1, . . . , Xn be random variables with Xj : K â†’Dj, where the sets Dj are either
ï¬nite or countably inï¬nite. The set D deï¬ned by
D = D1 Ã— â‹…â‹…â‹…Ã— Dn = {(x1, . . . , xn) , xj âˆˆDj}
is at most countably inï¬nite and âƒ—X : K â†’D. Consequently, Pâƒ—X is uniquely described
by the probabilities
px1, ... ,xn = P{X1 = x1, . . . , Xn = xn} ,
xj âˆˆDj .
Proposition 3.5.10. For 1 â‰¤j â‰¤n and x âˆˆDj,
P{Xj = x} =

x1âˆˆD1
â‹…â‹…â‹…

xjâ€“1âˆˆDjâ€“1

xj+1âˆˆDj+1
â‹…â‹…â‹…

xnâˆˆDn
px1, ... ,xjâ€“1,x,xj+1 ... xn .
Proof: The proof is exactly the same as that of Proposition 3.5.7. Therefore,
we omit it.
âˆ
Next, we want to state an important example that shows how Proposition 3.5.10
applies. To do so we need the following deï¬nition.

3.5 Joint and Marginal Distributions
127
Deï¬nition 3.5.11. Let n and m be integers with m â‰¥2 and let p1, . . . , pm be certain
success probabilities satisfying pj â‰¥0 and p1+ â‹…â‹…â‹…+pm = 1. An m-dimensional ran-
dom vector âƒ—X = (X1, . . . , Xm) is called multinomial distributed with parameters
n and p1, . . . , pm if, whenever k1 + â‹…â‹…â‹…+ km = n, then
P{X1 = k1, . . . , Xm = km} =

n
k1, . . . , km

pk1
1
â‹…â‹…â‹…pkm
m .
Equivalently, a random vector âƒ—X is multinomial distributed if and only if
its probability distribution Pâƒ—X is a multinomial distribution as introduced in
Deï¬nition 1.4.12.
Remark 3.5.12. The m-dimensional random vector âƒ—X in Example 3.4.4 is multinomial
distributed with parameters n and pj = 1/m. That means
P{X1 = k1, . . . , Xm = km} =

n
k1, . . . , km
  1
m
n
,
k1 + â‹…â‹…â‹…+ km = n .
Example 3.5.13. Let âƒ—X = (X1, . . . , Xm) be a multinomial random vector with paramet-
ers n and p1, . . . , pm. What are the marginal distributions of âƒ—X ?
Answer: To simplify the calculations, we only determine the probability distribu-
tion of Xm. The other cases follow in the same way. First note that in the notation of
Proposition 3.5.10
pk1, ... ,km =
 
n
k1, ... ,km

pk1
1
â‹…â‹…â‹…pkm
m : k1 + â‹…â‹…â‹…+ km = n
0
: k1 + â‹…â‹…â‹…+ km /= n
Consequently, Proposition 3.5.10 leads to
P{Xm = k} =
n

k1=0
â‹…â‹…â‹…
n

kmâ€“1=0
pk1, ... ,kmâ€“1,k
=

k1+ â‹…â‹…â‹…+kmâ€“1=nâ€“k
n!
k1! â‹…â‹…â‹…kmâ€“1! k! pk1
1
â‹…â‹…â‹…pkmâ€“1
mâ€“1 pk
m
=
n!
k! (n â€“ k)! pk
m

k1+ â‹…â‹…â‹…+kmâ€“1=nâ€“k
(n â€“ k)!
k1! â‹…â‹…â‹…kmâ€“1! pk1
1
â‹…â‹…â‹…pkmâ€“1
mâ€“1
=
n
k

pk
m

k1+ â‹…â‹…â‹…+kmâ€“1=nâ€“k

n â€“ k
k1, . . . , kmâ€“1

pk1
1
â‹…â‹…â‹…pkmâ€“1
mâ€“1
=
n
k

pk
m (p1 + â‹…â‹…â‹…+ pmâ€“1)nâ€“k =
n
k

pk
m (1 â€“ pm)nâ€“k .
Hereby, in the last step, we used the multinomial theorem (Proposition A.16) with mâ€“1
summands, with power n â€“ k and entries p1, . . . , pmâ€“1.

128
3 Random Variables and Their Distribution
Thus Xm is binomial distributed with parameters n and pm. In the same way one
gets that each Xj is Bn,pj-distributed.
Remark 3.5.14. The previous result can also be seen more directly without using Pro-
position 3.5.10. Assume we place n particles into m boxes, where pj is the probability to
put a single particle into box j. Fix some j â‰¤m and and let success occur if a particle is
placed into box j. Then Xj equals the number of successes, hence it is Bn,pj-distributed.
Note that failure occurs if the particle is not placed into box j, and the probability for
this is given by 1 â€“ pj = n
i=1
i/=j pi.
3.5.2 Marginal Distributions: Continuous Case
Let us turn now to the continuous case. Analogous to Deï¬nition 3.2.7, a random vector
is said to be continuous whenever it possesses a density.6 More precisely, we suppose
that a random vector shares the following property.
Deï¬nition 3.5.15. A random vector âƒ—X = (X1, . . . , Xn) is said to be continuous if
there is a function p : Rn â†’R such that, for all numbers, aj < b1, 1 â‰¤j â‰¤n,
P{a1 â‰¤X1 â‰¤b1, . . . , an â‰¤Xn â‰¤bn} =
b1

a1
â‹…â‹…â‹…
bn

an
p(x1, . . . , xn) dxn . . . dx1 .
Equivalently, for all real numbers t1, . . . , tn,
P{X1 â‰¤t1, . . . , Xn â‰¤tn} =
t1

â€“âˆ
â‹…â‹…â‹…
tn

â€“âˆ
p(x1, . . . , xn) dxn . . . dx1 .
The function p is called the density function of âƒ—X or also the joint density of
X1, . . . , Xn.
Remark 3.5.16. Observe that a random vector âƒ—X is continuous if and only if its prob-
ability distribution Pâƒ—X is so, that is, the joint distribution of X1, . . . Xn, is a continuous
probability measure on B(Rn) in the sense of Deï¬nition 1.8.5. Moreover, its density
function coincides with the density of Pâƒ—X.
6 The following is true: for continuous random variables the generated vector possesses a density.
The proof is far above the scope of this book. Furthermore, we do not need this assertion because we
assume âƒ—X to be continuous, not the Xjs.

3.5 Joint and Marginal Distributions
129
In the case of continuous random variables, the marginal distributions are evaluated
by the following rule.
Proposition 3.5.17. If a random vector âƒ—X = (X1, . . . , Xn) has density p : Rn â†’R, then
for each j â‰¤n the random variable Xj is continuous with density
pj(xj) =
âˆ

â€“âˆ
â‹…â‹…â‹…
âˆ

â€“âˆ



nâ€“1 integrals
p( . . . , xjâ€“1, xj, xj+1 . . . )dxn . . . dxj+1 dxjâ€“1 . . . dx1 .
(3.13)
If n = 2, the above formula reads as
p1(x1) =
âˆ

â€“âˆ
p(x1, x2) dx2
and
p2(x2) =
âˆ

â€“âˆ
p(x1, x2) dx1 .
Proof: Fix an integer j â‰¤n. An application of Proposition 3.5.6 implies
PXj([a, b]) = Pâƒ—X(R Ã— â‹…â‹…â‹…Ã— [a, b]
  
j
Ã— â‹…â‹…â‹…Ã—R)
=
âˆ

â€“âˆ
â‹…â‹…â‹…
b

a

j
â‹…â‹…â‹…
âˆ

â€“âˆ
p(x1, . . . xn) dxn . . . dx1
=
b

a
  âˆ
â€“âˆ
â‹…â‹…â‹…
 âˆ
â€“âˆ
p( . . . , xjâ€“1, xj, xj+1, . . . )dxn . . . dxj+1 dxjâ€“1 . . . dx1

dxj
=
 b
a
pj(xj) dxj
with pj deï¬ned by eq. (3.13). The interchange of the integrals was justiï¬ed by Fubiniâ€™s
theorem (Proposition A.5.5); note that p is a density, hence it is non-negative. Since
the preceding equation holds for all real numbers a < b, the function pj has to be a
density of PXj. This completes the proof.
âˆ
Remark 3.5.18. Another way to formulate Proposition 3.5.17 is as follows: if the func-
tion p : Rn â†’R is a joint density of X1, . . . , Xn, then p1, . . . , pn deï¬ned in eq. (3.13)
are densities of the random variables X1, . . . , Xn, respectively.
Example 3.5.19. Choose by random a point x = (x1, x2, x3) in the unit ball of R3. How
are the coordinates x1, x2, and x3 distributed?

130
3 Random Variables and Their Distribution
Answer: Let âƒ—X = (X1, X2, X3) be uniformly distributed on the unit ball
K = {(x1, x2, x3) : x2
1 + x2
2 + x2
3 â‰¤1} .
Then the joint density is given by7
p(x) =

3
40
:
x âˆˆK
0
:
x âˆ‰K
An application of Proposition 3.5.17 leads to p1(x1) = 0 whenever |x1| > 1 and, if |x1| â‰¤1,
then it follows that
p1(x1) = 3
40

x2
2+x2
3â‰¤1â€“x2
1
dx2dx3 = 3
40 (1 â€“ x2
1)0 = 3
4(1 â€“ x2
1) .
Hence, X1 has the density
p1(s) =

3
4(1 â€“ s2)
:
â€“1 â‰¤s â‰¤1
0
:
otherwise
Of course, by symmetry X2 and X3 possess exactly the same distribution densities.
Example 3.5.20. Suppose the two-dimensional random vector (X1, X2) has the density
p deï¬ned by8
p(x1, x2) :=

8 x1x2
:
0 â‰¤x1 â‰¤x2 â‰¤1
0
:
otherwise
Then, the density p1 of X1 is given by
p1(x1) =
âˆ

â€“âˆ
p(x1, x2) dx2 = 8 x1
1

x1
x2 dx2 = 4(x1 â€“ x3
1) ,
0 â‰¤x1 â‰¤1 ,
and p1(x1) = 0 if x1 âˆ‰[0, 1].
In the case of p2, the density of X2, it follows that
p2(x2) =
âˆ

â€“âˆ
p(x1, x2) dx1 = 8 x2
x2

0
x1 dx1 = 4 x3
2 ,
0 â‰¤x2 â‰¤1 ,
and p2(x2) = 0 if x2 âˆ‰[0, 1].
7 Recall vol3(K) = 4
3 0.
8 Check that p is indeed a probability density.

3.6 Independence of Random Variables
131
3.6 Independence of Random Variables
The central question considered in this section is as follows: when are n given random
variables independent? Surely everybody has an intuitive idea about the independ-
ence or dependence of random values. But how do we express this property by a
mathematical formula? Let us try to approach a solution of this problem with an
example.
Example 3.6.1. Roll a fair die twice and deï¬ne the two random variables X1 and X2 as
a result of the ï¬rst and second roll, respectively. These random variables are intuitively
independent of each other. But what formulas do these express? Take two subsets
B1, B2 âˆˆ{1, . . . , 6} and look at their preimages A1 = Xâ€“1
1 (B1) and A2 = Xâ€“1
2 (B2). Then A1
occurs if the ï¬rst result belongs to B1 while the same is true for A2 whenever the second
result belongs to B2. For example, A1 might be that the ï¬rst result is an even number
while A2 could occur if the second result equals â€œ4.â€ The basic observation is, no mat-
ter how B1 and B2 were chosen, the occurrence of their preimages A1 and A2 only de-
pends on the ï¬rst or second roll, respectively. Therefore, they should be independent
(as events) in the sense of Deï¬nition 2.2.2, that is, the following equation should hold:
P{X1 âˆˆB1, X2 âˆˆB2} = P

Xâ€“1
1 (B1) âˆ©Xâ€“1
2 (B2)

= P

A1 âˆ©A2

= P(A1) â‹…P(A2) = P

Xâ€“1
1 (B1)

â‹…P

Xâ€“1
2 (B2)

= P{X1 âˆˆB1} â‹…P{X2 âˆˆB2} .
This observation leads us to the following deï¬nition of independence.
Deï¬nition 3.6.2. Let X1, . . . , Xn be n random variables mapping K into R. These
variables are said to be (stochastically) independent if, for all Borel sets Bj âŠ†R,
P{X1 âˆˆB1, . . . , Xn âˆˆBn} = P{X1 âˆˆB1} â‹…â‹…â‹…P{Xn âˆˆBn} .
(3.14)
Remark 3.6.3. By virtue of Remark 3.5.4, eq. (3.14) may also be written as
P(X1, ... ,Xn)(B1 Ã— â‹…â‹…â‹…Bn) = PX1(B1) â‹…â‹…â‹…PXn(Bn) ,
Bj âˆˆB(R) .
Before proceeding further, we shortly recall Corollary 1.9.7.
Corollary 3.6.4. Given n probability measures P1, . . . , Pn deï¬ned on B(R), there exists
a unique probability measure P on B(Rn), the product measure denoted by P = P1 âŠ—â‹…â‹…â‹…
âŠ—Pn, such that for all Borel sets Bj âŠ†R
P(B1 Ã— â‹…â‹…â‹…Ã— Bn) = P1(B1) â‹…â‹…â‹…Pn(Bn) .
(3.15)

132
3 Random Variables and Their Distribution
Now, we are prepared to state the characterization of independent random variables
by properties of their distributions.
Proposition 3.6.5. The random variables X1, . . . , Xn are independent if and only if their
joint distribution coincides with the product probability of the marginal distributions.
That is, if and only if
P(X1, ... ,Xn) = PX1 âŠ—â‹…â‹…â‹…âŠ—PXn .
Proof: In view of Corollary 3.6.4, the product probability P of PX1, . . . , PXn is the
unique probability measure on B(Rn) satisfying
P(B1 Ã— â‹…â‹…â‹…Ã— Bn) = PX1(B1) â‹…â‹…â‹…PXn(Bn) ,
Bj âˆˆB(R) .
On the other hand, by Remark 3.6.3, the Xjs are independent if and only if
P(X1, ... ,Xn)(B1 Ã— â‹…â‹…â‹…Bn) = PX1(B1) â‹…â‹…â‹…PXn(Bn) ,
Bj âˆˆB(R) .
(3.16)
Consequently, eq. (3.16) holds for all Borel sets Bj if and only if P(X1, ... ,Xn) is the product
probability PX1 âŠ—â‹…â‹…â‹…âŠ—PXn. This completes the proof.
âˆ
Corollary 3.6.6. If X1, . . . , Xn are independent, the joint distribution P(X1, ... ,Xn) is
uniquely determined by its marginal distributions PX1, . . . , PXn.
Proof: Proposition 3.6.5 asserts P(X1, ... ,Xn) = PX1 âŠ—â‹…â‹…â‹…âŠ—PXn. Hence, the joint
distribution is uniquely described by the marginal ones.
âˆ
The next proposition clariï¬es the relation between the properties â€œindependence of
eventsâ€ and â€œindependence of random variables.â€ At a ï¬rst glance the assertion looks
trivial or self-evident, but it is not at all. The reason is that the deï¬nition of independ-
ence for more than two events, as given in Deï¬nition 2.2.12, is more complicated than
in the case of two events.
Proposition 3.6.7. The random variables X1, . . . , Xn are independent if and only if for
all Borel sets B1, . . . , Bn in R the events
Xâ€“1
1 (B1), . . . , Xâ€“1
n (Bn)
are stochastically independent in (K, A, P).

3.6 Independence of Random Variables
133
Proof 9: When are Xâ€“1
1 (B1), . . . , Xâ€“1
n (Bn) independent? According to Deï¬nition 2.2.12
this holds if for all subsets I âŠ†{1, . . . , n}
P
 
iâˆˆI
Xâ€“1
i (Bi)

=
%
iâˆˆI
P

Xâ€“1
i (Bi)

.
(3.17)
On the other hand, by Deï¬nition 3.6.2, the X1, . . . , Xn are independent if
P
 n

i=1
Xâ€“1
i (Bi)

= P{X1 âˆˆB1, . . . , Xn âˆˆBn}
=
n
%
i=1
P{Xi âˆˆBi} =
n
%
i=1
P

Xâ€“1
i (Bi)

.
(3.18)
Of course, eq. (3.17) implies eq. (3.18); use eq. (3.17) with I = {1, . . . , n}. But it is far
from clear why, conversely, eq. (3.18) should imply eq. (3.17). As we saw in Example
2.2.10, for ï¬xed sets Bj this is even false. The key observation is that eq. (3.17) has to be
valid for all Borel sets Bj. This allows us to choose the Borel sets in an appropriate way.
Thus let us assume the validity of eq. (3.18) for all Borel sets in R. Given Bj âˆˆB(R)
and a subset I of {1, . . . , n} we introduce â€œnewâ€ Bâ€²
1, . . . , Bâ€²
n as follows: Bâ€²
i = Bi if i âˆˆI
and Bâ€²
i = R if i âˆ‰I. This choice of the Bâ€²
j implies Xâ€“1
i (Bâ€²
i) = K whenever i âˆ‰I. An
application of eq. (3.18) to Bâ€²
1, . . . , Bâ€²
n leads to (recall Xâ€“1
i (Bâ€²
i) = K if i âˆ‰I)
P

iâˆˆI
Xâ€“1
i (Bi)

= P
 n

i=1
Xâ€“1
i (Bâ€²
i)

=
n
%
i=1
P

Xâ€“1
i (Bâ€²
i)

=
%
iâˆˆI
P

Xâ€“1
i (Bi)

.
This proves eq. (3.17) for any subset I of {1, . . . , n}. Hence, Xâ€“1
1 (B1), . . . , Xâ€“1
n (Bn) are
independent as asserted.
âˆ
Remark 3.6.8. To verify the independence of X1, . . . , Xn, it is not necessary to check
eq. (3.14) for all Borel sets Bj. It sufï¬ces if this is valid for real intervals [aj, bj]. In other
words, X1, . . . , Xn are independent if and only if, for all aj < bj,
P{a1 â‰¤X1 â‰¤b1, . . . , an â‰¤Xn â‰¤bn}
= P{a1 â‰¤X1 â‰¤b1} â‹…â‹…â‹…P{an â‰¤Xn â‰¤bn} .
(3.19)
Furthermore, it also sufï¬ces to choose the Borel sets as intervals (â€“âˆ, tj] for tj âˆˆR, i.e.,
X1, . . . , Xn are independent if and only if, for all tj âˆˆR,
P{X1 â‰¤t1, . . . , Xn â‰¤tn} = P{X1 â‰¤t1} â‹…â‹…â‹…P{Xn â‰¤tn} .
9 The proposition and its proof are not necessarily needed for further reading. But they may be helpful
for a better understanding of the independence of events and of random variables.

134
3 Random Variables and Their Distribution
3.6.1 Independence of Discrete Random Variables
As in Section 3.5.1, we restrict ourselves to the case of two random variables. The ex-
tension to more than two variables is straightforward and will be shortly considered
at the end of this section. We use the same notation as in Section 3.5.1. That is, the
two random variables are denoted by X and Y, and they map K into D = {x1, x2, . . . }
and E = {y1, y2, . . . }, respectively. The joint distribution (X, Y) as well as the marginal
distributions, that is, the distributions of X and Y, are described as in eqs. (3.11) and
(3.12) by
pij = P{X = xi, Y = yj} ,
qi = P{X = xi}
and
rj = P{Y = yj} .
With these notations the following result is valid.
Proposition 3.6.9. For the independence of two random variables X and Y, it is
necessary and sufï¬cient that
pij = qi â‹…rj ,
1 â‰¤i, j < âˆ
Proof: The assertion is an immediate consequence of Propositions 1.9.9 and 3.6.5. But,
because of the importance of the result, we give an alternative proof avoiding the direct
use of product probabilities; only the techniques are similar.
Let us ï¬rst show that the condition is necessary. Therefore, choose indices i and
j, and put B1 := {xi} and B2 := {yj}. Then {X âˆˆB1} occurs if and only if X = xi, and, in
the same way, the occurrence of {Y âˆˆB2} is equivalent to Y = yj. Since X and Y are
assumed to be independent, as claimed,
pij = P{X = xi, Y = yj} = P{X âˆˆB1, Y âˆˆB2} = P{X âˆˆB1} â‹…P{Y âˆˆB2}
= P{X = xi} â‹…P{Y = yj} = qi â‹…rj .
To prove the converse implication, assume we have pij = qi â‹…rj for all pairs (i, j) of
integers. Let B1 and B2 be two arbitrary subsets of R. Then it follows
P{X âˆˆB1, Y âˆˆB2} = P(X,Y)(B1 Ã— B2) =

{(i,j):(xi,yj)âˆˆB1Ã—B2}
pij
=

{(i,j):xiâˆˆB1, yjâˆˆB2}
qi â‹…rj =

{i:xiâˆˆB1}

{ j:yjâˆˆB2}
qi â‹…rj
=
 
{i:xiâˆˆB1}
qi

â‹…


{ j:yjâˆˆB2}
rj

= PX(B1) â‹…PY(B2)
= P(X âˆˆB1) â‹…P(Y âˆˆB2) .

3.6 Independence of Random Variables
135
Since B1 and B2 were arbitrary, the random variables X and Y are independent. This
completes the proof.
âˆ
Remark 3.6.10. The previous proposition implies again that for (discrete) independ-
ent random variables the joint distribution is determined by the marginal ones.
Indeed, in order to know the pijs, it sufï¬ces to know the qis and rjs.
Let us represent the assertion of Proposition 3.6.9 graphically. It asserts that the ran-
dom variables X and Y are independent if and only if the table describing their joint
distribution may be represented as follows:
Y\X
x1
x2
x3
â‹…
â‹…
y1
q1r1
q2r1
q3r1
â‹…
â‹…
r1
y2
q1r2
q2r2
q3r2
â‹…
â‹…
r2
y3
q1r3
q2r3
q3r3
â‹…
â‹…
r3
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
â‹…
q1
q2
q3
â‹…
â‹…
1
Example 3.6.11. Proposition 3.6.9 lets us conclude that X and Y in Example 3.5.8
(without replacing) are dependent while Xâ€² and Yâ€² (with replacement) are inde-
pendent. Furthermore, by the same argument, the random variables X and Y in
Example 3.5.9 (minimum and maximum value when rolling a die twice) are dependent
as well.
Example 3.6.12. Let X and Y be two independent Pois+-distributed random variables.
Then the joint distribution of the vector (X, Y) is determined by
P{X = k, Y = l} = +k+l
k! l! eâ€“2+ ,
(k, l) âˆˆN0 Ã— N0 .
For example, applying this for P(X,Y)(B) with B = {(k, l) : k = l} leads to
P{X = Y} =
âˆ

k=0
P{X = k, Y = k} =
âˆ

k=0
+2k
(k!)2 eâ€“2+ .
Example 3.6.13. Suppose X and Y are two independent geometric distributed random
variables, with parameters p and q, respectively. Evaluate P(X â‰¤Y) .

136
3 Random Variables and Their Distribution
Solution: By the independence of X and Y,
P(X â‰¤Y) =
âˆ

k=1
P(X = k, Y â‰¥k) =
âˆ

k=1
P(X = k) â‹…P(Y â‰¥k)
=
âˆ

k=1
p(1 â€“ p)kâ€“1
âˆ

l=k
q(1 â€“ q)lâ€“1 = p q
 âˆ

k=0
(1 â€“ p)k

âˆ

l=k+1
(1 â€“ q)lâ€“1

= p q
 âˆ

k=0
(1 â€“ p)k
 âˆ

l=k
(1 â€“ q)l

= p q
 âˆ

k=0
(1 â€“ p)k(1 â€“ q)k
 âˆ

l=0
(1 â€“ q)l

=
p
1 â€“ (1 â€“ p)(1 â€“ q) =
p
p + q â€“ pq .
Example of application: Player A rolls a die and, simultaneously, player B tosses two
fair coins labeled with â€œ0â€ and â€œ1.â€ Find the probability that player A observes the
number â€œ6â€ for the ï¬rst time strictly before player B gets â€œ1â€ two times.
Answer: Let {Y = k} be the event that player A observes his ï¬rst â€œ6â€ in trial k.
Similarly, {X = k} occurs if player B has his ï¬rst two â€œonesâ€ in trial k. Then we ask
for the probability P{Y < X}. Note that X is geometrically distributed with parameter
p = 1/4, while the success probability for Y is q = 1/6. Hence, by the above calculations,
P{Y < X} = 1 â€“ P{X â‰¤Y} = 1 â€“
1/4
1/4 + 1/6 â€“ 1/24 = 1
3 .
The next objective is to investigate in which cases two quite special random variables
are independent. To this end we need the following notation.
Deï¬nition 3.6.14. Let K be a set and A âŠ†K. Then the indicator function 1A :
K â†’R of A is deï¬ned by
1A(9) :=

1 : 9 âˆˆA
0 : 9 âˆ‰A
(3.20)
Let us state some basic properties of indicator functions.
Proposition 3.6.15. Let (K, A, P) be a probability space.
(1)
The indicator function of a set A âŠ†K is a random variable if and only if A âˆˆA.
(2)
If A âˆˆA, then 1A is B1,p-distributed (binomial) where p = P(A).
(3)
If A, B âˆˆA, then the random variables 1A and 1B are independent if and only if the
events A and B are so.

3.6 Independence of Random Variables
137
Proof: Given t âˆˆR, the event {9 âˆˆK : 1A(9) â‰¤t} is either empty, Ac or K in depend-
ence of t < 0, 0 â‰¤t < 1 or t â‰¥1. Consequently, the set {9 âˆˆK : 1A(9) â‰¤t} is in A for all
t âˆˆR if and only if Ac âˆˆA. But this happens if and only if A âˆˆA, which proves the ï¬rst
assertion.
To prove the second part we ï¬rst observe that 1A attains only the values â€œ0â€ and
â€œ1.â€ Since
P{1A = 1} = P{9 âˆˆK : 1A(9) = 1} = P(A) = p ,
it is B1,p-distributed with p = P(A) as claimed.
Let us turn to the last assertion. Given A, B âˆˆA their joint distribution in table
form is
1B\1A
0
1
0
P(Ac âˆ©Bc) P(A âˆ©Bc) P(Bc)
1
P(Ac âˆ©B) P(A âˆ©B) P(B)
P(Ac)
P(A)
Consequently, by Proposition 3.6.9 the random variables 1A and 1B are independent
if and only if the following equations are valid:
P(Ac âˆ©Bc) = P(Ac) â‹…P(Bc) ,
P(Ac âˆ©B) = P(Ac) â‹…P(B)
P(A âˆ©Bc) = P(A) â‹…P(Bc) ,
P(A âˆ©B) = P(A) â‹…P(B) .
Because of Proposition 2.2.7 these four equations are satisï¬ed if and only if the events
A and B are independent. This proves the third assertion.
âˆ
Finally, let us shortly discuss the independence of more than two discrete random
variables. Hereby we use the same notation as in Proposition 3.5.10, that is, the ran-
dom variables X1, . . . , Xn satisfy Xj : K â†’Dj, where Dj is either ï¬nite or countably
inï¬nite. Then the following generalization of Proposition 3.6.9 is valid. Its proof is
almost identical to that for two variables. Therefore, we omit it.
Proposition 3.6.16. The random variables X1, . . . , Xn are independent if and only if for
all xj âˆˆDj
P{X1 = x1, . . . , Xn = xn} = P{X1 = x1} â‹…â‹…â‹…P{Xn = xn} .
Example 3.6.17. Let us consider the problem of tossing a biased coin n times. The
sample space is K = {0, 1}n, and the describing probability measure P is as in eq. (3.5).
The random variables Xj are deï¬ned as results of toss j. Then Xj : K â†’Dj, where

138
3 Random Variables and Their Distribution
Dj = {0, 1}. If we choose arbitrary xj âˆˆDj, then either xj = 0 or xj = 1. Let k be the
number of those xj, which equals 1, that is, k = x1 + â‹…â‹…â‹…+ xn. Formula (3.5) implies
P{X1 = x1, . . . , Xn = xn} = P{(x1, . . . , xn)} = pk(1 â€“ p)nâ€“k .
On the other hand, as shown in Example 3.2.16, the probability distribution of each Xj
satisï¬es
P{Xj = 0} = 1 â€“ p
and
P{Xj = 1} = p .
Since exactly k of the xjs are â€œ1â€ and n â€“ k are â€œ0,â€ this implies
P{X1 = x1} â‹…â‹…â‹…P{Xn = xn} = pk(1 â€“ p)nâ€“k .
Summing up, for all xj âˆˆDj,
P{X1 = x1, . . . , Xn = xn} = pk(1 â€“ p)nâ€“k = P{X1 = x1} â‹…â‹…â‹…P{Xn = xn} ,
that is, X1, . . . , Xn are independent.
3.6.2 Independence of Continuous Random Variables
We will consider the question in which cases continuous random variables are in-
dependent. Thus, let X1, . . . , Xn be continuous random variables with distribution
densities p1, . . . , pn, that is, for 1 â‰¤j â‰¤n and real numbers a < b
PXj([a, b]) = P{a â‰¤Xj â‰¤b} =
b

a
pj(x) dx .
With this notation the independence of the Xjs may be characterized as follows.
Proposition 3.6.18. For random variables X1, . . . , Xn with densities p1, . . . , pn we
deï¬ne a function p : Rn â†’R by
p(x1, . . . , xn) := p1(x1) â‹…â‹…â‹…pn(xn) ,
(x1, . . . , xn) âˆˆRn .
(3.21)
Then the Xjs are independent if and only if p deï¬ned by eq. (3.21) is a distribution density
of the random vector âƒ—X = (X1, . . . , Xn).
Proof: As in the discrete case, the result follows directly from Propositions 1.9.12 and
3.6.5. Without using product probabilities, we may argue as follows.

3.6 Independence of Random Variables
139
First we observe that p deï¬ned by eq. (3.21) is a distribution density of âƒ—X if and
only if for all aj < bj
P{a1 â‰¤X1 â‰¤b1, . . . , an â‰¤Xn â‰¤bn}
=
b1

a1
â‹…â‹…â‹…
bn

an
p1(x1) â‹…â‹…â‹…pn(xn) dxn . . . dx1 .
(3.22)
The right-hand side of eq. (3.22) coincides with
â›
âœâ
b1

a1
p1(x1) dx1
â
âŸâ â‹…â‹…â‹…
â›
â
bn

an
pn(xn) dxn
â
â 
= P{a1 â‰¤X1 â‰¤b1} â‹…â‹…â‹…P{an â‰¤Xn â‰¤bn} .
From this we derive that eq. (3.22) is valid for all aj < bj if and only if
P{a1 â‰¤X1 â‰¤b1, . . . , an â‰¤Xn â‰¤bn} = P{a1 â‰¤X1 â‰¤b1} â‹…â‹…â‹…P{an â‰¤Xn â‰¤bn} .
By Remark 3.6.8 this is equivalent to the independence of the Xjs. This completes the
proof.
âˆ
Example 3.6.19. Throw a dart to a target, which is a circle of radius 1. The center of the
circle is the point (0, 0) and (x1, x2) âˆˆK denotes the point where the dart hits the target.
We assume that the point hit is uniformly distributed on K. The question is whether
or not the coordinates x1 and x2 of the point hit are dependent or independent of each
other.
Answer: Let P be the uniform distribution on K, and deï¬ne two random variables
X1 and X2 by X1(x1, x2) = x1 and X2(x1, x2) = x2. In this notation, the above question
is whether the random variables X1 and X2 are independent. The density p1 of X1 was
found in eq. (3.7). By symmetry, p2, the density of X2, coincides with p1, that is, we have
p1(x1) =

2
0
+
1 â€“ x2
1 : |x1| â‰¤1
0
: |x1| > 1
and
p2(x2) =

2
0
+
1 â€“ x2
2 : |x2| â‰¤1
0
: |x2| > 1 .
But p1(x1) â‹…p2(x2) cannot be a distribution density of P(X1,X2). Indeed, the vector âƒ—X =
(X1, X2) is uniformly distributed on K, thus its (correct) density is p with
p(x1, x2) =

1
0
:
x2
1 + x2
2 â‰¤1
0
:
otherwise
Thus, we conclude that X1 and X2 are dependent, hence also the coordinates x1 and x2
of the point hit.

140
3 Random Variables and Their Distribution
Example 3.6.20. We suppose now that the dart does not hit a circle but some rect-
angle set R := [!1, "1]Ã—[!2, "2]. Again we assume that the point (x1, x2) âˆˆR is uniformly
distributed on R. The posed question is the same as in Example 3.6.19, namely whether
x1 and x2 are independent of each other.
Answer: Deï¬ne X1 and X2 as in the previous example. By assumption, the vector
âƒ—X = (X1, X2) is uniformly distributed on R, hence its distribution density p is given by
p(x1, x2) =

1
vol2(R)
:
(x1, x2) âˆˆR
0
:
(x1, x2) âˆ‰R .
For the density p1 of X1 we get
p1(x1) =
âˆ

â€“âˆ
p(x1, x2) dx2 = "2 â€“ !2
vol2(R) =
1
"1 â€“ !1
provided that !1 â‰¤x1 â‰¤"1. Otherwise, we have p1(x1) = 0. This tells us that X1 is
uniformly distributed on [!1, "1]. In the same way, we obtain for x2 âˆˆ[!2, "2] that
p2(x2) =
1
"2 â€“ !2
and p2(x2) = 0 otherwise. Hence, X2 is also uniformly distributed, but this time on
[!2, "2]. From the equations for p1 and p2 it follows that for the joint density p holds
p(x1, x2) = p1(x1) â‹…p(x2) ,
(x1, x2) âˆˆR2 .
Consequently, by Proposition 3.6.18 the random variables X1 and X2 are independent,
and so are the coordinates x1 and x2 of the point hit.
Example 3.6.21. Let us look at Example 3.6.20 from the reversed side. Now we assume
that the coordinates are uniformly distributed, not the vector. Thus let U1, . . . , Un be
independent random variables with Uj uniformly distributed on the interval [!j, "j],
1 â‰¤j â‰¤n. Then the random vector âƒ—U = (U1, . . . , Un) is (multivariate) uniformly dis-
tributed on the box K = [!1, "1] Ã— â‹…â‹…â‹…Ã— [!n, "n]. This is an immediate consequence
of Example 1.9.13 combined with Proposition 3.6.5. A direct proof of this fact, without
using product measures, is as follows.
The density of Uj is pj =
1
"jâ€“!j 1[!j,"j], hence by Proposition 3.6.18 the joint density
p of âƒ—U is given by
p(x) = p1(x1) â‹…â‹…â‹…pn(xn) =
n
%
j=1
("j â€“ !j)â€“1 =
1
voln(K) ,
x = (x1, . . . , xn) âˆˆK ,

3.7 â‹†Order Statistics
141
and p(x) = 0 if x âˆ‰K. Therefore,
P{âƒ—U âˆˆB} =

B
p(x) dx = voln(K âˆ©B)
voln(K)
,
B âˆˆB(Rn) ,
and âƒ—U is uniformly distributed on K as asserted.
Example 3.6.22. Let X1, . . . , Xn be independent standard normally distributed.
Which joint density does the vector âƒ—X = (X1, . . . , Xn) possess?
Answer: The densities pj of each of the Xjs are
pj(x) =
1
âˆš
20
eâ€“x2/2 ,
x âˆˆR .
Consequently, by the independence of the Xjs the joint density p equals
p(x) = p1(x1) â‹…â‹…â‹…pn(xn) =
1
(20)n/2 eâ€“(x2
1+ â‹…â‹…â‹…+x2n)/2
=
1
(20)n/2 eâ€“|x|2/2 ,
x = (x1, . . . , xn) .
This tells us that Pâƒ—X
= N(0, 1)âŠ—n (cf. Deï¬nition 1.9.16) or, equivalently, âƒ—X is n-
dimensional standard normally distributed.
Example 3.6.23. If X1, . . . , Xn are independent E+-distributed, then
pj(t) =

0
: t < 0
+eâ€“+t : t â‰¥0
hence, the random vector âƒ—X = (X1, . . . , Xn) has the joint density
p(t) = +neâ€“+(t1+ â‹…â‹…â‹…+tn) ,
t = (t1, . . . , tn) , tj â‰¥0 ,
and p(t) = 0 if one of the tjs is negative.
3.7
â‹†Order Statistics
This section is devoted to a quite practical problem. Suppose we execute a random
experiment n times so that different trials are independent of each other. The results
of these trials are x1, . . . , xn. For example, one may think of n different measurements
of the same item, and x1, . . . , xn are the observed values. After getting x1, . . . , xn we
reorder them by their size. These â€œnewâ€ numbers are denoted by xâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤xâˆ—
n. In
other words, the numbers are the same as before but in nondecreasing order. We now
ask for the distribution of the ordered xâˆ—
ks.

142
3 Random Variables and Their Distribution
The precise mathematical formulation of this problem is as follows: let X1, . . . , Xn
be n independent identically distributed random variables deï¬ned on a sample
space K. For each ï¬xed 9 âˆˆK, we choose a permutation 09 âˆˆSn (we use the notation
of Section A.3.1), such that
X09(1)(9) â‰¤â‹…â‹…â‹…â‰¤X09(n)(9) .
(3.23)
Of course, it may happen that there exists more than one permutation for which the
inequalities (3.23) hold, namely if Xi(9) = Xj(9) for some i /= j. In this case, we choose
any of these permutations. Finally, for each 9 âˆˆK we set
Xâˆ—
1 (9) = X09(1)(9) , . . . , Xâˆ—
n(9) = X09(n)(9) .
In this way10 we obtain random variables Xâˆ—
k satisfying Xâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤Xâˆ—
n. For example, it
holds
Xâˆ—
1 = min{X1, . . . , Xn} , . . . , Xâˆ—
n = max{X1, . . . , Xn} .
Remark 3.7.1. It is worthwhile to mention that the Xâˆ—
ks are no longer independent nor
identical distributed.
Remark 3.7.2. For a better understanding of the procedure, let us look at the
case n = 3. There exist 6 = 3! possible ways the Xj(9)s may be ordered. For example,
if X2(9) < X3(9) < X1(9), then set 09(1) = 2, 09(2) = 3, and 09(3) = 1 or, equival-
ently, 9 âˆˆA0 where 0(1) = 2, 0(2) = 3, and 0(3) = 1. Hence, in that example we have
Xâˆ—
1 (9) = X2(9), Xâˆ—
2(9) = X3(9), and Xâˆ—
3(9) = X1(9). At the end, we get 6 subsets A0 of
K where 09 = 0 for a given 0 âˆˆS3, that is, on each of these six sets, the same type of
reordering is applied.
Deï¬nition 3.7.3. The ordered random variables Xâˆ—
1 , . . . , Xâˆ—
n are called order
statistics of X1, . . . , Xn.
Remark 3.7.4. Order statistics play an important role in Mathematical Statistics. For
example, suppose at time t = 0 we switch on n light bulbs of the same type. Let us
record the times 0 < tâˆ—
1 < tâˆ—
2 < . . . < tâˆ—
n, where some of the n bulbs burns out. Then
these times are nothing else than the order statistics of the life times t1, . . . , tn of the
ï¬rst, second, and so on light bulb.
10 Another way to describe the procedure of reordering is as follows. For each permutation 0 let
A0 âŠ†K be the set of those 9 âˆˆK for which X0(1)(9) â‰¤â‹…â‹…â‹…â‰¤X0(n)(9), that is, where 0 = 09. Then
it follows Xâˆ—
j (9) = X0(j)(9) whenever 9 âˆˆA0. Note that there are at most n! different sets A0.

3.7 â‹†Order Statistics
143
Before we state and prove the main result of this section, let us recall that the Xjs
are assumed to be identically distributed. Consequently, all of them possess the same
distribution function F. That is, for all j â‰¤n, we have
F(t) = P{Xj â‰¤t} ,
t âˆˆR ,
Proposition 3.7.5. Let X1, . . . , Xn be independent identically distributed random vari-
ables with distribution function F. Then for each k â‰¤n we have
P{Xâˆ—
k â‰¤t} =
n

i=k
n
i

F(t)i (1 â€“ F(t))nâ€“i , t âˆˆR .
(3.24)
Proof: Fix t âˆˆR. When does the event {Xâˆ—
k â‰¤t} occur? To answer this, for i â‰¤n
introduce disjoint sets Ai as follows: the event Ai occurs if and only if exactly i of the
Xjs attain a value in (â€“âˆ, t]. More precisely,
Ai = {9 âˆˆK : #{j â‰¤n : Xj(9) â‰¤t} = i} .
Next, observe that the event {Xâˆ—
k â‰¤t} occurs if and only if at least k of the Xjs attain a
value in (â€“âˆ, t]. For example, it holds Xâˆ—
1 â‰¤t if at least one of the Xjs is less than or
equal to t while we have Xâˆ—
n â‰¤t if Xj â‰¤t for all j â‰¤n. Thus, by the deï¬nition of the Ais
the event {Xâˆ—
k â‰¤t} coincides with n
i=k Ai . Consequently, since the Ais are disjoint, it
follows that
P{Xâˆ—
k â‰¤t} =
n

i=k
P(Ai) .
(3.25)
Let Yj = 1(â€“âˆ,t](Xj). Then Yj = 1 if and only if Xj â‰¤t while Yj = 0 otherwise. Hence, the
Yjs are binomial distributed with parameters 1 and p, where
p = P{Yj = 1} = P{Xj â‰¤t} = F(t) .
Since the Xjs are independent, so are the Yjs and their sum11 Y1 + â‹…â‹…â‹…+ Yn is binomial
distributed with parameters n and p = F(t). Note that the event Ai occurs if and only if
Y1 + â‹…â‹…â‹…+ Yn = i , which implies
P(Ai) = P{Y1 + â‹…â‹…â‹…+ Yn = i} =
n
i

pi(1 â€“ p)nâ€“i =
n
i

F(t)i(1 â€“ F(t))nâ€“i .
(3.26)
Plugging eq. (3.26) into eq. (3.25) proves eq. (3.24).
âˆ
11 Here we already use a result, which will be proved later on in Proposition 4.6.1.

144
3 Random Variables and Their Distribution
Example 3.7.6. Let us choose independently and according to the uniform distribu-
tion n numbers x1, . . . , xn out of {1, . . . , N}. Here, the same number may be chosen
more than one time. Given integers m â‰¤N and k â‰¤n, ï¬nd the probability that the kth
largest number xâˆ—
k equals m.
Answer: The distribution function F of the uniform distribution on {1, . . . , N}
satisï¬es
F(m) = m
N ,
m = 1, . . . , N .
Thus Proposition 3.7.5 implies
P{xâˆ—
k â‰¤m} =
n

i=k
n
i
 m
N

i 
1 â€“ m
N

nâ€“i
.
Because of {xâˆ—
k = m} = {xâˆ—
k â‰¤m}\{xâˆ—
k â‰¤m â€“ 1} we obtain
P{xâˆ—
k = m} = P{xâˆ—
k â‰¤m} â€“ P{xâˆ—
k â‰¤m â€“ 1}
=
n

i=k
n
i
) m
N

i 
1 â€“ m
N

nâ€“i
â€“
m â€“ 1
N
i 
1 â€“ m â€“ 1
N
nâ€“i *
.
For example, roll a die four times and order the results in nondecreasing order as
xâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤xâˆ—
4. What is the probability that xâˆ—
3 equals 5 ?
Answer: Let us apply the previous formula with N = 6, k = 3, and n = 4. For
m = 1, . . . , 6 this implies
P{xâˆ—
3 = m} =
4

i=3
4
i
) m
6

i 6 â€“ m
6
4â€“i
â€“
m â€“ 1
6
i 6 â€“ m + 1
6
4â€“i *
.
The probabilities are
m
P{xâˆ—
3 = m}
1
0.0162037
2
0.0949074
3
0.201389
4
0.280093
5
0.275463
6
0.131944
thus, xâˆ—
3 = 4 is most likely.

3.7 â‹†Order Statistics
145
Let us now turn to the case of continuous random variables. That is, we assume that
the random variables Xj possess a distribution density p satisfying
P{Xj â‰¤t} =
t

â€“âˆ
p(x) dx ,
t âˆˆR .
Again we remark that the preceding formula holds for all j â‰¤n. Indeed, the Xjs
are identically distributed, hence they all have the same density. A natural question
arises: what distribution density does Xâˆ—
k possess?
Proposition 3.7.7. Suppose p is the common density of the Xjs. Let Xâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤Xâˆ—
n be
the order statistics of the Xj. Then the distribution density pk of Xâˆ—
k is given by
pk(t) =
n!
(k â€“ 1)!(n â€“ k)! p(t) F(t)kâ€“1(1 â€“ F(t))nâ€“k .
Proof: It holds that
pk(t) = d
dt P{Xâˆ—
k â‰¤t} = d
dt
n

i=k
n
i

F(t)i (1 â€“ F(t))nâ€“i
=
n

i=k
i
n
i

p(t)F(t)iâ€“1(1 â€“ F(t))nâ€“i â€“
n

i=k
(n â€“ i)
n
i

p(t)F(t)i (1 â€“ F(t))nâ€“iâ€“1 . (3.27)
In fact, the index i in the second sum of eq. (3.27) runs only from k to n â€“ 1. Hence,
shifting it by 1, this sum becomes
n

i=k+1
(n â€“ i + 1)
 n
i â€“ 1

p(t) F(t)iâ€“1 (1 â€“ F(t))nâ€“i .
Because of
i
n
i

=
n!
(i â€“ 1)!(n â€“ i)! = (n â€“ i + 1)
 n
i â€“ 1

both sums in eq. (3.27) cancel out for i = k + 1, . . . , n, and it remains the term for i = k.
Thus, we obtain
pk(t) = k
n
k

p(t) F(t)kâ€“1(1 â€“ F(t))nâ€“k
=
n!
(k â€“ 1)!(n â€“ k)! p(t) F(t)kâ€“1(1 â€“ F(t))nâ€“k
as asserted.
âˆ

146
3 Random Variables and Their Distribution
Example 3.7.8. Let us choose independently and according to the uniform distribu-
tion on [0, 1] numbers x1, . . . , xn. After reordering them, we get 0 â‰¤xâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤xâˆ—
n â‰¤1.
Which distribution does xâˆ—
k possess?
Answer: The density p of the uniform distribution on [0, 1] is 1[0,1]. Furthermore,
its distribution function F is given by F(t) = t for 0 â‰¤t â‰¤1. Thus, by Proposition 3.7.7,
the density pk coincides with
pk(t) =
n!
(k â€“ 1)!(n â€“ k)! tkâ€“1(1 â€“ t)nâ€“k ,
0 â‰¤t â‰¤1 .
As already mentioned in Example 1.6.31, this is nothing else than the density of a beta
distribution with parameters k and n â€“ k + 1. Hence, for all k = 1, . . . n and all 0 â‰¤a <
b â‰¤1, it follows that
P{a â‰¤xâˆ—
k â‰¤b} = Bk,nâ€“k+1([a, b]) =
n!
(k â€“ 1)! (n â€“ k)!
b

a
xkâ€“1(1 â€“ x)nâ€“k dx .
Example 3.7.9. Let us investigate here the example that was already mentioned in
Remark 3.7.4. At time t = 0 we switch on n electric bulbs of the same type. The times
0 < tâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤tâˆ—
n are those where we observe that some of the bulbs burns out. If
we assume that the lifetime of each bulb is exponentially distributed, what can we say
about the distribution of the tâˆ—
ks?
Answer: Let X1, . . . , Xn be the lifetimes of the n light bulbs. By assumption, they
are independent and all exponentially distributed with some parameter + > 0. Then
the distribution of tâˆ—
k is that of Xâˆ—
k. Furthermore, we have p(t) = + eâ€“+t and F(t) = 1 â€“ eâ€“+t
for t â‰¥0. By Proposition 3.7.7, the distribution density pk of Xâˆ—
k equals
pk(t) = +
n!
(k â€“ 1)!(n â€“ k)! (1 â€“ eâ€“+t)kâ€“1 eâ€“+t(nâ€“k+1) ,
t â‰¥0 .
For example, for tâˆ—
1 , the time when we observe the ï¬rst burnout of any of the bulbs,
this implies
p1(t) = + n eâ€“+tn ,
t â‰¥0 ,
that is, tâˆ—
1 is E+n-distributed.
3.8 Problems
Problem 3.1. The joint distribution of a random vector âƒ—X = (X1, X2) is described by
X2\X1
0
1
0
1
10
2
5
1
2
5
1
10

3.8 Problems
147
Deï¬ne another vector âƒ—Y = (Y1, Y2) by Y1 := min{X1, X2} and Y2 := max{X1, X2}. Find the
probability distribution of âƒ—Y = (Y1, Y2). Are Y1 and Y2 independent?
Problem 3.2. Let âƒ—X = (X1, X2) be uniformly distributed on the square in R2 with corner
points (0, 1), (1, 0), (0, â€“1), and (â€“1, 0). Find the marginal distributions of âƒ—X.
Problem 3.3. In a lottery, six numbers are chosen out of {1, . . . , 49}. As usual in lot-
teries, chosen numbers are not replaced. Let X1, . . . , X6 be the chosen numbers as
they appeared. That is, X1 is the number chosen ï¬rst while X6 is the number, which
appeared last.
1.
Determine the joint distribution of the vector âƒ—X = (X1, . . . , X6), as well its marginal
distributions.
2.
Argue why X1, . . . , X6 are not independent.
3.
Reordering the six chosen numbers leads to the order statistics Xâˆ—
1 < â‹…â‹…â‹…< Xâˆ—
6.
Find the joint distribution of the vector (Xâˆ—
1 , . . . , Xâˆ—
6), as well as its marginal
distributions.
Problem 3.4. A random variable X is geometric distributed. Given natural numbers k
and n, show that
P{X = k + n|X > n} = P{X = k} .
Why is this property called â€œlack of memory propertyâ€?
Problem 3.5. A random variable is exponentially distributed. Prove
P(X > s + t|X > s) = P(X > t)
for all t, s â‰¥0.
Problem 3.6. Two random variables X and Y are independent and geometrically
distributed with parameters p and q for some 0 < p, q < 1. Evaluate P{X â‰¤Y â‰¤2X}.
Problem 3.7. Suppose two independent random variables X and Y satisfy
P{X = k} = P{Y = k} = 1
2k ,
k = 1, 2, . . . .
Find the probabilities P{X â‰¤Y} and P{X = Y}.

148
3 Random Variables and Their Distribution
Problem 3.8. Choose two numbers b and c independently, b according to the uniform
distribution on [â€“1, 1] and c according to the uniform distribution on [0, 1]. Find the
probability that the equation
x2 + bx + c = 0
does not possess a real solution.
Problem 3.9. Use Problem 1.31 to prove the following: If X is a random variable, then
the number of points t âˆˆR with P{X = t} > 0 is at most countably inï¬nite.
Problem 3.10. Suppose a fair coin is labeled with â€œ0â€ and â€œ1.â€ Toss the coin n times.
Let X be the maximum observed value and Y the sum of the n values. Determine the
joint distribution of (X, Y). Argue that X and Y are not independent.
Problem 3.11. Suppose a random vector (X, Y) has the joint density function p
deï¬ned by
p(u, v) :=

c â‹…u v : u, v â‰¥0, u + v â‰¤1
0
:
otherwise
1.
Find the value of the constant c so that p becomes a density function.
2.
Determine the density functions of X and Y .
3.
Evaluate P{X + Y â‰¤1/2}.
4.
Are X and Y independent?
Problem 3.12. Gambler A has a biased coin with â€œheadâ€ having probability p for some
0 < p < 1, and gambler Bâ€™s coin is biased with â€œheadâ€ having probability q for some
0 < q < 1. A and B toss their coins simultaneously. Whoever lands on â€œheadâ€ ï¬rst
wins. If both gamblers observe â€œheadâ€ at the same time, then the game ends in a draw.
Evaluate the probability that A wins and the probability that the game ends in a draw.
Problem 3.13. Randomly choose two integers x1 and x2 from 1 to 10. Let X be the min-
imum of x1 and x2. Determine the distribution and the probability mass functions of
X in the two following cases:
â€“
The number chosen ï¬rst is replaced.
â€“
The ï¬rst number is not replaced.
Evaluate in both cases P{2 â‰¤X â‰¤3} and P{X â‰¥8}.
Problem 3.14. There are four balls labeled with â€œ0â€ and three balls are labeled with
â€œ2â€ in an urn. Choose three balls without replacement. Let X be the sum of the values
on the three chosen balls. Find the distribution of X.

4 Operations on Random Variables
4.1 Mappings of Random Variables
This section is devoted to the following problem: let X : K â†’R be a random variable
and let f : R â†’R be some function. Set Y := f(X), that is, for all 9 âˆˆK we have Y(9) =
f(X(9)). Suppose the distribution of X is known. Then the following question arises:
Which distribution does Y = f(X) possess?
For example, if f(t) = t2, and we know the distribution of X, then we ask for the
probability distribution of X2. Is it possible to compute this by easy methods?
At the moment it is not clear at all whether Y = f(X) is a random variable. Only if
this is valid, the probability distribution PY is well-deï¬ned. For arbitrary functions f
this need not to be true, they have to satisfy the following additional property.
Deï¬nition 4.1.1. A function f : R â†’R is called measurable if for B âˆˆB(R) the
preimage f â€“1(B) is a Borel set as well.
Remark 4.1.2. This is a purely technical condition for f, which will not play an im-
portant role later on. All functions of interest, for example, piecewise continuous,
monotone, pointwise limits of continuous functions, and so on, are measurable.
The measurability of f is needed to prove the following result.
Proposition 4.1.3. Let X : K â†’R be a random variable. If f : R â†’R is measurable,
then Y = f(X) is a random variable as well.
Proof: Take a Borel set B âˆˆB(R). Then
Yâ€“1(B) = Xâ€“1
f â€“1(B)

= Xâ€“1(Bâ€²)
with Bâ€² := f â€“1(B). We assumed f to be measurable, which implies Bâ€² âˆˆB(R), and hence,
since X is a random variable, we conclude Yâ€“1(B) = Xâ€“1(Bâ€²) âˆˆA. The Borel set B was
arbitrary, thus, as asserted, Y is a random variable.
âˆ
There does not exist a general method for the description of PY in terms of PX. Only
for some special functions, for example, for linear functions or for strictly monotone
and differentiable, there exist general rules for the computation of PY. Nevertheless,
quite often we are able to determine PY directly. Mostly the following two approaches
turn out to be helpful.

150
4 Operations on Random Variables
If X is discrete with values in D := {x1, x2, . . .}, then Y = f(X) maps the sample
space K into f(D) = {f(x1), f(x2), . . .}. Problems arise if f is not one-to-one. In this case
one has to combine those xjs that are mapped onto the same element in f(D). For ex-
ample, if X is uniformly distributed on D = {â€“2, â€“1, 0, 1, 2} and f(x) = x2, then Y = X2
has values in f(D) = {0, 1, 4}. Combining â€“1 and 1 and â€“2 and 2 leads to
P{Y = 0} = P{X = 0} = 1
5 , P{Y = 1} = P{X = â€“1} + P{X = 1} = 2
5 ,
P{Y = 4} = P{X = â€“2} + P{X = 2} = 2
5 .
The case of one-to-one functions f is easier to handle because then
P{Y = f(xj)} = P{X = xj} ,
j = 1, 2, . . . , ,
and the distribution of Y can be directly computed from that of X.
For continuous X one tries to determine the distribution function FY of Y. Recall
that this was deï¬ned as
FY(t) = P{Y â‰¤t} = P{f(X) â‰¤t} .
If we are able to compute FY, then we are almost done because then we get the
distribution density q of Y as derivative of FY.
For instance, if f is increasing, we get FY easily by
FY(t) = P{X â‰¤f â€“1(t)} = FX(f â€“1(t))
with inverse function f â€“1 (cf. Problem 4.15).
The following examples demonstrate how we compute the distribution of f(X) in
some special cases.
Example 4.1.4. Assume the random variable X is N(0, 1)-distributed. Which distribu-
tion does Y := X2 possess?
Answer: Of course, FY(t) = P{Y â‰¤t} = 0 when t â‰¤0. Consequently, it sufï¬ces to
determine FY(t) for t > 0. Then
FY(t) = P{X2 â‰¤t} = P{â€“
âˆš
t â‰¤X â‰¤
âˆš
t} =
1
âˆš
20
âˆš
t

â€“
âˆš
t
eâ€“s2/2 ds
=
2
âˆš
20
âˆš
t

0
eâ€“s2/2 ds = h(
âˆš
t) ,
where
h(u) :=
âˆš
2
âˆš0
u

0
eâ€“s2/2 ds ,
u â‰¥0 .

4.1 Mappings of Random Variables
151
Differentiating FY with respect to t, the chain rule and the fundamental theorem of
Calculus lead to
q(t) = Fâ€²
Y(t) = d
dt
âˆš
t

hâ€²âˆš
t

= tâ€“1/2
2
â‹…
âˆš
2
âˆš0 eâ€“t/2
=
1
21/2A(1/2) t
1
2 â€“1 eâ€“t/2 ,
t > 0 .
Hereby, in the last step, we used A(1/2) = âˆš0. Consequently, Y possesses the density
function
q(t) =

0
: t â‰¤0
1
21/2A(1/2) tâ€“1/2eâ€“t/2 : t > 0 .
But this is the density of a A2, 1
2 -distribution. Therefore, we obtained the following
result, which we, because of its importance, state as a separate proposition.
Proposition 4.1.5. If X is N(0, 1)-distributed, then X2 is A2, 1
2 -distributed or, equivalently,
distributed according to 72
1.
Example 4.1.6. Let U be uniformly distributed on [0, 1]. Which distribution does Y :=
1/U possess?
Answer: Again we determine FY. From P{X âˆˆ(0, 1]} = 1 we derive P(Y â‰¥1) = 1,
thus, FY(t) = 0 if t < 1. Therefore, we only have to regard numbers t â‰¥1. Here we have
FY(t) = P
5 1
U â‰¤t
6
= P
5
U â‰¥1
t
6
= 1 â€“ 1
t .
Hence, the density function q of Y is given by
q(t) = Fâ€²
Y(t) =

0 : t < 1
1
t2 : t â‰¥1
Example 4.1.7 (Random walk on Z). A particle is located at the point 0 of Z. In a ï¬rst
step it moves either to â€“1 or to +1. In the second step it jumps, independently of the
ï¬rst move, again to the left or to the right. Thus, after two steps it is located either at
â€“2, 0, or 2. Hereby we assume that p is the probability for jumps to the right, hence 1â€“p
for jumps to the left. This procedure is repeated arbitrarily often. Let Sn be the position
of the particle after n jumps or, equivalently, after n steps.1 The (random) sequence
(Sn)nâ‰¥0 is called a (next-neighbor) random walk on Z, where by the construction
P{S0 = 0} = 1.
1 Sn can also be viewed as the loss or win after n games, where p is the probability to win one dollar in
a single game, while 1 â€“ p is the probability to lose one dollar.

152
4 Operations on Random Variables
After n steps the possible positions of the particle are in
Dn = {â€“n, â€“n + 2, . . . , n â€“ 2, n} .
In other words, Sn is a random variable with values in Dn. Which distribution does Sn
possess? To answer this question deï¬ne
Yn := 1
2 (Sn + n) .
The random variable Yn attains values in {0, 1, . . . , n} and, moreover, Yn = m if the
position of the particle after n steps is 2m â€“ n, that is, if it jumped m times to the
right and n â€“ m times to the left. To see this, take m = 0, hence Sn = â€“n, which
can only be achieved if all jumps were to the left. If m = 1, then Sn = â€“n + 2, that
is, there were n â€“ 1 jumps to the left and 1 to the right. The same argument applies for
all m â‰¤n.
This observation tells us that Yn is Bn,p-distributed, that is,
P{Yn = m} =
n
m

pm(1 â€“ p)nâ€“m ,
m = 0, . . . , n .
Since Yn = 1
2 (Sn + n), if k âˆˆDn, then it follows that
P{Sn = k} = P
5
Yn = 1
2 (k + n)
6
=
 n
n+k
2

p(n+k)/2 (1 â€“ p)(nâ€“k)/2 .
(4.1)
For even n we have 0 âˆˆDn, thus one may ask for the probability of Sn = 0, that is, for
the probability that the particle returns to its starting point after n steps. Applying (4.1)
with k = 0 gives
P{Sn = 0} =
n
n
2

pn/2 (1 â€“ p)n/2 ,
hence, if p = 1/2, then
P{Sn = 0} =
n
n
2

2â€“n =
n!
((n/2)!)2 2â€“n .
An application of Stirlingâ€™s formula (1.51) implies
lim
nâ†’âˆn1/2 P{Sn = 0} = lim
nâ†’âˆn1/2
âˆš
20n (n/e)n
âˆš0n (n/2e)n/22 2â€“n =
"
2
0 ,
that is, if n â†’âˆ, then P{Sn = 0} âˆ¼
+
2
0 nâ€“1/2.

4.1 Mappings of Random Variables
153
Example 4.1.8. Suppose X is Bâ€“
n,p-distributed, that is,
P{X = k} =
k â€“ 1
k â€“ n

pn(1 â€“ p)kâ€“n ,
k = n, n + 1, . . . .
Let Y = X â€“ n. Which probability distribution does Y possess?
Answer: An easy transformation (cf. formula (1.34)) leads to
P{Y = k} = P{X = k + n} =
n + k â€“ 1
k

pn (1 â€“ p)k =
â€“n
k

pn (p â€“ 1)k
(4.2)
for all k = 0, 1, . . .
Additional question: Which random experiment does Y describe?
Answer: We perform a series of random trials where each time we may obtain
either failure or success. Hereby, the success probability is p âˆˆ(0, 1). Then the event
{Y = k} occurs if and only if we observe the nth success in trial k + n.
We conclude this section with the investigation of the following problem. Suppose
X1, . . . , Xn are independent random variables. Given n measurable functions f1, . . . , fn
from R to R, we deï¬ne â€œnewâ€ random variables Y1, . . . , Yn by
Yi := fi(Xi) ,
1 â‰¤i â‰¤n .
It is intuitively clear that then Y1, . . . , Yn are also independent; the values of Yi only
depend on those of Xi, thus the independence should be preserved. For example, if X1
and X2 are independent, then this should also be valid for X2
1 and 2X2.
The next result shows that this is indeed true.
Proposition 4.1.9. Let X1, . . . , Xn be independent random variables and let (fi)n
i=1 be
measurable functions from R to R. Then f1(X1), . . . , fn(Xn) are independent as well.
Proof: Choose arbitrary Borel sets B1, . . . , Bn in R and set Ai := f â€“1
i (Bi), 1 â‰¤i â‰¤n.
With this notation, an 9 âˆˆK satisï¬es fi(Xi(9)) âˆˆBi if and only if Xi(9) âˆˆAi. Hence, an
application of the independence of Xi (use 3.14 with the Xis and the Ais) leads to
P{f1(X1) âˆˆB1, . . . , fn(Xn) âˆˆBn} = P{X1 âˆˆA1, . . . , Xn âˆˆAn}
= P{X1 âˆˆA1} â‹…â‹…â‹…P{Xn âˆˆAn} = P{f1(X1) âˆˆB1} â‹…â‹…â‹…P{fn(Xn) âˆˆBn} .
The Bis were chosen arbitrarily, thus the random variables f1(X1), . . . , fn(Xn) are
independent as well.
âˆ
Remark 4.1.10. Without proof we still mention that the independence of random vari-
ables is preserved whenever they are put together into disjoint groups. For example,

154
4 Operations on Random Variables
if X1, . . . , Xn are independent, then so are f(X1, . . . , Xk) and g(Xk+1, . . . , Xn) for suitable
functions f and g. Assume we roll a die ï¬ve times and let X1, . . . , X5 be the results. Then
these random variables are independent, but so are also the two random variables
max{X1, X2} and X3 + X4 + X5 or the three X1, max{X2, X3} and min{X4, X5}.
4.2 Linear Transformations
Let a and b real numbers with a /= 0. Given a random variable X set Y := aX +b, that is,
Y arises from X by a linear transformation. We ask now for the probability distribution
of Y.
Proposition 4.2.1. Deï¬ne Y = aX + b with a, b âˆˆR and a /= 0.
(a)
In respective of a > 0 or a < 0,
FY(t) = FX
t â€“ b
a

or
FY(t) = 1 â€“ P
5
X < t â€“ b
a
6
.
If a < 0 and FX is continuous at tâ€“b
a , then FY(t) = 1 â€“ FX

tâ€“b
a

.
(b)
Let X be a continuous random variable with density p. Then Y is also continuous
with density q given by
q(t) = 1
|a| p
t â€“ b
a

,
t âˆˆR .
(4.3)
Proof: Let us ï¬rst treat the case a > 0. Then we get
FY(t) = P{aX + b â‰¤t} = P

X â‰¤t â€“ b
a

= FX
t â€“ b
a

as asserted.
In the case a < 0 we conclude as follows:
FY(t) = P{aX + b â‰¤t} = P

X â‰¥t â€“ b
a

= 1 â€“ P

X < t â€“ b
a

.
If FX is continuous at tâ€“b
a , then P

X = tâ€“b
a

= 0, hence
1 â€“ P

X < t â€“ b
a

= 1 â€“ P

X â‰¤t â€“ b
a

= 1 â€“ FX
t â€“ b
a

,
completing the proof of part (a).
Suppose now that p is a density function of X, that is,
FX(t) = P{X â‰¤t} =
t

â€“âˆ
p(x)dx ,
t âˆˆR .

4.2 Linear Transformations
155
If a > 0, by part (a) and the change of variables x = yâ€“b
a , we get
FY(t) = FX
t â€“ b
a

=
tâ€“b
a

â€“âˆ
p(x)dx =
t

â€“âˆ
1
a p
y â€“ b
a

dy =
t

â€“âˆ
q(y) dy .
Thus, q is a density of Y.
If a < 0, the same change of variables2 leads to
FY(t) = 1 â€“ FX
t â€“ b
a

=
âˆ

tâ€“b
a
p(x)dx = â€“
t

â€“âˆ
1
a p
y â€“ b
a

dy
=
t

â€“âˆ
1
â€“a p
y â€“ b
a

dy =
t

â€“âˆ
1
|a| p
y â€“ b
a

dy =
t

â€“âˆ
q(y) dy .
This being true for all t âˆˆR completes the proof.
âˆ
Example 4.2.2. Let X be N(0, 1)-distributed. Given a /= 0 and , âˆˆR, we ask for the
distribution of Y := a X + ,.
Answer: The random variable X is assumed to be continuous with density
p(t) =
1
âˆš
20
eâ€“t2/2 .
We apply eq. (4.3) with b = , to deduce that the density q of Y equals
q(t) = 1
|a| p
t â€“ ,
|a|

=
1
âˆš
20 |a|
eâ€“(tâ€“,)2/2a2 .
That is, the random variable Y is N(,, |a|2)-distributed. In particular, if 3 > 0 and
, âˆˆR, then 3 X + , is distributed according to N(,, 32).
Additional question: Suppose Y is N(,, 32)-distributed. Which probability distri-
bution does X := Yâ€“,
3
possess?
Answer: Formula (4.3) immediately implies that X is standard normally
distributed.
Because of the importance of the previous observation, we formulate it as proposition.
Proposition 4.2.3. Suppose , âˆˆR and 3 > 0. Then the following are equivalent:
X is N(0, 1)-distributed
â‡â‡’
3X + , is distributed according to N(,, 32).
2 Observe that now a < 0, hence the order of integration changes and a minus sign appears.

156
4 Operations on Random Variables
Corollary 4.2.4. Let I be the Gaussian I-function introduced in eq. (1.62). For each
interval [a, b],
N(,, 32)([a, b]) = I
b â€“ ,
3

â€“ I
a â€“ ,
3

.
Proof: This is a direct consequence of Proposition 4.2.3. Indeed, if X is standard
normally distributed, then
N(,, 32)([a, b]) = P{a â‰¤3X + , â‰¤b} = P
5a â€“ ,
3
â‰¤X â‰¤b â€“ ,
3
6
= I
b â€“ ,
3

â€“ I
a â€“ ,
3

as asserted.
âˆ
Let X be an N(,, 32)-distributed random variable. The next result shows that X with
high probability (more than 99.7%) attains values in [,â€“3 3, ,+3 3]. Therefore, in most
cases, one may assume that X maps into [, â€“ 3 3, , + 3 3]. This observation is usually
called 33-rule.
Corollary 4.2.5 (33-rule). If X is distributed according to N(,, 32), then
P{|X â€“ ,| â‰¤2 3} â‰¥0.954
and
P{|X â€“ ,| â‰¤3 3} â‰¥0.997 .
Proof: By virtue of Corollary 4.2.4, for each c > 0
P{|X â€“ ,| â‰¤c 3} = I(c) â€“ I(â€“c) ,
hence the desired estimates follow by
I(2) â€“ I(â€“2) = 0.9545
and
I(3) â€“ I(â€“3) = 0.9973 .
âˆ
Example 4.2.6. Let U be uniformly distributed on [0, 1]. What is the probability
distribution of aU + b if a /= 0 and b âˆˆR?
Answer: The distribution density p of U is given by p(t) = 1 if 0 â‰¤t â‰¤1 and p(t) = 0
otherwise. Therefore, the density q of aU + b equals
q(t) =

1
|a| : 0 â‰¤tâ€“b
a â‰¤1
0 : otherwise .
Assume ï¬rst a > 0. Then q(t) = 1/a if and only if b â‰¤t â‰¤a + b and q(t) = 0 otherwise.
Consequently, aU + b is uniformly distributed on [b, a + b].

4.3 Coin Tossing versus Uniform Distribution
157
If, in contrast, a < 0, then q(t) = 1/|a| if and only if a + b â‰¤t â‰¤b and q(t) = 0
otherwise. Hence, now aU + b is uniformly distributed on [a + b, b].
It is easy to see that the reversed implications are also true. That is, we have
U unif. distr. on [0, 1] â‡â‡’aU + b unif. distr. on

[b, a + b] : a > 0
[a + b, b] : a < 0
$
Corollary 4.2.7. A random variable X is uniformly distributed on [0, 1] if and only if 1â€“X
is so. In particular, if U is uniformly distributed on [0, 1], then U
d= 1 â€“ U.
Example 4.2.8. Suppose a random variable X is A!,"-distributed for some !, " > 0 and
let a > 0. Which distribution does aX possess?
Answer: The distribution density p of X satisï¬es p(t) = 0 if t â‰¤0 and, if t > 0, then
p(t) =
1
!" A(") t"â€“1 eâ€“t/! .
An application of eq. (4.3) implies that the density q of aX is given by q(t) = 0 if t â‰¤0
and, if t > 0, then
q(t) = 1
a p
 t
a

=
1
a !" A(")
 t
a
"â€“1
eâ€“t/a! =
1
(a!)" A(")t"â€“1 eâ€“t/a! .
Thus, aX is Aa!,"-distributed.
In the case of the exponential distribution E+ = A1/+,1 the previous result implies
the following: if a > 0, then a random variable X is E+-distributed if and only if aX
possesses an E+/a distribution.
4.3 Coin Tossing versus Uniform Distribution
4.3.1 Binary Fractions
We start this section with the following statement: each real number x âˆˆ[0, 1) may be
represented as binary fraction x = 0.x1x2 â‹…â‹…â‹…, where xk âˆˆ{0, 1}. This is a shortened way
to express that
x =
âˆ

k=1
xk
2k .
The representation of x as binary fraction is in general not unique. For example,
1
2 = 0.10000 â‹…â‹…â‹…,
but also
1
2 = 0.01111 â‹…â‹…â‹….

158
4 Operations on Random Variables
Check this by computing the inï¬nite sums in both cases.
It is not difï¬cult to prove that exactly those x âˆˆ[0, 1) admit two different rep-
resentations, which may be written as x = k/2n for some n âˆˆN and some k =
1, 3, 5, . . . , 2n â€“ 1.
To make the binary representation unique we declare the following:
Convention 4.1. If a number x âˆˆ[0, 1) admits the representations
x = 0.x1 â‹…â‹…â‹…xnâ€“11000 â‹…â‹…â‹…
and
x = 0.x1 â‹…â‹…â‹…xnâ€“10111 â‹…â‹…â‹…,
then we always choose the former one. In other words, there do not exist numbers x âˆˆ
[0, 1) whose binary representation consists from a certain point only of 1s.
How do we get the binary fraction for a given x âˆˆ[0, 1) ?
The procedure is not difï¬cult. First, one checks whether x <
1
2 or x â‰¥
1
2. In the
former case one takes x1 = 0 and in the latter x1 = 1.
By this choice it follows that 0 â‰¤x â€“ x1
2 < 1
2. In the next step one asks whether
x â€“ x1
2 < 1
4 or x â€“ x1
2 â‰¥1
4. Depending on this one chooses either x2 = 0 or x2 = 1. This
choice implies 0 â‰¤x â€“ x1
2 â€“ x2
22 < 1
4, and if this difference belongs either to [0, 1
8) or to
[ 1
8, 1
4), then x3 = 0 or x3 = 1, respectively. Proceeding further in that way leads to the
binary fraction representing x.
After that heuristic method we now present a mathematically more exact way. To
this end, for each n â‰¥1, we divide the interval [0, 1) into 2n intervals of length 2â€“n.
We start with n = 1 and divide [0, 1) into the two intervals
I0 :=

0 , 1
2

and
I1 :=
1
2 , 1

.
In the second step we divide each of the two intervals I0 and I1 further into two parts
of equal length. In this way we obtain the four intervals
I00 :=

0 , 1
4

,
I01 :=
 1
4, 1
2

,
I10 :=
1
2 , 3
4

and
I11 :=
 3
4, 1

.
Observe that the left corner point of Ia1a2 equals a1/2 + a2/4, that is,
Ia1a2 =
â¡
â£
2

j=1
aj
2j ,
2

j=1
aj
2j + 1
22
â
â ,
a1, a2 âˆˆ{0, 1} .
It is clear now how to proceed. Given n â‰¥1 and numbers a1, . . . , an âˆˆ{0, 1}, set
Ia1 â‹…â‹…â‹…an =
â¡
â£
n

j=1
aj
2j ,
n

j=1
aj
2j + 1
2n
â
â .
(4.4)

4.3 Coin Tossing versus Uniform Distribution
159
In this way, we obtain 2n disjoint intervals of length 2â€“n where the left corner points
are 0.a1a2 â‹…â‹…â‹…an.
The following lemma makes the above heuristic method more precise.
Lemma 4.3.1. For all a1, . . . , an âˆˆ{0, 1} the intervals in deï¬nition (4.4) are characterized
by
Ia1 â‹…â‹…â‹…an = {x âˆˆ[0, 1) : x = 0.a1a2 â‹…â‹…â‹…an â‹…â‹…â‹…} .
Verbally, a number in [0, 1) belongs to Ia1 â‹…â‹…â‹…an if and only if its ï¬rst n digits in the binary
fraction are a1, . . . , an.
Proof: Assume ï¬rst x âˆˆIa1 â‹…â‹…â‹…an. If a := 0.a1 â‹…â‹…â‹…an denotes the left corner point of
Ia1,...,an, by deï¬nition a â‰¤x < a + 1/2n or, equivalently, 0 â‰¤x â€“ a < 1/2n. Therefore,
the binary fraction of x â€“ a is of the form 0.00 â‹…â‹…â‹…0bn+1 â‹…â‹…â‹…with certain numbers
bn+1, bn+2, . . . âˆˆ{0, 1}. This yields
x = a + (x â€“ a) = 0.a1 â‹…â‹…â‹…anbn+1 â‹…â‹…â‹….
Thus, as asserted, the ï¬rst n digits in the representation of x are a1, . . . , an.
Conversely, if x can be written as x = 0.x1x2 â‹…â‹…â‹…with x1 = a1, . . . , xn = an, then a â‰¤x
where, as above, a denotes the left corner point of Ia1 â‹…â‹…â‹…an. Moreover, by Convention
4.3.1 at least one of the xks, k > n, has to be zero. Consequently,
x â€“ a =
âˆ

k=n+1
xk
2k <
âˆ

k=n+1
1
2k = 1
2n ,
that is, we have a â‰¤x < a + 1
2n or, equivalently, x âˆˆIa1 â‹…â‹…â‹…an as asserted.
âˆ
A direct consequence of Lemma 4.3.1 is as follows.
Corollary 4.3.2. For each n â‰¥1 the 2n sets Ia1 â‹…â‹…â‹…an form a disjoint partition of [0, 1),
that is,
	
a1,...,anâˆˆ{0,1}
Ia1 â‹…â‹…â‹…an = [0, 1)
and
Ia1 â‹…â‹…â‹…an âˆ©Iaâ€²
1 â‹…â‹…â‹…aâ€²n = âˆ…
provided that (a1, . . . , an) /= (aâ€²
1, . . . , aâ€²
n). Furthermore,
{x âˆˆ[0, 1) : xk = 0} =
	
a1,...,akâ€“1âˆˆ{0,1}
Ia1 â‹…â‹…â‹…akâ€“10 .

160
4 Operations on Random Variables
4.3.2 Binary Fractions of Random Numbers
We saw above each number x âˆˆ[0, 1) admits a representation x = 0.x1x2 â‹…â‹…â‹…with certain
xk âˆˆ{0, 1}. What does happen if we choose a number x randomly, say according to the
uniform distribution on [0, 1] ? Then the xks in the binary fraction are also random,
with values in {0, 1}. How are they distributed?
The mathematical formulation of this question is as follows: let U : K â†’R be a
random variable uniformly distributed on [0, 1]. If 9 âˆˆK, write3
U(9) = 0.X1(9)X2(9) â‹…â‹…â‹…=
âˆ

k=1
Xk(9)
2k
.
(4.5)
In this way we obtain inï¬nitely many random variables Xk : K â†’{0, 1}.
Which distribution do these random variables possess? Answer gives the next
proposition.
Proposition 4.3.3. If k âˆˆN, then
P{Xk = 0} = P{Xk = 1} = 1
2 .
(4.6)
Furthermore, given n â‰¥1, the random variables X1, . . . , Xn are independent.
Proof: By assumption PU is the uniform distribution on [0, 1]. Thus, the ï¬nite addit-
ivity of PU, Corollary 4.3.2 and eq. (1.45) imply
P{Xk = 0} = PU

	
a1,...,akâ€“1âˆˆ{0,1}
Ia1 â‹…â‹…â‹…akâ€“10

=

a1,...,akâ€“1âˆˆ{0,1}
PU

Ia1 â‹…â‹…â‹…akâ€“10

=

a1,...,akâ€“1âˆˆ{0,1}
1
2k = 2kâ€“1
2k
= 1
2 .
Since Xk attains only two different values, P{Xk = 1} = 1/2 as well, proving the ï¬rst
part.
We want to verify that for all n â‰¥1 the random variables X1, . . . , Xn are independ-
ent. Equivalently, according to Proposition 3.6.16, the following has to be proven: if
a1, . . . , an âˆˆ{0, 1}, then
P{X1 = a1, . . . , Xn = an} = P{X1 = a1} â‹…â‹…â‹…P{Xn = an} .
(4.7)
By eq. (4.6) the right-hand side of eq. (4.7) equals
P{X1 = a1} â‹…â‹…â‹…P{Xn = an} = 1
2 â‹…â‹…â‹…1
2



n
= 1
2n .
3 Note that P{U âˆˆ[0, 1)} = 1. Thus, without losing generality, we may assume U(9) âˆˆ[0, 1).

4.3 Coin Tossing versus Uniform Distribution
161
To compute the left-hand side of eq. (4.7), note that Lemma 4.3.1 implies that we have
X1 = a1 up to Xn = an if and only if U attains a value in Ia1 â‹…â‹…â‹…an. The intervals Ia1 â‹…â‹…â‹…an are
of length 2â€“n, hence by eq. (1.45) (recall that PU is the uniform distribution on [0, 1]),
P{X1 = a1, . . . , Xn = an} = P{U âˆˆIa1 â‹…â‹…â‹…an} = PU(Ia1 â‹…â‹…â‹…an) = 1
2n .
Thus, for all a1, . . . , an âˆˆ{0, 1} eq. (4.7) is valid, and, as asserted, the random variables
X1, . . . , Xn are independent.
âˆ
To formulate the previous result in a different way, let us introduce the following
notation.
Deï¬nition 4.3.4. An inï¬nite sequence X1, X2, . . . of random variables is said to be
independent provided that any ï¬nite collection of the Xks is independent.
Remark 4.3.5. Since any subcollection of independent random variables is independ-
ent as well, the independence of X1, X2, . . . is equivalent to the following. For all n â‰¥1
the random variables X1, . . . , Xn are independent, that is, for all n â‰¥1 and all Borel
sets B1, . . . , Bn it follows that
P{X1 âˆˆB1, . . . , Xn âˆˆBn} = P{X1 âˆˆB1} â‹…â‹…â‹…P{Xn âˆˆBn} .
Remark 4.3.6. In view of Deï¬nition 4.3.4 the basic observation in Example 3.6.17 may
now be formulated in the following way. If we toss a (maybe biased) coin, labeled
with â€œ0â€ and â€œ1,â€ inï¬nitely often and if we let X1, X2, . . . be the results of the single
tosses, then this inï¬nite sequence of random variables is independent with P{Xk =
0} = 1 â€“ p and P{Xk = 1} = p. In particular, for a fair coin the Xks possess the following
properties:
(a)
If k âˆˆN, then P{Xk = 0} = P{Xk = 1} = 1/2.
(b)
X1, X2, . . . is an inï¬nite sequence of independent random variables.
This observation leads us to the following deï¬nition.
Deï¬nition 4.3.7. An inï¬nite sequence X1, X2, . . . of independent random vari-
ables with values in {0, 1} satisfying
P{Xk = 0} = P{Xk = 1} = 1/2 ,
k = 1, 2, . . . ,
is said to be a model for tossing a fair coin inï¬nitely often.
Consequently, Proposition 4.3.3 asserts that the random variables X1, X2, . . . deï¬ned
by eq. (4.5) serve as model for tossing a fair coin inï¬nitely often.

162
4 Operations on Random Variables
4.3.3 Random Numbers Generated by Coin Tossing
We saw in Proposition 4.3.3 that choosing a random number in [0, 1] leads to a model
for tossing a fair coin inï¬nitely often. Our aim is now to investigate the converse ques-
tion. That is, we are given an inï¬nite random sequence of zeros and ones and we want
to construct a uniformly distributed number in [0, 1]. The precise mathematical ques-
tion is as follows: suppose we are given an inï¬nite sequence (Xk)kâ‰¥1 of independent
random variables with
P{Xk = 0} = P{Xk = 1} = 1/2 ,
k = 1, 2, . . . .
(4.8)
Is it possible to construct from these Xks a uniform distributed U ? The next proposi-
tion answers this question to the afï¬rmative.
Proposition 4.3.8. Let X1, X2, . . . be an arbitrary sequence of independent random
variables satisfying eq. (4.8). If U is deï¬ned by
U(9) :=
âˆ

k=1
Xk(9)
2k
,
9 âˆˆK ,
then this random variable is uniformly distributed on [0, 1].
Proof: In order to prove that U is uniformly distributed on [0, 1], we have to show
that, if t âˆˆ[0, 1), then
P{U â‰¤t} = t .
(4.9)
We start the proof of eq. (4.9) with the following observation: suppose the binary frac-
tion of some t âˆˆ[0, 1) is 0.t1t2 â‹…â‹…â‹…for certain ti âˆˆ{0, 1}. If s = 0.s1s2 â‹…â‹…â‹…, then s < t if and
only if there is an n âˆˆN so that the following is satisï¬ed4:
s1 = t1, . . . , snâ€“1 = tnâ€“1 ,
sn = 0 and tn = 1 .
Fix t âˆˆ[0, 1) for a moment and set
An(t) := {s âˆˆ[0, 1) : s1 = t1, . . . , snâ€“1 = tnâ€“1, sn < tn} .
4 In the case n = 1 this says s1 = 0 and t1 = 1.

4.3 Coin Tossing versus Uniform Distribution
163
Of course, An(t) âˆ©Am(t) = âˆ…whenever n /= m and, moreover, An(t) /= âˆ…if and only if
tn = 1. Furthermore, by the previous remark
[0, t) =
âˆ
	
n=1
An(t) =
	
{n:tn=1}
An(t) .
Finally, if An(t) /= âˆ…, that is, if tn = 1, then
P{U âˆˆAn(t)} = P{X1 = t1, . . . , Xnâ€“1 = tnâ€“1, Xn = 0}
= P{X1 = t1} â‹…â‹…â‹…P{Xnâ€“1 = tnâ€“1} â‹…P{Xn = 0} = 1
2n .
In the last step we used both properties of the Xks, that is, they are independent and
satisfy P{Xk = 0} = P{X = 1} = 1/2.
Summing up, we get
P{U < t} = P
5
U âˆˆ
	
{n:tn=1}
An(t)
6
=

{n:tn=1}
P{U âˆˆAn(t)}
=

{n:tn=1}
1
2n =
âˆ

n=1
tn
2n = t .
This â€œalmostâ€ proves eq. (4.9). It remains to show that P{U < t} = P{U â‰¤t} or,
equivalently, P{U = t} = 0. To verify this we use the continuity of P from above. Then
P{U = t} = P{X1 = t1, X2 = t2, . . .}
= lim
nâ†’âˆP{X1 = t1, . . . , Xn = tn} = lim
nâ†’âˆ
1
2n = 0 .
Consequently, eq. (4.9) holds for all t
âˆˆ[0, 1) and, as asserted, U is uniformly
distributed on [0, 1].
âˆ
Remark 4.3.9. Another possibility to write U is as binary fraction
U(9) = 0.X1(9)X2(9) â‹…â‹…â‹…,
9 âˆˆK .
Consequently, in order to construct a random number u in [0, 1] one may proceed as
follows: toss a fair coin with â€œ0â€ and â€œ1â€ inï¬nitely often and take the obtained se-
quence as binary fraction of u. The u obtained in this way is uniformly distributed
on [0, 1].
Of course, in practice one tosses a coin not inï¬nitely often. One stops the pro-
cedure after N trials for some â€œlargeâ€ N. In this way one gets a number u, which is
â€œalmostâ€ uniformly distributed on [0, 1].

164
4 Operations on Random Variables
Then how does one construct n independent numbers u1, . . . , un, all uniformly
distributed on [0, 1] ? The answer is quite obvious. Take n coins and toss them. As
functions of independent observations the generated u1, . . . , un are independent as
well and, by the construction, each of these numbers is uniformly distributed on [0, 1].
Another way is to toss the same coin n times â€œinï¬nitely often,â€ thus getting n inï¬nite
sequences of zeroes and ones.
4.4 Simulation of Random Variables
Proposition 4.3.8 provides us with a technique to simulate a uniformly distributed
random variable U by tossing a fair coin. The aim of this section is to ï¬nd a suitable
function f : [0, 1] â†’R, so that the transformed random variable X = f(U) possesses a
given probability distribution.
Example 4.4.1. Typical questions of this kind are as follows: ï¬nd a function f so
that X = f(U) is standard normally distributed. Does there exist another function
g : [0, 1] â†’R for which g(U) is Bn,p-distributed?
Suppose for a moment we already found such functions f and g. According to Re-
mark 4.3.9, we construct independent numbers u1, . . . , un, uniformly distributed on
[0, 1], and set xi = f(ui) and yi = g(ui). In this way we get either n standard normally
distributed numbers x1, . . . , xn or n binomial distributed numbers y1, . . . , yn. Moreover,
by Proposition 4.1.9 these numbers are independent. In this way we may simulate
independent random numbers possessing a given probability distribution.
We start with simulating discrete random variables. Thus suppose we are given
real numbers x1, x2, . . . and pk â‰¥0 with âˆ
k=1 pk = 1, and we look for a random variable
X = f(U) such that
P{X = xk} = pk ,
k = 1, 2, . . . .
One possible way to ï¬nd such a function f is as follows: divide [0, 1) into disjoint in-
tervals I1, I2, . . . of length |Ik| = pk, k = 1, 2, . . . . Since âˆ
k=1 pk = 1, such intervals exist.
For example, take I1 = [0, p1) and
Ik =
) kâ€“1

i=1
pi,
k

i=1
pi

,
k = 2, 3, . . . .
With these intervals Ik we deï¬ne f : [0, 1] â†’R by
f(x) := xk
if
x âˆˆIk ,
(4.10)

4.4 Simulation of Random Variables
165
or, equivalently,
f(x) =
âˆ

k=1
xk 1Ik(x) .
(4.11)
Then the following is true.
Proposition 4.4.2. Let U be uniformly distributed on [0, 1], and set X = f(U) with f
deï¬ned by eq. (4.10) or eq. (4.11). Then
P{X = xk} = pk ,
k = 1, 2, . . .
Proof: Using that U is uniformly distributed on [0, 1], this is an easy consequence of
eq. (1.45) in view of
P{X = xk} = P{f(U) = xk} = P{U âˆˆIk} = |Ik| = pk .
âˆ
Remark 4.4.3. Note that the concrete shape of the intervals5 Ik is not important at all.
They only have to satisfy |Ik| = pk, k = 1, 2, . . . . Moreover, these intervals need not
necessarily to be disjoint; a â€œsmallâ€ overlap does not inï¬‚uence the assertion. Indeed,
it sufï¬ces that P{U âˆˆIk âˆ©Il} = 0 whenever k /= l. For example, if always #(Ik âˆ©Il) < âˆ,
k /= l, then the construction works as well. In particular, we may choose also Ik =
kâ€“1
i=1 pi, k
i=1 pi

.
Example 4.4.4. We want to simulate a random variable X, which is uniformly distrib-
uted on {x1, . . . , xN}. How to proceed?
Answer: Divide the interval [0, 1) into N intervals I1, . . . , IN of length 1
N . For ex-
ample, choose Ik :=
 kâ€“1
N , k
N

, k = 1, . . . , N. If f = N
k=1 xk 1Ik, then X = f(U) is uniformly
distributed on {x1, . . . , xN}.
Example 4.4.5. Suppose we want to simulate a number k âˆˆN0, which is Pois+-
distributed. Set
Ik :=
 kâ€“1

j=0
+j
j! eâ€“+,
k

j=0
+j
j! eâ€“+

,
k = 0, 1, . . . ,
where the left-hand sum is supposed to be zero if k = 0. Choose randomly a number
u âˆˆ[0, 1] and take the k with u âˆˆIk. Then k is the number we are interested in.
5 They do not even need to be intervals.

166
4 Operations on Random Variables
Our next aim is to simulate continuous random variables. More precisely, suppose we
are given a probability density p. Then we look for a function f : [0, 1] â†’R such that p
is the density of X = f(U), that is, that
P{X â‰¤t} =
t

â€“âˆ
p(x) dx ,
t âˆˆR ,
(4.12)
To this end set
F(t) =
t

â€“âˆ
p(x) dx ,
t âˆˆR .
(4.13)
Thus, F is the distribution function of the random variable X, which we are going to
construct.
Suppose ï¬rst that F is one-to-one on a ï¬nite or inï¬nite interval (a, b), so that
F(x) = 0 if x < a, and F(x) = 1 if x > b. Since F is continuous, the inverse function
Fâ€“1 exists and maps (0, 1) to (a, b).
Proposition 4.4.6. Let p be a probability density and deï¬ne F by eq. (4.12). Suppose F
satisï¬es the above condition. If X = Fâ€“1(U), then
P{X â‰¤t} =
t

â€“âˆ
p(x) dx ,
t âˆˆR ,
that is, p is a density of X.
Proof: First note that the assumptions about F imply that F is increasing on (a, b).
Hence, if t âˆˆR, then
P{X â‰¤t} = P{Fâ€“1(U) â‰¤t} = P{U â‰¤F(t)} = F(t) =
 t
â€“âˆ
p(x) dx ,
t âˆˆR .
Here we used 0 â‰¤F(t) â‰¤1 and P{U â‰¤s} = s whenever 0 â‰¤s â‰¤1. This completes the
proof.
âˆ
But what do we do if F does not satisfy the above assumption? For example, this hap-
pens if p(x) = 0 on an interval I = (!, ") and p(x) > 0 on some left- and right-hand
intervals6 of I. In this case Fâ€“1 does not exist, and we have to modify the construction.7
6 Take, for instance, p with p(x) = 1
2 if x âˆˆ[0, 1] and if x âˆˆ[1, 2], and p(x) = 0 otherwise.
7 All subsequent distribution functions F possess an inverse function on a suitable interval (a, b).
Thus, Proposition 4.4.6 applies in almost all cases of interest. Therefore, to whom the statements about
pseudo-inverse functions look too complicated, you may skip them.

4.4 Simulation of Random Variables
167
Deï¬nition 4.4.7. Let F be deï¬ned by eq. (4.13). Then we set
Fâ€“(s) = inf{t âˆˆR : F(t) = s} ,
0 â‰¤s < 1 .
The function Fâ€“, mapping [0, 1) to [â€“âˆ, âˆ), is called the pseudo-inverse of F.
Remark 4.4.8. If 0 < s < 1, then Fâ€“(s) âˆˆR while Fâ€“(0) = â€“âˆ. Moreover, whenever F is
increasing on some interval I, then Fâ€“(s) = Fâ€“1(s) for s âˆˆI.
Lemma 4.4.9. The pseudo-inverse function Fâ€“ possesses the following properties.
1.
If s âˆˆ(0, 1) and t âˆˆR, then
F(Fâ€“(s)) = s
and
Fâ€“(F(t)) â‰¤t .
2.
Given t âˆˆ(0, 1) we have
Fâ€“(s) â‰¤t â‡â‡’s â‰¤F(t) .
(4.14)
Proof: The equality F(Fâ€“(s)) = s is a direct consequence of the continuity of F. Indeed,
if there are tn â†˜Fâ€“(s) with F(tn) = s, then
s = lim
nâ†’âˆF(tn) = F(Fâ€“(s)) .
The second part of the ï¬rst assertion follows by the deï¬nition of Fâ€“.
Now let us come to the proof of property (4.14). If Fâ€“(s) â‰¤t, then the monotonicity
of F as well as F(Fâ€“(s)) = s lead to s = F(Fâ€“(s)) â‰¤F(t).
Conversely, if s
â‰¤F(t), then Fâ€“(s)
â‰¤Fâ€“(F(t))
â‰¤t by the ï¬rst part, thus,
property (4.14) is proved.
âˆ
Now choose a uniform distributed U and set X = Fâ€“(U). Since P{U = 0} = 0, we may
assume that X attains values in R.
Proposition 4.4.10. Let p be a probability density, that is, we have p(x) â‰¥0 and
# âˆ
â€“âˆp(x)dx = 1. Deï¬ne F by eq. (4.13) and let Fâ€“ be its pseudo-inverse. Take U uniform
on [0, 1] and set X = Fâ€“(U). Then p is a distribution density of the random variable X.
Proof: Using property (4.14) it follows
FX(t) = P{X â‰¤t} = P{9 âˆˆK : Fâ€“(U(9)) â‰¤t} = P{9 âˆˆK : U(9) â‰¤F(t)} = F(t),
which completes the proof.
âˆ

168
4 Operations on Random Variables
Remark 4.4.11. Since Fâ€“ = Fâ€“1 whenever the inverse function exists, Proposition 4.4.6
is a special case of Proposition 4.4.10.
Example 4.4.12. Let us simulate an N(0, 1)-distributed random variable, that is, we
are looking for a function f : (0, 1) â†’R such that for uniformly distributed U
P{f(U) â‰¤t} =
1
âˆš
20
t

â€“âˆ
eâ€“x2/2 dx ,
t âˆˆR .
The distribution function
I(t) =
1
âˆš
20
t

â€“âˆ
eâ€“x2/2 dx
is one-to-one from R â†’(0, 1), hence Proposition 4.4.6 applies, and Iâ€“1(U) is a standard
normal random variable.
How does one get an N(,, 32)-distributed random variable? If X is standard nor-
mal, by Proposition 4.2.3 the transformed variable 3X + , is N(,, 32)-distributed.
Consequently, 3Iâ€“1(U) + , possesses the desired distribution.
How do we ï¬nd n independent N(,, 32)-distributed numbers x1, . . . , xn ? To
achieve this, choose u1, . . . , un in [0, 1] according to the construction presented in
Remark 4.3.9 and set xi = 3Iâ€“1(ui) + ,, 1 â‰¤i â‰¤n.
Example 4.4.13. Our next aim is to simulate an E+-distributed (exponentially distrib-
uted) random variable. Here
F(t) =

0
: t â‰¤0
1 â€“ eâ€“+t : t > 0,
which satisï¬es the assumptions of Proposition 4.4.6 on the interval (0, âˆ). Its inverse
Fâ€“1 maps (0, 1) to (0, âˆ) and equals
Fâ€“1(s) = â€“ln(1 â€“ s)
+
,
0 < s < 1 .
Therefore, if U is uniformly distributed on [0, 1], then X = â€“ ln(1â€“U)
+
is E+ distributed.
This is true for any uniformly distributed random variable U. By Corollary 4.2.7 the
random variable 1 â€“ U has the same distribution as U, hence, setting
Y = â€“ln(1 â€“ (1 â€“ U))
+
= â€“ln(U)
+
,
Y is E+ distributed as well.

4.5 Addition of Random Variables
169
Example 4.4.14. Let us simulate a random variable with Cauchy distribution
(cf. Deï¬nition 1.6.33). The distribution function F is given by
F(t) = 1
0
 t
â€“âˆ
1
1 + x2 dx = 1
0 arctan(t) + 1
2 ,
t âˆˆR ,
hence X := tan(0U â€“ 0
2 ) possesses a Cauchy distribution.
Example 4.4.15. Finally, let us give an example where Proposition 4.4.10 applies and
Proposition 4.4.6 does not. Suppose we want to simulate a random variable X with
distribution function F deï¬ned by
F(t) =
â§
âªâªâªâªâªâªâ¨
âªâªâªâªâªâªâ©
0
:
t < 0
t
2
: 0 â‰¤t < 1
1
2
: 1 â‰¤t < 2
1
2 + tâ€“2
2 : 2 â‰¤t < 3
1
:
t â‰¥3
(4.15)
Direct computations imply
Fâ€“(s) =
â§
âªâ¨
âªâ©
2s
: 0 < s < 1
2
1
:
s = 1
2
2s + 1 : 1
2 < s â‰¤1 ,
hence, if X is deï¬ned by
X = 2U 1{Uâ‰¤1
2 } + (2U + 1) 1{U> 1
2 } ,
then P{X â‰¤t} = F(t) with F deï¬ned by eq. (4.15). In other words, X is acting as follows.
Choose by random a number u âˆˆ[0, 1]. If u â‰¤1
2, then X(u) = 2u while for u > 1
2 we take
X(u) = 2u + 1.
4.5 Addition of Random Variables
Suppose we are given two random variables X and Y, both mapping from K into R. As
usual, their sum X + Y is deï¬ned by
(X + Y)(9) := X(9) + Y(9) ,
9 âˆˆK .
The main question we investigate in this section is as follows: suppose we know the
probability distributions of X and Y. Is there a way to compute the distribution of X+Y?
For example, if we roll a die twice, X is the result of the ï¬rst roll, Y that of the second,
then we know PX and PY. But how do we get PX+Y ?

170
4 Operations on Random Variables
Before we treat this question, we have to be sure that X + Y is also a random vari-
able. This is not obvious at all. Otherwise, the probability distribution of X + Y is not
deï¬ned and our question does not make sense.
Proposition 4.5.1. If X and Y are random variables, then so is X + Y.
Proof: We start the proof with the following observation. For two real numbers a and
b holds a < b if and only if there is a rational number q âˆˆQ such that a < q and b > q.
Therefore, given t âˆˆR, it follows that
{9 âˆˆK : X(9) + Y(9) < t} = {9 âˆˆK : X(9) < t â€“ Y(9)}
=
	
qâˆˆQ

{9 : X(9) < q} âˆ©{9 : q < t â€“ Y(9)}

.
(4.16)
By assumption, X and Y are random variables. Hence, for each q âˆˆQ,
Aq := {9 : X(9) < q} âˆˆA
and
Bq := {9 : Y(9) < t â€“ q} âˆˆA ,
which by the properties of 3-ï¬elds implies Cq := Aq âˆ©Bq âˆˆA. With this notation we
may write eq. (4.16) as
{9 âˆˆK : X(9) + Y(9) < t} =
	
qâˆˆQ
Cq .
The 3-ï¬eld A is closed under countable union, thus, since Q is countably inï¬nite and
Cq âˆˆA, it follows that 
qâˆˆQ Cq âˆˆA. Therefore, we have proven that, if t âˆˆR, then
{9 âˆˆK : X(9) + Y(9) < t} âˆˆA .
Proposition 3.1.6 lets us conclude that, as asserted, X + Y is a random variable .
âˆ
Remark 4.5.2. In view of Proposition 4.5.1 the following question makes sense: does
there exist a general approach to evaluate PX+Y by virtue of PX and of PY?
Answer: Such a general way does not exist. The deeper reason behind this is that,
in order to get PX+Y, one has to know the joint distribution of (X, Y). And as we saw in
Section 3.5, in general, the knowledge of PX and PY does not sufï¬ce to determine their
joint distribution, hence generally we also do not know PX+Y.

4.5 Addition of Random Variables
171
The next example emphasizes the previous remark.
Example 4.5.3. Let X, Y, Xâ€², and Yâ€² be as in Example 3.5.8, that is,
P{X = 0, Y = 0} = 1
6 ,
P{X = 0, Y = 1} = 1
3
P{X = 1, Y = 0} = 1
3 ,
P{X = 1, Y = 1} = 1
6
and
P{Xâ€² = 0, Yâ€² = 0} = P{Xâ€² = 0, Yâ€² = 1} = P{Xâ€² = 1, Yâ€² = 0}
= P{Xâ€² = 1, Yâ€² = 1} = 1
4 .
Then PX = PXâ€² and PY = PYâ€², but
P{X + Y = 0} = 1
6 , P{X + Y = 1} = 2
3
and
P{X + Y = 2} = 1
6 ,
P{Xâ€² + Yâ€² = 0} = 1
4 , P{Xâ€² + Yâ€² = 1} = 1
2
and
P{Xâ€² + Yâ€² = 2} = 1
4 .
Thus, X and Xâ€² as well as Y and Yâ€² are identically distributed, but the sums X + Y and
Xâ€² + Yâ€² are not.
On the other hand, as we saw in Proposition 3.6.5, the joint distribution is uniquely
determined by the marginal ones, provided the random variables are independent.
Therefore, for independent random variables X and Y, the distribution of X + Y is
determined by those of X and Y. The question remains, how PX+Y can be computed.
4.5.1 Sums of Discrete Random Variables
We ï¬rst consider an important special case, namely that X and Y attain values in Z.
Here we have
Proposition 4.5.4 (Convolution formula for Z-valued random variables). Let X and Y
be two independent random variables with values in Z. If k âˆˆZ, then
P{X + Y = k} =
âˆ

i=â€“âˆ
P{X = i} â‹…P{Y = k â€“ i} .
Proof: Fix k âˆˆZ and deï¬ne Bk âŠ†Z Ã— Z by
Bk := {(i, j) âˆˆZ Ã— Z : i + j = k} .

172
4 Operations on Random Variables
Then we get
P{X + Y = k} = P{(X, Y) âˆˆBk} = P(X,Y)(Bk)
(4.17)
with joint distribution P(X,Y). Proposition 3.6.9 asserts that for independent X and Y
and B âŠ†Z Ã— Z,
P(X,Y)(B) =

(i,j)âˆˆB
PX({i}) â‹…PY({j}) =

(i,j)âˆˆB
P{X = i} â‹…P{Y = j} .
We apply this formula with B = Bk, and by eq. (4.17) we obtain
P{X + Y = k} =

(i,j)âˆˆBk
P{X = i} â‹…P{Y = j}
=

{(i,j) : i+j=k}
P{X = i} â‹…P{Y = j} =
âˆ

i=â€“âˆ
P{X = i} â‹…P{Y = k â€“ i} ,
as asserted.
âˆ
Example 4.5.5. Two independent random variables X and Y are distributed according
to P{X = j} = P{Y = j} = 1/2j, j = 1, 2, . . . . Determine the probability distribution of
X â€“ Y.
Solution: First note that P{X = j} = P{Y = j} = 0 for j â‰¤0. Hence, given k âˆˆZ, an
application of Proposition 4.5.4 to X and â€“Y yields
P{X â€“ Y = k} =
âˆ

i=â€“âˆ
P{X = i} â‹…P{â€“Y = k â€“ i} =
âˆ

i=1
P{X = i} â‹…P{Y = i â€“ k} .
If k â‰¥0, then P{Y = i â€“ k} = 0 for i â‰¤k, thus
P{X â€“ Y = k} =
âˆ

i=k+1
P{X = i} â‹…P{Y = i â€“ k} =
âˆ

i=k+1
1
2i â‹…
1
2iâ€“k
= 2k
âˆ

i=k+1
1
22i = 2k â‹…2â€“2kâ€“2 â‹…
âˆ

i=0
1
22i = 2â€“kâ€“2 â‹…4
3 = 2â€“k
3 .
For k < 0 it follows that
P{X â€“ Y = k} =
âˆ

i=1
1
2i â‹…
1
2iâ€“k = 2k
âˆ

i=1
1
22i = 2k
âˆ

i=1
1
4i = 2k
3 .
We combine both cases and obtain
P{X â€“ Y = k} = 2â€“|k|
3
,
k âˆˆZ .

4.5 Addition of Random Variables
173
Which random experiment does X â€“ Y describe? Suppose player A and B both toss
a fair coin. Let X be the number of necessary trials for A to observe the ï¬rst â€œhead.â€
Similarly, Y describes how often B has to toss his coin to get the ï¬rst â€œhead.â€ Thus, the
value of X â€“ Y tells us how many trials later (or earlier) player A got his ï¬rst â€œheadâ€
than B got his one.
For example, if B got his ï¬rst â€œheadâ€ one trial earlier than A, then X â€“ Y = 1. The
probability that this occurs equals 1/6.
One special case of Proposition 4.5.4 is of particular interest.
Proposition 4.5.6 (Convolution formula for N0-valued random variables). Let X and Y
be two independent random variables with values in N0. If k âˆˆN0, then it follows that
P{X + Y = k} =
k

i=0
P{X = i} â‹…P{Y = k â€“ i} .
Proof: Regard X and Y as Z-valued random variables with P{X = i} = P{Y = i} = 0 for
all i = â€“1, â€“2 . . . . If k âˆˆN0, then Proposition 4.5.4 lets us conclude that
P{X + Y = k} =
âˆ

i=â€“âˆ
P{X = i} â‹…P{Y = k â€“ i} =
k

i=0
P{X = i} â‹…P{Y = k â€“ i} .
Here we used P{X = i} = 0 for i < 0 and P{Y = k â€“ i} = 0 if i > k. For k < 0 it follows that
P{X + Y = k} = 0 because in this case P{Y = k â€“ i} = 0 for all i â‰¥0. This completes the
proof.
âˆ
Example 4.5.7. Let X and Y be two independent random variables, both uniformly
distributed on {1, 2, . . . , N}. Which probability distribution does X + Y possess?
Answer: Of course, X + Y attains only values in {2, 3, . . . , 2N}. Hence, P{X + Y = k}
is only of interest for 2 â‰¤k â‰¤2N. Here we get
P{X + Y = k} = #(Ik)
N2 ,
(4.18)
where Ik is deï¬ned by
Ik := {i âˆˆ{1, . . . , N} : 1 â‰¤k â€“ i â‰¤N} = {i âˆˆ{1, . . . , N} : k â€“ N â‰¤i â‰¤k â€“ 1} .

174
4 Operations on Random Variables
To verify eq. (4.18) use that for i âˆ‰Ik either P{X = i} = 0 or P{Y = k â€“ i} = 0. It is not
difï¬cult to prove that
#(Ik) =

k â€“ 1
: 2 â‰¤k â‰¤N + 1
2N â€“ k + 1 : N + 1 < k â‰¤2N
which leads to
P{X + Y = k} =
â§
âªâ¨
âªâ©
kâ€“1
N2
: 2 â‰¤k â‰¤N + 1
2Nâ€“k+1
N2
: N + 1 < k â‰¤2N
0
:
otherwise
If N = 6, then X + Y may be viewed as the sum of two rolls of a die. Here the above for-
mula leads to the values of P{X + Y = k}, k = 2, . . . , 12, which we, by a direct approach,
already computed in Example 3.2.15.
Finally, let us shortly discuss the case of two arbitrary independent discrete random
variables. Assume that X and Y have values in at most countable inï¬nite sets D and E,
respectively. Then X + Y maps into
D + E := {x + y : x âˆˆD , y âˆˆE} .
Note that D + E is also at most countably inï¬nite.
Under these assumptions the following is valid.
Proposition 4.5.8. Suppose X and Y are two independent discrete random variables
with values in the (at most) countably inï¬nite sets D and E, respectively. For z âˆˆD + E it
follows that
P{X + Y = z} =

{(x,y)âˆˆDÃ—E : x+y=z}
P{X = x} â‹…P{Y = y} .
Proof: For ï¬xed z âˆˆD + E deï¬ne Bz âŠ†D Ã— E by Bz := {(x, y) : x + y = z}. Using this
notation we get
P{X + Y = z} = P{(X, Y) âˆˆBz} = P(X,Y)(Bz) ,
where again P(X,Y) denotes the joint distribution of X and Y. Now we may proceed as
in the proof of Proposition 4.5.4. The independence of X and Y implies
P(X,Y)(Bz) =

{(x,y)âˆˆDÃ—E:x+y=z}
P{X = x} â‹…P{Y = y} ,
proving the proposition.
âˆ

4.5 Addition of Random Variables
175
Remark 4.5.9. If D = E = Z, then Proposition 4.5.8 implies Proposition 4.5.4, while for
D = E = N0 we rediscover Proposition 4.5.6.
4.5.2 Sums of Continuous Random Variables
In this section we investigate the following question: let X and Y be two continuous
random variables with density functions p and q. Is X + Y continuous as well, and if
this is so, how do we compute its density?
To answer this question we need a special type of composing two functions.
Deï¬nition 4.5.10. Let f and g be two Riemann integrable functions from R to R.
Their convolution f â‹†g is deï¬ned by
(f â‹†g)(x) :=
âˆ

â€“âˆ
f(x â€“ y) g(y) dy ,
x âˆˆR .
(4.19)
Remark 4.5.11. The convolution is a commutative operation, that is,
f â‹†g = g â‹†f .
This follows by the change of variables u = x â€“ y in eq. (4.19), thus
(f â‹†g)(x) =
âˆ

â€“âˆ
f(x â€“ y) g(y) dy =
âˆ

â€“âˆ
f(u) g(x â€“ u) du = (g â‹†f)(x) ,
x âˆˆR .
Remark 4.5.12. For general functions f and g the integral in eq. (4.19) does not always
exist for all x âˆˆR. The investigation of this question requires facts and notations8
from Measure Theory; therefore, we will not treat it here. We only state a special case,
which sufï¬ces for our later purposes. Moreover, for concrete functions f and g it is
mostly easy to check for which x âˆˆR the value (f â‹†g)(x) exists.
Proposition 4.5.13. Let p and q be two probability densities and suppose that at least
one of them is bounded. Then (p â‹†q)(x) exists for all x âˆˆR.
Proof: Say p is bounded, that is, there is a constant c â‰¥0 such that 0 â‰¤p(z) â‰¤c for all
z âˆˆR. Since q(y) â‰¥0, if x âˆˆR, then
0 â‰¤
âˆ

â€“âˆ
p(x â€“ y)q(y) dy â‰¤c
âˆ

â€“âˆ
q(y) dy = c < âˆ.
8 For example, exists â€œalmost everywhere.â€

176
4 Operations on Random Variables
This proves that (p â‹†g)(x) exists for all x âˆˆR.
Since p â‹†q = q â‹†p, the same argument applies if q is bounded.
âˆ
The next result provides us with a formula for the evaluation of the density function
of X + Y for independent continuous X and Y.
Proposition 4.5.14 (Convolution formula for continuous random variables). Let X and
Y be two independent random variables with distribution densities p and q. Then X + Y
is continuous as well, and its density r may be computed by
r(x) = (p â‹†q)(x) =
âˆ

â€“âˆ
p(y) q(x â€“ y) dy
Proof: We have to show that r = p â‹†q satisï¬es
P{X + Y â‰¤t} =
 t
â€“âˆ
r(x) dx ,
t âˆˆR .
(4.20)
Fix t âˆˆR for a moment and deï¬ne Bt âŠ†R2 by
Bt := {(u, y) âˆˆR2 : u + y â‰¤t} .
Then we get
P{X + Y â‰¤t} = P{(X, Y) âˆˆBt} = P(X,Y)(Bt) .
(4.21)
To compute the right-hand side of eq. (4.21) we use Proposition 3.6.18. It asserts that
the joint distribution P(X,Y) of independent X and Y is given by (u, y) â†¦p(u)q(y), that
is, if B âŠ†R2, then
P(X,Y)(B) =

B
p(u)q(y) dy du .
Choosing B = Bt in the last formula, eq. (4.21) may now be written as
P{X + Y â‰¤t} =

Bt
p(u) q(y) dy du =
âˆ

â€“âˆ
â¡
â£
tâ€“y

â€“âˆ
p(u) du
â¤
â¦q(y) dy .
(4.22)

4.6 Sums of Certain Random Variables
177
Next we change the variables in the inner integral as follows9: u = xâ€“y, hence du = dx.
Then the right-hand integrals in eq. (4.22) coincide with
âˆ

â€“âˆ
â¡
â£
t

â€“âˆ
p(x â€“ y) dx
â¤
â¦q(y) dy =
t

â€“âˆ
â¡
â£
âˆ

â€“âˆ
p(x â€“ y) q(y) dy
â¤
â¦dx
=
t

â€“âˆ
(p â‹†q)(x) dx .
Hereby we used that p and q are non-negative, so that we may interchange the integ-
rals by virtue of Proposition A.5.5. Thus, eq. (4.20) is satisï¬ed, which completes the
proof.
âˆ
4.6 Sums of Certain Random Variables
Let us start with the investigation of the sum of independent binomial distributed
random variables. Here the following is valid.
Proposition 4.6.1. Let X and Y be two independent random variables, accordingly
Bn,p and Bm,p distributed for some n, m â‰¥1, and some p
âˆˆ
[0, 1]. Then X + Y is
Bn+m,p-distributed.
Proof: By Proposition 4.5.6 we get that for 0 â‰¤k â‰¤m + n
P{X + Y = k} =
k

j=0
n
j

pj (1 â€“ p)nâ€“j

â‹…
 m
k â€“ j

pkâ€“j (1 â€“ p)mâ€“(kâ€“j)

= pk (1 â€“ p)n+mâ€“k
k

j=0
n
j
 m
k â€“ j

.
To evaluate the sum we apply Vandermondeâ€™s identity (Proposition A.3.8), which
asserts
k

j=0
n
j
 m
k â€“ j

=
n + m
k

.
This leads to
P{X + Y = k} =
n + m
k

pk (1 â€“ p)m+nâ€“k ,
and X + Y is Bn+m,p-distributed.
âˆ
9 Note that in the inner integral y is a constant.

178
4 Operations on Random Variables
Interpretation: In a ï¬rst experiment we toss a biased coin n times and in a second one
m times. We combine these two experiments to one and toss the coin now n + m times.
Then we observe exactly k times â€œheadâ€ during the n + m trials if there is some j â‰¤k
so that we had j â€œheadsâ€ among the ï¬rst n trials and k â€“ j among the second m ones.
Finally, we have to sum the probabilities of all these events over j â‰¤k.
Corollary 4.6.2. Let X1, . . . , Xn be independent B1,p-distributed, that is,
P{Xj = 0} = 1 â€“ p
and
P{Xj = 1} = p ,
j = 1, . . . , n .
Then their sum X1 + â‹…â‹…â‹…+ Xn is Bn,p-distributed.
Proof: Apply Proposition 4.6.1 successively, ï¬rst to X1 and X2, then to X1 + X2 and X3,
and so on.
âˆ
Remark 4.6.3. Observe that
X1 + â‹…â‹…â‹…+ Xn = #{j â‰¤n : Xj = 1} .
Corollary 4.6.2 justiï¬es the interpretation of the binomial distribution given in Sec-
tion 1.4.3. Indeed, the event {Xj = 1} occurs if in trial j we observe success. Thus,
X1, . . . , Xn equals the number of successes in n independent trials. Hereby, the success
probability is P{Xj = 1} = p.
In the literature the following notation is common.
Deï¬nition 4.6.4. A sequence X1, . . . , Xn of independent B1,p-distributed random
variables is called a Bernoulli trial or Bernoulli process with success probability
p âˆˆ[0, 1].
With these notations, Corollary 4.6.2 may now be formulated as follows:
Let X1, X2, . . . be a Bernoulli trial with success probability p. Then for n â‰¥1,
P{X1 + â‹…â‹…â‹…+ Xn = k} =
n
k

pk (1 â€“ p)nâ€“k ,
k = 0, . . . , n .
Let X and Y be two independent Poisson distributed random variables. Which
distribution does X + Y possess? The next result answers this question.
Proposition 4.6.5. Let X and Y be independent Pois+- and Pois,-distributed for some
+ > 0 and , > 0, respectively. Then X + Y is Pois++,-distributed.
Proof: Proposition 4.5.6 and the binomial theorem (cf. Proposition A.3.7) imply

4.6 Sums of Certain Random Variables
179
P{X + Y = k} =
k

j=0
)
+j
j! eâ€“+
* )
,kâ€“j
(k â€“ j)! eâ€“,
*
= eâ€“(++,)
k!
k

j=0
k!
j! (k â€“ j)!+j ,kâ€“j
= eâ€“(++,)
k!
k

j=0
k
j

+j ,kâ€“j = (+ + ,)k
k!
eâ€“(++,) .
Consequently, as asserted, X + Y is Pois++,-distributed.
âˆ
Interpretation: The number of phone calls arriving per day at some call centers A and
B are Poisson distributed with parameters10 + and ,. Suppose that these two centers
have different customers, that is, we assume that the number of calls in A and B is
independent of each other. Proposition 4.6.5 asserts that the number of calls arriving
per day either in A or in B is again Poisson distributed, yet now with parameter + + ,.
Example 4.6.6.
This example deals with the distribution of raisins in a set of
dough. More precisely, suppose we have N pounds of dough and therein are n rais-
ins uniformly distributed. Choose by random a one-pound piece of dough. Find the
probability that there are k â‰¥0 raisins in the chosen piece.
Approach 1: Since the raisins are uniformly distributed in the dough, the probab-
ility that a single raisin is in the chosen piece equals 1/N. Hence, if X is the number
of raisins in that piece, it is Bn,p-distributed with p = 1/N. Assuming that N is big, the
random variable X is approximately Pois+-distributed with + = n/N, that is,
P{X = k} = +k
k! eâ€“+ ,
k = 0, 1, . . . .
Note that + = n/N coincides with the average number of raisins per pound dough.
Approach 2: Assume that we took in the previous model N â†’âˆ, that is, we have
an â€œinï¬niteâ€ amount of dough and â€œinï¬nitelyâ€ many raisins. Which distribution does
X, the number of raisins in a one-pound piece, now possess?
First we have to determine what it means that the amount of dough is â€œinï¬n-
iteâ€ and that the raisins are uniformly distributed11 therein. This is expressed by the
following conditions:
(a)
The mass of dough is unbelievably huge, hence, whenever we choose two dif-
ferent pieces, the numbers of raisins in each of these pieces are independent of
each other.
10 Later on, in Proposition 5.1.16, we will see that + and , are the mean values of arriving calls per day.
11 Note that the multivariate uniform distribution only makes sense (cf. Deï¬nition 1.8.10) if the
underlying set has a ï¬nite volume.

180
4 Operations on Random Variables
(b)
The fact that the raisins are uniformly distributed is expressed by the following
condition: suppose the number of raisins in a one-pound piece is n â‰¥0. If this
piece is split into two pieces, say K1 and K2 of weight ! and 1 â€“ ! pounds, then
the probability that a single raisin (of the n) is in K1 equals !, and that it is in K2
is 1 â€“ !.
Fix 0 < ! < 1 and choose in a ï¬rst step a piece K1 of ! pounds and in a second one
another piece K2 of weight 1 â€“ !. Let X1 and X2 be the number of raisins in each of
the two pieces. By condition (a), the random variables X1 and X2 are independent. If
X := X1 + X2, then X is the number of raisins in a randomly chosen one-pound piece.
Suppose now X = n, that is, there are n raisins in the one-pound piece. Then by con-
dition (b), the probability for k raisins in K1 is described by the binomial distribution
Bn,!. Recall that the success probability for a single raisin is !, thus, X1 = k means, we
have k times success. This may be formulated as follows: for 0 â‰¤k â‰¤n,
P{X1 = k|X = n} = Bn,!({k}) =
n
k

!k(1 â€“ !)nâ€“k .
(4.23)
Rewriting eq. (4.23) leads to
P{X1 = k, X2 = n â€“ k} = P{X1 = k, X = n}
= P{X1 = k|X = n} â‹…P{X = n} = P{X = n} â‹…
n
k

!k(1 â€“ !)nâ€“k .
(4.24)
Observe that in contrast to eq. (4.23), eq. (4.24) remains valid if P{X = n} = 0. Indeed,
if P{X = n} = 0, by Proposition 4.5.6, the event {X1 = k, X2 = n â€“ k} has probability zero
as well.
The independence of X1 and X2 and eq. (4.24) imply that, if n = 0, 1, . . . and k =
0, . . . , n, then
P{X1 = k} â‹…P{X2 = n â€“ k} = P{X = n} â‹…
n
k

!k(1 â€“ !)nâ€“k .
Seting k = n, we get
P{X1 = n} â‹…P{X2 = 0} = P{X = n} â‹…!n ,
(4.25)
while for n â‰¥1 and k = n â€“ 1 we obtain
P{X1 = n â€“ 1} â‹…P{X2 = 1} = P{X = n} â‹…n â‹…!nâ€“1 (1 â€“ !) .
(4.26)
In particular, from eq. (4.25) follows P{X2 = 0} > 0. If this probability would be zero,
then this would imply P{X = n} = 0 for all n âˆˆN0, which is impossible in view of
P{X âˆˆN0} = 1.

4.6 Sums of Certain Random Variables
181
In a next step we solve eqs. (4.25) and (4.26) with respect to P{X = n} and make
them equal. Doing so, for n â‰¥1 we get
P{X1 = n} = !
n (1 â€“ !)â€“1 â‹…P{X2 = 1}
P{X2 = 0} â‹…P{X1 = n â€“ 1}
= !+
n â‹…P{X1 = n â€“ 1} ,
(4.27)
where + â‰¥0 is deï¬ned by
+ := (1 â€“ !)â€“1 â‹…P{X2 = 1}
P{X2 = 0} .
(4.28)
Do we have + > 0 ? If + = 0, then P{X2 = 1} = 0 and by eq. (4.26) follows P{X = n} = 0 for
n â‰¥1. Consequently, P{X = 0} = 1, which says that there are no raisins in the dough.
We exclude this trivial case, thus it follows that + > 0.
Finally, a successive application of eq. (4.27) implies for n âˆˆN012
P{X1 = n} = (!+)n
n!
â‹…P{X1 = 0} ,
(4.29)
leading to
1 =
âˆ

n=0
P{X1 = n} = P{X1 = 0} â‹…
âˆ

n=0
(!+)n
n!
= P{X1 = 0} e!+ ,
that is, we have P{X1 = 0} = eâ€“!+. Plugging this into eq. (4.29) gives
P{X1 = n} = (!+)n
n!
eâ€“!+ ,
and X1 is Poisson distributed with parameter !+.
Let us interchange now the roles of X1 and X2, hence also of ! and 1â€“!. An applica-
tion of the ï¬rst step to X2 tells us that it is Poisson distributed, but now with parameter
(1 â€“ !)+â€², where in view of eq. (4.28) +â€² is given by13
+â€² = !â€“1 â‹…P{X1 = 1}
P{X1 = 0} = !â€“1 !+ eâ€“!+
eâ€“!+
= + .
Thus, X2 is Pois(1â€“!)+-distributed.
12 If n = 0, the equation holds by trivial reason.
13 Observe that we have to replace X2 by X1 and 1 â€“ ! by !.

182
4 Operations on Random Variables
Since X1 and X2 are independent, Proposition 4.6.5 applies, hence X = X1 + X2 is
Pois+-distributed or, equivalently,
P{There are k raisins in an one pound piece} = +k
k! eâ€“+ .
Remark 4.6.7. Which role does the parameter + > 0 play in this model? As already
mentioned, Proposition 5.1.16 will tell us that + is the average number of raisins per
pound dough. Thus, if 1 > 0 and we ask for the number of raisins in a piece of 1
pounds, then this number is Pois1+-distributed14, that is,
P{k raisins in 1 pounds dough} = (1+)k
k!
eâ€“1+ .
Assume a dough contains on the average 20 raisins per pound. Let X be number of
raisins in a bread baked of ï¬ve pounds dough. Then X is Pois100-distributed and
P({95 â‰¤X â‰¤105}) = 0.4176 ,
P({90 â‰¤X â‰¤110}) = 0.7065 ,
P({85 â‰¤X â‰¤115}) = 0.8793 ,
P({80 â‰¤X â‰¤120}) = 0.9599 ,
P({75 â‰¤X â‰¤125}) = 0.9892 ,
P({70 â‰¤X â‰¤130}) = 0.9976 .
Additional question: Suppose we buy two loaves of bread baked from 1 pounds dough
each. What is the probability that one of these two loaves contains at least twice as
many raisins than the other one?
Answer: Let X be the number of raisins in the ï¬rst loaf, and Y is the number of
raisins in the second one. By assumption, X and Y are independent, and both are
Pois1+-distributed, where as before + > 0 is the average number of raisins per pound
dough. The probability we are interested in is
P{X â‰¥2Y or Y â‰¥2X} = P{X â‰¥2Y} + P{Y â‰¥2X} = 2 P{X â‰¥2Y} .
It follows
2 P(X â‰¥2Y) = 2
âˆ

k=0
P(Y = k, X â‰¥2k) = 2
âˆ

k=0
P(Y = k) â‹…P(X â‰¥2k)
= 2
âˆ

k=0
P(Y = k) â‹…
âˆ

j=2k
P(X = j) = 2 eâ€“21+
âˆ

k=0
(1+)k
k!
âˆ

j=2k
(1+)j
j!
.
14 Because on average there are 1+ raisins in a piece of 1 pounds.

4.6 Sums of Certain Random Variables
183
If the average number of raisins per pound is + = 20, and if the loaves are baked from
1 = 5 pounds dough, then this probability is approximatively
P(X â‰¥2Y or Y â‰¥2X) = 3.17061 Ã— 10â€“6 .
If 1 = 1, that is, the loaves are made from one-pound dough each, then
P(X â‰¥2Y or Y â‰¥2X) = 0.0430079 .
Now we investigate the distribution of the sum of two independent negative binomial
distributed random variables. Recall that X is Bâ€“
n,p-distributed if
P{X = k} =
k â€“ 1
k â€“ n

pn (p â€“ 1)kâ€“n ,
k = n, n + 1, . . . .
Proposition 4.6.8. Let X and Y be independent accordingly Bâ€“
n,p and Bâ€“
m,p distributed
for some n, m â‰¥1. Then X + Y is Bâ€“
n+m,p-distributed.
Proof: We derive from Example 4.1.8 that, if k âˆˆN0, then
P{X â€“ n = k} =
â€“n
k

pn (p â€“ 1)k
and
P{Y â€“ m = k} =
â€“m
k

pm (p â€“ 1)k .
An application of Proposition 4.5.6 to X â€“ n and Y â€“ m implies
P{X + Y â€“ (n + m) = k} =
k

j=0
â€“n
j

pn(p â€“ 1)j
  â€“m
k â€“ j

pm(p â€“ 1)kâ€“j

= pn+m(p â€“ 1)k
k

j=0
â€“n
j
 â€“m
k â€“ j

.
To compute the last sum we use Proposition A.5.3, which asserts that
k

j=0
â€“n
j
 â€“m
k â€“ j

=
â€“n â€“ m
k

.
Consequently, for each k âˆˆN0,
P{X + Y â€“ (n + m) = k} =
â€“n â€“ m
k

pn+m(p â€“ 1)k .
Another application of eq. (4.2) (this time with n + m) leads to
P{X + Y = k} =

k â€“ 1
k â€“ (n + m)

pn+m (1 â€“ p)kâ€“(n+m) ,
k = n + m, n + m + 1, . . . .
This completes the proof.
âˆ

184
4 Operations on Random Variables
Corollary 4.6.9. Let X1, . . . , Xn be independent Gp-distributed (geometric distributed)
random variables. Then their sum X1 + â‹…â‹…â‹…+ Xn is Bâ€“
n,p-distributed.
Proof: Use Gp = Bâ€“
1,p and apply Proposition 4.6.8 n times.
âˆ
Interpretation: The following two experiments are completely equivalent: one is to
play the same game as long as one observes success for the nth time. The other ex-
periment is, after each success to start a new game, as long as one observes success in
the nth (and last) game. Here we assume that all n games are executed independently
and possess the same success probability.
Let U and V be two independent random variables, both uniformly distributed
on [0, 1]. Which distribution density does X + Y possess?
Proposition 4.6.10. The sum of two independent random variables U and V, uniformly
distributed on [0, 1], has the density r deï¬ned by
r(x) =
â§
âªâ¨
âªâ©
x
: 0 â‰¤x < 1
2 â€“ x : 1 â‰¤x â‰¤2
0
: otherwise .
(4.30)
Proof: The distribution densities p and q of U and V are given by p(x) = q(x) = 1 if
0 â‰¤x â‰¤1 and p(x) = q(x) = 0 otherwise. Proposition 4.5.14 asserts that U + V has
density r = p â‹†q computed by
r(x) =
âˆ

â€“âˆ
p(x â€“ y) q(y) dy =
 1
0
p(x â€“ y) dy .
But, p(x â€“ y) = 1 if and only if 0 â‰¤x â€“ y â‰¤1 or, equivalently, if and only if x â€“ 1 â‰¤y â‰¤x.
Taking into account the restriction 0 â‰¤y â‰¤1, it follows p(x â€“ y)q(y) = 1 if and only if
y âˆˆ

max{x â€“ 1, 0}, min{x, 1}

. In particular, r(x) = 0 for x âˆ‰[0, 2], and if 0 â‰¤x â‰¤2, then
r(x) = min{x, 1} â€“ max{x â€“ 1, 0} .
It is not difï¬cult to see that r may also be written as in eq. (4.30). This completes the
proof.
âˆ
Application: Suppose we choose independently and according to the uniform distri-
bution two numbers u1 and u2 in [0, 1]. Then the probability that a â‰¤u1 + u2 â‰¤b equals
# b
a r(x) dx with r given by eq. (4.30). For example,
P
1
2 â‰¤u1 + u2 â‰¤3
2

=
 1
1/2
x dx +
 3/2
1
(2 â€“ x) dx = 3
4 .

4.6 Sums of Certain Random Variables
185
We investigate now the sum of two gamma distributed random variables. Recall that
the density of a A!,"-distributed random variable is given by
p!,"(x) =
1
!" A(") x"â€“1 eâ€“x/!
if x > 0, while p!,"(x) = 0 otherwise.
Proposition 4.6.11. Let X1 and X2 be two independent random variables distributed
according to A!,"1 and A!,"2, respectively. Then X1 + X2 is A!,"1+"2-distributed.
Proof: If r denotes the density of X1 + X2, Proposition 4.5.14 implies
r(x) = (p!,"1 â‹†p!,"2)(x) =
âˆ

â€“âˆ
p!,"1(x â€“ y)p!,"2(y) dy ,
x âˆˆR ,
(4.31)
and we have to show that r = p!,"1+"2.
It is easy to see that r(x) = 0 if x â‰¤0, hence it sufï¬ces to evaluate eq. (4.31) for
x > 0. Since p!,"2(x â€“ y) = 0 if y > x,
r(x) =
1
!"1+"2A("1)A("2)
x

0
y"1â€“1(x â€“ y)"2â€“1 eâ€“y/! eâ€“(xâ€“y)/! dy
=
1
!"1+"2A("1)A("2) x"1+"2â€“2 eâ€“x/!
x

0
y
x

"1â€“1 
1 â€“ y
x

"2â€“1
dy .
Changing the variable as u := y/x, hence dy = x du, we obtain
r(x) =
1
!"1+"2A("1)A("2) x"1+"2â€“1 eâ€“x/!
 1
0
u"1â€“1(1 â€“ u)"2â€“1du
=
B("1, "2)
!"1+"2 A("1) A("2) â‹…x"1+"2â€“1 eâ€“x/! ,
(4.32)
where B denotes the beta function deï¬ned by eq. (1.58). Equation (1.59) yields
B("1, "2)
A("1) A("2) =
1
A("1 + "2) ,
(4.33)
hence, if x > 0, then by eqs. (4.32) and (4.33) it follows that r(x) = p!,"1+"2(x). This
completes the proof.
âˆ
Recall that the Erlang distribution is deï¬ned as E+,n = A+â€“1,n. Thus, Proposition 4.6.11
implies the following corollary.
Corollary 4.6.12. Let X and Y be independent and distributed according to E+,n and
E+,m, respectively. Then their sum X + Y is E+,n+m-distributed.

186
4 Operations on Random Variables
Another corollary of Proposition 4.5.14 (or of Corollary 4.6.12) describes the sum of
independent exponentially distributed random variables.
Corollary 4.6.13. Let X1, . . . , Xn be independent E+-distributed. Then their sum
X1 + â‹…â‹…â‹…+ Xn is Erlang distributed with parameters + and n.
Proof: Recall that E+ = E+,1. By Corollary 4.6.12 X1 + X2 is E+,2-distributed. Proceeding
in this way, every time applying Corollary 4.6.12 leads to the desired result.
âˆ
Example 4.6.14. The lifetime of light bulbs is assumed to be E+-distributed for a cer-
tain + > 0. At time zero we switch on a ï¬rst bulb. In the moment it burns out, we
replace it by a second one of the same type. If the second burns out, we replace it by a
third one, and so on. Let Sn be the moment when the nth light bulb burns out. Which
distribution does Sn possess?
Answer: Let X1, X2, . . . be the lifetimes of the ï¬rst, second, and so on light bulb.
Then Sn = X1 + â‹…â‹…â‹…+ Xn. Since the light bulbs are assumed to be of the same type,
the random variables Xj are all E+-distributed. Furthermore, the different lifetimes do
not inï¬‚uence each other, thus, we may assume that the Xjs are independent. Now
Corollary 4.6.13 lets us conclude that Sn is Erlang distributed with parameters + and n,
hence, if t > 0, by Proposition 1.6.25 we get
P{Sn â‰¤t} =
+n
(n â€“ 1)!
t

0
xnâ€“1 eâ€“+x dx = 1 â€“
nâ€“1

j=0
(+t)j
j!
eâ€“+t .
(4.34)
Example 4.6.15. We continue the preceding example, but ask now a different
question. How often do we have to change light bulbs before some given
time T > 0 ?
Answer: Let Y be the number of changes necessary until time T. Then for n â‰¥0 the
event {Y = n} occurs if and only if Sn â‰¤T, but Sn+1 > T. Hereby, we use the notation of
Example 4.6.14. In other words,
P{Y = n} = P{Sn â‰¤T, Sn+1 > T} = P

{Sn â‰¤T} âˆ–{Sn+1 â‰¤T}

,
n = 0, 1, . . . .
Since {Sn+1 â‰¤T} âŠ†{Sn â‰¤T}, by eq. (4.34) follows that
P{Y = n} = P{Sn â‰¤T} â€“ P{Sn+1 â‰¤T}
=
â¡
â£1 â€“
nâ€“1

j=0
(+T)j
j!
eâ€“+T
â¤
â¦â€“
â¡
â£1 â€“
n

j=0
(+T)j
j!
eâ€“+T
â¤
â¦
= (+T)n
n!
eâ€“+T = Pois+T({n}) .

4.6 Sums of Certain Random Variables
187
Let us still mention an important equivalent random â€œexperimentâ€: customers arrive
at the post ofï¬ce randomly. We assume that the times between their arrivals are inde-
pendent and E+-distributed. Then Sn is the time when the nth customer arrives. Hence,
under these assumptions, the number of arriving customers until a certain time T > 0
is Poisson distributed with parameter +T.
We investigate now the sum of two independent chi-squared distributed random
variables. Recall Deï¬nition 1.6.26: A random variable X is 72
n-distributed if it is A2, n
2 -
distributed. Hence, Proposition 4.6.11 implies the following result.
Proposition 4.6.16. Suppose that X is 72
n-distributed and that Y is 72
m-distributed for
some n, m â‰¥1. If X and Y are independent, then X + Y is 72
n+m-distributed.
Proof: Because of Proposition 4.6.11, the sum X + Y is A2, n
2 + m
2 = 72
n+m-distributed. This
proves the assertion.
âˆ
Proposition 4.6.16 has the following important consequence.
Proposition 4.6.17. Let X1, . . . , Xn be a sequence of independent N(0, 1)-distributed
random variables. Then X2
1 + â‹…â‹…â‹…+ X2
n is 72
n-distributed.
Proof: Proposition 4.1.5 asserts that the random variables X2
j are 72
1-distributed. Fur-
thermore, because of Proposition 4.1.9 they are also independent. Thus a successive
application of Proposition 4.6.16 proves the assertion.
âˆ
Our next and ï¬nal aim in this section is to investigate the distribution of the sum of two
independent normally distributed random variables. Here the following important
result is valid.
Proposition 4.6.18. Let X1 and X2 be two independent random variables distributed
according to N(,1, 32
1) and N(,2, 32
2). Then X1 + X2 is N(,1 + ,2, 32
1 + 32
2)-distributed.
Proof: In a ï¬rst step we treat a special case, namely ,1 = ,2 = 0 and 31 = 1. To simplify
the notation, set + = 32. Thus we have to prove the following: if X1 and X2 are N(0, 1)-
and N(0, +2)-distributed, then X1 + X2 is N(0, 1 + +2)-distributed.
Let p0,1 and p0,+2 be the corresponding densities introduced in eq. (1.47). Then we
have to prove that
p0,1 â‹†p0,+2 = p0,1++2 .
(4.35)

188
4 Operations on Random Variables
To verify this start with
(p0,1 â‹†p0,+2)(x) =
1
20 +
 âˆ
â€“âˆ
eâ€“(xâ€“y)2/2 eâ€“y2/2+2 dy
=
1
20 +
 âˆ
â€“âˆ
eâ€“ 1
2 (x2â€“2xy+(1++â€“2)y2) dy .
(4.36)
We use
x2 â€“ 2xy + (1 + +â€“2) y2
=

(1 + +â€“2)1/2y â€“ (1 + +â€“2)â€“1/2 x

2
â€“ x2

1
1 + +â€“2 â€“ 1

=

(1 + +â€“2)1/2y â€“ (1 + +â€“2)â€“1/2 x

2
+
x2
1 + +2
=

!y â€“ x
!

2
+
x2
1 + +2
with ! := (1 + +â€“2)1/2. Plugging this transformation into eq. (4.36) leads to
(p0,1 â‹†p0,+2)(x) = eâ€“x2/2(1++2)
20 +
âˆ

â€“âˆ
eâ€“(!yâ€“ x
! )2/2 dy .
(4.37)
Next change the variables by u := !y â€“ x/!, thus, dy = du/!, and observe that !+ =
(1 + +2)1/2. Then the right-hand side of eq. (4.37) transforms to
eâ€“x2/2(1++2)
20 (1 + +2)1/2
âˆ

â€“âˆ
eâ€“u2/2 du = p0,1++2(x) .
Hereby, we used Proposition 1.6.6 asserting
# âˆ
â€“âˆeâ€“u2/2 du =
âˆš
20. This proves the
validity of eq. (4.35).
In a second step we treat the general case, that is, X1 is N(,1, 32
1)- and X2 is
N(,2, 32
2)-distributed. Set
Y1 := X1 â€“ ,1
31
and
Y2 := X2 â€“ ,2
32
.
By Proposition 4.2.3, the random variables Y1 and Y2 are standard normal and,
moreover, because of Proposition 4.1.9, also independent. Thus, the sum X1 + X2 may
be represented as
X1 + X2 = ,1 + ,2 + 31Y1 + 32Y2 = ,1 + ,2 + 31 Z
where Z = Y1 + +Y2 with + = 32/31.

4.7 Products and Quotients of Random Variables
189
An application of the ï¬rst step shows that Z is N(0, 1 + +2)-distributed. Hence,
Proposition 4.2.3 implies the existence of a standard normally distributed Z0 such that
Z = (1 + +2)1/2 Z0. Summing up, X1 + X2 may now be written as
X1 + X2 = ,1 + ,2 + 31 (1 + +2)1/2 Z0 = ,1 + ,2 +

32
1 + 32
2
1/2 Z0 ,
and another application of Proposition 4.2.3 lets us conclude that, as asserted, the
sum X1 + X2 is N(,1 + ,2, 32
1 + 32
2)-distributed.
âˆ
4.7 Products and Quotients of Random Variables
Let X and Y be two random variables mapping a sample space K into R. Then their
product X â‹…Y and their quotient X/Y (assume Y(9) /= 0 for 9 âˆˆK) are deï¬ned by
(X â‹…Y)(9) := X(9) â‹…Y(9)
and
X
Y

(9) := X(9)
Y(9) ,
9 âˆˆK .
The aim of this section is to investigate the distribution of such products and quo-
tients. We restrict ourselves to continuous X and Y because, later on, we will only
deal with products and quotients of those random variables. Furthermore, we omit the
proof of the fact that products and fractions are random variables as well. The proofs
of these permanent properties are not complicated and follow the ideas used in the
proof of Proposition 4.5.1. Thus, our interest are products X â‹…Y and quotients X/Y for
independent X and Y, where, to simplify the computations, we suppose P{Y > 0} = 1.
We start with the investigation of products of continuous random variables. Thus,
let X and Y be two random variables with distribution densities p and q. Since we
assumed P{Y > 0} = 1, we may choose the density q such that q(x) = 0 if x â‰¤0.
Proposition 4.7.1. Let X and Y be two independent random variables possessing the
stated properties. Then Xâ‹…Y is continuous as well, and its density r may be calculated by
r(x) =
 âˆ
0
p
x
y
 q(y)
y
dy ,
x âˆˆR .
(4.38)
Proof: For t âˆˆR we evaluate P{X â‹…Y â‰¤t}. To this end ï¬x t âˆˆR and set
At := {(u, y) âˆˆR Ã— (0, âˆ) : u â‹…y â‰¤t} .
As in the proof of Proposition 4.5.14, it follows that
P{X â‹…Y â‰¤t} = P(X,Y)(At) =
âˆ

0
â¡
â¢â£
t/y

â€“âˆ
p(u) du
â¤
â¥â¦q(y) dy .
(4.39)

190
4 Operations on Random Variables
In the inner integral of eq. (4.39) we change the variables by x := u y, hence dx =
y du. Notice that in the inner integral y is a constant. After this change of variables the
right-hand integral in eq. (4.39) becomes15
âˆ

0
â¡
â£
t

â€“âˆ
p
x
y

dx
â¤
â¦q(y)
y
dy =
t

â€“âˆ
â¡
â£
âˆ

0
p
x
y
 q(y)
y
dy
â¤
â¦dx =
t

â€“âˆ
r(x) dx .
This being valid for all t âˆˆR, the function r is a density of X â‹…Y.
âˆ
Example 4.7.2. Let U and V be two independent random variables uniformly distrib-
uted on [0, 1]. Which probability distribution does U â‹…V possess?
Answer: We have p(y) = q(y) = 1 if 0 â‰¤y â‰¤1, and p(y) = q(y) = 0 otherwise.
Furthermore, 0 â‰¤U â‹…V â‰¤1, hence its density r satisï¬es r(x) = 0 if x âˆ‰[0, 1]. For x âˆˆ[0, 1]
we apply formula (4.38) and obtain
r(x) =
âˆ

0
p
x
y
 q(y)
y
dy =
1

x
1
y dy = â€“ ln(x) = ln
 1
x

,
0 < x â‰¤1 .
Consequently, if 0 < a < b â‰¤1, then
P{a â‰¤U â‹…V â‰¤b} = â€“
b

a
ln(x) dx = â€“ [x ln x â€“ x]b
a = a ln(a) â€“ b ln(b) + b â€“ a .
In particular, it follows that
P{U â‹…V â‰¤t} = t â€“ t ln t ,
0 < t â‰¤1 .
(4.40)
Our next objective are quotients of random variables X and Y. We denote their
densities by p and q, thereby assuming q(x) = 0 if x â‰¤0. Then we get
Proposition 4.7.3. Let X and Y be independent with P{Y > 0} = 1. Then their quotient
X/Y has the density r given by
r(x) =
âˆ

0
y p(x y) q(y) dy ,
x âˆˆR .
Proof: The proof of Proposition 4.7.3 is quite similar to that of 4.7.1. Therefore, we
present only the main steps. Setting
At := {(u, y) âˆˆR Ã— (0, âˆ) : u â‰¤t y} ,
15 The interchange of the integrals is justiï¬ed by Proposition A.5.5. Note that p and q are nonnegative.

4.7 Products and Quotients of Random Variables
191
we obtain
P{(X/Y) â‰¤t} = P(X,Y)(At) =
âˆ

0
â¡
â£
ty

â€“âˆ
p(u) du
â¤
â¦q(y) dy .
(4.41)
We change the variables in the inner integral of eq. (4.41) by putting x = u/y. After that
we interchange the integrals and arrive at
P{(X/Y) â‰¤t} =
t

â€“âˆ
r(x) dx
for all t âˆˆR. This proves that r is a density of X/Y.
âˆ
Example 4.7.4. Let U and V be as in Example 4.7.2. We investigate now their quotient
U/V. By Proposition 4.7.3 its density r can be computed by
r(x) =
âˆ

0
y p(xy)q(y) dy =
1

0
yp(xy)dy =
1

0
y dy = 1
2
in the case 0 â‰¤x â‰¤1. If 1 â‰¤x < âˆ, then p(xy) = 0 if y > 1/x, and it follows that
r(x) =
1/x

0
y dy =
1
2x2
for those x. Combining both cases, the density r of U/V may be written as
r(x) =
â§
âªâ¨
âªâ©
1
2 : 0 â‰¤x â‰¤1
1
2x2 : 1 < x < âˆ
0 : otherwise .
Question: Does there exist an easy geometric explanation for r(x) =
1
2 in the case
0 â‰¤x â‰¤1 ?
Answer: If t > 0, then
FU/V(t) = P{U/V â‰¤t} = P{U â‰¤t V} = P(U,V)(At) ,
where
At := {(u, v) âˆˆ[0, 1]2 : 0 â‰¤u â‰¤v t} .
If 0 < t â‰¤1, then At is a triangle in [0, 1]2 with area vol2(At) = t
2. The independence of
U and V implies (cf. Example 3.6.21) that P(U,V) is the uniform distribution on [0, 1]2,
hence
FU/V(t) = P(U,V)(At) = vol2(At) = t
2 ,
0 < t â‰¤1 ,
leading to r(t) = Fâ€²
U/V(t) = 1
2 for those t.

192
4 Operations on Random Variables
4.7.1 Studentâ€™s t-Distribution
Let us use Proposition 4.7.3 to compute the density of a distribution, which plays a
crucial role in Mathematical Statistics.
Proposition 4.7.5. Let X be N(0, 1)-distributed and Y be independent of X and 72
n-
distributed for some n â‰¥1. Deï¬ne the random variable Z as
Z :=
X
=
Y/n
.
Then Z possesses the density r given by
r(x) =
A
 n+1
2

âˆšn 0 A
 n
2


1 + x2
n
â€“n/2 â€“1/2
,
x âˆˆR .
(4.42)
Proof: In a ï¬rst step we determine the density of
âˆš
Y with Y distributed according to
72
n. If t > 0, then
Fâˆš
Y(t) = P{
âˆš
Y â‰¤t} = P{Y â‰¤t2} =
1
2n/2 A
 n
2

t2

0
xn/2 â€“1 eâ€“x/2 dx .
Thus, if t > 0, then the density q of
âˆš
Y equals
q(t) = d
dtFâˆš
Y(t) =
1
2n/2 A
 n
2
 (2t) tnâ€“2 eâ€“t2/2
=
1
2n/2 â€“1 A
 n
2
 tnâ€“1 eâ€“t2/2 .
(4.43)
Of course, we have q(t) = 0 if t â‰¤0.
In a second step we determine the density Ëœr of ËœZ = Z/âˆšn = X/
âˆš
Y. An application
of Proposition 4.7.3 for p(x) =
1
âˆš
20 eâ€“x/2 and q given in eq. (4.43) leads to
Ëœr(x) =
âˆ

0
y

1
âˆš
20
eâ€“(xy)2/2
 )
1
2n/2 â€“1 A
 n
2
 ynâ€“1 eâ€“y2/2
*
dy
=
1
âˆš0 2n/2 â€“1/2 A
 n
2

âˆ

0
yn eâ€“(1+x2)y2/2 dy .
(4.44)
Change the variables in the last integral by v =
y2
2 (1 + x2). Then y =
âˆš
2v
(1+x2)1/2 and,
consequently, dy =
1
âˆš
2 vâ€“1/2 (1 + x2)â€“1/2 dv. Inserting this into eq. (4.44) shows that

4.7 Products and Quotients of Random Variables
193
Ëœr(x) =
1
âˆš0 2n/2 A
 n
2

âˆ

0
2n/2 vn/2 â€“1/2 eâ€“v
(1 + x2)n/2 +1/2 dv
=
A
 n+1
2

âˆš0 A
 n
2
 (1 + x2)â€“n/2 â€“1/2 .
(4.45)
In a third step, we ï¬nally obtain the density r of Z. Since Z = âˆšn ËœZ, formula (4.3)
applies with b = 0 and a = âˆšn. Thus, by eq. (4.45) for Ëœr, as asserted,
r(x) =
1
âˆšn
Ëœr
 x
âˆšn

=
A
 n+1
2

âˆšn 0 A
 n
2


1 + x2
n
â€“n/2 â€“1/2
.
âˆ
Deï¬nition 4.7.6. The probability measure on (R, B(R)) with density r, given by
eq. (4.42), is called tn-distribution or Studentâ€™s t-distribution with n degrees of
freedom. A random variable Z is said to be tn-distributed or t-distributed with n
degrees of freedom, provided its probability distribution is a tn-distribution, that
is, for a < b
P{a â‰¤Z â‰¤b} =
A
 n+1
2

âˆšn 0 A
 n
2

b

a

1 + x2
n
â€“n/2 â€“1/2
dx .
Remark 4.7.7. The t1-distribution coincides with the Cauchy distribution introduced
in 1.6.33. Observe that A(1/2) = âˆš0 and A(1) = 1.
In view of Deï¬nition 4.7.6, we may now formulate Proposition 4.7.5 as follows.
Proposition 4.7.8. If X and Y are independent and N(0, 1)- and 72
n distributed, then
X
âˆš
Y/n is tn-distributed.
Proposition 4.6.17 leads still to another version of Proposition 4.7.5:
Proposition 4.7.9. If X, X1, . . . , Xn are independent N(0, 1)-distributed, then
X
+
1
n
n
i=1 X2
i
is tn-distributed.

194
4 Operations on Random Variables
Corollary 4.7.10. If X and Y are independent and N(0, 1)-distributed, then X/|Y| pos-
sesses a Cauchy distribution.
Proof: An application of Proposition 4.7.9 with n = 1 and X1 = Y implies that X/|Y|
is t1-distributed. We saw in Remark 4.7.7 the t1 and the Cauchy distribution coincide,
thus, X/|Y| is also Cauchy distributed.
âˆ
4.7.2 F-Distribution
We present now another important class of probability measures or probability
distributions playing a central role in Mathematical Statistics.
Proposition 4.7.11. For two natural numbers m and n let X and Y be independent and
72
m- and 72
n-distributed. Then Z := X/m
Y/n has the distribution density r deï¬ned as
r(x) =
â§
â¨
â©
0
: x â‰¤0
mm/2 nn/2 â‹…
A( m+n
2 )
A( m
2 )A( n
2 ) â‹…
xm/2 â€“1
(mx+n)(m+n)/2 : x > 0
(4.46)
Proof: We ï¬rst evaluate the density Ëœr of ËœZ = X/Y. To this end we apply Proposition
4.7.3 with functions p and q given by
p(x) =
1
2m/2 A(m/2) xm/2 â€“1 eâ€“x/2
and
q(y) =
1
2n/2 A(n/2) yn/2 â€“1 eâ€“y/2
whenever x, y > 0. Then we get
Ëœr(x) =
1
2(m+n)/2 A(m/2) A(n/2)
âˆ

0
y (xy)m/2 â€“1 yn/2 â€“1 eâ€“xy/2 eâ€“y/2 dy
=
xm/2 â€“1
2(m+n)/2 A(m/2) A(n/2)
âˆ

0
y(m+n)/2 â€“1 eâ€“y(1+x)/2 dy .
(4.47)
We replace in eq. (4.47) the variable y by u = y(1+ x)/2, thus, dy =
2
1+x du. Inserting this
into eq. (4.47), the last expression transforms to
xm/2 â€“1
A(m/2) A(n/2) (1 + x)â€“(n+m)/2
âˆ

0
u(m+n)/2 â€“1 eâ€“u du
=
A
 m+n
2

A
 m
2

A
 n
2
 â‹…
xm/2 â€“1
(1 + x)(m+n)/2 .

4.7 Products and Quotients of Random Variables
195
Because of Z = n
m â‹…ËœZ, we obtain the density r of Z by Proposition 1.7.17. Indeed, then
r(x) = m
n Ëœr
mx
n

= mm/2 nn/2 â‹…
A
 m+n
2

A
 m
2

A
 n
2
 â‹…
xm/2 â€“1
(mx + n)(m+n)/2
as asserted.
âˆ
Remark 4.7.12. Using relation (1.59) between the beta and the gamma functions, the
density r of Z may also be written as
r(x) = mm/2 nn/2
B
 m
2 , n
2
 â‹…
xm/2 â€“1
(mx + n)(m+n)/2 ,
x > 0 .
Deï¬nition 4.7.13. The probability measure on (R, B(R)) with density r deï¬ned by
eq. (4.46) is called Fisherâ€“Snecedor distribution or F-distribution (with m and
n degrees of freedom).
A random variable Z is F-distributed (with m and n degrees of freedom),
provided its probability distribution is an F-distribution. Equivalently, if 0 â‰¤a < b,
then
P{a â‰¤Z â‰¤b} = mm/2 nn/2 â‹…
A
 m+n
2

A
 m
2

A
 n
2

b

a
xm/2 â€“1
(mx + n)(m+n)/2 dx .
The random variable Z is also said to be Fm,n-distributed.
With this notation, Proposition 4.7.11 may now be formulated as follows:
Proposition 4.7.14. If two independent random variables X and Y are 72
m- and 72
n
distributed, then X/m
Y/n is Fm,n-distributed.
Finally, Proposition 4.6.17 implies the following version of the previous result.
Proposition 4.7.15. Let X1, . . . , Xm, Y1, . . . , Yn be independent N(0, 1)-distributed.
Then
1
m
m
i=1 X2
i
1
n
n
j=1 Y2
j
is Fm,n-distributed.
Corollary 4.7.16. If a random variable Z is Fm,n-distributed, then 1/Z possesses an Fn,m
distribution.
Proof: This is an immediate consequence of Proposition 4.7.11.
âˆ

196
4 Operations on Random Variables
4.8 Problems
Problem 4.1. Let U be uniformly distributed on [0, 1]. Which distributions do the
following random variables possess
min{U, 1 â€“ U}, max{U, 1 â€“ U}, |2U â€“ 1| and
...U â€“ 1
3
... ?
Problem 4.2 (Generating functions). Let X be a random variable with values in N0.
For k âˆˆN0 let pk = P{X = k}. Then its generating function >X is deï¬ned by
>X(t) =
âˆ

k=0
pk tk .
1.
Show that >X(t) exists if |t| â‰¤1.
2.
Let X and Y be two independent random variables with values in N0. Prove that
then
>X+Y = >X â‹…>Y .
3.
Compute >X in each of the following cases:
(a) X is uniformly distributed on {1, . . . , N} for some N â‰¥1.
(b) X is Bn,p-distributed for some n â‰¥1 and p âˆˆ[0, 1].
(c) X is Pois+-distributed for some + > 0.
(d) X is Gp-distributed for a certain 0 < p < 1.
(e) X is Bâ€“
n,p-distributed.
Problem 4.3. Roll two dice simultaneously. Let X be result of the ï¬rst die and Y that
of the second one. Is it possible to falsify these two dice in such a way so that X + Y
is uniformly distributed on {2, . . . , 12}? It is not assumed that both dice are falsiï¬ed in
the same way.
Hint: One possible way to answer this question is as follows: investigate the gen-
erating functions of X and Y and compare their product with the generating function
of the uniform distribution on {2, . . . , 12}.
Problem 4.4. Let X1, . . . , Xn be a sequence of independent identically distributed
random variables with common distribution function F and distribution density p,
that is,
P{Xj â‰¤t} = F(t) =
t

â€“âˆ
p(x) dx ,
j = 1, . . . , n .

4.8 Problems
197
Deï¬ne random variables Xâˆ—and Xâˆ—by
Xâˆ—:= min{X1, . . . , Xn}
and
Xâˆ—:= max{X1, . . . , Xn} .
1.
Determine the distribution functions and densities of Xâˆ—and Xâˆ—.
2.
Describe the distribution of the random variable Xâˆ—in the case that the Xjs are
exponentially distributed with parameter + > 0.
3.
Suppose now the Xjs are uniformly distributed on [0, 1]. Describe the distribution
of Xâˆ—and Xâˆ—in this case.
Problem 4.5. Find a function f from (0, 1) to R such that
P{f(U) = k} = 1
2k ,
k = 1, 2, . . .
for U uniformly distributed on [0, 1].
Problem 4.6. Let U be uniform distributed on [0, 1]. Find functions f and g such that
X = f(U) and Y = g(U) have the distribution densities p and q with
p(x) :=

0
: x âˆ‰(0, 1]
xâ€“1/2
2
: x âˆˆ(0, 1]
and
q(x) :=
â§
âªâ¨
âªâ©
0
:
|x| > 1
x + 1 : â€“1 â‰¤x â‰¤0
1 â€“ x :
0 < x â‰¤1
.
Problem 4.7. Let X and Y be independent random variables with
P{X = k} = P{Y = k} = 1
2k ,
k = 1, 2, . . . .
How is X + Y distributed?
Problem 4.8. The number of customers visiting a shop per day is Poisson distributed
with parameter + > 0. The probability that a single customer buys something equals p
for a given 0 â‰¤p â‰¤1. Let X be the number of customers per day buying some goods.
Determine the distribution of X.
Remark: We assume that the decision whether or not a single customer buys
something is independent of the number of daily visitors.
A different way to formulate the above question is as follows: let X0, X1, . . . be
independent random variables with P{X0 = 0} = 1,
P{Xj = 1} = p
and
P{Xj = 0} = 1 â€“ p ,
j = 1, 2, . . . ,

198
4 Operations on Random Variables
for a certain p âˆˆ[0, 1]. Furthermore, let Y be a Poisson-distributed random variable
with parameter + > 0, independent of the Xj. Determine the distribution of
X :=
Y

j=0
Xj .
Hint: Use the â€œinï¬niteâ€ version of the law of total probability as stated in Problem 2.4.
Problem 4.9. Suppose X and Y are independent and exponentially distributed with
parameter + > 0. Find the distribution densities of X â€“ Y and X/Y.
Problem 4.10. Two random variables U and V are independent and uniformly distrib-
uted on [0, 1]. Given n âˆˆN, ï¬nd the distribution density of U + n V.
Problem 4.11. Let X and Y be independent random variable distributed according to
Pois+ and Pois,, respectively. Given n âˆˆN0 and some k âˆˆ{0, . . . , n}, prove
P{X = k | X + Y = n} =
n
k
 
+
+ + ,
k 
,
+ + ,
nâ€“k
= Bn,p({k})
with p =
+
++,.
Reformulation of the preceding problem: An owner of two stores, say store A and
store B, observes that the number of customers in each of these stores is independent
and Pois+ and Pois, distributed. One day he was told that there were n customers in
both stores together. What is the probability that k of the n customers were in store A,
hence n â€“ k in store B ?
Problem 4.12. Let X and Y be independent standard normal variables. Show that X/Y
is Cauchy distributed.
Hint: Use Corollary 4.7.10 and the fact that the vectors (X, Y), (â€“X, Y), (X, â€“Y), and
(â€“X, â€“Y) are identically distributed. Note that the probability distribution of each of
these two-dimensional vectors is the (two-dimensional) standard normal distribution.
Problem 4.13. Let X and Y be independent Gp-distributed. Find the probability distri-
bution of X â€“ Y.
Hint: Compare Example 4.5.5. There we evaluated the distribution of Xâ€“Y if p = 1
2.
Problem 4.14. Let U and V be as in Example 4.7.2. Find an analytic (or geometric)
explanation for
P{U â‹…V â‰¤t} = t â€“ t ln t ,
0 < t â‰¤1 ,
proved in (4.40).
Hint: Use that the vector (U, V) is uniformly distributed on [0, 1]2.

4.8 Problems
199
Problem 4.15. Suppose X is a random variable with values in (a, b) âŠ†R and with dens-
ity p. Let f from (a, b) â†’R be (strictly) monotone and differentiable. Give a formula
for q, the density of f(X).
Hint: Investigate the cases of decreasing and increasing functions f separately.
Use this formula to evaluate the density of eX and of eâ€“X for a N(0, 1)-
distributed X.

5 Expected Value, Variance, and Covariance
5.1 Expected Value
5.1.1 Expected Value of Discrete Random Variables
What is an expected value (also called mean value or expectation) of a random vari-
able? How is it deï¬ned? Which property of the random variable does it describe and
how it can be computed? Does every random variable possess an expected value?
To approach the solution of these questions, let us start with an example.
Example 5.1.1. Suppose N students attend a certain exam. The number of possible
points is 100. Given j = 0, 1, . . . , 100, let nj be the number of students who achieved j
points. Now choose randomly, according to the uniform distribution (a single student
is chosen with probability 1/N), one student. Name him or her 9, and deï¬ne X(9) as
the number of points that the chosen student achieved. Then X is a random variable
with values in D = {0, 1, . . . , 100}. How is X distributed? Since X has values in D, its
distribution is described by the probabilities
pj = P{X = j} = nj
N ,
j = 0, 1, . . . , 100 .
(5.1)
As expected value of X we take the average number A of points in this exam. How is A
evaluated? The easiest way to do this is
A = 1
N
100

j=0
j â‹…nj =
100

j=0
j â‹…nj
N =
100

j=0
j â‹…pj ,
where the pjs are deï¬ned by eq. (5.1). If we write EX for the expected value (or mean
value) of X, and if we assume that this value coincides with A, then the preceding
equation says
EX =
100

j=0
j pj =
100

j=0
j P{X = j} =
100

j=0
xj P{X = xj} ,
where the xj = j, j = 0, . . . , 100 denote the possible values of X.
In view of this example, the following deï¬nition for the expected value of a discrete
random variable X looks feasible. Suppose X has values in D = {x1, x2, . . . }, and let
pj = P{X = xj}, j = 1, 2, . . . . Then the expected value EX of X is given by
EX =
âˆ

j=1
xj pj =
âˆ

j=1
xj P{X = xj} .
(5.2)

5.1 Expected Value
201
Unfortunately, the sum in eq. (5.2) does not always exist. In order to overcome this
difï¬culty, let us recall some basic facts about inï¬nite series of real numbers.
A sequence (!j)jâ‰¥1 of real numbers is called summable, provided its sequence of
partial sums (sn)nâ‰¥1 with sn = n
j=1 !j converges in R. Then one deï¬nes
âˆ

j=1
!j = lim
nâ†’âˆsn .
If the sequence of partial sums diverges, nevertheless, in some cases we may assign to
the inï¬nite series a limit. If either limnâ†’âˆsn = â€“âˆor limnâ†’âˆsn = âˆ, then we write
âˆ
j=1 !j = â€“âˆor âˆ
j=1 !j = âˆ, respectively. In particular, if !j â‰¥0 for j âˆˆN, then the
sequence of partial sums is nondecreasing, which implies that only two different cases
may occur: Either âˆ
j=1 !j < âˆ(in this case the sequence is summable) or âˆ
j=1 !j = âˆ.
Let (!j)jâ‰¥1 be an arbitrary sequence of real numbers. If âˆ
j=1 |!j| < âˆ, then it is
called absolutely summable. Note that each absolutely summable sequence is sum-
mable. This is a direct consequence of Cauchyâ€™s convergence criterion. The converse
implication is wrong, as can be seen by considering ((â€“1)n/n)nâ‰¥1.
Now we are prepared to deï¬ne the expected value of a non-negative random
variable.
Deï¬nition 5.1.2. Let X be a discrete random variable with values in {x1, x2, . . . }
for some xj â‰¥0. Equivalently, the random variable X is discrete with X â‰¥0. Then
the expected value of X is deï¬ned by
EX :=
âˆ

j=1
xj P{X = xj} .
(5.3)
Remark 5.1.3. Since xj P{X = xj} â‰¥0 for non-negative X, for those random variables
the sum in eq. (5.3) is always well-deï¬ned, but may be inï¬nite. That is, each non-
negative discrete random variable X possesses an expected value EX âˆˆ[0, âˆ].
Let us now turn to the case of arbitrary (not necessarily non-negative) random
variables. The next example shows which problems may arise.
Example 5.1.4. We consider the probability measure introduced in Example 1.3.6 and
choose a random variable X with values in Z distributed according to the probability
measure in this example. In other words,
P{X = k} = 3
02
1
k2 ,
k âˆˆZ\{0} .

202
5 Expected Value, Variance, and Covariance
If we try to evaluate the expected value of X by formula (5.2), then this leads to the
undetermined expression
3
02
âˆ

k=â€“âˆ
k/=0
k
k2 = 3
02
lim
nâ†’âˆ
mâ†’âˆ
n

k=â€“m
1
k = 3
02
)
lim
nâ†’âˆ
n

k=1
1
k + lim
mâ†’âˆ
1

k=â€“m
1
k
*
= 3
02
)
lim
nâ†’âˆ
n

k=1
1
k â€“ lim
mâ†’âˆ
m

k=1
1
k
*
= âˆâ€“ âˆ.
To exclude phenomenons as in Example 5.1.4, we suppose that a random variable has
to meet the following condition.
Deï¬nition 5.1.5. Let X be discrete with values in {x1, x2, . . . } âŠ‚R. Then the
expected value of X exists, provided that
E|X| =
âˆ

j=1
|xj| P{X = xj} < âˆ.
(5.4)
We mentioned above that an absolutely summable sequence is summable. Hence,
under assumption (5.4), the sum in the subsequent deï¬nition is a well-deï¬ned real
number.
Deï¬nition 5.1.6. Let X be a discrete random variable satisfying E|X| < âˆ. Then its
expected value is deï¬ned as
EX =
âˆ

j=1
xj P{X = xj} .
As before, x1, x2, . . . are the possible values of X.
Example 5.1.7. We start with an easy example that demonstrates how to compute the
expected value in concrete cases. If the distribution of a random variable X is deï¬ned
as P{X = â€“1} = 1/6, P{X = 0} = 1/8, P{X = 1} = 3/8, and P{X = 2} = 1/3, then its expected
value equals
EX = (â€“1) â‹…P{X = â€“1} + 0 â‹…P{X = 0} + 1 â‹…P{X = 1} + 2 â‹…P{X = 2}
= â€“ 1
6 + 3
8 + 2
3 = 7
8 .

5.1 Expected Value
203
Example 5.1.8. The next example shows that EX = âˆmay occur even for quite nat-
ural random variables. Thus, let us come back to the model presented in Example
1.4.39. There we developed a strategy how to win always one dollar in a series of
games. The basic idea was, after losing a game, next time one doubles the amount in
the pool. As in Example 1.4.39, let X(k) be the amount of money needed when winning
for the ï¬rst time in game k. We obtained
P{X = 2k â€“ 1} = p(1 â€“ p)kâ€“1 ,
k = 1, 2 . . . .
Recall that 0 < p < 1 is the probability to win a single game. We ask for the expected
value of money needed to apply this strategy. It follows
EX =
âˆ

k=1
(2k â€“ 1)P{X = 2k â€“ 1} = p
âˆ

k=1
(2k â€“ 1)(1 â€“ p)kâ€“1 .
(5.5)
If the game is fair, that is, if p = 1/2, then this leads to
EX =
âˆ

k=1
2k â€“ 1
2k
= âˆ,
because of (2k â€“ 1)/2k â†’1 as k â†’âˆ. This yields EX = âˆfor all1 p â‰¤1/2.
Let us sum up: if p â‰¤1/2 (which is the case in all provided games), the ob-
tained result tells us that the average amount of money needed, to use this strategy,
is arbitrarily large. The owners of gambling casinos know this strategy as well. There-
fore, they limit the possible amount of money in the pool. For example, if the largest
possible stakes is N dollars, then the strategy breaks down as soon as one loses n
games for some n with 2n > N. And, as our calculations show, on average this always
happens.
Remark 5.1.9. If p > 1/2, then the average amount of money needed is ï¬nite, and it
can be calculated by
EX = p
âˆ

k=1
(2k â€“ 1)(1 â€“ p)kâ€“1 = 2p
âˆ

k=0
(2 â€“ 2p)k â€“ p
âˆ

k=0
(1 â€“ p)k
=
2p
1 â€“ (2 â€“ 2p) â€“
p
1 â€“ (1 â€“ p) =
2p
2p â€“ 1 â€“ 1 =
1
2p â€“ 1 .
5.1.2 Expected Value of Certain Discrete Random Variables
The aim of this section is to compute the expected value of the most interesting
discrete random variables. We start with uniformly distributed ones.
1 If p â‰¤1/2 then 1 â€“ p â‰¥1/2, hence the sum in eq. (5.5) becomes bigger and, therefore, it also diverges.

204
5 Expected Value, Variance, and Covariance
Proposition 5.1.10. Let X be uniformly distributed on the set {x1, . . . , xN} of real
numbers. Then it follows that
EX = 1
N
N

j=1
xj .
(5.6)
That is, EX is the arithmetic mean of the xjs.
Proof: This is an immediate consequence of P{X = xj} = 1/N, implying
EX =
N

j=1
xj â‹…P{X = xj} =
N

j=1
xj â‹…1
N .
âˆ
Remark 5.1.11. For general discrete random variables X with values x1, x2, . . . , their
expected value EX may be regarded as a weighted (the weights are the pjs) mean of
the xjs.
Example 5.1.12. Let X be uniformly distributed on {1, . . . , 6}. Then X is a model for
rolling a fair die. Its expected value is, as is well known,
EX = 1 + â‹…â‹…â‹…+ 6
6
= 21
6 = 7
2 .
Next we determine the expected value of a binomial distributed random variable.
Proposition 5.1.13. Let X be binomial distributed with parameters n and p. Then we get
EX = n p .
(5.7)
Proof: The possible values of X are 0, . . . , n. Thus, it follows that
EX =
n

k=0
k â‹…P{X = k} =
n

k=1
k â‹…
n
k

pk(1 â€“ p)nâ€“k
=
n

k=1
n!
(k â€“ 1)! (n â€“ k)! pk(1 â€“ p)nâ€“k
= n p
n

k=1
(n â€“ 1)!
(k â€“ 1)!(n â€“ k)! pkâ€“1(1 â€“ p)nâ€“k .

5.1 Expected Value
205
Shifting the index from k â€“ 1 to k in the last sum implies
EX = np
nâ€“1

k=0
(n â€“ 1)!
k! (n â€“ 1 â€“ k)! pk(1 â€“ p)nâ€“1â€“k
= np
nâ€“1

k=0
n â€“ 1
k

pk(1 â€“ p)nâ€“1â€“k
= np

p + (1 â€“ p)
nâ€“1 = np .
This completes the proof.
âˆ
Remark 5.1.14. The previous result tells us the following: if we perform n independent
trials of an experiment with success probability p, then on the average we will observe
np times success.
Example 5.1.15. One kilogram of a radioactive material consists of N atoms. The atoms
decay independently of each other and, moreover, the lifetime of each of the atoms is
exponentially distributed with some parameter + > 0. We ask for the time T0 > 0, at
which, on the average, half of the atoms are decayed. T0 is usually called radioactive
half-life.
Answer: If T > 0, then the probability that a single atom decays before time T is
given by
p(T) = E+([0, T]) = 1 â€“ e+T.
Since the atoms decay independently, the number of atoms decaying before time T
is BN,p(T)-distributed. Therefore, by Proposition 5.1.13, the expected value of decayed
atoms equals N â‹…p(T) = N(1 â€“ e+T). Hence, T0 has to satisfy
N(1 â€“ eâ€“+T0) = N
2 ,
leading to T0 = ln 2/+. Conversely, if we know T0 and want to determine +, then + =
ln 2/T0. Consequently, the probability that a single atom decays before time T > 0 can
also be described by
E+([0, T]) = 1 â€“ eâ€“T ln 2/T0 = 1 â€“ 2â€“T/T0 .
Next, we determine the expected value of Poisson distributed random variables.
Proposition 5.1.16. For some + > 0, let X be distributed according to Pois+. Then it
follows that EX = +.

206
5 Expected Value, Variance, and Covariance
Proof: The possible values of X are 0, 1, . . . . Hence, the expected value is given by
EX =
âˆ

k=0
k â‹…P{X = k} =
âˆ

k=1
k +k
k! eâ€“+ = +
âˆ

k=1
+kâ€“1
(k â€“ 1)! eâ€“+ ,
which transforms by a shift of the index to
+
 âˆ

k=0
+k
k!

eâ€“+ = +

e+
eâ€“+ = + .
This proves the assertion.
âˆ
Interpretation: Proposition 5.1.16 explains the role of the parameter + in the deï¬nition
of the Poisson distribution. Whenever certain numbers are Poisson distributed, then
+ > 0 is the average of the observed values. For example, if the number of accidents per
week is known to be Pois+-distributed, then the parameter + is determined by the aver-
age number of accidents per week in the past. Or, as we already mentioned in Example
4.6.6, the number of raisins in a piece of 1 pounds of dough is Pois+1-distributed, where
+ is the proportion of raisins per pound dough, hence +1 is the average number of
raisins per 1 pounds.
Example 5.1.17. Let us once more take a look at Example 4.6.15. There we considered
light bulbs with E+-distributed lifetime. Every time a bulb burned out, we replaced it
by a new one of the same type. It turned out that the number of necessary replace-
ments until time T > 0 was Pois+T-distributed. Consequently, by Proposition 5.1.16, on
average, until time T we have to change the light bulbs + T times.
Finally, we compute the expected value of a negative binomial distributed random
variable. According to Deï¬nition 1.4.41, a random variable X is Bâ€“
n,p-distributed if
P{X = k} =
k â€“ 1
k â€“ n

pn (1 â€“ p)kâ€“n ,
k = n, n + 1, . . .
or, equivalently, if
P{X = k + n} =
â€“n
k

pn (p â€“ 1)k ,
k = 0, 1, . . .
(5.8)
Proposition 5.1.18. Suppose X is Bâ€“
n,p-distributed for some n â‰¥1 and p âˆˆ(0, 1). Then
EX = n
p .

5.1 Expected Value
207
Proof: Using eq. (5.8), the expected value of X is computed as
EX =
âˆ

k=n
k P{X = k} =
âˆ

k=0
(k + n) P{X = k + n}
= pn
âˆ

k=1
k
â€“n
k

(p â€“ 1)k + n pn
âˆ

k=0
â€“n
k

(p â€“ 1)k .
(5.9)
To evaluate the two sums in eq. (5.9) we use Proposition A.5.2, which asserts
1
(1 + x)n =
âˆ

k=0
â€“n
k

xk
(5.10)
for |x| < 1. Applying this with x = p â€“ 1 (recall 0 < p < 1),
n pn
âˆ

k=0
â€“n
k

(p â€“ 1)k = n pn
1
(1 + (p â€“ 1))n = n .
(5.11)
Next we differentiate eq. (5.10) with respect to x and obtain
â€“n
(1 + x)n+1 =
âˆ

k=1
k
â€“n
k

xkâ€“1 ,
which, multiplying both sides by x, gives
â€“nx
(1 + x)n+1 =
âˆ

k=1
k
â€“n
k

xk .
(5.12)
Letting x = p â€“ 1 in eq. (5.12), the ï¬rst sum in eq. (5.9) becomes
pn
âˆ

k=1
k
â€“n
k

(p â€“ 1)k = pn
â€“n(p â€“ 1)
(1 + (p â€“ 1))n+1 = n(1 â€“ p)
p
.
(5.13)
Finally, we combine eqs. (5.9), (5.11), and (5.13) and obtain
EX = n(1 â€“ p)
p
+ n = n
p
as claimed.
âˆ
Remark 5.1.19. Proposition 5.1.18 asserts that on average the nth success occurs in
trial n/p. For example, rolling a die, on average, the ï¬rst appearance of number â€œ6â€
will be in trial 6, the second in trial 12, and so on.

208
5 Expected Value, Variance, and Covariance
Corollary 5.1.20. If X is geometric distributed with parameter p, then
EX = 1
p .
(5.14)
Proof: Recall that Gp = Bâ€“
1,p, hence X is Bâ€“
1,p-distributed, and EX = 1
p by Proposition
5.1.18.
âˆ
Alternative proof of Corollary 5.1.20: Suppose X is Gp-distributed. Then we write
EX = p
âˆ

k=1
k(1 â€“ p)kâ€“1 = p
âˆ

k=0
(k + 1)(1 â€“ p)k
= (1 â€“ p)
âˆ

k=0
k p (1 â€“ p)kâ€“1 + p
âˆ

k=0
(1 â€“ p)k
= (1 â€“ p) EX + 1 .
Solving this equation with respect to EX proves eq. (5.14) as asserted. Observe that
this alternative proof is based upon the knowledge of EX < âˆ. Otherwise, we could
not solve the equation with respect to EX. But, because of 0 < p < 1, this fact is an
easy consequence of
EX = p
âˆ

k=1
k(1 â€“ p)kâ€“1 < âˆ.
5.1.3 Expected Value of Continuous Random Variables
Let X be a continuous random variable with distribution density p, that is, if t âˆˆR,
then
P{X â‰¤t} =
t

â€“âˆ
p(x) dx .
How to deï¬ne EX in this case?
To answer this question, let us present formula (5.3) in an equivalent way. Suppose
X maps K into a set D âŠ‚R, which is either ï¬nite or countably inï¬nite. Let p : R â†’[0, 1]
be the probability mass function of X introduced in eq. (3.4). Then the expected value
of X may also be written as
EX =

xâˆˆR
x p(x) .
In this form, the preceding formula suggests that in the continuous case the sum
should be replaced by an integral. This can made more precise by approximating

5.1 Expected Value
209
continuous random variables by discrete ones. But this is only a heuristic explan-
ation; for a precise approach, deeper convergence theorems for random variables
are needed. Therefore, we do not give more details here, we simply replace sums by
integrals.
Doing so, for continuous random variables the following approach for the deï¬ni-
tion of EX might be taken. If p : R â†’[0, âˆ) is the distribution density of X, set
EX :=
âˆ

â€“âˆ
x p(x) dx .
(5.15)
However, here we have a similar problem as in the discrete case, namely that the in-
tegral in eq. (5.15) need not exist. Therefore, let us give a short digression about the
integrability of real functions.
Let f : R â†’R be a function such that for all a < b the integral
# b
a f(x)dx is a
well-deï¬ned real number. Then
âˆ

â€“âˆ
f(x) dx := lim
aâ†’â€“âˆ
bâ†’âˆ
b

a
f(x) dx ,
(5.16)
provided both limits on the right-hand side of eq. (5.16) exist. In this case we call f
integrable (in the Riemann sense) on R.
If f(x) â‰¥0, x âˆˆR, then the limit lim aâ†’â€“âˆ
bâ†’âˆ
# b
a f(x) dx always exists in a generalized
sense, that is, it may be ï¬nite (then f is integrable) or inï¬nite, then this is expressed
by
# âˆ
â€“âˆf(x) dx = âˆ.
If
# âˆ
â€“âˆ|f(x)| dx < âˆ, then f is said to be absolutely integrable, and as in the case
of inï¬nite series, absolutely integrable function are integrable. Note that x â†¦sin x/x
is integrable, but not absolutely integrable.
After this preparation, we come back to the deï¬nition of the expected value for
continuous random variables.
Deï¬nition 5.1.21. Let X be a random variable with distribution density p. If
p(x) = 0 for x < 0, or, equivalently, P{X â‰¥0} = 1, then the expected value of
X is deï¬ned by
EX :=
âˆ

0
x p(x) dx .
(5.17)
Observe that under these conditions upon p or X, we have x p(x) â‰¥0. Therefore, the
integral in eq. (5.17) is always well-deï¬ned, but might be inï¬nite. In this case we write
EX = âˆ.

210
5 Expected Value, Variance, and Covariance
Let us turn now to the case of R-valued random variables. The following example
shows that the integral in eq. (5.15) may not exist, hence, in general, without an
additional assumption the expected value cannot be deï¬ned by eq. (5.15).
Example 5.1.22. A random variable X is supposed to possess the density (check that
this is indeed a density function)
p(x) =

0 : â€“1 < x < 1
1
2 x2 :
|x| â‰¥1
If we try to evaluate EX by virtue of eq. (5.15), then, because of
âˆ

â€“âˆ
x p(x)dx = lim
aâ†’â€“âˆ
bâ†’âˆ
b

a
x p(x) dx = 1
2
â¡
â£lim
bâ†’âˆ
b

1
dx
x + lim
aâ†’â€“âˆ
â€“1

a
dx
x
â¤
â¦
= 1
2
â¡
â£lim
bâ†’âˆ
b

1
dx
x â€“ lim
aâ†’âˆ
a

1
dx
x
â¤
â¦= âˆâ€“ âˆ,
we observe an undetermined expression. Thus, there is no meaningful way to intro-
duce an expected value for X.
We enforce the existence of the integral by the following condition.
Deï¬nition 5.1.23. Let X be a (real-valued) random variable with distribution dens-
ity p. We say the expected value of X exists, provided p satisï¬es the following
integrability condition2:
E|X| :=
âˆ

â€“âˆ
|x| p(x) dx < âˆ.
(5.18)
Condition (5.18) says nothing but that f(x) := x p(x) is absolutely integrable. Hence,
as mentioned above, f is integrable, and the integral in the following deï¬nition is
well-deï¬ned.
Deï¬nition 5.1.24. Suppose condition (5.18) is satisï¬ed. Then the expected value
of X is deï¬ned by
EX :=
âˆ

â€“âˆ
x p(x) dx .
2 At this point it is not clear that the right-hand integral is indeed the expected value of |X|. This will
follow later on by Proposition 5.1.36. Nevertheless, we use this notation before giving a proof.

5.1 Expected Value
211
5.1.4 Expected Value of Certain Continuous Random Variables
We start with computing the expected value of a uniformly distributed (continuous)
random variable.
Proposition 5.1.25. Let X be uniformly distributed on the ï¬nite interval I = [!, "]. Then
EX = ! + "
2
,
that is, the expected value is the midpoint of the interval I.
Proof: The distribution density of X is the function p deï¬ned as p(x) = (" â€“ !)â€“1 if
x âˆˆI, and p(x) = 0 if x âˆ‰I. Of course, X possesses an expected value,3 which can be
evaluated by
EX =
âˆ

â€“âˆ
xp(x) dx =
"

!
x
" â€“ ! dx =
1
" â€“ !
x2
2
"
!
= 1
2 â‹…"2 â€“ !2
" â€“ ! = ! + "
2
.
This proves the proposition.
âˆ
Next we determine the expected value of a gamma distributed random variable.
Proposition 5.1.26. Suppose X is A!,"-distributed with !, " > 0. Then its expected
value is
EX = ! " .
Proof: Because of P{X â‰¥0} = 1, its expected value is well-deï¬ned and computed by
EX =
âˆ

0
xp(x) dx =
1
!" A(")
âˆ

0
x â‹…x"â€“1 eâ€“x/! dx
=
1
!" A(")
âˆ

0
x" eâ€“x/! dx .
(5.19)
The change of variables u := x/! transforms eq. (5.19) into
EX =
!"+1
!" A(")
âˆ

0
u" eâ€“u du =
!"+1
!" A(") â‹…A(" + 1) = ! " ,
where we used eq. (1.48) in the last step. This completes the proof.
âˆ
3 |x|p(x) is bounded and nonzero only on a ï¬nite interval.

212
5 Expected Value, Variance, and Covariance
Corollary 5.1.27. Let X be E+-distributed for a certain + > 0. Then
EX = 1
+ .
Proof: Note that E+ = A+â€“1,1.
âˆ
Example 5.1.28. The lifetime of a special type of light bulbs is exponentially dis-
tributed. Suppose the average lifetime constitutes 100 units of time. This implies
+ = 1/100, hence, if X describes the lifetime, then
P{X â‰¤t} = 1 â€“ eâ€“t/100 ,
t â‰¥0 .
For example, the probability that the light bulb burns longer than 200 time units
equals
P{X â‰¥200} = eâ€“200/100 = eâ€“2 = 0.135335 â‹…â‹…â‹…
Remark 5.1.29. If we evaluate in the previous example
P{X â‰¥EX} = P{X â‰¥100} = eâ€“1 ,
then we see that in general P{X â‰¥EX} /= 1/2. Thus, in this case, the expected value is
different from the median of X deï¬ned as a real number M satisfying P{X â‰¥M} â‰¥1/2
and P{X â‰¤M} â‰¥1/2. In particular, if FX satisï¬es the condition of Proposition 4.4.6,
then the median is uniquely determined by M = Fâ€“1
X (1/2), i.e., by P{X â‰¤M} = 1/2. It
is easy to see that the above phenomenon appears for all exponentially distributed
random variables. Indeed, if X is E+-distributed, then M = ln 2/+ while, as we saw,
EX = 1/+.
Corollary 5.1.30. If X is 72
n-distributed, then
EX = n .
Proof: Since 72
n = A2,n/2, by Proposition 5.1.26 follows that EX = 2 â‹…n/2 = n.
âˆ
Which expected value does a beta distributed random variable possess? The next
proposition answers this question.
Proposition 5.1.31. Let X be B!,"-distributed for certain !, " > 0. Then
EX =
!
! + " .

5.1 Expected Value
213
Proof: Using eq. (1.60), by eq. (5.17) we obtain, as asserted,
EX =
1
B(!, ")
1

0
x â‹…x!â€“1(1 â€“ x)"â€“1 dx
=
1
B(!, ")
1

0
x!(1 â€“ x)"â€“1 dx = B(! + 1, ")
B(!, ")
=
!
! + " .
âˆ
Example 5.1.32. Suppose we choose independently n numbers x1, . . . , xn uniformly
distributed on [0, 1] and order them by their size. Then we get the order statistics 0 â‰¤
xâˆ—
1 â‰¤â‹…â‹…â‹…â‰¤xâˆ—
n â‰¤1. According to Example 3.7.8, if 1 â‰¤k â‰¤n, then the number xâˆ—
k is
Bk,nâ€“k+1-distributed. Thus Proposition 5.1.31 implies that the average value of xâˆ—
k, that
is, of the kth largest number, equals
k
k + (n â€“ k + 1) =
k
n + 1 .
In particular, the expected value of the smallest number is
1
n+1 while that of the largest
one is
n
n+1.
Does a Cauchy distributed random variable possess an expected value? Here we obtain
the following.
Proposition 5.1.33. If X Cauchy distributed, then EX does not exist.
Proof: First observe that we may not use Deï¬nition 5.17. The distribution density of X
is given by p(x) = 1
0 â‹…
1
1+x2 , hence, it does not satisfy p(x) = 0 for x < 0. Consequently,
we have to check whether condition (5.18) is satisï¬ed. Here we get
E|X| = 1
0
âˆ

â€“âˆ
|x|
1 + x2 dx = 2
0
âˆ

0
x
1 + x2 dx = 1
0

ln(1 + x2)
âˆ
0 = âˆ.
Thus, E|X| = âˆ, that is, X does not possess an expected value.
âˆ
Finally, we determine the expected value of normally distributed random variables.
Proposition 5.1.34. If X is N(,, 32)-distributed, then
EX = , .

214
5 Expected Value, Variance, and Covariance
Proof: First, we check whether the expected value exists. The density of X is given by
eq. (1.47), hence
âˆ

â€“âˆ
|x| p,,3(x) dx =
1
âˆš
20 3
âˆ

â€“âˆ
|x| eâ€“(xâ€“,)2/232 dx
=
1
âˆš0
âˆ

â€“âˆ
|
âˆš
23u + ,| eâ€“u2 du
â‰¤3 2
âˆš
2
âˆš0
âˆ

0
u eâ€“u2 du + |,| 2
âˆš0
âˆ

0
eâ€“u2 du < âˆ,
where we used the well-known fact4 that for all k âˆˆN0
âˆ

0
uk eâ€“u2 du < âˆ.
The expected value EX is now evaluated in a similar way by
EX =
âˆ

â€“âˆ
x p,,3(x) dx =
1
âˆš
20 3
âˆ

â€“âˆ
x eâ€“(xâ€“,)2/232 dx
=
1
âˆš
20
âˆ

â€“âˆ
(3v + ,) eâ€“v2/2 dv
= 3
1
âˆš
20
âˆ

â€“âˆ
v eâ€“v2/2 dv + ,
1
âˆš
20
âˆ

â€“âˆ
eâ€“v2/2 dv .
(5.20)
The function f(v) := v eâ€“v2/2 is odd, that is, f(â€“v) = â€“f(v), thus
# âˆ
â€“âˆf(v) dv = 0, and the
ï¬rst integral in eq. (5.20) vanishes. To compute the second integral use Proposition
1.6.6 and obtain
,
1
âˆš
20
âˆ

â€“âˆ
eâ€“v2/2 dv = ,
1
âˆš
20
âˆš
20 = , .
This completes the proof.
âˆ
Remark 5.1.35. Proposition 5.1.34 justiï¬es the notation â€œexpected valueâ€ for the para-
meter , in the deï¬nition of the probability measure N(,, 32).
4 See either [Spi08] or use that for all k â‰¥1 one has supu>0 uk eâ€“u < âˆ.

5.1 Expected Value
215
5.1.5 Properties of the Expected Value
In this section we summarize the main properties of the expected value. They are
valid for both discrete and continuous random variables. But, unfortunately, within
the framework of this book it is not possible to prove most of them in full generality.
To do so one needs an integral (Lebesgue integral)
#
K fdP of functions f : K â†’R for
some probability space (K, A, P). Then EX =
#
K XdP, and all subsequent properties of
X â†¦EX follow from those of the (Lebesgue) integral.
Proposition 5.1.36. The expected value of random variables owns the following
properties:
(1)
The expected value of X only depends on its probability distribution PX, not on the
way how X is deï¬ned. That is, if X
d= Y for two random variables X and Y, then
EX = EY.
(2)
If X is with probability 1 constant, that is, there is some c âˆˆR with P(X = c) = 1,
then EX = c .
(3)
The expected value is linear: let X and Y be two random variables possessing an
expected value and let a, b âˆˆR. Then E(aX + bY) exists as well and, moreover,
E(aX + bY) = a EX + b EY .
(4)
Suppose X is a discrete random variable with values in x1, x2, . . . . Given a function
f from R to R, the expected value Ef(X) exists if and only if
âˆ

i=1
|f(xi)| P(X = xi) < âˆ,
and, moreover, then
Ef(X) =
âˆ

i=1
f(xi) P(X = xi) .
(5.21)
(5)
If X is continuous with density p, then for any measurable function f : R â†’R the
expected value Ef(X) exists if and only if
âˆ

â€“âˆ
|f(x)| p(x) dx < âˆ.
In this case it follows that
Ef(X) =
âˆ

â€“âˆ
f(x) p(x) dx .
(5.22)

216
5 Expected Value, Variance, and Covariance
(6)
For independent X and Y possessing an expected value, the expected value of Xâ‹…Y
exists as well and, moreover,
E[X Y] = EX â‹…EY.
(7)
Write X â‰¤Y provided that X(9) â‰¤Y(9) for all 9 âˆˆK. If in this sense |X| â‰¤Y for
some Y with EY < âˆ, then E|X| < âˆand, hence, EX exists.
(8)
Suppose EX and EY exist. Then X â‰¤Y implies EX â‰¤EY. In particular, if X â‰¥0,
then EX â‰¥0.
Proof: We only prove properties (1), (2), (4), and (8). Some of the other properties are
not difï¬cult to verify in the case of discrete random variables, for example, (3), but
because the proofs are incomplete, we do not present them here. We refer to [Bil12],
[Dur10] or [Kho07] for the proofs of the remaining properties.
We begin with the proof of (1). If X and Y are identically distributed, then either
both are discrete or both are continuous. If they are discrete, and PX(D) = 1 for an at
most countably inï¬nite set D, then X
d= Y implies PY(D) = 1. Moreover, by the same
argument PX({x}) = PY({x}) for any x âˆˆD. Hence, in view of Deï¬nition 5.1.2, EX ex-
ists if and only if EY does so. Moreover, if this is valid, then EX = EY by the same
argument.
In the continuous case we argue as follows. Let p be a density of X. By X
d= Y it
follows that
t

â€“âˆ
p(x) dx = PX((â€“âˆ, t]) = PY((â€“âˆ, t]) ,
t âˆˆR .
Thus, p is also a distribution density of Y and, consequently, in view of Deï¬nition
5.1.23, the expected value of X exists if and only if this is the case for Y. Moreover, by
Deï¬nition 5.1.24 we get EX = EY.
Next we show that (2) is valid. Thus, suppose P{X = c} = 1 for some c âˆˆR. Then X
is discrete with PX(D) = 1 where D = {c}, and by Deï¬nition 5.1.2 we obtain
EX = c â‹…P{X = c} = c â‹…1 = c
as asserted.
To prove (4) we assume that X has values in D = {x1, x2, . . . }. Then Y = f(X) maps
into f(D) = {y1, y2, . . . }. Given j âˆˆN let Dj = {xi : f(xi) = yj}. Thus,
P{Y = yj} = P{X âˆˆDj} =

xiâˆˆDj
P{X = xi} .

5.1 Expected Value
217
Consequently, since Dj âˆ©Djâ€² = Ã¸ if j /= jâ€², by âˆ
j=1 Dj = D we get
E|Y| =
âˆ

j=1
|yj|P{Y = yj} =
âˆ

j=1

xiâˆˆDj
|yj|P{X = xi}
=
âˆ

j=1

xiâˆˆDj
|f(xi)|P{X = xi} =
âˆ

i=1
|f(xi)|P{X = xi} = E|X| .
This proves the ï¬rst part of (4). The second part follows by exactly the same arguments
(replace |yj| by yj). Therefore, we omit its proof.
We ï¬nally prove (8). To this end we ï¬rst show the second part, that is, EX â‰¥0 for
X â‰¥0. If X is discrete, then X attains values in D, where D consists only of non-negative
real numbers. Hence, xjP{X = xj} â‰¥0, which implies EX â‰¥0. If X is continuous,
in view of X â‰¥0, we may choose its density p such that p(x) = 0 if x < 0. Then
EX =
# âˆ
0 p(x)dx â‰¥0.
Suppose now X â‰¤Y. Setting Z = Y â€“ X, by the ï¬rst step follows EZ â‰¥0. But, prop-
erty (3) implies EZ = EY â€“ EX, from which we derive EX â‰¤EY as asserted. Note that
by assumption EX and EY are real numbers, so that EY â€“ EX is not an undetermined
expression.
âˆ
Remark 5.1.37. Properties (4) and (5) of the previous proposition, applied with f(x) =
|x|, lead to
E|X| =
âˆ

j=1
|xj|P{X = xj}
or
E|X| =
âˆ

â€“âˆ
|x| p(x) dx ,
as we already stated in conditions (5.4) and (5.18).
Corollary 5.1.38. If EX exists, then shifting X by , = EX, it becomes centralized (the
expected value is zero).
Proof: If Y = X â€“ ,, then properties (2) and (3) of Proposition 5.1.36 imply
EY = E(X â€“ ,) = EX â€“ E, = , â€“ , = 0 ,
as asserted.
âˆ
An important consequence of (8) in Proposition 5.1.36 reads as follows.
Corollary 5.1.39. If EX exists, then
|EX| â‰¤E|X| .

218
5 Expected Value, Variance, and Covariance
Proof: For all 9 âˆˆK follows that
â€“|X(9)| â‰¤X(9) â‰¤|X(9)| ,
that is, we have â€“|X| â‰¤X â‰¤|X|. We apply now (3) and (8) of Proposition 5.1.36 and
conclude that
â€“ E|X| = E(â€“|X|) â‰¤EX â‰¤E|X| .
(5.23)
Since |a| â‰¤c for a, c âˆˆR is equivalent to â€“c â‰¤a â‰¤c, the desired estimate is a
consequence of inequalities (5.23) with a = EX and c = E|X|.
âˆ
We now present some examples that show how Proposition 5.1.36 may be used to
evaluate certain expected values.
Example 5.1.40. Suppose we roll n fair dice. Let Sn be the sum of the observed values.
What is the expected value of Sn ?
Answer: If Xj denotes the value of die j, then X1, . . . , Xn are uniformly distributed
on {1, . . . , 6} with EXj = 7/2 and, moreover, Sn = X1 + â‹…â‹…â‹…+ Xn. Thus, property (3) lets
us conclude that
ESn = E(X1 + â‹…â‹…â‹…+ Xn) = EX1 + â‹…â‹…â‹…+ EXn = 7n
2 .
Example 5.1.41. In Example 4.1.7 we investigated the random walk of a particle on Z.
Each time it jumped with probability p either one step to the right or with probability
1 â€“ p one step to the left. Sn denoted the position of the particle after n steps. What is
the expected position after n steps?
Answer: We proved that Sn = 2Yn â€“ n with a Bn,p-distributed random variable Yn.
Proposition 5.1.13 implies EYn = np, hence the linearity of the expected value leads to
ESn = 2 EYn â€“ n = 2np â€“ n = n(2p â€“ 1) .
For p = 1/2 we obtain the (not very surprising) result ESn = 0.
Alternative approach: If Xj is the size of jump j, then P{Xj = â€“1} = 1 â€“ p and P{Xj =
+1} = p. Hence, EXj = (â€“1)(1 â€“ p) + 1 â‹…p = 2p â€“ 1, and because of Sn = X1 + â‹…â‹…â‹…+ Xn we
get ESn = n EX1 = n(2p â€“ 1) as before.
The next example demonstrates how property (4) of Proposition 5.1.36 may be used.
Example 5.1.42. Let X be Pois+-distributed. Find EX2.
Solution: Property (4) of Proposition 5.1.36 implies
EX2 =
âˆ

k=0
k2 P{X = k} =
âˆ

k=1
k2 +k
k! eâ€“+ = +
âˆ

k=1
k
+kâ€“1
(k â€“ 1)! eâ€“+ .

5.1 Expected Value
219
We shift the index of summation in the right-hand sum by 1 and get
+
âˆ

k=0
(k + 1) +k
k! eâ€“+ = +
âˆ

k=0
k +k
k! eâ€“+ + +
âˆ

k=0
+k
k! eâ€“+ .
By Proposition 5.1.16, the ï¬rst sum coincides with +EX = +2, while the second one gives
+ Pois+(N0) = + â‹…1 = +. Adding both values leads to
EX2 = +2 + + .
The next example rests upon an application of properties (3), (4) and (6) in Proposi-
tion 5.1.36.
Example 5.1.43. Compute EX2 for X being Bn,p-distributed.
Solution: Let X1, . . . , Xn be independent B1,p-distributed random variables. Then
Corollary 4.6.2 asserts that X = X1 + â‹…â‹…â‹…+ Xn is Bn,p-distributed. Therefore, it sufï¬ces
to evaluate EX2 with X = X1 + â‹…â‹…â‹…+ Xn. Thus, property (3) of Proposition 5.1.36 implies
EX2 = E(X1 + â‹…â‹…â‹…+ Xn)2 =
n

i=1
n

j=1
EXiXj .
If i /= j, then Xi and Xj are independent, hence property (6) applies and yields
EXiXj = EXi â‹…EXj = p â‹…p = p2 .
For i = j, property (4) gives
EX2
j = 02 â‹…P{Xj = 0} + 12 â‹…P{Xj = 1} = p .
Combining both cases leads to
EX2 =

i/=j
EXi â‹…EXj +
n

j=1
EX2
j = n(n â€“ 1) p2 + n p = n2 p2 + n p(1 â€“ p) .
Example 5.1.44. Let X be Gp-distributed. Compute EX2.
Solution: We claim that
EX2 = 2 â€“ p
p2
.
(5.24)
To prove this, let us start with
EX2 =
âˆ

k=1
k2 P{X = k} = p
âˆ

k=1
k2(1 â€“ p)kâ€“1 .
(5.25)

220
5 Expected Value, Variance, and Covariance
We evaluate the right-hand sum by the following approach. If |x| < 1, then
1
1 â€“ x =
âˆ

k=0
xk .
Differentiating both sides of this equation leads to
1
(1 â€“ x)2 =
âˆ

k=1
k xkâ€“1 .
Next we multiply this equation by x and arrive at
x
(1 â€“ x)2 =
âˆ

k=1
k xk .
Another time differentiating of both functions on {x âˆˆR : |x| < 1} implies
1
(1 â€“ x)2 +
2x
(1 â€“ x)3 =
âˆ

k=1
k2xkâ€“1 .
If we use the last equation with x = 1 â€“ p, then by eq. (5.25)
EX2 = p

1
(1 â€“ (1 â€“ p))2 +
2(1 â€“ p)
(1 â€“ (1 â€“ p))3

= 2 â€“ p
p2
,
as we claimed in eq. (5.24).
In the next example we us property (5) of Proposition 5.1.36.
Example 5.1.45. Let U be uniformly distributed on [0, 1]. Which expected value does
âˆš
U possess?
Solution: By property (5) it follows that
E
âˆš
U =
1

0
âˆš
x p(x) dx =
1

0
âˆš
x dx = 2
3

x3/21
0 = 2
3 .
Here p = 1[0,1] denotes the distribution density of U.

5.1 Expected Value
221
Another approach is as follows. Because of
Fâˆš
U(t) = P{
âˆš
U â‰¤t} = P{U â‰¤t2} = t2
for 0 â‰¤t â‰¤1, the density q of
âˆš
U is given by q(x) = 2x, 0 â‰¤x â‰¤1, and q(x) = 0,
otherwise. Thus,
E
âˆš
U =
1

0
x 2x dx = 2
x3
3
1
0
= 2
3 .
Let us present now an interesting example called Coupon collectorâ€™s problem. It was
ï¬rst mentioned in 1708 by A. De Moivre. We formulate it in a present-day version.
Example 5.1.46. A company produces cornï¬‚akes. Each pack contains a picture. We
assume that there are n different pictures and that they are equally likely. That is,
when buying a pack, the probability to get a certain ï¬xed picture is 1/n. How many
packs of cornï¬‚akes have to be bought on the average before one gets all possible n
pictures?
An equivalent formulation of the problem is as follows. In an urn are n balls
numbered from 1 to n. One chooses balls out of the urn with replacement. How many
balls have to be chosen on average before one observes all n numbers?
Answer: Assume we already have k different pictures for some k = 0, 1, . . . , n â€“ 1.
Let Xk be the number of necessary purchases to obtain a new picture, that is, to get
one which we do not have. Since each pack contains a picture,
P{X0 = 1} = 1 .
If k â‰¥1, then there are still n â€“ k pictures that one does not possess. Hence, Xk is
geometric distributed with success probability pk = (n â€“ k)/n. If Sn = X0 + â‹…â‹…â‹…+ Xnâ€“1,
then Sn is the totality of necessary purchases. By Corollary 5.1.20 we obtain
EXk = 1
pk
=
n
n â€“ k ,
k = 0, . . . , n â€“ 1 .
Note that EX0 = 1, thus the previous formula also holds in this case. Then the linearity
of the expected value implies
ESn = 1 + EX1 + â‹…â‹…â‹…+ EXnâ€“1 = 1 + 1
p1
+ â‹…â‹…â‹…+
1
pnâ€“1
= 1 +
n
n â€“ 1 +
n
n â€“ 2 + â‹…â‹…â‹…+ n
1 = n
n

k=1
1
k .

222
5 Expected Value, Variance, and Covariance
Consequently, on average, one needs n n
k=1
1
k purchases to obtain a complete collec-
tion of all pictures.
For example, if n = 50, on average, we have to buy 225 packs, if n = 100, then 519,
for n = 200, on average, there are 1176 purchases necessary, if n = 300, then 1885, if
n = 400 we have to buy 2628 packs, and, ï¬nally, if n = 500 we need to buy 3397 ones.
Remark 5.1.47. As n â†’âˆ, the harmonic series n
k=1
1
k behaves like ln n. More
precisely (cf. [Lag13] or [Spi08], Problem 12, Chapter 22)
lim
nâ†’âˆ
) n

k=1
1
k â€“ ln n
*
= # ,
(5.26)
where # denotes Eulerâ€™s constant, which is approximately 0.57721. Therefore, for
large n, the average number of necessary purchases is approximately n [ln n + #]. For
example, if n = 300, then the approximative value is 1884.29, leading also to 1885
necessary purchases.
5.2 Variance
5.2.1 Higher Moments of Random Variables
Deï¬nition 5.2.1. Let n â‰¥1 be some integer. A random variable X possesses an
nth moment, provided that E|X|n < âˆ. We also say X has a ï¬nite absolute nth
moment. If this is so, then EXn exists, and it is called nth moment of X.
Remark 5.2.2. Because of |X|n = |Xn|, the assumption E|X|n < âˆimplies the existence
of the nth moment EXn.
Note that a random variable X has a ï¬rst moment if and only if the expected value
of X exists, cf. conditions (5.4) and (5.18). Moreover, then the ï¬rst moment coincides
with EX.
Proposition 5.2.3. Let X be either a discrete random variable with values in {x1, x2, . . . }
and with pj = P{X = xj}, or let X be continuous with density p. If n â‰¥1, then
E|X|n =
âˆ

j=1
|xj|n â‹…pj
or
E|X|n =
âˆ

â€“âˆ
|x|n p(x) dx .
(5.27)

5.2 Variance
223
Consequently, X possesses a ï¬nite absolute nth moment if and only if either the sum or
the integral in eq. (5.27) are ï¬nite. If this is satisï¬ed, then
EXn =
âˆ

j=1
xn
j â‹…pj
or
EXn =
âˆ

â€“âˆ
xn p(x) dx .
Proof: Apply properties (4) and (5) in Proposition 5.1.36 with f(x) = |x|n or f(x) = xn,
respectively.
âˆ
Example 5.2.4. Let U be uniformly distributed on [0, 1]. Then
E|U|n = E Un =
1

0
xn dx =
1
n + 1 .
For the subsequent investigations, we need the following elementary lemma.
Lemma 5.2.5. If 0 < ! < ", then for all x â‰¥0
x! â‰¤x" + 1 .
Proof: If 0 â‰¤x â‰¤1, by x" â‰¥0 follows that
x! â‰¤1 â‰¤x" + 1 ,
and the inequality is valid.
If x > 1, then ! < " implies x! < x", hence also for those x we arrive at
x! < x" â‰¤x" + 1 ,
which proves the lemma.
âˆ
Proposition 5.2.6. Suppose a random variable X has a ï¬nite absolute nth moment.
Then X possesses all mth moments with m < n.
Proof: Suppose E|X|n < âˆand choose an m < n. For ï¬xed 9 âˆˆK we apply Lemma
5.2.5 with ! = m, " = n and x = |X(9)|. Doing so, we obtain
|X(9)|m â‰¤|X(9)|n + 1 ,
and this being true for all 9 âˆˆK implies |X|m â‰¤|X|n + 1. Hence, property (7) of
Proposition 5.1.36 yields
E|X|m â‰¤E(|X|n + 1) = E|X|n + 1 < âˆ.

224
5 Expected Value, Variance, and Covariance
Consequently, as asserted, X possesses also an absolute mth moment.
Remark 5.2.7. There exist much stronger estimates between different absolute mo-
ments of X. For example, HÃ¶lderâ€™s inequality asserts that for any 0 < ! â‰¤"

E|X|!1/! â‰¤

E|X|"1/"
.
âˆ
The case n = 2 and m = 1 in Proposition 5.2.6 is of special interest. Here we get the
following useful result.
Corollary 5.2.8. If X possesses a ï¬nite second moment, then E|X| < âˆ, that is, its
expected value exists.
Let us state another important consequence of Proposition 5.2.6.
Corollary 5.2.9. Suppose X has a ï¬nite absolute nth moment. Then for any b âˆˆR we
also have E |X + b|n < âˆ.
Proof: An application of the binomial theorem (Proposition A.3.7) implies
|X + b|n â‰¤(|X| + |b|)n =
n

k=0
n
k

|X|k |b|nâ€“k .
Hence, using properties (3) and (7) of Proposition 5.1.36, we obtain
E|X + b|n â‰¤
n

k=0
n
k

|b|nâ€“k E|X|k < âˆ.
Note that Proposition 5.2.6 implies E|X|k < âˆfor all k < n. This ends the proof.
âˆ
Example 5.2.10. Let X be A!,"-distributed with parameters !, " > 0. Which moments
does X possess, and how can they be computed?
Answer: In view of X â‰¥0 it sufï¬ces to investigate EXn. For all n â‰¥1 it follows that
EXn =
1
!"A(")
âˆ

0
xn+"â€“1 eâ€“x/! dx =
!n+"
!"A(")
âˆ

0
yn+"â€“1 eâ€“y dy
= !n A(" + n)
A(")
= !n (" + n â€“ 1)(" + n â€“ 2) â‹…â‹…â‹…(" + 1)" .
In particular, X has moments of any order n â‰¥1.

5.2 Variance
225
In the case of an E+-distributed random variable X we have ! = 1/+ and " = 1,
hence
EXn = n!
+n .
Example 5.2.11. Suppose a random variable is tn-distributed. Which moments does X
possess?
Answer: We already know that a t1-distributed random variable does not pos-
sess a ï¬rst moment. Recall that X is t1-distributed if it is Cauchy distributed. And in
Proposition 5.1.33 we proved E|X| = âˆfor Cauchy distributed random variables.
But what can be said if n â‰¥2 ?
According to Deï¬nition 4.7.6, the random variable X has the density p with
p(x) =
A
 n+1
2

âˆšn 0 A
 n
2


1 + x2
n
â€“n/2 â€“1/2
,
x âˆˆR .
If m âˆˆN, then
E|X|m =
A
 n+1
2

âˆšn 0 A
 n
2

âˆ

â€“âˆ
|x|m

1 + x2
n
â€“n/2 â€“1/2
dx .
Hence, X has an mth moment, if and only if the integral
âˆ

â€“âˆ
|x|m

1 + x2
n
â€“n/2 â€“1/2
dx = 2
âˆ

0
xm

1 + x2
n
â€“n/2 â€“1/2
dx
(5.28)
is ï¬nite. Note that
lim
xâ†’âˆxn+1

1 + x2
n
â€“n/2 â€“1/2
= lim
xâ†’âˆ

xâ€“2 + 1
n
â€“n/2 â€“1/2
= nn/2+1/2 ,
thus, there are constants 0 < c1 < c2 (depending on n, but not on x) such that
c1
xnâ€“m+1 â‰¤xm

1 + x2
n
â€“n/2 â€“1/2
â‰¤
c2
xnâ€“m+1
(5.29)
for large x, that is, if x > x0 for a suitable x0 âˆˆR.
Recall that
# âˆ
1
xâ€“! dx < âˆif and only if ! > 1. Having this in mind, in view of
eq. (5.28) and by the estimates in (5.29) we get E|X|m < âˆif and only if n â€“ m + 1 > 1,
that is, if and only if m < n.
Summing up, a tn-distributed random variable has moments of order 1, . . . , n â€“ 1,
but no moments of order greater than or equal n.

226
5 Expected Value, Variance, and Covariance
Finally, let us investigate the moments of normally distributed random variables.
Example 5.2.12. How do we calculate EXn for an N(0, 1)-distributed random vari-
able?
Answer: Well-known properties of the exponential function imply
E|X|n =
1
âˆš
20
âˆ

â€“âˆ
|x|n eâ€“x2/2 dx =
2
âˆš
20
âˆ

0
xn eâ€“x2/2 dx < âˆ
for all n âˆˆN. Thus, a normally distributed random variable possesses moments of any
order. These moments are evaluated by
EXn =
âˆ

â€“âˆ
xn p0,1(x) dx =
1
âˆš
20
âˆ

â€“âˆ
xn eâ€“x2/2 dx .
If n is an odd integer, then x â†¦xn eâ€“x2/2 is an odd function, hence EXn = 0 for these n.
Therefore, it sufï¬ces to investigate even n = 2m with m âˆˆN. Here we get
EX2m = 2 â‹…
1
âˆš
20
âˆ

0
x2m eâ€“x2/2 dx ,
which, by the change of variables y := x2/2, thus x = âˆš2y with dx =
1
âˆš
2 yâ€“1/2 dy,
transforms into
EX2m =
1
âˆš0 2m
âˆ

0
ymâ€“1/2 eâ€“y dy = 2m
âˆš0 A

m + 1
2

.
By A(1/2) = âˆš0 and an application of eq. (1.48) we ï¬nally obtain
EX2m = 2m
âˆš0 A

m + 1
2

= 2m
âˆš0

m â€“ 1
2

A

m â€“ 1
2

= 2m
âˆš0

m â€“ 1
2
 
m â€“ 3
2

A

m â€“ 3
2

= 2mA(1/2) â‹…1/2 â‹…3/2 â‹…â‹…â‹…(m â€“ 1/2)
âˆš0
= (2m â€“ 1)(2m â€“ 3) â‹…â‹…â‹…3 â‹…1 := (2m â€“ 1)!! .
5.2.2 Variance of Random Variables
Let X be a random variable with ï¬nite second moment. As we saw in Corollary 5.2.8,
then its expected value , := EX exists. Furthermore, letting b = â€“,, by Corollary 5.2.9,

5.2 Variance
227
we also have E|X â€“ ,|2 < âˆ. After this preparation we can introduce the variance of a
random variable.
Deï¬nition 5.2.13. Let X be a random variable possessing a ï¬nite second moment.
If , := EX, then its variance is deï¬ned as
VX := E|X â€“ ,|2 = E|X â€“ EX|2 .
Interpretation: The expected value , of a random variable is its main characteristic.
It tells us around which value the observations of X have to be expected. But it does
not tell us how far away from , these observations will be on average. Are they con-
centrated around , or are they widely dispersed? This behavior is described by the
variance. It is deï¬ned as the average quadratic distance of X to its mean value. If VX is
small, then we will observe realizations of X quite near to its mean. Otherwise, if VX
is large, then it is very likely to observe values of X far away from its expected value.
How do we evaluate the variance in concrete cases? We answer this question for
discrete and continuous random variables separately.
Proposition 5.2.14. Let X be a random variable with ï¬nite second moment and let , âˆˆR
be its expected value. Then it follows that
VX =
âˆ

j=1
(xj â€“ ,)2 â‹…pj
and
VX =
âˆ

â€“âˆ
(x â€“ ,)2 p(x) dx
(5.30)
in the discrete and continuous case, respectively. Hereby, x1, x2, . . . are the possible val-
ues of X and pj = P{X = xj} in the discrete case, while p denotes the density of X in the
continuous case.
Proof: The assertion follows directly by an application of properties (4) and (5) of
Proposition 5.1.36 to f(x) = (x â€“ ,)2.
âˆ
Before we present concrete examples, let us state and prove certain properties of the
variance, which will simplify the calculations later on.
Proposition 5.2.15. Assume X and Y are random variables with ï¬nite second moment.
Then the following are valid.
(i)
We have
VX = EX2 â€“ (EX)2 .
(5.31)

228
5 Expected Value, Variance, and Covariance
(ii)
If P{X = c} = 1 for some c âˆˆR, then5 VX = 0.
(iii)
For a, b âˆˆR follows that
V(a X + b) = a2 VX .
(iv)
In the case of independent X and Y one has
V(X + Y) = VX + VY .
Proof: Let us begin with the proof of (i). With , = EX we obtain
VX = E(X â€“ ,)2 = E

X2 â€“ 2,X + ,2
= EX2 â€“ 2,EX + ,2
= EX2 â€“ 2,2 + ,2 = EX2 â€“ ,2 .
This proves (i).
To verify (ii) we use property (2) in Proposition 5.1.36. Then , = EX = c , hence
P{X â€“ , = 0} = 1. Another application of property (2) leads to
VX = E(X â€“ ,)2 = 0
as asserted.
Next we prove (iii). If a, b âˆˆR, then E(aX + b) = aEX + b by the linearity of the
expected value. Consequently,
V(aX + b) = E

aX + b â€“ (aEX + b)
2 = a2 E(X â€“ EX)2 = a2 VX .
Thus (iii) is valid.
To prove (iv) observe that, if , := EX and - := EY, then E(X +Y) = ,+-, and hence
V(X + Y) = E

(X â€“ ,) + (Y â€“ -)
2
= E(X â€“ ,)2 + 2 E[(X â€“ ,)(Y â€“ -)] + E(Y â€“ -)2
= VX + 2 E[(X â€“ ,)(Y â€“ -)] + VY .
(5.32)
By Proposition 4.1.9 the independence of X and Y implies that of X â€“ , and Y â€“ -.
Therefore, from property (6) in Proposition 5.1.36 we derive
E[(X â€“ ,)(Y â€“ -)] = E(X â€“ ,) â‹…E(Y â€“ -) = (EX â€“ ,) â‹…(EY â€“ -) = 0 â‹…0 = 0 .
Plugging this into eq. (5.32) completes the proof of (iv).
âˆ
5 The converse implication is also true. If VX = 0, then X is constant with probability 1.

5.2 Variance
229
5.2.3 Variance of Certain Random Variables
Our ï¬rst objective is to describe the variance of a random variable uniformly distrib-
uted on a ï¬nite set.
Proposition 5.2.16. If X is uniformly distributed on {x1, . . . , xN}, then
VX = 1
N
N

j=1
(xj â€“ ,)2 ,
where , is given by , = 1
N
N
j=1 xj .
Proof: Because of pj = 1
N , 1 â‰¤j â‰¤N, this is a direct consequence of eq. (5.30). Recall
that , was computed in eq. (5.6).
âˆ
Example 5.2.17. Suppose X is uniformly distributed on {1, . . . , 6}. Then EX = 7/2, and
we get
VX =

1 â€“ 7
2
2 +

2 â€“ 7
2
2 +

3 â€“ 7
2
2 +

4 â€“ 7
2
2 +

5 â€“ 7
2
2 +

6 â€“ 7
2
2
6
=
25
4 + 9
4 + 1
4 + 1
4 + 9
4 + 25
4
6
= 35
12 .
Thus, when rolling a die once, the variance is given by 35
12 .
Now assume that we roll the die n times. Let X1, . . . , Xn be the results of the single
rolls. The Xjs are independent, hence, if Sn = X1 + â‹…â‹…â‹…+ Xn denotes the sum of the n
trials, then by (iv) in Proposition 5.2.15 it follows that
VSn = V(X1 + â‹…â‹…â‹…+ Xn) = VX1 + â‹…â‹…â‹…VXn = 35 n
12 .
The next proposition examines the variance of binomial distributed random variables.
Proposition 5.2.18. If X is Bn,p-distributed, then
VX = np(1 â€“ p) .
(5.33)
Proof: Let X be Bn,p-distributed. In Example 5.1.44 we found EX2 = n2p2 + np (1 â€“ p).
Moreover, EX = np by Proposition 5.1.13. Thus, from formula (5.31) we derive
VX = EX2 â€“ (EX)2 = n2p2 + np(1 â€“ p) â€“ (np)2 = np(1 â€“ p)
as asserted.
âˆ

230
5 Expected Value, Variance, and Covariance
Corollary 5.2.19. Binomial distributed random variables have maximal variance (with
n ï¬xed) if p = 1/2.
Proof: The function p â†¦np(1 â€“ p) becomes maximal for p = 1
2. In the extreme cases
p = 0 and p = 1 the variance is zero.
âˆ
Next we determine the variance of Poisson distributed random variables.
Proposition 5.2.20. Let X be Pois+-distributed for some + > 0. Then
VX = + .
Proof: In Example 5.1.42 we computed EX2 = +2++. Furthermore, by Proposition 5.1.16
we know that EX = +. Thus, by eq. (5.31) we obtain, as asserted,
VX = EX2 â€“ (EX)2 = +2 + + â€“ +2 = + .
âˆ
Next, we compute the variance of a geometric distributed random variable.
Proposition 5.2.21. Let X be Gp-distributed for some 0 < p < 1. Then its variance equals
VX = 1 â€“ p
p2
.
Proof: In Example 5.1.44 we found EX2 =
2â€“p
p2 , and by eq. (5.14) we have EX = 1
p.
Consequently, formula (5.31) implies
VX = 2 â€“ p
p2
â€“
 1
p
2
= 1 â€“ p
p2
,
as asserted.
âˆ
Corollary 5.2.22. If X is Bâ€“
n,p-distributed, then
VX = n 1 â€“ p
p2
Proof: Let X1, . . . , Xn be independent Gp-distributed random variables. By Corollary
4.6.9 their sum X := X1 + â‹…â‹…â‹…+Xn is Bâ€“
n,p-distributed, hence property (iv) in Proposition
5.2.15 lets us conclude that
VX = V(X1 + â‹…â‹…â‹…+ Xn) = VX1 + â‹…â‹…â‹…+ VXn = n VX1 = n 1 â€“ p
p2
.
âˆ
Interpretation: The smaller p becomes the bigger is the variance of a geometrically or
negative binomially distributed random variable (for n ï¬xed). This is not surprising,

5.2 Variance
231
because the smaller p is, the larger is the expected value, and the values of X may be
very far from 1/p (success is very unlikely).
We consider now variances of continuous random variables. Let us begin with
uniformly distributed ones.
Proposition 5.2.23. Let X be uniformly distributed on an interval [!, "]. Then it fol-
lows that
VX = (" â€“ !)2
12
.
Proof: We know by Proposition 5.1.25 that EX = (! + ")/2. In order to apply formula
(5.31), we still have to compute the second moment EX2. Here we obtain
EX2 =
1
" â€“ !
"

!
x2 dx = 1
3 â‹…"3 â€“ !3
" â€“ ! = "2 + !" + !2
3
.
Consequently, formula (5.31) lets us conclude that
VX = EX2 â€“ (EX)2 = "2 + !" + !2
3
â€“
! + "
2
2
= "2 + !" + !2
3
â€“ !2 + 2!" + "2
4
= !2 â€“ 2!" + "2
12
= (" â€“ !)2
12
.
This completes the proof.
âˆ
In the case of gamma distributed random variables, the following is valid.
Proposition 5.2.24. If X is A!,"-distributed, then
VX = !2" .
Proof: Recall that EX = !" by Proposition 5.1.26. Furthermore, in Example 5.2.10 we
evaluated EXn for a gamma distributed X. Taking n = 2 implies
EX2 = !2 (" + 1) " ,
and, hence, by eq. (5.31),
VX = EX2 â€“ (EX)2 = !2 (" + 1) " â€“ (!")2 = !2"
as asserted.
âˆ

232
5 Expected Value, Variance, and Covariance
Corollary 5.2.25. If X is E+-distributed, then
VX = 1
+2 .
Proof: Because of E+ = A 1
+ ,1, this directly follows from Proposition 5.2.24.
âˆ
Corollary 5.2.26. For a 72
n-distributed X holds
VX = 2n .
Proof: Let us give two alternative proofs of the assertion. The ï¬rst one uses Proposi-
tion 5.2.24 and 72
n = A2, n
2 .
The second proof is longer, but maybe more interesting. Let X1, . . . , Xn be
independent N(0, 1)-distributed random variables. Proposition 4.6.17 implies that
X2
1+ â‹…â‹…â‹…+X2
n is 72
n-distributed, thus property (iv) of Proposition 5.2.15 applies and leads
to
VX = VX2
1 + â‹…â‹…â‹…+ VX2
n = nVX2
1 .
In Example 5.2.12 we evaluated the moments of an N(0, 1)-distributed random vari-
able. In particular, EX2
1 = 1 and, E(X2
1)2 = EX4
1 = 3!! = 3, hence
VX = n VX2
1 = n (EX4
1 â€“ (EX2
1)2) = (3 â€“ 1)n = 2n
as claimed.
âˆ
Finally we determine the variance of a normal random variable.
Proposition 5.2.27. If X is N(,, 32)-distributed, then it follows that
VX = 32 .
Proof: Of course, this could be proven by computing the integral
VX =
âˆ

â€“âˆ
(x â€“ ,)2p,,3(x)dx .
We prefer a different approach that avoids the calculation of integrals. Because of Pro-
position 4.2.3, the random variable X may be represented as X = 3X0 +, for a standard
normal X0. Applying (iii) in Proposition 5.2.15 gives
VX = 32 VX0 .
(5.34)

5.3 Covariance and Correlation
233
But EX0 = 0, and by Example 5.2.12 we have EX2
0 = 1, thus
VX0 = 1 â€“ 0 = 1 .
Plugging this into eq. (5.34) proves VX = 32.
âˆ
Remark 5.2.28. The previous result explains why the parameter 32 of an N(,, 32)-
distribution is called â€œvariance.â€
5.3 Covariance and Correlation
5.3.1 Covariance
Suppose we know or we conjecture that two given random variables X and Y are
dependent. The aim of this section is to introduce a quantity that measures their de-
gree of dependence. Such a quantity should tell us whether the random variables are
strongly or only weakly dependent. Furthermore, we want to know what kind of de-
pendence we observe. Do larger values of X trigger larger values of Y or is it the other
way round? To illustrate these questions let us come back to the experiment presented
in Example 2.2.5.
Example 5.3.1. In an urn are n balls labeled with â€œ0â€ and another n balls labeled with
â€œ1.â€ Choose two balls out of the urn without replacement Let X be the number appear-
ing on the ï¬rst ball and Y that on the second. Then X and Y are dependent (check this),
but it is intuitively clear that if n becomes larger, then their dependence diminishes.
We ask for a quantity that tells us their degree of dependence. This measure should
decrease as n increases and it should tend to zero as n â†’âˆ.
Moreover, if X = 1 occurred, then there remained in the urn more balls with â€œ0â€
than with â€œ1,â€ and the probability of the event {Y = 0} increases. Thus, larger values
of X make smaller values of Y more likely.
Before we are able to introduce such a â€œmeasure of dependence,â€ we need some
preparation.
Proposition 5.3.2. If two random variables X and Y possess a ï¬nite second moment,
then the expected value of their product X Y exists.
Proof: We use the elementary estimate |ab| â‰¤a2+b2
2
valid for a, b âˆˆR. Thus, if 9 âˆˆ
K, then
|X(9)Y(9)| â‰¤X(9)2
2
+ Y(9)2
2
,

234
5 Expected Value, Variance, and Covariance
that is, we have
|XY| â‰¤X2
2 + Y2
2 .
(5.35)
By assumption
E
X2
2 + Y2
2

= 1
2

EX2 + EY2
< âˆ,
consequently, because of estimate (5.35), property (7) in Proposition 5.1.36 applies and
tells us that E|XY| < âˆ. Thus, E[XY] exists as asserted.
âˆ
How do we compute E[XY] for given X and Y ? In Section 4.5 we observed that the
distribution of X + Y does not only depend on the distributions of X and Y. We have
to know their joint distribution, that is, the distribution of the vector (X, Y). And the
same is true for products and the expected value of the product.
Example 5.3.3. Let us again investigate the random variables X, Y, Xâ€², and Yâ€² intro-
duced in Example 3.5.8. Recall that they satisï¬ed
P{X = 0, Y = 0} = 1
6 ,
P{X = 0, Y = 1} = 1
3 ,
P{X = 1, Y = 0} = 1
3 ,
P{X = 1, Y = 1} = 1
6 ,
P{Xâ€² = 0, Yâ€² = 0} = 1
4 ,
P{Xâ€² = 0, Yâ€² = 1} = 1
4 ,
P{Xâ€² = 1, Yâ€² = 0} = 1
4 ,
P{Xâ€² = 1, Yâ€² = 1} = 1
4
Then PX = PXâ€² as well as PY = PYâ€², but
E[XY] = 1
6 (0 â‹…0) + 1
3 (1 â‹…0) + 1
3 (0 â‹…1) + 1
6 (1 â‹…1) = 1
6
and
E[Xâ€²Yâ€²] = 1
4 (0 â‹…0) + 1
4 (1 â‹…0) + 1
4 (0 â‹…1) + 1
4 (1 â‹…1) = 1
4 .
This example tells us that we have to know the joint distribution in order to compute
E[XY]. The knowledge of the marginal distributions does not sufï¬ce.
To evaluate E[XY] we need the following two-dimensional generalization of formulas
(5.21) and (5.22).
Proposition 5.3.4. Let X and Y be two random variables and let f : R2 â†’R be some
function.

5.3 Covariance and Correlation
235
1.
Suppose X and Y are discrete with values in {x1, x2, . . . } and in {y1, y2, . . . }. Set pij =
P{X = xi, Y = yj}. If
E|f(X, Y)| =
âˆ

i,j=1
|f(xi, yj)| pij < âˆ,
(5.36)
then Ef(X, Y) exists and can be computed by
Ef(X, Y) =
âˆ

i,j=1
f(xi, yj) pij .
2.
Let f : R2 â†’R be continuous6. If p : R2 â†’R is the joint density of (X, Y) (recall
Deï¬nition 3.5.15), then
E|f(X, Y)| =
âˆ

â€“âˆ
âˆ

â€“âˆ
|f(x, y)| p(x, y) dxdy < âˆ
(5.37)
implies the existence of Ef(X, Y), which can be evaluated by
Ef(X, Y) =
âˆ

â€“âˆ
âˆ

â€“âˆ
f(x, y) p(x, y) dxdy .
(5.38)
Remark 5.3.5. The previous formulas extend easily to higher dimensions. That is, if
âƒ—X = (X1, . . . , Xn) is an n-dimensional random vector with (joint) distribution density
p : Rn â†’R, then for continuous7 f : Rn â†’R one has
Ef(âƒ—X) = Ef(X1, . . . , Xn) =

Rn f(x1, . . . , xn) p(x1, . . . , xn) dxn â‹…â‹…â‹…dx1
provided the integral exists. The case of discrete X1, . . . , Xn is treated in a similar way.
If âƒ—X maps into the ï¬nite or uncountably inï¬nite set D âŠ‚Rn, then
Ef(âƒ—X) = Ef(X1, . . . , Xn) =

xâˆˆD
f(x)P{âƒ—X = x} .
6 In fact we need only a measurability in the sense of 4.1.1, but this time for functions f from R2 to R.
For our purposes â€œcontinuityâ€ of f sufï¬ces.
7 cf. the remark for n = 2.

236
5 Expected Value, Variance, and Covariance
If we apply Proposition 5.3.4 with f : (x, y) â†¦x â‹…y, then we obtain the following formu-
las for the evaluation of E[XY]. Hereby, we assume that conditions (5.36) or (5.37) are
satisï¬ed.
Corollary 5.3.6. In the notation of Proposition 5.3.4 the following are valid:
E[XY] =
âˆ

i,j=1
(xi â‹…yj)pij
and
E[XY] =
âˆ

â€“âˆ
âˆ

â€“âˆ
(x â‹…y) p(x, y) dxdy
in the discrete and in the continuous case, respectively.
After all these preparations we are now in position to introduce the covariance of two
random variables.
Deï¬nition 5.3.7. Let X and Y be two random variables with ï¬nite second mo-
ments. Setting , = EX and - = EY, the covariance of X and Y is deï¬ned as
Cov(X, Y) = E[(X â€“ ,)(Y â€“ -)] .
Remark 5.3.8. Apply Corollary 5.2.9 and Proposition 5.3.2 to see that the covariance is
well-deï¬ned for random variables with ï¬nite second moment. Furthermore, in view of
Proposition 5.3.4, the covariance may be computed as
Cov(X, Y) =
âˆ

i,j=1
(xi â€“ ,)(yj â€“ -) pij
in the discrete case (recall that pij = P{X = xi, Y = yj}), and as
Cov(X, Y) =
âˆ

â€“âˆ
âˆ

â€“âˆ
(x â€“ ,) (y â€“ -) p(x, y) dxdy
in the continuous one.
Example 5.3.9. Let us once more consider the random variables X, Y, Xâ€², and Yâ€² in
Example 3.5.8 or Example 5.3.3, respectively. Each of the four random variables has
the expected value 1/2. Therefore, we obtain
Cov(X, Y) = 1
6

0 â€“ 1
2

â‹…

0 â€“ 1
2

+ 1
3

1 â€“ 1
2

â‹…

0 â€“ 1
2

+ 1
3

0 â€“ 1
2

â‹…

1 â€“ 1
2

+ 1
6

1 â€“ 1
2

â‹…

1 â€“ 1
2

= â€“ 1
12 ,

5.3 Covariance and Correlation
237
while
Cov(Xâ€², Yâ€²) = 1
4

0 â€“ 1
2

â‹…

0 â€“ 1
2

+ 1
4

1 â€“ 1
2

â‹…

0 â€“ 1
2

+ 1
4

0 â€“ 1
2

â‹…

1 â€“ 1
2

+ 1
4

1 â€“ 1
2

â‹…

1 â€“ 1
2

= 0 .
The following proposition summarizes the main properties of the covariance.
Proposition 5.3.10. Let X and Y be random variables with ï¬nite second moments. Then
the following are valid.
(1)
Cov(X, Y) = Cov(Y, X) .
(2)
Cov(X, X) = VX .
(3)
The covariance is bilinear, that is, for X1, X2 and real numbers a1 and a2
Cov(a1X1 + a2X2, Y) = a1Cov(X1, Y) + a2Cov(X2, Y)
and, analogously,
Cov(X, b1Y1 + b2Y2) = b1Cov(X, Y1) + b2Cov(X, Y2)
for random variables Y1, Y2 and real numbers b1, b2.
(4)
The covariance may also evaluated by
Cov(X, Y) = E[XY] â€“ (EX)(EY) .
(5.39)
(5)
Cov(X, Y) = 0 for independent X and Y.
Proof: Properties (1) and (2) follow directly from the deï¬nition of the covariance.
Let us verify (3). Setting ,1 = EX1 and ,2 = EX2, the linearity of the expected value
implies
E(a1X1 + a2X2) = a1,1 + a2,2 .
Hence, if - = EY, then
Cov(a1X1 + a2X2, Y) = E

a1(X1 â€“ ,1) + a2(X2 â€“ ,2)

(Y â€“ -)

= a1E

(X1 â€“ ,1)(Y â€“ -)

+ a2E

(X2 â€“ ,2)(Y â€“ -)

= a1Cov(X1, Y) + a2Cov(X2, Y) .
This proves the ï¬rst part of (3). The second part can be proven in the same way or one
uses Cov(X, Y) = Cov(Y, X) and the ï¬rst part of (3).

238
5 Expected Value, Variance, and Covariance
Next we prove eq. (5.39). With , = EX and - = EY by
(X â€“ ,)(Y â€“ -) = XY â€“ ,Y â€“ -X + ,- ,
we get that
Cov(X, Y) = E [XY â€“ ,Y â€“ -X + ,-] = E[XY] â€“ ,EY â€“ -EX + ,-
= E[XY] â€“ ,- .
This proves (4) by the deï¬nition of , and -.
Finally, we verify (5). If X and Y are independent, then by Proposition 4.1.9 this
is also true for X â€“ , and Y â€“ -. Thus, property (6) of Proposition 5.1.36 applies and
leads to
Cov(X, Y) = E

(X â€“ ,)(Y â€“ -)

= E(X â€“ ,) E(Y â€“ -) = [EX â€“ ,] [EY â€“ -] = 0 .
Therefore, the proof is completed.
âˆ
Remark 5.3.11. Quite often the computation of Cov(X, Y) can be simpliï¬ed by the use
of eq. (5.39). For example, consider X and Y in Example 3.5.8. In Example 5.3.3 we
found E[XY] = 1/6. Since EX = EY = 1/2, by eq. (5.39) we immediately get
Cov(X, Y) = 1
6 â€“ 1
4 = â€“ 1
12 .
We obtained the same result in Example 5.3.9 with slightly more efforts.
Property (5) in Proposition 5.3.10 is of special interest. It asserts Cov(X, Y) = 0 for inde-
pendent X and Y. One may ask now whether this characterizes independent random
variables. More precisely, are the random variables X and Y independent if and only if
Cov(X, Y) = 0 ?
The answer is negative as the next example shows.
Example 5.3.12. The joint distribution of X and Y is given by the following table:
Y\X
â€“1
0
1
â€“1
1
10
1
10
1
10
3
10
0
1
10
2
10
1
10
2
5
1
1
10
1
10
1
10
3
10
3
10
2
5
3
10
Of course, EX = EY = 0 and, moreover,
E[XY] = 1
10

(â€“1)(â€“1) + (â€“1)(+1) + (+1)(â€“1) + (+1)(+1)

= 0 ,

5.3 Covariance and Correlation
239
which by eq. (5.39) implies Cov(X, Y) = 0. On the other hand, Proposition 3.6.9
tells us that X and Y are not independent. For example, P{X = 0, Y = 0} = 1
5 while
P{X = 0}P{Y = 0} = 4
25.
Example 5.3.12 shows that Cov(X, Y) = 0 is in general weaker than the independence
of X and Y. Therefore, the following deï¬nition makes sense.
Deï¬nition 5.3.13. Two random variables X and Y satisfying Cov(X, Y) = 0 are said
to be uncorrelated. Otherwise, if Cov(X, Y) /= 0, then X and Y are correlated.
More generally, a sequence X1, . . . , Xn of random variables is called (pair-
wise) uncorrelated, if Cov(Xi, Xj) = 0 whenever i /= j.
Using this notation, property (5) in Proposition 5.3.10 may now be formulated in the
following way:
X and Y independent
â‡’
/
â‡
X and Y uncorrelated
Example 5.3.14. Let A, B âˆˆA be two events in a probability space (K, A, P) and let
1A and 1B be their indicator functions as introduced in Deï¬nition 3.6.14. How can we
compute Cov(1A, 1B) ?
Answer: Since E1A = P(A), we get
Cov(1A, 1B) = E[1A 1B] â€“ (E1A)(E1B) = E1Aâˆ©B â€“ P(A) P(B)
= P(A âˆ©B) â€“ P(A) P(B) .
This tells us that 1A and 1B are uncorrelated if and only if the events A and B are
independent. But as we saw in Proposition 3.6.15, this happens if and only if the ran-
dom variables 1A and 1B are independent. In other words, two indicator functions are
independent if and only if they are uncorrelated.
Finally we consider the covariance of two continuous random variables.
Example 5.3.15. Suppose a random vector (X, Y) is uniformly distributed on the unit
ball of R2. Then the joint density of (X, Y) is given by
p(x, y) =

1
0 : x2 + y2 â‰¤1
0 : x2 + y2 > 1 .

240
5 Expected Value, Variance, and Covariance
We proved in Example 3.5.19 that X and Y possess the distribution densities
q(x) =

2
0
âˆš
1 â€“ x2 : |x| â‰¤1
0
: |x| > 1
and
r(y) =

2
0
=
1 â€“ y2 : |y| â‰¤1
0
: |y| > 1
The function y â†¦y (1 â€“ y2)1/2 is odd. Consequently, because we integrate over an
interval symmetric around the origin,
EX = EY = 2
0
1

â€“1
y (1 â€“ y2)1/2 dy = 0 .
By the same argument we obtain
E[XY] =
âˆ

â€“âˆ
âˆ

â€“âˆ
(x â‹…y) p(x, y) dx dy = 1
0
1

â€“1
y
â¡
â¢â¢â£
âˆš
1â€“y2

â€“âˆš
1â€“y2
x dx
â¤
â¥â¥â¦dy = 0 ,
and these two assertions imply Cov(X, Y) = 0. Hence, X and Y are uncorrelated, but as
we already observed in Example 3.6.19, they are not independent.
5.3.2 Correlation Coefï¬cient
The question arises whether or not the covariance is the quantity that we are looking
for, that is, which measures the degree of dependence. The answer is only partially
afï¬rmative. Why? Suppose X and Y are dependent. If a is a nonzero real number, then
a natural demand is that the degree of dependence between X and Y should be the
same as that between a X and Y. But
Cov(aX, Y) = a Cov(X, Y) ,
thus, if a /= 1, then the measure of dependence would increase or decrease. To
overcome this drawback, we normalize the covariance in the following way.
Deï¬nition 5.3.16. Let X and Y be random variables with ï¬nite second moments.
Furthermore, we assume that neither X nor Y are constant with probability 1, that
is, we have VX > 0 and VY > 0. Then the quotient
1(X, Y) :=
Cov(X, Y)
(VX)1/2(VY)1/2
(5.40)
is called correlation coefï¬cient of X and Y.

5.3 Covariance and Correlation
241
To verify a crucial property of the correlation coefï¬cient we need the following version
of the Cauchyâ€“Schwarz inequality.
Proposition 5.3.17 (Cauchyâ€“Schwarz inequality). For any two random variables X and
Y with ï¬nite second moments it follows that
|E(XY)| â‰¤

EX21/2 
EY21/2 .
(5.41)
Proof: By property (8) of Proposition 5.1.36 we have
0 â‰¤E(|X| â€“ +|Y|)2 = EX2 â€“ 2+E|XY| + +2 EY2
(5.42)
for any + âˆˆR. To proceed further, we have to assume8 EX2 > 0 and EY2 > 0. The latter
assumption allows us to choose + as
+ := (EX2)1/2
(EY2)1/2 .
If we apply inequality (5.42) with this +, then we obtain
0 â‰¤EX2 â€“ 2 (EX2)1/2
(EY2)1/2 E|XY| + EX2 = 2 EX2 â€“ 2 (EX2)1/2
(EY2)1/2 E|XY| ,
which easily implies (recall that we assumed EX2 > 0)
E|XY| â‰¤

EX21/2 
EY21/2 .
To complete the proof, we use Corollary 5.1.39 and get
|E(XY)| â‰¤E|XY| â‰¤

EX21/2 
EY21/2
as asserted.
âˆ
Corollary 5.3.18. The correlation coefï¬cient satisï¬es
â€“1 â‰¤1(X, Y) â‰¤1 .
Proof: Let as before , = EX and - = EY. Applying inequality (5.41) to X â€“ , and Y â€“ -
leads to
|Cov(X, Y)| = |E(X â€“ ,)(Y â€“ -)| â‰¤

E(X â€“ ,)21/2 
E(Y â€“ -)21/2
= (VX)1/2 (VY)1/2 ,
8 The Cauchyâ€“Schwarz inequality remains valid for EX2 = 0 or EY2 = 0. In this case follows P{X =
0} = 1 or P{Y = 0} = 1, hence P{XY = 0} = 1 and E[XY] = 0.

242
5 Expected Value, Variance, and Covariance
or, equivalently,
â€“ (VX)1/2 (VY)1/2 â‰¤Cov(X, Y) â‰¤(VX)1/2 (VY)1/2 .
By the deï¬nition of 1(X, Y) given in eq. (5.40), this implies â€“1 â‰¤1(X, Y) â‰¤1 as asserted.
âˆ
Interpretation: For uncorrelated X and Y we have 1(X, Y) = 0. In particular, this is valid
if X and Y are independent. On the contrary, 1(X, Y) /= 0 tells us that X and Y are de-
pendent. Thereby, values near to zero correspond to weak dependence, while 1(X, Y)
near to 1 or â€“1 indicate a strong dependence. The strongest possible dependence is
when Y = aX for some a /= 0. Then 1(X, Y) = 1 if a > 0 while 1(X, Y) = â€“1 for a < 0.
Deï¬nition 5.3.19. Two random variables X and Y are said to be positively cor-
related if 1(X, Y) > 0. In the case that 1(X, Y) < 0, they are said to be negatively
correlated.
Interpretation: X and Y are positively correlated, provided that larger (or smaller) val-
ues of X make larger (or smaller) values of Y more likely. This does not mean that
a larger X-value always implies a larger Y-value. Only that the probability for those
larger values increases. And in the same way, if X and Y are negatively correlated,
then larger values of X make smaller Y-values more likely. Let us explain this with
two typical examples. Choose by random a person 9 in the audience. Let X(9) be his
height and Y(9) his weight. Then X and Y will surely be positively correlated. But
this does not necessarily mean that each taller person has a bigger weight. Another
example of negatively correlated random variables could be as follows: X is the aver-
age number of cigarettes that a randomly chosen person smokes per day and Y is his
lifetime.
Example 5.3.20. Let us come back to Example 5.3.1: in an urn are n balls labeled with
â€œ0â€and n labeled with â€œ1.â€ One chooses two balls without replacement. Then X is the
value of the ï¬rst ball, Y that of the second. How does the correlation coefï¬cient of X
and Y depend on n ?
Answer: The joint distribution of X and Y is given by the following table:
Y\X
0
1
0
nâ€“1
4nâ€“2
n
4nâ€“2
1
2
1
n
4nâ€“2
nâ€“1
4nâ€“2
1
2
1
2
1
2

5.4 Problems
243
Direct computations show EX = EY = 1/2 and VX = VY = 1/4. Moreover, it easily
follows E[XY] =
nâ€“1
4nâ€“2, hence
Cov(X, Y) = n â€“ 1
4n â€“ 2 â€“ 1
4 =
â€“1
8n â€“ 4 ,
and the correlation coefï¬cient equals
1(X, Y) =
â€“1
8nâ€“4
+
1
4
+
1
4
=
â€“1
2n â€“ 1 .
If n â†’âˆ, then 1(X, Y) is of order â€“1
2n. Hence, if n is large, then the random variables X
and Y are â€œalmostâ€ uncorrelated.
Since 1(X, Y) < 0, the two random variables are negatively correlated. Why? This
was already explained in Example 5.3.1: an occurrence of X = 1 makes Y = 0 more
likely, while the occurrence of X = 0 increases the likelihood of Y = 1. Some word
about the case n = 1. Here Y is completely determined by the value of X, expressed by
1(X, Y) = â€“1.
5.4 Problems
Problem 5.1.
1.
Put successively and independently of each other n particles into N boxes.
Thereby, each box is equally likely. How many boxes remain empty on average?
Hint: Deï¬ne random variables X1, . . . , XN as follows: set Xi = 1 if box i remains
empty and Xi = 0, otherwise.
2.
Fifty persons write randomly (according to the uniform distribution), and inde-
pendently of each other, one of the 26 letters in the alphabet on a sheet of paper.
On average, how many different letters appear?
Problem 5.2. Let (K, A, P) be a probability space. Given (not necessarily disjoint)
events A1, . . . , An in A and real numbers !1, . . . , !n, deï¬ne X : K â†’R by9.
X :=
n

j=1
!j1Aj .
1.
Why is X a random variable?
2.
Prove
EX =
n

j=1
!jP(Aj)
and
VX =
n

i,j=1
!i!j

P(Ai âˆ©Aj) â€“ P(Ai)P(Aj)

.
How does VX simplify for independent events A1, . . . , An?
9 For the deï¬nition indicator functions 1Ai see eq. (3.20).

244
5 Expected Value, Variance, and Covariance
Problem 5.3. Suppose a fair â€œdieâ€ has k faces labeled by the numbers from 1 to k.
1.
How often one has to roll the die on the average before the ï¬rst â€œ1â€ shows up?
2.
Suppose one rolls the die exactly k times. Let pk be the probability that â€œ1â€ appears
exactly once and qk is the probability that â€œ1â€ shows up at least once. Compute
pk and qk and determine their behavior as k â†’âˆ, that is, ï¬nd limkâ†’âˆpk and
limkâ†’âˆqk.
Problem 5.4.
1.
Let X be a random variable with values in N0 = {0, 1, 2, . . . }. Prove that
EX =
âˆ

k=1
P{X â‰¥k} .
2.
Suppose now that X is continuous with P{X â‰¥0} = 1. Verify
âˆ

k=1
P{X â‰¥k} â‰¤EX â‰¤1 +
âˆ

k=1
P{X â‰¥k} .
Problem 5.5. Let X be an N0-valued random variable with
P{X = k} = qâ€“k,
k = 1, 2, . . .
for some q â‰¥2.
(a)
Why we have to suppose q â‰¥2, although âˆ
k=1 qâ€“k < âˆfor q > 1 ?
(b)
Determine P{X = 0} ?
(c)
Compute EX by the formula in Problem 5.4.
(d)
Compute EX directly by EX = âˆ
k=0 k P{X = k}.
Problem 5.6. Two independent random variables X and Y with third moment satisfy
EX = EY = 0. Prove that then
E(X + Y)3 = EX3 + EY3 .
Problem 5.7. A random variable X is Pois+-distributed for some + > 0. Evaluate
E

1
1 + X

and
E

X
1 + X

.
Problem 5.8. In a lottery are randomly chosen 6 of 49 numbers. Let X be the largest
number of the 6 ones. Show that
EX = 6 â‹…43!
49!
49

k=6
k(k â€“ 1)(k â€“ 2)(k â€“ 3)(k â€“ 4)(k â€“ 5) = 42.8571 .
Evaluate EX if X is the smallest number of the 6 chosen.

5.4 Problems
245
Hint: Either one modiï¬es the calculations for the maximal value suitably or one
reduces the second problem to the ï¬rst one by an easy algebraic operation.
Problem 5.9. A fair coin is labeled by â€œ0â€ on one side and with â€œ1â€ on the other one.
Toss it four times. Let X be the sum of the two ï¬rst tosses and Y be the sum of all
four ones. Determine the joint distribution of X and Y. Evaluate Cov(X, Y) as well
as 1(X, Y).
Problem 5.10. In an urn are ï¬ve balls, two labeled by â€œ0â€ and three by â€œ1.â€ Choose
two balls without replacement. Let X be the number on the ï¬rst ball and Y that on the
second.
1.
Determine the distribution of the random vector (X, Y) as well as its marginal
distributions.
2.
Compute 1(X, Y).
3.
Which distribution does X + Y possess?
Problem 5.11. Among 40 students are 30 men and 10 women. Also, 25 of the 30 men
and 8 of the 10 women passed an exam successfully. Choose randomly, according to
the uniform distribution, one of the 40 students. Let X = 0 if the chosen person is a
man, and X = 1 if it is a woman. Furthermore, set Y = 0 if the person failed the exam,
and Y = 1 if she or he passed.
1.
Find the joint distribution of X and Y.
2.
Are X and Y independent? If not, evaluate Cov(X, Y).
3.
Are X and Y negatively or positively correlated? What does it express, when X and
Y are positively or negatively correlated?
Problem 5.12. Let (K, A, P) be a probability space. Prove for any two events A and B
in A the estimate
|P(A âˆ©B) â€“ P(A) P(B)| â‰¤1
4 .
Is it possible to improve the upper bound 1
4 ?
Problem 5.13. (Problem of Luca Pacioli in 1494; the ï¬rst correct solution was found
by Blaise Pascal in 1654) Two players, say A and B, are playing a fair game consisting
of several rounds. The ï¬rst player who wins six rounds wins the game and the stakes
of 20 Taler that have been bet throughout the game. However, one day the game is
interrupted and must be stopped. If player A has won ï¬ve rounds and player B has
won three rounds, how should the stakes be divided fairly among the players?

246
5 Expected Value, Variance, and Covariance
Problem 5.14. In Example 5.1.46 we computed the average number of necessary pur-
chases to get all n pictures. Let m be an integer with 1 â‰¤m < n. How many purchases
are necessary on average to possess m of the n pictures?
For n even choose m = n/2 and for n odd take m = (n â€“ 1)/2. Let Mn be the average
number of purchases to get m pictures, that is, to get half of the pictures. Determine
lim
nâ†’âˆ
Mn
n .
Hint: Use eq. (5.26).
Problem 5.15. Compute E|X|2n+1 for a standard normal distributed X and n = 0, 1, . . . .
Problem 5.16. Suppose X has the density
p(x) =

0
:
x < 1
c! x!
:
x â‰¥1
for some ! < â€“1.
1.
Determine c! such that p is a density.
2.
For which n â‰¥1 does X possess an nth moment?
Problem 5.17. Let U be uniform distributed on an interval [!, "]. Show that for n â‰¥1
EUn = "n + !"nâ€“1 + â‹…â‹…â‹…!nâ€“1" + "n
n + 1
.
Problem 5.18. Let X1, . . . , Xn be random variables with ï¬nite second moment and
with EXj = 0. Show that
E [X1 + â‹…â‹…â‹…+ Xn]2 =
n

i,j=1
Cov(Xi, Xj) =
n

j=1
VXj + 2

1â‰¤i<jâ‰¤n
Cov(Xi, Xj) .
Problem 5.19. Show
EX = nM
N
for a hypergeometric distributed random variable X with
P{X = m} =
M
m
 Nâ€“M
nâ€“m

N
n

,
m = 0, . . . , n .
Problem 5.20. Let X be N(0, 1)-distributed. Determine VX3 and VX4.

5.4 Problems
247
Problem 5.21.
Given a non-negative random variable X, deï¬ne >X from [0, âˆ) to
[0, âˆ] by >X(t) = E tX. Then >X is called generating function of X (see [GS01b],
Section 5.1).
(1)
Suppose X has values in N0. Show that, if t â‰¥0, then this â€œnewâ€ deï¬nition of the
generating function coincides with the one given in Problem 4.2.
(2)
Let X1, . . . , Xn be independent and non-negative. For !j â‰¥0, 1 â‰¤j â‰¤n, let
X = !1X1 + â‹…â‹…â‹…+ !nXn .
Prove
>X(t) = >X1(t!1) â‹…â‹…â‹…>Xn(t!n) .
(3)
Find >X for an exponentially distributed X.

6 Normally Distributed Random Vectors
6.1 Representation and Density
In Example 3.4.3 we considered a two-dimensional random vector (X1, X2), where X1
was the height of a randomly chosen person and X2 was his weight. From experience
and in view of the central limit theorem (cf. Section 7), it is quite reasonable to as-
sume that X1 and X2 are normally distributed. Suppose we are able to determine their
expected values and their variances. However, this is not sufï¬cient to describe the ex-
periment. Why? The random variables X1 and X2 are surely dependent, and the most
interesting problem is to describe their degree of dependence. This cannot be done
based only on the knowledge of their distributions. What we really need to know is
their joint distribution. Therefore, we not only have to suppose X1 and X2 to be normal,
but the generated vector (X1, X2) has to be as well.
But what does it mean that a random vector is normally distributed? This section
is devoted to answer this and related questions.
Let us ï¬rst recall the univariate case, investigated in Example 4.2.2 and in the
subsequent Proposition 4.2.3. The main observation was that a random variable Y is
normally distributed if and only if it may be written as
Y = aX + ,
(6.1)
for some a /= 0, , âˆˆR, and a standard normal random variable X.
Let now âƒ—Y = (Y1, . . . , Yn) be an n-dimensional random vector. We want to represent
it in the same way as Y in eq. (6.1). Consequently, we have to replace X by a multivari-
ate standard normal vector and the function x â†¦ax + , by a suitable mapping from
Rn to Rn. But which kind of mapping this should be and what is an n-dimensional
standard normal vector?
Let us begin by answering the second question. Therefore, recall the deï¬nition
of the multivariate standard normal distribution N(0, 1)âŠ—n introduced in Deï¬nition
1.9.16. This probability measure on (Rn, B(Rn)) was given by
N(0, 1)âŠ—n(B) =
1
(20)n/2

B
eâ€“|x|2/2 dx
=
1
(20)n/2

â‹…â‹…â‹…




B
eâ€“(x2
1+â‹…â‹…â‹…+x2n)/2 dxn â‹…â‹…â‹…dx1
with B
âˆˆ
B(Rn). Thus, a random vector âƒ—X should be standard normal distrib-
uted whenever its probability distribution is N(0, 1)âŠ—n. Let us formulate this as a
deï¬nition.

6.1 Representation and Density
249
Deï¬nition 6.1.1. A random vector âƒ—X = (X1, . . . , Xn) is standard normally (distrib-
uted) if its probability distribution satisï¬es Pâƒ—X = N(0, 1)âŠ—n.
To make this deï¬nition more descriptive, let us state some equivalent properties.
Proposition 6.1.2. For a random vector âƒ—X = (X1, . . . , Xn) the following are equivalent:
1.
âƒ—X is standard normal.
2.
If B âˆˆB(Rn), then
P{âƒ—X âˆˆB} =
1
(20)n/2

B
eâ€“|x|2/2 dx .
3.
The coordinate mappings X1, . . . , Xn are (univariate) standard normal distributed
and independent. That is, for all tj âˆˆR, 1 â‰¤j â‰¤n,
P{X1 â‰¤t1, . . . , Xn â‰¤tn} = P{X1 â‰¤t1} â‹…â‹…â‹…P{Xn â‰¤tn}
=
â›
â
1
âˆš
20
t1

â€“âˆ
eâ€“x2
1/2dx1
â
â â‹…â‹…â‹…
â›
â
1
âˆš
20
tn

â€“âˆ
eâ€“x2n/2dxn
â
â .
Proof: Taking into account the deï¬nition of N(0, 1)âŠ—n, this is an immediate con-
sequence of Propositions 3.6.5 and 3.6.18. Compare also the considerations in Ex-
ample 3.6.22.
âˆ
An adequate substitute for x â†¦ax + , in representation (6.1) is still undetermined.
Which mappings in Rn should be considered?
Observe that x â†¦ax +, is afï¬ne linear from R to R. The counterpart in Rn is of the
form x â†¦Ax + ,, where A is a linear mapping in Rn and , âˆˆRn. Linear mappings in Rn
are described by n Ã— n matrices A =

!ij
n
i,j=1 and act as follows:
Ax =
â›
â
n

j=1
!1jxj, . . . ,
n

j=1
!njxj
â
â ,
x = (x1, . . . , xn) âˆˆRn .
Consequently, the suitable generalization of x â†¦ax + , is the mapping x â†¦Ax + ,
with an n Ã— n matrix A and , âˆˆRn. The condition a /= 0 transfers to det(A) /= 0 or,
equivalently, A has to be regular, that is, the generated mapping is one-to-one from
Rn onto Rn. Here and in the sequel we will use results and notations as presented in
Section A.4.
Now we are in position to deï¬ne normally (distributed) random vectors.

250
6 Normally Distributed Random Vectors
Deï¬nition 6.1.3. A random vector âƒ—Y is said to be normally distributed (or simply,
normal) provided there exists a regular nÃ—n matrix A and a vector , âˆˆRn such that
âƒ—Y = Aâƒ—X + ,
(6.2)
for some standard normal âƒ—X.
Remark 6.1.4. Let us reformulate Deï¬nition 6.1.3 due to its importance. A random vec-
tor âƒ—Y = (Y1, . . . , Yn) is normal if and only if there exists a regular matrix A =

!ij
n
i,j=1
and a vector , = (,1, . . . , ,n) such that
Yi =
n

j=1
!ijXj + ,i ,
1 â‰¤i â‰¤n ,
with X1, . . . , Xn independent N(0, 1)-distributed.
Example 6.1.5. Suppose the three-dimensional random vector âƒ—Y
= (Y1, Y2, Y3) is
deï¬ned by
Y1 = 2X1 + X2 â€“ X3 + 4 ,
Y2 = X1 â€“ 2X2 + X3 â€“ 2
and
Y3 = X1 â€“ 2X3 + 5
with N(0, 1)-distributed independent X1, X2, X3. Then âƒ—Y is normally distributed. Ob-
serve that it may be represented in the form of eq. (6.2) with A given by
A =
â›
âœâ
2
1
â€“1
1
â€“2
1
1
0
â€“2
â
âŸâ 
and with , = (4, â€“2, 5). Moreover, we have det(A) = 9, hence A is regular.
Given a normal vector âƒ—Y, how do we get the standard normal âƒ—X in representation (6.2)?
The next proposition answers this question.
Proposition 6.1.6. A random vector âƒ—Y = (Y1, . . . , Yn) is normal if and only if there exists
a regular nÃ—n matrix B = ("ij)n
i,j=1 and a vector - = (-1, . . . , -n) âˆˆRn such that the random
variables Xi, deï¬ned by
Xi :=
n

j=1
"ijYj + -i ,
1 â‰¤i â‰¤n ,
are independent standard normal.

6.1 Representation and Density
251
Proof: This is a direct consequence of the following observation. One has âƒ—Y = Aâƒ—X + ,
if and only if âƒ—X may be represented as âƒ—X = Aâ€“1 âƒ—Y â€“Aâ€“1,. Therefore, the assertion follows
by choosing B and - such that B = Aâ€“1 and - = â€“Aâ€“1,.
âˆ
Example 6.1.7. For the random vector âƒ—Y investigated in Example 6.1.5, the generated
independent standard normal random variables X1, X2, and X3 may be represented as
follows:
X1 = 1
9 (4Y1 + 2Y2 â€“ Y3 + 7)
X2 = 1
9 (Y1 â€“ Y2 â€“ Y3 + 1)
X3 = 1
9 (2Y1 + Y2 â€“ 5Y3 â€“ 19) .
Suppose âƒ—Y = Aâƒ—X + , is a normal vector. How can we evaluate its distribution density?
To answer this question, we introduce the following function. Let R > 0 be an n Ã— n-
matrix and , âˆˆRn. The inverse matrix of R is Râ€“1, and to simplify the notation, set
|R| = det(R). Observe that R > 0 implies |R| > 0. With these notations we deï¬ne a
function p,,R from Rn to R by
p,,R(x) :=
1
(20)n/2|R|1/2 e
â€“
>
Râ€“1(xâ€“,),(xâ€“,)
?@
2 ,
x âˆˆRn .
(6.3)
Now we are prepared to answer the above question about the density of âƒ—Y.
Proposition 6.1.8. Suppose the normal vector âƒ—Y is represented as in eq. (6.2) with regu-
lar A and , âˆˆRn. Deï¬ne the positive matrix R by R = AAT. Then p,,R, as given in eq. (6.3),
is the distribution density of âƒ—Y. In other words, if B âˆˆB(Rn), then
P{âƒ—Y âˆˆB} =
1
(20)n/2|R|1/2

B
e
â€“
>
Râ€“1(xâ€“,),(xâ€“,)
?@
2 dx .
Proof: Because âƒ—Y = Aâƒ—X + , with âƒ—X standard normal, Proposition 6.1.2 implies
P{âƒ—Y âˆˆB} = P{Aâƒ—X + , âˆˆB} = P{âƒ—X âˆˆAâ€“1(B â€“ ,)}
=
1
(20)n/2

Aâ€“1(Bâ€“,)
eâ€“|y|2/2 dy
for any Borel set B âŠ†Rn. Hereby, B â€“ , denotes the set {b â€“ , : b âˆˆB}.
In the next step we change the variables by setting x = Ay + ,. Then dx =
|det(A)| dy, where by assumption det(A) /= 0 and, moreover, we have y âˆˆAâ€“1(B â€“ ,)
if and only if x âˆˆB. Therefore, the last integral transforms to

252
6 Normally Distributed Random Vectors
P{âƒ—Y âˆˆB} =
1
(20)n/2 |det(A)|â€“1

B
eâ€“|Aâ€“1(xâ€“,)|2/2 dx .
(6.4)
Proposition A.4.1 implies R > 0 and, moreover,
|R| = det(R) = det(AAT) = det(A) â‹…det(AT) = det(A)2 .
Since |R| = det(R) > 0, this leads to |R|1/2 = |det(A)|, that is, to
|det(A)|â€“1 = |R|â€“1/2 .
(6.5)
Note that
|Aâ€“1(x â€“ ,)|2 =
A
Aâ€“1(x â€“ ,), Aâ€“1(x â€“ ,)
B
=
>
(Aâ€“1)TAâ€“1(x â€“ ,), (x â€“ ,)
?
,
which by

Aâ€“1T â—‹Aâ€“1 =

AT
â€“1
â—‹Aâ€“1 =

A â—‹AT
â€“1
= Râ€“1
implies
|Aâ€“1(x â€“ ,)|2 =
A
Râ€“1(x â€“ ,), (x â€“ ,)
B
.
(6.6)
Plugging eqs. (6.5) and (6.6) into eq. (6.4), we get
P{âƒ—Y âˆˆB} =

B
p,,R(x) dx
with p,,R as in eq. (6.3). This completes the proof.
âˆ
Remark 6.1.9. How does Proposition 6.1.8 look like for n = 1 ? Here Y = aX + ,, that is,
A =

a

, and since A has to be regular, this implies a /= 0. Hence we get R = AAT =

a2
,
Râ€“1 =

aâ€“2
and |R|1/2 = |a|. Thus, the density of Y is given by
p,,R(x) =
1
(20)1/2|R|1/2 e
â€“
>
Râ€“1(xâ€“,),xâ€“,
?@
2 =
1
(20)1/2|a|e â€“(xâ€“,)2/2a2 ,
x âˆˆR .
This coincides with the result obtained in Example 4.2.2.
In view of Proposition 6.1.8 we will use the following notation.

6.1 Representation and Density
253
Deï¬nition 6.1.10. A normal vector âƒ—Y is said to be N(,, R)-distributed if p,,R is its
density, that is, if
P{âƒ—Y âˆˆB} =
1
(20)n/2|R|1/2

B
e
â€“
>
Râ€“1(xâ€“,),(xâ€“,)
?@
2 dx .
Remark 6.1.11. It follows from Proposition A.4.2 that, given any , âˆˆRn and any R > 0,
there exists a normal vector âƒ—Y that is N(,, R)-distributed. Indeed, write R > 0 as
R = AAT and set âƒ—Y = Aâƒ—X + , with âƒ—X standard normal. Then âƒ—Y is N(,, R)-distributed
by Proposition 6.1.8.
{Distributions of Rn-valued normal vectors}
â‡â‡’
{, âˆˆRn, R > 0}
Example 6.1.12. Assume
Y1 = X1 â€“ X2 + 3
and
Y2 = 2X1 + X2 â€“ 2
for X1, X2 independent N(0, 1)-distributed. Then we get
, = (3, â€“2)
and
A =

1 â€“1
2
1

,
which implies
R = AAT =

1
â€“1
2
1

â‹…

1
2
â€“1
1

=

2
1
1
5

.
(6.7)
Thus, âƒ—Y is N(,, R)-distributed with , = (3, â€“2) and R as in eq. (6.7).
Which density does âƒ—Y possess? To answer this, we have to compute det(R) and Râ€“1.
One easily gets det(R) = 9. The inverse matrix of R equals
Râ€“1 = 1
9

5 â€“1
â€“1
2

.
Therefore, the distribution density p,,R of âƒ—Y = (Y1, Y2) is given by

254
6 Normally Distributed Random Vectors
p,,R(x1, x2) = 1
60 exp

â€“1
2
A
Râ€“1(x1 â€“ 3, x2 + 2), (x1 â€“ 3, x2 + 2)
B
= 1
60 exp

â€“ 1
18

5(x1 â€“ 3)2 â€“ 2(x1 â€“ 3)(x2 + 2) + 2(x2 + 2)2
.
(6.8)
2
0
â€“2
â€“4
â€“6
6
4
2
0
Figure 6.1: The density given by eq. (6.8).
For later purposes we have to name the probability measures on (Rn, B(Rn)) appearing
as distributions of normal vectors.
Deï¬nition 6.1.13. Given , âˆˆRn and R > 0, the probability measure N(,, R) on
(Rn, B(Rn)) is deï¬ned by
N(,, R)(B) =

B
p,,R(x) dx =
1
(20)n/2|R|1/2

B
e
â€“ 1
2
>
Râ€“1(xâ€“,),(xâ€“,)
?
dx .
N(,, R) is called a multivariate normal distribution with1 expected value , and
covariance matrix R.
According to Deï¬nition 6.1.13, we may now formulate Proposition 6.1.8 as follows:
Proposition 6.1.14. Let âƒ—Y be a random vector. Then the following are equivalent.
1.
âƒ—Y is N(,, R)-distributed.
2.
Pâƒ—Y = N(,, R).
3.
There is a regular n Ã— n matrix A with R = AAT such that âƒ—Y = Aâƒ—X + ,.
Remark 6.1.15. The case R = In (as in Section A.4 we denote the identity matrix in Rn
by In) and , = 0 is of special interest. Because Iâ€“1
n = In and det(In) = 1, we get
p0,In(x) =
1
(20)n/2 eâ€“|x|2/2 ,
x âˆˆRn .
1 Why they are named in this way will become clear in the next section.

6.1 Representation and Density
255
This tells us that N(0, In) is nothing else as the multivariate standard normal distribu-
tion introduced in Deï¬nition 1.9.16. Written as formula, this means
N(0, 1)âŠ—n = N(0, In) .
More generally, in view of eq. (1.75) it follows that
N(,, 32)âŠ—n = N(âƒ—,, 32 In)
where âƒ—, = (,, . . . , ,) âˆˆRn and 3 > 0. In other words,
N(,, 32)âŠ—n(B) = N(âƒ—,, 32 In)(B) =
1
(20)n/23n

B
eâ€“|xâ€“âƒ—,|2/232 dx .
(6.9)
For later purposes, the next result is of importance.
Proposition 6.1.16. Suppose a normal vector âƒ—Y = (Y1, . . . , Yn) may be written as
âƒ—Y = U âƒ—X
with an N(0, In)-distributed (standard normal) âƒ—X and a unitary matrix U. Then its
coordinate mappings Y1, . . . , Yn are independent standard normal random variables.
Proof: The random vector âƒ—Y is N(0, UUT)-distributed. But U is unitary, hence, UUT =
In and âƒ—Y is N(0, In) or, equivalently, standard normally distributed. Then the assertion
follows by Proposition 6.1.2.
âˆ
Example 6.1.17. For ( âˆˆ[0, 20) deï¬ne the 2 Ã— 2 matrix U by
U =

cos ( sin (
â€“ sin ( cos (

.
The matrix U is unitary and by Proposition 6.1.16 the vector âƒ—Y = U âƒ—X is standard normal.
In other words, given independent standard normal X1 and X2, for each ( âˆˆ[0, 20) the
random variables
Y1 := cos ( X1 + sin ( X2
and
Y2 = â€“ sin ( X1 + cos ( X2
are independent and standard normally distributed as well.

256
6 Normally Distributed Random Vectors
6.2 Expected Value and Covariance Matrix
We start with the following deï¬nition.
Deï¬nition 6.2.1. Let âƒ—Y = (Y1, . . . , Yn) be a random vector such that E|Yj| < âˆfor
all 1 â‰¤j â‰¤n. Then the vector
Eâƒ—Y := (EY1, . . . , EYn) = (,1, . . . , ,n)
is called the (multivariate) expected value of âƒ—Y-
If EY2
j < âˆ, 1 â‰¤j â‰¤n, then the matrix
Covâƒ—Y :=

Cov(Yi, Yj)

n
i,j=1 =

E(Yi â€“ ,i)(Yj â€“ ,j)

n
i,j=1
is said to be the covariance matrix of âƒ—Y.
Remark 6.2.2. It is important to notice that both Eâƒ—Y and the covariance matrix Covâƒ—Y
depend only on the distribution of âƒ—Y. That is, whenever Pâƒ—Y1 = Pâƒ—Y2, then
Eâƒ—Y1 = Eâƒ—Y2
and
Covâƒ—Y1 = Covâƒ—Y2 .
The next proposition describes the (multivariate) expected value and the covariance
matrix of a normally distributed vector.
Proposition 6.2.3. Assume âƒ—Y = Aâƒ—X + , for some regular matrix A and , âˆˆRn. Deï¬ne
R =

rij
n
i,j=1 as R = AAT. Then the following is valid.
(1)
We have Eâƒ—Y = , and Covâƒ—Y =

Cov(Yi, Yj)

n
i,j=1 = R.
(2)
Given a âˆˆRn, a /= 0, then
>
âƒ—Y, a
?
is a normal random variable with expected value
âŸ¨,, aâŸ©and variance âŸ¨Ra, aâŸ©.
(3)
The coordinate mappings Yi are N

,i, rii

-distributed, 1 â‰¤i â‰¤n, that is, the
marginal distributions of âƒ—Y are the probability measures N(,i, rii).
Proof: By assumption
Yi =
n

j=1
!ijXj + ,i ,
i = 1, . . . , n ,
(6.10)
hence, the linearity of the expected value and EXj = 0 imply
EYi =
n

j=1
!ij EXj + ,i = ,i ,
1 â‰¤i â‰¤n .
This proves Eâƒ—Y = (EY1, . . . , EYn) = ,.

6.2 Expected Value and Covariance Matrix
257
Let us now verify the second part of property (1). Using ,j = EYj, by representation
(6.10) we get
Cov(Yi, Yj) = E[(Yi â€“ ,i)(Yj â€“ ,j)] = E
 n

k=1
!ikXk
  n

l=1
!jlXl

=
n

k,l=1
!ik!jl EXkXl .
The Xjs are independent N(0, 1)-distributed, hence
EXkXl =

1 : k = l
0 : k /= l ,
leading to
Cov(Yi, Yj) =
n

k=1
!ik!jk = rij .
To see this, recall that R = AAT, hence rij = n
k=1 !ik!jk. This proves Covâƒ—Y = R as
asserted.
To verify property (2) we ï¬rst treat a special case, namely that the vector is
standard normally distributed. So suppose that âƒ—X is N(0, In)-distributed. In this case,
property (2) asserts the following. For any b âˆˆRn, b /= 0,
>
âƒ—X, b
?
is distributed according to N(0, |b|2) .
(6.11)
If b = (b1, . . . , bn), then
>
âƒ—X, b
?
=
n

j=1
bjXj =
n

j=1
Zj
with Zj = bjXj. The random variables Z1, . . . , Zn are independent and, moreover, by
Proposition 4.2.3, the Zjs are N(0, b2
j )-distributed. Proposition 4.6.18 implies that
n

j=1
Zj is distributed according to N

0,
n

j=1
b2
j

.
In view of n
j=1 b2
j = |b|2 this proves assertion (6.11).
Let us now turn to the general case. Recall that
âƒ—Y = Aâƒ—X + ,

258
6 Normally Distributed Random Vectors
and R = AAT. If a âˆˆRn is a nonzero vector, then we take the scalar product with respect
to a on both sides of the last equation and obtain
>
âƒ—Y, a
?
=
>
Aâƒ—X, a
?
+ âŸ¨,, aâŸ©=
>
âƒ—X, ATa
?
+ âŸ¨,, aâŸ©.
An application of statement (6.11) with b = ATa lets us conclude that
>
âƒ—X, ATa
?
is
N(0, |ATa|2)-distributed, that is,
>
âƒ—Y, a
?
is N(âŸ¨,, aâŸ©, |ATa|2)-distributed. Here we used
that A, hence also AT, are regular, so that a /= 0 yields b = ATa /= 0, and statement (6.11)
applies. Assertion (2) follows now by
|ATa|2 =
>
ATa, ATa
?
=
>
AATa, a
?
= âŸ¨Ra, aâŸ©.
Property (3) is an immediate consequence of the second one. An application of
property (2) to the ith unit vector ei = (0, . . . , 0,
1

i
, 0, . . . , 0) in Rn leads on one side to
>
âƒ—Y, ei
?
= Yi ,
1 â‰¤i â‰¤n ,
and on the other side to
âŸ¨Rei, eiâŸ©= rii
and
âŸ¨,, eiâŸ©= ,i ,
1 â‰¤i â‰¤n .
Thus, by property (2), for each i â‰¤n the random variable Yis is N(,i, rii)-distributed.
This completes the proof.
âˆ
Corollary 6.2.4. If âƒ—Y is N(,, R)-distributed, then Eâƒ—Y = , and Covâƒ—Y= R.
Proof: Choose any regular n Ã— n matrix ËœA such that R = ËœA ËœAT. The existence of such
an ËœA is proved in Proposition A.4.2. Set âƒ—Z = ËœAâƒ—X + , for some standard normal vec-
tor âƒ—X. Then âƒ—Y as well as âƒ—Z are both N(,, R)-distributed, hence âƒ—Z
d= âƒ—Y. Proposition 6.2.3
implies Eâƒ—Z = , and Covâƒ—Z = R. Consequently, by Remark 6.2.2 follows
Eâƒ—Y = Eâƒ—Z = ,
and
Covâƒ—Y = Covâƒ—Z = R ,
which completes the proof.
âˆ
In view of property Corollary 6.2.4 we will use the following notation.
Deï¬nition 6.2.5. If âƒ—Y is N(,, R), distributed, then the parameters , and R are
called the (multivariate) expected value and the covariance matrix of âƒ—Y,
respectively.

6.2 Expected Value and Covariance Matrix
259
Remark 6.2.6. We proved above that for any normal vector âƒ—Y the coordinate mappings
Yi =
>
âƒ—Y, ei
?
are normal as well. The converse is not valid. There are random vectors âƒ—Y
with all random variables
>
âƒ—Y, ei
?
normal, 1 â‰¤i â‰¤n, but âƒ—Y is not so.
In contrast to this remark, the following is valid.
Proposition 6.2.7. If
>
âƒ—Y, a
?
is normal for all nonzero a âˆˆRn, then âƒ—Y is normal as well.
Idea of the proof. By assumption, for each a /= 0 there are real numbers ,a and 3a > 0
such that
>
âƒ—Y, a
?
is N(,a, 32
a)-distributed. In order to prove the proposition, one has to
show that there are a , âˆˆRn with ,a = âŸ¨,, aâŸ©and an R > 0 such that 32
a = âŸ¨Ra, aâŸ©,
a âˆˆRn. The existence of the vector , easily follows from
,!a+"b = E
>
âƒ—Y, !a + "b
?
= !E
>
âƒ—Y, a
?
+ "
>
âƒ—Y, b
?
= !,a + ",b ,
using the fact that each linear mapping from Rn to R is of the form a â†¦âŸ¨a, ,âŸ©for a
suitable , âˆˆRn.
The existence of an R > 0 with 32
a = âŸ¨Ra, aâŸ©is consequence of a representation
theorem for positive quadratic forms on Rn. To this end, one has to show that a â†¦32
a
is a positive quadratic form, which follows by using 32
a = E
>
âƒ—Y, a
?2
.
As we saw above (cf. Proposition 5.3.10), independent random variables are un-
correlated. On the other hand, Examples 5.3.12 and 5.3.15 showed the existence of
uncorrelated variables that are not independent. Thus, in general, the property of
being uncorrelated is weaker than that of being independent.
One of the basic features of normal vectors is that for them uncorrelated coordin-
ate mappings are already independent. This somehow explains why in the common
speech these properties are synonymies.
Proposition 6.2.8. Let âƒ—Y = (Y1, . . . , Yn) be a normally distributed vector. Then the
following are equivalent.
(1)
Y1, . . . , Yn are independent.
(2)
Y1, . . . , Yn are uncorrelated.
(3)
The covariance matrix Covâƒ—Y is a diagonal matrix.
Proof: The implication (1) â‡’(2) follows by Proposition 5.3.10. If the Yjs are uncorrel-
ated, then this tells us that Cov(Yi, Yj) = 0 whenever i /= j. Thus, Covâƒ—Y is a diagonal
matrix, which proves (2) â‡’(3).
It remains to verify (3) â‡’(1). Thus assume that âƒ—Y is N(,, R) distributed, where
R > 0 is a diagonal matrix. Let r11, . . . , rnn be the entries of R at the diagonal. Deï¬ne A
as diagonal matrix with r1/2
11 , . . . , r1/2
nn on the diagonal. Note that R > 0 implies rii > 0,
hence A is well-deï¬ned. Of course, then AAT = R, hence âƒ—Y has the same distribution
as the the vector (Z1, . . . , Zn) with

260
6 Normally Distributed Random Vectors
Zi = r1/2
ii Xi + ,i ,
1 â‰¤i â‰¤n ,
where X1, . . . , Xn are independent standard normal. Proposition 4.1.9 lets us conclude
that Z1, . . . , Zn are independent normal random variables. But since âƒ—Y
d= âƒ—Z, the random
variables Y1, . . . , Yn are independent as well2.
âˆ
Remark 6.2.9. Another property, being equivalent to those in Proposition 6.2.8, is as
follows. The density function of âƒ—Y is
p,,R(x) =
1
(20)n/2|R|1/2 eâ€“ n
j=1(xjâ€“,j)2/2rjj ,
x = (x1, . . . , xn) .
Note that |R| = det(R) = r11 â‹…â‹…â‹…rnn.
Finally, we investigate the case of two-dimensional normal vectors more thoroughly.
Thus assume âƒ—Y = (Y1, Y2) is a normal vector. Then the covariance matrix R is given by
R =

VY1
Cov(Y1, Y2)
Cov(Y1, Y2)
VY2

Let 32
1 and 32
2 be the variance of Y1 and Y2, respectively, and let 1 := 1(Y1, Y2) be their
correlation coefï¬cient. Because of
Cov(Y1, Y2) = (VY1)1/2(VY2)1/2 1(Y1, Y2) = 3132 1
we may rewrite R as
R =

32
1
13132
13132
32
2

.
This implies det(R) = 32
132
2(1 â€“ 12). Since 32
1 > 0, the matrix R is positive if and only if
|1| < 1. The inverse matrix Râ€“1 can be computed by Cramerâ€™s rule as
Râ€“1 =
1
32
132
2(1 â€“ 12)

32
2
â€“13132
â€“13132
32
1

=
1
1 â€“ 12
â›
â
1
32
1
â€“1
3132
â€“1
3132
1
32
2
â
â .
Consequently,
A
Râ€“1x, x
B
=
1
1 â€“ 12
 x2
1
32
1
â€“ 21x1x2
3132
+ x2
2
32
2

,
x = (x1, x2) âˆˆR2 .
2 Indeed, use the characterization of independent random variables given in Proposition 3.6.5. The
condition stated there depends only on the joint distribution.

6.2 Expected Value and Covariance Matrix
261
If , = (,1, ,2) = (EY1, EY2) denotes the expected value of âƒ—Y, then for a1 < b1 and
a2 < b2,
P{a1 â‰¤Y1 â‰¤b1, a2 â‰¤Y2 â‰¤b2} =
1
20(1 â€“ 12)1/23132
Ã—
Ã—
b1

a1
b2

a2
exp

â€“
1
2(1 â€“ 12)
(x1 â€“ ,1)2
32
1
â€“ 21 (x1 â€“ ,1)(x2 â€“ ,2)
3132
+(x2 â€“ ,2)2
32
2

dx2 dx1 .
(6.12)
Compare this with the case of independent Y1 and Y2. Here it follows that
P{a1 â‰¤Y1 â‰¤b1, a2 â‰¤Y2 â‰¤b2}
=
1
203132
b1

a1
b2

a2
exp

â€“1
2
(x1 â€“ ,1)2
32
1
+ (x2 â€“ ,2)2
32
2

dx2 dx1 .
(6.13)
It is worthwhile to mention that in both cases (dependent and independent) the mar-
ginal distributions are the same, namely N(,1, 32
1) and N(,2, 32
2). A comparison of
eqs. (6.12) and (6.13) shows clearly the inï¬‚uence of the correlation coefï¬cient to the
density (Fig. 6.2).
2
4
4
0
2
0
0
0
2
2
â€“2
â€“2
â€“2
â€“4
â€“4
â€“2
2
4
0
2
0
â€“2
â€“4
â€“2
2
4
0
2
0
â€“2
â€“4
â€“2
Figure 6.2: ,1 = ,2 = 0, 31 = 2, 32 = 1 and 1 = 0, 1 = 1/4, 1 = 3/4, and 1 = â€“1/2 from top left to bottom
right.

262
6 Normally Distributed Random Vectors
6.3 Problems
Problem 6.1. Let âƒ—Y = (Y1, . . . , Yn) be an arbitrary (not necessarily normal) random
vector.
1.
Show that E|Yj| < âˆ, 1 â‰¤j â‰¤n, if and only if E|âƒ—Y| < âˆ. Here |âƒ—Y| denotes the
Euclidean distance of âƒ—Y.
2.
Let A be an arbitrary n Ã— n matrix. Prove that
E(Aâƒ—Y) = A(Eâƒ—Y)
provided that E|âƒ—Y| < âˆ.
3.
Show that E|Yj|2 < âˆ, 1 â‰¤j â‰¤n, if and only if E|âƒ—Y|2 < âˆ.
4.
Suppose E|âƒ—Y|2 < âˆ. Let Covâƒ—Y be the covariance matrix of âƒ—Y. Prove that Covâƒ—Y is
non-negative deï¬nite, that is,
A
Covâƒ—Yx, x
B
â‰¥0 ,
x âˆˆRn .
Problem 6.2. Let âƒ—X = (X1, X2) be a two-dimensional standard normal vector. Compute
P{|X| â‰¤1} = P{X2
1 + X2
2 â‰¤1} .
Hint: Compare the proof of Proposition 1.6.6.
Problem 6.3. Let X1, . . . , Xn+m be a sequence of independent standard normal random
variables. For an n Ã— n matrix A =

!ij
n
i,j=1 and an m Ã— m matrix B = ("kl)m
k,l=1 deï¬ne two
normal vectors âƒ—Y and âƒ—Z by
Yi =
n

j=1
!ijXj
and
Zk =
m

l=1
"klXl+n ,
1 â‰¤i â‰¤n and 1 â‰¤k â‰¤m. Let (âƒ—Y, âƒ—Z) be the (n + m)-dimensional vector
(âƒ—Y, âƒ—Z) = (Y1, . . . , Yn, Z1, . . . , Zm) .
Why is (âƒ—Y, âƒ—Z) normal? Show that the covariance matrix Cov(âƒ—Y,âƒ—Z) is given by
Cov(âƒ—Y,âƒ—Z) =

Covâƒ—Y
0
0
Covâƒ—Z

.

6.3 Problems
263
Problem 6.4. Let X1, X2, and X3 be three standard normal independent random vari-
ables. Deï¬ne the random vector âƒ—Y by
âƒ—Y := (X1 â€“ 1, X1 + X2 â€“ 1, X1 + X2 + X3 â€“ 1) .
1.
Argue why âƒ—Y is normal. Determine its expected value, its covariance matrix, and
the correlation coefï¬cients 1(Yi, Yj), 1 â‰¤i < j â‰¤3.
2.
Determine the distribution density of âƒ—Y.
Problem 6.5. The random vector âƒ—Y = (Y1, . . . , Yn) is N(,, R)-distributed for some , âˆˆ
Rn and R > 0. Determine the distribution of Y1 + â‹…â‹…â‹…+ Yn.
Problem 6.6. Prove the following assertion: If âƒ—Y is N(0, R)-distributed, then there ex-
ist an orthonormal basis (fj)n
j=1 in Rn, positive numbers +1, . . . , +n and independent
N(0, 1)-distributed .1, . . . , .n such that
âƒ—Y =
n

j=1
+j.j fj .
(6.14)
Hint: Use the principal axis transformation for symmetric matrices and the fact that
unitary matrices map an orthonormal basis onto an orthonormal basis.
Conclude from eq. (6.14) the following: If âƒ—Y is N(0, R)-distributed, then there are
a1, . . . , an in Rn such that
>
âƒ—Y, a1
?
, . . . ,
>
âƒ—Y, an
?
is a sequence of independent standard
normal random variables.
Problem 6.7. The n-dimensional vector âƒ—Y is distributed according to N(,, R). For some
regular n Ã— n matrix S deï¬ne âƒ—Z by âƒ—Z := S âƒ—Y. Is âƒ—Z normal? If this is so, determine the
expected value and the covariance matrix of âƒ—Z.
Problem 6.8. Let âƒ—X = (X1, X2) be standard normal. Deï¬ne random variables Y1 and
Y2 by
Y1 :=
1
âˆš
2
(X1 + X2)
and
Y2 :=
1
âˆš
2
(X1 â€“ X2) .
Why are Y1 and Y2 also independent and standard normal?

7 Limit Theorems
Probability Theory does not have the ability to predict the occurrence or nonoccur-
rence of a single event in a random experiment; besides, this event occurs either with
probability one or with probability zero. For example, Probability Theory does not
give any information about the next result when rolling a die, it does not predict the
numbers appearing next week on the lottery nor is it able to foresee the lifetime of a
component in a machine. Such statements are impossible within the theory. The the-
ory is only able to say that some events are more likely and others are less likely. For
instance, when rolling a die twice, it is more likely that the sum of both rolls will be
â€œ7â€ than â€œ2.â€ Nevertheless, next when we roll the die the sum may be â€œ2,â€ not â€œ7.â€ The
event â€œthe sum is 2â€ is not impossible, only less likely.
In contrast, Probability Theory provides us with very precise and far-reaching in-
formation about the behavior of the results when we execute â€œmanyâ€ identical random
experiments. As already said, we cannot tell anything about the expected number on a
die when we roll it once, but we are able to say a lot about the frequency of the number
â€œ6â€ when rolling a die many times, namely that, on average, this number will appear
in one of six cases (provided the die is fair). In this example, certain laws of Probab-
ility Theory, which we will present in this section, are operating. These laws are only
applicable in the case of many experiments, not in that of a single one.
Limit theorems in Probability Theory belong to the most beautiful and most im-
portant assertions within this theory. They are always the highlight of a lecture about
advanced Probability Theory. However, their proofs require a longer comprehensive
mathematical explanation, which is impossible to give here within the frame of this
book. For those who are interested in knowing more about this topic, they may look
into one of the more advanced books, such as [Bil12], [Dur10], or [Kho07]. Although
the proofs of the limit theorems are mostly quite complicated, they are very important,
and their consequences inï¬‚uence our daily lives. Moreover, great parts of Mathemat-
ical Statistics are based on these results. Therefore, we decided to state here the crucial
assertions without proving most of them. Thus, our main focus is to present the most
important limit theorems, to explain them in detail, and to give examples that show
how they apply. If possible, we give some hint as to how the results are derived, but
mostly we must resign to prove them.
7.1 Laws of Large Numbers
7.1.1 Chebyshevâ€™s Inequality
Our ï¬rst objective is to prove Chebyshevâ€™s inequality. To do so, we need the following
lemma.

7.1 Laws of Large Numbers
265
Lemma 7.1.1. Let Y be a non-negative random variable. Then for each +
>
0 it
follows that
P{Y â‰¥+} â‰¤EY
+ .
(7.1)
Proof: Let us ï¬rst treat the case that Y is discrete. Since Y â‰¥0, its possible values
y1, y2, . . . are nonnegative real numbers. Therefore, we get
EY =
âˆ

j=1
yj P{Y = yj} â‰¥

yjâ‰¥+
yj P{Y = yj}
â‰¥+

yjâ‰¥+
P{Y = yj} = +P{Y â‰¥+} .
Solving the inequality for P{Y â‰¥+} proves inequality (7.1).
The proof of estimate (7.1) for continuous Y uses similar methods. If q denotes the
distribution density of Y, by Y â‰¥0 we may suppose q(y) = 0 for y < 0. Then, as in the
discrete case, we conclude that
EY =
âˆ

0
yq(y) dy â‰¥
âˆ

+
yq(y) dy â‰¥+
âˆ

+
q(y) dy = +P{Y â‰¥+} .
From this inequality (7.1) follows directly.
âˆ
Remark 7.1.2. Sometimes it is useful to apply inequality (7.1) in a slightly modiï¬ed
way. For example, if Y â‰¥0 and ! > 0, then one derives
P{Y â‰¥+} = P{Y! â‰¥+!} â‰¤EY!
+! .
Or, if Y is real valued, then for + âˆˆR we obtain
P{Y â‰¤+} = P

eâ€“Y â‰¥eâ€“+
â‰¤E eâ€“Y
eâ€“+
= e+ E eâ€“Y .
Now we are in a position to state and to prove Chebyshevâ€™s inequality.
Proposition 7.1.3 (Chebyshevâ€™s inequality). Let X be a random variable with ï¬nite
second moment. Then, if c > 0, it follows that
P{|X â€“ EX| â‰¥c} â‰¤VX
c2 .
(7.2)

266
7 Limit Theorems
Proof: Setting Y := |X â€“ EX|2, we have Y â‰¥0 and EY = VX. Now apply inequality (7.1)
to Y with + = c2. This leads to
P{|X â€“ EX| â‰¥c} = P{|X â€“ EX|2 â‰¥c2} = P{Y â‰¥c2} â‰¤EY
c2 = VX
c2 ,
and estimate (7.2) is proven.
âˆ
Interpretation: Inequality (7.2) quantiï¬es the interpretation of VX as a measure for the
dispersion of X. The smaller VX, the less the values of X vary around its expected
value EX.
Remark 7.1.4. Another way to formulate inequality (7.2) is as follows. If * > 0, then
P{|X â€“ EX| â‰¥* (VX)1/2} â‰¤1
*2 .
To see this, apply inequality (7.2) with c = * (VX)1/2.
Example 7.1.5. Roll a fair die n times. We are interested in the relative frequency of the
occurrence of the event A := {6}. Recall that this frequency was deï¬ned in eq. (1.1).
Moreover, we claimed in this section that limnâ†’âˆrn(A) = P(A) =
1
6. Is it possible to
estimate the probability for |rn(A) â€“ 1
6| being bigger than some given c > 0 ?
Answer: Deï¬ne the random variable X as the absolute frequency of the occurrence
of A, that is, we have X = k for some k = 0, . . . , n provided that A occurred exactly
k times. Then X is binomial distributed with parameters n and p = 1/6. To see this,
deï¬ne â€œsuccessâ€ as appearance of â€œ6.â€ Consequently, the relative frequency can be
represented as rn(A) = X
n . An application of eqs. (5.7) and (5.33) gives
E rn(A) = 1
n EX = np
n = p = 1
6
and
V rn(A) = np(1 â€“ p)
n2
=
5
36 n .
Thus, inequality (7.2) leads to
P
5....rn(A) â€“ 1
6
.... â‰¥c
6
â‰¤
5
36 c2 n .
If, for example, n = 103, and if we choose c = 1/36, then Chebyshevâ€™s inequality yields
P
5 5
36 < r103(A) < 7
36
6
â‰¥1 â€“ 9
50 = 0.82 .
For the absolute frequency this means
P{139 â‰¤a103 â‰¤194} â‰¥0.82 .

7.1 Laws of Large Numbers
267
Let us interpret the result. Suppose we roll a fair die 1000 times. Then, with a
probability of at least 82%, the frequency of â€œ6â€ will be between 139 and 194.
Let us present a second quite similar example.
Example 7.1.6. Roll a fair die n times and let Sn be the sum of the n results. Then Sn =
X1+ â‹¯+Xn, where X1, . . . , Xn are uniformly distributed on {1, . . . , 6} and independent.
By Example 5.2.17 we know that
ESn = EX1 + â‹¯+ EXn = 7n
2
and
VSn = VX1 + â‹¯+ VXn = 35n
12 ,
hence
E
Sn
n

= 7
2
and
V
Sn
n

= 35
12n .
An application of inequality (7.2) leads then to
P
5....
Sn
n â€“ 7
2
.... â‰¥c
6
â‰¤
35
12nc2 .
For example, if n = 103 and c is chosen as c = 0.1, then
P
5
3.4 < S103
103 < 3.6
6
â‰¥0.709 .
The interpretation of this result is as in the previous example. With a probability larger
than 70% the sum of 1000 rolls of a fair die will be a number between 3400 and 3600.
7.1.2
â‹†Inï¬nite Sequences of Independent Random Variables
Whenever one wants to describe the limit behavior of random variables or random
events, one needs a model for the inï¬nite performance of random experiments. Other-
wise, we cannot investigate limits or other related quantities. This is comparable with
similar investigations in Calculus. In order to analyze limits, inï¬nite sequences are
necessary, not ï¬nite ones. Thus, for the examination of limits of random variables we
need an inï¬nite sequence X1, X2, . . . of random variables, which are, on one hand, in-
dependent in the sense of Deï¬nition 4.3.4 and, on the other hand, possess some given
probability distributions.
Example 7.1.7. In order to describe the inï¬nite tossing of a fair coin we need inde-
pendent random variables X1, X2, . . . such that P{Xj = 0} = P{Xj = 1} = 1
2. Or, similarly,
for a model of rolling a die inï¬nitely often we need inï¬nitely many independent
random variables all uniformly distributed on {1, . . . , 6}.

268
7 Limit Theorems
In Proposition 4.3.3 we presented the construction of independent (Xj)âˆ
j=1 distrib-
uted according to B1,1/2. This technique can be extended to more general sequences
of random variables, but it is quite complicated. Another, much smarter way is to use
so-called inï¬nite product measures. Their existence follows by a deep theorem due
to A. N. Kolmogorov. As a consequence one gets the following result, which cannot
be proven within the framework of this book. We refer to [Kho07], Chapter 5, Â§2, for
further reading.
Proposition 7.1.8. Let P1, P2, . . . be arbitrary probability measures on (R, B(R)). Then
there are a probability space (K, A, P) and an inï¬nite sequence of random variables
Xj : K â†’R such that the following holds.
1.
The probability distribution of Xj is Pj, j = 1, 2, . . . . That is, for all j â‰¥1 and all
B âˆˆB(R) it follows that
P{Xj âˆˆB} = Pj(B) .
2.
The random variables X1, X2, . . . are independent in the sense of Deï¬nition 4.3.4.
This says, for all n â‰¥1 and all Bj âˆˆB(R) it follows that
P{X1 âˆˆB1, . . . , Xn âˆˆBn} = P{X1 âˆˆB1} â‹¯P{Xn âˆˆBn} = P1(B1) â‹¯Pn(Bn) .
Of special interest is the case P1 = P2 = â‹¯= P0 for a certain probability measure P0
on R. Then the previous proposition implies the following.
Corollary 7.1.9. Given an arbitrary probability measure P0 on B(R), there are random
variables X1, X2, . . . such that for all n â‰¥1 and all Bj âˆˆB(R)
P{X1 âˆˆB1, . . . , Xn âˆˆBn} = P0(B1) â‹¯P0(Bn) .
Example 7.1.10. Choosing as P0 the uniform distribution on [0, 1], the previous corol-
lary ensures the existence of (independent) random variables X1, X2, . . . such that for
all n â‰¥1 and all 0 â‰¤aj < bj â‰¤1
P{a1 â‰¤X1 â‰¤b1, . . . , an â‰¤Xn â‰¤bn} =
n
%
j=1
(bj â€“ aj) .
The sequence X1, X2, . . . models the independent choosing of inï¬nitely many num-
bers uniformly distributed in [0, 1].
Remark 7.1.11. One may ask whether the kind of independence in Deï¬nition 4.3.4 suf-
ï¬ces for later purposes. Recall, we only require X1, . . . , Xn to be independent for all
(ï¬nite) n â‰¥1. Maybe one would expect a condition that involves the whole inï¬nite se-
quence, not only a ï¬nite part of it. The answer is that such a condition for the whole

7.1 Laws of Large Numbers
269
sequence is a consequence of Deï¬nition 4.3.4. Namely, if B1, B2, . . . are Borel sets in
R, then, by the continuity of probability measures from above, it follows that
P{X1 âˆˆB1, X2 âˆˆB2, . . . } = lim
nâ†’âˆP{X1 âˆˆB1, . . . , Xn âˆˆBn}
= lim
nâ†’âˆP{X1 âˆˆB1} â‹¯P{Xn âˆˆBn} = lim
nâ†’âˆ
n
%
j=1
P{Xj âˆˆBj} =
âˆ
%
j=1
P{Xj âˆˆBj} .
In particular, this implies
P{a1 â‰¤X1 â‰¤b1, a2 â‰¤X2 â‰¤b2, . . . } =
âˆ
%
j=1
P{aj â‰¤Xj â‰¤bj} .
(7.3)
Example 7.1.12. Let X1, X2, . . . be a sequence of independent E+-distributed random
variables for some + > 0. Given real numbers !j > 0, we ask for the probability of
P{X1 â‰¤!1, X2 â‰¤!2, . . . } .
Answer: If we apply eq. (7.3) with aj = 0 and with bj = !j, then we get
P{X1 â‰¤!1, X2 â‰¤!2, . . . } =
âˆ
%
j=1
P{Xj â‰¤!j} =
âˆ
%
j=1

1 â€“ eâ€“+!j

.
Of special interest are sequences (!j)jâ‰¥1 such that the inï¬nite product converges, that
is, for these sequences (!j)jâ‰¥1 we have ,âˆ
j=1

1 â€“ eâ€“+!j

> 0. This happens if and only if
ln
â›
â
âˆ
%
j=1

1 â€“ eâ€“+!j

â
â =
âˆ

j=1
ln[1 â€“ eâ€“+!j] > â€“âˆ.
(7.4)
Because of
lim
xâ†’0
ln(1 â€“ x)
â€“x
= 1 ,
by the limit comparison test for inï¬nite series, condition (7.4) holds if and only if
âˆ

j=1
eâ€“+!j < âˆ.
If, for example, !j = c â‹…ln(j + 1) for some c > 0, then
âˆ

j=1
eâ€“+!j =
âˆ

j=1
1
(j + 1)+c .

270
7 Limit Theorems
This sum is known to be ï¬nite if and only if +c > 1, that is, if c > 1/+.
Another way to formulate this observation is as follows. It holds
P

sup
jâ‰¥1
Xj
ln(j + 1) â‰¤c
$
= P
C
Xj â‰¤c ln(j + 1) , âˆ€j â‰¥1
D
=
âˆ
%
j=1

1 â€“
1
(j + 1)+c

,
and this probability is positive if and only if c > 1/+.
7.1.3
â‹†Borelâ€“Cantelli Lemma
The aim of this section is to present one of the most useful tools for the investigation of
the limit behavior of inï¬nite sequences of random variables and events. Let (K, A, P)
be a probability space and let A1, A2, . . . be a sequence of events in A. Then two typical
questions arise. What is the probability that there exists some n âˆˆN such that all
events Am with m â‰¥n occur? The other related question asks for the probability that
inï¬nitely many of the events An occur.
To explain why these questions are of interest, let us once more regard Example
4.1.7 of the random walk. Here Sn denotes the integer where the particle is located after
n random jumps. For example, letting An := {9 âˆˆK : Sn(9) > 0}, then the existence
of an n âˆˆN, such that Am occurs for all m â‰¥n, says that the particle from a certain
(random) moment attains only positive numbers and never goes back to the negative
ones. Or, if we investigate the events Bn := {9 âˆˆK : Sn(9) = 0}, then the Bns occur
inï¬nitely often if and only if the particle returns to zero inï¬nitely often. Equivalently,
there are (random) n1 < n2 < â‹¯with Snj(9) = 0.
To formulate the two previous questions more precisely, let us introduce the
following two events.
Deï¬nition 7.1.13. Let A1, A2, . . . be subsets of K. Then
lim inf
nâ†’âˆAn :=
âˆ
	
n=1
âˆ

m=n
Am
and
lim sup
nâ†’âˆ
An :=
âˆ

n=1
âˆ
	
m=n
Am
are called the lower and the upper limit of the Ans.
Remark 7.1.14. Let us characterize when the lower and the upper limit occur.
1.
An element 9 âˆˆK belongs to lim infnâ†’âˆAn if and only if there is an n âˆˆN such
that 9 âˆˆâˆ
m=n Am, that is, if it is an element of Am for m â‰¥n. In other words, the
lower limit occurs if there is an1 n âˆˆN such that after n the events Am always occur.
1 Note that this n is random, that is, it may depend on the chosen 9 âˆˆK.

7.1 Laws of Large Numbers
271
Therefore, we say that lim infnâ†’âˆAn occurs if the Ans ï¬nally always occur. Thus,
P{9 âˆˆK : âˆƒn s.t. 9 âˆˆAm , m â‰¥n} = P

lim inf
nâ†’âˆAn

.
2.
An element 9 âˆˆK belongs to lim supnâ†’âˆAn if and only if for each n âˆˆN there is
an m â‰¥n such that 9 âˆˆAm. But this is nothing else as to say that the number of
Ans with 9 âˆˆAn is inï¬nite. Therefore, the upper limit consists of those elements
for which we have inï¬nitely often 9 âˆˆAn. Note that also these events may be
different for different 9s. Thus,
P{9 âˆˆK : 9 âˆˆAn for inï¬nitely many n} = P

lim sup
nâ†’âˆ
An

.
Example 7.1.15. Suppose a fair coin is labeled on one side with â€œ0â€ and on the
other side with â€œ1.â€ We toss it inï¬nitely often. Let An occur if the nth toss is â€œ1.â€
Then lim infnâ†’âˆAn occurs if after a certain number of tosses â€œ1â€ always shows up.
On the other hand, lim supnâ†’âˆAn occurs if and only if the number â€œ1â€ appears
inï¬nitely often.
Let us formulate and prove some easy properties of the lower and upper limit.
Proposition 7.1.16. If A1, A2, . . . are subsets of K, then
(1)
lim inf
nâ†’âˆAn âŠ†lim sup
nâ†’âˆ
An ,
(2)

lim sup
nâ†’âˆ
An

c
= lim inf
nâ†’âˆAc
n
and

lim inf
nâ†’âˆAn

c
= lim sup
nâ†’âˆ
Ac
n .
Proof: We prove these properties in the interpretation of the lower and upper limit
given in Remark 7.1.14.
Suppose that 9 âˆˆlim infnâ†’âˆAn. Then for some n â‰¥1 it follows that 9 âˆˆAm,
m â‰¥n. Of course, then the number of events with 9 âˆˆAn is inï¬nite, which implies
9 âˆˆlim supnâ†’âˆAn. This proves (1).
Observe that we have 9 âˆ‰lim supnâ†’âˆAn if and only if 9 âˆˆAn for only ï¬nitely
many n âˆˆN. Equivalently, there is an n â‰¥1 such that whenever m â‰¥n, then 9 âˆ‰Am, or,
that 9 âˆˆAc
m. In other words, this happens if and only if 9 âˆˆlim infnâ†’âˆAc
n. This proves
the left-hand identity in (2). The second one follows by the same arguments. One may
also prove this by applying the left-hand identity with Ac
n.
âˆ
Before we can formulate the main result in this section, we have to deï¬ne when an
inï¬nite sequence of events is independent.

272
7 Limit Theorems
Deï¬nition 7.1.17. A sequence of events A1, A2, . . . in A is said to be independent
provided that for all n â‰¥1 the events A1, . . . , An are independent in the sense of
Deï¬nition 2.2.12.
Remark 7.1.18. Using the method for the proof of eq. (7.3) one may deduce the
following â€œinï¬niteâ€ version of independence. For independent A1, A2, . . . follows that
P
 âˆ

n=1
An

=
âˆ
%
n=1
P(An) .
Remark 7.1.19. According to Proposition 3.6.7, the independence of random variables
and events are linked as follows.
The random variables X1, X2, . . . are independent in the sense of Deï¬nition 4.3.4
if and only if for all Borel sets B1, B2, . . . in R the preimages Xâ€“1
1 (B1), Xâ€“1
2 (B2), . . . are
independent events as introduced in Deï¬nition 7.1.17.
Now we are in the position to state and prove the main result of this section.
Proposition 7.1.20 (Borelâ€“Cantelli lemma). Let (K, A, P) be a probability space and let
An âˆˆA, n = 1, 2, . . . .
1.
If âˆ
n=1 P(An) < âˆ, then this implies
P(lim sup
nâ†’âˆ
An) = 0 .
(7.5)
2.
For independent A1, A2, . . . the following is valid. If âˆ
n=1 P(An) = âˆ, then
P(lim sup
nâ†’âˆ
An) = 1 .
Proof: We start with proving the ï¬rst assertion. Thus, take arbitrary subsets An âˆˆA
satisfying âˆ
n=1 P(An) < âˆ. Write
lim sup
nâ†’âˆ
An =
âˆ

n=1
Bn
with Bn := âˆ
m=n Am. Since B1 âŠ‡B2 âŠ‡â‹¯, property (7) in Proposition 1.2.1 applies, and
together with (5) in the same proposition this leads to
P(lim sup
nâ†’âˆ
An) = lim
nâ†’âˆP(Bn) â‰¤lim inf
nâ†’âˆ
âˆ

m=n
P(Am) .
(7.6)

7.1 Laws of Large Numbers
273
If !1, !2, . . . are non-negative numbers with âˆ
n=1 !n < âˆ, then it is known that
âˆ
m=n !m â†’0 as n â†’âˆ. Applying this observation to !n = P(An), assertion (7.5) is
a direct consequence of estimate (7.6). Thus, the ï¬rst part is proven.
To prove the second assertion we investigate the probability of the complementary
event. Here we have
(lim sup
nâ†’âˆ
An)c =
âˆ
	
n=1
âˆ

m=n
Ac
m .
An application of (5) in Proposition 1.2.1 implies
P

(lim sup
nâ†’âˆ
An)c
â‰¤
âˆ

n=1
P
 âˆ

m=n
Ac
m

.
(7.7)
Fix n âˆˆN and for k â‰¥n set Bk := k
m=n Ac
m. Then Bn âŠ‡Bn+1 âŠ‡â‹¯, hence by property (7)
in Proposition 1.2.1 it follows that
P
 âˆ

m=n
Ac
m

= P
 âˆ

k=n
Bk

= lim
kâ†’âˆP(Bk) = lim
kâ†’âˆ
k
%
m=n
(1 â€“ P(Am)) .
Here we used in the last step that, according to Proposition 2.2.15, the events
Ac
1, Ac
2, . . . are independent as well. Next we apply the elementary inequality
1 â€“ x â‰¤eâ€“x ,
0 â‰¤x â‰¤1 ,
for x = P(Am), and because of âˆ
m=n P(Am) = âˆwe arrive at
P
 âˆ

m=n
Ac
m

â‰¤lim sup
kâ†’âˆ
exp

â€“
k

m=n
P(Am)

= 0 .
Plugging this into estimate (7.7) ï¬nally implies
P

(lim sup
nâ†’âˆ
An)c
= 0 ,
hence
P(lim sup
nâ†’âˆ
An) = 1
as asserted.
âˆ
Remark 7.1.21. The second assertion in Proposition 7.1.20 remains valid under the
weaker condition of pairwise independence. But then the proof becomes more
complicated.

274
7 Limit Theorems
Corollary 7.1.22. Let An âˆˆA be independent events. Then the following are equivalent.
P(lim sup
nâ†’âˆ
An) = 0 â‡”
âˆ

n=1
P(An) < âˆ
P(lim sup
nâ†’âˆ
An) = 1 â‡”
âˆ

n=1
P(An) = âˆ.
Example 7.1.23. Let (Un)nâ‰¥1 be a sequence of independent random variables, uni-
formly distributed on [0, 1]. Given positive real numbers (!n)nâ‰¥1, we deï¬ne events An
by setting An := {Un â‰¤!n}. Since the Uns are independent, so are the events An, and
Corollary 7.1.22 applies. Because of P(An) = !n this leads to
P {Un â‰¤!n inï¬nitely often} =

0 : âˆ
n=1 !n < âˆ
1 : âˆ
n=1 !n = âˆ
or, equivalently, to
P {Un > !n ï¬nally always} =

0 : âˆ
n=1 !n = âˆ
1 : âˆ
n=1 !n < âˆ.
For example, we have
P
C
Un â‰¤1/n inï¬nitely often
D
= 1
and
P
C
Un â‰¤1/n2 inï¬nitely often
D
= 0 .
Example 7.1.24. Let (Xn)nâ‰¥1 be a sequence of independent N(0, 1)-distributed random
variables and let cn > 0. What probability does the event, to observe inï¬nitely often
{|Xn| â‰¥cn} , possess?
Answer: It holds
âˆ

n=1
P{|Xn| â‰¥cn} =
2
âˆš
20
âˆ

n=1
âˆ

cn
eâ€“x2/2 dx =
2
âˆš
20
âˆ

n=1
>(cn) ,
where
>(t) :=
âˆ

t
eâ€“x2/2 dx ,
t âˆˆR .
Setting 8(t) := tâ€“1 eâ€“t2/2, t > 0, then
>â€²(t) = â€“eâ€“t2/2
and
8â€²(t) = â€“

1 + 1
t2

eâ€“t2/2 ,

7.1 Laws of Large Numbers
275
hence lâ€™HÃ´pitalâ€™s rule implies
lim
tâ†’âˆ
>â€²(t)
8â€²(t) = 1 ,
thus
lim
tâ†’âˆ
>(t)
8(t) = 1 .
The limit comparison test for inï¬nite series tells us that âˆ
n=1 >(cn) < âˆif and only if
âˆ
n=1 8(cn) < âˆ. Thus, by the deï¬nition of 8 the following are equivalent.
âˆ

n=1
P{|Xn| â‰¥cn} < âˆ
â‡â‡’
âˆ

n=1
eâ€“c2n/2
cn
< âˆ.
In other words, we have
P{|Xn| â‰¥cn inï¬nitely often} =

0
1
â‡â‡’
âˆ

n=1
eâ€“c2n/2
cn
< âˆ
= âˆ
For example, if cn = c
âˆš
ln n for some c > 0, then
âˆ

n=1
eâ€“c2n/2
cn
= 1
c
âˆ

n=1
1
nc2/2 âˆš
ln n
< âˆ
if and only if c >
âˆš
2. In particular, this yields the following interesting fact:
P{|Xn| â‰¥
âˆš
2 ln n inï¬nitely often} = 1 ,
while for each c > 2
P{|Xn| â‰¥
âˆš
c ln n inï¬nitely often} = 0 .
From this we derive
P
5
9 âˆˆK : lim sup
nâ†’âˆ
|Xn(9)|
âˆš
ln n
=
âˆš
2
6
= 1 .
Example 7.1.25. In a lottery 6 of 49 numbers are randomly chosen. Find the probabil-
ity to have inï¬nitely often the six chosen numbers on your lottery ticket.
Answer: Let An be the event to have in the nth drawing the six chosen numbers on
the ticket. We saw (compare Example 1.4.3) that
P(An) =
1
49
6
 := $ > 0 .

276
7 Limit Theorems
Consequently, it follows âˆ
n=1 P(An)
=
âˆ, and since the Ans are independent,
Proposition 7.1.20 implies
P{An inï¬nitely often} = 1 .
Therefore, the event to win inï¬nitely often has probability 1. One does only not play
long enough!
Remark 7.1.26. Corollary 7.1.22 shows particularly that for independent Ans either
P(lim sup
nâ†’âˆ
An) = 0
or
P(lim sup
nâ†’âˆ
An) = 1 .
Because of Proposition 7.1.16 the same is valid for the lower limit. Here operate so-
called 0-1 laws, which, roughly spoken, assert the following. Whenever the occurrence
or nonoccurrence of an event is independent of the ï¬rst ï¬nitely many results, then
such events occur either with probability 0 or 1. For example, the occurrence or nonoc-
currence of the lower or upper limit is completely independent of what had happened
during the ï¬rst n results, n â‰¥1.
7.1.4 Weak Law of Large Numbers
Given random variables X1, X2, . . . let
Sn := X1 + â‹¯+ Xn
(7.8)
be the sum of the ï¬rst n values. One of the most important questions in Probability
Theory is that about the behavior of Sn as n â†’âˆ. Suppose we play a series of games
and Xj denotes the loss or the gain in game j â‰¥1. Then Sn is nothing else than the total
loss or gain after n games. Also recall the random walk presented in Example 4.1.7. Set
Xj = â€“1 if in step j the particle jumps to the left and Xj = 1, otherwise. Then Sn is the
point in Z where the particle is located after n jumps.
Let us come back to the general case. We are given arbitrary independent and
identical distributed random variables X1, X2, . . . . Recall that â€œidentically distributedâ€
says that they possess all the same probability distribution. Set Sn = X1 + â‹¯+ Xn. A
ï¬rst result gives some information about the behavior of the arithmetic mean Sn/n
as n â†’âˆ.
Proposition 7.1.27 (Weak law of large numbers). Let X1, X2, . . . be independent
identically distributed random variables with (common) expected value , âˆˆR. If % > 0,
then it follows that
lim
nâ†’âˆP
5....
Sn
n â€“ ,
.... â‰¥%
6
= 0 .

7.1 Laws of Large Numbers
277
Proof: We prove the result with only an additional condition, namely that X1, and
hence all Xj, possess a ï¬nite second moment. The result remains true without this
condition, but then its proof becomes signiï¬cantly more complicated.
From (3) in Proposition 5.1.36 we derive
E
Sn
n

= ESn
n
= E(X1 + â‹¯+ Xn)
n
= EX1 + â‹¯+ EXn
n
= n,
n = , .
Furthermore, by the independence of the Xjs, property (iv) in Proposition 5.2.15 also
gives
V
Sn
n

= VSn
n2
= VX1 + â‹¯+ VXn
n2
= VX1
n
.
Consequently, inequality (7.2) implies
P
5....
Sn
n â€“ ,
.... â‰¥%
6
â‰¤V(Sn/n)
%2
= VX1
n%2 ,
and the desired assertion follows by
lim sup
nâ†’âˆ
P
5....
Sn
n â€“ ,
.... â‰¥%
6
â‰¤lim
nâ†’âˆ
VX1
n%2 = 0 .
âˆ
Remark 7.1.28. The type of convergence appearing in Proposition 7.1.27 is usu-
ally called convergence in probability. More precisely, given random variables
Y1, Y2, . . . , they converge in probability to some random variable Y provided that for
each % > 0
lim
nâ†’âˆP{|Yn â€“ Y| â‰¥%} = 0 .
Hence, in this language the weak law of large numbers asserts that Sn/n converges in
probability to a random variable Y, which is the constant ,.
Interpretation of Proposition 7.1.27 : Fix % > 0 and deï¬ne events An, n â‰¥1, by
An :=
5
9 âˆˆK :
....
Sn(9)
n
â€“ ,
.... < %
6
.
Then Proposition 7.1.27 implies limnâ†’âˆP(An) = 1. Hence, given $ > 0, then there is an
n0 = n0(%, $) such that P(An) â‰¥1â€“$ whenever n â‰¥n0. In other words, if n is sufï¬ciently
large, then with high probability (recall, , is the expected value of the Xjs)
, â€“ % â‰¤1
n
n

j=1
Xj â‰¤, + % .

278
7 Limit Theorems
This conï¬rms once more the interpretation of the expected value as (approximat-
ive) arithmetic mean of the observed values, provided that we execute the same
experiment arbitrarily often and the results do not depend on each other.
7.1.5 Strong Law of Large Numbers
Proposition 7.1.27 does not imply Sn/n â†’, in the usual sense. It only asserts the
convergence of Sn/n in probability, which, in general, does not imply a pointwise
convergence. The following theorem shows that, nevertheless, a strong type of con-
vergence takes place. The proof of this result is much more complicated than that of
Proposition 7.1.27. Therefore, we cannot present it in the scope of this book, and we
refer to [Dur10], Section 2.4, for a proof.
Proposition 7.1.29 (Strong law of large numbers). Let X1, X2, . . . be a sequence of in-
dependent identically distributed random variables with expected value , = EX1. If Sn
is deï¬ned by eq. (7.8), then
P
5
9 âˆˆK : lim
nâ†’âˆ
Sn(9)
n
= ,
6
= 1 .
Remark 7.1.30. Given random variables Y1, Y2, . . . and Y, one says that the Yns
converge to Y almost surely, if
P

lim
nâ†’âˆYn = Y

= P

9 âˆˆK : lim
nâ†’âˆYn(9) = Y(9)

= 1 .
Thus, Proposition 7.1.29 asserts that Sn/n converges almost surely to a random variable
Y, which is constant ,.
Remark 7.1.31. Proposition 7.1.29 allows the following interpretation. There exists a
subset K0 in the sample space K with P(K0) = 1 such that for all 9 âˆˆK0 and all % > 0,
there is an n0 = n0(%, 9) with
....
Sn(9)
n
â€“ ,
.... < %
whenever n â‰¥n0.
In other words, with probability one the following happens: given % > 0, then
there is a certain n0 depending on 9, hence being random, such that for n â‰¥n0 the
arithmetic mean Sn/n is in an %-neighborhood of , and never leaves it again.
Let us emphasize once more that Sn/n is random, hence Sn/n may attain different
values for a different series of experiments. Nevertheless, starting from a certain point,
which may be different for different experiments, the arithmetic mean of the ï¬rst n
results will be in (, â€“ %, , + %).

7.1 Laws of Large Numbers
279
When we introduced probability measures in Section 1.1.3, we claimed that the
number P(A) may be regarded as limit of the relative frequencies of the occurrence of
A. As a ï¬rst consequence of Proposition 7.1.29 we show that this is indeed true.
Proposition 7.1.32. Suppose a random experiment is described by a probability space
(K, A, P). Execute this experiment arbitrarily often. Given an event A âˆˆA, let rn(A) be
the relative frequency of A in n trials as deï¬ned in eq. (1.1). Then almost surely
lim
nâ†’âˆrn(A) = P(A) .
Proof: Deï¬ne random variables X1, X2, . . . as follows. Set Xj = 1 if A occurs in trial
j, while Xj = 0 otherwise. Since the experiments are executed independently of each
other, the Xjs are independent as well. Moreover, we execute every time exactly the
same experiment, hence the Xjs are also identically distributed.
By the deï¬nition of the Xjs,
Sn
n = rn(A) .
Thus, it remains to evaluate , = EXj. To this end observe that the Xjs are B1,p-
distributed with success probability p = P(A). Recall that Xj = 1 if and only if A occurs
in experiment j, and since the experiment is described by (K, A, P), the probability for
Xj being one is P(A). Consequently, EXj = P(A).
Proposition 7.1.29 now implies that almost surely
lim
nâ†’âˆrn(A) = lim
nâ†’âˆ
Sn
n = EX1 = P(A) .
This completes the proof.
âˆ
What does happen in the case that the Xjs do not possess an expected value? Does then
Sn/n converge nevertheless? If this is so, could we take this limit as a â€œgeneralizedâ€
expected value? The next proposition shows that such an approach does not work.
Proposition 7.1.33. Let X1, X2, . . . be independent and identically distributed with
E|X1| = âˆ. Then it follows that
P
5
9 âˆˆK : Sn(9)
n
diverges
6
= 1 .
For example, if we take an independent sequence (Xj)jâ‰¥1 of Cauchy distributed random
variables, then their arithmetic means Sn/n will diverge almost surely.

280
7 Limit Theorems
Remark 7.1.34. Why does one need a weak law of large numbers when there exists
a strong one? This question is justiï¬ed, and in fact, in the situation described in
this book the weak law is a consequence of the strong one, thus, it is not necessarily
needed.
The situation is different if one investigates independent, but not necessar-
ily identically distributed, random variables. Then there are sequences X1, X2, . . .
satisfying the weak law but not the strong one.2
Let us state two applications of Proposition 7.1.29, one taken from Numerical Mathem-
atics, the other from Number Theory.
Example 7.1.35 (Monte Carlo method for integrals). Suppose we are given a quite
â€œcomplicatedâ€ function f : [0, 1]n â†’R. The task is to ï¬nd the numerical value of

[0,1]n
f(x) dx =
1

0
â‹¯
1

0
f(x1, . . . , xn) dxn â‹¯dx1 .
For large n this can be a highly nontrivial problem. One way to overcome this difï¬culty
is to use a probabilistic approach that is based on the strong law of large numbers.
To this end, choose an independent sequence âƒ—U1, âƒ—U2, . . . of random vectors
uniformly distributed on [0, 1]n. For example, such a sequence can be constructed
as follows. Take independent U1, U2, . . . uniformly distributed on3 [0, 1] and build
random vectors by âƒ—U1 = (U1, . . . , Un), âƒ—U2 = (Un+1, . . . , U2n), and so on.
Proposition 7.1.36.
As above, let âƒ—U1, âƒ—U2, . . . be independent random vectors uni-
formly distributed on [0, 1]n. Given an integrable function f : [0, 1]n â†’R, then, with
probability one,
lim
Nâ†’âˆ
1
N
N

j=1
f
âƒ—Uj

=

[0,1]n
f(x) dx .
Proof: Set Xj := f(âƒ—Uj), j = 1, 2, . . . . By construction, the Xjs are independent and
identically distributed random variables. Proposition 3.6.18 implies (compare also
Example 3.6.21) that the distribution densities of the random vectors âƒ—Uj are given by
p(x) =

1 : x âˆˆ[0, 1]n
0 : x âˆ‰[0, 1]n .
2 In the case of nonidentically distributed Xjs one investigates if 1
n
n
j=1(Xj â€“ EXj) converges to zero
either in probability (weak law) or almost surely (strong law).
3 Use the methods developed in Section 4.4 to construct such Ujs.

7.1 Laws of Large Numbers
281
As already mentioned in Remark 5.3.5, formula (5.38), stated for a function of two
variables, also holds for functions of n variables, n â‰¥1 arbitrary. This implies
EX1 = Ef
âƒ—U1

=

Rn
f(x) p(x) dx =

[0,1]n
f(x) dx .
Thus, Proposition 7.1.29 applies and leads to
P
â§
âªâ¨
âªâ©
lim
Nâ†’âˆ
1
N
N

j=1
f
âƒ—Uj

=

[0,1]n
f(x) dx
â«
âªâ¬
âªâ­
= P
â§
â¨
â©lim
Nâ†’âˆ
1
N
N

j=1
Xj = EX1
â«
â¬
â­= 1
as asserted.
âˆ
Remark 7.1.37. The numerical application of the preceding proposition is as follows.
Choose independent numbers u(j)
i , 1 â‰¤i â‰¤n, 1 â‰¤j â‰¤N, uniformly distributed on [0, 1]
and set
RN(f) := 1
N
N

j=1
f

u(j)
1 , . . . , u(j)
n

.
Proposition 7.1.36 asserts that RN(f) converges almost surely to
#
[0,1]n
f(x) dx. Thus, if
N â‰¥1 is large, then RN(f) may be taken as approximative value for
#
[0,1]n
f(x) dx.
If we apply Proposition 7.1.36 to the indicator function of a Borel set B âŠ†[0, 1]n,
that is, we choose f = 1B with 1B as in Deï¬nition 3.6.14, then with probability 1 it
follows that
voln(B) =

[0,1]n
1B(x) dx = lim
Nâ†’âˆ
1
N
N

j=1
1B(âƒ—Uj) = lim
Nâ†’âˆ
#{j â‰¤N : âƒ—Uj âˆˆB}
N
.
This provides us with a method to determine the volume voln(B), even for quite
â€œcomplicatedâ€ Borel sets B âŠ†Rn.
Example 7.1.38 (Normal numbers). As we saw in Section 4.3.1, each x âˆˆ[0, 1) admits a
representation as binary fraction x = 0.x1x2 â‹¯with xj âˆˆ{0, 1}. Take some ï¬xed x âˆˆ[0, 1)
with binary representation x = 0.x1x2 â‹¯. Then one may ask whether in the binary
representation of x one of the numbers 0 or 1 occurs more frequently than the other
one. Or do both numbers possess the same frequency, at least on average?
To investigate this question, for n âˆˆN set
a0
n(x) := #{k â‰¤n : xk = 0}
and
a1
n(x) := #{k â‰¤n : xk = 1} ,
x = 0.x1x2 â‹¯
Thus, a0
n(x) is the frequency of the number 0 among the ï¬rst n positions in the
representation of x.

282
7 Limit Theorems
Deï¬nition 7.1.39. A number x âˆˆ[0, 1) is said to be normal (with respect to
base 2) if
lim
nâ†’âˆ
a0
n(x)
n
= lim
nâ†’âˆ
a1
n(x)
n
= 1
2 .
In other words, a number x âˆˆ[0, 1) is normal with respect to base 2 if, on average, in
its binary representation the frequency of 0, and hence also of 1, equals 1/2. Are there
many normal numbers as, for example, x = 0.0101010 â‹¯or maybe only a few ones?
Answer gives the next proposition.
Proposition 7.1.40. Let P be the uniform distribution on [0, 1]. Then there is a subset
M âŠ†[0, 1) with P(M) = 1 such that all x âˆˆM are normal with respect to base 2.
Proof: Deï¬ne random variables Xk : [0, 1) â†’R, k = 0, 1, . . . , by Xk(x) := xk whenever
x = 0.x1x2 â‹¯. Proposition 4.3.3 tells us that the Xks are independent with P{Xk = 0} =
1/2 and P{Xk = 1} = 1/2. Recall that the underlying probability measure P on [0, 1] is
the uniform distribution. By the deï¬nition of the Xks it follows that
Sn(x) := X1(x) + â‹¯+ Xn(x) = #{k â‰¤n : Xk(x) = 1} = a1
n(x) .
Since EX1 = 1/2, Proposition 7.1.29 implies the existence of a subset M âŠ†[0, 1) with
P(M) = 1 such that for x âˆˆM it follows that
lim
nâ†’âˆ
a1
n(x)
n
= lim
nâ†’âˆ
Sn(x)
n
= EX1 = 1
2 .
Since a0
n(x) = n â€“ a1
n(x), this completes the proof.
âˆ
Remark 7.1.41. The previous considerations do not depend on the fact that the base of
the representation was 2. It extends easily to representations with respect to any base
b â‰¥2. Here, the deï¬nition of normal numbers has to be extended slightly. Fix b â‰¥2.
Each x âˆˆ[0, 1) admits the representation x = 0.x1x2 â‹¯where xj âˆˆ{0, . . . , bâ€“1} provided
that x = âˆ
k=1
xk
bk . To make this representation unique we do not allow representations
x = 0.x1x2 â‹¯where for some k0 âˆˆN we have xk = b â€“ 1 whenever k â‰¥k0.
Then a number x is said to be normal with respect to the base b â‰¥2 if for all
â„“= 0, . . . b â€“ 1
lim
nâ†’âˆ
#{j â‰¤n : xj = â„“}
n
= 1
b ,
x = 0.x1x2 . . . .
Similar methods as used in the proof of Proposition 7.1.40 show that there is a set
Mb âŠ‚[0, 1] with P(Mb) = 1 such that all x âˆˆMb are normal with respect to base b.

7.2 Central Limit Theorem
283
Letting M = âˆ
b=2 Mb, then property (5) (Booleâ€™s inequality) in Proposition 1.2.1 easily
gives P(M) = 1. Numbers x âˆˆM are completely normal, which says that they are
normal for any base b â‰¥2. Again we see that with respect to the uniform distribution
on [0, 1] almost all numbers are completely normal.
7.2 Central Limit Theorem
Why does the normal distribution play such an important role in Probability The-
ory and why are so many observed random phenomenons normally distributed? The
reason for this is the central limit theorem, which we are going to present in this
section.
Regard a sequence of independent and identically distributed random variables
(Xj)jâ‰¥1 with ï¬nite second moment. As in eq. (7.8) let Sn be the sum of X1, . . . , Xn. For
example, if Xj is the loss or gain in the jth game, then Sn is the total loss or gain after
n games. Which probability distribution does Sn possess? Theoretically, this can be
evaluated by the convolution formulas stated in Section 4.5. But practically, this is
mostly impossible; imagine, we want to determine the distribution of the sum of 100
rolls with a fair die. Therefore, one is very interested in asymptotic statements about
the distribution of Sn.
To get a clue about possible asymptotic distributions of Sn, take independent B1,p-
distributed Xjs. In this case, the distribution of Sn is known to be Bn,p.
For example, if p = 0.4 and n = 30, then P{Sn = k} = Bn,p({k}), k = 0, . . . , 30, may
be described in Fig. 7.1.
The summit of the diagram occurs at k = 12, which is the expected value of S30.
Enlarging the number of trials leads to a shift of the summit to the right. At the same
time, the height of the summit becomes smaller.
The shape of the diagram in Figure 7.1 lets us suggest that sums of independ-
ent, identically distributed random variables are â€œalmostâ€ normally distributed. If
this is so, which expected value and which variance would the approximating normal
distribution possess?
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
Figure 7.1: Probability mass function of Bn,p, n = 30 and p = 0.4.

284
7 Limit Theorems
Let us investigate this question in the general setting. Thus, we are given a
sequence (Xj)jâ‰¥1 of independent identically distributed random variables with ï¬-
nite second moment and with ,
=
EX1 and 32
=
VX1
>
0. If, as before,
Sn = X1 + â‹¯+ Xn, then
ESn = n,
and
VSn = n32 .
Consequently, if we conjecture that Sn is â€œapproximativeâ€ normally distributed, then
the normalized sum (Sn â€“ n,)/3âˆšn should be â€œapproximativeâ€ N(0, 1)-distributed.
Recall that Propositions 5.1.36 and 5.2.15 imply
E
Sn â€“ n,
3âˆšn

= 0
and
V
Sn â€“ n,
3âˆšn

= 1 .
The question about the possible limit of the normalized sums (Sn â€“ n,)/3âˆšn remained
open for long time. In 1718 Abraham de Moivre investigated the limit behavior for a
special case of binomial distributed random variables. As limit he found some inï¬n-
ite series, not a concrete function. In 1808 the American scientist and mathematician
Robert Adrain published a paper where for the ï¬rst time the normal distribution oc-
curred. A year later, independently of the former work, Carl Friedrich GauÃŸ used the
normal distribution for error estimates. In 1812 Pierre-Simon Laplace proved that the
normalized sums of independent binomial distributed random variables approximate
the normal distribution. Later on, Andrei Andreyevich Markov, Aleksandr Mikhail-
ovich Lyapunov, Jarl Waldemar Lindeberg, Paul LÃ©vy, and other mathematicians
continued the work of De Moivre and Laplace. In particular, they showed that the nor-
mal distribution occurs always as a limit, not only for binomial distributed random
variables. The only assumption is that the random variables possess a ï¬nite second
moment. We refer to the very interesting book [Fis11] for further reading about the
history of normal approximation.
It remains the question in which sense does (Sn â€“ n,)/3âˆšn converge to the stand-
ard normal distribution. To answer this we have to introduce the concept of the
convergence in distribution.
Deï¬nition 7.2.1. Let Y1, Y2, . . . and Y be random variables with distribution func-
tions4F1, F2, . . . and F. The sequence (Yn)nâ‰¥1 converges to Y in distribution
provided that
lim
nâ†’âˆFn(t) = F(t)
for all t âˆˆR at which F is continuous.
(7.9)
In this case one writes Yn
D
 â†’Y .
4 Fn(t) = P{Yn â‰¤t}, t âˆˆR.

7.2 Central Limit Theorem
285
Remark 7.2.2. An alternative way to formulate property (7.9) is as follows:
lim
nâ†’âˆP{Yn â‰¤t} = P{Y â‰¤t} for all t âˆˆR with P{Y = t} = 0 .
Without proof we state two other characterizations of convergence in distribution.
Proposition 7.2.3. One has Yn
D
 â†’Y if and only if for all bounded continuous functions
f : R â†’R
lim
nâ†’âˆEf(Yn) = Ef(Y) .
Furthermore, this is also equivalent to
lim sup
nâ†’âˆ
P{Yn âˆˆA} â‰¤P{Y âˆˆA}
for all closed subsets A âŠ†R.
If the distribution function of Y is continuous, that is, we have P{Y = t} = 0 for all
t âˆˆR, then Yn
D
 â†’Y is equivalent to limnâ†’âˆFn(t) = F(t) for all t âˆˆR. Besides, in this
case, the type of convergence is stronger as the next proposition shows.
Proposition 7.2.4. Let Y1, Y2, . . . and Y be random variables with P{Y = t} = 0 for all
t âˆˆR. Then Yn
D
 â†’Y implies that the distribution functions converge uniformly, that is,
lim
nâ†’âˆsup
tâˆˆR
|P{Yn â‰¤t} â€“ P{Y â‰¤t}| = 0 ,
hence also
lim
nâ†’âˆsup
a<b
..P{a â‰¤Yn â‰¤b} â€“ P{a â‰¤Y â‰¤b}
.. = 0 .
We have now all notations and deï¬nitions that are necessary to formulate the central
limit theorem. Mostly, this theorem is proved via properties of so-called character-
istic functions (see Chapter 3 of [Dur10] for such a proof). For alternative proofs using
properties of moment generating functions we refer to [Ros14] and [Gha05].
Proposition 7.2.5 (Central limit theorem). Let (Xj)jâ‰¥1 be a sequence of independent
identically distributed random variables with ï¬nite second moment. Let , be the expec-
ted value of the Xjs and let 32 > 0 be their variance. Then for the sums Sn = X1 + â‹¯+ Xn
it follows that

286
7 Limit Theorems
Sn â€“ n,
3âˆšn
D
 â†’Z .
(7.10)
Here Z is an N(0, 1)-distributed random variable.
Since the limit Z in statement (7.10) is a continuous random variable, Proposition 7.2.4
applies, and the central limit theorem may also be formulated as follows.
Proposition 7.2.6. Suppose (Xj)jâ‰¥1 and Sn are as in Proposition 7.2.5. Then it follows that
lim
nâ†’âˆsup
tâˆˆR
......
P
5Sn â€“ n,
3âˆšn
â‰¤t
6
â€“
1
âˆš
20
t

â€“âˆ
eâ€“x2/2 dx
......
= 0
and
(7.11)
lim
nâ†’âˆsup
a<b
......
P
5
a â‰¤Sn â€“ n,
3âˆšn
â‰¤b
6
â€“
1
âˆš
20
b

a
eâ€“x2/2 dx
......
= 0 .
(7.12)
Remark 7.2.7. Recall that I denotes the distribution function of the standard nor-
mal distribution as introduced in eq. (1.62). Thus, another way to write eq. (7.11) is as
follows:
lim
nâ†’âˆsup
tâˆˆR
....P
5Sn â€“ n,
3âˆšn
â‰¤t
6
â€“ I(t)
.... = 0 .
Our next objective is another reformulation of eq. (7.12). If we set aâ€² = a 3âˆšn + n, and
bâ€² = b 3âˆšn + n,, then these numbers depend on n âˆˆN. But since the convergence in
eq. (7.12) is uniform, we may replace a and b by aâ€² and bâ€², respectively and obtain
lim
nâ†’âˆsup
aâ€²<bâ€²
....P
C
aâ€² â‰¤Sn â‰¤bâ€²D
â€“ P
5aâ€² â€“ n,
3âˆšn
â‰¤Z â‰¤bâ€² â€“ n,
3âˆšn
6.... = 0 .
(7.13)
Here, as before, Z denotes a standard normally distributed random variable. For a ï¬nal
reformulation set
Zn := 3
âˆš
n Z + n, .
Then eq. (7.13) is equivalent to
lim
nâ†’âˆsup
aâ€²<bâ€²
..P
C
aâ€² â‰¤Sn â‰¤bâ€²D
â€“ P
C
aâ€² â‰¤Zn â‰¤bâ€²D.. = 0 .
(7.14)
By Proposition 4.2.3, the random variables Zn are N(n,, n32)-distributed, which al-
lows us to interpret eq. (7.13), or eq. (7.14), as follows. If , = EXj and 32 = VXj, then for
large n, the sum Sn is â€œapproximativeâ€ N

n,, n32
-distributed.

7.2 Central Limit Theorem
287
In other words, for â€“âˆâ‰¤a < b â‰¤âˆit follows that
P{a â‰¤Sn â‰¤b} â‰ˆI
b â€“ n,
3âˆšn

â€“ I
a â€“ n,
3âˆšn

.
Interpretation: We emphasize once more that the central limit theorem is valid for
all sequences of independent identically distributed random variables possessing a
second moment. For example, it is true for Xjs that are binomial distributed, for Xjs
being exponentially distributed, and so on. Thus, no matter how the random vari-
ables with second moment are distributed, all their normalized sums possess the
same limit, the normal distribution. This explains the outstanding role of the normal
distribution.
The deeper reason for this phenomenon is that Sn may be viewed as the su-
perposition of many â€œsmallâ€ independent errors or perturbations, all of the same
kind.5 Although each perturbation is distributed according to PX1, the independent
superposition of the perturbations leads to the fact that the ï¬nal result is approxim-
ative normally distributed. This explains why so many random phenomena may be
described by normally distributed random variables.
Remark 7.2.8 (Continuity correction). A slight technical problem arises in the case of
discrete random variables Xj. Then the Sns are discrete as well, hence their distribu-
tion functions Fn have jumps. If these noncontinuous Fns approximate the continuous
function I, then there occur certain errors at the points where the jumps of Fn are.
To understand the problem, assume that the Xjs possess values in Z, then Sn is also
Z-valued, hence for any 0 â‰¤h < 1, and all integers k < l, it follows that
P{k â‰¤Sn â‰¤l} = P{k â€“ h â‰¤Sn â‰¤l + h} .
Consequently, for each such number h, the value
I
l + h â€“ n,
3âˆšn

â€“ I
k â€“ h â€“ n,
3âˆšn

may be taken as normal approximation of the above probability. Which number h < 1
should be chosen?
To answer this question observe the following. If l < m < k, then
P{k â‰¤Sn â‰¤l} = P{k â‰¤Sn â‰¤m} + P{m + 1 â‰¤Sn â‰¤l} ,
5 The central limit theorem also holds for not necessarily identically distributed random variables
provided that all â€œerrorsâ€ become uniformly small. That is, one has to exclude that certain errors are
dominating the other ones.

288
7 Limit Theorems
which is approximated by
I
l + h â€“ n,
3âˆšn

â€“ I
m + 1 â€“ h â€“ n,
3âˆšn

+ I
m + h â€“ n,
3âˆšn

â€“ I
k â€“ h â€“ n,
3âˆšn

.
Thus, in order to get neither an overlap nor a gap between m+1â€“hâ€“n, and m+hâ€“n,,
it is customary to choose h = 0.5. This leads to the following deï¬nition.
Deï¬nition 7.2.9. Suppose X1, X2, . . . are independent identically distributed with
values in Z. Then the corrected normal approximation is given by
P{k â‰¤Sn â‰¤l} â‰ˆI
l + 0.5 â€“ n,
3âˆšn

â€“ I
k â€“ 0.5 â€“ n,
3âˆšn

.
It is called continuity correction or histogram correction for the normal
approximation. In a similar way, one corrects the approximation for inï¬nite
intervals by
P{Sn â‰¤l} â‰ˆI
l + 0.5 â€“ n,
3âˆšn

and by
P{Sn â‰¥k} â‰ˆ1 â€“ I
k â€“ 0.5 â€“ n,
3âˆšn

= I
n, â€“ k + 0.5
3âˆšn

.
(7.15)
The next result tells us that the continuity correction is only needed for small ns.
Proposition 7.2.10. For all x âˆˆR and h âˆˆR it follows that
....I
x + h â€“ n,
3âˆšn

â€“ I
x â€“ n,
3âˆšn
.... â‰¤
|h|
3
âˆš
20n
.
Proof: The mean value theorem of Calculus implies the existence of an intermediate
value . in

xâ€“|h|â€“n,
3âˆšn
, x+|h|â€“n,
3âˆšn

such that
....I
x + h â€“ n,
3âˆšn

â€“ I
x â€“ n,
3âˆšn
.... = |h| Iâ€²(.)
3âˆšn .
Using
Iâ€²(.) =
1
âˆš
20
eâ€“.2/2 â‰¤
1
âˆš
20
,
this proves the asserted estimate.
âˆ

7.2 Central Limit Theorem
289
Remark 7.2.11. An application of Proposition 7.2.10 with x = k or x = l, and with
h = Â±0.5, shows that the improvement by the continuity correction is at most of order
nâ€“1/2. Thus, it is no longer needed for large n.
Example 7.2.12. Roll a fair die n times. Let Sn be the sum of the n rolls. In view
of eq. (7.14), this sum Sn is approximately N
 7n
2 , 35n
12

distributed. In other words, it
follows that
lim
nâ†’âˆP

a â‰¤Sn â€“ 7n/2
=
35n/12
â‰¤b
$
=
1
âˆš
20
b

a
eâ€“x2/2 dx = I(b) â€“ I(a) .
Moreover, this convergence takes place uniformly for all a < b. Therefore, at least for
large n, the right-hand side of the last equation may be taken as approximative value
of the left-hand one.
At ï¬rst, we consider an example with a small number of trials. We roll a die three
times and ask for the probability of the event {7 â‰¤S3 â‰¤8}. Let us compare the exact
value
P{7 â‰¤S3 â‰¤8} = 1
6 = 0.16667
with the one we get by applying the central limit theorem. Without continuity
correction, the approximative value is
I

8 â€“ 21/2
=
3 â‹…35/12

â€“ I

7 â€“ 21/2
=
3 â‹…35/12

= 0.08065 ,
while an application of the continuity correction leads to
I

8 + 0.5 â€“ 21/2
=
3 â‹…35/12

â€“ I

7 â€“ 0.5 â€“ 21/2
=
3 â‹…35/12

= 0.16133 .
We see the improvement using the continuity correction.
Next we treat an example with large n. Let us investigate once more Example 7.1.6,
but this time from the point of view of the central limit theorem. Choose again n = 103,
a = â€“ 100
âˆš
12
âˆš
35000 and b = 100
âˆš
12
âˆš
35000. Then it follows that
P{3400 â‰¤Sn â‰¤3600} â‰ˆ
1
âˆš
20
b

a
eâ€“x2/2 dx â‰ˆ0.93592 .
As we see, the use of the central limit theorem improves considerably the bound 0, 709
obtained by Chebyshevâ€™s inequality.
Example 7.2.13. We investigate once more the model of a random walk on Z as presen-
ted in Example 4.1.7. What does the central limit theorem imply in this case? To

290
7 Limit Theorems
simplify the calculations let us assume p = 1/2, that is, jumps to the left and to the
right are equally likely. Thus, if Xj = â€“1 if the particle jumps to the left in step j
and Xj = 1 otherwise, then P{Xj = â€“1} = P{Xj = 1} = 1/2 and Sn = X1 + â‹¯+ Xn
is the position of the particle after n jumps. Moreover, by assumption the Xjs are
independent and, of course, identically distributed. Thus, the central limit theorem
applies with , = EX1 = 0 and with 32 = VX1 = 1. Consequently, Sn is approximately
N (0, n)-distributed. More precisely, we have
lim
nâ†’âˆP{a
âˆš
n â‰¤Sn â‰¤b
âˆš
n} =
1
âˆš
20
b

a
eâ€“x2/2 dx .
For instance, if a = â€“2 and b = 2, then it follows that
lim
nâ†’âˆP
C
â€“2
âˆš
n â‰¤Sn â‰¤2
âˆš
n
D
=
1
âˆš
20
2

â€“2
eâ€“x2/2 dx â‰ˆ0.9544997 .
Keep in mind that the possible values of Sn are between â€“n and n. But in realness, with
probability greater than 0.95, the position of the particle will be in the much smaller
interval [â€“2âˆšn, 2âˆšn].
Example 7.2.14 (Round-off errors).
Many calculations in a bank, for instance of in-
terest, lead to amounts that are not integral in cents. In this case the bank rounds the
calculated value either up or down, whether the remainder is larger or smaller than 0.5
cents. For example, if the calculations lead to $12.837, then the bank transfers $12.84.
Thus, in this case, the bank loses 0.3 cents. This seems to be a small amount, but if,
for example, the bank performs 106 calculations per day, the total loss or gain could
sum up to an amount of $5000.00. But does this really happen?
Answer: Theoretically, the rounding procedure could lead to huge losses or gains
of the bank. But, as the central limit theorem shows, in reality such a scenario is ex-
tremely unlikely. To make this more precise, we use the following model. Let Xj be the
loss or gain (in cents) of the bank in calculation j. Then the Xj are independent and
uniformly distributed on [â€“0.5, 0.5]. Thus, the total loss or gain after n calculations
equals Sn = X1 + â‹¯+ Xn. By Propositions 5.1.25 and 5.2.23 we know that
, = EX1 = 0
and
32 = VX1 = 1
12 ,
hence, if a < b, the central limit theorem implies
lim
nâ†’âˆP
5aâˆšn
âˆš
12
â‰¤Sn â‰¤bâˆšn
âˆš
12
6
=
1
âˆš
20
b

a
eâ€“x2/2 dx .

7.2 Central Limit Theorem
291
For example, if n = 106, then taking a =
âˆš
12 and b = âˆ, this leads to
P{Sn â‰¥$10} = P{Sn â‰¥103 cents} â‰ˆ
1
âˆš
20
âˆ

âˆš
12
eâ€“x2/2 dx â‰ˆ0.00026603 ,
which is an extremely small probability. By symmetry, it also follows that
P{Sn â‰¤â€“$10} â‰ˆ
1
âˆš
20
â€“
âˆš
12

â€“âˆ
eâ€“x2/2 dx â‰ˆ0.00026603 .
In a similar way one obtains
P{Sn â‰¥$1} â‰ˆ0.364517 ,
P{Sn â‰¥$2} â‰ˆ0.244211
P{Sn â‰¥$5} â‰ˆ0.0416323
and
P{Sn â‰¥$20} â‰ˆ2, 1311 Ã— 10â€“12 .
This shows that even for many calculations, in our case 106 ones, the probability for
a loss or gain of more than $5 is very unlikely. Recall that theoretically an amount of
$5000.00 would be possible.
Special Cases of the Central Limit Theorem:
Binomial distributed random variables: In 1738 De Moivre, and later on in 1812 Laplace,
investigated the normal approximation of binomial distributed6 random variables.
This was the starting point for the investigation of general central limit theorems. Let
us state their result.
Proposition 7.2.15 (De Moivreâ€“Laplace theorem). Let Xj
be independent B1,p-
distributed random variables. Then their sums Sn = X1 + â‹¯+ Xn satisfy
lim
nâ†’âˆP

a â‰¤
Sn â€“ np
=
np(1 â€“ p)
â‰¤b
$
=
1
âˆš
20
b

a
eâ€“x2/2 dx .
(7.16)
Proof: Recall that for a B1,p-distributed random variable X we have , = EX = p and
32 = VX = p(1 â€“ p). Consequently, Proposition 7.2.6 applies and leads to eq. (7.16).
âˆ
Remark 7.2.16. By Corollary 4.6.2 we know that Sn = X1 + â‹¯+ Xn is Bn,p-distributed.
Consequently, eq. (7.16) may also be written as
lim
nâ†’âˆ

kâˆˆIn,a,b
n
k

pk (1 â€“ p)nâ€“k =
1
âˆš
20
b

a
eâ€“x2/2 dx,
6 De Moivre investigated sums of B1,1/2-distributed random variables while Laplace treated B1,p-
distributed ones for general 0 â‰¤p â‰¤1.

292
7 Limit Theorems
where
In,a,b :=

k â‰¥0 : a â‰¤
k â€“ np
=
np(1 â€“ p)
â‰¤b
$
.
Another way to formulate the De Moivreâ€“Laplace theorem is as follows. For â€œlargeâ€ n,
Sn is approximative N(np, np(1 â€“ p))-distributed. That is, if 0 â‰¤l < m â‰¤n, then
m

k=l
n
k

pk(1 â€“ p)nâ€“k â‰ˆI

m â€“ np
=
np(1 â€“ p)

â€“ I

l â€“ np
=
np(1 â€“ p)

.
(7.17)
Since the sums Sn are integer-valued, the continuity correction should be applied for
small ns, that is, on the right-hand side of eq. (7.17) the numbers m and l should be
replaced by m + 0.5 and l by l â€“ 0.5, respectively.
Example 7.2.17. Play a series of games with success probability 0 < p < 1. Let ! âˆˆ(0, 1)
be a given security probability, and m âˆˆN is some integer. How many games one has
to play in order to have with probability greater than or equal to 1 â€“ ! at least m times
success?
Answer: Deï¬ne random variables Xj by setting Xj = 1 when winning game j, while
Xj = 0 in the case of losing it. Then the Xjs are independent and B1,p-distributed.
Hence, if Sn = X1 + â‹¯Xn, then the above question may be formulated as follows. What
is the smallest n âˆˆN for which
P{Sn â‰¥m} â‰¥1 â€“ ! ?
(7.18)
By Corollary 4.6.2, the sum Sn is Bn,p-distributed and, therefore, estimate (7.18)
transforms to
n

k=m
n
k

pk(1 â€“ p)nâ€“k â‰¥1 â€“ ! .
(7.19)
Thus, the â€œexactâ€ answer to the above question is as follows. Choose the minimal n â‰¥1
for which estimate (7.19) is valid.
Remark 7.2.18. For large m it may be a difï¬cult task to determine the minimal n
satisfying estimate (7.19). Therefore, one looks for an â€œapproximativeâ€ approach via
Proposition 7.2.15. Rewriting estimate (7.18) as
P

Sn â€“ np
=
np(1 â€“ p)
â‰¥
m â€“ np
=
np(1 â€“ p)
$
â‰¥1 â€“ ! ,

7.2 Central Limit Theorem
293
an â€œapproximativeâ€ condition for n is
1 â€“ ! â‰¤1 â€“ I

m â€“ np
=
np(1 â€“ p)

= I

np â€“ m
=
np(1 â€“ p)

.
Given " âˆˆ(0, 1), let us deï¬ne7 u" by I(u") = ". Consequently, the approximative
solution of the above question is to choose the minimal n â‰¥1 satisfying
np â€“ m
=
np(1 â€“ p)
â‰¥u1â€“! .
(7.20)
For â€œsmallâ€ n we have to modify the previous approach slightly. Here we have to use
the continuity correction. In view of eq. (7.15) the condition is now
1 â€“ ! â‰¤I

np â€“ m + 0.5
=
np(1 â€“ p)

,
leading to
np â€“ m + 0.5
=
np(1 â€“ p)
â‰¥u1â€“! .
(7.21)
Let us explain Remark 7.2.18 with the help of a concrete example.
Example 7.2.19. Find the minimal n â‰¥1 such that, rolling a fair die n times, one
observes with probability greater than or equal to 0.9 at least 100 times the number 6 ?
The â€œexactâ€ answer is, choose the minimal n â‰¥1 satisfying
n

k=100
n
k
  1
6
k  5
6
nâ€“k
â‰¥0.9 .
Numerical calculations give that the left-hand side equals 0.897721 if n = 670, and it
is 0.900691 if n = 671. Thus, in order to observe, with probability greater than 0.9, the
number â€œ6â€ at least 100 times, one has to roll the die at least 671 times.
Let us compare this result with the one that we obtain by the approximative
approach. First we approximate Sn directly, that is, without applying the continu-
ity correction. Here estimate (7.20) says that we have to look for the minimal n â‰¥1
satisfying
n â€“ 600
âˆš
5n
â‰¥u0.9 = 1.28155 .
(7.22)
7 Later on, in Section 8.4.3, these numbers u" will play an important role; compare also Deï¬nition
8.4.5.

294
7 Limit Theorems
Since
665 â€“ 600
âˆš
5 â‹…665
= 1.12724
and
666 â€“ 600
âˆš
5 â‹…666
= 1.4373 ,
the smallest n satisfying estimate (7.22) is 666.
Applying the continuity correction, by estimate (7.21), condition (7.22) has to be
replaced by
n â€“ 600 + 3
âˆš
5n
â‰¥u0.9 = 1.28155 .
The left-hand side equals 1.27757 for n = 671 and 1.29387 if n = 672. Consequently, this
type of approximation gives the (more precise) value n = 672 for the minimal number
of necessary rolls of the die.
Poisson distributed random variables: Let X1, X2, . . . be independent and Pois+-
distributed. By Propositions 5.1.16 and 5.2.20 we know
EX1 = +
and
VX1 = + .
Thus, in this case Proposition 7.2.6 reads as follows.
Proposition 7.2.20. Let (Xj)jâ‰¥1 be independent Pois+-distributed. Then the sums
Sn = X1 + â‹¯+ Xn satisfy
lim
nâ†’âˆP
5
a â‰¤Sn â€“ n+
âˆš
n+
â‰¤b
6
=
1
âˆš
20
b

a
eâ€“x2/2 dx .
(7.23)
Remark 7.2.21. By Proposition 4.6.5, the sum Sn is Pois+n-distributed, hence eq. (7.23)
transforms to
lim
nâ†’âˆ

kâˆˆJn,a,b
(+n)k
k!
eâ€“+n =
1
âˆš
20
b

a
eâ€“x2/2 dx ,
(7.24)
where
Jn,a,b :=
5
k âˆˆN0 : a â‰¤k â€“ n+
âˆš
n+
â‰¤b
6
.
Another way to express this is as follows. If 0 â‰¤l < m < âˆ, then
m

k=l
(+n)k
k!
eâ€“+n â‰ˆI
m â€“ n+
âˆš
n+

â€“ I
l â€“ n+
âˆš
n+

.

7.2 Central Limit Theorem
295
Remark 7.2.22. Choosing in eq. (7.24) the numbers as a = â€“âˆ, b = 0 and + = 1, we get
lim
nâ†’âˆeâ€“n
n

k=0
nk
k! = 1
2 ,
which is interesting in its own right. Taking a = â€“âˆand bn = âˆšn yields
lim
nâ†’âˆ
......
eâ€“n
2n

k=0
nk
k! â€“
1
âˆš
20
bn

â€“âˆ
eâ€“x2/2 dx
......
= 0 ,
hence, because of
lim
nâ†’âˆ
1
âˆš
20
âˆšn

â€“âˆ
eâ€“x2/2 dx = 1 ,
we obtain
lim
nâ†’âˆeâ€“n
2n

k=0
nk
k! = 1 .
Gamma distributed random variables: Finally, we investigate sums of gamma distrib-
uted random variables. Here the central limit theorem leads to the following result.
Proposition 7.2.23. Let X1, X2, . . . be independent A!,"-distributed random variables.
Then their sums Sn = X1 + â‹¯+ Xn satisfy
lim
nâ†’âˆP

a â‰¤Sn â€“ n!"
!
=
n"
â‰¤b
$
=
1
âˆš
20
b

a
eâ€“x2/2 dx .
(7.25)
Proof: Propositions 5.1.26 and 5.2.24 tell us that the expected value and the variance
of the Xjs are given by , = EX1 = !" and 32 = VX1 = !2". Therefore, eq. (7.25) follows
by an application of Proposition 7.2.6.
âˆ
Remark 7.2.24. Note that Proposition 4.6.11 implies that Sn is A!,n"-distributed. Thus,
setting
In,a,b :=

x â‰¥0 : a â‰¤x â€“ n!"
!
=
n"
â‰¤b
$
,
eq. (7.25) leads to
lim
nâ†’âˆ
1
!n"A(n")

In,a,b
xn"â€“1 eâ€“x/! dx =
1
âˆš
20
b

a
eâ€“x2/2 dx .

296
7 Limit Theorems
Another way to express this is as follows. If 0 â‰¤a < b, then
1
!n"A(n")
b

a
xn"â€“1 eâ€“x/! dx â‰ˆI

b â€“ n!"
!
=
n"

â€“ I

a â€“ n!"
!
=
n"

.
Two cases of Proposition 7.2.23, or of Remark 7.2.24, are of special interest.
(a)
For n â‰¥1 let Sn be a 72
n-distributed random variable. Then it follows that
lim
nâ†’âˆP
5
a â‰¤Sn â€“ n
âˆš
2n
â‰¤b
6
=
1
âˆš
20
b

a
eâ€“x2/2 dx .
(b)
If Sn is distributed according to the Erlang distribution E+,n, then we get
lim
nâ†’âˆP
5
a â‰¤+Sn â€“ n
âˆšn
â‰¤b
6
=
1
âˆš
20
b

a
eâ€“x2/2 dx .
For + = 1 this implies (set a = â€“âˆand b = 0) that
lim
nâ†’âˆ
1
A(n)
n

0
xnâ€“1 eâ€“x dx =
1
âˆš
20
0

â€“âˆ
eâ€“x2/2 dx = 1
2 .
Additional Remarks:
(1) We play a series of the same game. Suppose in each game we may lose or win
a certain amount of money. A natural condition for this game (among friends) is it
should be fair. But what does it mean that a game is fair? Is this the case if
(i)
the average loss or gain in each single game is zero or is it fair if
(ii)
the probability that, after n games, the total loss or gain is positive, tends to 1/2
as n tends to inï¬nity?
The mathematical formulation of the previous question is as follows. Let X1, X2, . . .
denote the win or loss in the ï¬rst game, the second one, and so on. Then the Xjs are
independent identically distributed random variables. The above question reads now
as follows. Is the game fair if
(i)
the expected value , = EX1 satisï¬es , = 0 or is this the case if
(ii)
the sum Sn := X1 + â‹¯+ Xn fulï¬lls
lim
nâ†’âˆP{Sn â‰¤0} = lim
nâ†’âˆP{Sn â‰¥0} = 1
2 ?
(7.26)
In the sequel we have to exclude the trivial case P{Xj = 0} = 1, that is, in each game
one neither wins nor loses some money. Of course, then eq. (7.26) does not hold.
At a ï¬rst glance one might believe that the two possible deï¬nitions of fairness
describe the same fact. But this is not so as one may see in an example in [Fel68],

7.2 Central Limit Theorem
297
Chapter X, Â§4. There one ï¬nds a sequence of independent random variables X1, X2, . . .
with EX1 = 0, however
lim
nâ†’âˆP{Sn â‰¤0} = 1 .
In particular, this tells us that, in general, condition (i) does not imply condition (ii).
The next result clariï¬es the relation between these two deï¬nitions of fairness in
the case that the random variables possess a ï¬nite second moment.
Proposition 7.2.25. Let X1, X2, . . . be independent and identically distributed with
expected value ,. Assume P{Xj = 0} < 1.
1.
Then eq. (7.26) always implies , = 0. That is, a fair game in the sense of (ii) also
satisï¬es condition (i).
2.
Conversely, if E|X1|2 < âˆ, then (ii) is a consequence of (i). Hence, assuming the
existence of a second moment, conditions (i) and (ii) are equivalent.
Proof: We prove the contraposition of the ï¬rst statement. Thus, suppose that (i) does
not hold, that is, we have , /= 0. Without losing generality we may assume , > 0.
Otherwise, investigate â€“X1, â€“X2, . . . . An application of Proposition 7.1.27 with % = ,/2
yields
lim
nâ†’âˆP
5....
Sn
n â€“ ,
.... â‰¤,
2
6
= 1 .
(7.27)
Since
... Sn
n â€“ ,
... â‰¤,/2 implies Sn
n â‰¥,/2, hence Sn â‰¥0, it follows that
P
5....
Sn
n â€“ ,
.... â‰¤,
2
6
â‰¤P{Sn â‰¥0} .
Consequently, from eq. (7.27) we derive
lim
nâ†’âˆP{Sn â‰¥0} = 1 ,
hence eq. (7.26) cannot be valid. This proves the ï¬rst part of the proposition.
We prove now the second assertion. Thus, suppose , = 0 as well as the existence
of the variance 32 = VX1. Note that 32 > 0. Why? If a random variable X satisï¬es EX = 0
and VX = 0, then necessarily P{X = 0} = 1. But, since we assumed P{X1 = 0} < 1, we
cannot have 32 = VX1 = 0.
Thus, Proposition 7.2.6 applies and leads to
lim
nâ†’âˆP{Sn â‰¥0} = lim
nâ†’âˆ
5 Sn
3âˆšn â‰¥0
6
=
1
âˆš
20
âˆ

0
eâ€“x2/2 dx = 1
2 .
The proof for P{Sn â‰¤0} â†’1/2 follows in the same way, thus eq. (7.26) is valid. This
completes the proof.
âˆ

298
7 Limit Theorems
(2) How fast does Snâ€“n,
3âˆšn converge to a normally distributed random variable?
Before we answer this question, we have to determine how this speed is measured. In
view of Proposition 7.2.6 we use the following quantity depending on n â‰¥1:
sup
tâˆˆR
......
P
5Sn â€“ n,
3âˆšn
â‰¤t
6
â€“
1
âˆš
20
t

â€“âˆ
eâ€“x2/2 dx
......
.
Doing so, the following classical result holds (see [Dur10], Section 3.4.4, for a proof).
Proposition 7.2.26 (Berryâ€“EssÃ©en theorem). Let X1, X2, . . . be independent identic-
ally distributed random variables with ï¬nite third moment, that is, with E|X1|3 < âˆ.
If , = EX1 and 32 = VX1 > 0, then it follows that
sup
tâˆˆR
......
P
5Sn â€“ n,
3âˆšn
â‰¤t
6
â€“
1
âˆš
20
t

â€“âˆ
eâ€“x2/2 dx
......
â‰¤C E|X1|3
33
nâ€“1/2 .
(7.28)
Here C > 0 denotes a universal constant.
Remark 7.2.27. The order nâ€“1/2 in estimate (7.28) is optimal and cannot be improved.
This can be seen by the following example. Take independent random variables
X1, X2, . . . with P{Xj = â€“1} = P{Xj = 1} = 1/2. Hence, in this case , = 0 and 32 = 1.
Then one has
lim inf
nâ†’âˆn1/2 sup
tâˆˆR
......
P
5 Sn
âˆšn â‰¤t
6
â€“
1
âˆš
20
t

â€“âˆ
eâ€“x2/2 dx
......
> 0 .
(7.29)
Assertion (7.29) is a consequence of the fact that, if n is even, then the function
t â†¦P

Sn
âˆšn â‰¤t

has a jump of order nâ€“1/2 at zero. This follows by the calculations in Ex-
ample 4.1.7. On the other hand, t â†¦I(t) is continuous, hence the maximal difference
between these two functions is at least the half of the height of the jump.
Remark 7.2.28. The exact value of the constant C > 0 appearing in estimate (7.28)
is, in spite of intensive investigations, still unknown. At present, the best-known
estimates are 0.40973 < C < 0.478.
7.3 Problems
Problem 7.1. Let A1, A2, . . . and B1, B2, . . . be two sequences of events in a probability
space (K, A, P). Prove that
lim sup
nâ†’âˆ(An âˆªBn) = lim sup
nâ†’âˆ(An) âˆªlim sup
nâ†’âˆ(Bn) .

7.3 Problems
299
Is this also valid for the intersection? That is, does one have
lim sup
nâ†’âˆ(An âˆ©Bn) = lim sup
nâ†’âˆ(An) âˆ©lim sup
nâ†’âˆ(Bn) ?
Problem 7.2. Let (Xn)nâ‰¥1 be a sequence of independent E+-distributed random vari-
ables. Characterize sequences (cn)nâ‰¥1 of positive real numbers for which
P{Xn â‰¥cn inï¬nitely often} = 1 ?
Problem 7.3. Let f : [0, 1] â†’R be a continuous function. Its Bernstein polynomial
Bf
n of degree n is deï¬ned by
Bf
n(x) :=
n

k=0
f
k
n
 n
k

xk(1 â€“ x)nâ€“k ,
0 â‰¤x â‰¤1 .
Show that Proposition 7.1.29 implies the following. If P is the uniform distribution on
[0, 1], then
P

x âˆˆ[0, 1] : lim
nâ†’âˆBf
n(x) = f(x)

= 1 .
Remark: Using methods from Calculus, one may even show the uniform convergence,
that is,
lim
nâ†’âˆsup
0â‰¤xâ‰¤1
|Bf
n(x) â€“ f(x)| = 0 .
Problem 7.4. Roll a fair die 180 times. What is the probability that the number â€œ6â€
occurs less than or equal to 25 times. Determine this probability by the following three
methods:
â€“ Directly via the binomial distribution.
â€“ Approximative by virtue of the central limit theorem.
â€“ Approximative by applying the continuity correction.
Problem 7.5. Toss a fair coin 16 times. Compute the probability to observe exactly
eight times â€œheadâ€ by the following methods.
â€“ Directly via the binomial distribution.
â€“ Approximative by applying the continuity correction.
Why does one not get a reasonable result using the normal approximation directly,
that is, without continuity correction?

300
7 Limit Theorems
Problem 7.6. Let X1, X2, . . . be a sequence of independent Gp-distributed random
variables, that is, for some 0 < p < 1 one has
P{Xj = k} = p(1 â€“ p)kâ€“1 ,
k = 1, 2, . . .
1.
What does the central limit theorem tell us in this case about the behavior of the
sums Sn = X1 + â‹¯Xn ?
2.
For two real numbers a < b set
In,a,b :=

k â‰¥0 : a â‰¤pk â€“ n(1 â€“ p)
=
n(1 â€“ p)
â‰¤b
$
.
Show that
lim
nâ†’âˆ

kâˆˆIn,a,b
â€“n
k

pn(1 â€“ p)k =
1
âˆš
20
b

a
eâ€“x2/2dx .
Hint: Use Corollary 4.6.9 and investigate Sn â€“ n.

8 Mathematical Statistics
8.1 Statistical Models
8.1.1 Nonparametric Statistical Models
The main objective of Probability Theory is to describe and analyze random experi-
ments by means of a suitable probability space (K, A, P). Here it is always assumed
that the probability space is known, in particular, that the describing probability
measure, P, is identiï¬ed.
Probability Theory:
Description of a random experiment and its properties by a probability space. The
distribution of the outcomes is assumed to be known.
Mathematical Statistics deals mainly with the reverse question: one executes an ex-
periment, that is, one draws a sample (e.g., one takes a series of measurements of an
item or one interrogates several people), and, on the basis of the observed sample,
one wants to derive as much information as possible about the (unknown) underlying
probability measure P. Sometimes the precise knowledge of P is not needed; it may
sufï¬ce to know a certain parameter of P.
Mathematical Statistics:
As a result of a statistical experiment, a (random) sample is observed. On its basis,
conclusions are drawn about the unknown underlying probability distribution.
Let us state the mathematical formulation of the task: ï¬rst we mention that it is stand-
ard practice in Mathematical Statistics to denote the describing probability space by
(X, F, P). As before, X is the sample space (the set that contains all possible outcomes
of the experiment), and F is a suitable 3-ï¬eld of events. The probability measure P de-
scribes the experiment, that is, P(A) is the probability of observing a sample belonging
to A, but recall that P is unknown.
Based on theoretical considerations or on long-time experience, quite often we
are able to restrict the entirety of probability measures in question. Mathematically,
that means that we choose a set P of probability measures on (X, F), which contains
what we believe to be the â€œcorrectâ€ P. Thereby, it is not impossible that P is the set of
all probability measures, but for most statistical methods it is very advantageous to
take P as small as possible. On the other hand, the set P cannot be chosen too small,
because we have to be sure that the â€œcorrectâ€ P is really contained in P. Otherwise, the
obtained results are either false or imprecise.

302
8 Mathematical Statistics
Deï¬nition 8.1.1. A subset P of probability measures on (X, F) is called a dis-
tribution assumption, that is, one assumes that the underlying P belongs
to P.
After having ï¬xed the distribution assumption P, one now regards only probability
measures P âˆˆP or, equivalently, measures not in P are sorted out.
To get information about the unknown probability measure, one performs a stat-
istical experiment or analyzes some given data. In both cases, the result is a random
sample x âˆˆX. The task of Mathematical Statistics is to get information about P âˆˆP,
based on the observed sample x âˆˆX. A suitable way to describe the problem is as
follows.
Deï¬nition 8.1.2. A (nonparametric) statistical model is a collection of probabil-
ity spaces (X, F, P) with P âˆˆP. Here, X and F are ï¬xed, and P varies through the
distribution assumption P. One writes for the model
(X, F, P)PâˆˆP
or
{(X, F, P) : P âˆˆP} .
Let us illustrate the previous deï¬nition with two examples.
Example 8.1.3. In an urn are white and black balls of an unknown ratio. Let ( âˆˆ[0, 1]
be the (unknown) proportion of white balls, hence 1 â€“ ( is that of the black ones. In or-
der to get some information about (, one randomly chooses n balls with replacement.
The result of this experiment, or the sample, is a number k âˆˆ{0, . . . , n}, the frequency
of observed white balls. Thus, the sample space is X = {0, . . . , n} and as 3-ï¬eld we may
choose, as always for ï¬nite sample spaces, the powerset P(X). The possible probabil-
ity measures describing this experiment are binomial distributions Bn,( with 0 â‰¤( â‰¤1.
Consequently, the distribution assumption is
P = {Bn,( : ( âˆˆ[0, 1]} .
Summing up, the statistical model describing the experiment is
(X, P(X), P)PâˆˆP
where
X = {0, . . . , n}
and
P = {Bn,( : 0 â‰¤( â‰¤1} .
Next, we consider an important example from quality control.
Example 8.1.4. A buyer obtains from a trader a delivery of N machines. Among them
M â‰¤N are defective. The buyer does not know the value of M. To determine it, he

8.1 Statistical Models
303
randomly chooses n machines from the delivery and checks them. The result, or the
sample, is the number 0 â‰¤m â‰¤n of defective machines among the n tested.
Thus, the sample space is X = {0, . . . , n}, F = P(X), and the probability measures
in question are hypergeometric ones. Therefore, the distribution assumption is
P = {HN,M,n : M = 0, . . . , N} ,
where HN,M,n denotes the hypergeometric distribution with parameters N, M, and n,
as introduced in Deï¬nition 1.4.25.
Before we proceed further, we consider a particularly interesting case of statistical
model, which describes the n-fold independent repetition of a single experiment.
To explain this model, let us investigate the following easy example.
Example 8.1.5. We are given a die that looks biased. To check this, we roll it n
times and record the sequence of numbers appearing in each of the trials. Thus, our
sample space is X = {1, . . . , 6}n, and the observed sample is x = (x1, . . . , xn), with
1 â‰¤xk â‰¤6. Let (1, . . . , (6 be the probabilities for 1 to 6. Then we want to check whether
(1 = â‹…â‹…â‹…= (6 = 1/6, that is, whether P0 given by P0({k}) = (k, 1 â‰¤k â‰¤6, is the
uniform distribution. What are the possible probability measures on (X, P(X)) de-
scribing the statistical experiment? Since the results of different rolls are independent,
the describing measure P is of the form P = PâŠ—n
0
with
PâŠ—n
0 ({x}) = P0({x1}) â‹…â‹…â‹…P0({xn}) = (m1
1
â‹…â‹…â‹…(m6
6
,
x = (x1, . . . , xn) ,
and where the mks denote the frequency of the number 1 â‰¤k â‰¤6 in the sequence x.
Consequently, the natural distribution assumption is
P = {PâŠ—n
0
: P0 probability measure on {1, . . . , 6}} .
Suppose we are given a probability space (X0, F0, P0) with unknown P0 âˆˆP0. Here,
P0 denotes a set of probability measures on (X0, F0), hopefully containing the â€œcor-
rectâ€ P0. We call (X0, F0, P0)P0âˆˆP0 the initial model. In Example 8.1.5, the initial
model is X0 = {1, . . . , 6}, while P0 is the set of all probability measures on (X0, P(F0)).
In order to determine P0, we execute n independent trials according to P0. The
result, or the observed sample, is a vector x = (x1, . . . , xn) with xi âˆˆX0. Consequently,
the natural sample space is X = X n
0 .
Which statistical model does this experiment describe? To answer this question,
let us recall the basic results in Section 1.9, where exactly those problems have been
investigated. As 3-ï¬eld F we choose the n times product 3-ï¬eld of F0, that is,
F = F0 âŠ—â‹…â‹…â‹…âŠ—F0



n times
,

304
8 Mathematical Statistics
and the describing probability measure P is of the form PâŠ—n
0 , that ist, it is the n-fold
product of P0. Recall that, according to Deï¬nition 1.9.5, the product PâŠ—n
0
is the unique
probability measure on (X, F) satisfying
PâŠ—n
0 (A1 Ã— â‹…â‹…â‹…Ã— An) = P0(A1) â‹…â‹…â‹…P0(An) ,
whenever Aj âˆˆF0.
Since we assumed P0 âˆˆP0, the possible probability measures are PâŠ—n
0
with
P0 âˆˆP0.
Let us summarize what we obtained until now.
Deï¬nition 8.1.6. The statistical model for the n-fold independent repetition of
an experiment, determined by the initial model (X0, F0, P0)P0âˆˆP0, is given by
(X, F, PâŠ—n
0 )P0âˆˆP0
where X = X n
0 , F denotes the product 3-ï¬eld of the F0s, and PâŠ—n
0
is the n-fold
product measure of P0.
Remark 8.1.7. Of course, the main goal in the model of n-fold repetition is to get some
knowledge about P0. To obtain the desired information, we perform n independent
trials, each time observing a value distributed according to P0. Altogether, the sample
is a vector x = (x1, . . . , xn), which is now distributed according to PâŠ—n
0 .
The two following examples explain Deï¬nition 8.1.6.
Example 8.1.8. A coin is labeled on one side with â€œ0â€ and on the other side with â€œ1.â€
There is some evidence that the coin is biased. To check this, let us execute the follow-
ing statistical experiment: toss the coin n times and record the sequence of zeroes and
ones. Thus, the observed sample is some x = (x1, . . . , xn), with each xk being either â€œ0â€
or â€œ1.â€
Our initial model is given by X0 = {0, 1} and P0 = B1,( for a certain (unknown)
( âˆˆ[0, 1]. Then the experiment is described by X = {0, 1}n and P = {BâŠ—n
1,( : 0 â‰¤( â‰¤1}.
Note that
BâŠ—n
1,(({x}) = (k(1 â€“ ()nâ€“k ,
k = x1 + â‹…â‹…â‹…+ xn .
Example 8.1.9. A company produces a new type of light bulbs with an unknown dis-
tribution of the lifetime. To determine it, n light bulbs are switched on at the same
time. Let t = (t1, . . . , tn) be the times when the bulbs burn through. Then our sample is
the vector t âˆˆ(0, âˆ)n.

8.1 Statistical Models
305
By long-time experience one knows the lifetime of each light bulb is exponen-
tially distributed. Thus, the initial model is (R, B(R), P0) with P0 = {E+ : + > 0}.
Consequently, the experiment of testing n light bulbs is described by the model
(Rn, B(Rn), PâŠ—n)PâˆˆP0 = (Rn, B(Rn), EâŠ—n
+ )+>0 ,
where P0 = {E+ : + > 0}. Recall that EâŠ—n
+
is the probability measure on (Rn, B(Rn)) with
density p(t1, . . . , tn) = +n eâ€“+(t1+â‹…â‹…â‹…+tn) for tj â‰¥0.
8.1.2 Parametric Statistical Models
In all of our previous examples there was a parameter that parametrized the probab-
ility measures in P in natural way. In Example 8.1.3, this is the parameter ( âˆˆ[0, 1],
in Example 8.1.4, the probability measures are parametrized by M âˆˆ{0, . . . , N}, in Ex-
ample 8.1.8 the parameter is also ( âˆˆ[0, 1], and, ï¬nally, in Example 8.1.9 the natural
parameter is + > 0. Therefore, from now on, we assume that there is a parameter set
C such that P may be represented as
P = {P( : ( âˆˆC} .
Deï¬nition 8.1.10. A parametric statistical model is deï¬ned as
(X, F, P()(âˆˆC
with parameter set C. Equivalently, we suppose that the distribution assump-
tion P, appearing in Deï¬nition 8.1.2, may be represented as P = {P( : ( âˆˆC} .
In this notation, the parameter sets in Examples 8.1.3, 8.1.4, 8.1.8, and 8.1.9 are C =
[0, 1], C = {0, . . . , N}, C = [0, 1], and C = (0, âˆ), respectively.
Remark 8.1.11. It is worthwhile mentioning that the parameter can be quite general;
for example, it can be a vector ( = ((1, . . . , (k), so that in fact there are k unknown para-
meters (j, combined to a single vector (. For instance, in Example 8.1.5, the unknown
parameters are (1, . . . , (6, thus, the parameter set is given by
C = {( = ((1, . . . , (6) : (k â‰¥0 , (1 + â‹…â‹…â‹…+ (6 = 1} .
Let us present two further examples with slightly more complicated parameter sets.

306
8 Mathematical Statistics
Example 8.1.12. We are given an item of unknown length. It is measured by an in-
strument of an unidentiï¬ed precision. We assume that the instrument is unbiased,
that is, on average, it shows the correct value. In view of the central limit theorem
we may suppose that the measurements are distributed according to a normal dis-
tribution N(,, 32). Here , is the â€œcorrectâ€ length of the item, and 3 > 0 reï¬‚ects the
precision of the measuring instrument. A small 3 > 0 says that the instrument is quite
precise, while large 3s correspond to inaccurate instruments. Consequently, by the
distribution assumption the initial model is given as
(R, B(R), N(,, 32)),âˆˆR, 32>0 .
In order to determine , (and maybe also 3) we measure the item n times by the same
method. As a result we obtain a random sample x = (x1, . . . , xn) âˆˆRn. Thus, our model
describing this experiment is

Rn, B(Rn), N(,, 32)âŠ—n
(,,32)âˆˆRÃ—(0,âˆ) .
Because of eq. (6.9), the model may also be written as

Rn, B(Rn), N(âƒ—,, 32In)

(,,32)âˆˆRÃ—(0,âˆ)
with âƒ—, = (,, . . . , ,) âˆˆRn, and with diagonal matrix 32In. The unknown parameter is
(,, 32), taken from the parameter set R Ã— (0, âˆ).
Example 8.1.13. Suppose now we have two different items of lengths ,1 and ,2. We
take m measurements of the ï¬rst item and n of the second one. Thereby, we use dif-
ferent instruments with maybe different degrees of precision. All measurements are
taken independently of each other. As a result we get a vector (x, y) âˆˆRm+n, where
x = (x1, . . . , xm) are the values of the ï¬rst m measurements and y = (y1, . . . , yn) those
of the second n one. As before we assume that the xis are distributed according to
N(,1, 32
1), and the yjs according to N(,2, 32
2). We neither know ,1 and ,2 nor 32
1 and
32
2. Thus, the sample space is Rm+n and the vectors (x, y) are distributed according to
N((âƒ—,1, âƒ—,2), R32
1,32
2) with diagonal matrix R32
1,32
2 having 32
1 on its ï¬rst m entries and 32
2 on
the remaining n ones.
Note that by Deï¬nition 1.9.5,
N((âƒ—,1, âƒ—,2), R32
1,32
2) = N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n .
This is valid because, if A âˆˆB(Rm) and B âˆˆB(Rn), then it follows that
N((âƒ—,1, âƒ—,2), R32
1,32
2)(A Ã— B) = N(,1, 32
1)âŠ—m(A) â‹…N(,2, 32
2)âŠ—n(B) .

8.2 Statistical Hypothesis Testing
307
The parameter set in this example is given as R2 Ã— (0, âˆ)2, hence the statistical model
may be written as

Rm+n, B(Rm+n), N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n
(,1,,2,32
1,32
2)âˆˆR2Ã—(0,âˆ)2 .
8.2 Statistical Hypothesis Testing
8.2.1 Hypotheses and Tests
We start with a parametric statistical model (X, F, P()(âˆˆC. Suppose the parameter set
C is split up into disjoint subsets C0 and C1. The aim of a test is to decide, on the basis
of the observed sample, whether or not the â€œtrueâ€ parameter ( belongs to C0 or to C1.
Let us explain the problem with two examples.
Example 8.2.1. Consider once more the situation described in Example 8.1.4. Assume
there exists a critical value M0 â‰¤N such that the buyer accepts the delivery if the
number M of defective machines satisï¬es M â‰¤M0. Otherwise, if M > M0, the buyer
rejects it and sends the machines back to the trader. In this example the parameter set
is C = {0, . . . , N}. Letting C0 = {0, . . . , M0} and C1 = {M0 +1, . . . , N}, the question about
acceptance or rejection of the delivery is equivalent to whether M âˆˆC0 or M âˆˆC1.
Assume now the buyer checked n of the N machines and found m defective machines.
On the basis of this observation, the buyer has to decide about acceptance or rejection,
or, equivalently, about M âˆˆC0 or M âˆˆC1.
Example 8.2.2. Let us consider once more Example 8.1.13. There we had two measur-
ing instruments, both being unbiased. Consequently, the expected values ,1 and ,2
are the correct lengths of the two items. The parameter set was C = R2 Ã— (0, âˆ)2. Sup-
pose we conjecture that both items are of equal length, that is, we conjecture ,1 = ,2.
Letting
C0 := {(,, ,, 32
1, 32
2) : , âˆˆR , 32
1, 32
2 > 0}
and C1 = C\C0, to prove or disprove the conjecture, we have to check whether
(,1, ,2, 32
1, 32
2) belongs to C0 or to C1.
On the other hand, if we want to know whether or not the ï¬rst item is smaller than
the second one, then we have to choose
C0 := {(,1, ,2, 32
1, 32
2) : â€“âˆ< ,1 â‰¤,2 < âˆ, 32
1, 32
2 > 0}
and to check whether or not (,1, ,2, 32
1, 32
2) belongs to C0.
An exact mathematical formulation of the previous problems is as follows.

308
8 Mathematical Statistics
Deï¬nition 8.2.3. Let (X, F, P()(âˆˆC be a parametric statistical model and suppose
C = C0 âˆªC1 with C0 âˆ©C1 = Ã¸.
Then the hypothesis or, more precisely, null hypothesis H0 says that for the
â€œcorrectâ€ ( âˆˆC one has ( âˆˆC0. This is expressed by writing H0 : ( âˆˆC0 .
The alternative hypothesis H1 says ( âˆˆC1. This is formulated as H1 : ( âˆˆC1 .
After the hypothesis is set, one executes a statistical experiment. Here the order is
important: ï¬rst one has to set the hypothesis, then test it, not vice versa. If the hypo-
thesis is chosen on the basis of the observed results, then, of course, the sample will
conï¬rm it.
Say the result of the experiment is some sample x âˆˆX. One of the fundamental
problems in Mathematical Statistics is to decide, on the basis of the observed sample,
about acceptance or rejection of H0. The mathematical formulation of the problem is
as follows.
Deï¬nition 8.2.4. A (hypothesis) test T for checking H0 (against H1) is a disjoint
partition T = (X0, X1) of the sample space X. The set X0 is called the region of
acceptance while X1 is said to be the critical region1 or region of rejection.
By mathematical reasoning we have to assume X0 âˆˆF, which of course implies
X1 âˆˆF as well.
Remark 8.2.5. A hypothesis test T = (X0, X1) operates as follows: if the statistical
experiment leads to a sample x âˆˆX1, then we reject H0. But, if we get an x âˆˆX0, then
this does not contradict the hypothesis, and for now we may furthermore work with it.
Important comment: If we observe an x âˆˆX0, then this does not say that H0 is
correct. It only asserts that we failed to reject it or that there is a lack of evidence
against it.
Let us illustrate the procedure with Example 8.2.1.
Example 8.2.6. By the choice of C0 and C1, the hypothesis H0 is given by
H0 : 0 â‰¤M â‰¤M0 ,
hence
H1 : M0 < M â‰¤N .
To test H0 against H1, the sample space X = {0, . . . , n} is split up into the two regions
X0 := {0, . . . , m0} and X1 := {m0 + 1, . . . , n} with some (for now) arbitrary number
m0 âˆˆ{0, . . . , n}. If among the checked n machines m are defective with some m > m0,
1 Sometimes also called â€œcritical section.â€

8.2 Statistical Hypothesis Testing
309
then m âˆˆX1, hence one rejects H0. In this case the buyer refuses to take the delivery
and sends it back to the trader. On the other hand, if m â‰¤m0, then m âˆˆX0, which does
not contradict H0, and the buyer will accept the delivery and pay for it. Of course, the
key question is how to choose the value m0 in a proper way.
Remark 8.2.7. Sometimes tests are also deï¬ned as mappings > : X â†’{0, 1}. The link
between these two approaches is immediately clear. Starting with > the hypothesis
test T = (X0, X1) is constructed by X0 = {x âˆˆX : >(x) = 0} and X1 = {x âˆˆX :
>(x) = 1}. Conversely, if T = (X0, X1) is a given test, then set >(x) = 0 if x âˆˆX0
and >(x) = 1 for x âˆˆX1. The advantage of this approach is that it allows us to deï¬ne so-
called randomized tests. Here > : X â†’[0, 1]. Then, as before, X0 = {x âˆˆX : >(x) = 0}
and X1 = {x âˆˆX : >(x) = 1}. If 0 < >(x) < 1, then
>(x) = P{reject H0 if x is observed} .
That is, for certain observations x âˆˆX, an additional random experiment (e.g., tossing
a coin) decides whether we accept or reject H0. Randomized tests are useful in the case
of ï¬nite or countably inï¬nite sample spaces.
When applying a test T = (X0, X1) to check the null hypothesis H0 : ( âˆˆC0, two
different types of errors may occur.
Deï¬nition 8.2.8. An error of the ï¬rst kind or type I error occurs if H0 is true
but one observes a sample x âˆˆX1, hence rejects H0.
Type I error = incorrect rejection of a true null hypothesis
In other words, a type I error happens if the â€œtrueâ€ ( is in C0, but we observe an x âˆˆX1.
Deï¬nition 8.2.9. An error of the second kind or type II error occurs if H0
is false, but the observed sample lies in X0, hence we do not reject the false
hypothesis H0.
Type II error = failure to reject a false null hypothesis
Consequently, a type II error occurs if the â€œtrueâ€ ( is in C1, but the observed sample is
an element of the region of acceptance X0.

310
8 Mathematical Statistics
Example 8.2.10. In the context of Example 8.2.6 a type I error occurs if the delivery
was well, but among the checked machines were more than m0 defective, so that the
buyer rejects the delivery. Since the trader was not able to sell a proper delivery, this
error is also called the risk of the trader.
On the other hand, a type II error occurs if the delivery is not in good order, but
among the checked machines were only a few defective ones (less than or equal to
m0). Thus, the buyer accepts the bad delivery and pays for it. Therefore, this type of
error is also called the risk of the buyer.
8.2.2 Power Function and Signiï¬cance Tests
The power of a test is described by its power function deï¬ned as follows.
Deï¬nition 8.2.11. Let T = (X0, X1) be a test for H0 : ( âˆˆC0 against H1 : ( âˆˆC1.
The function "T from C to [0, 1] deï¬ned as
"T(() := P((X1)
is called the power function of the test T.
Remark 8.2.12. If ( âˆˆC0, that is, if H0 is true, then "T(() = P((X1) is the probability
that X1 occurs or, equivalently, that a type I error happens.
On the contrary, if ( âˆˆC1, that is, H0 is false, then 1 â€“ "T(() = P((X0) is the
probability that X0 occurs or, equivalently, that a type II error appears.
Thus, a â€œgoodâ€ test should satisfy the following conditions: the power function "T
attains small values on C0 and/or 1â€“"T has small values on C1. Then the probabilities
for the occurrence of type I and/or type II errors are not too big.2
Example 8.2.13. What is the power function of the test presented in Example 8.2.6?
Recall that C = {0, . . . , N} and X1 = {m0 + 1, . . . , n}. Hence, "T maps {0, . . . , N} to [0, 1]
in the following way:
"T(M) = HN,M,n(X1) =
n

m=m0+1
M
m
Nâ€“M
nâ€“m

N
n

.
(8.1)
2 In the literature the power function is sometimes deï¬ned in a slightly different way. If ( âˆˆC0, then
it is as in our Deï¬nition 8.2.11 while for ( âˆˆC1 one deï¬nes it as 1 â€“ "T((). Moreover, for 1 â€“ "T one ï¬nds
the notations operation characteristics or oc-function.

8.2 Statistical Hypothesis Testing
311
Thus, the maximal probability for a type I error is given by
max
0â‰¤Mâ‰¤M0
"T(M) =
max
0â‰¤Mâ‰¤M0
n

m=m0+1
M
m
Nâ€“M
nâ€“m

N
n

,
while the maximal probability for a type II error equals
max
M0<Mâ‰¤N(1 â€“ "T(M)) =
max
M0<Mâ‰¤N
m0

m=0
M
m
Nâ€“M
nâ€“m

N
n

.
Remark 8.2.14. The previous example already illustrates the dilemma of hypothesis
testing. To minimize the type I error one has to choose m0 as large as possible. But
increasing m0 enlarges the type II error.
This dilemma occurs always in the theory of hypothesis testing. In order to mini-
mize the probability of a type I error, the critical region X1 has to be chosen as small as
possible. But making X1 smaller enlarges X0, hence the probability for the occurrence
of a type II error increases. In the extreme case, if X1 = Ã¸, hence X0 = X, then a
type I error I cannot occur at all. In the context of Example 8.2.6 that means the buyer
accepts all deliveries and the trader takes no risk.
On the other hand, to minimize the occurrence of a type II error, the region of ac-
ceptance X0 has to be as small as possible. In the extreme case, if we choose X0 = Ã¸,
then a type II error cannot occur because we always reject the hypothesis. In the con-
text of Example 8.2.6 this says the buyer rejects all deliveries. In this way he avoids
buying any delivery of bad quality, but he also never gets a proper one. Thus the buyer
takes no risk.
It is pretty clear that both extreme cases presented above are very absurd. Therefore,
one has to ï¬nd a suitable compromise. The approach for such a compromise is as fol-
lows: in a ï¬rst step one chooses tests where the probability of a type I error is bounded
from above. And in a second step, among all these tests satisfying this bound, one
takes the one that minimizes the probability of a type II error. More precisely, we will
investigate tests satisfying the following condition.
Deï¬nition 8.2.15. Suppose we are given a number ! âˆˆ(0, 1), the so-called signi-
ï¬cance level. A test T = (X0, X1) for testing the hypothesis H0 : ( âˆˆC0 against
H1 : ( âˆˆC1 is said to be an !-signiï¬cance test (or shorter !-test), provided the
probability for the occurrence of a type I error is bounded by !. That is, the test
has to satisfy
sup
(âˆˆC0
"T(() = sup
(âˆˆC0
P((X1) â‰¤! .

312
8 Mathematical Statistics
Interpretation: The signiï¬cance level ! is assumed to be small. Typical choices are
! = 0.1 or ! = 0.01. Let T be an !-signiï¬cance test and assume that H0 is true. If we
observe now a sample in the critical region X1, then an event occurred with probability
less than or equal to !, that is, a very unlikely event has been observed. Therefore, we
can be very sure that this could not happen provided that H0 would be true, and we
reject this hypothesis. The probability that we made a mistake is less than or equal
to !, hence very small.
Recall that !-signiï¬cance tests admit no bound for the probability of a type II error.
Therefore, we look for those !-signiï¬cance tests that minimize the probability for a
type II error.
Deï¬nition 8.2.16. Let T1 and T2 be two !-signiï¬cance tests for checking H0
against H1. If their power functions satisfy
"T1(() â‰¥"T2(() ,
( âˆˆC1 ,
then we say that T1 is (uniformly) more powerful than T2.
A (uniformly) most powerful !-test T is one that is more powerful than all
other !-tests.
Remark 8.2.17. Note that "T1(() â‰¥"T2(() implies 1 â€“ "T1(() â‰¤1 â€“ "T2((), hence if T1 is
more powerful than T2, then, according to Remark 8.2.12, the probability for the oc-
currence of a type II error is smaller for T1 than it is for T2. Therefore, a most powerful
!-test is the one that minimizes the probability of occurrence of a type II error.
Remark 8.2.18. The question about existence and uniqueness of most powerful !-
tests is treated in the Neymanâ€“Pearson lemma and its consequences. We will not
discuss that problem here; instead we will construct most powerful tests in concrete
situations. See [CB02], Chapter 8.3.2, for a detailed discussion of the Neymanâ€“Pearson
lemma and its consequences.
We start with the construction of such tests in the hypergeometric case. Here we have
the following.
Proposition 8.2.19. If the statistical model is (X, P(X), HM,N,n)M=0,...,N with X
=
{0, . . . , n}, then a most powerful !-test for testing M â‰¤M0 against M > M0 is given
by T = (X0, X1), where X0 = {0, . . . , m0}, and m0 is deï¬ned by
m0 := max

k â‰¤n :
n

m=k
M0
m
Nâ€“M0
nâ€“m

N
n

> !
$
= min

k â‰¤n :
n

m=k+1
M0
m
Nâ€“M0
nâ€“m

N
n

â‰¤!
$
.

8.2 Statistical Hypothesis Testing
313
Proof: The proof of Proposition 8.2.19 needs the following lemma.
Lemma 8.2.20. The power function, deï¬ned by eq. (8.1), is a nondecreasing function on
the set {0, . . . , N}.
Proof: Suppose we get a delivery of N machines containing M defective ones. Now
there are not only defective machines within the delivery, but also ËœM â€“ M false ones
for some ËœM â‰¥M. We take a sample of size n and test these machines. Let X be the
number of defective machines and let ËœX be the number of machines that are either
defective or false. Of course, we have X â‰¤ËœX implying P(X > m0) â‰¤P( ËœX > m0). Note that
X is HN,M,n-distributed while ËœX is distributed according to HN, ËœM,n. These observations
lead to
"T(M) = HN,M,n({m0 + 1, . . . , n}) = P{X > m0} â‰¤P{ ËœX > m0}
= HN, ËœM,n({m0 + 1, . . . , n}) = "T( ËœM) .
This being true for all M â‰¤ËœM proves that "T is nondecreasing.
âˆ
Let us come back to the proof of Proposition 8.2.19. Set X0 := {0, . . . , m0}, thus X1 =
{m0 + 1, . . . , n} for some (at the moment arbitrary) m0 â‰¤n. Because of Lemma 8.2.20,
the test T = (X0, X1) is an !-signiï¬cance test if and only if it satisï¬es
n

m=m0+1
M0
m
Nâ€“M0
nâ€“m

N
n

= HN,M0,n(X1) = sup
Mâ‰¤M0
HN,M,n(X1) â‰¤! .
To minimize the probability for the occurrence of a type II error, we have to choose X1
as large as possible or, equivalently, m0 as small as possible, that is, if we replace m0
by m0 â€“1, then the new test is no longer an !-test. Thus, in order that T is an !-test that
minimizes the probability for a type II error, the number m0 has to be chosen such that
n

m=m0+1
M0
m
Nâ€“M0
nâ€“m

N
n

â‰¤!
and
n

m=m0
M0
m
Nâ€“M0
nâ€“m

N
n

> ! .
This completes the proof.
âˆ
Example 8.2.21. A buyer gets a delivery of 100 machines. In the case that there are
strictly more than 10 defective machines in the delivery, he will reject it. Thus, his
hypothesis is H0 : M â‰¤10. In order to test H0, he chooses 15 machines and checks
them. Let m be the number of defective machines among the checked ones. For which
m does he reject the delivery with signiï¬cance level ! = 0.01?

314
8 Mathematical Statistics
Answer: We have N = 100, M0 = 10, and n = 15. Since ! = 0.01, by
15

m=5
10
m
 90
15â€“m

100
15

= 0.0063 â‹…â‹…â‹…< !
and
15

m=4
10
m
 90
15â€“m

100
15

= 0.04 â‹…â‹…â‹…> ! ,
it follows that the optimal choice is m0 = 4. Consequently, we have X0 = {0, . . . , 4},
thus, X1 = {5, . . . , 15}. If there are 5 or even more defective machines among the tested
15 ones, then the buyer should reject the delivery. The probability that his decision is
wrong is less than or equal to 0.01.
What can be said about the probability for a type II error? For this test we have
"T(M) =
15

m=5
M
m
100â€“M
15â€“m

100
15

,
hence
1 â€“ "T(M) =
4

m=0
M
m
100â€“M
15â€“m

100
15

.
Since "T is nondecreasing, 1 â€“ "T is nonincreasing, and the probability for a type II
error becomes maximal for M = 11. Recall that C0 = {0, . . . , 10} and, therefore, C1 =
{11, . . . , 100}. Thus, an upper bound for the probability of a type II error is given by
1 â€“ "T(M) â‰¤1 â€“ "T(11) =
4

m=0
11
m
 89
15â€“m

100
15

= 0.989471 ,
M = 11, . . . , 100 .
This tells us that even in the case of most powerful tests the likelihood for a type II
error may be quite large. Even if the number of defective machines is big , this error
may occur with higher probability. For example, we have
1 â€“ "T(20) = 0.853089
or
1 â€“ "T(40) = 0.197057 .
Important Remark: An !-signiï¬cance test provides us with quite precise information
when rejecting the hypothesis H0. In contrast, when we observe a sample x âˆˆX0,
then the only information we get is that we failed to reject H0, thus, we must continue
to regard it as true. Consequently, whenever ï¬xing the null hypothesis, we have to
ï¬x it in a way that either a type I error has the most serious consequences or that
we can achieve the greatest information by rejecting H0. Let us explain this with two
examples.
Example 8.2.22. A certain type of food sometimes contains a special kind of poison.
Suppose there are , milligrams poison in one kilogram of the food. If , > ,0, then

8.3 Tests for Binomial Distributed Populations
315
eating this becomes dangerous while for , â‰¤,0 it is unproblematic. How do we suc-
cessfully choose the hypothesis when testing some sample of the food? We could take
either H0 : , > ,0 or H0 : , â‰¤,0. Which is the right choice?
Answer: The correct choice is H0 : , > ,0. Why? If we reject H0, then we can be
very sure that the food is not poisoned and may be eaten. The probability that someone
will be poisoned is less than !. A type II error occurs if the food is harmless, but we
discard it because our test tells us that it is poisoned. That results in a loss for the
company that produced it, but no one will suffer from poisoning. If we had chosen
H0 : , â‰¤,0, then a type II error occurs if H0 is false, that is, the food is poisoned, but
our test says that it is eatable. Of course, this error is much more serious, and we have
no control in regards to its probability.
Example 8.2.23. Suppose the height of 18-year-old males in the US is normally dis-
tributed with expected value , and variance 32 > 0. We want to know whether
the average height is above or below 6 feet. There is strong evidence that we will
have , â‰¤6, but we cannot prove this. To do so, we execute a statistical experiment
and choose randomly n males of age 18 and measure their height. Which hypothesis
should be checked? If we take H0 : , â‰¤6, then it is very likely that our experiment will
lead to a result that does not contradict this hypothesis, resulting in a small amount
of information gained. But, if we work with the hypothesis H0 : , > 6, then a rejection
of this hypothesis tells us that H0 is very likely wrong, and we may say the conjecture
is true with high probability, namely that we have , â‰¤6. Here the probability that our
conclusion is wrong is very small.
8.3 Tests for Binomial Distributed Populations
Because of its importance we present tests for binomial distributed populations in a
separate section. The starting point is the problem described in Examples 8.1.3 and
8.1.8. In a single experiment we may observe either â€œ0â€ or â€œ1,â€ but we do not know
the probabilities for the occurrence of these events. To obtain some information about
the unknown probabilities we execute n independent trials and record how often â€œ1â€
occurs. This number is Bn,(-distributed for some 0 â‰¤( â‰¤1. Hence, the describing
statistical model is given by
(X, P(X), Bn,()(âˆˆ[0,1]
where
X = {0, . . . , n} .
(8.2)
Two-Sided Tests: We want to check whether the unknown parameter ( satisï¬es ( = (0
or ( /= (0 for some given (0 âˆˆ[0, 1]. Thus, C0 = {(0} and C1 = [0, 1]\{(0}. In other words,
the null and the alternative hypothesis are
H0 : ( = (0
and
H1 : ( /= (0,
respectively.

316
8 Mathematical Statistics
To construct a suitable !-signiï¬cance test for checking H0 we introduce two num-
bers n0 and n1 as follows. Note that these numbers are dependent on (0 and, of course,
also on !.
n0 := min
â§
â¨
â©k â‰¤n :
k

j=0
n
j

(j
0(1 â€“ (0)nâ€“j > !/2
â«
â¬
â­
= max
â§
â¨
â©k â‰¤n :
kâ€“1

j=0
n
j

(j
0(1 â€“ (0)nâ€“j â‰¤!/2
â«
â¬
â­
and
(8.3)
n1 := max
â§
â¨
â©k â‰¤n :
n

j=k
n
j

(j
0(1 â€“ (0)nâ€“j > !/2
â«
â¬
â­
= min
â§
â¨
â©k â‰¤n :
n

j=k+1
n
j

(j
0(1 â€“ (0)nâ€“j â‰¤!/2
â«
â¬
â­.
(8.4)
Proposition 8.3.1. Regard the statistical model (8.2) and let 0 < ! < 1 be a signiï¬cance
level. The hypothesis test T = (X0, X1) with
X0 := {n0, n0 + 1, . . . , n1 â€“ 1, n1}
and
X1 = {0, . . . , n0 â€“ 1} âˆª{n1 + 1, . . . , n}
is an !-signiï¬cance test to check H0 : ( = (0 against H1 : ( /= (0. Here n0 and n1 are
deï¬ned as in eqs. (8.3) and (8.4).
Proof: Since C0 consists only of the point {(0}, an arbitrary test T = (X0, X1) is an
!-signiï¬cance test if and only if Bn,(0(X1) â‰¤!. Now let T be as in the formulation of the
proposition. By the deï¬nition of the numbers n0 and n1 we obtain
Bn,(0(X1) =
n0â€“1

j=0
n
j

(j
0(1 â€“ (0)nâ€“j +
n

j=n1+1
n
j

(j
0(1 â€“ (0)nâ€“j â‰¤!
2 + !
2 = ! ,
that is, as claimed, the test T := (X0, X1) is an !-signiï¬cance test. Note that the re-
gion X1 is chosen maximal. In fact, neither n0 can be enlarged nor n1 can be made
smaller.
âˆ
Remark 8.3.2. In this test the critical region X1 consists of two parts or tails. There-
fore, this type of hypothesis test is called two-sided test.
Example 8.3.3. In an urn is an unknown number of white and black balls. Let ( âˆˆ[0, 1]
be the proportion of white balls. We conjecture that there are as many white as black
balls in the urn. That is, the null hypothesis is H0 : ( = 0.5. To test this hypothesis we

8.3 Tests for Binomial Distributed Populations
317
choose one after the other 100 balls with replacement. In order to determine n0 and n1
in this situation let > be deï¬ned as
>(k) :=
kâ€“1

j=0
100
j

â‹…
1
2
100
.
Numerical calculations give
>(37) = 0.00331856, >(38) = 0.00601649, >(39) = 0.0104894
>(40) = 0.0176001, >(41) = 0.028444, >(42) = 0.044313
>(43) = 0.0666053, >(44) = 0.096674, >(45) = 0.135627
>(46) = 0.184101, >(47) = 0.242059, >(48) = 0.30865,
>(49) = 0.382177, >(50) = 0.460205 .
If the signiï¬cance level is chosen as ! = 0.1 we see that >(42) â‰¤0.05, but >(43) > 0.05.
Hence, by the deï¬nition of n0 in eq. (8.3), it follows that n0 = 42. By symmetry, for
n1 deï¬ned in eq. (8.4), we get n1 = 58. Consequently, the regions of acceptance and
rejection are given by
X0 = {42, 43, . . . , 57, 58}
and
X1 = {0, . . . , 41} âˆª{59, . . . , 100} .
For example, if we observe during 100 trials k white balls for some k < 42 or some
k > 58, then we may be quite sure that our null hypothesis is wrong, that is, the number
of white and black balls is signiï¬cantly different. This assertion is 90% sure.
If we want to be more secure about the conclusion, we have to choose a smaller
signiï¬cance level. For example, if we take ! = 0.01, the values of > imply n0 = 37 and
n1 = 63, hence
X0 = {37, 38, . . . , 62, 63}
and
X1 = {0, . . . , 36} âˆª{64, . . . , 100} .
Again we see that a smaller bound for the probability of a type I error leads to an
enlargement of X0, thus, to an increase of the chance for a type II error.
One-Sided Tests: Now the null hypothesis is H0 : ( â‰¤(0 for some (0 âˆˆ[0, 1]. In the
context of Example 8.1.3 we claim that the proportion of white balls in the urn does not
exceed (0. For instance, if (0 = 1/2, then we want to test whether or not the number of
white balls is less than or equal to that of black ones.
Before we present a most powerful test for this situation let us deï¬ne a number n0
depending on (0 and on the signiï¬cance level 0 < ! < 1.

318
8 Mathematical Statistics
n0 := max
â§
â¨
â©k â‰¤n :
n

j=k
n
j

(j
0(1 â€“ (0)nâ€“j > !
â«
â¬
â­
(8.5)
= min
â§
â¨
â©k â‰¤n :
n

j=k+1
n
j

(j
0(1 â€“ (0)nâ€“j â‰¤!
â«
â¬
â­.
Now we are in a position to state the most powerful one-sided !-test for a binomial
distributed population.
Proposition 8.3.4. Suppose X = {0, . . . , n}, and let (X, P(X), Bn,()(âˆˆ[0,1] be the statist-
ical model describing a binomial distributed population. Given 0 < ! < 1, deï¬ne n0 by
eq. (8.5) and set X0 = {0, . . . , n0}, hence X1 = {n0 + 1, . . . , n}. Then T = (X0, X1) is the
most powerful !-test to check the null hypothesis H0 : ( â‰¤(0 against H1 : ( > (0.
Proof: With an arbitrary 0 â‰¤nâ€² â‰¤n deï¬ne the region of acceptance X0 of a test T by
X0 = {0, . . . , nâ€²}. Then its power function is given by
"T(() = Bn,((X1) =
n

j=nâ€²+1
n
j

(j (1 â€“ ()nâ€“j ,
0 â‰¤( â‰¤1 .
(8.6)
To proceed further we need the following lemma.
Lemma 8.3.5. The power function (8.6) is nondecreasing in [0, 1].
Proof: Suppose in an urn there are white, red, and black balls. Their proportions are
(1, (2 â€“(1 and 1â€“(2 for some 0 â‰¤(1 â‰¤(2 â‰¤1. Choose n balls with replacement. Let X be
the number of chosen white balls, and Y is the number of balls that were either white
or red. Then X is Bn,(1-distributed, while Y is distributed according to Bn,(2. Moreover,
X â‰¤Y, hence it follows that P(X > nâ€²) â‰¤P(Y > nâ€²), which leads to
"T((1) = Bn,(1({nâ€² + 1, . . . , n}) = P(X > nâ€²) â‰¤P(Y > nâ€²)
= Bn,(2({nâ€² + 1, . . . , n}) = "T((2) .
This being true for all (1 â‰¤(2 completes the proof.
âˆ
An application of Lemma 8.3.5 implies that the above test T is an !-signiï¬cance test if
and only if
n

j=nâ€²+1
n
j

(j
0(1 â€“ (0)nâ€“j = "T((0) = sup
(â‰¤(0
"T(() â‰¤! .
In order to minimize the probability of a type II error, we have to choose X0 as small
as possible. That is, if we replace nâ€² by nâ€² â€“ 1, the modiï¬ed test is no longer an !-test.

8.4 Tests for Normally Distributed Populations
319
Thus, the optimal choice is nâ€² = n0 where n0 is deï¬ned by eq. (8.5). This completes the
proof of Proposition 8.3.4.
âˆ
Example 8.3.6. Let us come back to the problem investigated in Example 8.1.3. Our
null hypothesis is H0 : ( â‰¤1/2, that is, we claim that at most half of the balls are white.
To test H0, we choose 100 balls and record their color. Let k be the number of observed
white balls. For which k must we reject H0 with a security of 90%?
Answer: Since
100

k=56
100
k

2â€“100 = 0.135627
and
100

k=57
100
k

2â€“100 = 0.096674 ,
for ! = 0.1 the number n0 in eq. (8.5) equals n0 = 56. Consequently, the region of
acceptance for the best 0.1-test is given by X0 = {0, . . . , 56}. Thus, whenever there are
57 or more white balls among the chosen 100 the hypothesis has to be rejected. The
probability for a wrong decision is less than or equal to 0.1.
Making the signiï¬cance level smaller, for example, taking ! = 0.01, this implies
n0 = 63. Hence, if the number of white balls is 64 or larger, a rejection of H0 is
99% sure.
Remark 8.3.7. Example 8.3.6 emphasizes once more the dilemma of hypothesis test-
ing. The price one pays for higher security, when rejecting H0, is the increase of the
likelihood of a type II error. For instance, replacing ! = 0.1 by ! = 0.01 in the previ-
ous example leads to an enlargement of X0 from {0, . . . , 56} to {0, . . . , 63}. Thus, if we
observe 60 white balls, we reject H0 in the former case, but we cannot reject it in the
latter one. This once more stresses the fact that an observation of an x âˆˆX0 does not
guarantee that H0 is true. It only means that the observed sample does not allow us to
reject the hypothesis.
8.4 Tests for Normally Distributed Populations
During this section we always assume X = Rn. That is, our samples are vectors
x = (x1, . . . , xn) with xj âˆˆR. Given a sample x âˆˆRn, we derive from it the following
quantities that will soon play a crucial role.
Deï¬nition 8.4.1. If x = (x1, . . . , xn) âˆˆRn, then we set
Â¯x := 1
n
n

j=1
xj , s2
x :=
1
n â€“ 1
n

j=1
(xj â€“ Â¯x)2 and 32
x := 1
n
n

j=1
(xj â€“ Â¯x)2 .
(8.7)

320
8 Mathematical Statistics
The number Â¯x is said to be the sample mean of x, while s2
x and 32
x are said to
be the unbiased sample variance and the (biased) sample variance of the
vector x, respectively.
Analogously, if X = (X1, . . . , Xn) is an n-dimensional random vector,3 then we deï¬ne
the corresponding expressions pointwise. For instance, we have
Â¯X(9) := 1
n
n

j=1
Xj(9)
and
s2
X(9) :=
1
n â€“ 1
n

j=1
(Xj(9) â€“ Â¯X(9))2 .
8.4.1 Fisherâ€™s Theorem
We are going to prove important properties of normally distributed populations. They
turn out to be the basis for all hypothesis tests in the normally distributed case. The
starting point is a crucial lemma going back to Ronald Aylmer Fisher.
Lemma 8.4.2 (Fisherâ€™s lemma). Let Y1, . . . , Yn be independent N(0, 1)-distributed ran-
dom variables and let B =

"ij
n
i,j=1 be a unitary n Ã— n matrix. The random variables
Z1, . . . , Zn are deï¬ned as
Zi :=
n

j=1
"ijYj ,
1 â‰¤i â‰¤n .
They possess the following properties.
(i)
The variables Z1, . . . , Zn are also independent and N(0, 1)-distributed.
(ii)
For m < n let the quadratic form Q on Rn be deï¬ned by
Q :=
n

j=1
Y2
j â€“
m

i=1
Z2
i .
Then Q is independent of all Z1, . . . , Zm and distributed according to 72
nâ€“m.
Proof: Assertion (i) was already proven in Proposition 6.1.16.
3 To simplify the notation, now and later on, we denote random vectors by X, not by âƒ—X as we did
before. This should not lead to confusion.

8.4 Tests for Normally Distributed Populations
321
Let us verify (ii). The matrix B is unitary, thus it preserves the length of vectors in
Rn. Applying this to Y = (Y1, . . . , Yn) and Z = BY gives
n

i=1
Z2
i = |Z|2
2 = |BY|2
2 = |Y|2
2 =
n

j=1
Y2
j ,
which leads to
Q = Z2
m+1 + â‹…â‹…â‹…+ Z2
n .
(8.8)
By virtue of (i) the random variables Z1, . . . , Zn are independent, hence by eq. (8.8)
and Remark 4.1.10 the quadratic form Q is independent of Z1, . . . , Zm.
Recall that Zm+1, . . . , Zn are independent N(0, 1)-distributed. Thus, in view of
eq. (8.8), Proposition 4.6.17 implies that Q is 72
nâ€“m-distributed. Observe that Q is the
sum of n â€“ m squares.
âˆ
Now we are in a position to state and prove one of the most important results in
Mathematical Statistics.
Proposition 8.4.3 (Fisherâ€™s theorem). Suppose X1, . . . , Xn are independent and distrib-
uted according to N(,, 32) for some , âˆˆR and some 32 > 0. Then the following are
valid:
âˆš
n
Â¯X â€“ ,
3
is
N(0, 1)-distributed .
(8.9)
(n â€“ 1) s2
X
32
is
72
nâ€“1-distributed .
(8.10)
âˆš
n
Â¯X â€“ ,
sX
is
tnâ€“1-distributed ,
(8.11)
where sX := +
+
s2
X. Furthermore, Â¯X and s2
X are independent random variables.
Proof: Let us begin with the proof of assertion (8.9). Since the Xjs are independent
and N(,, 32)-distributed, by Proposition 4.6.18 their sum X1 + â‹…â‹…â‹…+ Xn possesses an
N(n,, n32) distribution. Consequently, an application of Proposition 4.2.3 implies that
Â¯X is N(,, 32/n)-distributed, hence, another application of Proposition 4.2.3 tells us
that
Â¯Xâ€“,
3/âˆšn is standard normal. This completes the proof of statement (8.9).
We turn now to the veriï¬cation of the remaining assertions. Letting
Yj := Xj â€“ ,
3
,
1 â‰¤j â‰¤n ,
(8.12)

322
8 Mathematical Statistics
the random variables Y1, . . . , Yn are independent N(0, 1)-distributed. Moreover, their
(unbiased) sample variance may be calculated by
s2
Y =
1
n â€“ 1
n

j=1
(Yj â€“ Â¯Y)2 =
1
n â€“ 1
â§
â¨
â©
n

j=1
Y2
j â€“ 2 Â¯Y
n

j=1
Yj + n Â¯Y2
â«
â¬
â­
=
1
n â€“ 1
â§
â¨
â©
n

j=1
Y2
j â€“ 2n Â¯Y2 + n Â¯Y2
â«
â¬
â­=
1
n â€“ 1
â§
â¨
â©
n

j=1
Y2
j â€“ (
âˆš
n Â¯Y)2
â«
â¬
â­.
(8.13)
To proceed further, set b1
:= (nâ€“1/2, . . . , nâ€“1/2), and note that b1 is a normalized
n-dimensional vector, that is, we have |b1|2 = 1. Let E âŠ†Rn be the (n â€“ 1)-dimensional
subspace consisting of elements that are perpendicular to b1. Choosing an orthonor-
mal basis b2, . . . , bn in E, then, by the choice of E, the vectors b1, . . . , bn form an
orthonormal basis in Rn. If bi = ("i1, . . . , "in), 1 â‰¤i â‰¤n, let B be the n Ã— n-matrix with
entries "ij, that is, the vectors b1, . . . , bn are the rows of B. Since (bi)n
i=1 are orthonormal,
B is unitary.
As in Lemma 8.4.2, deï¬ne Z1, . . . , Zn by
Zi :=
n

j=1
"ijYj ,
1 â‰¤i â‰¤n ,
and the quadratic form Q (with m = 1) as
Q :=
n

j=1
Y2
j â€“ Z2
1 .
Because of Lemma 8.4.2, the quadratic form Q is 72
nâ€“1-distributed and, furthermore, it
is independent of Z1. By the choice of B and of b1,
"11 = â‹…â‹…â‹…= "1n = nâ€“1/2 ,
hence Z1 = n1/2 Â¯Y, and by eq. (8.13) this leads to
Q =
n

j=1
Y2
j â€“ (n1/2 Â¯Y)2 = (n â€“ 1) s2
Y .
This observation implies (n â€“ 1) s2
Y is 72
nâ€“1-distributed and, moreover, (n â€“ 1)s2
Y and Z1
are independent, thus also s2
Y and Z1.

8.4 Tests for Normally Distributed Populations
323
The choice of the Yjs in eq. (8.12) immediately implies Â¯Y =
Â¯Xâ€“,
3 , hence
(n â€“ 1) s2
Y =
n

j=1
(Yj â€“ Â¯Y)2 =
n

j=1

Xj â€“ ,
3
â€“
Â¯X â€“ ,
3
2
= s2
X
32 (n â€“ 1) ,
which proves assertion (8.10).
Recall that Z1 = n1/2 Â¯Y = n1/2 Â¯Xâ€“,
3 , which leads to Â¯X = nâ€“1/2 3Z1 + ,. Thus, because
of Proposition 4.1.9, the independence of s2
Y = s2
X/32 and Z1 implies that s2
X and Â¯X are
independent as well.
It remains to prove statement (8.11). We already know that V := âˆšn
Â¯Xâ€“,
3 is standard
normal, and W := (n â€“ 1) s2
X/32 is 72
nâ€“1-distributed. Since they are independent, by
Proposition 4.7.8, applied with n â€“ 1, we get
âˆš
n
Â¯X â€“ ,
sX
=
V
+
1
nâ€“1 W
is
tnâ€“1-distributed .
This implies assertion (8.11) and completes the proof of the proposition.
âˆ
Remark 8.4.4. It is important to mention that the random variables X1, . . . , Xn satisfy
the assumptions of Proposition 8.4.3 if and only if the vector (X1, . . . , Xn) is N(,, 32)âŠ—n-
distributed or, equivalently, if its probability distribution is N(âƒ—,, 32In).
8.4.2 Quantiles
Quantiles may be deï¬ned in a quite general way. However, we will restrict ourselves
to those quantiles that will be used later on. The ï¬rst quantiles we consider are those
of the standard normal distribution.
Deï¬nition 8.4.5. Let I be the distribution function of N(0, 1), as it was intro-
duced in Deï¬nition 1.62. For a given " âˆˆ(0, 1), the "-quantile z" of the standard
normal distribution is the unique real number satisfying
I(z") = "
or, equivalently,
z" = Iâ€“1(") .
Another way to deï¬ne z" is as follows. Let X be a standard normal random variable.
Then z" is the unique real number such that
P{X â‰¤z"} = " .
The following properties of z" will be used later on.

324
8 Mathematical Statistics
Proposition 8.4.6. Let X be standard normally distributed. Then the following are valid
1.
We have z" â‰¤0 for " â‰¤1/2 and z" > 0 for " > 1/2.
2.
P{X â‰¥z"} = 1 â€“ ".
3.
If 0 < " < 1, then z1â€“" = â€“z" .
4.
For 0 < ! < 1 we have P{|X| â‰¥z1â€“!/2} = ! .
Proof: The ï¬rst property easily follows by I(0) = 1/2, hence I(t) > 1/2 if and only if
t > 0.
Let X be standard normal. Then P{X â‰¥z"} = 1 â€“ P{X â‰¤z"} = 1 â€“ ", which proves the
second assertion.
Since â€“X is standard normal as well, by 2. it follows that
P{X â‰¤â€“z"} = P{X â‰¥z"} = 1 â€“ " = P{X â‰¤z1â€“"} ,
hence z1â€“" = â€“z" as asserted.
To prove the fourth assertion note that properties 2 and 3 imply
P{|X| â‰¥z1â€“!/2} = P{X â‰¤â€“z1â€“!/2 or X â‰¥z1â€“!/2}
= P{X â‰¤â€“z1â€“!/2} + P{X â‰¥z1â€“!/2}
= P{X â‰¤z!/2} + P{X â‰¥z1â€“!/2} = !/2 + !/2 = ! .
Here we used 1 â€“ !/2 > 1/2 implying z1â€“!/2 > 0, hence the events {X â‰¤â€“z1â€“!/2} and
{X â‰¥z1â€“!/2} are disjoint.
âˆ
The next quantile, needed later on, is that of a 72
n distribution.
Deï¬nition 8.4.7. Let X be distributed according to 72
n and let 0 < " < 1. The unique
(positive) number 72
n;" satisfying
P{X â‰¤72
n;"} = "
is called "-quantile of the 72
n-distribution.
Two other, equivalent, ways to introduce these quantiles are as follows.
1.
If X1, . . . , Xn are independent standard normal, then
P{X2
1 + â‹…â‹…â‹…+ X2
n â‰¤72
n;"} = " .

8.4 Tests for Normally Distributed Populations
325
2.
The quantile 72
n;" satisï¬es
1
2n/2A(n/2)
 72
n;"
0
xn/2â€“1 eâ€“x/2dx = " .
For later purposes we mention also the following property. If 0 < ! < 1, then for any
72
n-distributed random variable X,
P{X âˆ‰[72
n;!/2 , 72
n;1â€“!/2]} = ! .
In a similar way we deï¬ne now the quantiles of Studentâ€™s tn and of Fisherâ€™s
Fm,n distributions. For their descriptions we refer to Deï¬nitions 4.7.6 and 4.7.13,
respectively.
Deï¬nition 8.4.8. Let X be tn-distributed and let Y be distributed according to Fm,n.
For " âˆˆ(0, 1) the "-quantiles tn;" and Fm,n;" of the tn- and Fm,n-distributions are the
unique numbers satisfying
P{X â‰¤tn;"} = "
and
P{Y â‰¤Fm,n;"} = " .
Remark 8.4.9. Let X be tn distributed. Then â€“X is tn distributed as well, hence
P{X â‰¤s} = P{â€“X â‰¤s} for s âˆˆR. Therefore, as in the case of the normal distribution,
we get â€“tn;" = tn;1â€“", and also
P{|X| > tn;1â€“!/2} = P{|X| â‰¥tn;1â€“!/2} = ! .
(8.14)
Remark 8.4.10. Another way to introduce the quantiles of the Fm,n-distribution is
as follows. Let X and Y be independent and distributed according to 72
m and 72
n,
respectively. The quantile Fm,n;" is the unique number satisfying
P
5X/m
Y/n â‰¤Fm,n;"
6
= " .
If s > 0, then
P
5X/m
Y/n â‰¤s
6
= P
5 Y/n
X/m â‰¥1
s
6
= 1 â€“ P
5 Y/n
X/m â‰¤1
s
6
,
which immediately implies
Fm,n;" =
1
Fn,m;1â€“"
.

326
8 Mathematical Statistics
8.4.3 Z-Tests or Gauss Tests
Suppose we have an item of unknown length. In order to get some information about
its length, we measure the item n times with an instrument of known accuracy. As
sample we get a vector x = (x1, . . . , xn), where xj is the value obtained in the jth meas-
urement. These measurements were executed independently, thus, we may assume
that the xjs are independent N(,, 32
0)-distributed with known 32
0 > 0 and unknown
length , âˆˆR. Therefore, the describing statistical model is

Rn, B(Rn), N(,, 32
0)âŠ—n
,âˆˆR =

Rn, B(Rn), N(âƒ—,, 32
0In)

,âˆˆR .
From the hypothesis, two types of tests apply in this case. We start with the so-called
one-sided Z-test (also called one-sided Gauss test). Here the null hypothesis is H0 :
, â‰¤,0, where ,0 âˆˆR is a given real number. Consequently, the alternative hypothesis
is H1 : , > ,0, that is, C0 = (â€“âˆ, ,0] while C1 = (,0, âˆ). In the above context this
says that we claim that the length of the item is less than or equal to a given ,0, and to
check this we measure the item n times.
Proposition 8.4.11. Let ! âˆˆ(0, 1) be a given security level. Then T = (X0, X1) with
X0 :=

x âˆˆRn : Â¯x â‰¤,0 + nâ€“1/2 30 z1â€“!

and with
X1 :=

x âˆˆRn : Â¯x > ,0 + nâ€“1/2 30 z1â€“!

is an !-signiï¬cance test to check H0 against H1. Here z1â€“! denotes the (1 â€“ !)-quantile
introduced in Deï¬nition 8.4.5.
Proof: The assertion of Proposition 8.4.11 says that
sup
,â‰¤,0
P,(X1) = sup
,â‰¤,0
N(,, 32
0)âŠ—n(X1) â‰¤! .
To verify this, let us choose an arbitrary , â‰¤,0 and deï¬ne S : Rn â†’R by
S(x) :=
âˆš
n Â¯x â€“ ,
30
,
x âˆˆRn .
(8.15)
Regard S as a random variable on the probability space (Rn, B(Rn), N(,, 32
0)âŠ—n). Then,
by property (8.9), it is standard normally distributed.4 Consequently,
4 This fact is crucial. For better understanding, here is a more detailed reasoning. Deï¬ne random
variables Xj on the probability space (Rn, B(Rn), N (,, 32
0)âŠ—n) by Xj(x) = xj, where x = (x1, . . . , xn).
Then the random vector X = (X1, . . . , Xn) is the identity on Rn, hence N (,, 32
0)âŠ—n-distributed. In view
of Remark 8.4.4 and by
S(x) =
âˆš
n
Â¯X(x) â€“ ,
30
,
assertion (8.9) applies for S, that is, it is N (0, 1)-distributed.

8.4 Tests for Normally Distributed Populations
327
N(,, 32
0)âŠ—n{x âˆˆRn : S(x) > z1â€“!} = ! .
(8.16)
Since , â‰¤,0, we have
X1 =

x âˆˆRn : Â¯x > ,0 + nâ€“1/2 30 z1â€“!

âŠ†{x âˆˆRn : Â¯x > , + nâ€“1/2 30 z1â€“!} = {x âˆˆRn : S(x) > z1â€“!} ,
hence, by eq. (8.16), it follows that
N(,, 32
0)âŠ—n(X1) â‰¤N(,, 32
0)âŠ—n{x âˆˆRn : S(x) > z1â€“!} = ! .
This completes the proof.
âˆ
What does the power function of the Z-test in Proposition 8.4.11 look like? If S is as in
eq. (8.15), then, according to Deï¬nition 8.2.11,
"T(,) = N(,, 32
0)âŠ—n(X1) = N(,, 32
0)âŠ—n
5
x âˆˆRn :
âˆš
n Â¯x â€“ ,0
30
> z1â€“!
6
= N(,, 32
0)âŠ—n
5
x âˆˆRn : S(x) > z1â€“! + (,0 â€“ ,)
âˆšn
30
6
= 1 â€“ I

z1â€“! + (,0 â€“ ,)
âˆšn
30

= I

z! + (, â€“ ,0)
âˆšn
30

.
In particular, "T is increasing on R with "T(,0) = !. Moreover, we see that "T(,) < ! if
, < ,0, and "T(,) > ! for , > ,0.
1.0
0.8
0.6
0.4
0.2
1
2
3
4
Figure 8.1: Power function of T with ! = 0.05, ,0 = 2, 30 = 1, and n = 10.

328
8 Mathematical Statistics
While the critical region of a one-sided Z-test is an interval, in the case of the two-
sided Z-test it is the union of two intervals. Here the null hypothesis is H0 : , = ,0,
hence the alternative hypothesis is given as H1 : , /= ,0.
Proposition 8.4.12. The test T = (X0, X1), where
X0 :=

x âˆˆRn : ,0 â€“ nâ€“1/2 30 z1â€“!/2 â‰¤Â¯x â‰¤,0 + nâ€“1/2 30 z1â€“!/2

and X1 = Rn\X0, is an !-signiï¬cance test to check H0 : , = ,0 against H1 : , /= ,0.
Proof: Since here C0 = {,0}, the proof becomes easier than in the one-sided case. We
only have to verify that
N(,0, 32
0)âŠ—n(X1) â‰¤! .
(8.17)
Regarding S, deï¬ned by
S(x) :=
âˆš
n Â¯x â€“ ,0
30
,
as random variable on (Rn, B(Rn), N(,0, 32
0)âŠ—n), by the same arguments as in the pre-
vious proof, it is standard normally distributed. Thus, using assertion 4 of Proposition
8.4.6, we obtain
N(,0, 32
0)âŠ—n(X1) = N(,0, 32
0)âŠ—n{x âˆˆRn : |S(x)| > z1â€“!/2} = ! .
Of course, this completes the proof.
âˆ
8.4.4 t-Tests
The problem is similar to the one considered in the case of the Z-test. But, there is one
important difference. We do no longer assume that the variance is known, which will
be so in most cases. Therefore, this test is more realistic than the Z-test.
The starting point is the statistical model
(Rn, B(Rn), N(,, 32)âŠ—n)(,,32)âˆˆRÃ—(0,âˆ) .
Observe that the unknown parameter is now a vector (,, 32) âˆˆR Ã— (0, âˆ). We begin by
investigating the one-sided t-test. Given some ,0 âˆˆR, the null hypothesis is as before,
that is, we have H0 : , â‰¤,0. In the general setting that means C0 = (â€“âˆ, ,0] Ã— (0, âˆ),
while C1 = (,0, âˆ) Ã— (0, âˆ)

8.4 Tests for Normally Distributed Populations
329
To formulate the next result, let us shortly recall the following notations. If s2
x
denotes the unbiased sample variance, as deï¬ned in eq. (8.7), then we set sx := +
=
s2x.
Furthermore, tnâ€“1;1â€“! denotes the (1â€“!)-quantile of the tnâ€“1-distribution, as introduced
in Deï¬nition 8.4.8.
Proposition 8.4.13. Given ! âˆˆ(0, 1), the regions X0 and X1 in Rn are deï¬ned by
X0 :=

x âˆˆRn : Â¯x â‰¤,0 + nâ€“1/2 sx tnâ€“1;1â€“!

and X1 = Rn\X0. With this choice of X0 and X1, the test T = (X0, X1) is an !-signiï¬cance
test for H0 : , â‰¤,0 against H1 : , > ,0.
Proof: Given , â‰¤,0, deï¬ne the random variable S on (Rn, B(Rn), N(,, 32)âŠ—n) as
S(x) :=
âˆš
n Â¯x â€“ ,
sx
,
x âˆˆRn .
Property (8.11) implies that S is tnâ€“1-distributed, hence by the deï¬nition of the quantile
tnâ€“1;1â€“!, it follows that
N(,, 32)âŠ—n{x âˆˆRn : S(x) > tnâ€“1;1â€“!} = ! .
From , â‰¤,0 we easily derive
X1 âŠ†{x âˆˆRn : S(x) > tnâ€“1;1â€“!} ,
thus, as asserted,
sup
,â‰¤,0
N(,, 32)âŠ—n(X1) â‰¤N(,, 32)âŠ—n{x âˆˆRn : S(x) > tnâ€“1;1â€“!} = ! .
âˆ
As in the case of the Z-test, the null hypothesis of the two-sided t-test is H0 : , = ,0
for some ,0 âˆˆR. Again, we do not assume that the variance is known.
A two-sided t-test with signiï¬cance level ! may be constructed as follows.
Proposition 8.4.14. Given ! âˆˆ(0, 1), deï¬ne regions X0 and X1 in Rn by
X0 :=
5
x âˆˆRn :
âˆš
n
....
Â¯x â€“ ,0
sx
.... â‰¤tnâ€“1;1â€“!/2
6
and X1 = Rn\X0. Then T = (X0, X1) is an !-signiï¬cance test for H0 : , = ,0 against
H1 : , /= ,0.

330
8 Mathematical Statistics
Proposition 8.4.14 is proven by similar methods, as we have used for the proofs of
Propositions 8.4.12 and 8.4.13. Therefore, we decline to prove it here.
Example 8.4.15. We claim a certain workpiece has a length of 22 inches. Thus, the null
hypothesis is H0 : , = 22. To check H0, we measure the piece 10 times under the same
conditions. The 10 values we obtained are (in inches)
22.17, 22.11, 22.10, 22.14, 22.02, 21.95, 22.02, 22.08, 21.98, 22.15
Do these values allow us to reject the hypothesis or do they conï¬rm it?
We have
Â¯x = 22.072
and
sx = 0.07554248 ,
hence
âˆš
10 Â¯x â€“ 22
sx
= 3.013986 .
If we choose the security level ! = 0.05, we have to investigate the quantile t9;0.975,
which equals t9;0.975 = 2.26. This lets us conclude the observed vector x = (x1, . . . , x10)
belongs to X1, and we may reject H0. Consequently, with a security of 95% we may say,
, /= 22.
Remark 8.4.16. If we plug these 10 values into a mathematical program, the result will
be a number !0 = 0.00128927. What does this number tell us? It says the following. If
we have chosen a signiï¬cance level ! with ! > !0, then we have to reject H0. But, if
the chosen ! satisï¬es ! < !0, then we fail to reject H0. In our case we had ! = 0.05 >
0.00128927 = !0, hence we may reject H0.
8.4.5 72-Tests for the Variance
The aim of this section is to get some information about the (unknown) variance of
a normal distribution. Again we have to distinguish between the following two cases.
The expected value is known or, otherwise, the expected value is unknown.
Let us start with the former case, that is, we assume that the expected value is
known to be some ,0 âˆˆR. Then the statistical model is (Rn, B(Rn), N(,0, 32)âŠ—n)32>0.
In the one-sided 72-test, the null hypothesis is H0 : 32 â‰¤32
0, for some given 32
0 > 0,
while in the two-sided 72-test we claim that H0 : 32 = 32
0.
Proposition 8.4.17. In the one-sided setting, an !-signiï¬cance 72-test T = (X0, X1) is
given by
X0 :=
â§
â¨
â©x âˆˆRn :
n

j=1
(xj â€“ ,0)2
32
0
â‰¤72
n;1â€“!
â«
â¬
â­.

8.4 Tests for Normally Distributed Populations
331
For the two-sided case, choose
X0 :=
â§
â¨
â©x âˆˆRn : 72
n;!/2 â‰¤
n

j=1
(xj â€“ ,0)2
32
0
â‰¤72
n;1â€“!/2
â«
â¬
â­,
to obtain an !-signiï¬cance test. In both cases the critical region is X1 := Rn\X0.
Proof: We prove the assertion only in the (slightly more difï¬cult) one-sided case. For
an arbitrarily chosen 32 â‰¤32
0, let N(,0, 32)âŠ—n be the underlying probability measure.
We deï¬ne now the random variables Xj : Rn â†’R as Xj(x) = xj for x = (x1, . . . , xn). Then
the Xjs are independent N(,0, 32)-distributed. The normalization Yj :=
Xjâ€“,0
3
leads to
independent standard normal Yjs. Thus, if
S :=
n

j=1
(Xj â€“ ,0)2
32
=
n

j=1
Y2
j ,
then by Proposition 4.6.17, the random variable S is 72
n-distributed. By the deï¬nition of
quantiles, we arrive at
N(,0, 32)âŠ—n C
x âˆˆRn : S(x) > 7n;1â€“!
D
= ! .
Since 32 â‰¤32
0, it follows that
X1 âŠ†
C
x âˆˆRn : S(x) > 7n;1â€“!
D
,
hence N(,0, 32)âŠ—n(X1)
â‰¤
!. This proves, as asserted, that T
=
(X0, X1) is an
!-signiï¬cance test.
âˆ
Let us now turn to the case where the expected value is unknown. Here the statistical
model is given by
(Rn, B(Rn), N(,, 32)âŠ—n)(,,32)âˆˆRÃ—(0,âˆ) .
In the one-sided case, the parameter set C = R Ã— (0, âˆ) splits up into C = C0 âˆªC1
with
C0 = R Ã— (0, 32
0]
and
C1 = R Ã— (32
0, âˆ) .
In the two-sided case we have
C0 = R Ã— {32
0}
and
C1 = R Ã—

(0, 32
0) âˆª(32
0, âˆ)

.

332
8 Mathematical Statistics
Proposition 8.4.18. In the one-sided case, an !-signiï¬cance test T = (X0, X1) is given by
X0 :=
5
x âˆˆRn : (n â€“ 1) s2
x
32
0
â‰¤72
nâ€“1;1â€“!
6
.
In the two-sided case, choose the region of acceptance as
X0 :=
5
x âˆˆRn : 72
n;!/2 â‰¤(n â€“ 1) s2
x
32
0
â‰¤72
nâ€“1;1â€“!/2
6
to get an !-signiï¬cance test. Again, the critical regions are given by X1 := Rn\X0.
Proof: The proof is very similar to the one of Proposition 8.4.17, but with some
important difference. Here we have to set
S(x) := (n â€“ 1) s2
x
32 ,
x âˆˆRn .
Then property (8.10) applies, and it lets us conclude that S is 72
nâ€“1-distributed, provided
that N(,, 32)âŠ—n is the true probability measure. After that observation the proof is
completed as the one of Proposition 8.4.17.
âˆ
8.4.6 Two-Sample Z-Tests
The two-sample Z-test compares the parameters of two different populations. Suppose
we are given two different series of data, say x = (x1, . . . , xm) and y = (y1, . . . , yn), which
were obtained independently by executing m experiments of the ï¬rst kind and n of the
second one. Combine both series to a single vector (x, y) âˆˆRm+n.
A typical example for the described situation is as follows. A farmer grows grain
on two different acres. On one acre he added fertilizer, on the other one he did not.
Now he wants to ï¬gure out whether or not adding fertilizer inï¬‚uenced the amount
of grain gathered. Therefore, he measures the amount of grain on the ï¬rst acre at m
different spots and those on the second one at n spots. The aim is to compare the mean
values in both series of experiments.
We suppose that the samples x1, . . . , xm of the ï¬rst population are independent
and N(,1, 32
1)-distributed, while the y1, . . . , yn of the second population are independ-
ent and N(,2, 32
2)-distributed. Typical questions are as follows. Do we have ,1 = ,2 or,
maybe, only ,1 â‰¤,2? One may also ask whether or not 32
1 = 32
2 or, maybe, only 32
1 â‰¤32
2.
To apply the two-sample Z-test, one has to suppose the variances 32
1 and 32
2 as
known. This reduces the number of parameters from 4 to 2, namely to ,1 and ,2 in R.
Thus, the describing statistical model is given by

Rm+n, B(Rm+n), N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n
(,1,,2)âˆˆR2 .
(8.18)

8.4 Tests for Normally Distributed Populations
333
Recall that N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n denotes the multivariate normal distribution
with expected value (,1, . . . , ,1



m
, ,2, . . . , ,2



n
) and covariance matrix R = (rij)m+n
i,j=1, where
rii = 32
1 if 1 â‰¤i â‰¤m, and rii = 32
2 if m < i â‰¤m + n. Furthermore, rij = 0 if i /= j.
Proposition 8.4.19. The statistical model is that in (8.18). To test H0 : ,1 â‰¤,2 against
H1 : ,1 > ,2, set
X0 :=

(x, y) âˆˆRm+n :
E
mn
n32
1 + m32
2
(Â¯x â€“ Â¯y) â‰¤z1â€“!
$
and X1 = Rm+n\X0. Then the test T = (X0, X1) is an !-signiï¬cance test for checking H0
against H1.
To test H0 : ,1 = ,2 against H1 : ,1 /= ,2, let
X0 :=

(x, y) âˆˆRm+n :
E
mn
n32
1 + m32
2
|Â¯x â€“ Â¯y| â‰¤z1â€“!/2
$
and X1 = Rm+n\X0. Then the test T = (X0, X1) is an !-signiï¬cance test for checking H0
against H1.
Proof: Since the proof of the two-sided case is very similar to that of the one-sided
one, we only prove the ï¬rst assertion. Thus, let us assume that H0 is valid, that is, we
have ,1 â‰¤,2. Then we have to verify that
N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n(X1) â‰¤! .
(8.19)
To prove this, we investigate the random variables Xi and Yj deï¬ned as Xi(x, y) = xi
and Yj(x, y) = yj. Since the underlying probability space is
(Rm+n, B(Rm+n), N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n) ,
these random variables are independent and distributed according to N(,1, 32
1) and
N(,2, 32
2), respectively. Consequently, Â¯X is N

,1,
32
1
m

-distributed, while Â¯Y is distrib-
uted according to N

,2,
32
2
n

. By the construction, Â¯X and Â¯Y are independent as well,
and moreover since â€“ Â¯Y is N

â€“,2,
32
2
n

-distributed, we conclude that the distribution
of Â¯X â€“ Â¯Y equals N

,1 â€“ ,2,
32
1
m +
32
2
n

. Therefore, the mapping S : Rm+n â†’R deï¬ned by
S(x, y) :=
32
1
m + 32
2
n
â€“1/2 
( Â¯X(x, y) â€“ Â¯Y(x, y)) â€“ (,1 â€“ ,2)


334
8 Mathematical Statistics
is standard normal. By the deï¬nition of the quantiles, this leads to
N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n{(x, y) âˆˆRm+n : S(x, y) > z1â€“!} = ! .
(8.20)
Since we assumed H0 to be correct, that is, we suppose ,1 â‰¤,2, it follows that
S(x, y) â‰¥
32
1
m + 32
2
n
â€“1/2
[ Â¯X(x, y) â€“ Â¯Y(x, y)] =
E
mn
n32
1 + m32
2
[ Â¯X(x, y) â€“ Â¯Y(x, y)] .
Hence
X1 âŠ†{(x, y) âˆˆRm+n : S(x, y) > z1â€“!} ,
which by eq. (8.20) implies estimate (8.19). This completes the proof of this part of the
proposition.
âˆ
8.4.7 Two-Sample t-Tests
The situation is similar as in the two-sample Z-test, yet with one important difference.
The variances 32
1 and 32
2 of the two populations are no longer known. Instead, we have
to assume that they coincide, that is, we suppose
32
1 = 32
2 := 32 .
Therefore, there are three unknown parameters, the expected values ,1, ,2, and the
common variance 32. Thus, the statistical model describing this situation is given by

Rm+n, B(Rm+n), N(,1, 32)âŠ—m âŠ—N(,2, 32)âŠ—n
(,1,,2,32)âˆˆR2Ã—(0,âˆ) .
(8.21)
To simplify the formulation of the next statement, introduce T : Rm+n â†’R as
T(x, y) :=
"
(m + n â€“ 2) m n
m + n
Â¯x â€“ Â¯y
+
(m â€“ 1)s2x + (n â€“ 1)s2y
,
(x, y) âˆˆRm+n .
(8.22)
Proposition 8.4.20. Let the statistical model be as in (8.21). If
X0 :=
C
(x, y) âˆˆRm+n : T(x, y) â‰¤tm+nâ€“2;1â€“!
D
and X1 = Rm+n\X0, then T = (X0, X1) is an !-signiï¬cance test for H0 : ,1 â‰¤,2 against
H1 : ,1 > ,2.
On the other hand, the test T = (X0, X1) with
X0 :=
C
(x, y) âˆˆRm+n : |T(x, y)| â‰¤tm+nâ€“2;1â€“!/2
D
and X1 = Rm+n\X0 is an !-signiï¬cance test for H0 : ,1 = ,2 against H1 : ,1 /= ,2.

8.4 Tests for Normally Distributed Populations
335
Proof: This time we prove the two-sided case, that is, the null hypothesis is given by
H0 : ,1 = ,2.
Let the random vectors X = (X1, . . . , Xm) and Y = (Y1, . . . , Yn) on Rm+n be deï¬ned
with Xis and Yjs as in the proof of Proposition 8.4.19, that is, we have X(x, y) = x
and Y(x, y) = y. Then by Proposition 4.1.9 and Remark 4.1.10, the unbiased sample
variances
s2
X =
1
m â€“ 1
m

i=1
(Xi â€“ Â¯X)2
and
s2
Y =
1
n â€“ 1
m

j=1
(Yj â€“ Â¯Y)2
are independent as well. Furthermore, by virtue of statement (8.10), the random
variables
(m â€“ 1)s2
X
32
and
(n â€“ 1)s2
Y
32
are distributed according to 72
mâ€“1 and 72
nâ€“1, respectively. Proposition 4.6.16 implies that
S2
(X,Y) := 1
32
C
(m â€“ 1)s2
X + (n â€“ 1)s2
Y
D
is 72
m+nâ€“2-distributed. Since s2
X and Â¯X as well as s2
Y and Â¯Y are independent, by Propos-
ition 8.4.3, this is also so for S2
(X,Y) and Â¯X â€“ Â¯Y. As in the proof of Proposition 8.4.19, it
follows that Â¯X â€“ Â¯Y is distributed according to N

,1 â€“ ,2,
32
1
m +
32
2
n

. Assume now that
H0 is true, that is, we have ,1 = ,2. Then the last observation implies that
âˆšmn
3âˆšm+n( Â¯Xâ€“ Â¯Y)
is a standard normally distributed random variable and, furthermore, independent of
S2
(X,Y). Thus, by Proposition 4.7.8, the distribution of the quotient
Z :=
âˆš
m + n â€“ 2
âˆšmn
3âˆšm+n( Â¯X â€“ Â¯Y)
S(X,Y)
,
where S(X,Y) := +
+
S2
(X,Y), is tm+nâ€“2-distributed. If T is as in eq. (8.22), then it is not difï¬-
cult to prove that Z = T(X, Y). Therefore, by the deï¬nition of X and Y, the mapping T is
a tm+nâ€“2-distributed random variable on Rm+n, endowed with the probability measure
P,1,,2,32 = N(,1, 32)âŠ—m âŠ—N(,2, 32)âŠ—n. By eq. (8.14) this implies
P,1,,2,32(X1) = P,1,,2,32
C
(x, y) âˆˆRm+n : |T(x, y)| > tm+nâ€“2;1â€“!/2
D
= ! ,
as asserted.
âˆ

336
8 Mathematical Statistics
8.4.8 F-Tests
In this ï¬nal section about tests we compare the variances of two normally distributed
sample series. Since the proofs of the assertions follow the schemes presented in the
previous propositions, we decline to verify them here. We only mention the facts that
play a crucial role during the proofs.
1.
If X1, . . . , Xm and Y1, . . . , Yn are independent and distributed according to
N(,1, 32
1) and N(,2, 32
2), then
V := 1
32
1
m

i=1
(Xi â€“ ,1)2
and
W := 1
32
2
n

j=1
(Yj â€“ ,2)2
are 72
m and 72
n-distributed and independent. Consequently, the quotient V/m
W/n is
Fm,n-distributed.
2.
For X1, . . . , Xm and Y1, . . . , Yn independent and standard normal, the random
variables
(m â€“ 1) s2
X
32
1
and
(n â€“ 1) s2
Y
32
2
are independent and distributed according to 72
mâ€“1 and 72
nâ€“1, respectively. Thus,
assuming 31 = 32, the quotient s2
X/s2
Y possesses an Fmâ€“1,nâ€“1-distribution.
When applying an F-test, as before, two different cases have to be considered.
(K) The expected values ,1 and ,2 of the two populations are known. Then the
statistical model is given by

Rm+n, B(Rm+n), N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n
(32
1,32
2)âˆˆ(0,âˆ)2 .
(U) The expected values are unknown. This case is described by the statistical model

Rm+n, B(Rm+n), N(,1, 32
1)âŠ—m âŠ—N(,2, 32
2)âŠ—n
(,1,,2,32
1,32
2)âˆˆR2Ã—(0,âˆ)2 .
In both cases the null hypothesis may either be H0 : 32
1 â‰¤32
2 in the one-sided case
or H0 : 32
1 = 32
2 in the two-sided one. The regions of acceptance in each of the four
different cases are given by the following subsets of Rm+n, and always X1 = Rm+n\X0.
Case 1:
H0 : 32
1 â‰¤32
2 and ,1, ,2 are known.
X0 :=

(x, y) âˆˆRm+n :
1
m
m
i=1(xi â€“ ,1)2
1
n
n
j=1(yj â€“ ,2)2 â‰¤Fm,n;1â€“!
$

8.5 Point Estimators
337
Case 2:
H0 : 32
1 = 32
2 and ,1, ,2 are known.
X0 :=

(x, y) âˆˆRm+n : Fm,n;!/2 â‰¤
1
m
m
i=1(xi â€“ ,1)2
1
n
n
j=1(yj â€“ ,2)2 â‰¤Fm,n;1â€“!/2
$
Case 3:
H0 : 32
1 â‰¤32
2 and ,1, ,2 are unknown.
X0 :=

(x, y) âˆˆRm+n : s2
x
s2y
â‰¤Fmâ€“1,nâ€“1;1â€“!
$
Case 4:
H0 : 32
1 = 32
2 and ,1, ,2 are unknown.
X0 :=

(x, y) âˆˆRm+n : Fmâ€“1,nâ€“1;!/2 â‰¤s2
x
s2y
â‰¤Fmâ€“1,nâ€“1;1â€“!/2
$
8.5 Point Estimators
Starting point is a parametric statistical model (X, F, P()(âˆˆC. Assume we execute a
statistical experiment and observe a sample x âˆˆX. The aim of this section is to show
how this observation leads to a â€œgoodâ€ estimation of the unknown parameter ( âˆˆC.
Example 8.5.1. Suppose the statistical model is (Rn, B(Rn), N(,, 32
0)âŠ—n),âˆˆR for some
known 32
0 > 0. Thus, the unknown parameter is the expected value , âˆˆR. To estimate
it, we execute n independent measurements and get x = (x1, . . . , xn) âˆˆRn. Knowing
this vector x, what is a â€œgoodâ€ estimation for ,? An intuitive approach is to deï¬ne the
point estimator Ë†, : Rn â†’R as
Ë†,(x) = 1
n
n

j=1
xj = Â¯x ,
x = (x1, . . . , xn) âˆˆRn .
In other words, if the observed sample is x, then we take its sample mean Ë†,(x) = Â¯x as
estimation for ,. An immediate question is whether Ë†, is a â€œgoodâ€ estimator for ,. Or
do there exist maybe â€œbetterâ€ (more precise) estimators for ,?
Before we investigate such and similar questions, the problem has to be generalized
slightly. Sometimes it happens that we are not interested in the concrete value of the
parameter ( âˆˆC. We only want to know the value #(() derived from (. Thus, for some
function # : C â†’R we want to ï¬nd a â€œgoodâ€ estimator Ë†# : X â†’R for #((). In other
words, if we observe a sample x âˆˆX, then we take Ë†#(x) as estimation for the (unknown)
value #((). However, in most cases the function # is not needed. That is, here we have
#(() = (, and we look for a good estimator Ë†( : X â†’C for (.
Let us state an example where a nontrivial function # plays a role.

338
8 Mathematical Statistics
Example 8.5.2. Let (Rn, B(Rn), N(,, 32)âŠ—n)(,,32)âˆˆRÃ—(0,âˆ) be the statistical model. Thus,
the unknown parameter is the two-dimensional vector (,, 32). But, in fact we are only
interested in ,, not in the pair (,, 32). That is, if
#(,, 32) := , ,
(,, 32) âˆˆR Ã— (0, âˆ) ,
then we want to ï¬nd an estimation for #(,, 32).
Analogously , if we only want an estimation for 32, then we choose # as
#(,, 32) := 32 ,
(,, 32) âˆˆR Ã— (0, âˆ) .
After these preliminary considerations, we state now the precise deï¬nition of an
estimator.
Deï¬nition 8.5.3. Let (X, F, P()(âˆˆC be a parametric statistical model and let # :
C â†’R be a function of the parameter. A mapping Ë†# : X â†’R is said to be a point
estimator (or simply estimator) for #(() if, given t âˆˆR, the set {x âˆˆX : Ë†#(x) â‰¤t}
belongs to the 3-ï¬eld F. In other words, Ë†# is a random variable deï¬ned on X.
The interpretation of this deï¬nition is as follows. If one observes the sample x âˆˆX,
then Ë†#(x) is an estimation for #((). For example, if one measures a workpiece four times
and gets 22.03, 21.87, 22.11, and 22, 15 inches as results, then using the estimator Ë†, in
Example 8.5.2, the estimation for the mean value equals 22.04 inches.
8.5.1 Maximum Likelihood Estimation
Let (X, F, P()(âˆˆC be a parametric statistical model. There exist several methods to con-
struct â€œgoodâ€ point estimators for the unknown parameter (. In this section we present
the probably most important of these methods, the so-called maximum likelihood
principle.
To understand this principle, the following easy example may be helpful.
Example 8.5.4. Suppose the parameter set consists of two elements, say C = {0, 1}.
Moreover, also the sample space X has cardinality two, that is, X = {a, b}. Then the
problem is as follows. Depending on the observation a or b, we have to choose either 0
or 1 as estimation for (.
For example, let us assume that P0({a}) = 1/4, hence P0({b}) = 3/4, and P1({a}) =
P1({b}) = 1/2. Say, an experiment has outcome â€œa.â€ What would be a good estimation
for ( in this case? Should we take â€œ0â€ or â€œ1â€? The answer is, we should choose â€œ1.â€
Why? Because the sample â€œaâ€ ï¬ts better to P1 than to P0. By the same argument, we

8.5 Point Estimators
339
should take â€œ0â€ as an estimation if we observe â€œb.â€ Thus, the point estimator for ( is
given by Ë†((a) = 1 and Ë†((b) = 0.
Which property characterizes the estimator Ë†( in Example 8.5.4? To answer this
question, ï¬x x âˆˆX and look at the function
( â†¦P(({x}) ,
( âˆˆC .
(8.23)
If x = a, this function becomes maximal for ( = 1, while for x = b it attains its maximal
value at ( = 0. Consequently, the estimator Ë†( could also be deï¬ned as follows. For each
ï¬xed x âˆˆX, choose as estimation the ( âˆˆC, for which the function (8.23) becomes
maximal. But this is exactly the approach of the maximum likelihood principle.
In order to describe this principle in the general setting, we have to introduce the
notion of the likelihood function. Let us ï¬rst assume that the sample space X consists
of at most countably many elements.
Deï¬nition 8.5.5. The function p from C Ã— X to R deï¬ned as
p((, x) := P(({x}) ,
( âˆˆC , x âˆˆX ,
is called likelihood function of the statistical model (X, P(X), P()(âˆˆC.
We come now to the case where all probability measures P( are continuous. Thus, we
assume that the statistical model is (Rn, B(Rn), P()(âˆˆC and, moreover, each P( is con-
tinuous, that is, it has a density mapping Rn to R. This density is not only a function
of x âˆˆRn, it also depends on the probability measure P(, hence on ( âˆˆC. Therefore,
we denote the densities by p((, x). In other words, for each ( âˆˆC and each box Q âŠ†Rn
as in eq. (1.65) we have
P((Q) =

Q
p((, x) dx =
b1

a1
â‹…â‹…â‹…
bn

an
p((, x1, . . . , xn) dxn . . . dx1 .
(8.24)
Deï¬nition 8.5.6. The function p : C Ã— Rn â†’R satisfying eq. (8.24) for all boxes Q
and all ( âˆˆC is said to be the likelihood function of the statistical model
(Rn, B(Rn), P()(âˆˆC.
For a better understanding of Deï¬nitions 8.5.5 and 8.5.6, let us give some examples of
likelihood functions.

340
8 Mathematical Statistics
1.
First take (X, P(X), Bn,()0â‰¤(â‰¤1 with X
= {0, . . . , n} from Section 8.3. Then its
likelihood function equals
p((, k) =
n
k

(k(1 â€“ ()nâ€“k ,
( âˆˆ[0, 1] , k âˆˆ{0, . . . , n} .
(8.25)
2.
Consider the statistical model (X, P(X), HN,M,n)M=0,...,N investigated in Example
8.1.4. Then its likelihood function is given by
p(M, m) =
M
m
Nâ€“M
nâ€“m

N
n

,
M = 0, . . . , N , m = 0, . . . , n .
(8.26)
3.
The likelihood function of the model (Nn
0, P(Nn
0), PoisâŠ—n
+ )+>0 investigated in Ex-
ample 8.5.21 is
p(+, k1, . . . , kn) = +k1+â‹…â‹…â‹…+kn
k1! â‹…â‹…â‹…kn! eâ€“+n ,
+ > 0 , kj âˆˆN0 .
(8.27)
4.
The likelihood function of (Rn, B(Rn), N(,, 32)âŠ—n)(,,32)âˆˆRÃ—(0,âˆ) from Example 8.1.12
can be calculated by
p(,, 32, x) =
1
(20)n/23n exp

â€“|x â€“ âƒ—,|2
232

, , âˆˆR , 32 > 0 .
(8.28)
Here, as before, let âƒ—, = (,, . . . , ,).
5.
The likelihood function of (Rn, B(Rn), EâŠ—n
+ )+>0 from Example 8.1.9 may be repres-
ented as
p(+, t1, . . . , tn) =

+n eâ€“+(t1+â‹…â‹…â‹…+tn) : tj â‰¥0 , + > 0
0
:
otherwise
(8.29)
Deï¬nition 8.5.7. Let (X, F, P()(âˆˆC be a parametric statistical model with likeli-
hood function p : C Ã— X â†’R. An estimator Ë†( : X â†’C is said to be a maximum
likelihood estimator (MLE) for ( âˆˆC provided that, for each x âˆˆX, the following
is satisï¬ed:
p(Ë†((x), x) = max
(âˆˆC p((, x)

8.5 Point Estimators
341
Remark 8.5.8. Another way to deï¬ne the MLE is as follows5:
Ë†((x) = arg max
(âˆˆC
p((, x) ,
x âˆˆX .
How does one ï¬nd the MLE for concrete statistical models? One observation is that
the logarithm is an increasing function. Thus, the likelihood function p( â‹…, x) becomes
maximal at a certain parameter ( âˆˆC if ln p( â‹…, x) does so.
Deï¬nition 8.5.9. Let (X, F, P()(âˆˆC be a statistical model and let p : C Ã— X â†’R be
its likelihood function. Suppose p((, x) > 0 for all ((, x). Then the function
L((, x) := ln p((, x) ,
( âˆˆC , x âˆˆX ,
is called log-likelihood function of the model.
Thus, Ë†( is an MLE if and only if
Ë†((x) = arg max
(âˆˆC
L((, x) ,
x âˆˆX ,
or, equivalently, if
L(Ë†((x), x) = max
(âˆˆC L((, x) .
Example 8.5.10. If p is the likelihood function in eq. (8.25), then the log-likelihood
function equals
L((, k) = c + k ln ( + (n â€“ k) ln(1 â€“ () ,
0 â‰¤( â‰¤1 , k = 0, . . . , n .
(8.30)
Here c âˆˆR denotes a certain constant independent of (.
Example 8.5.11. The log-likelihood function of p in eq. (8.29) is well-deï¬ned for + > 0
and tj â‰¥0. For those +s and tjs it is given by
L(+, t1, . . . , tn) = n ln + â€“ +(t1 + â‹…â‹…â‹…+ tn) .
To proceed further we assume now that the parameter set C is a subset of Rk for some
k â‰¥1. That is, each parameter ( consists of k unknown components, that is, it may be
5 If f is a real-valued function with domain A, then x = arg max
yâˆˆA
f(y) if x âˆˆA and f(x) â‰¥f(y) for all
y âˆˆA. In other words, x is one of the points in the domain A where f attains its maximal value.

342
8 Mathematical Statistics
written as ( = ((1, . . . , (k) with (j âˆˆR. Furthermore, suppose that for each ï¬xed x âˆˆX
the log-likelihood function L( â‹…, x) is continuously differentiable6 on C. Then points
(âˆ—âˆˆC where L( â‹…, x) becomes maximal must satisfy
âˆ‚
âˆ‚(i
L((, x)
...
(=(âˆ—= 0 ,
i = 1, . . . , k .
(8.31)
In particular, this is true for the MLE Ë†((x). If for each x âˆˆX the log-likelihood function
L( â‹…, x) is continuously differentiable on C âŠ†Rk, then the MLE Ë†( satisï¬es
âˆ‚
âˆ‚(i
L((, x)
...
(=Ë†((x) = 0 ,
i = 1, . . . , k .
Example 8.5.12. Let us determine the MLE for the log-likelihood function in eq. (8.30).
Here we have C = [0, 1] âŠ†R, hence the MLE Ë†( : {0, . . . , n} â†’[0, 1] has to satisfy
âˆ‚
âˆ‚(L(Ë†((k), k) =
k
Ë†((k)
â€“
n â€“ k
1 â€“ Ë†((k)
= 0 .
This easily gives Ë†((k) = k
n , that is, the MLE in this case is deï¬ned by
Ë†((k) = k
n ,
k = 0, . . . , n .
Let us interpret this result. In an urn are white and black balls of unknown proportion.
Let ( be the proportion of white balls. To estimate (, draw n balls out of the urn, with
replacement. Assume k of the chosen balls are white. Then Ë†((k) = k
n is the MLE for the
unknown proportion ( of white balls.
Example 8.5.13. The logarithm of the likelihood function p in eq. (8.28) equals
L(,, 32, x) = L(,, 32, x1, . . . , xn) = c â€“ n
2 â‹…ln 32 â€“
1
232
n

j=1
(xj â€“ ,)2
with some constant c âˆˆR, independent of , and of 32. Thus, here C âŠ†R2, hence, if
(âˆ—= (,âˆ—, 32âˆ—) denotes the pair satisfying eq. (8.31), then
âˆ‚
âˆ‚,L(,, 32, x)
...
(,,32)=(,âˆ—,32âˆ—) = 0
and
âˆ‚
âˆ‚32 L(,, 32, x)
...
(,,32)=(,âˆ—,32âˆ—) = 0 .
6 The partial derivatives exist and are continuous.

8.5 Point Estimators
343
Now
âˆ‚
âˆ‚,L(,, 32, x) = 1
32
n

j=1
(xj â€“ ,) = 1
32
â¡
â£
n

j=1
xj â€“ n,
â¤
â¦,
which implies ,âˆ—= 1
n
n
j=1 xj = Â¯x.
The derivative of L with respect to 32, taken at ,âˆ—= Â¯x, equals
âˆ‚
âˆ‚32 L(Â¯x, 32, x) = â€“n
2 â‹…1
32 + 1
34
n

j=1
(xj â€“ Â¯x)2 .
It becomes zero at 32âˆ—satisfying
32âˆ—= 1
n
n

j=1
(xj â€“ Â¯x)2 = 32
x ,
where 32
x was deï¬ned in eq. (8.7). Combining these observations, we see that the only
pair (âˆ—= (,âˆ—, 32âˆ—) satisfying eq. (8.31) is given by (Â¯x, 32
x). Consequently, as MLE for
( = (,, 32) we obtain
Ë†,(x) = Â¯x
and
F
32(x) = 32
x ,
x âˆˆRn .
Remark 8.5.14. Similar calculations as in the previous examples show that the MLE
for the likelihood functions in eqs. (8.27) and (8.29) coincide with
Ë†+(k1, . . . , kn) = 1
n
n

i=1
ki
and
Ë†+(t1, . . . , tn) =
1
1
n
n
i=1 ti
.
Finally, we present two likelihood functions where we have to determine their max-
imal values directly. Note that the above approach via the log-likelihood function does
not apply if the parameter set C is either ï¬nite or countably inï¬nite. In this case a de-
rivative of L( â‹…, x) does not make sense, hence we cannot determine points where it
vanishes.
The ï¬rst problem is the one we discussed in Remark 1.4.27. A retailer gets a deliv-
ery of N machines. Among the N machines are M defective ones. Since M is unknown,
the retailer wants a â€œgoodâ€ estimate for it. Therefore, he chooses by random n ma-
chines and tests them. Suppose he observes m defective machines among the tested.
Does this lead to an estimation of the number M of defective machines? The next
proposition answers this question.

344
8 Mathematical Statistics
Proposition 8.5.15. The statistical model is given by (X, P(X), HM,N,n)M=0,...,N. Then
the MLE Ë†M for M is of the form
Ë†M(m) =
 
m(N+1)
n

: m < n
N
: m = n
Here [ â‹…] denotes the integer part of a real number, for example, [1.2] = 1 or [0] = 3.
Proof: The likelihood function p was determined in eq. (8.26) as
p(M, m) =
M
m
Nâ€“M
nâ€“m

N
n

,
M = 0, . . . , N , m = 0, . . . , n .
First note that p(M, m) /= 0 if and only if M âˆˆ{m, . . . , Nâ€“n+m} and, therefore, it sufï¬ces
to investigate p(M, m) for Ms in this region. Thus, if M â€“ 1 â‰¥m, then easy calculations
lead to
p(M, m)
p(M â€“ 1, m) =
M
M â€“ m â‹…N â€“ M + 1 â€“ (n â€“ m)
N â€“ M + 1
.
(8.32)
By eq. (8.32) it follows that we have p(M, m) â‰¥p(M â€“ 1, m) if and only if
M(N â€“ M + 1 â€“ (n â€“ m)) â‰¥(M â€“ m)(N â€“ M + 1) .
Elementary transformations show the last estimate is equivalent to
â€“nM â‰¥â€“mN â€“ m ,
which happens if and only if M â‰¤m(N+1)
n
.
Consequently, M â†¦p(M, m) is nondecreasing on

0, . . . ,

m(N+1)
n

, and it is
nonincreasing on

m(N+1)
n

, . . . , N]

. Thus, if m < n, then the likelihood function
M â†¦p(M, m) becomes maximal for Mâˆ—=

m(N+1)
n

, and the MLE is given by
Ë†M(m) =
m(N + 1)
n

,
m = 0, . . . , n â€“ 1 .
If m = n, then M â†¦p(M, m) is nonincreasing on {0, . . . , N}, hence in this case the
likelihood function attains its maximal value at M = N, that is, Ë†M(n) = N.
âˆ
Example 8.5.16. A retailer gets a delivery of 100 TV sets for further selling. He chooses
by random 15 sets and tests them. If there is exactly one defective TV set among the
15 tested, then the estimation for the number of defective sets in the delivery is 6. If
he observes 2 defective sets, the estimation is 13, for 4 it is 26, and if there are even

8.5 Point Estimators
345
6 defective TV sets among the 15 chosen, then the estimation is that 40 sets of the
delivery are defective.
Finally we come back to the question asked in Remark 1.4.29. In order to estimate
the number N of ï¬sh in a pond one catches M of them, marks them and puts them
back into the pond. After some time one catches ï¬sh again, this time n of them.
Among them m are marked. Does this number m lead to a â€œgoodâ€ estimation of
the number of ï¬sh in the pond? To describe this problem we choose as statistical
model
(X, P(X), HN,M,n)N=0,1,...
where X = {0, . . . , n}. Here HN,M,n denotes the hypergeometric probability measure
introduced in Deï¬nition 1.4.25. Thus, in this case the likelihood function is given by
p(N, m) =
M
m
Nâ€“M
nâ€“m

N
n

,
N = 0, 1, . . . ,
m = 0, . . . , n .
In the sequel we have to exclude m = 0; in this case there does not exist a reasonable
estimation for N.
Proposition 8.5.17. If 1 â‰¤m â‰¤n , then the MLE Ë†N for N is
Ë†N(m) =
Mn
m

.
(8.33)
Proof: The proof is quite similar to that of Proposition 8.5.15. Since
p(N, m)
p(N â€“ 1, m) = N â€“ M
N
â‹…
N â€“ n
N â€“ M â€“ (n â€“ m) ,
it easily follows that the inequality p(N, m) â‰¥p(N â€“ 1, m) is valid if and only if N â‰¤Mn
m .
Therefore, N â†¦p(N, m) is nondecreasing if N â‰¤

Mn
m

and nonincreasing for the
remaining N. This immediately shows that the MLE is given by eq. (8.33).
âˆ
Example 8.5.18. An unknown number of balls are in an urn. In order to estimate
this number, we choose 50 balls from the urn and mark them. We put back the
marked balls and mix the balls in the urn thoroughly. Then we choose another 30
balls from the urn. If there are 7 marked among the 30, then the estimation for the
number of balls in the urn is 214. In the case of two marked balls, the estimation
equals 750 while in the case of 16 marked balls we estimate that there are 93 balls in
the urn.

346
8 Mathematical Statistics
8.5.2 Unbiased Estimators
Let us come back to the general setting. We are given a function # : C â†’R and look for
a â€œgoodâ€ estimation for #((). If Ë†#(x) is the estimation, in most cases it will not be the
correct value #((). Sometimes the estimate is larger than #((), sometimes one observes
an x âˆˆX for which Ë†#(x) is smaller than the true value. For example, if the retailer in
Example 8.5.16 gets every week a delivery of 100 TV sets, then sometimes his estim-
ation for the number of defective sets will be bigger than the true value, sometimes
smaller. Since he only pays for the nondefective sets, sometimes he pays too much,
sometimes too less. Therefore, a crucial condition for a good estimator should be that,
on average, it meets the correct value. That is, in the long run the loss and the gain of
the retailer should balance. In other words, the estimator should not be biased by a
systematic error.
In view of Proposition 7.1.29, this condition for the estimator Ë†# may be formulated
as follows. If ( âˆˆC is the â€œtrueâ€ parameter, then the expected value of Ë†# should be #(().
To make this more precise7 we need the following notation.
Deï¬nition 8.5.19. Let (X, F, P()(âˆˆC be a statistical model and let X : X â†’R be
a random variable. We write E(X whenever the expected value of X is taken with
respect to P(. Similarly, in this case deï¬ne
V(X = E(|X â€“ E(X|2
as variance of X. Of course, we have to assume that the expected value and/or the
variance exist.
Remark 8.5.20. If X is discrete with values in {t1, t2, . . .}, then
E(X =
âˆ

j=1
tj P({X = tj} .
The case of continuous X is slightly more difï¬cult because here we have to describe
the density function of X with respect to P(.
To become acquainted with Deï¬nition 8.5.19, the two following examples may be
helpful. The ï¬rst one deals with the discrete case, the second with the continuous
one.
7 How the expected value is deï¬ned? Note that we do not have only one probability measure, but
many different ones.

8.5 Point Estimators
347
Example 8.5.21. Suppose the daily number of customers in a shopping center is Pois-
son distributed with unknown parameter + > 0. To estimate this parameter, we record
the number of customers on n different days. Thus, the sample we obtain is a vec-
tor âƒ—k = (k1, . . . , kn) with kj âˆˆN0, where kj is the number of customers on day j. The
describing statistical model is given by (Nn
0, P(Nn
0), PoisâŠ—n
+ )+>0 with distribution Pois+.
Let X : Nn
0 â†’R be deï¬ned by
X(âƒ—k) = X(k1, . . . , kn) := 1
n
n

j=1
kj ,
âƒ—k = (k1, . . . , kn) âˆˆNn
0 .
Which value does E+X possess?
Answer: If we choose PoisâŠ—n
+
as probability measure, then all Xjs deï¬ned by
Xj(k1, . . . , kn) := kj are Pois+-distributed (and independent, but this is not needed
here). Note that Xj is nothing else as the number of customers at day j. Hence, by
Proposition 5.1.16, the expected value of Xj is +, and since X =
1
n
n
j=1 Xj, we ï¬nally
obtain
E+X = E+
â›
â1
n
n

j=1
Xj
â
â = 1
n
n

j=1
E+Xj = 1
n n+ = + .
Example 8.5.22. Take
(Rn, B(Rn), N(,, 32)âŠ—n)(,,32)âˆˆRÃ—(0,âˆ)
as the statistical model. Thus, the parameter is of the form (,, 32) for some , âˆˆR and
32 > 0. Deï¬ne X : Rn â†’R by X(x) = Â¯x. If the underlying measure is N(,, 32)âŠ—n, then8
X is N(,, 32/n)-distributed. Consequently, in view of Propositions 5.1.34 and 5.2.27 we
obtain
E,,32X = ,
and
V,,32X = 32
n .
Using the notation introduced in Deï¬nition 8.5.19, the above-mentioned requirement
for â€œgoodâ€ estimators may now be formulated more precisely.
Deï¬nition 8.5.23. An estimator Ë†# : X â†’R is said to be an unbiased estimator for
# : C â†’R provided that for each ( âˆˆC
E(|Ë†#| < âˆ
and
E(Ë†# = #(() .
8 Compare the ï¬rst part of the proof of Proposition 8.4.3.

348
8 Mathematical Statistics
Remark 8.5.24. In view of Proposition 7.1.29, an estimator Ë†# is unbiased if it possesses
the following property: observe N independent samples x1, . . . , xN of a statistical ex-
periment. Suppose that ( âˆˆC is the â€œtrueâ€ parameter (according to which the xjs are
distributed). Then
P
â§
â¨
â©lim
Nâ†’âˆ
1
N
n

j=1
Ë†#(xj) = #(()
â«
â¬
â­= 1 .
Thus, on average, the estimator Ë†# meets approximately the correct value.
Example 8.5.25. Let us investigate whether the estimator in Example 8.5.12 is un-
biased. The statistical model is (X, P(X), Bn,()0â‰¤(â‰¤1, where X = {0, . . . , n} and the
estimator Ë†( acts as
Ë†((k) = k
n ,
k = 0, . . . , n .
Setting Z := n Ë†(, then Z is the identity on X, hence Bn,(-distributed. Proposition 5.1.13
implies E(Z = n (, thus,
E(Ë†( = E(

Z/n

= E(Z/n = ( .
(8.34)
Equation (8.34) holds for all ( âˆˆ[0, 1], that is, Ë†( is an unbiased estimator for (.
Example 8.5.26. Next we come back to the problem presented in Example 8.5.21. The
number of customers per day is Pois+-distributed with an unknown parameter + > 0.
The data of n days are combined in a vector Ë†k = (k1, . . . , kn) âˆˆNn
0. Then the parameter
+ > 0 is estimated by Ë†+ deï¬ned as
Ë†+(âƒ—k) = Ë†+(k1, . . . , kn) := 1
n
n

j=1
kj .
Is this estimator for + unbiased?
Answer: Yes, it is unbiased. Observe that Ë†+ coincides with the random variable X
investigated in Example 8.5.21. There we proved E+ = +, hence, if + > 0, then we have
E+Ë†+ = + .
Example 8.5.27. We are given certain data x1, . . . , xn, which are known to be normally
distributed and independent, and where the expected value , and the variance 32
of the underlying probability measure are unknown. Thus, the describing statistical
model is
(Rn, B(Rn), N(,, 32)n)(,,32)âˆˆC
with
C = R Ã— (0, âˆ) .

8.5 Point Estimators
349
The aim is to ï¬nd unbiased estimators for , and for 32. Let us begin with estimating ,.
That is, if # is deï¬ned by #(,, 32) = ,, then we want to construct an unbiased estimator
Ë†# for #. Let us take the MLE Ë†# deï¬ned as
Ë†#(x) := Â¯x = 1
n
n

j=1
xj ,
x = (x1, . . . , xn) .
Due to the calculations in Example 8.5.22 we obtain
E,,32 Ë†# = , = #(,, 32) .
This holds for all , and 32, hence Ë†# is an unbiased estimator for , = #(,, 32).
How to ï¬nd a suitable estimator for 32? This time the function # has to be chosen
as #(,, 32) := 32. With s2
x deï¬ned in eq. (8.7) set
Ë†#(x) := s2
x =
1
n â€“ 1
n

j=1
(xj â€“ Â¯x)2 ,
x âˆˆRn .
Is this an unbiased estimator for 32 ? To answer this we use property (8.10) of Pro-
position 8.4.3. It asserts that the random variable x â†¦(n â€“ 1) s2x
32 is 72
nâ€“1-distributed,
provided it is deï¬ned on (Rn, B(Rn), N(,, 32)âŠ—n). Consequently, by Corollary 5.1.30 it
follows that
E,,32

(n â€“ 1) s2
x
32

= n â€“ 1 .
Using the linearity of the expected value, we ï¬nally obtain
E,,32 Ë†# = E,,32 s2
x = 32 .
Therefore, Ë†#(x) = s2
x is an unbiased9 estimator for 32.
Remark 8.5.28. Taking the estimator Ë†#(x) = 32
x in the previous example, then, in view
of 32
x = nâ€“1
n s2
x, it follows that
E,,32 Ë†# = n â€“ 1
n
32 .
Thus, the estimator Ë†#(x) = 32
x is biased. But note that
lim
nâ†’âˆ
n â€“ 1
n
32 = 32 ,
9 This explains why s2
x is called unbiased sample variance.

350
8 Mathematical Statistics
hence, if the sample size n is big, then this estimator is â€œalmostâ€ unbiased. One says in
this case the sequence of estimators (in dependence on n) is asymptotically unbiased.
The next example is slightly more involved, but of great interest in application.
Example 8.5.29. The lifetime of light bulbs is supposed to be exponentially distrib-
uted with some unknown parameter + > 0. To estimate + we switch on n light bulbs
and record the times t1, . . . , tn when they burn out. Thus, the observed sample is a
vector t = (t1, . . . , tn) in (0, âˆ)n. As estimator for + we choose
Ë†+(t) :=
n
n
j=1 tj
= 1
-Â¯t .
Is this an unbiased estimator for +?
Answer: The statistical model describing this experiment is (Rn, B(Rn), EâŠ—n
+ )+>0. If
the random variables Xj are deï¬ned by Xj(t) := tj, then they are independent and E+-
distributed. Because of Proposition 4.6.13, their sum X := n
j=1 Xj possesses an Erlang
distribution with parameters n and +. An application of eq. (5.22) in Proposition 5.1.36
for f(x) := n
x implies
E+ Ë†+ = E+
 n
X

=
âˆ

0
n
x
+n
(n â€“ 1)!xnâ€“1eâ€“+x dx .
A change of variables s := +x transforms the last integral into
+n
(n â€“ 1)!
âˆ

0
snâ€“2 eâ€“s ds =
+n
(n â€“ 1)! A(n â€“ 1) =
+n
(n â€“ 1)! â‹…(n â€“ 2)! = + â‹…
n
n â€“ 1 .
This tells us that, Ë†+ is not unbiased estimator for +. But, as mentioned in Remark 8.5.28
for 32
x, the sequence of estimators is asymptotically unbiased as n â†’âˆ.
Remark 8.5.30. If we replace the estimator in Example 8.5.29 by
Ë†+(t) := n â€“ 1
n
j=1 tj
=
1
1
nâ€“1
n
j=1 tj
,
t = (t1, . . . , tn) ,
then the previous calculations imply
E+ Ë†+ = n â€“ 1
n
â‹…+ â‹…
n
n â€“ 1 = + .
Hence, from this small change we get an unbiased estimator Ë†+ for +.
Observe that the calculations in Example 8.5.29 were only valid for n â‰¥2. If n = 1,
then the expected value of Ë†+ does not exist.

8.5 Point Estimators
351
8.5.3 Risk Function
Let (X, F, P()(âˆˆC be a parametric statistical model. Furthermore, # : C â†’R is a func-
tion of the parameter and Ë†# : X â†’C is an estimator for #. Suppose ( âˆˆC is the true
parameter and we observe some x âˆˆX. Then, in general, we will have #(() /= Ë†#(x), and
the quadratic error |#(() â€“ Ë†#(x)|2 occurs. Other ways to measure the error are possible
and useful, but we restrict ourselves to the quadratic distance. In this way we get the
so-called loss function L : C Ã— X â†’R of Ë†# deï¬ned by
L((, x) := |#(() â€“ Ë†#(x)|2 .
In other words, if ( is the correct parameter and our sample is x âˆˆX, then, using Ë†# as
the estimator, the (quadratic) error or loss will be L((, x). On average, the (quadratic)
loss is evaluated by E(|#(() â€“ Ë†#|2 .
Deï¬nition 8.5.31. The function R describing this average loss of Ë†# is said to be the
risk function of the estimator Ë†#. It is deï¬ned by
R((, Ë†#) := E(|#(() â€“ Ë†#|2 ,
( âˆˆC .
Before giving some examples of risk functions, let us rewrite R as follows.
Proposition 8.5.32. If ( âˆˆC, then it follows that
R((, Ë†#) = |#(() â€“ E(Ë†#|2 + V(Ë†# .
(8.35)
Proof: The assertion is a consequence of
R((, Ë†#) = E(

#(() â€“ Ë†#
2 = E(

(#(() â€“ E(Ë†#) + (E(Ë†# â€“ Ë†#)
2
= |#(() â€“ E(Ë†#|2 + 2((#(() â€“ E(Ë†#) E((E(Ë†# â€“ Ë†#) + V(Ë†# .
Because of
E((E(Ë†# â€“ Ë†#) = E(Ë†# â€“ E(Ë†# = 0 ,
this implies eq. (8.35).
âˆ
Deï¬nition 8.5.33. The function ( â†¦|#(() â€“ E(Ë†#|2, which appears in eq. (8.35), is
said to be the bias or the systematic error of the estimator Ë†#.

352
8 Mathematical Statistics
Corollary 8.5.34. A point estimator Ë†# is unbiased if and only if for all ( âˆˆC its bias is
zero. Moreover, if this is so, then its risk function is given by
R((, Ë†#) = V(Ë†# ,
( âˆˆC .
Remark 8.5.35. Another way to formulate eq. (8.35) is as follows. The risk function of
an estimator consists of two parts. One part is the systematic error, which does not
occur for unbiased estimators. And the second part is given by V(Ë†#. Thus, the smaller
the bias and/or V(Ë†# become, the smaller is the risk to get a wrong estimation for #((),
and the better is the estimator.
Example 8.5.36. Let us determine the risk functions for the two estimators presented
in Example 8.5.27. The estimator Ë†# for , was given by Ë†#(x) = Â¯x. Since this is an unbiased
estimator, by Corollary 8.5.34, its risk function is computed as
R((,, 32), Ë†#) = V(,,32)Ë†# .
The random variable x â†¦Â¯x is N(,, 32/n)-distributed, hence
R((,, 32), Ë†#) = 32
n .
There are two interesting facts about this risk function. First, it does not depend on the
parameter , that we want to estimate. And secondly, if n â†’âˆ, then the risk tends to
zero. In other words, the bigger the sample size, the less becomes the risk for a wrong
estimation.
Next we evaluate the risk function of the estimator Ë†#(x) = s2
x. As we saw in Example
8.5.29, this Ë†# is also an unbiased estimator for 32, hence
R((,, 32), Ë†#) = V(,,32)Ë†# .
By eq. (8.10) we know that nâ€“1
32 s2
x is 72
nâ€“1-distributed, hence Corollary 5.2.26 implies
V(,,32)
n â€“ 1
32
s2
x

= 2 (n â€“ 1) .
From this one easily derives
R((,, 32), Ë†#) = V(,,32)s2
x = 2 (n â€“ 1) â‹…
34
(n â€“ 1)2 = 234
n â€“ 1 .
Here, the risk function depends heavily on the parameter 32 that we want to estimate.
Furthermore, if n â†’âˆ, then also in this case the risk tends to zero.

8.5 Point Estimators
353
Example 8.5.37. Finally, regard the statistical model (X, P(X), Bn,()0â‰¤(â‰¤1, where
X = {0, . . . , n}. In order to estimate ( âˆˆ[0, 1], we take, as in Example 8.5.25, the estim-
ator Ë†((k) = k
n. There it was shown that the estimator is unbiased, hence, by Corollary
8.5.34, it follows that
R((, Ë†() = V( Ë†( ,
0 â‰¤( â‰¤1 .
If X is the identity on X, by Proposition 5.2.18, its variance equals V(X = n ((1 â€“ ().
Since Ë†( = X
n this implies
R((, Ë†() = V((X/n) = V(X
n2
= ((1 â€“ ()
n
.
Consequently, the risk function becomes maximal for ( = 1/2, while for ( = 0 or ( = 1
it vanishes.
We saw in Corollary 8.5.34 that R((, Ë†#) = V(Ë†# for unbiased Ë†#. Thus, for such estimators
inequality (7.2) implies
P({x âˆˆX : |#(() â€“ Ë†#(x)| > c} â‰¤V(Ë†#
c2 ,
that is, the smaller V(Ë†# is, the greater is the chance to estimate a value near the correct
one. This observation leads to the following deï¬nition.
Deï¬nition 8.5.38. Let Ë†#1 and Ë†#2 be two unbiased estimators for #((). Then Ë†#1 is
said to be uniformly better than Ë†#2 provided that
V(Ë†#1 â‰¤V(Ë†#2
for all ( âˆˆC .
An unbiased estimator Ë†#âˆ—is called the uniformly best estimator if it is uniformly
better than all other unbiased estimators for #(().
Example 8.5.39. We observe values that, for some b > 0, are uniformly distributed
on [0, b]. But the number b > 0 is unknown. In order to estimate it, one executes n
independent trials and obtains as sample x = (x1, . . . , xn). As point estimators for b > 0
one may either choose
Ë†b1(x) := n + 1
n
max
1â‰¤iâ‰¤n xi
or
Ë†b2(x) := 2
n
n

i=1
xi .

354
8 Mathematical Statistics
According to Problem 8.4, the estimators Ë†b1 and Ë†b2 are both unbiased. Furthermore,
not too difï¬cult calculations show that
Vb Ë†b1 =
b2
n(n + 2)
and
Vb Ë†b2 = b2
3n2 .
Therefore, Vb Ë†b1 â‰¤Vb Ë†b2 for all b > 0. This tells us that Ë†b1 is uniformly better than Ë†b2.
Remark 8.5.40. A very natural question is whether there exists a lower bound for
the precision of an estimator. In other words, are there estimators for which the risk
function becomes arbitrarily small? The answer depends heavily on the inherent in-
formation in the statistical model. To explain this let us come back once more to
Example 8.5.4.
Suppose we had P0({a}) = 1 and P1({b}) = 1. Then the occurrence of â€œaâ€ would
tell us with 100% security that ( = 0 is the correct parameter. The risk for the corres-
ponding estimator is then zero. On the contrary, if P0({a}) = P0({b}) = 1/2, then the
occurrence of â€œaâ€ tells us nothing about the correct parameter.
To make the previous observation more precise, we have to introduce some quantity
that measures the information contained in a statistical model.
Deï¬nition 8.5.41. Let (X, F, P()(âˆˆC be a statistical model with log-likelihood
function L introduced in Deï¬nition 8.5.9. For simplicity, assume C âŠ†R. Then the
function I : C â†’R deï¬ned by
I(() := E(
âˆ‚L
âˆ‚(
2
is called the Fisher information of the model. Of course, we have to suppose that
the derivatives and the expected value exist.
Example 8.5.42. Let us investigate the Fisher information for the model treated in
Example 8.5.13. There we had
L(,, 32, x) = L(,, 32, x1, . . . , xn) = c â€“ n
2 â‹…ln 32 â€“
1
232
n

j=1
(xj â€“ ,)2 .
Fix 32 and take the derivative with respect to ,. This leads to
âˆ‚L
âˆ‚, = nÂ¯x â€“ n,
32
,

8.6 Conï¬dence Regions and Intervals
355
hence
âˆ‚L
âˆ‚,
2
= n2
34 |Â¯x â€“ ,|2 .
Recall that Â¯x is N(,, 32/n)-distributed, hence the expected value of |Â¯x â€“ ,|2 is nothing
else than the variance of Â¯x, that is, it is 32/n. Consequently,
I(,) = E,,32
âˆ‚L
âˆ‚,
2
= n2
34
32
n = n
32 .
The following result answers the above question: how precise can an estimator
become at the most?
Proposition 8.5.43 (Raoâ€“CramÃ©râ€“Frechet). Let (X, F, P()(âˆˆC be a parametric model
for which the Fisher information I : C â†’R exists. If Ë†( is an unbiased estimator for
(, then
V( Ë†( â‰¥
1
I(() ,
( âˆˆC .
(8.36)
Remark 8.5.44. Estimators Ë†( that attain the lower bound in estimate (8.36) are said
to be efï¬cient. That is, for those estimators holds V(Ë†( = 1/I(() for all ( âˆˆC. In other
words, efï¬cient estimators possess the best possible accuracy.
In view of Examples 8.5.36 and 8.5.42, for normally distributed populations the
estimator Ë†,(x) = Â¯x is an efï¬cient estimator for ,. Other efï¬cient estimators are those
investigated in Examples 8.5.26 and 8.5.12. On the other hand, the estimator for 32 in
Example 8.5.27 is not efï¬cient. But it can be shown that s2
x is a uniformly best estimator
for 32, that is, there do not exist efï¬cient estimators in this case.
8.6 Conï¬dence Regions and Intervals
Point estimations provide us with a single value ( âˆˆC. Further work or necessary
decisions are then based on this estimated parameter. The disadvantages of this ap-
proach are that we have no knowledge about the precision of the obtained value. Is
the estimated parameter far away from the true one or maybe very near? To explain
the problem, let us come back to the situation described in Example 8.5.16. If the re-
tailer observes 4 defective TV sets among 15 tested, then he estimates that there are 26
defective sets in the delivery of 100. But he does not know how precise his estimation
of 26 is. Maybe there are much more defective sets in the delivery, or maybe less than
26. The only information he has is that the estimates are correct on average. But this
does not say anything about the accuracy of a single estimate.

356
8 Mathematical Statistics
This disadvantage of point estimators is avoided when estimating a certain set
of parameters, not only a single point. Then the true parameter is contained with
great probability in this randomly chosen region. In most cases, these regions will
be intervals of real or natural numbers.
Deï¬nition
8.6.1. Suppose
we
are
given
a
parametric
statistical
model
(X, F, P()(âˆˆC. A mapping C
:
X â†’P(C) is called an interval estimator,10
provided for ï¬xed ( âˆˆC
{x âˆˆX : ( âˆˆC(x)} âˆˆF .
(8.37)
Remark 8.6.2. Condition (8.37) is quite technical and will play no role later on. But it
is necessary because otherwise the next deï¬nition does not make sense.
Deï¬nition 8.6.3. Let ! be a real number in (0, 1). Suppose an interval estimator
C : X â†’P(C) satisï¬es for each ( âˆˆC the condition
P({x âˆˆX : ( âˆˆC(x)} â‰¥1 â€“ ! .
(8.38)
Then C is said to be a 100(1 â€“ !)% interval estimator.11 The sets C(x) âŠ†C with
x âˆˆX are called 100(1 â€“ !)% conï¬dence regions or conï¬dence intervals.12
How does an interval estimator apply? Suppose ( âˆˆC is the â€œtrueâ€ parameter. In a
statistical experiment, one obtains some sample x âˆˆX distributed according to P(. In
dependence of the observed sample x, we choose a set C(x) of parameters. Then with
probability greater than or equal to 1â€“!, the observed x âˆˆX leads to a region C(x) that
contains the true parameter (.
Remark 8.6.4. It is important to say that the region C(x) is random, not the un-
known parameter ( âˆˆC. Metaphorically speaking, a ï¬sh (the true parameter () is
in a pond at some ï¬xed but unknown spot. We execute a certain statistical experiment
to get some information about the place where the ï¬sh is situated. In dependence of
the result of the experiment, we throw a net into the pond. Doing so, we know that
with probability greater than or equal to 1 â€“ !, the result of the experiment leads to a
net that catches the ï¬sh. In other words, the position of the ï¬sh is not random, it is the
observed sample, hence also the thrown net.
10 Better notation would be â€œregion estimatorâ€ because C(x) âŠ†C may be an arbitrary subset, not
necessarily an interval, but â€œinterval estimatorâ€ is commonly accepted, therefore, we use it here also.
11 Also 1 â€“ ! estimator.
12 Also 1 â€“ ! conï¬dence regions or intervals.

8.6 Conï¬dence Regions and Intervals
357
Remark 8.6.5. It is quite self-evident that one should try to choose the conï¬dence re-
gions as small as possible, without violating condition (8.38). If we are not interested
in â€œsmallâ€ conï¬dence regions, then we could always chose C(x) = C. This is not
forbidden, but completely useless.
Construction of conï¬dence regions: For a better understanding of the subsequent con-
struction, let us shortly recall the main assertions about hypothesis tests from a
slightly different point of view.
Let (X, F, P;);âˆˆC be a statistical model. We choose a ï¬xed, but arbitrary, ( âˆˆC.
With this chosen (, we formulate the null hypothesis as H0 : ; = (. The alternative
hypothesis is then H1 : ; /= (. Let T = (X0, X1) be an !-signiï¬cance test for H0 against
H1. Because the hypothesis, hence also the test, depends on the chosen ( âˆˆC, we
denote the null hypothesis by H0(() and write T(() = (X0((), X1(()) for the test. That
is, H0(() : ; = ( and T(() is an !-signiï¬cance test for H0((). With this notation set
C(x) := {( âˆˆC : x âˆˆX0(()} .
(8.39)
Example 8.6.6. Choose the hypothesis and the test as in Proposition 8.4.12. The stat-
istical model is then given by (Rn, B(Rn), N(-, 32
0)âŠ—n)-âˆˆR, where this time we denote
the unknown expected value by -. For some ï¬xed, but arbitrary, , âˆˆR let
H0(,) : - = ,
and
H1(,) : - /= , .
The !-signiï¬cance test T(,) constructed in Proposition 8.4.12 possesses the region of
acceptance
X0(,) =
5
x âˆˆRn :
âˆš
n
....
Â¯x â€“ ,
30
.... â‰¤z1â€“ !/2
6
.
Thus, in this case, the set C(x) in eq. (8.39) consists of those , âˆˆR that satisfy the
estimate âˆšn
... Â¯xâ€“,
30
... â‰¤z1â€“ !/2. That is, given x âˆˆRn, then C(x) is the interval
C(x) =

Â¯x â€“ 30
âˆšn z1â€“!/2 , Â¯x + 30
âˆšn z1â€“!/2

.
Let us come back to the general situation. The statistical model is (X, F, P;);âˆˆC. Given
( âˆˆC let T(() be an !-signiï¬cance test for H0(() against H1(() where H0(() is the hypo-
thesis H0(() : ; = (. Given x âˆˆX deï¬ne C(x) âŠ†C by eq. (8.39). Then the following is
valid.
Proposition 8.6.7. Let T(() be as above an !-signiï¬cance test for H0(() against H1(().
Deï¬ne C(x) by eq. (8.39) where X0(() denotes the region of acceptance of T((). Then
the mapping x â†¦C(x) from X into P(C) is a 100(1 â€“ !)% interval estimator. Hence,
{C(x) : x âˆˆX} is a collection of 100(1 â€“ !)% conï¬dence regions.

358
8 Mathematical Statistics
Proof: By assumption, T(() is an !-signiï¬cance test for H0((). The deï¬nition of those
tests tells us that
P((X1(()) â‰¤! ,
hence
P((X0(()) â‰¥1 â€“ ! .
Given ( âˆˆC and x âˆˆX, by the construction of C(x), one has ( âˆˆC(x) if and only if
x âˆˆX0((). Combining these two observations, given ( âˆˆC, then it follows that
P({x âˆˆX : ( âˆˆC(x)} = P({x âˆˆX : x âˆˆX0(()} = P((X0(()) â‰¥1 â€“ ! .
This completes the proof.
âˆ
Example 8.6.8. Proposition 8.6.7 implies that the intervals C(x) in Example 8.6.6 are
1 â€“ ! conï¬dence intervals. That is, if we execute an experiment or if we analyze
some data, then with probability greater than or equal to 1 â€“ ! we will observe values
x = (x1, . . . , xn) such that the â€œtrueâ€ parameter , satisï¬es
Â¯x â€“ 30
âˆšn z1â€“!/2 â‰¤, â‰¤Â¯x + 30
âˆšn z1â€“!/2 .
For example, if we choose ! = 0.05 and observe the nine values
10.1 , 9.2 , 10.2 , 10.3 , 10.1 , 9.9 , 10.0 , 9.7 , 9.8 ,
then Â¯x = 9.9222. The variance 30 is not known, therefore we use its estimation by s2
x,
that is, we take 30 as sx = 0.330824. Because of z1â€“!/2 = z0.975 = 1.95996, with security
of 95% we ï¬nally get
9.7061 â‰¤, â‰¤10.1384 .
In the next example we describe the conï¬dence intervals generated by the t-test
treated in Proposition 8.4.12.
Example 8.6.9. The statistical model is
(Rn, B(Rn), N(-, 32)âŠ—n)(-,32)âˆˆRÃ—(0,âˆ) .
By Proposition 8.4.12 an !-signiï¬cance test T(,) is given by the region of acceptance
X0(,) =
5
x âˆˆRn :
âˆš
n
....
Â¯x â€“ ,
sx
.... â‰¤tnâ€“1;1â€“!/2
6
.

8.6 Conï¬dence Regions and Intervals
359
From this one easily derives
C(x) =

, âˆˆR :
âˆš
n
....
Â¯x â€“ ,
sx
.... â‰¤tnâ€“1;1â€“!/2

=

Â¯x â€“ sx
âˆšn tnâ€“1;1â€“!/2 , Â¯x + sx
âˆšn tnâ€“1;1â€“!/2

.
Let us explain the result by the concrete sample investigated in Example 8.4.15. There
we had Â¯x = 22.072, sx = 0.07554248, and n = 10. For ! = 0.05, the quantile of t9 equals
t9;0.975 = 2, 26. From this we derive [22.016 , 22.126] as 95% conï¬dence interval.
Verbally this says with a security of 95% we observed those x1, . . . , x10 for which
, âˆˆC(x) = [22.016, 22.126].
The next example shows how Proposition 8.6.7 applies in the case of discrete probab-
ility measures.
Example 8.6.10. The statistical model is (X, P(X), Bn,()0â‰¤(â‰¤1 where the sample space
is X = {0, . . . , n}. Our aim is to construct conï¬dence regions C(k) âŠ†[0, 1], k = 0, . . . , n,
such that
Bn,({k â‰¤n : ( âˆˆC(k)} â‰¥1 â€“ ! .
In order to get these conï¬dence regions, we use Proposition 8.6.7. As shown in Pro-
position 8.3.1, the region of acceptance X0(() of an !-signiï¬cance test T((), where
H0 : ; = (, is given by
X0(() = {n0((), . . . , n1(()} .
Here, the numbers n0(() and n1(() were deï¬ned by
n0(() := min
â§
â¨
â©k â‰¤n :
k

j=0
n
j

(j(1 â€“ ()nâ€“j > !/2
â«
â¬
â­
and
n1(() := max
â§
â¨
â©k â‰¤n :
n

j=k
n
j

(j(1 â€“ ()nâ€“j > !/2
â«
â¬
â­.
Applying Proposition 8.6.7, the sets
C(k) := {( âˆˆ[0, 1] : k âˆˆX0(()} = {( âˆˆ[0, 1] : n0(() â‰¤k â‰¤n1(()} ,
k = 0, . . . , n ,

360
8 Mathematical Statistics
are 1 â€“ ! conï¬dence regions. By the deï¬nition of n0(() and of n1((), given k â‰¤n, then a
number ( âˆˆ[0, 1] satisï¬es n0(() â‰¤k â‰¤n1(() if and only if at the same time
Bn,(({0, . . . , k}) =
k

j=0
n
j

(j(1 â€“ ()nâ€“j > !/2
and
Bn,(({k, . . . , n}) =
n

j=k
n
j

(j(1 â€“ ()nâ€“j > !/2 .
In other words, observing k â‰¤n, then the corresponding 1 â€“ ! conï¬dence region is
given by
C(k) =
C
( : Bn,(({0, . . . , k}) > !/2
D
âˆ©
C
( : Bn,(({k, . . . , n}) > !/2
D
.
(8.40)
These sets are called the 100(1 â€“ !)% Clopperâ€“Pearson intervals or also exact
conï¬dence intervals for the binomial distribution.
Let us consider the following concrete example. In an urn are white and black
balls with an unknown proportion ( of white balls. In order to get some information
about (, we choose randomly 500 balls with replacement. Say, 220 of the chosen balls
are white. What is the 90% conï¬dence interval for ( based on this observation?
Answer: We have n = 500 and the observed k equals 220. Consequently, the
conï¬dence interval C(220) consists of those ( âˆˆ[0, 1] for which at the same time
f(() > !/2 = 0.05
and
g(() > !/2 = 0.05 ,
where
f(() :=
220

j=0
500
j

(j(1 â€“ ()500â€“j
and
g(() :=
500

j=220
500
j

(j(1 â€“ ()500â€“j .
Numerical calculations tell us that
f(0.4777) = 0.0500352 â‰ˆ0.05
as well as
g(0.4028) = 0.0498975 â‰ˆ0.05 .
Therefore, a 90% conï¬dence interval C(220) is given by
C(220) = (0.4028, 0.4777) .
For n = 1000 and 440 observed white balls similar calculations lead to the smaller,
hence more signiï¬cant, interval
C(440) = (0.4139, 0.4664) .

8.6 Conï¬dence Regions and Intervals
361
Remark 8.6.11. The previous example already indicates that the determination of
the Clopperâ€“Pearson intervals becomes quite complicated for large n. Therefore, one
looks for â€œapproximativeâ€ intervals. Background for the construction is the central
limit theorem in the form presented in Proposition 7.2.15. For Sns distributed according
to Bn,( it implies
lim
nâ†’âˆP
.....
Sn â€“ n(
=
n((1 â€“ ()
..... â‰¤z1â€“!/2
$
= 1 â€“ ! ,
or, equivalently,
lim
nâ†’âˆBn,(

k â‰¤n :
.....
k â€“ n(
=
n((1 â€“ ()
..... â‰¤z1â€“!/2
$
= 1 â€“ ! .
Here z1â€“!/2 are the quantiles introduced in Deï¬nition 8.4.5. Thus, an â€œapproximativeâ€
region of acceptance, testing the hypothesis â€œthe unknown parameter is (,â€ is given
by
X0(() =

k â‰¤n :
....
k
n â€“ (
.... â‰¤z1â€“!/2
"
((1 â€“ ()
n
$
.
(8.41)
An application of Proposition 8.6.7 leads to certain conï¬dence regions, but these are
not very useful. Due to the term
=
((1 â€“ () on the right-hand side of eq. (8.41), it is not
possible, for a given k â‰¤n, to describe explicitly those (s for which k âˆˆX0((). To
overcome this difï¬culty, we change X0(() another time by replacing ( on the right-
hand side by its MLE Ë†((k) = k
n. That is, we replace eq. (8.41) by
ËœX0(() =
â§
â¨
â©k â‰¤n :
....
k
n â€“ (
.... â‰¤z1â€“!/2
E
k
n(1 â€“ k
n)
n
â«
â¬
â­.
Doing so, an application of Proposition 8.6.7 leads to the â€œapproximativeâ€ conï¬dence
intervals ËœC(k), k = 0, . . . , n, deï¬ned as
ËœC(k) =
â¡
â£k
n â€“ z1â€“!/2
E
k
n(1 â€“ k
n)
n
, k
n + z1â€“!/2
E
k
n(1 â€“ k
n)
n
â¤
â¦.
(8.42)
Example 8.6.12. We investigate once more Example 8.6.10. Among 500 chosen balls
we observed 220 white ones. This observation led to the â€œexactâ€ 90% conï¬dence
interval C(220) = (0.4028, 0.4777).
Let us compare this result with the interval we get by using the approximative
approach. Since the quantile z1â€“!/2 for ! = 0.1 equals z0.95 = 1.64485, the left and the

362
8 Mathematical Statistics
right endpoints of the interval (8.42) with k = 220 are evaluated by
220
500 â€“ 1.64485 â‹…
"
220 â‹…280
5003
= 0.4035
and
220
500 + 1.64485 â‹…
"
220 â‹…280
5003
= 0.4765 .
Thus, the â€œapproximativeâ€ 90% conï¬dence interval is ËœC(220) = (0.4035, 0.4765), which
does not defer very much from C(220) = (0.4028, 0.4777).
In the case of 1000 trials and 440 white balls, the endpoints of a conï¬dence
interval are evaluated by
440
1000 â€“ 1.64485 â‹…
"
440 â‹…560
10003
= 0.414181
and
440
1000 + 1.64485 â‹…
"
440 â‹…560
10003
= 0.4645819 .
That is, ËœC(440) = (0.4142, 0.4659) compared with C(440) = (0.4139, 0.4664).
Example 8.6.13. A few days before an election 1000 randomly chosen people are
questioned for whom they will vote next week, either candidate A or candidate B. 540
of the interviewed people answered that they will vote for candidate A, the remaining
460 favor candidate B. Find a 90% sure conï¬dence interval for the expected result of
candidate A in the election.
Solution: We have n = 1000, k = 540, and ! = 0.1 The quantile of level 0.95 of the
standard normal distribution equals z0.95 = 1.64485 (compare Example 8.6.12). This
leads to [0.514, 0.566] as â€œapproximativeâ€ 90% conï¬dence interval for the expected
result of candidate A.
If one questions another 1000 randomly chosen people, another conï¬dence inter-
val will occur. But, on average, in 9 of 10 cases a questioning of 1000 people will lead
to an interval containing the correct value.
8.7 Problems
Problem 8.1. For some b > 0 let Pb be the uniform distribution on [0, b]. The precise
value of b > 0 is unknown. We claim that b â‰¤b0 for a certain b0 > 0. Thus, the
hypotheses are
H0 : b â‰¤b0
and
H1 : b > b0 .

8.7 Problems
363
To test H0, we chose randomly n numbers x1, . . . , xn distributed according to Pb.
Suppose the region of acceptance X0 of a hypothesis test Tc is given by
X0 := {(x1, . . . , xn) : max
1â‰¤iâ‰¤n xi â‰¤c}
for some c > 0.
1.
Determine those c > 0 for which Tc is an !-signiï¬cance test of level ! < 1.
2.
Suppose Tc is an !-signiï¬cance test. For which of those c > 0 does the probability
for a type II error become minimal?
3.
Determine the power function of the !-test Tc that minimizes the probability of the
occurrence of a type II error.
Problem 8.2. For ( > 0 let P( be the probability measure with density p( deï¬ned by
p((s) =

(s(â€“1 : s âˆˆ(0, 1]
0
: otherwise
1.
Check whether the p(s are probability density functions.
2.
In order to get information about ( we execute n independent trials according to
P(. Which statistical model describes this experiment?
3.
Find the maximum likelihood estimator for (.
Problem 8.3. The lifetime of light bulbs is exponentially distributed with unknown
parameter + > 0. In order to determine + we switch on n light bulbs and record the
number of light bulbs that burn out until a certain time T > 0. Determine a statistical
model that describes this experiment. Find the MLE for +.
Problem 8.4. Consider
the
statistical
model
in
Example
8.5.39,
that
is,
(Rn, B(Rn), PâŠ—n
b )b>0 with uniform distribution Pb on [0, b]. There are two natural
estimators for b > 0, namely Ë†b1 and Ë†b2 deï¬ned by
Ë†b1(x) := n + 1
n
max
1â‰¤iâ‰¤n xi
and
Ë†b2(x) := 2
n
n

i=1
xi ,
x = (x1, . . . , xn) âˆˆRn .
Prove that Ë†b1 and Ë†b2 possess the following properties.
1.
The estimators Ë†b1 and Ë†b2 are unbiased.
2.
One has
Vb Ë†b1 =
b2
n(n + 2)
and
Vb Ë†b2 = b2
3n2 .
Problem 8.5. In a questioning of 2000 randomly chosen people 1420 answered that
they regularly use the Internet. Find an â€œapproximativeâ€ 90% conï¬dence interval for

364
8 Mathematical Statistics
the proportion of people using the Internet regularly. Determine the inequalities that
describe the exact intervals in eq. (8.40).
Problem 8.6. How do the conï¬dence intervals in eq. (8.40) look like for k = 0 or k = n?
Problem 8.7. Suppose
the
statistical
model
is
(X, P(X), HN,M,n)Mâ‰¤N
with
X = {0, . . . , n} and with the hypergeometric distributions HN,M,n introduced in
Deï¬nition 1.4.25.
1.
For some M0 â‰¤M the hypotheses are H0 : M = M0 against H1 : M /= M0. Find
(optimal) numbers 0 â‰¤m0 â‰¤m1 â‰¤n such that X0 = {m0, . . . , m1} is the region of
acceptance of an !-signiï¬cance test T for H0 against H1.
Hint: Modify the methods developed in Proposition 8.2.19 and compare the
construction of two-sided tests for a binomial distributed population.
2.
Use Proposition 8.6.7 to derive from X0 conï¬dence intervals C(m), 0 â‰¤m â‰¤n, of
level ! for the unknown parameter M.
Hint: Follow the methods in Example 8.6.10 for the binomial distribution.
Problem 8.8. Use Proposition 8.6.7 to derive from Propositions 8.4.17 and 8.4.18
conï¬dence intervals for the unknown variance of a normal distributed population.

A Appendix
A.1 Notations
Throughout the book we use the following standard notations:
1.
The natural numbers starting at 1 are always denoted by N. In the case 0 is
included we write N0.
2.
As usual the integers Z are given by Z = {. . . , â€“2, â€“1, 0, 1, 2, . . .} .
3.
By R we denote the ï¬eld of real numbers endowed with the usual algebraic op-
erations and its natural order. The subset Q âŠ‚R is the union of all rational
numbers, that is, of numbers m/n where m, n âˆˆZ and n /= 0.
4.
Given n â‰¥1 let Rn be the n-dimensional Euclidean vector space, that is,
Rn = {x = (x1, . . . , xn) : xj âˆˆR} .
Addition and scalar multiplication in Rn are carried out coordinate-wise,
x + y = (x1, . . . , xn) + (y1, . . . , yn) = (x1 + y1, . . . xn + yn)
and if ! âˆˆR, then
! x = (!x1, . . . , !xn) .
A.2 Elements of Set Theory
Given a set M its powerset P(M) consists of all subsets of M. In the case that M is ï¬nite
we have #(P(M)) = 2#(M), where #(A) denotes the cardinality (number of elements) of
a ï¬nite set A.
If A and B are subsets of M, written as A, B âŠ†M or also as A, B âˆˆP(M), their union
and their intersection are, as usual, deï¬ned by
A âˆªB = {x âˆˆM : x âˆˆA or x âˆˆB} and A âˆ©B = {x âˆˆM : x âˆˆA and x âˆˆB} .
Of course, it always holds that
A âˆ©B âŠ†A âŠ†A âˆªB
and
A âˆ©B âŠ†B âŠ†A âˆªB .
In the same way, given subsets A1, A2, . . . of M their union âˆ
j=1 Aj and their intersec-
tion âˆ
j=1 Aj is the set of those x âˆˆM that belong to at least one of the Aj or that belong
to all Aj, respectively.

366
A Appendix
Quite often we use the distributive law for intersection and union. This asserts
A âˆ©
â›
â
âˆ
	
j=1
Bj
â
â =
âˆ
	
j=1
(A âˆ©Bj) .
Two sets A and B are said to be disjoint1 provided that A âˆ©B = Ã¸. A sequence of sets
A1, A2, . . . is called disjoint2 whenever Ai âˆ©Aj = Ã¸ if i /= j.
An element x âˆˆM belongs to the set difference A\B provided that x âˆˆA but x âˆ‰B.
Using the notion of the complementary set Bc := {x âˆˆM : x âˆ‰B}, the set difference
may also be written as
A\B = A âˆ©Bc .
Another useful identity is
A\B = A\(A âˆ©B) .
Conversely, the complementary set may be represented as the set difference Bc = M\B.
We still mention the obvious (Bc)c = B.
Finally we introduce the symmetric difference ABB of two sets A and B as
ABB := (A\B) âˆª(B\A) = (A âˆ©Bc) âˆª(B âˆ©Ac) = (A âˆªB)\(A âˆ©B) .
Note that an element x âˆˆM belongs to ABB if and only if x belongs exactly to one of
the sets A or B.
De Morganâ€™s rules are very important and assert the following:
â›
â
âˆ
	
j=1
Aj
â
â 
c
=
âˆ

j=1
Ac
j
and
â›
â
âˆ

j=1
Aj
â
â 
c
=
âˆ
	
j=1
Ac
j .
Given sets A1, . . . , An their Cartesian product A1 Ã— â‹…â‹…â‹…Ã— An is deï¬ned by
A1 Ã— â‹…â‹…â‹…Ã— An := {(a1, . . . , an) : aj âˆˆAj} .
Note that #(A1 Ã— â‹¯Ã— An) = #(A1) â‹¯#(An).
Let S be another set, for example, S = R, and let f : M â†’S be some mapping from
M to S. Given a subset B âŠ†S, we denote the preimage of B with respect to f by
f â€“1(B) := {x âˆˆM : f(x) âˆˆB} .
(A.1)
1 Sometimes called â€œmutually exclusive.â€
2 More precisely, one should say â€œpairwise disjoint.â€

A Appendix
367
In other words, an element x âˆˆM belongs to f â€“1(B) if and only if its image with respect
to f is an element of B.
We summarize some crucial properties of the preimage in a proposition.
Proposition A.2.1. Let f : M â†’S be a mapping from M into another set S.
(1)
f â€“1(Ã¸) = Ã¸ and f â€“1(S) = M.
(2)
For any subsets Bj âŠ†S the following equalities are valid:
f â€“1
â›
â	
jâ‰¥1
Bj
â
â =
	
jâ‰¥1
f â€“1(Bj) and f â€“1
â›
â
jâ‰¥1
Bj
â
â =

jâ‰¥1
f â€“1(Bj) .
(A.2)
Proof: We only prove the left-hand equality in eq. (A.2). The right-hand one is proved
by the same methods. Furthermore, assertion (1) follows immediately.
Take x âˆˆf â€“1 
jâ‰¥1 Bj

. This happens if and only if
f(x) âˆˆ
	
jâ‰¥1
Bj
(A.3)
is satisï¬ed. But this is equivalent to the existence of a certain j0 â‰¥1 with f(x) âˆˆBj0.
By deï¬nition of the preimage the last statement may be reformulated as follows: there
exists a j0 â‰¥1 such that x âˆˆf â€“1(Bj0). But this implies
x âˆˆ
	
jâ‰¥1
f â€“1(Bj) .
(A.4)
Consequently, an element x âˆˆM satisï¬es condition (A.3) if and only if property (A.4)
holds. This proves the left-hand identity in formulas (A.2).
âˆ
A.3 Combinatorics
A.3.1 Binomial Coefï¬cients
A one-to-one mapping 0 from {1, . . . , n} to {1, . . . , n} is called a permutation (of or-
der n). Any permutation reorders the numbers from 1 to n as 0(1), 0(2), . . . , 0(n) and,
vice versa, each reordering of these numbers generates a permutation. One way to
write a permutations is
0 =

1
2
. . .
n
0(1)
0(2)
. . .
0(n)

For example, if n = 3, then 0 =

1 2 3
2 3 1

is equivalent to the order 2, 3, 1 or to
0(1) = 2, 0(2) = 3 and 0(3) = 1.

368
A Appendix
Let Sn be the set of all permutations of order n. Then one may ask for #(Sn) or,
equivalently, for the number of possible orderings of the numbers {1, . . . , n}.
To treat this problem we need the following deï¬nition.
Deï¬nition A.3.1. For n âˆˆN we deï¬ne n-factorial by setting
n! = 1 â‹…2 â‹…â‹…â‹…(n â€“ 1) â‹…n
Furthermore, let 0! = 1.
Now we may answer the question about the cardinality of Sn.
Proposition A.3.2. We have
#(Sn) = n!
(A.5)
or, equivalently, there are n! different ways to order n distinguishable objects.
Proof: The proof is done by induction over n. If n = 1 then #(S1) = 1 = 1! and eq. (A.5)
is valid.
Now suppose that eq. (A.5) is true for n. In order to prove eq. (A.5) for n + 1 we split
Sn+1 as follows:
Sn+1 =
n+1
	
k=1
Ak,
where
Ak = {0 âˆˆSn+1 : 0(n + 1) = k} ,
k = 1, . . . , n + 1 .
Each 0
âˆˆ
Ak generates a one-to-one mapping Ëœ0 from {1, . . . , n} onto the set
{1, . . . , k â€“ 1, k + 1, . . . , n} by letting Ëœ0(j) = 0(j), 1 â‰¤j â‰¤n. Vice versa, each such Ëœ0 deï¬nes
a permutation 0 âˆˆAk by setting 0(j) = Ëœ0(j), j â‰¤n, and 0(n + 1) = k. Consequently, since
eq. (A.5) holds for n we get #(Ak) = n!. Furthermore, the Aks are disjoint, and
#(Sn+1) =
n+1

k=1
#(Ak) = (n + 1) â‹…n! = (n + 1)! ,
hence eq. (A.5) also holds for n + 1. This completes the proof.
âˆ
Next we treat a tightly related problem. Say we have n different objects and we want to
distribute them into two disjoint groups, one having k elements, the other nâ€“k. Hereby
it is of no interest in which order the elements are distributed, only the composition of
the two sets matters.

A Appendix
369
Example A.3.3. There are 52 cards in a deck that are distributed to two players, so that
each of them gets 26 cards. For this game it is only important which cards each player
has, not in which order the cards were received. Here n = 52 and k = n â€“ k = 26.
The main question is: how many ways can n elements be distributed, say the numbers
from 1 to n, into one group of k elements and into another of n â€“ k elements? In
the above example, that is how many ways can 52 cards be distributed into two
groups of 26.
To answer this question we use the following auxiliary model. Let us take any
permutation 0 âˆˆSn. We place the numbers 0(1), . . . , 0(k) into group 1 and the remain-
ing 0(k + 1), . . . , 0(n) into group 2. In this way we obtain all possible distributions but
many of them appear several times. Say two permutations 01 and 02 are equivalent if
(as sets)
{01(1), . . . , 01(k)} = {02(1), . . . , 02(k)} .
Of course, this also implies
{01(k + 1), . . . , 01(n)} = {02(k + 1), . . . , 02(n)} ,
and two permutations generate the same partition if and only if they are equivalent.
Equivalent permutations are achieved by taking one ï¬xed permutation 0, then per-
muting {0(1), . . . , 0(k)} and also {0(k + 1), . . . , 0(n)}. Consequently, there are exactly
k!(n â€“ k)! permutations that are equivalent to a given one. Summing up, we get that
there are
n!
k!(nâ€“k)! different classes of equivalent permutations. Setting
n
k

=
n!
k! (n â€“ k)!
we see the following.
There are
n
k

different ways to distribute n objects into one group of k and into another
one of n â€“ k elements.
The numbers
n
k

are called binomial coefï¬cients, read â€œn chosen k.â€ We let
n
k

= 0
in case of k > n or k < 0.
Example A.3.4. A digital word of length n consists of n zeroes or ones. Since at every
position we may have either 0 or 1, there are 2n different words of length n. How many
of these words possess exactly k ones or, equivalently, n â€“ k zeroes? To answer this put
all positions where there is a â€œ1â€ into a ï¬rst group and those where there is a â€œ0â€ into a
second one. In this way the numbers from 1 to n are divided into two different groups

370
A Appendix
of size k and n â€“ k, respectively. But we already know how many such partitions exist,
namely
n
k

. As a consequence we get
There are
n
k

words of length n possessing exactly k ones and n â€“ k zeroes.
The next proposition summarizes some crucial properties of binomial coefï¬cients.
Proposition A.3.5. Let n be a natural number, k = 0, . . . , n and let r â‰¥0 be an integer.
Then the following equations hold:
n
k

=
 n
n â€“ k

(A.6)
n
k

=
n â€“ 1
k

+
n â€“ 1
k â€“ 1

and
(A.7)
n + r
n

=
n

j=0
n + r â€“ j â€“ 1
n â€“ j

=
n

j=0
r + j â€“ 1
j

.
(A.8)
Proof: Equations (A.6) and (A.7) follow immediately by the deï¬nition of the binomial
coefï¬cients. Note that eq. (A.7) also holds if k = n because we agreed that
nâ€“1
n

= 0.
An iteration of eq. (A.7) leads to
n
k

=
k

j=0
n â€“ j â€“ 1
k â€“ j

.
Replacing in the last equation n by n + r as well as k by n we obtain the left-hand
identity (A.8). The right-hand equation follows by inverting the summation, that is,
one replaces j by n â€“ j.
âˆ
Remark A.3.6. Equation (A.7) allows a graphical interpretation by Pascalâ€™s triangle.
The coefï¬cient
n
k

in the nth row follows by summing the two values
nâ€“1
kâ€“1

and
nâ€“1
k

above
n
k

in the (n â€“ 1)th row.
1
1
1
1
2
1
1
3
3
1
â‹…
â‹…
â‹…
â‹…
â‹…
1
â‹…
â‹…
â‹…
nâ€“1
kâ€“1

nâ€“1
k

â‹…
â‹…
â‹…
1
1
n
1

â‹…
â‹…
â‹…
â‹…
n
k

â‹…
â‹…
â‹…
â‹…
 n
nâ€“1

1
Next we state and prove the important binomial theorem.

A Appendix
371
Proposition A.3.7 (Binomial theorem). For real numbers a and b and any n âˆˆN0,
(a + b)n =
n

k=0
n
k

ak bnâ€“k .
(A.9)
Proof:
The binomial theorem is proved by induction over n. If n = 0, then eq. (A.9)
holds trivially.
Suppose now that eq. (A.9) has been proven for n â€“ 1. Our aim is to verify that it is
also true for n. Using that the expansion holds for n â€“ 1 we get
(a + b)n = (a + b)nâ€“1(a + b)
=
nâ€“1

k=0
n â€“ 1
k

ak+1bnâ€“1â€“k +
nâ€“1

k=0
n â€“ 1
k

akbnâ€“k
= an +
nâ€“2

k=0
n â€“ 1
k

ak+1bnâ€“1â€“k + bn +
nâ€“1

k=1
n â€“ 1
k

akbnâ€“k
= an + bn +
nâ€“1

k=1
n â€“ 1
k â€“ 1

+
n â€“ 1
k

akbnâ€“k
=
n

k=0
n
k

ak bnâ€“k ,
where we used eq. (A.7) in the last step .
âˆ
The following property of binomial coefï¬cients plays an important role when in-
troducing the hypergeometric distribution (compare Proposition 1.4.24). It is also
used during the investigation of sums of independent binomial distributed random
variables (compare Proposition 4.6.1).
Proposition A.3.8 (Vandermondeâ€™s identity). If k, m, and n in N0, then
k

j=0
n
j
 m
k â€“ j

=
n + m
k

.
(A.10)
Proof: An application of the binomial theorem leads to
(1 + x)n+m =
n+m

k=0
n + m
k

xk ,
x âˆˆR .
(A.11)

372
A Appendix
On the other hand, another use of Proposition A.3.7 implies3
(1 + x)n+m = (1 + x)n(1 + x)m
=
â¡
â£
n

j=0
n
j

xj
â¤
â¦
) m

i=0
m
i

xi
*
=
n

j=0
m

i=0
n
j
m
i

xi+j
=
n+m

k=0
â¡
â£
i+j=k
n
j
m
i
â¤
â¦xk =
n+m

k=0
â¡
â£
k

j=0
n
j
 m
k â€“ j
â¤
â¦xk .
(A.12)
The coefï¬cients in an expansion of a polynomial are unique. Hence, in view of eqs.
(A.11) and (A.12), we get for all k â‰¤m + n the identity
n + m
k

=
k

j=0
n
j
 m
k â€“ j

.
Hereby note that both sides of eq. (A.10) become zero whenever k > n + m. This
completes the proof.
âˆ
Our next objective is to generalize the binomial coefï¬cients. In view of
n
k

= n (n â€“ 1) â‹…â‹…â‹…(n â€“ k + 1)
k!
for k â‰¥1 and n âˆˆN the generalized binomial coefï¬cient is introduced as
â€“n
k

:= â€“n (â€“n â€“ 1) â‹…â‹…â‹…(â€“n â€“ k + 1)
k!
.
(A.13)
The next lemma shows the tight relation between generalized and â€œordinaryâ€ bino-
mial coefï¬cients.
Lemma A.3.9. For k â‰¥1 and n âˆˆN,
â€“n
k

= (â€“1)k
n + k â€“ 1
k

.
3 When passing from line 2 to line 3 the order of summation is changed. One no longer sums over the
rectangle [0, m] Ã— [0, n]. Instead one sums along the diagonals, where i + j = k.

A Appendix
373
Proof: By deï¬nition of the generalized binomial coefï¬cient we obtain
â€“n
k

= (â€“n) (â€“n â€“ 1) â‹…â‹…â‹…(â€“n â€“ k + 1)
k!
= (â€“1)k (n + k â€“ 1) (n + k â€“ 2) â‹…â‹…â‹…(n + 1) n
k!
= (â€“1)k
n + k â€“ 1
k

.
This completes the proof.
âˆ
For example, Lemma A.3.9 implies
â€“1
k

= (â€“1)k and
â€“n
1

= â€“n.
A.3.2 Drawing Balls out of an Urn
Assume that there are n balls labeled from 1 to n in an urn. We draw k balls out of
the urn, thus observing a sequence of length k with entries from {1, . . . , n}. How many
different results (sequences) may be observed? To answer this question we have to
decide the arrangement of drawing. Do we or do we not replace the chosen ball? Is
it important in which order the balls were chosen or is it only of importance which
balls were chosen at all? Thus, we see that there are four different ways to answer this
question (replacement or nonreplacement, recording the order or nonrecording).
Example A.3.10. Let us regard the drawing of two balls out of four, that is, n = 4
and k = 2. Depending on the different arrangements the following results may be
observed. Note, for example, that in the two latter cases (3, 2) does not appear because
it is identical to (2, 3).
Replacement and order is
important
(1, 1)
(1, 2)
(1, 3)
(1, 4)
(2, 1)
(2, 2)
(2, 3)
(2, 4)
(3, 1)
(3, 2)
(3, 3)
(3, 4)
(4, 1)
(4, 2)
(4, 3)
(4, 4)
Nonreplacement and order is
important
â‹…
(1, 2)
(1, 3)
(1, 4)
(2, 1)
â‹…
(2, 3)
(2, 4)
(3, 1)
(3, 2)
â‹…
(3, 4)
(4, 1)
(4, 2)
(4, 3)
â‹…
16 different results
12 different results
Replacement and order is not
important
(1, 1)
(1, 2)
(1, 3)
(1, 4)
â‹…
(2, 2)
(2, 3)
(2, 4)
â‹…
â‹…
(3, 3)
(3, 4)
â‹…
â‹…
â‹…
(4, 4)
Nonreplacement and order
is not important
â‹…
(1, 2)
(1, 3)
(1, 4)
â‹…
â‹…
(2, 3)
(2, 4)
â‹…
â‹…
â‹…
(3, 4)
â‹…
â‹…
â‹…
â‹…
10 different results
6 different results

374
A Appendix
Let us come back now to the general situation of n different balls from which we
choose k at random.
Case 1 : Drawing with replacement and taking the order into account.
We have n different possibilities for the choice of the ï¬rst ball and since the chosen
ball is placed back there are also n possibilities for the second one and so on. Thus,
there are n possibilities for each of the k balls, leading to the following result.
The number of different results in this case is nk
Example A.3.11. Letters in Braille, a scripture for blind people, are generated by dots
or nondots at six different positions. How many letters may be generated in that way?
Answer: It holds that n = 2 (dot or no dot) at k = 6 different positions. Hence,
the number of possible representable letters is 26 = 64. In fact, there are only 63
possibilities because we have to rule out the case of no dots at all 6 positions.
Case 2 : Drawing without replacement and taking the order into account.
This case only makes sense if k â‰¤n. There are n possibilities to choose the ï¬rst ball.
After that there are still n â€“ 1 balls in the urn. Hence there are only n â€“ 1 possibilities
for the second choice, n â€“ 2 for the third, and so on. Summing up we get the following.
The number of possible results in this case equals
n(n â€“ 1) â‹…â‹…â‹…(n â€“ k + 1) =
n!
(n â€“ k)!
Example A.3.12. In a lottery 6 numbers are chosen out of 49. Of course, the chosen
numbers are not replaced. If we record the numbers as they appear (not putting them
in order) how many different sequences of six numbers exist?
Answer: Here we have n = 49 and k = 6. Hence the wanted number equals
49!
43! = 49 â‹…â‹…â‹…44 = 10, 068, 347, 520
Case 3 : Drawing with replacement not taking the order into account.
This case is more complicated and requires a different point of view. We count how
often each of the n balls was chosen during the k trials. Let k1 â‰¥0 be the frequency
of the ï¬rst ball, k2 â‰¥0 that of the second one, and so on. In this way we obtain n
non-negative integers k1, . . . , kn satisfying
k1 + â‹…â‹…â‹…+ kn = k .

A Appendix
375
Indeed, since we choose k balls, the frequencies have to sum to k. Consequently, the
number of possible results when drawing k of n balls with replacement and not taking
the order into account coincides with
#{(k1, . . . , kn) , kj âˆˆN0 , k1 + â‹…â‹…â‹…+ kn = k} .
(A.14)
In order to determine the cardinality (A.14) we use the following auxiliary model:
Let B1, . . . , Bn be n boxes. Given n nonnegative integers k1, . . . , kn, summing to k,
we place exactly k1 dots into B1, k2 dots into B2, and so on. At the end we distributed
k nondistinguishable dots into n different boxes. Thus, we see that the value of (A.14)
coincides with the number of different possibilities to distribute k nondistinguishable
dots into n boxes. Now assume that the boxes are glued together; on the very left we
put box B1, on its right we put box B2 and continue in this way up to box Bn on the very
right. In this way we obtain n + 1 dividing walls, two outer and n â€“ 1 inner ones. Now
we get all possible distributions of k dots into n boxes by shufï¬‚ing the k dots and the
n â€“ 1 inner dividing walls. For example, if we get the order w, w, d, d, w . . . , then this
means that there are no dots in B1 and B2, but there are two dots in B3.
Summing up, we have N = n + k â€“ 1 objects, k of them are dots and n â€“ 1 are walls.
As we know there are
N
k

different ways to order these N objects. Hence we arrived at
the following result.
The number of possibilities to distribute k anonymous dots into n boxes equals
n + k â€“ 1
k

=
n + k â€“ 1
n â€“ 1

.
It coincides with #{(k1, . . . , kn) , kj âˆˆN0 , k1 + â‹…â‹…â‹…+ kn = k} as well as with the number of
different results when choosing k balls out of n with replacement and not taking order
into account.
Example A.3.13. Dominoes are marked on each half either with no dots, one dot or
up to six dots. Hereby the dominoes are symmetric, that is, a tile with three dots on
the left-hand side and two ones on the right-hand one is identical with one having two
dots on the left-hand side and three dots on the right-hand one. How many different
dominoes exist?
Answer: It holds n = 7 and k = 2, hence the number of different dominoes equals
7+ 2 â€“ 1
2

=
8
2

= 28 .
Case 4 : Drawing without replacement not taking the order into account.

376
A Appendix
Here we also have to assume k â‰¤n. We already investigated this case when we
introduced the binomial coefï¬cients. The k chosen numbers are put in group 1, the
remaining n â€“ k balls in group 2. As we know there are
n
k

ways to split the n numbers
into such two groups. Hence we obtained the following.
The number of different results in this case is
n
k

Example A.3.14. If the order of the six numbers is not taken into account in Example
A.3.12, that is, we ignore which number was chosen ï¬rst, which second, and so on the
number of possible results equals
49
6

= 49 â‹…â‹…â‹…43
6!
= 13, 983, 816
Let us summarize the four different cases in a table. Here O and NO stand for re-
cording or nonrecording of the order while R and NR represent replacement or
nonreplacement.
R
NR
O
nk
n!
(nâ€“k)!
NO
n+kâ€“1
k

n
k

A.3.3 Multinomial Coefï¬cients
The binomial coefï¬cient
n
k

describes the number of possibilities to distribute n ob-
jects into two groups of k and n â€“ k elements. What happens if we have not only two
groups but m â‰¥2 ? Say the ï¬rst group has k1 elements, the second has k2 elements, and
so on, up to the mth group that has km elements. Of course, if we distribute n elements
the kj have to satisfy
k1 + â‹…â‹…â‹…+ km = n .
Using exactly the same arguments as in the case where m = 2 we get the following.
There exists exactly
n!
k1!â‹…â‹…â‹…km! different ways to distribute n elements into m groups of
sizes k1, k2, . . . , km where k1 + â‹…â‹…â‹…+ km = n.
In accordance with the binomial coefï¬cient we write

n
k1, . . . , km

:=
n!
k1! â‹…â‹…â‹…km! ,
k1 + â‹…â‹…â‹…+ km = n ,
(A.15)
and call

n
k1,...,km

a multinomial coefï¬cient, read â€œn chosen k1 up to km.â€

A Appendix
377
Remark A.3.15. If m = 2, then k1 + k2 = n, and

n
k1, k2

=

n
k1, n â€“ k1

=
 n
k1

=
 n
k2

.
Example A.3.16. A deck of cards for playing skat consists of 32 cards. Three players
each gets 10 cards; the remaining two cards (called â€œskatâ€) are placed on the table.
How many different distributions of the cards exist?
Answer: Let us ï¬rst deï¬ne what it means for two distribution of cards to be
identical. Say, this happens if each of the three players has exactly the same cards as in
the previous game. Therefore, the remaining two cards on the table are also identical.
Hence we distribute 32 cards into 4 groups possessing 10, 10, 10, and 2 elements.
Consequently, the number of different distributions equals 4

32
10, 10, 10, 2

=
32!
(10!)3 2! = 2.753294409 Ã— 1015 .
Remark A.3.17. One may also look at multinomial coefï¬cients from a different point
of view. Suppose we are given n balls of m different colors. Say there are k1 balls of
color 1, k2 balls of color 2, up to km balls of color m where, of course, k1 + â‹¯+ km = n.
Then there exist

n
k1, . . . , km

different ways to order these n balls. This is followed by the same arguments as we
used in Example A.3.4 for m = 2.
For instance, given 3 blue, 4 red and 2 white balls, then there are

9
3, 4, 2

=
9!
3! 4! 2! = 1260
different ways to order them.
Finally, let us still mention that in the literature one sometimes ï¬nds another
(equivalent) way for the introduction of the multinomial coefï¬cients. Given nonnegat-
ive integers k1, . . . , km with k1 + â‹¯+ km = n, it follows that

n
k1, . . . , km

=
 n
k1
 n â€“ k1
k2
 n â€“ k1 â€“ k2
k3

â‹¯
n â€“ k1 â€“ â‹¯â€“ kmâ€“1
km

.
(A.16)
A direct proof of this fact is easy and left as an exercise.
4 The huge size of this number explains why playing skat never becomes boring.

378
A Appendix
There is a combinatorial interpretation of the expression on the right-hand side of
eq. (A.16). To reorder n balls of m different colors, one chooses ï¬rst the k1 positions
for balls of color 1. There are
 n
k1

ways to do this. Thus, there remain n â€“ k1 possible
positions for balls of color 2, and there are
nâ€“k1
k2

possible choices for this, and so on.
Note that at the end there remain km positions for km balls; hence, the last term on the
right-hand side of eq. (A.16) equals 1.
Let us come now to the announced generalization of Proposition A.3.7.
Proposition A.3.18 (Multinomial theorem). Let n â‰¥0. Then for any m â‰¥1 and real
numbers x1, . . . , xm,
(x1 + â‹…â‹…â‹…+ xm)n =

k1+â‹…â‹…â‹…+km=n
kiâ‰¥0

n
k1, . . . , km

xk1
1 â‹…â‹…â‹…xkm
m .
(A.17)
Proof: Equality (A.17) is proved by induction. In contrast to the proof of the binomial
theorem, now induction is done over m, the number of summands.
If m = 1 the assertion is valid by trivial reasons.
Suppose now eq. (A.17) holds for m, all n â‰¥1 and all real numbers x1, . . . , xm. We
have to show the validity of eq. (A.17) for m + 1 and all n â‰¥1. Given real numbers
x1, . . . , xm+1 and n â‰¥1 set y := x1 + â‹…â‹…â‹…+ xm. Using A.3.7, by the validity of eq. (A.17) for
m and all n â€“ j, 0 â‰¤j â‰¤n, we obtain
(x1 + â‹…â‹…â‹…+ xm+1)n = (y + xm+1)n =
n

j=1
n!
j! (n â€“ j)! xj
m+1ynâ€“j
=
n

j=1
n!
j! (n â€“ j)!

k1+â‹…â‹…â‹…+km=nâ€“j
kiâ‰¥0
(n â€“ j)!
k1! â‹…â‹…â‹…km! xk1
1 â‹…â‹…â‹…xkm
m xj
m+1 .
Replacing j by km+1 and combining both sums leads to
(x1 + â‹…â‹…â‹…+ xm+1)n =

k1+â‹…â‹…â‹…+km+1=n
kiâ‰¥0
n!
k1! â‹…â‹…â‹…km+1! xk1
1 â‹…â‹…â‹…xkm+1
m+1 ,
hence eq. (A.17) is also valid for m + 1. This completes the proof.
âˆ
Remark A.3.19. The number of summands in eq. (A.17) equals5 n+mâ€“1
n

.
5 Compare case 3 in Section A.3.2.

A Appendix
379
A.4 Vectors and Matrices
The aim of this section is to summarize results and notations about vectors and
matrices used throughout this book. For more detailed reading we refer to any book
about Linear Algebra, for example, [Axl15].
Given two vectors x and y in Rn, their6 scalar product is deï¬ned as
âŸ¨x, yâŸ©:=
n

j=1
xjyj ,
x = (x1, . . . , xn) , y = (y1, . . . , yn) .
If x âˆˆRn, then
|x| := âŸ¨x, xâŸ©1/2 =
â›
â
n

j=1
x2
j
â
â 
1/2
denotes the Euclidean distance of x to 0. Thus, |x| may also be regarded as the length
of the vector x. In particular, we have |x| > 0 for all nonzero x âˆˆRn.
Any matrix A =

!ij
n
i,j=1 of real numbers !ij generates a linear7 mapping (also
denoted by A) via
Ax =
â›
â
n

j=1
!1jxj, . . . ,
n

j=1
!njxj
â
â ,
x = (x1, . . . , xn) âˆˆRn .
(A.18)
Conversely, any linear mapping A : Rn â†’Rn deï¬nes a matrix

!ij
n
i,j=1 by representing
Aej âˆˆRn as
Aej = (!1j, . . . , !nj) ,
j = 1, . . . , n .
Here ej = (0, . . . , 0,
1

j
, 0 . . . , 0) denotes the jth unit vector in Rn. With this generated
matrix

!ij
n
i,j=1 the linear mapping A acts as stated in eq. (A.18). Consequently, we may
always identify linear mappings in Rn with n Ã— n-matrices

!ij
n
i,j=1.
A matrix A is said to be regular8 if the generated linear mapping is one-to-one,
that is, if Ax = 0 implies x = 0. This is equivalent to the fact that the determinant
det(A) is nonzero.
6 Sometimes also called â€œdot-productâ€.
7 A mapping A : Rn â†’Rn is said to be linear if A(!x + "y) = !Ax + "Ay for all !, " âˆˆR and x, y âˆˆRn.
8 Sometimes also called nonsingular or invertible.

380
A Appendix
Let A =

!ij
n
i,j=1 be an n Ã— n matrix. Then its transposed matrix is deï¬ned as
AT :=

!ji
n
i,j=1. With this notation it follows for x, y âˆˆRn that
âŸ¨Ax, yâŸ©=
>
x, ATy
?
.
A matrix A with A = AT is said to be symmetric. In other words, A satisï¬es
âŸ¨Ax, yâŸ©= âŸ¨x, AyâŸ©,
x, y âˆˆRn .
An n Ã— n matrix R =

rij
n
i,j=1 is positive deï¬nite (or shorter, positive) provided it is
symmetric and that
âŸ¨Rx, xâŸ©=
n

i,j=1
rijxixj > 0 ,
x = (x1, . . . , xn) /= 0 .
We will write R > 0 in this case. In particular, each positive matrix R is regular and its
determinant satisï¬es det(R) > 0.
Let A =

!ij
n
i,j=1 be an arbitrary regular n Ã— n matrix. Set
R := AAT ,
(A.19)
that is, the entries rij of R are computed by
rij =
n

k=1
!ik!jk ,
1 â‰¤i, j â‰¤n .
Proposition A.4.1. Suppose the matrix R is deï¬ned by eq. (A.19) for some regular A.
Then it follows that R > 0.
Proof: Because of
RT =

AAT
T
=

AT
T
AT = AAT = R ,
the matrix R is symmetric. Furthermore, for x âˆˆRn with x /= 0 we obtain
âŸ¨Rx, xâŸ©=
>
AATx, x
?
=
>
ATx, ATx
?
= |ATx|2 > 0 .
Hereby we used that for a regular A the transposed matrix AT is regular
too. Consequently, if x /= 0, then ATx /= 0, thus |ATx| > 0. This completes the
proof.
âˆ

A Appendix
381
The identity matrix In is deï¬ned as n Ã— n matrix with entries $ij, 1 â‰¤i, j â‰¤n, where
$ij =

1
:
i = j
0
:
i /= j
(A.20)
Of course, Inx = x for x âˆˆRn.
Given a regular n Ã— n matrix A, there is unique matrix B such that A B = In. B is
called the inverse matrix of A and denoted by Aâ€“1. Recall that also Aâ€“1 A = In and,
moreover, (AT)â€“1 = (Aâ€“1)T.
An n Ã— n matrix U is said to be unitary or orthogonal provided that
UUT = UTU = In
with identity matrix In. Another way to express this is either that UT = Uâ€“1 or,
equivalently, that U satisï¬es
âŸ¨Ux, UyâŸ©= âŸ¨x, yâŸ©,
x, y âˆˆRn .
In particular, for each x âˆˆRn it follows
|Ux|2 = âŸ¨Ux, UxâŸ©= âŸ¨x, xâŸ©= |x|2 ,
that is, U preserves the length of vectors in Rn.
It is easy to see that an n Ã— n matrix U is unitary if and only if its column vec-
tors u1, . . . , un form an orthonormal basis in Rn. That is,
A
ui, uj
B
= $ij with $ijs as
in (A.20). This characterization of unitary matrices remains valid when we take the
column vectors instead of those generated by the rows.
We saw in Proposition A.4.1 that each matrix R of the form (A.19) is positive. Next
we prove that conversely, each R > 0 may be represented in this way.
Proposition A.4.2. Let R be an arbitrary positive nÃ—n matrix. Then there exists a regular
matrix A such that R = A AT.
Proof: Since R is symmetric, we may apply the principal axis transformation for sym-
metric matrices. It asserts that there exists a diagonal matrix9 D and a unitary matrix
U such that
R = UDUT .
Let $1, . . . , $n be the entries of D at its diagonal. From R > 0 we derive $j > 0, 1 â‰¤j â‰¤n.
To see this ï¬x j â‰¤n and set x := Uej where as above ej denotes the jth unit vector in Rn.
9 The entries dij of D satisfy dij = 0 if i /= j.

382
A Appendix
Then UTx = ej, hence
0 < âŸ¨Rx, xâŸ©=
>
UDUTx, x
?
=
>
DUTx, UTx
?
=
A
Dej, ej
B
= $j .
Because of $j > 0 we may deï¬ne D1/2 as diagonal matrix with entries $1/2
j
on its
diagonal. Setting A := UD1/2, because of (D1/2)T = D1/2 it follows that
R = (UD1/2)(UD1/2)T = AAT .
Since |det(A)|2 = det(A)det(AT) = det(R) > 0, the matrix A is regular, and this completes
the proof.
âˆ
Remark A.4.3. Note that representation (A.19) is not unique. Indeed, whenever
R = A AT, then we also have R = (AV)(AV)T for any unitary matrix V.
A.5 Some Analytic Tools
The aim of this section is to present some special results of Calculus that play an im-
portant role in the book. Hereby we restrict ourselves to those topics that are maybe
less known and that are not necessarily taught in a basic Calculus course. For a gen-
eral introduction to Calculus, including those topics as convergence of power series,
fundamental theorem of Calculus, mean-value theorem, and so on, we refer to the
books [Spi08] and [Ste15].
We start with a result that is used in the proof of Poissonâ€™s limit theorem 1.4.22.
From Calculus it is well known that for x âˆˆR
lim
nâ†’âˆ

1 + x
n

n
= ex .
(A.21)
The probably easiest proof of this fact is via the approach presented in [Spi08]. There
the logarithm function is deï¬ned by ln t =
# t
1
1
sds, t > 0. Hence, lâ€™HÃ´pitalâ€™s rule implies
lim
tâ†’âˆt ln

1 + x
t

= x ,
x âˆˆR .
From this eq. (A.21) easily follows by the continuity of the exponential function.
The next proposition may be viewed as a slight generalization of eq. (A.21).
Proposition A.5.1. Let (xn)nâ‰¥1 be a sequence of real numbers with limnâ†’âˆxn = x for
some x âˆˆR. Then we get
lim
nâ†’âˆ

1 + xn
n

n
= ex .
Proof: Because of eq. (A.21) it sufï¬ces to verify that
lim
nâ†’âˆ
....

1 + xn
n

n
â€“

1 + x
n

n.... = 0 .
(A.22)

A Appendix
383
Since the sequence (xn)nâ‰¥1 is converging, it is bounded. Consequently, there is a c > 0
such that for all n â‰¥1, we have |xn| â‰¤c. Of course, we may also assume |x| â‰¤c. Fix for
a moment n â‰¥1 and set
a := 1 + xn
n
and
b := 1 + x
n .
The choice of c > 0 yields |a| â‰¤1 + c/n as well as |b| â‰¤1 + c/n. Hence it follows
|an â€“ bn| = |a â€“ b| |anâ€“1 + anâ€“2b + â‹…â‹…â‹…+ abnâ€“2 + bnâ€“1|
â‰¤|a â€“ b|

|a|nâ€“1 + |a|nâ€“2|b| + â‹…â‹…â‹…+ |a||b|nâ€“2 + |b|nâ€“1
â‰¤|a â€“ b| n

1 + c
n

nâ€“1
â‰¤C n |a â€“ b| .
Here C > 0 is some constant that exists since (1 + c/n)nâ€“1 converges to ec. By the
deï¬nition of a and b,
....

1 + xn
n

n
â€“

1 + x
n

n.... â‰¤C n|xn â€“ x|
n
= C |x â€“ xn| .
Since xn â†’x, this immediately implies eq. (A.22) and proves the proposition.
âˆ
Our next objective is to present some properties of power series and of the functions
generated by them. Hereby we restrict ourselves to such assertions that we will use in
this book. For further reading we refer to Part IV in [Spi08].
Let (ak)kâ‰¥0 be a sequence of real numbers. Then its radius of convergence r âˆˆ
[0, âˆ] is deï¬ned by
r :=
1
lim sup
kâ†’âˆ
|ak|1/k .
Hereby we let 1/0 := âˆand 1/âˆ:= 0. If 0 < r â‰¤âˆand |x| < r, then the inï¬nite series
f(x) :=
âˆ

k=0
ak xk
(A.23)
converges (even absolutely). Hence the function f generated by eq. (A.23) is well-
deï¬ned on its region of convergence {x âˆˆR : |x| < r}. We say that f is represented as
a power series on {x âˆˆR : |x| < r}.

384
A Appendix
The function f deï¬ned by eq. (A.23) is inï¬nitely often differentiable on its region
of convergence and
f (n)(x) =
âˆ

k=n
k (k â€“ 1) â‹…â‹…â‹…(k â€“ n + 1) ak xkâ€“n
=
âˆ

k=0
(k + n) (k + n â€“ 1) â‹…â‹…â‹…(k + 1) ak+n xk = n!
âˆ

k=0
n + k
k

ak+n xk .
(A.24)
(compare [Spi08], Â§27, Thm. 6)
The coefï¬cients n!
n+k
k

an+k in the series representation of the nth derivative f (n)
possess the same radius of convergence as the original sequence (ak)kâ‰¥0. This is easy
to see for n = 1. The general case then follows by induction.
Furthermore, eq. (A.24) implies an = f (n)(0)/n! , which, in particular, tells us that
given f, the coefï¬cients (ak)kâ‰¥0 in representation (A.23) are unique.
Proposition A.5.2. If n â‰¥1 and |x| < 1 then it follows
1
(1 + x)n =
âˆ

k=0
â€“n
k

xk .
(A.25)
Proof: Using the formula to add a geometric series and applying
â€“1
k

= (â€“1)k yields
for |x| < 1 that
1
1 + x =
âˆ

k=0
(â€“1)k xk =
âˆ

k=0
â€“1
k

xk .
Consequently Proposition A.5.2 holds for n = 1.
Assume now we have proven the proposition for n â€“ 1, that is, if |x| < 1, then
1
(1 + x)nâ€“1 =
âˆ

k=0
â€“n + 1
k

xk .
Differentiating this equality on the region {x : |x| < 1} implies
â€“
n â€“ 1
(1 + x)n =
âˆ

k=1
â€“n + 1
k

k xkâ€“1 =
âˆ

k=0
â€“n + 1
k + 1

(k + 1) xk .
(A.26)
Direct calculations give
â€“k + 1
n â€“ 1
â€“n + 1
k + 1

= â€“k + 1
n â€“ 1 â‹…(â€“n + 1)(â€“n) â‹…â‹…â‹…(â€“n + 1 â€“ (k + 1) + 1)
(k + 1)!
= (â€“n)(â€“n â€“ 1) â‹…â‹…â‹…(â€“n â€“ k + 1)
k!
=
â€“n
k

,

A Appendix
385
which together with eq. (A.26) leads to
1
(1 + x)n =
âˆ

k=0
â€“n
k

xk .
This completes the proof of Proposition A.5.2.
âˆ
The next proposition may be viewed as a counterpart to eq. (A.10) in the case of
generalized binomial coefï¬cients.
Proposition A.5.3. For k â‰¥0 and m, n âˆˆN,
k

j=0
â€“n
j
 â€“m
k â€“ j

=
â€“n â€“ m
k

.
Proof: The proof is similar to that of Proposition A.3.8. Using Proposition A.5.2 we
represent the function (1 + x)â€“nâ€“m as power series in two different ways. On the one
hand for |x| < 1 we have the representation
1
(1 + x)n+m =
âˆ

k=0
â€“n â€“ m
k

xk
(A.27)
and on the other hand
1
(1 + x)n+m =
â¡
â£
âˆ

j=0
â€“n
j

xj
â¤
â¦
) âˆ

l=0
â€“m
l

xl
*
=
âˆ

k=0
â¡
â£
j+l=k
â€“n
j
â€“m
l
â¤
â¦xk =
âˆ

k=0
â¡
â£
k

j=0
â€“n
j
 â€“m
k â€“ j
â¤
â¦xk .
(A.28)
As observed above the coefï¬cients in a power series are uniquely determined. Thus,
the coefï¬cients in eqs. (A.27) and (A.28) have to coincide, which implies
k

j=0
â€“n
j
 â€“m
k â€“ j

=
â€“n â€“ m
k

as asserted.
âˆ
Let f : Rn â†’R be a function. How does one deï¬ne the integral
#
Rn f(x) dx ? To
simplify the notation let us restrict ourselves to the case n = 2. The main problems
already become clear in this case and the obtained results easily extend to higher
dimensions.

386
A Appendix
The easiest way to introduce the integral of a function of two variables is as
follows:

R2 f(x) dx :=
âˆ

â€“âˆ
â¡
â£
âˆ

â€“âˆ
f(x1, x2) dx2
â¤
â¦dx1 .
In order for this double integral to be well-deï¬ned we have to assume the existence of
the inner integral for each ï¬xed x1 âˆˆR and then the existence of the integral of the
function
x1 â†¦
âˆ

â€“âˆ
f(x1, x2) dx2 .
Doing so the following question arises immediately: why do we not deï¬ne the integral
in reversed order, that is, ï¬rst integrating via x1 and then with respect to x2?
To see the difï¬culties that may appear let us consider the following example.
Example A.5.4. The function f : R2 â†’R is deï¬ned as follows (Fig. A.1): If either x1 < 0
or x2 < 0 set f(x1, x2) = 0. If x1, x2 â‰¥0 deï¬ne f by
f(x1, x2) :=
â§
âªâªâ¨
âªâªâ©
+1
:
x1 â‰¤x2 < x1 + 1
â€“1
:
x1 + 1 â‰¤x2 â‰¤x1 + 2
0
:
otherwise
We immediately see that
âˆ

0
f(x1, x2) dx2 = 0 for all x1 âˆˆR , hence
âˆ

0
â¡
â£
âˆ

0
f(x1, x2) dx2
â¤
â¦dx1 = 0 .
+1
â€“1
0
0
0
1
2
3
4
1
2
3
4
Figure A.1: The function f.

A Appendix
387
On the other side it follows
âˆ

0
f(x1, x2) dx1 =
â§
âªâªâªâ¨
âªâªâªâ©
# x2
0 (+1) dx1 = x2
:
0 â‰¤x2 < 1
# x2â€“1
0
(â€“1) dx1 +
# x2
x2â€“1(+1) dx1 = 2 â€“ x2
:
1 â‰¤x2 â‰¤2
# x2
x2â€“2 f(x1, x2) dx1 = 0
:
2 < x2 < âˆ
leading to
âˆ

0
â¡
â£
âˆ

0
f(x1, x2) dx1
â¤
â¦dx2 = 1 /= 0 =
âˆ

0
â¡
â£
âˆ

0
f(x1, x2) dx2
â¤
â¦dx1 .
Example A.5.4 shows that neither the deï¬nition of the integral of functions of several
variables nor the interchange of integrals are unproblematic. Fortunately, we have the
following positive result (see [Dur10], Section 1.7, for more information).
Proposition A.5.5 (Fubiniâ€™s theorem). If f(x1, x2) â‰¥0 for all (x1, x2) âˆˆR2, then one may
interchange the order of integration. In other words,
âˆ

â€“âˆ
â¡
â£
âˆ

â€“âˆ
f(x1, x2) dx1
â¤
â¦dx2 =
âˆ

â€“âˆ
â¡
â£
âˆ

â€“âˆ
f(x1, x2) dx2
â¤
â¦dx1 .
(A.29)
Hereby we do not exclude that one of the two, hence also the other, iterated integral is
inï¬nite.
Furthermore, in the general case (f may attain also negative values) equality (A.29)
holds provided that one of the iterated integrals, for example,
âˆ

â€“âˆ
â¡
â£
âˆ

â€“âˆ
|f(x1, x2)| dx1
â¤
â¦dx2
is ï¬nite. Due to the ï¬rst part then we also have
âˆ

â€“âˆ
â¡
â£
âˆ

â€“âˆ
|f(x1, x2)| dx2
â¤
â¦dx1 < âˆ.
Whenever a function f on R2 satisï¬es one of the two assumptions in Proposition A.5.5,
then by

R2
f(x) dx :=
âˆ

â€“âˆ
â¡
â£
âˆ

â€“âˆ
f(x1, x2) dx1
â¤
â¦dx2 =
âˆ

â€“âˆ
â¡
â£
âˆ

â€“âˆ
f(x1, x2) dx2
â¤
â¦dx1

388
A Appendix
the integral of f is well-deï¬ned. Given a subset B âŠ†R2 we set

B
f(x) dx :=

R2
f(x) 1B(x) dx ,
provided the integral exists. Recall that 1B denotes the indicator function of B
introduced in eq. (3.20).
For example, let K1 be the unit circle in R2, that is, K1 = {(x1, x2) : x2
1 + x2
2 â‰¤1}, then
it follows

K1
f(x) dx =
1

â€“1
+
1â€“x2
1

â€“
+
1â€“x2
1
f(x1, x2) dx2 dx1 .
Or, if B = {(x1, x2, x3) âˆˆR3 : x1 â‰¤x2 â‰¤x3}, we have

B
f(x) dx =
âˆ

â€“âˆ
x3

â€“âˆ
x2

â€“âˆ
f(x1, x2, x3) dx1 dx2 dx3 .
Remark A.5.6. Proposition A.5.5 is also valid for inï¬nite double series. Let !ij be real
numbers either satisfying !ij â‰¥0 or âˆ
i=0
âˆ
j=0 |!ij| < âˆ, then this implies
âˆ

i=0
âˆ

j=0
!ij =
âˆ

j=0
âˆ

i=0
!ij =
âˆ

i,j=0
!ij .
Even more generally, if the sets Ik âŠ†N2
0, k âˆˆN0, form a disjoint partition of N2
0, then
âˆ

i,j=0
!ij =
âˆ

k=0

(i,j)âˆˆIk
!ij .
For example, if Ik = {(i, j) âˆˆN2 : i + j = k}, then
âˆ

i,j=0
!ij =
âˆ

k=0

(i,j)âˆˆIk
!ij =
âˆ

k=0
k

i=0
!i kâ€“i .

Bibliography
[Art64]
Emil Artin. The Gamma Function. Athena Series: Selected Topics in Mathematics, Holt,
Rinehart and Winston, New York-Toronto-London, 1964.
[Axl15]
Sheldon Axler. Linear Algebra Done Right. Springer International Publishing, Cham
Heidelberg, New York, Dordrecht, London, 3rd edition, 2015.
[Bil12]
Patrick Billingsley. Probability and Measure. John Wiley and Sons, Inc., Hoboken, 4th
edition, 2012.
[CB02]
George Casella and Roger L. Berger. Statistical Inference. Duxburg Press, Paciï¬c Grove,
CA, 2nd edition, 2002.
[Mor16]
Samuel G. Moreno. A Short and Elementary Proof of the Basel Problem. College Math. J. 47
(2016), 134â€“135.
[Coh13]
Donald L. Cohn. Measure Theory. BirkhÃ¤user Advanced Texts. BirkhÃ¤user, Springer,
New York, 2nd edition, 2013.
[Dud02] Richard M. Dudley. Real Analysis and Probability. Cambridge University Press, Cambridge,
2002.
[Dur10]
Richard Durrett. Probability: Theory and Examples. Cambridge University Press, New York,
4th edition, 2010.
[Fel68]
William Feller. An Introduction to Probability Theory and its Applications, volume 1. John
Wiley and Sons, New York-London-Sydney, 1968.
[Fis11]
Hans Fischer. A History of the Central Limit Theorem. Ergebnisse der Mathematik und ihrer
Grenzgebiete. Springer, New York, 2011.
[Gha05] Saeed Ghahramani. Fundamentals of Probability. Pearson Education, Inc., Upper Saddle
River, NJ, 3rd edition, 2005.
[GS01a] Geoffrey R. Grimmett and David R. Stirzacker. One Thousand Exercises in Probability.
Oxford University Press, Oxford, New York, 1st edition, 2001.
[GS01b] Geoffrey R. Grimmett and David R. Stirzacker. Probability and Random Processes. Oxford
University Press, Oxford, New York, 3rd edition, 2001.
[Kho07] Davar Khoshnevisan. Probability. Graduate Studies in Mathematics, 80. American
Mathematical Society, New York, 2007.
[Kol33]
Andrey Nikolajewitsch Kolmogorov. Grundbegriffe der Wahrscheinlichkeitsrechnung.
Ergebnisse der Mathematik und ihrer Grenzgebiete. Julius Springer, Berlin, 1933.
[Lag13]
Jeffrey C. Lagarias. Eulerâ€™s Constant: Eulerâ€™s Work and Modern Developments. Bull. Amer.
Math. Soc. (N.S.) 50 (2013), 527â€“628.
[Pao06] Marc S. Paolella. Fundamental Probability. A Computational Approach. John Wiley and
Sons, Chichester, 2006.
[Ros14]
Sheldon Ross. A First Course in Probability. Pearson Education Limited, Essex, 9th edition,
2014.
[Spi08]
Michael Spivak. Calculus. Publish or Perish, Houston, TX, 4th edition, 2008.
[Ste15]
James Stewart. Calculus. Cengage Learning, Boston, 8th edition, 2015.


Index
Absolute nth moment
â€“ of a random variable 222
!-signiï¬cance test 312
â€“ most powerful 312
Banachâ€™s matchbox problem 39
Bayesâ€™ formula 92
Bernoulli trial 178
Bernstein polynomial 299
Berry-EssÃ©en theorem 298
Bertrand paradox 84
B!,", beta distribution 55
Beta distribution 55
Beta function 54
Bias
â€“ of an estimator 352
Binary fraction 157
Binomial coefï¬cient 369
â€“ generalized 372
Binomial distribution 23
Binomial theorem 371
Bn,p, binomial distribution 23
Bâ€“
n,p, negative binomial distribution 37
Booleâ€™s inequality 9
Borel 3-ï¬eld
â€“ on R 5
â€“ on Rn 65
Borel set
â€“ in R 5
â€“ in Rn 65
Borel-Cantelli lemma 272
Box
â€“ n-dimensional 64
Buffonâ€™s needle test 70
Cantor set 45
Cardinality of a set 365
Cartesian product 366
Cauchy distribution 57
Cauchy-Schwarz inequality 241
Central limit theorem 286
â€“ for A-distributed random variables 295
â€“ for binomial random variables 291
â€“ for Poisson random variables 294
Chebyshevâ€™s inequality 265
Chi-squared distribution 54
72-distribution 54
72-tests
â€“ known expected value 331
â€“ unknown expected value 332
Clopper-Pearson intervals 360
Complementary set 366
Completely normal numbers 283
Conditional distribution 90
Conditional probability 90
Conï¬dence intervals 356
Conï¬dence regions 356
Continuity correction
â€“ for normal approximation 288
Continuity of a probability measure
â€“ from above 9
â€“ from below 9
Continuous random variable 110
Convergence
â€“ almost surely 278
â€“ in distribution 284
â€“ in probability 277
Convolution
â€“ of two functions 175
Convolution formula
â€“ continuous random variables 176
â€“ N0-valued random variables 173
â€“ Z-valued random variables 171
Coordinate mappings
â€“ of a random vector 119
Correlated random variables 239
Correlation coefï¬cient 241
Coupon collectorâ€™s problem 221
Covariance
â€“ of two random variables 236
Covariance matrix
â€“ of a normal vector 258
â€“ of a random vector 256
Critical region 308
Cumulative distribution function
â€“ of a probability measure 57
â€“ of a random variable 114
De Morganâ€™s rules 366
Density
â€“ of a probability measure
â€“ multivariate 65
â€“ univariate 42

392
Index
Density function
â€“ of a probability measure
â€“ multivariate 64
â€“ univariate 40
â€“ of a random variable 110
â€“ of a random vector 128
Dependence of events 95
Dilemma
â€“ of hypothesis testing 311
Dirac measure 18
Discrete random variable 110
Disjoint sets 366
Distribution
â€“ of a random variable 109
â€“ of a random vector 121
Distribution assumption 302
Distribution density
â€“ of a random variable 110
â€“ of a random vector 128
Distribution function
â€“ of a probability measure 57
â€“ of a random variable 114
Drawing with replacement
â€“ no order 374
â€“ with order 374
Drawing without replacement
â€“ no order 375
â€“ with order 374
E+, exponential distribution 51
Elementary event 2
E+,n, Erlang distribution 52
Erlang distribution 52
Error
â€“ of the ï¬rst kind 309
â€“ of the second kind 309
Error function
â€“ Gaussian 59
Estimator 338
â€“ efï¬cient 355
â€“ maximum likelihood 341
â€“ unbiased 347
â€“ uniformly best 353
Euclidean distance
â€“ in Rn 379
Eulerâ€™s constant 222
Event 2
â€“ certain 2
â€“ impossible 2
Expected value
â€“ of continuous random variables 210
â€“ of discrete random variables 202
â€“ of non-negative random variables
â€“ continuous case 209
â€“ discrete case 201
â€“ of random vectors 256
Exponential distribution 51
Factorial 368
F-distribution 195
Finite additivity 6
Fisher information 354
Fisherâ€™s
â€“ lemma 320
â€“ theorem 321
Fisher-Snecedor distribution 195
Frequency
â€“ absolute 6
â€“ relative 6
F-tests 336
Fubiniâ€™s theorem 387
Function
â€“ absolutely integrable 209
â€“ integrable 209
A!,", gamma distribution 51
Gamma function 48
Gauss test
â€“ one-sided 326
â€“ two-sided 328
Gaussian error function 59
Gaussian I-function 58
Generalized binomial coefï¬cient 372
Generated 3-ï¬eld 4
Generating function
â€“ of a non-negative random variable 247
â€“ of an N0-valued random variable 196
Geometric distribution 34
Gp, geometric distribution 34
Histogram correction
â€“ for normal approximation 288
HN,M,n, hypergeometric distribution 31
Hypergeometric distribution 31
Hypothesis
â€“ alternative 308
â€“ null 308
Hypothesis test 308

Index
393
Identically distributed 109
Inclusion-exclusion formula 80
Independence
â€“ of n events 98
â€“ of inï¬nitely many events 272
â€“ of two events 95
Independent random variables 131
â€“ continuous case 138
â€“ discrete case 134
â€“ inï¬nitely many 161
Independent repetition
â€“ of an experiment 303
Indicator function
â€“ of a set 136
Inequality
â€“ Booleâ€™s 9
â€“ Cauchy-Schwarz 241
â€“ Chebyshevâ€™s 265
Initial model
â€“ of a statistical experiment 303
Interval estimator 356
Joint density
â€“ of n random variables 128
Joint distribution
â€“ of n random variables 121
Laplace distribution 19
Law
â€“ of multiplication 87
â€“ of total probability 90
Lemma
â€“ Borel-Cantelli 272
â€“ Fisherâ€™s 320
Likelihood function
â€“ continuous case 339
â€“ discrete case 339
Log-likelihood function 341
Lower limit
â€“ of events 270
Marginal distributions
â€“ of a random vector 122
â€“ continuous case 129
â€“ discrete case 124
Matchbox problem 39
Matrix
â€“ identity matrix 381
â€“ inverse 381
â€“ invertible 379
â€“ non-singular 379
â€“ orthogonal 381
â€“ positive deï¬nite 380
â€“ regular 379
â€“ symmetric 380
â€“ unitary 381
Maximum likelihood estimator 341
Measurable function 149
Median
â€“ of a random variable 212
MLE 341
Moments
â€“ of a random variable 222
Monte Carlo method 280
Monty Hall problem 81
Multinomial
â€“ coefï¬cient 376
â€“ random vector 127
â€“ theorem 378
Multinomial distribution 25
N, natural numbers 365
N0, natural numbers with zero 365
Needle test 70
Negative binomial distribution 37
Negatively correlated 242
N (,, R), normal distribution
â€“ multivariate 254
N (,, 32), normal distribution
â€“ univariate 47
Normal distribution
â€“ multivariate 254
â€“ univariate 47
Normal numbers 282
Occurrence
â€“ of an event 2
Occurrence of events
â€“ ï¬nally always 271
â€“ inï¬nitely often 271
Order statistics 142
Pairwise independence 97
Paradox
â€“ of Bertrand 84
â€“ of Chevalier de MÃ©rÃ© 81
Parameter set 305
Pascalâ€™s triangle 370
Permutation 367
Point estimator 338
Point measure 18
Pois+, Poisson distribution 28

394
Index
Poisson distribution 28
Poissonâ€™s limit theorem 28
Positively correlated 242
Power function
â€“ of a test 310
Power series 383
Powerset 365
Preimage 367
Principal axis transformation 381
Probabilities
â€“ a posteriori 92
â€“ a priori 92
Probability density function
â€“ multivariate 64
â€“ univariate 40
Probability distribution 7
â€“ of a random variable 109
â€“ continuous case 113
â€“ discrete case 111
â€“ of a random vector 121
Probability mass function 111
Probability measure 7
â€“ continuous
â€“ multivariate 65
â€“ univariate 42
â€“ discrete 17
Probability space 8
Product 3-ï¬eld 72
Product measure 73
â€“ of continuous probabilities 76
â€“ of discrete probabilities 74
Pseudo-inverse
â€“ of a distribution function 167
Q, rational numbers 365
Quantile
â€“ 72
n-distribution 324
â€“ Fm,n-distribution 325
â€“ standard normal distribution 323
â€“ tn-distribution 325
R, real numbers 365
Radius of convergence 383
Raisins in dough 179
Random experiment 1
Random real number 106
Random variable 106
â€“ continuous 110
â€“ discrete 110
â€“ real-valued 106
â€“ singularly continuous 114
â€“ vector valued 119
Random variables
â€“ identically distributed 109
â€“ independent 131
Random vector 119
â€“ multinomial distributed 127
â€“ N (,, R)-distributed 253
â€“ normally distributed 250
â€“ standard normally distributed 249
Random walk
â€“ (next neighbor) on Z 152
Randomized test 309
Reduction
â€“ of the sample space 88
Region
â€“ of acceptance 308
â€“ of rejection 308
Region of convergence 383
Risk function
â€“ of an estimator 351
Rn, n-dimensional Euclidian space 365
Round-off errors 290
Sample
â€“ random 302
Sample mean 320
Sample space 1
Sample variance
â€“ biased 320
â€“ unbiased 320
Scalar product
â€“ of two vectors 379
Sequence
â€“ absolutely summable 201
â€“ summable 201
Set difference 366
3-additivity 7
3-ï¬eld 3
â€“ generated 4
Signiï¬cance level 312
Signiï¬cance test 312
â€“ for a binomial population
â€“ one-sided 317
â€“ two-sided 315
â€“ for a hypergeometric population
â€“ one-sided 313
â€“ two-sided 364

Index
395
Simulation
â€“ of a random variable
â€“ continuous case 166
â€“ discrete case 164
Standard normal distribution
â€“ multivariate 79, 255
â€“ univariate 48
Statistical model
â€“ non-parametric 302
â€“ parametric 305
Stirlingâ€™s formula
â€“ for n-factorial 50
â€“ for the A-function 50
Strong law of large numbers 278
Studentâ€™s t-distribution 193
Success probability 24
Symmetric difference 366
Systematic error
â€“ of an estimator 352
t-distribution 193
t-test
â€“ one-sided 329
â€“ two-sided 329
Theorem
â€“ Berry-EssÃ©en 298
â€“ binomial 371
â€“ De Moivre-Laplace 291
â€“ Fisherâ€™s 321
â€“ Fubiniâ€™s 387
â€“ multinomial 378
â€“ Poissonâ€™s limit 28
â€“ Rao-CramÃ©r-Frechet 355
33-rule 156
Tossing a coin
â€“ inï¬nitely often 161
Two-sample t-tests 334
Two-sample Z-tests 332
Type I error 309
Type II error 309
Unbiased estimator 347
Uncorrelated random variables 239
Uniform distribution
â€“ on a ï¬nite set 19
â€“ on a set in Rn 68
â€“ on an interval 44
Uniformly best estimator 353
Upper limit
â€“ of events 270
Vandermondeâ€™s identity 371
Variance
â€“ of a random variable 227
Volume
â€“ n-dimensional 66
Weak law of large numbers 277
Z, integers 365
Z-test
â€“ one-sided 326
â€“ two-sided 328


