Free ebooks ==>  
www.Ebook777.com
www.Ebook777.com

Free ebooks ==>   www.Ebook777.com
The CERT
® Guide to
Insider Threats
www.Ebook777.com

T
he SEI Series in Software Engineering represents is a collaborative 
undertaking of the Carnegie Mellon Software Engineering Institute (SEI) and 
Addison-Wesley to develop and publish books on software engineering and 
related topics. The common goal of the SEI and Addison-Wesley is to provide 
the most current information on these topics in a form that is easily usable by 
practitioners and students.
Books in the series describe frameworks, tools, methods, and technologies 
designed to help organizations, teams, and individuals improve their technical 
or management capabilities. Some books describe processes and practices for 
developing higher-quality software, acquiring programs for complex systems, or 
delivering services more effectively. Other books focus on software and system 
architecture and product-line development. Still others, from the SEI’s CERT 
Program, describe technologies and practices needed to manage software 
and network security risk. These and all books in the series address critical 
problems in software engineering for which practical solutions are available. 
Visit informit.com/sei for a complete list of available products.
The SEI Series in 
Software Engineering

The CERT
® Guide to 
Insider Threats
How to Prevent, Detect, and Respond to 
Information Technology Crimes  
(Theft, Sabotage, Fraud)
Dawn Cappelli 
Andrew Moore 
Randall Trzeciak
Upper Saddle River, NJ • Boston• Indianapolis • San Francisco
New York • Toronto • Montreal • London • Munich • Paris • Madrid
Capetown • Sydney • Tokyo • Singapore • Mexico City

Free ebooks ==>   www.Ebook777.com
The SEI Series in Software Engineering
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as 
 trademarks. Where those designations appear in this book, and the publisher was aware of a trademark claim, 
the designations have been printed with initial capital letters or in all capitals.
CMM, CMMI, Capability Maturity Model, Capability Maturity Modeling, Carnegie Mellon, CERT, and CERT 
Coordination Center are registered in the U.S. Patent and Trademark Office by Carnegie Mellon University.
ATAM; Architecture Tradeoff Analysis Method; CMM Integration; COTS Usage-Risk Evaluation; CURE; EPIC; 
Evolutionary Process for Integrating COTS Based Systems; Framework for Software Product Line Practice; 
IDEAL; Interim Profile; OAR; OCTAVE; Operationally Critical Threat, Asset, and Vulnerability Evaluation; 
Options Analysis for Reengineering; Personal Software Process; PLTP; Product Line Technical Probe; PSP; 
SCAMPI; SCAMPI Lead Appraiser; SCAMPI Lead Assessor; SCE; SEI; SEPG; Team Software Process; and TSP 
are service marks of Carnegie Mellon University.
Special permission to reproduce portions of Carnegie Mellon University copyrighted materials has been 
granted by the Software Engineering Institute. (See page 388 for details.)
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as 
 trademarks. Where those designations appear in this book, and the publisher was aware of a trademark claim, 
the designations have been printed with initial capital letters or in all capitals.
The authors and publisher have taken care in the preparation of this book, but make no expressed or 
implied warranty of any kind and assume no responsibility for errors or omissions. No liability is assumed 
for  incidental or consequential damages in connection with or arising out of the use of the information or 
 programs contained herein.
The publisher offers excellent discounts on this book when ordered in quantity for bulk purchases or special 
sales, which may include electronic versions and/or custom covers and content particular to your business, 
training goals, marketing focus, and branding interests. For more information, please contact: U.S. Corporate 
and Government Sales, (800) 382-3419, corpsales@pearsontechgroup.com.
For sales outside the United States, please contact: International Sales, international@pearson.com.
Visit us on the Web: informit.com/aw
Cataloging-in-Publication Data is on file with the Library of Congress.
Copyright © 2012 Pearson Education, Inc.
All rights reserved. Printed in the United States of America. This publication is protected by copyright, and 
permission must be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval 
system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or 
likewise. To obtain permission to use material from this work, please submit a written request to Pearson 
 Education, Inc., Permissions Department, One Lake Street, Upper Saddle River, New Jersey 07458, or you may 
fax your request to (201) 236-3290.
ISBN-13: 978-0-321-81257-5 
ISBN-10: 
0-321-81257-3
Text printed in the United States on recycled paper at Courier in Westford, Massachusetts. 
First printing, January 2012
www.Ebook777.com

For Fred, Anthony, and Alyssa. You are my life—I love you!
—Dawn
For those who make my life oh so sweet: Susan, Eric, Susan’s  
amazing family, and my own Mom, Dad, Roger, and Lisa. 
—Andy
For Marianne, Abbie, Nate, and Luke. I am the luckiest person in  
the world to have such a wonderful family. 
—Randy

This page intentionally left blank 

vii
Contents
Preface  .......................................................................................................... xvii
Acknowledgments  ....................................................................................  xxxi
Chapter 1. Overview .........................................................................................1
True Stories of Insider Attacks ......................................................3
Insider IT Sabotage .......................................................................3
Insider Fraud ................................................................................4
Insider Theft of Intellectual Property ............................................5
The Expanding Complexity of Insider Threats ..........................6
Breakdown of Cases in the Insider Threat Database .................7
CERT’s MERIT Models of Insider Threats ..................................9
Why Our Profiles Are Useful ......................................................10
Why Not Just One Profile? .........................................................11
Why Didn’t We Create a Single Insider Theft Model? ...............12
Overview of the CERT Insider Threat Center ...........................13
Timeline of the CERT Program’s Insider Threat Work ............16
2000 Initial Research ..................................................................16
2001 Insider Threat Study ..........................................................16
2001 Insider Threat Database .....................................................17
2005 Best Practices .....................................................................17
2005 System Dynamics Models ..................................................17
2006 Workshops ..........................................................................17

viii
Contents
2006 Interactive Virtual Simulation Tool ...................................18
2007 Insider Threat Assessment .................................................18
2009 Insider Threat Lab ..............................................................18
2010 Insider Threat Exercises .....................................................18
2010 Insider Threat Study—Banking and Finance Sector .........19
Caveats about Our Work .............................................................20
Summary .......................................................................................20
Chapter 2. Insider IT Sabotage .....................................................................23
General Patterns in Insider IT Sabotage Crimes ......................28
Personal Predispositions .............................................................28
Disgruntlement and Unmet Expectations ..................................31
Behavioral Precursors .................................................................35
Stressful Events ..........................................................................37
Technical Precursors and Access Paths .......................................40
The Trust Trap .............................................................................45
Mitigation Strategies ....................................................................46
Early Mitigation through Setting of Expectations .....................47
Handling Disgruntlement through Positive Intervention .........49
Eliminating Unknown Access Paths ..........................................50
More Complex Monitoring Strategies ........................................52
A Risk-Based Approach to Prioritizing Alerts ............................53
Targeted Monitoring ...................................................................55
Measures upon Demotion or Termination ..................................56
Secure the Logs ............................................................................56
Test Backup and Recovery Process ..............................................57
One Final Note of Caution ..........................................................59
Summary .......................................................................................59
Chapter 3. Insider Theft of Intellectual Property ......................................61
Impacts ...........................................................................................66
General Patterns in Insider Theft of Intellectual  
Property Crimes ............................................................................68

Free ebooks ==>   www.Ebook777.com
ix
Contents
The Entitled Independent ............................................................69
Insider Contribution and Entitlement ........................................70
Insider Dissatisfaction ................................................................72
Insider Theft and Deception ........................................................74
The Ambitious Leader .................................................................78
Insider Planning of Theft ............................................................79
Increasing Access ........................................................................80
Organization’s Discovery of Theft ..............................................80
Theft of IP inside the United States Involving Foreign  
Governments or Organizations ..................................................83
Who They Are .............................................................................85
What They Stole ..........................................................................86
Why They Stole ...........................................................................88
Mitigation Strategies for All Theft of Intellectual  
Property Cases ..............................................................................88
Exfiltration Methods ...................................................................89
Network Data Exfiltration ..........................................................90
Host Data Exfiltration ................................................................93
Physical Exfiltration ...................................................................95
Exfiltration of Specific Types of IP ..............................................95
Concealment ...............................................................................95
Trusted Business Partners ..........................................................96
Mitigation Strategies: Final Thoughts .......................................97
Summary .......................................................................................98
Chapter 4. Insider Fraud ..............................................................................101
General Patterns in Insider Fraud Crimes ..............................106
Origins of Fraud .......................................................................108
Continuing the Fraud ...............................................................110
Outsider Facilitation ................................................................. 111
Recruiting Other Insiders into the Scheme ...............................113
Insider Stressors ........................................................................115
Insider Fraud Involving Organized Crime .............................115
www.Ebook777.com

x
Contents
Snapshot of Malicious Insiders Involved with  
Organized Crime.......................................................................116
Who They Are ...........................................................................117
Why They Strike .......................................................................118
What They Strike ......................................................................118
How They Strike .......................................................................118
Organizational Issues of Concern and Potential  
Countermeasures ........................................................................120
Inadequate Auditing of Critical and Irregular Processes ..........120
Employee/Coworker Susceptibility to Recruitment ..................121
Verification of Modification of Critical Data .............................123
Financial Problems ...................................................................124
Excessive Access Privilege ........................................................125
Other Issues of Concern ............................................................125
Mitigation Strategies: Final Thoughts .....................................126
Summary .....................................................................................127
Chapter 5.  Insider Threat Issues in the Software    
Development Life Cycle ...........................................................129
Requirements and System Design Oversights .......................131
Authentication and Role-Based Access Control .......................132
Separation of Duties ..................................................................133
Automated Data Integrity Checks ............................................134
Exception Handling ..................................................................135
System Implementation, Deployment, and Maintenance  
Issues ............................................................................................136
Code Reviews ............................................................................136
Attribution ................................................................................137
System Deployment ..................................................................137
Backups .....................................................................................139
Programming Techniques Used As an Insider  
Attack Tool ...................................................................................139
Modification of Production Source Code or Scripts ..................140
Obtaining Unauthorized Authentication Credentials ..............141
Disruption of Service and/or Theft of Information ...................141

xi
Contents
Mitigation Strategies ..................................................................142
Summary .....................................................................................143
Chapter 6.  Best Practices for the Prevention and  Detection  
of Insider Threats ......................................................................145
Summary of Practices.................................................................146
Practice 1: Consider Threats from Insiders  
and Business Partners in Enterprise-Wide  
Risk Assessments ........................................................................151
What Can You Do? ...................................................................151
Case Studies: What Could Happen if I Don’t Do It? ................152
Practice 2: Clearly Document and Consistently  
Enforce Policies and Controls ...................................................155
What Can You Do? ...................................................................155
Case Studies: What Could Happen if I Don’t Do It? ................156
Practice 3: Institute Periodic Security Awareness  
Training for All Employees .......................................................159
What Can You Do? ...................................................................159
Case Studies: What Could Happen if I Don’t Do It? ................162
Practice 4: Monitor and Respond to Suspicious 
or Disruptive Behavior, Beginning  
with the Hiring Process .............................................................164
What Can You Do? ...................................................................164
Case Studies: What Could Happen if I Don’t Do It? ................166
Practice 5: Anticipate and Manage Negative  
Workplace Issues ........................................................................168
What Can You Do? ...................................................................168
Case Studies: What Could Happen if I Don’t Do It? ................169
Practice 6: Track and Secure the Physical Environment ........171
What Can You Do? ...................................................................171
Case Studies: What Could Happen if I Don’t Do It? ................173
Practice 7: Implement Strict Password- and Account- 
Management Policies and Practices .........................................174
What Can You Do? ...................................................................174
Case Studies: What Could Happen if I Don’t Do It? ................176

xii
Contents
Practice 8: Enforce Separation of Duties and  
Least Privilege .............................................................................178
What Can You Do? ...................................................................178
Case Studies: What Could Happen if I Don’t Do It? ................180
Practice 9: Consider Insider Threats in the Software  
Development Life Cycle ............................................................182
What Can You Do? ...................................................................182
Requirements Definition ...........................................................182
System Design ..........................................................................183
Implementation .........................................................................183
Installation ................................................................................184
System Maintenance .................................................................185
Case Studies: What Could Happen if I Don’t Do It? ................185
Practice 10: Use Extra Caution with System  
Administrators and Technical or Privileged Users ................187
What Can You Do? ...................................................................187
Case Studies: What Could Happen if I Don’t Do It? ................189
Practice 11: Implement System Change Controls ...................191
What Can You Do? ...................................................................191
Case Studies: What Could Happen if I Don’t Do It? ................192
Practice 12: Log, Monitor, and Audit Employee  
Online Actions ............................................................................195
What Can You Do? ...................................................................195
Case Studies: What Could Happen if I Don’t Do It? ................198
Practice 13: Use Layered Defense against Remote Attacks ...200
What Can You Do? ...................................................................200
Case Studies: What Could Happen if I Don’t Do It? ................201
Practice 14: Deactivate Computer Access Following 
 Termination .................................................................................203
What Can You Do? ...................................................................203
Case Studies: What Could Happen if I Don’t Do It? ................205
Practice 15: Implement Secure Backup and Recovery  
Processes ......................................................................................207
What Can You Do? ...................................................................207
Case Studies: What Could Happen if I Don’t Do It? ................209

xiii
Contents
Practice 16: Develop an Insider Incident Response Plan.......211
What Can You Do? ...................................................................211
Case Studies: What Could Happen if I Don’t Do It? ................212
Summary .....................................................................................213
References/Sources of Best Practices .......................................214
Chapter 7. Technical Insider Threat Controls ..........................................215
Infrastructure of the Lab ............................................................217
Demonstrational Videos ............................................................218
High-Priority Mitigation Strategies .........................................219
Control 1: Use of Snort to Detect Exfiltration of  
Credentials Using IRC ...............................................................220
Suggested Solution ...................................................................221
Control 2: Use of SiLK to Detect Exfiltration of Data  
Using VPN ...................................................................................221
Suggested Solution ...................................................................222
Control 3: Use of a SIEM Signature to Detect Potential  
Precursors to Insider IT Sabotage .............................................223
Suggested Solution ...................................................................224
Database Analysis .....................................................................225
SIEM Signature ........................................................................227
Common Event Format .............................................................228
Common Event Expression .......................................................229
Applying the Signature.............................................................230
Conclusion ................................................................................231
Control 4: Use of Centralized Logging to Detect Data 
 Exfiltration during an Insider’s Last Days  
of Employment ...........................................................................231
Suggested Solution ...................................................................232
Monitoring Considerations Surrounding Termination ............233
An Example Implementation Using Splunk .............................235
Advanced Targeting and Automation .......................................237
Conclusion ................................................................................239

xiv
Contents
Insider Threat Exercises .............................................................239
Summary .....................................................................................239
Chapter 8. Case Examples ............................................................................241
Sabotage Cases ............................................................................241
Sabotage Case 1 .........................................................................243
Sabotage Case 2 .........................................................................244
Sabotage Case 3 .........................................................................244
Sabotage Case 4 .........................................................................245
Sabotage Case 5 .........................................................................245
Sabotage Case 6 .........................................................................246
Sabotage Case 7 .........................................................................246
Sabotage Case 8 .........................................................................247
Sabotage Case 9 .........................................................................247
Sabotage Case 10 .......................................................................248
Sabotage Case 11 .......................................................................248
Sabotage Case 12 .......................................................................249
Sabotage Case 13 .......................................................................249
Sabotage Case 14 .......................................................................250
Sabotage Case 15 .......................................................................250
Sabotage Case 16 .......................................................................251
Sabotage Case 17 .......................................................................252
Sabotage Case 18 .......................................................................252
Sabotage Case 19 .......................................................................253
Sabotage Case 20 .......................................................................253
Sabotage Case 21 .......................................................................254
Sabotage Case 22 .......................................................................255
Sabotage Case 23 .......................................................................255
Sabotage Case 24 .......................................................................256
Sabotage/Fraud Cases ...............................................................256
Sabotage/Fraud Case 1 ..............................................................257
Sabotage/Fraud Case 2 ..............................................................257
Sabotage/Fraud Case 3 ..............................................................258

xv
Contents
Theft of IP Cases .........................................................................258
Theft of IP Case 1 ......................................................................259
Theft of IP Case 2 ......................................................................260
Theft of IP Case 3 ......................................................................260
Theft of IP Case 4 ......................................................................261
Theft of IP Case 5 ......................................................................261
Theft of IP Case 6 ......................................................................262
Fraud Cases .................................................................................262
Fraud Case 1 .............................................................................264
Fraud Case 2 .............................................................................264
Fraud Case 3 .............................................................................265
Fraud Case 4 .............................................................................265
Fraud Case 5 .............................................................................266
Fraud Case 6 .............................................................................266
Fraud Case 7 .............................................................................266
Fraud Case 8 .............................................................................267
Fraud Case 9 .............................................................................267
Fraud Case 10 ...........................................................................268
Fraud Case 11 ............................................................................268
Fraud Case 12 ...........................................................................269
Miscellaneous Cases ...................................................................269
Miscellaneous Case 1 ................................................................270
Miscellaneous Case 2 ................................................................271
Miscellaneous Case 3 ................................................................271
Miscellaneous Case 4 ................................................................271
Miscellaneous Case 5 ................................................................272
Miscellaneous Case 6 ................................................................272
Summary .....................................................................................273
Chapter 9. Conclusion and Miscellaneous Issues ...................................275
Insider Threat from Trusted Business Partners ......................275
Overview of Insider Threats from Trusted  
Business Partners .....................................................................278
Fraud Committed by Trusted Business Partners ......................279

xvi
Contents
IT Sabotage Committed by Trusted Business Partners .............280
Theft of Intellectual Property Committed by Trusted  
Business Partners .....................................................................281
Open Your Mind: Who Are Your Trusted  
Business Partners? ...................................................................282
Recommendations for Mitigation and Detection ......................283
Malicious Insiders with Ties to the Internet  
Underground ..............................................................................286
Snapshot of Malicious Insiders with Ties to the Internet    
Underground ............................................................................287
Range of Involvement of the Internet Underground .................288
The Crimes ................................................................................288
Use of Unknown Access Paths Following Termination ............289
Insufficient Access Controls and Monitoring ...........................291
Conclusions: Insider Threats Involving the Internet  
Underground ............................................................................293
Final Summary ............................................................................293
Let’s End on a Positive Note! ....................................................296
Appendix A. Insider Threat Center Products and Services...................299
Appendix B. Deeper Dive into the Data ...................................................307
Appendix C. CyberSecurity Watch Survey ..............................................319
Appendix D. Insider Threat Database Structure .....................................325
Appendix E.  Insider Threat Training Simulation:  
MERIT InterActive ................................................................333
Appendix F. System Dynamics Background ...........................................345
Glossary of Terms ............................................................................................351
References .........................................................................................................359
About the Authors...........................................................................................365
Index ..................................................................................................................369

xvii
Preface
A night-shift security guard at a hospital plants malware1 on the hospital’s 
computers. The malware could have brought down the heating, ventila-
tion, and cooling systems and ultimately cost lives. Fortunately, he has 
posted a video of his crime on YouTube and is caught before carrying out 
his illicit intent.
A programmer quits his job at a nuclear power plant in the United States 
and returns to his home country of Iran with simulation software contain-
ing schematics and other engineering information for the power plant.
A group of employees at a Department of Motor Vehicles work together to 
make some extra money by creating driver’s licenses for undocumented 
immigrants and others who could not legally get a license. They are finally 
arrested after creating a license for an undercover agent who claimed to be 
on the “No Fly List.”
These insider incidents are the types of crimes we will discuss in this 
book—crimes committed by current or former employees, contractors, or 
business partners of the victim organization. As you will see, consequences 
of malicious insider incidents can be substantial, including financial losses, 
operational impacts, damage to reputation, and harm to individuals. The 
actions of a single insider have caused damage to organizations ranging 
from a few lost staff hours to negative publicity and financial damage so 
extensive that businesses have been forced to lay off employees and even 
close operations. Furthermore, insider incidents can have repercussions 
beyond the victim organization, disrupting operations or services critical 
to a specific sector or creating serious risks to public safety and national 
security.
1. Malware: code intended to execute a malicious function; also commonly referred to as malicious 
code. [Note: The first time any word from the Glossary is used in the book it will be printed in boldface.]

xviii
Preface
We use many actual case examples throughout the book. It is important 
that you consider each case example by asking yourself the following ques-
tions: Could this happen in my organization? Could a night-shift security 
guard plant malicious code on our computers? Do we have employees, 
contractors, or business partners who might steal our sensitive information 
and give it to a competitor or foreign government or organization? Do we 
have systems that our employees could be paid by outsiders to  manipulate? 
For most of you, the answer to at least one of those questions will be an 
unequivocal yes! The good news is that after more than ten years of research 
into these types of crimes, we have developed insights and mitigation 
strategies that you can put in place in your organization to increase your 
chances of avoiding or surviving these types of situations. 
Insider threats are an intriguing and complex problem. Some assert that 
they are the most significant threat faced by organizations today. High- 
profile insider threat cases, such as those conducted by people who stole 
and passed proprietary and classified information to WikiLeaks, certainly 
support that assertion, and demonstrate the danger posed by insiders in 
both government and private industry.2
Unfortunately, insider threats cannot be mitigated solely through hard-
ware and software solutions. There is no “silver bullet” for stopping insider 
threats. Furthermore, malicious insiders go to work every day and bypass 
both physical and electronic security measures. They have legitimate, 
authorized access to your most confidential, valuable information and sys-
tems, and they can use that legitimate access to perform criminal activity. 
You have to trust them; it is not practical to watch everything each of your 
employees does every day. The key to successfully mitigating these threats 
is to turn those advantages for the malicious insiders into advantages for 
you. This book will help you to do just that. 
In 2001, shortly before September 11, the Secret Service sponsored the 
Insider Threat Study, a joint project conducted by the Secret Service and 
the Software Engineering Institute CERT Program at Carnegie Mellon 
 University. We never dreamed when we started that study that it would 
have such far-reaching impacts, and that we would become so passionate 
about the subject that we would end up devoting more than a decade (to 
date!) of our careers to the problem. 
2. For information regarding the WikiLeaks insider threat cases, see http://en.wikipedia.org/wiki/
Wikileaks.

Free ebooks ==>   www.Ebook777.com
xix
Preface
When we started our work on the insider threat problem, very little was 
known about insider attacks: Who commits them, why do they do it, when 
and where do they do it, and how do they set up and carry out their crimes? 
After delving deep into the issue, we are happy to say that we now know 
the answers to those questions. In addition, we have come a long way in 
designing mitigation strategies for preventing, detecting, and responding 
to those threats. 
We have the largest collection of detailed insider threat case files that we 
know of in the world. At the time of this publication, we had more than 
700 cases, and that number grows weekly. We’ve had the opportunity to 
interview many of the victims of these crimes, giving us a unique chance to 
find out from supervisors and coworkers how the insider behaved at work, 
what precipitating events occurred, what technical controls were in place 
at the time, what policies and procedures were in place but not followed, 
and so on. We’ve also had the unique opportunity to actually interview 
convicted insiders and ask them probing questions about what made them 
do it, what might have made them change their mind, and what technical 
measures should have been in place to prevent this from happening. 
We have a comprehensive database—the CERT insider threat database—
where we track the technical, behavioral, and organizational details of every 
crime. We have combined our technical expertise in the CERT Insider Threat 
Center with psychological expertise from federal law enforcement, the U.S. 
Department of Defense (DOD), and our own independent consultants to 
ensure that we consider the “big picture” of the problem, not just the techni-
cal details. We have created “crime models” or “crime profiles” that describe 
the patterns in the crimes so that you can recognize an escalating insider 
threat problem in your own organization. We have created an insider threat 
lab where we are developing new technical solutions based on our mod-
els. We created an insider threat vulnerability assessment based on all of the 
cases in the CERT database so that you can learn from past mistakes and not 
suffer the same consequences as previous victim organizations. We publish 
best practices for mitigating insider threats, hold workshops, and conduct 
technical exercises for incident responders. Finally, we continue to collect 
new cases of malicious insider compromises to track the changing face of 
the threat.
We have been publishing our work for the past ten years; now we’ve 
decided that for the tenth anniversary of the start of our work, it is appro-
priate to pull all of our most current information into a book. This book 
provides a comprehensive reference for our entire body of knowledge on 
insider threats. 
www.Ebook777.com

xx
Preface
Scope of the Book: What Is and Is Not Included
Let’s begin by defining what we mean by malicious insider threats:
A malicious insider threat is a current or former employee, contractor, or 
business partner who has or had authorized access to an organization’s 
network, system, or data and intentionally exceeded or misused that 
access in a manner that negatively affected the confidentiality, integrity, or 
availability of the organization’s information or information systems.
There are a few important items to note. First of all, malicious insider 
threats are not only employees.3 We chose to include contractors in our 
definition because contractors often are granted authorized access to their 
clients’ information, systems, and networks, and the nontechnical controls 
for contractors are often much more lax than for employees. Interestingly, 
we did not include business partners in our original definition of insider 
threats in 2001. However, over time we found that more and more crimes 
involved not employees or contractors, but trusted business partners who 
had authorized access to the organization’s systems, networks, or informa-
tion. We encountered cases involving outsourcing, offshoring, and, more 
recently, cloud computing. These cases raise complex insider threat risks 
that should not be overlooked; therefore, we decided to add business part-
ners to our definition.
Second, note that malicious insider attacks do not only come from current 
employees. In fact, one particular type of crime, insider IT sabotage, is more 
often committed by former employees than current employees.
Now that we have explained whom we will discuss in the book, let’s focus 
on what types of crimes we will examine. Before we describe the types of 
crimes, it is important that you understand why we categorized them the 
way we have. Much of the success in our work is due to the identification 
of patterns found in the insider threat cases. These patterns describe the 
“story” behind the cases. Who commits these crimes? Why? Are there signs 
that they might commit a crime beforehand, so-called observable behaviors, 
in the workplace? When do they do it, where, and do they do it alone or 
with  others? 
The important thing to remember is that the patterns are different for each 
type of crime. There is not one single pattern for insider threats in general. 
3. Henceforth, for simplicity, reference to insider threats specifically means malicious insider threats 
unless otherwise specified.

xxi
Preface
Instead, we have identified three models, or profiles, for insider threats. 
Those three types of crimes are as follows.
• IT sabotage: An insider’s use of information technology (IT) to direct 
specific harm at an organization or an individual. 
• Theft of intellectual property (IP): An insider’s use of IT to steal 
intellectual property from the organization. This category includes 
industrial espionage involving insiders.
• Fraud: An insider’s use of IT for the unauthorized modification, addi-
tion, or deletion of an organization’s data (not programs or systems) 
for personal gain, or theft of information that leads to an identity crime 
(e.g., identity theft, credit card fraud).
Note that this book does not specifically describe national security 
 espionage crimes: the act of obtaining, delivering, transmitting, communi-
cating, or receiving information about the national defense with an intent, 
or reason to believe, that the information may be used to the injury of the 
United States or to the advantage of any foreign nation. Espionage is a vio-
lation of 18 United States Code sections 792–798 and Article 106, Uniform 
Code of Military Justice.4 The CERT Insider Threat Center does work in 
that area, but that research is only available to a limited audience. How-
ever, there are many similarities between national security espionage and 
all three types of crimes: fraud, theft of intellectual property, and IT sabo-
tage. Therefore, we believe there are many lessons to be learned from these 
insider incidents that can be applied to national security espionage as well. 
In addition, this book deals primarily with malicious insider threats. We 
certainly recognize the importance of unintentional insider threats— 
insiders who accidentally affect the confidentiality, availability, or integrity 
of an organization’s information or information systems, possibly by being 
tricked by an outsider’s use of social engineering. However, we only 
recently began researching those types of threats; intentional attacks have 
kept us extremely busy for the past ten years! In addition, we believe 
that many of the mitigation strategies we advocate for malicious insid-
ers could also be effective against unintentional incidents, as well as those 
perpetrated by outsiders. And finally, it is difficult to gather information 
regarding unintentional insider threats; because no crime was committed, 
organizations tend to handle these incidents quietly, internal to the organi-
zation, if possible. 
4. Dictionary of Military and Associated Terms. U.S. Department of Defense, 2005.

xxii
Preface
Finally, we use many case examples from the CERT database  throughout 
the book. Some of the examples go into greater detail than others; we 
include only the details that serve to illustrate the point we are making 
in that part in the book. We also have included a large collection of case 
examples in  Chapter 8, as we believe these will be of great interest to many 
of you. Again, we stress that you should use that chapter to examine your 
organization and decide if you need to take any proactive measures to 
ensure that you do not fall victim to the same types of  incidents. 
As a matter of policy, we never identify the organizations or insid-
ers involved in our case examples. Some, however, may be apparent 
to readers, inasmuch as they are drawn from public records, including 
court documents and newspaper accounts. For examples not in the pub-
lic domain, we have further masked the targeted organizations to shield 
their identities.
Intended Audience
A common misconception is that insider threat risk management is 
the responsibility of IT and information security staff members alone. 
 Unfortunately, that is one of the biggest reasons that insider attacks con-
tinue to occur, repeating the same patterns we have observed in cases since 
1996, the earliest cases in the CERT database. IT and information security 
personnel will benefit from reading this book, as we will suggest new 
 technical controls you can implement using technology you are already 
using in the workplace. In addition, this book can be used by technical 
staffs to motivate other stakeholders within their organization, since IT and 
information security cannot successfully implement an effective insider 
threat mitigation strategy on their own. 
We wrote this book with a diverse audience in mind. The ideal audience 
includes top management, as their support will be needed to implement 
the organization-wide insider threat policies, procedures, and technologies 
we recommend. It is important that all managers understand the patterns 
they need to recognize in their employees, and to advocate up the manage-
ment chain for support for an insider threat program. 
For the same reasons, government leaders will benefit from this book, 
since they need to support the government-wide insider threat policies, 
 procedures, and technologies we recommend.

xxiii
Preface
Human resources personnel need to understand this book, as they are 
often the only ones who are aware of indicators of potential increased 
risk of insider threats in individual employees. Other staff members who 
should  understand this information include security, software engineering, 
and physical security personnel, as well as data owners. It is also essen-
tial to include your general counsel in any discussions about implementing 
technical and nontechnical controls to combat the insider threat, to ensure 
compliance with federal, state, and local laws.
In summary, an effective insider threat program requires understanding, 
collaboration, and buy-in from across your organization. 
Reader Benefits
After reading this book you will realize that the insider threat is real and 
the consequences of malicious insider activities can be extremely damag-
ing. Real-life case studies will drive home the point that “this could happen 
to me.” Many organizations focus their technical defenses against outsid-
ers attempting to gain unauthorized access. This book emphasizes the need 
to balance defense against outsider threats with defense against insider 
threats, understanding that insider attacks can be more damaging than out-
sider attacks.
After reading this book you also will be able to recognize the high-level 
patterns in the three primary types of insider threats: IT sabotage, theft 
of intellectual property, and fraud. In addition, you will understand the 
details of how insiders commit those crimes. We present concrete defensive 
countermeasures that will help you to defend against insider attacks. You 
can compare your own defensive strategies to the controls we propose and 
determine whether your existing controls are sufficient to prevent, detect, 
and respond to insider attacks like those presented throughout the book. 
Once you identify gaps in your defensive posture, you can implement 
countermeasures we propose to fill those gaps.
Structure of the Book: Recommendations to Readers
We begin the book in Chapter 1, Overview, by describing the insider threat 
problem, and raise awareness to the complexity of the problem— tangential 
issues such as insider threats from trusted business partners,  malicious 

xxiv
Preface
insiders with ties to the Internet underground, and programming 
 techniques used as an insider attack tool. Next, we provide a breakdown 
of the crimes in the CERT database, followed by an overview of the CERT 
Insider Threat Center. Because our crime “profiles” or “models” have had 
such an impact on the understanding of insider threats, we also provide a 
short section describing why those models are so important. We end with 
a brief timeline of the evolution of our body of work in the CERT Insider 
Threat Center. 
It is important that you read the first chapter so that you understand the 
concepts and terminology used throughout the remainder of the book. 
After that, you can use the book in various ways. If the first chapter has 
been an eye-opener for you and you are interested in gaining a compre-
hensive understanding of insider threats, continue reading the book from 
beginning to end. However, it is not necessary to read the book in that man-
ner; it is designed such that Chapters 2 through 9 and the appendices can 
be used as stand-alone references. 
Chapters 2, 3, and 4 are devoted to the three types of insider threats: insider 
IT sabotage, theft of intellectual property, and fraud. In each chapter we 
describe who commits the crime so that you know which positions within 
your organization pose that particular type of threat. We describe the pat-
terns in how each type of crime evolves over time: What motivates the 
insider, what behavioral indicators are prevalent, how do they set up and 
carry out the crime, when do they do it, whether others are involved, and 
so on. We also suggest mitigation strategies throughout each chapter. 
We recommend that everyone reads Chapter 2, Insider IT Sabotage, as that 
crime has occurred in organizations in every critical infrastructure sector. 
Most organizations have some type of intellectual property that must be 
protected: strategic or business plans, engineering or scientific information, 
source code, and so on. Therefore, it is important that you read Chapter 3, 
Insider Theft of Intellectual Property, so that you fully understand who 
inside your organization poses a threat to that information. 
Chapter 4, Insider Fraud, is applicable to you if you have information or 
systems that your employees could use to make extra money on the side. 
Credit card information and Personally Identifiable Information (PII) such 
as Social Security numbers are valuable for committing various types of 
fraud. However, it is also important that you also consider threats posed 
by insiders modifying information for financial gain. Do you have systems 
that outsiders would be willing to pay your employees to manipulate? Or 

xxv
Preface
do you have systems that your employees could illicitly use for personal 
financial gain, perhaps by colluding with other employees? If so, Chapter 4 
is applicable to you. Note that Chapter 4 also describes the insider threats 
in the CERT database involving organized crime, as all of those crimes 
were fraud.
Chapter 5, Insider Threat Issues in the Software Development Life Cycle, 
explores said issues. The Software Development Life Cycle (SDLC) is syn-
onymous with “software process” as well as “software engineering”; it is 
a structured methodology used in the development of software products 
and packages. This methodology is used from the conception phase to the 
delivery and end of life of a final software product.5 We explore each phase 
of the SDLC and the types of insider threats that need to be considered 
at each phase. In addition, we describe how oversights at various phases 
have resulted in system vulnerabilities that have enabled insider threats 
to be carried out later by others, often by end users of the system. If your 
organization develops software, you should carefully consider the lessons 
learned in this chapter. It should make you look differently at the entire 
SDLC: from how to consider potential insider threats in the requirements 
and design phases, to potential threats posed by developers in the imple-
mentation and maintenance phases.
If you are looking for information on mitigation strategies, go to  Chapters 6 
and 7. You can use Chapter 6, Best Practices for the Prevention and Detection 
of Insider Threats, to compare best practices for prevention and detection 
of insider threats to your organization’s practices. Many of the best prac-
tices were described in previous chapters, but Chapter 6  summarizes all 
of the suggestions in a stand-alone reference. This chapter is based on our 
“Common Sense Guide to Prevention and Detection of Insider Threats,” 
for years one of the top downloads on the entire CERT Web site. 
If you are in a technical security role and would like more detailed infor-
mation on new controls you can implement, you should read Chapter 7, 
Technical Insider Threat Controls. This chapter describes the technical solu-
tions we have developed in the CERT insider threat lab. These technical 
solutions are based on technologies that you most likely are already using 
for technical security. We provide new signatures, rules, and configurations 
for using them for more effective detection of insider threats. 
5. Whatis.com

xxvi
Preface
Chapter 8, Case Examples, contains a collection of case examples from the 
CERT database. We provide a summary table at the beginning of the chapter 
so that you can reference specific cases by type of crime, sector of the orga-
nization, and brief summary of the crime. Many people have requested this 
type of information from us over the years, so we believe this will provide 
enormous value to many of you. We highly recommend that you review 
these cases and consider your vulnerability to the same type of malicious 
actions within your organization. Chapter 8 is also of value to researchers 
who might want to use case examples for their own research. 
Chapter 9, Conclusion and Miscellaneous Issues, contains a final collec-
tion of miscellaneous information that didn’t fit anywhere else in the book. 
For example, we provide an analysis of insiders with connections to the 
Internet underground. We also provide details on insiders who attacked 
not their own organization, but trusted business partners that had a formal 
relationship with their employer. 
After the chapters, we provide a series of appendices. 
Appendix A, Insider Threat Center Products and Services, contains infor-
mation on products and services provided by the CERT Insider Threat 
Center, including insider threat assessments, workshops, online exercises, 
and technical controls. We also discuss sponsored research opportunities 
for the Insider Threat Center. If you are extremely concerned about insider 
threats and want immediate assistance from the CERT Program, be sure to 
read this appendix.
Appendix B, Deeper Dive into the Data, contains interesting data mined 
from the CERT database.
Appendix C, CyberSecurity Watch Survey, contains data collected from the 
CyberSecurity Watch Survey, an annual survey we conduct in conjunction 
with CSO Magazine and the Secret Service.6
Appendix D, Insider Threat Database Structure, contains the database 
structure for the CERT database. If you are interested in exactly what kind 
of data we track for each case, you should read this appendix. Also, we 
frequently respond to queries to mine the CERT database for interesting 
data—if you see a field or fields you would like us to explore with you, 
please contact us. We can be reached via email at insider-threat-feedback@
cert.org. 
Appendix E, Insider Threat Training Simulation: MERIT InterActive, 
 contains detailed information about an interactive virtual simulation we 
6. Note that in some years Deloitte and Microsoft also participated in the survey.

xxvii
Preface
developed for insider threat training. It is basically a prototype of a video 
game for insider threat training. What do you need for a successful video 
game? Good guys playing against the bad guys, complex plots, interesting 
characters—that’s insider threat! We didn’t want to distract you with that 
information in the body of the book, but some of you might find it interest-
ing, so we included it in this appendix. In addition, if you are interested in 
new and innovative training methods, this appendix should be of interest. 
Appendix F, System Dynamics Background, provides background informa-
tion on system dynamics.7 We provide brief references to system dynamics 
throughout the book, but it is not necessary that you understand system 
dynamics when you read the book. Nonetheless, we wanted to provide 
more in-depth information for those of you who wish to learn more. 
Finally, the book concludes with references, a glossary, and a complete 
index.
Note that the accompanying Web site, www.cert.org/insider_threat, con-
tains our system dynamics models for use by other researchers. It is also 
updated regularly with new insider threat controls, best practices, and case 
examples. 
In summary, the book is intended to be a reference for many different types 
of readers. It contains the entire CERT Insider Threat Center body of knowl-
edge on insider threats, and therefore can be used as a reference for raising 
awareness, informing your risk management processes, designing and 
implementing new technical and nontechnical controls, and much more. 
About the CERT Program
The CERT Program is part of the Software Engineering Institute (SEI), a 
federally funded research and development center at Carnegie Mellon 
 University in Pittsburgh. Following the Morris worm incident, which 
brought 10% of Internet systems to a halt in November 1988, the Defense 
Advanced Research Projects Agency (DARPA) charged the SEI with setting 
up a center to coordinate communication among experts during security 
emergencies and to help prevent future incidents. This center was named 
the CERT Coordination Center (CERT/CC).
7. “System dynamics is a computer-aided approach to policy analysis and design. It applies to dynamic 
problems arising in complex social, managerial, economic, or ecological systems—literally any dynamic 
systems characterized by interdependence, mutual interaction, information feedback, and circular cau-
sality” (www.systemdynamics.org/what_is_system_dynamics.html).

xxviii Preface
While we continue to respond to major security incidents and analyze 
product vulnerabilities, our role has expanded over the years. Along 
with the rapid increase in the size of the Internet and its use for critical 
functions, there have been progressive changes in intrusion techniques, 
increased amounts of damage, increased difficulty of detecting an attack, 
and increased difficulty of catching the attackers. To better manage these 
changes, the CERT/CC is now part of the larger CERT Program, which 
develops and promotes the use of appropriate technology and systems 
management practices to resist attacks on networked systems, to limit 
damage, and to ensure continuity of critical services. 
The CERT Insider Threat Center
The objective of the CERT Insider Threat Center is to assist organizations 
in preventing, detecting, and responding to insider compromises. We have 
been researching this problem since 2001 in partnership with the DOD, 
the U.S. Department of Homeland Security (DHS), other federal agencies, 
federal law enforcement, the intelligence community, private industry, 
academia, and the vendor community. The foundation of our work is 
the CERT database of more than 700 insider threat cases. We use system 
dynamics modeling to characterize the nature of the insider threat prob-
lem, explore dynamic indicators of insider threat risk, and identify and 
experiment with administrative and technical controls for insider threat 
mitigation. The CERT insider threat lab provides a foundation to iden-
tify, tune, and package technical controls as an extension of our modeling 
efforts. We have developed an assessment framework based on the fraud, 
theft of intellectual property, and IT sabotage case data that we have used 
to assist organizations in identifying their technical and nontechnical vul-
nerabilities to insider threats, as well as executable countermeasures. The 
CERT Insider Threat Center is uniquely positioned as a trusted broker to 
assist the community in the short term, and through our ongoing research. 
Dawn Cappelli and Andy Moore have been working on CERT insider 
threat research since 2001, and Randy Trzeciak joined the team in 2006. 
Dawn is the technical manager of the CERT Insider Threat Center, Andy 
is the lead researcher, and Randy is the technical lead for insider threat 
research. Although our insider threat team has now grown into an official 
Insider Threat Center, for many years the CERT Program’s insider threat 
team consisted of Andy, Randy, and Dawn, which is why we decided to 
team up and capture our history in this book.

xxix
Preface
Summary
The purpose of this book is to raise awareness of the insider threat issue 
from the ground up: staff members in IT, information security, and human 
resources; data owners; and physical security, software engineering, 
legal, and other security personnel. We strongly believe after studying 
this problem for more than a decade that in order to effectively mitigate 
insider threats it takes common understanding, support, and commu-
nication from all of those people across the organization. In addition, 
buy-in is needed from upper management, as they will need to support 
the cross-organizational communication required to formulate an effective 
mitigation strategy. And finally, it requires awareness and consideration by 
government leaders, as some of the issues are even larger than individual 
organizations. Employee privacy issues and mergers and acquisitions with 
organizations outside the United States are two such examples. 
This book covers our extensive work in studying insider IT sabotage, theft 
of intellectual property, and fraud. Although it does not deal explicitly with 
insiders who committed national security espionage, many of the lessons 
in this book are directly applicable to that domain as well. 
Most of the book can be read and easily understood by technical and non-
technical readers alike. The only exception is Chapter 7. If you are not a 
“technical” person you are best off skipping this chapter. However, we 
strongly suggest you lend the book to your technical security staff so that 
they can consider implementing these controls. 
Now that you understand the purpose of the book and its contents, we will 
begin to dig a little deeper into each type of insider crime, our modeling of 
insider threats, and the CERT Insider Threat Center in Chapter 1. We rec-
ommend that you read that chapter next so that you understand the basic 
concepts. After completing Chapter 1 you will have the foundation you 
need so that you can explore the rest of the book in any order you wish!

This page intentionally left blank 

xxxi
Acknowledgments
We would like to start by thanking our amazing team at the CERT Insider 
Threat Center. This book represents the hard work of many  brilliant peo-
ple. First, thank you to our current team in the Insider Threat Center, listed 
here in the order in which they joined the team: Adam Cummings, Mike 
Hanley, Derrick Spooner, Chris King, Joji Montelibano, Cindy Nesta, Josh 
Burns, George Silowash, and Dr. Bill Claycomb. And a special thank you to 
Tara Sparacino and Cindy Walpole, who helped us to keep our heads above 
water at work while we wrote this book in our “spare time.” The CERT 
Insider Threat Center is part of the Enterprise Threat and  Vulnerability 
Management (ETVM) team in the CERT Program. The ETVM team is 
a very tight-knit group, and we would be remiss if we did not acknowl-
edge these awesome, dedicated technical security experts, again listed in 
the order in which they started on the team: Georgia Killcrece (retired, but 
sorely missed!), Robin Ruefle, Mark Zajicek, David Mundie, Becky Cooper, 
Charlie Ryan, Russ Griffin, Sandi Behrens, Alex Nicoll, Sam Perl, and Kristi 
Keeler. 
Thank you to the current and former CMU/SEI/CERT staff members 
who have participated in our insider threat work over the years: Chris 
 Bateman, Sally Cunningham, Casey Dunlevy, Rob Floodeen, Carly Huth, 
Dr. Joseph (“Jay”) Kadane, Greg Longo, David McIntire, David Mundie, 
Dr. Dan Phelps, Stephanie Rogers, Dr. Greg Shannon, Dr. Tim Shimeall, 
 Rhiannon Weaver, Pam Williams, Bradford Willke, and Mark Zajicek. And 
a special thank you to Dr. Tom Longstaff, who was the CERT technical 
manager for the original Insider Threat Study, and worked on the CERT 
Program’s original insider threat collaboration with the U.S. Department of 
Defense (DOD) Personnel Security Research Center. 
Thank you to the many fabulous graduate students who have worked on 
our insider threat projects throughout the years, starting with our two cur-
rent students: Todd Lewellen, Lynda Pillage, Jen Stanley, Chase Midler, 
Andrew Santell, Luke Hogan, Jaime Tupino, Tyler Dean, Will  Schroeder, 

xxxii
Acknowledgments
Matt Houy, Bob Weiland, Devon Rollins, Tom Caron, John Wyrick, 
 Christopher Nguyen, Hannah Joseph, and Akash Desai. Many of those stu-
dents were from the Scholarship for Service Program—we commend the 
U.S. federal government for this program, which produces the most out-
standing talent in the cybersecurity field. 
A special thank you to Dr. Eric Shaw, who has been a Visiting Scientist in 
the CERT Program and a clinical psychologist at Consulting &  Clinical 
 Psychology, Ltd. Eric has been the guiding force in the psychological 
aspects of our research since the conclusion of our first Insider Threat Study 
with the Secret Service National Threat Assessment Center. 
Thank you to Noopur Davis, Claude Williams, and Dr. Marvine Hamner, 
who worked for us as visiting scientists. 
Thank you to the CERT Program’s director, Rich Pethia, and deputy direc-
tor, Bill Wilson, who have given us the autonomy and authority over the 
past decade to take our research in so many exciting directions. Thank you 
to our retired boss, Dr. Barbara Laswell, who helped us evolve from the 
Insider Threat Team of three people into the CERT Insider Threat Center. 
Thank you to SEI Director Dr. Paul Neilson and Deputy Director Clyde 
Chittister, for their support and recognition. We’re extremely grateful to 
Terry Roberts for the visibility she has brought to our work. And thank you 
to Dr. Angel Jordan, former provost of Carnegie Mellon University, who 
has been an advocate for our work over the years. 
We would like to thank the Secret Service, our original partner in this quest 
to understand and help organizations protect themselves from malicious 
insider attacks. Thank you to National Threat Assessment Center (NTAC) 
staff members who participated on the project, especially research coordi-
nator Dr. Marisa Reddy Randazzo, who founded and directed the Insider 
Threat Study within NTAC; Dr. Michelle Keeney, who took over when 
Marisa left; Eileen Kowalski, who was the lynchpin throughout the project; 
and Matt Doherty, the Special Agent in Charge of NTAC. Also, thank you 
to Jim Savage, the sponsor of our original work with the Secret  Service. 
Finally, a big thank you to our Secret Service liaisons for the Insider Threat 
Study, who moved to Pittsburgh and joined the CERT Program for a few 
years: Cornelius Tate, Dave Iacovetti, and Wayne Peterson. What great 
times we had in those good old days! And thank you to our current Secret 
Service liaisons, Tom Dover and Ryan Moore. 
A special thank you to Dr. Douglas Maughan and the DHS Science and 
Technology (S&T) Directorate, who took over funding of the original 
CERT/Secret Service Insider Threat Study shortly after DHS was formed. 

xxxiii
Acknowledgments
We’re especially excited that Doug came back to us last year and told us he 
wanted to get the old team back together—and funded our current study of 
insider threats in the financial sector. In addition, we’re receiving assistance 
on that project from the Secret Service, U.S. Department of the Treasury, 
and the financial sector. Thank you to Brian Peretti, who was in the very 
first financial sector review of our work for the original study, and is now 
back on the team in our current fraud project. And thank you to Ed Cabrera 
and Trae McAbee from the Secret Service—we could not possibly succeed 
in the current study without all of your hard work in gathering all of the 
case files and scheduling the interviews. Thank you to Pablo Martinez for 
being a strong supporter of our work, starting back in the original study, 
and continuing today. 
Thank you to the Army Research Office and Carnegie Mellon CyLab, espe-
cially Dr. Pradeep Khosla, Dr. Virgil Gligor, Dr. Adrian Perrig, Richard 
Power, Gene Hambrick, and Dr. Don McGillen, who provided seed funding 
for many of our insider threat projects that have grown into full bodies of 
work. Your support sustained the insider threat database for years, enabled 
us to experiment with our modeling work, provided the infrastructure 
for the insider threat lab, and funded one of our most “fun” projects: our 
insider threat “video game.” 
We are especially grateful to our current sponsors at the U.S. DHS  Federal 
Network Security (FNS) branch, Matt Coos and Don Benack, as well as the 
project leads, Rob Karas, Sean McAfee, and Will Harmon. Don and Matt 
had the vision to step up to the plate three years ago and fund our work 
“for the good of all.” They realized the importance of our work and were 
willing to fund it before insider threats became a top-priority issue in the 
current cybersecurity environment. Thanks to their foresight, we can offer 
technical controls, assessments, and training to the community. We’re 
excited about the opportunity to continue to make an impact together!
We are also thankful to our sponsors and collaborators in the DOD and 
intelligence community: Dr. Deborah Loftis, Laura Sellers, Dr. Stephen 
R. Band, Dr. Aaron J. Ferguson, Dr. Lynn Fischer, Dr. Howard Timm, 
Dr.  Katherine Herbig, Dr. Ron Dodge, and Dr. Kirk Kennedy. Their exper-
tise and experience have enabled a much richer treatment of the insider 
threat problem than would have otherwise been possible.
Our work in the system dynamics modeling of insider threats began 
and continues to be influenced by the Security Dynamics Network 
(SDN), a largely unfunded and loosely coordinated group of national 
 laboratories and universities applying system dynamics to explore issues 

Free ebooks ==>   www.Ebook777.com
xxxiv Acknowledgments
of  cybersecurity. In the past, the group has focused on malicious insider 
threats and has been a source of expertise, information, and inspiration for 
the insider threat models developed in this book. We are very thankful to 
the members of the SDN, especially its founder, Dr. Jose Gonzalez of Agder 
University College; Dr. David Andersen and Dr. Eliot Rich of the University 
at Albany; Dr. Ignacio Martinez-Moyano of Argonne National Laboratory; 
Dr. Stephen Conrad of Sandia National Laboratories; and Dr. Jose Maria 
Sarriegui of the University of Navarra. A special thank you goes to Dr. Elise 
Weaver of the Human Resources Research Organization, who worked with 
us as a Visiting Scientist at the CERT Program and assisted us in our very 
first system dynamics modeling efforts. 
We would also like to thank all of the SEI business development staff mem-
bers who have helped us with our insider threat work over the years: Jan 
Philpot, Mike Greenwood, Joe McLeod, Frank Redner, David Ulicne, Bob 
Rosenstein, Greg Such, Dave Scherb, and Angela Llamas-Butler. Thank you 
to Summer Fowler and Lisa Marino, who have helped us with project man-
agement activities that have become increasingly complex over the years, 
and Michele Tomasic, who has helped us with so many things over the 
years. Thank you to Bill Shore and everyone in the SEI Security Office, and 
Dave Thompson and everyone in SEI IT, especially Jerry Czerwinski and 
Craig Lewis; and thank you to Linda Pesante and her staff, especially Ed 
Desautels and Paul Ruggerio, who have helped us with editing and techni-
cal writing over the years. Also, thank you to David Biber for the wonderful 
graphics he has created for us over the years, including nice crisp images 
for this book!
Finally, we would like to thank Dr. Don Marinelli, cofounder of Carnegie 
Mellon’s Entertainment Technology Center (ETC), and the ETC faculty 
and students who worked with us to create the first video game for insider 
threat training. Semester 1: faculty advisors Dr. Scott Stevens and Jessica 
Trybus; student team Ankur Ahlawat, Chris Daniel, Aditya Dave, and 
Todd Waits; and visiting scholars Soo Jeoung Kim and Michelle Macau. 
Semester 2: faculty advisors Dr. Scott Stevens and Dr. Ralph Vituccio; and 
student team Stephen Calender, Julie Charles, Evan Miller, and Todd Waits. 
We still hope to interest a sponsor in turning that prototype into an opera-
tional system someday! 
If we forgot someone who has helped us throughout the years, we apolo-
gize profusely! We tried hard to include everyone, but if we overlooked 
you, please let us know.
www.Ebook777.com

xxxv
Acknowledgments
From Dawn: Thank you to my wonderful husband and soul mate, 
Fred—you’ve been inspiring me for 35 years and without you I can’t 
imagine where I would be! To my daughter and best girlfriend, Alyssa—I 
treasure all of our fun times together. To my son, Anthony—you are truly 
the happiest person I know! Thanks to my sister, Cindy, who has always 
been there for me. And finally, thank you to the greatest parents in the 
world—whom I miss terribly. Your faith and encouragement made me 
what I am today. 
Thank you to Andy and Randy—how exciting to accomplish this together 
after all of those years as team “Andy, Randy, and Dawn!”
From Andy: My heartfelt thanks go, most of all, to my beautiful wife, 
Susan, for sharing our life adventure. Coming home to you each day is the 
best thing in my life! And thanks to my incredible son, Eric, who put up 
with my having my nose in a laptop during many early morning hours. 
Your achievements continue to amaze me and your love and friendship 
enrich our lives immeasurably. Finally, thanks to Dawn and Randy’s stead-
fast dedication and friendship. It is hard to believe how far we’ve come in 
the ten years since it all started.
From Randy: Thank you, Marianne, for being my wife and best friend! You 
are truly a blessing to me, to our family, and to all the other lives you touch. 
To my daughter, Abbie, you are an amazing, intelligent, and strong young 
lady. To Nate the Great, always keep those around you laughing. To Luke, 
thank you for making every day fun. Thank you to my parents for all of the 
hard work and sacrifices you made over the years! 
Finally, thank you to Dawn and Andy for bringing me into the circle of 
trust. It is truly a pleasure working with both of you!

This page intentionally left blank 

1
Chapter  1
Overview
Insiders pose a substantial threat due to their knowledge of and access to 
their employers’ systems and/or information. They bypass physical and 
electronic security measures through legitimate means every day. There is 
no demographic profile of a malicious insider—they are men and women, 
married  and  single,  young  and  old,  and  cover  a  range  of  ethnicities. 
 However, we have identified some distinct characteristics of insiders and 
their crimes, which can be used in designing mitigation strategies.
Insider  IT  sabotage  is  typically  committed  by  technical  users  with 
 privileged access, such as system administrators, database  administrators, 
and programmers. The motivation in these crimes is usually revenge for 
a negative workplace event, and the crimes are often set up while still 
employed, but executed following termination.
Insider theft of intellectual property (IP) is usually committed by  scientists, 
engineers,  programmers,  and  salespeople.  These  insiders  usually  steal 
the information they worked on, and take it with them as they leave the 
 organization to start their own business, take with them to a new job, or 
give to a foreign government or organization.
Insider fraud is usually committed by lower-level employees such as help 
desk, customer service, and data entry clerks. The crimes are motivated 
by financial need or greed, and they typically continue for a long period 
of time. Many of these insiders are recruited by outsiders to steal informa-
tion. Collusion with other insiders is very common in crimes involving 
modification of information for payment from the outside.

Chapter 1.  Overview
2
In this chapter, we begin with true stories of insider attacks, which will 
help you to understand the different types of insider crimes as well as the 
potential consequences. We believe that the more actual cases you read, the 
more you will come to understand the patterns in the cases.
Next, we point out the expanding complexity of insider threats. Although 
we have broken the problem into three distinct crime profiles, and most 
incidents resemble those profiles, there are some complex issues that we 
must point out so you understand the scope of the problem. In this chap-
ter we simply want to raise the issues so that you keep them in mind as 
you read the rest of the book. In Chapter 9, Conclusion and  Miscellaneous 
Issues, we provide more detail on each of these issues.
The next section contains a breakdown of the cases in our insider threat 
database. Our database of more than 700 insider threat cases provides 
an  unmatched  wealth  of  information  that  can  be  useful  to  all  of  you 
in   understanding  insider  threats  and  in  designing  mitigation  strate-
gies. If you are interested in additional details from our database, refer 
to   Appendix  B,  Deeper  Dive  into  the  Data.  In  addition,  Appendix  C, 
 CyberSecurity Watch Survey, contains detailed findings from the Cyber-
Security  Watch  Survey,  which  we  conduct  annually  with  the  Secret 
Service and CSO Magazine.1
Next, we explain the importance of our crime profiles and associated crime 
models. Over the years, we have heard that the first impression of some 
practitioners is that they are not interested in “academic models.” The good 
news is that, although in some cases we started with complex academic 
models,  we  have  translated  them  into  straightforward,  practical  teach-
ing tools that have raised awareness and resulted in successful mitigation 
strategies for practitioners for years. Those high-level models are the ones 
we use in this book.
We end this chapter with a brief description of the objective and work of 
the CERT Insider Threat Center. If you don’t care where material in this 
book came from, you certainly can skip the end of this chapter and go on 
to Chapter 2, Insider IT Sabotage. However, some of you might feel better 
with a brief glimpse of the history of our research so that you deem the 
advice we give in the book to be trustworthy. We provide a brief timeline of 
the development of the Insider Threat Center in this chapter.
1.  Note that in some years Deloitte and Microsoft also participated in the survey.

Free ebooks ==>   www.Ebook777.com
3
True Stories of Insider Attacks
 
www.Ebook777.com

Chapter 1.  Overview
4
 

5
 

Chapter 1.  Overview
6
orders, quotes requested, and more. The next day, he received a formal 
employment offer. He sent an email accepting the offer, and included a 
copy of the program he had emailed to his home earlier. Next, he deleted 
the contents of his hard drive at work, thinking that would destroy the 
evidence of his crime, and turned in his resignation. After starting his new 
job a few days later, he continued to access the secure customer area of his 
previous employer’s Web site using the passwords he had stolen.
This case fits our profile of insider theft of intellectual property perfectly, 
as  you  will  see  in  Chapter  3,  Insider  Theft  of  Intellectual  Property.  In 
addition, it highlights a specific area of concern: passwords and account 
management.  It  is  well  known  that  an  employee’s  account  should  be 
disabled, and passwords for shared accounts should be changed imme-
diately  upon  termination.  This  case  points  out  other  types  of  shared 
accounts  that  could  be  easily  overlooked,  however:  Web  site  accounts, 
customer  accounts,  and  so  on.  Does  your  termination  process  include 
consideration of these types of accounts? Do you even have a comprehen-
sive list of the types of accounts that exist and need to be considered at 
termination? Based on our experience, it might be a good idea for you to 
double-check!
The Expanding Complexity of Insider Threats
As our work matured, we began to realize that the insider threat is much 
more complex than it appears on the surface. The expanding complexity of 
insider threats includes the issues outlined in Table 1-1.
Table 1-1  The Expanding Complexity of Insider Threats
Collusion with 
 Outsiders
Insiders can be recruited by or work for outsiders, 
including organized crime and foreign organizations or 
governments.
Business    
Partners
It is important to control and monitor access to your 
information and systems by “trusted” business partners.
Mergers and 
 Acquisitions
Consider heightened risk of insider threats when 
 organizations are merged or acquired.
Cultural 
 Differences
Behavioral indicators exhibited by malicious insiders 
who were born in different countries may differ.

7
Breakdown of Cases in the Insider Threat Database
Foreign 
 Allegiances
Organizations operating branches outside their own 
country must consider the insider threats posed by 
employees with allegiance to another country.
Internet 
 Underground
Some insiders seek technical assistance from the 
Internet underground. The Internet underground is 
a collection of individuals with shared goals where 
there is some degree of hierarchical structure and 
the  primary communication mechanism or agent of 
electronic crime involves the Internet. Further, it may 
demonstrate some degree of pseudoanonymity and/
or secrecy, which may be useful for organizing and 
 carrying out electronic crimes.
We will address these issues throughout the remainder of the book. For 
example, collusion with outsiders is a factor in fraud cases where stolen 
information  is  sold  to  outsiders  and  outsiders  often  recruit  insiders  to 
commit the crime, and in theft of IP cases in which information is stolen 
to benefit a foreign government or competitor. Those types of issues are 
explored in Chapter 3 and Chapter 4.
Trusted business partners have been the source of insider fraud, theft of 
intellectual  property,  and  IT  sabotage  committed  by  technical  contrac-
tors. Collusion with the Internet underground can significantly multiply 
the potential impact of an IT sabotage crime; therefore, countermeasures 
should be considered to prevent or detect suspicious communication in the 
workplace. These issues are covered in Chapter 9.
Mergers and acquisitions increase the risk of insider threats; therefore, we 
recommend you carefully consider all of the best practices in Chapter 6, 
Best Practices for the Prevention and Detection of Insider Threats, before 
embarking on that activity.
Cultural differences and foreign allegiance could influence the behavioral 
models presented in Chapter 2 and Chapter 3.
 

Free ebooks ==>   www.Ebook777.com
Chapter 1.  Overview
8
 
Figure 1-1  Breakdown of intentional insider crimes in the United States 
 (including national security espionage)
250
200
100
150
50
0
235
134
120
90
52
IT Sabotage
Fraud
Theft of IP
Misc.
Espionage
www.Ebook777.com

9
CERT’s MERIT Models of Insider Threats
product, including the backups, and took the only remaining copy with 
him. He then offered to restore the data for $50,000, which he believed to 
be the amount of severance to which he was entitled. He threatened to 
retaliate with massive legal and personal attacks if the company contacted 
law enforcement or its lawyers; however, he was arrested and convicted. 
Unfortunately, the company went out of business because the information, 
valued at up to $10 million, was never recovered.
The insider in that example stole the information (theft of intellectual prop-
erty) in order to harm the company (IT sabotage) and extorted money for 
its return (fraud). Therefore, it is important when considering the details 
of each type of crime as described in this book that some insiders carry out 
multiple types of crimes.
CERT’s MERIT Models of Insider Threats
MERIT stands for Management and Education of the Risk of Insider Threat. 
As part of the MERIT project we developed a series of models and asso-
ciated tools that evolved into the assessments, workshops, and technical 
solutions you will read about in the remainder of this book.
As you read this book, you will notice that we rely heavily on our insider 
threat models for designing the most effective mitigation strategies. Our 
insider threat database yields a wealth of information regarding the details 
of hundreds of insider crimes. It is quite useful to be able to determine the 
number of permanent employees versus contractors, the number of insid-
ers who constructed logic bombs,2 how many organizations experienced 
a reduction in force before an insider attack, and so on, directly from our 
database. However, because of the complexity of the insider threat issue, 
we feel that understanding the “big picture” of the problem is the key to 
success in overcoming it. The insider threat models help describe and com-
municate this big picture.
2.  Logic bomb: malicious code implanted on a target system and configured to execute after a desig-
nated period of time or on the occurrence of a specified system action.
MERIT stands for Management and Education of the Risk of Insider 
Threat.

Chapter 1.  Overview
10
The purpose of our models is to identify patterns in the evolution of the 
cases over time. In short, we focused on the story behind the cases, and 
developed models that tell that story in a way that you can understand 
and act on.
In short, we focused on the story behind the cases, and developed 
 models that tell that story in a way that you can understand and act on.
 
3.  Malicious code: intended to execute a malicious function. Also commonly referred to as malware.

11
CERT’s MERIT Models of Insider Threats
 production system and cause it to fail or disrupt operations? Do you do 
code reviews of every change to that system?
The good news is that by understanding our insider threat profiles, you 
will have a chance of preventing this from happening to you. This is an 
example of an IT sabotage attack, so please read Chapter 2 for mitigation 
strategies for this type of incident. You will learn that disgruntled techni-
cal employees who exhibit concerning behaviors in the workplace over an 
extended period of time should not be taken lightly. In addition, many of 
them set up their attack while still employed but execute the attack follow-
ing termination. Our mitigation strategies for insider IT sabotage are based 
on those patterns.
Why Not Just One Profile?
As  we  worked  on  the  Insider  Threat  Study  we  came  to  realize  that  all 
insider threats are not alike. However, we also realized that there appeared 
to be distinct similarities in how each type of insider crime evolved over 
time. Therefore, we chose one type of insider crime to profile first: insider 
IT  sabotage.  The  cases  of  insider  IT  sabotage  intrigued  us  because  they 
were among the  more technically sophisticated attacks examined in the 
study and resulted in substantial harm to people and organizations.
In performing the “big picture” analysis of insider IT sabotage, we first 
reviewed  all  insider  IT  sabotage  cases  to  identify  those  with  sufficient 
information for this type of analysis. We needed case files that contained 
details regarding why the insider attacked, what events surrounded the 
attack, what technical actions the insider took to set up and carry out the 
attack, what concerning behaviors did the insider exhibit at work prior to 
the attack, and so on. We discovered a very strong pattern that applied to 
almost every IT sabotage case in our database.
NOTe
Insider IT sabotage crimes have happened in every sector and no 
 organization should disregard this type of threat.
NOTe
It is important that you understand that the crime profiles and  associated 
models are very different for each type of insider threat. Who does it, 
when, why, how—these are very different for each of the three types of 
crimes: insider IT sabotage, theft of intellectual property, and fraud.

Chapter 1.  Overview
12
Next,  we  validated  those  patterns  against  the  data  in  our  database  and 
identified general observations about the majority of the cases, and then we 
were ready to create our models. We chose system dynamics modeling; we 
found that the system dynamics approach helped to structure and focus the 
team’s discussion. We used a group modeling approach with experts from 
both psychology and information security. Appendix F,  System Dynamics 
Background, contains a more in-depth discussion of system dynamics for 
readers who are interested in more details.
Our MERIT model of insider IT sabotage was published in 2008: The “Big 
Picture” of Insider IT Sabotage Across U.S. Critical Infrastructures [Moore 2008]. 
The information from that report is covered in Chapter 2. Our next insider 
threat model was for national security espionage and is not included in this 
book. In 2011 we published our MERIT model of insider theft of intellectual 
property, A Preliminary Model of Insider Theft of Intellectual Property [Moore 
2011a]. The information from that report is covered in Chapter 3.
We will soon be creating a fraud model as part of a current project with the 
Secret Service, the U.S. Department of Homeland Security (DHS) Science 
and Technology (S&T) Directorate, and U.S. Department of the Treasury. 
We have included a preliminary analysis of our fraud cases prior to that 
study in Chapter 4, which is being published in the CERT Research Annual 
Report [Moore 2011b].
Why Didn’t We Create a Single Insider Theft Model?
After the success of our insider IT sabotage model, we decided to create an 
insider theft model. We went through the same steps as before: We identi-
fied cases with rich information available, identified key elements in the 
cases,  and  then  attempted  to  identify  the  prevalent  patterns  in  a  group 
modeling session. However, in examining all of our theft cases, we found 
that there was not a strong pattern like the one we identified for the IT sab-
otage cases. Instead, we discovered two different patterns that seemed to 
be based on the type of information stolen.
We  realized  that  insiders  who  steal  information  that  is  used  to  commit 
identity theft or credit card fraud tend to be lower-level employees in the 
organization who find a way to make extra money on the side by stealing 
information. They usually sell the data to someone outside the organiza-
tion who actually uses the data to commit identity theft or credit card fraud. 
These tend to be long, ongoing schemes that continue until the insider is 
caught.

Free ebooks ==>   www.Ebook777.com
13
Overview of the CERT Insider Threat Center
The insiders who steal intellectual property are totally different! They tend 
to be engineers, scientists, programmers, and salespeople who steal infor-
mation as they are leaving the organization. Furthermore, they steal the 
information to take to their new employer, usually a competitor, or to start 
their own competing business.
Thus, we ended up creating the model for insider theft of intellectual prop-
erty, and the insider fraud model. Oh, but wait: There’s just a bit more!
As we explored the data further, we discovered more interesting patterns. 
First, we found that the insider theft of intellectual property crimes actually 
did fall into two overlapping groups: insiders who acted alone, and those 
who actually led a “ring” of insiders to steal the information. See Chapter 3 
for more details.
Second, we found that cases in which insiders modified information for 
financial gain fit the same model as the ones who stole information to com-
mit fraud; they were lower-level employees. They simply found a way to 
make extra money by modifying information rather than stealing it. For 
instance, they created fake driver’s licenses, modified criminal histories, 
or changed salaries. There are obviously differences in the technical meth-
ods used to steal versus modify information, but the other patterns in the 
crimes are the same. Therefore, our insider fraud model includes both types 
of crimes. See Chapter 4 for details.
Overview of the CERT Insider Threat Center
The  objective  of  the  CERT  Insider  Threat  Center  is  to  assist  organiza-
tions in preventing, detecting, and responding to insider compromises. 
 Figure 1-2 depicts the malicious insider at the start of the incident time-
line, and the damage at the end of the timeline. Our ultimate goal is to 
help you prevent the insider from attacking. However, if he should decide 
to  attack,  our  objective  is  to  provide  you  with  the  understanding  and 
solutions you need to detect the illicit activity as early in the timeline as 
possible.  Unfortunately,  some  malicious  insiders  will  succeed  in  their 
attack; in those cases we want to arm you with policies, practices, and 
technical measures so that you can respond to the attack as quickly as pos-
sible. Response measures include recovering from the attack, identifying 
the perpetrator, and implementing new measures for improved incident 
management in the future.
www.Ebook777.com

Chapter 1.  Overview
14
Figure 1-2 also illustrates how we hope to achieve those objectives: through 
detection of both technical and nontechnical indicators. If you learn only 
one thing from this book, let it be this: Insider threats cannot be prevented and 
detected with technology alone. Insiders use authorized access to the systems 
and information they access every day to carry out their attacks; therefore, 
automated detection based solely on online actions is extremely difficult if 
not impossible.
Figure 1-2  Objective of the CERT Insider Threat Center
HR, Legal, Physical
Nontechnical Indicators
Respond
Detect
Prevent
Timeline
Technical Indicators
Opportunities to prevent, detect, and respond to an insider attack
INSIDER
DAMAGE
If you learn only one thing from this book, let it be this: Insider threats 
 cannot be prevented and detected with technology alone.
 

15
Overview of the CERT Insider Threat Center
 
Figure 1-3  CERT Insider Threat 
 Center body of work
Research
Lab
Models
Database
Outreach
and
Transition
Figure 1-4  Information sharing in the 
CERT Insider Threat Center
Research
Lab
Models
Database
Outreach
and
Transition

Chapter 1.  Overview
16
policy and legal research and applies science-based approaches to analyze 
the efficacy of solutions developed in the lab. The lab tackles difficult prob-
lems uncovered by the Outreach and Transition Team doing assessments 
in the field. The Outreach and Transition Team gathers information about 
what is actually working and not working for practitioners and conveys 
those issues to the other teams, and so on.
Over the years we have built a structure in the Insider Threat Center 
that  enables  us  to  stay  in  touch  with  what’s  happening  in  the  field, 
take  advantage  of  our  unique  position  in  one  of  the  leading  research 
 universities in the world, and partner with government and industry to 
develop solutions that are having an immediate impact on insider threat 
 mitigation.
Timeline of the CERT Program’s Insider Threat Work
The CERT Program’s insider threat research began in 2000 and has contin-
ued to grow. In this section we present a brief timeline of the history of the 
CERT Program’s work in this area. Figure 1-5 summarizes the evolution of 
the body of work of the CERT Insider Threat Center.
2000 Initial Research
The CERT Program’s original insider threat research was sponsored by the 
U.S. Department of Defense (DOD) in 2000, and focused on insider threats 
in the military services and defense agencies.
2001 Insider Threat Study
Our insider threat research ramped up the following year, in 2001, when the 
Secret Service National Threat Assessment Center (NTAC) and the CERT 
Program joined efforts to conduct a unique study of insider incidents, the 
Insider Threat Study (ITS). The Department of Homeland Security, Office 
of Science and Technology (DHS S&T) provided financial support for the 
completion of the study in 2003 and 2004. Four reports were produced as a 
result of that effort focusing on the banking and finance sector [Randazzo 
2004], the information technology sector [Kowalski 2008a], the government 
sector [Kowalski 2008b], and the analysis of insider IT sabotage across all 
critical infrastructure sectors [Keeney 2005].

17
Timeline of the CERT Program’s Insider Threat Work
2001 Insider Threat Database
After the completion of the Insider Threat Study with the Secret Service, 
we  realized  the  enormous  value  of  our  database.  Following  the  study, 
 Carnegie Mellon’s CyLab4 agreed to sponsor the ongoing maintenance 
and  evolution  of  the  database,  and  in  2009  the  DHS  Federal  Network 
Security  (FNS)  branch  became  the  sponsor  of  the  CERT  insider  threat 
database.
2005 Best Practices
In 2005, CyLab provided funding to us for the “Common Sense Guide to 
Prevention and Detection of Insider Threats.” Our best practice work is 
now being sponsored by DHS FNS. The best practices from the “Common 
Sense Guide” are detailed in Chapter 6.
2005 System Dynamics Models
After publishing the Insider Threat Study reports with the Secret Service, 
we felt that people were looking for a few nuggets they could take back 
to their IT staff for technical resolution, and were not seeing the “big pic-
ture” of how these crimes evolve over time. We convinced CyLab to fund 
us  to  develop  models  of  insider  threat.  The  project,  titled  MERIT  (for 
Management  and  Education  of  the  Risk  of  Insider  Threat),  resulted  in 
groundbreaking models that have influenced researchers and practitioners 
around the world ever since. Those models have become another founda-
tion upon which all of our work is based.
We  discuss  our  system  dynamics  modeling  work  in  more  detail  in 
 Appendix F.
2006 Workshops
In 2006, CyLab continued its support of our insider threat work by  funding 
us  to  develop  an  insider  threat  workshop.  What  started  out  as  a  half-
day workshop has expanded over the years so that we now offer several 
versions:  a  two-day  public  offering,  on-site  workshops  for  individual 
organizations,  half-day  and  one-day  versions,  and  custom  workshops, 
including an executive workshop for C-level executives and academically 
oriented workshops focused on a specific research objective.
4.  www.cylab.cmu.edu/

Chapter 1.  Overview
18
 

19
Timeline of the CERT Program’s Insider Threat Work
an isolated network.5 In 2010, DHS FNS funded us to create insider threat 
exercises using XNET. These exercises are now offered to government and 
industry practitioners at workshops and conferences.
See Chapter 7 for more information about our insider threat exercises.
2010 Insider Threat Study—Banking and Finance Sector
In 2010, DHS S&T brought together the CERT Insider Threat Center, the 
Secret Service, and the Department of the Treasury to repeat the original 
Insider Threat Study. This time, however, the focus was solely on cases that 
occurred in the banking and finance sector. At the end of the study, a report 
will be published much like the original study. In addition, we will pub-
lish a system dynamics fraud model that will evolve the preliminary fraud 
model presented in this book.
Chapter 4 contains a preliminary fraud model that was developed previ-
ously as part of the CyLab MERIT project.
Figure  1-5  shows  a  summary  of  the  history  of  the  CERT  Insider  Threat 
 Center body of work.
5.  For more information on CERT’s XNET capability, see http://xnet.cert.org/.
Figure 1-5  CERT Insider Threat Center timeline
2000
2001
2002
2003
2004
2005
2006
2007
2008
2009
2010
2011
Initial
Research
Insider Threat Study
Insider Threat Database
Insider Threat Assessment
Insider Threat Lab
Insider Threat
Exercises
Insider Threat
Study – Banking
and Finance Sector
Best Practices
System Dynamics Models
Workshops
Interactive
Virtual
Simulation
Tool

Chapter 1.  Overview
20
Caveats about Our Work
Organizations  are  often  reluctant  to  report  incidents  of  illicit  insider 
 cyberactivity,  even  to  law  enforcement.  Therefore,  the  actual  number  of 
insider cases is most likely significantly greater than those that we have 
been able to identify. Our work is largely based on reported cases, although 
our   assessments  have  exposed  us  to  additional  cases  not  reported  to 
law enforcement. This limits the ability to generalize our findings to all 
 organizations and underscores the difficulty other researchers have faced 
in trying to better understand insider threat. Nevertheless, this limitation 
does not diminish the value of the knowledge that we gained from analyz-
ing these incidents. We provide insight into actual criminal and other illicit 
acts committed by insiders. This insight has been found to be quite useful 
to individuals who are charged with protecting critical assets as they begin 
to examine ways to improve their defenses against insider threats.
The other limitation of our work is that we have only collected data for 
malicious insiders. We have not been able to collect similar data for “good 
guys.” We know how the convicted insiders acted in our cases, and have 
identified definite patterns in their behavior, both online and socially. But 
we have no idea if “normal” people exhibit those same behaviors. This is 
an area of research that is widely recognized to be lacking in the insider 
threat domain, but unfortunately no one has come up with a good way 
to   collect  the  comprehensive  types  of  data  we  have  without  violating 
employee  privacy.
Do these caveats impact the usefulness of our research? From an academic 
perspective,  yes.  However,  feedback  from  practitioners  since  2001  has 
encouraged us to continue forging ahead in our study of malicious actors, 
since  our  findings  resonate  with  the  community.  In  addition,  our  coun-
termeasures have received overwhelmingly positive feedback from those 
tasked with keeping their organizations’ systems, data, and networks safe 
from insider threats.
 

21
Summary
for each, so you should now understand which of those threats are of most 
concern to you. You should now know which chapter—2, 3, or 4—you want 
to read next in the book. We do recommend that you understand the nature 
of the insider threat problem before you jump to the solutions offered in 
Chapter 6 and Chapter 7.
Chapter 5, Insider Threat Issues in the Software Development Life Cycle, 
is devoted to that specific type of insider threat. These crimes can be quite 
destructive and difficult to detect, so we strongly recommend you read that 
chapter if you do any software development in your organization.
You should now recognize the expanding complexity of insider threats, 
including threats from trusted business partners, dangers posed by collu-
sion with the Internet underground and organized crime, and impacts of 
foreign allegiances and cultural issues. If these issues are of concern, you 
will find them addressed in more detail throughout the book.
We  discussed  our  system  dynamics  modeling,  and  explained  that  the 
descriptions of our models in this book are written for managers and prac-
titioners. We described the high-level patterns we observed for each type 
of crime. We have presented these models for years to diverse audiences, 
including technical and nontechnical, management and nonmanagement, 
as well as CISOs, CSOs, and personnel in legal, HR, physical security, soft-
ware  engineering,  and  so  on.  The  feedback  is  always  overwhelmingly 
positive.
Finally, we provided a brief overview of the CERT Insider Threat Center. 
We wanted to give you enough background on the breadth of our capabili-
ties so that you would be comfortable that we know what we’re doing, and 
you can trust the material in this book!

This page intentionally left blank 

Free ebooks ==>   www.Ebook777.com
23
Chapter  2
Insider IT Sabotage
 
1.  Material in this chapter includes portions from previously published works. The primary source was 
written by the authors of this book as a chapter in Insider Attack and Cyber Security: Beyond the Hacker 
edited by S.J. Stolfo et al., Springer Science + Business Media, LLC [Moore 2008]. Earlier versions of the 
insider IT sabotage model were published in [Moore 2007, Cappelli 2006, Band 2006].
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
24
attacks is next to impossible. Fortunately, we have identified distinct pat-
terns in nearly every insider IT sabotage case. In this chapter we describe 
those patterns and present mitigation strategies that use those patterns to 
your advantage. These techniques include both technical and nontechni-
cal measures. In addition, some are proactive across the enterprise, while 
others are targeted at specific employees triggered by indicators that could 
suggest an increased risk of attack.
For example, we suggest countermeasures such as periodic account audits, 
since a number of these insiders created backdoor accounts2 prior to being 
fired so that they could get back in and exact their revenge following ter-
mination. With more and more identity management systems3 available, 
we would expect to see a reduction in the use of this technique. However, 
during the week this chapter was written, a former system administrator at 
a large, multinational corporation used a VPN token4 he had created for a 
nonexistent employee prior to being fired to break back into his employer’s 
network and sabotage its systems.
On the other hand, we realize that account audits are time consuming and 
difficult to perform, especially at times of reduced staffing levels.  Therefore, 
we also suggest that when a system administrator is sanctioned and “on 
the HR radar” you perform a detailed audit of all accounts that have been 
created since he first became disgruntled and began exhibiting concerning 
behaviors in the workplace.
The bottom line is that we believe there is a good chance to thwart these 
attacks, but it requires careful planning and implementation of mitigation 
strategies across your organization. We do have some “good-news” cases.
2.  Backdoor account:  an  unauthorized  account  created  for  gaining  access  to  a  system  or  network 
known only to the person who created it.
3.  Identity Management System: a system or technology that supports the management of identities. 
It is generally accepted that an IMS will establish identities, describe identities through one or more 
attributes, follow identity activity, and be capable of removing an identity from the system it manages 
(adapted from Future of Identity in the Information Society).
4.  Virtual private network (VPN): a virtual network, built on top of existing physical networks, that 
provides a secure communications tunnel for data and other information transmitted between net-
works (NIST SP 800-46). A VPN token is a device, possibly physical, that an authorized user of the VPN 
is given to ease authentication.
Fortunately, we have identified distinct patterns in nearly every insider IT 
sabotage case. In this chapter we describe those patterns and present 
mitigation strategies that use those patterns to your advantage.

Free ebooks ==>   www.Ebook777.com
25
   Insider IT Sabotage
•  A logic bomb would have wiped out every file on every server on 
the network. Fortunately, the organization reacted swiftly to a suspi-
cious comment made by a system administrator who was to be fired 
the following Monday, took all systems offline over the weekend, and 
discovered the logic bomb before it executed.
•  A logic bomb would have destroyed information on more than 
70 servers, including a critical patient-specific, drug-interaction 
 conflict database.  Fortunately,  a  computer  system  administrator, 
while  investigating a  system error, discovered the logic bomb, noti-
fied IT, and the malicious code was neutralized before impacting the 
organization.
The impacts of an insider IT sabotage attack can be devastating:  Companies 
have gone out of business, lost millions of dollars, lost entire product lines, 
or  had  to  undergo  massive  layoffs.  Impacts  of  these  attacks  in  govern-
ment agencies and critical infrastructure organizations have ranged from 
embarrassing reputational impacts to serious threats to national security. 
Financial impacts in the 123 cases in the CERT database at the time this was 
written averaged $1.7 million, ranging from $1,000 to $87 million. (Note 
that half of the organizations suffered $50,000 or less in financial losses.) 
However, the impacts are not limited to financial losses; operational and 
business impacts were devastating in many of these cases.
We strongly suggest that you pay close attention to this chapter. We find 
that many people do not fully understand the risk of insider IT sabotage to 
their organization. For instance, financial institutions are understandably 
concerned with internal fraud. But what if a financial institution’s custom-
ers could not use their debit or credit cards, use ATMs, or access any of their 
money for an entire weekend after a fired system administrator sabotaged 
critical servers on a Friday night? That’s what happened to one unfortu-
nate financial institution.
Likewise,  manufacturing,  pharmaceutical,  and  chemical  organizations 
seem to be most concerned with protection of their trade secrets—formulas, 
manufacturing processes, and engineering information. But what if, as in 
one company, a rogue system administrator sabotaged the manufacturing 
process, resulting in the disruption of critical machinery and the ultimate 
collapse of the company?
Finally, national security espionage arguably receives the most attention 
in the U.S. government, but consider multiple cases in which government 
employees  helped  undocumented  immigrants  obtain  citizenship  and 
 government credentials for profit.
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
26
Unfortunately,  all  of  these  things  really  did  happen,  and  much  to  the 
 surprise of the victim organizations. It does not take much imagination to 
envision the potential for a threat of even greater harm, such as malicious 
software that results in the release of toxic chemicals by a manufacturer, or 
mass casualties of our armed forces.
Now that we have caught your attention, let’s look at the characteristics 
and “big picture” of insider IT sabotage attacks.
Impacts of Insider IT Sabotage Attacks
The impacts of insider IT sabotage attacks have included the following.
•  Electricity between power grids was shut down in one area of the 
United States.
•  A safety hotline was disabled.
•  More than 50,000 customer records were corrupted.
•  Thirty thousand copies of a newspaper had to be reprinted.
•  A company’s domain name5 was added to anti-spam blacklists.6
•  Critical data was lost and the company went out of business (multiple 
cases).
•  The organization’s network was inaccessible—ranging from hours to 
days to three months (multiple cases).
•  A person was marked as being deceased in a large government 
 database, causing major problems for the person.
•  Cars inexplicably shut down or their horns beeped nonstop.
•  A company’s voice-mail system was redirected to a pornographic 
phone service.
•  Customers’ credit card numbers were posted to the Internet along 
with other proprietary information.
•  All administrative passwords at a company were changed, system 
files were deleted, a billing system was destroyed, and two internal 
databases were deleted.
•  A company’s international e-commerce site was unavailable ( multiple 
cases).
•  Hundreds of staff hours were required to recover from backups or 
reenter data manually (multiple cases).
•  A company’s clients’ Web pages were modified to contain embarrassing 
information.
These are documented cases.
5.  Domain names:  host  names  tied  to  IP  resources  such  as  Web  sites  (adapted  from  ICANN/ 
Wikipedia).
6.  Anti-spam blacklists: a system designed to block spam messages through a system of IP address 
filtering. Often functions in tandem with a content-recognition system.

27
   Insider IT Sabotage
 
7.  ftp://ftp.bls.gov/pub/special.requests/lf/aat11.txt
8.  Recall as described in Chapter 1, Overview, that MERIT stands for Management and Education of the 
Risk of Insider Threat.

Chapter 2.  Insider IT Sabotage
28
these attacks. Even better: It is very likely that you already own all of the 
technology you need in order to implement our suggestions!
General Patterns in Insider IT Sabotage Crimes
The intent of the MERIT model of insider IT sabotage is to describe the 
 general profile of insider IT sabotage crimes. The MERIT models describe 
the patterns in the crimes as they evolve over time—profiling the life cycle 
of the crime, rather than profiling only the perpetrator. Our study of insider 
IT sabotage cases brought to light how the problem of malicious insider 
retribution arises and escalates within an organization. The key elements of 
the model were observed in a majority of cases in the CERT database.
The MERIT model of insider IT sabotage was first published in 2008. It has 
been widely accepted by industry and government as being representative 
of these types of attacks. The model was created using system dynamics 
modeling, which is described in the original report. Over the years, how-
ever, we have found that a higher-level view of that model is more useful in 
describing the patterns to practitioners so that clear, actionable guidance can 
be provided for mitigating these attacks. That higher-level form of the model 
and accompanying countermeasure guidance is presented is the remainder 
of this chapter. We have broken the model into small pieces in this chapter in 
order to make it more understandable. The full model is shown in Figure 2-1. 
Figure 2-2 shows the system dynamics model with mitigating factors noted.
Personal Predispositions
 
NOTE
­

General Patterns in Insider IT Sabotage Crimes
29
Figure 2-1  MERIT model of insider IT sabotage
Actual Risk of
Insider Attack
Technical
Precursor
Acquiring
Unknown
Paths
Behavioral
Precursor
Ability to
Conceal
Activity
Unknown
Access Paths
Disgruntlement
Discovery of
Precursors
Technical
Monitoring
Sanctions
Insider’s Unmet
Expectation
Behavioral
Monitoring
Perceived Risk
of Insider Attack
Organization’s
Trust of Insider
Insider’s
Expectation
Expectation
Fulfillment
Precipitating
Event
Personal
Predisposition
Figure 2-2  Insider IT sabotage mitigating measures
Actual Risk of
Insider Attack
Technical
Precursor
Acquiring
Unknown
Paths
Forgetting
Paths
Discovering
Paths
Disabling
Paths
Behavioral
Precursor
Ability to
Conceal
Activity
Unknown
Access Paths
Known
Access Paths
Disgruntlement
Discovery of
Precursors
Technical
Monitoring
Sanctions
Positive
Intervention
Insider’s Unmet
Expectation
Behavioral
Monitoring
Perceived Risk
of Insider Attack
Organization’s
Trust of Insider
Expectation
Setting
Tracking
Insider’s
Expectation
Expectation
Fulfillment
Precipitating
Event
Personal
Predisposition
Insider Demotion
or Termination

Chapter 2.  Insider IT Sabotage
30
 

General Patterns in Insider IT Sabotage Crimes
31
 drug-related offenses (11%), and nonfinancial/fraud-related theft offenses 
(11%)  [ Keeney  2005].  (Note  that  some  of  the  insiders  had  been  arrested 
for  multiple offenses.) The relatively high frequency of previous criminal 
arrests underscores the need for background checks. These proactive mea-
sures should not be punitive in nature; rather, you should indoctrinate the 
employee  into  the  organization  with  appropriate  care.  In  addition,  this 
information should be used as part of a risk-based decision process in deter-
mining whether it is appropriate to give the new employee privileged access 
to critical,  confidential, or proprietary information or systems.
You should require background checks for all potential employees,  including 
contractors and subcontractors. In one case in the CERT database, an organi-
zation employed a contractor to perform system administration duties. The 
hiring organization was told by the contractor’s company that a background 
check had been performed on him. The contractor later compromised the 
organization’s systems; during the investigation it was discovered that the 
contractor had a criminal history of illegally accessing protected computers.
Disgruntlement and Unmet Expectations
 
TIP
To reduce the insider threat, begin in the hiring process by performing 
background checks and evaluating individuals based on the information 
received.
9.  Most  of  the  insiders  who  committed  IT  sabotage  were  male.  Therefore,  male  gender  is  used  to 
describe the generic insider in this chapter.
NOTE
Most insiders who committed IT sabotage were disgruntled due to unmet 
expectations.
Unmet expectation: an unsatisfied assumption by an individual that an 
organization action or event will (or will not) happen, or a condition will 
(or will not) exist.

Chapter 2.  Insider IT Sabotage
32
 personal  files,  but  was  reprimanded  by  management  for  exercising 
those  freedoms.
•  The insider expected to work for the hiring supervisor or work on a 
 certain project, but over time a new supervisor was hired or he was 
moved to a different project.
•  The  insider  expected  a  certain  financial  reward  for  his  work,  but 
bonuses or raises were lower than expected due to the organization’s 
financial status.
Figure 2-3 depicts the insider’s personal predisposition leading to height-
ened expectations; then a precipitating event results in unmet expectations 
that lead to insider disgruntlement.
Over  time,  employees  and  contractors  come  to  expect  certain  things  in 
the workplace based on past history. In IT sabotage cases, a precipitating 
event leads to unmet expectations, triggering disgruntlement in insiders. 
A precipitating event is anything that removes or restricts the freedom or 
recognition to which the employee or contractor has become accustomed. 
For  instance,  a  new  supervisor  who  suddenly  enforces  the  organiza-
tion’s acceptable-use policy may cause extreme disgruntlement in certain 
employees. Other precipitating events include the insider being passed up 
for a promotion, as well as sanctions by management, transfer, demotion, 
or termination of the insider.
Figure 2-3 Expectation escalation
Disgruntlement
Insider’s Unmet
Expectation
Expectation
Fulfillment
Personal
Predisposition
Precipitating
Event
Insider’s
Expectation
(R1)

Free ebooks ==>   www.Ebook777.com
General Patterns in Insider IT Sabotage Crimes
33
Note  that  some  precipitating  events,  such  as  raises  that  are  lower  than 
expected,  lack  of  bonuses,  and  downsizing,  simply  cannot  be  avoided, 
especially  in  times  of  economic  downturn.  It  is  very  important  that 
 organizations appreciate the influence such factors can play in insider IT 
sabotage  attacks  by  planning  carefully  and  increasing  vigilance  as  such 
steps are executed. In one CERT case, a system administrator planted a 
logic bomb designed to wipe out data on 70 company servers after finding 
out about planned layoffs due to the company’s reorganization. Even after 
surviving the downsizing, the insider refined the logic bomb and set it to 
go off more than a year later. Fortunately, other IT personnel discovered 
the logic bomb while investigating a system problem and neutralized the 
destructive code.
Unmet expectations from the CERT cases include
•  Salary/bonus
•  Promotion
•  Freedom of online actions
•  Work ethic
•  Project requirements (deadlines, milestones)
•  Overestimated abilities
•  Access to information following termination
•  Use of company resources
•  Job dissatisfaction
•  Supervisor demands
•  Coworker relations
•  Responsibilities
Precipitating events in the CERT cases include
•  Being passed over for promotion
•  Demotion due to project completion
•  Transfer between departments
•  Supervisor issues:
•  New supervisor hired
•  Disagreement with supervisor
•  Access changed
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
34
•  Financial:
•  Disagreement over salary and compensation
•  Bonuses lower than expected
•  Termination of subcontractor contract
•  Termination of partnership because of financial issues
•  Coworkers overriding decisions
•  Outsourcing of project
What Can You Do?
Responsibilities and constraints of your employees and consequences for 
violations  need  to  be  clearly  communicated  and  consistently  enforced. 
Policies or controls that are misunderstood, not communicated, or incon-
sistently enforced can breed resentment among employees, lead to unmet 
expectations, and potentially result in harmful insider actions. A consistent, 
clear message on your organization’s policies and controls will help reduce 
the chance that employees will lash out for a perceived injustice.
As  individuals  join  your  organization,  they  should  receive  a  copy  of 
 organizational  policies  that  clearly  lays  out  what  is  expected  of  them, 
together with the consequences of violations. Evidence that each individual 
has read and agreed to the organization’s policies should be maintained.
Consistent enforcement of policies is essential to maintain a harmonious 
work environment. When employees see inconsistent enforcement of pol-
icies, it quickly leads to animosity within the workplace. In many of the 
cases  analyzed,  inconsistent  enforcement  or  perceived  injustices  within 
organizations led to insider disgruntlement. Coworkers often felt that “star 
performers” were above the rules and received special treatment. Many 
times that disgruntlement led the insiders to commit IT sabotage.
In one case, employees had become accustomed to lax policy enforcement 
over a long period of time. New management dictated immediate strict policy 
enforcement, which caused one employee to become embittered and strike 
out  against  the  organization.  In  other  words,  policies  should  be  enforced 
 consistently across all employees, as well as consistently enforced over time.
TIP
Clearly communicate and consistently enforce responsibilities and 
 constraints of your employees and consequences for violations.

General Patterns in Insider IT Sabotage Crimes
35
Of course, organizations are not static entities; change in your policies and 
controls is inevitable. Employee constraints, privileges, and  responsibilities 
change  as  well.  You  need  to  recognize  times  of  change  as  particularly 
 stressful  times  for  employees,  appreciate  the  increased  risk  that  comes 
along with these stress points, and mitigate it with clear communication 
 regarding what employees can expect in the future.
It is important that you anticipate and manage negative workplace issues, 
beginning  with  preemployment,  continuing  through  employment,  and 
especially at termination. When employees have issues they need an ave-
nue within your organization to seek assistance. Employees need to be able 
to openly discuss work-related issues with a member of management or 
human  resources  without  the  fear  of  reprisal  or  negative  consequences. 
Managers need to address these issues when discovered or reported, before 
they escalate out of control.
When employee issues arise because of outside issues, including  financial 
and personal stressors, it can be helpful to use a service such as an employee 
assistance program. These programs offer confidential counseling to assist 
employees, allowing them to restore their work performance, health, or 
general well-being.
Finally, contentious employee terminations must be handled with utmost 
care, as most insider IT sabotage attacks occur following termination.
Behavioral Precursors
Often, the first sign of disgruntlement is the onset of concerning behav-
iors in the workplace. Some examples of concerning behaviors in the CERT 
cases were
•  Conflicts with coworkers or supervisors
•  A sudden pattern of missing work, arriving late, or leaving early
•  A sudden decline in job performance
•  Drug use
NOTE
Behavioral precursors were observable in insider IT sabotage cases.
Behavioral precursor: an individual action, event, or condition that 
involves personal or interpersonal behaviors and that precedes and is 
associated with malicious insider activity.

Free ebooks ==>   www.Ebook777.com
Chapter 2.  Insider IT Sabotage
36
•  Aggressive or violent behavior
•  Mood swings
•  Bizarre behavior
•  Sexual harassment
•  Poor hygiene
Unfortunately,  in  many  of  the  incidents  in  the  CERT  database,  the 
 concerning  behaviors  were  not  recognized  by  management  prior  to  the 
incidents, or the organization failed to take action to address the behaviors.
Note that the precipitating events in the CERT cases most likely affected 
many employees, not only the malicious insider. Therefore, it is likely that 
many employees were similarly disgruntled, and also exhibited concerning 
behaviors similar to the insider. Therefore, at this point in the model, it is 
most likely difficult to distinguish between insiders who might eventually 
attack, and those employees who are simply disgruntled. It is important 
that you do not rely on only one portion of the model to identify a person 
who may be at risk of committing IT sabotage, but instead recognize the 
escalating risk as an employee or contractor progresses along the path in 
the model.
What Can You Do?
You should invest time and resources in training supervisors to  recognize 
and  respond  to  inappropriate  or  concerning  behavior  in  employees.  In 
some  of  the  CERT  cases,  less  serious  but  inappropriate  behavior  was 
noticed in the workplace but not acted on because it did not rise to the level 
of a policy violation. However, failure to define or enforce security policies 
in some cases emboldened the employees to commit repeated violations 
that escalated in severity, with increasing risk of significant harm to the 
organization. It is important that you consistently investigate and respond 
to all rule violations committed by employees.
 
TIP
Train supervisors to recognize and respond to inappropriate or 
 concerning behaviors.
www.Ebook777.com

General Patterns in Insider IT Sabotage Crimes
37
be  screened,  all  reports  should  be  investigated.  If  an  employee   exhibits 
 suspicious  behavior,  you  should  respond  with  due  care.  Disruptive 
employees should not be allowed to migrate from one position to another 
within the organization, evading documentation of disruptive or concern-
ing   activity.  Threats,  boasting  about  malicious  acts  or  capabilities  (“You 
wouldn’t believe how easily I could trash this net!”), and other negative 
sentiments should also be treated as concerning behavior. Many employ-
ees will have concerns and grievances from time to time, and a formal and 
accountable process for addressing those grievances may satisfy those who 
might  otherwise resort to malicious activity. Specifically, any employee or 
contractor  with  privileged  access  who  is  experiencing  difficulties  in  the 
workplace should be aided in the resolution of those difficulties.
Once  concerning  behavior  is  identified,  several  steps  might  assist  you 
in managing risks of malicious activity. First, the employee’s privileged 
access to critical information, systems, and networks should be evaluated. 
Logs should be reviewed to carefully examine recent online activity by the 
employee. While this is done, the organization should provide options to 
the individual for coping with the behavior, perhaps including access to a 
confidential employee assistance program.
Stressful Events
 
NOTE
In most cases stressful events, including organizational sanctions, 
 contributed to the likelihood of insider IT sabotage.
Stressful events: events that cause concerning behaviors in individuals 
predisposed to malicious acts.

Chapter 2.  Insider IT Sabotage
38
 
Figure 2-4 Typical escalation of disgruntlement (a) and intended effect 
of sanctions (b)
(a)
(b)
Behavioral
Precursor
Disgruntlement
Discovery of
Precursors
Sanctions
Behavioral
Monitoring
Behavioral
Precursor
Discovery of
Precursors
Sanctions
Behavioral
Monitoring

General Patterns in Insider IT Sabotage Crimes
39
distinguish between insiders who might retaliate and those who most likely 
will not. We believe that in most nonmalicious employees and  contractors, 
imposition  of  sanctions  will  serve  as  a  “wake-up  call,”  and  they  either 
accept the circumstances or seek a new job, rather than  planning an attack.
What Can You Do?
It  is  important  that  managers  and  human  resources  staff  members 
 understand and consider the potential for insider IT sabotage when there 
are ongoing, observable behavioral precursors that continue or even esca-
late following employee sanctions. In the remainder of this chapter we will 
discuss technical monitoring that should be considered once this escalating 
pattern of disgruntlement by technically privileged users is recognized.
It is also important to point out that sanctions can be quite important when 
they  involve  contractors  rather  than  employees.  The  following  exam-
ple  illustrates  important  physical  security  and  legal/contracting  issues 
 regarding contractors.
An energy management facility subcontracted with a company for  system 
administrator  support.  One  such  system  administrator,  who  worked 
physically on-site at the energy management facility, was suspended by 
his employer late on Friday afternoon due to an employee dispute. His 
employer  decided  to  wait  and  inform  the  energy  management  facility 
of the suspension on Monday morning. Late Sunday night he used his 
authorized physical access to the energy production facility, used a ham-
mer to break the glass case enclosing the emergency power off button, and 
hit the button. Some of the computer systems were shut down as a result, 
including computers that regulated the exchange of electricity between 
power grids. For a period of two hours, the shutdown denied the orga-
nization access to the energy trading market, but fortunately didn’t affect 
the  transmission grid directly.
In order to protect yourself from this type of risk, consider contractually 
requiring  advance  notification  of  pending  employee  sanctions  by  your 
 subcontractors.
TIP
Managers and human resources staff members must understand and 
consider the potential for insider IT sabotage when there are ongoing, 
observable behavioral precursors.

Chapter 2.  Insider IT Sabotage
40
Technical Precursors and Access Paths
 
NOTE
In many cases organizations failed to detect technical precursors.
Technical precursor: an individual action, event, or condition that 
involves computer or electronic media and that precedes and is 
 associated with malicious insider activity.
NOTE
Insiders created or used access paths unknown to the organization to 
set up their attack and conceal their identity or actions. The majority of 
 insiders attacked after termination.
Access path: a sequence of one or more access points that lead to a 
critical system.
10.  Password cracker: a program used to identify passwords to a computer or network resource; used 
to obtain passwords for other employee accounts.
11.  Remote network administration tools: tools to allow the administration of a computer from a 
 location other than the computer being administered.

General Patterns in Insider IT Sabotage Crimes
41
also contribute to the damage potential of the attack. Examples include 
 sabotage of backups and decreases in the redundancy of critical services 
or software. Insiders often acquire access paths unknown to the organiza-
tion—“unknown access paths.” This increases their ability to conceal their 
activity, making it more difficult for you to discover the precursors. To make 
matters worse, this ability to hide their actions may actually embolden the 
risk-averse insiders to continue, or even increase, their efforts to attack.
Examples of methods used by insiders to create unknown access paths to 
set up their attack include
•  Creating  backdoors  before  termination  or  after  being  notified  of 
 termination
•  Installing a modem for access following termination
•  Disabling anti-virus programs on desktops and testing a virus
•  Network probing  (any  number  of  practices  in  which  a  particular 
 network is either passively surveilled or actively scanned)
•  Installing a remote network administration tool
•  Downloading and installing malicious code and tools (e.g., a rootkit,12 
password cracker, or virus)
•  Planting  a  logic  bomb  while  still  employed—here  the  logic  bomb  is 
performing on behalf of the insider and thus is a virtual access path to 
disrupt systems
Figure 2-5 Technical precursors due to disgruntlement
Acquiring
Unknown
Paths
Actual Risk of
Insider Attack
Behavioral
Precursor
Ability to
Conceal
Activity
Unknown
Access Paths
Discovery of
Precursors
Disgruntlement
Technical
Monitoring
Technical
Precursor
12.  Rootkit: software that enables continued privileged access to a computer while actively  hiding 
its  presence  from  administrators  by  subverting  standard  operating  system  functionality  or  other 
 applications.

Chapter 2.  Insider IT Sabotage
42
 

Free ebooks ==>   www.Ebook777.com
General Patterns in Insider IT Sabotage Crimes
43
malicious  insider  activity  occurs,  nonrepudiation  techniques  allow  each 
and every activity to be attributed to a single employee. Policies, practices, 
and technologies exist for configuring systems and networks to facilitate 
nonrepudiation. However, keep in mind that system administrators and 
other privileged users will be the ones responsible for designing, creating, 
and implementing those policies, practices, and technologies. Therefore, 
separation of duties13  is  also  very  important:  Network,  system,  and 
 application security designs should be created, implemented, and enforced 
by multiple privileged users.
 
13.  Separation of duties: the separation of tasks among various individuals.
14.  Nonrepudiation: ability to verify a particular user is accessing a system or performing a particular 
action; the goal being to make it more difficult for a user to hide illicit activity.
TIP
Nonrepudiation14 techniques must be implemented to attribute all 
actions to the person that performed them.
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
44
users to reduce the risk of extortion after they leave the organization. The 
two-person rule is a control mechanism that requires the involvement of 
two persons for a particular operation (adapted from Wikipedia).
Some  unknown  access  paths  used  by  malicious  insiders  included 
 compromised accounts. They used password crackers, obtained passwords 
through social engineering,15 and used unattended computers left logged 
in. Password policies and procedures should ensure that all passwords are 
strong, employees do not share their passwords with anyone, employees 
change  their  passwords  regularly,  and  all  computers  automatically  exe-
cute password-protected screen savers after a fixed period of inactivity. As 
a result, all activity from any account should be attributable to its owner. 
In addition, an anonymous reporting mechanism should be available and 
its use encouraged for employees to report all attempts at unauthorized 
account access.
Some insiders created backdoor accounts that provided them with system 
administrator or privileged access following termination. Other insiders 
found that shared accounts  were  overlooked in the termination  process 
and  were  still  available  to  them.  System  administrator  accounts  were 
commonly used. Other shared accounts included database administrator 
(DBA) accounts. Some insiders used other types of shared accounts,16 such 
as those set up for access by external partners like contractors and vendors. 
One insider also used training accounts that were repeatedly reused over 
time without ever changing the password.
Periodic  account  audits  combined  with  technical  controls  enable  identi-
fication of the following:
•  Backdoor accounts that could be used later for malicious actions by an 
insider, whether those accounts were specifically set up by the insider 
or were left over from a previous employee
•  Shared accounts whose password was known by the insider and not 
changed after termination
•  Accounts created for access by external partners such as contractors 
and vendors whose passwords were known by multiple employees, 
and were not changed when one of those employees was terminated
15.  Social engineering: a nontechnical form of intrusion that relies heavily on human interaction and 
often involves tricking other people to break normal security procedures (Whatis.com).
16.  Shared account: an account used by two or more people.

Free ebooks ==>   www.Ebook777.com
General Patterns in Insider IT Sabotage Crimes
45
The need for every account should be reevaluated periodically. Limiting 
accounts to those that are absolutely necessary, with strict procedures and 
technical controls that enable auditors or investigators to trace all online 
activity on those accounts to an individual user, diminishes an insider’s 
ability  to  conduct  malicious  activity  without  being  identified.  Account 
management policies that include strict documentation of all access privi-
leges  for  all  users  enable  a  straightforward  termination  procedure  that 
reduces the risk of attack by terminated employees.
It is important that your password and account management policies are 
also applied to all contractors, subcontractors, and vendors that have access 
to your information systems or networks. These policies should be written 
into contracting agreements, requiring the same level of accountability in 
tracking who has access to your systems. Contractors, subcontractors, and 
vendors should not be granted shared accounts for access to your informa-
tion systems. They should not be permitted to share passwords, and when 
employees are terminated at the external organization, your organization 
should be notified in advance so that account passwords can be changed. 
Finally, be sure to include contractor, subcontractor, and vendor accounts 
in the regularly scheduled password-change process.
The Trust Trap
In addition to insider predispositions and behaviors, organizational predis-
positions and behaviors—such as excessive trust of employees, a reluctance 
to “blow the whistle” on coworkers, or inconsistent enforcement of organi-
zation policies—can also influence an organization’s exposure to malicious 
insider acts. Figure 2-6 depicts a trap in which organizations sometimes 
find themselves. We call this the Trust Trap and have described its role in 
previous models [Andersen 2004, Cappelli 2006, Band 2006].
To understand the Trust Trap, we need to distinguish between the actual and 
perceived risk of an insider attack. As shown in the top portion of  Figure 2-6, 
actual risk depends on the behavioral and technical precursors exhibited by 
the insider. However, your perceived risk of insider attack is influenced by the 
extent that you discover and understand behavioral and technical precursors.
NOTE
The “Trust Trap” contributed to organizations being victimized in IT 
 sabotage attacks.
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
46
A key factor in the Trust Trap is your trust of your employees, as shown 
in Figure 2-6. Clearly, there are good reasons why you want to create a 
 workplace in which individuals can trust one another and there is a good 
trust  relationship  between  the  organization  and  its  employees  (e.g.,  to 
increase  morale  and  productivity).  However,  managers  who  strive  to 
promote  trusting  workplace  relationships  sometimes  shortcut  essential 
behavioral and technical monitoring procedures, or allow them to erode 
over  time  due  to  competing  pressures  and  priorities.  Lower  levels  of 
monitoring lead to undiscovered precursors, resulting in an overall lower 
perceived  risk  of  attack.  This  false  sense  of  security  reinforces  manag-
ers’ trust in the individuals working for them. The cycle continues, with 
your monitoring ability steadily deteriorating until a major compromise 
becomes obvious to all involved. It is essential that you trust your employ-
ees, but you must balance trust with verification, by applying consistent 
levels of behavioral and technical monitoring.
 
Figure 2-6 Trust Trap
Technical
Precursor
Behavioral
Monitoring
Perceived Risk
of Insider Attack
Organization’s
Trust of Insider
Technical
Monitoring
Behavioral
Precursor
Discovery of
Precursors
Actual Risk of
Insider Attack

Mitigation Strategies
47
We  therefore  propose  countermeasures  based  on  expert  opinions  in 
 behavioral  psychology and information security.
It is critical that all levels of management recognize and acknowledge the 
threat posed by insiders and take appropriate steps to mitigate malicious 
attacks. While it may not be realistic to expect that every attempt at insider 
IT  sabotage  will  be  stopped  before  damage  is  inflicted,  it  is  realistic  to 
expect that you can build resiliency into your infrastructure and business 
processes to allow you to detect the attacks earlier, thereby minimizing the 
financial and operational impact.
The remainder of this chapter describes potential countermeasures that we 
believe could be effective in mitigating insider IT sabotage. Figure 2-7 depicts 
organizational issues of concern in the sabotage cases in our  database.
The suggestions that follow apply to identifying and mitigating the most 
prevalent areas of concern from the graph, as well as some of the other 
issues that were relevant in a number of cases.
Early Mitigation through Setting of Expectations
First, you should recognize the personal predispositions of employees and 
understand the impact they can have on insider threat risk. Second, you 
should actively manage the expectations of employees to minimize unmet 
expectations.  This  can  be  achieved  through  communication  between 
managers  and  employees,  especially  in  the  form  of  regular  employee 
reviews, taking action to address employee dissatisfaction when possible. 
 Consistent enforcement of policies for all employees is also important so 
that individual employees do not come to feel that they are above the rules 
or that the rules are inconsistently enforced.
TIP
All levels of management must recognize and acknowledge the threat 
posed by insiders and take appropriate steps to mitigate malicious 
attacks.
TIP
Managers should recognize the personal predispositions of employees 
and understand the impact they can have on insider threat risk.

Chapter 2.  Insider IT Sabotage
48
When the expectations of the insider are in line with your practices and 
policies, unmet expectations are not an issue. However, if a precipitating 
event impacts expectation fulfillment, proactive actions by management to 
reset expectations may decrease the level of unmet expectations. If you fail 
to reset expectations, the level of unmet expectations may continue to rise, 
increasing disgruntlement on the part of the insider.
For  example,  you  can  attempt  to  lower  the  level  of  unmet  expectations 
regarding  system  use  and  job  responsibilities  by  a  number  of  proactive 
countermeasures.
•  You institute an acceptable use policy, describing the employee’s roles 
and  responsibilities  when  using  the  organization’s  information  sys-
tems. The policy should be given to each employee as part of his or her 
orientation to the organization. As changes to the policy occur, employ-
ees  need  to be  made  aware  of  the changes and the  impact to them. 
Finally, the policy must be consistently enforced for all employees so 
that no employees feel that they are “above the rules.”
Figure 2-7 Issues of concern
80
70
60
50
40
30
20
10
0
Change of Employment Status
Disgruntled Employee
Concerning Behavior or Activity
Users with System Administrator Privileges
to Sabotage Systems or Data
Handling of Negative Employment Issues
Verification of Deletion of Critical Files
Ability to Conduct a Denial-of-Service Attack
Violent or Aggressive Behavior
Insufficient Backups
Compromised Passwords
Conditional, Contract, or Temporary
Employment Status
Inserted Malicious Code into Operational System
Concealment of Current Illicit Activity–Technical
Employee Extortion, Threats, or Legal Demands
Ability of Users to Create Unknown Access
Paths into Organization Systems
Failure to Disable Accounts or Connections
upon Employee Termination

Free ebooks ==>   www.Ebook777.com
Mitigation Strategies
49
•  Management,  in  conjunction  with  human  resources,  should  clearly 
define  job  responsibilities  for  each  employee  in  the  organization. 
 Processes such as performance reviews should be used to check and set 
expectations periodically.
Handling Disgruntlement through Positive Intervention
First of all, management should be trained to pay attention to employee 
behaviors in the workplace, and to recognize the fact that ongoing concern-
ing behaviors in the workplace could signal potential problems. Remember 
that insiders who commit IT sabotage are typically very technical, privi-
leged users. It is important that managers of information technology and 
software engineering teams receive management training so that they are 
trained to manage people, not just technology.
 
TIP
Managers should be trained to pay attention to employee behaviors in the 
workplace.
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
50
the  employee  could  be  given  increased  responsibility  or  professional 
 development, in order to better position him for the next opportunity for 
promotion.
Eliminating Unknown Access Paths
Careful tracking and monitoring of access paths available to each employee 
and contractor is critical so that they can be disabled upon termination. 
Recall that unknown access paths used by insiders to carry out IT sabo-
tage attacks include backdoor accounts, shared accounts, malicious code 
planted by the insider, logic bombs, and remote access via remote access 
systems. Note that some of those access paths, such as shared accounts, 
are  legitimate  paths,  while  others,  such  as  logic  bombs,  are  solely  for 
 illegitimate purposes.
 
TIP
Careful tracking and monitoring of access paths is critical so that they can 
be disabled upon termination.

Mitigation Strategies
51
 
Figure 2-8 Access paths available to the insider
Discovering
Paths
Forgetting
Paths
Known
Access Paths
Unknown
Access Paths
Acquiring
Unknown
Paths
Disabling
Known
Paths

Chapter 2.  Insider IT Sabotage
52
 

Free ebooks ==>   www.Ebook777.com
Mitigation Strategies
53
Logic bombs are often planted in a place where they are sure to execute, 
such as operating system scripts or stable, production systems. Note that 
these are files that should not be modified on a frequent basis, and therefore, 
triggering an alert when such files are modified is a practical monitoring 
strategy. Commercial configuration-management and change-management 
software provide the technical solutions for implementing these triggers. 
While configuring such a system takes some time up front to determine 
what files should be changed infrequently, if ever, the time spent will be 
well worth it should malicious code be discovered when planted by a mali-
cious insider or outsider.
 
TIP
Some access paths require a more complex detection program, such as 
monitoring for logic bombs or other malicious code.
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
54
use was legitimate. The insider simply commented out the one line of code 
that sent the alert to Security, and then used the screen to attack the orga-
nization. That action would be extremely difficult to detect. First, he was 
authorized to modify the source code, so that action alone would not look 
like anomalous activity. Second, how many organizations do code reviews 
of every change made to the source code for production systems? In our 
experience, not many do. Fortunately, there is a solution.
As we discussed previously, configuration-management systems can detect 
changes to files, including source code; in fact, this organization used such a 
system and the change was in the logs. However, it is not usually practical to 
investigate every change to every source code file. In this case, however, that 
particular source code was in a critical file, and any changes to it could have 
triggered an alert. We recommend that system owners take the time to prior-
itize the most critical source code files in their systems—the ones that should 
trigger a code review anytime a change is made. The change-control system 
can be set up to report alerts in order of priority, which would make it easy 
for information security teams to investigate suspicious changes quickly.
In  another  case,  a  securities  trader  for  a  bank,  who  was  previously  a 
 computer  specialist,  inserted  malicious  code  into  a  risk  model  program 
that  he  had  created.  This  caused  other  employees  to  make  increasingly 
riskier financial deals. The malicious code was discovered by a program-
mer who was making legitimate modifications to the source code. As in the 
previous case, the file modified was arguably one of the most critical source 
code files in their system. Prioritized alerts by a configuration-management 
system could have alleviated this problem by immediately triggering an 
investigation of the change.
Prioritizing  assets  is  a  time-consuming  activity,  and  one  that  many 
 organizations do not take the time to do. Rather than trying to prioritize 
everything, we suggest that each system and data owner tackle only their 
areas, and focus on identifying the highest-priority files. In this way, priori-
tized alerts can be generated for changes to those files—the ones posing the 
highest degree of risk to the organization.
TIP
System and data owners should focus on identifying their highest-priority 
assets and implement prioritized alerting when changes to those files 
occur.

Free ebooks ==>   www.Ebook777.com
Mitigation Strategies
55
Targeted Monitoring
It  is  probably  not  practical  for  you  to  monitor  every  behavioral  and 
 technical action taken by each employee and contractor. However, a rea-
sonable level of proactive logging of online activity across your network 
provides data that can be monitored or audited for suspicious activity pro-
actively, or targeted to monitor people who have raised the suspicions of 
their managers.
As the perceived risk of an insider attack increases, due to detection of 
behavioral  or  technical  precursors,  the  amount  of  technical  and  behav-
ioral monitoring should also increase. Increased monitoring could lead to 
discovery of precursor activity, enabling you to identify individuals at a 
higher risk for malicious behavior and implement more targeted  individual 
 monitoring.
If  a  manager  notices  an  employee  progressing  through  the  pattern  of 
behavior  described  in  this  chapter,  he  might  consider  an  audit  of  that 
employee’s online activity. If the employee’s behaviors, either technical or 
nontechnical, are extreme enough, managers may need to escalate the level 
of logging and monitoring of that employee’s online activity.
Note that very clearly defined policies should be in place in advance of 
such targeted logging and monitoring; an organization should not perform 
these  actions  without  consulting  with  its  legal  department  in  advance. 
Thresholds  for  beginning  targeted  monitoring  must  be  very  clearly 
defined. In addition, such policies must be consistently enforced. If you 
institute targeted monitoring of one employee, and do not implement it 
for another employee exhibiting the same behaviors, there could be legal 
repercussions.
Targeted  monitoring  should  be  part  of  a  comprehensive  insider  threat 
incident-management plan, which should be developed by management, 
working together with the human resources, information security, legal, 
and physical security departments.
TIP
Since it is not practical to monitor every behavioral and technical action, 
proactive monitoring of people who are on the HR radar should be 
 implemented.
www.Ebook777.com

Chapter 2.  Insider IT Sabotage
56
Measures upon Demotion or Termination
Termination or demotion was the final precipitating event in many cases 
we examined. It is important for you to recognize that such precipitating 
events may cause the insider to take technical actions to set up and carry 
out the attack, possibly using previously acquired unknown access paths. 
A clearly defined process for demotions and terminations in combination 
with proactive IT best practices for detecting unknown access paths and 
eliminating  unauthorized  access  paths  can  reduce  the  insider’s  ability 
and/or desire to attack you.
 
TIP
Precipitating events, such as demotions or termination, may cause 
increased disgruntlement, so organizations should follow a consistent 
termination process.

Mitigation Strategies
57
insiders, knowing that the logs would be used for identification, attempted 
to conceal their actions by modifying the logs. In some cases, they modified 
the logs to implicate someone else for their actions.
 
TIP
It is particularly important that you architect your systems to ensure the 
integrity of your logs by implementing continuous logging to a centralized, 
secure log server.

Free ebooks ==>   www.Ebook777.com
Chapter 2.  Insider IT Sabotage
58
 
www.Ebook777.com

Summary
59
and insiders would be less likely to strike against connectivity because of 
the reduced impact.
One Final Note of Caution
You  must  be  aware  of  the  possibility  that  your  employees  could  attack 
another organization, possibly a previous employer, using your systems. 
While  not  common,  such  crimes  can  and  do  happen—there  are  a  few 
such cases in the CERT database. You need to consider the liability and 
 disruption that such a case could cause.
One such attack by an insider against his former employer from his current 
employer’s systems may have been a major factor in the current employer’s 
downfall. The insider claimed that the attack was payback for misdeeds 
against him and his current company. Although the current employer dis-
avows having anything to do with the attack, it too suffered as a result of 
the insider’s action. The law enforcement surrounded its offices and told 
workers not to tamper with any company data or files, putting its work on 
temporary hold. In a panic, the insider started massive erasure of poten-
tial evidence. The insider received five years for computer hacking and 
20 years for obstruction of justice.
 
TIP
Effective backup and recovery processes need to be in place and 
 operational so that if compromises do occur, business operations can be 
sustained with minimal interruption.

Chapter 2.  Insider IT Sabotage
60
precipitating  event  in  the  workplace,  such  as  no  raises  due  to  a  poor 
economy, a new supervisor that no one cares for, or being put onto a new 
project. As a result, they become disgruntled. Chances are that others in the 
organization are similarly disgruntled, since they most likely are subjected 
to the same circumstances. For a certain period of time, the atmosphere at 
work is probably tense, but then most employees “get over it.” The mali-
cious insiders, however, do not get over it. Instead, they become more and 
more  disgruntled.  They  continue  to  exhibit  concerning  behaviors  in  the 
workplace,  basically  caught  in  a  downward  spiral  that  continues  to  get 
increasingly worse until they make the decision to attack.
By the time they decide they want revenge, they realize they most likely 
will be fired, or they voluntarily quit the organization. They know they will 
need to get back into the organization’s network following their termina-
tion, so they create what we call “unknown access paths.” For instance, they 
create backdoor accounts, insert malicious code into source code, social-
engineer passwords, download malicious code, or write logic bombs. It is 
at this point that you either detect the unknown access path and setup of 
the attack, or have little chance of preventing the attack from occurring.
Our  recommendations  for  preventing  these  types  of  attacks  involve 
 multiple parts of your organization. Management needs to be trained to 
recognize the signs of a potential insider attack. They need to recognize the 
warning signs, and try to alleviate the problem if possible. If not, they need 
to work with human resources to carefully handle the problem. If the situ-
ation worsens, they need to be able to pull in the information security and 
IT departments to audit recent activity by the employee or contractor, and 
perform targeted monitoring of his activity on an ongoing basis.
It is important that you plan ahead, however, or you will be prohibited 
from performing those actions by employee privacy laws. You need to put 
policies in place that clearly define when you can conduct targeted auditing 
and monitoring of an individual employee or contractor’s online activity. 
You also must have clearly defined practices that are consistently enforced 
to implement those policies.
Now that you understand insider IT sabotage, you have a choice of where 
to  go  next  in  this  book.  If  you  want  to  follow  up  immediately  on  the 
insider IT sabotage problem, you can go to Chapter 6, Best Practices for 
the  Prevention and Detection of Insider Threats, or to Chapter 7, Technical 
Insider Threat Controls.
If you want to understand the whole landscape of insider threats, you can 
continue with Chapter 3, Insider Theft of Intellectual Property.

61
Chapter  3
Insider Theft of 
Intellectual Property
Insider theft of intellectual property (IP): an insider’s use of IT to steal 
proprietary information from the organization. This category includes 
industrial espionage involving insiders.
Intellectual property: intangible assets created and owned by an organiza-
tion that are critical to achieving its mission.1
1.  While  IP  does  not  generally  include  individuals’  Personally  Identifiable  Information  (PII), 
which an organization does not own, it could include a database that the organization developed that 
contains PII.
Types of IP Stolen
The types of IP stolen in the cases in our database include the following:
•  Proprietary software/source code
•  Business plans, proposals, and strategic plans
•  Customer information
•  Product information (designs, formulas, schematics)

Chapter 3.  Insider Theft of Intellectual Property
62
What if one of your scientists or engineers walked away with your most 
valuable trade secrets? Or a contract programmer whose contract ended 
took your source code with him—source code for your premier product 
line? What if one of your business people or salespeople took your strategic 
plans with him to start his own competing business? And possibly worst of 
all, what if one of them gave your intellectual property to a foreign govern-
ment or organization? Once your IP leaves the United States it’s extremely 
difficult, often impossible, to get it back.
Those are the types of crimes we will examine in this chapter.  Organizations 
in almost every critical infrastructure sector have been victims of insider 
theft of IP.
In one case of insider theft of IP, an engineer and an accomplice stole trade 
secrets from four different high-tech companies they worked for, with the 
intention of using them in a new company they had created with funding 
from a foreign country. In another, a company discovered that an employee 
had copied trade secrets worth $40 million to removable media,2 and was 
using the information in a side business she had started with her husband. 
In yet another, a large IT organization didn’t realize that it had been victim-
ized until it happened to see a former employee at a trade show selling a 
product that was remarkably similar to the organization’s!
When  we  began  examining  the  theft  of  IP  cases  in  our  database  we 
 surmised that insiders probably stole IP for financial reasons. We were very 
wrong about that! We found that quite the opposite is true: Very few insid-
ers steal intellectual property in order to sell it. Instead, they steal it for a 
business advantage: either to take with them to a new job, to start their own 
 competing business, or to take to a foreign government or organization.
 
2.  Removable media: computer storage  media that  is  designed to be  removed  from the  computer 
 without  powering  the  computer  off.  Examples  include  CDs,  USB  flash  drives,  and  external  hard 
disk drives.
Very few insiders steal intellectual property in order to sell it. Instead, they 
steal it for a business advantage: either to take with them to a new job, to 
start their own competing business, or to take to a foreign government or 
organization.

Free ebooks ==>   www.Ebook777.com
63
   Insider Theft of Intellectual Property
to our data! We don’t have a single case in our database in which a system 
administrator stole intellectual property, although we do have a few cases 
involving other IT staff members. However, keep in mind that we only 
have cases in which the perpetrator was discovered and caught; it is pos-
sible that system administrators are stealing IP and are simply getting away 
with it.
In fact, the insiders who steal IP are usually current employees who are 
scientists, engineers, programmers, or salespeople. Most of them are male. 
We checked the U.S. Bureau of Labor Statistics to determine if most of those 
types of positions are held by men, but the results, listed here for 2010, were 
inconsistent.
•  12.9%  of  all  architectural  and  engineering  positions  were  held  by 
women.
•  45.8% of all biological scientists were women.
•  33.5% of all chemists and materials scientists were women.
•  26.2% of all environmental scientists and geoscientists were women.
•  39.5% of all other physical scientists were women.
•  49.9% of all sales and related occupations were held by women.3
 
3.  ftp://ftp.bls.gov/pub/special.requests/lf/aat11.txt
Insiders who steal IP are usually current employees who are scientists, 
engineers, programmers, or salespeople.
www.Ebook777.com

Chapter 3.  Insider Theft of Intellectual Property
64
access, and usually steal it at work during normal business hours. In fact, 
they  steal  the  same  information  that  they  access  in  the  course  of  their 
 normal job. Therefore, it can be very difficult to distinguish illicit access 
from legitimate access.
Fortunately,  we  have  come  up  with  some  good  strategies  based  on  our 
MERIT model of insider theft of intellectual property that we will detail 
in this chapter. The first half of this chapter describes the model at a high 
level. In the second half of the chapter we will dig deeper into the techni-
cal methods used in committing these crimes and mitigation strategies that 
you should consider based on all of this information.
The MERIT model describes the profile of insider theft of IP by identifying 
common patterns in the evolution of the incidents over time. These pat-
terns are strikingly similar across the cases in our database. Unfortunately, 
we were not quite as lucky in creating our theft of IP model as we were in 
creating our insider IT sabotage model. While we found one very distinct 
pattern that was exhibited in almost every IT sabotage case, we could not 
identify a single pattern for theft of IP. Instead, we ended up identifying 
two overlapping models.
•  Entitled Independent:  an  insider  acting  primarily  alone  to  steal 
 information to take to a new job or to his4 own side business
•  Ambitious Leader: a leader of an insider crime who recruits insiders to 
steal information for some larger purpose
The cases in our database break up just about 50/50 between the two 
models. In addition, the models have different but overlapping patterns; 
the  Ambitious  Leader  model  builds  from  the  Entitled  Independent 
model. This is good news, as our suggested mitigation strategies apply 
to both models.
4.  Most of the insiders who stole IT property were male. Therefore, male gender is used to describe the 
generic insider in this chapter.
Insiders steal information for which they already have authorized access, 
and usually steal it at work during normal business hours. In fact, they 
steal the same information that they access in the course of their  normal 
job. Therefore, it can be very difficult to distinguish illicit access from 
 legitimate access.

65
   Insider Theft of Intellectual Property
 
5.  Material in this chapter includes portions of previously published works. Specifically, the insider 
theft of intellectual property modeling work was published by Andrew Moore, Dawn Cappelli, Dr. Eric 
Shaw, Thomas Caron, Derrick Spooner, and Randy Trzeciak in the Journal of Wireless Mobile Networks, 
Ubiquitous Computing, and Dependable Applications [Moore 2011a]. An earlier version of the model was 
published by the same authors in [Moore 2009].
6.  Digital watermarking:  the  process  of  embedding  information  into  a  digital  signal  that  may 
be used to verify its authenticity or the identity of its owners, in the same manner as paper bearing 
a watermark for visible identification (Wikipedia).
7.  Digital rights management (DRM): a term for access control technologies that are used by  hardware 
manufacturers,  publishers,  copyright  holders,  and  individuals  to  limit  the  use  of  digital  content 
and devices.
8.  Data loss prevention (DLP) systems: refers to systems designed to detect and prevent  unauthorized 
use and transmission of confidential information (Wikipedia). Also commonly called data leakage tools.

Chapter 3.  Insider Theft of Intellectual Property
66
insider as he is setting up his attack—planting malicious code or creating a 
backdoor account—you cannot really detect theft of IP until the information 
is actually in the process of being stolen—as it is being copied to removable 
media or emailed off of the network. In other words, your window of oppor-
tunity can be quite small, and therefore you need to pay close attention when 
you see potential indicators of heightened risk of insider theft of IP.
We  have  some  “good-news”  cases  that  indicate  that  it  is  possible  to 
detect theft of IP using technical measures in time to prevent disastrous 
 consequences.
•  An organization detected IP emailed from a contractor’s email account 
at work to a personal email account, investigated, and discovered sig-
nificant data exfiltration by the contractor. The organization found the 
contractor was working with a former employee to steal information 
to start a competing business. Obviously, the stolen IP was extremely 
valuable, as the contractor was arrested, convicted, ordered to pay a 
fine of $850,000, and sentenced to 26 years in prison!
•  After a researcher resigned and started a new job, his former employer 
noticed that he had downloaded a significant number of proprietary 
documents  prior  to  his  departure.  This  led  to  his  arrest  before  he 
could  transfer  the  information  to  his  new  employer’s  network.  The 
 information was valued at $400 million.
•  During  an  organization’s  routine  auditing  of  HTTPS traffic9  it 
 discovered that an employee who had turned in his resignation had 
exfiltrated  proprietary  source  code  on  four  separate  occasions  to  a 
server  located  outside  the  United  States.  Although  the  employee 
claimed the transfer was accidental, and that he had only uploaded 
open source information, he was arrested.
 
9.  HTTPS traffic: network traffic that is encrypted via the Secure Sockets Layer protocol.

Impacts
67
has  been  given  to  competitors.  More  than  half  of  our  theft  of  IP  cases 
involved trade secrets.
In addition, impacts in these cases can reach beyond the victim  organization. 
Here are some examples.
•  Source code for products on the U.S. Munitions List was shared with 
foreign military organizations.10
•  A government contractor stole passwords that provided unauthorized 
access to sensitive, potentially classified information.
•  Source code was added to software in a telecommunications company 
that enabled the perpetrators to listen in on phone calls made by 103 
high-ranking government and nongovernment officials.
Estimated financial impacts in the theft of IP cases in the CERT database 
averaged around $13.5 million (actual) and $109 million (potential).11 The 
median  estimated  financial  impact  was  $337,000  (actual)  and  $950,000 
(potential). This means that a few extremely high-impact cases skew the 
average significantly. The highest estimated potential financial losses were
•  $1 billion in a high-tech case in the IT sector
•  $600 million in a telecommunications company
•  $500 million in a pharmaceutical company
•  $400 million in a chemical company
•  $100 million in a biotech company
The highest estimated actual financial losses were
•  $100 million in a manufacturing business
•  $40 million in a manufacturing business
•  $6 million in the financial services sector
•  $1.5 million in a high-tech software development organization
10.  In U.S. law, the U.S. Munitions List is the list of weapons and similar items that are subject to 
 licensing because of the danger they pose. The U.S. Munitions List is related to the International Traffic 
in Arms Regulations. Farlex Financial Dictionary. Copyright © 2009 Farlex, Inc. 
11.  Twenty-five of the 85 cases of theft of IP had known estimates on actual or potential financial impact.
More than half of our theft of IP cases involved trade secrets.

Chapter 3.  Insider Theft of Intellectual Property
68
These are only some of the cases with the highest financial consequences. 
We provided this list for several reasons. First, we are frequently asked how 
to calculate return on investment (ROI) for insider threat mitigation. That is 
a very difficult question, and one that has not yet been answered adequately 
for cybersecurity in general. To start, you should identify what your critical 
assets are, and estimate the potential loss if those assets were to leave your 
organization. The losses we listed from actual cases should help you to con-
vince your management that insider threat is not to be taken lightly!
Second,  although  almost  half  of  the  insider  theft  of  IP  cases  occurred 
in the IT sector, we want to emphasize that these types of crimes have 
resulted in significant losses in other sectors as well.
We  strongly  suggest  that  you  pay  close  attention  to  this  chapter  if  you 
are  concerned  about  the  security  of  your  proprietary  and  confidential 
information.  Now  that  we  have  caught  your  attention,  let’s  look  at  the 
characteristics and “big picture” of insider theft of intellectual property.
General Patterns in Insider Theft of Intellectual  
Property Crimes
The intent of our MERIT model of insider theft of intellectual property is to 
describe the general profile of insider theft of IP crimes. The MERIT models 
describe the patterns in the crimes as they evolve over time—profiling the 
life cycle of the crime, rather than profiling only the perpetrator.
The MERIT model of insider theft of IP was first published in 2009. The 
model was created using system dynamics modeling, which is described 
in the original report and in Appendix F, System Dynamics Background. 
Over the years, however, we have found that a higher-level view of that 
model  is  more  useful  in  describing  the  patterns  to  practitioners  so  that 
clear, actionable guidance can be provided for mitigating these incidents. 
That higher-level form of the model and accompanying countermeasure 
guidance is presented in the remainder of this chapter.
As mentioned earlier, our overall model for theft of IP actually consists of 
two models: the Entitled Independent and the Ambitious Leader; we will 
present those one at a time. We have broken each model down into small 
pieces in this chapter in order to make it more understandable. The full 
model of the Entitled Independent is shown in Figure 3-1. Figure 3-2 shows 
the full model of the Ambitious Leader.

69
General Patterns in Insider Theft of Intellectual Property Crimes
Figure 3-1  MERIT model of insider theft of IP:  Entitled  Independent
Organization’s
Denial of
Insider Request
Insider’s
Planning to Go
to Competitor
Level of Technical
and Behavioral
Monitoring
Organization’s
Discovery of Theft
Opportunity
to Detect
Theft
Information
Stolen
Insider’s Desire
to Steal
Insider’s
Dissatisfaction
Insider’s
Entitlement
Insider’s
Contribution
Precipitating Event
(e.g., Proposal by
Competitor)
Figure 3-2  MERIT model of insider theft of IP: Ambitious Leader
Insider’s
Contribution
Insider’s
Entitlement
Precipitating Event
(e.g., Proposal by
Competitor)
Insider’s
Planning to Go
to Competitor
Level of Technical
and Behavioral
Monitoring
Perpetrated
Deceptions
Organization’s
Discovery of
Deceptions
Organization’s
Discovery of Theft
Insider’s
Concern Over
Being Caught
Insider’s Desire
to Steal
Opportunity
to Detect
Theft
Extent of
Planning to
Steal
Information
Stolen
Increasing
Access to
Information
Recruitment
of Other
Insiders

Chapter 3.  Insider Theft of Intellectual Property
70
The Entitled Independent
This section describes the model of the Entitled Independent, an insider 
acting primarily alone to steal information to take to a new job or to his 
own side business.
 
NOTE
Most insiders felt entitled to take the information they were accused of 
stealing.
Figure 3-3 Insider entitlement
Insider’s
Contribution
Insider’s
Entitlement

The Entitled Independent
71
 

Chapter 3.  Insider Theft of Intellectual Property
72
 longer necessary. This mechanism has been very successful in controlling 
the erosion of access controls in the organization.
Some insiders exhibited an unusual degree of possessiveness toward their 
work before stealing it. For instance, a few insiders kept all source code on 
their own laptops and refused to store it on the file servers, so they would 
have full control over it. This type of behavior should be recognized and 
remediated as early as possible.
Insider Dissatisfaction
Dissatisfaction played a role in many of the Entitled Independent cases. Dis-
satisfaction typically resulted from the denial of an insider’s request, as shown 
in Figure 3-4. Denial of an employee or contractor request can lead to dissat-
isfaction, which in turn decreases the person’s desire to contribute. This also 
affects the person’s sense of loyalty to you. Dissatisfaction often spurred the 
insider in our cases to look for another job; the majority had already accepted 
positions with another company or had started a competing company at the 
time of their theft. Once the insider receives a job offer and begins planning to 
go to a competing organization, his desire to steal information increases. This 
desire is amplified by his dissatisfaction with his current employer and his 
sense of entitlement to the products  developed by his group.
 
Dissatisfaction often spurred the insider in our cases to look for 
another job.
Figure 3-4 Insider dissatisfaction leading to  compromise
Organization’s
Denial of
Insider Request
Precipitating Event
(e.g., Proposal by
Competitor)
Insider
Planning to Go
to Competitor
Insider’s
Dissatisfaction

The Entitled Independent
73
 
Issues Leading to Dissatisfaction
Issues leading to dissatisfaction in the CERT database include the 
 following:
•  Disagreement over ownership of intellectual property
•  Financial compensation issues
•  Disagreement over benefits
•  Relocation issues
•  Hostile work environment
•  Mergers and acquisitions
•  Company attempting to obtain venture capital
•  Problems with supervisor
•  Passed over for promotion
•  Layoffs

Chapter 3.  Insider Theft of Intellectual Property
74
access even when  contractors and contracting organizations change on a 
 frequent basis?
Insider Theft and Deception
As shown in Figure 3-5, eventually the desire to steal information becomes 
strong enough, leading to the theft and finally the opportunity for you to 
detect the theft. Perhaps someone observes an employee’s actions, or con-
sequences of those actions, that seem suspicious in some way. The most 
likely person to discover an insider theft according to our data is a non-
technical employee; in cases where we were able to isolate the person who 
discovered  the  incident,  72%  were  detected  by  nontechnical  employees. 
Therefore,  you  should  have  processes  in  place  for  employees  to  report 
suspicious behavior, employees should be aware of those processes, and 
you should follow up on reports quickly, particularly if they concern an 
employee who fits the profile described in our models.
NOTE
The insider’s plan to leave the organization, dissatisfaction, and his sense 
of entitlement all contribute to the decision to steal the information.
Figure 3-5 Insider theft and deception
Insider
Planning to Go
to Competitor
Insider’s
Dissatisfaction
Organization’s
Discovery of Theft
Level of Technical
and Behavioral
Monitoring
Opportunity
to Detect
Theft
Information
Stolen
Insider’s Desire
to Steal
Insider’s
Entitlement

The Entitled Independent
75
Our Entitled Independents did not exhibit great concern with being caught. 
Even  though  signed  IP  agreements  were  in  place  in  around  40%  of  the 
cases, fewer than one-quarter of the Entitled Independents tried to deceive 
the organization while taking their information. While explicit deception 
is not a major factor in most of these crimes, the fact that it did occur in 
 one-fourth of them suggests that you need to anticipate it when designing 
your countermeasures.
For  example,  upon  announcing  his  resignation,  one  insider  lied  to  his 
manager and said he had no follow-on employment, even though he had 
told a coworker about his new job at a competitor. If you become aware of 
deliberate deception like this, it may be an indicator of problems to come. 
Deceptions generally make it harder for you to sense the risk of theft, and 
that is why the insider does it. But if you are vigilant, deceptions may be 
discovered, alerting you to increased risk of insider threat. If the organiza-
tion in this example had known that the insider had given contradictory 
information to his manager and coworker, it may have been forewarned of 
the heightened risk.
In general, your accurate understanding of your risk is directly related 
to  your  ability  to  detect  the  insider’s  illicit  actions.  With  sufficient 
levels  of  technical  and  behavioral  monitoring,  these  actions  may  be 
 discoverable.
 
NOTE
Most information was stolen within one month of resignation using a 
 variety of methods.

Chapter 3.  Insider Theft of Intellectual Property
76
committing their final theft right before  resignation. However, fewer than 
one-third of the insiders continued their theft for more than one month.
One insider planned with a competing organization abroad and transferred 
documents to the company for almost two years prior to her resignation. 
However, for the most part, the insiders did steal the information quickly 
upon resignation.
 
NOTE
The one-month window includes the month before the insider resigns and 
the month after he resigns—actually two months in total.

The Entitled Independent
77
 
12.  Data leakage tools: systems designed to detect and prevent unauthorized use and transmission of 
confidential information (Wikipedia). Also commonly called data loss prevention (DLP) systems.

Chapter 3.  Insider Theft of Intellectual Property
78
IP agreement, reminding them of the contents of the IP agreement while 
they are walking out the door.
The Ambitious Leader
This section describes the Ambitious Leader model. These cases involve a 
leader who recruits insiders to steal information with him—essentially a 
“spy ring.” Unlike the Entitled Independent, these insiders don’t only want 
the assets they created or have access to, they want more: an entire product 
line or an entire software system. They don’t have the access to steal all that 
they want themselves, so they recruit others into their scheme to help.
We omitted the What Can You Do? section from most of the Ambitious 
Leader scenarios because it is so similar to the Entitled Independent model. 
But we provide extensive advice at the end of the chapter when we explore 
the technical details in all of the cases.
More than half of the Ambitious Leaders planned to develop a competing 
product or use the information to attract clients away from the victim orga-
nization. Others (38%) worked with a new employer that was a competitor. 
Only 10% actually sold the information to a competing  organization.
About one-third of our theft of IP cases were for the benefit of a foreign 
government or organization. The average financial impact for these cases 
was more than four times that of domestic IP theft. In these cases, loyalty to 
the insider’s native country trumped loyalty to the employer. Insiders with 
an affinity toward a foreign country were motivated by the goal of bringing 
value to, and sometimes eventually relocating in, that country.
In general, the cases involving a foreign government or organization fit 
the Ambitious Leader model. However, because the consequences of these 
crimes are much more severe, and both government and private organi-
zations are so concerned about this threat, we have included a separate 
section  at  the  end  of  the  Ambitious  Leader  model  that  analyzes  those 
crimes in a bit more depth.
About one-third of our theft of IP cases were for the benefit of a foreign 
government or organization. The average financial impact for these cases 
was more than four times that of domestic IP theft.

The Ambitious Leader
79
 

Chapter 3.  Insider Theft of Intellectual Property
80
of  other  insiders.  Other  forms  of  planning  involved  creating  a  new 
business in almost half of the cases, coordinating with a competing orga-
nization in almost half of the cases, and collecting information in advance 
of the theft.
This aspect of the insider behavior is reflected in Figure 3-6, which describes 
the Ambitious Leader formulating plans to steal the information prior to 
the actual theft. This extensive planning is an additional potential point 
of exposure of the impending theft, and therefore results in measures by 
the insider to hide his actions. In most of the Ambitious Leader cases, the 
insider was planning the theft a month or more before his departure from 
the organization.
The one-month window surrounding resignation holds for most  Ambitious 
Leaders just as it does for Entitled Independents.
Increasing Access
In  more  than  half  of  the  Ambitious  Leader  cases,  the  lead  insider  had 
 authorization for only part of the information targeted and had to take steps 
to gain additional access. In one case involving the transfer of proprietary 
documents to a foreign company, the lead insider asked her supervisor to 
assign her to a special project that would increase her access to highly sen-
sitive information. She did this just weeks prior to leaving the country with 
a company laptop and numerous company documents, both physical and 
electronic.
Figure 3-6 Theft planning by Ambitious Leader
Information
Stolen
Extent of
Planning to
Steal
Insider’s
Concern Over
Being Caught
Opportunity
to Detect
Theft
Insider’s Desire
to Steal

The Ambitious Leader
81
As shown in Figure 3-7, the recruitment of additional insiders is the  primary 
means Ambitious Leaders use to gain access to more information. The need 
for recruitment increases the amount of planning activity  necessary to coor-
dinate insider activities.
Organization’s Discovery of Theft
There are many more avenues for you to detect heightened risk of insider 
theft of IP in Ambitious Leader cases than in Entitled Independent cases. 
Entitled Independents are often fully authorized to access the information 
they steal, and do so very close to resignation with very little planning. 
In addition, Entitled Independents rarely act as if what they are doing is 
wrong, probably because they feel a proprietary attachment to the informa-
tion or product. Ambitious Leaders, on the other hand, often have to gain 
access to information for which they are not authorized. This involves, in 
part, coordinating the activities of other insiders and committing deception 
to cover up the extensive planning required.
What Can You Do?
Figure 3-8 illustrates the avenues available for you to continually assess the 
risk you face regarding theft of IP. Because deception is such a prominent 
factor in Ambitious Leader cases, its discovery may be a better means to 
detect heightened insider risk here than in Entitled Independent cases.
Figure 3-7 Increasing access by the Ambitious Leader
Information
Stolen
Recruitment
of Other
Insiders
Increasing
Access to
Information
Opportunity
to Detect
Theft
Insider’s Desire
to Steal

Chapter 3.  Insider Theft of Intellectual Property
82
 
Figure 3-8  Organization’s discovery of theft of IP in Ambitious Leader cases
Information
Stolen
Increasing
Access to
Information
Extent of
Planning to
Steal
Perpetrated
Deceptions
Insider’s
Concern Over
Being Caught
Opportunity
to Detect
Theft
Level of Technical
and Behavioral
Monitoring
Organization’s
Discovery of Theft

Theft of IP inside the United States Involving Foreign Governments or Organizations
83
provides a window of opportunity for you to detect theft prior to employee 
termination.
Of course, the earlier you can become aware of illicit plans the better. Early 
awareness depends on behavioral as well as technical monitoring and is 
more likely to catch incidents involving Ambitious Leaders than Entitled 
Independents. In Ambitious Leader scenarios, you need to look for evolv-
ing plans and collusion by insiders to steal information, including attempts 
to gain access to information over and above that for which an employee is 
authorized. There were behavioral or technical precursors to the crime in 
all of the Ambitious Leader cases.
One insider, over a period of several years, exhibited suspicious patterns 
of foreign travel and remote access to organizational systems while claim-
ing  medical  sick  leave.  It  is  not  always  this  blatant,  but  signs  are  often 
 observable if you are vigilant.
Theft of IP inside the United States Involving Foreign 
Governments or Organizations
This  section  focuses  on  cases  of  malicious  insiders  who  misused  a 
 company’s systems, data, or network to steal intellectual property from an 
organization inside the United States for the benefit of a foreign entity—
either an existing foreign organization or a new company that the insiders 
established in a foreign country.13 These cases fit the problem described in 
the Annual Report to Congress on Foreign Economic Collection and Industrial 
Espionage, FY07 prepared by the Office of the National Counterintelligence 
Executive.
The United States remains the prime target for foreign economic collec-
tion and industrial espionage as a result of its worldwide technological 
and business leadership. Indeed, strong US international competitiveness 
underlies the continuing drive by foreign collectors to target US informa-
tion and technology.14
13.  Material in this section includes portions from a previously published work. Specifically, a joint 
CyLab and CERT Program article was published as “Spotlight On: Insider Theft of Intellectual Property 
inside the U.S. Involving Foreign Governments or Organizations” by Derrick Spooner, Dawn Cappelli, 
Andrew Moore, and Randy Trzeciak [Spooner 2008].
14.  See www.ncix.gov/publications/reports/fecie_all/fecie_2007/FECIE_2007.pdf.

Chapter 3.  Insider Theft of Intellectual Property
84
These cases also include activities defined by the Office of the National 
Counterintelligence  Executive  as  economic  espionage  or  industrial 
 espionage.
Economic Espionage—the conscious and willful misappropriation of trade 
secrets with the knowledge or intent that the offense will benefit a foreign govern-
ment, foreign instrumentality, or foreign agent.15
Industrial Espionage—the conscious and willful misappropriation of trade 
secrets related to, or included in, a product that is produced for, or placed in, inter-
state or foreign commerce to the economic benefit of anyone other than the owner, 
with the knowledge or intent that the offense will injure the owner of that trade 
secret.16
Cases that involve foreign beneficiaries can differ from other theft of IP 
cases because the insiders may have a sense of duty or loyalty to their 
countries  of  origin  that  overrides  any  loyalty  to  their  employer.  More-
over, some of these cases suggest that some foreign entities appear to be 
interested in recruiting insiders to steal IP to advance businesses in that 
particular  country.  Competing  loyalties,  coupled  with  recruitment  of 
employees in U.S. businesses by foreign nations or organizations, make 
this type of crime a potent threat for organizations that rely on IP for com-
petitive advantage.
There are several reasons for heightened concern about this kind of crime. 
The impact of a crime that extends outside the jurisdiction of U.S. law 
enforcement on an organization can be substantially greater than a case 
that remains within U.S. jurisdiction. Insiders who leave the United States 
may be difficult or impossible to locate and arrest. And even if the insider 
were  located  and  arrested,  extradition  to  the  United  States  would  be 
required. Therefore, there can be more risk from an employee who intends 
to leave the United States following the theft than from employees con-
templating criminal acts against their employer who remain in the United 
States.
15.  Ibid.
16.  Ibid.
NOTE
We have not included any cases of national security espionage in 
this book.

Theft of IP inside the United States Involving Foreign Governments or Organizations
85
In addition, it can be very difficult to recover stolen IP once it leaves the 
United States. In cases within U.S. borders, companies that receive the sto-
len IP can suffer similar consequences under the same laws as the insiders 
if they use the stolen IP for their own advantage. Thus, domestic organiza-
tions are under greater obligation to cooperate with authorities and return 
all stolen IP than foreign organizations might be.
Who They Are
The majority of the insiders worked as either a scientist or an engineer. 
Males committed most of the incidents. Of the cases that identify citizen-
ship, about half were foreign nationals, about 40% were naturalized U.S. 
citizens, two were U.S. citizens, and the rest were resident aliens or had 
dual citizenship.
The insiders’ countries of origin, for cases in which the information was 
available, are shown in Table 3-1.
About one-fourth of the cases involved at least one accomplice who was 
also an insider. Some of those involved multiple insiders; one case involved 
14 insiders in all! Almost 40% had at least one external accomplice.
Table 3-1  Countries of Origin (When Known)
Country
Number of Cases
China
13
United States
2
Taiwan
2
Canada (naturalized citizen from China)
2
South Korea
1
Germany
1
Russia
1
Iran
1
Ecuador
1
India
1
Dual citizenship, China and United States
1

Chapter 3.  Insider Theft of Intellectual Property
86
Note that when multiple insiders are involved in a case we only code it as 
a single case, and code details for the primary insider. Additional informa-
tion about conspirators is also coded for the case. If you are interested in 
a detailed description of the information coded for each case, please see 
Appendix D, Insider Threat Database Structure.
What They Stole
All  of  these  insiders  stole  intellectual  property  in  digital  form,  physical 
form, or both. The methods used were consistent with those described else-
where in this chapter.
Table 3-2 contains the details known for these cases. Damage amounts are 
supplied  when  they  were  available.  We  only  used  the  term  trade secrets 
when that term was used in the case file; otherwise, we used the descrip-
tion supplied in the case file.
Table 3-2  Breakdown of Cases17
Sector
Number 
of Cases
Damages17
What Was Stolen
Information and 
 telecommunications
11
1 case, 
$1  billion
1 case, 
$600 million
Trade secrets 
(4 cases)
Source code 
(3 cases)
1 case, 
$1 million
1 case, 
$100,000
1 case, $5,000
6 cases, 
Unknown
Confiden-
tial  product 
 information 
(3 cases)
Confidential 
manufacturing 
 information (1 case)
Proprietary 
 documents and 
source code 
(1 case)
17.  In the majority of the cases, damages reported were in the form of potential loss to the organization 
as reported in court documents.

Theft of IP inside the United States Involving Foreign Governments or Organizations
87
Chemical indus-
try and hazardous 
 materials
7
1 case, 
$400 million
1 case, 
$100 million
1 case, 
$50 million to 
$60 million
4 cases, 
Unknown
Trade secrets 
(5 cases)
Sensitive product 
information
(1 case)
Confidential 
 documents 
(1 case)
Manufacturing
3
1 case, 
$40 million
1 case, 
$32 million
Trade secrets 
(2 cases)
Confidential 
 documents 
(1 case)
Banking and finance
1
$5,000
Source code
Commercial facilities
1
Unknown
Trade secrets
Defense industrial 
base
1
Unknown
Source code
Education
1
$3 million
Patentable 
 proprietary 
 information
Energy
1
Unknown
Sensitive software
Government– Federal
1
Unknown
Government 
restricted 
 information
Public health
1
$500 million
Trade secrets
Water
1
$1 million
Trade secrets and 
source code

Chapter 3.  Insider Theft of Intellectual Property
88
Why They Stole
The specific motives fall into several categories.
•  To form a new competing business: One-third of the insiders stole the 
IP to establish a new business venture in a foreign country that would 
compete with their current employer. In all of these cases, the insiders 
had at least one accomplice who assisted them with their theft, with 
forming and/or running the new business, or with both. All but one 
of these insiders had already started their business before they left the 
victim organization; in fact, some of them had already established the 
business and had made money for quite some time.
•  To take to a new employer in a competing business: More than 40% of 
these insiders stole IP to take to their new employers, businesses located 
outside the United States that competed with their current employer. In 
all but two of these cases, the insiders had already accepted jobs with 
the competitors before leaving the victim organization.
•  To take to their home country:  In  three  of  the  cases,  this  was  the 
 somewhat vague reason they gave for their theft. In another case, the 
insider stated he wanted to “benefit the homeland.”
•  To sell to a competitor: In two cases, the insider stole the information to 
sell to a competitor in another country outside the United States.
Mitigation strategies for these cases are the same as for any other cases of 
insider theft of intellectual property, which is covered in the next section.
 

Mitigation Strategies for All Theft of Intellectual Property Cases 
89
legal,  data  owners,  physical  security,  information  security/ information 
 technology, and other relevant areas of the organization. It is critical that 
all levels of management recognize and acknowledge the threat posed by 
their  current  and former employees, contractors, and  business partners, 
and take appropriate steps to mitigate the associated risk. It may not be 
realistic to expect that all intellectual property exfiltrated by insiders will 
be stopped before the information leaves your network, but it is realistic to 
expect that you can implement countermeasures into your infrastructure 
and  business processes to allow you to detect as many incidents as pos-
sible, thereby minimizing the financial impact on your organization.
The remainder of this chapter describes potential countermeasures that we 
believe could be effective in mitigating insider theft of intellectual property.
Exfiltration Methods
We begin this section by providing more in-depth details of the  technical 
methods  used  by  insiders  to  steal  IP  in  our  database.  Methods  varied 
widely,  but  the  top  three  methods  used  were  email  from  work,  remov-
able media, and remote network access. Table 3-3 describes the primary 
 methods of exfiltration.
Table 3-3  Exfiltration Methods
Exfiltration Method
Description
Email
Insiders exfiltrated information through their work 
email account. The email may have been sent to a 
personal email account or directly to a competitor or 
foreign government or organization. Insiders used 
email attachments or the body of the email to  transmit 
the sensitive information out of the network.
An overall solution should include policies, business processes, and tech-
nical solutions that are endorsed by senior leadership in HR, legal, data 
owners, physical security, information security/information technology, 
and other relevant areas of the organization.
Continues

Chapter 3.  Insider Theft of Intellectual Property
90
Table 3-3  Exfiltration Methods (Continued)
Exfiltration Method
Description
Removable media
Common removable media types were USB devices, 
CDs, and removable hard drives.
Printed  documents
Insiders printed documents or screenshots of 
 sensitive information, and then physically removed 
the hard copies from the organization.
Remote network 
access
Insiders remotely accessed the network through a 
virtual private network (VPN) or other remote  channel 
to download sensitive information from an off-site 
location.
File transfer
The insider was at work, on the company network, and 
transferred a file outside of the network using the Web, 
File Transfer Protocol (FTP),18 or other methods. 
Although email could potentially fit this category, we 
thought that email should be considered  separately 
due to the large number of crimes that used email.
Laptops
Insiders exfiltrated data by downloading IP onto a 
laptop at work and bringing it outside the workplace. 
For example, one insider was developing an applica-
tion for his company on a laptop and later purposely 
leaked the source code. In other cases the insiders 
simply downloaded sensitive files onto their laptops 
for personal or business use later.
 
18.  File Transfer Protocol (FTP): a communication standard used to transfer files from one host to 
another over a network, such as the Internet (Wikipedia).

Mitigation Strategies for All Theft of Intellectual Property Cases 
91
the insiders in the database who stole IP. Removal methods included in 
this  category  were  email,  a  remote  network  access  channel  (originating 
 externally), and network file transfer (originating outside the network).
About one-fourth of the insiders used their work email account to send the 
IP outside the network, either sending IP to their personal email account, 
or  directly  emailing  the  IP  to  a  competitor  or  foreign  government  or 
 organization.
 
About one-fourth of the insiders used their work email account to send the 
IP outside the network.

Chapter 3.  Insider Theft of Intellectual Property
92
 
19.  Proxies: A proxy server, more commonly known as a proxy, is a server that routes network traffic 
through itself, thereby masking the origins of the network traffic.

Mitigation Strategies for All Theft of Intellectual Property Cases 
93
exfiltration  method.  You  should  carefully  consider  the  balance  between 
security and personal use of email and Web services from your network.
As  mentioned,  most  insiders  steal  IP  within  30  days  of  leaving  an 
 organization. You should consider a more targeted monitoring strategy for 
employees and contractors when they give notice of their exit. For instance, 
check  your  email  logs  for  emails  they  sent  to  competitors  or   foreign 
 governments or organizations. Also check for large email attachments they 
sent to Gmail, Hotmail, and similar email accounts.
Further, you should consider inspecting available log traffic for any indi-
cators  of  suspicious  access,  large  file  transfers,  suspicious  email  traffic, 
after-hours  access,  or  use  of  removable  media  by  resigning  employees. 
Central  logging  appliances  and  event correlation20  engines  may  help 
craft automated queries that reduce an analyst’s workload for routinely 
 inspecting this data.
Host Data Exfiltration
Host-based exfiltration was the second most common method of  removing 
IP  from  organizations;  close  to  half  of  the  cases  involved  an  insider 
 removing data from a host computer and leaving the organization with 
it. In these cases, insiders often used their laptops to remove data from 
the  organization.  We  had  difficulty  determining  the  exact  ownership 
and authorization of the laptops used. However, we do know that about 
 one-sixth of the insiders who stole IP used laptops taken from the organiza-
tion’s site during normal work hours. Half of them transferred proprietary 
software  and  source  code;  the  other  half  removed  sensitive  documents 
from the  organization.
In  one  case,  the  insider  worked  for  a  consulting  company  and  stole 
 proprietary software programs from a customer by downloading them to 
a laptop. He attempted to disguise the theft by deleting references to the 
victim organization contained in the program, and then attempted to sell 
portions of the program to a third party for a large sum of money.
Another  case  involved  an  insider  who  accessed  and  downloaded  trade 
secrets to his laptop after he accepted an offer from a foreign competitor. He 
gave his employer two weeks’ notice, and continued to steal  information 
until he left.
20.  Event correlation: a technique for making sense of a large number of events and pinpointing the 
few events that are really important in that mass of information (Wikipedia).

Chapter 3.  Insider Theft of Intellectual Property
94
By far, the most common method of host-based exfiltration in the database 
was removable media; 80% of these cases involved trade secrets, and the 
majority of those insiders took the stolen trade secrets to a competitor. The 
type of removable media used varied. Where information was available, 
we determined that insiders most often used writable CDs. Thumb drives 
and external hard disks were used in just 30% of the cases. However, the 
type of removable media used has changed over time. Insiders primarily 
used CDs prior to 2005. Since 2005, however, most insiders using remov-
able  media  to  steal  IP  use  thumb  drives  and  external  hard  drives.  This 
trend indicates that changes in technology are providing new and easier 
methods of stealing data from host computers.
In  one  case,  an  insider  resigned  from  his  organization  after  accepting  a 
position  at  another  organization.  He  downloaded  personal  files  as  well 
as the organization’s proprietary information onto CDs. Despite signing a 
nondisclosure agreement, the insider took the trade secrets to a competitor.
In a similar example, an insider received an offer from a competitor three 
months prior to resignation. He lied about his new position and employ-
ment status to coworkers. Only days before leaving the organization, he 
convinced a coworker to download his files to an external hard drive, 
supposedly to free up disk space. He came into work at unusual hours 
to  download  additional  proprietary  information  onto  a  CD.  Finally, 
he  took  this  information  with  him  to  his  new  position  at  a  competing 
 organization.
What Can You Do?
It  is  unlikely  that  the  victim  organizations  in  our  database  prohibited 
removable  media  in  their  daily  computing  environments.  You  should 
consider carefully who in your organization really needs to use remov-
able  media.  Perhaps  access  to  removable  media  is  a  privilege  granted 
only  to  users  in  certain  roles.  Along  with  that  privilege  could  come 
enhanced monitoring of all files copied onto such devices. In addition, 
understanding who requires removable media and for what purposes can 
help you to determine what may constitute normal and healthy business 
use, and to monitor for usage patterns that deviate from that. Inventory 
control, as it pertains to removable media, may also be helpful. For exam-
ple, you could allow use of removable media only on company-owned 
devices  prohibited  from  leaving  your  facility.  Organizations  requiring 
the highest-assurance environment should consider disallowing remov-
able media completely, or allowing it only in special situations that are 
 carefully audited.

Mitigation Strategies for All Theft of Intellectual Property Cases 
95
Finally, recall the 30-day window in our theft of IP cases. Can you log all file 
transfers to removable media? You might not have the resources to review 
all of those logs (depending on how restricted your use of such media is). 
However, if the logs exist, you can audit them immediately on the hosts 
accessed by any employee who has announced his resignation. This would 
provide one quick mechanism for detecting IP that might be exfiltrated by 
an employee on his way out the door.
Physical Exfiltration
Only 6% of the theft of IP cases involved some sort of physical  exfiltration. 
We  found  that  physical  exfiltration  usually  occurs  in  conjunction  with 
some other form of exfiltration that would have produced a more obvious 
network or host-based observable event.
Exfiltration of Specific Types of IP
Once we determined what kinds of IP were stolen and how, we determined 
what methods of exfiltration were associated with the different types of IP. 
Several  interesting  findings  surfaced.  In  particular,  business  plans  were 
stolen  almost  exclusively  through  network  methods,  particularly  using 
remote access. Conversely, proprietary software and source code involve a 
much higher use of non-network methods. This may be due in part to the 
volume of data associated with different asset types. Software and source 
code files are often large, but business plans are usually smaller documents 
that are easier to move over a VPN or as an email attachment.  Enumerating 
the most frequent methods by which particular assets are exfiltrated may 
help steer monitoring strategies with respect to computers that house par-
ticular types of assets or are allowed to access given assets over the  network.
Concealment
Some  insiders  attempted  to  conceal  their  theft  of  IP  through  various 
actions.  These  cases  signify  a  clear  intent  to  operate  covertly,  implying 
the insiders may have known their actions were wrong. In one case, an 
insider was arrested by federal authorities after stealing product design 
documents and transferring them to a foreign company where he was to be 
employed. After being arrested, he asked a friend to log in to his personal 
email account, which was used in the exfiltration, and delete hundreds of 
emails related to the incident.
Another case involved an insider who used an encryption suite to mask the 
data he had stolen when moving it off the network.

Chapter 3.  Insider Theft of Intellectual Property
96
Trusted Business Partners
Trusted business partners accounted for only 16% of our theft of IP cases, 
but this is still a complicated insider threat that you need to consider in 
your contracting vehicles and technical security strategies.
For example, a telecommunications company was involved in a lawsuit, 
and had to hand over all of its applicable proprietary information to its 
attorneys,  which  it  did  in  hard-copy  form.  The  law  firm  subcontracted 
with a document imaging company to make copies of all of the informa-
tion. One of the employees of the document imaging company asked his 
nephew, a student, if he would like to make a little extra spending money 
by helping him make the copies at the law firm. The nephew realized that 
he had access to proprietary access control technology that the telecom-
munications company used to restrict its services based on fees paid by 
each  individual  customer.  He  felt,  like  many  others,  that  the  company 
unfairly  overcharged  for  these  services,  so  he  posted  the  information 
online to the Internet underground. This basically released the telecom-
munications company’s “secret sauce,” and now it was easy for members 
of that community to obtain free services. When the post was discovered, 
law enforcement investigated the source of the post and traced the activity 
back to the student.
It is important that you consider these types of threats when drawing 
up  contracts  with your business partners. Could that scenario  happen 
to  you?  Do  you  write  legal  language  into  your  contracts  that  dictates 
how your confidential and proprietary information can and cannot be 
 handled?
It is important that you understand the policies and procedures of your 
trusted business partners. You establish policies and procedures in order 
to protect your information. When you enlist the support of a trusted busi-
ness partner, you should ensure that their policies and procedures are at 
least as effective as your safeguards. This includes physical security, staff 
 education, personnel background checks, security procedures,  termination, 
and other safeguards.
In addition, you should monitor intellectual property to which access is 
provided. When you establish an agreement with a trusted business part-
ner, you need assurance that IP you provide access to is protected. You 
need to get assurances that access to and distribution of this data will be 
monitored. You should verify that there are mechanisms for logging the 
dissemination  of  data,  and  review  their  procedures  for  investigating 
 possible disclosure of your information.

Mitigation Strategies: Final Thoughts
97
These are just a few recommendations. We detail eight recommendations 
in  Chapter  9,  Conclusion  and  Miscellaneous  Issues,  regarding  trusted 
 business partners.
 
Figure 3-9  Issues of concern
Employee Went to Work for a
Competitor
Change of Employment Status
Foreign National/Non-U.S. Native
Employee/Coworker Susceptibility
to Recruitment
Unauthorized Data Download
to/from Home
Unauthorized Data Download to Media
Employee Sought Other Employment
Email/Chat with Competitors or
Conspirators
Planning with Competitor
Failure to Protect Critical Files
Employee Side Business
Unauthorized Data Exports—Unknown
Unauthorized Data Exports—Digital
Equipment/Media
Concealment of Current Illicit
Activity—Nontechnical
Concerning Behavior or Activity
40
35
30
25
20
15
10
5
0

Chapter 3.  Insider Theft of Intellectual Property
98
to monitor emails going to a competitor. We provide a control for doing 
that in Chapter 7, Technical Insider Threat Controls. Also, note the  second 
most  prevalent  issue  of  concern:  change  in  employment  status,  which 
would account for the insiders who stole information within 30 days of 
resignation. The third most prevalent issue is foreign national/non-U.S. 
native,  which  we  covered  in  depth  in  the  section  Theft  of  IP  inside  the 
United States Involving Foreign Governments or Organizations earlier in 
this chapter. The fourth issue, employee/coworker susceptibility to recruit-
ment, applies in all of the Ambitious Leader cases.
One final thought regarding the 30-day window: You should review your 
access-termination procedures associated with employee and contractor exit 
procedures. Several cases provided evidence that insiders remotely accessed 
systems  by  using  previously  authorized  accounts  that  were  not  disabled 
upon the employee’s exit. Precautions against this kind of incident seem to be 
common sense, but this trend continues to manifest in newly cataloged cases.
Summary
Insiders who steal intellectual property are usually scientists, engineers, 
salespeople, or programmers. The IP stolen includes trade secrets, proprie-
tary information such as scientific formulas, engineering drawings, source 
code, and customer information. These insiders typically steal information 
that they have access to, and helped to create. They rarely steal it for finan-
cial gain, but rather they take it with them as they leave the organization 
to take to a new job, give to a foreign government or organization, or start 
their own business.
These  insider  threats  fall  into  two  groups.  The  first  is  the  Entitled 
 Independent, an insider who acts alone to take the information with him as 
he leaves the organization. The second is the Ambitious Leader, an insider 
who creates a “ring” of insiders who work together to steal the  information. 
Ambitious  Leaders  want  to  steal  more  than  just  the  information  they 
 created—they want the entire product line, or whole suite of source code, 
for example.
NOTE
For more details of technical controls you can implement to prevent or 
detect insider theft of IP, see Chapter 7, where we describe new technical 
controls from our insider threat lab.

Summary
99
A portion of this chapter was devoted to insiders who stole IP to take to 
a  foreign  government  or  organization.  These  crimes  can  be  particularly 
disastrous, since it is much more difficult to recover the information once it 
leaves the United States. We described the countries involved, the positions 
of the employees, and the methods of theft.
The most useful pattern we found in modeling these crimes was that most 
of the insiders stole at least some of the information within 30 days of res-
ignation. That time frame actually encompasses a 60-day window: 30 days 
before turning in their resignation, and 30 days after. Our mitigation strate-
gies use that time frame; we recommend logging of all potential exfiltration 
methods, especially emails off of the network and use of removable media, 
so that you can audit the information when an employee who has access 
to your critical information resigns. You need to be able to go backward in 
time when such an employee resigns to make sure he has not emailed your 
IP outside the network—for example, to competitors, to governments or 
organizations outside the United States, or to Gmail or Hotmail accounts. 
You  also  need  to  be  able  to  identify  information  that  was  copied  to 
 removable media during that time frame. Finally, you need to do  real-time 
alerting when such online activity takes place in that period between when 
the insider resigns and when his employment actually terminates.
The  next  chapter  turns  to  insider  fraud.  Insider  fraud  involves  theft  as 
well, but theft of a different type of information: Personally Identifiable 
 Information  (PII),  credit  card  information,  and  other  data  that  could  be 
used to commit fraud. It also includes crimes in which an insider modified 
information for financial gain, often for pay by outsiders.

This page intentionally left blank 

101
Chapter  4
Insider Fraud
 
1.  This definition comes from the Secret Service Web site: www.secretservice.gov/criminal.shtml.

Chapter 4.  Insider Fraud
102
anticipated that three of his meter readers would carry out a fraud scheme 
with 17 customers for 18 months for a total of $325,000. But that’s exactly 
what happened. Take a minute to think about your information systems 
and which ones might provide an attractive means of earning some extra 
cash to your employees, contractors, or business partners.
Those are the types of crimes we will explore in this chapter. Recall from 
Chapter 1, Overview, that fraud crimes are by far the most prevalent in 
the CERT insider threat database. The data breach laws could account for 
the significant number of cases, because victim organizations can no longer 
handle those types of crimes quietly, internal to the organization. However, 
the fact remains that these types of crimes are definitely occurring, and not 
only in the financial sector as one might initially guess.
In  our  insider  fraud  cases,  the  insider  is  not  necessarily  the  one  who 
 commits the actual identity crime, but the insider is often associated with 
others (possibly outsiders) who do commit an identity crime. In fact, all 
of the crimes in the CERT database that involved organized crime were 
insider fraud cases. In this chapter we describe the profile of insider fraud 
and present strategies for mitigating the insider fraud crimes.2 We devote 
a  section  of  this  chapter  specifically  to  the  cases  involving  organized 
crime because the impacts of those were substantial: The average dam-
ages in these cases exceed $4 million, with one case resulting in almost 
$50  million in losses.
2.  Material in this chapter includes portions from a 2010 CERT Research Annual Report article on insider 
fraud modeling work by Andrew Moore, Adam Cummings, and Derrick Spooner. See www.cert.org/
cert/information/researchers.html.
NOTE
By insider fraud we mean insiders who modify, add, or delete information 
for their own advantage, and those who relay information to others, either 
insiders or outsiders, who use it to commit fraud.
We devote a section of this chapter specifically to the cases involving 
organized crime because the impacts of those were substantial: The 
 average damages in these cases exceed $4 million.

103
 
 
3.  From Wikipedia: “Insider trading is the trading of a corporation’s stock or other securities (e.g., bonds 
or stock options) by individuals with potential access to non-public information about the  company.”

Chapter 4.  Insider Fraud
104
 

105
 
 
4.  ftp://ftp.bls.gov/pub/special.requests/lf/aat11.txt
Impacts of Insider IT Fraud
The impacts of insider IT fraud attacks include the following:
•  Losses of almost $700 million hidden from a financial organization for 
five years
•  More than $8 million worth of military equipment lost
•  Driver’s licenses provided to 195 people unable to obtain legal 
licenses
•  Credit histories of 178 consumers modified or deleted, resulting in 
more than $4 million in high-risk loans that otherwise would not 
have been granted
•  Loss to fraud of $335,000 among ten financial institutions and 
25 retailers in multiple states
•  More than $600,000 in fraudulent disability payments
•  Loss of more than $250,000 by a city government through payments 
to fake vendors
•  Almost $63,000 in fraudulent lottery winnings paid

Chapter 4.  Insider Fraud
106
characteristics are all that useful to identify likely  perpetrators. Instead, 
we recommend focusing on general patterns of behavior that can provide 
insights into the nature of the crime and how to prevent it, or at least detect 
and respond to the crime to limit damage.
At  the  time  this  chapter  was  written,  the  U.S.  Department  of  Homeland 
Security (DHS) Science and Technology (S&T) Directorate brought the origi-
nal Secret Service/CERT Insider Threat Study team back together to study 
insider fraud in the financial sector. The U.S. Department of the Treasury also 
participated in the study to help us to connect with the financial sector. We 
are still in the case-gathering mode, and do not yet have analysis to report. 
However,  this  chapter  reports  preliminary  findings  based  on  our  earlier 
fraud modeling work sponsored by CyLab, updated based on all of the fraud 
cases currently in the CERT database. Please keep checking our Web site at 
www.cert.org/insider_threat for our report and fraud model.
General Patterns in Insider Fraud Crimes
The starting point for describing patterns of insider fraud, including the 
MERIT fraud model, is the Fraud Triangle, developed by the criminolo-
gist Donald Cressey in the early 1950s [Cressey 1974].5 The Fraud Triangle 
evolved through Cressey’s interviews with imprisoned bank embezzlers. 
His observation that many of these formerly law-abiding citizens had what 
he termed a “non-sharable financial problem” led to his development of 
the Fraud Triangle. As depicted in Figure 4-1, the Fraud Triangle involves 
three dimensions: pressure, opportunity, and rationalization. As the theory 
goes, all three elements must be present in order for fraud to occur.
•  Pressure is what causes a person to commit fraud, often stemming from 
a significant financial need or problem. This problem or need can arise 
due  to  external  pressures  such  as  medical  bills,  addiction  problems, 
or even just expensive tastes. While some fraud is committed simply 
out of greed, Cressey’s observation was that there was often a need to 
resolve the problem in secret, that is, it was “non-sharable.”
5.  At the time we were writing this book, our insider fraud case files did not have sufficient data to 
support strong conclusions about the dynamic over-time nature of the crime, as is required for our 
modeling efforts. We therefore thought it was even more important to start the modeling efforts off in 
the existing, fairly well-established theory of the Fraud Triangle. Our current work expands insider 
fraud case data and we hope to validate these foundations as we move forward in refining the MERIT 
insider fraud model.

General Patterns in Insider Fraud Crimes
107
•  Opportunity  is  the  perpetrator’s  ability  to  commit  fraud.  Within  an 
organization, weak security controls and inadequate oversight by man-
agement  provide  opportunities  for  some  fraudsters.  Organizations 
have more control over the opportunity dimension than the other two 
dimensions. Organizations can build processes, procedures, and con-
trols that inhibit or deter an employee’s ability to commit fraud and 
that effectively detect it when it does occur.
•  Rationalization involves the process of overcoming any personal ethical 
hesitations to commit the fraud. It involves reconciling the bad behav-
ior with commonly accepted notions of decency or trust. Rationalizing 
individuals may believe that, due to perceived mistreatment, the orga-
nization owes them something, or that committing the fraud is the only 
way to save their family from sure devastation. Rationalization may 
include beliefs that the fraudster is merely “borrowing” money until 
it can be paid back. At the other end of the spectrum, rationalization 
includes misunderstanding about the severity of the fraudulent acts or 
apathy about their consequences.
Figure 4-1  Fraud Triangle
What causes a person to
commit fraud. Examples:
medical bills,
expensive tastes,
addiction problems, etc.
Personal reconciling behavior
(stealing) with commonly
accepted notions of decency and 
trust. Examples: sacrifice for
loved one, only “borrowing,” it is
owed, does not care, etc.
Ability to commit fraud.
Created through weak internal
controls, poor management
oversight, use of one’s position
and authority, etc.
Rationalization
(Attitude)
Opportunity
(Ability)
Pressure
(Incentive)

Chapter 4.  Insider Fraud
108
 
Figure 4-2  Insider Fraud Triangle
Social Networking
Pressures
Insider’s Feeling
that Organization
Owes Him
Insider’s Feeling
of Having No
Other Option
Insider’s Intent to
Make Things
Right Eventually
Fraud Prevention
Controls
Implemented
Need to Help
Family/Friends
Insider’s Incentive
(Pressures) to
Commit Fraud
Insider’s Opportunity
to Commit Fraud
Insider’s
Financial
Problems
Insider’s Rationalization of
(Attitude Toward) Fraud
Insider’s
Dissatisfaction with
Compensation

General Patterns in Insider Fraud Crimes
109
 information. Some insiders were motivated to provide additional income 
for their relatives, and a few insiders had large credit card debts or drug-
related financial difficulties.
The  most  common  and  straightforward  means  used  by  insiders  was 
stealing information to which they had access. Most thefts were not very 
sophisticated. Remember, these are largely not technical, and are not com-
mitted by highly educated individuals.
Some of them did use electronic means to exfiltrate information, however.
•  They downloaded the information to home.
•  They looked it up online and used it immediately.
•  They copied it to removable media.
•  They telephoned or faxed the information.
•  They emailed the information.
A few fraud cases did involve more sophisticated methods. One insider 
was paid by an outsider to intentionally double-click on an email attach-
ment that contained malicious code and a software keystroke logger.6 The 
malicious code periodically transmitted customer information to a compet-
itor. Another insider used an anonymous remailer to mask his involvement 
in a fraud scheme. An anonymous remailer is a server that receives email 
messages containing embedded instructions on where to forward them. 
The server then forwards the messages while also masking their originat-
ing location.
Some insider fraud crimes involved theft of information, but other insiders 
modified information, often paid for by outsiders who stood to benefit. For 
example, a series of insider crimes in the CERT database victimized credit 
history organizations; data entry clerks figured out that they could make 
money by “improving” the credit history of individuals trying to obtain 
loans for which they did not qualify.
6.  Software keystroke logger:  a  software-based  method  of  recording  keystrokes  entered  from  a 
 keyboard.
NOTE
Fraud crimes involved theft and modification of information, often to solve 
the insider’s financial problems.

Chapter 4.  Insider Fraud
110
Most modification cases involved changing information in a system, as in the 
previous example. However, some insiders added information—as in cases 
in which fake driver’s licenses were created by adding false information to an 
application and generating the corresponding license. Very few cases involved 
the deletion of information, but some involved a combination of methods.
Figure  4-3  shows  how  financial  problems,  on  the  left-hand  side  of  the 
 figure, provide incentives for the insider to conduct fraudulent activities. 
The crime results in financial benefit, which helps to reduce the financial 
problems that originally motivated the crime. (The dotted line in Figure 4-3 
indicates that the insider’s financial problems are reduced.)
Continuing the Fraud
A major difference between insider fraud and the other types of insider 
crimes is the time frame over which the crimes typically occur. Insider fraud 
is typically a long and ongoing crime. Insider IT sabotage and, to a lesser 
extent, theft of IP are largely big-bang events where the insider commits 
the crime and leaves the organization as fast as he can. Such smash-and-
grab events do not work as well to perpetrate fraud, since insiders typically 
want to siphon off or modify information slowly and repeatedly for as long 
as possible so as not to be noticed. Since financial difficulty is often the 
motivating factor, losing or leaving one’s job is not an attractive option.
Figure 4-3  Origins of fraud
Insider’s Incentive
(Pressures) to
Commit Fraud
Insider’s Rationalization of
(Attitude Toward) Fraud
Insider’s
Financial
Problems
Insider’s
Greed
Insider’s
Activities
Related to
Fraud
Insider’s Financial
Benefit Due to
Fraud
Insider fraud is typically a long and ongoing crime.

General Patterns in Insider Fraud Crimes
111
The  average  insider  fraud  crime  spanned  about  fifteen  months,  with 
half of the crimes lasting five months or more. More than half of the inci-
dents  were  ongoing  with  frequent  periods  of  significant  compromise. 
Of the short, quick compromises, about half ended because the insider 
was caught quickly, and most of the others ended because the crime was 
committed as the employee was leaving the organization, or following 
termination.
Interestingly, many crimes involved the theft or modification of relatively 
small pieces of information—a credit card number, Social Security num-
ber, or credit history record—in contrast to the much larger thefts typical 
in the theft of IP cases. Each small piece of information brought the insider 
a small financial benefit, so the insider was motivated to keep the fraud 
going as long as possible and to “fly under the radar” of any organizational 
scrutiny.
Often,  the  insider’s  financial  problems  are  eventually  resolved,  but  the 
additional income is too good to resist and the fraud takes on a life of its 
own. This is where the insider’s greed comes into play in Figure 4-3. The 
financial benefits, along with the ability to get away with the crime, result 
in an emboldening of the insider and the desire to keep things going.
Outsider Facilitation
 
NOTE
Outsiders facilitated many of the fraud crimes and recruited the insider to 
commit the crime in about one-third of the cases.

Chapter 4.  Insider Fraud
112
 
Figure 4-4  Outsider facilitation of insider fraud
Outsider’s Pressure on
Insider to Begin or
Continue Fraud
Insider’s Incentive
(Pressures) to
Commit Fraud
Insider’s Opportunity
to Commit Fraud 
Insider’s Rationalization of
(Attitude Toward) Fraud
Outsider’s
Facilitation
of Fraud
Insider’s
Activities
Related to
Fraud
Extent of
Fraud
Committed
Outsider’s Financial
Benefit Due to
Fraud

Free ebooks ==>   www.Ebook777.com
General Patterns in Insider Fraud Crimes
113
that type of crime. Outsiders recruited insiders to steal information more 
often than to modify it, probably because committing identity theft is much 
easier than coming up with a scheme for modifying an organization’s infor-
mation to their advantage. As you will see in the next section, not only was 
modification to commit fraud more likely the insider’s idea, but insiders 
often recruited other coworkers to help.
Recruiting Other Insiders into the Scheme
 
NOTE
Coworkers facilitated many of the insider fraud crimes, especially for 
fraud involving modification of information.
Outsiders recruited insiders to steal information more often than to 
 modify it.
www.Ebook777.com

Chapter 4.  Insider Fraud
114
 
Figure 4-5  Coworker recruitment
Insider’s Perceived
Risk of Getting
Caught
Insider’s Perceived
Loss if Caught
Insider’s
Knowledge of
Organization’s
Fraud Controls
Insider’s Incentive
(Pressures) to
Commit Fraud
Insider’s
Activities
Related to
Fraud
Insider Recruits
Other Employees
to Conceal Crime

Insider Fraud Involving Organized Crime
115
 
by outsiders. While the motivations for the crimes appeared to largely 
come from outside the workplace, some workplace issues were evident. 
Some  insiders  had  disagreements  over  financial  compensation  or  with 
supervisors. Such issues at times led to intense situations and what might 
be deemed as a hostile work environment. The threat of layoffs was also 
an issue in some cases. Here the insiders may have wanted to make as 
much  money  at  the  organization’s  expense  as  possible  prior  to  being 
 terminated.
 
NOTE
Stressors both inside and outside the workplace were observable in 
insider fraud cases.

Chapter 4.  Insider Fraud
116
maintain their position through the use of actual or threatened violence, 
corrupt public officials, graft, or extortion, and generally have a significant 
impact on the people in their locales, region, or the country as a whole.7
The  24  insider  threat  cases  facilitated  by  organized  crime  in  the  CERT 
 database constitute about 10% of all of our fraud cases. These cases typi-
cally  involve  multiple  insiders  and/or  outsiders  committing  long-term 
fraud. The average damages in these cases exceeded $4 million, and one 
case amounted to almost $50 million in losses. Criminal enterprises mask 
their fraud by involving multiple insiders who often work in different parts 
of the organization. These insiders know how to bypass critical processes 
and remain undetected.
In  several  cases,  management  was  involved  in  the  fraud.  The  insiders 
affiliated with organized crime either sell information to them for further 
exploitation or are directly employed by them to enable the fraud.
Snapshot of Malicious Insiders Involved with Organized Crime
All of the insiders involved with organized crime in the 24 cases attacked 
the organization for financial gain. The insiders were usually employed in 
 lower-level positions in the organization, were motivated by financial gain, 
and were often recruited by outsiders to commit their crimes. Sound famil-
iar? Although these crimes fit the patterns we have already described for 
fraud, the impacts seem to be amplified by the involvement of organized 
crime.8
This section will discuss the two different types of insider organized crime 
activity.
•  Insiders with ties to existing external organized crime groups.
•  Insiders  who  form  or  participate  in  their  own  criminal  enterprises. 
A criminal enterprise is a group of individuals with an identified hier-
archy, or comparable structure, engaged in significant criminal activity.9
Here is a sample case involving a criminal enterprise.
Five  insiders  worked  for  a  credit  reporting  company.  Each  of  them 
was  a  low-level  employee  with  job  responsibilities  of  data  entry  and 
7.  www.fbi.gov/about-us/investigate/organizedcrime/glossary
8.  This section includes material authored by Christopher King in “Spotlight On: Malicious Insiders 
and Organized Crime Activity” published in SEI Technical Note CMU/SEI-2011-TN-025 [King 2011].
9.  www.fbi.gov/about-us/investigate/organizedcrime/glossary

Insider Fraud Involving Organized Crime
117
 modification  of  credit  reports.  A  car  salesman  befriended  one  of  the 
insiders while shopping for a car, and found out what the insider’s job 
entailed. He offered to pay the insider $150 per customer to change credit 
reports of individuals who wished to purchase a car but had insufficient 
credit.  The  insider  then  recruited  his  colleagues  to  participate  in  the 
scheme. Each week the  outsider dropped off the names of the individu-
als and  associated payments. The organization had a business process 
in  place  to  verify  changes  to  credit  reports,  but  two  of  the  employees 
involved  in  the  scheme  had  the  authority  to  override  the  verification 
process. The fraud continued for more than a year until a routine audit 
discovered the  discrepancy.
Here is an example case of a person affiliated with organized crime.
A teller at a large U.S. bank handled customer information on a daily basis 
and  processed  checks  for  customers.  Heavily  in  debt,  the  insider  was 
approached by individuals in the Mafia who offered to pay him to steal 
customers’ PII. Over the course of several years, the insider sold PII to 
the organized crime group, who used it to create fraudulent checks, open 
unauthorized credit cards, and commit identity theft. The theft was caught 
when the bank became suspicious of the exceptionally high rate of fraud 
occurring in one of its local branches.
Who They Are
This section is based on 20 cases that involved a criminal enterprise and 
four cases with ties to organized crime. The majority of the insiders were 
employed  in  nontechnical  positions,  although  four  held  a  management 
position. The crimes involving management went on for a longer period of 
time and the scale of the crime was much larger. The majority of the insid-
ers were female, which is greater than the breakdown of all fraud cases 
in the CERT database (roughly 50% male/female). Finally, almost all cases 
involved collusion with outsiders. In cases involving existing organized 
crime groups there tended to be fewer insiders involved.
In the crimes involving management, the average loss was very high. One 
case involving a manager at a Department of Motor Vehicles (DMV) caused 
losses of $250,000; another DMV case resulted in a $1 million loss for the 
organization. The most damaging case involved an insider working for a 
city tax office, who was able to steal $48 million over the course of almost 
two decades. These insiders were lower- or mid-level managers with few 
technical skills. They used their deep knowledge of the organization’s pro-
cesses and systems to bypass the checks and balances in place and recruited 
their subordinates into the crime.

Chapter 4.  Insider Fraud
118
Why They Strike
These insiders held low-level positions in the organization, and committed 
the crimes for financial gain.
What They Strike
These insiders primarily copied or modified data for financial gain. Crimes 
included  stealing  customer  information  to  sell  for  identity  theft,  modi-
fying credit reports to give buyers a higher credit score, or creating fake 
credentials, such as driver’s licenses. Insiders primarily modified data in 
organization databases and bypassed integrity checks.
How They Strike
Nearly three-fourths of the attacks occurred on-site during normal work 
hours.  For  the  most  part,  insiders  used  their  authorized  access  to  copy, 
modify, or delete critical data from the organization’s systems.
Technical methods used included the following.
•  Social engineering to obtain credentials or information
The insider, after resigning from a law enforcement agency, convinced 
colleagues  to  run  searches  and  gather  information  on  companies  to 
help him and his conspirators perform insider trading.
•  Authorized use of the organization’s systems
An insider used his access to customer credit reports to sell the data to 
conspirators who would conduct identity theft.
•  Bypassed secure processes
An organization required two employees to issue tax-refund checks, 
but both insiders in the process were part of the same criminal enter-
prise and would issue fraudulent checks to their conspirators.
•  Compromised account
An insider working for a credit reporting agency performed modifica-
tions of customer credit in exchange for money. The insider used stolen 
passwords of coworkers to conceal evidence of the crime.
Table 4-1 contains summary information for all of the insider fraud cases in 
the CERT database that involved organized crime.

Insider Fraud Involving Organized Crime
119
Table 4-1  Summary of Organized Crime Cases
Case #
Total # of 
Conspirators
# of 
Insiders
# of 
Outsiders
­
Insider-Led?
1
10
4
6
$48,115,451
Yes
2
94
1
93
$10,000,000
No
3
4
3
1
$6,775,434
Yes
4
3
1
2
$2,700,000
Yes
5
14
13
1
$2,288,946
Unknown
6
10
1
9
$1,500,000
Unknown
7
7
2
5
$1,000,000
No
8
4
1
3
$841,164
Yes
9
10
5
5
$800,000
Yes
10
6
1
5
$638,000
No
11
6
2
4
$335,000
No
12
16
6
10
$287,500
Unknown
13
4
4
0
$250,000
Yes
14
6
1
5
$231,500
Yes
15
6
1
5
$157,000
Unknown
16
16
1
15
$77,300
No
17
6
2
4
$75,000
Yes
18
2
1
1
$10,000
No
19
8
2
6
Unknown
No
20
4
2
2
Unknown
No
21
9
5
4
Unknown
Yes
22
11
1
10
Unknown
No
23
Unknown
1
Unknown
Unknown
No
24
21
1
20
Unknown
Unknown

Chapter 4.  Insider Fraud
120
 
Figure 4-6  Issues of concern
120
80
100
60
20
40
0
Inadequate Auditing of Critical
Processes
Employee/Coworker Susceptibility
to Recruitment
Verification of Modification
of Critical Data
Financial Problems
Excessive Access Privilege
Unauthorized Data Exports
Unauthorized Data Export—Paper
Insufficient Separation of Duties
Concerning Behavior or Activity
Inadequate Auditing of Irregular
Processes
Unexplained Wealth
Falsified or Omitted Information
Concealment of Current Illicit Activity–
Nontechnical
Compromised Passwords
Employee Susceptibility to
Social Engineering
Quality Control of Critical Data
Verification of Authorized
Access of Critical Data
Masquerading
Violation of Need to Know Policy

Organizational Issues of Concern and Potential Countermeasures
121
 

Chapter 4.  Insider Fraud
122
 

Free ebooks ==>   www.Ebook777.com
Organizational Issues of Concern and Potential Countermeasures
123
 
www.Ebook777.com

Chapter 4.  Insider Fraud
124
 

Organizational Issues of Concern and Potential Countermeasures
125
 
10. Role-based access: access required by a person’s duties. Typically, a person’s access to data/ systems 
should be no greater than what is required the person’s role.

Chapter 4.  Insider Fraud
126
They will have a very difficult time proving that they did not commit 
the illegal activity when all of the evidence points directly to them!
•  Employee susceptibility to social engineering
In  some  of  the  fraud  cases,  employees  unwittingly  assisted  other 
employees in committing crimes by falling for social engineering. In 
one case, an insider who worked for a credit card point-of-sale terminal 
vendor used social engineering to obtain authentication information 
from the credit card company help staff. He posed as a distraught indi-
vidual (with a fabricated identity) working for a particular, authorized 
merchant needing help with a malfunctioning terminal. He was then 
able to credit his own credit card by reprogramming a terminal using 
the information he had obtained. It is important that your employees 
are  educated  to  understand  potential  social  engineering  techniques, 
not only from outsiders, but from other insiders as well.
 

Summary
127
organizations. The fact that insider fraud crimes are often long and  ongoing 
is bad news for the victim organizations. However, it does afford the orga-
nization with ample opportunity to discover the crime, and possibly curtail 
the activity to limit damage.
There are two means for detecting insider fraud. The first is external dis-
covery of the crime, potentially as a result of investigation into financial 
losses incurred by the fraud victims. As we have explained previously, the 
actual fraud crime is often conducted by an outsider to the victim orga-
nization.  Detection  of  these  activities  is  likely  to  be  a  point  where  law 
enforcement is brought in to investigate the potential problem. The second 
is the discovery of the internal crime—the insider’s or accomplice’s mali-
cious actions. Here the organization has the opportunity to detect the illicit 
insider activity at any point from planning to insider recruitment to online 
execution.
Summary
Insiders  who  commit  fraud  are  usually  low-level  employees  who  use 
authorized access during normal work hours to either steal information or 
modify information for financial gain. Stolen information is usually PII or 
customer information that is then sold to outsiders who commit the actual 
fraud against the victims. Information is sometimes modified for the direct 
financial  benefit  of  the  insider,  and  sometimes  is  done  for  payment  by 
 outsiders.
All of the insider crimes in the CERT database involving organized crime fit 
into the fraud category. Most of these involve insiders who form their own 
criminal enterprise, but some involve insiders being recruited by external 
organized crime groups. These crimes have a significant impact, with aver-
age losses of more than $4 million.
Insiders who commit fraud are primarily motivated by financial difficulty. 
They start the crime due to mounting financial pressures, but then tend 
to carry out their scheme for as long as possible. Outsiders play a role in 
many  of  these  crimes,  either  paying  for  stolen  information,  or  finding 
“ customers” who are willing to pay the insider to modify information.
In this chapter we explored technical methods used, as well as mitigation 
strategies.

Chapter 4.  Insider Fraud
128
A preliminary MERIT model of insider fraud is presented in Figure 4-7.
We have now explored each of the three types of crimes, insider IT sabo-
tage, theft of intellectual property, and fraud, in detail. Next, we will dig a 
little deeper into one specific method of committing insider crimes: in the 
Software Development Life Cycle.
Figure 4-7  Preliminary MERIT model of insider fraud
Outsider Pressure
on Insider to Begin
or Continue Fraud 
Insider’s Perceived
Risk of Getting
Caught
Social Networking
Pressures
Insider’s
Knowledge of
Organization’s
Fraud Controls
Insider’s
Dissatisfaction with
Compensation
Insider’s Feeling
of Having No
Other Option
Insider’s Intent to
Make Things
Right Eventually
Fraud Prevention
Controls
Implemented
Need to Help
Family/Friends
Insider’s Feeling
that Organization
Owes Him
Insider’s Incentive
(Pressures) to
Commit Fraud
Insider’s Opportunity
to Commit Fraud
Insider’s Rationalization of
(Attitude Toward) Fraud
Insider’s
Financial
Problems
Insider’s Financial
Benefit Due to
Fraud
Outsider
Facilitation
of Fraud
Insider’s
Greed
Outsider’s Financial
Benefit Due to
Fraud
Insider’s
Activities
Related to
Fraud
Insider Recruits
Other Employees
to Conceal Crime
Extent of
Fraud
Committed

129
Chapter  5
Insider Threat Issues  
in the Software  
Development Life 
Cycle
 
1.  Webopedia.

Chapter 5.  Insider Threat Issues in the Software  Development Life Cycle
130
to exploitation later by end users of the system. Then it addresses malicious 
software engineers.
One  critical  requirement  of  most  software  systems  should  be  that  the 
 system  ensures  the  confidentiality,  integrity,  and  availability  of  the 
underlying information. Unfortunately, in today’s tumultuous economic 
conditions, time to market is often the driving factor in product develop-
ment, often sacrificing important stages of the SDLC designed to address 
security issues. Software engineers, including both employees and contrac-
tors, have intentionally and unintentionally bypassed critical processes in 
the SDLC, leaving vulnerabilities in software that allowed exploitation by 
end users once it was in production.
In addition, software engineers and data owners often do spend a good bit 
of time anticipating and addressing information security issues.  However, 
in many cases in the CERT insider threat database we have observed that 
the  system  designers  neglected  to  anticipate  how  authorized users  could 
commit illicit activity using the software. Finally, once the software is in 
production,  developers  tend  to  have  free  reign  in  many  organizations, 
releasing changes to source code without any two-person control.
Neglecting  to  consider  insider  threat  security  requirements  in  software 
systems has allowed insiders to sabotage critical systems, defraud organi-
zations of large sums of money, and modify data in systems to create false 
identity documents. While the impact in some incidents can be measured 
in dollars, other incidents impact organizational operations or threaten the 
national security of the United States.
The  following  case  demonstrates  the  potential  of  an  employee  with 
 software development skills and access to cause financial impact.
A foreign currency trader in a financial institution started losing money 
on trades. Fearing job-related consequences, he executed a complex fraud 
scheme by modifying the source code of the trading system to hide fake 
trades he entered to counterbalance his losses. Since his undergraduate 
degree was in computer science, he had convinced the development team 
that it would be easier on all of them if he could just modify the source code 
himself when needed. Therefore, he had been given authorized access to 
the source code, and was able to modify it to hide his illicit activity.
His  scheme  ended  up  continuing  for  more  than  five  years;  making  it 
appear that the bank was profiting instead of losing close to $700 million. 
The insider was convicted, ordered to pay almost $700 million in restitu-
tion, and sentenced to more than seven years of imprisonment followed 
by five years of probation.

Requirements and System Design Oversights
131
It is important for you to carefully consider this case. Many controls are 
built in to your software systems so that your end users cannot perform 
illicit activity. Therefore, it is very important that you do not allow your 
end users to have access to your source code. This is a new slant on the 
 concept of separation of duties!
Given that most organizations are reliant on IT systems for achieving their 
mission, it is easy to see why the integrity of the software underlying those 
systems is critical. If the organization does not incorporate adequate secu-
rity controls in its SDLC processes or an insider is able to bypass existing 
security controls, the potential for sabotage, fraud, or theft of information 
is increased.
Twenty-eight  of  the  cases  in  the  CERT  database  had  issues  related  to 
exploiting a vulnerability in the SDLC. The majority of those cases involved 
an insider who sabotaged a previous employer’s critical system. In a few 
of  the  cases  the  insider’s  malicious  actions  resulted  in  fraud  or  theft  of 
 intellectual property.
By looking at the 28 incidents, it became apparent that the vulnerabilities 
exploited could be broken down into two general categories:
•  Requirements definition and system design
•  System implementation and maintenance
 

Chapter 5.  Insider Threat Issues in the Software  Development Life Cycle
132
 auditing functions that can be implemented and run automatically on a 
more  frequent basis than manual system audits.
Exception handling, or authorized system overrides, which were designed 
to  accommodate  unusual,  special  circumstances  that  could  not  follow 
the standard business processes, provided an easy mechanism for some 
 insiders in the CERT database to commit malicious activity.
Note  that all of the recommendations detailed here for defining system 
requirements apply to both systems built by the organization and those 
the organization acquired. When evaluating new systems for acquisition, 
the types of requirements detailed here should also be considered. Once 
requirements  have  been  defined  and  potential  systems  are  evaluated 
for purchase, the ability of each system to meet those requirements is an 
important part of the evaluation process.
Authentication and Role-Based Access Control
 
NOTE
Neglecting to require authentication and role-based access control 
 simplified insider attacks.

Requirements and System Design Oversights
133
could read information from the database, but also could use other system 
 functions. At that point, at the request of her accomplice, she began to cre-
ate, in return for payment, illegal driver’s licenses in the system for people 
who were unable to gain legitimate licenses. Fortunately, a confidential 
informant led to her arrest for fraudulently creating approximately 195 
illegal driver’s licenses.
This case is a “low-tech” incident that was enabled by oversights in  defining 
and implementing access controls within a critical application. All system 
users had the same level of access, even to perform a critical function such 
as adding a driver’s license to the database.
Separation of Duties
Most organizations implement separation of duties in business processes 
to reduce the risk of fraud. Separation of duties should require that more 
than one person be involved in a critical business process. For example, one 
employee is given authorized access to generate a payment, but a second 
employee is required to approve and finalize the payment. Failure to iden-
tify requirements for separation of duties enabled some insiders to commit 
crimes against their organization.
The office manager for a large trucking firm fraudulently added her hus-
band to the payroll each week for weekly payouts, and then deleted him 
from the system and erased all records of the payments. This scheme went 
on for more than a year and resulted in more than $100,000 in losses to 
the firm.
In this case, the office manager had the ability to add employees to the pay-
roll, generate paychecks, and delete records of payments from the database. 
One might expect this type of situation in a small organization, but this 
case example described a large trucking organization. Nonetheless, we real-
ize that some organizations, especially smaller ones, can’t afford to have 
multiple people involved in functions such as payroll. However, it is still 
important to use security controls to protect the records, payroll records in 
this case, from being modified by that single user, and to periodically audit 
those records for fraudulent activity.
NOTE
Neglecting to define security requirements/separation of duties 
 requirements for automated business processes provided an easy 
method for insider attack.

Chapter 5.  Insider Threat Issues in the Software  Development Life Cycle
134
Automated Data Integrity Checks
 
NOTE
Neglecting to define requirements for automated data integrity checks 
made it difficult to detect malicious insider actions.

Requirements and System Design Oversights
135
observed in fraud cases, it is recommended that system designers consider 
how they might implement yet another layer of defense on top of separa-
tion of duties, to discover incidents in which two employees are working 
together to commit a crime. Most of these types of crimes continue over a 
prolonged period, so although detection might not be immediate, patterns 
of suspicious activity can be discovered to catch the activity sooner rather 
than later.
Exception Handling
Several insiders used special system functions created for exception han-
dling  to  carry  out  their  crimes.  They  realized  that  these  functions  were 
created for exceptional situations in which changes had to be made quickly, 
thus  bypassing  the  usual  mandated  security  checks.  This  type  of  func-
tionality provided an easy way for insiders to get around the rules. The 
following case describes how insiders were able to bypass automated data 
integrity checks by using the system’s “Expedite” function. This same case 
example was used in the previous chapter, as we believe that this issue is 
important enough to be included in both chapters, and this is the best case 
to illustrate the concept.
Six  contractors  were  case  workers  for  an  organization  that  distributed 
child care vouchers. The insiders issued food stamps to people who did 
not qualify for the assistance and increased monthly allotments on exist-
ing cases for payment. Over a six-month period, they pocketed $32,000 in 
kickbacks for issuing food stamps to 53 unauthorized beneficiaries. They 
were able to evade the business processes enforced in the system without 
a supervisor’s authorization by opening the cases as “Expedited.” They 
were  only  caught  when  someone  that  the  insiders  attempted  to  solicit 
reported their activity to local law enforcement. The victim organization’s 
incident-related loss was $75,000.
It is important to design special data integrity checks for any data modi-
fied, added, or deleted using these exception-handling functions.
NOTE
Neglecting to consider security vulnerabilities posed by “authorized 
 system overrides” resulted in an easy method for insiders “to get around 
the rules.”

Chapter 5.  Insider Threat Issues in the Software  Development Life Cycle
136
System Implementation, Deployment, and Maintenance 
Issues
Very  few  insiders  actually  introduced  intentional  vulnerabilities  or 
 malicious code into source code during the initial development process; 
that type of activity was more often carried out during the maintenance 
phase of the SDLC. It is not uncommon for organizations to follow strin-
gent  development  practices  during  initial  development  but  allow  the 
practices to erode once the system moves into operation.
Code Reviews2
There is only one case in the CERT database in which the insider commit-
ted malicious activity during the initial development phase of a project, but 
it is still a risk that we cannot overlook. An 18-year-old Web developer used 
a backdoor he had inserted into his source code during software develop-
ment to access his former company’s network, spam its customers, alter its 
applications, and ultimately put it out of business. Code reviews and strict 
change control, a part of any solid software development process, could 
have detected the backdoor and perhaps saved the company.
More  insider  incidents  occurred  during  the  maintenance  phase  of  the 
SDLC  than  during  initial  system  implementation.  It  appears  that  orga-
nizations impose more stringent controls during the initial development 
process, but once a system has been in production and stabilized following 
initial release, those controls tend to become more lax. Insiders in the cases 
in the CERT database took advantage of those relaxed controls in a variety 
of ways.
A hardware engineer was unhappy with his new boss because he had mod-
ified the organization’s bonus system. To exact revenge, he downloaded 
a virus from the Internet and embedded it inside the company’s produc-
tion executable. That night, he released the new executable to  customers’ 
systems. The next day, one by one, the organization’s  customers executed 
2.  Code review: a process to examine source code, typically by someone other than the original coder, 
with the purpose of identifying and addressing mistakes.
NOTE
Lack of code reviews allowed insiders to insert backdoors into source 
code, especially for stable, production systems.

System Implementation, Deployment, and Maintenance Issues
137
the  infected  software,  requiring  that  someone  be  flown  on-site  to  each 
 customer location around the country to repair the damage.
While many organizations institute mandatory code reviews for develop-
ment of new systems or for significant new modules in existing systems, 
several insiders were able to inject malicious code into stable production 
systems without detection. Ineffective configuration or change control pro-
cesses contributed to their ability to do so. A few organizations in the cases 
examined implemented configuration-management systems that recorded 
a detailed log of the malicious insider activity. However, there was no pro-
active process for actually controlling system releases using those systems 
or reviewing the logs to detect malicious activity after the fact.
Attribution
During the software development process, organizations are vulnerable to 
the same types of insider attacks that can occur on production systems. One 
software development project manager, recognizing there was no way to 
attribute actions to a single user in the development environment, repeat-
edly sabotaged his team’s project. The motivation in this case is unique: His 
team was falling behind in the project schedule, and he used the repeated 
sabotage as a convenient excuse for missed deadlines. It is important that 
organizations consider security during the development process just as on 
production systems.
System Deployment
A variety of oversights in the process of moving a system from develop-
ment  to  production  provided  avenues  for  attack  by  insiders.  Examples 
from several different cases follow.
NOTE
Inability to attribute actions to a single user enabled insiders to sabotage 
projects.
NOTE
Oversights in moving a system from development to production provided 
avenues for attack by insiders.

Chapter 5.  Insider Threat Issues in the Software  Development Life Cycle
138
 

Programming Techniques Used As an Insider Attack Tool
139
these types of issues for any infrastructure technologies you have acquired. 
It is important that you carefully consider these types of issues as you move 
systems from development to production because employees using those 
systems on a daily basis will likely notice the vulnerabilities.
Backups
Insiders were able to sabotage backup systems that were left unprotected to 
amplify their attack. Risk management of critical systems needs to extend 
beyond the system itself to surrounding support systems, such as backups.
Programming Techniques Used As an Insider 
Attack Tool
In this section we do a deep dive into insiders who used programming 
techniques as an attack tool.3 We find these cases to be very interesting, 
and  think  that  they  might  open  your  eyes  to  new  attack  vectors.  Most 
of  these  attacks  were  conducted  by  system  administrators  or  program-
mers,  although  a  few  were  conducted  by  managers  and  other  technical 
staff members. Most were current employees when they committed their 
crimes, although in some cases the impact was not realized until after the 
insider left the organization. The majority of the employees struck at the 
workplace, but many launched their attack remotely.
The  majority  of  the  insiders  were  motivated  by  revenge  against  their 
employers,  but  more  than  one-third  were  motivated  by  financial  gain. 
Other motives include recognition and ideology.
The following case summaries describe how some of the insiders modified 
production source code or scripts to perpetrate their attacks. The methods 
used to achieve these objectives suggest countermeasures that should be con-
sidered to help mitigate risks associated with these types of insider attacks.
3.  Material  from  this  section  includes  portions  from  the  joint  CyLab  and  CERT  Program  article 
 “Spotlight On: Programming Techniques Used as an Insider Attack Tool,” authored by Dawn Cappelli, 
Thomas Caron, Randy Trzeciak, and Andrew Moore [Cappelli 2008a].
NOTE
Ineffective or lack of backup processes amplified the impact of insiders’ 
mass deletion of data.

Chapter 5.  Insider Threat Issues in the Software  Development Life Cycle
140
Modification of Production Source Code or Scripts
Here are several cases of modification of production source code or scripts.
Case 1: A consultant modified source code used by his former employer, 
an Internet service provider (ISP), and disabled its communications capa-
bility for three weeks. He gained remote access to the ISP’s radio-tower 
computer, and then used administrator passwords to reprogram the wire-
less access points of 110 of its customers, cutting off their Internet service. 
He reprogrammed the access points to complicate repair efforts, requiring 
that the service provider dispatch technicians to the premises of the sub-
scribers who lost Internet access, an effort that extended over a three-week 
period. His actions also disrupted the communications of other ISPs out-
side the victim’s network.
Case 2: A system administrator, fearing company layoffs, embedded mali-
cious code within scripts on the organization’s servers. The code was set to 
execute on his next birthday, approximately six months in the future. Had 
he been successful, the code would have wiped out critical data on more 
than 70 servers and caused widespread financial damage. It also would 
have caused potential health risks to the organization’s customers. Even 
after surviving the layoffs a few days later, the insider did not remove the 
malicious code; in fact, he modified it one month later. The malicious code 
contained a programming error and failed to execute on his birthday as 
scheduled.  However,  the  insider  allegedly  corrected  the  programming 
error six months later, setting the code to execute on his next birthday. 
 Fortunately, a few months before the intended execution date, another sys-
tem administrator investigating a system error discovered the  malicious 
code and disabled it.
Case 3: A contractor hired as a system administrator wrote a logic bomb to 
delete all of the organization’s files. He placed the logic bomb in two dif-
ferent scripts. The first was in an operating system script that rotated log 
files when a volume reached a certain point; rather than rotating log files 
it would execute his logic bomb. He placed the second logic bomb in his 
supervisor’s log-in script. The logic bomb was set up to display a threaten-
ing and insulting message to his supervisor during login, execute the logic 
bomb, and remove all traces of the logic bomb from the system, including 
log files.
Case 4: Following termination, a former application developer at a con-
sumer  data  marketing  firm  remotely  logged  in  to  the  organization’s 
systems  and  modified  its  Web  site  by  inserting  pornographic  images. 
While this attack did not definitively use programming techniques, we 
chose to include it in this chapter due to the serious consequences.

Programming Techniques Used As an Insider Attack Tool
141
 

Chapter 5.  Insider Threat Issues in the Software  Development Life Cycle
142
 rendering  the  organization’s  systems  inaccessible.  This  action  followed 
a  year  of  unmet  demands  and  threats  by  the  consultant.  The  insider 
intended to return the code once his demands were met.
Case 4: A system administrator, disgruntled because his yearly bonus was 
not as large as he expected, built and deployed a logic bomb that deleted 
10 billion files and took down more than 2,000 servers around the country. 
He was able to distribute the malicious code by using the standard soft-
ware distribution methods.
Mitigation Strategies
Mitigation strategies for insiders who exploit vulnerabilities in the SDLC to 
sabotage critical systems include the following.
•  Resilient system architecture that allows for efficient recovery or sus-
tains  the  organization  during  disasters.  The  requirements  for  the 
architecture should be defined at the beginning of each project so as to 
set expectations for recovery in the event an incident occurs that dis-
rupts operations.
•  Configuration and access control of source code. All attempts to access 
source code in development and production should be tracked and reg-
ular audits of access to source code should be performed.
•  Formal code review/inspection to prevent malicious code from being 
inserted into production systems.
The mitigation strategy for insiders who exploit vulnerabilities in the SDLC 
to commit fraud involves automated workflow processes. These processes 
should enforce proper authorizations, approvals, and separation of duties 
for critical business functions.
Mitigation strategies for insiders who exploit vulnerabilities in the SDLC to 
steal source code focus on configuration and access control of source code. 
Source code in development and production should be monitored closely 
to  ensure  it  is  not  being  moved  off  the  organization’s  network  without 
knowledge and approval of the organization.

Free ebooks ==>   www.Ebook777.com
Summary
143
Summary
In this chapter we presented one specific type of insider threat: those that 
exploited the Software Development Life Cycle. Some insiders took advan-
tage of oversights in the requirements and design phases of the SDLC to 
carry out their attacks. Others were software engineers or system adminis-
trators who actually injected malicious code into the source code in order 
to commit IT sabotage or fraud.
This chapter was intended to raise awareness of this type of insider threat 
so  that  you  realize  that  you  need  to  involve  your  software  engineering 
teams in your mitigation strategies.
In  the  next  chapter,  Best  Practices  for  the  Prevention  and  Detection  of 
Insider Threats, we present an entire collection of best practices that we 
have accumulated based on the actual crimes in the CERT database. That 
chapter  includes  best  practices  that  are  applicable  to  the  SDLC-related 
crimes described in this chapter, as well as all insider threats covered in 
this book.
www.Ebook777.com

This page intentionally left blank 

145
Chapter  6
Best Practices 
for the Prevention 
and Detection of 
Insider Threats
 
1.  This chapter includes portions from “Common Sense Guide to Prevention and Detection of Insider 
Threats 3rd Edition–Version 3.1, ” by Dawn Cappelli, Andrew Moore, Randall Trzeciak, and Timothy 
J. Shimeall.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
146
along with your data owners, understand the overall scope of the problem 
and communicate it to all employees in your organization.
We briefly describe each practice, explain what you should do, and provide 
a  few  actual  case  examples  illustrating  what  could  happen  if  the  prac-
tice is not implemented. Finally, we describe how the practice could have 
 prevented an attack or facilitated early detection.
While you read, please remember everything else you have read so far in 
this book regarding contractors and trusted business partners. Although 
we usually use the term employee in this chapter, much of this chapter also 
applies to contractors and trusted business partners. Please keep this in 
mind, and do not overlook those insiders!
 

Summary of Practices
147
policies  are  discussed  in  this  practice.  In  addition,  consistent  policy 
enforcement is important. Some employees in our cases felt they were 
being treated differently than other employees, and retaliated against 
this  perceived  unfairness  by  attacking  their  employer’s  IT  systems. 
Other insiders were able to steal or modify information due to inconsis-
tent or unenforced policies.
•  Practice 3: Institute periodic security awareness training for all 
employees.
A culture of security awareness must be instilled in your organization 
so that all employees understand the need for policies, procedures, and 
technical controls. All employees in your organization must be aware 
that security policies and procedures exist, that there is a good reason 
why they exist, that they must be enforced, and that there can be serious 
consequences for infractions. They also need to be aware that individu-
als, either inside or outside the organization, may try to co-opt them into 
activities counter to your mission. Each employee needs to understand 
your security policies and the process for reporting policy violations.
•  Practice 4: Monitor and respond to suspicious or disruptive behavior, 
beginning with the hiring process.
You should attempt to identify suspicious or disruptive behavior by 
individuals before they are hired, and closely monitor employee behav-
ior  in  the  workplace,  including  repeated  policy  violations  that  may 
indicate  or  escalate  into  more  serious  criminal  activity.  The  effect  of 
 personal and professional stressors should also be considered.
•  Practice 5: Anticipate and manage negative workplace issues.
This  practice  describes  suggestions  beginning  with  preemployment 
issues,  continuing  through  employment,  and  including  termination 
issues. For example, you need to clearly formulate employment agree-
ments and conditions of employment. Responsibilities and constraints 
of  the  employee  and  consequences  for  violations  need  to  be  clearly 
communicated and consistently enforced. In addition, workplace dis-
putes or inappropriate relationships between coworkers can serve to 
undermine a healthy and productive working environment. Employees 
should feel encouraged to discuss work-related issues with a member 
of management or human resources without fear of reprisal or negative 
consequences. Managers need to address these issues when discovered 
or  reported,  before  they  escalate  out  of  control.  Finally,   contentious 
employee  terminations  must  be  handled  with  utmost  care,  as  most 
insider IT sabotage attacks occur following termination.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
148
 

Summary of Practices
149
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
150
systems  or  networks  at  work.  Insiders  tend  to  feel  more  confident 
and less inhibited when they have little fear of scrutiny by coworkers; 
therefore, remote access policies and procedures must be designed and 
implemented very carefully. When remote access to critical systems is 
deemed necessary, you should consider offsetting the added risk with 
requiring  connections  only  via  organization-owned  machines  and 
closer logging and frequent auditing of remote transactions.  Disabling 
remote  access  and  collection  of  your  equipment  is   particularly 
 important for  terminated employees.
•  Practice 14: Deactivate computer access following termination.
When  an  employee  or  contractor  terminates  employment,  whether 
the  circumstances  were  favorable  or  not,  it  is  important  that  you 
have in place a rigorous termination procedure that disables all of the 
employee’s access points to your physical locations, networks, systems, 
applications,  and  data.  Fast  action  to  disable  all  access  paths  avail-
able  to  a  terminated  employee  requires  ongoing  and  strict  tracking 
and management practices for all employee avenues of access includ-
ing  computer  system  accounts,  shared  passwords,  and  card-control 
 systems.
•  Practice 15: Implement secure backup and recovery processes.
No organization can completely eliminate its risk of insider attack; risk 
is inherent in the operation of all organizations. However, with a goal of 
organizational resiliency, risks must be acceptable to the stakeholders, 
and as such, impacts of potential insider attacks must be minimized. 
Therefore, it is important for you to prepare for the possibility of insider 
attack  and  minimize  response  time  by  implementing  secure  backup 
and recovery processes that avoid single points of failure and are tested 
periodically. This practice contains descriptions of insider threat cases 
in which the organization’s lack of attention to incident response and 
organizational resiliency resulted in serious disruption of service to its 
customers.
•  Practice 16: Develop an insider incident response plan.
You need to develop an insider incident response plan to control the 
damage  due  to  malicious  insiders.  This  is  challenging  because  the 
same  people  assigned  to  a  response  team  may  be  the  insiders  who 
can use their technical skills against you. Only those responsible for 
carrying out the plan need to understand and be trained on its execu-
tion. Should an insider attack, it is important that you have evidence 
in hand to  identify the insider and follow up appropriately. Lessons 
learned should be used to continually improve the plan.

151
Practice 1: Consider Threats from Insiders and Business Partners
Practice 1: Consider Threats from Insiders and Business 
Partners in Enterprise-Wide Risk Assessments
You  need  to  develop  a  comprehensive  risk-based  security  strategy  to 
 protect your critical assets against threats from inside and outside, as well 
as trusted business partners who are given authorized insider access.
What Can You Do?
It  is  not  practical  for  most  organizations  to  implement  100%  protection 
against every threat to every organizational resource. Therefore, it is impor-
tant to focus on protecting your critical information and resources and not 
direct significant effort toward protecting relatively unimportant data and 
resources. A realistic and achievable security goal is to protect those assets 
deemed critical to your mission from both external and internal threats.
Risk  is  the  combination  of  threat,  vulnerability,  and  mission  impact. 
 Enterprise-wide  risk  assessments  help  identify  critical  assets,  potential 
threats to those assets, and mission impact if the assets are compromised. 
You should use the results of the assessment to develop or refine your over-
all strategy for securing your systems, striking the proper balance between 
countering the threat and accomplishing your mission.2
You need to understand the threat environment under which your  systems 
operate in order to accurately assess enterprise risk. Characterization of 
the threat environment can proceed in parallel with evaluation of the vul-
nerability and its impact. However, the sooner the threat environment can 
be characterized, the better. The purpose of this practice is to assist you 
in correctly assessing the insider threat environment, your vulnerabilities 
that enable that threat, and potential impacts that could result from insider 
 incidents, including financial, operational, and reputational.
Unfortunately, many organizations focus on protecting information from 
access or sabotage by those external to the organization and overlook insid-
ers. Moreover, an information technology and security solution designed 
without consciously acknowledging and accounting for potential insider 
threats  often  leaves  the  role  of  protection  in  the  hands  of  some  of  the 
 potential threats—the insiders themselves. It is imperative that you rec-
ognize the potential danger posed by the knowledge and access of your 
employees,  contractors,  and  business  partners,  and  specifically  address 
that threat as part of an enterprise risk assessment.
2.  See www.cert.org/resilience/.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
152
Understanding  your  vulnerability  to  a  threat  is  also  important,  but 
 organizations  often  focus  on  low-level  technical  vulnerabilities,  for 
example,  by  relying  on  automated  computer  and  network  vulnerability 
scanners. While such techniques are important, our studies of insider threat 
have indicated that vulnerabilities in an organization’s business processes 
are at least as important as technical vulnerabilities. You need to manage 
the impact of threats rather than chase individual technical vulnerabilities.
In addition, new areas of concern have become apparent in recent cases, 
including legal and contracting issues. Organizations are increasingly out-
sourcing critical business functions. As a result, people external to your 
organization sometimes have full access to your policies, processes, infor-
mation, and systems; access and knowledge previously only provided to 
your employees. You need to recognize the increased risk; your enterprise 
boundary includes all people who have an understanding of and privi-
leged access to your organization, information, and information systems.
Insider  threats  may  impact  the  integrity,  availability,  or  confidentiality 
of  information critical to your mission. Insiders have affected the integ-
rity of their organizations’ information in various ways; for example, by 
manipulating  customer  financial  information  or  defacing  their  employ-
ers’ Web sites. They have also violated confidentiality of information by 
stealing  trade  secrets  or  customer  information.  Still  others  have  inap-
propriately  disseminated  confidential  information,  including  private 
customer  information  as  well  as  sensitive  email  messages  between  the 
organization’s management. Finally, insiders have affected the availabil-
ity of their organization’s information by deleting data, sabotaging entire 
systems and networks, destroying backups, and committing other types of 
 denial-of-service attacks.
In those types of insider incidents, current or former employees,  contractors, 
or business partners were able to compromise their organizations’ critical 
assets. It is important that protection strategies are designed focusing on 
those assets: financial data, confidential or proprietary information, and 
other mission-critical systems and data.
Case Studies: What Could Happen if I Don’t Do It?
An insider was the sole system administrator for his organization. One 
day, he quit with no prior notice. His organization refused to pay him 
for his last two days of work, and he subsequently refused to give the 
 organization the passwords for its system administrator accounts. Over a 
period of three days, the insider modified the systems so that employees 
could not access them, defaced the company Web site, and deleted files.

153
Practice 1: Consider Threats from Insiders and Business Partners
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
154
He received almost 100 shipments with a retail value of almost $5 million 
and sold the equipment on the Internet.
This incident indicates the need to have transaction verification built into 
supplier agreements. Even though operations might be outsourced, you 
still need to include those operations in your enterprise risk assessment 
so  that  you  can  ensure  that  your  trusted  business  partners  implement 
 adequate controls against insider threat in their organizations.
A system administrator had authorized access to sanitized databases of 
customer information on an FTP server hosted by one of his organiza-
tion’s business partners. The business partner was contracted by financial 
institutions  and  phone  companies  to  perform  services  using  customer 
data.  He  located  an  unsanitized  version  of  these  customer  databases 
when looking around on the FTP server. The databases were protected 
with  passwords  and  encryption.  The  insider  ran  a  password  cracking 
utility and obtained more than 300 passwords he could use to access the 
protected information. He found original and complete phone records, 
billing information, and other PII for millions of Americans. He proceeded 
to download millions of customer records from the databases, including 
Social Security numbers, birthdates, and other personal information. The 
insider bragged in online IRC channels about his access to confidential 
and personal data, and was asked at one point by another individual in 
the chat room to provide data on an FBI agent who was actively inves-
tigating him. The insider provided the information within minutes. The 
ongoing FBI investigation of that individual led back to the insider, who 
was found with dozens of CDs and other media containing millions of 
customer records in his apartment.
In  this  case,  proprietary  information  from  the  original  organizations’ 
 customers  was  inadequately  protected  from  access  by  a  third  organi-
zation  that  was  subcontracted  by  a  second  organization,  the  trusted 
business partner. Legal controls to ensure contractor compliance with your 
data-handling policies could be employed to protect against the extended 
pool of insiders created by working with vendors and other external part-
ners. These measures would allow contractors to perform their work, while 
 protecting your sensitive information.

Practice 2: Clearly Document and Consistently Enforce Policies and Controls
155
Practice 2: Clearly Document and Consistently Enforce 
Policies and Controls
A  consistent,  clear  message  on  organizational  policies  and  controls  will 
help reduce the chance that employees will commit a crime or lash out at 
the organization for a perceived injustice.
What Can You Do?
Policies  or  controls  that  are  misunderstood,  not  communicated,  or 
 inconsistently enforced can breed resentment among employees and can 
potentially result in harmful insider actions. For example, multiple insiders 
in cases in the CERT database took intellectual property they had created 
to a new job, not realizing that they did not own it. They were quite sur-
prised when they were arrested for a crime they did not realize they had 
 committed.
You should ensure the following with regard to your policies and controls:
•  Concise and coherent documentation, including reasoning behind the 
policy, where applicable
•  Fairness for all employees
•  Consistent enforcement
•  Periodic employee training on the policies, justification, implementa-
tion, and enforcement
You should be particularly clear on policies regarding
•  Acceptable use of your systems, information, and resources
•  Ownership of information created as a paid employee or contractor
•  Evaluation  of  employee  performance,  including  requirements  for 
 promotion and financial bonuses
•  Processes and procedures for addressing employee grievances
As individuals join your organization, they should receive a copy of your 
policies that clearly lays out what is expected of them, together with the 
consequences of violations. You should retain evidence that each  individual 
has read and agreed to your policies.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
156
Employee  disgruntlement  was  a  recurring  factor  in  insider  incidents; 
 particularly in insider IT sabotage cases. As explained in Chapter 2, Insider 
IT Sabotage, disgruntlement is usually caused by some unmet  expectation 
on  the  part  of  the  insider.  Examples  of  unmet  expectations  observed  in 
cases include
•  Insufficient salary increase or bonus
•  Limitations on use of company resources
•  Diminished authority or responsibilities
•  Perception of unfair work requirements
•  Poor coworker relations
Clear documentation of policies and controls can help prevent employee 
misunderstandings  that  can  lead  to  unmet  expectations.  Consistent 
enforcement can ensure that employees don’t feel they are being treated 
differently from or worse than other employees. In one case, employees 
had become accustomed to lax policy enforcement over a long period of 
time.  New  management  dictated  immediate  strict  policy  enforcement, 
which caused one employee to become embittered and strike out against 
the organization. In other words, policies should be enforced consistently 
across all employees, as well as consistently enforced over time.
Of course, organizations are not static entities; change in organizational 
policies and controls is inevitable. Employee constraints, privileges, and 
responsibilities  change  as  well.  You  need  to  recognize  times  of  change 
as  particularly  stressful  times  for  employees,  recognize  the  increased 
risk that comes along with these stress points, and mitigate it with clear 
 communication regarding what employees can expect in the future.
Case Studies: What Could Happen if I Don’t Do It?
Two  contractors  were  formerly  employed  as  software  developers  for  a 
company that provided news filtering and distribution services to Web 
sites. In response to their termination, their legal counsel faxed a letter 
to the company. The letter insisted that the insiders owned the software 
they had created during their employment, and demanded that the com-
pany stop using the software and return all copies to them. On the evening 
before a holiday, the insiders used a home computer and their own creden-
tials, which were still active, to remotely access the company’s network 
and download the proprietary software and business plans. The insiders 
were arrested after the company discovered the unauthorized access, and 
connected them to the theft using their usernames and system logs.

Practice 2: Clearly Document and Consistently Enforce Policies and Controls
157
In this case, it is clear that there was confusion regarding who owned the 
software the contractors had created for the company. Intellectual property 
ownership should be documented in formal policies that are clearly com-
municated to all employees and contractually enforced for all contractors 
and trusted business partners. In addition, you should have your employ-
ees  re-sign  the  agreements  periodically.  We  have  discussed  this  with 
several organizations who instituted IP agreements for all employees more 
than 20 years ago. All employees signed them at that time, and all new 
employees  now  sign  them.  However,  some  employees  have  not  signed 
again since they originally signed more than 20 years ago! It is debatable 
whether those aged agreements would stand up in a court of law!
You might also consider incorporating a new angle into your IP  agreements 
to protect yourself from being the unknowing recipient of stolen IP from 
another  organization. As  part  of  your  IP  agreement  that  you  make  new 
employees sign, you might want to include a statement attesting to the fact 
that they have not brought any IP from any previous employer with them 
to your organization.
An insider accepted a promotion, leaving a system administrator position 
in one department for a position as a systems analyst in another depart-
ment of the same organization. In his new position, he was responsible for 
information sharing and collaboration between his old department and 
the new one. The following events ensued.
•  The original department terminated his system administrator account 
and issued him an ordinary user account to support the access required 
in his new position.
•  Shortly  thereafter,  the  system  security  manager  at  the  original 
 department noticed that the former employee’s new account had been 
granted unauthorized system administration rights.
•  The security manager reset the account back to ordinary access rights, 
but a day later found that administrative rights had been granted to it 
once again.
•  The security manager closed the account, but over the next few weeks 
other accounts exhibited unauthorized access and usage patterns.
An  investigation  of  these  events  led  to  charges  against  the  analyst  for 
misuse  of  the  organization’s  computing  systems.  These  charges  were 
eventually  dropped,  in  part  because  there  was  no  clear  policy  regard-
ing account sharing or exploitation of vulnerabilities to elevate account 
 privileges.
This case illustrates the importance of clearly established policies that are 
consistent across departments, groups, and subsidiaries of the  organization.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
158
There  are  many  cases  in  the  CERT  database  where  an  employee 
 compromised an organization’s information or system in order to address 
some perceived injustice.
•  An insider planted a logic bomb in an organization’s system because 
he felt that he was required to follow stricter work standards than his 
f ellow employees.
•  In reaction to a lower bonus than expected, an insider planted a logic 
bomb that would, he expected, cause the organization’s stock value to 
go down, thus causing stock options he owned to increase in value.
•  A  network  administrator  who  designed  and  controlled  an  organi-
zation’s  manufacturing  support  systems  detonated  a  logic  bomb  to 
destroy his creation because of his perceived loss of status and control.
•  A quality-control inspector, who believed his employer insufficiently 
addressed the quality requirements of its product, supplied confiden-
tial company information to the media to force the company to deal 
with the problem.
•  An insider, who was upset about his company’s practice of canceling 
insurance policies for policy holders who paid late, provided sensitive 
company information to the opposing lawyers engaged in a lawsuit 
against the company.
What these insiders did is wrong and against the law. Nevertheless, more 
clearly defined policies and grievance procedures for perceived policy vio-
lations might have avoided the serious insider attacks experienced by these 
organizations.

Practice 3: Institute Periodic Security Awareness Training for All Employees
159
Practice 3: Institute Periodic Security Awareness 
Training for All Employees
Without broad understanding and buy-in from the organization, technical 
or managerial controls will be short-lived.
What Can You Do?
All employees need to understand that insider crimes do occur, and there 
are severe consequences. In addition, it is important for them to under-
stand that malicious insiders can be highly technical people or those with 
 minimal technical ability. Ages of perpetrators in the CERT database range 
from late teens to retirement. Both men and women have been malicious 
insiders, including introverted “loners,” aggressive “get it done” people, 
and  extroverted  “star  players.”  Positions  have  included  low-wage  data 
entry clerks, cashiers, programmers, artists, system and network adminis-
trators, salespersons, managers, and executives. They have been new hires, 
long-term  employees,  currently  employed,  recently  terminated,  contrac-
tors, temporary employees, and employees of trusted business partners. 
There is not one demographic profile for a malicious insider.
Security awareness training should encourage observation of behavior in 
the workplace to identify employees who may be at higher risk of malicious 
activity, not by stereotypical characteristics. Behaviors of concern include
•  Threats  against  the  organization  or  bragging  about  the  damage  one 
could do to the organization
•  Association  with  known  criminals  or  suspicious  people  outside  the 
workplace
•  Large downloads close to resignation
•  Use  of  organization  resources  for  a  side  business,  or  discussions 
 regarding starting a competing business with coworkers
•  Attempts to gain employees’ passwords or to obtain access through 
trickery  or  exploitation  of  a  trusted  relationship  (often  called  social 
engineering)
Your managers and employees need to be trained to recognize recruitment 
in which an insider engages other employees to join his schemes, particu-
larly to steal or modify information for financial gain. Warning employees 
of  this  possibility  and  the  consequences  may  help  to  keep  them  on  the 
watch for such manipulation and to report it to management.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
160
Social engineering is often associated with attempts to gain either physical 
access or electronic access via accounts and passwords. Some of the CERT 
database cases reveal social engineering of a different type, however. In one 
case, a disgruntled employee placed a hardware keystroke logger on a com-
puter at work to capture confidential company information. After being 
fired unexpectedly, the now-former employee tried to co-opt a nontechni-
cal employee still at the company to recover the device for him. Although 
the employee had no idea the device was a keystroke logger, she was smart 
enough to recognize the risk of providing it to him and notified manage-
ment instead. Forensics revealed that he had transferred the keystrokes file 
to his computer at work at least once before being fired.
Training programs should create a culture of security appropriate for your 
organization and include all personnel. For effectiveness and longevity, the 
measures used to secure your organization against insider threat need to be 
tied to the organization’s mission, values, and critical assets, as determined 
by an enterprise-wide risk assessment. For example, if your organization 
places a high value on customer service quality, you may view customer 
information as its most critical asset and focus security on protection of 
your  data. Your  organization  could  train  your  employees  to  be  vigilant 
against malicious employee actions, focusing on a number of key issues, 
including
•  Detecting  and  reporting  disruptive  behavior  by  employees  (see 
Practice 4)
•  Monitoring  adherence  to  organizational  policies  and  controls  (see 
 Practices 2 and 11)
•  Monitoring  and  controlling  changes  to  organizational   systems—
for  example,  to  prevent  the  installation  of  malicious  code  (see 
Practices 9 and 11)
•  Requiring  separation  of  duties  between  employees  who  modify 
customer  accounts  and  those  who  approve  modifications  or  issue 
 payments (see Practice 8)
•  Detecting and reporting violations of the security of the organization’s 
facilities and physical assets (see Practice 6)
•  Planning for potential incident response proactively (see Practice 16)
Training on reducing risks to customer service processes would focus on
•  Protecting computer accounts used in these processes (see Practice 7)
•  Auditing access to customer records (see Practice 12)

Practice 3: Institute Periodic Security Awareness Training for All Employees
161
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
162
 

Free ebooks ==>   www.Ebook777.com
Practice 3: Institute Periodic Security Awareness Training for All Employees
163
its intellectual property on the CD. An investigation confirmed the theft, 
specifically  of  proprietary  source  code.  The  contractor  was  arrested, 
 convicted, and sentenced to one year of work furlough.
This case demonstrates many interesting security awareness issues. First, 
would your custodial staff or security guards fall for that scheme? Don’t 
forget them when preparing and delivering your security awareness train-
ing! Second, do you educate your employees to report suspicious activity 
in their offices? Would they fall for this ploy? What would your employ-
ees do if they caught someone in their office after hours? Finally, there is 
good news at the end of this case: The organization was suspicious enough 
to notify law enforcement of the departing contractor carrying a CD out 
with him.
The  lead  developer  of  a  mission-critical  safety-related  application  had 
extensive control over the application source code. The only copy of the 
source code was on his laptop, there were no backups performed, and 
very little documentation existed, even though management had repeat-
edly  requested  it.  The  insider  told  coworkers  he  had  no  intention  of 
documenting the source code and any documentation he did write would 
be obscure.
A month after learning of a pending demotion, he erased the hard drive 
of his laptop, deleting the only copy of the source code the organization 
possessed, and quit his job. It took more than two months to recover the 
source code after it was located by law enforcement in encrypted form 
at  the  insider’s  home. Another  four  months  elapsed  before  the  insider 
provided the password to decrypt the source code. During this time the 
organization had to rely on the executable version of the application, with 
no ability to make any modifications.
This case could have had dire consequences due to the critical nature of 
the application. How could the problem have been avoided? We could say 
that management should have had more direct oversight of the develop-
ment  process,  but  the  malicious  insider  was  the  lead  developer,  so  you 
can’t necessarily blame management completely. However, the insider’s 
team members were aware of the insider’s deliberate inaction; they could 
have informed management of his statements and actions in time to pre-
vent the attack. This case demonstrates the importance of educating all of 
your employees that the security and survivability of the system is every-
one’s responsibility, as well as clear procedures for reporting concerning 
behavior.
www.Ebook777.com

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
164
 
3.  See [Keeney 2005].

165
 
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
166
 

167
Practice 4: Monitor and Respond to Suspicious or Disruptive Behavior
 subcontracting  organization  probably  did  not  perform  a  background 
check prior to hiring.
Background  checks  should  be  required  for  all  potential  employees, 
 including contractors and subcontractors.
A former system administrator at a university’s cancer institute deleted 
18  months  of  cancer  research  after  quitting  because  of  personality  and 
work ethic differences between himself, his supervisor, and his coworkers. 
He had been the sole system administrator on the cancer research project 
team.  On  numerous  occasions  he  had  displayed  aggressive  and  mali-
cious (nontechnical) behaviors before quitting his job. He was not liked 
by his coworkers, but was seen as a “necessary evil” for his skills. He was 
described as very lazy—slacking on the job—but they didn’t know how to 
get rid of him. A few days after quitting, he returned to the lab. His badge 
had been disabled, so he could not enter on his own; therefore, he asked an 
employee who recognized him to let him in. Once inside the building, he 
used a key that had not been confiscated to enter the office and delete the 
cancer research.
In this case, the employee obviously exhibited concerning behaviors in the 
workplace. As stated earlier, it is important to have established policies and 
procedures for dealing with concerning behaviors in the workplace.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
168
 

Practice 5: Anticipate and Manage Negative Workplace Issues
169
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
170
 performance was affected by the team with which she worked. A transfer 
to another part of the organization might have been considered, in order to 
improve a negative situation for a historically excellent employee.
A vice president for engineering who was responsible for oversight of all 
software  development  in  the  company  was  engaged  in  a  long-running 
dispute with upper management. This dispute was characterized as ver-
bal attacks by the insider and statements to colleagues about how much 
he had upset management. He engaged in personal attacks once or twice 
a week and on one occasion, in a restaurant, screamed personal attacks at 
the CEO of the company. A final explosive disagreement prompted him 
to quit. When no severance package was offered, he copied a portion of 
the company’s product under development to removable media, deleted 
it  from  the  company’s  server,  and  removed  the  recent  backup  tapes. 
He then offered to restore the software in exchange for $50,000. He was 
charged and convicted of extortion, misappropriation of trade secrets, and 
grand theft. However, the most recent version of the software was never 
 recovered.
If the company in this case had recognized that the warning signs—the 
disruptive  behavior—could  signal  a  potential  insider  attack,  it  could 
have secured its assets and substantial losses could have been avoided. 
It  is  critical  that  managers  recognize,  manage,  and  realize  the  potential 
 consequences of negative workplace issues.

Practice 6: Track and Secure the Physical Environment
171
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
172
 

Free ebooks ==>   www.Ebook777.com
Practice 6: Track and Secure the Physical Environment
173
of those violations could enable you to detect a security violation before 
major damage is inflicted.
Finally, you need to implement a strategy for tracking and disposing of 
 documents that contain controlled information. In addition, precautions 
against insider threats must be applied to all employees, even if they appar-
ently have no access to your computing resources. Several cases involved 
the compromise of sensitive, proprietary, confidential, or secret  information 
due to lax controls involving disposal of materials containing that infor-
mation. In one case, a night-shift janitor obtained personal information for 
bank customers by searching through office trash, and then used the infor-
mation to commit identity theft. In another case, an employee was able to 
obtain documents containing trade secrets from a hopper containing con-
fidential  material  to  be  destroyed,  and  sold  the  documents  to  a  foreign 
competitor.
Case Studies: What Could Happen if I Don’t Do It?
An employee was suspended by his employer, “based on an employee 
dispute.” The employee had been subcontracted by his employer as an IT 
consultant at an energy management facility. Because he was suspended 
late Friday afternoon, his employer decided to wait until Monday morning 
to notify the energy management facility of his suspension. Late Sunday 
night he went to the energy production facility; he still had authorized 
access since facility personnel had not been notified of his suspension. He 
used a hammer to break the glass case enclosing the “Emergency power 
off button” and hit the button, shutting down some of the computer sys-
tems,  including  computers  that  regulated  the  exchange  of  electricity 
between power grids. For a period of two hours, the shutdown denied the 
organization access to the energy trading market, but fortunately didn’t 
affect the transmission grid directly.
This case raises important physical security and legal/contracting issues 
regarding contractors. These types of contracting issues were already dis-
cussed in Practice 1. This case serves as another example of why you should 
alter your contracting practices to require advance notification of pending 
employee sanctions by your subcontractors, and requiring immediate noti-
fication if one of the contractors is terminated or resigns. It also illustrates 
the potential damage that could be caused by the cascading effects from 
a  disgruntled  insider  using  physical  sabotage  to  impact  mission-critical 
 systems.
www.Ebook777.com

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
174
 
4.  See Choosing and Protecting Passwords: www.us-cert.gov/cas/tips/ST04-002.html.

175
Practice 7: Implement Strict Password- and Account-Management Policies
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
176
 

177
Practice 7: Implement Strict Password- and Account-Management Policies
not authorized. The insider was discovered when he bragged to the system 
administrator that he knew the root password. As a result, his  organization 
modified  its  policies  and  procedures  to  implement   countermeasures  to 
prevent such attacks in the future. System administrators were permitted 
to run password crackers and notify users with weak passwords, and the 
organization improved security training for  employees on how and why 
to choose strong passwords.
This case ends up being a “good-news” case when you consider how the 
organization responded to the incident!

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
178
 

Practice 8: Enforce Separation of Duties and Least Privilege
179
 separating roles responsible for key business processes and functions. Here 
are some examples:
•  Requiring  online  management  authorization  for  critical  data  entry 
transactions
•  Instituting code reviews for the software development and  maintenance 
process
•  Using configuration-management processes and technology to control 
software distributions and system modification
•  Designing  auditing  procedures  to  protect  against  collusion  among 
auditors
Physical,  administrative,  and  technical  controls  can  be  used  to  restrict 
employees’  access  to  only  those  resources  needed  to  accomplish  their 
jobs.  Access-control  gaps  often  facilitated  insider  crimes.  For  example, 
employees circumvented separation of duties enforced via policy rather 
than  through  technical  controls.  Ideally,  you  should  include  separation 
of duties in the design of your business processes and enforce them via a 
 combination of technical and nontechnical means.
These  principles  have  implications  in  both  the  physical  and  the  virtual 
worlds. In the physical world, you need to prevent employees from gaining 
physical access to resources not required by their work roles.  Researchers 
need to have access to their laboratory space but do not need access to human 
resources file cabinets. Likewise, human resources personnel need access to 
personnel records but do not need access to laboratory facilities. There is a 
direct analogy in the virtual world in which you must prevent employees 
from gaining online access to information or services that are not required 
for their job. This kind of control is often called role-based access control. 
Prohibiting access by personnel in one role from the functions permitted for 
another role limits the damage they can inflict if they become disgruntled or 
otherwise decide to exploit the organization for their own purposes.
It is important to understand that separation of duties alone is not always 
sufficient to protect against insider threats; it is one layer in a multitiered 
defense. Many of the insiders who committed fraud in the CERT database 
collaborated with at least one other insider to carry out the crime. A number 
of reasons could explain the high degree of collusion. For example, internal 
collusion could be necessary to overcome controls that enforce separation 
of duties. Given that the enforcement of separation of duties alone will not 
prevent insider attacks, it is essential that you implement a layered defense 
to decrease the likelihood of such an attack.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
180
One  pattern  observed  in  multiple  fraud  cases  involved  insiders  who 
changed the mailing address and/or email address of customers so that 
they did not receive automated notifications, bills, and other company cor-
respondences regarding fraudulent credit card accounts that the insiders 
then opened using the customer’s identity. Some banks and other organi-
zations have instituted practices for verifying customer address and email 
address changes before actually making the change in customer databases. 
This practice provides an additional control on top of the separation of 
duties that used to be sufficient for protection of such information.
Finally, it is important to design auditing procedures to detect potential 
 collusion among employees, with the assumption that collusion to  override 
separation of duties controls is quite possible.
Case Studies: What Could Happen if I Don’t Do It?
A currency trader (who also happened to have a college minor in  computer 
science)  developed  much  of  the  software  used  by  his  organization  to 
record, manage, confirm, and audit trades. He implemented obscure func-
tionality in the software that enabled him to conceal illegal trades totaling 
approximately $700 million over a period of five years. In this case, it was 
nearly  impossible  for  auditors  to  detect  his  activities.  The  insider,  who 
consented to be interviewed for the CERT Program/Secret Service Insider 
Threat Study, told the study researchers that problems can arise when “the 
fox is guarding the henhouse” [Randazzo 2004]. Specifically, his supervi-
sor managed both the insider and the auditing department responsible for 
ensuring his trades were legal or compliant. When auditing department 
personnel raised concern about his activities, they were doing so to the 
insider’s supervisor (who happened to be their supervisor as well). The 
supervisor directed auditing department personnel not to worry about his 
activities and to cease raising concern, for fear he would become  frustrated 
and quit.
This case illustrates two ways in which separation of duties can prevent an 
insider attack or detect it earlier.
•  End users of your critical systems should not be authorized to modify 
the system functionality or access the underlying data directly.
•  Responsibility  for  maintaining  critical  data  and  responsibility  for 
 auditing that same data should never be assigned to the same person.

Practice 8: Enforce Separation of Duties and Least Privilege
181
A  supervisor  fraudulently  altered  U.S.  immigration  asylum  decisions 
using his organization’s computer system in return for payments of up to 
several thousand dollars per case, accumulating $50,000 over a  two-year 
period. He would approve an asylum decision himself, request that one of 
his subordinates approve the decision, or overturn someone else’s denial 
of  an  asylum  application.  Several  foreign  nationals  either  admitted  in 
an interview or pleaded guilty in a court of law to lying on their asylum 
applications and bribing public officials to approve their applications.
The  organization  had  implemented  separation  of  duties  via  role-based 
access control by limiting authorization for approving or modifying asylum 
decisions to supervisors’ computer accounts. However, supervisors were 
able to alter any decisions in the entire database, not just those assigned 
to their subordinates. An additional layer of defense, least privilege, also 
could have been implemented to prevent supervisors from approving asy-
lum applications or overturning asylum decisions with which they or their 
teams were not involved.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
182
 

Free ebooks ==>   www.Ebook777.com
Practice 9: Consider Insider Threats in the Software Development Life Cycle
183
 
www.Ebook777.com

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
184
type of activity was more often carried out during the maintenance phase 
of the SDLC. However, one 18-year-old Web developer did use backdoors 
he had inserted into his source code during system development to access 
his former company’s network, spam its customers, alter its applications, 
and ultimately put it out of business. Code reviews and strict change con-
trol, a part of any solid software development process, could have detected 
the backdoors and perhaps saved the company.
During the software development process, you are vulnerable to the same 
types of insider attacks that can occur on production systems. One software 
development project manager, recognizing there was no way to attribute 
actions to a single user in the development environment, repeatedly sabo-
taged his own team’s project. The motivation in this case was unique: His 
team was falling behind in the project schedule, and he used the repeated 
sabotage  as  a  convenient  excuse  for  missed  deadlines.  It  is  important 
that  you  consider  resiliency  during  the  development  process  just  as  on 
 production systems.
Installation
A variety of oversights in the process of moving a system from  development 
to  production  provided  avenues  for  attack  by  insiders.  Examples  from 
 several different cases follow.
•  The same password file was used for the operational system when it 
was moved into production as had been used in the development envi-
ronment, enabling one of the developers to access and steal sensitive 
data after it had been entered into the operational system.
•  Unrestricted  access  to  all  customers’  systems  enabled  a  computer 
 technician to plant a virus directly on customer networks.
•  An  organization  implemented  a  Web  content-management  system 
that  managed  all  changes to  its public Web site. Although it used  a 
change-control system to track changes, it had no process for approval 
of changes before they were released to the Web site. As a result, a col-
lege intern, before leaving for the summer, published material intended 
to be a joke on the organization’s Web site, causing quite a scandal and 
damage to the reputation of the government agency.
It is important that you carefully consider these types of issues as you move 
a system from development to production because employees using those 
systems on a daily basis will likely notice the vulnerabilities.

Practice 9: Consider Insider Threats in the Software Development Life Cycle
185
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
186
 management system, and attributed to the project leader. Six months later, 
the insider left the company to take another job. Six months thereafter, the 
logic bomb finally detonated, causing immense confusion and disruption 
to the  company’s services to its customers.
This case exemplifies many of the issues discussed in this section. The next 
case illustrates a more low-tech incident that was enabled by oversights in 
the SDLC, with serious consequences.
The primary responsibility of a police communications operator was to 
communicate  information  regarding  driver’s  licenses  to  police  officers 
in the field. This case began when the operator was approached by an 
acquaintance and asked if she would be willing to look up information 
for  three  people  for  him,  and  she  agreed.  Over  time,  she  proceeded  to 
look up information on people in return for payment by her acquaintance. 
At some point she discovered that she not only could read information 
from  the  database,  but  also  could  use  other  system  functions.  At  that 
point, at the request of her accomplice, she began to generate, in return 
for payment, illegal driver’s licenses for people who were unable to gain 
legitimate licenses. Fortunately, a confidential informant led to her arrest 
for  fraudulently creating approximately 195 illegal driver’s licenses.
This  case  shows  the  dangers  of  overlooking  role-based  access  control 
requirements when defining system requirements, designing the system, 
and during implementation.

187
Practice 10: Use Extra Caution with System Administrators
 
5.  Privileged users:  users  who  have  an  elevated  level  of  access  to  a  network,  computer  system,  or 
 application  that  is  short  of  full  system  administrator  access.  For  example,  database  administrators 
(DBAs) are privileged users because they have the ability to create new user accounts and control the 
access rights of users within their domain.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
188
 

189
Practice 10: Use Extra Caution with System Administrators
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
190
script that sends an email to the manager of the team that the employee 
 transferred  from  three  months  after  the  transfer.  The  script  reminds 
the manager that the employee left, and lists all of the email aliases the 
employee is still on, all internal Web sites the employee still has access to, 
all shared folders the employee still has access to, and so on. The organiza-
tion has found that a three-month transition period is typically the right 
amount of time in which employees need legitimate access to both their 
new and old team’s information. After three months, the organization has 
found that most managers are ready to rescind access for their team’s for-
mer employee.
The following case demonstrates how organizational  failures in dealing 
with  disgruntled  system  administrators  and  other  privileged  users  can 
eventually result in IT sabotage.
A developer of e-commerce software for an organization decided to move 
his family to a different state, and therefore he could no longer work for the 
organization. The organization hired him as a consultant and he traveled 
across state lines to work two days a week, and telecommuted three days 
a week from home. He was disgruntled because the organization would 
not provide him the benefits he felt he deserved once he became a contrac-
tor, and the relationship continued to deteriorate. Finally, the organization 
told  him  his  employment  would  be  terminated  in  approximately  one 
month. After a week and a half, he logged in remotely from home, deleted 
the software he was developing, as well as software being developed by 
others, modified the system logs to conceal his actions, and then changed 
the root password. He then joined a telephone conference, never mention-
ing what he had done. After the telephone conference ended he reported 
that he was having problems logging in, again to conceal his actions. At 
the end of the day he announced his resignation. This action cost the orga-
nization more than $25,000, including 230 staff hours and associated costs.
In  much  of  the  text  in  this  book  we  use  the  word  employees  when  we 
really mean employees and contractors. This case points out that you cannot 
 overlook contractors who have system administrator or privileged access 
to your systems, networks, and information.

Practice 11: Implement System Change Controls
191
 
6.  Wikipedia
7.  File integrity checker: a tool that partially automates the process of identifying changes to  system 
files  or  the  addition  of  malicious  code  and  flagging  them  for  investigation.  See  www.sans.org/
resources/idfaq/integrity_checker.php for a discussion of file integrity checkers.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
192
 

Free ebooks ==>   www.Ebook777.com
Practice 11: Implement System Change Controls
193
eventually  expanded,  opening  additional  offices  and  plants  nationally 
and internationally. The insider did the following.
•  He  began  to  feel  disgruntled  at  his  diminishing  importance  to  the 
 company.
•  He launched verbal and physical assaults on coworkers.
•  He sabotaged projects of which he was not in charge.
•  He loaded faulty programs to make coworkers look bad.
He received a verbal warning and two written reprimands, was demoted, 
and finally was fired as a result of his actions. A few weeks later, a logic 
bomb executed on the company’s network, deleting 1,000 critical manu-
facturing  programs  from  the  company’s  servers.  The  estimated  cost  of 
the damage exceeded $10 million, leading to the layoff of approximately 
eighty employees. The investigation revealed that the insider had actually 
tested the logic bomb three times on the company’s network after hours 
prior to his termination.
In this case, practices for detection of malicious code would have detected 
that  a  new  program  had  been  released  with  timed  execution.  Change-
control  procedures  with  a  two-person  rule  for  release  of  system-level 
programs, and characterization procedures, could have detected the release 
of a new system file that was not part of the original system baseline.
An organization built automated monitoring into its software that sent 
automatic notification to the security officer anytime a highly restricted 
screen was used to modify information stored in the database. Role-based 
access control restricted access to this screen to a few privileged users; the 
automated notification provided a second layer of defense against illegal 
data modification using that function. However, an IT manager who had 
access to the source code modified it so that the automated notification 
was no longer sent; he simply commented out a single line of code. He 
then proceeded to use the function to steal a large sum of money from his 
employer.
Interestingly,  this  organization  had  a  configuration-management  system 
in place for software changes. When a program was compiled, a report 
was  produced  listing  which  files  were  compiled,  by  which  computer 
account,  and  when.  It  also  listed  modules  added,  modified,  or  deleted. 
 Unfortunately, this report was not monitored, and therefore the application 
changes were not detected during the year and a half over which the fraud 
was committed. Had it been monitored, or had the configuration-control 
system enforced a two-person rule for releasing new versions of software, 
the removal of the security notification would have been detected and the 
insider could not have committed the fraud.
www.Ebook777.com

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
194
Although this insider committed fraud, stop to ask yourself if you have 
any mission-critical systems that could be modified in this way. What if 
this had been a safety system, or a security system? What potential damage 
could one of your employees or contractors inflict by commenting out a 
few lines of source code?
Some cases in the CERT database involved theft of information using a 
keystroke logger—a hardware or software device that records the exact 
keystrokes entered into a computer system. Keystroke loggers can be used 
maliciously to obtain an organization’s confidential information or an indi-
vidual’s private information, and in the worst case can be used to obtain 
passwords or encryption keys.
A  claims  manager  at  an  insurance  company,  who  was  upset  with  the 
company’s  practice  of  canceling  policies  after  late  payment,  installed  a 
hardware keystroke logger on the computer of the secretary to a chief exec-
utive. Although he did not have access to the executive’s office, he realized 
that an abundance of confidential information passed from the secretary to 
and from the executive. Furthermore, her desk was not physically secured, 
like the executive’s office was. The insider used the keystroke logger to 
gather confidential information from the secretary’s computer, which he 
then sent to the legal team assembling the case against the organization.
Other cases involved software keystroke loggers.
Two insiders colluded with an external person to collect their company’s 
intellectual property and relay it to a competitor. The external collaborator 
sent an email message containing an attachment infected with a virus to 
one of the insiders. The insider deliberately double-clicked on the infected 
attachment, and it proceeded to install a keystroke logger on machines on 
the company’s network. The keystroke logger periodically sent confiden-
tial information to a competitor, who used it to lure customers away from 
the victim organization.
The  software  keystroke  logger  could  have  been  detected  by  a  change-
control process as described in this section.

Practice 12: Log, Monitor, and Audit Employee Online Actions
195
 
8.  Many  risk  management  methodologies  are  based  on  protection  of  critical  assets—for  example, 
the OCTAVE (Operationally Critical Threat, Asset, and Vulnerability Evaluation) risk-based strategic 
assessment and planning technique for security [Alberts 2003]. See also www.cert.org/octave/.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
196
 

Practice 12: Log, Monitor, and Audit Employee Online Actions
197
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
198
 

Practice 12: Log, Monitor, and Audit Employee Online Actions
199
had run several different password-cracking programs on the  company’s 
network five different times over a ten-month period. Initially, he stored 
the cracked passwords in a file on the company’s server. Later he installed 
a more sophisticated password-cracking program on the company’s sys-
tem. This program enabled him to automatically transfer all accounts and 
passwords that could be cracked to a remote computer on a periodic basis. 
Five thousand passwords for company employees were successfully trans-
ferred.
This case illustrates the importance of logging and proactive monitoring. 
Because of those practices, this insider’s actions were detected before any 
malicious activity was committed using the accounts and passwords or the 
backdoor account. The next case provides a contrasting example—one in 
which lack of auditing permitted the insider to conduct an attack that was 
less technically sophisticated but that enabled him to steal almost $260,000 
from his employer over a two-year period.
The  insider,  who  was  the  manager  of  a  warehouse,  convinced  his 
 supervisor  that  he  needed  privileged  access  to  the  entire  purchasing 
system for the warehouse. He then added a fake vendor to the list of autho-
rized suppliers for the warehouse. Over the next two years, he entered 
78 purchase orders for the fake vendor, and, although no supplies were 
ever received, he also authorized payment to the vendor. He was aware 
of approval procedures, and all of his fraudulent purchases fell beneath 
the threshold for independent approval. The bank account for the vendor 
happened to be owned by his wife. The fraud was accidentally detected by 
a finance clerk who noticed irregularities in the paperwork accompanying 
one of the purchase orders.
This fraud could have been detected earlier by closer monitoring of online 
activities by privileged users, particularly since this user possessed unusu-
ally extensive privileged access. In addition, normal auditing procedures 
could have validated the new vendor, and automated integrity checking 
could have detected discrepancies between the warehouse inventory and 
purchasing records.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
200
Practice 13: Use Layered Defense against Remote Attacks
Remote access provides a tempting opportunity for insiders to attack with 
less risk.
What Can You Do?
Insiders  often  attack  organizations  remotely,  either  using  legitimate 
access or following termination. While remote access can greatly enhance 
employee productivity, caution is advised when remote access is provided 
to  critical  data,  processes,  or  information  systems.  Insiders  have  admit-
ted to us in interviews that it is easier to conduct malicious activities from 
home because it eliminates the concern that someone could be physically 
observing the malicious acts.
The  vulnerabilities  inherent  in  allowing  remote  access  suggest  that 
 multiple layers of defense should be built against remote attack. You may 
provide remote access to email and noncritical data but should consider 
limiting  remote  access  to  the  most  critical  data  and  functions  and  only 
from machines that are administered by your organization. Access to data 
or functions that could inflict major damage to you should be limited to 
employees physically located inside the workplace as much as possible. 
Remote  system  administrator  access  should  be  limited  to  the  smallest 
group practicable, if not prohibited altogether.
When remote access to critical data, processes, and information systems 
is deemed necessary, you should offset the added risk with closer logging 
and  frequent  auditing  of  remote  transactions.  Allowing  remote  access 
only from organization-owned machines will enhance your ability to con-
trol access to information and networks and monitor the activity of remote 
employees. Information such as login account, date/time connected and 
disconnected, and IP address should be logged for all remote logins. It 
also is useful to monitor failed remote logins, including the reason the 
login failed. If authorization for remote access to critical data is kept to a 
 minimum, monitoring can become more manageable and effective.
Disabling remote access is a sometimes overlooked but critical part of the 
employee  termination  process.  It  is  critical  that  employee  termination 
 procedures include
•  Retrieving any organization-owned equipment
•  Disabling remote access accounts (such as VPN and dial-in accounts)

Practice 13: Use Layered Defense against Remote Attacks
201
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
202
source  code  and  password  files  from  the  developmental  system.  The 
unusually large size of the remote downloads raised red flags in the orga-
nization, which resulted in an investigation that traced the downloads to 
his residence and led to his arrest, prosecution, and imprisonment.
This  case  demonstrates  the  value  of  vigilant  monitoring  of  remote 
access  logs  and  reaction  to  suspicious  behavior  in  limiting  damage  to   
your  interests.

Practice 14: Deactivate Computer Access Following Termination
203
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
204
 

Practice 14: Deactivate Computer Access Following Termination
205
that other employees are aware that the person was terminated. Multiple 
insider attacks were facilitated when terminated employees were able to 
obtain physical access to the organization by piggybacking through doors, 
using the excuse that they forgot their badge.
Case Studies: What Could Happen if I Don’t Do It?
A software engineer at a high-technology company that developed and 
manufactured computer chips was terminated due to poor performance. 
He was responsible for managing an automated manufacturing system, 
and during the work week he maintained a constant remote access con-
nection from his home to the company’s network. Prior to informing him 
of his termination, the company terminated his network access, but failed 
to detect his remote access connection that was active from home. The day 
after his termination, outside of work hours and under the influence of 
alcohol, he used the open remote access connection to completely shut 
down the company’s manufacturing system by deleting critical files. Due 
to his actions, the company lost four hours of manufacturing time and had 
to load backup data to restart the manufacturing process. The incident cost 
the company $20,000 to remedy. Connection and activity logs connected 
the insider to the incident. He was arrested and convicted, but sentencing 
details were unavailable.
This case points out one easy step that you should add to your employee 
termination process, if it’s not in there already: Check for any active remote 
connections by the employee.
A  financial  organization’s  system  administrator  was  terminated  sud-
denly with no advanced notice that his employer was dissatisfied with 
his work. That night he suspected that his replacement, who he felt was 
technically inferior, had not disabled his access. He attempted to access 
the  system  from  home  and  found  that  he  was  right—his  replacement 
had failed to disable his access through the company firewall. In addi-
tion, although his account had been disabled, she had failed to change 
the password of the system administrator account. The insider used that 
account to shut down the company’s primary server, one that had been 
having  problems  and  had  in  fact  crashed  the  previous  weekend  (and 
had taken the organization an entire weekend to bring up again). It took 
the financial institution three days to bring the server back into service; 
during that time none of its  customers were able to access any of their 
accounts in any way.
This case illustrates the necessity of thoroughly disabling access, as well as 
the consequences when you have no competent backup for a single system 
administrator.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
206
A system administrator logged in one morning and was notified by her 
custom-written  login  software  that  her  last  login  was  one  hour  earlier. 
This set off immediate alarms, as she had in fact not logged in for sev-
eral days. She had previously taken steps to redirect logging of actions 
by her account to a unique file rather than the standard shell history file. 
Therefore, she was able to trace the intruder’s steps and saw that he had 
read another employee’s email using her account, and then deleted the 
standard history file for her account so that there would be no log of his 
actions. The login was traced to a computer at a subsidiary of the com-
pany. Further investigation showed that the same computer had logged 
in to the company’s system periodically for the past month, and that a for-
mer employee had accessed up to 16 of his former employer’s systems on 
a daily basis during work hours. The insider had done the following:
•  Gained access to at least 24 user accounts
•  Read email
•  Reviewed source code for his previous project
•  Deleted two software modification notices for the project
The former employee had been terminated for nonperformance and then 
went to work for the subsidiary.
This case illustrates the importance of terminating access completely for 
former  employees,  careful  monitoring  for  post-termination  access,  and 
paying particular attention to terminated technical employees.

Practice 15: Implement Secure Backup and Recovery Processes
207
Practice 15: Implement Secure Backup and Recovery 
Processes
Despite all of the precautions you take, it is still possible that an insider will 
successfully attack. Therefore, it is important that you prepare for that pos-
sibility and enhance your resiliency by implementing secure backup and 
recovery processes that are tested periodically.
What Can You Do?
Prevention of insider attacks is the first line of defense. However,  experience 
has  taught  us  that  there  will  always  be  avenues  for  determined  insid-
ers to successfully compromise a system. Effective backup and  recovery 
processes need to be in place and operational so that if compromises do 
occur  business  operations  can  be  sustained  with  minimal  interruption. 
Our research has shown that effective backup and recovery mechanisms 
affected the outcomes in actual cases, and can mean the difference between
•  Several hours of downtime to restore systems from backups
•  Weeks of manual data entry when current backups are not available
•  Months or years to reconstruct information for which no backup copies 
existed
Backup and recovery strategies should consider the following:
•  Controlled access to the facility where the backups are stored
•  Controlled access to the physical media (e.g., no one individual should 
have access to both online data and the physical backup media)
•  Separation of duties and the two-person rule when changes are made 
to the backup process
In  addition,  accountability  and  full  disclosure  should  be  legally  and 
 contractually required of any third-party vendors responsible for provid-
ing backup services, including off-site storage of backup media. It should 
be clearly stated in service level agreements the required recovery period, 
who has access to physical media while it is being transported off-site, as 
well as who has access to the media in storage. Furthermore, case examples 
throughout this book have demonstrated the threat presented by employ-
ees of trusted partners; the mitigation strategies presented for those threats 
should also be applied to backup service providers.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
208
When possible, multiple copies of backups should exist, with  redundant 
copies  stored  off-site  in  a  secure  facility.  Different  people  should  be 
responsible for the safekeeping of each copy so that it would require the 
cooperation  of  multiple  individuals  to  fully  compromise  the  means  to 
recovery. An  additional  level  of  protection  for  the  backups  can  include 
encryption,  particularly  when  the  redundant  copies  are  managed  by  a 
third-party vendor at the off-site secure facility. Encryption provides an 
additional level of protection, but it does come with additional risk. The 
two-person rule should always be followed when managing the encryp-
tion keys so that you are always in control of the decryption process in the 
event the employees responsible for backing up your information leave 
your organization.
You should ensure that the physical media on which backups are stored are 
also protected from insider corruption or destruction. Insider cases in our 
research have involved attackers who did the following:
•  Deleted backups
•  Stole backup media (including off-site backups in one case)
•  Performed actions that could not be undone due to faulty backup sys-
tems
Some system administrators neglected to perform backups in the first place, 
while others sabotaged established backup mechanisms. Such actions can 
amplify the negative impact of an attack on an organization by eliminating 
the only means of recovery. To guard against insider attack, you should
•  Perform and periodically test backups
•  Protect media and content from modification, theft, or destruction
•  Apply separation of duties and configuration-management procedures 
to backup systems just as you do for other system modifications
•  Apply  the  two-person  rule  for  protecting  the  backup  process  and 
 physical  media  so  that  one  person  cannot  take  action  without  the 
knowledge and approval of another employee
Make sure you account for pockets of development systems, or production 
systems that are maintained independently instead of being managed as 
part of your IT enterprise. These systems can be just as critical to you as 
your enterprise systems are, and they are not necessarily managed using 
the same rigor as your centrally maintained IT systems.

Practice 15: Implement Secure Backup and Recovery Processes
209
 

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
210
these programs supported the company’s critical applications.  Restoration 
of  the  deleted  files  from  backup  failed. Although  the  insider  had  been 
 responsible  for  backups,  company  personnel  believe  that  the  backups 
were not maliciously corrupted. The backups had simply not been tested 
to ensure that they were properly recording the critical data. As a result, 
the  organization’s  operations  in  North  and  South  America  were  shut 
down for two days, resulting in more than $80,000 in losses.
This case illustrates the delay that can be caused in recovery following an 
insider attack if backups are not tested periodically.

Practice 16: Develop an Insider Incident Response Plan
211
Practice 16: Develop an Insider Incident Response Plan
Procedures for investigating and dealing with malicious insiders present 
unique  challenges;  response  must  be  planned,  clearly  documented,  and 
agreed to by your managers and attorneys.
What Can You Do?
An  incident  response  plan  for  insider  incidents  differs  from  a  response 
plan for incidents caused by an external attacker. You need to minimize 
the chances that the internal perpetrator is assigned to the response team 
or is aware of its progress. This is challenging since the technical people 
assigned to the response team may be among the employees with the most 
knowledge and ability to use their technical skills against the organization. 
Another challenge of insider incident response is the hesitation or resis-
tance that managers may have to participating in an investigation. This 
hesitation could have several causes: It could divert the team’s resources 
from  mission-critical  activities,  expose  a  team  member  to  investigation, 
or expose shortcomings by management or oversights in system security, 
opening the managers up to embarrassment or liability for losses.
You need to develop an insider incident response plan with the rights of 
everyone involved in mind. Specific actions to control damage by malicious 
insiders should be identified, together with the circumstances under which 
those efforts are appropriate. The plan should describe the general pro-
cess to be followed and the responsibilities of the members of the response 
team. A  mediator  for  communication  between  the  departments  of  your 
organization needs to be assigned that is trusted by all department heads. 
Your department heads need to understand the plan and what information 
can and cannot be shared in the investigation of the incident.
The  details  of  the  insider  incident  response  plan  probably  would  not  be 
shared with all of your employees. Only those responsible for carrying out the 
plan need to understand it and be trained on its content and execution. Your 
employees may know of its existence and should be trained on how to (anon-
ymously) report suspicious behavior, as well as specific types of suspicious 
behaviors that should be reported. Your managers need to understand how 
to handle personal and professional problems and when they might indicate 
increased risk of insider compromise. If your organization experiences dam-
age due to a malicious insider or as your risks evolve—for instance, due to 
new internal or external attack vectors—your employee training should be 
updated. Lessons learned from insider  incidents should be fed back into your 
insider incident response plan to ensure its continual improvement.

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
212 
?

Free ebooks ==>   www.Ebook777.com
Summary
213
correspondence  with  reporters  discussing  the  proprietary  documents, 
articles, and meetings.
While  hindsight  is  20/20,  if  the  organization  had  executed  an  incident 
response plan at the time of the attempted extortion, it may have prevented 
the insider’s follow-on actions and have been able to prevent the flow of its 
confidential information to the media.
 
www.Ebook777.com

Chapter 6.  Best Practices for Prevention and Detection of Insider Threats
214
 information, or networks. Much of what you read in this chapter applies 
equally well to those types of insider threats!
This  chapter  presented  a  framework  that  you  can  use  across  your 
 organization. The “Common Sense Guide” (referenced at the beginning of 
this chapter) has been one of the most popular documents we have created, so 
we stand behind its usefulness and strongly encourage you to measure your 
organization’s practices against it to identify gaps that should be addressed.
When we were writing this book, the National Institute of Standards and 
Technology (NIST) was working on the next version of Special Publication 
800-53: Recommended Security Controls for Federal Information Systems and 
Organizations.9 The special publication is aimed at providing federal agen-
cies, state and local governments, and private-sector organizations a set of 
security and privacy controls to safeguard their critical assets. This new 
version will include new guidance in the form of controls to address pri-
vacy, mobility, cloud computing, industrial controls, application security, 
Web applications, and insider threats. The CERT Insider Threat Center con-
tributed input on insider threat controls to the Joint Task Force, a group 
of civilian-, defense-, and intelligence-agency information security experts 
working to produce a unified, federal IT security framework. Please refer 
to that publication10 for more information on specific controls.
References/Sources of Best Practices
This chapter described 16 practices, based on existing industry-accepted 
best practices, providing you with defensive measures that could prevent 
or facilitate early detection of many of the insider incidents other organi-
zations experienced in the hundreds of cases in the CERT insider threat 
database.  If  you  would  like  more  detail  on  implementing  any  of  the 
 practices we described, you should consult the following resources:
•  CERT RMM (www.cert.org/resilience/)
•  ISO 27002 (www.27000.org/iso-27002.htm)
•  NIST 800-53 (http://csrc.nist.gov/publications/PubsSPs.html)
•  SANS  Top  20  Security  Controls  (www.sans.org/critical-security-
controls/)
  9.  http://csrc.nist.gov/publications/nistpubs/800-53-Rev3/sp800-53-rev3-final.pdf
10.  NIST 800-53: http://csrc.nist.gov/publications/PubsSPs.html

215
Chapter  7
Technical Insider 
Threat Controls
Chapter  6,  Best  Practices  for  the  Prevention  and  Detection  of  Insider 
Threats,  covered  the  broader  range  of  insider  threat  controls,  including 
both administrative and technical controls. This chapter will be of interest 
to the more technical readers among you, as it contains suggestions for new 
technical controls you can implement to prevent and detect insider threats. 
These controls are the output of the insider threat lab. First, we describe 
the lab at a high level, then we explain how we developed these controls, 
and then we describe each control. Note that the controls become increas-
ingly sophisticated as you progress through the chapter, since we present 
them in the order they were developed. They progress from straightfor-
ward controls that many organizations do not seem to implement, to actual 
signatures that you can import into existing tools in your organization.
Since we anticipate technical experts reading this chapter, you might care 
about the details behind the lab. However, if you don’t care about the lab or 
how we created the controls you can skip right to the discussion of controls 
later in the chapter.
We do not include definitions of technical terminology in this chapter, since 
there would be far too many definitions! We assume that if you are reading 
this chapter you are technical enough to understand it without that level of 
assistance.

Chapter 7.  Technical Insider Threat Controls
216
Also, all of the signatures, rules, and queries contained in this chapter are 
also available on our Web site: www.cert.org/insider_threat. Please go to 
the Web site so that you can copy and paste or import them directly into 
your  tools.  In  addition,  we  will  continue  to  release  improvements  for 
these controls as more organizations implement them, and as we receive 
feedback  from  practitioners  on  how  to  make  them  even  more  useful  in 
an operational environment. These controls have been presented at large 
conferences such as RSA and have received very positive feedback, but 
we realize that they will need to be tailored and optimized depending on 
each organization’s specific requirements. Therefore, these controls are not 
intended to be implemented blindly, but rather should be used as a general 
template that you can customize for your own use.
The insider threat lab is the newest addition to our body of work on insider 
threat.1 In 2008 we decided that after studying the insider threat problem 
for seven years it was time to shift our focus to solutions. We felt that we 
understood insider threat as well as anyone could: who does it, how, when, 
why, where, and so on. We also had added technical security experts to our 
team at that time who had the ability and vision to embark on innovative 
new work for us. Therefore, in 2009 we started the CERT insider threat lab.
Integrating  the  insider  threat  lab  into  our  research  has  resulted  in 
 tremendous  advances  in  helping  the  community  to  better  understand 
insider threat. The lab has a variety of purposes, including the following:
•  Performing live testing of commercial and open source tools and tool 
configurations that aim to combat insider threats against re-creations of 
actual insider events from the CERT database
•  Developing new insider threat controls using existing technology
1.  Material from this chapter includes portions from previously published works. Specifically, Michael 
Hanley, Tyler Dean, Will Schroeder, Matt Houy, Randy Trzeciak, and Joji Montelibano published infor-
mation about the lab in “An Analysis of Technical Observations in Insider Theft of Intellectual Property 
Cases” [Hanley 2011b]. Joji Montelibano also published information about Control 3 in “Insider Threat 
Control: Using a SIEM Signature to Detect Potential Precursors to IT Sabotage” [Montelibano 2011]. 
Finally, Michael Hanley published information about Control 4 in “Candidate Technical Controls and 
Indicators of Insider Attack from Socio-Technical Models and Data,” in the Proceedings of the 2010 
NSA Center of Academic Excellence (CAE) Workshop on Insider Threat, and in a later refinement of 
that control [Hanley 2010, Hanley 2011a].
These controls are not intended to be implemented blindly, but rather 
should be used as a general template that you can customize for your 
own use.

Infrastructure of the Lab
217
•  Creating demonstrational videos for conferences and workshops that 
illustrate those new controls
•  Developing  online  exercises  to  give  cyberdefenders  hands-on 
 experience  to  better  prepare  them  for  insider  threats  within  their 
 organizations
Over the years, our ongoing analysis of insider cases yielded best  practices, 
models  of  insider  behavior,  training  materials,  and  other  useful  results. 
The  insider  threat  lab  enables  us  to  put  this  body  of  knowledge  into 
practice, testing our results in a realistic environment. We can determine 
the effectiveness of various controls and tools against the threat of mali-
cious insiders and are now in a better position to make concrete, technical 
 recommendations for prevention and mitigation.
Our lab team continually reviews the ever-changing commercial and open 
source tool space to ensure that we understand the available technology, 
and leverages our case studies of real incidents to draw conclusions about 
gap areas that exist in the industry. We also factor in knowledge gained 
by our insider threat assessment teams and workshop instructors regard-
ing feedback from practitioners on what’s working and not working for 
them. When we discover a new control that someone in the community is 
using successfully, we transition that via our blog, workshops, conference 
 presentations, and reports. We then focus our work in the lab on gap areas 
for which we have not found a proven solution.
In this chapter we briefly describe the infrastructure of the lab, and the 
process we use in creating demonstrational videos, new controls, and exer-
cises. Next, we describe the solutions we have developed so far in the lab. 
Note that demonstrational videos, signatures, and rules are available on 
our Web site, and we will continue to add new ones even after publication 
of this book. Keep checking our Web site periodically to ensure that you are 
picking up the latest releases from the CERT insider threat lab!
 

Chapter 7.  Technical Insider Threat Controls
218
workstations, and users in order to stage our scenario. The “macro-lab” can 
replicate a network topology of several hundred servers and workstations, 
and we have actually used this lab environment to simulate the behavior of 
up to 5,000 users.
The micro-lab consists of a few physical systems running various virtual 
machines to simulate complete networks. This flexibility provides a quick 
way  to  reconstruct  insider  attacks  and  respective  defense  mechanisms. 
It enables us to determine the effectiveness of various controls and tools 
against the threat of malicious insiders and to test our proposed new coun-
termeasures in a realistic environment. As a result, we can now provide 
concrete,  technical  recommendations  for  prevention  and  mitigation  of 
insider threats. We create realistic environments to study insider attacks 
and to evaluate candidate defense mechanisms. Additionally, the lab allows 
us to rapidly prototype small to medium-sized networks at minimal cost 
and allows us to integrate physical devices into the simulated  topology.
The  larger  macro-lab  uses  the  XNET2  environment.  XNET  is  a 
 next-generation cybersecurity training and simulation platform. Its infra-
structure  consists  of  several  server-grade  rack-mounted  servers  capable 
of  seamlessly  running  simultaneous  instances  of  virtual  machines.  The 
major  difference  between  the  micro-  and  macro-labs  is  scale.  We  also 
deploy controls in the micro-lab prior to testing it in the XNET environ-
ment. The reason for this approach is that we try to focus on the attack and 
defense mechanisms when testing in the micro-lab. Once we confirm that 
our defense strategy is sound, we then deploy the scenario in XNET, to see 
how our defensive mechanisms behave in a typical network, with a large 
amount of traffic or “noise.” Only when a control passes both of these tests 
do we release it for pilot testing in production environments.
 
2.  XNET CERT Exercise Network: http://xnet.cert.org

High-Priority Mitigation Strategies
219
at various conferences, including the RSA Conference, the U.S.  Department 
of  Defense  Cyber  Crime  Conference  (DC3),  the   Government  Forum  of 
Incident Response and Security Teams (GFIRST), the Forum of Incident 
Response and Security Teams (FIRST), and MIS  Training Institute InfoSec 
World.
The demos can be watched at the following URL: www.cert.org/insider_
threat. We release additional demos every few months, so we recommend 
that you watch that site for new releases. In this chapter we will describe 
the insider threat mitigation strategies depicted in the demos.
High-Priority Mitigation Strategies
The  first  step  in  creating  a  new  control  is  case  selection.  We  have  a 
 prioritized list of issues we feel need to be addressed, based on our cases, 
assessments, and feedback from workshop participants. We use that list to 
select the type of case—sabotage, fraud, or theft of IP—as well as the tech-
nical method we wish to address. We then pull the applicable cases from 
the CERT database, review the details for each case, and eliminate those 
without much technical detail. The final candidate cases are analyzed once 
more, and three to four cases are chosen that are interesting, are represen-
tative, and have sufficient technical detail for a demonstration. The case 
that is the most interesting to both a technical and nontechnical audience 
is the final selection. This ensures that not only is the chosen case optimal 
for a technical demonstration, but it will also be interesting for the widest 
 audience possible.
Once  the  case  is  chosen,  tools  that  could  have  detected  or  mitigated 
the  insider  attack  are  selected.  As  a  Federally  Funded  Research  and 
 Development Center (FFRDC), the Software Engineering Institute is unable 
to endorse or promote specific vendors. Therefore, we try to use open source 
tools as much as possible in our demos. However, the mitigation strategies 
we highlight in our demos can be implemented using whatever technolo-
gies you already have in place in your organization. Our goal is to teach you 
the strategy and basic functionality that can be implemented using tools 
that you likely already have in place, or provide an open source alternative.
Next, we construct the demonstration. We usually have to fill in some gaps 
in the cases with plausible details as we rarely have complete technical infor-
mation needed to re-create the case exactly. This results in a product based 
largely on a factual case with enough technical detail to make it interesting.

Chapter 7.  Technical Insider Threat Controls
220
Finally, we create the environment for the demo in the insider threat lab. 
Once  the  machines  are  built  and  the  scenario  is  working  correctly,  the 
 virtual  network  is  moved  into  the  CERT  Program’s  XNET  environment 
and the demonstrations are recorded.
These demonstrations are not meant to be critical of the victim  organizations. 
We  only  use  these  cases  as  opportunities  to  point  out  where  a  typical 
 organization could be able to intervene, and how, in given  scenarios.
In the rest of this chapter we will describe the controls we have created at 
time of publication. We will describe the case examples used in the cor-
responding demos, and then explain the countermeasures we suggest you 
consider to protect you from being a victim of a similar attack. You do not 
need to watch the videos in order to understand this chapter, but they are 
available on our Web site in order to reinforce these lessons.
Control 1: Use of Snort to Detect Exfiltration of 
Credentials Using IRC
Our  first  control  was  modeled  after  an  insider  IT  sabotage  case  that 
occurred at an Internet Service Provider (ISP). We chose this case because it 
enabled us to illustrate a fundamental concept in insider threat mitigation: 
You should consider using your intrusion detection system (IDS) to detect 
not only intrusions, as the name suggests, but also exfiltration of sensitive 
information. Snort is a popular open source IDS tool that could easily be 
tuned to examine inbound as well as outbound traffic.
A technical support employee at an Internet service provider (ISP) had 
extensive  ties  to  hacker  groups,  used  several  online  aliases,  attended 
organized hacker meetings, and communicated with hackers from work 
in online IRC chat sessions. A coworker of the insider discovered that the 
insider was attending organized hacker meetings.
The  employee’s  Internet  access  was  suspended  because  his   supervisor 
 discovered unauthorized programs on his machine, specifically a credit 
card  number  verification  program  and  a  network  sniffer.  Since  free 
 Internet access was an employee benefit, this sanction resulted in extreme 
disgruntlement. In order to exact revenge, the employee connected with an 
outside hacker via IRC chat and gave him the usernames and passwords 
for customer accounts that were expired but not disabled. The hacker then 
used those credentials to deface the ISP’s Web site and steal large amounts 
of customer information.

Control 2: Use of SiLK to Detect Exfiltration of Data Using VPN
221
Suggested Solution
Our suggested solution focuses on how a known and often rogue channel 
of communication, IRC chat, could be detected. Assuming that IRC chat is 
prohibited, a Snort rule could have been alerted on the insider/hacker IRC 
communication,  and  an  administrator  could  use  the  Basic Analysis  and 
Security Engine (BASE) user interface to investigate.
Responding to that alert, the administrator could have investigated further 
using a packet sniffing application such as Wireshark to rebuild the commu-
nication stream. Using Wireshark he could completely reconstruct the full 
communication stream between the insider and the hacker. He would have 
immediately seen the exfiltration of credentials for the dormant customer 
accounts,  as  well  as  the  hacker’s  plan  to  attack  the  organization.  Using 
open source tools, he could have prevented the attack from  occurring.
The lesson to be learned from this case is that many organizations use an 
IDS to detect attempted intrusions from outside their network.  However, 
you can also tune it to detect unauthorized communications from within 
your network. If communications mechanisms such as IRC chat are pro-
hibited  on  your  network,  this  Snort  rule  should  not  generate  many 
false-positive alerts, and therefore could be an easy, new control for your 
insider threat mitigation toolbox.
 

Chapter 7.  Technical Insider Threat Controls
222
proprietary documents. Four months later she returned to her original job 
as a full-time employee.
Over  the  next  three  days  she  purchased  a  one-way  ticket  abroad, 
 downloaded more than 200 proprietary documents, and removed physi-
cal documents from the office. Then she resigned from her job via email, 
downloaded  more  information  that  night,  and  attempted  to  leave  the 
United States with the company laptop.
Fortunately, airport security caught her with the proprietary documents 
as she was leaving the country with them. The laptop, CDs, thumb drive, 
and a videotape contained proprietary documents and source code.
Suggested Solution
Our suggested solution utilizes a CERT open source tool suite known as 
SiLK,3 which could be used to detect the exfiltration of proprietary infor-
mation from a network. The SiLK tool suite is designed to collect, store, 
and analyze network flow data, providing a valuable platform for network 
situational awareness.
A SiLK sensor could be configured to watch all traffic at the perimeter of 
a subnet where VPN connections attach to the network. A standard SiLK 
configuration can be used to identify large flows of traffic from sensitive 
file servers to users on VPN connections, indicating potentially suspicious 
traffic. Especially during an off-peak time, a network administrator could 
detect an anomaly by doing the following:
•  Recognizing  a  change  in  the  distribution  of  the  port/protocol  of 
 network traffic
•  Seeing two devices moving a large amount of data in one direction in a 
short period of time
During an off-peak time when network activity is typically low,  movement 
of a large amount of data over Windows file shares would cause the per-
centage  of  traffic  passing  the  flow  sensor  to  rapidly  rise  beyond  other 
protocols, even HTTP. This would alert the administrator to a concerning 
behavior exhibited on the network. From here, the analyst could use SiLK 
to identify the specific flows involved, and thus, the specific host on the 
VPN, for further inquiry.
3.  See http://tools.netsa.cert.org/silk/ for more information.

Free ebooks ==>   www.Ebook777.com
223
 
This is a prime example of how open source tools can be repurposed to 
assist with detection of malicious insider behavior. We are now exploring 
new alerting mechanisms using additions to the SiLK suite that process 
flow data in real time, looking for patterns that might be associated with 
data exfiltration. Keep an eye on our Web site for demonstrations of this 
new technical control in the coming months.
Control 3: Use of a SIEM Signature to Detect Potential 
Precursors to Insider IT Sabotage
After creating the first two demonstrations, we decided it was time to begin 
documenting our controls in a more formal manner, rather than simply cre-
ating demonstrations. The remainder of this section describes each control 
in more detail, and provides more implementation guidance.
This section describes development and suggested application of a Security 
Information  and  Event  Management  (SIEM)  signature  to  detect  possible 
malicious insider activity that could lead to IT sabotage. Since there is no uni-
form, standardized event logging format, we present the signature in two of 
the most visible public formats: Common Event Format (CEF) and Common 
Event Expression (CEE). Because CEF and CEE are both in draft format at 
the time of this writing, the SIEM described in this section also employs an 
operational version of the proposed signature in an ArcSight environment.
Recall that insider IT sabotage is defined as an insider’s use of  information 
technology  to  direct  specific  harm  at  an  organization  or  an  individual. 
The purpose of this analysis SIEM signature is to detect the presence of a 
 malicious insider based on key indicators related to IT sabotage activity.
A  former  software  engineer  who  had  been  employed  by  the  victim 
 organization, a huge, high-tech company, was responsible for managing an 
automated manufacturing system. During the workweek, he maintained 
a constant remote access connection from his home to the organization’s 
 network.
The  insider,  who  had  previously  worked  in  another  department  at  the 
organization, was terminated due to poor performance. Prior to informing 
the insider of his termination, the organization terminated the insider’s 
network access, but failed to check if his remote access connection was 
active. (Most organizations we have talked to about this have admitted 
that they would not catch this either.)
www.Ebook777.com

Chapter 7.  Technical Insider Threat Controls
224
 

225
 
 

Chapter 7.  Technical Insider Threat Controls
226
the office. We found that 54% of the attacks used remote access and 27% 
occurred on-site. In only 19% of the cases, the location of the attack was 
unknown. Therefore, if we discard Unknowns, 66% of the attacks occurred 
using remote access and 34% occurred on-site. Figure 7-2 presents these 
findings.
Note that even for employees “on the HR radar” who have been placed 
under targeted monitoring, the VPN connection alone does not necessar-
ily  indicate  malicious  activity.  The  insiders  in  the  CERT  database  most 
often used a remote connection to the target system after they established 
a VPN connection with the organization’s network. For this reason, we do 
not include VPN traffic as a monitored protocol, but instead we include 
the VPN username in cases where that account may differ from the user’s 
 regular username. This will become clearer as you continue reading.
Figure 7-2 Location of attack for IT sabotage cases
27%
19%
54%
On-Site
Remote Access
Location Unknown
Figure 7-1 Time of attack for IT sabotage cases
26%
39%
35%
During Work Hours
Outside Work Hours
Time Unknown

227
 
Figure 7-3 depicts the typical sequence of events associated with a remote 
attack via VPN.
The specific protocols insiders use for remote connections are not currently 
coded in the CERT database. However, through interviews with some of 
the actual perpetrators, as well as through a more detailed analysis of these 
cases, we discovered that the most common known ports used for remote 
attacks are ports 22 (SSH), 23 (Telnet), and 3389 (Terminal Services, or RDP). 
Since a majority of malicious insiders used remote access for their attacks, 
we considered instances of connections to these three ports as suspicious 
in  the  development  of  our  signature,  and  pilot  testing  by  practitioners 
validated this assertion. You will need to account for other protocols used 
in your own environment to make sure you are monitoring all possible 
 channels of communication.
Based on this analysis of the CERT database, we found that the relevant 
indicators to be included in this particular control are the location of the 
attack  and  the  time  of  the  attack. Also,  as  previously  mentioned,  since 
remote access is a common method of attack, it is important to consider 
the type of protocol the attacker uses (although this information was not 
 specifically coded in the database). This information is the basis for our 
SIEM signature.
SIEM Signature
Remember  that  this  signature  is  to  be  applied  only  to  individuals  who 
 warrant increased scrutiny. This signature should not be applied to all privileged 
users as it will generate inordinate false positives.
The  characteristics  of  the  attacker  involve  someone  accessing  the 
 organization’s information systems remotely, outside normal work hours. 
With these characteristics, we developed the following signature:
Figure 7-3 Typical remote attack activity via VPN
Malicious
Insider
VPN Connection
to Enterprise
Network
VPN Endpoint:
Entry to Network
Remote
Connection to 
Target System via
SSH/Telnet/RDP or
Other Remote
Protocols
Target System

Chapter 7.  Technical Insider Threat Controls
228
Detect <username> and/or <VPN account name> and/or <hostname> using 
<ssh> and/or <telnet> and/or <RDP> from <5:00 PM> to <9:00 AM>
The  purpose  of  the  signature  is  to  identify  the  attacker,  the  remote 
 connection protocol used, and whether this activity is occurring outside 
normal work hours. The identity of the attacker can be retrieved through 
any or all of the following parameters: username, VPN account name, or 
host name. Similarly, the remote connection protocol can be any or all of the 
following: SSH, Telnet, or RDP. We have based the signature on the follow-
ing key fields: username, VPN account name (in case this account name is 
different from the local username), host name of the attacker, and whether 
the attacker is using SSH, Telnet, or RDP.
With this basic structure in mind, we used two standards for creating the 
signature:  the  Common  Event  Format,  developed  by ArcSight,  and  the 
Common Event Expression, developed by MITRE. Brief summaries of each 
standard are provided in the following sections.
Common Event Format
The Common Event Format is an event interoperability standard developed 
by ArcSight. The purpose of this standard is to improve the interoperabil-
ity of infrastructure devices by instituting a common log output format for 
different technology vendors. It ensures that an event and its semantics 
contain all necessary information. CEF is an extensible, text-based format 
designed to support multiple device types in the easiest way possible. It 
defines syntax for log records consisting of a standard header and a vari-
able extension that is formatted as key-value pairs. This format contains 
the most relevant information, which makes it easier for event consumers 
to parse and use them. The format of CEF is (header/extension):
CEF:Version|Device Vendor|Device Product|Device
Version|Signature ID|Name|Severity|Extension
­
Extension part of the message is a placeholder for additional fields, which 
are part of a predetermined set.

229
 
 

Chapter 7.  Technical Insider Threat Controls
230
for  <logTime>,  <user>,  <src>,  and  <shost>,  to  detect  remote  access 
 outside normal work hours in XML format, is:
<event name=”remote connection by suspected malicious insider”>
<logTime>2011-03-17T12:17:32</logtime>
<suser>maliciousinsider</suser>
<src>10.0.0.1</src>
<shost>insider_system</shost>
<prot>TCP</prot>
<dpt>{22,23,3389}</dpt>
<start>17:00:00</start>
<end>08:00:00</end>
</event>
 

231
Control 4: Use of Centralized Logging
such  as  system  administrators,  typically  connect  remotely  to  various 
 systems  outside office hours in the normal course of their daily activities. 
To determine which users merit more targeted monitoring through this sig-
nature, you will have to rely on management and human resources records 
to properly identify employees who have exhibited concerning behaviors 
that warrant closer inspection.
Conclusion
Ideally, your information security personnel should regularly  communicate 
with different departments across the enterprise, especially with HR and 
legal. They should be informed when an employee meets the threshold 
of  concerning  behavior  that  warrants  targeted  monitoring,  as  explained 
in  Chapter  2.  In  the  CERT  database,  the  vast  majority  of  insiders  who 
committed  IT  sabotage  were  guilty  of  policy  violations  and  ongoing, 
excessive, concerning behaviors in the workplace prior to the execution 
of their attack. In most cases, insiders carried out their attack via a VPN 
 connection, from which they launched remote connections to their target 
systems.  Organizations should first identify suspicious insiders and then 
have their information security staff apply the SIEM signature described in 
this  section to ensure that their actions are closely monitored.
 
The SIEM signatures described here should not be applied to a general 
user population because that will generate a large number of false positives.
You will have to rely on management and human resources records to 
properly identify employees who have exhibited concerning behaviors that 
warrant closer inspection.

Chapter 7.  Technical Insider Threat Controls
232
 
4.  www.splunk.com

233
Control 4: Use of Centralized Logging
This compelling pattern from our modeling work provides an interesting 
opportunity for a technical control.
Our goal was to create a new control using tools already being used by 
many organizations. We decided to utilize centralized logging, or a central-
ized log querying mechanism, to detect email sent to a direct competitor’s 
domain, outside the United States, containing an attachment within one 
month of termination.
 
CAUTION
It is important to note that this signature is not intended to be applied to 
all users across the enterprise, as doing so will generate a large number 
of false positives. You need to have a policy in place that defines explicit 
thresholds for monitoring of high-risk insiders, and it must be consistently 
enforced.

Chapter 7.  Technical Insider Threat Controls
234
 

235
Control 4: Use of Centralized Logging
where the intended recipient resides in an untrusted zone or in a namespace 
you otherwise have no control over. You may choose to significantly pare 
down  this  portion  of  the  query  based  on  specific  intelligence  or  threat 
information. For instance, you could specify sets of “unwanted” recipient 
addresses by country code top-level domains (ccTLD), known-bad domain 
names, or other similar criteria.
Because not all mail servers indicate an attachment’s presence in the same 
way, the query next uses byte count to indicate potential data exfiltration. 
Setting a reasonable per-day byte threshold, starting between 20 and 50 
kilobytes, should allow you to detect when several attachments, or large 
volumes of text in the bodies of email messages, leave your network on any 
given day.
An Example Implementation Using Splunk
If you are using Splunk for centralized log indexing and interrogation, you 
can configure it to raise an alert when it observes the behaviors we described. 
If you are using a different log correlation engine, you can implement the 
same functionality by replicating what we demonstrate in this section.
The  following  is  a  Splunk  rule  that  you  can  adjust  to  your  particular 
 environment. The sample rule uses a sample internal namespace to illus-
trate the implementation. We assume a generic internal namespace of corp.
merit.lab, with two servers of interest. MAILHOST is an Exchange server, 
and DC is an Active Directory domain controller.
The  characteristics  of  the  attacker  involve  someone  accessing  your 
information  systems  remotely,  outside  normal  work  hours.  With  these 
characteristics, we developed the following Splunk rule:
Terms: ‘host=MAILHOST
[search host=”DC.corp.merit.lab”
Message=”A user account was disabled. *”
| eval Account_Name=mvindex(Account_Name, -1)
| fields Account_Name
| strcat Account_Name “@corp.merit.lab” sender_address
| fields - Account_Name]
total_bytes > 50000 AND recipient_address!=”*corp.merit.lab”
startdaysago=30
| fields client_ip, sender_address, recipient_address,
message_subject, total_bytes’

Chapter 7.  Technical Insider Threat Controls
236
 

237
Control 4: Use of Centralized Logging
after  resignation.  This  can  be  adjusted  as  needed,  though  the  data  on 
insider theft of IP exhibits the 30-day pattern discussed previously.
Final Section: fields client_ip, sender_address, recipient_address, 
message_subject, total_bytes’
The final section of the query creates a table with relevant information for 
a security operator’s review. The operator receives a comma-separated val-
ues (CSV) file showing the sender, recipient, message subject line, total byte 
count, and client IP address that sent the message. This information, along 
with a finite number of messages that match these criteria, should provide 
sufficient information for further investigation.
Advanced Targeting and Automation
Originally, this control required manually identifying a user, or users, of 
interest to populate the query with targets. In fact, we find that there are 
ways to go a step further using simple tools to identify all users who have 
accounts set to expire within a 30-day window, and possibly feed these 
directly into Splunk via a command-line tool.
First,  when  an  employee  or  contractor  resigns,  you  must  set  his  or  her 
accounts to expire on his or her last day of employment. In Microsoft Active 
Directory,  you  can  quickly  identify  the  users  who  have  accounts  expir-
ing in the next 30 days by using the PowerShell AD administration tools 
with a simple, one-line query. You can run the following example query by 
importing the AD PowerShell modules. Depending on privilege delegation 
in your environment, a privileged user in the directory might be required 
to run the command.
PS C:\Users\ffishbeck_sec> Search-ADAccount -AccountExpiring -TimeSpan 
30.00:00:00
AccountExpirationDate : 7/9/2011 12:00:00 AM
DistinguishedName : CN=Brian Smith,OU=Employees,DC=corp,DC=merit, 
DC=lab
Enabled : True
LastLogonDate : 7/1/2011 18:40:03 AM
LockedOut : False
Name : Brian Smith
ObjectClass : user
ObjectGUID : a6ed88a4-fab3-494d-9f45-4d9ad11e1069
PasswordExpired : True
PasswordNeverExpires : False

Chapter 7.  Technical Insider Threat Controls
238
SamAccountName : Brian Smith
SID : S-1-5-21-2581603451-735610124-1584908375-1108
UserPrincipalName : bsmith@corp.merit.lab
AccountExpirationDate : 7/23/2011 12:00:00 AM
DistinguishedName : CN=Jennifer Burns,OU=Employees,DC=corp, 
DC=merit,DC=lab
Enabled : True
LastLogonDate : 6/29/2011 12:18:00 PM
LockedOut : False
Name : Jennifer Burns
ObjectClass : user
ObjectGUID : fdd0b06f-c929-4da9-9f89-4c9415e3d756
PasswordExpired : True
PasswordNeverExpires : False
SamAccountName : Jennifer Burns
SID : S-1-5-21-2581603451-735610124-1584908375-1110
UserPrincipalName : jburns@corp.merit.lab
AccountExpirationDate : 7/2/2011 12:00:00 AM
DistinguishedName : CN=Megan Jordan,OU=Employees,DC=corp,DC=merit,
DC=lab
Enabled : True
LastLogonDate : 6/30/2011 4:30:28 AM
LockedOut : False
Name : Megan Jordan
ObjectClass : user
ObjectGUID : 4f11a5f4-7e49-4ec7-a34b-882fb643e5a3
PasswordExpired : True
PasswordNeverExpires : False
SamAccountName : Megan Jordan
SID : S-1-5-21-2581603451-735610124-1584908375-1117
UserPrincipalName : mjordan@corp.merit.lab
Once you know which user accounts are expiring in the near future, you 
can  either  manually  populate  the  Splunk  query  with  these  LDAP  user-
names, or experiment with piping them into a command-line Splunk query. 
There are open source projects, including splunk-powershell, that would 
support this type of activity with a very simple script.5 While this project 
does not appear to work with the newest release of PowerShell 2, it does 
work with the original PowerShell binaries and will successfully query a 
current v4.1.x Splunk installation.
5.  http://code.google.com/p/splunk-powershell/

Summary
239
Conclusion
According to our research, it is very important that you carefully consider 
organizational  communications  during  the  time  frame  surrounding  an 
employee’s resignation. Many insiders have stolen information within a 
30-day window of termination from their organization. Further, many of 
these thefts occurred via use of standard corporate email servers. A well-
constructed rule set can be placed on a centralized logging appliance to 
identify  suspicious  mail  traffic  originating  from  soon-to-be-departing 
employees. These well-crafted rules, based on trends observed from actual 
cases, can reduce analysts’ workloads by presenting them with behaviors 
that are known to be malicious in several actual instances, and therefore 
merit further investigation.
Insider Threat Exercises
We recently moved the networks from the insider threat lab into the CERT 
XNET environment to create realistic training exercises for cyberdefend-
ers.  These  interactive,  team-based  exercises  re-create  complex  actual 
insider  threat  scenarios  and  challenge  participants  to  prepare  for  and 
respond to insider threat incidents. They include various injects from the 
teams running the exercise to simulate incidents. These exercises can be 
conducted within an organization to better equip its defenses against mali-
cious insiders, or can be used in cyberflag exercises to recognize the most 
sophisticated team among multiple competing organizations. Appendix A, 
Insider Threat Center Products and Services, contains a description of our 
insider threat exercises.
 

Chapter 7.  Technical Insider Threat Controls
240
like their authorized day-to-day online activity. Their behavior does not 
appear to be anomalous. In addition, many insider threat detection tools 
result  in  information  overload.  The  line  between  malicious  and  normal 
behavior is so difficult to discern that these tools end up reporting a multi-
tude of false positives that make the tools unusable. So, what is the answer?
We  have  discovered  that  it  is  possible  to  create  effective  insider  threat 
 controls using existing technology, even open source tools in many cases. 
The tools simply need to be configured and integrated based on the  patterns 
of activity observed in our insider threat models.
This chapter presented controls for using
•  Snort to detect exfiltration of credentials using IRC
•  SiLK to detect exfiltration of data using VPN
•  A SIEM signature to detect potential precursors to insider IT sabotage
•  Centralized logging to detect data exfiltration during an insider’s last 
days of employment
As you can see, we have used a variety of existing technology to detect 
insider threats based on the most common behavioral patterns in the CERT 
database. Keep checking our Web site, www.cert.org/insider_threat, as we 
continue to release more controls on an ongoing basis!
The  next  chapter  is  composed  of  many  case  examples  from  the  CERT 
 database. Throughout the years, we have found that these cases are valu-
able tools in helping practitioners, management, and other leaders to realize 
the potential threats facing organizations. As you read through the exam-
ples, ask yourself once again: Could this happen to me? Unfortunately, in 
many cases the answer will be yes. The good news is that this book can help 
you to figure out what you need to do to change the answer to no.

241
Chapter  8
Case Examples
We’ve  already  used  many  case  examples  throughout  this  book.  This 
 chapter presents an additional selection of cases from the CERT insider 
threat database.1 The descriptions used here were derived from a variety of 
public sources. While we tried to corroborate the details where we could, 
it was not always possible. Nevertheless, we believe many lessons can be 
learned from reviewing these cases—obviously, we have learned a lot from 
them over the years!
The first section contains IT sabotage cases, followed by cases that were both 
sabotage and fraud, then theft of IP, fraud, and finally the  miscellaneous 
cases. Within each section, the cases are sorted by the sector of the victim 
organization. Each section starts with a table describing each case in that 
section. You might want to use those tables to search for cases that you find 
particularly interesting, either because of the method used or because of 
the applicability to your organization.
Sabotage Cases
Table 8-1 provides an index of sabotage cases in the CERT insider threat 
database.
1.  Some of these summaries were pulled from previously published works cited in other chapters. 
Others were pulled from the CERT insider threat database. We would like to recognize the many staff 
members on our team who have contributed to these summaries over the past ten years; they are listed 
by name in the Acknowledgments section of the Preface.

Chapter 8.  Case Examples
242
Table 8-1  Sabotage Cases
Case #
Industry or Government 
Sector
Description
1
Banking and finance
Revenge via framing of another 
employee
2
Banking and finance
Logic bomb that covered its tracks
3
Banking and finance
Logic bomb propagated to server 
 configuration management baseline
4
Banking and finance
Insider threatens attack from the 
 Internet underground
5
Commercial facilities
Insider conducts attack with help from 
the Internet underground
6
Defense industrial 
base
Multiple logic bombs
7
Defense industrial 
base
Massive leakage of  proprietary 
 information to the media by 
 whistle-blower
8
Defense industrial 
base
Insider tests logic bomb three times 
before final attack
9
Energy
Contractor still has access even after 
his company suspends him
10
Food
Consultant steals 5,000 passwords
11
Government
Contractor plants logic bomb just prior 
to termination
12
Government
Former DBA deletes critical 
 information following denied EEOC 
complaint
13
Government
Insider changes someone to 
“deceased” in a government database
14
Information 
 technology
Consultant attacks after being told 
 contract will end

Free ebooks ==>   www.Ebook777.com
Sabotage Cases
243
15
Information 
 technology
Consultant renders systems 
 inaccessible after being reduced to 
part-time
16
Information 
 technology
Insider who left ISP prevents 
 customers from accessing Internet for 
three weeks
17
Information 
 technology
System administrator, fearing layoffs, 
plants malicious code
18
Information 
 technology
Manufacturer suffers widespread 
 shutdown after disgruntled employee 
of business partner sabotages wire-
less networks
19
Information 
 technology
Programmer plants malicious code 
that disrupts critical operations 
12 months after he left
20
Information 
 technology
Former application developer inserts 
pornographic images on company 
Web site
21
Information 
 technology
IT worker brings down 911 systems so 
that he can “play the hero”
22
Information 
 technology
Technical support person works 
with the Internet underground to 
 compromise his organization and 
deface its Web site
23
Information 
 technology
Computer technician with a criminal 
history posts employees’ PII to the 
Internet
24
Postal and shipping
Company discovers backups had 
not been recording critical data 
after  former programmer deletes his 
 software
 
www.Ebook777.com

Chapter 8.  Case Examples
244
 

Sabotage Cases
245
he had set to go off two weeks later, deleted billions of files and disrupted 
service on thousands of servers throughout the United States. Prior to the 
logic bomb’s detonation, the insider purchased put options of the company 
stock, expecting the subsequent detonation of the logic bomb to drive the 
firm’s stock price lower. Although the stock price did not drop, the victim 
organization  estimated  that  the  attack  would  cost  more  than  $3  million 
in network repairs, and could have affected more than 1 billion shares of 
its  stock. A  forensics  investigation  connected  the  insider  to  the  incident 
through virtual private network (VPN) access, and through code snippets 
both on his home computer and on the organization’s network. The insider 
was convicted and sentenced to more than eight years in prison.
Sabotage Case 4
A system administrator and several of his colleagues were laid off by a finan-
cial firm. Over a period of four days after receiving the bad news, the insider 
contacted management at the victim organization and threatened them. He 
stated that if he did not receive a significantly larger severance package and 
good employment recommendations, he would recruit his friends from an 
underground Internet hacking ring to attack the victim organization. He also 
claimed  to  have  opened  backdoors  throughout  the  victim  organization’s 
systems to facilitate such an attack. The organization contacted law enforce-
ment and consensually recorded phone calls between the insider and the 
victim, capturing the insider’s demands, threats, and intent. He was arrested 
before the attacks ever came to fruition, was convicted, and was sentenced to 
15 months of imprisonment and three years of supervised release.
Sabotage Case 5
A system administrator for a retail company was terminated over issues with 
a server for which he was responsible. Following his termination, he recruited 
members of an online hacking group to help him attack his former employ-
er’s systems. He relayed passwords and other access control information to 
the underground group, and provided detailed instructions on how to use 
those credentials to break into his former employer’s network. Over a period 
of one week, the insider was able to organize the group and execute a coor-
dinated denial-of-service attack against the retailer that lasted from the day 
before Thanksgiving until the Sunday after Thanksgiving—commonly recog-
nized as the busiest shopping days of the year. Personnel at the organization 
detected  problems  in  the  network  that  were  obstructing  online  sales  and 
promptly responded to the incident. The insider was convicted, sentenced to 
18 months of imprisonment, and ordered to pay $64,000 in restitution.

Chapter 8.  Case Examples
246
Sabotage Case 6
A self-employed contractor was a system administrator for a military branch, 
and in that capacity he helped to oversee the daily operation of a computer 
system used to track and plot the locations of various military vehicles. When 
the victim organization rejected his proposal for follow-on work and decided 
to award the work to another firm, he became disgruntled and decided to 
take action to make the new system administrator “look bad.” He sabotaged 
the organization’s systems by planting logic bombs on five servers set to det-
onate after he left. Three of the five servers were subsequently damaged and 
went offline. Another system administrator searched for similar malicious 
code and uncovered the additional logic bombs; the administrator’s actions 
prevented the malicious code from affecting the other two targeted comput-
ers. The victim organization then took extensive steps to secure and restore 
the network and its data. The insider was convicted, ordered to pay $25,000 
in restitution and a $10,000 fine, and sentenced to more than a year in prison 
followed by a period of supervised release.
Sabotage Case 7
An inspector at a manufacturing plant complained to management about 
the lack of support given to inspectors to do their job, saying that inspec-
tors were pressured to approve work regardless of quality. Despite the fact 
that an independent evaluator determined that his claims were unfounded, 
the insider threatened to sue the company and offered his silence for a cash 
settlement. This extortion attempt was declined by the company and no 
further action was taken until years later when newspaper articles began 
appearing  that  divulged  the  company’s  proprietary  information.  After 
receiving an anonymous tip that the insider was responsible for the leaks, 
the organization started an investigation. Working with law enforcement, 
the organization found evidence that the insider had been downloading 
its confidential information, which was outside his area of responsibility, 
for more than two years. The insider had downloaded massive numbers 
of proprietary documents using a USB removable storage drive and stored 
the  data  at  his  residence.  The  investigation  also  found  evidence  of  the 
insider’s email correspondence with reporters discussing the proprietary 
documents,  articles,  and  meetings.  The  entire  incident  took  place  over 
three years and the victim organization estimated its loss at $5 million to 
$15 million. The trial ended with a continuance agreement between the 
insider  and  the  victim  organization  that  directed  the  insider  to  cooper-
ate with law enforcement to retrieve leaked documents and not leak any 
 further  organization information.

Sabotage Cases
247
 

Chapter 8.  Case Examples
248
 
 ­
 

Sabotage Cases
249
 

Chapter 8.  Case Examples
250
 

Sabotage Cases
251
 

Chapter 8.  Case Examples
252
 

Sabotage Cases
253
 

Chapter 8.  Case Examples
254
organization’s systems, modified its Web site (including the insertion of 
pornographic images), changed system passwords, and sent emails to 
customers saying that their accounts had been hacked and their pass-
words stolen. The emails included the client’s username and password. 
The  incident  involved  two  separate  attacks,  which  were  more  than  a 
month apart. Web logs showed the IP address used to launch the attack 
was  associated  with  the  insider’s  wife’s  ISP  account.  The  organiza-
tion spent $53,000 and more than 330 hours repairing the damage. The 
insider was convicted, ordered to pay more than $48,000 in restitution, 
and sentenced to five months of imprisonment followed by two years of 
supervised probation.
Sabotage Case 21
An  IT  worker  was  located  in  the  network  support  department  of  a 
 telecommunications  company  that  administered  an  emergency  911 
system.  One  Friday  night,  the  insider  deleted  the  entire  database  and 
software from three servers in the organization’s network operations cen-
ter (NOC) by gaining physical access using a contractor’s badge, which 
he later claimed to have found. The NOC, which was left unattended, 
was solely protected via physical security; all machines in the room were 
left logged in with system administrator access. The motivation of this 
particular insider was a bit unusual: A new boss was starting work on 
Monday, and on Friday night he decided he would “play the hero” to 
gain favorable attention from the new boss on Monday morning. Obvi-
ously, the impacts were huge, since he brought down the 911 systems on 
a Friday night.
Although the NOC system administrators were immediately notified of 
the system failure via an automatic paging system, there were no auto-
mated failover mechanisms. The organization’s recovery plan relied solely 
on backup tapes, which were also stored in the NOC. Unfortunately, the 
insider,  realizing  that  the  systems  could  be  easily  recovered,  took  all  of 
the backup tapes with him when he left the facility. In addition, the same 
contractor’s badge was authorized for access to the off-site backup storage 
facility, from which the insider next stole more than 50 additional backup 
tapes. The insider turned himself in and physical access logs connected him 
to the incident. He was convicted, ordered to pay more than $200,000 in 
restitution, and sentenced to five years of probation, including six months 
of home detention.

Sabotage Cases
255
 
2.  Network sniffer (also known as a sniffer): a computer program or a piece of hardware that can 
 intercept and log traffic passing through a network.
3.  Internet Relay Chat (IRC) channel: functionally similar to a multiuser chat instance.

Chapter 8.  Case Examples
256
the  organization’s  chairman.  The  IP  address  associated  with  the  action 
was   connected  to  an  ISP  account  registered  to  the  insider’s  wife.  The 
 organization obtained a temporary restraining order directing the insider 
to stop publicizing its employees’ PII. After a process server attempted to 
deliver a copy of the restraining order to him, the insider posted a threat to 
kill the process server on his Web site. He also threatened the organization’s 
assistant general counsel (including posting a detailed map to her home on 
the site) and the chairman of the victim organization. He was convicted and 
sentenced to 46 months of imprisonment. After his release, he had severely 
limited access to computers and was restricted from  communication with 
the  victims of his threats as well as witnesses.
Sabotage Case 24
A programmer in a logistics company was terminated as the result of a reor-
ganization within the company. The company followed proper procedures 
by escorting him to his office to collect his belongings and then out of the 
building. The IT staff also followed the company’s security policy by dis-
abling his remote access and changing passwords. However, they overlooked 
one password that was known to only three people in the organization. The 
terminated insider used that account to gain access to the system the night 
of his termination and to delete the programs he had created while working 
there. The organization detected the incident when one of the servers and 
several financial packages failed. The insider had installed several backdoors 
and was one of only two people who knew the password to the account used 
in the attack. Restoration of the deleted files from backup failed. Although 
the insider had been responsible for  backups, company personnel believe 
that the backups were not maliciously corrupted. The backups had simply 
not been tested to ensure that they were properly recording the critical data. 
As a result, the organization’s operations in North and South America were 
shut down for two days, causing more than $80,000 in losses. The insider 
was convicted, ordered to pay $80,000 in restitution, and sentenced to one 
year in prison followed by six months of home confinement.
Sabotage/Fraud Cases
Table 8-2 provides an index of sabotage/fraud cases in the CERT insider 
threat database.

Sabotage/Fraud Cases
257
Table 8-2  Sabotage/Fraud Cases
Case #
Industry or Government 
Sector
Description
1
Banking and finance
DBA works with Internet underground 
for two years to commit fraud using 
employee data
2
Information 
 technology
Sole security administrator for small 
firm holds company hostage for more 
pay and launches attacks from its 
 network
3
Information 
 technology
VP of engineering quits, takes source 
code and backups, and demands 
$50,000 for its return
 

Chapter 8.  Case Examples
258
 compensation for his work, and also had a series of conflicts with  coworkers. 
He had a lengthy history of pirating material online and had committed 
prior electronic crimes related to unauthorized system and network access. 
Following  his  termination,  a  manager  at  the  organization  called  him  at 
home to request administrative passwords since he had not turned them 
over to anyone when he quit his job. He refused to disclose the administra-
tive passwords until he received additional pay to which he felt entitled. 
He turned them over three days later, after locking the organization out 
of all administrative functions. For a month afterward, he used backdoor 
accounts he had created previously to remotely access the organization’s 
systems and delete files that he had created during his employment. He 
also changed the DNS records for the Internet-facing servers to point to 
another server named to slander the organization, and launched offensive 
attacks from within the organization’s network. For instance, he used the 
victim’s network to run network scanning tools against military networks. 
He was convicted, ordered to pay a $3,000 fine, and sentenced to two years 
of supervised probation.
Sabotage/Fraud Case 3
A vice president of engineering who was responsible for oversight of all 
software  development  in  his  company  was  engaged  in  a  long-running 
dispute with upper management. This dispute was characterized by ver-
bal attacks by the insider and statements to colleagues about the degree 
of upset he had caused to management. He engaged in personal attacks 
once or twice a week and on one occasion, in a restaurant, screamed per-
sonal attacks at the CEO of the company. A final explosive disagreement 
prompted  the  insider  to  quit.  When  no  severance  package  was  offered, 
he copied a portion of a software product under development to remov-
able media, deleted it from the company’s server, and removed the recent 
backup  tapes.  He  then  offered  to  restore  the  software  in  exchange  for 
$50,000. Unfortunately, the most recent version of the software was never 
recovered. The insider was convicted, sentenced to five years of probation, 
and ordered to pay restitution.
Theft of IP Cases
Table 8-3 provides an index of theft of intellectual property cases in the 
CERT insider threat database.

Theft of IP Cases
259
Table 8-3  Theft of IP Cases
Case #
Industry or Government 
Sector
Description
1
Chemical
Product development director is caught 
stealing IP when laptop he returned 
upon termination is examined
2
Defense industrial 
base
Former systems engineer modifies the 
 company’s software slightly and sells it 
abroad for new employer
3
Government
Large downloads from the network 
 trigger  investigation that leads to  
former  contract  programmer
4
Information 
 technology
Insiders from multiple high-tech 
 companies steal IP and start company 
funded by foreign  government
5
Information 
 technology
Company’s IP is stolen by nephew 
of an employee of a trusted business 
 partner’s trusted business partner
6
Information 
 technology
Trio of insiders conspire to steal IP, give 
it to  foreign manufacturer, and receive 
 commissions from that  company’s sales
 

Chapter 8.  Case Examples
260
 

Theft of IP Cases
261
 
4.  TIFF images: Tagged Image File Format (or .tif) is a file type often used in image manipulation 
 programs.

Chapter 8.  Case Examples
262
 organization.  The  nephew  was  convicted,  ordered  to  pay   approximately 
$146,000 in restitution, and  sentenced to home  confinement and probation.
Theft of IP Case 6
A senior engineer, his wife, and another accomplice all worked for an auto 
parts manufacturer. The insider’s wife quit her job as a vice president of sales, 
and conspired with the accomplice inside the organization to set up a new 
company. The trio intended to steal proprietary information from the auto 
parts manufacturer in the United States, provide it to a manufacturer based 
outside the United States, and then receive commissions on sales made by the 
manufacturer. While still employed by the auto parts manufacturer, the engi-
neer was able to copy hundreds of files to CDs, including proprietary design 
and manufacturing process information. He then relayed this information to 
his wife, who proceeded to forward it to the external manufacturer. The theft 
was detected and reported by the suppliers to the external manufacturer, 
when they received email about the proprietary manufacturing processes. 
The primary insider—the senior engineer—was convicted and sentenced to 
six months of imprisonment followed by periods of house arrest and proba-
tion. The conspirators were also convicted and imprisoned.
Fraud Cases
Table  8-4  provides  an  index  of  fraud  cases  in  the  CERT  insider  threat 
 database.
Table 8-4  Fraud Cases
Case #
Industry or Government 
Sector
Description
1
Banking and finance
Loan officer is recruited to steal identity 
information from her customers as part 
of a six-person identity theft ring
2
Banking and finance
More than $4 million in risky loans 
result from ring of coworkers who 
 modify credit histories for pay

Free ebooks ==>   www.Ebook777.com
Fraud Cases
263
3
Banking and finance
Foreign-currency trader covers up 
 trading losses for five years
4
Commercial facilities
Insider intentionally opens infected 
email attachment, installing  malicious 
code that sends  confidential 
 information to his company’s 
 competitor
5
Defense industrial 
base
Computer help desk attendant at a 
military contractor steals more than 
$8 million worth of equipment using 
fake email addresses
6
Emergency services
Police communications operator 
 creates 195 illegal driver’s licenses due 
to lack of role-based access controls
7
Food
Group shares their passwords so that 
they can work more efficiently
8
Government–Federal
Supervisor uses his authority and 
 privileged access to grant asylum 
to foreign nationals who had been 
denied asylum in the United States
9
Government–Federal
After being promoted, insider retains 
old role and new role in a system, 
enabling her to enter and approve of 
fraudulent transactions
10
Government–State/
Local
Insider with multiple roles is able to 
authorize payments of more than 
$250,000 to his wife
11
Government–State/
Local
Manager instructs subordinate to 
reformat backup tapes, destroying the 
evidence against him
12
Health care
Subcontractor changes address of 
medical provider and has checks sent 
to her accomplice
www.Ebook777.com

Chapter 8.  Case Examples
264
Fraud Case 1
The insider was a loan officer in a financial institution. The incident was 
part of a massive identity theft ring composed of six individuals. They stole 
identities from at least 25 people, and then used the identities to defraud ten 
financial institutions and 25 retailers in multiple states for a total of $335,000 
over a four-year period. The ringleader, an outsider, carefully recruited par-
ticipants, each with a specific role in the scheme. This particular insider was 
recruited to steal personal and financial information of customers apply-
ing for a mortgage with her company, and another insider, an employee at 
an escrow firm, stole financial information of her  company’s clients. The 
insider’s part in the crime occurred over a  ten-month period. The informa-
tion was used by two members of the crime ring with equipment to create 
counterfeit driver’s licenses. The remaining conspirators used the licenses 
to open new credit accounts with banks and retailers, purchased goods 
and services with the new accounts, and drained the cash from existing 
checking and savings accounts of the victims. The incident was detected 
by a probation officer, who discovered equipment for creating false iden-
tification documents at the home of one of the coconspirators. The insider 
was  convicted,  ordered  to  pay  $200,000  in  restitution,  and   sentenced  to 
18 months of imprisonment.
Fraud Case 2
The insider maintained the information in the consumer credit database 
at a consumer credit report organization. In exchange for money from an 
external collaborator, she conspired with coworkers to artificially inflate 
the credit scores of specific consumers to enable them to secure loans from 
credit  institutions  and  lenders.  Over  four  months,  she  and  her  internal 
conspirators  modified  or  deleted  credit-history  data  for  178  consumers. 
The purpose was to strengthen their creditworthiness and cause lenders 
to issue loans to these consumers. She received advance payment for the 
modification and passed the payment on to coworkers to make the alter-
ations in the database. She was experiencing financial difficulties, which 
motivated her to participate in the scheme. More than $4 million of risky 
loans  resulted  in  this  case.  It  cost  the  organization  $5,000  to  restore  the 
integrity of the information in the database, but the organization also had 
to pay more than $675,000 to creditors. The insider was arrested, convicted, 
ordered to pay a $3,000 fine, and sentenced to five months of imprisonment 
followed by five months of home detention and three years of supervised 
release. She fully cooperated with authorities, which led to the sentencing 
of her two coconspirators.

Fraud Cases
265
 

Chapter 8.  Case Examples
266
 

Fraud Cases
267
 

Chapter 8.  Case Examples
268
 

Miscellaneous Cases
269
who confirmed that they were not winners. The insider was not initially 
 suspected,  until  he  started  behaving  strangely.  Consequently,  he  was 
placed on administrative leave. Before he left on administrative leave, he 
deleted a history log that may have contained evidence of his criminal act. 
He also instructed one of his subordinates to reformat the backup tapes, 
claiming that they wouldn’t be useful under a new backup data format that 
was being implemented. The subordinate complied with this request and 
the organization lost much of the evidence of his tampering with system 
security controls. He fraudulently won almost $63,000 from the state lot-
tery system (he used 141 tickets and claimed prizes for 126 of them). He 
was convicted, ordered to pay the $63,000 restitution, fined $25,000, and 
sentenced to 60 days in jail and three years of probation.
Fraud Case 12
The primary insider was a subcontractor working for an organization that 
handled  state  government  employee  health  insurance  claims.  Using  the 
medical  identity  number  of  an  unsuspecting  psychologist,  she  changed 
the  name  and  address  associated  with  the  psychologist  to  an  internal 
accomplice’s  name  and  address.  Over  two  and  a  half  months,  she  filed 
40 fake claims and sent the payments to the bogus medical provider and 
address. One of her internal accomplices granted her the increased access 
she needed to perpetrate the fraud. Another accomplice was responsible 
for cashing the checks and distributing the money. Auditors discovered the 
scheme when they began questioning why a psychologist was submitting 
payment claims for treating broken bones and open wounds, and admin-
istering chemotherapy. They also noticed that the name associated with 
the psychologist was the name of one of their subcontractors. During the 
investigation it was determined that the primary insider had a criminal his-
tory for fraud. She was arrested on a separate fraud charge and accepted 
a plea bargain after one of her accomplices named her as the ringleader of 
the incident.
Miscellaneous Cases
Table 8-5 provides an index of miscellaneous cases in the CERT insider 
threat database.

Chapter 8.  Case Examples
270
Table 8-5  Miscellaneous Cases
Case #
Industry or Government 
Sector
Description
1
Banking and finance
Former employee “eavesdrops” on 
 executives’ emails regarding  pending 
employee terminations three years 
 following termination
2
Education
Student gains access to his 
 professor’s university and personal 
account and changes his grade
3
Education
Student installs malicious program 
that steals personal information for 
37,000  students
4
Government
Contractor “breaks” 40 organiza-
tion  passwords in order to prove his 
 complaints about lack of security
5
Information 
 technology
Millions of customer records 
are  compromised by a system 
 administrator at a trusted business 
partner’s trusted  business partner
6
Information 
 technology
System administrator’s  customized 
login software catches former 
 employee’s  unauthorized access
 

Miscellaneous Cases
271
 

Chapter 8.  Case Examples
272
 

Summary
273
for his previous project, and deleted two software  modification notices for 
the project. The activity was detected when a system  administrator logged 
in one morning and was notified by her custom-written login software that 
her last login was one hour earlier. This set off immediate alarms, as she 
had in fact not logged in for several days. She had previously taken steps 
to redirect logging of actions by her account to a unique file rather than the 
standard shell history file. Therefore, she was able to trace the intruder’s 
steps and saw that the intruder had read another employee’s email using 
her account, and then deleted the standard history file for her account so 
that there would be no log of his actions. The login was traced to a  computer 
at  the  company  subsidiary.  The  insider  was  convicted  and  sentenced 
to  two  concurrent  terms  of  probation,  as  well  as  unspecified  fines  and   
penalties.
Summary
This  chapter  presented  a  variety  of  cases  from  the  CERT  insider  threat 
 database. We chose cases that exhibited different characteristics and from 
which different lessons can be learned. You may wish to refer back to this 
chapter  periodically  to  test  your  own  organization’s  countermeasures 
against these cases by asking the question: Could this happen to us?

This page intentionally left blank 

275
Chapter  9
Conclusion and 
Miscellaneous Issues
This chapter wraps up the book by covering two miscellaneous issues that 
we mentioned briefly but did not cover in detail earlier: insider threats from 
trusted business partners, and malicious insiders with ties to the Internet 
underground. We conclude with a final summary, which could serve as a 
handy reference should you need a “cheat sheet” for future  discussions on 
insider threat.
Insider Threat from Trusted Business Partners
Trusted business partner (TBP): any external organization or individual 
an organization has contracted to perform a service for the organization. 
The nature of this service requires the organization to provide the TBP 
authorized access to proprietary data, critical files, and/or internal infra-
structure. For example, if an organization contracts with a company to 
perform billing services, it would have to provide access to its customer 
data, thereby establishing a trusted business partnership. However, the 
TBP concept does not include cases in which the organization is simply a 
customer of another company. For example, when an organization uses a 
bank, it is simply a client of the bank. This customer–vendor relationship 
would not be considered a TBP relationship.

Chapter 9.  Conclusion and Miscellaneous Issues
276
Trusted business partners can be individuals or other organizations.1 For 
example,  when  an  organization  outsources  its  customer  help  desk  sup-
port service to an outside company it enters into a TBP relationship with 
that company. In this case, the organization must grant access to its cus-
tomer  database  to  the  outside  company.  On  the  other  hand,  TBPs  also 
include  individual  consultants,  temporary  employees,  and  contractors, 
including any former employees of the organization who are then hired as 
 consultants or contractors.
Use of TBPs is common in today’s business environment for weathering 
the  ups  and  downs  of  the  economy  without  impacting  the  permanent 
 workforce,  and  maximizing  profits  by  outsourcing  appropriate  func-
tions. That is why it is important that you read this section and carefully 
consider the potential insider threat risk posed by those contractors and 
business partners that you provide authorized access to for your systems, 
 information, and networks.
A  few  examples  of  each  type  of  TBP  follow,  in  order  to  help  you  to 
 understand the difference. First, we present a few examples of organiza-
tional TBP relationships. The first example is especially important as it is an 
insider threat from an IT services provider—an emerging threat in today’s 
cloud computing environment.
A company—the TBP—provided IT and information security solutions for 
its customers. One of its employees was an information security  analyst 
who used his access to the customers’ networks to steal 637,000 credit card 
numbers. He then advertised the stolen data for sale on an Internet site 
used for marketing stolen credit card information. Fortunately, he sold the 
majority of the credit card numbers to two undercover investigators; only 
318 credit card numbers were sold to individuals that wanted to perpetrate 
credit card fraud. The insider was arrested and sentenced to 50 months of 
imprisonment.
A financial institution was having problems with its computer system, so 
it contracted with a company to repair it—the TBP—and supplied the TBP 
with passwords for its systems. These passwords also provided access to 
other critical transaction systems. One of the employees at the contracted 
organization was having financial difficulties, and abused his access to 
the financial institution’s systems to initiate fraudulent transactions. He 
accessed the Automated Clearing House (ACH) system and performed 
unauthorized  transactions.  He  then  used  the  money  received  from  the 
1.  Material from this section includes portions from a joint CyLab and CERT Program article titled 
“ Spotlight On: Insider Threat from Trusted Business Partners,” authored by Robert Weiland, Andrew 
Moore, Dawn Cappelli, Randy Trzeciak, and Derrick Spooner [Weiland 2010].

Insider Threat from Trusted Business Partners
277
 falsified  transactions  to  pay  for  construction  projects  on  his  properties, 
two mortgages, car loans, overseas vacations, and other debts. The money 
was  transferred  to  his  personal  accounts,  his  wife’s  accounts,  and  his 
business’s accounts. Cashier’s checks were also purchased with fraudu-
lent funds. The fraud was detected and reported by the insider’s business 
partner at the TBP when he noticed large deposits to the business account. 
He contacted the victim organization, which then conducted an investiga-
tion using ACH data and system logs. The victim organization stated that 
the fraud would have likely gone undetected had it not been reported by 
the TBP itself. The insider was sentenced to five years in prison and five 
years of supervised release, and had to repay more than $1.8 million in 
 restitution.
Next are two examples of individuals who were trusted business partners 
of the victim organization.
A  contractor—the  TBP—was  formerly  employed  as  a  help  desk  and 
network  technician  by  the  victim  organization.  While  working  for  the 
company, he had system administrator and remote access to the network, 
in  order  to  perform  maintenance  and  to  troubleshoot  problems  from 
home. He was a temporary employee hoping to be hired into the organiza-
tion full-time, but his application for full-time employment was rejected 
because he had received a poor performance review from his supervisor, 
who characterized him as volatile, angry, inflexible, and not a team player. 
The insider, who was trying to gain full custody of his daughter, also had 
financial issues. Due to cutbacks at the organization and rules surrounding 
temporary employment, he was informed that his employment would be 
terminated in two months. After learning of his pending termination, he 
wrote several emails to the organization’s human resources department, 
threatening to sue the organization for unfair labor practices. As a result 
of the emails, he was immediately terminated. He used backdoors he had 
previously  created  to  access  the  organization’s  network  and  removed 
access  to  systems,  changed  administrative  passwords,  deleted  system 
event  logging,  and  modified  accounts  associated  with  individuals  who 
were involved with his termination. The insider’s actions were discovered 
the following day when employees could not access the system. Fortu-
nately, the insider had failed to delete all of the logs that connected him to 
the incident. He admitted responsibility for the incident,  acknowledged 
that he made a mistake, and wanted to help minimize damages.
A  contractor  was  employed  as  a  process  controls  engineer  by  a  manu-
facturing organization. He became angry with his supervisor and feared 
that his job was in jeopardy, so he disclosed the organization’s technical 
drawings to another organization via email and fax over the course of one 
month. The insider was arrested, convicted, ordered to pay $1.3 million in 
restitution, and sentenced to 27 months in prison.

Chapter 9.  Conclusion and Miscellaneous Issues
278
Overview of Insider Threats from Trusted Business Partners
According to a recent study by the security companies RSA and Interactive 
Data  Corporation  (IDC),  which  surveyed  C-level  executives,  “Contractors 
and temporary staff represent the greatest internal risk [to] organizations.”2 
The purpose of this section is to raise awareness to the threat from trusted 
business partners; however, it is worth noting that contractors account for less 
than 10% of the cases in the CERT database. We are not saying that you should 
not be concerned about contractors; on the contrary, we advise you to consider 
insider threat risk from all individuals and organizations that have autho-
rized access to your systems, networks, and information. It is concerning that 
C-level executives do not recognize the risk posed by their own employees.
Table  9-1  shows  the  breakdown  of  TBP  cases  by  sector,  including  the 
 percentages of all individual as well as organizational TBP cases.
Table 9-1  Breakdown of Trusted Business Partner Cases
Sector
Percentage of All 
Individual TBP Cases
Percentage of All 
Organizational TBP 
Cases
Banking and finance
11%
13%
Commercial facilities
11%
6%
Defense industrial 
base
3%
9%
Education
6%
3%
Energy
3%
3%
Food
3%
—
Government
19%
22%
IT
33%
19%
Manufacturing
—
3%
Not a member of a 
critical sector
—
6%
Public health
11%
13%
Water
—
3%
2.  See www.rsa.com/solutions/business/insider_risk/wp/10388_219105.pdf.

 

Chapter 9.  Conclusion and Miscellaneous Issues
280
 
3.  Because no verdict was known, the insider’s actions described in this case are alleged.

Insider Threat from Trusted Business Partners
281
 

Chapter 9.  Conclusion and Miscellaneous Issues
282
and emailed them from his personal account to his work email. Later, he 
proceeded to send the images from his work account to other coworkers in 
another plant who were tasked with actually manufacturing their version 
of the trade-secret equipment for the Chinese company.
This case is somewhat similar to the cases related in Chapter 3. The  insiders 
used authorized access to steal the trade secrets from their client. The coun-
termeasures described in Chapter 3 apply here as well: It is important to 
identify your most valuable IP, and target your countermeasures on pro-
tecting it. You can’t possibly watch everything everyone does on a daily 
basis; therefore, you need to focus your attention on what’s most impor-
tant.  In  this  case,  the  organization  obviously  had  extensive  controls  for 
protecting its trade secrets; however, it did not recognize the threat posed 
by its TBPs, and allowed them to access the area unescorted, even though 
all visitors had to be escorted at all times.
Open Your Mind: Who Are Your Trusted Business Partners?
By now you probably understand that you need to include contractors and 
companies  you  do  business  with  when  designing  countermeasures  for 
insider threat risk. But before you stop reading, are you sure you haven’t 
forgotten anyone? Is there anyone else you provide authorized access to 
your systems, information, or network?
The reason we ask is because we have two cases involving a different type 
of trusted business partner: prisoners. This is a perfect example of how you 
have to open your mind to the expanding complexity of insider threat for 
your organization.
An  inmate  at  a  prison  was  incarcerated  because  he  was  previously 
involved  in  a  hacking  and  phishing  scam  and  had  also  engaged  in 
credit card fraud. The prison asked him to write a program and create 
an internal, closed network television station. The inmate was left unsu-
pervised and altered the system passwords and locked everyone out of 
the prison’s network. The prison hired external consultants to repair the 
damage, and the inmate was put into segregation as punishment. It is 
unknown whether charges were filed against the inmate in relation to 
the incident.
This case clearly illustrates a new angle on insider threats! In Chapter 6, 
Best  Practices  for  the  Prevention  and  Detection  of  Insider  Threats,  we 
 indicated  that  you  should  consider  the  increased  risk  that  is  posed  by 
potential employees with a criminal history. Providing authorized access to 
a  convicted hacker obviously poses additional risk of insider threat.

Insider Threat from Trusted Business Partners
283
 

Chapter 9.  Conclusion and Miscellaneous Issues
284
 

Insider Threat from Trusted Business Partners
285
you should perform an assessment of the individual’s insider risk. 
You should remove the individual’s access and change any shared 
accounts that access was provided in order to mitigate risks when 
the individual is informed he or she will not be hired. It has proven 
risky to retain the services of  disappointed or disgruntled temporary 
workers.
•  Recommendation 6: Deactivate access following termination. 
When  an  employee,  consultant,  or  contractor  is  terminated  or  sus-
pended, all access that the person had should be disabled. When you 
are  drawing up an agreement with a trusted business partner, you 
should  make  certain  the  trusted  business  partner  performs  rigor-
ous termination procedures as well. In a number of cases involving 
contractors,  access  was  not  disabled  immediately  after  termination 
and the insider was able to exploit that access in the commission of 
his crime.
•  Recommendation 7: Enforce separation of duties. 
A number of insiders exploited the fact that certain actions could be 
performed  in  such  a  way  that  circumvented  normal  separation  of 
duties controls. Business processes should enforce separation of duties, 
regardless of the speed or priority required. While different levels of 
controls may be associated with different priority tasks, no processes 
should be left without  protections against possible exploitation by a 
disgruntled or greedy insider.
•  Recommendation 8: Create clear contractual agreements that specifi-
cally state that the TBP is also responsible for protecting organizational 
resources. 
Contracts with a trusted business partner should include restrictions 
on how the TBP handles and shares your information. This should 
include restrictions on the TBP’s ability to subcontract with other 
organizations  on  tasks  involving  your  sensitive   information  and 
systems. There should be standard terms and conditions that allow 
you to apply the same policies and procedures to contractors, sub-
contracts, and consultants that you apply to your own employees, 
including  mandatory  flow-down  provisions  from  prime  contrac-
tors  to  subcontractors. Also,  contracts  should  include   notification 
requirements  for  breaches  and  termination  of  key  employees. 
You  should  make  your  security  requirements  clear  and  also 
develop  consequences that will incentivize the TBP to  protect key 
resources.

Chapter 9.  Conclusion and Miscellaneous Issues
286
 
4.  Material from this section includes portions from a joint CyLab and CERT Program article titled 
“Spotlight On: Malicious Insiders with Ties to the Internet Underground Community,” authored by 
Michael Hanley, Andrew Moore, Dawn Cappelli, and Randall Trzeciak [Hanley 2009].
5.  See Federal Bureau of Investigation—Organized Crime—Glossary of Terms for more information 
(www.fbi.gov/about-us/investigate/organizedcrime/glossary).
6.  See definition on Cambridge Dictionaries at http://dictionary.cambridge.org/.

Malicious Insiders with Ties to the Internet Underground
287
different from traditional organized crime. These are interesting facets of 
the problem to bear in mind as we continue our discussion of the Internet 
underground community.
The goal of this section is not to recommend detection methods for  locating 
employees  and  contractors  who  might  be  involved  with  the  Internet 
underground.  That  would  be  prohibitively  expensive  and  would  likely 
have a fairly high false-positive detection rate given that several tools and 
forums in the underground do have legitimate uses. Instead, this section 
demonstrates how motivated insiders could use the Internet underground 
community and its resources as a force multiplier to amplify the impact 
of their attacks against you. Also, the best practices detailed in Chapter 6 
might have eliminated the organizational and technical vulnerabilities that 
the insiders in these cases were able to exploit.
Snapshot of Malicious Insiders with Ties to the Internet 
 Underground
The  majority  of  these  incidents  were  IT  sabotage  cases,  which  follow 
the patterns we described in Chapter 2. Therefore, the proactive mea-
sures we have described throughout this book for prevention and early 
detection of insider IT sabotage are applicable to many of these cases. As 
in most IT sabotage cases, the majority of these insiders held technical 
roles,  such  as  system  administrators,  database  administrators  (DBAs), 
computer technicians, and technology architects; many of them were for-
mer employees or contractors at the time of the attack. They were often 
considered to be among the most technical individuals in their organiza-
tions; special care should be used when employing technically skilled 
individuals  with  known  or  suspected  connections  to  Internet  under-
ground communities.
Only a few of the insiders were in positions that were purely  managerial 
or  nontechnical.  In  addition,  all  of  these  insiders  were  male;  however, 
recall our caution in Chapter 2 that technical positions are highly male-
dominated. Therefore, you should not focus on male employees in your 
mitigation  efforts.  Some  of  these  insiders  were  characterized  by  fellow 
employees  and  their  organization’s  leadership  as  the  most  technically 
 valuable employees in the organization.
Most of these insiders were motivated by revenge against their employer, 
although a few had motivators such as looking for recognition, proving 
some ideological point, or supporting an underground movement.

Chapter 9.  Conclusion and Miscellaneous Issues
288
Range of Involvement of the Internet Underground
The case examples in this section reflect varying degrees in which insiders 
were involved with the Internet underground community. At the low end 
is a system administrator who worked for a market research firm. He used 
his legitimate access to steal PII he found on servers that belonged to one 
of his employer’s business partners. There was no evidence that he dis-
tributed the stolen data via the Internet underground; rather, he appeared 
to enjoy the thrill of collecting it and bragging about it in online IRC chat 
rooms.
Most of the insiders in the CERT database used their ties to the Internet 
underground to generate support for their attack. One insider had access to 
trade secrets relating to anti-piracy technology used by an organization to 
protect its primary business service. He stole the information and actively 
distributed it throughout the hacker community to promote piracy of the 
organization’s services. In another case, a system administrator for a retail 
clothing firm was terminated over issues with a server for which he was 
responsible.  He  then  engaged  the  Internet  underground  community  for 
assistance in organizing and executing a denial-of-service attack7 against 
his former employer using passwords and access mechanisms he provided 
to them.
The Crimes
Most  attacks  targeted  the  organization  directly.  For  example,  insid-
ers  deleted  critical  files,  disrupted  system  operations,  and  denied 
access.   Others  used  their  organization’s  systems  for  their  own  illicit 
 activities—for example, running sniffers and port scans of governmental 
systems. One targeted an unsuspecting outsider by changing her status 
to deceased in a critical government database. Other employees or con-
tractors  transmitted proprietary information to hacker sites, collected PII, 
and broke into systems and defaced Web sites for fun. Some provided 
information to outsiders who used it to commit cybercrimes, including 
one person who posted instructions to an online hacker group on how to 
break into his organization’s systems, and another who posted employ-
ees’ PII to a Web site.
7.  Denial-of-service attack: a type of cyberattack in which a large amount of traffic is directed at a 
server in an attempt to disable it.

Malicious Insiders with Ties to the Internet Underground
289
Use of Unknown Access Paths Following Termination
In  the  cases  that  follow,  procedures  for  ensuring  secure  separation  of 
employees at the conclusion of their employment were not sufficient to 
prevent an insider attack. Insiders were able to exploit access that was not 
disabled upon termination, allowed to copy data before leaving the facility 
for the final time, or able to access previously created privileged backdoor 
accounts used to attack the organization after termination.
A system administrator for a retail company was terminated over issues 
with a server for which he was responsible. Following his termination, 
he  recruited  members  of  an  online  hacking  group  to  help  him  attack 
his former employer’s systems. He relayed passwords and other access 
information  to  the  underground  group,  and  provided  detailed  instruc-
tions on how to use those credentials to break into his former employer’s 
network. He was able to organize the group and execute a coordinated 
denial-of-service  attack  against  the  retailer  that  lasted  from  the  day 
before  Thanksgiving  until  the  Sunday  after  Thanksgiving—commonly 
 recognized as the busiest shopping days of the year.
Attacks Involving the Internet Underground
Attacks involving the Internet underground used some of the following 
technical methods:
•  Exploitation of unpatched vulnerabilities
•  Organized distributed denial-of-service (DDoS) attacks by the 
 Internet underground crime
•  Change of all administrative passwords
•  Modification of DNS server to point to malicious site
•  Use of hacking techniques that were accumulated from various 
underground forums and Web sites
•  Downloading of employee PII to removable media and then posting 
the PII on underground sites
•  Downloading of files to a home computer
•  Exfiltration of copyrighted source code, which was then sold on the 
“black market” and eventually made available on underground file 
sharing sites
•  Theft of trade secrets by scanning physical documents and 
 transmitting to the Internet underground
•  Unauthorized use of a coworker’s account or computer
•  Malicious modification of data
•  Creation and use of backdoor accounts and unknown 
access paths

Chapter 9.  Conclusion and Miscellaneous Issues
290
A computer technician was fired shortly after starting his job because 
he refused to give his Social Security number to the human resources 
department and he failed to disclose prior criminal convictions. Before 
leaving, he stole PII for 8,000 employees and posted it to a Web site he 
had established to smear the organization’s image. The Web site threat-
ened  to  publish  more  information  and  link  it  to  underground  sites 
known to facilitate and engage in identity theft and fraud. The insider 
had been with the organization for only a short time but had been given 
system administrator access to the systems he attacked within his first 
few weeks at the organization.
A system administrator was fired after a confrontation with his man-
ager over the possibility of being laid off. The manager had suggested 
that since the systems were performing well, the employee’s help may 
no longer be needed. Outraged by this, he immediately created a set of 
backdoor accounts with full access to all networked machines within 
his  control  and  planted  a  malicious  program  that  would  erase  hard 
drives  on  command.  The  day  after  his  termination,  he  remotely  trig-
gered the execution of that program and wiped out several devices at 
the organization. Several months after the initial attack, he attacked the 
organization  a  second  time  by  redirecting  the  organization’s  domain 
name for their external-facing Web site to a Web site that hosted por-
nographic images, racial slurs, and defamatory statements against his 
former employer. During the investigation, it was discovered that dur-
ing his employment he had broken into other sites while at work, and 
had  accumulated  a  wealth  of  hacking  material  from  various  under-
ground  forums  and  Web  sites  that  may  have  helped  him  launch  his 
attack  against  his  former  employer.  In  addition,  investigators  found 
disk loads of pornography, passwords, hacking tools, credit card infor-
mation, and music  downloads.
The  sole  security  administrator  for  a  small  telecommunications  firm 
quit  his  job  with  no  advance  notice.  While  he  was  employed  he  had 
expressed  feelings  of  dissatisfaction  due  to  insufficient  gratitude  and 
compensation  for  his  work,  and  also  had  a  series  of  conflicts  with 
coworkers. He had a lengthy history of pirating material online and had 
committed prior electronic crimes related to unauthorized system and 
network access. For a month following his departure, he used backdoor 
accounts he had created previously to remotely access the organization’s 
systems  and  delete  files  that  he  had  created  during  his  employment. 
He also redirected the Internet-facing Web servers to point to another 
server  named  to  slander  the  organization,  and  launched  other  offen-
sive attacks from within the organization’s network, such as using the 
victim’s  network  to  run  network  scanning  tools  against  government 
military networks.

Malicious Insiders with Ties to the Internet Underground
291
As  we  have  mentioned  previously  in  this  book,  you  should  develop  a 
 formal employee termination process. The process should involve
•  Disabling of accounts and access paths
•  A debriefing regarding nondisclosure or intellectual property  agreements
•  Communication to the rest of the organization that the trust  relationship 
with the former employee has been terminated, and that the employee 
should  not  be  allowed  physical  or  electronic  access  from  that  point 
 forward
Please refer to Chapter 6 for more details regarding employee termination 
procedures.
One additional item of note pertains to the last two cases described in this 
section, both of which redirected external DNS registrations to sites meant 
to disrepute and slander the victim organization. Authorization to main-
tain DNS registration falls under a special category of highly privileged but 
infrequently used functions that require special documentation. Because 
these functions are used infrequently, access to them may go unnoticed and 
be forgotten when an administrator leaves the organization. This leaves 
a potential access path for a disgruntled insider to exploit for months, if 
not years, after the separation takes place. A suggested countermeasure is 
to maintain an inventory of privileged functions and a list of employees 
who have authorization to execute those functions. A regular review of this 
inventory for necessary changes based on job function or employment sta-
tus can help mitigate the risk of items such as this that may slip through the 
cracks with serious consequences.
Insufficient Access Controls and Monitoring
The  following  incidents  demonstrate  the  consequences  of  insufficient 
access controls and monitoring of access to highly sensitive information 
and materials, especially when trusted business partners are involved.
Authorization to maintain DNS registration falls under a special category 
of highly privileged but infrequently used functions that require special 
documentation. Because these functions are used infrequently, access 
to them may go unnoticed and be forgotten when an administrator leaves 
the organization.

Chapter 9.  Conclusion and Miscellaneous Issues
292
A document imaging firm was contracted by a law firm that was working 
for a telecommunications provider as outside counsel. An employee of the 
document imaging firm brought in his nephew, the insider in this case, 
to help with a backlog of copying to be completed at night. The nephew 
scanned images of trade-secret documentation associated with anti-piracy 
technology and transmitted it to the leader of an online community whose 
purpose was to pirate the services offered by the telecommunications firm. 
The forum administrator originally refused to post the information, stat-
ing it was too sensitive to be released, but eventually did so anyway under 
pressure from the insider.
A  DBA  responsible  for  a  very  large  database  containing  PII  for  an 
 insurance company became frustrated by what he perceived to be unfairly 
low pay. He lashed out at the organization by downloading PII for more 
than 60,000 people from the organization’s database to removable media. 
He used message boards to advertise the availability of the information 
to underground individuals, and solicited bids for the information. He 
also leveraged newsgroups dedicated to credit card fraud to post credit 
card  numbers,  suggesting  that  the  information  he  was  providing  be 
used to obtain additional credit cards in the names of the victims. Law 
 enforcement eventually captured the insider when an undercover agent 
posed as a potential buyer of his stolen information.
A common theme in these cases is largely unrestricted access to  proprietary 
data by the insiders, due to poor data handling policies and practices and 
lack  of  granular  access  controls.  Interestingly,  the  first  case  involves  a 
trusted business partner as well as the Internet underground! In the first 
example, company trade secrets were left largely unsecured in the hands 
of a third-party organization (the document-imaging company) contracted 
by  the  trusted  business  partner  (the  law  firm).  Trade  secrets  should  be 
protected appropriately, given their value. Contracts should specify physi-
cal  and  electronic  security  requirements,  as  well  as  personnel  security 
 requirements for anyone with access to the information.
The second case involves an insider with uncontrolled and unmonitored 
access to proprietary data. Although it is difficult to control access by DBAs, 
countermeasures should be considered for critical organizational data. For 
example, a “two sets of eyes” policy could be implemented and technically 
enforced, whereby two DBAs together are required to perform sensitive 
functions.  Other  possible  solutions  involve  delegation  models  that  use 
technical measures to limit the control that any one account has over the 
environment, or cryptographic controls that require the use of specifically 
trusted devices that cannot be removed from a controlled area to perform 
sensitive functions. These techniques limit the insider’s capacity to misuse 
access to systems or data without having at least one accomplice.

Final Summary
293
Conclusions: Insider Threats Involving the Internet Underground
The threat of insider actions associated with the Internet underground is 
very real. As shown in the case examples in this chapter, these crimes occur 
primarily out of revenge that stems from unmet expectations and disgrun-
tlement over salary or other work-related issues. Many of the attacks occur 
off-site, after termination, using access and prior knowledge the employee 
or contractor had as part of his job role.
Further, nearly all attacks involved the use of at least one form of compro-
mised account, such as an authorized third-party account or a backdoor 
account created specifically for the execution of the insider’s attack plans. 
Finally, most of the insiders in the CERT database were considered to be 
highly technical and were working in some kind of privileged  technical 
role for the organization.
Of  course,  it  is  not  always  readily  apparent  that  employees  have 
 connections with the Internet underground. You can institute measures 
to block certain illicit communication channels at the workplace, or moni-
tor and investigate their use. In addition, it is important that managers 
of technical employees exercise good management practices, including 
attempting to maintain a degree of awareness of employees’ morale, and 
suspicious behaviors both at work and outside the workplace.
Since  most  of  these  insiders  were  highly  technical,  chances  are  good 
that  they  could  have  attacked  alone,  without  enlisting  assistance  from 
the  Internet underground. In most cases, their associates simply helped 
them to amplify their attack. Therefore, implementing the best practices 
described  in  Chapter  6  of  this  book  could  have  corrected  many  of  the 
vulnerabilities that the insiders in these cases were able to successfully 
exploit.
Final Summary
You now should understand what we mean by malicious insider threat. 
This is not meant to be an authoritative definition, but it is important that 
you understand that everything you read in this book was grounded by 
this definition:
A malicious insider threat is a current or former employee, contractor, or 
business partner who has or had authorized access to an organization’s 
network, system, or data and intentionally exceeded or misused that access 

Chapter 9.  Conclusion and Miscellaneous Issues
294
in a manner that negatively affected the confidentiality, integrity, or 
 availability of the organization’s information or information systems.
Next,  we  will  turn  our  attention  to,  among  other  things,  unintentional 
insider threats. However, everything we presented in this book pertains to 
intentional malicious insider threats.
We covered three main types of insider threats in the book.
•  IT sabotage: an insider’s use of information technology (IT) to direct 
specific harm at an organization or an individual.
•  Theft of intellectual property (IP):  an  insider’s  use  of  IT  to  steal 
 proprietary information from the organization. This category includes 
industrial espionage involving insiders.
•  Fraud:  an  insider’s  use  of  IT  for  the  unauthorized  modification, 
 addition, or deletion of an organization’s data (not programs or sys-
tems) for personal gain, or theft of information that leads to an identity 
crime (e.g., identity theft, credit card fraud).
We categorized them in this way because each type of crime has a  prevalent 
pattern  that  is  common  across  the  majority  of  the  cases.  Every  type  of 
insider crime is very different: who, what, where, why, when, and how! 
Here are specifics regarding those differences.
•  Insider  IT  sabotage  is  typically  committed  by  technical  users  with 
 privileged access, such as system administrators, DBAs, and program-
mers. The motivation in these crimes is usually revenge for a negative 
workplace event, and the crimes are often set up while the insider is 
still employed, but are executed following termination.
•  Insider  theft  of  IP  is  usually  committed  by  scientists,  engineers, 
 programmers,  and  salespeople.  These  insiders  usually  steal  the 
information they worked on, and take it with them as they leave the 
organization to either start their own business, take with them to a new 
job, or give to a foreign government or organization.
•  Insider  fraud  is  usually  committed  by  lower-level  employees  such 
as help desk, customer service, and data entry clerks. The crimes are 
motivated by financial need or greed, and they typically continue for 
a long period of time. Many of these insiders are recruited by outsid-
ers to steal information. Collusion with other insiders is very common 
in  crimes  involving  modification  of  information  for  payment  from 
outside.

Final Summary
295
You should also now recognize the expanding complexity of insider threat:
•  Collusion with outsiders
•  Trusted business partners
•  Mergers and acquisitions
•  Cultural differences
•  Foreign allegiances
•  The Internet underground
We covered collusion with outsiders in the theft of IP and fraud crimes. We 
discussed trusted business partners and insiders with ties to the Internet 
underground at length in the beginning of this chapter. And we explained 
how insiders stole intellectual property for the benefit of a foreign gov-
ernment  or  organization  in  Chapter  3.  We  did  not  discuss  mergers  and 
acquisitions or cultural differences much at all, however. The reason for 
that is that we have not done research specifically in those areas yet. We 
recognize them as being important issues, and therefore want to raise your 
awareness to them. We are exploring research potentials in both areas, so 
keep an eye on our Web site for possible future reports on those topics.
The  crime  profiles  and  many  case  examples  in  this  book  should  have 
 convinced  you  that  malicious  insider  online  activity  is  very  similar  to 
what insiders do every day in the course of their normal jobs. That is why 
prevention and detection are so complex. However, mitigation strategies 
rooted in the crime profiles that involve the entire organization working 
together  have  a  much  better  chance  of  success  than  implementation  of 
broad technical controls alone. If there is one fact you take away from this 
book, it should be this: IT and information security personnel cannot stop 
insider threats alone! They need the cooperation of management, human 
resources, security, legal, data owners, and physical security.
Every type of insider crime is very different: who, what, where, why, when, 
and how!
If there is one fact you take away from this book, it should be this: IT and 
information security personnel cannot stop insider threats alone! They 
need the cooperation of management, human resources, security, legal, 
data owners, and physical security.

Chapter 9.  Conclusion and Miscellaneous Issues
296
 

Final Summary
297
The insider’s employment was terminated for undisclosed reasons. On three 
occasions over a six-month period, the insider sold 40 individuals’ names, 
DOBs, and SSNs to a law enforcement informant. Subsequently, the insider 
tried to sell a USB drive with 1,100 SSNs and 1,600 bank account numbers to 
an undercover agent. When the insider downloaded the information remains 
undetermined, but the organization believes that the insider downloaded 
the PII prior to his termination. The insider was arrested, convicted, ordered 
to pay $50,000 in restitution, and sentenced to 42 months of imprisonment 
followed by three years of  supervised release.
Theft of IP: Insider Caught before IP Released
Prior  to  the  incident,  the  insider,  a  naturalized  U.S.  citizen  who  was  a 
 programmer at an investment banking firm, submitted his letter of resig-
nation. The duration of the incident was five days; the insider used both 
on-site and remote access, outside of work hours, to carry out the attack. He 
used a swipe card to access the building, and used a Bash script that cop-
ied, compressed, and merged source code files, then encrypted, renamed, 
and uploaded them to an external file host. On four separate occasions, he 
uploaded 32 MB of files to a file host outside the country. He deleted the 
encryption program and attempted to erase the Bash history, but the orga-
nization retained backup copies of the Bash history. The insider claimed 
that the upload was accidental and that the intent was to transfer only open 
source information. The information was not passed to any third parties 
because  the  organization  had  safeguards  in  place,  including  monitor-
ing  outgoing  email  attachments,  disallowing  outgoing  FTP,  monitoring 
HTTPS, and requiring the insider to sign an intellectual property agree-
ment. The incident was detected through regular auditing of HTTPS traffic. 
The insider was arrested, but verdict details were unavailable.8
IT Sabotage: Logic Bomb Detected before It Went Off
After hearing he was going to be terminated, the insider planted a logic 
bomb to delete the root credentials of 4,000 of the organization’s servers, 
disable all monitoring, and erase all of the data. Five days after the insider 
was  terminated,  however,  one  of  the  organization’s  engineers  detected 
the malicious script and alerted organization officials before it was able to 
 execute.
8.  Because no verdict was known, the insider’s actions described in this case are alleged.

This page intentionally left blank 

299
Appendix  A
Insider Threat Center 
Products and Services
The purpose of this book is to raise awareness and assist you in formulating 
a mitigation strategy for insider threats. Some of you might choose to take 
advantage of products and services readily available from the CERT Insider 
Threat Center to jumpstart your efforts. That is the purpose of this appen-
dix. We provide an overview of products and services currently available 
from the CERT Program. Table A-1 identifies problems that you might have 
with regard to managing insider threat risks and how our  current products 
and services could help solve those problems.
Table A-1  Solutions to Current Problems
Your Pain Points
Solutions from the 
Insider Threat Center
Benefits to Your 
Organization
How can I become 
more aware of any 
organizational issues 
impacting my risk of 
insider threat?
Insider threat 
 workshops
Greater  understanding 
of the nature and 
 prevalence of insider 
threat  concerns 
and candidate 
 countermeasures
Continues

Appendix A. Insider Threat Center Products and Services
300
Table A-1  Solutions to Current Problems (Continued)
Your Pain Points
Solutions from the 
Insider Threat Center
Benefits to Your  
Organization
How can I get  better 
indications and 
 warnings of malicious 
behavior and detect 
warning signs?
Insider threat 
 assessment
More comprehensive 
protection, knowing 
that you are watching 
for the attack patterns 
of  previous malicious 
 insiders
How do I make 
the best use of my 
 existing tools?
Customized,  tactical 
countermeasure 
 guidance based 
on new operational 
 controls from the 
CERT insider threat 
lab
Insider Threat 
 standards (NIST SP 
800-53)
Better situational 
 awareness and 
improved security 
posture since tools are 
configured and properly 
tailored to the unique 
systems and concerns 
found in the mission 
operating  environment
Cost savings— analysts’ 
time is used more 
 efficiently
Where can I get 
 education and 
 training for my staff to 
effectively deal with 
and diagnose insider 
attacks?
Insider threat 
 workshops
Customized insider 
threat executive 
workshop
Cyberdefense 
 exercises  conducted 
on the CERT  Exercise 
Network (XNET)
Technical security 
 workforce more skilled 
in detecting indications 
and warnings of insider 
threat
More effective incident 
response, reducing 
the likelihood that an 
insider attack will be 
missed,  misdiagnosed, 
or dealt with 
 inappropriately

Insider Threat Workshop
301
Are my policies and 
procedures  inhibiting 
detection and 
 prevention of insider 
threats?
Insider threat 
 assessment
Customized insider 
threat executive 
 workshop
Strategic action 
plan and  supported 
 execution
Stronger ability to 
detect and respond 
to insider attacks, 
which will protect the 
 organization and avoid 
compromises of assets, 
information, and 
 reputation
Other issues of 
 concern
Sponsored research 
by the Insider Threat 
C enter
Reduction in 
 international insider 
threat risk, risk in cloud 
computing environ-
ment, unintentional 
insider threats, etc.
The rest of this appendix provides information on the five primary 
 products and services offered:
•  Insider threat workshop
•  Customized insider threat executive workshop
•  Insider threat exercises
•  Insider threat assessment
•  Insider threat sponsored research
Brochures describing the products and services are also available on our 
Web  site  at  www.cert.org/insider_threat.  Thanks  to  CERT   Business  Ser-
vices, CERT Information Services, and the CERT Insider Threat Center staff 
for help in preparing these materials.
 
1.  We also offer half-day and one-day versions of the workshop.

Appendix A. Insider Threat Center Products and Services
302
 organizational,  personnel,  security,  and  process  issues.  The  purpose  of 
the exercises is to assist participants in assessing their own organization’s 
vulnerability to insider threat in specific areas of concern. To reinforce the 
principles  taught  in  the  workshop,  we  will  also  present  technical  dem-
onstrations of monitoring techniques that could have detected malicious 
activity in actual insider threat cases. Our goal is that participants leave the 
workshop with actionable steps that they can take to better manage the risk 
of insider threat in their organization.
Who Should Attend?
The  target  audience  is  managers,  leaders,  directors,  and  chief   executives 
across all facets of the organization including IT, HR, legal, physical security, 
and operations. The workshop will benefit team leaders, project managers, 
business managers, finance managers, security officers, risk officers, C-level 
managers, and anyone else responsible for creating, implementing,  enforcing, 
and auditing practices and procedures throughout the organization.
Topics
Topics include the following:
•  Overview of insider threats
•  Insider IT sabotage
•  Insider theft of intellectual property
•  Insider fraud
•  Best practices for prevention and detection
Objectives
The workshop objectives include the following.
•  Attendees will leave the workshop with actionable steps that they can 
take to better manage the risk of insider threat in their  organization.
•  Attendees will understand the best practices that can be implemented 
to prevent insider incidents or detect them as early as possible.
•  Attendees will know what “observables” they should be looking for 
within their organizations that could indicate a pending insider attack.
•  Attendees  can  compare  our  list  of  technical  methods  against  their 
 organizations’ technical controls to identify gaps.

303
Insider Threat Exercises
Customized Insider Threat Executive Workshop
This workshop is conducted with the executive management team in your 
organization. It differs from the public workshop in several ways. First, it is 
streamlined for an executive audience. Second, the workshop materials can 
be tailored to include actual malicious insider incidents that occurred in your 
organization. To prepare for the customized workshop, you provide us with a 
number of insider incidents so that we can understand your threat landscape. 
For three days prior to the workshop, members of the Insider Threat Center 
will be on-site at your location, interviewing staff members who are familiar 
with the set of insider incidents. We treat all  customer data as confidential.
The actual workshop spans two days. The first day consists of interactive 
exercises, which help you to assess your vulnerability to insider threat. The 
second day focuses on providing you with actionable steps to better manage 
your risk of insider threat. On the second day, we help the executive team in 
developing a strategic action plan to address the risk of insider threat in your 
organization. This action plan is useful because it is created and endorsed 
by  senior  leadership,  addresses  the  particular  problems  faced  by  your 
 organization, and considers your unique corporate culture.
The  target  audience  for  the  workshop  is  senior  executives  and  decision 
makers within an organization. However, the complex nature of the insider 
threat  problem  requires  a  holistic  approach.  Multiple  departments  must 
be involved in the overall strategy. These departments include, but are not 
limited  to,  human  resources,  information  technology,  legal  and  contract-
ing, physical security, and software engineering. This inter- departmental 
 cooperation is the key to creating an effective strategy against insider threat.
 

Appendix A. Insider Threat Center Products and Services
304
platform  using  the  CERT  XNET2  environment  that  showcases  actual 
tactics, techniques, and procedures used by insiders to steal critical or sen-
sitive information, or to damage an organization’s image or infrastructure. 
The  exercises teach participants how to detect, prevent, and respond to 
crimes by insiders and helps tune their focus for trends in insider behavior 
 highlighted by the CERT Insider Threat Center’s previous body of work.
These  interactive,  team-based  exercises  re-create  complex  actual  insider 
threat scenarios and challenge participants to prepare for and respond to 
insider threat incidents. They include various injects from the teams run-
ning the exercise to simulate incidents. These exercises can be conducted 
within an organization to better equip its defenses against malicious insid-
ers, or can be used in cyberflag exercises to recognize the most sophisticated 
team among multiple competing organizations.
To date, we have created two exercises that we have offered at individual 
customer sites and in conjunction with information security conferences.
The first exercise involves the participants detecting and responding to a 
malicious code infection on their enterprise network and determining how 
the machines were infected (by malicious insider or malware). Participants 
are given the information that there is an infection somewhere on their net-
work, and the exercise progresses via quizzes that guide the participants 
toward strategies for locating the source of the infection. Participants are 
provided with familiar network monitoring tools such as Snort, Ntop, and 
Wireshark, as well as a netflow tool called SiLK. Using these tools, they will 
need to examine a network that includes simulated user traffic designed to 
model a small business organization.
The second exercise begins with the participants detecting a large source 
code  exfiltration  and  determining  how  the  exfiltration  was  carried  out. 
After investigating that attack, they will encounter several other attacks 
against  internal  systems  and  respond  to  them  accordingly.  The  exercise 
is intended to surprise participants by revealing the insider as a system 
administrator, making it difficult for them to tell whether changes were 
authorized or not.
 
2.  XNET CERT Exercise Network: http://xnet.cert.org

Insider Threat Assessment
305
risks.  The  assessment  instrument  encompasses  information  technology, 
human  resources,  physical  security,  business  processes,  legal,  manage-
ment, and organizational issues. It merges technical, behavioral, process, 
and policy issues into a single, actionable framework.
For the assessment, members of the Insider Threat Center staff will spend 
three to five days at your organization. During that time, we will review 
documents, interview key personnel, and observe key processes and secu-
rity issues. We sign nondisclosure agreements, and all collaborations will 
remain confidential. After the on-site visit, we provide you with a confiden-
tial report that contains the findings of the assessment and considerations 
for potential mitigation strategies. Organizations have used this report to 
do the following:
•  Identify and implement short-term tactical countermeasures
•  Help guide their ongoing risk management process for implementing 
long-term, strategic countermeasures
•  Justify follow-up actions to key decision makers
Our research has proven that the insider threat problem is quite complex, 
and you need an instrument that has the following characteristics:
•  Encompasses policies, practices, and technologies
•  Is empirically based yet adaptable to current trends and technologies
•  Focuses on prevention, detection, and response strategies
The  CERT  insider  threat  assessment,  which  is  based  on  psychological 
expertise as well as technical expertise, helps you to better safeguard your 
critical infrastructure. The purpose of the assessment is as follows:
•  Enable  you  to  gain  a  better  understanding  of  your   vulnerability 
to  insider  threat  and  an  enhanced  ability  to  assess  and  manage 
 associated risks
•  Include  technical,  organizational,  personnel,  and  business  security 
and process issues from all of our past research in a single, actionable 
framework
•  Benefit  all  individuals  involved  in  the  insider  threat  vulnerability 
assessment process: information technology, human resources, physi-
cal  security,  data  and  business  process  “owners,”  and  all  levels  of 
 organizational management

Appendix A. Insider Threat Center Products and Services
306
Insider Threat Sponsored Research
All of the products and services offered here have evolved from sponsored 
research  projects  we  have  undertaken  in  the  past.  We  are  always  seek-
ing  new  research  and  development  opportunities  to  assist  government 
and  private  industry  organizations  with  their  specific  areas  of  concern. 
For  example,  we  would  like  to  investigate  international  insider  threat 
risk, insider threat risk in cloud computing environments, and uninten-
tional insider threats. We also are actively developing, pilot-testing, and 
 transitioning new insider threat controls to the community.
If you are interested in discussing potential collaborations, please contact 
us at insider-threat-feedback@cert.org.

307
Appendix  B
Deeper Dive into 
the Data
We are constantly mining the CERT insider threat database for new and 
useful information, sometimes to support specific research and develop-
ment activities, sometimes based on curiosity, and sometimes at the request 
of someone outside of our team. Frequently when we hold workshops or 
give conference presentations we are asked new questions that we have not 
yet explored in the data. We often take those queries back with us, ask our 
database experts to find the answers, and provide the answers to the per-
son who asked. We also try to incorporate those answers into posts on our 
blog,1 in our workshops, and in new publications if applicable. The pur-
pose of this appendix is to provide some of those details to you, because we 
believe it could be useful to you in designing your insider threat  mitigation 
strategies.
 
1.  www.cert.org/blogs/insider_threat/

Appendix B. Deeper Dive into the Data
308
 telecommunications sector. Those two sectors together account for more 
than half of all of the cases in our database! If you are a part of one of those 
sectors, it is a good thing you are reading this book!
The  government  sectors  are  next,  followed  by  public  health,  and  then 
 commercial facilities. This is particularly interesting to us because the pub-
lic health sector did not even show up in our breakdown until the past few 
years. However, it is quite possible that those cases were occurring before, 
but organizations were keeping them quiet. More recently, in light of the 
data breach laws, organizations no longer have the option of covering up 
theft of private information.
In Figure B-2 we dig a little deeper into the top six sectors. Now we see 
that,  no  surprise,  fraud  is  the  most  prevalent  crime  in  the  banking  and 
finance sector. They are not immune to theft of IP or IT sabotage, however, 
and therefore still need to focus on protecting assets such as merger and 
 acquisition plans, strategic plans, and earnings. And as mentioned earlier 
in the book, no sector should ignore the risk of insider IT sabotage.
Figure B-1 U.S. cases by  critical infrastructure sector
N/A 4%
Postal and Shipping <1%
Transportation 1%
Water 1%
Manufacturing 2%
Public
Health
7%
Banking and Finance
29%
Chemical Industry &
Hazardous Materials 2%
Information and
Telecommunications
22%
Commercial Facilities 6%
Defense Industrial Base 2%
Education 4%
Emergency Services 1%
Energy 1%
Food 2%
Government—Federal
7%
Government—State/Local
9%

Breakdown of Cases by Type of Crime
309
The IT sector, on the other hand, has suffered a large number of IT sabotage 
attacks, as well as theft of intellectual property. Theft of IP is no surprise, 
due to the highly competitive nature and innovative nature of their busi-
ness. The prevalence of IT sabotage also deserves attention in that sector; 
the consequences of those crimes can be highly damaging!
The  government  sector  has  suffered  most  from  fraud,  followed  by  IT 
 sabotage. It is important that the government sector protect the PII with 
which it is entrusted by its citizens. In addition, it should not ignore the risk 
of IT sabotage, as there were some significant cases in that sector.
 
Figure B-2 Breakdown of crimes for top six sectors
140
160
180
80
100
120
20
40
60
Theft of IP
Banking and Finance
Information and Telecommunications
Government—State/Local
Commercial Facilities
Public Health
Government—Federal
All Other Sectors
IT Sabotage
0
Fraud

Appendix B. Deeper Dive into the Data
310
 
Figure B-3 U.S. insider IT  sabotage cases by sector
Public Health 4%
N/A 2%
Postal and Shipping 1%
Transportation
3%
Water 1%
Banking and
Finance
11%

Commercial Facilities 9%
Manufacturing 2%
Education 4%
Energy 4%
Information and
Telecommunications
40%40%

Food 2%
Government—Federal 7%
Government—State/Local 7%
DefenseIndustrialBase 3%
Banking and
Finance
11%

Information and
Telecommunications
40%


Breakdown of Cases by Type of Crime
311
Figure B-4 U.S. insider theft of IP cases by sector
N/A 2%
Water 1%
Banking and
Finance
11%
Chemical Industry &
Hazardous Materials 9%
Manufacturing 10%
Defense Industrial Base 4%
Education 2%
Energy 1%
Food 1%
Information and
Telecommunications 
45%
Government—Federal 2%
Government—State/Local 1%
Public Health 3%
Commercial Facilities 8%
Figure B-5 U.S. insider fraud cases by sector
Postal and Shipping <1%
Transportation <1%
Water 1%
Information and
Telecommunications 9%
Manufacturing 0%
N/A 4%
Public
Health
8%
Banking and Finance
47%
Government—
State/Local
11%
Food 3%
Government—Federal 5%
Chemical Industry & Hazardous
Materials 1%
Commercial Facilities 4%
Defense Industrial Base 1%
Education 4%
Emergency Services 0%

Appendix B. Deeper Dive into the Data
312
fraud cases. Government–state/local is second, followed by information 
and telecommunications and public health. Some of the sectors had little 
if any insider fraud cases; however, if you are in any of those sectors men-
tioned you should pay close attention to Chapter 4, Insider Fraud.
 
Figure B-6 Insider incident end dates over time
5
2
7
11
1996
10
20
30
40
50
60
70
1997
1998
1999
2000
2001
2002
2003
2004
2005
2006
2007
2008
2009
2010
2011
11
11
5
21
1
3
3
6
6
9
9
9
9
13
11
6
6
3
14
6
3
3
3
3
10
23
9
7
7
7
16
36
8
8
5
2
2
2
2
4
21
4
5
4
8
28
11
1
21
4
8
5
7
3
10
5
9
3
4
4
4
1
IT Sabotage
Fraud
Theft of IP
Misc.
National Security Espionage

Employees versus Contractors, Current versus Former
313
like to think that the widespread attention our work has gotten in recent 
years might be helping to increase the success rates for preventing these 
crimes, or detecting them in the planning or early execution stages, before 
the damages occur.
Employees versus Contractors, Current versus Former
Figure B-7 shows the number of cases per year by employee type. Until the 
past year, the percentage of incidents involving a contractor hovers around 
15%. As mentioned previously, our experience has shown that any data for 
2010 and 2011 is going to change quite a bit as more and more cases come 
to light, and therefore we will focus on the previous years in this graph. 
Whether the number of total incidents for a particular year is higher or 
lower, the percentages stay roughly the same. What is also interesting is 
that this ratio has stayed the same over the course of ten years of a fairly 
tumultuous economic environment. This result may indicate that it isn’t 
likely for contractor crimes to raise or lower significantly. But with almost 
one in seven of our insider threat crimes being committed by contractors, 
are you adequately considering the risk posed by this group?
Figure B-7 Insiders versus contractors
35
30
25
20
15
10
5
0 '00 '01 '02 '03 '04 '05 '06 '07
All Cases (n =436)
Employee
Contractor
'08 '09 '10 '11
Number of Cases
All Cases by Type of Employee Over Time

Appendix B. Deeper Dive into the Data
314
Figure B-8 shows the percentage of cases perpetrated by current and former 
employees, as well as employment type (full-time, part-time, or contractor). 
In some cases, we were not certain whether the incident was committed by 
a current or former employee, so we indicated those incidents as unknown. 
Full-time employees account for the greatest percentage for both current 
and former employees. Part-time employees made up a very small per-
centage of our cases, and all of them were current employees when they 
committed their illicit activity. Contractors are somewhat interesting in that 
more contractors attacked following termination than when employed by 
the victim organization.
Figures B-7 and B-8 provide some interesting data points for you to consider. 
Do you use the same prevention and detection controls for all employees 
and contractors, or are you only worried about the majority—the current, 
full-time employees you see on a daily basis? What are your procedures 
when a contractor leaves? Can you be sure that the contractor’s access has 
been fully disabled? Food for thought as you decide on the next steps after 
reading this book. . . .
Technical versus Nontechnical Insiders
Figure  B-9  shows  technical  versus  nontechnical  insiders  over  the  past 
11 years. Note that only six months of 2011 are represented in this graph.
Figure B-8 Comparison by employee type and status
100%
75%
50%
25%
0%
Note:
All Cases n = 496
Current
Former
Unknown
Contractor
Part-Time
Full-Time
Unknown
Comparison of All Sector Cases
By Type and Status of Employee

What’s Next: Other Threats
315
How  have  you  allocated  resources  for  preventing,  detecting,  and 
 responding  to  threats  posed  by  technical  and  nontechnical  employees? 
Do you focus on one type of employee and not the other? Our observa-
tions indicate that you should consider potential insider threats from both 
 technical  and  nontechnical  employees.  Insider  threats  could  come  from 
anyone.
 
Figure B-9 Technical versus nontechnical insider threats
40
35
30
25
20
15
10
5
0
2001
2000
2002
2003
2004
2005
2006
2007
2008
2009
2010
2011
Nontechnical
Technical
Both
Technical versus Nontechnical Over Time

Appendix B. Deeper Dive into the Data
316
Information (PII), which in most cases would have to be reported under the 
data breach laws. Another such event would be when an insider uninten-
tionally provides access to an external intruder—for example, by clicking 
on  an  infected  attachment,  clicking  on  a  link  in  a  phishing  email,  and 
so forth.
We have been somewhat successful in collecting insider cases that occurred 
outside  the  United  States,  but  have  not  collected  enough  from  any  one 
country to actually perform an empirical analysis. There has been a high 
degree of interest over the years in having us study the similarities and dif-
ferences in intentional insider crimes committed in countries outside the 
United States. It is more difficult to locate international cases because in 
the United States, when someone is arrested it becomes a matter of pub-
lic record, likewise when that person goes to trial. However, outside the 
United States this is not always the case. To perform a thorough insider 
threat study outside the United States we believe we need a partnership 
with  international  law  enforcement,  other  organizations  located  in  the 
country  of  interest,  or  global  organizations.  Table  B-1  shows  the  break-
down of our 45 international intentional malicious insider threat cases by 
country of  origin.
Table B-1 International Malicious Insider Cases in Our Database
Number of Cases
Country
18
United Kingdom
4
Australia
3
India
2
Japan
4
Korea
1
Canada
2
China
1
Europe
2
France
1
Greece
1
Italy

What’s Next: Other Threats
317
1
Romania
1
Russia
1
Singapore
1
Switzerland
1
Thailand
1
United Arab Emirates
Stay tuned to our Web site, www.cert.org/insider_threat, for new research 
in these areas!

This page intentionally left blank 

319
Appendix  C
CyberSecurity Watch 
Survey
To  properly  allocate  information  security  resources  and  budgets, 
 organizations need to know the prevalence of insider threat, especially as 
compared to outsider threat.
In 2004 we decided that we should develop another method for  measuring 
the  prevalence  of  malicious  insider  incidents  across  the  United  States. 
Therefore,  we  partnered  with  CSO  Magazine  and  the  Secret  Service  to 
conduct  the  first  annual  CyberSecurity  Watch  Survey.  The  survey  has 
been a successful method for gathering information regarding electronic 
crimes, techniques, best practices, and emerging trends; therefore, we have 
 continued to conduct the survey on an annual basis1 [CSO 2011a].
The survey is sent out annually to CSO Magazine readers and site visitors, 
as well as members and partners of the Secret Service’s Electronic Crimes 
Task Forces. Results from the 2011 survey are provided in this section to 
describe the prevalence and current trends of insider threat according to 
that survey [CSO 2011b].
1.  Note that in some years Deloitte and Microsoft also participated in the survey.

Appendix C. CyberSecurity Watch Survey
320
The overarching question we always ponder is how many organizations 
are actually victims of insider threats. Figure C-1 displays the results of that 
question throughout the years. As you can see, the number of  organizations 
experiencing a malicious insider incident peaked in 2006, and definitely 
decreased in 2010. After the number hovered at around 50% for three years, 
we are greatly encouraged by the drop last year! We know from annual 
survey  results  that  organizations  are  implementing  the  countermea-
sures recommended by organizations like ours, which might explain the 
decrease.
Note  that  the  size  of  organizations  was  well  represented;  38%  of  the 
 organizations have more than 5,000 employees and 37% of organizations 
have fewer than 500 employees.
One of the questions we are frequently asked is the breakdown of  insiders 
versus outsiders. The e-crime survey is an opportunity to obtain data to 
answer  that  question.  Figure  C-2  shows  the  breakdown  in  our  survey 
results.2
2.  Source: 2011 CyberSecurity Watch Survey, CSO Magazine, U.S. Secret Service, Software Engineering 
Institute CERT Program at Carnegie Mellon University, and Deloitte, January 2011 [CSO 2011b].
Figure C-1  Percentage of survey participants who  experienced a malicious 
insider incident (Source: 2011  CyberSecurity Watch Survey, CSO  Magazine, 
U.S. Secret Service, Software  Engineering Institute CERT  Program at 
 Carnegie Mellon University, and Deloitte, January 2011.)
2004
41
39
55
49
51
43
2005
2006
2007
2008
2010
60
40
20
0
100
80

Appendix C. CyberSecurity Watch Survey 
321
 
3.  Ibid.
Figure C-2  Insiders  versus outsiders (Source: 2011  CyberSecurity 
Watch Survey, CSO Magazine, U.S. Secret Service, Software 
 Engineering Institute CERT Program at Carnegie Mellon University, 
and Deloitte, January 2011.)
80
71
100
80
60
40
20
0
69
66
73
27
34
31
32
20
29
68
2004
2005
2006
2007
2008
2010
Insiders
Outsiders

Appendix C. CyberSecurity Watch Survey
322
 
4.  Ibid.
Figure C-3  Which crimes were more costly? (Source: 
2011 CyberSecurity Watch Survey, CSO Magazine, 
U.S. Secret Service, Software  Engineering Institute 
CERT Program at Carnegie Mellon  University, and 
Deloitte, January 2011.)
Outsiders
38%
Unknown
29%
Insiders
33%

Appendix C. CyberSecurity Watch Survey 
323
for the crime. Our goal in this book is to help you with these reasons so 
that you can identify the perpetrator, and you have sufficient evidence to 
 prosecute if you choose to do so.
Figure C-4  How insider  intrusions are handled 
(Source: 2011  CyberSecurity Watch  Survey, CSO    
Magazine, U.S. Secret  Service,  Software  Engineering    
Institute CERT Program at  Carnegie Mellon University,  
and Deloitte, January 2011.)
76%
8%
3%
12%
Internally (without Legal Action or Law
Enforcement) 
Externally (Filing a Civil Action)
Internally (with Legal Action)
Externally (Notifying Law Enforcement)

This page intentionally left blank 

325
Appendix  D
Insider Threat 
Database Structure
Since 2001, we have been collecting incidents of malicious insider activity 
that occurred in U.S. organizations. In each of those incidents, the insider was 
found guilty in a U.S. court of law. To date, we have collected more than 700 
cases of insider IT sabotage, fraud, theft of intellectual property, and national 
security espionage. This data provides the foundation for all of our insider 
threat research, work in our lab, assessments, workshops, and exercises.
We record actual insider incidents, providing a behavioral and technical 
framework for characterizing insider activity and analyzing incidents in a 
meaningful way that can be used to prevent, detect, and respond to insider 
threats. The recording of the details of an insider incident is commonly 
referred to as “coding.” This appendix describes the structure of the insider 
threat  database,  as  well  as  our  data  collection  and  coding  process.  This 
appendix will most likely be useful to other researchers, as it addresses 
questions we have received from the research community over the years.
 

Appendix D. Insider Threat Database Structure
326
affected  organization. We then research the case to collect as much source 
 material as we can find. The majority of our cases come from public sources 
of information, although more than 200 cases have been obtained through 
law  enforcement  partners  and  victim  organizations;  those  cases  include 
 confidential information regarding the insider or the victim organization.
The  sources  of  information  we  gather  and  use  to  code1  insider  threat 
cases are
•  Public sources of information
•  Media reports, including Department of Justice and U.S. Attorney’s 
Office press releases
•  Court documents obtained using LexisNexis, from law enforcement, 
or directly from the courts
•  Other  publications,  including  books,  news  outlets,  police  reports, 
and organization press releases
•  Nonpublic sources of information
•  Law enforcement investigations
•  Victim organization investigations
•  Interviews with victim organizations
•  Interviews with convicted insiders
•  Interviews with investigators and prosecutors
Recently,  we  received  feedback  from  practitioners  on  the  front  line  of 
 computer network defense that while malicious insider activity is of great 
concern, of equal concern is nonmalicious (accidental) activity, for which 
controls also need to be put in place. In addition, we have received feedback 
from individuals outside the United States, and from global organizations 
that have branches located outside the United States. They would like to 
know if the insider activity exhibited in U.S. cases is similar to or differ-
ent from activity in incidents in organizations outside the United States. In 
addition, they need to know if the same countermeasures we recommend 
are  legal  in  various  other  countries,  due  to  stringent  employee  privacy 
laws.  Based  on  this  feedback,  we  have  begun  collecting  incidents  from 
outside the United States, as well as unintentional insider threats, such as 
accidental data disclosure or clicking on infected email attachments.
1.  Code:  in  the  context  of  insider  threat  case  research,  entering  the  details  of  a  case  in  a  database 
 according to a set of well-defined criteria.

Coding Process
327
Coding Process
Information  about  three  entities  is  needed  when  coding  insider  threat 
cases: the organization(s) involved, the insider (subject), and the details 
of the incident. Figure D-1 shows the primary relationships among these 
three entities.
Organization Data
Multiple organizations can be involved in a single incident. An  organization 
that  is  negatively  impacted  by  an  incident  is  designated  as  a  victim 
 organization. Incidents may also involve another organization—the victim 
organization’s trusted business partner. In these incidents, the malicious 
insider  is  not  directly  employed  by  the  victim  organization,  but  is  able 
to  attack  the  organization  because  of  authorized  access  granted  to  him 
through a contractual relationship with his  or her employer. Chapter 9, 
Conclusion and Miscellaneous Issues, contains a section devoted to insider 
threats from trusted business partners.
Incidents,  particularly  those  involving  theft  of  IP,  may  also  have  a 
 beneficiary organization,  an  organization  that  knowingly  or  unknow-
ingly gains an advantage from the incident to the detriment of the victim 
organization. We identify the organization and any organizational issues 
that were relevant to the case, as shown in Table D-1. The tables in this 
appendix are not the data dictionary for the insider threat database; they 
are provided to give you insight into the type of information collected for 
each incident and a few sample values for each type of data.
Figure D-1  Entities needed when coding insider threat 
cases
Subject
Organization
Incident
Harms
Perpetuates
Grants Access
To

Appendix D. Insider Threat Database Structure
328
Table D-1  Organization Information Collected
Organization Subcategory
Information Collected in the Database
Organization Descriptors
Name, address, relation to insider
Organization Type
Victim, beneficiary, trusted business  partner, 
other
Organization Description
Description of the organization
Industry Sector
Critical infrastructure sector of the 
 organization
Based in the United 
States?
Location of the organization; based in the 
United States?
Organization Issues
Work environment such as hostile work 
environment or culture of mistrust; layoffs, 
mergers and acquisitions, reorganizations, 
and other workplace events that may have 
contributed to an insider’s  decision to act
Opportunity Provided to 
Insider
Actions taken by organization that may 
have contributed to the insider’s  decision 
to take action (such as demotions or 
 transfers of employees); failure on the part 
of the  organization to take action based on 
 concerning behaviors or other events, actions, 
or conditions; or vulnerabilities—for example, 
insufficient monitoring of external access
Subject Data
We  collect  any  details  we  can  find  about  the  insider,  including  details 
regarding planning activities. These details are generally discovered after 
an  incident  has  already  occurred,  but  are  essential  to  preventing  future 
insider threats. We also collect information about the insider’s accomplices, 
including demographic data, the accomplice’s relationship to the insider 
and the victim organization, and the accomplice’s role in the incident.
We do not make any judgments about the insider or attempt to diagnose 
his or her behavior; we code exactly what we find in the source materials.
Table D-2 describes the subject attributes in more detail.

Coding Process
329
Table D-2  Subject Information Collected
Subject Subcategory
Information Collected in the Database
Descriptors
Name, gender, age, citizenship, residence, 
education, employee title/type/status, 
 departure date, tenure, access, position
Motives and Unmet 
 Expectations
Motives (financial, curiosity, ideology, 
 recognition, external benefit), unmet 
 expectation (promotion, workload, financial, 
usage)
Concerning Behaviors
Tardiness, insubordination, absences, 
 complaints, drug/alcohol abuse, 
 disgruntlement, coworker/supervisor conflict, 
violence, harassment, poor performance, 
poor hygiene, etc.
Violation History
Security violations, resource 
 misuse,  complaints, deception about 
 background
Consequences
Reprimands, transfers, demotion, HR report, 
termination, suspension, access revocation, 
counseling
Substance Abuse
Alcohol, hallucinogens, marijuana, 
 amphetamines, cocaine, sedatives, heroin, 
inhalants
Planning and Deception
Prior planning activities, explicit deceptions
Incident Data
Information  about  the  incident  includes  individual  actions  taken  to  set 
up the attack, vulnerabilities exploited during the attack, steps taken to 
conceal it, how the incident was detected, and the impact to the victim 
 organization. In addition, when available, data is collected on actions taken 
by the organization in response to the incident, and events and conditions 
that may have contributed to an insider’s decision to carry out an attack. 
Table D-3 describes the incident attributes in more detail.

Appendix D. Insider Threat Database Structure
330
Table D-3  Incident Information Collected
Incident Subcategory
Information Collected in the Database
Case Summary
Incident dates, duration, prosecution
Conspirators
Accomplices, type of collusion, relationships 
to insider
Information Sources
Origination, type
Incident Chronology
Sequence, date, place, event
Investigation and Capture
How identified and caught
Prosecution Result
Indictment, subject’s story, sentence, case 
outcome
Recruitment
Outside/competitor induced, insider collusion, 
outsider collusion, acted alone, reasons for 
collusion
IT Accounts Used
Subject’s, organization’s, system 
 administrator’s, database administrator’s, 
coworker’s, authorized third party, shared, 
backdoor
Outcome
Data copied/deleted/read/modified/created/
disclosed, used in identity theft, unauthorized 
document created, denial of service
Impact
Description, financial
How Detected
Software, information system, audit, 
 nontechnical, system failure
Who Detected
Self-reported, IT staff, other internal; 
 customer, law enforcement, competitor, other 
external
Log Files Used
System files, email, remote access, ISP
Who Responded
Incident response team, management, other 
internal
Vulnerabilities Exploited
Sequence of exploit, description, vulnerability 
grouping

Coding Process
331
Technical Methods
Technical methods used to set up and/or 
carry out the attack (e.g., hardware device, 
malicious code, modified logs, compromised 
account, sabotaged backups, modified 
 backups)
Concealment Methods
Concealment methods used to hide technical 
and nontechnical methods

This page intentionally left blank 

333
Appendix  E
Insider Threat 
Training Simulation: 
MERIT InterActive
 

Appendix E. Insider Threat Training Simulation: MERIT InterActive
334
are  becoming  increasingly   important  for  providing  training  in  complex 
 socio-technical domains efficiently and effectively.
This appendix describes our development of a training simulation, called 
MERIT InterActive, for the complex socio-technical domain of insider threat 
[Greitzer 2008]. The first section is geared more toward a research audience, 
providing  background  on  the  effectiveness  of  various  training  mecha-
nisms. The second section describes the MERIT InterActive prototype, and 
will be of more interest to practitioners.
As we describe in [Greitzer 2008], MERIT InterActive “immerses players in 
a realistic business setting from which they make decisions about how to 
prevent, detect, and respond to insider actions and see how their decisions 
impact key performance metrics. It provides a team-oriented,  role-playing 
experience  using  model-based  simulation  of  critical  aspects  of  insider 
threat risk management in a realistic organizational context. Team orien-
tation  is  critical  because  organizations  typically  identify  these  problems 
at  an  organizational  enterprise  level  rather  than  an  individual  manager 
or department level. Role playing is also crucial because solutions gener-
ally require collaboration among multiple stakeholders; role playing helps 
players understand and acquire the necessary skills.”
 

335
Background on Effectiveness of Various Training Mechanisms
funded development of MERIT InterActive—a proof of concept for an insider 
threat training simulation. We have discussed and demonstrated our MERIT 
InterActive prototype at several government and industry meetings and con-
ferences, and have received positive feedback [Cappelli 2006, Moore 2007].
The  MERIT  InterActive  prototype  is  based  on  system  dynamics  [Sterman 
2000, Forrester 1994]. Refer to Appendix F, System Dynamics Background, 
for more information. The combination of system dynamics to characterize 
the complex, feedback-rich domain of insider threat, and a remotely playable 
game-like environment for learner immersion, seems to be a match made in 
heaven. In the domain of information security, the positive effects of training 
on performance have been demonstrated [Phelps 2006]. Training simulation 
techniques can facilitate an organization’s difficult transition from a reactive 
to a proactive management culture [Moore 2006]. Lane [1995] and Groess-
ler [2004] review the history of training simulation and describe the value 
of and requirements for using these simulations to provide managers with 
an intellectually and emotionally rich and engaging educational experience. 
Business management training simulation promotes more effective learning 
by developing critical attitudes and both the skill and confidence needed to 
transition lessons learned to an  operational environment.
 
The combination of system dynamics to characterize the complex, 
feedback-rich domain of insider threat, and a remotely playable game-like 
environment for learner immersion, seems to be a match made in heaven.

Appendix E. Insider Threat Training Simulation: MERIT InterActive
336
the course of about nine months. The Manufacturing Game workshops helped 
build a common culture and vision around creating a more reliable operation. 
The workshops improved the refinery’s bottom line by more than $10 million 
annually by improving output, eliminating waste, and cutting costs.
Another  simulation  game  related  to  information  security,  called 
 CyberCIEGE, teaches network security concepts through a Sim City–styled 
simulation, and has garnered positive feedback [Cone 2006].
 
Figure E-1  Development of case-based training simulation
Modeling
Training
Simulation
Case
Analysis
Learning
Objectives
Empirical
Data
Scenarios
Development
of Case-Based
Training Simulation

337
The MERIT InterActive Prototype
the learning objectives. The second semester focused on the development of 
the system engine and a user interface that uses state-of-the-art graphics, 
video, and audio technologies to bring the scenario to life.
You, as a player of Merit InterActive, serve as a new team manager for a com-
pany that hosts Web sites and stores information for clients. As the manager, 
your team must migrate the customer database to a Web-based online ser-
vice providing clients the ability to customize their service faster and more 
easily. Your mission is to meet the deadline established for migrating the 
database while adequately managing the team through a set of business 
and information technology processes. What you don’t realize is that one of 
your team members is disgruntled with the new management situation and 
covertly plans to execute a logic bomb to destroy the team’s work.
The core struggle you face, which makes the game challenging and fun, is 
to ensure the team’s progress toward project completion while mitigating 
the risk of insider attack.
As in any organization, you work with the human resources (HR)  department 
to manage people and with the information technology (IT) department to 
manage IT. The game also engages you in regular (video) meetings with your 
boss to get feedback on how well you are doing and to get advice on future 
directions in terms of both execution of the migration and mitigation of the 
risk of insider attack. Figure E-2 shows the interface for the game.
Figure E-2  MERIT  InterActive interface—information  technology floor

Appendix E. Insider Threat Training Simulation: MERIT InterActive
338
 
Figure E-3  Range of  game-playing results
Attack
Successful;
Project
Devastated
Attack
Successful,
but Partial 
Recovery
Not
Disgruntled;
Project
Succeeds
Disgruntled,
but Attack
Deterred
Attack
Attempted
but Blocked

339
The MERIT InterActive Prototype
 

Appendix E. Insider Threat Training Simulation: MERIT InterActive
340
properties and lessons of each stage are described in the sidebars. After 
you  go  through  each  stage,  the  checkpoint  provides  video-supported 
player  feedback,  evaluation,  and  scoring.  Our  general  strategy  is  that 
players should learn by failing, and improving, in a safe environment. So, 
even  perfect performance on your part in our initial prototype still leads 
to entering Stage 3 (i.e., an insider starting to set up the attack), but good 
performance could prevent the insider from entering Stage 4 (i.e., attack 
execution). Table E-1 provides an overview of each stage.

Table E-1  Overview of MERIT InterActive Stages
Stage
Pre- condition
Post- conditions
Example Properties of 
the Scenario
Example Key Lessons
Stage 1: 
Expectation 
Escalation and 
Management
An insider is 
predisposed 
to malicious 
action.
Worst case: an insider 
whose expectations have 
been allowed to grow way 
beyond what can be sup-
ported
Best case: an insider 
whose expectations were 
constrained to a level 
consistent with a clearly 
defined organizational 
policy
Expectation escala-
tion is exhibited by 
the insider’s height-
ened freedom or 
recognition within the 
organization, e.g., the 
more the insider gets, 
the more he wants, 
and the more the 
organization gives in 
return (up to a point).
Management’s communi-
cation with its employees 
concerning organizational  
policies, appropriate 
expectations in light of 
those policies, and man-
agement’s consistent 
enforcement of organiza-
tional policies can keep 
insiders’ expectations from 
growing beyond that which 
can practically be fulfilled.
Stage 2: 
Disgruntlement 
Escalation and 
Management
The insider’s 
unmet expec-
tations cause 
disgrunt-
lement to an 
extent that 
he starts dis-
rupting the 
workplace 
(behaviorally).
Worst case: a seriously 
disgruntled insider who is 
motivated to set up a tech-
nical attack
Best case: an insider who 
is given an appropriate 
mechanism for dealing 
with his disgruntlement 
(e.g., employee-assistance 
 program referral)
Disgruntlement 
escalation is exhib-
ited by the insider’s 
increased behavioral 
disruption within 
the workplace in 
response to man-
agement action (or 
inaction).
 Managers need to handle 
the initial grievance 
appropriately. They can 
also play a key role in 
providing the insider with 
a  mechanism to reduce 
his disgruntlement level.
Continues
341

Stage
Pre- condition
Post- conditions
Example Properties of 
the Scenario
Example Key Lessons
Stage 3: Attack 
Setup and 
Monitoring
An insider is 
disgruntled 
to an extent 
that he starts 
setting up 
a technical 
attack.
Worst case: an insider who 
is ready and willing to exe-
cute his technical attack
Best case: an  organization 
that is aware when the 
insider takes technical 
steps to set up the attack, 
perhaps even preventing 
the attack from occurring
Attack setup is exhib-
ited by the insider’s 
move toward greater 
concealment of his 
disgruntlement and 
increased technical 
actions to set up and 
amplify the impacts of 
the impending attack.
Given an insider’s desire 
to attack, management’s 
knowledge of access 
paths available to the 
insider is essential for 
beingable to  prevent 
an attack. Auditing can 
help discover previously 
unknown paths, but it 
takes time to work. This 
delay may be all the 
insider needs to attack.
Stage 4: Attack 
 Execution and 
 Recovery
An insider has 
a technical 
attack set up 
and ready to 
execute.
Worst case: an insider who 
has attacked the organi-
zation’s systems and a 
manager whose project is 
destroyed
Best case: an organization 
that is able to recover quickly 
from the attack, minimizing 
the operational and financial 
impact, because of a proven 
disaster recovery plan
If the insider’s desire 
to attack upon termi-
nation is moderate 
or if risk aversion is 
high, discussions 
post-termination that 
emphasize the orga-
nization’s vigilance 
may result in  reducing 
in reducing the insid-
er’s desire to attack.
Strong backup and recov-
ery plans and procedures 
can lessen the impact 
due to attack.
Table E-1  Overview of MERIT InterActive Stages (Continued)
342

343
Conclusion
Conclusion
The current prototype provides a coherent, well-grounded, and engaging 
environment for teaching primary lessons for mitigating risk of insider IT 
sabotage. Our future research will investigate the effectiveness of training 
simulation for teaching insider threat concepts. We hypothesize that those 
experiences that engage the student with direct, mastery experiences, such as 
would be the case with a gaming or simulation environment, would increase 
the individual’s domain self-efficacy to an extent greater than would be the 
case with just a vicarious training situation, such as often occurs with a lec-
ture or workshop environment. A hybrid approach that utilizes both direct 
and vicarious experience, however, should produce even greater increases in 
domain self-efficacy than either approach  individually.
While the particular media used has generally shown not to significantly 
affect the quality of learning [Russell 2001], the instructional design strategy 
can play a large role in participant learning and performance improvement. 
Utilizing Bandura’s Social Cognitive Theory, we will examine the nature of 
the relationship between insider threat training and effectiveness of insider 
threat  management  as  measured  by  pre-  and  post-training  assessments 
of  domain  self-efficacy.  We  will  also  evaluate  the  individual  and  rela-
tive effectiveness of alternative traditional training modalities, both with 
and without training simulation. Finally, we will evaluate the individual 
and comparative effectiveness of differing interactive content within the 
 training simulation.
While the focus so far has been on insider IT sabotage, the design is, to some 
extent, data-driven allowing the implementation of additional scenarios 
without necessitating changes to the code. Using this approach, the initial 
release of MERIT InterActive would include the IT sabotage scenario, but 
subsequent effort would implement additional scenarios for insider fraud 
and insider theft of intellectual property, based on the models described in 
this book. Future work in this area will require experiments to determine 
how well game players are learning important insider threat domain les-
sons. We believe continued research will produce training simulations for 
insider threat that will help decision makers make more informed  decisions 
about insider threat risk mitigation.

This page intentionally left blank 

345
Appendix  F
System Dynamics 
Background
 

Appendix F. System Dynamics Background
346
worse in the long term. For example, employee termination might solve an 
immediate problem, but it may also lead to long-term problems for the orga-
nization if the insider has the technical means to attack the system following 
termination. System dynamics is a valuable analysis tool for  gaining insight 
into long-term solutions and for demonstrating their  benefits.
A  powerful  tenet  of  system  dynamics  is  that  the  dynamic  complexity  of 
 problematic behavior is captured by the underlying feedback structure of 
that behavior. We decompose the causal structure of the problematic behav-
ior into its feedback loops to understand which loop is strongest (i.e., which 
loop’s  influence  on  behavior  dominates  all  others)  at  particular  points 
through time. We can then thoroughly understand and communicate the 
nature of the  problematic behavior and the benefits of alternative  mitigations.
System dynamics model boundaries are drawn so that all the enterprise 
elements necessary to generate and understand problematic behavior are 
contained  within  them.  This  approach  encourages  the  inclusion  of  soft 
(as well as hard) factors in the model, such as policy-related, procedural, 
administrative, or cultural factors. The exclusion of soft factors in other 
modeling techniques essentially treats their influence as negligible, which 
is often not the case. This endogenous viewpoint helps show the benefits of 
mitigations to the problematic behavior that are often overlooked, partly 
due to a narrow focus in resolving problems.
In our work we rely on system dynamics as a tool to help understand and 
communicate contributing factors to insider threats and implications for 
various mitigation strategies and tactics. It is tempting to use the simulation 
of the model to help predict the occurrence of insider attacks or the effect of 
mitigation strategies, but what is the nature of the types of predictions that 
system dynamics facilitates? Dennis Meadows offers a concise answer by 
categorizing outputs from models as follows [Meadows et al. 1974]:
•  Absolute and precise predictions (e.g., exactly when and where will the 
next cyberattack take place?)
•  Conditional  precise  predictions  (e.g.,  how  much  will  it  cost  my 
 organization if a cyberattack occurs?)
•  Conditional  imprecise  projections  of  dynamic  behavior  modes  (e.g., 
if  a  bank  mandates  background  checks  for  all  new  employees,  will 
its   damages  from  insider  fraud  be  less  than  they  would  have  been 
 otherwise?)
•  Current trends that may influence future behavior (e.g., what effect will 
current trends in espionage have on national security in five years?)

347
   System Dynamics Background
•  Philosophical explorations of the consequences of a set of  assumptions, 
without  regard  for  the  real-world  accuracy  or  usefulness  of  those 
assumptions (e.g., if another country succeeds in human cloning, how 
would this affect the risk of espionage for the United States?)
Our  models—and  system  dynamics  models  in  general—provide  infor-
mation  of  the  third  sort.  Meadows  explains  further  that  “this  level  of 
knowledge is less satisfactory than a perfect, precise prediction would be, 
but it is still a significant advance over the level of understanding  permitted 
by current mental models.”
In the models in this book, we have modified the system dynamics causal 
loop diagram notation to be more suitable for our readers. Arrows still rep-
resent the pair-wise influence of the variable at the source of the arrow on 
the variable at the target of the arrow, but their look indicates how they 
should be interpreted.
•  Roughly, a solid arrow indicates a positive influence—that the value of 
the source and target variables moves in the same direction.1
•  Roughly, a dashed arrow indicates a negative influence—that the value 
of the source and target variables moves in the opposite  direction.2
As mentioned, dynamically complex problems can often be best  understood 
in terms of the feedback loops underlying those problems. There are two 
types of feedback loops: balancing and reinforcing.
•  Balancing  loops  describe  the  system  aspects  that  oppose  change, 
 tending to drive organizational variables to some goal state. In other 
words, balancing loops tend to move the system to an equilibrium state 
even in the face of change. The behavior of a thermostat is an exam-
ple of a balancing loop. It continually changes the air flow into a room 
based on the temperature of the room, with the goal of maintaining an 
 equilibrium temperature.
1.  More formally, a solid arrow indicates that if the value of the source variable increases, the value of 
the target variable increases above what it would otherwise have been, all other things being equal. 
And if the value of the source variable decreases, the value of the target variable decreases below what 
it would otherwise have been, all other things being equal.
2.  More formally, a dashed arrow indicates that if the value of the source variable increases, the value 
of the target variable decreases below what it would otherwise have been, all other things being equal. 
And if the value of the source variable decreases, the value of the target variable increases above what it 
would otherwise have been, all other things being equal.

Appendix F. System Dynamics Background
348
•  Reinforcing loops describe the system aspects that tend to drive  variable 
values consistently upward or consistently downward. In other words, 
reinforcing loops can “spiral out of control.” A flu epidemic is an exam-
ple of a reinforcing loop. It spirals out of control as more and more 
people contract the flu.
System dynamics models are described as a sequence of feedback loops 
that characterize how the problem unfolds over time. Each feedback loop 
describes a single aspect of the problem. Multiple feedback loops interact 
to capture the complexities of the problem domain.
You can determine the type of a feedback loop by counting the number of 
negative influences along the path of the loop. An odd number of nega-
tive influences indicates a balancing loop, and an even (or zero) number of 
negative influences indicates a reinforcing loop.
 
3.  SDN members include University at Albany; Agder University College; TECNUN, University of 
Navarra; Worcester Polytechnic Institute; Sandia National Labs; Argonne National Labs; and the CERT 
Program at the Software Engineering Institute.
4.  At the time of this writing, the Web site for the Conflict, Defense, & Security SIG at www.ConflictSIG 
.org was under construction.

The Security Dynamics Network
349
We  bring  technical  security  experts  together  with  insider  threat  experts 
and behavioral scientists to build models that cover the broad spectrum of 
behavioral and technical aspects of the problem.
First SDMIS Workshop: The first workshop, in February 2003, was attended 
by a small number of organizations and held at Agder University College 
in Grimstad, Norway. Group modeling conducted there focused on a par-
ticular insider who planted a logic bomb in an organization’s systems that 
he helped engineer because he felt that a new system administrator hired 
above  him  in  the  organization  was  incompetent.  The  group  published 
a  number  of  papers  in  the  2003  System  Dynamics  Society  Conference 
[Melara  2003]  and  in  a  book  titled  From Modeling to Managing Security: 
A System Dynamics Approach, edited by Jose Gonzalez [Gonzalez 2003].
Second SDMIS Workshop:  The  SDN  grew  nearly  to  its  present  size  in 
 convening  the  second  workshop  held  in  February  2004  at  the  CERT 
 Program at the Software Engineering Institute in Pittsburgh. Group mod-
eling  focused  on  identifying  patterns  across  a  set  of  six  actual  cases  of 
insider compromise: Two insiders stole for financial gain, two created and 
detonated a logic bomb, and two stole software critical to the company. 
The  cases  varied  widely  in  terms  of  their  technical  sophistication  and 
primary motivation. The work established the “dynamic trigger” hypoth-
esis to explain that the dynamic behaviors leading up to and triggering 
attacks can enable the design of more effective defense strategies. Results 
were documented at a public Web site, www.cert.org/research/sdmis/, 
and in a conference paper [Andersen 2004]. Our follow-on work, in col-
laboration with one SDN member, Dr. Elise Weaver, then from Worcester 
 Polytecnic  Institute,  led  to  the  development  of  the  insider  IT  sabotage 
model [Cappelli 2006].
Third SDMIS Workshop:  The  SDN  decided  to  focus  on  a  particular 
class  of  insider  crimes—insider  fraud—in  the  third  workshop  held  in 
November 2004, again at the Software Engineering Institute in Pittsburgh. 
While the group model developed was based on real cases of insider fraud 
from the CERT insider threat database, the model was set in the context 
of a representative (instructional) case that exhibited many of the prop-
erties  of  the  real  cases.  As  insider  fraud  cases  typically  progress  over 
longer  periods  of  time  than  other  types  of  insider  attacks,  signal  detec-
tion theory and judgment analysis was incorporated into the model and 
the result used in classroom settings. In addition to a paper at the Society’s 
2005 conference [Rich 2005], a number of journal papers were published 
[Martinez-Moyano 2006,  Martinez-Moyano 2008].

Appendix F. System Dynamics Background
350
The SDN had limited success in getting funding for collaboration across 
all  member  institutions,  but  we’ve  gotten  together  to  share  information 
and progress in Grimstad and Albany, with NATO support. In addition, 
individual member organizations have continued to use system dynam-
ics  effectively  for  their  own  bodies  of  work.  We  have  continued  to 
develop models of insider threat based on the CERT database of insider 
crimes, as described in this book [Moore 2011a, Moore 2011c, Moore 2008, 
Moore  2007].  Sandia  has  also  recently  published  an  employee  life-cycle 
model of the evolution of insiders within an organization based on cases 
of insider compromise that it has identified [Duran 2009]. Of course, others 
outside the SDN have recognized the value of system dynamics model-
ing for this domain [Foroughi 2008] and we look forward to expanding the 
network and the domain of modeling as we integrate with the Conflict, 
Defense, & Security SIG of the System Dynamics Society.

351
Glossary of Terms
access path:  A sequence of one or more access points that lead to a critical 
system.
Ambitious Leader:  A leader of an insider crime who recruits insiders to 
steal information for some larger purpose.
anonymous remailer:  A server that receives email messages containing 
embedded instructions on where to forward them. The server then 
 forwards the messages while also masking their originating location.
anti-spam blacklists:  A system designed to block spam messages 
through a system of IP address filtering. Often functions in tandem 
with a content-recognition system.
backdoor account:  An unauthorized account created for gaining access 
to a system or network known only to the person who created it.
behavioral precursor:  An individual action, event, or condition that 
involves personal or interpersonal behaviors and that precedes and is 
associated with malicious insider activity.
beneficiary organization:  An organization that knowingly or unknow-
ingly gains an advantage from the incident to the detriment of the 
victim organization.
change controls:  Formal processes used to ensure that changes to a prod-
uct or system are introduced in a controlled and coordinated manner.1
1. Wikipedia

352
Glossary of Terms
code reviews:  A process to examine source code, typically by someone 
other than the original coder, with the purpose of identifying and 
addressing mistakes.
coded:  In the context of insider threat case research, the details of a case 
entered in a database according to a set of well-defined criteria.
data leakage tools:  See data loss prevention (DLP) systems.
data loss prevention (DLP) systems:  Refers to systems designed to 
detect and prevent unauthorized use and transmission of confidential 
 information.2 Also commonly called data leakage tools.
denial-of-service attack:  A type of cyberattack in which a large amount 
of traffic is directed at a server in an attempt to disable it.
digital rights management (DRM):  A term for access control  technologies 
that are used by hardware manufacturers, publishers, copyright 
 holders, and individuals to limit the use of digital content and devices.
digital watermarking:  The process of embedding information into a 
 digital signal, which may be used to verify its authenticity or the iden-
tity of its owners, in the same manner as paper bearing a watermark 
for visible identification.3
domain names:  Host names tied to IP resources such as Web sites 
(adapted from ICANN/Wikipedia).
economic espionage:  The conscious and willful misappropriation of 
trade secrets with the knowledge or intent that the offense will benefit 
a foreign government, foreign instrumentality, or foreign agent.4
Entitled Independent:  An insider, usually with some expectation of own-
ership or entitlement to organization property, acting primarily alone 
to steal  information to take to a new job or to his own side business.
event correlation:  A technique for making sense of a large number of 
events and pinpointing the few events that are really important in that 
mass of information.5
2. Wikipedia
3. Wikipedia
4. See www.ncix.gov/publications/reports/fecie_all/fecie_2007/FECIE_2007.pdf.
5. Wikipedia

Glossary of Terms
353
file integrity checker:  A tool that partially automates the process of 
 identifying changes to system files or the addition of malicious code 
and flagging them for investigation.6
File Transfer Protocol (FTP):  A communication standard used to transfer 
files from one host to another over a network, such as the Internet.7
fraud:  See insider fraud.
HTTPS traffic:  Network traffic that is encrypted via the Secure Sockets 
Layer protocol.
identity crime:  The misuse of personal or financial identifiers in order 
to gain something of value and/or facilitate some other criminal 
activity.8
identity management system:  A system or technology that supports the 
management of identities. It is generally accepted that an IMS will 
establish identities, describe identities through one or more attributes, 
follow identity activity, and be capable of removing an identity from 
the system it manages (adapted from FIDIS).
industrial espionage:  The conscious and willful misappropriation of 
trade secrets related to, or included in, a product that is produced for, 
or placed in, interstate or foreign commerce to the economic benefit of 
anyone other than the owner, with the knowledge or intent that the 
offense will injure the owner of that trade secret.9
insider fraud:  An insider’s use of IT for the unauthorized modification, 
addition, or deletion of an organization’s data (not programs or sys-
tems) for personal gain, or theft of information that leads to an identity 
crime (e.g., identity theft, credit card fraud).
insider IT sabotage:  An insider’s use of information technology (IT) to 
direct specific harm at an organization or an individual.
insider theft of intellectual property:  An insider’s use of IT to steal 
 proprietary information from the organization. This category includes 
industrial espionage involving insiders.
6. See www.sans.org/resources/idfaq/integrity_checker.php for a discussion of file integrity checkers.
7. Wikipedia
8. This definition comes from the Secret Service Web site: www.secretservice.gov/criminal.shtml.
9. See www.ncix.gov/publications/reports/fecie_all/fecie_2007/FECIE_2007.pdf.

Glossary of Terms
354
insider trading:  The trading of a corporation’s stock or other securities 
(e.g., bonds or stock options) by individuals with potential access to 
nonpublic information about the company.10
intellectual property:  Intangible assets created and owned by an 
 organization that are critical to achieving its mission.11
Internet relay chat (IRC) channel:  Functionally similar to a multiuser 
chat instance.
Internet underground:  A collection of individuals with shared goals 
where there is some degree of hierarchical structure and the primary 
communication mechanism or agent of electronic crime involves the 
Internet. Further, it may demonstrate some degree of pseudoanonym-
ity and/or secrecy, which may be useful for organizing and carrying 
out electronic crimes.
IT sabotage:  See insider IT sabotage.
keystroke logger (or key logger):  A hardware or software device that 
records the exact keystrokes entered into a computer system.
least privilege:  Authorizing people only for the resources needed to do 
their job.
logic bomb:  Malicious code implanted on a target system and configured 
to execute after a designated period of time or on the occurrence of a 
specified system action.
malicious code:  See malware.
malicious insider threat:  A current or former employee, contractor, 
or business partner who has or had authorized access to an orga-
nization’s network, system, or data and intentionally exceeded or 
misused that access in a manner that negatively affected the confi-
dentiality, integrity, or availability of the organization’s information 
or  information systems.
malware:  Code intended to execute a malicious function. Also commonly 
referred to as malicious code.
national security espionage:  The act of obtaining, delivering, transmit-
ting, communicating, or receiving information about the national 
defense with an intent, or reason to believe, that the information 
10. Wikipedia
11. While IP does not generally include individuals’ Personally Identifiable Information (PII), which 
an organization does not own, it could include a database that the organization developed that 
contains PII.

Glossary of Terms
355
may be used to the injury of the United States or to the advantage of 
any  foreign nation. Espionage is a violation of 18 United States Code 
 sections 792–798 and Article 106, Uniform Code of Military Justice.12
network probing:  Any number of practices in which a particular  network 
is either passively surveilled or actively scanned.
network sniffer (also known as a sniffer):  A computer program or a 
piece of hardware that can intercept and log traffic passing through a 
network.
nonrepudiation:  Ability to verify a particular user is accessing a  system 
or performing a particular action; the goal being to make it more 
 difficult for a user to hide illicit activity.
password cracker:  A program used to identify passwords to a  computer 
or network resource; used to obtain passwords for other employee 
accounts.
personal predisposition:  A characteristic historically linked to a propen-
sity to exhibit malicious insider behavior.
privileged users:  Users who have an elevated level of access to a 
 network, computer system, or application that is short of full system 
administrator access. For example, database administrators (DBAs) 
are privileged users because they have the ability to create new user 
accounts and control the access rights of users within their domain.
proxies:  A proxy server, more commonly known as a proxy, is a server 
that routes network traffic through itself, thereby masking the  origins 
of the network traffic.
remote network administration tools:  Tools to allow the  administration of 
a computer from a location other than the  computer being  administered.
removable media:  Computer storage media that is designed to be 
removed from the computer without powering the computer off. 
Examples include CDs, USB flash drives, and external hard disk drives.
role-based access:  Access required by a person’s duties. Typically, a 
person’s access to data/systems should be no greater than what is 
required of the person’s role.
rootkit:  Software that enables continued privileged access to a computer 
while actively hiding its presence from administrators by subverting 
standard operating system functionality or other applications.
12. Dictionary of Military and Associated Terms. U.S. Department of Defense, 2005.

Glossary of Terms
356
separation of duties:  The separation of tasks among various individuals.
shared account:  An account used by two or more people.
social engineering:  A nontechnical form of intrusion that relies  heavily 
on human interaction and often involves tricking other people to break 
normal security procedures.13
Software Development Life Cycle (SDLC):  Synonymous with “software 
process” as well as “software engineering,” it is a structured method-
ology used in the development of software products and packages. 
This methodology is used from the conception phase through to the 
delivery and end of life of a final software product.14
software keystroke logger:  A software-based method of recording key-
strokes entered from a keyboard.
stressful events:  Events that may cause concerning behaviors in individ-
uals predisposed to malicious acts.
system dynamics:  An approach to understanding the behavior of 
 complex systems over time. It deals with internal feedback loops and 
time delays that affect the behavior of the entire system.15
technical precursor:  An individual action, event, or condition that 
involves computer or electronic media and that precedes and is 
 associated with malicious insider activity.
theft of intellectual property:  See insider theft of intellectual property.
thin client:  A computer that does not run programs or store data itself, 
but accesses programs and data over a network from a central 
 computer server.
TIFF images:  Tagged Image File Format (or .tif) is a file type often used in 
image-manipulation programs.
trusted business partner (TBP):  Any external organization or individual 
an organization has contracted to perform a service for the organiza-
tion. The nature of this service requires the organization to provide the 
TBP authorized access to proprietary data, critical files, and/or inter-
nal infrastructure. For example, if an organization contracts with a 
company to perform billing services, it would have to provide access 
13. Whatis.com
14. Webopedia
15. MIT System Dynamics in Education Project (SDEP)

Glossary of Terms
357
to its customer data, thereby establishing a trusted business partner-
ship. However, the TBP concept does not include cases in which the 
organization is simply a customer of another company. For example, 
when an organization uses a bank, it is simply a client of the bank. 
This customer–vendor relationship would not be considered a TBP 
 relationship.
two-person rule:  A control mechanism that requires the involvement of 
two persons for a particular operation (adapted from Wikipedia).
unintentional insider threat:  An insider who accidently affects the 
 confidentiality, availability, or integrity of an organization’s informa-
tion or information systems, possibly by being tricked by an outsider’s 
use of social engineering.
unmet expectation:  An unsatisfied assumption by an individual that an 
organization action or event will (or will not) happen, or a condition 
will (or will not) exist.
victim organization:  An organization that is negatively impacted by 
an incident.
virtual private network (VPN):  A virtual network, built on top of 
 existing physical networks, that provides a secure communications 
tunnel for data and other information transmitted between networks 
(NIST SP 800-46).
VPN token:  A device, possibly physical, that an authorized user of the 
VPN is given to ease authentication.
watermarking:  See Digital Watermarking.

This page intentionally left blank 

359
References
[1] URLs are valid as of the publication date of this book.
[2] AICPA 2002 American Institute for CPA. Consideration of Fraud in a 
Financial Statement Audit (AU 316.02). American Institute for CPA, 
2002; www.aicpa.org/Research/Standards/AuditAttest/Download 
ableDocuments/AU-00316.pdf.
[3] Alberts 2003 C. Alberts and A. Dorofee. Managing Information  Security 
Risks: The OCTAVE® Approach (Boston: Addison-Wesley, 2003).
[4] Andersen 2004 D.F. Andersen, D.M. Cappelli, J.J. Gonzalez, 
M.  Mojtahedzadeh, A.P. Moore, E. Rich, J.M. Sarriegui, T.J.  Shimeall, 
J.M. Stanton, E. Weaver, and A. Zagonel. “Preliminary System  Dynamics 
Maps of the Insider Cyber-Threat Problem.” In Proceedings of the 22nd 
International Conference of the System Dynamics Society, July 2004.
[5] Band 2006 S.R. Band, D.M. Cappelli, L.F. Fischer, A.P. Moore, 
E.D. Shaw, and R.F. Trzeciak. “Comparing Insider IT Sabotage and 
Espionage: A Model-Based Analysis.” Software Engineering Institute 
Technical Report CMU/SEI-2006-TR-026, Carnegie Mellon University, 
December 2006; www.cert.org/archive/pdf/06tr026.pdf.
[6] Cappelli 2006 D.M. Cappelli, A.G. Desai, A.P. Moore, T.J. Shimeall, 
E.A. Weaver, and B.J. Willke. “Management and Education of the Risk 
of Insider Threat (MERIT): System Dynamics Modeling of Computer 
System Sabotage.” In Proceedings of the 24th International Conference of 
the System Dynamics Society, July 2006.

[7] Cappelli 2007 D.M. Cappelli, A.G. Desai, A.P. Moore, T.J. Shimeall, 
E.A. Weaver, and B.J. Willke. “Management and Education of the 
Risk of Insider Threat (MERIT): Mitigating the Risk of Sabotage to 
Employers’ Information, Systems, or Networks.” Software Engineering 
Institute Technical Note CMU/SEI-2006-TN-041, March 2007; www.sei
.cmu.edu/reports/06tn041.pdf.
[8] Cappelli 2008a D.M. Cappelli, T. Caron, R.F. Trzeciak, and A.P. Moore. 
“Spotlight On: Programming Techniques Used as an Insider Attack 
Tool.” Joint CyLab (CMU) and CERT (SEI) Report, December 2008; www
.cert.org/archive/pdf/insiderthreat_programmers_1208.pdf.
[9] Cappelli 2008b D.M. Cappelli, A.P. Moore, R.F. Trzeciak, and 
T.J. Shimeall. “Common Sense Guide to Prevention and Detection 
of Insider Threats: 3rd Edition.” Joint CyLab (CMU) and CERT (SEI) 
Report, September 2008 (updated from July 2006 and April 2005); 
www.cert.org/archive/pdf/CSG-V3.pdf.
[10] Cone 2006 B.D. Cone, M.F. Thompson, C.E. Irvine, and T.D. Nguyen. 
“Cyber Security Training and Awareness Through Game Play.” In IFIP 
International Federation for Information  Processing, Volume 201, Security and 
Privacy in Dynamic Environments; S. Fischer- Hubner, K.  Rannenberg, 
L. Yngstrom, and S. Lindskog, Eds. (Boston: Springer, 2006), pp. 431–436.
[11] Cordova 1996 D.I. Cordova and M.R. Lepper. “Intrinsic Motivation 
and the Process of Learning: Beneficial Effects of  Contextualization, 
Personalization, and Choice.” Journal of Education Psychology 88: 
pp. 715–730, 1996.
[12] Cressey 1974 D.R. Cressey. Other People’s Money: A Study in the Social 
Psychology of Embezzlement (Montclair, NJ: Patterson Smith, 1972).
[13] CSO 2011a CSO Magazine, Secret Service, Software  Engineering 
Institute CERT Program at Carnegie Mellon University, and Deloitte. 
2011 CyberSecurity Watch Survey: Press Release, January 2011; www
.cert.org/archive/pdf/CyberSecuritySurvey2011.pdf.
[14] CSO 2011b CSO Magazine, Secret Service, Software Engineering 
Institute CERT Program at Carnegie Mellon University, and Deloitte. 
2011 CyberSecurity Watch Survey: Data, January 2011; www.cert.org/
archive/pdf/CyberSecuritySurvey2011Data.pdf.
[15] Duran 2009 F.A. Duran, S.H. Conrad, G.N. Conrad, D.P. Duggan, 
and E.B. Held. “Building a System for Insider Security.” IEEE Security 
and Privacy, pp. 30–38, November/December 2009.
References
360

References
361
[16] Foroughi 2008 F. Foroughi. “The Application of System Dynamics for 
Managing Information Security Insider-Threats of IT  Organization.” 
In Proceedings of the World Congress on Engineering 2008, Vol. I, WCE 
2008, July 2–4, 2008, London, U.K.
[17] Forrester 1994 J.W. Forrester. “Learning through System  Dynamics 
as Preparation for the 21st Century.” Keynote address for Systems 
 Thinking and Dynamic Modeling Conference for K–12 Education, 1994.
[18] Gonzalez 2003 J.J. Gonzalez, Ed. From Modeling to Managing Security: 
A System Dynamics Approach. Vol. 35, Research Series (Kristiansand, 
Norway: Norwegian Academic Press, 2003).
[19] Greitzer 2008 F.L. Greitzer, A.P. Moore, D.M. Cappelli, D.H. Andrews, 
L.A. Carroll, and T.D. Hull. “Combating the Insider Cyber Threat.” 
IEEE Security and Privacy 6(1): January/February 2008.
[20] Groessler 2004 A. Groessler. “Don’t Let History Repeat Itself – 
Methodological Issues Concerning the Use of Simulators in 
Teaching and Experimentation.” System Dynamics Review 20(3): 
pp. 263–274, 2004.
[21] Hanley 2009 M. Hanley, A.P. Moore, D.M. Cappelli, and 
R.F. Trzeciak. “Spotlight On: Malicious Insiders with Ties to 
the Internet Underground Community.” Joint CyLab (CMU) and 
CERT (SEI) Report, March 2009; www.cert.org/archive/pdf/
CyLab%20Insider%20Threat%20Quarterly%20on%20Internet%20
 Underground%20-%20March%202009P.pdf.
[22] Hanley 2010 M. Hanley. “Candidate Technical Controls and 
 Indicators of Insider Attack from Socio-Technical Models and Data.” 
In Proceedings of the 2010 NSA Center of Academic Excellence (CAE) Work-
shop on Insider Threat, November 2010 (also published as SEI Technical 
Note CMU/SEI-2011-TN-003, January 2011).
[23] Hanley 2011a M. Hanley, J. Montelibano. “Insider Threat Control: 
Using Centralized Logging to Detect Data Exfiltration Near Insider 
Termination.” SEI Technical Note CMU/SEI-2011-TN-024, Software 
Engineering Institute, Carnegie Mellon University,   October 2011.
[24] Hanley 2011b M. Hanley, T. Dean, W. Schroeder, M. Houy, 
R. F. Trzeciak, and J. Montelibano. “An Analysis of Technical 
 Observations in Insider Theft of Intellectual Property Cases.” SEI 
Technical Note CMU/SEI-2011-TN-006, Software Engineering Institute, 
 Carnegie Mellon University, 2011.

References
362
 

References
363
information system.” In Proceedings of the 21st International Conference 
of the System Dynamics Society, New York City, July 20–24, 2003.
[35] Montelibano 2011 J. Montelibano. “Insider Threat Control: Using 
a SIEM Signature to Detect Potential Precursors to IT Sabotage.” 
CERT Program Technical Report, SEI Technical Note CMU/SEI-2011-TN-
021, Software Engineering Institute, Carnegie Mellon University, 
April 2011.
[36] Moore 2006 A.P. Moore and R.S. Antao. “Improving Management of 
Information Technology: System Dynamics Analysis of IT Controls 
in Context.” In Proceedings of the 24th International System Dynamics 
 Conference, July 2006.
[37] Moore 2007 A.P. Moore, D.M. Cappelli, H. Joseph, and R.F. Trzeciak. 
“An Experience Using System Dynamics to Facilitate an Insider 
Threat Workshop.” In Proceedings of the 25th International Conference of 
the System Dynamics Society, July 2007; www.cert.org/archive/pdf/
ISDC2007.pdf.
[38] Moore 2008 A.P. Moore, D.M. Cappelli, and R.F. Trzeciak. “The ‘Big 
Picture’ of Insider IT Sabotage Across U.S. Critical Infrastructures.” 
In Insider Attack and Cyber Security: Beyond the Hacker. S.J. Stolfo et al., 
Eds., Springer Science + Business Media, LLC, 2008 (also published in 
SEI Technical Report - CMU/SEI-2008-TR-009); www.cert.org/archive/
pdf/08tr009.pdf).
[39] Moore 2009 A.P. Moore, D.M. Cappelli, T. Caron, E. Shaw, and 
R.F. Trzeciak. “Insider Theft of Intellectual Property for Business 
 Advantage: A Preliminary Model.” In Proceedings of the 1st  International 
Workshop on Managing Insider Security Threats (MIST2009), Purdue 
University, West Lafayette, IN, June 16, 2009; www.cert.org/insider_
threat/docs/Insider_Theft_of_IP_Model_MIST09.pdf.
[40] Moore 2011a A.P. Moore, D.M. Cappelli, T. Caron, E. Shaw, and 
R.F. Trzeciak. “A Preliminary Model of Insider Theft of Intellectual 
 Property.” Journal of Wireless Mobile Networks, Ubiquitous Computing, 
and Dependable Applications 2(1), Special Issue: Addressing Insider 
Threats and Information Leakage, 2011, pp. 28–49 (also published as 
SEI Technical Note CMU/SEI-2011-TN-013).
[41] Moore 2011b A.P. Moore, A. Cummings, and D. Spooner. “ Modeling 
and Analysis of Insider Fraud.” In 2010 CERT Research Annual 
Report, 2011.

References
364
[42] Phelps 2006 D. Phelps and J. Gathegi. “Information Security 
 Self-Efficacy.” In Proceedings of the 2006 Americas Conference on 
 Information Systems (AMCIS 2006), Acapulco, Mexico, August 2006.
[43] Randazzo 2004 M.R. Randazzo, M.M. Keeney, E.F. Kowalski, 
D.M. Cappelli, and A.P. Moore. “Insider Threat Study: Illicit Cyber 
 Activity in the Banking and Finance Sector.” Joint SEI and U.S. 
Secret Service Report, August 2004; www.secretservice.gov/ntac/its_
report_040820.pdf.
[44] Repenning 2001 N. Repenning and J.D. Sterman. “Nobody Ever 
Gets Credit for Fixing Problems That Never Happened: Creating 
and  Sustaining Process Improvement.” California Management Review 
43(4): pp. 64–88, 2001.
[45] Ricci 1996 K. Ricci, E. Salas, and J.A. Cannon-Bowers. “Do computer 
based games facilitate knowledge acquisition and retention?” Military 
Psychology 8(4): pp. 295–307, 1996.
[46] Rich 2005 E. Rich, I.J. Martinez-Moyano, S. Conrad, D.M.  Cappelli, 
A.P. Moore, T.J. Shimeall, D.F. Andersen, J.J. Gonzalez, R.J.  Ellison, 
H.F.  Lipson, D.A. Mundie, J.M. Sarriegui, A. Sawicka, T.R.  Stewart, 
J.M.  Torres, E.A. Weaver, and J. Wiik. “Simulating Insider 
 Cyber-Threat Risks: A Model-Based Case and a Case-Based Model.” 
In Proceedings of the 23rd International Conference of the  System 
Dynamics Society, July 2005; www.cert.org/insider_threat/docs/
insider_threatISDC2005.pdf.
[47] Spooner 2008 D. Spooner, D.M. Cappelli, A.P. Moore, and 
R.F. Trzeciak. “Spotlight On: Insider Theft of Intellectual Property 
inside the U.S. Involving Foreign Governments or Organizations.” 
Joint CyLab (CMU) and CERT (SEI) Report, December 2008; www.cert.
org/archive/pdf/insiderthreat_programmers_1208.pdf.
[48] Sterman 2000 J.D. Sterman. Business Dynamics: Systems Thinking and 
Modeling for a Complex World (McGraw-Hill, 2000).
[49] Weiland 2010 R.M. Weiland, A.P. Moore, D.M. Cappelli, R.F. Trzeciak, 
and D. Spooner. “Spotlight On: Insider Threat from Trusted Business 
Partners.” Joint CyLab (CMU) and CERT (SEI) Report,  February 2010; 
www.cert.org/archive/pdf/TrustedBusinessPartners0210.pdf.

365
About the Authors
Dawn Cappelli, CISSP, is technical manager of 
the CERT Insider Threat Center and the Enterprise 
Threat and Vulnerability Management Team at 
Carnegie Mellon University’s Software  Engineering 
Institute. She has devoted the past ten years of her 
career to helping organizations in  government and 
industry to protect themselves from the ultimate 
betrayal of trust: insider threats. She works with 
the Secret Service, U.S. Department of Homeland 
Security, U.S. Department of Defense, and other 
government agencies and  private  organizations. 
She leads a team of more than 30 security analysts who address real-world 
problems by performing modeling and analysis, creating practical  solutions, 
and disseminating solutions broadly to government and industry. Dawn has 
more than 30 years of experience in software engineering, technical project 
management, information security, and research. She is often an invited 
speaker at national and international venues, is adjunct professor in Carnegie 
Mellon’s Heinz College of Public Policy and  Management, and is vice-chair 
for the CERT Computer Security Incident Handler Certification Advisory 
Board. She is on the program committee for several prominent security 
conferences, and was recently awarded the Software Engineering Institute 
Director’s Office Award of Excellence. Before joining CMU in 1988 she worked 
for Westinghouse as a software engineer  developing nuclear power systems. 
She spends every spare moment she can at her cabin in the mountains with 
her family, and volunteers her time for the Friends of Flight 93.

366
About the Authors
Andrew P. Moore is a lead researcher in the CERT 
Insider Threat Center and senior member of the 
technical staff at Carnegie Mellon University’s 
Software Engineering Institute. He explores ways 
to improve the security, survivability, and resiliency 
of enterprise systems through insider threat and 
defense modeling, incident management, and 
architecture engineering and analysis. Andy also 
works with teams across the SEI applying modeling 
and simulation techniques to hard system and 
software engineering problems. Before joining 
the SEI in 2000, he worked for the Naval Research Laboratory (NRL) 
investigating high-assurance system development methods for the U.S. 
Navy. He has more than 20 years of experience developing and applying 
mission-critical system analysis methods and tools, leading to the transfer 
of critical technology to both industry and the military. Andy has served as 
principal investigator on numerous projects sponsored by NSA and DARPA; 
has served on numerous computer assurance and security conference 
program committees and working groups; and has published two book 
chapters and a wide variety of technical journal and conference papers. 
His research interests include computer and network attack modeling and 
analysis, IT management control analysis, survivable systems engineering, 
formal assurance techniques, and security risk management. Andy received 
a master’s degree in computer science from Duke University, a bachelor’s 
degree in mathematics from the College of Wooster, and a graduate 
certificate in system dynamics from Worcester Polytechnic Institute.
Randall F. Trzeciak is currently the technical 
team lead for the Insider Threat Research Group 
in the CERT Insider Threat Center and senior 
member of the technical staff at Carnegie Mellon 
University’s Software Engineering Institute. The 
team focuses on insider threat research, exploring 
both the technical and nontechnical ways in 
which insiders have harmed organizations; threat 
analysis and modeling; and incident management. 
Prior to joining Carnegie Mellon University 
in 1999, he worked for nine years at Software 
Technology Incorporated in Alexandria, Virginia, supporting multiple 
contracts primarily at the Naval Research Laboratory (NRL), building and 
supporting large-scale information systems. Randy has more than 20 years 
of experience in software engineering; project management; information 

367
About the Authors
security; and database design, development, and maintenance. For more 
than ten years, Randy has been an adjunct faculty member at Carnegie 
Mellon’s Heinz College of Information Systems and Management. He was 
invited to chair the Security and Risk track at the 2012 SEPG Conference. 
Randy regularly represents the Insider Threat Center by speaking at security 
conferences around the United States and has also spoken internationally. 
Randy holds a master’s degree in management from the University of 
Maryland, and bachelor’s degrees in management information systems 
and business administration from Geneva College.

This page intentionally left blank 

369
A
Acceptable use policies for sabotage, 42, 48
Acceptable workplace behavior, 168
Access and access controls
Ambitious Leader model, 80–81
description, 179
erosion of, 71, 189
fraud, 125
Internet underground, 291–292
logs, 172–173
remote, 90–92, 200–201
SDLC, 132–133
separation of duties and least privilege, 
178–181
source code, 131, 142
system change controls, 193
after termination, 203–206
Access paths
eliminating, 50–52
sabotage, 40–45
Access rights management, 284
Accomplices
fraud, 103, 121, 269
information collection on, 328
theft of IP, 86
Accountability of third-party vendors, 57
Accounts and account management
expiration dates, 234
organized crime, 118
policies and practices, 174–177
for sabotage, 45, 52
terminated employees, 203–204
Accumulation of privileges, 71
ACH (Automated Clearing House) 
system, 276
Index
Active Directory, 234–235, 237
Administrator passwords for unknown 
access paths, 50
Advanced targeting for centralized logging, 
237–238
Aggressive behavior as sabotage 
precursor, 36
Agreements, IP, 157, 168–169
Agricultural products firm fraud case, 
266–267
Alarms, 172
Alerts, prioritizing, 53–54
Ambitious Leader model
access, 80–81
organization discovery of theft, 81
overview, 78–79
risk assessment, 81–83
theft of IP, 64, 68–70
theft planning, 79–80
American Institute for Certified Public 
Accountants, 108
“Analysis of Technical Observations in 
Insider Theft of Intellectual Property 
Cases,” 216
Annual Report to Congress on Foreign 
Economic Collection and Industrial 
Espionage, FY07, 83
Anonymous remailer fraud, 109
Anti-spam blacklists, 26
ArcSight environment, 223, 228, 230
Arrests history in background checks, 164
Arrows in system dynamics  
modeling, 347
Assessment, risk and threat, 81–83, 151–154, 
304–305

Index
370
Attachments
detecting, 235–236
fraud case, 109, 265–266
large, 77, 93, 197
logging, 233–234
theft of IP, 81, 89, 95
Attribution in SDLC, 137
Audits
critical and irregular processes, 120–121
database transactions, 123
employee online actions, 195–199
HTTPS traffic, 66
passwords and account management, 175
for sabotage, 24
Authentication
multifactor, 172
SDLC, 132–133
social engineering, 126
unauthorized credentials, 141, 271
Authenticity, digital watermarking for, 65
Author biographies, 365–367
Authorization
Ambitious Leader model, 80–81
DNS registration, 291
maintaining, 185
online, 179
organized crime, 118
remote access, 200
SDLC, 130
updating, 56
Authorized system overrides
SDLC, 132
system design, 183
Auto parts manufacturer theft of IP case, 262
Automated Clearing House (ACH) 
system, 276
Automation
backdoor account detections, 195
centralized logging, 237–238
email for access control, 71
integrity checking, 134, 195
limitations, 14
separation of duties in, 131
system change controls monitoring, 193
Availability
SDLC, 130
threats impact on, 152
B
Backdoors
automated detection, 195
government theft of IP cases, 260–261
Internet underground, 290
logistics company sabotage case, 256
privileges, 175–176
remote attacks, 201–202
sabotage, 24, 40, 44–45
SDLC, 136, 184
terminated employees, 203
Background checks
financial problems, 124
functions, 164
sabotage, 30–31
subcontractors, 166–167
Backups
Ambitious Leader model, 82–83
best practices, 207–210
change, 192
fraud case, 268–269
physical protection, 172
sabotage, 24, 40, 44–45, 139, 208, 256
sabotage/fraud case, 258
SDLC, 138–139
single system administrators, 205
testing, 57–59
Badges, 171
Balancing loops in system dynamics 
modeling, 347
Banking and finance industry
case prevalence, 307
foreign theft of IP, 87
fraud cases, 264–265
fraud losses, 104–105
Insider Threat Study, 19
miscellaneous case, 270–271
sabotage cases, 243–245
sabotage/fraud cases, 257
Basic Analysis and Security Engine (BASE) 
user interface, 221
Behavioral concerns
monitoring and responding to, 164–167
sabotage precursors, 35–37
security awareness training for, 159
Beneficiary organizations, 327

Index
371
Benefit disagreements as dissatisfaction 
factor, 73
Best practices
in 2005, 17
backup and recovery processes, 207–210
employee online actions, 195–199
enterprise-wide risk assessments, 151–154
incident response plans, 211–213
monitoring and responding to suspicious 
and disruptive behavior, 164–167
negative workplace issues, 168–170
overview, 145–146
password and account management 
policies and practices, 174–177
physical environment, 171–173
policies and controls, 155–158
remote attacks, 200–202
SDLC, 182–186
security awareness training, 159–163
separation of duties and least privilege, 
178–181
summary, 146–150, 213–214
system administrators and technical and 
privileged users, 187–190
system change controls, 191–194
termination, 203–206
“Big Picture” of Insider IT Sabotage Across 
U.S. Critical Infrastructures, 12
Bizarre behavior as sabotage precursor, 36
Bonus issues
fraud case, 265
policies, 155
sabotage from, 32–34, 158, 189, 244–245, 253
SDLC, 136, 142, 185
British Petroleum Refinery, 335
Business advantage, theft of IP for, 62
Business management training simulation, 
335
Business partners. See Trusted business 
partners (TBPs)
Business plans theft, 95
C
Cameras
cell phone, 281
closed circuit, 172
Canada, theft of IP in, 85
Cappelli, Dawn
best practices, 145
biography, 365
Internet underground, 286
SDLC, 139
theft of IP, 65, 83
trusted business partners, 276
Caron, Thomas
SDLC, 139
theft of IP threats, 65
Case-based training simulation, 336
Case breakdown
country, 316–317
current employees vs. former, 314
employees vs. contractors, 313
international cases, 315–317
sectors, 307–309
technical vs. nontechnical insiders, 
314–315
trends over time, 312–313
type of crime, 309–312
Case examples, 241
backup and recovery processes, 209–210
employee online actions, 198–199
enterprise-wide risk assessments, 152–154
fraud. See Fraud cases
incident response plans, 212–213
miscellaneous, 269–273
monitoring and responding to suspicious 
and disruptive behavior, 166–167
password and account management 
policies, 176–177
physical environment, 173
policies and controls, 156–158
positive outcomes, 296–297
remote attacks, 201–202
sabotage cases. See Sabotage cases
sabotage/fraud cases, 256–258
SDLC, 185–186
security awareness training, 162–163
separation of duties and least privilege, 
180–181
system administrators and technical and 
privileged users, 189–190
system change controls, 192–194
terminated employees, 205–206

Index
372
Case examples (contd.)
theft of IP. See Theft of IP cases
trusted business partners, 276–277
Categories of threats, 8–9
ccTLD (code top-level domains), 235
CEE (Common Event Expression), 223, 
229–230
CEF (Common Event Format), 223, 228–229
Centralized logging
advanced targeting and automation, 
237–238
appliances, 197
conclusion, 239
overview, 231–233
Splunk rules, 235–237
termination monitoring, 233–235
CERT
insider threat center. See Insider threat 
center
MERIT. See MERIT (Management and 
Education of the Risk of Insider 
Threat) project
Changes
change management software, 53–54
controls, 191–194
in employment status, theft of IP, 98
in policies and controls, sabotage  
from, 35
Changing passwords for sabotage, 42
Characterization of configurations, 191–192
Chemical industry cases, 87, 258–259
China, theft of IP in, 85
Cigarettes, low-nicotine, 345
Citizenship in theft of IP, 85
City government fraud losses, 105
Classified information, theft of, 67
Closed circuit cameras, 172
Code, defined, 326
Code reviews
benefits, 10–11
formal, 142
SDLC, 136–137
Code top-level domains (ccTLD), 235
Coding process
incident data, 329–331
organization data, 327–328
subject data, 328–329
Collection of data, 325–326
Collusion, 1
complexity of, 6
fraud, 111–113, 117, 134–135, 294
SDLC, 183
separation of duties, 179–180
system design, 183
theft of IP, 194
Commercial facilities industry
case prevalence, 308–310
foreign theft of IP, 87
fraud cases, 263, 265–266
sabotage cases, 242, 245
trusted business partner cases, 278
Common Event Expression (CEE), 223, 
229–230
Common Event Format (CEF), 223, 228–229
“Common Sense Guide to Prevention and 
Detection of Insider Threats,” 17
Communication for sabotage, 34
Compensating measures for 
disgruntlement, 49
Competing businesses, foreign theft of IP 
for, 88
Competitors, email to, 77
Complexity of insider threats, 6–7
Compromised accounts in organized 
crime, 118
Compromised passwords in fraud, 125–126
Concealment in theft of IP, 95
Conditional projections, 346
Confidentiality
in reporting, 161
SDLC, 130
threats impact on, 152
training about, 162
Conflicts, sabotage from, 35
Consistency checks in SDLC, 183
Consistent enforcement for sabotage, 34, 168
Conspirators in theft of IP, 86
Consultants
food industry sabotage case, 248
information technology sabotage case, 
250–251
source code modification, 140–142
Consumer credit database fraud case, 264
Contentious employee terminations, 35
Contractors and third parties
background checks, 166–167

Index
373
backups, 57
defense industrial base sabotage case, 246
vs. employees, 313
energy industry sabotage case, 247–248
enterprise-wide risk assessments, 152
fraud cases, 266
government sabotage case, 248–249
government theft of IP cases, 260–261
health care fraud case, 269
kiosk access case, 153
ownership case, 156–157
password and account management 
policies, 175–176
password cracking case, 154
physical security, 173
sabotage, 39, 44–45
theft of IP, 73
unauthorized access case, 272–273
Contracts with trusted business partners, 285
Contribution perception in Entitled 
Independent 
model, 70–72
Controlled information documents, 173
Controls
access. See Access and access controls
best practices, 155–158
change, 191–194
documenting, 155–158
Copied documents as theft of IP indicator, 77
Corporate fraud, 103
Countries
case breakdown by, 316–317
cultural differences, 6
in theft of IP, 85
Coworkers in fraud recruitment, 113–115, 
121–123
Crackers, 40
Credentials
information technology sabotage case, 255
Snort for, 220–221
termination sabotage case, 245
unauthorized, 141
Credit card debt as fraud factor, 109
Credit card number verification program 
case, 255
Credit database fraud case, 264
Credit histories fraud losses, 105
Cressey, Donald, 106
Crime
case breakdown by, 309–312
types, 8–9, 116
Criminal history
in background checks, 164
information technology sabotage case, 
30–31, 255–256
Internet underground, 290
Critical business functions, outsourcing, 152
Critical data modification verification, 123
Critical infrastructure, protecting, 172
Critical processes, auditing, 120–121
Cultural differences in threats, 6
Cummings, Adam, 102
Currency trader case, 180
Current employees vs. former, 314
Custodial staff training, 162–163
Customer records stolen cases, 272
Customer service processes, training for, 
160–161
CyberCIEGE game, 336
CyberSecurity Watch Survey, 319–323
CyLab
fraud modeling, 105
insider threat assessment sponsored by, 
17–18
MERIT InterActive. See MERIT InterActive 
tool
workshops, 17
D
Dashed arrows in system dynamics 
modeling, 347
Data audits, 195
Data collection for database, 325–326
Data integrity in SDLC, 134, 183
Data leakage tools, 65, 77, 197
Data loss prevention (DLP) systems, 65, 77
Database administrators
government sabotage case, 249
Internet underground, 292
privileges, 149
sabotage/fraud case, 257
shared accounts, 44, 52
Database breakdown of cases, 7–9
country, 316–317
current employees vs. former, 314

Index
374
Database breakdown of cases (contd.)
employees vs. contractors, 313
international cases, 315–317
sectors, 307–309
technical vs. nontechnical insiders, 314–315
trends over time, 312–313
type of crime, 309–312
Databases, 325
coding process, 327–331
data collection, 325–326
password cracking case, 154
SIEM analysis, 225–227
transactions auditing, 123
DC (domain controller), 235–236
DC3 (Defense Cyber Crime Conference), 219
Deactivating access after termination, 
203–206
Dean, Tyler, 216
Deception in Entitled Independent model, 
74–78
Defense Cyber Crime Conference  
(DC3), 219
Defense industrial base
foreign theft of IP, 87
fraud cases, 266
sabotage cases, 246–247
theft of IP case, 260
Deleted backups, 58
Demonstrational videos, 218–219
Demotions as sabotage precursor, 38, 56
Denial-of-service attacks, 288
Departing employees. See Termination
Detection
Ambitious Leader model, 81–82
automated, 14, 195
fraud, 127
IDS, 220–221
malicious code, 193
sabotage, 53
trusted business partners, 283–285
Dictionaries in Common Event 
Expression, 229
Digital rights management (DRM), 65
Digital watermarking, 65
Directory services, 234
Disability fraud cases, 105, 267–268
Disabling
known paths, 51–52
remote access, 200–201
system logs, 42
Disagreements as dissatisfaction factor, 73
Discrimination complaint in government 
sabotage case, 249
Disgruntlement issues
defense industrial base sabotage cases, 
246–247
fired employee sabotage case,  
243–244
government case, 271–272
password theft, 176–177
positive intervention for, 49–50
resigned employee case, 169–170
as sabotage factor, 31–34, 37–38, 40–42
system administrators and other 
privileged users, 190
Disposal of controlled information 
documents, 173
Disruption of service in SDLC, 141–142
Disruptive employees
monitoring and responding to, 164–167
as sabotage precursor, 37
Dissatisfaction in Entitled Independent 
model, 72–74
DLP (data loss prevention) systems, 65, 77
DNS
registrations redirection, 291
suffixes, 236
Document imaging company in theft of IP 
case, 96, 261–262
Documentation
policies and controls, 155–158, 161
SDLC, 138
Domain controller (DC), 235–236
Domain names, in sabotage, 26
Doors, locking, 172
Downsizing, sabotage from, 33
Downward spiral situations in sabotage, 42
Driver’s licenses case, 105, 186, 266
DRM (digital rights management), 65
Dynamic trigger hypotheses, 349
E
E-commerce developer in sabotage  
case, 250
Economic espionage, 84

Index
375
Ecuador, theft of IP in, 85
Education industry
foreign theft of IP, 87
miscellaneous case, 271
EEOC complaint in government sabotage 
case, 249
Email
for access control, 71
attachments. See Attachments
eavesdropping case, 270–271
fake addresses cases, 153–154, 266
pornographic images case, 201
Splunk rules, 235–237
theft of IP, 89, 91, 93
theft of IP indicator, 77
Emergency services fraud cases, 266
Employee assistance programs
for disgruntlement, 49
for disruptive employees, 166
for fraud, 124–125
for sabotage, 35, 37
Employees
vs. contractors, 313
disgruntlement. See Disgruntlement issues
online actions best practices, 195–199
protecting, 171
security awareness training for, 159–163
susceptibility to recruitment, 121–123
susceptibility to social engineering, 126
termination. See Termination
Encryption
backups, 58, 208
theft of IP, 95
End user source code access, 131
Energy industry
foreign theft of IP, 87
sabotage case, 247–248
Enforcement of policies in sabotage, 34, 168
Engineers, theft of IP by, 63, 85
Enterprise-wide risk assessments, 151–154
Entertainment Technology Center (ETC), 
18, 336
Entitled Independent model in theft of IP
contribution perception in, 70–72
deception, 74–78
dissatisfaction, 72–74
overview, 68–70
threats, 64
Erosion of access controls, 71, 189
Espionage
foreign governments and organizations, 84
prevalence, 8
ETC (Entertainment Technology Center), 
18, 336
Event correlation engines, 93, 197
Events
MERIT InterActive, 338–339
SIEM signature, 228–230
Exception handling
SDLC, 132, 135
system design, 183
Excessive access privileges, 125
Expectations
policies and controls for, 156
setting, 47–49
unmet. See Unmet expectations
Expedite function in SDLC, 135
Expiration dates of accounts, 234
External hard disks for theft of IP, 94
External organizations
attacks against, 196
email to, 77
External partners. See Trusted business 
partners (TBPs)
Extortion
manufacturing plant case, 212–213
two-person rule for, 44
F
Fake email addresses, 153–154, 266
Fake vendor fraud losses, 105
FCI (Force Concept Inventory), 335
Federal Bureau of Investigation (FBI) 
organized crime definition,  
115–116, 286
Federal Network Security (FNS) branch, 17
Federally Funded Research and 
Development Center (FFRDC), 219
Feedback loops in system dynamics 
modeling, 347–348
File integrity checkers, 191
File transfer, 90–91
File Transfer Protocol (FTP), 90
Finance industry. See Banking and finance 
industry

Index
376
Financial compensation as dissatisfaction 
factor, 73
Financial gain as motive, 139
Financial impact
Ambitious Leader model, 78
fraud, 103–105
theft of IP, 67
Financial problems
in background checks, 165
fraud from, 111, 124–125
non-sharable, 106
FIRST (Forum of Incident Response and  
Security Teams), 219
Flagging database transactions, 123
Flood control, 345
FNS (Federal Network Security)  
branch, 17
Food industry
fraud cases, 266–267
sabotage case, 248
Force Concept Inventory (FCI), 335
Foreign-currency trader fraud  
case, 265
Foreign governments and organizations
Ambitious Leader model, 78
theft of IP, 67, 83–88, 261–262
threat complexity, 7
Foreign nationals asylum case, 181, 267
Formal code reviews, 142
Former employees vs. current, 314
Forum of Incident Response and Security 
Teams (FIRST), 219
Fraud
auditing for, 120–121
continuing, 110–111
defined, 101
description, 4
excessive access privileges, 125
financial problems, 124–125
impacts, 103, 105
insider stressors, 115
models, 13
organizational issues, 120–126
organized crime, 115–119
origins, 108–110
outsider facilitation, 111–113
overview, 101–106
patterns, 106–108
perpetrator characteristics, 1
recruiting others, 113–115, 121–123
trusted business partners, 279–280
verification of modification of critical 
data, 123
Fraud cases, 4–5, 262–263
banking and finance industry, 264–265
commercial facilities industry, 263,  
265–266
defense industrial base, 266
emergency services, 266
food industry, 266–267
government, 267–269
health care industry, 166, 269
lottery agency, 212
positive outcome, 296–297
prevalence, 8, 310–312
Fraud Triangle, 106–108
From Modeling to Managing Security: A 
System Dynamics Approach, 349
FTP (File Transfer Protocol), 90
Full disclosure by third-party vendors, 57
G
Games. See MERIT InterActive tool
GFIRST (Government Forum of Incident 
Response and Security Teams), 219
Globalization issues, 176
Glossary of terms, 351–357
Gmail accounts as theft of IP indicator, 77
Gonzalez, Jose, 349
Government
case prevalence, 308–309
defense industrial base sabotage cases, 
246–247
espionage, 84
fake email addresses case, 153–154
foreign theft of IP, 87
fraud, 104–105, 267–269
miscellaneous case, 271–272
sabotage cases, 248–250
theft of IP cases, 260–261
Government Forum of Incident Response 
and Security Teams (GFIRST), 219
Group modeling, 349
Guards

Index
377
for deterrence, 171
security awareness training for, 162–163
H
Hanley, Michael
insider threat lab, 216
Internet underground, 286
Hazardous material sector, 87
Headers in Common Event Format, 228
Health industry
case prevalence, 308
claims fraud case, 166, 269
foreign theft of IP, 87
Help desk fraud cases, 266
High-priority mitigation strategies, 219–220
Hiring process, 164
Host data exfiltration, 93–95
Hostile work environments
case study, 169–170
dissatisfaction factor, 73
Hotmail accounts as theft of IP indicator, 77
Houy, Matt, 216
HTTPS traffic, 66
Human resources (HR) department
account expiration dates, 234
for disgruntlement, 49
MERIT InterActive, 337, 339
for sabotage, 39
I
IDC (Interactive Data Corporation) 
survey, 278
Identity crimes. See also Personally 
Identifiable Information (PII)
defined, 101
prevalence, 113–114
Identity management systems, 24
IDS (intrusion detection system),  
220–221
Immigration asylum case, 181, 267
Impacts, 152
Ambitious Leader model, 78
fraud, 103–105
SDLC, 130
theft of IP, 66–68
Implementation in SDLC, 183–184
Incident data in coding process, 329–331
Incident management process, 124
Incident response plans, 211–213
Inconsistent enforcement of policies, 
sabotage from, 34, 168
Industrial espionage, 84
Information and telecommunications 
industry
case prevalence, 307–309
foreign theft of IP, 86
Information overload, 196, 198
Information technology departments, 
MERIT InterActive for, 337
Information technology industry cases
miscellaneous, 272–273
sabotage, 250–256
sabotage/fraud, 257–258
theft of IP, 261–262
Infrastructure
insider threat lab, 217–218
protecting, 172
Insider and Cyber Security: Beyond the 
Hacker, 23
Insider threat assessment in 2007, 18
Insider threat center, 3
exercises, 303–304
objectives, 13–14
products and services, 299–301
sponsored research, 306
teams, 15
threat assessment, 304–305
workshops, 301–303
Insider threat exercises in 2010, 18–19
Insider threat lab, 15–16
in 2009, 18
centralized logging. See Centralized 
logging
demonstrational videos, 218–219
exercises, 239
high-priority mitigation strategies, 
219–220
infrastructure, 217–218
overview, 215–216
purposes, 216–217
SIEM signature. See Security Information 
and Event Management (SIEM) 
signature

Index
378
Insider threat lab (contd.)
SiLK tool, 221–223
Snort tool, 220–221
Insider Threat Outreach and Transition 
Team, 15–16
Insider threat research in 2000, 16
Insider Threat Research Team, 15
Insider Threat Study (ITS)
in 2001, 16
banking and finance sector, 19
fraud modeling, 105
profiles from, 11
Insider trading, 103
Installation in SDLC, 184
Insurance fraud case, 166, 269
Integrity
SDLC, 130
threats impact on, 152
training on, 162
Integrity checks
automated, 134, 195
database transactions, 123
SDLC, 134
Intellectual property agreements, 157, 
168–169
Intellectual property theft. See Theft of 
intellectual property (IP)
Interactive Data Corporation (IDC) 
survey, 278
Interactive virtual simulation tool. 
See MERIT InterActive tool
International cases, 315–317
International Traffic in Arms 
Regulations, 67
Internet Relay Chat (IRC) channels, 255
Internet service providers (ISPs) cases
customer information, 220–221
sabotage, 251–252, 255–256
source code modification, 140
threatening email, 176
Internet underground threats
access controls and monitoring, 291–292
complexity of, 7
conclusions, 293
crimes, 288–289
insider characteristics, 287
insider involvement, 288
overview, 286–287
sabotage cases, 245, 251–252
sabotage/fraud case, 257
unknown access paths, 289–291
Intrusion detection system (IDS), 220–221
Inventory control, 94
IRC (Internet Relay Chat) channels, 255
Irregular processes, auditing, 120–121
ISPs. See Internet service providers (ISPs) 
cases
ITS. See Insider Threat Study (ITS)
J
Job performance declines as sabotage 
precursor, 35
Job responsibilities descriptions, 49
Journal of Wireless Mobile Networks, 
Ubiquitous Computing, and Dependable 
Applications, 65
K
Key-value pairs in Common Event 
Format, 228
Keystroke loggers
fraud cases, 109, 265–266
system change control cases, 194
theft of IP, 160
King, Christopher, 116
Kiosk access case, 153
Known-bad domain names, 235
L
Laptops for theft of IP, 90–91
Large attachments as theft of IP indicator, 77
Last days of employment
centralized logging. See Centralized 
logging
precautions, 98
theft of IP, 76, 95, 98
Lax overtime controls, 185
Layered defense for remote attacks, 200–202
LDAP directory service, 234
Least privilege best practices, 178–181
Legal firm theft of IP case, 261–262
Legal issues, 152

Index
379
Lessons learned step for financial 
problems, 124
Limiting accounts, 45
Loan officer fraud case, 264
Locking doors and windows, 172
Logic bombs
defense industrial base sabotage case, 
246–247
description, 9
government sabotage case, 248–249
information technology sabotage case, 
252–253
placement, 53
positive outcome case, 25, 297
SDLC case, 185–186
system administrator case, 189, 244–245
system change controls, 193
unmet expectations, 33
Logistics company sabotage case, 256
Logs and logging
access, 172–173
centralized. See Centralized logging
change, 192
Common Event Expression, 229
employee online actions, 195–199
reviewing, 166
sabotage, 37, 42, 56–57
SDLC, 137
theft of IP, 93, 95
Loops in system dynamics modeling, 
347–348
Lottery
fraud case, 212, 268–269
fraud losses, 105
Low-nicotine cigarettes, 345
Lower-level employees, 104–105
M
Macro-lab, 218
MAILHOST server, 235–236
Maintenance phase in SDLC, 136
Malicious activity in system design, 183
Malicious code
description, 10
expected bonus sabotage case, 244–245
fraud case, 265–266
information technology sabotage case, 
252–253
network manager sabotage case, 244
unauthorized access case, 271
Management and Education of the Risk of 
Insider Threat (MERIT) project, 9
development of, 17
insider threat models, 9–12, 27
Managers as organized crime 
participants, 117
Manufacturing sector
extortion case, 212–213
foreign theft of IP, 87
terminated employee case, 205
Market trend product analysis organization 
sabotage case, 253–254
Meadows, Dennis, 346
Media
backups, 208
theft of IP, 62, 90, 94
Mergers and acquisitions
complexity of, 6
as dissatisfaction factor, 73
MERIT (Management and Education of the 
Risk of Insider Threat) project, 9
development of, 17
insider threat models, 9–12, 27
MERIT InterActive tool, 18
conclusion, 343
effectiveness, 334–336
overview, 333–334
prototype, 336–340
stages, 339–342
Micro-lab, 217–218
Military equipment fraud losses, 105
MIS Training Institute InfoSec World, 219
Miscellaneous cases, 8, 269–273
Missing work as sabotage precursor, 35
Mitigation strategies
insider threat lab, 219–220
SDLC, 142
theft of IP, 88–97
trusted business partners, 283–285
Modification
fraud cases, 110–111
production source code and scripts, 
140–142
verifying, 123

Index
380
Monitoring
employee online actions, 195–199
Internet underground, 291–292
network traffic for sabotage, 51
strategies, 52–53
suspicious and disruptive behavior, 
164–167
targeted, 55
termination, 233–235
for theft of IP, 95
trusted business partners, 284
Montelibano, Joji, 216
Monthly auditing, 196
Mood swings as sabotage precursor, 36
Moore, Andrew P.
best practices, 145
biography, 366
fraud modeling, 102
Internet underground, 286
SDLC, 139
theft of IP, 65, 83
trusted business partners, 276
Motives
Ambitious Leader model, 79
foreign theft of IP, 88
Internet underground insiders, 287
organized crime, 118
SDLC, 139
Moves in MERIT InterActive, 338
Multiple roles in fraud cases, 267–268
N
National Threat Assessment Center 
(NTAC), 16
Negative influences in system dynamics 
modeling, 347
Negative workplace issues
managing, 168–170
sabotage from, 35
trusted business partners, 284–285
Network sniffers, 221, 255, 304
Networks
information technology sabotage case, 
252–253
kiosk access case, 153
monitoring, 51
sabotage, 41
theft of IP, 90–93
Nigerian Mafia, 122
911 system case, 209, 254
NOC system administrators sabotage 
case, 254
Non-sharable financial problems, 106
Noncompete agreements, 168–169
Nonpublic sources of information, 326
Nonrepudiation techniques
benefits, 187
for sabotage, 42–43
Nontechnical employees, insider theft 
discovered by, 74
Nontechnical insiders vs. technical, 314–315
NTAC (National Threat Assessment 
Center), 16
Ntop tool, 304
O
OCTAVE (Operationally Critical Threat, 
Asset, and Vulnerability Evaluation) 
technique, 195
Office of National Counterintelligence 
Executive, 83
Office trash, 173
One-month termination window
centralized logging, 233–237
precautions, 98
theft of IP, 76, 95, 98
Online actions best practices, 195–199
Operationally Critical Threat, Asset, and 
Vulnerability Evaluation (OCTAVE) 
technique, 195
Opportunity in Fraud Triangle, 106–107
Organization data coding process, 327–328
Organization-issued badges, 171
Organizational issues in fraud, 120–126
Organized crime, 286–287
fraud, 115–119
malicious insiders, 116–117
methods, 118–119
motives, 118
participants, 117
prevalence, 116
targets, 118

Index
381
Origins of fraud, 108–110
Outreach and Transition Team, 15–16
Outsider facilitation of fraud, 111–113
Outsourcing
critical business functions, 152
and password and account management 
policies, 176
Overtime, lax controls on, 185
Ownership disagreements, 73, 156–157
P
Packet sniffers, 221, 255, 304
Partners. See Trusted business partners 
(TBPs)
Password cracking, 40, 154
Password-protected screen savers, 172
Passwords, 42
auditing, 44
customer records stolen cases, 272
food industry case, 266–267
fraud, 125–126
government case, 271–272
information technology sabotage case, 255
policies and practices, 45, 174–177
student unauthorized access case, 271
system administrator termination 
sabotage case, 245
withheld pay case, 152–153
Patterns
fraud, 106–108
sabotage, 28–29
theft of IP, 68–70
Performance reviews for sabotage, 49
Periodic security awareness training, 159–163
Personal information in fraud, 103–104
Personal predispositions for sabotage, 28, 30
Personally Identifiable Information (PII)
access control case, 292
fraud, 111, 121, 279
future threats, 315–316
information technology sabotage case, 
255–256
Internet underground, 288–290
organized crime, 117
positive outcome case, 296–297
prevalence, 113–114
trusted business partner access to, 279
Personnel policies for trusted business 
partners, 284
Physical environment, tracking and 
securing, 171–173
Physical exfiltration, 95
Physical media for backups, 208
PII. See Personally Identifiable 
Information (PII)
Planned layoffs, sabotage from, 33
Planning in Ambitious Leader model, 79–80
Police communications operator case, 132, 
186, 266
Policies and procedures
documenting, 155–158
passwords and account management, 
174–177
reporting suspicious behavior, 165–166
for sabotage, 34, 36
SIEM, 225
termination, 203–206
training based on, 161
trusted business partners, 283
Pornographic images case, 140, 201, 254
Positive influence in system dynamics 
modeling, 347
Positive intervention for disgruntlement, 
49–50
Possessiveness in Entitled Independent 
model, 72
Postal and shipping industry sabotage 
case, 256
Potential precursors to sabotage, 37–42, 
223–231
PowerShell AD administration tools, 
237–238
Precipitating events for sabotage,  
31–34
Precise predictions in system dynamics, 346
Precursors to sabotage, 37–42, 223–231
Predictions in system dynamics 
modeling, 346
Preliminary Model of Insider Theft of 
Intellectual Property, 12
Prescription benefit plans sabotage  
case, 252
Pressure in Fraud Triangle, 106
Preventive controls for fraud, 126
Printed documents for theft of IP, 90

Index
382
Prioritizing alerts in risk-based approach, 
53–54
Prison inmate cases, 282–283
Privileges
accumulation of, 71
backdoor accounts, 175–176
best practices, 187–190
excessive, 125
hacking case, 157–158
least privilege best practices, 178–181
Proactive monitoring of employee online 
actions, 199
Production source code modification, 140
Profiles in MERIT threat models, 10–12
Programmer theft of IP threats, 63
Programming techniques for attacks,  
139–142
Progress Measure in MERIT InterActive, 338
Project managers in government sabotage 
case, 249
Promotion disagreements as dissatisfaction 
factor, 73
Proprietary software in theft of IP, 95
Prototypes in MERIT InterActive, 
336–340
Proxies in theft of IP, 93
Public health industry
case prevalence, 308
foreign theft of IP, 87
Public sources of information, 326
Q
Quarterly auditing, 196
R
Random auditing, 196
Rationalization in Fraud Triangle,  
106–107
Recovery processes
best practices, 207–210
SDLC, 142
testing, 57–59
Recruitment
fraud, 113–115, 121–123
security awareness training for, 159
theft of IP case, 261
References, 359–364
Reinforcing loops in system dynamics 
modeling, 348
Relocation issues as dissatisfaction  
factor, 73
Remailers, 109
Remote network access
layered defense for, 200–202
terminated employees, 204
for theft of IP, 90–92
Remote network administration tools for 
sabotage, 40
Removable media for theft of IP, 62, 90, 94
Reorganization, sabotage from, 33
Reporting
confidential, 161
suspicious behavior, 165–166
Reprimands as sabotage precursor, 38
Requirements in SDLC, 131–132, 182–183
Research by insider threat center, 306
Research chemist case, 198
Research deleted case, 166
Research Team, 15
Resignations in theft of IP, 73, 76
Responding to suspicious and disruptive 
behavior, 164–167
Responsibilities removal as sabotage 
precursor, 38
Return on investment (ROI) in theft of IP 
mitigation, 68
Revenge
Internet underground insiders, 287, 293
sabotage cases, 243–244, 250, 257, 280
SDLC, 139
Risk assessments
Ambitious Leader model, 81–83
enterprise-wide, 151–154
process, 304–305
Risk-based approach in prioritizing alerts, 
53–54
Risk Measure in MERIT InterActive, 338
ROI (return on investment) in theft of IP 
mitigation, 68
Role-based access control
description, 179
fraud, 125
SDLC, 132–133
system change controls, 193

Index
383
Role playing, 334
Rootkits, 41
S
Sabotage
backup and recovery process tests, 57–59
backups, 24, 40, 44–45, 139, 208, 256
behavioral precursors, 35–37
demotion measures, 56
description, 3
disgruntlement strategies, 49–50
expectations setting, 47–49
impacts, 26–27
mitigation strategies, 46–47
monitoring strategies, 52–53
of other organizations, 59
overview, 23–28
patterns, 28–29
perpetrator characteristics, 1, 27
personal predispositions, 28, 30
precipitating events, 31–34
profiles for, 11
reducing, 30–31, 34–35
risk-based approach to prioritizing alerts, 
53–54
secure logs, 56–57
SIEM signature for, 223–231
from stressful events, 37–39
targeted monitoring, 55
technical precursors and access paths, 
40–45
termination measures, 35, 40, 56
time and attack location, 225–227
Trust Trap, 45–46
trusted business partners, 44–45, 280–281
unknown access paths, 41–42, 50–52
Sabotage cases, 3–4, 241–243
banking and finance industry, 243–245
commercial facilities industry, 242, 245
defense industrial base, 246–247
energy industry, 247–248
food industry, 248
government, 248–250
information technology industry, 250–256
positive outcome, 297
postal and shipping industry, 256
prevalence, 8, 309–310
Sabotage/fraud cases, 256–258
Salary and compensation as sabotage 
factor, 34
Salespeople theft of IP threats, 63
Sanctions as sabotage precursor, 38–39
Schroeder, Will, 216
Scientists in theft of IP, 63, 85
Screen savers, password-protected, 172
Scripts modification, 140
SDLC. See Software Development Life 
Cycle (SDLC)
SDMIS (System Dynamics Modeling for 
Information Security), 348–349
SDN (Security Dynamics Network), 348–350
Secret Service
fraud modeling, 106
National Threat Assessment Center, 16
Sectors, case breakdown by, 307–309
Secure logs for sabotage, 56–57
Security
awareness training, 159–163
backup and recovery processes, 207–210
bypassing in organized crime, 118
physical environment, 171–173
SDLC, 131, 138–139
Security Dynamics Network (SDN), 348–350
Security guards
for deterrence, 171
training for, 162–163
Security Information and Event 
Management (SIEM) signature,  
223–225
application, 227–228, 230–231
Common Event Expression, 229–230
Common Event Format, 228–229
database analysis, 225–227
overview, 223–225
Sense of ownership in Entitled Independent 
model, 70
Separation of duties
backups, 58
best practices, 178–181
fraud, 125
for sabotage, 43
SDLC, 133
system administrators, 188
system design, 183
trusted business partners, 285

Index
384
Shared accounts
audits for, 175
for sabotage, 44, 52
terminated employees, 204
Sharing passwords in sabotage, 42
Shaw, Eric, 65
Shimeall, Timothy J., 145
SIEM. See Security Information and Event 
Management (SIEM) signature
SiLK tool, 221–223, 304
Sim City-styled simulation, 336
Simulation. See MERIT InterActive tool
Snort tool, 220–221, 304
Social engineering
fraud, 126
organized crime, 118
sabotage, 44
security awareness training for, 160
Software Development Life Cycle 
(SDLC), 129
attribution, 137
authentication and role-based access 
control, 132–133
automated data integrity checks, 134
backups, 138–139
best practices, 182–186
code reviews, 136–137
disruption of service and theft of 
information, 141–142
exception handling, 132, 135
mitigation strategies, 142
modification of production source code 
and scripts, 140
overview, 129–131
programming techniques, 139–142
requirements and system design 
oversights, 131–132
separation of duties, 133
system deployment, 137–139
unauthorized authentication 
credentials, 141
Software Engineering Institute, 219
Software keystroke loggers
fraud cases, 109, 265–266
system change control cases, 194
Software ownership issues, 73, 156–157
Sole system administrators
backups, 205
sabotage, 44
sabotage/fraud case, 257–258
system change controls, 192–193
withheld pay case, 152–153
Solid arrows in system dynamics 
modeling, 347
Source code
access control, 142
backups, 138
defense industrial base sabotage case, 247
deleted, 163
end user access, 131
modification, 140
sabotage/fraud case, 258
shared, 67
theft of IP, 95
Special Publication 800–53: Recommended 
Security Controls for Federal Information 
Systems and Organizations, 214
Special treatment of employees, sabotage 
from, 34, 168
splunk-powershell project, 238
Splunk rules, 235–237
Splunk tool, 232
Sponsored research for insider threat 
center, 306
Spooner, Derrick
fraud modeling, 102
theft of IP, 65, 83
trusted business partners, 276
“Spotlight On: Insider Theft of 
Intellectual Property inside the U.S. 
Involving Foreign Governments or 
Organizations,” 83
“Spotlight On: Insider Threat from Trusted 
Business Partners,” 276
“Spotlight On: Malicious Insiders and 
Organized Crime Activity,” 116
“Spotlight On: Malicious Insiders with 
Ties to the Internet Underground 
Community,” 286
“Spotlight On: Programming Techniques 
Used as an Insider Attack Tool,” 139
Stages in MERIT InterActive, 339–342
Star performer treatment, sabotage from, 
34, 168
Stolen backup media, 58
Stressful events
fraud from, 115
sabotage from, 37–39

Index
385
Strict password policies and practices, 
174–177
Students unauthorized access cases, 271
Subcontractors
background checks, 166–167
password and account management 
policies, 175–176
Subject data in coding process, 328–329
Supervisors as dissatisfaction factor, 73
Supply chain management, 176
Surveys
CyberSecurity Watch Survey, 319–323
IDC, 278
Suspensions as sabotage precursor, 38
Suspicious behavior
Entitled Independent model, 74
monitoring and responding to, 164–167
reporting, 165–166
as sabotage precursor, 37
System administrators
backups, 205
best practices, 187–190
sabotage, 44
sabotage/fraud case, 257–258
system change controls, 192–193
theft of IP threats, 62–63
withheld pay case, 152–153
System change controls, 191–194
System deployment in SDLC, 137–139
System design in SDLC, 131–132, 183
System dynamics modeling, 12
in 2005, 17
MERIT InterActive based on, 335
overview, 345–348
Security Dynamics Network, 348–350
System Dynamics Modeling for Information 
Security (SDMIS), 348–349
System Dynamics Society, 348–349
System Dynamics Society Conference, 349
System logs for sabotage, 42
System maintenance in SDLC, 185
System overrides in system design, 183
T
Tagging documents for theft of IP, 77
Targeted monitoring for sabotage, 55
Targeting centralized logging, 237–238
TBPs. See Trusted business partners (TBPs)
Team-oriented, role-playing 
experiences, 334
Teams in CERT Insider Threat Center, 15
Technical controls. See Insider threat lab
Technical insiders vs. nontechnical,  
314–315
Technical monitoring in Ambitious Leader 
model, 83
Technical precursors for sabotage, 40–45
Technical users best practices, 187–190
Technology solution limitations, 14
Telecommunications company
case prevalence, 307–309
foreign theft of IP, 86
information technology sabotage case, 253
sabotage/fraud case, 257–258
Temporary staff, threats from, 278
Termination
best practices, 203–206
monitoring, 233–235
property retrieval in, 169
remote access, 200–201
sabotage, 35, 40, 56
theft of IP, 73
trusted business partners, 285
unknown access paths, 289–291
Termination cases
backups, 209–210
commercial facilities sabotage, 245, 
289–290
eavesdropping, 270–271
information technology sabotage,  
250–251
logistics company sabotage, 256
theft of IP, 260
trusted business partner, 277
unauthorized access, 272–273
Terms, glossary, 351–357
Testing backup and recovery process,  
57–59
Theft of information
employee remote access case, 198–199
SDLC, 141–142
Theft of intellectual property (IP)
Ambitious Leader model, 78–83
concealment, 95
description, 5
Entitled Independent model. See Entitled
Independent model in theft of IP

Index
386
Theft of intellectual property (IP) (contd.)
foreign governments and organizations, 
83–88
host data, 93–95
impacts, 66–68
methods overview, 89–90
mitigation strategies, 88–97
models, 12–13
network data, 90–93
overview, 61–66
patterns, 68–69
perpetrator characteristics, 1
physical theft, 95
trusted business partners, 96–97, 281–282
types, 61
Theft of IP cases
chemical industry, 258–259
customer information, 5–6
defense industrial base, 246, 260
fraud, 265–266
government, 260–261
information technology industry, 261–262
ownership issue, 156–157
positive outcome, 297
prevalence, 8, 310–311
Theft ring in fraud case, 264
Third-parties. See Contractors and third 
parties
30-day window
centralized logging, 233–237
precautions, 98
theft of IP, 76, 95, 98
Threads in MERIT InterActive, 339
Threat models, 9–12, 27
Threatening emails case, 201
Thumb drives for theft of IP, 94
TIFF images, 261
Time frame in fraud, 110–111
Tracking
access paths, 52
controlled information documents, 173
physical environment, 171–173
theft of IP, 92
Trade secrets. See Theft of intellectual 
property (IP)
Trader fraud case, 265
Training
for disgruntlement, 49
effectiveness of, 334–336
security awareness, 159–163
simulation for. See MERIT 
InterActive tool
supervisors for sabotage, 36
Transactions
auditing, 123
verifying, 154
Trash, office, 173
Trends
cases breakdown by, 312–313
system dynamics modeling, 346
Trigger hypotheses, 349
True stories. See Case examples
Trust Trap in sabotage, 45–46
Trusted business partners (TBPs)
complexity of threats, 6
customer records stolen cases, 272
fraud, 5, 279–280
identifying, 282–283
mitigation and detection 
recommendations, 283–285
overview, 275–277
password and account management 
policies, 175–176
sabotage, 44–45, 280–281
theft of IP, 96–97, 281–282
threat overview, 278–279
Trzeciak, Randall F.
best practices, 145
biography, 366
insider threat lab, 216
Internet underground, 286
SDLC, 139
theft of IP, 65, 83
trusted business partners, 276
Two-person rule
backups, 58, 208
description, 178
for sabotage, 43–45
system change controls, 193
Type of crime, case breakdown by, 309–312
U
UIDs (userids)
converting, 234
information technology sabotage case, 255

Index
387
Unauthorized authentication 
credentials, 141
Undercover agent fraud case, 296–297
Unknown access paths
eliminating, 50–52
Internet underground, 289–291
sabotage, 41–42
Unmet expectations
information technology sabotage case, 253
logic bomb sabotage cases, 244–245
policies and controls for, 156
sabotage from, 31–34
SDLC case, 185–186
system administrator case, 189
U.S. Munitions List source code theft, 67
Userids (UIDs)
converting, 234
information technology sabotage case, 255
V
Validation of configurations, 191–192
Vendors
backup services, 57
password and account management 
policies, 175–176
sabotage, 44–45
Verification
modification of critical data, 123
transaction, 154
Victim organizations, 327
Videos at insider threat lab, 218–219
Violent behavior
arrests for, 30
as sabotage precursor, 36
Virtual private networks (VPNs)
attack prevalence, 225–227
sabotage, 24
theft of IP case, 221–223
Virtual simulation tool, 18
Virtual world, 179
Visual simulation company theft of IP 
case, 260
Voice-mail system case, 201–202
VPNs (virtual private networks)
attack prevalence, 225–227
sabotage, 24
theft of IP case, 221–223
Vulnerabilities assessments, 152
W
Water sector
foreign theft of IP, 87
fraud, 104
Web site for insider threat controls, 216
Weiland, Robert, 276
Windows, locking, 172
Wireless networks
information technology sabotage cases, 
251–253
kiosk access case, 153
Wireshark packet sniffer, 221, 304
Withheld passwords case, 152–153
Workshops
insider threat center, 301–303
SDMIS, 349
Writable CDs for theft of IP, 94
X
XNET platform, 18–19, 218, 239, 304

S.R. Band, D.M. Cappelli, L.F. Fischer, A.P. Moore, E.D. Shaw, and R.F. Trzeciak, “Comparing Insider  
IT Sabotage and Espionage: A Model-Based Analysis,” Software Engineering Institute Technical Report 
CMU/SEI-2006-TR-026, Carnegie Mellon University, December 2006. http://www.cert.org/archive/
pdf/06tr026.pdf.
D.M. Cappelli, T. Caron, R.F. Trzeciak, and A.P. Moore, “Spotlight On: Programming Techniques Used as an 
Insider Attack Tool,” Joint CyLab (CMU) and CERT (SEI) Report, December 2008. http://www.cert.org/
archive/pdf/insiderthreat_programmers_1208.pdf
D.M. Cappelli, Moore, A.P., Trzeciak, R.F. and Shimeall, T.J., “Common Sense Guide to Prevention and 
 Detection of Insider Threats: 3rd Edition,” Joint CyLab (CMU) and CERT (SEI) Report, September 2008 
(updated from July 2006 and April 2005). http://www.cert.org/archive/pdf/CSGV3.pdf
D.M. Cappelli, A.G. Desai, A.P. Moore, T.J. Shimeall, E.A. Weaver, B.J. Willke, “Management and  
Education of the Risk of Insider Threat (MERIT): Mitigating the Risk of Sabotage to Employers’  Information, 
Systems, or Networks,” Software Engineering Institute Technical Note CMU/SEI-2006-TN-041, March 2007. 
http://www.sei.cmu.edu/reports/06tn041.pdf
M. Hanley, J. Montelibano, “Insider Threat Control: Using Centralized Logging to Detect Data Exfiltration 
Near Insider Termination,” SEI Technical Note SEI-TN-024, Software Engineering Institute, Carnegie Mellon 
University, October 2011.
M. Hanley, T. Dean, W. Schroeder, M. Houy, R.F. Trzeciak and J. Montelibano, “An Analysis of Technical 
Observations in Insider Theft of Intellectual Property Cases,” SEI Technical Note CMU/SEI-2011-TN-006, 
Software Engineering Institute, Carnegie Mellon University, 2011.
M. Hanley, A.P. Moore, D.M. Cappelli, and R.F. Trzeciak, “Spotlight On: Malicious Insiders with  
Ties to the Internet Underground Community,” Joint CyLab (CMU) and CERT (SEI) Report, March 2009. 
http://www.cert.org/archive/pdf/CyLab%20Insider%20Threat%20Quarterly%20on%20Internet%20 
Underground%20-%20March%202009P.pdf
C. King, “Spotlight On: Malicious Insiders and Organized Crime Activity,” SEI Technical Note CMU/
SEI-2011-TN-025, September 2011.
J. Montelibano, “Insider Threat Control: Using a SIEM Signature to Detect Potential Precursors to IT Sabotage,” 
SEI Technical Note SEI-TN-021, Software Engineering Institute, Carnegie Mellon University, April 2011.
A.P. Moore, A. Cummings, and D. Spooner, “Modeling and Analysis of Insider Fraud,” in 2010 CERT Research 
Annual Report, 2011.
D. Spooner, D.M. Cappelli, A.P. Moore, and R.F. Trzeciak, “Spotlight On: Insider Theft of Intellectual Property 
inside the U.S. Involving Foreign Governments or Organizations,” Joint CyLab (CMU) and CERT (SEI) Report, 
December 2008. http://www.cert.org/archive/pdf/insiderthreat_programmers_1208.pdf
R.M. Weiland, A.P. Moore, D.M. Cappelli, R.F. Trzeciak, D. Spooner “Spotlight On: Insider Threat from 
Trusted Business Partners,” Joint CyLab (CMU) and CERT (SEI) Report, February 2010. http://www.cert.org/
archive/pdf/TrustedBusinessPartners0210.pdf
A.P. Moore, D.M. Cappelli, T. Caron, E. Shaw, and R.F. Trzeciak, “A Preliminary Model of Insider Theft of 
Intellectual Property.” SEI Technical Note CMU/SEI-2011-TN-013.
A.P. Moore, D.M. Cappelli, and R.F. Trzeciak, “The ‘Big Picture’ of Insider IT Sabotage Across U.S.  
Critical Infrastructures,” SEI Technical Report CMU/SEI-2008-TR-009 http://www.cert.org/archive/
pdf/08tr009.pdf)
M. Hanley, “Candidate Technical Controls and Indicators of Insider Attack from Socio-Technical Models and 
Data,” in Proceedings of the 2010 NSA Center of Academic Excellence (CAE) Workshop on Insider Threat, 
November 2010 (also published as SEI Technical Note CMU/SEI-2011-TN-003, January 2011).
A.P. Moore, D.M. Cappelli, T. Caron, E. Shaw, and R.F. Trzeciak, “A Preliminary Model of Insider Theft of 
Intellectual Property.” Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable  
This page constitutes a continuation of the copyright page, which begins on page iv.
388

Applications 2, 1 (Special Issue Addressing Insider Threats and Information Leakage, 2011): 28–49  
(also published as SEI Technical Note CMU/SEI-2011-TN-013).
A.P. Moore, D.M. Cappelli, T. Caron, E. Shaw, and R.F. Trzeciak, “Insider Theft of Intellectual Property for 
Business Advantage: A Preliminary Model,” in Proceedings of the 1st International Workshop on  
Managing Insider Security Threats (MIST2009), Purdue University, West Lafayette, USA, June 16, 2009.  
http://www.cert.org/insider_threat/docs/Insider_Theft_of_IP_Model_MIST09.pdf
A.P. Moore, D.M. Cappelli, and R.F. Trzeciak, “The ‘Big Picture’ of Insider IT Sabotage Across U.S. Critical 
Infrastructures,” in Insider Attack and Cyber Security: Beyond the Hacker, eds. Stolfo, S.J., et. al., Springer 
Science + Business Media, LLC, 2008 (also published in SEI Technical Report - CMU/SEI-2008-TR-009  
http://www.cert.org/archive/pdf/08tr009.pdf)
A.P. Moore, D.M. Cappelli, H. Joseph, R.F. Trzeciak, “An Experience Using System Dynamics to Facilitate an 
Insider Threat Workshop,” in Proceedings 25th International Conference of the System Dynamics Society,  
July 2007. http://www.cert.org/archive/pdf/ISDC2007.pdf
CSO Magazine, Secret Service, Software Engineering Institute CERT Program at Carnegie Mellon University 
and Deloitte, 2011 CyberSecurity Watch Survey: Press Release, January 2011. http://www.cert.org/archive/
pdf/CyberSecuritySurvey2011.pdf
CSO Magazine, Secret Service, Software Engineering Institute CERT Program at Carnegie Mellon University 
and Deloitte, 2011 CyberSecurity Watch Survey: Data, January 2011. http://www.cert.org/archive/pdf/
CyberSecuritySurvey2011Data.pdf
M.M. Keeney, E.F. Kowalski, D.M. Cappelli, A.P. Moore, T.J. Shimeall, and S.N. Rogers, “Insider Threat 
Study: Computer System Sabotage in Critical Infrastructure Sectors,” Joint SEI and U.S. Secret Service Report, 
May 2005. http://www.cert.org/archive/pdf/insidercross051105.pdf
E.F. Kowalski, M.M. Keeney, D.M. Cappelli, and A.P. Moore, “Insider Threat Study: Illicit Cyber Activity in 
the Information Technology and Telecommunications Sector,” Joint SEI and U.S. Secret Service Report,  
January 2008. http://www.cert.org/archive/pdf/insiderthreat_it2008.pdf
E.F. Kowalski, T. Conway, S. Keverline, M. Williams, D. McCauley, D.M. Cappelli, B.W. Willke, and A.P. Moore, 
“Insider Threat Study: Illicit Cyber Activity in the Government Sector,” Joint SEI and U.S. Secret Service 
Report, January 2008. http://www.cert.org/archive/pdf/insiderthreat_gov2008.pdf
M.R. Randazzo, M.M. Keeney, E.F. Kowalski, D.M. Cappelli, A.P. Moore, “Insider Threat Study: Illicit Cyber 
Activity in the Banking and Finance Sector,” Joint SEI and U.S. Secret Service Report, 2004, August, available at 
http://www.secretservice.gov/ntac/its_report_040820.pdf.
389

This page intentionally left blank 

Do you know how vulnerable your organization is to its own insiders? 
Employees, contractors, or business partners can exploit their  
knowledge to attack your organization.
The CERT Insider Threat Center, part of Carnegie Mellon University’s 
Software Engineering Institute, studies the technical and behavioral 
aspects of real insider compromises. Our Insider Threat Vulnerability 
Assessment for government, private, public, for-profit, and not-for-
profit organizations is a confidential, on-site evaluation of your entire 
organization’s ability to prevent, detect, and respond to insider threats. 
The results are incorporated into an actionable framework for  
managing your organization’s vulnerability.
The CERT® Insider Threat Vulnerability
Assessment: Identify vulnerabilities and 
remediation strategies from the inside out. 
To learn more about the Insider Threat Center,  
visit the CERT website: http://www.cert.org/insider_threat.
To learn more about the Insider Threat Assessment or to 
schedule one, email the Insider Threat Center staff:  
insider-threat-feedback@cert.org.

Activate your FREE Online Edition at  
informit.com/safarifree
StEp 1: 
 Enter the coupon code: PRIVHFH.
StEp 2: 
 New Safari users, complete the brief registration form.  
Safari subscribers, just log in.
If you have difficulty registering on Safari or accessing the online edition,  
please e-mail customer-service@safaribooksonline.com
Your purchase of The CERT® Guide to Insider Threats includes access to a free online edition 
for 45 days through the Safari Books Online subscription service. Nearly every Addison-Wesley 
Professional book is available online through Safari Books Online, along with thousands of books 
and videos from publishers such as Cisco Press, Exam Cram, IBM Press, O’Reilly Media, Prentice 
Hall, Que, Sams, and VMware Press. 
Safari Books Online is a digital library providing searchable, on-demand access to thousands 
of technology, digital media, and professional development books and videos from leading 
publishers. With one monthly or yearly subscription price, you get unlimited access to learning 
tools and information on topics including mobile app and software development, tips and tricks 
on using your favorite gadgets, networking, project management, graphic design, and much more.
FREE  
Online Edition

Free ebooks ==>   www.Ebook777.com

www.Ebook777.com

