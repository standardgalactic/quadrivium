123
$MBVEJP$BOVUPt"OJUB5BCBDDP
Mathematical Analysis I
UNITEXT
UNITEXT
4FDPOE&EJUJPO

UNITEXT – La Matematica per il 3+2
Volume 84
For further volumes:
http://www.springer.com/series/5418

Claudio Canuto · Anita Tabacco
MathematicalAnalysisI
Second Edition

Claudio Canuto
Department of Mathematical Sciences
Politecnico di Torino
Torino, Italy
Anita Tabacco
Department of Mathematical Sciences
Politecnico di Torino
Torino, Italy
UNITEXT – La Matematica per il 3+2
ISSN 2038-5722
ISSN 2038-5757 (electronic)
ISBN 978-3-319-12771-2
ISBN 978-3-319-12772-9 (eBook)
DOI 10.1007/978-3-319-12772-9
Springer Cham Heidelberg New York Dordrecht London
Library of Congress Control Number: 2014951876
© Springer International Publishing Switzerland 2015
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, re-
citation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or
information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed. Exempted from this legal reservation are brief ex-
cerpts in connection with reviews or scholarly analysis or material supplied speciﬁcally for the purpose
of being entered and executed on a computer system, for exclusive use by the purchaser of the work.
Duplication of this publication or parts thereof is permitted only under the provisions of the Copyright
Law of the Publisher’s location, in its current version, and permission for use must always be obtained
from Springer. Permissions for use may be obtained through RightsLink at the Copyright Clearance
Center. Violations are liable to prosecution under the respective Copyright Law.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publi-
cation does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the
relevant protective laws and regulations and therefore free for general use.
While the advice and information in this book are believed to be true and accurate at the date of pu-
blication, neither the authors nor the editors nor the publisher can accept any legal responsibility for
any errors or omissions that may be made. The publisher makes no warranty, express or implied, with
respect to the material contained herein.
Cover Design: Simona Colombo, Giochi di Graﬁca, Milano, Italy
Files provided by the Authors
Springer is a part of Springer Science+Business Media (www.springer.com)

Preface
This textbook is meant to help students acquire the basics of Calculus in curricula
where mathematical tools play a crucial part (so Engineering, Physics, Computer
Science and the like). The fundamental concepts and methods of Diﬀerential and
Integral Calculus for functions of one real variable are presented with the primary
purpose of letting students assimilate their eﬀective employment, but with critical
awareness. The general philosophy inspiring our approach has been to simplify the
system of notions available prior to the university reform; at the same time we
wished to maintain the rigorous exposition and avoid the trap of compiling a mere
formulary of ready-to-use prescriptions.
In view of the current Programme Speciﬁcations, the organization of a ﬁrst
course in Mathematics often requires to make appropriate choices about lecture
content, the comprehension level required from the recipients, and which kind
of language to use. From this point of view, the treatise is ‘stratiﬁed’ in three
layers, each corresponding to increasingly deeper engagement by the user. The
intermediate level corresponds to the contents of the eleven chapters of the text.
Notions are ﬁrst presented in a na¨ıve manner, and only later deﬁned precisely.
Their features are discussed, and computational techniques related to them are
exhaustively explained. Besides this, the fundamental theorems and properties are
followed by proofs, which are easily recognisable by the font’s colour.
At the elementary level the proofs and the various remarks should be skipped.
For the reader’s sake, essential formulas, and also those judged important, have
been highlighted in blue, and gray, respectively. Some tables, placed both through-
out and at the end of the book, collect the most useful formulas. It was not our
desire to create a hierachy-of-sorts for theorems, instead to leave the instructor
free to make up his or her own mind in this respect.
The deepest-reaching level relates to the contents of the ﬁve appendices and
enables the strongly motivated reader to explore further into the subject. We
believe that the general objectives of the Programme Speciﬁcations are in line with
the fact that willing and able pupils will build a solid knowledge, in the tradition
of the best academic education. The eleven chapters contain several links to the
diﬀerent appendices where the reader will ﬁnd complements to, and insight in

VI
Preface
various topics. In this fashion every result that is stated possesses a corresponding
proof.
To make the approach to the subject less harsh, and all the more gratifying,
we have chosen an informal presentation in the ﬁrst two chapters, where relevant
deﬁnitions and properties are typically part of the text. From the third chapter
onwards they are highlighted by the layout more discernibly. Some deﬁnitions and
theorems are intentionally not stated in the most general form, so to privilege
a brisk understanding. For this reason a wealth of examples are routinely added
along the way right after statements, and the same is true for computational
techniques. Several remarks enhance the presentation by underlining, in particular,
special cases and exceptions. Each chapter ends with a large number of exercises
that allow one to test on the spot how solid one’s knowledge is. Exercises are
grouped according to the chapter’s major themes and presented in increasing order
of diﬃculty. All problems are solved, and at least half of them chaperone the reader
to the solution.
We have adopted the following graphical conventions for the constituent build-
ing blocks: deﬁnitions appear on a gray background, theorems’ statements on blue,
a vertical coloured line marks examples, and boxed exercises, like 12. , indicate
that the complete solution is provided.
We wish to dedicate this volume to Professor Guido Weiss of Washington
University in St. Louis, a master in the art of teaching. Generations of students
worldwide have beneﬁted from Guido’s own work as a mathematician; we hope
that his own clarity is at least partly reﬂected in this textbook.
This second English edition reﬂects the latest version of the Italian book, that
is in use since over a decade, and has been extensively and successfully tested at
the Politecnico in Turin and in other Italian Universities. We are grateful to the
many colleagues and students whose advice, suggestions and observations have
allowed us to reach this result. Special thanks are due to Dr. Simon Chiossi, for
the careful and eﬀective work of translation.
Finally, we wish to thank Francesca Bonadei – Executive Editor, Mathem-
atics and Statistics, Springer Italia – for her encouragement and support in the
preparation of this textbook.
Torino, August 2014
Claudio Canuto, Anita Tabacco

Contents
1
Basic notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Elements of mathematical logic. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2.1
Connectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.2.2
Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.2.3
Quantiﬁers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.3
Sets of numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.3.1
The ordering of real numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.3.2
Completeness of R . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
1.4
Factorials and binomial coeﬃcients . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
1.5
Cartesian product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
1.6
Relations in the plane . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
1.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
1.7.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2
Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.1
Deﬁnitions and ﬁrst examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.2
Range and pre-image . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
2.3
Surjective and injective functions; inverse function . . . . . . . . . . . . . . . 38
2.4
Monotone functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.5
Composition of functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
2.5.1
Translations, rescalings, reﬂections. . . . . . . . . . . . . . . . . . . . . . . 45
2.6
Elementary functions and properties . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
2.6.1
Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
2.6.2
Polynomial and rational functions . . . . . . . . . . . . . . . . . . . . . . . 50
2.6.3
Exponential and logarithmic functions . . . . . . . . . . . . . . . . . . . 50
2.6.4
Trigonometric functions and inverses . . . . . . . . . . . . . . . . . . . . . 51
2.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
2.7.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

VIII
Contents
3
Limits and continuity I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.1
Neighbourhoods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.2
Limit of a sequence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
3.3
Limits of functions; continuity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
3.3.1
Limits at inﬁnity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
3.3.2
Continuity. Limits at real points. . . . . . . . . . . . . . . . . . . . . . . . . 74
3.3.3
One-sided limits; points of discontinuity . . . . . . . . . . . . . . . . . . 82
3.3.4
Limits of monotone functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
3.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
3.4.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4
Limits and continuity II . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.1
Theorems on limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.1.1
Uniqueness and sign of the limit . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.1.2
Comparison theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
4.1.3
Algebra of limits. Indeterminate forms of algebraic type . . . . 96
4.1.4
Substitution theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
4.2
More fundamental limits. Indeterminate forms of exponential type . 105
4.3
Global features of continuous maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
4.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
4.4.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
5
Local comparison of functions. Numerical sequences and series 123
5.1
Landau symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
5.2
Inﬁnitesimal and inﬁnite functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
5.3
Asymptotes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
5.4
Further properties of sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
5.5
Numerical series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
5.5.1
Positive-term series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
5.5.2
Alternating series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
5.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
5.6.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
6
Diﬀerential calculus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
6.1
The derivative . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
6.2
Derivatives of the elementary functions. Rules of diﬀerentiation. . . . 172
6.3
Where diﬀerentiability fails . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
6.4
Extrema and critical points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
6.5
Theorems of Rolle, Lagrange, and Cauchy . . . . . . . . . . . . . . . . . . . . . . 183
6.6
First and second ﬁnite increment formulas . . . . . . . . . . . . . . . . . . . . . . 186
6.7
Monotone maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
6.8
Higher-order derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
6.9
Convexity and inﬂection points . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
6.9.1
Extension of the notion of convexity . . . . . . . . . . . . . . . . . . . . . 195
6.10 Qualitative study of a function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196

Contents
IX
6.10.1 Hyperbolic functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
6.11 The Theorem of de l’Hˆopital . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200
6.11.1 Applications of de l’Hˆopital’s theorem . . . . . . . . . . . . . . . . . . . . 202
6.12 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
6.12.1 Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
7
Taylor expansions and applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
7.1
Taylor formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
7.2
Expanding the elementary functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
7.3
Operations on Taylor expansions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
7.4
Local behaviour of a map via its Taylor expansion . . . . . . . . . . . . . . . 244
7.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
7.5.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250
8
Geometry in the plane and in space . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
8.1
Polar, cylindrical, and spherical coordinates . . . . . . . . . . . . . . . . . . . . . 259
8.2
Vectors in the plane and in space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
8.2.1
Position vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
8.2.2
Norm and scalar product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
8.2.3
General vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
8.3
Complex numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
8.3.1
Algebraic operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
8.3.2
Cartesian coordinates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
8.3.3
Trigonometric and exponential form . . . . . . . . . . . . . . . . . . . . . 275
8.3.4
Powers and nth roots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
8.3.5
Algebraic equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
8.4
Curves in the plane and in space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
8.5
Functions of several variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
8.5.1
Continuity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
8.5.2
Partial derivatives and gradient . . . . . . . . . . . . . . . . . . . . . . . . . 288
8.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
8.6.1
Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294
9
Integral calculus I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
9.1
Primitive functions and indeﬁnite integrals . . . . . . . . . . . . . . . . . . . . . 302
9.2
Rules of indeﬁnite integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306
9.2.1
Integrating rational maps. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312
9.3
Deﬁnite integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
9.4
The Cauchy integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320
9.5
The Riemann integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322
9.6
Properties of deﬁnite integrals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328
9.7
Integral mean value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
9.8
The Fundamental Theorem of integral calculus . . . . . . . . . . . . . . . . . . 333
9.9
Rules of deﬁnite integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
9.9.1
Application: computation of areas . . . . . . . . . . . . . . . . . . . . . . . 340

X
Contents
9.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
9.10.1 Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
10
Integral calculus II . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
10.1 Improper integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
10.1.1 Unbounded domains of integration . . . . . . . . . . . . . . . . . . . . . . 357
10.1.2 Unbounded integrands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
10.2 More improper integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
10.3 Integrals along curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
10.3.1 Length of a curve and arc length . . . . . . . . . . . . . . . . . . . . . . . . 375
10.4 Integral vector calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
10.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380
10.5.1 Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
11
Ordinary diﬀerential equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389
11.1 General deﬁnitions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389
11.2 First order diﬀerential equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
11.2.1 Equations with separable variables . . . . . . . . . . . . . . . . . . . . . . 394
11.2.2 Linear equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
11.2.3 Homogeneous equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
11.2.4 Second order equations reducible to ﬁrst order . . . . . . . . . . . . 400
11.3 Initial value problems for equations of the ﬁrst order . . . . . . . . . . . . . 401
11.3.1 Lipschitz functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
11.3.2 A criterion for solving initial value problems . . . . . . . . . . . . . . 404
11.4 Linear second order equations with constant coeﬃcients . . . . . . . . . . 406
11.5 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 412
11.5.1 Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414
Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425
A.1 The Principle of Mathematical Induction . . . . . . . . . . . . . . . . . . . . . . 427
A.2 Complements on limits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . 431
A.2.1 Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431
A.2.2 Elementary functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
A.2.3 Napier’s number . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 437
A.3 Complements on the global features of continuous maps . . . . . . . 441
A.3.1 Subsequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441
A.3.2 Continuous functions on an interval . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
A.3.3 Uniform continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447

Contents
XI
A.4 Complements on diﬀerential calculus . . . . . . . . . . . . . . . . . . . . . . . . . . 449
A.4.1 Derivation formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449
A.4.2 De l’Hˆopital’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 452
A.4.3 Convex functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 454
A.4.4 Taylor formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 456
A.5 Complements on integral calculus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461
A.5.1 The Cauchy integral. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461
A.5.2 The Riemann integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462
A.5.3 Improper integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470
Tables and Formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 479

1
Basic notions
In this introductory chapter some mathematical notions are presented rapidly,
which lie at the heart of the study of Mathematical Analysis. Most should already
be known to the reader, perhaps in a more thorough form than in the following
presentation. Other concepts may be completely new, instead. The treatise aims
at ﬁxing much of the notation and mathematical symbols frequently used in the
sequel.
1.1 Sets
We shall denote sets mainly by upper case letters X, Y, . . ., while for the members
or elements of a set lower case letters x, y, . . . will be used. When an element x is
in the set X one writes x ∈X (‘x is an element of X’, or ‘the element x belongs
to the set X’), otherwise the symbol x ̸∈X is used.
The majority of sets we shall consider are built starting from sets of numbers.
Due to their importance, the main sets of numbers deserve special symbols, namely:
N = set of natural numbers
Z = set of integer numbers
Q = set of rational numbers
R = set of real numbers
C = set of complex numbers.
The deﬁnition and main properties of these sets, apart from the last one, will
be brieﬂy recalled in Sect. 1.3. Complex numbers will be dealt with separately in
Sect. 8.3.
Let us ﬁx a non-empty set X, considered as ambient set. A subset A of X
is a set all of whose elements belong to X; one writes A ⊆X (‘A is contained,
or included, in X’) if the subset A is allowed to possibly coincide with X, and
A ⊂X (‘A is properly contained in X’) in case A is a proper subset of X, that
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_1,
© Springer International Publishing Switzerland 2015

2
1 Basic notions
X
A
B
X
A
CA
Figure 1.1. Venn diagrams (left) and complement (right)
is, if it does not exhaust the whole X. From the intuitive point of view it may
be useful to represent subsets as bounded regions in the plane using the so-called
Venn diagrams (see Fig. 1.1, left).
A subset can be described by listing the elements of X which belong to it
A = {x, y, . . . , z};
the order in which elements appear is not essential. This clearly restricts the use
of such notation to subsets with few elements. More often the notation
A = {x ∈X | p(x)}
or
A = {x ∈X : p(x)}
will be used (read ‘A is the subset of elements x of X such that the condition p(x)
holds’); p(x) denotes the characteristic property of the elements of the subset, i.e.,
the condition that is valid for the elements of the subset only, and not for other
elements. For example, the subset A of natural numbers smaller or equal than 4
may be denoted
A = {0, 1, 2, 3, 4}
or
A = {x ∈N | x ≤4}.
The expression p(x) =‘x ≤4’ is an example of predicate, which we will return to
in the following section.
The collection of all subsets of a given set X forms the power set of X, and
is denoted by P(X). Obviously X ∈P(X). Among the subsets of X there is the
empty set, the set containing no elements. It is usually denoted by the symbol
∅, so ∅∈P(X). All other subsets of X are proper and non-empty.
Consider for instance X = {1, 2, 3} as ambient set. Then
P(X) = { ∅, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, X}.
Note that X contains 3 elements (it has cardinality 3), while P(X) has 8 = 23
elements, hence has cardinality 8. In general if a ﬁnite set (a set with a ﬁnite
number of elements) has cardinality n, the power set of X has cardinality 2n.

1.1 Sets
3
Starting from one or more subsets of X, one can deﬁne new subsets by means
of set-theoretical operations. The simplest operation consists in taking the com-
plement: if A is a subset of X, one deﬁnes the complement of A (in X) to be the
subset
CA = {x ∈X | x ̸∈A}
made of all elements of X not belonging to A (Fig. 1.1, right).
Sometimes, in order to underline that complements are taken with respect to
the ambient space X, one uses the more precise notation CXA. The following
properties are immediate:
CX = ∅,
C∅= X,
C(CA) = A.
For example, if X = N and A is the subset of even numbers (multiples of 2), then
CA is the subset of odd numbers.
Given two subsets A and B of X, one deﬁnes intersection of A and B the
subset
A ∩B = {x ∈X | x ∈A and x ∈B}
containing the elements of X that belong to both A and B, and union of A and
B the subset
A ∪B = {x ∈X | x ∈A or x ∈B}
made of the elements that are either in A or in B (this is meant non-exclusively,
so it includes elements of A ∩B), see Fig. 1.2.
We recall some properties of these operations.
i) Boolean properties:
A ∩CA = ∅,
A ∪CA = X;
X
A
B
A ∩B
X
A
B
A ∪B
A ∪B
A ∪B
Figure 1.2. Intersection and union of sets

4
1 Basic notions
ii) commutative, associative and distributive properties:
A ∩B = B ∩A,
A ∪B = B ∪A,
(A ∩B) ∩C = A ∩(B ∩C),
(A ∪B) ∪C = A ∪(B ∪C),
(A ∩B) ∪C = (A ∪C) ∩(B ∪C),
(A ∪B) ∩C = (A ∩C) ∪(B ∩C);
iii) De Morgan laws:
C(A ∩B) = CA ∪CB,
C(A ∪B) = CA ∩CB.
Notice that the condition A ⊆B is equivalent to A ∩B = A, or A ∪B = B.
There are another couple of useful operations. The ﬁrst is the diﬀerence
between a subset A and a subset B, sometimes called relative complement
of B in A
A \ B = {x ∈A | x ̸∈B} = A ∩CB
(read ‘A minus B’), which selects the elements of A that do not belong to B. The
second operation is the symmetric diﬀerence of the subsets A and B
A Δ B = (A \ B) ∪(B \ A) = (A ∪B) \ (A ∩B),
which picks out the elements belonging either to A or B, but not both (Fig. 1.3).
For example, let X = N, A be the set of even numbers and B = {n ∈N | n ≤
10} the set of natural numbers smaller or equal than 10. Then B\A = {1, 3, 5, 7, 9}
is the set of odd numbers smaller than 10, A \ B is the set of even numbers larger
than 10, and AΔB is the union of the latter two.
X
A
B
A \ B
X
A
B
A Δ B
A Δ B
Figure 1.3. The diﬀerence A \ B (left) and the symmetric diﬀerence A Δ B (right) of
two sets

1.2 Elements of mathematical logic
5
1.2 Elements of mathematical logic
In Mathematical Logic a formula is a declarative sentence, or statement, the truth
or falsehood of which can be established. Thus within a certain context a formula
carries a truth value: True or False. The truth value can be variously represented,
for instance using the binary value of a memory bit (1 or 0), or by the state of
an electric circuit (open or close). Examples of formulas are: ‘7 is an odd number’
(True), ‘3 >
√
12’ (False), ‘Venus is a star’ (False), ‘This text is written in english’
(True), et cetera. The statement ‘Milan is far from Rome’ is not a formula, at least
without further speciﬁcations on the notion of distance; in this respect ‘Milan is
farther from Rome than Turin’ is a formula. We shall indicate formulas by lower
case letters p, q, r, . . ..
1.2.1 Connectives
New formulas can be built from old ones using logic operations expressed by certain
formal symbols, called connectives.
The simplest operation is called negation: by the symbol ¬p (spoken ‘not p’)
one indicates the formula whose truth value is True if p is False, and False if p
is True. For example if p=‘7 is a rational number’, then ¬p =‘7 is an irrational
number’.
The conjunction of two formulas p and q is the formula p ∧q (‘p and q’),
which is true if both p and q are true, false otherwise. The disjunction of p and
q is the formula p ∨q (‘p or q’); the disjunction is false if p and q are both false,
true in all other cases. Let for example p =‘7 is a rational number’ and q = ‘7 is
an even number’; the formula p ∧q = ‘7 is an even rational number’ is false since
q is false, and p ∨q = ‘7 is rational or even’ is true because p is true.
Many statements in Mathematics are of the kind ‘If p is true, then q is true’,
also read as ‘suﬃcient condition for q to be true is that p be true’, or ‘necessary
condition for p to be true is that q be true’. Such statements are diﬀerent ways
of expressing the same formula p ⇒q (‘p implies q’, or ‘if p, then q’), called
implication, where p is the ‘hypothesis’ or ‘assumption’, q the ‘consequence’
or ‘conclusion’. By deﬁnition, the formula p ⇒q is false if p is true and q false,
otherwise it is always true. In other words the implication does not allow to deduce
a false conclusion from a true assumption, yet does not exclude a true conclusion
being implied by a false hypothesis. Thus the statement ‘if it rains, I’ll take the
umbrella’ prevents me from going out without umbrella when it rains, but will not
interfere with my decision if the sky is clear.
Using p and q it is easy to check that the formula p ⇒q has the same truth
value of ¬p∨q. Therefore the connective ⇒can be expressed in terms of the basic
connectives ¬ and ∨.
Other frequent statements are structured as follows: ‘the conclusion q is true
if and only if the assumption p is true’, or ‘necessary and suﬃcient condition for a
true q is a true p’. Statements of this kind correspond to the formula p ⇔q (‘p is

6
1 Basic notions
(logically) equivalent to q’), called logic equivalence. A logic equivalence is true
if p and q are simultaneously true or simultaneously false, and false if the truth
values of p and q diﬀer. An example is the statement ‘a natural number is odd if
and only if its square is odd’. The formula p ⇔q is the conjuction of p ⇒q and
q ⇒p, in other words p ⇔q and (p ⇒q) ∧(q ⇒p) have the same truth value.
Thus the connective ⇔can be expressed by means of the basic connectives ¬, ∨
and ∧.
The formula p ⇒q (a statement like ‘if p, then q’) can be expressed in various
other forms, all logically equivalent. These represent rules of inference to attain
the truth of the implication. For example, p ⇒q is logically equivalent to the
formula ¬q ⇒¬p, called contrapositive formula; symbolically
(p ⇒q)
⇐⇒
(¬q ⇒¬p).
This is an easy check: p ⇒q is by deﬁnition false only when p is true and q false,
i.e., when ¬q is true and ¬p false. But this corresponds precisely to the falsehood
of ¬q ⇒¬p. Therefore we have established the following inference rule: in order
to prove that the truth of p implies the truth of q, one may assume that the
conclusion q is false and deduce from it the falsehood of the assumption p. To
prove for instance the implication ‘if a natural number is odd, then 10 does not
divide it’, we may suppose that the given number is a multiple of 10 and (easily)
deduce that the number must be even.
A second inference rule is the so-called proof by contradiction, which we will
sometimes use in the textbook. This is expressed by
(p ⇒q)
⇐⇒
(p ∧¬q ⇒¬p).
In order to prove the implication p ⇒q one can proceed as follows: suppose p is
true and the conclusion q is false, and try to prove the initial hypothesis p false.
Since p is also true, we obtain a self-contradictory statement.
A more general form of the proof by contradiction is given by the formula
(p ⇒q)
⇐⇒
(p ∧¬q ⇒r ∧¬r),
where r is an additional formula: the implication p ⇒q is equivalent to assuming
p true and q false, then deducing a simultaneously true and false statement r (note
that the formula r ∧¬r is always false, whichever the truth value of r).
At last, we mention a further rule of inference, called Principle of Mathematical
Induction, for which we refer to Appendix A.1, p. 427.
1.2.2 Predicates
Let us now introduce a central concept. A predicate is an assertion or property
p(x, . . .) that depends upon one or more variables x, . . . belonging to suitable sets,
and which becomes a formula (hence true or false) whenever the variables are

1.2 Elements of mathematical logic
7
ﬁxed. Let us consider an example. If x is an element of the set of natural numbers,
the assertion p(x) = ‘x is an odd number’ is a predicate: p(7) is true, p(10) false
et c. If x and y denote students of the Polytechnic of Turin, the statement p(x, y)
= ‘x and y follow the same lectures’ is a predicate.
Observe that the aforementioned logic operations can be applied to predicates
as well, and give rise to new predicates (e.g., ¬p(x), p(x) ∨q(x) and so on). This
fact, by the way, establishes a precise relation among the essential connectives
¬, ∧, ∨and the set-theoretical operations of taking complements, intersection and
union. In fact, recalling the deﬁnition A = {x ∈X | p(x)} of subset of a given
set X, the ‘characteristic property’ p(x) of the elements of A is nothing else but
a predicate, which is true precisely for the elements of A. The complement CA is
thus obtained by negating the characteristic property
CA = {x ∈X | ¬p(x)},
while the intersection and union of A with another subset B = {x ∈X | q(x)} are
described respectively by the conjuction and the disjunction of the corresponding
characteristic properties:
A ∩B = {x ∈X | p(x) ∧q(x)},
A ∪B = {x ∈X | p(x) ∨q(x)}.
The properties of the set-theoretical operations recalled in the previous section
translate into similar properties enjoyed by the logic operations, which the reader
can easily write down.
1.2.3 Quantiﬁers
Given a predicate p(x), with the variable x belonging to a certain set X, one is
naturally lead to ask whether p(x) is true for all elements x, or if there exists at
least one element x making p(x) true. When posing such questions we are actually
considering the formulas
∀x, p(x)
(read ‘for all x, p(x) holds’ )
and
∃x, p(x)
(read ‘there exists at least one x, such that p(x) holds’ ).
If indicating the set to which x belongs becomes necessary, one writes ‘∀x ∈
X, p(x)’ and ‘∃x ∈X, p(x)’. The symbol ∀(‘for all’) is called universal quan-
tiﬁer, and the symbol ∃(‘there exists at least’) is said existential quantiﬁer.
(Sometimes a third quantiﬁer is used, ∃!, which means ‘there exists one and only
one element’ or ‘there exists a unique’.)
We wish to stress that putting a quantiﬁer in front of a predicate transforms
the latter in a formula, whose truth value may be then determined. The predicate

8
1 Basic notions
p(x) = ‘x is strictly less than 7’ for example, yields the false formula ‘∀x ∈N, p(x)’
(since p(8) is false, for example), while ‘∃x ∈N, p(x)’ is true (e.g., x = 6 satisﬁes
the assertion).
The eﬀect of negation on a quantiﬁed predicate must be handled with attention.
Suppose for instance x indicates the generic student of the Polytechnic, and let p(x)
= ‘x is an Italian citizen’. The formula ‘∀x, p(x)’ (‘every student of the Polytechnic
has Italian citizenship’) is false. Therefore its negation ‘¬(∀x, p(x))’ is true, but
beware: the latter does not state that all students are foreign, rather that ‘there
is at least one student who is not Italian’. Thus the negation of ‘∀x, p(x)’ is
‘∃x, ¬p(x)’. We can symbolically write
¬(∀x, p(x))
⇐⇒
∃x, ¬p(x).
Similarly, it is not hard to convince oneself of the logic equivalence
¬(∃x, p(x))
⇐⇒
∀x, ¬p(x).
If a predicate depends upon two or more arguments, each of them may be
quantiﬁed. Yet the order in which the quantiﬁers are written can be essential.
Namely, two quantiﬁers of the same type (either universal or existential) can be
swapped without modifying the truth value of the formula; in other terms
∀x ∀y, p(x, y)
⇐⇒
∀y ∀x, p(x, y),
∃x ∃y, p(x, y)
⇐⇒
∃y ∃x, p(x, y).
On the contrary, exchanging the places of diﬀerent quantiﬁers usually leads to
diﬀerent formulas, so one should be very careful when ordering quantiﬁers.
As an example, consider the predicate p(x, y) = ‘x ≥y’, with x, y varying in the
set of natural numbers. The formula ‘∀x ∀y, p(x, y)’ means ‘given any two natural
numbers, each one is greater or equal than the other’, clearly a false statement.
The formula ‘∀x ∃y, p(x, y)’, meaning ‘given any natural number x, there is a
natural number y smaller or equal than x’, is true, just take y = x for instance.
The formula ‘∃x ∀y, p(x, y)’ means ‘there is a natural number x greater or equal
than each natural number’, and is false: each natural number x admits a successor
x + 1 which is strictly bigger than x. Eventually, ‘∃x ∃y, p(x, y)’ (‘there are at
least two natural numbers such that one is bigger or equal than the other’) holds
trivially.
1.3 Sets of numbers
Let us brieﬂy examine the main sets of numbers used in the book. The discussion
is on purpose not exhaustive, since the main properties of these sets should already
be known to the reader.

1.3 Sets of numbers
9
The set N of natural numbers. This set has the numbers 0, 1, 2, . . . as elements.
The operations of sum and product are deﬁned on N and enjoy the well-known
commutative, associative and distributive properties. We shall indicate by N+ the
set of natural numbers diﬀerent from 0
N+ = N \ {0}.
A natural number n is usually represented in base 10 by the expansion n = ck10k+
ck−110k−1 + · · · + c110 + c0, where the ci’s are natural numbers from 0 to 9 called
decimal digits; the expression is unique if one assumes ck ̸= 0 when n ̸= 0. We
shall write n = (ckck−1 . . . c1c0)10, or more easily n = ckck−1 . . . c1c0. Any natural
number ≥2 may be taken as base, instead of 10; a rather common alternative is
2, known as binary base.
Natural numbers can also be represented geometrically as points on a straight
line. For this it is suﬃcient to ﬁx a ﬁrst point O on the line, called origin, and
associate it to the number 0, and then choose another point P diﬀerent from
O, associated to the number 1. The direction of the line going from O to P is
called positive direction, while the length of the segment OP is taken as unit for
measurements. By marking multiples of OP on the line in the positive direction
we obtain the points associated to the natural numbers (see Fig. 1.4).
The set Z of integer numbers. This set contains the numbers 0, +1, −1,
+2, −2, . . . (called integers). The set N can be identiﬁed with the subset of Z
consisting of 0, +1, +2, . . . The numbers +1, +2, . . . (−1, −2, . . .) are said positive
integers (resp. negative integers). Sum and product are deﬁned in Z, together with
the diﬀerence, which is the inverse operation to the sum.
An integer can be represented in decimal base z = ±ckck−1 . . . c1c0. The geo-
metric picture of negative integers extends that of the natural numbers to the left
of the origin (Fig. 1.4).
The set Q of rational numbers. A rational number is the quotient, or ratio,
of two integers, the second of which (denominator) is non-zero. Without loss of
generality one can assume that the denominator is positive, whence each rational
number, or rational for simplicity, is given by
r = z
n,
with z ∈Z and n ∈N+.
Moreover, one may also suppose the fraction is reduced, that is, z and n have no
common divisors. In this way the set Z is identiﬁed with the subset of rationals
O
P
0
1
2
−1
−2
5
4
Figure 1.4. Geometric representation of numbers

10
1 Basic notions
whose denominator is 1. Besides sum, product and diﬀerence, the operation of
division between two rationals is deﬁned on Q, so long as the second rational is
other than 0. This is the inverse to the product.
A rational number admits a representation in base 10 of the kind r =
±ckck−1 · · · c1c0.d1d2 · · ·, corresponding to
r = ±(ck10k + ck−110k−1 + · · · + c110 + c0 + d110−1 + d210−2 + · · ·).
The sequence of digits d1, d2, . . . written after the dot satisﬁes one and only one of
the following properties: i) all digits are 0 from a certain subscript i ≥1 onwards (in
which case one has a ﬁnite decimal expansion; usually the zeroes are not written),
or ii) starting from a certain point, a ﬁnite sequence of numbers not all zero –
called period – repeats itself over and over (inﬁnite periodic decimal expansion;
the period is written once with a line drawn on top). For example the following
expressions are decimal expansions of rational numbers
−35163
100
= −351.6300 · · · = −371.63
and
11579
925
= 12.51783783 · · · = 12.51783.
The expansion of certain rationals is not unique. If a rational number has a ﬁnite
expansion in fact, then it also has a never-ending periodic one obtained from the
former by reducing the right-most non-zero decimal digit by one unit, and adding
the period 9. The expansions 1.0 and 0.9 deﬁne the same rational number 1;
similarly, 8.357 and 8.3569 are equivalent representations of 4120
493 .
The geometric representation of a rational r = ± m
n is obtained by subdividing
the segment OP in n equal parts and copying the subsegment m times in the
positive or negative direction, according to the sign of r (see again Fig. 1.4).
The set R of real numbers. Not every point on the line corresponds to a rational
number in the above picture. This means that not all segments can be measured
by multiples and sub-multiples of the unit of length, irrespective of the choice of
this unit.
It has been known since the ancient times that the diagonal of a square is not
commensurable with the side, meaning that the length d of the diagonal is not a
rational multiple of the side’s length ℓ. To convince ourselves about this fact recall
Pythagoras’s Theorem. It considers any of the two triangles in which the diagonal
splits the square (Fig. 1.5), and states that
d2 = ℓ2 + ℓ2,
i.e.,
d2 = 2ℓ2.
0
ℓ
d
√
2ℓ
Figure 1.5. Square with side ℓand its diagonal

1.3 Sets of numbers
11
Calling p the ratio between the lengths of diagonal and side, we square d = pℓand
substitute in the last relation to obtain p2 = 2. The number p is called the square
root of 2 and it is indicated by the symbol
√
2.
Property 1.1 If the number p satisﬁes p2 = 2, it must be non-rational.
Proof.
By contradiction: suppose there exist two integers m and n, necessarily
non-zero, such that p =
m
n . Assume m, n are relatively prime. Taking
squares we obtain m2
n2 = 2, hence m2 = 2n2. Thus m2 is even, which is to
say that m is even. For a suitable natural number k then, m = 2k. Using
this in the previous relation yields 4k2 = 2n2, i.e., n2 = 2k2. Then n2,
whence also n, is even. But this contradicts the fact that m and n have no
common factor, which comes from the assumption that p is rational.
2
Another relevant example of incommensurable lengths, known for centuries,
pertains to the length of a circle measured with respect to the diameter. In this
case as well, one can prove that the lengths of circumference and diameter are
not commensurable because the proportionality factor, known by the symbol π,
cannot be a rational number.
The set of real numbers is an extension of the rationals and provides a math-
ematical model of the straight line, in the sense that each real number x can be
associated to a point P on the line uniquely, and vice versa. The former is called
the coordinate of P. There are several equivalent ways of constructing such exten-
sion. Without going into details, we merely recall that real numbers give rise to any
possible decimal expansion. Real numbers that are not rational, called irrational,
are characterised by having a non-periodic inﬁnite decimal expansion, like
√
2 = 1.4142135623731 · · ·
and
π = 3.1415926535897 · · ·
Rather than the actual construction of the set R, what is more interesting to us
are the properties of real numbers, which allow one to work with the reals. Among
these properties, we recall some of the most important ones.
i) The arithmetic operations deﬁned on the rationals extend to the reals with
similar properties.
ii) The order relation x < y of the rationals extends to the reals, again with similar
features. We shall discuss this matter more deeply in the following Sect. 1.3.1.
iii) Rational numbers are dense in the set of real numbers. This means there are
inﬁnitely many rationals sitting between any two real numbers. It also implies
that each real number can be approximated by a rational number as well
as we please. If for example r = ckck−1 · · · c1c0.d1d2 · · · didi+1 · · · has a non-
periodic inﬁnite decimal expansion, we can approximate it by the rational
qi = ckck−1 · · · c1c0.d1d2 · · · di obtained by ignoring all decimal digits past the
ith one; as i increases, the approximation of r will get better and better.

12
1 Basic notions
iv) The set of real numbers is complete. Geometrically speaking, this is equivalent
to asking that each point on the line is associated to a unique real number, as
already mentioned. Completeness guarantees for instance the existence of the
square root of 2, i.e., the solvability in R of the equation x2 = 2, as well as of
inﬁnitely many other equations, algebraic or not. We shall return to this point
in Sect. 1.3.2.
1.3.1 The ordering of real numbers
Non-zero real numbers are either positive or negative. Positive reals form the
subset R+, negative reals the subset R−. We are thus in presence of a partition
R = R−∪{0} ∪R+. The set
R∗= {0} ∪R+
of non-negative reals will also be needed. Positive numbers correspond to points
on the line lying at the right – with respect to the positive direction – of the origin.
Instead of x ∈R+, one simply writes x > 0 (‘x is bigger, or larger, than
0’); similarly, x ∈R∗will be expressed by x ≥0 (‘x is bigger or equal than 0’).
Therefore an order relation is deﬁned by
x < y
⇐⇒
y −x > 0.
This is a total ordering, i.e., given any two distinct reals x and y, one (and only
one) of the following holds: either x < y or y < x. From the geometrical point of
view the relation x < y tells that the point with coordinate x is placed at the left
of the point with coordinate y. Let us also deﬁne
x ≤y
⇐⇒
x < y
or
x = y.
Clearly, x < y implies x ≤y. For example the relations 3 ≤7 and 7 ≤7 are true,
whereas 3 ≤2 is not.
The order relation ≤(or <) interacts with the algebraic operations of sum and
product as follows:
if x ≤y and z is any real number, then x + z ≤y + z
(adding the same real number to both sides of an inequality leaves the latter
unchanged);
if x ≤y and if
 z ≥0,
then xz ≤yz,
z < 0,
then xz ≥yz
(multiplying by a non-negative number both sides of an inequality does not alter it,
while if the number is negative it inverts the inequality). Example: multiplying by
−1 the inequality −3 ≤2 gives −2 ≤3. The latter property implies the well-known

1.3 Sets of numbers
13
sign rule: the product of two numbers with alike signs is positive, the product of
two numbers of diﬀerent sign is negative.
Absolute value. Let us introduce now a simple yet important notion. Given a
real number x, one calls absolute value of x the real number
|x| =
 x
if x ≥0,
−x
if x < 0.
Thus |x| ≥0 for any x in R. For instance |5| = 5, |0| = 0, |−5| = 5. Geometrically,
|x| represents the distance from the origin of the point with coordinate x; thus,
|x −y| = |y −x| is the distance between the two points of coordinates x and y.
The following relations, easy to prove, will be useful
|x + y| ≤|x| + |y|,
for all x, y ∈R
(1.1)
(called triangle inequality) and
|xy| = |x||y|,
for all x, y ∈R.
Throughout the text we shall solve equations and inequalities involving abso-
lute values. Let us see the simplest ones. According to the deﬁnition,
|x| = 0
has the unique solution x = 0. If a is any number > 0, the equation
|x| = a
has two solutions x = a and x = −a, so
|x| = a
⇐⇒
x = ±a,
∀a ≥0.
In order to solve
|x| ≤a,
where a ≥0,
consider ﬁrst the solutions x ≥0, for which |x| = x, so that now the inequality
reads x ≤a; then consider x < 0, in which case |x| = −x, and solve −x ≤a, or
−a ≤x. To summarise, the solutions are real numbers x satisfying 0 ≤x ≤a or
−a ≤x < 0, which may be written in a shorter way as
|x| ≤a
⇐⇒
−a ≤x ≤a.
(1.2)

14
1 Basic notions
Similarly, it is easy to see that if b ≥0,
|x| ≥b
⇐⇒
x ≤−b or x ≥b.
(1.3)
The slightly more general inequality
|x −x0| ≤a,
where x0 ∈R is ﬁxed and a ≥0, is equivalent to −a ≤x−x0 ≤a; adding x0 gives
|x −x0| ≤a
⇐⇒
x0 −a ≤x ≤x0 + a.
(1.4)
In all examples we can replace the symbol ≤by < and the conclusions hold.
Intervals. The previous discussion shows that Mathematical Analysis often deals
with subsets of R whose elements lie between two ﬁxed numbers. They are called
intervals.
Deﬁnition 1.2 Let a and b be real numbers such that a ≤b. The closed
interval with end-points a, b is the set
[a, b] = {x ∈R | a ≤x ≤b}.
If a < b, one deﬁnes open interval with end-points a, b the set
(a, b) = {x ∈R | a < x < b}.
An equivalent notation is ]a, b[.
If one includes only one end-point, then the interval with end-points a, b
[a, b) = {x ∈R | a ≤x < b}
is called half-open on the right, while
(a, b] = {x ∈R | a < x ≤b}.
is half-open on the left.
a
b
a
b
Figure 1.6. Geometric representation of the closed interval [a, b] (left) and of the open
interval (a, b) (right)

1.3 Sets of numbers
15
Example 1.3
Describe the set A of elements x ∈R such that
2 ≤|x| < 5.
Because of (1.2) and (1.3), we easily have
A = (−5, −2] ∪[2, 5).
2
Intervals deﬁned by a single inequality are useful, too. Deﬁne
[a, +∞) = {x ∈R | a ≤x},
(a, +∞) = {x ∈R | a < x},
and
(−∞, b] = {x ∈R | x ≤b},
(−∞, b) = {x ∈R | x < b}.
The symbols −∞and +∞do not indicate real numbers; they allow to extend
the ordering of the reals with the convention that −∞< x and x < +∞for all
x ∈R. Otherwise said, the condition a ≤x is the same as a ≤x < +∞, so the
notation [a, +∞) is consistent with the one used for real end-points. Sometimes it
is convenient to set
(−∞, +∞) = R.
In general one says that an interval I is closed if it contains its end-points, open
if the end-points are not included. All points of an interval, apart from the end-
points, are called interior points.
Bounded sets. Let us now discuss the notion of boundedness of a set.
Deﬁnition 1.4 A subset A of R is called bounded from above if there
exists a real number b such that
x ≤b,
for all x ∈A.
Any b with this property is called an upper bound of A.
The set A is bounded from below if there is a real number a with
a ≤x,
for all x ∈A.
Every a satisfying this relation is said a lower bound of A.
At last, one calls A bounded if it is bounded from above and below.
In terms of intervals, a set is bounded from above if it is contained in an interval
of the sort (−∞, b] with b ∈R, and bounded if it is contained in an interval [a, b]
for some a, b ∈R. It is not diﬃcult to show that A is bounded if and only if there
exists a real c > 0 such that
|x| ≤c,
for all x ∈A.

16
1 Basic notions
Examples 1.5
i) The set N is bounded from below (each number a ≤0 is a lower bound), but
not from above: in fact, the so-called Archimedean property holds: for any
real b > 0, there exists a natural number n with
n > b.
(1.5)
ii) The interval (−∞, 1] is bounded from above, not from below. The interval
(−5, 12) is bounded.
iii) The set
A =

n
n + 1 | n ∈N

=

0, 1
2, 2
3, 3
4, . . .

(1.6)
is bounded, in fact 0 ≤
n
n + 1 < 1 for any n ∈N.
iv) The set B = {x ∈Q | x2 < 2} is bounded. Taking x such that |x| > 3
2 for
example, then x2 > 9
4 > 2, so x ̸∈B. Thus B ⊂[−3
2, 3
2].
2
Deﬁnition 1.6 A set A ⊂R admits a maximum if an element xM ∈A
exists such that
x ≤xM,
for any x ∈A.
The element xM (necessarily unique) is the maximum of the set A and
one denotes it by xM = max A.
The minimum of a set A, denoted by xm = min A, is deﬁned in a similar
way.
A set admitting a maximum must be bounded from above: the maximum is an
upper bound for the set, actually the smallest of all possible upper bounds, as we
shall prove. The opposite is not true: a set can be bounded from above but not
admit a maximum, like the set A of (1.6). We know already that 1 is an upper
bound for A. Among all upper bounds, 1 is privileged, being the smallest upper
bound. To convince ourselves of this fact, let us show that each real number r < 1
is not an upper bound, i.e., there is a natural number n such that
n
n + 1 > r.
The inequality is equivalent to n + 1
n
< 1
r , hence 1 + 1
n < 1
r , or 1
n < 1 −r
r
. This
is to say n >
r
1 −r , and the existence of such n follows from property (1.5). So,
1 is the smallest upper bound of A, yet not the maximum, for 1 ̸∈A: there is no
natural number n such that
n
n + 1 = 1. One calls 1 the supremum, or least upper
bound, of A and writes 1 = sup A.

1.3 Sets of numbers
17
Analogously, 2 is the smallest of upper bounds of the interval I = (0, 2), but
it does not belong to I. Thus 2 is the supremum, or least upper bound, of I,
2 = sup I.
Deﬁnition 1.7 Let A ⊂R be bounded from above. The supremum or least
upper bound of A is the smallest of all upper bounds of A, denoted by sup A.
If A ⊂R is bounded from below, one calls inﬁmum or greatest lower
bound of A the largest of all lower bounds of A. This is denoted by inf A.
The number s = sup A is characterised by two conditions:
i)
x ≤s for all x ∈A;
ii) for any real r < s, there is an x ∈A with x > r.
(1.7)
While i) tells that s is an upper bound for A, according to ii) each number smaller
than s is not an upper bound for A, rendering s the smallest among all upper
bounds.
The two conditions (1.7) must be fulﬁlled in order to show that a given number
is the supremum of a set. That is precisely what we did to claim that 1 was the
supremum of (1.6).
The notion of supremum generalises that of maximum of a set. It is immediate
to see that if a set admits a maximum, this maximum must be the supremum
as well.
If a set A is not bounded from above, one says that its supremum is +∞, i.e.,
one deﬁnes
sup A = +∞.
Similarly, inf A = −∞for a set A not bounded from below.
1.3.2 Completeness of R
The property of completeness of R may be formalised in several equivalent ways.
The reader should have already come across (Dedekind’s) separability axiom: de-
composing R into the union of two disjoint subsets C1 and C2 (the pair (C1, C2)
is called a cut) so that each element of C1 is smaller or equal than every element
in C2, there exists a (unique) separating element s ∈R:
x1 ≤s ≤x2,
∀x1 ∈C1, ∀x2 ∈C2.
An alternative formulation of completeness involves the notion of supremum of
a set: every bounded set from above admits a supremum in R, i.e., there is a real
number smaller or equal than all upper bounds of the set.
With the help of this property one can prove, for example, the existence in
R of the square root of 2, hence of a number p (> 0) such that p2 = 2. Going

18
1 Basic notions
back to Example 1.5 iv), the completeness of the reals ensures that the bounded
set B = {x ∈Q | x2 < 2} has a supremum, say p. Using the properties of R it
is possible to show that p2 < 2 cannot occur, otherwise p would not be an upper
bound for B, and neither p2 > 2 holds, for p would not be the least of all upper
bounds. Thus necessarily p2 = 2. Note that B, albeit contained in Q, is not allowed
to have a rational upper bound, because p2 = 2 prevents p from being rational
(Property 1.1).
This example explains why the completeness of R lies at the core of the pos-
sibility to solve in R many remarkable equations. We are thinking in particular
about the family of algebraic equations
xn = a,
(1.8)
where n ∈N+ and a ∈R, for which it is worth recalling the following known fact.
Property 1.8 i) Let n ∈N+ be odd. Then for any a ∈R equation (1.8) has
exactly one solution in R, denoted by x =
n√a or x = a1/n and called the nth
root of a.
ii) Let n ∈N+ be even. For any a > 0 equation (1.8) has two real solutions
with the same absolute value but opposite signs; when a = 0 there is one
solution x = 0 only; for a < 0 there are no solutions in R. The non-negative
solution is indicated by x =
n√a or x = a1/n, and called the nth (arithmetic)
root of a.
1.4 Factorials and binomial coeﬃcients
We introduce now some noteworthy integers that play a role in many areas of
Mathematics.
Given a natural number n ≥1, the product of all natural numbers between
1 and n goes under the name of factorial of n and is indicated by n! (read ‘n
factorial’). Out of conveniency one sets 0! = 1. Thus
0! = 1,
1! = 1,
n! = 1 · 2 · . . . · n = (n −1)! n
for n ≥2.
(1.9)
Factorials grow extremely rapidly as n increases; for instance 5! = 120, 10! =
3628800 and 100! > 10157.
Example 1.9
Suppose we have n ≥2 balls of diﬀerent colours in a box. In how many ways
can we extract the balls from the box?

1.4 Factorials and binomial coeﬃcients
19
When taking the ﬁrst ball we are making a choice among the n balls in the box;
the second ball will be chosen among the n −1 balls left, the third one among
n −2 and so on. Altogether we have n(n −1) · . . . · 2 · 1 = n! diﬀerent ways to
extract the balls: n! represents the number of arrangements of n distinct objects
in a sequence, called permutations of n ordered objects.
If we stop after k extractions, 0 < k < n, we end up with n(n −1) . . .(n −k + 1)
possible outcomes. The latter expression, also written as
n!
(n −k)!, is the number
of possible permutations of n distinct objects in sequences of k objects.
If we allow repeated colours, for instance by reintroducing in the box a ball of
the same colour as the one just extracted, each time we choose among n. After
k > 0 choices there are then nk possible sequences of colours: nk is the number
of permutations of n objects in sequences of k, with repetitions (i.e.,
allowing an object to be chosen more than once).
2
Given two natural numbers n and k such that 0 ≤k ≤n, one calls binomial
coeﬃcient the number
n
k

=
n!
k!(n −k)!
(1.10)
(the symbol
n
k

is usually read ‘n choose k’). Notice that if 0 < k < n
n! = 1·. . .·n = 1·. . .·(n−k)(n−k+1)·. . .·(n−1)n = (n−k)!(n−k+1)·. . .·(n−1)n,
so simplifying and rearranging the order of factors at the numerator, (1.10) be-
comes
n
k

= n(n −1) · . . . · (n −k + 1)
k!
,
(1.11)
another common expression for the binomial coeﬃcient. From deﬁnition (1.10) it
follows directly that
n
k

=

n
n −k

and
n
0

=
n
n

= 1,
n
1

=

n
n −1

= n.
Moreover, it is easy to prove that for any n ≥1 and any k with 0 < k < n
n
k

=
n −1
k −1

+
n −1
k

,
(1.12)
which provides a convenient means for computing binomial coeﬃcients recursively;
the coeﬃcients relative to n objects are easily determined once those involving
n −1 objects are computed. The same formula suggests to write down binomial

20
1 Basic notions
coeﬃcients in a triangular pattern, known as Pascal’s triangle1 (Fig. 1.7): each
coeﬃcient of a given row, except for the 1’s on the boundary, is the sum of the two
numbers that lie above it in the preceding row, precisely as (1.12) prescribes. The
construction of Pascal’s triangle shows that the binomial coeﬃcients are natural
numbers.
1
1
1
1
2
1
1
3
3
1
1
4
6
4
1
1 . . .
. . . 1
Figure 1.7. Pascal’s triangle
The term ‘binomial coeﬃcient’ originates from the power expansion of the
polynomial a + b in terms of powers of a and b. The reader will remember the
important identities
(a + b)2 = a2 + 2ab + b2
and
(a + b)3 = a3 + 3a2b + 3ab2 + b3.
The coeﬃcients showing up are precisely the binomial coeﬃcients for n = 2 and
n = 3. In general, for any n ≥0, the formula
(a + b)n = an + nan−1b + . . . +
n
k

an−kbk + . . . + nabn−1 + bn
=
n
	
k=0
n
k

an−kbk
(1.13)
holds, known as (Newton’s) binomial expansion. This formula is proven with
(1.12) using a proof by induction (see Appendix A.1, p. 428).
Example 1.9 (continuation)
Given n balls of diﬀerent colours, let us ﬁx k with 0 ≤k ≤n. How many diﬀerent
sets of k balls can we form?
Extracting one ball at a time for k times, we already know that there are
n(n −1) . . .(n −k + 1) outcomes. On the other hand the same k balls, extracted
in a diﬀerent order, will yield the same set. Since the possible orderings of k
elements are k!, we see that the number of distinct sets of k balls chosen from n
is n(n −1) · . . . · (n −k + 1)
k!
=
n
k

. This coeﬃcient represents the number of
combinations of n objects taken k at a time. Equivalently, the number of
subsets of k elements of a set of cardinality n.
1 Sometimes the denomination Tartaglia’s triangle appears.

1.5 Cartesian product
21
Formula (1.13) with a = b = 1 shows that the sum of all binomial coeﬃcients
with n ﬁxed equals 2n, non-incidentally also the total number of subsets of a set
with n elements.
2
1.5 Cartesian product
Let X, Y be non-empty sets. Given elements x in X and y in Y , we construct the
ordered pair of numbers
(x, y),
whose ﬁrst component is x and second component is y. An ordered pair is concep-
tually other than a set of two elements. As the name says, in an ordered pair the
order of the components is paramount. This is not the case for a set. If x ̸= y the
ordered pairs (x, y) and (y, x) are distinct, while {x, y} and {y, x} coincide as sets.
The set of all ordered pairs (x, y) when x varies in X and y varies in Y is the
Cartesian product of X and Y , which is indicated by X × Y . Mathematically,
X × Y = {(x, y) | x ∈X, y ∈Y }.
The Cartesian product is represented using a rectangle, whose basis corres-
ponds to the set X and whose height is Y (as in Fig. 1.8).
If the sets X, Y are diﬀerent, the product X × Y will not be equal to Y × X,
in other words the Cartesian product is not commutative.
But if Y = X, it is customary to put X × X = X2 for brevity. In this case the
subset of X2
Δ = {(x, y) ∈X2 | x = y}
of pairs with equal components is called the diagonal of the Cartesian product.
X
Y
x
y
X × Y
(x, y)
Figure 1.8. Cartesian product of sets

22
1 Basic notions
The most signiﬁcant example of Cartesian product stems from X = Y = R. The
set R2 consists of ordered pairs of real numbers. Just as the set R mathematically
represents a straight line, so R2 is a model of the plane (Fig. 1.9, left). In order
to deﬁne this correspondence, choose a straight line in the plane and ﬁx on it an
origin O, a positive direction and a length unit. This shall be the x-axis. Rotating
this line counter-clockwise around the origin by 90o generates the y-axis. In this
way we have now an orthonormal frame (we only mention that it is sometimes
useful to consider frames whose axes are not orthogonal, and/or the units on the
axes are diﬀerent).
Given any point P on the plane, let us draw the straight lines parallel to the
axes passing through the point. Denote by x the real number corresponding to the
intersection of the x-axis with the parallel to the y-axis, and by y the real number
corresponding to the intersection of the y-axis with the parallel to the x-axis. An
ordered pair (x, y) ∈R2 is thus associated to each point P on the plane, and vice
versa. The components of the pair are called (Cartesian) coordinates of P in the
chosen frame.
The notion of Cartesian product can be generalised to the product of more
sets. Given n non-empty sets X1, X2, . . . , Xn, one considers ordered n−tuples
(x1, x2, . . . , xn)
where, for every i = 1, 2, . . . , n, each component xi lives in the set Xi. The
Cartesian product X1 × X2 × . . . × Xn is then the set of all such n−tuples.
When X1 = X2 = . . . = Xn = X one simply writes X × X × . . . × X = Xn.
In particular, R3 is the set of triples (x, y, z) of real numbers, and represents a
mathematical model of three-dimensional space (Fig. 1.9, right).
x
y
(x, y)
x
y
z
(x, y, z)
Figure 1.9. Models of the plane (left) and of space (right)

1.6 Relations in the plane
23
1.6 Relations in the plane
We call Cartesian plane a plane equipped with an orthonormal Cartesian frame
built as above, which we saw can be identiﬁed with the product R2.
Every non-empty subset R of R2 deﬁnes a relation between real numbers;
precisely, one says x is R-related to y, or x is related to y by R, if the ordered
pair (x, y) belongs to R. The graph of the relation is the set of points in the plane
whose coordinates belong to R.
A relation is commonly deﬁned by one or more (in)equalities involving the
variables x and y. The subset R is then deﬁned as the set of pairs (x, y) such that
x and y satisfy the constraints. Finding R often means determining its graph in
the plane. Let us see some examples.
Examples 1.10
i) An equation like
ax + by = c,
with a, b constant and not both vanishing, deﬁnes a straight line. If b = 0, the line
is parallel to the y-axis, whereas a = 0 yields a parallel to the x-axis. Assuming
b ̸= 0 we can write the equation as
y = mx + q,
where m = −a
b and q = c
b. The number m is called slope of the line. The line
can be plotted by ﬁnding the coordinates of two points that belong to it, hence
two distinct pairs (x, y) solving the equation. In particular c = 0 (or q = 0) if
and only if the origin belongs to the line. The equation x −y = 0 for example
deﬁnes the bisectrix of the ﬁrst and third quadrants of the plane.
ii) Replacing the ‘=’ sign by ‘<’ above, consider the inequality
ax + by < c.
It deﬁnes one of the half-planes in which the straight line of equation ax+by = c
divides the plane (Fig. 1.10). If b > 0 for instance, the half-plane below the line
is obtained. This set is open, i.e., it does not contain the straight line, since the
inequality is strict. The inequality ax + by ≤c deﬁnes instead a closed set, i.e.,
including the line.
x + 2y = 2
x + 2y < 2
0
1
2
Figure 1.10. Graph of the relation of Example 1.10 ii)

24
1 Basic notions
iii) The system
 y > 0,
x −y ≥0,
deﬁnes the intersection between the open half-plane above the x-axis and the
closed half-plane lying below the bisectrix of the ﬁrst and third quadrants. Thus
the system describes (Fig. 1.11, left) the wedge between the positive x-axis and
the bisectrix (the points on the x-axis are excluded).
iv) The inequality
|x −y| < 2
is equivalent, recall (1.2), to
−2 < x −y < 2.
The inequality on the left is in turn equivalent to y < x+2, so it deﬁnes the open
half-plane below the line y = x + 2; similarly, the inequality on the right is the
same as y > x−2 and deﬁnes the open half-plane above the line y = x−2. What
we get is therefore the strip between the two lines, these excluded (Fig. 1.11,
right).
v) By Pythagoras’s Theorem, the equation
x2 + y2 = 1
deﬁnes the set of points P in the plane with distance 1 from the origin of the
axes, that is, the circle centred at the origin with radius 1 (in trigonometry it
goes under the name of unit circle). The inequality
x2 + y2 ≤1
then deﬁnes the disc bounded by the unit circle (Fig. 1.12, left).
vi) The equation
y = x2
yields the parabola with vertical axis, vertex at the origin and passing through
the point P of coordinates (1, 1).
x −y = 0
y = 0
y = x + 2
y = x −2
Figure 1.11. Graphs of the relations of Examples 1.10 iii) (left) and 1.10 iv) (right)

1.7 Exercises
25
x2 + y2 = 1
1
1
1
y = 1
y = x2
0
Figure 1.12. Graphs of the relations in Examples 1.10 v) (left) and 1.10 vi) (right)
Thus the inequalities
x2 ≤y ≤1
deﬁne the region enclosed by the parabola and by the straight line given by y = 1
(Fig. 1.12, right).
2
1.7 Exercises
1. Solve the following inequalities:
a)
2x −1
x −3 > 0
b)
1 −7x
3x + 5 > 0
c)
x −1
x −2 > 2x −3
x −3
d)
|x|
x −1 > x + 1
2x −1
e)
2x + 3
x + 5 ≤x + 1
|x −1|
f)
√
x2 −6x > x + 2
g)
x −3 ≤

x2 −2x
h)
x + 3
(x + 1)2√
x2 −3
≥0
i)

|x2 −4| −x ≥0
ℓ)
x

|x2 −4|
x2 −4
−1 > 0
2. Describe the following subsets of R:
a)
A = {x ∈R : x2 + 4x + 13 < 0} ∩{x ∈R : 3x2 + 5 > 0}
b)
B = {x ∈R : (x + 2)(x −1)(x −5) < 0} ∩{x ∈R : 3x + 1
x −2 ≥0}
c)
C = {x ∈R : x2 −5x + 4
x2 −9
< 0} ∪{x ∈R :
√
7x + 1 + x = 17}
d)
D = {x ∈R : x −4 ≥
√
x2 −6x + 5} ∪{x ∈R : x + 2 > √x −1}

26
1 Basic notions
3. Determine and draw a picture of the following subsets of R2:
a)
A = {(x, y) ∈R2 : xy ≥0}
b) B = {(x, y) ∈R2 : x2 −y2 > 0}
c)
C = {(x, y) ∈R2 : |y −x2| < 1}
d) D = {(x, y) ∈R2 : x2 + y2
4 ≥1}
e)
E = {(x, y) ∈R2 : 1 + xy > 0}
f) F = {(x, y) ∈R2 : x −y ̸= 0}
4. Tell whether the following subsets of R are bounded from above and/or below,
specifying upper and lower bounds, plus maximum and minimum (if existent):
a)
A = {x ∈R : x = n or x = 1
n2 , n ∈N \ {0}}
b)
B = {x ∈R : −1 < x ≤1 or x = 20}
c)
C = {x ∈R : 0 ≤x < 1 or x = 2n −3
n −1 , n ∈N \ {0, 1}}
d)
D = {z ∈R : z = xy with x, y ∈R, −1 ≤x ≤2, −3 ≤y < −1}
1.7.1 Solutions
1. Inequalities:
a) This is a fractional inequality. A fraction is positive if and only if numerator
and denominator have the same sign. As N(x) = 2x −1 > 0 if x > 1/2, and
D(x) = x −3 > 0 for x > 3, the inequality holds when x < 1/2 or x > 3.
b) −5
3 < x < 1
7.
c) Shift all terms to the left and simplify:
x −1
x −2 −2x −3
x −3 > 0 ,
i.e.,
−x2 + 3x −3
(x −2)(x −3) > 0 .
The roots of the numerator are not real, so N(x) < 0 always. The inequality
thus holds when D(x) < 0, hence 2 < x < 3.
d) Moving terms to one side and simplifying yields:
|x|
x −1 −x + 1
2x −1 > 0 ,
i.e.,
|x|(2x −1) −x2 + 1
(x −1)(2x −1)
> 0 .
Since |x| = x for x ≥0 and |x| = −x for x < 0, we study the two cases
separately.
When x ≥0 the inequality reads
2x2 −x −x2 + 1
(x −1)(2x −1) > 0 ,
or
x2 −x + 1
(x −1)(2x −1) > 0 .

1.7 Exercises
27
The numerator has no real roots, hence x2 −x + 1 > 0 for all x. Therefore
the inequality is satisﬁed if the denominator is positive. Taking the constrain
x ≥0 into account, this means 0 ≤x < 1/2 or x > 1.
When x < 0 we have
−2x2 + x −x2 + 1
(x −1)(2x −1)
> 0 ,
i.e.,
−3x2 + x + 1
(x −1)(2x −1) > 0 .
N(x) is annihilated by x1 = 1−
√
13
6
and x2 = 1+
√
13
6
, so N(x) > 0 for x1 < x <
x2 (notice that x1 < 0 and x2 ∈( 1
2, 1)). As above the denominator is positive
when x < 1/2 and x > 1. Keeping x < 0 in mind, we have x1 < x < 0.
The initial inequality is therefore satisﬁed by any x ∈(x1, 1
2) ∪(1, +∞).
e) −5 < x ≤−2, −1
3 ≤x < 1, 1 < x ≤5+
√
57
2
;
f) x < −2
5.
g) First of all observe that the right-hand side is always ≥0 where deﬁned, hence
when x2 −2x ≥0, i.e., x ≤0 or x ≥2. The inequality is certainly true if the
left-hand side x −3 is ≤0, so for x ≤3.
If x −3 > 0, we take squares to obtain
x2 −6x + 9 ≤x2 −2x ,
i.e.,
4x ≥9 ,
whence
x ≥9
4 .
Gathering all information we conclude that the starting inequality holds
wherever it is deﬁned, that is for x ≤0 and x ≥2.
h) x ∈[−3, −
√
3) ∪(
√
3, +∞).
i) As |x2 −4| ≥0,

|x2 −4| is well deﬁned. Let us write the inequality in the
form

|x2 −4| ≥x .
If x ≤0 the inequality is always true, for the left-hand side is positive. If x > 0
we square:
|x2 −4| ≥x2 .
Note that
|x2 −4| =
 x2 −4
if x ≤−2 or x ≥2,
−x2 + 4
if −2 < x < 2 .
Consider the case x ≥2 ﬁrst; the inequality becomes x2 −4 ≥x2, which is
never true.
Let now 0 < x < 2; then −x2 + 4 ≥x2, hence x2 −2 ≤0. Thus 0 < x ≤
√
2
must hold.
In conclusion, the inequality holds for x ≤
√
2.
ℓ) x ∈(−2, −
√
2) ∪(2, +∞).
2. Subsets of R:
a) Because x2 + 4x + 13 = 0 cannot be solved over the reals, the condition
x2 + 4x + 13 < 0 is never satisﬁed and the ﬁrst set is empty. On the other
hand, 3x2 + 5 > 0 holds for every x ∈R, therefore the second set is the whole
R. Thus A = ∅∩R = ∅.

28
1 Basic notions
b) B = (−∞, −2) ∪(2, 5).
c) We can write
x2 −5x + 4
x2 −9
= (x −4)(x −1)
(x −3)(x + 3) ,
whence the ﬁrst set is (−3, 1) ∪(3, 4).
To ﬁnd the second set, let us solve the irrational equation √7x + 1 + x = 17,
which we write as √7x + 1 = 17−x. The radicand must necessarily be positive,
hence x ≥−1
7. Moreover, a square root is always ≥0, so we must impose
17 −x ≥0, i.e., x ≤17. Thus for −1
7 ≤x ≤17, squaring yields
7x + 1 = (17 −x)2 ,
x2 −41x + 288 = 0 .
The latter equation has two solutions x1 = 9, x2 = 32 (which fails the con-
straint x ≤17, and as such cannot be considered). The second set then contains
only x = 9.
Therefore C = (−3, 1) ∪(3, 4) ∪{9}.
d) D = [1, +∞).
3. Subsets of R2:
a) The condition holds if x and y have equal signs, thus in the ﬁrst and third
quadrants including the axes (Fig. 1.13, left).
b) See Fig. 1.13, right.
c) We have
|y −x2| =
 y −x2
if y ≥x2 ,
x2 −y
if y ≤x2 .
Demanding y ≥x2 means looking at the region in the plane bounded from
below by the parabola y = x2. There, we must have
y −x2 < 1 ,
i.e.,
y < x2 + 1 ,
x = y
x = −y
Figure 1.13. The sets A and B of Exercise 3

1.7 Exercises
29
y = x2 −1
y = x2 + 1
y = x2
1
−1
1
2
x2 + y2
4 = 1
Figure 1.14. The sets C and D of Exercise 3
that is x2 ≤y < x2 + 1.
Vice versa if y < x2,
x2 −y < 1 ,
i.e.,
y > x2 −1 ,
hence x2 −1 < y ≤x2.
Eventually, the required region is conﬁned by (though does not include) the
parabolas y = x2 −1 and y = x2 + 1 (Fig. 1.14, left).
d) See Fig. 1.14, right.
e) For x > 0 the condition 1 + xy > 0 is the same as y > −1
x. Thus we consider
all points of the ﬁrst and third quadrants above the hyperbola y = −1
x.
For x < 0, 1+ xy > 0 means y < −1
x, satisﬁed by the points in the second and
fourth quadrants this time, lying below the hyperbola y = −1
x.
At last, if x = 0, 1 + xy > 0 holds for any y, implying that the y-axis belongs
to the set E.
Therefore: the region lies between the two branches of the hyperbola (these
are not part of E) y = −1
x, including the y-axis (Fig. 1.15, left).
f) See Fig. 1.15, right.
xy = −1
xy = −1
x = y
Figure 1.15. The sets E and F of Exercise 3

30
1 Basic notions
4. Bounded and unbounded sets:
a) We have A = {1, 2, 3, . . ., 1
4, 1
9, 1
16, . . .}. Since N \ {0} ⊂A, the set A is not
bounded from above, hence sup A = +∞and there is no maximum.
In addition, the fact that every element of A is positive makes A bounded from
below. We claim that 0 is the greatest lower bound of A. In fact, if r > 0 were
a lower bound of A, then
1
n2 > r for any non-zero n ∈N. This is the same as
n2 < 1
r, hence n <
1
√r. But the last inequality is absurd since natural numbers
are not bounded from above. Finally 0 /∈A, so we conclude inf A = 0 and A
has no minimum.
b) inf B = −1, sup B = max B = 20, and min B does not exist.
c) C = [0, 1] ∪{ 3
2, 5
3, 7
4, 9
5, . . .} ⊂[0, 2); then C is bounded, and inf C = min C =
0. Since 2n −3
n −1 = 2 −
1
n −1, it is not hard to show that sup C = 2, although
there is no maximum in C.
d) inf C = min C = −6, sup B = max B = 3.

2
Functions
Functions crop up regularly in everyday life (for instance: each student of the
Polytechnic of Turin has a unique identiﬁcation number), in physics (to each point
of a region in space occupied by a ﬂuid we may associate the velocity of the particle
passing through that point at a given moment), in economy (each working day at
Milan’s stock exchange is tagged with the Mibtel index), and so on.
The mathematical notion of a function subsumes all these situations.
2.1 Deﬁnitions and ﬁrst examples
Let X and Y be two sets. A function f deﬁned on X with values in Y is
a correspondence associating to each element x ∈X at most one element y ∈Y .
This is often shortened to ‘a function from X to Y ’. A synonym for function is
map. The set of x ∈X to which f associates an element in Y is the domain of
f; the domain is a subset of X, indicated by dom f. One writes
f : dom f ⊆X →Y.
If dom f = X, one says that f is deﬁned on X and writes simply f : X →Y .
The element y ∈Y associated to an element x ∈dom f is called the image of
x by or under f and denoted y = f(x). Sometimes one writes
f : x →f(x).
The set of images y = f(x) of all points in the domain constitutes the range of
f, a subset of Y indicated by im f.
The graph of f is the subset Γ(f) of the Cartesian product X × Y made of
pairs (x, f(x)) when x varies in the domain of f, i.e.,
Γ(f) =

(x, f(x)) ∈X × Y
: x ∈dom f

.
(2.1)
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_2,
© Springer International Publishing Switzerland 2015

32
2 Functions
X
Y
x
y = f(x)
f
dom f
im f
x′
Figure 2.1. Naive representation of a function using Venn diagrams
In the sequel we shall consider maps between sets of numbers most of the time.
If Y = R, the function f is said real or real-valued. If X = R, the function is
of one real variable. Therefore the graph of a real function is a subset of the
Cartesian plane R2.
A remarkable special case of map arises when X = N and the domain contains
a set of the type {n ∈N : n ≥n0} for a certain natural number n0 ≥0. Such a
function is called sequence. Usually, indicating by a the sequence, it is preferable
to denote the image of the natural number n by the symbol an rather than a(n);
thus we shall write a : n →an. A common way to denote sequences is {an}n≥n0
(ignoring possible terms with n < n0) or even {an}.
Examples 2.1
Let us consider examples of real functions of real variable.
i) f : R →R, f(x) = ax + b (a, b real coeﬃcients), whose graph is a straight line
(Fig. 2.2, top left).
ii) f : R →R, f(x) = x2, whose graph is a parabola (Fig. 2.2, top right).
iii) f : R\{0} ⊂R →R, f(x) = 1
x, has a rectangular hyperbola in the coordinate
system of its asymptotes as graph (Fig. 2.2, bottom left).
iv) A real function of a real variable can be deﬁned by multiple expressions on
diﬀerent intervals, in which case is it called a piecewise function. An example
is given by f : [0, 3] →R
f(x) =
⎧
⎨
⎩
3x
if 0 ≤x ≤1,
4 −x
if 1 < x ≤2,
x −1
if 2 < x ≤3,
(2.2)
drawn in Fig. 2.2, bottom right.

2.1 Deﬁnitions and ﬁrst examples
33
0
1
−2
0
1
−2
−1
2
4
1
1
−1 1
−1
0
1
2
3
1
2
3
Figure 2.2. Graphs of the maps f(x) = 2x−2 (top left), f(x) = x2 (top right), f(x) = 1
x
(bottom left) and of the piecewise function (2.2) (bottom right)
Among piecewise functions, the following are particularly important:
v) the absolute value (Fig. 2.3, top left)
f : R →R,
f(x) = |x| =
 x
if x ≥0,
−x
if x < 0;
vi) the sign (Fig. 2.3, top right)
f : R →Z,
f(x) = sign(x) =
⎧
⎨
⎩
+1
if x > 0,
0
if x = 0,
−1
if x < 0;
vii) the integer part (Fig. 2.3, bottom left), also known as ﬂoor function,
f : R →Z,
f(x) = [x] = the greatest integer ≤x
(for example, [4] = 4, [
√
2] = 1, [−1] = −1, [−3
2] = −2); notice that
[x] ≤x < [x] + 1 ,
∀x ∈R ;

34
2 Functions
0
0
1
−1
0
1
−1
−2
2
3
1
2
−1
−2
1
2
3
−1
−2
1
0
Figure 2.3. Clockwise from top left: graphs of the functions: absolute value, sign, man-
tissa and integer part
viii) the mantissa (Fig. 2.3, bottom right)
f : R →R,
f(x) = M(x) = x −[x]
(the property of the ﬂoor function implies 0 ≤M(x) < 1).
Let us give some examples of sequences now.
ix) The sequence
an =
n
n + 1
(2.3)
is deﬁned for all n ≥0. The ﬁrst few terms read
a0 = 0 ,
a1 = 1
2 = 0.5 ,
a2 = 2
3 = 0.6 ,
a3 = 3
4 = 0.75 .
Its graph is shown in Fig. 2.4 (top left).
x) The sequence
an =

1 + 1
n
n
(2.4)
is deﬁned for n ≥1. The ﬁrst terms are
a1 = 2 ,
a2 = 9
4 = 2.25 ,
a3 = 64
27 = 2.37037,
a4 = 625
256 = 2.44140625 .
Fig. 2.4 (top right) shows the graph of such sequence.

2.1 Deﬁnitions and ﬁrst examples
35
0
1
2
3
4
5
6
1
0
1
2
3
4
5
6
2
3
0
1
2
3
4
5
6
24
120
0
1
2
3
4
5
6
1
−1
Figure 2.4. Clockwise: graphs of the sequences (2.3), (2.4), (2.6), (2.5)
xi) The sequence
an = n!
(2.5)
associates to each natural number its factorial, deﬁned in (1.9). The graph of
this sequence is shown in Fig. 2.4 (bottom left); as the values of the sequence
grow rapidly as n increases, we used diﬀerent scalings on the coordinate axes.
xii) The sequence
an = (−1)n =
 +1
if n is even,
−1
if n is odd,
(n ≥0)
(2.6)
has alternating values +1 and −1, according to the parity of n. The graph of the
sequence is shown in Fig. 2.4 (bottom right).
At last, here are two maps deﬁned on R2 (functions of two real variables).
xiii) The function
f : R2 →R,
f(x, y) =

x2 + y2
maps a generic point P of the plane with coordinates (x, y) to its distance from
the origin.
xiv) The map
f : R2 →R2,
f(x, y) = (y, x)
associates to a point P the point P ′ symmetric to P with respect to the bisectrix
of the ﬁrst and third quadrants.
2

36
2 Functions
Consider a map from X to Y . One should take care in noting that the symbol
for an element of X (to which one refers as the independent variable) and the
symbol for an element in Y (dependent variable), are completely arbitary. What
really determines the function is the way of associating each element of the domain
to its corresponding image. For example, if x, y, z, t are symbols for real numbers,
the expressions y = f(x) = 3x, x = f(y) = 3y, or z = f(t) = 3t denote the same
function, namely the one mapping each real number to its triple.
2.2 Range and pre-image
Let A be a subset of X. The image of A under f is the set
f(A) = {f(x) : x ∈A} ⊆im f
of all the images of elements of A. Notice that f(A) is empty if and only if A
contains no elements of the domain of f. The image f(X) of the whole set X is
the range of f, already denoted by im f.
Let y be any element of Y ; the pre-image of y by f is the set
f −1(y) = {x ∈dom f : f(x) = y}
of elements in X whose image is y. This set is empty precisely when y does not
belong to the range of f. If B is a subset of Y , the pre-image of B under f is
deﬁned as the set
f −1(B) = {x ∈dom f : f(x) ∈B},
union of all pre-images of elements of B.
It is easy to check that A ⊆f −1(f(A)) for any subset A of dom f, and
f(f −1(B)) = B ∩im f ⊆B for any subset B of Y .
Example 2.2
Let f : R →R, f(x) = x2. The image under f of the interval A = [1, 2] is the
interval B = [1, 4]. Yet the pre-image of B under f is the union of the intervals
[−2, −1] and [1, 2], namely, the set
f −1(B) = {x ∈R : 1 ≤|x| ≤2}
(see Fig. 2.5).
2
The notions of inﬁmum, supremum, maximum and minimum, introduced in
Sect. 1.3.1, specialise in the case of images of functions.

2.2 Range and pre-image
37
1
2
1
0
4
y = f(x)
A
f(A)
1
2
1
4
−2
−1
y = f(x)
B
f −1(B)
Figure 2.5. Image (left) and pre-image (right) of an interval relative to the function
f(x) = x2
Deﬁnition 2.3 Let f be a real map and A a subset of dom f. One calls
supremum of f on A (or in A) the supremum of the image of A under f
sup
x∈A
f(x) = sup f(A) = sup{f(x) | x ∈A}.
Then f is bounded from above on A if the set f(A) is bounded from above,
or equivalently, if sup
x∈A
f(x) < +∞.
If sup
x∈A
f(x) is ﬁnite and belongs to f(A), then it is the maximum of this set.
This number is the maximum value (or simply, the maximum) of f on
A and is denoted by max
x∈A f(x).
The concepts of inﬁmum and of minimum of f on A are deﬁned similarly.
Eventually, f is said bounded on A if the set f(A) is bounded.
At times, the shorthand notations supA f, maxA f, et c. are used.
The maximum value M = maxA f of f on the set A is characterised by the
conditions:
i) M is a value assumed by the function on A, i.e.,
there exists xM ∈A such that f(xM) = M;
ii) M is greater or equal than any other value of the map on A, so
for any x ∈A, f(x) ≤M.
Example 2.4
Consider the function f(x) deﬁned in (2.2). One veriﬁes easily
max
x∈[0,2] f(x) = 3,
min
x∈[0,2] f(x) = 0,
max
x∈[1,3]f(x) = 3,
inf
x∈[1,3] f(x) = 1.
The map does not assume the value 1 anywhere in the interval [1, 3], so there is
no minimum on that set.
2

38
2 Functions
2.3 Surjective and injective functions; inverse function
A map with values in Y is called onto if im f = Y . This means that each y ∈Y
is the image of one element x ∈X at least. The term surjective (on Y ) has the
same meaning. For instance, f : R →R, f(x) = ax + b with a ̸= 0 is surjective
on R, or onto: the real number y is the image of x = y−b
a . On the contrary, the
function f : R →R, f(x) = x2 is not onto, because its range coincides with the
interval [0, +∞).
A function f is called one-to-one (or 1-1) if every y ∈im f is the image of a
unique element x ∈dom f. Otherwise put, if y = f(x1) = f(x2) for some elements
x1, x2 in the domain of f, then necessarily x1 = x2. This, in turn, is equivalent to
x1 ̸= x2
⇒
f(x1) ̸= f(x2)
for all x1, x2 ∈dom f (see Fig. 2.6). Again, the term injective may be used. If a
map f is one-to-one, we can associate to each element y in the range the unique x
in the domain with f(x) = y. Such correspondence determines a function deﬁned
on Y and with values in X, called inverse function of f and denoted by the
symbol f −1. Thus
x = f −1(y)
⇐⇒
y = f(x)
(the notation mixes up deliberately the pre-image of y under f with the unique
element this set contains). The inverse function f −1 has the image of f as its
domain, and the domain of f as range:
dom f −1 = im f,
im f −1 = dom f.
X
Y
x1
y1 = f(x1)
x2
y2 = f(x2)
f
f −1
f
f −1
dom f
im f
Figure 2.6. Representation of a one-to-one function and its inverse

2.3 Surjective and injective functions; inverse function
39
A one-to-one map is therefore invertible; the two notions (injectivity and invert-
ibility) coincide.
What is the link between the graphs of f, deﬁned in (2.1), and of the inverse
function f −1? One has
Γ(f −1) = {

y, f −1(y)

∈Y × X : y ∈dom f −1}
= {(f(x), x) ∈Y × X : x ∈dom f}.
Therefore, the graph of the inverse map may be obtained from the graph of f by
swapping the components in each pair. For real functions of one real variable, this
corresponds to a reﬂection in the Cartesian plane with respect to the bisectrix
y = x (see Fig. 2.7: a) is reﬂected into b)). On the other hand, ﬁnding the explicit
expression x = f −1(y) of the inverse function could be hard, if possible at all.
Provided that the inverse map in the form x = f −1(y) can be determined, often
one prefers to denote the independent variable (of f −1) by x, and the dependent
variable by y, thus obtaining the expression y = f −1(x). This is merely a change
of notation (see the remark at the end of Sect. 2.1). The procedure allows to draw
the graph of the inverse function in the same frame system of f (see Fig. 2.7, from
b) to c)).
a)
x
y
y = f(x)
y = x
dom f
im f
b)
x
y
y = x
x = f −1(y)
dom f
im f
c)
x
y
y = x
y = f −1(x)
dom f −1
im f −1
Figure 2.7. From the graph of a function to the graph of its inverse

40
2 Functions
Examples 2.5
i) The function f : R →R, f(x) = ax + b is one-to-one for all a ̸= 0 (in fact,
f(x1) = f(x2) ⇒ax1 = ax2 ⇒x1 = x2). Its inverse is x = f −1(y) = y−b
a , or
y = f −1(x) = x−b
a .
ii) The map f : R →R, f(x) = x2 is not one-to-one because f(x) = f(−x) for
any real x. Yet if we consider only values ≥0 for the independent variable, i.e.,
if we restrict f to the interval [0, +∞), then the function becomes 1-1 (in fact,
f(x1) = f(x2) ⇒x2
1 −x2
2 = (x1 −x2)(x1 + x2) = 0 ⇒x1 = x2). The inverse
function x = f −1(y) = √y is also deﬁned on [0, +∞). Conventionally one says
that the ‘squaring’ map y = x2 has the function ‘square root’ y = √x for inverse
(on [0, +∞)). Notice that the restriction of f to the interval (−∞, 0] is 1-1, too;
the inverse in this case is y = −√x.
iii) The map f : R →R, f(x) = x3 is one-to-one. In fact f(x1) = f(x2)
⇒
x3
1 −x3
2 = (x1 −x2)(x2
1 + x1x2 + x2
2) = 0 ⇒x1 = x2 since x2
1 + x1x2 + x2
2 =
1
2[x2
1 + x2
2 + (x1 + x2)2] > 0 for any x1 ̸= x2. The inverse function is the ‘cubic
root’ y =
3√x, deﬁned on all R.
2
As in Example ii) above, if a function f is not injective over the whole domain,
it might be so on a subset A ⊆dom f. The restriction of f to A is the function
f|A : A →Y
such that
f|A(x) = f(x) ,
∀x ∈A ,
and is therefore invertible.
Let f be deﬁned on X with values Y . If f is one-to-one and onto, it is called
a bijection (or bijective function) from X to Y . If so, the inverse map f −1 is
deﬁned on Y , and is one-to-one and onto (on X); thus, f −1 is a bijection from Y
to X.
For example, the functions f(x) = ax + b (a ̸= 0) and f(x) = x3 are bijections
from R to itself. The function f(x) = x2 is a bijection on [0, +∞) (i.e., from
[0, +∞) to [0, +∞)).
If f is a bijection between X and Y , the sets X and Y are in bijective cor-
rispondence through f: each element of X is assigned to one and only one element
of Y , and vice versa. The reader should notice that two ﬁnite sets (i.e., containing
a ﬁnite number of elements) are in bijective correspondence if and only if they
have the same number of elements. On the contrary, an inﬁnite set can correspond
bijectively to a proper subset; the function (sequence) f : N →N, f(n) = 2n, for
example, establishes a bijection between N and the subset of even numbers.
To conclude the section, we would like to mention a signiﬁcant interpretation
of the notions of 1-1, onto, and bijective maps just introduced. Both in pure Math-
ematics and in applications one is frequently interested in solving a problem, or
an equation, of the form
f(x) = y ,

2.4 Monotone functions
41
where f is a suitable function between two sets X and Y . The quantity y represents
the datum of the problem, while x stands for the solution to the problem, or the
unknown of the equation. For instance, given the real number y, ﬁnd the real
number x solution of the algebraic equation
x3 + x2 −
3√x = y.
Well, to say that f is an onto function on Y is the same as saying that the problem
or equation of concern admits at least one solution for each given y in Y ; asking f
to be 1-1 is equivalent to saying the solution, if it exists at all, is unique. Eventually,
f bijection from X to Y means that for any given y in Y there is one, and only
one, solution x ∈X.
2.4 Monotone functions
Let f be a real map of one real variable, and I the domain of f or an interval
contained in the domain. We would like to describe precisely the situation in which
the dependent variable increases or decreases as the independent variable grows.
Examples are the increase in the pressure of a gas inside a sealed container as
we raise its temperature, or the decrease of the level of fuel in the tank as a car
proceeds on a highway. We have the following deﬁnition.
Deﬁnition 2.6 The function f is increasing on I if, given elements x1, x2
in I with x1 < x2, one has f(x1) ≤f(x2); in symbols
∀x1, x2 ∈I,
x1 < x2
⇒
f(x1) ≤f(x2).
(2.7)
The function f is strictly increasing on I if
∀x1, x2 ∈I,
x1 < x2
⇒
f(x1) < f(x2) .
(2.8)
I
y = f(x)
x1
x2
f(x1)
f(x2)
I
y = f(x)
x1
x2
f(x1) = f(x2)
Figure 2.8. Strictly increasing (left) and decreasing (right) functions on an interval I

42
2 Functions
If a map is strictly increasing then it is increasing as well, hence condition (2.8) is
stronger than (2.7).
The deﬁnitions of decreasing and strictly decreasing functions on I are
obtained from the previous deﬁnitions by reverting the inequality between f(x1)
and f(x2).
The function f is (strictly) monotone on I if it is either (strictly) increasing
or (strictly) decreasing on I. An interval I where f is monotone is said interval
of monotonicity of f.
Examples 2.7
i) The map f : R →R, f(x) = ax + b, is strictly increasing on R for a > 0,
constant on R for a = 0 (hence increasing as well as decreasing), and strictly
decreasing on R when a < 0.
ii) The map f : R →R, f(x) = x2 is strictly increasing on I = [0, +∞). Taking
in fact two arbitrary numbers x1, x2 ≥0 with x1 < x2, we have x2
1 ≤x1x2 < x2
2.
Similarly, f is strictly decreasing on (−∞, 0]. It is not diﬃcult to check that
all functions of the type y = xn, with n ≥4 even, have the same monotonic
behaviour as f (Fig. 2.9, left).
iii) The function f : R →R, f(x) = x3 strictly increases on R. All functions like
y = xn with n odd have analogous behaviour (Fig. 2.9, right).
iv) Referring to Examples 2.1, the maps y = [x] and y = sign(x) are increasing
(though not strictly increasing) on R.
The mantissa y = M(x) of x, instead, is not monotone on R; but it is nevertheless
strictly increasing on each interval [n, n + 1), n ∈Z.
2
−1
1
1
x2
x4
x10
−1
1
1
−1
x3
x5
x11
Figure 2.9. Graphs of some functions y = xn with n even (left) and n odd (right)

2.5 Composition of functions
43
Now to a simple yet crucial result.
Proposition 2.8 If f is strictly monotone on its domain, then f is one-to-
one.
Proof.
To ﬁx ideas, let us suppose f is strictly increasing. Given x1, x2 ∈dom f
with x1 ̸= x2, then either x1 < x2 or x2 < x1. In the former case, using
(2.8) we obtain f(x1) < f(x2), hence f(x1) ̸= f(x2). In the latter case the
same conclusion holds by swapping the roles of x1 and x2.
2
Under the assumption of the above proposition, there exists the inverse function
f −1 then; one can comfortably check that f −1 is also strictly monotone, and in the
same way as f (both are strictly increasing or strictly decreasing). For instance,
the strictly increasing function f : [0, +∞) →[0, +∞), f(x) = x2 has, as inverse,
the strictly increasing function f −1 : [0, +∞) →[0, +∞), f −1(x) = √x.
The logic implication
f is strictly monotone on its domain
⇒
f is one-to-one
cannot be reversed. In other words, a map f may be one-to-one without increasing
strictly on its domain. For instance f : R →R deﬁned by
f(x) =
⎧
⎨
⎩
1
x
if x ̸= 0,
0
if x = 0,
is one-to-one, actually bijective on R, but it is not strictly increasing, nor strictly
decreasing or R. We shall return to this issue in Sect. 4.3.
A useful remark is the following. The sum of functions that are similarly mono-
tone (i.e., all increasing or all decreasing) is still a monotone function of the same
kind, and turns out to be strictly monotone if one at least of the summands is.
The map f(x) = x5 + x, for instance, is strictly increasing on R, being the sum
of two functions with the same property. According to Proposition 2.8 f is then
invertible; note however that the relation f(x) = y cannot be made explicit in the
form x = f −1(y).
2.5 Composition of functions
Let X, Y, Z be sets. Suppose f is a function from X to Y , and g a function from
Y to Z. We can manifacture a new function h from X to Z by setting
h(x) = g(f(x)).
(2.9)
The function h is called composition of f and g, sometimes composite map,
and is indicated by the symbol h = g ◦f (read ‘g composed (with) f’).

44
2 Functions
Example 2.9
Consider the two real maps y = f(x) = x −3 and z = g(y) = y2 + 1 of one real
variable. The composition of f and g reads z = h(x) = g ◦f(x) = (x−3)2 +1. 2
Bearing in mind deﬁnition (2.9), the domain of the composition g ◦f is de-
termined as follows: in order for x to belong to the domain of g ◦f, f(x) must be
deﬁned, so x must be in the domain of f; moreover, f(x) has to be a element of
the domain of g. Thus
x ∈dom g ◦f
⇐⇒
x ∈dom f
and
f(x) ∈dom g.
The domain of g ◦f is then a subset of the domain of f (see Fig. 2.10).
Examples 2.10
i) The domain of f(x) = x + 2
|x −1| is R \ {1}, while g(y) = √y is deﬁned on the
interval [0, +∞). The domain of g ◦f(x) =
 x + 2
|x −1| consists of the x ̸= 1 such
that x + 2
|x −1| ≥0; hence, dom g ◦f = [−2, +∞) \ {1}.
ii) Sometimes the composition g ◦f has an empty domain. This happens for
instance for f(x) =
1
1 + x2 (notice f(x) ≤1) and g(y) = √y −5 (whose domain
is [5, +∞)).
2
X
Y
Z
x
y = f(x)
z = g ◦f(x)
x′
y′ = f(x′)
y′′
z′′ = g(y′′)
f
f
g
g
dom f
im f
dom g
im g
dom g ◦f
im g ◦f
g ◦f
Figure 2.10. Representation of a composite function via Venn diagrams.

2.5 Composition of functions
45
The operation of composition is not commutative: if g ◦f and f ◦g are both
deﬁned (for instance, when X = Y = Z), the two composites do not coincide in
general. Take for example f(x) = 1
x and g(x) =
1
1 + x, for which g ◦f(x) =
x
1 + x,
but f ◦g(x) = 1 + x.
If f and g are both one-to-one (or both onto, or both bijective), it is not diﬃcult
to verify that g◦f has the same property. In the ﬁrst case in particular, the formula
(g ◦f)−1 = f −1 ◦g−1
holds.
Moreover, if f and g are real monotone functions of real variable, g ◦f too will
be monotone, or better: g ◦f is increasing if both f and g are either increasing
or decreasing, and decreasing otherwise. Let us prove only one of these properties.
Let for example f increase and g decrease; if x1 < x2 are elements in dom g ◦f,
the monotone behaviour of f implies f(x1) ≤f(x2); now the monotonicity of g
yields g(f(x1)) ≥g(f(x2)), so g ◦f is decreasing.
We observe ﬁnally that if f is a one-to-one function (and as such it admits
inverse f −1), then
f −1 ◦f(x) = f −1(f(x)) = x,
∀x ∈dom f,
f ◦f −1(y) = f(f −1(y)) = y,
∀y ∈im f.
Calling identity map on a set X the function idX : X →X such that idX(x) = x
for all x ∈X, we have f −1 ◦f = iddom f
and f ◦f −1 = id im f.
2.5.1 Translations, rescalings, reﬂections
Let f be a real map of one real variable (for instance, the function of Fig. 2.11).
Fix a real number c ̸= 0, and denote by tc : R →R the function tc(x) = x + c.
Composing f with tc results in a translation of the graph of f: precisely, the
y = f(x)
Figure 2.11. Graph of a function f(x)

46
2 Functions
graph of the function f ◦tc(x) = f(x+c) is shifted horizontally with respect to the
graph of f: towards the left if c > 0, to the right if c < 0. Similarly, the graph of
tc ◦f(x) = f(x)+ c is translated vertically with respect to the graph of f, towards
the top for c > 0, towards the bottom if c < 0. Fig. 2.12 provides examples of these
situations.
Fix a real number c > 0 and denote by sc : R →R the map sc(x) = cx. The
composition of f with sc has the eﬀect of rescaling the graph of f. Precisely,
if c > 1 the graph of the function f ◦sc(x) = f(cx) is ‘compressed’ horizontally
towards the y-axis, with respect to the graph of f; if 0 < c < 1 instead, the
graph ‘stretches’ away from the y-axis. The analogue eﬀect, though in the vertical
direction, is seen for the function sc ◦f(x) = cf(x): here c > 1 ‘spreads out’ the
graph away from the x-axis, while 0 < c < 1 ‘squeezes’ it towards the axis, see
Fig. 2.13.
Notice also that the graph of f(−x) is obtained by reﬂecting the graph of f(x)
along the y-axis, like in front of a mirror. The graph of f(|x|) instead coincides
with that of f for x ≥0, and for x < 0 it is the mirror image of the latter with
respect to the vertical axis. At last, the graph of |f(x)| is the same as the graph of
f when f(x) ≥0, and is given by reﬂecting the latter where f(x) < 0, see Fig. 2.14.
y = f(x + c), c > 0
y = f(x + c), c < 0
y = f(x) + c, c < 0
y = f(x) + c, c > 0
Figure 2.12. Graphs of the functions f(x + c) (c > 0: top left, c < 0: top right), and
f(x) + c (c < 0: bottom left, c > 0: bottom right), where f(x) is the map of Fig. 2.11

2.6 Elementary functions and properties
47
y = f(cx), c > 1
y = f(cx), c < 1
y = cf(x), c > 1
y = cf(x), c < 1
Figure 2.13. Graph of f(cx) with c > 1 (top left), 0 < c < 1 (top right), and of cf(x)
with c > 1 (bottom left), 0 < c < 1 (bottom right)
2.6 Elementary functions and properties
We start with a few useful deﬁnitions.
Deﬁnition 2.11 Let f : dom f ⊆R →R be a map with a symmetric domain
with respect to the origin, hence such that x ∈dom f forces −x ∈dom f as
well. The function f is said even if f(−x) = f(x) for all x ∈dom f, odd if
f(−x) = −f(x) for all x ∈dom f.
The graph of an even function is symmetric with respect to the y-axis, and that
of an odd map symmetric with respect to the origin. If f is odd and deﬁned in the
origin, necessarily it must vanish at the origin, for f(0) = −f(0).
Deﬁnition 2.12 A function f : dom f ⊆R →R is said periodic of period
p (with p > 0 real) if dom f is invariant under translations by ±p (i.e., if
x ± p ∈dom f for all x ∈dom f) and if f(x + p) = f(x) holds for any
x ∈dom f.

48
2 Functions
y = f(−x)
y = f(|x|)
y = |f(x)|
y = |f(|x|)|
Figure 2.14. Clockwise: graph of the functions f(−x), f(|x|), |f(|x|)|, |f(x)|
One easily sees that an f periodic of period p is also periodic of any multiple
mp (m ∈N \ {0}) of p. If the smallest period exists, it goes under the name
of minimum period of the function. A constant map is clearly periodic of any
period p > 0 and thus has no minimum period.
Let us review now the main elementary functions.
2.6.1 Powers
These are functions of the form y = xα. The case α = 0 is trivial, giving rise to the
constant function y = x0 = 1. Suppose then α > 0. For α = n ∈N \ {0}, we ﬁnd
the monomial functions y = xn deﬁned on R, already considered in Example 2.7 ii)
and iii). When n is odd, the maps are odd, strictly increasing on R and with range
R (recall Property 1.8). When n is even, the functions are even, strictly decreasing
on (−∞, 0] and strictly increasing on [0, +∞); their range is the interval [0, +∞).
Consider now the case α > 0 rational. If α = 1
m where m ∈N\{0}, we deﬁne a
function, called mth root of x and denoted y = x1/m =
m√x, inverting y = xm. It
has domain R if m is odd, [0, +∞) if m is even. The mth root is strictly increasing
and ranges over R or [0, +∞), according to whether m is even or odd respectively.
In general, for α =
n
m ∈Q, n, m ∈N \ {0} with no common divisors, the
function y = xn/m is deﬁned as y = (xn)1/m =
m√xn. As such, it has domain R

2.6 Elementary functions and properties
49
Figure 2.15. Graphs of the functions y = x5/3 (left), y = x4/3 (middle) and y = x3/2
(right)
if m is odd, [0, +∞) if m is even. It is strictly increasing on [0, +∞) for any n,
m, while if m is odd it strictly increases or decreases on (−∞, 0] according to the
parity of n.
Let us consider some examples (Fig. 2.15). The map y = x5/3, deﬁned on R,
is strictly increasing and has range R. The map y = x4/3 is deﬁned on R, strictly
decreases on (−∞, 0] and strictly increases on [0, +∞), which is also its range. To
conclude, y = x3/2 is deﬁned only on [0, +∞), where it is strictly increasing and
has [0, +∞) as range.
Let us introduce now the generic function y = xα with irrational α > 0. To this
end, note that if a is a non-negative real number we can deﬁne the power aα with
α ∈R+\Q, starting from powers with rational exponent and exploiting the density
of rationals inside R. If a ≥1, we can in fact deﬁne aα = sup{an/m |
n
m ≤α},
while for 0 ≤a < 1 we set aα = inf{an/m |
n
m ≤α}. Thus the map y = xα with
α ∈R+ \Q is deﬁned on [0, +∞), and one proves it is there strictly increasing and
its range is [0, +∞).
Summarising, we have deﬁned y = xα for every value α > 0. They are all
deﬁned a least on [0, +∞), interval on which they are strictly increasing; moreover,
they satisfy y(0) = 0, y(1) = 1. It will turn out useful to remark that if α < β,
0 < xβ < xα < 1,
for 0 < x < 1,
1 < xα < xβ,
for x > 1
(2.10)
(see Fig. 2.16).
0
1
1
x6
x
√
3
x
x1/
√
3
x1/6
Figure 2.16. Graphs of y = xα, x ≥0 for some α > 0

50
2 Functions
1
1
−1
−1
x−2
x−9
Figure 2.17. Graphs of y = xα for a two values α < 0
At last, consider the case of α < 0. Set y = xα =
1
x−α by deﬁnition. Its
domain coincides with the domain of y = x−α minus the origin. All maps are
strictly decreasing on (0, +∞), while on (−∞, 0) the behaviour is as follows: writing
α = −n
m with m odd, the map is strictly increasing if n is even, strictly decreasing
if n is odd, as shown in Fig. 2.17. In conclusion, we observe that for every α ̸= 0,
the inverse function of y = xα, where deﬁned, is y = x1/α.
2.6.2 Polynomial and rational functions
A polynomial function, or simply, a polynomial, is a map of the form P(x) =
anxn + · · ·+ a1x + a0 with an ̸= 0; n is the degree of the polynomial. Such a map
is deﬁned over all R; it is even (resp. odd) if and only if all coeﬃcients indexed by
even (odd) subscripts vanish (recall that 0 is an even number).
A rational function is of the kind R(x) = P(x)
Q(x), where P and Q are poly-
nomials. If these have no common factor, the domain of the rational function will
be R without the zeroes of the denominator.
2.6.3 Exponential and logarithmic functions
Let a be a positive real number. According to what we have discussed previously,
the exponential function y = ax is deﬁned for any real number x; it satisﬁes
y(0) = a0 = 1.
If a > 1, the exponential is strictly increasing; if a = 1, this is the constant
map 1, while if a < 1, the function is strictly decreasing. When a ̸= 1, the range
is (0, +∞) (Fig. 2.18). Recalling a few properties of powers is useful at this point:
for any x, y ∈R
ax+y = axay ,
ax−y = ax
ay ,
(ax)y = axy .

2.6 Elementary functions and properties
51
0
1
2
3
1
2
4
8
0
1
Figure 2.18. Graphs of the exponential functions y = 2x (left) and y = ( 1
2)x (right)
When a ̸= 1, the exponential function is strictly monotone on R, hence invertible.
The inverse y = loga x is called logarithm, is deﬁned on (0, +∞) and ranges over
R; it satisﬁes y(1) = loga 1 = 0. The logarithm is strictly increasing if a > 1,
strictly decreasing if a < 1 (Fig. 2.19). The previous properties translate into the
following:
loga(xy) = loga x + loga y,
∀x, y > 0 ,
loga
x
y = loga x −loga y,
∀x, y > 0 ,
loga(xy) = y loga x,
∀x > 0 , ∀y ∈R .
0
1
0
1
Figure 2.19. Graphs of y = log2 x (left) and y = log1/2 x (right)
2.6.4 Trigonometric functions and inverses
Denote here by X, Y the coordinates on the Cartesian plane R2, and consider the
unit circle, i.e., the circle of unit radius centred at the origin O = (0, 0), whose

52
2 Functions
equation reads X2 + Y 2 = 1. Starting from the point A = (1, 0), intersection
of the circle with the positive x-axis, we go around the circle. More precisely,
given any real x we denote by P(x) the point on the circle reached by turning
counter-clockwise along an arc of length x if x ≥0, or clockwise by an arc of
length −x if x < 0. The point P(x) determines an angle in the plane with vertex
O and delimited by the outbound rays from O through the points A and P(x)
respectively (Fig. 2.20). The number x represents the measure of the angle in
radians. The one-radian angle is determined by an arc of length 1. This angle
measures
360
2π
= 57.2957795 · · · degrees. Table 2.1 provides the correspondence
between degrees and radians for important angles. Henceforth all angles shall be
expressed in radians without further mention.
degrees
0
30
45
60
90
120
135
150
180
270
360
radians
0
π
6
π
4
π
3
π
2
2π
3
3π
4
5π
6
π
3π
2
2π
Table 2.1. Degrees versus radians
Increasing or decreasing by 2π the length x has the eﬀect of going around the
circle once, counter-clockwise or clockwise respectively, and returning to the initial
point P(x). In other words, there is a periodicity
P(x ± 2π) = P(x),
∀x ∈R.
(2.11)
Denote by cos x (‘cosine of x’) and sin x (‘sine of x’) the X- and Y -coordinates,
respectively, of the point P(x). Thus P(x) = (cos x, sin x). Hence the cosine func-
tion y = cos x and the sine function y = sin x are deﬁned on R and assume all
0
A
P(x)
Q(x)
cos x
sin x
x
Figure 2.20. The unit circle

2.6 Elementary functions and properties
53
0
1
−1
π
2
π
3
2π
2π
−π
−2π
Figure 2.21. Graph of the map y = sin x
values of the interval [−1, 1]; by (2.11), they are periodic maps of minimum period
2π. They satisfy the crucial trigonometric relation
cos2 x + sin2 x = 1,
∀x ∈R.
(2.12)
It is rather evident from the geometric interpretation that the sine function
is odd, while the cosine function is even. Their graphs are represented in Figures
2.21 and 2.22.
Important values of these maps are listed in the following table (where k is any
integer):
sin x = 0
for x = kπ ,
cos x = 0
for x = π
2 + kπ ,
sin x = 1
for x = π
2 + 2kπ ,
cos x = 1
for x = 2kπ ,
sin x = −1 for x = −π
2 + 2kπ ,
cos x = −1 for x = π + 2kπ .
0
1
−1
π
2
π
3
2π
2π
−π
2
−3
2π
Figure 2.22. Graph of the map y = cos x

54
2 Functions
Concerning monotonicity, one has
y = sin x
is
⎧
⎪
⎨
⎪
⎩
strictly increasing on

−π
2 + 2kπ, π
2 + 2kπ

strictly decreasing on
π
2 + 2kπ, 3π
2 + 2kπ

,
y = cos x
is
 strictly decreasing on [2kπ, π + 2kπ]
strictly increasing on [π + 2kπ, 2π + 2kπ] .
The addition and subtraction formulas are relevant
sin(α ± β) = sin α cos β ± cos α sin β
cos(α ± β) = cos α cos β ∓sin α sin β.
Suitable choices of the arguments allow to infer from these the duplication formulas
sin 2x = 2 sin x cos x,
cos 2x = 2 cos2 x −1,
(2.13)
rather than
sin x −sin y = 2 sin x −y
2
cos x + y
2
,
(2.14)
cos x −cos y = −2 sin x −y
2
sin x + y
2
,
(2.15)
or the following
sin(x + π) = −sin x,
cos(x + π) = −cosx,
(2.16)
sin(x + π
2 ) = cos x,
cos(x + π
2 ) = −sin x.
(2.17)
In the light of Sect. 2.5.1, the ﬁrst of (2.17) tells that the graph of the cosine is
obtained by left-translating the sine’s graph by π/2 (compare Figures 2.21 and
2.22).
The tangent function y = tan x (sometimes y = tg x) and the cotangent
function y = cotan x (also y = ctg x) are deﬁned by
tan x = sin x
cos x,
cotan x = cos x
sin x .
Because of (2.16), these maps are periodic of minimum period π, and not 2π. The
tangent function is deﬁned on R\{ π
2 +kπ : k ∈Z}, it is strictly increasing on the

2.6 Elementary functions and properties
55
0
π
2
π
3
2π
−π
2
−π
0
π
2
π
Figure 2.23. Graphs of the functions y = tan x (left) and y = cotan x (right)
intervals (−π
2 +kπ, π
2 +kπ) where it assumes every real number as value. Similarly,
the cotangent function is deﬁned on R \ {kπ : k ∈Z}, is strictly decreasing on
the intervals (kπ, π + kπ), on which it assumes every real value. Both maps are
odd. Their respective graphs are found in Fig. 2.23.
Recall that tan x expresses geometrically the Y -coordinate of the intersection
point Q(x) between the ray from the origin through P(x) and the vertical line
containing A (Fig. 2.20).
The trigonometric functions, being periodic, cannot be invertible on their whole
domains. In order to invert them, one has to restrict to a maximal interval of strict
monotonicity; in each case one such interval is chosen.
The map y = sin x is strictly increasing on [−π
2 , π
2 ]. The inverse function on
this particular interval is called inverse sine or arcsine and denoted y = arcsinx
0
1
−1
π
2
−π
2
0
1
−1
π
π
2
Figure 2.24. Graphs of y = arcsin x (left) and y = arccos x (right)

56
2 Functions
or y = asin x; it is deﬁned on [−1, 1], everywhere strictly increasing and ranging
over the interval [−π
2 , π
2 ]. This function is odd (Fig. 2.24, left).
Similarly, the function y = cos x is strictly decreasing on the interval [0, π]. By
restricting it to this interval one can deﬁne the inverse cosine, or arccosine,
y = arccosx or y = acos x on [−1, 1], which is everywhere strictly decreasing and
has [0, π] for range (Fig. 2.24, right).
The function y = tan x is strictly increasing on (−π
2 , π
2 ). There, the inverse
is called inverse tangent, or arctangent, and denoted y = arctan x or y =
atan x (also arctg x). It is strictly increasing on its entire domain R, and has range
(−π
2 , π
2 ). Also this is an odd map (Fig. 2.25, left).
In the analogous way the inverse cotangent, or arccotangent, y = arccotanx
is the inverse of the cotangent on (0, π) (Fig. 2.25, right).
−π
2
π
2
0
π
π
2
0
Figure 2.25. Graphs of y = arctan x (left) and y = arccotanx (right)
2.7 Exercises
1. Determine the domains of the following functions:
a) f(x) =
3x + 1
x2 + x −6
b)
f(x) =
√
x2 −3x −4
x + 5
c) f(x) = log(x2 −x)
d)
f(x) =
⎧
⎨
⎩
1
2x + 1
if x ≥0 ,
e
√x+1
if x < 0
2. Determine the range of the following functions:
a) f(x) =
1
x2 + 1
b) f(x) =
√
x + 2 −1
c) f(x) = e5x+3
d) f(x) =
 log x
if x ≥1 ,
−2x −5
if x < 1
3.
Find domain and range for the map f(x) = √cos x −1 and plot its graph.

2.7 Exercises
57
4.
Let f(x) = −log(x −1); determine f −1([0, +∞)) and f −1((−∞, −1]).
5. Sketch the graph of the following functions indicating the possible symmetries
and/or periodicity:
a) f(x) =

1 −|x|
b) f(x) = 1 + cos 2x
c) f(x) = tan

x + π
2

d) f(x) =

x2 −x −1
if x ≤1 ,
−x
if x > 1
6. Using the map f(x) in Fig. 2.26, draw the graphs of
f(x) −1,
f(x + 3),
f(x −1),
−f(x),
f(−x),
|f(x)|.
7.
Check that the function f : R →R deﬁned by f(x) = x2 −2x + 5 is not
invertible. Determine suitable invertible restrictions of f and write down the
inverses explicitly.
8.
Determine the largest interval I where the map
f(x) =

|x −2| −|x| + 2
is invertible, and plot a graph. Write the expression of the inverse function of
f restricted to I.
9.
Verify that f(x) = (1 + 3x)(2x −|x −1|), deﬁned on [0, +∞), is one-to-one.
Determine its range and inverse function.
10. Let f and g be the functions below. Write the expressions for g ◦f, f ◦g, and
determine the composites’ domains.
a)
f(x) = x2 −3
and
g(x) = log(1 + x)
b)
f(x) =
7x
x + 1
and
g(x) = √2 −x
1
−1
3
Figure 2.26. Graph of the function f in Exercise 6

58
2 Functions
11. Write h(x) = 2ex + 1
e2x + 2 as composition of the map f(x) = ex with some other
function.
12.
Given f(x) = x2 −3x + 2
and
g(x) = x2 −5x + 6, ﬁnd the expressions
and graphs of
h(x) = min(f(x), g(x))
and
k(x) = max(h(x), 0).
2.7.1 Solutions
1. Domains:
a) dom f = R \ {−3, 2}.
b) The conditions x2 −3x −4 ≥0 and x + 5 ̸= 0 are necessary. The ﬁrst is
tantamount to (x + 1)(x −4) ≥0, hence x ∈(−∞, −1] ∪[4, +∞); the second
to x ̸= −5. The domain of f is then
dom f = (−∞, −5) ∪(−5, −1] ∪[4, +∞).
c) dom f = (−∞, 0) ∪(1, +∞).
d) In order to study the domain of this piecewise function, we treat the cases
x ≥0, x < 0 separately.
For x ≥0, we must impose 2x+1 ̸= 0, i.e., x ̸= −1
2. Since −1
2 < 0, the function
is well deﬁned on x ≥0.
For x < 0, we must have x + 1 ≥0, or x ≥−1. For negative x then, the
function is deﬁned on [−1, 0).
All in all, dom f = [−1, +∞).
2. Ranges:
a) The map y = x2 has range [0, +∞); therefore the range of y = x2 + 1 is
[1, +∞). Passing to reciprocals, the given function ranges over (0, 1].
b) The map is obtained by translating the elementary function y = √x (whose
range is [0, +∞)) to the left by −2 (yielding y = √x + 2) and then downwards
by 1 (which gives y = √x + 2 −1). The graph is visualised in Fig. 2.27, and
clearly im f = [−1, +∞).
Alternatively, one can observe that 0 ≤√x + 2 < +∞implies −1 ≤√x + 2 −
1 < +∞, whence im f = [−1, +∞).
−1
−2
im f
Figure 2.27. Graph of y = √x + 2 −1

2.7 Exercises
59
c) im f = (0, +∞);
d) im f = (−7, +∞).
3. Imposing cos x −1 ≥0 tells that cos x ≥1. Such constraint is true only for
x = 2kπ, k ∈Z, where the cosine equals 1; thus dom f = {x ∈R : x = 2kπ, k ∈Z}
and im f = {0}. Fig. 2.28 provides the graph.
2π
4π
6π
0
−2π
−4π
−6π
Figure 2.28. Graph of y = √cos x −1
4. f −1([0, +∞)) = (1, 2] and f −1((−∞, −1]) = [e + 1, +∞).
5. Graphs and symmetries/periodicity:
a) The function is even, not periodic and its graph is shown in Fig. 2.29 (top left).
b) The map is even and periodic of period π, with graph in Fig. 2.29 (top right).
c) This function is odd and periodic with period π, see Fig. 2.29 (bottom left).
d) The function has no symmetries nor a periodic behaviour, as shown in Fig. 2.29
(bottom right).
1
1
0
−1
2
0
π
π
−π
0
1
2
1
−1
−5
4
Figure 2.29. Graphs relative to Exercises 5.a) (top left), 5.b) (top right), 5.c) (bottom
left) and 5.d) (bottom right)

60
2 Functions
f(x) −1
−2
0
3
f(x + 3)
−3
0
f(x −1)
1
4
−f(x)
0
3
f(−x)
0
−3
|f(x)|
0
3
Figure 2.30. Graphs of Exercise 6
6. See Fig. 2.30.
7. The function represents a parabola with vertex (1, 4), and as such it is not
invertible on R, not being one-to-one (e.g., f(0) = f(2) = 5). But restricted to the
intervals (−∞, 1] and [1, +∞) separately, it becomes invertible. Setting
f1 = f|(−∞,1] : (−∞, 1] →[4, +∞) ,
f2 = f|[1,+∞) : [1, +∞) →[4, +∞) ,
we can compute
f −1
1
: [4, +∞) →(−∞, 1] ,
f −1
2
: [4, +∞) →[1, +∞)
explicitly. In fact, from x2 −2x + 5 −y = 0 we obtain
x = 1 ±

y −4.
With the ranges of f −1
1
and f −1
2
in mind, swapping the variables x, y yields
f −1
1 (x) = 1 −
√
x −4 ,
f −1
2 (x) = 1 +
√
x −4.
8. Since
f(x) =
⎧
⎨
⎩
2
if x ≤0 ,
√4 −2x
if 0 < x ≤2 ,
0
if x > 2 ,
the required interval I is [0, 2], and the graph of f is shown in Fig. 2.31.
In addition f([0, 2]) = [0, 2], so f −1 : [0, 2] →[0, 2]. By putting y = √4 −2x we
obtain x = 4−y2
2
, which implies f −1(x) = 2 −1
2x2.

2.7 Exercises
61
2
2
0
Figure 2.31. Graph of y =

|x −2| −|x| + 2
9. We have
f(x) =

9x2 −1
if 0 ≤x ≤1 ,
3x2 + 4x + 1
if x > 1
and the graph of f is in Fig. 2.32.
The range of f is [−1, +∞). To determine f −1 we discuss the cases 0 ≤x ≤1 and
x > 1 separately. For 0 ≤x ≤1, we have −1 ≤y ≤8 and
y = 9x2 −1
⇐⇒
x =

y + 1
9
.
For x > 1, we have y > 8 and
y = 3x2 + 4x + 1
⇐⇒
x = −2 + √3y + 1
3
.
8
−1
1
Figure 2.32. Graph of y = (1 + 3x)(2x −|x −1|)

62
2 Functions
Thus
f −1(x) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩

x + 1
9
if −1 ≤x ≤8 ,
−2 + √3x + 1
3
if x > 8.
10. Composite functions:
a) As g ◦f(x) = g(f(x)) = g(x2 −3) = log(1 + x2 −3) = log(x2 −2), it follows
dom g ◦f = {x ∈R : x2 −2 > 0} = (−∞, −
√
2) ∪(
√
2, +∞).
We have f ◦g(x) = f(g(x)) = f(log(1 + x)) = (log(1 + x))2 −3, so
dom f ◦g = {x ∈R : 1 + x > 0} = (−1, +∞).
b) g ◦f(x) =

2 −5x
x + 1
and
dom g ◦f = (−1, 2
5];
f ◦g(x) =
7√2 −x
√2 −x + 1
and
dom f ◦g = (−∞, 2].
11. g(x) = 2x + 1
x2 + 2 and h(x) = g ◦f(x).
12. After drawing the parabolic graphs f(x) and g(x) (Fig. 2.33), one sees that
h(x) =
 x2 −3x + 2
if x ≤2 ,
x2 −5x + 6
if x > 2 ,
1
2
3
6
2
Figure 2.33. Graphs of the parabolas f(x) = x2 −3x + 2 and g(x) = x2 −5x + 6

2.7 Exercises
63
2
1
3
2
1
3
Figure 2.34. Graphs of the maps h (left) and k (right) relative to Exercise 12
and the graph of h is that of Fig. 2.34, left.
Proceeding as above,
k(x) =
⎧
⎨
⎩
x2 −3x + 2
if x ≤1 ,
0
if 1 < x < 3 ,
x2 −5x + 6
if x ≥3 ,
and k has a graph as in Fig. 2.34, right.

3
Limits and continuity I
This chapter tackles the limit behaviour of a real sequence or a function of one
real variable, and studies the continuity of such a function.
3.1 Neighbourhoods
The process of deﬁning limits and continuity leads to consider real numbers which
are ‘close’ to a certain real number. In equivalent geometrical jargon, one considers
points on the real line ‘in the proximity’ of a given point. Let us begin by making
mathematical sense of the notion of neighbourhood of a point.
Deﬁnition 3.1 Let x0 ∈R be a point on the real line, and r > 0 a real
number. We call neighbourhood of x0 of radius r the open and bounded
interval
Ir(x0) = (x0 −r, x0 + r) = {x ∈R : |x −x0| < r}.
Hence, the neighbourhood of 2 of radius 10−1, denoted I10−1(2), is the set of real
numbers lying between 1.9 and 2.1, these excluded. By understanding the quantity
|x −x0| as the Euclidean distance between the points x0 and x, we can then say
that Ir(x0) consists of the points on the real line whose distance from x0 is less
than r. If we interpret |x −x0| as the tolerance in the approximation of x0 by
x, then Ir(x0) becomes the set of real numbers approximating x0 with a better
margin of precision than r.
x0
x0 + r
x0 −r
Figure 3.1. Neighbourhood of x0 of radius r
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_3,
© Springer International Publishing Switzerland 2015

66
3 Limits and continuity I
Varying r in the set of positive real numbers, while mantaining x0 in R ﬁxed,
we obtain a family of neighbourhoods of x0. Each neighbourhood is a proper
subset of any other in the family that has bigger radius, and in turn it contains
all neighbourhoods of lesser radius.
Remark 3.2 The notion of neighbourhood of a point x0 ∈R is nothing but a
particular case of the analogue for a point in the Cartesian product Rd (hence the
plane if d = 2, space if d = 3), presented in Deﬁnition 8.11.
The upcoming deﬁnitions of limit and continuity, based on the idea of neigh-
bourhood, can be stated directly for functions on Rd, by considering functions of
one real variable as subcases for d = 1. We prefer to follow a more gradual ap-
proach, so we shall examine ﬁrst the one-dimensional case. Sect. 8.5 will be devoted
to explaining how all this generalises to several dimensions.
2
It is also convenient to include the case where x0 is one of the points +∞or −∞.
Deﬁnition 3.3 For any real a ≥0, we call neighbourhood of +∞with
end-point a the open, unbounded interval
Ia(+∞) = (a, +∞).
Similarly, a neighbourhood of −∞with end-point −a will be deﬁned as
Ia(−∞) = (−∞, −a).
0
a
−a
+∞
−∞
Figure 3.2. Neighbourhoods of −∞(left) and +∞(right)
The following convention will be useful in the sequel. We shall say that the
property P(x) holds ‘in a neighbourhood’ of a point c (c being a real number x0 or
+∞, −∞) if there is a certain neighbourhood of c such that for each of its points
x, P(x) holds. Colloquially, one also says ‘P(x) holds around c’, especially when
the neighbourhood needs not to be speciﬁed. For example, the map f(x) = 2x −1
is positive in a neighbourhood of x0 = 1; in fact, f(x) > 0 for any x ∈I1/2(1).
3.2 Limit of a sequence
Consider a real sequence a : n →an. We are interested in studying the behaviour of
the values an as n increases, and we do so by looking ﬁrst at a couple of examples.

3.2 Limit of a sequence
67
Examples 3.4
i) Let an =
n
n + 1. The ﬁrst terms of this sequence are presented in Table 3.1. We
see that the values approach 1 as n increases. More precisely, the real number 1
can be approximated as well as we like by an for n suﬃciently large. This clause
is to be understood in the following sense: however small we ﬁx ε > 0, from a
certain point nε onwards all values an approximate 1 with a margin smaller that
ε.
The condition |an −1| < ε, in fact, is tantamount to
1
n + 1 < ε, i.e., n + 1 > 1
ε;
thus deﬁning nε =
1
ε

and taking any natural number n > nε, we have n + 1 >
1
ε

+ 1 > 1
ε, hence |an −1| < ε. In other words, for every ε > 0, there exists an
nε such that
n > nε
⇒
|an −1| < ε.
Looking at the graph of the sequence (Fig. 3.3), one can say that for all n > nε
the points (n, an) of the graph lie between the horizontal lines y = 1 −ε and
y = 1 + ε.
n
an
0
0.00000000000000
1
0.50000000000000
2
0.66666666666667
3
0.75000000000000
4
0.80000000000000
5
0.83333333333333
6
0.85714285714286
7
0.87500000000000
8
0.88888888888889
9
0.90000000000000
10
0.90909090909090
100
0.99009900990099
1000
0.99900099900100
10000
0.99990000999900
100000
0.99999000010000
1000000
0.99999900000100
10000000
0.99999990000001
100000000 0.99999999000000
n
an
1
2.0000000000000
2
2.2500000000000
3
2.3703703703704
4
2.4414062500000
5
2.4883200000000
6
2.5216263717421
7
2.5464996970407
8
2.5657845139503
9
2.5811747917132
10
2.5937424601000
100
2.7048138294215
1000
2.7169239322355
10000
2.7181459268244
100000
2.7182682371975
1000000
2.7182804691564
10000000
2.7182816939804
100000000 2.7182817863958
Table 3.1. Values, estimated to the 14th digit, of the sequences an =
n
n+1 (left) and
an =

1 + 1
n
n (right)

68
3 Limits and continuity I
1
1 + ε
1 −ε
nε
Figure 3.3. Convergence of the sequence an =
n
n+1
ii) The ﬁrst values of the sequence an =

1 + 1
n
n
are shown in Table 3.1. One
could imagine, even expect, that as n increases the values an get closer to a
certain real number, whose decimal expansion starts as 2.718 . . . This is actually
the case, and we shall return to this important example later.
2
We introduce the notion of converging sequence. For simplicity we shall assume
the sequence is deﬁned on the set {n ∈N : n ≥n0} for a suitable n0 ≥0.
Deﬁnition 3.5 A sequence a : n →an converges to the limit ℓ∈R (or
converges to ℓor has limit ℓ), in symbols
lim
n→∞an = ℓ,
if for any real number ε > 0 there exists an integer nε such that
∀n ≥n0,
n > nε
⇒
|an −ℓ| < ε.
Using the language of neighbourhoods, the condition n > nε can be written n ∈
Inε(+∞), while |an −ℓ| < ε becomes an ∈Iε(ℓ). Therefore, the deﬁnition of
convergence to a limit is equivalent to: for any neighbourhood Iε(ℓ) of ℓ, there
exists a neighbourhood Inε(+∞) of +∞such that
∀n ≥n0,
n ∈Inε(+∞)
⇒
an ∈Iε(ℓ).
Examples 3.6
i) Referring to Example 3.4 i), we can say
lim
n→∞
n
n + 1 = 1.

3.2 Limit of a sequence
69
ii) Let us check that
lim
n→∞
3n
2 + 5n2 = 0.
Given ε > 0, we must show

3n
2 + 5n2
 < ε
for all n greater than a suitable natural number nε. Observing that for n ≥1

3n
2 + 5n2
 =
3n
2 + 5n2 < 3n
5n2 = 3
5n,
we have
3
5n < ε
⇒

3n
2 + 5n2
 < ε.
But
3
5n < ε
⇐⇒
n > 3
5ε,
so we can set nε =
 3
5ε

.
2
Let us examine now a diﬀerent be-
n
an
0
0
1
1
2
4
3
9
4
16
5
25
6
36
7
49
8
64
9
81
10
100
100
10000
1000
1000000
10000
100000000
100000 10000000000
Table 3.2. Values of an = n2
haviour as n increases. Consider for
instance the sequence
a : n →an = n2.
Its ﬁrst few values are written in Table
3.2. Not only the values seem not to
converge to any ﬁnite limit ℓ, they are
not even bounded from above: how-
ever large we choose a real number
A > 0, if n is big enough (meaning
larger than a suitable nA), an will be
bigger than A. In fact, it is suﬃcient
to choose nA = [
√
A] and note
n > nA ⇒n >
√
A ⇒n2 > A.
One says that the sequence diverges
to +∞when that happens.
In general the notion of divergent sequence is deﬁned as follows.

70
3 Limits and continuity I
Deﬁnition 3.7 The sequence a : n →an tends to +∞(or diverges to
+∞, or has limit +∞), written
lim
n→∞an = +∞,
if for any real A > 0 there exists an nA such that
∀n ≥n0,
n > nA
⇒
an > A.
(3.1)
Using neighbourhoods, one can also say that for any neighbourhood IA(+∞) of
+∞, there is a neighbourhood InA(+∞) of +∞satisfying
∀n ≥n0,
n ∈InA(+∞)
⇒
an ∈IA(+∞).
The deﬁnition of
lim
n→∞an = −∞
is completely analogous, with the proviso that the implication of (3.1) is changed
to
∀n ≥n0,
n > nA
⇒
an < −A.
Examples 3.8
i) From what we have seen it is clear that
lim
n→∞n2 = +∞.
ii) The sequence an = 0 + 1 + 2 + . . . + n =
n
	
k=0
k associates to n the sum of the
natural numbers up to n. To determine the limit we show ﬁrst of all that
n
	
k=0
k = n(n + 1)
2
,
(3.2)
a relation with several uses in Mathematics. For that, note that an can also be
written as an = n + (n −1) + . . . + 2 + 1 + 0 =
n
	
k=0
(n −k), hence
2an =
n
	
k=0
k +
n
	
k=0
(n −k) =
n
	
k=0
n = n
n
	
k=0
1 = n(n + 1) ,
and the claim follows. Let us verify lim
n→∞
n(n + 1)
2
= +∞. Since n(n + 1)
2
> n2
2 ,
we can proceed as in the example above, so for a given A > 0, we may choose
nA = [
√
2A]
2

3.2 Limit of a sequence
71
The previous examples show that some sequences are convergent, other di-
vergent (to +∞or −∞). But if neither of these cases occurs, one says that the
sequence is indeterminate. Such are for instance the sequence an = (−1)n, which
we have already met, or
an =

1 + (−1)n
n =
 2n
for n even,
0
for n odd.
A suﬃcient condition to avoid an indeterminate behaviour is monotonicity.
The deﬁnitions concerning monotone functions, given in Sect. 2.4, apply to se-
quences, as well, which are nothing but particular functions deﬁned over the nat-
ural numbers. For them they become particularly simple: it will be enough to
compare the values for all pairs of subscripts n, n + 1 belonging to the domain of
the sequence. So, a sequence is monotone increasing if
∀n ≥n0,
an ≤an+1,
the other deﬁnitions being analogous. The following result holds.
Theorem 3.9 A monotone sequence a : n →an is either convergent or
divergent. Precisely, in case an is increasing:
i) if the sequence is bounded from above, i.e., there is an upper bound b ∈R
such that an ≤b for all n ≥n0, then the sequence converges to the
supremum ℓof its image:
lim
n→∞an = ℓ= sup {an : n ≥n0};
ii) if the sequence is not bounded from above, then it diverges to +∞.
In case the sequence is decreasing, the assertions modify in the obvious way.
Proof.
Assume ﬁrst that {an} is bounded from above, which is to say that ℓ=
sup {an : n ≥n0} ∈R. Due to conditions (1.7), for any ε > 0 there exists
an element anε such that ℓ−ε < anε ≤ℓ. As the sequence is monotone,
anε ≤an, ∀n ≥nε; moreover, an ≤ℓ, ∀n ≥n0 by deﬁnition of the
supremum. Therefore
ℓ−ε < an ≤ℓ< ℓ+ ε ,
∀n ≥nε ,
hence each term an with n ≥nε belongs to the neighbourhood of ℓof
radius ε. But this is precisely the meaning of
lim
n→∞an = ℓ.
Let now ℓ= +∞. Put diﬀerently, for any A > 0 there exists an element
anA so that anA > A. Monotonicity implies an ≥anA > A, ∀n ≥nA. Thus

72
3 Limits and continuity I
every an with n ≥nA belongs to the neighbourhood IA(+∞) = (A, +∞)
of +∞, i.e.,
lim
n→∞an = +∞.
2
Example 3.10
Let us go back to Example 3.4 i). The sequence an =
n
n + 1 is strictly increasing,
for an < an+1, i.e.,
n
n + 1 < n + 1
n + 2, is equivalent to n(n + 2) < (n + 1)2, hence
n2 + 2n < n2 + 2n + 1, which is valid for any n.
Moreover, an < 1 for all n ≥0; actually, 1 is the supremum of the set {an : n ∈
N}, as remarked in Sect. 1.3.1. Theorem 3.9 recovers the already known result
lim
n→∞an = 1.
2
The number e
Consider the sequence an =

1 + 1
n
n
introduced in Example 3.4 ii). It is possible
to prove that it is a strictly increasing sequence (hence in particular an > 2 = a1 for
any n > 1) and that it is bounded from above (an < 3 for all n). Thus Theorem 3.9
ensures that the sequence converges to a limit between 2 and 3, which traditionally
is indicated by the symbol e:
lim
n→∞

1 + 1
n
n
= e.
(3.3)
This number, sometimes called Napier’s number or Euler’s number, plays a
role of the foremost importance in Mathematics. It is an irrational number, whose
ﬁrst decimal digits are
e = 2.71828182845905 · · ·
Proofs of the stated properties are given in Appendix A.2.3, p. 437.
The number e is one of the most popular bases for exponentials and logarithms.
The exponential function y = ex shall sometimes be denoted by y = exp x. The
logarithm in base e is called natural logarithm and denoted by log or ln, instead
of loge (for the base-10 logarithm, or decimal logarithm, one uses the capitalised
symbol Log).
3.3 Limits of functions; continuity
Let f be a real function of real variable. We wish to describe the behaviour of
the dependent variable y = f(x) when the independent variable x ‘approaches’ a
certain point x0 ∈R, or one of the points at inﬁnity −∞, +∞. We start with the
latter case for conveniency, because we have already studied what sequences do at
inﬁnity.

3.3 Limits of functions; continuity
73
3.3.1 Limits at inﬁnity
Suppose f is deﬁned around +∞. In analogy to sequences we have some deﬁnitions.
Deﬁnition 3.11 The function f tends to the limit ℓ∈R for x going to
+∞, in symbols
lim
x→+∞f(x) = ℓ,
if for any real number ε > 0 there is a real B ≥0 such that
∀x ∈dom f,
x > B
⇒
|f(x) −ℓ| < ε.
(3.4)
This condition requires that for any neighbourhood Iε(ℓ) of ℓ, there exists a neigh-
bourhood IB(+∞) of +∞such that
∀x ∈dom f,
x ∈IB(+∞)
⇒
f(x) ∈Iε(ℓ).
Deﬁnition 3.12 The function f tends to +∞for x going to +∞, in
symbols
lim
x→+∞f(x) = +∞,
if for each real A > 0 there is a real B ≥0 such that
∀x ∈dom f,
x > B
⇒
f(x) > A.
(3.5)
For functions tending to −∞one should replace f(x) > A by f(x) < −A. The
expression
lim
x→+∞f(x) = ∞
means
lim
x→+∞|f(x)| = +∞.
If f is deﬁned around −∞, Deﬁnitions 3.11 and 3.12 modify to become deﬁn-
itions of limit (L, ﬁnite or inﬁnite) for x going to −∞, by changing x > B to
x < −B:
lim
x→−∞f(x) = L.
At last, by
lim
x→∞f(x) = L
one intends that f has limit L (ﬁnite or not) both for x →+∞and x →−∞.

74
3 Limits and continuity I
Examples 3.13
i) Let us check that
lim
x→+∞
x2 + 2x
2x2 + 1 = 1
2.
Given ε > 0, the condition |f(x) −1
2| < ε is equivalent to

4x −1
2(2x2 + 1)
 < ε.
Without loss of generality we assume x > 1
4, so that the absolute value sign can
be removed. Using simple properties of fractions
4x −1
2(2x2 + 1) <
2x
2x2 + 1 < 2x
2x2 = 1
x < ε
if x > 1
ε.
Thus (3.4) holds for B = max
1
4, 1
ε

.
ii) We prove
lim
x→+∞
√x = +∞.
Let A > 0 be ﬁxed. Since √x > A implies x > A2, putting B = A2 fulﬁlls (3.5).
iii) Consider
lim
x→−∞
1
√1 −x = 0.
With ε > 0 ﬁxed,

1
√1 −x
 =
1
√1 −x < ε
is tantamount to √1 −x > 1
ε, that is 1 −x > 1
ε2 , or x < 1 −1
ε2 . So taking
B = max

0, 1
ε2 −1

, we have
x < −B
⇒

1
√1 −x
 < ε.
2
3.3.2 Continuity. Limits at real points
We now investigate the behaviour of the values y = f(x) of a function f when x
‘approaches’ a point x0 ∈R. Suppose f is deﬁned in a neighbourhood of x0, but
not necessarily at the point x0 itself. Two examples will let us capture the essence
of the notions of continuity and ﬁnite limit.
Fix x0 = 0 and consider the real
functions of real variable f(x) = x3 + 1, g(x) = x + [1 −x2] and h(x) = sin x
x
(recall that [z] indicates the integer part of z); their respective graphs, at least in
a neighbourhood of the origin, are presented in Fig. 3.4 and 3.5.
As far as g is concerned, we observe that |x| < 1 implies 0 < 1 −x2 ≤1 and
g assumes the value 1 only at x = 0; in the neighbourhood of the origin of unit
radius then,

3.3 Limits of functions; continuity
75
0
−1
1
1 + ε
1 −ε
−3√ε
3√ε
6
5
4
5
1
−1
1
ε
−ε
ε
−ε
Figure 3.4. Graphs of f(x) = x3 + 1 (left) and g(x) = x + [1 −x2] (right), in a
neighbourhood of the origin
g(x) =
 1
if x = 0 ,
x
if x ̸= 0 ,
as the picture shows. Note the function h is not deﬁned in the origin.
For each of f and g, let us compare the values at points x near the origin with
the actual value at the origin. The two functions behave rather diﬀerently. The
value f(0) = 1 can be approximated as well as we like by any f(x), provided x
is close enough to 0. Precisely, having ﬁxed an (arbitrarily small) ‘error’ ε > 0 in
advance, we can make |f(x) −f(0)| smaller than ε for all x such that |x −0| = |x|
is smaller than a suitable real δ > 0. In fact |f(x) −f(0)| = |x3| = |x|3 < ε means
|x| <
3√ε, so it is suﬃcient to choose δ =
3√ε. We shall say that the function f is
continuous at the origin.
0
1
π
−π
Figure 3.5. Graph of h(x) = sin x
x
around the origin

76
3 Limits and continuity I
On the other hand, g(0) = 1 cannot be approximated well by any g(x) with
x close to 0. For instance, let ε =
1
5. Then |g(x) −g(0)| < ε is equivalent to
4
5 < g(x) <
6
5; but all x diﬀerent from 0 and such that, say, |x| <
1
2, satisfy
−1
2 < g(x) = x < 1
2, in violation to the constraint for g(x). The function g is not
continuous at the origin.
At any rate, we can specify the behaviour of g around 0: for x closer and closer
to 0, yet diﬀerent from 0, the images g(x) approximate not the value g(0), but
rather ℓ= 0. In fact, with ε > 0 ﬁxed, if x ̸= 0 satisﬁes |x| < min(ε, 1), then
g(x) = x and |g(x) −ℓ| = |g(x)| = |x| < ε. We say that g has limit 0 for x going
to 0.
As for the function h, it cannot be continuous at the origin, since comparing
the values h(x), for x near 0, with the value at the origin simply makes no sense,
for the latter is not even deﬁned. Neverthless, the graph allows to ‘conjecture’ that
these values might estimate ℓ= 1 increasingly better, the closer we choose x to
the origin. We are lead to say h has a limit for x going to 0, and this limit is 1.
We shall substantiate this claim later on.
The examples just seen introduce us to the deﬁnition of continuity and of
(ﬁnite) limit.
Deﬁnition 3.14 Let x0 be a point in the domain of a function f. This func-
tion is called continuous at x0 if for any ε > 0 there is a δ > 0 such that
∀x ∈dom f,
|x −x0| < δ
⇒
|f(x) −f(x0)| < ε.
(3.6)
In neighbourhood-talk: for any neighbourhood Iε(f(x0)) of f(x0) there exists a
neighbourhood Iδ(x0) of x0 such that
∀x ∈dom f,
x ∈Iδ(x0)
⇒
f(x) ∈Iε(f(x0)).
(3.7)
Deﬁnition 3.15 Let f be a function deﬁned on a neighbourhood of x0 ∈R,
except possibly at x0. Then f has limit ℓ∈R (or tends to ℓor converges
to ℓ) for x approaching x0, written
lim
x→x0 f(x) = ℓ,
if given any ε > 0 there exists a δ > 0 such that
∀x ∈dom f,
0 < |x −x0| < δ
⇒
|f(x) −ℓ| < ε.
(3.8)
Alternatively: for any given neighbourhood Iε(ℓ) of ℓthere is a neighbourhood
Iδ(x0) of x0 such that

3.3 Limits of functions; continuity
77
x0
x0 + δ
x0 −δ
x
f(x)
ℓ
ℓ+ ε
ℓ−ε
y = f(x)
Figure 3.6. Deﬁnition of ﬁnite limit of a function
∀x ∈dom f,
x ∈Iδ(x0) \ {x0}
⇒
f(x) ∈Iε(ℓ).
The deﬁnition of limit is represented in Fig. 3.6.
Let us compare the notions just seen. To have continuity one looks at the values
f(x) from the point of view of f(x0), whereas for limits these f(x) are compared
to ℓ, which could be diﬀerent from f(x0), provided f is deﬁned in x0. To test the
limit, moreover, the comparison with x = x0 is excluded: requiring 0 < |x −x0|
means exactly x ̸= x0; on the contrary, the implication (3.6) is obviously true for
x = x0.
Let f be deﬁned in a neighbourhood of x0. If f is continuous at x0, then (3.8)
is certainly true with ℓ= f(x0); vice versa if f has limit ℓ= f(x0) for x going to
x0, then (3.6) holds. Thus the continuity of f at x0 is tantamount to
lim
x→x0 f(x) = f(x0).
(3.9)
In both deﬁnitions, after ﬁxing an arbitrary ε > 0, one is asked to ﬁnd at
least one positive number δ (‘there is a δ’) for which (3.6) or (3.8) holds. If either
implication holds for a certain δ, it will also hold for every δ′ < δ. The deﬁnition
does not require to ﬁnd the biggest possible δ satisfying the implication. With this
ﬁrmly in mind, testing continuity or verifying a limit can become much simpler.
Returning to the functions f, g, h of the beginning, we can now say that f is
continuous at x0 = 0,
lim
x→0 f(x) = 1 = f(0),
whereas g, despite having limit 0 for x →0, is not continuous:
lim
x→0 g(x) = 0 ̸= g(0).

78
3 Limits and continuity I
We shall prove in Example 4.6 i) that h admits a limit for x going to 0, and actually
lim
x→0 h(x) = 1.
The functions g and h suggest the following deﬁnition.
Deﬁnition 3.16 Let f be deﬁned on a neighbourhood of x0, excluding the
point x0. If f admits limit ℓ∈R for x approaching x0, and if a) f is deﬁned
in x0 but f(x0) ̸= ℓ, or b) f is not deﬁned in x0, then we say x0 is a (point
of) removable discontinuity for f.
The choice of terminology is justiﬁed by the fact that one can modify the function
at x0 by deﬁning it in x0, so that to obtain a continuous map at x0. More precisely,
the function
˜f(x) =
 f(x)
if x ̸= x0,
ℓ
if x = x0,
is such that
lim
x→x0
˜f(x) = lim
x→x0 f(x) = ℓ= ˜f(x0),
hence it is continuous at x0.
For the above functions we have ˜g(x) = x in a neighbourhood of the origin,
while
˜h(x) =
⎧
⎨
⎩
sin x
x
if x ̸= 0,
1
if x = 0.
In the latter case, we have deﬁned the continuous prolongation of y = sin x
x
,
by assigning the value that renders it continuous at the origin. From now on when
referring to the function y = sin x
x
, we will always understand it as continuously
prolonged in the origin.
Examples 3.17
We show that the main elementary functions are continuous.
i) Let f : R →R, f(x) = ax + b and x0 ∈R be given. For any ε > 0,
|f(x)−f(x0)| < ε if and only if |a| |x−x0| < ε. When a = 0, the condition holds
for any x ∈R; if a ̸= 0 instead, it is equivalent to |x −x0| < ε
|a|, and we can put
δ = ε
|a| in (3.6). The map f is thus continuous at every x0 ∈R.
ii) The function f : R →R, f(x) = x2 is continuous at x0 = 2. We shall prove
this fact in two diﬀerent ways. Given ε > 0, |f(x) −f(2)| < ε, or |x2 −4| < ε,
means
4 −ε < x2 < 4 + ε.
(3.10)

3.3 Limits of functions; continuity
79
We can suppose ε ≤4 (for if |f(x) −f(2)| < ε for a certain ε, the same will
be true for all ε′ > ε); as we are looking for x in a neighbourhood of 2, we can
furthermore assume x > 0. Under such assumptions (3.10) yields
√
4 −ε < x <
√
4 + ε,
hence
−(2 −
√
4 −ε) < x −2 <
√
4 + ε −2.
(3.11)
This suggests to take δ = min(2 −√4 −ε, √4 + ε −2) (= √4 + ε −2, easy to
verify). If |x −2| < δ, then (3.11) holds, which was equivalent to |x2 −4| < ε.
With a few algebraic computations, this furnishes the greatest δ for which the
inequality |x2 −4| < ε is true.
We have already said that the largest value of δ is not required by the deﬁnitions,
so we can also proceed alternatively. Since
|x2 −4| = |(x −2)(x + 2)| = |x −2| |x + 2| ,
by restricting x to a neighbourhood of 2 of radius < 1, we will have −1 < x−2 <
1, hence 1 < x < 3. The latter will then give 3 < x + 2 = |x + 2| < 5. Thus
|x2 −4| < 5|x −2|.
(3.12)
To obtain |x2 −4| < ε it will suﬃce to demand |x −2| < ε
5; since (3.12) holds
when |x −2| < 1, we can set δ = min

1, ε
5

and the condition (3.6) will be
satisﬁed. The neighbourhood of radius < 1 was arbitrary: we could have chosen
any other suﬃciently small neighbourhood and obtain another δ, still respecting
the continuity requirement.
Note at last that a similar reasoning tells f is continuous at every x0 ∈R.
iii) We verify that f : R →R, f(x) = sin x is continuous at every x0 ∈R. We
establish ﬁrst a simple but fundamental inequality.
Lemma 3.18 For any x ∈R,
| sin x| ≤|x|,
(3.13)
with equality holding if and only if x = 0.
Proof.
Let us start assuming 0 < x ≤π
2 and look at the right-angled triangle
PHA of Fig. 3.7. The vertical side PH is shorter than the hypotenuse PA,
whose length is in turn less than the length of the arc PA (the shortest
distance between two points is given by the straight line joining them):
PH < PA <
⌢
PA .
By deﬁnition PH = sin x > 0, and
⌢
PA = x > 0 (angles being in radians).
Thus (3.13) is true. The case −π
2 ≤x < 0 is treated with the same

80
3 Limits and continuity I
O
A
H
P
x
sin x
1
Figure 3.7. | sin x| ≤|x|
argument observing | sin x| = sin |x| for 0 < |x| ≤π
2 . At last, when |x| > π
2
one has | sin x| ≤1 < π
2 < |x|, ending the proof.
2
Thanks to (3.13) we can prove that sine is a continuous function. Recalling
formula (2.14),
sin x −sin x0 = 2 sin x −x0
2
cos x + x0
2
,
(3.13) and the fact that | cos t| ≤1 for all t ∈R, imply
| sin x −sin x0| = 2
sin x −x0
2

cos x + x0
2

≤2

x −x0
2
 · 1 = |x −x0|.
Therefore, given an ε > 0, if |x −x0| < ε we have | sin x −sin x0| < ε; in other
words, condition (3.6) is satisﬁed by δ = ε.
Similarly, formula (2.15) allows to prove g(x) = cos x is continuous at every
x0 ∈R.
2
Deﬁnition 3.19 Let I be a subset of dom f. The function f is called con-
tinuous on I (or over I) if f is continuous at every point of I.
We remark that the use of the term ‘map’ (or ‘mapping’) is very diﬀerent from
author to author; in some books a map is simply a function (we have adopted
this convention), for others the word ‘map’ automatically assumes continuity, so
attention is required when browsing the literature.

3.3 Limits of functions; continuity
81
The following result is particularly relevant and will be used many times
without explicit mention. For its proof, see Appendix A.2.2, p. 436.
Proposition 3.20 All elementary functions (polynomials, rational func-
tions, powers, trigonometric functions, exponentials and their inverses) are
continuous over their entire domains.
Let us point out that there exists a notion of continuity of a function on a
subset of its domain, that is stronger than the one given in Deﬁnition 3.19; it is
called uniform continuity. We refer to Appendix A.3.3, p. 447, for its deﬁnition
and main properties.
Now back to limits. A function f deﬁned in a neighbourhood of x0, x0 excluded,
may assume bigger and bigger values as the independent variable x gets closer to
x0. Consider for example the function
f(x) =
1
(x −3)2
on R \ {3}, and ﬁx an arbitrarily large real number A > 0. Then f(x) > A for all
x ̸= x0 such that |x −3| <
1
√
A
. We would like to say that f tends to +∞for x
approaching x0; the precise deﬁnition is as follows.
Deﬁnition 3.21 Let f be deﬁned in a neighbourhood of x0 ∈R, except pos-
sibly at x0. The function f has limit +∞(or tends to +∞) for x ap-
proaching x0, in symbols
lim
x→x0 f(x) = +∞,
if for any A > 0 there is a δ > 0 such that
∀x ∈dom f,
0 < |x −x0| < δ
⇒
f(x) > A.
(3.14)
Otherwise said, for any neighbourhood IA(+∞) of +∞there exists a neighbour-
hood Iδ(x0) di x0 such that
∀x ∈dom f,
x ∈Iδ(x0) \ {x0}
⇒
f(x) ∈IA(+∞).
The deﬁnition of
lim
x→x0 f(x) = −∞
follows by changing f(x) > A to f(x) < −A.

82
3 Limits and continuity I
One also writes
lim
x→x0 f(x) = ∞
to indicate lim
x→x0 |f(x)| = +∞. For instance the hyperbola f(x) = 1
x , with graph
in Fig. 2.2, does not admit limit for x →0, because on each neighbourhood Iδ(0) of
the origin the function assumes both arbitrarily large positive and negative values
together. On the other hand, |f(x)| tends to +∞when x nears 0. In fact, for ﬁxed
A > 0
∀x ∈R \ {0},
|x| < 1
A
⇒
1
|x| > A.
Hence lim
x→0
1
x = ∞.
3.3.3 One-sided limits; points of discontinuity
The previous example shows that a map may have diﬀerent limit behaviours at
the left and right of a point x0. The function f(x) = 1
x grows indeﬁnitely as x
takes positive values tending to 0; at the same time it becomes smaller as x goes
to 0 assuming negative values. Consider the graph of the mantissa y = M(x) (see
Fig. 2.3, p. 34) on a neighbourhood of x0 = 1 of radius < 1. Then
M(x) =
 x
if x < 1,
x −1
if x ≥1.
When x approaches 1, M tends to 0 if x takes values > 1 (i.e., at the right of 1),
and tends to 1 if x assumes values < 1 (at the left).
The notions of right-hand limit and left-hand limit (or simply right limit and
left limit) arise from the need to understand these cases. For that, we deﬁne right
neighbourhood of x0 of radius r > 0 the bounded half-open interval
I+
r (x0) = [x0, x0 + r) = {x ∈R : 0 ≤x −x0 < r}.
The left neighbourhood of x0 of radius r > 0 will be, similarly,
I−
r (x0) = (x0 −r, x0] = {x ∈R : 0 ≤x0 −x < r}.
Substituting the condition 0 < |x −x0| < δ (i.e., x ∈Iδ(x0) \ {x0}) with 0 <
x −x0 < δ (i.e., x ∈I+
δ (x0) \ {x0}) in Deﬁnitions 3.15 and 3.21 produces the
corresponding deﬁnitions for right limit of f for x tending to x0, otherwise
said limit of f for x approaching x0 from the right or limit on the right;
such will be denoted by
lim
x→x+
0
f(x).

3.3 Limits of functions; continuity
83
For a ﬁnite limit, this reads as follows.
Deﬁnition 3.22 Let f be deﬁned on a right neighbourhood of x0 ∈R, except
possibly at x0. The function f has right limit ℓ∈R for x →x0, if for every
ε > 0 there is a δ > 0 such that
∀x ∈dom f,
0 < x −x0 < δ
⇒
|f(x) −ℓ| < ε.
Alternatively, for any neighbourhood Iε(ℓ) di ℓthere exists a right neighbourhood
I+
δ (x0) of x0 such that
∀x ∈dom f,
x ∈I+
δ (x0) \ {x0}
⇒
f(x) ∈Iε(ℓ).
The notion of continuity on the right is analogous.
Deﬁnition 3.23 A function f deﬁned on a right neighbourhood of x0 ∈R is
called continuous on the right at x0 (or right-continuous) if
lim
x→x+
0
f(x) = f(x0).
If a function is only deﬁned on a right neighbourhood of x0, right-continuity co-
incides with the earlier Deﬁnition (3.6). The function f(x) = √x for example is
deﬁned on [0, +∞), and is continuous at 0.
Limits of f from the left and left-continuity are completely similar: now one
has to use left neighbourhoods of x0; the left limit shall be denoted by
lim
x→x−
0
f(x).
The following easy-to-prove property provides a handy criterion to study limits
and continuity.
Proposition 3.24 Let f be deﬁned in a neighbourhood of x0 ∈R, with the
possible exception of x0. The function f has limit L (ﬁnite or inﬁnite) for
x →x0 if and only if the right and left limits of f, for x →x0, exist and
equal L.
A function f deﬁned in a neighbourhood of x0 is continuous at x0 if and only
if it is continuous on the right and on the left at x0.

84
3 Limits and continuity I
Returning to the previous examples, it is not hard to see
lim
x→0+
1
x = +∞;
lim
x→0−
1
x = −∞
and
lim
x→1+ M(x) = 0;
lim
x→1−M(x) = 1.
Note M(1) = 0, so lim
x→1+ M(x) = M(1). All this means the function M(x) is con-
tinuous on the right at x0 = 1 (but not left-continuous, hence neither continuous,
at x0 = 1).
Deﬁnition 3.25 Let f be deﬁned on a neighbourhood of x0 ∈R, except pos-
sibly at x0. If the left and right limits of f for x going to x0 are diﬀerent, we
say that x0 is a (point of ) discontinuity of the ﬁrst kind (or a jump
point) for f. The gap value of f at x0 is the diﬀerence
[f]x0 = lim
x→x+
0
f(x) −lim
x→x−
0
f(x).
Thus the mantissa has a gap = −1 at x0 = 1 and, in general, at each point
x0 = n ∈Z.
Also the ﬂoor function y = [x] jumps, at each x0 = n ∈Z, with gap = 1, for
lim
x→n+[x] = n;
lim
x→n−[x] = n −1.
The sign function y = sign (x) has a jump point at x0 = 0, with gap = 2:
lim
x→0+ sign (x) = 1;
lim
x→0−sign (x) = −1.
Deﬁnition 3.26 A discontinuity point which is not removable, nor of the
ﬁrst kind is said of the second kind.
This occurs for instance when f does not admit limit (neither on the left nor
on the right) for x →x0. The function f(x) = sin 1
x has no limit for x →0 (see
Fig. 3.8 and the explanation in Remark 4.19).
3.3.4 Limits of monotone functions
Monotonicity aﬀects the possible limit behaviour of a map, as the following results
explain.

3.3 Limits of functions; continuity
85
1
−1
Figure 3.8. Graph of f(x) = sin 1
x
Theorem 3.27 Let f be a monotone function deﬁned on a right neighbour-
hood I+(c) of the point c (where c is real or −∞), possibly without the point
c itself. Then the right limit for x →c exists (ﬁnite or inﬁnite), and precisely
lim
x→c+ f(x) =
 inf{f(x) : x ∈I+(c), x > c}
if f is increasing,
sup{f(x) : x ∈I+(c), x > c}
if f is decreasing.
In the same way, f monotone on a left neighbourhood I−(c)\{c} of c (c real
or +∞) satisﬁes
lim
x→c−f(x) =
 sup{f(x) : x ∈I−(c), x < c}
if f is increasing,
inf{f(x) : x ∈I−(c), x < c}
if f is decreasing.
Proof.
We shall prove that if f increases in the right neighbourhood I+(c) of c
then
lim
x→c+ f(x) = inf{f(x) : x ∈I+(c), x > c} .
The other cases are similar.
Let ℓ= inf{f(x) : x ∈I+(c), x > c} ∈R. The inﬁmum is characterised,
in analogy with (1.7), by:
i)
for all x ∈I+(c) \ {c}, f(x) ≥ℓ;
ii) for any ε > 0, there exists an element xε ∈I+(c)\{c} such that
f(xε) < ℓ+ ε.
By monotonicity we have
f(x) ≤f(xε) ,
∀x ∈I+(c) \ {c}, x < xε ,
therefore

86
3 Limits and continuity I
ℓ−ε < ℓ≤f(x) < ℓ+ ε ,
∀x ∈I+(c) \ {c}, x < xε .
So, each f(x) belongs to the neighbourhood of ℓof radius ε if x ̸= c is in
the right neighbourhood of c with supremum xε. Thus we have
lim
x→c+ f(x) = ℓ.
Let now ℓ= −∞; this means that for any A > 0 there is an xA ∈I+(c) \
{c} such that f(xA) < −A. Using monotonicity again we obtain f(x) ≤
f(xA) < −A, ∀x ∈I+(c) \ {c} and x < xA. Hence f(x) belongs to the
neighbourhood of −∞with supremum −A provided x ̸= c is in the right
neighbourhood of c of supremum xA. We conclude
lim
x→c+ f(x) = −∞.
2
A straightforward consequence is that a monotone function can have only a
discontinuity of the ﬁrst kind.
Corollary 3.28 Let f be monotone on a neighbourhood I(x0) of x0 ∈R.
Then the right and left limits for x →x0 exist and are ﬁnite. More precisely,
i) if f is increasing
lim
x→x−
0
f(x) ≤f(x0) ≤lim
x→x+
0
f(x);
ii) if f is decreasing
lim
x→x−
0
f(x) ≥f(x0) ≥lim
x→x+
0
f(x).
Proof.
Let f be increasing. Then for all x ∈I(x0) with x < x0, f(x) ≤f(x0).
The above theorem guarantees that
lim
x→x−
0
f(x) = sup{f(x) : x ∈I(x0), x < x0} ≤f(x0).
Similarly, for x ∈I(x0) with x > x0,
f(x0) ≤inf{f(x) : x ∈I(x0), x > x0} = lim
x→x+
0
f(x),
from which i) follows. The second implication is alike.
2

3.4 Exercises
87
3.4 Exercises
1. Using the deﬁnition prove that
a)
lim
n→+∞n! = +∞
b)
lim
n→+∞
n2
1 −2n = −∞
c)
lim
x→1(2x2 + 3) = 5
d)
lim
x→2±
1
x2 −4 = ±∞
e)
lim
x→−∞
x
√
x2 −1
= −1
f)
lim
x→+∞
x2
1 −x = −∞
2.
Let f(x) = sign (x2 −x). Discuss the existence of the limits
lim
x→0 f(x)
and
lim
x→1 f(x)
and study the function’s continuity.
3. Determine the values of the real parameter α for which the following maps are
continuous on their respective domains:
a)
f(x) =
 α sin(x + π
2 )
if x > 0 ,
2x2 + 3
if x ≤0
b) f(x) =
 3eαx−1
if x ≥1 ,
x + 2
if x < 1
3.4.1 Solutions
1. Limits:
a) Let a real number A > 0 be given; it is suﬃcient to choose any natural number
nA ≥A and notice that if n > nA then
n! = n(n −1) · · · 2 · 1 ≥n > nA ≥A.
Thus
lim
n→+∞n! = +∞.
b) Fix a real A > 0 and note
n2
1−2n < −A is the same as
n2
2n−1 > A. For n ≥1, that
means n2−2An+A > 0. If we consider a natural number nA ≥A+

A(A + 1),
the inequality holds for all n > nA.
c) Fix ε > 0 and study the condition |f(x) −ℓ| < ε:
|2x2 + 3 −5| = 2|x2 −1| = 2|x −1| |x + 1| < ε .
Without loss of generality we assume x belongs to the neighbourhood of 1 of
radius 1, i.e.,

88
3 Limits and continuity I
−1 < x −1 < 1 ,
whence
0 < x < 2
and
1 < x + 1 = |x + 1| < 3.
Therefore
|2x2 + 3 −5| < 2 · 3|x −1| = 6|x −1|.
The expression on the right is < ε if |x −1| <
ε
6. It will be enough to set
δ = min(1, ε
6) to prove the claim.
2. Since x2 −x > 0 when x < 0 or x > 1, the function f(x) is thus deﬁned:
f(x) =
⎧
⎨
⎩
1
if x < 0 and x > 1 ,
0
if x = 0 and x = 1 ,
−1
if 0 < x < 1 .
So f is constant on the intervals (−∞, 0), (0, 1), (1, +∞) and
lim
x→0−f(x) = 1,
lim
x→0+ f(x) = −1,
lim
x→1−f(x) = −1,
lim
x→1+ f(x) = 1.
The required limits do not exist. The function is continuous on all R with the
exception of the jump points x = 0 and x = 1.
3. Continuity:
a) The domain of f is R and the function is continuous for x ̸= 0, irrespective of
α. As for the continuity at x = 0, observe that
lim
x→0−f(x) = lim
x→0−(2x2 + 3) = 3 = f(0) ,
lim
x→0+ f(x) = lim
x→0+ α sin(x + π
2 ) = α.
These imply f is continuous also in x = 0 if α = 3.
b) α = 1.

4
Limits and continuity II
The study of limits continues with the discussion of tools that facilitate compu-
tations and avoid having to resort to the deﬁnition each time. We introduce the
notion of indeterminate form, and infer some remarkable limits. The last part of
the chapter is devoted to continuous functions on real intervals.
4.1 Theorems on limits
A bit of notation to begin with: the symbol c will denote any of x0, x+
0 , x−
0 ,
+∞, −∞, ∞introduced previously. Correspondingly, I(c) will be a neighbourhood
Iδ(x0) of x0 ∈R of radius δ, a right neighbourhood I+
δ (x0), a left neighbourhood
I−
δ (x0), a neighbourhood IB(+∞) of +∞with end-point B > 0, a neighbourhood
IB(−∞) of −∞with end-point −B, or a neighbourhood IB(∞) = IB(−∞) ∪
IB(+∞) of ∞.
We shall suppose from now on f, g, h, . . . are functions deﬁned on a neighbour-
hood of c with the point c deleted, unless otherwise stated. In accordance with the
meaning of c, the expression lim
x→c f(x) will stand for the limit of f for x →x0 ∈R,
the right or left limit, the limit for x tending to +∞, −∞, or for |x| →+∞.
4.1.1 Uniqueness and sign of the limit
We start with the uniqueness of a limit, which justiﬁes having so far said ‘the limit
of f’, in place of ‘a limit of f’.
Theorem 4.1 (Uniqueness of the limit) Suppose f admits (ﬁnite or in-
ﬁnite) limit ℓfor x →c. Then f admits no other limit for x →c.
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_4,
© Springer International Publishing Switzerland 2015

90
4 Limits and continuity II
y
ℓ
ℓ+ ε
ℓ−ε
ℓ′
ℓ′ + ε
ℓ′ −ε
Figure 4.1. The neighbourhoods of ℓ, ℓ′ of radius ε ≤1
2|ℓ−ℓ′| are disjoint
Proof.
We assume there exist two limits ℓ′ ̸= ℓand infer a contradiction. We
consider only the case where ℓand ℓ′ are both ﬁnite, for the other situations
can be easily deduced adapting the same argument. First of all, since ℓ′ ̸= ℓ
there exist disjoint neighbourhoods I(ℓ) of ℓand I(ℓ′) of ℓ′
I(ℓ) ∩I(ℓ′) = ∅.
(4.1)
To see this fact, it is enough to consider neighbourhoods of radius ε smaller
or equal than half the distance of ℓand ℓ′, ε ≤1
2|ℓ−ℓ′| (Fig. 4.1).
Taking I(ℓ), the hypothesis lim
x→c f(x) = ℓimplies the existence of a neigh-
bourhood I(c) of c such that
∀x ∈dom f,
x ∈I(c) \ {c}
⇒
f(x) ∈I(ℓ).
Similarly for I(ℓ′), from lim
x→c f(x) = ℓ′ it follows there is I′(c) with
∀x ∈dom f,
x ∈I′(c) \ {c}
⇒
f(x) ∈I(ℓ′).
The intersection of I(c) and I′(c) is itself a neighbourhood of c: it contains
inﬁnitely many points of the domain of f since we assumed f was deﬁned
in a neighbourhood of c (possibly minus c). Therefore if ¯x ∈dom f is any
point in the intersection, diﬀerent from c,
f(¯x) ∈I(ℓ) ∩I(ℓ′),
hence the intervals I(ℓ) and I(ℓ′) do have non-empty intersection, contra-
dicting (4.1).
2
The second property we present concerns the sign of a limit around a point c.
Theorem 4.2 Suppose f admits limit ℓ(ﬁnite or inﬁnite) for x →c. If
ℓ> 0 or ℓ= +∞, there exists a neighbourhood I(c) of c such that f is strictly
positive on I(c) \ {c}. A similar assertion holds when ℓ< 0 or ℓ= −∞.
Proof.
Assume ℓis ﬁnite, positive, and consider the neighbourhood Iε(ℓ) of ℓof
radius ε = ℓ/2 > 0. According to the deﬁnition, there is a neighbourhood
I(c) of c satisfying

4.1 Theorems on limits
91
x0
I(x0)
f(x0)
ℓ
I(ℓ)
3ℓ
2
ℓ
2
y = f(x)
Figure 4.2. Around a limit value, the sign of a map does not change
∀x ∈dom f,
x ∈I(c) \ {c}
⇒
f(x) ∈Iε(ℓ).
As Iε(ℓ) = ( ℓ
2, 3ℓ
2 ) ⊂(0, +∞), all values f(x) are positive.
If ℓ= +∞it suﬃces to take a neighbourhood IA(+∞) = (A, +∞) of +∞
(A > 0) and use the corresponding deﬁnition of limit.
2
The next result explains in which sense the implication in Theorem 4.2 can be
‘almost’ reversed.
Corollary 4.3 Assume f admits limit ℓ(ﬁnite or inﬁnite) for x tending to
c. If there is a neighbourhood I(c) of c such that f(x) ≥0 in I(c) \ {c}, then
ℓ≥0 or ℓ= +∞. A similar assertion holds for a ‘negative’ limit.
Proof.
By contradiction, if ℓ= −∞or ℓ< 0, Theorem 4.2 would provide a neigh-
bourhood I′(c) of c such that f(x) < 0 on I′(c)\{c}. On the intersection of
I(c) and I′(c) we would then simultaneously have f(x) < 0 and f(x) ≥0,
which is not possible.
2
Note that even assuming the stronger inequality f(x) > 0 on I(c), we would
not be able to exclude ℓmight be zero. For example, the map
f(x) =

x2
if x ̸= 0,
1
if x = 0,
is strictly positive in every neighbourhood of the origin, yet lim
x→0 f(x) = 0.
4.1.2 Comparison theorems
A few results are known that allow to compare the behaviour of functions, the ﬁrst
of which generalises the above corollary.

92
4 Limits and continuity II
Corollary 4.4 (First comparison theorem) Let a function f have limit
ℓand a function g limit m (ℓ, m ﬁnite or not) for x →c. If there is a
neighbourhood I(c) of c such that f(x) ≤g(x) in I(c) \ {c}, then ℓ≤m.
Proof.
If ℓ= −∞or m = +∞there is nothing to prove. Otherwise, consider the
map h(x) = g(x) −f(x). By assumption h(x) ≥0 on I(c) \ {c}. Besides,
Theorem 4.10 on the algebra of limits guarantees
lim
x→c h(x) = lim
x→c g(x) −lim
x→c f(x) = m −ℓ.
The previous corollary applied to h forces m −ℓ≥0, hence the claim. 2
We establish now two useful criteria on the existence of limits based on com-
paring a given function with others whose limit is known.
Theorem 4.5 (Second comparison theorem – ﬁnite case, also known
as “Squeeze rule”) Let functions f, g and h be given, and assume f and h
have the same ﬁnite limit for x →c, precisely
lim
x→c f(x) = lim
x→c h(x) = ℓ.
If there is a neighbourhood I(c) of c where the three functions are deﬁned
(except possibly at c) and such that
f(x) ≤g(x) ≤h(x),
∀x ∈I(c) \ {c},
(4.2)
then
lim
x→c g(x) = ℓ.
Proof.
We follow the deﬁnition of limit for g. Fix a neighbourhood Iε(ℓ) of ℓ; by
the hypothesis lim
x→c f(x) = ℓwe deduce the existence of a neighbourhood
I′(c) of c such that
∀x ∈dom f,
x ∈I′(c) \ {c}
⇒
f(x) ∈Iε(ℓ).
The condition f(x) ∈Iε(ℓ) can be written as |f(x) −ℓ| < ε, or
ℓ−ε < f(x) < ℓ+ ε,
(4.3)
recalling (1.4). Similarly, lim
x→c h(x) = ℓimplies there is a neighbourhood
I′′(c) of c such that

4.1 Theorems on limits
93
x0
ℓ
y = f(x)
y = f(x)
y = g(x)
y = g(x)
y = h(x)
y = h(x)
Figure 4.3. The squeeze rule
∀x ∈dom h,
x ∈I′′(c) \ {c}
⇒
ℓ−ε < h(x) < ℓ+ ε.
(4.4)
Deﬁne then I′′′(c) = I(c) ∩I′(c) ∩I′′(c). On I′′′(c) \ {c} the constraints
(4.2), (4.3) and (4.4) all hold, hence in particular
x ∈I′′′(c) \ {c}
⇒
ℓ−ε < f(x) ≤g(x) ≤h(x) < ℓ+ ε.
This means g(x) ∈Iε(ℓ), concluding the proof.
2
Examples 4.6
i) Let us prove the fundamental limit
lim
x→0
sin x
x
= 1.
(4.5)
Observe ﬁrst that y = sin x
x
is even, for sin(−x)
−x
= −sin x
−x
= sin x
x
. It is thus
suﬃcient to consider a positive x tending to 0, i.e., prove that lim
x→0+
sin x
x
= 1.
Recalling (3.13), for all x > 0 we have sin x < x, or sin x
x
< 1. To ﬁnd a
lower bound, suppose x < π
2 and consider points on the unit circle: let A have
coordinates (1, 0), P coordinates (cos x, sin x) and let Q be deﬁned by (1, tan x)
(Fig. 4.4). The circular sector OAP is a proper subset of the triangle OAQ, so
Area OAP < Area OAQ.
Since
Area OAP = OA·
⌢
AP
2
= x
2
and
Area OAQ = OA · AQ
2
= tan x
2
,

94
4 Limits and continuity II
O
A
Q
P
x
1
Figure 4.4. The sector OAP is properly contained in OAQ
it follows
x
2 < sin x
2 cosx,
i.e.,
cos x < sin x
x
.
Eventually, on 0 < x < π
2 one has
cos x < sin x
x
< 1.
The continuity of the cosine ensures lim
x→0+ cos x = 1. Now the claim follows from
the Second comparison theorem.
ii) We would like to study how the function g(x) = sin x
x
behaves for x tending
to +∞. Remember that
−1 ≤sin x ≤1
(4.6)
for any real x. Dividing by x > 0 will not alter the inequalities, so in every
neighbourhood IA(+∞) of +∞
−1
x ≤sin x
x
≤1
x.
Now set f(x) = −1
x, h(x) = 1
x and note
lim
x→+∞
1
x = 0. By the previous theorem
lim
x→+∞
sin x
x
= 0.
2
The latter example is part of a more general result which we state next (and
both are consequences of Theorem 4.5).

4.1 Theorems on limits
95
Corollary 4.7 Let f be a bounded function around c, i.e., there exist a
neighbourhood I(c) and a constant C > 0 such that
|f(x)| ≤C,
∀x ∈I(c) \ {c} .
(4.7)
Let g be such that
lim
x→c g(x) = 0.
Then it follows
lim
x→c f(x)g(x) = 0.
Proof.
By deﬁnition lim
x→c g(x) = 0 if and only if lim
x→c |g(x)| = 0, and (4.7) implies
0 ≤|f(x)g(x)| ≤C|g(x)|,
∀x ∈I(c) \ {c}.
The claim follows by applying Theorem 4.5.
2
Theorem 4.8 (Second comparison theorem – inﬁnite case) Let f, g be
given functions and
lim
x→c f(x) = +∞.
If there exists a neighbourhood I(c) of c, where both functions are deﬁned
(except possibly at c), such that
f(x) ≤g(x),
∀x ∈I(c) \ {c},
(4.8)
then
lim
x→c g(x) = +∞.
A result of the same kind for f holds when the limit of g is −∞.
Proof.
The proof is, with the necessary changes, like that of Theorem 4.5, hence
left to the reader.
2
Example 4.9
Compute the limit of g(x) = x + sin x when x →+∞. Using (4.6) we have
x −1 ≤x + sin x,
∀x ∈R.
Set f(x) = x −1; since
lim
x→+∞f(x) = +∞, the theorem tells us
lim
x→+∞(x + sin x) = +∞.
2

96
4 Limits and continuity II
4.1.3 Algebra of limits. Indeterminate forms of algebraic type
This section is devoted to the interaction of limits with the algebraic operations
of sum, diﬀerence, product and quotient of functions.
First though, we must extend arithmetic operations to treat the symbols +∞
and −∞. Let us set:
+∞+ s = +∞
(if s ∈R or s = +∞)
−∞+ s = −∞
(if s ∈R or s = −∞)
±∞· s = ±∞
(if s > 0 or s = +∞)
±∞· s = ∓∞
(if s < 0 or s = −∞)
±∞
s
= ±∞
(if s > 0)
±∞
s
= ∓∞
(if s < 0)
s
0 = ∞
(if s ∈R \ {0} or s = ±∞)
s
±∞= 0
(if s ∈R)
Instead, the following expressions are not deﬁned
±∞+ (∓∞),
±∞−(±∞),
±∞· 0,
±∞
±∞,
0
0.
A result of the foremost importance comes next.
Theorem 4.10 Suppose f admits limit ℓ(ﬁnite or inﬁnite) and g admits
limit m (ﬁnite or inﬁnite) for x →c. Then
lim
x→c

f(x) ± g(x)

= ℓ± m,
lim
x→c

f(x) g(x)

= ℓm,
lim
x→c
f(x)
g(x) = ℓ
m,
provided the right-hand-side expressions make sense. (In the last case one
assumes g(x) ̸= 0 on some I(c)\{c}.)

4.1 Theorems on limits
97
Proof.
We shall prove two relations only, referring the reader to Appendix A.2.1,
p. 433, for the ones left behind. The ﬁrst we concentrate upon is
lim
x→c

f(x) + g(x)

= ℓ+ m
when ℓand m are ﬁnite. Fix ε > 0, and consider the neighbourhood of ℓ
of radius ε/2. By assumption there is a neighbourhood I′(c) of c such that
∀x ∈dom f,
x ∈I′(c) \ {c}
⇒
|f(x) −ℓ| < ε/2.
For the same reason there is also an I′′(c) with
∀x ∈dom g,
x ∈I′′(c) \ {c}
⇒
|g(x) −m| < ε/2.
Put I(c) = I′(c) ∩I′′(c). Then if x ∈dom f ∩dom g belongs to I(c) \ {c},
both inequalities hold; the triangle inequality (1.1) yields
|(f(x) + g(x)) −(ℓ+ m)| = |(f(x) −ℓ) + (g(x) −m)|
≤|f(x) −ℓ| + |g(x) −m| < ε
2 + ε
2 = ε,
proving the assertion.
The second relation is
lim
x→c

f(x) g(x)

= +∞
with ℓ= +∞and m > 0 ﬁnite. For a given real A > 0, consider the
neighbourhood of +∞with end-point B = 2A/m > 0. We know there is
a neighbourhood I′(c) such that
∀x ∈dom f,
x ∈I′(c) \ {c}
⇒
f(x) > B.
On the other hand, considering the neighbourhood of m of radius m/2,
there exists an I′′(c) such that
∀x ∈dom g,
x ∈I′(c) \ {c}
⇒
|g(x) −m| < m/2,
i.e., m/2 < g(x) < 3m/2. Set I(c) = I′(c) ∩I′′(c). If x ∈dom f ∩dom g is
in I(c) \ {c}, the previous relations will be both fulﬁlled, whence
f(x) g(x) > f(x) m
2 > B m
2 = A.
2
Corollary 4.11 If f and g are continuous maps at a point x0 ∈R, then also
f(x) ± g(x), f(x) g(x) and f(x)
g(x) (provided g(x0) ̸= 0) are continuous at x0.

98
4 Limits and continuity II
Proof.
The condition that f and g are continuous at x0 is equivalent to lim
x→x0 f(x) =
f(x0) and lim
x→x0 g(x) = g(x0) (recall (3.9)). The previous theorem allows
to conclude.
2
Corollary 4.12 Rational functions are continuous on their domain. In par-
ticular, polynomials are continuous on R.
Proof.
We veriﬁed in Example 3.17, part i), that the constants y = a and the
linear function y = x are continuous on R. Consequently, maps like y = axn
(n ∈N) are continuous. But then so are polynomials, being sums of the
latter. Rational functions, as quotients of polynomials, inherit the property
wherever the denominator does not vanish.
2
Examples 4.13
i) Calculate
lim
x→0
2x −3 cosx
5 + x sin x = ℓ.
The continuity of numerator and denominator descends from algebraic oper-
ations on continuous maps, and the denominator is not zero at x = 0. The
substitution of 0 to x produces ℓ= −3/5.
ii) Discuss the limit behaviour of y = tan x when x →π
2 . Since
lim
x→π
2
sin x = sin π
2 = 1
and
lim
x→π
2
cos x = cos π
2 = 0,
the above theorem tells
lim
x→π
2
tan x = lim
x→π
2
sin x
cos x = 1
0 = ∞.
But one can be more precise by looking at the sign of the tangent around π
2 . Since
sin x > 0 in a neighbourhood of π
2 , while cos x > 0 (< 0) in a left (resp. right)
neighbourhood of π
2 , it follows
lim
x→π
2
± tan x = ∓∞.
iii) Let R(x) = P(x)
Q(x) be rational and reduced, meaning the polynomials P, Q
have no common factor. Call x0 ∈R a zero of Q, i.e., a point such that Q(x0) = 0.
Clearly P(x0) ̸= 0, otherwise P and Q would be both divisible by (x−x0). Then
lim
x→x0 R(x) = ∞
follows. In this case too, the sign of R(x) around of x0 retains some information.
For instance, y = x2 −3x + 1
x2 −x
is positive on a left neighbourhood of x0 = 1 and
negative on a right neighbourhood, so

4.1 Theorems on limits
99
lim
x→1±
x2 −3x + 1
x2 −x
= ∓∞.
In contrast, the function y =
x −2
x2 −2x + 1 is negative in a whole neighbourhood
of x0 = 1, hence
lim
x→1
x −2
x2 −2x + 1 = −∞.
2
Theorem 4.10 gives no indication about the limit behaviour of an algebraic
expression in three cases, listed below. The expressions in question are called in-
determinate forms of algebraic type.
i)
Consider f(x)+g(x) (resp. f(x)−g(x)) when both f, g tend to ∞with diﬀerent
(resp. same) signs. This gives rise to the indeterminate form denoted by the
symbol
∞−∞.
ii) The product f(x) g(x), when one function tends to ∞and the other to 0, is
the indeterminate form with symbol
∞· 0.
iii) Relatively to f(x)
g(x) , in case both functions tend to ∞or 0, the indeterminate
forms are denoted with
∞
∞
or
0
0.
In presence of an indeterminate form, the limit behaviour cannot be told a
priori, and there are examples for each possible limit: inﬁnite, ﬁnite non-zero, zero,
even non-existing limit. Every indeterminate form should be treated singularly and
requires often a lot of attention.
Later we shall ﬁnd the actual limit behaviour of many important indeterminate
forms. With those and this section’s theorems we will discuss more complicated in-
determinate forms. Additional tools to analyse this behaviour will be provided fur-
ther on: they are the local comparison of functions by means of the Landau symbols
(Sect. 5.1), de l’Hˆopital’s Theorem (Sect. 6.11), the Taylor expansion (Sect. 7.1).
Examples 4.14
i) Let x tend to +∞and deﬁne functions f1(x) = x + x2, f2(x) = x + 1, f3(x) =
x + 1
x, f4(x) = x + sin x. Set g(x) = x. Using Theorem 4.10, or Example 4.9, one
veriﬁes easily that all maps tend to +∞. One has
lim
x→+∞[f1(x) −g(x)] =
lim
x→+∞x2 = +∞,
lim
x→+∞[f2(x) −g(x)] =
lim
x→+∞1 = 1,
lim
x→+∞[f3(x) −g(x)] =
lim
x→+∞
1
x = 0 ,

100
4 Limits and continuity II
whereas the limit of f4(x) −g(x) = sin x does not exist: the function sin x is
periodic and assumes each value between −1 and 1 inﬁnitely many times as
x →+∞.
ii) Consider now x →0. Let f1(x) = x3, f2(x) = x2, f3(x) = x, f4(x) = x2 sin 1
x,
and g(x) = x2. All functions converge to 0 (for f4 apply Corollary 4.7). Now
lim
x→0
f1(x)
g(x) = lim
x→0 x = 0,
lim
x→0
f2(x)
g(x) = lim
x→0 1 = 1,
lim
x→0
f3(x)
g(x) = lim
x→0
1
x, = ∞,
but f4(x)
g(x) = sin 1
x does not admit limit for x →0 (Remark 4.19 furnishes a
proof of this).
iii) Let us consider a polynomial
P(x) = anxn + . . . + a1x + a0
(an ̸= 0)
for x →±∞. A function of this sort can give rise to an indeterminate form
∞−∞according to the coeﬃcients’ signs and the degree of the monomials
involved. The problem is sorted by factoring out the leading term (monomial of
maximal degree) xn
P(x) = xn 
an + an−1
x
+ . . . +
a1
xn−1 + a0
xn

.
The part in brackets converges to an when x →±∞, so
lim
x→±∞P(x) =
lim
x→±∞anxn = ∞
The sign of the limit is easily found. For instance,
lim
x→−∞(−5x3 + 2x2 + 7) =
lim
x→−∞(−5x3) = +∞.
Take now a reduced rational function
R(x) = P(x)
Q(x) = anxn + . . . + a1x + a0
bmxm + . . . + b1x + b0
(an, bm ̸= 0, m > 0).
When x →±∞, an indeterminate form ∞
∞arises. With the same technique as
before,
lim
x→±∞
P(x)
Q(x) =
lim
x→±∞
anxn
bmxm = an
bm
lim
x→±∞xn−m =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
∞
if n > m ,
an
bm
if n = m ,
0
if n < m .

4.1 Theorems on limits
101
For example:
lim
x→+∞
3x3 −2x + 1
x −x2
=
lim
x→+∞
3x3
−x2 = −∞,
lim
x→−∞
−4x5 + 2x3 −7
8x5 −x4 + 5x =
lim
x→−∞
−4x5
8x5
= −1
2 ,
lim
x→−∞
6x2 −x + 5
−x3 + 9
=
lim
x→−∞
6x2
−x3 = 0.
iv) The function y = sin x
x
becomes indeterminate 0
0 for x →0; we proved in part
i), Examples 4.6 that y converges to 1. From this, we can deduce the behaviour
of y = 1 −cos x
x2
as x →0, another indeterminate form of the type 0
0. In fact,
lim
x→0
1 −cos x
x2
= lim
x→0
(1 −cos x)(1 + cos x)
x2(1 + cos x)
= lim
x→0
1 −cos2 x
x2
· lim
x→0
1
1 + cos x.
The fundamental trigonometric equation cos2 x + sin2 x = 1 together with The-
orem 4.10 gives
lim
x→0
sin2 x
x2
= lim
x→0
sin x
x
2
=

lim
x→0
sin x
x
2
= 1.
The same theorem tells also that the second limit is 1
2, so we conclude
lim
x→0
1 −cos x
x2
= 1
2.
2
With these examples we have taken the chance to look at the behaviour of
elementary functions at the boundary points of their domains. For completeness we
gather the most signiﬁcant limits relative to the elementary functions of Sect. 2.6,
their proofs may be found in Appendix A.2.2, p. 435.
lim
x→+∞xα = +∞,
lim
x→0+ xα = 0
α > 0
lim
x→+∞xα = 0 ,
lim
x→0+ xα = +∞
α < 0
lim
x→±∞
anxn + . . . + a1x + a0
bmxm + . . . + b1x + b0
= an
bm
lim
x→±∞xn−m
lim
x→+∞ax = +∞,
lim
x→−∞ax = 0
a > 1
lim
x→+∞ax = 0 ,
lim
x→−∞ax = +∞
a < 1
lim
x→+∞loga x = +∞,
lim
x→0+ loga x = −∞a > 1
lim
x→+∞loga x = −∞,
lim
x→0+ loga x = +∞a < 1

102
4 Limits and continuity II
lim
x→±∞sin x ,
lim
x→±∞cos x ,
lim
x→±∞tan x
do not exist
lim
x→( π
2 +kπ)
± tan x = ∓∞,
∀k ∈Z
lim
x→±1 arcsin x = ±π
2 = arcsin(±1)
lim
x→+1 arccosx = 0 = arccos1 ,
lim
x→−1 arccosx = π = arccos(−1)
lim
x→±∞arctanx = ±π
2
4.1.4 Substitution theorem
The so-called Substitution theorem is important in itself for theoretical reasons,
besides providing a very useful method to compute limits.
Theorem 4.15 Suppose a map f admits limit
lim
x→c f(x) = ℓ,
(4.9)
ﬁnite or not. Let g be deﬁned on a neighbourhood of ℓ(excluding possibly the
point ℓ) and such that
i) if ℓ∈R, g is continuous at ℓ;
ii) if ℓ= +∞or ℓ= −∞, the limit lim
y→ℓg(y) exists, ﬁnite or not.
Then the composition g ◦f admits limit for x →c and
lim
x→c g(f(x)) = lim
y→ℓg(y).
(4.10)
Proof.
Set m = lim
y→ℓg(y) (noting that under i), m = g(ℓ) ). Given any neighbour-
hood I(m) of m, by i) or ii) there will be a neighbourhood I(ℓ) of ℓsuch
that
∀y ∈dom g,
y ∈I(ℓ)
⇒
g(y) ∈I(m).
Note that in case i) we can use I(ℓ) instead of I(ℓ) \ {ℓ} because g is
continuous at ℓ(recall (3.7)), while ℓdoes not belong to I(ℓ) for case ii).
With such I(ℓ), assumption (4.9) implies the existence of a neighbourhood
I(c) of c with
∀x ∈dom f,
x ∈I(c) \ {c}
⇒
f(x) ∈I(ℓ).

4.1 Theorems on limits
103
Since x ∈dom g ◦f means x ∈dom f plus y = f(x) ∈dom g, the previous
two implications now give
∀x ∈dom g ◦f,
x ∈I(c) \ {c}
⇒
g(f(x)) ∈I(m).
But I(m) was arbitrary, so
lim
x→c g(f(x)) = m.
2
Remark 4.16 An alternative condition that yields the same conclusion is the
following:
i’) if ℓ∈R, there is a neighbourhood I(c) of c where f(x) ̸= ℓfor all x ̸= c, and
the limit lim
y→ℓg(y) exists, ﬁnite or inﬁnite.
The proof is analogous.
2
In case ℓ∈R and g is continuous at ℓ(case i) ), then lim
y→ℓg(y) = g(ℓ), so (4.10)
reads
lim
x→c g(f(x)) = g(lim
x→c f(x)).
(4.11)
An imprecise but eﬀective way to put (4.11) into words is to say that a continuous
function commutes (exchanges places) with the symbol of limit.
Theorem 4.15 implies that continuity is inherited by composite functions, as
we discuss hereby.
Corollary 4.17 Let f be continuous at x0, and deﬁne y0 = f(x0). Let fur-
thermore g be deﬁned around y0 and continuous at y0. Then the composite
g ◦f is continuous at x0.
Proof.
From (4.11)
lim
x→x0(g ◦f)(x) = g( lim
x→x0 f(x)) = g(f(x0)) = (g ◦f)(x0),
which is equivalent to the claim.
2
A few practical examples will help us understand how the Substitution theorem
and its corollary are employed.
Examples 4.18
i) The map h(x) = sin(x2) is continuous on R, being the composition of the
continuous functions f(x) = x2 and g(y) = sin y.

104
4 Limits and continuity II
ii) Let us determine
lim
x→0
sin(x2)
x2
.
Set f(x) = x2 and
g(y) =
⎧
⎨
⎩
sin y
y
if y ̸= 0,
1
if y = 0.
Then lim
x→0 f(x) = 0, and we know that g is continuous at the origin. Thus
lim
x→0
sin(x2)
x2
= lim
y→0
sin y
y
= 1.
iii) We study the behaviour of h(x) = arctan

1
x −1

around the point 1.
Deﬁning f(x) =
1
x −1, we have
lim
x→1± f(x) = ±∞. If we call g(y) = arctan y ,
lim
y→±∞g(y) = ±π
2 (see the Table on page 101). Therefore
lim
x→1± arctan

1
x −1

=
lim
y→±∞g(y) = ±π
2 .
iv) Determine
lim
x→+∞log sin 1
x .
Setting f(x) = sin 1
x has the eﬀect that ℓ=
lim
x→+∞f(x) = 0. Note that f(x) > 0
for all x > 1
π. With g(y) = log y we have lim
y→0+ g(y) = −∞, so Remark 4.16 yields
lim
x→+∞log sin 1
x = lim
y→0+ g(y) = −∞.
2
Remark 4.19 Theorem 4.15 extends easily to cover the case where the role of f
is played by a sequence a : n →an with limit
lim
n→∞an = ℓ.
Namely, under the same assumptions on g,
lim
n→∞g(an) = lim
y→ℓg(y).
This result is often used to disprove the existence of a limit, in that it provides a
Criterion of non-existence for limits: if two sequences a : n →an, b : n →bn
have the same limit ℓand
lim
n→∞g(an) ̸= lim
n→∞g(bn),
then g does not admit limit when its argument tends to ℓ.

4.2 More fundamental limits. Indeterminate forms of exponential type
105
For example we can prove, with the aid of the criterion, that y = sin x has no
limit when x →+∞: deﬁne the sequences an = 2nπ and bn = π
2 + 2nπ, n ∈N, so
that
lim
n→∞sin an = lim
n→∞0 = 0,
and at the same time
lim
n→∞sin bn = lim
n→∞1 = 1.
Similarly, the function y = sin 1
x has neither left nor right limit for x →0.
2
4.2 More fundamental limits. Indeterminate forms of
exponential type
Consider the paramount limit (3.3). Instead of the sequence an =

1 + 1
n
n
, we
look now at the function of real variable
h(x) =

1 + 1
x
x
.
It is deﬁned when 1 + 1
x > 0, hence on (−∞, −1) ∪(0, +∞). The following result
states that h and the sequence resemble each other closely when x tends to inﬁnity.
Its proof is given in Appendix A.2.3, p. 439.
Property 4.20 The following limit holds
lim
x→±∞

1 + 1
x
x
= e.
By manipulating this formula we achieve a series of new fundamental limits.
The substitution y = x
a, with a ̸= 0, gives
lim
x→±∞

1 + a
x
x
=
lim
y→±∞

1 + 1
y
ay
=

lim
y→±∞

1 + 1
y
ya
= ea.
In terms of the variable y = 1
x then,
lim
x→0 (1 + x)1/x =
lim
y→±∞

1 + 1
y
y
= e.
The continuity of the logarithm together with (4.11) furnish
lim
x→0
loga(1 + x)
x
= lim
x→0 loga (1 + x)1/x = loga lim
x→0 (1 + x)1/x = loga e =
1
log a
for any a > 0. In particular, taking a = e:

106
4 Limits and continuity II
lim
x→0
log(1 + x)
x
= 1.
Note by the way ax −1 = y is equivalent to x = loga(1 + y), and y →0 if x →0.
With this substitution,
lim
x→0
ax −1
x
= lim
y→0
y
loga(1 + y) =

lim
y→0
loga(1 + y)
y
−1
= log a.
(4.12)
Taking a = e produces
lim
x→0
ex −1
x
= 1.
Eventually, let us set 1 + x = ey. Since y →0 when x →0,
lim
x→0
(1 + x)α −1
x
= lim
y→0
eαy −1
ey −1 = lim
y→0
eαy −1
y
y
ey −1
= lim
y→0
(eα)y −1
y
lim
y→0
y
ey −1 = log eα = α
(4.13)
for any α ∈R.
For the reader’s conveniency, all fundamental limits found so far are gathered
below.
lim
x→0
sin x
x
= 1
lim
x→0
1 −cos x
x2
= 1
2
lim
x→±∞

1 + a
x
x
= ea
(a ∈R)
lim
x→0(1 + x)1/x = e
lim
x→0
loga(1 + x)
x
=
1
log a (a > 0); in particular, lim
x→0
log(1 + x)
x
= 1
lim
x→0
ax −1
x
= log a
(a > 0);
in particular,
lim
x→0
ex −1
x
= 1
lim
x→0
(1 + x)α −1
x
= α
(α ∈R).

4.2 More fundamental limits. Indeterminate forms of exponential type
107
Let us return to the map h(x) =

1 + 1
x
x
. By setting f(x) =

1 + 1
x

and
g(x) = x, we can write
h(x) = [f(x)]g(x).
In general such an expression may give rise to indeterminate forms for x tending
to a certain c. Suppose f, g are functions deﬁned in a neighbourhood of c, except
possibly at c, and that they admit limit for x →c. Assume moreover f(x) > 0
around c, so that h is well deﬁned in a neighbourhood of c (except possibly at c).
To understand h it is convenient to use the identity
f(x) = elog f(x).
From this in fact we obtain
h(x) = eg(x) log f(x).
By continuity of the exponential and (4.11), we have
lim
x→c[f(x)]g(x) = exp

lim
x→c [g(x) log f(x)]

.
In other words, h(x) can be studied by looking at the exponent g(x) log f(x).
An indeterminate form of the latter will thus develop an indeterminate form
of exponential type for h(x). Namely, we might ﬁnd ourselves in one of these
situations:
i) g tends to ∞and f to 1 (so log f tends to 0): the exponent is an indeterminate
form of type ∞· 0, whence we say that h presents an indeterminate form of
type
1∞.
ii) g and f both tend to 0 (so log f tends to −∞): once again the exponent is of
type ∞· 0, and the function h is said to have an indeterminate form of type
00.
iii) g tends to 0 and f tends to +∞(log f →+∞): the exponent is of type ∞· 0,
and h becomes indeterminate of type
∞0.
Examples 4.21
i) The map h(x) =

1 + 1
x
x
is an indeterminate form of type 1∞when x →
±∞, whose limit equals e.
ii) The function h(x) = xx, for x →0+, is an indeterminate form of type 00. We
shall prove in Chap. 6 that lim
x→0+ x log x = 0, therefore lim
x→0+ h(x) = 1.

108
4 Limits and continuity II
iii) The function h(x) = x1/x is for x →+∞an indeterminate form of type ∞0.
Substituting y = 1
x, and recalling that log 1
y = −log y, we obtain
lim
x→+∞
log x
x
=
−lim
y→0+ y log y = 0 , hence
lim
x→+∞h(x) = 1.
2
When dealing with h(x) = [f(x)]g(x), a rather common mistake – with tragic
consequences – is to calculate ﬁrst the limit of f and/or g, substitute the map
with this value and compute the limit of the expression thus obtained. This is to
emphasize that it might be incorrect to calculate the limit for x →c of the
indeterminate form h(x) = [f(x)]g(x) by ﬁnding ﬁrst
m = lim
x→c g(x),
and from this proceed to
lim
x→c[f(x)]m.
Equally incorrect might be to determine
lim
x→c ℓg(x),
already knowing
ℓ= lim
x→c f(x).
For example, suppose we are asked to ﬁnd the limit of h(x) =

1 + 1
x
x
for
x →±∞; we might think of ﬁnding ﬁrst ℓ=
lim
x→±∞

1 + 1
x

= 1 and from this
lim
x→±∞1x =
lim
x→±∞1 = 1. This would lead us to believe, wrongly, that h converges
to 1, in spite of the fact the correct limit is e.
4.3 Global features of continuous maps
Hitherto the focus has been on several local properties of functions, whether in the
neighbourhood of a real point or a point at inﬁnity, and limits have been discussed
in that respect. Now we turn our attention to continuous functions deﬁned on a
real interval, and establish properties of global nature, i.e., those relative to the
behaviour on the entire domain.
Let us start with a plain deﬁnition.
Deﬁnition 4.22 A zero of a real-valued function f is a point x0 ∈dom f
at which the function vanishes.
For instance, the zeroes of y = sin x are the multiples of π, i.e., the elements of
the set {mπ | m ∈Z}.
The problem of solving an equation like
f(x) = 0

4.3 Global features of continuous maps
109
is equivalent to determining the zeroes of the function y = f(x). That is why it
becomes crucial to have methods, both analytical and numerical, that allow to
ﬁnd the zeroes of a function, or at least their approximate position.
A simple condition to have a zero inside an interval goes as follows.
Theorem 4.23 (Existence of zeroes) Let f be a continuous map on a
closed, bounded interval [a, b]. If f(a)f(b) < 0, i.e., if the images of the end-
points under f have diﬀerent signs, f admits a zero within the open inter-
val (a, b).
If moreover f is strictly monotone on [a, b], the zero is unique.
a
b
x0
f(a)
f(b)
y = f(x)
Figure 4.5. Theorem of existence of zeroes
Proof.
Throughout the proof we shall use properties of sequences, for which we
refer to the following Sect. 5.4. Assuming f(a) < 0 < f(b) is not restrictive.
Deﬁne a0 = a, b0 = b and let c0 =
a0+b0
2
be the middle point of the
interval [a0, b0]. There are three possibilities for f(c0). If f(c0) = 0, the
point x0 = c0 is a zero and the proof ends. If f(c0) > 0, we set a1 = a0 and
b1 = c0, so to consider the left half of the original interval. If f(c0) < 0,
let a1 = c0, b1 = b0 and take the right half of [a0, b0] this time. In either
case we have generated a sub-interval [a1, b1] ⊂[a0, b0] such that
f(a1) < 0 < f(b1)
and
b1 −a1 = b0 −a0
2
.
Repeating the procedure we either reach a zero of f after a ﬁnite number
of steps, or we build a sequence of nested intervals [an, bn] satisfying:

110
4 Limits and continuity II
[a0, b0] ⊃[a1, b1] ⊃. . . ⊃[an, bn] ⊃. . . ,
f(an) < 0 < f(bn)
and
bn −an = b0 −a0
2n
(the rigorous proof of the existence of such a sequence relies on the Prin-
ciple of Induction; details are provided in Appendix A.1, p. 429). In this
second situation, we claim that there is a unique point x0 belonging to
every interval of the sequence, and this point is a zero of f. For this,
observe that the sequences {an} and {bn} satisfy
a0 ≤a1 ≤. . . ≤an ≤. . . ≤bn ≤. . . ≤b1 ≤b0.
Therefore {an} is monotone increasing and bounded, while {bn} is mono-
tone decreasing and bounded. By Theorem 3.9 there exist x−
0 , x+
0 ∈[a, b]
such that
lim
n→∞an = x−
0
and
lim
n→∞bn = x+
0 .
On the other hand, Example 5.18 i) tells
x+
0 −x−
0 = lim
n→∞(bn −an) = lim
n→∞
b −a
2n
= 0,
so x−
0 = x+
0 . Let x0 denote this number. Since f is continuous, and using
the Substitution theorem (Theorem 9, p. 138), we have
lim
n→∞f(an) = lim
n→∞f(bn) = f(x0).
But f(an) < 0 < f(bn), so the First comparison theorem (Theorem 4,
p. 137) for {f(an)} and {f(bn)} gives
lim
n→∞f(an) ≤0
and
lim
n→∞f(bn) ≥0.
As 0 ≤f(x0) ≤0, we obtain f(x0) = 0.
In conclusion, if f is strictly monotone on [a, b] it must be injective by
Proposition 2.8, which forces the zero to be unique.
2
Some comments on this theorem might prove useful. We remark ﬁrst that
without the hypothesis of continuity on the closed interval [a, b], the condition
f(a)f(b) < 0 would not be enough to ensure the presence of a zero. The function
f : [0, 1] →R
f(x) =
 −1
for x = 0,
+1
for 0 < x ≤1
takes values of discordant sign at the end-points but never vanishes; it has a jump
point at a = 0.
Secondly, f(a)f(b) < 0 is a suﬃcient requirement only, and not a necessary one,
to have a zero. The continuous map f(x) = (2x −1)2 vanishes on [0, 1] despite
being positive at both ends of the interval.

4.3 Global features of continuous maps
111
Thirdly, the halving procedure used in the proof can be transformed into an al-
gorithm of approximation, known in Numerical Analysis under the name Bisection
method.
A ﬁrst application of the Theorem of existence of zeroes comes next.
Example 4.24
The function f(x) = x4 + x3 −1 on [0, 1] is a polynomial, hence continuous.
As f(0) = −1 and f(1) = 1, f must vanish somewhere on [0, 1]. The zero is
unique because the map is strictly increasing (it is sum of the strictly increasing
functions y = x4 and y = x3, and of the constant function y = −1).
2
Our theorem can be generalised usefully as follows.
Corollary 4.25 Let f be continuous on the interval I and suppose it admits
non-zero limits (ﬁnite or inﬁnite) that are diﬀerent in sign for x tending to
the end-points of I. Then f has a zero in I, which is unique if f is strictly
monotone on I.
Proof.
The result is a consequence of Theorems 4.2 and 4.23 (Existence of zeroes).
For more details see Appendix A.3.2, p. 444.
2
Example 4.26
Consider the map f(x) = x+log x, deﬁned on I = (0, +∞). The functions y = x
and y = log x are continuous and strictly increasing on I, and so is f. Since
lim
x→0+ f(x) = −∞and
lim
x→+∞f(x) = +∞, f has exactly one zero on its domain.
2
Corollary 4.27 Consider f and g continuous maps on the closed bounded
interval [a, b]. If f(a) < g(a) and f(b) > g(b) , there exists at least one point
x0 in the open interval (a, b) with
f(x0) = g(x0).
(4.14)
Proof.
Consider the auxiliary function h(x) = f(x)−g(x), which is continuous in
[a, b] as sum of continuous maps. By assumption, h(a) = f(a) −g(a) < 0
and h(b) = f(b) −g(b) > 0. So, h satisﬁes the Theorem of existence of
zeroes and admits in (a, b) a point x0 such that h(x0) = 0. But this is
precisely (4.14).
Note that if h is strictly increasing on [a, b], the solution of (4.14) has to
be unique in the interval.
2

112
4 Limits and continuity II
a
b
x0
f(a)
f(b)
y = f(x)
g(a)
g(b)
y = g(x)
Figure 4.6. Illustration of Corollary 4.27
Example 4.28
Solve the equation
cos x = x.
(4.15)
For any real x, −1 ≤cos x ≤1, so the equation cannot be solved when x < −1 or
x > 1. Similarly, no solution exists on [−1, 0), because cos x is positive while x is
negative on that interval. Therefore the solutions, if any, must hide in [0, 1]: there
the functions f(x) = x and g(x) = cos x are continuous and f(0) = 0 < 1 = g(0),
f(1) = 1 > cos 1 = g(1) (cosine is 1 only for multiples of 2π). The above corollary
implies that equation (4.15) has a solution in (0, 1). There can be no other
solution, for f is strictly increasing and g strictly decreasing on [0, 1], making
h(x) = f(x) −g(x) strictly increasing.
2
When one of the functions is a constant, the corollary implies this result.
Theorem 4.29 (Intermediate value theorem) If a function f is continu-
ous on the closed and bounded interval [a, b], it assumes all values between
f(a) and f(b).
Proof.
When f(a) = f(b) the statement is trivial, so assume ﬁrst f(a) < f(b).
Call z an arbitrary value between f(a) and f(b) and deﬁne the constant
map g(x) = z. From f(a) < z < f(b) we have f(a) < g(a) and f(b) > g(b).
Corollary 4.27, applied to f and g in the interval [a, b], yields a point x0
in [a, b] such that f(x0) = g(x0) = z.
If f(a) > f(b), we just swap the roles of f and g.
2
The Intermediate value theorem has, among its consequences, the remarkable
fact that a continuous function maps intervals to intervals. This is the content of
the next result.

4.3 Global features of continuous maps
113
x0
a
b
z = f(x0)
f(b)
f(a)
y = f(x)
Figure 4.7. Intermediate value theorem
Corollary 4.30 Let f be continuous on an interval I. The range f(I) of I
under f is an interval delimited by infI f and supI f.
Proof.
A subset of R is an interval if and only if it contains the interval [α, β] as
subset, for any α < β.
Let then y1 < y2 be points of f(I). There exist in I two (necessarily dis-
tinct) pre-images x1 and x2, i.e., f(x1) = y1, f(x2) = y2. If J ⊆I denotes
the closed interval between x1 and x2, we need only to apply the Intermedi-
ate value theorem to f restricted to J, which yields [y1, y2] ⊆f(J) ⊆f(I).
The range f(I) is then an interval, and according to Deﬁnition 2.3 its
end-points are infI f and supI f.
2
Either one of infI f, supI f may be ﬁnite or inﬁnite, and may or not be an
element of the interval itself. If, say, infI f belongs to the range, the function
admits minimum on I (and the same for supI f).
In case I is open or half-open, its image f(I) can be an interval of any kind. Let
us see some examples. Regarding f(x) = sin x on the open bounded I = (−π
2 , π
2 ),
the image f(I) = (−1, 1) is open and bounded. Yet under the same map, the image
of the open bounded set (0, 2π) is [−1, 1], bounded but closed. Take now f(x) =
tan x: it maps the bounded interval (−π
2 , π
2 ) to the unbounded one (−∞, +∞).
Simple examples can be built also for unbounded I.
But if I is a closed bounded interval, its image under a continuous map cannot
be anything but a closed bounded interval. More precisely, the following funda-
mental result holds, whose proof is given in Appendix A.3.2, p. 443.

114
4 Limits and continuity II
Theorem 4.31 (Weierstrass) A continuous map f on a closed and bounded
interval [a, b] is bounded and admits minimum and maximum
m = min
x∈[a,b] f(x)
and
M = max
x∈[a,b] f(x).
Consequently,
f([a, b]) = [m, M].
(4.16)
a
b
xm
m
xM
M
y = f(x)
Figure 4.8. The Theorem of Weierstrass
In conclusion to this section, we present two results about invertibility (their
proofs may be found in Appendix A.3.2, p. 445). We saw in Sect. 2.4 that a strictly
monotone function is also one-to-one (invertible), and in general the opposite im-
plication does not hold. Nevertheless, when speaking of continuous functions the
notions of strict monotonicity and injectivity coincide. Moreover, the inverse func-
tion is continuous on its domain of deﬁnition.
Theorem 4.32 A continuous function f on an interval I is one-to-one if
and only if it is strictly monotone.
Theorem 4.33 Let f be continuous and invertible on an interval I. Then
the inverse f −1 is continuous on the interval J = f(I).
Theorem 4.33 guarantees, by the way, the continuity of the inverse trigonomet-
ric functions y = arcsinx, y = arccosx and y = arctanx on their domains, and
of the logarithm y = loga x on R+ as well, as inverse of the exponential y = ax.
These facts were actually already known from Proposition 3.20.

4.4 Exercises
115
I
J = f(I)
y = f(x)
I
J
x = f −1(y)
Figure 4.9. Graph of a continuous invertible map (left) and its inverse (right)
4.4 Exercises
1. Compute the following limits using the Comparison theorems:
a)
lim
x→+∞
cos x
√x
b)
lim
x→+∞
√x + sin x

c)
lim
x→−∞
2x −sin x
3x + cos x
d)
lim
x→+∞
[x]
x
e)
lim
x→0 sin x · sin 1
x
f)
lim
x→0
x −tan x
x2
2. Determine the limits:
a)
lim
x→0
x4 −2x3 + 5x
x5 −x
b)
lim
x→+∞
x + 3
x3 −2x + 5
c)
lim
x→−∞
x3 + x2 + x
2x2 −x + 3
d)
lim
x→+∞
2x2 + 5x −7
5x2 −2x + 3
e)
lim
x→−1
x + 1
√
6x2 + 3 + 3x
f)
lim
x→2
3√10 −x −2
x −2
g)
lim
x→+∞
√
x + 1 −√x

h)
lim
x→+∞
√x + x
x
i)
lim
x→−∞
 3√
x + 1 −
3√
x −1

ℓ)
lim
x→−∞
√
2x2 + 3
4x + 2
3. Relying on the fundamental limits, compute:
a) lim
x→0
sin2 x
x
b) lim
x→0
x tan x
1 −cos x

116
4 Limits and continuity II
c)
lim
x→0
sin 2x −sin 3x
4x
d)
lim
x→0+
1 −cos √x
2x2
e)
lim
x→0
tan x −sin x
x3
f)
lim
x→0
cos(tan x) −1
tan x
g)
lim
x→1
cos π
2 x
1 −x
h)
lim
x→π
2
sin x −1
 π
2 −x
2
i)
lim
x→π
cos x + 1
cos 3x + 1
ℓ)
lim
x→0
√1 + tan x −√1 −tan x
sin x
4. Calculate:
a)
lim
x→0
log(1 + x)
3x −1
b)
lim
x→0
e2x −1
e3x −1
c)
lim
x→e
log x −1
x −e
d)
lim
x→+∞
ex
ex −1
e)
lim
x→0+
2e2x −1
2x
f)
lim
x→1
log x
ex −e
g)
lim
x→0
5√1 + 3x −1
x
h)
lim
x→−1
x + 1
4√x + 17 −2
5. Compute the limits:
a)
lim
x→+∞
x5/2 −2x√x + 1
2
√
x5 −1
b)
lim
x→0
ex −e−x
sin x
c)
lim
x→0

cotan x −
1
sin x

d)
lim
x→+∞
√x
√
x + 1 −
√
x −1

e)
lim
x→+∞
x −1
x + 3
x−2
f)
lim
x→0 (1 + x)cotan x
g)
lim
x→5
x −5
√x −
√
5
h)
lim
x→−∞
3x −3−x
3x + 3−x
i)
lim
x→0

1
x tan x −
1
x sin x

ℓ)
lim
x→+∞xex sin

e−x sin 2
x

m)
lim
x→+∞x(2 + sin x)
n)
lim
x→−∞xesin x
6. Determine the domain of the functions below and their limit behaviour at the
end-points of the domain:
a)
f(x) = x3 −x2 + 3
x2 + 3x + 2
b)
f(x) =
ex
1 + x4
c)
f(x) = log

1 + exp
x2 + 1
x

d)
f(x) =
3√xe−x2

4.4 Exercises
117
4.4.1 Solutions
1. Limits:
a) 0 ;
b) +∞.
c) We have
lim
x→−∞
2x −sin x
3x + cosx =
lim
x→−∞
x

2 −sin x
x

x

3 + cos x
x
 = 2
3
because
lim
x→−∞
sin x
x
=
lim
x→−∞
cos x
x
= 0 by Corollary 4.7.
d) From [x] ≤x < [x] + 1 (Example 2.1 vii)) one deduces straightaway x −1 <
[x] ≤x, whence
x −1
x
< [x]
x ≤1
for x > 0. Therefore, the Second comparison theorem 4.5 gives
lim
x→+∞
[x]
x = 1.
e) 0.
f) First of all f(x) = x −tan x
x2
is an odd map, so lim
x→0+ f(x) = −lim
x→0−f(x). Let
now 0 < x < π
2 . From
sin x < x < tan x
(see Example 4.6 i) for a proof) it follows
sin x −tan x < x −tan x < 0,
that is,
sin x −tan x
x2
< x −tan x
x2
< 0.
Secondly,
lim
x→0+
sin x −tan x
x2
= lim
x→0+
sin x (cos x −1)
x2 cos x
= lim
x→0+
sin x
cos x
cos x −1
x2
= 0 .
Thus the Second comparison theorem 4.5 makes us conclude that
lim
x→0+
x −tan x
x2
= 0,
therefore the required limit is 0.
2. Limits:
a) −5 ;
b) 0.

118
4 Limits and continuity II
c) Simple algebraic operations give
lim
x→−∞
x3 + x2 + x
2x2 −x + 3 =
lim
x→−∞
x3 
1 + 1
x +
1
x2

x2 
2 −1
x +
3
x2
 =
lim
x→−∞
x
2 = −∞.
d)
2
5.
e) Rationalising the denominator we see
lim
x→−1
x + 1
√
6x2 + 3 + 3x
= lim
x→−1
(x + 1)(
√
6x2 + 3 −3x)
6x2 + 3 −9x2
= lim
x→−1
(x + 1)(
√
6x2 + 3 −3x)
3(1 −x)(1 + x)
= 1 .
f) Use the relation a3 −b3 = (a −b)(a2 + ab + b2) in
lim
x→2
3√10 −x −2
x −2
= lim
x→2
10 −x −8
(x −2)( 3
(10 −x)2 + 2
3√10 −x + 4)
= lim
x→2
−1
3
(10 −x)2 + 2
3√10 −x + 4
= −1
12 .
g) 0 ;
h) 1 ;
i) 0.
ℓ) We have
lim
x→−∞
√
2x2 + 3
4x + 2
=
lim
x→−∞
|x|

2 +
3
x2
x

4 + 2
x

=
√
2
4
lim
x→−∞
−x
x = −
√
2
4 .
3. Limits:
a) 0 ;
b) 2.
c) We manipulate the expression so to obtain a fundamental limit:
lim
x→0
sin 2x −sin 3x
4x
= lim
x→0
sin 2x
4x
−lim
x→0
sin 3x
4x
= 1
2 −3
4 = −1
4 .
d) We use the cosine’s fundamental limit:
lim
x→0+
1 −cos √x
2x2
= lim
x→0+
1 −cos √x
x
lim
x→0+
1
2x = 1
2 lim
x→0+
1
2x = +∞.
e)
1
2.
f) Putting y = tan x and substituting,
lim
x→0
cos(tan x) −1
tan x
= lim
y→0
cos y −1
y
= lim
y→0
cos y −1
y2
· y = 0 .

4.4 Exercises
119
g) Letting y = 1 −x transforms the limit into:
lim
x→1
cos π
2 x
1 −x = lim
y→0
cos π
2 (1 −y)
y
= lim
y→0
sin π
2 y
y
= π
2 .
h) −1
2 ;
i) 1
9.
ℓ) One has
lim
x→0
√1 + tan x −√1 −tan x
sin x
= lim
x→0
1 + tan x −1 + tan x
sin x
√1 + tan x + √1 −tan x

= 1
2 lim
x→0
2 tan x
sin x
= lim
x→0
1
cos x = 1 .
4. Limits:
a)
1
log 3 ;
b) 2
3.
c) By deﬁning y = x −e we recover a known fundamental limit:
lim
x→e
log x −1
x −e
= lim
y→0
log(y + e) −1
y
= lim
y→0
log e (1 + y/e) −1
y
= lim
y→0
log(1 + y/e)
y
= 1
e .
Another possibility is to set z = x/e:
lim
x→e
log x −1
x −e
= lim
z→1
log(ez) −1
e(z −1)
= 1
e lim
z→1
log z
z −1 = 1
e .
d) 1.
e) We have
lim
x→0+
2e2x −1
2x
= lim
x→0+
2(e2x −1) + 1
2x
= lim
x→0+ 2e2x −1
2x
+ lim
x→0+
1
2x = 2 + lim
x→0+
1
2x = +∞.
f) Substitute y = x −1, so that
lim
x→1
log x
ex −e = lim
x→1
log x
e(ex−1 −1)
= lim
y→0
log(1 + y)
e(ey −1) = 1
e lim
y→0
log(1 + y)
y
·
y
ey −1 = 1
e .
g)
3
5.

120
4 Limits and continuity II
h) The new variable y = x + 1 allows to recognize (4.13), so
lim
x→−1
x + 1
4√x + 17 −2 = lim
y→0
y
4√y + 16 −2 = lim
y→0
y
2

4
1 + y
16 −1

= 16
2 lim
y→0
y/16
4
1 + y
16 −1 = 8 · 4 = 32 .
5. Limits:
a)
1
2.
b) We have
lim
x→0
ex −e−x
sin x
= lim
x→0
e−x 
e2x −1

sin x
= lim
x→0 e−x · e2x −1
2x
· 2 ·
x
sin x = 2 .
c) One has
lim
x→0

cotan x −
1
sin x

= lim
x→0
cos x −1
sin x
= lim
x→0
cos x −1
x2
·
x
sin x · x = 0 .
d) 1.
e) Start with
lim
x→+∞
x −1
x + 3
x−2
= exp

lim
x→+∞(x −2) log x −1
x + 3

= exp

lim
x→+∞(x −2) log

1 −
4
x + 3

= eL .
Now deﬁne y =
1
x + 3, and substitute x = 1
y −3 at the exponent:
L = lim
y→0+
1
y −5

log (1 −4y) = lim
y→0+
log (1 −4y)
y
−5 log (1 −4y)

= −4 .
The required limit equals e−4.
f) e ;
g) 2
√
5.
h) We have
lim
x→−∞
3x −3−x
3x + 3−x =
lim
x→−∞
3−x 
32x −1

3−x (32x + 1) = −1 .
i) −1
2.
ℓ) Start by multiplying numerator and denominator by the same function:
lim
x→+∞xexe−x sin 2
x · sin

e−x sin 2
x

e−x sin 2
x
=
lim
x→+∞x sin 2
x ·
lim
x→+∞
sin

e−x sin 2
x

e−x sin 2
x
= L1 · L2 .

4.4 Exercises
121
Now put y = 1
x in the ﬁrst factor to get
L1 = lim
y→0+
sin 2y
y
= 2 ;
next, let t = e−x sin 2
x. Since t →0 for x →+∞, by Corollary 4.7, the second
factor is
L2 = lim
t→0
sin t
t
= 1 ,
and eventually the limit is 2.
m) The fact that −1 ≤sin x ≤1 implies 1 ≤2 + sin x ≤3, so x ≤x(2 + sin x)
when x > 0. Since
lim
x→+∞x = +∞, the Second comparison theorem 4.8 gives
+∞for an answer.
n) −∞.
6. Domains and limits:
a) dom f = R \ {−2, −1},
lim
x→−2± f(x) = ±∞,
lim
x→−1± f(x) = ±∞,
lim
x→±∞f(x) = ±∞.
b) The function is deﬁned on the entire R and
lim
x→+∞f(x) =
lim
x→+∞
ex
x4 ·
x4
1 + x4 =
lim
x→+∞
ex
x4 = +∞,
lim
x→−∞f(x) =
lim
x→−∞ex ·
lim
x→−∞
1
1 + x4 = 0 .
c) This function makes sense when x ̸= 0 (because 1 + exp

x2+1
x

> 0 for any
non-zero x). As for the limits:
lim
x→−∞f(x) = log
lim
x→−∞

1 + exp
x2 + 1
x

= log 1 = 0 ,
lim
x→+∞f(x) = log
lim
x→+∞

1 + exp
x2 + 1
x

= +∞,
lim
x→0−f(x) = log lim
x→0−

1 + exp
x2 + 1
x

= log 1 = 0 ,
lim
x→0+ f(x) = log lim
x→0+

1 + exp
x2 + 1
x

= +∞.
d) dom f = R;
lim
x→±∞f(x) = 0.

5
Local comparison of functions. Numerical
sequences and series
In the ﬁrst part of this chapter we learn how to compare the behaviour of two
functions in the neighbourhood of a point. To this aim, we introduce suitable
symbols – known as Landau symbols – that make the description of the possible
types of behaviour easier. Of particular importance is the comparison between
functions tending to 0 or ∞.
In the second part, we revisit some results on limits which we discussed in
general for functions, and adapt them to the case of sequences. We present speciﬁc
techniques for the analysis of the limiting behaviour of sequences. At last, numer-
ical series are introduced and the main tools for the study of their convergence are
provided.
5.1 Landau symbols
As customary by now, we denote by c one of the symbols x0 (real number), x+
0 ,
x−
0 , or +∞, −∞. By ‘neighbourhood of c’ we intend a neighbourhood – previously
deﬁned – of one of these symbols.
Let f and g be two functions deﬁned in a neighbourhood of c, with the possible
exception of the point c itself. Let also g(x) ̸= 0 for x ̸= c. Assume the limit
lim
x→c
f(x)
g(x) = ℓ
(5.1)
exists, ﬁnite or not. We introduce the following deﬁnition.
Deﬁnition 5.1 If ℓis ﬁnite, we say that f is controlled by g for x tending
to c, and we shall use the notation
f = O(g),
x →c ,
read as ‘f is big o of g for x tending to c’.
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_5,
© Springer International Publishing Switzerland 2015

124
5 Local comparison of functions. Numerical sequences and series
This property can be made more precise by distinguishing three cases:
a) If ℓis ﬁnite and non-zero, we say that f has the same order of mag-
nitude as g (or is of the same order of magnitude) for x tending to
c; if so, we write
f ≍g,
x →c.
As sub-case we have:
b) If ℓ= 1, we call f equivalent to g for x tending to c; in this case we use
the notation
f ∼g,
x →c.
c) Eventually, if ℓ= 0, we say that f is negligible with respect to g when
x goes to c; for this situation the symbol
f = o(g),
x →c,
will be used, spoken ‘f is little o of g for x tending to c’.
Not included in the previous deﬁnition is the case in which ℓis inﬁnite. But in
such a case
lim
x→c
g(x)
f(x) = 1
ℓ= 0,
so we can say that g = o(f) for x →c.
The symbols O, ≍, ∼, o are called Landau symbols.
Remark 5.2 The Landau symbols can be deﬁned under more general assump-
tions than those considered at present, i.e., the mere existence of the limit (5.1).
For instance the expression f = O(g) as x →c could be extended to mean that
there is a constant C > 0 such that in a suitable neighbourhood I of c
|f(x)| ≤C|g(x)|,
∀x ∈I, x ̸= c.
The given deﬁnition is nevertheless suﬃcient for our purposes.
2
Examples 5.3
i) Keeping in mind Examples 4.6, we have
sin x ∼x, x →0,
in fact
lim
x→0
sin x
x
= 1,
sin x = o(x), x →+∞,
since
lim
x→+∞
sin x
x
= 0;
ii) We have sin x = o(tan x), x →π
2 since
lim
x→π
2
sin x
tan x = lim
x→π
2
cos x = 0.

5.1 Landau symbols
125
iii) One has cos x ≍2x −π, x →π
2 , because
lim
x→π
2
cos x
2x −π = lim
t→0
cos(t + π
2 )
2t
= −lim
t→0
sin t
2t
= −1
2.
2
Properties of the Landau symbols
i)
It is clear from the deﬁnitions that the symbols ≍, ∼, o are particular instances
of O, in the sense that
f ≍g ⇒f = O(g),
f ∼g ⇒f = O(g),
f = o(g) ⇒f = O(g)
for x →c. Moreover the symbol ∼is a subcase of ≍
f ∼g
⇒
f ≍g.
Observe that if f ≍g, then (5.1) implies
lim
x→c
f(x)
ℓg(x) = 1,
hence f ∼ℓg.
ii) The following property is useful
f ∼g
⇐⇒
f = g + o(g).
(5.2)
By deﬁning h(x) = f(x) −g(x) in fact, so that f(x) = g(x) + h(x), we have
f ∼g
⇐⇒
lim
x→c
f(x)
g(x) = 1
⇐⇒
lim
x→c
f(x)
g(x) −1

= 0
⇐⇒
lim
x→c
h(x)
g(x) = 0
⇐⇒
h = o(g).
iii) Computations are simpliﬁed once we notice that for any constant λ ̸= 0
o(λf) = o(f)
and
λ o(f) = o(f).
(5.3)
In fact g = o(λf) means that lim
x→c
g(x)
λf(x) = 0, otherwise said lim
x→c
g(x)
f(x) = 0,
or g = o(f). The remaining identity is proved in a similar way. Analogous
properties to (5.3) hold for the symbol O.
Note that o(f) and O(f) do not indicate one speciﬁc function, rather a precise
property of any map represented by one of the two symbols.
iv) Prescribing f = o(1) amounts to asking that f converge to 0 when x →c.
Namely
lim
x→c f(x) = lim
x→c
f(x)
1
= 0.

126
5 Local comparison of functions. Numerical sequences and series
Similarly f = O(1) means f converges to a ﬁnite limit for x tending to c.
More generally (compare Remark 5.2), f = O(1) means that f is bounded in
a neighbourhood of c: that is to say, there exists a constant C > 0 such that
|f(x)| ≤C,
∀x ∈I, x ̸= c,
I being a suitable neighbourhood of c.
v) The continuity of a function f at a point x0 can be expressed by means of the
symbol o in the equivalent form
f(x) = f(x0) + o(1),
x →x0.
(5.4)
Recalling (3.9) in fact, we have
lim
x→x0 f(x) = f(x0)
⇐⇒
lim
x→x0

f(x) −f(x0)

= 0
⇐⇒
f(x) −f(x0) = o(1),
x →x0.
The algebra of “little o’s”
i)
Let us compare the behaviour of the monomials xn as x →0:
xn = o(xm),
x →0,
⇐⇒
n > m.
In fact
lim
x→0
xn
xm = lim
x→0 xn−m = 0 if and only if n −m > 0.
Therefore when x →0, the bigger of two powers of x is negligible.
ii) Now consider the limit when x →±∞. Proceeding as before we obtain
xn = o(xm),
x →±∞,
⇐⇒
n < m.
So, for x →±∞, the lesser power of x is negligible.
iii) The symbols of Landau allow to simplify algebraic formulas quite a lot when
studying limits. Consider for example the limit for x →0. The following prop-
erties, which deﬁne a special “algebra of little o’s”, hold. Their proof is left to
the reader as an exercise:
a)
o(xn) ± o(xn) = o(xn) ;
b)
o(xn) ± o(xm) = o(xp) ,
with p = min(n, m) ;
c)
o(λxn) = o(xn),
for each λ ∈R \ {0} ;
(5.5)

5.1 Landau symbols
127
d)
ϕ(x)o(xn) = o(xn)
if ϕ is bounded in a neighbourhood of x = 0 ;
e)
xmo(xn) = o(xm+n) ;
f)
o(xm)o(xn) = o(xm+n) ;
g)
[o(xn)]k = o(xkn) .
Fundamental limits
The fundamental limits in the Table of p. 106 can be reformulated using the sym-
bols of Landau:
sin x ∼x,
x →0;
1 −cos x ≍x2,
x →0;
precisely,
1 −cos x ∼1
2x2,
x →0;
log(1 + x) ∼x,
x →0;
equivalently, log x ∼x −1,
x →1;
ex −1 ∼x,
x →0;
(1 + x)α −1 ∼αx,
x →0.
With (5.2), and taking property (5.5) c) into account, these relations read:
sin x = x + o(x),
x →0;
1 −cos x = 1
2x2 + o(x2),
x →0, or cos x = 1 −1
2x2 + o(x2),
x →0;
log(1 + x) = x + o(x),
x →0, or log x = x −1 + o(x −1),
x →1;
ex = 1 + x + o(x),
x →0;
(1 + x)α = 1 + αx + o(x),
x →0.
Besides, we shall prove in Sect. 6.11 that:
a)
xα = o(ex),
x →+∞,
∀α ∈R;
b)
ex = o(|x|α),
x →−∞,
∀α ∈R;
c)
log x = o(xα),
x →+∞,
∀α > 0;
d)
log x = o
 1
xα

,
x →0+,
∀α > 0.
(5.6)
Examples 5.4
i) From et = 1 + t + o(t), t →0, by setting t = 5x we have e5x = 1 + 5x + o(5x),
i.e., e5x = 1 + 5x + o(x), x →0. In other words e5x −1 ∼5x, x →0.

128
5 Local comparison of functions. Numerical sequences and series
ii) Setting t = −3x2 in (1+t)1/2 = 1+ 1
2t+o(t), t →0, we obtain (1−3x2)1/2 =
1 −3
2x2 + o(−3x2) = 1 −3
2x2 + o(x2), x →0. Thus (1 −3x2)1/2 −1 ∼−3
2x2,
x →0.
iii) The relation sin t = t + o(t), t →0, implies, by putting t = 2x, x sin 2x =
x(2x + o(2x)) = 2x2 + o(x2), x →0. Then x sin 2x ∼2x2, x →0.
2
We explain now how to use the symbols of Landau for calculating limits. All
maps dealt with below are supposed to be deﬁned, and not to vanish, on a neigh-
bourhood of c, except possibly at c.
Proposition 5.5 Let us consider the limits
lim
x→c f(x)g(x)
and
lim
x→c
f(x)
g(x) .
Given functions ˜f and ˜g such that ˜f ∼f and ˜g ∼g for x →c, then
lim
x→c f(x)g(x) = lim
x→c
˜f(x)˜g(x),
(5.7)
lim
x→c
f(x)
g(x) = lim
x→c
˜f(x)
˜g(x) .
(5.8)
Proof.
Start with (5.7). Then
lim
x→c f(x)g(x) = lim
x→c
f(x)
˜f(x)
˜f(x)g(x)
˜g(x) ˜g(x)
= lim
x→c
f(x)
˜f(x)
lim
x→c
g(x)
˜g(x) lim
x→c
˜f(x)˜g(x).
From the deﬁnition of ˜f ∼f and ˜g ∼g the result follows. The proof of
(5.8) is completely analogous.
2
Corollary 5.6 Consider the limits
lim
x→c

f(x) + f1(x)

g(x) + g1(x)

and
lim
x→c
f(x) + f1(x)
g(x) + g1(x) .
If f1 = o(f) and g1 = o(g) when x →c, then
lim
x→c

f(x) + f1(x)

g(x) + g1(x)

= lim
x→c f(x)g(x),
(5.9)
lim
x→c
f(x) + f1(x)
g(x) + g1(x) = lim
x→c
f(x)
g(x) .
(5.10)

5.1 Landau symbols
129
Proof.
Set ˜f = f + f1; by assumption ˜f = f + o(f), so from (5.2) one has ˜f ∼f.
Similarly, putting ˜g = g + g1 yields ˜g ∼g. The claim follows from the
previous Proposition.
2
The meaning of these properties is clear: when computing the limit of a product,
we may substitute each factor with an equivalent function. Alternatively, one may
ignore negligible summands with respect to others within one factor. In a similar
way one can handle the limit of a quotient, numerator and denominator now being
the ‘factors’.
Examples 5.7
i) Compute
lim
x→0
1 −cos 2x
sin2 3x
.
From the equivalence 1 −cos t ∼1
2t2, t →0, the substitution t = 2x gives
1 −cos 2x ∼2x2,
x →0.
Putting t = 3x in sin t ∼t, t →0, we obtain sin 3x ∼3x, x →0, hence
sin2 3x ∼9x2,
x →0.
Therefore (5.8) implies
lim
x→0
1 −cos 2x
sin2 3x
= lim
x→0
2x2
9x2 = 2
9.
ii) Evaluate
lim
x→0
sin 2x + x3
4x + 5 log(1 + x2).
We shall show that for x →0, x3 is negligible with respect to sin 2x, and similarly
5 log(1 + x2) is negligible with respect to 4x. With that, we can use the previous
corollary and conclude
lim
x→0
sin 2x + x3
4x + 5 log(1 + x2) = lim
x→0
sin 2x
4x
= 1
2.
Recall sin 2x ∼2x for x →0; thus
lim
x→0
x3
sin 2x = lim
x→0
x3
2x = 0,
that is to say x3 = o(sin 2x) for x →0. On the other hand, since log(1 + t) ∼t
for t →0, writing t = x2 yields log(1 + x2) ∼x2 when x →0. Then
lim
x→0
5 log(1 + x2)
4x
= lim
x→0
5x2
4x = 0,
i.e., 5 log(1 + x2) = o(4x) for x →0.
2
These ‘simpliﬁcation’ rules hold only in the case of products and quotients.
They do not apply to limits of sums or diﬀerences of functions. Otherwise put,
the fact that ˜f ∼f and ˜g ∼g when x →c, does not allow to conclude that

130
5 Local comparison of functions. Numerical sequences and series
lim
x→c[f(x) ± g(x)] = lim
x→c[ ˜f(x) ± ˜g(x)].
For example set f(x) =
√
x2 + 2x and g(x) =
√
x2 −1 and consider the limit
lim
x→+∞

x2 + 2x −

x2 −1

.
Rationalisation turns this limit into
lim
x→+∞
(x2 + 2x) −(x2 −1)
√
x2 + 2x +
√
x2 −1
=
lim
x→+∞
2x + 1
x

1 + 2
x +

1 −
1
x2
 = 1.
Had we substituted to f(x) the function ˜f(x) = x, equivalent to f for x →+∞,
we would have obtained a diﬀerent limit, actually a wrong one. In fact,
lim
x→+∞

x −

x2 −1

=
lim
x→+∞
x2 −(x2 −1)
x +
√
x2 −1
=
lim
x→+∞
1
x(1 +

1 −1
x2 )
= 0.
The reason for the mismatch lies in the cancellation of the leading term x2 ap-
pearing in the numerator after rationalisation, which renders the terms of lesser
degree important for the limit, even though they are negligible with respect to x2
for x →+∞.
5.2 Inﬁnitesimal and inﬁnite functions
Deﬁnition 5.8 Let f be a function deﬁned in a neighbourhood of c, except
possibly at c. Then f is said inﬁnitesimal (or an inﬁnitesimal) at c if
lim
x→c f(x) = 0,
i.e., if f = o(1) for x →c. The function f is said inﬁnite at c if
lim
x→c f(x) = ∞.
Let us introduce the following terminology to compare two inﬁnitesimal or
inﬁnite maps.
Deﬁnition 5.9 Let f, g be two inﬁnitesimals at c.
If f ≍g for x →c, f and g are said inﬁnitesimals of the same order.
If f = o(g) for x →c, f is called inﬁnitesimal of bigger order than g.
If g = o(f) for x →c, f is called inﬁnitesimal of smaller order than g.
If none of the above are satisﬁed, f and g are said non-comparable inﬁn-
itesimals.

5.2 Inﬁnitesimal and inﬁnite functions
131
Deﬁnition 5.10 Let f and g be two inﬁnite maps at c.
If f ≍g for x →c, f and g are said to be inﬁnite of the same order.
If f = o(g) for x →c, f is called inﬁnite of smaller order than g.
If g = o(f) for x →c, f is called inﬁnite of bigger order than g.
If none of the above are satisﬁed, the inﬁnite functions f and g are said
non-comparable.
Examples 5.11
Bearing in mind the fundamental limits seen above, it is immediate to verify the
following facts:
i) ex −1 is an inﬁnitesimal of the same order as x at the origin.
ii) sin x2 is an inﬁnitesimal of bigger order than x at the origin.
iii)
sin x
(1 −cos x)2 is inﬁnite of bigger order than 1
x at the origin.
iv) For every α > 0, ex is inﬁnite of bigger order than xα for x →+∞.
v) For every α > 0, log x is inﬁnite of smaller order than 1
xα for x →0+.
vi) The functions f(x) = x sin 1
x and g(x) = x are inﬁnitesimal for x tending
to 0 (for f recall Corollary 4.7). But the quotient f(x)
g(x) = sin 1
x does not admit
limit for x →0, for in any neighbourhood of 0 it attains every value between −1
and 1 inﬁnitely many times. Therefore none of the conditions f ≍g, f = o(g),
g = o(f) hold for x →0. The two functions f and g are thus not comparable. 2
Using a non-rigorous yet colourful language, we shall express the fact that f
is inﬁnitesimal (or inﬁnite) of bigger order than g by saying that f tends to 0 (or
∞) faster than g. This suggests to measure the speed at which an inﬁnitesimal (or
inﬁnite) map converges to its limit value.
For that purpose, let us ﬁx an inﬁnitesimal (or inﬁnite) map ϕ deﬁned in a
neighbourhood of c and particularly easy to compute. We shall use it as term of
comparison (‘test function’) and in fact call it an inﬁnitesimal test function
(or inﬁnite test function) at c. When the limit behaviour is clear, we refer to
ϕ as test function for brevity. The most common test functions (certainly not the
only ones) are the following. If c = x0 ∈R, we choose
ϕ(x) = x −x0
or
ϕ(x) = |x −x0|
as inﬁnitesimal test functions (the latter in case we need to consider non-integer
powers of ϕ, see later), and
ϕ(x) =
1
x −x0
or
ϕ(x) =
1
|x −x0|

132
5 Local comparison of functions. Numerical sequences and series
as inﬁnite test functions. For c = x+
0 (c = x−
0 ), we will choose as inﬁnitesimal test
function
ϕ(x) = x −x0
(ϕ(x) = x0 −x)
and as inﬁnite test function
ϕ(x) =
1
x −x0
(ϕ(x) =
1
x0 −x ).
For c = +∞, the inﬁnitesimal and inﬁnite test functions will respectively be
ϕ(x) = 1
x
and
ϕ(x) = x,
while for c = −∞, we shall take
ϕ(x) = 1
|x|
and
ϕ(x) = |x|.
The deﬁnition of ‘speed of convergence’ of an inﬁnitesimal or inﬁnite f depends
on how f compares to the powers of the inﬁnitesimal or inﬁnite test function. To
be precise, we have the following deﬁnition
Deﬁnition 5.12 Let f be inﬁnitesimal (or inﬁnite) at c. If there exists a real
number α > 0 such that
f ≍ϕα,
x →c,
(5.11)
the constant α is called the order of f at c with respect to the inﬁnites-
imal (inﬁnite) test function ϕ.
Notice that if condition (5.11) holds, it determines the order uniquely. In the
ﬁrst case in fact, it is immediate to see that for any β < α one has f = o(ϕβ),
while β > α implies ϕβ = o(f). A similar argument holds for inﬁnite maps.
If f has order α at c with respect to the test function ϕ, then there is a real
number ℓ̸= 0 such that
lim
x→c
f(x)
ϕα(x) = ℓ.
Rephrasing:
f ∼ℓϕα,
x →c,
which is to say – recalling (5.2) – f = ℓϕα + o(ℓϕα), for x →c. For the sake of
simplicity we can omit the constant ℓin the symbol o, because if a function h
satisﬁes h = o(ℓϕα), then h = o(ϕα) as well. Therefore
f = ℓϕα + o(ϕα),
x →c.

5.2 Inﬁnitesimal and inﬁnite functions
133
Deﬁnition 5.13 The function
p(x) = ℓϕα(x)
(5.12)
is called the principal part of the inﬁnitesimal (inﬁnite) map f at c
with respect to the inﬁnitesimal (inﬁnite) test function ϕ.
From the qualitative point of view the behaviour of the function f in a small
enough neighbourhood of c coincides with the behaviour of its principal part (in
geometrical terms, the two graphs resemble each other). With a suitable choice of
test function ϕ, like one of those mentioned above, the behaviour of the function
ℓϕα(x) becomes immediately clear. So if one is able to determine the principal
part of a function, even a complicated one, at a given point c, the local behaviour
around that point is easily described.
We wish to stress that to ﬁnd the order and the principal part of a function f
at c, one must start from the limit
lim
x→c
f(x)
ϕα(x)
and understand if there is a number α for which such limit – say ℓ– is ﬁnite and
diﬀerent from zero. If so, α is the required order, and the principal part of f is
given by (5.12).
Examples 5.14
i) The function f(x) = sin x −tan x is inﬁnitesimal for x →0. Using the basic
equivalences of p. 127 and Proposition 5.5, we can write
sin x −tan x = sin x (cos x −1)
cos x
∼x ·

−1
2x2
1
= −1
2x3,
x →0.
It follows that f(x) is inﬁnitesimal of order 3 at the origin with respect to the
test function ϕ(x) = x; its principal part is p(x) = −1
2x3.
ii) The function
f(x) =

x2 + 3 −

x2 −1
is inﬁnitesimal for x →+∞. Rationalising the expression we get
f(x) = (x2 + 3) −(x2 −1)
√
x2 + 3 +
√
x2 −1
=
4
x

1 +
3
x2 +

1 −
1
x2
.
The right-hand side shows that if one chooses ϕ(x) = 1
x then
lim
x→+∞
f(x)
ϕ(x) = 2.

134
5 Local comparison of functions. Numerical sequences and series
Therefore f is inﬁnitesimal of ﬁrst order for x →+∞with respect to the test
function 1
x, with principal part p(x) = 2
x.
iii) The function
f(x) =

9x5 + 7x3 −1
is inﬁnite when x →+∞. To determine its order with respect to ϕ(x) = x, we
consider the limit
lim
x→+∞
f(x)
xα
=
lim
x→+∞
x
5
2

9 +
7
x2 −
1
x5
xα
.
By choosing α = 5
2 the limit becomes 3. So f has order 5
2 for x →+∞with
respect to the test function ϕ(x) = x. The principal part is p(x) = 3x5/2.
2
Remark 5.15 The previous are typical instances of how to determine the order
of a function with respect to some test map. The reader should not be mislead to
believe that this is always possible. Given an inﬁnitesimal or an inﬁnite f at c, and
having chosen a corresponding test map ϕ, it may well happen that there is no real
number α > 0 satisfying f ≍ϕα for x →c. In such a case it is convenient to make
a diﬀerent choice of test function, one more suitable to describe the behaviour of
f around c. We shall clarify this fact with two examples.
Start by taking the function f(x) = e2x for x →+∞. Using (5.6) a), it follows
immediately that xα = o(e2x), whichever α > 0 is considered. So it is not possible
to determine an order for f with respect to ϕ(x) = x: the exponential map grows
too quickly for any polynomial function to keep up with it. But if we take as test
function ϕ(x) = ex then clearly f has order 2 with respect to ϕ.
Consider now f(x) = x log x for x →0+. In (5.6) d) we claimed that
lim
x→0+
log x
1
xβ
= 0,
∀β > 0.
So in particular f(x) = log x
1/x is inﬁnitesimal when x →0+. Using the test function
ϕ(x) = x one sees that
lim
x→0+
x log x
xα
= lim
x→0+
log x
xα−1 =
 0
if α < 1,
−∞
otherwise.
Deﬁnition 5.9 yields that f is an inﬁnitesimal of bigger order than any power of
x with exponent less than one. At the same time it has smaller order than x and
all powers with exponent greater than one. In this case too, it is not possible to
determine the order of f with respect to x. The function |f(x)| = x| log x| goes to
zero more slowly than x, yet faster than xα for any α < 1. Thus it can be used as
alternative inﬁnitesimal test map when x →0+.
2

5.3 Asymptotes
135
5.3 Asymptotes
We now consider a function f deﬁned in a neighbourhood of +∞and wish to
study its behaviour for x →+∞. A remarkable case is that in which f behaves
as a polynomial of ﬁrst degree. Geometrically speaking, this corresponds to the
fact that the graph of f will more and more look like a straight line. Precisely, we
suppose there exist two real numbers m and q such that
lim
x→+∞(f(x) −(mx + q)) = 0,
(5.13)
or, using the symbols of Landau,
f(x) = mx + q + o(1) ,
x →+∞.
We then say that the line g(x) = mx + q is a right asymptote of the function f.
The asymptote is called oblique if m ̸= 0, horizontal if m = 0. In geometrical
terms condition (5.13) tells that the vertical distance d(x) = |f(x)−g(x)| between
the graph of f and the asymptote tends to 0 as x →+∞(Fig. 5.1).
The asymptote’s coeﬃcients can be recovered using limits:
m =
lim
x→+∞
f(x)
x
and
q =
lim
x→+∞(f(x) −mx) .
(5.14)
The ﬁrst relation comes from (5.13) noting that
0 =
lim
x→+∞
f(x) −mx −q
x
=
lim
x→+∞
f(x)
x
−lim
x→+∞
mx
x −lim
x→+∞
q
x =
lim
x→+∞
f(x)
x
−m,
while the second one follows directly from (5.13). The conditions (5.14) furnish the
means to ﬁnd the possible asymptote of a function f. If in fact both limits exist
y = mx + q
y = f(x)
d(x)
x
Figure 5.1. Graph of a function with its right asymptote

136
5 Local comparison of functions. Numerical sequences and series
and are ﬁnite, f admits y = mx + q as a right asymptote. If only one of (5.14) is
not ﬁnite instead, then f will not have an asymptote.
Notice that if f has an oblique asymptote, i.e., if m ̸= 0, the ﬁrst of (5.14)
tells us that f is inﬁnite of order 1 with respect to the test function ϕ(x) = x for
x →+∞. The reader should beware that not all functions satisfying the latter
condition do admit an oblique asymptote: the function f(x) = x+√x for example
is equivalent to x for x →+∞, but has no asymptote since the second limit in
(5.14) is +∞.
Remark 5.16 The deﬁnition of (linear) asymptote given above is a particular
instance of the following. The function f is called asymptotic to a function g for
x →+∞if
lim
x→+∞(f(x) −g(x)) = 0.
If (5.13) holds one can then say that f is asymptotic to the line g(x) = mx + q.
The function f(x) = x2 + 1
x instead has no line as asymptote for x →+∞, but is
nevertherless asymptotic to the parabola g(x) = x2.
2
In a similar fashion one deﬁnes oblique or horizontal asymptotes for x →−∞
(that is oblique or horizontal left asymptotes).
If the line y = mx + q is an oblique or horizontal asymptote both for x →+∞
and x →−∞, we shall say that it is a complete oblique or complete horizontal
asymptote for f.
Eventually, if at a point x0 ∈R one has lim
x→x0 f(x) = ∞, the line x = x0 is
called a vertical asymptote for f at x0. The distance between points on the
graph of f and on a vertical asymptote with the same y-coordinate converges to
zero for x →x0. If the limit condition holds only for x →x+
0 or x →x−
0 we talk
about a vertical right or left asymptote respectively.
Examples 5.17
i) Let f(x) =
x
x + 1. As
lim
x→±∞f(x) = 1
and
lim
x→−1± f(x) = ∓∞,
the function has a horizontal asymptote y = 1 and a vertical asymptote x = −1.
ii) The map f(x) =
√
1 + x2 satisﬁes
lim
x→±∞f(x) = +∞,
lim
x→±∞
f(x)
x
=
lim
x→±∞
|x|
√
1 + x−2
x
= ±1
and
lim
x→+∞

1 + x2 −x

=
lim
x→+∞
1 + x2 −x2
√
1 + x2 + x
= 0 ,
lim
x→−∞

1 + x2 + x

=
lim
x→−∞
1 + x2 −x2
√
1 + x2 −x = 0 .

5.4 Further properties of sequences
137
Therefore f has an oblique asymptote for x →+∞given by y = x, plus another
one of equation y = −x for x →−∞.
iii) Let f(x) = x + log x. Since
lim
x→0+(x + log x) = −∞,
lim
x→+∞(x + log x) = +∞,
lim
x→+∞
x + log x
x
= 1,
lim
x→+∞(x + log x −x) = +∞,
the function has a vertical right asymptote x = 0 but no horizontal nor oblique
asymptotes.
2
5.4 Further properties of sequences
We return to the study of the limit behaviour of sequences begun in Sect. 3.2.
General theorems concerning functions apply to sequences as well (the latter being
particular functions deﬁned over the integers, after all). For the sake of complete-
ness those results will be recalled, and adapted to the case of concern. We shall
also state and prove other speciﬁc properties of sequences.
We say that a sequence {an}n≥n0 satisﬁes a given property eventually, if there
exists an integer N ≥n0 such that the sequence {an}n≥N satisﬁes that property.
This deﬁnition allows for a more ﬂexible study of sequences.
Theorems on sequences
1. Uniqueness of the limit: the limit of a sequence, when deﬁned, is unique.
2. Boundedness: a converging sequence is bounded.
3. Existence of limit for monotone sequences: if an eventually monotone se-
quence is bounded, then it converges; if not bounded then it diverges (to
+∞if increasing, to −∞if decreasing).
4. First comparison theorem: let {an} and {bn} be sequences with ﬁnite or
inﬁnite limits lim
n→∞an = ℓand lim
n→∞bn = m. If an ≤bn eventually, then
ℓ≤m.
5. Second comparison theorem (“Squeeze rule”): let {an}, {bn} and {cn} be
sequences with lim
n→∞an = lim
n→∞cn = ℓ. If an ≤bn ≤cn eventually, then
lim
n→∞bn = ℓ.
6. Theorem: a sequence {an} is inﬁnitesimal, that is lim
n→∞an = 0, if and only
if the sequence {|an|} is inﬁnitesimal.
7. Theorem: let {an} be an inﬁnitesimal sequence and {bn} a bounded one.
Then the sequence {anbn} is inﬁnitesimal.

138
5 Local comparison of functions. Numerical sequences and series
8. Algebra of limits: let {an} and {bn} be such that lim
n→∞an = ℓand lim
n→∞bn =
m (ℓ, m ﬁnite or inﬁnite). Then
lim
n→∞(an ± bn) = ℓ± m ,
lim
n→∞an bn = ℓm ,
lim
n→∞
an
bn
= ℓ
m,
if bn ̸= 0 eventually ,
each time the right-hand sides are deﬁned according to the Table on p. 96.
9. Substitution theorem: let {an} be a sequence with lim
n→∞an = ℓand suppose
g is a function deﬁned in a neighbourhood of ℓ:
a) if ℓ∈R and g is continuous at ℓ, then lim
n→∞g(an) = g(ℓ);
b) if ℓ/∈R and lim
x→ℓg(x) = m exists, then lim
n→∞g(an) = m.
Proof.
We shall only prove Theorem 2 since the others are derived adapting the
similar proofs given for functions.
Let the sequence {an}n≥n0 be given, and suppose it converges to ℓ∈R.
With ε = 1 ﬁxed, there exists an integer n1 ≥n0 so that |an −ℓ| < 1 for
all n > n1. For such n’s then the triangle inequality (1.1) yields
|an| = |an −ℓ+ ℓ| ≤|an −ℓ| + |ℓ| < 1 + |ℓ|.
By putting M = max{|an0|, . . . , |an1|, 1 + |ℓ|} one obtains |an| ≤M,
∀n ≥n0.
2
Examples 5.18
i) Consider the sequence an = qn,where q is a ﬁxed number in R. It goes under
the name of geometric sequence. We claim that
lim
n→∞qn =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
0
if |q| < 1,
1
if q = 1,
+∞
if q > 1,
does not exist
if q ≤−1.
If either q = 0 or q = 1, the sequence is constant and thus trivially convergent
to 0 or 1 respectively. When q = −1 the sequence is indeterminate.
Let q > 1: the sequence is now strictly increasing and so admits a limit. In order
to show that the limit is indeed +∞we write q = 1 + r with r > 0 and apply
the binomial formula (1.13):

5.4 Further properties of sequences
139
qn = (1 + r)n =
n
	
k=0
n
k

rk = 1 + nr +
n
	
k=2
n
k

rk.
As all terms in the last summation are positive, we obtain
(1 + r)n ≥1 + nr ,
∀n ≥0 ,
(5.15)
called Bernoulli inequality1. Therefore qn ≥1 + nr; passing to the limit for
n →∞and using the First comparison theorem we can conclude.
Let us examine the case |q| < 1 with q ̸= 0. We just saw that 1
|q| > 1 implies
lim
n→∞
 1
|q|
n
= +∞. The sequence {|q|n} is thus inﬁnitesimal, and so is {qn}.
At last, take q < −1. Since
lim
k→∞q2k = lim
k→∞(q2)k = +∞,
lim
k→∞q2k+1 = q lim
k→∞q2k = −∞,
the sequence qn is indeterminate.
ii) Let p be a ﬁxed positive number and consider the sequence
n√p. Applying the
Substitution theorem with g(x) = px we have
lim
n→∞
n√p = lim
n→∞p1/n = p0 = 1 .
iii) Consider the sequence
n√n; using once again the Substitution theorem to-
gether with (5.6) c), it follows that
lim
n→∞
n√n = lim
n→∞exp log n
n
= e0 = 1.
2
There are easy criteria to decide whether a sequence is inﬁnitesimal or inﬁnite.
Among them, the following is the most widely employed.
Theorem 5.19 (Ratio test)
Let {an} be a sequence for which an > 0
eventually. Suppose the limit
lim
n→∞
an+1
an
= q
exists, ﬁnite or inﬁnite. If q < 1 then lim
n→∞an = 0; if q > 1 then lim
n→∞an =
+∞.
1 By the Principle of Induction, one can prove that (5.15) actually holds for any r ≥−1;
see Appendix A.1, p. 427.

140
5 Local comparison of functions. Numerical sequences and series
Proof.
Suppose an > 0, ∀n ≥n0. Take q < 1 and set ε = 1 −q. By deﬁnition of
limit there exists an integer nε ≥n0 such that for all n > nε
an+1
an
< q + ε = 1 ,
i.e.,
an+1 < an.
So the sequence {an} is monotone decreasing eventually, and as such it
admits a ﬁnite non-negative limit ℓ. Now if ℓwere diﬀerent from zero, the
fact that
q = lim
n→∞
an+1
an
= ℓ
ℓ= 1
would contradict the assumption q < 1.
If q > 1, it is enough to consider the sequence {1/an}.
2
Nothing can be said if q = 1.
Remark 5.20 The previous theorem has another proof, which emphasizes the
speed at which a sequence converges to 0 or +∞. Take for example the case q < 1.
The deﬁnition of limit tells that for all r with q < r < 1, if one puts ε = r −q
there is a nε ≥n0 such that
an+1
an
< r
that is,
an+1 < ran
for each n > nε. Repeating the argument leads to
an+1 < ran < r2an−1 < . . . < rn−nεanε+1
(5.16)
(a precise proof of which requires the Principle of Induction; see Appendix A.1,
p. 430). The First comparison test and the limit behaviour of the geometric se-
quence (Example 5.18 i)) allow to conclude. Formula (5.16) shows that the smaller
q is, the faster the sequence {an} goes to 0.
Similar considerations hold when q > 1.
2
At last we consider a few signiﬁcant sequences converging to +∞. We compare
their limit behaviour using Deﬁnition 5.10. To be precise we examine the sequences
log n , nα , qn , n! , nn
(α > 0, q > 1)
and show that each sequence is inﬁnite of order bigger than the one preceding it.
Comparing the ﬁrst two is immediate, for the Substitution theorem and (5.6) c)
yield log n = o(nα) for n →∞.
The remaining cases are tackled by applying the Ratio test 5.19 to the quotient of
two nearby sequences. Precisely, let us set an = nα
qn . Then
an+1
an
= (n + 1)α
qn+1
qn
nα =
n + 1
n
α 1
q
→
1
q < 1 ,
n →∞.
Thus lim
n→∞an = 0, or nα = o(qn) for n →∞.

5.5 Numerical series
141
Now take an = qn
n! , so
an+1
an
=
qn+1
(n + 1)!
n!
qn =
q
(n + 1)n! n! =
q
n + 1
→
0 < 1 ,
n →∞,
and then qn = o(n!) per n →∞.
Eventually, let an = n!
nn . Then
an+1
an
=
(n + 1)!
(n + 1)n+1
nn
n! =
(n + 1)n!
(n + 1)(n + 1)n
nn
n! =

n
n + 1
n
=
1
 n+1
n
n =
1

1 + 1
n
n
→
1
e < 1 ,
n →∞,
and so n! = o(nn) for n →∞. To be more precise, one could actually prove the
so-called Stirling formula,
n! ∼
√
2πn
n
e
n
,
n →∞,
a helpful approximation of the factorial of large natural numbers.
5.5 Numerical series
Consider a segment of length ℓ= 2 (Fig. 5.2). The middle point splits it into
two parts of length a0 = ℓ/2 = 1. While keeping the left half ﬁxed, we further
subdivide the right one in two parts of length a1 = ℓ/4 = 1/2. Iterating the
process indeﬁnitely one can think of the initial segment as the union of inﬁnitely
many ‘left’ segments of lengths 1, 1
2, 1
4, 1
8,
1
16, . . . Correspondingly, the total length
of the starting segment can be thought of as sum of the lengths of all sub-segments,
in other words
2 = 1 + 1
2 + 1
4 + 1
8 + 1
16 + . . .
(5.17)
On the right we have a sum of inﬁnitely many terms. The notion of inﬁnite sum
can be deﬁned properly using sequences, and leads to numerical series.
0
2
1
3
2
7
4
15
8
1
1
2
1
4
1
8
1
16
Figure 5.2. Successive splittings of the interval [0, 2]. The coordinates of the subdivision
points are indicated below the blue line, while the lengths of subintervals lie above it

142
5 Local comparison of functions. Numerical sequences and series
Given the sequence {ak}k≥0, one constructs the so-called sequence of partial
sums {sn}n≥0 in the following manner:
s0 = a0 ,
s1 = a0 + a1 ,
s2 = a0 + a1 + a2,
and in general
sn = a0 + a1 + . . . + an =
n
	
k=0
ak .
Note that sn = sn−1 + an. Then it is only natural to study the limit behaviour of
such a sequence. Let us (formally) deﬁne
∞
	
k=0
ak = lim
n→∞
n
	
k=0
ak = lim
n→∞sn .
The symbol
∞
	
k=0
ak is called (numerical) series, and ak is the general term of
the series.
Deﬁnition 5.21 Given the sequence {ak}k≥0 and sn =
n
	
k=0
ak, consider the
limit lim
n→∞sn.
i) If the limit exists and is ﬁnite, we say that the series
∞
	
k=0
ak converges.
The value s of the limit is called sum of the series and one writes
s =
∞
	
k=0
ak.
ii) If the limit exists and is inﬁnite, we say that the series
∞
	
k=0
ak diverges.
iii) If the limit does not exist, we say that the series
∞
	
k=0
ak is indetermin-
ate.
Examples 5.22
i) Let us go back to the interval split inﬁnitely many times. The length of the
shortest segment obtained after k + 1 subdivisions is ak =
1
2k , k ≥0. Thus, we
consider the series
∞
	
k=0
1
2k . Its partial sums read

5.5 Numerical series
143
s0 = 1 ,
s1 = 1 + 1
2 = 3
2 ,
s2 = 1 + 1
2 + 1
4 = 7
4 ,
...
sn = 1 + 1
2 + . . . + 1
2n .
Using the fact that an+1 −bn+1 = (a −b)(an + an−1b + . . . + abn−1 + bn), and
choosing a = 1 and b = x arbitrary but diﬀerent from one, we obtain the identity
1 + x + . . . + xn = 1 −xn+1
1 −x
.
(5.18)
Therefore
sn = 1 + 1
2 + . . . + 1
2n = 1 −
1
2n+1
1 −1
2
= 2

1 −
1
2n+1

= 2 −1
2n ,
and so
lim
n→∞sn = lim
n→∞

2 −1
2n

= 2 .
The series converges and its sum is 2. This provides solid ground for having
written (5.17) earlier.
ii) Consider the series
∞
	
k=0
k. Recalling (3.2), we have
sn =
n
	
k=0
k = n(n + 1)
2
.
Then
lim
n→∞sn = lim
n→∞
n(n + 1)
2
= +∞,
and the series diverges (to +∞).
iii) The partial sums of the series
∞
	
k=0
(−1)k satisfy
s0 = 1 ,
s1 = 1 −1 = 0
s2 = s1 + 1 = 1
s3 = s2 −1 = 0
...
s2n = 1
s2n+1 = 0 .
The terms with even index are all equal to 1 while the odd ones are 0. Therefore
lim
n→∞sn cannot exist and the series is indeterminate.
2
Sometimes the sequence {ak} is only deﬁned for k ≥k0 with k0 > 0; Deﬁni-
tion 5.21 then modiﬁes in the obvious way. The following fact holds, whose rather
immediate proof is left to the reader.

144
5 Local comparison of functions. Numerical sequences and series
Property 5.23 The behaviour of a series does not change by adding, chan-
ging or removing a ﬁnite number of terms.
This property does not tell anything about the sum of a converging series, which
in general changes by manipulating the terms. For instance
∞
	
k=1
1
2k =
∞
	
k=0
1
2k −1 = 2 −1 = 1 .
Examples 5.24
i) The series
∞
	
k=2
1
(k −1)k is called series of Mengoli. As
ak =
1
(k −1)k =
1
k −1 −1
k,
it follows that
s2 = a2 =
1
1 · 2 = 1 −1
2
s3 = a2 + a3 =

1 −1
2

+
1
2 −1
3

= 1 −1
3,
and in general
sn = a2 + a3 + . . . + an =

1 −1
2

+
1
2 −1
3

+ . . . +

1
n −1 −1
n

= 1 −1
n .
Thus
lim
n→∞sn = lim
n→∞

1 −1
n

= 1
and the series converges to 1.
ii) For the series
∞
	
k=1
log

1 + 1
k

one has
ak = log

1 + 1
k

= log k + 1
k
= log(k + 1) −log k
so
s1 = log 2
s2 = log 2 + (log 3 −log 2) = log 3
...
sn = log 2 + (log 3 −log 2) + . . . +(log(n + 1) −log n) = log(n + 1) .
Then
lim
n→∞sn = lim
n→∞log(n + 1) = +∞
and the series diverges (to +∞).
2

5.5 Numerical series
145
The two instances just considered belong to the larger class of telescopic
series. These are deﬁned by ak = bk+1 −bk for a suitable sequence {bk}k≥k0.
Since sn = bn+1 −bk0, the behaviour of a telescopic series is the same as that of
the sequence {bk}.
We shall now present a simple yet useful necessary condition for a numerical
series to converge.
Property 5.25 Let
∞
	
k=0
ak be a converging series. Then
lim
k→∞ak = 0 .
(5.19)
Proof.
Let s = lim
n→∞sn. Since ak = sk −sk−1, then
lim
k→∞ak = lim
k→∞(sk −sk−1) = s −s = 0 ,
i.e., {ak} is inﬁnitesimal.
2
Observe that condition (5.19) is not suﬃcient to guarantee that the series
converge. The general term of a series may tend to 0 without the series having to
converge. For example we saw that the series
∞
	
k=1
log

1 + 1
k

diverges, but at the
same time lim
k→∞log

1 + 1
k

= 0 (Example 5.24 ii)).
If a series converges to s, the quantity
rn = s −sn =
∞
	
k=n+1
ak .
is called nth remainder.
Property 5.26 Take a converging series
∞
	
k=0
ak. Then the remainder satisﬁes
lim
n→∞rn = 0 .
Proof.
Indeed,
lim
n→∞rn = lim
n→∞(s −sn) = s −s = 0 .
2

146
5 Local comparison of functions. Numerical sequences and series
Example 5.27
Consider the geometric series
∞
	
k=0
qk ,
where q is a ﬁxed number in R.
If q = 1 then sn = a0 +a1 +. . .+an = 1+1+. . .+1 = n+1 and lim
n→∞sn = +∞,
whence the series diverges to +∞.
If q ̸= 1 instead, (5.18) implies
sn = 1 + q + q2 + . . . + qn = 1 −qn+1
1 −q
.
Example 5.18 gives
lim
n→∞sn = lim
n→∞
1 −qn+1
1 −q
=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1
1 −q
if |q| < 1 ,
+∞
if q > 1 ,
does not exist
if q ≤−1 .
In conclusion,
∞
	
k=0
qk
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
converges to
1
1 −q
if |q| < 1 ,
diverges to
+ ∞
if q ≥1 ,
is indeterminate
if q ≤−1 .
2
That said, it is not always possible to predict the behaviour of a series
∞
	
k=0
ak
using merely the deﬁnition. It may well happen that the sequence of partial sums
cannot be computed explicitly, so it becomes important to have other ways to es-
tablish whether the series converges or not. Only in case of convergence, it could be
necessary to determine the actual sum. This may require using more sophisticated
techniques, which go beyond the scopes of this text.
5.5.1 Positive-term series
We deal with series
∞
	
k=0
ak for which ak ≥0 for any k ∈N. The following result
holds.
Proposition 5.28 A series
∞
	
k=0
ak with positive terms either converges or
diverges to +∞.

5.5 Numerical series
147
Proof.
The sequence sn is monotonically increasing since
sn+1 = sn + an ≥sn ,
∀n ≥0 .
It is then suﬃcient to use Theorem 3.9 to conclude that lim
n→∞sn exists,
and is either ﬁnite or +∞.
2
We list now a few tools for studying the convergence of positive-term series.
Theorem 5.29 (Comparison test) Let
∞
	
k=0
ak and
∞
	
k=0
bk be positive-term
series such that 0 ≤ak ≤bk, for any k ≥0.
i) If the series
∞
	
k=0
bk converges, then also the series
∞
	
k=0
ak converges and
∞
	
k=0
ak ≤
∞
	
k=0
bk.
ii) If
∞
	
k=0
ak diverges, then
∞
	
k=0
bk diverges as well.
Proof.
i) Denote by {sn} and {tn} the sequences of partial sums of
∞
	
k=0
ak,
∞
	
k=0
bk
respectively. Since ak ≤bk for all k,
sn ≤tn ,
∀n ≥0 .
By assumption, the series
∞
	
k=0
bk converges, so lim
n→∞tn = t ∈R. Propos-
ition 5.28 implies the limit lim
n→∞sn = s exists, ﬁnite or inﬁnite. By the
First comparison theorem (Theorem 4, p. 137) we have
s = lim
n→∞sn ≤lim
n→∞tn = t ∈R .
Therefore s ∈R, and the series
∞
	
k=0
ak converges. Furthermore s ≤t.
ii) If the series
∞
	
k=0
bk converged, part i) of this proof would force
∞
	
k=0
ak
to converge, too.
2

148
5 Local comparison of functions. Numerical sequences and series
Examples 5.30
i) Consider
∞
	
k=1
1
k2 . Since
1
k2 <
1
(k −1)k
∀k ≥2 ,
and the series of Mengoli
∞
	
k=2
1
(k −1)k converges (Example 5.24 i)), we conclude
that our series converges and its sum is smaller or equal than 2. One could prove
that the precise value of the sum is π2/6.
ii) The series
∞
	
k=1
1
k is known as harmonic series. In Chap. 6 (Exercise 12) we
shall prove the inequality log(1 + x) ≤x, for all x > −1, whereby
log

1 + 1
k

≤1
k ,
∀k ≥1.
Since the series
∞
	
k=1
log

1 + 1
k

diverges (Example 5.24 ii)), then also the har-
monic series must diverge.
2
Here is a useful criterion that generalizes the Comparison test.
Theorem 5.31 (Asymptotic comparison test) Let
∞
	
k=0
ak and
∞
	
k=0
bk be
positive-term series and suppose the sequences {ak}k≥0 and {bk}k≥0 have the
same order of magnitude for k →∞. Then the series have the same behaviour.
Proof.
Having the same order of magnitude for k →∞is equivalent to
lim
k→∞
ak
bk
= ℓ∈R \ {0} .
Therefore the sequences
ak
bk

k≥0
and
 bk
ak

k≥0
are both convergent,
hence both bounded (Theorem 2, p. 137). So, there must exist constants
M1, M2 > 0 such that

ak
bk
 ≤M1
and

bk
ak
 ≤M2
for any k > 0, i.e.,

5.5 Numerical series
149
|ak| ≤M1|bk|
and
|bk| ≤M2|ak| .
Now it suﬃces to use Theorem 5.29 to ﬁnish the proof.
2
Examples 5.32
i) Consider
∞
	
k=0
ak =
∞
	
k=0
k + 3
2k2 + 5 and let bk = 1
k . Then
lim
k→∞
ak
bk
= 1
2
and the given series behaves as the harmonic series, hence diverges.
ii) Take the series
∞
	
k=1
ak =
∞
	
k=1
sin 1
k2 . As sin 1
k2 ∼1
k2 for k →∞, the series has
the same behaviour of
∞
	
k=1
1
k2 , so it converges.
2
Eventually, here are two more results – of algebraic ﬂavour and often easy to
employ – which provide suﬃcient conditions for a series to converge or diverge.
Theorem 5.33 (Ratio test) Let
∞
	
k=0
ak have ak > 0, ∀k ≥0. Assume the
limit
lim
k→∞
ak+1
ak
= ℓ
exists, ﬁnite or inﬁnite. If ℓ< 1 the series converges; if ℓ> 1 it diverges.
Proof.
First take ℓﬁnite. By deﬁnition of limit we know that for any ε > 0, there
is an integer kε ≥0 such that for all k > kε one has

ak+1
ak
−ℓ
 < ε
i.e.,
ℓ−ε < ak+1
ak
< ℓ+ ε .
Assume ℓ< 1. Choose ε = 1−ℓ
2
and set q = 1+ℓ
2 , so
0 < ak+1
ak
< ℓ+ ε = q ,
∀k > kε .
Repeating the argument we obtain
ak+1 < qak < q2ak−1 < . . . < qk−kεakε+1
hence

150
5 Local comparison of functions. Numerical sequences and series
ak+1 < akε+1
qkε qk ,
∀k > kε .
The claim follows by Theorem 5.29 and from the fact that the geometric
series, with q < 1, converges (Example 5.27).
Now consider ℓ> 1. Choose ε = ℓ−1, and notice
1 = ℓ−ε < ak+1
ak
,
∀k > kε .
Thus ak+1 > ak > . . . > akε+1 > 0, so the necessary condition for conver-
gence fails, for lim
k→∞ak ̸= 0.
Eventually, if ℓ= +∞, we put A = 1 in the condition of limit, and there
exists kA ≥0 with ak > 1, for any k > kA. Once again the necessary
condition to have convergence does not hold.
2
Theorem 5.34 (Root test) Given a series
∞
	
k=0
ak with non-negative terms,
suppose
lim
k→∞
k√ak = ℓ
exists, ﬁnite or inﬁnite. If ℓ< 1 the series converges, if ℓ> 1 it diverges.
Proof.
Since this proof is essentially identical to the previous one, we leave it to
the reader.
2
Examples 5.35
i) For
∞
	
k=0
k
3k we have ak = k
3k and ak+1 = k + 1
3k+1 , therefore
lim
k→∞
ak+1
ak
= lim
k→∞
1
3
k + 1
k
= 1
3 < 1 .
The given series converges by the Ratio test 5.33.
ii) The series
∞
	
k=1
1
kk has
lim
k→∞
k√ak = lim
k→∞
1
k = 0 < 1 .
The Root test 5.34 ensures that the series converges.
2
We remark that the Ratio and Root tests do not allow to conclude anything
if ℓ= 1. For example,
∞
	
k=1
1
k diverges and
∞
	
k=1
1
k2 converges, yet they both satisfy
Theorems 5.33 and 5.34 with ℓ= 1.

5.5 Numerical series
151
5.5.2 Alternating series
These are series of the form
∞
	
k=0
(−1)kbk
with
bk > 0 ,
∀k ≥0.
For them the following result due to Leibniz holds.
Theorem 5.36 (Leibniz’s alternating series test) An alternating series
∞
	
k=0
(−1)kbk converges if the following conditions hold
i)
lim
k→∞bk = 0 ;
ii) the sequence {bk}k≥0 decreases monotonically .
Denoting by s its sum, for all n ≥0
|rn| = |s −sn| ≤bn+1
and
s2n+1 ≤s ≤s2n .
Proof.
As {bk}k≥0 is a decreasing sequence, one has
s2n = s2n−2 −b2n−1 + b2n = s2n−2 −(b2n−1 −b2n) ≤s2n−2
and
s2n+1 = s2n−1 + b2n −b2n+1 ≥s2n−1 .
Thus the subsequence of partial sums made by the terms with even index
decreases, whereas the subsequence of terms with odd index increases. For
any n ≥0, moreover,
s2n = s2n−1 + b2n ≥s2n−1 ≥. . . ≥s1
and
s2n+1 = s2n −b2n+1 ≤s2n ≤. . . ≤s0.
Thus {s2n}n≥0 is bounded from below and {s2n+1}n≥0 from above. By
Theorem 3.9 both sequences converge, so let us put
lim
n→∞s2n = inf
n≥0 s2n = s∗
and
lim
n→∞s2n+1 = sup
n≥0
s2n+1 = s∗.
However, the two limits coincide, since
s∗−s∗= lim
n→∞

s2n −s2n+1

= lim
n→∞b2n+1 = 0 ;

152
5 Local comparison of functions. Numerical sequences and series
we conclude that the series
∞
	
k=0
(−1)kbk has sum s = s∗= s∗. In addition,
s2n+1 ≤s ≤s2n ,
∀n ≥0 ,
in other words the sequence {s2n}n≥0 approximates s from above, while
{s2n+1}n≥0 approximates s from below.
For any n ≥0 we have
0 ≤s −s2n+1 ≤s2n+2 −s2n+1 = b2n+2
and
0 ≤s2n −s ≤s2n −s2n+1 = b2n+1,
i.e., |rn| = |s −sn| ≤bn+1.
2
Example 5.37
Consider the alternating harmonic series
∞
	
k=1
(−1)k 1
k. Given that
lim
k→∞bk = lim
k→∞
1
k = 0
and the sequence
 1
k

k≥1
is strictly monotone decreasing, the series converges.
2
In order to study series with arbitrary signs it is useful to introduce the notion
of absolute convergence.
Deﬁnition 5.38 The series
∞
	
k=0
ak converges absolutely if the positive-
term series
∞
	
k=0
|ak| converges.
Example 5.39
The series
∞
	
k=0
(−1)k 1
k2 converges absolutely because
∞
	
k=0
1
k2 converges.
2
The next fact ensures that absolute convergence implies convergence.

5.5 Numerical series
153
Theorem 5.40 (Absolute convergence test) If
∞
	
k=0
ak converges abso-
lutely then it also converges and

∞
	
k=0
ak
 ≤
∞
	
k=0
|ak| .
Proof.
Let us introduce the sequences
a+
k =
 ak
if ak ≥0
0
if ak < 0
and
a−
k =
 0
if ak ≥0
−ak
if ak < 0 .
Notice a+
k , a−
k ≥0 for any k ≥0, and
ak = a+
k −a−
k ,
|ak| = a+
k + a−
k .
Since 0 ≤a+
k , a−
k
≤|ak|, for any k ≥0, the Comparison test (The-
orem 5.29) says that the series
∞
	
k=0
a+
k and
∞
	
k=0
a−
k converge. Observing
that
∞
	
k=0
ak =
∞
	
k=0

a+
k −a−
k

=
∞
	
k=0
a+
k −
∞
	
k=0
a−
k ,
for any n ≥0, we deduce that also the series
∞
	
k=0
ak =
∞
	
k=0
a+
k −
∞
	
k=0
a−
k
converges.
Finally, passing to the limit n →∞the relation

n
	
k=0
ak
 ≤
n
	
k=0
|ak|
yields the desired inequality.
2
Remark 5.41 There are series that converge, but not absolutely. The alternating
harmonic series
∞
	
k=1
(−1)k 1
k is one such example, for it has a ﬁnite sum, but does not
converge absolutely, since the harmonic series
∞
	
k=1
1
k diverges. In such a situation
one speaks about conditional convergence.
2
The previous criterion allows to study alternating series by their absolute con-
vergence. As the series of absolute values has positive terms, the criteria seen in
Sect. 5.5.1 apply.

154
5 Local comparison of functions. Numerical sequences and series
5.6 Exercises
1. Compare the inﬁnitesimals:
a)
x −1,
3

1
x −1, (√x −1)2 for x →1
b)
1
x3 , e−x, x2e−x, x23−x
for x →+∞
2. Compare the inﬁnite maps:
a)
x4,
3
x11 −2x2,
x4
log(1 + x)
when x →+∞
b)
x2
log x, x log x, x23x, 3x log x when x →+∞
3.
Verify that f(x) = √x + 3 −
√
3 and g(x) = √x + 5 −
√
5 are inﬁnitesimals
of the same order for x →0 and determine ℓ∈R such that f(x) ∼ℓg(x) for
x →0.
4. Verify that f(x) =
3√
x3 −2x2 + 1 and g(x) = 2x + 1 are inﬁnite of the same
order for x →−∞and determine ℓ∈R with f(x) ∼ℓg(x) when x →−∞.
5. Determine the order and the principal part with respect to ϕ(x) =
1
x, for
x →+∞, of the inﬁnitesimal functions:
a) f(x) = 2x2 +
5√x
x4
b) f(x) =

x
x + 3 −1
c) f(x) = sin

x2 + 1 −x

d) f(x) = log

9 + sin 2
x

−2 log 3
6. Determine the order and the principal part with respect to ϕ(x) = x, for
x →+∞, of the inﬁnite functions:
a) f(x) = x −

x2 + x4
b) f(x) =
1
√
x2 + 2 −
√
x2 + 1
7. Find the order and the principal part with respect to ϕ(x) = x, for x →0, of
the inﬁnitesimal functions:
a) f(x) =
√
1 + 3x −1

sin 2x2
b) f(x) =
3√cos x −1
c) f(x) =
√
1 + 3x3
1 + 2x3
−1
d) f(x) =
ex
1 + x2 −1
e) f(x) = log cos x
f) f(x) = ecos x −e
√
x3+1

5.6 Exercises
155
8. Find the order and the principal part with respect to ϕ(x) = x−x0, for x →x0,
of the inﬁnitesimals:
a) f(x) = log x −log 3 ,
x0 = 3
b) f(x) = √x −
√
2 ,
x0 = 2
c) f(x) = ex2 −e ,
x0 = 1
d) f(x) = sin x ,
x0 = π
e) f(x) = 1 + cos x ,
x0 = π
f) f(x) = sin(π cos x) ,
x0 = π
9. Compute the limits:
a) lim
x→0
1
x2
√
1 + 3x2
cos x
−1

b) lim
x→2
(√x −
√
2)2
x −2
c)
lim
x→3
log(3 −√x + 1)
3 −x
d) lim
x→1
e
√x+2 −e
√
3
(x −1)2
10. Determine domain and asymptotes of the following functions:
a) f(x) =
x2 + 1
√
x2 −1
b) f(x) = x + 2 arctanx
c) f(x) = x2 −(x + 1)|x −2|
2x + 3
d) f(x) = xe1/|x2−1|
e) f(x) =

1 + 1
x
x
f) f(x) = log(x + ex)
11. Study the behaviour of the sequences:
a) an = n −√n
b) an = (−1)n n2 + 1
√
n2 + 2
c) an = 3n −4n
1 + 4n
d) an = (2n)!
n!
e) an = (2n)!
(n!)2
f) an =
n
3
 6
n3
g) an =
n2 −n + 1
n2 + n + 2
√
n2+2
h) an = 2n sin(2−nπ)
i) an = n cos n + 1
n
π
2
ℓ) an = n!

cos
1
√
n!
−1

12. Compute the following limits:
a) lim
n→∞
n2 + 1
2n + 5n
b)
lim
n→∞n

1 + 1
n −

1 −2
n


156
5 Local comparison of functions. Numerical sequences and series
c)
lim
n→∞
cos n
n
d)
lim
n→∞(1 + (−1)n)
e)
lim
n→∞
n
3n3 + 2
f)
lim
n→∞
(n + 3)! −n!
n2(n + 1)!
g)
lim
n→∞n

3

1 + 1
n −1

h)
lim
n→∞
n2 + sin n
n2 + 2n −3
13. Study the convergence of the following positive-term series:
a)
∞
	
k=0
3
2k2 + 1
b)
∞
	
k=2
2k
k5 −3
c)
∞
	
k=0
3k
k!
d)
∞
	
k=1
k!
kk
e)
∞
	
k=1
k arcsin 7
k2
f)
∞
	
k=1
log

1 + 5
k2

14. Study the convergence of the following alternating series:
a)
∞
	
k=1
(−1)k log
 1
k + 1

b)
∞
	
k=0
(−1)k

k3 + 3
2k3 −5
c)
∞
	
k=1
sin

kπ + 1
k

d)
∞
	
k=1
(−1)k

1 + 1
k2
√
2
−1

15. Study the convergence of:
a)
∞
	
k=1

1 −cos 1
k3

b)
∞
	
k=1
sin k
k2
c)
∞
	
k=1
1
k3
k
2

d)
∞
	
k=0
(−1)k 
k√
2 −1

16. Verify that the following series converge and determine their sum:
a)
∞
	
k=1
(−1)k 2k−1
5k
b)
∞
	
k=0
3k
2 · 42k
c)
∞
	
k=1
2k + 1
k2(k + 1)2
d)
∞
	
k=0
1
(2k + 1)(2k + 3)

5.6 Exercises
157
5.6.1 Solutions
1. Comparing inﬁnitesimals:
a) Since
lim
x→1
x −1
3
1
x −1
= lim
x→1
3

x
1 −x(x −1) = −lim
x→1
3√x(x −1)2/3 = 0
lim
x→1
(√x −1)2
x −1
= lim
x→1
(x −1)2
(x −1)(√x + 1)2 = lim
x→1
x −1
(√x + 1)2 = 0 ,
we have, for x →1,
x −1 = o

3

1
x −1

,
(√x −1)2 = o(x −1) .
Thus we can order the three inﬁnitesimals by increasing order from left to
right:
3

1
x −1 ,
x −1 ,
(√x −1)2 .
The same result can be attained observing that for x →1
3

1
x −1 =
3

1 −x
x
∼−(x −1)1/3
and
√x −1 =

1 + (x −1) −1 ∼1
2(x −1),
so (√x −1)2 ∼1
4(x −1)2.
b) Putting in increasing order we have: 1
x3 , x2e−x, e−x, x23−x.
2. Comparison of inﬁnite maps:
a) As
lim
x→+∞
x4
3√
x11 −2x2 =
lim
x→+∞
x4
x11/3
3√
1 −2x−9 =
lim
x→+∞
x1/3
3√
1 −2x−9 = +∞,
it follows
3
x11 −2x2 = o(x4) for x →+∞, so
3√
x11 −2x2 is inﬁnite of smaller
order than x4.
It is immediate to see that
x4
log(1 + x) = o(x4). Moreover

158
5 Local comparison of functions. Numerical sequences and series
lim
x→+∞
3√
x11 −2x2 log(1 + x)
x4
=
lim
x→+∞
log(1 + x)
3√
1 −2x−9
x1/3
=
lim
x→+∞
log(1 + x)
x1/3
= 0 ,
that is,
3√
x11 −2x2 = o

x4
log(1 + x)

. Therefore the order increases from left
to right in
3
x11 −2x2 ,
x4
log(1 + x) ,
x4 .
b) Following the increasing order we have x log x,
x2
log x, 3x log x, x23x.
3. Since
lim
x→0
√x + 3 −
√
3
√x + 5 −
√
5 = lim
x→0
(x + 3 −3)(√x + 5 +
√
5)
(x + 5 −5)(√x + 3 +
√
3)
= lim
x→0
√x + 5 +
√
5
√x + 3 +
√
3 =

5
3
we conclude that f(x) ∼

5
3 g(x) as x →0.
4. The result is f(x) ∼1
2 g(x) for x →−∞.
5. Order of inﬁnitesimal and principal part:
a) We have
lim
x→+∞
f(x)
1/xα =
lim
x→+∞xα 2x2 +
5√x
x4
=
lim
x→+∞xα 2 + x−9/5
x2
=
lim
x→+∞2xα−2 .
This limit is ﬁnite and equals 2 if α = 2. Therefore the order of f(x) is 2 and
its principal part p(x) =
2
x2 .
Alternatively one could remark that for x →+∞,
5√x = o(x2), so 2x2 +
5√x ∼
2x2 and then f(x) ∼2x2
x4 =
2
x2 .
b) This is an inﬁnitesimal of ﬁrst order with principal part p(x) = −3
2x.
c) Note ﬁrst of all that
lim
x→+∞

x2 −1 −x

=
lim
x→+∞
x2 + 1 −x2
√
x2 −1 + x
= 0,
hence the function f(x) is inﬁnitesimal for x →+∞. In addition
lim
x→+∞
sin
√
x2 −1 −x

√
x2 −1 −x
= lim
y→0
sin y
y
= 1 .

5.6 Exercises
159
Then
lim
x→+∞xα sin

x2 −1 −x

=
lim
x→+∞xα 
x2 −1 −x
 sin
√
x2 −1 −x

√
x2 −1 −x
=
lim
x→+∞xα 
x2 −1 −x

.
One can otherwise observe that sin g(x) ∼g(x) for x →x0 if the function g(x)
is inﬁnitesimal for x →x0. For x →+∞then,
sin

x2 −1 −x

∼

x2 −1 −x
and Proposition 5.5 yields directly
lim
x→+∞xα sin

x2 −1 −x

=
lim
x→+∞xα 
x2 −1 −x

.
Computing the right-hand-side limit yields
lim
x→+∞xα 
x2 −1 −x

=
lim
x→+∞
xα
√
x2 −1 + x =
lim
x→+∞
xα−1

1 +
1
x2 + 1
= 1
2
if α = 1. Therefore the order is 1 and the principal part reads p(x) =
1
2x.
d) Consider
log

9 + sin 2
x

−2 log 3 = log 9

1 + 1
9 sin 2
x

−log 9
= log

1 + 1
9 sin 2
x

.
For x →+∞we have 1
9 sin 2
x ∼
2
9x (see the previous exercise) and log(1+y) ∼y
for y →0. So
lim
x→+∞xαf(x) =
lim
x→+∞xα 1
9 sin 2
x =
lim
x→+∞
2xα
9x = 2
9
if α = 1. Thus the order of f is 1 and its principal part p(x) =
2
9x.
6. Order of inﬁnite and principal part:
a) A computation shows
lim
x→+∞
f(x)
xα
=
lim
x→+∞
x2 
1
x −

1
x2 + 1

xα
= −
lim
x→+∞x2−α = −1
when α = 2. Then f has order 2 and principal part p(x) = −x2.
b) The order of f is 1 and the principal part is p(x) = 2x.

160
5 Local comparison of functions. Numerical sequences and series
7. Order of inﬁnitesimal and principal part:
a) First, √1 + 3x −1 ∼3
2x for x →0, in fact
lim
x→0
√1 + 3x −1
3
2x
= lim
x→0
2
3
1 + 3x −1
x(√1 + 3x + 1) = lim
x→0
2
√1 + 3x + 1 = 1 .
But sin 2x2 ∼2x2 for x →0, so
f(x) ∼3
2x · 2x2,
i.e.,
f(x) ∼3x3 ,
x →0 .
Therefore the order of f is 3 and the principal part is p(x) = 3x3.
b) The order of f is 2 and the principal part is p(x) = −1
6x2.
c) The function f has order 3 and principal part p(x) = −1
2x3.
d) Using the relation ex = 1 + x + o(x) for x →0 we have
lim
x→0
f(x)
xα
= lim
x→0
ex −1 −x2
xα(1 + x2) = lim
x→0
ex −1 −x2
xα
= lim
x→0
ex −1
xα
−x2−α

= 1
for α = 1. The order of f is 1 and the principal part is p(x) = x.
e) The function f has order 2 with principal part p(x) = −1
2x2.
f) Recalling that
cos x = 1 −1
2x2 + o(x2)
x →0 ,

x3 + 1 = (1 + x3)1/2 = 1 + 1
2x3 + o(x3)
x →0 ,
et = 1 + t + o(t)
t →0 ,
we have
f(x) = e1−1
2 x2+o(x2) −e1+ 1
2 x3+o(x3) = e

e−1
2 x2+o(x2) −e
1
2 x3+o(x3)
= e

1 −1
2x2 + o(x2) −1 −1
2x3 + o(x3)

= e

−1
2x2 + o(x2)

= −e
2x2 + o(x2) ,
x →0 .
This means f is inﬁnitesimal of order 2 and has principal part p(x) = −e
2x2.
8. Order of inﬁnitesimal and principal part:
a) Set t = x −3 so that t →0 when x →3. Then

5.6 Exercises
161
log x −log 3 = log(3 + t) −log 3 = log 3

1 + t
3

−log 3 = log

1 + t
3

.
Since log

1 + t
3

∼t
3 for t →0, it follows
f(x) = log x −log 3 ∼1
3(x −3) ,
x →3,
hence f is inﬁnitesimal of order 1 and has principal part p(x) = 1
3(x −3).
b) The order of f is 1 and the principal part is p(x) =
√
2
4 (x −2).
c) Remembering that et −1 ∼t as t →0,
f(x) = e(ex2−1 −1) ∼e(x2 −1)
= e(x + 1)(x −1) ∼2e(x −1)
for
x →1 .
Thus f is inﬁnitesimal of order 1 and has principal part p(x) = 2e(x −1).
d) The order of f is 1 and the principal part p(x) = −(x −π).
e) By setting t = x −π it follows that
1 + cos x = 1 + cos(t + π) = 1 −cos t .
But t →0 for x →π, so 1 −cos t ∼1
2t2 and
f(x) = 1 + cos x ∼1
2(x −π)2 ,
x →π .
Therefore f ha order 2 and principal part p(x) = 1
2(x −π)2.
f) The order of f is 2 and the principal part reads p(x) = π
2 (x −π)2.
9. Limits:
a) We remind that when x →0,

1 + 3x2 = 1 + 3
2x2 + o(x2)
and
cos x = 1 −1
2x2 + o(x2) ,
so we have
lim
x→0
√
1 + 3x2 −cos x
x2 cos x
= lim
x→0
1 + 3
2x2 −1 + 1
2x2 + o(x2)
x2
= lim
x→0
2x2 + o(x2)
x2
= 2 .
b) 0.

162
5 Local comparison of functions. Numerical sequences and series
c) Let y = 3 −x, so that
L = lim
x→3−
log(3 −√x + 1)
3 −x
= lim
y→0+
log(3 −√4 −y)
y
= lim
y→0+
log(3 −2

1 −y/4)
y
.
But since

1 −y/4 = 1 −1
8y + o(y), y →0, we have
L = lim
y→0+
log(3 −2 + y
4 + o(y))
y
= lim
y→0+
log(1 + y
4 + o(y))
y
= lim
y→0+
y
4 + o(y)
y
= 1
4 .
d) Albeit the limit does not exist, the right limit is +∞and the left one −∞.
10. Domain and asymptotes:
a) The function is deﬁned for x2 −1 > 0, that is to say x < −1 and x > 1; thus
dom f = (−∞, −1) ∪(1, +∞). It is even, so its behaviour on x < 0 can be
deduced from x > 0. We have
lim
x→±∞f(x) =
lim
x→±∞
x2 
1 + 1
x2

|x|

1 −1
x2
=
lim
x→±∞
x2
|x| = +∞
lim
x→−1−f(x) = 2
0+ = +∞,
lim
x→1+ f(x) = 2
0+ = +∞.
The line x = −1 is a vertical left asymptote and x = 1 is a vertical right
asymptote; there are no horizontal asymptotes. Let us search for an oblique
asymptote for x →+∞:
lim
x→+∞
f(x)
x
=
lim
x→+∞
x2 
1 + 1
x2

x2

1 −
1
x2
= 1
lim
x→+∞(f(x) −x) =
lim
x→+∞
x2 + 1 −x
√
x2 −1
√
x2 −1
=
lim
x→+∞
(x2 + 1)2 −x4 + x2
√
x2 −1(x2 + 1 + x
√
x2 −1)
=
lim
x→+∞
3x2 + 1
x3

1 −
1
x2

1 +
1
x2 +

1 −
1
x2
 =
lim
x→+∞
3x2
2x3 = 0 ,
showing that the line y = x is a oblique right asymptote.
For x →−∞we proceed in a similar way to obtain that the line y = −x is an
oblique left asymptote.

5.6 Exercises
163
b) dom f = R; y = x + π is an oblique right asymptote, y = x −π an oblique left
asymptote.
c) The function is deﬁned for x ̸= −3
2, hence dom f = R \ {−3
2}. Moreover
lim
x→−∞f(x) =
lim
x→−∞
x2 −(x + 1)(2 −x)
2x + 3
=
lim
x→−∞
2x2 −x −2
2x + 3
= −∞
lim
x→+∞f(x) =
lim
x→+∞
x2 −(x + 1)(x −2)
2x + 3
=
lim
x→+∞
x + 2
2x + 3 = 1
2
lim
x→−3
2
± f(x) =
lim
x→−3
2
±
x2 −(x + 1)(2 −x)
2x + 3
= 4
0± = ±∞;
making the line y = 1
2 a horizontal right asymptote and x = −3
2 a vertical
asymptote. Computing
lim
x→−∞
f(x)
x
=
lim
x→−∞
2x2 −x −2
x(2x + 3)
= 1
lim
x→−∞(f(x) −x) =
lim
x→+∞
−4x −2
2x + 3 = −2
tells that y = x −2 is an oblique left asymptote.
d) dom f = R\{±1}; x = ±1 are vertical asymptotes; the line y = x is a complete
oblique asymptote.
e) dom f = (−∞, −1)∪(0, +∞); horizontal asymptote y = e, vertical left asymp-
tote x = −1.
f) the function f is deﬁned for x + ex > 0. To solve this inequality, note that
g(x) = x + ex is a strictly increasing function on R (as sum of two such maps)
satisfying g(−1) = −1 + 1
e < 0 and g(0) = 1 > 0. The Theorem of existence of
zeroes 4.23 implies that there is a unique point x0 ∈(−1, 0) with g(x0) = 0.
Thus g(x) > 0 for x > x0 and dom f = (x0, +∞). Moreover
lim
x→x+
0
f(x) = log lim
x→x+
0
(x + ex) = −∞
and
lim
x→+∞f(x) = +∞,
so x = x0 is a vertical right asymptote and there are no horizontal ones for
x →+∞. For oblique asymptotes consider
lim
x→+∞
f(x)
x
=
lim
x→+∞
log ex(1 + xe−x)
x
=
lim
x→+∞
x + log(1 + xe−x)
x
= 1 +
lim
x→+∞
log(1 + xe−x)
x
= 1 ,
lim
x→+∞(f(x) −x) =
lim
x→+∞log(1 + xe−x) = 0
because
lim
x→+∞xe−x = 0 (recalling (5.6) a)). Thus the line y = x is an oblique
right asymptote.

164
5 Local comparison of functions. Numerical sequences and series
11. Sequences behaviour:
a) Diverges to +∞;
b) indeterminate.
c) The geometric sequence (Example 5.18 i)) suggests to consider
lim
n→∞an = lim
n→∞
4n 
( 3
4)n −1

4n(4−n + 1) = −1 ,
hence the given sequence converges to −1.
d) Diverges to +∞.
e) Let us write
an = 2n(2n −1) · · · (n + 2)(n + 1)
n(n −1) · · · 2 · 1
= 2n
n · 2n −1
n −1 · · · n + 2
2
· n + 1
1
> n + 1 .
As lim
n→∞(n + 1) = +∞, the Second comparison theorem (with inﬁnite limits)
forces the sequence to diverge to +∞.
f) Converges to 1.
g) Since
an = exp

n2 + 2 log n2 −n + 1
n2 + n + 2

,
we consider the sequence
bn =

n2 + 2 log n2 −n + 1
n2 + n + 2 =

n2 + 2 log

1 −
2n + 1
n2 + n + 2

.
Note that
lim
n→∞
2n + 1
n2 + n + 2 = 0
implies
log

1 −
2n + 1
n2 + n + 2

∼−
2n + 1
n2 + n + 2 ,
n →∞.
Then
lim
n→∞bn = −lim
n→∞
√
n2 + 2 (2n + 1)
n2 + n + 2
= −lim
n→∞
2n2
n2 = −2
and the sequence {an} converges to e−2.
h) Call x = 2−nπ, so that x →0+ for n →∞. Then
lim
n→∞an = lim
x→0+ π sin x
x
= π
and {an} converges to π.

5.6 Exercises
165
i) Because
cos n + 1
n
π
2 = cos
π
2 + π
2n

= −sin π
2n ,
putting x =
π
2n has the eﬀect that
lim
n→∞an = −lim
n→∞n sin π
2n = −lim
x→0+
π
2
sin x
x
= −π
2 ,
thus {an} converges to −π
2 .
ℓ) Converges to −1
2.
12. Limits:
a) 0.
b) Since 1
n →0 for n →∞,

1 + 1
n = 1 + 1
2n + o
 1
n

and

1 −2
n = 1 −1
n + o
 1
n

so
lim
n→∞n

1 + 1
n −

1 −2
n

= lim
n→∞n
 3
2n + o
 1
n

= 3
2 .
c) 0;
d) does not exist.
e) Let us write
n
3n3 + 2 = exp
 1
n log(3n3 + 2)

and observe
1
n log(3n3 + 2) = log

3n3 
1 +
2
3n3

n
= log 3
n
+ 3 log n
n
+ log

1 +
2
3n3

n
.
In addition
log

1 +
2
3n3

∼
2
3n3 ,
n →∞.
Thus
lim
n→∞
1
n log(3n3 + 2) = 0
and the required limit is e0 = 1.
f) From
(n + 3)! −n!
n2(n + 1)!
= n!((n + 3)(n + 2)(n + 1) −1)
n2(n + 1)n!
= (n + 3)(n + 2)(n + 1) −1
n2(n + 1)
it follows that
lim
n→∞
(n + 3)! −n!
n2(n + 1)!
= lim
n→∞
(n + 3)(n + 2)(n + 1) −1
n2(n + 1)
= 1 .

166
5 Local comparison of functions. Numerical sequences and series
g) As
3

1 + 1
n = 1 + 1
3n + o
 1
n

,
n →∞,
we have
lim
n→∞n

3

1 + 1
n −1

= lim
n→∞n
 1
3n + o
 1
n

= 1
3 .
h) 1.
13. Convergence of positive-term series:
a) Converges.
b) The general term ak tends to +∞for k →∞. By Property 5.25 the series
diverges. Alternatively, the Root test 5.34 can be used.
c) By the Ratio test 5.33 one obtains
lim
k→∞
ak+1
ak
= lim
k→∞
3k+1
(k + 1)!
k!
3k ;
writing (k + 1)! = (k + 1)k! and simplifying we see that
lim
k→∞
ak+1
ak
= lim
k→∞
3
k + 1 = 0
and the series converges.
d) Again with the help of the Ratio test 5.33, we have
lim
k→∞
ak+1
ak
= lim
k→∞
(k + 1)!
(k + 1)k+1 · kk
k! = lim
k→∞

k
k + 1
k
= 1
e < 1
and the series converges.
e) Notice
ak ∼k 7
k2 = 7
k
for
k →∞.
By the Asymptotic behaviour test 5.31, and remembering that the harmonic
series does not converge, we conclude that the given series must diverge too.
f) Converges.
14. Convergence of alternating series:
a) Converges;
b) does not converge.

5.6 Exercises
167
c) Since
sin

kπ + 1
k

= cos(kπ) sin 1
k = (−1)k sin 1
k ,
the given series has alternating sign, with bk = sin 1
k. As
lim
k→∞bk = 0
and
bk+1 < bk ,
Leibniz’s test 5.36 guarantees convergence. The series does not converge abso-
lutely since sin 1
k ∼1
k for k →∞, so the series of absolute values behaves as
the (diverging) harmonic series.
d) By using one of the equivalences of p. 127 one sees that
(−1)k

1 + 1
k2
√
2
−1
 ∼
√
2
k2 ,
k →∞.
Example 5.30 i) suggests to apply the Asymptotic comparison test 5.31 to the
series of absolute values. We conclude that the given series converges abso-
lutely.
15. Study of convergence:
a) Converges.
b) Observe ﬁrst that

sin k
k2
 ≤1
k2 ,
for all k > 0 ;
the series
∞
	
k=1
1
k2 converges and the Comparison test 5.29 tells that the series
of absolute values converges. Thus the given series converges absolutely.
c) Diverges.
d) This is an alternating series where bk =
k√
2 −1. The ﬁrst term b0 = 0 apart,
the sequence {bk}k≥1 decreases because
k√
2 >
k+1√
2 for all k ≥1. Thus Leib-
niz’s test 5.36 allows us to conclude that the series converges. Notice that
convergence is not absolute, as
k√
2 −1 = e
log 2
k
−1 ∼log 2
k
,
k →∞,
conﬁrming that the series of absolute values is like the harmonic series, which
diverges.
16. Computing the sum of a converging series:
a) −1
7 .

168
5 Local comparison of functions. Numerical sequences and series
b) Apart from a constant, this is essentially a geometric series; by Example 5.27
then,
∞
	
k=1
3k
2 · 42k = 1
2
∞
	
k=1
 3
16
k
= 1
2

1
1 −3
16
−1

= 3
26
(note that the ﬁrst index in the sum is 1).
c) The series is telescopic since
2k + 1
k2(k + 1)2 = 1
k2 −
1
(k + 1)2 ,
so
sn = 1 −
1
(n + 1)2 .
This implies s = lim
n→∞sn = 1.
d)
1
2 .

6
Diﬀerential calculus
The precise deﬁnition of the notion of derivative, studying a function’s diﬀerenti-
ability and computing its successive derivatives, the use of derivatives to analyse
the local and global behaviours of functions are all constituents of Diﬀerential
Calculus.
6.1 The derivative
We start by deﬁning the derivative of a function.
Let f : dom f ⊆R →R be a real function of one real variable, take x0 ∈dom f
and suppose f is deﬁned in a neighbourhood Ir(x0) of x0. With x ∈Ir(x0), x ̸= x0
ﬁxed, denote by
Δx = x −x0
the (positive or negative) increment of the independent variable between
x0 and x, and by
Δf = f(x) −f(x0)
the corresponding increment of the dependent variable. Note that x = x0 +
Δx, f(x) = f(x0) + Δf.
The ratio
Δf
Δx = f(x) −f(x0)
x −x0
= f(x0 + Δx) −f(x0)
Δx
is called diﬀerence quotient of f between x0 and x.
In this manner Δf represents the absolute increment of the dependent variable
f when passing from x0 to x0 + Δx, whereas the diﬀerence quotient detects the
rate of increment (while Δf/f is the relative increment). Multiplying the diﬀerence
quotient by 100 we obtain the so-called percentage increment. Suppose a rise by
Δx = 0.2 of the variable x prompts an increment Δf = 0.06 of f; the diﬀerence
quotient Δf
Δx equals 0.3 =
30
100, corresponding to a 30% increase.
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_6,
© Springer International Publishing Switzerland 2015

170
6 Diﬀerential calculus
x0
f(x0)
P0
x0 + Δx
f(x0 + Δx)
P1
y = f(x)
y = s(x)
y = t(x)
Figure 6.1. Secant and tangent lines to the graph of f at P0
Graphically, the diﬀerence quotient between x0 and a point x1 around x0 is the
slope of the straight line s passing through P0 =

x0, f(x0)

and P1 =

x1, f(x1)

,
points that belong to the graph of the function; this line is called secant of the
graph of f at P0 and P1 (Fig. 6.1). Putting Δx = x1 −x0 and Δf = f(x1)−f(x0),
the equation of the secant line reads
y = s(x) = f(x0) + Δf
Δx(x −x0),
x ∈R.
(6.1)
A typical application of the diﬀerence quotient comes from physics. Let M be
a point-particle moving along a straight line; call s = s(t) the x-coordinate of the
position of M at time t, with respect to a reference point O. Between the instants
t0 and t1 = t0 + Δt, the particle changes position by Δs = s(t1) −s(t0). The
diﬀerence quotient Δs
Δt represents the average velocity of the particle in the given
interval of time.
How does the diﬀerence quotient change, as Δx approaches 0? This is answered
by the following notion.
Deﬁnition 6.1 A map f deﬁned on a neighbourhood of x0 ∈R is called
diﬀerentiable at x0 if the limit of the diﬀerence quotient Δf
Δx between x0
and x exists and is ﬁnite, as x approaches x0. The real number
f ′(x0) = lim
x→x0
f(x) −f(x0)
x −x0
= lim
Δx→0
f(x0 + Δx) −f(x0)
Δx
is called (ﬁrst) derivative of f at x0.

6.1 The derivative
171
The derivative at x0 is variously denoted, for instance also by
y′(x0),
df
dx(x0),
Df(x0).
The ﬁrst symbol goes back to Newton, the second is associated to Leibniz.
From the geometric point of view f ′(x0) is the slope of the tangent line at
P0 =

x0, f(x0)

to the graph of f: such line t is obtained as the limiting position
of the secant s at P0 and P =

x, f(x)

, when P approaches P0. From (6.1) and
the previous deﬁnition we have
y = t(x) = f(x0) + f ′(x0)(x −x0),
x ∈R.
In the physical example given above, the derivative v(t0) = s′(t0) = lim
Δt→0
Δs
Δt
is the instantaneous velocity of the particle M at time t0.
Let
dom f ′ = {x ∈dom f : f is diﬀerentiable at x}
and deﬁne the function f ′ : dom f ′ ⊆R →R, f ′ : x →f ′(x) mapping x ∈dom f ′
to the value of the derivative of f at x. This map is called (ﬁrst) derivative of f.
Deﬁnition 6.2 Let I be a subset of dom f. We say that f is diﬀerentiable
on I (or in I) if f is diﬀerentiable at each point of I.
A ﬁrst yet signiﬁcant property of diﬀerentiable maps is the following.
Proposition 6.3 If f is diﬀerentiable at x0, it is also continuous at x0.
Proof.
Continuity at x0 prescribes
lim
x→x0 f(x) = f(x0),
that is
lim
x→x0

f(x) −f(x0)

= 0.
If f is diﬀerentiable at x0, then
lim
x→x0

f(x) −f(x0)

= lim
x→x0
f(x) −f(x0)
x −x0
(x −x0)
= lim
x→x0
f(x) −f(x0)
x −x0
lim
x→x0(x −x0)
= f ′(x0) · 0 = 0.
2

172
6 Diﬀerential calculus
Not all continuous maps at a point are diﬀerentiable though. Consider the map
f(x) = |x|: it is continuous at the origin, yet the diﬀerence quotient between the
origin and a point x ̸= 0 is
Δf
Δx = f(x) −f(0)
x −0
= |x|
x =
 +1
if x > 0,
−1
if x < 0,
(6.2)
so the limit for x →0 does not exist. Otherwise said, f is not diﬀerentiable at
the origin. This particular example shows that the implication of Proposition 6.3
can not be reversed: diﬀerentiability is thus a stronger property than continuity,
an aspect to which Sect. 6.3 is entirely devoted.
6.2 Derivatives of the elementary functions. Rules of
diﬀerentiation
We begin by tackling the issue of diﬀerentiability for elementary functions using
Deﬁnition 6.1.
i) Consider the aﬃne map f(x) = ax + b, and let x0 ∈R be arbitrary. Then
f ′(x0) = lim
Δx→0

a(x0 + Δx) + b

−(ax0 + b)
Δx
= lim
Δx→0 a = a,
in agreement with the fact that the graph of f is a straight line of slope a. The
derivative of f(x) = ax + b is then the constant map f ′(x) = a.
In particular if f is constant (a = 0), its derivative is identically zero.
ii) Take f(x) = x2 and x0 ∈R. Since
f ′(x0) = lim
Δx→0
(x0 + Δx)2 −x2
0
Δx
= lim
Δx→0(2x0 + Δx) = 2x0,
the derivative of f(x) = x2 is the function f ′(x) = 2x.
iii) Now let f(x) = xn with n ∈N. The binomial formula (1.13) yields
f ′(x0) = lim
Δx→0
(x0 + Δx)n −xn
0
Δx
= lim
Δx→0
xn
0 + nxn−1
0
Δx +
n
	
k=2

n
k

xn−k
0
(Δx)k −xn
0
Δx
= lim
Δx→0

nxn−1
0
+
n
	
k=2

n
k

xn−k
0
(Δx)k−1

= nxn−1
0
.
for all x0 ∈R. Therefore, f ′(x) = nxn−1 is the derivative of f(x) = xn .

6.2 Derivatives of the elementary functions. Rules of diﬀerentiation
173
iv) Even more generally, consider f(x) = xα where α ∈R, and let x0 ̸= 0 be a
point of the domain. Then
f ′(x0) = lim
Δx→0
(x0 + Δx)α −xα
0
Δx
= lim
Δx→0
xα
0

1 + Δx
x0
α
−1

Δx
= xα−1
0
lim
Δx→0

1 + Δx
x0
α
−1
Δx
x0
.
Substituting y =
Δx
x0 brings the latter into the form of the fundamental limit
(4.13), so
f ′(x0) = αxα−1
0
.
When α > 1, f is diﬀerentiable at x0 = 0 as well, and f ′(0) = 0. The function
f(x) = xα is thus diﬀerentiable at all points where the expression xα−1 is well
deﬁned; its derivative is f ′(x) = αxα−1.
For example f(x) = √x = x1/2, deﬁned on [0, +∞), is diﬀerentiable on (0, +∞)
with derivative f ′(x) =
1
2√x. The function f(x) =
3√
x5 = x5/3 is deﬁned on R,
where it is also diﬀerentiable, and f ′(x) = 5
3x2/3 = 5
3
3√
x2.
v) Now consider the trigonometric functions. Take f(x) = sin x and x0 ∈R.
Formula (2.14) gives
f ′(x0) = lim
Δx→0
sin(x0 + Δx) −sin x0
Δx
= lim
Δx→0
2 sin Δx
2 cos(x0 + Δx
2 )
Δx
= lim
Δx→0
sin Δx
2
Δx
2
lim
Δx→0 cos

x0 + Δx
2

.
The limit (4.5) and the cosine’s continuity tell
f ′(x0) = cos x0.
Hence the derivative of f(x) = sin x is f ′(x) = cos x.
Using in a similar way formula (2.15), we can see that the derivative of f(x) =
cos x is the function f ′(x) = −sin x.
vi) Eventually, consider the exponential function f(x) = ax. By (4.12) we have
f ′(x0) = lim
Δx→0
ax0+Δx −ax0
Δx
= ax0 lim
Δx→0
aΔx −1
Δx
= ax0 log a,
showing that the derivative of f(x) = ax is f ′(x) = (log a)ax.
As log e = 1, the derivative of f(x) = ex is f ′(x) = ex = f(x), whence the
derivative f ′ coincides at each point with the function f itself. This is a crucial
fact, and a reason for choosing e as privileged base for the exponential map.

174
6 Diﬀerential calculus
We next discuss diﬀerentiability in terms of operations (algebraic operations,
composition, inversion) on functions. We shall establish certain diﬀerentiation
rules to compute derivatives of functions that are built from the elementary ones,
without resorting to the deﬁnition each time. The proofs may be found in Ap-
pendix A.4.1, p. 449.
Theorem 6.4 (Algebraic
operations) Let f(x), g(x) be diﬀerentiable
maps at x0 ∈R. Then the maps f(x) ± g(x), f(x)g(x) and, if g(x0) ̸= 0,
f(x)
g(x) are diﬀerentiable at x0. To be precise,
(f ± g)′(x0) = f ′(x0) ± g′(x0),
(6.3)
(f g)′(x0) = f ′(x0)g(x0) + f(x0)g′(x0),
(6.4)
f
g
′
(x0) = f ′(x0)g(x0) −f(x0)g′(x0)
[g(x0)]2
.
(6.5)
Corollary 6.5 (Linearity of the derivative) If f(x) and g(x) are diﬀer-
entiable at x0 ∈R, the map αf(x) + βg(x) is diﬀerentiable at x0 for any
α, β ∈R and
(αf + βg)′(x0) = αf ′(x0) + βg′(x0).
(6.6)
Proof.
Consider (6.4) and recall that diﬀerentiating a constant gives zero; then
(αf)′(x0) = αf ′(x0) and (βg)′(x0) = βg′(x0) follow. The rest is a con-
sequence of (6.3).
2
Examples 6.6
i) To diﬀerentiate a polynomial, we use the fact that D xn = nxn−1 and apply
the corollary repeatedly. So, f(x) = 3x5 −2x4 −x3 + 3x2 −5x + 2 diﬀerentiates
to
f ′(x) = 3 · 5x4 −2 · 4x3 −3x2 + 3 · 2x −5 = 15x4 −8x3 −3x2 + 6x −5.
ii) For rational functions, we compute the numerator and denominator’s deriv-
atives and then employ rule (6.5), to the eﬀect that
f(x) = x2 −3x + 1
2x −1
has derivative
f ′(x) = (2x −3)(2x −1) −(x2 −3x + 1)2
(2x −1)2
= 2x2 −2x + 1
4x2 −4x + 1.

6.2 Derivatives of the elementary functions. Rules of diﬀerentiation
175
iii) Consider f(x) = x3 sin x. The product rule (6.4) together with (sin x)′ = cos x
yield
f ′(x) = 3x2 sin x + x3 cos x.
iv) The function
f(x) = tan x = sin x
cos x
can be diﬀerentiated with (6.5)
f ′(x) = cos x cos x −sin x (−sin x)
cos2 x
= cos2 x + sin2 x
cos2 x
= 1 + sin2 x
cos2 x = 1 + tan2 x.
Another possibility is to use cos2 x + sin2 x = 1 to obtain
f ′(x) =
1
cos2 x.
2
Theorem 6.7 (“Chain rule”) Let f(x) be diﬀerentiable at x0 ∈R and g(y)
a diﬀerentiable map at y0 = f(x0). Then the composition g ◦f(x) = g

f(x)

is diﬀerentiable at x0 and
(g ◦f)′(x0) = g′(y0)f ′(x0) = g′
f(x0)

f ′(x0).
(6.7)
Examples 6.8
i) The map h(x) =
√
1 −x2 is the composite of f(x) = 1 −x2, whose derivative
is f ′(x) = −2x, and g(y) = √y, for which g′(y) =
1
2√y . Then (6.7) directly gives
h′(x) =
1
2
√
1 −x2 (−2x) = −
x
√
1 −x2 .
ii) The function h(x) = ecos 3x is composed by f(x) = cos 3x, g(y) = ey. But
f(x) is in turn the composite of ϕ(x) = 3x and ψ(y) = cos y; thus (6.7) tells
f ′(x) = −3 sin3x. On the other hand g′(y) = ey. Using (6.7) once again we
conclude
h′(x) = −3ecos 3x sin 3x.
2
Theorem 6.9 (Derivative of the inverse function) Suppose f(x) is a
continuous, invertible map on a neighbourhood of x0 ∈R, and diﬀerentiable
at x0, with f ′(x0) ̸= 0. Then the inverse map f −1(y) is diﬀerentiable at
y0 = f(x0), and
(f −1)′(y0) =
1
f ′(x0) =
1
f ′(f −1(y0)).
(6.8)

176
6 Diﬀerential calculus
Examples 6.10
i) The function y = f(x) = tan x has derivative f ′(x) = 1 + tan2 x and inverse
x = f −1(y) = arctan y. By (6.8)
(f −1)′(y) =
1
1 + tan2 x =
1
1 + y2 .
Setting for simplicity f −1 = g and denoting the independent variable with x,
the derivative of g(x) = arctanx is the function g′(x) =
1
1 + x2 .
ii) We are by now acquainted with the function y = f(x) = sin x: it is invertible
on [−π
2 , π
2 ], namely x = f −1(y) = arcsiny. Moreover, f diﬀerentiates to f ′(x) =
cos x. Using cos2 x + sin2 x = 1, and taking into account that on that interval
cos x ≥0, one can write the derivative of f in the equivalent form f ′(x) =

1 −sin2 x. Now (6.8) yields
(f −1)′(y) =
1

1 −sin2 x
=
1

1 −y2 .
Put once again f −1 = g and change names to the variables: the derivative of
g(x) = arcsin x is g′(x) =
1
√
1 −x2 .
In similar fashion g(x) = arccosx diﬀerentiates to g′(x) = −
1
√
1 −x2 .
iii) Consider y = f(x) = ax. It has derivative f ′(x) = (log a)ax and inverse
x = f −1(y) = loga y. The usual (6.8) gives
(f −1)′(y) =
1
(log a)ax =
1
(log a)y .
Deﬁning f −1 = g and renaming x the independent variable gives g′(x) =
1
(log a)x
as derivative of g(x) = loga x (x > 0).
Take now h(x) = loga(−x) (with x < 0), composition of x →−x and g(y): then
h′(x) =
1
(log a)(−x)(−1) =
1
(log a)x. Putting all together shows that g(x) =
loga |x| (x ̸= 0) has derivative g′(x) =
1
(log a)x.
With the choice of base a = e the derivative of g(x) = log |x| is g′(x) = 1
x.
2
Remark 6.11 Let f(x) be diﬀerentiable and strictly positive on an interval I.
Due to the previous result and the Chain rule, the derivative of the composite
map g(x) = log f(x) is
g′(x) = f ′(x)
f(x) .
The expression f ′
f is said logarithmic derivative of the map f.
2

6.3 Where diﬀerentiability fails
177
The section ends with a useful corollary to the Chain rule 6.7.
Property 6.12 If f is an even (or odd) diﬀerentiable function on all its
domain, the derivative f ′ is odd (resp. even).
Proof.
Since f is even, f(−x) = f(x) for any x ∈dom f. Let us diﬀerentiate both
sides. As f(−x) is the composition of x →−x and y →f(y), its derivative
reads −f ′(−x). Then f ′(−x) = −f ′(x) for all x ∈dom f, so f ′ is odd.
Similarly if f is odd.
2
We reckon it could be useful to collect the derivatives of the main elementary
functions in one table, for reference.
D xα = αxα−1
(∀α ∈R)
D sin x = cos x
D cos x = −sin x
D tan x = 1 + tan2 x =
1
cos2 x
D arcsinx =
1
√
1 −x2
D arccosx = −
1
√
1 −x2
D arctanx =
1
1 + x2
D ax = (log a) ax
in particular,
D ex = ex
D loga |x| =
1
(log a) x
in particular,
D log |x| = 1
x
6.3 Where diﬀerentiability fails
It was noted earlier that the function f(x) = |x| is continuous but not diﬀerentiable
at the origin. At each other point of the real line f is diﬀerentiable, for it coincides
with the line y = x when x > 0, and with y = −x for x < 0. Therefore f ′(x) = +1

178
6 Diﬀerential calculus
for x > 0 and f ′(x) = −1 on x < 0. The reader will recall the sign function
(Example 2.1 iv)), for which
D |x| = sign(x),
for all x ̸= 0.
The origin is an isolated point of non-diﬀerentiability for y = |x|.
Returning to the expression (6.2) for the diﬀerence quotient at the origin, we
observe that the one-sided limits exist and are ﬁnite:
lim
x→0+
Δf
Δx = 1,
lim
x→0−
Δf
Δx = −1.
This fact suggests us to introduce the following notion.
Deﬁnition 6.13 Suppose f is deﬁned on a right neighbourhood of x0 ∈R. It
is called diﬀerentiable on the right at x0 if the right limit of the diﬀerence
quotient Δf
Δx between x0 and x exists ﬁnite, for x approaching x0. The real
number
f ′
+(x0) = lim
x→x+
0
f(x) −f(x0)
x −x0
=
lim
Δx→0+
f(x0 + Δx) −f(x0)
Δx
is the right (or backward) derivative of f at x0. Similarly it goes for the
left (or forward) derivative f ′
−(x0).
If f is deﬁned only on a right (resp. left) neighbourhood of x0 and is diﬀerenti-
able on the right (resp. the left) at x0, we shall simply say that f is diﬀerentiable
at x0, and write f ′(x0) = f ′
+(x0) (resp. f ′(x0) = f ′
−(x0)).
From Proposition 3.24 the following criterion is immediate.
Property 6.14 A map f deﬁned around a point x0 ∈R is diﬀerentiable at
x0 if and only if it is diﬀerentiable on both sides at x0 and the left and right
derivatives coincide, in which case
f ′(x0) = f ′
+(x0) = f ′
−(x0).
Instead, if f is diﬀerentiable at x0 on the left and on the right, but the two
derivatives are diﬀerent (as for f(x) = |x| at the origin), x0 is called corner
(point) for f (Fig. 6.2). The term originates in the geometric observation that the
right derivative of f at x0 represents the slope of the right tangent to the graph
of f at P0 = (x0, f(x0)), i.e., the limiting position of the secant through P0 and
P = (x, f(x)) as x > x0 approaches x0. In case the right and left tangent (similarly
deﬁned) do not coincide, they form an angle at P0.

6.3 Where diﬀerentiability fails
179
Figure 6.2. Non-diﬀerentiable maps: the origin is a corner point (left), a point with
vertical tangent (middle), a cusp (right)
Other interesting cases occur when the right and left limits of the diﬀerence
quotient of f at x0 exist, but one at least is not ﬁnite. These will be still denoted
by f ′
+(x0) and f ′
−(x0).
Precisely, if just one of f ′
+(x0), f ′
−(x0) is inﬁnite, we still say that x0 is a corner
point for f.
If both f ′
+(x0) and f ′
−(x0) are inﬁnite and with same sign (hence the limit of
the diﬀerence quotient is +∞or −∞), x0 is a point with vertical tangent for
f. This is the case for f(x) =
3√x:
f ′
±(0) = lim
x→0±
3√x
x
= lim
x→0±
1
3√
x2 = +∞.
When f ′
+(x0), f ′
−(x0) are ﬁnite and have diﬀerent signs, x0 is called a cusp
(point) of f. For instance the map f(x) =

|x| has a cusp at the origin, for
f ′
±(0) = lim
x→0±

|x|
x
= lim
x→0±

|x|
sign(x) |x| = lim
x→0±
1
sign(x)

|x|
= ±∞.
Another criterion for diﬀerentiability at a point x0 is up next. The proof is
deferred to Sect. 6.11, for it relies on de l’Hˆopital’s Theorem.
Theorem 6.15 Let f be continuous at x0 and diﬀerentiable at all points
x ̸= x0 in a neighbourhood of x0. Then f is diﬀerentiable at x0 provided that
the limit of f ′(x) for x →x0 exists ﬁnite. If so,
f ′(x0) = lim
x→x0 f ′(x).
Example 6.16
We take the function
f(x) =
 a sin 2x −4
if x < 0,
b(x −1) + ex
if x ≥0,

180
6 Diﬀerential calculus
and ask ourselves whether there are real numbers a and b rendering f diﬀeren-
tiable at the origin. The continuity at the origin (recall: diﬀerentiable implies
continuous) forces the two values
lim
x→0−f(x) = −4,
lim
x→0+ f(x) = f(0) = −b + 1
to agree, hence b = 5. With b ﬁxed, we may impose the equality of the right
and left limits of f ′(x) for x →0, to the eﬀect that f ′(x) admits ﬁnite limit for
x →0. Then we use Theorem 6.15, which prescribes that
lim
x→0−f ′(x) = lim
x→0−2a cos 2x = 2a,
and
lim
x→0+ f ′(x) = lim
x→0+(5 + ex) = 6
are the same, so a = 3.
2
Remark 6.17 In using Theorem 6.15 one should not forget to impose continuity
at the point x0. The mere existence of the limit for f ′ is not enough to guarantee
f will be diﬀerentiable at x0. For example, f(x) = x + sign x is diﬀerentiable at
every x ̸= 0: since f ′(x) = 1, it necessarily follows lim
x→0 f ′(x) = 1. The function is
nonetheless not diﬀerentiable, because not continuous, at x = 0.
2
6.4 Extrema and critical points
Deﬁnition 6.18 One calls x0 ∈dom f a relative (or local) maximum
point for f if there is a neighbourhood Ir(x0) of x0 such that
∀x ∈Ir(x0) ∩dom f,
f(x) ≤f(x0).
Then f(x0) is a relative (or local) maximum of f.
One calls x0 an absolute maximum point (or global maximum point)
for f if
∀x ∈dom f,
f(x) ≤f(x0),
and f(x0) becomes the (absolute) maximum of f. In either case, the max-
imum is said strict if f(x) < f(x0) when x ̸= x0.
Exchanging the symbols ≤with ≥one obtains the deﬁnitions of relative and
absolute minimum point. A minimum or maximum point shall be referred to
generically as an extremum (point) of f.
Examples 6.19
i) The parabola f(x) = 1+2x−x2 = 2−(x−1)2 has a strict absolute maximum
point at x0 = 1, and 2 is the function’s absolute maximum. Notice the derivative
f ′(x) = 2(1 −x) is zero at that point. There are no minimum points (relative or
absolute).

6.4 Extrema and critical points
181
x0
x0
x0
Figure 6.3. Types of maxima
ii) For g(x) = arcsin x (see Fig. 2.24), x0 = 1 is a strict absolute maximum point,
with maximum value π
2 . The point x1 = −1 is a strict absolute minimum, with
value −π
2 . At these extrema g is not diﬀerentiable.
2
We are interested in ﬁnding the extremum points of a given function. Provided
the latter is diﬀerentiable, it might be useful to look for the points where the ﬁrst
derivative vanishes.
Deﬁnition 6.20 A critical point (or stationary point) of f is a point x0
at which f is diﬀerentiable with derivative f ′(x0) = 0.
The tangent at a critical point is horizontal.
x0
x1
x2
Figure 6.4. Types of critical points
Theorem 6.21 (Fermat) Suppose f is deﬁned in a full neighbourhood of a
point x0 and diﬀerentiable at x0. If x0 is an extremum point, then it is critical
for f, i.e.,
f ′(x0) = 0.

182
6 Diﬀerential calculus
Proof.
To ﬁx ideas, assume x0 is a relative maximum point and that Ir(x0) is a
neighbourhood where f(x) ≤f(x0) for all x ∈Ir(x0). On such neighbour-
hood then Δf =f(x) −f(x0) ≤0.
If x > x0, hence Δx = x −x0 > 0, the diﬀerence quotient Δf
Δx is non-
positive. Corollary 4.3 implies
lim
x→x+
0
f(x) −f(x0)
x −x0
≤0.
Vice versa, if x < x0, i.e., Δx < 0, then Δf
Δx is non-negative, so
lim
x→x−
0
f(x) −f(x0)
x −x0
≥0.
By Property 6.14,
f ′(x0) = lim
x→x+
0
f(x) −f(x0)
x −x0
= lim
x→x−
0
f(x) −f(x0)
x −x0
,
so f ′(x0) is simultaneously ≤0 and ≥0, hence zero.
A similar argument holds for relative minima.
2
Fermat’s Theorem 6.21 ensures that the extremum points of a diﬀerentiable
map which belong to the interior of the domain should be searched for among
critical points.
A function can nevertheless have critical points that are not extrema, as in
Fig. 6.4. The map f(x) = x3 has the origin as a critical point (f ′(x) = 3x2 = 0 if
and only if x = 0), but admits no extremum since it is strictly increasing on the
whole R.
At the same time though, a function may have non-critical extremum point
(Fig. 6.3); this happens when a function is not diﬀerentiable at an extremum that
lies inside the domain (e.g. f(x) = |x|, whose absolute minimum is attained at the
origin), or when the extremum point is on the boundary (as in Example 6.19 ii)).
The upshot is that in order to ﬁnd all extrema of a function, browsing through
the critical points might not be suﬃcient.
To summarise, extremum points are contained among the points of the domain
at which either
i)
the ﬁrst derivative vanishes,
ii) or the function is not diﬀerentiable,
iii) or among the domain’s boundary points (inside R).

6.5 Theorems of Rolle, Lagrange, and Cauchy
183
6.5 Theorems of Rolle, Lagrange, and Cauchy
We begin this section by presenting two theorems, Rolle’s Theorem and Lagrange’s
or Mean Value Theorem, that are fundamental for the study of diﬀerentiable maps
on an interval.
Theorem 6.22 (Rolle) Let f be a function deﬁned on a closed bounded
interval [a, b], continuous on [a, b] and diﬀerentiable on (a, b) (at least). If
f(a) = f(b), there exists an x0 ∈(a, b) such that
f ′(x0) = 0.
In other words, f admits at least one critical point in (a, b).
Proof.
By the Theorem of Weierstrass the range f([a, b]) is the closed interval
[m, M] bounded by the minimum and maximum values m, M of the map:
m = min
x∈[a,b] f(x) = f(xm),
M = max
x∈[a,b]f(x) = f(xM),
for suitable xm, xM ∈[a, b].
In case m = M, f is constant on [a, b], so in particular f ′(x) = 0 for any
x ∈(a, b) and the theorem follows.
Suppose then m < M. Since m ≤f(a) = f(b) ≤M, one of the strict
inequalities f(a) = f(b) < M, m < f(a) = f(b) will hold.
If f(a) = f(b) < M, the absolute maximum point xM cannot be a nor b;
thus, xM ∈(a, b) is an interior extremum point at which f is diﬀerentiable.
By Fermat’s Theorem 6.21 we have that xM = x0 is a critical point.
If m < f(a) = f(b), one proves analogously that xm is the critical point
x0 of the claim.
2
The theorem proves the existence of one critical point in (a, b); Fig. 6.5 shows that
there could actually be more.
a
b
x0
f(a) = f(b)
Figure 6.5. Rolle’s Theorem

184
6 Diﬀerential calculus
Theorem 6.23 (Mean Value Theorem or Lagrange Theorem) Let f
be deﬁned on the closed and bounded interval [a, b], continuous on [a, b] and
diﬀerentiable (at least) on (a, b). Then there is a point x0 ∈(a, b) such that
f(b) −f(a)
b −a
= f ′(x0).
(6.9)
Every such point x0 we shall call Lagrange point for f in (a, b).
Proof.
Introduce an auxiliary map
g(x) = f(x) −f(b) −f(a)
b −a
(x −a)
deﬁned on [a, b]. It is continuous on [a, b] and diﬀerentiable on (a, b), as
diﬀerence of f and an aﬃne map, which is diﬀerentiable on all of R. Note
g′(x) = f ′(x) −f(b) −f(a)
b −a
.
It is easily seen that
g(a) = f(a),
g(b) = f(a),
so Rolle’s Theorem applies to g, with the consequence that there is a point
x0 ∈(a, b) satisfying
g′(x0) = f ′(x0) −f(b) −f(a)
b −a
= 0.
But this is exactly (6.9).
2
a
b
x0
f(a)
f(b)
Figure 6.6. Lagrange point for f in (a, b)

6.5 Theorems of Rolle, Lagrange, and Cauchy
185
The meaning of the Mean Value Theorem is clariﬁed in Fig. 6.6. At each Lag-
range point, the tangent to the graph of f is parallel to the secant line passing
through the points

a, f(a)

and

b, f(b)

.
Example 6.24
Consider f(x) = 1 + x +
√
1 −x2, a continuous map on its domain [−1, 1] as
composite of elementary continuous functions. It is also diﬀerentiable on the
open interval (−1, 1) (not at the end-points), in fact
f ′(x) = 1 −
x
√
1 −x2 .
Thus f fulﬁlls the Mean Value Theorem’s hypotheses, and must admit a Lag-
range point in (−1, 1). Now (6.9) becomes
1 = f(1) −f(−1)
1 −(−1)
= f ′(x0) = 1 −
x0

1 −x2
0
,
satisﬁed by x0 = 0.
2
The following result is a generalisation of the Mean Value Theorem 6.23 (which
is recovered by g(x) = x in its statement). It will be useful during the proofs
of de l’Hˆopital’s Theorem 6.41 and Taylor’s formula with Lagrange’s remainder
(Theorem 7.2).
Theorem 6.25 (Cauchy) Let f and g be maps deﬁned on the closed,
bounded interval [a, b], continuous on [a, b] and diﬀerentiable (at least) on
(a, b). Suppose g′(x) ̸= 0 for all x ∈(a, b). Then there exists x0 ∈(a, b) such
that
f(b) −f(a)
g(b) −g(a) = f ′(x0)
g′(x0) .
(6.10)
Proof.
Note ﬁrst that g(a) ̸= g(b), otherwise Rolle’s Theorem would have g′(x)
vanish somewhere in (a, b), against the assumption.
Take the function
h(x) = f(x) −f(b) −f(a)
g(b) −g(a) (g(x) −g(a))
deﬁned on [a, b]. It is continuous on [a, b] and diﬀerentiable on the open
interval (a, b), because diﬀerence of maps with those properties. Moreover
h′(x) = f ′(x) −f(b) −f(a)
g(b) −g(a) g′(x).
As
h(a) = f(a),
h(b) = f(a) ,

186
6 Diﬀerential calculus
the map h satisﬁes Rolle’s Theorem, so there must be a point x0 ∈(a, b)
with
h′(x0) = f ′(x0) −f(b) −f(a)
g(b) −g(a) g′(x0) = 0,
which is exactly (6.10).
2
6.6 First and second ﬁnite increment formulas
We shall discuss a couple of useful relations to represent how a function varies
when passing from one point to another of its domain.
Let us begin by assuming f is diﬀerentiable at x0. By deﬁnition
lim
x→x0
f(x) −f(x0)
x −x0
= f ′(x0),
that is to say
lim
x→x0
f(x) −f(x0)
x −x0
−f ′(x0)

= lim
x→x0
f(x) −f(x0) −f ′(x0)(x −x0)
x −x0
= 0.
Using the Landau symbols of Sect. 5.1, this becomes
f(x) −f(x0) −f ′(x0)(x −x0) = o(x −x0),
x →x0.
An equivalent formulation is
f(x) −f(x0) = f ′(x0)(x −x0) + o(x −x0),
x →x0,
(6.11)
or
Δf = f ′(x0)Δx + o(Δx),
Δx →0,
(6.12)
by putting Δx = x −x0 and Δf = f(x) −f(x0).
Equations (6.11)-(6.12) are equivalent writings of what we call the ﬁrst formula
of the ﬁnite increment, the geometric interpretation of which can be found in
Fig. 6.7. It tells that if f ′(x0) ̸= 0, the increment Δf, corresponding to a change
Δx, is proportional to Δx itself, if one disregards an inﬁnitesimal which is negligible
with respect to Δx. For Δx small enough, in practice, Δf can be treated as
f ′(x0)Δx.
Now take f continuous on an interval I of R and diﬀerentiable on the interior
points. Fix x1 < x2 in I and note that f is continuous on [x1, x2] and diﬀerentiable
on (x1, x2). Therefore f, restricted to [x1, x2], satisﬁes the Mean Value Theorem,
so there is ¯x ∈(x1, x2) such that
f(x2) −f(x1)
x2 −x1
= f ′(¯x),

6.6 First and second ﬁnite increment formulas
187
x0
f(x0)
x0 + Δx
f(x0 + Δx)
Δx
Δf
o(Δx)
f ′(x0)Δx
y = f(x)
y = t(x)
Figure 6.7. First formula of the ﬁnite increment
that is, a point ¯x ∈(x1, x2) with
f(x2) −f(x1) = f ′(¯x)(x2 −x1).
(6.13)
We shall refer to this relation as the second formula of the ﬁnite increment.
It has to be noted that the point ¯x depends upon the choice of x1 and x2, albeit
this dependency is in general not explicit. The formula’s relevance derives from
the possibility of gaining information about the increment f(x2) −f(x1) from the
behaviour of f ′ on the interval [x1, x2].
The second formula of the ﬁnite increment may be used to describe the local
behaviour of a map in the neighbourhood of a certain x0 with more precision than
that permitted by the ﬁrst formula. Suppose f is continuous at x0 and diﬀerentiable
around x0 except possibly at the point itself. If x is a point in the neighbourhood
of x0, (6.13) can be applied to the interval bounded by x0 and x, to the eﬀect that
Δf = f ′(¯x)Δx,
(6.14)
where ¯x lies between x0 and x. This alternative formulation of (6.13) expresses the
increment of the dependent variable Δf as if it were a multiple of Δx; at closer
look though, one realises that the proportionality coeﬃcient, i.e., the derivative
evaluated at a point near x0, depends upon Δx (and on x0), besides being usually
not known.
A further application of (6.13) is described in the next result. This will be
useful later.

188
6 Diﬀerential calculus
Property 6.26 A function deﬁned on a real interval I and everywhere diﬀer-
entiable is constant on I if and only if its ﬁrst derivative vanishes identically.
Proof.
Let f be the map. Suppose ﬁrst f is constant, therefore for every x0 ∈I,
the diﬀerence quotient f(x) −f(x0)
x −x0
, with x ∈I, x ̸= x0, is zero. Then
f ′(x0) = 0 by deﬁnition of derivative.
Vice versa, suppose f has zero derivative on I and let us prove that f is
constant on I. This would be equivalent to demanding
f(x1) = f(x2),
∀x1, x2 ∈I.
Take x1, x2 ∈I and use formula (6.13) on f. For a suitable ¯x between
x1, x2, we have
f(x2) −f(x1) = f ′(¯x)(x2 −x1) = 0,
thus f(x1) = f(x2).
2
6.7 Monotone maps
In the light of the results on diﬀerentiability, we tackle the issue of monotonicity.
Theorem 6.27 Let I be an interval upon which the map f is diﬀerentiable.
Then:
a) If f is increasing on I, then f ′(x) ≥0 for all x ∈I.
b1) If f ′(x) ≥0 for any x ∈I, then f is increasing on I;
b2) if f ′(x) > 0 for all x ∈I, then f is strictly increasing on I.
Proof.
Let us prove claim a). Suppose f increasing on I and consider an interior
point x0 of I. For all x ∈I such that x < x0, we have
f(x) −f(x0) ≤0
and
x −x0 < 0.
Thus, the diﬀerence quotient Δf
Δx between x0 and x is non-negative. On
the other hand, for any x ∈I with x > x0,
f(x) −f(x0) ≥0
and
x −x0 > 0.
Here too the diﬀerence quotient Δf
Δx between x0 and x is positive or zero.
Altogether,

6.7 Monotone maps
189
¯x
x1
x2
f(x1)
f(x2)
Figure 6.8. Proof of Theorem 6.27, b)
Δf
Δx = f(x) −f(x0)
x −x0
≥0,
∀x ̸= x0;
Corollary 4.3 on
lim
x→x0
Δf
Δx = f ′(x0)
yields f ′(x0) ≥0. As for the possible extremum points in I, we arrive
at the same conclusion by considering one-sided limits of the diﬀerence
quotient, which is always ≥0.
Now to the implications in parts b). Take f with f ′(x) ≥0 for all x ∈I.
The idea is to ﬁx points x1 < x2 in I and prove that f(x1) ≤f(x2).
For that we use (6.13) and note that f ′(¯x) ≥0 by assumption. But since
x2 −x1 > 0, we have
f(x2) −f(x1) = f ′(¯x)(x2 −x1) ≥0,
proving b1). Considering f such that f ′(x) > 0 for all x ∈I instead, (6.13)
implies f(x2) −f(x1) > 0, hence also b2) holds.
2
The theorem asserts that if f is diﬀerentiable on I, the following logic equival-
ence holds:
f ′(x) ≥0,
∀x ∈I
⇐⇒
f is increasing on I.
Furthermore,
f ′(x) > 0,
∀x ∈I
=⇒
f is strictly increasing on I.
The latter implication is not reversible: f strictly increasing on I does not imply
f ′(x) > 0 for all x ∈I. We have elsewhere observed that f(x) = x3 is everywhere
strictly increasing, despite having vanishing derivative at the origin.
A similar statement to the above holds if we change the word ‘increasing’ with
‘decreasing’ and the symbols ≥, > with ≤, <.

190
6 Diﬀerential calculus
Corollary 6.28 Let f be diﬀerentiable on I and x0 an interior critical point.
If f ′(x) ≥0 at the left of x0 and f ′(x) ≤0 at its right, then x0 is a maximum
point for f. Similarly, f ′(x) ≤0 at the left, and ≥0 at the right of x0 implies
x0 is a minimum point.
Theorem 6.27 and Corollary 6.28 justify the search for extrema among the
zeroes of f ′, and explain why the derivative’s sign aﬀects monotonicity intervals.
Example 6.29
The map f : R →R, f(x) = xe2x diﬀerentiates to f ′(x) = (2x + 1)e2x, whence
x0 = −1
2 is the sole critical point. As f ′(x) > 0 if and only if x > −1
2, f(x0) is an
absolute minimum. The function is strictly decreasing on (−∞, −1
2] and strictly
increasing on [−1
2, +∞).
2
6.8 Higher-order derivatives
Let f be diﬀerentiable around x0 and let its ﬁrst derivative f ′ be also deﬁned
around x0.
Deﬁnition 6.30 If f ′ is a diﬀerentiable function at x0, one says f is twice
diﬀerentiable at x0. The expression
f ′′(x0) = (f ′)′(x0)
is called second derivative of f at x0. The second derivative of f,
denoted f ′′, is the map associating to x the number f ′′(x), provided the latter
is deﬁned.
Other notations commonly used for the second derivative include
y′′(x0),
d2f
dx2 (x0),
D2f(x0) .
The third derivative, where deﬁned, is the derivative of the second derivative:
f ′′′(x0) = (f ′′)′(x0) .
In general, for any k ≥1, the derivative of order k (kth derivative) of f at
x0 is the ﬁrst derivative, where deﬁned, of the derivative of order (k −1) of f at
x0:
f (k)(x0) = (f (k−1))′(x0) .

6.8 Higher-order derivatives
191
Alternative symbols are:
y(k)(x0),
dkf
dxk (x0),
Dkf(x0) .
For conveniency one deﬁnes f (0)(x0) = f(x0) as well.
Examples 6.31
We compute the derivatives of all orders for three elementary functions.
i) Choose n ∈N and consider f(x) = xn. Then
f ′(x) = nxn−1 =
n!
(n −1)!xn−1
f ′′(x) = n(n −1)xn−2 =
n!
(n −2)!xn−2
...
...
f (n)(x) = n(n −1) · · · 2 · 1 xn−n = n! .
More concisely,
f (k)(x) =
n!
(n −k)!xn−k
with 0 ≤k ≤n. Furthermore, f (n+1)(x) = 0 for any x ∈R (the derivative of
the constant function f (n)(x) is 0), and consequently all derivatives f (k) of order
k > n exist and vanish identically.
ii) The sine function f(x) = sin x satisﬁes f ′(x) = cos x, f ′′(x) = −sin x,
f ′′′(x) = −cosx and f (4)(x) = sin x. Successive derivatives of f clearly re-
produce this cyclical pattern. The same phenomenon occurs for y = cos x.
iii) Because f(x) = ex diﬀerentiates to f ′(x) = ex, it follows that f (k)(x) = ex
for every k ≥0, proving the remarkable fact that all higher-order derivatives of
the exponential function are equal to ex.
2
A couple of deﬁnitions wrap up the section.
Deﬁnition 6.32 A map f is of class
Ck (k ≥0) on an interval I if f is
diﬀerentiable k times everywhere on I and its kth derivative f (k) is continuous
on I. The collection of all Ck maps on I is denoted by Ck(I).
A map f is of class C∞on I if it is arbitrarily diﬀerentiable everywhere on
I. One indicates by C∞(I) the collection of such maps.
In virtue of Proposition 6.3, if f ∈Ck(I) all derivatives of order smaller or
equal than k are continuous on I. Similarly, if f ∈C∞(I), all its derivatives are
continuous on I.
Moreover, the elementary functions are diﬀerentiable any number of times (so
they are of class C∞) at every interior point of their domains.

192
6 Diﬀerential calculus
6.9 Convexity and inﬂection points
Let f be diﬀerentiable at the point x0 of the domain. As customary, we indicate
by y = t(x) = f(x0) + f ′(x0)(x −x0) the equation of the tangent to the graph of
f at x0.
Deﬁnition 6.33 The map f is convex at x0 if there is a neighbourhood
Ir(x0) ⊆dom f such that
∀x ∈Ir(x0),
f(x) ≥t(x);
f is strictly convex if f(x) > t(x), ∀x ̸= x0.
The deﬁnitions for concave and strictly concave functions are alike (just change
≥, > to ≤, <).
What does this say geometrically? A map is convex at a point if around that
point the graph lies ‘above’ the tangent line, concave if its graph is ‘below’ the
tangent (Fig. 6.9).
Example 6.34
We claim that f(x) = x2 is strictly convex at x0 = 1. The tangent at the given
point has equation
t(x) = 1 + 2(x −1) = 2x −1 .
Since f(x) > t(x) means x2 > 2x −1, hence x2 −2x + 1 = (x −1)2 > 0, t lies
below the graph except at the touching point x = 1.
2
Deﬁnition 6.35 A diﬀerentiable map f on an interval I is convex on I if
it is convex at each point of I.
For understanding convexity, inﬂection points play a role reminiscent of ex-
tremum points for the study of monotone functions.
x0
y = f(x)
y = t(x)
x0
y = f(x)
y = t(x)
Figure 6.9. Strictly convex (left) and strictly concave (right) maps at x0

6.9 Convexity and inﬂection points
193
Deﬁnition 6.36 The point x0 is an inﬂection point for f if there is a
neighbourhood Ir(x0) ⊆dom f where one of the following conditions holds:
either
∀x ∈Ir(x0),
 if x < x0,
f(x) ≤t(x),
if x > x0,
f(x) ≥t(x),
or
∀x ∈Ir(x0),
 if x < x0,
f(x) ≥t(x),
if x > x0,
f(x) ≤t(x)
In the former case we speak of an ascending inﬂection, in the latter the
inﬂection is descending.
In the plane, the graph of f ‘cuts through’ the inﬂectional tangent at an in-
ﬂection point (Fig. 6.10).
The analysis of convexity and inﬂections of a function is helped a great deal
by the next results.
Theorem 6.37 Given a diﬀerentiable map f on the interval I,
a) if f is convex on I, then f ′ is increasing on I.
b1) If f ′ is increasing on I, then f is convex on I;
b2) if f ′ is strictly increasing on I, then f is strictly convex on I.
Proof.
See Appendix A.4.3, p. 455.
2
x0
y = f(x)
y = t(x)
x0
y = f(x)
y = t(x)
Figure 6.10. Ascending (left) and descending (right) inﬂections at x0

194
6 Diﬀerential calculus
Corollary 6.38 If f is diﬀerentiable twice on I, then
a) f convex on I implies f ′′(x) ≥0 for all x ∈I.
b1) f ′′(x) ≥0 for all x ∈I implies f convex on I;
b2) f ′′(x) > 0 for all x ∈I implies f strictly convex on I.
Proof.
This follows directly from Theorem 6.37 by applying Theorem 6.27 to the
function f ′.
2
There is a second formulation for this, namely: under the same hypothesis, the
following formulas are true:
f ′′(x) ≥0,
∀x ∈I
⇐⇒
f is convex on I
and
f ′′(x) > 0,
∀x ∈I
=⇒
f is strictly convex on I.
Here, as in the characterisation of monotone functions, the last implication has no
reverse. For instance, f(x) = x4 is strictly convex on R, but has vanishing second
derivative at the origin.
Analogies clearly exist concerning concave functions.
Corollary 6.39 Let f be twice diﬀerentiable around x0.
a) If x0 is an inﬂection point, then f ′′(x0) = 0.
b) Assume f ′′(x0) = 0. If f ′′ changes sign when crossing x0, then x0 is an
inﬂection point (ascending if f ′′(x) ≤0 at the left of x0 and f ′′(x) ≥0 at
its right, descending otherwise). If f ′′ does not change sign, x0 is not an
inﬂection point.
The proof relies on Taylor’s formula, and will be given in Sect. 7.4.
The reader ought to beware that f ′′(x0) = 0 does not warrant x0 is a point
of inﬂection for f. The function f(x) = x4 has second derivative f ′′(x) = 12x2
which vanishes at x0 = 0. The origin is nonetheless not an inﬂection point, for
the tangent at x0 is the axis y = 0, and the graph of f stays always above it. In
addition, f ′′ does not change sign around x0.
Example 6.29 (continuation)
For f(x) = xe2x we have f ′′(x) = 4(x+1)e2x vanishing at x1 = −1. As f ′′(x) > 0
if and only if x > −1, f is strictly concave on (−∞, −1) and strictly convex on
(−1, +∞). The point x1 = −1 is an ascending inﬂection. The graph of f(x) is
shown in Fig. 6.11.
2

6.9 Convexity and inﬂection points
195
x0
x1
Figure 6.11. Example 6.29
6.9.1 Extension of the notion of convexity
The geometrical nature of convex maps manifests itself by considering a gener-
alisation of the notion given in Sect. 6.9. Recall a subset C of the plane is said
convex if the segment P1P2 between any two points P1, P2 ∈C is all contained
in C.
Given a function f : I ⊆R →R, we denote by
Ef = {(x, y) ∈R2 : x ∈I, y ≥f(x)}
the set of points of the plane lying above the graph of f (as in Fig. 6.12, left).
Deﬁnition 6.40 The map f : I ⊆R →R is called convex on I if the set
Ef is a convex subset of the plane.
It is easy to convince oneself that the convexity of Ef can be checked by
considering points P1, P2 belonging to the graph of f only. In other words, given
x
y
a
b
y = f(x)
x
y
y = |x|
Figure 6.12. The set Ef for a generic f deﬁned on I (left) and for f(x) = |x| (right)

196
6 Diﬀerential calculus
x1, x2 in I, the segment S12 between (x1, f(x1)) and (x2, f(x2) should lie above
the graph.
Since one can easily check that any x between x1 and x2 can be represented as
x = (1 −t)x1 + tx2
with
t = x −x1
x2 −x1
∈[0, 1] ,
the convexity of f reads
f

(1 −t)x1 + tx2

≤(1 −t)f(x1) + tf(x2)
∀x1, x2 ∈I , ∀t ∈[0, 1] .
If the inequality is strict for x1 ̸= x2 and t ∈(0, 1), the function is called strictly
convex on I.
For diﬀerentiable functions on the interval I, Deﬁnitions 6.40, 6.33 can be
proven to be equivalent. But a function may well be convex according to Deﬁn-
ition 6.40 without being diﬀerentiable on I, like f(x) = |x| on I = R (Fig. 6.12,
right). Note, however, that convexity implies continuity at all interior points of I,
although discontinuities may occur at the end-points.
6.10 Qualitative study of a function
We have hitherto supplied the reader with several analytical tools to study a
map f on its domain and draw a relatively thorough – qualitatively speaking –
graph. This section describes a step-by-step procedure for putting together all the
information acquired.
Domain and symmetries
It should be possible to determine the domain of a generic function starting from
the elementary functions that build it via algebraic operations and composition.
The study is greatly simpliﬁed if one detects the map’s possible symmetries and
periodicity at the very beginning (see Sect. 2.6). For instance, an even or odd map
can be studied only for positive values of the variable. We point out that a function
might present diﬀerent kinds of symmetries, like the symmetry with respect to a
vertical line other than the y-axis: the graph of f(x) = e−|x−2| is symmetric with
respect to x = 2 (Fig. 6.13).
For the same reason the behaviour of a periodic function is captured by its
restriction to an interval as wide as the period.
Behaviour at the end-points of the domain
Assuming the domain is a union of intervals, as often happens, one should ﬁnd the
one-sided limits at the end-points of each interval. Then the existence of asymp-
totes should be discussed, as in Sect. 5.3.
For instance, consider
f(x) = log(2 −x)
√
x2 −2x .

6.10 Qualitative study of a function
197
1
2
Figure 6.13. The function f(x) = e−|x−2|
Now, log(2 −x) is deﬁned for 2 −x > 0, or x < 2; in addition,
√
x2 −2x has
domain x2 −2x ≥0, so x ≤0 or x ≥2, and being a denominator, x ̸= 0, 2.
Thus dom f = (−∞, 0). Since
lim
x→0−f(x) = +∞, the line x = 0 is a vertical left
asymptote, while
lim
x→−∞f(x) =
lim
x→−∞
log(2 −x)
|x|
= 0 yields the horizontal left
asymptote y = 0.
Monotonicity and extrema
The ﬁrst step consists in computing the derivative f ′ and its domain dom f ′. Even
if the derivative’s analytical expression might be deﬁned on a larger interval, one
should in any case have dom f ′ ⊆dom f. For example f(x) = log x has f ′(x) = 1
x
and dom f = dom f ′ = (0, +∞), despite g(x) =
1
x makes sense for any x ̸= 0.
After that, the zeroes and sign of f ′ should be determined. They allow to ﬁnd the
intervals where f is monotone and discuss the nature of critical points (the zeroes
of f ′), in the light of Sect. 6.7.
A careless analysis might result in wrong conclusions. Suppose a map f is
diﬀerentiable on the union (a, b) ∪(b, c) of two bordering intervals where f ′ > 0.
If f is not diﬀerentiable at the point b, deducing from that that f is increasing
on (a, b) ∪(b, c) is wrong. The function f(x) = −1
x satisﬁes f ′(x) =
1
x2 > 0 on
(−∞, 0) ∪(0, +∞), but it is not globally increasing therein (e.g. f(−1) > f(1));
we can only say f is increasing on (−∞, 0) and on (0, +∞) separately.
Recall that extremum points need not only be critical points. The function
f(x) =

x
1 + x2 , deﬁned on x ≥0, has a critical point x = 1 giving an abso-
lute maximum. At the other extremum x = 0, the function is not diﬀerentiable,
although f(0) is the absolute minimum.
Convexity and inﬂection points
Along the same lines one determines the intervals upon which the function is
convex or concave, and its inﬂections. As in Sect. 6.9, we use the second derivative
for this.
Sign of the function and its higher derivatives
When sketching the graph of f we might ﬁnd useful (not compulsory) to establish
the sign of f and its vanishing points (the x-coordinates of the intersections of the

198
6 Diﬀerential calculus
graph with the horizontal axis). The roots of f(x) = 0 are not always easy to ﬁnd
analytically. In such cases one may resort to the Theorem of existence of zeroes
4.23, and deduce the presence of a unique zero within a certain interval. Likewise
can be done for the sign of the ﬁrst or second derivatives.
The function f(x) = x log x −1 is deﬁned for x > 0. One has f(x) < 0 when
x ≤1. On x ≥1 the map is strictly increasing (in fact f ′(x) = log x + 1 > 0 for
x > 1/e); besides, f(1) = −1 < 0 and f(e) = e −1 > 0. Therefore there is exactly
one zero somewhere in (1, e), f is negative to the left of said zero and positive to
the right.
6.10.1 Hyperbolic functions
An exemplary application of what seen so far is the study of a family of functions,
called hyperbolic, that show up in various concrete situations.
We introduce the maps f(x) = sinh x and g(x) = cosh x by
sinh x = ex −e−x
2
and
cosh x = ex + e−x
2
.
They are respectively called hyperbolic sine and hyperbolic cosine. The ter-
minology stems from the fundamental relation
cosh2 x −sinh2 x = 1 ,
∀x ∈R ,
whence the point P of coordinates (X, Y ) = (cosh x, sinh x) runs along the right
branch of the rectangular hyperbola X2 −Y 2 = 1 as x varies.
The ﬁrst observation is that dom f = dom g = R; moreover, f(x) = −f(−x)
and g(x) = g(−x), hence the hyperbolic sine is an odd map, whereas the hyperbolic
cosine is even. Concerning the limit behaviour,
lim
x→±∞sinh x = ±∞,
lim
x→±∞cosh x = +∞.
This implies that there are no vertical nor horizontal asymptotes. No oblique
asymptotes exist either, because these functions behave like exponentials for x →
∞. More precisely
sinh x ∼±1
2e|x| ,
cosh x ∼1
2e|x| ,
x →±∞.
It is clear that sinh x = 0 if and only if x = 0, sinh x > 0 when x > 0, while
cosh x > 0 everywhere on R. The monotonic features follow easily from
D sinh x = cosh x
and
D cosh x = sinh x ,
∀x ∈R .
Thus the hyperbolic sine is increasing on the entire R. The hyperbolic cosine is
strictly increasing on [0, +∞) and strictly decreasing on (−∞, 0], has an absolute
minimum cosh 0 = 1 at x = 0 (so cosh x ≥1 on R).

6.10 Qualitative study of a function
199
1
1
Figure 6.14. Hyperbolic sine (left) and hyperbolic cosine (right)
Diﬀerentiating once more gives
D2 sinh x = sinh x
and
D2 cosh x = cosh x ,
∀x ∈R ,
which says that the hyperbolic sine is strictly convex on (0, +∞) and strictly
concave on (−∞, 0). The origin is an ascending inﬂection point. The hyperbolic
cosine is strictly convex on the whole R. The graphs are drawn in Fig. 6.14.
In analogy to the ordinary trigonometric functions, there is a hyperbolic
tangent deﬁned as
tanh x = sinh x
cosh x = e2x −1
e2x + 1 .
Its domain is R, it is odd, strictly increasing and ranges over the open interval
(−1, 1) (Fig. 6.15).
The inverse map to the hyperbolic sine, appropriately called inverse hyper-
bolic sine, is deﬁned on all of R, and can be made explicit by means of the
logarithm (inverse of the exponential)
sinh−1 x = log(x +

x2 + 1) ,
x ∈R .
(6.15)
1
−1
Figure 6.15. Hyperbolic tangent

200
6 Diﬀerential calculus
There normally is no confusion with the reciprocal 1/ sinh x, whence the use of
notation1. The inverse hyperbolic cosine is obtained by inversion of the hyper-
bolic cosine restricted to [0, +∞)
cosh−1 x = log(x +

x2 −1) ,
x ∈[1, +∞) .
(6.16)
To conclude, the inverse hyperbolic tangent inverts the corresponding hyper-
bolic map on R
tanh−1 x = 1
2 log 1 + x
1 −x ,
x ∈(−1, 1) .
(6.17)
The inverse hyperbolic functions have ﬁrst derivatives
D sinh−1 x =
1
√
x2 + 1 ,
D cosh−1 x =
1
√
x2 −1 ,
D tanh−1 x =
1
1 −x2 .
(6.18)
6.11 The Theorem of de l’Hˆopital
This ﬁnal section is entirely devoted to a single result, due to its relevance in com-
puting the limits of indeterminate forms. Its proof can be found in Appendix A.4.2,
p. 452. As always, c is one of x0, x+
0 , x−
0 , +∞, −∞.
Theorem 6.41 Let f, g be maps deﬁned on a neighbourhood of c, except
possibly at c, and such that
lim
x→c f(x) = lim
x→c g(x) = L,
where L = 0, +∞or −∞. If f and g are diﬀerentiable around c, except
possibly at c, with g′ ̸= 0, and if
lim
x→c
f ′(x)
g′(x)
exists (ﬁnite or not), then also
lim
x→c
f(x)
g(x)
(6.19)
exists and equals the previous limit.
1 Some authors also like the symbol Arc sinh.

6.11 The Theorem of de l’Hˆopital
201
Under said hypotheses the results states that
lim
x→c
f(x)
g(x) = lim
x→c
f ′(x)
g′(x) .
(6.20)
Examples 6.42
i) The limit
lim
x→0
e2x −e−2x
sin 5x
gives rise to an indeterminate form of type 0
0. Since numerator and denominator
are diﬀerentiable functions,
lim
x→0
2e2x + 2e−2x
5 cos 5x
= 4
5.
Therefore
lim
x→0
e2x −e−2x
sin 5x
= 4
5.
ii) When the ratio f ′(x)/g′(x) is still an indeterminate form, supposing f and g
are twice diﬀerentiable around c, except maybe at c, we can iterate the recipe of
(6.20) by studying the limit of f ′′(x)/g′′(x), and so on.
Consider for instance the indeterminate form 0/0
lim
x→0
1 + 3x −

(1 + 2x)3
x sin x
.
Diﬀerentiating numerator and denominator, we are lead to
lim
x→0
3 −3√1 + 2x
sin x + x cos x,
still of the form 0/0. Thus we diﬀerentiate again
lim
x→0
−
3
√1+2x
2 cosx −x sin x = −3
2.
Applying (6.20) twice allows to conclude
lim
x→0
1 + 3x −

(1 + 2x)3
sin2 x
= −3
2.
2
Remark 6.43 De l’Hˆopital’s Theorem is a suﬃcient condition only, for the exist-
ence of (6.19). Otherwise said, it might happen that the limit of the derivatives’
diﬀerence quotient does not exist, whereas we have the limit of the functions’ dif-
ference quotient. For example, set f(x) = x + sin x and g(x) = 2x + cos x. While
the ratio f ′/g′ does not admit limit as x →+∞(see Remark 4.19), the limit of
f/g exists:
lim
x→+∞
x + sin x
2x + cos x =
lim
x→+∞
x + o(x)
2x + o(x) = 1
2.
2

202
6 Diﬀerential calculus
6.11.1 Applications of de l’Hˆopital’s theorem
We survey some situations where the result of de l’Hˆopital lends a helping hand.
Fundamental limits
By means of Theorem 6.41 we recover the important limits
lim
x→+∞
ex
xα = +∞,
lim
x→−∞|x|αex = 0,
∀α ∈R,
(6.21)
lim
x→+∞
log x
xα
= 0,
lim
x→0+ xα log x = 0,
∀α > 0.
(6.22)
These were presented in (5.6) in the equivalent formulation of the Landau symbols.
Let us begin with the ﬁrst of (6.21) when α = 1. From (6.20)
lim
x→+∞
ex
x =
lim
x→+∞
ex
1 = +∞.
For any other α > 0, we have
lim
x→+∞
ex
xα =
lim
x→+∞
 1
α
e
x
α
x
α
α
= 1
αα

lim
y→+∞
ey
y
α
= +∞.
At last, for α ≤0 the result is rather trivial because there is no indeterminacy. As
for the second formula of (6.21)
lim
x→−∞|x|αex =
lim
x→−∞
|x|α
e−x =
lim
x→−∞
|x|α
e|x| =
lim
y→+∞
yα
ey = 0.
Now to (6.22):
lim
x→+∞
log x
xα
=
lim
x→+∞
1
x
αxα−1 = 1
α
lim
x→+∞
1
xα = 0
and
lim
x→0+ xα log x = lim
x→0+
log x
x−α = lim
x→0+
1
x
(−α)x−α−1 = −1
α lim
x→0+ xα = 0.
Proof of Theorem 6.15
We are now in a position to prove this earlier claim.
Proof.
By deﬁnition only,
f ′(x0) = lim
x→x0
f(x) −f(x0)
x −x0
;
but this is an indeterminate form, since
lim
x→x0

f(x) −f(x0)

= lim
x→x0(x −x0) = 0,
hence de l’Hˆopital implies
f ′(x0) = lim
x→x0
f ′(x)
1
.
2

6.12 Exercises
203
Computing the order of magnitude of a map
Through examples we explain how de l’Hˆopital’s result detects the order of mag-
nitude of inﬁnitesimal or inﬁnite functions, and their principal parts.
The function
f(x) = ex −1 −sin x
is inﬁnitesimal for x →0. With inﬁnitesimal test function ϕ(x) = x we apply the
theorem twice (supposing for a moment this is possible)
lim
x→0
ex −1 −sin x
xα
= lim
x→0
ex −cos x
αxα−1
= lim
x→0
ex + sin x
α(α −1)xα−2 .
When α = 2 the right-most limit exists and is in fact 1
2. This fact alone justiﬁes the
use of de l’Hˆopital’s Theorem. Thus f(x) is inﬁnitesimal of order 2 at the origin
with respect to ϕ(x) = x; its principal part is p(x) = 1
2x2.
Next, consider
f(x) = tan x,
an inﬁnite function for x →π
2
−. Setting ϕ(x) =
1
π
2 −x, we have
lim
x→π
2
−
tan x

1
π
2 −x
α =
lim
x→π
2
−sin x
lim
x→π
2
−
 π
2 −x
α
cos x
.
While the ﬁrst limit is 1, for the second we apply de l’Hˆopital’s Theorem
lim
x→π
2
−
 π
2 −x
α
cos x
=
lim
x→π
2
−
−α( π
2 −x)α−1
−sin x
.
The latter equals 1 when α = 1, so tan x is inﬁnite of ﬁrst order, for x →π
2
−, with
respect to ϕ(x) =
1
π
2 −x. The principal part is indeed ϕ(x).
6.12 Exercises
1. Discuss diﬀerentiability at the point x0 indicated:
a)
f(x) = x + |x −1| ,
x0 = 1
b)
f(x) = sin |x| ,
x0 = 0
c)
f(x) =

e−1/x2
x ̸= 0
0
x = 0
,
x0 = 0
d)
f(x) =

1 + x3 ,
x0 = −1

204
6 Diﬀerential calculus
2. Say where the following maps are diﬀerentiable and ﬁnd the derivatives:
a)
f(x) = x

|x|
b)
f(x) = cos |x|
c)
f(x) =

x2 + 1
if x ≥0,
ex −x
if x < 0
d)
f(x) =

x2 + x −5
if x ≥1,
x −4
if x < 1
3. Compute, where deﬁned, the ﬁrst derivative of:
a) f(x) = 3x
3
1 + x2
b) f(x) = log | sin x|
c) f(x) = cos

ex2+1
d) f(x) =
1
x log x
4. On the given interval, ﬁnd maximum and minimum of:
a)
f(x) = sin x + cos x ,
[0, 2π]
b)
f(x) = x2 −|x + 1| −2 ,
[−2, 1]
5. Write the equation of the tangent at x0 to the graph of the following maps:
a)
f(x) = log(3x −2) ,
x0 = 2
b) f(x) =
x
1 + x2 ,
x0 = 1
c)
f(x) = e
√2x+1 ,
x0 = 0
d) f(x) = sin 1
x ,
x0 = 1
π
6.
Verify that f(x) = 5x + x3 + 2x5 is invertible on R, f −1 is diﬀerentiable on
the same set, and compute (f −1)′(0) and (f −1)′(8).
7.
Prove that f(x) = (x −1)ex2 + arctan(log x) + 2 is invertible on its domain
and ﬁnd the range.
8.
Verify that f(x) = log(2 + x) + 2x + 1
x + 2 has no zeroes apart from x0 = −1.
9.
Determine the number of zeroes and critical points of
f(x) = x log x −1
x2
.
10.
Discuss relative and absolute minima of the map
f(x) = 2 sin x + 1
2 cos 2x
on [0, 2π].

6.12 Exercises
205
11.
Find the largest interval containing x0 = 1
2 on which the function
f(x) = log x −
1
log x
has an inverse, which is also explicitly required. Calculate the derivative of the
inverse at the origin.
12.
Verify that
log(1 + x) ≤x ,
∀x > −1 .
13.
Sketch a graph for f(x) = 3x5−50x3+135x. Then ﬁnd the largest and smallest
possible numbers of real roots of f(x) + k, as k varies in the reals.
14.
Consider f(x) = x4 −2√log x and
a) ﬁnd its domain;
b) discuss monotonicity;
c) prove the point (e4 −2, e) belongs to the graph of f −1, then compute the
derivative of f −1 at e4 −2.
15.
Regarding
f(x) =
√
x2 −3
x + 1 ,
a) ﬁnd domain, limits at the domain’s boundary and possible asymptotes;
b) study the intervals of monotonicity, the maximum and minimum points,
specifying which are relative, which absolute;
c) sketch a graph;
d) deﬁne
g(x) =

f(x +
√
3)
if x ≥0 ,
f(x −
√
3)
if x < 0 .
Relying on the results found for f draw a picture of g, and study its
continuity and diﬀerentiability at the origin.
16.
Given
f(x) =

|x2 −4| −x,
a) ﬁnd domain, limits at the domain’s boundary and asymptotes;
b) determine the sign of f;
c) study the intervals of monotonicity and list the extrema;
d) detect the points of discontinuity and of non-diﬀerentiability;
e) sketch the graph of f.
17.
Consider
f(x) =
3
e2x −1.

206
6 Diﬀerential calculus
a) What does f(x) do at the boundary of the domain?
b) Where is f monotone, where not diﬀerentiable?
c) Discuss convexity and ﬁnd the inﬂection points.
d) Sketch a graph.
18.
Let
f(x) = 1 −e−|x| + x
e
be given.
a) Find domain and asymptotes, if any;
b) discuss diﬀerentiability and monotonic properties;
c) determine maxima, minima, saying whether global or local;
d) sketch the graph.
19.
Given
f(x) = ex(x2 −8|x −3| −8),
determine
a) the monotonicity;
b) the relative extrema and range im f;
c) the points where f is not continuous, or not diﬀerentiable;
d) a rough graph;
e) whether there is a real α such that
g(x) = f(x) −α|x −3|
is of class C1 over the whole real line.
20.
Given
f(x) = log |1 + x|
(1 + x)2 ,
ﬁnd
a) domain, behaviour at the boundary, asymptotes,
b) monotonicity intervals, relative or absolute maxima and minima,
c) convexity and inﬂection points,
d) and sketch a graph.
21.
Let
f(x) =
x log |x|
1 + log2 |x|.
a) Prove f can be prolonged with continuity to R and discuss the diﬀerenti-
ability of the prolongation g;
b) determine the number of stationary points g has;
c) draw a picture for g that takes monotonicity and asymptotes into account.

6.12 Exercises
207
22.
Determine for
f(x) = arctan |x| + 3
x −3
a) domain, limits at the boundary, asymptotes;
b) monotonicity, relative and absolute extremum points, inf f and sup f;
c) diﬀerentiability;
d) concavity and convexity;
e) a graph that highlights the previous features.
23.
Consider the map
f(x) = arcsin

2ex −e2x
and say
a) what are the domain, the boundary limits, the asymptotes of f(x);
b) at which points the function is diﬀerentiable;
c) where f is monotone, where it reaches a maximum or a minimum;
d) what the graph of f(x) looks like, using the information so far collected.
e) Deﬁne a map ˜f continuously prolonging f to the entire R.
6.12.1 Solutions
1. Diﬀerentiability:
a) Not diﬀerentiable.
b) The right and left limits of the diﬀerence quotient, for x →0, are:
lim
x→0+
sin x −0
x −0
= 1 ,
lim
x→0−
sin(−x) −0
x −0
= −1 .
Consequently, the function is not diﬀerentiable at x0 = 0.
c) For x ̸= 0 the map is diﬀerentiable and
f ′(x) = 2
x3 e−1/x2 .
Moreover
lim
x→0 f(x) = lim
x→0 f ′(x) = 0 ,
so f is continuous at x0 = 0. By
Theorem 6.15, it is also diﬀerentiable at that point.
d) Not diﬀerentiable.
2. Diﬀerentiability:
a) Because
f(x) =
 x√x
if x ≥0 ,
x√−x
if x < 0 ,

208
6 Diﬀerential calculus
f ′ is certainly diﬀerentiable at x ̸= 0 with
f ′(x) =

3
2
√x
if x > 0 ,
3
2
√−x
if x < 0 .
The map is continuous on R (composites and products preserve continuity),
hence in particular also at x = 0. Furthermore, lim
x→0+ f ′(x) = lim
x→0−f ′(x) = 0,
making f diﬀerentiable at x = 0 , with f ′(0) = 0.
b) Diﬀerentiable on R, f ′(x) = −sin x.
c) Diﬀerentiable everywhere, f ′(x) =
 2x
if x ≥0 ,
ex −1
if x < 0.
d) The map is clearly continuous for x ̸= 1; but also at x = 1, since
lim
x→1+(x2 + x −5) = f(1) = −3 = lim
x→1−(x −4).
The derivative is
f ′(x) =
 2x + 1
if x > 1 ,
1
if x < 1 ,
so f is diﬀerentiable at least on R \ {1}. Using Theorem 6.15 on the right- and
left-hand derivatives independently, gives
f ′
+(1) = lim
x→1+ f ′(x) = 3 ,
f ′
−(1) = lim
x→1−f ′(x) = 1 .
At the point x = 1, a corner, the function is not diﬀerentiable.
3. Derivatives:
a) f ′(x) =
5x2 + 3
(1 + x2)2/3
b) f ′(x) = cotan x
c) f ′(x) = −2xex2+1 sin ex2+1
d) f ′(x) = −log x + 1
x2 log2 x
4. Maxima and minima:
Both functions are continuous so the existence of maxima and minima is guaran-
teed by Weierstrass’s theorem.
a) Maximum value
√
2 at the point x =
π
4 ; minimum −
√
2 at x =
5
4π. (The
interval’s end-points are relative minimum and maximum points, not absolute.)
b) One has
f(x) =
 x2 + x −1
if x < −1 ,
x2 −x −3
if x ≥−1 .
The function coincides with the parabola y = (x + 1
2)2 −5
4 for x < −1. The
latter has vertex in (−1
2, −5
4) and is convex, so on the interval [−2, −1] of
concern it decreases; its maximum is 1 at x = −2 and minimum −1 at x = −1.

6.12 Exercises
209
1
−1
−3
−13
4
1
−1
−2
1
2
Figure 6.16. Graph of f(x) = x2 −|x + 1| −2
For x ≥−1, we have the convex parabola y = (x−1
2)2−13
4 with vertex ( 1
2, −13
4 ).
Thus on [−1, 1], there is a minimum point x =
1
2 with image f( 1
2) = −13
4 .
Besides, f(−1) = −1 and f(1) = −3, so the maximum −1 is reached at x = −1.
In conclusion, f has minimum −13
4 (for x = 1
2) and maximum 1 (at x = −2);
see Fig. 6.16.
5. Tangent lines:
a) Since
f ′(x) =
3
3x −2 ,
f(2) = log 4 ,
f ′(2) = 3
4 ,
the equation of the tangent is
y = f(2) + f ′(2)(x −2) = log 4 + 3
4(x −2) .
b) y = 1
2.
c) As
f ′(x) = e
√2x+1
√2x + 1 ,
f(0) = f ′(0) = e ,
the tangent has equation
y = f(0) + f ′(0)x = e + ex .
d) y = π2(x −1
π).
6. As sum of strictly increasing elementary functions on R, so is our function.
Therefore invertibility follows. By continuity and because
lim
x→±∞f(x) = ±∞,
Corollary 4.30 implies im f = R. The function is diﬀerentiable on the real line,
f ′(x) = 5 + 3x2 + 10x4 > 0 for all x ∈R; Theorem 6.9 tells that f −1 is diﬀerenti-
able on R. Eventually f(0) = 0 and f(1) = 8, so

210
6 Diﬀerential calculus
(f −1)′(0) =
1
f ′(0) = 1
5
and
(f −1)′(8) =
1
f ′(1) = 1
18 .
7. On the domain (0, +∞) the map is strictly increasing (as sum of strictly in-
creasing maps), hence invertible. Monotonicity follows also from the positivity of
f ′(x) = (2x2 −2x + 1)ex2 +
1
x(1 + log2 x).
In addition, f is continuous, so Corollary 4.30 ensures that the range is an interval
bounded by inf f and sup f:
inf f = lim
x→0+ f(x) = −1 −π
2 + 2 = 1 −π
2 ,
sup f =
lim
x→+∞f(x) = +∞.
Therefore im f = (1 −π
2 , +∞).
8. The map is deﬁned only for x > −2, and continuous, strictly increasing on the
whole domain as
f ′(x) =
1
x + 2 +
2
(x + 2)2 > 0 ,
∀x > −2 .
Therefore f(x) < f(1) = 0 for x < 1 and f(x) > f(1) = 0 for x > 1.
9. The domain is x > 0. The zeroes solve
x log x −1 = 0
i.e.
log x = 1
x .
If we set h(x) = log x and g(x) = 1
x, then
h(1) = 0 < 1 = g(1)
and
h(e) = 1 > 1
e = g(e) ;
Corollary 4.27 says there is an x0 ∈(1, e) such that h(x0) = g(x0). Such a point
has to be unique because h is strictly increasing and g strictly decreasing. Thus f
has only one vanishing point, conﬁned inside (1, e).
For the critical points, we compute the ﬁrst derivative:
f ′(x) = x2(log x + 1) −2x(x log x −1)
x4
= x + 2 −x log x
x3
.
The zeroes of f ′ are then the roots of
x + 2 −x log x = 0
i.e.
log x = 2 + x
x
.
Let ¯g(x) = 2+x
x
= 1 + 2
x, whence
h(e) = 1 < 1 + 2
e = ¯g(e)
and
h(e2) = 2 > 1 + 2
e2 = ¯g(e2) ;

6.12 Exercises
211
again, Corollary 4.27 indicates a unique ¯x0 ∈(e, e2) with h(¯x0) = ¯g(¯x0) (unique-
ness follows from the monotonicity of h and ¯g). In conclusion, f has precisely one
critical point, lying in (e, e2).
10. In virtue of the duplication formulas (2.13),
f ′(x) = 2 cosx −sin 2x = 2 cosx(1 −sin x).
Thus f ′(x) = 0 when x = π
2 and x = 3
2π, f ′(x) > 0 for 0 < x < π
2 or 3
2π < x < 2π.
This says x = π
2 is an absolute maximum point, where f( π
2 ) = 3
2, while x = 3
2π
gives an absolute minimum f( 3
2π) = −5
2. Additionally, f(0) = f(2π) = 1
2 so the
boundary of [0, 2π] are extrema: more precisely, x = 0 is a minimum point and
x = 2π a maximum point.
11. Since f is deﬁned on x > 0 with x ̸= 1, the maximal interval containing
x0 = 1
2 where f is invertible must be a subset of (0, 1). On the latter, we study the
monotonicity, or equivalently the invertibility, of f which is, remember, continuous
everywhere on the domain. Since
f ′(x) = 1
x +
1
x log2 x = log2 x + 1
x log2 x ,
it is immediate to see f ′(x) > 0 for any x ∈(0, 1), meaning f is strictly increasing
on (0, 1). Therefore the largest interval of invertibility is indeed (0, 1).
To write the inverse explicitly, put t = log x so that
y = t −1
t ,
t2 −ty −1 = 0 ,
t = y ±

y2 + 4
2
,
and changing variable back to x,
x = e
y±√
y2+4
2
.
Being interested in x ∈(0, 1) only, we have
x = f −1(y) = e
y−√
y2+4
2
,
or, in the more customary notation,
y = f −1(x) = e
x−√
x2+4
2
.
Eventually f −1(0) = e−1, so
(f −1)′(0) =
1
f ′(e−1) = 1
2e .

212
6 Diﬀerential calculus
12. The function f(x) = log(1 + x) −x is deﬁned on x > −1, and
lim
x→−1+ f(x) = −∞,
lim
x→+∞f(x) =
lim
x→+∞

−x + o(x)

= −∞.
As
f ′(x) =
1
1 + x −1 = −
x
1 + x ,
x = 0 is critical, plus f ′(x) > 0 on x < 0 and f ′(x) < 0 for x > 0. Thus
f increases on (−1, 0] and decreases on [0, +∞); x = 0 is the point where the
absolute maximum f(0) = 0 is reached. In conclusion f(x) ≤f(0) = 0, for all
x > −1.
13. One checks f is odd, plus
f ′(x) = 15x4 −150x2 + 135 = 15(x4 −10x2 + 9)
= 15(x2 −1)(x2 −9) = 15(x + 1)(x −1)(x + 3)(x −3) .
The sign of f ′ is summarised in the diagram:
0
−3
−1
3
1
+
−
+
−
+
x2 −9
x2 −1
What this tells is that f is increasing on (−∞, −3], [−1, 1] and [3, +∞), while
decreasing on [−3, −1] and [1, 3]. The points x = −1, x = 3 are relative minima,
x = 1 and x = −3 relative maxima:
216
88
3
1
−216
−88
−3
−1
Figure 6.17. The function f(x) = 3x5 −50x3 + 135x

6.12 Exercises
213
f(1) = −f(−1) = 88
and
f(3) = −f(−3) = −216.
Besides,
lim
x→−∞f(x) = −∞,
lim
x→+∞f(x) = +∞.
The graph of f is in Fig. 6.17.
The second problem posed is equivalent to studying the number of solutions of
f(x) = −k as k varies: this is the number of intersections between the graph of f
and the line y = −k. Indeed,
if k > 216 or k < −216
one solution
if k = ±216
two solutions
if k ∈(−216, −88) ∪(88, 216)
three solutions
if k = ±88
four solutions
if k ∈(−88, 88)
ﬁve solutions.
This gives the maximum (5) and minimum (1) number of roots of the polynomial
3x5 −50x3 + 135x + k.
14. Study of the function f(x) = x4 −2√log x:
a) Necessarily x > 0 and log x ≥0, i.e., x ≥1, so dom f = [1, +∞).
b) From
f ′(x) = 4x4√log x −1
x√log x
we have
f ′(x) = 0
⇐⇒
4x4
log x = 1
⇐⇒
g1(x) = log x =
1
16x8 = g2(x) .
On x ≥1 there is an intersection x0 between the graphs of g1, g2 (Fig. 6.18).
Hence f ′(x) > 0 for x > x0, f is decreasing on [1, x0], increasing on [x0, +∞).
x0
g1(x)
g2(x)
Figure 6.18. Graphs of g1(x) = log x and g2(x) =
1
16x8

214
6 Diﬀerential calculus
This makes x0 a minimum point, and monotonicity gives f invertible on [1, x0]
and [x0, +∞). In addition, g1(1) = log 1 = 0 <
1
16 = g2(1) and g1(2) = log 2 >
1
212 = g2(2), which implies 1 < x0 < 2.
c) As f(e) = e4 −2, the point (e4 −2, e) belongs to the graph of f −1 and
(f −1)′(e4 −2) =
1
f ′(e) =
e
4e4 −1.
15. Study of f(x) =
√
x2−3
x+1 :
a) The domain is determined by x2 −3 ≥0 together with x ̸= −1, hence dom f =
(−∞, −
√
3] ∪[
√
3, +∞). At the boundary points:
lim
x→±∞f(x) =
lim
x→±∞
|x|

1 −
3
x2
x(1 + 1
x)
=
lim
x→±∞
|x|
x = ±1 ,
lim
x→−
√
3−f(x) =
lim
x→
√
3+ f(x) = 0,
so y = 1 is the horizontal right asymptote, y = −1 the horizontal left asymp-
tote.
b) The derivative
f ′(x) =
x + 3
(x + 1)2√
x2 −3
vanishes at x = −3 and is positive for x ∈(−3, −
√
3) ∪(
√
3, +∞). Thus f
is increasing on [−3, −
√
3] and [
√
3, +∞), decreasing on (−∞, −3]; x = −3
is an absolute minimum with f(−3) = −
√
6
2
< −1. Furthermore, the points
x = ±
√
3 are extrema too, namely x = −
√
3 is a relative maximum, x =
√
3
a relative minimum: f(±
√
3) = 0.
c) Fig. 6.19 (left) shows the graph of f.
1
√
3
−1
−
√
3
−3
1
−1
−3+
√
3
Figure 6.19. Graphs of f (left) and g (right) of Exercise 15

6.12 Exercises
215
d) Right-translating the negative branch of f by
√
3 gives g(x) for x < 0, whereas
shifting to the left the branch on x > 0 gives the positive part of g. The ﬁnal
result is shown in Fig. 6.19 (right).
The map g is continuous on R, in particular
lim
x→0−g(x) = lim
x→0−f(x −
√
3) = f(−
√
3) = 0 = f(
√
3) = lim
x→0+ g(x).
Since
lim
x→0± g′(x) =
lim
x→
√
3+ f ′(x) =
lim
x→−
√
3−f ′(x) = +∞
g is not diﬀerentiable at x = 0.
16. Study of f(x) =

|x2 −4| −x:
a) The domain is R and
lim
x→+∞f(x) =
lim
x→+∞
x2 −4 −x2
√
x2 −4 + x = 0−,
lim
x→−∞f(x) = +∞.
Thus y = 0 is a horizontal right asymptote. Let us search for oblique asymp-
totic directions. As
lim
x→−∞
f(x)
x
=
lim
x→−∞

−

1 −4
x2 −1

= −2 ,
lim
x→−∞(f(x) + 2x) =
lim
x→−∞

x2 −4 + x

=
lim
x→−∞
x2 −4 −x2
√
x2 −4 −x
= 0,
the line y = −2x is an oblique left asymptote.
b) It suﬃces to solve

|x2 −4|−x ≥0. First,

|x2 −4| ≥x for any x < 0. When
x ≥0, we distinguish two cases: x2 −4 < 0 (so 0 ≤x < 2) and x2 −4 ≥0 (i.e.,
x ≥2).
On 0 ≤x < 2, squaring gives
4 −x2 ≥x2
⇐⇒
x2 −2 ≤0
⇐⇒
0 ≤x ≤
√
2 .
For x ≥2, squaring implies x2 −4 ≥x2, which holds nowhere. The function
then vanishes only at x =
√
2, is positive on x <
√
2 and strictly negative for
x >
√
2.
c) Since
f(x) =
 √
4 −x2 −x
if −2 < x < 2 ,
√
x2 −4 −x
if x ≤−2 , x ≥2 ,
we have
f ′(x) =
⎧
⎪
⎨
⎪
⎩
−x
√
4 −x2 −1
if −2 < x < 2 ,
x
√
x2 −4 −1
if x < −2 , x > 2 .

216
6 Diﬀerential calculus
−2 −
√
2
2
2
√
2
Figure 6.20. The function f(x) =

|x2 −4| −x
When −2 < x < 2, f ′(x) ≥0 if x +
√
4 −x2 ≤0, that is
√
4 −x2 ≤−x. The
inequality does not hold for x ≥0; on −2 < x < 0 we square, so that
4 −x2 ≤x2
⇐⇒
x2 −2 ≥0
⇐⇒
−2 ≤x ≤−
√
2 .
Hence f ′(x) = 0 for x = −
√
2, f ′(x) > 0 for −2 < x < −
√
2 and f ′(x) < 0
when −
√
2 < x < 2.
If x < −2 or x > 2, f ′(x) ≥0 if x −
√
x2 −4 ≥0, i.e.,
√
x2 −4 ≤x. The latter
is never true for x < −2; for x > 2, x2 ≥x2 −4 is a always true. Therefore
f ′(x) > 0 per x > 2 e f ′(x) < 0 per x < −2.
Summary: f decreases on (−∞, −2] and [−
√
2, 2], increases on [−2, −
√
2] and
[2, +∞). The points x = ±2 are relative minima, x = −
√
2 a relative max-
imum. The corresponding values are f(−2) = 2, f(2) = −2, f(−
√
2) = 2
√
2,
so x = 2 is actually a global minimum.
d) As composite of continuous elementary maps, f is continuous on its domain.
To study diﬀerentiability it is enough to examine f ′ for x →±2. Because
lim
x→±2 f ′(x) = ∞,
at x = ±2 there is no diﬀerentiability.
e) The graph is shown in Fig. 6.20.
17. Study of f(x) =
3√
e2x −1:
a) The function is deﬁned everywhere
lim
x→+∞f(x) = +∞
and
lim
x→−∞f(x) = −1.
b) The ﬁrst derivative
f ′(x) = 2
3
e2x
(e2x −1)2/3

6.12 Exercises
217
−1
1
2 log 3
Figure 6.21. The map f(x) =
3√
e2x −1
is positive for x ∈R \ {0}, and f is not diﬀerentiable at x = 0, for lim
x→0f ′(x) =
+∞. Therefore f increases everywhere on R.
c) The second derivative (for x ̸= 0)
f ′′(x) = 4
9e2x
e2x −3
(e2x −1)5/3
vanishes at x = 1
2 log 3; it is positive when x ∈(−∞, 0) ∪( 1
2 log 3, +∞). This
makes x =
1
2 log 3 an ascending inﬂection, plus f convex on (−∞, 0] and
[ 1
2 log 3, +∞), concave on [0, 1
2 log 3]. Suitably extending the deﬁnition, the
point x = 0 may be acknowledged as an inﬂection (with vertical tangent).
d) See Fig. 6.21.
18. Study of f(x) = 1 −e−|x| + x
e :
a) Clearly dom f = R. As
lim
x→±∞e−|x| = 0 ,
we immediately obtain
lim
x→±∞f(x) = ±∞,
lim
x→±∞
f(x)
x
=
lim
x→±∞
 1
x −e−|x|
x
+ 1
e

= 1
e ,
lim
x→±∞

f(x) −x
e

=
lim
x→±∞(1 −e−|x|) = 1.
This makes y = 1
ex + 1 a complete oblique asymptote.
b) The map is continuous on R, and certainly diﬀerentiable for x ̸= 0. As

218
6 Diﬀerential calculus
−e
x0
−1
1
1 −2
e
y = x
e + 1
Figure 6.22. Graph of f(x) = 1 −e−|x| + x
e
f ′(x) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
e−x + 1
e
if x > 0 ,
−ex + 1
e
if x < 0 ,
it follows
lim
x→0−f ′(x) = lim
x→0−

−ex + 1
e

= 1
e −1
̸= lim
x→0+ f ′(x) = lim
x→0+

e−x + 1
e

= 1
e + 1,
preventing diﬀerentiability at x = 0.
Moreover, for x > 0 we have f ′(x) > 0. On x < 0, f ′(x) > 0 if ex <
1
e,
i.e., x < −1. The map is increasing on (−∞, −1] and [0, +∞), decreasing on
[−1, 0].
c) The previous considerations imply x = −1 is a local maximum with f(−1) =
1 −2
e, x = 0 a local minimum where f(0) = 0.
d) See Fig. 6.22.
19. Study of f(x) = ex(x2 −8|x −3| −8):
a) The domain covers R. Since
f(x) =

ex(x2 + 8x −32)
if x < 3 ,
ex(x2 −8x + 16)
if x ≥3 ,
we have
f ′(x) =

ex(x2 + 10x −24)
if x < 3 ,
ex(x2 −6x + 8)
if x > 3 .

6.12 Exercises
219
On x < 3: f ′(x) = 0 if x2 +10x−24 = 0, so x = −12 or x = 2, while f ′(x) > 0
if x ∈(−∞, −12) ∪(2, 3). On x > 3: f ′(x) = 0 if x2 −6x + 8 = 0, i.e., x = 4
(x = 2 is a root, but lying outside the interval x > 3 we are considering), while
f ′(x) > 0 if x ∈(4, +∞).
Therefore f is increasing on the intervals (−∞, −12], [2, 3] and [4, +∞), de-
creasing on [−12, 2] and [3, 4].
b) From part a) we know x = −12 and x = 3 are relative maxima, x = 2 and x = 4
relative minima: f(−12) = 16e−12, f(2) = −12e2, f(3) = e3 and f(4) = 0. For
the range, let us determine
lim
x→−∞f(x) =
lim
x→−∞ex(x2 + 8x −32) = 0 ,
lim
x→+∞f(x) =
lim
x→+∞ex(x2 −8x + 16) = +∞.
Continuity implies
im f = [min f(x), sup f(x)) = [f(2), +∞) = [−12e2, +∞).
c) No discontinuities are present, for the map is the composite of continuous
functions. As for the diﬀerentiability, the only unclear point is x = 3. But
lim
x→3−f ′(x) = lim
x→3−ex(x2 + 10x −24) = 15e3 ,
lim
x→3+ f ′(x) = lim
x→3+ ex(x2 −6x + 8) = −e3,
sof is not diﬀerentiable at x = 3.
d) See Fig. 6.23; a neighbourhood of x = −12 is magniﬁed.
−12
−12
−10
−14
−2 · 10−4
2 · 10−4
2
e3
4
−12e2
3
Figure 6.23. Graph of f(x) = ex(x2 −8|x −3| −8)

220
6 Diﬀerential calculus
e) The function g is continuous on the real axis and
g′(x) =

ex(x2 + 10x −24) + α
if x < 3 ,
ex(x2 −6x + 8) −α
if x > 3 .
In order for g to be diﬀerentiable at x = 3, we must have
lim
x→3−g′(x) = 15e3 + α = lim
x→3+ g′(x) = −e3 −α ;
the value α = −8e3 makes g of class C1 on the whole real line.
20. Study of f(x) = log |1+x|
(1+x)2 :
a) dom f = R \ {−1}. By (5.6) c)
lim
x→±∞f(x) = 0+
while
lim
x→−1± f(x) = ∞
0+ = −∞.
From this, x = −1 is a vertical asymptote, and y = 0 is a complete oblique
asymptote.
b) The derivative
f ′(x) = 1 −2 log |x + 1|
(x + 1)3
tells that f(x) is diﬀerentiable on the domain; f ′(x) = 0 if |x + 1| = √e, hence
for x = −1±√e; f ′(x) > 0 if x ∈(−∞, −√e−1)∪(−1, √e−1). All this says f
increases on (−∞, −√e−1] and (−1, −1+√e], decreases on [−√e−1, −1) and
[−1+√e, +∞), has (absolute) maxima at x = −1±√e, with f(−1±√e) =
1
2e.
c) From
f ′′(x) = −5 + 6 log |x + 1|
(x + 1)4
the second derivative is deﬁned at each point of dom f, and vanishes at |x+1| =
e5/6, so x = −1±e5/6. Since f ′′(x) > 0 on x ∈(−∞, −1−e5/6)∪(e5/6−1, +∞),
f is convex on (−∞, −1 −e5/6] and [e5/6 −1, +∞), while is concave on [−1 −
e5/6, −1) and (−1, e5/6 −1]. The points x = −1 ± e5/6 are inﬂections.
d) See Fig. 6.24.
21. Study of f(x) =
x log |x|
1+log2 |x|:
a) The domain is clear: dom f = R\ {0}. Since lim
x→0f(x) = 0 (x ‘wins’ against the
logarithm) we can extend f to R with continuity, by deﬁning g(0) = 0. The
function is odd, so we shall restrict the study to x > 0.

6.12 Exercises
221
−1
−e
5
6 −1
e
5
6 −1
↑
−√e −1
↑
√e −1
1
2e
Figure 6.24. Graph of f(x) = log |1+x|
(1+x)2
As far as the diﬀerentiability is concerned, when x > 0
f ′(x) = log3 x −log2 x + log x + 1
(1 + log2 x)2
;
with t = log x, the limit reads
lim
x→0 f ′(x) =
lim
t→−∞
t3 −t2 + t + 1
(1 + t2)2
=
lim
t→−∞
t3
t4 = 0.
Therefore the map g, prolongation of f, is not only continuous but also diﬀer-
entiable, due to Theorem 6.15, on the entire R. In particular g′(0) = 0.
b) Part a) is also telling that x = 0 is stationary for g. To ﬁnd other critical
points, we look at the zeroes of the map h(t) = t3 −t2 + t + 1, where t = log x
(x > 0). Since
lim
t→−∞h(t) = −∞,
lim
t→∞h(t) = +∞,
h(0) = 1,
h′(t) = 3t2 −2t + 1 > 0,
∀t ∈R,
h is always increasing and has one negative zero t0. Its graph is represented in
Fig. 6.25 (left).
As t0 = log x0 < 0, 0 < x0 = et0 < 1. But the function is odd, so g has two
more stationary points, x0 and −x0 respectively.
c) By the previous part g′(x) > 0 on (x0, +∞) and g′(x) < 0 on (0, x0). To
summarise then, g (odd) is increasing on (−∞, −x0] and [x0, +∞), decreasing
on [−x0, x0]. Because
lim
x→+∞g(x) = +∞
and
lim
x→+∞
g(x)
x
=
lim
x→+∞
log x
1 + log2 x =
lim
t→+∞
t
1 + t2 = 0,

222
6 Diﬀerential calculus
t0
1
1
x0
−x0
−1
Figure 6.25. The functions h (left) and g (right) of Exercise 21
there are no asymptotes.
For the graph see Fig. 6.25 (right).
22. Study of f(x) = arctan |x|+3
x−3 :
a) dom f = R \ {3}. The function is more explicitly given by
f(x) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
arctan −x + 3
x −3 = arctan(−1) = −π
4
if x ≤0 ,
arctan x + 3
x −3
if x > 0,
whence
lim
x→−∞f(x) =
lim
x→−∞−π
4 = −π
4 ,
lim
x→+∞f(x) = arctan 1 = π
4 ,
lim
x→3−f(x) = arctan 6
0−= arctan(−∞) = −π
2 ,
lim
x→3+ f(x) = arctan 6
0+ = arctan(+∞) = π
2 .
Then the straight lines y = −π
4 , y = π
4 are horizontal asymptotes (left and
right respectively).
b) The map
f ′(x) =
⎧
⎨
⎩
0
if x < 0 ,
−
3
x2 + 9
if x > 0,
x ̸= 3,
is negative on x > 0, x ̸= 3, so f is strictly decreasing on [0, 3) and (3, +∞),
but only non-increasing on (−∞, 3). The reader should take care that f is
not strictly decreasing on the whole [0, 3) ∪(3, +∞) (recall the remarks of
p. 197). The interval (−∞, 0) consists of points of relative non-strict maxima
and minima, for f(x) = −π
4 , whereas x = 0 is a relative maximum.

6.12 Exercises
223
3
π
2
−π
2
π
4
−π
4
Figure 6.26. The function f(x) = arctan |x| + 3
x −3
Eventually, inf f(x) = −π
2 , sup f(x) = π
2 (the map admits no maximum, nor
minimum).
c) Our map is certainly diﬀerentiable on R \ {0, 3}. At x = 3, f is not deﬁned; at
x = 0, f is continuous but
lim
x→0−f ′(x) = 0 ̸= lim
x→0+ f ′(x) = lim
x→0+ −
3
x2 + 9 = −1
3,
showing that diﬀerentiability does not extend beyond R \ {0, 3}.
d) Computing
f ′′(x) =
⎧
⎨
⎩
0
if x < 0 ,
6x
(x2 + 9)2
if x > 0,
x ̸= 3 ,
reveals that f ′′(x) > 0 for x > 0 with x ̸= 3, so f is convex on [0, 3) and
(3, +∞).
e) See Fig. 6.26.
23. Study of f(x) = arcsin
√
2ex −e2x:
a) We have to impose 2ex−e2x ≥0 and −1 ≤
√
2ex −e2x ≤1 for the domain; the
ﬁrst constraint is equivalent to 2−ex ≥0, hence x ≤log 2. Having assumed that
square roots are always positive, the second inequality reduces to 2ex−e2x ≤1.
With y = ex, we can write y2 −2y + 1 = (y −1)2 ≥0, which is always true.
Thus dom f = (−∞, log 2]. Moreover,
lim
x→−∞f(x) = 0 ,
f(log 2) = 0,
and y = 0 is a horizontal left asymptote.

224
6 Diﬀerential calculus
b) From
f ′(x) =
ex(1 −ex)

ex(2 −ex)(1 −2ex + e2x)
=
ex(1 −ex)

ex(2 −ex)(1 −ex)2
=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
−
ex

ex(2 −ex)
if 0 < x < log 2 ,
ex

ex(2 −ex)
if x < 0 ,
we see that
lim
x→(log 2)−f ′(x) = −∞,
lim
x→0+ f ′(x) = −1 ,
lim
x→0−f ′(x) = 1 .
In this way f is not diﬀerentiable at x = log 2, where the tangent is vertical,
and at the corner point x = 0.
c) The sign of f ′ is positive for x < 0 and negative for 0 < x < log 2, meaning that
x = 0 is a global maximum point, f(0) = π
2 , while at x = log 2 the absolute
minimum f(log 2) = 0 is reached; f is monotone on (−∞, 0] (increasing) and
[0, log 2] (decreasing).
d) See Fig. 6.27.
e) A possible choice to extend f with continuity is
˜f(x) =

f(x)
if x ≤log 2 ,
0
if x > log 2 .
log 2
π
2
Figure 6.27. The map f(x) = arcsin
√
2ex −e2x

7
Taylor expansions and applications
The Taylor expansion of a function around a real point x0 is the representation of
the map as sum of a polynomial of a certain degree and an inﬁnitesimal function of
order bigger than the degree. It provides an extremely eﬀective tool both from the
qualitative and the quantitative point of view. In a small enough neighbourhood of
x0 one can approximate the function, however complicated, using the polynomial;
the qualitative features of the latter are immediate, and polynomials are easy to
handle. The expansions of the main elementary functions can be aptly combined
to produce more involved expressions, in a way not dissimilar to the algebra of
polynomials.
7.1 Taylor formulas
We wish to tackle the problem of approximating a function f, around a given point
x0 ∈R, by polynomials of increasingly higher degree.
We begin by assuming f be continuous at x0. Introducing the constant poly-
nomial (degree zero)
T f0,x0(x) = f(x0),
∀x ∈R,
formula (5.4) prompts us to write
f(x) = T f0,x0(x) + o(1),
x →x0.
(7.1)
Put in diﬀerent terms, we may approximate f around x0 using a zero-degree-
polynomial, in such a way that the diﬀerence f(x) −T f0,x0(x) (called error of
approximation, or remainder), is inﬁnitesimal at x0 (Fig. 7.1). The above relation
is the ﬁrst instance of a Taylor formula.
Suppose now f is not only continuous but also diﬀerentiable at x0: then the
ﬁrst formula of the ﬁnite increment (6.11) holds. By deﬁning the polynomial in x
of degree one
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_7,
© Springer International Publishing Switzerland 2015

226
7 Taylor expansions and applications
x0
f(x0)
y = f(x)
y = T f0(x)
Figure 7.1. Local approximation of f by the polynomial T f0 = T f0,x0
T f1,x0(x) = f(x0) + f ′(x0)(x −x0),
whose graph is the tangent line to f at x0 (Fig. 7.2), relation (6.11) reads
f(x) = T f1,x0(x) + o(x −x0),
x →x0.
(7.2)
This is another Taylor formula: it says that a diﬀerentiable map at x0 can be
locally approximated by a linear function, with an error of approximation that
not only tends to 0 as x →x0, but is inﬁnitesimal of order bigger than one.
In case f is diﬀerentiable in a neighbourhood of x0, except perhaps at x0, the
second formula of the ﬁnite increment (6.13) is available: putting x1 = x0, x2 = x
we write the latter as
f(x) = T f0,x0(x) + f ′(¯x)(x −x0),
(7.3)
x0
f(x0)
y = f(x)
y = T f1(x)
Figure 7.2. Local approximation of f by the polynomial T f1 = T f1,x0

7.1 Taylor formulas
227
where ¯x denotes a suitable point between x0 and x. Compare this with (7.1): now
we have a more accurate expression for the remainder. This allows to appraise
numerically the accuracy of the approximation, once the increment x −x0 and an
estimate of f ′ around x0 are known. Formula (7.3) is of Taylor type as well, and
the remainder is called Lagrange’s remainder. In (7.1), (7.2) we call it Peano’s
remainder, instead.
Now that we have approximated f with polynomials of degrees 0 or 1, as
x →x0, and made errors o(1) = o

(x−x0)0
or o(x−x0) respectively, the natural
question is whether it is possible to approximate the function by a quadratic
polynomial, with an error o

(x −x0)2
as x →x0. Equivalently, we seek for a real
number a such that
f(x) = f(x0) + f ′(x0)(x −x0) + a(x −x0)2 + o

(x −x0)2
,
x →x0 .
(7.4)
This means
lim
x→x0
f(x) −f(x0) −f ′(x0)(x −x0) −a(x −x0)2
(x −x0)2
= 0.
By de l’Hˆopital’s Theorem, such limit holds if
lim
x→x0
f ′(x) −f ′(x0) −2a(x −x0)
2(x −x0)
= 0,
i.e.,
lim
x→x0
1
2
f ′(x) −f ′(x0)
x −x0
−a

= 0,
or
1
2 lim
x→x0
f ′(x) −f ′(x0)
x −x0
= a.
We conclude that (7.4) is valid when the right-hand-side limit exists and is ﬁnite: in
other words, when f is twice diﬀerentiable at x0. If so, the coeﬃcient a is 1
2f ′′(x0).
In this way we have obtained the Taylor formula (with Peano’s remainder)
f(x) = T f2,x0(x) + o

(x −x0)2
,
x →x0,
(7.5)
where
T f2,x0(x) = f(x0) + f ′(x0)(x −x0) + 1
2f ′′(x0)(x −x0)2
is the Taylor polynomial of f at x0 with degree 2 (Fig. 7.3).
The recipe just described can be iterated, and leads to polynomial approxim-
ations of increasing order. The ﬁnal result is the content of the next theorem.

228
7 Taylor expansions and applications
x0
f(x0)
y = f(x)
y = T f2(x)
Figure 7.3. Local approximation of f by T f2 = T f2,x0
Theorem 7.1 (Taylor formula with Peano’s remainder) Let n ≥0 and
f be n times diﬀerentiable at x0. Then the Taylor formula holds
f(x) = T fn,x0(x) + o

(x −x0)n
,
x →x0,
(7.6)
where
T fn,x0(x) =
n
	
k=0
1
k!f (k)(x0)(x −x0)k
= f(x0) + f ′(x0)(x −x0) + . . . + 1
n!f (n)(x0)(x −x0)n.
(7.7)
The term T fn,x0(x) is the Taylor polynomial of f at x0 of order (or degree)
n, while o

(x −x0)n
as in (7.6) is Peano’s remainder of order n. The rep-
resentation of f given by (7.6) is called Taylor expansion of f at x0 of order n,
with remainder in Peano’s form.
Under stronger hypotheses on f we may furnish a preciser formula for the
remainder, thus extending (7.3).
Theorem 7.2 (Taylor formula with Lagrange’s remainder) Let n ≥0
and f diﬀerentiable n times at x0, with continuous nth derivative, be given;
suppose f is diﬀerentiable n + 1 times around x0, except possibly at x0. Then
the Taylor formula
f(x) = T fn,x0(x) +
1
(n + 1)!f (n+1)(¯x)(x −x0)n+1,
(7.8)
holds, for a suitable ¯x between x0 and x.

7.2 Expanding the elementary functions
229
This remainder is said Lagrange’s remainder of order n, and (7.8) is the Taylor
expansion of f at x0 of order n with Lagrange’s remainder.
Theorems 7.1 and 7.2 are proven in Appendix A.4.4, p. 456.
An additional form of the remainder of order n in a Taylor formula, called
integral remainder, will be provided in Theorem 9.44.
A Taylor expansion centred at the origin (x0 = 0) is sometimes called Mac-
laurin expansion. A useful relation to simplify the computation of a Maclaurin
expansion goes as follows.
Property 7.3 The Maclaurin polynomial of an even (respectively, odd) map
involves only even (odd) powers of the independent variable.
Proof.
If f is even and n times diﬀerentiable around the origin, the claim follows
from (7.7) with x0 = 0, provided we show all derivatives of odd order
vanish at the origin.
Recalling Property 6.12, f even implies f ′ odd, f ′′ even, f ′′′ odd et cetera.
In general, even-order derivatives f (2k) are even functions, whereas f (2k+1)
are odd. But an odd map g must necessarily vanish at the origin (if deﬁned
there), because x = 0 in g(−x) = −g(x) gives g(0) = −g(0), whence
g(0) = 0.
The argument is the same for f odd.
2
7.2 Expanding the elementary functions
The general results permit to expand simple elementary functions. Other functions
will be discussed in Sect. 7.3.
The exponential function
Let f(x) = ex. Since all derivatives are identical with ex, we have f (k)(0) = 1 for
any k ≥0. Maclaurin’s expansion of order n with Peano’s remainder is
ex = 1 + x + x2
2 + . . . + xk
k! + . . . + xn
n! + o(xn) =
n
	
k=0
xk
k! + o(xn) .
(7.9)
Using Lagrange’s remainder, we have
ex =
n
	
k=0
xk
k! +
e¯x
(n + 1)!xn+1,
for a certain ¯x between 0 and x.
(7.10)
Maclaurin’s polynomials for ex of order n = 1, 2, 3, 4 are shown in Fig. 7.4.

230
7 Taylor expansions and applications
0
1
f
Tf1
Tf2
Tf3
Tf4
f
T f1
T f2
T f3
T f4
Figure 7.4. Local approximation of f(x) = ex by T fn = T fn,0 for n = 1, 2, 3, 4
Remark 7.4 Set x = 1 in the previous formula:
e =
n
	
k=0
1
k! +
e¯x
(n + 1)!
(con 0 < ¯x < 1).
For any n ≥0, we obtain an estimate (from below) of the number e, namely
en =
n
	
k=0
1
k!;
(7.11)
because 1 < e¯x < e < 3 moreover, the following is an estimate of the error:
1
(n + 1)! < e −en <
3
(n + 1)!.
In contrast to the sequence {an =

1 + 1
n
n} used to deﬁne the constant e, the
sequence {en} converges at the rate of a factorial, hence very rapidly (compare
Tables 7.1 and 3.1). Formula (7.11) gives therefore an excellent numerical approx-
imation of the number e.
2
The expansion of f(x) = ex at a generic x0 follows from the fact that f (k)(x0) = ex0
ex = ex0 + ex0(x −x0) + ex0 (x −x0)2
2
+ . . . + ex0 (x −x0)n
n!
+ o

(x −x0)n
=
n
	
k=0
ex0 (x −x0)k
k!
+ o

(x −x0)n
.

7.2 Expanding the elementary functions
231
n
en
0
1.0000000000000
1
2.0000000000000
2
2.5000000000000
3
2.6666666666667
4
2.7083333333333
5
2.7166666666667
6
2.7180555555556
7
2.7182539682540
8
2.7182787698413
9
2.7182815255732
10
2.7182818011464
Table 7.1. Values of the sequence {en} of (7.11)
The logarithm
The derivatives of the function f(x) = log x are
f ′(x) = 1
x = x−1 ,
f ′′(x) = (−1)x−2 ,
f ′′′(x) = (−1)(−2)x−3 ,
and in general,
f (k)(x) = (−1)k−1(k −1)! x−k.
Thus for k ≥1,
f (k)(1)
k!
= (−1)k−1 1
k
and the Taylor expansion of order n at x0 = 1 is
log x = (x −1) −(x −1)2
2
+ . . . + (−1)n−1 (x −1)n
n
+ o

(x −1)n
=
n
	
k=1
(−1)k−1 (x −1)k
k
+ o

(x −1)n
.
(7.12)
Let us change the independent variable x −1 →x, to obtain the Maclaurin ex-
pansion of order n of log(1 + x)
log(1 + x) = x −x2
2 + . . . + (−1)n−1 xn
n + o(xn)
=
n
	
k=1
(−1)k−1 xk
k + o(xn).
(7.13)
The Maclaurin polynomials of order n = 1, 2, 3, 4 for y = log(1+x) are represented
in Fig. 7.5.

232
7 Taylor expansions and applications
0
f
T f1
T f2
Tf3
Tf4
f
T f1
Tf2
Tf3
Tf4
Figure 7.5. Local approximation of f(x) = log(1 + x) by T fn = T fn,0 for n = 1, 2, 3, 4
The trigonometric functions
The function f(x) = sin x is odd, so by Property 7.3 its Maclaurin expansion con-
tains just odd powers of x. We have f ′(x) = cos x, f ′′′(x) = −cosx and in general
f (2k+1)(x) = (−1)k cos x, whence f (2k+1)(0) = (−1)k. Maclaurin’s expansion up
to order n = 2m + 2 reads
sin x = x −x3
3! + x5
5! −. . . + (−1)m
x2m+1
(2m + 1)! + o(x2m+2)
=
m
	
k=0
(−1)k
x2k+1
(2k + 1)! + o(x2m+2).
(7.14)
The typical structure of the expansion of an odd map should be noticed. Mac-
laurin’s polynomial T f2m+2,0 of even order 2m + 2 coincides with the polynomial
T f2m+1,0 of odd degree 2m + 1, for f (2m+2)(0) = 0. Stopping at order 2m + 1
would have rendered
sin x =
m
	
k=0
(−1)k
x2k+1
(2k + 1)! + o(x2m+1) ,
to which (7.14) is preferable, because it contains more information on the re-
mainder’s behaviour when x →0. Figure 7.6 represents the Maclaurin polynomials
of degree 2m + 1, 0 ≤m ≤6, of the sine.
As far as the even map f(x) = cos x is concerned, only even exponents appear.
From f ′′(x) = −cos x, f (4)(x) = cos x
and f (2k)(x) = (−1)k cos x, it follows
f (2k)(0) = (−1)k, so Maclaurin’s expansion of order n = 2m + 1 is

7.2 Expanding the elementary functions
233
0
f
T f1
Tf3
Tf5
Tf7
T f7
T f9
T f11
T f13
Tf1
Tf3
Tf5
Tf9
Tf11
Tf13
Figure 7.6. Local approximation of f(x) = sin x by polynomials T f2m+1 = T f2m+1,0
with 0 ≤m ≤6
cos x = 1 −x2
2 + x4
4! −. . . + (−1)m x2m
(2m)! + o(x2m+1)
=
m
	
k=0
(−1)k x2k
(2k)! + o(x2m+1).
(7.15)
The considerations made about the sine apply also here. Maclaurin’s polynomials
of order 2m (1 ≤m ≤6) for y = cos x can be seen in Fig. 7.7.
f
Tf2
Tf2
Tf4
Tf6
T f6
Tf8
T f8
Tf10
T f10
T f12
Tf4
Tf12
0
Figure 7.7. Local approximation of f(x) = cos x by T f2m = T f2m,0 when 1 ≤m ≤6

234
7 Taylor expansions and applications
Power functions
Consider the family of maps f(x) = (1 + x)α for arbitrary α ∈R. We have
f ′(x) = α(1 + x)α−1
f ′′(x) = α(α −1)(1 + x)α−2
f ′′′(x) = α(α −1)(α −2)(1 + x)α−3.
From the general relation f (k)(x) = α(α −1) . . . (α −k + 1)(1 + x)α−k we get
f(0) = 1 ,
f (k)(0)
k!
= α(α −1) · · · (α −k + 1)
k!
for k ≥1 .
At this point it becomes convenient to extend the notion of binomial coeﬃcient
(1.10), and allow α to be any real number by putting, in analogy to (1.11),
α
0

= 1 ,
α
k

= α(α −1) · · · (α −k + 1)
k!
for k ≥1 .
(7.16)
Maclaurin’s expansion to order n is thus
(1 + x)α = 1 + αx + α(α −1)
2
x2 + . . . +
α
n

xn + o(xn)
=
n
	
k=0
α
k

xk + o(xn).
(7.17)
Let us see in detail what happens for special values of the parameter. When
α = −1
−1
2

= (−1)(−2)
2
= 1,
−1
3

= (−1)(−2)(−3)
3!
= −1, . . . ,
−1
k

= (−1)(−2) · · · (−k)
k!
= (−1)k,
so
1
1 + x = 1 −x + x2 −. . . + (−1)nxn + o(xn) =
n
	
k=0
(−1)kxk + o(xn).
(7.18)
Choosing α = 1
2 gives
 1
2
2

=
1
2( 1
2 −1)
2
= −1
8,
 1
2
3

=
1
2( 1
2 −1)( 1
2 −2)
3!
= 1
16,
and the expansion of f(x) = √1 + x arrested to the third order is

7.2 Expanding the elementary functions
235
f
−1
f
T f1
T f3
T f2
T f4
Tf1
Tf3
Tf2
T f4
0
1
Figure 7.8. Local approximation of f(x) = √1 + x by T fn = T fn,0 for n = 1, 2, 3, 4
√
1 + x = 1 + 1
2x −1
8x2 + 1
16x3 + o(x3).
The polynomials of order n = 1, 2, 3, 4 are shown in Fig. 7.8.
For conveniency, the following table collects the expansions with Peano’s re-
mainder obtained so far. A more comprehensive list is found on p. 476.
ex = 1 + x + x2
2 + . . . + xk
k! + . . . + xn
n! + o(xn)
log(1 + x) = x −x2
2 + . . . + (−1)n−1 xn
n + o(xn)
sin x = x −x3
3! + x5
5! −. . . + (−1)m
x2m+1
(2m + 1)! + o(x2m+2)
cos x = 1 −x2
2 + x4
4! −. . . + (−1)m x2m
(2m)! + o(x2m+1)
(1 + x)α = 1 + αx + α(α −1)
2
x2 + . . . +
α
n

xn + o(xn)
1
1 + x = 1 −x + x2 −. . . + (−1)nxn + o(xn)
√
1 + x = 1 + 1
2x −1
8x2 + 1
16x3 + o(x3)

236
7 Taylor expansions and applications
7.3 Operations on Taylor expansions
Consider the situation where a map f has a complicated analytic expression, that
involves several elementary functions; it might not be that simple to ﬁnd its Taylor
expansion using the deﬁnition, because computing derivatives at a point up to a
certain order n is no straighforward task. But with the expansions of the element-
ary functions at our avail, a more convenient strategy may be to start from these
and combine them suitably to arrive at f. The techniques are explained in this
section.
This approach is indeed justiﬁed by the following result.
Proposition 7.5 Let f : (a, b) →R be n times diﬀerentiable at x0 ∈(a, b).
If there exists a polynomial Pn, of degree ≤n, such that
f(x) = Pn(x) + o

(x −x0)n
for x →x0,
(7.19)
then Pn is the Taylor polynomial Tn = T fn,x0 of order n for the map f at x0.
Proof.
Formula (7.19) is equivalent to
Pn(x) = f(x) + ϕ(x),
with ϕ(x) = o

(x −x0)n
for x →x0.
On the other hand, Taylor’s formula for f at x0 reads
Tn(x) = f(x) + ψ(x),
with ψ(x) = o

(x −x0)n
.
Therefore
Pn(x) −Tn(x) = ϕ(x) −ψ(x) = o

(x −x0)n
.
(7.20)
But the diﬀerence Pn(x) −Tn(x) is a polynomial of degree lesser or equal
than n, hence it may be written as
Pn(x) −Tn(x) =
n
	
k=0
ck(x −x0)k.
The claim is that all coeﬃcients ck vanish. Suppose, by contradiction, there
are some non-zero ck, and let m be the smallest index between 0 and n
such that cm ̸= 0. Then
Pn(x) −Tn(x) =
n
	
k=m
ck(x −x0)k
so
Pn(x) −Tn(x)
(x −x0)m
= cm +
n
	
k=m+1
ck(x −x0)k−m,

7.3 Operations on Taylor expansions
237
by factoring out (x −x0)m. Taking the limit for x →x0 and recalling
(7.20), we obtain
0 = cm,
in contrast with the assumption.
2
The proposition guarantees that however we arrive at an expression like (7.19)
(in a mathematically correct way), this must be exactly the Taylor expansion of
order n for f at x0.
Example 7.6
Suppose the function f(x) satisﬁes
f(x) = 2 −3(x −2) + (x −2)2 −1
4(x −2)3 + o((x −2)3)
for x →2.
Then (7.7) implies
f(2) = 2,
f ′(2) = −3,
f ′′(2)
2
= 1,
f ′′′(2)
3!
= −1
4,
hence
f(2) = 2,
f ′(2) = −3,
f ′′(2) = 2,
f ′′′(2) = −3
2.
2
For simplicity we shall assume henceforth x0 = 0. This is always possible by a
change of the variables, x →t = x −x0.
Let now
f(x) = a0 + a1x + ... + anxn + o(xn) = pn(x) + o(xn)
and
g(x) = b0 + b1x + ... + bnxn + o(xn) = qn(x) + o(xn)
be the Maclaurin expansions of the maps f and g.
Sums
From (5.5) a), it follows
f(x) ± g(x) = [pn(x) + o(xn)] ± [qn(x) + o(xn)]
= [pn(x) ± qn(x)] + [o(xn) ± o(xn)]
= pn(x) ± qn(x) + o(xn).
The expansion of a sum is the sum of the expansions involved.
Example 7.7
Let us ﬁnd the expansions at the origin of the hyperbolic sine and cosine, intro-
duced in Sect. 6.10.1. Changing x to −x in
ex = 1 + x + x2
2 + ... +
x2n+2
(2n + 2)! + o(x2n+2)

238
7 Taylor expansions and applications
gives
e−x = 1 −x + x2
2 −... +
x2n+2
(2n + 2)! + o(x2n+2).
Thus
sinh x = 1
2(ex −e−x) = x + x3
3! + x5
5! + ... +
x2n+1
(2n + 1)! + o(x2n+2).
Similarly,
cosh x = 1
2(ex + e−x) = 1 + x2
2 + x4
4! + ... + x2n
(2n)! + o(x2n+1) .
The analogies of these expansions to sin x and cos x should not go amiss.
2
Note that when the expansions of f and g have the same monomial terms up to
the exponent n, these all cancel out in the diﬀerence f −g. In order to ﬁnd the ﬁrst
non-zero coeﬃcient in the expansion of f −g one has to look at an expansions of f
and g of order n′ > n. In general it is not possible to predict what the minimum n′
will be, so one must proceed case by case. Using expansions ‘longer’ than necessary
entails superﬂuous computations, but is no mistake, in principle. On the contrary,
terminating an expansion ‘too soon’ leads to meaningless results or, in the worst
scenario, to a wrong conclusion.
Example 7.8
Determine the order at 0 of
h(x) = ex −
√
1 + 2x
by means of Maclaurin’s expansion (see Sect. 7.4 in this respect).
Using ﬁrst order expansions,
f(x) = ex = 1 + x + o(x),
g(x) =
√
1 + 2x = 1 + x + o(x),
leads to the cancellation phenomenon just described. We may only say
h(x) = o(x),
which is clearly not enough for the order of h. Instead, if we expand to second
order
f(x) = ex = 1 + x + x2
2 + o(x2)
g(x) =
√
1 + 2x = 1 + x −x2
2 + o(x2),
then
h(x) = x2 + o(x2)
shows h(x) is inﬁnitesimal of order two at the origin.
2
Products
Using (5.5) d) and then (5.5) a) shows that

7.3 Operations on Taylor expansions
239
f(x)g(x) = [pn(x) + o(xn)][qn(x) + o(xn)]
= pn(x)qn(x) + pn(x)o(xn) + qn(x)o(xn) + o(xn)o(xn)
= pn(x)qn(x) + o(xn) + o(xn) + o(x2n)
= pn(x)qn(x) + o(xn).
The product pn(x)qn(x) contains powers of x larger than n; each of them is an
o(xn), so we can eschew calculating it explicitly. We shall write
pn(x)qn(x) = rn(x) + o(xn),
intending that rn(x) gathers all powers of order ≤n, and nothing else, so in
conclusion
f(x)g(x) = rn(x) + o(xn).
Example 7.9
Expand to second order
h(x) =
√
1 + x ex
at the origin. Since
f(x) =
√
1 + x = 1 + x
2 −x2
8 + o(x2),
g(x) = ex = 1 + x + x2
2 + o(x2),
it follows
h(x) =

1 + x
2 −x2
8
 
1 + x + x2
2

+ o(x2)
=

1 + x + x2
2

+

x
2 + x2
2 + x3
4

−

x2
8 + x3
8
+ x4
16

+ o(x2)
= 1 + 3
2x + 7
8x2 + o(x2).
The boxed terms have order larger than two, and therefore are already accounted
for by the symbol o(x2). Because of this, they need not have been computed
explicitly, although no harm was done.
2
Quotients
Suppose g(0) ̸= 0 and let
h(x) = f(x)
g(x) ,
for which we search an expansion
h(x) = rn(x) + o(xn),
with rn(x) =
n
	
k=0
ckxk.

240
7 Taylor expansions and applications
From h(x)g(x) = f(x) we have
rn(x)qn(x) + o(xn) = pn(x) + o(xn).
This means that the part of degree ≤n in the polynomial rn(x)qn(x) (degree 2n)
must coincide with pn(x). By this observation we can determine the coeﬃcients ck
of rn(x) starting from c0. The practical computation may be carried out like the
division algorithm for polynomials, so long as the latter are ordered with respect
to the increasing powers of x:
a0 + a1x + a2x2 + ... + anxn + o(xn)
b0 + b1x + b2x2 + ... + bnxn + o(xn)
a0 + a′
1x + a′
2x2 + ... + a′
nxn + o(xn)
c0 + c1x + ... + cnxn + o(xn)
0 + ˜a1x + ˜a2x2 + ... + ˜anxn + o(xn)
˜a1x + ˜a′
2x2 + ... + ˜a′
nxn + o(xn)
...
0 + o(xn)
Examples 7.10
i) Let us compute the second order expansion of h(x) =
ex
3 + 2 log(1 + x) . By
(7.9), (7.13), we have ex = 1 + x + 1
2x2 + o(x2), and 3 + 2 log(1 + x) = 3 + 2x −
x2 + o(x2); dividing
1 + x + 1
2x2 + o(x2)
3 + 2x −x2 + o(x2)
1 + 2
3x −1
3x2 + o(x2)
1
3 + 1
9x + 11
54x2 + o(x2)
1
3x + 5
6x2 + o(x2)
1
3x + 2
9x2 + o(x2)
11
18x2 + o(x2)
11
18x2 + o(x2)
o(x2)
produces h(x) = 1
3 + 1
9x + 11
54x2 + o(x2).
ii) Expand h(x) = tan x to the fourth order. The function being odd, it suﬃces
to ﬁnd Maclaurin’s polynomial of degree three, which is the same as the one of
order four. Since
sin x = x −x3
6 + o(x3)
and
cos x = 1 −x2
2 + o(x3) ,
dividing

7.3 Operations on Taylor expansions
241
x −x3
6 + o(x3)
1 −x2
2 + o(x3)
x −x3
2 + o(x3)
x + x3
3 + o(x3)
x3
3 + o(x3)
x3
3 + o(x3)
o(x3)
yields
tan x = x + x3
3 + o(x3) = x + x3
3 + o(x4) .
2
Composite maps
Let
f(x) = a1x + a2x2 + ... + anxn + o(xn)
be the Maclaurin expansion of an inﬁnitesimal function for x →0 (hence a0 = 0).
Write
g(y) = b0 + b1y + ... + bnyn + o(yn)
for a second map g(y). Recall
o(yn)
stands for
an inﬁnitesimal of bigger order than yn
as y →0,
which can be written
o(yn) = yno(1)
with o(1) →0 for y →0.
Now consider the composition h(x) = g

f(x)

and substitute y = f(x) in the
expansion of g(y):
g(f(x)) = b0 + b1f(x) + b2[f(x)]2 + ... + bn[f(x)]n + [f(x)]no(1).
As f(x) is continuous at 0, y = f(x) →0 for x →0, so o(1) →0 for x →0 as
well. Furthermore, expanding
[f(x)]n = an
1xn + o(xn)
yields
[f(x)]no(1) = o(xn)
per x →0.
The powers [f(x)]k (1 ≤k ≤n), expanded with respect to x up to order n, provide
the expression of g

f(x)

.

242
7 Taylor expansions and applications
Examples 7.11
i) Calculate to order two the expansion at 0 of
h(x) = e
√1+x−1.
Deﬁne
f(x) =
√
1 + x −1 = x
2 −x2
8 + o(x2),
g(y) = ey = 1 + y + y2
2 + o(y2).
Then
h(x) = 1 +
x
2 −x2
8 + o(x2)

+ 1
2
x
2 −x2
8 + o(x2)
2
+ o(x2)
= 1 +
x
2 −x2
8 + o(x2)

+ 1
2
x2
4 + o(x2)

+ o(x2)
= 1 + x
2 + o(x2).
ii) Expand to order three in 0 the map
h(x) =
1
1 + log(1 + x).
We can view this map as a quotient, but also as the composition of
f(x) = log(1 + x) = x −x2
2 + x3
3 + o(x3)
with
g(y) =
1
1 + y = 1 −y + y2 −y3 + o(y3).
It follows
h(x) = 1 −

x −x2
2 + x3
3 + o(x3)

+

x −x2
2 + x3
3 + o(x3)
2
−

x −x2
2 + x3
3 + o(x3)
3
+ o(x3)
= 1 −

x −x2
2 + x3
3 + o(x3)

+

x2 −x3 + o(x3)

−

x3 + o(x3)

+ o(x3)
= 1 −x + 3x2
2
−7x3
3
+ o(x3).
2
Remark 7.12 If f(x) is inﬁnitesimal of order greater that one at the origin, we
can spare ourselves some computations, in the sense that we might be able to
infer the expansion of h(x) = g

f(x)

of degree n from lower-order expansions of
g(y). For example, let f be inﬁnitesimal of order 2 at the origin (a1 = 0, a2 ̸= 0).
Because [f(x)]k = ak
2x2k + o(x2k), an expansion for g(y) of order n
2 (if n even) or
n+1
2
(n odd) is suﬃcient to determine h(x) up to degree n. (Note that f(x) should
be expanded to order n, in general.)
2

7.3 Operations on Taylor expansions
243
Example 7.13
Expand to second order
h(x) = √cos x =

1 + (cos x −1).
Set
f(x) = cos x −1 = −x2
2 + o(x2)
(2nd order)
g(y) =

1 + y = 1 + y
2 + o(y)
(1st order).
Then
h(x) = 1 + 1
2

−x2
2 + o(x2)

+ o(x2)
= 1 −x2
4 + o(x2)
(2nd order).
2
Asymptotic expansions (not of Taylor type)
In many situations where f(x) is inﬁnite for x →0 (or x →x0) it is possible
to ﬁnd an ‘asymptotic’ expansion of f(x) in increasing powers of x (x −x0), by
allowing negative powers in the expression:
f(x) = a−m
xm + a−m+1
xm−1 + ... + a−1
x
+ a0 + a1x + ... + anxn + o(xn).
This form helps to understand better how f tends to inﬁnity. In fact, if a−m ̸= 0,
f will be inﬁnite of order m with respect to the test function x−1.
To a similar expansion one often arrives by means of the Taylor expansion of
1
f(x), which is inﬁnitesimal for x →0.
We explain the procedure with an example.
Example 7.14
Let us expand ‘asymptotically’, for x →0, the function
f(x) =
1
ex −1.
The exponential expansion arrested at order three gives
ex −1 = x + x2
2 + x3
6 + o(x3)
= x

1 + x
2 + x2
6 + o(x2)

,
so
f(x) = 1
x
1
1 + x
2 + x2
6 + o(x2)
.
The latter ratio can be treated using Maclaurin’s formula
1
1 + y = 1 −y + y2 + o(y2) ;

244
7 Taylor expansions and applications
by putting
y = x
2 + x2
6 + o(x2)
in fact, we obtain
f(x) = 1
x

1 −x
2 + x2
12 + o(x2)

= 1
x −1
2 + x
12 + o(x) ,
the asymptotic expansion of f at the origin. Looking at such expression, we can
deduce for instance that f is inﬁnite of order 1 with respect to ϕ(x) =
1
x, as
x →0.
Ignoring the term x/12 and writing f(x) = 1
x −1
2 + o(1) shows f is asymptotic
to the hyperbola
g(x) = 2 −x
2x .
2
7.4 Local behaviour of a map via its Taylor expansion
Taylor expansions at a given point are practical tools for studying how a function
locally behaves around that point. We examine in the sequel a few interesting
applications of Taylor expansions.
Order and principal part of inﬁnitesimal functions
Let
f(x) = a0 + a1(x −x0) + ... + an(x −x0)n + o

(x −x0)n
be the Taylor expansion of order n at a point x0, and suppose there is an index m
with 1 ≤m ≤n such that
a0 = a1 = ... = am−1 = 0,
but
am ̸= 0.
In a suﬃciently small neighbourhood of x0,
f(x) = am(x −x0)m + o

(x −x0)m
will behave like the polynomial
p(x) = am(x −x0)m,
which is the principal part of f with respect to the inﬁnitesimal y = x −x0. In
particular, f(x) has order m with respect to that test function.
Example 7.15
Compute the order of the inﬁnitesimal f(x) = sin x −x cos x −1
3x3 with respect
to ϕ(x) = x as x →0. Expanding sine and cosine with Maclaurin we have
f(x) = −1
30x5 + o(x5),
x →0.
Therefore f is inﬁnitesimal of order 5 and has principal part p(x) = −1
30x5.
The same result descends from de l’Hˆopital’s Theorem, albeit diﬀerentiating ﬁve
times is certainly more work than using well-known expansions.
2

7.4 Local behaviour of a map via its Taylor expansion
245
Local behaviour of a function
The knowledge of the Taylor expansion of f to order two around a point x0,
f(x) = a0 + a1(x −x0) + a2(x −x0)2 + o

(x −x0)2
,
x →x0 ,
allows us to deduce from (7.7) that
f(x0) = a0 ,
f ′(x0) = a1 ,
f ′′(x0) = 2a2 .
Suppose f is diﬀerentiable twice with continuity around x0. By Theorem 4.2 the
signs of a0, a1, a2 (when ̸= 0) coincide with the signs of f(x), f ′(x), f ′′(x), re-
spectively, in a neighbourhood of x0. This fact permits, in particular, to detect
local monotonicity and convexity, because of Theorem 6.27 b2) and Corollary 6.38
b2).
Example 7.6 (continuation)
Return to Example 7.6: we have f(2) > 0, f ′(2) < 0 and f ′′(2) > 0. Around
x0 = 2 then, f is strictly positive, strictly decreasing and strictly convex.
2
We deal with the cases a1 = 0 or a2 = 0 below.
Nature of critical points
Let x0 be a critical point for f, which is assumed diﬀerentiable around x0. By
Corollary 6.28, diﬀerent signs of f ′ at the left and right of x0 mean that the point
is an extremum; if the sign stays the same instead, x0 is an inﬂection point with
horizontal tangent.
When f possesses higher derivatives at x0, in alternative to the sign of f ′
around x0 we can understand what sort of critical point x0 is by looking at the
ﬁrst non-zero derivative of f evaluated at the point. In fact,
Theorem 7.16 Let f be diﬀerentiable n ≥2 times at x0 and suppose
f ′(x0) = . . . = f (m−1)(x0) = 0,
f (m)(x0) ̸= 0
(7.21)
for some 2 ≤m ≤n.
i) When m is even, x0 is an extremum, namely a maximum if f (m)(x0) < 0,
a minimum if f (m)(x0) > 0.
ii) When m is odd, x0 is an inﬂection point with horizontal tangent; more
precisely the inﬂection is descending if f (m)(x0) < 0, ascending if
f (m)(x0) > 0.

246
7 Taylor expansions and applications
Proof.
Compare f(x) and f(x0) around x0. From (7.6)-(7.7) and the assumption
(7.21), we have
f(x) −f(x0) = f (m)(x0)
m!
(x −x0)m + o

(x −x0)m
.
But o

(x −x0)m
= (x −x0)mo(1), so
f(x) −f(x0) = (x −x0)m
f (m)(x0)
m!
+ h(x)

,
for a suitable h(x), inﬁnitesimal when x →x0. Therefore, in a suﬃciently
small neighbourhood of x0, the term in square brackets has the same sign
as f (m)(x0), hence the sign of f(x) −f(x0), in that same neighbourhood,
is determined by f (m)(x0) and (x −x0)m. Examining all sign possibilities
proves the claim.
2
Example 7.17
Assume that around x0 = 1 we have
f(x) = 2 −15(x −1)4 + 20(x −1)5 + o

(x −1)5
.
(7.22)
From this we deduce
f ′(1) = f ′′(1) = f ′′′(1) = 0 ,
but
f (4)(1) = −360 < 0 .
Then x0 is a relative maximum (Fig. 7.9, left).
Suppose now that in a neighbourhood of x1 = −2 we can write
f(x) = 3 + 10(x + 2)5 −35(x + 2)7 + o

(x + 2)7
.
(7.23)
Then
f ′(−2) = f ′′(−2) = f ′′′(−2) = f (4)(−2) = 0 ,
and
f (5)(−2) = 10 · 5! > 0 ,
telling x1 is an ascending inﬂection with horizontal tangent (Fig. 7.9, right).
2
1
2
y = f(x)
3
y = f(x)
−2
Figure 7.9. The map deﬁned in (7.22), around x0 = 1 (right), and the one deﬁned in
(7.23), around x0 = −2 (left)

7.4 Local behaviour of a map via its Taylor expansion
247
Points of inﬂection
Consider a twice diﬀerentiable f around x0. By Taylor’s formulas we can decide
whether x0 is an inﬂection point for f.
First though, we need to prove Corollary 6.39 stated in Chap. 6, whose proof
we had to postpone to the present section.
Proof.
a) Let x0 be an inﬂection point for f. Denoting as usual by y = t(x) =
f(x0) + f ′(x0)(x −x0) the tangent line to f at x0, Taylor’s formula (7.6)
(n = 2) gives
f(x) −t(x) = 1
2f ′′(x0)(x −x0)2 + o

(x −x0)2
,
which we can write
f(x) −t(x) = (x −x0)2
1
2f ′′(x0) + h(x)

for some inﬁnitesimal h at x0. By contradiction, if f ′′(x0) ̸= 0, in an arbit-
rarily small neighbourhood of x0 the right-hand side would have constant
sign at the left and right of x0; this cannot be by hypothesis, as f is
assumed to inﬂect at x0.
b) In this case we use Taylor’s formula (7.8) with n = 2. For any x ̸= x0,
around x0 there is a point ¯x, lying between x0 and x, such that
f(x) −t(x) = 1
2f ′′(¯x)(x −x0)2.
Analysing the sign of the right-hand side concludes the proof.
2
Suppose, from now on, that f ′′(x0) = 0 and f admits derivatives higher than
the second. Instead of considering the sign of f ′′ around x0, we may study the
point x0 by means of the ﬁrst non-zero derivative of order > 2 evaluated at x0.
Theorem 7.18 Let f be n times diﬀerentiable (n ≥3) at x0, with
f ′′(x0) = . . . = f (m−1)(x0) = 0,
f (m)(x0) ̸= 0
(7.24)
for some m (3 ≤m ≤n).
i) When m is odd, x0 is an inﬂection point: descending if f (m)(x0) < 0,
ascending if f (m)(x0) > 0.
ii) When m is even, x0 is not an inﬂection for f.
Proof.
Just like in Theorem 7.16, we obtain
f(x) −t(x) = (x −x0)m
f (m)(x0)
m!
+ h(x)

,

248
7 Taylor expansions and applications
−2
3
y = t(x)
y = f(x)
Figure 7.10. Local behaviour of the map (7.25)
where h(x) is a suitable inﬁnitesimal function for x →x0. The claim follows
from a sign argument concerning the right-hand side.
2
Example 7.19
Suppose that around x0 = 3 we have
f(x) = −2 + 4(x −3) −90(x −3)5 + o

(x −3)5
.
(7.25)
Then f ′′(3) = f ′′′(3) = f (4)(3) = 0, f (5)(3) = −90 · 5! < 0. This implies that
x0 = 3 is a descending inﬂection for f (Fig. 7.10).
2
7.5 Exercises
1. Use the deﬁnition to write the Taylor polynomial, of order n and centred at
x0, for:
a)
f(x) = ex ,
n = 4 ,
x0 = 2
b)
f(x) = sin x ,
n = 6 ,
x0 = π
2
c)
f(x) = log x ,
n = 3 ,
x0 = 3
d)
f(x) = √2x + 1 ,
n = 3 ,
x0 = 4
e)
f(x) = 7 + x −3x2 + 5x3 ,
n = 2 ,
x0 = 1
f)
f(x) = 2 −8x2 + 4x3 + 9x4 ,
n = 3 ,
x0 = 0
2. Determine the Taylor expansion of the indicated functions of the highest-
possible order; the expansion should be centred around x0 and have Peano’s
remainder:
a)
f(x) = x2|x| + e2x ,
x0 = 0
b)
f(x) = 2 + x + (x −1)
3
x2 −1 ,
x0 = 1

7.5 Exercises
249
3. With the aid of the elementary functions, write the Maclaurin expansion of
the indicated functions of the given order, with Peano’s remainder:
a)
f(x) = x cos 3x −3 sin x ,
n = 2
b)
f(x) = log 1 + x
1 + 3x ,
n = 4
c)
f(x) = ex2 sin 2x ,
n = 5
d)
f(x) = e−x cos x + sin x −cos x ,
n = 2
e)
f(x) =
3
cos(3x −x2) ,
n = 4
f)
f(x) =
x
6√
1 + x2 −sin x ,
n = 5
g)
f(x) = cosh2 x −

1 + 2x2 ,
n = 4
h)
f(x) = e2x −1
√
cos 2x ,
n = 3
i)
f(x) =
1
−
√
8 sin x −2 cosx ,
n = 3
ℓ)
f(x) =
3
8 + sin 24x2 −2(1 + x2 cos x2) ,
n = 4
4. Ascertain order and ﬁnd principal part, for x →0, with respect to ϕ(x) = x
of the indicated functions:
a) f(x) = ecos 2x −e
b)
f(x) = cos 2x + log(1 + 4x2)
cosh 2x
−1
c) f(x) =
√
x3 −sin3 √x
e3√x −1
d)
f(x) = 2x + (x2 −1) log 1 + x
1 −x
e) f(x) = x −arctan
x
√
1 −4x2
f)
f(x) =
3
1 −x2 −

1 −2
3x2 + sin x4
18
5. Calculate order and principal part, when x →+∞, with respect to ϕ(x) = 1
x
of the indicated functions:
a)
f(x) =
1
x −2 −
1
2(x −2) −log(x −1)
b)
f(x) = e−
x
4x2+1 −1
c)
f(x) =
3
1 + 3x2 + x3 −
5
2 + 5x4 + x5
d)
f(x) =
3

2 + sinh 2
x2 −
3√
2
6. Compute the limits:
a)
lim
x→0(1 + x6)1/(x4 sin2 3x)
b) lim
x→2
cos 3
4πx −3
2π log x
2
(4 −x2)2

250
7 Taylor expansions and applications
c)
lim
x→0
1
x

1
sin(tan x) −1
x

d)
lim
x→0

ex7 + sin2 x −sinh2 x
1/x4
e)
lim
x→0
18x4
3√
cos 6x −1 + 6x2
f)
lim
x→0
3x4[log(1 + sinh2 x)] cosh2 x
1 −
√
1 + x3 cos
√
x3
7.
As a varies in R, determine the order of the inﬁnitesimal map
h(x) = log cos x + log cosh(ax)
as x →0.
8.
Compute the sixth derivative of
h(x) = sinh(x2 + 2 sin4 x)
1 + x10
evaluated at x = 0.
9.
Let
ϕ(x) = log(1 + 4x) −sinh 4x + 8x2.
Determine the sign of y = sin ϕ(x) on a left and on a right neighbourhood of
x0 = 0.
10.
Prove that there exists a neighbourhood of 0 where
2 cos(x + x2) ≤2 −x2 −2x3.
11.
Compute the limit
lim
x→0+
ex/2 −cosh √x
(x +
5√x)α
for all values α ∈R+.
12.
Determine α ∈R so that
f(x) = (arctan 2x)2 −αx sin x
is inﬁnitesimal of the fourth order as x →0.
7.5.1 Solutions
1. Taylor’s polynomials:
a) All derivatives of f(x) = ex are identical with the function itself, so f (k)(2) =
e2, ∀k ≥0. Therefore
T f4,2(x) = e2 + e2(x −2) + e2
2 (x −2)2 + e2
6 (x −2)3 + e2
24(x −2)4 .

7.5 Exercises
251
b) T f6, π
2 (x) = 1 −1
2(x −π
2 )2 + 1
4!(x −π
2 )4 −1
6!(x −π
2 )6.
c) From f ′(x) = 1
x, f ′′(x) = −1
x2 , f ′′′(x) = 2
x3 it follows f(3) = log 3, f ′(3) = 1
3,
f ′′(3) = −1
9, f ′′′(3) = 2
27. Then
T f3,3(x) = log 3 + 1
3(x −3) −1
18(x −3)2 + 1
81(x −3)3.
d) T f3,4(x) = 3 + 1
3(x −4) −1
54(x −4)2 +
1
486(x −4)3.
e) As f ′(x) = 1 −6x + 15x2, f ′′(x) = −6 + 30x, we have f(1) = 10, f ′(1) = 10,
f ′′(1) = 24 and
T f2,1(x) = 10 + 10(x −1) + 12(x −1)2.
Alternatively, we may substitute t = x−1, i.e. x = 1+t. The polynomial f(x),
written in the variable t, reads
g(t) = f(1 + t) = 7 + (1 + t) −3(1 + t)2 + 5(1 + t)3 = 10 + 10t + 12t2 + 5t3.
Therefore the Taylor polynomial of f(x) centred at x0 = 1 corresponds to the
Maclaurin polynomial of g(t), whence immediately
T g2,0(t) = 10 + 10t + 12t2.
Returning to the variable x, we ﬁnd the same result.
f) T f3,0(x) = 2 −8x2 + 4x3.
2. Taylor’s expansions:
a) We can write f(x) = g(x) + h(x) using g(x) = x2|x| and h(x) = e2x. The sum
h(x) is diﬀerentiable on R ad libitum, whereas g(x) is continuous on R but
arbitrarily diﬀerentiable only for x ̸= 0. Additionally
g′(x) =
 3x2
if x > 0 ,
−3x2
if x < 0 ,
g′′(x) =
 6x
if x > 0 ,
−6x
if x < 0 ,
so
lim
x→0+ g′(x) = lim
x→0−g′(x) = 0,
lim
x→0+ g′′(x) = lim
x→0−g′′(x) = 0.
By Theorem 6.15 we infer g is diﬀerentiable twice at the origin, with vanishing
derivatives. Since g′′(x) = 6|x| is not diﬀerentiable at x = 0, g is not diﬀeren-
tiable three times at 0, which makes f expandable only up to order 2. From
h′(x) = 2e2x and h′′(x) = 4e2x, we have f(0) = 1, f ′(0) = 2, f ′′(0) = 4, so
Maclaurin’s formula reads:
f(x) = 1 + 2x + 2x2 + o(x2) .

252
7 Taylor expansions and applications
b) The map is diﬀerentiable only once at x0 = 1, and the expansion is f(x) =
3 + (x −1) + o(x −1).
3. Maclaurin’s expansions:
a) f(x) = −2x + o(x2).
b) Writing f(x) = log(1 + x) −log(1 + 3x), we can use the expansion of log(1 + t)
with t = x and t = 3x
f(x) = x −x2
2 + x3
3 −x4
4 −3x + (3x)2
2
−(3x)3
3
+ (3x)4
4
+ o(x4)
= −2x + 4x2 −26
3 x3 + 20x4 + o(x4) .
c) Combining the expansions of et with t = x2, and of sin t with t = 2x:
f(x) =

1 + x2 + x4
2 + o(x5)
 
2x −(2x)3
3!
+ (2x)5
5!
+ o(x5)

= 2x + 2x3 + x5 −4
3x3 −4
3x5 + 4
15x5 + o(x5)
= 2x + 2
3x3 −1
15x5 + o(x5) .
d) f(x) = x2 + o(x2).
e) f(x) = 1 −3
2x2 + x3 −31
24x4 + o(x4).
f) This is solved by expanding (1 + t)α and changing α = −1
6 and t = x2:
x
6√
1 + x2 = x

1 + x2−1/6 = x

1 −1
6x2 +
−1
6
2

x4 + o(x4)

= x −1
6x3 + 7
72x5 + o(x5),
from which
f(x) = x −1
6x3 + 7
72x5 −x + 1
6x3 −1
5!x5 + o(x5) = 4
45x5 + o(x5).
g) Referring to the expansions of coshx and (1 + t)α, with α = 1
2, t = 2x2:
f(x) =

1 + 1
2x2 + 1
4!x4 + o(x4)
2
−

1 + 2x21/2
= 1 + x2 + 1
4x4 + 2
4!x4 + o(x4) −

1 + 1
22x2 +

1/2
2

(2x2)2 + o(x4)

= 1 + x2 + 1
3x4 −1 −x2 + 1
2x4 + o(x4) = 5
6x4 + o(x4) .
h) f(x) = 2x + 2x2 + 10
3 x3 + o(x3).

7.5 Exercises
253
i) Substitute to sin x, cos x the respective Maclaurin expansions, to the eﬀect
that
f(x) =
1
−2 −
√
8x + x2 +
√
8
3! x3 + o(x3)
.
Expansion of the reciprocal eventually gives us
f(x) = −1
2 +
√
2
2 x −5
4x2 + 17
12
√
2 x3 + o(x3) .
ℓ) f(x) = −2x4 + o(x4).
4. Order of inﬁnitesimal and principal part for x →0:
a) The order is 2 and p(x) = −2 e x2 the principal part.
b) Write
h(x) = cos 2x + log(1 + 4x2) −cosh 2x
cosh 2x
,
and note that the order for x →0 can be deduced from the numerator only, for
the denominator converges to 1. The expansions of cos t, log(1 + t) and cosh t
are known, so
cos 2x + log(1 + 4x2) −cosh 2x
= 1 −1
2(2x)2 + 1
4!(2x)4 + (2x)2 −1
2(2x)4 −1 −1
2(2x)2 −1
4!(2x)4 + o(x4)
= −8x4 + o(x4).
Thus the order is 4, the principal part p(x) = −8x4.
c) Expanding sin t and et, then putting t = √x, we have
g(t) = t3 −sin3 t
e3t −1
= t3 −

t −1
6t3 + o(t3)
3
1 + 3t + o(t) −1
=
1
2t5 + o(t5)
3t + o(t)
= 1
6t4 + o(t4)
for t →0. Hence
f(x) = 1
6x2 + o(x2),
implying that the order is 2 and p(x) = 1
6x2.
d) The map has order 3 with principal part p(x) = 4
3x3.
e) Use the expansion of (1 + t)α (where α = −1
2) and arctan t:
(1 −4x2)−1/2 = 1 + 2x2 + o(x3) ,
x
√
1 −4x2 = x + 2x3 + o(x4)
arctan
x
√
1 −4x2 = x + 2x3 + o(x4) −1
3(x −2x3 + o(x4))3 + o(x3)
= x + 5
3x3 + o(x3).

254
7 Taylor expansions and applications
In conclusion,
f(x) = −5
3x3 + o(x3), ,
so that the order is 3 and the principal part p(x) = −5
3x3.
f) Order 6 and principal part p(x) = (−5
34 +
1
2·33 )x6.
5. Order of inﬁnitesimal and principal part as x →+∞:
a) When x →+∞we write
f(x) =
x −2 −log(x −1)
2(x −2)2 −(x −2) log(x −1)
=
x −2 −log(x −1)
2x2 −8x + 8 −(x −2) log(x −1)
=
x + o(x)
2x2 + o(x2) = 1
2x + o
 1
x

,
from which one can recognise the order 1 and the principal part p(x) =
1
2x.
b) The map is inﬁnitesimal of order one, with principal part p(x) = −1
4x.
c) Write
f(x) =
3

x3

1 + 3
x + 1
x3

−
5

x5

1 + 5
x + 2
x5

= x

1 + 3
x + 1
x3
1/3
−x

1 + 5
x + 2
x5
1/5
.
Using the expansion of (1 + t)α ﬁrst with α = 1
3, t = 3
x + 1
x3 , then with α = 1
5,
t = 5
x +
2
x5 , we get
f(x) = x

1 + 1
3
 3
x + 1
x3

−
 1
3
2
  3
x + 1
x3
2
+ o
 1
x2

+
−1 −1
5
 5
x + 2
x5

−
 1
5
2
  5
x + 2
x5
2
+ o
 1
x2

= x
 1
x +
1
3x3 −1
x2 −1
x −
2
5x5 + 2
x2 + o
 1
x2

= x
 1
x2 + o
 1
x2

= 1
x + o
 1
x

.
Therefore the order is 1, and p(x) = 1
x.
d) The order is 2 and p(x) =
3√
2
3x2 .

7.5 Exercises
255
6. Limits:
a) Let us rewrite as
lim
x→0(1 + x6)1/(x4 sin2 3x) = lim
x→0 exp

1
x4 sin2 3x log(1 + x6)

= exp

lim
x→0
log(1 + x6)
x4 sin2 3x

= eL.
To compute L, take the expansions of log(1 + t) and sin t:
L = lim
x→0
x6 + o(x6)
x4(3x + o(x2))2 = lim
x→0
x6 + o(x6)
9x6 + o(x6) = 1
9.
The required limit is e1/9.
b)
3
256π.
c) Expanding the sine and tangent,
L = lim
x→0
x −sin(tan x)
x2 sin(tan x) = lim
x→0
x −tan x + 1
6 tan3 x + o(x3)
x2(tan x + o(x))
= lim
x→0
x −x −1
3x3 + 1
6x3 + o(x3)
x3 + o(x3)
= lim
x→0
−1
6x3 + o(x3)
x3 + o(x3)
= −1
6.
d) e−2/3;
e) −1.
f) Observe that
3x4[log(1 + sinh2 x)] cosh2 x ∼3x4 sinh2 x ∼3x6 .
for x →0. Moreover, the denominator can be written as
Den : 1 −(1 + x3)1/2 cos x3/2
= 1 −

1 + 1
2x3 +

1/2
2

x6 + o(x6)
 
1 −1
2x3 + 1
4!x6 + o(x6)

= 1 −

1 + 1
2x3 −1
8x6 −1
2x3 −1
4x6 + 1
24x6 + o(x6)

= 1
3x6 + o(x6).
The limit is thus
lim
x→0
3x6 + o(x6)
1
3x6 + o(x6) = 9.
7. Expand log(1 + t), cos t, cosh t, so that
h(x) = log

1 −1
2x2 + 1
4!x4 + o(x5)

+ log

1 + 1
2(ax)2 + 1
4!(ax)4 + o(x5)


256
7 Taylor expansions and applications
= −1
2x2 + 1
4!x4 −1
2

−1
2x2 + 1
4!x4
2
+ o(x5) + a2
2 x2 + a4
4! x4 −
−1
2
a2
2 x2 + a4
4! x4
2
+ o(x5)
= 1
2(a2 −1)x2 +
 1
4! −1
8

(a4 + 1)x4 + o(x5).
If a ̸= ±1, h(x) is inﬁnitesimal of order 2 for x →0. If a = ±1 the ﬁrst non-zero
coeﬃcient multiplies x4, making h inﬁnitesimal of order 4 for x →0.
8. In order to compute h(6)(x) at x = 0 we use the fact that the Maclaurin
coeﬃcient of x6 is a6 = h(6)(0)
6!
. Therefore we need the expansion up to order six.
Working on sin t and sinh t, the numerator of h becomes
Num : sinh

x2 + 2

x4 −4
3!x6 + o(x6)

= sinh

x2 + 2x4 −4
3x6 + o(x6)

= x2 + 2x4 −4
3x6 + 1
3!x6 + o(x6)
= x2 + 2x4 −7
6x6 + o(x6).
Dividing x2 + 2x4 −7
6x6 + o(x6) by 1 + x10 one ﬁnds
h(x) = x2 + 2x4 −7
6x6 + o(x6),
so h(6)(0) = −7
6 · 6! = −840.
9. Use the expansions of log(1 + t) and sinh t to write
ϕ(x) = 4x −1
2(4x)2 + 1
3(4x)3 −4x −1
3!(4x)3 + 8x2 + o(x3) = 32
3 x3 + o(x3).
Since the sine has the same sign as its argument around the origin, the function
y = sin ϕ(x) is negative for x < 0 and positive for x > 0.
10. Using cos t in Maclaurin’s form,
2 cos(x + x2) = 2

1 −1
2(x + x2)2 + 1
4!(x + x2)4 + o

(x + x2)4
= 2 −(x2 + 2x3 + x4) +
1
3 · 4x4 + o(x4)
= 2 −x2 −2x3 −11
12x4 + o(x4)
on some neighbourhood I of the origin. Then the given inequality holds on I,
because the principal part of the diﬀerence between right- and left-hand side,
clearly negative, equals −11
12x4.

7.5 Exercises
257
11. Expand numerator and denominator separately as
Num : 1 + 1
2x + 1
2
x
2
2
+ o(x2) −

1 + 1
2x + 1
4!x2 + o(x2)

=
1
8 −1
4!

x2 + o(x2) = 1
12x2 + o(x2) ,
Den :

x1/5 
1 + x4/5α
= xα/5 
1 + x4/5α
= xα/5 
1 + αx4/5 + o(x4/5)

.
Then
lim
x→0+
ex/2 −cosh √x
(x +
5√x)α
= lim
x→0+
1
12x2 + o(x2)
xα/5 
1 + αx4/5 + o(x4/5)

=
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
1
12
if 2 = α
5 ,
0
if 2 > α
5 ,
+∞
if 2 < α
5
=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
1
12
if α = 10 ,
0
if α < 10 ,
+∞
if α > 10.
12. Writing arctan t and sin t in Maclaurin’s form provides
f(x) =

2x −1
3(2x)3 + o(x3)
2
−αx

x −1
6x3 + o(x3)

= 4x2 −32
3 x4 + o(x4) −αx2 + α
6 x4 + o(x4)
= (4 −α)x2 −
32
3 −α
6

x4 + o(x4).
This proves f(x) inﬁnitesimal of the fourth order at the origin if α = 4. For such
value in fact,
f(x) = 10x4 + o(x4).

8
Geometry in the plane and in space
The chapter has two main goals. The ﬁrst is to discuss the possibilities of repres-
enting objects in the plane and in three-dimensional space; in this sense we can
think of this as an ideal continuation of Chap. 1. We shall introduce coordinate
systems other than the Cartesian system, plus vectors and their elementary prop-
erties, and then the set C of complex numbers. Secondly, it is a good occasion for
introducing concepts that will be dealt with in more depth during other lecture
courses, for instance functions of several variables, or the theory of curves in space.
8.1 Polar, cylindrical, and spherical coordinates
A point P in the Cartesian plane can be described, apart from using the known
coordinates (x, y), by polar coordinates (r,θ ), which are deﬁned as follows.
Denote by r the distance of P from the origin O. If r > 0 we let θ be the angle,
measured in radians up to multiples of 2π, between the positive x-axis and the
half-line emanating from O and passing through P, as in Fig. 8.1. It is common to
O
x
y
r
θ
P = (x, y)
Figure 8.1. Polar and Cartesian coordinates in the plane
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_8,
© Springer International Publishing Switzerland 2015

260
8 Geometry in the plane and in space
choose θ in (−π, π], or in [0, 2π). When r = 0, P coincides with the origin, and θ
may be any number.
The passage from polar coordinates (r, θ) to Cartesian coordinates (x, y) is
given by
x = r cos θ ,
y = r sin θ .
(8.1)
The inverse transformation, provided θ is chosen in the interval (−π, π], is
r =

x2 + y2 ,
θ =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
arctan y
x
if x > 0 ,
arctan y
x + π
if x < 0, y ≥0 ,
arctan y
x −π
if x < 0, y < 0 ,
π
2
if x = 0, y > 0 ,
−π
2
if x = 0, y < 0 .
(8.2)
Examples 8.1
i) Let P have Cartesian coordinates (x, y) = (6
√
2, 2
√
6). Its distance from the
origin is
r =
√
72 + 24 =
√
96 = 4
√
6 .
As x > 0,
θ = arctan 2
√
6
6
√
2 = arctan
√
3
3
= π
6 .
The polar coordinates of P are then (r, θ) =

4
√
6, π
6

.
ii) Let now P have Cartesian coordinates (x, y) = (−5, −5). Then r = 5
√
2, and
since x, y < 0,
θ = arctan −5
−5 −π = arctan 1 −π = π
4 −π = −3
4π
whence (r, θ) =

5
√
2, −3
4π

.
iii) Take P of polar coordinates (r, θ) =

4, 2
3π

this time; in the Cartesian
system
x = 4 cos 2
3π = 4 cos

π −π
3

= −4 cos π
3 = −2 ,
y = 4 sin 2
3π = 4 sin

π −π
3

= 4 sin π
3 = 2
√
3 .
2
Moving on to the representation of a point P ∈R3 of coordinates (x, y, z),
we shall introduce two new frame systems: cylindrical coordinates and spherical
coordinates.

8.1 Polar, cylindrical, and spherical coordinates
261
The cylindrical system is simply given by replacing the coordinates (x, y) of
the point P ′, orthogonal projection of P on the xy-plane, by its polar ones (r′, θ),
and mantaining z as it is. Denoting (r′, θ, t) the cylindrical coordinates of P,
we have
x = r′ cos θ ,
y = r′ sin θ ,
z = t .
In this case too the angle θ is deﬁned up to multiples of 2π; if we conﬁne θ to the
interval (−π, π], as above, cylindrical coordinates are functions of the Cartesian
ones by deﬁning r′ and θ with (8.2) (Fig. 8.2, left).
Spherical coordinates (r, ϕ, θ) are deﬁned as follows. Let r =

x2 + y2 + z2
be the distance of P from the origin, ϕ the angle between the positive z-axis and
the ray from O through P, θ the angle between the positive x-axis and the line in
the xy-plane passing through the origin and the projection P ′ of P on the same
plane. This is probably better understood by looking at Fig. 8.2, right. Borrowing
terms from geography, one calls θ the longitude and ϕ the colatitude of P
(whereas π
2 −ϕ is the latitude, in radians).
Therefore z = r cos ϕ, while the expressions x = r′ cos θ and y = r′ sin θ derive
from noting that r′ is the distance of P ′ from O, r′ = r sin ϕ. Then the Cartesian
coordinates of P are, in terms of the spherical triple (r, ϕ, θ),
x = r sin ϕ cos θ ,
y = r sin ϕ sin θ ,
z = r cos ϕ .
The inverse transformation is easily found by dimensional reduction. We just re-
mark that it is enough to vary ϕ in an interval of width π, e.g. [0, π]. Instead, θ
has freedom 2π, for instance θ ∈(−π, π], as in the 2-dimensional case.
x
O
y
z
r′
θ
P = (x, y, z)
P ′ = (x, y, 0)
x
O
y
z
r
r′
θ
ϕ
P = (x, y, z)
P ′ = (x, y, 0)
Figure 8.2. Cylindrical coordinates (left) and spherical coordinates (right)

262
8 Geometry in the plane and in space
Example 8.2
Consider the point P of Cartesian coordinates (1, 1,
√
6). The point P ′ = (1, 1, 0)
is the orthogonal projection of P onto the xy-plane, so its polar coordinates are
(r′, θ) =
√
2, π
4

in that plane. The cylindrical coordinates of P are therefore
(r′, θ, t) =
√
2, π
4 ,
√
6

.
Now to spherical coordinates. First, r = √1 + 1 + 6 = 2
√
2; moreover, sin ϕ =
√
2
2
√
2 = 1
2 implies ϕ = π/6, because ϕ varies in [0, π]. Therefore P has coordinates
(r, θ, ϕ) =

2
√
2, π
4 , π
6

.
2
8.2 Vectors in the plane and in space
We discuss the basics of Vector Calculus, which focuses on vectors and how they
add, multiply, and so on. We start with vectors whose initial point is the origin,
and later generalise this situation to arbitrary initial points in the plane or in
space.
8.2.1 Position vectors
Equip the plane with an orthogonal frame system. A pair (x, y) ̸= (0, 0) in R2
identiﬁes a position vector (or just vector) v in the plane, given by the line
segment with initial point O = (0, 0) and end point P = (x, y), see Fig. 8.3, left.
(The orientation from O to P is indicated by an arrow with point at P.)
The coordinates x, y of P are said components of the vector v (in the chosen
frame system); one writes v = (x, y), identifying the vector v with its end point P.
Position vectors in space are deﬁned in a similar fashion: a vector v with
components (x, y, z) ̸= (0, 0, 0) is drawn as the oriented segment going from O =
(0, 0, 0) to P = (x, y, z) (Fig. 8.3, right), so one writes v = (x, y, z).
v
P = (x, y)
O
v
P = (x, y, z)
O
Figure 8.3. A vector in the plane (left), and in space (right)

8.2 Vectors in the plane and in space
263
In space or in the plane, the vector 0 with components all zero is called the
zero vector; it is identiﬁed with the origin and has no arrow. In this way position
vectors in the plane (or in space) are in bijective correspondence with points of
R2 (resp. R3). Henceforth we shall not specify every time whether we are talking
about planar or spatial vectors: the generic v, of components (v1, v2) or (v1, v2, v3),
will be described with (v1, . . . , vd). The capital letter V will be the set of vectors
of the plane or of space, with no distinction.
Having ﬁxed the origin point O, a vector is intrinsically determined (irrespect-
ive of the chosen Cartesian frame) by a direction, the straight line through the
origin and containing the vector, an orientation, the direction given by the arrow,
and a length or norm, the actual length of the segment OP. Rather often the
notion of direction tacitly includes an orientation as well.
Let us deﬁne operations. Take vectors v = (v1, . . . , vd) and w = (w1, . . . , wd).
The sum of v and w is the vector v + w whose components are given by the sum
of the corresponding (i.e., with the same subscript) components of the two original
vectors
v + w = (v1 + w1, . . . , vd + wd) .
(8.3)
In Vector Calculus real numbers λ ∈R are referred to as scalars. The product
of the vector v by (the scalar) λ is the vector λv, whose jth component is the
product of the jth component of v by λ
λv = (λv1, . . . , λvd) .
(8.4)
The product (−1)v is denoted −v and said opposite vector to v. The diﬀerence
v −w is deﬁned as
v −w = v + (−w) = (v1 −w1, . . . , vd −wd) .
(8.5)
The operations just introduced enjoy the familiar properties of the sum and the
product (associative, commutative, distributive, . . . ), due to their component-wise
nature.
These operations have also a neat geometric interpretation. If λ > 0, the vector
λv has the same direction (and orientation) as v, i.e., it lies on the same (oriented)
straight line, and its length is λ times the length of v (see Fig. 8.4); if λ < 0,
λv = −|λ|v = |λ|(−v) so the same argument applies to −v. Two vectors v and w
are parallel, or collinear, if w = λv for a λ ̸= 0.
The sum of non-zero position vectors v and w should be understood as follows.
When the two vectors are collinear, w = λv, then v + w = (1 + λ)v, parallel to
both of them. Otherwise, v and w lie on distinct straight lines, say rv and rw, that
meet at the origin. Let Π be the plane determined by these lines (if v and w are
vectors in the plane, clearly Π is the plane); v and w determine a parallelogram on
Π (Fig. 8.5). Precisely, let P, Q be the end points of v and w. The parallelogram
in question is then enclosed by the lines rv, rw, the parallel to rw through P and

264
8 Geometry in the plane and in space
v
λv
P = (x, y)
Q = (λx, λy)
O
Figure 8.4. The vectors v and λv
the parallel to rv through Q; its vertices are O, P, Q and R, the vertex ‘opposite’
the origin. The sum v + w is then the diagonal OR, oriented from O to R. The
vertex R can be reached by ‘moving’ along the sides: for instance, we can start at
P and draw a segment parallel to OQ, having the same length, and lying on the
same side with respect to rv.
Figure 8.6 represents the diﬀerence v−w: the position vector v−w = v+(−w)
is the diagonal of the parallelogram determined by vectors v, −w. Alternatively,
we can take the diagonal QP and displace it ‘rigidly’ to the origin, i.e., keeping it
parallel to itself, ﬁnding v −w.
The set V of vectors (in the plane or in space), equipped with the operations
of sum and multiplication by a scalar, is an example of a vector space over
R. Any vector v = λv1 + μv2, with v1, v2 ∈V and λ, μ ∈R is called a linear
combination of the two vectors v1 and v2. This generalises to linear combinations
of a ﬁnite number of vectors.
v
w
v + w
P
O
Q
R
rv
rw
Figure 8.5. Sum of two vectors v + w

8.2 Vectors in the plane and in space
265
v
w
−w
v −w
P
O
Q
R
Q′
R′
Figure 8.6. Diﬀerence vector v −w
Examples 8.3
i) Given vectors v1 = (2, 5, −4) and v2 = (−1, 3, 0), the sum v = 3v1 −5v2 is
v = (11, 0, −12).
ii) The vectors v = (
√
8, −2, 2
√
5) and w = (2, −
√
2,
√
10) are parallel, since the
ratios of the corresponding components is always the same:
√
8
2
=
−2
−
√
2 = 2
√
5
√
10 =
√
2 ;
hence v =
√
2 w.
2
8.2.2 Norm and scalar product
The norm of a position vector v with end point P is deﬁned, we recall, as the
length of OP , i.e., the Euclidean distance of P to the origin. It is denoted by the
symbol ∥v∥and can be expressed in terms of v’s components like
∥v∥=
 
!
!
"
d
	
i=1
v2
i =
⎧
⎨
⎩

v2
1 + v2
2
if d = 2 ,

v2
1 + v2
2 + v2
3
if d = 3 .
The norm of a vector is always non-negative, and moreover ∥v∥= 0 if and only if
v = 0. The following relations hold, proof of which will be given on p. 269:
∥λv∥= |λ| ∥v∥,
∥v + w∥≤∥v∥+ ∥w∥
(8.6)
for any v, w ∈V and any λ ∈R.
A vector of norm 1 is called unit vector, and geometrically, it has end point
P lying on the unit circle or unit sphere centred at the origin. Each vector v has

266
8 Geometry in the plane and in space
a corresponding unit vector ˆv =
v
∥v∥, parallel to v. Thus v = ∥v∥ˆv, showing that
any vector can be represented as the product of a unit vector by its own length.
Let us introduce the operation known as scalar product, or dot product of
two vectors. Given v = (v1, . . . , vd) and w = (w1, . . . , wd), their dot product is the
real number
v · w =
d
	
i=1
viwi =
 v1w1 + v2w2
if d = 2 ,
v1w1 + v2w2 + v3w3
if d = 3 .
Easy-to-verify properties are:
v · w = w · v ,
(8.7)
(λv1 + μv2) · w = λ(v1 · w) + μ(v2 · w) .
(8.8)
for any v, w, v1, v2 ∈V, λ, μ ∈R.
A vector’s norm may be deﬁned from the scalar product, as
∥v∥= √v · v
(8.9)
for any v ∈V . Vice versa, for any v, w ∈V , one has
v · w = 1
2

∥v + w∥2 −∥v∥2 −∥w∥2
,
(8.10)
which allows to compute scalar products using norms (see p. 269 for the proof).
Furthermore, a fundamental relation, known as Cauchy-Schwarz inequality,
holds: for every v, w ∈V
|v · w| ≤∥v∥∥w∥.
(8.11)
Even more precisely,
v · w = ∥v∥∥w∥cos θ
(8.12)
where θ is the angle formed by v and w (whether θ is the clockwise, anti-clockwise,
acute or obtuse angle is completely irrelevant, for cosθ = cos(−θ) = cos(2π −θ)).
Formulas (8.11) and (8.12) as well will be proved later.
The dot product leads to the notion of orthogonality. Two vectors v, w are
said orthogonal (or perpendicular) if
v · w = 0 ;
formula (8.12) tells that two vectors are orthogonal when either one is the zero
vector, or the angle between them is a right angle. By (8.10), the orthogonality of
v and w is equivalent with
∥v + w∥2 = ∥v∥2 + ∥w∥2 ,

8.2 Vectors in the plane and in space
267
v
w
v + w
P
O
Q
R
Figure 8.7. Pythagoras’s Theorem
well known to the reader under the name Pythagoras’s Theorem (Fig. 8.7).
Given a vector v and a unit vector u, the component of v along u is the
vector
vu = (v · u) u ,
while the component of v orthogonal to u is the complement
vu⊥= v −vu .
Therefore the vector v splits as a sum
v = vu + vu⊥
with
vu · vu⊥= 0 ,
(8.13)
a relation called orthogonal decomposition of v with respect to the unit vector
u (Fig. 8.8).
v
u
vu
vu⊥
P
O
Figure 8.8. Orthogonal decomposition of v with respect to the unit vector u

268
8 Geometry in the plane and in space
i
j
k
x
y
z
Figure 8.9. The unit vectors i, j, k
Examples 8.4
i) v = (1, 0,
√
3) and w = (1, 2,
√
3) have norm
∥v∥=
√
1 + 0 + 3 = 2 ,
∥w∥=
√
1 + 4 + 3 = 2
√
2 ;
their scalar product is v · w = 1 + 0 + 3 = 4.
To compute the angle θ they form, we recover from (8.12)
cos θ =
v · w
∥v∥∥w∥=
√
2
2 ,
so θ = π
4 .
ii) The vectors v = (1, 2, −1), w = (−1, 1, 1) are orthogonal since v · w =
−1 + 2 −1 = 0.
iii) Take the unit vector u =

1
√
3,
1
√
3, −1
√
3

. Given v = (3, 1, 1), we have
v · u =
√
3 + 1
√
3 −1
√
3 =
√
3,
so the component of v along u is
vu =
√
3
 1
√
3, 1
√
3, −1
√
3

= (1, 1, −1) ,
while the orthogonal component reads
vu⊥= (3, 1, 1) −(1, 1, −1) = (2, 0, 2) .
That (8.13) holds is now easy to check.
2
We introduce the unit vectors i = (1, 0, 0), j = (0, 1, 0) and k = (0, 0, 1) of
space, which are parallel to the axes of the Cartesian frame (Fig. 8.9); at times
these unit vectors are denoted e1, e2, e3. They are clearly pairwise orthogonal
i · j = j · k = i · k = 0 .
(8.14)
They form a so-called orthonormal frame for V (by deﬁnition, a set of pairwise
orthogonal unit vectors).

8.2 Vectors in the plane and in space
269
Let v = (v1, v2, v3) be arbitrary. Since
v = (v1, 0, 0) + (0, v2, 0) + (0, 0, v3)
= v1(1, 0, 0) + v2(0, 1, 0) + v3(0, 0, 1)
we write
v = v1i + v2j + v3k .
This explains that any vector in space can be represented as a linear combination
of the unit vectors i, j, k, whence the latter triple forms an orthonormal basis of
V . The dot product of v with the orthonormal vectors i, j, k yields the components
of v
v1 = v · i ,
v2 = v · j ,
v3 = v · k .
Summarising, a generic vector v ∈V admits the representation
v = (v · i) i + (v · j) j + (v · k) k .
(8.15)
Similarly, planar vectors can be represented by
v = (v · i) i + (v · j) j
with respect to the orthonormal basis made by i = (1, 0) and j = (0, 1) .
Proofs of some formulas above
Proof.
We start from (8.6). The equality follows from the deﬁnition of norm. The
inequality descends from the deﬁnition in case v and w are collinear; for
generic v, w instead, it states a known property of triangles, according to
which any side is shorter than the sum of the other two. In the triangle
OPR of Fig. 8.5 in fact, ∥v + w∥= |OR|, ∥v∥= |OP| and ∥w∥= |PR|.
Formula (8.10) derives from expanding ∥v + w∥2 using (8.7)–(8.9) as fol-
lows:
∥v + w∥2 = (v + w) · (v + w)
= v · v + w · v + v · w + w · w
= ∥v∥2 + 2v · w + ∥w∥2 .
(8.16)
The Cauchy-Schwarz inequality (8.11) can be proved by writing the second
of (8.6) as ∥v + w∥2 ≤

∥v∥+ ∥w∥
2. For the left-hand side we use (8.16),
so that v · w ≤∥v∥∥w∥; but the latter is (8.11) in case v · w ≥0. When
v · w < 0, it suﬃces to ﬂip the sign of v, to the eﬀect that
|v · w| = −v · w = (−v) · w ≤∥−v∥∥w∥= ∥v∥∥w∥.
Eventually, let us prove (8.12). Suppose v and w are non-zero vectors
(for otherwise the relation is trivially satisﬁed by any θ). Without loss of
generality we may assume 0 ≤θ ≤π. Let u = ˆ
w =
w
∥w∥be the unit vector
corresponding to w. Then the component of v along u is
vu = v · w
∥w∥u .
(8.17)

270
8 Geometry in the plane and in space
w
u
v
vu
P
O
Q
θ
P ′
w
u
v
vu
P
O
Q
θ
P ′
Figure 8.10. Projection of v along w (the angle formed by the vectors is acute on the
left, obtuse on the right)
Suppose ﬁrst that 0 < θ < π/2. In the triangle OP ′P (Fig. 8.10, left)
∥vu∥= |OP ′| = |OP| cos θ = ∥v∥cosθ; as vu has the same orientation as
u, we have
vu = ∥v∥cosθ u .
(8.18)
If θ is obtuse instead, in Fig. 8.10, right, we have ∥vu∥= ∥v∥cos(π −θ) =
−∥v∥cosθ; precisely because now vu has opposite sign to u, (8.18) still
holds. In the remaining cases θ = 0, π/2, π it is not hard to reach the
same conclusion. Comparing (8.17) and (8.18), and noting λv = μv means
λ = μ if v ̸= 0, we ﬁnally get to
v · w
∥w∥= ∥v∥cosθ,
whence (8.12).
2
8.2.3 General vectors
Many applications involve vectors at points diﬀerent from the origin, like forces in
physics acting on a point-particle. The general notion of vector can be deﬁned as
follows.
Let v be a non-zero position vector of components (v1, v2), and P0 an arbit-
rary point of the plane, with coordinates (x01, x02). Deﬁne P1 by the coordinates
(x11, x12) = (x01 + v1, x02 + v2), as in Fig. 8.11. The line segment P0P1 from P0
to P1 is parallel to v and has the same orientation. We say that it represents
the vector v at P0, and we write (P0, v). Vice versa, given any segment going
from P0 = (x01, x02) to P1 = (x11, x12), we deﬁne the vector v of components
(v1, v2) = (x11 −x01, x12 −x02). The segment identiﬁes the vector v at P0.
A general vector in the plane is mathematically speaking a pair (P0, v), whose
ﬁrst component is a point P0 of the plane, and whose second component is a

8.3 Complex numbers
271
v
(P0, v)
(P0, v)
(P0, v)
P0
P0
P0
P1
P1
P1
O
Figure 8.11. The position vector v and the same vector at P0
position vector v. Normally though, and from now onwards, the vector (P0, v)
shall be denoted simply by v; we will make the initial point P0 explicit only if
necessary. Analogous considerations are valid for vectors in space.
The operations on (position) vectors introduced earlier carry over to vectors
with the same initial point. The vectors (P0, v) and (P0, w) add up to (P0, v) +
(P0, w), equal to (P0, v + w) by deﬁnition. Operations between vectors at diﬀerent
points are not deﬁned, at least in this context.
8.3 Complex numbers
According to conventional wisdom, not every algebraic equation
p(x) = 0
(p being a polynomial of degree n in x) admits solutions in the ﬁeld of real numbers.
The simplest example is given by p(x) = x2 + 1, i.e., the equation
x2 = −1 .
(8.19)
This would prescribe to take the square root of the negative number −1, and it is
well known this is not possible in R. The same happens for the generic quadratic
equation
ax2 + bx + c = 0
(8.20)
when the discriminant Δ = b2 −4ac is less than zero. The existence of solutions of
algebraic equations needs to be guaranteed both in pure and applied Mathematics.
This apparent deﬁciency of real numbers is overcome by enlarging R to a set,
called complex numbers, where adding and multiplying preserve the same formal
properties of the reals. Obviously deﬁning this extension-of-sorts so to contain
the roots of every possible algebraic equations might seem daunting. The good
news is that considering equation (8.19) only is suﬃcient in order to solve any
algebraic equation, due to a crucial and deep result that goes under the name of
Fundamental Theorem of Algebra.

272
8 Geometry in the plane and in space
8.3.1 Algebraic operations
A complex number z can be deﬁned as an ordered pair z = (x, y) of real numbers
x, y. As such, the set of complex numbers C can be identiﬁed with R2. The reals
x and y are the real part and the imaginary part of z
x = Re z
and
y = Im z
respectively. The subset of complex numbers of the form (x, 0) is identiﬁed with
R, and with this in mind one is entitled to write R ⊂C. Complex numbers of the
form (0, y) are called purely imaginary.
Two complex numbers z1 = (x1, y1), z2 = (x2, y2) are equal if they have
coinciding real and imaginary parts
z1 = z2
⇐⇒
x1 = x2
and
y1 = y2 .
Over C, we deﬁne the sum and product of two numbers by
z1 + z2 = (x1, y1) + (x2, y2) = (x1 + x2, y1 + y2)
(8.21)
z1 z2 = (x1, y1) (x2, y2) = (x1 x2 −y1 y2, x1 y2 + x2 y1) .
(8.22)
Notice
(x, 0) + (0, y) = (x, y) ,
(0, 1) (y, 0) = (0, y),
so
(x, y) = (x, 0) + (0, 1) (y, 0) .
(8.23)
Moreover, (8.21) and (8.22) are old acquaintances when restricted to the reals:
(x1, 0) + (x2, 0) = (x1 + x2, 0)
and
(x1, 0) (x2, 0) = (x1 x2, 0) .
In this sense complex numbers are a natural extension of real numbers.
Introduce the symbol i to denote the purely imaginary number (0, 1). By identi-
fying (r, 0) with the real number r, (8.23) reads
z = x + iy ,
called Cartesian form or algebraic form of z = (x, y).
Observe that
i2 = (0, 1) (0, 1) = (−1, 0) = −1 ,
so the complex number i is a root of equation (8.19). The sum (8.21) and multi-
plication (8.22) of complex numbers in Cartesian form become
z1 + z2 = (x1 + iy1) + (x2 + iy2) = x1 + x2 + i(y1 + y2) ,
(8.24)

8.3 Complex numbers
273
z1 z2 = (x1 + iy1) (x2 + iy2) = x1 x2 −y1 y2 + i(x1 y2 + x2 y1) .
(8.25)
The recipe is to use the familiar rules of algebra, taking the relation i2 = −1 into
account.
The next list of properties is left to the reader to check:
z1 + z2 = z2 + z1 ,
z1 z2 = z2 z1 ,
(z1 + z2) + z3 = z1 + (z2 + z3) ,
(z1 z2) z3 = z1 (z2 z3) ,
z1 (z2 + z3) = z1 z2 + z1 z3
for any z1, z2, z3 ∈C. The numbers 0 = (0, 0) and 1 = (1, 0) are the additive and
multiplicative units respectively, because
z + 0 = 0 + z = z
and
z 1 = 1 z = z ,
∀z ∈C .
The opposite or negative of z = (x, y) is the complex number −z = (−x, −y),
in fact z + (−z) = 0. With this we can deﬁne, for any z1, z2 ∈C, the diﬀerence:
z1 −z2 = z1 + (−z2)
or, equivalently,
x1 + iy1 −(x2 + iy2) = x1 −x2 + i(y1 −y2) .
The inverse or reciprocal of a complex number z ̸= 0, denoted 1
z or z−1, is given
by the relation zz−1 = 1, and it is easy to see
1
z = z−1 =
x
x2 + y2 + i
−y
x2 + y2 .
The formula
z1
z2
= z1 z−1
2
= x1 x2 + y1 y2
x2
2 + y2
2
+ i x2 y1 −x1 y2
x2
2 + y2
2
deﬁnes the ratio or quotient of z1, z2 ∈C with z2 ̸= 0.
At last, let us remark that the ordering of real numbers cannot be extended to
C to preserve the compatibility properties of Sect. 1.3.1 in any way.
8.3.2 Cartesian coordinates
With the identiﬁcation of C and R2, it becomes natural to associate the number
z = (x, y) = x + iy to the point of coordinates x and y in the Cartesian plane
(Fig. 8.12). The point z can also be thought of as the position vector having end
point at z. The horizontal axis of the plane is called real axis and the vertical
axis imaginary axis. For any z1, z2 ∈C the sum z1 + z2 corresponds to the
vector obtained by the parallelogram rule (as in Fig. 8.13, left), while z1 −z2 is
represented by the diﬀerence vector (same ﬁgure, right).

274
8 Geometry in the plane and in space
Re z
Im z
x
y
z = x + iy
Figure 8.12. Cartesian coordinates of the complex number z = x + iy
The modulus (or absolute value) of z = x + iy, denoted |z|, is the non-
negative number
|z| =

x2 + y2
representing the distance of (x, y) from the origin; non-incidentally, this deﬁnition
is the same as that of norm of the vector v associated to z, |z| = ∥v∥. Moreover, if
a complex number is real, its modulus is the absolute value as of Sect. 1.3.1. This
justiﬁes the choice of name, and explains why the absolute value of a real number is
sometimes called modulus. We point out that, whereas the statement z1 < z2 has
no meaning, the inequality |z1| < |z2| does, indeed the point (corresponding to) z1
is closer to the origin than the point z2. The distance of the points corresponding
to z1 and z2 is |z1 −z2|.
Given z ∈C, the following are easy:
|z| ≥0 ;
|z| = 0 if and only if z = 0 ;
|z|2 = (Re z)2 + (Im z)2 ;
Re z ≤|Re z| ≤|z| ,
Im z ≤|Im z| ≤|z| ;
|z1| −|z2|
 ≤|z1 + z2| ≤|z1| + |z2| .
Re z
Im z
z1
z2
z1 + z2
Re z
Im z
z1
z2
z1 −z2
Figure 8.13. Sum (left) and diﬀerence (right) of complex numbers

8.3 Complex numbers
275
The complex conjugate, or just conjugate, of z = x + iy is the complex
number
¯z = x −iy .
(8.26)
On the plane, the conjugate ¯z is the point (x, −y) obtained by reﬂection of (x, y)
with respect to the real axis. The following properties hold for any z, z1, z2 ∈C:
¯z = z ,
|¯z| = |z| ,
z ¯z = |z|2 ,
z1 + z2 = ¯z1 + ¯z2 ,
z1 −z2 = ¯z1 −¯z2 ,
z1 z2 = ¯z1 ¯z2 ,
z1
z2

= ¯z1
¯z2
(z2 ̸= 0) .
(8.27)
Of immediate proof is also
Re z = z + ¯z
2
,
Im z = z −¯z
2i
,
for all z ∈C.
8.3.3 Trigonometric and exponential form
Let r and θ be the polar coordinates of the point (x, y). Since
x = r cos θ
and
y = r sin θ ,
the number z = (x, y) has a polar form, also called trigonometric,
z = r (cos θ + i sin θ) .
(8.28)
First of all, r = |z|. The number θ, denoted by θ = arg z, is said argument of
z (less often, but to some more suggestively, ‘amplitude’). Geometrically arg z is
an angle (in radians) delimited by the positive real axis and the direction of the
position vector z (as in Fig. 8.14).
Re z
Im z
x
y
r
θ
z = x + iy
Figure 8.14. Polar coordinates of the number z = x + iy

276
8 Geometry in the plane and in space
The argument can assume inﬁnitely many values, all diﬀering by integer mul-
tiples of 2π. One calls principal value of arg z, and denotes by the capitalised
symbol Arg z, the unique value θ of arg z such that −π < θ ≤π; the principal
value is deﬁned analytically by (8.2).
Two complex numbers z1 = r1(cos θ1 + i sin θ1) and z2 = r2(cos θ2 + i sin θ2)
are equal if and only if r1 = r2 and θ1, θ2 diﬀer by an integer multiple of 2π.
The representation in polar form is useful to multiply complex numbers, and
consequently, to compute powers and nth roots. Let in fact
z1 = r1 (cos θ1 + i sin θ1)
and
z2 = r2 (cos θ2 + i sin θ2) ;
the addition formulas for trigonometric functions tell us that
z1 z2 = r1 r2
#
(cos θ1 cos θ2 −sin θ1 sin θ2) + i(sin θ1 cos θ2 + sin θ2 cos θ1)
$
= r1 r2
#
cos(θ1 + θ2) + i sin(θ1 + θ2)
$
.
(8.29)
Therefore
arg (z1 z2) = arg z1 + arg z2 .
(8.30)
Note that this identity is false when using Arg : take for instance z1 = −1 =
cos π + i sin π and z2 = i = cos π
2 + i sin π
2 , so
z1 z2 = −i = cos

−π
2

+ i sin

−π
2

,
i.e.,
Arg z1 = π ,
Arg z2 = π
2 ,
Arg z1 + Arg z2 = 3
2π ̸= Arg z1 z2 = −π
2 .
The so-called exponential form is also useful. To deﬁne it, let us extend
the exponential function to the case where the exponent is purely imaginary, by
putting
eiθ = cos θ + i sin θ
(8.31)
for any θ ∈R. Such a relation is sometimes called Euler formula, and can be
actually proved within the theory of series over the complex numbers. We shall
take it as deﬁnition without further mention. The expression (8.28) now becomes
z = reiθ ,
(8.32)
the exponential form of z. The complex conjugate of z is
¯z = r(cos θ −i sin θ) = r(cos(−θ) + i sin(−θ)) = re−iθ
in exponential form.
Then (8.29) immediately furnishes the product of z1 = r1eiθ1 and z2 = r2eiθ2
z1 z2 = r1 r2 ei(θ1+θ2) .
(8.33)

8.3 Complex numbers
277
Thus the moduli are multiplied, the arguments added. To divide complex numbers
(8.29) gives, with r1 = r2 = 1,
eiθ1eiθ2 = ei(θ1+θ2) .
(8.34)
In particular,
eiθe−iθ = 1
so e−iθ is the inverse of eiθ. The reciprocal of z = reiθ ̸= 0 is then
z−1 = 1
r e−iθ .
(8.35)
Combining this formula with the product one shows that the ratio of z1 = r1eiθ1
and z2 = r2eiθ2 ̸= 0 is
z1
z2
= r1
r2
ei(θ1−θ2) .
(8.36)
8.3.4 Powers and nth roots
Re-iterating (8.33) and (8.35) we obtain, for any n ∈Z,
zn = rn einθ .
(8.37)
For r = 1, this is the so-called De Moivre’s formula
(cos θ + i sin θ)n = cos nθ + i sin nθ .
(8.38)
By (8.37) we can calculate nth roots of a complex number. Fix n ≥1 and a
complex number w = ρ eiϕ, and let us determine the numbers z = r eiθ such that
zn = w. Relation (8.37) implies
zn = rn einθ = ρ eiϕ = w,
which means
 rn = ρ ,
nθ = ϕ + 2kπ ,
k ∈Z ,
hence
 r =
n√ρ ,
θ = ϕ + 2kπ
n
,
k ∈Z .
The expression of θ does not necessarily give the principal values of the roots’ ar-
guments. Nevertheless, as sine and cosine are periodic, we have n distinct solutions
zk =
n√ρ ei ϕ+2kπ
n
=
n√ρ

cos ϕ + 2kπ
n
+ i sin ϕ + 2kπ
n

,
k = 0, 1, . . . , n −1

278
8 Geometry in the plane and in space
Re z
Im z
1 +
√
3i
z0
z1
z2
z3
z4
Figure 8.15. The point 1 +
√
3i and its ﬁfth roots zj, j = 0, . . . , 4
to the problem. These points lie on the circle centred at the origin with radius
n√ρ; they are precisely the vertices of a regular polygon of n sides (an ‘n-gon’, see
Fig. 8.15).
Examples 8.5
i) For n ≥1 consider the equation
zn = 1 .
Writing 1 = 1ei0 we obtain the n distinct roots
zk = ei 2kπ
n ,
k = 0, 1, . . . , n −1,
called nth roots of unity. When n is odd, only one of these is real, z0 = 1, whilst
for n even there are two real roots of unity z0 = 1 and zn/2 = −1 (Fig. 8.16).
ii) Verify that
z2 = −1
admits, as it should, the solutions z± = ±i. Write −1 = 1eiπ, from which
z+ = z0 = ei π
2 = i
and
z−= z1 = ei π+2π
2
= e−i π
2 = −i .
2
Note ﬁnally that (8.31) permits to deﬁne the exponential of arbitrary (not only
imaginary) complex numbers z = x + iy, by letting
ez = exeiy = ex(cos y + i sin y) .
(8.39)

8.3 Complex numbers
279
Re z
Im z
z0
z1
z2
Re z
Im z
z0
z1
z2
z3
z4
z5
Figure 8.16. Roots of unity: cubic roots (left) and sixth roots (right)
Using (8.34) it is now an easy task to verify that the fundamental relation ez1+z2 =
ez1ez2 is still valid in the realm of complex numbers. In addition to that,
|ez| = eRe z > 0 ,
arg ez = Im z .
The ﬁrst tells, amongst other things, that ez ̸= 0 for any z ∈C. The periodicity
of the trigonometric functions implies
ez+2kπi = ez ,
for all k ∈Z .
8.3.5 Algebraic equations
We will show that the quadratic equation with real coeﬃcients
az2 + bz + c = 0
admits two complex-conjugate solutions in case the discriminant Δ is negative.
We can suppose a > 0. Inspired by the square of a binomial we write
0 = z2 + b
az + c
a =

z2 + 2 b
2az + b2
4a2

+ c
a −b2
4a2 ,
that is

z + b
2a
2
= Δ
4a2 < 0 .
Therefore
z + b
2a = ±i
√
−Δ
2a
,
or
z = −b ± i
√
−Δ
2a
.
We write this as z = −b ±
√
Δ
2a
, in analogy to the case Δ ≥0.

280
8 Geometry in the plane and in space
The procedure may be applied when the coeﬃcients a ̸= 0, b and c are complex
numbers, as well. Thus
z = −b ±
√
b2 −4ac
2a
are the two solutions of the equation az2 + bz + c = 0 in the greatest possible
generality.
Third- and fourth-degree algebraic equations have three and four solutions re-
spectively (counted with multiplicity): these roots can be made explicit via algeb-
raic operations, namely square and cubic roots1. There can be instead no analytic
expression for solving an equation of ﬁfth degree or higher. Despite all though, the
Fundamental Theorem of Algebra warrants that every algebraic equation p(z) = 0,
where p is a polynomial of degree n with real or complex coeﬃcients, admits ex-
actly n solutions in C, each counted with its multiplicity. This is how it goes.
Theorem 8.6 Let p(z) = anzn +. . .+a1z +a0, with an ̸= 0, be a polynomial
of degree n with coeﬃcients ak ∈C, 0 ≤k ≤n. There exist m ≤n distinct
complex numbers z1, . . . , zm, and m non-zero natural numbers μ1, . . . , μm with
μ1 + . . . + μm = n, such that p(z) factorises as
p(z) = an(z −z1)μ1 . . . (z −zm)μm.
The numbers zk are the roots of the polynomial p, in other words the solutions of
p(z) = 0; the exponent μk is the multiplicity of the root zk. A root is simple if it
has multiplicity one, double if the muliplicity is 2, and so on.
It is opportune to remark that if the coeﬃcients of p are real and if z0 is a
complex root, then also ¯z0 is a root of p. In fact, taking conjugates of p(z0) = 0
and using known properties (see (8.27)), we obtain
0 = ¯0 = p(z0) = ¯an¯zn
0 + . . . + ¯a1¯z0 + ¯a0 = an¯zn
0 + . . . + a1¯z0 + a0 = p(¯z0) .
The polynomial p(z) is then divisible by (z −z0)(z −¯z0), a quadratic polynomial
with real coeﬃcients.
A version of the Fundamental Theorem of Algebra for real polynomials, that
does not involve complex numbers, is stated in Theorem 9.15.
1 The cubic equation x3+ax2+bx+c = 0 for example, reduces to the form y3+py+q = 0,
by changing x = y −a
3 ; p and q are suitable coeﬃcients, which are easy to ﬁnd. The
solutions of the reduced equation read
y =
3

−q
2 +

q2
4 + p3
27 −
3

q
2 +

q2
4 + p3
27 ,
a formula due to Cardano. Extracting a root yields as many solutions as the order of
the root (here 2 or 3), yielding a maximum of 12 solutions, at least in principle: it is
possible to prove that at most 3 of them are distinct.

8.4 Curves in the plane and in space
281
8.4 Curves in the plane and in space
The second part of the chapter sees the return of functions, and the present section
devotes itself in particular to the notion of a curve in Euclidean space or on the
plane. A curve can describe the boundary of a planar region such as a polygon, or
an ellipse; it is a good model for the trajectory of a point-particle moving in time
under the eﬀect of a force. In Chap. 10 we shall see how to perform integral calculus
along curves, which enables to describe mathematically the notion of work, to stay
with the physical analogy.
Let I be an arbitrary interval of the real line and γ : I →R3 a map. Denote
by γ(t) =

x(t), y(t), z(t)

the point of R3 image of t ∈I under γ. One says γ is a
continuous map on I if the components x, y, z : I →R are continuous functions.
Deﬁnition 8.7 A continuous map γ : I ⊆R →R3 is called a curve (in
space). The range of the map is called image and will be denoted by the letter
C = γ(I) ⊆R3.
If the image lies on a plane, one talks about a plane curve. A special case is that
where γ(t) =

x(t), y(t), 0

, that is, curves lying in the xy-plane which we indicate
simply as γ : I →R2, γ(t) =

x(t), y(t)

.
Thus a curve is a function of one real variable, whereas the image is a subset of
space (or the plane). Curves furnish a way to parametrise their image by associat-
ing to each value of the parameter t ∈I exactly one point. The set C could be the
image of many curves, by diﬀerent parametrisations. For example, the plane curve
γ(a)
γ(b)
γ(a)
γ(b)
γ(a) = γ(b)
γ(a) = γ(b)
Figure 8.17. Clockwise from top left: images C = γ([a, b]) of a simple arc, a non-
simplearc, a closed arc which is not simple, a Jordan arc

282
8 Geometry in the plane and in space
γ(t) = (t, t) with t ∈[0, 1] has the segment with endpoints A = (0, 0), B = (1, 1)
as image. But this is also the image of δ(t) = (t2, t2), t ∈[0, 1]; the two curves
γ and δ are parametrisations of the segment AB. The middle point of AB is for
example image of t = 1
2 under γ and t =
√
2
2 under δ.
A curve γ is simple if γ is a one-to-one map, i.e., if diﬀerent values of the
parameter determine distinct points on the image.
Suppose the interval I = [a, b] is closed and bounded, as in the previous ex-
amples, in which case the curve γ is called an arc. An arc is closed if γ(a) = γ(b);
clearly a closed arc is not simple. Nevertheless, one deﬁnes simple closed arc (or
Jordan arc) a closed arc which is simple except for one single point γ(a) = γ(b).
Fig. 8.17 illustrates various types of situations.
The reader might encounter the word arc in the literature (as in ‘arc of circum-
ference’) to denote a subset of R2 or R3, endowed with the most natural – hence
implicitly understood – parametrisation.
Examples 8.8
i) The simple plane curve
γ(t) = (at + b, ct + d) ,
t ∈R , a ̸= 0 ,
has for an image the line y = c
ax + ad −bc
a
. Setting x = x(t) = at + b and
y = y(t) = ct + d, in fact, gives t = x −b
a
, so
y = c
a(x −b) + d = c
ax + ad −bc
a
.
ii) The curve
γ(t) =

x(t), y(t)

= (1 + cos t, 3 + sin t) ,
t ∈[0, 2π] ,
has the circle centred at (1, 3) with radius 1 as image; in fact

x(t) −1
2 +

y(t) −3
2 = cos2 t + sin2 t = 1. This is a simple closed curve and provides the
most natural way to parametrise the circle that starts at (2, 3) and runs in the
counter-clockwise direction.
In general, the image of the Jordan curve
γ(t) =

x(t), y(t)

= (x0 + r cos t, y0 + r sin t) ,
t ∈[0, 2π] ,
is the circle with centre (x0, y0) and radius r.
If t varies in an interval [0, 2kπ], with k ≥2 a positive integer, the curve has the
same image seen as a set; but because we wind around the centre k times, the
curve is not simple.
Instead, if t varies in [0, π], the curve is an arc of circumference, simple but not
closed.
iii) Given a, b > 0, the map
γ(t) =

x(t), y(t)

= (a cos t, b sin t) ,
t ∈[0, 2π] ,

8.4 Curves in the plane and in space
283
Figure 8.18. The spiral and helix of Examples 8.8 iv), vi)
is a simple closed curve parametrising the ellipse with centre in the origin and
semi-axes a and b.
iv) The image of
γ(t) =

x(t), y(t)

= (t cos t, t sin t) ,
t ∈[0, +∞) ,
is drawn in Fig. 8.18 (left); the spiral coils counter-clockwise around the origin.
The generic point γ(t) has distance

x2(t) + y2(t) = t from the origin, so it
moves always farther as t grows, making the spiral a simple curve.
v) Let P = (xP , yP , zP ) and Q = (xQ, yQ, zQ) be distinct points in space. The
image of the simple curve
γ(t) = P + (Q −P)t ,
t ∈R ,
is the straight line through P and Q, because γ(0) = P, γ(1) = Q and the vector
γ(t) −P has constant direction, being parallel to Q −P.
The same line can be parametrised more generally by
γ(t) = P + (Q −P) t −t0
t1 −t0
,
t ∈R ,
(8.40)
where t0 ̸= t1; in this case γ(t0) = P, γ(t1) = Q.
vi) Consider the simple curve
γ(t) =

x(t), y(t), z(t)

= (cos t, sin t, t) ,
t ∈R .
Its image is the circular helix (Fig. 8.18, right) resting on the inﬁnite cylinder
along the z-axis with radius one, i.e., the set {(x, y, z) ∈R3 : x2 + y2 = 1}.
2
A curve γ : I →R3 is diﬀerentiable if the components x, y, z : I →R are dif-
ferentiable maps on I (recall that diﬀerentiable on I means diﬀerentiable at every
interior point, and diﬀerentiable on one side at the boundary, if this is included in
I). Let γ′ : I →R3 be the derivative function γ′(t) =

x′(t), y′(t), z′(t)

.

284
8 Geometry in the plane and in space
T (t)
S(t)
σ
γ(t)
PΔt = γ(t0 + Δt)
γ′(t0)
P0 = γ(t0)
Figure 8.19. Tangent vector and secant at the point P0
Deﬁnition 8.9 The curve γ : I →R3 is regular if it is diﬀerentiable over
I with continuous derivative (i.e., the components are of class C1 on I) and
if γ′(t) ̸= (0, 0, 0), for every t ∈I.
A curve γ : I →R3 is said piecewise regular if I is the union of ﬁnitely-
many subintervals where γ is regular.
When the curve γ is regular and t0 ∈I, the vector γ′(t0) is called tangent
vector to (the image of) the curve at P0 = γ(t0). The name comes from the
geometric picture (Fig. 8.19). Let t0 + Δt ∈I be such that the point PΔt =
γ(t0 + Δt) is diﬀerent from P0, and consider the straight line passing through P0
and PΔt. By (8.40) such line can be parametrised as
S(t) = P0 +

PΔt −P0
t −t0
Δt
= γ(t0) + γ(t0 + Δt) −γ(t0)
Δt
(t −t0) .
(8.41)
As Δt goes to 0, the point PΔt approaches P0 (component-wise). At the same time,
the regularity assumption forces the vector σ = σ(t0, Δt) = γ(t0 + Δt) −γ(t0)
Δt
to tend to γ′(t0). Therefore the limiting position of (8.41) is
T (t) = γ(t0) + γ′(t0)(t −t0) ,
t ∈R ,
the straight line tangent to the curve at P0. To be very precise, the tangent vector
at P0 is the vector

P0, γ′(t0)

, but it is common to write it simply γ′(t0) (as
discussed in Sect. 8.2.3). One can easily verify that the tangent line to a curve
at a point is an intrinsic notion – independent of the chosen parametrisation,
whereas the tangent vector does depend on the parametrisation, as far as length
and orientation are concerned.

8.4 Curves in the plane and in space
285
In kinematics, a curve represents a trajectory, i.e., the position γ(t) a particle
occupies at time t. If the curve is regular, the tangent vector γ′(t) describes the
velocity of the particle at time t.
Examples 8.10
i) All curves in Examples 8.8 are regular.
ii) Let f : I →R be diﬀerentiable with continuity on I. The curve
γ(t) =

t, f(t)

,
t ∈I ,
is regular, and has image the graph of the function f. In fact,
γ′(t) =

1, f ′(t)

̸= (0, 0) ,
for any t ∈I .
iii) The arc γ : [0, 2] →R2
γ(t) =

(t, 1) ,
if t ∈[0, 1) ,
(t, t) ,
if t ∈[1, 2] ,
parametrises the polygonal chain ABC (Fig. 8.20, left), while
γ(t) =
⎧
⎪
⎨
⎪
⎩
(t, 1) ,
if t ∈[0, 1) ,
(t, t) ,
if t ∈[1, 2) ,

4 −t, 2 −1
2(t −2)

,
if t ∈[2, 4] ,
describes ABCA (Fig. 8.20, right). Both are piecewise regular curves.
iv) The curves
γ(t) =

1 +
√
2 cos t,
√
2 sin t

,
t ∈[0, 2π] ,
%γ(t) =

1 +
√
2 cos 2t, −
√
2 sin 2t

,
t ∈[0, π] ,
parametrise the same circle C (counter-clockwise and clockwise respectively)
with centre (1, 0) and radius
√
2.
1
1
2
A
B
C
O
1
1
2
A
B
C
O
Figure 8.20. The polygonal chains ABC (left) and ABCA (right) in Example 8.10 iii)

286
8 Geometry in the plane and in space
They are regular and diﬀerentiate to
γ′(t) =
√
2

−sin t, cos t

,
%γ′(t) = 2
√
2

−sin 2t, −cos2t

.
The point P0 = (0, 1) ∈C is the image under γ of t0 =
3
4π, under %γ of the
value %t0 =
5
8π, P0 = γ(t0) = %γ(%t0). In the former case the tangent vector is
γ′(t0) = (−1, −1) and the tangent to C at P0
T (t) = (0, 1) −(1, 1)

t −3
4π

=

−t + 3
4π, 1 −t + 3
4π

,
t ∈R .
For the latter parametrisation, %γ′(%t0) = (2, 2) and
%T(t) = (0, 1) + (2, 2)

t −5
8π

=

2(t −5
8π), 1 + 2(t −5
8π)

,
t ∈R .
The tangent vectors at P0 have diﬀerent lengths and orientations, but same dir-
ection. Recalling Example 8.8 in fact, in both cases the tangent line has equation
y = 1 + x.
2
8.5 Functions of several variables
Object of our investigation in the previous chapters have been functions of one
real variable, that is, maps deﬁned on a subset of the real line R (like an interval),
with values in R.
We would like now to extend some of those notions and introduce new ones,
relative to real-valued functions of two or three real variables. These are deﬁned
on subsets of R2 or R3 and valued in R
f : dom f ⊆Rd →R
(d = 2 or 3) ,
x →f(x) .
The symbol x indicates a generic element of Rd, hence a pair x = (x1, x2) if d = 2
or a triple x = (x1, x2, x3) if d = 3. For simplicity we might write (x1, x2) = (x, y)
and (x1, x2, x3) = (x, y, z), and the coordinates of x shall be (x1, . . . , xd) when
it is not relevant whether d = 2 or 3. Each x ∈Rd is uniquely associated to a
point P of the plane or space, whose coordinates in an orthogonal Cartesian frame
are the components of x. In turn, P determines a position vector of components
x1, . . . , xd, so the element x ∈Rd can be thought of as that vector. In this way,
Rd inherits the operations of sum x + y = (x1 + y1, . . . , xd + yd), multiplication
λx = (λx1, . . . , λxd) and dot product x · y = x1y1 + . . . + xdyd. Furthermore, the
Euclidean norm ∥x∥=

x2
1 + . . . + x2
d represents the Euclidean distance of P to
O. Notice ∥x −y∥=

(x1 −y1)2 + . . . + (xd −yd)2 is the distance between the
points P and Q of respective coordinates x and y.
8.5.1 Continuity
By means of the norm we can deﬁne neighbourhoods of a point in Rd and extend
the concepts of continuity, and limit, to functions of several variables.

8.5 Functions of several variables
287
Deﬁnition 8.11 Let x0 ∈Rd and r > 0 real. The set
Ir(x0) = {x ∈Rd : ∥x −x0∥< r}
of points Rd whose distance from x0 is less than r is called neighbourhood
of x0 of radius r.
With x0 = (x01, . . . , x0d), the condition ∥x −x0∥< r is equivalent to
(x1 −x01)2 + (x2 −x02)2 < r2
if d = 2 ,
(x1 −x01)2 + (x2 −x02)2 + (x3 −x03)2 < r2
if d = 3 .
Therefore Ir(x0) is respectively the disc or the ball centred at x0 with radius r,
without boundary.
Deﬁning continuity is formally the same as for one real variable.
Deﬁnition 8.12 A function f : dom f ⊆Rd →R is continuous at x0 ∈
dom f if for any ε > 0 there exists δ > 0 such that
∀x ∈dom f,
∥x −x0∥< δ
⇒
|f(x) −f(x0)| < ε .
Otherwise said, if
∀x ∈dom f,
x ∈Iδ(x0)
⇒
f(x) ∈Iε

f(x0)

.
Example 8.13
The map f : R2 →R, f(x) = 2x1 + 5x2 is continuous at x0 = (3, 1), for
|f(x) −f(x0)| = |2(x1 −3) + 5(x2 −1)|
≤2|x1 −3| + 5|x2 −1| ≤7∥x −x0∥.
Here we have used the fact that |yi| ≤∥y∥for any i = 1, . . . , d and any y ∈Rd,
a direct consequence of the deﬁnition of norm. Given ε > 0, it is suﬃcient to
choose δ = ε/7.
The same argument shows that f is continuous at every x0 ∈R2.
2
A map f : dom f ⊆Rd →R is continuous on the region Ω ⊆dom f if it is
continuous at each point x ∈Ω.
The limit for x →x0 ∈Rd is deﬁned in a completely similar way to the one
given in Chap. 3.

288
8 Geometry in the plane and in space
8.5.2 Partial derivatives and gradient
Let f : dom f ⊆R2 →R be a function of two variables deﬁned in a neighbourhood
of x0 = (x0, y0). Now ﬁx the second variable to obtain a map of one real variable
x deﬁned around x0 ∈R
x →f(x, y0).
If this is diﬀerentiable at x0, one says that the function f admits partial deriv-
ative with respect to x at x0, written
∂f
∂x (x0) = d
dxf(x, y0)

x=x0
.
Similarly, if y →f(x0, y) is diﬀerentiable at y0, one says that f admits partial
derivative with respect to y at x0
∂f
∂y (x0) = d
dy f(x0, y)

y=y0
.
If both conditions above hold, f admits (ﬁrst) partial derivatives at x0, and there-
fore the gradient vector of f at x0 is well deﬁned: this is denoted
∇f(x0) =
∂f
∂x (x0), ∂f
∂y (x0)

∈R2 .
In the same fashion, let f : dom f ⊆R3 →R be a function of three variables
deﬁned around x0 = (x0, y0, z0); the (ﬁrst) partial derivatives at x0 with respect
to x, y, z are
∂f
∂x (x0) = d
dxf(x, y0, z0)

x=x0
,
∂f
∂y (x0) = d
dy f(x0, y, z0)

y=y0
,
∂f
∂z (x0) = d
dz f(x0, y0, z)

z=z0
,
assuming implicitly that the right-hand-side terms exist. The gradient of f at x0
is the vector
∇f(x0) =
∂f
∂x (x0), ∂f
∂y (x0), ∂f
∂z (x0)

∈R3 .

8.5 Functions of several variables
289
Examples 8.14
i) Let f(x, y) =

x2 + y2 be the distance function from the origin. Considering
x0 = (2, −1) we have
∂f
∂x (2, −1) =
d
dx

x2 + 1

(2) =
x
√
x2 + 1

x=2
=
2
√
5
∂f
∂y (2, −1) =
d
dy

4 + y2

(−1) =
y

4 + y2

y=−1
= −1
√
5 .
so
∇f(2, −1) =
 2
√
5, −1
√
5

=
1
√
5(2, −1) .
ii) For f(x, y, z) = y log(2x −3z) we have, at x0 = (2, 3, 1),
∂f
∂x (2, 3, 1) =
 d
dx 3 log(2x −3)

(2) = 3
2
2x −3

x=2
= 6 ,
∂f
∂y (2, 3, 1) =
d
dy y log 1

(3) = 0 ,
∂f
∂z (2, 3, 1) =
d
dz 3 log(4 −3z)

(1) = 3
−3
4 −3z

z=1
= −9 ,
thus
∇f(2, 3, 1) = (6, 0, −9) .
2
Set x = (x1, . . . , xd). The partial derivative of f at x0 with respect to the
variable xi, i = 1, . . . , d, is often indicated also by
Dxif(x0)
or
fxi(x0) .
The function
∂f
∂xi
: x →∂f
∂xi
(x) ,
deﬁned on a subset dom ∂f
∂xi ⊆dom f ⊆Rd with values in R, is called partial
derivative of f with respect to xi. The gradient function of f,
∇f : x →∇f(x),
is deﬁned on the intersection of the domains of the partial derivatives. The gradient
is an example of a vector ﬁeld, i.e., a function deﬁned on a subset of Rd with values
in Rd (thought of as a vector space).
Examples 8.15
Let us look at the previous examples.
i) The gradient of f(x, y) =

x2 + y2 is

290
8 Geometry in the plane and in space
∇f(x) =

x

x2 + y2 ,
y

x2 + y2

=
x
∥x∥
and dom ∇f = R2 \ {0}.
ii) For the function f(x, y, z) = y log(2x −3z) we have
∇f(x) =

2y
2x −3z, log(2x −3z),
−3y
2x −3z

,
so dom ∇f = dom f = {(x, y, z) ∈R3 : 2x −3z > 0}.
2
Partial derivatives with respect to xi, i = 1, . . . , d are special directional deriv-
atives, which we discuss hereby. Let f be a map deﬁned around a point x0 ∈Rd
and suppose v ∈Rd is a given non-zero vector. By deﬁnition, f admits (partial)
derivative at x0 in the direction v if the quantity
∂f
∂v (x0) = lim
t→0
f(x0 + tv) −f(x0)
t
exists and is ﬁnite. Another name is directional derivative along v, written
Dvf(x0).
The condition expresses the diﬀerentiability at t0 = 0 of the map t →f(x0+tv)
deﬁned around t0 (because if t is small enough, x0 + tv is in the neighbourhood of
x0 where f is well deﬁned). The curve t →x0 + tv = γ(t) is a parametrisation of
the straight line passing through x0 with direction v, and (f ◦γ)(t) = f(x0 + tv).
The directional derivative at x0 along v is therefore
∂f
∂v (x0) =
d
dt f ◦γ

(0) .
Let ei be the unit vector whose ith component is 1 and all others zero (so
e1 = i, e2 = j, e3 = k). Taking v = ei gives the partial derivative at x0 with
respect to xi
∂f
∂ei
(x0) = ∂f
∂xi
(x0),
i = 1, . . . , d .
For example, let d = 2 and i = 1: from
f(x0 + te1) = f

(x0, y0) + t(1, 0)

= f(x0 + t, y0)
we obtain, substituting x = x0 + t,
∂f
∂ei
(x0, y0) = lim
t→0
f(x0 + t, y0) −f(x0, y0)
t
= lim
x→x0
f(x, y0) −f(x0, y0)
x −x0
= ∂f
∂x (x0, y0) .

8.6 Exercises
291
It can be proved that if f admits partial derivatives with respect to every
variable xi in a whole neighbourhood of x0, and if such maps are in this neigh-
bourhood continuous, then f admits at x0 derivatives along any vector v ̸= 0;
these directional derivatives can be written using the gradient as follows
∂f
∂v (x0) = v · ∇f(x0) = v1
∂f
∂x1
(x0) + · · · + vd
∂f
∂xd
(x0) .
From this formula we also deduce the useful relations
∂f
∂xi
(x0) = ei · ∇f(x0),
i = 1, . . . , d .
Under the same assumptions on f, if γ : I →Rd is any diﬀerentiable curve
at t0 ∈I such that γ(t0) = x0, the composite map (f ◦γ)(t) = f

γ(t)

remains
diﬀerentiable at t0 and
d
dt f ◦γ

(t) = γ′(t0) · ∇f(x0) ;
(8.42)
this should be understood as a generalisation of the chain rule seen for one real
variable.
Example 8.16
Consider the distance function f(x, y) =

x2 + y2 and let γ : (0, +∞) →R2 be
the spiral γ(t) = (t cos t, t sin t). Since
f

γ(t)

=

t2 cos2 t + t2 sin2 t = t ,
we see directly that d
dt f

γ(t)

= 1 for any t > 0. Let us double-check the same
result using (8.42). Deﬁne x = γ(t) and the unit vector ˆx =
x
∥x∥= (cos t, sin t).
Then γ′(t) = (cos t, sin t) + t(−sin t, cos t) = ˆx + tˆx⊥; the notation for the unit
vector ˆx⊥= (−sin t, cos t) is due to ˆx⊥· ˆx = 0. We already know though
(Example 8.15) that ∇f(x) = ˆx for any x ̸= 0. Therefore
γ′(t) · ∇f(x) = (ˆx + tˆx⊥) · ˆx = ˆx · ˆx + t ˆx⊥· ˆx = ∥ˆx∥2 = 1 ,
as expected.
2
8.6 Exercises
1.
Determine the polar coordinates of the following points in the plane:
A = (5
√
6, 5
√
2) ,
B = (5
√
6, −5
√
2) ,
C = (−5
√
6, 5
√
2) ,
D = (−5
√
6, −5
√
2) .

292
8 Geometry in the plane and in space
2. Write the following points of the plane in polar coordinates:
a) A = (−5, 0)
b) B = (0, 4)
c) C = (0, −3)
3. Determine the polar coordinates of the following points (without computing
explicitly the angle):
a)
A = (2
√
3 −3
√
2, 1)
b) B = (3
√
2 −2
√
3, 3
√
2 + 2
√
3)
4.
Determine the polar coordinates of the following points in the plane (leaving
the argument written in terms of a trigonometric function):
A = (cos π
9 , sin π
9 ) ,
B = (−cos π
9 , sin π
9 ) ,
C = (sin π
9 , cos π
9 ) .
5. Change to polar coordinates:
a)
A = (
√
2
2 cos π
9 −
√
2
2 sin π
9 ,
√
2
2 cos π
9 +
√
2
2 sin π
9 )
b)
B = (2 cos 28
9 π, 2 sin 28
9 π)
6.
Given v1 = (1, 0, −2) and v2 = (0, 1, 1), ﬁnd a real number λ so that v1 + λv2
is orthogonal to v3 = (−1, 1, 1).
7.
Describe the set of planar vectors orthogonal to v = (2, −5).
8.
Determine the set of vectors in space orthogonal to v1 = (1, 0, 2) and v2 =
(2, −1, 3) simultaneously.
9.
Find the norm of the vectors:
v1 = (0,
√
3, 7) ,
v2 = (1, 5, −2) ,
v3 =

cos π
5 , sin π
5 cos π
7 , −sin π
5 sin π
7

.
10. Determine the cosine of the angle formed by the following pairs:
a) v = (0, 1, 0) ,
w = (0,
2
√
3, 2)
b) v = (1, 2, −1) ,
w = (−1, 1, 1)
11.
Determine the unit vector u corresponding to w = (5, −3, −
√
2). Then ﬁnd
the component of v = (2, −1, 2
√
2) along u and the orthogonal one.
12. Write the following complex numbers in Cartesian form:
a) (2 −3i)(−2 + i)
b) (3 + i)(3 −i)
 1
5 + 1
10i

c) 1 + 2i
3 −4i + 2 −i
5i
d)
5
(1 −i)(2 −i)(3 −i)

8.6 Exercises
293
13. Determine the trigonometric and exponential forms of:
a) z = i
b) z = −1
c) z = 1 + i
d) z = i(1 + i)
e) z = 1 + i
1 −i
f) z = sin α + i cos α
14. Compute the modulus of:
a) z =
1
1 −i +
2i
i −1
b) z = 1 + i −
i
1 −2i
15.
Prove that

3z −i
3 + iz
 = 1 if |z| = 1.
16. Solve the following equations:
a)
z2 −2z + 2 = 0
b)
z2 + 3iz + 1 = 0
c)
z|z| −2z + i = 0
d)
|z|2z2 = i
e)
z2 + i¯z = 1
f)
z3 = |z|4
17.
Verify 1 + i is a root of the polynomial z4 −5z3 + 10z2 −10z + 4 and then
determine all remaining roots.
18. Compute z2, z9, z20 when:
a) z = 1 −i
i
b)
z =
2
√
3 −i
+ 1
i
19. Write explicitly the following numbers in one of the known forms and draw
their position in the plane:
a) z =
3√−i
b)
z =
5√
1
c) z = √2 −2i
20. Determine the domains of the functions:
a)
f(x, y) = x −3y + 7
x −y2
b)
f(x, y) =

1 −3xy
c)
f(x, y) =

3x + y + 1 −
1
√2y −x
d)
f(x, y, z) = log(x2 + y2 + z2 −9)

294
8 Geometry in the plane and in space
21. Calculate all partial derivatives of:
a) f(x, y) =

3x + y2 at (x0, y0) = (1, 2)
b) f(x, y, z) = yex+yz
at (x0, y0, z0) = (0, 1, −1)
22. Find the gradient for:
a) f(x, y) = arctan x + y
x −y
b) f(x, y) = (x + y) log(2x −y)
c) f(x, y, z) = sin(x + y) cos(y −z)
d) f(x, y, z) = (x + y)z
23. Compute the directional derivatives of the following maps along the vector v
and evaluate them at the point indicated:
a) f(x, y) = x

y −3
v = (−1, 6)
x0 = (2, 12)
b) f(x, y, z) =
1
x + 2y −3z
v = (12, −9, −4)
x0 = (1, 1, −1)
8.6.1 Solutions
1. All four points have modulus r = √25 · 6 + 25 · 2 = 5
√
8. Formula (8.2) yields,
for A,
θA = arctan 5
√
2
5
√
6 = arctan 1
√
3 = π
6
since x > 0. Similarly for B
θB = arctan

−1
√
3

= −arctan 1
√
3
= −π
6 .
For the point C, since x < 0 and y > 0,
θC = arctan

−1
√
3

+ π = −π
6 + π = 5
6π ,
while x < 0, y < 0 for D, so
θD = arctan 1
√
3 −π = π
6 −π = −5
6π .
2. Polar coordinates in the plane:
a)
r = 5 ,
θ = π ;
b) r = 4 ,
θ = π
2 ;
c) r = 3 ,
θ = −π
2 .

8.6 Exercises
295
3. Polar coordinates:
a) The modulus is r =

31 −12
√
6. From 2
√
3 < 3
√
2 we have
θ = arctan
1
2
√
3 −3
√
2
+ π = arctan 2
√
3 + 3
√
2
−6
+ π
= −arctan
√
3
3 +
√
2
2

+ π .
b)
r = 5
√
6 ,
θ = arctan(5 + 2
√
6) .
4. All points have unit modulus r = 1. For A
θA = arctan tan π
9 = π
9 .
For B, x < 0 and y > 0, so
θB = arctan

−tan π
9

+ π = −π
9 + π = 8
9π .
As for C,
θC = arctan cos π
9
sin π
9
;
by (2.17), and since the tangent function has period π, it follows
cos π
9
sin π
9
= −sin( π
9 + π
2 )
cos( π
9 + π
2 ) = −tan 11
18π = −tan

−7
18π

= tan 7
18π ,
hence θC =
7
18π .
5. Polar coordinates:
a) Just note
√
2
2 = sin π
4 = cos π
4 and apply the addition formulas for sine/cosine:
A =

cos
π
4 + π
9

, sin
π
4 + π
9

=

cos 13
36π, sin 13
36π

.
Because 13
36π < π
2 , we immediately have r = 1 and θ = 13
36π .
b)
r = 2 ,
θ = −8
9π .
6. The vectors v1 + λv2 and v3 are orthogonal if (v1 + λv2) · v3 = 0. But
(v1 + λv2) · v3 = v1 · v3 + λv2 · v3 = −3 + 2λ ,
whence λ = 3
2 follows.
7. A vector (x, y) is orthogonal to v if (x, y) · (2, −5) = 2x −5y = 0. The required
set is then made by the vectors lying on the straight line 2x −5y = 0. One way to
describe this set is {λ(5, 2) : λ ∈R} .

296
8 Geometry in the plane and in space
8. Imposing w = (x, y, z) orthogonal to v1 and v2 yields w · v1 = x + 2z = 0 plus
w · v2 = 2x −y + 3z = 0, hence x = −2z and y = −z. Put z = λ, and the set
becomes {λ(−2, −1, 1) : λ ∈R} .
9. ∥v1∥=
√
52 ,
∥v2∥=
√
30 ,
∥v3∥= 1 .
10. Angles between vectors:
a)
cos θ = 1
2 ;
b) cos θ = 1 .
11. From ∥w∥= 6 it follows u =
 5
6, −1
2, −
√
2
6

. Since v · w = 3
2,
vu =
5
4, −3
4, −
√
2
4

,
vu⊥= (2, −1, 2
√
2) −
5
4, −3
4, −
√
2
4

=
3
4, −1
4, 9
4
√
2

.
12. Cartesian form of complex numbers:
a)
−1 + 8i ;
b) 2 + i ;
c) −2
5 ;
d)
1
2i .
13. Exponential and trigonometric form:
a)
z = cos π
2 + i sin π
2 = ei π
2 ;
b) z = cos π + i sin π = eiπ ;
c) z =
√
2

cos π
4 +i sin π
4

=
√
2ei π
4 ;
d) z =
√
2

cos 3
4π+i sin 3
4π

=
√
2ei 3
4 π ;
e) cosπ
2 +i sin π
2 = ei π
2 ;
f) cos
π
2 −α

+i sin
π
2 −α

= ei( π
2 −α) .
14. Modulus of complex numbers:
a)

5
2 ;
b)

13
5 .
15. We proceed indirectly and multiply ﬁrst the denominator by |¯z| (= 1) to get

3z −i
3 + iz
 =

3z −i
3¯z + i
 =

3z −i
3z −i
 = |3z −i|
3z −i
 = 1 .
16. Solving equations:
a)
z = 1 ± i .
b) The formula for a quadratic equation gives
z = −3i ± √−9 −4
2
= −3i ±
√
13i
2
= −3 ±
√
13
2
i .

8.6 Exercises
297
c) Write z = x + iy, so that the equation reads
(x + iy)

x2 + y2 −2x −2iy + i = 0 ,
or equivalently,
x

x2 + y2 −2x + i

y

x2 + y2 −2y + 1

= 0 .
The real and imaginary parts at the two sides of the equality must be the
same, so

x

x2 + y2 −2

= 0
y

x2 + y2 −2y + 1 = 0 .
The ﬁrst equation in the system implies either x = 0 or

x2 + y2 = 2. Substi-
tuting 2 to the square root in the second equation gives 1 = 0, which cannot
be. Therefore the only solutions are
 x = 0
y|y| −2y + 1 = 0 .
Distinguishing the cases y ≥0 and y < 0, we have
 x = 0
y2 −2y + 1 = 0 ,
and
 x = 0
−y2 −2y + 1 = 0
so
 x = 0
y = 1
and
 x = 0
y = −1 ±
√
2 .
In conclusion, the solutions are z = i, z = i(−1−
√
2) (because y = −1+
√
2 > 0
must be discarded).
d)
z = ±
√
2
2 (1 + i) ;
e)
z =
√
7
2 −i1
2 ; z = −
√
7
2 −i1
2 .
f) Using |z|2 = z¯z, the new equation is
z3 = z2¯z2
⇐⇒
z2(z −¯z2) = 0 .
One solution is certainly z = 0, and the others satisfy z −¯z2 = 0. Write
z = x + iy, so to obtain

x2 −y2 −x = 0
2xy + y = 0 .
The bottom relation factorises into y(2x + 1) = 0, hence we have two subsys-
tems
 y = 0
x(x −1) = 0 ,

x = −1
2
y2 = 3
4 .
Putting real and imaginary parts back together, the solutions read
z = 0 ;
z = 1 ;
z = −1
2 ±
√
3
2 i .

298
8 Geometry in the plane and in space
17. The fact that the polynomial has real coeﬃcients implies the existence of the
complex-conjugate ¯z = 1−i to z = 1+i as root. This means (z −1−i)(z −1+i) =
z2 −2z + 2 divides the polynomial, indeed
z4 −5z3 + 10z2 −10z + 4 = (z2 −2z + 2)(z2 −3z + 2) = (z2 −2z + 2)(z −1)(z −2) .
Thus the roots are
z = 1 + i ,
z = 1 −i ,
z = 1 ,
z = 2 .
18. Powers of complex numbers:
a)
z2 = 2i ,
z9 = −16(1 + i) ,
z20 = −210 .
b) Rationalising the denominators yields
z = 2
√
3 + i
4
−i = 1
2(
√
3 −i) .
Now write the number in exponential form
z = 1
2(
√
3 −i) = e−π
6 i,
from which
z2 = e−π
3 i = cos π
3 −i sin π
3 = 1
2(1 −
√
3i) ;
z9 = e−3
2 πi = e
π
2 i = cos π
2 + i sin π
2 = i ,
z20 = e−20
6 πi = e
2
3 πi = 1
2(−1 +
√
3i) .
19. Computing and drawing complex numbers:
a) z0 = i ,
z1 = −1
2
√
3 + i

,
z2 = 1
2
√
3 −i

They are drawn in Fig. 8.21, left.
b) Write the number 1 as 1 = e0πi. Then because ea+2π = ea, we have
z0 = 1 ,
z1 = e
2
5 πi ,
z2 = e
4
5 πi ,
z3 = e−4
5 πi ,
z4 = e−2
5 πi ,
see Fig. 8.21, middle.
c) z0 =
4√
8e
7
8 πi ,
z1 =
4√
8e−1
8 πi are represented in Fig. 8.21, right.
20. Domain of functions:
a) The domain is {(x, y) ∈R2 : x ̸= y2}, the set of all plane points oﬀthe
parabola x = y2.

8.6 Exercises
299
Re z
Im z
z2
z0
z1
Re z
Im z
z0
z1
z2
z3
z4
Re z
Im z
z1
z0
Figure 8.21. From left: cubic roots of −i, ﬁfth roots of unity, square roots of 2 −2i
b) The map is well deﬁned where the radicand is non-negative, so the domain is
{(x, y) ∈R2 : y ≤1
3x if x > 0, y ≥1
3x if x < 0, y ∈R if x = 0},
the set of points lying between the branches of the hyperbola y =
1
3x.
c) Only for 3x + y + 1 ≥0 and 2y −x > 0 the function is deﬁned, which makes
{(x, y) ∈R2 : y ≥−3x −1} ∩{(x, y) ∈R2 : y > x
2}
the domain of the function, represented in Fig. 8.22.
d) The map is well deﬁned where the logarithm’s argument is positive, hence the
domain is the subset of space
{(x, y, z) ∈R3 : x2 + y2 + x2 > 9} .
These are the points outside the sphere centred at the origin and with radius
three.
y = x
2
y = −3x −1
Figure 8.22. The domain of the map f(x, y) = √3x + y + 1 −
1
√2y−x

300
8 Geometry in the plane and in space
21. Partial derivatives:
a)
∂f
∂x(1, 2) =
3
2
√
7 ,
∂f
∂y (1, 2) =
2
√
7 .
b)
∂f
∂x(0, 1, −1) = e−1 ,
∂f
∂y (0, 1, −1) = 0 ,
∂f
∂z (0, 1, −1) = e−1 .
22. Gradients:
a)
∇f(x, y) =

−
y
x2 + y2 ,
x
x2 + y2

.
b)
∇f(x, y) =

log(2x −y) + 2(x + y)
2x −y , log(2x −y) −x + y
2x −y

.
c)
∇f(x, y, z) =

cos(x + y) cos(y −z) , cos(x + 2y −z) , sin(x + y) sin(y −z)

.
d)
∇f(x, y, z) =

z(x + y)z−1 , z(x + y)z−1 , (x + y)z log(x + y)

.
23. Directional derivatives:
a)
∂f
∂v (x0) = −1 ;
b) ∂f
∂v (x0) = 1
2 .

9
Integral calculus I
Integral calculus tackles two rather diﬀerent issues:
i)
Find all functions that diﬀerentiate to a given map over an interval of the real
line. This operation is essentially an anti-derivation of sorts, and goes by the
name of indeﬁnite integration.
ii) Deﬁne precisely and compute the area of a region in the plane bounded by
graphs of maps deﬁned on closed bounded intervals, known as deﬁnite integ-
ration.
The two problems seem to have little in common, at ﬁrst sight. The outcome of
indeﬁnite integration is, as we shall soon see, an inﬁnite set of functions. Deﬁnite
integration produces instead a number, the surface area of a certain planar region.
A cornerstone result, not casually called the Fundamental Theorem of integral
calculus lest its importance goes amiss, states that the two problems are actually
equivalent: if one can reconstruct a map knowing its derivative, then it is not hard
to ﬁnd the area of the region bounded by the derivative’s graph and the lines
parallel to the coordinate axes, and vice versa.
The beginning of the chapter is devoted to the former problem. Then, we
explain two constructions of deﬁnite integrals, due to Cauchy and Riemann; albeit
strongly related, these are presented as separate items for the didactic purpose of
keeping the treatise as versatile as possible. Only in later sections we discuss the
properties of integrals in a uniform manner. Eventually, we prove the Fundamental
Theorem of integral calculus and show how it is employed to determine areas.
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_9,
© Springer International Publishing Switzerland 2015

302
9 Integral calculus I
9.1 Primitive functions and indeﬁnite integrals
Let f be a function deﬁned on some interval I.
Deﬁnition 9.1 Each function F, diﬀerentiable on I, such that
F ′(x) = f(x),
∀x ∈I,
is called a primitive (function) or an antiderivative of f on I.
Not any map deﬁned on a real interval admits primitives: not necessarily, in
other words, will any function be the derivative of some map. Finding all maps that
admit primitives on a real interval, which we call integrable on that interval, is
too-far-reaching a problem for this book’s aims. We limit ourselves to point out an
important class of integrable maps, that of continuous maps on a real interval;
the fact that continuity implies integrability will follow from the Fundamental
Theorem of integral calculus.
Examples 9.2
i) Given the map f(x) = x on R, a primitive function is F(x) = 1
2x2. The latter
is not the only primitive of f: each map G(x) = 1
2x2 + c, where c is an arbitrary
constant, is a primitive of f, because diﬀerentiating a constant gives nought.
ii) Consider f(x) =
1
x over the interval I = (−∞, 0). The collection of maps
F(x) = log |x| + c (c ∈R) consists of primitives of f on I.
2
The previous examples should explain that if F(x) is a primitive of f(x) on
the interval I, then also maps of type F(x) + c, with c constant, are primitives.
It becomes therefore natural to ask whether there are other primitives at all. The
answer is no, as shown in the next crucial result.
Proposition 9.3 If F and G are both primitive maps of f on the interval I,
there exists a constant c such that
G(x) = F(x) + c,
∀x ∈I.
Proof.
Take the function H(x) = G(x) −F(x) and diﬀerentiate it
H′(x) = G′(x) −F ′(x) = f(x) −f(x) = 0,
∀x ∈I.
Thus H has zero derivative at every point of I, and as such it must be
constant by Property 6.26.
2
Summarising, the following characterisation of the set of primitives of f holds.

9.1 Primitive functions and indeﬁnite integrals
303
Theorem 9.4 Let f be an integrable map on I and F a primitive. Then any
primitive of f is of the form F(x) + c, with the constant c varying in R.
That in turn motivates the following name.
Deﬁnition 9.5 The set of all primitives of f on a real interval is indicated
by
&
f(x) dx
(called indeﬁnite integral of f, and spoken ‘integral of f(x) dx’ ).
If F is a primitive then,
&
f(x) dx = {F(x) + c : c ∈R}.
It has to be clear that the indeﬁnite integral of f is not a number; it stands rather
for a set of inﬁnitely many maps. It is just quicker to omit the curly brackets and
write
&
f(x) dx = F(x) + c,
which might be sloppy but is certainly eﬀective.
Examples 9.6
i) The map f(x) = x4 resembles the derivative 5x4 = D x5, so a primitive of f
is given by F(x) = 1
5x5 and
&
x4 dx = 1
5x5 + c.
ii) Let f(x) = e2x. Recalling that D e2x = 2e2x, the map F(x) = 1
2e2x is one
primitive, hence
&
e2x dx = 1
2e2x + c.
iii) As D cos 5x = −5 sin 5x, f(x) = sin 5x has primitive F(x) = −1
5 cos 5x, and
&
sin 5x dx = −1
5 cos 5x + c.
iv) Let
f(x) = sin |x| =
 −sin x
if x < 0 ,
sin x
if x ≥0 .

304
9 Integral calculus I
We adopt the following strategy to determine all primitive maps of f(x) on R.
We split the real line in two intervals I1 = (−∞, 0), I2 = (0, +∞) and discuss
the cases separately. On I1, primitives of f(x) are of the form
F1(x) = cos x + c1
with c1 ∈R arbitrary;
similarly, on I2, a primitive will look like
F2(x) = −cosx + c2
c2 ∈R arbitrary.
The general primitive F(x) on R will be written as
F(x) =
 F1(x)
if x < 0,
F2(x)
if x > 0.
Moreover F will have to be continuous at x = 0, because a primitive is by mere
deﬁnition diﬀerentiable – hence continuous a fortiori – at every point in R. We
should thus make sure that the two primitives agree, by imposing
lim
x→0−F(x) = lim
x→0+ F(x).
As F1 and F2 are continuous at x = 0, the condition reads F1(0) = F2(0), that
is
1 + c1 = −1 + c2.
The relation between c1, c2 allows to determine one constant in terms of the
other (coherently with the fact that each primitive depends on one, and only
one, arbitrary real number). For example, putting c1 = c gives c2 = 2 + c. The
expression for the general primitive of f(x) on R is then
F(x) =
 cos x + c
if x < 0,
−cosx + 2 + c
if x ≥0.
2
Theorem 9.4 states that the graph of a primitive of an integrable map is the
vertical translate of any other (see Fig. 9.1).
How to select a particular map among all primitives of a given f then? One
way is to assign a value y0 at a given point x0 on I. The knowledge of any one
primitive F(x) determines the primitive G(x) = F(x) + c0 of f(x) whose value at
x0
y0
y = F(x)
y = F(x) + c
y = F(x) −F(x0) + y0
Figure 9.1. Primitives of a given map diﬀer by an additive constant

9.1 Primitive functions and indeﬁnite integrals
305
x0 is precisely y0. In fact,
G(x0) = F(x0) + c0 = y0
yields c0 = y0 −F(x0) and so
G(x) = F(x) −F(x0) + y0.
The table of derivatives of the main elementary maps can be at this point read
backwards, as a list of primitives. For instance,
a)
&
xα dx = xα+1
α + 1 + c
(α ̸= −1)
b)
& 1
x dx = log |x| + c
(for x > 0 or x < 0)
c)
&
sin x dx = −cos x + c
d)
&
cos x dx = sin x + c
e)
&
ex dx = ex + c
f)
&
1
1 + x2 dx = arctanx + c
g)
&
1
√
1 −x2 dx = arcsinx + c
(9.1)
Examples 9.7
i) Determine the primitive of f(x) = cos x with value 5 at x0 = π
2 . The map
F(x) = sin x is one primitive. We are then searching for a G(x) = sin x + c0.
Imposing G( π
2 ) = 5 we see c0 = 4, and the required primitive is
G(x) = sin x + 4.
ii) Find the value at x1 = 3 of the primitive of f(x) = 6x2 + 5x that vanishes at
the point x0 = 1. One primitive map of f(x) is
F(x) = 2x3 + 5
2x2.
If G(x) = F(x) + c0 has to satisfy G(1) = 0, then c0 = −9
2, whence
G(x) = 2x3 + 5
2x2 −9
2.
The image of x1 = 3 is G(3) = 72.

306
9 Integral calculus I
iii) Consider the piecewise-deﬁned map
f(x) =
 x
if x ≤1,
(x −2)2
if x ≥1.
Mimicking Example 9.6 iv) we obtain
F(x) =
 1
2x2 + c1
if x < 1,
1
3(x −2)3 + c2
if x > 1.
Continuity at x = 1 forces 1
2 + c1 = −1
3 + c2. From this relation, writing c1 = c
gives
F(x) =
 1
2x2 + c
if x < 1,
1
3(x −2)3 + 5
6 + c
if x ≥1.
Let us ﬁnd the primitive of f(x) with zero x0 = 3. Since x0 > 1, the second
expression of F(x)
F(3) = 1
3(3 −2)3 + 5
6 + c = 0
tells c = −7
6. It follows
F(x) =
 1
2x2 −7
6
if x < 1,
1
3(x −2)3 −1
3
if x ≥1.
Beware that it would have been wrong to make 1
2x2 + c vanish at x0 = 3, for
this expression is a primitive only when x < 1 and not on the entire line.
Determining the primitive of f(x) that is zero at x0 = 1 does not depend on the
choice of expression for F(x), because of continuity. The solution is
F(x) =
 1
2x2 −1
2
if x < 1,
1
3(x −2)3 + 1
3
if x ≥1.
2
9.2 Rules of indeﬁnite integration
The integrals of the elementary functions are important for the determination of
other indeﬁnite integrals. The rules below provide basic tools for handling integrals.
Theorem 9.8 (Linearity of the integral) Suppose f(x), g(x) are integ-
rable functions on the interval I. For any α, β ∈R the map αf(x) + βg(x) is
still integrable on I, and
& 
αf(x) + βg(x)

dx = α
&
f(x) dx + β
&
g(x) dx.
(9.2)

9.2 Rules of indeﬁnite integration
307
Proof.
Suppose F(x) is a primitive of f(x) and G(x) a primitive of g(x). By
linearity of the derivative

αF(x) + βG(x)
′
= αF ′(x) + βG′(x) = αf(x) + βg(x),
∀x ∈I.
This means αF(x) + βG(x) is a primitive of αf(x) + βg(x) on I, which is
the same as (9.2).
2
The above property says that one can integrate a sum one summand at a time,
and pull multiplicative constants out of the integral sign.
Examples 9.9
i) Integrate the polynomial 4x2 + 3x −5. By (9.1) a)
&
(4x2 + 3x −5) dx = 4
&
x2 dx + 3
&
x dx −5
&
dx
= 4
1
3x3 + c1

+ 3
1
2x2 + c2

−5(x + c3)
= 4
3x3 + 3
2x2 −5x + c.
The numbers c1, c2, c3 arising from the single integrals have been ‘gathered’ into
one arbitrary constant c.
ii) Integrate f(x) = cos2 x. From
cos2 x = 1
2(1 + cos 2x)
and D sin 2x = 2 cos 2x, it follows
&
cos2 x dx = 1
2
&
dx + 1
2
&
cos 2x dx = 1
2x + 1
4 sin 2x + c .
Similarly
&
sin2 x dx = 1
2x −1
4 sin 2x + c .
2
Theorem 9.10 (Integration by parts) Let f(x), g(x) be diﬀerentiable
over I. If the map f ′(x)g(x) is integrable on I, then so is f(x)g′(x), and
&
f(x)g′(x) dx = f(x)g(x) −
&
f ′(x)g(x) dx.
(9.3)

308
9 Integral calculus I
Proof.
Let H(x) be any primitive of f ′(x)g(x) on I. By formula (6.4)
[f(x)g(x) −H(x)]′ =

f(x)g(x)
′ −H′(x)
= f ′(x)g(x) + f(x)g′(x) −f ′(x)g(x)
= f(x)g′(x).
Therefore the map f(x)g(x) −H(x) is a primitive of f(x)g′(x), exactly
what (9.3) claims.
2
In practice, one integrates a product of functions by identifying ﬁrst one factor
with f(x) and the other with g′(x); then one determines a primitive g(x) of g′(x)
and, at last, one ﬁnds the primitive of f ′(x)g(x) and uses (9.3).
Examples 9.11
i) Compute
&
xex dx.
Call f(x) = x and g′(x) = ex. Then f ′(x) = 1, and we conveniently choose ex as
primitive of itself. Formula (9.3) yields
&
xex dx = xex −
&
ex dx = xex −(ex + c) = (x −1)ex + c.
Since the constant of integration is completely arbitrary, in the last step the sign
of c was ﬂipped with no harm done.
Had we chosen f(x) = ex and g′(x) = x (f ′(x) = ex and g(x) = 1
2x2), we would
have ended up with
&
xex dx = 1
2x2ex −1
2
&
x2ex dx,
which is not particularly helpful (rather the opposite).
ii) Determine
&
log x dx.
Let us put f(x) = log x and g′(x) = 1, so that f ′(x) = 1
x, g(x) = x. Thus
&
log x dx = x log x −
& 1
x x dx = x log x −
&
dx
= x log x −(x + c) = x(log x −1) + c,
given that c is arbitrary.
iii) Find
S =
&
ex sin x dx.
We start by deﬁning f(x) = ex and g′(x) = sin x. Then f ′(x) = ex, g(x) =
−cos x, and
S = −ex cos x +
&
ex cos x dx.

9.2 Rules of indeﬁnite integration
309
Let us integrate by parts once again, by putting f(x) = ex and g′(x) = cos x
this time. Since f ′(x) = ex, g(x) = sin x,
S = −ex cos x + ex sin x −
&
ex sin x dx = ex(sin x −cos x) −S.
A primitive F(x) of ex sin x may be written as
F(x) = ex(sin x −cos x) −G(x) ,
G(x) being another primitive of ex sin x. By the characterisation of Theorem 9.4
then,
2S = ex(sin x −cos x) + c
hence
S = 1
2ex(sin x −cos x) + c.
2
Theorem 9.12 (Integration by substitution) Let f(y) be integrable on
the interval J and F(y) a primitive. Suppose ϕ(x) is a diﬀerentiable function
from I to J. Then the map f

ϕ(x)

ϕ′(x) is integrable on I and
&
f

ϕ(x)

ϕ′(x) dx = F

ϕ(x)

+ c,
(9.4)
which is usually stated in the less formal yet simpler way
&
f

ϕ(x)

ϕ′(x) dx =
&
f(y) dy.
(9.5)
Proof.
Formula (6.7) for diﬀerentiating a composite map gives
d
dxF

ϕ(x)

= dF
dy

ϕ(x)
 dϕ
dx (x) = f

ϕ(x)

ϕ′(x).
Thus F

ϕ(x)

integrates f

ϕ(x)

ϕ′(x), i.e., (9.4) is proven.
2
We insist on the fact that the correct meaning of (9.5) is expressed by (9.4):
the integral on the left is found by integrating f with respect to y and then
substituting to y the function ϕ(x), so that the right-hand side too depends on the
variable x. Formula (9.5) is easy to remember with a trick: diﬀerentiate y = ϕ(x),
so that dy
dx = ϕ′(x). Viewing the right-hand side as a formal quotient (in Leibniz’s
notation), multiply it by dx; substituting dy = ϕ′(x)dx in one integral yields the
other.
Examples 9.13
i) Determine
&
x ex2 dx.

310
9 Integral calculus I
Let y = ϕ(x) = x2, so ϕ′(x) = 2x. Then
&
x ex2 dx = 1
2
&
ex22x dx = 1
2
&
ey dy = 1
2ey + c.
Going back to x,
&
x ex2 dx = 1
2ex2 + c.
ii) Compute
&
tan x dx.
First, recall tan x = sin x
cos x and (cos x)′ = −sin x. Put y = ϕ(x) = cos x:
&
tan x dx = −
&
1
cos x(cos x)′ dx = −
& 1
y dy
= −log |y| + c = −log | cos x| + c.
iii) Find
&
1
√
1 + x2 dx .
By (6.18) it follows directly
&
1
√
1 + x2 dx = sinh−1 x + c .
Alternatively, we may substitute y = ϕ(x) =
√
1 + x2 −x:
dy =

x
√
1 + x2 −1

dx = x −
√
1 + x2
√
1 + x2
dx ,
hence
1
√
1 + x2 dx = −1
y dy. This gives
&
1
√
1 + x2 dx = −
& 1
y dy = −log |y| + c = −log(

1 + x2 −x) + c ,
where the absolute value was removed, as
√
1 + x2 −x > 0 for any x.
The two expressions are indeed the same, for
−log(

1 + x2 −x) = log(

1 + x2 + x) = sinh−1 x .
iv) The integral
&
1
√
x2 −1
dx
can be determined by the previous technique. The substitution y = ϕ(x) =
√
x2 −1 −x gives
&
1
√
x2 −1
dx = log |

x2 −1 + x| + c .

9.2 Rules of indeﬁnite integration
311
v) The integral
S =
& 
1 + x2 dx
is found as in example iii). Integrate by parts with f(x) =
√
1 + x2 and g′(x) = 1,
so f ′(x) =
x
√
1 + x2 , g(x) = x and
S = x

1 + x2 −
&
x2
√
1 + x2 dx = x

1 + x2 −
& x2 + 1 −1
√
1 + x2 dx
= x

1 + x2 −
& 
1 + x2 dx +
&
1
√
1 + x2 dx
= x

1 + x2 −S +
&
1
√
1 + x2 dx .
Therefore
2S = x

1 + x2 +
&
1
√
1 + x2 dx = x

1 + x2 + log(

1 + x2 + x) + c,
and eventually
S = 1
2x

1 + x2 + 1
2 log(

1 + x2 + x) + c .
Similar story for
& 
x2 −1 dx.
vi) Determine
S =
& 
1 −x2 dx .
As above, we may integrate by parts remembering
&
1
√
1 −x2 dx = arcsinx+c.
Namely, with f(x) =
√
1 −x2, g′(x) = 1, we have f ′(x) = −
x
√
1 −x2 , g(x) = x,
whence
S = x

1 −x2 −
&
−x2
√
1 −x2 dx = x

1 −x2 −S +
&
1
√
1 −x2 dx .
So we have
2S = x

1 −x2 +
&
1
√
1 −x2 dx ,
i.e.,
S = 1
2x

1 −x2 + 1
2 arcsin x + c .
Let us do this in a diﬀerent way. Put y = arcsin x, so dx = cos y dy and
√
1 −x2 =
cos y. These give
S =
&
cos2 y dy = 1
2
&
(cos 2y + 1) dy = 1
4 sin 2y + 1
2y + c
= 1
2 sin y cos y + 1
2y + c = 1
2x

1 −x2 + 1
2 arcsinx + c .

312
9 Integral calculus I
vii) Finally, let us determine
&
1
ex + e−x dx.
Change y = ex, so dy = exdx, or dx = 1
ydy. Then
&
1
ex + e−x dx =
&
1
y + 1
y
1
y dy
=
&
1
1 + y2 dy = arctan y + c = arctanex + c.
2
Example ii) is a special case of the following useful relation
& ϕ′(x)
ϕ(x) dx = log |ϕ(x)| + c
(9.6)
that descends from (9.5) by f(y) = 1
y:
Hitherto all instances had one common feature: the maps f were built from a
ﬁnite number of elementary functions by algebraic operations and compositions,
and so were the primitives F. In such a case, one says that f is integrable by
elementary methods. Unfortunately though, not all functions arising this way
are integrable by elementary methods. Consider f(x) = e−x2, whose relevance in
Probability Theory is paramount. It can be shown its primitives (which exist, for f
is continuous on R) cannot be expressed by elementary functions. The same holds
for f(x) = sin x
x
.
The problem of ﬁnding an explicit primitive for a given function is highly non-
trivial. A large class of maps which are integrable by elementary methods is that
of rational functions.
9.2.1 Integrating rational maps
Consider maps of the general form
f(x) = P(x)
Q(x),
where P(x) and Q(x) denote polynomials of degrees n, m (m ≥1) respectively.
We want to prove they admit primitives in terms of rational functions, logarithms
and inverse tangent functions.
First of all note that if n ≥m, we may divide P(x) by Q(x)
P(x) = Q(x)D(x) + R(x),
with D(x) a polynomial of degree n −m and R(x) of degree ≤m −1. Therefore

9.2 Rules of indeﬁnite integration
313
& P(x)
Q(x) dx =
&
D(x) dx +
& R(x)
Q(x) dx.
The problem boils down to integrating a rational map g(x) = R(x)
Q(x) in which the
numerator’s degree is less than the denominator’s.
We discuss a few simple situations of this type, which will turn out to be
fundamental for treating the generic integrand.
i) Let g(x) =
1
x −α, with α ∈R; by (9.1) b)
&
1
x −α dx = log |x −α| + c.
(9.7)
ii) Take g(x) =
1
(x −α)r , where r > 1; using (9.1) a) yields
&
1
(x −α)r dx =
1
1 −r
1
(x −α)r−1 + c.
(9.8)
iii) Let g(x) =
1
x2 + 2px + q , with p2 −q < 0, so that the denominator has no real
roots and is positive. Putting
s =

q −p2 > 0,
a little algebra shows
x2 + 2px + q = x2 + 2px + p2 + (q −p2) = (x + p)2 + s2 = s2

1 +
x + p
s
2
.
Now substitute y = ϕ(x) = x + p
s
&
1
x2 + 2px + q dx = 1
s2
&
1
1 + y2 s dy.
Recalling (9.1) f) we may conclude
&
1
x2 + 2px + q dx = 1
s arctan x + p
s
+ c.
(9.9)
iv) Consider g(x) =
ax + b
x2 + 2px + q , with p2 −q still negative. Due to the identity
ax + b = ax + ap + b −ap = a
2(2x + 2p) + (b −ap)

314
9 Integral calculus I
we write
&
ax + b
x2 + 2px + q dx = a
2
&
2x + 2p
x2 + 2px + q dx + (b −ap)
&
1
x2 + 2px + q dx.
Now use (9.6) with ϕ(x) = x2 + 2px + q, and (9.9):
&
ax + b
x2 + 2px + q dx = a
2 log(x2 + 2px + q) + b −ap
s
arctan x + p
s
+ c.
(9.10)
v) More generally, let g(x) =
ax + b
(x2 + 2px + q)r , with p2 −q < 0 and r > 1. Integ-
rating by parts
&
1
(x2 + 2px + q)r−1 dx
and substituting ϕ(x) = x2 + 2px + q, we end up writing the integral of g as sum
of known terms, plus the integral of a map akin to g, but where the exponent is
r−1. Thus the integrand to consider simpliﬁes to one whose denominator is raised
to a smaller power. From r = 1, solved above, we ﬁnd r = 2, then r = 3 et cetera
up to the given r, one step at a time. The argument’s details are left to the willing
reader.
Examples 9.14
As direct application we compute
&
1
2x −4 dx = 1
2 log |x −2| + c,
&
1
(3x + 5)2 dx = −
1
3(3x + 5) + c,
&
4x −5
x2 −2x + 10 dx = 2
&
2x −2
x2 −2x + 10 dx −
&
1
(x −1)2 + 9 dx
= 2 log(x2 −2x + 10) −1
3 arctan x −1
3
+ c.
2
Reducing the integration of the general rational function g(x) = R(x)
Q(x) to the
previous special cases requires a factorisation of the denominator involving only
terms like
(x −α)r
or
(x2 + 2px + q)s
with p2 −q < 0. The existence of such a decomposition descends from a version of
the Fundamental Theorem of Algebra.
Theorem 9.15 A polynomial Q(x) of degree m with real coeﬃcients decom-
poses uniquely as a product
Q(x) = d(x−α1)r1 · · · (x−αh)rh(x2+2p1x+q1)s1 · · · (x2+2pkx+qk)sk, (9.11)

9.2 Rules of indeﬁnite integration
315
where d, αi, pj, qj are real and ri, sj integers such that
r1 + · · · + rh + 2s1 + · · · + 2sk = m .
The αi, all distinct, are the real roots of Q counted with multiplicity ri. The
factors x2+2pjx+qj are pairwise distinct and irreducible over R, i.e., p2
j −qj <
0, and have two complex (-conjugate) roots βj,± of multiplicity sj.
Using the factorisation (9.11) of Q(x) we can now write g(x) as sum of partial
fractions
R(x)
Q(x) = 1
d
#
F1(x) + · · · + Fh(x) + ¯F1(x) + · · · + ¯Fk(x)
$
,
(9.12)
where each Fi(x) takes the form
Fi(x) =
Ai1
x −αi
+
Ai2
(x −αi)2 + · · · +
Airi
(x −αi)ri ,
while ¯Fj(x) are like
¯Fj(x) =
Bj1x + Cj1
x2 + 2pjx + qj
+
Bj2x + Cj2
(x2 + 2pjx + qj)2 + · · · +
Bj¯rjx + Cj¯rj
(x2 + 2pjx + qj)sj ,
for suitable constants Aiℓ, Bjμ, Cjμ. Note the total number of constants is r1 +
· · · rh + 2s1 + · · · + 2sk = m.
To recover the undetermined coeﬃcients we can transform the right-hand side
of (9.12) into one fraction, whose denominator is clearly Q(x). The numerator
R(x) is a polynomial of degree ≤m −1 that must coincide with R(x), and its
coeﬃcients are linear combinations of the unknown constants we are after. To ﬁnd
these numbers, the following principle on identity of polynomials is at our disposal.
Theorem 9.16 Two polynomials of degree m−1 coincide if and only if either
of the next conditions holds
a) the coeﬃcients of corresponding monomials coincide;
b) the polynomials assume the same values at m distinct points.
The ﬁrst equivalence is easily derived from Proposition 7.5.
Going back to the m unknowns Aiℓ, Bjμ, Cjμ, we could impose that the coef-
ﬁcients of each monomial in R(x) and R(x) be the same, or else choose m values
of x where the polynomials must agree. In the latter case the best choice falls on
the real zeroes of Q(x); should these be less than m in number, we could also take
x = 0.
Once these coeﬃcients have been determined, we can start integrating the
right-hand side of (9.12) and rely on the fundamental cases i)–v) above.

316
9 Integral calculus I
As usual, the technique is best illustrated with a few examples.
Examples 9.17
i) Let us integrate
f(x) = 2x3 + x2 −4x + 7
x2 + x −2
.
The numerator has greater degree than the denominator, so we divide the poly-
nomials
f(x) = 2x −1 +
x + 5
x2 + x −2.
The denominator factorises as Q(x) = (x −1)(x + 2). Therefore the coeﬃcients
to be found, A1 = A11 and A2 = A21, should satisfy
x + 5
x2 + x −2 =
A1
x −1 +
A2
x + 2,
that is to say
x + 5 = A1(x + 2) + A2(x −1),
(9.13)
hence
x + 5 = (A1 + A2)x + (2A1 −A2) .
Comparing coeﬃcients yields the linear system
 A1 + A2 = 1,
2A1 −A2 = 5,
solved by A1 = 2, A2 = −1. Another possibility is to compute (9.13) at the
zeroes x = 1, x = −2 of Q(x), obtaining 6 = 3A1 and 3 = −3A2, whence again
A1 = 2, A2 = −1. Therefore,
&
f(x) dx =
&
(2x −1) dx + 2
&
1
x −1 dx −
&
1
x + 2 dx
= x2 −x + 2 log |x −1| −log |x + 2| + c.
ii) Determine a primitive of the function
f(x) = x2 −3x + 3
x3 −2x2 + x.
The denominator splits as Q(x) = x(x −1)2, so we must search for A1 = A11,
A21 and A22 such that
x2 −3x + 3
x3 −2x2 + x = A1
x + A21
x −1 +
A22
(x −1)2 ,
or
x2 −3x + 3 = A1(x −1)2 + A21x(x −1) + A22x .
Putting x = 0 yields A1 = 3, with x = 1 we ﬁnd A22 = 1. The remaining
A21 is determined by picking a third value x ̸= 0, 1. For instance x = −1 gives
7 = 12 + 2A21 −1, so A21 = −2.

9.2 Rules of indeﬁnite integration
317
In conclusion,&
f(x) dx = 3
& 1
x dx −2
&
1
x −1 dx +
&
1
(x −1)2 dx
= 3 log |x| −2 log |x −1| −
1
x −1 + c.
iii) Integrate
f(x) =
3x2 + x −4
x3 + 5x2 + 9x + 5.
The point x = −1 annihilates the denominator (the sum of the odd-degree
coeﬃcients equals those of even degree), so the denominator splits Q(x) =
(x + 1)(x2 + 4x + 5) by Ruﬃni’s rule. The unknown coeﬃcients are A = A11,
B = B11, C = C11 so that
3x2 + x −4
x3 + 5x2 + 9x + 5 =
A
x + 1 +
Bx + C
x2 + 4x + 5,
hence
3x2 + x −4 = A(x2 + 4x + 5) + (Bx + C)(x + 1) .
Choosing x = −1, and then x = 0, produces A = −1 and C = 1. The last
coeﬃcient B = 4 is found by taking x = −1. Thus
&
f(x) dx = −
&
1
x + 1 dx +
&
4x + 1
x2 + 4x + 5 dx
= −
&
1
x + 1 dx + 2
&
2x + 4
x2 + 4x + 5 dx −7
&
1
1 + (x + 2)2 dx
= −log |x + 1| + 2 log(x2 + 4x + 5) −7 arctan(x + 2) + c.
2
Note that many functions f(x) that are not rational in the variable x can be
transformed – by an appropriate change t = ϕ(x) – into a rational map in the new
variable t. Special cases thereof include:
i) f is a rational function of
p√x −a for some integer p and a real. Then one lets
t =
p√x −a,
whence x = a + tp and dx = ptp−1dt.
ii) f is rational in eax for some real a ̸= 0. The substitution
t = eax
gives x = 1
a log t and dx = 1
at dt.
iii) f is rational in sin x and/or cos x. In this case
t = tan x
2 ,
together with the identities
sin x =
2t
1 + t2 ,
cos x = 1 −t2
1 + t2 ,
(9.14)

318
9 Integral calculus I
does the job, because then x = 2 arctant, hence
dx =
2
1 + t2 dt.
(9.15)
iv) If f is rational in sin2 x, cos2 x, tan x, it is more convenient to set t = tan x
and use
sin2 x =
t2
1 + t2 ,
cos2 x =
1
1 + t2 ;
(9.16)
from x = arctant, it follows
dx =
1
1 + t2 dt .
(9.17)
In the concluding examples we only indicate how to arrive at a rational expres-
sion in t, leaving it to the reader to integrate and return to the original variable x.
Examples 9.18
i) Consider
S =
&
x
1 + √x −1 dx.
We let t = √x −1, so x = 1 + t2 and dx = 2t dt. The substitution gives
S = 2
& (1 + t2)t
1 + t
dt.
ii) The integral
S =
&
e−x
e2x −2ex + 2 dx
becomes, by t = ex, dx = 1
t dt,
S =
&
1
t2(t2 −2t + 2) dt.
iii) Reduce the integrand in
S =
&
sin x
1 + sin x dx
to a rational map.
Referring to (9.14) and (9.15),
S = 4
&
t
(1 + t)2(1 + t2) dt.
iv) At last, consider
S =
&
1
1 + sin2 x dx.
Here we use (9.16) and (9.17):
S =
&
1
1 + 2t2 dt.
2

9.3 Deﬁnite integrals
319
a
b
y = f(x)
Figure 9.2. Trapezoidal region of f over [a, b]
9.3 Deﬁnite integrals
Let us consider a bounded map f deﬁned on a bounded and closed interval I =
[a, b] ⊂R. One suggestively calls trapezoidal region of f over the interval
[a, b], denoted by T (f; a, b), the part of plane enclosed within the interval [a, b], the
vertical lines passing through the end-points a, b and the graph of f (see Fig. 9.2)
T (f; a, b) = {(x, y) ∈R2 : a ≤x ≤b,
0 ≤y ≤f(x) or f(x) ≤y ≤0}
(which constraint on y clearly depending on the sign of f(x)).
Under suitable assumptions on f one can associate to the trapezoidal region of
f over [a, b] a number, the ‘deﬁnite integral of f over [a, b]’. In case f is positive,
this number is indeed the area of the region. In particular, when the region is
particularly simple (a rectangle, a triangle, a trapezium and the like), the deﬁnite
integral returns one of the classical formulas of elementary geometry.
The many notions of deﬁnite integral depend on what is demanded of the
integrand. We shall present two types. The ﬁrst one, normally linked to the name
of Cauchy, deals with continuous or piecewise-continuous maps on [a, b].
Deﬁnition 9.19 A map f : [a, b] →R is piecewise-continuous when it
is continuous everywhere except at a ﬁnite number of points, at which the
discontinuity is either removable or a jump.
The second construction goes back to Riemann, and leads to a wider class of
integrable functions1.
1 A further type, known as Lebesgue integral, deﬁnes yet another set of integrable func-
tions, which turns out to be the most natural in modern applications. This theory
though goes beyond the purposes of the present textbook.

320
9 Integral calculus I
9.4 The Cauchy integral
To start with, we assume f continuous on [a, b], and generalise slighty at a suc-
cessive step. The idea is to construct a sequence that approximates the trapezoidal
region of f, and then take a limit-of-sorts. Let us see how.
Take n any positive integer. Divide [a, b] in n equal parts of length Δx = b−a
n
and denote by xk = a + kΔx, k = 0, 1, . . ., n, the subdivision points; note that
they are ordered increasingly by the index, as a = x0 < x1 < . . . < xn−1 < xn = b.
For k = 1, . . . , n, we denote by Ik the interval [xk−1, xk]. The map f is continuous
on [a, b], hence by restriction on each Ik; Weierstrass’s theorem 4.31 implies f
assumes minimum and maximum on Ik, say
mk = min
x∈Ik f(x),
Mk = max
x∈Ik f(x).
Deﬁne now the quantities
sn =
n
	
k=1
mkΔx
and
Sn =
n
	
k=1
MkΔx,
called respectively lower sum and upper sum of f for the above partition of [a, b].
By deﬁnition mk ≤Mk and Δx > 0, so sn ≤Sn.
When f is positive on [a, b], the meaning is immediate (Fig. 9.3): mkΔx repres-
ents the area of the rectangle rk = Ik ×[0, mk], contained in the trapezoidal region
of f over Ik. Thus, sn is the total area of the rectangles rk and approximates from
below the area of T (f; a, b). For the same reasons, Sn is the area of the union of
of rectangles Rk = Ik × [0, Mk], and it approximates T (f; a, b) from above.
Using properties of continuous maps deﬁned on closed and bounded intervals,
we can prove the following result (see Appendix A.5.1, p. 461).
Theorem 9.20 The sequences {sn} and {Sn} are convergent, and their lim-
its coincide.
a
b
y = f(x)
xk−1 xk
Ik
Δx
mk
a
b
y = f(x)
Ik
Δx
Mk
Figure 9.3. Lower sum (left) and upper sum (right) of f on [a, b]

9.4 The Cauchy integral
321
Based on this fact, we can introduce the deﬁnite integral.
Deﬁnition 9.21 One calls deﬁnite integral of f over [a, b] the number
& b
a
f(x) dx = lim
n→∞sn = lim
n→∞Sn
(which we read integral from a to b of f(x)dx or just integral from a to b
of f).
Examples 9.22
i) Take a constant f on [a, b]. If c is its value, then mk = Mk = c for any k, so
sn = Sn = c
n
	
k=1
Δx = c(b −a)
whichever n. Therefore
& b
a
f(x) dx = c(b −a).
ii) Consider f(x) = x over [0, 1]. The region T (x; 0, 1) is the isosceles right
triangle of vertices A = (0, 0), B = (1, 0), C = (1, 1) that has area 1
2. We want
to check the deﬁnite integral of f over [0, 1] gives the same result. Fix n > 1.
Then Δx = 1
n and, for k = 0, . . . , n, xk = k
n. Since f is increasing, mk = xk−1
and Mk = xk, so
sn =
n
	
k=1
xk−1Δx = 1
n2
n
	
k=1
(k −1),
Sn =
n
	
k=1
xkΔx = 1
n2
n
	
k=1
k.
Now
n
	
k=1
k is the sum of the ﬁrst n natural numbers, hence n(n+1)
2
, by (3.2). For
analogous reasons
n
	
k=1
(k −1) is the sum of natural numbers from 0 (or 1) to
n −1, and equals (n−1)n
2
, whence
sn = n(n −1)
2n2
,
Sn = n(n + 1)
2n2
.
Taking the limit for n →∞of these sequences, we ﬁnd 1
2 for both.
2
This example shows that even for a function as harmless as f(x) = x, computing
the deﬁnite integral using the deﬁnition is rather demanding. Obviously one would
hope to have more eﬃcient tools to calculate integrals of continuous maps. For that
we shall have to wait until Sect. 9.8.

322
9 Integral calculus I
We discuss now the extension of the notion of deﬁnite integral. If f is continuous
on [a, b] and x∗denotes an interior point of the interval, it is possible to prove
& b
a
f(x) dx =
& x∗
a
f(x) dx +
& b
x∗f(x) dx.
This formula’s meaning is evident, and it suggests how to deﬁne integrals of
piecewise-continuous maps. Let x0 = a < x1 < . . . < xm−1 < xm = b be the
points where f is not continuous, lying between a and b (assuming the latter
might be discontinuity points too). Let fi be the restriction of f to the interior of
[xi−1, xi] that extends f continuously at the boundary
fi(x) =
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
lim
x→x+
i−1
f(x),
for x = xi−1,
f(x),
for xi−1 < x < xi,
lim
x→x−
i
f(x),
for x = xi.
We deﬁne
& b
a
f(x) dx =
m
	
i=1
& xi
xi−1
fi(x) dx.
If f is genuinely continuous on [a, b], the above box coincides with Deﬁnition 9.21,
because m = 1 and the map f1 is f.
Moreover, it follows immediately that modifying a (piecewise-)continuous map
at a ﬁnite number of points will not alter its deﬁnite integral.
The study of Cauchy’s integral will be resumed with Sect. 9.6.
9.5 The Riemann integral
Throughout the section f will indicate a bounded map on [a, b]. Let us start from
integrating some elementary functions (called step functions), and slowly proceed
to more general maps, whose integral builds upon the former type by means of
upper and lower bounds.
Choose n + 1 points of [a, b] (not necessarily uniformly spread)
a = x0 < x1 < . . . < xn−1 < xn = b .
They induce a partition of [a, b] into sub-intervals Ik = [xk−1, xk], k = 1, . . . , n.
Dividing further one of the Ik we obtain a so-called ﬁner partition, also known as
reﬁnement of the initial partition. Step functions are constant on each subinterval
of a partition of [a, b], see Fig. 9.4. More precisely,

9.5 The Riemann integral
323
a = x0
x1
x2
x3
x4 = b
c1
c2
c3
c4
Figure 9.4. Graph of a step function on [a, b]
Deﬁnition 9.23 A map f : [a, b] →R is a step function if there exist a
partition of [a, b] by {x0, x1, . . . , xn} together with constants c1, c2, . . . , cn ∈R
such that
f(x) = ck ,
∀x ∈(xk−1, xk),
k = 1, . . . , n.
We say that the partition is adapted to f if f is constant on each interval
(xk−1, xk). Reﬁnements of adapted partitions are still adapted. In particular if
f and g are step functions on [a, b], it is always possible to manifacture a parti-
tion that is adapted to both maps just by taking the union of the points of two
partitions adapted to f and g, respectively.
From now on S([a, b]) will denote the set of step functions on [a, b].
Deﬁnition 9.24 Let f ∈S([a, b]) and {x0, x1, . . . , xn} be an adapted parti-
tion. Call ck the constant value of f on (xk−1, xk). Then the number
&
I
f =
n
	
k=1
ck(xk −xk−1)
is called deﬁnite integral of f on I = [a, b].
A few remarks are necessary.
i)
The deﬁnition is independent of the chosen partition. In particular, if f(x) = c
is constant on [a, b],
&
I
f = c(b −a).
ii) Redeﬁning f at a ﬁnite number of places leaves the integral unchanged; in
particular, the deﬁnite integral does not depend upon the values of f at points
of discontinuity.
In case f is positive on I, the number
'
I f represents precisely the area of the
trapezoidal region of f over I: the latter is in fact the sum of rectangles with base
xk −xk−1 and height ck (Fig. 9.5).
The next result will play an important role.

324
9 Integral calculus I
a = x0
x1
x2
x3
x4 = b
Figure 9.5. Region under a positive step function on the interval [a, b]
Property 9.25 If g, h ∈S([a, b]) are such that g(x) ≤h(x), ∀x ∈[a, b], then
&
I
g ≤
&
I
h .
Proof.
Let {x0, x1, . . . , xn} deﬁne a partition adapted to both maps (this exists
by what said earlier). Call ck and dk the values assumed on (xk−1, xk) by
g and h, respectively. By hypothesis ck ≤dk, k = 1, . . . , n, so
&
I
g =
n
	
k=1
ck(xk −xk−1) ≤
n
	
k=1
dk(xk −xk−1) =
&
I
h .
2
Now let f : [a, b] →R be a generic bounded map, and put
sf = sup
x∈[a,b]
f(x) ∈R
and
if =
inf
x∈[a,b] f(x) ∈R.
We introduce the sets of step functions bounding f from above or from below,
namely
S+
f =

h ∈S([a, b]) : f(x) ≤h(x), ∀x ∈[a, b]
(
contains all step functions bigger than f, while
S−
f =

g ∈S([a, b]) : g(x) ≤f(x), ∀x ∈[a, b]
(
contains all those smaller than f. These are not empty, for they contain at least
the constant maps
h(x) = sf
and
g(x) = if .
It then makes sense to look at the sets of deﬁnite integrals.

9.5 The Riemann integral
325
Deﬁnition 9.26 The number
&
I
f = inf
&
I
h : h ∈S+
f

is called the upper integral of f on I = [a, b], and
&
I
f = sup
&
I
g : g ∈S−
f

the lower integral of f on I = [a, b].
As S+
f
̸= ∅, clearly '
If < +∞, and similarly '
If > −∞. The fact that such
quantities are ﬁnite relies on the following.
Property 9.27 Each bounded map f deﬁned on [a, b] satisﬁes
&
I
f ≤
&
I
f.
Proof.
If g ∈S−
f and h ∈S+
f , by deﬁnition
g(x) ≤f(x) ≤h(x) ,
∀x ∈[a, b],
so Property 9.25 implies
&
I
g ≤
&
I
h.
Keeping g ﬁxed and varying h we have
&
I
g ≤
&
I
f.
Now varying g in this inequality proves the claim.
2
At this stage one could ask whether equality in (9.27) holds by any chance for
all bounded maps. The answer is no, as the example tells.
Example 9.28
The Dirichlet function is deﬁned as follows
f(x) =
 1
if x ∈Q ,
0
if x ∈R \ Q .

326
9 Integral calculus I
Each interval (xk−1, xk) of a partition of [0, 1] contains rational and non-rational
points. Step functions in S+
f are all larger than one, whereas the maps in S−
f
will be non-positive (except at a ﬁnite number of places). In conclusion
&
I
f = 1
and
&
I
f = 0 .
2
Our observation motivates introducing the next term.
Deﬁnition 9.29 A bounded map f on I = [a, b] is said integrable (pre-
cisely: Riemann integrable) on I if
&
I
f =
&
I
f.
The common value is called deﬁnite integral of f on [a, b], and denoted
with
'
I f or
' b
a f(x) dx.
When f is a positive map on [a, b] the geometric meaning of the deﬁnite integral
is quite clear: T (f; a, b) is a subset of T (h; a, b) for any function h ∈S+
f , and
contains T (g; a, b) relative to any g ∈S−
f . The upper integral gives thus an estimate
from above (i.e., larger) of the area of the trapezoidal region of f over I, and
similarly, the lower integral represents an approximation from below. Essentially,
f is integrable when these two coincide, hence when the integral ‘is’ the area of
the trapezoidal region of f.
Step functions f are evidently integrable: denoting by
'
I f the quantity of
Deﬁnition 9.24, the fact that f ∈S−
f
implies
'
I f ≤
'
If, and
'
If ≤
'
I f is
consequence of f ∈S+
f . Therefore
&
I
f ≤
&
I
f ≤
&
I
f ≤
&
I
f
and the upper integral must be equal to the lower.
Beyond step functions, the world of integrable maps is vast.
Example 9.30
Consider f(x) = x on [0, 1]. We verify by Riemann integration that the
trapezoidal region of f measures indeed 1/2. Divide [0, 1] into n > 1 equal parts, a
partition corresponding to the points

0, 1
n, 2
n, . . . , n−1
n , 1

=
 k
n : k = 0, . . . , n

.
Now take the step functions
hn(x) =
⎧
⎨
⎩
k
n
if k −1
n
< x ≤k
n,
k = 1, . . . , n,
0
if x = 0,

9.5 The Riemann integral
327
and
gn(x) =
 k −1
n
if k −1
n
< x ≤k
n,
k = 1, . . . , n,
0
if x = 0.
Since gn(x) ≤f(x) ≤hn(x), ∀x ∈[0, 1], it follows hn ∈S+
f , gn ∈S−
f . Moreover
by (3.2),
&
I
hn =
n
	
k=1
k
n
k
n −k −1
n

=
n
	
k=1
k
n2 = 1
n2
n
	
k=1
k = 1
n2
n(n + 1)
2
= 1
2 + 1
2n
and similarly
&
I
gn = 1
2 −1
2n.
These imply &
I
f ≤inf
n
&
I
hn = 1
2
and
&
I
f ≥sup
n
&
I
gn = 1
2,
hence
&
I
f ≤1
2 ≤
&
I
f.
Recalling 9.27 we conclude
'
I f = 1
2.
2
Studying the integrability of a map by means of the deﬁnition is rather non-trivial,
even when one deals with maps having simple expression. So it would be good on
the one hand to know in advance a large class of integrable maps, on the other
to have powerful methods for computing integrals. While the second point will be
addressed in Sect. 9.8, the result we state next is a relatively broad answer to the
former problem; its proof may be found in Appendix A.5.2, p. 463.
Theorem 9.31 Among the class of integrable maps on [a, b] are
a) continuous maps on [a, b];
b) piecewise-continuous maps on [a, b];
c) continuous maps on (a, b) which are bounded on [a, b];
d) monotone functions on [a, b].
As an application of the theorem,
f(x) =
⎧
⎨
⎩
1 + sin 1
x
if 0 < x ≤1,
0
if x = 0,
is integrable, for continuous on (0, 1] and bounded (by 0 and 2) on [0, 1].

328
9 Integral calculus I
0
1
2
0
1
4
1
3
1
2
1
1
4
1
3
1
2
1
Figure 9.6. Integrable maps on [0, 1]
The same for
f(x) =
⎧
⎨
⎩
1
n
if
1
n + 1 < x ≤1
n, n = 1, 2, . . . ,
0
if x = 0,
which is increasing (not strictly) on [0, 1], see Fig. 9.6.
A couple more properties will be useful later; see Appendix A.5.2, p. 466, for
their proof.
Proposition 9.32 If f is integrable on [a, b], then
i) f is integrable on any subinterval [c, d] ⊂[a, b];
ii) |f| is integrable on [a, b].
9.6 Properties of deﬁnite integrals
A (piecewise-)continuous map is Cauchy integrable (Theorem 9.20) and at the
same time integrable following Riemann (Theorem 9.31). The two types of deﬁnite
integral always agree for such maps, as seen explicitly for f(x) = x in Examples
9.22 ii), 9.30. We shall not prove this fact rigorously. Anyhow, that reason is
good enough to use a unique symbol for both Riemann’s and Cauchy’s integrals.
Henceforth R([a, b]) shall be the set of integrable maps on [a, b].
Recall
' b
a f(x) dx is a number, depending only on f and the interval [a, b]; it
certainly depends upon no variable. The letter x, present in the symbol for histor-
ical reasons essentially, is a ‘virtual variable’, and as such may be substituted by
one’s own preferred letter; writing ' b
a f(x) dx, rather than ' b
a f(s) ds or ' b
a f(y) dy
is a matter of taste, for all three symbols represent the same number.

9.6 Properties of deﬁnite integrals
329
a
b
y = f(x)
a
b
y = |f(x)|
Figure 9.7. The area of the trapezoidal region of f on [a, b] is
 b
a
|f(x)| dx
If f ∈R([a, b]) is positive we have shown the deﬁnite integral expresses the area
of the trapezoidal region of f over [a, b]. For negative f the same holds provided
one changes sign to the value. When f has no ﬁxed sign, the integral measures
the diﬀerence of the positive regions (above the x-axis) and the negative regions
(below it), so the area between f and the horizontal axis is also the integral of the
map |f|
Area of T (f; a, b) =
& b
a
|f(x)| dx.
This is due to the symmetrising eﬀect of the absolute value, which reﬂects the
regions lying below the axis in a rigid way (as in Fig. 9.7).
Finally, let us slightly generalise the deﬁnite integral. Take f ∈R([a, b]). For
a ≤c < d ≤b, set
& c
d
f(x) dx = −
& d
c
f(x) dx
and
& c
c
f(x) dx = 0.
(9.18)
The symbol
' d
c f(x) dx is now deﬁned whichever limits c and d we consider in the
integrability domain [a, b].
The following ﬁve properties descend immediately from the deﬁnition.
Theorem 9.33 Let f and g be integrable on a bounded interval I of the real
line.
i) (Additivity with respect to the domain of integration) For any
a, b, c ∈I,
& b
a
f(x) dx =
& c
a
f(x) dx +
& b
c
f(x) dx.

330
9 Integral calculus I
ii) (Linearity) For any a, b ∈I and α, β ∈R,
& b
a

αf(x) + βg(x)

dx = α
& b
a
f(x) dx + β
& b
a
g(x) dx.
iii) (Positivity) Let a, b ∈I, with a < b. If f ≥0 on [a, b] then
& b
a
f(x) dx ≥0.
If f is additionally continuous, equality holds if and only if f is the zero
map.
iv) (Monotonicity) Let a, b ∈I, a < b. If f ≤g in [a, b], then
& b
a
f(x) dx ≤
& b
a
g(x) dx.
v) (Upper and lower bounds) Let a, b ∈I, a < b. Then

& b
a
f(x) dx
 ≤
& b
a
|f(x)| dx.
Proof.
See Appendix A.5.2, p. 467.
2
9.7 Integral mean value
The deﬁnite integral of an integrable map f over the usual real interval [a, b]
furnishes a way of approximating the function’s behaviour by a constant.
Deﬁnition 9.34 By (integral ) mean value (sometimes integral average)
of f over the interval [a, b] one understands the number
m(f; a, b) =
1
b −a
& b
a
f(x) dx.
The geometric meaning is clear when f is positive on [a, b], for an equivalent version
of the mean value reads
& b
a
f(x) dx = (b −a)m(f; a, b).

9.7 Integral mean value
331
a
b
y = f(x)
m(f; a, b)
Figure 9.8. Integral average of f over [a, b]
In this case T (f; a, b) equals the area of the rectangle with base [a, b] and having
the integral average as height (Fig. 9.8).
The next statement formalises the relation between the integral mean value of
a function and its range.
Theorem 9.35 (Mean Value Theorem) Let f be integrable over [a, b].
The integral mean of f over [a, b] satisﬁes
inf
x∈[a,b] f(x) ≤m(f; a, b) ≤sup
x∈[a,b]
f(x).
(9.19)
If moreover f is continuous on [a, b], there is at least one z ∈[a, b] such that
m(f; a, b) = f(z).
(9.20)
Proof.
Call if =
inf
x∈[a,b] f(x) and sf = sup
x∈[a,b]
f(x), so for any x ∈[a, b]
if ≤f(x) ≤sf.
By property iv) of Theorem 9.33
(b −a) if =
& b
a
if dx ≤
& b
a
f(x) dx ≤
& b
a
sf dx = (b −a) sf.
where we have used the expression for the integral of a constant. Now
divide by b −a to attain (9.19).
Supposing f continuous, Weierstrass’s Theorem 4.31 yields
if = min
x∈[a,b] f(x)
and
sf = max
x∈[a,b] f(x),
hence (9.19) tells that m(f; a, b) lies between the maximum and minimum
of f on [a, b]. The existence of a point z for which (9.20) holds then follows
from (4.16).
2

332
9 Integral calculus I
3
4 1
2
m = 0
M = 2
m(f; 0, 2) = f( 3
4)
y = f(x)
1
2
2
m = 0
y = f(x)
M = 5
m(f; 0, 2)
Figure 9.9. The Mean Value Theorem of integral calculus
Example 9.36
The integral mean of the continuous map
f(x) =
 2x
if 0 ≤x ≤1,
2
if 1 < x ≤2,
over [0, 2] is
m(f; 0, 2) = 1
2
& 2
0
f(x) dx = 1
2
& 1
0
2x dx +
& 2
1
2 dx

= 1
2(1 + 2) = 3
2.
In conformity with the statement, the mean value is indeed a value the function
takes, in fact m(f; 0, 2) = f( 3
4) (Fig. 9.9, left).
Consider now the piecewise-continuous map
f(x) =
 2x
if 0 ≤x ≤1,
5
if x > 1.
The mean value over [0, 5/4] is m(f; 0, 5/4) = f(9/10) and belongs to the map’s
range; this is not so when we consider [0, 2], because m(f; 0, 2) = 3 (Fig. 9.9,
right). This example shows that the continuity of f is just a suﬃcient condition
for (9.20) to hold.
2
A closing remark for the sequel. Taking (9.18) into account, we observe that
the mean value formula stays valid if the limits of integration are interchanged,
hence the theorem is correct also when a > b:
m(f; a, b) =
1
b −a
& b
a
f(x) dx =
1
a −b
& a
b
f(x) dx = m(f; b, a).
(9.21)

9.8 The Fundamental Theorem of integral calculus
333
9.8 The Fundamental Theorem of integral calculus
Let f be deﬁned on the real interval I, which we do not assume bounded necessarily,
but suppose f is integrable on every closed and bounded subinterval of I. This is
the case if f is continuous. We call integral function of f on I any map of the
form
F(x) = Fx0(x) =
& x
x0
f(s) ds,
(9.22)
where x0 ∈I is a ﬁxed point and x varies in I. An integral function is thus obtained
by integrating f on an interval in which one end-point is ﬁxed while the other is
variable. By (9.18) any integral function is deﬁned on the whole I, and Fx0 has a
zero at x0.
The Fundamental Theorem of integral calculus establishes the basic inverse
character of the operations of diﬀerentiation and integration, namely that any
integral function of a given continuous map f over I is a primitive of f on that
interval.
Theorem 9.37 (fundamental of integral calculus) Let f be deﬁned and
continuous over a real interval I. Given x0 ∈I, let
F(x) =
& x
x0
f(s) ds
denote an integral function of f on I. Then F is diﬀerentiable everywhere
over I and
F ′(x) = f(x),
∀x ∈I.
Proof.
Let us start by ﬁxing an x inside I and calling Δx an increment (positive
or negative) such that x+Δx belongs to I. Consider the diﬀerence quotient
of F
F(x + Δx) −F(x)
Δx
=
1
Δx
& x+Δx
x0
f(s) ds −
& x
x0
f(s) ds

.
By property i) in Theorem 9.33,
& x+Δx
x0
f(s) ds =
& x
x0
f(s) ds +
& x+Δx
x
f(s) ds
so
F(x + Δx) −F(x)
Δx
=
1
Δx
& x+Δx
x
f(s) ds = m(f; x, x + Δx).

334
9 Integral calculus I
x0
x
x+Δx
z(Δx)
m(f; x, x + Δx)
y = f(x)
Figure 9.10. The Fundamental Theorem of integral calculus
Thus, the diﬀerence quotient of the integral function F between x and
x + Δx equals the mean value of f between x and x + Δx. Since f is
continuous, the Mean Value Theorem 9.35 guarantees the existence in that
interval of a z = z(Δx) for which m(f; x, x + Δx) = f

z(Δx)

, in other
words
F

x + Δx

−F(x)
Δx
= f(z(Δx)).
(9.23)
Take the limit for Δx →0. For simplicity we can assume Δx > 0. From
x ≤z(Δx) ≤x + Δx
and Theorem 4.5 we deduce that
lim
Δx→0+ z(Δx) = x.
By similar arguments
lim
Δx→0−z(Δx) = x, so
lim
Δx→0 z(Δx) = x. But f is
continuous at x, hence (4.11) implies
lim
Δx→0 f

z(Δx)

= f

lim
Δx→0 z(Δx)

= f(x).
Passing to the limit in (9.23), we ﬁnd the thesis
F ′(x) = lim
Δx→0
F(x + Δx) −F(x)
Δx
= f(x).
In case x is a boundary point of I it suﬃces to take one-sided limits instead,
and the same conclusion follows.
2

9.8 The Fundamental Theorem of integral calculus
335
Corollary 9.38 Let Fx0 be an integral function of a continuous f on I. Then
Fx0(x) = G(x) −G(x0),
∀x ∈I
for any primitive map G of f on I.
Proof.
There exists a number c with Fx0(x) = G(x) −c, ∀x ∈I by Theorem 9.4.
The constant is ﬁxed by the condition Fx0(x0) = 0.
2
The next corollary has great importance, for it provides the deﬁnite integral
by means of an arbitrary primitive of the integrand.
Corollary 9.39 Let f be continuous on [a, b] and G any primitive of f on
that interval. Then
& b
a
f(x) dx = G(b) −G(a).
(9.24)
Proof.
Denoting Fa the integral map vanishing at a, one has
& b
a
f(x) dx = Fa(b).
The previous corollary proves the claim once we put x0 = a, x = b.
2
Very often the diﬀerence G(b) −G(a) is written as
#
G(x)
$b
a
or
G(x)
b
a.
Examples 9.40
The three integrals below are computed using (9.24).
& 1
0
x2 dx =
1
3x31
0 = 1
3.
& π
0
sin x dx =
#
−cos x
$π
0 = 2.
& 6
2
1
x dx =
#
log x
$6
2 = log 6 −log 2 = log 3.
2

336
9 Integral calculus I
Remark 9.41 There is a generalisation of the Fundamental Theorem of integ-
ral calculus to piecewise-continuous maps, which goes like this. If f is piecewise-
continuous on all closed and bounded subintervals of I, then any integral function
F on I is continuous on I, it is diﬀerentiable at all points where f is continuous,
and F ′(x) = f(x). Jump discontinuities for f inside I correspond to corner points
for F.
The integral F is called then a generalised primitive of f on I.
2
Now we present an integral representation of a diﬀerentiable map, which turns
out to be useful in many circumstances.
Corollary 9.42 Given f diﬀerentiable on I with continuous ﬁrst derivative,
and any x0 ∈I,
f(x) = f(x0) +
& x
x0
f ′(s) ds,
∀x ∈I.
(9.25)
Proof.
Obviously f is a primitive of its own derivative, so (9.24) gives
& x
x0
f ′(s) ds = f(x) −f(x0),
whence the result follows.
2
We illustrate this result by providing two applications. The ﬁrst one is the
justiﬁcation of the Maclaurin expansion of f(x) = arcsin x and f(x) = arctanx.
First though, a technical lemma.
Lemma 9.43 If ϕ is a continuous map around 0 such that ϕ(x) = o(xα) for
x →0, and α ≥0, then the primitive ψ(x) =
' x
0 ϕ(s) ds satisﬁes ψ(x) =
o(xα+1) as x →0. This can be written as
& x
0
o(sα) ds = o(xα+1)
for x →0.
(9.26)
Proof.
From de l’Hˆopital’s Theorem 6.41,
lim
x→0
ψ(x)
xα+1 = lim
x→0
ψ′(x)
(α + 1)xα =
1
α + 1 lim
x→0
ϕ(x)
xα
= 0.
2
So now take f(x) = arctan x. As its derivative reads f ′(x) =
1
1 + x2 , (9.25)
allows us to write
arctan x =
& x
0
1
1 + s2 ds.

9.8 The Fundamental Theorem of integral calculus
337
The Maclaurin expansion of f ′(s), obtained from (7.18) changing x = s2, reads
1
1 + s2 = 1 −s2 + s4 −. . . + (−1)ms2m + o(s2m+1)
=
m
	
k=0
(−1)ks2k + o(s2m+1).
Term-by-term integration together with (9.26) yields Maclaurin’s expansion for f(x):
arctan x = x −x3
3 + x5
5 −. . . + (−1)m x2m+1
2m + 1 + o(x2m+2)
=
m
	
k=0
(−1)k x2k+1
2k + 1 + o(x2m+2).
As for the inverse sine, write
f(x) = arcsinx =
& x
0
1
√
1 −s2 ds.
Now use (7.17) with α = −1
2 and change x = −s2:
1
√
1 −s2 = 1 + 1
2s2 + 3
8s4 + . . . +

−1
2
m
 s2m + o(s2m+1)
=
m
	
k=0

−1
2
k
 s2k + o(s2m+1).
Integrating the latter term-by-term and using (9.26) yields the expansion
arcsin x = x + x3
6 + 3x5
40 + . . . +

−1
2
m

x2m+1
2m + 1 + o(x2m+2)
=
m
	
k=0

−1
2
k

x2k+1
2k + 1 + o(x2m+2).
As a second application of Corollary 9.42, we derive a new form for the re-
mainder in a Taylor formula, which adds to the already known expressions due to
Peano and Lagrange (recall formulas (7.6) and (7.8)). Such a form, called integral
form, may provide more accurate information on the behaviour of the error than
the previous ones, although under a stronger assumption on the function f. The
proof of this result, that makes use of the Principle of Induction, is given in Ap-
pendix A.4.4, p. 458, where the reader may also ﬁnd an example of application of
the new form.

338
9 Integral calculus I
Theorem 9.44 (Taylor formula with integral remainder) Let n ≥0
be an arbitrary integer, f diﬀerentiable n + 1 times around a point x0, with
continuous derivative of order n + 1. Then
f(x) −T fn,x0(x) = 1
n!
& x
x0
f (n+1)(t)(x −t)n dt .
9.9 Rules of deﬁnite integration
The Fundamental Theorem of integral calculus and the rules that apply to indef-
inite integrals, presented in Sect. 9.2, furnish similar results for deﬁnite integrals.
Theorem 9.45 (Integration by parts) Let f and g be diﬀerentiable with
continuity on [a, b]. Then
& b
a
f(x)g′(x) dx = [f(x)g(x)]b
a −
& b
a
f ′(x)g(x) dx.
(9.27)
Proof.
If H(x) denotes any primitive of f ′(x)g(x) on [a, b], the known result
on integration by parts prescribes that f(x)g(x) −H(x) is a primitive
of f(x)g′(x). Thus (9.24) implies
& b
a
f(x)g′(x) dx =
#
f(x)g(x)
$b
a −
#
H(x)
$b
a.
It then suﬃces to use (9.24) on the map f ′(x)g(x).
2
Theorem 9.46 (Integration by substitution) Let f(y) be continuous on
[a, b]. Take a map ϕ(x) from [α, β] to [a, b], diﬀerentiable with continuity.
Then
& β
α
f

ϕ(x)

ϕ′(x) dx =
& ϕ(β)
ϕ(α)
f(y) dy.
(9.28)
If ϕ bijects [α, β] onto [a, b], this formula may be written as
& b
a
f(y) dy =
& ϕ−1(b)
ϕ−1(a)
f

ϕ(x)

ϕ′(x) dx.
(9.29)

9.9 Rules of deﬁnite integration
339
Proof.
Let F(y) be a primitive of f(y) on [a, b]. Formula (9.28) follows from (9.4)
and Corollary 9.39. When ϕ is bijective, the two formulas are equivalent
for a = ϕ(α), b = ϕ(β) if ϕ is strictly increasing, and a = ϕ(β), b = ϕ(α)
if strictly decreasing.
2
Both formulas are used in concrete applications.
Examples 9.47
i) Compute
&
3π
4
0
sin3 x cos x dx.
Set y = ϕ(x) = sin x, so that ϕ′(x) = cos x, ϕ(0) = 0, ϕ( 3π
4 ) =
1
√
2. From (9.28)
we obtain
&
3π
4
0
sin3 x cos x dx =
&
1
√
2
0
y3 dy =
1
4y4

1
√
2
0
= 1
16.
Note ϕ is not injective on [0, 3π
4 ].
ii) To determine
S =
& 1
0
arcsin

1 −y2 dy,
we change y = ϕ(x) = cos x, with x varying in [0, π
2 ]. On this interval ϕ is strictly
decreasing, hence one-to-one; moreover ϕ(0) = 1 and ϕ( π
2 ) = 0, i.e., ϕ−1(0) = π
2 ,
ϕ−1(1) = 0. Note also
arcsin

1 −cos2 x = arcsin

sin2 x = arcsin(sin x) = x.
Formula (9.29) gives
S =
& 0
π/2
(arcsin

1 −cos2 x) (−sin x) dx =
& π/2
0
x sin x dx,
and eventually we may use (9.27)
S =
#
−x cos x
$π/2
0
+
& π/2
0
cos x dx =
#
sin x
$π/2
0
= 1.
2
Corollary 9.48 Let f be integrable on the interval [−a, a], a > 0. If f is an
even map,
& a
−a
f(x) dx = 2
& a
0
f(x) dx ;
if f is odd,
& a
−a
f(x) dx = 0 .

340
9 Integral calculus I
Proof.
Theorem 9.33 i) gives
& a
−a
f(x) dx =
& 0
−a
f(x) dx +
& a
0
f(x) dx .
Substitute y = ϕ(x) = −x in the middle integral
& 0
−a
f(x) dx = −
& 0
a
f(−y) dy =
& a
0
f(−y) dy .
The right-most integral coincides with
& a
0
f(y) dy if f is even, with its op-
posite when f is odd. The claim follows because the variable of integration
is a mute symbol.
2
9.9.1 Application: computation of areas
This ﬁrst chapter on integrals ends with a few examples of the use of the Funda-
mental Theorem to determine the area of planar regions.
i)
Suppose we are asked to ﬁnd the area A of the region enclosed by the graphs
of the maps y = f(x) = x2 and y = g(x) = √x, given in Fig. 9.11. The curves
meet at points corresponding to x = 0 and x = 1, and the region in question can
be seen as diﬀerence between the trapezoidal region of g and the trapezoidal
region of f, both over the interval [0, 1]. Therefore
A =
& 1
0
g(x) dx −
& 1
0
f(x) dx =
& 1
0
[√x −x2] dx =
2
3x3/2 −1
3x3
1
0
= 1
3.
0
1
1
y = x2
y = √x
Figure 9.11. Region bounded by the graphs of f(x) = x2 and g(x) = √x

9.9 Rules of deﬁnite integration
341
0
r
r
y =
√
r2 −x2
Figure 9.12. Area under y =
√
r2 −x2 in the ﬁrst quadrant
ii) In the second example we check the known relation A(r) = πr2 for the area
of a disc in function of its radius r. The disc centred at the origin with radius
r is the set of points (x, y) such that x2 + y2 ≤r2. The quarter is then the
trapezoidal region of y =
√
r2 −x2 relative to [0, r] (Fig. 9.12), so
A(r) = 4
& r
0

r2 −x2 dx.
Let us change variables by x = ϕ(t) = rt, so that dx = rdt and 0 = ϕ(0), r =
ϕ(1). Because of (9.29), we have
A(r) = 4r2
& 1
0

1 −t2 dt.
(9.30)
From Example 9.13 vi), we already know a primitive of f(t) =
√
1 −t2 is
F(t) = 1
2t

1 −t2 + 1
2 arcsint .
Therefore
A(r) = 4r2
1
2t

1 −t2 + 1
2 arcsin t
1
0
= 4r2 π
4 = πr2 .
iii) We compute the area A of the part of plane bounded by the parabola y =
f(x) = x(1 −x) and the line y = g(x) = −x
2 (Fig. 9.13, left). The curves
intersect at the origin and at ( 3
2, −3
4), plus on the interval [0, 3
2] we have f(x) ≥
g(x). Albeit part of the region overlaps the negative half-plane (where y < 0),
the total area can still be calculated by
A =
& 3/2
0

f(x) −g(x)

dx

342
9 Integral calculus I
1
3
2
−3
4
y = f(x)
y = g(x)
3
2
3
4
y = f(x) + 3
4
y = g(x) + 3
4
Figure 9.13. The area bounded by the graphs of f(x) and g(x) is translation-invariant
for the following reason. The number A is also the area of the region bounded
by the graphs of the translated maps f(x)+ 3
4 and g(x)+ 3
4; shifting the x-axis
vertically so that the origin goes to (0, −3
4), does not alter the surface area
(Fig. 9.13, right). So,
A =
& 3/2
0
3
2x −x2

dx =
3
4x2 −1
3x3
3/2
0
= 9
16 .
9.10 Exercises
1. Determine the general primitive of :
a)
f(x) = (x + 1)27
b) f(x) = e−3x −e−5x
c)
f(x) = x + 1
x2 + 1
d) f(x) = 2 −sin x
2x + cos x
2. Find the primitive map taking the value y0 at x0 of the functions:
a)
f(x) = xe2x2
x0 =
√
2
y0 = 1
b)
f(x) =
x2
1 + x6
x0 = 0
y0 = 1
c)
f(x) = log x
x
x0 = e
y0 = 0
d)
f(x) = cos x esin x
x0 = π
2
y0 = e

9.10 Exercises
343
3. Compute the indeﬁnite integrals:
a)
&
x
x2 + 7 dx
b)
&
(6x + 3)8 dx
c)
& e1/x2
x3
dx
d)
&
1
x log2 x dx
e)
&
ex√
1 + ex dx
f)
&
x
√
x2 + 7
dx
4. Compute the indeﬁnite integrals:
a)
&
x2 sin x dx
b)
&
x2 log 2x dx
c)
&
log2 x dx
d)
&
x arctan x dx
e)
&
e2x cos x dx
f)
&
1
(1 + x2)2 dx
5. Compute the indeﬁnite integrals:
a)
&
2x
x2 −4x + 3 dx
b)
& x4 −5x3 + 8x2 −9x + 11
x2 −5x + 6
dx
c)
&
x
x3 −1 dx
d)
& 17x2 −16x + 60
x4 −16
dx
e)
&
x4 + 1
x3 −x2 dx
f)
& 2x3 −2x2 + 7x + 3
(x2 + 4)(x −1)2
dx
6. Compute the indeﬁnite integrals:
a)
&
e2x
ex + 1 dx
b)
&
1
(ex −2)2 dx
c)
& 1 + cos x
1 −cos x dx
d)
&
1
1 + sin x dx
e)
&
1
cos x dx
f)
&
cos2 x
1 −2 sin2 x dx
7. Compute the indeﬁnite integrals:
a)
&
x
√2 + x dx
b)
&
x
(1 + x2)2 dx
c)
&
1
x −3 + √3 −x dx
d)
&
1
sinh x dx

344
9 Integral calculus I
e)
&
cosh2 x dx
f)
&
log
3
1 + x2 dx
g)
&
1
1 + tan x dx
h)
&
1
e4x + 1 dx
i)
&
sin5 x dx
ℓ)
&
cos4 x dx
8.
Write the primitive of f(x) = |x| log(2 −x) that has a zero at x = 1.
9.
Find the primitive F(x) of f(x) = xe−|x| with
lim
x→+∞F(x) = −5.
10.
What is the primitive, on the interval (−3, +∞), of
f(x) =
x + 2
(|x| + 3)(x −3)
that vanishes at x = 0?
11.
Determine the generalised primitive of
f(x) =

2x3 −5x + 3
if x ≥1,
4x −7
if x < 1
vanishing at the origin.
12.
Verify that
arctan 1
x = π
2 −arctan x ,
∀x > 0 .
13.
Write the Maclaurin expansion of order 9 for the generic primitive of the map
f(x) = cos 2x2.
14.
Write the Maclaurin expansion of order 4 for the generic primitive of the map
f(x) = 2 + e−x
3 + x3 .
15. Determine the following deﬁnite integrals:
a)
& π
0
x cos x dx
b)
& 1/2
0
1
√
1 −x2 dx
c)
& e2
e
x log x dx
d)
& π/2
0
1
4 sin x + 3 cos x dx
e)
& 3
1
1
[x]2 dx
f)
& √
3
0
M(x2 −1) dx
(Recall [x] is the integer part of x and M(x) denotes the mantissa.)

9.10 Exercises
345
16.
Compute the area of the trapezoidal region of f(x) = | log x| restricted
to [e−1, e].
17. Find the area of the region enclosed by y = f(x) and y = g(x), where:
a) f(x) = |x| ,
g(x) =
√
1 −x2
b) f(x) = x2 −2x ,
g(x) = −x2 + x
18.
Determine
F(x) =
& x
−1
(|t −1| + 2) dt .
9.10.1 Solutions
1. Primitive functions:
a) F(x) =
1
28(x + 1)28 + c ;
b) F(x) = 1
5e−5x −1
3e−3x + c .
c) Since we can write
x + 1
x2 + 1 = 1
2
2x
x2 + 1 +
1
x2 + 1,
it follows
F(x) = 1
2 log(x2 + 1) + arctanx + c .
d) F(x) = log |2x + cos x| + c .
2. Primitives:
a) The general primitive f(x) reads F(x) = 1
4e2x2 + c. Imposing F(
√
2) = 1, we
get
1 = 1
4e4 + c
whence
c = 1 −1
4e4,
so the required map is
F(x) = 1
4e2x2 + 1 −1
4e4 .
b) F(x) = 1
3 arctanx3+1 ;
c) F(x) = 1
2 log2 x−1
2 ;
d) F(x) = esin x .
3. Indeﬁnite integrals:
a) S = 1
2 log(x2 + 7) + c ;
b) S =
1
54(6x + 3)9 + c .
c) Changing y =
1
x2 gives dy = −2
x3 dx, hence
S = −1
2
&
et dt = −1
2et + c = −1
2e1/x2 + c .

346
9 Integral calculus I
d) S = −
1
log x + c .
e) Set y = 1 + ex, so that dy = ex dx and
S =
& √
t dt = 2
3t3/2 + c = 2
3

(1 + ex)3 + c .
f) S =
√
x2 + 7 + c .
4. Indeﬁnite integrals:
a) S = (2 −x2) cos x + 2x sin x + c ;
b) S = 1
3x3(log 2x −1
3) + c .
c) We integrate by parts choosing f(x) = log2 x and g′(x) = 1. Then f ′(x) =
2
x log x, g(x) = x , giving
S = x log2 x −2
&
log x dx .
The integral on the right requires another integration by parts (as in Example
9.11 ii)) and eventually leads to
S = x log2 x −2x(log x −1) + c = x(log2 x −2 log x + 2) + c .
d) We take f(x) = arctan x, g′(x) = x and integrate by parts. Since f ′(x) =
1
1+x2
and g(x) = 1
2x2,
S = 1
2x2 arctan x −1
2
&
x2
1 + x2 dx
= 1
2x2 arctan x −1
2
& 
1 −
1
1 + x2

dx
= 1
2x2 arctan x −1
2x + 1
2 arctan x + c .
e) S = 1
5e2x(sin x + 2 cos x) + c .
f) The remarks made on p. 314 v) suggest to integrate S1 =
'
1
1+x2 dx by parts
with f(x) =
1
1+x2 and g′(x) = 1. Then f ′(x) = −
2x
(1+x2)2 , g(x) = x, and
S1 =
&
1
1 + x2 dx =
x
1 + x2 + 2
&
x2
(1 + x2)2 dx
=
x
1 + x2 + 2
& x2 + 1 −1
(1 + x2)2 dx =
x
1 + x2 + 2S1 −2
&
1
(1 + x2)2 dx .
The solution is then
S = 1
2

S1 +
x
1 + x2

= 1
2

arctanx +
x
1 + x2

+ c .

9.10 Exercises
347
5. Indeﬁnite integrals:
a) S = 3 log |x −3| −log |x −1| + c .
b) S = 1
3x3 + 2x + 2 log |x −3| −log |x −2| + c .
c) Splitting into partial fractions
x
x3 −1 =
x
(x −1)(x2 + x + 1) =
A
x −1 +
Bx + C
x2 + x + 1 ,
yields
A(x2 + x + 1) + (Bx + C)(x −1) = x .
From x = 1 and x = 0 we
ﬁnd the constants A = C = 1
3, while x = −1 determines B = −1
3. Therefore
x
x3 −1 = 1
3

1
x −1 −
x −1
x2 + x + 1

= 1
3

1
x −1 −1
2
2x + 1 −3
x2 + x + 1

= 1
3

1
x −1 −1
2
2x + 1
x2 + x + 1 + 3
2
1
(x + 1
2)2 + 3
4

.
In conclusion,
S = 1
3

log |x −1| −1
2 log(x2 + x + 1) +
√
3 arctan 2
√
3
(x + 1
2)

+ c .
d) S = log(x2 + 4) + 3 log |x −2| −5 log |x + 2| + 1
2 arctan x
2 + c .
e) We search for the undetermined coeﬃcients in
x4 + 1
x3 −x2 = x + 1 + x2 + 1
x3 −x2 = x + 1 +
A
x −1 + B
x + C
x2 .
Choosing x = 1 and x = 0 for
Ax2 + (Bx + C)(x −1) = x2 + 1
produces A = 2, C = −1, while x = −1 tells B = −1:
S =
& 
x + 1 +
2
x −1 −1
x −1
x2

dx = 1
2x2+x+2 log |x−1|−log |x|+ 1
x +c .
f) The integrand splits as
2x3 −2x2 + 7x + 3
(x2 + 4)(x −1)2
=
A
x −1 +
B
(x −1)2 + Cx + D
x2 + 4 .
Imposing
A(x −1)(x2 + 4) + B(x2 + 4) + (Cx + D)(x −1)2 = 2x3 −2x2 + 7x + 3 ,

348
9 Integral calculus I
leads to A = 1, B = 2, C = 1, D = −1, hence
S =
& 
1
x −1 +
2
(x −1)2 + x −1
x2 + 4

dx
= log |x −1| −
2
x −1 + 1
2 log(x2 + 4) −1
2 arctan x
2 + c .
6. Indeﬁnite integrals:
a) Put y = ex, then dy = ex dx, and
S =
&
y
y + 1 dy =
& 
1 −
1
y + 1

dy
= y −log |y + 1| + c
= ex −log(ex + 1) + c .
b) S = 1
4x −1
4 log |ex −2| −1
2
1
ex−2 + c .
c) Changing t = tan x
2 we can write cos x = 1−t2
1+t2 and dx =
2
1+t2 dt. Then
S = 2
&
1
t2(1 + t2) dt = 2
&  1
t2 −
1
1 + t2

dt
= −2
t −2 arctant + c = −
2
tan x
2
−x + c .
d) S = −
2
1 + tan x
2
+ c ;
e) S = log

1 + tan x
2
1 −tan x
2
 + c .
f) Set t = tan x, so sin2 x =
t2
1+t2 , cos2 t =
1
1+t2 and dx =
1
1+t2 dt. From that,
S =
&
1
(1 + t2)(1 −t2) dt =
&  A
1 + t +
B
1 −t + Ct + D
1 + t2

dt .
Now evaluate at t = −1, t = 1, t = 0 and t = 2 the condition
A(1 −t)(1 + t2) + B(1 + t)(1 + t2) + (Ct + D)(1 −t2) = 1 ,
to obtain A = 1
4, B = 1
4, C = 0, D = 1
2. Then
S =
& 1
4
1
1 + t + 1
4
1
1 −t + 1
2
1
1 + t2

dt
= 1
4 log |1 + t| −1
4 log |1 −t| + 1
2 arctan t + c
= 1
4 log

1 + t
1 −t
 + 1
2 arctant + c = 1
4 log

sin x + cos x
sin x −cos x
 + 1
2x + c .

9.10 Exercises
349
7. Indeﬁnite integrals:
a) S = 2
3

(2 + x)3 −4√2 + x + c ;
b) S = −
1
2(1+x2) + c .
c) With t2 = 3 −x we have x = 3 −t2 and 2t dt = −dx, so
S =
&
2t
t2 −t dt = 2
&
1
t −1 dt = 2 log |t −1| + c = 2 log |
√
3 −x −1| + c .
d) By deﬁnition sinh x = ex−e−x
2
, so y = ex yields
S =
&
2
y2 −1 dy =
& 
1
y −1 −
1
y + 1

dy
= log |y −1| −log |y + 1| + c = log |ex −1|
ex + 1 + c .
e) S = 1
4
 1
2e2x −1
2e−2x + 2x

+ c = 1
4 sinh 2x + 1
2x + c .
f) Observe log
3√
1 + x2 = 1
3 log(1 + x2) . We integrate by parts putting f(x) =
log(1 + x2), g′(x) = 1, so f ′(x) =
2x
1+x2 and g(x) = x. Then
S = 1
3

x log(1 + x2) −2
&
x2
1 + x2 dx

= 1
3

x log(1 + x2) −2
& 
1 −
1
1 + x2

dx

= 1
3

x log(1 + x2) −2x + 2 arctanx

+ c .
g) S = 1
2

log |1 + tan x| −1
2 log(1 + tan2 x) + x

+ c .
h) Setting y = e4x implies dy = 4e4x dx, dx =
1
4y dy. Thus
S = 1
4
&
1
y(y + 1) dy = 1
4
& 1
y −
1
y + 1

dy
= 1
4 (log |y| −log |y + 1|) + c = 1
4(4x −log(e4x + 1)) + c
= x −1
4 log(e4x + 1) + c .
i) Because
sin5 x = sin x sin4 x = sin x(1 −cos2 x)2 ,
choosing y = cos x has the eﬀect that dy = −sin x dx and
&
sin5 x dx = −
&
(1 −y2)2 dy =
&
(−1 + 2y2 −y4) dy
= −y + 2
3y3 −1
5y5 + c = −cosx + 2
3 cos3 x −1
5 cos5 x + c .

350
9 Integral calculus I
ℓ) Given that cos4 x = cos x cos3 x, let us integrate by parts with f(x) = cos3 x
and g′(x) = cos x, implying f ′(x) = −3 sinx cos2 x and g(x) = sin x. Thus
S =
&
cos4 x dx = sin x cos3 x + 3
&
cos2 x sin2 x dx
= sin x cos3 x + 3
&
cos2 x(1 −cos2 x) dx
= sin x cos3 x + 3
&
cos2 x dx −3S .
Now recalling Example 9.9 ii),
4S = sin x cos3 x + 3
1
2x + 1
4 sin 2x

+ c .
Finally,
&
cos4 x dx = 1
4 sin x cos3 x + 3
8x + 3
16 sin 2x + c .
8. Note that f(x) is deﬁned on (−∞, 2), where
f(x) =
 x log(2 −x)
if 0 ≤x < 2,
−x log(2 −x)
if x < 0 .
In order to ﬁnd a primitive, compute the integral
'
x log(2 −x) dx by parts. Put
g(x) = log(2 −x) and h′(x) = x, implying g′(x) =
1
x−2, h(x) = 1
2x2, and
&
x log(2 −x) dx = 1
2x2 log(2 −x) −1
2
&
x2
x −2 dx
= 1
2x2 log(2 −x) −1
2
& 
x + 2 +
4
x −2

dx
= 1
2x2 log(2 −x) −1
4x2 −x −2 log(2 −x) + c .
Thus
F(x) =
 1
2x2 log(2 −x) −1
4x2 −x −2 log(2 −x) + c1
if 0 ≤x < 2 ,
−1
2x2 log(2 −x) + 1
4x2 + x + 2 log(2 −x) + c2
if x < 0 .
The constraint F(1) = 0 forces c1 = 5
4, and since F must be continuous at x = 0
it follows
F(0+) = −2 log 2 + 5
4 = F(0−) = 2 log 2 + c2 .
This gives c2 = −4 log 2 + 5
4, and the primitive is
F(x) =
 1
2x2 log(2 −x) −1
4x2 −x −2 log(2 −x) + 5
4
if 0 ≤x < 2 ,
−1
2x2 log(2 −x) + 1
4x2 + x + 2 log(2 −x) −4 log 2 + 5
4
if x < 0 .

9.10 Exercises
351
9. We write, equivalently,
f(x) =
 xe−x
if x ≥0 ,
xex
if x < 0 .
With Example 9.11 i) in mind,
F(x) =
 −(x + 1)e−x + c1
if x ≥0 ,
(x −1)ex + c2
if x < 0 .
Continuity at x = 0 implies F(0) = F(0+) = c1 = F(0−) = c2, so the generic
primitive of f is
F(x) =
 −(x + 1)e−x + c
if x ≥0 ,
(x −1)ex + c
if x < 0,
i.e., F(x) = −(|x| + 1)e−|x| + c . Additionally,
lim
x→+∞F(x) =
lim
x→+∞

−(x + 1)e−x + c

= c ,
meaning that the condition
lim
x→+∞F(x) = −5 holds when c = −5. The required
map is
F(x) = −(|x| + 1)e−|x| −5 .
10. Integrate the two cases
f(x) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x + 2
(x + 3)(x −3)
if x ≥0 ,
−x + 2
(x −3)2
if −3 < x < 0 ,
separately, that is, determine
S1 =
&
x + 2
(x + 3)(x −3) dx
and
S2 =
&
x + 2
(x −3)2 dx .
These are rational integrands, so we ought to ﬁnd the partial fractions ﬁrst. Rather
easily one sees
x + 2
(x + 3)(x −3) =
A
x + 3 +
B
x −3 = 1
6

1
x + 3 +
5
x −3

x + 2
(x −3)2 =
A
x −3 +
B
(x −3)2 =
1
x −3 +
5
(x −3)2 ,
whence
S1 = 1
6 (log |x + 3| + 5 log |x −3|) + c1 ,
S2 = log |x −3| −
5
x −3 + c2 .
A primitive of f has then the form

352
9 Integral calculus I
F(x) =
 S1
if x ≥0 ,
−S2
if −3 < x < 0
=
⎧
⎪
⎨
⎪
⎩
1
6 (log |x + 3| + 5 log |x −3|) + c1
if x ≥0 ,
−log |x −3| +
5
x −3 + c2
if −3 < x < 0 .
Continuity and the vanishing at x = 0 tell
0 = F(0) = F(0+) = log 3 + c1 = F(0−) = −log 3 −5
3 + c2 .
Thus c1 = −log 3, c2 = log 3 + 5
3, and
F(x) =
⎧
⎪
⎨
⎪
⎩
1
6 (log(x + 3) + 5 log |x −3|) −log 3
if x ≥0 ,
−log(3 −x) +
5
x −3 + log 3 + 5
3
if −3 < x < 0 .
11. The generalised primitive F(x) of f(x) should be continuous and satisfy
F ′(x) = f(x) at all points where f(x) is continuous, in our case every x ̸= 1.
Therefore
F(x) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
&
(2x3 −5x + 3) dx
if x ≥1,
&
(4x −7) dx
if x < 1
=
⎧
⎪
⎨
⎪
⎩
1
2x4 −5
2x2 + 3x + c1
if x ≥1,
2x2 −7x + c2
if x < 1 ;
the relation of c1, c2 derives from imposing continuity at x = 1:
F(1) = F(1+) = 1 + c1 = F(1−) = −5 + c2 .
Thus c2 = 6 + c1 and
F(x) =
⎧
⎨
⎩
1
2x4 −5
2x2 + 3x + c
if x ≥1,
2x2 −7x + 6 + c
if x < 1 .
Let us demand F(0) = 6 + c = 0, i.e., c = −6. That implies
F(x) =
⎧
⎨
⎩
1
2x4 −5
2x2 + 3x −6
if x ≥1,
2x2 −7x
if x < 1 .
Alternatively, notice the required map (cf. Remark 9.41) equals
F(x) =
& x
0
f(t) dt ,
from which we may then integrate f(t).

9.10 Exercises
353
12. Consider F(x) = arctan 1
x and G(x) = −arctan x. As
F ′(x) = −
1
1 + x2 = G′(x) ,
F(x) and G(x) are primitives of the same f(x) = −
1
1+x2 . As such, Proposition 9.3
ensures they diﬀer by a constant c ∈R
F(x) = G(x) + c .
The value c = π
2 is a consequence of F(1) = π
4 , G(1) = −π
4 .
13. The generic primitive for f is like
F(x) = c +
& x
0
cos 2t2 dt .
By Lemma 9.43, if
cos 2t2 = 1 −2t4 + 2
3t8 + o(t9) ,
t →0 ,
F expands, for x →0, as
F(x) = c +
& x
0

1 −2t4 + 2
3t8 + o(t9)

dt = c + x −2
5x5 + 2
27x9 + o(x10) .
14. As in Exercise 13, write ﬁrst Maclaurin’s polynomial up to degree 3:
f(x) = 1
3

2 + e−x 
1 + x3
3
−1
= 1
3

3 −x + 1
2x2 −1
6x3 + o(x3)
 
1 −1
3x3 + o(x3)

= 1
3

3 −x + 1
2x2 −1
6x3 −x3 + o(x3)

= 1 −1
3x + 1
6x2 −7
18x3 + o(x3) ,
x →0 .
Then
F(x) = c +
& x
0
f(t) dt = c +
& x
0

1 −1
3t + 1
6t2 −7
18t3 + o(t3)

dt
= c + x −1
6x2 + 1
18x3 −7
72x4 + o(x4) ,
x →0 .
15. Deﬁnite integrals:
a) −2 ;
b) π
6 ;
c) 1
4e2(3e2 −1) ;
d) 1
5 log 6 .

354
9 Integral calculus I
e) Since
[x] =
⎧
⎨
⎩
1
if 1 ≤x < 2 ,
2
if 2 ≤x < 3 ,
3
if x = 3 ,
we have
S =
& 2
1
dx +
& 3
2
1
4 dx = 5
4 .
f) The parabola y = x2 −1, on 0 ≤x ≤
√
3, has the following range set:
−1 ≤x2 −1 < 0
for
x ∈[0, 1)
0 ≤x2 −1 < 1
for
x ∈[1,
√
2)
1 ≤x2 −1 < 2
for
x ∈[
√
2,
√
3).
Therefore
M(x2 −1) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
x2 −1 + 1
if x ∈[0, 1) ,
x2 −1
if x ∈[1,
√
2) ,
x2 −1 −1
if x ∈[
√
2,
√
3) ,
0
if x =
√
3 ,
and
S =
& 1
0
x2 dx +
& √
2
1
(x2 −1) dx +
& √
3
√
2
(x2 −2) dx =
√
2 −
√
3 + 1 .
16. As (see Fig. 9.14)
| log x| =
 −log x
if e−1 ≤x < 1 ,
log x
if 1 ≤x < e ,
1
1
e−1
e
Figure 9.14. Trapezoidal region of the function f(x) = | log x|

9.10 Exercises
355
1
−1
y =
√
1 −x2
y = |x|
−
√
2
2
√
2
2
Figure 9.15. Region of Exercise 17 a)
from Example 9.11 ii) we infer
A =
& e
e−1 | log x| dx = −
& 1
e−1 log x dx +
& e
1
log x dx
= −

x(log x −1)
1
e−1 +

x(log x −1)
e
1 = 2 −2
e .
17. Computing areas:
a) The region is symmetric with respect to the y-axis (Fig. 9.15). Comparing to
the example of Sect. 9.9.1, we can say that the area will be
A = 2
& √
2/2
0
(

1 −x2 −x) dx

=

x

1 −x2 + arcsin x
√
2/2
0
−

x2√
2/2
0
= π
4 .
The result agrees with the fact that the region is actually one quarter of a disc.
b)
9
8 .
18. From
|t −1| =
 1 −t
if t < 1 ,
t −1
if t ≥1 ,
we write
F(x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
& x
−1
(1 −t + 2) dt
if x < 1 ,
& 1
−1
(1 −t + 2) dt +
& x
1
(t −1 + 2) dt
if x ≥1
=
⎧
⎪
⎨
⎪
⎩
−1
2x2 + 3x + 7
2
if x < 1 ,
1
2x2 + x + 9
2
if x ≥1 .

10
Integral calculus II
This second chapter on integral calculus consists roughly of two parts. In the
ﬁrst part we give a meaning to the term ‘improper’ integral, and thus extend the
notion of area to include unbounded regions. The investigation relies on the tools
developed when discussing limits.
The remaining part is devoted to the integration of functions of several variables
along curves, which generalises the results on real intervals of Chap. 9.
10.1 Improper integrals
Hitherto integrals have been deﬁned for bounded maps over closed bounded inter-
vals of the real line. However, several applications induce one to consider unboun-
ded intervals quite often, or functions tending to inﬁnity. To cover such cases the
notion of integral, be it Cauchy’s or Riemann’s, must be extended by means of
limits.
We begin with improper integrals with unbounded domain of integration, and
then treat inﬁnite integrands.
10.1.1 Unbounded domains of integration
Let Rloc([a, +∞)) be the set of maps deﬁned on the ray [a, +∞) and integrable
on every closed and bounded subinterval [a, c] of the domain.
Taking f ∈Rloc([a, +∞)) we can introduce the integral function
F(c) =
& c
a
f(x) dx
on [a, +∞). The natural question to answer concerns its behaviour when c →+∞.
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_10,
© Springer International Publishing Switzerland 2015

358
10 Integral calculus II
Deﬁnition 10.1 Let f ∈Rloc([a, +∞)). We (formally) set
& +∞
a
f(x) dx =
lim
c→+∞
& c
a
f(x) dx.
The symbol on the left is said improper integral of f on [a, +∞).
i) If the limit exists and is ﬁnite, we say that the map f is integrable over
[a, +∞), or equivalently, that its improper integral converges.
ii) If the limit exists but is inﬁnite, we say that the improper integral of f
diverges.
iii) If the limit does not exist, we say that the improper integral is inde-
terminate.
The class of integrable maps over [a, +∞) will be indicated R([a, +∞)).
Visualising the improper integral of a positive function is easy. Note ﬁrst that
the following holds.
Proposition 10.2 Let f ∈Rloc([a, +∞)) be such that f(x) ≥0, for all
x ∈[a, +∞). Then the integral map F(c) is increasing on [a, +∞).
Proof.
Take c1, c2 ∈[a, +∞) with c1 < c2. By the property of additivity of the
domain of integration (Theorem 9.33, i)),
F(c2) =
& c2
a
f(x) dx =
& c1
a
f(x) dx +
& c2
c1
f(x) dx
= F(c1) +
& c2
c1
f(x) dx.
The last integral is ≥0 by Theorem 9.33, iii). Therefore F(c2) ≥F(c1). 2
Corollary 10.3 The improper integral of a positive map belonging to
Rloc([a, +∞)) is either convergent or divergent to +∞.
Proof.
This descends from the proposition by applying Theorem 3.27 to F.
2
Going back to the geometric picture, we can say that the improper integral of
a positive function represents the area of the trapezoidal region of f over [a, +∞)
(Fig. 10.1). This region is unbounded and may be viewed as the limit, for c →∞, of
the regions deﬁned over the subintervals [a, c]. The area of the trapezoidal region
over the entire domain of integration [a, +∞) is ﬁnite if the improper integral
converges, and one says that the area is inﬁnite when the integral is divergent.

10.1 Improper integrals
359
a
c
y = f(x)
+∞
Figure 10.1. Trapezoidal region of f over the unbounded interval [a, +∞)
Examples 10.4
i) We consider the integral over [1, +∞) of the family of functions f(x) =
1
xα
for various α > 0. Since
& c
1
1
xα dx =
⎧
⎪
⎨
⎪
⎩
x1−α
1 −α

c
1
if α ̸= 1,
log x|c
1
if α = 1
=
⎧
⎨
⎩
c1−α −1
1 −α
if α ̸= 1,
log c
if α = 1,
when α ̸= 1, one has
& +∞
1
1
xα dx =
lim
c→+∞
c1−α −1
1 −α
=
⎧
⎨
⎩
1
α −1
if α > 1,
+∞
if α < 1.
If α = 1 instead,
& +∞
1
1
x dx =
lim
c→+∞log c = +∞.
The integral behaves in the same manner whichever the lower limit of integration
a > 0. Therefore
& +∞
a
1
xα dx
 converges
if α > 1,
diverges
if α ≤1.
ii) Let f(x) = cos x. The integral
F(c) =
& c
0
cos x dx = sin c
does not admit limit for c →+∞, hence
' +∞
0
cos x dx is indeterminate.
2
Improper integrals inherit some features of deﬁnite integrals. To be precise, if
f, g belong to R([a, +∞)):

360
10 Integral calculus II
i) for any c > a
& +∞
a
f(x) dx =
& c
a
f(x) dx +
& +∞
c
f(x) dx ;
ii) for any α, β ∈R
& +∞
a

αf(x) + βg(x)

dx = α
& +∞
a
f(x) dx + β
& +∞
a
g(x) dx ;
iii) supposing f ≥0 on [a, +∞) then
& +∞
a
f(x) dx ≥0 .
All are consequence of properties i)-iii) in Theorem 9.33 and the properties of
limits.
Convergence criteria
The integrability of f ∈Rloc([a, +∞)) cannot always be established using just the
deﬁnition. Indeed, we may not be able to ﬁnd an integral function F(c) explicitly.
Thus, it becomes all the more important to have other ways to decide about con-
vergence. When the integral is convergent, computing it might require techniques
that are too sophisticated for this textbook, and which will not be discussed.
The ﬁrst convergence test we present concerns positive functions.
Theorem 10.5 (Comparison test) Let f, g ∈Rloc([a, +∞)) be such that
0 ≤f(x) ≤g(x) for all x ∈[a, +∞). Then
0 ≤
& +∞
a
f(x) dx ≤
& +∞
a
g(x) dx.
(10.1)
In particular,
i) if the integral of g converges, so does the integral of f;
ii) if the integral of f diverges, then the integral of g diverges, too.
Proof.
The deﬁnite integral is monotone, and using 0 ≤f(x) ≤g(x) over [a, +∞),
we have
F(c) =
& c
a
f(x) dx ≤
& c
a
g(x) dx = G(c).
By Corollary 10.3 the maps F(c) and G(c) admit limit for c →+∞;
comparing the limits, with the help of Corollary 4.4, we obtain
0 ≤
lim
c→+∞F(c) ≤
lim
c→+∞G(c),
which is (10.1). The statements i) and ii) are straightforward consequences
of (10.1).
2

10.1 Improper integrals
361
Example 10.6
Discuss the convergence of the integrals
& +∞
1
arctan x
x2
dx
and
& +∞
1
arctanx
x
dx.
For all x ∈[1, +∞)
π
4 ≤arctanx < π
2 ,
so
arctanx
x2
<
π
2x2
and
π
4x ≤arctan x
x
.
Therefore
& +∞
1
arctan x
x2
dx <
& +∞
1
π
2x2 dx
and
& +∞
1
π
4x dx ≤
& +∞
1
arctan x
x
dx.
From Example 10.4 we know
& +∞
1
π
2x2 dx converges, whereas
& +∞
1
π
4x dx di-
verges. Because of Theorem 10.5, the implication of i) ensures that the integral
& +∞
1
arctan x
x2
dx converges, while ii) makes
& +∞
1
arctan x
x
dx diverge.
2
When the integrand has no ﬁxed sign, we can rely on this criterion.
Theorem 10.7 (Absolute convergence test) Suppose f ∈Rloc([a, +∞))
is such that |f| ∈R([a, +∞)). Then f ∈R([a, +∞)), and moreover

& +∞
a
f(x) dx
 ≤
& +∞
a
|f(x)| dx.
Proof.
We introduce f+ and f−, respectively called positive and negative part
of f, as follows:
f+(x) = max(f(x), 0) =

f(x)
if f(x) ≥0 ,
0
if f(x) < 0,
f−(x) = max(−f(x), 0) =

0
if f(x) ≥0 ,
−f(x)
if f(x) < 0.
Both are non-negative, and allow to decompose f, |f|:
f(x) = f+(x) −f−(x),
|f(x)| = f+(x) + f−(x)
(10.2)

362
10 Integral calculus II
y = f(x)
y = f+(x)
y = f−(x)
Figure 10.2. Graphs of a map f (left), its positive part (centre) and negative part (right)
(see Fig. 10.2). Adding and subtracting these relations leads to
f+(x) = |f(x)| + f(x)
2
,
f−(x) = |f(x)| −f(x)
2
,
which, together with Theorem 9.33 ii), imply f+, f−∈Rloc([a, +∞)).
Since 0 ≤f+(x), f−(x) ≤|f(x)| for any x ≥a, the Comparison test 10.5
yields that f+ and f−are integrable over [a, +∞). The ﬁrst of (10.2) tells
that also f satisﬁes the same.
Eventually, property v) of Theorem 9.33 implies, for all c > a,

& c
a
f(x) dx
 ≤
& c
a
|f(x)| dx;
Passing to the limit c →+∞proves the claim.
2
Example 10.8
Let us consider the integral
& +∞
1
cos x
x2
dx.
Since
cos x
x2
 ≤
1
x2 , the function |f(x)| =
cos x
x2
 is integrable on [1, +∞) by
Theorem 10.5 and Example 10.4. The above test guarantees integrability, and

& +∞
1
cos x
x2
dx
 ≤
& +∞
1
cos x
x2
 dx ≤
& +∞
1
1
x2 dx = 1.
2
Remark 10.9 The Absolute convergence test is a suﬃcient condition for integ-
rability, not a necessary one. This is clariﬁed by the following example
& +∞
1
sin x
x
dx
converges, but
& +∞
1

sin x
x
 dx
diverges.
(10.3)
(For a proof we refer to Appendix A.5.3, p. 470.)
2
A map f whose absolute value |f| belongs to R([a, +∞)) is said absolutely
integrable on [a, +∞).

10.1 Improper integrals
363
Another useful result is based on the study of the order of inﬁnitesimal of the
integrand as x →+∞.
Theorem 10.10 (Asymptotic comparison test) Suppose the function
f ∈Rloc([a, +∞)) is inﬁnitesimal of order α, for x →+∞, with respect
to ϕ(x) = 1
x. Then
i) if α > 1, f ∈R([a, +∞));
ii) if α ≤1,
& +∞
a
f(x) dx diverges.
Proof.
See Appendix A.5.3, p. 471.
2
Examples 10.11
i) Consider
& +∞
1
(π −2 arctanx) dx.
The map f(x) = π −2 arctanx is inﬁnitesimal of ﬁrst order for x →+∞: by de
l’Hˆopital’s Theorem namely,
lim
x→+∞
π −2 arctanx
1/x
=
lim
x→+∞
2x2
1 + x2 = 2.
The integral therefore diverges.
ii) Discuss the integral
& +∞
1
x + cos x
x3 + sin x dx.
As cos x = o(x), sin x = o(x3) for x →+∞, it follows
x + cos x
x3 + sin x ∼1
x2
x →+∞,
and the integral converges.
2
Let us now consider a family of improper integrals generalising Example 10.4 i).
Example 10.12
We show how the convergence of
& +∞
2
1
xα(log x)β dx
depends on the values of α, β > 0.
i) The case α = 1 can be tackled by direct integration. Changing variables to
t = log x, one has

364
10 Integral calculus II
& +∞
2
1
x(log x)β dx =
& +∞
log 2
1
tβ dt,
so the integral converges if β > 1, diverges if β ≤1.
ii) If α > 1, we observe preliminarily that x ≥2 implies log x ≥log 2 and hence
1
xα(log x)β ≤
1
xα(log 2)β ,
∀x ≥2.
This is suﬃcient to conclude that the integral converges irrespective of β, by the
Comparison test.
iii) When α < 1, let us write
1
xα(log x)β = 1
x
x1−α
(log x)β .
The function
x1−α
(log x)β tends to +∞, for any β. There is thus an M > 0 such
that
1
xα(log x)β ≥M
x ,
∀x ≥2.
By comparison the integral diverges.
2
If f is deﬁned on [k0, +∞), it could turn out useful, sometimes, to think of its
value at x = k as the general term ak of a series. Under appropriate assumptions
then, we can relate the behaviour of the series with that of the integral of f over
[k0, +∞), as shown hereby (a proof of this result may be found in Appendix A.5.3,
p. 472).
Theorem 10.13 (Integral test) Let f be continuous, positive and decreas-
ing on [k0, +∞), for k0 ∈N. Then
∞
	
k=k0+1
f(k) ≤
& +∞
k0
f(x) dx ≤
∞
	
k=k0
f(k) ,
(10.4)
therefore the integral and the series share the same behaviour. Precisely:
a)
& +∞
k0
f(x) dx converges
⇐⇒
∞
	
k=k0
f(k) converges;
b)
& +∞
k0
f(x) dx diverges
⇐⇒
∞
	
k=k0
f(k) diverges.
Examples 10.14
i) The previous criterion tells for which values of the parameter α the general-
ised harmonic series

10.1 Improper integrals
365
∞
	
k=1
1
kα
converges. Note in fact that
1
xα , α > 0, satisﬁes the theorem’s hypotheses, and
has convergent integral over [1, +∞) if and only if α > 1. Therefore
∞
	
k=1
1
kα
 converges for α > 1 ,
diverges for 0 < α ≤1 .
ii) In order to study
∞
	
k=2
1
k log k
we take the map f(x) =
1
x log x; its integral over [2, +∞) diverges, by case i) of
Example 10.12. Then the series
∞
	
k=2
1
k log k is divergent.
2
A last remark to say that an integral can be deﬁned over (−∞, b] by putting
& b
−∞
f(x) dx =
lim
c→−∞
& b
c
f(x) dx.
All properties and convergence results easily adapt.
10.1.2 Unbounded integrands
Consider the set Rloc([a, b)) of functions deﬁned on the bounded interval [a, b) and
integrable over each closed subinterval [a, c], a < c < b.
If f ∈Rloc([a, b)) the integral function
F(c) =
& c
a
f(x) dx
is thus deﬁned over [a, b). We wish to study the limiting behaviour of such, for
c →b−.
Deﬁnition 10.15 Let f ∈Rloc([a, b)) and deﬁne, formally,
& b
a
f(x) dx = lim
c→b−
& c
a
f(x) dx;
(10.5)
as before, the left-hand side is called improper integral of f over [a, b).

366
10 Integral calculus II
i) If the limit exists and is ﬁnite, one says f is (improperly) integrable on
[a, b), or that its improper integral converges.
ii) If the limit exists but inﬁnite, one says that the improper integral of f
is divergent.
iii) If the limit does not exist, one says that the improper integral is inde-
terminate.
As usual, integrable functions over [a, b) shall be denoted by R([a, b)).
If a map is bounded and integrable on [a, b] (according to Cauchy or Riemann),
it is also integrable on [a, b) in the above sense. Its improper integral coincides with
the deﬁnite integral. Indeed, letting M = sup
x∈[a,b]
|f(x)|, we have

& b
a
f(x) dx −
& c
a
f(x) dx
 =

& b
c
f(x) dx
 ≤
& b
c
|f(x)| dx ≤M(b −c) .
In the limit for c →b−we obtain (10.5). This is why the symbol is the same
for deﬁnite and improper integrals. At the same time, (10.5) explains that the
concept of improper integral over a bounded domain is especially relevant when
the integrand is inﬁnite in the neighbourhood of the point b.
Example 10.16
Take f(x) =
1
(b −x)α with α > 0 (Fig. 10.3 shows one choice of the parameter),
and study its integral over [a, b):
& c
a
1
(b −x)α dx =
⎧
⎪
⎨
⎪
⎩
(b −x)1−α
α −1

c
a
if α ̸= 1,
−log(b −x)
c
a
if α = 1
=
⎧
⎪
⎪
⎨
⎪
⎪
⎩
(b −c)1−α −(b −a)1−α
α −1
if α ̸= 1,
log b −a
b −c
if α = 1.
When α ̸= 1,
& b
a
1
(b −x)α dx = lim
c→b−
(b −c)1−α −(b −a)1−α
α −1
=
⎧
⎨
⎩
(b −a)1−α
1 −α
if α < 1,
+∞
if α > 1.
For α = 1,
& b
a
1
b −x dx = lim
c→b−log b −a
b −c = +∞.

10.1 Improper integrals
367
1
2
2
y = f(x)
Figure 10.3. Trapezoidal region of the unbounded map f(x) =
1
√2−x over [ 1
2, 2)
Therefore
& b
a
1
(b −x)α dx
 converges
if α < 1,
diverges
if α ≥1.
2
In analogy to what seen previously, the integral of a positive f over [a, b) can
be proven to be either convergent or divergent to +∞.
Convergence tests similar to those already mentioned hold in the present situ-
ation, so we just state a couple of results, without proofs.
Theorem 10.17 (Comparison test) Let f, g ∈Rloc([a, b)) be such that
0 ≤f(x) ≤g(x) for any x ∈[a, b). Then
0 ≤
& b
a
f(x) dx ≤
& b
a
g(x) dx.
(10.6)
In particular,
i) if the integral of g converges, the integral of f converges;
ii) if the integral of f diverges, the integral of g diverges.
Theorem 10.18 (Asymptotic comparison test) If f ∈Rloc([a, b)) is in-
ﬁnite of order α for x →b−with respect to ϕ(x) =
1
b−x, then
i) if α < 1, f ∈R([a, b));
ii) if α ≥1,
& b
a
f(x) dx diverges.

368
10 Integral calculus II
Integrals over (a, b] are deﬁned similarly:
& b
a
f(x) dx = lim
c→a+
& b
c
f(x) dx.
With the obvious modiﬁcations all properties carry over.
Examples 10.19
i) Consider the integral
& 3
1

7 −x
3 −x dx .
The function f(x) =

7−x
3−x is deﬁned and continuous on [1, 3), but has a dis-
continuity for x →3−. As 7 −x ≤6 on [1, 3), by the Comparison test we have
& 3
1

7 −x
3 −x dx ≤
& 3
1
√
6
√3 −x dx < +∞,
(recall Example 10.16). The integral therefore converges.
ii) Consider
& 2
1
ex + 1
(x −1)2 dx .
When x ∈(1, 2],
e + 1
(x −1)2 <
ex + 1
(x −1)2 ,
so by comparison the integral diverges to +∞.
iii) Determine the behaviour of
& π/2
0
√x
sin x dx .
For x →0+, f(x) =
√x
sin x ∼
1
√x, therefore the integral converges by the Asymp-
totic comparison test .
iv) The integral
& 4
π
log(x −3)
x3 −8x2 + 16x dx
has integrand f deﬁned on [π, 4); f tends to +∞for x →4−and
f(x) = log(1 + (x −4))
x(x −4)2
∼
1
4(x −4),
x →4−.
Thus Theorem 10.18 implies divergence to −∞(f(x) = 1/(x −4) is negative at
the left of x = 4).
2

10.2 More improper integrals
369
10.2 More improper integrals
Suppose we want to integrate a map with ﬁnitely many discontinuities in an inter-
val I, bounded or not. Subdivide I into a ﬁnite number of intervals Ij, j = 1, . . . , n,
so that the restricted map falls into one of the cases examined so far (see Fig. 10.4).
Then formally deﬁne
&
I
f(x) dx =
n
	
j=1
&
Ij
f(x) dx .
One says that the improper integral of f on I converges if the integrals on the
right all converge. It is not so hard to verify that the improper integral’s behaviour
and its value, if convergent, are independent of the chosen partition of I.
Examples 10.20
i) Suppose we want to study
S =
& +∞
−∞
1
1 + x2 dx .
If we split the real line at the origin we can write
S =
& 0
−∞
1
1 + x2 dx +
& +∞
0
1
1 + x2 dx ;
the two integrals converge, both to π/2, so S = π.
ii) The integrand of
S1 =
& +∞
0
sin x
x2
dx
I1
I2
I3
Figure 10.4. Trapezoidal region of an inﬁnite map, over an unbounded interval

370
10 Integral calculus II
is inﬁnite at the origin, so we divide the domain into (0, 1] ∪[1, +∞), obtaining
S1 =
& 1
0
sin x
x2
dx +
& +∞
1
sin x
x2
dx ;
but
sin x
x2
∼1
x
for x →0+
and

sin x
x2
 ≤1
x2 ,
so Theorem 10.18 forces the ﬁrst integral to diverge, whereas the second con-
verges by Theorem 10.5. In conclusion S1 tends to +∞.
For similar reasons
S2 =
& +∞
0
sin x
x3/2 dx
converges.
iii) Let S denote
& 6
1
x −5
(x + 1)
3√
x2 −6x + 8
dx .
The integrand diverges at −1 (which lies outside the domain of integration), at
2 and also at 4. Hence we write
S =
& 2
1
+
& 3
2
+
& 4
3
+
& 6
4

x −5
(x + 1) 3
(x −2)(x −4)
dx .
The function is inﬁnite of order 1/3 for x →2± and also for x →4±, so the
integral converges.
2
10.3 Integrals along curves
The present and next sections deal with the problem of integrating over a curve,
rather than just an interval (see Sect. 8.4). The concept of integral along a curve –
or path integral as it is also known – has its origin in concrete applications, and is
the ﬁrst instance we encounter of an integral of a function of several real variables.
Let γ : [a, b] →Rd (d = 2, 3) be a regular arc and C = γ([a, b]) its image,
called a path. Take f : dom f ⊆Rd →R a function deﬁned at least on C, hence
such that C ⊆dom f. Suppose moreover that the composite map f ◦γ : [a, b] →R,
deﬁned by (f ◦γ)(t) = f

γ(t)

, is continuous on [a, b].
Deﬁnition 10.21 The line integral of f along γ is the number
&
γ
f =
& b
a
f

γ(t)

∥γ′(t)∥dt ,
(10.7)
where ∥γ′(t)∥=

|x′(t)|2 + |y′(t)|2 + |z′(t)|2 is the modulus (i.e., the Euc-
lidean norm) of the vector γ′(t). Alternative expression are ‘path integral of
f along γ’, or simply, ‘integral of f along γ’.

10.3 Integrals along curves
371
The right-hand-side integral in (10.7) is well deﬁned, for the map f

γ(t)

∥γ′(t)∥
is continuous on [a, b]. In fact γ is regular by hypothesis, its components’ ﬁrst de-
rivatives are likewise continuous, and so is the norm ∥γ′(t)∥, by composition. And
recall f

γ(t)

is continuous from the very beginning.
Integrals along curves have the following interpretation. Let γ be a simple arc
in the plane with image C and f a non-negative function on C with graph
Γ(f) =

(x, y, z) ∈R3 : (x, y) ∈dom f, z = f(x, y)

.
By
Σ =

(x, y, z) ∈R3 : (x, y) ∈C, 0 ≤z ≤f(x, y)

we indicate the upright-standing surface bounded by C and by its image f(C) lying
on the graph of f, as in Fig. 10.5. One can prove that the value of the integral of
f along γ equals the area of Σ. For example if f is constant on C, say equal to h,
the area of Σ is the product of the height h times the base C. Accepting that the
base measures ℓ(C) =
' b
a ∥γ′(t)∥dt (which we shall see in Sect. 10.3.1), we have
Area (Σ) = h ℓ(C) =
& b
a
f

γ(t)

∥γ′(t)∥dt =
&
γ
f .
Examples 10.22
i) Let γ : [0, 1] →R2 be the regular arc γ(t) = (t, t2) parametrising the parabola
y = x2 between O = (0, 0) and A = (1, 1). Then γ′(t) = (1, 2t) has length
∥γ′(t)∥=
√
1 + 4t2. If f : R × [0, +∞) →R is deﬁned by f(x, y) = 3x + √y, the
composition f ◦γ reads f

γ(t)

= 3t +
√
t2 = 4t and therefore
&
γ
f =
& 1
0
4t

1 + 4t2 dt .
 
 
 
 
 
 
 
 
Σ
f(C)
C
dom f
Γ(f)
Figure 10.5. Geometric interpretation of the integral along a curve

372
10 Integral calculus II
Substituting s = 1 + 4t2 we obtain
&
γ
f = 2
& 5
1
√s ds = 2
2
3s3/25
1 = 4
3(5
√
5 −1) .
ii) The curve γ : [0, 2π] →R2 parametrises the circle centred at (2, 1) with
radius 2, γ(t) = (2 + cos t, 1 + sin t), so ∥γ′(t)∥=

4 sin2 t + 4 cos2 t = 2 for
all t. With the function f : R2 →R, f(x, y) = (x −2)(y −1) + 1, we have
f

γ(t)

= 4 sin t cos t + 1, and
&
γ
f = 2
& 2π
0
(4 sin t cos t + 1) dt = 2
#
2 sin 2t + t
$2π
0
= 4π .
If we represent the circle by some γ having the same components as γ but t
varying in [0, 2kπ] (i.e., winding k times), then
&
γ
f = 2
& 2kπ
0
(4 sin t cos t + 1) dt = 4kπ .
2
Example ii) shows that integrals along curves depend not only on the image of the
curve along which one integrates, but upon the chosen parametric representation
as well. That said, certain parametrisations give rise to the same integral.
Deﬁnition 10.23 Two regular curves γ : I →Rd, δ : J →Rd are called
equivalent if there is a bijection ϕ : J →I, with continuous and strictly
positive derivative, such that
δ = γ ◦ϕ ,
i.e., δ(τ) = γ

ϕ(τ)

for all τ ∈J.
Deﬁnition 10.24 Let γ : I →Rd be a regular curve. If −I is the interval
{t ∈R : −t ∈I}, the curve −γ : −I →Rd deﬁned by (−γ)(t) = γ(−t) is
termed opposite to γ .
Flipping the parameter means we can write (−γ) = γ ◦ϕ, where ϕ : −I →I is the
bijection ϕ(t) = −t that reverts the orientation of the real line. If γ : [a, b] →Rd
is a regular arc, so is −γ over [−b, −a].
It is convenient to call congruent two curves γ e δ that either are equivalent
or one is equivalent to the opposite of the other. In other words, δ = γ ◦ϕ where
ϕ is a strictly monotone bijection of class C1. Since the values of the parameter
play the role of ‘tags’ for the points on the image C of γ, all curves congruent to γ
still have C as image. Furthermore, a curve congruent to a simple curve obviously
remains simple.

10.3 Integrals along curves
373
Let f be a function deﬁned on the image of a regular arc γ : [a, b] →Rd with
f ◦γ continuous, so that the integral of f along γ exists. The map f ◦δ (where
δ is an arc congruent to γ) is continuous as well, for it arises by composing a
continuous map between intervals with f ◦γ.
Proposition 10.25 Let γ : [a, b] →Rd be a regular arc with image C, f
deﬁned on C such that f ◦γ is continuous. Then
&
γ
f =
&
δ
f ,
for any arc δ congruent to γ.
Proof.
Suppose (−γ)′(t) = −γ′(−t), so norms are preserved, i.e., ∥(−γ)′(t)∥=
∥γ′(−t)∥, and
&
−γ
f =
& −a
−b
f

(−γ)(t)

∥(−γ)′(t)∥dt
=
& −a
−b
f

γ(−t)

∥γ′(−t)∥dt .
With the change of variables s = −t, ds = −dt, we obtain
&
−γ
f = −
& a
b
f

γ(s)

∥γ′(s)∥ds
=
& b
a
f

γ(s)

∥γ′(s)∥ds =
&
γ
f .
Similarly, if δ = γ ◦ϕ, where ϕ : [c, d] →[a, b], is an equivalent arc to γ,
then δ′(τ) = γ′
ϕ(τ)

ϕ′(τ) with ϕ′(τ) > 0. Thus
&
δ
f =
& d
c
f

δ(τ)

∥δ′(τ)∥dτ
=
& d
c
f

γ(ϕ(τ))

∥γ′
ϕ(τ)

ϕ′(τ)∥dτ
=
& d
c
f

γ(ϕ(τ))

∥γ′
ϕ(τ)

∥ϕ′(τ) dτ .
By t = ϕ(τ), hence dt = ϕ′(τ)dτ, we see that
&
δ
f =
& b
a
f

γ(t)

∥γ′(t)∥dt =
&
γ
f .
2

374
10 Integral calculus II
The proposition immediately implies the following result.
Corollary 10.26 The integral of a function along a curve does not change
if the curve is replaced by another one, congruent to it.
Next, let us note that naming c an arbitrary point in (a, b) and setting γ1 =
γ|[a,c], γ2 = γ|[c,b], we have
&
γ
f =
&
γ1
f +
&
γ2
f ,
(10.8)
because integrals are additive with respect to their domain of integration.
Integrating along a curve extends automatically to piecewise-regular arcs. More
precisely, we let γ : [a, b] →R3 be a piecewise-regular arc and take points a =
a0 < a1 < . . . < an = b so that the arcs γi = γ|[ai−1,ai], i = 1, . . . , n, are regular.
Suppose, as before, that f is a map with domain containing the image C of γ and
such that f ◦γ is piecewise-continuous on [a, b]. Then we deﬁne
&
γ
f =
n
	
i=1
&
γi
f ,
coherently with (10.8).
Remark 10.27 Finding an integral along a piecewise-regular arc might be easier
if one uses Corollary 10.26. According to this,
&
γ
f =
n
	
i=1
&
δi
f,
(10.9)
where δi are suitable arcs congruent to γi, i = 1, . . . , n, chosen to simplify com-
putations.
2
Example 10.28
We want to calculate
'
γ x2, where γ : [0, 4] →R2 is the following parametrisation
of the boundary of the unit square [0, 1] × [0, 1]:
γ(t) =
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
γ1(t) = (t, 0)
if 0 ≤t < 1 ,
γ2(t) = (1, t −1)
if 1 ≤t < 2 ,
γ3(t) = (3 −t, 1)
if 2 ≤t < 3 ,
γ4(t) = (0, 4 −t)
if 3 ≤t ≤4

10.3 Integrals along curves
375
O
1
γ1
γ2
γ3
γ4
O
1
δ1
δ2
δ3
δ4
Figure 10.6. Parametrisation of the unit square, Example 10.28
(see Fig. 10.6, left). Let us represent the four sides by
δ1(t) = γ1(t)
0 ≤t ≤1 ,
δ1 = γ1 ,
δ2(t) = (1, t)
0 ≤t ≤1 ,
δ2 ∼γ2 ,
δ3(t) = (t, 1)
0 ≤t ≤1 ,
δ3 ∼−γ3 ,
δ4(t) = (0, t)
0 ≤t ≤1 ,
δ4 ∼−γ4
(see Fig. 10.6, right). Then
&
γ
x2 =
& 1
0
t2 dt +
& 1
0
1 dt +
& 1
0
t2 dt +
& 1
0
0 dt = 5
3 .
2
10.3.1 Length of a curve and arc length
The length of a piecewise-regular curve γ : [a, b] →R3 is, by deﬁnition,
ℓ(γ) =
&
γ
1 .
(10.10)
In case of a regular arc, (10.10) reads
ℓ(γ) =
& b
a
∥γ′(t)∥dt =
& b
a

x′(t)
2 +

y′(t)
2 +

z′(t)
2 dt .
(10.11)
The origin of the term is once again geometric. A ﬁxed partition a = t0 < t1 <
. . . , tn−1 < tn = b of [a, b] determines points Pi = γ(ti) ∈C, i = 0, . . . , n. These
in turn give rise to a (possibly degenerate) polygonal path in R3 whose length is
clearly
ℓ(t0, t1, . . . , tn) =
n
	
i=1
dist (Pi−1, Pi),

376
10 Integral calculus II
dist (Pi−1, Pi) = ∥Pi −Pi−1∥being the Euclidean distance of two consecutive
points. If we let Δti = ti −ti−1, and
Δx
Δt

i
=
x(ti) −x(ti−1)
ti −ti−1

(and similarly for the coordinates y and z), then
∥Pi −Pi−1∥=

x(ti) −x(ti−1)
2 +

y(ti) −y(ti−1)
2 +

z(ti) −z(ti−1)
2
=
Δx
Δt
2
i
+
Δy
Δt
2
i
+
Δz
Δt
2
i
Δti.
Therefore
ℓ(t0, t1, . . . , tn) =
n
	
i=1
Δx
Δt
2
i
+
Δy
Δt
2
i
+
Δz
Δt
2
i
Δti ,
which ought to be considered an approximation of the integral appearing in (10.11).
Provided the curve is suﬃciently regular (piecewise-regular is enough), one can in-
deed prove that the supremum of ℓ(t0, t1, . . . , tn), taken over all possible partitions
of [a, b], is ﬁnite and equals ℓ(γ).
The length, as of (10.10), depends on the image C of the curve but also on the
parametrisation. The circle x2 + y2 = r2, parametrised by γ1(t) = (r cos t, r sin t),
t ∈[0, 2π], has length
ℓ(γ1) =
& 2π
0
r dt = 2πr ,
a well-known result in elementary geometry. But if we represent it using the curve
γ2(t) = (r cos 2t, r sin 2t), t ∈[0, 2π], we obtain
ℓ(γ2) =
& 2π
0
2r dt = 4πr ,
because now the circle winds around twice. Proposition 10.25 says that congruent
curves keep lengths ﬁxed, and it is a fact that the length of a simple curve depends
but on its image C (and not the parametrisation); it is called the length ℓ(C) of
C. In the example, γ1 is simple, in contrast to γ2; as we have seen, ℓ(C) = ℓ(γ1).
Let now γ be a regular curve on the interval I. We ﬁx a point t0 ∈I and deﬁne
the map s : I →R
s(t) =
& t
t0
∥γ′(τ)∥dτ .
(10.12)

10.3 Integrals along curves
377
Recalling (10.11), we have
s(t) =
⎧
⎪
⎨
⎪
⎩
ℓ(γ|[t0,t])
if t > t0 ,
0
if t = t0 ,
−ℓ(γ|[t,t0])
if t < t0 .
In practice the function s furnishes a reparametrisation of the image of γ. As a
matter of fact,
s′(t) = ∥γ′(t)∥> 0 ,
∀t ∈I
by the Fundamental Theorem of integral calculus and by regularity. Therefore s is
strictly increasing, hence invertible, on I. Letting J = s(I) be the image interval
under s, we denote by t : J →I ⊆R the inverse map to s. Otherwise said, we write
t = t(s) in terms of the new parameter s. The curve %γ : J →Rd, %γ(s) = γ

t(s)

,
is equivalent to γ (and as such it has the same image C). If P1 = γ(t1) is a point
on C and t1 corresponds to s1 under the change of variable, then we also have
P1 = %γ(s1). The number s1 is called arc length of P1.
Diﬀerentiating the inverse map,
%γ′(s) = d%γ
ds (s) = dγ
dt

t(s)
 dt
ds(s) =
γ′(t)
∥γ′(t)∥,
whence
∥%γ′(s)∥= 1 ,
∀s ∈J .
This expresses the fact that the arc length parametrises the motion along a curve
with constant ‘speed’ 1.
Remark 10.29 Take γ : [a, b] →R a regular curve and let s be the arc length as
in (10.12), with t0 = a; then s(a) = 0 and s(b) =
' b
a ∥γ′(τ)∥dτ = ℓ(γ). Using this
special parameter, we have
&
γ
f =
&
γ
f =
& ℓ(γ)
0
f
%γ(s)

ds =
& ℓ(γ)
0
f
˜γ(t(s))

ds .
2
The notion of arc length can be deﬁned to cover in the obvious way piecewise-
regular curves.
Example 10.30
The curve γ : R →R3, γ(t) = (cos t, sin t, t) describes the circular helix (see
Example 8.8 vi)). Since ∥γ′(t)∥= ∥(−sin t, cos t, 1)∥= (sin2 t + cos2 t + 1)1/2 =
√
2, choosing t0 = 0 we have
s(t) =
& t
0
∥γ′(τ)∥dτ =
√
2
& t
0
dτ =
√
2t .
It follows that t = t(s) =
√
2
2 s, s ∈R, and the helix can be reparametrised by
arc length
%γ(s) =

cos
√
2
2 s, sin
√
2
2 s,
√
2
2 s

.
2

378
10 Integral calculus II
10.4 Integral vector calculus
The last section deals with vector ﬁelds and their integration, and provides the
correct mathematical framework for basic dynamical concepts such as force ﬁelds
and the work done by a force.
Deﬁnition 10.31 Let Ω indicate a non-empty subset of Rd, d = 2, 3. A
function F : Ω →Rd is called a vector ﬁeld on Ω.
Conventionally fi : Ω →R, i = 1, . . . , d, are the components of F , written
F = (f1, . . . , fd). Using the unit vectors i, j, k introduced in Sect. 8.2.2, we can
also write F = f1i + f2j if d = 2 and F = f1i + f2j + f3k if d = 3.
Vector ﬁelds may be integrated along curves, leading to a slightly more general
notion of path integral. Take a regular arc γ : [a, b] →Rd whose image C = γ([a, b])
is contained in Ω. In this fashion the composition F ◦γ : t →F

γ(t)

maps [a, b]
to Rd. We shall assume this composite is continuous, i.e., every fi

γ(t)

from [a, b]
to R is a continuous map. For any t ∈[a, b] we denote by
τ(t) =
γ′(t)
∥γ′(t)∥
the unit tangent vector to C at P(t) = γ(t). The scalar function Fτ = F · τ,
Fτ(t) =

F · τ

(t) = F

γ(t)

· τ(t)
is the component of the ﬁeld F along the unit tangent to γ at the point P = γ(t).
Deﬁnition 10.32 The line integral or path integral of F along γ is
the integral along the curve γ of the map Fτ:
&
γ
F · dP =
&
γ
Fτ .
As the integral on the right equals
&
γ
Fτ =
&
γ
F · τ =
& b
a
F

γ(t)

· τ(t) ∥γ′(t)∥dt =
& b
a
F

γ(t)

· γ′(t) dt ,
the line integral of F on γ reads
&
γ
F · dP =
& b
a
F

γ(t)

· γ′(t) dt .
(10.13)

10.4 Integral vector calculus
379
Here the physical interpretation is paramount, and throws new light on the consid-
erations made so far. If F describes a ﬁeld of forces applied to C, the line integral
becomes the work done by F during motion along the curve. The counterpart to
Proposition 10.25 is
Proposition 10.33 Let γ : [a, b] →Rd be a regular curve with image C, and
F a vector ﬁeld over C such that F ◦γ is continuous. Then
&
γ
F · dP = −
&
−γ
F · dP
and
&
γ
F · dP =
&
δ
F · dP ,
over any curve δ equivalent to γ.
In mechanics this result would tell that the work is done by (resp. against) the
force if the directions of force and motion are the same (opposite); once a direction
of motion has been ﬁxed, the work depends only on the path and not on how we
move along it.
Examples 10.34
i) Consider the planar vector ﬁeld F : R2 →R2 given by F (x, y) = (y, x). Take
the ellipse x2
9 + y2
4 = 1, parametrised by γ : [0, 2π] →R2, γ(t) = (3 cost, 2 sin t).
Then F

γ(t)

= (2 sin t, 3 cos t) and γ′(t) = (−3 sin t, 2 cost). Therefore
&
γ
F · dP =
& 2π
0
(2 sin t, 3 cost) · (−3 sin t, 2 cost) dt
= 6
& 2π
0
(−sin2 t + cos2 t) dt = 6
& 2π
0
(2 cos2 t −1) dt
= 12
& 2π
0
cos2 t dt −12π = 0 ,
because
& 2π
0
cos2 t dt =
1
2t + 1
4 sin 2t
2π
0
= π
(see Example 9.9 ii)).
ii) Let F : R3 →R3 be given by F (x, y, z) = (ex, x+y, y+z), and γ : [0, 1] →R3
by γ(t) = (t, t2, t3). The vector ﬁeld along the path reads
F

γ(t)

= (et, t + t2, t2 + t3)
and
γ′(t) = (1, 2t, 3t2) .
Thus
&
γ
F · dP =
& 1
0
(et, t + t2, t2 + t3) · (1, 2t, 3t2) dt
=
& 1
0
#
et + 2(t2 + t3) + 3(t4 + t5)
$
dt = e + 19
15 .
2

380
10 Integral calculus II
10.5 Exercises
1. Check the convergence of the following integrals and compute them explicitly:
a)
& +∞
0
1
x2 + 3x + 2 dx
b)
& +∞
0
x
(x + 1)3 dx
c)
& +∞
2
1
x√x −2 dx
d)
& 1
−1
1

|x|(x −4)
dx
2. Discuss the convergence of the improper integrals:
a)
& +∞
0
sin x
x√x dx
b)
& +∞
0
1
log2(2 + ex) dx
c)
& +∞
0
xe−x dx
d)
& +∞
e
log x
3√
x2 dx
e)
& 1
0
√
x −x2
sin πx
dx
f)
& π/2
0
1
√
sin x
dx
g)
& π
0
x −π/2
cos x
√
sin x
dx
h)
& π
0
(π −x) log x

| log(1 −sin x)|
dx
3.
Study the convergence of
Sn =
& +∞
2
x

(x2 + 3)n dx
for varying n ∈N. What is the smallest value of n for which Sn converges?
4. Determine α ∈R such that the integrals below converge:
a)
& +∞
−∞
arctan x
|x|α
dx
b)
& +∞
−∞
1
|x3 + 5x2 + 8x + 4|α dx
c)
& +∞
0
1
xα(4 + 9x)2 dx
d)
& +∞
α
1
(x −2)

|x −3|
dx
5.
For which α ∈R does
& 3
2
x(sin(x −2))α
√
x2 −4
dx
converge? What is its value when α = 0?

10.5 Exercises
381
6. Tell when the following integrals converge:
a)
& +∞
1
(log(x + 1) −log x) dx
b)
& +∞
0
ex −1 −sin x
eπx −1 −sin πx dx
c)
& +∞
2
1
3√x −2 log x −2
x + 1 dx
d)
& +∞
0
x
sin x −(x + x2) log(e + x) dx
7.
Compute the integral of
f(x, y, z) =
x2(1 + 8y)

1 + y + 4x2y
along the curve γ(t) = (t, t2, log t) , t ∈[1, 2].
8. Integrate the function f(x, y) = x on the Jordan curve γ whose image consists
of the parabolic arc of equation y = 4−x2 going from A = (−2, 0) to C = (2, 0),
and the circle x2 + y2 = 4 between C and A.
9.
Let γ be the curve in the ﬁrst quadrant with image the union of the segment
from O = (0, 0) to A = (1, 0), the arc of the ellipse 4x2 + y2 = 4 between
A and B = (
√
2
2 ,
√
2), and the segment joining B to the origin. Integrate
f(x, y) = x + y along the simple closed curve γ.
10. Integrate
f(x, y) =
1
x2 + y2 + 1
along the simple closed curve γ which is piecewise-deﬁned by the segment
from O to A = (
√
2, 0), the arc of equation x2 + y2 = 2 lying between A and
B = (1, 1), and the segment joining B to the origin.
11.
Integrate the vector ﬁeld F (x, y) = (x2, xy) along the curve γ(t) = (t2, t),
t ∈[0, 1].
12. Compute the line integral of the ﬁeld F (x, y, z) = (z, y, 2x) along γ(t) =
(t, t2, t3), t ∈[0, 1].
13. Integrate F (x, y, z) = (2√z, x, y) along γ(t) = (−sin t, cos t, t2), t ∈[0, π
2 ].
14.
Integrate F (x, y) = (xy2, x2y) along the simple path γ consisting of the quad-
rilateral of vertices A = (0, 1), B = (1, 1), C = (0, 2) and D = (1, 2).
15. Integrate F (x, y) = (0, y) along the closed simple curve consisting of the seg-
ment from O to A = (1, 0), the arc of circumference x2 + y2 = 1 between A
and B = (
√
2
2 ,
√
2
2 ), the segment from B back to O.

382
10 Integral calculus II
10.5.1 Solutions
1. Convergence and computation of integrals:
a) log 2 ;
b) 1
2 .
c) The function f(x) =
1
x√x−2 is unbounded at x = 0 and x = 2. The point x = 0
lies outside the domain of integration, hence can be ignored. We then split the
integral as
& +∞
2
1
x√x −2 dx =
& 3
2
1
x√x −2 dx +
& +∞
3
1
x√x −2 dx = S1 + S2 .
For x →2+, f(x) ∼
1
2(x−2)1/2 , so f is inﬁnite of order 1
2 < 1. By Asymptotic
comparison test, i.e., Theorem 10.18, S1 converges. As for S2, let us consider
f when x →+∞. Because
f(x) ∼
1
x · x1/2 =
1
x3/2 ,
x →+∞,
Theorem 10.10 guarantees S2 converges as well.
To compute the integral, let t2 = x −2, hence 2tdt = dx and x = t2 + 2, by
which
S =
& +∞
0
2
t2 + 2 dt =
2
√
2
arctan t
√
2

+∞
0
=
√
2
2 π .
d) The integrand is inﬁnite at x = 0, x = 4. The latter point is irrelevant, for it
does not belong to the domain of integration. At x = 0
f(x) ∼−
1
4

|x|
for
x →0 ,
so the integral converges by applying Theorem 10.18 to
S1 =
& 0
−1
1
√−x(x −4) dx
and
S2 =
& 1
0
1
√x(x −4) dx
separately. For S1, let us change t2 = −x, so 2tdt = −dx and x −4 = −t2 −4.
Then
S1 = −
& 1
0
2
t2 + 4 dt = −arctan t
2

1
0 = −arctan 1
2 .
Putting t2 = x in S2
S2 =
& 1
0
2
t2 −4 dt = 1
2
& 1
0

1
t −2 −
1
t + 2

dt = 1
2

log

t −2
t + 2

1
0
= 1
2 log 1
3 .
Therefore S = S1 + S2 = −

arctan 1
2 + 1
2 log 3

.

10.5 Exercises
383
2. Convergence of improper integrals:
a) Converges.
b) The map f(x) =
1
log2(2+ex) has R as domain since 2 + ex > 2, ∀x ∈R. It is
then suﬃcient to consider x →+∞. As
log(2 + ex) = log ex(1 + 2e−x) = x + log(1 + 2e−x) ,
it follows
f(x) =
1
(x + log(1 + 2e−x))2 ∼1
x2 ,
x →+∞.
The integral converges by Theorem 10.10.
c) Converges.
d) Over the integration domain the map is bounded. Moreover,
log x
3√
x2 ≥
1
3√
x2 ,
∀x ≥e .
By the Comparison test (Theorem 10.5), the integral diverges.
e) Converges;
f) converges.
g) The integrand is not deﬁned at x = 0, π
2 , nor at π. For x = π
2 though, the
function admits a continuous prolongation mapping π
2 to −1, because if we
put t = x −π
2 , then
cos x = cos(t + π
2 ) = −sin t = −sin(x −π
2 )
and so
f(x) =
x −π
2
cos x
√
sin x
∼−1 ,
x →π
2 .
Therefore the integral is ‘proper’ at x = π
2 . From
f(x) ∼−π
2√x ,
x →0+ ,
f(x) ∼−
π
2√π −x ,
x →π−,
we have convergence by asymptotic comparison (Theorem 10.18).
h) The map to be integrated is not deﬁned for x = 0, x = π
2 , x = π. In the limit
x →0+,
f(x) ∼
π log x
| log(1 −x)|1/2 ∼π log x
√x
.
The map has no well-deﬁned order of inﬁnite with respect to the test function
1
x; nevertheless, it is clearly inﬁnite of smaller order than any power
1
xα with
1
2 < α < 1, since the logarithm grows less than
1
xq for any q > 0 when
x →0+. The Asymptotic comparison test (Theorem 10.18) forces the integral
to converge around 0.

384
10 Integral calculus II
About the other points, for x →π
2 , the function tends to 0, so the integral in
not improper at π
2 ; when x →π−, we have
f(x) ∼
(log π)(π −x)
| log(1 + sin(x −π))|1/2 ∼(log π)(π −x)
| sin(x −π)|1/2 ∼(log π)(π −x)1/2 ,
so the integral in x = π is proper because f goes to 0. Eventually then, the
integral always converges.
3. The map is deﬁned over all R with
f(x) ∼x
xn =
1
xn−1 ,
x →+∞.
Thus S converges if n−1 > 1, i.e., the lowest n for which convergence occurs must
be n = 3. Let us ﬁnd
& +∞
2
x

(x2 + 3)3 dx
then. Deﬁne t = x2 + 3, so dt = 2xdx, and
1
2
& +∞
7
t−3/2 dt =
1
√
7
.
4. Interval of convergence of improper integrals:
a) α ∈(1, 2).
b) Having factorised x3+5x2+8x+4 = (x+2)2(x+1), we can study the function
for x →±∞, x →−2 and x →−1:
f(x) ∼
1
|x|3α ,
x →±∞;
f(x) ∼
1
|x + 2|2α ,
x →−2 ;
f(x) ∼
1
|x + 1|α ,
x →−1 .
In order to ensure convergence, we should impose 3α > 1, 2α < 1 plus α < 1.
Therefore α ∈( 1
3, 1
2).
c) α ∈(−1, 1).
d) The integrand is inﬁnite at x = 2 and x = 3. But
f(x) ∼
1
x3/2 ,
x →+∞,
f(x) ∼
1
x −2 ,
x →2 ,
f(x) ∼
1
|x −3|1/2 ,
x →3 ,

10.5 Exercises
385
so everything is ﬁne when x →+∞or x →3. The point x = 2 is problematic
only if included in the domain of integration, whence we should have α > 2 to
guarantee convergence.
5. α > −1
2 and S =
√
5.
6. Convergence of improper integrals:
a) Diverges;
b) converges.
c) Over (2, +∞) the map is not bounded in a neighbourhood of x = 2. Since
log x −2
x + 1 ∼log 1
3(x −2)
is inﬁnite of lower order than any positive power of
1
x−2 when x →2+, it
follows f is inﬁnite of lesser order than
1
(x −2)1/3+α (any α > 0). This order,
for a suitable choice of α (e.g., α = 1
2) is smaller than 1 . Therefore the integral
converges at x = 2.
For x →+∞,
log x −2
x + 1 ∼log

1 −
3
x + 1

∼−
3
x + 1 ∼−3
x ,
whence
f(x) ∼−
3
x1/3 · x = −3
x4/3 ,
x →+∞.
Altogether, the integral converges.
d) Let us examine f at x = 0. As
sin x −(x + x2) log(e + x) = x + o(x2) −(x + x2)

1 + log

1 + x
e

= −x2 + o(x2) −(x + x2)
x
e + o(x)

= −

1 + 1
e

x2 + o(x2) ,
x →0,
we have
f(x) ∼−
1
(1 + 1
e)x ,
x →0 .
The integral then must diverge at x = 0.
Studying the behaviour for x →+∞is unnecessary to conclude that the
integral diverges (albeit a direct computation would establish the same).
7. When t ∈[1, 2],
f

γ(t)

=
t2(1 + 8t2)
√
1 + t2 + 4t4 ,
γ′(t) =

1, 2t, 1
t

,

386
10 Integral calculus II
whence
&
γ
f =
& 2
1
t2(1 + 8t2)
√
1 + t2 + 4t4
1
t

1 + t2 + 4t4 dt =
& 2
1
t(1 + 8t2) dt = 63
2 .
8. 0.
9. First of all we ﬁnd the coordinates of B, intersection in the ﬁrst quadrant of the
straight line y = 2x and the ellipse 4x2+y2 = 4, i.e., B = (
√
2
2 ,
√
2). The piecewise-
regular curve γ can be divided into three regular arcs γ1, γ2, γ3, whose images
are the segment OA, the elliptical path AB and the segment BO respectively. Let
us reparametrise these arcs by calling them:
δ1(t) = (t, 0)
0 ≤t ≤1 ,
δ1 = γ1 ,
δ2(t) = (cos t, 2 sin t)
0 ≤t ≤π
4 ,
δ2 ∼γ2 ,
δ3(t) = (t, 2t)
0 ≤t ≤
√
2
2 ,
δ3 ∼−γ3 .
Then
&
γ
f =
&
δ1
f +
&
δ2
f +
&
δ3
f .
Since
f

δ1(t)

= t ,
f

δ2(t)

= cos t + 2 sin t ,
f

δ3(t)

= 3t ,
δ′
1(t) = (1, 0) ,
δ′
2(t) = (−sin t, 2 cost) ,
δ′
3(t) = (1, 2) ,
∥δ′
1(t)∥= 1 ,
∥δ′
2(t)∥=

sin2 t + 4 cos2 t ,
∥δ′
3(t)∥=
√
5 ,
we have
&
γ
f =
& 1
0
t dt +
& π/4
0

cos t + 2 sin t

sin2 t + 4 cos2 t dt +
& √
2/2
0
3
√
5t dt
= 1
2 + 3
4
√
5 +
& π/4
0
cos t

4 −3 sin2 t dt + 2
& π/4
0
sin t

1 + 3 cos2 t dt
= 1
2 + 3
4
√
5 + I1 + I2 .
To compute I1, put u =
√
3 sin t, so du =
√
3 cos t dt, and
I1 =
1
√
3
& √
6/2
0

4 −u2 du .
With the substitution v = u
2 , and recalling Example 9.13 vi),
I1 =
1
√
3
1
2u

4 −u2 + 2 arcsin u
2
√
6/2
0
=
√
5
4 + 2
√
3 arcsin
√
6
4 .

10.5 Exercises
387
For I2 the story goes analogously: let u =
√
3 cos t, hence du = −
√
3 sin t dt and
I2 = −2
√
3
& √
6/2
0

1 + u2 du .
By Example 9.13 v), we have
I2 = −2
√
3
1
2u

1 + u2 + 1
2 log

1 + u2 + u
√
6/2
√
3
= −
√
5
2 + 2 + 1
√
3

log(2 +
√
3) −log
√
10 −
√
6
2

.
Overall,
&
γ
f = 5
2 +
√
5
2 + 2
√
3 arcsin
√
6
4 + 1
√
3

log(2 +
√
3) −log
√
10 −
√
6
2

.
10. 2 arctan
√
2 +
√
2
12 π.
11. Since F

γ(t)

= (t4, t3) and γ′(t) = (2t, 1),
&
γ
F · dP =
& 1
0
(t4, t3) · (2t, 1) dt =
& 1
0
(2t5 + t3) dt = 7
12 .
12. 9
4 ;
13. π
4 .
14. The arc γ is piecewise-regular, so we take the regular bits γ1, γ2, γ3 whose
images are the segments AB, BC, CD. Deﬁne δi, reparametrisation of γi, ∀i =
1, 2, 3, by
δ1(t) = (t, 1)
0 ≤t ≤1 ,
δ1 ∼γ1 ,
δ2(t) = (t, 2 −t)
0 ≤t ≤1 ,
δ2 ∼−γ2 ,
δ3(t) = (t, 2)
0 ≤t ≤1 ,
δ3 ∼γ3 .
Since
F

δ1(t)

= (t, t2) ,
F

δ2(t)

=

t(2 −t)2, t2(2 −t)

,
F

δ3(t)

= (4t, 2t2)
δ′
1(t) = (1, 0) ,
δ′
2(t) = (1, −1) ,
δ′
3(t) = (1, 0) ,
one has&
γ
F · dP =
&
δ1
F · dP −
&
δ2
F · dP +
&
δ3
F · dP
=
& 1
0
(t, t2) · (1, 0) dt −
& 1
0

t(2 −t)2, t2(2 −t)

· (1, −1) dt
+
& 1
0
(4t, 2t2) · (1, 0) dt = 2 .
15. 0.

11
Ordinary diﬀerential equations
A large part of the natural phenomena occurring in physics, engineering and other
applied sciences can be described by a mathematical model, a collection of relations
involving a function and its derivatives. The example of uniformly accelerated
motion is typical, the relation being
d2s
dt2 = g,
(11.1)
where s = s(t) is the motion in function of time t, and g is the acceleration.
Another example is radioactive decay. The rate of disintegration of a radioactive
substance in time is proportional to the quantity of matter:
dy
dt = −ky,
(11.2)
in which y = y(t) is the mass of the element and k > 0 the decay constant. The
above relations are instances of diﬀerential equations.
The present chapter aims at introducing the reader to some types of diﬀerential
equations. Although we cannot aﬀord to go into the general theory, we will present
the basic notions and explain a few techniques for solving certain classes of diﬀer-
ential equations (of ﬁrst and second order) that we judge particularly signiﬁcant.
11.1 General deﬁnitions
By an ordinary diﬀerential equation, abbreviated ODE, one understands a
relation among an independent real variable, say x, an unknown function y = y(x)
and its derivatives y(k) up to a speciﬁed order n. It is indicated by
F(x, y, y′, ..., y(n)) = 0,
(11.3)
where F is a real map depending on n + 2 real variables. The diﬀerential equation
has order n, if n is the highest order of diﬀerentiation in (11.3). A solution (in
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_11,
© Springer International Publishing Switzerland 2015

390
11 Ordinary diﬀerential equations
the classical sense) of the ODE over a real interval I is a function y : I →R,
diﬀerentiable n times on I, such that
F

x, y(x), y′(x), ..., y(n)(x)

= 0
for all x ∈I.
It happens many times that the highest derivative y(n) in (11.3) can be ex-
pressed in terms of x and the remaining derivatives explicitly,
y(n) = f(x, y, ..., y(n−1)),
(11.4)
with f a real function of n + 1 variables (in several concrete cases this is precisely
the form in which the equation crops up). If so, the diﬀerential equation is written
in normal form. It should also be clear what the term ‘solution of an ordinary
diﬀerential equation in normal form’ means.
A diﬀerential equation is said autonomous if F (or f) does not depend on
the variable x. Equations (11.1), (11.2) are autonomous diﬀerential equations in
normal form, of order two and one respectively.
The rest of the chapter is committed to ﬁrst order diﬀerential equations in
normal form, together with a particularly important class of equations of the
second order.
11.2 First order diﬀerential equations
Let f be a real-valued map deﬁned on a subset of R2. A solution to the equation
y′ = f(x, y)
(11.5)
over an interval I of R is a diﬀerentiable map y = y(x) such that y′(x) = f

x, y(x)

for any x ∈I. The graph of a solution to (11.5) is called integral curve of the
diﬀerential equation.
Relation (11.5) admits a signiﬁcant geometric interpretation. For each point
(x, y) in the domain of f, f(x, y) is the slope of the tangent to the integral curve
containing (x, y) – assuming the curve exists in the ﬁrst place – so equation (11.5)
is ﬁttingly represented by a ﬁeld of directions in the plane (see Fig. 11.1).
Remark 11.1 If we start to move from (x, y) = (x0, y0) along the straight line
with slope f(x0, y0) (the tangent), we reach a point (x1, y1) in the proximity of
the integral curve passing through (x0, y0). From there we can advance a little bit
farther along the next tangent, reach (x2, y2) nearby the curve and so on, progress-
ively building a polygonal path close to the integral curve issuing from (x0, y0).
This is the so-called explicit Euler method which is the simplest numerical proced-
ure for approximating the solution of a diﬀerential equation when no analytical
tools are available. This and other techniques are the content of the lecture course
on Numerical Analysis.
2

11.2 First order diﬀerential equations
391
Figure 11.1. Field of directions representing y′ = (1 + x)y + x2
Solving (11.5) generalises the problem of ﬁnding the primitives of a given map.
If f depends on x and not on y, (11.5) reads
y′ = f(x);
(11.6)
assuming f continuous on I, the solutions are precisely the primitives y(x) =
F(x) + C of f over I, with F a particular primitive and C an arbitrary constant.
This shows that, at least in the case where f does not depend upon y, (11.5) admits
inﬁnitely many distinct solutions, which depend on one constant. Note that any
chosen integral curve is the vertical translate of another.
Actually, equation (11.6) plays a fundamental role, because in several circum-
stances, suitable manipulations show that solving (11.5) boils down to the quest for
primitives of known functions. Furthermore, under fairly general hypotheses one
can prove that (11.5) always admits a one-parameter family of distinct solutions,
depending on an arbitrary constant of integration C. We shall write solutions in
the form
y = y(x; C)
(11.7)
with C varying in (an interval of) R. An expression like (11.7) is the general
integral of equation (11.5), while any solution corresponding to a particular choice
of C shall be a particular integral.
Example 11.2
Solving the diﬀerential equation
y′ = y
(11.8)
amounts to locating the maps that coincide with their ﬁrst derivative. We have
already remarked that the exponential y(x) = ex enjoys this important property.

392
11 Ordinary diﬀerential equations
Figure 11.2. Integral curves of y′ = y
Since diﬀerentiating is a linear operation, any function y(x) = Cex, C ∈R
possesses this feature. Further on we will prove there are no other maps doing
the same, so we can conclude that the solutions to (11.8) belong to the family
y(x; C) = Cex,
C ∈R.
The integral curves are drawn in Fig. 11.2.
2
In order to get hold of a particular integral of (11.5), one should tell how to
select one value of the constant of integration. A customary way to do so is to
ask that the solution assume a speciﬁc value at a point x ﬁxed in advance. More
explicitly, we impose y(x0; C) = y0, where x0 and y0 are given, corresponding to
the geometric constraint that the integral curve passes through (x0, y0). Essen-
tially, we have solved a so-called initial value problem. More precisely, an initial
value problem, or a Cauchy problem, for (11.5) on the interval I consists in
determining a diﬀerentiable function y = y(x) such that

y′ = f(x, y)
on I,
y(x0) = y0
(11.9)
with given points x0 ∈I, y0 ∈R. The understated reference to time in the words
‘initial value’ is due to the fact that many instances of (11.9) model the evolution
of a physical system, which is in the state y0 at the time x0 in which simulation
starts.

11.2 First order diﬀerential equations
393
Example 11.3
The initial value problem y′ = y,
on I = [0, +∞) ,
y(0) = 2,
is solved by the function y(x) = 2ex.
2
Remark 11.4 The prescription of an initial condition, albeit rather common, is
not the sole possibility to pin down a particular solution of a diﬀerential equation.
Take the following problem as example: ﬁnd the solution of y′ = y having mean
value 1 on the interval I = [0, 2]. The general solution y = Cex has to satisfy the
constraint
1
2
& 2
0
y(x) dx = 1 ,
which easily yields C =
2
e2−1.
2
Remark 11.5 Let us return to equations of order n for the moment. With the
proper assumptions, the general integral of such an equation depends upon n real,
arbitrary constants of integration Ck (k = 1, 2, ..., n)
y = y(x; C1, C2, ..., Cn).
The initial value problem supplies the values of y and its n −1 derivatives at a
given x0 ∈I
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
y(n) = f(x, y, ..., y(n−1))
on I,
y(x0) = y00,
y′(x0) = y01,
...
y(n−1)(x0) = y0,n−1,
where y00, y01, ..., y0,n−1 are n ﬁxed real numbers. For instance, the trajectory of
the particle described by equation (11.1) is uniquely determined by the initial
position s(0) and initial velocity s′(0).
Besides initial value problems, a particular solution to a higher order equation
can be found by assigning values to the solution (and/or some derivatives) at the
end-points of the interval. In this case one speaks of a boundary value problem.
For instance, the problem of the second order
 y′′ = k sin y
on the interval (a, b),
y(a) = 0, y(b) = 0 ,
models the sag from the rest position of a thin elastic beam subject to a small
load acting in the direction of the x-axis.
2
We focus now on three special kinds of ﬁrst order diﬀerential equations, which
can be solved by ﬁnding few primitive functions.

394
11 Ordinary diﬀerential equations
11.2.1 Equations with separable variables
The variables are said “separable” in diﬀerential equations of type
y′ = g(x)h(y),
(11.10)
where the f(x, y) of (11.5) is the product of a continuous g depending only on x,
and a continuous function h of y alone.
If ¯y ∈R annihilates h, i.e., h(¯y) = 0, the constant map y(x) = ¯y is a particular
integral of (11.10), for the equation becomes 0 = 0. Therefore an equation with
separable variables has, to start with, as many particular solutions y(x) = constant
as the number of distinct zeroes of h. These are called singular integrals of the
diﬀerential equation.
On each interval J where h(y) does not vanish we can write (11.10) as
1
h(y)
dy
dx = g(x).
Let H(y) be a primitive of
1
h(y) (with respect to y). By the Chain rule (Theorem
6.7)
d
dx H

y(x)

= dH
dy
dy
dx =
1
h(y)
dy
dx = g(x) ,
so H

y(x)

is a primitive function of g(x). Therefore, given an arbitrary primitive
G(x) of g(x), we have
H

y(x)

= G(x) + C,
C ∈R.
(11.11)
But we assumed
1
h(y) = dH
dy had no zeroes on J, hence it must have constant
sign (being continuous). This implies that H(y) is strictly monotone on J, i.e.,
invertible by Theorem 2.8. We are then allowed to make y(x) explicit in (11.11):
y(x) = H−1
G(x) + C

,
(11.12)
where H−1 is the inverse of H. This expression is the general integral of equation
(11.10) over every interval where h

y(x)

is never zero. But, should we not be
able to attain the analytic expression of H−1(x), formula (11.12) would have a
paltry theoretical meaning. In such an event one is entitled to stop at the implicit
form (11.11).
If equation (11.10) has singular solutions, these might admit the form (11.12)
for special values of C. Sometimes, taking the limit for C →±∞in (11.12) fur-
nishes singular integrals.

11.2 First order diﬀerential equations
395
Formula (11.11) is best remembered by interpreting the derivative dy
dx as a
formal ratio, following Leibniz. Namely, dividing (11.10) by h(y) and ‘multiplying’
by dx gives
dy
h(y) = g(x)dx,
which can be then integrated
&
dy
h(y) =
&
g(x) dx.
This corresponds exactly to (11.11). The reader must not forget though that the
correct proof of the formula is the one showed earlier!
Examples 11.6
i) Solve the diﬀerential equation
y′ = y(1 −y).
Let us put g(x) = 1 and
h(y) = y(1 −y). The zeroes of h produce two singular integrals y1(x) = 0 and
y2(x) = 1.
Suppose now h(y) is not 0. We write the equation as
&
dy
y(1 −y) =
&
dx,
then integrate with respect to y on the left, and on the right with respect to x
log

y
1 −y
 = x + C.
Exponentiating, we obtain

y
1 −y
 = ex+C = kex,
where k = eC is an arbitrary positive constant. Therefore
y
1 −y = ±kex = Kex,
K being any non-zero constant. Writing y in function of x, we get
y(x) =
Kex
1 + Kex .
Note the singular solution y1(x) = 0 belongs to the above family for K = 0, a
value K was originally prevented to take. The other singular integral, y2(x) = 1,
formally arises by letting K go to inﬁnity.
ii) Consider the equation
y′ = √y.
At ﬁrst glance we spot the singular solution y1(x) = 0. That apart, by separating
variables we have &
dy
√y =
&
dx
hence
2√y = x + C ,

396
11 Ordinary diﬀerential equations
and so
y(x) =
x
2 + C
2
,
C ∈R
(where C/2 has become C).
iii) Solve
y′ = ex + 1
ey + 1.
Let g(x) = ex+1 and h(y) =
1
ey + 1 > 0 for any y; there are no singular integrals.
The separation of x and y yields
&
(ey + 1) dy =
&
(ex + 1) dx ,
so
ey + y = ex + x + C,
C ∈R.
But now we are stuck, for it is not possible to explicitly write y as function of
the variable x.
2
11.2.2 Linear equations
A diﬀerential equation akin to
y′ + a(x)y = b(x) ,
(11.13)
where a and b are continuous on I, is called linear, because the function f(x, y) =
−a(x)y + b(x) is a linear polynomial in y with coeﬃcients in the variable x.
This equation is said homogeneous if the source term vanishes, b(x) = 0, non-
homogeneous otherwise.
We begin by solving the homogeneous case
y′ = −a(x)y.
(11.14)
This is a particular example of equation with separable variables. So referring to
(11.10) we have g(x) = −a(x) and h(y) = y. The constant y(x) = 0 is a solution.
Excluding this possibility, we can write
& 1
y dy = −
&
a(x) dx.
If A(x) denotes a primitive of a(x), i.e., if
&
a(x) dx = A(x) + C,
C ∈R,
(11.15)
then
log |y| = −A(x) −C,

11.2 First order diﬀerential equations
397
or, equivalently,
|y(x)| = e−Ce−A(x),
hence
y(x) = ±Ke−A(x),
where K = e−C > 0. The particular integral y(x) = 0 is included if we allow K to
become 0. The solutions of the homogeneous linear equation (11.14) are
y(x) = Ke−A(x),
K ∈R,
with A(x) deﬁned by (11.15).
Now let us assess the case b ̸= 0. We make use of the method of variation of
parameters, which consists in searching for solutions of the form
y(x) = K(x) e−A(x),
where K(x), a function of x, is unknown. Such a representation for y(x) always
exists, since e−A(x) > 0. Substituting in (11.13), we obtain
K′(x)e−A(x) + K(x)e−A(x)
−a(x)

+ a(x)K(x)e−A(x) = b(x),
or
K′(x) = eA(x)b(x).
Calling B(x) a primitive of eA(x)b(x),
&
eA(x)b(x) dx = B(x) + C,
C ∈R,
(11.16)
we have
K(x) = B(x) + C,
so the general solution to (11.13) reads
y(x) = e−A(x)
B(x) + C

,
(11.17)
where A(x) and B(x) are deﬁned by (11.15) and (11.16). The integral is more
often than not found in the form
y(x) = e−

a(x) dx
&
e

a(x) dx b(x) dx.
(11.18)
The expression highlights the various steps involved in the solution of a non-
homogeneous linear equation: one has to integrate twice, in succession.
If we are asked to solve the initial value problem

y′ + a(x)y = b(x)
on the interval I,
y(x0) = y0,
with x0 ∈I and y0 ∈R,
(11.19)

398
11 Ordinary diﬀerential equations
we might want to choose, as primitive for a(x), the one vanishing at x0, which we
write A(x) =
& x
x0
a(s) ds by the Fundamental Theorem of integral calculus; the
same we do for
B(x) =
& x
x0
e
 t
x0 a(s) ds b(t) dt
(recall the variables in the deﬁnite integral are arbitrary symbols). Substituting
these expressions in (11.17) we obtain y(x0) = C, hence the solution to (11.19)
will satisfy C = y0, namely
y(x) = e−
 x
x0 a(s) ds

y0 +
& x
x0
e
 t
x0 a(s) ds b(t) dt

.
(11.20)
Examples 11.7
i) Determine the general integral of the linear equation
y′ + ay = b,
where a ̸= 0 and b are real numbers. By choosing A(x) = ax, B(x) = b
aeax we
ﬁnd the general solution
y(x) = Ce−ax + b
a.
If a = −1, b = 0, the formula provides the announced result that every solution
of y′ = y has the form y(x) = Cex.
For the initial value problem

y′ + ay = b
on [1, +∞),
y(1) = y0,
it is convenient to have A(x) = a(x −1), B(x) = b
a

ea(x−1) −1

, so that
y(x) =

y0 −b
a

e−a(x−1) + b
a.
Note that if a > 0 the solution converges to b
a for x →+∞(independent of the
initial datum y0).
ii) Determine the integral curves of
xy′ + y = x2
that lie in the ﬁrst quadrant of the (x, y)-plane. Written as (11.13), the equation is
y′ + 1
xy = x,
so a(x) = 1
x, b(x) = x. With A(x) = log x we have eA(x) = x and e−A(x) = 1
x.
Consequently,
&
eA(x)b(x) dx =
&
x2 dx = 1
3x3 + C.

11.2 First order diﬀerential equations
399
Therefore, when x > 0 the general integral is
y(x) = 1
x
1
3x3 + C

= 1
3x2 + C
x .
For C ≥0, y(x) > 0 for any x > 0, whereas C < 0 implies y(x) > 0 for
x >
3
3|C|.
2
11.2.3 Homogeneous equations
Homogeneity refers to the form
y′ = ϕ
y
x

,
(11.21)
in which ϕ = ϕ(z) is continuous in the variable z. Thus, f(x, y) depends on x, y
only in terms of their ratio y
x; we can equivalently say that f(λx, λy) = f(x, y) for
any λ > 0.
A homogeneous equation can be solved by separation of variables, in that one
puts z = y
x, to be understood as z(x) = y(x)
x . In this manner y(x) = xz(x) and
y′(x) = z(x) + xz′(x). Substituting in (11.21) yields
z′ = ϕ(z) −z
x
,
an equation in z where the variables are separated. We can apply the strategy of
Sect. 11.2.1. Every solution ¯z of ϕ(z) = z gives rise to a singular integral z(x) = ¯z,
i.e., y(x) = ¯zx. Supposing instead ϕ(z) diﬀerent from z, we have
&
dz
ϕ(z) −z =
& dx
x ,
giving
H(z) = log |x| + C,
where H(z) is a primitive of
1
ϕ(z) −z . Indicating by H−1 the inverse map, we
have
z(x) = H−1(log |x| + C),
so the general integral of (11.21) reads (returning to y)
y(x) = x H−1(log |x| + C).

400
11 Ordinary diﬀerential equations
Example 11.8
Solve
x2y′ = y2 + xy + x2.
(11.22)
We can put the equation in normal form
y′ =
y
x
2
+ y
x + 1,
which is homogeneous for ϕ(z) = z2 + z + 1. Substituting y = xz, we arrive at
z′ = z2 + 1
x
,
whose variables are separated.
As z2 + 1 is positive, there are no singular solutions. Integrating we obtain
arctanz = log |x| + C
and the general solution to (11.22) is
y(x) = x tan(log |x| + C).
We remark that C can be chosen either in (−∞, 0) or in (0, +∞), because of the
singularity at x = 0. Moreover, the domain of existence of each solution depends
on the value of C.
2
11.2.4 Second order equations reducible to ﬁrst order
Suppose an equation of second order does not contain the variable y explicitly,
that is,
y′′ = f(y′, x).
(11.23)
Then the substitution z = y′ transforms it into a ﬁrst order equation
z′ = f(z, x)
in the unknown z = z(x). If the latter has general solution z(x; C1), we can recover
the integrals of (11.23) by solving
y′ = z,
hence by ﬁnding the primitives of z(x; C1). This will generate a new constant of
integration C2. The general solution to (11.23) will have the form
y(x; C1, C2) =
&
z(x; C1) dx = Z(x; C1) + C2,
where Z(x; C1) is a particular primitive of z(x; C1).

11.3 Initial value problems for equations of the ﬁrst order
401
Example 11.9
Solve
y′′ −(y′)2 = 1.
Put z = y′ so that the equation becomes
z′ = z2 + 1,
The variables are separated and the integral is arctan z = x + C1, i.e.,
z(x, C1) = tan(x + C1).
Integrating once again,
y(x; C1, C2) =
&
tan(x + C1) dx
=
& sin(x + C1)
cos(x + C1) dx
= −log

cos(x + C1)

+ C2 ,
C1, C2 ∈R .
2
11.3 Initial value problems for equations of the ﬁrst order
Hitherto we have surveyed families of diﬀerential equations of the ﬁrst order, and
shown ways to express the general solution in terms of indeﬁnite integrals of known
functions. These examples do not exhaust the class of equations which can be
solved analytically, and various other devices have been developed to furnish ex-
act solutions to equations with particularly interesting applications. That said,
analytical tools are not available for any conceivable equation, and even when so,
they might be unpractical. In these cases it is necessary to adopt approximations,
often numerical ones. Most of the times one can really only hope to approximate
an integral stemming, for instance, from an initial value problem. The use of such
techniques must in any case follow a qualitative investigation of the ODE, to make
sure at least that a solution exists. A qualitative study of this kind has its own
interest, regardless of subsequent approximations, for it allows to understand in
which way the solution of an initial value problem depends upon the initial datum,
among other things.
Let us analyse the problem (11.9) and talk about a simple constraint on f that
has a series of consequences: in the ﬁrst place it guarantees that the problem admits
a solution in a neighbourhood of x0; secondly, that such solution is unique, and
thirdly, that the latter depends on y0 with continuity. Should all this happen, we
say that the initial value problem (11.9) is well posed (in the sense of Hadamard).
11.3.1 Lipschitz functions
Before getting going, we present a remarkable way in which functions can depend
on their variables.

402
11 Ordinary diﬀerential equations
Deﬁnition 11.10 A real-valued map of one real variable f : J →R, J
interval, is said Lipschitz continuous on J if there exists a constant L ≥0
such that
|f(y1) −f(y2)| ≤L|y1 −y2| ,
∀y1, y2 ∈J .
(11.24)
Another way to write the same is
|f(y1) −f(y2)|
|y1 −y2|
≤L ,
∀y1, y2 ∈J , y1 ̸= y2 ,
(11.25)
which means the diﬀerence quotient of f is bounded as y1 ̸= y2 vary in J.
If (11.24) holds for a certain constant L, it is valid for bigger numbers too.
The smallest constant fulﬁlling (11.24) is called Lipschitz constant of f on J.
The Lipschitz constant is nothing else but the supremum of the left-hand side
of (11.25), when the variables vary in J. This number is far from being easy to
determine, but normally one makes do with an approximation from above.
A Lipschitz-continuous map on J is necessarily continuous everywhere on J
(actually, it is uniformly continuous on J, according to the deﬁnition given in
Appendix A.3.3, p. 447), for condition (3.6) works with δ = ε/L. Continuous
maps that fail (11.25) do exist nevertheless, like f(y) = √y over J = [0, +∞);
choosing y2 = 0 we have
|f(y1) −f(y2)|
|y1 −y2|
=
√y1
y1
=
1
√y1
,
∀y1 > 0 ,
and in the limit for y1 →0 the ratio on the left exceeds any constant. Note that
the function has inﬁnite (backward) derivative at y = 0.
The forthcoming result is the quickest to adopt, among those testing Lipschitz
continuity.
Proposition 11.11 Let f : J →R be diﬀerentiable on J with bounded de-
rivative, and L = sup
y∈J
|f ′(y)| < +∞. Then f is Lipschitz continuous on J
with Lipschitz constant L.
Proof.
For (11.24) it is enough to employ the second formula of the ﬁnite incre-
ment (6.13) to f between y1, y2, so that
f(y1) −f(y2) = f ′(¯y)(y1 −y2)
for some ¯y between y1 and y2. Therefore
|f(y1) −f(y2)| = |f ′(¯y)| |y1 −y2| ≤L|y1 −y2| .
This proves the Lipschitz constant L∗of f is ≤L.

11.3 Initial value problems for equations of the ﬁrst order
403
Vice versa, take any y0 ∈J. By (11.25)

f(y) −f(y0)
y −y0
 ≤L∗,
∀y ∈J ,
so
|f ′(y0)| =
 lim
y→y0
f(y) −f(y0)
y −y0
 = lim
y→y0

f(y) −f(y0)
y −y0
 ≤L∗,
and then L ≤L∗.
2
Let us see some examples of Lipschitz-continuous maps.
Examples 11.12
i) The function f(y) = √y is Lipschitz continuous on every interval [a, +∞) with
a > 0, because
0 < f ′(y) =
1
√2y ≤
1
√
2a
on said intervals; the Lipschitz constant is L =
1
√
2a.
ii) The trigonometric maps f(y) = sin y, f(y) = cos y are Lipschitz continuous
on the whole R with L = 1, since |f ′(y)| ≤1, ∀y ∈R and there exist y ∈R at
which |f ′(y)| = 1.
ii) The exponential f(y) = ey is Lipschitz continuous on all intervals (−∞, b],
b ∈R, with constant L = eb; it is not globally Lipschitz continuous, for
sup
y∈R
f ′(y) = +∞.
2
Proposition 11.11 gives a suﬃcient condition for Lipschitz continuity. A func-
tion can in fact be Lipschitz continuous on an interval without being diﬀerentiable:
f(y) = |y| is not diﬀerentiable at the origin, yet has Lipschitz constant 1 every-
where on R, because
|y1| −|y2|
 ≤|y1 −y2| ,
∀y1, y2 ∈R .
Now to several variables. A function f : Ω ⊆Rd →R is Lipschitz continuous
on Ω if there is a constant L ≥0 such that
|f(y1) −f(y2)| ≤L∥y1 −y2∥,
∀y1, y2 ∈Ω .
We say a map f : I × J ⊆R2 →R, with I, J real intervals, is Lipschitz
continuous on Ω = I × J in y, uniformly in x, if there is a constant L ≥0
such that
|f(x, y1) −f(x, y2)| ≤L|y1 −y2| ,
∀y1, y2 ∈J, ∀x ∈I .
(11.26)
This condition holds if f has bounded partial y-derivative on Ω, i.e., L =
sup
(x,y)∈Ω

∂f
∂y (x, y)
 < +∞, because Proposition 11.11 can be applied for every x ∈I.

404
11 Ordinary diﬀerential equations
Example 11.13
Consider
f(x, y) =
3√x sin(x + y)
on Ω = [−8, 8] × R. Since
∂f
∂y (x, y) =
3√x cos(x + y) ,
for any (x, y) ∈Ω
∂f
∂y (x, y)
 = | 3√x | | cos(x + y)| ≤
3√
8 · 1 = 2 .
Thus (11.26) holds with L = 2.
2
11.3.2 A criterion for solving initial value problems
After the intermezzo on Lipschitz-continuous functions, we are ready to state the
main result concerning the initial value problem (11.9).
Theorem 11.14 Let I, J be non-empty real intervals, J additionally open.
Suppose f : Ω = I×J ⊆R2 →R is continuous on Ω and Lipschitz continuous
on Ω in y, uniformly in x.
For any (x0, y0) ∈Ω, the initial value problem (11.9) admits one, and only
one, solution y = y(x), deﬁned and diﬀerentiable with continuity on an in-
terval I′ ⊆I containing x0 and bigger than a singlet, such that

x, y(x)

∈Ω
for any x ∈I′.
If ˜y = ˜y(x) denotes the solution on an interval I′′ ⊆I to the problem with
initial value (x0, ˜y0) ∈Ω, then
|y(x) −˜y(x)| ≤eL|x−x0||y0 −˜y0| ,
∀x ∈I′ ∩I′′ ,
(11.27)
where L is the constant of (11.26).
The theorem ensures existence and uniqueness of a “local” solution, a solution
deﬁned in a neighbourhood of x0. The point is, the solution might be deﬁned not
everywhere on I, because the integral curve

x, y(x)

, also known as trajectory,
could leave the region Ω before x has run over the entire I. For example, f(y) = y2
is Lipschitz continuous on every bounded interval Ja = (−a, a), a > 0, because
sup
y∈Ja
|f ′(y)| = sup
|y|<a
|2y| = 2a ,
but is not Lipschitz continuous on R. The initial value problem
⎧
⎨
⎩
y′ = y2 ,
y(0) = 1
2 ,
(11.28)

11.3 Initial value problems for equations of the ﬁrst order
405
a
Ja
−a
I
1/2
2
Ωa
Figure 11.3. The solution of (11.28) is not deﬁned on I = [0, +∞)
has no solution over all of I = [0, +∞): separating variables we discover
y(x) =
1
2 −x ,
showing that the trajectory

x, y(x)

leaves every strip Ωa = I × Ja, a > 1, before
x can reach 2 (see Fig. 11.3).
When the theorem is true with J = R, we can prove the solution exists over
all of I.
The uniqueness of the solution to (11.9) follows immediately from (11.27): if
y(x) and ˜y(x) are solutions corresponding to the same initial datum y0 = ˜y0 at
x0, then y(x) = ˜y(x) for any x.
Observe that if f is not Lipschitz continuous in the second variable around
(x0, y0), the initial value problem may have many solutions. The problem
 y′ = √y ,
y(0) = 0
is solvable by separation of variables, and admits the constant y(x) = 0 (the
singular integral), as well as y(x) = 1
4x2 as solutions. As a matter of fact there are
inﬁnitely many solutions
y(x) =
 0
if 0 ≤x ≤c ,
1
4(x −c)2
if x > c ,
c ≥0 ,
obtained by ‘gluing’ in the right way the aforementioned integrals.
Finally, (11.27) expresses the continuous dependency of the solution to (11.9)
upon y0: an ε-deviation of the initial datum aﬀects at most by eL|x−x0|ε the solu-
tion at x ̸= x0. Otherwise said, when two solutions evolve the distance of the

406
11 Ordinary diﬀerential equations
corresponding trajectories can grow at most by the factor eL|x−x0| in going from
x0 to x. In any case the factor eL|x−x0|ε is an exponential in x, so its impact
depends on the distance |x −x0| and on the Lipschitz constant.
11.4 Linear second order equations with constant
coeﬃcients
A linear equation of order two with constant coeﬃcients has the form
y′′ + ay′ + by = g,
(11.29)
where a, b are real constants and g = g(x) is a continuous map. We shall prove
that the general integral can be computed without too big an eﬀort in case g = 0,
hence when the equation is homogeneous. We will show, moreover, how to ﬁnd
the explicit solutions when g is a product of exponentials, algebraic polynomials,
sine- and cosine-type functions or, in general, a sum of these.
To study equation (11.29) we let the map y = y(x) be complex-valued, for
convenience. The function y : I ⊆R →C is (n times) diﬀerentiable if yr =
Re y : I →R and yi = Im y : I →R are (n times) diﬀerentiable, in which case
y(n)(x) = y(n)
r
(x) + iy(n)
i
(x).
A special case of this situation goes as follows. Let λ = λr + iλi ∈C be an
arbitrary complex number. With (8.39) in mind, we consider the complex-valued
map of one real variable x →eλx = eλrx(cos λix + i sin λix). Then
d
dx eλx = λeλx,
(11.30)
precisely as if λ were real. In fact,
d
dx eλx = d
dx(eλrx cos λix) + i d
dx(eλrx sin λix)
= λreλrx cos λix −λieλrx sin λix + i(λreλrx sin λix + λieλrx cos λix)
= λreλrx(cos λix + i sin λix) + iλieλrx(cos λix + iλi sin λix)
= (λr + iλi)eλx = λeλx .
Let us indicate by Ly = y′′+ay′+by the left-hand side of (11.29). Diﬀerentiating
is a linear operation, so
L(αy + βz) = αLy + βLz
(11.31)
for any α, β ∈R and any twice-diﬀerentiable real functions y = y(x), z = z(x).
Furthermore, the result holds also for α, β ∈C and y = y(x), z = z(x) complex-
valued. This sort of linearity of the diﬀerential equation will be crucial in the
study.

11.4 Linear second order equations with constant coeﬃcients
407
We are ready to tackle (11.29). Let us begin with the homogeneous case
Ly = y′′ + ay′ + by = 0 ,
(11.32)
and denote by
χ(λ) = λ2 + aλ + b
the characteristic polynomial of the diﬀerential equation, obtained by replacing
kth derivatives by the power λk, for every k ≥0. Equation (11.30) suggests to look
for a solution of the form y(x) = eλx for a suitable λ. If we do so,
L(eλx) = λ2eλx + aλeλx + beλx = χ(λ)eλx,
and the equation holds if and only if λ is a root of the characteristic equation
λ2 + aλ + b = 0 .
When the discriminant Δ = a2 −4b is non-zero, there are two distinct roots λ1, λ2,
to whom correspond distinct solutions y1(x) = eλ1x and y2(x) = eλ2x; roots and
relative solutions are real if Δ > 0, complex-conjugate if Δ < 0. When Δ = 0,
there is a double root λ, hence one solution y1(x) = eλx. Multiplicity two implies
χ′(λ) = 0; letting y2(x) = xeλx, we have
y′
2(x) = (1 + λx) eλx
and
y′′
2(x) = (2λ + λ2x) eλx .
Substituting back into the equation we obtain
L(y2) = χ(λ) x eλx + χ′(λ) eλx = 0
after a few algebraic steps. Therefore the function y2 solves the equation, and is
other than y1. In all cases, we have found two distinct solutions y1, y2 of (11.32).
Since (11.31) is linear, if y1, y2 solve (11.32) and C1, C2 are constants, then
L(C1y1 + C2y2) = C1L(y1) + C2L(y2) = C10 + C20 = 0 ,
hence the linear combination C1y1 + C2y2 is yet another solution of the homogen-
eous equation. Moreover, if y denotes a solution, one can prove that there exist
two constants C1, C2 such that y = C1y1 + C2y2, where y1, y2 are the solutions
found earlier.
In conclusion, the general integral of the homogeneous equation (11.32) takes
the form
y(x; C1, C2) = C1y1(x) + C2 y2(x),
with C1, C2 constants and y1(x), y2(x) deﬁned by the recipe:
if Δ ̸= 0, y1(x) = eλ1x and y2(x) = eλ2x with λ1, λ2 distinct roots of the charac-
teristic equation χ(λ) = 0;
if Δ = 0, y1(x) = eλx and y2(x) = xeλx, where λ is the double root of χ(λ) = 0.

408
11 Ordinary diﬀerential equations
When Δ < 0, the solution can be written using real functions, instead of
complex-conjugate ones as above. It is enough to substitute to y1(x), y2(x) the
real part eλrx cos λix and the imaginary part eλrx sin λix of y1(x) respectively,
where λ1 = ¯λ2 = λr + iλi. In fact, if y is a solution of the homogeneous equation,
L(Re y) = Re (Ly) = Re 0 = 0 ,
L(Im y) = Im (Ly) = Im 0 = 0
since the coeﬃcients are real, so Re y and Im y are solutions too.
Summarising, the general integral of the homogeneous equation (11.32) can be
expressed in terms of real functions as follows.
The case Δ > 0. The characteristic equation has two distinct real roots
λ1,2 = −a ±
√
Δ
2
and the general integral reads
y(x; C1, C2) = C1 eλ1x + C2 eλ2x,
with C1, C2 arbitrary constants.
The case Δ = 0. The characteristic equation has a double root
λ = −a
2 ,
and the general integral reads
y(x; C1, C2) = (C1 + C2x) eλx ,
C1, C2 ∈R .
The case Δ < 0. The characteristic equation has no real roots. Deﬁning
σ = λr = −a
2,
ω = λi =

|Δ|
2
,
the general integral reads
y(x; C1, C2) = eσx(C1 cos ωx + C2 sin ωx) ,
C1, C2 ∈R.
Now we are ready for the non-homogeneous equation (11.29). The general
integral can be written like
y(x; C1, C2) = y0(x; C1, C2) + yp(x),
(11.33)

11.4 Linear second order equations with constant coeﬃcients
409
where y0(x; C1, C2) is the general solution of the associated homogeneous equation
(11.32), while yp(x) denotes an arbitrary particular integral of (11.29). Based on
linearity in fact,
L(y0 + yp) = L(y0) + L(yp) = 0 + g = g ,
so the right-hand side of (11.33) solves (11.29). Vice versa, if y(x) is a generic
solution of (11.29), the function y(x) −yp(x) satisﬁes
L(y −yp) = L(y) −L(yp) = g −g = 0 ,
so it will be of the form y0(x; C1, C2) for some C1 and C2.
Should the source term g be a mixture of products of algebraic polynomials,
trigonometric and exponentials functions, we can ﬁnd a particular integral of the
same sort. To understand better, we start with g(x) = pn(x) eαx, where α ∈C and
pn(x) is a polynomial of degree n ≥0. We look for a particular solution of the form
yp(x) = qN(x) eαx, with qN unknown polynomial of degree N ≥n. Substituting
the latter and its derivatives in the equation, we obtain
L(qN(x) eαx) =

χ(α)qN(x) + χ′(α)q′
N(x) + q′′
N(x)

eαx = pn(x) eαx ,
whence
χ(α)qN(x) + χ′(α)q′
N(x) + q′′
N(x) = pn(x) .
If α is not a characteristic root, it suﬃces to choose N = n and determine
the unknown coeﬃcients of qn by comparing the polynomials on either side of the
equation; it is better to begin from the leading term and proceed to the lower-
degree monomials.
If α is a simple root, χ(α) = 0 and χ′(α) ̸= 0; we choose N = n + 1 and hunt
for a polynomial solution of χ′(α)q′
N (x) + q′′
N(x) = pn(x). Since the coeﬃcient of
qn+1 of degree 0 is not involved in the expression, we limit ourselves to qn+1 of
the form qn+1(x) = xqn(x), with qn an arbitrary polynomial of degree n.
Eventually, if α is a multiple root, we put N = n+2 and solve q′′
n+2(x) = pn(x),
seeking qn+2 in the form qn+2(x) = x2qn(x), where qn is arbitrary and of degree
n. In the second and third cases one speaks of resonance.
When α is complex, χ(α) and χ′(α) are complex expressions, so qN(x) has to be
found among polynomials over C, generally speaking. But as in the homogeneous
case, we can eschew complex variables by inspecting the real and imaginary parts
of pn(x) eαx; with α = μ + iϑ, they are pn(x) eμx cos ϑx and pn(x) eμx sin ϑx.
Our analysis has shown that if the source term g is real and of the form
g(x) = pn(x) eμx cos ϑx
or
g(x) = pn(x) eμx sin ϑx ,
(11.34)
we can attempt to ﬁnd a particular solution
yp(x) = xmeμx(q1,n(x) cos ϑx + q2,n(x) sin ϑx),
(11.35)

410
11 Ordinary diﬀerential equations
where qi,n(x) are algebraic polynomials of degree n, and m is generically 0 except
in case of resonance:
i)
for Δ > 0: set m = 1 if ϑ = 0 and if μ coincides with either root λ1, λ2 of the
characteristic polynomial;
ii) for Δ = 0: set m = 2 if ϑ = 0 and μ coincides with the (double) root λ of the
characteristic polynomial;
iii) for Δ < 0: set m = 1 if μ = σ and ϑ = ω.
Substituting the particular integral (11.35) in (11.29), and comparing the terms
xkeμx sin ϑx and xkeμx cos ϑx for all k = 0, . . . , n, we can determine yp.
At last, if g is a sum of pieces of the form (11.34), yp will be the sum of
the particular solutions corresponding to the single source terms: suppose that
g = g1 + g2 + . . . + gK and ypk solves L(y) = gk for all k = 1, . . . , K. Then
yp = yp1 + . . . + ypK satisﬁes
L(yp) = L(yp1) + . . . + L(ypK) = g1 + . . . + gK = g ,
and as such it solves L(y) = g as well. This is the so-called principle of superposi-
tion.
With the help of a few examples the procedure will result much clearer.
Examples 11.15
i) Consider
y′′ + y′ −6y = g.
(11.36)
First of all, we ﬁnd the general integral of the associated homogeneous equation
y′′ + y′ −6y = 0.
(11.37)
The characteristic equation
λ2 + λ −6 = 0
has distinct roots λ1 = −3, λ2 = 2, so the general integral of (11.37) is
y0(x; C1, C2) = C1 e−3x + C2 e2x.
Now we determine a particular solution to (11.36), assuming that g(x) = 3x2 −
x + 2. By (11.34), p2(x) = 3x2 −x + 2 and μ = ϑ = 0. Since μ is neither λ1 nor
λ2, yp will have the form yp(x) = αx2 + βx + γ. Substituting y′
p, y′′
p in (11.36)
yields
−6αx2 + (2α −6β)x + (2α + β −6γ) = 3x2 −x + 2.
The comparison of coeﬃcients implies
yp(x) = −1
2(x2 + 1).
Therefore, the general integral of (11.36) reads
y(x; C1, C2) = C1 e−3x + C2 e2x −1
2(x2 + 1).

11.4 Linear second order equations with constant coeﬃcients
411
Assume instead that g(x) = e2x. In (11.34) we have p0(x) = 1, μ = λ2 = 2,
ϑ = 0. We need a yp written as yp(x) = αxe2x. Substituting in (11.36) gives
5αe2x = e2x ,
hence α = 1
5. The general solution is then
y(x; C1, C2) = C1e−3x +

C2 + 1
5x

e2x.
ii) Examine the equation
y′′ −2y′ + y = g.
(11.38)
The characteristic polynomial λ2 −2λ + 1 has a root λ = 1 of multiplicity two.
The general integral of the homogeneous equation is thus
y0(x; C1, C2) = (C1 + C2x) ex.
Suppose g(x) = xe3x. As μ = 3 is not λ = 1, we search for a particular solution
yp(x) = (αx + β) e3x. As before, the substitution of the latter back into the
equation yields
4(αx + α + β) e3x = x e3x,
giving
yp(x) = 1
4(x −1) e3x.
We conclude that the general integral is
y(x; C1, C2) = (C1 + C2x) ex + 1
4(x −1) e3x.
Taking g(x) = −4ex, instead, calls for a yp of type yp(x) = αx2ex. Then
2αex = −4ex
implies α = −2, and the general solution reads
y(x; C1, C2) = (C1 + C2x −2x2) ex .
iii) The last example is
y′′ + 2y′ + 5y = g.
(11.39)
This ODE has characteristic equation λ2 + 2λ + 5 = 0 with negative discrim-
inant Δ = −16. From σ = −1, ω = 2, the general integral of the homogeneous
equation is
y0(x; C1, C2) = e−x(C1 cos 2x + C2 sin 2x).
Take g(x) = sin x. Referring to the left term in (11.34), we have p0(x) = 1,
μ = 0, ϑ = 1. We want a particular integral yp(x) = α cos x + β sin x. Rewrite
(11.39) using the derivatives y′
p, y′′
p and yp, so that
(4α + 2β) cos x + (4β −2α) sin x = sin x.
Compare the coeﬃcients of sin x and cos x, so α = −1
10 and β = 1
5, i.e.,
yp(x) = −1
10 cos x + 1
5 sin x.

412
11 Ordinary diﬀerential equations
The general solution is
y(x) = e−x(C1 cos 2x + C2 sin 2x) −1
10 cos x + 1
5 sin x .
Another variant is to suppose g(x) = e−x sin 2x. Using the ﬁrst of (11.34),
μ = σ = −1 and ϑ = ω = 2, so we look for the particular integral
yp(x) = xe−x(α cos 2x + β sin 2x). The substitution yields
e−x(4β cos 2x −4α sin 2x) = e−x sin 2x,
hence α = −1
4, β = 0, and the general solution reads
y(x) = e−x

C1 −1
4x

cos 2x + C2 sin 2x

.
2
11.5 Exercises
1. Determine the general integral of these ODEs with separable variables:
a) y′ = x log(1 + x2)
b)
y′ = (x + 2)y
x(x + 1)
c)
y′ =
y2
x log x −
1
x log x
d)
y′ =
3√2y + 3 tan2 x
2. Find the general solution of the homogeneous ODEs:
a)
4x2y′ = y2 + 6xy −3x2
b)
x2y′ = x2 + 4y2 + yx
c)
xyy′ = x2 + y2
d)
x2y′ −y2ex/y = xy
3. Solve in full generality the linear ODEs:
a) y′ + 3xy = x3
b)
y′ = 1
xy −3x + 2
x3
c)
y′ = 2x −y
x −1
d)
xy′ = y +
2x2
1 + x2
4.
Write the particular solution of the equation
y′ = 1 −e−y
2x + 1
such that y(0) = 1.
5.
Establish whether the diﬀerential equation
y′ = −2y + e−2x
has solutions with vanishing derivative at the origin.

11.5 Exercises
413
6. Solve, over the ray [ 4√e, +∞), the initial value problem

eyy′ = 4x3 log x(1 + ey)
y( 4√e) = 0.
7.
Find the solutions of
⎧
⎨
⎩
y′ =
3x
x2 −4|y|
y(0) = −1
that are deﬁned on the interval (−2, 2).
8.
Determine the general integral of
y′ sin 2x −2(y + cos x) = 0,
x ∈

0, π
2

,
and indicate the solution that stays bounded when x →π
2
−.
9.
For α ∈R, solve the ODE
y′ = (2 + α)y −2eαx
so that y(0) = 3. Tell which values of α make the improper integral
& +∞
0
y(x) dx
converge.
10.
Let a, b be real numbers. Solve the initial value problem

y′ = ay
x + 3xb
y(2) = 1
restricted to the half-line [2, +∞).
11.
Consider the parametric diﬀerential equation
y′(x) = −3xy(x) + kx
depending on k ∈R.
a) Find the solution with a zero at the origin.
b) For such solution y determine k so that y(x) ∼x2 as x →0.
12. Given the ODE
y′ = y2 −2y −3
2(1 + 4x) ,
determine:
a) the general integral;
b) the particular integral y0(x) satisfying y0(0) = 1;
c) Maclaurin’s expansion of y0(x) up to second order.

414
11 Ordinary diﬀerential equations
13. Work out the general solution to the following second order ODEs by reducing
them to the ﬁrst order:
a) y′′ = 2ex
b)
y′′ + y′ −x2 = 0
14. Compute the general integral of the linear ODEs of the second order:
a) y′′ + 3y′ + 2y = x2 + 1
b)
y′′ −4y′ + 4y = e2x
c)
y′′ + y = 3 cosx
d)
y′′ −3y′ + 2y = ex
e)
y′′ −9y = e−3x
f)
y′′ −2y′ −3y = sin x
15. Solve the initial value problems:
a)
⎧
⎨
⎩
y′′ + 2y′ + 5y = 0
y(0) = 0
y′(0) = 2
b)
⎧
⎨
⎩
y′′ −5y′ + 4y = 2x + 1
y(0) = 7
8
y′(0) = 0
11.5.1 Solutions
1. ODEs with separable variables:
a) y = 1
2(1 + x2) log(1 + x2) −1
2x2 + C .
b) The map h(y) = y has a zero at y = 0, which is consequently a singular integral.
Suppose then y ̸= 0 and separate the variables:
& 1
y dy =
&
x + 2
x(x + 1) dx .
We compute the integral on the right by partial fractions:
x + 2
x(x + 1) = A
x +
B
x + 1 = 2
x −
1
x + 1
implies
&
x + 2
x(x + 1) dx =
&  2
x −
1
x + 1

dx = 2 log |x| −log |x + 1| + log C
= log
Cx2
|x + 1| ,
C > 0 .
Thus
log |y| = log
Cx2
|x + 1| ,
C > 0 ,
|y| = C
x2
|x + 1| ,
C > 0 ,

11.5 Exercises
415
y = C
x2
x + 1 ,
C ̸= 0 .
The singular integral y = 0 belongs to this family if we allow the value C = 0.
c) The problem requires x > 0 due to the presence of the logarithm. Rearranging
the equation as
y′ = y2 −1
x log x
yields h(y) = y2 −1. Thus the constant maps y = 1, y = −1 are singular
solutions. Let now y ̸= ±1; separating the variables returns
&
1
y2 −1 dy =
&
1
x log x dx .
The method of partial fractions in the left integral and the substitution t = log x
on the right give
1
2 log

y −1
y + 1
 = log | log x| + log C = log C| log x| ,
C > 0 ,
equivalent to
log

y −1
y + 1
 = log C log2 x ,
C > 0 ,
or
y −1
y + 1 = C log2 x ,
C ̸= 0 ;
Altogether, the general integral is
y = 1 + C log2 x
1 −C log2 x ,
C ∈R ,
which includes the singular solution y = 1 for C = 0.
d) y = −3
2 ± 1
2
# 4
3 (tan x −x + C)
$3/2 plus the constant solution y = −3
2.
2. Homogeneous diﬀerential equations:
a) Supposing x ̸= 0 and dividing by 4x2 gives
y′ = 1
4
y2
x2 + 3
2
y
x −3
4 .
By renaming z = y
x we have y′ = z + xz′, hence
z + xz′ = 1
4z2 + 3
2z −3
4 ,
4xz′ = (z −1)(z + 3) .

416
11 Ordinary diﬀerential equations
Because ϕ(z) = (z −1)(z + 3) has zeroes z = 1, z = −3, the maps y = x
y = −3x are singular integrals. For the general solution let us separate the
variables
&
4
(z −1)(z + 3) dz =
& 1
x dx .
Decomposing
4
(z −1)(z + 3) =
A
z −1 +
B
z + 3 =
1
z −1 −
1
z + 3 ,
the right-hand-side integral is
&
4
(z −1)(z + 3) dz =
& 
1
z −1 −
1
z + 3

dz = log

z −1
z + 3
 + c .
Therefore
log

z −1
z + 3
 = log C|x| ,
C > 0 ,
z −1
z + 3 = Cx ,
C ̸= 0 ,
z = 1 + 3Cx
1 −Cx ,
C ∈R ;
this incorporates the singular solution z = 1 as well. Returning to the variable
y, the general integral reads
y = x + 3Cx2
1 −Cx
,
C ∈R .
b) y = 1
2x tan (2 log C|x|) , C > 0 ;
c) y = ±x

2 log C|x| , C > 0 .
d) If x ̸= 0 we divide by x2
y′ = y2
x2 ex/y + y
x .
Changing z = y
x gives y′ = z + xz′, so
z + xz′ = z2e1/z + z ,
whence
xz′ = z2e1/z .
The function z = 0, corresponding to y = 0, is a singular integral of the ODE.
By separation of the variables
& e−1/z
z2
dz =
& 1
x dx ,
integrating which,

11.5 Exercises
417
e−1/z = log C|x| ,
C > 0 ,
−1
z = log log C|x| ,
C > 0 ,
z = −
1
log log C|x| ,
C > 0 ,
i.e.,
y = −
x
log log C|x| ,
C > 0 .
in terms of y.
3. Linear ODEs:
a) y = 1
3

x2 −2
3

+ Ce−3
2 x2 .
b) Using (11.18) with a(x) = −1
x and b(x) = −3x+2
x3
produces
y = e

1
x dx
&
e−

1
x dx

−3x + 2
x3

dx = elog |x|
&
elog
1
|x|

−3x + 2
x3

dx
= |x|
& −(3x + 2)
|x|x3
dx = x
& −(3x + 2)
xx3
dx
= x
& 
−3
x3 −2
x4

dx = x
 3
2x2 +
2
3x3 + C

= 3
2x +
2
3x2 + Cx ,
C ∈R .
c) By writing
y′ +
1
x −1y =
2x
x −1
we recognise formula (11.18) where a(x) =
1
x−1, b(x) =
2x
x−1. Then
y = e−

1
x−1 dx
&
e

1
x−1 dx 2x
x −1 dx = e−log |x−1|
&
elog |x−1| 2x
x −1 dx
=
1
|x −1|
&
|x −1| 2x
x −1 dx =
1
x −1
&
2x dx =
1
x −1(x2 + C) ,
C ∈R .
d) y = 2x arctanx + Cx , C ∈R .
4. The equation has separable variables, but the constant solution y = 0 is not
admissible, for it does not meet the condition y(0) = 1. So we write
&
1
1 −e−y dy =
&
1
2x + 1 dx.
Renaming t = e−y (hence dt = −e−ydy, −1
t dt = dy) implies

418
11 Ordinary diﬀerential equations
&
1
1 −e−y dy =
&
1
t(t −1) dt =
& 
1
t −1 −1
t

dt
= log

t −1
t
 + c = log
1 −1
t
 + c = log |1 −ey| + c.
Then
log |1 −ey| = 1
2 log |2x + 1| + log C ,
C > 0,
log |1 −ey| = log C

|2x + 1| ,
C > 0,
|1 −ey| = C

|2x + 1| ,
C > 0 ,
1 −ey = C

|2x + 1| ,
C ̸= 0.
In conclusion, the general integral
y = log

1 −C

|2x + 1|

,
C ∈R ,
also takes into account y = 0, corresponding to C = 0.
Now to the condition y(0) = 1: from C = 1 −e the required solution is
y = log

1 + (e −1)

|2x + 1|

.
5. The general integral of the linear equation reads
y = e−

2 dx
&
e

2 dxe−2x dx = e−2x(x + C) ,
C ∈R .
The constraint is y′(0) = 0. Putting x = 0 in y′(x) = −2y(x)+e−2x, that becomes
y(0) = 1
2, and implies C = 1
2. The ﬁnal solution is thus
y = e−2x

x + 1
2

.
6. y = log

2ex4(log x−1
4 ) −1

.
7. When x ∈(−2, 2), x2 −4 < 0. The initial condition y(0) = −1 allows moreover
to restrict to y(x) < 0 in a neighbourhood of x = 0. That said, we separate
variables:
−
& 1
y dy =
&
3x
x2 −4 dx,
−log |y| = −log(−y) = 3
2 log |x2 −4| + C,
C ∈R,
−1
y = C(4 −x2)3/2,
C > 0,

11.5 Exercises
419
y = C(4 −x2)−3/2,
C < 0.
Since y(0) = −1, C must be −8 and the solution reads
y = −
8
(4 −x2)3/2 .
Notice that the constant function y = 0 was disregarded because it fails to meet
y(0) = −1.
8. The duplication formula sin 2x = 2 sin x cos x bestows
y′ sin x cos x = y + cos x.
For x ∈

0, π
2

we have sin x cos x ̸= 0, and so
y′ =
1
sin x cos x y +
1
sin x.
This is a linear equation, with integral
y = e

1
sin x cos x dx
&
e−

1
sin x cos x dx ·
1
sin x dx.
Let us compute
S =
&
1
sin x cos x dx
by setting t = sin x (dt = cos x dx, cos2 x = 1 −t2) and integrating the rational
function thus obtained:
S =
&
1
t(1 −t2) dt =
& 1
t +
1
2(1 −t) −
1
2(1 + t)

dt
= log |t| −1
2|1 −t| −1
2 log |1 + t| + c
= log
|t|

|1 −t2|
+ c = log sin x
cos x + c ,
x ∈

0, π
2

.
Then
y = sin x
cos x
&
cos x
sin2 x dx = sin x
cos x

−
1
sin x + C

,
C ∈R ,
and the solution to the ODE is
y = C sin x −1
cos x
,
C ∈R .
We need to ﬁnd a bounded solution around π
2
−:
lim
x→π
2
−
C sin x −1
cos x
∈R.

420
11 Ordinary diﬀerential equations
But
lim
x→π
2
−
C sin x −1
cos x
= lim
t→0−
1 −C cos t
sin t
= lim
t→0−
1 −C(1 + o(t2))
t + o(t2)
= 0
if and only if C = 1, so the desired solution is
y = sin x −1
cos x
.
9. The equation is linear, so at once
y = e

(2+α) dx
&
e−

(2+α) dx(−2eαx) dx
= e(2+α)x(e−2x + C) = eαx(1 + C e2x) ,
C ∈R.
From y(0) = 3 it follows 3 = 1 + C, so C = 2. The solution we want is thus
y = eαx(1 + 2e2x).
The improper integral
& +∞
0
(eαx + 2e(α+2)x) dx
converges precisely when the exponential of bigger magnitude has negative expo-
nent. Therefore the integral converges if α < −2.
10. Directly from the formula for linear equations,
y = ea

1
x dx

3
&
e−a

1
x dxxb dx

= xa

3
&
xb−a dx

=
⎧
⎨
⎩
xa

3
b −a + 1 xb−a+1 + C

if b −a ̸= −1,
xa (3 log x + C)
if b −a = −1 ,
=
⎧
⎨
⎩
3
b −a + 1xb+1 + C xa
if b −a ̸= −1,
3xa log x + Cxa
if b −a = −1.
Imposing y(2) = 1,
⎧
⎨
⎩
3
b −a + 1 2b+1 + C 2a = 1
if b −a ̸= −1,
3 · 2a log 2 + C 2a = 1
if b −a = −1 ,
whence the constant is respectively
⎧
⎨
⎩
C = 2−a

1 −
3
b −a + 1 2b+1

if b −a ̸= −1,
C = 2−a −3 log 2
if b −a = −1.

11.5 Exercises
421
In conclusion,
y =
⎧
⎪
⎨
⎪
⎩
3
b −a + 1 xb+1 + 2−a

1 −
3
b −a + 1 2b+1

xa
if b −a ̸= −1,
3xa log x +

2−a −3 log 2

xa
if b −a = −1.
11. The ODE y′(x) = −3xy(x) + kx:
a) The equation is linear, with integral
y = e−3

x dx
&
e3

x dx kx dx
= e−3
2 x2 k
3 e
3
2 x2 + C

= k
3 + C e−3
2 x2,
C ∈R.
The condition y(0) = 0 forces 0 = k
3 + C, so C = −k
3, and the solution is
y = k
3

1 −e−3
2 x2
.
b) The solution must now fulﬁll
k
3

1 −e−3
2 x2
∼x2
as x →0.
But
e−3
2 x2 = 1 −3
2x2 + o(x2)
for x →0
implies
y(x) = k
3

1 −1 + 3
2x2 + o(x2)

= k
2x2 + o(x2)
for x →0.
Therefore y is ﬁxed by k
2 = 1, i.e., k = 2.
12. Solution of y′ = y2−2y−3
2(1+4x) :
a) y(x) = 3 + C

|1 + 4x|
1 −C

|1 + 4x|
with C ∈R, and the constant y(x) = −1.
b) y0(x) = 3 −

|1 + 4x|
1 +

|1 + 4x|
;
c) T2(x) = 1 −2x + 4x2 + o(x2).
13. Second order linear ODEs reducible to ﬁrst order:
a) y = 2ex + C1x + C2 , C1, C2 ∈R .

422
11 Ordinary diﬀerential equations
b) We deﬁne z = y′ so that to obtain the linear equation of the ﬁrst order
z′ + z = x2 ,
solved by
z = e−

dx
&
e

dxx2 dx = e−x
&
x2ex dx .
By integration by parts (twice),
z = e−x 
x2ex −2xex + 2ex + C1

= x2 −2x + 2 + C1e−x ,
C1 ∈R .
Integrating once more to go back to y gives
y = 1
3x3 −x2 + 2x + C1e−x + C2 ,
C1, C2 ∈R .
14. Linear ODEs of the second order:
a) y = C1e−x + C2e−2x + 1
2x2 −3
2x + 9
4 , C1, C2 ∈R .
b) Let us solve ﬁrst the homogeneous equation. The characteristic polynomial
λ2 −4λ+4λ = 0 admits a unique root λ = 2 with multiplicity two; the integral
is then
y0(x; C1, C2) = (C1 + C2x)e2x ,
C1, C2 ∈R .
As μ = λ = 2, we require the particular integral to resemble yp(x) = αx2e2x.
Diﬀerentiating and substituting,
2αe2x = e2x
forces α = 1
2. Thus yp(x) = 1
2x2e2x, and the general solution to the ODE is
y(x; C1, C2) = (C1 + C2x)e2x + 1
2x2e2x ,
C1, C2 ∈R .
c) The characteristic equation λ2 + 1 = 0 has discriminant Δ = −4, hence σ = 0,
ω = 1, making
y0(x; C1, C2) = C1 cos x + C2 sin x ,
C1, C2 ∈R ,
the general solution of the homogeneous case. Since μ = σ = 0 we want a
particular integral yp(x) = x(α cos x + β sin x). This gives
−2α sin x + 2β cos x = 3 cos x ,
hence α = 0 and β = 3
2, and in turn yp(x) = 3
2x sin x. Thus
y(x; C1, C2) = C1 cos x + C2 sin x + 3
2x sin x ,
C1, C2 ∈R .

11.5 Exercises
423
d) y = C1ex + C2e2x −xex , C1, C2 ∈R .
e) λ = ±3 solve the characteristic equation λ2 −9 = 0, so
y0(x; C1, C2) = C1e−3x + C2e3x ,
C1, C2 ∈R ,
is how the integral of the homogeneous equation looks like. We are seeking a
particular integral yp(x) = αxe−3x. In the usual way
−6αe−3x = e−3x ,
from which α = −1
6 follows. The particular solution yp(x) = −1
6xe−3x is as-
similated into the general integral
y(x; C1, C2) = C1e−3x + C2e3x −1
6xe−3x ,
C1, C2 ∈R .
f) y = C1e−x + C2e3x + 1
10 cos x −1
5 sin x , C1, C2 ∈R .
15. Initial value problems:
a) y = e−x sin 2x .
b) We start from the homogeneous ODE, and solve the characteristic equation
λ2 −5λ + 4 = 0, which has roots λ = 1, λ = 4. In this way
y0(x; C1, C2) = C1ex + C2e4x ,
C1, C2 ∈R ,
is the general expression for the integral. A particular solution yp(x) = αx + β
furnishes
−5α + 4αx + 4β = 2x + 1 ,
hence α = 1
2, β = 7
8. In this way we subsume yp(x) = 1
2x + 7
8 into the general
integral
y(x; C1, C2) = C1ex + C2e4x + 1
2x + 7
8 ,
C1, C2 ∈R .
The initial conditions lead to the system
 C1 + C2 = 0
C1 + 4C2 + 1
2 = 0 .
Its solutions C1 = 1
6, C2 = −1
6 now give
y = 1
6ex −1
6e4x + 1
2x + 7
8 .

Appendices

A.1
The Principle of Mathematical Induction
The Principle of Induction represents a useful rule for proving properties that hold
for any integer number n, or possibly from a certain integer n0 ∈N onwards.
Theorem A.1.1 (Principle of Mathematical Induction) Let n0 ≥0 be
an integer and denote by P(n) a predicate deﬁned for every integer n ≥n0.
Suppose the following conditions hold:
i) P(n0) is true;
ii) for any n ≥n0, if P(n) is true then P(n + 1) is true.
Then P(n) is true for all integers n ≥n0.
Proof. The proof relies on the fact that each non-empty subset of N admits a
minimum element; this property, which is self-evident, may be deduced from the
axioms that deﬁne the set N.
Let us proceed by contradiction, and assume there is an integer n ≥n0 such
that P(n) is false. This is the same as saying that the set
F = {n ∈N : n ≥n0 and P(n) is false}
is not empty. Deﬁne ¯n = min F. As P(¯n) is false, condition i) prevents ¯n from
being equal to n0, so ¯n > n0. Therefore ¯n −1 ≥n0, and P(¯n −1) is true by
deﬁnition of the minimum. But applying ii) with n = ¯n −1 implies that P(¯n) is
true, that is, ¯n /∈F. This contradicts the fact that ¯n is the minimum of F.
2
In practice, the Principle of Induction is employed as follows: one checks ﬁrst
that P(n0) is true; then one assumes that P(n) is true for a generic n, and proves
that P(n + 1) is true as well.
As a ﬁrst application of the Principle of Induction, let us prove Bernoulli’s
inequality: For all r ≥−1,
(1 + r)n ≥1 + nr ,
∀n ≥0 .
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_A1,
© Springer International Publishing Switzerland 2015

428
A.1 The Principle of Mathematical Induction
In this case, the predicate P(n) is given by “(1 + r)n ≥1 + nr”. For n = 0 we have
(1 + r)0 = 1 = 1 + 0r , hence P(0) holds.
Assume the inequality is true for a given n and let us show it holds for n + 1.
Observing that 1 + r ≥0, we have
(1 + r)n+1 = (1 + r)(1 + r)n ≥(1 + r)(1 + nr)
= 1 + r + nr + nr2 = 1 + (n + 1)r + nr2
≥1 + (n + 1)r ,
and thus the result.
Recall that this inequality has been already established in Example 5.18 with
another proof, which however is restricted to the case r > 0.
The Principle of Induction allows us to prove various results given in previous
chapters. Hereafter, we repeat their statements and add the corresponding proofs.
▶Proof of the Newton binomial expansion, p. 20
(a + b)n =
n
	
k=0
n
k

an−kbk ,
n ≥0 .
Proof. For n = 0 we have
(a + b)0 = 1
and
0
	
k=0
0
0

a0b0 = a0b0 = 1 ,
so the relation holds.
Let us now suppose that the formula is true for a generic n and verify that it
remains true for the successive integer; the claim is thus
(a + b)n+1 =
n+1
	
k=0
n + 1
k

an+1−kbk .
We expand the n + 1-term
(a + b)n+1 = (a + b)(a + b)n = (a + b)
n
	
k=0
n
k

an−kbk
=
n
	
k=0
n
k

an+1−kbk +
n
	
k=0
n
k

an−kbk+1 ;
by putting k + 1 = h in the second sum we obtain
n
	
k=0
n
k

an−kbk+1 =
n+1
	
h=1

n
h −1

an+1−hbh

A.1 The Principle of Mathematical Induction
429
and, going back to the original variable k, since h is merely a symbol, we obtain
n
	
k=0
n
k

an−kbk+1 =
n+1
	
k=1

n
k −1

an+1−kbk .
Therefore
(a + b)n+1 =
n
	
k=0
n
k

an+1−kbk +
n+1
	
k=1

n
k −1

an+1−kbk
=
n
0

an+1b0 +
n
	
k=1
n
k

+

n
k −1

an+1−kbk +
n
n

a0bn+1 .
Using (1.12), with n replaced by n + 1, and recalling that
n
0

= 1 =
n + 1
0

e
n
n

= 1 =
n + 1
n + 1

we eventually ﬁnd
(a + b)n+1 =
n + 1
0

an+1b0 +
n
	
k=1
n + 1
k

an+1−kbk +
n + 1
n + 1

a0bn+1
=
n+1
	
k=0
n + 1
k

an+1−kbk ,
i.e., the claim.
2
▶Proof of the Theorem of existence of zeroes, p. 109
Theorem 4.23 (Existence of zeroes) Let f be a continuous map on a
closed, bounded interval [a, b]. If f(a)f(b) < 0, i.e., if the images of the end-
points under f have diﬀerent signs, f admits a zero within the open inter-
val (a, b).
If moreover f is strictly monotone on [a, b], the zero is unique.
Proof. We refer to the proof given on p. 109. Therein, it is enough to justify the
existence of two sequences {an} and {bn}, ﬁnite or inﬁnite, that fulﬁll the predicate
P(n):
[a0, b0] ⊃[a1, b1] ⊃. . . ⊃[an, bn]
f(an) < 0 < f(bn)
and
bn −an = b0 −a0
2n
.
When n = 0, by assumption f(a0) = f(a) < 0 < f(b) = f(b0), so trivially we have
b0 −a0 = b0 −a0
20
.

430
A.1 The Principle of Mathematical Induction
Assume the above relations hold up to a certain n. Let cn = an + bn
2
be the
mid-point of the interval [an, bn]. If f(cn) = 0, the construction of the sequences
terminates, since a zero of the function is found. If f(cn) ̸= 0, let us verify P(n+1).
If f(cn) > 0, we set an+1 = an and bn+1 = cn, whereas if f(cn) < 0, we set
an+1 = cn and bn+1 = bn. The interval [an+1, bn+1] is a sub-interval of [an, bn],
and
f(an+1) < 0 < f(bn+1)
and
bn+1 −an+1 = bn −an
2
= b0 −a0
2n+1
.
2
▶Proof of inequality (5.16), p. 140
Let us begin by establishing the following general property.
Property A.1.2 Let {bm}m≥0 be a sequence with non-negative terms. As-
sume there exists a number r > 0 for which the following inequalities hold:
bm+1 ≤r bm ,
∀m ≥0 .
Then one has
bm ≤rmb0 ,
∀m ≥0 .
Proof. We apply the Principle of Induction. For m = 0, the inequality is trivially
true, since b0 ≤r0b0 = b0.
Let us assume the inequality to be true for m and let us check it for m + 1.
Using the assumption, one has
bm+1 ≤r bm ≤r rmb0 = rm+1b0 .
2
If all terms of the sequence {bm}m≥0 are strictly positive, a similar statement holds
with strict inequalities, i.e., with ≤replaced by <.
Next, consider inequality (5.16). In order to derive the implication
an+1 < r an
⇒
an+1 < rn−nεanε+1 ,
let us set bm = am+nε+1 and observe that the assumption
an+1 < r an ,
∀n > nε
is equivalent to
bm+1 < r bm ,
∀m ≥0 .
Thus, the previous property yields bm < rmb0, whence we get (5.16) by choosing
m = n −nε.

A.2
Complements on limits and continuity
In this appendix, we ﬁrst state and prove some results about limits, that are used
in the subsequent proof of Theorem 4.10 concerning the algebra of limits. Next, we
rigorously justify the limit behaviour of the most important elementary functions
at the extrema of their domain, and we check the continuity of these functions at
all points they are deﬁned. At last, we provide the proofs of several properties of
Napier’s number stated in the text, and we show that this important number is
irrational.
A.2.1 Limits
Now we discuss few results that will be useful later.
Theorem A.2.1 (local boundedness) If a map f admits a ﬁnite limit for
x →c, there exist a neighbourhood I(c) of c and a constant Mf > 0 such that
∀x ∈dom f ∩I(c) \ {c} , |f(x)| ≤Mf .
Proof. Let ℓ= lim
x→c f(x) ∈R; the deﬁnition of limit with, say, ε = 1, implies the
existence of a neighbourhood I(c) of c such that
∀x ∈dom f,
x ∈I(c) \ {c}
⇒
|f(x) −ℓ| < 1 .
By the triangle inequality (1.1), on such set
|f(x)| = |f(x) −ℓ+ ℓ| ≤|f(x) −ℓ| + |ℓ| < 1 + |ℓ| .
Therefore it is enough to choose Mf = 1 + |ℓ|.
2
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_A2,
© Springer International Publishing Switzerland 2015

432
A.2 Complements on limits and continuity
Theorem A.2.2 (Theorem 4.2, strong form) If f admits non-zero limit
(ﬁnite or inﬁnite) for x →c, then there are a neighbourhood I(c) of c and a
constant Kf > 0 for which
∀x ∈dom f ∩I(c) \ {c} ,
|f(x)| > Kf .
(A.2.1)
Proof. Let ℓ= lim
x→c f(x). If ℓ∈R \ {0}, and given for instance ε = |ℓ|/2 in the
deﬁnition of limit for f, there exists a neighbourhood I(c) with ∀x ∈dom f ∩I(c)\
{c}, |f(x) −ℓ| < |ℓ|/2. Thus we have
|ℓ| = |f(x) + ℓ−f(x)| ≤|f(x)| + |f(x) −ℓ| < |f(x)| + |ℓ|
2
hence
|f(x)| > |ℓ| −|ℓ|
2 = |ℓ|
2 .
The claim follows by taking Kf = |ℓ|
2 .
If ℓ± ∞, then lim
x→c |f(x)| = +∞and it is suﬃcient to take A = 1 in the
deﬁnition of limit to have |f(x)| > 1 in a neighbourhood I(c) of c; in this case we
may take in fact Kf = 1.
2
Remark A.2.3 Notice that if ℓ> 0, Theorem 4.2 ensures that on a suitable
neighbourhood of c, possibly excluding c itself, the function is positive. Therefore
the inequality in (A.2.1) becomes the more precise f(x) > Kf. Similarly for ℓ< 0,
in which case (A.2.1) reads f(x) < −Kf. In this sense Theorem A.2.2 is stronger
than Theorem 4.2.
2
The next property makes checking a limit an easier task.
Property A.2.4 In order to prove that lim
x→c f(x) = ℓ∈R it is enough to ﬁnd
a constant C > 0 such that for every ε > 0 there is a neighbourhood I(c) with
∀x ∈dom f,
x ∈I(c) \ {c}
⇒
|f(x) −ℓ| < Cε .
(A.2.2)
Proof. Condition (3.8) follows indeed from (A.2.2) by choosing ε/C instead of ε.
2

A.2.1
Limits
433
▶Proof of Theorem 4.10, p. 96
Teorema 4.10 Suppose f admits limit ℓ(ﬁnite or inﬁnite) and g admits limit
m (ﬁnite or inﬁnite) for x →c. Then
lim
x→c [f(x) ± g(x)] = ℓ± m,
lim
x→c [f(x) g(x)] = ℓm,
lim
x→c
f(x)
g(x) = ℓ
m
provided the right-hand-side expressions make sense. (In the last case one as-
sumes g(x) ̸= 0 on some I(c)\{c}.)
Proof. The cases we shall prove are:
a) if ℓ∈R and m = −∞, then lim
x→c

f(x) −g(x)

= +∞;
b) if ℓ, m ∈R, then lim
x→c f(x)g(x) = ℓm ∈R;
c) if ℓ, m ∈R and m ̸= 0, then lim
x→c
f(x)
g(x) = ℓ
m ∈R;
d) if ℓ∈R \ {0} or ℓ± ∞, and m = 0, then lim
x→c
f(x)
g(x) = ∞.
All remaining possibilities are left to the reader as exercise.
a) Let A > 0 be arbitrarily ﬁxed.
By Theorem A.2.1 applied to f, there is a neighbourhood I′(c) of c and there is a
constant Mf > 0 such that for each x ∈dom f ∩I′(c) \ {c}, |f(x)| ≤Mf.
Moreover, lim
x→c g(x) = −∞is the same as saying that for any B > 0 there is an
I′′(c) such that g(x) < −B for every x ∈dom g∩I′′(c)\{c}, i.e, −g(x) > B. Choose
B = A+Mf and set I(c) = I′(c)∩I′′(c): then for all x ∈dom f ∩dom g∩I(c)\{c},
f(x) −g(x) > −Mf + B ≥A .
This proves that lim
x→c

f(x) −g(x)

= +∞.
b) Fix ε > 0.
Assuming lim
x→c f(x) = ℓ∈R, as we have, tells
∃I′(c) : ∀x ∈dom f, x ∈I′(c) \ {c}
⇒
|f(x) −ℓ| < ε ,
while Theorem A.2.1 gives
∃I′′(c), ∃Mf > 0 : ∀x ∈dom f, x ∈I′′(c) \ {c}
⇒
|f(x)| < Mf .

434
A.2 Complements on limits and continuity
Analogously, lim
x→c g(x) = m ∈R implies
∃I′′′(c) : ∀x ∈dom g, x ∈I′′′(c) \ {c}
⇒
|g(x) −m| < ε .
Set now I(c) = I′(c) ∩I′′(c) ∩I′′′(c); for all x ∈dom f ∩dom g ∩I(c) \ {c} we have
|f(x)g(x) −ℓm| = |f(x)g(x) −f(x)m + f(x)m −ℓm|
= |f(x)

g(x) −m

+

f(x) −ℓ

m|
≤|f(x)||g(x) −m| + |f(x) −ℓ| |m| < (Mf + |m|)ε .
This means that (A.2.2) holds with C = Mf + |m| .
c) Let ε > 0 be given.
From lim
x→c f(x) = ℓ∈R and lim
x→c g(x) = m ∈R it follows
∃I′(c) : ∀x ∈dom f, x ∈I′(c) \ {c}
⇒
|f(x) −ℓ| < ε
and
∃I′′(c) : ∀x ∈dom g, x ∈I′′(c) \ {c}
⇒
|g(x) −m| < ε .
Since m ̸= 0 moreover, Theorem A.2.2 guarantees there is a neighbourhood I′′′(c)
of c together with a constant Kg > 0 such that |g(x)| > Kg, ∀x ∈dom g, x ∈
I′′′(c) \ {c}.
Set I(c) = I′(c) ∩I′′(c) ∩I′′′(c); then for all x ∈dom f ∩dom g, x ∈I(c) \ {c}

f(x)
g(x) −ℓ
m
 =

f(x)m −ℓg(x)
mg(x)
 = |f(x)m −ℓm + ℓm −ℓg(x)|
|m||g(x)|
=

f(x) −ℓ

m + ℓ

m −g(x)

|m||g(x)|
≤|f(x) −ℓ| |m| + |ℓ| |g(x) −m|
|m||g(x)|
< |m| + |ℓ|
|m|Kg
ε .
Hence (A.2.2) holds for C = |m| + |ℓ|
|m|Kg
.
d) Fix a constant A > 0.
Using Theorem A.2.2 on f we know there are a neighbourhood I′(c) of c and a
Kf > 0 such that ∀x ∈dom f∩∈I′(c) \ {c}, |f(x)| > Kf.
By hypothesis lim
x→c g(x) = 0, so choosing ε = Kf/A ensures that there exists a
neighbourhood I′′(c) of c with |g(x)| < Kf/A, for any x ∈dom g ∩I′′(c) \ {c}.
Now let I(c) = I′(c) ∩I′′(c), so that for all x ∈dom f ∩dom g ∩I(c) \ {c}

f(x)
g(x)
 > Kf
A
Kf
= A .
This shows that lim
x→c

f(x)
g(x)
 = +∞, which was our claim.
2

A.2.2
Elementary functions
435
A.2.2 Elementary functions
▶Check of the limits in the table on p. 101
a)
lim
x→+∞xα = +∞,
lim
x→0+ xα = 0
α > 0
b)
lim
x→+∞xα = 0 ,
lim
x→0+ xα = +∞
α < 0
c)
lim
x→±∞
anxn + . . . + a1x + a0
bmxm + . . . + b1x + b0
=
an
bm
lim
x→±∞xn−m
d)
lim
x→+∞ax = +∞,
lim
x→−∞ax = 0
a > 1
e)
lim
x→+∞ax = 0 ,
lim
x→−∞ax = +∞
a < 1
f)
lim
x→+∞loga x = +∞,
lim
x→0+ loga x = −∞
a > 1
g)
lim
x→+∞loga x = −∞,
lim
x→0+ loga x = +∞
a < 1
h)
lim
x→±∞sin x ,
lim
x→±∞cos x ,
lim
x→±∞tan x
do not exist
i)
lim
x→( π
2 +kπ)
± tan x = ∓∞,
∀k ∈Z
l)
lim
x→±1 arcsin x = ±π
2 = arcsin(±1)
m)
lim
x→+1 arccosx = 0 = arccos1 ,
lim
x→−1 arccosx = π = arccos(−1)
n)
lim
x→±∞arctan x = ±π
2
Proof.
a) Take the ﬁrst limit. Fix A > 0 and set B = A1/α > 0. As power functions are
monotone,
∀x ∈R+,
x > B
⇒
xα > Bα = A ,
so the requirement for the limit to hold (Deﬁnition 3.12) is satisﬁed.
As for the second limit, with a given ε > 0 we let δ = ε1/α; again by mono-
tonicity we have
∀x ∈R+,
x < δ
⇒
xα > δα = ε .
The condition of Deﬁnition 3.15 holds.

436
A.2 Complements on limits and continuity
b) These limits follow from a) by substituting z = 1
x, which gives xα =
1
z|α| . The
algebra of limits and the Substitution theorem 4.15 allow to conclude.
c) The formula was proved in Example 4.14 iii).
d) Put a = 1 + b, with b > 0, in the ﬁrst limit and use Bernoulli’s inequality
an = (1 + b)n ≥1 + nb. Fix an arbitrary A > 0 and let n ∈N be such that
1 + nb > A. Since the exponential is monotone we obtain
∀x ∈R,
x > n
⇒
ax > an ≥1 + nb > A ,
hence the condition of Deﬁnition 3.12 holds for B = n.
The second limit is a consequence of the ﬁrst, for
lim
x→−∞ax =
lim
x→−∞
1
a−x =
1
lim
z→+∞az = 0 .
e) These descend from d) using the identity ax =
1
(1/a)x .
f) The limits of d) and Corollary 4.30 imply that the range of y = ax is the interval
(0, +∞). Therefore the inverse y = loga x is well deﬁned on (0, +∞), and
strictly increasing because inverse of a likewise map; its range is (−∞, +∞).
The claim then follows from Theorem 3.27.
g) A consequence of e), for the same reason as above.
h) That the ﬁrst limit does not exist was already observed in Remark 4.19. In a
similar way one can discuss the remaining cases.
More generally, notice that a non-constant periodic function does not admit
limit for x →±∞.
i) Follows from the algebra of limits.
l)-m) The functions are continuous at the limit points (Theorem 4.33), making the
results clear.
n) We can argue as in f) relatively to y = tan x, restricted to (−π
2 , π
2 ), and its
inverse map y = arctan x.
2
▶Proof of Proposition 3.20, p. 81
Proposition 3.20 All elementary functions (polynomials, rational functions,
powers, trigonometric functions, exponentials and their inverses) are continu-
ous over their entire domains.
Proof. The continuity of rational functions was established in Corollary 4.12.
That, together with Theorems 4.17 and 4.33 on composites and inverses, implies in
particular that power functions with positive rational exponent y = xm/n =
m√
xn
are continuous; the same holds for negative rational exponent xq =
1
x−q by using
the algebra of limits. At last, powers with irrational exponent are continuous by

A.2.3
Napier’s number
437
deﬁnition xα = eα log x and because of Theorem 4.17, once the logarithm and the
exponential function have been proven continuous.
As for sine and cosine, their continuity was ascertained in Example 3.17 iii), so
the algebra of limits warrants continuity to the tangent and cotangent functions; by
Theorem 4.33 we infer that the inverse trigonometric functions arcsine, arccosine,
arctangent and arccotangent are continuous as well.
What remains to show is then the continuity of the exponential map only,
because that of the logarithm will follow from Theorem 4.33. Let us consider the
case a > 1, for if 0 < a < 1, we can write ax =
1
(1/a)x and use the same argument.
The identities
ax1+x2 = ax1ax2 ,
a−x = 1
ax
and the monotonicity
x1 < x2
⇒
ax1 < ax2
follow easily from the properties of integer powers and their inverses when the
exponents are rational; for real exponents, we can apply the same argument using
the deﬁnitions of exponential function and supremum.
First of all let us prove that y = ax is continuous at the right of the origin
lim
x→0+ ax = 1 .
(A.2.3)
With ε > 0 ﬁxed, we shall determine a δ > 0 such that
0 ≤x < δ
⇒
0 ≤ax −1 < ε .
The exponential map being monotone, it suﬃces to ﬁnd δ with aδ −1 < ε, i.e.,
aδ < 1 + ε. Searching for δ of the form δ =
1
n, with n integer, the condition
becomes a < (1 + ε)n. Bernoulli’s inequality (5.15) implies (1 + ε)n ≥1 + nε. It
is therefore enough to pick n so that 1 + nε > a, or n > a−1
ε . Thus (A.2.3) holds.
Left-continuity at the origin is a consequence of
lim
x→0−ax = lim
x→0−a−(−x) = lim
x→0−
1
a−x =
1
lim
z→0+ az = 1 ,
so the exponential map is indeed continuous at the origin. Eventually, from
lim
x→x0 ax = lim
x→x0 ax0+(x−x0) = ax0 lim
x→x0 ax−x0 = ax0 lim
z→0 az = ax0 ,
we deduce that the function is continuous at every point x0 ∈R.
2
A.2.3 Napier’s number
We shall prove some properties of the sequence an =

1 + 1
n
n
, n > 0, deﬁning
the Napier’s number e (p. 72).

438
A.2 Complements on limits and continuity
Property A.2.5 The sequence {an} is strictly increasing.
Proof. Using Newton’s formula (1.13) and (1.11), we may write
an =

1 + 1
n
n
=
n
	
k=0
n
k
 1
nk =
n
	
k=0
1
k!
n(n −1) · · · (n −k + 1)
nk
=
n
	
k=0
1
k!
n
n
n −1
n
· · · n −k + 1
n
=
n
	
k=0
1
k! · 1 ·

1 −1
n

· · ·

1 −k −1
n

;
(A.2.4)
similarly,
an+1 =
n+1
	
k=0
1
k! · 1 ·

1 −
1
n + 1

· · ·

1 −k −1
n + 1

.
(A.2.5)
We note that

1 −1
n

<

1 −
1
n + 1

,
· · ·
,

1 −k −1
n

<

1 −k −1
n + 1

so each summand of (A.2.4) is smaller than the corresponding term in (A.2.5).
The latter sum, moreover, contains an additional positive summand labelled by
k = n + 1. Therefore an < an+1 for each n.
2
Property A.2.6 The sequence {an} is bounded; precisely,
2 < an < 3 ,
∀n > 1 .
Proof. Since a1 = 2, and the sequence is strictly monotone by the previous prop-
erty, we have an > 2 , ∀n > 1. Let us show that an < 3 , ∀n > 1. By (A.2.4), and
observing that k! = 1 · 2 · 3 · · · k ≥1 · 2 · 2 · · · 2 = 2k−1, it follows
an =
n
	
k=0
1
k! · 1 ·

1 −1
n

· · ·

1 −k −1
n

<
n
	
k=0
1
k!
= 1 +
n
	
k=1
1
k! ≤1 +
n
	
k=1
1
2k−1 = 1 +
n−1
	
k=0
1
2k .
Example 5.27 will tell us that
n−1
	
k=0
1
2k = 1 −
1
2n
1 −1
2
= 2

1 −1
2n

< 2 .
We conclude that an < 3.
2

A.2.3
Napier’s number
439
▶Proof of Property 4.20, p. 105
Property 4.20 The following limit holds
lim
x→±∞

1 + 1
x
x
= e.
Proof. We start by considering the limit for x →+∞. Denoting by n = [x] the
integer part of x (see Examples 2.1), by deﬁnition n ≤x < n + 1; from that it
follows
1
n + 1 < 1
x ≤1
n, in other words 1 +
1
n + 1 < 1 + 1
x ≤1 + 1
n. The familiar
features of power functions yield

1 +
1
n + 1
n
≤

1 +
1
n + 1
x
<

1 + 1
x
x
≤

1 + 1
n
x
<

1 + 1
n
n+1
hence

1 +
1
n + 1
n+1 
1 +
1
n + 1
−1
<

1 + 1
x
x
<

1 + 1
n
n 
1 + 1
n

.
(A.2.6)
When x tends to +∞, n does the same. Using (3.3) we have
lim
n→+∞

1 + 1
n
n 
1 + 1
n

=
lim
n→+∞

1 + 1
n
n
lim
n→+∞

1 + 1
n

= e;
the substitution m = n + 1 similarly gives
lim
n→+∞

1 +
1
n + 1
n+1 
1 +
1
n + 1
−1
= e.
Applying the Second comparison theorem 4.5 to the three functions in (A.2.6)
proves the claim for x →+∞. Now let us look at the case when x tends to −∞.
If x < 0 we can write x = −|x|, so

1 + 1
x
x
=

1 −1
|x|
−|x|
=
|x| −1
|x|
−|x|
=

|x|
|x| −1
|x|
=

1 +
1
|x| −1
|x|
.
Set y = |x| −1 and note y tends to +∞as x goes to −∞. Therefore,
lim
x→−∞

1 + 1
x
x
=
lim
y→+∞

1 + 1
y
y+1
=
lim
y→+∞

1 + 1
y
y
lim
y→+∞

1 + 1
y

= e.
This concludes the proof.
2

440
A.2 Complements on limits and continuity
▶Proof of the irrationality of Napier’s number, p. 72
Property A.2.7 Napier’s number e is irrational, and lies between 2 and 3.
Proof. Based on the First comparison theorem for sequences (p. 137, Theorem
4), from the previous property we quickly deduce
2 < e ≤3 .
(A.2.7)
Suppose, by contradiction, that e is a rational number, so that there exist two
integers m0 and n0 ̸= 0 such that e = m0
n0
. Recall that for any n ≥0
e =
n
	
k=0
1
k! +
e¯xn
(n + 1)! ,
0 < ¯xn < 1
(see Remark 7.4). From this,
n!e = n!m0
n0
=
n
	
k=0
n!
k! + e¯xn
n + 1 .
(A.2.8)
As the exponential map is monotone, and using (A.2.7), we deduce
1 = e0 < e¯xn < e < 3 .
Choosing now n ≥max(3, n0), the numbers n!m0
n0
and
n
	
k=0
n!
k!
are integers,
whereas
e¯xn
n + 1 lies in the open interval between 0 and 1. The identity (A.2.8) then
must be false, so e is irrational and equality in (A.2.7) never occurs.
2

A.3
Complements on the global features of continuous
maps
We ﬁrst introduce the concept of subsequence of a given sequence, and establish a
number of related properties. Among them, the Theorem of Bolzano-Weierstrass,
which is a fundamental ingredient in the subsequent proof of the Theorem of
Weierstrass concerning continuous functions on an interval of the real line; the
proofs of other results for such functions are also provided. The appendix ends with
the deﬁnition of uniform continuity and the discussion of some of its properties;
these concepts will ﬁnd application to the study of integral calculus and diﬀerential
equations.
A.3.1 Subsequences
Theorem 2 on p. 137 states that every converging sequence is bounded. In general,
though, the opposite implication is false. In fact, the sequence an = (−1)n does not
converge despite being bounded (|an| = 1, ∀n). But if we take just the elements
with even subscript, we obtain the constant sequence {bk}k≥0 where bk = a2k =
1, k ≥0, which is patently convergent. Similarly if we take odd indexes only:
the constant sequence {ck}k≥0 with ck = a2k+1 = −1, k ≥0, converges. Such
sequences have been extracted, so to say, from the initial sequence {an}n≥0, in the
sense formalised below.
Deﬁnition A.3.1 Let {an}n≥n∗be a sequence and {nk}k≥0 a strictly in-
creasing sequence of integers ≥n∗. The sequence {ank}k≥0 is said sub-
sequence of {an}n≥n∗.
Observe that the sequence {ank}k≥0 is a composite function, for it is obtained
by composing the map k →nk with n →an.
Any subsequence of a converging or diverging sequence preserves the limit
behaviour of the ‘mother’ sequence:
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_A3,
© Springer International Publishing Switzerland 2015

442
A.3 Complements on the global features of continuous maps
Proposition A.3.2 Let the sequence {an}n≥n∗admit limit
lim
n→+∞an = ℓ,
ﬁnite or inﬁnite. Then for any subsequence {ank}k≥0
lim
k→+∞ank = ℓ.
Proof. It is not that diﬃcult to see, by induction, that
nk ≥k ,
∀k ≥0 .
(A.3.1)
Clearly, n0 ≥0; supposing nk ≥k we have nk+1 > nk because the sequence is
strictly increasing. That in turn implies nk+1 ≥k + 1, whence the claim follows.
Due to the First comparison theorem (p. 137, Theorem 4), the inequality
(A.3.1) tells that the sequence {nk} diverges to +∞. The result then follows from
Theorem 4.15 adapted to sequences (whose proof is similar to the one given on
p. 102).
2
The fact that one can extract a converging subsequence from a bounded se-
quence, as we showed with the example an = (−1)n, is a general and deep result.
This is how it goes.
Theorem A.3.3 (Bolzano-Weierstrass) A bounded sequence always ad-
mits a converging subsequence.
Proof. Suppose {xn}n≥n∗is a bounded sequence by assuming
a ≤xn ≤b ,
∀n ≥n∗,
for suitable a, b ∈R. We shall bisect the interval [a, b] over and over, as in the
proof of Theorem 4.23 of existence of zeroes. Set
a0 = a ,
b0 = b ,
N0 = {n ≥n∗} ,
n0 = n∗.
Call c0 the midpoint of [a0, b0] and deﬁne the sets
N −
0 = {n ∈N0 : xn ∈[a0, c0]} ,
N +
0 = {n ∈N0 : xn ∈[c0, b0]} .
Note N0 = N −
0 ∪N +
0 , where at least one of N −
0 , N +
0 must be inﬁnite because N0
is. If N −
0 is inﬁnite, set
a1 = a0 ,
b1 = c0 ,
N1 = N −
0 ;
otherwise,
a1 = c0 ,
b1 = b0 ,
N1 = N +
0 .
Now let n1 be the ﬁrst index > n0 contained N1; we can make such a choice since
N1 is inﬁnite. Iterating the procedure (as always, in these situations, the Principle

A.3.2
Continuous functions on an interval
443
of Induction A.1.1 is required in order to make things formal), we can build a
sequence of intervals
[a0, b0] ⊃[a1, b1] ⊃. . . ⊃[ak, bk] ⊃. . . ,
with
bk −ak = b0 −a0
2k
,
a sequence of inﬁnite sets
N0 ⊇N1 ⊇. . . ⊇Nk ⊇. . .
and a strictly increasing sequence of indices {nk}k≥0, nk ∈Nk, such that
ak ≤xnk ≤bk ,
∀k ≥0 .
Then just as in the proof of Theorem 4.23, there will be a unique ℓ∈[a, b] satisfying
lim
k→∞ak = lim
k→∞bk = ℓ.
From the Second comparison theorem (Theorem 5 on p. 137) we deduce that the
sequence {xnk}k≥0, extracted from {xn}n≥n∗, converges to ℓ.
2
A.3.2 Continuous functions on an interval
▶Proof of the Theorem of Weierstrass, p. 114
Theorem 4.31 (Weierstrass) A continuous map f on a closed and bounded
interval [a, b] is bounded and admits minimum and maximum
m = min
x∈[a,b] f(x)
and
M = max
x∈[a,b]f(x).
Consequently,
f([a, b]) = [m, M].
Proof. We will show ﬁrst that f admits a maximum in [a, b], in other words there
exists ξ ∈[a, b] such that f(x) ≤f(ξ), ∀x ∈[a, b]. For this, let
M = sup f([a, b]),
which is allowed to be both real or +∞. In the former case the characterisation of
the supremum, (1.7) ii), tells that for any n ≥1 there is xn ∈[a, b] with
M −1
n < f(xn) ≤d.

444
A.3 Complements on the global features of continuous maps
Letting n go to +∞, from the Second comparison theorem (Theorem 5 on p. 137)
we infer
lim
n→∞f(xn) = M.
In the other case, by deﬁnition of unbounded set (from above) we deduce that for
any n ≥1 there is xn ∈[a, b] such that
f(xn) ≥n.
The Second comparison theorem implies
lim
n→∞f(xn) = +∞= M.
In either situation, the sequence {xn}n≥1 thus deﬁned is bounded (it is contained
in [a, b]). We are then entitled to use Theorem of Bolzano-Weierstrass and call
{xnk}k≥0 a convergent subsequence. Let ξ be its limit; since all xnk belong to
[a, b], necessarily ξ ∈[a, b]. But {f(xnk)}k≥0 is a subsequence of {f(xn)}n≥0, so
by Proposition A.3.2
lim
k→∞f(xnk) = M.
The continuity of f at ξ implies
f(ξ) = f( lim
k→∞xnk) = lim
k→∞f(xnk) = M,
which tells us that M cannot be +∞. Moreover, M belongs to the range of f,
hence
M = max f([a, b]).
Arguing in a similar fashion one proves that the number
m = min f([a, b])
exists and is ﬁnite. The ﬁnal claim is a consequence of Corollary 4.30.
2
▶Proof of Corollary 4.25, p. 111
Corollary 4.25 Let f be continuous on the interval I and suppose it admits
non-zero limits (ﬁnite or inﬁnite) that are diﬀerent in sign for x tending to
the end-points of I. Then f has a zero in I, which is unique if f is strictly
monotone on I.
Proof. We indicate by α, β (ﬁnite or not) the end-points of I and call
lim
x→α+ f(x) = ℓα
and
lim
x→β−f(x) = ℓβ .

A.3.2
Continuous functions on an interval
445
Should one end-point, or both, be inﬁnite, these writings denote the usual limits
at inﬁnity.
We suppose ℓα < 0 < ℓβ, for otherwise we can swap the roles of ℓα and ℓβ. By
Theorem 4.2 there exist a right neighbourhood I+(α) of α and a left neighbourhood
I−(β) of β such that
∀x ∈I+(α) , f(x) < 0
and
∀x ∈I−(β) , f(x) > 0 .
Let us ﬁx points a ∈I+(α) and b ∈I−(β) with α < a, b < β. The interval [a, b] is
contained in I, hence f is continuous on it, and by construction f(a) < 0 < f(b).
Therefore f will vanish somewhere, in virtue of Theorem 4.23 (existence of zeroes)
applied to [a, b].
If f is strictly monotone, uniqueness follows from Proposition 2.8 on the inter-
val I.
2
▶Proof of Theorems 4.32 and 4.33, p. 114
Let us prove a preliminary result before proceeding.
Lemma A.3.4 Let f be continuous and invertible on an interval I. For any
chosen points x1 < x2 < x3 in I, then one, and only one, of
(i)
f(x1) < f(x2) < f(x3)
or
(ii)
f(x1) > f(x2) > f(x3)
holds.
Proof. As f is invertible, hence one-to-one, the images f(x1) and f(x3) cannot
coincide. Then either f(x1) < f(x3) or f(x1) > f(x3), and we claim that these
cases imply (i) or (ii), respectively.
Suppose f(x1) < f(x3), and assume by contradiction that (i) is false, so f(x2)
does not lie strictly between f(x1) and f(x3). For instance,
f(x1) < f(x3) < f(x2)
(if f(x2) < f(x1) < f(x3) the argument is the same). As f is continuous on the
closed interval [x1, x2] ⊆I, the Intermediate value theorem 4.29 prescribes that it
will assume every value between f(x1) and f(x2) on [x1, x2]. In particular, there
will be a point ¯x ∈(x1, x2) such that
f(¯x) = f(x3),
in contradiction to injectivity: ¯x and x3 are in fact distinct, because separated
by x2.
2

446
A.3 Complements on the global features of continuous maps
Theorem 4.32 A continuous function f on an interval I is one-to-one if and
only if it is strictly monotone.
Proof. Thanks to Proposition 2.8 we only need to prove the implication
f invertible onI
⇒
f strictly monotone on I .
Letting x1 < x2 be arbitrary points of I, we claim that if f(x1) < f(x2) then f
is strictly increasing on I (f(x1) > f(x2) will similarly imply f strictly decreases
on I).
Let z1 < z2 be points in I, and suppose both lie within (x1, x2); the other
possibilities are dealt with in the same way. Hence we have
x1 < z1 < z2 < x2.
Let us use Lemma A.3.4 on the triple x1, z1, x2: since we have assumed f(x1) <
f(x2), it follows
f(x1) < f(z1) < f(x2).
Now we employ the triple z1, z2, x2, to the eﬀect that
f(z1) < f(z2) < f(x2).
The ﬁrst inequality in the above line tells f is strictly increasing, proving The-
orem 4.32.
2
Theorem 4.33 Let f be continuous and invertible on an interval I. Then the
inverse f −1 is continuous on the interval J = f(I).
Proof. The ﬁrst remark is that J is indeed an interval, by Corollary 4.30. Using
Theorem 4.32 we deduce f is strictly monotone on I: to ﬁx ideas, suppose it is
strictly increasing (having f strictly decreasing would not change the proof). By
deﬁnition of a monotone map we have that f −1 is strictly increasing on J as well.
But it is known that a monotone map admits at most discontinuities of the ﬁrst
kind (Corollary 3.28). We will show that f −1 cannot have this type either. By
contradiction, suppose there is a jump point y0 = f(x0) ∈J = f(I) for f −1.
Equivalently, let
z−
0 = sup
y<y0
f −1(y) = lim
y→y−
0
f −1(y) ,
z+
0 = inf
y>y0 f −1(y) = lim
y→y+
0
f −1(y) ,
and suppose z−
0 < z+
0 . Then inside (z−
0 , z+
0 ) there will be at most one element
x0 = f −1(y0) of the range f −1(J). Thus f −1(J) is not an interval. By deﬁnition
of J, on the other hand, f −1(J) = I is an interval by hypothesis. In conclusion,
f −1 must be continuous at each point of J.
2

A.3.3
Uniform continuity
447
A.3.3 Uniform continuity
Let the map f be deﬁned on the real interval I. Recall f is called continuous on
I if it is continuous at each point x0 ∈I, i.e., for any x0 ∈I and any ε > 0 there
exists δ > 0 such that
∀x ∈I,
|x −x0| < δ
⇒
|f(x) −f(x0)| < ε .
In general δ = δ(ε, x0), meaning that δ depends on x0, too. But if, for ﬁxed ε > 0,
we ﬁnd δ = δ(ε) independent of x0 ∈I, we say f is uniformly continuous on I.
More precisely,
Deﬁnition A.3.5 A function f is called uniformly continuous on I if,
for any ε > 0, there is a δ > 0 satisfying
∀x′, x′′ ∈I,
|x′ −x′′| < δ
⇒
|f(x′) −f(x′′)| < ε .
(A.3.2)
Examples A.3.6
i)
Let f(x) = x2, deﬁned on I = [0, 1]. Then
|f(x′) −f(x′′)| = |(x′)2 −(x′′)2| = |x′ + x′′| |x′ −x′′| ≤2|x′ −x′′| .
If |x′ −x′′| < ε
2 we see |f(x′) −f(x′′)| < ε, hence δ = ε
2 fulﬁlls (A.3.2) on I,
rendering f uniformly continuous on I.
ii) Take f(x) = x2 on I = [0, +∞). We want to prove by contradiction that f is
not uniformly continuous on I. If it were, with ε = 1 for example, there would
be a δ > 0 satisfying (A.3.2). Choose x′ ∈I and let x′′ = x′ + δ
2, so that
|x′ −x′′| = δ
2 < δ; then
|f(x′) −f(x′′)| = |x′ + x′′| |x′ −x′′| < 1 ,
or

2x′ + δ
2
δ
2 < 1 .
Now letting x′ tend to +∞we obtain a contradiction.
iii) Consider f(x) = sin x on I = R. From
sin x′ −sin x′′ = 2 sin x′ −x′′
2
cos x′ + x′′
2
we have
| sin x′ −sin x′′| ≤|x′ −x′′| ,
∀x′, x′′ ∈R .
With a ﬁxed ε > 0, δ = ε satisﬁes the requirement for uniform continuity.

448
A.3 Complements on the global features of continuous maps
iv) Let f(x) = 1
x on I = (0, +∞). Note that
|f(x′) −f(x′′)| =

1
x′ −1
x′′
 = |x′ −x′′|
x′x′′
.
By letting x′, x′′ tend to 0, one easily veriﬁes that f cannot be uniformly
continuous on I.
But if we consider only Ia = [a, +∞), where a > 0 is ﬁxed, then
|f(x′) −f(x′′)| ≤|x′ −x′′|
a2
,
so δ = a2ε satisﬁes the requirement on Ia, for any given ε > 0.
2
Are there conditions guaranteeing uniform continuity? One answer is provided
by the following result.
Theorem A.3.7 (Heine-Cantor) Let f be a continuous map on the closed
and bounded interval I = [a, b]. Then f is uniformly continuous on I.
Proof. Let us suppose f is not uniformly continuous on I. This means that there
exists an ε > 0 such that, for any δ > 0, there are x′, x′′ ∈I with |x′ −x′′| < δ
and |f(x′) −f(x′′)| ≥ε. Choosing δ = 1
n, n ≥1, we ﬁnd two sequences of points
{x′
n}n≥1, {x′′
n}n≥1 inside I such that
|x′
n −x′′
n| < 1
n
and
|f(x′
n) −f(x′′
n)| ≥ε .
The condition on the left implies
lim
n→∞(x′
n −x′′
n) = 0 ,
while the one on the right implies that f(x′
n) −f(x′′
n) will not tend to 0 for n →
∞. On the other hand the sequence {x′
n}n≥1 is bounded, a ≤x′
n ≤b for all
n, so Theorem A.3.3, of Bolzano-Weierstrass, will give a subsequence {x′
nk}k≥0
converging to a certain ¯x ∈I:
lim
k→∞x′
nk = ¯x .
Also the subsequence {x′′
nk}k≥0 converges to ¯x, for
lim
k→∞x′′
nk = lim
k→∞[x′
nk + (x′′
nk −x′
nk)] = lim
k→∞x′
nk + lim
k→∞(x′′
nk −x′
nk) = ¯x + 0 = ¯x .
Now, f being continuous at ¯x, we have
lim
k→∞f(x′
nk) = f

lim
k→∞x′
nk

= f(¯x)
and
lim
k→∞f(x′′
nk) = f

lim
k→∞x′′
nk

= f(¯x) .
Then
lim
k→∞

f(x′
nk) −f(x′′
nk)

= f(¯x) −f(¯x) = 0 ,
contradicting the fact that
|f(x′
nk) −f(x′′
nk)| ≥ε > 0 ,
∀k ≥0 .
2

A.4
Complements on diﬀerential calculus
This appendix is entirely devoted to the proof of important results of diﬀerential
calculus. We ﬁrst justify the main derivation formulas, then we prove the Theorem
of de l’Hˆopital. Our next argument is the study of diﬀerentiable and convex func-
tions, for which we highlight logical links between convexity and certain properties
of the ﬁrst derivative. At last, we establish Taylor formulas with three forms of
the remainder, i.e., Peano’s, Lagrange’s and the integral form.
A.4.1 Derivation formulas
▶Proof of Theorem 6.4, p. 174
Theorem 6.4 (Algebraic operations) Let f(x), g(x) be diﬀerentiable maps
at x0 ∈R. Then the maps f(x) ± g(x), f(x)g(x) and, if g(x0) ̸= 0, f(x)
g(x) are
diﬀerentiable at x0. To be precise,
(f ± g)′(x0) = f ′(x0) ± g′(x0),
(f g)′(x0) = f ′(x0)g(x0) + f(x0)g′(x0),
f
g
′
(x0) = f ′(x0)g(x0) −f(x0)g′(x0)
[g(x0)]2
.
Proof. Let us start by (6.3). By Theorem 4.10 we have
lim
x→x0

f(x) ± g(x)

−

f(x0) ± g(x0)

x −x0
= lim
x→x0
f(x) −f(x0)
x −x0
± g(x) −g(x0)
x −x0

= lim
x→x0
f(x) −f(x0)
x −x0
± lim
x→x0
g(x) −g(x0)
x −x0
= f ′(x0) ± g′(x0) .
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_A4,
© Springer International Publishing Switzerland 2015

450
A.4 Complements on diﬀerential calculus
Next we prove (6.4). For this, recall that a diﬀerentiable map is continuous (Pro-
position 6.3), so lim
x→x0 g(x) = g(x0). Therefore
lim
x→x0
f(x) g(x) −f(x0) g(x0)
x −x0
lim
x→x0
f(x) g(x) −f(x0) g(x) + f(x0) g(x) −f(x0) g(x0)
x −x0
= lim
x→x0
f(x) −f(x0)
x −x0
g(x) + f(x0) g(x) −g(x0)
x −x0

= lim
x→x0
f(x) −f(x0)
x −x0
lim
x→x0 g(x) + f(x0) lim
x→x0
g(x) −g(x0)
x −x0
= f ′(x0) g(x0) + f(x0) g′(x0) .
Eventually, we show (6.5). Since lim
x→x0 g(x) = g(x0) ̸= 0, Theorem 4.2 ensures there
is a neighbourhood of x0 where g(x) ̸= 0. Then the function f(x)
g(x) is well deﬁned
on such neighbourhood and we can consider its diﬀerence quotient
lim
x→x0
f(x)
g(x) −f(x0)
g(x0)
x −x0
= lim
x→x0
f(x) g(x0) −f(x0) g(x)
g(x) g(x0) (x −x0)
= lim
x→x0
f(x) g(x0) −f(x0) g(x0) + f(x0) g(x0) −f(x0) g(x)
g(x) g(x0) (x −x0)
= lim
x→x0
1
g(x) g(x0) lim
x→x0
f(x) −f(x0)
x −x0
g(x0) −f(x0)g(x) −g(x0)
x −x0

=
1

g(x0)
2

lim
x→x0
f(x) −f(x0)
x −x0
g(x0) −lim
x→x0 f(x0)g(x) −g(x0)
x −x0

= f ′(x0)g(x0) −f(x0)g′(x0)

g(x0)
2
.
2
▶Proof of Theorem 6.7, p. 175
Theorem 6.7 (“Chain rule”) Let f(x) be diﬀerentiable at x0 ∈R and g(y)
a diﬀerentiable map at y0 = f(x0). Then the composition g ◦f(x) = g

f(x)

is diﬀerentiable at x0 and
(g ◦f)′(x0) = g′(y0)f ′(x0) = g′
f(x0)

f ′(x0).
Proof. Let us use the ﬁrst formula of the ﬁnite increment (6.11) on g at the point
y0 = f(x0):

A.4.1
Derivation formulas
451
g(y) −g(y0) = g′(y0)(y −y0) + o(y −y0),
y →y0 .
By deﬁnition of ‘little o’, the above means that there exists a map ϕ such that
lim
y→y0 ϕ(y) = 0 = ϕ(y0) satisfying
g(y) −g(y0) = g′(y0)(y −y0) + ϕ(y)(y −y0) ,
on a neighbourhood I(y0) of y0 .
As f is continuous at x0 (Proposition 6.3), there is a neighbourhood I(x0) of x0
such that f(x) ∈I(y0) for all x ∈I(x0). If we put y = f(x) in the displayed
relation, this becomes
g(f(x)) −g(f(x0))
x −x0
= g′(f(x0)) f(x) −f(x0)
x −x0
+ ϕ(f(x)) f(x) −f(x0)
x −x0
.
Observing that
lim
x→x0 ϕ(f(x)) = lim
y→y0 ϕ(y) = 0
by the Substitution theorem 4.15, we can pass to the limit and conclude
lim
x→x0
g(f(x)) −g(f(x0))
x −x0
= g′(f(x0)) lim
x→x0
f(x) −f(x0)
x −x0
+ lim
x→x0 ϕ(f(x)) lim
x→x0
f(x) −f(x0)
x −x0
= g′(f(x0))f ′(x0) .
2
▶Proof of Theorem 6.9, p. 175
Theorem 6.9 (Derivative of the inverse function) Suppose f(x) is a
continuous, invertible map on a neighbourhood of x0 ∈R, and diﬀerentiable
at x0, with f ′(x0) ̸= 0. Then the inverse map f −1(y) is diﬀerentiable at y0 =
f(x0), and
(f −1)′(y0) =
1
f ′(x0) =
1
f ′(f −1(y0)).
Proof. The inverse map is continuous on a neighbourhood of y0 in virtue of
Theorem 4.33. Write x = f −1(y), so that on the same neighbourhood
f −1(y) −f −1(y0)
y −y0
=
x −x0
f(x) −f(x0) =
1
f(x)−f(x0)
x−x0
.
By the Substitution theorem 4.15, with x = f −1(y), we have
lim
y→y0
f −1(y) −f −1(y0)
y −y0
= lim
x→x0
1
f(x)−f(x0)
x−x0
=
1
f ′(x0) .
2

452
A.4 Complements on diﬀerential calculus
A.4.2 De l’Hˆopital’s Theorem
▶Proof of de l’Hˆopital’s Theorem, p. 200
Theorem 6.41 (de l’Hˆopital) Let f, g be maps deﬁned on a neighbourhood
of c, except possibly at c, and such that
lim
x→c f(x) = lim
x→c g(x) = L,
where L = 0, +∞or −∞. If f and g are diﬀerentiable around c, except possibly
at c, with g′ ̸= 0, and if
lim
x→c
f ′(x)
g′(x)
exists (ﬁnite or not), then also
lim
x→c
f(x)
g(x)
exists and equals the previous limit.
Proof. The theorem includes several statements corresponding to the values as-
sumed by L and c, and the arguments used for the proofs vary accordingly. For
this reason we have grouped the proofs together into cases.
a) The cases L = 0, c = x+
0 , x−
0 , x0.
Let us suppose c = x+
0 . By assumption
lim
x→x+
0
f(x) =
lim
x→x+
0
g(x) = 0, so we may
extend both functions to x0 (re-deﬁning their values if necessary) by putting
f(x0) = g(x0) = 0; thus f and g become right-continuous at x0. Let I+(x0) denote
the right neighbourhood of x0 where f, g satisfy the theorem, and take x ∈I+(x0).
On the interval [x0, x] Theorem 6.25 is valid, so there is t = t(x) ∈(x0, x) such
that
f(x)
g(x) = f(x) −f(x0)
g(x) −g(x0) = f ′(t)
g′(t) .
As x0 < t(x) < x, the Second comparison theorem 4.5 guarantees that for x
tending to x0 also t = t(x) approaches x0. Now the Substitution theorem 4.15
yields
lim
x→x+
0
f(x)
g(x) = lim
x→x+
0
f ′(t(x))
g′(t(x)) = lim
t→x+
0
f ′(t)
g′(t) ,
and the proof ends.
We proceed similarly when c = x−
0 ; the remaining case c = x0 descends from the
two one-sided limits.
b) The cases L = 0, c = ±∞.

A.4.2
De l’Hˆopital’s Theorem
453
Suppose c = +∞. The substitution z = 1
x leads to consider the limit of the quotient
f( 1
z)
g( 1
z) for z →0+. Because d
dz f
1
z

= −1
z2 f ′
1
z

, and similarly for the map g,
it follows
lim
z→0+
d
dz f
 1
z

d
dz g
 1
z
 = lim
z→0+
f ′  1
z

g′  1
z
 =
lim
x→+∞
f ′(x)
g′(x) .
In this way we return to the previous case c = 0+, and the result is proved. The
same for c = −∞.
c) The cases L = ±∞, c = x+
0 , x−
0 , x0.
Assume c = x+
0 and put
lim
x→x+
0
f ′(x)
g′(x) = ℓ. When ℓ∈R, let I+(x0) be the right
neighbourhood of x0 on which f and g satisfy the theorem. For every ε > 0 there
exists δ1 > 0 with x0 + δ1 ∈I+(x0) so that for all x ∈(x0, x0 + δ1) we have

f ′(x)
g′(x) −ℓ
 < ε. On [x, x0 + δ1] Theorem 6.25 holds, hence there is t = t(x) ∈
(x, x0 + δ1) such that
f(x) −f(x0 + δ1)
g(x) −g(x0 + δ1) = f ′(t)
g′(t) .
(A.4.1)
Write the ratio f(x)
g(x) as
f(x)
g(x) = ψ(x)f ′(t)
g′(t) ,
where, by (A.4.1),
ψ(x) =
1 −g(x0+δ1)
g(x)
1 −f(x0+δ1)
f(x)
,
with
lim
x→x+
0
ψ(x) = 1 ,
because L = ±∞. The last limit implies that there is a δ2 > 0, with δ2 < δ1, such
that
|ψ(x)| ≤2
and
|ψ(x) −1| < ε
for every x ∈(x0, x0 + δ2). Therefore, for all x ∈(x0, x0 + δ2),

f(x)
g(x) −ℓ
 =
ψ(x)f ′(t)
g′(t) −ψ(x)ℓ+ ψ(x)ℓ−ℓ

= |ψ(x)|

f ′(t)
g′(t) −ℓ
 + |ψ(x) −1||ℓ| <

2 + |ℓ|

ε .
We conclude
lim
x→x+
0
f(x)
g(x) = ℓ.

454
A.4 Complements on diﬀerential calculus
Let now ℓ= +∞; for all A > 0 there is δ1 > 0, with x0 + δ1 ∈I+(x0), such that
for all x ∈(x0, x0 + δ1) we have f ′(x)
g′(x) > A. As before, using Theorem A.2.2 we
observe that
lim
x→x+
0
ψ(x) = 1 implies the existence of a δ2 > 0, with δ2 < δ1, such
that ψ(x) ≥1
2 for all x ∈(x0, x0 + δ2). Therefore, for every x ∈(x0, x0 + δ2),
f(x)
g(x) = ψ(x)f ′(t)
g′(t) ≥1
2A ,
proving the claim. The procedure is the same for ℓ= −∞.
An analogous proof holds for c = x−
0 , and c = x0 is dealt with by putting the
two arguments together.
d) The cases L = ±∞, c = ±∞.
As in b), we may substitute z = 1
x and use the previous argument.
2
A.4.3 Convex functions
We begin with a lemma, which tells that local convexity (i.e., convexity on a
neighbourhood of every point of I) is in fact a global condition (valid on all of I).
intorno di ogni punto di I) `e in realt`a globale (cio`e valida su tutto I).
Lemma A.4.1 Let f be diﬀerentiable on the interval I. Then f is convex on
I if and only if for every x0 ∈I
f(x) ≥f(x0) + f ′(x0)(x −x0)
∀x ∈I .
(A.4.2)
Proof. Obviously, it is enough to show that if f is convex according to Deﬁni-
tion 6.33 on I, then also (A.4.2) holds. To this end, one usefully notes that f is
convex on I if and only if the map g(x) = f(x)+ax+b, a, b ∈R is convex; in fact, re-
quiring f(x) ≥f(x0)+f ′(x0)(x−x0) is equivalent to g(x) ≥g(x0)+g′(x0)(x−x0).
Let then x0 ∈I be ﬁxed arbitrarily and consider the convex map g(x) =
f(x)−f(x0)−f ′(x0)(x−x0), which satisﬁes g(x0) = g′(x0) = 0. We have to prove
that g(x) ≥0, ∀x ∈I. Suppose x0 is not the right end-point of I and let us show
g(x) ≥0, ∀x ∈I, x > x0; a ‘symmetry’ argument will complete the proof.
Being g convex at x0, we have g(x) ≥0 on a (right) neighbourhood of x0. It
makes then sense to deﬁne
P = {x > x0 : g(s) ≥0, ∀s ∈[x0, x]}
and x1 = sup P.
If x1 coincides with the right end-point of I, the assertion follows. Let us
assume, by contradiction, x1 lies inside I; By deﬁnition g(x) ≥0, ∀x ∈[x0, x1),

A.4.3
Convex functions
455
while in each (right) neighbourhood of x1 there exist points x ∈I at which g(x) <
0. From this and the continuity of g at x1 we deduce that necessarily g(x1) = 0 (so,
in particular, x1 = max P). We want to prove g(x) = 0, ∀x ∈[x0, x1]. Once we
have done that, then g′(x1) = 0 (as g is diﬀerentiable at x1 and constant on a left
neighbourhood of the same point). Therefore the convexity of g at x1 implies the
existence of a neighbourhood of x1 where g(x) ≥0, against the deﬁnition of x1.
It remains to prove g(x) = 0 in [x0, x1]. As g(x) ≥0 on [x0, x1] by deﬁnition,
we assume, again by contradiction, that M = max{g(x) : x ∈[x0, x1]} > 0, and
let ¯x ∈(x0, x1) be a pre-image of g(¯x) = M. By Fermat’s Theorem 6.21 g′(¯x) = 0,
so the convexity at ¯x yields a neighbourhood of ¯x on which g(x) ≥g(¯x) = M;
but M is the maximum of g on [x0, x1], so g(x) = M on said neighbourhood. Now
deﬁne
Q = {x > ¯x : g(s) = M, ∀s ∈[¯x, x]}
and x2 = sup Q. The map g is continuous, hence x2 = max Q, and moreover
x2 < x1 because g(x1) = 0. As before, the hypothesis of convexity at x2 leads to
a contradiction.
2
▶Proof of Theorem 6.37, p. 193
Theorem 6.37 Given a diﬀerentiable map f on the interval I,
a) if f is convex on I, then f ′ is increasing on I.
b1) If f ′ is increasing on I, then f is convex on I;
b2) if f ′ is strictly increasing on I, then f is strictly convex on I.
Proof.
a) Take x1 < x2 two points in I. From (A.4.2) with x0 = x1 and x = x2 we obtain
f ′(x1) ≤f(x2) −f(x1)
x2 −x1
,
while putting x0 = x2, x = x1 gives
f(x2) −f(x1)
x2 −x1
≤f ′(x2) .
Combining the two inequalities yields the result.
b1) Let x > x0 be chosen in I. The second formula of the ﬁnite increment of f on
[x0, x] prescribes the existence of a point ¯x ∈(x0, x) such that
f(x) = f(x0) + f ′(¯x)(x −x0) .
The map f ′ is monotone, so f ′(¯x) ≥f ′(x0) hence (A.4.2). When x < x0 the
argument is analogous.
b2) In the proof for b1) we now have f ′(¯x) > f ′(x0), whence (A.4.2) is strict (for
x ̸= x0).
2

456
A.4 Complements on diﬀerential calculus
A.4.4 Taylor formulas
We open this section by describing an interesting property of Taylor expansions.
Observe to this end that if a map g is deﬁned only at one point x0, its Taylor
polynomial of degree 0 can still be deﬁned, by letting T g0,x0(x) = g(x0).
Lemma A.4.2 Let f be n times diﬀerentiable at x0. The derivative of order
h, 0 ≤h ≤n, of the Taylor polynomial of f of degree n at x0 coincides with
the Taylor polynomial of f (h) of order n −h at x0:
DhT fn,x0(x) = T f (h)
n−h,x0(x) .
(A.4.3)
In particular,
DhT fn,x0(x0) = f (h)(x0) ,
∀h = 0, . . . , n .
(A.4.4)
Proof. From Example 6.31 i) we know that
Dh(x −x0)k =
 0
if h > k
k!
(k −h)!(x −x0)k−h
if h ≤k .
Therefore
DhT fn,x0(x) =
n
	
k=0
f (k)(x0)
k!
Dh(x −x0)k
=
n
	
k=h
f (k)(x0)
(k −h)! (x −x0)k−h .
Note also that
f (k)(x0) = f (h+k−h)(x0) =

f (h)(k−h)(x0) ,
in other words diﬀerentiating k −h times the derivative of order h produces the
kth derivative. In this way, putting ℓ= k −h gives
DhT fn,x0(x) =
n
	
k=h

f (h)(k−h)(x0)
(k −h)!
(x −x0)k−h
=
n−h
	
ℓ=0

f (h)(ℓ)(x0)
ℓ!
(x −x0)ℓ= T f (h)
n−h,x0(x) ,
which is (A.4.3). Formula (A.4.4) follows by recalling that the Taylor expansion
at a point x0 of a function coincides with the function itself at that point.
2

A.4.4
Taylor formulas
457
▶Proof of Theorem 7.1, p. 228
Theorem 7.1 (Taylor formula with Peano’s remainder) Let n ≥0 and
f be n times diﬀerentiable at x0. Then the Taylor formula holds
f(x) = T fn,x0(x) + o

(x −x0)n
,
x →x0,
where
T fn,x0(x) =
n
	
k=0
1
k!f (k)(x0)(x −x0)k
= f(x0) + f ′(x0)(x −x0) + . . . + 1
n!f (n)(x0)(x −x0)n.
Proof. We need to show that
L = lim
x→x0
f(x) −T fn,x0(x)
(x −x0)n
= 0 .
The limit is an indeterminate form of type
0
0; in order to apply de l’Hˆopital’s
Theorem 6.41 we are lead to consider this
lim
x→x0
f ′(x) −(T fn,x0)′(x)
n(x −x0)n−1
= lim
x→x0
f ′(x) −T f ′
n−1,x0(x)
n(x −x0)n−1
,
(in which Lemma A.4.2, with h = 1, was used); note that the other requirements
of 6.41 are fulﬁlled.
For n > 1 we are still in presence of an indeterminate form 0
0, so repeating
n −1 times the argument above brings us to the limit
lim
x→x0
f (n−1)(x) −T f (n−1)
1,x0
(x)
n!(x −x0)
= lim
x→x0
f (n−1)(x) −f (n−1)(x0) −f (n)(x0)(x −x0)
n!(x −x0)
= 1
n! lim
x→x0
f (n−1)(x) −f (n−1)(x0)
x −x0
−f (n)(x0)

= 0 ,
by deﬁnition of nth derivative at x0. This grants the green light to the use of de
l’Hˆopital’s Theorem, and L = 0.
2

458
A.4 Complements on diﬀerential calculus
▶Proof of Theorem 7.2, p. 228
Theorem 7.2 (Taylor formula with Lagrange’s remainder) Let n ≥0
and f diﬀerentiable n times at x0, with continuous nth derivative, be given;
suppose f is diﬀerentiable n + 1 times around x0, except possibly at x0. Then
the Taylor formula
f(x) = T fn,x0(x) +
1
(n + 1)!f (n+1)(¯x)(x −x0)n+1,
holds, for a suitable ¯x between x0 and x.
Proof. Let ϕ(x) = f(x) −T fn,x0(x) and ψ(x) = (x −x0)n+1. Using (A.4.4), for
h = 0, . . . , n we have
ϕ(h)(x0) = 0 ;
moreover, ψ(h)(x0) = 0 and ψ(h)(x) ̸= 0 for any x ̸= x0. Applying Theorem 6.25
to ϕ, ψ on the interval I0 between x0 and x, we know there is a point x1 ∈I0 such
that
ϕ(x)
ψ(x) = ϕ(x) −ϕ(x0)
ψ(x) −ψ(x0) = ϕ′(x1)
ψ′(x1) .
The same recipe used on the maps ϕ′(x), ψ′(x) on the interval I1 between x0, x1
produces a point x2 ∈I1 ⊂I0 satisfying
ϕ′(x1)
ψ′(x1) = ϕ′(x1) −ϕ′(x0)
ψ′(x1) −ψ′(x0) = ϕ′′(x2)
ψ′′(x2) .
Iterating the argument eventually gives a xn+1 ∈I0 such that
ϕ(x)
ψ(x) = · · · = ϕ(n+1)(xn+1)
ψ(n+1)(xn+1) .
But ϕ(n+1)(x) = f (n+1)(x) and ψ(n+1)(x) = (n + 1)!, putting ¯x = xn+1 in which
yields the assertion.
2
▶Proof of Theorem 9.44, p. 338
Theorem 9.44 (Taylor formula with integral remainder) Let n ≥0
be an arbitrary integer, f diﬀerentiable n + 1 times around a point x0, with
continuous derivative of order n + 1. Then
f(x) −T fn,x0(x) = 1
n!
& x
x0
f (n+1)(t)(x −t)n dt .

A.4.4
Taylor formulas
459
Proof. We shall use the induction principle (see Appendix A.1). When n = 0, the
formula reduces to the identity
f(x) −f(x0) =
& x
x0
f ′(t) dt ,
established in Corollary 9.42.
Supposing the statement true for a certain n, let us prove it for n+1. Integrating
by parts and using the hypothesis,
1
(n + 1)!
& x
x0
f (n+2)(t)(x −t)n+1 dt
=
1
(n + 1)!

f (n+1)(t)(x −t)n+1
x
x0 + (n + 1)
& x
x0
f (n+1)(t)(x −t)n dt

= −f (n+1)(x0)
(n + 1)! (x −x0)n+1 + 1
n!
& x
x0
f (n+1)(t)(x −t)n dt
= −f (n+1)(x0)
(n + 1)! (x −x0)n+1 + f(x) −T fn,x0(x)
= f(x) −T fn+1,x0(x) .
2
At last, we provide an example that illustrates how a more accurate piece of
information may be extracted from the integral form of the remainder, as opposed
to the Lagrange form.
Example A.4.3 Consider the MacLaurin expansion of the exponential function
f(x) = ex with remainder of order 1, both in Lagrange’s form and in integral form.
Assuming x > 0, if we use the former form we have for a suitable ¯x ∈(0, x)
ex = 1 + x + 1
2e¯xx2 ,
(A.4.5)
whereas with the latter form we obtain
ex = 1 + x +
& x
0
et(x −t) dt .
(A.4.6)
Since the exponential function is strictly increasing, it holds e¯x < ex, hence, we
deduce from (A.4.5) that the error due to approximating ex by the polynomial
1 + x satisﬁes
0 < ex −(1 + x) < 1
2x2ex .
(A.4.7)
On the other hand, if we look at the integral remainder, we easily check that the
function g(t) = et(x−t) under the integral sign admits for x ≥1 a strict maximum
at t = x −1, where it takes the value ex−1. Hence,

460
A.4 Complements on diﬀerential calculus
0 <
& x
0
et(x −t) dt < ex−1
& x
0
dt = ex−1x .
Therefore, we deduce from (A.4.6) that
0 < ex −(1 + x) < 1
exex ,
x ≥1 .
(A.4.8)
Since it is trivially seen that 1
exex < 1
2x2ex for x ≥1, we conclude that (A.4.8)
provides a more accurate estimate of the approximation error than (A.4.7) does.
For instance, for x = 1 the error is
e1 −(1 + 1) = e −2 = 0.71828... ;
inequality (A.4.7) gives the upper bound 0.71828... <
1
2e = 1.35914..., whereas
(A.4.8) gives the bound 0.71828... < 1
ee = 1, which is sharper.
2

A.5
Complements on integral calculus
We begin this appendix by checking the convergence of the two sequences that
enter the deﬁnition of the Cauchy integral. We then consider the Riemann integral;
we justify the integrability of relevant classes of functions, and we establish several
properties of integrable functions and of the deﬁnite integral. We conclude by
proving a few results concerning improper integrals.
A.5.1 The Cauchy integral
▶Proof of Theorem 9.20, p. 320
Theorem 9.20 The sequences {sn} and {Sn} are convergent, and their limits
coincide.
Proof. We claim that for any p ≥1
sn ≤spn ,
Spn ≤Sn .
In fact, subdividing the interval Ik in p subintervals Iki (1 ≤i ≤p) of equal width
Δx/p, and letting
mki = min
x∈Iki f(x) ,
it follows mk ≤mki for each i, hence
mkΔx ≤
p
	
i=1
mki
Δx
p .
Summing over k we obtain sn ≤spn. The second inequality is similar.
Let now sn, Sm be arbitrary sums. Since
sn ≤snm ≤Snm ≤Sm
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9_A5,
© Springer International Publishing Switzerland 2015

462
A.5 Complements on integral calculus
any lower sum is less or equal than any upper sum. Deﬁne
s = sup
n sn
and
S = inf
n Sn .
We know s ≤Sm holds for any m, so s ≤S. We wish to prove that s = S, and
that such number is indeed the required limit. By the Heine-Cantor’s Theorem
A.3.7 the map f is uniformly continuous: given ε > 0, there is δ > 0 such that if
x′, x′′ ∈[a, b] then
|x′ −x′′| < δ
implies
|f(x′) −f(x′′)| < ε .
Let nε be the integer such that b−a
nε < δ. Take any n ≥nε; in each subinterval Ik
of [a, b] of width Δx = b−a
n
there exist points ξk and ηk such that
f(ξk) = mk = min
x∈Ik f(x)
and
f(ηk) = Mk = max
x∈Ik f(x) .
As |ηk −ξk| ≤b−a
n
≤b−a
nε < δ, it follows
Mk −mk = f(ηk) −f(ξk) < ε .
Therefore
Sn −sn =
n
	
k=1
MkΔx −
n
	
k=1
mkΔx
=
n
	
k=1

Mk −mk

Δx < ε
n
	
k=1
Δx = ε(b −a) .
In other words, given ε > 0 there is an nε > 0 so that for all n ≥nε we have
0 ≤Sn −sn < ε(b −a). This implies
S −s ≤Sn −sn < ε(b −a) .
Letting ε tend to 0, S = s follows. In addition,
S −sn ≤Sn −sn < ε
if
n ≥nε ,
that is,
lim
n→∞sn = S .
The same arguments may be adapted to show lim
n→∞Sn = S .
2
A.5.2 The Riemann integral
Throughout the section we shall repeatedly use the following result.

A.5.2
The Riemann integral
463
Lemma A.5.1 Let f be a bounded function on I = [a, b]. Then f is integrable
if and only if for any ε > 0 there exist two maps hε ∈S+
f and gε ∈S−
f such
that
&
I
hε −
&
I
gε < ε .
Proof. According to the deﬁnition, f is integrable if and only if
&
I
f = inf
&
I
h : h ∈S+
f

= sup
&
I
g : g ∈S−
f

.
Let then f be integrable. Given ε > 0, by deﬁnition of lower and upper bound one
can ﬁnd a map hε ∈S+
f satisfying
&
I
hε −
&
I
f < ε/2 and, similarly, a function
gε ∈S−
f such that
&
I
f −
&
I
gε < ε/2. Hence
&
I
hε −
&
I
gε =
&
I
hε −
&
I
f +
&
I
f −
&
I
gε < ε .
Vice versa, using Deﬁnition 9.26 together with Property 9.27, one has
&
I
gε ≤
&
I
f ≤
&
I
f ≤
&
I
hε ,
hence
&
I
f −
&
I
f ≤
&
I
hε −
&
I
gε < ε .
But ε is completely arbitrary, so
&
I
f =
&
I
f. In other words, f is integrable on [a, b].
2
▶Proof of Theorem 9.31, p. 327
Theorem 9.31 Among the class of integrable maps on [a, b] are
a) continuous maps on [a, b];
b) piecewise-continuous maps on [a, b];
c) continuous maps on (a, b) which are bounded on [a, b];
d) monotone functions on [a, b].
Proof.
a) The Theorem of Weierstrass tells that f is bounded over [a, b], and by Heine-
Cantor’s Theorem A.3.7 f is uniformly continuous on [a, b]. Thus for any given

464
A.5 Complements on integral calculus
ε > 0, there exists a δ > 0 such that if x′, x′′ ∈[a, b] with |x′ −x′′| < δ then
|f(x′) −f(x′′)| < ε. Let us consider a partition {x0, x1, . . . , xn} of [a, b] such
that each interval [xk−1, xk] has width < δ (k = 1, . . . , n). We apply Weierstrass’
Theorem 4.31 to each one of them: for every k = 1, . . . , n, there are points ξk, ηk ∈
[xk−1, xk] such that
f(ξk) = mk =
min
x∈[xk−1,xk] f(x)
and
f(ηk) = Mk =
max
x∈[xk−1,xk] f(x) .
Since |ηk −ξk| < δ,
Mk −mk = f(ηk) −f(ξk) < ε .
Let hε ∈S+
f and gε ∈S−
f be deﬁned by
hε(x) =
 Mk
if x ∈(xk−1, xk], k = 1, . . . , n,
f(a)
if x = a,
gε(x) =
 mk
if x ∈(xk−1, xk], k = 1, . . . , n,
f(a)
if x = a.
For any x ∈[a, b] we have hε(x) −gε(x) < ε, hence
&
I
hε −
&
I
gε =
&
I
(hε −gε) <
&
I
ε = (b −a)ε .
Given that ε is arbitrary, Lemma A.5.1 yields the result.
b) Call {x1, x2, . . . , xn−1} the discontinuity points of f inside [a, b], with xk−1 < xk,
and set x0 = a and xn = b. For k = 1, . . . , n, consider the continuous maps on
[xk−1, xk] deﬁned as follows:
fk(x) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
f(x)
if x ∈(xk−1, xk),
lim
x→x+
k−1
f(x)
if x = xk−1,
lim
x→x−
k
f(x)
if x = xk .
Mimicking the proof of part a), given ε > 0 there exist hε,k ∈S+
fk, gε,k ∈S−
fk such
that
hε,k(x) −gε,k(x) < ε ,
∀x ∈[xk−1, xk] .
Deﬁne hε ∈S+
f and gε ∈S−
f by
hε(x) =
 hε,k(x)
if x ∈(xk−1, xk], k = 1, . . . , n,
f(a)
if x = a,
gε(x) =
 gε,k(x)
if x ∈(xk−1, xk], k = 1, . . . , n,
f(a)
if x = a.
For any x ∈[a, b] then, hε(x) −gε(x) < ε; as before, Lemma A.5.1 ends the proof.

A.5.2
The Riemann integral
465
c) Fix ε > 0 so that Iε = [a + ε, b −ε] ⊂[a, b]. The map f is continuous on Iε and
we may ﬁnd – as in part a) – two step functions deﬁned on Iε, say ϕε and ψε, such
that
ϕε(x) ≤f(x) ≤ψε(x)
and
ψε(x) −ϕε(x) < ε ,
∀x ∈Iε .
Name M = sup
x∈I
f(x) and m = inf
x∈I f(x) the supremum and inﬁmum of f. Consider
the step functions hε ∈S+
f , gε ∈S−
f given by
hε(x) =
 ψε(x)
if x ∈Iε,
M
if x /∈Iε,
gε(x) =
 ϕε(x)
if x ∈Iε,
m
if x /∈Iε.
Theorem 9.33 i) implies
&
I
hε −
&
I
gε =
&
[a,a+ε]
(hε −gε) +
&
Iε
(hε −gε) +
&
[b−ε,b]
(hε −gε)
= 2(M −m)ε +
&
Iε
(hε −gε)
< 2(M −m)ε + (b −a −2ε)ε <

2(M −m) + b −a

ε .
Now Lemma A.5.1 allows to conclude.
d) Assume f is increasing. (In case f is decreasing, the proof is analogous.) Note
ﬁrst that f is bounded on [a, b], for f(a) ≤f(x) ≤f(b), ∀x ∈[a, b].
Given ε > 0, let n be a natural number such that n > b −a
n
; split the interval
into n parts, each b −a
n
< ε wide, and let {x0, x1, . . . , xn} indicate the partition
points. Introduce the step maps hn ∈S+
f , gn ∈S−
f by
hn(x) =
 f(xk)
if x ∈(xk−1, xk], k = 1, . . . , n,
f(a)
if x = a,
gn(x) =
 f(xk−1)
if x ∈(xk−1, xk], k = 1, . . . , n,
f(a)
if x = a.
Then
&
I
hn −
&
I
gn =
n
	
k=1
f(xk)(xk −xk−1) −
n
	
k=1
f(xk−1)(xk −xk−1)
= b −a
n
n
	
k=1

f(xk) −f(xk−1)

= b −a
n

f(b) −f(a)

= ε

f(b) −f(a)

.
Once again, the result follows from Lemma A.5.1.
2

466
A.5 Complements on integral calculus
▶Proof of Proposition 9.32, p. 328
Proposition 9.32 If f is integrable on [a, b], then
i) f is integrable on any subinterval [c, d] ⊂[a, b];
ii) |f| is integrable on [a, b].
Proof.
i) If f is a step function the statement is immediate. More generally, let f be
integrable over [a, b]; for ε > 0, Lemma A.5.1 yields maps hε ∈S+
f , gε ∈S−
f such
that
& b
a
hε −
& b
a
gε =
& b
a

hε −gε

< ε .
As
& d
c

hε −gε

≤
& b
a

hε −gε

< ε ,
the result is a consequence of Lemma A.5.1 applied to the function f restricted
to [c, d].
ii) Recall |f| = f+ + f−, where f+ and f−denote the positive and negative parts
of f respectively. Thus it is enough to show that f+ and f−are integrable, for
then we can use Theorem 9.33 ii).
Let us prove f+ is integrable. Given ε > 0, by Lemma A.5.1 there exist hε ∈S+
f
and gε ∈S−
f such that
' b
a hε −
' b
a gε < ε. Let {x0, x1, . . . , xn} be a partition of
I = [a, b] adapted to both maps hε, gε. Consider the positive parts hε,+, gε,+ of
the step functions. Having ﬁxed an interval Ik = [xk−1, xk], we may examine the
three possible occurrencies 0 ≤gε ≤hε, gε ≤0 ≤hε or gε ≤hε ≤0. It is easy to
check
gε,+ ≤f+ ≤hε,+
and
&
Ik
hε,+ −
&
Ik
gε,+ ≤
&
Ik
hε −
&
Ik
gε < ε .
Consequently, hε,+ ∈S+
f+, gε,+ ∈S−
f+, and
&
I
hε,+ −
&
I
gε,+ =
n
	
k=1
 &
Ik
hε,+ −
&
Ik
gε,+

≤
n
	
k=1
 &
Ik
hε −
&
Ik
gε

< ε .
Lemma A.5.1 yields then integrability for f+.
A similar proof would tell that f−is integrable as well.
2

A.5.2
The Riemann integral
467
▶Proof of Theorem 9.33, p. 329
Theorem 9.33 Let f and g be integrable on a bounded interval I of the real
line.
i) (Additivity with respect to the domain of integration) For any
a, b, c ∈I,
& b
a
f(x) dx =
& c
a
f(x) dx +
& b
c
f(x) dx.
ii) (Linearity) For any a, b ∈I and α, β ∈R,
& b
a

αf(x) + βg(x)

dx = α
& b
a
f(x) dx + β
& b
a
g(x) dx.
iii) (Positivity) Let a, b ∈I, with a < b. If f ≥0 on [a, b] then
& b
a
f(x) dx ≥0.
If f is additionally continuous, equality holds if and only if f is the zero
map.
iv) (Monotonicity) Let a, b ∈I, a < b. If f ≤g in [a, b], then
& b
a
f(x) dx ≤
& b
a
g(x) dx.
v) (Upper and lower bounds) Let a, b ∈I, a < b. Then

& b
a
f(x) dx
 ≤
& b
a
|f(x)| dx.
Proof. We shall directly prove statements i) -v) for generic integrable maps, for
the case of step functions is fairly straightforward.
i) We shall suppose a < c < b, for the other instances descend from this and (9.18).
By Proposition 9.32 i) f is integrable on the intervals [a, b], [a, c], [c, b]. Given ε > 0
moreover, let gε ∈S−
f , hε ∈S+
f be such that
& b
a
hε −
& b
a
gε < ε
and
& b
a
gε ≤
& b
a
f ≤
& b
a
hε .
The property holds for step functions, so
& b
a
gε =
& c
a
gε +
& b
c
gε ≤
& c
a
f +
& b
c
f ≤
& c
a
hε +
& b
c
hε =
& b
a
hε

468
A.5 Complements on integral calculus
and hence

& b
a
f −
& c
a
f −
& b
c
f
 ≤
& b
a
hε −
& b
a
gε < ε .
The claim follows because ε is arbitrary.
ii) We split the proof in two, and prove that
a)
& b
a
αf(x) dx = α
& b
a
f(x) dx
b)
& b
a

f(x) + g(x)

dx =
& b
a
f(x) dx +
& b
a
g(x) dx .
We start from a), and suppose a < b for simplicity. When α = 0 the result is clear,
so let α > 0. If g ∈S−
f , h ∈S+
f then αg ∈S−
αf and αh ∈S+
αf; thus
α
& b
a
g(x) dx =
& b
a
αg(x) dx ≤
& b
a
αf(x) dx
≤
& b
a
αf(x) dx ≤
& b
a
αh(x) dx = α
& b
a
h(x) dx .
From α
& b
a
g(x) dx ≤
& b
a
αf(x) dx, taking the upper bound of the integrals
' b
a g
as g varies in S−
f , and using the integrability of f on [a, b], we obtain
α
& b
a
f(x) dx = α
& b
a
f(x) dx ≤
& b
a
αf(x) dx ;
similarly from
& b
a
αf(x) dx ≤α
& b
a
h(x) dx we get
& b
a
αf(x) dx ≤α
& b
a
f(x) dx = α
& b
a
f(x) dx .
In conclusion,
α
& b
a
f(x) dx ≤
& b
a
αf(x) dx ≤
& b
a
αf(x) dx ≤α
& b
a
f(x) dx
hence α
& b
a
f(x) dx =
& b
a
αf(x) dx.
When α < 0, the proof is the same because g ∈S−
f , h ∈S+
f satisfy αg ∈S+
αf and
αh ∈S−
αf.
Now part b). Take f1 ∈S−
f , f2 ∈S+
f , g1 ∈S−
g , g2 ∈S+
g ; then f1 + g1 ∈S−
f+g,
f2 + g2 ∈S+
f+g, and

A.5.2
The Riemann integral
469
& b
a
f1(x) dx +
& b
a
g1(x) dx =
& b
a

f1(x) + g1(x)

dx ≤
& b
a

f(x) + g(x)

dx
≤
& b
a

f(x) + g(x)

dx ≤
& b
a

f2(x) + g2(x)

dx
=
& b
a
f2(x) dx +
& b
a
g2(x) dx .
Fix g1, f2 and g2, and take the upper bound of the integrals
& b
a
f1(x) dx as f1 ∈S−
f
varies:
& b
a
f(x) dx +
& b
a
g1(x) dx ≤
& b
a

f(x) + g(x)

dx
≤
& b
a

f(x) + g(x)

dx ≤
& b
a
f2(x) dx +
& b
a
g2(x) dx ;
varying g1 in S−
g and taking the upper bound of the integrals
& b
a
g1(x) dx we ﬁnd
& b
a
f(x) dx +
& b
a
g(x) dx ≤
& b
a

f(x) + g(x)

dx
≤
& b
a

f(x) + g(x)

dx ≤
& b
a
f2(x) dx +
& b
a
g2(x) dx .
Now we may repeat the argument ﬁxing g2 and varying f2 ∈S+
f ﬁrst, then varying
g2 ∈S+
g , to obtain
& b
a
f(x) dx +
& b
a
g(x) dx ≤
& b
a

f(x) + g(x)

dx
≤
& b
a

f(x) + g(x)

dx ≤
& b
a
f(x) dx +
& b
a
g(x) dx .
iii) The zero map g belongs in S−
f (it is constant), hence
0 =
& b
a
g(x) dx ≤
& b
a
f(x) dx .
Suppose f continuous; clearly f(x) = 0 forces
& b
a
f(x) dx = 0. We shall prove
the opposite implication:
& b
a
f(x) dx = 0 implies f(x) = 0. If, by contradiction,
f(¯x) ̸= 0 for a certain ¯x ∈(a, b), Theorem A.2.2 would give a neighbourhood

470
A.5 Complements on integral calculus
Iδ(¯x) = (¯x −δ, ¯x + δ) ⊂[a, b] and a constant Kf > 0, for any x ∈Iδ(¯x). The step
function
g(x) =

Kf
if x ∈Iδ(¯x)
0
if x /∈Iδ(¯x)
would belong to S−
f , and
& b
a
f(x) dx ≥
& b
a
g(x) dx = δKf > 0 ,
a contradiction. Therefore f(x) = 0 for all x ∈(a, b), and by continuity f must
vanish also at the end-points a, b.
iv) This follows directly from iii), noting h(x) = g(x) −f(x) ≥0.
v) Proposition 9.32 ii) says that |f| is integrable over [a, b]. But f = f+ −f−
(f+ and f−are the positive and negative parts of f respectively), so the linearity
proven in part ii) yields
& b
a
f(x) dx =
& b
a
f+(x) dx −
& b
a
f−(x) dx .
Using the triangle inequality, property iii) (f+, f−≥0) and the relation |f| =
f+ + f−, we eventually have

& b
a
f(x) dx
 ≤

& b
a
f+(x) dx
 +

& b
a
f−(x) dx
 =
& b
a
f+(x) dx +
& b
a
f−(x) dx
=
& b
a

f+(x) + f−(x)

dx =
& b
a
|f(x)| dx .
2
A.5.3 Improper integrals
▶Check of property (10.3), p. 362
& +∞
1
sin x
x
dx
converges, but
& +∞
1

sin x
x
 dx
diverges.
Proof. We explain ﬁrst why
& +∞
1
sin x
x
dx converges. Let us integrate by parts
over each interval [1, a] with a > 1, by putting f(x) = 1
x and g′(x) = sin x; since
f ′(x) = −1
x2 , g(x) = −cos x, it follows
& a
1
sin x
x
dx = −cos x
x

a
1 −
& a
1
cos x
x2
dx ;

A.5.3
Improper integrals
471
the last integral is known to converge from Example 10.8. Thus the map sin x
x
has
a well-deﬁned improper integral over [1, +∞).
Now let us convince ourselves that sin x
x
is not absolutely integrable on [1, +∞).
Since | sin x| ≤1 for any x, we have

sin x
x
 ≥sin2 x
x
= 1
2
1 −cos 2x
x
.
We claim the integral
& +∞
1
1 −cos 2x
x
dx diverges, hence the Comparison test
(Theorem 10.5) forces
& +∞
1

sin x
x
 dx to diverge as well. In fact,
& +∞
1
1 −cos 2x
x
dx =
& +∞
1
1
x dx −
& +∞
1
cos 2x
x
dx .
While the ﬁrst integral on the right-hand side diverges, the second one converges,
as can be proved by the same procedure as above. Therefore
& +∞
1
1 −cos 2x
x
dt
diverges, and the function sin x
x
cannot be absolutely integrable.
2
▶Proof of Theorem 10.10, p. 363
Theorem 10.10 (Asymptotic comparison test) Suppose the function f ∈
Rloc([a, +∞)) is inﬁnitesimal of order α, for x →+∞, with respect to ϕ(x) =
1
x. Then
i) if α > 1, f ∈R([a, +∞));
ii) if α ≤1,
& +∞
a
f(x) dx diverges.
Proof. Since f(x) ∼
1
xα for x →+∞, we may assume the map f has constant sign
for x suﬃciently large, for instance when x > A > 0. Without loss of generality we
may also take f strictly positive, for otherwise we could just change sign. Moreover,
for x →+∞,
f(x) ∼1
xα
⇒
f(x) = O
 1
xα

and
1
xα = O

f(x)

;
otherwise said, there exist positive constants c1, c2 such that
c1
xα ≤f(x) ≤c2
xα ,
∀x > A .

472
A.5 Complements on integral calculus
In order to conclude, it suﬃces to use the Comparison test (Theorem 10.5) jointly
with Example 10.4.
2
▶Proof of Theorem 10.13, p. 364
Theorem 10.13 (Integral test) Let f be continuous, positive and decreasing
on [k0, +∞), for k0 ∈N. Then
∞
	
k=k0+1
f(k) ≤
& +∞
k0
f(x) dx ≤
∞
	
k=k0
f(k) .
Therefore the integral and the series share the same behaviour:
a)
& +∞
k0
f(x) dx converges
⇐⇒
∞
	
k=k0
f(k) converges;
b)
& +∞
k0
f(x) dx diverges
⇐⇒
∞
	
k=k0
f(k) diverges.
Proof. Since f decreases, for any k ≥k0 we have
f(k + 1) ≤f(x) ≤f(k) ,
∀x ∈[k, k + 1] ,
and as the integral is monotone,
f(k + 1) ≤
& k+1
k
f(x) dx ≤f(k) .
Then for all n ∈N with n > k0 we obtain
n+1
	
k=k0+1
f(k) ≤
& n
k0
f(x) dx ≤
n
	
k=k0
f(k)
(after re-indexing the ﬁrst series). Passing to the limit for n →+∞and recalling
f is positive and continuous, we conclude.
2

Tables and Formulas
Recurrent formulas
cos2 x + sin2 x = 1,
∀x ∈R
sin x = 0
se x = kπ,
∀k ∈Z ,
cos x = 0
se x = π
2 + kπ
sin x = 1
se x = π
2 + 2kπ,
cos x = 1
se x = 2kπ
sin x = −1
se x = −π
2 + 2kπ,
cos x = −1
se x = π + 2kπ
sin(α ± β) = sin α cos β ± cos α sin β
cos(α ± β) = cos α cos β ∓sin α sin β
sin 2x = 2 sin x cos x ,
cos 2x = 2 cos2 x −1
sin x −sin y = 2 sin x −y
2
cos x + y
2
cos x −cos y = −2 sin x −y
2
sin x + y
2
sin(x + π) = −sin x ,
cos(x + π) = −cos x
sin(x + π
2 ) = cos x ,
cos(x + π
2 ) = −sin x
ax+y = axay ,
ax−y = ax
ay ,
(ax)y = axy
loga(xy) = loga x + loga y ,
∀x, y > 0
loga
x
y = loga x −loga y,
∀x, y > 0
loga(xy) = y loga x,
∀x > 0 , ∀y ∈R
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9,
© Springer International Publishing Switzerland 2015

474
Tables and Formulas
Fundamental limits
lim
x→+∞xα = +∞,
lim
x→0+ xα = 0 ,
α > 0
lim
x→+∞xα = 0 ,
lim
x→0+ xα = +∞,
α < 0
lim
x→±∞
anxn + . . . + a1x + a0
bmxm + . . . + b1x + b0
= an
bm
lim
x→±∞xn−m
lim
x→+∞ax = +∞,
lim
x→−∞ax = 0 ,
a > 1
lim
x→+∞ax = 0 ,
lim
x→−∞ax = +∞,
a < 1
lim
x→+∞loga x = +∞,
lim
x→0+ loga x = −∞,
a > 1
lim
x→+∞loga x = −∞,
lim
x→0+ loga x = +∞,
a < 1
lim
x→±∞sin x ,
lim
x→±∞cos x ,
lim
x→±∞tan x
do not exist
lim
x→( π
2 +kπ)
± tan x = ∓∞, ∀k ∈Z ,
lim
x→±∞arctan x = ±π
2
lim
x→±1 arcsin x = ±π
2 = arcsin(±1)
lim
x→+1 arccosx = 0 = arccos1 ,
lim
x→−1 arccosx = π = arccos(−1)
lim
x→0
sin x
x
= 1 ,
lim
x→0
1 −cos x
x2
= 1
2
lim
x→±∞

1 + a
x
x
= ea ,
a ∈R ,
lim
x→0(1 + x)
1
x = e
lim
x→0
loga(1 + x)
x
=
1
log a , a > 0;
in particular,
lim
x→0
log(1 + x)
x
= 1
lim
x→0
ax −1
x
= log a ,
a > 0;
in particular,
lim
x→0
ex −1
x
= 1
lim
x→0
(1 + x)α −1
x
= α ,
α ∈R

Tables and Formulas
475
Derivatives of elementary functions
f(x)
f ′(x)
xα
αxα−1 ,
∀α ∈R
sin x
cos x
cos x
−sin x
tan x
1 + tan2 x =
1
cos2 x
arcsin x
1
√
1 −x2
arccosx
−
1
√
1 −x2
arctan x
1
1 + x2
ax
(log a) ax
loga |x|
1
(log a) x
sinh x
cosh x
cosh x
sinh x
Diﬀerentiation rules

αf(x) + βg(x)
′
= αf ′(x) + βg′(x)

f(x)g(x)
′
= f ′(x)g(x) + f(x)g′(x)
f(x)
g(x)
′
= f ′(x)g(x) −f(x)g′(x)

g(x)
2

g(f(x))
′
= g′(f(x))f ′(x)

476
Tables and Formulas
Maclaurin’s expansions
ex = 1 + x + x2
2 + . . . + xk
k! + . . . + xn
n! + o(xn)
log(1 + x) = x −x2
2 + . . . + (−1)n−1 xn
n + o(xn)
sin x = x −x3
3! + x5
5! −. . . + (−1)m
x2m+1
(2m + 1)! + o(x2m+2)
cos x = 1 −x2
2 + x4
4! −. . . + (−1)m x2m
(2m)! + o(x2m+1)
sinh x = x + x3
3! + x5
5! + . . . +
x2m+1
(2m + 1)! + o(x2m+2)
cosh x = 1 + x2
2 + x4
4! + . . . + x2m
(2m)! + o(x2m+1)
arcsin x = x + x3
6 + 3x5
40 + . . . +

−1
2
m

x2m+1
2m + 1 + o(x2m+2)
arctan x = x −x3
3 + x5
5 −. . . + (−1)m x2m+1
2m + 1 + o(x2m+2)
(1 + x)α = 1 + αx + α(α −1)
2
x2 + . . . +
α
n

xn + o(xn)
1
1 + x = 1 −x + x2 −. . . + (−1)nxn + o(xn)
√
1 + x = 1 + 1
2x −1
8x2 + 1
16x3 + o(x3)

Tables and Formulas
477
Integrals of elementary functions
f(x)
&
f(x) dx
xα
xα+1
α + 1 + c ,
α ̸= −1
1
x
log |x| + c
sin x
−cosx + c
cos x
sin x + c
ex
ex + c
sinh x
cosh x + c
cosh x
sinh x + c
1
1 + x2
arctanx + c
1
√
1 −x2
arcsinx + c
1
√
1 + x2
log(x +

x2 + 1) + c = sett sinh x + c
1
√
x2 −1
log(x +

x2 −1) + c = sett cosh x + c
Integration rules
& 
αf(x) + βg(x)

dx = α
&
f(x) dx + β
&
g(x) dx
&
f(x)g′(x) dx = f(x)g(x) −
&
f ′(x)g(x) dx
& ϕ′(x)
ϕ(x) dx = log |ϕ(x)| + c
&
f(ϕ(x))ϕ′(x) dx =
&
f(y) dy
where
y = ϕ(x)

Index
Absolute value, 13
Antiderivative, 302
Arc, 282
closed, 282
Jordan, 282
length, 377
simple, 282
Arccosine, 56, 114
Archimedean property, 16
Arcsine, 56, 114, 176, 336
Arctangent, 114, 176, 336
Argument, 275
Asymptote, 135
horizontal, 135
oblique, 135
vertical, 136
Binomial
coeﬃcient, 19, 234
expansion, 20, 428
Bisection method, 111
Cardinality, 2
Colatitude, 261
Combination, 20
Conjunction, 5
Connective, 5
Coordinates
cylindrical, 261
polar, 259
spherical, 261
Corner, 178
Cosine, 52, 101, 173, 176, 232
hyperbolic, 198, 237
Cotangent, 54
Curve, 281
congruent, 372
equivalent, 372
integral, 390
opposite, 372
piecewise regular, 284
plane, 281
regular, 284
simple, 282
De Morgan laws, 4
Degree, 50, 52
Derivative, 170, 190
backward, 178
forward, 178
left, 178
logarithmic, 176
of order k, 190
partial, 288, 290
right, 178
second, 190
Diﬀerence, 4
quotient, 169
symmetric, 4
Diﬀerential equation
autonomous, 390
homogeneous, 396, 399, 406
linear, 396, 406
ordinary, 389
solution, 389
with separable variables, 394
C. Canuto, A. Tabacco: Mathematical Analysis I, 2nd Ed.,
UNITEXT – La Matematica per il 3+2 84, DOI 10.1007/978-3-319-12772-9,
© Springer International Publishing Switzerland 2015

480
Index
Discontinuity
of ﬁrst kind, 84
of second kind, 84
removable, 78
Disjunction, 5
Domain, 31
Equation
characteristic, 407
Equivalence
logic, 6
Expansion
asymptotic, 243
Maclaurin, 229, 235
Taylor, 228
Exponential, 50, 173, 229
Factorial, 18
Form
algebraic, 272
Cartesian, 272
exponential, 276
indeterminate, 99, 107
normal, 390
polar, 275
trigonometric, 275
Formula, 5
addition, 54
contrapositive, 6
De Moivre, 277
duplication, 54
Euler, 276
ﬁnite increment, 186
Stirling, 141
subtraction, 54
Taylor, 228, 456, 457
Function, 31
absolute value, 33, 34
absolutely integrable, 362
arccosine, 56, 114
arcsine, 56, 114, 176, 336
arctangent, 114, 176, 336
asymptotic, 136
big o, 123
bijective, 40
bounded, 37, 95
bounded from above, 37
composite, 103, 175, 241
composition, 43
concave, 192
continuous, 76, 80, 287
continuous on the right, 83
convex, 192
cosine, 52, 101, 173, 176, 232
cotangent, 54
decreasing, 42
diﬀerentiable, 170, 190
equivalent, 124
even, 47, 177, 229
exponential, 50, 173, 229
hyperbolic, 198
hyperbolic cosine, 198, 237
hyperbolic sine, 198, 237
hyperbolic tangent, 199
increasing, 41
inﬁnite, 130
inﬁnite of bigger order, 131
inﬁnite of same order, 131
inﬁnite of smaller order, 131
inﬁnitesimal, 130, 244
injective, 38
integer part, 33, 34
integrable, 326
integral, 333
inverse, 38, 114, 175
cosine, 56
hyperbolic tangent, 200
hyperbolic cosine, 200
hyperbolic sine, 199
sine, 55
tangent, 56
invertible, 39
little o, 124
logarithm, 51, 114, 176, 231
mantissa, 34
monotone, 41, 84, 114, 188
negative part, 361
negligible, 124
odd, 47, 177, 229
of class C∞, 191
of class Ck, 191
of real variable, 32
of same order of magnitude, 124
of several variables, 286
one-to-one, 38, 114
onto, 38
periodic, 47
piecewise, 32

Index
481
piecewise-continuous, 319
polynomial, 50, 98, 100, 174, 315
positive part, 361
power, 48, 234
primitive, 302
rational, 50, 98, 100, 101, 312
real, 32
real-valued, 32
Sign, 33, 34
sine, 52, 79, 93, 106, 173, 232
step, 323
surjective, 38
tangent, 54, 175, 240
trigonometric, 51
uniformly continuous, 447
Gap, 84
Gradient, 288
Graph, 31
Image, 31, 36
of a curve, 281
Implication, 5
Inequality
Bernoulli, 139, 427
Cauchy-Schwarz, 266
triangle, 13
Inﬁmum
of a function, 37
of a set, 17
Inﬁnite, 203
of bigger order, 131
of same order, 131
of smaller order, 131
test function, 131
Inﬁnitesimal, 130, 203
of bigger order, 130
of same order, 130
of smaller order, 130
test function, 131
Inﬂection, 193, 247
ascending, 193
descending, 193
Integral
Cauchy, 320
deﬁnite, 319, 321, 323, 326
general, 391
improper, 358, 365, 369
indeﬁnite, 302, 303
line, 370, 378
lower, 325
mean value, 330
particular, 391
Riemann, 322
singular, 394
upper, 325
Integration
by parts, 307, 338
by substitution, 309, 317, 338
Intersection, 3, 7
Interval, 14
of monotonicity, 42, 188
Inverse
cosine, 56, 114
sine, 55, 114
tangent, 56, 114
Landau symbols, 123
Latitude, 261
Length
of a curve, 375, 376
of a vector, 263
Limit, 68, 70, 73, 76, 81
left, 82
right, 82
Logarithm, 51, 106, 114, 176, 231
natural, 72
Longitude, 261
Lower bound, 15
greatest, 17, 113
Map, 31
identity, 45
Maximum, 16, 37
absolute, 180
relative, 180
Minimum, 16, 37
Modulus, 274
Negation, 5
Neighbourhood, 65, 287
left, 82
right, 82
Norm
of a vector, 263
Number
complex, 272
integer, 9

482
Index
Napier, 72, 106, 173, 437
natural, 9
rational, 9
real, 10
Order, 244
of a diﬀerential equation, 389
of an inﬁnite function, 132
of an inﬁnitesimal function, 132
of magnitude, 203
Pair
ordered, 21
Part
imaginary, 272
negative, 361
positive, 361
principal, 133, 244
real, 272
Partition, 322
adapted, 323
Period, 10, 47
minimum, 48
Permutation, 19
Point
corner, 178
critical, 181, 245
cusp, 179
extremum, 180
inﬂection, 193, 247
interior, 15
jump, 84
Lagrange, 184
maximum, 180
minimum, 180
of discontinuity, 84
with vertical tangent, 179
Polynomial, 50, 98, 100, 174, 315
characteristic, 407
Taylor, 228
Pre-image, 36
Predicate, 2, 6
Primitive, 302
Principle of Induction, 427
Problem
boundary value, 393
Cauchy, 392
initial value, 392
Product
Cartesian, 21
dot, 266
scalar, 266
Prolongation, 78
Proof by contradiction, 6
Quantiﬁer
existential, 7
universal, 7
Radian, 52
Radius, 65
Range, 31, 36
Reﬁnement, 322
Region
under the curve, 319
Relation, 23
Remainder
integral, 338, 458
Lagrange, 227, 229, 458
of a series, 145
Peano, 227, 228, 457
Restriction, 40
Sequence, 32, 66, 104, 137
convergent, 68
divergent, 70
geometric, 138
indeterminate, 71
monotone, 71
of partial sums, 142
subsequence, 441
Series, 141
absolutely convergent, 152
alternating, 151
conditionally converging, 153
converging, 142
diverging, 142
general term, 142
geometric, 146
harmonic, 148, 152, 364
indeterminate, 142
Mengoli, 144
positive-term, 146
telescopic, 145
Set, 1
ambient, 1
bounded, 15

Index
483
bounded from above, 15
bounded from below, 15
complement, 3, 7
empty, 2
power, 2
Sine, 52, 79, 93, 106, 173, 232
hyperbolic, 198, 237
Subsequence, 441
Subset, 1, 7
Sum of a series, 142
Supremum
of a function, 37
of a set, 17
Tangent, 54, 171, 175, 240
Test
absolute convergence, 153, 361
asymptotic comparison, 148, 363, 367,
471
comparison, 147, 360, 367
integral, 364, 472
Leibniz, 151
ratio, 139, 149
root, 150
Theorem
Bolzano-Weierstrass, 442
Cauchy, 185
comparison, 92, 95, 137
de l’Hˆopital, 200, 452
existence of zeroes, 109, 429
Fermat, 181
Fundamental of integral calculus, 333
Heine-Cantor, 448
intermediate value, 112
Lagrange, 184
local boundedness, 431
Mean Value, 184
Mean Value of integral calculus, 331
Rolle, 183
substitution, 102, 138
uniqueness of the limit, 89
Weierstrass, 114, 443
Translation, 45
Union, 3, 7
Unit circle, 51
Upper bound, 15
least, 17, 113
Value
maximum, 37
principal, 276
Variable
dependent, 36, 169
independent, 36, 169
Vector, 262
at a point, 270
direction, 263
ﬁeld, 378
lenght, 263
orientation, 263
orthogonal, 266
perpendicular, 266
position, 262
space, 264
tangent, 284
unit, 265
Venn diagrams, 2
Zero, 108

Collana Unitext – La Matematica per il 3+2
Series Editors:
A. Quarteroni (Editor-in-Chief)
L. Ambrosio
P. Biscari
C. Ciliberto
M. Ledoux
W.J. Runggaldier
Editor at Springer:
F. Bonadei
francesca.bonadei@springer.com
As of 2004, the books published in the series have been given a volume num-
ber. Titles in grey indicate editions out of print.
As of 2011, the series also publishes books in English.
A. Bernasconi, B. Codenotti
Introduzione alla complessità computazionale
1998, X+260 pp, ISBN 88-470-0020-3
A. Bernasconi, B. Codenotti, G. Resta
Metodi matematici in complessità computazionale
1999, X+364 pp, ISBN 88-470-0060-2
E. Salinelli, F. Tomarelli
Modelli dinamici discreti
2002, XII+354 pp, ISBN 88-470-0187-0
S. Bosch
Algebra
2003, VIII+380 pp, ISBN 88-470-0221-4
S. Graffi, M. Degli Esposti
Fisica matematica discreta
2003, X+248 pp, ISBN 88-470-0212-5
S. Margarita, E. Salinelli
MultiMath – Matematica Multimediale per l’Università
2004, XX+270 pp, ISBN 88-470-0228-1

A. Quarteroni, R. Sacco, F.Saleri
Matematica numerica (2a Ed.)
2000, XIV+448 pp, ISBN 88-470-0077-7
2002, 2004 ristampa riveduta e corretta
(1a edizione 1998, ISBN 88-470-0010-6)
13. A. Quarteroni, F. Saleri
Introduzione al Calcolo Scientiﬁco (2a Ed.)
2004, X+262 pp, ISBN 88-470-0256-7
(1a edizione 2002, ISBN 88-470-0149-8)
14. S. Salsa
Equazioni a derivate parziali - Metodi, modelli e applicazioni
2004, XII+426 pp, ISBN 88-470-0259-1
15. G. Riccardi
Calcolo differenziale ed integrale
2004, XII+314 pp, ISBN 88-470-0285-0
16. M. Impedovo
Matematica generale con il calcolatore
2005, X+526 pp, ISBN 88-470-0258-3
17. L. Formaggia, F. Saleri, A. Veneziani
Applicazioni ed esercizi di modellistica numerica
per problemi differenziali
2005, VIII+396 pp, ISBN 88-470-0257-5
18. S. Salsa, G. Verzini
Equazioni a derivate parziali – Complementi ed esercizi
2005, VIII+406 pp, ISBN 88-470-0260-5
2007, ristampa con modiﬁche
19. C. Canuto, A. Tabacco
Analisi Matematica I (2a Ed.)
2005, XII+448 pp, ISBN 88-470-0337-7
(1a edizione, 2003, XII+376 pp, ISBN 88-470-0220-6)
20. F. Biagini, M. Campanino
Elementi di Probabilità e Statistica
2006, XII+236 pp, ISBN 88-470-0330-X

21. S. Leonesi, C. Toffalori
Numeri e Crittograﬁa
2006, VIII+178 pp, ISBN 88-470-0331-8
22. A. Quarteroni, F. Saleri
Introduzione al Calcolo Scientiﬁco (3a Ed.)
2006, X+306 pp, ISBN 88-470-0480-2
23. S. Leonesi, C. Toffalori
Un invito all’Algebra
2006, XVII+432 pp, ISBN 88-470-0313-X
24. W.M. Baldoni, C. Ciliberto, G.M. Piacentini Cattaneo
Aritmetica, Crittograﬁa e Codici
2006, XVI+518 pp, ISBN 88-470-0455-1
25. A. Quarteroni
Modellistica numerica per problemi differenziali (3a Ed.)
2006, XIV+452 pp, ISBN 88-470-0493-4
(1a edizione 2000, ISBN 88-470-0108-0)
(2a edizione 2003, ISBN 88-470-0203-6)
26. M. Abate, F. Tovena
Curve e superﬁci
2006, XIV+394 pp, ISBN 88-470-0535-3
27. L. Giuzzi
Codici correttori
2006, XVI+402 pp, ISBN 88-470-0539-6
28. L. Robbiano
Algebra lineare
2007, XVI+210 pp, ISBN 88-470-0446-2
29. E. Rosazza Gianin, C. Sgarra
Esercizi di ﬁnanza matematica
2007, X+184 pp, ISBN 978-88-470-0610-2
30. A. Machì
Gruppi – Una introduzione a idee e metodi della Teoria dei Gruppi
2007, XII+350 pp, ISBN 978-88-470-0622-5
2010, ristampa con modiﬁche

31 Y. Biollay, A. Chaabouni, J. Stubbe
Matematica si parte!
A cura di A. Quarteroni
2007, XII+196 pp, ISBN 978-88-470-0675-1
32. M. Manetti
Topologia
2008, XII+298 pp, ISBN 978-88-470-0756-7
33. A. Pascucci
Calcolo stocastico per la ﬁnanza
2008, XVI+518 pp, ISBN 978-88-470-0600-3
34. A. Quarteroni, R. Sacco, F. Saleri
Matematica numerica (3a Ed.)
2008, XVI+510 pp, ISBN 978-88-470-0782-6
35. P. Cannarsa, T. D’Aprile
Introduzione alla teoria della misura e all’analisi funzionale
2008, XII+268 pp, ISBN 978-88-470-0701-7
36. A. Quarteroni, F. Saleri
Calcolo scientiﬁco (4a Ed.)
2008, XIV+358 pp, ISBN 978-88-470-0837-3
37. C. Canuto, A. Tabacco
Analisi Matematica I (3a Ed.)
2008, XIV+452 pp, ISBN 978-88-470-0871-3
38. S. Gabelli
Teoria delle Equazioni e Teoria di Galois
2008, XVI+410 pp, ISBN 978-88-470-0618-8
39. A. Quarteroni
Modellistica numerica per problemi differenziali (4a Ed.)
2008, XVI+560 pp, ISBN 978-88-470-0841-0
40. C. Canuto, A. Tabacco
Analisi Matematica II
2008, XVI+536 pp, ISBN 978-88-470-0873-1
2010, ristampa con modiﬁche
41. E. Salinelli, F. Tomarelli
Modelli Dinamici Discreti (2a Ed.)
2009, XIV+382 pp, ISBN 978-88-470-1075-8

42. S. Salsa, F.M.G. Vegni, A. Zaretti, P. Zunino
Invito alle equazioni a derivate parziali
2009, XIV+440 pp, ISBN 978-88-470-1179-3
43. S. Dulli, S. Furini, E. Peron
Data mining
2009, XIV+178 pp, ISBN 978-88-470-1162-5
44. A. Pascucci, W.J. Runggaldier
Finanza Matematica
2009, X+264 pp, ISBN 978-88-470-1441-1
45. S. Salsa
Equazioni a derivate parziali – Metodi, modelli e applicazioni (2a Ed.)
2010, XVI+614 pp, ISBN 978-88-470-1645-3
46. C. D’Angelo, A. Quarteroni
Matematica Numerica – Esercizi, Laboratori e Progetti
2010, VIII+374 pp, ISBN 978-88-470-1639-2
47. V. Moretti
Teoria Spettrale e Meccanica Quantistica – Operatori in spazi di Hilbert
2010, XVI+704 pp, ISBN 978-88-470-1610-1
48. C. Parenti, A. Parmeggiani
Algebra lineare ed equazioni differenziali ordinarie
2010, VIII+208 pp, ISBN 978-88-470-1787-0
49. B. Korte, J. Vygen
Ottimizzazione Combinatoria. Teoria e Algoritmi
2010, XVI+662 pp, ISBN 978-88-470-1522-7
50. D. Mundici
Logica: Metodo Breve
2011, XII+126 pp, ISBN 978-88-470-1883-9
51. E. Fortuna, R. Frigerio, R. Pardini
Geometria proiettiva. Problemi risolti e richiami di teoria
2011, VIII+274 pp, ISBN 978-88-470-1746-7
52. C. Presilla
Elementi di Analisi Complessa. Funzioni di una variabile
2011, XII+324 pp, ISBN 978-88-470-1829-7

53. L. Grippo, M. Sciandrone
Metodi di ottimizzazione non vincolata
2011, XIV+614 pp, ISBN 978-88-470-1793-1
54. M. Abate, F. Tovena
Geometria Differenziale
2011, XIV+466 pp, ISBN 978-88-470-1919-5
55. M. Abate, F. Tovena
Curves and Surfaces
2011, XIV+390 pp, ISBN 978-88-470-1940-9
56. A. Ambrosetti
Appunti sulle equazioni differenziali ordinarie
2011, X+114 pp, ISBN 978-88-470-2393-2
57. L. Formaggia, F. Saleri, A. Veneziani
Solving Numerical PDEs: Problems, Applications, Exercises
2011, X+434 pp, ISBN 978-88-470-2411-3
58. A. Machì
Groups. An Introduction to Ideas and Methods of the Theory of Groups
2011, XIV+372 pp, ISBN 978-88-470-2420-5
59. A. Pascucci, W.J. Runggaldier
Financial Mathematics. Theory and Problems for Multi-period Models
2011, X+288 pp, ISBN 978-88-470-2537-0
60. D. Mundici
Logic: a Brief Course
2012, XII+124 pp, ISBN 978-88-470-2360-4
61. A. Machì
Algebra for Symbolic Computation
2012, VIII+174 pp, ISBN 978-88-470-2396-3
62. A. Quarteroni, F. Saleri, P. Gervasio
Calcolo Scientifico (5a ed.)
2012, XVIII+450 pp, ISBN 978-88-470-2744-2
63. A. Quarteroni
Modellistica Numerica per Problemi Differenziali (5a ed.)
2012, XVIII+628 pp, ISBN 978-88-470-2747-3

64. V. Moretti
Spectral Theory and Quantum Mechanics
With an Introduction to the Algebraic Formulation
2013, XVI+728 pp, ISBN 978-88-470-2834-0
65. S. Salsa, F.M.G. Vegni, A. Zaretti, P. Zunino
A Primer on PDEs. Models, Methods, Simulations
2013, XIV+482 pp, ISBN 978-88-470-2861-6
66. V.I. Arnold
Real Algebraic Geometry
2013, X+110 pp, ISBN 978-3-642–36242-2
67. F. Caravenna, P. Dai Pra
Probabilità. Un’introduzione attraverso modelli e applicazioni
2013, X+396 pp, ISBN 978-88-470-2594-3
68. A. de Luca, F. D’Alessandro
Teoria degli Automi Finiti
2013, XII+316 pp, ISBN 978-88-470-5473-8
69. P. Biscari, T. Ruggeri, G. Saccomandi, M. Vianello
Meccanica Razionale
2013, XII+352 pp, ISBN 978-88-470-5696-3
70. E. Rosazza Gianin, C. Sgarra
Mathematical Finance: Theory Review and Exercises. From Binomial
Model to Risk Measures
2013, X+278pp, ISBN 978-3-319-01356-5
71. E. Salinelli, F. Tomarelli
Modelli Dinamici Discreti (3a Ed.)
2014, XVI+394pp, ISBN 978-88-470-5503-2
72. C. Presilla
Elementi di Analisi Complessa. Funzioni di una variabile (2a Ed.)
2014, XII+360pp, ISBN 978-88-470-5500-1
73. S. Ahmad, A. Ambrosetti
A Textbook on Ordinary Differential Equations
2014, XIV+324pp, ISBN 978-3-319-02128-7

74. A. Bermúdez, D. Gómez, P. Salgado
Mathematical Models and Numerical Simulation in Electromagnetism
2014, XVIII+430pp, ISBN 978-3-319-02948-1
75. A. Quarteroni
Matematica Numerica. Esercizi, Laboratori e Progetti (2a Ed.)
2013, XVIII+406pp, ISBN 978-88-470-5540-7
76. E. Salinelli, F. Tomarelli
Discrete Dynamical Models
2014, XVI+386pp, ISBN 978-3-319-02290-1
77. A. Quarteroni, R. Sacco, F. Saleri, P. Gervasio
Matematica Numerica (4a Ed.)
2014, XVIII+532pp, ISBN 978-88-470-5643-5
78. M. Manetti
Topologia (2a Ed.)
2014, XII+334pp, ISBN 978-88-470-5661-9
79. M. Iannelli, A. Pugliese
An Introduction to Mathematical Population Dynamics. Along the trail
of Volterra and Lotka
2014, XIV+338pp, ISBN 978-3-319-03025-8
80. V. M. Abrusci, L. Tortora de Falco
Logica. Volume 1
2014, X+180pp, ISBN 978-88-470-5537-7
81. P. Biscari, T. Ruggeri, G. Saccomandi, M. Vianello
Meccanica Razionale (2a Ed.)
2014, XII+390pp, ISBN 978-88-470-5725-8
82. C. Canuto, A. Tabacco
Analisi Matematica I (4a Ed.)
2014, XIV+508pp, ISBN 978-88-470-5722-7
83. C. Canuto, A. Tabacco
Analisi Matematica II (2a Ed.)
2014, XII+576pp, ISBN 978-88-470-5728-9
84. C. Canuto, A. Tabacco
Mathematical Analysis I (2nd Ed.)
2015, XIV+484pp, ISBN 978-3-319-12771-2

85. C. Canuto, A. Tabacco
Mathematical Analysis II (2nd Ed.)
2015, XII+550pp, ISBN 978-3-319-12756-9
The online version of the books published in this series is available at
SpringerLink.
For further information, please visit the following link:
http://www.springer.com/series/5418

