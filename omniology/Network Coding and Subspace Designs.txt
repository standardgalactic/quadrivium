Signals and Communication Technology
Marcus Greferath
Mario Osvin Pavčević
Natalia Silberstein
María Ángeles Vázquez-Castro    Editors 
Network 
Coding and 
Subspace 
Designs

Signals and Communication Technology

More information about this series at http://www.springer.com/series/4748

Marcus Greferath
• Mario Osvin Pavčević
Natalia Silberstein
• María Ángeles Vázquez-Castro
Editors
Network Coding
and Subspace Designs
123

Editors
Marcus Greferath
Department of Mathematics
and Systems Analysis
Aalto University
Espoo
Finland
Mario Osvin Pavčević
Faculty of Electrical Engineering
and Computing, Department
of Applied Mathematics
University of Zagreb
Zagreb
Croatia
Natalia Silberstein
Yahoo Research
Haifa
Israel
María Ángeles Vázquez-Castro
Department of Telecommunications
and Systems Engineering
Universitat Autònoma de Barcelona
Cerdanyola del Vallès, Barcelona
Spain
ISSN 1860-4862
ISSN 1860-4870
(electronic)
Signals and Communication Technology
ISBN 978-3-319-70292-6
ISBN 978-3-319-70293-3
(eBook)
https://doi.org/10.1007/978-3-319-70293-3
Library of Congress Control Number: 2017958828
© Springer International Publishing AG 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made. The publisher remains neutral with regard to
jurisdictional claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

This article/publication is based upon work from COST Action IC1104 Random
Network Coding and Designs over GF(q), supported by COST (European
Cooperation in Science and Technology).
COST (European Cooperation in Science and Technology) is a funding agency
for research and innovation networks. Our Actions help connect research initiatives
across Europe and enable scientists to grow their ideas by sharing them with their
peers. This boosts their research, career and innovation.
http://www.cost.eu
Funded by the Horizon 2020 Framework Programme
of the European Union
v

Foreword
The beautiful and the elegant are often inspired by the seemingly mundane.
The chapters of this book follow from a line of work rooted in a practical engi-
neering problem: namely, the efﬁcient transmission of information in packet net-
works. Traditional approaches to the operation of packet networks treat information
ﬂow as commodity ﬂow, emphasizing the efﬁcient routing of the information along
network pathways, while avoiding or cleverly resolving contention for transmission
resources. Network coding, introduced in 2000 in the seminal paper of Ahlswede,
Cai, Li, and Yeung, challenges this conventional approach.
Network coding is based on a simple, yet far-reaching, idea: Rather than simply
routing packets, intermediate nodes are permitted to “mix” packets, transmitting
functions of the data that they receive. At the network boundary, received packets
are treated as evidence that must be gathered in sufﬁcient quantity so as to permit
decoding of the transmitted message.
A special case arises when the packets are interpreted as vectors of symbols
drawn from a ﬁnite ﬁeld, and the local mixing functions are chosen to be linear
transformations. From the 2003 paper of Li, Yeung, and Cai, it is known that such
linear network coding can achieve, when the underlying ﬁeld is large enough, the
so-called multicast capacity of a network, in which a single source wishes to
communicate the same message to a number of different terminals. An elegant
algebraic proof of this fact is given in the 2003 paper of Kötter and Médard via the
existence of a nonzero for a particular multivariate polynomial arising as a product
of matrix determinants. Indeed, as was demonstrated in the 2006 paper of Ho,
Médard, Kötter, Karger, Effros, Shi, and Leong, the multicast capacity of a network
is achieved, with high probability in a sufﬁciently large ﬁeld, by a completely
random choice of local mixing functions, obviating the need for a deliberate
network-topology-dependent code design.
Such random linear network coding yields an interesting new type of data
transmission model. In this model, to send a message the transmitter injects into the
network a collection of vectors which propagate through intermediate nodes in the
network, where they are randomly linearly combined, before arriving at any given
terminal. A terminal observes a number of such vectors, from which the transmitted
vii

message must be inferred. Since the linear transformation by the channel of the
transmitted vectors is not known in advance by the transmitter or any of the
receivers, such a model is sometimes referred to as a noncoherent transmission
model (in contrast with a so-called coherent model, in which knowledge of the
channel transformation is assumed).
To achieve information transmission in this noncoherent model of random linear
network coding, one might seek a communication invariant: some property of the
transmitted vectors that is preserved by the operation of the channel. As observed in
my 2008 paper with Ralf Kötter, an essential invariant—the key property preserved
by the random action of the channel—is the vector space spanned by the trans-
mitted vectors. No matter the action of the channel, we are guaranteed (in the
absence of errors) that each of the vectors observed at any terminal belongs to the
space spanned by the transmitted vectors. Thus, we are naturally led to consider
information transmission not via the choice of the transmitted vectors themselves,
but rather by the choice of the vector space that they span.
Such a transmission model also lends itself to a concise description of the effects
of the injection (by an adversary, say) of erroneous vectors into the network: The
erroneous vectors combine linearly with the transmitted ones, resulting in a vector
space observed at any receiver that may differ from the transmitted one. Whenever a
space V is transmitted (by injection into the network of a basis for V), and a space U
is observed at a terminal (by observation of a basis for U), the transmitted V is
related to the received U via the direct sum U ¼ HðVÞ  E, where the operator H
selects some subspace of V and E is a suitable error space intersecting trivially with
V. This so-called operator channel takes in a vector space from the transmitter and
produces some vector space at any given receiver, where the received space may
suffer from erasures (deletion of vectors from the transmitted space) or errors
(addition of vectors to the transmitted space).
A coding theory for the operator channel thus presents itself very naturally. The
collection PðWÞ of subspaces of the ambient packet space W plays the role of input
and output alphabets. One may deﬁne metrics on PðWÞ to measure the adversarial
effort required to convert a transmitted subspace V to a received one U; intuitively,
two spaces should be near each other if they intersect in a space of relatively large
dimension. One natural measure, which equally weights erasures and errors, is the
“subspace
metric”
dSðU; VÞ ¼ dimðU þ VÞ  dimðU \ WÞ.
Another
measure,
introduced in my 2008 paper with Silva and Kötter, is the “injection distance”
dIðU; VÞ ¼ maxfdimðUÞ; dimðVÞg  dimðU \ VÞ, which accounts for the possi-
bility that a single injection of a packet by an adversary may simultaneously case
the deletion of a dimension (an erasure) and the insertion of one (an error). These
two metrics coincide (except for a factor of two) in the case of constant dimension,
i.e., in the case when dimðUÞ ¼ dimðVÞ.
A subspace code for the operator channel is then a nonempty subset of PðWÞ,
i.e., a nonempty codebook of vector spaces, each a subspace of the ambient packet
space W. As in classical coding theory, the error- and erasure-correcting capability
of such a code is determined by the minimum distance between codewords, mea-
sured according to either the subspace distance or the injection distance. In the
viii
Foreword

important special case when the codewords all have the same dimension, a so-called
constant dimension code, an analog of a “constant weight code” in classical coding
theory, arises.
Many very interesting mathematical and engineering questions arise immedi-
ately; indeed, the chapters of this book aim to pose, study, and answer some
of them.
As in classical coding theory, one can ask for extremal codes. For example,
when the ambient packet space is Fn
q, which codes with codewords of constant
dimension k have maximum codebook cardinality M while preserving minimum
injection distance d? Similarly, for a ﬁxed codebook cardinality M, which codes of
constant dimension k have largest possible minimum injection distance d? One
might also be interested in extremal codes with codewords not all of the same
dimension, in which case the distinction between the subspace distance and the
injection distance becomes important. Many classical coding theory bounds on
extremal codes (e.g., the Hamming bound, the Singleton bound, the Gilbert bound)
have analogs in the new setting of subspace codes.
One may also ask for code constructions that admit efﬁcient decoding algorithms.
In the case where k j n, the analog of a classical extremal code, the repetition code,
is now an extremal object in ﬁnite geometry: a spread, a collection of pairwise
trivially intersecting k-dimensional subspaces of Fn
q whose union is Fn
q. In our 2008
papers, we showed that constant dimension codes of very large (“nearly” extremal)
cardinality can be constructed by a “lifting” of extremal codes—such as the maxi-
mum rank-distance Delsarte–Gabidulin codes—constructed for the rank metric.
These codes consist of the row spaces of matrices of the form I j M
½
, where I is the
identity matrix and M is a matrix codeword of a rank-metric code. Furthermore, we
showed that efﬁcient analogs of classical bounded distance decoding algorithms for
Reed–Solomon codes can be developed for such lifted Delsarte–Gabidulin codes.
Closely related to the combinatorial questions of code construction, a large part
of combinatorial mathematics and ﬁnite geometry deals with the existence,
construction, and properties of so-called combinatorial designs: collections of sub-
sets of
some ambient set exhibiting particular balance or symmetry properties.
A prototypical example is a Steiner system: a collection of k-element subsets (called
blocks) of S ¼ f1; . . .; ng with the property that each t-element subset of S is con-
tained in exactly one block. In this context of subspaces of a ﬁxed ambient space, one
can ask for q-analogs of such designs: namely, collections of subspaces of some
ambient space over Fq exhibiting particular balance or symmetry properties. For
example, the q-analog of a Steiner system would be a collection of k-dimensional
subspaces (blocks) of W ¼ Fn
q with the property that each t-dimensional subspace of
W is contained in exactly one block. That nontrivial (t  2) q-Steiner systems even
exist was not known until the 2013 paper of Braun, Etzion, Östergård, Vardy, and
Wassermann.
Written by leading experts in the ﬁeld, this book is an exploration of the
beautiful and elegant mathematical and engineering ideas that are related to network
coding. Here, you will ﬁnd new constructions of subspace codes of various types as
Foreword
ix

well as interesting generalizations. You will ﬁnd a deep discussion of rank-metric
codes and their properties, and you will ﬁnd connections made to ﬁnite geometry
and the theory of combinatorial designs, including a description of state-of-the-art
computational methods that can be used to search for designs. You will learn how
network coding is related to problems of broadcasting with side information at the
receivers, and how network coding can be applied in various wireless communi-
cation scenarios. Network coding ideas have also been used to determine bounds on
the parameters of codes that are useful in distributed storage systems. In this book,
you will ﬁnd a nice overview of the desirable features—such as “locality”—that
such codes should possess, along with new constructions for locally repairable
codes, and codes that permit so-called private information retrieval from a dis-
tributed storage system.
That such a diversity of new ideas should arise from the problem of efﬁcient
transmission of information in a packet network suggests that the original problem
may not have been so mundane after all.
Toronto, Canada
Frank R. Kschischang
Dept. of Electrical & Computer Engineering
University of Toronto
x
Foreword

Preface
When the four editors authoring this short editorial came up with the plan for this
book project, the initial idea was to present, disseminate, and advertise for a large
collection of results of COST Action IC1104. This Action, named Random Network
Coding and Designs over GF(q), as granted by the European Science Foundation in
2011, supported 4 years of a joint endeavor in European research within the newly
established ﬁeld of network coding and subspace designs. When we look at the
collection of material of this book today, we recognize that this book has developed
to be much more: We feel that what we present here has become more signiﬁcant
than the Action itself in that it describes the state-of-the-art in many aspects of
network coding and related topics.
Historically, the new concepts and inventive ideas of the seminal paper
R. Koetter and F. R. Kschischang: Coding for errors and erasures in random network
coding, IEEE Transactions on Information Theory 54 (2008), 3579–3591.
attracted attention of scholars from many areas of coding theory and related sci-
entiﬁc disciplines. They felt that this endeavor allowed them to make original
contributions to their established knowledge and techniques. Algebraic coding
theorists, combinatorialists, computers scientists, and engineers—they all saw their
opportunities to apply their skills and experience to an interdisciplinary work on the
introduced topics. So, it happened that the COST Action offered the perfect plat-
form at the right time for enabling fruitful discussions and exchange resulting in an
abundance of results by scientists all over the ﬁeld.
With growing enthusiasm, a competent union of more than hundred and twenty
scholars from 27 different countries joined actively the project illuminating different
directions, opening new questions, and connecting more and more branches of
science.
This book consists of 16 chapters by various protagonists of Action IC1104 and
a foreword by Frank Kschischang that brieﬂy provides conceptual framework,
initial information on the contents of the chapters, and points the coherence between
the
interdisciplinary
chapters.
Authors
are
invited
project
members
and
xi

internationally renowned experts who proved excellence in the ﬁeld, not only
within the 4 years of European support.
The chapters are as much self-contained as due and possible; they all start with
basics but come soon to the frontiers of knowledge without feeling obliged to
overdo in explaining too many details. Some of the chapters include respectable
new results that have not been published yet elsewhere, along with a list of open
problems and ideas for further research. This makes each of the chapters an
excellent start for Ph.D. students or newcomers to the ﬁeld who wish to commence
research on a particular topic connected with network coding or combinatorial
design theory. Since this research area is still growing and opening new problems
and topics, we sincerely hope that this book will provide ample and appropriate
guidance, when used by mathematicians as well as computer scientists and elec-
trical engineers.
We greatly appreciate the kindness of all the authors to cooperate and present the
chapters in such a useful review paper style. Our special thanks are addressed to the
European Science Foundation and its COST framework for the ﬁnancial support for
Action IC1104 and in particular for helping this book to come to existence.
Espoo, Finland
Marcus Greferath
Zagreb, Croatia
Mario Osvin Pavčević
Haifa, Israel
Natalia Silberstein
Cerdanyola del Vallès, Barcelona, Spain
María Ángeles Vázquez-Castro
xii
Preface

Contents
Part I
Subspace Codes and Rank Metric Codes
Codes Endowed with the Rank Metric . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Elisa Gorla and Alberto Ravagnani
Constructions of Constant Dimension Codes . . . . . . . . . . . . . . . . . . . . .
25
Anna-Lena Horlemann-Trautmann and Joachim Rosenthal
Constructions of Cyclic Subspace Codes
and Maximum Rank Distance Codes . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
Kamil Otal and Ferruh Özbudak
Generalizing Subspace Codes to Flag Codes
Using Group Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
Dirk Liebhold, Gabriele Nebe and María Ángeles Vázquez-Castro
Multi-shot Network Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
Diego Napp and Filipa Santana
Part II
Finite Geometries and Subspace Designs
Geometrical Aspects of Subspace Codes . . . . . . . . . . . . . . . . . . . . . . . . .
107
Antonio Cossidente, Francesco Pavese and Leo Storme
Partial Spreads and Vector Space Partitions . . . . . . . . . . . . . . . . . . . . .
131
Thomas Honold, Michael Kiermaier and Sascha Kurz
q-Analogs of Designs: Subspace Designs . . . . . . . . . . . . . . . . . . . . . . . . .
171
Michael Braun, Michael Kiermaier and Alfred Wassermann
Computational Methods in Subspace Designs. . . . . . . . . . . . . . . . . . . . .
213
Michael Braun, Michael Kiermaier and Alfred Wassermann
xiii

Part III
Application of Network Coding
Index Coding, Network Coding and Broadcast
with Side-Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
247
Eimear Byrne and Marco Calderini
Implementation of Network Coding in Wireless Systems . . . . . . . . . . . .
295
Semiha Tedik Basaran, Ali Reza Heidarpour, Selahattin Gokceli,
Gunes Karabulut Kurt, Murat Uysal and Ibrahim Altunbas
Opportunistic Network Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
319
Kemal Alic and Ales Svigelj
Coded Random Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
339
Čedomir Stefanović and Dejan Vukobratović
Part IV
Codes for Distributed Storage Systems
An Overview of Coding for Distributed Storage Systems . . . . . . . . . . . .
363
Shiqiu Liu and Frédérique Oggier
Matroid Theory and Storage Codes: Bounds and Constructions . . . . . .
385
Ragnar Freij-Hollanti, Camilla Hollanti and Thomas Westerbäck
Batch and PIR Codes and Their Connections
to Locally Repairable Codes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
427
Vitaly Skachek
xiv
Contents

Part I
Subspace Codes and Rank
Metric Codes

Codes Endowed with the Rank Metric
Elisa Gorla and Alberto Ravagnani
Abstract We review the main results of the theory of error-correcting codes with
the rank metric, introducing combinatorial techniques for their analysis. We study
their duality theory and MacWilliams identities, comparing in particular rank-metric
codes in vector and matrix representation. We then investigate the structure of MRD
codes and cardinality-optimal anticodes in the rank metric, describing how they relate
to each other.
Introduction
A q-ary rank-metric code is a set of matrices over Fq equipped with the rank distance,
which measures the rank of the difference of a pair of matrices. Rank-metric codes
were ﬁrst studied in [3] by Delsarte for combinatorial interest.
More recently, codes endowed with the rank metric have been re-discovered for
error correction in the context of linear network coding, and featured prominently in
the coding theory literature.
In linear network coding, a source attempts to transmit information packets to
multiple destinations via a network of intermediate nodes. The nodes compute and
forward in the direction of the sinks linear functions of the received packets, rather
than simply routing them. In [1, 9] it was shown that linear network coding achieves
the optimal multicast throughput over sufﬁciently large alphabets.
Rank-metric codes were proposed in [8, 18] for end-to-end error correction in
noisy and adversarial networks. In this context, as shown in [17], the correction
capability of a rank-metric code is measured by a fundamental parameter, called the
minimum rank distance of the code.
In this chapter, we survey the main results of the mathematical theory of rank-
metric codes, with emphasis on their combinatorial structure.
E. Gorla
Institut de Mathématiques, Université de Neuchâtel, Neuchâtel, Switzerland
e-mail: elisa.gorla@unine.ch
A. Ravagnani (B)
School of Mathematics and Statistics, University College Dublin,
Dublin, Ireland
e-mail: alberto.ravagnani@ucd.ie
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_1
3

4
E. Gorla and A. Ravagnani
In Sect.1 we introduce the most important parameters of a rank-metric code,
namely, the minimum distance, the weight distribution, and the distance distribution.
We then deﬁne the trace-dual of a linear rank-metric code, and compare the duality
theories of codes in matrix and vector representation. In particular, we show that the
former generalizes the latter.
Section2 is devoted to the duality theory of codes endowed with the rank met-
ric. We study how combinatorial properties of a linear code relate to combinatorial
properties of the dual code. In particular, we show that the weight distribution of a
linear code and the weight distribution of its dual code determine each other via a
MacWilliams-type transformation. We also show an application of the MacWilliams
identities for the rank metric to an enumerative combinatorics problem.
In Sect.3 we study codes that have the largest possible cardinality for their param-
eters. These are called Maximum Rank Distance codes (MRD in short) and have
very remarkable properties. We ﬁrst show the existence of linear MRD codes for all
choices of the parameters and of the ﬁeld size. Then we prove that the dual of a linear
MRD code is MRD. Finally, we show that the distance distribution of a (possibly
non-linear) rank-metric code is completely determined by its parameters.
Section4 is devoted to rank-metric anticodes, i.e., sets of matrices where the
distance between any two of them is bounded from above by a given integer. We
study how codes and anticodes relate to each other, deriving in particular an upper
bound for the cardinality of any anticode of given parameters. We conclude the
section showing that the dual of an optimal linear anticode is an optimal anticode.
1
Rank-Metric Codes
Throughout this chapter, q denotes a ﬁxed prime power, and Fq the ﬁnite ﬁeld with
q elements. Moreover, k and m denote positive integers with k ≤m without loss
of generality, and Fk×m
q
is the space of k × m matrices over Fq. Finally, for given
integers a, b ∈N we denote by
a
b

q
the q-ary binomial coefﬁcient of a and b, which counts the number of b-dimensional
subspaces of an a-dimensional space over Fq. See e.g. [19, Sect.1.7] for details.
Deﬁnition 1 The rank distance is the function d : Fk×m
q
× Fk×m
q
→N deﬁned by
d(M , N) = rk(M −N) for all M , N ∈Fk×m
q
.
It is easy to check that d is indeed a distance function on Fk×m
q
.
Deﬁnition 2 A (rank-metric) code over Fq is a non-empty subset C ⊆Fk×m
q
. When
|C | ≥2, the minimum distance of C is the positive integer
d(C ) = min{d(M , N) | M , N ∈C , M ̸= N}.

Codes Endowed with the Rank Metric
5
A code C is linear if it is an Fq-linear subspace of Fk×m
q
. In this case its dual code
is deﬁned as
C ⊥= {N ∈Fk×m
q
| Tr(MN t) = 0 for all M ∈C } ⊆Fk×m
q
,
where Tr(·) denotes the trace of a square k × k matrix.
The map (M , N) →Tr(MN t) ∈Fq is a scalar product on Fk×m
q
, i.e., it is sym-
metric, bilinear and non-degenerate. In particular, the dual of a linear code is a linear
code of dimension
dim(C ⊥) = km −dim(C ).
Other fundamental parameters of a rank-metric code are the following.
Deﬁnition 3 The weight distribution and the distance distribution of a code C
are the collections {Wi(C ) | i ∈N} and {Di(C ) | i ∈N} respectively, where
Wi(C ) = |{M ∈C |rk(M ) = i}|,
Di(C ) = 1/|C | · |{(M , N) ∈C 2 |d(M , N) = i}|
for all i ∈N.
If C is a linear code, then for all P ∈C there are precisely |C | pairs (M , N) ∈C 2
such that M −N = P. Therefore
Di(C ) = 1/|C | ·

P∈C
rk(P)=i
|{(M , N) ∈C 2 | M −N = P}| = Wi(C )
for all i ∈N. Moreover, if |C | ≥2 then d(C ) = min{rk(M ) | M ∈C , M ̸= 0}.
In [5], Gabidulin proposed independently a different notion of rank-metric code,
in which the codewords are vectors with entries from an extension ﬁeld Fqm rather
than matrices over Fq.
Deﬁnition 4 The rank of a vector v = (v1, ..., vk) ∈Fk
qm is the dimension of the
linear spaces generated over Fq by its entries, i.e., rkG(v) = dimFq⟨v1, ..., vk⟩. The
rank distance between vectors v, w ∈Fk
qm is dG(v, w) = rkG(v −w).
One can check that dG is a distance function on Fk
qm.
Deﬁnition 5 A vector rank-metric code over Fqm is a non-empty subset C ⊆Fk
qm.
When |C| ≥2, the minimum distance of C is the positive integer
dG(C) = min{dG(v, w) | v, w ∈C, v ̸= w}.
The code C is linear if it is an Fqm-linear subspace of Fk
qm. In this case the dual of C
is deﬁned as

6
E. Gorla and A. Ravagnani
C⊥=

w ∈Fk
qm |
k

i=1
viwi = 0 for all v ∈C

⊆Fk
qm.
The map (v, w) → viwi is an Fqm-scalar product on Fk
qm. Therefore for all linear
vector rank-metric codes C ⊆Fk
qm we have
dimFqm(C⊥) = k −dimFqm(C).
Deﬁnition 6 The weight distribution and the distance distribution of a vector
rank-metric code C are the integer vectors (Wi(C) | i ∈N) and (Di(C) | i ∈N)
respectively, where
Wi(C) = |{v ∈C | rkG(v) = i}|,
Di(C) = 1/|C| · |{(v, w) ∈C2 | dG(v, w) = i}|
for all i ∈N.
There exists a natural way to associate to a vector rank-metric code a code in
matrix representation with the same cardinality and metric properties.
Deﬁnition 7 Let Γ = {γ1, ..., γm} be a basis of Fqm over Fq. The matrix associated
to a vector v ∈Fk
qm with respect to Γ is the k × m matrix Γ (v) with entries in Fq
deﬁned by
vi =
m

j=1
Γ (v)ijγj
for all i = 1, ..., k.
The rank-metric code associated to a vector rank-metric code C ⊆Fk
qm with respect
to Γ is
Γ (C) = {Γ (v) | v ∈C} ⊆Fk×m
q
.
Notice that in the previous deﬁnition the i-th row of Γ (v) is the expansion of the
entry vi over the basis Γ .
The proof of the following result is standard and left to the reader.
Proposition 1 For every Fq-basis Γ of Fqm the map v →Γ (v) is an Fq-linear
bijective isometry (Fk
qm, dG) →(Fk×m
q
, d).
In particular, if C ⊆Fk
qm is a vector rank-metric code, then Γ (C) has the same
cardinality, rank distribution and distance distribution as C. Moreover, if |C| ≥2
then dG(C) = d(Γ (C)).
In the remainder of the section we compare the duality theories of matrix and vec-
tor rank-metric codes, showing that the former generalizes the latter. The following
results appear in [12].
Given an Fqm-linear vector rank-metric code C ⊆Fk
qm and a basis Γ of Fqm over
Fq, it is natural to ask whether the codes Γ (C⊥) and Γ (C)⊥coincide or not. The
answer is negative in general, as we show in the following example.

Codes Endowed with the Rank Metric
7
Example 1 Let q = 3, k = m = 2 and F32 = F3[η], where η is a root of the irre-
ducible primitive polynomial x2 + 2x + 2 ∈F3[x]. Let ξ = η2, so that ξ 2 + 1 = 0.
Set α = (ξ, 2), and let C ⊆F2
32 be the 1-dimensional vector rank-metric code gen-
erated by α over F32. Take Γ = {1, ξ} as basis of F32 over F3. One can check that
Γ (C) is generated over F3 by the two matrices
Γ (α) =
0 1
2 0

,
Γ (ξα) =
−1 0
0 2

.
Let β = (ξ, 1) ∈F2
32. We have α1β1 + α2β2 = 1 ̸= 0, and so β /∈C⊥. It follows
Γ (β) /∈Γ (C⊥). On the other hand,
Γ (β) =
0 1
1 0

,
and it is easy to see that Γ (β) is trace-orthogonal to both Γ (α) and Γ (ξα). Therefore
Γ (β) ∈Γ (C)⊥, hence Γ (C)⊥̸= Γ (C⊥).
Although the duality notions for matrix and vector rank-metric codes do not
coincide, there is a simple relation between them via orthogonal bases of ﬁnite
ﬁelds.
Let Trace : Fqm →Fq be the map deﬁned by Trace(α) = α + αq + · · · + αqm−1
for all α ∈Fqm. Bases Γ = {γ1, ..., γm} and Γ ′ = {γ ′
1, ..., γ ′
m} of Fqm over Fq are
called orthogonal if Trace(γ ′
i γj) = δij for all i, j ∈{1, ..., m}. It is well-known that
every basis Γ of Fqm over Fq has a unique orthogonal basis Γ ′ (see [10], p. 54).
Theorem 1 Let C ⊆Fk
qm be an Fqm-linear vector rank-metric code, and let Γ , Γ ′
be orthogonal bases of Fqm over Fq. We have
Γ ′(C⊥) = Γ (C)⊥.
In particular, C has the same weight distribution as Γ (C), and C⊥has the same
weight distribution as Γ (C)⊥.
Proof Write Γ = {γ1, ..., γm} and Γ ′ = {γ ′
1, ..., γ ′
m}. Let M ∈Γ ′(C⊥) and N ∈
Γ (C). There exist α ∈C⊥and β ∈C such that M = Γ ′(α) and N = Γ (β). By
Deﬁnition 7 we have
0 =
k

i=1
αiβi =
k

i=1
m

j=1
Mijγ ′
j
m

t=1
Nitγt =
k

i=1
m

j=1
m

t=1
MijNitγ ′
j γt.
(1)
Applying the function Trace : Fqm →Fq to both sides of Eq.(10) we obtain
0 = Trace
⎛
⎝
k

i=1
m

j=1
m

t=1
MijNitγ ′
j γt
⎞
⎠=
k

i=1
m

j=1
m

t=1
MijNitTrace(γ ′
j γt) = Tr(MNt).

8
E. Gorla and A. Ravagnani
Therefore Γ ′(C⊥) ⊆Γ (C)⊥. Proposition 1 implies that Γ ′(C⊥) and Γ (C)⊥have
the same dimension over Fq. Hence the two codes are equal. The second part of the
statement follows from Proposition 1.
Theorem 1 shows that the duality theory of Fq-linear rank-metric codes in matrix
representation can be regarded as a generalization of the duality theory of Fqm-linear
vector rank-metric codes. For this reason, in the sequel we only treat rank-metric
codes in matrix representation.
Rank-metriccodes canbeusedtoconstruct several types of subspacecodes, aclass
of error-correcting codes introduced in [8] in the context of random linear network
coding. See chapters “Constructions of Constant Dimension Codes”, “Constructions
of Cyclic Subspace Codes and Maximum Rank Distance Codes”, “Generalizing
subspace codes to ﬂag codes using group actions”, and “Partial spreads and vector
space partitions” for constructions of subspace codes, and chapter “Geometrical
aspects of subspace codes” for their structural properties.
2
MacWilliams Identities for the Rank Metric
This section is devoted to the duality theory of codes endowed with the rank metric.
We concentrate on linear rank-metric codes, and show that the weight distributions
of a code C and its dual code C ⊥determine each other via a MacWilliams-type
transformation. This result was established by Delsarte in [3, Theorem 3.3] using
the machinery of association schemes, and may be regarded as the rank-analogue
of a celebrated theorem by MacWilliams on the weight distribution of linear codes
endowed with the Hamming metric (see [11]). In this section we present a lattice-
theoretic proof inspired by [13, Theorem 27].
Notation 1 We denote by colsp(M ) ⊆Fk
q the Fq-space generated by the columns of
a matrix M ∈Fk×m
q
. Given a code C ⊆Fk×m
q
and an Fq-subspace U ⊆Fk
q, we let
C (U) = {M ∈C | colsp(M ) ⊆U} ⊆Fk×m
q
be the set of matrices in C whose columnspace is contained in U.
Note that for all M , N ∈Fk×m
q
we have colsp(M + N) ⊆colsp(M ) + colsp(N).
As a consequence, if U ⊆Fk
q is an Fq-linear subspace and C ⊆Fk×m
q
is a linear code,
then C (U) is a linear code as well.
We start with a series of preliminary results. In the sequel we denote by U ⊥the
orthogonal (or dual) of an Fq-vector space U ⊆Fk
q with respect to the standard inner
product of Fk
q. It will be clear from context if by “⊥” we denote the trace-dual in
Fk×m
q
or the standard dual in Fk
q.
Lemma 1 Let U ⊆Fk
q be a subspace. The following hold.
1. dim(Fk×m
q
(U)) = m · dim(U).

Codes Endowed with the Rank Metric
9
2. Fk×m
q
(U)⊥= Fk×m
q
(U ⊥).
Proof
1. Let s = dim(U) and V = {(x1, ..., xk) ∈Fk
q | xi = 0 for i > s} ⊆Fk
q.
There exists an Fq-isomorphism g : Fk
q →Fk
q that mapsU to V . Let G ∈Fk×k
q
be
the invertible matrix associated to g with respect to the canonical basis {e1, ..., ek}
of Fk
q, i.e.,
g(ej) =
k

i=1
Gijei
for all j = 1, ..., k.
The map M →GM is an Fq-isomorphism Fk×m
q
(U) →Fk×m
q
(V ). Property 1
of the lemma now directly follows from the deﬁnition of Fk×m
q
(V ).
2. Let N ∈Fk×m
q
(U ⊥) and M ∈Fk×m
q
(U). Using the deﬁnition of trace-product one
sees that Tr(MN t) = m
i=1⟨Mi, Ni⟩, where ⟨·, ·⟩is the standard inner product of
Fk
q, and Mi, Ni denote the i-th column of M and N (respectively). Each column of
N belongs to U ⊥, and each column of M belongs to U. Therefore Tr(MN t) = 0,
hence Fk×m
q
(U ⊥) ⊆Fk×m
q
(U)⊥. By property 1, the two spaces Fk×m
q
(U ⊥) and
Fk×m
q
(U)⊥have the same dimension over Fq. Therefore they are equal.
The following result is [12, Lemma 28].
Proposition 2 Let C ⊆Fk×m
q
be a linear code, and let U ⊆Fk
q be a subspace of
dimension u over Fq. Then
|C (U)| =
|C |
qm(k−u) |C ⊥(U ⊥)|.
Proof We have C (U)⊥= (C ∩Fk×m
q
(U))⊥= C ⊥+ Fk×m
q
(U)⊥= C ⊥+ Fk×m
q
(U⊥), where
the last equality follows from part 2 of Lemma 1. Therefore
|C (U)| · |C ⊥+ Fk×m
q
(U ⊥)| = qkm.
(2)
On the other hand, part 1 of Lemma 1 gives
dim(C ⊥+ Fk×m
q
(U ⊥)) = dim(C ⊥) + m · dim(U ⊥) −dim(C ⊥(U ⊥)).
As a consequence,
|C ⊥+ Fk×m
q
(U ⊥)| =
qkm · qm(k−u)
|C | · |C ⊥(U ⊥)|.
(3)
Combining Eqs.(2) and (3) one obtains the proposition.
We will also need the following preliminary lemma, which is an explicit version
of the Möbius inversion formula for the lattice of subspaces of Fk
q. We include a short
proof for completeness. See [19, Sects.3.7–3.10] for details.

10
E. Gorla and A. Ravagnani
Lemma 2 Let P(Fk
q) be the set of all Fq-subspaces of Fk
q, and let f : P(Fk
q) →Z
be any function. Deﬁne g : P(Fk
q) →Z by g(V ) = 
U⊆V f (U) for all V ⊆Fk
q.
Then for all i ∈{0, ..., k} and for any subspace V ∈P(Fk
q) with dim(V ) = i we
have
f (V ) =
i
u=0
(−1)i−uq(i−u
2 )

U⊆V
dim(U)=u
g(U).
Proof Fix an integer i ∈{0, ..., k} and a vector space V ∈P(Fk
q) with dim(V ) = i.
We inductively deﬁne a function μ : {U ∈P(Fk
q) | U ⊆V } →Z by μ(U) = 1 if
U = V , and μ(U) = −
U⊊S⊆V μ(S) if U ⊊V . By deﬁnition of g we have

U⊆V
μ(U)g(U) =

U⊆V
μ(U)

S⊆U
f (S) =

S⊆V
f (S)

S⊆U⊆V
μ(U) = f (V ),
where the last equality immediately follows from the deﬁnition of μ. Therefore it
sufﬁces to show that for all U ⊆V we have
μ(U) = (−1)i−uq(i−j
2 ),
(4)
where u = dim(U). We proceed by induction on i −u. If i = u then Eq.(4) is trivial.
Now assume i > u. By deﬁnition of μ and the induction hypothesis we have
μ(U) = −

U⊊S⊆V
μ(S) = −
i
s=u+1
(−1)i−sq(i−s
2 )
i −j
s −u

q
= −
i
s=u+1
(−1)i−sq(i−s
2 )
i −u
i −s

q
= −
i−u

s=0
(−1)sq(s
2)
i −u
s

q
+ (−1)i−uq(i−u
2 )
= (−1)i−uq(i−u
2 ),
where the last equality follows from the q-Binomial Theorem (see [19], p. 74).
We can now prove the main result of this section, ﬁrst established by Delsarte in
[3, Theorem 3.3]. A proof for the special case of Fqm-linear vector rank-metric codes
using different techniques can be found in [6].
Theorem 2 (MacWilliams identities for the rank metric) Let C ⊆Fk×m
q
be an linear
rank-metric code. For all i ∈{0, ..., k} we have

Codes Endowed with the Rank Metric
11
Wi(C ⊥) =
1
|C |
k

j=0
Wj(C )
k

u=0
(−1)i−uqmu+(i−u
2 )
k −u
k −i

q
k −j
u

q
.
Proof For all subspaces V ⊆Fk
q deﬁne
f (V ) = |{M ∈C ⊥| colsp(M ) = V }|,
g(V ) =

U⊆V
f (U) = |C ⊥(V )|.
By Lemma 2, for any i ∈{0, ..., k} and for any vector space V ⊆Fk
q of dimension i
we have
f (V ) =
i
u=0
(−1)i−uq(i−u
2 )

U⊆V
dim(U)=u
|C ⊥(U)|
=
i
u=0
(−1)i−uq(i−u
2 )

T⊆Fk
q
T⊇V ⊥
dim(T)=k−u
|C ⊥(T ⊥)|
=
1
|C |
i
u=0
(−1)i−uqmu+(i−u
2 )

T⊆Fk
q
T⊇V ⊥
dim(T)=k−u
|C (T)|,
where the last equality follows from Proposition 2. Now observe that
Wi(C ⊥) =

V ⊆Fk
q
dim(V )=i
f (V )
=
1
|C |
i
u=0
(−1)i−uqmu+(i−u
2 )

V ⊆Fk
q
dim(V )=i

T⊆Fk
q
T⊇V ⊥
dim(T)=k−u
|C (T)|
=
1
|C |
i
u=0
(−1)i−uqmu+(i−u
2 )

T⊆Fk
q
dim(T)=k−u

V ⊆Fk
q
V ⊇T ⊥
dim(V )=i
|C (T)|
=
1
|C |
i
u=0
(−1)i−uqmu+(i−u
2 )
k −u
i −u

q

T⊆Fk
q
dim(T)=k−u
|C (T)|.
(5)

12
E. Gorla and A. Ravagnani
On the other hand,

T⊆Fk
q
dim(T)=k−u
|C (T)| =

T⊆Fk
q
dim(T)=k−u
k−u

j=0

S⊆T
dim(S)=j
|{M ∈C | colsp(M ) = S}|
=
k−u

j=0

S⊆Fk
q
dim(S)=j

T⊆Fk
q
T⊇S
dim(T)=k−u
|{M ∈C | colsp(M ) = S}|
=
k−u

j=0
k −j
u

q
Wj(C ).
(6)
Combining Eqs.(5) and (6) one obtains the desired result.
Example 2 Let q = 2, k = 2, m = 3. Let C ⊆Fk×m
q
be the 2-dimensional linear
code generated over F5 ∼= Z/5Z by the matrices
1 0 2
0 2 4

,
2 3 0
1 4 0

.
We have W0(C ) = 1, W1(C ) = 8 and W2(C ) = 16. Using Theorem 2 one computes
W0(C ⊥) = 1, W1(C ⊥) = 65 and W2(C ) = 560. Observe that C ⊥has dimension
6 −2 = 4, and that 1 + 64 + 560 = 625 = 54, as expected.
We now present a different formulation of the MacWilliams identities for the rank
metric. The following result is [12, Theorem 31].
Theorem 3 Let C ⊆Fk×m
q
be a linear code. For all 0 ≤ν ≤k we have
k−ν

i=0
Wi(C )
k −i
ν

q
=
|C |
qmν
ν

j=0
Wj(C ⊥)
k −j
ν −j

q
.
Proof Proposition 2 gives

U⊆Fk
q
dim(U)=k−ν
|C (U)|
=
|C |
qmν

U⊆Fk
q
dim(U)=ν
|C ⊥(U)|.
(7)
Observe that

U⊆Fk
q
dim(U)=k−ν
|C (U)| = |{(U, M ) | U ⊆Fk
q, dim(U) = k −ν, M ∈C , colsp(M ) ⊆U}|

Codes Endowed with the Rank Metric
13
=

M ∈C
|{U ⊆Fk
q, dim(U) = k −ν, colsp(M ) ⊆U}|
=
k

i=0

M ∈C
rk(M )=i
|{U ⊆Fk
q, dim(U) = k −ν, colsp(M ) ⊆U}|
=
k

i=0

M ∈C
rk(M )=i

k −i
k −ν −i

q
=
k−ν

i=0
Wi(C )
k −i
ν

q
.
(8)
Using the same argument with C ⊥and k −ν one shows that

U⊆Fk
q
dim(U)=ν
|C ⊥(U)| =
k−ν

j=0
Wj(C ⊥)
k −j
ν −j

q
.
(9)
The result now follows combining Eqs.(7), (8) and (9).
Remark 1 The two formulations of the MacWilliams identities for the rank metric
given in Theorems 2 and 3 are equivalent. See [6, Corollary 1 and Proposition 3] and
[12, Theorem 61] for details.
The next theorem is [2, Theorem 27], and shows that the weight distribution of a
linear code is determined by its parameters, together with the number of codewords
of small weight. We state it without proof. An application of this result will be given
in Sect.3 (see Corollary 3).
Theorem 4 Let C ⊆Fk×m
q
be a linear code with 1 ≤dim(C ) ≤km −1, minimum
distance d = d(C ), and dual minimum distance d⊥= d(C ⊥). Let ε = 1 if C is
MRD, and ε = 0 otherwise. For all 1 ≤i ≤d⊥we have
Wk−d⊥+i(C ) = (−1)iq(i
2)
k−d

u=d⊥

u
d⊥−i

q
u −d⊥+ i −1
i −1

q
Wk−u(C )
+

k
d⊥−i

q
i−1−ε

u=0
(−1)uq(u
2)
k −d⊥+ i
u

q

qdim(C )−m(d⊥−i+u) −1

.
In particular, k, m, t, d, d⊥and Wd(C ), . . . , Wk−d⊥(C ) completely determine the
weight distribution of C .
We conclude this section showing how MacWilliams identities for the rank metric
can be employed to solve certain enumerative problems of matrices over ﬁnite ﬁelds.
The following result is [13, Corollary 52].
Corollary 1 Let I ⊆{(i, j) ∈{1, ..., k} × {1, ..., m} | i = j} be a set of diagonal
entries. For all 0 ≤r ≤k the number of k × m matrices M over Fq having rank r
and Mij = 0 for all (i, j) ∈I is

14
E. Gorla and A. Ravagnani
q−|I|
k

t=0
|I|
t

(q −1)t
k

u=0
(−1)r−u qmu+(r−u
2 )
k −u
k −r

q
k −t
u

q
.
Proof Deﬁne the linear code C = {M ∈Fk×m
q
| Mij = 0 for all (i, j) /∈I} ⊆Fk×m
q
.
Then dim(C ) = |I|, Wt(C ) = 0 for |I| < t ≤k, and
Wt(C ) =
|I|
t

(q −1)t
for 0 ≤t ≤|I|. Moreover, C ⊥= {M ∈Fk×m
q
| Mij = 0 for all (i, j) ∈I}. Therefore
the number of matrices M ∈Fk×m
q
having rank r and Mij = 0 for all (i, j) ∈I is
precisely Wr(C ⊥). The corollary now follows from Theorem 2.
3
MRD Codes
In this section we study rank-metric codes that have the largest possible cardinality
for their parameters. We start with a Singleton-type bound for the cardinality of a
rank-metric code of given minimum distance. A code is called MRD if it attains the
bound. We then show that for any admissible choice of the parameters there exists a
linear MRD code with those parameters.
In the second part of the section we study general structural properties of MRD
codes. We ﬁrst prove in Theorem 7 that the dual of a linear MRD code is MRD. Then
we show in Theorem 8 that the weight distribution of a possibly non-linear MRD
code C ⊆Fk×m
q
with 0 ∈C is determined by k, m and d(C ). As a corollary, we
prove that these three parameters completely determine the distance distribution of
any MRD code. Our proofs are inspired by the lattice-theory approach to the weight
functions of coding theory proposed in [13, 14].
Theorem 5 (Singleton-like bound) Let C ⊆Fk×m
q
be a rank-metric code with |C | ≥
2 and minimum distance d. Then |C | ≤qm(k−d+1).
Proof Let π : C →F(k−d+1)×m
q
denote the projection on the last k −d + 1 rows.
Since C has minimum distance d, the map π is injective. Therefore
|C | = |π(C )| ≤qm(k−d+1).
A code is MRD if its parameters attain the Singleton-like bound.
Deﬁnition 8 We say that C ⊆Fk×m
q
is an MRD code if |C | = 1, or |C | ≥2 and
|C | = qm(k−d+1), where d = d(C ).
We now prove that for any choice of q, k, m and d there exists a linear rank-metric
code C ⊆Fk×m
q
that attains the bound of Theorem 5. This result was ﬁrst shown by

Codes Endowed with the Rank Metric
15
Delsarte in [3], and rediscovered independently by Gabidulin in [5] and by Kötter
and Kschischang in [8] in the context of linear network coding.
Theorem 6 For all 1 ≤d ≤k there exists an Fqm-linear vector rank-metric code
C ⊆Fk
qm with dG(C) = d and dimFqm(C) = k −d + 1. In particular, there exists a
linear MRD code C ⊆Fk×m
q
with d(C ) = d.
We include an elegant proof for Theorem 6 from [8]. Recall that a linearized
polynomial p over Fqm is a polynomial of the form
p(x) = α0x + α1xq + α2xq2 + · · · + αsxqs,
αi ∈Fqm, i = 0, ..., s.
The degree of p, denoted by deg(p), is the largest integer i ≥0 such that αi ̸= 0. The
Fqm-vector space of linearized polynomials over Fqm of degree at most s is denoted
by Linq(m, s). It is easy to see that dimFqm(Linq(m, s)) = s + 1.
Remark 2 The roots of a linearized polynomial p over Fqm form an Fq-vector sub-
space of Fqm (see [10], Theorem 3.50), which we denote by V (p) ⊆Fqm in the sequel.
Clearly, for any non-zero linearized polynomial p we have dimFq V (p) ≤deg(p) by
the Fundamental Theorem of Algebra.
Proof (of Theorem 6) Let E = {β1, ..., βk} ⊆Fqm be a set of Fq-independent ele-
ments. These elements exist as k ≤m by assumption. Deﬁne the Fqm-linear map
evE : Linq(m, k −d) →Fk
qm,
evE(p) = (p(β1), ..., p(βk)) for p ∈Linq(m, k −d).
We claim that C = evE(Linq(m, k −d)) ⊆Fk
qm is a vector rank-metric code with the
desired properties.
Clearly, C is Fqm-linear. Now let p ∈Linq(m, k −d) be a non-zero linearized
polynomial, and let W ⊆Fqm denote the space generated over Fq by the eval-
uations p(β1), ..., p(βk). The polynomial p induces an Fq-linear evaluation map
p : ⟨β1, ..., βk⟩Fq →Fqm. The image of p is W, and therefore by the rank-nullity theo-
rem we have dimFq(W) = k −dimFq V (p). By Remark 2 we conclude dimFq(W) ≥
k −(k −d) = d. This shows that dG(C) ≥d. In particular, as d ≥1, the map evE
is injective, and the dimension of C is dimFqm(C) = k −d + 1. Combining Propo-
sition 1 and Theorem 5 we obtain dG(C) = d.
The second part of the theorem immediately follows from Proposition 1.
The MRD code construction in the proof of Theorem 6 was later generalized by
Sheekey in [15], introducing a new class of MRD codes. See chapter “Constructions
of Cyclic Subspace Codes and Maximum Rank Distance Codes” for other construc-
tions of MRD codes.
The reminder of the section is devoted to the structural properties of MRD codes.
We start with a preliminary result from [14, Chap. 7].

16
E. Gorla and A. Ravagnani
Lemma 3 Let C ⊆Fk×m
q
be an MRD code with |C | ≥2 and minimum distance d.
For all subspaces U ⊆Fk
q with u = dim(U) ≥d −1 we have
|C (U)| = qm(u−d+1).
Proof As in Lemma 1, deﬁne V = {(x1, ..., xk) ∈Fk
q | xi = 0 for i > u} ⊆Fk
q. Let
g : Fk
q →Fk
q be an Fq-isomorphism with f (U) = V . Denote by G ∈Fk×k
q
the matrix
associated to g with respect to the canonical basis of Fk
q. Deﬁne the rank-metric code
D = GC = {GM | M ∈C }. Clearly, D has the same dimension and minimum
distance as C . In particular, it is MRD. Observe moreover that C (U) = D(V ).
Consider the maps
D
π1
−→F(k−d+1)×m
q
π2
−→F(k−u)×m
q
,
where π1 is the projection on the last k −d + 1 coordinates, and π2 is the projection
on the last k −u coordinates. Since d(D) = d, π1 is injective. Since D is MRD, we
have logq(|D|) = m(k −d + 1). Therefore π1 is bijective. The map π2 is Fq-linear
and surjective. Therefore
|π−1
2 (0)| = |π−1
2 (M )| = qm(u−d+1) for all M ∈F(k−u)×m
q
.
Since π1 is bijective and π2 is surjective, the map π = π2 ◦π1 is surjective. Moreover,
|π−1(0)| = |π−1(M )| = qm(u−d+1) for all M ∈F(k−u)×m
q
.
The lemma now follows from the identity C (U) = D(V ) = π−1(0).
We can now show that the dual of a linear MRD code is MRD. The next funda-
mental result is [13, Theorem 5.5].
Theorem 7 Let C ⊆Fk×m
q
be a linear MRD code. Then C ⊥is MRD.
Proof The result is immediate if dim(C ) ∈{0, km}. Assume 1 ≤dim(C ) ≤km −1,
and let d = d(C ), d⊥= d(C ⊥). Applying Theorem 5 to C and C ⊥we obtain
dim(C ) ≤m(k −d + 1),
dim(C ⊥) ≤m(k −d⊥+ 1).
Therefore km = dim(C ) + dim(C ⊥) ≤2mk −m(d + d⊥) + 2m, i.e.,
d + d⊥≤k + 2.
(10)
Let U ⊆Fk
q be any Fq-subspace with dim(U) = k −d + 1. By Proposition 2 we
have
|C ⊥(U)| =
|C ⊥|
qm(d−1) |C (U ⊥)|.
(11)

Codes Endowed with the Rank Metric
17
Since dim(U ⊥) = d −1, by Lemma 3 we have |C (U ⊥)| = |C |/qm(k−d+1) = 1,
where the last equality follows from the fact that C is MRD. Therefore (11) becomes
|C ⊥(U)| =
|C ⊥|
qm(d−1) = qkm/qm(d−1)
qm(d−1)
= 1.
Since U is arbitrary with dim(U) = k −d + 1, this shows d⊥≥k −d + 2.
Using (10) we conclude d⊥= k −d + 2. The theorem now follows from
dim(C ⊥) = km −dim(C ) = km −m(k −d + 1) = m(k −d⊥+ 1).
The proof of Theorem 7 also shows the following useful characterization of linear
MRD codes in terms of their minimum distance and dual minimum distance.
Proposition 3 Let C ⊆Fk×m
q
be a linear code with 1 ≤dim(C ) ≤km −1. The
following are equivalent.
1. C is MRD,
2. C ⊥is MRD,
3. d(C ) + d(C ⊥) = k + 2.
In the remainder of the section we concentrate on the weight and distance dis-
tributions of (possibly non-linear) MRD codes. We start with a result on the weight
distribution of MRD codes containing the zero vector (see [14, Theorem 7.46]).
Theorem 8 Let C be an MRD code with |C | ≥2 and 0 ∈C . Let d = d(C ). Then
W0(C ) = 1, Wi(C ) = 0 for 1 ≤i ≤d −1, and
Wi(C ) =
d−1

u=0
(−1)i−uq(i−u
2 )
k
i

q
i
u

q
+
i
u=d
(−1)i−uq(i−u
2 )+m(u−d+1)
k
i

q
i
u

q
for d ≤i ≤k.
Proof Since 0 ∈C , we have W0(C ) = 1 and Wi(C ) = 0 for 1 ≤i ≤d −1. For all
subspaces V ⊆Fk
q deﬁne
f (V ) = |{M ∈C | colsp(M ) = V }|,
g(V ) =

U⊆V
f (U) = |C (V )|.
Fix 0 ≤i ≤k and a vector space V ⊆Fk
q of dimension i. By Lemma 2 we have
f (V ) =
i
u=0
(−1)i−uq(i−u
2 )

U⊆V
dim(U)=u
g(U).
Using Lemma 3 and the fact that C is MRD with 0 ∈C we obtain

18
E. Gorla and A. Ravagnani
g(U) =

1
if 0 ≤dim(U) ≤d −1,
qm(u−d+1) if d ≤dim(U) ≤k.
Therefore
f (V ) =
d−1

u=0
(−1)i−uq(i−u
2 )
i
u

q
+
i
u=d
(−1)i−uq(i−u
2 )+m(u−d+1)
i
u

q
.
The result now follows from the identity
Wi(C ) =

V ⊆Fk
q
dim(V )=i
f (V ).
Different formulas for the weight distribution of linear MRD codes were obtained
in [4] employing elementary methods.
Theorem 8 implies the following [3, Theorem 5.6], which states that the distance
distribution of any MRD code is determined by its parameters.
Corollary 2 Let C ⊆Fk×m
q
be an MRD code with |C | ≥2 and minimum distance
d. We have D0(C ) = 1, Di(C ) = 0 for 1 ≤i ≤d −1, and
Di(C ) =
d−1

u=0
(−1)i−uq(i−u
2 )
k
i

q
i
u

q
+
i
u=d
(−1)i−uq(i−u
2 )+m(u−d+1)
k
i

q
i
u

q
for d ≤i ≤k.
Proof Fix an i with d ≤i ≤k. For N ∈C deﬁne C −N = {M −N | M ∈C }. By
deﬁnition of distance distribution we have
|C | · Di(C ) = |{(M , N) ∈C 2 | rk(M −N) = i}| =

N∈C
Wi(C −N).
For all N ∈C the code C −N is MRD. Moreover, 0 ∈C −N. The result now easily
follows from Theorem 8.
Corollary 2 shows in particular that the weight distribution of a linear MRD
code is determined by k, m and d(C ). Recall from Proposition 3 that an MRD
code C ⊆Fk×m
q
is characterized by the property d(C ) + d(C ⊥) = k + 2. We now
prove that the weight distribution of a linear code C with d(C ) + d(C ⊥) = k + 1
is determined by k, m and dim(C ). The following result is [2, Corollary 28].
Corollary 3 Let C ⊆Fk×m
q
be a linear rank-metric code with 1 ≤dim(C ) ≤km −
1 and d(C ) + d(C ⊥) = k + 1. Then
dim(C ) ̸≡0
mod m
and
d(C ) = k −⌈dim(C )/m⌉+ 1.

Codes Endowed with the Rank Metric
19
Moreover, for all d ≤i ≤k we have
Wi(C ) =
k
i

q
i−d(C )

u=0
(−1)uq(u
2)
i
u

q

qdim(C )−m(k+u−i) −1

.
Proof Assume by contradiction that dim(C ) = αm for some α. Applying Theorem 5
to C and C ⊥we obtain
d(C ) ≤k −α + 1,
d(C ⊥) ≤α + 1.
(12)
By Proposition 3, the two inequalities in (12) are either both equalities, or both strict
inequalities. Since d(C ) + d(C ⊥) = k + 1 by assumption, they must be both strict
inequalities. Therefore
d(C ) ≤k −α,
d(C ⊥) ≤α,
hence d(C ) + d(C ⊥) ≤k, a contradiction. This shows that dim(C ) ̸≡0 mod m.
Now write dim(C ) = αm + β with 1 ≤β ≤m −1. Applying again Theorem 5
to C and C ⊥one ﬁnds
d(C ) ≤k −
αm + β
m

+ 1 = k −α,
d(C ⊥) ≤k −
km −αm −β
m

= α + 1.
Since d(C ) + d(C ⊥) = k + 1, we must have
d(C ) = k −
αm + β
m

+ 1 = k −
dim(C )
m

+ 1,
as claimed. The last part of the statement follows from Theorem 4.
4
Rank-Metric Anticodes
This section is devoted to rank-metric anticodes, i.e., rank-metric codes in which the
distance between any two matrices is bounded from above by a given integer δ.
In Theorem 9 we give a bound for the cardinality of a (possibly non-linear)
anticode, using a code-anticode-type bound. We also characterize optimal anticodes
in terms of MRD codes. Then we show that the dual of an optimal linear anticode is
an optimal linear anticode. The main results of this section appear in [12, 14].
Deﬁnition 9 Let 0 ≤δ ≤k be an integer. A (rank-metric) δ-anticode is a non-
empty subset A ⊆Fk×m
q
such that d(M , N) ≤δ for all M , N ∈A . We say that A
is linear if it is an Fq-linear subspace of Fk×m
q
.

20
E. Gorla and A. Ravagnani
Example 3 Any A ⊆Fk×m
q
with |A | = 1 is a 0-anticode. The ambient space Fk×m
q
is a k-anticode. The vector space of k × m matrices over Fq whose last k −δ rows
are zero is a linear δ-anticode of dimension mδ.
In the sequel we work with a ﬁxed integer 0 ≤δ ≤k. Moreover, for A , C ⊆Fk×m
q
we set A + C = {M + N | M ∈A , N ∈C }.
Theorem 9 Let A ⊆Fk×m
q
be a δ-anticode. Then |A | ≤qmδ. Moreover, if δ ≤k −
1 then the following are equivalent.
1. |A | = qmδ.
2. A + C = Fk×m
q
for some MRD code C with d(C ) = δ + 1.
3. A + C = Fk×m
q
for all MRD codes C with d(C ) = δ + 1.
Proof Let C ⊆Fk×m
q
be any MRD code with d(C ) = δ + 1. Such a code exists by
Theorem 6. For all M ∈A let [M ] = M + C = {M + N | N ∈C }. Then [M ] ∩
[M ′] = ∅for all M , M ′ ∈A with M ̸= M ′. Moreover, by deﬁnition of MRD code
we have |[M ]| = |C | = qm(k−δ) for all M ∈A , hence
|Fk×m
q
| ≥


M ∈A
[M ]
 =

M ∈A
|[M ]| = |A | · |C | = |A | · qm(k−δ).
Therefore |A | ≤qmδ, and equality holds if and only if
Fk×m
q
=

M ∈A
[M ] = A + C .
A similar argument shows that properties 1, 2 and 3 are equivalent.
Deﬁnition 10 We say that a δ-anticode A is (cardinality)-optimal if it attains the
bound of Theorem 9.
Remark 3 Example 3 shows the existence of optimal linear δ-anticodes for all
choices of δ.
In the remainder of the section we prove that the dual of an optimal linear δ-
anticode is an optimal (k −δ)-anticode. The result may be regarded as the analogue
of Theorem 7 in the context of rank-metric anticodes. We start with a preliminary
result on the weight distribution of MRD codes.
Lemma 4 Let C ⊆Fk×m
q
be an MRD code with 0 ∈C , |C | ≥2 and d(C ) = d.
Then Wd+ℓ(C ) > 0 for all 0 ≤ℓ≤k −d.
Proof By Theorem 8, we shall prove the lemma for a given MRD code C ⊆Fk×m
q
of our choice with |C | ≥2, minimum distance d, and 0 ∈C . We will ﬁrst produce
a convenient MRD code with the prescribed properties.

Codes Endowed with the Rank Metric
21
Let C ⊆Fk
qm be the vector rank-metric code constructed in the proof of Theorem 6,
with evaluation set E = {β1, ..., βk} and evaluation map evE. Let Γ be any basis of
Fqm over Fq. By Proposition 1, C = Γ (C) ⊆Fk×m
q
is a linear code with dim(C ) =
m(k −d + 1) and the same weight distribution as C. In particular, C is a non-zero
linear MRD code with minimum distance d.
Now we prove the lemma for the MRD code C constructed above. Fix ℓwith
0 ≤ℓ≤k −d. Deﬁne t = k −d −ℓ, and letU ⊆Fqm be the Fq-subspace generated
by {β1, ..., βt}. If t = 0 we set U to be the zero space. By [10], Theorem 3.52,
pU =

γ ∈U
(x −γ )
is a linearized polynomial over Fqm of degree t = k −d −ℓ≤k −d, i.e., by def-
inition, pU ∈Linq(n, k −d). Therefore by Proposition 1 it sufﬁces to prove that
evE(pU) = (pU(β1), ..., pU(βk)) has rank d + ℓ= k −t. Clearly, V (pU) = U. In
particular we have evE(pU) = (0, ..., 0, pU(βt+1), ..., pU(βk)). We will show that
pU(βt+1), ..., pU(βk) are linearly independent over Fq. Assume that there exist
at+1, ..., ak ∈Fq such that k
i=t+1 aipU(βi) = 0. Then we have pU
k
i=t+1 aiβi

=
0, i.e., k
i=t+1 aiβi ∈V (pU) = U. It follows that there exist a1, ..., at ∈Fq such
that t
i=1 aiβi = k
i=t+1 aiβi, i.e., t
i=1 aiβi −k
i=t+1 aiβi = 0. Since β1, ..., βk
are independent over Fq, we have ai = 0 for all i = 1, ..., k. In particular ai = 0
for i = t + 1, ..., k. Hence pU(βt+1), ..., pU(βk) are linearly independent over Fq, as
claimed.
The following proposition characterizes optimal linear anticodes in terms of their
intersection with linear MRD codes.
Proposition 4 Assume 0 ≤δ ≤k −1, and let A ⊆Fk×m
q
be a linear code with
dim(C ) = mδ. The following are equivalent.
1. A is an optimal δ-anticode.
2. A ∩C = {0} for all non-zero MRD linear codes C ⊆Fk×m
q
with d(C ) = δ + 1.
Proof By Theorem 9, it sufﬁces to show that if A ∩C = {0} for all non-zero MRD
linear codes C ⊆Fk×m
q
with d(C ) = δ + 1, then A is a δ-anticode.
By contradiction, assume that A is not a δ-anticode. Since A is linear, by def-
inition of δ-anticode there exists N ∈C with rk(N) ≥δ + 1. Let D be a non-zero
linear MRD code with d(D) = δ + 1 (see Theorem 6 for the existence of such a
code). By Lemma 4 there exists M ∈D with rk(M ) = rk(N). There exist invert-
ible matrices A and B of size k × k and m × m, resp., such that N = AMB. Deﬁne
C = ADB = {APB | P ∈D}. Then C ⊆Fk×m
q
is a non-zero linear MRD code with
d(C ) = δ + 1 and such that N ∈A ∩C . Since rk(N) ≥δ + 1 ≥1, N is not the
zero matrix. Therefore A ∩C ̸= {0}, a contradiction.
We conclude the section showing that the dual of an optimal linear anticode is an
optimal linear anticode.

22
E. Gorla and A. Ravagnani
Theorem 10 LetA ⊆Fk×m
q
beanoptimallinearδ-anticode.ThenA ⊥isanoptimal
linear (k −δ)-anticode.
Proof Let A ⊆Fk×m
q
be an optimal linear δ-anticode. If δ = k then the result is
trivial. From now on we assume 0 ≤δ ≤k −1. By Deﬁnition 10 we have dim(A ) =
mδ, hence dim(A ⊥) = m(k −δ). Therefore by Proposition 4 it sufﬁces to show
that A ⊥∩C = {0} for all non-zero linear MRD codes C ⊆Fk×m
q
with d(C ) =
k −δ + 1. Let C be such a code. Then
dim(C ) = m(k −(k −δ + 1) + 1) = mδ < mk.
Combining Theorem 7 and Proposition 3 one shows that C ⊥is a linear MRD code
with d(C ⊥) = k −(k −δ + 1) + 2 = δ + 1. By Proposition 4 we have A ∩C ⊥=
{0}. Since dim(A ) + dim(C ⊥) = mδ + m(k −(δ + 1) + 1) = mk, we have A ⊕
C ⊥= Fk×m
q
. Therefore {0} = (Fk×m
q
)⊥= (A ⊕C ⊥)⊥= A ⊥∩C . This shows the
theorem.
References
1. R. Ahlswede, N. Cai, S.-Y.R. Li, R.W. Yeung, Network information ﬂow. IEEE Trans. Inf.
Theory 46(4), 1204–1216 (2000)
2. J. De la Cruz, E. Gorla, H.H. López, A. Ravagnani, Rank distribution of Delsarte codes. Des.
Codes Cryptogr. (to appear)
3. P. Delsarte, Bilinear forms over a ﬁnite ﬁeld, with applications to coding theory. J. Comb.
Theory A 25(3), 226–241 (1978)
4. J.G. Dumas, R. Gow, G. McGuire, J. Sheekey, Subspaces of matrices with special rank prop-
erties. Linear Algebr. Appl. 433, 191–202 (2010)
5. E. Gabidulin, Theory of codes with maximum rank distance. Probl. Inf. Transm. 1(2), 1–12
(1985)
6. M. Gadouleau, Z. Yan, MacWilliams Identities for Codes with the Rank Metric. EURASIP J.
Wirel. Commun. Networ. (2008)
7. E. Gorla, A. Ravagnani, Subspace codes from Ferrers diagrams. J. Algebr. Appl. 16, 7 (2017)
8. R. Kötter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579–3591 (2008)
9. S.-Y.R. Li, R.W. Yeung, N. Cai, Linear network coding. IEEE Trans. Inf. Theory 49(2), 371–
381 (2003)
10. R. Lidl, H. Niederreiter, Finite Fields. Addison-Wesley Publishing Company (1983)
11. F.J. MacWilliams, A theorem on the distribution of weights in a systematic code. Bell Syst.
Tech. J. 42(1), 79–94 (1963)
12. A. Ravagnani, Rank-metric codes and their duality theory. Des. Codes Cryptogr. 80(1), 197–
216 (2016)
13. A.Ravagnani,Dualityofcodessupportedonregularlattices,withanapplicationtoenumerative
combinatorics. Submitted. Online preprint: https://arxiv.org/abs/1510.02383
14. A. Ravagnani, Properties and Constructions of Codes with the Rank and the Subspace Metric.
PhD thesis, Université de Neuchâtel, 2016
15. J. Sheekey, A new family of MRD codes. Adv. Math. Commun. 10, 3 (2016)
16. D. Silva, F.R. Kschishang, On metrics for error correction in network coding. IEEE Trans. Inf.
Theory 55(12), 5479–5490 (2009)

Codes Endowed with the Rank Metric
23
17. D. Silva, F.R. Kschischang, On metrics for error correction in network coding. IEEE Trans.
Inf. Theory 55(12), 5479–5490 (2009)
18. D. Silva, E.S. Rogers, F.R. Kschishang, R. Koetter, A Rank-Metric Approach to Error Control
in Random Network Coding. IEEE Trans. Inf. Theory 54(9), 3951–3967 (2008)
19. P. Stanley, Enumerative Combinatorics, vol. 1, Cambridge Stud. Adv. Math., vol. 49. Cam-
bridge University Press (2012)

Constructions of Constant Dimension Codes
Anna-Lena Horlemann-Trautmann and Joachim Rosenthal
Abstract Constant dimension codes are subsets of the ﬁnite Grassmann variety. The
subspace distance is a natural metric on the Grassmannian. It is desirable to have
constructions of codes with large cardinality and efﬁcient decoding algorithm for
all parameters. This article provides a survey on constructions of constant dimen-
sion codes with a prescribed minimum distance. The article starts with a review of
geometric properties of the Grassmann variety. We emphasize the classical Plücker
embedding which shows that the Grassmannian describing all k-dimensional sub-
spaces of a vector space can be naturally embedded in a projective space and hence
has the structure of a projective variety itself. On the construction side we ﬁrst con-
centrate on the construction of equidistant codes, which include spreads and partial
spreads. Then we review constructions based on matrix codes equipped with the
rank metric, in particular those matrices whose non-zero entries constitute certain
Ferrers diagrams. A large part of the survey is then concerned with orbit codes, i.e.,
subsets of the Grassmannian that can be expressed as the orbit under an action of
an algebraic group. Finally we review several constructions of constant dimension
codes starting with another constant dimension code having good parameters. We
conclude by giving references to other results related to constant dimension codes
and references to results on constructions of mixed dimension codes.
A.-L. Horlemann-Trautmann (B)
Faculty of Mathematics and Statistics, University of St. Gallen,
Bodanstrasse 6, 9000 St. Gallen, Switzerland
e-mail: anna-lena.horlemann@unisg.ch
J. Rosenthal
Mathematics Institute, University of Zurich, Winterthurerstr 190,
8057 Zurich, Switzerland
e-mail: rosen@math.uzh.ch
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_2
25

26
A.-L. Horlemann-Trautmann and J. Rosenthal
1
Introduction
In this article we give an overview of general constructions of constant dimension
codes, also called Grassmannian codes.
The framework for these codes and their usage for error-correction in random (or
non-coherent) network coding was ﬁrst given in [42]. There a subspace code was
deﬁned as a set of subspaces of Fn
q, Fq the ﬁnite ﬁeld of q elements, equipped with
the subspace distance, deﬁned as
dS(U, V) := dim(U + V) −dim(U ∩V)
(1)
for U, V ⊆Fn
q. For simplicity, one often restricts to constant dimension codes, where
all codewords have the same ﬁxed dimension k. Thus, a constant dimension code
is a subset C of the Grassmann variety Grass(k, Fn
q), which we will also denote by
Gq(k, n). Because of this constant dimension codes are also called Grassmannian
codes in the literature.
As in the classical literature on coding theory one deﬁnes the minimum distance
dist(C) of a code C as the minimal distance of two different code elements; in this case
the minimal subspace distance between two subspaces. The goal is once more the
construction of subspace codes with many code elements and prescribed minimum
distance. For the most part of this paper we will focus on constructions of constant
dimension codes; we give a short overview of mixed dimension code constructions
in the end.
The paper is structured in the following way. In Sect.2 we will collect some
background material on the geometry of the ﬁnite Grassmann variety, which serves
as the ambient space for constant dimension codes.
In Sect.3 we will cover spread codes, partial spread codes and equidistant codes.
Spread and partial spread codes are characterized by the property that they have the
maximal possible minimum distance 2k. Spread codes can be deﬁned if k divides
n; they have maximal cardinality among all codes with this minimum distance. A
generalization of (partial) spreads are equidistant codes, where any two codewords
must have the same ﬁxed distance, but not necessarily distance 2k.
One of the most successful ways to construct constant dimension codes with large
minimum distance is through a lifting process starting with some rank-metric code
of a given minimum distance. In Sect.4 we will survey some of these constructions.
The general linear group GLn acts naturally and transitively on the Grassmannian.
In Sect.5 we will give an overview on constant dimension codes which are also orbits
of some subgroup G of GLn acting on the Grassmannian. Like classical linear codes
the class of orbit codes have a rich mathematical structure.
As it is the case for the construction of classical linear codes inside Fn
q there are
also several known techniques to come up with constructions of constant dimension
codes from known constant dimension codes of smaller parameters. These techniques
are surveyed in Sect.6.

Constructions of Constant Dimension Codes
27
The focus of our survey is on algebraic constructions of constant dimension codes.
Constructions from combinatorial designs will be covered in chapter “q-analogs
of Designs: Subspace Designs” of this book. We also do not treat codes which were
derived by computer searches, but we give some references in this regard in the ﬁnal
remarks of this paper.
2
Remarks on the Geometry of the Finite Grassmann
Variety
Assume k < n are two integers. The set of all k-dimensional subspaces in Fn
q is called
the Grassmann variety or Grassmannian which we will denote by Gq(k, n). As the
name indicates the Grassmannian has a variety structure. To be more precise the set
Gq(k, n) can be embedded into a projective space using the Plücker embedding:
ϕ : Gq(k, n) −→P(ΛkFn
q) = P(n
k)−1
span(u1, . . . , uk) −→Fq(u1 ∧. . . ∧uk).
The image of the map ϕ is described by a set of quadratic equations called shufﬂe
relations. In order to make this more precise we will introduce a basis and coordinate
functions. For this assume {e1, . . . , en} is the canonical basis of Fn
q. Then N kFn
q has
as a canonical basis
{ei1 ∧. . . ∧eik | 1 ≤i1 < . . . < ik ≤n}.
If an element of the Grassmannian Gq(k, n) is described by a full rank k × n matrix
U then an elementary computation shows that the Plücker coordinates of a subspace
rs(U) inside the projective space P(n
k)−1 are exactly the k × k full size minors of the
k × n matrix U.
In the sequel denote by U[i1, . . . , ik] the submatrix of U given by the columns
i1, . . . , ik. The numbers xi1,...,ik := det(U[i1, . . . , ik]) are then called the Plücker
coordinates of the subspace rs(U). In terms of Plücker coordinates the Plücker
embedding is simply described through
rs(U) −→(x1,...,k : x1,...,k−1,k+1 : ... : xn−k+1,...,n).
A vector inside the projective space P(n
k)−1 is in the image of the Plücker map
ϕ exactly when the coordinates satisfy the shufﬂe relations as formulated in the
following proposition:
Proposition 1 ([40, 47]) Consider x := [x1,...,k : · · · : xn−k+1,...,n] ∈P(n
k)−1. Then
there exists a subspace U ∈Gq(k, n) such that ϕ(U) = x if and only if

28
A.-L. Horlemann-Trautmann and J. Rosenthal

j∈{i1,...,ik+1}
sgn(σ j)xi1,...,ik+1\ jx j,ik+2,...,i2k = 0
(2)
∀(i1, . . . , ik+1) ∈
 [n]
k+1

, (ik+2, . . . , i2k) ∈
 [n]
k−1

, where sgn(σ j) denotes the sign of
the permutation such that
σiℓ(i1, . . . , ik+1) = (iℓ, i1, . . . , iℓ−1, iℓ+1, . . . , ik+1).
Note that the shufﬂe relations (2) form a set of quadratic equations in terms of the
Plücker coordinates, and these equations describe exactly the image of the Plücker
map ϕ. It follows that the Grassmannian Gq(k, n) has the structure of a projective
variety.
If one considers all subspaces rs(U) whose ﬁrst Plücker coordinate x1,...,k is
nonzero one sees that this is a Zariski open set isomorphic to Fk(n−k)
q
, in particu-
lar the dimension of Gq(k, n) is equal to k(n −k).
The above dimension calculation is true over any base ﬁeld F. Over a ﬁnite ﬁeld
Gq(k, n) is a ﬁnite set and it is well-known that the cardinality of the Grassmannian
is given by the Gaussian binomial, i.e.,
|Gq(k, n)| =
n
j

q
=
k−1

i=0
qn −qi
qk −qi .
For the purpose of coding theory it is important to understand the set of all sub-
spaces V ∈Gq(k, n) whose subspace distance (1) to a given subspace U is at most
t. In other words we are interested in the geometric structure of the ball of radius t
around a subspace U:
Bt := {V ∈Gq(k, n) | dS(U, V) ≤t}.
The subsets Bt have classically been studied in the algebraic geometry literature and
as a matter of fact Bt is a special case of a so called Schubert variety.
In order to make this notion more precise one considers a so called ﬂag F, this is
a sequence of nested linear subspaces
F : {0} ⊂V1 ⊂V2 ⊂. . . ⊂Vn = Fn
q,
where one requires that dim V j = j for j = 1, . . . , n. Denote by ν = (ν1, . . . , νk)
an ordered index set satisfying
1 ≤ν1 < . . . < νk ≤n.
For a given ﬂag F one deﬁnes the Schubert variety
S(ν; F) := {W ∈Gq(k, n) | dim(W

Vvi) ≥i for i = 1, . . . , k}.
(3)

Constructions of Constant Dimension Codes
29
The Schubert varieties are sub-varieties of the Grassmannian Gq(k, n). The deﬁning
equations of the Schubert variety S(ν; F) in terms of Plücker coordinates are on
one side the deﬁning shufﬂe relations (2) describing the Grassmannian Gq(k, n). In
addition a set of linear equations (see [40]) have to be satisﬁed. These equations
simplify if one wants to describe the ball Bt only and the interested reader will ﬁnd
more details in [48].
Using the natural inner product inside the vector space Fn
q one has a natural dual-
ity between a k-dimensional subspace U ∈Gq(k, n) and the (n −k)-dimensional
subspace U⊥∈Gq(n −k, n). This duality induces a duality between the Grassmann
variety Gq(k, n) and the Grassmannian Gq(n −k, n), in particular both these Grass-
mannians are isomorphic. In case C ⊆Gq(k, n) is a subspace code it was pointed out
in [42, Sect.3.A] that the dual code C⊥⊆Gq(n −k, n) has the same cardinality and
minimum subspace distance as C. For the purpose of studying codes it is therefore
enough to restrict the study to codes in Gq(k, n) with n ≥2k.
Grassmannians Gq(k, n) are also homogeneous spaces. For this note that the gen-
eral linear group GLn acts naturally and transitively on Gq(k, n) through ‘right mul-
tiplication’:
Gq(k, n) × GLn →Gq(k, n)
(rs(U), A) →rs(U A).
As a consequence the tangent space at every point of Gq(k, n) is isomorphic and it
follows that Gq(k, n) is also a smooth variety. If one restricts above GLn-action to
some subgroup G ⊆GLn then one obtains a partition of Gq(k, n) into G-orbits. In
terms of coding theory a particular G-orbit deﬁnes a so called orbit code, which we
will say more about in Sect.5.
3
Spread Codes, Partial Spread Codes and Equidistant
Codes
The maximal possible distance two elements U, V ∈C ⊆Gq(k, n) of a constant
dimension code can have is dS(U, V) = 2k and this happens exactly when
U ∩V = {0}.
As a consequence the maximal possible minimum distance a constant dimension
code C ⊆Gq(k, n) can have is 2k.
Thenaturalquestionhenceariseswhatthemaximalcardinalityofnon-intersecting
k-dimensional subspaces in Fn
q can be?
When n is a multiple of k, i.e., n = rk for some natural number r, then it is a well
known result in ﬁnite geometry [34] that one has a collection of constant dimensional
subspaces in Fn
q having the property that any two subspaces intersect only in a trivial

30
A.-L. Horlemann-Trautmann and J. Rosenthal
manner and in addition every nonzero vector v ∈Fn
q lies in one and only one subspace
of this collection.
Deﬁnition 2 Let n = rk. Then a set S ⊆Gq(k, n) is called a spread if all elements
of S intersect only trivially and they cover the whole space Fn
q.
One immediately computes the cardinality of a spread as
qn −1
qk −1 = qk(r−1) + qk(r−2) + · · · + qk + 1.
i.e., a spread in Gq(k, n) is a constant dimension code with minimum distance 2k and
cardinality (qn −1)/(qk −1). In [44] constant dimension codes which also have the
structure of a spread were called spread codes. A concrete construction of spread
codes can be obtained in the following way:
Let P be the k × k companion matrix of a monic and irreducible polynomial
p(x) ∈Fq[x] of degree k. It is then well known (see e.g. [43]) that the Fq-algebra
Fq[P] ⊂Fk×k
q
is isomorphic to the ﬁnite ﬁeld Fqk. Denote by 0k, Ik ∈Fk×k
q
the zero
and the identity matrix respectively. Then one has the following theorem which was
proven in [44]:
Theorem 3 Let n = rk. The collection of subspaces
S :=
r	
i=1

rs

0k · · · 0k Ik Ai+1 · · · Ar

| Ai+1, . . . , Ar ∈Fq[P]

⊂Gq(k, n)
is a spread code with minimum distance 2k and cardinality (qn −1)/(qk −1).
Spreads are similar to classical MDS codes in the sense that they have maximal
possible minimum distance and at the same time maximal cardinality.
In [27] the authors studied the situation when k does not divide n. For these cases
spreads cannot exist but the construction of Theorem 3 can be done ‘up to the last
block’ and this then leads to the notion of a partial spread code. The following
deﬁnition was inspired by work in ﬁnite geometry [7]:
Deﬁnition 4 ([27, 28]) A partial spread code in Gq(k, n) is a subspace code C ⊂
Gq(k, n) having minimum distance dist(C) = 2k.
In [27] a concrete construction of a partial spread code is provided whose cardi-
nality is maximal among all subspace codes of minimum distance 2k inside Gq(k, n).
For more information on partial spreads the reader is referred to chapters “Geo-
metrical Aspects Of Subspace Codes” and “Partial Spreads And Vector Space
Partitions” of this book.
Spread codes and partial spread codes are special cases of equidistant subspace
codes – these are codes where any two distinct code words have the same distance:
Deﬁnition 5 A code C ⊆Gq(k, n) is an equidistant code if for any U, V ∈C
dS(U, V) = d for some ﬁxed d.

Constructions of Constant Dimension Codes
31
Note that for (partial) spread codes any two elements have distance d = 2k.
A special class of equidistant codes is the one of sunﬂowers, where all codewords
intersect in the same subspace of Fn
q. When the ambient vector space Fn
q is large it
was shown in [15] that an equidistant code of maximal cardinality is a sunﬂower.
The paper [28] provides an almost complete classiﬁcation in case the ground ﬁeld
is sufﬁciently large. The authors show that for most parameters an equidistant code
of maximal cardinality with minimum subspace distance less than 2k is either a
sunﬂower or its dual is a sunﬂower.
Any partial spread gives rise to a sunﬂower in a larger ambient space, which gives
rise to the following result [28, Theorem 34]:
Theorem 6 Let c ≤k −1 be an integer. Write n −c = h(k −c) + r, with 0 ≤r ≤
k −c −1, h ≥2. Then there exist an equidistant code in Gq(k, n) with minimum
distance 2k −2c and cardinality (qn−c −qr)/(qk−c −1) −qr + 1.
The following result about equidistant codes follows from [30, Theorem 1]. The
correspondingcodesareconstructedfromosculatingsubspacesofVeronesevarieties.
Theorem 7 Let ℓ, s, t be integers such that t/2 ≤ℓ≤t, and deﬁne k :=
ℓ+s
s

, n :=
t+s
s

. Then there exist an equidistant code in Gq(k, n) with minimum distance 2k −
2
2ℓ−t+s
s

and cardinality (qs+1 −1)/(q −1).
Furthermore, one can construct non-sunﬂower equidistant codes with minimum
distance 2k −2 with the help of the Plücker embedding:
Theorem 8 [15, Theorem 15] For every k ≥2, there exists an equidistant code in
Gq(k,
k+1
2

) with minimum distance 2k −2 and cardinality (qk+1 −1)/(q −1).
More examples of equidistant codes which are different from sunﬂowers can be
found in [4].
4
Constructions Based on (Ferrers Diagram) Rank-Metric
Codes
Some of the ﬁrst constructions for subspace codes were based on rank-metric codes.
These codes are sets of matrices of a ﬁxed size over Fq, equipped with the rank
metric, which is deﬁned as
dR(A, B) := rk(A −B),
A, B ∈Fm×n
q
.
The usefulness of rank-metric codes for the construction of subspace codes is due to
the following fact, which follows from [52, Proposition 4]:
Lemma 9 Let C ⊆Fk×(n−k)
q
be a code with minimum rank distance d. Then the
lifted code

32
A.-L. Horlemann-Trautmann and J. Rosenthal
lift(C) := {rs[Ik | A] | A ∈C}
is a constant dimension code in Gq(k, n) with minimum subspace distance 2d and
cardinality |C|.
Note that geometrically the set of subspaces of the form rs[Ik | A] inside the
Grassmannian Gq(k, n) represents a subset isomorphic to the afﬁne space Fk×(n−k)
q
.
Geometers also call this subset the ‘thick open cell’ of the Grassmannian Gq(k, n).
Constructions of optimal rank-metric codes are known for any set of parameters
(see e.g. [21]), the corresponding codes are called maximum rank distance (MRD)
codes. An MRD code C ⊆Fm×n
q
with minimum rank distance d has cardinality
qmax(m,n)(min(m,n)−d+1). Therefore, a lifted MRD code C ⊆Gq(k, n) with k ≤n/2
and minimum subspace distance 2d has cardinality q(n−k)(n−d+1).
For more information on partial spreads the reader is referred to chapters “Geo-
metrical Aspects Of Subspace Codes” and “Partial Spreads And Vector Space
Partitions” of this book.
Inthefollowingweneedthenotionofanidentifyingvector v(U)ofasubspaceU ∈
Gq(k, n), which is deﬁned as the vector of length n that has a one in the coordinates
where the reduced echelon form of U has a pivot, and zeros elsewhere. It was shown
in [17, Lemma 2] that for U, V ∈Gq(k, n) one has
dS(U, V) ≥dH(v(U), v(V)).
With this we can generalize the lifted MRD construction, as follows.
Theorem 10 [53, Theorem 2.9] Let C j be some MRD code with minimum rank
distance d in Fk×(n−k−jd)
q
for j = 0, . . . , ⌊n−k
d ⌋. Deﬁne
C j :=

rs
0k× jd Ik×k A 
| A ∈C j

and
C :=
⌊n−k
d ⌋
	
j=0
C j.
Then C ⊆Gq(k, n) has minimum distance 2d and cardinality
N =
⌊n−2k
d
⌋

i=0
q(k−d+1)(n−k−di) +
⌊n−k
d ⌋

i=⌊n−2k
d
⌋+1
⌈qk(n−k+1−d(i+1))⌉.
Note that similar statements to the previous theorem can also be found in [20, 22].
One can generalize the lifting idea to general reduced row echelon forms of
matrices, where the unit column vectors are not necessarily in the ﬁrst k columns.
This idea was introduced in [16]. First, let us brieﬂy provide some deﬁnitions needed
for this construction. A Ferrers diagram F is a collection of dots such that the rows
have a decreasing and the columns have an increasing number of dots (from top to

Constructions of Constant Dimension Codes
33
bottom and from left to right, respectively). We denote the matrix representation of
a vector space U ∈Gq(k, n) in reduced row echelon form by RE(U) ∈Fk×n
q
.
Deﬁnition 11 The Ferrers diagram form of a subspace U ∈Gq(k, n), denoted by
F(U), is obtained from RE(U) by ﬁrst removing the zeros to the left of the leading
coefﬁcient from each row of RE(U), and then removing the columns which contain
the leading ones. All the remaining entries are shifted to the right. The Ferrers
diagram of U, denoted by FU, is obtained from F(U) by replacing the entries of
F(U) with dots.
Deﬁnition 12 Let F be a Ferrers diagram with k rows and n columns. A correspond-
ing Ferrers diagram code is a matrix code F ⊆Fk×n
q
, such that all matrix entries not
in F are zero in all codewords. The minimum rank distance of a Ferrers diagram
code is deﬁned as usual. Similarly, the lifting of a Ferrers diagram code is deﬁned
analogously to the lifting of a rectangular rank-metric code, with a corresponding
reduced row echelon form.
We can now state the multi-level construction:
Theorem 13 Let C ⊆Fn
2 be a binary block code of constant weight k and minimum
Hamming distance 2d. Use each codeword vi ∈C as the identifying vector of a
reduced row echelon form and construct the corresponding lifted Ferrers diagram
code Ci with minimum rank distance d. Then the constant dimension code C =
|C|
i=1 Ci ⊆Gq(k, n) has minimum subspace distance 2d.
The size of these codes depends mainly on the size of the corresponding Ferrers
diagram codes, for which we do not have a general construction. In [17, Theorem 1]
an upper bound on the cardinality of linear Ferrers diagram codes with a prescribed
minimum rank distance is given. Moreover, code constructions for special types
of Ferrers diagrams attaining this bound are given. The authors conjecture that the
bound is always attainable, for any set of parameters. More constructions of codes
for certain Ferrers diagrams were derived in [14, 51].
It is an open question, which choice of the identifying vectors is optimal for the
multi-level construction. It was suggested in [17] that lexicographic binary constant
weight codes are the best choice. However, a counterexample for this statement is
given in [29, Example 57]. Furthermore, related results to lexicographic codes and
corresponding constant dimension codes found by computer search are presented in
[50].
As a next step, it was shown in [56] that one can construct larger codes than with
the multi-level construction, if one allows pending dots in the construction. We will
explain this pending dots construction in the following.
Deﬁnition 14 Let F be a Ferrers diagram. A dot of F is called a pending dot if the
maximal size of a Ferrers diagram code for F is the same as the maximal size of a
Ferrers diagram code for F without that dot.
We can now state the pending dots construction:

34
A.-L. Horlemann-Trautmann and J. Rosenthal
Theorem 15 Construct a constant weight-k code C ⊆Fn
2 of identifying vectors as
follows:
1. Let v1 = (11...10...0) be the ﬁrst identifying vector in C.
2. Choose the next identifying vector such that dH(vi, v1) ≥2d and ﬁx the set of
pending dots (if there are any) of the corresponding Ferrers diagram as μ1.
3. For the next identifying vector choose the ﬁrst 1 in the same positions as before
and use the next lexicode element of distance ≥2d −2 from the other elements
with the same pending dots and ≥2d from any other element of C. Fix the pending
dots as a tuple μi different from the tuples already used for echelon-Ferrers forms,
where the Hamming distance of the identifying vectors is 2d −2.
4. Repeat step 3 until no possibilities for a new skeleton code word with the ﬁxed 1
are left.
5. In the skeleton code choose the next vector in lexicographic order that has distance
≥2d from all other skeleton code words and repeat steps 2,3,4 and 5.
Then construct a lifted Ferrers diagram code for all identifying vectors, with the
given assignments of the pending dots in the Ferrers diagram. The union of all these
codes is a constant dimension code C ⊆Gq(k, n) with minimum subspace distance
2d.
One of the disadvantages of the multi-level and the pending dots construction is,
that there is no closed formula for the code cardinalities in general. Therefore, in [18,
51] the authors used the pending dots construction (or a slight generalization called
the pending blocks construction) to derive codes with a closed cardinality formula
for variable length n. To do so they gave a general construction of the constant weight
code for the identifying vectors and for the corresponding Ferrers diagram codes.
The results are given in the following theorems.
Theorem 16 [18, Theorem 16] Let k = 3 and q, n be such that
q2 + q + 1 ≥
n −3 n even
n −4 n odd .
Then the code C ⊆Gq(3, n) obtained from Construction I in [18] with minimum
subspace distance 4 has cardinality q2(n−3) +
n−3
2

q.
A similar result for small q has also been given in [18, Theorem 17].
Theorem 17 [51, Theorem 19] Let k ≥4, s := k
i=3 i = k2+k−6
2
, n ≥s + 2 + k =
k2+3k−2
2
and q2 + q + 1 ≥ℓ, where ℓ:= n −s = n −k2+k−6
2
for odd n −s (or ℓ:=
n −s −1 = n −k2+k−4
2
for even n −s). Then the code C ⊆Gq(k, n) obtained from
Construction A in [51] has minimum subspace distance 2(k −1) and cardinality
q2(n−k) + q2(n−(k+(k−1))) + . . . + q2(n−k2+k−6
2
) +
n −k2+k−6
2
2

q
.

Constructions of Constant Dimension Codes
35
A similar result for small q has also been given in [51, Corollary 22].
Theorem 18 [51, Corollary 27] Let n ≥2k + 2. Then the code C ⊆Gq(k, n)
obtained from Construction B (recursively applied) in [51] has minimum subspace
distance 4 and cardinality at least
⌊n−2
k ⌋−1

i=1

q(k−1)(n−ik) + (q2(k−2) −1)(q2(n−ik−1) −1)
(q4 −1)2
q(k−3)(n−ik−2)+4

.
Furthermore, two constructions for codes in Gq(4, n) and Gq(5, n) with minimum
subspace distance 4 with closed cardinality formula were presented in [51, Sect.
IV.B].
5
Orbit Codes
In this section we present several constructions for orbit codes. We will ﬁrst present
theory about single orbits in Gq(k, n), whereas in the second subsection we will
review constructions of unions of orbits with a prescribed minimum subspace dis-
tance.
Throughout the section we will make use of the isomorphism Fqn ∼= Fn
q. By abuse
of notation we will change between the two representations with the same notation.
5.1
Single Orbits
The general linear group of order n with entries from Fq, denoted by GLn(q), deﬁnes
an action on Gq(k, n) as follows:
Gq(k, n) × GLn(q) −→Gq(k, n)
U × A −→rs(RE(U)A)
An orbit code C ⊆Gq(k, n), in general, is deﬁned as the orbit of a subgroup G ≤
GLn(q) with some initial point U ∈Gq(k, n), i.e.,
C = UG := {U A | A ∈G}.
These codes can be seen as the analog of linear codes in the classical block coding
case, since linear block codes are orbit codes with respect to additive subgroups of
Fn
q (see e.g. [54, 55]). One of the consequences of this fact is, that the minimum
distance of an orbit code can be determined by comparing all elements of the orbit

36
A.-L. Horlemann-Trautmann and J. Rosenthal
with the initial point (instead of all possible pairs of codewords), as shown in [54,
Theorem 17]:
Lemma 19 Let U ∈Gq(k, n) be an initial point, G ≤GLn(q) a subgroup and let
C = UG be an orbit code. Then
dS(C) = min{dS(U, U A) | A ∈G, A /∈StabG(U)},
where StabG(U) := {A ∈G | U A = U}.
Of particular interest are cyclic orbit codes, where the deﬁning subgroup G ≤
GLn(q) is cyclic, i.e., there is a matrix P ∈GLn(q) such that G = ⟨P⟩and therefore
C = UG = {U Pi | i = 0, . . . , ord(P) −1}.
Understood best is the case where P is the companion matrix of a monic irreducible
polynomial p(x) ∈Fq[x] of degree n. These codes are also called irreducible cyclic
orbit codes [54]. If the irreducible polynomial is primitive, we call the corresponding
codes primitive cyclic orbit codes.
It is well-known that one can construct spread codes as primitive cyclic orbit
codes, see e.g. [49, Theorem 3]:
Theorem 20 Let k | n and p(x) ∈Fq[x] be monic, primitive and of degree n, and
let α ∈Fqn be a root of p(x). Denote by P ∈GLn(q) the companion matrix of p(x).
Then
U :=

α
i qn−1
qk −1 | i = 0, . . . , qk −2

∪{0}
is an element of Gq(k, n) and C = U⟨P⟩is a spread in Gq(k, n).
Note that, in Theorem 20, U is the subﬁeld Fqk of Fqn. Moreover, one does not
need the companion matrix P in the description of the orbit, instead one can also
write C = {αiFqk | i = 0, . . . , (qn −1)/(qk −1) −1}. The previous construction
has been generalized in [6, Section3.B] as follows:
Theorem 21 Let d ∈N divide k and n. Then
C =
 k/d

i=1
αiFqd | α1, . . . , αk/d ∈Fqn are linearly independent over Fqd

is a code in Gq(k, n) with minimum subspace distance 2d and cardinality
n/d
k/d

qd.
Furthermore, it is conjectured that for all parameters, except some border cases,
an irreducible cyclic orbit code of minimum subspace distance 2(k −1) exists:
Conjecture 22 For any k, q and n ≥6 there exists an irreducible orbit code
C ⊆Gq(k, n) with minimum subspace distance 2(k −1) and cardinality (qn −1)/
(q −1).

Constructions of Constant Dimension Codes
37
This conjecture was stated for general n in [12, 54], but the case n = 8, k = 4
has been disproven in [25]. On the other hand, in [6, 45] it was shown that for any
q, k there exist inﬁnitely many n where the conjecture holds. The other parameter
sets remain as a conjecture.
In general, one can determine the minimum subspace distance of a cyclic orbit
code by just looking at the initial point U ∈Gq(k, n) of the orbit. This was done in
[12, 41] for Singer subgroup orbits and, in more general, for any cyclic group in [54,
Sect.4]. This method was later on reﬁned in [25, Theorem 4.11], where the authors
deﬁned the best friend of a subspace U ∈Gq(k, n) as the largest subﬁeld Fqr of Fqn
over which U is a vector space. With the help of the best friend one gets the following
estimates on cardinality and distance of the corresponding code (see [25, Corollary
3.13, Lemma 4.1]):
Theorem 23 Let U ∈Gq(k, n) and P ∈GLn(q) be a companion matrix of a monic
primitive polynomial of degree n. Consider the orbit code C = U⟨P⟩. If Fqr is the
best friend of U, then
|C| = qn −1
qr −1
and
2r ≤dS(C) ≤2k.
Based on the previously mentioned methods to determine the minimum subspace
distance of a cyclic orbit code, the paper [24] establishes a connection between the
choice of initial point of a cyclic orbit code and the construction of cyclic difference
sets of appropriate parameters. Moreover, in [2] some results related to irreducible
cyclic orbit codes are given.
5.2
Unions of Orbits
In [20] the notion of a cyclic subspace code was introduced. In our terminology, this
is a union of primitive cyclic orbit codes, although in its general form it could be
a union of primitive cyclic orbit codes of different dimensions. In [6] it was shown
how subspace polynomials can be used to construct good cyclic subspace codes.
Deﬁnition 24 Let U ⊆Fqn be a Fq-subspace. The subspace polynomial of U is
deﬁned as the monic (linearized) polynomial PU(x) of least degree, such that
PU(u) = 0 for any u ∈U.
Note that a subspace polynomial of some Fq-subspace of Fqn is always a linearized
polynomial, i.e., it is of the form m
i=0 aixqi with a0, . . . , am ∈Fqn. The following
result, which is a reformulation of [6, Corollary 2], relates the shapes of two subspace
polynomials to the subspace distance of the corresponding subspaces:

38
A.-L. Horlemann-Trautmann and J. Rosenthal
Lemma 25 Let U, V ∈Gq(k, n), with PU(x) = xqk + ℓ
i=0 aixqi where aℓ̸= 0,
and PV(x) = xqk + m
i=0 bixqi where bm ̸= 0. Then
dS(U, V) ≥2 min(k −ℓ, k −m).
Another useful fact is that one can describe the subspace polynomials of an orbit
with the help of the subspace polynomial of the initial point [6, Lemma 4]:
PαU(x) = αqk PU(α−1x).
With the above tools one can derive the following code constructions.
Theorem 26 [6, Theorem 4] Let n be a prime and γ ∈Fqn be primitive. If Fq N is the
splitting ﬁeld of PU(x) := xqk + γqxq + γx and U ∈Gq(k, N) is the corresponding
subspace (i.e., the kernel of PU(x)), then
C :=
n−1
	
i=0
{αUqi | α ∈F∗
q N }
is a cyclic subspace code with minimum subspace distance 2k −2 and size n(q N −
1)/(q −1).
This construction was generalized in [45, Theorem 3] to more general trinomials
that can be used as subspace polynomials, which allows even larger code sizes.
Furthermore, a generalization to subspace polynomials with s + 2 summands (for
s > 1), such that the arising subspace code has minimum subspace distance 2k −2s,
is given in [45, Corollary 4].
For more information on rank-metric and MRD codes the reader is referred to
chapters “Codes Endowed With The Rank Metric” and “Constructions of Cyclic
Subspace Codes and Maximum Rank Distance Codes” of this book.
Besides the previous theoretical results, there are many related results using smart
computer searches to construct large codes, in particular cyclic subspace codes.
In [41] unions of irreducible cyclic orbit codes are found by solving linear
inequalities under Diophantine restrictions. This Diophantine system is only fea-
sible because the authors impose a prescribed automorphism group (namely the one
of irreducible cyclic orbit codes) on the solutions. The results of that paper are for
length 6 ≤n ≤14, dimension k = 3, and minimum subspace distance 4. Some of
these codes are still the best codes known for the given parameter sets.
In [20, SectionIII] optimal cyclic codes of length 8 and 9 are presented, in the
sense that there is no larger cyclic subspace code of the same length and distance.
These two computational methods prescribe Fqn as the automorphism group in
order to make the computer search feasible. Despite this restriction on unions of
primitive cyclic orbit codes, the codes found come quite close to known bounds.
This shows that cyclic orbit codes (or cyclic subspace codes) form a powerful class
of constant dimension codes.

Constructions of Constant Dimension Codes
39
6
New from Old Codes
There are several results about how to construct new constant dimension codes from
known constant dimension codes of smaller parameters.
A fairly simple, but very effective construction is given in Construction D of [51].
Theorem 27 [51, Theorem 37] Let C′ ∈Gq(k, n) be a code with minimum subspace
distance 2d, let Δ ≥k, and let CR ⊆Fk×Δ
q
be an MRD code of minimum rank
distance d. Deﬁne the code
C := {rs[ RE(U)
A ] | U ∈C′, A ∈CR}.
Then C is a constant dimension code in Gq(k, n + Δ) with minimum subspace dis-
tance 2d and cardinality |C′|qΔ(k−d+1).
As noted in [51, Corollary 39], one can easily extend this construction by adding
constant dimension codes with prescribed zero columns in the beginning, analo-
gously to Theorem 10. This idea is the basis of the linkage construction of [26]:
Theorem 28 [26, Theorem 2.3] For i = 1, 2 let ˆCi ⊆Gq(k, ni) with minimum sub-
space distance di. Furthermore, let CR ⊆Fk×n2 be a linear rank-metric code with
minimum rank distance dR. Then the code C := C1 ∪C2, where
C1 := {rs[ RE(U)
A ] | U ∈ˆC1, A ∈CR},
C2 := {rs[ 0k×n1
RE(U) ] | U ∈ˆC2},
is a constant dimension code in Gq(k, n1 + n2), with minimum subspace distance
min{d1, d2, 2dR} and cardinality | ˆC2| + | ˆC1||CR|.
Notethat intheoriginal statement of this theorem, thematrixrepresentations of the
subspaces U do not necessarily have to be the reduced row echelon forms. Different
basis matrices will give different codewords in C3, but the cardinality and minimum
distance of the code remains the same. Furthermore note that this construction can
be used to construct good partial spreads [26, Sect.3].
The coset construction from [33] can be reformulated as follows, for which we
need the following map: Let U ∈Gq(k, n) and F ∈Fm×(n−k)
q
, then ϕU(F) is a matrix
M ∈Fm×n
q
, such that M has a zero column wherever RE(U) has a pivot and the other
columns of M are the columns of F.
Theorem 29 Let A, B be disjoint unions of sets Ai ⊆Gq(k′, n′), Bi ⊆Gq(k −
k′, n −n′), respectively. Moreover, let CF ⊆Fk′×(n−n′−k+k′)
q
be an MRD code of min-
imum rank distance d. Let C be a subset of the set
	
i

rs
RE(U) ϕU(F)
0
RE(V)

| U ∈Ai, V ∈Bi, F ∈CF


40
A.-L. Horlemann-Trautmann and J. Rosenthal
such that dS(U, U′) + dS(V, V′) ≥2d for any two elements of the above form in C.
Then C is a constant dimension code in Gq(k, n) with minimum subspace distance
2d.
Note that the sets Ai, Bi can be thought of as known constant dimension codes.
A very effective family of unions of subsets, that was used in [33] in the coset
construction are parallelisms, i.e., partitions of Gq(k, n) into spreads.
7
Final Remarks
Besides the constructions presented in detail in this survey one can ﬁnd more results
on subspace codes. E.g., a family of constant dimension codes called linear sub-
space codes was deﬁned in [8]. More results on these codes were derived in [5, 46].
Furthermore, one can derive constant dimension codes from Riemann-Roch spaces,
as done in [3, 31]. Many results on constant dimension codes with certain ﬁxed
parameters, often based on smart computer search, can be found in the literature, see
e.g. in [1, 9–12, 35, 36] and references therein.
Moreover, results on non-constant dimension subspace codes, also called mixed-
dimension subspace codes, can be found in [17, 23, 37–39, 51]. Note that in the
non-constant dimension case there are two different metrics one can consider - the
subspace and the injection metric. The before mentioned results include results for
both metrics.
The best known subspace codes for given parameters can be looked up in the
online database [32] at
http://subspacecodes.uni-bayreuth.de.
Finally, some open problems on various aspects of subspace codes can be found
in the overview articles [13, 19].
Acknowledgements The authors were partially supported by COST – European Cooperation
in Science and Technology. The second author was also supported by Swiss National Science
Foundation grant no. 169510.
References
1. J. Ai, T. Honold, H. Liu, The expurgation-augmentation method for constructing good plane
subspace codes (2016). arXiv:1601.01502 [math.CO]
2. F. Bardestani, A. Iranmanesh, Cyclic orbit codes with the normalizer of a singer subgroup. J.
Sci. Islam. Repub. Iran 26(1), 49–55 (2015)
3. D. Bartoli, M. Bonini, M. Giulietti, Constant dimension codes from Riemann-Roch spaces
(2015). arXiv:1508.01727
4. D. Bartoli, F. Pavese, A note on equidistant subspace codes. Discret. Appl. Math. 198, 291–296
(2016)

Constructions of Constant Dimension Codes
41
5. P. Basu, N. Kashyap. On linear subspace codes closed under intersection. In 2015 Twenty First
National Conference on Communications (NCC), pages 1–6, February 2015
6. E. Ben-Sasson, T. Etzion, A. Gabizon, N. Raviv, Subspace polynomials and cyclic subspace
codes. IEEE Trans. Inf. Theory 62(3), 1157–1165 (2016)
7. A. Beutelspacher, Blocking sets and partial spreads in ﬁnite projective spaces. Geom. Dedic.
9(4), 425–449 (1980)
8. M. Braun, T. Etzion, A. Vardy, Linearity and complements in projective space. Linear Algebr.
Appl. 438(1), 57–70 (2013)
9. M. Braun, P. Östergard, A. Wassermann. New lower bounds for binary constant-dimension
subspace codes. Exp. Math. 1–5 (to appear)
10. A. Cossidente, F. Pavese. Subspace codes in PG(2n-1,q). Combinatorica (2016), p. 1–23
11. A. Cossidente, F. Pavese, Veronese subspace codes. Des. Codes Cryptogr. 81(3), 445–457
(2016)
12. A. Elsenhans, A. Kohnert, A. Wassermann. Construction of codes for network coding. In
Proceedings of the 19th International Symposium on Mathematical Theory of Networks and
Systems – MTNS (Budapest, Hungary, 2010), pp. 1811–1814
13. T. Etzion. Problems on q-analogs in coding theory (2013). arXiv:1305.6126
14. T. Etzion, E. Gorla, A. Ravagnani, A. Wachter-Zeh, Optimal Ferrers diagram rank-metric codes.
IEEE Trans. Inf. Theory 62(4), 1616–1630 (2016)
15. T. Etzion, N. Raviv, Equidistant codes in the Grassmannian. Discret. Appl. Math. 186, 87–97
(2015)
16. T. Etzion, N. Silberstein. Construction of error-correcting codes for random network coding. In
IEEE 25th Convention of Electrical and Electronics Engineers in Israel, 2008. (IEEEI 2008)
(2008), pp. 070–074
17. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inf. Theory 55(7), 2909–2919 (2009)
18. T. Etzion, N. Silberstein, Codes and designs related to lifted MRD codes. IEEE Trans. Inf.
Theory 59(2), 1004–1017 (2013)
19. T. Etzion, L. Storme, Galois geometries and coding theory. Des. Codes Cryptogr. 78(1),
311–350 (2016)
20. T. Etzion, A. Vardy, Error-correcting codes in projective space. IEEE Trans. Inf. Theory 57(2),
1165–1173 (2011)
21. E.M. Gabidulin, Theory of codes with maximum rank distance. Problemy Peredachi Informatsii
21(1), 3–16 (1985)
22. E.M.Gabidulin,N.I.Pilipchuk.Multicomponent networkcoding.In Proceedingsof the Seventh
International Workshop on Coding and Cryptography (WCC) 2011, (Paris, France, 2011), pp.
443–452
23. A. Ghatak. Subspace codes for random networks based on Plücker coordinates and Schubert
cells (2013). arXiv:1301.6362 [cs.IT]
24. A. Ghatak. Construction of Singer subgroup orbit codes based on cyclic difference sets. In
2014 Twentieth National Conference on Communications (NCC) (2014), pp. 1–4
25. H. Gluesing-Luerssen, K. Morrison, C. Troha, Cyclic orbit codes and stabilizer subﬁelds. Adv.
Math. Commun. 9(2), 177–197 (2015)
26. H. Gluesing-Luerssen, C. Troha, Construction of subspace codes through linkage. Adv. Math.
Commun. 10(3), 525–540 (2016)
27. E. Gorla, A. Ravagnani, Partial spreads in random network coding. Finite Fields Appl. 26,
104–115 (2014)
28. E. Gorla, A. Ravagnani, Equidistant subspace codes. Linear Algebr. Appl. 490, 48–65 (2016)
29. E. Gorla, A. Ravagnani. Subspace codes from Ferrers diagrams. J. Algebr. Appl. 1750131
(2016) (online)
30. J.P. Hansen, in Osculating spaces of varieties and linear network codes. Lecture Notes in
Computer Science, vol 8080, 83–88 (2013)
31. J.P. Hansen, Riemann-Roch spaces and linear network codes. Comput. Sci. 10(1), 1–11 (2015)

42
A.-L. Horlemann-Trautmann and J. Rosenthal
32. D. Heinlein, M. Kiermaier, S. Kurz, A. Wassermann. Tables of subspace codes (2016).
arXiv:1601.02864
33. D. Heinlein, S. Kurz. Coset construction for subspace codes (2015). arXiv:1512.07634
[math.CO]
34. J.W.P. Hirschfeld, Projective Geometries over Finite Fields, 2nd edn. (Oxford Mathematical
Monographs. The Clarendon Press, Oxford University Press, New York, 1998)
35. T. Honold, M. Kiermaier. On putative q-analogues of the Fano plane and related combinatorial
structures, in Dynamical Systems, Number Theory and Applications: A Festschrift in Honor of
Armin Leutbecher’s 80th Birthday. (World Scientiﬁc, 2016), pp. 141–175
36. T. Honold, M. Kiermaier, S. Kurz. Optimal binary subspace codes of length 6, constant dimen-
sion 3 and minimum subspace distance 4. In Topics in ﬁnite ﬁelds, vol. 632 of Contemporary
Mathematics (American Mathematical Society, Providence, RI, 2015), pp. 157–176
37. T. Honold, M. Kiermaier, S. Kurz, Constructions and bounds for mixed-dimension subspace
codes. Adv. Math. Commun. 10(3), 649–682 (2016)
38. A. Khaleghi. Projective Space Codes for the Injection Metric. (Masters thesis, University of
Toronto, 2009)
39. A. Khaleghi, D. Silva, F.R. Kschischang. Subspace codes. In IMA International Conference
on Cryptography and Coding (2009), pp. 1–21
40. S.L. Kleiman, D. Laksov, Schubert calculus. Am. Math. Mon. 79, 1061–1082 (1972)
41. A. Kohnert, S. Kurz. Construction of large constant dimension codes with a prescribed mini-
mum distance. in MMICS eds. by J. Calmet, W. Geiselmann, J. Müller-Quade. Lecture Notes
in Computer Science, vol. 5393 (Springer, Berlin, 2008), pp. 31–42
42. R. Kötter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Transac. Inf. Theory 54(8), 3579–3591 (2008)
43. R. Lidl, H. Niederreiter, Introduction to Finite Fields and their Applications (Cambridge Uni-
versity Press, Cambridge, London, 1986)
44. F. Manganiello, E. Gorla, J. Rosenthal. Spread codes and spread decoding in network coding.
In Proceedings of the 2008 IEEE International Symposium on Information Theory (Toronto,
Canada, 2008), pp. 851–855
45. K. Otal, F. Özbudak, Cyclic subspace codes via subspace polynomials. Des. Codes Cryptogr.
1–14 (2016)
46. S. Pai, S. Rajan. On the bounds of certain maximal linear codes in a projective space. In IEEE
International Symposium on Information Theory (ISIT) (2015), pp. 591–595
47. C. Procesi. A Primer Of Invariant Theory. (Brandeis lecture notes, Brandeis University, 1982).
Notes by G. Bofﬁ
48. J. Rosenthal, N. Silberstein, A.-L. Trautmann, On the geometry of balls in the Grassmannian
and list decoding of lifted Gabidulin codes. Des. Codes Cryptogr. 73(2), 393–416 (2014)
49. J. Rosenthal, A.-L. Trautmann, A complete characterization of irreducible cyclic orbit codes
and their Plücker embedding. Des. Codes Cryptogr. 66(1–3), 275–289 (2013)
50. N. Silberstein, T. Etzion, Large constant dimension codes and lexicodes. Adv. Math. Commun.
5(2), 177–189 (2011)
51. N. Silberstein, A.-L. Trautmann, Subspace codes based on graph matchings, Ferrers diagrams,
and pending blocks. IEEE Trans. Inf. Theory 61(7), 3937–3953 (2015)
52. D. Silva, F. Kschischang, F. Kötter, A rank-metric approach to error control in random network
coding. IEEE Trans. Inf. Theory 54(9), 3951–3967 (2008)
53. A.-L. Trautmann. Constructions, Decoding and Automorphisms of Subspace Codes. PhD the-
sis, University of Zurich, 2013
54. A.-L. Trautmann, F. Manganiello, M. Braun, J. Rosenthal, Cyclic orbit codes. IEEE Trans.
Inform. Theory 59(11), 7386–7404 (2013)
55. A.-L. Trautmann, F. Manganiello, J. Rosenthal, Orbit codes - a new concept in the area of
network coding, in 2010 IEEE Information Theory Workshop (ITW) (Dublin, Ireland, 2010),
pp. 1–4
56. A.-L. Trautmann, J. Rosenthal. New improvements on the echelon-Ferrers construction. In
Proceedings of the 19th International Symposium on Mathematical Theory of Networks and
Systems – MTNS (Budapest, Hungary, 2010), pp. 405–408

Constructions of Cyclic Subspace Codes
and Maximum Rank Distance Codes
Kamil Otal and Ferruh Özbudak
Abstract This chapter is a survey of the recent results on the constructions of cyclic
subspace codes and maximum rank distance codes. Linearized polynomials are the
main tools used to introduce both constructions in this chapter. In the construction
of cyclic subspace codes, codewords are considered as the root spaces of some
subspace polynomials (which are a particular type of linearized polynomials). In
this set up, some algebraic manipulations on the coefﬁcients and degrees of such
polynomials are applied to provide a systematic construction of cyclic subspace
codes. In constructions of maximum rank distance codes, linearized polynomials
are used as codewords again, but in a different way. Codewords of rank metric
codes are considered as the linear maps that these polynomials represent. All known
constructions of maximum rank distance codes in the literature are summarized using
this linearized polynomial representation. Connections among the constructions and
further explanations are also provided.
1
Introduction
Subspace codes have an increasing interest in the last decade thank to their applica-
tions in random network coding. Similar to subspace codes, the theory of rank metric
codes have gained an increasing attraction due to their application to various areas
including subspace codes. Linearized polynomials are quite useful mathematical
tools to represent and solve some current problems within these areas.
In this chapter, the main goal is to provide all known advances in two recent prob-
lems: constructions of cyclic subspace codes and maximum rank distance codes.
In particular, Sect.1 is devoted to the brief introductions of linearized polynomials,
cyclic subspace codes and rank metric codes. Further details and an explicit construc-
K. Otal (B) · F. Özbudak
Middle East Technical University, Ankara, Turkey
e-mail: kotal@metu.edu.tr
F. Özbudak
e-mail: ozbudak@metu.edu.tr
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_3
43

44
K. Otal and F. Özbudak
tion of cyclic subspace codes are introduced in Sect.2, whereas the constructions of
maximum rank distance codes in the literature are summarized in Sect.3.
1.1
Linearized Polynomials
We recall the deﬁnition and some basic properties of linearized polynomials before
to explain their applications mentioned above. Let Fq be a ﬁnite ﬁeld of q elements,
Fq N be its N-th degree ﬁeld extension and Fq be its algebraic closure. A polynomial
f (x) ∈Fq N [x] of the form
f (x) =
l
i=0
αixqi ,
(1)
for some non-negative integerl, is called a q-polynomial (or, a linearized polynomial)
over Fq N . In this representation, l is called the q-degree of f if αl ̸= 0. Some useful
properties of linearized polynomials of form (1) are listed below.
• f (cα + β) = cf (α) + f (β) for all c ∈Fq and α, β ∈Fq.
• The multiplicity of each root of f in Fq is the same and equal to qr, where r is the
smallest integer satisfying αr ̸= 0.
• The set of roots of f in an extension of Fq N constitutes a vector space over Fq.
In particular, the set of roots of f in Fq N is a subspace of Fq N over Fq. This
set is called the kernel of f and denoted by ker( f ). The rank of f is given by
N −dim(ker( f )) and denoted by rank( f ).
These properties can be proved directly by using the deﬁnition. Further information
about linearized polynomials can be found, for example, in [19, Sect.3.4].
A monic q-polynomial is called a subspace polynomial if it splits completely over
Fq N (i.e. all roots are in Fq N ) and has no multiple roots (i.e. α0 ̸= 0). Therefore, there
is a one to one correspondence between an l-dimensional subspace U of Fq N and a
subspace polynomial f of q-degree l satisfying f (U) = {0}.
1.2
Subspace Codes
The set of all subspaces of Fq N is called the projective space of (vector) dimension
N over Fq and denoted by Pq(N). The set of all k dimensional elements of Pq(N)
is called Grassmannian space (or brieﬂy Grassmannian) over Fq and denoted by
Gq(N, k). The metric d given by
d(U, V ) := dim U + dim V −2 dim(U ∩V )

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
45
on Pq(N) is called the subspace distance. A subset C ⊆Pq(N) including at
least two elements and equipped with this metric is called a subspace code. If
moreover C ⊆Gq(N, k), then C is also called a constant dimension code (see
chapter “Constructions of Constant Dimension Codes” for various constructions
of such codes). We naturally deﬁne the minimum distance d(C ) of a code C
by d(C ) := min{d(U, V ) : U, V ∈C and U ̸= V }. A cyclic shift of a subspace
U ⊆Fq N is given by αU := {αu : u ∈U}, where α ∈F∗
q N . Observe that a cyclic
shift is a subspace of Fq N over Fq, and the dimension of the cyclic shift is the same
as the dimension of U. A subspace code C is called cyclic if αU ∈C for all U ∈C
and α ∈F∗
q N , and quasi-cyclic if αU ∈C for all U ∈C and α ∈G, where G is a
multiplicative subgroup of F∗
q N . Quasi-cyclic codes are also known as “(cyclic) orbit
codes” (see, for example, [13, 35]).
Subspace codes are the main mathematical tools in random network coding due
to their error correction capabilities shown in [17]. Cyclic subspace codes have
a particular interest thank to their efﬁcient encoding and decoding algorithms. A
systematic construction of cyclic subspace codes including several orbits was given
in [1] using subspace polynomials. In [28], this construction was generalized and
improved by increasing the code size and the number of possible parameters. In
Sect.2, we aim to give this construction with some computational illustrations.
1.3
Rank Metric Codes
Let Fm×n
q
be the set of m × n matrices over Fq. On Fm×n
q
× Fm×n
q
, the function d
deﬁned by
d(A, B) := rank(A −B),
which satisﬁes the usual axioms of a metric, is called the rank distance on Fm×n
q
.
Remark 1 Notice that we use d to denote both the subspace distance and the rank
distance together, since we think that there is a less possibility to confuse them in this
chapter. Observe that they are deﬁned on different ambient spaces, also we examine
them in separate sections (Sects.2 and 3).
A subset C of Fm×n
q
including at least two elements and equipped with the rank
distance is called a rank metric code. The minimum distance d(C ) of a code C
is naturally deﬁned by d(C ) := min{d(A, B) : A, B ∈C and A ̸= B}. Equivalence
between any two rank metric codes is determined considering the set of rank distance
preservingmapsunderthelightof[36,Theorem3.4]:TworankmetriccodesC , C ′ ⊆
Fm×n
q
are called equivalent if there exist X ∈GL(m, Fq), Y ∈GL(n, Fq) and Z ∈
Fm×n
q
such that
C ′ = XC σY + Z := {XCσY + Z : C ∈C } when m ̸= n,
C ′ = XC σY + Z or C ′ = X(C t)σY + Z when m = n,
(2)

46
K. Otal and F. Özbudak
for some automorphism σ acting on the entries of C ∈C , where the superscript t
denotes the transposition of matrices. If both C and C ′ are closed under addition,
then Z must be the zero matrix. Similarly, if both C and C ′ are linear over Fq, then
σ can be taken as the identity without loss of generality. This equivalence idea, in
different forms and scopes, is used in several studies [3, 20, 22, 23, 25–27, 31].
Rank metric codes have a well-known Singleton-like bound given in the follow-
ing proposition.
Proposition 1 ([5]) Assume m ≥n without loss of generality. Let C ⊆Fm×n
q
be a
rank metric code with the minimum rank distance d. Then |C | ≤qm(n−d+1).
We may give an elementary proof for this proposition as follows.
Proof Let C ′ ⊆Fm×(n−d+1)
q
be the set of matrices obtained by deleting the last d −1
columns of codewords in C . If A, B ∈C are distinct, then their images A′, B′ ∈C ′
are also distinct since d(A, B) = rank(A −B) > d −1, hence |C | = |C ′|. Also the
inclusion C ′ ⊆Fm×(n−d+1)
q
implies |C ′| ≤qm(n−d+1). That is, |C | ≤qm(n−d+1). □
If the Singleton-like bound is met, then the code is called maximum rank distance
(MRD) code. MRD codes have a rich mathematical structure, inheriting the q-
analogue dimension of classical coding theory. Besides the theoretical importance,
they also have various applications, for example, in random network coding (e.g.,
[33]), space-time coding (e.g., [21, 34]) and cryptology (e.g., [29, 32]).
Finding new optimal codes, up to an equivalence notion, is one of the basic
problems in coding theory. Accordingly, the problem of ﬁnding new MRD codes
up to the equivalence relation given in (2) has gained interest especially in the last
decade. We may summarize the history of the results about this problem as follows.
• Linear MRD codes:
– 1978, 1985 and 1991: Gabidulin codes in [5, 12, 30].
– 2005: Generalized Gabidulin codes in [15] (brieﬂy called GG codes).
– 2016: Twisted Gabidulin codes in [31] (brieﬂy called TG codes). A particular
case was also discovered independently in [25].
– 2016: Generalized twisted Gabidulin codes in [20, 31] (brieﬂy called GTG
codes).
• Non-linear additive MRD codes:
– 2017: Additive generalized twisted Gabidulin codes in [26] (brieﬂy called AGTG
codes).
• Non-additive (but closed under multiplication by a scalar) MRD codes:
– 2016: A family for the m = n = 3 and d = 2 case in [4].
– 2017: A generalization of [4] to the d = m −1 case in [7].
• Non-additive and not closed under multiplication by a scalar MRD codes:
– 2017: A family for arbitrary d in [27].

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
47
In Sect.3 we give these constructions explicitly using their linearized polynomial
representation. Notice that all families listed above are constructed for m = n. From
a code C ⊆Fm×m
q
of minimum distance d, by deleting last m −n rows (or columns),
we can obtain another code C ′ ⊆Fm×n
q
of minimum distance larger than or equal
to d −m + n. The new code C ′ is called a punctured code. Remark that if a rank
metric code C is MRD then so is its punctured version C ′. However, punctured codes
are not involved in this chapter, since the m = n case may be considered the more
general case in this perspective.
2
Construction of Cyclic Subspace Codes
Let U ∈Gq(N, k). We never consider the trivial cases, so assume 1 < k < N unless
otherwise stated. Here, U is a linear space over Fq, but U can be also a linear space
over Fqt for some t > 1 (observe that t always divides both N and k in this case).
Such a property affects some important parameters. In case we need to emphasize
this property, we brieﬂy say “Fq−linear” and “Fqt−linear” correspondingly.
The Orb(U) := {αU : α ∈F∗
q N } set is called the orbit of U. The cardinality of
an orbit can be determined as in the following well-known theorem.
Theorem 1 Let U ∈Gq(N, k). Then, Fqd is the largest ﬁeld over which U is linear
if and only if
|Orb(U)| = q N −1
qd −1 .
Similar versions of this theorem are available also in [1, 6, 13]. We may prove
this theorem in an elementary way as follows.
Proof (⇒) : Let Fqd be the largest ﬁeld over which U is linear. Then we have
|Orb(U)| ≤q N −1
qd−1 since aU = U for all a ∈Fqd. Assume that the equality does not
hold. Then there exists an α ∈Fq N \ Fqd such that αU = U, by pigeon hole principle.
It implies U is also Fqd(α)−linear, but Fqd ⊊Fqd(α) since α /∈Fqd. Hence Fqd is not
the largest ﬁeld over which U is linear, contradiction. Therefore, the equality must
hold, i.e. |Orb(U)| = q N −1
qd−1 .
(⇐) : It can be shown by the (⇒) part.
□
If d = 1 in Theorem 1, then the orbit is called full length orbit. Otherwise, the
orbit is called degenerate orbit.
Remark 2 In case we need to study degenerate orbits, equivalently we can study full
length orbits over Fqd and then carry all the data from Gqd(N/d, k/d) to Gq(N, k).

48
K. Otal and F. Özbudak
2.1
A Construction Including Many Full Length Orbits
The following theorem gives a systematic construction of cyclic subspace codes
including many full length orbits in Gq(N, k), when the minimum distance is 2k −2.
Theorem 2 ([28]) Consider r polynomials
Ti(x) := xqk + θixq + γix ∈Fqn[x],
1 ≤i ≤r
satisfying θi ̸= 0 and γi ̸= 0 for all 1 ≤i ≤r, and
γi
γ j
̸=

γi
γ j
 θi
θ j
−1 qk −1
q−1
when i ̸= j.
(3)
Also let
– Ni be the degree of the splitting ﬁeld of Ti for 1 ≤i ≤r,
– Ui ⊆Fq Ni be the kernel of Ti for 1 ≤i ≤r,
– N be a multiple of lcm(N1, . . . , Nr).
Then the code C ⊆Gq(N, k) given by
C =
r
i=1
{αUi : α ∈F∗
q N }
is a cyclic code of size r q N −1
q−1 and of minimum distance 2k −2.
Proof Let Ci := {αUi : α ∈F∗
q N }, for 1 ≤i ≤r. Then C := r
i=1 Ci is a subset of
Gq(N, k) and it is obviously cyclic. To prove that |C | = r q N −1
q−1 and d(C ) = 2k −2,
it is enough to prove
dim(αUi ∩βU j) ≤1 when i ̸= j or α
β /∈Fq.
(4)
Let θ ∈αUi ∩βU j, where 1 ≤i, j ≤r. Then there exist u ∈Ui (i.e. Ti(u) = 0) and
v ∈U j (i.e. Tj(v) = 0) such that θ = αu = βv. Eliminating v by taking v = α
β u and
hence solving the system Ti(u) = 0 and Tj( α
β u) = 0 in terms of u, we obtain

(αqk
βqk )θi −(αq
βq )θ j

uq +

(αqk
βqk )γi −(α
β )γ j

u = 0.
(5)
The left hand side of equation (5) is a q−polynomial in terms of u. If we assume
that the left hand side is identically zero, then we obtain a contradiction with (3)

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
49
after eliminating α and β in (5). Hence, the polynomial on the left hand side of
(5) can not be identically zero. Conclusively, the fundamental theorem of algebra
implies (4).
□
Remark 3 Let T (x) ∈Fq N [x] be a subspace polynomial and U be the set of all
roots of T (x). We can determine another subspace U ⊆Fq N associated with T (x)
as follows.
u ∈U ⇔T (x) =

xq −
1
uq−1 x

◦Q(x)
for some q−polynomial Q(x) over Fq N , where ◦denotes the composition of poly-
nomials. This space can be also characterized by
u ∈U ⇔uq is a root of T (x) := (α0x)qk + · · · + (αk−1x)q + x,
where
T (x) = xqk + αk−1xqk−1 + · · · + α0x.
Here, U is called the adjoint space of U (see [24, Theorem 14, 15 and 16]
for the proofs of these facts). Therefore, corresponding to a code C obtained
in Theorem 2, we can construct another code C using the polynomials Ti(x) =
γ qk
i xqk + θqk−1
i
xqk−1 + x instead of Ti(x) in Theorem 2. Both C and C have the
same parameters. We call C the adjoint code of C .
The following corollary, as a particular case of Theorem 2, shows that we can
construct cyclic subspace codes including up to (qn −1) orbits.
Corollary 1 If θi = γ q
i for all 1 ≤i ≤r in Theorem 2, then (3) is satisﬁed. If more-
over γi and γ j are conjugate as γi = γ ql
j
for some i, j and l, then Ui = U ql
j and
hence Ni = N j.
Proof The inequality (3) holds clearly when θi = γ q
i for all 1 ≤i ≤r in Theorem 2.
Nowletθi = γ q
i forall1 ≤i ≤r,andγi = γ ql
j forsomei, j andl.Takeu ∈U ql
j ,then
u = vql forsomev ∈U j.Hence, Tj(v) = Tj(uq−l) = 0 whichimpliesthat Ti(u) = 0.
In that way, we see that Ti(u) = 0 and so U ql
j ⊆Ui. It can be shown similarly that
Ui ⊆U ql
j . Conclusively Ui = U ql
j and hence Ni = N j.
□
Remark 4 A particular case of Corollary 1, the r = n and γi = γ qi case for some
primitive element γ of Fqn for all 1 ≤i ≤n, was given in [1].
Remark 5 What is done in Corollary 1 is to pick some (up to qn −1) full length
orbits satisfying the following.
• The minimum distance in an orbit is ≥2k −2,
• The minimum distance between any two orbits is ≥2k −2.

50
K. Otal and F. Özbudak
At this point, it is natural to ask for the number of all full length orbits, i.e. the size
of the pool we pick orbits from. The next theorem from [6] answers this question.
Before stating it, we recall some basic deﬁnitions and facts:
• Möbius function μ over the set of positive integers is given by
μ(n) =
⎧
⎨
⎩
1
if n = 1,
(−1)r if n is a product of r distinct primes ,
0
if n is divisible by a square of a prime .
• Gaussian coefﬁcient (or q-binomial coefﬁcient) is deﬁned by
N
k

q
:=
k−1

i=0
q N −qi
qk −qi =
k−1

i=0
q N−i −1
qk−i −1 .
The size of Gq(N, k) is actually
N
k

q.
Theorem 3 ([6]) Let d be a positive integer dividing both N and k. The number of
orbits in Gq(N, k) of size q N −1
qd−1 is
qd −1
q N −1

t:d|t and t| gcd(N,k)
μ(t/d)
N/t
k/t

qt.
(6)
The following corollary demonstrates the approximate density of the orbits used
in Corollary 1 in the set of all orbits. Similar approximations can be found also in
[18].
Corollary 2 Let r ≤qn −1 for some n dividing N as in Corollary 1. Also let s be
the number of positive integers dividing gcd(N, k). The ratio of the number of orbits
in the code obtained by Corollary 1 to the size of the whole set of full length orbits
is approximately
r
sq(N−k−1)(k−1) .
Proof Taking d = 1 in Theorem 3, we see that there are s terms in the sum of (6),
and the absolute value of each one is less than or equal to
N
k

q
q−1
q N −1. On the other
hand, Corollary 1 gives r orbits. Hence the proportion is
r
s
N
k

q
q−1
q N −1
≈
rq N−1
sqkN−k(k−1)
2
−k(k+1)
2
=
r
sq(N−k−1)(k−1) .
□
Remark 6 Corollary 2 says that we pick only a small amount of orbits in Corollary
1 especially when N is large and k is close to N/2. Also, the s and r (and so n)
numbers play an important role.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
51
2.2
Generalization to Other Small Minimum Distances
Theorem 2 can be generalized for the codes of other minimum distances as in the
following corollary.
Corollary 3 Consider r polynomials
Ti(x) := xqk + γs,ixqs + · · · + γ1,ixq + γ0,ix ∈Fqn[x],
1 ≤i ≤r
satisfying
• γ0,i ̸= 0 for all 1 ≤i ≤r,
• there exist 0 ≤l1 < l2 ≤s such that
– gcd(l1,l2) = 1,
– l2 −l1 divides k −l2,
– γl2,i ̸= 0 and γl1,i ̸= 0 for all 1 ≤i ≤r,
– for all 1 ≤i ≤r, we have
γl1,i
γl1, j
̸=
 γl1,i
γl1, j
( γl2,i
γl2, j
)−1
M
,
where
M = qk−l1 −1
ql2−l1 −1.
Also let
• Ni be the degree of the splitting ﬁeld of Ti, for 1 ≤i ≤r,
• Ui ⊆Fq Ni be the kernel of Ti, for 1 ≤i ≤r,
• N be a multiple of lcm(N1, . . . , Nr).
Then the code C ⊆Gq(N, k) given by
C =
r
i=1
{αUi : α ∈F∗
q N }
is a cyclic code of size r q N −1
q−1 and of minimum distance 2k −2s.
Proof The proof is similar to the proof of Theorem 2. There are a few things to notice
about the extra assumptions:
• We want qk−l1−1
ql2−l1−1 to be an integer, so we should have “l2 −l1 divides k −l1” or
equivalently “l2 −l1 divides k −l2”.
• We want Ui to be a full length orbit for all 1 ≤i ≤r. Notice that U is Fqt−linear
if and only if the subspace polynomial of U is a qt−polynomial. Hence we
should take gcd(k −l2,l2 −l1,l1) = 1 to obtain only q−polynomials. The “l2 −

52
K. Otal and F. Özbudak
l1 divides k −l2” property above implies that gcd(k −l2,l2 −l1,l1) = 1 if and
only if gcd(l1,l2) = 1.
□
Remark 7 In case s > 1, we can choose the elements γ j,i ∈Fqn freely, for j /∈
{0,l1,l2}. So r can be as many as qn(s−1)(qn −1) if l1 = 0, and qn(s−2)(qn −1)2
otherwise. Case s = 1, l1 = 0 and l2 = 1 is Theorem 2 in particular.
Remark 8 In case s > 1, if there exists an integer i such that 1 < i ≤s and i divides
k, then we can insert also degenerate orbits into the code. In that way we can improve
Corollary 3 further. We prefer to illustrate this further improvement by only an
example below.
Example 1 Let k = 6 and s = 3. For some positive integer n, consider r1 polyno-
mials
xq6 + γ3,ixq3 + γ2,ixq2 + γ1,ixq + γ0,ix ∈Fqn,
1 ≤i ≤r1
as in Corollary 3 by taking l1 = 0 and l2 = 1. Using them, we can construct a cyclic
code C1 of size up to q2n(qn −1) q N1−1
q−1 and of minimum distance ≥2k −2s = 6 for
some suitable N1.
Consider r2 polynomials
xq6 + γ2,ixq2 + γ0,ix ∈Fqn,
1 ≤i ≤r2
satisfying
• γ0,i ̸= 0 and γ2,i ̸= 0 for all 1 ≤i ≤r2,
•
γ0,i
γ0, j ̸=

γ0,i
γ0, j ( γ2,i
γ2, j )−1M2 when i ̸= j,
where M2 = qk−1
q2−1. Using them in Theorem 2, we can construct a cyclic code C2 of
size up to (qn −1) q N2−1
q2−1 and of minimum distance ≥2k −2s = 6 for some suitable
N2.
Consider r3 polynomials
xq6 + γ3,ixq3 + γ0,ix ∈Fqn,
1 ≤i ≤r3
satisfying
• γ0,i ̸= 0 and γ3,i ̸= 0 for all 1 ≤i ≤r3,
•
γ0,i
γ0, j ̸=

γ0,i
γ0, j ( γ3,i
γ3, j )−1M3 when i ̸= j,
where M3 = qk−1
q3−1. Using them in Theorem 2 again, we can construct a cyclic code
C3 of size up to (qn −1) q N3−1
q3−1 and of minimum distance ≥2k −2s = 6 for some
suitable N3.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
53
Now consider r′
2 polynomials
xq6 + γ3,ixq3 + γ2,ixq2 + γ0,ix ∈Fqn,
1 ≤i ≤r′
2
satisfying
• γ0,i ̸= 0, γ2,i ̸= 0 and γ3,i ̸= 0 for all 1 ≤i ≤r′
2,
•
γ2,i
γ2, j ̸=

γ2,i
γ2, j ( γ3,i
γ3, j )−1M′
2 when i ̸= j,
where M′
2 = qk−2−1
q−1 . Using them in Corollary 1, we can construct a cyclic code C ′
2
of size up to (qn −1)(qn −1) q N2−1
q−1
and of minimum distance ≥2k −2s = 6 for
some suitable N ′
2.
Clearly C1, C2, C ′
2 and C3 are disjoint (recall the uniqueness of subspace polyno-
mials), and the minimum distance between any two of them is greater than or equal
to 6 again. Therefore, we can construct a code C := C1 ∪C2 ∪C ′
2 ∪C3 of size up to
q2n(qn −1)q N −1
q −1 + (qn −1)(qn −1)q N −1
q −1 + (qn −1)q N −1
q2 −1 + (qn −1)q N −1
q3 −1
and of minimum distance 6, where N is a multiple of lcm(N1, N2, N ′
2, N3).
2.3
Possible Values for the Length Parameter
Notice that parameter N in Theorem 2 is not chosen freely, it is depending on some
elements in Fqn. Accordingly, some N values can not be achievable.
In [35] it was conjectured that there exists a cyclic code of size q N −1
q−1 and of
minimum distance 2k −2 in Gq(N, k), for all positive integers N and k such that
k ≤N/2. In [13] it was proved by an exhaustive search that there are no cyclic
codes with parameters N = 8, k = 4 and q = 2; i.e. the conjecture is not true when
N = 2k.
In [1] the authors give an approach to determine a set of possible N values. Their
proof is given by considering Fq N0 which is the splitting ﬁeld of T (x) = xqk + xq +
x ∈Fq[x]. Here, the set of inﬁnitely many N values is N0N := {N0, 2N0, . . .}. Hence
the proof can be completed using the proof of Theorem 2 taking n = 1, r = 1 and
γ1 = 1.
Remark 9 When q > 2, the construction of a set of possible N values given in [1]
can be improved so that the set of possible N values is denser. It can be done by
taking the polynomials xqk + a1xq + a0x over Fq for all non-zero a1 and non-zero
a0 instead of taking only xqk + xq + x.
Proof Let T (x) := xqk + a1xq + a0x for some non-zero a1 and a0 in Fq. Let U
be its kernel in the splitting ﬁeld Fq N0 . It is easy to show that dim(αU ∩βU) ≤

54
K. Otal and F. Özbudak
1 when α
β /∈Fq, as in the proof of Theorem 2. Later on, we take another polynomial
T ′(x) by using another pair (a′
1, a′
0) and obtain N ′
0. Taking the union N0N ∪N ′
0N, we
obtain an opportunity to enlarge the set of possible N values. Then, we take another
pair (a′′
0, a′′
1) and so on.
□
We think that this basic observation is worth emphasizing because of its usefulness
that can be seen in the following example.
Example 2 Let q = 5 and k = 3. If we consider only T (x) = xqk + xq + x, then
we obtain N0 = 62. That is, N values can be chosen from 62N. In addition, by
considering xqk + xq + 4x we obtain 31N. Similarly, if we consider xqk + xq + 2x,
then we obtain 24N. By trying other non-zero couples, we get 31N ∪24N ∪20N as
a sample space for N.
Now,werecallsometoolsthatwecanusetofactorizesomelinearizedpolynomials
in an easier way.
Deﬁnition 1 [19, Deﬁnition 3.58] The polynomials
l(x) :=
N

i=0
αixi and L(x) :=
N

i=0
αixqi
over Fq N are called q−associates of each other. More speciﬁcally, l(x) is the con-
ventional q−associate of L(x) and L(x) is the linearized q−associate of l(x).
Lemma 1 ([19, Theorem 3.62]) Let L1(x) and L(x) be q−polynomials over Fq with
conventional q−associates l1(x) and l(x) respectively. Then L1(x) divides L(x) if
and only if l1(x) divides l(x).
Lemma 2 ([19, Theorem 3.63]) Let f (x) be irreducible over Fq and let F(x) be
its linearized q−associate. Then the degree of every irreducible factor of F(x)/x is
equal to the order of f (x).
Remark 10 The construction of the set of possible N values can be improved in the
following way: Factorize the conventional q-associate t(x) = xk + x + 1 and ﬁnd
the orders of its irreducible factors, then take the least common multiple of these
orders and thus determine N. In this way, the factorization cost can be decreased
signiﬁcantly.
The proof of Remark 10 is straightforward from Lemmas 1 and 2. In addition,
Remarks 9 and 10 can be combined to obtain larger sets in easier ways. We illustrate
the efﬁciency of Remark 10 by the following example.
Example 3 Letq = 5 and k = 3 again. Instead of factorizing T (x) = x125 + x5 + x,
we can easily factorize t(x) = x3 + x + 1, it is actually irreducible since it has
no roots in F5, and its order can be only in {e ∈N : e|(53 −1) and e ≥k} =
{4, 31, 62, 124}. Notice that t(x) does not divide x4 −1 and x31 −1 but divides
x62 −1, thus we ﬁnd N0 = 62 easily.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
55
3
Construction of Maximum Rank Distance Codes
Note that chapter “Codes Endowed with the Rank Metric” provides some essential
information about the analysis of rank metric codes in vector and matrix representa-
tion. In this section we just focus on the various constructions of MRD codes using
the linearized polynomial representation.
Let f (x) ∈Fqn[x] be a q−polynomial of q−degree at most n −1. Let {δ1, δ2,
. . . , δn} and {ε1, ε2, . . . , εn} be two ordered bases of Fqn over Fq. Then, for any
α ∈Fqn we have
f (α) = f (c1δ1 + c2δ2 + · · · + cnδn)
= c1 f (δ1) + c2 f (δ2) + · · · + cn f (δn)
=
 f (δ1) f (δ2) . . . f (δn)  c1 c2 . . . cn
t
= [ε1 ε2 . . . εn]
⎡
⎢⎢⎢⎣
f (δ1)ε1 f (δ2)ε1 . . . f (δn)ε1
f (δ1)ε2 f (δ2)ε2 . . . f (δn)ε2
...
...
...
...
f (δ1)εn f (δ2)εn . . . f (δn)εn
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
c1
c2
...
cn
⎤
⎥⎥⎥⎦
(7)
for some ci ∈Fq, for 1 ≤i ≤n; where f (δi)ε j denotes the coefﬁcient of ε j when
f (δi) is written as a linear combination of ε1, . . . , εn, for all 1 ≤i, j ≤n. Let
F denote the matrix given by F = [ f (δi)ε j] j,i ∈Fn×n
q
. Notice that there is a one
to one correspondence between f and F with respect to the ﬁxed ordered bases
{δ1, δ2, . . . , δn} and {ε1, ε2, . . . , εn}, also we have rank(F) = rank( f ). Moreover,
the algebra Fn×n
q
with the matrix addition and the matrix multiplication corresponds
to the algebra
Ln := {α0x + α1xq + · · · + αn−1xqn−1 : α0, . . . , αn−1 ∈Fqn}
with the addition and the composition of polynomials modulo xqn −x, respectively.
Let f (x) = n−1
i=0 αixqi ∈Ln and let {δ1, δ2, . . . , δn} given above be a normal
basis. Also take εi = δi for all i = 1, . . . , n. Then, the correspondence f ↔F above
implies the correspondence f ↔Ft, where f is given by f (x) = n−1
i=0 αqi
n−ixqi
mod xqn −x and the subscript is for modulo n. Here, f is called the adjoint of f .
Consider the algebra Ln as the ambient space instead of the algebra Fn×n
q
while
studying on rank metric codes. In that way, we can inherit the equivalence notion as
follows. Let C and C ′ be non-empty subsets of Ln, then C and C ′ are equivalent if
and only if there exist g1, g2, g3 ∈Ln such that g1(x) and g2(x) are invertible, and
C ′ = g1(x) ◦C ◦g2(x) + g3(x)
:= {g1(x) ◦f (x) ◦g2(x) + g3(x)
mod xqn −x : f (x) ∈C }, or
C ′ = g1(x) ◦
C ◦g2(x) + g3(x)
:= {g1(x) ◦f (x) ◦g2(x) + g3(x)
mod xqn −x : f (x) ∈C },
(8)

56
K. Otal and F. Özbudak
where the ◦operation denotes the composition. Notice also that, if C is closed under
addition, then the minimum distance d(C ) of C is indeed the minimum non-zero
rank of the elements in C .
In this section, we introduce all MRD codes in the literature. Before that, we give
a very useful lemma that efﬁciently works to construct new MRD codes.
Lemma 3 ([14])
Let
f (x) = α0x + α1xq + · · · + αlxql ∈Fqn[x]
be
a
q−
polynomial of q−degree l, where 0 < l < n. If Normqn/q(αl) ̸= (−1)nkNormqn/q
(α0), then dim(ker( f )) ≤l −1.
3.1
Linear MRD Codes
The ﬁrst examples of MRD codes were naturally linear ones. The largest family
including all known linear MRD codes can be stated as follows.
Theorem 4 ([20, 31]) Let n, k, s, h ∈Z+ satisfying gcd(n, s) = 1 and k < n −1.
Let η ∈Fqn such that Normqn/q(η) ̸= (−1)nk. Then the set
Hn,k,s(η, h) := {α0x + α1xqs + · · · + αk−1xqs(k−1) + ηαqh
0 xqsk : α0, α1, . . . , αk−1 ∈Fqn}
is a linear MRD code of size qnk and minimum distance n −k + 1.
The codes constructed in Theorem 4 are called generalized twisted Gabidulin
codes (or brieﬂy GTG codes). The main tool used to prove the bound of minimum
rank distance of such codes is Lemma 3. Some subclasses of this family can be listed
as follows.
• The η = 0 and s = 1 case: Gabidulin codes, ﬁrstly given in [5, 12, 30].
• The η = 0 case: Generalized Gabidulin codes, ﬁrstly given in [15].
• The s = 1 case: Twisted Gabidulin codes, ﬁrstly given in [31]. A special case was
also discovered independently in [25].
Classiﬁcation of Hn,k,s(η, h) under the equivalence given in (8) is dependent on
parameters.Forexample,non-GabidulinexamplesofgeneralizedGabidulincodesdo
not appear for 1 ≤n ≤4. Similarly, the smallest non-Gabidulin example of linear
MRD codes for k = 2 is H3,2,1(2, 1). Notice also that there are no examples of
linear codes which are not generalized Gabidulin when q = 2. We give the following
theorem as an example of classiﬁcation of H4,2,1(η, 2) with respect to the proﬁle
of η.
Theorem 5 ([25]) Let η1, η2 ∈Fq4 with Norm(η1) ̸= 1 and Norm(η2) ̸= 1, then
H4,2,1(η1, 2) and H4,2,1(η2, 2) are equivalent if and only if
ηqi
1 = η2cq2−1 or η−qi
1
= η2cq2−1
for some c ∈Fq4 and i ∈{0, 1, 2, 3}.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
57
Proof (⇒) : Assume there are invertible q−polynomials A(x) = a0x + a1xq +
a2xq2 + a3xq3 and B(x) = b0x + b1xq + b2xq2 + b3xq3 in Fq4[x] and an invertible
map Fq4 × Fq4 →Fq4 × Fq4 given by (α0, α1) →(β0, β1) such that
α0x + α1xq + η1αq2
0 xq2 ≡A(x) ◦(β0x + β1xq + η2βq2
0 xq2) ◦B(x)
mod xq4 −x,
or
α0x + α1xq + η1αq2
0 xq2 ≡A(x) ◦(β0x + ηq2
2 β0xq2 + βq3
1 xq3) ◦B(x)
mod xq4 −x.
for all α0, α1 ∈Fq4. Then we should have
(the coefﬁcient of xq3) ≡0
mod xq4 −x, and
(the coefﬁcient of xq2) ≡η1(the coefﬁcient of x)q2
mod xq4 −x,
on the right hand side. This property implies a system of 16 equations with 8
unknowns a0, a1, a2, a3, b0, b1, b2, b3. Some algebraic manipulations on the solu-
tion of this system yield the result. Simultaneously, an invertible map Fq4 × Fq4 →
Fq4 × Fq4 given by (α0, α1) →(β0, β1) can be constructed.
(⇐) : In each case, suitable invertible A(x) and B(x) couples can be deter-
mined computationally. Also an invertible map Fq4 × Fq4 →Fq4 × Fq4 given by
(α0, α1) →(β0, β1) can be constructed simultaneously. For example, consider case
ηqi
1 = η2cq2−1 for some c ∈Fq4 and i ∈{0, 1, 2, 3}. Then A(x) = cxqi and B(x) =
xq4−i, which are clearly invertible, can be used to show the equivalence. Also we have
(α0, α1) = (cβqi
0 , cβqi
1 ).
□
Theorem 5 says that H4,2,1(η1, 2) and H4,2,1(η2, 2) are equivalent when
Norm(η1) = Norm(η2). However, we can have both equivalence and inequivalence
when Norm(η1) = Norm(η2)−1 as we can observe in the following example.
Example 4 Let q = 5 and Fq4 = Fq(γ ), where γ is a primitive element satisfying
γ 4 + γ 2 + 2γ + 2 = 0.
1. Let η1 = γ 39 and η2 = γ 273. Then Norm(η1) = 3 and Norm(η2) = 2. Here,
η−1
1
= η2cq2−1 for c = γ 26. Hence H4,2,1(η1, 2) and H4,2,1(η2, 2) are equiva-
lent according to Theorem 5.
2. Let η1 = γ 39 and η2 = γ 253. Then Norm(η1) = 3 and Norm(η2) = 2, that is,
Norm(η1) = Norm(η2)−1. However, ηqi
1 ̸= η2cq2−1 for all c ∈Fq4 and i ∈Z.
Therefore, H4,2,1(η1, 2) and H4,2,1(η2, 2) are not equivalent according to Theo-
rem 5.

58
K. Otal and F. Özbudak
3.2
Additive MRD Codes
Consider case q = qu
0 for some integer u > 1 and a prime power q0. A set of
q−polynomials, i.e. a rank metric code, can be Fq0−linear but does not have to
be Fq−linear. We can observe this situation in the following example.
Example 5 Consider case q0 = 2, u = 2, n = 2. Let F4 = F2(ω) where ω2 + ω +
1 = 0, and F42 = F4(ζ) where ζ 2 + ζ + ω = 0. Then the set
{αx + (ωα + ωα2 + ω2α4 + ω2α8)x4 ∈F42[x] : α ∈F42}
is an MRD code with d = 2. Taking F4−bases (ε1, ε2) = (1, ζ) and (δ1, δ2) = (1, ζ)
as in (7), we can construct the matrix version of this code as follows.
C = SpanF2
 1 0
0 1

,
 1 1
1 0

,
 ω 0
1 ω

,
 ω ω
ω 1

as a subset of F2×2
4
. Remark that this code is not linear (over F4), because
ω
 1 0
0 1

=
ω 0
0 ω

/∈C .
At this point, we want to clarify a possible misunderstanding. Note that the ﬁeld
Fq = Fqu
0 is isomorphic to a suitable subset of Fu×u
q0 . This well-known fact is available
in [19, Sect.2.5]. Therefore, it seems that there is a natural and trivial lifting an MRD
code C ⊆Fn×n
q
with the minimum rank distance d over Fq to another MRD code
C ′ ⊆Fnu×nu
q0
with the minimum rank distance du over Fq0. It is actually true when
d = n as we can observe in Example 5 above, also there are some similar observations
in [3, 31] considering semiﬁelds. However, it is not true when d < n, as we can see
in the following proposition.
Proposition 2 Let q = qu
0 for some prime power q0 and integer u > 1. Let C ⊆
Fn×n
q
be an MRD code with d(C ) = d. Let C ′ ⊆Fnu×nu
q0
be the code obtained by
writing the entries of matrices from C in matrix representation. Then C ′ is a rank
metric code with d(C ′) = du. Moreover, C ′ is an MRD code if and only if d = n.
Proof The ﬁrst part is clear from the isomorphism. The fact about being MRD can be
observed from the inequality of sizes qn(n−d+1) ≤qnu(nu−du+1)
0
, where the equality
holds only when d = n.
□
Remark 11 When we lift a code C ⊆Fn×n
q
to another code C ′ ⊆Fnu×nu
q0
using
matrix representation, the distance function also changes from rank(A −B) to
rankFq0 (A −B) (i.e. the rank of A −B over Fq0). However, keeping it as rank(A −
B) does not change the value of the distance.
Now, we give a family of MRD codes which includes also non-linear but additive
MRD codes. Recall that Lemma 3 was used in [31] in order to construct Theorem

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
59
4. In case q is not a prime, it is possible to reinterpret this family by using another
basic observation, as demonstrated in the following theorem.
Theorem 6 ([26]) Let n, k, s, u, h ∈Z+ satisfying gcd(n, s) = 1, q = qu
0 and k <
n. Let η ∈Fqn such that Normqn/q0(η) ̸= (−1)nku. Then the set
Hn,k,s,q0(η, h) = {α0x + α1xqs + · · · + αk−1xqs(k−1)
+ηα
qh
0
0 xqsk : α0, α1, . . . , αk−1 ∈Fqn}
is an Fq0−linear (but does not have to be linear) MRD code of size qnk and minimum
distance n −k + 1.
Proof Code size and Fq0−linearity are clear from the deﬁnition. The trick related to
Lemma 3 about the norm of η can be observed from the transitivity of norm function
(see, for example, [19, Theorem 2.29]).
□
We call the code family obtained in Theorem 6 as additive generalized twisted
Gabidulin codes, or brieﬂy AGTG codes. Investigation of equivalence among such
codes and some further results are available in [26].
Remark 12 The Venn diagram of families of all known additive MRD codes has
been given in Fig.1. The conditions about the parameters can be summarized as
follows.
• When u divides h, an AGTG code is a GTG code.
• When u divides h and s = 1, an AGTG code is a TG code.
• When u divides h and η = 0, an AGTG code is a GG code.
• When u divides h, s = 1 and η = 0, an AGTG code is a Gabidulin code.
Now, we focus on the equivalence idea for additive codes. Consider f (x)pi :=
x pi ◦f (x) mod xqn −x, where p is the prime dividing q. If we expand f (x)pi to
the corresponding matrix as in (7), then we obtain the matrix B−1F pi A, where
A and B are invertible matrices satisfying [δ pi
1
. . . δ pi
n ]A = [δ1 . . . δn] and
[ε pi
1
. . . ε pi
n ]B = [ε1 . . . εn]. That is, f (x)pi does not correspond to F pi directly. In
fact, f (x)pi is not a q−polynomial when i ̸≡0 mod logp(q), so it corresponds to
another q−polynomial which has the matrix form B−1F pi A when we ﬁx the ordered
bases {ε1, . . . , εn} and {δ1, . . . , δn}. Therefore, in polynomial form, it makes sense
to write the equivalence between two additive codes C and C ′ as follows: C ≡C ′
if and only if
C ′ = g ◦C pi ◦h := {g(x) ◦f (x)pi ◦h(x)
mod xqn −x : f (x) ∈C }, or
C ′ = g ◦
C pi ◦h := {g(x) ◦f (x)pi ◦h(x)
mod xqn −x : f (x) ∈C }
for some invertible q−polynomials g, h ∈Fqn[x] and a non-negative integer i, even
if some elements are not q−polynomials.

60
K. Otal and F. Özbudak
Fig. 1 Venn diagram of all
known additive MRD code
families
AGTG
GTG
TG
GG
Gabid.
Notice that Hn,k,s,q0(η, h) is not linear when u̸ | h, hence an AGTG code is not
equivalent to a GTG code when u̸ | h. It is because, a code which is equivalent to a
linear code must be linear, too. When h is a multiple of u, Hn,k,s,q0(η, h) is clearly
linear, and equivalent to a GTG code by a new h := h/u. This idea can be summed
up and summarized as follows.
Proposition 3 Let C1, C2 ⊆Fn×n
q
be two additive rank metric codes and let Fq1, Fq2
be the largest subﬁelds of Fq such that C1 is Fq1−linear and C2 is Fq2−linear. If
q1 ̸= q2, then C1 and C2 are inequivalent.
In that way, when we compare two AGTG codes, we observe the following.
Corollary 4 Let q = qu1
1 = qu2
2 . Then Hn,k,s,q1(η, h) and Hn,k,s,q2(η, h) are not
equivalent when gcd(h, u1) ̸= gcd(h, u2).
3.3
A Family of Non-additive MRD Codes
Notice that being non-additive is not enough for a code to be new, since it can be
obtained by adding a ﬁxed non-zero element to each codeword in an additive code.
We call such codes afﬁne codes. However, there are also some non-additive codes
which are not afﬁne. In this section, we construct such a family of MRD codes. For
λ ∈Fqn \ {0}, let

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
61
πλ := {(αx) ◦(x + λxq + λ1+qxq2 + · · · + λ1+q+···+qn−2xqn−1) ◦(βx) :
α, β ∈Fqn \ {0}},
Jλ := {(αx) ◦(x −λxqn−1) ◦(βx) : α, β ∈Fqn \ {0}},
A1 := {αx : α ∈Fqn \ {0}},
A2 := {αxqn−1 : α ∈Fqn \ {0}}.
Lemma 4 ([7]) Consider the deﬁnitions and notations above, then πλ1 = πλ2 and
Jλ1 = Jλ2 when Norm(λ1) = Norm(λ2).
Let Norm(λ) = a, Lemma 4 allows us to use πa and Ja instead of using the
notations πλ and Jλ, respectively.
Theorem 7 ([7]) Let q > 2 and n ≥3. For any subset I of Fq \ {0, 1}, put I =

a∈I πa, I = 
b∈Fq\(I∪{0}) Jb and set
An,I := I ∪I ∪A1 ∪A2 ∪{0} ⊆Ln.
Then An,I is a non-additive and non-afﬁne MRD code of minimum distance n −1.
Remark 13 Notice that An,I is closed under multiplication by scalars, see [7] also
for the geometric interpretation of Theorem 7.
Remark 14 Theorem 7 is a generalization of the result in [4] which presents the
particular case A3;I.
3.4
Another Family of Non-additive MRD Codes
Lemma 3 was used to construct AGTG codes. In this section, as a second application
of Lemma 3 to construct new MRD codes, we provide a family of non-additive MRD
codes.
Theorem 8 ([27]) Let I be a subset of Fq, k and s be positive integers such that
k < n and gcd(n, s) = 1. Also let
C (1)
n,k,s,I :=
k−1

i=0
αi xqsi
mod xqn −x : α0, . . . , αk−1 ∈Fqn, Normqn/q(α0) ∈I

,
C (2)
n,k,s,I :=
 k

i=1
βi xqsi
mod xqn −x : β1, . . . , βk ∈Fqn, Normqn/q(βk) /∈(−1)n(k+1)I

.
Then Cn,k,s,I := C (1)
n,k,s,I ∪C (2)
n,k,s,I is an MRD code with d(Cn,k,s,I) = n −k + 1.
Proof Firstly notice that C (1)
n,k,s,I and C (2)
n,k,s,I are disjoint. We can observe it as follows.
In case 0 /∈I, the coefﬁcient of x of each element of C (1)
n,k,s,I is non-zero, whereas

62
K. Otal and F. Özbudak
the coefﬁcient of x of each element of C (2)
n,k,s,I is zero; therefore, C (1)
n,k,s,I and C (2)
n,k,s,I
do not have common elements. In case 0 ∈I, the coefﬁcient of xqk of each element
of C (2)
n,k,s,I is non-zero, whereas the coefﬁcient of xqk of each element of C (1)
n,k,s,I is
zero; therefore, C (1)
n,k,s,I and C (2)
n,k,s,I do not have common elements in this case, too.
In addition, recall that the norm function is a qn−1
q−1 to 1 function on the set of
non-zero elements of Fqn, and sends only zero to zero. Therefore, we observe that
|C (1)
n,k,s,I| = qn(k−1)|I|

qn−1
q−1

,
|C (2)
n,k,s,I| = qn(k−1) 
1 + (q −1 −|I|)

qn−1
q−1
 
if 0 /∈I, or
|C (1)
n,k,s,I| = qn(k−1) 
1 + (|I| −1)

qn−1
q−1
 
,
|C (2)
n,k,s,I| = qn(k−1)(q −|I|)

qn−1
q−1

otherwise. In both cases,
|C (1)
n,k,s,I| + |C (2)
n,k,s,I| = qnk,
which is equal to |Cn,k,s,I| since C (1)
n,k,s,I and C (2)
n,k,s,I are disjoint.
Now, we need to show that rank( f −g) ≥n −k + 1 for all f, g ∈Cn,k,s,I.
Let f (x) −g(x) = θ0x + θ1xq + · · · + θkxqk for arbitrary f, g ∈Cn,k,s,I. If f, g ∈
C (1)
n,k,s,I (or f, g ∈C (2)
n,k,s,I), then the q-degree of f (x) −g(x) and the coefﬁcient of x
implies that dim(ker( f (x) −g(x))) ≤k −1. If f ∈C (1)
n,k,s,I and g ∈C (2)
n,k,s,I (or vice
verse), then we have Normqn/q(θ0) ̸= (−1)nkNormqn/q(θk) since Normqn/q(θ0) ∈
I whereas Normqn/q(θk) ∈Fq \ (−1)nk I; i.e. dim(ker( f (x) −g(x))) ≤k −1 by
Lemma 3.
Combining these four cases, we deduce that rank( f (x) −g(x)) ≥n −(k −1) =
n −k + 1 for all f, g ∈Cn,k,s,I.
Conclusively, we have proved that |Cn,k,s,I| = qnk and d(Cn,k,s,I) = n −k + 1,
and hence Cn,k,s,I is an MRD code.
□
The code Cn,k,s,I given in Theorem 8 is a generalized Gabidulin code when q = 2
or I = {0} or I = Fq \ {0}. However, Cn,k,s,I is not equivalent to any additive MRD
codes when q > 2, I ̸= {0} and I ̸= Fq \ {0}.
Theorem 9 The code Cn,k,s,I given in Theorem 8 has the following properties.
1. If q = 2 or I = {0} or I = Fq \ {0}, then Cn,k,s,I is a generalized Gabidulin code.
2. If q > 2 and I ̸= {0} and I ̸= Fq \ {0}, then Cn,k,s,I is not an afﬁne code (i.e.,
not a translated version of an additively closed code).
When we take two arbitrary I and J subsets of Fq, we can not say anything about
the equivalence between Cn,k,s,I and Cn,k,s,J for now. However, we can see that they
are equivalent if J = Fq \ I, taking the adjoint polynomials into account.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
63
Corollary 5 Let I be a subset of Fq, k and s be positive integers such that k < n
and gcd(n, s) = 1. Then Cn,k,s,Fq\I is equivalent to Cn,k,s,I.
In addition, we can give another result about the equivalence between Cn,k,s,I and
Cn,k,s,J when both I and J include only one non-zero element.
Corollary 6 Let a and b be non-zero elements of Fq, k and s be positive integers
such that k < n and gcd(n, s) = 1. Then Cn,k,s,{a} is equivalent to Cn,k,s,{b}.
The Cn,k,s,I family in Theorem 8 is called partition codes.
Remark 15 Some properties of non-additive code families An,I constructed in The-
orem 7 and Cn,k,s,I constructed in Theorem 8 in comparison can be listed as follows.
• The construction of Cn,k,s,I works for all parameters, whereas the minimum dis-
tance of an An,I code is ﬁxed to be n −1.
• An An,I code is closed under multiplication by scalars, but a Cn,k,s,I code is not
always.
The following example provides partition codes which are not twisted (i.e., not
additively closed).
Example 6 • Let q = 5, n = 3, k = 2, s = 1 and I = {1, 2, 3}. Then,
C (1)
n,k,s,I = {α0x + α1xq : α0, α1 ∈Fqn and Norm(α0) ∈{1, 2, 3}},
C (2)
n,k,s,I = {β1xq + β2xq2 : β1, β2 ∈Fqn and Norm(β2) ∈{0, 1}}
and the resulting partition code Cn,k,s,I is not additively closed.
• Let q = 4, n = 5, k = 1, s = 2 and I = {1, u}, where u ∈Fq satisﬁes u2 + u +
1 = 0. Then,
C (1)
n,k,s,I = {α0x : α0 ∈Fqn and Norm(α0) ∈{1, u}},
C (2)
n,k,s,I = {β1xqs : β1 ∈Fqn and Norm(β1) ∈{0, u + 1}}.
Similarly, the resulting partition code is not additively closed.
Example 7 Let q = 7, n = 3, k = 2, s = 1 and I = {1, 2}. Then,
C (1)
n,k,s,I = {α0x + α1xq : α0, α1 ∈Fqn and Norm(α0) ∈{1, 2}},
C (2)
n,k,s,I = {β1xq + β2xq2 : β1, β2 ∈Fqn and Norm(β2) ∈{0, 1, 2, 3, 4}}.
Remember that the norm function is multiplicative. Therefore, the resulting partition
code Cn,k,s,I is not closed under multiplication by a scalar (and also not closed under
addition).

64
K. Otal and F. Özbudak
AGTG
Partition
GTG
GG
Gabid.
Fig. 2 Venn diagram of MRD code families
3.5
Some Concluding Remarks
We may give the Venn diagram of involvements for all MRD codes except Theorem
7 in Fig.2.
Singleton-like bound and Lemma 3 provide some connections with some certain
optimal sets as we can see in the following corollary.
Corollary 7 Let k be a positive integer. The size of the largest possible subset T ⊆
Fqn × Fqn satisfying
β1 −β2 = 0, or α1 −α2 = 0, or Norm(β1 −β2) ̸= (−1)nkNorm(α1 −α2)
for all (α1, β1), (α2, β2) ∈T is qn.
Example 8 Sheekey’s example from [31]: Let h be a positive integer and η ∈Fqn
satisfying Norm ̸= (−1)nk. Then
Tη,h := {(α, ηαqh) : α ∈Fqn}
is an optimal set given as in Corollary 7.
Example 9 Example from the construction in Theorem 8: Let I be a subset of Fq.
Then
TI := {(α, 0), (0, β) : α, β ∈Fqn, Norm(α) ∈I, Norm(β) /∈(−1)n(k+1)I}
is another optimal set given as in Corollary 7.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
65
As observed in Examples 8 and 9, ﬁnding new optimal sets as in Corollary 7 gives
an opportunity to construct new MRD codes. However, testing the equivalence with
the existing codes should be taken into account, too. There are several such sets that
can be found by computation easily, but most of their MRD codes were equivalent
to some known codes.
Acknowledgements The authors thank COST for the support under Action IC 1104. The ﬁrst
author thanks also TÜB˙ITAK for the support under the program B˙IDEB 2211.
References
1. E. Ben-Sasson, T. Etzion, A. Gabizon, N. Raviv, Subspace polynomials and cyclic subspace
codes. IEEE Trans. Inf. Theory 62, 1157–1165 (2016)
2. M. Braun, T. Etzion, P. Ostergard, A. Vardy, A. Wasserman, Existence of q-analogues of Steiner
systems. Forum Math. Pi 4, 14 (2016). https://doi.org/10.1017/fmp.2016.5
3. J. Cruz, M. Kiermaier, A. Wassermann, W. Willems, Algebraic structures of MRD codes. Adv.
Math. Commun. 10, 499–510 (2016)
4. A. Cossidente, G. Marino, F. Pavese, Non-linear maximum rank distance codes. Des. Codes
Cryptogr. 79, 597–609 (2016)
5. P. Delsarte, Bilinear forms over a ﬁnite ﬁeld, with applications to coding theory. J. Comb.
Theory A 25, 226–241 (1978)
6. K. Drudge, On the orbits of Singer groups and their subgroups. Electron. J. Comb. 9 (2002)
7. N. Durante, A. Siciliano, Non-linear maximum rank distance codes in the cyclic model for the
ﬁeld reduction of ﬁnite geometries, arXiv: 1704.02110 [cs.IT]
8. T. Etzion, Problems on q-analogs in coding theory, arXiv: 1305.6126 [cs.IT]
9. T. Etzion, E. Gorla, A. Ravagnani, A. Wachter-Zeh, Optimal Ferrers diagram rank-metric codes.
IEEE Trans. Inf. Theory 62, 1616–1630 (2016)
10. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inf. Theory 55, 2909–2919 (2009)
11. T. Etzion, A. Vardy, Error correcting codes in projective space. IEEE Trans. Inf. Theory 57,
1165–1173 (2011)
12. E.M. Gabidulin, The theory with maximal rank metric distance. Probl. Inform. Trans. 21, 1–12
(1985)
13. H. Gluesing-Luerssen, K. Morrison, C. Troha, Cyclic orbit codes and stabilizer subﬁelds. Adv.
Math. Commun. 25, 177–197 (2015)
14. R. Gow, R. Quinlan, Galois theory and linear algebra. Linear Algebra Appl. 430, 1778–1789
(2009)
15. A. Kshevetskiy, E.M. Gabidulin, The new construction of rank codes. In: Proceedings of the
IEEE International Symposium on Information Theory, 2105–2108 (2005)
16. A. Kohnert, S. Kurz, Construction of large constant dimension codes with a prescribed mini-
mum distance. Lect. Notes Comput. Sci. 5393, 31–42 (2008)
17. R. Kötter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54, 3579–3591 (2008)
18. A. Klein, K. Metsch, L. Storme, Small maximal partial spreads in classical ﬁnite polar spaces.
Adv. Geom. 10, 379–402 (2010)
19. R. Lidl, H. Niederreiter, Finite ﬁelds. In: Encyclopedia of Mathematics and its Applications,
vol. 20. Cambridge University Press, Cambridge (1997)
20. G. Lunardon, R. Trombetti, Y. Zhou, Generalized twisted Gabidulin codes, arXiv:
1507.07855v2 [math.CO]

66
K. Otal and F. Özbudak
21. P.J. Lusina, E.M. Gabidulin, M. Bossert, Maximum rank distance codes as space-time codes.
IEEE Trans. Inf. Theory 49, 2757–2760 (2003)
22. K. Marshall, A.-L. Horlemann-Trautmann, New criteria for MRD and Gabidulin codes and
some rank-metric code constructions. Adv. Math. Commun. (to appear)
23. K. Morrison, Equivalence of rank-metric and matrix codes and automorphism groups of
Gabidulin codes. IEEE Trans. Inf. Theory 60, 7035–7046 (2014)
24. O. Ore, On a special class of polynomials. Trans. Am. Math. Soc. 35, 559–584 (1933)
25. K. Otal, F. Özbudak, Explicit constructions of some non-Gabidulin linear MRD codes. Adv.
Math. Commun. 10, 589–600 (2016)
26. K. Otal, F. Özbudak, Additive rank metric codes. IEEE Trans. Inf. Theory 63, 164–168 (2017)
27. K. Otal, F. Özbudak, Some new non-additive maximum rank distance codes (submitted)
28. K. Otal, F. Özbudak, Cyclic subspace codes via subspace polynomials. Des. Codes Cryptogr.
https://doi.org/10.1007/s10623-016-0297-1
29. R. Overbeck, Structural attacks for public key cryptosystems based on Gabidulin codes. J.
Cryptol. 21, 280–301 (2008)
30. R.M. Roth, Maximum-rank array codes and their application to crisscross error correction.
IEEE Trans. Inf. Theory 37, 328–336 (1991)
31. J. Sheekey, A new family of linear maximum rank distance codes. Adv. Math. Commun. 10,
475–488 (2016)
32. D. Silva, F.R. Kschischang, Universal secure network coding via rank-metric codes. IEEE
Trans. Inf. Theory 57, 1124–1135 (2011)
33. D. Silva, F.R. Kschischang, R. Kötter, A rank-metric approach to error control in random
network coding. IEEE Trans. Inf. Theory 54, 3951–3967 (2008)
34. V. Tarokh, N. Seshadri, A.R. Calderbank, Space-time codes for high data rate wireless commu-
nication: performance criterion and code construction. IEEE Trans. Inf. Theory 44, 744–765
(1998)
35. A.-L. Trautmann, F. Manganiello, M. Braun, J. Rosenthal, Cyclic orbit codes. IEEE Trans. Inf.
Theory 59, 7386–7404 (2013)
36. Z.-X. Wan, Geometry of matrices. In: Memory of Professor L.K. Hua (1910–1985). (World
Scientiﬁc, Singapore, 1996)

Generalizing Subspace Codes to Flag Codes
Using Group Actions
Dirk Liebhold, Gabriele Nebe and María Ángeles Vázquez-Castro
Abstract In this chapter, we ﬁrst discuss structural properties of subspace codes
by applying group actions. We will see that the projective space, the Grassmannian
and the Schubert cells can be realized by looking at the orbits of certain linear
groups on matrices. The approach naturally leads to a generalization, where we
replace subspace codes with ﬂag codes. We describe and analyze a channel model
for these new codes that is similar to the operator channel introduced by Koetter
and Kschischang, give examples of ﬂag codes and discuss how to compute sphere
packing and sphere covering bounds for ﬂag codes.
1
Introduction
Network Coding is by now a well-established theoretical concept for transmission
of information over a network. The main difference compared to routing is that in a
network coded network, nodes cannot only forward network information units but
can also perform linear operations on them.
In their seminal work [7], Koetter and Kschischang described such a network
coded network as an operator channel for which input and output alphabets are given
as subspaces. Their results triggered a wide research into the ﬁeld of subspace codes,
see for example [1, 2, 4, 10, 11].
In this work, we will analyze the structure of subspace codes using group actions.
This will suggest ﬂag codes [9, 14] as a natural generalization of subspace codes and
D. Liebhold (B) · G. Nebe
RWTH Aachen, 52062 Aachen, Germany
e-mail: liebhold@mathb.rwth-aachen.de
G. Nebe
e-mail: nebe@math.rwth-aachen.de
M. Á. Vázquez-Castro
Department of Telecommunications and Systems Engineering, Universitat Autònoma de
Barcelona, Cerdanyola del Vallès, 08193 Barcelona, Spain
e-mail: angeles.vazquez@uab.cat
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_4
67

68
D. Liebhold et al.
we will therefore discuss such codes, introducing distance functions, cells, circles
and sphere packing bounds.
The chapter is structured as follows. In the ﬁrst section, we collect some results
on subspace codes. We describe the operator channel by Koetter and Kschischang
and the Ferrers diagram approach to the construction of subspace codes. Here we
also introduce the term of a cell in the set of subspaces. In the second section, we talk
about group actions. After brieﬂy introducing the concept and giving some examples,
we let certain groups act on matrices and on subspaces, giving us structural results.
For example, it will turn out that each cell is an orbit code in itself, that is an orbit
under a subgroup of the general linear group.1 These actions lead to the concept of
ﬂags, which we then discuss in the third section. We extend the notion of cells to
the set of ﬂags, discuss distance functions and show how the subspace case embeds
into this more general theory. In the fourth section, we brieﬂy discuss ﬂag codes and
show how to alter the network model to allow for a ﬂag to be transmitted rather than
a subspace. We also give sphere packing and sphere covering bounds in a special
case and discuss the ℓ−dp polynomial, which allows us to read off these bounds,
although an efﬁcient algorithm for its computation is not yet known.
2
Preliminaries
In this section, we collect known results on subspace codes. We will start by brieﬂy
describing the network model introduced in [7], and then discuss how to use matri-
ces when working with subspaces, ﬁnishing with the Ferrers diagram construction
introduced in [1]. We will focus on the basic concepts, which will be reviewed later
on with the help of group actions and generalized from subspaces to ﬂags. For a more
detailed overview see chapter “Constructions of Constant Dimension Codes”.
2.1
The Network Model for Subspace Codes
We consider the multicast scenario, having a single source and multiple receivers. A
ﬁnite ﬁeld Fq is ﬁxed and the source injects vectors (packets) of constant length m,
i.e. elements of Fm
q , into the network. These vectors are the information units that
are sent through the network to realize communication between the source and the
multiple receivers. We will denote such vectors as information packets. In-network
intermediate nodes form linear combinations (e.g. at random) of their received pack-
ets and forward the result and each receiver tries to recompute the original message
from his received vectors.
Now we assume that the process of communication consists of sending n con-
secutive packets. This set of packets is called “generation” in the related literature,
1For more details on orbit codes, see chapter “Constructions of Constant Dimension Codes” by
Horlemann-Trautmann and Rosenthal.

Generalizing Subspace Codes to Flag …
69
with n being the generation size. The channel model introduced in [7] is based on
the fact that having a generation of n packets x1, x2, . . . xn ∈Fm
q , what is left invari-
ant when forming linear combinations of these vectors is the corresponding vector
space, U := ⟨x1, x2, . . . , xn⟩. Assuming no errors or erasures, a receiver can recover
the subspace U – or rather a reduced basis of U – as soon as he has collected n
linearly independent vectors. Thus the operator channel given in [7] uses the set
P(Fm
q ) of all subspaces of Fm
q both as input and output alphabet. This set can be
further broken down into the Grassmannians, Grn(Fm
q ), the set of all subspaces of
dimension n of Fm
q .
As the codewords are full vector spaces in this setting, a bit-wise error count is
not reasonable; one should rather deﬁne errors and erasures dimension-wise. Assume
that the space U was sent and a receiver observes a space W. Then the network can
be modeled as an operator channel as follows [7]
W = Hk(U) ⊕E
where Hk(U) = W ∩U is a subspace of dimension k of U and E is some subspace
of W satisfying E ∩U = {0}. Therefore, Hk(U) is the part of U that was not erased
by the network and E is an error space. In this case, we say that the network has
introduced ρ := dim(U) −k erasures and t := dim(E) errors. Network erasures
model the loss of dimension of the original space, which is due to the fact that
the underlying protocols of the network erase packets, for example because they
are found corrupted. Network errors on the other hand model the injection into the
network of exogenous packets that were not contained in the original generation of
packets (that generate U). The distance function counting errors and erasures is the
Grassmannian distance,
ρ + t = dim(U + W) −dim(U ∩W).
As this is a distance function, it also obeys a triangle inequality. This allows to show
that given a set of subspaces with minimal distance dmin, a minimal distance decoder
can correct all errors and erasures as long as 2(ρ + t) < dmin [7, Theorem2].
2.2
Matricial Representation of Subspaces
In this subsection, we discuss the matricial representation of subspaces. We will
show how the structural properties of such a representation allow for both efﬁcient
computations and for the construction of subspace codes in matricial representation.
Most of the concepts for this subsection were introduced in [11] and reﬁned and
used for code construction in [1].
Given a subspace U ≤Fm
q , there are different ways to represent it. First, it is a
ﬁnite set, so one could write down the elements. However, if d = dim(U) this would
be a set of size qd, which is often too big to handle efﬁciently. A more efﬁcient way

70
D. Liebhold et al.
is by computing a basis of U. This would be a set of size d which can be computed
using Gaussian elimination. However, such a basis is not unique; the space U of
dimension d has d−1
i=0 (qd −qi) ordered bases. To achieve uniqueness, we look at
matrices in reduced row echelon form.
Deﬁnition 1 A matrix X ∈Fd×m
q
of full rank d ≤m is in reduced row echelon form,
if
1. For every 1 ≤i ≤d the ﬁrst non-zero entry in the ith row is a 1.
2. If ri is the column containing the ﬁrst non-zero entry of row i, then we have
r1 < r2 < . . . < rd.
3. The column ri does only contain the single 1 in row i; all other entries are zero.
The binary vector v(X) ∈Fm
2 deﬁned by v(X) j = 1 if j = ri for some 1 ≤i ≤d
and v(X) j = 0 otherwise, is called the identifying vector of X.
The reduced row echelon form is well-known as the form returned by the classical
Gaussian elimination. For a quick example consider
X =
⎛
⎝
1 1 0 1 1 0
0 0 1 0 1 0
0 0 0 0 0 1
⎞
⎠.
This matrix is in reduced row echelon form and the corresponding identifying vector
is given by v(X) = (1, 0, 1, 0, 0, 1). By using Gaussian elimination, every matrix
can be transformed to a matrix in reduced row echelon form. As this transformation
only forms linear combinations of the rows, the row space of X does not change.
Hence, by writing an arbitrary basis of U as rows into a matrix and performing
Gaussian elimination, we get that every vector space U has a unique ordered basis
in reduced row echelon form.
Deﬁnition 2 Let U ≤Fm
q be a subspace having dimension d. A matrix X ∈Fd×m
q
is called the basis matrix of U, if X is in reduced row echelon form and the rows of
X form a basis of U. The identifying vector of U is then deﬁned to be the identifying
vector of X, v(U) := v(X).
We now have a way to store the information of a subspace uniquely in a matrix.
Note that the Hamming weight of v(U) satisﬁes wH(v(U)) = dim(U). This will
become important when constructing codes later on.
To store the information of a subspace more compactly, we look at the free posi-
tions in X. As an example, take the matrix X from above, having as identifying vector
v(X) = (1, 0, 1, 0, 0, 1). Every matrix having this identifying vector is of the form
⎛
⎝
1 • 0 • • 0
0 0 1 • • 0
0 0 0 0 0 1
⎞
⎠

Generalizing Subspace Codes to Flag …
71
where • can be any element of Fq and we can hence conclude that there are exactly
q5 subspaces of Fm
q having this identifying vector.
Deﬁnition 3 For a given binary vector w ∈Fm
2 , the set of all subspaces of Fm
q having
this identifying vector is called the Schubert cell of w,
C(w) := {U ≤Fm
q | v(U) = w}.
In the case that the base ﬁeld might vary, we write Cq(w). To store all necessary
information for a subspace, we hence only need the identifying vector and the entries
for the free positions. The free positions in such a matrix form a Ferrers-diagram, in
the above case the diagram
• • •
• •
If all free entries are zero, we call the space the standard space with identifying vector
v, written as S(v).
Deﬁnition 4 Let n be a positive integer and n = n1 + n2 + . . . + nk be a partition of
n into positive integers, ordered such that n1 ≥n2 ≥. . . ≥nk. Then a representation
of this partition by patterns of dots such that the ith row has the same number of
dots as the ith term in the partition and in each row the dots are shifted to the right
is called a Ferrers diagram.
Note that such diagrams are closely related to Young tableaux. Taking a Ferrers
diagram, one can construct a Ferrers diagram rank metric code [1].
Deﬁnition 5 Let F be a Ferrers diagram with n rows and k columns. A subspace
C ≤Fn×k
q
is called a Ferrers diagram rank metric code with respect to F, if every
matrix in C has zeros in the positions where F has no dots.
The distance function on such a matrix code is called the rank metric. For two
matrices A, B it is deﬁned as dr(A, B) := rk(A −B). We have seen that a subspace
U of Fm
q can be uniquely described through its identifying vector v(U) and a matrix
A with corresponding Ferrers diagram. Given an identifying binary vector v and the
corresponding matrix A, the subspace U := ℓ(v, A) is called the lift of w and A. An
important relation regarding the distances was shown in [11].
Lemma 1 Let v ∈Fn
2 and let A, B be matrices for the Ferrers diagram induced by
v. Then d(ℓ(v, A), ℓ(v, B)) = 2dr(A, B).
Thus the rank distance gives us the subspace distance as long as we are in the
same cell. To illustrate some ideas, we prove this lemma for the special case of
v = 1k0m−k = (1, 1, . . . , 1, 0, 0, . . . , 0). For given matrices A, B, the basis matrices
for the two subspaces U := ℓ(v, A) and W := ℓ(v, B) will be (Ik A) and (Ik B) and
the sum U + W is the row space of

72
D. Liebhold et al.
Ik B
Ik A

.
Using Gaussian elimination, we reduce this matrix to
Ik
B
0 A −B

and as dim(U + W) is the rank of this matrix, we see that
dim(U + W) = k + rk(A −B).
The well-known formula
dim(U + W) = dim(U) + dim(W) −dim(U ∩W)
now also allows us to compute dim(U ∩W), giving d(U, W) = 2dr(A, B)
in the end.
In general, given two vector spaces U and W by a matrix in reduced row echelon
formorbyanidentifyingvectorandamatrix,computingtherepresentationofU + W
can be done efﬁciently by Gaussian elimination. A representation for U ∩W can be
obtained similarly using Zassenhaus’ algorithm.
2.3
Subspace Codes
Above, we saw that every subspace has an identifying vector and a Ferrers diagram.
Here, we will discuss a construction from [1], where a certain set of vectors is
prescribed and the problem of ﬁnding good Ferrers diagram rank metric codes is
tackled for every cell separately.
First, we ﬁx some notations. A subset C ⊆P(Fm
q ) is called a subspace code. The
minimal distance of C is deﬁned as
dmin(C ) := min{d(U, W) | U ̸= W ∈C }.
We say that C is a (m, logq(|C |), dmin) subspace code. Furthermore,
• if every space in C has the same dimension, we say that C is a constant
dimension code.
• if every space in C has the same identifying vector, we say that C is a
single cell code.
Note that every code is a disjoint union of constant dimension codes and every
constant dimension code is a disjoint union of single cell codes. The most common
example of a single cell code (see for example [7, Example1]) has as identifying

Generalizing Subspace Codes to Flag …
73
vector v = 1k0n−k, the corresponding matrices are often taken from an MRD code.
When using a subspace code for transmission, the size of C gives a bound on how
muchinformationcanbeencoded.However,havingabigcodedoesnotautomatically
mean that much information can be sent at once; one would also need efﬁcient
encoding. The same holds for the distance. A big minimal distance theoretically
allows for good error correction in the sense that a minimal distance decoder can
correct all ρ erasures and t errors as long as 2(ρ + t) < d (see [7] for more details),
but a minimal distance decoder is not efﬁcient in general.
We have already seen that having two subspaces in the same cell, the distance is
determined by the rank distance of the corresponding matrices. Having two subspaces
in different cells, the identifying vectors give a bound on the distance.
Lemma 2 Let U, W ≤Fm
q be subspaces and u, w ∈Fn
2 their corresponding identi-
fying vectors. Then d(U, W) ≥dH(u, w).
Thus, given a minimal distance d and the task to construct a constant dimension
subspace code with dimension k achieving this minimal distance with a big size,
we ﬁrst choose a constant weight code C ⊆Fn
2 with Hamming distance d, the so
called skeleton code. For every vector v ∈C, we then construct a Ferrers diagram
rank metric code with minimal distance (in the rank metric) at least d/2. As the size
of a cell is strongly related to how far the ones in the identifying vector are to the
left, a skeleton code chosen for example in a lexicographic way leads to good results.
Finding big codes with a given Ferrers diagram is harder. An upper bound on the
size of such a code was given in [1, Theorem1] and codes achieving this bound were
constructed in many cases (see for instance [4, 10]) and properties of such maximal
codes were also discussed (e.g. in [2]). However, the question if this bound is always
achievable and the search for a general construction always achieving this bound are
still open.
Furthermore, even if these codes are very big, they do not always allow for efﬁcient
encoding and decoding. Using results from [1], one can reduce these problems to
the question of ﬁnding efﬁcient encoding and decoding algorithms for the skeleton
code and for every rank metric code used. A big class of important rank metric codes
for which efﬁcient algorithms are known (see for example [11]) are Gabidulin codes
[3], but not all Ferrers diagram constructions are based on such codes.
3
Group Actions
The above matricial representations of subspaces and constructions are related to the
structural properties of the input and output alphabet of the network, the set P(Fm
q )
of all subspaces of Fm
q . We propose to use group actions to identify further structural
properties that can be relevant for subspace codes and its possible generalization.
A group is a non-empty set of elements G together with a composition rule

74
D. Liebhold et al.
◦: G × G →G,
such that for all a, b, c ∈G we have
• Associativity: a ◦(b ◦c) = (a ◦b) ◦c,
• a neutral element 1 ∈G, satisfying 1 ◦a = a ◦1 for all a ∈G,
• an inverse element a−1, satisfying a ◦a−1 = a−1 ◦a = 1.
Classical examples for groups are the general linear group GL(V ) of a vector
space V , the set of all invertible linear maps from V into itself, and Sm, the set of
all permutations on m points. A group G is said to act (from the left) on a set Ω if
there is a map ∗: G × Ω →Ω satisfying 1 ∗ω = ω and g ∗(h ∗ω) = (g ◦h) ∗ω
for all ω ∈Ω and all g, h ∈G. Similarly, one can also deﬁne the action on the
right. For example the two groups mentioned above come with a natural action:
GL(V ) acts on V by applying a map to a vector and Sm acts on a set of m points
by applying a permutation. Other actions are for example the multiplication in the
group itself, setting ∗:= ◦and Ω := G, or the conjugation in the group, where we
set ∗: G × G →G, g ∗h = ghg−1.
The acting groups induce structural properties in the sets acted upon, such as a
partition of the elements of the set into orbits. For an element ω ∈Ω, the orbit of ω
under G is deﬁned as
G ∗ω := {g ∗ω | g ∈G}.
The set of all orbits, denoted by O, is a partition of Ω, being in the same orbit is an
equivalence relation on Ω and an action having only a single orbit is called transitive.
In order to understand the structural properties of the set given by the orbits, one looks
at invariants.
Deﬁnition 6 Let G be a group that acts on a set Ω, let O = {G ∗ω | ω ∈Ω} be
the set of orbits and I a set. A map ϕ : Ω →I is called an invariant for the group
operation if ϕ is constant on the orbits, that is ϕ(gω) = ϕ(ω) for all g ∈G and all
ω ∈Ω. In this case the invariant induces a map
Φ : O →I, G ∗ω →ϕ(ω)
and the invariant is called separating if Φ is injective.
Note that the set I can often be reduced to make Φ surjective, in this case a sepa-
rating invariant classiﬁes the orbits. Every action has a separating invariant by taking
I = O and Φ = id. However, other invariants might be more useful in understand-
ing the structure of orbits or to quickly decide if two given elements lie in the same
orbit or not.
As an example, take the set Ω to be acted on as the projective space P(K m) and
the group GLm(K) acting on the right by applying a linear transformation to every
vector of a subspace U ∈P(K m):

Generalizing Subspace Codes to Flag …
75
P(K m) × GLm(K) →P(K m), (U, g) →{ug | u ∈U}.
The orbits under this action are the Grassmannians Grn(K m), the set of subspaces
of dimension n of K m, i.e. in this case we have
O ∼= {Grn(K m) | 0 ≤n ≤m}.
Therefore, a separating invariant of this action is the dimension of subspaces.
Now consider Ω as the matricial representation of subspaces of Fm
q , given as
rectangular matrices. In particular, let Fn×m,n
q
denote the set of n × m matrices of
rank n. Then the action on the right
Fn×m,n
q
× GLm(K) →Fn×m,n
q
, (M, g) →Mg
is transitive. Note that the rank of a matrix equals the dimension of its row space, and
thus we see how the abstract and matricial actions are related. However, there is not a
bijection between the elements of an orbit of the abstract action and the elements of
the orbit of the matricial action, as different matrices can have the same row space.
Another important action, relating matricial and abstract notion of subspaces, is
the action of GLn(Fq) on the left via matrix multiplication,
GLn(Fq) × Fn×m,n
q
→Fn×m,n
q
, (g, M) →gM
which induces orbits of matrices that can be represented by the same reduced row
echelon form (Fig.1). Thus the map that takes a matrix to its reduced row echelon
form is a separating invariant of this action. But also the orbit generated by the rows
of the matrix can be used as a separating invariant. Therefore, there exists a bijection
between the elements of an orbit of the abstract action (i.e. subspaces) and the orbits
of the matricial action on the left (i.e. sets of matrices represented by a unique reduced
row echelon form). Note that in the matricial representation, similar to the action on
the left, we have an action on the right, giving us as invariants the column echelon
form and the column space – looking at rows rather than columns is a convention,
not a restriction.
To join all these actions together, we ﬁll a matrix of Fn×m,n
q
with redundant rows,
that is linear combinations of the given rows, to get a quadratic m × m matrix. In
this manner, we can construct all m × m matrices. Looking at the action
(GLm(Fq) × GLm(Fq)) × Fm×m
q
→Fm×m
q
, ((g, h), M) →gMh−1,
what is left invariant is the rank of the matrices. A set of representatives of the orbits
are the rank normal forms
In 0
0 0

for 0 ≤n ≤m.

76
D. Liebhold et al.
Fig. 1 Graphical illustration of the orbits of the abstract action P(K m) × GLm(K) →P(K m)
and the correspondence of the elements of its orbits with the orbits of the matricial action GLn(Fq) ×
Fn×m,n
q
→Fn×m,n
q
We just saw that acting on both sides with the general linear group, only the rank
was left invariant. To get more structure, we introduce the groups of upper and lower
triangular matrices,
B := {X ∈GLm(Fq) | Xi j = 0 ∀i < j} and BT := {X ∈GLm(Fq) | Xi j = 0 ∀i > j}.
When acting with BT on P(Fm
q ) through
P(Fm
q ) × BT →P(Fm
q ), (U, b) →{ub | u ∈U},
the orbits turn out to be the Schubert cells.
Theorem 1 The orbits of BT on P(Fm
q ) are the Schubert cells Cq(v) introduced in
Deﬁnition3.
Proof Let v ∈Fm
2 be a vector having ones exactly at positions i1, i2, . . . in, U = S(v)
the corresponding standard space and X ∈BT a matrix with rows x1, x2, . . . , xm.
Then(xi1, xi2, . . . , xin) is a basis of U X, and as X is an upper triangular matrix, the
vector xi j has its ﬁrst non-zero entry at position i j for all j. Thus U X lies in the same
cell as U. On the other hand, every space W in the cell parametrized by v has a basis
(y1, y2, . . . , yn) where the ﬁrst non zero entry of y j is at position i j for all j. We can
thus deﬁne a matrix Y ∈BT having y j as rows in the desired positions and ﬁlled up
with rows of the identity matrix. Thus W = UY and hence U BT is exactly the cell
as claimed.
□

Generalizing Subspace Codes to Flag …
77
We thus see that the orbits of GLm(Fq) × BT on Fm×m
q
are in bijection to the cells,
in this case giving us
O ∼= {C(v) | v ∈Fm
2 }.
As these are indexed by binary vectors v ∈Fm
2 , let μ(v) ∈Fm×m
q
be a matrix in
reduced row echelon form having ones at positions indexed by v and zeros at any
other position (meaning that S(v) is the row space of μ(v)). Then our results up to
now tell us that for every M ∈Fm×m
q
, there is a unique v ∈Fm
2 , such that there exists
g ∈GLm(Fq) and b ∈BT with M = gμ(v)b. This can be written as
Fm×m
q
=
	
v∈Fm
2
GLm(Fq)μ(v)BT .
Operating with B from the left also gives interesting results when extending from
subspaces to ﬂags in the next section.
4
Flags
In this section, we introduce ﬂags and generalize the results on subspaces discussed
above. We start by deﬁning the basic terms.
Deﬁnition 7 A ﬂag Λ is a chain of distinct, non-trivial, proper subspaces of Fm
q ,
Λ = {V1 < V2 < . . . < Vk}.
The tuple (dim(V1), dim(V2), . . . , dim(Vk)) is called the type of the ﬂag and the ﬂag
is said to be a full (or ﬁne) ﬂag if it is of type (1, 2, 3, . . . , m −1).
By F = F(m, Fq) we denote the set of all ﬂags and by F f = F f (m, Fq) the
set of all full ﬂags. The group G := GLm(Fq) acts on F from the right by applying
a linear transformation to every single subspace in a ﬂag and the type is a separating
invariant of this action. Given a ﬂag Λ and a g ∈G, we write Λ · g for this action.
In the next two sections, we will focus on full ﬂags, returning to the general case
afterwards.
4.1
Cells and the Gauss–Jordan Decomposition
Here we try to transfer the concept of cells – indexed by pivot positions – to the set
of ﬂags. Note that our cells will not coincide with the Bruhat cells in the theory of
ﬂags (see for example [12]) but rather with the cells for subspaces. The Bruhat cells
will be called “circles” in this article and will be discussed in the next section.

78
D. Liebhold et al.
To talk about pivot positions, we ﬁrst need to deﬁne the matricial representation of
a ﬂag. Given a matrix X ∈G, the rows x1, x2, . . . , xm of X are linearly independent.
Thus the sequence of subspaces
⟨x1⟩< ⟨x1, x2⟩< . . . < ⟨x1, x2, . . . , xm−1⟩
forms a full ﬂag, which we will call Δ(X). Note that we do not need the last row of
X to deﬁne the ﬂag. If X = Im is the identity matrix, we write Δ0 := Δ(Im) and if
π ∈Sm has the corresponding permutation matrix Π ∈G, we write Δπ := Δ(Π),
thus Δ0 = Δid. The set A = {Δπ | π ∈Sm} is called the standard apartment and
plays an important role when looking at cells and circles. Given X, Y ∈G, we get
that Δ(X) · Y = Δ(XY), thus explaining why we consider the right action on ﬂags.
In fact, we can write Δ(X) = Δ0 · X for all X ∈G.
When discussing subspaces, we saw that Gaussian elimination does not change
the row space of a matrix. However, this is not true for the ﬂag represented by a
matrix in general, e.g. it is easy to see that interchanging two rows of a matrix will
always change the full ﬂag. The only operations in the Gaussian elimination that
leave the ﬂag unchanged are multiplications of rows and adding rows downwards,
that is adding row i to row j for j > i. These operations can be represented by
triangular matrices of the already introduced group B, giving us the following result.
Lemma 3 Let X ∈G. Then Y ∈G represents the same full ﬂag as X, if and only if
Y ∈BX = {bX | b ∈B}.
We thus see that operating with B on the left, what is left invariant is not only the
row space but the whole ﬂag. Furthermore, we can conclude that
Δ0 · b = Δ(b) = Δ(b · Im) = Δ0
for all b ∈B. In fact, B is the stabilizer of Δ0 under the action of G on F.
For subspaces, we have the reduced row echelon form as a normal form under the
operation of G. For ﬂags, we call a matrix X a basis matrix of a ﬂag Λ, if Λ = Δ(X)
and X is reduced downwards, that is the ﬁrst non-zero entry in each row of X is a one
and below all these ones, which we once again call pivots, X has only zeros. The two
big differences to the classical reduced row echelon form are that we do not enforce
zeros above the pivots and that the pivot positions do not have to be ordered. As an
example, consider a permutation π ∈Sm with permutation matrix Π ∈G. Then Π
is a basis matrix for Δπ.
As the basis matrix is exactly what we get when reducing only downwards, we
get that every ﬂag has a unique basis matrix, that is every B orbit on G (via left
multiplication) contains exactly one basis matrix. As all our matrices are invertible,
we have to have a pivot element in each row and each column. If pi denotes the
position of the pivot element in the ith row, we thus have that (p1, p2, . . . , pm) is a
permutation, an element of Sm (in list notation). This yields the deﬁnition of a cell
in the ﬂag case.

Generalizing Subspace Codes to Flag …
79
Deﬁnition 8 Let Λ be a ﬂag with basis matrix X whose pivot positions yield the
permutation π ∈Sm. Then we call π the identifying permutation of Λ, written as
π = perm(Λ). The cell of a permutation π ∈Sm is deﬁned as
C(π) := {Λ ∈F f | perm(Λ) = π}.
The biggest cell is C(id), having size qk with k = m(m −1)/2, the smallest cell
is C(w) where w : {1, 2, . . . , m} →{1, 2, . . . , m}, i →m −i + 1; this cell contains
only a single element. The general size of a cell will be computed in Sect.4.3. A
representation system for the cells is given by the standard apartment. Just as we did
with subspaces, one can show that the cells are exactly the orbits of BT ≤G under
the action of G on ﬂags described above, i.e. C(π) = Δπ · BT . Identifying π ∈Sm
with its permutation matrix, we get the well-known Gauss–Jordan decomposition
G =
	
π∈Sm
Bπ BT .
4.2
Circles, Sm-valued Distance and the Gauss–Bruhat
Decomposition
In the last section we saw that the action of BT on ﬂags yields the Gauss–Jordan
decomposition. Different from the subspace case, also the action of B on the right
yields interesting results for ﬂags. The following decomposition of G is called
the Gauss–Bruhat decomposition and will help us to analyze distance functions
on F f and F:
G =
	
π∈Sm
Bπ B.
Using that B = wBT w where w is deﬁned as above, this decomposition can also be
computed using Gaussian elimination. We now show how the orbits of B on F f
relate to distance functions.
Lemma 4 Let d : F f × F f →Z≥0 be a distance function that is invariant under
the operation of G, i.e. d(Λ, Γ ) = d(Λ · g, Γ · g) for all Λ, Γ ∈F f and all g ∈G.
Let further X, Y ∈G and π ∈Sm such that there exist b1, b2 ∈B with XY −1 =
b1Πb2. Then d(Δ(X), Δ(Y)) depends only on π.
Proof Write Δ(X) = Δ0 · X and Δ(Y) = Δ0 · Y. As d is assumed to be invariant
under the action of G, we have that
d(Δ(X), Δ(Y)) = d(Δ0 · (XY −1), Δ0) = d(Δ(b1Πb2), Δ0).

80
D. Liebhold et al.
Now b1 ∈B does not change the ﬂag represented by the matrix Πb2 and b2 ∈B
satisﬁes Δ0 · b−1
2
= Δ0 and hence we get
d(Δ(b1πb2), Δ0) = d(Δπ, Δ0 · b−1
2 ) = d(Δπ, Δ0)
and thus the value of d only depends on π as claimed.
□
The assumption that d should be invariant under the operation allows for more
structure to be exploited. In fact, both distance functions that we will discuss in
Sect.4.3 will have this property. Each such distance is thus made up of two parts: A
function f : Sm →Z≥0 and the function that we call the Sm-valued distance function,
deﬁned through
dSm(Δ(X), Δ(Y)) := π ∈Sm
if there exist b1, b2 ∈B such that XY −1 = b1πb2. As in this case we will have
dSm(Δ(Y), Δ(X)) = π−1, the function f should be invariant under taking inverses.
Furthermore, to guarantee that f ◦dSm has all properties of a distance function, it
should satisfy f (π) = 0 if and only if π = id and f (πϕ) ≤f (π) + f (ϕ) for all
π, ϕ ∈Sm.
The length and the depth are two such functions and will be discussed in
the next section.
Just as the Gauss–Jordan decomposition gave us the cells, the Gauss–Bruhat
decomposition gives us the circles.
Deﬁnition 9 For π ∈Sm, the π-circle around a ﬂag Λ is deﬁned as
Cπ(Λ) := {Γ ∈F f | dSm(Γ, Λ) = π}.
Taking as center Λ = Δ0, the circles around that ﬂag are exactly the B orbits on
F f and in this case, the standard apartment is once again a set of orbit representatives
through Cπ(Δ0) = Δπ · B. As we assumed the original distance d to be invariant
under the action of G, one should assume the same to be true for dSm. Indeed,
taking two matrices X, Y ∈G and corresponding ﬂags Δ(X), Δ(Y), we get the same
Sm-valued distance for Δ(X) · g = Δ(Xg) and Δ(Y) · g = Δ(Yg), due to the fact
that XY −1 = (Xg)(Yg)−1. Using this result and once again the relation B = wBT w,
we can show a relation between cells and circles.
Lemma 5 For every π ∈Sm we have C(π) = Cπw(Δw).
Proof Let Λ ∈C(π). Then there exists bT ∈BT such that Λ = Δπ · bT . Writ-
ing bT = wb′w for some b′ ∈B, we get Λ = Δπw · b′w. Thus Λ · w = Δπw · b′
has Sm-distance dSm(Λw, Δ0) = πw and thus dSm(Λ, Δw) = πw, hence giving us
Λ ∈Cπw(Δw). Retracing these steps, we also get the other inclusion and thus the
claimed equality.
□

Generalizing Subspace Codes to Flag …
81
4.3
Length and Depth of a Permutation and Corresponding
Distance Functions
The two functions on the symmetric group Sm that we introduce in this section are
the length and the depth. The length plays an important role when studying Sm as a
Coxeter group (see for example [12, 13]), but it also appears in other contexts. The
deﬁnition of the length is based on the fact that
S := {(1, 2), (2, 3), (3, 4), . . . , (m −1, m)}
is a generating set for the group Sm, that is every permutation can be constructed
by successively interchanging neighboring elements. The length of a permutation
π ∈Sm is then deﬁned as the length of a shortest word in S∗yielding π, written as
ℓ(π). From this deﬁnition we can immediately conclude the desired properties of a
function f given at the end of the last section: As every transposition (i, i + 1) is
self-inverse, we get ℓ(π) = ℓ(π−1). We further get ℓ(π) = 0 if and only if π = id
and given a word w1 ∈S∗for π and a word w2 ∈S∗for a permutation ϕ, we get
that w1w2 is a representation of πϕ (although not necessarily a shortest one). Not
immediately clear, but also important, is the fact that the permutation w, mapping i
to m −i + 1, is the unique longest element of Sm, having length m(m −1)/2.
A well-known way to compute a shortest word for a permutation π – given as a list
(π(1), π(2), . . . , π(m)) – is the bubble sort algorithm, as it only changes neighboring
elements. This fact yields the following formula for the length (see for instance [6]
for more details):
ℓ(π) =
m

i=1
|{1 ≤k ≤i | π(k) > π(i)}|.
This way to compute the length allows us to now introduce the depth, which looks
quite similar:
dp(π) :=
m

i=1
|{1 ≤k ≤i | π(k) > i}| =
m

k=1,k<π(k)
π(k) −k = 1
2
m

k=1
|π(k) −k|.
Unlike the length, which has been used for several centuries already, the depth
of a permutation received some attention only recently in [5, 8], whereas twice the
depth – called the sum of distances – was studied in [6].
Given the similar sum notation of the length and the depth, one might conjecture
a relation between these two functions. In [8], such a relation was found, namely for
all π ∈Sm we have
ℓ(π)
2
≤dp(π) ≤ℓ(π).

82
D. Liebhold et al.
We now introduce the corresponding distance functions on ﬂags, starting with the
length of a permutation. As in the generating set S, only neighboring elements are
interchanged in one step, we ﬁrst deﬁne neighboring ﬂags, calling two ﬂags
Λ = {V1 < V2 < . . . < Vm−1} and Γ = {W1 < W2 < . . . < Wm−1}
neighbors, if they differ in exactly one space. Using this deﬁnition, we construct a
graph on the set F f , joining two ﬂags by an edge if they are neighbors. A shortest
path from a ﬂag Λ to a ﬂag Γ in this graph is called a gallery between Λ and Γ , the
length of such a path is called the gallery distance of Λ and Γ . This distance is the
classically used distance when working with (full) ﬂags and it is well-known (see
for example [12, 13]) that this distance is invariant under the action of G and that
the gallery distance of Δ0 and Δπ is exactly ℓ(π).
If we look at ﬂags as a generalization of subspaces, we would like a distance
function that is deﬁned for all ﬂags (not only full ones) such that the distance of
two ﬂags of length one Λ = {U} and Γ = {W} is exactly the Grassmannian dis-
tance dim(U + W) −dim(U ∩W). The length function, however, is classically only
deﬁned for full ﬂags and ﬁnding a generalization to arbitrary ﬂags that is still easy
to compute seems to be difﬁcult. We thus take a different approach, generalizing the
Grassmannian distance to the set of all ﬂags. This yields the Grassmannian distance
on ﬂags, ﬁrst introduced in [9].
Deﬁnition 10 Let Λ = {V1 < V2 < . . . < Vk} and Γ = {W1 < W2 < . . . < Wn}
be two ﬂags. Fill the shorter one with Fm
q such that n = k and then deﬁne the
Grassmannian distance
dG(Λ, Γ ) :=
k

i=1
dim(Vi + Wi) −dim(Vi ∩Wi).
Following the proof from [7] that the Grassmannian distance for subspaces is a
distance, one can show that dG is a distance function. Note that dG can be extended to
a distance on the set of all sequences (not necessarily ordered as a ﬂag) of subspaces.
As the Grassmannian distance on subspaces is invariant under the operation of
G, so is the distance dG. The corresponding map on Sm is twice the depth, i.e.
dG(Δ0, Δπ) = 2 dp(π), the factor two coming from the fact that the Grassmannian
distance of two subspaces of the same dimension is always even; hence also a sum
over such values is.
Using the length, we can now also compute the size of a cell and a sphere in F f .
The size of a circle – what is called a Bruhat cell in the literature – is well-known
(see for example [12, 13]) to be
|Cπ(Λ)| = qℓ(π).

Generalizing Subspace Codes to Flag …
83
The size of a cell then follows from Lemma5 as
|C(π)| = qℓ(πw).
4.4
Non-full Flags
In this section, we brieﬂy translate the previous results to the case of non-full ﬂags,
taking ﬂags of length one as examples. We already mentioned before that ﬂags of
length one are basically subspaces; now we will see that the concepts of cells and
distance translate properly.
For full ﬂags, we looked at the stabilizer of the ﬂag Δ0, which we called B. Taking
the same approach here, we ﬁx a type T = (d1, d2, . . . , dk) and for a matrix X ∈G
we let ΔT (X) be the corresponding ﬂag of this type, i.e. we take the full ﬂag Δ(X)
and drop all spaces but the ones that have dimension di for some i. By dropping
these spaces, the stabilizer of the standard ﬂag of type T , ΔT (Im), gets bigger and
we get a so called standard parabolic group, which is the group of all block triangular
matrices, having block sizes di+1 −di. For example taking the type T = (n) and thus
ﬂags of length one, the stabilizer of ΔT (Im) is
Pn :=
A 0
B C

| A ∈GL(n, Fq), C ∈GL(m −n, Fq), B ∈F(m−n)×n
q

.
We can once again deﬁne the cell of a permutation for such ﬂags. However, different
permutations may yield the same cell. In fact, for a π ∈Sm we have that the permu-
tation matrix Π lies in Pn if and only if π maps {1, 2 . . . , n} ⊆{1, 2, . . . , m} onto
itself. Two permutations π, ϕ ∈Sm will give the same cell if and only if ΠΦ−1 ∈Pn.
We thus get that the number of cells for ﬂags of type T = (n) is
|Sm|
|Sn × Sm−n| =
m!
n!(m −n)! =
m
n

,
which is exactly the number of weight n vectors in Fm
2 . This once again shows that
the deﬁnition of a cell in the ﬂag case is a generalization of the deﬁnition in the
subspace case.
5
Flag Codes
In this section, we describe how to use ﬂags in a network coded network, deﬁne
basic properties of a ﬂag code and take a look at sphere packing and sphere covering
bounds.

84
D. Liebhold et al.
A set of ﬂags C ⊆F(Fm
q ) is called a ﬂag code. Similar to subspaces, we call
dmin := min{dG(Λ, Γ ) | Λ ̸= Γ ∈C }
the minimum distance of C and say that C is a (m, logq(|C |), dmin) ﬂag code.
Furthermore,
• if every ﬂag in C has the same type T , we say that C is a constant type code, if
T = (1, 2, . . . , m −1) is the type of full ﬂags, we say that C is a full ﬂag code.
• if C is a constant type code and every ﬂag lies in the same cell, we say that C is a
single cell code.
The last ingredient we need to analyze ﬂag codes is the rate of such a code. For
that, let dmax(C ) be the biggest dimension of a space in a ﬂag in C . Then only the
ﬁrst m −dmax rows of a basis matrix contain information on a ﬂag of C and hence
need to be sent, thus yielding a rate of
R(C ) :=
logq(|C |)
mdmax
.
If we take for example C = C(id) to be the biggest cell of full ﬂags, we have a rate
of 1/2. Taking C = F f , the set of all full ﬂags, the rate also converges towards 1/2
if we ﬁx m and increase q. On the other hand, ﬁxing q and looking at big m allows
for rates bigger than 1/2.
By introducing additional zeros in the biggest cell, we can get higher distances.
Take for example the set
Dk = {X ∈BT | Xii = 1 ∀i, Xi j = 0 ∀i < j ≤i + k}
of all strict upper triangular matrices having k secondary diagonals ﬁlled with zeros.
Then two different matrices of Dk always yield two different full ﬂags and the
corresponding ﬂag code has minimal distance 2(k + 1) and rate
(m −k)(m −k −1)
2m(m −1)
(see [9] for proofs). Furthermore, the set Dk forms a subgroup of BT , thus allowing
for easier computation of distances and structure. Error correction for example is
possible efﬁciently using this code. A similar construction is also possible in other
cells,allowingustofurtherextendthiscode.Toknowwhichcellstochoose,wewould
like a result on the distance between two cells, similar to the one on subspaces.
Lemma 6 Let Λ ∈C(π) and Γ ∈C(ϕ) be two full ﬂags. Then
dG(Λ, Δ) ≥2 dp(ϕ−1π).

Generalizing Subspace Codes to Flag …
85
Note that we use left convention, meaning that ϕ−1π is the permutation that maps
every i to ϕ−1(π(i)).
Proof Let Λ = {V1 < V2 < . . . < Vm−1} and Γ = {W1 < W2 < . . . Wm1}, and let
further 1 ≤i ≤m such that ϕ−1(π(i)) = j > i. Then Vi is the ﬁrst space in Λ
having a pivot element at position π(i) and W j is the ﬁrst space in Γ containing a
pivot at the same position. Thus we have Vk ̸= Wk for all i ≤k < j and as these
spaces have the same dimension, they hence have subspace distance at least two. As
we sum over all subspace distances to form the Grassmannian distance, we hence
get a distance of at least 2( j −i) in this case, in total giving us
dG(Λ, Δ) ≥2
n

i=1,ϕ−1(π(i))>i
ϕ−1(π(i)) −i,
which is exactly the deﬁnition of twice the depth of πϕ−1.
□
To see that this bound is tight, remember that Δπ ∈C(π) and Δϕ ∈C(ϕ) have
exactly distance 2 dp(ϕ−1π).
5.1
The Network Model for Flag Codes
In a network coded network, we assume a source to inject packets, that are then
linearly combined and forwarded by intermediate nodes. Looking at today’s net-
works (e.g. the Internet), there is, however, something else to exploit: a numbering
of packets. Assuming that we want to send a ﬂag Λ = {V1 < V2 < . . . < Vk} of type
(d1, d2, . . . , dk) through a network. This ﬂag is given to the transmitter in the form
of a basis matrix X and the transmitter then injects the rows of X into the network.
While doing so, the rows are numbered according to the current space Vi in the ﬂag,
that is the ﬁrst d1 rows get the number one, the next d2 −d1 rows get number two, etc.
An intermediate node now forms and forwards linear combinations in a desired way
(e.g. at random) and marks the outgoing vector with the highest number of vectors
used in the linear combination. Therefore, a vector with number i always lies in Vi
and hence also in all Vj with j ≥i. Thus collecting enough vectors with different
numbers, a receiver can reconstruct X and hence also Λ. Just as constant dimension
subspace codes simplify this process in the subspace setting, constant type ﬂag codes
allow the receiver in this setting to know when he has enough vectors. To assure that
every receiver gets enough vectors, a proper choice of type and transmission protocol,
one that might take into account the numbering of packets, is necessary.
To introduce errors and erasures, assume that the ﬂag Λ as above was sent. The
receiver reconstructs the spaces Wi generated by all received vectors with number
j ≤i and thus gets a stuttering ﬂag Γ = {W1 ≤W2 ≤. . . ≤Wk}, the term stuttering
meaning that some of these spaces might coincide. Similar to the operator channel
model in [7], we say that an erasure occurred at some point i, if Wi does not contain

86
D. Liebhold et al.
all of Vi. An error occurred, if Wi contains elements that do not lie in Vi. Writing
Wi = Hri(Vi) ⊕Ei, where Hr(Vi) = Wi ∩Vi is a subspace of Vi of dimension
ri and Ei is some subspace of Wi satisfying Ei ∩Vi = {0}, we thus have di −ri
erasures and dim(Ei) errors in the ith space. Then the total number of erasures is
ρ := k
i=1 di −ri and the total number of errors is t := k
i=1 dim(Ei). As these
deﬁnitions and the Grassmannian distance on ﬂags are both generalizations of the
constructions for subspaces, we get the following result, analog to [7, Theorem2].
Theorem 2 Using a ﬂag code C of minimal distance dmin for transmission, a mini-
mal distance decoder can correct all errors and erasures, as long as 2(ρ + t) < dmin.
The
proof
of
this
generalization
uses
the
triangle
inequality
and
can be found in [9].
5.2
Sphere Sizes and the ℓ−dp Polynomial
In this section, we compute some sphere packing and sphere covering bounds for
full ﬂags and compare them to the bounds on subspaces computed in [7]. To do so,
remember that a π-circle around a full ﬂag has exactly size qℓ(π) where ℓdenotes
the length function on Sm. A sphere of radius 2t with regard to the Grassmannian
distance thus contains

π∈Sm,dp(π)≤t
qℓ(π)
ﬂags. To compute sphere sizes, it would therefore be helpful to be able to efﬁciently
compute the ℓ−dp polynomial
Pm(x, y) :=

π∈Sm
xℓ(π)ydp(π).
Computing this polynomial once, we can then read off sphere sizes by dropping
certain powers of y and then inserting (x, y) = (q, 1). However, an efﬁcient way to
compute this polynomial or a closed form is not yet known.
Using computed values of Pm, we can give sphere packing and sphere covering
bounds for full ﬂag codes and compare them to subspace codes. The following ﬁgure
shows the bounds for full ﬂag codes in the space F8
2 and compares them to the bounds
on constant dimension subspace codes of dimension 4 computed in [7]. Note that
ﬂag codes are able to achieve minimal distances that are not reachable by subspace
codes (Fig.2).
We will now collect some properties of this polynomial. The special value
Pm(x, 1) is well-known to be the generating function of the length,
Pm(x, 1) =
m

i=1
xi −1
x −1 .

Generalizing Subspace Codes to Flag …
87
Fig. 2 Sphere packing and sphere covering bounds
For the generating function of the depth, Pm(1, y), a continued fraction was found
recently in [5]. We will here show a nice property, regarding the alternating distribu-
tion of the depth.
Lemma 7 We have
Pm(−1, y) =

π∈Sm
sign(π)ydp(π) = (1 −y)m−1.
Proof We will use the deﬁnition
dp(π) = 1
2
m

k=1
|π(k) −k|.
The ﬁrst equality is clear, as the length is one well-known way to compute the
signum of a permutation. We thus show the second equality by induction over m.
For m = 1 there is only the identity, having signum 1 and depth 0. Thus assume that
the claim holds for m −1. Let H ≤Sm be the stabilizer of the point m. Then H acts
on {1, 2, . . . , m −1} and is isomorphic to Sm−1. We have

88
D. Liebhold et al.
Sm =
m
	
i=1
(i, m)H,
where (i, m) denotes the transposition interchanging i and m and (m, m) stands for
the identity. Now let i < m −1, let h ∈H be arbitrary and set f := (i, m)h and
g := (i, m)(i, m −1)h. We will now compute twice the depth of f and g, seeing
that they are the same.
2 dp( f ) :
Let j := h−1(i). Then f ( j) = m, f (m) = i and f (x) = h(x) for all other values
x. Thus we have to add these two terms for f and subtract the original ones for h,
getting
2 dp( f ) = 2 dp(h) + |m −j| + |i −m| −|i −j| −|m −m|
= 2 dp(h) + (m −j) + (m −i) −|i −j|
= 2(dp(h) + m −max(i, j)).
2 dp(g) :
Set j := h−1(i) and k := h−1(m −1). Then g( j) = m −1, g(k) = m, g(m) = i
and g(x) = h(x) for all other values of x. Thus we get
2 dp(g) = 2 dp(h) + |m −1 −j| + |m −k| + |i −m| −|i −j| −|m −1 −k|
= 2 dp(h) + (m −1 −j) + (m −k) + (m −i) −(m −1 −k) −|i −j|
= 2(dp(h) + m −max(i, j)).
As for i < m −1 we always have that (i, m −1) ∈H is a non-trivial transpo-
sition, the elements f and g are different, but in the same class (i, m)H. As they
have the same depth but opposite signum, the corresponding terms cancel out when
taking the sum. We thus only have to look at the cases i = m −1 and i = m. For
i = m we get the subgroup H itself, thus by induction hypothesis this case con-
tributes (1 −y)m−2 to the polynomial. For i = m −1 and h ∈H, we once again can
set f := (m −1, m)h and j := h−1(m −1). Using that m −1 ≥j, we then get
2 dp( f ) = 2 dp(h) + (m −j) −(m −1 −j) + (m −(m −1)) −(m −m) = 2 dp(h) + 2
and thus dp( f ) = dp(h) + 1. This gives us that the set (m −1, m)H contributes
−y(1 −y)m−2 to the sum, as the signum of every element of H switches and the
depth is increased by one. In total we thus get
Pm(−1, y) = −y(1 −y)m−2 + (1 −y)m−2 = (1 −y)m−1.
□

Generalizing Subspace Codes to Flag …
89
References
1. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inform. Theory 55(7), 2909–2919 (2009)
2. T. Etzion, E. Gorla, A. Ravagnani, A. Wachter-Zeh, Optimal Ferrers diagram rank-metric codes.
IEEE Trans. Inform. Theory 62(4), 1616–1630 (2016)
3. È.M. Gabidulin, Theory of codes with maximum rank distance. Problemy Peredachi Informatsii
21(1), 3–16 (1985)
4. E. Gorla, A. Ravagnani, Subspace codes from Ferrers diagrams. J. Algebra Appl. (to appear)
5. M. Guay-Paquet, T. Kyle Petersen, The generating function for total displacement. Electron.
J. Combin. 21(3), Paper 3.37, 13 (2014)
6. D.E. Knuth, The Art of Computer Programming: Sorting and Searching, vol. 3 (Addison-
Wesley, Reading, 1998)
7. R. Kötter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inform. Theory 54(8), 3579–3591 (2008)
8. T. Kyle Petersen, B. Eileen Tenner, The depth of a permutation. J. Comb. 6(1–2), 145–178
(2015)
9. D.Liebhold,G.Nebe,A.Vazquez-Castro,Networkcodingwithﬂags.Des.CodesandCryptogr.
(2017)
10. N. Silberstein, A.-L. Trautmann, Subspace codes based on graph matchings, Ferrers diagrams,
and pending blocks. IEEE Trans. Inform. Theory 61(7), 3937–3953 (2015)
11. D. Silva, F.R. Kschischang, R. Kötter, A rank-metric approach to error control in random
network coding. IEEE Trans. Inform. Theory 54(9), 3951–3967 (2008)
12. T.A. Springer, Linear Algebraic Groups, 2nd edn., Modern Birkhäuser Classics (Birkhäuser,
Boston, 2009)
13. D.E. Taylor, The Geometry of the Classical Groups, vol. 9, Sigma Series in Pure Mathematics
(Heldermann Verlag, Berlin, 1992)
14. M.A. Vazquez-Castro, A geometric approach to dynamic network coding, in 2015 IEEE Infor-
mation Theory Workshop - Fall (ITW) (2015), pp. 207–211

Multi-shot Network Coding
Diego Napp and Filipa Santana
Abstract The seminal paper of Koetter and Kschischang [11] introduced coding
concepts for errors and erasures in a random network coding setting and since then
has opened a major research area in communication technology. Here, the network is
allowed to change very quickly, which is the case in many mobile applications. The
problem is suitably modeled via the operator channel, which makes a very clear con-
nection between network coding and classical information theory. However, coding
can also be performed over multiple uses of the network, whose internal structure
may change at each shot, giving rise to the so-called multi-shot network coding.
Although the potential of using multi-shot network coding was already observed in
[11], only recently this more involved approach have been investigated. The general
idea stems from the fact that creating dependencies among the transmitted codewords
of different shots can improve the error-correction capabilities. A very natural way to
impose correlation of codewords(subspaces) over time is by means of convolutional
codes, originating the notion of rank metric convolutional codes. In this Chapter we
review some of the main results and ideas of multi-shot network coding, propose
new approaches and point out some avenues for future research.
1
Introduction
In many multicast communication networks, like the internet, wireless communi-
cation and cloud computing, a transmitter sends packets to several users through
a series of intermediate nodes. In 2008, a seminal and award winning paper [11]
provided the mathematical foundations for the case where the topology of the net-
D. Napp (B) · F. Santana
CIDMA - Center for Research and Development in Mathematics and Applications,
Department of Mathematics, University of Aveiro, Campus Universitario de Santiago,
3810 -193 Aveiro, Portugal
e-mail: diego@ua.pt
F. Santana
e-mail: vfssantana@ua.pt
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_5
91

92
D. Napp and F. Santana
work is unknown and the nodes perform a random linear combination of the packets
received and forward this random combination to adjacent nodes. If one considers
the transmitted packet as columns of a matrix with entries in a ﬁnite ﬁeld Fq, then the
linear combinations performed in the nodes are columns operations on this matrix.
If no errors occur during the transmission over such a network, the column space of
the transmitted matrix remains invariant. In such an scenario the problem of reliable
communication is suitably modeled via the operator channel, which makes a very
clear connection between network coding and classical information theory. The oper-
ator channel can be seen as a standard discrete memoryless channel with input and
output alphabets given by the projective space P(Fn
q), i.e., the set of all possible vec-
tor subspaces of the vector space Fn
q. To achieve a reliable communication over this
channel, matrix codes are employed forming the so-called rank metric codes [26].
Rank metric codes such as Gabidulin codes are known to be able to protect packets
in such a scenario. We call these codes one-shot codes, as they use the (network)
channel only once.
However, coding can also be performed over multiple uses of the network as it
has been recently shown by several authors, see for instance [2, 13, 16, 20, 28]. The
general idea stems from the fact that creating dependencies among the transmitted
codewords (subspaces) of different shots can improve the error-correction capabili-
ties of the code. In order to increase the error-correcting capabilities of a block code in
one single shot, one necessarily needs to increase the ﬁeld size or the packet size and
this might not be optimal or impossible in many applications and consequently one
must create dependencies across multiple nodes to approach the channel capacity.
Thus, multi-shot codes constitute an attractive class of codes for such situations.
There are mainly two approaches for building multi-shot codes: one using con-
catenation of codes and other using rank metric convolutional codes. In [20], a type
of concatenated n-shot codes (n ≥1) was proposed based on a multilevel code. In
[17], a concatenation scheme was presented using a Hamming metric convolutional
code as an outer code and a rank metric code as an inner code. A different type of
concatenation was introduced in [13] where the authors use codes that layer both
Maximum Sum Rank (MSR) codes and Gabidulin in order to achieve the streaming
capacity for the Burst Erasure Channel.
Apart from concatenated codes, another very natural way to spread redundancy
across codewords is by means of convolutional codes [3, 7, 10, 15, 18]. Adapting
this class of codes to the context of networks gave rise to rank metric convolutional
codes and interestingly there have been little research on these codes, see [2, 12, 13,
28]. The work in [28] was pioneer in this direction by presenting the ﬁrst class of
rank metric convolutional codes together with a decoding algorithm able to deal with
errors, erasures and deviations. However, the results were only valid for unit memory
convolutional codes and in [2, 12] (see also the references therein) an interesting
and more general class of rank metric convolutional codes was introduced to cope
with network streaming applications. For a more general theoretical framework to
rank metric convolutional codes, see [16] and for more information on new investi-
gations on rank metric codes properties the reader is also referred to chapters “Codes
Endowed with the Rank Metric” and “Constructions of Cyclic Subspace Codes and
Maximum Rank Distance Codes”.

Multi-shot Network Coding
93
In this multi-shot setting a new distance, called sum rank distance, was introduced
as a generalization of the rank distance used for one-shot network coding. This new
distance has proven to be the proper notion in order to deal with delay-free networks,
i.e., assuming that the natural delay in the transmission (due, for instance, to the
delay of the nodes) is so small that can be disregarded. In this work we show that
in order to handle networks with delays, a new metric needs to be introduced: the
generalized sum rank distance.
Finally, we note that in the last years others papers have also appeared dealing
with convolutional network coding using very different approaches [8, 22]. These
codes do not transmit over the operator channel and therefore are not equipped with
the rank metric.
In this chapter, we aim to provide a general overview of the area of multi-shot
codes for network coding and indicate some open problems and avenues for further
research. We will review the approaches and results proposed so far and present
some new alternatives such as a new metric that can be considered as an analog of
the column distance of Hamming convolutional codes. We note that by no means it
is a complete review as important issues such as decoding are not included.
Notation: Denote a ﬁnite ﬁeld with q elements by Fq. For a given basis of Fq M
viewed as an M vector space over Fq, any element of Fq M can be seen as a vector in
FM
q . Analogously, any vector x of length n over Fq M can be regarded as an element
X in FM×n
q
, the set of M × n matrices over Fq. We commit a harmless abuse of
notation and deﬁne the rank of a vector x ∈Fn
q M as the rank of x as an M × n matrix
over Fq. If each column of X represents a packet of length M then so it does xi, for
i ∈{1, . . . n}, where x = (x1, . . . , xn). Throughout the paper we denote the vectors
in lower-case type whereas a matrix is identiﬁed using upper-case type. We use them
interchangeably if no confusion arises.
2
Preliminaries
In order to state more precisely the results to be presented we introduce in this section
the necessary material and notation on standard theory of (one-shot) network coding
and convolutional codes.
2.1
One-Shot Network Coding
2.1.1
The Network Model
Let v ∈Fn
q M (or equivalently V ∈FM×n
q
) represents the n packets of length M to be
sent through the network at one time instance. We shall follow the approach proposed
in [11, 26] and consider the operator channel for one shot given by

94
D. Napp and F. Santana
x = vA + z,
(1)
where x ∈Fn
q M represents the received packets, A ∈Fn×n
q
is the rank deﬁciency
channelmatrixand z ∈Fn
q M istheadditiveerror.Theadversariesofthematrixchannel
(1) come as rank deﬁciency of the channel matrix and as the additive error matrix.
The channel matrix A correspond to the overall linear transformations applied by the
network over the base ﬁeld Fq and it is known by the receiver (as the combinations
are carried over in the header bits of the packets). For perfect communications we
have that z = 0 and rank(A) = n, but failing and deactivated links may cause a rank
deﬁcient channel matrix. We call n −rank(A) the rank deﬁciency of the channel.
2.1.2
Rank Metric
A rank metric code C is deﬁned as any nonempty subset of FM×n
q
. A natural metric
for matrix codes is induced by the distance measure drank(V, W) = rank(V −W),
where V, W ∈FM×n
q
[11]. In the context of the rank metric, a matrix code is called
rank metric code.
The rank distance of a code C ⊂FM×n
q
is deﬁned as
drank(C) =
min
V,W∈C, V ̸=W drank(V, W).
Consider linear codes over Fq M and use k for the dimension of the linear code over
Fq M. To simplify presentation we will assume that M ≥n. In this case, for linear
(n, k) rank metric codes over Fq M the following analog of the Singleton bound holds:
drank(C) ≤n −k + 1.
A code that achieves this bound is called Maximum Rank Distance (MRD).
Gabidulin codes are a well-known class of MRD codes [6], see also [5, 9].
Although rank metric codes in FM×n
q
are usually constructed as block codes of
length n over the extension ﬁeld Fq M [11] a more general construction was considered
in [16]. Here, an (˜n × M, ˜k) rank metric code C ⊂F˜n×M
q
of rate ˜k/˜nM < 1 is seen
as an image of a monomorphism ϕ : F˜k
q →F˜n×M
q
(ϕ = ψ ◦γ is a composition of an
isomorphism ψ and a monomorphism γ ):
ϕ :F˜k
q
γ
−→
F˜nM
q
ψ
−→
F˜n×M
q
u 	−→v = uG 	−→V = ψ(v)
where G ∈F˜k×˜nM
q
and [Vi j] = vi+˜n j with 0 ≤i < ˜n and 0 ≤j < M.

Multi-shot Network Coding
95
In [16, Theorem 3.1] the following upper bound on the rank distance of an (˜n ×
M, ˜k) linear rank metric code was presented
drank(C) ≤˜n −
 ˜k −1
M

= ˜n −
 ˜k
M

+ 1.
2.2
Convolutional Codes
As opposed to block codes, convolutional encoders take a stream of information
bits and converts it into a stream of transmitted bits (by means of shift registers) and
therefore they are very suitable for streaming applications. Mathematically speaking,
a convolutional code C of rate k/n is an Fq M[D]-submodule of Fq M[D]n of rank k.
A full row rank matrix G(D) ∈Fq M[D]k×n with the property that
C = imFqM [D]G(D) =

u(D)G(D) | u(D) ∈Fk
q M[D]

,
is called a generator matrix. The degree δ of a convolutional code C is the maximum
of the degrees of the determinants of the k × k sub-matrices of one, and hence any,
generator matrix of C.
A rate k/n code C with degree δ is called an (n, k, δ)-convolutional code [15].
An (n, k) block code is an (n, k, δ) convolutional code with δ = 0.
We say that a generator matrix G(D) is basic (see, e.g., [23, 25]) if it has a
polynomial right inverse.1
Let wt(vi) be the number of the nonzero components of a vector vi ∈Fn
q M and
wt(v(D)) the Hamming weight of a polynomial vector v(D) = 
i∈N
vi Di deﬁned as
wt(v(D)) = 
i∈N
wt(vi).
An important distance measure for a convolutional code C is its free distance or
Hamming distance dH(C) deﬁned as
dH(C) = min {wt(v(D)) | v(D) ∈C and v(D) ̸= 0} .
Let v[0, j](D) = v0 + v1D + · · · + v j D j be the jth truncation of the codeword
v(D) = 
i∈N
vi Di ∈C.
1Using a basic generator matrix it allows to avoid catastrophic situations in which a sequence u(D)
with an inﬁnite number of nonzero coefﬁcients can be encoded into a sequence v(D) with a ﬁnite
number of nonzero coefﬁcients; this case would decode ﬁnitely many errors on the received code
sequence into inﬁnitely many errors when recovering the original information sequence.

96
D. Napp and F. Santana
Another important distance measure for a convolutional code C is the jth column
distance dc
j(C), given by the expression
d j
H(C) = min
	
wt(v[0, j](D)) | v(D) ∈C and v0 ̸= 0

.
This notion is related to the free distance dH(C) in the following way
dH(C) = lim
j→∞d j
H(C).
3
Multi-shot Network Coding
In this section we explain how to extend the classical theory of (one-shot) network
coding to the context of multi-shot network coding. In fact, this is possible as each
packet carries a label identifying the shot (or generation) to which it corresponds.
Despite the little research in the area, this possibility was already observed in the
seminal papers [11, 26].
3.1
Encoder and Decoder
The transmitter receives at each time instance t a source packet ut ∈Fk
q M (constituted
by a set of k packets) and a channel packet vt ∈Fn
q M (constituted by a set of n packets)
is constructed using not only ut but also previous source packets u0, . . . , ut−1.
A channel packet vt is sent through the network at each shot (time instance) t.
The receiver collects the packets xt as they arrive causally and tries to infer vt from
(x0, . . . , xt).
3.2
Channel Model
Following the operator channel in (1) at each shot t the received packets xt ∈Fn
q M are
constituted by corrupted packets z and linear combinations of the packets of vt and,
if there is delay in the transmission, also of combinations of the previous packets
v0, . . . , vt−1. Hence, we have
x[0, j] = v[0, j] A[0, j] + z
(2)
where x[0, j]=(x1, x2, . . . , x j), v[0, j]=(v0, v1, . . . v j) ∈Fn( j+1)
q M
, A[0, j]∈Fn( j+1)×n( j+1)
q
is a block upper triangular truncated channel matrix and z ∈Fn( j+1)
q M
the additive

Multi-shot Network Coding
97
error. So far this channel model has not been proposed nor addressed in the literature
in this generality and only the delay-free case has been considered, see [12] and
reference therein. In the delay-free case only combinations of packets of vt arrive
at time instance t and not of packets of vi, i < t and therefore in this case the rank
deﬁciency matrix A[0, j] is a block diagonal matrix.
3.3
Distances
The sum rank distance is the distance that has been widely considered for multi-
shot network coding and can be seen as the analog of the rank distance for one-shot
network coding. This distance was ﬁrst introduced in [20] under the name of extended
rank distance and is deﬁne as follows.
Let v = (v0, . . . , vt) and w = (w0, . . . , wt) be two t-tuples of vectors in Fn
q M. The
sum rank distance (SRD) between them is
dSR(v, w) =
t
i=0
rank(vi −wi).
Since the rank distance is a metric so it is the SRD and is obviously upper bound by
dSR(v, w) ≤(t + 1)(n −k + 1).
As we will see below, the SRD is a metric that can be used to fully characterize the
error-correctingcapabilitiesofmulti-shotcodesinthecontextofdelay-freenetworks.
For the general case we propose the following distance,
dGR(v, w) = rank(v −w) = rank((v0, . . . , vt) −(w0, . . . , wt)).
This is a straightforward generalization of the rank distance for one-shot network
codes but it is new in the context of multi-shot network codes. We call it generalized
rank distance (GRD). In the next section we will show that it is the proper metric
to deal with network that allows delays. Still, further research needs to be done to
understand this less investigated situation.
In the next two sections we present some of the approaches to deal with multi-shot
network coding.
4
Rank Metric Convolutional Codes
In the context of rank metric convolutional codes two different settings have been
proposed. Similarly as in the block code case, rank metric convolutional codes have
been typically constructed over the extension ﬁeld Fq M. However, a more general

98
D. Napp and F. Santana
framework was introduced in [16], where a rank metric convolutional code can be
deﬁned for any given rate over the base ﬁeld Fq.
4.1
General Framework
A rank metric convolutional code C ⊂F˜n×M
q
is deﬁned as the image of an homomor-
phism ϕ : Fq[D]˜k →Fq[D]˜n×M and written as a composition of a monomorphism
γ and an isomorphism ψ:
ϕ : Fq[D]
˜k
γ
−→Fq[D]˜nM
ψ
−→Fq[D]˜n×M
u(D) 	→v(D)=u(D)G(D) 	→V (D)
(3)
where G(D) ∈F˜k×˜nM
q
is a full row rank polynomial matrix, called generator matrix
of C, and V (D) = [Vi j[D]], such that Vi j(D) = vMi+ j(D).
The sum rank distance of a rank metric convolutional code C is deﬁned as
dSR(C) =
min
V (D),U(D)∈C,V (D)̸=U(D) dSR(V (D),U(D))
=
min
0̸=V (D)∈Crank

V (D)

.
In the next theorem authors establish the Singleton-like bound for rank metric
convolutional codes.
Theorem 1 ([16, Theorem 4.1]) Let C be a (˜n × M, ˜k, δ)-rank metric convolutional
code. Then the sum rank distance of C is upper bounded by
dsumrank(C) ≤˜n
δ
˜k

+ 1

−
⎡
⎢⎢⎢
˜k(

δ
˜k

+ 1) −δ
M
⎤
⎥⎥⎥
+ 1.
(4)
4.2
Usual Approach
Consider from now on the extension ﬁeld Fq M instead of Fq. This leads to the fol-
lowing deﬁnitions.
For an (n, k, δ)-convolutional code C and v(D) = v0 + v1D + v2D2 + · · · ∈C
we deﬁne its free sum rank distance as
dSR(C) = min

i≥0
rank(vi) | v(D) ∈C and v(D) ̸= 0

,

Multi-shot Network Coding
99
and its column sum rank distance as
d j
SR(C) = min

j

i=0
rank(vi) | v(D) ∈C and v0 ̸= 0

.
Moreover, based in the GRD we introduce a new distance for convolutional codes,
the generalized column rank distance, as follows:
d j
GR(C) = min
	
rank(v0, . . . , v j) | v(D) ∈C and v0 ̸= 0

.
Adapting (4) to the deﬁnitions considered in this paper, this bound reads as fol-
lows:
dSR(C) ≤(n −k)
δ
k

+ 1

+ δ + 1.
(5)
Note that this bound coincides with the so-called generalized Singleton bound of
(Hamming) (n, k, δ)-convolutional codes [21, 24]. Thus, the bound (5) could be
also derived from the fact that the rank distance is upper bounded by the Hamming
distance [6]. The problem of existence and construction of rank metric convolutional
codes whose free rank distance achieves the bound (5) remains open.
For the column SRD the following upper bound was presented in [14]:
d j
SR(C) ≤(n −k)( j + 1) + 1,
and moreover,

d j
SR(C) = (n −k)( j + 1) + 1

⇒

di
SR(C) = (n −k)(i + 1) + 1 for i = 0, . . . , j

.
In [28], concrete decoding algorithms for unit memory rank metric convolutional
codes were presented using another distance, namely the active rank distance. How-
ever, in [14], it was shown that this metric fails to determine the error-correcting
capabilities of rank metric convolutional codes with arbitrary memory and the col-
umn SRD needs to be considered. In fact, necessary and sufﬁcient conditions were
inferred to recover rank deﬁciencies within a given time interval in delay-free net-
works when no errors occur (i.e., when z = 0 in (2)).
Theorem 2 ([14, Theorem 2]) Let C be a (n, k, δ) rank metric convolutional code
and v(D) = v0 + v1D + · · · ∈C with v0 ̸= 0. Assume a delay-free transmission
and let A[0,T ] = diag(A0, . . . , AT ) represent the block diagonal truncated channel
matrix with Ai ∈Fn×n
q
, i.e., x[0,T ] = v[0,T ]A[0,T ] is the received set of packets with
xi = vi Ai, i = 0, 1, . . . , T . Note that in this case rank(A[0,T ]) = T
j=0 rank(A j).
Then, we can recover v0 if

100
D. Napp and F. Santana
dT
SR(C) > n(T + 1) −rank(A[0,T ]).
(6)
Theorem 2 illustrates how the column SRD can characterize the rank deﬁciency
correcting capabilities of a rank metric convolutional code in delay-free networks
within a time interval. The more column SRD a convolutional codes has the better
is its rank deﬁciencies correcting capabilities.
Constructive constructions of convolutional codes having maximum column SRD
proﬁle were also presented in [14] using a superregular matrix derived in [1]. These
constructions are not optimal as they require very large ﬁnite ﬁelds. The problem of
deriving optimal constructions remains an interesting open problem for research.
Motivated by streaming applications, rank metric convolutional codes tailor-made
to cope with burst of rank deﬁciency networks where studied in [13]. This can be
considered a generalization of the theory of burst erasure convolutional codes, from
a Hamming context to a network context. Concrete constructions of optimal rank
metric convolutional codes in this setting are not known yet.
The following example illustrates that, in the case the network has delays in the
transmission of packets, the previous theorem fails to characterize the rank deﬁciency
correcting capability of C.
Example 1 Let G(D) = G0 + G1D ∈F26[D]2×3 be a generator matrix of the con-
volutional code C ⊂F26[D]3, α a primitive element of F26 and
G0 =
1 0 0
1 α α2

, G1 =
 0
1
0
α3 α4 α5

.
It is easy to see that d1
SR(C) = 2 and that there exists a v(D) ∈C such that v[0,1] =
(1, 0, 0 | 0, 1, 0) ∈F6
26. Theorem 2 says that we can recover v0 if the 1th column SRD
of C is larger than the rank deﬁciency of a delay-free channel in the window [0, 1], i.e.,
ifn(T + 1) −rank(A[0,T ]) = 6 −rank(A[0,T ]) ≤1orequivalently,ifrank(A[0,1]) ≥
5. However, in presence of delays in the network this does not necessarily hold. Take
A =
⎛
⎜⎜⎜⎜⎜⎜⎝
0 0 0 0 −1 0
0 1 0 0 0 0
0 0 1 0 0 0
0 0 0 1
0 0
0 0 0 0
1 0
0 0 0 0
0 1
⎞
⎟⎟⎟⎟⎟⎟⎠
∈F6×6
2
that has rank equal to 5 and yields v[0,1] A[0,1] = 0, i.e., v[0,1] is indistinguishable from
the zero sequence and therefore cannot be corrected.
The next result can be considered the analog of Theorem 2 for the general case in
which the network admits delay in the transmission.
Theorem 3 Let C be a (n, k, δ) rank metric convolutional code, v(D) ∈C and A[0,T ]
be the truncated channel matrix. Then, we can recover v[0,T ] if

Multi-shot Network Coding
101
dT
GR(C) > n(T + 1) −rank(A[0,T ]).
(7)
Proof Let x[0,T ] = v[0,T ]A[0,T ]. Due to the linearity of the code it is enough to show
that all output channel sequence are distinguishable from the zero sequence, i.e.,
we need to prove that v[0,T ]A[0,T ] = 0 is impossible if rank(A[0,T ]) satisﬁes (7).
It is easy to see that rank(v[0,T ]) ≤n(T + 1) −rank(A[0,T ]). Using this, together
with assumption (7), it follows that rank(v[0,T ]) < dT
GR(C) which is impossible by
deﬁnition of dT
GR(C).
5
Concatenation Codes
In this section we brieﬂy comment on another alternative to construct multi-shot
codes: concatenated codes. A widely used class of concatenated codes in the Ham-
ming context is the one constituted by an inner convolutional code concatenated to
a outer block code (typically a Reed-Solomon code). The idea is that the Viterbi
decoder will clean up the channel by correcting most of the errors but will occa-
sionally output a burst of errors that will be handled by the Reed-Solomon code.
However, in the network coding context little is known about the decoding of rank
metric convolutional codes. Next, we present a class of concatenated codes obtained
by the concatenation of a Hamming metric outer convolutional code and a rank metric
inner block code. The idea is that the rank metric code deals with the possible errors
occurring in the network during the transmission at each shot and either delivers the
correct symbol or an erasure to the convolutional code. The reason for choosing this
non-standard scheme is twofold: Firstly, we want to exploit the fact that convolu-
tional codes perform very efﬁciently when dealing only with erasures. It was recently
shown in [4, 27] that using the ﬂexibility of selecting different sliding windows in
convolutional codes allows to recover (using elementary linear algebra) patterns of
erasures that cannot be decoded by an MDS block code of the same rate. Secondly,
we want to exploit the existing efﬁcient decoding algorithms for rank metric codes.
It was shown in [17] that despite the simple way in which these codes add complex
dependencies to data streams, this concatenation scheme can exploit the potential of
both codes to produce a code that can correct a large number of error patterns.
Let CI be a linear (nI, kI) rank metric code with (rank) distance drank(CI) and
generator matrix G I. Let Co be a (no, ko, δ) convolutional code over the ﬁeld Fq MkI
with (Hamming) distance dH(Co), column distance d j
H(Co) and a basic generator
matrix Go(D). The concatenation scheme is explain as follows.
Let u(D) = u0 + u1D + u2D2 + · · · ∈Fq MkI [D]ko be the information sequence
of source packets. Encode it through Go(D) ∈Fq MkI [D]ko×no to obtain
v(D) = v0 + v1D + v2D2 + · · · = u(D)Go(D) ∈Co ⊂Fq MkI [D]no.

102
D. Napp and F. Santana
We write
vi = (v0
i , v1
i , . . . , vno−1
i
), v j
i ∈Fq MkI .
We identify v j
i ∈Fq MkI with a vector ν j
i ∈FkI
q M (for a given basis of Fq MkI over
Fq M) and write
νi = (ν0
i , ν1
i , . . . , νno−1
i
) ∈(FkI
q M)no
and therefore
ν(D) = ν0 + ν1D + ν2D2 + · · · ∈FkI
q M[D]no.
Finally, the codewords c(D) of the concatenated code C are obtained through the
matrix G I ∈FkI ×nI
q M
in the following way:
c j
i = ν j
i G I ∈FnI
q M,
ci = (c0
i , c1
i , . . . , cno−1
i
) ∈(FnI
q M)no
and
c(D) = c0 + c1D + c2D2 + · · · ∈C ⊂FnI
q M[D]no.
Next, we present some of the distance properties of the concatenated code C as
described above.
Theorem 4 ([17]) The sum rank distance of the concatenated code C satisﬁes
dSR(C) ≥dH(Co)drank(CI)
and
d j
SR(C) ≥d j
H(Co)drank(CI).
Moreover,
dSR(C) ≤(nonI −kokI)
 δ
ko

+ 1

+ δkI + 1.
In [17], decoding algorithms were also presented together with some performance
evaluation. Simulation results showed that this class of codes perform very efﬁciently
when transmitting streaming data over a network.
Finally, it is worth mentioning the pioneer work of Nóbrega et al. in [19, 20]
where for the ﬁrst time the general ideas of multi-shot code for network coding were
laid out. Moreover, the authors presented an n-shot code (for a ﬁxed n) by means
of a concatenated code using a multilevel construction. Some interesting upper and
lower bounds were derived.

Multi-shot Network Coding
103
Acknowledgements The authors are supported by Portuguese funds through the CIDMA - Center
for Research and Development in Mathematics and Applications, and the Portuguese Foundation
for Science and Technology (FCT-Fundação para a Ciência e a Tecnologia), within project PEst-
UID/MAT/04106/2013.
References
1. P. Almeida, D. Napp, R. Pinto, A new class of superregular matrices and MDP convolutional
codes. Linear Algebra Appl. 439(7), 2145–2157 (2013)
2. A. Badr, A. Khisti, Wai-Tian. Tan, J. Apostolopoulos, Layered constructions for low-delay
streaming codes. IEEE Trans. Inform. Theory (2013)
3. J.J. Climent, D. Napp, C. Perea, R. Pinto, Maximum distance separable 2D convolutional codes.
IEEE Trans. Inf. Theory 62(2), 669–680 (2016)
4. J.J. Climent, D. Napp, R. Pinto, R. Sim˜oes, Decoding of 2D convolutional codes over the
erasure channel. Adv. Math. Commun. 10(1), 179–193 (2016)
5. Ph Delsarte, Bilinear forms over a ﬁnite ﬁeld, with applications to coding theory. J. Comb.
Theory Ser. A 25(3), 226–241 (1978)
6. É.M. Gabidulin, Theory of codes with maximum rank distance. Prob. Inf. Transm. 21, 1–12
(1985)
7. H. Gluesing-Luerssen, J. Rosenthal, R. Smarandache, Strongly MDS convolutional codes.
IEEE Trans. Inf. Theory 52(2), 584–598 (2006)
8. W. Guo, X. Shi, N. Cai, M. Medard, Localized dimension growth: a convolutional random
network coding approach to managing memory and decoding delay. IEEE Trans. Commun.
61(9), 3894–3905 (2013)
9. A. Horlemann-Trautmann, K. Marshall, New criteria for MRD and gabidulin codes and some
rank-metric code constructions, arXiv: 1507.08641
10. R. Johannesson, KSh Zigangirov, Fundamentals of Convolutional Coding (IEEE Press, New
York, 1999)
11. R. Kötter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579–3591 (2008)
12. R. Mahmood, Rank Metric Convolutional Codes with Applications in Network Streaming.
Master of applied science (2015)
13. R. Mahmood, A. Badr, A. Khisti, Streaming-codes for multicast over burst erasure channels.
IEEE Trans. Inf. Theory 61(8), 4181–4208 (2015)
14. R. Mahmood, A. Badr, A. Khisti, Convolutional codes with maximum column sum rank for
network streaming. IEEE Trans. Inf. Theory 62(6), 3039–3052 (2016)
15. R.J.McEliece,Thealgebraictheoryofconvolutionalcodes,inHandbookofCodingTheory,vol.
1, ed. by V. Pless, W.C. Huffman (Elsevier Science Publishers, Amsterdam, The Netherlands,
1998), pp. 1065–1138
16. D. Napp, R. Pinto, J. Rosenthal, P. Vettori, Rank metric convolutional codes, in Proceedings of
the 22nd International Symposium on Mathematical Theory of Network and Systems (MTNS)
(Minnesota, USA, 2016)
17. D. Napp, R. Pinto, V.R. Sidorenko, Concatenation of convolutional codes and rank metric
codes for multi-shot network coding. submitted to Des. Codes Cryptogr
18. D. Napp, R. Pinto, T. Toste, On MDS convolutional codes over Zpr (Designs, Codes and
Cryptography, 2016), pp. 1–14
19. R.W. Nóbrega, B.F. Uchoa-Filho, Multishot codes for network coding: Bounds and a multilevel
construction, in 2009 IEEE International Symposium on Information Theory (Seoul, South
Korea, 2009), pp. 428–432
20. R.W. Nóbrega, B.F. Uchoa-Filho, Multishot codes for network coding using rank-metric codes,
in Wireless Network Coding Conference (WiNC) (IEEE 2010), pp. 1–6

104
D. Napp and F. Santana
21. F. Pollara, R.J. McEliece, K. Abdel-Ghaffar, Finite-state codes. IEEE Trans. Inf. Theory 34(5),
1083–1089 (1988)
22. K. Prasad, B.S. Rajan, Network error correction for unit-delay, memory-free networks using
convolutional codes. in 2010 IEEE International Conference on Communications (ICC) (2010),
pp. 1 –6
23. J. Rosenthal, Connections between linear systems and convolutional codes, in Codes, Systems
and Graphical Models, IMA, vol. 123, ed. by B. Marcus, J. Rosenthal (Springer, 2001). pp.
39–66
24. J. Rosenthal, R. Smarandache, Maximum distance separable convolutional codes. Appl. Alge-
bra Eng. Comm. Comput. 10(1), 15–32 (1999)
25. J. Rosenthal, E.V. York, BCH convolutional codes. IEEE Trans. Autom. Control 45(6), 1833–
1844 (1999)
26. D. Silva, R. Kötter, F.R. Kschischang, A rank-metric approach to error control in random
network coding. IEEE Trans. Inf. Theory 54(9), 3951–3967 (2008)
27. V. Tomas, J. Rosenthal, R. Smarandache, Decoding of convolutional codes over the erasure
channel. IEEE Trans. Inf. Theory 58(1), 90–108 (2012)
28. A. Wachter-Zeh, M. Stinner, V. Sidorenko, Convolutional codes in rank metric with application
to random network coding. IEEE Trans. Inf. Theory 61(6), 3199–3213 (2015)

Part II
Finite Geometries and
Subspace Designs

Geometrical Aspects of Subspace Codes
Antonio Cossidente, Francesco Pavese and Leo Storme
Abstract Subspace codes are codes whose codewords are equal to subspaces of a
ﬁnite vector space V (n, q). Since the geometry of the subspaces of a ﬁnite vector
space V (n, q) is equivalent to the geometry of the subspaces of a projective space
PG(n −1, q), problems on subspace codes can be investigated by using geometri-
cal arguments. Here, we illustrate this approach by showing some recent results on
subspace codes, obtained via geometrical arguments. We discuss upper bounds on
the sizes of subspace codes, by showing the link between the Johnson bound and
the size of partial spreads in ﬁnite projective spaces. We present geometrical con-
structions of subspace codes, and we also focus on subspace codes constructed from
Maximum Rank Distance (MRD) codes. Here, we also present geometrical links of
MRD codes to exterior sets of Segre varieties. Our aim is to motivate researchers on
subspace codes to also consider geometrical arguments when investigating problems
on subspace codes.
1
Introduction
The ﬁnite projective space PG(n −1, q) of dimension n −1 over the ﬁnite ﬁeld Fq
of order q is constructed from the vector space V (n, q) of dimension n over the
ﬁnite ﬁeld Fq of order q in the following way: an i-dimensional projective subspace
A. Cossidente (B)
Dipartimento di Matematica e Informatica, Università della Basilicata,
Contrada Macchia Romana, 85100 Potenza, Italy
e-mail: antonio.cossidente@unibas.it
F. Pavese
Dipartimento di Meccanica, Matematica e Management, Politecnico di Bari, Via Orabona 4,
70125 Bari, Italy
e-mail: francesco.pavese@poliba.it
L. Storme
Department of Mathematics, Ghent University, Krijgslaan 281, 9000 Ghent, Belgium
e-mail: leo.storme@ugent.be
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_6
107

108
A. Cossidente et al.
of PG(n −1, q) is deﬁned by an (i + 1)-dimensional subspace of the vector space
V (n, q).
R. Kötter and F. Kschischang [31] proved that a very good way of transmission in
networksisobtainedifsubspacecodes areused.Here,thecodewordsaresubspacesof
the n-dimensional vector space V (n, q) over the ﬁnite ﬁeld Fq of order q. To transmit
a codeword, i.e. a k-dimensional vector space, through the network, it is sufﬁcient
to transmit a basis of this k-dimensional vector space. But a k-dimensional subspace
has different bases. Kötter and Kschischang proved that the transmission can be
optimalized if the nodes in the network transmit linear combinations of the incoming
basis vectors of the k-dimensional subspace which represents the codeword.
The geometry of the subspaces of a vector space over a ﬁnite ﬁeld can be inves-
tigated in the setting of ﬁnite projective spaces, also called Galois geometries. The
three standard references [24–26] to Galois geometries contain a wealth of infor-
mation on Galois geometries. In Galois geometries, geometrical methods, and also
other methods, such as polynomial methods and links with other domains, can be
used to investigate a great variety of problems on substructures of these ﬁnite pro-
jective spaces. Since a subspace code precisely is a substructure of a ﬁnite projective
space, this setting has, and still is able, to provide many new interesting results on
subspace codes.
This article wishes to highlight this fact. We present some constructions of, and
results on, subspace codes, which, presently, are among the best results, and which
match results that are found via other techniques. We have concentrated on the
constructions and results which can illustrate in an optimal way the ideas which have
been used, and which show that Galois geometries and geometrical techniques are of
great value for the study of subspace codes. We hope via these examples to motivate
many researchers to also investigate problems on subspace codes via geometrical
techniques, and to help showing that the study of Galois geometries is not only of
purely theoretical importance, but also of practical importance.
We ﬁrst present the basic ideas on Galois geometries to ﬁx notations and proper-
ties. We then present these particular examples of results on subspace codes, obtained
via geometrical arguments.
2
Preliminaries
Let Fq be the ﬁnite ﬁeld of order q and let V (n, q) be the vector space of dimen-
sion n over Fq. The 1-dimensional subspaces of V (n, q) are called vector lines,
the 2-dimensional subspaces are called vector planes. The number of k-dimensional
subspaces of V (n, q) is the q-binomial coefﬁcient
n
k

q
= (qn −1)(qn−1 −1) · · · (qn−k+1 −1)
(qk −1)(qk−1 −1) · · · (q −1)
.

Geometrical Aspects of Subspace Codes
109
The number of k-dimensional subspaces containing a ﬁxed t-dimensional sub-
space, t ≤k, is
n −t
k −t

q
.
The subspace distance between subspaces U and W of V (n, q) is deﬁned by
d(U, W) = dim(U + W) −dim(U ∩W).
AsubspacecodeC isanon-emptycollectionofsubspacesof V (n, q).Acodeword
is an element of C . The minimum distance of C is deﬁned by
d(C ) := min{d(U, W) | U, W ∈C ,U ̸= W}.
A code C is called an (n, M, d)-subspace code if C consists of subspaces of
V (n, q), is of cardinality M, and has minimum distance d. The maximal number of
codewords in an (n, M, d)-code, deﬁned over Fq, is denoted by Aq(n, d). A constant
dimension subspace code is a code with all codewords of the same dimension. If all
codewords of an (n, M, d)-code C are k-dimensional subspaces of V (n, q), then we
say that C is an (n, M, d, k)-subspace code. The maximum number of codewords
in an (n, M, d, k)-code, deﬁned over Fq, is denoted by Aq(n, d, k).
2.1
Codes in Projective Spaces
We will investigate subspace codes in the projective setting.
The projective space PG(n, q) of projective dimension n over Fq is the lattice of
subspaces of V (n + 1, q) with respect to set inclusion. In this article, a k-space, 0 ≤
k ≤n, is a subspace PG(k, q) of PG(n, q) of projective dimension k. This means that
a projective k-space is deﬁned by a (k + 1)-dimensional subspace of V (n + 1, q),
but we interpret the vector lines contained in this (k + 1)-dimensional subspace as 0-
dimensional objects, called projective points. The dimension k of a projective space
PG(k, q) is called the projective dimension of this subspace PG(k, q).
Thenumberofprojectivepointsofak-spaceis
k+1
1

q.Ani-dimensionalprojective
spacePG(i, q),i = 1, 2, 3, n −1,iscalledaprojectiveline,aprojectiveplane,asolid
or a hyperplane of PG(n, q), respectively.
Alternatively, PG(n, q) can be deﬁned as a point-line geometry [15]. Let Δ be
a k-space of PG(n, q). If the subspaces of PG(n, q) of dimension k + 1 and k + 2,
containing Δ, are considered as new points and lines, with inclusion as incidence,
then they correspond to a projective geometry PG(n −k −1, q), called the quotient
geometry of Δ. We shall denote the quotient geometry of Δ as PG(n −k −1, q)Δ.
An m-space of PG(n, q) that contains Δ has projective dimension m −k −1 in
PG(n −k −1, q)Δ.

110
A. Cossidente et al.
To illustrate the close links between subspace codes and ﬁnite projective spaces,
we illustrate how the study of the Johnson bound immediately relates to the study
of a geometrical object in ﬁnite projective spaces, called a partial spread, which is
already investigated for many years in Galois geometries.
3
Johnson Bound and Partial Spreads in Finite
Projective Spaces
3.1
The Johnson Bound and Partial Spreads
Deﬁnition 1 A (k −1)-spread of PG(n −1, q) is a partitioning of the point set of
PG(n −1, q) in (k −1)-spaces.
A partial (k −1)-spread S of PG(n −1, q) is a set of pairwise disjoint (k −1)-
spaces of PG(n −1, q).
A (k −1)-spread of PG(n −1, q) exists if and only if n ≡0 (mod k). Then, the
size of a (k −1)-spread is
n
1

q/
k
1

q.
Partial spreads are closely related to subspace codes. A (k −1)-spread of PG(n −
1, q) is a maximal (n, M, 2k, k)-code of cardinality
M = Aq(n, 2k, k) =
n
1

q
/
k
1

q
,
when n ≡0
(mod k).
A partial (k −1)-spread of PG(n −1, q), n ≡0 (mod k), of size M is also an
(n, M, 2k, k)-code, not necessarily of the maximal size.
When k does not divide n, the following lower bound on Aq(n, 2k, k) is known.
Theorem 1 ([6, 20]) Let n ≡r (mod k), 0 ≤r ≤k −1. Then for all q, we have
Aq(n, 2k, k) ≥qn −qk(qr −1) −1
qk −1
.
The following upper bound on Aq(n, 2k, k) is known.
Theorem 2 ([5, 17]) Let S be a partial t-spread in PG(d, q), where d = k(t +
1) −1 + r, 1 ≤r ≤t.
Let |S | = qr · qk(t+1)−1
qt+1−1 −s. Then
• s ≥q −1.
• s > qr−1
2
−q2r−t−1
5
.

Geometrical Aspects of Subspace Codes
111
Since Theorem1 states that there exists an example with s = qr −1, we know
that
Aq(n, 2k, k) = qn −qk(qr −1) −1
qk −1
,
when r = 1.
For many years, it was conjectured that
Aq(n, 2k, k) = qn −qk(qr −1) −1
qk −1
,
so the lower bound of Theorem1 is sharp.
However, El-Zanati et al. [18] found a counter example: there is a partial 3-spread
in the ﬁnite vector space V (8, 2), which corresponds to a partial 2-spread in PG(7, 2),
of size 34, but there exists no example of size 35. So A2(8, 6, 3) = 34.
But, very recently, a major breakthrough has been made by E. N˘astase and P.
Sissokho [37].
Theorem 3 ([37]) Let r ≡n (mod k). Then, if
k > qr −1
q −1 ,
the maximal size for a partial (k −1)-spread in PG(n −1, q) is equal to
qn−qk(qr−1)−1
qk−1
.
Consequently, if k > qr−1
q−1 , then
Aq(n, 2k, k) = qn −qk(qr −1) −1
qk −1
.
Similar results for q = 2 were recently also proven by Kurz [32].
We now make the link between the problem of the largest size of partial spreads
in ﬁnite projective spaces to the Johnson bound on subspace codes.
In general, in the terminology of projective geometry, an (n, M, d, k)-code C
can be viewed as a set of (k −1)-spaces of PG(n −1, q) of cardinality M with the
following property: t = k −d/2 + 1 is the smallest integer such that every (t −1)-
space of PG(n −1, q) is contained in at most one (k −1)-space of C . Equivalently,
any two distinct codewords of C intersect in at most a (t −2)-space. Hence, (k −1)-
spacesofC througha(t −2)-spaceΔformapartial(k −t)-spreadCΔ inthequotient
geometry PG(n −t, q)Δ of Δ. Note that CΔ is an (n −k + d/2, M′, d, d/2)-code,
called the quotient code of Δ. Using this observation, the following upper bound
on the size of a constant dimension code was obtained. This upper bound is known
under the name Johnson bound.

112
A. Cossidente et al.
Theorem 4 (Johnson bound [20]) The maximal size Aq(n, d, k) of an (n, M, d, k)-
code satisﬁes the upper bound
Aq(n, d, k) ≤
 n
t−1

q
 k
t−1

q
Aq(n −k + d/2, d, d/2),
where t = k −d/2 + 1 and where Aq(n −k + d/2, d, d/2) is the maximal size of
a partial (d/2 −1)-spread in PG(n −k + d/2 −1, q).
Corollary 1 The maximal size Aq(n, d, k) of an (n, M, d, k)-code, with n −k +
d/2 ≡0 (mod d/2), satisﬁes the upper bound
Aq(n, d, k) ≤
n
t

q
k
t

q
.
The main problem is whether there exist constant dimension codes meeting the
Johnson bound.
For d = 2k, this is the classical partial spreads problem, mentioned above. This
shows that a particular problem on subspace codes is completely equivalent to a
geometrical problem, already for decades of interest and of importance in Galois
geometries. This is one of the classical examples of the close links between the
theory of subspace codes and the theory of Galois geometries.
For more detailed information on partial spreads in ﬁnite projective spaces, we
refer to Chap.“Partial Spreads and Vector Space Partitions” of this Springer special
volume.
3.2
Subspace Codes from Maximum Rank Distance Codes
Rank distance codes were introduced by Delsarte [14] and are suitable for error
correction in the case where the network topology and the underlying network code
are known (the coherent case).
The set Mm×n(q) of m × n matrices over the ﬁnite ﬁeld Fq forms a metric space
with respect to the rank distance, deﬁned by
dr(A, B) = rk(A −B).
The maximum size of a code of minimum distance d, 1 ≤d ≤min{m, n}, in
(Mm×n(q), dr) is qn(m−d+1) for m ≤n and qm(n−d+1) for m ≥n. A code A ⊂
Mm×n(q) attaining this bound is said to be an (m, n, k)q maximum rank distance
code (MRD code), where k = m −d + 1 for m ≤n and k = n −d + 1 for m ≥n. A
rank distance code A is called Fq–linear if A is a subspace of Mm×n(q) considered
as a vector space over Fq. We can always assume that m ≤n.

Geometrical Aspects of Subspace Codes
113
In [40], the authors introduced a method, called the lifting process, to construct
a constant dimension subspace code from a maximum rank distance code. Let A be
an m × n matrix over Fq, and let Im be the m × m identity matrix. The rows of the
m × (n + m)matrix(Im|A)canbeviewedascoordinatesofpointsingeneralposition
of an (m −1)–dimensional projective space of PG(n + m −1, q). This subspace is
denoted by L(A). Hence, the matrix A can be lifted to a subspace L(A). Let C be
an (m, n, k)q MRD code, and let A1 and A2 be two distinct matrices of C . Since
rk(A1 −A2) ≥d, we have that
rk
 Im A1
Im A2

= m + rk(A1 −A2) ≥m + d.
Hence, L(A1) meets L(A2) in at most an (m −d −1)–dimensional projective space
and {L(A) | A ∈C } is an (n + m, qnk, 2d, m) subspace code. A constant dimen-
sion subspace code such that all of its codewords are lifted codewords of an MRD
code is called a lifted MRD code.
This lifting process implies the following result.
Theorem 5 ([40])
Aq(n + m, 2d, m) ≥qn(m−d+1).
Although the size of a lifted MRD code equals the highest power of q in the
Johnson bound, it is known that it is not maximal and it can be extended to a larger
subspace code.
Several examples of linear (n, n, k)q MRD codes are known to exist (Gabidulin
codes [14, 22], twisted Gabidulin codes [39], generalized twisted Gabidulin
codes [35]).
3.3
Planes in PG(5, q) Pairwise Intersecting
in at Most a Point
Let us consider an other case for the Johnson bound.
Honold, Kiermaier, and Kurz proved that A2(6, 4, 3) = 77 and there are exactly
ﬁve codes of size 77 [27].
Geometrically, this means that, in the projective space PG(5, 2), a set of projective
planes pairwise intersecting in at most one projective point, has size at most 77, and
there are exactly ﬁve different examples of such sets of 77 planes.
Honold, Kiermaier, and Kurz managed to extend one of the ﬁve examples to an
inﬁnite class of q6 + 2q2 + 2q + 1 planes in PG(5, q), pairwise intersecting in at
most one point.
Alternatively, Cossidente and Pavese [12] also constructed an inﬁnite class ofq6 +
2q2 + 2q + 1 planes in PG(5, q), pairwise intersecting in at most one point. We wish
to highlight this construction since it relies on many nice geometrical properties and

114
A. Cossidente et al.
results. This includes bundles of conics in a plane of PG(3, q), hyperbolic quadrics
in PG(3, q), and the Klein correspondence between the lines of PG(3, q) and the
Klein quadric Q+(5, q) of PG(5, q).
We now present the construction of a set of q6 + 2q2 + 2q + 1 planes in PG(5, q),
pairwise intersecting in at most one point, by Cossidente and Pavese. This leads to
the result
Theorem 6
q6 + 2q2 + 2q + 1 ≤Aq(6, 4, 3) ≤(q3 + 1)2.
TheconstructionofCossidenteandPaveseusestheKleincorrespondencebetween
lines of PG(3, q) and their Plücker coordinates on the Klein quadric Q+(5, q) in
PG(5, q) [24, Sect.15.4].
We ﬁrst present the hyperbolic quadric Q+(3, q) of PG(3, q). This is the quadric
with standard equation Q+(3, q) : X0X2 −X1X3 = 0.
This quadric contains two particular sets of q + 1 lines, which play a symmetrical
role, and which are called a regulus R and its opposite regulus R⊥.
Lines of a regulus are pairwise disjoint, while the lines of one regulus intersect
the lines of the opposite regulus in one point. Figure1 presents a drawing of a 3-
dimensional hyperbolic quadric, with three lines of every regulus.
We now introduce the basic facts of the Klein correspondence which plays a
central role in the construction of Cossidente and Pavese [24].
Deﬁnition 2 Consider a line ℓin PG(3, q) and suppose that y(y0, y1, y2, y3) and
z(z0, z1, z2, z3) are different points of ℓ. Let pi j = yiz j −y jzi.
Fig. 1 The hyperbolic
quadric Q+(3, q)

Geometrical Aspects of Subspace Codes
115
Then the Plücker coordinates of the line ℓare the 6-tuple (p01, p02, p03,
p23, p31, p12).
The Plücker coordinates of a line ℓin PG(3, q) are well-deﬁned. However, not
every 6-tuple is Plücker coordinates of a line ℓof PG(3, q).
Theorem 7 The 6-tuple (p01, p02, p03, p23, p31, p12) is Plücker coordinates of a
line ℓof PG(3, q) if and only if
p01 p23 + p02 p31 + p03 p12 = 0.
(1)
The set of points Q of PG(5, q), deﬁned by the equation p01 p23 + p02 p31 +
p03 p12 = 0, is a hyperbolic quadric Q+(5, q) of PG(5, q), called the Klein quadric.
This hyperbolic quadric Q+(5, q) contains points, lines and planes. The planes of
the hyperbolic quadric Q+(5, q) are also called the generators of Q+(5, q). The link
with the corresponding sets of lines in PG(3, q) is deﬁned in the following list [24,
Sect.15.4].
• Point of PG(5, q) on the Klein quadric deﬁnes a line ℓof PG(3, q).
• Line of PG(5, q) on the Klein quadric deﬁnes the set of q + 1 lines of PG(3, q)
through a ﬁxed point P in a ﬁxed plane π.
• Planes of PG(5, q) on the Klein quadric deﬁne either the set of all lines of PG(3, q)
through a ﬁxed point P, or the set of all lines of PG(3, q) lying in a ﬁxed plane π.
A Greek plane is a plane contained in the Klein quadric, deﬁning the lines of
PG(3, q) lying in a ﬁxed plane π, and a Latin plane is a plane contained in the
Klein quadric, deﬁning the lines of PG(3, q) through a ﬁxed point P.
• Greek planes, respectively Latin planes, on the Klein quadric pairwise intersect
in one point, while a Latin and a Greek plane either are skew to each other, or
intersect in a line.
• Consider a plane π of PG(5, q), intersecting the Klein quadric in a conic C. This
conic corresponds to a regulus R of a hyperbolic quadric Q+(3, q) in PG(3, q).
The polar plane π⊥of π with respect to the Klein quadric also intersects the Klein
quadric in a conic C⊥, corresponding to the opposite regulus R⊥of R of this
hyperbolic quadric Q+(3, q) in PG(3, q).
These two polar planes π and π⊥are skew to each other in PG(5, q).
In the preceding description, we recognize already the fact that the set of planes
of the Klein quadric can be partitioned into two equivalence classes. Two planes of
the Klein quadric are called equivalent when they are equal or intersect in a point
[26, p. 20]. This deﬁnition leads to an equivalence relation on the set of planes of
the Klein quadric, having two distinct equivalence classes. They are in the preceding
description respectively the class of the Greek planes and the class of the Latin planes.
The equivalence classes of the generators of the Klein quadric are also sometimes
called the systems of generators.

116
A. Cossidente et al.
The construction of Cossidente and Pavese of a set of q6 + 2q2 + 2q + 1 planes
of PG(5, q), pairwise intersecting in at most one point, starts by considering speciﬁc
structures in PG(3, q), and then transferring, via the Klein correspondence, to planes
in PG(5, q).
• Consider a ﬁxed plane π of PG(3, q).
• A bundle of conics B in this plane π is a set of q2 + q + 1 conics pairwise
intersecting in one point.
• Each conic of the bundle B is contained in q3(q −1)/2 hyperbolic quadrics
Q+(3, q) of PG(3, q).
This leads to (q6 −q3)/2 hyperbolic quadrics Q+(3, q) having q6 −q3 reguli,
and, by applying the Klein correspondence, to a set L1 of q6 −q3 planes of PG(5, q),
pairwise intersecting in at most one point.
Figure2 shows a drawing of the plane π, together with two conics of the bundle
of conics B in this plane π, and one hyperbolic quadric passing through each one
of these two conics.
In the second step of the construction of Cossidente and Pavese, consider this
ﬁxed plane π in PG(3, q), containing the bundle of conics B. This plane π deﬁnes
a Greek plane Π on the Klein quadric.
Add the other q3 + q2 + q Greek planes on the Klein quadric to the set L1. This
leads to a larger set L2 of q6 + q2 + q planes of PG(5, q), pairwise intersecting in
at most one point.
In the third step, consider again the Greek plane Π in PG(5, q), corresponding to
the plane π in PG(3, q), containing the bundle of conics B.
Fig. 2 The bundle of conics
and the hyperbolic quadrics
passing through the conics of
the bundle

Geometrical Aspects of Subspace Codes
117
Each line r of Π lies in q −1 planes of PG(5, q) only intersecting the Klein
quadric in the line r.
For every line r of Π, select one such plane, and add it to the set L2. This gives
the desired set L of q6 + 2q2 + 2q + 1 planes of PG(5, q), pairwise intersecting in
at most one point.
3.4
Planes in PG(5, q) Pairwise Intersecting
in at Most a Point (Alternative Construction)
Let Ui = (0, . . . , 0, 1, 0, . . . , 0), i = 0, . . . , 5, be the vector with the one in the
(i + 1)-th position.
Let C be a linear (3, 3, 2)q MRD code. Let L = {L(A) | A ∈C } be the lifted
MRD code obtained by lifting the elements of C . Then L consists of q6 planes of
PG(5, q) mutually intersecting in at most a point. In particular, members of L are
disjoint from the special plane T = ⟨U3,U4,U5⟩and therefore every line covered
by an element of L is disjoint from T . Moreover, from [27, Lemma6], every line of
PG(5, q) disjoint from T is covered by a member of L exactly once. We denote by
T ′ the plane ⟨U0,U1,U2⟩. Since the zero matrix belongs to C , we have that T ′ ∈L .
Let S denote the set of q3 3 × 3 skew–symmetric matrices over Fq. Here, for q
even, the diagonal elements of a 3 × 3–skew symmetric matrix are zeros. Since there
exists a linear (3, 3, 2)q MRD code containing S , we may assume that S ⊂C , see
[10, Proposition3.1].
Now, we introduce the non–degenerate hyperbolic quadric Q of PG(5, q) having
the following equation:
X0X3 + X1X4 + X2X5 = 0.
The planes T and T ′ are generators of Q. They belong to different systems of
generators of Q. Let M , M ′ be the system of generators of Q containing T , T ′,
respectively.
It can be seen that if A is a 3 × 3 skew–symmetric matrix over Fq, then L(A) is
a generator of Q disjoint from T .
Remark 1 Since the number of generators of Q disjoint from T equals q3, we have
that each such a plane is of the form L(A), for some A ∈S . Note that, if A ∈S ,
then L(A) belongs to the system M ′ of generators containing T ′.
Let L ′ be the set consisting of the q3 planes obtained by lifting the matrices
of S . Then, the set (L \ L ′) ∪M consists of q6 + q2 + q + 1 planes mutually
intersecting in at most a point.
Corresponding to a line r of T , there corresponds a set Tr of q −1 planes of
PG(5, q) meeting Q exactly in r. Varying the line r over the line set of T and
choosing one of the planes in Tr, we obtain a set T of q2 + q + 1 planes mutually
intersecting in at most one point.

118
A. Cossidente et al.
Finally, we have that the set (L \ L ′) ∪M ∪T is a set of q6 + 2q2 + 2q + 1
planes mutually intersecting in at most a point.
3.5
Solids in PG(7, q) Pairwise Intersecting in at Most a Line
Let C be a linear (4, 4, 3)q MRD code. Let L1 = {L(A) | A ∈C } be the lifted
MRD code obtained by lifting the elements of C . Then L1 consists of q12 solids
of PG(7, q) mutually intersecting in at most a line. In particular, members of L1
are disjoint from the special solid T = ⟨U4,U5,U6,U7⟩and therefore every plane
covered by an element of L1 is disjoint from T . Moreover, from [27, Lemma6],
every plane of PG(7, q) disjoint from T is covered by a member of L1 exactly once.
We denote by T ′ the solid ⟨U0,U1,U2,U3⟩. Since the zero matrix belongs to C , we
have that T ′ ∈L1.
Let Cr ⊂C be the set consisting of all the matrices of C having rank r, with
2 ≤r ≤4. From [22], it is known that a linear (4, 4, 3)q MRD code contains (q4 −
1)(q2 + 1)(q2 + q + 1) matrices of rank 2, (q4 −1)(q2 + 1)(q + 1)(q4 −q2 −q)
matrices of rank 3, and (q4 −1)q3(q5 −q4 −q3 + q + 1) matrices of rank 4.
Let A be an element of C2. As in Sect.3.2, the rows of the 4 × 8 matrix (A|I4)
can be viewed as coordinates of points in general position of a solid, say L′(A),
of PG(7, q). The solid L′(A) is disjoint from T ′ and meets T in a line. Let L2 =
{L′(A) | A ∈C2} be the set of solids obtained from the elements of C2. Then we
have that L1 ∪L2 is a set of q12 + (q4 −1)(q2 + 1)(q2 + q + 1) solids of PG(7, q)
mutually intersecting in at most a line.
Let S denote the set of q6 4 × 4 skew–symmetric matrices over Fq. Here, for q
even, the diagonal elements of a 4 × 4–skew symmetric matrix are zeros. Since there
exists a linear (4, 4, 3)q MRD code containing S , we may assume that S ⊂C , see
[10, Proposition3.1].
Now, we introduce the non-degenerate hyperbolic quadric Q1 of PG(7, q) having
the following equation:
X0X4 + X1X5 + X2X6 + X3X7 = 0.
Here again, the solids (generators) of the hyperbolic quadric Q1 of PG(7, q) are
partitioned into two equivalence classes M1 and M ′
1 [26]. Two generators Π1 and
Π2 are called equivalent when they are equal or intersect in a line. This relation is
again an equivalence relation, having two equivalence classes M1 and M ′
1 on the set
of generators of the hyperbolic quadric Q1 of PG(7, q).
The solids T and T ′ are generators of Q1. They belong to the same system of
generators of Q1, say M1. Let D(X) and I (X) denote the set of generators in M1
disjoint from the solid X or meeting non–trivially X, respectively. Then
M1 = D(T ) ∪(D(T ′) ∩I (T )) ∪(I (T ′) ∩I (T )),
where D(T ), D(T ′) ∩I (T ) and I (T ′) ∩I (T ) are trivially intersecting sets.

Geometrical Aspects of Subspace Codes
119
It can be seen that if A is a 4 × 4 skew–symmetric matrix over Fq, then L(A)
(resp. L′(A)) is a generator of Q1 disjoint from T (resp. T ′).
Remark 2 Since the number of generators of Q1 disjoint from T equals q6 [30,
Lemma3], we have that each such a solid is of the form L(A), for some A ∈S .
Note that, if A ∈S , then L(A) belongs to M1.
On the other hand, a solid L′(A) in D(T ′) is disjoint from T if and only if A
is a skew–symmetric matrix of rank 4. Therefore, the number of skew–symmetric
matrices of rank 4 is equal to |D(T ) ∩D(T ′)|. It follows that
|D(T ′) ∩I (T )| = |D(T ′)| −|D(T ′) ∩D(T )| =
= q6 −(q −1)q2(q3 −1) = q2(q3 + q −1)
and
|I (T ′) ∩I (T )| = |M1| −2q6 + (q −1)q2(q3 −1) = (q2 + 1)(q2 + q + 1).
Since S ⊂C , we have that D(T ) ⊂L1. Moreover, every element g ∈D(T ′) ∩
I (T ) is of the form L′(A) for some skew–symmetric matrix A having rank 2.
Hence, g ∈L2. The set L1 ∪L2 ∪(I (T ′) ∩I (T )) consists of q12 + (q4 −1)(q2 +
1)(q2 + q + 1) + (q2 + 1)(q2 + q + 1) solids of PG(7, q) mutually intersecting in
at most a line.
Let γ be a non–zero element of Fq such that the polynomial X2 −X −γ is
irreducible over Fq. Let Q2 be the hyperbolic quadric of PG(7, q) having equation
X0X6 + X1X7 + γ −1(X2X4 + X3X5 + X2X6 + X3X7) = 0.
The hyperbolic quadrics Q1 and Q2 generate a pencil of hyperbolic quadrics of
PG(7, q), say F, containing q −1 other distinct quadrics, say Qi, 3 ≤i ≤q + 1,
none of which is degenerate. Let X be the base locus of F. Since the hyperbolic
quadrics of F cover all the points of PG(7, q), and any two distinct quadrics in F
intersect precisely in X , we have that |X | = (q + 1)(q2 + 1)2. There are 2(q2 + 1)
generators belonging to each hyperbolic quadric of the pencil F and they all belong
to the same system of generators with respect to each of the quadrics Qi in F, say
Mi. In particular, T and T ′ belong to each hyperbolic quadric of the pencil F. Let G
be the set of generators meeting both T and T ′ non-trivially, and belonging to each
hyperbolic quadric of the pencil F. We have that G ⊂Mi, for every 1 ≤i ≤q + 1,
and |G | = q2 + 1.
Let Ii(X) denote the set of solids in Mi meeting non–trivially X, 2 ≤i ≤q + 1.
Then G = q+1
i=2 (Ii(T ) ∩Ii(T ′)) ∩(I (T ) ∩I (T ′)).
The set L1 ∪L2 ∪(	q+1
i=2 (Ii(T ) ∩Ii(T ′))) ∪(I (T ) ∩I (T ′)) is a set of q12 +
(q4 −1)(q2 + 1)(q2 + q + 1) + q(q + 1)2(q2 + 1) + (q2 + 1) solids of PG(7, q)
mutually intersecting in at most a line.

120
A. Cossidente et al.
The set G consists of q2 + 1 generators belonging to each hyperbolic quadric of
the pencil F such that every element in G meets both T and T ′ in a line. The set DT =
{A ∩T | A ∈G }, DT ′ = {A ∩T ′ | A ∈G } is a line–spread of T , T ′, respectively.
In particular, for a ﬁxed line ℓ∈DT , there exists a unique element in DT ′, say Aℓ,
such that ⟨ℓ, Aℓ⟩is in G , and viceversa. Furthermore, if ℓ∈DT and B ∈DT ′ \ {Aℓ},
then ⟨ℓ, B⟩is a solid meeting a hyperbolic quadric of the pencil F in a 3-dimensional
hyperbolic quadric Q+(3, q). Let D′ be the set of solids of the form ⟨ℓ, B⟩, where
ℓ∈DT and B ∈DT ′ \ {Aℓ}. Then D′ is disjoint from G and |D′| = q2(q2 + 1). We
have that L1 ∪L2 ∪(	q+1
i=2 (Ii(T ) ∩Ii(T ′))) ∪(I (T ) ∩I (T ′)) ∪D′ ∪{T } is a set
of solids mutually intersecting in at most a line, of size
q12 + (q4 −1)(q2 + 1)(q2 + q + 1) + (q3 + 3q2 + q + 1)(q2 + 1) + 1.
There exists a group H in the orthogonal group PGO+(8, q), stabilizing Q1, ﬁxing
both T , T ′, their line–spreads D(T ), D(T ′), and permuting in a single orbit the
remaining lines of T (respectively T ′). Let ⊥be the orthogonal polarity of PG(7, q)
associated with Q1. If r′ is a line of T ′, then r′⊥meets T in a line r. If r′ belongs
to DT ′, then r belongs to DT . Assume that r′ does not belong to DT ′. Of course, r′
meets q + 1 lines l′
1, . . . ,l′
q+1 of DT ′ and r meets q + 1 lines l1, . . . ,lq+1 of DT .
The group H contains a subgroup ﬁxing the lines l′
1, . . . ,l′
q+1 and having q(q −
1)/2 orbits of size q2 −q on the lines of T distinct from l1, . . . ,lq+1. Each one of
them, together with l1, . . . ,lq+1, is a line–spread of T , one of them being DT . Let E
be one of the orbits of size q2 −q disjoint from DT and let Y be the solid generated
by r′ and a line of E . It is possible to prove that Y H is a set of q6 −q2 solids mutually
intersecting in at most a line.
Finally,wehavethatthesetL1 ∪L2 ∪(	q+1
i=2 (Ii(T ) ∩Ii(T ′))) ∪(I (T ) ∩I (T ′))
∪D′ ∪Y H ∪{T } is an (8, M, 4, 4)q–subspace code, where
M = q12 + q2(q2 + 1)2(q2 + q + 1) + 1.
This leads to the following result.
Corollary 2
Aq(8, 4, 4) ≥q12 + q2(q2 + 1)2(q2 + q + 1) + 1.
Remark 3 The previous lower bound was obtained with different techniques in
[19], where the authors, among other interesting results, proved that q12 + q2(q2 +
1)2(q2 + q + 1) + 1 is also the maximum size of an (8, M, 4, 4)q–subspace code
containing a lifted MRD code.
For more information on constant dimension codes, we also refer to
Chap.“Constructions of Constant Dimension Codes” of this Springer special vol-
ume.

Geometrical Aspects of Subspace Codes
121
4
Optimal Mixed-Dimension Subspace Codes in PG(4, q)
Via geometrical arguments, it can be shown that Aq(5, 3) = 2(q3 + 1). Here, a
(5, 2(q3 + 1), 3)-code consists of subspaces of the vector space V (5, q), equiva-
lently, of subspaces of the projective space PG(4, q).
To give an idea which arguments are used to get geometrical insight in which
subspaces could be contained in a mixed-dimension (5, M, 3)-subspace code, we try
to see how the codewords of this code can intersect.
The vector space V (5, q) has four types of subspaces: vector lines, vector planes,
subspaces of dimension three, and subspaces of dimension four.
The formula for the subspace distance d(U,U ′) = dim(U + U ′) −dim(U ∩U ′)
shows that a (5, M, 3)-subspace code with minimum distance 3:
1. cannot contain two vector lines, and cannot contain two subspaces of dimension
four,
2. two vector planes in the code should only intersect in the zero vector,
3. two subspaces of dimension three should only intersect in a vector line,
4. a vector line in the code cannot be contained in a vector plane or in a 3-dimensional
vector space belonging to the code, a vector plane in the code cannot be contained
in a 3-dimensional subspace or 4-dimensional subspace belonging to the code,
and a 3-dimensional subspace in the code cannot be contained in a 4-dimensional
subspace belonging to the code.
We now interpret these conditions in the geometrical setting, so we replace all
the codewords in the (5, 2(q3 + 1), 3)-code by their geometrical equivalents in the
projective space PG(4, q).
Condition (2) implies that two projective lines belonging to the code are skew to
each other. Hence, the projective lines belonging to the (5, 2(q3 + 1), 3)-code form
a partial line spread of PG(4, q).
From Theorem2, the largest partial line spread of PG(4, q) has size q3 + 1. So,
if C is an optimal (5, 3)q subspace code, then C contains at most q3 + 1 pairwise
skew lines. A dual argument shows that C contains at most q3 + 1 planes, and these
planes pairwise intersect in a projective point.
Hence, if C consists of projective lines and projective planes, we have that |C | ≤
2(q3 + 1) and, if |C | = 2(q3 + 1), then C consists of a set L of q3 + 1 pairwise
skew lines and of a set P of q3 + 1 planes mutually intersecting in exactly a point,
such that no line of L is contained in a plane of P.
Note that Condition (1) above states that C contains at most one point and, dually,
C contains at most one solid.
Counting arguments of [11] prove that if C contains a point, then C contains at
most q3 planes. Dually, if C contains a solid, then C contains at most q3 lines.
It follows from these arguments that Aq(5, 3) ≤2(q3 + 1) and there are four
possibilities for the code C :
(I) C consists of one point, q3 + 1 lines, and q3 planes;
(II) C consists of q3 lines, q3 + 1 planes, and one solid;

122
A. Cossidente et al.
(III) C consists of one point, q3 lines, q3 planes, and one solid;
(IV) C consists of q3 + 1 lines and q3 + 1 planes.
We present the construction for q odd, showing that Aq(5, 3) = 2(q3 + 1). A
similar construction exists for q even, but since it is more technical, we refer to [11]
for its description.
Let q = ph, where p is an odd prime. Let PG(4, q) be equipped with homoge-
neous coordinates (X0, X1, X2, X3, X4), let π be the projective plane with equations
X3 = X4 = 0 and let ℓbe the line of π with equations X2 = X3 = X4 = 0. Let ω
be a primitive element of Fq and denote by Πi the solid of PG(4, q) passing through
π with equation X3 = ωi−1X4, if 1 ≤i ≤q −1, X3 = 0 if i = q, and X4 = 0 if
i = q + 1.
Let a, b, c be ﬁxed elements of Fq such that the polynomial X3 + aX2 + bX +
c = 0 is irreducible over Fq and consider the following matrices
Mr,s,t =
⎛
⎜⎜⎜⎜⎝
1 0 r r2 −ar + s
t
0 1 s
2rs −t
s2 + bs −cr
0 0 1
2r
2s
0 0 0
1
0
0 0 0
0
1
⎞
⎟⎟⎟⎟⎠
.
Then the group of projective transformations G = {x →Mr,s,t · x | r, s, t ∈Fq} is
a p-group of order q3.
This group G has within the set of lines of PG(4, q), exactly q3 orbits of size q3,
each consisting of pairwise disjoint lines that are disjoint from π. Similarly, every
plane of PG(4, q), intersecting the plane π in exactly one point, not belonging to the
line ℓ, belongs to an orbit of G, consisting of q3 planes, pairwise intersecting in one
point.
Consider such an orbit under G of q3 planes intersecting the ﬁxed plane π in a
point not belonging to the line ℓ. Such a plane contains q2 lines skew to π. They
deﬁne only q2 of the q3 orbits of lines that are disjoint from π. Hence, by taking
one of the remaining q3 −q2 orbits of such lines, a set of q3 planes and q3 lines is
obtained forming a subspace code with minimum distance 3.
This (5, 2q3, 3)-code can be extended to a (5, 2(q3 + 1), 3)-code by adding a line
r of π, r ̸= ℓ, and a plane ξ through the line ℓ, but with ξ ̸= π, to this code. This
leads to an optimal (5, Aq(5, 3), 3)-code consisting of q3 + 1 lines and planes.
Figure3 presents the setting for this mixed dimension code in PG(4, q), q odd.
The drawing shows the plane π, the line ℓwith the plane ξ passing through ℓ, and
the line r. Two of the q + 1 solids through the plane π are shown. They are denoted
by Πi and Π j. The orbit of q3 lines skew to π is denoted by the three vertical lines,
sharing one point with the solids Πi and Π j. Finally, one plane is drawn of the orbit
of q3 planes sharing one point with the plane π, which does not belong to ℓ, and
which are skew to the q3 lines of the selected orbit of lines.

Geometrical Aspects of Subspace Codes
123
Fig. 3 The mixed
dimension construction in
PG(4, q), q odd
In [11, Remark2.6], it is shown that minor changes can be made to the construc-
tion, to also construct optimal (5, Aq(5, 3), 3)-codes of type (I), (II), and (III).
5
Geometrical Links to Non-linear Maximum Rank
Distance Codes
In this context, we can make links to the Segre variety of PG(n2 −1, q) [13, 26].
The Segre map
σ : PG(n −1, q) × PG(n −1, q) →PG(n2 −1, q),
takes a pair of points x = (x0, . . . , xn−1), y = (y0, . . . , yn−1) of PG(n −1, q) to their
product (x0y0, x0y1, . . . , xn−1yn−1) (the products xi y j are taken in lexicographical
order). The image of the Segre map is an algebraic variety of PG(n2 −1, q), called
the Segre variety, and is denoted by Sn−1,n−1.
When n = 2, the Segre variety S1,1 of PG(3, q) is a non–degenerate hyperbolic
quadric Q+(3, q). In Sect.3.3, we deﬁned the hyperbolic quadric as the quadric with
equation X0X2 −X1X3 = 0, but equivalently, this quadric is given as the zero locus
of the quadratic polynomial given by the determinant of the matrix
 x0y0 x0y1
x1y0 x1y1

.

124
A. Cossidente et al.
In the case n = 3, the Segre variety S2,2 of PG(8, q) is deﬁned to be the zero
locus of all quadratic polynomials given by the determinants of the 2 × 2 matrices
of the matrix
⎛
⎝
x0y0 x0y1 x0y2
x1y0 x1y1 x1y2
x2y0 x2y1 x2y2
⎞
⎠.
In other terms, in the projective space PG(Mn×n(q)), if n = 2, the Segre variety
S1,1 of PG(3, q) is represented by all 2 × 2 matrices of rank 1 and if n = 3, the
Segre variety S2,2 of PG(8, q) is represented by all 3 × 3 matrices of rank 1.
The following deﬁnition considers a set of points that at ﬁrst sight is of purely
geometrical interest with respect to a Segre variety.
Deﬁnition 3 An exterior set with respect to a Segre variety Sn−1,n−1 of PG(n2 −
1, q) is a set of points E of PG(n2 −1, q) \ Sn−1,n−1 of size (qn2−n −1)/(q −1)
such that the line joining any two points of E is disjoint from Sn−1,n−1.
But this deﬁnition and the previous observations give an immediate link with
maximum rank distance codes.
In general, an exterior set E of PG(n2 −1, q) with respect to a Segre variety
Sn−1,n−1, of size (qn2−n −1)/(q −1), gives rise to a MRD code: this is done by
identifying a point of E and its nonzero scalar multiples together with the zero matrix
with members of Mn×n(q). This is also the key tool of our approach. We formulate
this in the next proposition.
Proposition 1 An exterior set with respect to Sn−1,n−1 gives rise to an (n, n, n −1)
MRD code closed under Fq–multiplication, and viceversa.
Corollary 3 An (n, n, n −1) Fq-linear Gabidulin code G is a certain subspace X
of PG(n2 −1, q) of dimension n2 −n −1 which is an exterior set with respect to
Sn−1,n−1.
The preceding corollary is of particular interest since the maximum dimension of
a subspace of PG(n2 −1, q) disjoint from Sn−1,n−1 is exactly n2 −n −1 [9].
5.1
The Case n = 2
In this subsection, we report the complete classiﬁcation of linear and non–linear
MRD codes that are closed under Fq–multiplication when n = m = 2. We do this
because this is linked to the solution of a purely geometrical problem, related to the
hyperbolic quadric Q+(3, q) of the projective space PG(3, q), which is the smallest
example of a Segre variety.
A ﬂock of the hyperbolic quadric Q+(3, q) of the ﬁnite projective space PG(3, q)
is a partition of Q+(3, q) consisting of q + 1 irreducible conics. A linear ﬂock of
Q+(3, q) is a ﬂock which consists of q + 1 irreducible conics, lying in the q + 1

Geometrical Aspects of Subspace Codes
125
planes through a ﬁxed line ℓskew to the hyperbolic quadric Q+(3, q). A maximal
exterior set (MES) with respect to the hyperbolic quadric Q+(3, q) is a set of q + 1
points of PG(3, q) such that the line joining any two of them has no point in common
with Q+(3, q). The polar planes, with respect to the polarity induced by Q+(3, q),
of the points of a MES, deﬁne a ﬂock, and conversely.
In [41], J.A. Thas proved that all ﬂocks of Q+(3, q) are linear if q is even, and
that Q+(3, q) has non–linear ﬂocks (called Thas ﬂocks) if q is odd. Furthermore, he
showed that, for q = 3, 7 and q ≡1 mod 4, Q+(3, q) has only (up to a projectivity)
the linear ﬂock and the Thas ﬂock. For q = 11, 23, 59, other ﬂocks of Q+(3, q) were
discovered, called exceptional ﬂocks [1, 3, 29]. Finally, the combined results of Bader
and Lunardon [2] and Thas [42] proved that every ﬂock of Q+(3, q), q odd, is linear,
a Thas ﬂock or one of the exceptional ﬂocks.
The classiﬁcation theorem is therefore as follows.
Theorem 8 Let E be a MES deﬁned by a ﬂock F of Q+(3, q) in the matrix model of
PG(3, q). Then, either q is even and E is a line, or q is odd and one of the following
possibilities occurs:
(1) E is a line;
(2) E consists of (q + 1)/2 points on two lines ℓ, ℓ⊥, where ⊥is the polarity of
Q+(3, q);
(3) E is one of the sporadic examples.
In our setting, the linear MES corresponds to a (2, 2, 1) Fq-linear MRD-code. In
all the other instances (Theorem8 (2) and (3)), the MES corresponds to a (2, 2, 1)
non-linear maximum rank distance code.
5.2
The Case n = 3
A very useful model of S2,2 arises from the geometry of the Desarguesian projective
plane π := PG(2, q3). Indeed, each point P of PG(2, q3), when read over Fq, deﬁnes
a projective plane X(P) of the projective space PG(8, q), and the set D = {X(P) :
P ∈PG(2, q3)} is a Desarguesian spread of PG(8, q) [38, Sect.25]. The incidence
structure π := (D, L ), whose points are the elements of D and whose line set
L consists of the 5–dimensional projective subspaces of PG(8, q) joining any two
distinct elements of D, is isomorphic to PG(2, q3). The pair (D, L ) is called the
Fq-linear representation of PG(2, q3) (with respect to the Desarguesian spread D).
Let X0, X1, X2 denote projective homogeneous coordinates inπ ≃PG(2, q3) and
let ¯π be a subplane of π of order q. Let G denote the stabilizer of ¯π in PGL(3, q3).
Choose homogeneous coordinates in such a way that ¯π := {(1, xq+1, xq) : x ∈
Fq3 \ {0}, N(x) = 1}, where N(·) is the norm function from Fq3 over Fq. It turns
out that ¯π is ﬁxed pointwise by the order three semilinear collineation of PG(2, q3)
given by φ : (X0, X1, X2) →(Xq
2, Xq
0, Xq
1).

126
A. Cossidente et al.
Let ⟨S⟩be a Singer cyclic group of G [28]. We can assume that S is given by
⎛
⎝
ω 0
0
0 ωq
0
0 0 ωq2
⎞
⎠,
where ω is a primitive element of Fq3.
Remark 4 The subgroup ⟨S⟩ﬁxes the three points E1 = (1, 0, 0), E2 = (0, 1, 0) and
E3 = (0, 0, 1) of π, and hence the lines Ei E j, 1 ≤i < j ≤3. All the other orbits
are subplanes of order q of π. Note that the line Ei E j is partitioned into the two
points Ei and E j, and into q −1 orbits of ⟨S⟩of size q2 + q + 1. The collineation
φ above normalizes ⟨S⟩.
The points of ¯π correspond to the q2 + q + 1 planes ﬁlling the system of a Segre
variety S2,2 of PG(8, q) contained in the Desarguesian spread D. Also, the lines of
π, arising from sublines of ¯π, yield a set of (q3 −q)(q2 + q + 1) points of π that
together with the points of ¯π give rise to the points of the secant variety Ω(S2,2) of
S2,2 [33, 36].
Under the action of the stabilizer G of ¯π in PGL(3, q3), the point set of π is
partitioned into three orbits corresponding to the points of ¯π, points of π \ ¯π on
extended sublines of ¯π, and the complement. Under the same group, by duality, the
line set of π is partitioned into three orbits corresponding to sublines of ¯π, lines
meeting ¯π in a point, and lines external to ¯π.
Proposition 2 In the linear representation of PG(2, q3), any line of π disjoint from
¯π corresponds to a 5-dimensional projective subspace of PG(8, q) disjoint from
S2,2.
Of course, any line of π disjoint from ¯π gives rise to an exterior set with respect to
S2,2 and hence, from a coding theoretical point of view, a (3, 3, 2) Fq–linear MRD
code.
Now let q > 2 and consider the set X of points of π whose coordinates satisfy
the equation X0Xq
1 −Xq+1
2
= 0. The set X has size q3 + 1 and it is ﬁxed by ⟨S⟩.
Also, it contains q −1 subplanes of order q, one of which is ¯π, and the points E1
and E2. More precisely, the subplanes of order q embedded in X are the subsets of
points of π given by
πa := {(1, xq+1, xq) : x ∈Fq3, N(x) = a},
where a is a nonzero element of Fq. In particular, π1 = ¯π. From [16, Proposition3.1],
a line of π intersects X in 0, 1, 2 or q + 1 points, and the intersections of size q + 1
are actually lines of subplanes of order q of π embedded in X . We can assume
that the Segre variety corresponding to ¯π = π1 is the only Segre variety of PG(8, q)
corresponding to rank one matrices of order three.

Geometrical Aspects of Subspace Codes
127
We recall the following deﬁnition.
Deﬁnition 4 ([4]) Let ℓ∞be a line of π disjoint from the subplane ¯π. The exterior
splash of ¯π on ℓ∞is deﬁned to be the set of q2 + q + 1 points of ℓ∞that belong to
an extended line of ¯π.
The line E1E2 is disjoint from all the q −1 subplanes πa, a ∈Fq \ {0}, of π
contained in X . Also, for each subplane πa, with a ∈Fq \ {0}, its exterior splash
on E1E2 is the set of q2 + q + 1 points of E1E2 given by
Za := {(1, x, 0) : x ∈Fq3, N(x) = −a2}.
Such a set is a so-called Fq-linear set of pseudoregulus type. For further details on
these linear sets, see [16, 34, 36]. All these subplanes and splashes are of course
⟨S⟩-orbits.
Now, let T be the fundamental triangle E1E2E3 of π. One can prove that a
line of π is either a side of T , or it contains a vertex of T , or it induces a subline
of a unique subplane of order q of π invariant under ⟨S⟩. Consider now the set
K := (X \ {π1}) ∪Z1. It turns out that K is such that every line deﬁned by any two
of its points is disjoint from π1. Correspondingly, the set K ′ corresponding to K in
PG(8, q), q > 2, is an exterior set of size (q3 + 1)(q2 + q + 1) with respect to the
Segre variety S2,2 corresponding to π1.
In terms of coding theory, we have the following result.
Theorem 9 There exists a (3, 3, 2) MRD non-linear code admitting a Singer cyclic
group of PGL(3, q), q > 2, as an automorphism group.
Remark 5 In [21], R. Figueroa presented a new class of non-Desarguesian projective
planes of order q3, q a prime power with q ̸≡1 mod 3, q > 2. C. Hering and H.-J.
Schaffer in [23] improved and simpliﬁed the construction for all prime powers q.
From [7, Corollary3], the set K constructed above represents a line in the Figueroa
plane of order q3.
Remark 6 When q = 2, some computer tests performed with MAGMA [8] give that
all subsets of PG(2, 8) yielding exterior sets with respect to a Segre variety S2,2 are
precisely the 24 lines disjoint from ¯π. When q = 2, no non-linear MRD codes arise
from our construction.
We also refer the readers to Chap.“Codes Endowed with the Rank Metric” of this
Springer special volume, dedicated to rank metric codes, and to Chap.“Constructions
of Cyclic Subspace Codes and Maximum Rank Distance Codes” of this special
volume on the construction of cyclic subspace codes and maximum rank distance
codes.

128
A. Cossidente et al.
References
1. L. Bader, Some new examples of ﬂocks of Q+(3, q). Geom. Dedicata 27, 213–218 (1988)
2. L. Bader, G. Lunardon, On the ﬂocks of Q+(3, q). Geom. Dedicata 29, 177–183 (1989)
3. R.D. Baker, G.L. Ebert, A nonlinear ﬂock in the minkowski plane of order 11. Congr. Numer.
58, 75–81 (1987)
4. S.G. Barwick, W.-A. Jackson, Exterior splashes and linear sets of rank 3. Discret. Math. 339,
1613–1623 (2016)
5. A. Beutelspacher, Partial spreads in ﬁnite projective spaces and partial designs. Math. Z. 145,
211–229 (1975)
6. A. Beutelspacher, On t-covers in ﬁnite projective spaces. J. Geom. 12, 10–16 (1979)
7. J.M.N. Brown, Some partitions in Figueroa planes. Note Mat. 29, 33–43 (2009)
8. J. Cannon, C. Playoust, An introduction to MAGMA, University of Sydney, Sydney, Australia
(1993)
9. B.N. Cooperstein, External ﬂats to varieties in PG(Mn,n(GF(q))). Linear Algebra Appl. 267,
175–186 (1997)
10. A. Cossidente, F. Pavese, Subspace codes in PG(2n −1, q). Combinatorica (to appear). https://
doi.org/10.1007/s00493-016-3354-5
11. A. Cossidente, F. Pavese, L. Storme, Optimal subspace codes in PG(4, q) (In preparation)
12. A. Cossidente, F. Pavese, On subspace codes. Des. Codes Cryptogr. 78, 527–531 (2016)
13. A. Cossidente, G. Marino, F. Pavese, Non-linear maximum rank distance codes. Des. Codes
Cryptogr. 79, 597–609 (2016)
14. P. Delsarte, Bilinear forms over a ﬁnite ﬁeld, with applications to coding theory. J. Combin.
Theory Ser. A 25, 226–241 (1978)
15. P. Dembowski, Finite Geometries (Springer, Berlin, 1968)
16. G. Donati, N. Durante, Scattered linear sets generated by collineations between pencils of lines.
J. Algebr. Combin. 40, 1121–1134 (2014)
17. J.Eisfeld,L.Storme,(Partial)t-spreadsandminimalt-coversinﬁniteprojectivespaces.Lecture
notes, Universiteit Gent (2000), http://cage.ugent.be/~fdc/courses/GGaGP2.php
18. S. El-Zanati, H. Jordon, G. Seelinger, P. Sissokho, L. Spence, The maximum size of a partial
3-spread in a ﬁnite vector space over GF(2). Des. Codes Cryptogr. 54, 101–107 (2010)
19. T. Etzion, N. Silberstein, Codes and designs related to lifted MRD codes. IEEE Trans. Inform.
Theory 59, 1004–1017 (2013)
20. T. Etzion, A. Vardy, Error-correcting codes in projective space. IEEE Trans. Inform. Theory
57, 1165–1173 (2011)
21. R. Figueroa, A family of not (V,l)-transitive projective planes of order q3,
and q>2. Math. Z. 181, 471–479 (1982)
22. E.M. Gabidulin, Theory of codes with maximum rank distance. Probl. Inform. Trans. 21, 1–12
(1985)
23. C. Hering, H.-J. Schaffer, On the new projective planes of R. Figueroa, Combinatorial Theory,
vol. 969, Lecture Notes in Mathematics (Springer, Berlin, 1982), pp. 187–190
24. J.W.P. Hirschfeld, Finite Projective Spaces of Three Dimensions (Oxford University Press,
Oxford, 1985)
25. J.W.P. Hirschfeld, Projective Geometries Over Finite Fields, 2nd edn. (Oxford University Press,
Oxford, 1998)
26. J.W.P. Hirschfeld, J.A. Thas, General Galois Geometries (Oxford University Press, Oxford,
1991)
27. T. Honold, M. Kiermaier, S. Kurz, Optimal binary subspace codes of length 6, constant dimen-
sion 3 and minimum distance 4. Contemp. Math. 632, 157–176 (2015)
28. B. Huppert, Endliche Gruppen, I, Die Grundlehren der Mathematischen Wissenschaften, Band
134 (Springer, Berlin, 1967)
29. N.L.Johnson,Flocksofhyperbolicquadricsandtranslationplanesadmittingafﬁnehomologies.
J. Geom. 34, 50–73 (1989)

Geometrical Aspects of Subspace Codes
129
30. A. Klein, K. Metsch, L. Storme, Small maximal partial spreads in classical ﬁnite polar spaces.
Adv. Geom. 10, 379–402 (2010)
31. R. Kötter, F. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inform. Theory 54, 3579–3591 (2008)
32. S. Kurz, Improved upper bound for partial spread. Des. Codes Cryptogr. 85, 97–106 (2017)
33. M. Lavrauw, G. Van de Voorde, Field reduction and linear sets in ﬁnite geometry. Contemp.
Math. 632, 271–293 (2015)
34. M. Lavrauw, C. Zanella, Subgeometries and linear sets on a projective line. Finite Fields Appl.
34, 95–106 (2015)
35. G. Lunardon, R. Trombetti, Y. Zhou, Generalized twisted Gabidulin codes, arXiv:1507.07855
36. G. Lunardon, G. Marino, O. Polverino, R. Trombetti, Maximum scattered linear sets of pseu-
doregulus type and the Segre Variety Sn,n. J. Algebr. Combin. 39, 807–831 (2014)
37. E. Nastase, P. Sissokho, The maximum size of a partial spread in a ﬁnite projective space.
J. Combin. Theory Ser. A 152, 353–362 (2017)
38. B. Segre, Teoria di Galois, ﬁbrazioni proiettive e geometrie non desarguesiane. Ann. Mat. Pura
Appl. 64, 1–76 (1964)
39. J. Sheekey, A new family of linear maximum rank distance codes. Adv. Math. Commun. 10,
475–488 (2016)
40. D. Silva, F.R. Kschischang, R. Koetter, A rank-metric approach to error control in random
network coding. IEEE Trans. Inform. Theory 54, 3951–3967 (2008)
41. J.A. Thas, Flocks of non-singular ruled quadrics in PG(3, q). Atti Accad. Naz. Lincei Rend.
Cl. Sci. Fis. Mat. Natur. 59, 83–85 (1975)
42. J.A. Thas, Flocks, maximal exterior sets and inversive planes, Finite Geometries and Com-
binatorial Designs, vol. 111, Contemporary Mathematics (American Mathematical Society,
Providence, 1990), pp. 187–218

Partial Spreads and Vector Space Partitions
Thomas Honold, Michael Kiermaier and Sascha Kurz
Abstract Constant-dimension codes with the maximum possible minimum distance
have been studied under the name of partial spreads in Finite Geometry for several
decades. Not surprisingly, for this subclass typically the sharpest bounds on the
maximal code size are known. The seminal works of Beutelspacher and Drake &
Freeman on partial spreads date back to 1975 and 1979, respectively. From then until
recently, there was almost no progress besides some computer-based constructions
and classiﬁcations. It turns out that vector space partitions provide the appropriate
theoretical framework and can be used to improve the long-standing bounds in quite a
few cases. Here, we provide a historic account on partial spreads and an interpretation
of the classical results from a modern perspective. To this end, we introduce all
required methods from the theory of vector space partitions and Finite Geometry in
a tutorial style. We guide the reader to the current frontiers of research in that ﬁeld,
including a detailed description of the recent improvements.
1
Introduction
Let Fq be the ﬁnite ﬁeld with q elements, where q > 1 is a prime power. By Fv
q we
denote the standard vector space of dimension v ≥1 over Fq, whose vectors are the
v-tuples x = (x1, . . . , xv) with xi ∈Fq. The set of all subspaces of Fv
q, ordered by
the incidence relation ⊆, is called (v −1)-dimensional projective geometry over Fq
and denoted by PG(v −1, Fq). It forms a ﬁnite modular geometric lattice with meet
X ∧Y = X ∩Y, join X ∨Y = X + Y, and rank function X →dim(X). Employing
this algebraic notion of dimension instead of the geometric one, we will use the term
T. Honold
Zhejiang University, Hangzhou 310027, China
e-mail: honold@zju.edu.cn
M. Kiermaier · S. Kurz (B)
University of Bayreuth, 95440 Bayreuth, Germany
e-mail: sascha.kurz@uni-bayreuth.de
M. Kiermaier
e-mail: michael.kiermaier@uni-bayreuth.de
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_7
131

132
T. Honold et al.
k-subspace to denote a k-dimensional vector subspace of Fv
q.1 The important geomet-
ric interpretation of subspaces will still be visible in the terms points, lines, planes,
solids, hyperplanes (denoting 1-, 2-, 3-, 4- and (v −1)-subspaces, respectively), and
in general through our extensive use of geometric language. For more geometrical
aspects we refer the reader to Chapter “Geometrical Aspects of Subspace Codes”.
In the same way as Fv
q, an arbitrary v-dimensional vector space V over Fq gives
rise to a projective geometry PG(V ), and the terminology introduced before (and
thereafter) applies to this general case as well. Since a vector space isomorphism
V ∼= Fv
q induces a geometric isomorphism (“collineation”) PG(V ) ∼= PG(Fv
q) =
PG(v −1, Fq), we could in principle avoid the use of non-standard vector spaces,
but only at the expense of ﬂexibility—for example, the Singer representation of the
point-hyperplane design of PG(v −1, Fq) is best developed using the ﬁeld extension
Fqv/Fq as ambient vector space V (and not Fv
q, which would require a discussion of
matrix representations of ﬁnite ﬁelds).
The set of all k-subspaces of an Fq-vector space V will be denoted by
V
k

q.
The sets
V
k

q form ﬁnite analogues of the Graßmann varieties studied in Algebraic
Geometry. In terms of v = dim(V ), the cardinality of
V
k

q is given by the Gaussian
binomial coefﬁcient
v
k

q
:=
 (qv−1)(qv−1−1)···(qv−k+1−1)
(qk−1)(qk−1−1)···(q−1)
if 0 ≤k ≤v;
0
otherwise,
which are polynomials of degree k(v −k) in q (if they are nonzero) and represent
q-analogues of the ordinary binomial coefﬁcients in the sense that limq→1
v
k

q =
v
k

.
Their most important combinatorial properties are described in [2, Sect.3.3] and [66,
Chap. 24].
Making the connection with the main topic of this book, the geometry PG(v −
1, Fq) serves as input and output alphabet of the so-called linear operator chan-
nel (LOC), a clever model for information transmission in coded packet networks
subject to noise [43].2 The relevant metrics on the LOC are given by the subspace dis-
tance
dS(X, Y) := dim(X + Y) −dim(X ∩Y) = 2 · dim(X + Y) −dim(X) −
dim(Y), which can also be seen as the graph-theoretic distance in the Hasse diagram
of PG(v −1, Fq), and the injection distance dI(X, Y) := max {dim(X), dim(Y)} −
dim(X ∩Y). A set C of subspaces of Fv
q is called a subspace code and serves as a
channel code for the LOC in the same way as classical linear codes over Fq do for
the q-ary symmetric channel.3 The minimum (subspace) distance of C is given by
d = min{dS(X, Y) | X, Y ∈C , X ̸= Y}. If all elements of C have the same dimen-
1Using the algebraic dimension has certain advantages—for example, the existence criterion v =
tk for spreads (cf. Theorem 1) looks ugly when stated in terms of the geometric dimensions:
v′ = t(k′ −1) + 1.
2The use of distributed coding at the nodes of a packet-switched network, generally referred to as
Network Coding, is described in [27, 56, 70] and elsewhere in this volume.
3Except that attention is usually restricted to “one-shot subspace codes”, i.e. subsets of the alphabet,
which makes no sense in the classical case.

Partial Spreads and Vector Space Partitions
133
sion, we call C a constant-dimension code. For a constant-dimension code C we
have dS(X, Y) = 2dI(X, Y) for all X, Y ∈C , so that we can restrict attention to the
subspace distance. Constant-dimension codes are the most suitable for coding pur-
poses, and the quest for good system performance leads straight to the problem of
determining the maximum possible cardinality Aq(v, d; k) of a constant-dimension-
k code in Fv
q with minimum subspace distance d. For two codewords X and Y of
dimension k the inequality dS(X, Y) ≥d is equivalent to dim(X ∩Y) ≤k −d/2.4
Thus, the maximum possible minimum distance of a constant-dimension code with
codewords of dimension k is 2k. This extremal case has been studied under the name
“partial spreads” in Finite Geometry for several decades. A partial k-spread in Fv
q is
a collection of k-subspaces with pairwise trivial, i.e., zero-dimensional intersection.
Translating this notion into Projective Geometry and identifying thereby, as usual,
subspaces of Fv
q with their sets of incident points, we have that a partial k-spread in
Fv
q is the same as a set of mutually disjoint k-subspaces, or (k −1)-dimensional ﬂats
in the geometric view, of the geometry PG(v −1, Fq).5
With the history of partial spreads in mind, it comes as no surprise that the sharpest
bounds on the maximal code sizes Aq(v, d; k) of constant-dimension codes are typ-
ically known for this special subclass. The primary goal of this survey is to collect
all available information on the numbers Aq(v, 2k; k) and present this information
in an accessible way. Following standard practice in Finite Geometry, we will refer
to partial k-spreads of size Aq(v, 2k; k) as maximal partial k-spreads.6
In the case of a perfect packing, i.e., a partition of the point set of PG(v −1, Fq),
we speak of a k-spread. Partitions into subspaces of possibly different dimensions are
equivalent to vector space partitions. A vector space partition C of Fv
q is a collection
of nonzero subspaces with the property that every non-zero vector is contained in a
unique member of C . If C contains md subspaces of dimension d, then C is said to
be of type kmk · · · 1m1. Zero frequencies md = 0 are usually suppressed.7 So, partial
k-spreads are just the special case of vector space partitions, in which all members
have dimension either k or 1. For k ≥2 (the case k = 1 is trivial) the members of
dimension 1 correspond to points not covered by a k-subspace of the partial spread
and are called holes in this context.
Although vector space partitions can be seen as a mixed-dimension analogue of
partial spreads, they are not usable as subspace codes of their own.8 However, it
turns out that they provide an appropriate framework to study bounds on the sizes of
partial spreads.
4Note that the distance between codewords of the same dimension, and hence also the minimum
distance of a constant-dimension code, is an even integer.
5In other words, partial spreads are just packings of the point set of a projective geometry
PG(v −1, Fq) into subspaces of equal dimension.
6The weaker property of complete (i.e., inclusion-maximal) partial spreads will not be considered.
7Since 	
X∈C dim(X) = 	
d dmd = v, the type of C can be viewed as an ordinary integer partition
of v.
8The subspace distance dS(X, Y) depends not only on dim(X ∩Y) but also on dim(X) and dim(Y),
which are not constant in this case.

134
T. Honold et al.
There is a vast amount of related work that we will not cover in this survey:
Partial spreads have also been studied for combinatorial designs and in polar spaces;
for the latter see, e.g., [5, 21]. In the special case v = 2k spreads can be used to
deﬁne translation planes and provide a rich source for constructing non-desarguesian
projective planes [41, 42, 51]. Also motivated by this geometric point-of-view, partial
k-spreads in F2k
q of size close to the maximum size (given by Theorem 1) have been
studied extensively. Most of this research has focused on partial spread replacements
and complete partial spreads, while we consider only partial spreads of maximum
cardinality and hence do not touch the case v = 2k (except for Theorem 1). The
classiﬁcation of all (maximal) partial spreads up to isomorphism, see e.g. [55], is
also not treated here. Further, there is a steady stream of literature that characterizes
the existing types of vector space partitions in Fv
2 for small dimensions v. Here,
we touch only brieﬂy on some results that are independent of the ambient space
dimension v and refer to [30] otherwise.
The remaining part of this chapter is structured as follows. In Sect.2 we review
some, mostly classical, bounds and constructions for partial spreads. After intro-
ducing the concept of qr-divisible sets and codes in Sect.3, we are able to obtain
improved upper bounds for partial spreads in Theorems 9 and 10. Constructions for
qr-divisible sets are presented in Sect.4, some non-existence results for qr-divisible
sets are presented in Sect.5, and we close this survey with a collection of open
research problems in Sect.6.
2
Bounds and Constructions for Partial Spreads
Counting points in Fv
q and Fk
q gives the obvious upper bound Aq(v, 2k; k) ≤
v
1

q/
k
1

q = (qv −1) /

qk −1

for the size of a partial k-spread in Fv
q. Equality
corresponds to the case of spreads, for which a handy existence criterion is known
from the work of Segre in 1964.9
Theorem 1 ([62, Sect. VI], [17, p. 29]) Fv
q contains a k-spread if and only if k is a
divisor of v.
Since qv−1
qk−1 is an integer if and only if k divides v (an elementary number theory
exercise), only the constructive part needs to be shown. To this end we write v = kt
for a suitable integer t, take the ambient space V as the restriction (“ﬁeld reduction”)
of (Fqk)t to Fq, which clearly has dimension v, and deﬁne the k-spread S in V/Fq as
the set of 1-subspaces of V/Fqk. That S is indeed a k-spread, is easily veriﬁed: Each
member of S has dimension k over Fq; the members form a vector space partition
of V (this property does not depend on the particular ﬁeld of scalars); and the size
t
1

qk = qv−1
qk−1 of S is as required.10
9Segre in turn built to some extent on work of André, who had earlier considered the special case
v = 2k in his seminal paper on translation planes [1].
10Alternatively, the member of S containing a nonzero vector x is the k-subspace Fqk x of V/Fq.

Partial Spreads and Vector Space Partitions
135
Example 1 We consider the parameters q = 3, v = 4, and k = 2. Using canonical
representatives in F9 ≃F3[x]/(x2 + 1), the
2
1

9 = 10 points in F2
9 are generated by

0
1

,

1
0

,

1
1

,

1
2

,

1
x

,

1
x + 1

,

1
x + 2

,

 1
2x

,

1
2x + 1

,

1
2x + 2

.
The
particular
point
P = F9

1
x+1

=
 0
0

,

1
x+1

,

2
2x+2

,

x
x+2

,
 x+1
2x

,
 x+2
1

,

2x
2x+1

,
 2x+1
x

,
 2x+2
2

on the projective line PG(1, F9) deﬁnes a 2-
subspace of F2
9/F3 ∼= F4
3, whose 4 associated points are F3x, x ∈P, x ̸=
 0
0

; and
similarly for the other points of PG(1, F9). These ten 2-subspaces form the 2-spread
S .
Using any F3-isomorphism F2
9/F3 ∼= F4
3, we can translate S into a 2-spread S ′
of the standard vector space F4
3. Taking, for example, coordinates with respect to the
basis (1, x) of F9/F3 and extending to F2
9 in the obvious way translates P into the
2-subspace of F4
3 with vectors
⎛
⎜⎜⎝
0
0
0
0
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
1
0
1
1
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
2
0
2
2
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
0
1
2
1
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
1
1
0
2
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
2
1
1
0
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
0
2
1
2
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
1
2
0
1
⎞
⎟⎟⎠,
⎛
⎜⎜⎝
2
2
2
0
⎞
⎟⎟⎠.
The other members of S ′ are obtained in the same way.
We remark that k-spreads are a special case of subspace designs, see chapters “q-
Analogs of Designs: Subspace Designs” and “Computational Methods in Subspace
Designs”.
From now on we assume that k does not divide v and write v = tk + r with
1 ≤r ≤k −1. Since the cases t ∈{0, 1} are trivial (Aq(r, 2k; k) = 0 and Aq(k +
r, 2k; k) = 1), we also assume t ≥2. The stated upper bound then takes the form
Aq(v, 2k; k) ≤
qv −1
qk −1

= qtk+r −qr
qk −1
+
qr −1
qk −1

=
t−1

s=0
qsk+r = qr
t
1

qk.
(2.1)
We also see from this computation that the number of holes of a partial k-spread
is at least qv−1
q−1 mod qk−1
q−1 = qr−1
q−1 . However, as we will see later, this bound can be
improved further.
In accordance with (2.1) we make the following deﬁnition (similar to that in [7]):
The number σ deﬁned by Aq(v; 2k; k) = 	t−1
s=0 qsk+r −σ is called the deﬁciency of
the maximal partial k-spreads in Fv
q.11 From (2.1) we have σ ≥0. In terms of the
deﬁciency, the minimum possible number of holes is σ · qk−1
q−1 + qr−1
q−1 .
Our next goal is to derive a good lower bound for Aq(v, 2k; k) (equivalently, a
lowerboundforthecorrespondingdeﬁciency)byconstructingalargepartialk-spread
11This makes sense also for r = 0: Spreads are assigned deﬁciency σ = 0.

136
T. Honold et al.
in Fv
q. For this we will employ a special case of the echelon-Ferrers construction for
general subspace codes [24], which involves only standard maximum rank distance
codes of full row rank. More details on the echelon-Ferrers construction can be found
in Chapter “Constructions of Constant Dimension Codes”. For maximum rank dis-
tance codes see Chapters “Codes Endowed with the Rank Metric” and “Constructions
of Cyclic Subspace Codes and Maximum Rank Distance Codes”.
To this end, recall that every k-subspace X of Fv
q is the row space of a unique
“generating” matrix A ∈Fk×v
q
in reduced row-echelon form, which can be obtained
by applying the Gaussian elimination algorithm to an arbitrary generating matrix of
X. This matrix A is called canonical matrix of X, and is uniquely speciﬁed by its k
pivot columns 1 ≤j1 < j2 < · · · < jk ≤v (forming a k × k identity submatrix of A)
and the complementary submatrix B ∈Fk×(v−k)
q
, which has zero entries in positions
(i, j) with j ≤ji −i but otherwise can be arbitrary. The k-set { j1, . . . , jk} will be
named pivot set of X. The positions of the unrestricted entries in B form the Ferrers
diagram of an integer partition, as shown in the following for the cases v = 8, k = 3,
(i1, i2, i3) = (1, 2, 3), (2, 4, 7).
matrix shape
Ferrers diagram
integer partition
⎛
⎝
1
0
0
∗
∗
∗
∗
∗
0
1
0
∗
∗
∗
∗
∗
0
0
1
∗
∗
∗
∗
∗
⎞
⎠
• • • • •
• • • • •
• • • • •
15 = 5 + 5 + 5
⎛
⎝
0
1
∗
0
∗
∗
0
∗
0
0
0
1
∗
∗
0
∗
0
0
0
0
0
0
1
∗
⎞
⎠
• • • •
• • •
•
8 = 4 + 3 + 1
(2.2)
The following lemma is a special case of [24, Lemma 2].
Lemma 1 If subspaces X, Y of Fv
q have disjoint pivot sets, they are itself disjoint
(i.e., X ∩Y = {0}).
Proof A nonzero vector in X must have its pivot (ﬁrst nonzero position) in the pivot
set of X, and similarly for Y. The result follows.
□
Now we focus on the special case in which the pivot set is {1, . . . , k}, i.e., the
canonical matrix has the “systematic” form A = (Ik|B). For matrices A, B ∈Fk×v
q
the rank distance is deﬁned as dR(A, B) := rk(A −B). Codes based on the rank
distance are discussed in detail in Chapter “Codes Endowed with the Rank Metric”.
The subspace distance of two k-subspaces with pivot set {1, . . . , k} can be computed
from the rank distance of the corresponding canonical matrices:
Lemma 2 ([64, Proposition 4]) Let X, X′ be k-subspaces of Fv
q with canonical
matrices (Ik|B) and (Ik|B′), respectively. Then dS(X, X′) = 2 · dR(B, B′). 12
12More generally, this formula holds if X and X′ have the same pivot set and B, B′ ∈Fk×(v−k)
q
denote the corresponding complementary submatrices in their canonical matrices; see e.g. [63,
Corollary 3].

Partial Spreads and Vector Space Partitions
137
Proof The matrix

Ik B
Ik B′

generates X + X′ and reduces via Gaussian elimina-
tion to

Ik
B
0 B′ −B

. Hence dim(X + X′) = k + rk(B′ −B) = k + dR(B, B′) and
dS(X, X′) = 2 dim(X + X′) −2k = 2 dR(B, B′).
□
The so-called lifting construction [64, Sect. IV.A] associates with a matrix code
B ⊆Fk×(v−k)
q
the constant-dimension code C in Fv
q whose codewords are the k-
spaces generated by (Ik|B), B ∈B. By Lemma 2, the code C is isometric to B with
scale factor 2. In particular, C is a partial k-spread if and only if B has minimum
rank distance dR(B) = k.
Lemma 3 There exists a partial k-spread S of size qv−k in Fv
q whose codewords
cover precisely the points outside the (v −k)-subspace S = {x ∈Fv
q; x1 = x2 =
· · · = xk = 0}.
Proof Write n = v −k and consider a matrix representation M : Fqn →Fn×n
q
,
obtained by expressing the multiplication maps μα : Fqn →Fqn, x →αx (which are
linear over Fq) in terms of a ﬁxed basis of Fqn/Fq. Then M(α + β) = M(α) + M(β),
M(αβ) = M(α)M(β), M(1) = In, and hence all matrices in M(Fqn) are invertible
and have mutual rank distance n.13
Now let B ⊆Fk×n
q
be the matrix code obtained from M(Fqn) by deleting the last
n −k rows, say, of every matrix. Then #B = qn and dR(B) = k. Hence by applying
the lifting construction to B we obtain a partial k-spread S in Fv
q of size qn = qv−k
(Lemma 2).
The codewords in S cover only points outside S (compare the proof of Lemma 1).
It remains to show that every such point is covered. This can be done by a counting
argument or in the following more direct fashion: Let a ∈Fk
q \ {0}, b ∈Fv−k
q
be arbi-
trary vectors and consider the equation aX = b for X ∈B. Since rk(X −X′) = k
for X ̸= X′, the qv−k elements aX, X ∈B, are distinct and hence account for
all elements in Fv−k
q
. Thus the equation has a solution B ∈B, and the point
P = Fq(a|b) = Fqa(Ik|B) is covered by the codeword in S with canonical matrix
(Ik|B).
□
Now we are ready for the promised construction of large partial k-spreads.
Theorem 2 ([7]) Let v, k be positive integers satisfying v = tk + r, t ≥2 and 1 ≤
r ≤k −1. There exists a partial k-spread S in Fv
q of size
#S = 1 +
t−1

s=1
qv−sk = 1 +
t−1

s=1
qsk+r,
and hence we have Aq(v, 2k; k) ≥1 + 	t−1
s=1 qsk+r.
13In ring-theoretic terms, the matrices in M(Fqn) form a maximal subﬁeld of the ring of n × n
matrices over Fq.

138
T. Honold et al.
The corresponding bound for the deﬁciency is σ ≤qr −1. It depends only on k and
the residue r = v mod k.
It had been conjectured in [21, Sect.2.2] that σ = qr −1 in general, but this
conjecture was later disproved in [22] by exhibiting a maximal partial plane spread
of size 34 in F8
2, which has deﬁciency 22 −2.
Proof The proof is by induction on t, using Lemma 2 and applying the inductive
hypothesis to S ∼= Fv−k
q
. The case v = k + r, in which Aq(v, 2k; k) = 1, serves as
the anchor of the induction.
□
The partial spread S exhibited in the proof of Theorem 2 consists of t −1 “layers”
S1, …, St−1 of decreasing sizes #Ss = qv−sk, whose codewords are obtained from
matrix representations of Fqv−sk and have their pivots in positions (s −1)k + 1, (s −
1)k + 2, …, sk (hence vanish on the ﬁrst (s −1)k coordinates). The union t−1
s=1 Ss
leaves exactly the points of a (k + r)-subspace S of Fv
q (the span of the last k + r
standard unit vectors) uncovered. Finally, one further k-subspace S0 of S is selected
to form S = t−1
s=1 Ss ∪{S0}.14
Example 2 We consider the particular case q = 2, v = 5, k = 3, in which #S =
23 + 1 = 9. In this case there is only one layer S1, which can be obtained from a
matrix representation of F8 as follows: Representing F8 as F2(α) with α3 + α + 1 =
0, we ﬁrst express the powers α j, 0 ≤j ≤6 in terms of the basis 1, α, α2 of F8/F2,
as in the following matrix:
M =
α0 α1 α2 α3 α4 α5 α6 α0 α1
α0 1
0
0
1
0
1
1
1
0
α1 0
1
0
1
1
1
0
0
1
α2 0
0
1
0
1
1
1
0
0
(2.3)
The seven consecutive 3 × 3 submatrices of this matrix, which has been extended to
the right in order to mimic the cyclic wrap-around, form a matrix ﬁeld isomorphic
to F8 (with 0 ∈F3×3
2
added). Similarly, the code B ⊂F2×3
2
is obtained by extracting
the ﬁrst seven consecutive 3 × 2 submatrices, adding 0 ∈F3×2
2
, and transposing; cf.
the proof of Lemma 3). Prepending the 2 × 2 identity matrix then gives the canonical
matrices of the 8 codewords of S1:

 1 0 0 0 0
0 1 0 0 0

,

 1 0 1 0 0
0 1 0 1 0

,

 1 0 0 1 0
0 1 0 0 1

,

 1 0 0 0 1
0 1 1 1 0

,

 1 0 1 1 0
0 1 0 1 1

,

 1 0 0 1 1
0 1 1 1 1

,

 1 0 1 1 1
0 1 1 0 1

,

 1 0 1 0 1
0 1 1 0 0

.
Finally, from the seven lines in the plane S = {x ∈F5
2; x1 = x2 = 0} a 9th codeword
L0 (moving line) is selected to form S = S1 ∪{L0}.
14The space S0 has been named moving subspace of S , since it can be freely “moved” within S
without affecting the partial spread property of S .

Partial Spreads and Vector Space Partitions
139
The partial line spread S is in fact maximal, as we will see in a moment,
and represents one of the 4 isomorphism types of maximal partial line spreads in
PG(F5
2) = PG(4, F2).15
Now we will reduce the upper bound (2.1) by a summand of q −1, which is
sufﬁcient to settle the caser = 1 and hence determine the numbers Aq(tk + 1, 2k; k).
The key ingredient will be the observation that a partial k-spread induces in every
hyperplane a vector space partition, whose members have dimension k, k −1, or
1. Before turning to the general case, which is a little technical, we continue the
preceding example and illustrate the method for partial line spreads in F5
2.
The geometry PG(4, F2) has 31 points, each line containing 3 points, and thus it
is conceivable that a partial line spread S of size 10 exists in PG(4, F2). But in fact it
does not. To prove this, consider a hyperplane (solid) H in PG(4, F2). If H contains
α lines of S , it meets the remaining #S −α lines in a point, giving the constraint
α · 3 + (#S −α) · 1 ≤15, the total number of points in H. This is equivalent to
#S ≤15 −2α. In order to complete the proof, we need to show that there exists
a hyperplane containing at least 3 lines of S . This can be done by an averaging
argument. On average, a hyperplane contains

H
#{L ∈S ; L ⊂H}
25 −1
=

L∈S
#{H; H ⊃L}
25 −1
= #S (23 −1)
25 −1
= 7
31 · #S
(2.4)
lines of S . If #S ≥9, this number is > 2, implying the desired conclusion σ ≥1.16
The general case is the subject of the following
Theorem 3 ([21, Theorem 2.7(a)]) The deﬁciency of a maximal k-spread in Fv
q,
where k does not divide v, is at least q −1.
Proof Reasoning as in the preceding example gives α · qk−1
q−1 + (#S −α) qk−1−1
q−1
≤
qtk+r−1−1
q−1
and hence the bound
#S ≤qtk+r−1 −1 −α(qk −qk−1)
qk−1 −1
(2.5)
for any partial k-spread S having a hyperplane incident with α members of S .
Now suppose #S = 1 + 	t−1
s=1 qsk+r, the same size as the partial k-spread in
Theorem 2. In this case the average number of codewords contained in a hyperplane is
15The full classiﬁcation, including also partial line spreads of smaller size, can be found in [26].
To our best knowledge there is only one further nontrivial parameter case, where a classiﬁcation of
maximal (proper) partial spreads is known, viz. the case of plane spreads in PG(6, F2), settled in
[38].
16In this particular case one may also argue as follows: If #S = 10 then there is only one hole and
the hyperplane constraint becomes 3α + (10 −α) + h = 15, where h ∈{0, 1}. This forces α = 2
and h = 1, i.e., every hyperplane should contain the hole. This is absurd, of course.

140
T. Honold et al.
q(t−1)k+r −1
qtk+r −1

1 +
t−1

s=1
qsk+r

=
1
qtk+r −1
2t−2

s=t
qsk+2r −
t−2

s=1
qsk+r −1

=
1
qtk+r −1
2t−2

s=t
qsk+2r −
t−2

s=0
qsk+r + qr −1

=
t−2

s=0
qsk+r +
qr −1
qtk+r −1.
It follows that S , and likewise all partial k-spreads of deﬁciency ≤qr −1, have a
hyperplane containing at least 1 + 	t−2
s=0 qsk+r codewords. Substituting this number
into (2.5) gives
#S ≤
1
qk−1 −1

qtk+r−1 −1 −

1 +
t−2

s=0
qsk+r

(qk −qk−1)

=
1
qk−1 −1

qtk+r−1 −1 −qk + qk−1 −
t−1

s=1
qsk+r +
t−2

s=0
qsk+r+k−1

= 1 +
t−2

s=1
qsk+r + qtk+r−1 −qk −q(t−1)k+r + qr+k−1
qk−1 −1
= 1 +
t−1

s=1
qsk+r + qr+k−1 −qk
qk−1 −1
= 1 +
t−1

s=1
qsk+r + qr −q + qr −q
qk−1 −1
=
t−1

s=0
qsk+r −(q −1) + qr −q
qk−1 −1,
valid now for any partial k-spread S in Fv
q. Since the last summand is < 1, we obtain
the desired conclusion σ ≥q −1.
□
Theorem 3 has the following immediate corollary, established by Beutelspacher
in 1975, which settles the case r = 1 completely.
Corollary 1 ([Theorem 4.1]; see also [7, 36] for the special case q = 2)
For
integers k ≥2 and v = tk + 1 with t ≥1 we have Aq(v, 2k; k) = 1 + 	t−1
s=1 qsk+1,17
with corresponding deﬁciency σ = q −1.18
In particular, maximal partial line spreads in Fv
q, v odd (the case where no line
spreads exist), have size qv−2 + qv−4 + · · · + q3 + 1, deﬁciency q −1, and q2 holes.
17This can also written as Aq(v, 2k; k) = q1 · qv−1−1
qk−1 −q + 1 = qv−qk+1+qk−1
qk−1
.
18The corresponding number of holes is qk.

Partial Spreads and Vector Space Partitions
141
In his original proof of the corollary Beutelspacher considered the set of holes
N and the average number of holes per hyperplane, which is less than the total
number of holes divided by q. An important insight was the relation #N ≡#(H ∩N)
(mod qk−1) for each hyperplane H, i.e., the number of holes per hyperplane satisﬁes
a certain modulo constraint. We will see this concept in full generality in Sect.3.
In terms of integer linear programming, the upper bound is obtained by an integer
rounding cut. The construction in [7, Theorem 4.2] recursively uses arbitrary k′-
spreads, so that it is more general than the one of Theorem 2.
For a long time the best known upper bound on Aq(v, 2k; k), i.e., the best known
lower bound on σ, was the one obtained by Drake and Freeman in 1979:
Theorem 4 (Corollary 8 in [20]) The deﬁciency of a maximal partial k-spread in Fv
q
is at least ⌊θ⌋+ 1 = ⌈θ⌉,19 where 2θ =

1 + 4qk(qk −qr) −(2qk −2qr + 1).
The authors concluded from the existence of a partial spread the existence of
a (group-constructible) (s,r, μ)-net and applied [11, Theorem 1B]—a necessary
existence criterion formulated for orthogonal arrays of strength 2 by Bose and Bush
in 1952. The underlying proof technique can be further traced back to [60] and is
strongly related to the classical second-order Bonferroni Inequality [10, 25]; see also
[39, Sect.2.5] for an application to bounds for subspace codes.
Given Theorem 1 and Corollary 1, the ﬁrst open binary case is A2(8, 6; 3). The
constructionfromTheorem2givesapartialspreadofcardinality33,whileTheorem4
implies an upper bound of 34. As already mentioned, in 2010 El-Zanati et al. [22]
found a sporadic partial plane spread in F8
2 of cardinality 34 by a computer search.
Together with the following easy lemma, this completely answers the situation for
partial plane spreads in Fv
2; see Corollary 2 below.
Lemma 4 For ﬁxed q, k and r the deﬁciency σ is a non-increasing function of
v = kt + r.
Proof Let S be a maximal partial k-spread in Ftk+r
q
and σ its deﬁciency, so that
Aq(tk + r, 2k; k) = 	t−1
s=0 qsk+r −σ. We can embed S into F(t+1)k+r
q
by prepending
k zeros to each codeword. Then Lemma 3 can be applied and yields a partial k-
spread S ′ in F(t+1)k+r
q
of size qtk+r, whose codewords are disjoint from those in S .
This implies Aq((t + 1)k + r, 2k; k) ≥#S ∪S ′ = 	t
s=0 qsk+r −σ, and hence the
deﬁciency σ ′ of a maximal partial k-spread in F(t+1)k+r
q
satisﬁes σ ′ ≤σ.
□
So, any improvement of the best known lower bound for a single parameter case
gives rise to an inﬁnite series of improved lower bounds. Unfortunately, so far, the
sporadic construction in [22] is the only known example being strictly superior to
the general construction of Theorem 2.
19Assuming 1 + 4qk(qk −qr) = 1 + 4qk+r(qk−r −1) = (2z −1)2 = 1 + 4z(z −1) for some
integer z > 1 implies qk+r | z or qk+r | z −1, so that z ≥qk+r, which is impossible for (k,r) ̸=
(1, 0). Thus, 2θ /∈Z, so that θ /∈Z and ⌊θ⌋+ 1 = ⌈θ⌉.

142
T. Honold et al.
Corollary 2 For each integer m ≥2 we have A2(3m, 6; 3) = 23m−1
7
, A2(3m +
1, 6; 3) = 23m+1−9
7
, and A2(3m + 2, 6; 3) = 23m+2−18
7
. The corresponding deﬁciencies
are 0, 1 and 2, respectively.
Very recently, the case q = r = 2 was completely settled. For k = 3 the answer
is given in the preceding corollary, and for k ≥4 by the following
Theorem 5 ([46, Theorem 5]) For integers k ≥4 and v = tk + 2 with t ≥1 we
have σ = 3 and A2(kt + 2, 2k; k) = 1 + 	t−1
s=1 2tk+2 = 2kt+2−3·2k−1
2k−1
.20
The technique used to prove this theorem is very similar to the one presented in
the proof of Theorem 3.
Corollary 3 We
have
A2(4m, 8; 4) = 24m−1
15 .
A2(4m + 1, 8; 4) = 24m+1−17
15
,
A2(4m + 2, 8; 4) = 24m+2−49
15
, and 24m+3−113
15
≤A2(4m + 3, 8; 4) ≤24m+3−53
15
for all
m ≥2. The corresponding deﬁciencies are 0, 1, 3 and 3 ≤σ ≤7, respectively
As a consequence, the ﬁrst unknown binary case is now 129 ≤A2(11, 8; 4) ≤
133.21 For r = 2 and q = 3 the upper bound of Theorem 4 has been decreased by 1:
Lemma 5 (cf.[46, Lemma 4]) For integers t ≥2 and k ≥4, we have σ ≥5 and
A3(kt + 2, 2k; k) ≤3kt+2−32
3k−1
−5.
Again, the proof technique is very similar to that used in the proof of Theorem 3.
Theorem 2 is asymptotically optimal for k ≫r = v mod k, as recently shown by
N˘astase and Sissokho:
Theorem 6 ([59, Theorem 5]) If k >
r
1

q then σ = qr −1 and Aq(v, 2k; k) =
1 + 	t−1
s=1 qsk+r.22
Choosing q = r = 2, this result covers Theorem 5. The same authors have reﬁned
their analysis, additionally using Theorem 14 from the theory of vector space par-
titions, to obtain improved upper bounds for some of the cases k ≤
r
1

q, see [58,
Theorem 6 and 7]. Using the theory of qr-divisible codes, presented in the next
section, we extend their results further in Corollary 7 and Theorem 10.
3
qr-divisible Sets and Codes
The currently most effective approach to good upper bounds for partial spreads
follows the original idea of Beutelspacher and considers the set of holes as a stand-
alone object. As it appears in the proof of Beutelspacher, the number of holes in a
20Thus in all these cases σ = 22 −1 and the partial spreads of Theorem 2 are maximal. This notably
differs from the case k = 3.
21The upper bound can be sharpened to 132, as we will see later.
22This corresponds again to the upper bound σ = qr −1.

Partial Spreads and Vector Space Partitions
143
hyperplane satisﬁes a certain modulo constraint. In this section we consider sets of
points in PG(v −1, Fq) having the property that modulo some integer Δ > 1 the
number of points in each hyperplane is the same. Such point sets are equivalent
to Δ-divisible codes [68, 69] with projectively distinct coordinate functionals (so-
called projective codes), and this additional restriction forces Δ to be a power of
the same prime as q. Writing q = pe, p prime, and Δ = p f , we have Δ = qr with
r = f/e ∈1
eZ.
We will derive several important properties of these qr-divisible sets and codes
and in particular observe that the set of holes of a partial spread is exactly of this type.
Without the notion of qr-divisible sets and the reference to the linear programming
method, almost all results of this section are contained in [47, 48]. A more extensive
introduction to the topic, including constructions and relations to other combinatorial
objects, is currently in preparation [31].
In what follows, we denote the point set of PG(v −1, Fq) by P and call for
subsets C ⊆P and subspaces X of Fv
q the integer #(C ∩X) = #{P ∈C ; P ⊆X}
the multiplicity of X with respect to C .
Deﬁnition 1 Let Δ > 1 be an integer. A set C of points in PG(v −1, Fq) is called
weakly Δ-divisible if there exists u ∈Z with #(C ∩H) ≡u (mod Δ) for each
hyperplane H of PG(v −1, Fq). If u ≡#C (mod Δ), we call C (strongly) Δ-
divisible.
Trivial cases are C = ∅(strongly Δ-divisible for any Δ) and C = P (weakly Δ-
divisible for any Δ, with largest strong divisor Δ = qv−1).23
It is well-known (see, e.g., [18, 65, Proposition 1]) that the relation C →C , asso-
ciating with a full-length linear [n, v] code C over Fq the n-multiset C of points in
PG(v −1, Fq) deﬁned by the columns of any generator matrix, induces a one-to-one
correspondence between classes of (semi-)linearly equivalent spanning multisets and
classes of (semi-)monomially equivalent full-length linear codes. Point sets corre-
spond in this way to projective linear codes, which are also characterized by the
condition d(C⊥) ≥3. The importance of the correspondence lies in the fact that it
relates coding-theoretic properties of C to geometric or combinatorial properties of
C . An example is the formula
w(aG) = n −#{1 ≤j ≤n; a · g j = 0} = n −#(C ∩a⊥),
(3.1)
where w denotes the Hamming weight, G = (g1| . . . |gn) ∈Fv×n
q
a generating matrix
of C, a · b = a1b1 + · · · + avbv, and a⊥is the hyperplane in PG(v −1, Fq) with
equation a1x1 + · · · + avxv = 0.
A linear code C is said to be Δ-divisible (Δ ∈Z>1) if all nonzero codeword
weights are multiples of Δ. A lower bound on the cardinality of Δ-divisible point
sets in PG(v −1, Fq) has been given in [3]. Following the Gleason-Pierce-Ward
Theorem on the divisibility of self-dual codes (see, e.g., [40, Chap. 9.1]), a rich
theory of divisible codes has been developed over time, mostly by H. N. Ward; cf.
23This is also true for v = 1, where C = ∅, P exhausts all possibilities.

144
T. Honold et al.
his survey [69]. One of Ward’s results implies that nontrivial weakly Δ-divisible point
sets in PG(v −1, Fq) are strongly Δ divisible and exist only in the case Δ = p f .
The proof uses the so-called standard equations for the hyperplane spectrum of C ,
which we state in the following lemma. The standard equations are equivalent to the
ﬁrst three MacWilliams identities for the weight enumerators of C and C⊥(stated
as Equation (3.6) below), specialized to the case of projective linear codes. The
geometric formulation, however, seems more in line with the rest of the paper.
Lemma 6 Let C be a set of points in PG(v −1, Fq) with #C = n, and let ai hyper-
planes of PG(v −1, Fq) contain exactly i points of C (0 ≤i ≤n). Then we have
n

i=0
ai =
v
1

q
,
(3.2)
n

i=1
iai = n ·
v −1
1

q
,
(3.3)
n

i=2

i
2

ai =

n
2

·
v −2
1

q
.
(3.4)
Proof Double-count24 incidences of the tuples (H), (P1, H), and ({P1, P2}, H),
where H is a hyperplane and P1 ̸= P2 are points contained in H.
□
IntheproofofTheorem7wewillneedthat (3.2)and (3.3)remaintrueforanymultiset
C of points in PG(v −1, Fq), provided points are counted with their multiplicities
in C and the cardinality #C is deﬁned in the obvious way. We will also need the
following concept of a quotient multiset. Let C be a set of points in PG(v −1, Fq)
and X a subspace of Fv
q. Deﬁne the multiset C /X of points in the quotient geometry
PG(Fv
q/X) by assigning to a point Y/X of PG(Fv
q/X) (i.e., Y satisﬁes dim(Y/X) =
1) the difference #(C ∩Y) −#(C ∩X) = #(C ∩Y \ X) as multiplicity.25 With this
deﬁnition it is obvious that #(C /X) = #C −#(C ∩X). In particular, if C is an n-set
and X = P is a point then #(C /P) = n −1 or n, according to whether P ∈C or
P /∈C , respectively.26
24The general (multiset) version of (3.4) has an additional summand of qv−2 · 	
P∈P
C (P)
2

on
the right-hand side, accounting for the fact that “pairs of equal points” are contained in
v−1
1

q
hyperplanes.
25This deﬁnition can be extended to multisets C by deﬁning the multiplicity of Y/X in C /X as the
sum of the multiplicities in C of all points in Y \ X.
26If C ↔C then the multisets C /P, P ∈P, are associated to the (v −1)-dimensional subcodes
D ⊂C, and the n points P ∈C correspond to the n subcodes D of effective length n −1 (“D is C
shortenedat P”).Thiscorrespondencebetweenpointsandsubcodesextendstoacorrelationbetween
PG(v −1, Fq) and PG(C/Fq), which includes the familiar correspondence between hyperplanes
and codewords as a special case; see [18, 65] for details.

Partial Spreads and Vector Space Partitions
145
Theorem 7 Let C ̸= ∅, P be a weakly Δ-divisible point set in PG(v −1, Fq), n =
#C , and C any linear [n, v]-code over Fq associated with C as described above.27
Then
(i) C is strongly Δ-divisible;
(ii) C is Δ-divisible;
(iii) Δ is a divisor of qv−2.
Proof (i) and (ii) are equivalent in view of (3.1).
First we prove (i). Let u be as in Deﬁnition 1. Choose a point P /∈C and let
C ′ = C /P. Then C ′ is an n-multiset of points in PG(Fv
q/P) ∼= PG(v −2, Fq) with
#(C ′ ∩H ′) ≡u (mod Δ) for each hyperplane H ′ of PG(Fv
q/P). The hyperplane
spectrum (a′
i) of C ′ satisﬁes (3.3) with v replaced by v −1. Multiplying the identity
for C ′ by q and subtracting from it the identity for C gives

i≥0
(u + iΔ)(au+iΔ −qa′
u+iΔ) = n

qv−1 −1
q −1
−qv−1 −q
q −1

= n.
Reading this equation modulo Δ and using (3.2) further gives
n ≡u

i≥0
(au+iΔ −qa′
u+iΔ) = u

qv −1
q −1 −qv −q
q −1

= u
(mod Δ),
as desired. Thus (i) and (ii) hold.
For the proof of (iii) we use a point Q ∈C and its associated quotient multiset
C ′′ = C /Q, which satisﬁes #C ′′ = n −1 and #(C ′′ ∩H ′′) ≡u −1 (mod Δ) for
each hyperplane H ′′ of PG(Fv
q/Q). Subtracting (3.3) for C ′ and C ′′ gives

i≥0
(u + iΔ)a′
u+iΔ −

i≥0
(u −1 + iΔ)a′′
u−1+iΔ = qv−2 −1
q −1 .
Again reading the equation modulo Δ and using (3.2) gives
qv−2 −1
q −1
≡u

i≥0
a′
u+iΔ −(u −1)

i≥0
a′′
u−1+iΔ = qv−1 −1
q −1
(mod Δ)
or qv−2 ≡0 (mod Δ), as asserted.
□
Let us remark that Part (ii) of Theorem 7 also follows from [68, Theorem 3], which
asserts that a not necessarily projective code C satisfying the assumption of the
theorem must be either Δ-divisible or the juxtaposition of a Δ-divisible code and a
v-dimensional linear constant weight code. Since the latter is necessarily a repetition
27It is not required that C is spanning; if it is not then (iii) sharpens to “Δ is a divisor of qdim⟨C ⟩−2”.

146
T. Honold et al.
of simplex codes, this case does not occur for projective codes. Our proofs of (i),
(iii) use the very same ideas as in [68], translated into the geometric framework.28
Part (iii) of Theorem 7 says that exactly Δ-divisible point sets in PG(v −1, Fq)
exist only if Δ = qr with r ∈1
eZ and r ≤v −129; the whole point set P has Δ =
qv−1, and v −2 < r < v −1 does not occur. Conversely, it is not difﬁcult to see that
everydivisorΔ > 1ofqv−2 isthelargestdivisorofsomepointsetinPG(v −1, Fq).30
In the proof of Theorem 7 we have used that the (weak) divisibility properties of
C and its quotient multisets C /X are the same. Now we consider the restrictions
C ∩X, which correspond to residual codes of the associated code C.
Lemma 7 Suppose that C is a qr-divisible set of points in PG(v −1, Fq) and X a
(v −j)-subspace of Fv
q with 1 ≤j < r. Then the restriction C ∩X is qr−j-divisible.
Proof By induction, it sufﬁces to consider the case j = 1, i.e., X = H is a hyperplane
in PG(v −1, Fq).
The hyperplanes of PG(H) are the (v −2)-subspaces of Fv
q contained in H. Hence
the assertion is equivalent to #(C ∩U) ≡#C = u (mod qr−1) for every (v −2)-
subspace U ⊂Fv
q. By assumption we have #(C ∩Hi) ≡u (mod qr) for the q + 1
hyperplanes H1, . . . , Hq+1 lying above U. This gives
(q + 1)u ≡
q+1

i=1
#(C ∩Hi) = q · #(C ∩U) + #C ≡q · #(C ∩U) + u
(mod qr)
and hence u ≡#(C ∩U) (mod qr−1), as claimed.
□
As mentioned at the beginning of this section, the set of holes of a partial spread
provides an example of a qr-divisible set. The precise statement is given in the
following theorem, which is formulated for general vector space partitions.
Theorem 8 (i) Let C be a vector space partition of Fv
q of type tmt · · · sms1m1 with
ms > 0 (i.e., C has a member of dimension > 1 and s chosen as the smallest
such dimension). Then the points (i.e., 1-subspaces) in C form a qs−1-divisible
set.
(ii) The holes of a partial k-spread in Fv
q form a qk−1-divisible set.
Proof It is immediate that (i) implies (ii). For the proof of (i) let H be a hyperplane
of PG(v −1, Fq). The points in P \ H are partitioned into the afﬁne subspaces
X \ H for those X ∈C satisfying X ⊈H. If such a t-subspace X is not a point, we
have t ≥s and hence #(X \ H) = qt−1 ≡0 (mod qs−1). Moreover, we also have
#(P \ H) = qv−1 ≡0 (mod qs−1). It follows that the number of points in C that
are not contained in H is divisible by qs−1 as well, completing the proof.
□
28Readers may have noticed that, curiously, the 3rd standard equation (which characterizes projec-
tive codes) was not used at all in the proof.
29By this we mean that Δ is the largest divisor in the sense of Deﬁnition 1 or Theorem 7.
30If t = ⌊r⌋and r′ ∈{0, 1, . . . , e −1} is deﬁned by r = t + r′/e, then the union of pr′ parallel
afﬁne subspaces of dimension t + 1 has this property.

Partial Spreads and Vector Space Partitions
147
Theorem 8 explains our motivation for studying qr-divisible points sets in PG(v −
1, Fq). Before delving deeper into this topic, we pause for a few example applications
to partial spreads, which may help advertising our approach.
First we consider the problem of improving the upper bound (2.1) for the size
of a partial k-spread in PG(v −1, Fq). The bound is equivalent to #C ≥qr−1
q−1 for
the corresponding hole sets, which are qk−1-divisible by Theorem 8(ii). But the
smallest nontrivial qk−1-divisible point sets in PG(v −1, Fq) are the k-subspaces
of Fv
q, since these are associated to the constant-weight-qk−1 simplex code.31 Thus
#C ≥qk−1
q−1 > qr−1
q−1 , and equality in (2.1) is not possible. Together with Theorem 2
this already gives the numbers A2(tk + 1, 2k; k).
The preceding argument gives A2(8, 6; 3) ≤35, and as a second application, we
now exclude the existence of a partial plane spread of size 35 in F8
2. As already
mentioned, this also follows from the Drake-Freeman bound (Theorem 4) and forms
an important ingredient in the determination of the numbers A2(v, 6; 3). The hole
set C of such a partial plane spread has size 28 −1 −35 · 7 = 10 and is 4-divisible,
i.e., it meets every hyperplane in 2 or 6 points.
We claim that dim⟨C ⟩= 4. The inequality dim⟨C ⟩≥4 is immediate from #C =
10. The reverse inequality follows from the fact that the linear code C associated
with C is doubly-even, hence self-orthogonal, but cannot be self-dual.32
Given that dim⟨C ⟩= 4, the existence of C is readily excluded using the standard
equations:
a2 +
a6 = 15,
2a2 +
6a6 = 10 · 7,
2
2

a2 +
6
2

a6 =
10
2

· 3.
(3.5)
The unique solution of the ﬁrst two equations is a2 = 5, a6 = 10 (corresponding to
the 2-fold repetition of the [5, 4, 2] even-weight code), but it does not satisfy the
third equation (since this code is not projective).33
As already mentioned, the standard equations in Lemma 6 have a natural gen-
eralization in the language of linear codes. To this end let C be a point set of size
#C = n in PG(k −1, Fq), which is spanning,34 and C the corresponding projective
linear [n, k] code over Fq. The hyperplane spectrum (ai)0≤i≤n of C and the weight
distribution (Ai)0≤i≤n of C are related by Ai = (q −1)an−i for 1 ≤i ≤n (supple-
mented by A0 = 1, an = 0) and hence provide the same information about C . The
famous MacWilliams Identities, [53]
31This follows, e.g., by applying the Griesmer bound to the associated linear code, which has
minimum distance ≥qk−1 and dimension ≥k.
32Just recall that the length of any doubly-even self-dual binary code must be a multiple of 8.
33Adding 20 = 5 · 4, which accounts for the 5 pairs of equal points in the code, to the right-hand
side “corrects” the third equation.
34This assumption is necessary for the relation Ai = (q −1)an−i to hold.

148
T. Honold et al.
n−i

j=0

n −j
i

A j = qk−i ·
i
j=0

n −j
n −i

A⊥
j
for 0 ≤i ≤n,
(3.6)
relate the weight distributions (Ai), (A⊥
i ) of the (primal) code C and the dual code
C⊥= {y ∈Fn
q; x1y1 + · · · + xnyn = 0 for all x ∈C}. They can be solved for Ai (or
A⊥
i ), resulting in linear relations whose coefﬁcients are values of Krawtchouk poly-
nomials; see, e.g., [40, Chap 7.2] for details. In our case we have A⊥
1 = A⊥
2 = 0,
since C⊥has minimum distance d⊥≥3, and the ﬁrst three equations in (3.6) are
equivalent to the equations in Lemma 6.
Of course the Ai and the A⊥
i in (3.6) have to be non-negative integers. Omitting the
integrality condition yields the so-called linear programming method, see e.g. [40,
Sect.2.6], where the Ai and A⊥
i are variables satisfying the mentioned constraints.35
Given some further constraints on the weights of the code and/or the dual code, one
may check whether the corresponding polyhedron contains non-negative rational
solutions. In general, this is a very powerful approach and was used to compute
bounds for codes with a given minimum distance; see [15, 52]. Here we consider a
subset of the MacWilliams identities and use analytical arguments.36
By considering the average number of points per hyperplane, we can guarantee
the existence of a hyperplane containing a relatively small number of points of C . If
this number is nonzero, Lemma 7 allows us to lower-bound #C by induction.37
Lemma 8 Suppose that C ̸= ∅in PG(v −1, Fq) is qr-divisible with #C = a ·
qr+1 + b for some a, b ∈Z and y ∈N0 with y ≡(q −1)b (mod qr+1). Then
there exists a hyperplane H such that #(C ∩H) ≤(a −1) · qr + b+y
q
∈Z and
#(C ∩H) ≡b (mod qr).
Proof Set n = #C and choose a hyperplane H such that n′ := #(C ∩H) is minimal.
Then, by considering the average number of points per hyperplane, we have
n′ ≤
1
v
1

q
·

hyperplane H′
#(C ∩H′) = n ·
v −1
1

q
/
v
1

q
< n
q = a · qr + b
q ≤a · qr + b + y
q
.
Since n′ ≡b ≡b+y
q
(mod qr), this implies n′ ≤(a −1)qr + b+y
q .
□
Note that the stated upper bound does not depend on the speciﬁc choice of a and
b, i.e., there is no need to take a non-negative or small b. Choosing y as small as
35Typically, the A⊥
i are removed from the formulation using the explicit formulas based on the
Krawtchouk polynomials, which may of course also be done automatically in the preprocessing
step of a customary linear programming solver.
36The use of a special polynomial, like we will do, is well known in the context of the linear
programming method, see e.g. [9, Sect.18.1].
37This result is not new at all. In [7] Beutelspacher used such an average argument in his upper
bound on the size of partial spreads. Recently, N˘astase and Sissokho used it in [59, Lemma 9]. In
coding theory it is well known in the context of the Griesmer bound. One may also interpret it as
an easy implication of the ﬁrst two MacWilliams identities, see Lemma 20 and Corollary 9.

Partial Spreads and Vector Space Partitions
149
possible clearly gives the sharpest bound.38 If b ≥0, which one can always achieve
by suitably decreasing a, it is always possible to choose y = (q −1)b. However,
for q = 3, r = 2, and #C = 1 · 33 + 16 = 43, i.e., a = 1 and b = 16, Lemma 8
with y = (2 −1)16 = 16 provides the existence of a hyperplane H with n′ = #(C ∩
H) ≤0 · 32 + 16 = 16. Using y = 7 gives n′ ≤7 and n′ ≡7 (mod 32), so that n′ =
7. Applying the argument again yields a subspace of co-dimension 2 containing
exactly one hole. Indeed, Equation (3.4) is needed additionally in order to exclude
the possibility of n′ = 7, so that A3(8, 6; 3) ≤248, i.e., σ ≥4, cf. Theorem 4 stating
the same bound.
Corollary 4 Suppose that C ̸= ∅in PG(v −1, Fq) is qr-divisible with #C = a ·
qr+1 + b for some a, b, y ∈Z with y ≡(q −1)b (mod qr+1) and y ≥1. Further,
let g ∈Q is the largest number with qg | y, and j ∈Z satisﬁes 1 ≤j < r + 1 −
max{0, g −1}. Then there exists a (v −j)-subspace U such that #(C ∩U) ≤(a −
j) · qr+1−j +
b+[ j
1]q·y
q j
and #(C ∩U) ≡b (mod qr+1−j).
Proof In order to apply induction on j, using Lemmas 7 and 8, we need to ensure
n′ > 0 in all but the last step. The latter holds due to pqg ∤b.39
□
Choosing the same value of y in every step, in general is not the optimal way
to iteratively apply Lemma 8, even if y is chosen optimal for the ﬁrst step. To this
end, consider a 33-divisible set C ∈PG(v −1, F3) with #C = 31 · 34 + 49 = 2560,
which indeed exists as the disjoint union of 64 solids is an example. Here y = 17 with
y ≡(3 −1) · 49 (mod 34) is the optimal choice in Lemma 8, so that Corollary 4
guarantees the existence of a subspace U with co-dimension 3, #(C ∩U) ≤(31 −
3) · 34−3 +
49+[3
1]3·17
33
= 94 and #(C ∩U) ≡49 ≡1 (mod 31). However, applying
Corollary 4 with j = 2 and y = 17 guarantees the existence of a subspaceU ′ with co-
dimension 2, #(C ∩U ′) ≤(31 −2) · 34−2 +
49+[2
1]3·17
32
= 29 · 32 + 13 = 30 · 32 +
4 = 274, and #(C ∩U ′) ≡49 ≡4 (mod 9). Since C ∩U ′ is 31-divisible and 8 ≡
2 · 4 (mod 32), we can apply Lemma 8 with y = 8 and deduce the existence of a
hyperplane H of U ′ with #(C ∩(U ′ ∩H)) ≤29 · 31 + 4+8
3
= 91 and #(C ∩(U ′ ∩
H)) ≡4 ≡1 (mod 31), while U ′ ∩H has co-dimension 3.
In the context of partial spreads or, more generally, vector space partitions another
parametrization using the number of non-hole elements of the vector space partition
turns out to be very useful in order to state a suitable formula for y. In what follows
we will say that a vector space partition P of Fv
q has hole-type (t, s, m1) if P has
m1 holes (1-subspaces), 2 ≤s ≤t < v, and s ≤dim(X) ≤t for all non-holes in P.
Additionally, we assume that there is at least one non-hole.
Corollary 5 LetP beavectorspacepartitionofFv
q ofhole-type(t, s, m1),l, x ∈N0
with 	t
i=s mi = lqs + x, and b, c ∈Z with m1 = bqs + c ≥1. If x ≥2 and g is the
38Another parametrization for y is given by y = qb′ −b, where b′ ∈Z with b′ ≥b
q and b′ ≡b
(mod qr+1), so that y ∈N0. Due to b′ = b+y
q , y is minimal if and only if b′ is minimal.
39The proof shows that the second assertion of the Corollary is true for all (v −j)-subspaces U.

150
T. Honold et al.
largest integer such that qg divides x −1, then for each 0 ≤j ≤s −max{1, g}
there exists a (v −j)-dimensional subspace U containing 
m1 holes with 
m1 ≡c
(mod qs−j) and 
m1 ≤(b −j) · qs−j +c, where c =
c+[ j
1]q·(x−1)
q j
∈Z.
Proof We have
v
1

q = m1 + 	t
i=s mi
i
1

q. Multiplication by q −1 and reduction
modulo qs yields −1 ≡(q −1)c −x (mod qs), allowing us to apply Corollary 4
with x = y −1. Observe that the parameters g from Corollaries 4 and 5 differ by at
most 1 −1/e if q = pe.
□
So far, we can guarantee that some subspace contains not too many holes, since
the average number of holes per subspace would be too large otherwise. The modulo-
constraints captured in the deﬁnition of a qr-divisible set enable iterative rounding,
thereby sharpening the bounds. First we consider the special case of partial spreads,
and then we will derive some non-existence results for vector space partitions with
few holes.
Lemma 9 Let P be a vector space partition of type kmk1m1 of Fv
q with mk =
lqk+x, where l = qv−k−qr
qk−1 , x ≥2, k =
r
1

q +1−z+u > r, qg | x−1, qg+1 ∤x−1, and
g, u, z,r, x ∈N0.Formax{1, g} ≤y ≤k thereexistsa(v −k + y)-subspaceU with
L ≤(z + y −1 −u)q y + w holes, where w = −(x −1)
y
1

q and L ≡w (mod q y).
Proof Due to m1 =
v
1

q −mk ·
k
1

q =
r
1

qqk −
k
1

q(x −1), we have m1 = bqk +
c for b =
r
1

q and c = −
k
1

q(x −1), where qg′ | x −1 if and only if qg′ | c. Setting
s = t = k and j = k −y, we observe 0 ≤j ≤k −max{1, g}, since max{1, g} ≤
y ≤k. With this, we apply Corollary 5 and obtain an (n −k + y)-subspace U with
L ≤(b −j) · qk−j +
c +
 j
1

q · (x −1)
q j
= (z + y −1 −u) · q y −(x −1) ·
k
1

q −
k−y
1

q
qk−y
= (z + y −1 −u)q y −(x −1)
y
1

q
= (z + y −1 −u)q y + w
holes, so that L ≤(z + y −1 −u)q y + w and L ≡w (mod q y).
□
The parameterl is chosen in such a way that mk = lqk + x matches the cardinality
of the partial k-spread given by the construction in Theorem 2 for x = 1. Thus the
assumption x ≥2 is no real restriction. Actually, the chosen parametrization using
x in Corollary 5 makes it very transparent why the construction of Theorem 2 is
asymptotically optimal—as stated in Theorem 6. If the dimension k of the elements
of the partial spread is large enough, a sufﬁcient number of rounding steps can be
performed while the rounding process is stopped at x = 1 for the other direction. For
small k we will not reach the lower bound of the construction of Theorem 2, so that
there remains some room for better constructions.

Partial Spreads and Vector Space Partitions
151
Lemma 10 Let Δ = qs−1, m ∈Z, and P be a vector space partition of Fv
q
of hole-type (t, s, c). Then, τq(c, Δ, m) · qv−2
Δ2 −m(m −1) ≥0 and τq(c, Δ, m) ≥
0, where τq(c, Δ, m) = m(m −1)Δ2q2 −c(2m −1)(q −1)Δq + c(q −1)

c(q −
1) + 1

. If c > 0, then τq(c, Δ, m) = 0 if and only if m = 1 and c =
s
1

q.
Proof Adding (c −mΔ)

c −(m −1)Δ

times the ﬁrst, −

2c −(2m −1)Δ −1

times the second and twice the third standard equation from Lemma 6, and divid-
ing the result by Δ2/(q −1) gives (q −1) · 	⌊c/Δ⌋
h=0 (m −h)(m −h −1)ac−hΔ =
τq(c, Δ, m) · qn−2
Δ2 −m(m −1), due to the qs−1-divisibility. We observe ai ≥0 and
(m −h)(m −h −1) ≥0 for all m, h ∈Z. If m /∈{0, 1}, then τq(c, Δ, m) > 0.
Solving τq(c, Δ, 0) = 0 yields c ∈

0, −qs+1
q−1

and solving τq(c, Δ, 1) = 0 yields
c ∈

0,
s
1

q

.
□
We remark that, in the case of τq(c, Δ, m) = 0, their are either no holes at all or
the holes form an s-subspace. [11, Theorem 1.B] is quite similar to Lemma 10 and
its implications. The multipliers used in the proof can be directly read off from the
inverse matrix of
A =
⎛
⎝
1
1
1
a
b
c
a2 −a
b2 −b
c2 −c
⎞
⎠,
which is given by
A−1 =
1
(c −a)(c −b)(b −a)
⎛
⎝
bc(c −b)
−(c + b −1)(c −b)
(c −b)
−ac(c −a)
(c + a −1)(c −a)
−(c −a)
ab(b −a)
−(b + a −1)(b −a)
(b −a)
⎞
⎠
for distinct numbers a, b, c. With this, Lemma 10 can be derived in a conceptual
way. Consider the linear programming method with just the ﬁrst three MacWilliams
identities. For parameters excluded by Lemma 10 this small linear program is infea-
sible, which can be seen at a certain basis solution, i.e., a choice of linear inequal-
ities that are satisﬁed with equality. Solving for these equations, i.e., a change of
basis, corresponds to a non-negative linear combination of the inequality system.40
In the parametric case we have to choose the basis solution also depending on the
parameters. Actually, we have implemented a degree of freedom in Lemma 10 using
the parameter m. Here, the basis consists of two neighboring non-zero ai-entries,
parametrized by m, and an arbitrary ai, which plays no role when the resulting equa-
tion is solved for all remaining ai-terms. In this way we end up with an equation of
40If we relax ≥0-inequalities by adding some auxiliary variable on the left hand side and the
minimization of this variable, we can remove the infeasibility, so that we apply the duality theorem
of linear programming. Then, the mentioned multipliers for the inequalities are given as the solution
values of the dual problem.

152
T. Honold et al.
the form 	⌊c/Δ⌋
h=0 (m −h)(m −h −1)ac−hΔ = β, where the ai and their coefﬁcients
are non-negative. The use of the underlying quadratic polynomial is well known and
frequently applied in the literature; see the remarks after Theorem 4.
Lemma 11 For integers v > k ≥s ≥2 and 1 ≤i ≤s −1, there exists no vector
space partition P of Fv
q of hole-type (k, s, c), where c = i · qs −
s
1

q + s −1.41
Proof Since we have c < 0 for i ≤0, we can assume i ≥1 in the following. Let,
to the contrary, P be such a vector space partition and apply Lemma 10 with m =
i(q −1) onto P. We compute τq(c, qs−1, m) = (m −1 −a) qs + a(a + 1) using
c(q −1) = qs(m −1) + a, where a := 1 + (s −1)(q −1). Setting i = s −1 −y,
we have 0 ≤y ≤s −2 and τq(c, qs−1, m) = −qs(y(q −1) + 2) + (s −1)2q2 −
q(s −1)(2s −5) + (s −2)(s −3). If q = 2, then y ≥0 and s ≥2 yields
τ2(c, 2s−1, m) = −2s(y + 2) + s2 + s ≤

s2 −s −2s
+

2s −2s
< 0.
If s = 2, then we have y = 0 and τq(c, qs−1, m) = −q2 + q < 0. If q, s ≥3,
then we have q(2s −5) ≥s −3, so that τq(c, qs−1, m) ≤−2qs + (s −1)2q2 ≤
−2 · 3s−2q2 + (s −1)2q2 due to y ≥0 and q ≥3. Since 2 · 3s−2 > (s −1)2 for
s ≥3, we have τq(c, qs−1, m) < 0 in all cases. Thus, Lemma 10 yields a contra-
diction, since qn−2s > 0 and m(m −1) ≥0 for every integer m.
□
Now we are ready to present the ﬁrst improved (compared to Theorem 4) upper
bound for partial spreads, which also covers Theorem 6 setting z = 0.
Theorem 9 For integers r ≥1, t ≥2, u ≥0, and 0 ≤z ≤
r
1

q/2 with k =
r
1

q +
1 −z + u > r we have Aq(v, 2k; k) ≤lqk + 1 + z(q −1), where l = qv−k−qr
qk−1
and
v = kt + r.
Proof Apply Lemma 9 with x = 2 + z(q −1) ≥2 in order to deduce the existence
of a (v −k + y)-subspace U with L ≤(z + y −1 −u)q y −(x −1)
y
1

q holes,
where L ≡−(x −1)
y
1

q (mod q y).Now,weset y = z + 1.Observethatqg | x −1
implies g ≤z < y and we additionally have 1 ≤y = z + 1 ≤
r
1

q + 1 −z ≤t. If
z = 0, then y = 1, x = 2, and L ≤−uq −1 < 0. For z ≥1, we apply Lemma 11
to the subspace U with s = y, c = (z+y−1−u)q y −(x−1)
y
1

q −jq y = (y−
1−j −u)q y −
y
1

q +y−1 for some j ∈N0, and i = y −1 −j −u ∈Z. Thus,
Aq(n, 2k; k) ≤lqk + x −1.
□
The case z = 0 covers Theorem 6. The non-negativity of the number of holes in a
certain carefully chosen subspace is sufﬁcient to prove this fact. The case z = 1 was
announced in [59, Lemma 10] and proven in [58]. Since the known constructions
41For more general non-existence results of vector space partitions see e.g. [29, Theorem 1] and the
related literature. Actually, we do not need the assumption of an underlying vector space partition
of the mentioned type. The result is generally true for qs−1-divisible codes, since the parameter x
is just a nice technical short-cut to ease the notation.

Partial Spreads and Vector Space Partitions
153
for partial k-spreads give Aq(kt + r, 2k; k) ≥lqk + 1, see e.g. [7] or Theorem 2,
Theorem 9 is tight for k ≥
r
1

q + 1 and A2(8, 6; 3) = 34.
So far Lemma 10 was just applied in the case of Lemma 11 excluding the existence
of some very special vector space partitions. Next, we look at a subspace and consider
the number of holes, i.e., we apply Lemma 9 giving us the freedom to choose the
dimension of the subspace. Then Lemma 10, stating that a certain quadratic poly-
nomial is non-negative, can be applied. By minimizing this function in terms of the
free parameter m, we obtain the following result.
Theorem 10 For integers r ≥1, t ≥2, y ≥max{r, 2}, z ≥0 with λ = q y, y ≤k,
k =
r
1

q + 1 −z > r, v = kt + r, and l = qv−k−qr
qk−1 , we have Aq(v, 2k; k) ≤lqk +
 
λ −1
2 −1
2
√1 + 4λ (λ −(z + y −1)(q −1) −1)
!
.
Proof From Lemma 9 we conclude L ≤(z + y −1)q y −(x −1)
y
1

q and L ≡
−(x −1)
y
1

q (mod q y) for the number of holes of a certain (v−k+y)-subspace
U. Using the notation of Lemma 9, P ∩U := {P ∩U | P ∈P} is of hole-type
(k, y, L) if y ≥2. Next, we will show that τq(c, Δ, m) ≤0, where Δ = q y−1 and
c = iq y −(x −1)
y
1

q with 1 ≤i ≤z + y −1, for suitable integers x and m. Note
that, in order to apply Lemma 9, we have to satisfy x ≥2 and y ≥g for all integers
g with qg | x −1. Applying Lemma 10 then gives the desired contradiction, so that
Aq(n, 2k; k) ≤lqk + x −1.
We choose42 m = i(q −1) −(x −1) + 1, so that τq(c, Δ, m) = x2 −(2λ +
1)x + λ(i(q −1) + 2). Solving τq(c, Δ, m) = 0 for x gives x0 = λ + 1
2 ± 1
2θ(i),
where
θ(i) = √1 −4iλ(q −1) + 4λ(λ −1).
We
have
τq(c, Δ, m) ≤0
for
|2x −2λ −1| ≤θ(i). We need to ﬁnd an integer x ≥2 such that this inequal-
ity is satisﬁed for all 1 ≤i ≤z + y −1. The strongest restriction is attained for
i = z + y −1. Since z + y −1 ≤
r
1

q and λ = q y ≥qr, we have θ(i) ≥θ(z +
y −1) ≥1, so that τq(c, Δ, m) ≤0 for x =
 
λ + 1
2 −1
2θ(z + y −1)
!
. (Observe
x ≤λ + 1
2 + 1
2θ(z + y −1) due to θ(z + y −1) ≥1.) Since x ≤λ + 1, we have
x −1 ≤λ = q y, so that qg | x −1 implies g ≤y provided x ≥2. The latter is true
due to θ(z + y −1) ≤√1 −4λ(q −1) + 4λ(λ −1) ≤√1 + 4λ(λ −2) < 2(λ −
1), which implies x ≥
 3
2
!
= 2.
So far we have constructed a suitable m ∈Z such that τq(c, Δ, m) ≤0 for
x =
 
λ + 1
2 −1
2θ(z + y −1)
!
. If τq(c, Δ, m) < 0, then Lemma 10 gives a con-
tradiction, so that we assume τq(c, Δ, m) = 0 in the following. If i < z + y −1
we have τq(c, Δ, m) < 0 due to θ(i) > θ(z + y −1), so that we assume i =
z + y −1. Thus, θ(z + y −1) ∈N0. However, we can write θ(z + y −1)2 = 1 +
4λ (λ −(z + y −1)(q −1) −1) = (2w −1)2 = 1 + 4w(w −1) for some integer
w. If w /∈{0, 1}, then gcd(w, w −1) = 1, so that either λ = q y | w or λ = q y |
w −1. Thus, in any case, w ≥q y, which is impossible since (z + y −1)(q −1) ≥1.
42 Solving ∂τq(c,Δ,m)
∂m
= 0, i.e., minimizing τq(c, Δ, m), yields m = i(q −1) −(x −1) + 1
2 +
x−1
q y . For y ≥r we can assume x −1 < q y due to Theorem 2, so that up-rounding yields the
optimum integer choice. For y < r the interval

λ + 1
2 −1
2θ(i), λ + 1
2 + 1
2θ(i)

may contain no
integer.

154
T. Honold et al.
Finally, w ∈{0, 1} implies w(w −1) = 0, so that λ −(z + y −1)(q −1) −1 = 0.
Thus, z + y −1 =
y
1

q ≥
r
1

q since y ≥r. The assumptions y ≤k and k =
r
1

q +
1 −z imply z + y −1 =
r
1

q and y = r. This gives k = r, which is excluded.
□
An example where Theorem 10 is strictly superior to the results of [58, Theo-
rems 6,7] is given by A3(15, 12; 6) ≤19695.43 Setting y = k, we obtain Theorem 4.
Compared to [11, 20], the new ingredients essentially are qr-divisible sets and Corol-
lary 5, which allows us to choose y < k. Theorem 4, e.g., gives A2(15, 12; 6) ≤516,
A2(17, 14; 7) ≤1028, and A9(18, 16; 8) ≤3486784442, while Theorem 10 gives
A2(15, 12; 6) ≤515, A2(17, 14; 7) ≤1026, and A9(18, 16; 8) ≤3486784420. For
2 ≤q ≤9, 5 ≤k ≤19, there are 66 improvements in total, i.e., almost 19%, and the
maximum gap is 22. Next, we provide an estimation of the bound of Theorem 4.
Lemma 12 For integers 1 ≤r < k and q ≥2 we have
2qk −qr −q2r−k
b
<

1 + 4qk(qk −qr) ≤2qk −qr −q2r−k
b
,
where b = 3+2
√
2
2
> 2.91 and b = 16
3 < 5.34.
Proof Due to q ≥2 and k ≥r + 1 ≥2, we have
1 + 4qk(qk −qr) > 4qk(qk −qr) −q2r ·
≥0
"
#$
%

4
b −1 −2
bq −
1
b2q2

≥4qk(qk −qr) −4
bq2r + q2r + 2
bq3r−k + 1
b2 q4r−2k =

2qk −qr −q2r−k
b
2
.
Similarly, 1+4qk(qk−qr) ≤4qk(qk−qr) −q2r ·

4
b −1

≤

2qk−qr −q2r−k
b
2
.
□
Corollary 6 For integers 1 ≤r < k and t ≥2 we have Aq(kt + r, 2k; k) < lqk +
qr
2 + 1
2 +
q2r−k
3+2
√
2, where l = q(t−1)k+r−qr
qk−1
. If k ≥2r, then Aq(kt + r, 2k; k) < lqk +
1 + qr
2 .
Corollary 7 For integers r ≥1, t ≥2, and u, z ≥0 with k =
r
1

q + 1 −z + u > r
we have Aq(v, 2k; k) ≤lqk + 1 + z(q −1), where l = qv−k−qr
qk−1
and v = kt + r.
Proof Using Corollary 6, we can remove the upper bound z ≤
r
1

q/2 from The-
orem 9. If z >
r
1

q/2, then z ≥
r
1

q/2 + 1/2, so that Aq(v, 2k; k) < lqk + 1 +
qr
2 ≤lqk + 1 + qr−1
2
+ q−1
2
≤lqk + 1 + z(q −1) for k ≥2r. Thus, we can assume
43For 2 ≤q ≤9, 1 ≤v, k ≤100 the bounds of [58, Theorem 6,7] are covered by Theorem 10 and
Corollary 7. In many cases the bounds coincide.

Partial Spreads and Vector Space Partitions
155
r + 1 ≤k ≤2r −1 and r ≥2. With this, we have z ≥
r
1

q −2(r −1) and lqk +
1 + z(q −1) ≥lqk + qr −2(q −1)(r −1). It remains to show lqk + qr −2(q −
1)(r −1) ≥lqk + qr
2 + 1
2 +
q2r−k
3+2
√
2 ≥lqk + qr
2 + 1
2 +
qr−1
3+2
√
2, i.e., qr ≥1 +
2qr−1
3+2
√
2
+ 4(q −1)(r −1). The latter inequality is valid for all pairs (r, q) except (2, 2),
(2, 3), and (3, 2). In those cases it can be veriﬁed directly that lqk + 1 + z(q −1) is
not strictly less than the upper bound of Theorem 4. Indeed, both bounds coincide.
□
We remark that the ﬁrst part of Corollary 6 can be written as σ ≥qr−1
2
−
q2r−k
3+2
√
2. Unfortunately, Theorem 10 is not capable to obtain σ ≥⌊(qr −1)/2⌋. For
A2(17, 12; 6), i.e., q = 2 and r = 5, it gives σ ≥13 while ⌊(qr −1)/2⌋= 15. In
Lemma 23 we give a cubic analog to Lemma 10, which yields σ ≥14 for these
parameters.
4
Constructions for qr-divisible Sets
First note that we can embed every Δ-divisible point set C in PG(v −1, Fq) into
ambient spaces with dimension larger than v and, conversely, replace Fv
q by the span
⟨C ⟩without destroying the Δ-divisibility. Since in this sense v is not determined by
C , we will refer to C as a Δ-divisible point set over Fq. In the sequel we develop
a few basic constructions of qr-divisible sets. For the statement of the ﬁrst lemma
recall our convention that subspaces of Fv
q are identiﬁed with subsets of the point set
P of PG(v −1, Fq).
Lemma 13 Every k-subspace C of PG(v −1, Fq) with k ≥2 is qk−1-divisible.
Proof By the preceding remark we may assume k = v and hence C = P. In this
case the result is clear, since #P −#H = qv−1 for each hyperplane H.
□
In fact a k-subspace of Fv
q is associated to the k-dimensional simplex code over Fq
and Lemma 13 is well-known.
For a point set C in PG(v −1, Fq) we denote by χC its characteristic function,
i.e., χC : P →{0, 1} ⊂Z with χC (P) = 1 if and only if P ∈C .
Lemma 14 Let Ci be Δi-divisible point sets in PG(v −1, Fq) and ai ∈Z for
1 ≤i ≤m. If C ⊆P satisﬁes χC = 	m
i=1 aiχC i then C is gcd(a1Δ1, . . . , amΔm)-
divisible.
Proof We have #C = 	m
i=1 ai · #Ci and #(C ∩H) = 	m
i=1 ai · #(Ci ∩H) for each
hyperplane H. Since #(Ci ∩H) ≡#Ci (mod Δi), the result follows.
□
Lemma 14 shows in particular that the union of mutually disjoint qr-divisible sets is
again qr-divisible. Another (well-known) corollary is the following, which expresses
the divisibility properties of the MacDonald codes.44
44The generalization to more than one “removed” subspace is also quite obvious and expresses the
divisibility properties of optimal linear codes of type BV in the projective case [4, 35, 50].

156
T. Honold et al.
Corollary 8 Let X ⊊Y be subspaces of Fv
q and C = Y \ X. If dim(X) = s then C
is qs−1-divisible.
In particular afﬁne k-subspaces of Fv
q are qk−1 divisible.
Lemma 15 Let C1 ∈P1, C2 ∈P2 be qr-divisible point sets in PG(v1 −1, Fq),
respectively, PG(v2 −1, Fq). Then there exists a qr-divisible set C in PG(v1 + v2 −
1, Fq) with #C = #C1 + #C2.
Proof Embed the point sets C1, C2 in the obvious way into PG(Fv1
q × Fv2
q ) ∼=
PG(v1 + v2 −1, Fq), and take C as their union.
□
Let us note that the embedding dimension v in Lemma 15 is usually not the smallest
possible, and the isomorphism type of C is usually not determined by C1 and C2.45
In analogy to the Frobenius Coin Problem, cf. [8, 13, 28], we deﬁne F(q,r) as the
smallest positive integer such that a qr-divisible set over Fq (i.e., with some ambient
space Fv
q) with cardinality n exists for all integers n > F(q,r). Using Lemma 13,
Corollary 8, and Lemma 15, we conclude that F(q,r) ≤
r+1
1

q · qr+1 −
r+1
1

q −
qr+1, the largest integer not representable as a1
r+1
1

q + a2qr+1 with a1, a2 ∈Z≥0.46
The bound may also be stated as F(q,r) ≤	2r+1
i=r+2 qi −	r
i=0 qi.
As the disjoint union of qr-divisible sets is again qr-divisible, one obtains a wealth
of constructions. Consequently, the qr-divisible point sets not arising in this way are
of particular interest. They are called indecomposable.
The next construction uses the concept of a “sunﬂower” of subspaces, which
forms the q-analogue of the Δ-systems, or sunﬂowers, considered in extremal set
theory [23].47
Deﬁnition 2 Let X be a subspace of Fv
q and t ≥2 an integer. A t-sunﬂower in
Fv
q with center X is a set {Y1, . . . , Yt} of subspaces of Fv
q satisfying Yi ̸= X and
Yi ∩Y j = X for i ̸= j. The point sets Yi \ Xi are called petals of the sunﬂower.
Lemma 16 (i) The union of the petals of a q-sunﬂower in Fv
q with r-dimensional
center forms a qr-divisible point set.
(ii) The union of the petals and the center of a q + 1-sunﬂower in Fv
q with r-
dimensional center forms a qr-divisible point set.
Proof (i) Let F = {Y1, . . . , Yq} and C = q
i=1(Yi \ Xi) =
 F

\ X. We have
χC = 	q
i=1 χYi −qχX. Since dim(Yi) ≥r + 1, Yi is qr-divisible, and so is qχX.
Hence, by Lemma 14, C is qr-divisible as well.
(ii) follows from (i) by adding one further space Yq+1 to F.
□
45If not both C1 and C2 are subspaces, then disjoint embeddings into a geometry PG(v −1, Fq)
with v < dim⟨C1⟩+ dim⟨C2⟩exist as well.
46Note that gcd
r+1
1

q, qr+1
= 1 and recall the solution of the ordinary Frobenius Coin Problem.
47Our sunﬂowers need not have constant dimension, however.

Partial Spreads and Vector Space Partitions
157
Lemma 17 Let r ≥1 be an integer and 1 ≤i ≤qr + 1. There exists a qr-divisible
set Ci over Fq with #Ci =
2r
1

q + i ·

qr+1 −qr −
r
1

q

.
Proof Let Y = F2r
q and X1, . . . , Xqr+1 an r-spread in Y. After embedding Y in
a space Fv
q of sufﬁciently large dimension v, it is possible to choose q-sunﬂowers
F1, . . . , Fqr+1 in Fv
q with the following properties: Y ∈Fi for alli; dim(Z) = r + 1
for Z ∈Fi \ {Y}; Fi has center Xi; petals in different sunﬂowers Fi and F j
are either equal (to Y) or disjoint. Having made such a choice, we set Ci =
 F1 ∪· · · ∪ Fi

\ (X1 ∪· · · ∪Xi)
for
1 ≤i ≤qr + 1.
Then
χC i =
	
Z∈F 1∪···∪Fi χZ −qχX1 −· · · −qχXi is qr-divisible (again by Lemma 14), and
#Ci is as asserted.
□
Replacing S by some arbitrary q1-divisible set, we similarly obtain:
Lemma 18 Let C ′ be a q1-divisible set of cardinality n, then there exist q1-divisible
sets of cardinality n + i ·

q2 −q −1

for all 0 ≤i ≤n.
Our last construction in this section uses the concept of a cone.
Deﬁnition 3 Let X, Y be complementary subspaces of Fv
q with dim(X) = s,
dim(Y) = t (hence v = s + t) and B a set of points in PG(Y). The cone with vertex
X and base B is the point set C = 
P∈B(X + P).
Lemma 19 Let B be a qr-divisible point set in PG(v −1, Fq) with #B = m and
s ≥1 an integer.
(i) If m ≡0 (mod qr+1) then there exists a qr+s-divisible point set C in PG(v +
s −1, Fq) of cardinality #C = mqs.
(ii) If m(q −1) ≡−1 (mod qr+1) then there exists a qr+s-divisible point set C in
PG(v + s −1, Fq) of cardinality #C =
s
1

q + mqs.
Proof Embed Fv
q into Fv+s
q
as Y and consider a cone K in PG(v + s −1, Fq) with
base B and s-dimensional vertex X. The hyperplanes H ⊇X satisfy #(K \ H) =
qs · #(K \ H) ≡0 (mod qr+s). The hyperplanes H ⊉X intersect X + P, P ∈B,
in an s-subspace ̸= X, hence contain
 s
s−1

q = points in X and qs−1 points in K \ X.
It follows that #(K \ H) = qs−1 + m(qs −qs−1) = (1 + m(q −1))qs−1. Thus in
Case (ii) we can take C = K and in Case (i) we can take C = K \ X.48
□
The preceding constructions can be combined in certain nontrivial ways to yield
further constructions of qr-divisible point sets. We will return to this topic in Sect.6.1.
Nonetheless, we are only scratching the surface of a vast subject. Projective two-
weight codes with weights w1, w2 satisfying w2 > w1 + 1 are qr-divisible by Del-
sarte’s Theorem [16, Corollary 2]. This yields many further examples of qr-divisible
point sets; see [14] and the online-table at http://moodle.tec.hkr.se/~chen/research/
2-weight-codes. Codes meeting the Griesmer bound whose minimum distance is a
48Note that m(q −1) ≡0 (mod qr+1) is equivalent to m ≡0 (mod qr+1).

158
T. Honold et al.
multiple of q are qr-divisible [69, Proposition 13].49 Optimal codes of lengths strictly
above the Griesmer bound tend to have similar divisibility properties; see, e.g., Best
Known Linear Codes in Magma.
5
More Non-existence Results for qr-divisible Sets
For a point set C in PG(v −1, Fq) let T (C ) := {0 ≤i ≤c | ai > 0}, where ai
denotes the number of hyperplanes with #(C ∩H) = i.
Lemma 20 For integers u ∈Z, m ≥0 and Δ ≥1 let C in PG(v −1, Fq) be Δ-
divisible of cardinality n = u + mΔ ≥0. Then, we have (q −1) · 	
h∈Z,h≤m hau+hΔ
= (u + mΔ −uq) · qv−1
Δ −m, where we set au+hΔ = 0 if u + hΔ < 0.
Proof Rewriting the equations from Lemma 6 yields (q −1) · 	
h∈Z,h≤m au+hΔ =
q · qv−1 −1 and (q −1) · 	
h∈Z,h≤m(u + hΔ)au+hΔ = (u + mΔ)(qv−1 −1). u
times the ﬁrst equation minus the second equation gives Δ times the stated equation.
□
Corollary 9 Let C in PG(v −1, Fq) satisfy n = #C = u + mΔ and T (C ) ⊆
{u, u + Δ, . . . , u + mΔ}. Then u < n
q or u = n = 0.
WhilethequadraticinequalityofLemma10isbasedontheﬁrstthreeMacWilliams
identities, the linear inequality of Lemma 20 is based on the ﬁrst two MacWilliams
identities. Corollary 9 corresponds to the average argument that we have used in
the proof of Lemma 8. Lemma 10 can of course be applied in the general case
of qr-divisible sets. First we characterize the part of the parameter space where
τq(c, Δ, m) ≤0 and then we analyze the right side of the corresponding interval,
Lemma 21 For m ∈Z, we have τq(c, Δ, m) ≤0 if and only if (q −1)c −(m −
1/2)Δq + 1
2 ∈

−1
2 ·

q2Δ2 −4qmΔ + 2qΔ + 1, 1
2 ·

q2Δ2 −4qmΔ + 2qΔ + 1

.
(5.1)
The last interval is non-empty, i.e., the radicand is non-negative if and only if m ≤
⌊(qΔ + 2)/4⌋. We have τq(u, Δ, 1) = 0 if and only if u = (Δq −1)/(q −1) or
u = 0.
Proof Solving τq(c, Δ, m) = 0 for c yields the boundaries for c stated in (5.1)).
Inside this interval we have τq(c, Δ, m) ≤0. Now, q2Δ2 −4qmΔ + 2qΔ + 1 ≥0
is equivalent to m ≤qΔ
4 + 1
2 +
1
4qΔ. Rounding downward the right-hand side, while
observing
1
4qΔ < 1
4, yields ⌊(qΔ + 2)/4⌋.
□
49In the case q = p, and in general for codes of type BV, such codes are even qe-divisible, where
qe is the largest power of p dividing the minimum distance [67, Theorem 1 and Proposition 2].

Partial Spreads and Vector Space Partitions
159
Lemma 22 For 1 ≤m ≤
&√(q −1)qΔ −q + 3
2
'
, we have (q −1)n −(m −1/2)
Δq + 1
2 ≤1
2 ·

q2Δ2 −4qmΔ + 2qΔ + 1, where n = m ·
r+1
1

q −1 and Δ = qr.
Proof Plugging in yields 1
2 · (qΔ + 3 −2m −2q) ≤1
2

q2Δ2 −(4m −2)qΔ + 1,
so that squaring and simplifying gives m ≤√(q −1)qΔ + 1/4 −q + 3
2.
□
Theorem 11 Let C in PG(v −1, Fq) be q1-divisible with 2 ≤n = #C ≤q2, then
either n = q2 or q + 1 divides n.
Proof First we show n /∈[(m −1)(q + 1) + 2, m(q + 1) −1] for 1 ≤m ≤q −
1. For m = 1 this statement follows from Lemmas 21 and 10. For m ≥2 let
(m −1)(q + 1) + 2 ≤n ≤m(q + 1) −1. Due to Lemma 10 it sufﬁces to verify
τq(n, q, m) ≤0. From n ≥(m −1)(q + 1) + 2 we conclude
(q −1)n −(m −1/2)Δq + 1
2 ≥−1
2 ·

q2 −4q + 1 + 2m

≥−1
2 ·

q2 −2m −3

≥−1
2 ·
(
q4 −4mq2 + 2q2 + 1 = −1
2 ·
(
q2Δ2 −4qmΔ + 2qΔ + 1
and from n ≤m(q + 1) −1 we conclude
(q−1)n −(m−1/2)Δq + 1
2 ≤1
2 ·

q2−2m−2q+3
 ⋆≤1
2 ·
(
q2Δ2−4qmΔ+2qΔ+1.
With respect to the estimation ⋆, we remark that −4q3 + 8q2 −12q + 8 + 4m(m +
2q −3)
m≤q−1
≤
−4(q −1)(q2 −4q + 6)
q≥2
≤0. Thus, Lemma 21 gives τq(n, q,
m) ≤0.
Applying Corollary 9 with u = m and Δ = q yields n ̸= (m −1)(q + 1) + 1 for
all 1 ≤m ≤q −1.
□
Theexistenceofovoidsshowsthattheupperboundn ≤q2 issharpinTheorem11.
Theorem 12 For the cardinality n of a qr-divisible set C over Fq we have
n /∈
)
(a(q −1) + b)
r + 1
1

q
+ a + 1, (a(q −1) + b + 1)
r + 1
1

q
−1
*
,
where a, b ∈N0 with b ≤q −2, a ≤r −1, and r ∈N>0.
In other words, if n ≤rqr+1, then n can be written as a
r+1
1

q + bqr+1 for some
a, b ∈N0.
Proof We prove by induction on r, set Δ = qr, and write n = (m −1)
r+1
1

q + x,
where a + 1 ≤x ≤
r+1
1

q −1 and m −1 = a(q −1) + b for integers 0 ≤b ≤q −
2, 0 ≤a ≤r −1. The induction start r = 1 is given by Theorem 11.
Now, assume r ≥2 and conclude that for 0 ≤b′ ≤q −2, 0 ≤a′ ≤r −2 we
have n′ /∈
+
(a′(q −1) + b′)
r
1

q + a′ + 1, (a′(q −1) + b′ + 1)
r
1

q −1
,
for the car-
dinality n′ of a qr−1-divisible set. If a ≤r −2 and x ≤
r
1

q −1, then b′ = b, a′ = a

160
T. Honold et al.
yields T (C ) ⊆{u, u + Δ, . . . , u + (m −2)Δ} for u = Δ + (m −1)
r
1

q + x. We
compute (q −1)u = qr+1 −qr + (m −1)qr −(m −1) + (q −1)x
x≥a+1
≥
(m −2)
qr + qr+1 > (m −2)Δ, so that we can apply Corollary 9. If a = r −1 and a + 1 ≤
x ≤
r
1

q −1, then b′ = b, a′ = a −1 yields T (C ) ⊆{u, u + Δ, . . . , u + (m −
1)Δ} for u = (m −1)
r
1

q + x. We compute (q −1)u = (m −1)qr −(m −1) +
x(q −1) > (m −1)Δ using x ≥a + 1, so that we can apply Corollary 9. Thus,
we can assume
r
1

q ≤x ≤
r+1
1

q −1 in the remaining part. Additionally we have
m ≤r(q −1).
We aim to apply Lemma 21. Due to Lemma 22 for the upper bound of the interval
it sufﬁces to show r(q −1) ≤
&√(q −1)qΔ −q + 3
2
'
. For q = 2 the inequality is
equivalent to r ≤
-√
2r+1 −1
2
.
, which is valid for r ≥2. Since the right hand side
is larger then (q −1)(
√
Δ −1), it sufﬁces to show qr/2 −1 ≥r, which is valid for
q ≥3 and r ≥2. For the left hand side of the interval if sufﬁces to show
(q −1)n −(m −1/2)Δq + 1
2 ≥−1
2 ·

(Δq)2 −(4m −2)Δq + 1,
which can be simpliﬁed to Δq + 2m −3 −2(q −1)x ≤

(Δq)2 −(4m −2)Δq + 1
using n = (m −1)
r+1
1

q + x. Since (q −1)x ≥qr −1 and m ≤r(q −1) it suf-
ﬁces to show
−Δ2 + 2rqΔ −2rΔ −Δ −r + r2q −r2 ≤0.
(5.2)
For q = 2 this inequality is equivalent to −22r + r2r+1 + r2 −2 −2r ≤0, which
is valid for r ≥2. For r = 2 Inequality (5.2) is equivalent to −q4 + 4q3 −4q2 −
q2 + 4q −6, which is valid for q ∈{2, 3} and q ≥4. For q ≥3 and r ≥3 we have
Δ ≥3rq, so that Inequality (5.2) is satisﬁed.
□
This classiﬁcation result enables us to decide the existence problem for qr-
divisible sets over Fq of cardinality n in many further cases. We restrict ourselves to
the cases q = 2, r ∈{1, 2, 3}, and refer to [31] for further results.
Theorem 13 (i) 21-divisible sets over F2 of cardinality n exist for all n ≥3 and
do not exist for n ∈{1, 2}; in particular, F(2, 1) = 2.
(ii) 22-divisible sets over F2 of cardinality n exist for n ∈{7, 8} and all n ≥14,
and do not exist in all other cases; in particular, F(2, 2) = 13.
(iii) 23-divisiblesetsoverF2 ofcardinalityn existforn ∈{15, 16, 30, 31, 32, 45, 46,
47, 48, 49, 50, 51}, for all n ≥60, and possibly for n = 59; in all other cases
they do not exist; thus F(2, 3) ∈{58, 59}.
Proof (i) The non-existence for n ∈{1, 2} is obvious. Existence for n ≥3 can be
shown by taking C as a projective basis in PG(n −2, Fq). The corresponding code
C is the binary [n, n −1, 2] even-weight code.

Partial Spreads and Vector Space Partitions
161
(ii) The non-existence part follows from Theorem 12. Existence for n ∈{7, 8} is
shown by the [7, 3, 4] simplex code and its dual (the [8, 4, 4] extended Hamming
code). These two examples and Lemma 15 in turn yield examples of 4-divisible point
sets for n ∈{14, 15, 16}.50 For n ∈{17, 18, 19, 20} Lemma 17 provides examples.51
Together these represent all arithmetic progressions modulo 7, showing existence for
n > 20.
(iii) Existence of 8-divisible sets for the indicated cases with n ≤48 is shown
in the same way as in (ii). Examples for n = 49, n = 50, and n = 74 were found
by computer search; we refer to [31] for generator matrices of the corresponding
8-divisible codes. The binary irreducible cyclic [51, 8] code, which is a two-weight
code with nonzero weights 24 and 32 (see, e.g., [54]), provides an example for
n = 51.52
For n ∈{63, . . . , 72} Lemma 17 provides examples. For n = 73, a suitable exam-
ple is given by the projective [73, 9] two-weight code with non-zero weights 32 and
40 in [44]. Together with the mentioned example for n = 74 these represent all
arithmetic progressions modulo 15, showing existence for n > 74.
The non-existence part follows for n ≤48 from Theorem 12 and for 53 ≤n ≤
58 from Lemma 10 with m = 4. It remains to exclude an 8-divisible point set in
PG(v −1, Fq)with#C = 52.Forthiswewilluseavariantofthelinearprogramming
method, which treats different ambient space dimensions simultaneously. Since C
is in particular 4-divisible, we conclude from Lemma 7 and Part (ii) that there are no
4- or 12-hyperplanes, i.e., A40 = A48 = 0. Using the parametrization y = 2v−3, the
ﬁrst four MacWilliams identities for the associated code C are
1 +
A8 +
A16 +
A24 +
A32 = 8y,
52 +
44A8 +
36A16 +
28A24 +
20A32 = 4y · 52,
52
2

+
44
2

A8 +
36
2

A16 +
28
2

A24 +
20
2

A32 = 2y ·
52
2

,
52
3

+
44
3

A8 +
36
3

A16 +
28
3

A24 +
20
3

A32 = y
52
3

+ A⊥
3

.
Substituting x = y A⊥
3 and solving for A8, A16, A24, A32 yields A8 = −4 +
1
512 x +
7
64 y, A16 = 6 −
3
512 x −17
64 y, A24 = −4 +
3
512 x + 397
64 y,and A32 = 1 −
1
512 x + 125
64 y.
Since A16, x ≥0, we have y ≤384
17 < 23. On the other hand, since 3A8 + A16 ≥0,
we also have −6 + y
16 ≥0, i.e., y ≥96—a contradiction.
□
50The three examples are realized in dimensions 6, 7 and 8, respectively. Alternative solutions for
n ∈{15, 16}, having smaller ambient space dimensions, are the [15, 4, 8] simplex code and the
[16, 5, 8] ﬁrst-order Reed-Muller code.
51These examples can be realized in F6
2 for n ∈{17, 18} and in F7
2 for n ∈{19, 20}.
52It might look tempting to construct a projective 8-divisible binary code of length 50 by shortening
such a code C of length 51. However, this does not work: By Lemma 24, C is the concatenation
of an ovoid in PG(3, F4) with the binary [3, 2] simplex code. By construction, the corresponding
8-divisible point set C is the disjoint union of 17 lines. In particular, each point of C is contained
in a line in C . Consequently, shortening C in any coordinate never gives a projective code.

162
T. Honold et al.
The non-existence of a 23-divisible set of cardinality n = 52 implies the (com-
pared with Theorem 4) tightened upper bound A2(11, 8; 4) ≤13253 and can also be
obtained from a more general result, viz., Corollary 10 with t = 3. Combining the
ﬁrst four MacWilliams identities we obtain an expression involving a certain cubic
polynomial [31]:
Lemma 23 Let C be Δ-divisible over Fq of cardinality n > 0 and t ∈Z. Then
	
i≥1 Δ2(i −t)(i −t −1) · (g1 · i + g0) · AiΔ + qhx = n(q −1)(n −tΔ)
(n −(t + 1)Δ)g2,
where
g1 = Δqh,
g0 = −n(q −1)g2,
g2 = h −(2Δqt+
Δq −2nq + 2n + q −2) and h = Δ2q2t2 + Δ2q2t −2Δnq2t −Δnq2 + 2Δnqt
+ n2q2 + Δnq −2n2q + n2 + nq −n.
Corollary 10 If there exists t ∈Z, using the notation of Lemma 23, with n/Δ /∈
[t, t+1], h ≥0, and g2 < 0, then there is no Δ-divisible set over Fq of cardinality n.
Applying Corollary 10 with t = 6 implies the non-existence of a 24-divisible
set C over F2 with #C = 200, so that A2(16, 12; 6) ≤1032, while Theorem 10
gives A2(16, 12; 6) ≤1033. There is no 85-divisible set C over F8 with #C =
6 · 86 + 3 = 1572867, which can be seen as follows. Corollary 4 implies the exis-
tence of a subspace U of co-dimension 4 such that C ∩U is 81-divisible, #C ∩U ≤
2 · 82 + 3 = 131, and #C ∩U ≡3 (mod 82). Applying Lemma 10 with m = 1
and m = 8 excludes the existence of a 81-divisible set with cardinality 3 or 67,
respectively. Cardinality 131 is ﬁnally excluded by Corollary 10 with t = 14. Thus,
A8(14; 12; 6) ≤16777237, while Theorem 10 gives A8(14, 12; 6) ≤16777238 and
Theorem 4 gives A8(14, 12; 6) ≤16777248. See also [33, 47] for a few more such
examples.
Most of the currently best known bounds for Aq(v, 2k; k) can also be directly
derived by linear programming; cf. the online tables at http://subspacecodes.uni-
bayreuth.de [33]. The following lemma gives a glimpse on coding-theoretic argu-
ments dealing with the MacWilliams equations and its non-negative integer solutions.
Lemma 24 Let C be a projective 8-divisible binary code of length n = 51. Then C
is isomorphic to the concatenation of an ovoid in PG(3, F4) with the binary [3, 2]
simplex code. The code C has the parameters [51, 8] and the weight enumerator
1 + 204X24 + 51X32.
Proof With the notation k = dim(C) and y = 2k−3, solving the equation system
of the ﬁrst three MacWilliams equations yields A0 = 1, A16 = −6 −3A8 + 3
16 y,
A24 = 8 + 3A8 + 49
8 y, and A32 = −3 −A8 + 27
16 y. Since A16 ≥0, we have y ≥32
and hence k ≥8. Plugging the stated equations into the fourth MacWilliams equation
and solving for A8 gives A8 = yA⊥
3
512 + 47y
512 −4 and A16 = 6 −3yA⊥
3
512 −45y
512. Since
A16 ≥0 and y A⊥
3 ≥0, we have 6 −45y
512 ≥0, so that y ≤68 + 4
15 and therefore
k ≤9.
53Consequently, for all t ≥2 the upper bound for A2(4t + 3, 8; 4) is tightened by one; cf. Lemma 4.

Partial Spreads and Vector Space Partitions
163
For k = 9, i.e., y = 64, A16 ≥0 gives A⊥
3 ≤1. A⊥
3 = 0 leads to A8 = 15
8 , which
is impossible. For A⊥
3 = 1 the resulting weight enumerator of C is 1 + 2X8 +
406X24 + 103X32. However, there is no such code, as the sum of the two code-
words of weight 8 would be a third non-zero codeword of weight at most 16, which
does not exist.
In the case k = 8, i.e., y = 32, the ﬁrst MacWilliams equation forces A16 =
A8 = 0. The resulting weight enumerator of C is given by 1 + 204X24 + 51X32. In
particular, C is a projective [51, 8] two-weight code. By [12], this code is unique.
The proof is concluded by the observation that an ovoid in PG(3, F4) is a projective
quaternary [17, 4] two-weight code, such that the concatenation with the binary [3, 2]
simplex code yields a projective binary [51, 8] two-weight code.
□
6
Open Research Problems
In this closing section we have collected some open research problems within the
scope of this article. All of them presumably are accessible using the theoreti-
cal framework of qr-divisible sets. Considerably more challenging is the question
whether similar methods can be developed for arbitrary constant-dimension codes in
place of of partial spreads (or vector space partitions). We only mention the following
example: The proof of A2(6, 4; 3) = 77 still depends on extensive computer calcula-
tions providing the upper bound A2(6, 4; 3) ≤77 [37]. The known theoretical upper
bound of 81 may be sharpened to 77 (along the lines of [57]), if only the existence
of a (6, 81, 4; 3)2 code can be excluded. The 81 planes in such a code would form
an exact 9-cover of the line set of PG(5, F2).
6.1
Better Constructions for Partial Spreads
The only known cases in which the construction of Theorem 2 has been surpassed are
derived from the sporadic example of a partial 3-spread of cardinality 34 in F8
2 [22],
which has 17 holes and can be used to show A2(3m + 2, 6; 3) ≥(23m+2 −18)/7
by adding m −2 layers of lifted MRD codes; cf. Lemma 4 and Corollary 2. A ﬁrst
step towards the understanding of the sporadic example is the classiﬁcation of all
22-divisible point sets of cardinality 17 in PG(k −1, F2). It turns out that there are
exactly 3 isomorphism types, one conﬁguration Hk for each dimension k ∈{6, 7, 8}.
Generating matrices for the corresponding doubly-even codes are

164
T. Honold et al.
⎛
⎜⎜⎜⎜⎜⎝
10000110010101110
01000010111011100
00100100000011000
00010111001110100
00001001100111110
00000011100111011
⎞
⎟⎟⎟⎟⎟⎠
,
⎛
⎜⎜⎜⎜⎜⎜⎜⎝
10000011110100110
01000001111111000
00100010000110000
00010010000101000
00001001001000100
00000101001000010
00000010101011111
⎞
⎟⎟⎟⎟⎟⎟⎟⎠
,
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
10000000111011110
01000000010110000
00100000011100000
00010000001110000
00001001100000010
00000101000001010
00000011000000110
00000001111011101
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
.
(6.1)
While the classiﬁcation, so far, is based on computer calculations,54 one can easily
see that there are exactly three solutions of the MacWilliams identities.
Lemma 25 Let C be a 22-divisible point set over F2 of cardinality 17. Then k =
dim⟨C ⟩∈{6, 7, 8}, and the solutions of the MacWilliams identities are unique for
each k: (k; a5, a9, a13; A⊥
3 ) = (6; 12, 49, 2; 6), (7; 25, 95, 7; 2), (8; 51, 187, 17; 0).
Proof The unique solution of the standard equations is given by a5 = 13
16 · 2k−2 −1,
a9 = 23
8 · 2k−2 + 3, and a13 =
5
16 · 2k−2 −3. Hence k ≥6, since otherwise a13 < 0,
and k ≤8, since C is self-orthogonal.55
□
Theholesetofthepartial3-spreadin[22]correspondstoH7.Ageometricdescription
of this conﬁguration is given in [49, p. 84]. We have computationally checked that
indeed all three hole conﬁgurations can be realized by a partial 3-spread of cardinality
34 in F8
2.56 All three conﬁgurations have a non-trivial automorphism group, and hence
there is a chance to ﬁnd a partial 3-spread with nontrivial symmetries and eventually
discover an underlying more general construction. 57 So far we can only describe the
geometric structure of H6, H7, H8.
The hole conﬁguration H6 consists of two disjoint planes E1, E2 in PG(5, F2) and
a solid S spanned by lines L1 ⊂E1 and L2 ⊂E2. The 17 = 4 + 4 + 9 points of H6
are those in E1 \ L1, E2 \ L2, and S \ (L1 ∪L2). An application of Lemma 17 (the
case q = r = i = 2) gives that H6 is 4-divisible. In sunﬂower terms, F1 = {S, E1},
F2 = {S, E2} with centers L1, L2, respectively.
The hole conﬁguration H7 can be obtained by modifying a 3-sunﬂower F =
{E, S1, S2}, whose petals are a plane E and two solids S1, S2 and whose base is a line
L. By Lemma 16(ii), the point set E ∪S1 ∪S2, of cardinality 3 + 4 + 12 + 12 = 31
is 4-divisible. From this set we remove two planes E1 ⊂S1, E2 ⊂S2 intersecting L
in different points. This gives H7.
The hole conﬁguration H8 can be obtained by modifying the cone construc-
tion of Lemma 19. We start with a projective basis B in F4
2, i.e., m = 5 points
with no 4 of them contained in a plane. Such point sets B are associated to the
54See http://www.rlmiller.org/de_codes and [19] for the classiﬁcation of, possibly non-projective,
doubly-even codes over Fv
2.
55Alternatively, the 4th MacWilliams identity yields 64 −2k−2 = 2k−3 · A⊥
3 and hence k ≤8.
56624 non-isomorphic examples can be found at http://subspacecodes.uni-bayreuth.de [33].
57In a forthcoming paper we classify the 2612 non-isomorphic partial 3-spreads of cardinality 34 in
F8
2 that admit an automorphism group of order exactly 8, which is possible for H6 only, and show
that the automorphism groups of all other examples have order at most 4.

Partial Spreads and Vector Space Partitions
165
[5, 4, 2]2 even-weight code and hence 2-divisible. Since m ≡1 (mod 4), the proof
of Lemma 19 shows that a generalized cone K over B with 1-dimensional ver-
tex Q of multiplicity −m(q −1) ≡−m ≡3 (mod 4) is 4-divisible. Working over
Z, we can set χK (Q) = −1 as well. Adding any 4-divisible point set D contain-
ing Q (i.e., χD (Q) = 1) to K then produces a 4-divisible multiset set C with
#C = 10 −1 + #D and χC (Q) = 0. By making the ambient spaces of K and C
intersect only in Q (which requires embedding the conﬁguration into a larger space
Fv
2), we can force C to be a set. The conﬁguration H8 is obtained by choosing D as
an afﬁne solid.58
From the preceding discussion it is clear that all possible hole types of a partial
3-spread of cardinality 34 in F8
2 belong to inﬁnite families of qr-divisible sets. Can
further 22-divisible sets of small cardinality be extended to an inﬁnite family?
Construction 1 For integers r ≥1 and 0 ≤m ≤r let S be a 2r-subspace. By
F1, . . . , F[m
1]q we denote the (2r + 1)-subspaces of F2r+m that contain S and by
L1, . . . , L[m
1]q we denote a list of r-subspaces of S with pairwise trivial inter-
section. Let 0 ≤a ≤
m
1

q and 0 ≤bi ≤qr−1 −1 for all 1 ≤i ≤a. For each
1 ≤i ≤a we choose q −1 + biq =: ci different (r + 1)-subspaces Ei, j of Fi
with Fi ∩S = Li. With this, we set C =

S\ ∪a
i=1 Li

∪

∪a
i=1 ∪ci
j=1

Ei, j\Li

and observe dim(C ) ≤2r + m, #C =
2r
1

q + a ·

qr+1 −
r+1
1

q

+ b · qr+1, where
b = 	a
i=1 bi, and that C is qr-divisible.
Proof Apply Lemmas 13, 14 using χv
C = χv
S +
a	
i=1
ci	
j=1
χv
Ei, j −q
a	
i=1
(bi + 1)χv
Li. □
We remark that the construction can easily be modiﬁed to obtain qr-divisible sets of
cardinality n =
2r
1

q + a ·

qr+1 −
r+1
1

q

+ b · qr+1 and dimension v for all 2r +
m ≤v ≤2r + a(q −1) + bq. Choosing m = r, a = qr−1, and b = 0 we obtain a
qr-divisible set C of cardinality n = q2r +
r−1
1

q and dimension v = 3r. For which
parameters r and q do partial (r + 1)-spreads of cardinality q2r+1 + qr−1, with hole
conﬁguration C , in F3r+2
q
exist? So far, such partial spreads are known for r = 1,
(q,r) = (2, 2) and all further examples would be strictly larger than the ones from
Theorem 2.
For the corresponding parameters over the ternary ﬁeld we currently only know
the bounds 244 ≤A3(8, 6; 3) ≤248. A putative plane spread in F8
3 of size 248 would
have a 32-divisible hole conﬁguration H of cardinality 56. Such a point set is unique
up to isomorphism and has dimension k = 6. It corresponds to an optimal two-weight
code with weight distribution 013661645112. The set H was ﬁrst described by R. Hill
in [34] and is known as the Hill cap. A generator matrix for is
58Since punctured afﬁne solids are associated to the [7, 4, 3]2 Hamming code, we may also think
of H8 as consisting of the 2-fold repetition of the [5, 4, 2]-code and the Hamming code “glued
together” in Q. In fact the doubly-even [17, 8, 4]2 code associated with H8 is the code I (3)
17 in [61,
p. 234]. The glueing construction is visible in the generator matrix.

166
T. Honold et al.
⎛
⎜⎜⎜⎜⎜⎜⎜⎝
1 0 0 0 0 0 2 2 1 1 0 1 0 0 1 1 0 2 0 2 1 1 1 1 0 0 1 0 1 2 0 1 0 2 1 2 1 1 1 1 1 2 2 0 0 1 2 0 0 2 0 1 2 2 1 1
0 1 0 0 0 0 1 1 1 0 1 2 1 0 1 0 1 1 2 1 1 2 0 0 1 0 2 1 1 2 2 2 1 1 1 2 1 0 0 0 0 2 1 2 0 2 2 2 0 0 2 2 2 0 1 0
0 0 1 0 0 0 2 2 2 2 0 2 2 1 0 2 0 0 1 1 2 0 0 1 0 1 1 2 0 0 2 0 2 0 2 0 0 2 1 1 1 2 2 1 2 1 1 2 2 2 0 0 1 1 1 2
0 0 0 1 0 0 1 0 1 1 2 2 2 2 0 2 2 1 0 2 0 0 2 2 1 0 0 1 0 1 0 1 0 0 2 2 2 2 1 0 0 2 2 2 1 1 2 1 2 2 2 2 1 2 0 0
0 0 0 0 1 0 2 0 1 2 1 0 2 2 1 1 2 1 1 2 0 0 1 0 2 1 1 0 2 2 1 1 1 2 1 0 0 0 0 2 1 2 0 2 2 2 0 2 1 2 2 0 1 0 0 1
0 0 0 0 0 1 1 2 2 0 2 0 0 2 2 0 1 0 1 2 1 2 2 0 0 2 0 1 1 0 2 0 1 2 1 2 2 2 2 2 1 2 0 0 2 1 0 0 2 0 2 1 1 2 2 2
⎞
⎟⎟⎟⎟⎟⎟⎟⎠
.
The automorphism group has order 40320. Given the large automorphism group of
H , is it possible to construct a partial plane spread in F8
3 with size larger than 244?
For q = 2, the ﬁrst open case is 129 ≤A2(11, 8; 4) ≤132. A putative partial 4-
spread of size 132 has a 23-divisible hole conﬁguration of cardinality 67. Such exist
for all dimensions 9 ≤k ≤11; cf. Theorem 13(iii). Can one such 23-divisible set be
completed to a partial 4-spread?
Already the smallest open cases pose serious computational challenges. A promis-
ing approach is the prescription of automorphisms in order to reduce the computa-
tional complexity; see, e.g., Chapter “Computational Methods in Subspace Designs”
and [45] for an application of this so-called Kramer-Mesner method to constant-
dimension codes. Of course, the automorphisms have to stabilize the hole conﬁg-
uration, whose automorphism group is known or can be easily computed in many
cases.
6.2
Existence Results for qr-divisible Sets
Even for rather small parameters q and r we cannot decide the existence question,
see Table1 and [32].
Table 1 Undecided cases for the existence of qr-divisible sets
q
r
n
2
3
59
2
4
130, 131, 163, 164, 165, 185, 215, 216, 232, 233, 244, 245, 246, 247
3
2
70, 77, 99, 100, 101, 102, 113, 114, 115, 128
4
2
129, 150, 151, 172, 173, 193, 194, 195, 215, 216, 217, 236, 237,238, 239, 251, 258,
259, 261, 272, 279, 280, 282, 283, 293, 301, 305, 313, 314, 322, 326, 333, 334,
335,. . .
5
1
40
7
1
75, 83, 91, 92, 95, 101, 102, 103, 109, 110, 111, 117, 118, 119, 125, 126, 127, 133,
134, 135, 142, 143, 151, 159, 167
8
1
93, 102, 111, 120, 121, 134, 140, 143, 149, 150, 151, 152, 158, 159, 160, 161, 167,
168, 169, 170, 176, 177, 178, 179, 185, 186, 187, 188, 196, 197, 205, 206, 214,
215, 223, 224, 232, 233, 241, 242, 250, 251
9
1
123, 133, 143, 153, 154, 175, 179, 185, 189, 195, 196, 199, 206, 207, 208, 209,
216, 217, 218, 219, 226, 227, 228, 229, 236, 237, 238, 239, 247, 248, 249, 257,
258, 259, 267, 268, 269, 277, 278, 279, 288, 289, 298, 299, 308, 309, 318, 319,
329, 339, 349, 359

Partial Spreads and Vector Space Partitions
167
6.3
Vector Space Partitions
The most general result on the non-existence of vector space partitions (without
conditions on the ambient space dimension v) seems to be:
Theorem 14 (Theorem 1 in [29])
Let C be a vector space partition of type
kz · · · d2bd1a of Fv
q, where a, b > 0.
(i) If qd2−d1 does not divide a and if d2 < 2d1, then a ≥qd1 + 1;
(ii) if qd2−d1 does not divide a and if d2 ≥2d1, then a > 2qd2−d1 or d1 divides d2
and a =

qd2 −1

/

qd1 −1

;
(iii) if qd2−d1 divides a and d2 < 2d1, then a ≥qd2 −qd1 + qd2−d1;
(iv) if qd2−d1 divides a and d2 ≥2d1, then a ≥qd2.
For the special case d1 = 1, Theorems 11 and 12, presented in Sect.5, pro-
vide tighter results. For d1 > 1 we can replace d1-subspaces by the correspond-
ing point sets and apply results for qr-divisible sets. For vector space partitions
of type kz · · · 4b2a in Fv
2 we obtain 23-divisible sets of cardinality n = 3a, so that
a ∈{5, 10, 15, 16} or a ≥20 by Theorem13(iii). Theorem 14 gives a = 5 or a ≥9,
and 4 | a implies a ≥16. However, not all results of Theorem 14 can be obtained
that easy. For vector space partitions of type kz · · · 4b3a in Fv
2 we obtain 23-divisible
sets of cardinality n = 7a, giving a = 7 or a ≥9. Theorem 14 gives a ≥9, and 2 | a
implies a ≥10. In order to exclude a = 7 one has to look at hyperplane intersec-
tions in this new setting. So far, we have used #(H ∩C ) ≡#C (mod qr). The sets
H ∩C have to come as a partition of type sd(s −1)c, where c + d = a. Here the
possible values for c are restricted by the cases of qr−1-divisible sets admitting the
partition type (s −1)c. This further reduces the possible hyperplane types, so that
eventually the linear programming method can be applied. In our situation we have
T (C ) ⊆{25, 49}, which is excluded by Lemma 20. For the general case we intro-
duce the following notation: A point set C in PG(v −1, Fq) admits the partition type
sms · · · 1m1 if there exists a vector space partition of Fv
q of type sms · · · 1m1 that covers
the points in C and no other points. In terms of this, we may restate the previous
result as “there is no 23-divisible set admitting the partition type 37”. However, we
are very far from the generality and compactness of Theorem 14. Nevertheless, the
sketched approach seems to be a very promising research direction (and a natural
extension of the study of qr-divisible sets).
Acknowledgements The authors would like to acknowledge the ﬁnancial support provided by
COST – European Cooperation in Science and Technology. The ﬁrst author was also supported by
the National Natural Science Foundation of China under Grant 61571006. The third author was
supported in part by the grant KU 2430/3-1 – Integer Linear Programming Models for Subspace
Codes and Finite Geometry from the German Research Foundation.

168
T. Honold et al.
References
1. J. André, Über nicht-desarguessche Ebenen mit transitiver Translationsgruppe. Mathematische
Zeitschrift 60(1), 156–186 (1954)
2. G. Andrews, The Theory of Partitions, 2nd edn. (Cambridge University Press, Cambridge,
1998)
3. S. Ball, A. Blokhuis, A. Gács, P. Sziklai, Z. Weiner, On linear codes whose weights and length
have a common divisor. Adv. Math. 211(1), 94–104 (2007)
4. B.I. Belov, V.N. Logachev, V.P. Sandimirov, Construction of a class of linear binary codes
achieving the Varshamov-Griesmer bound. Probl. Inf. Transm. 10, 211–217 (1974)
5. J.D. Beule, A. Klein, K. Metsch, Substructures of ﬁnite classical polar spaces. In Beule and
Storme [6]
6. J.D. Beule, L. Storme (eds.), Current Research Topics in Galois Geometry (Nova Science
Publishers, 2011)
7. A. Beutelspacher, Partial spreads in ﬁnite projective spaces and partial designs. Mathematische
Zeitschrift 145(3), 211–229 (1975)
8. A. Beutelspacher, Partitions of ﬁnite vector spaces: an application of the Frobenius number in
geometry. Archiv der Mathematik 31(1), 202–208 (1978)
9. J. Bierbrauer, Introduction to Coding Theory (2005)
10. C. Bonferroni, Libreria internazionale Seeber, Teoria Statistica Delle Classi e Calcolo Delle
Probabilità (1936)
11. R. Bose, K. Bush, Orthogonal arrays of strength two and three. Ann. Math. Statistics, 508–524
(1952)
12. I. Bouyukliev, V. Fack, W. Willems, J. Winne, Projective two-weight codes with small param-
eters and their corresponding graphs. Des. Codes Cryptogr. 41(1), 59–78 (2006)
13. A. Brauer, On a problem of partitions. Am. J. Math. 64(1), 299–312 (1942)
14. R. Calderbank, W. Kantor, The geometry of two-weight codes. Bull. Lond. Math. Soc. 18(2),
97–122 (1986)
15. P. Delsarte, Bounds for unrestricted codes, by linear programming. Philips Res. Rep 27,
272–289 (1972)
16. P. Delsarte, Weights of linear codes and strongly regular normed spaces. Discret. Math. 3,
47–64 (1972)
17. P. Dembowski, Finite Geometries: Reprint of the 1968 Edition (Springer Science and Business
Media, 2012)
18. S. Dodunekov, J. Simonis, Codes and projective multisets. Electron. J. Comb. 5(R37), 1–23
(1998)
19. C. Doran, M. Faux, S. Gates, T. Hübsch, K. Iga, G. Landweber, R. Miller, Codes and super-
symmetry in one dimension. Adv. Theor. Math. Phys. 15(6), 1909–1970 (2011)
20. D. Drake, J. Freeman, Partial t-spreads and group constructible (s,r, μ)-nets. J. Geom. 13(2),
210–216 (1979)
21. J. Eisfeld, L. Storme, t-spreads and minimal t-covers in ﬁnite projective spaces. Lecture Notes,
29 (2000)
22. S. El-Zanati, H. Jordon, G. Seelinger, P. Sissokho, L. Spence, The maximum size of a partial
3-spread in a ﬁnite vector space over GF(2). Des. Codes Cryptogr. 54(2), 101–107 (2010)
23. P. Erd˝os, R. Rado, Intersection theorems for systems of sets. J. Lond. Math. Soc. (1) 35(1),
85–90 (1960)
24. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inf. Theory 55(7), 2909–2919 (2009)
25. J. Galambos, Bonferroni inequalities. Ann. Probab. 577–581 (1977)
26. N.A. Gordon, R. Shaw, L.H. Soicher, Classiﬁcation of partial spreads in PG(4, 2) (2004). www.
maths.qmul.ac.uk/~leonard/partialspreads/PG42new.pdf
27. X. Guang, Z. Zhang, Linear Network Error Correction Coding (Springer, SpringerBriefs in
Computer Science, 2014)

Partial Spreads and Vector Space Partitions
169
28. O. Heden, The Frobenius number and partitions of a ﬁnite vector space. Archiv der Mathematik
42(2), 185–192 (1984)
29. O. Heden, On the length of the tail of a vector space partition. Discret. Math. 309(21), 6169–
6180 (2009)
30. O. Heden, A survey of the different types of vector space partitions. Discret. Math. Algorithms
Appl. 4(1), 14 (2012). nr. 1250001
31. D. Heinlein, T. Honold, M. Kiermaier, S. Kurz, A. Wassermann, On projective qr-divisible
codes. In preparation (2016)
32. D. Heinlein, T. Honold, M. Kiermaier, S. Kurz, A. Wassermann, Projective divisible binary
codes (2017). Preprint at arXiv: 1703.08291
33. D. Heinlein, M. Kiermaier, S. Kurz, A. Wassermann, Tables of subspace codes (2015). http://
subspacecodes.uni-bayreuth.de
34. R. Hill, Caps and codes. Discret. Math. 22(2), 111–137 (1978)
35. R. Hill, Optimal linear codes, in Cryptography and Coding II, ed. by C. Mitchell (Oxford
University Press, Oxford, 1992), pp. 75–104
36. S. Hong, A. Patel, A general class of maximal codes for computer applications. IEEE Trans.
Comput. 100(12), 1322–1331 (1972)
37. T. Honold, M. Kiermaier, S. Kurz, Optimal binary subspace codes of length 6, constant dimen-
sion 3 and minimum distance 4. Contemp. Math. 632, 157–176 (2015)
38. T. Honold, M. Kiermaier, S. Kurz, Classiﬁcation of large partial plane spreads in PG(6, 2) and
related combinatorial objects (2016). Preprint at arXiv: 1606.07655
39. T. Honold, M. Kiermaier, S. Kurz, Constructions and bounds for mixed-dimension subspace
codes. Adv. Math. Commun. 10(3), 649–682 (2016)
40. W. Huffman, V. Pless, Fundamentals of Error-Correcting Codes (Cambridge University Press,
Cambridge, 2003)
41. D.R. Hughes, F.C. Piper, Graduate Texts in Mathematics, 6th edn., Graduate Texts in Mathe-
matics (Springer, 1973)
42. N.L. Johnson, V. Jha, M. Biliotti, Handbook of Finite Translation Planes (CRC Press, 2007)
43. R. Koetter, F. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579–3591 (2008)
44. A. Kohnert, Constructing two-weight codes with prescribed groups of automorphisms. Discret.
Appl. Math. 155(11), 1451–1457 (2007)
45. A. Kohnert, S. Kurz, Construction of large constant dimension codes with a prescribed mini-
mum distance, Mathematical Methods in Computer Science (Springer, 2008), pp. 31–42
46. S. Kurz, Improved upper bounds for partial spreads. Designs, Codes and Cryptography (2016).
published online on Oct 25 (2016)
47. S. Kurz, Improved upper bounds for partial spreads. Des. Codes. Cryptogr. 85(1), 97–106
(2017–10). https://doi.org/10.1007/s10623-016-0290-8
48. S. Kurz, Packing vector spaces into vector spaces. Australas. J. Comb. 68(1), 122–130 (2017)
49. L. Lambert, Random network coding and designs over Fq. Ph.D. thesis, Ghent University,
Master Thesis, 2013
50. I.N. Landjev, Linear codes over ﬁnite ﬁelds and ﬁnite projective geometries. Discret. Math.
213, 211–244 (2000)
51. M. Lavrauw, O. Polverino, Finite semiﬁelds. In Beule and Storme [6], chapter 6, pp. 129–157
52. S. Lloyd, Binary block coding. Bell Syst. Tech. J. 36(2), 517–535 (1957)
53. F.J. MacWilliams, A theorem on the distribution of weights in a systematic code. Bell Syst.
Tech. J. 42(1), 79–94 (1963)
54. F.J. MacWilliams, J. Seery, The weight distributions of some minimal cyclic codes. IEEE Trans.
Inf. Theory 27, 796–806 (1981)
55. Z. Mateva, S. Topalova, Line spreads of PG(5, 2). J. Combin. Des. 17(1), 90–102 (2009)
56. M. Médard, A. Sprintson, Network Coding: Fundamentals and Applications (Elsevier, 2012)
57. A. Naki´c, L. Storme, On the extendability of particular classes of constant dimension codes.
Des. Codes Cryptogr. 79(3), 407–422 (2016)

170
T. Honold et al.
58. E. N˘astase, P. Sissokho, The maximum size of a partial spread II: upper bounds. Discret. Math.
340(7), 1481–1487 (2017). https://doi.org/10.1016/j.disc.2017.02.001
59. E.L. N˘astase, P.A. Sissokho, The maximum size of a partial spread in a ﬁnite projective space.
J. Comb. Theor. Ser. A 152, 353–362 (2017–11). https://doi.org/10.1016/j.jcta.2017.06.012
60. R. Plackett, J. Burman, The design of optimum multifactorial experiments. Biometrika 33(4),
305–325 (1946)
61. V. Pless, N. Sloane, On the classiﬁcation and enumeration of self-dual codes. J. Comb. Theory
Ser. A 18(3), 313–335 (1975)
62. B.Segre,Teoriadigalois,ﬁbrazioniproiettiveegeometrienondesarguesiane.AnnalidiMatem-
atica Pura ed Applicata 64(1), 1–76 (1964)
63. N. Silberstein, T. Etzion, Large constant dimension codes and lexicodes. Adv. Math. Commun.
5(2), 177–189 (2011)
64. D. Silva, F. Kschischang, R. Koetter, A rank-metric approach to error control in random network
coding. IEEE Trans. Inf. Theory 54(9), 3951–3967 (2008)
65. M.A. Tsfasman, S.G. Vl˘adu¸t, Geometric approach to higher weights. IEEE Trans. Inf. Theory
41, 1564–1588 (1995)
66. J.H. van Lint, R.M. Wilson, A Course in Combinatorics (Cambridge University Press, Cam-
bridge, 1992)
67. H. Ward, Divisibility of codes meeting the griesmer bound. J. Comb. Theory Ser. A 83(1),
79–93 (1998)
68. H. Ward, An introduction to divisible codes. Des. Codes Cryptogr. 17(1), 73–79 (1999)
69. H. Ward, Divisible codes - a survey. Serdica Math. J. 27(4), 263p–278p (2001)
70. R.W. Yeung, S.-Y.R. Li, N. Cai, Z. Zhang, Network coding theory. Found. Trends Commun.
Inf. Theory 2(4/5), 241–381 (2006)

q-Analogs of Designs: Subspace Designs
Michael Braun, Michael Kiermaier and Alfred Wassermann
Abstract For discrete structures which are based on a ﬁnite ambient set and its
subsets there exists the notion of a “q-analog”: For this, the ambient set is replaced
by a ﬁnite vector space and the subsets are replaced by subspaces. Consequently,
cardinalities of subsets become dimensions of subspaces. Subspace designs are the
q-analogs of combinatorial designs. Introduced in the 1970s, these structures gained
a lot of interest recently because of their application to random network coding. In
this chapter we give a thorough introduction to the subject starting from the sub-
space lattice and its automorphisms, the Gaussian binomial coefﬁcient and counting
arguments in the subspace lattice. This prepares us to survey the known structural
and existence results about subspace designs. Further topics are the derivation of
subspace designs with related parameters from known subspace designs, as well as
inﬁnite families, intersection numbers, and automorphisms of subspace designs. In
addition, q-Steiner systems and so called large sets of subspace designs will be cov-
ered. Finally, this survey aims to be a comprehensive source for all presently known
subspace designs and large sets of subspace designs with small parameters.
1
Introduction
Concepts, theories, and discrete structures based on ﬁnite sets and their subsets turn
into a combinatorial “q-analog” if they are considered over vector spaces over a ﬁnite
ﬁeld Fq with q elements. In this case, “subsets” of a ﬁnite set become “subspaces”
M. Braun (B)
Faculty of Computer Science, Darmstadt University of Applied Sciences, 64295 Darmstadt,
Germany
e-mail: michael.braun@h-da.de
M. Kiermaier · A. Wassermann
Department of Mathematics, University of Bayreuth, 95440 Bayreuth, Germany
e-mail: michael.kiermaier@uni-bayreuth.de
A. Wassermann
e-mail: alfred.wassermann@uni-bayreuth.de
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_8
171

172
M. Braun et al.
of a vector space and “cardinalities” of subsets become “dimensions” of subspaces.
In fact, combinatorics on ﬁnite sets can be considered as the limiting case “q tends
to 1” of combinatorics on vector spaces over Fq, see Tits [1] and Sect.2.2.
A very prominent example is the “q-analog of a combinatorial t-design”—the
major object of this chapter. We start with the well-known deﬁnition of a combina-
torial design.
Deﬁnition 1 Let V be a set of size v, 0 ≤t ≤k ≤v integers and λ a non-negative
integer. A pair D = (V, B), where B a (multi-)set of k-subsets (blocks) of V , is
called a t −(v, k, λ) design on V , if each t-subset of V is contained in exactly λ
blocks.
If B is a set, i.e. if every k-subset appears at most once in B, the design is called
simple.
For a t-(v, k, λ) design, the integer λ is the index of the design and t is called its
strength. Combinatorial designs have a long history starting in the 19th century with
the works of Plücker, Kirkman and Steiner. There are many prominent applications
of designs, among them are design of experiments and coding theory, to name the
most prominent ones. See the voluminous books Design Theory [2] and Handbook
of Combinatorial Designs [3] for a comprehensive overview.
Now, we turn to the q-analogs of combinatorial designs. Throughout this chapter,
q will be a prime power and V a vector space over the ﬁnite ﬁeld Fq of ﬁnite
dimension v. Subspaces of dimension k will be called k-subspaces. Then, the q-
analog of a design is deﬁned as follows.
Deﬁnition 2 Let 0 ≤t ≤k ≤v be integers and λ a non-negative integer. A pair
D = (V, B), where B is a collection of k-subspaces (blocks) of V , is called a t-
(v, k, λ)q subspace design on V if each t-subspace of V is contained in exactly λ
blocks.
If B is a set, i.e. if every k-subset appears at most once in B, the design is called
simple.
We will see that combinatorial designs can be seen as the case q = 1 of subspace
designs. Consequently, a t-(v, k, λ) design may also be denoted as a t-(v, k, λ)1
design, see Sect.2.2.
In the following, all subspace designs will be assumed to be simple unless explic-
itly stated otherwise. If we allow multiple occurrence of k-subspaces in the set of
blocks we speak of non-simple (subspace) designs.
A particular class of subspace designs are t-(v, k, 1)q designs which are called
q-analogs of Steiner systems or simply q-Steiner systems. Analogously to ordinary
Steiner systems on sets, we use the notation S(t, k, v)q in order to indicate a q-Steiner
system with parameters t-(v, k, 1)q. An important subclass is given by the q-Steiner
triple systems STS(v)q, which are Steiner systems with the parameters S(2, 3, v)q.
Viewed as subspace codes, q-Steiner system are diameter perfect codes, see [4]. For
more information on subspaces codes the reader is referred to part I, in particular to
chapters “Codes Endowed with the Rank Metric”–“Construction of Cyclic Subspace
Codes and Maximum Rank Distance Codes”, and for geometric aspects to chapters

q-Analogs of Designs: Subspace Designs
173
“Geometrical Aspects of Subspace Codes” and “Partial Spreads and Vector Space
Paritions”.
Remarkably, many different names for q-analogs of designs can be found in the
literature including
• subspace designs,
• designs over ﬁnite ﬁelds,
• designs over Fq,
• q-designs,
• geometric designs,
• designs in vector spaces, and
• designs in the q-Johnson scheme.
The name “subspace design” has the advantage of being short and not involving
symbols like q. Furthermore, it nicely ﬁts the closely related terms “subspace lattice”
and “subspace code”.
2
The Subspace Lattice
A closer look at Deﬁnition 1 reveals that the deﬁnition of a combinatorial design can
entirely be expressed in terms of the subset lattice of the v-element set V . The idea
behind q-analogs in combinatorics is to replace the subset lattice by the subspace
lattice of a v-dimensional Fq-vector space V .
An introduction to the theory of lattices can be found in the classical textbooks
by Birkhoff [5] and Stanley [6].
We denote the set of all subspaces of V by L (V ). The set of all k-subspaces of
V is called the Graßmannian and denoted by
V
k

q (Fig.1).
The partially ordered set (poset) (L (V ), ≤) forms a lattice—the subspace lat-
tice—with containment “≤” of subspaces as partial order relation, intersection “∩”
of subspaces as meet and sum “+” of subspaces as join operator. Moreover, the
subspace lattice is graded with the dimension “dim” of subspaces as rank function.
The dimension formula
dim(U) + dim(U ′) = dim(U ∩U ′) + dim(U + U ′) for all U,U ′ ∈L (V )
implies that L (V ) is a modular lattice.
Projective Geometry
From a slightly different point of view, for v ≥2 the lattice L (V ) is also known as
the projective geometry PG(V ). As the projective geometric dimension is always one
less then the corresponding algebraic dimension, k-subspaces are called (k −1)-ﬂats,
and the isomorphism class of the ﬁnite geometry PG(V ) is denoted by PG(v −1, q).
The 1-subspaces of V are called points, the 2-subspaces lines, the 3-subspaces planes,
the 4-subspaces solids and the (v −1)-subspaces hyperplanes.

174
M. Braun et al.
0000
V
0

2
0001
V
1

2
0010
0001
V
2

2
0100
0010
0001
V
3

2
1000
0100
0010
0001
V
4

2
Fig. 1 Subspace lattice of F4
2
Coordinates
After a choice of a basis, from now on we may identify V with Fv
q, whose elements
will be considered as row vectors. Now, subspaces U ∈L (V ) may be represented
as the row space of a dim(U) × v generator matrix A. To get a unique matrix, the
reduced row echelon form of A may be used.
Example 1 The following ﬁve matrices whose rows form bases of 2-dimensional
subspaces deﬁne a set of 2-subspaces of the standard vector space F4
2 yielding a
1-(4, 2, 1)2 design:
0110
0001

,
1000
0010

,
1100
0011

,
1001
0100

,
1011
0101

.
As can be seen in Fig.2, every 1-subspace is contained in exactly one block of the
design.
2.1
Automorphisms
Lattice Automorphisms
A bijection φ : L →L on a lattice (L , ≤, ∨, ∧) is an automorphism of L if one
of the following equivalent conditions is satisﬁed for all subspaces x, y ∈L :

q-Analogs of Designs: Subspace Designs
175
Fig. 2 A 1-(4, 2, 1)2 design in the subspace lattice of F4
2
• x ≤y if and only if α(x) ≤α(y),
• α(x ∨y) = α(x) ∨α(y),
• α(x ∧y) = α(x) ∧α(y).
Moreover, φ is an antiautomorphism of L if one of the following equivalent condi-
tions is satisﬁed for all subspaces:
• x ≤y if and only if α(y) ≤α(x),
• α(x ∨y) = α(x) ∧α(y),
• α(x ∧y) = α(x) ∨α(y).
The lattice L is called self-dual if and only if there exists an antiautomorphism of L .
The set of all automorphisms of L is a subgroup of the symmetric group on L . It is
called the automorphism group of L and denoted by Aut(L ). As the composition
of two antiautomorphisms is always an automorphism, we see that the set of all
automorphisms and antiautomorphisms forms a group, too, containing Aut(L ) as a
normal subgroup of index 1 or 2. The second case occurs if and only if # L ≥2 and
L is self-dual.
Group Actions
Let G be a group acting on a set X. The action is said to be transitive if there is only
a single orbit, so for each x ∈X we have {α(x) : α ∈G} = X. The kernel of the
action is deﬁned as
G X = {α ∈G | α(x) = x for all x ∈X} .

176
M. Braun et al.
The action is called faithful if G X = {1}. The stabilizers of elements in the same
orbit are related by the formula
Gα(x) = αGxα−1.
(1)
Automorphisms of the Subspace Lattice
As usual, the group of all linear bijective mappings on V is denoted by GL(V ),
and the group of all semilinear bijective mappings on V is denoted by L(V ). GL(V )
is a normal subgroup of L(V ) and L(V ) ∼= Aut(Fq) ⋊GL(V ).
Now, the groups GL(V ) and L(V ) act transitively and faithfully on the elements
of V . However in general, the induced actions on L (V ) are neither transitive nor
faithful. The orbits of the action of these groups on subspaces of V are given by
V
k

q
with k ∈{0, . . . , v}. In both cases, the kernel of the action is the set C = {v →λv |
λ ∈Fq}, which equals the center of GL(V ).1 So we arrive at the groups PGL(V ) =
GL(V )/C and PL(V ) = L(V )/C which act faithfully on L (V ). Again, PGL(V )
is a normal subgroup of PL(V ) and PL(V ) ∼= Aut(Fq) ⋊PGL(V ).
The elements of PGL(V ) will be called the linear elements of PL(V ). In the
case that q is prime, the group PL(V ) equals PGL(V ), and for the important case
q = 2, it reduces further to GL(V ). As the mappings in PGL(V ) and PL(V ) are
already determined by their images on the point set
V
1

q, we may consider them as
permutations of
V
1

q.
The following famous result which is called the “Fundamental Theorem of Pro-
jective Geometry” can be found for instance in Artin’s book [7].
Theorem 1 For v ≥3 the automorphism group of the lattice (L (V ), ≤) is given
by the natural action of PL(V ) on L (V ).
In this way, the group PL(V ) (and its subgroup PGL(V )) provide a notion of
(linear) automorphisms and (linear) equivalence on L (V ) and on derived sets like
the power set of L (V ).
The group GL(V ) is represented by the group GL(v, q) of all invertible v × v
matrices over Fq, via assigning the map x →xA to the matrix A ∈GL(v, q). More-
over, L(V ) is represented by the set L(v, q) of the pairs (A, σ) ∈GL(v, q) ×
Aut(Fq) via x →σ(x)A, where σ is applied simultaneously to all entries of x. By
composition of the represented maps (acting from the right), L(v, q) carries the
structure of a semidirect product GL(v, q) ⋊Aut(Fq), where the explicit multipli-
cation law is given by
(A, σ) · (A′, σ ′) = (σ ′(A)A′, σ ◦σ ′).
The center of GL(v, q) is the set Fq Iv of the scalar matrices (Iv denoting the v × v
identitymatrix).Therefore,PGL(V )isrepresentedbyPGL(v, q) = GL(v, q)/(Fq Iv)
and PL(V ) by PL(v, q) = L(V, q)/(Fq Iv, idFq).
1We would like to point out that the center of L(V ) is smaller, as it consists only of the elements
of C where λ is an element of the prime ﬁeld of Fq.

q-Analogs of Designs: Subspace Designs
177
Duality
We ﬁx some non-singular bilinear form β : V × V →Fq. For V = Fv
q, the standard
inner product (x, y) →v
i=1 xi yi may be taken. The dual subspace of U ∈L (V )
is deﬁned as
U ⊥= {x ∈V | β(x, y) = 0 for all y ∈U}.
For all U ∈L (V ), (U ⊥)⊥= U. In particular, U →U ⊥is a bijection on L (V ).
Moreover, for all U1,U2 ∈L (V ) we have
(U1 ∩U2)⊥= U ⊥
1 + U ⊥
2
and (U1 + U2)⊥= U ⊥
1 ∩U ⊥
2 .
Thus, the mapping U →U ⊥is an antiautomorphism of L (V ), showing that the
subspace lattice is self-dual.
2.2
The Gaussian Binomial Coefﬁcient
A complete chain in the subspace lattice of V has the form
{0} = U0 < U1 < U2 < . . . < Uv = V
with dim(Ui) = i.
To count the number of complete chains, we denote the number of partial chains
U0 < U1 < . . . < Uk with dim(Ui) = i by ak. For k ≥1, Uk = ⟨Uk−1 ∪{x}⟩for any
x ∈V \ Uk−1. As there are qv −qk−1 = qk−1(qv−k+1 −1) vectors x ∈V \ Uk, and
any qk −qk−1 = qk−1(q −1) vectors x yield the same space Uk, we see that
ak = qv−k+1 −1
q −1
ak−1 .
Now inductively,
ak =
k	
i=1
qv−i+1 −1
q −1
=
v	
i=v−k+1
qi −1
q −1
and therefore the number of complete chains of V is the q-factorial
[v]q! := av =
v	
i=1
qi −1
q −1 .
The name q-factorial stems from the observation that the complete ﬂags of the
subset lattice of a v-element set V correspond to the permutations of V and therefore,

178
M. Braun et al.
their number is the ordinary factorial v!. This can be carried a step further: Accepting
[v]q = qv−1
q−1 as the q-analog of the non-negative integer v, the q-factorial [v]q! =

v
i=1[i]q arises in the very same way from the q-numbers as the ordinary factorial
from ordinary numbers. For a deeper discussion ofq-analogs of permutations, see [6].
LetUk ∈
V
k

q andlet H = V/Uk = {v + Uk | v ∈V }bethecorrespondingfactor
vector space. It is easy to see that the mapping
{J ∈
V
j

q
| Uk ≤J} →
 H
j −k

q
, J →J/Uk = {v + Uk | v ∈J}
is a well-deﬁned bijection.
Next, we derive a formula for the number
v
k

q of k-subspaces of V . For this
purpose, we count the complete chains U0 < . . . < Uk < . . . < Uv of V in a second
way: There are
v
k

q possibilities for the choice of Uk. For ﬁxed Uk, the number of
possible head parts U0 < . . . < Uk is given by [k]q!. Modding out Uk,2 the possible
tail parts Uk < . . . < Uv = V uniquely correspond to the complete chains of V/Uk,
whose number is [v −k]q!. So,
[v]q! =
v
k

q
· [k]q! · [v −k]q! ,
and therefore
#
V
k

q
=
v
k

q
=
[v]q!
[k]q![v −k]q!.
The expression
v
k

q is known as the Gaussian binomial coefﬁcient or also as q-
binomial coefﬁcient, as it arises from the q-factorial in the usual way. If clear from
the context, the index q may be dropped from
v
k

q or
V
k

q for simplicity. Like for the
ordinary binomial coefﬁcient, it is convenient to deﬁne
v
k

q = 0 for integers k < 0
or k > v.
Many well-known formulas for binomial coefﬁcients have q-analogs, and quite
often, bijective proofs can be q-analogized. As easy examples, we mention
v
k

=

v
v −k

and
v
h
v −h
k

=
v
k
v −k
h

,
and for v ≥1 the q-Pascal triangle identities
2For a subspace U of V , the quotient space is given by V/U = {v + U | v ∈V } with the associated
canonical projection π : V →V/U, v →v + U. Extending the domain to the set of subspaces of
V , π provides an lattice isomorphism between the lattice interval [U, V ] = {U′ ∈L (V ) | U ≤
U′ ≤V } and the subspace lattice L (V/U).

q-Analogs of Designs: Subspace Designs
179
v
k

q
=
v −1
k −1

q
+ qk
v −1
k

q
= qv−k
v −1
k −1

q
+
v −1
k

q
.
The expressions [v]q = 1 + q + . . . + qv−1 and [v]q! are polynomials in Z[q] of
degrees v −1 and v(v −1)/2, respectively. By the formula
v
k

q
=
k	
i=1
qv−i+1 −1
qi −1
,
it is checked that
v
k

q is a polynomial in q, too, and its degree is
v−1
k−1

. The factoriza-
tion of Xn −1 in the UFD Z[X] is given by 
d Φd, where d runs over the positive
divisors of n and Φd ∈Z[X] denotes the d-th cyclotomic polynomial. Therefore,
q-numbers and q-binomial coefﬁcients factor into a product of pairwise distinct
cyclotomic polynomials Φd with d ≥2.
Remark 1 According to [8], q-analog numbers were introduced in [9] and their
binomial coefﬁcients in [10]. For a deeper discussion, see [6, 8, 11–13].
2.3
Counting Subspaces
The number of k-subspaces of V is given by
v
k

q. Applying this argument to the
quotient space V/U for some U ∈
V
u

q, we see that the number of k-subspaces K
with U ≤K ≤V equals
v−u
k−u

q.
Every k-subspace K of V has a complement, that is a subspace U ∈L (V ) with
K ∩U = {0} and K + U = V . By the dimension formula, dim(U) = v −k. An
important difference to the subset lattice is that in general, the complement is not
unique. More precisely, K has exactly qk(v−k) complements in V . For this, one
checks that after picking some complement U of K in L (V ), the complements
of K in L (V ) bijectively correspond to the homomorphisms φ ∈Hom(U, K) via
φ →im(id +φ). Now the claim follows as
dim(Hom(U, K)) = dim(U) dim(K) = (v −k)k .
Alternatively, after the choice of a suitable basis the subspace U can be represented
as the row space of the k × v-matrix (0 | Ik). One checks that the complements of U
are given by the row spaces of the k × v matrices (A | I) with A ∈F(v−k)v
q
, whose
number is qk(v−k).
Lemma 1 Let J ≤K ≤V be a chain of Fq-vector spaces of ﬁnite dimensions j, k
and v. The number of u-subspaces U of V with U ∩K = J is

180
M. Braun et al.
q(k−j)(u−j)
v −k
u −j

q
.
Proof By the dimension formula, dim(U + K) = u + k −j. So the possibilities
for U + K are given by the
v−k
u−j

q intermediate spaces W of K ≤V of dimension
u + k −j. Now modding out J, the u-subspaces U of V with U ∩K = J and
U + K = W correspond to the complements of K/J in W/J. Their number is
qdim(K/J)(dim(W/J)−dim(K/J)) = q(k−j)(u−j).
□
2.4
q-Analogs of Combinatorial Structures
As already discussed, we consider the subspace lattice L (V ) of a vector space
V of dimension v as the q-analog of the subset lattice of a v-element set V . In
Sect.2.2 we have used this approach to derive q-analog numbers, factorials and
binomial coefﬁcients, which are polynomials in Z[q]. For q = 1, they reduce to
ordinary numbers, factorials and binomial coefﬁcients. Hence the subset lattice may
be considered as the limit case q = 1 of a subspace lattice over Fq. For a deeper
discussion see [11], where even the notion of an unary “ﬁeld” F1 is used.
Many combinatorial areas, like design theory and coding theory, are based on
the subset lattice of a v-element ambient set V . Given such a class of combinatorial
objects, we may deﬁne its q-analog by replacing the subset lattice by the subspace
lattice of some Fq-vector space V of dimension v. Thereby, all notions depending
on the subset lattice get replaced by the corresponding counterpart in the subspace
lattice. Some of these correspondents are shown in Table2.4. The original class of
objects is then considered as the case q = 1 of the q-analog classes. An important
part of the theory of q-analogs is the investigation of results in the set-theoretic case
for their applicability in the q-analog case.
q = 1
q-analog
v-element set V
v-dim. Fq vector space V
elements of V (points) 1 −subspaces of V (points)
subset lattice of V
subspace lattice of V
V
k

V
k

q
v
k

v
k

q
cardinality
dimension
∩
∩
∪
+

q-Analogs of Designs: Subspace Designs
181
3
Subspace Designs
For all suitable parameters there exist always at least two designs. First, for all
t ∈{0, . . . , k} and B = ∅, (V, B) is a t-(v, k, 0)q subspace design. Second, (V, B)
with B being the full Graßmannian, i.e. B =
V
k

, is also a design for all t ≤k,
called the complete design.
Lemma 2 For 0 ≤t ≤k ≤v, (V,
V
k

q) is a t-(v, k,
v−t
k−t

q)q subspace design.
Proof As we have seen in Sect.2.3, any t-subspace T of V is contained in exactly
v−t
k−t

k-subspaces of V . This number is independent of the choice of T .
□
Both designs are called trivial. Since the full Graßmannian
V
k

is the design with
the largest possible value of λ among all simple designs with block dimension k, we
deﬁne
λmax =
v −t
k −t

q
.
It is clear that for any t-(v, k, λ)q subspace design D = (V, B), the supplementary
design (V,
V
k

\ B) is again a subspace design with the parameters t-(v, k,
v−t
k−t

q −
λ)q. The empty set and the full Graßmannian are supplementary to each other.
The earliest reference for q-analogs of designs we are aware of, is from Ray-
Chaudhuri [14], stated in the problem section of the Hypergraph Seminar at Ohio
State University 1972. One year later, Cameron [15] presented the same problem at
the British Combinatorial conference. The origin of the idea is unclear, since it is
stated there that “Several people have observed that the concept of a t-design can be
generalized [...]”. Subspace designs have also been mentioned—independently—in
a more general context by Delsarte in [16].
The existence of nontrivial subspace designs with t ≥2 was open for more than
a decade, until in [17] subspace designs with the parameters 2-(v, 3, 7)2 and v ≡
1, 5 mod 6, v ≥7 have been constructed. This construction was generalized to 2-
(v, 3, q2 + q + 1)q designs for arbitrary q in [18, 19]. In [20] a 3-(8, 4, 11)2 design
was given, the ﬁrst nontrivial subspace design with t = 3. Until now, no explicit
example with t ≥4 is known.
3.1
Divisibility Conditions
The following statement is the q-analog of a well-known property of combinatorial
designs and was ﬁrst shown in [21, Lemma 4.1(1)].
Lemma 3 Let
D = (V, B)
be
a
t-(v, k, λ)q
subspace
design.
For
each
s ∈{0, . . . , t}, D is an s-(v, k, λs)q subspace design with

182
M. Braun et al.
λs =
v−s
t−s

q
k−s
t−s

q
· λ =
v−s
k−s

q
v−t
k−t

q
· λ.
In particular, the number of blocks is given by #B = λ0.
Proof Let s ∈{0, . . . , t}, S ∈
V
t

q and λS the number of blocks of D containing S.
We count the set X of all pairs (T, B) ∈
V
t

q × B with S ≤T ≤B in two ways:
There are
v−s
t−s

q subspaces T containing S, and by the design property each T
is contained in λ blocks K. So #X =
v−s
t−s

q · λ. On the other hand, there are λS
blocks B ∈B containing S, each containing
k−s
t−s

q subspaces T ∈
V
t

q. This shows
#X = λS ·
k−s
t−s

q. The proof is concluded by equalizing these two expressions for
#X.
□
Deﬁnition 3 For s = t −1, the resulting design of Lemma 3 is called the reduced
design of D.
Furthermore,byLemma3,theexistenceofat-(v, k, λ)q designimpliestheintegrality
conditions
λs ∈Z, i.e.
v −s
t −s

q
· λ ≡0
(mod
k −s
t −s

q
)
for all s ∈{0, . . . , t}. Without requiring the actual existence of a corresponding
design,anyparametersett-(v, k, λ)q fulﬁllingtheintegralityconditionswillbecalled
admissible. Moreover, it will be called realizable if a t-(v, k, λ)q design does actually
exist. Of course, realizability implies admissibility. For q = 1, counterexamples are
known showing that the contrary is not always true. For q ≥2, this is an open
question.
It is easily seen that a 1-(v, k, λ)q design is admissible if and only if k | v. In fact,
for λ = 1, all those subspace designs are realizable:
Lemma 4 There exists a 1-(v, k, 1)q design if and only if k divides v.
Proof The direction “⇒” follows from the integrality conditions. For “⇐”, let v be
a multiple of k. Then
Fqv
1

qk forms a 1-(v, k, 1)q design on the Fq-vector space Fqv.
□
The above result has been shown in [22] (see also [23] for the case v = 2k) in
geometric terms: A 1-(v, k, 1)q design is known as a (k −1)-spread in PG(v −1, q).
The admissibility of a Steiner triple system STSq(v) (v ≥3) depends on the
numbers λ1 = [v−1]q
Φ2
and λ0 = [v−1]q[v]q
Φ2Φ3
(see Example 4) being integers. The result-
ing condition is that STSq(v) is admissible if and only if v ≡1 (mod 6) or v ≡3
(mod 6). This condition does not depend on q and coincides with the admissibility
in the case q = 1 of a combinatorial Steiner triple system STS(v).

q-Analogs of Designs: Subspace Designs
183
The smallest admissible parameter set of a q-analog of a Steiner system with
t ≥2 is the Steiner triple system STSq(7) or, in other words, a 2-(7, 3, 1)q design.
For q = 1, there is a unique design with these parameters, namely the Fano plane.
Arguably, the most important open problem in the theory of subspace designs is the
question for the existence of a 2-(7, 3, 1)q design, also known as a q-analog of the
Fano plane. This question was already stated in 1972, in the introduction on subspace
designs by Ray-Chaudhuri in [14].
The only q-analog of a Steiner triple system known to be realizable is STS(13)2,
see Sect.6.1.
3.2
New Designs from Old Ones
Lemma 5 (Suzuki [21]) Let D = (V, B) be a t-(v, k, λ)q-design. For subspaces
I ≤J ≤V , let i = dim(I), j = dim(V/J) and
ΛI,J = {B ∈B | I ≤B ≤J} .
If i + j ≤t, the number
λi, j := #ΛI,J
only depends on the dimensions i and j, but not on the exact choice of I and J. The
numbers λi, j are determined by the recurrence formula
λi,0 = λi
and λi, j = λi, j−1 −qv−k−j+1λi+1, j−1.
In closed form,
λi, j = λ
v−i−j
k−i

q
v−t
k−t

q
.
Proof Let i + j ≤t. We proceed by induction over j.
For j = 0, we have J = V and #ΛI,J = λi is independent of the choice of I.
Now assume j ≥1 and let ˆJ be a superspace of J with dim( ˆJ/J) = 1. We count the
set X of all pairs ( ˆI, B) ∈
 V
i+1

q × B with ˆI ≤B ≤ˆJ and ˆI ∩J = I in two ways.
By Lemma 1, the number of ˆI ∈

ˆJ
i+1

q with ˆI ∩J = I is q((v−j)−i)((i+1)−i) =
qv−j−i. By the induction hypothesis, for each such subspace ˆI there are λi+1, j+1
blocks B ∈B with ˆI ≤B ≤ˆJ. So,
#X = qv−j−iλi+1, j−1 .
Again by the induction hypothesis, there are λi, j−1 blocks B with I ≤B ≤ˆJ. By
the dimension formula, those blocks have either

184
M. Braun et al.
B ≤J
or
dim(J ∩B) = k −1 .
The blocks of the ﬁrst kind are the blocks in ΛI,J, which do not have a suitable
subspace ˆI.
For each of the λi, j−1 −#ΛI,J blocks B of the second kind, Lemma 1 gives the
number of choices for ˆI ∈
 B
i+1

q with ˆI ∩J = ˆI ∩(B ∩J) as q((k−1)−i)((i+1)−i) =
qk−i−1. So,
#X = (λi, j−1 −#ΛI,J)qk−i−1 .
Equalizing these two expressions for #X yields
#ΛI,J = λi, j−1 −qv−k−j+1λi+1, j−1,
which only depends on i and j. The closed formula is readily checked by induction.
□
The “reﬁned” λ’s of the above lemma are a q-analog of the values b j
i in [24]. Lemma 5
has originally been proven as [21, Lemma 4.1] (in the notation γ j
i ).
Example 2 If we look at the 1-(4, 2, 1)2 design from Example 1 and take as I the
trivial subspace I = {0} and as J an arbitrary hyperplane, i.e. i = 0 and j = 1, then
of course all blocks of the design contain I. But moreover, from
4 −0 −1
2 −0

2
/
4 −1
2 −1

2
= 1
we can conclude that every hyperplane J contains exactly one block of the design.
Deﬁnition 4 Let D = (V, B) be a t-(v, k, λ)q design.
(a) For any point P ∈
V
1

, we deﬁne
DerP(D) = (V/P, {B/P | B ∈B, P ≤B}) .
DerP(D) is called the derived design of D with respect to P.
(b) For any hyperplane H ∈
 V
v−1

, we deﬁne
ResH(D) = (H, {B | B ∈B, B ≤H}) .
ResH(D) is called the residual design of D with respect to H.
(c) The dual design of D is deﬁned by
D⊥= (V, {B⊥| B ∈B}) .
Different choices for the point P and the hyperplane H may lead to non-
isomorphic derived and residual designs. In contrast, up to isomorphism, the def-
inition of the dual design does not depend on the choice of the bilinear form β.

q-Analogs of Designs: Subspace Designs
185
For the special case of Steiner systems, the derived design shows up in [4, The-
orem 2]. The residual design was introduced in [25] and the dual design in [21,
Lemma 4.2].
Deﬁnition 4 is a q-analog of the established notions of the derived, the residual
and the complementary design of a combinatorial block design. However, for q = 1
the residual design is usually deﬁned as
(V \ {P}, {B ∈B|P /∈B})
(2)
for a point P of V . For q = 1, (2) is equivalent to Deﬁnition 4 via H = V \ {P}. This
shows that for q = 1, the derived and the residual design with respect to the same
point P provide a decomposition of the original t-design into two (t −1)-designs. In
particular, #D = # Der(D) + # Res(D). Unfortunately, this property is not true for
q ≥2. One might try to preserve the decomposition property by deﬁning theq-analog
of the residual design directly via (2). However, this is out of question as for q ≥2,
the base set V \ {B} is not a vector space, and staying with the original ambient space
V , the resulting set of blocks is not necessarily a design anymore. Deﬁnition 4 of
the residual design is further backed by all the properties stated below, which are all
q-analogs of well-known properties of classical combinatorial designs:
Theorem 2 Let D = (V, B) be a t-(v, k, λ)q design, P ∈
V
1

and H ∈
 V
v−1

.
(a) The derived design DerP(D) is a design on V/P with the parameters
(t −1)-(v −1, k −1, λ)q.
(b) The residual design ResH(D) is a design on H with the parameters
(t −1)-(v −1, k, qv−k −1
qk−t+1 −1λ)q .
(c) The dual design D⊥is a design on V with the parameters
t-(v, v −k,
v−t
k

v−t
k−t
 λ)q .
Proof (a) We see that for any t-subspace T containing P, the blocks B ∈B passing
through T uniquely correspond to the blocks B/P of DerU(D) passing through T/P.
(b) The λ-value of ResH(D) is given by the number λt−1,1 of Lemma 5.
(c) For T ∈
V
t

, the blocks B⊥of D⊥passing through T uniquely correspond to
the blocks B ∈B contained in T ⊥. By dim(T ⊥) = v −t, the λ-value of D⊥is the
number λ0,t of Lemma 5.
□

186
M. Braun et al.
We would like to mention the following straightforward relations:
(D⊥)⊥= D,
DerP(D)⊥= ResP⊥(D) and
ResH(D)⊥= DerH ⊥(D).
The numbers λi, j are nicely visualized in triangle form:
λ0,0
λ1,0
λ0,1
λ2,0
λ1,1
λ0,2
...
...
...
...
λt,0
λt−1,1
. . .
λ1,t−1
λ0,t
In this way, the λi, j-triangles of various modiﬁcations can be read off directly:
• Reduced design: The upper sub-triangle (arising after the deletion of the last row).
• Derived design: The lower left sub-triangle.
• Residual design: The lower right sub-triangle.
• Dual design: The left-right mirror image.
Example 3 The parameters 3-(8, 4, 1)q are admissible for any q, but known to be
realizable only in the ordinary case q = 1. Below, the λi, j-triangle for these param-
eters is shown, for q = 2 and for general q.
6477
381
381
21
45
21
1
5
5
1
Φ6Φ7Φ8
Φ6Φ7
Φ6Φ7
Φ3Φ6
Φ2Φ4Φ6
Φ3Φ6
1
Φ4
Φ4
1
The symmetry of the triangles reﬂects the property of the parameters being self-dual,
meaning that the dual design would have the same parameters. As the q-analog of
the Fano plane has the derived parameters of 3-(8, 4, 1)q, its triangle can be found
as the lower left sub-triangle.
Example 4 The λi, j-triangle for a Steiner triple system STSq(v) (a 2-(v, 3, 1)q
design) is:
[v−1]q[v]q
Φ2Φ3
[v−1]q
Φ2
[v−3]q[v−1]q
Φ2Φ3
1
[v−3]q
Φ2
[v−4]q[v−3]q
Φ2Φ3
By construction, for a design its derived and residual designs exist. It may be
surprising that also the converse is true, but not necessarily for the designs itself
but for the parameter sets. The following statements are the q-analogs of results

q-Analogs of Designs: Subspace Designs
187
independently found by Tran van Trung [26], van Leijenhorst [27] and Driessen [28].
It has been shown in [25, Lemma 4.1 and Theorem 1].
Theorem 3 Let t-(v, k, λ)q be some parameters.
(a) If the derived and the residual parameters are admissible, then the parameters
t-(v, k, λ)q are admissible, too.
(b) If the derived and the residual parameters are realizable, then the parameters
(t −1)-(v, k, λt−1)q, i.e. the parameters of the reduced design, are realizable,
too.
Further, there are cases where the derived parameters are realizable and the resid-
ual parameters coincide with the parameters of the dual of the derived design. Then,
the realizability of derived parameters sufﬁces to get the following corollary.
Corollary 1 ([25, Corollary 2]) The realizability of the parameters
t-(2k −1, k −1, λ)q
implies the realizability of the parameters
t-(2k, k, λ · (q2k−t −1)/(qk−t −1))q .
3.3
Intersection Numbers
Now we discuss intersection numbers, which describe the intersection sizes of the
blocks of a design with a ﬁxed subspace S and can be seen as an extension of the
numbers λi, j (Lemma 6). For combinatorial designs they have been originally deﬁned
in [29] for blocks S and independently as “i-Treffer” for general sets S in [30]. We
follow [31], where intersection numbers for subspace designs have been introduced.
Deﬁnition 5 Let D = (V, B) be a t-(v, k, λ)q subspace design. For any subspace
S of V and i ∈{0, . . . , k}, we deﬁne the i-th intersection number of S in D as
αi(S) = # {B ∈B | dim(B ∩S) = i} .
If the set S is clear from the context, we use the abbreviation αi = αi(S).
If α⊥denotes the intersection numbers of the dual design, by the dimension
formula and the properties of the dual we have
αi(S) =

0,
if i > s or k −i > v −s;
α⊥
(v−s)−(k−i)(S⊥), otherwise.

188
M. Braun et al.
The following lemma shows that if the dimension or the codimension of S in V is
at most t, the intersection numbers are uniquely determined and closely connected
to the numbers λi, j.
Lemma 6 ([31, Lemma 2.3])
αi(S) =
s
i

q · λi,s−i,
if dim(S) ≤t;
qsk−ivv−s
k−i

q · λk−i,(v−s)−(k−i), if dim(S) ≥v −t.
Proof The ﬁrst case is shown by double counting the set of all (I, B) ∈
S
i

q × B
with B ∩S = I. The second case follows by making use of the dual design.
□
Theorem 4 ([31, Theorem 2.4], q-analog of the Mendelsohn equations [29, Theo-
rem 1]) Let D be a t-(v, k, λ)q subspace design, S a subspace of V and s = dim(S).
For i ∈{0, . . . , t} we have the following equation on the intersection numbers of S
in D:
s

j=i
 j
i

q
α j =
s
i

q
λi
(3)
Proof Wecounttheset X ofallpairs(I, B) ∈
V
i

q × B with I ≤B ∩S intwoways:
On the one hand, there are
s
i

q possibilities for the choice of I ∈
S
i

q. By Lemma 3,
there are λi blocks B such that I ≤B, which shows that #X equals the right hand
side of Eq. (3). On the other hand, ﬁxing a block B, the number of i-subspaces I
of B ∩S is
dim(B∩S)
i

q. Summing over the possibilities for j = dim(B ∩S), we see
that #X also equals the left hand side of Eq.(3).
□
The Mendelsohn equations can be read as a linear system of equations Ax = b on
the intersection vector x = (α0, α1, . . . , αk). The left (t + 1) × (t + 1) square part
of the matrix A = (
 j
i

q)i j (i ∈{0, . . . , t} and j ∈{0, . . . , k}) is called the upper
triangular q-Pascal matrix, which is known to be invertible with inverse matrix

(−1) j−iq( j−i
2 ) j
i

q

i j. Left-multiplication of the equation system with this inverse
yields a parameterization of the intersection numbers α0, . . . , αt by αt+1, . . . , αk. In
this way, we get:
Theorem 5 ([31, Theorem 2.6], q-analog of the Köhler equations [32, Satz 1])
Let D be a t-(v, k, λ)q subspace design, S a subspace of V and s = dim(S). For
i ∈{0, . . . , t}, a parametrization of the intersection number αi by αt+1, . . . , αk is
given by
αi =
s
i

q
t
j=i
(−1) j−iq( j−i
2 )
s −i
j −i

q
λ j
+(−1)t+1−iq(t+1−i
2 )
k

j=t+1
 j
i

q
 j −i −1
t −i

q
α j.

q-Analogs of Designs: Subspace Designs
189
3.4
Combinatorial Designs from Subspace Designs
By identifying the blocks of a subspace design with its set of points, we can construct
combinatorial designs.
Theorem 6 Let D = (V, B) be a t-(v, k, λ)q subspace design. We deﬁne the fol-
lowing two combinatorial designs:
• Projective version: Let Dp = (
V
1

q, {
B
1

q | B ∈B})
• Afﬁne version: For any ﬁxed hyperplane H ∈
 V
v−1

q let
Da =
V
1

q
\
H
1

q
,
B
1

q
\
H
1

q
| B ∈B, B ≰H

Ift = 2,thenDp isacombinatorial2-(
v
1

q,
k
1

q, λ)designandDa isacombinatorial
2-(qv−1, qk−1, λ) design. In the case q = 2 and t = 3, Da is even a combinatorial
3-(qv−1, qk−1, λ) design.
Proof Let T be a 2-subset of
V
1

q. By the deﬁnition of Dp, each block consists of
the set of points of a certain k-subspace. Hence, any block containing the elements
of T has to contain all the points in the 2-subspace ⟨T ⟩. By the design property of
D, there are exactly λ blocks of D (and hence of Dp) with this property.
In the afﬁne case, the proof is similar as by deﬁnition, any block of Da containing
a 2-subset T of
V
1

q \
H
1

q has to contain the points in the afﬁne line ⟨T ⟩\
H
1

q, too,
and each block Ba of Da uniquely determines the corresponding block B = ⟨Ba⟩of
D. For q = 2 and t = 3, a triple T of points in
V
1

q \
H
1

q cannot be collinear, as
afﬁne lines consist of q = 2 points only. Hence dim(⟨T ⟩) = 3 and the claim follows
in an analogous way.
□
The key of the above proof is that dim(⟨T ⟩) is uniquely determined independently
of the choice of the t-subset T . This shows that the preconditions cannot be relaxed,
as in the projective version, this property is not true any more for t ≥3 (triples of
points may be collinear or not), and in the afﬁne situation the only exception is the
special case q = 2, t = 3 of Theorem 6 (where triples cannot be collinear). The
projective version of Theorem 6 is already mentioned in [33, Sect.1]. For the case
of Steiner systems, the afﬁne version is found in [4, Theorems 7 and 8].
3.5
On Automorphism Groups of Designs
As the deﬁnition of a subspace design can entirely be expressed in terms of the sub-
space lattice L (V ), the design property is invariant under the action of Aut(L (V )).
Thus, Aut(L (V )) provides a notion of isomorphism of designs: Two designs

190
M. Braun et al.
D = (V, B) and D′ = (V, B′) on V are called isomorphic if and only if they
are contained in the same orbit of Aut(L (V )) or equivalently, if there exists an
α ∈Aut(L (V )) such that α(B) = B′. The stabilizer of B with respect to the action
of Aut(L (V )) is called the automorphism group of D, that is
Aut(D) = Aut(L (V ))B = {α ∈Aut(L (V )) | α(B) = B} .
For any subgroup G of Aut(D), D is called G-invariant.
By Formula (1), the question for the existence of a G-invariant t-(v, k, λ)q design
D = (V, B) only depends on the conjugacy class of G in Aut(L (V )). Hence in
order to choose possible groups of automorphisms for a t-(v, k, λ)q design, it is
sufﬁcient to take only one representative of each conjugacy class of subgroups of
Aut(L (V )).
From the orbit-stabilizer-theorem of group actions, see [34, Sect.1.2], we also
get a one-to-one correspondence of the set of isomorphic designs of B with the set
of cosets of the automorphism group of B within Aut(L (V )). More formally, the
mapping
Aut(L (V ))(B) →Aut(L (V ))/ Aut(L (V ))B, α(B) →α Aut(L (V ))B
is a bijection.
In chapter “Computational Methods in Subspace Designs” on computer construc-
tion of subspace designs it is explained in detail how to construct subspace designs
with a prescribed group of automorphisms by computer. This is the so called Kramer-
Mesner method.
Theorem 7 (Kramer, Mesner [35]) Let G ≤PL(V ). There exists a G-invariant
t-(v, k, λ)q design if and only if there is a 0/1-vector x satisfying
AG
t,k · x =
⎛
⎝
λ
...
λ
⎞
⎠.
(4)
Details on the matrix AG
t,k can be found in the chapter “Computational Methods in
Subspace Designs”. In general, our aim in that chapter is to prescribe certain groups
of automorphisms which arise as subgroups G of the general linear group GL(V ).
The corresponding images ¯G in PGL(V ) ≤Aut(L (V )) are the groups to prescribed.
When it comes to the question which groups may occur as automorphism groups
of designs, one group stands out, which is the normalizer of a Singer cycle group: At
present, most of the successful computer searches for subspace designs have been
performed by prescribing this group or a subgroup of small index, see Sect.4.
Let φ ∈GL(V ) and ⟨φ⟩= {idV , φ, φ2, φ3, . . .} be the cyclic subgroup of GL(V )
generated by φ. By Cayley–Hamilton, the minimal polynomial of φ has at most
degree v, implying that the linear hull of ⟨φ⟩has at most dimension v. As 0 /∈⟨φ⟩,

q-Analogs of Designs: Subspace Designs
191
we get that ⟨φ⟩contains at most qv −1 distinct elements. In other words, the element
order of φ is at most qv −1.
An element of GL(V ) of order qv −1 is called a Singer cycle, and a cyclic sub-
group of order qv −1 is called a Singer cycle group. Indeed, Singer cycles and Singer
cycle groups do always exist: To see this, we equip V with a ﬁeld multiplication,
by setting V = Fqv. For any primitive element α of Fqv (that is, α is a generator of
the cyclic unit group F×
qv), σ : V →V , x →αx is an Fq-linear mapping of order
#F×
q = qv −1 and thus a Singer cycle.
To get a matrix representation of σ in GL(v, q), we can proceed as follows: Let
f = a0 + a1x + a2x2 + . . . + an−1xn−1 + xn ∈Fq[x] be the minimal polynomial
of α over Fq. Then f is a primitive irreducible polynomial of degree v. With respect
to the Fq-basis (1, α, α2, . . . , αv−1) of V = Fqv, the transformation matrix of σ is
given by the companion matrix of f , which is
⎛
⎜⎜⎜⎜⎝
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
−a0 −a1 −a2 . . . −av−1
⎞
⎟⎟⎟⎟⎠
.
By [36, Sect.7], any two Singer cycle subgroups of GL(V ) are conjugate. We
point out that, in general, this is not true for Singer cycles: For example, the Singer
cycles in GL(2, 3) and GL(3, 2) both fall into 2 conjugacy classes.3
The Galois group Gal(Fqv/Fq) of the ﬁeld extension Fqv/Fq, i.e. the group of all
ﬁeld automorphisms of Fqv element-wise ﬁxing Fq, is known to be cyclic of order v
and generated by the mapping F : x →xq. F is called Frobenius automorphism. It
is easily seen that F normalizes the Singer cycle group S = ⟨σ⟩, showing that ⟨σ, F⟩
is contained in the normalizer NGL(V )(S) of S in GL(V ). In fact, both groups are
equal [36, Satz 7.3], so
NGL(V )(S) = ⟨σ, F⟩= Gal(Fqv/Fq) ⋊S.
In particular, the normalizer NGL(V )(S) is of order v(qv −1) and the quotient of S
in its normalizer is cyclic of order v.
In the following, S(v, q) (and N(v, q)) will denote the conjugacy class of all
(normalizers of) Singer cycle groups in GL(v, q).
3For a singer cyclic subgroup S, we have [NGL(V )(S) : S] = v (see below), so under the action of
NGL(V )(S), the ϕ(qv −1) Singer cycles in S fall into ϕ(qv−1)
v
orbits of length v (ϕ denoting the
Euler’s phi function). From this, we get that the number of conjugacy classes of Singer cycles in
GL(v, q) equals ϕ(qv−1)
v
.

192
M. Braun et al.
4
Examples
In order to represent a G-invariant design it is sufﬁcient to list G by its generators
and the set of representatives of the selected orbits of G on
V
k

. For a compact
representation we will write all α × β matrices X over Fq with entries xi, j, whose
indices are numbered from 0, as vectors of integers
⎡
⎣
j
x0, jq j, . . . ,

j
xα−1, jq j
⎤
⎦.
Example 5 The ﬁrst nontrivial simple subspace design for t = 3 was constructed by
Braun, Kerber, and Laue [20]. It has parameters 3-(8, 4, 11)2 and is invariant under
the normalizer of the Singer cycle group N(8, 2) = ⟨σ, F⟩. The order of the group
is 2040, generators are
σ = [2, 4, 8, 16, 29, 32, 64, 128],
F = [1, 4, 16, 19, 29, 64, 116, 205] .
The design can be constructed from the following orbit representatives.
[28, 32, 64, 128], [2, 32, 64, 128],
[10, 32, 64, 128], [6, 32, 64, 128],
[22, 32, 64, 128],
[5, 32, 64, 128],
[8, 16, 64, 128],
[6, 16, 64, 128],
[33, 16, 64, 128], [3, 16, 64, 128],
[7, 16, 64, 128],
[39, 16, 64, 128], [47, 16, 64, 128], [2, 48, 64, 128],
[38, 48, 64, 128],
[14, 48, 64, 128], [37, 48, 64, 128], [13, 48, 64, 128], [38, 8, 64, 128],
[22, 8, 64, 128],
[54, 8, 64, 128],
[54, 40, 64, 128], [1, 24, 64, 128],
[51, 24, 64, 128], [39, 24, 64, 128],
[6, 56, 64, 128],
[35, 56, 64, 128], [59, 36, 64, 128], [34, 20, 64, 128], [59, 20, 64, 128],
[25, 12, 64, 128], [34, 28, 64, 128], [43, 28, 64, 128], [61, 42, 64, 128], [21, 62, 64, 128],
[105, 50, 84, 128]
In Tables1,2,3 and4 we list sets of parameters for subspace designs which are
known to be realizable. The subspace designs were either by the Kramer-Mesner
method and by the methods described in Sects.5 and 7 or by combining existing
subspace designs to get new ones, as described in Theorem 3 and Corollary 1.
Due to the existence of dual and supplementary designs we restrict the lists to
t-(v, k, λ)q designs satisfying 1 < t < k ≤v/2 and 1 ≤λ ≤λmax/2.
Given a prime power q and integers 0 < t < k < v, the smallest positive integer
value of λ for which t-(v, k, λ)q is admissible is denoted by λmin. By Lemma 3, the
set of all λ such that t-(v, k, λ)q is admissible is given by {λmin, 2λmin, . . . , λmax}.
As superscripts of the λ-values we give the earliest reference we are aware of.
The references are encoded by the following letters:

q-Analogs of Designs: Subspace Designs
193
Table 1 Parameters of simple t-(v, k, λ)2 designs known to be realizable
t-(v, k, λ)q
λmin
λmax
λ
2-(6, 3, λ)2
3
15
3a, 6b. Open: –
2-(7, 3, λ)2
1
31
3c, 4a, 5c, 6a, 7d, 8a, 9b, 10c, 11b, 12c, 14c, 15b. Open: 1,
2
2-(8, 3, λ)2
21
63
21b. Open: –
2-(8, 4, λ)2
7
651
7e, 14e, 21b, 35 f , 49e, 56g, 63∗, 70g, 84∗, 91b, 98e, 105g,
112e, 126g, 133g, 140b, 147∗, 154e, 161g, 168∗, 175g,
189∗, 196g, 203e, 210b, 217h, 231b, 245g, 252∗, 259e,
266g, 273∗, 280 f , 294∗, 301b, 308e, 315g. Open: 28, 42,
77, 119, 182, 224, 238, 287, 322
3-(8, 4, λ)2
1
31
11a, 15i. Open: 1, …, 10, 12, 13, 14
2-(9, 3, λ)2
1
127
7e, 12e, 19e, 21g, 22g, 24e, 31e, 36e, 42g, 43g, 48e, 49m,
55e, 60e, 63g
2-(9, 4, λ)2
7
2667
21 f , 63 f , 84 f , 126 f , 147 f , 189 f , 210 f , 252 f , 273 f ,
315 f , 336 f , 378 f , 399 f , 441b, 462 f , 504 f , 525 f , 567 f ,
588 f , 630b, 651 f , 693 f , 714 f , 756 f , 777 f , 819b, 840 f ,
882 f , 889h, 903 f , 945 f , 966 f , 1008 f , 1029 f , 1071 f ,
1092 f , 1134 f , 1155 f , 1197 f , 1218 f , 1260b, 1281 f ,
1323 f
3-(9, 4, λ)2
21
63
Open: 21
2-(10, 3, λ)2
3
255
15b, 30b, 45k, 60 j, 75 j, 90 j, 105 j, 120b
2-(10, 4, λ)2
5
10795
595∗, 1020∗, 1615∗, 1785∗, 1870∗, 2040∗, 2635∗, 3060∗,
3570∗, 3655∗, 4080∗, 4165∗, 4675∗, 5100∗, 5355∗
3-(10, 4, λ)2
1
127
–
2-(10, 5, λ)2
15
97155
765∗, 4590∗, 5355∗, 6885∗, 7650∗, 9180∗, 9945∗, 2295∗,
3060∗, 11475∗, 12240∗, 13770∗, 14535∗, 16065∗, 16830∗,
18360∗, 19125∗, 20655∗, 21420∗, 22950∗, 23715∗,
25245∗, 26010∗, 27540∗, 28305∗, 29835∗, 30600∗,
32130∗, 32385h, 32895∗, 34425∗, 35190∗, 36720∗,
37485∗, 39015∗, 39780∗, 41310∗, 42075∗, 43605∗,
44370∗, 45900∗, 46665∗, 48195∗
3-(10, 5, λ)2
21
63
Open: 21
2-(11, 3, λ)2
7
511
7d, 245e, 252e
2-(11, 4, λ)2
35
43435
–
2-(11, 5, λ)2
5
788035
43435∗, 74460∗, 117895∗, 130305∗, 136510∗, 148920∗,
192355∗, 223380∗, 260610∗, 266815∗, 297840∗, 304045∗,
341275∗, 372300∗, 390915∗
2-(12, 3, λ)2
3
1023
–
2-(12, 4, λ)2
7
174251
–
2-(12, 5, λ)2
465
6347715
–
2-(12, 6, λ)2
31
53743987
2962267∗, 5078172∗, 8040439∗, 8886801∗, 9309982∗,
10156344∗, 13118611∗, 15234516∗, 17773602∗,
18196783∗, 20312688∗, 20735869∗, 23274955∗,
25390860∗, 26660403∗
3-(12, k, λ)2
–
2-(13, 3, λ)2
1
2047
1l, 2q, …, 6q, 7d, 8q…, 1023q. Open: –

194
M. Braun et al.
Table 2 Parameters of simple t-(v, k, λ)3 designs known to be realizable
t-(v, k, λ)q
λmin
λmax
λ
2-(6, 3, λ)3
4
40
8e, 12e, 16 f , 20b. Open: 4
2-(7, 3, λ)3
1
121
5c, 6b, …, 12b, 13n, 14b, …, 40b, 41e, 42b, …, 60b.
Open: 1, …, 4
2-(8, 3, λ)3
52
364
52g, 104 f , 156 f . Open: –
2-(8, 4, λ)3
13
11011
91 · 5∗, 91 · 6∗, …, 91 · 60∗
2-(10, 3, λ)3
4
3280
1640◦
2-(11, 3, λ)3
13
9841
13n
2-(13, 3, λ)3
1
88573
13n
Table 3 Parameters of simple t-(v, k, λ)4 designs known to be realizable
t-(v, k, λ; q)
λmin
λmax
λ
2-(6, 3, λ)4
5
85
10e, 15e, 25e, 30e, 35e. Open: 5, 40
2-(7, 3, λ)4
1
341
21p
2-(8, 4, λ)4
21
93093
5733∗
Table 4 Parameters of simple t-(v, k, λ)5 designs known to be realizable
t-(v, k, λ; q)
λmin
λmax
λ
2-(6, 3, λ)5
6
78
78◦. Open: 6, 12, …, 72
2-(7, 3, λ)5
1
781
31n
2-(8, 4, λ)5
31
508431
20181∗
2-(10, 3, λ)5
6
97656
48828◦
a: Braun, Kerber, Laue (2005) [20],
b: Braun (2005) [37],
c: Miyakawa, Munemasa, Yoshiara (1995) [38],
d: Thomas (1987) [17],
e: Braun (2015) presentation at ALCOMA 2015,
f: S. Braun (2010) [39],
g: S. Braun (2009) [40],
h: Kiermaier, Laue, Wassermann (2016) [41],
i:
Braun (2013) [42],
j:
Braun (2011) presentation at Fq10,
k: Braun (2016) [43],
l:
Braun, Etzion, Östergård, Vardy, Wassermann (2016) [44]
m: Braun (2017) [45],
n: Suzuki (1992) [19],
o: Braun, Kiermaier, Kohnert, Laue (2017)[46],
p: Suzuki (1990) [18],
q: Braun, Wassermann (2017) [47],
∗: Kiermaier, Laue (2015) [25], see Theorem 3 and Corollary 1
In case there are only few remaining open cases, we list the λ-values in question.

q-Analogs of Designs: Subspace Designs
195
4.1
Special Subspace Designs
Designs for t = 2
A considerable part of the literature on combinatorial designs studies balanced
incompleteblockdesigns (BIBD)whichare2-(v, k, λ)designs.Thenumberofblocks
is denoted with b = λ0 and each point appears in r = λ1 blocks. Let M be the v × b
incidence matrix of the points and the blocks of a BIBD.
The results in the following theorem are classical and can be found e.g. in [2,
Chap. II, Sects.1 and2].
Theorem 8 For a 2-(v, k, λ) design it holds
(a) bk = vr,
(b) b ≥rank(M) = v. (Fisher’s inequality)
From the deﬁnitions of b and r it follows immediately that the q-analog of equation
(a) for 2-(v, k, λ)q subspace design is
[k]qb = [v]qr.
The incidence matrix M between the points, i.e. the 1-subspaces, and the blocks of
the designs has size [v]q × b. The q-analog of Fisher’s inequality is
b ≥rank(M) = [v]q,
see [15, 48].
Symmetric Designs
If a (combinatorial) 2-(v, k, λ) design attains the bound in Fisher’s inequality, i.e. if
v = b, the design is called symmetric. One consequence is that two different blocks
of a symmetric 2-(v, k, λ) design always intersect in exactly λ points, compare [2,
Chap.II, Sect.3]. That is, for B ∈B, αλ(B) is the only nonzero intersection num-
ber. Symmetric designs are especially interesting because of their relation to ﬁnite
projective planes.
It was shown already in [49] that symmetric subspace designs are always trivial.
To be precise, only the complete design (V,
 V
v−1

q) is symmetric, the intersection
of two different blocks always has dimension λ. We note however, that the resulting
combinatorial design of a symmetric subspace design is in general nontrivial.
Quasi-symmetric Designs
As seen above, symmetric designs are not interesting in the context of subspace
designs. Thus, one might relax the condition that two blocks always intersect in a
λ-dimensional subspace and allow two intersection numbers. Combinatorial designs
with this property are called quasi-symmetric. However, we are not aware of any
work about quasi-symmetric subspace designs.

196
M. Braun et al.
Signed Designs
Up to now, designs were either simple or non-simple, depending if the multiplicities
of all blocks of the design are one or larger than one. If one allows the multiplicity
of block to be also negative, the design is called a signed design. In [50] it is shown
that all admissible designs are realizable as signed designs. This is the q-analog of a
result by Wilson [51], which is a key ingredient in the proof of Keevash [52].
Generalized Subspace Designs
In [53, 54], Guruswami et al. give a more general deﬁnition of subspace designs.
They deﬁne an (s, λ)-subspace design to be a collection of subspaces B1, . . . , Bb of
V such that for every t-subspace T ≤V at most λ blocks Bi intersect T nontrivially.
4.2
Asymptotic Existence Results
For combinatorial designs, Teirlinck [55] showed that for all integers t > 0 there exist
simple t-designs for v, k, λ sufﬁciently large. In 2013, Fazeli, Lovett and Vardy [56]
succeeded in proving a similar result for subspace designs, with the difference that
the proof in [55] is constructive, but the proof in [56] is not.
Theorem 9 (Fazeli, Lovett, Vardy) Simple nontrivial t-(v, k, λ)q designs exist for
all q and t, and all k > 12(t + 1) provided that v ≥ckt for a large enough absolute
constant c. Moreover, these t-(v, k, λ)q designs have at most q12(t+1)v blocks.
In 2014, the long-standing question, whether Steiner systems over sets exist for all
integerst > 0, couldbeansweredafﬁrmativelyinacelebratedresult byKeevash[52].
The non-constructive proof relies heavily on an asymptotic approximation by Frankl
and Rödl [57].
For the time being, there is not such a result for q-Steiner systems. But in [57]
the asymptotic approximation result is also shown in the subspace case.
Theorem 10 (Frankl-Rödl) Let 0 < t < k be integers. Then for v →∞there exists
a set B ⊂
V
k

such that
#B = (1 −o(1))
v
t

q
/
k
t

q
and dim(K ′ ∩K ′′) < t for all distinct K ′, K ′′ ∈B.

q-Analogs of Designs: Subspace Designs
197
5
Inﬁnite Series of Subspace Designs
5.1
On Suzuki’s Construction
In 1987 Thomas [17] constructed the ﬁrst nontrivial simple t-subspace designs for
t = 2. More precisely, for all v ≥7 with (v, 4!) = 1 a Singer-invariant 2-(v, 3, 7)2
design was constructed.
Suzuki [18, 19] extended Thomas’ family using the following construction: For
any natural number r ≥2 we deﬁne the following map:
Lr :
V
2

→L (V ),
T →⟨b0 · b1 · . . . · br−1 | {b0, . . . , br−1} ⊂T ⟩.
The image of Lr is the set of blocks
Br :=

Lr(T ) | T ∈
V
2

.
Suzuki proved that for (v, (2r)!) = 1 the mapping T →Lr(T ) deﬁnes an embedding
from
V
2

into
 V
r+1

implying #Br =
v
2

q. Furthermore, if Br becomes a 2-(v,r +
1, λ)q design it has to satisfy λ =
r+1
2

q. For r = 2, Suzuki could prove that B2
deﬁnes a design. In addition, Abe and Yoshiara [58] determined a nontrivial group
of automorphisms of Suzuki’s design.
Theorem 11 (Suzuki, Abe, Yoshiara) For any prime power q and any integer v ≥7
satisfying (v, 4!) = 1 the set B2 of blocks deﬁnes an N(v, q)-invariant 2-(v, 3, q2 +
q + 1)q design.
Abe and Yoshiara also tried to generalize Suzuki’s construction to values r > 2.
But so far, computer experiments for q = 2 and small parameters failed for r ≥3.
The only exception is the case v = 7 and r = 3 which yields a 2-(7, 4, 35)2 design
B3, the dual design to Thomas’ 2-(7, 3, 7)2 design.
5.2
On Itoh’s Construction
In 1998 Itoh [59] gave a construction of a 2-(ℓm, 3, λ)q design invariant under the
special linear group G = SL(m, qℓ) ≤GL(ℓm, q) for all m ≥3, assuming the exis-
tence of certain S(ℓ, q)-invariant 2-(ℓ, 3, λ)q designs.
The major step Itoh did was the examination of the matrix AG
2,3. The structure
of this matrix turned out to be of the following shape consisting of four blocks of
columns

198
M. Braun et al.
ASL(m,qℓ)
2,3
=
⎡
⎢⎢⎣
a
0
AS(ℓ,q)
2,3
...
0
0
0
a
0
X
Y
Z
⎤
⎥⎥⎦,
where X, Y, Z are submatrices with exactly one row deﬁned by
X =

(q + 1)2, . . . , (q + 1)2, q + 1

, if 2 | ℓ;

(q + 1)2, . . . , (q + 1)2
,
else,
Y =

q(q + 1)(q3 −1), . . . , q(q + 1)(q3 −1), q(q2 −1)

, if 3 | ℓ;

q(q + 1)(q3 −1), . . . , q(q + 1)(q3 −1)

,
else,
Z =

q2ℓ−2, . . . , q2ℓ−2
, if m = 3;

q2ℓ−2 q(m−2)ℓ−1
q−1

,
if m > 3.
Additionally, we have a = qℓ−2(q(m−1)ℓ−1)/(q −1).
Now, the following extension result is immediate from inspection of the matrix. If
we have a selection of columns of AS(ℓ,q)
2,3
with constant row sum we can extend this
to a selection of columns of AG
2,3 with constant row sum by taking the right amount
of columns of the third block of columns.
Lemma 7 (Itoh) If there exists a S(ℓ, q)-invariant 2-(ℓ, 3, λ)q design with
λ = q(q + 1)(q3 −1)s + q(q2 −1)t
for some integer s ≥0 and
t ∈

{0, 1}, if 3 | ℓ;
{0},
else,
then there exists an SL(m, qℓ)-invariant 2-(ℓm, 3, λ)q design.
Moreover, Itoh noticed that this lemma is also true for the GL(m, qℓ) action. There-
fore S(ℓ, q)-invariant designs also imply families of GL(m, qℓ)-invariant designs.
Since the publication of Itoh’s paper several S(v, q)-invariant subspace designs
with index values λ of the required form for Itoh’s lemma have been constructed by
computer. These are listed in the sequel.
In the binary case we need a 2-(ℓ, 3, λ)q design with index
λ = 2(2 + 1)(23 −1)s + 2(22 −1)t = 42s + 6t
and over the ternary ﬁeld we need
λ = 3(3 + 1)(33 −1)s + 3(32 −1)t = 312s + 24t,

q-Analogs of Designs: Subspace Designs
199
Table 5 Simple subspace designs from Itoh’s lemma
t-(v, k, λ)q
Parameters
Group of automorphisms
2-(8m, 3, 42)2
m ≥3
SL(m, 28)
2-(9m, 3, 42s)2
m ≥3, 1 ≤s ≤2
SL(m, 29)
2-(10m, 3, 210)2
m ≥3
SL(m, 210)
2-(13m, 3, 42s)2
m ≥3, 1 ≤s ≤2
SL(m, 213)
2-(8m, 3, 312)2
m ≥3
SL(m, 38)
where in both cases s ≥0 and t is 0 or 1 if ℓis divisible by 3 or t is 0 otherwise.
All of the following given groups of automorphisms of the corresponding
2-(ℓ, 3, λ)q designs contain the Singer cycle group S(ℓ, q) as subgroup and therefore
the designs also admit this group as group of automorphisms.
• In [60] three disjoint N(8, 2)-invariant 2-(8, 3, 21)2 designs are given. Combining
two of them yields an N(8, 2)-invariant design of the supplementary parameters
2-(8, 3, 42)2.
• In Table1 there are N(3, 23)-invariant 2-(9, 3, λ)2 designs. The supplementary
design of the 2-(9, 3, 43)2 design has parameters 2-(9, 3, 42 · 2)2.
• Also in Table1 there is an N(10, 2)-invariant 2-(10, 3, 45)2 design. The supple-
mentary design has parameters 2-(10, 3, 42 · 5)2.
• In Table2 there is a N(8, 3)-invariant 2-(8, 3, 52)3 design. The supplementary
design is has the parameters 2-(8, 3, 312)3.
• There exist at least 586 pairwise disjoint N(13, 2)-invariant subspace designs with
parameters 2-(13, 3, 1)2 [44]. The union of these designs yields 2-(13, 3, 42s)2
designs for 1 ≤s ≤13.
By Itoh’s Lemma 7 these designs turn immediately into new families of inﬁnite
series [43] (Table5).
6
q-Analogs of Steiner Systems
Among subspace designs the case λ = 1 is of particular interest. Such a design is
called q-Steiner system. For t = 1, the existence of q-Steiner systems is already
answered by Lemma 4, such designs are called spreads.
It was a long standing open question whether q-Steiner systems exist at all for t ≥
2. There was already the conjecture that such structures do not exist [61]. Especially,
the smallest nontrivial set parameters 2-(7, 3, 1)2 (an STS(7)q) attracted quite a lot
of interest.

200
M. Braun et al.
6.1
q-Steiner Systems in Dimension 13
While the existence of a q-analog of the Fano plane is still undecided, meanwhile
the ﬁrst q-Steiner system for t ≥2 has been found, namely an S(2, 3, 13)2, see [44].
For the construction, the authors used the method of Kramer and Mesner. They
prescribed the normalizer N(13, 2) of a Singer subgroup of Aut(L (V )) as a group of
automorphisms. The group order is 106 483 and the Kramer-Mesner matrix AN(13,2)
2,3
has size 105 × 30 705.
With the algorithm dancing links by Knuth [62] meanwhile 1316 mutually disjoint
solutions have been determined [47]. That is, among 1 ≤λ ≤1316 mutually disjoint
designs, no block appears twice. Therefore, the union of their block sets gives a 2-
(13, 3, λ)2 design.
Together with their supplementary designs and noting that λmax = 2047, this
implies that all possible design parameters
2-(13, 3, λ)2,
1 ≤λ ≤2047,
are realizable.
6.2
q-Analog of the Fano Plane
Arguably, one of the most tantalizing open problems in this ﬁeld is the question for
the existence of a q-analog of the Fano plane which was asked already in 1972 by
Ray-Chaudhuri [14]. Its existence is still open over any ﬁnite base ﬁeld Fq. The most
important single case is the binary case q = 2, as it is the smallest one. Nonetheless,
so far the binary q-analog of the Fano plane has withstood all computational or
theoretical attempts for its construction or refutation.
Following the approach for other notorious putative combinatorial objects as, e.g.,
a projective plane of order 10 or a self-dual binary [72, 36, 16] code, the possible
automorphisms of a binary q-analog of the Fano plane have been investigated in [63,
64]. As a result, its automorphism group is at most of order 2.
For the groups of order 2, the above result was achieved as a special case of a more
general result on restrictions of the automorphisms of order 2 of a binary q-analog
of Steiner triple systems [63, Theorem 2].
Finally, the combination of the results of [63, 64] yields
Theorem 12 The automorphism group of a binary q-analog of the Fano plane is
either trivial or of order 2. In the latter case, up to conjugacy in GL(7, 2) the auto-
morphism group is represented by
"⎛
⎜⎝
0 1 0 0 0 0 0
1 0 0 0 0 0 0
0 0 0 1 0 0 0
0 0 1 0 0 0 0
0 0 0 0 0 1 0
0 0 0 0 1 0 0
0 0 0 0 0 0 1
⎞
⎟⎠
#
.

q-Analogs of Designs: Subspace Designs
201
7
“Large Sets” of Subspace Designs
In 1861 Sylvester [65] asked if it is possible to partition the set of 455 3-subsets
on 15 points into 13 resolvable 2-(15, 3, 1) designs. His question was answered
afﬁrmatively by Denniston [66] as late as in 1974. Later on, a partition of the k-subsets
into disjoint (combinatorial) t-(v, k, λ) designs was sometimes called packing. In the
1970s the term large set of disjoint designs evolved, nowadays such a partition into
designs is simply called a large set of designs.
In the q-analog situation, a large set of subspace designs—denoted by
LSq[N](t, k, n)—is a partition of the whole set
V
k

of all k-dimensional subspaces of
V into N disjoint t-(v, k, λ)q designs. Obviously, the complete t-(v, k, λmax)q design
forms an LSq[N](t, k, v) large set for N = 1 which is called trivial.
The parameter N determines the index λ, since it must be
λ · N =
v −t
k −t

= λmax .
If N = 2 we speak of a halving.
As for subspace designs, we call a set of parameters LSq[N](t, k, v) admissible
if the parameters are admissible, i.e. if N divides λmax and if the design parameters
t-(v, k, λmax/N)q are admissible. Using the second equation in Lemma 3 it is easy
to see that this is equivalent to
v −s
k −s

q
≡0
(mod N) for 0 ≤s ≤t.
If a large set with this parameters exists, it is called realizable (Fig.3).
Many results for subspace designs also hold true for their large sets. The following
results are from [25, 46].
Lemma 8 If LSq[N](t, k, v) is realizable, then for each divisor d | N, the parame-
ters LSq[d](t, k, v) are realizable, too.
Lemma 9 If there exists an LSq[N](t, k, v) for t ≥1 then there exists
(a) the dual large set LSq[N](t, v −k, v);
(b) the reduced large set LSq[N](t −1, k, v);
(c) the derived large set LSq[N](t −1, k −1, v −1);
(d) a residual large set LSq[N](t −1, k, v −1).
Lemma 10 ([25, Corollary 4]) If there exists an LSq[N](t, k −1, v −1) and an
LSq[N](t, k, v −1), then there exists an LSq(t, k, v).
A group G ≤Aut(L (V )) is called the automorphism group of the large set
{D1, D2, . . . , DN} if
G = Aut(L (V )){D1,D2,...,D N }

202
M. Braun et al.
Fig. 3 An LS2[7](1, 2, 4) in the subspace lattice of F4
2
Table 6 Known parallelisms, given by their subspace design parameters
t-(v, k, λ)
Constraints
Source
1-(2i, 2, 1)q
i ≥2
Denniston [69], Beutelspacher [69]
1-(v, 2, 1)q
v ≥3 odd
Baker [70], Wettl [71]
1-(6, 2, 1)3
Etzion, Vardy [72]
1-(6, 3, 1)2
Hishida, Jimbo [73], Sarmiento [74]
A large set {D1, D2, . . . , DN} is said to be uniformly-G if the designs D1, D2, . . .,
DN are G-invariant.
For ordinary combinatorial t-designs, large sets with t = 1 exist if and only if k
divides v [67]. In the q-analog case, this question is wide open, as it includes the
question for the existence of parallelisms in projective geometries: A large set of
1-(v, k, 1)q designs (i.e. spreads) is known as a (k −1)-parallelism of the projective
geometry PG(v −1, q). By admissibility, necessarily k | v. To our knowledge, the
only known existence results are the following: If v ≥2 is a power of 2, then all 1-
parallelisms do exist [68, 69]. Furthermore, for q = 2 and v even, all 1-parallelisms
do exist [70, 71]. In [72], a 1-parallelism of PG(5, 3) is given. The only known
parallelism for k ≥3 is a 2-parallelism of PG(5, 2) [73, 74] (Table6).

q-Analogs of Designs: Subspace Designs
203
Chapter “Computational Methods in Subspace Designs” contains a summary of
methods how to construct large sets of subspace designs by computer. For the time
being, there are not many examples for t ≥2 where this succeeded.
In [37] a 2-(6, 3, 20)3 design and in [46] a 2-(6, 3, 78)5 design has been presented
which were detected by computer search. In both cases, the supplementary designs
have exactly the same parameters. Thus, the design and it’s supplementary designs
form a large set for N = 2.
In [60] an LS2[3](2, 3, 8) was constructed. It is the ﬁrst large set with t ≥2 and
N ≥3. More large sets with the same parameters were constructed in [75]. Later on,
in [41] an LS2[3](2, 4, 8) was presented (Table7).
Table8 contains the complete listing of these few large sets found by computer.
7.1
Inﬁnite Series of Large Sets
BasedonideasofTeirlinck[76],Ajoodani-NaminiandKhosrovshahihavedeveloped
a rich framework of recursive constructions of large sets of combinatorial designs
[77–79]. For a survey see [80]. Recently, a q-analog version of parts of this theory
was found [46]. The basic idea is to decompose the Graßmannian into joins of
smaller large sets. In this way, given a suitable set of starting large sets, an inﬁnite
series of large sets with increasing values of v and k and constant values of N and t.
Principally, the method can be applied in a variety of situations. The problem is the
current shortage of starting large sets on which the recursion can be founded.
As a detailed description of this theory is beyond the scope for this chapter, we
conﬁne ourselves to the presentation of the newly constructed large sets (and thus,
subspace designs). The following theorems were tailored to ﬁt the ﬁve known large
sets from Table8.
Theorem 13 ([46, Theorem 6.4, Corollary 6.6]) If there exists an LSq[N](2, 3, 6),
then there exists an LSq[N](2, k, v) for all integers v and k with v ≥6, v ≡2
(mod 4), 3 ≤k ≤v −3 and k ≡3 (mod 4). In particular, all these large sets exist
for q ∈{3, 5} and N = 2.
An overview of the resulting large sets is given in Table9.
Theorem 14 Let q and N such that there exist large sets with parameters
LS2[N](2, 3, 8) and LS2[N](2, 4, 8). Let v and k be integers with v ≥8 and
0 ≤k ≤v such that
(a) v ≡2 mod 6 and k ≡3, 4, 5 mod 6 or
(b) v ≡3 mod 6 and k ≡4, 5 mod 6 or
(c) v ≡4 mod 6 and k ≡5 mod 6.

204
M. Braun et al.
Table 7 Admissible large set parameters for small values. All possible values of N > 1 are given
in brackets. Additionally, the design parameters for the largest given value of N is listed. Large set
parameters which are known to be are realizable are printed in boldface
LSq[N](t, k, v)
t-(v, k, λ)
LS2[5](2, 3, 6)
2-(6, 3, 3)2
LS2[31](2, 3, 7)
2-(7, 3, 1)2
LS2[3](2, 3, 8)
2-(8, 3, 21)2
LS2[3, 31, 93](2, 4, 8)
2-(8, 4, 7)2
LS2[31](3, 4, 8)
3-(8, 4, 1)2
LS2[127](2, 3, 9)
2-(9, 3, 1)2
LS2[3, 127, 381](2, 4, 9)
2-(9, 4, 7)2
LS2[3](3, 4, 9)
3-(9, 4, 21)2
LS2[5, 17, 85](2, 3, 10)
2-(10, 3, 3)2
LS2[17, 127, 2159](2, 4, 10)
2-(10, 4, 5)2
LS2[127](3, 4, 10)
3-(10, 4, 1)2
LS2[73](2, 3, 11)
2-(11, 3, 7)2
LS2[17, 73, 1241](2, 4, 11)
2-(11, 4, 35)2
LS2[17](3, 4, 11)
3-(11, 4, 15)2
LS2[11, 31, 341](2, 3, 12)
2-(12, 3, 3)2
LS2[11, 31, 73, 341, 803, 2263, 24893](2, 4, 12)
2-(12, 4, 7)2
LS2[73](3, 4, 12)
3-(12, 4, 7)2
LS2[23, 89, 2047](2, 3, 13)
2-(13, 3, 1)2
LS3[2, 5, 10](2, 3, 6)
2-(6, 3, 4)3
LS3[11, 121](2, 3, 7)
2-(7, 3, 1)3
LS3[7](2, 3, 8)
2-(8, 3, 52)3
LS3[7, 11, 77, 121, 847](2, 4, 8)
2-(8, 4, 13)3
LS3[11, 121](3, 4, 8)
3-(8, 4, 1)3
LS4[17](2, 3, 6)
2-(6, 3, 5)4
LS4[11, 31, 341](2, 3, 7)
2-(7, 3, 1)4
LS4[13](2, 3, 8)
2-(8, 3, 105)4
LS4[11, 13, 31, . . . , 4433](2, 4, 8)
2-(8, 4, 21)4
LS5[2, 13, 26](2, 3, 6)
2-(6, 3, 6)5
LS5[11, 71, 781](2, 3, 7)
2-(7, 3, 1)5
LS5[3, 7, 21](2, 3, 8)
2-(8, 3, 186)5
LS5[7, 11, . . . , 71, . . . , 16401](2, 4, 8)
2-(8, 4, 31)5

q-Analogs of Designs: Subspace Designs
205
Table 8 Large sets of simple subspace designs by computer construction
LS[N]q(t, k, v)
G
#AG
t,k
LS[2]3(2, 3, 6)
⟨σ 2, F2⟩
25 × 76
LS[2]3(2, 3, 6)
S(5, 3) × 1
51 × 150
LS[2]5(2, 3, 6)
N(6, 5)
53 × 248
LS[3]2(2, 3, 8)
S(8, 2)
43 × 381
LS[3]2(2, 4, 8)
⟨σ 5, F2⟩
69 × 1061
Then there exists an LSq[N](2, k, v). In particular, all these large sets exist for q = 2
and N = 3.
An overview of the resulting large sets is given in Table10.
8
Open Problems
The subject of subspace designs is still in its infancy and there are many questions
which wait for an answer, see [81, 82]. The most tantalizing open problems seem to
be:
• Is there a q-analog of the Fano plane? (subspace design with the parameters 2-
(7, 3, 1)q)
• Is there a geometric or algebraic description of the 2-(13, 3, 1)2 designs?
• Find more q-analogs of Steiner systems!
• Find a concrete construction of a subspace design with t ≥4!
• Do q-Steiner systems exist for all t, i.e. is there a q-analog of Keevash’ theo-
rem [52]?
• Are the parameters 2-(7, 3, 2)2 realizable?
• Is LS2[5](2, 3, 6) realizable?
• Are the halvings LSq[2](2, 3, 6) realizable for odd q > 5?
• For combinatorial designs, the halving conjecture states that all admissible designs
with λ = λmax/2 (i.e., halvings LS[2](t, k, v)q) are realizable [83, Sect.5]. For
t = 2, the conjecture has been proven in [84]. Can anything be said about this
conjecture in the q-analog case?

206
M. Braun et al.
Table 9 Admissibility and realizability of LSq[2](2, k, v) for q ∈{3, 5}. An integer value k means
LS2[3](2, k, v) is realizable for these k, v. “-” means the parameter set is not admissible, and “?”
means the parameter set is admissible but not known to be realizable
v
k
3
6
-
7
-
-
8
-
-
9
3
?
?
10
-
?
?
11
-
-
?
?
12
-
-
-
?
13
3
-
-
-
7
14
-
-
-
-
-
15
-
-
-
-
-
-
16
-
-
-
-
-
-
17
3
?
?
?
7
?
?
18
-
?
?
?
?
?
?
19
-
-
?
?
?
?
?
?
20
-
-
-
?
?
?
?
?
21
3
-
-
-
7
?
?
?
11
22
-
-
-
-
-
?
?
?
?
23
-
-
-
-
-
-
?
?
?
?
24
-
-
-
-
-
-
-
?
?
?
25
3
?
?
?
7
-
-
-
11
?
?
26
-
?
?
?
?
-
-
-
-
?
?
27
-
-
?
?
?
-
-
-
-
-
?
?
28
-
-
-
?
?
-
-
-
-
-
-
?
29
3
-
-
-
7
-
-
-
11
-
-
-
15
30
-
-
-
-
-
-
-
-
-
-
-
-
-
31
-
-
-
-
-
-
-
-
-
-
-
-
-
-
32
-
-
-
-
-
-
-
-
-
-
-
-
-
-
33
3
?
?
?
7
?
?
?
11
?
?
?
15
?
?
34
-
?
?
?
?
?
?
?
?
?
?
?
?
?
?
35
-
-
?
?
?
?
?
?
?
?
?
?
?
?
?
?
36
-
-
-
?
?
?
?
?
?
?
?
?
?
?
?
?
37
3
-
-
-
7
?
?
?
11
?
?
?
15
?
?
?
19
38

q-Analogs of Designs: Subspace Designs
207
Table 10 Admissibility and realizability of LS2[3](2, k, v). An integer value k means
LS2[3](2, k, v) is realizable for these k, v. “-” means the parameter set is not admissible, and
“?” means the parameter set is admissible but not known to be realizable
v
k
-
6
-
7
3
4
8
-
4
9
-
-
5
10
-
-
-
11
-
-
-
-
12
-
-
-
-
13
3
4
5
-
-
14
-
4
5
-
-
15
-
-
5
-
-
-
16
-
-
-
-
-
-
17
-
-
-
-
-
-
-
18
-
-
-
-
-
-
-
19
3
4
5
?
?
?
9
10
20
-
4
5
?
?
?
?
10
21
-
-
5
?
?
?
?
?
11
22
-
-
-
?
?
?
?
?
?
23
-
-
-
-
?
?
?
?
?
?
24
-
-
-
-
-
?
?
?
?
?
25
3
4
5
-
-
-
9
10
11
?
?
26
-
4
5
-
-
-
-
10
11
?
?
27
-
-
5
-
-
-
-
-
11
?
?
?
28
-
-
-
-
-
-
-
-
-
?
?
?
29
-
-
-
-
-
-
-
-
-
-
?
?
?
30
-
-
-
-
-
-
-
-
-
-
-
?
?
31
3
4
5
-
-
-
9
10
11
-
-
-
15
16
32
-
4
5
-
-
-
-
10
11
-
-
-
-
16
33
-
-
5
-
-
-
-
-
11
-
-
-
-
-
17
34
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
35
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
36
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
37
3
4
5
?
?
?
9
10
11
?
?
?
15
16
17
-
-
38
-
4
5
?
?
?
?
10
11
?
?
?
?
16
17
-
-
39
-
-
5
?
?
?
?
?
11
?
?
?
?
?
17
-
-
-
40

208
M. Braun et al.
References
1. J. Tits, Sur les analogues algébriques des groupes semi-simples complexes, in Colloque
d’algèbre supérieure, tenu à Bruxelles du 19 au 22 décembre 1956, Centre Belge de Recherches
Mathématiques (Établissements Ceuterick, Louvain; Librairie Gauthier-Villars, Paris 1957),
pp. 261–289
2. T. Beth, D. Jungnickel, H. Lenz, Design Theory, 2nd edn. (Cambridge University Press, Cam-
bridge, 1999)
3. C.J. Colbourn, J.H. Dinitz, Handbook of Combinatorial Designs, 2nd edn., Discrete Mathe-
matics and Its Applications (Chapman & Hall/CRC, Boca Raton, 2006)
4. M. Schwartz, T. Etzion, Codes and anticodes in the Grassman graph. J. Comb. Theory Ser. A
97(1), 27–42 (2002). https://doi.org/10.1006/jcta.2001.3188
5. G, Birkhoff, Lattice theory, Colloquium Publications, vol 25, 3rd edn. American Mathematical
Society (1967)
6. R.P. Stanley, Enumerative Combinatorics, 2nd edn., Cambridge Studies in Advanced Math-
ematics, vol. 1 (Cambridge University Press, Cambridge, 2012). https://doi.org/10.1017/
CBO9781139058520
7. E. Artin, Geometric Algebra (Wiley classics library, Interscience Publishers Inc., New York,
1988). https://doi.org/10.1002/9781118164518.ch1
8. R.D. Fray, Congruence properties of ordinary and q-binomial coefﬁcients. Duke Math. J. 34(3),
467–480 (1967). https://doi.org/10.1215/S0012-7094-67-03452-7
9. F.H. Jackson, q-difference equations. Am. J. Math. 32(3), 305–314 (1910). https://doi.org/10.
2307/2370183
10. M. Ward, A calculus of sequences. Am. J. Math. 58(2), 255–266 (1936). https://doi.org/10.
2307/2371035
11. H. Cohn, Projective geometry over F1 and the Gaussian binomial coefﬁcients. Am. Math. Mon.
111(6), 487–495 (2004). https://doi.org/10.2307/4145067
12. J. Goldman, G.C. Rota, On the foundations of combinatorial theory IV ﬁnite vector spaces and
Eulerian generating functions. Stud. Appl. Math. 49(3), 239–258 (1970)
13. G. Pólya, G. Alexanderson, Gaussian binomial coefﬁcients. Elem. Math. 26, 102–109 (1971),
http://eudml.org/doc/1410
14. C. Berge, D. Ray-Chaudhuri, Unsolved problems, in Hypergraph Seminar: Ohio State Uni-
versity 1972, Lecture Notes in Mathematics, ed. by C. Berge, D. Ray-Chaudhuri (Springer,
Berlin, 1974), pp. 278–287. https://doi.org/10.1007/BFb0066199
15. P.J. Cameron, Generalisation of Fisher’s inequality to ﬁelds with more than one element, in
Combinatorics - Proceedings of the British Combinatorial Conference 1973, London Mathe-
matical Society Lecture Note Series, ed. by T.P. McDonough, V.C. Mavron (Cambridge Uni-
versity Press, Cambridge, 1974), pp. 9–13. https://doi.org/10.1017/CBO9780511662072.003
16. P. Delsarte, Association schemes and t-designs in regular semilattices. J. Comb. Theory Ser.
A 20(2), 230–243 (1976). https://doi.org/10.1016/0097-3165(76)90017-0
17. S. Thomas, Designs over ﬁnite ﬁelds. Geom. Dedicata 24(2), 237–242 (1987). https://doi.org/
10.1007/BF00150939
18. H. Suzuki, 2-designs over GF(2m). Graphs Comb. 6(3), 293–296 (1990). https://doi.org/10.
1007/BF01787580
19. H. Suzuki, 2-designs over GF(q). Graphs Comb. 8(4), 381–389 (1992). https://doi.org/10.
1007/BF02351594
20. M. Braun, A. Kerber, R. Laue, Systematic construction of q-analogs of t-(v, k, λ)-designs.
Des. Codes Cryptogr. 34(1), 55–70 (2005). https://doi.org/10.1007/s10623-003-4194-z
21. H. Suzuki, On the inequalities of t-designs over a ﬁnite ﬁeld. Eur. J. Comb. 11(6), 601–607
(1990). https://doi.org/10.1016/S0195-6698(13)80045-5
22. B. Segre, Teoria di galois, ﬁbrazioni proiettive e geometrie non desarguesiane. Ann. Mat. Pura
Appl. 4 64(1), 1–76 (1964). https://doi.org/10.1007/BF02410047
23. J. André, Über nicht-Desarguessche Ebenen mit transitiver Translationsgruppe. Math. Z. 60(1),
156–186 (1954). https://doi.org/10.1007/BF01187370

q-Analogs of Designs: Subspace Designs
209
24. D.K. Ray-Chaudhuri, R.M. Wilson, On t-designs. Osaka J. Math. 12(3), 737–744 (1975)
25. M. Kiermaier, R. Laue, Derived and residual subspace designs. Adv. Math. Commun. 9(1),
105–115 (2015). https://doi.org/10.3934/amc.2015.9.105
26. T.V. Trung, On the construction of t-designs and the existence of some new inﬁnite families of
simple 5-designs. Arch. Math. 47(2), 187–192 (1986). https://doi.org/10.1007/BF01193690
27. D.C. van Leijenhorst, Orbits on the projective line. J. Comb. Theory Ser. A 31(2), 146–154
(1981). https://doi.org/10.1016/0097-3165(81)90011-X
28. L.M.H.E. Driessen, t-designs, t ≥3, Technical Report, Technische Universiteit Eindhoven,
1978
29. N.S. Mendelsohn, Intersection numbers of t-designs, in Studies in Pure Mathematics, ed. by
L. Mirsky (Academic Press, London, 1971), pp. 145–150
30. W. Oberschelp, Lotto-Garantiesysteme und Blockpläne. Math.-Phys. Semesterber. 19, 55–67
(1972)
31. M. Kiermaier, M.O. Pavˇcevi´c, Intersection numbers for subspace designs. J. Comb. Des. 23(11),
463–480 (2015). https://doi.org/10.1002/jcd.21403
32. E. Köhler, Allgemeine Schnittzahlen in t-Designs. Discret. Math. 73(1–2), 133–142 (1988–
1989). https://doi.org/10.1016/0012-365X(88)90141-0
33. S. Thomas, Designs and partial geometries over ﬁnite ﬁelds. Geom. Dedicata 63, 247–253
(1996)
34. A. Kerber, Applied Finite Group Actions, Algorithms and Combinatorics, vol 19 (Springer,
Berlin, 1999). https://doi.org/10.1007/978-3-662-11167-3
35. E.S. Kramer, D.M. Mesner, t-designs on hypergraphs. Discret. Math. 15(3), 263–296 (1976).
https://doi.org/10.1016/0012-365X(76)90030-3
36. B. Huppert, I. Endliche Gruppen, Grundlehren der Mathematischen Wissenschaften (Springer,
Berlin, 1967), http://opac.inria.fr/record=b1108495
37. M. Braun, Some new designs over ﬁnite ﬁelds. Bayreuth. Math. Schr. 74, 58–68 (2005)
38. M. Miyakawa, A. Munemasa, S. Yoshiara, On a class of small 2-designs over GF(q). J. Comb.
Des. 3(1), 61–77 (1995). https://doi.org/10.1002/jcd.3180030108
39. S, Braun, Construction of q-analogs of combinatorial designs, Presentation at the conference
Algebraic Combinatorics and Applications (ALCOMA10). (Thurnau, Germany, 2010)
40. S, Braun, Algorithmen zur computerunterstützten Berechnung von q-Analoga kombina-
torischer Designs. Diplomathesis Universität Bayreuth (2009)
41. M. Kiermaier, R. Laue, A. Wassermann, A new series of large sets of subspace designs over
the binary ﬁeld. Des. Codes Cryptogr. (2016). https://doi.org/10.1007/s10623-017-0349-1
42. M. Braun, New 3-designs over the binary ﬁeld. Int. Electron. J. Geom. 6(2), 79–87 (2013)
43. M. Braun, New inﬁnite series of 2-designs over the binary and ternary ﬁeld. Des. Codes
Cryptogr. 81(1), 145–152 (2016). https://doi.org/10.1007/s10623-015-0133-z
44. M. Braun, T. Etzion, P.R.J. Östergård, A. Vardy, A. Wassermann, Existence of q-analogs of
Steiner systems. Forum Math. 4(7), (2016). https://doi.org/10.1017/fmp.2016.5
45. M. Braun, Designs over the binary ﬁeld from the complete monomial group. Australas. J.
Comb. 67(3), 470–475 (2017)
46. M. Braun, M. Kiermaier, A. Kohnert, R. Laue, Large sets of subspace designs. J. Comb. Theory
Ser. A 147, 155–185 (2017). https://doi.org/10.1016/j.jcta.2016.11.004
47. M. Braun, A. Wassermann, Disjoint q-Steiner systems in dimension 13, Universität Bayreuth,
Bayreuth, Technical Report, 2017
48. H. Suzuki, Five days introduction to the theory of designs (1989), http://subsite.icu.ac.jp/
people/hsuzuki/lecturenote/designtheory.pdf
49. P.J. Cameron, Locally symmetric designs. Geom. Dedicata 3, 65–76 (1974)
50. D. Ray-Chaudhuri, N. Singhi, q-analogues of t-designs and their existence. Linear Algebra
Appl. 114–115, 57–68 (1989). https://doi.org/10.1016/0024-3795(89)90451-5
51. R.M. Wilson, The necessary conditions for t-designs are sufﬁcient for something. Util. Math
4, 207–215 (1973)
52. P. Keevash, The existence of designs. arXiv identiﬁer 1401.3665 (2014)

210
M. Braun et al.
53. V. Guruswami, S. Kopparty, Explicit subspace designs, in 2013 IEEE 54th Annual Sympo-
sium on Foundations of Computer Science, pp. 608–617 (2013). https://doi.org/10.1109/FOCS.
2013.71
54. V. Guruswami, C. Xing, List decoding Reed-Solomon, algebraic-geometric, and Gabidulin
subcodes up to the singleton bound, in Proceedings of the Forty-ﬁfth Annual ACM Symposium
on Theory of Computing, STOC ’13 (ACM, New York, NY, USA, 2013), pp. 843–852. https://
doi.org/10.1145/2488608.2488715
55. L. Teirlinck, Non-trivial t-designs without repeated blocks exist for all t. Discret. Math. 65(3),
301–311 (1987). https://doi.org/10.1016/0012-365X(87)90061-6
56. A. Fazeli, S. Lovett, A. Vardy, Nontrivial t-designs over ﬁnite ﬁelds exist for all t. J. Comb.
Theory Ser. A 127, 149–160 (2014)
57. P. Frankl, V. Rödl, Near perfect coverings in graphs and hypergraphs. Eur. J. Comb. 6(4),
317–326 (1985)
58. T. Abe, S. Yoshiara, On Suzuki’s construction of 2-designs over GF(q). Sci. Rep. Hirosaki
Univ. 10, 119–122 (1993)
59. T. Itoh, A new family of 2-designs over GF(q) admitting SLm(ql). Geom. Dedicata 69(3),
261–286 (1998). https://doi.org/10.1023/A:1005057610394
60. M. Braun, A. Kohnert, P.R.J. Östergård, A. Wassermann, Large sets of t-designs over ﬁnite
ﬁelds. J. Comb. Theory Ser. A 124, 195–202 (2014). https://doi.org/10.1016/j.jcta.2014.01.
008
61. K. Metsch, Bose–Burton Type Theorems for Finite Projective, Afﬁne and Polar Spaces, in
Surveys in Combinatorics, Lecture Notes Series, ed. by Lamb, Preece (London Mathematical
Society, 1999)
62. D.E. Knuth, Dancing links, in Millennial Perspectives in Computer Science, Cornerstones of
Computing, ed. by A.W. Roscoe, J. Davies, J. Woodcock (Palgrave, 2000), pp. 187–214
63. M. Braun, M. Kiermaier, A. Naki´c, On the automorphism group of a binary q-analog of the
Fano plane. Eur. J. Comb. 51, 443–457 (2016). https://doi.org/10.1016/j.ejc.2015.07.014
64. M. Kiermaier, S. Kurz, A. Wassermann, The order of the automorphism group of a binary
q-analog of the fano plane is at most two. Des. Codes Cryptogr. (2017). https://doi.org/10.
1007/s10623-017-0360-6
65. J.J.Sylvester,Noteonthehistoricaloriginoftheunsymmetricalsixvaluedfunctionofsixletters.
Philos. Mag. Ser. 4 21(141), 369–377 (1861). https://doi.org/10.1080/14786446108643072
66. R.H. Denniston, Sylvester’s problem of the 15 schoolgirls. Discret. Math. 9(3), 229–233 (1974).
https://doi.org/10.1016/0012-365X(74)90004-1
67. Z. Baranyai, On the factorization of the complete uniform hypergraph, in Inﬁnite and ﬁnite
Sets, Colloquia Mathematica Societatis János Bolyai, vol. 1, ed. by A. Hajnal, R. Rado, V.T.
Sós (Bolyai János Matematikai Társulat and North-Holland, Budapest and Amsterdam, 1975),
pp. 91–107
68. A. Beutelspacher, On parallelisms in ﬁnite projective spaces. Geometriae Dedicata 3(1), 35–40
(1974)
69. R.H.F. Denniston, Some packings of projective spaces. Atti Accad. Naz. Lincei Rend. Cl. Sci.
Fis. Mat. Natur. 52(8), 36–40 (1972)
70. R.D. Baker, Partitioning the planes of AG2m(2) into 2-designs. Discret. Math. 15(3), 205–211
(1976)
71. F. Wettl, On parallelisms of odd dimensional ﬁnite projective spaces. Period. Polytech. Transp.
Eng. 19(1–2), 111 (1991)
72. T. Etzion, A. Vardy, Automorphisms of codes in the Grassmann scheme. arXiv identiﬁer
1210.5724 (2012)
73. T. Hishida, M. Jimbo, Cyclic resolutions of the bib design in PG(5, 2). Australas. J. Comb.
22, 73–79 (2000)
74. J.F. Sarmiento, Resolutions of PG(5, 2) with point-cyclic automorphism group. J. Comb.
Des. 8(1), 2–14 (2000). https://doi.org/10.1002/(SICI)1520-6610(2000)8:1<2::AID-JCD2>3.
0.CO;2-H

q-Analogs of Designs: Subspace Designs
211
75. M.R. Hurley, B.K. Khadka, S.S. Magliveras, Some new large sets of geometric designs of type
[3][2, 3, 28]. J. Algebra Comb. Discret. Struct. Appl. 3(3), 165–176 (2016). https://doi.org/10.
13069/jacodesmath.40139
76. L. Teirlinck, Locally trivial t-designs and t-designs without repeated blocks. Discret. Math.
77(1–3), 345–356 (1989). https://doi.org/10.1016/0012-365X(89)90372-5
77. G. B. Khosrovshahi, S. Ajoodani-Namini, Combining t-designs. JCTSA 58(1), 26–34 (1991).
https://doi.org/10.1016/0097-3165(91)90071-N
78. S. Ajoodani-Namini, Extending large sets of t-designs. J. Comb. Theory Ser. A 76(1), 139–144
(1996). https://doi.org/10.1006/jcta.1996.0093
79. S. Ajoodani-Namini, G. Khosrovashahi, More on halving the complete designs. Discret. Math.
135(1–3), 29–37 (1994). https://doi.org/10.1016/0012-365X(93)E0096-M
80. G.B. Khosrovshahi, B. Tayfeh-Rezaie, Trades and t-designs, Surveys in Combinatorics 2009,
London Mathematical Society Lecture Note Series (Cambridge University Press, Cambridge,
2009), pp. 91–111. https://doi.org/10.1017/CBO9781107325975.005
81. T. Etzion, Problems on q-analogs in coding theory. arXiv identiﬁer 1305.6126 (2013)
82. T. Etzion, L. Storme, Galois geometries and coding theory. Des. Codes Cryptogr. 78(1), 311–
350 (2016). https://doi.org/10.1007/s10623-015-0156-5
83. A. Hartman, Halving the complete design. Ann. Discret. Math. 34, 207–224 (1987). https://
doi.org/10.1016/S0304-0208(08)72888-3
84. S. Ajoodani-Namini, All block designs with b =
v
k

/2 exist. Discret. Math. 179(1–3), 27–35
(1998). https://doi.org/10.1016/S0012-365X(97)00024-1

Computational Methods in Subspace Designs
Michael Braun, Michael Kiermaier and Alfred Wassermann
Abstract Subspace designs are the q-analogs of combinatorial designs. Introduced
in the 1970s, these structures gained a lot of interest recently because of their appli-
cation to random network coding. Compared to combinatorial designs, the number
of blocks of subspace designs are huge even for the smallest instances. Thus, for
a computational approach, sophisticated algorithms are indispensible. This chapter
highlights computational methods for the construction of subspace designs, in par-
ticular methods based on group theory. Starting from tactical decompositions we
present the method of Kramer and Mesner which allows to restrict the search for
subspace designs to those with a prescribed group of automorphisms. This approach
reduces the construction problem to the problem of solving a Diophantine linear
system of equations. With slight modiﬁcations it can also be used to construct large
sets of subspace designs. After a successful search, it is natural to ask if subspace
designs are isomorphic. We give several helpful tools which allow to give answers in
surprisingly many situations, sometimes in a purely theoretical way. Finally, we will
give an overview of algorithms which are suitable to solve the underlying Diophan-
tine linear system of equations. As a companion to chapter “q-Analogs of Designs:
Subspace Designs” this chapter provides an extensive list of groups which were used
to construct subspace designs and large sets of subspace designs.
M. Braun (B)
Faculty of Computer Science, Darmstadt University of Applied Sciences,
64295 Darmstadt, Germany
e-mail: michael.braun@h-da.de
M. Kiermaier · A. Wassermann
Department of Mathematics, University of Bayreuth, 95440 Bayreuth, Germany
e-mail: michael.kiermaier@uni-bayreuth.de
A. Wassermann
e-mail: alfred.wassermann@uni-bayreuth.de
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_9
213

214
M. Braun et al.
1
Introduction
Combinatorial design theory has a long and venerable history starting in the middle
of the 19th century. Combinatorial designs have many applications and there exists
a huge amount of literature. For a comprehensive overview we recommend the two
books [3, 29].
If one replaces in the deﬁnition of a combinatorial design set of points by vector
space and cardinality by dimension one gets the deﬁnition of a subspace design.
Subspace designs, also called q-analogs of designs, designs over ﬁnite ﬁelds,
or designs in vector spaces were introduced in the early 1970s independently by
Ray-Chaudhuri [2], Cameron [25, 26] and Delsarte [31]. While receiving only occa-
sionally attention by relatively few research groups until 10 years ago, the situation
has changed a lot since then. Subspace designs have found much increased interest
now due to the connection to random network coding pointed out by Kötter and
Kschischang [64]. For an in-depth introduction to subspace designs the reader is
referred to chapter “q-Analog of Designs: Subspace Design”.
In terms of random network coding, one is mainly interested in very speciﬁc
subspaces designs, namely q-Steiner systems. The reason is that q-Steiner systems
are the best possible constant-dimension codes for random network coding. To be
precise, they are diameter-perfect constant-dimension codes. This is analog to the
situation in “classical” coding theory, where (combinatorial) Steiner systems are
the best possible constant-weight codes for a given length and minimum distance.
For more information on constant-dimension codes the reader is referred to chapters
“Construction of Constant Dimension Codes” and “Construction of Cyclic Subspace
Codes and Maximum Rank”.
Subspace designs and subspace codes with t = 1 and λ = 1 are better known as
(partial) spreads, which have been studied in ﬁnite geometry since many decades.
However, the ﬁrst subspace design for t ≥2 was found only in 1987 [92], when the
explicit question for their existence has been open for already about 15 years. For
moreinformationongeometricaspectsthereaderisreferredtochapters“Geometrical
Aspects of Subspace Codes” and “Partial Spreads and Vector Space Paritions”.
Systematic computer search for subspace designs started in the 1990s [81]. Since
then, quite a few subspace designs could be constructed, the most prominent being
designs for t = 3 [17] and the ﬁrst q-Steiner systems for t = 2 [16].
In this chapter we will study computational methods to construct subspace designs
andsocalledlargesetsofsubspacedesigns.Foranin-depthstudyofsubspacedesigns
the reader is referred to chapter “q-Analog of Designs: Subspace Designs”. In par-
ticular, chapter “q-Analog of Designs: Subspace Designs” contains comprehensive
tables of all known simple subspace designs for small dimensions and t ≥2.
Much more detailed information on construction and classiﬁcation algorithms of
combinatorial objects can be found in the book by Kaski and Östergård [53] and in
the chapter on computer construction in the Handbook of combinatorial designs [42].

Computational Methods in Subspace Designs
215
2
Preliminaries
This is an overview in compressed form about subspace designs. The deﬁnitions
and results can be found in more details and together with references in chapter
“q-Analogs of Designs:Subspace Design”.
Throughout this chapter, V will be a vector space of ﬁnite dimension v over a
ﬁnite ﬁeld Fq. Subspaces of dimension k will be called k-subspaces. Sometimes,
1-subspaces will be denoted as points. If the dimension k is clear from the context,
k-subspaces will occasionally be called blocks.
For an integer 0 ≤k ≤v the set
V
k

q consisting of all k-subspaces of V is called
Graßmannian. Its cardinality is determined by the q-binomial coefﬁcient
#
V
k

q
=
v
k

q
= (qv −1) · · · (qv−k+1 −1)
(qk −1) · · · (q −1)
.
If clear from the context, we will omit the index q from
V
k

q and
v
k

q for sake of
readability. The q-analog of a combinatorial design is deﬁned as follows.
Deﬁnition 1 Let q be a prime power, V an Fq-vector space of ﬁnite dimension v,
0 ≤t ≤k ≤v integers and λ a non-negative integer. A pair D = (V, B), where B
is a collection of k-subspaces (blocks) of V , is called a t-(v, k, λ)q subspace design
on V if each t-subspace of V is contained in exactly λ blocks.
If B is a set, i.e. if every k-subset appears at most once in B, the design is called
simple.
A t-(v, k, 1)q design is also called S(t, k, v)q q-Steiner system.
If the strict equality conditions #{B ∈B | T ⊂B} = λ for all T ∈
V
t

q in
Deﬁnition1 is relaxed to “≤”, the structure is called packing design, whilst the
relaxation to “≥” is called covering design. Of course, the question is to maximize
(minimize) the number of blocks in a packing (covering) design. From the viewpoint
of random network coding, packing designs with λ = 1 are the same as constant-
dimension subspace codes of minimum subspace distance 2(k −t −1).
If not explicitly stated otherwise, for the rest of the chapter all designs will be
simple designs. The empty set and the full Graßmannian are designs for all values
of 0 ≤t ≤k, called trivial designs. The parameters of the Graßmannian
V
k

q as a
t-design are t-(v, k,
v−t
k−t

q)q. Thus, for ﬁxed values of t, v, k, the largest possible
value for λ is λmax :=
v−t
k−t

q.
Lemma 1 ([91]) Let D = (V, B) be a t-(v, k, λ)q subspace design. For each s ∈
{0, . . . , t}, D is an s-(v, k, λs)q subspace design with
λs =
v−s
t−s

q
k−s
t−s

q
· λ =
v−s
k−s

q
v−t
k−t

q
· λ.

216
M. Braun et al.
In particular, the number of blocks is given by
#B = λ0 = λ ·
v
t

q
/
k
t

q
.
A consequence of this lemma is that every 1-subspace is contained in
λ1 = λ ·
v−1
t−1

q
k−1
t−1

q
blocks of a t-(v, k, λ)q design.
A set t-(v, k, λ)q of design parameters is called admissible if for all 0 ≤s ≤t the
divisibility conditions
v −s
t −s

q
· λ ≡0
(mod
k −s
t −s

q
)
are fulﬁlled. If a t-(v, k, λ)q design exists, the parameters are called realizable.
For ﬁxed t, k, v the divisibility conditions imply a minimum λmin that fulﬁlls the
conditions. It is easy to see that all admissible values of λ are multiples of λmin.
If a t-(v, k, λ)q design is realizable, then also the dual design with parame-
ters t-(v, v −k,
v−t
k

/
v−t
k−t

λ)q and the supplementary design with parameters t-
(v, k, λmax −λ)q are realizable. Therefore, it is usually enough to restrict the search
for designs to 2 ≤k ≤v/2 and 1 ≤λ ≤λmax/2.
A celebrated, recent result by Fazeli, Lovett, and Vardy [36] is that there exist
subspace designs for every value of t and q if the parameters v, k, λ are large enough.
However, their proof is not constructive.
An automorphism of a subspace design D = (V, B) is a bijective mapping g ∈
PL(V ) such that Bg = B. Under the composition of mappings, the set of all
automorphisms of a design forms a group, the automorphism group Aut(D) of the
design D. For every subgroup G of its automorphism group a design is said to be
G-invariant.
The action of PL(V ) on the subspace lattice of V preserves containment, that
is, for all g ∈PL(V ) and all subspaces S, T ≤V ,
S ≤T if and only if Sg ≤T g.
(1)
In particular, for 0 ≤s ≤v and S ∈
V
s

the image Sg is again in
V
s

.
For computational purposes we will restrict ourselves to automorphisms from
GL(V ) which is represented by the group GL(v, q) of all invertible v × v matrices
over Fq, via assigning the map x →xA to the matrix A ∈GL(v, q).
Let G be a group acting on a set X via x →xg. The stabilizer of x in G is given
by Gx = {g ∈G | xg = x}, and the G-orbit of x is given by xG = {xg | g ∈G}. For

Computational Methods in Subspace Designs
217
two elements x, x′ ∈X in the same orbit, we write x ∼x′. Obviously, x ∼x′ if and
only if there exists an element g ∈G with x′ = xg. The relation ∼is an equivalence
relation on X. Therefore, by the action of G, the set X is partitioned into orbits.
For all x ∈X, there is the correspondence xg →Gxg between the orbit xG and the
set Gx\G of the right cosets of the stabilizer Gx in G. For ﬁnite orbit lengths, this
implies the orbit-stabilizer theorem stating that #xG = [G : Gx]. In particular, the
orbit lengths #xG are divisors of the group order #G. The stabilizers of elements in
the same orbit are related by the formula
Gxg = g−1Gxg.
(2)
A partition of the Graßmannian into N disjoint designs with the same parameters
is called large set of designs and denoted by LSq[N](t, k, v). It is clear that
N · λ = λmax.
that is, N has to divide λmax and N determines λ. The large set parameters
LSq[N](t, k, v) are called admissible if
v −s
k −s

q
≡0
(mod N) for 0 ≤s ≤t.
If an LSq[N](t, k, v) exists the parameters are called realizable.
If for a group G ∈PL(v, q) and a large set with parameters LSq[N](t, k, v) all
its designs—having parameters t-(v, k, λmax/N)q—are G-invariant, then the large
set is called uniformly-G.
3
Computer Construction
The computational approaches to construct subspace designs and combinatorial
designs are mostly the same. This is not a big surprise since both, combinatorial
designs and subspace designs, are ﬁnite incidence structures.
The main difference to combinatorial designs is that the cardinalities of the objects
which have to be considered for subspace designs are way larger than for combi-
natorial designs. As a consequence, so far only for comparatively small parameters
subspace designs could be constructed by computer.
Now, the question is how can a computer be instructed to ﬁnd t-(v, k, λ)q designs?
The most naive approach would be the following algorithm.

218
M. Braun et al.
Algorithm 1 Naive algorithm to search for a simple t-(v, k, 1)q design.
B ←∅, T ←
V
t

, T ←∅
success ←true
while success do
Search B ∈
V
k

such that for T ∈T : T ̸⊂B
if B exists:
B ←B ∪{B}
for T ⊂B:
T ←T \ {T }
T ←T ∪{T }
else:
success ←false
end while
return B // return packing design
Thus, this simple, greedy algorithm packs blocks into the design until no more
block can be found that consists solely of t-subspaces which are not covered yet.
Surprisingly enough, an analysis by Frankl and Rödl [40] shows that asymptotically
for v →∞, the set of blocks returned by Algorithm1 is expected to come quite close
to a Steiner system.
Theorem 1 (Frankl and Rödl) Suppose integers t, k are given, 0 < t < k < v. Then
for v →∞Algorithm1 is expected to return a set B ⊂
V
k

such that
#B = (1 −o(1))
v
t

q
/
k
t

q
and dim(K ′ ∩K ′′) < t for all distinct K ′, K ′′ ∈B.
An alternative description of Algorithm1 is the following: We ﬁx an order on all
subspaces T ∈
V
t

and K ∈
V
k

and deﬁne the matrix At,k = (ai, j) by
ai, j =

1,
if Ti ⊂K j;
0,
else.
That is, the matrix At,k is of size
v
t

×
v
k

. Now, if the resulting selection of blocks
in Algorithm1 even forms a q-Steiner system then this selection can be expressed
as a 0/1-vector x of length
v
k

such that
At,k · x =
⎛
⎜⎝
1
...
1
⎞
⎟⎠.
(3)

Computational Methods in Subspace Designs
219
Example 1 For a really small example we look at combinatorial designs instead of
subspace designs. That is, V is a set of points and the blocks are k-element subsets
of V .
In our example we want to cover every vertex (i.e. 1-subset) of the following
graph by exactly one edge (i.e. 2-subset). The result is a 1-(4, 2, 1) (combinatorial)
design.
a
b
c
d
1
2
3
4
5
6
It is easy to see that there are the following three solutions:
a
b
c
d
1
3
a
b
c
d
2
4
a
b
c
d
5
6
The matrix A1,2 together with the three solution vectors x⊤looks as follows.
vertices\edges 1 2 3 4 5 6
a
1 0 0 1 1 0
b
1 1 0 0 0 1
c
0 1 1 0 1 0
d
0 0 1 1 0 1
design1
1 0 1 0 0 0
design2
0 1 0 1 0 0
design3
0 0 0 0 1 1
The three designs consist of the block sets {{a, b}, {c, d}}, {{a, d}, {b, c}}, and
{{a, c}, {b, d}}.
It turns out that problem (3) is well-known in computer science. It is called exact
cover problem and is known to be NP-complete [52]. In the general case of searching
for a t-(v, k, λ)q design we get a generalized exact cover problem of the form
At,k · x =
⎛
⎜⎝
λ
...
λ
⎞
⎟⎠.
(4)
For the construction of packing designs, the “=” in Eq.(4) has to be replaced by a
“≤”, for covering designs it has to be replaced by a “≥”.
There is a plethora of algorithms available to solve the exact cover problem and
its generalizations. We will discuss a few solving strategies in Sect.6.

220
M. Braun et al.
But even if there are powerful algorithms available to solve these problems, the
biggest obstacle to this strategy for constructing subspace designs is that the sizes of
the problem instances will be prohibitively large even for small parameters.
Example 2 To ﬁnd the binary analog of the Fano plane, i.e. a 2-(7, 3, 1)2 design, the
matrix A2,3 has 2 667 rows and 11 811 columns. The design would consist of 381
3-subspaces.
Although being the smallest open parameter set for subspace designs, the problem
is still out of reach for all known computer algorithms.
4
Using Groups
A possible strategy to tackle even very large instances is not to select individual
blocks but to choose whole “chunks” of blocks which ﬁt together well. For this,
group theory comes in handy.
The idea to use groups to ﬁnd combinatorial objects can be traced back at least to
Dembowski [32], Parker [86] in the 1950s, and even to Moore [82] in 1896.
Dembowski [32] studied tactical decompositions via group actions and found
additional necessary conditions for combinatorial objects having such groups as
automorphism groups. Later on, Kramer and Mesner [65] had the idea to prescribe
an automorphism group and search by computer for combinatorial designs with this
automorphism group. The same approach has been used before the work of Kramer
and Mesner at least by Magliveras [77] and Klin [57] in their PhD theses. In fact, the
method is a systematic version of ﬁnding a tactical decomposition of a structure by
means of the automorphism group of the structure.
So, with tactical decompositions as well as with the Kramer–Mesner method
we choose a group G and search for G-invariant designs. The resulting computer
problem will be smaller and thus in many cases solvable by computer hardware. But
we must be aware that those designs which are not G-invariant will not be found by
this approach.
4.1
Tactical Decompositions
Tactical decompositions of combinatorial designs, mostly symmetric designs, were
studied already by Dembowski [32, 33]. In [68, 83] tactical decompositions of sub-
space designs are introduced.
An incidence structure is a triple (P, B, I) with P ∩B = ∅and an incidence
relation I ⊂P × B. The elements of P are called points and the elements of B
are called blocks.

Computational Methods in Subspace Designs
221
An incidence structure is called tactical conﬁguration if there is a number r′
such that #{B ∈B | (P, B) ∈I} = r′ for all points P ∈P and if there is a number
k′ such that #{P ∈P | (P, B) ∈I} = k′ for all B ∈B. Counting the incidences
(P, B) in two ways, we get the equation k′#B = r′#P.
Therefore, t-(v, k, λ)q subspace designs are tactical conﬁgurations with the blocks
of the design being the blocks of the tactical conﬁguration. As points of the tactical
conﬁgurations one can take one of the Graßmannians
V
s

, 0 ≤s ≤t. The incidence
relation is given by “≤”. Then, for the tactical conﬁguration we have k′ =
k
s

and
r′ = λs.
Deﬁnition 2 A decomposition of a tactical conﬁguration is a partition of the points
P = P1 ⊔. . . ⊔Pm and the blocks B = B1 ⊔. . . ⊔Bn.
A decomposition is tactical if there exist non-negative integers ρi, j, κi, j, 1 ≤i ≤
m, 1 ≤j ≤n, such that
1. every P ∈Pi is contained in exactly ρi, j blocks in B j,
2. every block in B j contains κi, j points in Pi.
The matrices (ρi, j) and (κi, j) are called tactical decomposition matrices.
In other words, a tactical decomposition is a partition P = P1 ⊔. . . ⊔Pm and
B = B1 ⊔. . . ⊔Bn of the points and blocks of a tactical conﬁguration such that
each pair (Pi, B j) itself is a tactical conﬁguration with regard to the incidence
relation I.
A tactical conﬁguration has always two trivial decompositions. One is the partition
of P, B into one set each, i.e. m = n = 1. The other one is the partition of P, B
into 1-element subsets.
Furthermore, the action of a subgroup G ≤Aut(D) yields a tactical decomposi-
tion which in general is nontrivial.
Theorem 2 (Dembowski [32]) Let G be a group of automorphisms of an incidence
structure (P, B, I). Then the orbits of G on the set of points P and the orbits of
G on the blocks B form a tactical decomposition.
Proof The statement follows immediately from (1) and from the fact that automor-
phisms map points to points and blocks to blocks.
⊓⊔
Remark 1 In [32] it was also observed that there are nontrivial tactical decomposition
which do not stem from group actions.
The deﬁnition of the tactical decomposition matrices leads directly to the follow-
ing equations for t-(v, k, λ)q designs and 0 ≤s ≤t:
m

i=1
κi, j =
k
s

,
n

j=1
ρi, j = λs.
(5)

222
M. Braun et al.
Furthermore, for all i ∈{1, . . . , m} and j ∈{1, . . . , n} we have
#Pi · ρi, j = #B j · κi, j,
(6)
since (Pi, B j) forms a tactical conﬁguration.
In [83] the following further relations are stated.
Theorem 3 (Naki´c, Pavˇcevi´c) Let 0 ≤s ≤t. Suppose that
V
s

= P1 ⊔. . . ⊔Pm,
B = B1 ⊔. . . ⊔Bn
is a tactical decomposition of a 2-(v, k, λ)q design. Let (ρi, j) and (κi, j) be the asso-
ciated decomposition matrices. Then, for all pairs of rows 1 ≤l,r ≤m,
n

j=1
ρl, jκr, j =

λ · #Pr,
l ̸= r;
λs + λ · (#Pr −1), l = r.
(7)
In the same paper there are more, reﬁned equations and inequalities for the special
case q = 2. The preprint [30] generalizes the above equations for subspace designs
with t = 3.
Algorithmic application
An algorithm to ﬁnd subspace designs with the help of tactical decompositions can
be the following approach. If we know the lengths of the block orbits then from
Eq.(6) we see that it is enough to work with one of the matrices (ρi, j) or (κi, j).
Algorithm 2 Choose a “promising” group G ≤PL(v, q) and ﬁnd 2-(v, k, λ)q
designs by using tactical decomposition matrices (ρi, j).
1. Search for tentative tactical decomposition matrices: Compute—up to permuta-
tions of rows and columns—all possible matrices (ρi, j) having nonnegative inte-
ger entries which satisfy the Eqs.(5) and (7) (and further equations or inequalities
if available, see [83]).
2. Indexing phase:
for all matrices (ρi, j) from 2.:
for 1 ≤i ≤m, 1 ≤j ≤n:
replace all entries (i, j) of (ρi, j) by 0/1-matrices of size #Pi × #B j
– having ρi, j ones in each row and
– being invariant under the simultaneous action of G on its rows and
columns.
if successful:
output incidence matrix of 2-(v, k, λ)q design

Computational Methods in Subspace Designs
223
Remark 2 Not every orbit matrix from Step 1 will give rise to subspace designs. In
contrast, a single matrix from Step 1 may produce more than one nonisomorphic
designs.
Example 3 WewanttoconstructacombinatorialdesignfromExample1byprescrib-
ing a cyclic symmetry, e.g. the mapping σ : (a, b, c, d) →(b, c, d, a). The induced
mapping on the edges maps (1, 2, 3, 4, 5, 6) →(2, 3, 4, 1, 6, 5). Under the action
of the group ⟨σ⟩the set of vertices is a single orbit {a, b, c, d} and the set of Edges
Is Partitioned Into the two orbits {1, 2, 3, 4} and {5, 6}.
a
b
c
d
1
2
3
4
5
6
Recall that we are searching for a 1-(v, 2, 1) design. We know, that such a design
consists of λ0 = 1
4
1

/
2
1

= 2 blocks and every point appears in λ1 = 1
3
0

/
1
0

= 1
blocks.
Therefore, we try to build our design by taking a block orbit of length two (there is
only one choice in this small case). Since there is just one point orbit, the only choice
in Step 1 is to take a trivial decomposition matrix consisting of the single entry, i.e.
n = m = 1. Equation (5) for combinatorial designs give immediately κ1,1 = 2 and
ρ1,1 = 1. Note, that we can not use the combinatorial design versions of Eq.(7) in
this case, since we are searching for a 1-design. Thus, the only possible matrix in
Step 1 is equal to (1).
In Step 2 we ﬁnd that up to the action of ⟨σ⟩just one 4 × 2-matrix having a single
one in every row:
⎛
⎜⎜⎝
1 0
0 1
1 0
0 1
⎞
⎟⎟⎠
It is the incidence matrix of the blocks points a, b, c, d and the blocks 5, 6. Therefore,
the blocks 5, 6 form a ⟨σ⟩-invariant 1-(4, 2, 1) design.
4.2
The Method of Kramer and Mesner
Similar as in the previous section we choose a group G and search for G-invariant
designs. Thus, instead of searching for individual k-subspaces as in (4) the design
has to be composed of G-orbits on the k-subspaces. This approach applied to com-
binatorial designs is commonly attributed to Kramer and Mesner [65] and has been
used there with great success.
The set of blocks B of a G-invariant t-(v, k, λ)q design (G ≤Aut(L(V ))) is
the disjoint union of orbits of G on the set
V
k

of k-dimensional subspaces of V .

224
M. Braun et al.
To obtain an appropriate selection of orbits of G on
V
k

we consider the incidence
matrix AG
t,k whose rows are indexed by the G-orbits on the set of t-subspaces of V
and whose columns are indexed by the orbits on k-subspaces. The entry aG
T,K of AG
t,k
corresponding to the orbits T G and K G is deﬁned by
aG
T,K := #{K ′ ∈K G | T ≤K ′}.
In other words, the matrix AG
t,k is the tactical decomposition matrix (ρi, j) for the
tacticaldecompositionofthepoints
V
t

andtheblocks
V
k

ofthetrivialt-(v, k, λmax)q
design into orbits on the t-subspaces and k-subspaces.
Since AG
t,k is a tactical decomposition of the complete design, i.e. a tactical conﬁg-
uration with #{B ∈B | P ≤T } = λmax for all T ∈
V
t

, we can search for a subset
of B′ ⊂B such that #{B ∈B′ | T ≤B′} = λ < λmax for all T ∈
V
t

, which is a
tactical decomposition of a t-(v, k, λ)q design. Therefore, the following theorem is
obvious.
Theorem 4 (Kramer, Mesner [65]) Let G ≤PL(v, q). There exists a G-invariant
t-(v, k, λ)q design if and only if there is a 0/1-vector x satisfying
AG
t,k · x =
⎛
⎜⎝
λ
...
λ
⎞
⎟⎠.
(8)
Example 4 We look again at the combinatorial design from Example1 and 3 and
prescribe again the mapping σ : (a, b, c, d) →(b, c, d, a). Counting how often a
representative of the point orbit {a, b, c, d} appears in each of the two orbits on lines,
we get the following table.
{1, 2, 3, 4} {5, 6}
{a, b, c, d}
2
1
That is, using the Theorem of Kramer and Mesner the matrix A1,2 is condensed to the
smaller matrix A⟨σ⟩
1,2 = (2 1). Now, if we choose the orbit {5, 6} as the set of blocks,
we get a 1-(4, 2, 1) design. If we choose the other orbit we get a 1-(4, 2, 2) design.
Note that the other two designs in Example1 are not found by this prescription of
automorphisms.
Remark 3 From Eq.(6) it is clear that AG
t,k can either be computed by determining
(ρi, j) or by computing (κi, j).
In some cases it is faster to compute (κi, j) and then determine (ρi, j) by (6). The
relation between these two matrices is also referred to as Alltop’s lemma [1].

Computational Methods in Subspace Designs
225
4.3
Promising Groups
In general, our approach in Sects.4.1 and 4.2 is to prescribe certain groups of auto-
morphisms which arise as subgroups G of the general linear group GL(V ). When it
comes to the question which groups may occur as automorphism groups of designs,
one group stands out. At least up to now, most successful computer searches for sub-
space designs with prescribed automorphism groups used this group or subgroups
thereof, see Sect.4.4. This group is the normalizer of a Singer cycle group. In the
following we will describe this group in more detail and explain why it is a promising
candidate for prescribing it as an automorphism group.
It will turn out to be helpful to apply the general linear group GL(v, q) in matrix
representation. In our notation, multiplication by group elements will be from the
right. Further—when appropriate—we will switch between the vectors of the vector
space V = Fv
q and the corresponding elements of the ﬁeld Fqv. The multiplicative
group (F∗
qv, ·) consisting of the nonzero elements of Fqv is known to be cyclic,
generators are called primitive elements of Fqv.
Any cyclic subgroup of order qv −1 of GL(V ) is called a Singer cycle group.
By setting V = Fqv it can be seen that Singer cycle groups do always exist: For any
primitive element α of Fqv, the mapping σ : V →V , x →αx is Fq-linear and of
order #F∗
q = qv −1 and thus generates a Singer cycle group.
To get a matrix representation of σ in GL(v, q), we can proceed as follows: Let
f = a0 + a1x + a2x2 + . . . + an−1xn−1 + xn ∈Fq[x] be the minimal polynomial
of α over Fq. Then f is a primitive irreducible polynomial of degree v. With respect
to the Fq-basis (1, α, α2, . . . , αv−1) of V = Fqv, the transformation matrix of σ is
given by the companion matrix of f , which is
⎛
⎜⎜⎜⎜⎜⎝
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
−a0 −a1 −a2 . . . −av−1
⎞
⎟⎟⎟⎟⎟⎠
.
By [49, Sect.7], any two Singer cycle subgroups of GL(V ) are conjugate.
The Galois group Gal(Fqv/Fq) of the ﬁeld extension Fqv/Fq, i.e. the group of all
ﬁeld automorphisms of Fqv element-wise ﬁxing Fq, is known to be cyclic of order v
and generated by the mapping F : x →xq. F is called Frobenius automorphism.
It is shown in [49, Satz 7.3] that the normalizer NGL(V )(S) of the Singer cycle
group S = ⟨σ⟩is given by
NGL(V )(S) = ⟨σ, F⟩= Gal(Fqv/Fq) ⋊S
and is of order v(qv −1).
In the following, S(v, q) (and N(v, q)) will denote the conjugacy class of all
(normalizers of) Singer cycle groups in GL(v, q).

226
M. Braun et al.
For a matrix group G ≤GL(v, q) we denote with G × n the group
M 0
0 In

| M ∈G

,
embedded into GL(v + n, q).
If one looks at the groups which have been used in the computer searches so far,
then this normalizer of a Singer cycle group, subgroups thereof, and embeddings into
higher dimensions are the predominant groups. Is there a reason for “the success” of
the normalizer of a Singer cycle group?
A possible answer can be found when looking to the analog situation for com-
binatorial designs. There, many designs have been found which have a transitive
automorphism group. In fact, a very successful approach is to search for designs
having an automorphism group which is transitive on the t-subsets of the point set. If
this is the case, then the Kramer–Mesner matrix of Sect.4.2 shrinks down to one row
and every collection of columns trivially fulﬁlls the matrix equation of Theorem4
and therefore gives a t-design.
But for subspace designs we face a slightly different situation as for combinatorial
designs. We say that a group G acts t-transitively on a vector space V if the set of
t-subspaces is a single orbit. Now, one might expect to construct a t-(v, k, λ)q design
by prescribing a t-transitive group for t ≥2. Unfortunately, by the following theorem
from [27, Prop. 8.4] this is only possible for the trivial design.
Theorem 5 (Cameron, Kantor) Let G ≤PL(v, q) be t-transitive with 2 ≤t ≤
v −2. Then G is k-transitive for all 1 ≤k ≤v −1.
That is, every group which is at least 2-transitive would shrink down the Kramer–
Mesner matrix not only to one row, but also to one column. But then, the only possible
choices are the trivial designs consisting of all k-subspaces or the empty design.
Nevertheless, when prescribing an automorphism group in the search for subspace
designs, choosing a 1-transitive group seems to be reasonable.
In [81] a list of all 1-transitive subgroups of GL(v, q) is given, based on the work
of [46, 47, 76].
Theorem 6 (Hering, Liebeck, see [81]) If G ≤GL(v, q) acts 1-transitively on the
1-subspaces of Fv
q with v ≥6, then one of the following holds:
(a) G ≤N(v, q),
(b) SL(a, qv/a) ⊴G,
where a | v, a ≤2,
(c) Sp(2a, qv/2a) ⊴G,
where 2a | v,
(d) G2(qv/6) ⊴G < Sp(6, qv/6),
where q = 2m and 6 | v,
(e) G ∼= U(3, 3) if q = 2 and v = 6,
(f) G ∼= SL(2, 13) < Sp(6, 3) if q = 3 and v = 6.
Here, Sp(2n, q) denotes the symplectic group Sp(2n, Fq), U(n, q) are the unitary
groups, and G2(2n) are the Chevalley groups.

Computational Methods in Subspace Designs
227
In the special case that v is prime, the possible 1-transitive automorphism groups are
exactly the subgroups of the normalizer of a Singer cycle group.
Corollary 1 If G is a transitive automorphism group of a non-trivial subspace
design (Fv
q, B) with v prime, then G is a subgroup of N(v, q).
4.4
Results
In [16] the ﬁrst q-Steiner system for t ≥2, an S(2, 3, 13)2, has been constructed.
Since it was found with the method of Kramer and Mesner, this is a good chance to
demonstrate the power of this approach.
Without using groups the system (3) would have
13
2

2 = 11 180 715 rows and
13
3

2 = 3 269 560 515 columns. A q-Steiner system, i.e. a selection of columns such
that every row is covered exactly once has to consist of precisely
13
2

2/
3
2

2 =
1 597 245 columns. However, ﬁnding a selection of that many columns is by far
out of reach of existing computer algorithms.
Instead, we prescribe the normalizer N(13, 2) of a Singer cycle group as automor-
phism group. Speciﬁcally, in [16] the Singer cycle group S(13, 2) for the polynomial
f (x) = x13 + x12 + x10 + x9 + 1 has been used.
In order to represent a G-invariant design it is sufﬁcient to list G by its genera-
tors and a set of representatives of the selected orbits of G on
V
k

. For a compact
representation we will write all n × m matrices X over Fq with entries xi, j, whose
indices are numbered from 0, as vectors of integers
⎡
⎣
m−1

j=0
x0, jq j, . . . ,
m−1

j=0
xn−1, jq j
⎤
⎦.
The order of the normalizer of the Singer cycle groups is #N(13, 2) = 13

213 −
1

= 106 483. Using compressed notation, one pair of generators is
[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 27] and
[1, 4, 16, 64, 256, 1024, 4096, 54, 216, 864, 3456, 5659, 6234].
The orbits of 2-subspaces and 3-subspaces under the action of N(13, 2) are all
full-length, resulting in a Kramer–Mesner matrix AN(13,2)
2,3
with
13
2

2/106 483 = 105
rows and
13
3

2/106 483 = 30 705 columns. Now, we need to ﬁnd a solution of the
Eq.(8) consisting of
13
2

2/
3
2

2
#N(13, 2) = 15

228
M. Braun et al.
columns of AN(13,2)
2,3
. Luckily, it turns out that this problem is in the reach of contem-
porary computer algorithms and hardware. It can be solved e.g. with the algorithm
dancing links by Knuth [59]. One solution corresponds to the 15 orbit representatives
listed below:
[416, 2048, 4096],
[32, 3072, 4096],
[1344, 512, 4096],
[3440, 1536, 4096], [8, 3328, 4096],
[3284, 3840, 4096],
[3428, 128, 4096],
[617, 2176, 4096], [1038, 3200, 4096],
[1113, 2688, 4096], [1338, 576, 4096], [3389, 2368, 4096],
[317, 2880, 4096],
[1448, 192, 4096], [774, 3232, 4096].
Meanwhile, 1316 mutually disjoint solutions have been determined with the algo-
rithm from Sect.5.1 [23]. Therefore, the union of 1 ≤λ ≤1316 of their block sets
gives a 2-(13, 3, λ)2 design. Together with their supplementary designs and noting
that λmax = 2047, this implies that all possible design parameters
2-(13, 3, λ)2,
1 ≤λ ≤2047,
are realizable.
Chapter “q-Analog of Designs: Subspace Designs” in this book contains tables
of all known subspace designs with small parameters. We conclude this section with
a list of those designs from these table which are constructed by computer and give
the prescribed groups as well as the sizes of the resulting Kramer–Mesner matrices.
The list contains one group which is not a subgroup of N(v, q), namely the
monomial group M(3, 23), see [15].
q = 2:
2-(6, 3, λ)2: For all designs ⟨σ 7⟩was used. Matrix size: 77 × 155.
2-(7, 3, λ)2: All known 2-(7, 3, λ)2 designs can be constructed by prescribing
S(7, 2). Matrix size: 3 × 15.
N(7, 2) for λ = 3, 5, 7, 10, 12, 14. Matrix size: 21 × 93.
2-(8, 3, 21)2: N(4, 22). Matrix size: 15 × 105.
2-(8, 4, λ)2: N(4, 22) for λ = 21, 35, 56, 70, 91, 105, 126, 140, 161, 175, 196, 210,
231, 245, 266, 280, 301, 315. Matrix size: 15 × 217.
N(7, 2) × 1 for λ = 7, 14, 49, 56, 63, 98 105, 112, 147, 154, 161, 196, 203, 210,
245, 252, 259, 294, 301, 308. Matrix size: 13 × 231.
⟨σ 5, φ⟩for λ = 217, 224. Matrix size: 35 × 531.
3-(8, 4, λ)2: N(4, 22) for λ = 11, 15. Matrix size: 105 × 217.
N(8, 2): λ = 11. Matrix size: 53 × 109.
2-(9, 3, λ)2: N(3, 23) for λ = 21, 22, 42, 43, 63. Matrix size: 31 × 529.
N(8, 2) × 1 for λ = 7, 12, 19, 24, 31, 36, 43, 48, 55, 60. Matrix size: 28 × 408.
M(3, 23) for λ = 49. Matrix size: 40 × 460.
2-(9, 4, λ)2: N(9, 2). Matrix size: 11 × 725.
2-(v, 3, λ)2, v = 10, 11, 13: N(v, 2). Matrix sizes: 20 × 633 for v = 10, 31 × 2263
for v = 11, 105 × 30705 for v = 13.

Computational Methods in Subspace Designs
229
q = 3:
2-(6, 3, λ)3: ⟨σ 13, φ⟩for λ = 16. Matrix size: 93 × 234.
S(5, 3) × 1 for λ = 8, 16, 20. Matrix size: 51 × 150.
⟨σ 2⟩× 1 for λ = 8, 12, 16, 20. Matrix size: 91 × 280.
2-(v, 3, λ)3, v = 7, 8: N(v, 3).Matrixsizes:13 × 121forv = 7,41 × 977forv = 8.
q = 4:
2-(6, 3, λ)4: ⟨σ 3, φ⟩for λ = 15, 35. Matrix size: 51 × 161
⟨σ 3, φ⟩× 1, designs for λ = 10, 25, 30, 35. Matrix size: 57 × 229.
q = 5:
2-(6, 3, 78)5: ⟨σ 2, φ⟩. Matrix size: 53 × 248.
4.5
Non-existence Results
In [16] a list of non-existence results for prominent design parameters is given. Their
results show that q-Steiner systems with the following parameters and automor-
phisms do not exist:
S(2, 3, 7)2, Galois group F(7, 2) (order 7)
S(3, 4, 8)2, Singer subgroup (order 255)
S(2, 4, 10)2, normalizer of Singer subgroup (order 10 230)
S(2, 4, 13)2, normalizer of Singer subgroup (order 106 483)
S(3, 4, 10)2, normalizer of Singer subgroup (order 10 230)
S(2, 3, 7)3, Singer subgroup (order 2 186)
S(2, 3, 7)3, normalizer of Singer subgroup (order 546 868)
This extends upon the previous work on non-existence of q-Steiner systems [34, 63,
92]. For example, it was shown in [92] that there is no Singer-invariant q-Steiner sys-
tem S(2, 3, 7)2.
In [19, 55], a systematic exclusion of automorphisms of an S(2, 3, 7)2 has been
performed. For the question of the existence of such a G-invariant design, the sub-
groups of PL(7, 2) = GL(7, 2) only need to be considered up to conjugacy, see
Eq.(2). The result is that the automorphism group of an S(2, 3, 7)2 q-Steiner system
is either trivial or of order two. In the latter case, group is conjugate to
⎛
⎜⎝
0 1 0 0 0 0 0
1 0 0 0 0 0 0
0 0 0 1 0 0 0
0 0 1 0 0 0 0
0 0 0 0 0 1 0
0 0 0 0 1 0 0
0 0 0 0 0 0 1
⎞
⎟⎠

.

230
M. Braun et al.
Interestingly, also a 2-(7, 3, 2)2 design is not known yet. For the automorphism
group of a design with these parameters, the authors were able to exclude all sub-
groups of GL(7, 2) except
• three conjugacy classes of groups of order 2,
• two conjugacy classes of groups of order 3,
• two conjugacy classes of groups of order 7.
4.6
Generation of the Kramer–Mesner Matrix
Computing orbit representatives for matrix groups can be very time consuming even
for small parameters. One way to do this is to keep the bases of the subspaces in row
reduced echelon form and the group action is realized as multiplication of matrices
followed by Gauss elimination.
A fast method relying on the subgroup lattice to compute orbit representatives
was developed by [89] for combinatorial designs. This approach was generalized
to subspace designs by [13, 17, 24]. Recently, Koch [62] improved this method
considerably by removing the high memory consumption of the original algorithm.
In case the prescribed group is the Singer cycle group or its normalizer the com-
putation of the Kramer–Mesner matrix can be sped up enormously by considering
vectors in Fv
q as elements of the ﬁnite ﬁeld Fqv. We use this to show how to classify the
subspaces of Fv
q into orbits under the action of Singer cycle group or its normalizer,
see [16, 35].
We ﬁx a primitive element α of Fqv, and write a k-subspace X of Fv
q as
X = {0, αx1, αx2, . . . , αxm}, where m = qk −1 and x1, x2, . . . , xm ∈Zqv−1. In other
words, we represent all nonzero vectors in Fv
q by their discrete logarithm with regard
to basis α.
For x ∈Zqv−1, let ρ(x) be the minimal cyclotomic representative for x, that is
ρ(x) = min{xqi mod (qv −1) | 0 ≤i ≤v −1}. We deﬁne
invF(X) := {ρ(xi) : 1 ≤i ≤m},
invS(X) := {xi −x j : 1 ≤i, j ≤m with i ̸= j},
invN(X) := {ρ(xi −x j) : 1 ≤i, j ≤m with i ̸= j}.
Lemma 2
1. If two k-subspaces X, Y of Fv
q are in the same orbit under the action
of the Galois group F(v, q) then invF(X) = invF(Y).
2. If two k-subspaces X, Y of Fv
q are in the same orbit under the action of the Singer
cycle group S(v, q) then invS(X) = invS(Y).
3. If two k-subspaces X, Y of Fv
q are in the same orbit under the action of the
normalizer N(v, q) of the Singer cycle group then invN(X) = invN(Y).

Computational Methods in Subspace Designs
231
Proof Let X = {0, αx1, αx2, . . . , αxm} be a k-subspace of Fv
q, with x1, x2, . . . , xm in
Zqv−1. The action of the generator of S(v, q) on X increases x1, x2, . . . , xm by one
modulo qv −1, thereby preserving the differences between them.
The action of the Frobenius automorphism φ on X multiplies each xi by q modulo
qv −1, thereby leaving it in the same cyclotomic coset.
⊓⊔
So, instead of using costly matrix multiplication we can compute the orbit repre-
sentatives with simple arithmetics modulo qv −1.
In the special situation that qv −1 is a prime we can speed up the computation of
invN even further. One example is q = 2 and v = 13. Instead of working in the ﬁnite
ﬁeld Zqv−1 we take once more the discrete logarithms and work modulo qv −2. By
doing this, the action of the Frobenius automorphism φ reduces to an addition by
(qv −2)/v. Thus, the numbers in invN are considered modulo (qv −2)/v.
4.7
Isomorphism Problems for Subspace Designs
Whenever subspace designs are constructed, immediately the natural question arises
which of them are isomorphic. The abstract formulation of this problem is the fol-
lowing: Given the action of a group G on a set X, and x, x′ ∈X, how can we decide
if x ∼x′? In our situation of subspace designs, the group G typically is GL(v, q) or
PGL(v, q) or PL(v, q) etc., and the set X is the power set of
V
k

.
A ﬁrst approach is the computation of invariants. Invariants are functions i :
X →Ω with some set Ω which are constant on the orbits, that is, x ∼x′ implies
i(x) = i(x′). In the case i(x) ̸= i(x′), we know that x ≁x′. However, in general an
invariant cannot prove that x ∼x′, so we need further methods which we apply in
the case i(x) = i(x′). A good invariant should be reasonably efﬁcient to compute
and not too often evaluate to the same expression if x and x′ are from different orbits.
A suitable source of invariants are the intersection numbers of blocks [56].
Sometimes, the following pragmatic approach can be applied: The isomorphism
problem is transformed into a graph theoretic problem and then fed into the software
nauty and its successors by McKay [80] to solve the graph isomorphism problem.
Furthermore, we would like to mention the algorithm of [38] (based on [37], see
also [39]), which is specialized for isomorphism problems on sets of subspaces of a
vector space.
Now we focus on the quite common situation that our designs have been con-
structed by subscribing some subgroup H of G, for example by the method of
Kramer–Mesner. Compared to the above situation, now we have the additional infor-
mation H ⊆Gx and H ⊆Gx′. To take advantage of this extra knowledge, the theory
of group actions comes in handy. By theoretical arguments, often it is possible to
simplify or even solve the isomorphism problem.
For combinatorial designs, this approach was described by Laue et. al. [44, 71,
72], see also [53]. It involves the normalizers of certain groups. For a group G with
subgroup H, the normalizer of H in G will be denoted by NG(H).

232
M. Braun et al.
Lemma 3 Let G be a group acting on a set X. For any x ∈X,
NG(Gx) = {g ∈G | Gx = Gxg}.
Proof This is a direct consequence of Eq.(2) Gxg = g−1Gxg.
⊓⊔
The above lemma has the following intuitive interpretation: The normalizer of the
stabilizer of x consists of all elements of G which preserve the symmetries of x.
As a consequence, to investigate two elements x, x′ with the same stabilizer H for
x ∼x′, it is enough to consider the action of the subgroup NG(H) instead of the full
group G. Depending on the group orders, this may be a signiﬁcant reduction of the
computational complexity. Unfortunately, in general this is not directly applicable
in our situation: Typically, we only know that x and x′ are H-invariant, but we don’t
know the full stabilizers Gx and Gx′, which may well be larger and not identical to
each other.
However, if we are in the comfortable situation that H is a maximal (but proper)
subgroupof G,theninallcasesofinterest, H hastobethefullautomorphismgroupof
H-invariant designs (as otherwise, the full automorphism group would be G, which
acts transitively on
V
k

and therefore only admits trivial solutions). If additionally
H is non-normal in G, then NG(H) = H and hence by Lemma3, any two distinct
H-invariant designs are non-isomorphic (with respect to the action of G). In the
case that the maximal group H is a normal subgroup of G, we have NG(H) = G.
Now by Lemma3 we get that each H-invariant design will appear in exactly [G : H]
isomorphic copies among the set of all H-invariant designs.
Example 5 The q-Steiner system 2-(13, 3, 1)2 has been found by prescribing the
normalizer N = N(13, 2) of a Singer cycle group in GL(13, 2). As N is a non-normal
maximal subgroup of GL(13, 2), any two different solutions of the Kramer–Mesner
system describe non-isomorphic designs. In this way, we know that in fact there are
thousands of non-isomorphic q-Steiner systems 2-(13, 3, 1)2.
If the prescribed group H is a proper subgroup of its normalizer N = NG(H),
this can be exploited algorithmically. For example, if we force one orbit K H to be in
the design, and the solving algorithm shows that there is no solution which contains
this orbit, all K-orbits in (K H)N can be excluded from being part of a solution, i.e.
the corresponding columns of the Kramer–Mesner matrix can be removed.
For algorithmic purposes also the Sylow subgroups of G and H are very valuable.
The following theorem is a slight generalization of [49, Hilfssatz IV 2.5] and [10,
Theorem3.1].
Theorem 7 Let G be a group acting on a set X, x, x′ ∈X with x ∼x′ and P
a common Sylow subgroup of Gx and Gx′. Then there exists an n ∈NG(P) with
x′ = xn.
Proof Let g ∈G with x′ = xg. From g−1Pg ⊆g−1Gxg = Gxg = Gx′, both groups
P and g−1Pg are Sylow subgroups of Gx′. As any two Sylow subgroups of the same
order are conjugate, there is a h ∈Gx′ with

Computational Methods in Subspace Designs
233
P = h−1(g−1Pg)h = (gh)−1P(gh).
Now n = gh ∈NG(P) satisﬁes xn = (xg)h = (x′)h = x′.
⊓⊔
By Lemma3, we saw that in the case Gx = Gx′, the investigation of x ∼x′ may be
done using the action of the subgroup N(Gx) instead of G, which potentially provides
a huge improvement in terms of computational complexity. Now by Theorem7, the
knowledge of a common Sylow subgroup P of Gx and Gx′ is enough to provide
a similar simpliﬁcation. In this case, the acting group G may be replaced by the
subgroup NG(P).
Example 6 We illustrate the above theorem with 2-(9, 4, 21)2 designs.
Prescribing N(9, 2) in the Kramer–Mesner method gives many solutions, which
are N(9, 2)-invariant 2-(9, 4, 21)2 designs. We can prove that all these designs are
mutually non-isomorphic without having knowledge of their full automorphism
groups. Let us point out that N(9, 2) is not maximal in GL(9, 2), so the argument of
Example5 doesn’t work in this case.
We have #N(9, 2) = (29 −1) · 9 = 32 · 7 · 73. Let P be a Sylow-73 subgroup
of N(9, 2). Then #P = 73, and by # GL(9, 2) = 8
i=0(29 −2i) = 236 · 35 · 52 ·
73 · 17 · 31 · 73 · 127, P is also a Sylow-73 subgroup of GL(9, 2). Hence, P is
a Sylow-73 subgroup of the full automorphism group of any N(9, 2)-invariant
design. With the above theorem we can conclude that if two N(9, 2)-invariant
designs D1 = (V, B1), D2 = (V, B2) are isomorphic there would be an element
n ∈NGL(9,2)(P) with Bn
1 = B2. But NGL(9,2)(P) = N(9, 2) and we know that both
designs are N(9, 2)-invariant. Therefore, D1 and D2 are non-isomorphic.
For the cases where Theorem7 is not applicable, further theoretical results exist,
see [72]. One example is the following theorem.
Theorem 8 Let G ≤GL(v, q) and let Δ be the set of G-invariant t-(v, k, λ)q
designs. Let P be a Sylow p-subgroup of G. Then after removing every design
from Δ that is invariant under any subgroup H such that either
• G < H < NGL(v,q)(G) or
• H = ⟨G, Gn⟩for some n ∈NGL(v,q)(P) with Gn ̸= G
two designs in Δ are isomorphic if and only if some element from NGL(v,q)(G) maps
one onto the other.
5
Constructing “Large Sets of Designs” by Computer
The method of Kramer–Mesner can also be adapted to construct large sets of designs.
This is explained for combinatorial designs in Chee [28]. In fact, the authors describe
three approaches based on the Kramer–Mesner theorem.

234
M. Braun et al.
1. Use t-homogeneous groups, i.e. the Kramer–Mesner matrix shrinks down to
a single row. This is not possible for subspace designs with t ≥2 because of
Theorem5.
2. Recursive approach. Construct a design from the Kramer–Mesner matrix, remove
the columns of the matrix which correspond to the design orbits and recurse.
3. Isomorphic designs. Search for uniformly-G large set consisting of N isomorphic
designs.
For the time being, large sets with t ≥2 could only be constructed by computer with
the second approach. Sarmiento [88] used an hybrid approach mixing methods 2 and
3 to classify all LS3[155](1, 3, 6) consisting of 155 point-transitive, uniformly-G
1-(6, 3, 1)3 designs.
5.1
Recursive Approach
The following algorithm describes a basic approach to ﬁnd large sets. A version of
this algorithm for large sets of combinatorial designs can be found in [28, 73, 74].
The algorithm computes an LSq[N](t, k, v) large set L consisting of N G-
invariant t-(v, k, λ)q designs. Either the algorithm terminates with a large set or
it ends without any statement about the existence.
Algorithm 3
1. [Initialize.] Set Ω as the complete set of G-orbits on
V
k

and set
L := ∅.
2. [Solve.] Find a random t-(v, k, λ)q design D = (V, B)) consisting of orbits of
Ω. If such a t-design exists insert D into L and continue with 3. Otherwise
terminate without a large set.
3. [Remove.] Remove the selected orbits in B from Ω. If Ω = ∅then terminate
with a large set L . Otherwise go to 2.
The described algorithm can be implemented by a slight modiﬁcation of the Kramer–
Mesner approach. We just have to add a further row to the Diophantine system of
Eq.(8) in the following way:
⎛
⎜⎜⎝
AG
t,k
· · · y · · ·
⎞
⎟⎟⎠· x =
⎛
⎜⎜⎜⎝
λ
...
λ
0
⎞
⎟⎟⎟⎠
The vector y is indexed by the G-orbits on
V
k

corresponding to the columns of AG
t,k.
The entry indexed by the G-orbit containing K is deﬁned to be one if the orbit of K
has already been covered by a selected t-(v, k, λ)q design. Otherwise it is zero. In
every iteration step the vector y has to be updated.

Computational Methods in Subspace Designs
235
Remark 4 Another approach is to compute all 0/1-vectors which are solutions of the
Kramer–Mesner system (8) for a given group G. Every solution vector corresponds
to a design.
In a second step we try to ﬁnd a subset of N disjoint solution vectors. This is again
an exact cover problem.
5.2
Large Sets from Isomorphic Designs
This approach is described in detail in [28] for combinatorial designs. The task will be
to search for a uniformly-G large set LSq[N](t, k, v), where G ≤H ≤PL(v, q).
Moreover, the designs of the large set will not only be G-invariant, but also mutually
isomorphic.
Let nG
k and nH
k be the number of orbits of G and H acting on
V
k

and ﬁx some
order K G
j , 1 ≤j ≤nG
k , and K H
i , 1 ≤i ≤nH
k , on the G-orbits and H-orbits acting
on
V
k

.
The fusion matrix F G,H
k
= ( fi, j) is the nH
k × nG
k matrix deﬁned by
fi, j =

1,
if K G
j ⊆K H
i ;
0,
else.
We want to ﬁnd a large set consisting of designs D1, D2, . . . , DN such that each
design Di is G-invariant. Suppose further that we want an isomorphism g ∈PL(V )
of order N such that
D gi
1 = Di,
0 ≤i < N.
Let H = ⟨G, σ⟩. Then, an orbit of H on k-subspaces is the union of (disjoint) G-
orbits on k-subspaces.
As a consequence, if we are able to ﬁnd a design (V, B1) that contains exactly one
G-orbit from every H-orbit, then {Bgi
1 | 0 ≤i < N} gives rise to disjoint designs,
i.e. a large set of designs. This can be summarized in the following theorem.
Theorem 9 (Chee [28]) Suppose that σ ∈PL(V ) with ord(σ) = N and G ≤
PL(V ). Let H = ⟨G, σ⟩.
There exists a uniformly-G large set LSq[N](t, k, v) if there is a 0/1-vector x
satisfying
 AG
t,k
F G,H
k

· x =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
λ
...
λ
1
...
1
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
.

236
M. Braun et al.
6
Solving Algorithms
Solving Eq.(8) is a special instance of the multi-dimensional subset sum problem
which is known to be NP-complete [41]. Since problem (8) can be reduced to many
other NP-hard problems it is no surprise that there are many solving algorithms
available. In this section we will give an overview of the so far most promising
strategies to ﬁnd subspace designs. For a survey, see also [42, 53, 78].
6.1
Backtracking
The problem (8) for λ = 1 is known as the exact cover problem. A common approach
to ﬁnd all solution of an exact cover problem is to systematically test all combinations
of block orbits. Walker [93] was the ﬁrst to call such an approach back-track.
A backtracking algorithm for solving the system (8) for λ = 1 and Kramer–
Mesner matrix A = (ai, j) is quite simple and straight forward to describe:
Algorithm 4 Choose columns of A to ﬁnd a solution of (8) for λ = 1.
1. If A has no columns, the problem is solved; terminate successfully.
2. Otherwise choose a row r with the least number of nonzero entries.
3. for each column c such that ar,c = 1:
include c in the partial solution
for each i such that ai,c = 1
delete row i from the matrix A;
for each j such that ai, j = 1,
delete column j from the matrix A.
4. Repeat this algorithm recursively on the reduced matrix A.
In [58] the strategy of Step 2 to choose those rows ﬁrst which have the least number
of nonzero entries is justiﬁed. If the goal is to ﬁnd all solutions then the order in
which the columns in Step 3 taken is irrelevant. This may be different if one wants
to ﬁnd one solution at all.
The speed of this algorithm is largely determined by the choice of the data struc-
tures. In [59] Knuth uses doubly linked lists, all the navigation through the matrix is
done via pointers. By a trick due to Hitotumatu and Noshita [48], the use of pointers
enables a very fast recovering of the original data after stepping back from recursion.
The algorithm is called dancing links.
In [95] a parallel version of dancing links is described. [55] uses a brute force
parallelization which is better suited for batch system on computing clusters.
For problem instances with λ > 1 the situation changes. The dancing links algo-
rithm can be adapted to this case. The library libexact [54] contains an imple-
mentation, see also [79].

Computational Methods in Subspace Designs
237
6.2
Maximum Clique Algorithms
A weighted graph G = (V, E) is a set of vertices V together with a set of edges
E which are 2-element subsets of V . Additionally, every vertex carries a (nonzero)
weight, i.e. there is a mapping wgt : V →Z≥0.
A clique of a graph G is a set of vertices C ⊂V such that {v, w} ∈E for all
v, w ∈C, v ̸= w.
The following decision problem is NP-complete: Given a weighted graph G and
an integer k, is there a clique in G with weight at least k? Although no polynomial-
time algorithm is known for the maximum weight clique problem, various algorithms
have been developed as these have many important applications. cliquer [85] is
one freely available software package that solves instances of the maximum weight
clique problem.
For λ = 1 problem (8) can be formulated as maximum weight clique problem.
The vertices of the graph are the block orbits. Their weights are given by the orbit
lengths. Two orbits share an edge if and only if they cover disjoint sets of t-subspaces.
This approach is promising if the cardinality of a maximum clique can be expected
to be reasonably small. The advantage of the method is that it can tackle instances
with very many block orbits.
If one is interested in improving the known bounds for packing designs, i.e. con-
stant dimension subspace codes, then it is sometimes good enough to ﬁnd approxi-
mate solutions of the maximum clique problem. In such a situation one may resort
to stochastic methods.
Stochasticalgorithmsforﬁndingcliqueshavebeenthoroughlystudied,butmostof
the studies consider unweighted graphs. For some recent results, see [87]. Typically,
a stochastic algorithm proceeds by adding and removing single vertices in a speciﬁc
manner, when building up a large clique.
Lower bounds for constant dimension subspace codes could be improved by such
a stochastic algorithm in [21].
For the time being, no q-Steiner systems could be found by this approach. In [35]
it is reported that with a weighted clique approach 14 of the necessary 15 orbits could
be packed together in the search for 2-(13, 3, 1)2 design.
6.3
Lattice Point Enumeration
When one attempts to solve systems of type (8) for large values of λ a detour via
lattices proves to be worthwhile.
Suppose that b1, b2, …, bn ∈Qm. The integer span of these vectors, i.e.
L = {
n

i=1
uibi | ui ∈Z}

238
M. Braun et al.
is called lattice. Given a lattice, central problems are to ﬁnd shortest nonzero lattice
vectors with regard to various norms ∥.∥and to ﬁnd a basis of L consisting of short
vectors with regard to ∥.∥2. We will not dive further into this subject and not give a
precise deﬁnition what a “basis of short vectors” exactly is. The reader is referred to
[84] for an extensive overview.
In 1982, Lenstra, Lenstra and Lovász [75] gave a celebrated method—LLL algo-
rithm—which produces approximate solutions to both problems in polynomial time.
The LLL algorithm does lattice basis reduction – it takes a lattice basis as input
and outputs a reduced basis of the lattice, hopefully consisting of short vectors. The
amazing power of the LLL algorithm is that it performs much better than the the-
oretical analysis predicts and in many practical cases the output bases are already
solutions of the above problems.
The ﬁrst ones to use lattice basis reduction for the search of combinatorial designs
were Kreher and Radziszowski [66, 67]. They used the original LLL algorithm as
proposed in [75] and the formulation of problem (8) as lattice problem from Lagarias
and Odlyzko [69].
Since then, this approach could be improved in many aspects. With improved
variants of the LLL algorithm much smaller basis vectors can be achieved, see [84].
In [94] an improved lattice formulation of problem (8) is given. For this lattice, a
solution of (8) corresponds to a shortest nonzero lattice vector in ∥.∥∞norm. This
was generalized in [96] to non-simple designs.
Further, the lattice basis reduction algorithms behave somewhat random. But [90]
proposes a method to ﬁnd a shortest vector for the Euclidean norm from an LLL
reduced lattice basis by exhaustive enumeration. This was generalized by [51] to
arbitrary norms.
Combining these improvements many combinatorial designs for t = 6, 7, 8, 9
were found [4, 5, 7–12, 70, 71, 94]. The algorithm is used in a software system called
DISCRETA [6] which allows the user to easily prescribe automorphism groups and
try to solve the corresponding Kramer–Mesner system of equations.
The algorithm was also the method of choice to construct subspace designs in
many publications, see [13, 14, 17–20, 24] for an incomplete list.
Let A be an l × s Kramer–Mesner matrix from (8). The corresponding lattice
proposed in [94] is generated by the linearly independent columns of the matrix
L =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
c · λ
c · A
...
c · λ
2
0
1
...
...
0
2
1
0 . . . 0
1
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
,
(9)

Computational Methods in Subspace Designs
239
consisting of s + 1 column vectors with l + s + 1 rows. The constant c is chosen
large enough such that the output of the lattice basis reduction looks like
 0 ∗
B ∗

and B has size (s + 1) × (s + 1 −rk(A)).
In the second phase of the algorithm we search with the enumeration algorithm
from [51] for all nonzero lattice vectors b of the lattice spanned by the columns of
B such that ∥b∥∞= 1. The integer vectors b = (b1, . . . , bs, bs+1)⊤of the lattice
spanned by the columns of B fulﬁll the equation
A ·
⎛
⎜⎝
(b1 −bs+1)/2
...
(bs −bs+1)/2
⎞
⎟⎠= −bs+1
⎛
⎜⎝
λ
...
λ
⎞
⎟⎠.
The condition ∥b∥∞= 1 ensures that bs+1 = ±1 and that bs+1 · (bi −bs+1)/2 ∈
{0, 1} for 1 ≤i ≤s.
The big advantage of this method is that the size of λ has not much inﬂuence on
the runtime. This is in strong contrast with the backtracking approach above which
is best for λ = 1.
The height of the search tree in the second phase is determined by the number of
columns of B, i.e. it is roughly the difference between the number of unknowns and
the number of equations. As a consequence, having many equations is good for the
runtime of the algorithm and the number of orbits which have to be selected has not
much inﬂuence on the runtime.
The disadvantage of this lattice based approach is that the lattice basis reduction
in the ﬁrst phase—albeit having polynomial runtime—takes prohibitively long time
for systems when the number of unknowns exceeds 3 000 (as a rule of thumb).
6.4
Counting Algorithms
If the design parameters are small enough it may be easy to ﬁnd one solution and one
is tempted to try to count all designs having automorphisms. Schmalz [89] developed
a graph theoretical approach to enumerate all solutions of (8) implicitly.
A similar approach is known in computer science as binary decision diagrams
and related data structures, see [60]. In [61, Exercise 50] Knuth describes a binary
method to count all solutions.

240
M. Braun et al.
6.5
Integer Linear Programming
The system of Eq.(8) can be regarded as integer linear programming problem. One
possible formulation is
max

i
xi
such that
AG
t,k · x =
⎛
⎜⎝
λ
...
λ
⎞
⎟⎠,
xi ∈{0, 1}.
There are a many software systems available to solve integer linear programming
problems. Among the most powerful and popular are CPLEX [50] and Gurobi [43].
It seems that for problems of type (8) integer linear programming algorithms are
still inferior to lattice basis reduction algorithms. But often the linear programming
part—i.e. using the relaxation xi ∈[0, 1] ⊂R—of these solvers is sufﬁcient to show
nonexistence of solutions.
Moreover, these solving algorithms show their power when it comes to ﬁnd pack-
ing designs, i.e. replacing “=” by “≤”. The online tables for the best bounds on
subspace codes1 contain many example where lower bounds were constructed by
using integer linear programming, compare [45, 63].
6.6
Other Algorithms
Asalreadymentioned,sinceproblem (8)isanNP-completeproblemitcanbereduced
to other NP-hard problems. Recently, randomized algorithms were successful for
related packing problems, e.g. [22, 97]. Other randomized algorithms are simulated
annealing, tabu search, hill climbing, see [42]. But also constraint logic algorithms
and SAT algorithms are candidates to be tried out.
References
1. W.O. Alltop, On the construction of block designs. J. Comb. Theory 1, 501–502 (1966)
2. C. Berge, D. Ray-Chaudhuri, in Unsolved problems, ed. by C. Berge, D. Ray-Chaudhuri.
Hypergraph Seminar: Ohio State University 1972, in Lecture Notes in Mathematics, vol. 411
(Springer, Berlin, 1974), pp. 278–287. https://doi.org/10.1007/BFb0066199
1http://subspacecodes.uni-bayreuth.de.

Computational Methods in Subspace Designs
241
3. T. Beth, D. Jungnickel, H. Lenz, Design Theory, vol. 1, 2, 2nd edn. (Cambridge University
Press, London, 1999)
4. A. Betten, A. Kerber, A. Kohnert, R. Laue, A. Wassermann, The discovery of simple 7-designs
with automorphism group PL(2,32), in AAECC 11, Lecture Notes in Computer Science, vol.
948 (Springer, Heidelberg, 1995), pp. 131–145
5. A. Betten, A. Kerber, R. Laue, A. Wassermann, Simple 8-designs with small parameters. Des.
Codes Cryptogr. 15(1), 5–27 (1998). https://doi.org/10.1023/A:1008263724078
6. A. Betten, R. Laue, A. Wassermann, DISCRETA – A tool for constructing t-designs. Lehrstuhl
II für Mathematik, Universität Bayreuth, http://www.mathe2.uni-bayreuth.de/discreta/
7. A. Betten, R. Laue, A. Wassermann, Simple 6 and 7-designs on 19 to 33 points. Congr. Numer.
123, 149–160 (1997)
8. A. Betten, R. Laue, A. Wassermann, Some simple 7-designs, eds. by. J.W.P. Hirschfeld, S.S.
Magliveras, M.J. de Resmini Geometry, Combinatorial Designs and Related Structures, Pro-
ceedings of the First Pythagorean Conference, London Mathematical Society Lecture Notes,
vol. 245, pp. 15–25 (1997)
9. A. Betten, R. Laue, A. Wassermann, New t-designs and large sets of t-designs. Discret. Math.
197/198, 83–109 (1999). Also appeared in the special volume Discrete Mathematics, Editor’s
Choice, Edition 1999
10. A. Betten, R. Laue, A. Wassermann, Simple 7-designs with small parameters. J. Comb. Des.
7, 79–94 (1999)
11. A. Betten, R. Laue, A. Wassermann, Simple 8-(40, 11, 1440) designs. Discret. Appl. Math.
95, 109–114 (1999)
12. A. Betten, R. Laue, A. Wassermann, A Steiner 5-design on 36 points. Des. Codes Cryptogr.
17, 181–186 (1999)
13. M. Braun, Konstruktion diskreter Strukturen unter Verwendung von Operationen linearer Grup-
pen auf dem linearen Verband, Ph.D. thesis, University of Bayreuth, Germany (2004)
14. M. Braun, Some new designs over ﬁnite ﬁelds. Bayreuth. Math. Schr. 74, 58–68 (2005)
15. M. Braun, Designs over the binary ﬁeld from the complete monomial group. Australas. J.
Comb. 67(3), 470–475 (2017)
16. M. Braun, T. Etzion, P.R.J. Östergård, A. Vardy, A. Wassermann, Existence of q-analogs of
steiner systems. Forum Math. Pi 4(e7), 14 (2016). https://doi.org/10.1017/fmp.2016.5
17. M. Braun, A. Kerber, R. Laue, Systematic construction of q-analogs of t-(v, k, λ)-designs.
Des. Codes Cryptogr. 34(1), 55–70 (2005). https://doi.org/10.1007/s10623-003-4194-z
18. M. Braun, M. Kiermaier, A. Kohnert, R. Laue, Large sets of subspace designs. J. Comb. Theory
Ser. A 147, 155–185 (2017). https://doi.org/10.1016/j.jcta.2016.11.004
19. M. Braun, M. Kiermaier, A. Naki´c, On the automorphism group of a binary q-analog of the
fano plane. Eur. J. Comb. 51, 443–457 (2016). https://doi.org/10.1016/j.ejc.2015.07.014
20. M. Braun, A. Kohnert, P.R.J. Östergård, A. Wassermann, Large sets of t-designs over ﬁnite
ﬁelds. J. Comb. Theory Ser. A 124, 195–202 (2014). https://doi.org/10.1016/j.jcta.2014.01.
008
21. M. Braun, P.R.J. Östergård, A. Wassermann, New lower bounds for binary constant-dimension
subspace codes. Exp. Math. 1–5 (2016). https://doi.org/10.1080/10586458.2016.1239145
22. M. Braun, J. Reichelt, q-analogs of packing designs. J. Comb. Des. 22(7), 306–321 (2014).
https://doi.org/10.1002/jcd.21376
23. M. Braun, A. Wassermann, Disjoint q-Steiner systems in dimension 13 Universität Bayreuth,
Bayreuth, Technical Report (2017)
24. S. Braun, Algorithmen zur computerunterstützten Berechnung von q-Analoga kombina-
torischer Designs. Diplomathesis Universität Bayreuth (2009)
25. P.J. Cameron, Generalisation of Fisher’s inequality to ﬁelds with more than one element. eds.
by T.P. McDonough, V.C. Mavron. Combinatorics - Proceedings of the British Combinatorial
Conference 1973, London Mathematical Society Lecture Note Series, vol. 13 (Cambridge
University Press, Cambridge, 1974), pp. 9–13. https://doi.org/10.1017/CBO9780511662072.
003
26. P.J. Cameron, Locally symmetric designs. Geom. Dedicata 3, 65–76 (1974)

242
M. Braun et al.
27. P.J. Cameron, W.M. Kantor, 2-transitive and antiﬂag transitive collineation groups of
ﬁnite projective spaces. J. Algebra 60(2), 384–422 (1979). https://doi.org/10.1016/0021-
8693(79)90090-5
28. Y.M. Chee, C.J. Colbourn, S.C. Furino, D.L. Kreher, Large sets of disjoint t-designs. Australas.
J. Comb. 2, 111–119 (1990)
29. C.J. Colbourn, J.H. Dinitz, in Handbook of Combinatorial Designs, 2nd edn, Discrete Mathe-
matics and Its Applications. (Chapman and Hall/CRC , 2006)
30. M. De Boeck, A. Naki´c, Necessary conditions for the existence of 3-designs over ﬁnite ﬁelds
with nontrivial automorphism groups. ArXiv e-prints arXiv:1509.09158 (2015)
31. P. Delsarte, Association schemes and t-designs in regular semilattices. J. Comb. Theory Ser.
A 20(2), 230–243 (1976). https://doi.org/10.1016/0097-3165(76)90017-0
32. P. Dembowski, Verallgemeinerungen von Transitivitätsklassen endlicher projektiver Ebenen.
Math. Z. 69, 59–89 (1958)
33. P. Dembowski, Finite Geometries: Reprint of the 1968 Edition. (Springer, 2012)
34. T. Etzion, A. Vardy, On q-analogs of Steiner systems and covering designs. Adv. Math. Com-
mun. 5(2), 161–176 (2011). https://doi.org/10.3934/amc.2011.5.161
35. T. Etzion, A. Vardy, Automorphisms of codes in the Grassmann scheme. ArXiv e-prints
arXiv:1210.5724 (2012)
36. A. Fazeli, S. Lovett, A. Vardy, Nontrivial t-designs over ﬁnite ﬁelds exist for all t. J. Comb.
Theory Ser. A 127, 149–160 (2014)
37. T. Feulner, The automorphism groups of linear codes and canonical representatives of their
semilinear isometry classes. Adv. Math. Commun. 3(4), 363–383 (2009). https://doi.org/10.
3934/amc.2009.3.363
38. T. Feulner, Canonical forms and automorphisms in the projective space (2013)
39. T. Feulner, Eine kanonische Form zur Darstellung äquivalenter Codes – Computergestützte
Berechnung und ihre Anwendung in der Codierungstheorie, Kryptographie und Geometrie.
Ph.D. thesis, Universität Bayreuth (2013)
40. P. Frankl, V. Rödl, Near perfect coverings in graphs and hypergraphs. Eur. J. Comb. 6(4),
317–326 (1985)
41. M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-
Completeness (W.H Freeman and Company, New York, 1979)
42. P.B Gibbons, P.R.J Östergård, in Computational methods in design theory,eds. by C.J. Col-
bourn, J.H. Dinitz. Handbook of Combinatorial Designs, 2 edn., chap. VII.6, (Chapman and
Hall/CRC, 2007), pp. 755–783
43. I. Gurobi Optimization, Gurobi optimizer reference manual (2016), http://www.gurobi.com
44. E. Haberberger, A. Betten, R. Laue, Isomorphism classiﬁcation of t-designs with group theo-
retical localisation techniques applied to some Steiner quadruple systems on 20 points. Congr.
Numer. 75–96 (2000)
45. D. Heinlein, M. Kiermaier, S. Kurz, A. Wassermann, Tables of subspace codes. ArXiv e-prints
arXiv:1601.02864 (2016)
46. C. Hering, Transitive linear groups and linear groups which contain irreducible subgroups of
prime order. Geom. Dedic. 2(4), 425–460 (1974). https://doi.org/10.1007/BF00147570
47. C. Hering, Transitive linear groups and linear groups which contain irreducible sub-
groups of prime order. II. J. Algebra 93(1), 151–164 (1985). https://doi.org/10.1016/0021-
8693(85)90179-6
48. H. Hitotumatu, K. Noshita, A technique for implementing backtrack algorithms and its applica-
tion. Inf. Process. Lett. 8(4), 174–175 (1979). https://doi.org/10.1016/0020-0190(79)90016-
4
49. B. Huppert, Endliche Gruppen I, in Grundlehren der mathematischen Wissenschaften, vol. 134
(Springer, Heidelberg, 1967)
50. IBM:
ILOG
CPLEX
Optimizer
(2010),
http://www-01.ibm.com/software/integration/
optimization/cplex-optimizer/
51. M. Kaib, H. Ritter, Block reduction for arbitrary norms Universität Frankfurt, Preprint (1995)

Computational Methods in Subspace Designs
243
52. R.M. Karp, Reducibility among combinatorial problems, eds. by R.E. Miller, J.W. Thatcher,
J.D. Bohlinger. Complexity of Computer Computations: Proceedings of a symposium on the
Complexity of Computer Computations, March 20–22, 1972, (Springer, Boston, 1972), pp.
85–103. https://doi.org/10.1007/978-1-4684-2001-2_9
53. P. Kaski, P.R. Östergård, Classiﬁcation Algorithms for Codes and Designs (Springer, Berlin,
2006). https://doi.org/10.1007/3-540-28991-7
54. P. Kaski, O. Pottonen, libexact user’s guide version 1.0. Technical Report 2008-1, Helsinki
University of Technology (2008)
55. M. Kiermaier, S. Kurz, A. Wassermann, The order of the automorphism group of a binary
q-analog of the fano plane is at most two. Designs, Codes and Cryptography (2017). To appear
https://doi.org/10.1007/s10623-017-0360-6
56. M. Kiermaier, M.O. Pavˇcevi´c, Intersection numbers for subspace designs. J. Comb. Des. 23(11),
463–480 (2015). https://doi.org/10.1002/jcd.21403
57. Klin, M.H.: Investigations of algebras of invariant relations of certain classes of permutation
groups. Ph.D. thesis, Nikolaev (1974). In russian
58. D.E. Knuth, Estimating the efﬁciency of backtrack programs. Math. Comp. 29(129), 121–136
(1975)
59. D.E Knuth, Dancing links, eds. by A.W. Roscoe, J. Davies, J. Woodcock. Millennial perspec-
tives in computer science, Cornerstones of computing, (Palgrave, 2000), pp. 187–214
60. D.E. Knuth, The art of computer programming, vol. 4A (Addison-Wesley, New Jersey, 2011)
61. D.E Knuth, Dancing links. Technical Report Fasc 5c, Stanford University (2017)
62. M. Koch, Neue Strategien zur Lösung von Isomorphieproblemen. Ph.D. thesis, University of
Bayreuth, Germany (2016)
63. A. Kohnert, S. Kurz, Construction of large constant dimension codes with a prescribed min-
imum distance, eds. by J. Calmet, W. Geiselmann, J. Müller-Quade. Mathematical Methods
in Computer Science: Essays in Memory of Thomas Beth, (Springer, Heidelberg, 2008), pp.
31–42. https://doi.org/10.1007/978-3-540-89994-5_4
64. R. Kötter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579–3591 (2008). https://doi.org/10.1109/TIT.2008.926449
65. E.S. Kramer, D.M. Mesner, t-designs on hypergraphs. Discret. Math. 15(3), 263–296 (1976).
https://doi.org/10.1016/0012-365X(76)90030-3
66. D.L. Kreher, S.P. Radziszowski, The existence of simple 6-(14, 7, 4) designs. J. Comb. Theory
Ser. A 43, 237–243 (1986)
67. D.L. Kreher, S.P. Radziszowski, Constructing 6-(14,7,4) designs. Contemp. Math. 111, 137–
151 (1990)
68. V. Krˇcadinac, A. Naki´c, M.O. Pavˇcevi´c, The Kramer–Mesner method with tactical decompo-
sitions: some new unitals on 65 points. J. Comb. Des. 19(4), 290–303 (2011). https://doi.org/
10.1002/jcd.20277
69. J.C. Lagarias, A.M. Odlyzko, Solving low-density subset sum problems. J. Assoc. Comp.
Mach. 32, 229–246 (1985). Appeared already in Proc. 24th IEEE Symp. Found. Comp. Sci.
(1983), 1–10
70. R. Laue, Halvings on small point sets. J. Comb. Des. 7, 233–241 (1999)
71. R. Laue, Constructing objects up to isomorphism, simple 9-designs with small parameters, in
Algebraic Combinatorics and Applications, (Springer, New York, 2001), pp. 232–260
72. R. Laue, Solving isomorphism problems for t-designs, ed by W.D. Wallis. Designs 2002:
Further Computational and Constructive Design Theory (Springer US, Boston, MA , 2003),
pp. 277–300. https://doi.org/10.1007/978-1-4613-0245-2_11
73. R. Laue, S. Magliveras, A. Wassermann, New large sets of t-designs. J. Comb. Des. 9, 40–59
(2001)
74. R. Laue, G.R. Omidi, B. Tayfeh-Rezaie, A. Wassermann, New large sets of t-designs with
prescribed groups of automorphisms. J. Comb. Des. 15(3), 210–220 (2007). https://doi.org/10.
1002/jcd.20128
75. A.K. Lenstra, H.W. Lenstra Jr., L. Lovász, Factoring polynomials with rational coefﬁcients.
Math. Ann. 261, 515–534 (1982)

244
M. Braun et al.
76. M.W. Liebeck, The afﬁne permutation groups of rank three. Proc. Lond. Math. Soc. (3) 54(3),
477–516 (1987). https://doi.org/10.1112/plms/s3-54.3.477
77. S.S Magliveras, The subgroup structure of the Higman-Sims simple group. Ph.D. thesis, Uni-
versity of Birmingham (1970)
78. R. Mathon, Computational methods in design theory, ed. by A.D. Keedwell. Surveys in combi-
natorics, Proceeding 13th Br. Combinatorial Conference, London Mathematical Society Lec-
ture Notes, vol. 166 (Guildford/UK, 1991), pp. 101–117
79. R. Mathon, Searching for spreads and packings, eds by J.W.P. Hirschfeld, S.S. Magliveras, M.J.
de Resmini. Geometry, Combinatorial Designs and Related Structures, Proceedings of the ﬁrst
Pythagorean conference, Mathematical Society Lecture Notes, vol. 245, (London, 1997), pp.
161–176
80. B.D.McKay,A.Piperno,Practicalgraphisomorphism,II.J.Symb.Comput. 60,94–112(2014).
https://doi.org/10.1016/j.jsc.2013.09.003
81. M. Miyakawa, A. Munemasa, S. Yoshiara, On a class of small 2-designs over GF(q). J. Comb.
Des. 3(1), 61–77 (1995). https://doi.org/10.1002/jcd.3180030108
82. E.H. Moore, Tactical memoranda i-iii. Am. J. Math. 18(4), 264–303 (1896)
83. A. Naki´c, M.O. Pavˇcevi´c, Tactical decompositions of designs over ﬁnite ﬁelds. Des. Codes
Cryptogr. 77(1), 49–60 (2015). https://doi.org/10.1007/s10623-014-9988-7
84. P.Q Nguyen, B. Vallée, in The LLL Algorithm: Survey and Applications, 1st edn. Information
Security and Cryptography. (Springer, Heidelberg, 2009). https://doi.org/10.1007/978-3-642-
02295-1
85. S. Niskanen, P.R.J Östergård, Cliquer user’s guide, version 1.0. Technical Report T48, Helsinki
University of Technology (2003)
86. E.T. Parker, On collineations of symmetric designs. Proc. Am. Math. Soc. 8(2), 350–351 (1957).
http://www.jstor.org/stable/2033742
87. W. Pullan, Optimisation of unweighted/weighted maximum independent sets and minimum
vertex covers. Discret. Optim. 6(2), 214–219 (2009). https://doi.org/10.1016/j.disopt.2008.12.
001
88. J.F. Sarmiento, Resolutions of PG(5, 2) with point-cyclic automorphism group. J.
Comb. Designs 8(1), 2–14 (2000). https://doi.org/10.1002/(SICI)1520-6610(2000)8:1<2::
AID-JCD2>3.0.CO;2-H
89. B. Schmalz, t-Designs zu vorgegebener automorphismengruppe. Bayreuth. Math. Schr 41,
1–164 (1992). Ph.D thesis, Universität Bayreuth
90. C.P Schnorr, M. Euchner, Lattice basis reduction: Improved practical algorithms and solving
subset sum problems, in Proceedings of Fundamentals of Computation Theory ’91, Lecture
Notes in Computer Science, vol. 529, (Springer, Heidelberg, 1991), pp. 68–85
91. H. Suzuki, On the inequalities of t-designs over a ﬁnite ﬁeld. Euro. J. Comb. 11(6), 601–607
(1990). https://doi.org/10.1016/S0195-6698(13)80045-5
92. S. Thomas, Designs over ﬁnite ﬁelds. Geom. Dedic. 24(2), 237–242 (1987). https://doi.org/
10.1007/BF00150939
93. R.J. Walker, An enumerative technique for a class of combinatorial problems. Proc. Sympos.
Appl. Math. 10, 91–94 (1960). American Mathematical Society, Providence, R.I. (1960)
94. A.Wassermann,Findingsimplet-designswithenumerationtechniques.J.Comb.Des.6(2),79–
90 (1998). https://doi.org/10.1002/(SICI)1520-6610(1998)6:2<79::AID-JCD1>3.0.CO;2-S
95. A. Wassermann, Covering the Aztec diamond with one-sided tetrasticks. Bull.Inst. Comb. Appl.
(ICA) 32, 70–76 (2001)
96. A. Wassermann, Attacking the market split problem with lattice point enumeration. J. Comb.
Optim. 6(1), 5–16 (2002)
97. J. Zwanzger, A heuristic algorithm for the construction of good linear codes. IEEE Trans. Inf.
Theory 54(5), 2388–2392 (2008). https://doi.org/10.1109/TIT.2008.920323

Part III
Application of Network Coding

Index Coding, Network Coding
and Broadcast with Side-Information
Eimear Byrne and Marco Calderini
Abstract Index coding, the problem of efﬁcient broadcast to many receivers with
side-infomation, is a rich and active research area. It has applications to a range of
multi-user broadcast scenarios such as video-on-demand and satellite communica-
tions. It has attracted signiﬁcant theoretical interest both as a hard problem in its
own right and due to its connections to other network capacity problems. The central
problem of index coding, that of determining the optimal rate of an index code, is
still open. We describe recent advances on the index coding problem and its general-
izations in the context of broadcast with side-information. The two main approaches
to bounding the optimal rate of an index code, namely rank-minimization methods
and linear programming models, are discussed in detail. The latter of these, based on
graph-theoretical ideas in the classical case, can be extended even to generalizations
of the index coding problem for which there is no associated side-information hyper-
graph. We discuss error-correction in the index coding problem, the corresponding
bounds on the optimal transmission rate and decoding algorithms. We also illustrate
the connections to network coding, interference alignment and coded caching.
1
Introduction
Broadcast with side-information describes a number of problems in network informa-
tion theory, including index coding, network coding, coded caching and interference
alignment. The equivalences and connections between these different topics has been
observed in the literature [18, 19, 27, 28]. The problem has several applications, such
as for satellite communications, distribution of media ﬁles (eg. video-on-demand),
topological interference alignment and distributed caching.
E. Byrne (B)
School of Mathematics and Statistics, University College Dublin, Dublin, Ireland
e-mail: ebyrne@ucd.ie
M. Calderini
Deptartment of Mathematics, University of Trento, Trento, Italy
e-mail: marco.calderini@unitn.it
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_10
247

248
E. Byrne and M. Calderini
Thecanonicalexampleofthebroadcastwithside-informationproblemisprovided
by index coding and is the main focus of this chapter. Birk and Kol in [6] introduced
the index coding (with side-information) problem as an aspect of informed source
coding on demand. One of ﬁrst appearances of the term ‘index coding’ was in [2].
It relates to a problem of source coding with side-information, in which receivers
have partial information of a broadcast prior to its transmission. The problem for the
sender is to exploit knowledge of the users’ side-information in order to optimize
the transmission rate. The problem has since become a subject of several studies and
generalizations, including error-correction, privacy and secrecy [1, 3–5, 12–14].
The index coding problem may be described informally as follows. A single
sender has a set of data packets. There is a set of some m clients each of whom
already possesses some packets of the sender’s data. Each receiver sends a request
to the sender for a single packet and these requests may differ from client to client.
The task for the sender is to satisfy all users’ demands using a minimum number of
transmissions. If the sender only transmits uncoded data packets, then the number of
transmissions required is simply the number of different requests of all users, and all
users will receive the requests of the other users. However, if data coding is permitted,
that is if the broadcaster transmits functions of its packets, then the number of required
transmissions can be greatly reduced. The main problem of index coding is the
determination of this minimum transmission rate, or the minimum number of packet
transmissions required by the sender in order to satisfy all users’ requests. Given an
ICSI instance, we also seek to obtain an explicit optimal encoding function, which is
computationally very hard. Therefore we seek bounds on the optimal transmission
rate and algorithms that generate good but possibly sub-optimal encoding functions.
It was shown in [2] that the best rate of a scalar linear binary index code is char-
acterized by the minrank of a graph, which is NP-hard to compute [29]. Clearly, any
encoding function for an instance necessarily gives an upper bound on the optimal
length of an index code for that instance. There have been a number of papers address-
ing this aspect of the problem, in fact ﬁnding sub-optimal but feasible solutions, using
linear programming methods to obtain partitions of the users into solvable subsets.
Such solutions involve obtaining clique covers, partial-clique covers, multicast par-
titions and some variants of these [5, 30, 33, 36]. Other than these LP approaches,
low-rank matrix completion methods may also be applied. This was considered for
index coding over the real numbers in [22], but the problem is essentially still open
for index coding over ﬁnite ﬁelds.
In Sect.2 we describe the general problem of broadcast with side information.
This is a problem with two fundamental aspects, namely that of delivery and place-
ment. The delivery problem is essentially a generalization of index coding, while the
placement problem is a generalized coded-caching problem. In Sect.3 we introduce
the classical index coding problem and describe the known efforts to estimate the
optimal transmission rate for an arbitrary instance, including approaches from graph
theory and algebraic approaches. In Sect.4 we describe a generalized version of the
index coding problem, namely that for coded side-information. We outline how many
of the graph-theoretic bounds can be extended to this more general case. In addition,
we consider the problem of error correction, when the sender’s transmission is sub-

Index Coding, Network Coding and Broadcast with Side-Information
249
ject to noise. We give bounds on the transmission rate in this context and describe a
decoding method for Hamming like errors. Finally, in Sect.5 we discuss connections
of the classical index coding problem to other problems of network communications,
such as its equivalence to network coding, relation to interference alignment and to
the coded-caching problem.
1.1
Notation
For any positive integer n, we let [n] := {1, . . . , n}. We write Fq to denote the ﬁnite
ﬁeld of order q and use Fn×t
q
to denote the vector space of all n × t matrices over Fq.
Given a matrix X ∈Fn×t
q
we write Xi and X j to denote the ith row and jth column
of X, respectively. More generally, for subsets S ⊂[n] and T ⊂[t] we write XS
and XT to denote the |S | × t and n × |T | submatrices of X comprised of the rows
of X indexed by S and the columns of X indexed by T respectively. We write ⟨X⟩
to denote the row space of X.
2
Broadcast with Side-Information
We present a general scenario, by which we deﬁne an instance of the broadcast with
side-information problem over Fq. The main ingredients are as follows.
• There is a single sender and m receivers (or users).
• X ∈Fn×t
q
is the uncoded data held by the sender.
• User i has side information (V (i), V (i)X), for some matrix V (i) ∈Fvi×n
q
of rank vi.
• User i has request matrix Ri, for some Ri ∈Fri×n
q
of rank ri.
• User i demands the request packet Ri X ∈Fri×t
q
.
The task of the sender is to ensure that each user i can combine its side-information
with the sender’s broadcast to decode to its demanded packet Ri X. We assume that
each ith user can generate all linear combinations of the rows of V (i), so it effectively
possesses this vi-dimensional space. The sender, after receiving each request Ri, may
send Y ∈FN×t
q
, a function of X, say Y = E(X) for some map E : Fn×t
q
−→FN×t
q
.
We say that the encoding E realizes a length N code for this problem if indeed each
user can retrieve its demand Ri X for any source data matrix X, given knowledge
of E, Y, V (i), V (i)X. Therefore, the source data matrix X should be thought of as
a variable of the above instance. Unless stated otherwise, we will assume that E is
Fq-linear, so that for all X, E(X) = L X for some N × n matrix L over Fq. Then we
say that L realizes the given instance if each user can retrieve its demand Ri X for
any source data matrix X, given knowledge of L, Y = L X, V (i), V (i)X. If such an
L exists, we say that the length N is achievable for the given instance. Finding such
an L (and indeed the length N) is computationally hard and the central problem of
broadcast with side-information.

250
E. Byrne and M. Calderini
User i can retrieve its demand Ri X, for all possible choices of X if and only if
there exist matrices Ai, Bi satisfying
Ri = AiV (i) + Bi L,
(1)
from which it computes Ri X, knowing V (i)X (as its side information) and L X (which
was transmitted) [4]. It is generally assumed that a user does not demand Ri X if it
already has it in its cache. Therefore, we assume that no row of Ri is contained in
the row space of V (i).
Remark 1 The uncoded downlink cost is nt, which is the cost of sending the full data
matrix X. The total coded downlink cost is N(n + t), which is the cost of transmitting
L and Y = L X. Therefore there is a coding gain only if t >
Nn
n−N .
We now describe this in terms of a matrix code. First let r = m
j=1 r j and let R
be the r × n matrix
R = [RT
1 , RT
2 , ..., RT
m]T .
We call R the request matrix. For each i, let
Ci = {AV (i) : A ∈Fri×vi
q
} ⊂Fri×n
q
.
Ci is a vector space of ri × n matrices for the scalars Fq. It can be thought of as ri
copies of the length n linear code generated by the rows of V (i). Now deﬁne
C =

[U T
1 ,U T
2 , ...,U T
m ]T : Ui ∈Ci

⊂Fr×n
q
,
which is a vector space of r × n matrices for the scalars Fq.
We say that the pair (C , R) is an instance of the broadcast with side-information
problem and we call the matrix code C the side-information code of the instance.
The problem of determining the optimal code length of the instance (C , R) and a
corresponding encoding matrix L is a delivery problem.
It can be shown, using (1), that the minimum length of a code for (C , R) is
κ(C , R) := min{rank(R + C) : C ∈C },
which is called the minrank of the instance (R, C ) [4]. The block length t does not
affect the minrank parameter, however, due to overhead transmission costs, the gains
of coding are greater as t increases. The set R + C := {R + C : C ∈C } is a coset
or translate of C , so κ(R + C ) is the minimum rank of any member of this coset.
It is also the rank distance of the matrix R to the side information code C . This
generalizes the minrank of a side-information graph or hypergraph, as it arises in the
index coding problem (cf. [3, 4, 13, 25]). Implicit in this is the fact that any full-rank
matrix L that realizes the instance (C , R) can be obtained by rank-factorization of a
member of R + C . Note that

Index Coding, Network Coding and Broadcast with Side-Information
251
dim C =

i∈[m]
rivi
over Fq, so |R + C | = qs where s = 
i∈[m] rivi ≤rn.
For a given side-information code C , the sender can satisfy any set of requests in
at most
ρ(C ) := max{κ(C , R) : R ∈Fm×n
q
}
transmissions, which is the rank-metric covering radius of the code C . So if the
side-information code C has low covering radius, then all instances (C , R) require
a small number of transmissions.
This relates to a placement problem: that of determining side-information codes
C with least maximal minrank κ(C , R) for some ﬁxed set of request matrices R in
Fr×n
q
.
The delivery problem of broadcast with side-information is essentially the index
coding problem and its generalizations. The placement problem is central to coded-
caching. The main focus of this chapter will be an account of the former. We remark
that with respect to delivery, there is no loss of generality in assuming that each
request matrix Ri is a single row vector; for example, if the user m has 2 × n request
matrix Rm then the instance can be equivalently represented by one for which user m
is now represented by two users m and m + 1, each with the same side-information
Cm. User m’s request vector is the ﬁrst row of Rm and the request vector of user
m + 1 is the 2nd row of Rm. Observe that both instances are represented by the same
pair (R, C ), and have the same minrank.
3
Index Coding with Side-Information
We start with the classical index coding (ICSI) with side information problem. In
this case it is assumed that the side-information held by the users is uncoded, so each
user has a subset of the data packets held by the broadcaster, and each user requests a
single other packet from the sender. As we will see below, a prominent characteristic
of the ICSI problem is that it can be identiﬁed with a unique directed hypergraph.
The unique sender has a data matrix X ∈Fn×t
q
. There are m receivers, each with a
request for a data packet Xi, and it is assumed that each receiver has a subset of mes-
sages XX i, for a subset Xi ⊆[n]. The requested packets of the users are described by
a surjection f : [m] →[n], such that the packet requested by i is denoted by X f (i),
and it is assumed that f (i) /∈Xi for all i ∈[m]. With respect to this viewpoint, the
side-information and requested data are represented as subsets of [n], the index set of
the data matrix X. Hence the term index coding. This description (see [13]), is indeed
a special case of the broadcast with side-information problem as given in Sect.2. To
translate back to this setting, set the side information codes Ci to be generated by
matrices V (i) whose rows are standard basis vectors and the request matrices to be
the standard basis vectors Ri = e f (i).

252
E. Byrne and M. Calderini
S
U4
has x2
requests x1
U3
has x1,x2
requests x3
U1
has x3
requests x1
U2
has x1,x3
requests x2
(a) ICSI problem
1
2
3
U1
U4
U2
U2
U3
U3
(b) Side information hypergraph H
Fig. 1 The ICSI problem of Example 1
For the remainder, let us ﬁx t, m, n to denote those parameters as described
above. Then for any X = (X1, . . . , Xn), Xi ⊂[n] and map f : [m] →[n], the
corresponding instance of the ICSI problem (or the ICSI instance) is denoted by
I = (X , f ).
The index coding problem given by an instance I can be described by a
side-information (directed) hypergraph [1]. We deﬁne a directed hypergraph H =
(V , E ), where the set of vertices is V = [n]. Each vertex i of H corresponds to the
data packet Xi. The set E is composed by the hyper-edges of type ( f (i), Xi).
Example 1 Consider the ICSI instance with n = 3 (three messages), m = 4 (four
users), f (1) = 1, f (2) = 2, f (3) = 3, f (4) = 1, X1 = {3}, X2 = {1, 3}, X3 =
{1, 2}, and X4 = {2}. The hypergraph H that describes this instance has three ver-
tices 1, 2, 3, and has four hyperarcs. These are e1 = (1, {3}), e2 = (2, {1, 3}), e3 =
(3, {1, 2}), and e4 = (2, {2}). This hypergraph is depicted in Fig.1.
When m = n we assume that f (i) = i for all i ∈[n], and the corresponding side
information hypergraph has precisely n hyperarcs, each with a different origin vertex.
It is simpler to describe such an ICSI instance as a digraph G = ([n], E ), the so-
called side information (di)graph [2]. For each hyperarc (i, Xi) of H , are |Xi| arcs
(i, j) of G , for j ∈Xi. Equivalently, E = {(i, j) : i, j ∈[n], j ∈Xi}.
We now formally deﬁne what is meant by a code for an instance of the ICSI
problem.
Deﬁnition 1 Given an instance of the ICSI problem described by an hypergraph H .
Let N be a positive integer. We say that the map
E : Fn×t
q
→FN
q ,
is an Fq-code of length N for the instance described by H if for each i ∈[m] there
exists a decoding map
Di : FN
q × F|X i|
q
→Ft
q,

Index Coding, Network Coding and Broadcast with Side-Information
253
satisfying
∀X ∈Fn×t
q
: Di(E(X), XX i ) = X f (i),
in which case we say that E is an H -IC. E is called an Fq-linear I -IC if E(X) = L X
for some L ∈FN×n
q
, in which case we say that L represents the code E. If t = 1 it is
called scalar linear.
3.1
Bounding the Optimal Rate of the Index Coding Problem
Bar-Yossef et al. showed [2, 3] that (for a given ﬁeld size), the optimal length of
a scalar linear index code is equal to the minrank of the associate side-information
graph. The notion of minrank for an undirected graph G was ﬁrst considered by
Haemers [21] in 1978 to obtain a bound for the Shannon graph capacity.
Such a result was extended to the more general case with m ≥n in [13]. Therefore,
minrank characterizes the best possible scalar linear index code for a given ﬁnite ﬁeld.
Let p be a ﬁxed prime. The broadcast rate of an IC-instance I is deﬁned as
follows [1].
Deﬁnition 2 Let H be a side-information hypergraph. We denote by βt(H ) the
minimalnumberofsymbolsrequiredtorealizeanindexcodinginstanceI associated
to H for block length t, over all possible extensions of Fp. That is,
βt(H ) = inf
q {N | ∃a q-ary index code of length N for I }.
Moreover we denote by β(H ) the limit
β(H ) = lim
t→∞
βt(H )
t
= inf
t
βt(H )
t
.
In the following we will consider the scalar case, i.e. t = 1, moreover we report
the results on the minrank in the more general case of the hypergraphs.
3.1.1
Algebraic Methods
Deﬁnition 3 Let H be the side-information hypergraph of an instance of the IC
problem. A matrix M = (mi, j) ∈Fm×n
q
ﬁts the hypergraph if
mi, j =

1 if j = f (i)
0 if j does not lie in Xi

254
E. Byrne and M. Calderini
The min-rank of H over Fq is deﬁned to be
minrkq(H ) = min{rankq(M) : M ﬁts H }
Example 2 Consider the ICSI instance given in Example 1. Then we have that a
matrix M that ﬁts the hypergraph H is of type
M =
U1
U2
U3
U4
X1 X2 X3
⎡
⎢⎢⎣
1 0 ∗
∗1 ∗
∗∗1
1 ∗0
⎤
⎥⎥⎦
where the symbol “∗” may be replace by an arbitrary element of the ﬁeld Fq.
The following lemma speciﬁes a sufﬁcient condition on a matrix L to correspond
to a H -IC. This result was implicitly formulated by Bar-Yossef et al. [2, 3] for the
case where m = n, f (i) = i for all i ∈[n], and q = 2, then generalized to the case
m ≥n for any q by [13].
Let Supp(v) denotes the support of a vector v ∈Fn
q.
Lemma 1 A I (X , f )-IC of length N over Fq has a linear encoding map if and
only if there exists a matrix L ∈FN×n
q
such that for each i ∈[m], there exists a vector
u(i) ∈Fn
q satisfying
Supp(u(i)) ⊆Xi
(2)
u(i) + e f (i) ∈⟨L⟩.
(3)
The lemma above implies the existence of a vector b(i) ∈FN
q such that b(i)L =
u(i) + e f (i), in which case the receiver at i retrieves
x f (i) = e f (i)X = b(i)L X −u(i)X = b(i)Y −u(i)XX i,
(4)
where Y is the message sent by the source over the broadcast channel.
As consequence we obtain the following
Theorem 1 Let I = (X , f ) be an instance of the ICSI problem, and H its
side information hypergraph. Then the optimal length of a q-ary linear H -IC is
minrkq(H ).
Therefore, min-rank characterizes the best possible scalar linear index code for a
given ﬁnite ﬁeld.
Theorem 2 Let H be a side-information hypergraph, for any q we have
β(H ) ≤minrkq(H ).

Index Coding, Network Coding and Broadcast with Side-Information
255
Example 3 Consider the instance given by Example 1. It is easy to check that a
matrix that ﬁts the hypergraph has at least rank 2 (see Example 2). Thus
M =
⎡
⎢⎢⎣
1 0 1
1 1 0
1 0 1
1 1 0
⎤
⎥⎥⎦
achieves the minimum rank possible 2. Now if we consider 2 linear independent
rows of M, suppose
L =
 1 0 1
1 1 0

.
Take into account receiver 1, that requested X1 and knows X3. Encoding X with L
we obtain
L X = [X1 + X3, X1 + X2]T .
So, deleting X3 from X1 + X3 receiver 1 obtain X1. Similarly for the other receivers.
Thus, do ﬁnd an encoded matrix we need to select the linear independents rows
of a ﬁtting matrix of the hypergraph.
The authors of [2] proved that in various cases, linear codes are optimal, so their
main conjecture was that linear index coding is always optimal, that is β(G ) =
minrk2(G ) for any graph G . This conjecture was later disproved by Lubetzky and
Stav in [26]. The authors show that for any positive ε > 0 there exist graphs, of
order n, where every linear index code requires at least n1−ε bits, whereas a given
non-linear index code utilizes only nε bits.
However, as shown by Peeters [29], computing the minrank of a general graph
is a hard task. More speciﬁcally, Peeters showed that deciding whether a graph has
min-rank three is an NP-complete problem.
DuetotheresultgiveninTheorem1,wehavethattheproblemofﬁndalinearindex
code is equivalent to a rank minimization problem over a ﬁnite ﬁeld. An approach
to the minimum rank matrix completion problem over ﬁnite ﬁelds representing the
linear index coding problem was studied in [17].
In [17] ﬁrst the complete sub-matrix of highest rank is identiﬁed, using a heuristic
scheme of polynomial complexity and then by using row (column) projection to
expand the complete sub-matrix iteratively. The goal of the projection step is to ﬁnd
possible completions of an incomplete row or column such that they are in the span of
the complete sub-matrix. The steps of row and column projections are administered
over a decision tree.
To identify the maximal complete sub-matrix of M of highest rank, a heuristic
algorithm, starting with an initial complete sub-matrix, tries to improve it iteratively.
The row-improving step is performing in the following way, supposing that we
have the complete sub-matrix M J
I :

256
E. Byrne and M. Calderini
• Let ¯I = [m] \ I, select a row of M J
¯I with fewer erasures (that is, stars “∗”).
• Suppose i is selected, consider M J
I∪{i} and remove the incomplete columns in it.
• If the rank of the resulting matrix is greater than M J
I , update the select I and J.
A similar approach is applied to improve the set of columns.
Data: Incomplete matrix M
Result: I, J such that the complete sub-matrix M J
I is of maximal rank
I ←{1, ..., m};
J ←∅;
k ←0;
N ←100;
while No change detected over N iterations in sequence do
th ←|I|/(|I| + |J|);
if rand([0, 1]) > th then
perform rows improvement
else
perform columns improvement
end
M′ ←the matrix obtain from the improvement;
if rk(M′) > k then
Update I and J
end
end
Algorithm 1: Complete sub-matrix
It is preferred to identify the maximal complete sub-matrix of highest rank within
the matrix M, however we can proceed to the subsequent steps for matrix completion
even with a sub-optimal choice. Thus, we may limit the number of iterations in
Algorithm 1 to N iterations.
The completion of the matrix M is done by alternating projection steps on rows
and columns. The goal of this step is to ﬁnd possible completions of an incomplete
row (column) such that it in the span of the complete sub-matrix. The row and column
projections are administered over a decision tree.
Here we describe the horizontal projection (that is, on the rows) in a branch. It is
similar for the columns. There are three possible cases (Fig.2).
1. There are one or more incomplete rows that may be completed in a unique way in
the subspace spanned by the rows of the current complete sub-matrix. In this case
we complete these rows and update the complete sub-matrix. Then we switch the
projection direction over the next branch.
2. There is no row that may be completed uniquely, but there are some rows that
are in the subspace spanned by the rows of the complete sub-matrix. In this case,
we choose the incomplete row with minimum possible solutions. Then, for each
solution we analyze the consequent matrix completion, over multiple subsequent
branches, continuing the procedure in the alternate direction of projection.

Index Coding, Network Coding and Broadcast with Side-Information
257
Fig. 2 A sample structure
for the decision tree
3. The last case is when no row can be completed with a vector of the span of
the complete sub-matrix. Thus, the rank of the solution is to be increased. If the
increased rank is larger than the rank of the previously completed branches, the
current branch is eliminated; otherwise, all the possible solutions are examined
over multiple subsequent branches.
Step 2, described above, can be performed using erasure decoding techniques. Con-
sider a generator matrix G of the code spanned by the complete submatrix and its
parity check matrix H. Then suppose to have selected the row Mi restricted to the
column of the complete sub-matrix (the symbols stars now represent our variables).
We verify the solution of the system Mi · H = 0.
At each iteration, the branch with ‘maximum opportunity’ is selected, which
is quantiﬁed by a metric deﬁned by the ratio of the completion percentage of the
matrix with respect to the rank of its complete sub-matrix. The branch with minimum
achieved rank identiﬁes the solution.
Note that the growth of the tree due to a rank increment, that is the number of
new branches, is bounded above by qe, where e is the maximum number of erasures
that we have in the rows or in the columns. Moreover, in a path of the tree we could
increment the rank at most minrk(H ) −k times, where k is the rank of the starting
complete submatrix.
Furthermore, the growth due to the multiple allowed combinations for completing
a row or (column) is bounded above by qmax(n,m)−k for each projection.
For large incomplete matrices the authors in [17] propose a sub-optimum algo-
rithm. Speciﬁcally, whenever the number of branches goes beyond a pre-set thresh-
old, we prune the branches having a small value with respect to the metric described
above.
In [31] the authors propose a linear algebraic algorithm to complete M (over F2)
given a random subset of its entries. They establish some conditions on the row and
column spaces of M which guarantee that the algorithm runs in polynomial time.
Moreover a linear programming-based extension is proposed.
In particular, given a matrix M ∈Fn×n
2
of rank r and a random subset of its
entries Ω, we can complete successfully M with high probability in time O(n2r+3),
whenever the cardinality of the set Ω is at least 
Ω

n2−
1
r+1

.

258
E. Byrne and M. Calderini
Data: Incomplete matrix M
Result: Complete matrix with minimum possible rank
Find maximal complete sub-matrix M J
I ;
while incomplete branches > 0 do
Choose the branch with maximum opportunity;
Perform projection in the proper direction;
Based on projection results add more branches or
eliminate current one if necessary ;
if matrix is complete in this branch then
if achieved rank < minimum achieved rank then
Update minimum achieved rank
end
end
end
Algorithm 2: Complete matrix
There have been several hardness results for matrix completion over ﬁnite ﬁelds.
Tan et al. [34] studied the more general problem where, instead of entries, random
linear combinations of the entries are observed. They give various information-
theoretic bounds on the number of measurements necessary for low rank matrix
recovery.
The matrix completion problem over the reals seems to behave rather differently
and techniques do not appear to transfer to the ﬁnite ﬁeld case. A method for matrix
completion over the real numbers is given in [22]. Note that linear index codes
over the reals have applications to topological interference management in wireless
networks [23, 27].
The method developed in [22] is based on an alternating projection (AP) approach.
As it is shown in the paper, completing the index coding matrix M by choosing values
for the symbols “∗” such that M has a low rank r can be thought of as ﬁnding the
intersection of two regions C and D in Rn×n deﬁned by,
C = {M ∈Rn×n | rk(M) ≤r},
and
D = {M ∈Rn×n | mi j = 0 if (i, j) ∈E (G ) and mii = 1, i ∈[n]}.
C is not convex and therefore convergence of the AP method is not guaranteed.
However, the AP method can give a certiﬁcate that a certain rank r is achievable.
Therefore we can use the AP method as a heuristic. This AP method, in some cases,
leads to up to 13% average savings in broadcast messages compared to graph coloring
(see next section).
The authors in [22] compare the AP methods also to the well studied Alternating
Minimization (AltMin) algorithm [20, 41, 42]. Jain et al. [41] gave one of the ﬁrst
performance guarantees of AltMin, in particular the authors proved that by observing
|Ω| = O

σ1
σr n log n log(r||M||F/ε)

random entries of an incoherent M, AltMin

Index Coding, Network Coding and Broadcast with Side-Information
259
can recover M in O(log(1/ε)) steps. Here σ1 and σr denote the largest and smallest
singular values of M, respectively, and || · ||F is the Frobenius norm. However in this
context the authors in [22] show that AltMin does not perform as well as AP.
Candès and Recht in [10] showed that replacing the rank function by the nuclear
norm leads to ﬁnding the minimum rank with high probability (under certain condi-
tions). However, these results do not carry over directly to the index coding problem
because the model in [10] assumes the location of the ﬁxed entries is chosen uni-
formly at random. In the index coding problem the matrix M has a speciﬁc structure,
that is, all the diagonal entries have to be equal to one. Indeed, as noted in [22] the
approach in [10] always output the maximum rank n.
In the analysis of the performance of these algorithms it is always assumed that
the set Ω is given at random. However, in the index coding problem, also in the case
of random graph, the diagonals entries are ﬁxed to one, so it is not guaranteed that
this algorithms performs well.
3.1.2
Graph Theoretic Methods
Graph theoretic methods start from the well-known fact that all the users forming a
clique in the side information digraph can be simultaneously satisﬁed by transmitting
the XOR of their packets. Indeed, for such a graph we have that Xi = [n] \ {i}. Thus
sending Y = 
i Xi, any receiver retrieves its requested packet.
Moreover, from the fact that for a graph G that is a union of disjoint graphs,
i.e. G = G1 ∪· · · ∪Gs, it holds that minrk(G ) = 
i minrk(Gi), we have that an
achievable scheme for index coding on graphs is the number of disjoint cliques
required to cover G [2]. This number is called the clique-covering number cc(G ),
which is equal to the chromatic number of the complement graph χ(G ). This is
because all the vertices assigned to the same color cannot share an edge and hence
must form a clique on the complement graph.
In [2] the authors prove that for an acyclic graph G of order n the optimal broadcast
rate is n. Therefore if α(G ) is the order of the maximum acyclic induced subgraph of
G then α(G ) ≤β(G ). In particular, when G is symmetric, α(G ) is the independence
number of G . These two results give the so-called sandwich property on the optimal
broadcast rate.
Theorem 3 ([2])
α(G ) ≤β(G ) ≤cc(G ).
Example 4 Consider the graph G in Fig.3. We can see that any clique partition of
G is composed of at least 3 cliques, e.g. {{1, 2}, {3, 4}, {5}}. Thus cc(G ) = 3, and an
encoded scheme for the instance associated to G is Y = [X1 + X2, X3 + X4, X5].
An other scheme given in [2] is based on the concept of partial-clique.
Deﬁnition 4 A graph G is called a k-partial clique if for all node i we have
degOut(i) ≥n −k −1 and there exists at least one node for which the equality

260
E. Byrne and M. Calderini
Fig. 3 The graph G of
Example 4
1
2
3
4
5
holds. Here degOut(i) denotes the out-degree of the node i, that is, the edges outgo-
ing from i.
Note that a 0-partial clique is a usual clique.
The nodes contained in a partial clique correspond to a set n of clients, each
missing at most k packets of the n −1 packets requested by the other receivers of the
set, and at least one client missing exactly k of those blocks. To satisfy the requests
of a k-partial clique we can use an (n, k + 1)-MDS code, e.g. Reed-Solomon codes.
Indeed suppose G is generator matrix, over a sufﬁcient large ﬁeld, of an MDS code
of length n and dimension k + 1. Now we can broadcast the message Y = GX. Now
any receiver is able to delete at least n −k −1 columns of G from Y. So since every
set of k + 1 columns of G are linearly independent, we can retrieve the requested
packet. So, instead of partitioning a graph in clique we can use partial-clique.
Theorem 4 ([2]) Let G a side-information graph and let G1, ..., Gr be a partition in
partial clique whose parameters are k1, ..., kr. Then
β(G ) ≤
r

i=1
ki + 1.
Example 5 Consider the instance given by the side information graph G in Fig.4.
We can see that using the scheme based on the clique cover we need 3 transmissions.
Using the partial clique scheme we can use 2 transmissions. In fact each receiver
knows one packet, so G is a 1-partial clique. Consider the matrix
G =
 1 0 1
0 1 1

Fig. 4 The graph G of
Example 5
1
2
3

Index Coding, Network Coding and Broadcast with Side-Information
261
which represents a (3, 2)-MDS code over F2. We can encode X = [X1, X2, X3]T
using G,thatisY = GX = [X1 + X3, X2 + X3].Itiseasytocheckthateachreceiver
can retrieve the requested packet.
It turns out that the idea based on partitioning with cliques leads to a family of
stronger bounds, starting with an LP relaxation called the fractional clique covering
number. It can be readily checked that this rate is the solution to the integer program
min

C∈C
yC
s.t.

C: j∈C
yC = 1 for all j ∈[n]
yC ∈{0, 1} for all C ∈C .
(5)
where C is the collection of all cliques in G .
Blasiak, Kleinberg, and Lubetzky [7] extended the clique covering bound to the
fractional clique covering bound, namely, the solution to the linear program obtained
by relaxing the integer constraint yC ∈{0, 1} to yC ∈[0, 1] in (5). This scheme
corresponds to an achievable (vector-linear) index code.
Example 6 Consider the graph G given in Example 4. A possible fractional partition
of the nodes is given by {{1, 2}, {2, 3}, {3, 4}, {4, 5}, {5, 1}}. Any node is contained
in two sets of the fractional partition. So if we consider a data matrix X composed
by two sub-packets for each packet, i.e.
X
⎡
⎢⎢⎢⎢⎣
X11 X12
X21 X22
X31 X32
X41 X42
X51 X52
⎤
⎥⎥⎥⎥⎦
.
Sending Y = [X11 + X21, X31 + X41, X12 + X51, X22 + X32, X42 + X52] we sat-
isfy all the requests, achieving a rate of 5/2.
Theorem 5 ([7]) The optimal broadcast rate is upper bounded by the optimal solu-
tion cc f (G ) of the LP relaxation of (5),
β(G ) ≤cc f (G ) ≤cc(G ).
In [40], Shanmugam, Dimakis, and Langberg showed, extending the clique cov-
ering scheme, that if the users are partitioned in cliques and the packets encoded for
each clique with the XOR as before, then we can reduce the number of transmissions
by applying an MDS code and using side information to recover them. Just as Birk
and Kol reduced the number of message transmissions with partial-clique [2].

262
E. Byrne and M. Calderini
The coding scheme given in [40] achieves the local clique covering number of G ,
denoted by ccl(G ) [16]. Further extending this scheme with fractional coloring, we
can establish the following.
Theorem 6 ([40]) The optimal broadcast rate is upper bounded by the optimal
solution ccl f (G ) of the LP relaxation of
min k
s.t.

C:C∩X j̸=∅
yC ≤k for all j ∈[n]

C: j∈C
yC = 1 for all j ∈[n]
yC ∈{0, 1} for all C ∈C .
(6)
Example 7 Consider the instance with n = m = 6, f (i) = i for all i and
X1 = {2, 3, 4}, X2 = {1, 3, 4},
X3 = {4, 5, 6}, X4 = {3, 5, 6},
X5 = {1, 2, 6}, X6 = {1, 2, 5}.
We associate the graph G given in Fig.5 with this instance, where an edge from
one clique to another means that all the nodes in a clique are connected to all the
nodes in the other clique. Using the scheme based on clique covering requires us to
use at least three transmissions. With local clique covering, we ﬁrst encode using
clique covering to obtain Y ′ = [X1 + X2, X3 + X4, X5 + X6]. Then, exploiting the
side information, we can encode Y ′ using the MDS code also used in Example 5 to
obtain Y = [X1 + X2 + X5 + X6, X3 + X4 + X5 + X6]. Then all receivers are able
to decode ther requested packets.
This linear programming approach was then used to extend these bounds to the
more general case of the hypergraphs. Blasiak, Kleinberg, and Lubetzky in [7] intro-
duced the concept of a hyperclique.
Fig. 5 The graph G for the
ICSI instance in Example 7
1
2
3
4
5
6

Index Coding, Network Coding and Broadcast with Side-Information
263
Deﬁnition 5 Let H a side-infromation hypergraph. A subset S ⊆[m] is a hyper-
clique if for every pair of distinct elements i, j ∈S f (i) ∈X j ∪{ f ( j)}.
As in the graph case we can satisfy the requests of all the receivers in a hyperclique
by just sending the XOR of all packets. We deﬁne the hyperclique covering number
ψ(H ) as the optimal solution of
min

C∈C
yC
s.t.

C: j∈C
yC = 1 for all j ∈[m]
yC ∈{0, 1} for all C ∈C .
(7)
The solution of the LP relaxation of (7) is denoted by ψ f (H ).
Theorem 7 ([7]) The optimal broadcast rate is upper bounded by ψ f (H )
β(G ) ≤ψ f (H ) ≤ψ(H ).
In the work of Tehrani, Dimakis and Neely [36] the authors extend the idea of the
partial clique to the case m ≥n, introducing the multicast partition.
As noted in [36], if we have a side-information hypergraph H and each receiver
knows at least k packets (i.e. |Xi| ≥k), then we can use the same approach as in the
partial-clique case, namely, to use the generator matrix of an MDS code to encode
the packets.
Theorem 8 ([36]) Let ψ p(H ) the optimal solution of
min

M
aMdm
s.t.

M: j∈M
aM = 1 for all j ∈[m]
aM ∈{0, 1} for all M ⊆[m],
dm = |R(M)| −max
j∈M |R(M) ∩X j|,
(8)
where R(M) = { f (i) | i ∈M}.
Then β(H ) ≤ψ p(H ).
Later, Shanmugam, Dimakis, and Langberg [30] proved that the fractional version
of this parameter provides an upper bound for the optimal rate.
In [30] the authors extended their previous result, deﬁning the local hyperclique
covering number ψl(H ) of an hypergraph as the optimal solution of the integer
program

264
E. Byrne and M. Calderini
min k
s.t.

C:C∩U j̸=∅
yC ≤k for all j ∈[m]

C: j∈C
yC = 1 for all j ∈[m]
yC ∈{0, 1} for all C ∈C ,
(9)
where U j = {i ∈[m] | f (i) /∈X j}. The LP relaxation of (9) is deﬁned to be the
fractional local hyperclique cover, denoted ψl f (H ).
Theorem 9 ([30]) The optimal broadcast rate is upper bounded by ψl f (H )
β(G ) ≤ψl f (H ) ≤ψl(H ).
In [30], another parameter, called the partitioned local hyperclique cover and its
fractional version for the groupcast setting is deﬁned. This pararameter is stronger
than those based on local hyperclique covering and partition multicast.
Deﬁnition 6 The partitioned local hyperclique cover number of H , denoted
ψ p
l (H ), is given by the following integer program:
min

M
aMkM
s.t.

C:C∩U j∩M̸=∅
yC ≤kM for all j ∈M

M: j∈M
aM = 1 for all j ∈[m]

C: j∈C
yC = 1 for all j ∈[m]
yC ∈{0, 1} for all C ∈C , aM ∈{0, 1} for allM ⊆[m].
(10)
The fractional version ψ p
l f (H ) is given by the LP relaxation of (10).
Theorem 10 ([30])
β(G ) ≤ψ p
l f (H ) ≤ψ p
l (H ).
However this new scheme is within a factor e from the fractional hyperclique
cover (implying the same for all previous bounds as well).
Theorem 11 ([30])
ψ f (H ) ≤eψ p
l f (H ).
In Fig.6 we report the comparison of all these parameters.

Index Coding, Network Coding and Broadcast with Side-Information
265
Fig. 6 Comparison of graph theoretic bounds for the ICSI problem. u ←v means u ≤v
4
Generalizations of the Index Coding
Problem - Coded-Side Information
In[12, 33]theauthorsgiveageneralizationoftheindexcodingprobleminwhichboth
demanded packets and locally cached packets may be linear combinations of some
set of data packets. We refer to this as the index coding with coded side information
problem (ICCSI). This represents a signiﬁcant departure from the ICSI problem in
that an ICCSI instance no longer has an obvious association to a graph, digraph or
hypergraph, as in the ICSI case. However, as we show here, it turns out that many of
the results for index coding have natural extensions in the ICCSI problem.
One motivation for the ICCSI generalization is related to the coded-caching prob-
lem. The method in [28] uses uncoded cache placement, but the authors give an
example to show that coded cache placement performs better in general. In [8], it is
shown that in a small cache size regime, when the number of users is not less than
the number of ﬁles, a scheme based on coded cache placement is optimal. Moreover
in [39] the authors show that the only way to improve the scheme given in [28] is by
coded cache placement.
Another motivation is toward applications for wireless networks with relay helper
nodes and cloud storage systems [12] (Fig.7).
Fig. 7 State of the network
after the 6th time slot
X1 +X2 +X3 +X4
U1
has X2, X3 +X4
wants X1
U2
has X1, X3 +X4
wants X2
U3
has X4, X1 +X2
wants X3
U4
has X3, X1 +X2
wants X4

266
E. Byrne and M. Calderini
Table 1 Illustration of utilizing coded packets as side information
Time slot
Packet sent
Received by
U1?
Received by
U2?
Received by
U3?
Received by
U4?
1
X1
No
Yes
No
No
2
X2
Yes
No
No
No
3
X3
No
No
No
Yes
4
X4
No
No
Yes
No
5
X1 + X2
No
No
Yes
Yes
6
X4 + X3
Yes
Yes
No
No
7
X1 + X2 + X3 + X4
Yes
Yes
Yes
Yes
Consider the example in Table1. We have a scenario with one sender and four
receivers U1, U2, U3 and U4. The source node has four packets X1, X2, X3 and X4
and for i = 1, ..., 4 user Ui wants packet Xi. The transmitted packet is subject to
independent erasures. It is assumed that there are feedback channels from the users,
informing the transmitting node which packets are successfully received. At the
beginning, in time slot 1, 2, 3 and 4 the source node transmits packets X1, X2, X3
and X4, respectively. After time slot 4 we have the following setting: U1 has packet
X2, U2 has packet X1, U3 has packet X4 and U4 has packet X3. Now from the classical
ICSI problem we have that receivers U1 and U2 form a clique, in the associated graph,
and then we can satisfy their request sending X1 + X2. Similarly for U3 and U4 we
can use X3 + X4. So, the source node in time slot 5 and 6 transmits the coded packet
X1 + X2 and X3 + X4, intending that users receive the respective packet. However,
U1 and U2 receive the coded packet X3 + X4 and U3 and U4 receive X1 + X2.
At this point if only the uncoded packets in their caches are used, we still need to
send two packets. If all packets in their caches are used, the source only needs to
transmit one coded packet X1 + X2 + X3 + X4 in time slot 7. If all four users can
receive this last transmission successfully, then all users can decode the required
packets by linearly combining with the packets received earlier.
We now describe an instance of index coding with coded-side information. As for
the uncoded case we have a data matrix X ∈Fn×t
q
and a set of m receivers. For each
i ∈[m], the ith user seeks some linear combination of the rows of X, say Ri X for
some Ri ∈Fn
q. We will refer to Ri as the request vector and to Ri X as the request
packet of User i. In this scenario a user’s cache is represented by a pair of matrices
V (i) ∈Fdi×n
q
and Λ(i) ∈Fdi×t
q
related by the equation
Λ(i) = V (i)X.
It is assumed that any vector in the row spaces of V (i) and Λ(i) can be generated at the
ith receiver. We denote these respective row spaces by X (i) := ⟨V (i)⟩and L (i) :=

Index Coding, Network Coding and Broadcast with Side-Information
267
⟨Λ(i)⟩for each i. The side information of the ith user is (X (i), L (i)). Similarly, the
sender S has the pair of row spaces (X (S), L (S)) for matrices
V (S) ∈FdS×n
q
and Λ(S) = V (S)X ∈FdS×t
q
and does not necessarily possess the matrix X itself.
The ith user requests a coded packet Ri X ∈L (S) with Ri ∈X (S)\X (i). We
denote by R the m × n matrix over Fq with each ith row equal to Ri. The matrix R
thus represents the requests of all m users.
Example 8 Consider the instance given by the example represented in Fig.4. Then
we have q = 2, m = n = 4, t = 1 and Ri = ei for all i ∈[4] and X (S) = F4
2. The
side information are given by the following matrices
V (1) =
 0 1 0 0
0 0 1 1

, V (2) =
 1 0 0 0
0 0 1 1

,
V (3) =
 1 1 0 0
0 0 0 1

, V (4) =
 1 1 0 0
0 0 1 0

.
Remark 2 The reader will observe that the classical ICSI problem is indeed a special
case of the index coding problem with coded side information. Setting V (S) to be the
n × n identity matrix, Ri = e f (i) ∈Fn
q and V (i) to be the di × n matrix with rows
V (i)
j
= ei j for each i j ∈Xi, yields X (i) = ⟨e j : j ∈Xi⟩. Then User i has the rows
of X indexed by Xi and requests X f (i).
Remark 3 The case where the sender does not necessarily possess the matrix X
itself can be applied to the broadcast relay channel, as described in [33]. The authors
consider a channel as in Fig.8, and assume that the relay is close to the users and
far away from the source, and in particular that all relay-user links are erasure-free.
Each node is assumed to have some storage capacity and stores previously received
data in its cache. The packets in the cache of the relay node are obtained as previous
broadcasts, hence it may contain both coded and uncoded packets. The relay node,
playing the role of the sender, transmits packets obtained by linearly combining
Fig. 8 A schematic for the
broadcast relay channel

268
E. Byrne and M. Calderini
the packets in its cache, depending on the requests and coded side information of
all users. It seeks to minimize the total number of broadcasts such that all users’
demands are met.
We denote by
X := {A ∈Fm×n
q
: Ai ∈X (i), i ∈[m]},
so that X = ⊕i∈[m]X (i) is the direct sum of the X (i) as a vector space over Fq. For
the remainder, we let X , X (S), R be as deﬁned above and write I = (X , X (S), R)
to denote an instance of the ICCSI problem for these parameters.
The deﬁnition of an index code is similar to that of the ICSI case.
Deﬁnition 7 Let N be a positive integer. We say that the map
E : Fn×t
q
→FN×t
q
,
is an Fq-code for I of length N if for each ith receiver, i ∈[m] there exists a
decoding map
Di : FN×t
q
× X (i) →Ft
q,
satisfying
∀X ∈Fn×t
q
: Di(E(X), A) = Ri X,
for some vector A ∈X (i), in which case we say that E is an I -IC. E is called an
Fq-linear I -IC if E(X) = LV (S)X for some L ∈FN×dS
q
, in which case we say that
L represents the code E, or that the matrix L realizes E. If t = 1, we say that L
represents a scalar linear index code. If t > 1 we say that the code is vector linear.
We write L to denote the space ⟨LV (S)⟩.
As before, for the ICCSI instance βt(I ) denotes the minimum broadcast rate for
block-length t where the encoding is over all possible extensions of Fp. That is, for
I = (X , X (S), R)
βt(I ) = inf
q {N | ∃a q-ary index code of length N for I }.
and the optimal broadcast rate is given by the limit
β(I ) = lim
t→∞
βt(I )
t
= inf
t
βt(I )
t
.

Index Coding, Network Coding and Broadcast with Side-Information
269
4.1
Bounding the Optimal Rate with Coded-Side Information
Asshownin[4],itturnsoutthatalsoforthecaseofcodedsideinformationtheoptimal
length of a scalar linear index code is linked to a problem of rank minimization.
The result of Lemma 1 is generalized by the following
Lemma 2 ([4]) Let L ∈FN×dS
q
. Then L represents an Fq-linear I -IC index code
of length N if and only if for each i ∈[m], Ri ∈L + X (i).
So Lemma 2 gives necessary and sufﬁcient conditions for a matrix L to represent
a linear code of the instance I . The sufﬁciency of the statement of Lemma 2 has
already been noted in [33]).
Remark 4 If the equivalent conditions of the above lemma hold we have that for each
i ∈[m], Ri = b(i)LV (S) + a(i)V (i) for some vectors a(i), b(i). So User i decodes its
request by computing
Ri X = b(i)LV (S)X + a(i)V (i)X = b(i)Y + a(i)Λ(i),
where Y is the received message.
The analogue of the min-rank is as follows:
Deﬁnition 8 ([4]) The min-rank of the instance I = (X , X (S), R) of the ICCSI
problem over Fq is
κ(I ) = min

rank(A + R) :
A ∈Fm×n
q
,
Ai ∈X (i) ∩X (S), ∀i ∈[m]

.
Let
˜
X = {Z ∈Fm×n
q
: Zi ∈X (S)}. We observe that the quantity κ(I ) is drk
(R, X ∩
˜
X ),whichistherank-distanceof R ∈Fm×n
q
totheFq-linearcodeX ∩
˜
X ,
or equivalently the minimum rank-weight of the coset R + (X ∩
˜
X ) ⊂Fm×n
q
.
As consequence of Lemma 2 we have
Theorem 12 ([4]) The length of an optimal Fq-linear I -IC is κ(I ). In particular
β(I ) ≤κ(I ).
Similarly to the classical ICSI, we have that optimal linear index coding matrix
can be obtained by solving a matrix completion problem over a ﬁnite ﬁeld. However,
this matrix completion problem is different from the conventional matrix completion
problem. This comes from the fact that, in this more general problem, the rows of
the matrix have to lie in the spaces X (i)’s. In [25] it is proposed a random greedy
algorithm (over F2) that minimizes the rank of the derived matrix.
As said before an ICCSI instance no longer has an obvious association to a com-
binatorial structure such as a graph or hypergraph. However, all the bounds given

270
E. Byrne and M. Calderini
in Sect.3.1 can be generalized to the ICCSI case adopting a Linear Programming
approach.
We start with the following deﬁnition, introduced in [33] as a coding group,
wherein a procedure to detect such as subset is given. It is easy to see that this
deﬁnition generalizes the deﬁnition of a hyperclique given in Sect.3.1.
Deﬁnition 9 Let I = (X , X (S), R) be an instance of the ICCSI problem. A subset
of receivers C ⊆[m] is called generalized clique if there exists v ∈X (S) such that
Ri ∈⟨v⟩+ X (i) for all i ∈C.
For simplicity in the following we refer to a generalized clique just as a clique.
Note that demand Ri X of each user i of a clique can be met by sending the message
vX, that is one packet as for the classical case. Hence a set of ℓcliques that partitions
the set [m] ensures that all requests can be delivered in at most ℓtransmissions.
We denote by C the set of all cliques of I = (X , X (S), R).
Deﬁnition 10 We deﬁne the generalized clique cover number of I , denoted by
ϕ(I ), to be the optimal solution of the following integer program:
min

C∈C
yC
s.t.

C: j∈C
yC = 1 for all j ∈[m]
yC ∈{0, 1} for all C ∈C .
(11)
The LP relaxation of (11) (so with the relaxed constraint 0 ≤yC ≤1 for all C)
is the fractional generalized clique cover number ϕ f (I ).
Theorem 13 ([5]) Let I = (X , X (S), R). There exist achievable Fq-linear index
codes corresponding to ϕ(I ) and ϕ f (H ). In particular, we have
β(I ) ≤ϕ f (I ) ≤ϕ(I ).
For each clique C ∈C deﬁne the set
R(C) := {v ∈Fn
q | Ri ∈⟨v⟩+ X (i) ∀i ∈C}.
That is, R(C) contains all the vectors that we can use to encode X in order that all
receivers in C can decode correctly.
Deﬁnition 11 For each C ∈C ﬁx a vector vC ∈R(C). We deﬁne the following
integer program with respect to the vectors vC.

Index Coding, Network Coding and Broadcast with Side-Information
271
min k
s.t.

C:vC /∈X ( j)
yC ≤k for all j ∈[m]

C: j∈C
yC = 1 for all j ∈[m]
yC ∈{0, 1}for all C ∈C and k ∈N.
(12)
We denote by φl(I , (vC ∈R(C) : C ∈C )) the optimal solution of (12), depend-
ing on the ﬁxed vC’s. The minimum over all possible vC’s is called the local gener-
alized clique cover number
ϕl(I ) =
min
(vC∈R (C):C∈C ) φl(I , (vC : C ∈C )).
This is an extension of the local hyperclique cover: for a set of ﬁxed vC, given
user j ∈[m] and some feasible solution to (11), count number of cliques C in that
generalized clique cover such that vC is not contained in the side-information X ( j)
and let k be the maximum number of such cliques for each j. The optimal solution
of (12) is the minimum value of k over all possible solutions of (11) and all choices
of vC. The minimum of the LP relaxation of (12) over all possible vC’s is called
the fractional local generalized clique cover number ϕl f (I ). Clearly the optimal
solution of (12) depends on the choice of vectors vC.
Theorem 14 ([5]) Let I = (X , X (S), R). There are achievable linear index codes
corresponding to ϕl(I ) and ϕl f (I ) implying β(I ) ≤ϕl f (I ) ≤ϕl(I ).
In the multicast partition scheme for the ICSI case we want to ﬁnd a partition
where the knowledge, i.e. the cardinality of Xi, of the users among the sets of the
partition is maximized. Now, the knowledge of a user is given by the dimension of
the space X (i), so we obtain the following
Deﬁnition 12 We deﬁne the partition generalized multicast number, ϕ p(I ) to be
the optimal solution of the following integer program
min

M⊂[m]
aMdM
s.t.

M: j∈M
aM = 1 for all j ∈[m]
aM ∈{0, 1} for all M ⊂[m], M ̸= ∅.
and dM = dim(⟨RM⟩) −min
j∈M dim(⟨RM⟩∩X ( j)).
(13)
The LP relaxation of (13) is called the fractional partition generalized multicast
number, ϕ p
f (I ).
We brieﬂy justify the above: each user is assigned to exactly one multicast group
M, so the selected groups M form a partition of [m]. Each member j of a multicast

272
E. Byrne and M. Calderini
group M ⊂[m] already has access to at least dim(⟨RM⟩∩X ( j)) independent vectors
in ⟨RM⟩, so a coding scheme can be applied to ensure delivery of all remaining
requests within a group using at most dM transmissions. In fact as it is shown in [4]
we have
Proposition 1 Let I = (X , X (S), R). If q > m then κ(I ) ≤max{n −di : i ∈
[m]}. For any q, κ(I ) ≤rank(R).
The essential content of the proof of Proposition 1 is that there exists an N ×
n matrix L realizing I for N ≤max{n −di : i ∈[m]}, which corresponds to a
multicast solution, so every user can retrieve any linear combination of the Xi. In
this case the matrix L is such that L + X (i) = Fn
q for each i.
Theorem 15 ([5]) Let I = (X , X (S), R). There are achievable linear index codes
of lengths ϕ p(I ) and ϕ p
f (I ), which implies that β(I ) ≤ϕ p
f (I ) ≤ϕ p(I ).
The ﬁnal approach considered combines partition multicast and local clique cov-
ering. The users are partitioned into multicast groups and independently covered by
generalized cliques. Each multicast group offers a reduced ICCSI problem to which
a restricted local clique cover is applied.
Deﬁnition 13 Deﬁne the following integer program
min

M⊂[m]
aMkM
s.t.

C:vC /∈X ( j)
C∩M̸=∅
yC ≤kM for all j ∈M

M: j∈M
aM = 1,

C: j∈C
yC = 1 for all j ∈[m]
aM, yC ∈{0, 1} for all C ∈C , M ⊂[m] and tM ∈N.
(14)
We denote by φ p
l (I , (vC ∈R(C) : C ∈C )) the optimal solution of (14) with
respect to (vC ∈R(C) : C ∈C ) ﬁxed. The minimum over all possible choices of
vC is called the partitioned local generalized clique cover number
ϕ p
l (I ) =
min
(vC∈R (C):C∈C ) φ p
l (I , (vC ∈R(C) : C ∈C )).
The minimum of the LP relaxation of (14) over all possible choices of vC is called
the fractional partitioned local generalized clique cover number ϕ p
l f (I ).
Theorem 16 ([5]) There are achievable linear index codes corresponding to ϕ p
l (I )
and ϕ p
l f (I ) implying β(I ) ≤ϕ p
l f (I ) ≤ϕ p
l (I ).
The comparison between the parameter introduced in Sect.3.1 (see Fig.6) are no
more valid in this contest, as shown in the following remarks.

Index Coding, Network Coding and Broadcast with Side-Information
273
Remark 5 The parameters ϕ p and ϕ p
l are not comparable. From the parameters given
in [30] we have that there exist instances of the ICSI problem for which ϕ p(I ) ≥
ϕ p
l (I ). Now, consider the ICCSI instance with m = n = 3, q = 2, X (S) = F3
2.
V (1) = [0 1 1]
V (2) = [1 1 1]
V (3) = [1 1 1],
and R1 = 100, R2 = 010, R3 = 001.
In order to satisfy the request of a receiver using only one vector then the coding
vectors should be
• v1 = 100 or v′
1 = 111 for User 1;
• v2 = 010 or v′
2 = 101 for User 2;
• v3 = 001 or v′
3 = 110 for User 3.
Then the set of all cliques is C = {{1}, {2}, {3}}. Moreover we can see that vi, v′
i /∈
X (1) for all i. Now, if we consider the multicast group M = {1, 2, 3} we can note
that dM = 2 and that kM = 3 because none of the six vectors above is in the space
X (1). Then we have 2 = ϕ p(I ) ≤ϕ p
l (I ) = 3.
Remark 6 The parameters ϕ p and ϕ are not comparable. From the parameters given
in [30], there exist instances of the ICSI problem for which ϕ(I ) ≥ϕ p(I ). Now
consider the ICCSI instance with m = n = 2, q = 2, X (S) = F2
2.
V (1) = [1 1]
V (2) = [0 0],
and R1 = 10, R2 = 01. It is easy to check that using the multicast group partition
we need two transmissions, but it can be seen that {1, 2} is a clique and that v{1,2} =
01 ∈R({1, 2}), yielding 1 = ϕ(I ) ≤ϕ p(I ) = 2.
Remark 7 We have ϕ p
l (I ) ≤ϕl(I ) ≤ϕ(I ). It is easy to check that ϕl(I ) ≤
ϕ(I ) as k is at most equal to the number of cliques that form a partition of [m].
Then we have also ϕ p
l (I ) ≤ϕl(I ). In fact, among the possible optimal solutions
we have those where M = [m] and in that case we obtain exactly ϕl(I ).
It is possible to introduce a weak deﬁnition of clique. C ⊆[m] is called weak
clique if for all i, j ∈C we have R j ∈X (i) or ⟨R j⟩= ⟨Ri⟩. Using this deﬁnition,
it is possible to introduce the notion of a weak clique cover, local weak clique cover
and partitioned local weak clique cover with respective corresponding parameters
wϕ(I ), wϕl(I ) and wϕ p
l (I ) along with their fractional counterparts. Note that if
C is a weak clique then it is also a generalized clique. In fact we can encode the
message using the sum of distinct requests as vector vC.
Moreover from the deﬁnition of weak clique, if we consider a clique as a multicast
group M then it results dM = 1. Therefore ϕ p(I ) ≤wϕ(I ) and the same holds for
the fractional parameters. However, also in this case, the partitioned local weak clique
cover and the partitioned multicast cover are not comparable (see example in Remark
5) (Fig.9).

274
E. Byrne and M. Calderini
Fig. 9 ICCSI bounds introduced in this section. Smaller quantities are placed to the left and the
weakest bound is placed to the rightmost of the ﬁgure. Arrows indicate the relationship they satisfy
4.2
Error Correction
Error correction in the index coding problem has been considered in [4, 14]. In this
model it is assumed that some erroneous packets have been transmitted among N
coded packets E(X), that is the users receive a transmission Y = E(X) + W, for
some error matrix W. The question is now to determine the shortest possible length
N of a linear index code such that each receiver can recover its demanded packet,
assuming that E(X) has been corrupted by noise.
This problem was introduced in [14] for the case of uncoded side information
and extended in [4] to include the coded-side information case. For the case of
Hamming errors, it is shown that ideas from classical coding theory can be adapted
to the linear index coding problem to obtain bounds on the transmission rate where
at most δ rows of E(X) have been affected by noise. For linear index codes, generic
decoding algorithms based on syndrome decoding can be applied. Rank-metric error
correction was also considered in [4]. In this exposition, for brevity we will describe
the Hamming case only.
The Hamming distance dH(Z, Z′) between a pair of matrices Z, Z′ is the number
of non-zero rows of their difference Z −Z′, which is also the Hamming weight
wH(Z −Z′).
The formal notion of a δ-error correcting index code is as follows.
Deﬁnition 14 Let I be an instance of an ICCSI problem and let N be a positive
integer. We say that the map
E : Fn×t
q
→FN×t
q
,
is a δ-error correcting code for I of length N, and say that E is an (I , δ)-ECIC, if
for each ith receiver there exists a decoding map

Index Coding, Network Coding and Broadcast with Side-Information
275
Di : FN×t
q
× X (i) →Ft
q,
satisfying
Di(E(X) + W, A) = Ri X
for all X, W ∈FN×t
q
, wH(W) ≤δ for some vector A ∈X (i). E is called a linear
code for I , or an Fq-linear I -ECIC if E(X) = LV (S)X for some L ∈FN×dS
q
, in
which case we say that L represents the linear (I , δ)-ECIC E.
Theorem 17 Let I be an instance of an ICCSI problem and let N be a positive
integer. A matrix L ∈FN×dS
q
represents a linear (I , δ)-ECIC if and only if for all
i ∈[m] it holds that
wH

LV (S)(X −X′)

≥2δ + 1,
for all X, X′ ∈M such that V (i)X = V (i)X′, Ri X ̸= Ri X′.
4.2.1
Bounds on the Transmission Rate of an (I , δ)-ECIC
We denote by N (I , δ) the optimal length of an Fq-linear Hamming metric (I , δ)-
ECIC and by N(k, d) the optimal length ℓof an Fq-[ℓ, k, d] code, i.e. a k-dimensional
Fq-linear code in Fℓ
q of minimum Hamming distance d.
Deﬁnition 15 We denote by α(I ) the maximum dimension of any subspace U of
Fn
q such that every member u of U satisﬁes V (i)u = 0 and Riu ̸= 0 for some i ∈[m].
That is,
α(I ) := max{dim U | U < Fn
q : ∀u ∈U \ {0}∃i ∈[m] s.t. V (i)u = 0, Riu ̸= 0}
Example 9 Let q = 2, m = 6, n = 4. Let
V (1) =
 1 0 1 0
0 0 0 1

, V (2) =
 1 0 0 0
0 0 1 1

, V (3) =
 1 0 0 0
0 1 0 0

,
V (4) =
 0 1 0 1
0 0 1 0

, V (5) =
 1 0 1 0
0 0 0 1

, V (6) =
0 1 0 0
0 0 0 1

,
and let the request vectors be given by
R1 = 1100, R2 = 0111, R3 = 1010, R4 = 1001, R5 = 0100, R6 = 1111.
Then the set of vectors of F4
q such that V (i)u = 0 and Riu ̸= 0 for some i ∈[4] is
given by
{1000, 0100, 0010, 1010, 0101, 0011, 1101, 1110, 0111},

276
E. Byrne and M. Calderini
which, after including the zero vector, contains the subspace {0000, 1010, 0100,
1110}, and no larger subspace. It follows that α(I ) = 2.
Theorem 18 (α-bound) Let I be an instance of the ICCSI problem. Then
N(α(I ), 2δ + 1) ≤N (I , δ).
The argument used in the proof of the α-bound may be sketched as follows. We
let CU := {LV (S)u : u ∈U} for U of maximum dimension as described above. If
L realizes an (I , δ)-ECIC then CU is an Fq-linear [N, α, 2δ + 1] code, so that the
ECIC necessarily has length at least α(I ). We give sufﬁcient conditions for tightness
of the α-bound.
Let U ⊥denotes the orthogonal space of U with respect to the usual scalar product
in Fn
q.
Corollary 1 Let I be an instance of the ICCSI problem. If there exists a matrix
B ∈Fα(I )×dS
q
satisfying BV (S)⊥∩V (i)⊥⊂Ri ⊥for all i ∈[m] then
N(α(I ), 2δ + 1) = N (I , δ).
Setting δ = 0 gives the following lower bound on the min-rank of an instance as
an immediate consequence of the α-bound and Corollary 1.
Corollary 2 Let I be an instance of the ICCSI problem. Then
α(I ) ≤κ(I ),
with equality occurring if there exists L ∈Fα(I )×dS
q
satisfying LV (S)⊥∩V (i)⊥⊂
Ri ⊥for all i ∈[m].
Theorem 19 (κ-bound) Let I be an instance of the ICCSI problem. Then
N (I , δ) ≤N(κ(I ), 2δ + 1).
In the proof of the κ bound, a matrix realizing an (I , δ)-ECIC is found as the
product L = L2L1 where L1 is a κ(I ) × dS matrix realizing an optimal I -IC and
the column space of L2 is an optimal Fq-[N, κ(I ), 2δ + 1] code.
A Singleton-like bound is deduced by observing that deleting any 2δ rows of a
matrix L that realizes an (I , δ)-ECIC results in an I -IC.
Theorem 20 (Singleton bound) Let I be an instance of the ICCSI problem. Then
κ(I ) + 2δ ≤N (I , δ).
Example 10 Let m = 6, n = 5, q = 2 and let X (S) = F5
q. Suppose that X (i) has
dimension di = 2 for each i ∈{1, ..., 6}. Let I be the instance deﬁned by user
side-information

Index Coding, Network Coding and Broadcast with Side-Information
277
V (1) =
 0 1 1 1 0
0 0 1 1 1

, V (2) =
 1 0 0 0 1
0 0 1 1 0

, V (3) =
 1 1 1 1 0
0 0 0 1 1

,
V (4) =
 1 0 0 1 0
0 1 1 1 1

, V (5) =
 0 0 1 1 0
0 0 0 1 1

, V (6) =
 1 0 0 1 0
0 0 1 1 0

,
and request vectors
R1 = 10000, R2 = 10000, R3 = 00101, R4 = 10001, R5 = 11000, R6 = 00111.
It can be checked that κ(I ) = 3 and that α(I ) = 3. It follows from the α-
bound that 6 = N(3, 3) = N(α(I ), 3) ≤N (I , 1). From the κ-bound we have
6 = N(3, 3) = N(κ(I ), 3) ≥N (I , 1).
We construct a matrix L that realizes a 1-error correcting ECIC for this instance
as
L =
⎡
⎢⎢⎢⎢⎢⎢⎣
10000
01000
00011
01011
11000
11011
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
100
010
001
011
110
111
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎣
10000
01000
00011
⎤
⎦= L2L1,
where L2 has column space a [6, 3, 3] binary linear code and L1 realizes an optimal
code I -IC.
If q ≥κ(I ) + 2δ −1 then there exists an Fq-linear [q + 1, κ(I ), 2δ + 1] opti-
mal code (in fact a maximum distance separable code), so the κ and Singelton bounds
combine to give the following result.
Corollary 3 Let I be an instance of the ICCSI problem. If q ≥κ(I ) + 2δ −1
then
N (I , δ) = κ(I ) + 2δ.
We let Vq(n,r) denote the size of a Hamming sphere of radius r in Fn
q.
Theorem 21 Let I be an instance of the ICCSI problem. Let L ∈FN×dS
q
be selected
uniformly at random over Fq. The probability that L corresponds to a Hamming
metric Fq-linear (I , δ)-ECIC is at least
1 −
m

i=1
qn−di−1(q −1)Vq(N, 2δ)
q N
.

278
E. Byrne and M. Calderini
In particular there exists an Fq-linear (I , δ)-ECIC of length N if
N > n −d −1 + logq(m(q −1)Vq(N, 2δ)),
where d = min{di : i ∈[m]}.
Let Hq denote the q-ary entropy function:
Hq : (0, 1) →R : x →x logq(q −1) −x logq(x) −(1 −x) logq(1 −x).
It is well known that the function Hq(x) is continuous and increasing on (0, 1 −
(1/q)) and that Vq(n, λn) ≤q Hq(λ)n [24].
Corollary 4 Let I be an instance of the ICCSI problem with. Let λ ∈Q such
that 0 < λ < 1 −1/q and let N ∈Z satisfy λN ∈Z Then, choosing the entries of
L ∈FN×dS
q
uniformly at random over the ﬁeld Fq, the probability that L corresponds
to a Hamming metric Fq-linear (I , δ)-ECIC, with δ =
 λN
2

, is at least
1 −(q −1)

i∈ˆm
q(n−di−1)
q N(1−Hq(λ)) .
In particular there exists an Fq-linear Hamming metric (I , δ)-ECIC if
m < q N(1−Hq(λ))−(n−d−1)
q −1
,
where d = min{di : i ∈[m]}.
Remark 8 Theα andSingletonboundshaverank-metricanalogues,asdoesTheorem
21. The interested reader is referred to [4] for further details.
4.2.2
Decoding an (I , δ)-ECIC
For the remainder of this section, we let L ∈FN×dS
q
be a matrix corresponding to an
(I , δ)-ECIC. Suppose that for some i ∈[m] the ith user, receives the message
Y(i) = LV (S)X + W(i) ∈FN×t
q
,
where LV (S)X is the codeword transmitted by S and W(i) is the error vector in FN
q .
Since Ri /∈X (i), there exists an invertible matrix M(i) ∈Fn×n
q
such that
V (i)M(i) = [I|0] where I is the identity matrix in Fdi×di, and Ri M(i) = edi+1.

Index Coding, Network Coding and Broadcast with Side-Information
279
Now deﬁne X′ := M−1
(i) X ∈Fn×t
q
. Then we have
V (i)
j X = e j M−1
(i) X = X′
j for j ∈[di]
and
Ri X = edi+1M−1
(i) X = X′
di+1.
Let L′ = LV (S)M(i) and let [s] := [n] \ [s]. Consider the following two codes. We
deﬁne C (i)⊂FN
q to be the column space of the matrix [L′di+1|L′[di+1]] ∈FN×n
q
and
we deﬁne C(i)⊂FN
q to be the subspace of C (i) spanned by the columns of L′[di+1].
For each i ∈[m], we have C(i) ⊆C (i) with dim(C (i)) = dim(C(i)) + 1. As usual,
for an Fq-linear code C ∈FN
q we write C⊥:= {y ∈FN
q : x · y = 0} to denote its
dual code. Then we have C (i)⊥⊆C(i)
⊥with ri = dim(C(i)
⊥) = dim(C (i)⊥) + 1 for
some ri. Let H(i) be a parity check matrix of C(i) of the form
H(i) =
 h(i)
H (i)

∈Fri×N
q
,
(15)
where H (i) is a parity check matrix of C (i) and h(i) ∈C(i)
⊥\ C (i)⊥.
Then
H(i)L′di+1 = [sdi+1, 0, . . . , 0]T
for some sdi+1 ∈Fq \ {0}.
We now outline a procedure for decoding the demand Ri X at the ith receiver,
which is based on syndrome decoding. In the ﬁrst step we compute syndrome, of H(i),
in which is embedded a syndrome of H (i). In the second step a table of syndromes
is computed for the code C (i). Finally, in the third step the output Ri X is computed.
Theorem 22 If wH(W(i)) ≤δ then Algorithm 3 has output ˆXdi+1 = X′
di+1 = Ri X.
Example 11 Let q = 2, m = n = 4, t = 1, δ = 1 and Ri = ei for all i ∈[4] and
X (S) = F4
2.
Let the side-information for this instance be encoded according to the matrices:
V (1) =
 0 1 1 0
0 0 1 0

, V (2) =
 1 0 0 0
0 0 1 1

, V (3) =
 1 0 0 0
0 0 0 1

, V (4) =
 1 1 0 1
0 1 1 0

.
The vectors in F4
2 in V (i)⊥\R⊥
i for some i ∈[4] comprise the set
S = {1001, 1000, 0111, 0100, 0010, 0110}.

280
E. Byrne and M. Calderini
Data: Erroneous Transmission Y(i) = LV (S)X + W(i) ∈FN×t
q
Output: Requested data Ri X
Step I:
Compute
H(i)(Y(i) −L′[di ]X′
[di ]) =

αi
βi

∈Fri ×t
q
(16)
Step I I:
Find ε ∈FN×t
q
with wH(ε) ≤δ such that
H(i)ε = βi ∈F(ri −1)×t
q
.
(17)
Step I I I: Compute
ˆXdi +1 = (αi −h(i)ε)/sdi +1.
(18)
Result: Ri X = ˆXdi +1
Algorithm 3: Correcting δ erroneous packets
It is easy to check that α(I ) = 2 and κ(I ) = 2, so from the α and κ bounds we
have
N (I , 1) ≤N(κ(I ), 3) = 5 = N(2, 3) = N(α(I ), 3) ≤N (I , 1).
We claim that the matrix
L =
⎡
⎢⎢⎢⎢⎣
1 0 1 0
0 1 1 1
1 1 0 0
1 1 1 0
0 0 1 0
⎤
⎥⎥⎥⎥⎦
represents an optimal linear (I , 1)-ECIC. Since no element of S is in the null space
of L, any 4 × t matrix Z satisfying V (i)Z = 0 and Ri Z ̸= 0 has at least one column
from S . Lv has weight at Hamming weight least 3 for any v ∈S , and hence L Z
has minimum Hamming weight at least 3.
Now suppose t = 1 and let X = [1111]T . The sender broadcasts L X. Suppose
one Hamming error occurs and U4 receives the vector
Y4 = L X + W(4) = [01010]T + [00010]T = [01001]T .
Let
M(4) =
⎡
⎢⎢⎣
1 0 1 1
0 0 0 1
0 1 0 1
0 0 1 0
⎤
⎥⎥⎦
and
L′ = LM(4) =
⎡
⎢⎢⎢⎢⎣
1 1 1 0
0 1 1 0
1 0 1 0
1 1 1 1
0 1 0 1
⎤
⎥⎥⎥⎥⎦

Index Coding, Network Coding and Broadcast with Side-Information
281
We obtain a parity check matrix of C(4), as in (15)
H(4) =
⎡
⎢⎢⎣
0 0 0 1 1
1 0 0 1 1
0 1 0 1 1
0 0 1 1 1
⎤
⎥⎥⎦.
Applying Step I of Algorithm 3 we obtain
H(4)(Y −L′[2]X′
[2]) =
⎡
⎢⎢⎣
0 0 0 1 1
1 0 0 1 1
0 1 0 1 1
0 0 1 1 1
⎤
⎥⎥⎦
⎡
⎢⎢⎢⎢⎣
1
1
1
1
1
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎣
0
1
1
1
⎤
⎥⎥⎦.
Therefore α4 = 0 and β4 = [111]T . Now from Step II, we obtain that the vector
ε = [00001]T is a solution of (3) and in Step III we obtain
ˆX3 = (0 −[00011] · [00001])/1 = 1 = X4.
5
Connections
The simplicity of the ICSI problem as a problem of multi-user communication, the
fact that it is a network with a single coding point or common link, has encouraged
many researchers to study capacity problems from the index coding point of view
[17, 18, 23, 27, 35, 38]. In this section we consider some connections of index
coding to other network communication problems.
5.1
Equivalence to Network Coding
The equivalence of the index and network coding problems is important, particularly
in relation to the fundamental question of determining the capacity of an arbitrary
network coding instance.
An instance of the index coding problem may be viewed as an instance of network
coding in which there is a single internal node of in-degree greater than one, i.e. a
single coding point, whose outgoing edge has some capacity cB, which represents
the broadcast rate. We illustrate this connection by an example shown in the Fig.5.1
below, where the index coding instance on the left is the same as that of Fig.1 and the
ﬁgure on the right is the corresponding network coding instance. The edges outgoing
from the source nodes all have unit capacity, whilst all other edges have capacity cB.
An edge joining an ith source node with a jth sink node (shown below in red) exists

282
E. Byrne and M. Calderini
S
has x1, x2, x3
1
has x3
requests x1
2
has x1, x3
requests x2
3
has x1, x2
requests x3
4
has x2
requests x1
edge capacities cB
x1
x2
x3
x1
x2
x3
x1
Fig. 10 Index coding as an instance of network coding
in the network coding representation if Receiver j possesses source xi as part of its
side-information (Fig.10).
This equivalence was described in [18, 19]. In [19] the authors establish this
equivalence for both scalar linear and vector linear coding, while in [18] is shown
that this equivalence holds in general. Explicitly, given a network coding instance, the
authors show how to reduce this to an index coding problem, showing that a solution
to the index coding problem also yields one for the network coding problem.
Recall that in describing an instance of index coding we have ﬁxed n as the number
of sources and m as the number of users. We give a slight generalization of the index
coding problem to describe this equivalence: we will assume now that each receiver
may demand more than one row of X. As noted before, this can be easily translated to
the problem of single requests by adding new users with identical side information.
An instance of the index coding problem is given by I = (X , R) where X =
(Xi : i ∈[n]) for Xi ⊂[n] corresponding to the side infomation held by each ith
receiver and R = (Ri : i ∈[m]) for Ri ⊂[n] corresponding to the requests of each
receiver.
Then I -IC is realized by (E, D) with D = {Di : i ∈[m]} if
E : Fn×t
q
→FN
q and Di : FN
q × F|X i|
q
→Ft
q
are maps such that
Di(E(X), XX i) = (X j : j ∈Ri)
for each X ∈Fn×t
q
and i ∈[m].
We now describe an instance of the network coding problem as a tuple I ′ =
(G, S,U, B), where G = (V , E ) is a directed acyclic graph, S is a set of source
nodes (those with in-degree 0), U is a set of receiver nodes (those with out-degree
0) and B is an |S| × |U| matrix with entry Bu
s = 1 if receiver u requests data from
source s and 0 otherwise.
We let In(v) and In(e) deonte the edges incoming to a node v or an edge e.
Deﬁne some local encoding functions F = {Fe : e ∈E } and decoding functions

Index Coding, Network Coding and Broadcast with Side-Information
283
D′ = {D′
u : u ∈U} such that the arguments of Fe and D′
u respectively are the outputs
of edges incoming to e and u. The acyclic structure of G means that F yields a well-
deﬁnedsetofglobalencodingfunctions P = {Pe : e ∈E },sothat Pe(X)istheoutput
of edge e for any transmitted X = (Xs : s ∈S). More precisely, for any e ∈E , we
have
Pe(X) = Fe(Pe′(X) : e′ ∈In(e)).
A network code for the instance I ′ is realized by (F, D′) if
D′
u(Pe(X) : e ∈In(u)) = (Xs : Bu
s = 1),
that is, if the output of D′
u is (Xs : Bu
s = 1) for any transmitted X.
We now outline the reduction of a network coding instance I ′ to an index coding
instance I .
• n := |S| + |E |.
For any X ∈Fn×t
q
, the ﬁrst |S| rows of X are enumerated by S and the remaining
rows are enumerated by |E |.
• m := |U| + |E | + 1
The m receivers are given by the set {tu : u ∈U} ∪{te : e ∈E} ∪{t0}.
• Foreachu ∈U,assigntheside-informationXu := {e : e ∈In(u)}andtherequests
Ru := {s : Bu
s = 1} to receiver tu.
• For each e ∈E , assign the side-information Xe := {e′ : e′ ∈In(e)} and the request
Re = {e} to receiver te.
• Assign the side-information X0 := S and the requests R0 = E to receiver t0.
• N := |E |.
The main result of [18] shows that a network code (F, D′) exists for I ′ if and only
if an index code (E, D) of length N exists for I constructed from I ′ as outlined
above.
Let (F, D′) be network code for the instance I ′ with corresponding matrix B,
indicating the requests of each user u ∈U. For each edge e ∈E , the global encoding
functions Pe have argument X S and
Xe = Pe(X S) = Fe(Pe′(X S) : e′ ∈In(e)).
The decoding functions D′
u satisfy
D′
u(Pe(X S) : e ∈In(u)) = (Xs : Bu
s = 1),
for each u ∈U. Deﬁne a map by
E : Fn×t
q
−→FN×t
q
: X →E(X) := (Ee(X) : e ∈E ) = (Xe + Pe(X S) : e ∈E ).
WeclaimthatforeachreceiverofthecorrespondinginstanceI therehaveadecoding
map that outputs its request vector.

284
E. Byrne and M. Calderini
• For each u ∈U, deﬁne
Du(E(X), XX u ) := D′
u((Ee(X) : e ∈Xu) −XX u) = D′
u((Ee(X) : e ∈In(u)) −XIn(u))
= D′
u(Xe + Pe(XS) −Xe : e ∈In(u)) = D′
u(Pe(XS) : e ∈In(u))
= (Xs : Bu
s = 1) = X Ru,
so receiver tu recovers its requested data.
• For each e ∈E , deﬁne
De(E(X), XX e) := Fe((Ee′(X) : e′ ∈Xe) −XX e)
= Fe(Pe′(X S) : e′ ∈In(e))
= Pe(X S) = Xe,
which is the data requested by te.
• For terminal t0, deﬁne
D0(E(X), XX 0) := (Ee(X) : e ∈E ) −(Pe(XX 0) : e ∈E )
= (Xe + Pe(X S) : e ∈E ) −(Pe(X S) : e ∈E )
= XE ,
as requested by user t0.
Therefore the network code (F, D′) for I ′ yields an index code for the instance
I .
Conversely, suppose there is a code (E, D) of length N = |E | for the index
coding instance I . We will construct a code (F, D′) for the network coding instance
I ′. Given any Y ∈Im E ⊂FN×t
q
, the existence of D0 means that for each W ∈
F|S|×t
q
there exists unique Z ∈FN×t
q
satisfying D0(Y, W) = Z; equivalently, such
that E(W, Z) = Y.
Then choose Y ∈Im E. Let X S be the source data to be transmitted. Then XE =
(Xe : e ∈E ) := D0(Y, X S). For each e ∈E , deﬁne recursively a local and global
encoding functions as follows.
• If e is incident with a source node s ∈S then
Xe = Pe(X S) = Fe(Xs) := De(Y, Xs) = Xs.
• For every e ∈E , deﬁne
Xe = Pe(X S) = Fe(XIn(e)) := De(Y, XIn(e)).
So Fe(XIn(e)) = Fe(Pe′(X S) : e′ ∈In(e)) for each e ∈E not incident with a source
node.

Index Coding, Network Coding and Broadcast with Side-Information
285
Fig. 11 The butterﬂy
network
s1
s1
u2
u1
e1
e2
e3
e4
e5
e6
e7
For each u ∈U, deﬁne a decoding function:
D′
u(XIn(u)) := Du(Y, XIn(u)) = (Xs : Bu
s = 1).
The index code (E, D) for the instance I thus yields the network code (F, D′) for
the network coding instance I ′.
We summarize this in the following theorem, which is a simpliﬁed version of
[18, Theorem 1], in which we assume constant rate of all sources and a zero-error
solution. The reader is referred to [18] for further details.
Theorem 23 Let I ′ be an instance of the network coding problem. Let I be the
corresponding instance of the index coding problem of length N. Then there exists
a network code for I ′ if and only if there exists an index code for I for the same
packet length t.
Example 12 We construct an index coding instance I from the instance of the
Butterﬂy Network, as shown below (Fig.11).
User 1 wants Y1 and User 2 wants Y2 for the sources transmitting Y1 and Y2
respectively, so B = I2.
• n := 2 + 7 = 9.
For any X ∈F7×t
q
, the ﬁrst 2 rows of X are enumerated by {1, 2} and the remaining
rows are enumerated by {e1, ..., e7}.
• m := 2 + 7 + 1 = 10
We label the 10 receivers by the set {tu1, tu2, te1, ..., te7, t0}.
• The side infomation sets are given by:
Xu1 = {e4, e7}, Xu2 = {e1, e6}, Xe1 = Xe2 = {1}, Xe3 = Xe4 = {2},
Xe5 = {e2, e3}, Xe6 = Xe7 = {e5}, X0 = {1, 2}.
• The request sets are given by:
R0 = {e1, ..., e7}, Ru1 = {1}, Ru2 = {2}, Rei = {ei}, i ∈[7].
• N := 7.

286
E. Byrne and M. Calderini
We remark that the set of all F2-linear feasible solutions for this index coding
problem are matrices with the same row space as one of the form
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1 0 0 0 0 ∗0 0 ∗
0 1 ∗0 0 0 ∗0 0
∗0 1 0 0 0 0 0 0
∗0 0 1 0 0 0 0 0
0 ∗0 0 1 0 0 0 0
0 ∗0 0 0 1 0 0 0
0 0 0 ∗∗0 1 0 0
0 0 0 0 0 0 ∗1 0
0 0 0 0 0 0 ∗0 1
∗∗1 1 1 1 1 1 1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
(19)
where ∗may be replace by an arbitrary element of F2. It can be checked that the least
F2-rank any such matrix may have is 7, so the optimal length of an F2-linear index
code of I is 7.
Of course there exists a linear network code over F2 for the instance I ′ illustrated
by the butterﬂy network. For Y ∈F2
2, the global encoding functions given by:
Pe1(Y) = Pe2(Y) = Y1, Pe3(Y) = Pe4(Y) = Y2, Pe5(Y) = Pe6(Y) = Pe7(Y) = Y1 + Y2
realize a a network code, with the decoding functions:
D′
u1(Y) = Pe7(Y) −Pe4(Y) = Y1 and D′
u2(Y) = Pe6(Y) −Pe1(Y) = Y2.
The claim is now that there exists a length 7 index code for the instance described.
Deﬁne a map E : F9
2 −→F7
2 by
E(X) = (Ee1(X), ..., Ee7(X)), with Eei(X) := Xei + Pei(X1, X2).
A matrix representing the linear map E is given by
L =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1 0 1 0 0 0 0 0 0
1 0 0 1 0 0 0 0 0
0 1 0 0 1 0 0 0 0
0 1 0 0 0 1 0 0 0
1 1 0 0 0 0 1 0 0
1 1 0 0 0 0 0 1 0
1 1 0 0 0 0 0 0 1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,

Index Coding, Network Coding and Broadcast with Side-Information
287
which can be checked to be an F2-linear I -IC. For example,
Du1(L X, X{e4,e7}) = D′
u1(Le4 · X −Xe4, Le7 · X −Xe7)
= D′
u1(X2 + Xe4 −Xe4, X1 + X2 + Xe7 −Xe7)
= D′
u1(X2, X1 + X2) = X1 + X2 −X2 = X1,
which is the demand of tu1.
D0(L X, X{1,2}) = L X −(Pe(X{1,2}) : e ∈{e1, ..., e7})
= L X −(X1, X1, X2, X2, X1 + X2, X1 + X2, X1 + X2)
= (Xe1, Xe2, Xe3, Xe4, Xe5, Xe6, Xe7),
which is the demand of t0.
Conversely, we know that the instance of the index coding problem I is real-
ized by a code of length 7; a linear one in fact. Let E(X) = L X for the matrix
L given above. Then the column space of [L1, L2] is contained in the column
space of [Le1, ..., Le7], so for any choice of X1, X2 there exist Xe1, ..., Xe7 such that
[L1, L2]X{1,2} = [Le1, ..., Le7]X{e1,...,e7}, i.e. such that L X = 0. Moreover, the exis-
tence of the decoding function D0 for t0 ensures that the Xe1, ..., Xe7 are uniquely
determined by X1, X2. The decoding functions for the index coding instance are
given by:
Du1(L X, Xe4,e7) = X1, Du2(L X, Xe1,e6) = X2, D0(L X, X1,2) = X{e1,...,e7}
De1(L X, X1) = Xe1, De2(L X, X1) = Xe2, De3(L X, X2) = Xe3, De4(L X, X2) = Xe4
De5(L X, Xe2,e3) = Xe5, De6(L X, Xe5) = Xe6, De7(L X, Xe5) = Xe7.
If we set L X = 0, then any pair X1, X2 ∈F2 determines a unique set of values
Xe1, ...Xe7, so we may deﬁne the local encoding functions for the edges e1, ..., e7 by
Fe1(X1) = De1(0, X1) = Xe1, Fe2(X1) = De2(0, X1) = Xe2, Fe3(X2) = De3(0, X2) = Xe3,
Fe4(X2) = De4(0, X2) = Xe4, Fe5(X{e2,e3}) = De5(0, X{e2,e3}) = Xe5,
Fe6(Xe5) = De6(0, Xe5) = Xe6, Fe7(Xe5) = De7(0, Xe5) = Xe7.
The decoding functions for u1 and u2 are given by
D′
u1(X{e4,e7}) := Du1(0, X{e4,e7}) = X1 and D′
u2(X{e1,e6}) := Du2(0, X{e1,e6}) = X2.
The stronger version of the equivalence between network and index coding is
given by the following.
Theorem 24 ([18, Theorem 1]) Let I ′ be an instance of the network coding prob-
lem. Let I be the corresponding instance of the index coding problem with broadcast

288
E. Byrne and M. Calderini
rate cB. For any rate vector R, any integer t, and any ε ≥0 it holds that I ′ is (ε, R′, t)
feasible if and only if I is (ε, R, cB, t) feasible.
Here R′ = (Rs : s ∈S) ∈ℜ|S| is a rate vector for I ′, indicating a transmission
rate of Rs for each source s ∈S, and R = (R′, ce : e ∈E ) ∈ℜn represents a rate
vector for I , where ce is the capacity of edge e in the network. The quantity cB is
the sum of the edge capacities: cB = 
e∈E ce. As before t is the block length. The
instance I ′ (respectively I ) is called (ε, R′, t)-feasible (respectively (ε, R, cB, t)-
feasible) if each terminal node can retrieve its required data with probability at least
1 −ε. The capacity region of the instance I ′ is the set of R′ such that for any ε, δ ≥0
the instance I ′ is (ε, (1 −δ)R′, t)-feasible for some blocklength t.
In spite of the equivalence demonstrated in Theorem 24, it is not known whether or
not the network coding capacity region of I ′ can be obtained by solving the capacity
region of the index coding instance I . This is referred to as capacity equivalence.
While this equivalence holds for linear codes, and for certain network topologies the
question of capapcity equivalence for general networks is unknown. The question
has an interesting connection to the edge removal problem.
5.2
Interference Alignment
Interference alignment is a technique used to manage interfering signals between
multiple sender-receiver pairs sharing the same channel. It has applications to dis-
tributed storage problems in network coding [9]. Such interference is common
in wireless networks, where topological interference management (TIM) may be
viewed as an index coding problem, with multiple data streams competing for a
common communication link [23, 27]. The term alignment comes from the fact that
the method exploits communication differences between clients, so that alignment of
signals for one user may yield orthogonality at another. The index coding analogue
is that diversity of side information among different users means that even though
alignment occurs at the broadcast, different users can still decode their own different
demands. In several cases, as shown in [27], optimal solutions of the index coding
problem provide optimal solutions of the TIM problem. We brieﬂy outline how the
scalar-linear (t = 1) ICSI problem may be viewed as a TIM problem, as described
in [27].
A scalar-linear index coding scheme of length N for an instance I = (X , f )
can be described as follows. There are
• precoding vectors L1, ..., Ln ∈FN×1
q
and
• for each pair (k,r = f (k)), receiver combining vectors Ur,k ∈F1×N
q
, satisfying
Ur,kLi = 0 if i ̸= r and i /∈Xk and is non-zero if i = r.
The sender then transmits
L X = [L1, ..., Ln][X T
1 , ..., X T
n ]T .

Index Coding, Network Coding and Broadcast with Side-Information
289
If r = f (k) then User k retrieves its demand Xr via
(Ur,kLr)−1Ur,k(L X −

i∈X k
Li Xi) = (Ur,kLr)−1Ur,k(

i /∈X k
Li Xi)
=

i /∈X k
(Ur,kLr)−1(Ur,kLi)Xi
= Xr +

i /∈X k,i̸=r
(Ur,kLr)−1(Ur,kLi)Xi
= Xr.
Choosing b(k) = (U f (k),kL f (k))−1U f (k),k and u(k) = (U f (k),kL f (k))−1U f (k),kLX k
yields a solution to the index coding problem as given in (4).
The alignment property corresponds to linear dependence among the columns
of L, which results in reduction of broadcast rate. If all columns of L are linearly
independent, N = n and the transmission rate is the same as for routing, that is,
where every transmitted symbol occupies a different time-slot. In TIM, the side-
information, Xi, of the ith user is called an antidote for the messages {X j, j ∈Xi}.
User i uses its antidotes to effectively cancel |Xi| columns of L and to hence observe
a linear combination of n −|Xi| −1 interfering vectors in the column space of the
remaining columns of L, i.e. in the column space of L[n]\(X i∪f (i)). Therefore, a
necessary condition for decoding at the ith receiver is that the column space of
L f (i) has trivial intersection with the column space of L[n]\(X i∪f (i)). In particular,
resolvability for User i requires the dimension of the space spanned by the interfering
columns of L, those indexed by [n]\(Xi ∪f (i)) should be no more than n −1, in
which case the interfering vectors must align in an n −1 dimensional space.
In Fig.5.2, the diagram on the left is the index coding instance shown already
in Fig.5.1. The image on the right is a related interference alignment problem. The
upper nodes represent transmitters and the lower nodes are receivers. In the TIM
graph shown a receiver node is connected to a sender node if the receiver lies within
the transmission range of the sender. In the corresponding index coding problem,
there is a link from a source node to a receiver if and only if it is absent in the TIM
graph (Fig.12).
An optimal solution to the toy index coding instance shown above (for which
receivers 1, ..., 4 demand X1, X2, X3, X1 respectively) is given by
L = [L1, L2, L3] =
 100
011

.
In the language of TIM, we say that there is alignment with respect to L2 and L3.
The vectors
U1,1 = [1 0],U2,2 = [0 1],U3,3 = [0 1],U4,1 = [1 0],

290
E. Byrne and M. Calderini
edge capacities cB
x1
x2
x3
x1
x2
x3
x1
S1
S2
S3
R1
R2
R3
R4
Fig. 12 Topological interference management and index coding
satisfy the conditions as described above, so each kth user can decode its demand
X f (k). For example,
X f (1) =

[1 0]
 1
0

[1 0]
⎛
⎝
 100
011
 ⎡
⎣
X1
X2
X3
⎤
⎦−X3
 0
1
⎞
⎠= X1
5.3
The Coded Caching Problem
The canonical coded-caching problem [28] corresponds to the placement phase of
a special class of the instances (C , R), as introduced in Sect.2. First it is assumed
that the n packets of X comprise k blocks X(i), ..., X(k) of size ℓ(so that n = kℓ)
and that each ith user wants some complete block, say X( j), after delivery. So Ri is
an ri × n matrix of the form
Ri = [O · · · H · · · O]
for some ri × ℓmatrix H with standard basis vectors of length ℓas rows. Each user
has a subset of some number of packets from each block and the same number of
packets v in total. In terms of (C , R), this imposes the constraints that for each i,
• V (i) is an v × n matrix,
• Ri and V (i) have standard basis vectors as rows,
• the jth block of ℓcolumns of V (i) has some ℓ−ri standard basis vectors of length
ℓas columns that complete H to a basis of Fℓ
q.
If a subset of users wish to receive the same block, the delivery to that set of users
becomes a local multicast problem.
The main difference between the coded-caching problem and the index coding
problem is the role of the sender in the placement phase. The index coding problem

Index Coding, Network Coding and Broadcast with Side-Information
291
is essentially one of delivery for given (C , R); the placement is not necessarily
controlled by the sender. However, in the coded caching problem, we seek an optimal
placement of the side-information code C in advance of knowing the users’ request
matrix R. The sender tries to choose C in such a way that for any R all users’ demands
can be met with a small number of transmissions. More precisely, the coded caching
problem seeks to ﬁnd, or obtain bounds on:
min{max{κ(R, C ) : R ∈Fr×n
q
} : C = C1 ⊕· · · Cm, dimCi = riv}.
In [28] the authors use the cut-set bound to derive a lower bound on the optimal
storage memory rate trade-off. Furthermore, they devise a scheme that achieves
this rate within a constant factor. So asymptotically, the canonical coded caching
problem is solved. Moreover, it was shown in [39] that improvements to the scheme
presented in [28] can only be achieved by considering caching schemes with coded
side-information.
For example, the matrices V (i) may have rows that are not standard basis vectors,
which corresponds to the cache data (the side-information) being encoded. Then Ci
is an arbitrary nv-dimensional matrix code for each i. In [35] the authors propose a
scheme for coded-caching with coded side-information using MDS and rank metric
codes. Their scheme delivers an improvement in the memeory-rate trade-off of sev-
eral known schemes and are in some cases optimal. However, their scheme requires
large ﬁeld sizes.
References
1. N. Alon, A. Hassidim, E. Lubetzky, U. Stav, A. Weinstein, Broadcasting with side information,
in Proceedings 49th Annual IEEE Symposium on Foundation of Computer Science (FOCS)
(2008), pp. 823–832
2. Z. Bar-Yossef, Z. Birk, T.S. Jayram, T. Kol, Index coding with side information, in Proceedings
of 47th Annual IEEE Symposium Foundations of Computer Science (2006), pp. 197–206
3. Z. Bar-Yossef, Z. Birk, T.S. Jayram, T. Kol, Index coding with side information. IEEE Trans.
Inf. Theory 57(3), 1479–1494 (2011)
4. E. Byrne, M. Calderini, Error correction for index coding with coded side information, in
IEEE Transactions on Information Theory, vol. 63(6), published online, 27 March 2017, pp.
3712–3728. https://doi.org/10.1109/TIT.2017.2687933
5. E. Byrne, M. Calderini, Bounding the Optimal Rate of the ICSI and ICCSI Problems, SIAM
J. Discret. Math. 31(2), 1403–1427 (2017). arXiv:1604.05991
6. Y. Birk, T. Kol, Informed source coding on demand (ISCOD) over broadcast channels, in
Proceedings of IEEE Conference on Computer Communication (San Francisco, CA, 1998),
pp. 1257–1264
7. A. Blasiak, R. Kleinberg, E. Lubetsky, Broadcasting with side information: bounding and
approximating the broadcast rate. IEEE Trans. Inf. Theory 59(9), 5811–5823 (2013)
8. Z. Chen, P. Fan, K.B. Letaief, Fundamental limits of caching: improved bounds for users with
small buffers. IET Commun. 10(17), 2315–2318 (2016)
9. V.R. Cadambe, S.A. Jafar, H. Maleki, K. Ramchandran, C. Suh, Asymptotic interference align-
ment for optimal repair of MDS codes in distributed storage. IEEE Trans. Inf. Theory 59(5),
2974–2987 (2013)

292
E. Byrne and M. Calderini
10. E.J. Candès, B. Recht, Exact matrix completion via convex optimization. Found. Comput.
Math. 9(6), 717–772 (2009)
11. T.H. Cormen, C. Stein, R.L. Rivest, C.E. Leiserson, Introduction to Algorithms, 2nd edn.
(McGraw-Hill Higher Education, New York, 2001)
12. M. Dai, K.W. Shum, C.W. Sung, Data dissemination with side information and feedback. IEEE
Trans. Wireless Commun. 13(9), 4708–4720 (2014)
13. S.H. Dau, V. Skachek, Y.M. Chee, On the security of index coding with side information. IEEE
Trans. Inf. Theory 58(6), 3975–3988 (2012)
14. S.H. Dau, V. Skachek, Y.M. Chee, Error correction for index coding with side information.
IEEE Trans. Inf. Theory 59(3), 1517–1531 (2013)
15. S.H. Dau, V. Skachek, Y.M. Chee, Optimal index codes with near-extreme rates. IEEE Trans.
Inf. Theory 60, 1515–1527 (2014)
16. P. Erdös, Z. Füredi, A. Hajnal, P. Komja’th, V. Rödl, A. Seress, Coloring graphs with locally
few colors. Discret. Math. 59(1), 21–34 (1986)
17. H. Esfahanizadeh, F. Lahouti, B. Hassibi, A matrix completion approach to linear index coding
problem, in Information Theory Workshop (ITW) (IEEE, 2014), pp. 531–535
18. M. Effros, S. El Rouayheb, M. Langberg, An equivalence between network coding and index
coding. IEEE Trans. Inf. Theory 61(5), 2478–2487 (2015)
19. A. El Rouayheb, A. Sprintson, C. Georghiades, On the index coding problem and its relation
to network coding and matroid theory. IEEE Trans. Inf. Theory 56(7), 3187–3195 (2010)
20. M. Fazel, H. Hindi, S. Boyd, Rank minimization and applications in system theory in American
Control Conference, vol. 4 (IEEE, 2004), pp. 3273–3278
21. W. Haemers, An upper bound for the Shannon capacity of a graph. Colloq. Math. Soc. Jànos
Bolyai 25 (1978)
22. X. Huang, S. El Rouayheb, Index coding and network coding via rank minimization, in IEEE
Information Theory Workshop (ITW) (2015), pp. 14–18
23. S.A. Jafar, Topological interference management through index coding. IEEE Trans. Inf. The-
ory 60(1), 529–568 (2014)
24. H. Loeliger, An upper bound on the volume of discrete spheres. IEEE Trans. Inf. Theory 40(6),
2071–2073 (1994)
25. N. Lee, A.G. Dimakis, R.W. Heath Jr, Index coding with coded side-information. IEEE Com-
mun. Lett. 19(3)(2015)
26. Eyal Lubetzky, Uri Stav, Nonlinear index coding outperforming the linear optimum. IEEE
Trans. Inf. Theory 55(8), 3544–3551 (2009)
27. H. Maleki, V.R. Cadambe, S.A. Jafar, Index coding - an interference alignment perspective.
IEEE Trans. Inf. Theory 60(9), 5402–5432 (2014)
28. M. Maddah-Ali, U. Niesen, Fundamental limits of caching. IEEE Trans. Inf. Theory 60(5),
2856–2867 (2014)
29. R. Peeters, Orthogonal representations over ﬁnite ﬁelds and the chromatic number of graphs.
Combinatorica 16(3), 417–431 (1996)
30. K. Shanmugan, A. Dimakis, M. Langberg, Graph theory versus minimum-rank for index cod-
ing, in Proceedings of the 2014 IEEE International Symposium on Information Theory (ISIT)
(2014), pp. 291–295. arXiv:1402.3898.v1
31. J. Saunderson, M. Fazel, B. Hassibi, Simple algorithms and guarantees for low rank matrix
completion over F2. IEEE Int. Symp. Inf. Theory (ISIT). Barcelona 2016, 86–90 (2016)
32. D. Silva, F.R. Kschischang, R. Koetter, Communication over ﬁnite-ﬁeld matrix channels. IEEE
Trans. Inf. Theory 56(3), 1296–1305 (2010)
33. K.W. Shum, D. Mingjun, C. Sung, Broadcasting with coded side information. 2012 IEEE 23rd
Int. Symp. Pers. Indoor Mobile Radio Commun. (PIMRC) 89(94), 9–12 (2012)
34. V.Y.F. Tan, L. Balzano, S.C. Draper, Rank minimization over ﬁnite ﬁelds: fundamental limits
and coding-theoretic interpretations. IEEE Trans. Inf. Theory 58(4), 2018–2039 (2012)
35. C. Tian, J. Chen, Caching and delivery via interference elimination, in 2016 IEEE International
Symposium on Information Theory (ISIT) (2016), pp. 830–834

Index Coding, Network Coding and Broadcast with Side-Information
293
36. A.S. Tehrani, A.G. Dimakis, M.J. Neely, Bipartite index coding, in Proceedings of the IEEE
2012 International Symposium on Information Theory (ISIT) (Boston, 1-6 Jul 2012), pp. 2246–
2250
37. J.I. Tamir, E.R. Elenberg, A. Banerjee, S. Vishwanath, Wireless index coding through rank
minimization, in IEEE ICC 2014 - Wireless Communications Symposium (2014), pp. 5209–
5214
38. M.F. Wong, M. Langberg, M. Effros, On a capacity equivalence between network and index
coding and the edge removal problem, in 2013 IEEE International Symposium on Information
Theory (2013), pp. 972–976
39. K. Wan, D. Tuninetti, P. Piantanida, On the optimality of uncoded cache placement, in 2016
IEEE Information Theory Workshop (ITW) (2016), pp. 161–165
40. K. Shanmugam, A.G. Dimakis, M. Langberg, Local graph coloring and index coding, in 2013
IEEE International Symposium on Information Theory Proceedings (ISIT) (2013), pp. 1152–
1156
41. P. Jain, P. Netrapalli, S. Sanghavi, Low-rank matrix completion using alternating minimization,
in Proceedings of the forty-ﬁfth annual ACM symposium on Theory of computing (ACM, 2013),
pp. 665–674
42. M. Hardt, Understanding alternating minimization for matrix completion, in IEEE 55th Annual
Symposium on Foundations of Computer Science (FOCS) (2014), pp. 651–660

Implementation of Network Coding
in Wireless Systems
Semiha Tedik Basaran, Ali Reza Heidarpour, Selahattin Gokceli,
Gunes Karabulut Kurt, Murat Uysal and Ibrahim Altunbas
Abstract In this chapter, we target to give extensive performance analyses about
application of network coding (NC) in wireless systems, referred to as network
coded cooperation (NCC), brings both diversity and multiplexing gains. We use
the diversity-multiplexing trade-off (DMT) to determine performance bounds of
NCC systems. Within the scope of this study, NCC is integrated with orthogo-
nal frequency division multiple access (OFDMA) and the corresponding system
model is characterized by speciﬁcally focusing on frequency diversity gain. DMT
expressions of the NCC-OFDMA system is given. A real-time implementation of
the NCC-OFDMA system is presented by creating a testbed NI USRP-2921, NI
PXIe-5644R, NI PXI-6683H software deﬁned radio (SDR) modules and LabVIEW
software. Obtained real-time performance measurements are essential to demon-
strate the practical advantages or disadvantages of the usage of the NCC-OFDMA
system. Overall, we aim to present a detailed overview of the fundamental perfor-
mance bounds of NCC and its extension to the practical applicability of NCC in
wireless networks.
S. Tedik Basaran (B) · S. Gokceli · G. K. Kurt · I. Altunbas
Department of Communications and Electronics Engineering, Istanbul Technical University,
3469 Istanbul, Turkey
e-mail: tedik@itu.edu.tr
S. Gokceli
e-mail: gokcelis@itu.edu.tr
G. K. Kurt
e-mail: gkurt@itu.edu.tr
I. Altunbas
e-mail: ibraltunbas@itu.edu.tr
A. R. Heidarpour
Department of Electrical and Computer Engineering, University of Alberta, Edmonton,
AB T6G 2R3, Canada
e-mail: alirezaheidarpour@ualberta.ca
M. Uysal
Department of Electrical and Electronics Engineering, Ozyegin University,
34794 Istanbul, Turkey
e-mail: murat.uysal@ozyegin.edu.tr
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_11
295

296
S. Tedik Basaran et al.
1
Introduction
In classical routing applications, intermediate nodes simply store and forward the
received symbol to the destinations or other intermediate nodes without modifying
the content of received packets. As 5G and beyond 5G communication technologies
target high data rate and low delay demands based on real-time applications in dense
network scenarios, the efﬁcient usage of network resources (bandwidth, power, and
time) becomes critical at intermediate nodes to jointly increase the throughput and
reduce the delay. Network coding (NC) is proposed as a smart routing solution which
meets high throughput and low latency demands [1].
The transmission process of NC systems is completed in two orthogonal phases;
the broadcast phase and the relaying phase. In the broadcast phase, information
symbols are radiated from source nodes and received by intermediate nodes (referred
to relay nodes hereafter). Relay nodes typically decode the received symbols and
combine symbols from multiple sources to obtain network coded symbols. In the
relaying phase, each relay node determines the NC coefﬁcients based on the selected
coding type for all symbols and encodes the detected source symbols. Then, relay
nodes forward the encoded symbols to destination nodes. Each destination node
needs to receive several coded symbols, at least as many as the number of source
nodes, to successfully decode the transmitted symbols.
In classical routing schemes, relay nodes sequentially send the received symbols,
which may cause a high delay and a low data rate. Hence, by using NC, the data
rate can be increased while obtaining low transmission latency. NC has a ﬂexible
nature for an extension to multiple source and multiple relay cases by determining
different code sets for each relay. Hence, we can use NC as a smart routing tool, by
efﬁciently serving dense network users, furthermore it can be used as a solution for
the scalability problem in dense networks. We focus on linear NC in this chapter, but
there are also some works about non-linear mapping schemes on received bits [2].
The application of NC in wireless networks inherently holds one advantage and
one disadvantage. Firstly, there may be direct links that may be used to provide
an improved error performance, between source and destination pairs due to the
broadcast nature of wireless channel. On the other hand, error propagation may
emerge at destination node due to wireless channel impairments. Whether a direct
link, also termed as cooperation link, is present or not depends on the corresponding
link qualities. These links provide additional cooperative diversity to improve the
error performance [3]. Hence, when the implementation of NC in wireless networks
is designed by considering cooperation links, the system is named as network coded
cooperation (NCC). NCC has higher diversity gain and increased spectral efﬁciency
when compared to NC with the help of cooperation links.
Wireless networks are more prone to transmission errors when compared to wired
counterparts due to channel impairments. In the early works on NC, only error-free
cases are considered [1]. Although this is a valid assumption for wired networks,
it is not realistic for wireless networks. As mentioned above, different from NC,
in NCC, destination nodes use the source symbols that are received through direct

Implementation of Network Coding in Wireless Systems
297
links in the broadcast phase to improve the error performance. Hence, destination
nodes have multiple received symbols in both broadcast and relaying phases. The
symbols received in the relaying phase are encoded by using the selected network
code. A combining procedure at destination nodes needs to be used to exploit full
diversity. As the combining procedure, there are two frequently used detector types;
the rank-based detector [4] and the maximum likelihood (ML) [5] detector.
Diversity-multiplexing trade-off (DMT) is a tool that determines the set of diver-
sity and multiplexing gain pairs that can be obtained simultaneously for commu-
nication systems. DMT can be used to assess the performance of NCC systems.
The asymptotic DMT of NCC systems is studied in [6, 7]. These works focus on
time-division multiple access (TDMA) to preserve orthogonality among different
source and relay transmissions. On the other hand, [8] considers an efﬁcient multi-
ple access technique, orthogonal-frequency division multiple access (OFDMA), to
provide orthogonality while providing frequency diversity gain. This system model
is called as NCC-OFDMA.
The theoretical DMT results of NCC-OFDMA system which is superior accord-
ing to benchmark systems is presented in [8]. In [9], an NCC-OFDMA framework is
established to evaluate its performance by using software deﬁned radio (SDR) nodes.
The results show that NCC-OFDMA system enables easy implementation and pro-
vides higher reliability against wireless channel errors, leading to higher throughput
when compared to its NC counterpart. Through implementation, real-time issues are
analyzed and insights about a more comprehensive deployment are shared.
The aim of this chapter is to show with theoretical analysis and practical applica-
tion scenarios, that NCC is a strong candidate for next generation wireless systems.
We address the theoretical performance bounds of NCC through DMT analyses and
highlight practical application challenges with real-time implementation by using
SDR nodes. In order to evaluate the system performance, bit error rate (BER), error
vector magnitude (EVM) and signal-to-noise ratio (SNR) metrics are used.
The rest of this chapter is organized as follows. In Sect.2, the signalling model
of NCC-OFDMA system and coding details are given. After that, DMT results of
NCC system are given in comparison with the state-of-the-art studies in Sect.3. In
Sect.4, implementation and test results of NCC-OFDMA system are presented. The
beneﬁts of NCC-OFDMA are emphasized in Sect.5.
2
Basic Principles
System models of NC and NCC are given in Fig.1 a, b, respectively. Both two
systems include P source nodes, M relay nodes, and a single destination node. The
main advantage of NCC different from NC is the exploitation of direct transmission
links between source and destination pairs, as shown in the ﬁgure. In the linear NC
system, the destination node has M network-coded symbols, composed of linear
combinations of P source symbols. In order to recover all P source symbols, the
destination node needs at least P symbols, hence, we need to satisfy P ≤M the

298
S. Tedik Basaran et al.
(a)
(b)
Fig. 1 a Block diagram of NC system. b Block diagram of NCC system with the presence of direct
source to destination links
constraint in an NC system. On the other hand, this necessity is eliminated due to the
presenceofdirecttransmissionlinksintheNCCsystem.Thedirecttransmissionlinks
assist the relay-aided communication by providing additional cooperative diversity
gain.
NCC systems using TDMA strategy are generally planned for multiple users. To
exploit frequency diversity gain while ensuring orthogonality among multiple users,
OFDMA technique is considered for multiple access for NCC systems, referred to
as NCC-OFDMA. The transmission process of the NCC-OFDMA system is also
completed in two orthogonal phases: broadcast and relaying phases. In the broadcast
phase, all source nodes emit their own signals. The signals of the sources can be
captured jointly by the relay nodes and the destination node because of the broadcast
nature of wireless channel. In the wireless systems, the transmission qualities of
source-relay links are generally considered to be higher than the source-destination
links. Therefore, the subcarrier assignment process is performed according to the
attributes of the source-destination links. Following the broadcast phase, the relay
nodes demodulate the signals when they received during the broadcast phase and
combine them by using the coefﬁcients of the selected network code. The combined
symbols formed at the relay nodes are called network coded symbols. After that, in
the relaying phase, relay nodes transmit the network coded symbols to the destination
nodes.
Let the frequency domain representation of the nth subcarrier channel gain of link
t be given by Ht[n], where t ∈{sid, sir j, r jd}, i = 1, . . . , P, j = 1, . . . , M, n ∈
Ft with Ft is the set of the assigned subcarriers of the transmitter of link t. The number
of subcarriers is equal to N. All transmissions are carried out with unit power in the
system. The received signal from jth relay node of ith source node in the broadcast
phase is given as:
Ysir j[n] = Hsir j[n]Xi[n] + Wsir j[n],
(1)
where Wsir j[n] represents the additive white Gaussian noise (AWGN) at the jth
relay node. jth relay node detects Xi[n] by using Ysir j[n], and the detected symbol

Implementation of Network Coding in Wireless Systems
299
is denoted by ˜Xi j[n]. The network code coefﬁcients indicated by αi j can be selected
from a maximum distance separable (MDS) code satisfying the Singleton bound
[10], maximum rank distance (also called Gabidulin) codes [11] or can be generated
randomly in random network coding (RNC). By using ˜Xi j[n] and αi j values the
network coded symbol at jth relay node is calculated as:
C j[n] = α1 j ˜X1 j[n]✢α2 j ˜X2 j[n] . . . , ✢αPj ˜X Pj[n]
(2)
where ✢denotes the summation operator in the ﬁeld, GF(q), where q is the size of
the ﬁeld. Source and network coded signals received by the destination node in two
phases from the source and relay nodes are deﬁned as follows:
Ysid[n] = Hsid[n]Xi[n] + Wsid[n]
Yr jd[n] = Hr jd[n]C j[n] + Wr jd[n],
(3)
where AWGN components at the destination node in the broadcast and relaying
phases are denoted by Wsid[n] and Wr jd[n], respectively.
If we assume error-free transmission among source-relay pairs, ( ˜Xi j = Xi), to
simplify the expressions, the vector notation of received signals can be given as:
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Ys1d
Ys2d
...
YsPd
Yr1d
...
YrMd
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎣
a1 0 · · · 0
α11 · · · α1M
0 a2 · · · 0
α21 · · · α2M
...
... ... ...
...
...
...
0 0 · · · aP αP1 · · · αPM
⎤
⎥⎥⎥⎦
T ⎡
⎢⎢⎢⎣
X1
X2
...
X P
⎤
⎥⎥⎥⎦,
(4)
which can be also expressed as y = Zx. The ﬁrst P entries of y represent the received
symbols of the direct transmission links among source and destination nodes. If the
ith direct transmission link is available, ai is equal to 1, otherwise it is equal to 0. αi j
is generated from GF(q) according to the current coding scheme in the relay nodes.
The last M entries of y denote the received encoded symbols from M relay nodes.
Z indicates the global coding matrix of NCC, consisting of direct link and relay link
coefﬁcients. The aim of destination node is to recover x from y thanks to Z. Detailed
explanations and comparisons about signal modeling of NC and NCC can be found
in [12]. We explain the detection methods of NCC in detail to show effect of the
detector on the system in the next subsection.

300
S. Tedik Basaran et al.
2.1
Detector Design
There are two receiver strategies of NC depending on the availability of the global
coding matrix (Z) at destination node: coherent and non-coherent NC. Most of NC
and NCC works assume that destination node knows the coding coefﬁcients [4, 13],
andthisstrategyisnamedascoherentNC.Ontheotherhand,ifcodingcoefﬁcientsare
not available at the destination node, the destination node can obtain the coefﬁcients
through transmitting pilot symbols. This second approach is called non-coherent
NC [14]. In order to recover source symbols, a new coding metric based on sub-
spaces is proposed against erasures and errors of non-coherent RNC. To obtain x,
Gauss–Jordan elimination method can be used to solve the set of linear equations of
NCC over GF(q) [4, 13]. To apply Gauss–Jordan elimination for obtaining P source
symbols, we need at least P independent equations. This condition corresponds to
Z to be of full rank. In addition to performance corruptions due to wireless channels
as mentioned above, incorrect estimations of Xi at relay nodes may cause error
propagation at destination node.
2.2
Code Design
Coding coefﬁcients, αi j, can be selected from different linear code sets like as MDS
[10], maximum rank distance (also called Gabidulin) codes [11] or be produced
randomly [4, 13]. MDS codes achieve equality in Singleton bound [11], and are
preferred in different applications as error correction and storage. MDS codes are
accepted as an important coding class due to their capabilities about error detection
and error correction based on the Hamming distance criterion. The redundancy-
reliability ratio of MDS codes is the optimal.
The other class of coding includes rank distance approach. In the rank distance
approach, the code construction is based on detecting and correcting of rank errors
by supplementing redundancy [11]. Instead of selecting from predetermined code
sets, in RNC, network code coefﬁcients can be generated randomly. In RNC, cod-
ing coefﬁcients have a uniform distribution and independently chosen from GF(q).
RNC yields ﬂexible scheduling opportunity to NCC systems based on dynamically
changing network components with improving the efﬁciency of the NCC systems.
To obtain more information about the dynamic coding according to wireless channel
can be found in chapter “Opportunistic Network Coding”.
2.3
On the Resource Usage of NCC
In both NC and NCC, broadcast and relaying phases are completed in P and M
orthogonal transmission blocks, respectively. TDMA, which causes undesired delay
for dense networks, can be used to provide orthogonality between transmission links.
On the other hand, multiplexing gain can be obtained by allocating transmission

Implementation of Network Coding in Wireless Systems
301
links in frequency domain thanks to OFDMA. At the same time, OFDMA provides
additional frequency diversity gain through assigning different subcarriers to users
according to channel quality of each subcarrier to the corresponding user. There are
also joint resource allocation schemes to unify assigning of various limited resources
as power, subcarrier, and bits. Employing subcarrier allocation processes can improve
the efﬁciency of the system. The comparative theoretical performance bounds of
various NCC schemes will be assessed in the following section by providing DMT
results.
3
Performance Limitations and DMT Analysis of NCC
Due to occurence at the same time, there is a fundamental trade-off referred to as
DMT between diversity and multiplexing gains of a communication systems. DMT
is an appropriate tool to evaluate performance of NCC-OFDMA system.
3.1
DMT of NCC Systems and Comparison with Cooperative
Communication Protocols
Figure2 depicts diversity gain d versus multiplexing gain r for various cooperative
communication protocols. It is known that conventional cooperative (CC) systems
including space-time coding [3] and opportunistic relaying [15] achieve the same
DMT of d(r) = (M + 1)(1 −2r), r ∈(0, 0.5).
In [6], Peng et al. consider a NCC system which consists of P source-destination
pairs and M relay nodes with dynamic coding (DC-NCC). Particularly, the “best”
relay (which has the best end-to-end path between source and destination) among the
set of M available relay nodes are selected and then the relay dynamically employs
XOR operation on the source packets based on instantaneous source to relay channel
quality. It is shown that the DC-NCC system can achieve a full diversity gain of
M + 1. However, diversity gain of M + 1 can only be obtained under the assumption
where the destination can successfully overhear the data from other source nodes. If
this optimistic assumption is removed, the achievable diversity gain of the DC-NCC
system reduces to only two and does not improve by increasing the number of relay
candidates.
In an effort to improve the diversity gain, random NCC (RNCC) system and
deterministic NCC (DNCC) system are presented in [7], where relay nodes encode
the sources’ packets using an encoding matrix of size (P + M) × P. As described
in the previous section, in this setup, the ﬁrst P rows form an identity sub-matrix,
corresponding to the direct transmissions in the broadcasting phase. In addition, the
remaining columns and rows correspond to the packets transmitted by relays in the
relaying phase. In DNCC system the coefﬁcients in the encoding matrix are preset
while in RNCC system are drawn randomly from ﬁnite ﬁeld. The associated DMT

302
S. Tedik Basaran et al.
1
P
P
P
P
M
1
0.5
r
( )
d r
1
M
2
1
Non-Cooperative
Repetition Coding
DC-NCC
DNCC, RNCC
CC 
Space-Time Coding,
 Opportunistic Relaying
1
1
M
Ideal
Fig. 2 DMT comparison for different cooperative communication protocols
analysis reveals that a full diversity gain of M + 1 can be maintained through the
use of MDS codes typically used for point to point channels.
The DMT expressions of DC-NCC and DNCC/RNCC systems are given in [7].
As can be seen from Fig.2, CC and RNCC/DNCC systems can achieve full diversity
gain of M + 1 whenr = 0. However, DNCC/RNCC systems outperform CC systems
in terms of multiplexing gain and offer higher diversity gain than that of CC systems
for the same spectral efﬁciency. On the other hand, in comparison to other schemes,
DC-NCC systems have the highest multiplexing gain and offer more diversity gain
as r increases. This is due to the fact that only one relay XOR’es source packets
and therefore the overall transmission takes place in P + 1 orthogonal time slots. It
is worth mentioning that as P increases the spectral efﬁciency of the NCC systems
movestowardstheidealcase.Therefore,NCCsystemshavebetterDMTperformance
and outperform CC systems. On the other hand, repititon coding which is based on
simply repeating the data bits, has the worst DMT performance.
3.2
Extension to CC-OFDMA
In CC systems, relay nodes either amplify and transmit (amplify-and-forward relay-
ing) or decode and retransmit (decode-and-forward relaying) the source signals to
the destination without any combining operation. It is shown that both protocols can
achieve full diversity gains [16] and therefore CC with OFDMA, referred to as CC-

Implementation of Network Coding in Wireless Systems
303
OFDMA systems are expected to extract both frequency and spatial diversity. In the
literature, DMT performance of CC-OFDMA system has been studied in [17]. The
underlying assumption in [17] is that the subcarriers are independent. Furthermore,
just one subcarrier is allocated to each source node. The derived DMT expression is
given by [17]
d(r) = N(M + 1)(1 −2r),r ∈(0, 0.5).
(5)
The maximum diversity gain is obtained when multiplexing gain r = 0, i.e., N(M +
1). This means that both frequency and spatial diversity can be achieved in CC-
OFDMA. On the other hand, the maximum multiplexing gain can be obtained when
d(r) = 0, i.e., r = 0.5.
3.3
Extension to NCC-OFDMA
The aforementioned NCC systems [6, 7] build upon the assumption of TDMA. To
exploit the multipath diversity gains and have further gains over NCC systems, the
combination of OFDM with NCC has been investigated in the literature. More specif-
ically, in [8] the DMT performance of NCC-OFDMA system is studied. In the system
under consideration, the transmission rate for all nodes is equal to R0. There is L
number of coherence bandwidths due to the frequency selective channel. Further-
more, K1 = N/P and K2 = N/M are the numbers of subcarriers assigned to each
source and each relay in the broadcasting phase and the relaying phase, respectively.
This leads to different transmission rates for subcarriers in these two phases i.e.,
Rs1 = R0/K1 for the broadcasting phase and Rs2 = R0/K2 for the relaying phase.
By using Marcum Q-function of order one represented by Q1(·, ·), the outage prob-
abilities of subcarriers in the broadcasting phase for S →D links over Rician fading
channels are given by [8]
Pout SD
sub (K1) = 1 −Q1 (α, βSD) ,
(6)
where α =
√
2k and βSD =

2 (1 + k)
	
2Rs1 ˆN −1

 
ρ GSD. ρ is SNR and G XY is
normalized path loss expressions with respect to S →D links. Similarly, for S →R
links, the outage probability of the subcarriers is given by
Pout SR
sub (K1) = 1 −Q1 (α, βSR) ,
(7)
where βSR =

2 (1 + k)
	
2Rs1 ˆN −1

 
ρ GSR.
In Eqs.(6) and (7), k is Rician factor, ˆN is the number of subcarriers within the
coherence bandwidth while calculating as ˆN=N/L. On the other hand, the outage
probability of subcarriers in the relaying phase (i.e., R →D links) can be obtained as

304
S. Tedik Basaran et al.
Pout RD
sub (K2) = 1 −Q1 (α, βRD) ,
(8)
where βRD =

2 (1 + k)
	
2Rs2 ˆN −1

 
ρ G RD.
3.4
Relaying Strategies
Relay nodes which successfully decode all of their received packets from P source
nodes are allowed to participate in the relaying phase and the rows of the encoding
matrix corresponding to the relays with erroneous decisions are discarded. The DMT
expression of NCC-OFDMA system is given by [8]
d(r) =L(M + 1)

1 −P + M
P
max {P, M}
L
r

, r ∈

0,
P
P + M
L
max {P, M}

.
(9)
As expected, NCC-OFDMA systems are capable to fully extract both frequency
and spatial diversity and signiﬁcantly outperform NCC systems which build upon
TDMA. The DMT of CC-OFDMA system with the same system conﬁguration is
given by [8]
d (r) = L (M + 1)

1 −(M + 1) max{P, M}
L
r

, r ∈

0,
1
M + 1
L
max{P, M}

where all relay nodes transmit in the relaying phase or
d (r) = L (M + 1)

1 −2max{P, M}
L
r

, r ∈

0, 0.5
L
max{P, M}

where selection relaying is considered. As can be seen from Fig.3, both CC-OFDMA
and NCC-OFDMA systems achieve full diversity gain of L(M + 1) when r = 0.
However, maximum multiplexing gain of CC-OFDMA systems is always lower than
that of NCC-OFDMA systems indicating multiplexing gain loss in CC systems.
As another transmission strategy, if relay can decode even one packet correctly
from one of P source packets, it is allowed to participate in the relaying phase. In
this case, only the coefﬁcients in the encoding matrix corresponding to the erroneous
packets would be zero instead of discarding the whole row. Let Popt
out denote the
outage probability of the system under this assumption. A lower bound on the outage
probability Plow
out is the case when all the relays decode all P packets correctly and can
participate in the relaying phase i,e., m = 0 (see Eq.(14) of [8]) and the probability
that any relay successfully decodes all P packets received during the broadcasting
phase PR is equal to 1. Therefore, Pout in (16) of [8] is reduced to

Implementation of Network Coding in Wireless Systems
305
0.5 max{ ,
}
L
P M
r
( )
d r
NCC-OFDMA 
 CC-OFDMA
 (Relay Selection)
CC-OFDMA 
(All Relays Participate)
(
1)
L M +
+
1
   1 max{ ,
}
L
M
P M
  
max{ ,
}
P
L
P
M
P M
+
Fig. 3 DMT comparison for CC-OFDMA and NCC-OFDMA systems
Plow
out =
M

j=0
M
j

P M−j
outRD

1 −PoutRD
 j
P−1−j

i=0
P
i

P P−i
outSD

1 −PoutSD
i .
(10)
The lower bound of the outage probability in high SNR regime can be obtained as
lim
β→0 Plow
out = C′

exp

−α2
2
 β2
2
L(M+1)
,
(11)
where C′ = M
j=0
M
j

P
P−1−j

G−L(M−j)
RD
G−L( j+1)
SD
.
Note that, Plow
out < Popt
out < Pout. Using squeezing theorem [18], we have
L(M + 1) < −lim log(Popt
out )
log(ρ)
< L(M + 1).
(12)
Therefore, one can conclude that the slopes of outage probability in log-log scale
for Plow
out , Popt
out , and Pout are identical and the achievable diversity gain of the system
remains the same regardless of which relaying strategy is used. Therefore, the DMTs
under two relaying strategies are identical.

306
S. Tedik Basaran et al.
4
Practical Implementation of NCC
NCC-OFDMA system gives full diversity gain when multiplexing gain is equal
to zero and maximum multiplexing gain performance among the other fundamen-
tal systems while no diversity gain. In order to test its high theoretical capability,
the real time implementation of NCC-OFDMA system is necessary. To perform
the implementation of NCC-OFDMA system, SDR implementation is used. SDR
implementations of various wireless communication techniques have been realized
recently. This trend continues to grow because of the beneﬁts of SDR implemen-
tations over simulations. Modeling a transmission environment in simulation is not
realistic in most cases because hardware related issues show random characteristics
at each transmission and appropriate modeling of these becomes impossible.
CC structure that is inherent to NCC systems, may complicate the implementation
of NCC models in real-time. Such an implementation requires the realization of
multiple nodes in addition to proper communication between these nodes. As a
natural consequence of these requirements, accurate synchronization of these nodes
is a must in order to operate them cooperatively. Beyond these necessities, a ﬂexible
design is also necessary to deploy algorithms to hardware without any problem.
In order to create a functional NCC testbed, an SDR based testbed is implemented
in [9] by considering the mentioned aspects. A testbed was created for the real-time
implementation of proposed NCC model in order to observe performance from a dif-
ferent perspective and validate simulation results. As SDR components, LabVIEW,
NI USRP-2921 nodes, NI PXI-6683H module, and NI PXIe-5644R Vector Signal
Transceiver (VST) are used. NCC testbed is implemented with 5 NI USRP-2921 SDR
nodes where three of them are used as source nodes and other two nodes are used as
destination. We used two physically separated receivers to seperately examine their
performances. For relay node, NI PXIe-5644R VST module is utilized which can
operate in 65MHz to 6GHz frequency range and can support 80MHz instantaneous
bandwidth. Moreover, NI PXI-6683H timing and synchronization module which
includes a TCXO oscillator is used as synchronization source. All PXI modules are
managed via NI PXIe-1082 chassis. LabVIEW is used as software tool due to its
easy programming and SDR compatibility features.
As an expected necessity, NCC testbed needs a proper synchronization solution
for the robust performance due to its cooperative setup. Main component of this
solution is NI PXI-6683H module which provides 10MHz clock signal. This signal
is distributed to one destination and two source nodes via RF cables. Other nodes
receive this signal with MIMO cables from synchronized nodes. Due to initial con-
nection of VST module to the chassis, relay node is also synchronized with the same
synchronization resource. One drawback of this setup is the limitation of distances
between nodes due to limited lengths of cables. These cables are used because of
their sufﬁcient RF performances, longer cables have higher losses. This limitation
makes observing the effects of different distances on the system performance difﬁ-
cult, however we overcome this drawback by conﬁguring source gains properly. By
conﬁguring the hardware in LabVIEW code, synchronization solution is generated.

Implementation of Network Coding in Wireless Systems
307
In hardware side, RF cables are used to distribute synchronization signals to two
sources and one destination. Remaining pairs receive these signals via pair-wise
cables. In the software side, these cable connections are indicated by conﬁguring
corresponding settings and a code is used in order to start and manage the distribu-
tion of synchronization signals. For source, relay and destination functionalities, the
codes are prepared for each operation in LabVIEW. NCC related functions are also
implemented and necessary codes are prepared. In the end, a ﬂexible combination
of codes is obtained, where possible modiﬁcations about algorithm can easily be
realized.
A physical view of the testbed is shown in Fig.4. The measurement parameters of
the given implementation setup are deﬁned in Table1. It can be seen from Fig.4 that
physical distances between nodes are limited in the testbed. However, conﬁgured
distances as well as transmission gains provide realistic transmission environment.
Therefore,aproperbalancebetweendistanceandrealistictransmissionisempirically
determined and nodes are located accordingly. It is noteworthy to state that during
experiments, distances between nodes were longer, distances between source and
destination nodes were around 250cm. Particularly low transmission gains provide
more realistic transmission circumstances. In this case, a limited distance up to 1m is
sufﬁcient to separate nodes and obtain realistic transmission qualities which are also
veriﬁed with real-time experiments. It should be highlighted that two experimenta-
tion setups are considered. These two setups are differentiated with the link quality
between source and destination nodes, and relay’s transmission quality. In the ﬁrst
setup, source nodes have a lower path loss, and transmission quality between source
and relay as well as destination nodes is sufﬁcient, as will be shown via measurement
results. However, in the second setup source nodes cannot properly communicating
Fig. 4 Created testbed of NCC system

308
S. Tedik Basaran et al.
Table 1 The measurement parameters of the given setup
Carrier frequency
2.45 GHz
I/Q data rate
Megasamples/sec
Number of bits used in one frame
2080 bits
Number of 4-QAM symbols
1040 samples
Total number of subcarriers of the one user data
portion
320 samples
Number of reference subcarriers
40 samples
Number of source nodes
3
Number of relay node
1
Number of destination nodes
2
Zero padding length
120 samples
DFT length (N)
1200 samples
CP length samples
300
with destination nodes. Moreover, relay’s link quality is subject to a higher path loss,
when compared to the ﬁrst setup. When experiment results are evaluated, transmis-
sion gain levels also need to be considered with distance conﬁgurations.
4.1
Software Description
As mentioned, code of NCC-OFDMA system is prepared by using LabVIEW. In Lab-
VIEW, smaller code fragments known as subVIs are used to increase functionality.
Hence, the code includes several SubVI components for source, relay and destina-
tion nodes which are managed from a timed ﬂad structure. Relay network coding
SubVI implements network coding to data received by relay node and includes cor-
responding GF(4) multiplication and addition SubVI. In this SubVI, ﬁrstly received
source symbols from source nodes by the relay node are multiplied with correspond-
ing coefﬁcients iSR that represent whether data is received properly or not by the
relay node. Then these multiplication outputs are multiplied with αi j in GF(4) by
using GF(4) multiplication SubVI. The coding matrix consists of αi j which can be
deﬁned as:
Z =
⎡
⎣
1 0 0 1 0 0
0 1 0 0 1 0
0 0 1 1 1 1
⎤
⎦
T
.
(13)
Note that although only a single physical device is used as a relay node, there are three
linear components of the received source symbols are generated at the relay node.
Then, results of these are summed in GF(4) by using GF(4) addition SubVI for
each data loop. In result, three separate network coded symbols are obtained which
are transmitted by relay node’s transmitter in corresponding frequency resources.

Implementation of Network Coding in Wireless Systems
309
Fig. 5 Block diagram of the relay network coding SubVI
In multiplication and addition SubVI, GF(4) multiplication and addition tables are
implemented by using multiple array functions and case structures. An exemplary
view of relay network coding SubVI can be seen in Fig.5. With corresponding input-
output conﬁgurations, NCC-OFDMA code is obtained.
In order to measure the performance of our system, real-time tests are exper-
imented. As explained earlier, two different setups are created, where difference
between the setups are the different distance conﬁgurations between nodes. The
quality of each link between nodes is measured. Both NC and NCC results are mea-
sured to compare their performances. The results of all types of links are shown in
this section, except source-relay links because of their superior performances. For
measuring the link performance, EVM, SNR and BER metrics are measured for each
link. EVM and SNR metrics are measured in terms of percentage and dB respec-
tively, and given with these units in the tables. The EVM value of the ith source for
single OFDMA frame can be calculated as:
EV Mi =

1
|Fsi d|

n∈Fsi d
	
Ii[n] −˜Ii[n]

2
+
	
Q[n] −˜Q[n]

2
|vmax|
,
(14)
where Ii[n] ( ˜Ii[n]) and Qi[n] ( ˜Qi[n]) denote the real and imaginary components of
the Xi[n] ( ˜Xi[n]). |Fsid| represents the cardinality of the subcarrier set, where |vmax|
denotes the maximum absolute value of Xi[n].
For the ﬁrst setup, three different relay transmit gain levels are experimented
for each destination nodes. Because of directional differences between source-
destination pairs due to location differences, error performance of the sources can be
quite different from each other. In order to approximate error performances, source
gains are selected differently for each source node. However, diversiﬁed source per-
formances can provide more comprehensive results. Therefore, locations and gains
of sources are organized in a way that clear performance differences can be observed.
The source transmission gains of S1, S2 and S3 are set as 14, 8 and 6 dB respec-
tively.Thesegainshavenotbeenchangedduringtheexperiments.Asstated,theeffect

310
S. Tedik Basaran et al.
of source gain changes on the overall performance is observed with two setups. Each
one has a different location-gain adjustment. As the ﬁrst step, ﬁrst setup is experi-
mented. Firstly, source-destination link performances are evaluated to analyze per-
formance differences between source nodes. For D1, S2 has the worst transmission
performance where the S1 is the best one, as demonstrated in Table3. EVM and
BER results can be used for this analysis. EVM and BER results are obtained as
26.71% and 1.5 × 10−3 for the data transmitted by the S2 where results are lower for
the S1 node’s transmitted data, which are 15.09% and 1 × 10−6 respectively. SNR
results show similar differences, which can be observed from the Table3. EVM,
BER and SNR metrics are obtained as 18.73%, 4.5 × 10−4 and 14.82 dB for the data
transmitted by S3. As explained, transmission gains of source nodes are not changed
during each setup, however, usage of two different setups allows us to understand
the effect of different source node gains on the performance. This effect will be dis-
cussed when source-destination link performances of the second setup will be given.
If similar error performance evaluation is done for the D2, it can be observed from
the Table3 that S2 has the worst transmission performance and S1 has the best trans-
mission performance similar to results obtained for the D1. One difference is the fact
that error performance is slightly better for the S2, however, this is not valid for other
source nodes and their transmission performances slightly worse for the D2. EVM
and BER results for the transmission of S2 are obtained as 25.11% and 1.3 × 10−3
respectively. These values are obtained as 16.15% and 6 × 10−5 for the transmission
of S1 and 19.02% and 7 × 10−4 for the transmission of S3. Secondly, error perfor-
mance results of relay-destination links are obtained which are shown in Table2, and
performance results for the overall NC and NCC operations are obtained as in Table4.
Table 2 Relay-destination performances for the ﬁrst setup
Destination
Source
BER
EVM
SNR
D1
S1
1 × 10−6
15.09
15.72
S2
1.5 × 10−3
26.71
13.39
S3
4.5 × 10−4
18.73
14.82
D2
S1
6 × 10−5
16.15
15.31
S2
1.3 × 10−3
25.11
13.40
S3
7 × 10−4
19.02
14.38
Table 3 Source-destination link performances for the ﬁrst setup
Destination
Relay gain (dBm) BER
EVM
SNR
D1
−12
1 × 10−7
13.60
18.80
−16
1.6 × 10−4
15.59
15.57
−20
4.2 × 10−3
33.01
10.40
D2
−12
0
8.91
18.13
−16
9 × 10−5
14.71
16.50
−20
1 × 10−3
25.60
12.12

Implementation of Network Coding in Wireless Systems
311
Table 4 NC and NCC performances for the ﬁrst setup
Destination
Source
Relay gain (dBm) NC-BER
NCC-BER
D1
S1
−12
1.4 × 10−4
0
−16
5.5 × 10−4
2 × 10−5
−20
3.6 × 10−3
2.7 × 10−4
S2
−12
8.6 × 10−4
4.7 × 10−4
−16
1.3 × 10−3
8 × 10−4
−20
6.5 × 10−3
3.3 × 10−3
S3
−12
3.3 × 10−4
1.9 × 10−4
−16
5.5 × 10−4
3.4 × 10−4
−20
6 × 10−3
8 × 10−4
D2
S1
−12
0
0
−16
2.9 × 10−5
1 × 10−6
−20
7 × 10−4
4 × 10−5
S2
−12
6 × 10−4
6 × 10−4
−16
8 × 10−4
1 × 10−4
−20
1.7 × 10−3
8 × 10−4
S3
−12
0
0
−16
7.9 × 10−5
1.4 × 10−5
−20
1.1 × 10−3
4 × 10−4
For the D1, at −12 dBm relay transmit gain, EVM results for the relay-destination
links are obtained as 13.29, 13.74 and 13.78% respectively. BER results for the same
components are obtained as 1 × 10−7 on average. At the same relay transmit gain,
NC operation’s BER results for the transmissions of S1, S2 and S3 are obtained as
1.4 × 10−4, 8.6 × 10−4 and 3.3 × 10−4 respectively. When compared to the source-
destination link results, slight performance improvement can be observed. However,
NCC operation improves error performances further, where these error performances
for the source nodes are obtained as 0, 4.7 × 10−4 and 1.9 × 10−4 respectively. As
shown, NCC operation is quite effective and error performance for the transmission
of ﬁrst source node decreases to 0.
For the −16 dBm relay transmit gain, relay-destination link EVM results are
obtained as 15.14, 16.07 and 15.57% respectively. BER performance of the same
links are obtained as 1.6 × 10−4 on average. At the same conﬁguration, NC opera-
tion’s BER results increase and obtained as 5.5 × 10−4, 1.3 × 10−3 and 5.5 × 10−4
respectively. BER values decrease with the NCC operation, obtained as 2 × 10−5,
8 × 10−4 and 3.4 × 10−4 respectively.
For the −20 dBm relay transmit gain, error performances decrease further. For
this gain, BER results for the relay-destination links are obtained as 4.2 × 10−3 on
average and EVM results are obtained as 32.38, 32.66 and 34% respectively. At this
gain, BER results for the NC operation are obtained as 3.6 × 10−3, 6.5 × 10−3 and
6 × 10−3 respectively. Better performances are observed with NCC operation where

312
S. Tedik Basaran et al.
BER results are obtained as 2.7 × 10−4, 3.3 × 10−3 and 8 × 10−4 respectively. It
is clear that performances of relay transmissions are critical for robust NC or NCC
operation and if low relay transmit gain is used, reliable performance cannot be
obtained.
For the D2, at −12 dBm relay transmit gain, BER results of NC operation for
the transmissions of S1 and S3 are obtained as 0, where related value is 6 × 10−4
for the S2. NCC operation does not create any improvement, as the same BER val-
ues are obtained. Error performance results are better for the D2, compared to the
D1. This is due to better relay-destination link performances which create effective
improvements. EVM results of relay-destination links are obtained as on average
8.91% and transmissions are completed without any bit error in these links. At
the −16 dBm relay transmit gain, BER results of NC operation are obtained as
2.9 × 10−5, 8 × 10−4 and 7.9 × 10−5 for source nodes, respectively. For these relay
experiments, NCC operation creates clear performance improvements as correspond-
ing BER values are obtained as 10−6, 1 × 10−4 and 1.4 × 10−5 respectively. EVM
results are obtained as 14.71% and BER results are obtained as 9 × 10−5 on average
for relay-destination link transmissions. At the −20 dBm relay transmit gain, for
relay-destination links, EVM results and BER results are obtained as 25.6% and
1 × 10−3 on average, respectively. At the same gain, BER results of NC operation
are obtained as 7 × 10−4, 1.7 × 10−3 and 1.1 × 10−3 for source nodes, respectively.
Moreover, BER results of NCC operation are obtained as 4 × 10−5, 8 × 10−4 and
4 × 10−4 respectively and clear performance improvements are observed. In result,
when compared to the previous results, relay-destination links are important espe-
cially for NCC operation’s performance and certain improvements can be observed.
As a common observation, as relay transmission performance becomes better, NC
and NCC operations can decrease source-destination errors effectively.
As mentioned, one more setup is conﬁgured in order to create worse source-
destination and relay-destination link performances compared to the ﬁrst setup. For
this setup, two relay transmit gains are experimented because, performance results
of good relay transmit gain levels are evaluated in the ﬁrst setup and relay transmit
gain can be decreased to the minimum of −15 dBm, conﬁgurations below this value
results in poor performance results. It is noteworthy that gain level is a parameter
conﬁgured in the LabVIEW, performance of relay or source nodes should also be
evaluated by considering distances to destination nodes.
Asﬁrststep,source-destinationlinkperformancesaremeasuredwhicharedemon-
strated in Table5. For the D1, again, worst performance is performed by the S2 and the
S1 has the best performance. BER results for source nodes are obtained as 7 × 10−4,
2.2 × 10−3 and 1 × 10−3 respectively. Similarly, EVM results for source nodes are
obtained as 29.20, 35.64 and 34.97% respectively. SNR results verify error perfor-
mances and obtained as 11.41, 10.61 and 10.66 dB respectively. Same measure-
ments are also performed for the D2. BER results for source nodes are obtained as
2.3 × 10−3, 3.6 × 10−3 and 4.6 × 10−3 respectively. EVM measurement is also per-
formedandEVMresults areobtainedas 31.05, 35.45and39.11%respectively. More-
over, SNR values are measured as 11.16, 10.09 and 9.67 dB respectively. Therefore,
it is clear that S3 has the worst performance where the S1 has the best performance.

Implementation of Network Coding in Wireless Systems
313
Table 5 Source-destination link performances for the second setup
Destination
Source
BER
EVM
SNR
D1
S1
7 × 10−4
29.20
11.41
S2
2.2 × 10−3
35.64
10.61
S3
1 × 10−3
34.97
10.66
D2
S1
2.3 × 10−3
31.05
11.16
S2
3.6 × 10−3
35.45
10.09
S3
4.6 × 10−3
39.11
9.67
Table 6 Relay-destination performances for the second setup
Destination
Relay gain (dBm) BER
EVM
SNR
D1
−13
3 × 10−5
14.64
17.08
−15
7 × 10−4
18.59
14.55
D2
−13
8 × 10−5
19.29
14.29
−15
2.5 × 10−3
22.05
13.13
Table 7 NC and NCC performances for the second setup
Destination
Source
Relay gain (dBm) NC-BER
NCC-BER
D1
S1
−13
3 × 10−5
1 × 10−5
−15
7 × 10−4
3 × 10−4
S2
−13
5.3 × 10−4
5 × 10−4
−15
1.7 × 10−3
5 × 10−4
S3
−13
5 × 10−4
4.6 × 10−4
−15
1.6 × 10−3
1 × 10−3
D2
S1
−13
3 × 10−4
1.7 × 10−4
−15
2.5 × 10−3
1 × 10−3
S2
−13
5 × 10−4
2.5 × 10−4
−15
3.5 × 10−3
1.2 × 10−3
S3
−13
6.5 × 10−4
3 × 10−4
−15
4.2 × 10−3
2.4 × 10−3
As second step, performances of relay-destination links with error performance
results for the overall NC and NCC operations are measured as shown in Tables6 and
7. For the D1, at −13 dBm relay transmit gain, BER results of the NC operation are
obtained as 3 × 10−5, 5.3 × 10−4 and 5 × 10−4 respectively. With NCC operation,
these performances are improved and results are obtained as 1 × 10−5, 5 × 10−4
and 4.6 × 10−4 respectively. BER results and EVM results for relay-destination
links are measured as 3 × 10−5 and 14.64% on average. For the same setup, at
−15 dBm relay transmit gain, BER results of the NC operation are obtained as
7 × 10−4, 1.7 × 10−3 and 1.6 × 10−3 respectively. Similarly, NCC operation’s BER
results are measured as 3 × 10−4, 5 × 10−4 and 1 × 10−3 respectively. When relay-

314
S. Tedik Basaran et al.
destination link performances are measured, BER and EVM results are obtained as
7 × 10−4 and 18.59% on average. Same observations are also done for the D2. At −13
dBm relay transmit gain, BER results for NC operation are measured as 3 × 10−4,
5 × 10−4 and 6.5 × 10−4 respectively. Accordingly, BER results for NCC operation
areobtainedas1.7 × 10−4,2.5 × 10−4 and3 × 10−4 respectively.Furthermore,BER
and EVM results for relay-destination links are obtained as 8 × 10−5 and 19.29% on
average. Similarly, at −15 dBm relay transmit gain, BER results for NC operation
are measured as 2.5 × 10−3, 3.5 × 10−3 and 4.2 × 10−3 respectively. Accordingly,
BER results for NCC operation are obtained as 1 × 10−3, 1.2 × 10−3 and 2.4 × 10−3
respectively. Thus, improvement that is obtained with NCC operation, is observed
similar to previous results. Furthermore, BER and EVM results for relay-destination
links are obtained as 2.5 × 10−3 and 22.05% on average.
In order to verify results demonstrated in the tables, individual BER and EVM
results obtained at each of 20 tests are given by bar charts. Firstly, BER results
obtained for the link between S2 and D1 that are obtained with ﬁrst setup at −16
dBm relay transmit gain, are given in Fig.6. Secondly, BER results obtained for
the link between S3 and D2 that are obtained with the second setup at −15 dBm
relay transmit gain, are given in Fig.7. It can be observed that individual results also
represent overall results given in the tables.
Moreover, EVM results obtained for the links between each source node and relay
nodes, are shown in Fig.8. As mentioned, these links have very good performances.
As the last observation, individual EVM results obtained at each test are shown in
Fig.9, where links between source nodes and D1 are considered with the second
setup. Similar to BER charts, EVM charts also show consistency of results shown in
the tables.
The usage of OFDMA is vital to analyze realistic usage scenarios of NCC opera-
tion. By evaluating multiple user scenarios with OFDMA, this NCC implementation
0
2
4
6
8
10
12
14
16
18
20
0
1
2
3
4
5
6
x 10
−3
Link error performances, S2−D1, at −16 dBm with first setup.
Bit Error Rate
Test Index
S−D
NC
NCC
Fig. 6 BER results obtained during consecutive tests for the ﬁrst setup

Implementation of Network Coding in Wireless Systems
315
0
2
4
6
8
10
12
14
16
18
20
0
1
2
3
4
5
6
7
8
x 10
−3
Link error performances, S3−D2, at −15 dBm with second setup.
Bit Error Rate
Test Index
S−D
NC
NCC
Fig. 7 BER results obtained at consecutive tests for the second setup
0
2
4
6
8
10
12
14
16
18
20
0
2
4
6
8
10
12
14
16
18
20
Link error performances, S−R, with first setup.
Error Vector Magnitude (%)
Test Index
S1
S2
S3
Fig. 8 EVM results obtained for the source-relay links
shows how resources can be divided and managed. Validating theoretical components
in real-time with realistic transmission environment and hardware issues is the most
crucial outcome of the implementation. It is shown that with a ﬂexible design of such
a testbed, NCC operation in real-time can be easily realized and error performance
can be improved signiﬁcantly. Beyond NCC, NC performance is also measured in
real-time. NC also improves error performance, but NCC has clear beneﬁts espe-
cially in terms of error performance. As future mobile networks will include massive
number of devices, it will be more challenging to obtain desired error performances.
Thus, relay-based communication would be very beneﬁcial in terms of the error per-

316
S. Tedik Basaran et al.
0
2
4
6
8
10
12
14
16
18
20
20
25
30
35
40
45
Link error performances, S−D1, with second setup.
Error Vector Magnitude (%)
Test Index
S1
S2
S3
Fig. 9 EVM results obtained at consecutive tests
formances. NCC is a suitable candidate for such dense network scenarios and tight
system requirements resulting from increasing usage rates can be overcome with
easy deployment and cost efﬁciency of NCC.
5
Conclusion
NCC is a candidate for smart routing application, that can be used in 5G or beyond
technologies. Due to its natural characteristics as allowing scalability and providing
robustness to channel impairments, NCC can be easily adapted to the target network,
alleviating the expected implementation issues in dense network deployments. In
this chapter, we present the theoretical DMT bounds in comparison with the state-
of-the-art design solutions and details of implementation setup of an NCC system.
We show that NCC is a convenient smart routing approach to satisfy requirements of
next generation communication systems by performing both of theoretical analyses
and real-time implementation.
References
1. R. Ahlswede, N. Cai, S.Y. Li, R.W. Yeung, Network information ﬂow. IEEE Trans. Inf. Theory
46(4), 1204–1216 (2000)
2. R. Dougherty, C. Freiling, K. Zeger, Insufﬁciency of linear coding in network information ﬂow.
IEEE Trans. Inf. Theory 51(8), 2745–2759 (2005)
3. J.N. Laneman, G.W. Wornell, Distributed space-time-coded protocols for exploiting coopera-
tive diversity in wireless networks. IEEE Trans. Inf. Theory, 49(10), 2415–2425 (2003)

Implementation of Network Coding in Wireless Systems
317
4. T. Ho, M. Mdard, R. Koetter, D.R. Karger, M. Effros, J. Shi, B. Leong, A random linear network
coding approach to multicast. IEEE Trans. Inf. Theory, 52(10), 4413–4430 (2006)
5. M. Di Renzo, M. Iezzi, F. Graziosi, On diversity order and coding gain of multisource multirelay
cooperative wireless networks with binary network coding. IEEE Trans. Veh. Tech. 62(3),
1138–1157 (2013)
6. C. Peng, Q. Zhang, M. Zhao, Y. Yao, W. Jia, On the performance analysis of network-coded
cooperation in wireless networks. IEEE Trans. Wireless Commun. 7, 3090–3097 (2008)
7. H. Topakkaya, Z. Wang, Wireless network code design and performance analysis using
diversity-multiplexing tradeoff. IEEE Trans. Commun. 59(2), 488–496 (2011)
8. A.R. Heidarpour, G.K. Kurt, M. Uysal, Finite-SNR diversity-multiplexing tradeoff for network
coded cooperative OFDMA Systems. IEEE Trans. Wirel. Commun. 16(3), 1385–1396 (2017)
9. S. Gokceli, H. Alakoca, S.T. Basaran, et al., EURASIP J. Adv. Sig. Process. 2016(8) (2016)
10. F.J. MacWilliams, N.J.A. Sloane, The Theory of Error-Correcting Codes. North-Holland
Mathematical Library (North-Holland Publishing Company, Amsterdam, 1977)
11. E.M. Gabidulin, Theory of codes with maximum rank distance. Problemy Peredachi Informat-
sii, 21(1), 3–16 (1985)
12. S.T. Basaran, G.K. Kurt, M. Uysal, I. Altunbas, A tutorial on network coded cooperation. IEEE
Commun. Surv. Tutor. 18(4), 2970–2990 (2016)
13. P.A. Chou, Y. Wu, K. Jain, Practical network coding. in Proceedings of the Annual Allerton
Conference on Communication Control and Computing, vol. 41, No. 1, (2003) pp. 40–49
14. R. Koetter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory, IEEE, 54, 3579–3591 (2008)
15. A. Bletsas, A. Khisti, D.P. Reed, A. Lippman, A simple cooperative diversity method based on
network path selection. IEEE J. Sel. Areas Commun. 24(3), 659–672 (2006)
16. J.N. Laneman, Network coding gain of cooperative diversity. in Proceedings of IEEE MILCOM,
vol. 1, (2004) pp. 106–112
17. B. Bai, W. Chen, K.B. Letaief, Z. Cao, Joint relay selection and sub-channel allocation for
amplify-and-forward OFDMA cooperative networks. in Proceedings of IEEE International
Communications Conference (ICC’2012) (2012) pp. 4192–4196
18. M. Gromov, Pseudo holomorphic curves in symplectic manifolds. Invent. Math. 82(2), 307–347
(1985)

Opportunistic Network Coding
Kemal Alic and Ales Svigelj
Abstract In this chapter we describe a practical view of the usage of the network
coding theory over realistic communication networks. In particular, we introduce
opportunistic network coding, which can be applied to wireless networks with mesh
topologies and multiple unicast streams. With the term opportunistic we describe
the opportunistic nature of this type of coding, as packets are encoded only if the
opportunity arises and there are no mechanisms within it to increase the number of
coding opportunities. Different coding approaches have been proposed that cover
different network conﬁgurations and trafﬁc patterns. In particular, we focused on the
main design aspects of BON and COPE, the two opportunistic network coding proce-
dures that perform network coding on the packet level and can signiﬁcantly improve
the network throughput. In addition, we are also describing performance metrics,
which are found suitable for performance evaluation of network coding algorithms.
For illustration purposes we also show typical results for the above mentioned algo-
rithms. The results show that opportunistic network coding can signiﬁcantly improve
the wireless mesh network performance in terms of throughput and delay.
Introduction
The network coding beneﬁts are not limited to either wireline networks or multicast
applications. The opportunistic network coding which is investigated in this chapter
shows, how beneﬁts can be achieved also in the wireless networks and with multiple
unicast streams.
The term opportunistic network coding describes the opportunistic nature of this
type of coding, as packets are encoded only if the opportunity arises and there are
no mechanisms to increase the number of coding opportunities. Packets are coded
for one hop only, where they are decoded. In general coding of different and same
streams is possible, though we can expect only coding of different streams.
K. Alic (B) · A. Svigelj
Jozef Stefan Institute, Ljubljana, Slovenia
e-mail: kemal.alic@ijs.si
A. Svigelj
e-mail: ales.svigelj@ijs.si
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_12
319

320
K. Alic and A. Svigelj
Fig. 1 Example of how
opportunistic network coding
increases the throughput
Vj
Vi
p2
VR
p2
p1
p1
Vj
Vi
p2
VR
p1
pR = p1
 p2
Network coding approach
No coding approach
Opportunistic network coding beneﬁts can be best explained with the help of the
simple example depicted in Fig.1. Consider a three-node chain topology where node
V1 hasapacket p1 destinedfornode V2,andnode V2 hasapacket p2 forthedestination
node V1. The two nodes can exchange their packets through an intermediate relay
node VR. Hence, nodes V1 and V2 send packets p1 and p2 to VR. In a conventional
systemwherenetworkcodingisnotused, VR ﬁrsttransmits p1,whichisthenfollowed
by the p2. In the case where a network coding procedure is applied, the VR performs
an algebraic operation over the two packets (e.g., XOR) and sends out an encoded
packet pR = p1 ⊕p2. Upon reception, node V1 XORs the received encoded packet
pR with the sent packet p1 and obtains the packet p2. The same procedure is used
on node V2. V2 is familiar with the content of p2 and XORs it with the just-received
packet pR, thus obtaining p1 ofﬁcially destined to it. By using network coding the
number of transmissions that all three nodes need to perform in order to deliver both
packets to their destinations has been reduced from 4 to 3.
The example in Fig.1 presents a topology that is suitable for the chain-structure
coding, i.e., a topology where the two packets are travelling in the opposite directions
and get encoded in the intermediate node(s). In such a case, all the recipient nodes
have sufﬁcient information for successful packet decoding without packet overhear-
ing. Furthermore, packet retransmission may appear only due to the unsuccessful
delivery of the encoded packet to one of the recipient nodes.
A more interesting case arises with a more general network deployment. In such
a case, the question is which packets the coding node should encode together in such
a way that the recipient nodes will be able to decode the encoded packet. When a
node has a packet to forward, it needs to know whether encoding of this packet with
other queued packet(s) might save bandwidth, i.e., it needs to determine whether the
receivers can decode the encoded packets. Consider the situation in Fig.2. Nodes V1
and V2 are sending packets p13 and p24 via the relay node VR to the nodes V3 and V4,
respectively. If VR creates an encoded packet from p13 and p24, e.g., pR = p13 ⊕p24,
thereceivingnode V3 willbeabletodecodetheencodedpacket pR if V3 hasoverheard

Opportunistic Network Coding
321
Fig. 2 General relaying
scenario in which network
coding can be used
V3
V4
p24
p13
p24
p13
VR
V1
V2
the p24 transmission from V2 to VR. The situation is similar for V4, which needs to
overhear the p13 transmission from V1 to R.
Let us highlight why the coding packets that travel in the opposite directions are
preferred. Assume the situation presented in Fig.1 where packets pn and pm travel
in the opposite directions, i.e. pn from Vj via VR to node Vi and pm via versa. If we
describe the links between nodes with packet delivery probabilities, i.e. probability
that packets are successfully transmitted between two links, then we can estimate the
chances that the encoded packet pn⊕pm will be successfully received and decoded
on the two nodes is
P = PVRVj PVRVi,
(1)
where PVRVj and PVRVi are the probabilities that packets are successfully transmitted
from node VR to node Vj and to node Vi, respectively.
In a more general situation where packet pn travels from Vi to Vj and pm from
Vk to Vl, then the probability that the encoded packet pn⊕pm will be successfully
received and decoded on the two recipient nodes is:
P = PVRVj PVRVi PVi Vl PVkVj·
(2)
The difference to the ﬁrst case is that also two overhearing events need to take place
for each of the receiving nodes to have sufﬁcient information to perform decoding.
Information Required in the Opportunistic Coding Process
The more packets we encode together the looser the conditions in coding process are,
and with that the higher the possibility that receiving nodes will not be able to decode
those packets. However, if coding conditions are hard to meet, then there are only few
coding opportunities and low bandwidth saving beneﬁts. Good opportunistic coding
algorithm does not only attempt to encode as many packets as possible, but rather
makes sure that the encoded packets are very likely to be decoded. Making incorrect

322
K. Alic and A. Svigelj
coding decisions leads to unnecessary retransmissions, which results in wasting of the
wireless resources. Therefore, an important development issue is ﬁnding a balance
between the number of coded packets and the successful decoding rate, by using
small network coding overhead.
Coding decisions can be based on knowledge, e.g. each node records the state of
the trafﬁc for its neighbouring nodes, although as shown in [1–3] this is only sufﬁcient
for a portion of coding decisions. Thus, guessing mechanism needs to be used in the
coding decision process. The guessing can be based on the information that is already
available on the node, and was collected by some protocol. For example, the COPE
build on the information already available on the node and acquire the information
gathered by the routing protocol. This is an excellent option as no new additional
overhead is introduced to the network [4, 5]. The drawback with this solution is that
the routing information has to be available in the layer where coding procedure is
implemented. With communication components available on the market this is not
always possible. An alternative is to acquire an estimation of coding possibilities
through own network coding evaluation. This could be performed through (i) trans-
mitting the probe (measurement) packets; or (ii) by estimating the coding success of
the regularly encoded packets. The ﬁrst option introduces additional overhead to the
network. By collecting the required information through measurements scheduled
periodically we introduce additional overhead, thus lowering goodput and beneﬁts
of network coding. With the second option the data is collected by just observing
the trafﬁc going through the network coding module e.g. collecting the statistics
on which packets have been encoded and how many retransmissions were needed.
The main drawback of such an approach is that there is a rather small portion of
packets that get encoded. Collecting them over longer periods of time is in general
not acceptable as this would make the system slow and unable to adapt to the fast
changes on wireless links. Practical value of such approach is low for general network
performance since the number of coding options (combinations of packet’s previous
hop and packet’s next hop) grows with the number of neighbours a node has i.e.
faster than exponentially (i.e. N!/2). In practice, there are too many possibilities to
provide a reliable estimation on which node pairs provide good coding matches. In
addition, the ongoing measurements should be able to detect the changes in wireless
links conditions and react fast in case of their degradation. The subset of possible
coding matches should be made in order to provide reliable decision process and
react to changes in wireless environment.
Living Environment for Opportunistic Network Coding
Opportunistic network coding works well in wireless mesh networks. With this term
we describe networks where nodes connect to each other via multi-hop wireless links.
Usually we consider them to be self-sustainable, i.e. adaptive and self-organised in
order to be able to maintain connectivity.
Wireless mesh networks are very limited in capacity. E.g. the 802.11 family of
products are advertised to support data rate of up to 54Mbps. Still, “protection”
mechanisms such as binary exponential backoff, rate adaptation, and protocol over-
heads, cut the throughput by 50%. Moreover, owing to backward compatibility with

Opportunistic Network Coding
323
802.11b and 802.11g is encumbered with legacy issues that reduce throughput by an
additional ∼20%. Besides, the actual bandwidth available to individual clients can
be even much lower due to the shared nature of the wireless medium. Also, mesh net-
works usually operate in the unlicensed 2.45GHz Industrial, Scientiﬁc and Medical
(ISM) frequency band. Hence, bandwidth is shared also with other networks or net-
work devices, e.g. Bluetooth peripheral devices, spread-spectrum cordless phones,
or microwave ovens. Interference affects the quality of a wireless link and, conse-
quently, its error rate and achievable capacity.
Regardless of their capacity limitations wireless mesh networks are appealing in
areas with scarce wired infrastructure. Such places can be found in less developed
areas or in places such as tunnels, battleﬁelds, on board of public transportation etc.
Furthermore, due to low operational and deployment costs commercial deployment
can also be found in urban areas with the main application of offering cheap Internet
connectivity.
In a mesh network, each router can be seen as part of a backbone infrastructure
and also as an access point for end users. In this chapter we see mesh routers as
access points that offer end-users access, hence trafﬁc generated on nodes can be
considered aggregated from multiple users.
The network coding procedures discussed in this work are positioned between the
network and the link layer.
Routing-path selection also inﬂuences the performance of network coding. Rout-
ing that takes into account also network coding can further boost the network per-
formance, as can poorly selected routing in combination with network coding result
even in poorer network performance. The proposed BON procedure works as an
independent layer, but its performance is indirectly still related to the performance
of routing [1, 2].
In this chapter we consider the link-state routing protocol that is widely adopted
in the wireless mesh networks. We adopted symmetric routing (with symmetric we
refer to path selection of trafﬁc ﬂows that travel in the opposite directions).
Wireless mesh networks were initially based on the IEEE 802.11 standard. There-
fore, we provide a brief overview of general properties of the standard important from
the opportunistic network coding perspective.
The standard offers mechanisms for packet distribution to the nodes within their
communication range. Unicast inherently assure reliable delivery of packets to the
next hop while broadcast offers distribution of data to multiple users. With network
coding we want all the nodes to listen to all the transmissions. To this end, the
broadcast mechanism in the link layer seems a suitable solution at a ﬁrst glance.
However, due to the absence of collision detection and backoff on the source node the
reliability of broadcast is questionable. For this purpose we adopt pseudo broadcast
ﬁrst presented in [1] and discussed in this chapter.
The Coding Algorithms
The general COPE and BON architecture is shown in Fig.3. Packets arriving from the
network layer are placed into the network coding queues. Both coding procedures

324
K. Alic and A. Svigelj
          Network coding layer
Packet decoding
Packet pool
Link layer
Network layer
P
Queues
Packet Coding 
ACK & Ret. 
management
Fig. 3 Opportunistic network coding architecture
foresee use of FIFO queues, but also other queue scheduling can be used. When
the node is granted access to the wireless channel the coding process takes the ﬁrst
packer from the queues and searches for coding opportunities amongst remaining
packets in the output queue. If there are no coding opportunities identiﬁed, the packets
are sent out as they are. None of the two algorithms deliberately delays packets
for the purpose of ﬁnding additional coding opportunities. If packet coding ﬁnds
coding opportunities, the outgoing packets are coded into one encoded packet and
retransmissions are scheduled for each individual native packet.
All the received packets go ﬁrst through the decoding process. If packets are suc-
cessfully decoded each native packet coded in the encoded packet is stored into the
packet pool. If any of the native packets are destined to the recipient node acknowl-
edgement message is sent out. If received packet is acknowledgement type of packet
the scheduled retransmission is cancelled. Packets with next hop address the same
as the recipient node are also sent to network layer for further processing.
COPE
All the received packets go ﬁrst through the decoding process. If packets are suc-
cessfully decoded each native packet coded in the encoded packet is stored into the
packet pool. If any of the native packets are destined to the recipient node acknowl-
edgement message is sent out. If received packet is acknowledgement type of packet
the scheduled retransmission is cancelled. Packets with next hop address the same
as the recipient node are also sent to network layer for further processing.
In COPE the coding process depends on the nodes’ knowledge on what infor-
mation (which packets) its neighbouring nodes have. Based on this knowledge the

Opportunistic Network Coding
325
coding process is straightforward and the decoding process will have a high suc-
cess rate. Due to the nature of wireless communications and imposed delays that
comes with this knowledge can be used only to ﬁnd a small portion of all possible
coding opportunities. Hence, the COPE coding process also uses guessing which is
done through the delivery probability that is calculated in all of the ETX (Expected
Transmissions Count) based routing protocols. COPE incorporates two techniques to
support such coding process, namely opportunistic listening and learning neighbour
state:
• opportunistic listening and
• learning neighbour state
• guessing
Opportunistic Listening
In COPE the coding process depends on the nodes’ knowledge on what information
(which packets) its neighbouring nodes have. Based on this knowledge the coding
process is straightforward.
COPE foresees that all the nodes listen to all transmissions. As already mentioned
all the packets carry potentially useful information that can be used in the decoding
process. COPE also uses information obtained for the coding process. When a packet
is received on the node the sender and recipient node information is extracted and
noted. The node that overheard the transmission now knows that the two nodes have
the packet.
Learning Neighbour State
COPE procedure also foresees the use of the reception reports. All the nodes in the
network send out reports in which information on the received packets is stored.
Reports are broadcasted periodically or when opportunity arises they are attached to
the regular outgoing packets.
Guessing
In a network where we do not want to delay packets and Quality of Service (QoS)
should be at least considered, relying solely on the knowledge on the state of the
network would miss a great deal of coding opportunities. Hence, COPE foresees
also guessing, when information on the state of the network, i.e. whether the packet
under the question was received by the node.
The well-known COPE algorithm guessing relies on the information gathered in
the network layer, i.e. the expected transmission count matrix (ETX):
ETX =
1
PVi Vl PVl Vi
(3)
With this metric each link between two nodes is described with the inverse of the
packet delivery probability and its successful acknowledgement. Information can be
used in a way that it reﬂects the probability that a node received certain packet.

326
K. Alic and A. Svigelj
The COPE Coding Algorithm
The node estimates probability that the node N has packet p by looking at the delivery
probability for the link between packet’s previous hop and node N.
With all the needed information, the node can code together as many packets
(p1, . . . , pn) as possible provided that none of the packets have been created on
the coding node, all the packets have different next hops and that there is a strong
possibility that all next hops will be able to decode the packet. The next hop can
decode the packet if it has already received all but one of the packets coded together.
Let the probability that a next hop has heard packet pm be Pm. Then, the probability,
PD, that it can decode its native packet is equal to the probability that it has heard all
of the n −1 native packets encoded with its own, i.e.,
PD = P1P2 . . . Pn−1
(4)
The coding algorithm assures that the decoding probability PD for all the next hops
for a given combination of encoded packets is above the threshold G.
BON
With BON assumptions that each node has positions of all of its neighbouring nodes,
and that nodes have ﬁxed locations are made. Algorithm makes coding decisions
based solely on the information about the packet’s previous and next hop node posi-
tion, hence, it acts completely independently of all other communication layers, and
is completely protocol agnostic.
The BON Coding Algorithm
The decision making on which packets to encode together can be based on the
information already available on the node or the required information needs to be
gathered.
The coding process is based on the local bearing (as used in the navigation)
of the packet, which is deﬁned on the relay node and depends on the positions of
the packet’s previous hop and the packet’s next hop [2, 3]. Packets that have not
travelled at least one hop are not codable, and so a bearing is not deﬁned for them.
Let us use the example from Fig.4a to explain the deﬁnition of bearing. A packet
pi j (R) has been transmitted from the node Vi to the relay node VR and its next hop is
Vj. Locations of nodes Vi and Vj are known and are given in Cartesian coordinate
system as (Xi, Yi)(X j, Y j). We deﬁne bearing for the packet pi j (R) on the relay node
VRas a unit vector calculated as:
⇀
bi j =
(X j −Xi, Y j −Yi)
∥(X j −Xi, Y j −Yi)∥,
(5)
and translated into three dimensional space where also the node elevation (Z) is
taken into account:

Opportunistic Network Coding
327
Vj
pij
(R)
VR
Vi
pij
(R)
pji
(R)
pij
(R)
VR
Vi
pij
(R)
pji
(R)
Vj
bij
→
Vj
pij
(R)
VR
pij
(R)
εij
(R)
Vi
εij
(R)
(a)
(b)
(c)
bij
→
bij
→
bji
→
Fig. 4 Graphical presentation of a a bearing, b bearings for two packets travelling in the opposite
direction and c the vicinity for packet pi j (R) in the shape of an inﬁnite cone
⇀
bi j =
(X j −Xi, Y j −Yi, Z j −Zi)
∥(X j −Xi, Y j −Yi, Z j −Zi)∥.
(6)
In the coding process we are primarily interested in packets that are travelling
in opposite directions. Without loss of generality we build on a two-dimensional
example presented in Fig.4b where the packet pi j (R) has the same next hop as was the
packet p ji (R)’s previous hop and vice versa (the case of the so-called chain topology).
In such a case, the bearings of the two packets are
⇀
bi j −
⇀
b ji =
⇀
0. The two packets can
beseenasrepresentativesofthetwoﬂowsthataretravellingintheoppositedirections.
Coding of such packets is an ideal combination as no overhearing between the nodes
is needed and the recipient nodes can always decode the encoded packet.
Since such opportunities (i.e. when packets travel in exactly opposite directions)
do not provide a sufﬁcient number of coding opportunities, the coding opportunities
need to be searched for also amongst other packets. In general, we can assume that
the nodes that are located in the vicinity of the transmitting node have a better chance
of successfully overhearing the packet transmission than nodes that are located far
from it. Thus, they also provide a possibly good coding opportunity. With the coding
algorithm we are looking for packets (pkl(R)) that are codeable with the transmitting
packet (pi j (R)) on the relay node. We consider pkl(R) to be codable with pi j (R), if
the pkl(R) destination node Vl is in the vicinity of the pi j (R) source node Vi and vice
versa.
Deﬁnition 1 With BON the vicinity of the node Vj for packet pi j (R) on the relay
node VR is described as an area within the shape of an inﬁnite cone with the apex in
the packet source Vi, and cone axis with the direction
⇀
bi j and the aperture 2εi j (R).

328
K. Alic and A. Svigelj
Example of such an area for a packet pi j (R) that is on the node VR, with the
previous hop Vi and the next hop Vj is shown in Fig.4c, where the cone has the apex
in node Vi and the aperture 2εi (R). The node Vj lies directly on the cone axes. With
εi (R) we deﬁne how large the vicinity for packet pi j (R) is, hence we refer to it as
tolerance angle.
Deﬁnition 2 With BON coding the packets pi j (R) and pkl(R) are codeable on the
relay node if previous hop of pi j (R) (Vi) is in the vicinity of the next hop of pkl(R) (Vl)
and vice versa, where vicinity of nodes for packets pi j (R) and pkl(R) is set according
to the Deﬁnition 1 with εi j (R) and ε ji (R) accordingly.
Let us illustrate using general two-dimensional examples from Fig.5a, b where
matching and a non-matching packet pairs are presented respectively. In both pre-
sented cases the initial situation is the same. Let us point out that the location of
the VR has no impact on the coding decision, and its location is changed only for
the reasons of graphical presentation. Packets pi j (R) and pkl(R) are both on the relay
node VR. Vi and Vj are the previous and the next hop for pi j (R) and Vk and Vl are the
previous and the next hop for pkl(R). εi j (R) and εkl(R) are tolerance angles that relate
to packets’ previous hops on the relay VR.
In Fig.5a we can see that the node Vi is located in the vicinity of the node Vl for
packet pkl(R) and the similar goes for the node Vk, which is in the vicinity of the node
Vj for packet pi j (R). Since we want that the condition in Deﬁnition 2 is met for both
situations in the given example, the two packets are codeable.
In Fig.5b we can see that the node Vi is located in the vicinity of the node Vl for
packet pkl(R) and the node Vk is outside the vicinity of the node Vj for packet pi j (R).
pkl
(R)
pkl
(R)
Vj
pij
(R)
VR
pij
(R)
Vl
Vi
Vk
→
pkl
(R)
Vj
VR
Vl
Vk
Vi
bij
→
bij
→
bkl    
→
bkl
kl
(R)
kl
(R)
ij
(R)
ij
(R)
pij
(R)
pij
(R)
pkl
(R)
Fig. 5 Graphical presentation of general coding case for a a matching packet pair and b of a general
coding case for a non-matching coding pair

Opportunistic Network Coding
329
Since we want that the condition is met for both situations in the given example
the two packets are not codeable. Packets pi j (R) and pkl(R) would be codeable if
εi j was larger. By increasing the tolerance angle we cover a larger area and thus
increase probability that packets will meet the conditions. However, by increasing
the tolerance angle parameter, the probability that the receiver will not be able to
decode the packet is also increased. By reducing the parameter ε towards zero, the
coding opportunities are reduced, but the probability of a successful packet decoding
on the receiving nodes is increased.
By further generalization the BON coding procedure allows also coding of mul-
tiple packets. Multiple packets are encoded into one encoded packet when all packet
pairs and their corresponding nodes are within the vicinity area. The higher the ε
values, the higher the possibility of coding multiple packets on the other hand, if
at least one ε = 0 only two packets can be encoded. In BON coding the balance
between coding opportunities and successful packet decoding is set through the
parameter ε, which is adapted automatically on every node. The algorithm handling
self-adjustment is presented in Algorithm 1.

330
K. Alic and A. Svigelj
Integration into the Communication Stack
In order to make use of the opportunistic network coding process, several supporting
mechanisms are required to be implemented on the nodes. Using the opportunis-
tic network coding, the nodes change the way packets are processed after being
received and a new signalization is required. Moreover, the opportunistic network
coding requires that the nodes are put in a broadcast receiving mode, while a pseudo-
broadcast mechanism is used for sending the packets.
All the nodes in the network listen to all the transmissions and try to overhear as
many packets as possible – including the ones that are not addressed to them. All the
overheard packets are saved into the packet pool for decoding purposes. A copy of a
received packet (i.e., a packet headed to the node) is also stored in the packet pool,
while the original is forwarded to the network layer.
Packet Queues
BON and COPE procedures use different outgoing queues for different packet types
i.e.:
• ACK packets. These are standalone acknowledgement messages that are created
only when no opportunity has been found to add them as a header to regular
outgoing packets.
• Retransmitted (native) packets dedicated queue is used in BON only. Packets are
placed in special sub-queue to prevent coding the same packet set together again
and thus trying to avoid the possible mistake in the coding process.
• Regular outgoing (native) packets that have arrived from the network layer and
have arrived from one of the neighbouring nodes or have their origin on this node.
COPE uses this queue also for retransmitted packets, which are placed at the top
of the queue and thus processed ﬁrst.
When there are packets present in one of the output queues, the BON and COPE
procedure signal the link layer that the access to the wireless media is required. When
the link layer signals that it has successfully gained access to the channel, the queue
is selected depending on its priority. If we are dealing with retransmitted or regular
queue, the coding procedure is initiated.
Coding Procedure
The coding process using the FIFO system always takes the packet p0 that is at the
head of the output queue (retransmission or regular) and searches for possible coding
opportunities with the other packets in the regular outgoing queue. If there are no
coding options found, the packet is sent out as-is (Fig.6).
Signalization
The two algorithms under the spotlight use two types of signalization, namely
acknowledgement messages and reception reports. The acknowledgements in BON
and COPE have the same structure, while reception reports are unique to COPE only.

Opportunistic Network Coding
331
Fig. 6 A ﬂow chart of the
BON and COPE coding
process
Access to the 
channel gained
Take packet from 
the head of the 
output queue
Encoded?
Encode if possible
Add
acknowledgements 
to headers
Send to wireless 
device
No
Schedule
retransmissions
Yes
Acknowledgement messages in the network coding layer are used only for native
packets that have been received as part of the encoded packet. Acknowledgement
messages are generated by the receiving node, designated as a packet’s next hop.
Please note that we are discussing only the acknowledgement messages in the net-
work coding layer, while acknowledgements in the other layers remain as they were.
The acknowledgement message in the network coding layer is required to indicate
the success in the packet decoding procedure.
Cumulative acknowledgement in a structure proposed in [1] are used. Acknowl-
edgement massages are sent in a bulk every time an opportunity arises and when there
are new messages in the pool. The latest received packet sequence number is used
for reference. This is followed by a sequence of Boolean values that also indicates
status of the received packets for the packets with lower sequence number. E.g. an
entry {A, 50, 01011111} conﬁrms that packets 50, 48, 46-42 have been received and
that packets 49 and 47 are still missing.

332
K. Alic and A. Svigelj
To make this operate, packet sequence number needs to be recorded. Each node
indexes outgoing packet per each neighbour individually and the same holds true for
all the received packets.
Acknowledgement messages conﬁrm reception for every received native packet
that has been received as part of the encoded packet. Cumulative acknowledgement
report messages are broadcasted periodically, every Tu (referred to as acknowledge-
ment packets). If the opportunity arises, the acknowledgement messages are attached
to the regular outgoing packets. In this case cumulative acknowledgement can be
seen only as an additional header, thus introducing less overhead. In case that the
upper limit of acknowledged packets per is reached, the acknowledgement process is
triggered and acknowledgement massages are sent out as individual packet. Cumu-
lative acknowledgement messages reduce the overhead compared to the individual
acknowledgement messages.
Reception reports are messages used in COPE only. With these nodes inform
their neighbours on which packets they have received Also reports are sent out when
opportunity arises or in the absence of those periodically. Similar as acknowledge-
ments, also reports are compact. They are formed as headers, where ﬁrst information
on number of reports in the header is given. One report is used for each neighbour
with updated status. Second information in the header is address of the neighbour that
transmitted the packet, followed by the last packet id received from that node. This
is followed by a sequence of Boolean values that also indicates status of the received
packets for the packets with lower sequence number. Reports include information
on the packet ID and neighbour address because both data are needed to identify the
packet in a unique way. More can be read in [1].
Packet Reception
In addition to handling acknowledgement packets, the recipient node needs to be able
to also handle native and encoded packets, which both can carry additional header
that contains acknowledgement massages.
Packet reception process is presented in Fig.7. Upon packet reception in the
network coding module, further actions depend on whether the packet is encoded
or native. In the case when an encoded packet (consisting of M native packets) is
received,theprocesschecksthepacketpoolwhereallthereceived,sentandoverheard
packets are stored for decoding purposes. The encoded packet can be decoded if a
node has in its packet pool at least M−1 packets. The process has to determine
whether it has already received M−1 of the packets encoded in the encoded packet.
If not, the encoded packet cannot be decoded and it is simply dropped. If the node
has at least the required M−1 packets, i.e., sufﬁcient information, it decodes the
encoded packet using these packets with the XOR operations, thus obtaining a native
packet that has not been received before. From here on the process is the same as
upon receiving a native packet. If the packet is new (i.e. newer received before),
its copy is inserted into the packet pool for decoding purposes. It does so for every
received native packet, as all the received packets are potentially needed for further
decoding purposes. The process checks whether the node is the next hop of the
native packet. If so, and if the packet has been a part of the encoded packet, an

Opportunistic Network Coding
333
Fig. 7 A ﬂow chart of the
BON and COPE reception
process
Packet arrival
Extract 
acknowledgements, 
update
retransmissions
Encoded?
Drop packet
Decodable?
Decode and schedule 
acknowledgements 
Add packet(s) to 
packet pool
Am I 
next-hop?
Drop packet
Send packet to 
routing module
No
Yes
Yes
No
No
acknowledgement message is scheduled and the packet is sent to the network layer
for further processing.
Packet Retransmission
If an ACK message is not received within a predetermined time, the retransmission
event is triggered. A native packet that has been sent out as part of the encoded packet
and has not been acknowledged, is placed in the retransmission output queue.
Packets require retransmissions for two reasons. Packets cannot be decoded on
the recipient node (i) because there are not enough packets in the packet pool, and
(ii) because packets get lost in the transmission/reception procedure.
The packets in the retransmissions queue can be coded again. However, coding
opportunities are searched for only within the packets in the regular output queue.

334
K. Alic and A. Svigelj
This mechanism ensures that it is not possible for the same set of packets to be coded
again. Hence, the situation where the same set of packets is encoded again is avoided.
With every packet retransmission we want to increase the probability of successful
packet decoding on the recipient node. and we can do so by decreasing the parameter
ε. Hence, we foresee that with every packet retransmission parameter ε is decreased.
Pseudo Broadcast
With network coding we need to overhear as many transmissions as possible for the
network coding mechanisms to seize their full potential. Hence, a natural approach
would be to use a broadcast mechanism. As shown in [1] this does not work due to
poor reliability and lack of backoff and they propose a pseudo broadcast mechanism
which unicasts packets that are meant for the broadcast.
The link-layer destination ﬁeld is set to the MAC address of one of the intended
recipients. Since all the nodes are set in the promiscuous mode, they can overhear
packets not addressed to them. When a node receives a packet with a MAC address
that is identical to its own, it sends an ACK message to the sender. Regardless of
the address of the next hop of the packet, the node sends the packet to the network
coding module.
Performance Metrics for Network Coding Procedures
Network coding is a relatively new approach; whose fundaments we are still learning.
With opportunistic network coding we may claim the same, as knowledge in what
kind of networks and with which trafﬁc distributions we can expect beneﬁts and how
does the new layer affect the performance of applications with high QoS demands has
not yet been obtained. Depending on what we wanted to show, we adopted different
metrics, and on the high level we can group them into two categories:
• Performance metrics that capture the detailed network response on the use of
network coding. Corresponding set of results is shown against the network load,
which is always measured over longer periods. Network load was selected as the
key inﬂuence for the network coding performance as it can be measured in a
straight-forward manner and there is a strong correlation between performance
beneﬁts and load.
• Performance metrics that allow higher level conclusions such as the inﬂuence
of the network topology on the performance of the network. The main issue in
showing such results is in deﬁning a performance metric that is only dependant
on the parameter under scope.
Thus, in the following we are presenting some performance metrics, which we found
suitable for performance evaluation of opportunistic network coding algorithms. In
addition, we also show some illustrative results. As the elementary metric reﬂecting
the quantity of service we can observe the network goodput (g), which is the number
of useful information bits delivered by the network to a certain destination per unit
of time. The goodput in graphs can be shown as a sum of all the goodput on all
the network nodes at particular network scenario e.g. particular load g(i) or plain as
current goodput on node or network.

Opportunistic Network Coding
335
Fig. 8 Goodput (g) with
respect to the network load
for COPE, BON and the case
when coding is not used
Fig. 9 Gain (G) with respect
to the network load for
COPE, BON and the case
when coding is not used
Example of goodput deﬁned as a sum of all the goodput on all the network nodes at
particular network load is shown in Fig.8. Goodput is shown for the two opportunistic
coding procedures and reference scenario, where coding is not used.
We further deﬁne the gain G(i) in ith simulation run as the relative increase of
goodput obtained with network coding with respect to goodput without network
coding:
G(i) = gNC(i) −gno coding(i)
gno coding(i)
100%
(7)
where gain can be observed for the whole trafﬁc in the network or just on the individ-
ual ﬂow level. Similar as goodput also gain can be observed for particular scenarios.
Example graph for gain for the same case scenario as presented in Fig.8 is shown in
Fig.9.
As a typical QoS metric we measure End-to-End Delay and jitter at the application
layer. Both ETE delay and jitter are measured for each particular ﬂow separately and
for all the ﬂows. Regardless of the case, we can write the following:

336
K. Alic and A. Svigelj
Fig. 10 End-to-end delay
(ETE) with respect to the
network load for COPE,
BON and the case when
coding is not used
ET E(i) =
Ka(i)
n−1 dn
Ka(i)
(8)
where dn is the ETE delay of the nth packet and Ka(i) is the number of packets
received in the application layer.
Jitter is the standard deviation from true periodicity of a presumed periodic signal.
We measure jitter only for ﬂows with constant interarrival packet rates:
jitter(i) =
1
F(i)
F(i)

f =1
1
K f (i)
K f (i)

n=1
(dnf −ET E f (i))2
(9)
where F is the number of ﬂows, K f is the number of packets received in the appli-
cation layer belonging to the f th ﬂow, and ETE f is ETE for f th ﬂow. Where we
are interested in jitter of only one particular ﬂow, this same equations is used for
calculation and F(i) = 1.
Typical delay results are presented in Fig.10. On the ﬁgure values for COPE,
BON and reference scenario where coding is not used are shown.
Opportunistic network coding performance primarily depends on the quantity of
load and also on different parameters. When analysis or evaluation on of the inﬂuence
of different network and trafﬁc characteristics on the performance efﬁciency of the
network coding needs to be performed we require a load independent metric to
quantify the result, in particular, if we want to access the dependency of gain on
other parameters (e.g. queue length, packet length, topology, etc.). Thus, we propose
MaxGain, which is calculated as the average of the 3 highest gain values obtained
among results for a given set of parameter values. We ﬁrst sort vector G(i) where i =
{1, 2,…, I} and I is the number of simulation runs from the highest to lowest value:
Gs = sort{G(1), G(2),
. . . , G(I)}
(10)

Opportunistic Network Coding
337
Fig. 11 MaxGain with
respect to the trafﬁc
symmetry ratio for COPE
and BON
and then the MaxGain is:
MaxGain = 1
3(Gs(1) + Gs(2) + Gs(3))
(11)
For example in Fig.11 we show dependency of opportunistic network coding
performance against trafﬁc symmetry ratio. In a network limited number of node
pairs were selected. Trafﬁc between the two loads was generated, while the symmetry
between the two ﬂows in the load pair was changing.
Summary
In this chapter we show how coding theory can be used in existing communication
networks. We introduced opportunistic network coding which can be applied to the
wireless networks and to multiple unicast streams. The term opportunistic describes
the opportunistic nature of this type of coding, as packets are encoded only if the
opportunity arises and there are no mechanisms within it to increase the number of
coding opportunities.
Different coding approaches have been proposed that cover different network
conﬁgurations and trafﬁc patterns. The core of all opportunistic network coding
approaches is which packets the coding (i.e. relaying) node should code together
in such a way that the recipient nodes will be able to decode the encoded packet.
In this chapter we focus on design aspects of two typical opportunistic network
coding representatives namely BON and COPE. Both are positioned between the
network and link layers and are performing network coding on the packet level
and can signiﬁcantly improve the network throughput. As the network coding is
a relatively new approach, we are also describing performance metrics, which we
found suitable for performance evaluation of network coding algorithms. For the
illustration purposes we also show some typical result for the above mentioned
algorithms. The results show, that opportunistic network coding can signiﬁcantly
improve the wireless mesh network performance in terms of throughput and delay.

338
K. Alic and A. Svigelj
References
1. S. Katti, H. Rahul, W. Hu, D. Katabi, M. Médard, J. Crowcroft, XORs in the air: practical
wireless network coding. IEEE/ACM Trans. Netw. 16, 497–510 (2008)
2. K. Alic, E. Pertovt, A. Svigelj, Bearing-opportunistic network coding. Int. J. Comput. Commun.
Control. 10, 154–164 (2015)
3. K. Alic, A. Svigelj, A one-hop opportunistic network coding algorithm for wireless mesh net-
works, Wirel. Netw. (2016) https://doi.org/10.1007/s11276-016-1384-y
4. K. Alic, A. Svigelj, Self-adaptive practical opportunistic network-coding procedure for static
wireless mesh networks, Ad Hoc Sens. Wirel. Netw. 36(1–4), 87–105 (2017)
5. S. Katti, D. Katabi, W. Hu, H. Rahul, M. Medard, The importance of being opportunistic:
practical network coding for wireless environments. Presented at the 43rd Allerton conference
on communication, control, and computing, 2005

Coded Random Access
ˇCedomir Stefanovi´c and Dejan Vukobratovi´c
Abstract This chapter presents an overview of coded slotted ALOHA (CSA), which
is a slotted ALOHA-based random access scheme with iterative interference can-
cellation. The iterative reception algorithm of CSA is analogous to the iterative
belief-propagation erasure-decoding, motivating the use of the tools from codes-on-
graphs to design and analyze CSA schemes. The asymptotic performance analysis
of CSA for the collision channel model is derived using the and-or tree evaluation
and instantiated for the case of frameless ALOHA. The and-or tree evaluation is then
adapted to the case of block-fading channels and threshold-based reception criterion,
which is another frequently used model in wireless systems. Finally, the performance
of CSA is assessed in multi access point scenario for the collision channel model,
assuming different variants of cooperation among the access points.
1
Introduction
The problem of random access arises in communication scenarios in which multiple
users (i.e., terminals) have to access the common access point (AP) over the shared
communication medium, see Fig.1, but the activation patterns of the terminals (i.e.,
instances of when the terminals will initiate the access) and, perhaps, even the number
of the accessing terminals are not known a-priori. A typical example can be found
in the connection establishment procedure taking place between a mobile phone and
a base station in a cellular network, with the purpose of initiating a call. The typical
approach in such case is to employ a decentralized algorithm that distributes the
ˇC. Stefanovi´c (B)
Department of Electronic Systems, Aalborg University (Copenhagen Campus), Frederikskaj 12,
2450 Copenhagen, Denmark
e-mail: cs@cmi.aau.dk
D. Vukobratovi´c
Faculty of Technical Sciences, Department of Power, Electronics
and Communication Engineering, University of Novi Sad,
21000 Novi Sad, Serbia
e-mail: dejanv@uns.ac.rs
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_13
339

340
ˇC. Stefanovi´c and D. Vukobratovi´c
Fig. 1 The random access
protocols are used for the
scenarios in which the
a-priori unknown subset of
users attempts access to the
common access point over
shared medium
time-instants in which users attempt the access in a random manner; the aim is to
avoid the interference among the users, as it may prevent successful reception of
their access requests by the AP.
Slotted ALOHA (SA) is a prominent example of a random access protocol, used,
e.g., in RFID networks, satellite networks, and as the basis for the connection estab-
lishment in cellular access networks. In its original form, SA assumes that the time
is divided in equal-length slots and that users are slot-synchronized, i.e., there is a
certain level of coordination among the users, provided by the AP that broadcasts
time-references. Each accessing user, independently and uncoordinatedly, decides on
the slot-basis with a certain probability whether to transmit. From the AP perspective,
a slot can be an idle (i.e., containing no transmission), a singleton (i.e., containing
a single transmission) or a collision slot (i.e., containing multiple transmissions).
The SA performance is standardly assessed on the collision channel model, which
assumes that (i) transmissions occurring in singleton slots are successfully received
(i.e., decoded) with probability 1, and (ii) any transmission occurring in a collision
slot is not received with probability 1. One of the basic performance metrics of SA is
the expected throughput, denoted by T , which is the measure of the efﬁciency of the
use of the slots. Speciﬁcally, the expected throughput can be deﬁned as the average
number of transmissions (i.e., user packets) that can be successfully decoded in a
slot, which, for the collision channel model, is equal to the probability that the slot
is singleton. Denoting the slot access probability by pA, the throughput is computed
as
T = Pr{slot is singleton} =
N
1

pA(1 −pA)N−1 ≈NpAe−Npa,
(1)
where N denotes the number of accessing users, and where the approximation holds
as N →∞, and NpA = β, where β is a constant. Obviously, in order to boost the
throughput of SA for the collision channel model, one should maximize the proba-
bility that an observed slot is singleton, which is done by optimizing the slot-access
probability pA. It is easy to verify that, asymptotically, the limit on the maximum
expected throughput is 1
e packet/slot, achieved when pA = 1
N (i.e., β = 1).

Coded Random Access
341
Fig. 2 Frame slotted
ALOHA: The users perform
access by transmitting in
randomly selected slots of
the frame
A scheme closely related to SA is the so-called framed slotted ALOHA (FSA),
where the time-slots are organized into frames, and the users are both frame- and
slot-synchronized. In FSA, a user attempts the access by transmitting in a randomly
selected slot in the frame, see Fig.2. Using similar arguments as in case of SA, it is
easy to verify that asymptotic limit on the maximum expected throughput of FSA
for the collision channel model is again 1
e, achieved when the number of the slots in
the frame, denoted by M, is equal to the number of accessing users N.
The collision channel model may serve as a valid approximation only for narrow-
band, single antenna systems, in which powers of the signals transmitted by users
are the same at the point of reception and in which the impact of the noise can be
neglected. On the other hand, the collision channel fails to accurately model the cases
when the signal powers at the point of reception are unequal, which may happen due
to fading and shadowing – the phenomena characteristic for wireless transmissions,
and/or when the noise power is substantial relative to the received signal power. In
particular, in the former case, the capture effect may occur in collision slots, when
one of the signals involved in a collision is sufﬁciently stronger then the interfering
signals and the noise combined, and thus becomes successfully decoded; in other
words, the existence of the capture effect removes the assumption of collision slots
being unusable by default. In the latter case, the noise may prevent receiving a signal
in a singleton slot; i.e., the singleton slots may not be usable by default.
A model often used due to its simplicity and analytical tractability is the threshold-
based capture model, according to which a signal is successfully received (i.e., cap-
tured) in a slot if its signal-to-interference-and-noise ratio (SINR) is above a certain
threshold. Speciﬁcally, by the threshold-based capture model, the capture occurs if
PS
PN + PI
≥b,
(2)
where PS, PN and PI are the signal power, the noise power and the combined power
of the interfering signals, respectively, and b is the capture threshold. It is typically
assumed that b does not depend on the SINR. Also, note that in the case when PI = 0,
which holds for singleton slots, the signal has to capture the slot against the noise.

342
ˇC. Stefanovi´c and D. Vukobratovi´c
Fig. 3 Example of FSA with iterative IC: Initially, packet 2 is decoded in singleton slot 3. In
the next step, the replica of packet 2 is cancelled from slot 1. Slot 1 now becomes singleton and
packet 1 becomes decoded. The replica of packet 1 is cancelled from slot 4, slot 4 becomes sin-
gleton and packet 3 becomes decoded. The throughput in this example is 3/4 packet/slot, while the
throughput of standard FSA would be 1/4 packet/slot
Fig. 4 Graph representation of the example in Fig.3: The decoding and the removal of replicas
correspond to the removal of the graph edges
2
Coded Slotted ALOHA
A substantial improvement of FSA performance can be achieved by modifying the
scheme such that (i) a user accesses the shared medium by sending replicas of its
packet in multiple slots of the frame, where each replica embeds a pointer to all
other replicas, and (ii) when a replica is decoded, it is removed from the slot as well
as all other replicas from the corresponding slots using an interference cancellation
(IC) algorithm.1 During this modiﬁed reception procedure, some of the slots affected
by the IC may provide for the decoding of new packets, propelling new iterations
of the IC, etc., as depicted in Fig.3. The ultimate result is that the overall number
of successfully received packets may signiﬁcantly increase in comparison to FSA
without IC, implying better slot utilization, and hence, larger throughputs. The price
to pay is that the scheme requires buffering of the (composite) signals received in
the slots, as well as additional signal processing in order to perform the IC.
The iterative decoding of users’ packets and application of IC can be represented
via removal of the edges on the corresponding graph, see Fig.4. Moreover, for the
collision channel model, this graph representation is completely analogous to the
graph representation of the iterative belief-propagation of erasure-correcting codes.
In other words, the theory and tools of codes-on-graphs can be applied to the analysis
and design of SA-based schemes that exploit iterative (i.e., successive) IC, referred
1Throughout the text it is assumed that the IC is perfect, i.e., the signal affected by the IC is perfectly
“erased” from the slot.

Coded Random Access
343
Fig. 5 Bipartite graph
representation of the access
scheme
to with an umbrella term Coded Slotted ALOHA (CSA). CSA schemes can asymp-
totically achieve throughput of 1 packet per slot on the collision channel, which is
the ultimate bound for this channel model.
2.1
Graph Representation
The contention process of CSA can be represented via a bipartite graph, see Fig.5,
standardly used for the representation of codes-on-graphs. The nodes on the left
represent users, the nodes on the right represent slots, and an edge that connects a
user node with a slot node corresponds to a transmission of the user packet replica.2
The number of edges incident to a user node u is called user degree, denoted by |u|.
Correspondingly, the number of edges incident to a slot node s is called slot degree
|s|.
In the basic version of frame-based CSA, so-called Irregular Repetition Slot-
ted ALOHA (IRSA), each user randomly and independently selects its degree,
i.e., number of replicas to be sent, from a predeﬁned probability distribution Λk,
k = 1, . . . , M,
Λk = Pr{|u| = k},
(3)
where α = M
k=1 kΛk is the average user degree. In the next step, each user u ran-
domly, independently and without repetition chooses |u| out of M slots from the
frame, in which it sends replicas of its packet. In this way, the bipartite graph is
created.
It is easy to verify the slot degrees are independent and identically distributed
(i.i.d.) binomial random variables. In particular,
Ωl = Pr{|s| = l} =
N
l
  β
N
l 
1 −β
N
N−l
,
(4)
2In the rest of text, the terms user/user node, slot/slot node, and edge/replica will be used inter-
changeably.

344
ˇC. Stefanovi´c and D. Vukobratovi´c
where β = αN
M is the average slot degree,3 and β
N is the probability that a user chooses
a particular slot when transmitting a replica. Letting M, N →∞, and M ∝N, (5)
becomes
Ωl = βl
l! e−β,
(5)
i.e., |s| becomes a Poisson distributed random variable. For the ease of exposition,
it is customary to use polynomial notation to denote the user and the slot degree
distributions:
Λ(x)
def
=
M

k=1
Λkxk,
(6)
Ω(x)
def
=
N

l=1
Ωlxl ≈e−β(1−x),
(7)
where (7) follows from (5). Strictly speaking, Λ(x)/Ω(x) are referred to as node-
oriented user/slot degree distributions. There are also edge-oriented user/slot degree
distributions, which correspond to probabilities that a randomly chosen edge is con-
nectedtoauser/slotnodeofacertaindegree.Speciﬁcally,denotebyλk theprobability
that an edge is connected to a user node of degree k and by ωl the probability that an
edge is connected to a slot node of degree l. λk can be computed as
λk = kΛk N
Nα
= kΛk
α , k = 1, . . . , M,
(8)
where kΛk N is the number of edges incident to user nodes of degree k and Nα is
the total number of edges. Similarly, ωl can be computed as
ωl = lΩl
β
≈
βl−1
(l −1)!e−β, l = 1, . . . , N.
(9)
The edge-oriented user/slot degree distributions are compactly written as
λ(x)
def
=
M

k=1
λkxk−1 = 1
α
M

k=1
kΛkxk−1 = Λ′(x)
α
,
(10)
ω(x)
def
=

l=1
Nωlxl−1 = 1
β =
N

l=1
lΩlxl−1 = Ω′(x)
β
≈e−β(1−x),
(11)
where F′(x) denotes the derivative of F(x), and where (11) follows from (7).
3It is easy to verify that β = N
l=1 lΩl.

Coded Random Access
345
Fig. 6 The tree
representation of the iterative
reception algorithm of CSA
2.2
Asymptotic Performance Evaluation
There is an elegant way to perform the asymptotic performance evaluation of IRSA
on the collision channel, derived from the so-called and-or tree evaluation. The
underlying assumption is that, as M, N →∞, the bipartite graph of the scheme does
not contain loops and can be unfolded into a rooted tree, see Fig.6. The evaluation
models the iterative reception algorithm and is concerned with the iterative updates
of the probabilities that: (i) an edge incident to a slot node is not removed,4 denoted
by pi, and (ii) the an edge incident to user node is not removed, denoted by qi,
where i denotes the iteration of the IC. Note that a single iteration consists of two
probability updates.
Pick an edge incident to a slot of degree l in the i-the iteration of the and-or tree
evaluation, and designate it as the reference edge. For the collision channel model,
the probability that the reference edge is removed is
1 −p(l)
i
= (1 −qi−1)l−1,
(12)
i.e., the edge is removed if and only if all the other l −1 edges incident to the
slot node have been removed via interference cancellation in previous iteration,
which happens with probability (1 −qi−1)l−1.5 Averaging over the edge-oriented
slot degree distribution yields
pi =

l
ωl p(l)
i
= 1 −

l
ωl(1 −qi−1)l−1 = 1 −ω(1 −qi−1) = 1 −e−βqi−1.
(13)
Similarly, pick an edge user node of degree k in the i-the iteration of the and-
or tree evaluation, and designate it as the reference edge. The probability that the
reference edge is not removed is equal to
4I.e., the corresponding packet replica is not decoded.
5Obviously, the recovery of the user packet in a slot can be modeled as logical ‘and’ operation.

346
ˇC. Stefanovi´c and D. Vukobratovi´c
q(k)
i
= pk−1
i
,
(14)
i.e., the edge is not removed only if none of the other edges incident to a user node
has been removed in the iteration.6 Averaging over the user edge-oriented degree
distribution yields
qi =

k
λkq(k)
i
=

k
λk pk−1
i
= λ(pi) = λ(1 −e−βqi−1).
(15)
The initial value is q0 = 1; i.e., initially, all edges are present in the graph. The output
of the evaluation is the probability that a user packet is recovered
PR = 1 −lim
i→∞qi.
(16)
The throughput can be calculated as
T = N PR
M
= G PR,
(17)
where G = N
M is the load of the scheme.
Evidently, from (15)–(17), the asymptotic performance crucially depends on the
choice of λ(x) and the average slot degree β, where β = Gα. On the other hand, both
λ(x) and the average user degree α depend on Λ(x). Therefore, the performance of
the scheme ultimately depends on Λ(x) and the load G. The threshold of the scheme,
denoted by G∗, is deﬁned as the maximum value of the load for which the following
condition holds
q > λ(1 −e−qGα), ∀q ∈(0, 1].
(18)
Comparing (18) with (15) reveals that, for given Λ(x), G∗is the maximum load for
which the probability of not recovering user packet will decrease over the iterations
of the reception algorithm. In other words, for given Λ(x) and when G ≤G∗, the
probability of user recovery PR tends to 1, and, thus, T becomes equal to G, see
(17). Finally, it can be proven the upper bound on the achievable threshold, denoted
by Gmax for any user degree distribution whose average degree is α is given by
Gmax = 1 −e−Gmaxα.
(19)
6I.e., a packet is recovered if any of its replicas is decoded, which can be modeled via logical ‘or’.

Coded Random Access
347
2.3
Frameless ALOHA
Frameless ALOHA is a variant of CSA that has two distinctive features: (i) frame-
length is not a-priori deﬁned, but determined on-the-ﬂy such that the instantaneous
throughput is maximized, and (ii) like in the original SA framework, each user
independently decides whether to transmit its packet replica on the slot basis using
a predeﬁned slot access probability.
Assume that the slot access probability pA is uniform for all users and over all
slots
pA = β
N ,
(20)
where N denotes the number of users. Assume that all users are synchronized, such
that they start contending from the ﬁrst slot of the frame and denote the current length
of the frame as M. The probability the a user degree is equal to k, k = 0, . . . , M, is
Λ(k) =
M
k

pk
A (1 −pA)M−k =
M
k
  β
N
k 
1 −β
N
M−k
≈

β
G
k
k!
e−β
G ,
(21)
where G here denotes the current load. Thus, the edge-oriented user degree distribu-
tion (10) becomes
λ(x) = e−β
G (1−x),
(22)
while (15) evaluates to
qi = e−β
G e−βqi−1 .
(23)
Asymptotic performance of frameless ALOHA cannot reach the one of IRSA,
due to the simplicity of the scheme. In fact, the probability of a user not transmitting
at all is
Λ0 ≈e−β
G ,
(24)
which also implies that a user packet can not be recovered at least with the same
probability. In other words, PR ≥1 −Λ0, and Λ0 →0 only when G →∞. How-
ever, the key strength of frameless ALOHA is the capability to adapt to the actual
evolution of the iterative reception algorithm, attempting to terminate the contention
when the instantaneous throughput is maximized. The instantaneous throughput is
deﬁned as
TI = NR
M ,
(25)

348
ˇC. Stefanovi´c and D. Vukobratovi´c
Fig. 7 Frameless ALOHA:
An example of the evolution
of the instantaneous
throughput TI and the
instantaneous fraction of
resolved users FI as the
number of the slots in the
frame increases M
0
25
50
75
100
125
150
M
0
0.2
0.4
0.6
0.8
1
=2.7, N = 100
TI
FI
where NR is the current number of recovered users and M denotes the current frame
length. Similarly, the instantaneous fraction of resolved users is deﬁned as
FI = NR
N .
(26)
Figure7 shows an example how TI and FI change with M for an instance of frameless
ALOHA. For this instance, the optimum frame length that maximizes the throughput
is when M = 120 and TI = 0.8. An optimal contention-termination criterion has to
identify when the maximum TI has been reached in every instance of the contention,
where both the slot-position of the maximum and the value of the maximum vary
across the instances.
2.4
Performance of CSA on Block Fading Channels with the
Threshold-Based Capture Model
Assume that the wireless links between the users and the AP are affected with block-
fading and noise, such that the composite signal received in slot sm, denoted by Sm
is
Sm =

n∈A m
hm,nUn + Zm, m = 1, . . . , M,
(27)
where Am is the set of the indices of the users active in sm, hm,n is the channel
coefﬁcient between the user un and the AP that describes the impact of the block-
fading, Un is the signal (i.e., packet replica) of user un, and Zm is the additive white
Gaussian noise. The total received power in sm is

Coded Random Access
349
Rm =

n∈A m
||hm,nUn||2 + PN,
(28)
where the expected noise power PN is constant for all slots. A frequent assumption
is that the users are able to perform long-term power control, such that the expected
powers of their transmissions at the point of reception are the same and equal to some
constant P. Further, assuming that hm,n are i.i.d. random variables for every m and
nm, (28) can be transformed to
Rm =

n∈A m
Xn P + PN,
(29)
where Xn is the random variable with unit power describing the impact of fading.
In the threshold-based model, the capture of signal U j in slot sm occurs if
X j
k
n∈A m,n̸= j Xn + PN/P
≥b,
(30)
c.f. (2). Moreover, the use of IC potentially enables the iterative recovery of col-
lided signals within sm. Speciﬁcally, if (30) is satisﬁed and U j recovered, then U j
is removed from sm (as well as all other slots where its replicas appear) and the
condition (30) may become satisﬁed for some of the signals remaining in sm. In
other words, besides inter-slot IC, the fading and capture effect also enable intra-
slot IC; note that the latter is not possible for the collision channel model. In terms
of the asymptotic performance evaluation, the possibility of performing intra-slot IC
impacts the probability of user recovery (12) in the following way
p(l)
i
= 1 −
l−1

t=0
C(t)
l −1
t

qt
i−1(1 −qi−1)l−t−1,
(31)
where C(t) is the probability that the reference edge is removed in slot of degree l
where l −t −1 edges have been removed via inter-slot IC in the previous iteration
(i.e., t + 1 edges remain in the slot).7 Assuming that b ≥1, i.e., that the receiver is
able to decode a single transmission at a time, C(t) can be further decomposed into
C(t) =
t
r=0
C(t,r)
(32)
where C(t,r) is the probability that the reference edge is recovered after r applica-
tions of the intra-slot IC.
7Note that for the collision channel model, it is implicitly assumed that C(0) = 1 and C(t) = 0,
t = 1, . . . ,l −1.

350
ˇC. Stefanovi´c and D. Vukobratovi´c
Without loss of generality and the slight abuse of notation, label the edges remain-
ing in slot sm at the start of the iteration i in the following way: (i) the ﬁrst r are
arranged by their powers in the descending order, (ii) the rest have their powers lower
than the power of the edge r but do not feature any particular arrangement, (iii) the
reference edge is labeled by r + 1, and (iv) the remaining t −r edges are labeled
arbitrarily. Then, the probability C(t,r) is equal to
C(t,r) =
t!
(t −r)!×
× Pr

X1
t+1
j=2 X j + PN/P
≥b;
X2
t+1
j=3 X j + PN/P
≥b; . . . ;
Xr+1
t+1
j=r+2 X j + PN/P
≥b
	
,
(33)
where Xi is the power of the ith edge, and where
t!
(t−r)! is the number of realizations
in which the power of the reference edge is not among r largest.8
If the coefﬁcients hm,n are i.i.d. Rayleigh distributed random variables, which is an
often used model in wireless communications, the probability distribution function
of X j is given by
pX j(x) = e−x, x ≥0, j = 1, . . . , t + 1.
(34)
It can be shown that in this case (33) evaluates to
C(t,r) =
t!
(t −r)!
e−1
γ ((1+b)r+1−1)
(1 + b)(r+1)(t+1−r+2
2 ) ,
(35)
where γ =
P
PN is the expected signal-to-noise ratio.
Combining (35), (33) and (31) produces
p(l)
i
= 1 −
l−1

t=0
t
r=0
t!
(t −r)!
e−1
γ ((1+b)r+1−1)
(1 + b)(r+1)(t+1−r+2
2 )
l −1
t

qt
i−1(1 −qi−1)l−t−1
(36)
= 1 −
l−1

t=0
t
r=0
l −1!
(t −r)!(l −t −1)!
e−1
γ ((1+b)r+1−1)
(1 + b)(r+1)(t+1−r+2
2 ) qt
i−1(1 −qi−1)l−t−1,
(37)
and averaging over the edge-oriented slot degree distribution yields
8It is assumed that the all realizations in terms of the ordering of the powers are a priori equally
likely.

Coded Random Access
351
pi =

l
ωl p(l)
i
= 1 −

l
βl−1
(l −1)! p(l)
i
(38)
= 1 −e−β 
l
βl−1
l−1

t=0
t
r=0
e−1
γ ((1+b)r+1−1)
(t −r)!(l −t −1)!
qt
i−1(1 −qi−1)l−t−1
(1 + b)(r+1)(t+1−r+2
2 ) .
(39)
As an example, for frameless ALOHA with β = 7.21, capture threshold b = 1,
and the expected signal-to-noise-ratio γ = 10, the maximum throughput that can be
achieved is 2.37 packet/slot, which is signiﬁcantly above the absolute upper bound
of 1 packet/slot that holds for the collision channel.
3
Coded Slotted ALOHA for Multi-AP Scenario
ThepreviouspartofthechapterconsideredtheCSAschemeinthesingleAPscenario.
However, in many wireless communication scenarios of interest, a user transmission
can be detected at multiple APs. Examples include satellite communication networks,
networks of WiFi APs, or dense deployment of cellular base stations in urban areas,
including e.g., the cellular small cell networks. One such scenario is illustrated in
Fig.8, where a large number of sensors attempt to upload their packets to a network
of APs.
In multi-AP scenarios, as introduced earlier, each AP can exploit the temporal
diversity of user’s packet replicas via IC across the time slots. However, the CSA
scheme can also exploit the spatial diversity, where IC is done across multiple APs
in a single time slot. More precisely, due to limited range of user transmissions, a
packet replica of a transmitting user may appear as a singleton slot at one of the
surrounding APs, while at the same time being a collision slot at other surrounding
Fig. 8 Multi-AP communication scenario

352
ˇC. Stefanovi´c and D. Vukobratovi´c
APs. In that case, an AP decoding a clean packet replica in a singleton slot can
(spatially) cooperate with neighboring APs by sharing the decoded packet replica,
thus allowing them to use IC to remove the replica from their collision slots.
In the rest of this chapter, we formalize more precisely the model for multi-
AP scenario and provide a brief review of some of the recent results and possible
directions for further study.
3.1
System Model for CSA in Multi-AP Scenario
We consider a scenario with N contending users and M APs, where both users and
APs are placed independently and uniformly at random in a unit-square area. The
time domain is slotted and slots are organized into frames containing τ slots per
frame. The system is both frame- and slot-synchronous across all APs and all users.
As in CSA, each user transmits packet replicas in one or more randomly selected
slots within the frame, where the number of transmitted replicas is governed by the
(temporal) degree distribution Λ(x) = 
i Λixi, and Λi is the probability of sending
i replicas. However, unlike in the single-AP model, in the multi-AP model we assume
that a user transmission is of limited range, so that the user’s signal can be detected
only by APs that lie in a circle of radius r centered at the user. The system load is
deﬁned as the number of users per AP per slot: G = N/(Mτ).
After users transmit their replicas in a given frame, the decoding process at all
the APs is initiated. We consider two decoding models: (i) non-cooperative, where
APs do not cooperate during the decoding process, and (ii) cooperative, where APs
cooperate by exchanging decoded users’ replicas during the decoding process. Note
that the cooperative case requires that if two APs exchange information, i.e., if they
share common users, then they have to be connected via a backhaul link. After the
decoding process is ﬁnished, each user is decoded if and only if it is decoded by
any of the APs in the network (thus we assume no explicit user-to-AP association).
We are interested in the two main performance metrics: (i) the probability that an
arbitrary user is recovered, denoted as PR, and (ii) the system throughput T deﬁned
as T = G · PR, both of which depend on the system load G.
For convenience, it is useful to introduce a graph representation of the multi-
AP setup. To this end, we deﬁne two different but related graph models. The
ﬁrst model illustrates the connectivity between the users and the APs. Let U =
{U1,U2, . . . ,UN} represents the set of user nodes, and B = {B1, B2, . . . , BM} rep-
resent the set of AP nodes. An edge of the graph connects the user node Ui and the
AP node B j iff the jth AP is within the range r of the ith user. The resulting graph
G = (U ∪B, EG ) is a random bipartite geometric graph. We denote the (spatial)
degree distributions of user and AP nodes as Q(x) = 
i Qixi and R(x) = 
i Rixi,
respectively, where Qi (resp. Ri) is the probability a user (resp. AP) node is of
degree i.
The second graph model reﬁnes the previous spatial model by introducing the
temporal dimension. In other words, it expands each AP node into τ slot nodes

Coded Random Access
353
observed at the AP during a frame of duration τ. Thus, apart from the set U , we
now have the set S of slot nodes Sj,t, 1 ≤j ≤M, 1 ≤t ≤τ, representing the tth
time slot at the jth AP. An edge of the graph connects the user node Ui and the
slot node Sj,t if and only if: (i) the ith user transmitted a replica in the tth time
slot, and (ii) the jth AP is within the range r from the ith user. The resulting graph
H = {U ∪S , EH } is a random bipartite geometric graph. We denote the degree
distributions of the user and the slot nodes in H as U(x) and S(x), and note that
they are easily derived from Λ(x), Q(x) and R(x).
Figure9 illustrates an example of the graph representation of the multi-AP system
from Fig.8, for a simple case when the frame contains a single slot, i.e., τ = 1. Note
that, in this case, the two graph models G and H are equivalent. Figure10 illustrates
an example of the same multi-AP scenario for the frame length equal τ = 3 slots. In
this case, Fig.10 represents the graph H , while the underlying graph G remains the
same as in Fig.9.
Similarlyasinthesingle-APmodel,thegraphmodelH isusefulforformalization
of the iterative IC decoding algorithm. We also consider the iterative IC decoding that
resembles the iterative graph-peeling erasure decoder for LDPC codes. However, the
Fig. 9 Graph representation of the multi-AP model (τ = 1)
Fig. 10 Graph representation of the multi-AP model (τ = 3)

354
ˇC. Stefanovi´c and D. Vukobratovi´c
IC decoder now operates on the graph H of the multi-AP model. Due to the fact that
this graph is based on the random bipartite geographic graph model, analyzing the
decoding performance is considerably more challenging for the multi-AP scenario.
Unfortunately, asymptotic analysis based on the density evolution method, which is
a standard tool for analyzing the IC decoders on sparse random graphs, does not hold
here. This follows from the fact that the probability of appearance of small cycles in
the underlying (geometric) graph does not vanish asymptotically with the size of the
graph.
In the following subsection, we discuss the performance of the IC decoding over
the graph models for the multi-AP scenario. We consider four different decoding
scenarios depending on the assumptions if the APs cooperate during the decoding
process and if each AP performs temporal IC decoding.
3.2
Performance of CSA in Multi-AP Scenario
In this section, we consider the performance of the iterative IC decoder in the multi-
AP scenario under the asymptotic setting. We let the number of user nodes N →∞
and the number of APs M = M(N) →∞, the number of slots in the frame τ →∞
and the transmission range r →0, under constraints that the average number of APs
within the range of a user: Mr2π →δ, and the load: N/(Mτ) →G, where δ and G
are positive constants. We ignore the edge-effects of users/APs placed close to the
edges of the unit-square area as they asymptotically vanish.
In the asymptotic setup, it is easy to show that the spatial degree distribution of
users Q(x) is a Poisson distribution with parameter δ. Thus an upper limit on PR is the
probability that a user is not heard by any AP, which equals PR ≤1 −exp(−δ). For
different decoding scenarios, we will be interested in the (asymptotic) user recovery
probability PR and the system throughput T . We will be also interested in threshold
phenomena involving the system load G; namely, the maximum load G⋆(δ) for which
the decoding scheme is still able to achieve the upper bound:G⋆(δ) = sup{G ≥0 :
PR →1 −e−δ}.
Case 1: Non-cooperative Decoding Without Temporal IC - In this model,
each AP follows standard SA protocol without IC decoding across the time slots.
In addition, APs do not communicate and exchange information with each other. In
this case, it is sufﬁcient to observe the decoder operation on a multi-AP graph with
a frame length τ = 1 (as in Fig.9). Note that the decoding process will be able to
collect all the users that have at least one edge incident to a degree one AP. However,
characterizing the number of such users is a rather challenging task.
• Recovery probability:
PR →
∞

k=1
(−1)k−1 δk
k!

 4
1
e−aδGdμk(a),
(40)

Coded Random Access
355
where μk is the probability distribution of αk: the area covered by the union of
k circles randomly thrown in a circle of radius r, normalized by π. However,
although above equation provides exact asymptotic limit, calculating PR as above
is a tedious task, albeit solvable using numerical methods.
• Throughput: Let ε = exp(−δ), then the peak normalized (per AP) throughput is
lower-bounded as T ⋆≥1
e
1−ε
ln(1/ε).
• Threshold load: G⋆(δ) = 0. In other words, PR splits away from 1 −exp(−δ)
exactly at G = 0.
Case 2: Cooperative Decoding Without Temporal IC - Performance improve-
ment over the previous case is obtained if the APs are allowed to share decoded user’s
replicas. As in the previous case, it is sufﬁcient to observe the decoder operation on
a multi-AP graph with τ = 1 (Fig.9). The cooperative decoding reduces to the iter-
ative graph-peeling erasure decoder on the underlying random bipartite geometric
graph G . Unfortunately, as noted earlier, rich asymptotic analysis tools from coding
theory do not directly apply to this scenario, due to the fact that very short cycles do
not asymptotically vanish.
• Recovery probability:
PR ≤1 −e−δ −(1 −e−δ/4)e−2δ(1 −e−Gδ/4).
(41)
The above bound follows from analyzing the probability of occurrence of the
stopping sets of size two in an underlying random bipartite geometric graph.
• Threshold load: G⋆(δ) = 0. As in the previous case, PR splits away from 1 −
exp(−δ) at G = 0, however, compared to Case 1, the negative slope of decay at
G = 0 is signiﬁcantly lower, thus providing better performance of spatial cooper-
ation over non-cooperative case.
The above two cases show that, without temporal IC across the time slots at each
AP, it is difﬁcult to exploit the full power of IC decoding due to the structure of the
underlying geometric graphs.
Case 3: Non-cooperative Decoding with Temporal IC - In this scenario, we
observe a system of M APs distributed in a unit-square area that do not cooperate, but
independently run the CSA across time slots of a frame. If observed independently,
the performance of each AP depends only on the temporal degree distribution Λ(x)
the users apply to generate replicas. More precisely, for a given Λ(x) and the load
H (number of users per slot), let P S
R(H) be the user recovery probability in the
asymptotic setup (where the number of users and slots tend to inﬁnity, but their ratio
tends to H). Then, a threshold load H ⋆exists such that, for H ≤H ⋆, it holds that
P S
R(H) = 1. As we present next, using the performance of CSA in the single-AP
case, we can express the performance of non-cooperative decoding with temporal IC
in the multi-AP case.
• Recovery probability:
PR ≤(1 −e−δ)P S
R(H = 8eδG).
(42)

356
ˇC. Stefanovi´c and D. Vukobratovi´c
• Throughput: Let ε = exp(−δ), then the peak normalized (per AP) throughput is
lower-bounded as T ⋆≥H ⋆
8 e
1−ε
ln(1/ε).
• Threshold load: G⋆(δ) ≥
1
8e
H ⋆
δ . In other words, the recovery probability stays at
the maximal possible value 1 −exp(−δ) at least in the range G ∈[0, 1
8e
H ⋆
δ ].
Case 4: Cooperative Decoding with Temporal IC - Performance-wise, this case
is the most powerful decoding scenario, where the IC decoder operates across the
complete spatio-temporal graph H (such as the one in Fig.10). However, compared
to the Case 3, no stronger results exist for this case (note that the bounds for Case 3
also hold for Case 4). In the following, we differentiate the performance of Case 4
from the previous cases using simulations.
Numerical results: In the simulation setup, we set the number of base stations
M = 40, and the number of slots in the frame to τ = 40. We simulate the recovery
probability PR versus G = N/(Mτ) by varying N. We perform Monte Carlo simu-
lations where for each N, we generate 30 random placements of users and APs. For
the cases with temporal IC, we apply the temporal degree distribution Λ(x) = x2
(i.e., each user generates two replicas per frame).
Figure11 plots the normalized throughput T (G) versus normalized load G for the
four decoding cases, assuming δ = 6. We can see that the Case 4 (spatio-temporal
cooperation) achieves much higher peak normalized throughput than the remaining
three schemes.
Fig. 11 Performance comparison of multi-AP decoding schemes

Coded Random Access
357
3.3
Discussion and Open Problems
In the case of CSA in Multi-AP scenario, a number of open problems arise that yet
have to be solved. Note that even the simplest extension to Multi-AP scenario, the
case of SA without cooperation and without temporal IC (Case 1) lacks an elegant
and closed-form solution for the average system throughput. In the following, we
provide several scenarios which we ﬁnd relevant and which are subject of our current
study.
Different Multi-AP Models; The Multi-AP model presented in this chapter is
mainly motivated by applications in dense cellular systems where APs correspond to
small base stations. In this case, the geometric graph model is a reasonable approxi-
mation of a user to AP coverage and connectivity. However, in certain scenarios such
as satellite networks, all users might be heard at all satellites, although with different
channel conditions (e.g., some user-to-AP channels being exposed to harsh fading
while others not). This has led to slightly different and analytically more tractable
model, wherein underlying graph representation follows random graph model (unlike
random geometric graph model).
Asynchronous System Operation: In reality, signals transmitted from users will
travel different distances to different neighbouring APs, thus arriving at APs with
different delay. This delay variability may vary from rather small in dense small cell
networks, to very large in multi-AP satellite systems. Thus the assumption that the
system is perfectly slot synchronized across all users and all APs might be impossi-
ble to achieve in practice. In more realistic model, we might explore the scenario in
which users are asynchronous and send their packet replicas in arbitrary time instants
which are not aligned to slot boundaries. Such a system may still employ IC decod-
ing and may still provide signiﬁcant performance improvements over traditional
ALOHA. Thus the performance of asynchronous ALOHA in Multi-AP scenario is
an interesting and relevant research direction.
Multi-AP Models with Directional Antennas: The latest trends in wireless com-
munications advocate shifting the operational communications band to higher fre-
quencies above 6GHz into the so called mmWave band. In such an environment, to
overcome high signal attenuation, typical transmission strategies involve directional
antennas in which the transmitted signal is emitted as a focused and narrow-angle
beaminacertaindirection.AninterestingextensiontoCSAinMulti-APenvironment
would be to observe how the system throughput changes with the transition towards
mmWave communications and narrow-beam antennas. Our preliminary results show
that this should help improving the system throughput in ultra-dense deployments
since users transmitting in narrow beams could better avoid interfering each other,
which in terms of the underlying graph representation means that the occurrence
of short cycles could be signiﬁcantly reduced, leading to better performance of the
iterative IC decoding.

358
ˇC. Stefanovi´c and D. Vukobratovi´c
4
Literature Review
The performance of slotted ALOHA was analyzed in [13]. Framed slotted ALOHA
was proposed in [9]. The threshold-based capture model was topic of multitude
works, c.f. [8, 17–19].
There is an abundance of literature related to CSA. In the following, some of
notable works are brieﬂy mentioned. An accessible overview of CSA is presented
in [12]. FSA with iterative IC was originally proposed in [1], assuming that each
user sends two replica in randomly selected slots of the frame and showing that the
maximum expected throughput on the collision channel is 0.55 packet/slot [1]. IRSA
was introduced in [4], where it was also shown how to design user degree distributions
whose thresholds are close to 1. The upper bound on the threshold of any user degree
distribution with a given average degree was derived in [10]. A generalization of
the scheme, in which users contend with segments produced by applying a linear
segment-oriented code on the segments of the user packet, is introduced and analyzed
in [11].
Frameless ALOHA was inspired by the rateless coding paradigm [5]; it was
introduced and its asymptotic performance analyzed in [15]. The optimization of the
termination criterion that maximizes expected throughput of the scheme in scenarios
with ﬁnite number of users was addressed in [14].
Derivation of the and-or tree evaluation for the threshold-based capture model
was performed in [16]; the same work also addresses the performance of frameless
ALOHA for Rayleigh black-fading channel with the threshold-based capture effect.
Design of the user degree distributions for IRSA on Rayleigh black-fading channel
with threshold-based capture was assessed in [2].
The and-or tree evaluation was originally conceived in [6].
CSA in Multi-AP scenario is introduced and analyzed in [3]. The exposition in
this chapter follow this approach. Somewhat different model and overview of results
is also presented in [7].
References
1. E. Casini, R.D. Gaudenzi, O. del Rio Herrero, Contention resolution diversity slotted ALOHA
(CRDSA): an enhanced random access scheme for satellite access packet networks. IEEE
Trans. Wirel. Commun. 6(4), 1408–1419 (2007)
2. F. Clazzer, E. Paolini, I. Membeli, C. Stefanovic, Irregular repetition slotted ALOHA over the
Rayleigh block fading channel with capture, in Proceedings of IEEE ICC 2017. Paris, France
(2017)
3. D. Jakovetic, D. Bajovic, D. Vukobratovic, V. Crnojevic, Cooperative slotted ALOHA for
multi-base station systems. IEEE Trans. Commun. 63(4), 1443–1456 (2015)
4. G. Liva, Graph-based analysis and optimization of contention resolution diversity slotted
ALOHA. IEEE Trans. Commun. 59(2), 477–487 (2011)
5. M. Luby, LT codes, in Proceedings of 43rd IEEE FOCS. Vancouver, BC, Canada (2002)
6. M.G. Luby, M. Mitzenmacher, A. Shokrollahi, Analysis of random processes via And-Or tree
evaluation, in Proceedings of 9th ACM-SIAM SODA. San Francisco, CA, USA (1998)

Coded Random Access
359
7. A.Munari,F.Clazzer,G.Liva,MultireceiverALOHA:asurveyandnewresults,in Proceedings
of IEEE ICC 2015 - MASSAP Workshop. London, UK (2015)
8. G.D. Nguyen, A. Ephremides, J.E. Wieselthier, On capture in random-access systems, in Pro-
ceedings of IEEE ISIT 2006. Seattle, WA, USA (2006)
9. H. Okada, Y. Igarashi, Y. Nakanishi, Analysis and application of framed ALOHA channel
in satellite packet switching networks - FADRA method. Electron. Commun. Jpn. 60, 60–72
(1977)
10. E. Paolini, G. Liva, M. Chiani, Graph-based random access for the collision channel without
feed-back: capacity bound, in Proceedings of IEEE Globecom 2011. Houston, TX, USA (2011)
11. E. Paolini, G. Liva, M. Chiani, Coded slotted ALOHA: a graph-based method for uncoordinated
multiple access. IEEE Trans. Inf. Theory 61(12), 6815–6832 (2015)
12. E. Paolini, C. Stefanovic, G. Liva, P. Popovski, Coded random access: how coding theory helps
to build random access protocols. IEEE Commun. Mag. 53(6), 144–150 (2015)
13. L.G. Roberts, ALOHA packet system with and without slots and capture. SIGCOMM Comput.
Commun. Rev. 5(2), 28–42 (1975)
14. C. Stefanovic, P. Popovski, ALOHA random access that operates as a rateless code. IEEE
Trans. Commun. 61(11), 4653–4662 (2013)
15. C. Stefanovic, P. Popovski, D. Vukobratovic, Frameless ALOHA protocol for wireless net-
works. IEEE Commun. Lett. 16(12), 2087–2090 (2012)
16. C. Stefanovic, M. Momoda, P. Popovski, Exploiting capture effect in frameless ALOHA for
massive wireless random access, in Proceedings of IEEE WCNC 2014. Istanbul, Turkey (2014)
17. A. Zanella, M. Zorzi, Theoretical analysis of the capture probability in wireless systems with
multiple packet reception capabilities. IEEE Trans. Commun. 60(4), 1058–1071 (2012)
18. M. Zorzi, Capture probabilities in random-access mobile communications in the presence of
Rician fading. IEEE Trans. Veh. Technol. 46(1), 96–101 (1997)
19. M. Zorzi, R.R. Rao, Capture and retransmission control in mobile radio. IEEE J. Sel. Areas
Commun. 2(4), 1289–1298 (1994)

Part IV
Codes for Distributed
Storage Systems

An Overview of Coding for Distributed
Storage Systems
Shiqiu Liu and Frédérique Oggier
Abstract This chapter provides a short survey of coding for distributed storage
systems. It describes the code design criteria for such codes, emphasizing what
makes them different from traditional codes for communication. It then focuses
on two large families of codes, regenerating codes and locally repairable codes,
including a discussion on how these codes are used in an adversarial setting.
1
Distributed Storage Systems and Erasure Codes
A distributed storage system consists of a set of hard drives (disks), or nodes, which
is used to store data in a distributed manner: the same ﬁle could be stored multiple
times, one copy per hard drive, over a set of two, three, or more hard drives, or pieces
of the same ﬁle could be stored across a set of hard drives. Reasons why one may
want to store data in a distributed manner (rather than on a single disk) include
• ease of scale: if the system runs out of memory, one just adds more disks to the
storage system,
• reliability: if there is a single disk, and it fails, the stored data is lost, while if there
are several disks containing the same data, the data will have chances of surviving,
depending on the failure(s), and on how the data is stored.
If there are several disks, but each ﬁle is stored only on a single disk, then reliability
cannot be achieved, because in the event of this speciﬁc disk failure, data will be lost.
This is why redundancy is needed. The simplest form of redundancy is replication.
Two or three copies of a ﬁle are made, and they are all stored in different disks. The
S. Liu (B)
Institute of Network Coding-The Chinese University of Hong Kong,
Hong Kong, China
e-mail: sqliu@inc.cuhk.edu.hk
F. Oggier
Division of Mathematical Sciences, School of Physical and Mathematical
Sciences, Nanyang Technological University, Singapore, Singapore
e-mail: frederique@ntu.edu.sg
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_14
363

364
S. Liu and F. Oggier
notion of redundancy has been well studied in the context of noisy communication,
via coding theory: a signal is transmitted over a noisy channel, because of the noise,
part of the signal will be lost, so redundancy is added to the transmitted signal, to
help the receiver recover the transmitted signal, despite it being distorted through the
communication channel. The process of adding redundancy to the transmitted signal
is called “encoding”.
We will assume throughout this chapter that data can be modeled as a vector with
coefﬁcients in some ﬁnite ﬁeld Fq, for q a prime power. Encoding thus consists of
mapping a vector f ∈FM
q to a vector x ∈Fn
q, called codeword, where n > M . The
set of codewords is called a code. If this mapping is linear, we can write x = fG for
some M × n matrix G of rank M , and we speak of a linear code, with parameters
[n, M ], where n is the length and M the dimension. The simplest example of linear
code is the repetition code with parameters [n, 1] which maps f to a vector containing
n copies of f: (f, . . . , f). The repetition code corresponds to a replication scheme for
storage: there are n copies of f, each of them are stored on a different disk, over n
disks. This scheme is very reliable: there are n copies of f, therefore n−1 disk failures
can happen, and still the data will survive. The same is true for communication over
a noisy channel: up to n−1 transmitted signals can be lost, the intended message will
still be communicated reliably. The problem with this scheme is that its rate M /n is
poor, respectively its storage overhead n/M is high.
The trade-off between reliability and rate is well known in coding theory, and
is characterized by the Singleton bound. Reliability is captured by the minimum
Hamming distance dH of a code C:
dH(C) = min
x̸=x′ d(x, x′)
where d(x, x′) counts in how many coefﬁcients the vectors x and x′ differ. The
minimum Hamming distance tells us that given a codeword in C, we can lose up to
dH(C)-1 coefﬁcients, and still be able to recover our data. This is because any x
differs in at least dH(C) coefﬁcients from any other x′. Now the Singleton bound
tells us, given n and M , what is the maximum possible dH.
Proposition 1 Given a code C of size |C| = qM , we have dH(C) ≤n −M + 1.
Proof Take the qM codewords of C, and look at their ﬁrst M −1 coefﬁcients. Since
we can have at most qM −1 distinct vectors of length M −1, among the vectors
obtained by looking at the ﬁrst M −1 coefﬁcients of qM vectors, there must be at
least two vectors which are the same by the pigeon hole principle, corresponding to
two codewords x ̸= x′ which are equal on their ﬁrst M −1 coefﬁcients, implying
that they can different at most on n −(M −1) coefﬁcients, which completes the
proof.
Codes reaching the Singleton bound are called maximum distance separable
(MDS) codes. The most famous class of MDS codes is the class of Reed–Solomon
codes [33]. A Reed–Solomon code C can be described as

An Overview of Coding for Distributed Storage Systems
365
C = {(p(w1), p(w2), . . . , p(wn)) : p(X ) =
M −1

i=0
piX i ∈Fq[X ]}
(1)
wherew1, . . . , wn arendistinctelementsofFq (andthusn ≤q).Fromthedescription,
a codeword is made of n evaluations of a polynomial of degree M −1. Polynomial
interpolation tells us that we can recover the polynomial as long as we still have the
evaluation of p(X ) in at least M points, which means that we can lose at most n−M
of them, corresponding to a Hamming distance of n −M + 1.
Reed–Solomon codes have been used for communications, and for storage appli-
cations such as CDs [12]. In the context of distributed storage systems, they are also
optimal when it comes to trade reliability and storage overhead. Why then not just
adopt Reed–Solomon codes as such1 instead of researching novel coding strategies
for distributed storage systems?
The reason is that coding for distributed storage includes one more dimension, on
top of reliability and storage overhead, namely that of maintenance or repairability.
In a communication scenario, a signal is transmitted, and received at a given point
of time. Once the signal is received, it must be recovered taking into account lost
information due to channel noise, but this degradation is now given, it will not
change. This is a main difference with a distributed storage scenario. Suppose a disk
has failed at a given point of time, nothing prevents another disk to fail later on,
in fact, the failure of one disk may trigger other disk failures. Therefore, without a
maintenance mechanism, the data will eventually be lost, because no coding solution
can protect against an arbitrarily large amount of failures. What maintenance does is
illustrated on an example with two copies of a ﬁle f. If the ﬁrst copy is lost because
of a disk failure, a disk or node which is still alive make a new copy of f, so that the
storage system still has two copies overall, despite one failure. In fact, keeping three
copies of f is somewhat even more prudent, because once the ﬁrst failure occurred,
there is no more protection. Having three copies allows to lose one, start recreating
a new copy, and tolerate one more failure in the process of creating a new copy
(which may take time). Suppose now a Reed–Solomon codeword is used to encode
f, each codeword coefﬁcient is stored on a distinct disk, across n different disks. In
the event of one failure, recovering the one missing coefﬁcient is asking for a lot
of resources: data needs to be transferred from M nodes, the codeword needs to be
recomputed, the missing coefﬁcient is then recovered, but at a high cost in terms of
both communication and computation costs. If the system were to wait for several
failures to happen before starting this repair procedure, the cost would be amortized,
but at the risk of losing the data if the system waits for too long.
Research on coding for distributed storage has thus focused on getting codes with
• high reliability (fault tolerance),
1We are not claiming that Reed–Solomon codes are not used in distributed storage systems, we
added “as such” as a way to say that something else has to be taken into account in all cases, even
if one wants to use Reed–Solomon codes.

366
S. Liu and F. Oggier
• low storage overhead (if storage overhead is not an issue, replication is a great
practical solution),
• good maintenance mechanisms.
What good maintenance means is still under discussion, but in this chapter, we
will focus on two aspects, low communication costs in Sect.2, and a low number of
live nodes to be contacted during repair in Sect.3. Other aspects are also discussed
in [23].
2
Regenerating Codes
When a node failure happens in a distributed storage system, a maintenance mech-
anism tries to replace the lost data using data available in the system. This involves
downloading data from live nodes, which incurs communication costs, referred to as
repair bandwidth.
In [4], Dimakis et al. introduced a min-cut max-ﬂow technique from network
coding to the setting of distributed storage to optimize the repair bandwidth. The
result of their analysis is a trade-off bound between storage and repair bandwidth,
and codes achieving this bound are called regenerating codes. In [4], the scenario
of only one single failure repair at a time is treated. The main idea of regenerating
codes is that they could satisfy an MDS-like property (the ﬁle can be retrieved by
contacting any choice of k nodes, where k is a ﬁxed threshold, not necessarily the code
dimension), and in the repair process, many nodes could be contacted (typically all
but the failed one) and less symbols downloaded, in turn reducing the cost of repairing
one single failure.
2.1
Parameters of Regenerating Codes and Min-Cut Bound
Considering a network of N nodes, a ﬁle f of length M stored in n of these N nodes.
Each node is assumed to have the same storage capacity α, that is α symbols are
stored in each of the nodes. When a failure occurs, a live node (called newcomer)
among these N nodes, which does not yet store data from f, is joining the repair
process. The newcomer contacts d live nodes and downloads β symbols from each
of them, to repair the data lost by the failed node, as shown on Fig.1. The newcomer
thus downloads γ = dβ amount of data, which constitutes the total repair bandwidth.
To analyze the trade-off between storage capacity α and repair bandwidth β, a min-
cut bound is computed [4] in an information ﬂow graph, where the data ﬂows from
a source S, into the storage system, through different nodes when repair happens, to
a data collector DC which wants to retrieve the data back.
Theorem 1 ([4]) Consider a directed information ﬂow graph, with a source S and
a sink as data collector. Every node (apart the source and the sink) has a storage

An Overview of Coding for Distributed Storage Systems
367
Fig. 1 Four nodes, labelled from 1 to 4 failed. Four other nodes in the center with the same labels
are repairing the lost data by contacting live nodes 5, 6, 8, 9. We have d = 2, e.g., node 3 downloads
data from nodes 5 and 9. In the original regenerating code case, the four failures will be repaired
sequentially. In the collaborative case discussed next, nodes 1, 2, 3, 4 involved in the repair are
exchanging data as well
capacity of α. When a failure occurs, a newcomer connects to d ≥k live nodes and
obtains β symbols from each of them. Suppose that a data collector DC connects to
k nodes which were all involved in different phases of repair. Then a min-cut bound
between the source S and the data collector DC is given by
mincut(S, DC) ≥
k−1

i=0
min{(d −i)β, α}.
(2)
Proof Let xi denote the newcomer during the ith repair, i ≥0. Write xi as a logical
pair (xin
i , xout
i
) formed by an incoming node, so that an edge between xin
i and xout
i
models the storage capacity α. Consider a data collector that connects to k output
nodes, say{xout
i
: i = 0, 1, . . . , k −1}. We show that any cut between S and DC in
the graph has a capacity that satisﬁes (2). Since we may assume that outgoing edges
of S and incoming edges of DC have inﬁnite capacity, we only need to consider cuts
(U,U), S ∈U and DC ∈U, where these inﬁnite capacity edges do not participate.
Let C denote the edges in the cut.
Let (xin
0 , xout
0 ) be the ﬁrst repair node. We have two cases: (1) If xin
0 ∈U, then the
edge with weight α between xin
0 and xout
0
must be in the cut C. (2) If xin
0 ∈U, then the
cut contains d edges carrying β coefﬁcients. Thus the ﬁrst node brings a contribution
of c0 ≥min{dβ, α} to the cut.
Let us consider the second repair node (xin
1 , xout
1 ). There are again two cases:
(1) xin
1 ∈U, then the edge with weight α is again in the cut. (2) If xin
1 ∈U, then
at most one of its incoming edges could be from xout
0 , thus at least d −1 edges
carrying β coefﬁcients are in the cut. The min-cut contribution from the second node
is c1 ≥min{(d −1)β, α}.

368
S. Liu and F. Oggier
In general, for the ith repair node (xin
i−1, xout
i−1), case 1) involves cutting the storage
capacity link, while for the second case, there are at most i −1 incoming edges
from nodes in U, thus at least d −i + 1 edges carrying β coefﬁcients, yielding
ci−1 ≥min{(d −i + 1)β, α}.
Summing these contributions leads to (2).
Using the Minimum cut-Maximum ﬂow Theorem, we get that the initial ﬁle size M
must satisfy
M ≤
k−1

i=0
min{(d −i)β, α}.
Thus the largest that M can get is M = k−1
i=0 min{(d −i)β, α}, and codes
reaching this bound are called regenerating codes. We may now ask to minimize
α = α(d, γ ) subject to the aforementioned constraint on the size of M , which can
equivalently be stated as a function of γ instead of β: M = k−1
i=0 min{(1−i/d)γ, α}.
This optimization problem can be easily solved in closed form. This is because
(1−(k −1)/d)γ < (1−(k −2)/d)γ < · · · < (1−1/d)γ < γ . Since α must belong
to any of these intervals, the constraints can be restated removing all the minima, and
the minimum value of α is found. Suppose for example that α ≤(1 −(k −1)/d)γ ,
then the constraint becomes kα = M , for which γ ≥α
d
d−(k−1) =
M
k
d
d−(k−1).
Similarly, if α ≥γ , we get
M =
k−1

i=0
(1 −i/d)γ =

k −1
d
(k −1)k
2

γ = k
2d −(k −1)
2d

γ,
showing that γ = M
k
2d
2d−(k−1). Then α ≥γ gives α = γ for minimum value of α.
The other regimes in between are obtained similarly, which show that the optimal is
a piece wise linear function, which forms a trade-off between α and γ , as illustrated
on Fig.2 for k = 4 and d = 5.
The smallest value of α, corresponding to
(α, γ ) =
M
k , M
k
d
d −(k −1)

,
(3)
is indeed characterizing the smallest possible value for α, since we have the constraint
that any k nodes should be able to retrieve the ﬁle f, thus no node can store less than
M /k symbols. This point of the trade-off is called the minimum storage regenerating
point (MSR). Then the other extreme point
(α, γ ) =
M
k
2d
2d −(k −1), M
k
2d
2d −(k −1)

,
(4)
says that α = γ , which minimizes the repair bandwidth in absolute, irrespectively of
α. This point is thus called the minimum repair bandwidth regenerating point (MBR).

An Overview of Coding for Distributed Storage Systems
369
0.2
0.3
0.4
0.5
0.6
0.2
0.3
0.4
0.5
alpha
gamma
Fig. 2 Two trade-off curves, with α on the x-axis, and γ = γ (α) on the y-axis. The outer line
corresponds to t = 1 failure repair. The inner one corresponds to t = 3 simultaneous repairs using
a collaborative strategy. The parameters are set to be k = 4, d = 5 and we normalized the ﬁle size.
We observe that t = 3 yields a better trade-off than t = 1
It is also clear from this formula that d = n −1 brings most beneﬁts in terms of
bandwidth savings.
No matter how many failures occurred in the storage system, the strategy that we
just analyzed holds for one failure repair at a time, so multiple failures are handled
by performing multiple repairs sequentially.
To repair more than one failure simultaneously, two independent works [14, 38]
introducedcollaborative(coordinated,cooperative)regeneratingcodes,whichallow
repairs using the data not only from live nodes, but also from all nodes currently being
repaired. This strategy introduces a collaborative phase, on top of the download phase
done previously. The analysis generalized the one presented above: a min-cut bound
is computed, taking into account the collaboration, and a trade-off for collaborative
regenerating codes is obtained, between storage and repair bandwidth, where repair
bandwidth takes into account that data is exchanged during collaboration.
Theorem 2 ([14, 38]) Consider an information ﬂow graph, where every node has
a storage capacity of α, and repairs are performed by a group of t nodes, that is
the system triggers a repair when t failures occur. Suppose that a data collector DC
connects to a subset of k nodes which were all involved in different phases of repairs,
where each phase involves a group of ui nodes, 1 ≤ui ≤t, and k = g−1
i=0 ui. Then
a min-cut bound for collaborative repair is

370
S. Liu and F. Oggier
M ≤
g−1

i=0
ui min
⎧
⎨
⎩α,
⎛
⎝d −
i−1

j=0
⎞
⎠β + (t −ui)β′
⎫
⎬
⎭,
(5)
where β′ is the exchange repair bandwidth, that is each of the repairing nodes
exchanges β′ symbols with every other t −1 repair nodes.
Solving the problem of minimizing α under the constraints given by the above
bound now becomes difﬁcult, the interested reader may refer to [40] for the compu-
tations. An example of the trade-off curve obtained for t = 3 is shown in Fig.2. It
turns out that increasing t actually improves the trade-off between storage and repair
bandwidth.
Both scenarios are included as particular cases of partially collaborative regen-
erating codes, proposed in [19]. The idea is to introduce freedom in the extent of
collaboration, by allowing repair nodes to exchange data with only a subset of the
nodes currently being repaired. A min-cut bound is available, however determining
the corresponding trade-off curve is open.
Theorem 3 ([19]) For partial collaboration, the repair process of t failures involves
t nodes, which will all download β amount of data from d live nodes, and exchange
β′ amount of data with a subset of t −s nodes, 1 ≤s ≤t. Then the min-cut bound is
M ≤min
u∈P
⎛
⎝
i∈I
ui min
⎧
⎨
⎩α,
⎛
⎝d −
i−1

j=0
uj
⎞
⎠β + (t −s + 1 −ui)β′
⎫
⎬
⎭
+

i∈¯I
ui min
⎧
⎨
⎩α,
⎛
⎝d −
i−1

j=0
uj
⎞
⎠β
⎫
⎬
⎭
⎞
⎠
(6)
where I = {i, t −s + 1 −ui ≥0}, ¯I = {i, t −s + 1 −ui < 0} and P = {u =
(u0, . . . , ug−1), 1 ≤ui ≤t and g−1
i=0 ui = k}.
When s = t, there is no collaboration, and (6) simpliﬁes to (2). When s = 1, the
collaboration phase involves all the other t −s = t −1 nodes, and we ﬁnd (5) again.
2.2
Functional Versus Exact Repair
The above bounds and trade-offs all address the preservation of data through different
repair phases. Suppose a node contains the piece fi2 of a ﬁle f, and after repair, afi
is being stored, for a ̸= 0. For example, using the alphabet F3 = {0, 1, 2}, a node
storing the coefﬁcient 1 fails, is repaired, but the value after repair is now 2, not 1.
2The same example can be done on a linear combination of fi.

An Overview of Coding for Distributed Storage Systems
371
In terms of recovering fi, both fi and afi play the same role (since a ̸= 0, a−1 exists
and computing a−1afi gives back fi, in the example, 2 · 2 gives back 1). However,
they are not bitwise the same data. Therefore, we distinguish exact repair, where lost
data is exactly recovered bit by bit, from functional repair, where the data itself is
not the same, but the information contained in the data is maintained. Exact repair is
often preferred, since it is easier to keep track of the data with respect to functional
repair, where transformation of the data should also be available. The above bounds
however hold for functional repair.
The question thus becomes that of achievability of these trade-offs for exact repair.
It is known that the extreme points (MSR and MBR) are achievable, and we will give
some example for these two cases in the next subsection. How to characterize the
interior points for exact repair remains open in general. We summarize some of
the results known so far. It was ﬁrst shown in [46], using a particular code with
parameters n = 4, k = 3, d = 3, that the exact repair trade-off lies strictly away
from the functional repair trade-off. In [35], it was more generally shown that the
exact repair trade-off lies strictly above the functional trade-off for any values n, k, d.
From these results, it became clear that one would have to address the question
of ﬁnding trade-off bounds for exact repair. However, the exact repair trade-off for a
ﬁxed (n, k, d) varies with the ﬁle size M , making it more natural to consider instead
the normalized pairs (α/M , β/M ).3 In this case, we refer to the normalized exact
repair (ER) trade-off. In [34, TheoremIII.4], an upper bound on the normalized ER
trade-off is computed for every choice of parameters n, k, d. This upper bound can
be combined with the code construction proposed in [36] for k = 3 and d = n −1,
for any n, to fully characterize the normalized ER tradeoff for this set of parameters.
In the introduction, we discussed linear codes, but so far, nothing was mentioned
about whether codes are linear or not. This is because the properties of information
preservation, or that of data recovery, are independent of the regenerating code being
linear. However, linear codes are of course nicer than non-linear ones, because they
have been better studied, they come with easier encoding and decoding algorithms.
So one may wonder whether adding the constraint of linearity might help in under-
standing the normalized ER trade-off. In [5], a non-explicit upper bound is given
for the general ER trade-off case, which, when applied to the special case of linear
codes, gives an explicit upper bound for the ER linear trade-off problem, for any
parameter n, k, d. In [21], another upper bound is given for the ER linear codes case,
which turns out to be optimal for the parameters k = n −1, d = n −1 for any n, but
for the limited region where β/M ≤2α/Mk. For an improvement of this bound, as
well as comparisons between the different bounds discussed, we refer to [34].
3Since γ = dβ, we may consider the trade-off in terms of either (α, γ ) or (α, β).

372
S. Liu and F. Oggier
2.3
MSR and MBR Code Constructions
We next present two code constructions, one at MSR point, and one at MBR point.
Construction of MSR codes. This construction is actually illustrating how an MDS
code can be used for storage, in the setting of regenerating codes. Consider a ﬁle f
of length M = k with coefﬁcients in Fq, q a prime power. Set the parameters of the
regenerating code to be
d = k, n ≥k + 1, M = k.
Let G be a generator matrix of an (n, k) MDS code over Fq, say that of a Reed–
Solomon code, and denote by gi the ith column of G, i = 1, . . . , n, that is G =
[g1, . . . , gn]. By the MDS property, any k columns of G form an invertible matrix.
We denote the data ﬁle f by a k-dimensional row vector, f = (f1, . . . , fk). Suppose
the ith node store fgi, that is α = 1.
Recovery.Thedatacanberecoveredbycontactingnodes i1, . . . , ik.Theil-thnode
contains fgil, for l = 1, . . . , k, for a total of k coefﬁcients, by the MDS property, the
data ﬁle can be retrieved.
Repair phase. Suppose that the ith node has failed. A newcomer connects to
d = k live nodes say i1, . . . , id and downloads fgil for l = 1, . . . , d from each of the
nodes, thus β = 1. By the MDS property, the newcomer can compute f.
The total number of coefﬁcients involved in the repair is dβ = k, that is the repair
bandwidth is k, and the construction indeed achieves the MSR point, since
(αMSR, γMSR) =
M
k , M
k
d
d −k + 1

= (1, k).
Construction of MBR codes [39]. This time, consider a data ﬁle f of length M =
k(k + 1) with coefﬁcients in Fq. Set the parameters of the regenerating code to be
d = k, n = k + 1, M = k(k + 1).
The object f can be written as f = (f1, . . . , fk+1) where fi = (f(i−1)k, . . . , fik−1) has
length k, 1 ≤i ≤n = k + 1.
Let g1, . . . , gn−1 be n −1 = k independent column vectors of length k over Fq.
For i = 1, 2, . . . , n, the content of node i consists of the k coefﬁcients of fi, and
of the n −1 parity-check coefﬁcients
fi+1g1, . . . , fi+(n−1)gn−1,
computed from other groups fi+j, j = 1, . . . , n−1. Node i thus stores α = k+n−1 =
2k coefﬁcients of the form fi+jgj where i + j and j are understood modulo n.
Recovery. Suppose without loss of generality that a data collector connects to
nodes 1, . . . , k, and downloads f1, f1+kgk from node 1,…, fk, fk+1g1 from node k.
Thecoefﬁcientsoffk+1 canbecomputedfromfk+1·gk, . . . , fk+1·g1 sinceg1, . . . , gn−1
are linearly independent.

An Overview of Coding for Distributed Storage Systems
373
Repair process. Suppose that node j failed. The newcomer downloads fi ·gi+(n−j)
and fj · gj+(n−i) from node i, i = 1, . . . , n, i ̸= j. Thus the parity-check coefﬁcients
stored in node j can be recovered directly from fi · gi+(n−j) with i = 1, . . . , n, i ̸=
j, while fj is recovered from fj · gj+(n−i), using that the gj involved are linearly
independent. The total number of coefﬁcients involved in the repair is 2k, that is the
repair bandwidth is 2k = 2d, and the construction indeed achieves MBR point, since
(αMBR, γMBR) =
M
k
2d
2d −k + 1, M
k
2d
2d −k + 1

= (2k, 2k).
There have been many works containing code constructions for regenerating
codes, the above two examples were meant to give an illustration, and are in no
way representative of the richness of the literature on this topic. Maybe the most
complete reference is http://storagewiki.ece.utexas.edu/doku.php.
2.4
Security
Once constructions and fault tolerance of regenerating codes have been well studied,
it became natural to wonder about their performance in the presence of an adversary.
The security of storage systems using (collaborative) regenerating codes has been
considered, both against passive adversaries, or eavesdroppers, who can only read
the data but not modify it, and active, or Byzantine attackers, who on the contrary
are able to corrupt data.
The techniques used in the context of secure regenerating codes are similar to
those discussed in the previous section: an information ﬂow graph is considered,
this time taking into account the presence of an adversary, and a min-cut bound is
computed. We present next one such analysis [28], for the passive adversary case.
As before, a ﬁle f ∈FM
q is encoded into n pieces f1, . . . , fn, and each piece is stored
at a distinct node. We label the nodes such that the ith node xi stores fi, i = 1, . . . , n.
As in Theorem1, we represent the node xi by (xin
i , xout
i
), with an edge of capacity α
in between. Assume that nodes x1, . . . , xk have failed, and have been repaired by the
newcomers xn+1, . . . , xn+k. In the presence of a passive eavesdropper, data objects
are encrypted for ensuring their conﬁdentiality. We therefore distinguish the secure
ﬁle fs of size M s from its encrypted version, the ﬁle f of size M . Encoding is then
done on top of the encrypted ﬁle f.
Denote by fε the encoded data stored in nodes belonging to the set ε. An eaves-
dropper who can read up to l, l < k, nodes among all the n storage nodes, possibly
at different time instances as the system evolves, accesses the l input nodes in the set
ε1 = {xin
n+1, . . . , xin
n+l} while they were being repaired.
Theorem 4 Consider a secure object f of secure ﬁle size M s, i.e., M s = H(fs), the
entropy of fs. Suppose that over time, k nodes have failed and been repaired at nodes
xn+1, . . . , xn+k. An eavesdropper has accessed the set of nodes ε1 = {xin
n+1, . . . , xin
n+l}.

374
S. Liu and F. Oggier
Consider a data collector DC that collects data from the k output nodes ε =
{xout
n+1, . . . , xout
n+k}. We have
M s ≤
k

j=l+1
min{(d + i −1)β, α}.
Proof That fs remains conﬁdential despite the knowledge of fε1 is modeled by
H(fs|fε1) = H(fs). Thus
M s = H(fs) = H(fs|fε1)
= H(fs|fε1) −H(fs|fε)
(7)
= I(fs; fε\ε1|fε1)
(8)
≤H(fε\ε1|fε1)
(9)
=
k

i=l+1
H(fn+i|fn+1, . . . , fn+i−1)
(10)
≤
k

i=l+1
min{(d −i + 1)β, α}
(11)
where (7) holds since |ε| = k, which is enough to retrieve f by deﬁnition of k.
Then since mutual information satisﬁes I(X ; Y|Z) = H(X |Z) −H(X |Y, Z), (8)
follows. Alternatively, I(X ; Y|Z) = H(X , Z) −H(Z) −H(X , Y, Z) + H(Y, Z) =
H(X , Z) −H(X , Y, Z) + H(Y|Z) ≤H(Y|Z), from which (9) is derived, and the
Chain rule for entropy H(X1, . . . , Xn|Y) = n
i=1 H(Xi|X1, . . . , Xi−1, Y) implies
(10). Finally, each node has a storage capacity of α, for each repair node H(fi) ≤dβ,
and from the proof of Theorem1, the repair node xin
n+i downloads β symbols from
each output node xout
n+1, . . . , xout
n+i−1, yielding (11).
Corollary 1 At the minimum storage repair point (MSR), the secure ﬁle size M s is
upper bounded by
M s ≤(k −l)α.
Corollary 2 At the minimum repair bandwidth point (MBR) with d = n −1, the
secure ﬁle size M s is upper bounded by
M s ≤
k

i=l+1
(n −i)β.
The above analysis was extended to the collaborative case [22], in particular
in the presence of rogue nodes which voluntarily corrupt the data that they transmit
during repair. It was shown that the repair bandwidth obtained to secure (information
theoretically) collaborative regenerating codes from Byzantine attacks is worse than

An Overview of Coding for Distributed Storage Systems
375
having no collaboration at all. This is a rational drawback of collaboration, since a
single corrupted node can pollute all other honest nodes involved in the repair.
In [37], Shah et al. gave a bound on the secure ﬁle size considering a passive
eavesdropper model that generalizes the model in [28], in that the eavesdropper can
access not only the stored data in nodes that have been repaired, l1 of them from a set
ε1, but also the data which is downloaded during the repair of l2 nodes from the set
ε2. This makes a difference, since more data may be in transit in nodes being repaired
than what will actually be stored. Code constructions of secure codes are given both
at MBR and MSR points. Rawat et al. [31] tightened the bound given in [37] at MSR
point, and also provided secure MSR codes for d = n −1. Finally, Koyluoglu et al.
[15] extended the bound in [31] to collaborative regenerating codes. A bound is also
available for partial collaboration [20].
Theorem 5 ([15, 20]) Consider a secure object f of secure ﬁle size M s, i.e., M s =
H(fs). Consider an eavesdropper who has access to the set of nodes ε1, ε2, |ε1| = l1,
|ε2| = l2, then
H(fs) ≤

j∈R
H(fj|fn+1, . . . , fj−1, fε1, dε2),
with R = {n + 1, . . . , n + k}\(ε1 ∪ε2), and dε2 denotes the downloaded data in the
set of nodes ε2.
As a consequence of the above min-cut bound, we obtain bounds on the secure
ﬁle size:
Proposition 2 ([15, Propositions5 and 9]) For a collaborative regenerating code at
the minimum repair bandwidth point (MBR), with β = 2β′, α = γ = (2d +t −1)β′,
and ﬁle size M = k(2d −k + t)β′, the secure ﬁle size M s is upper bounded by
M s ≤(k −l1)(2d + t −k −l1)β
2 .
(12)
At the minimum storage repair point (MSR), with by β = β′, α = (d −k + t)β
for a ﬁle of size M = k(d −k + t)β, the secure ﬁle size M s is upper bounded by
M s ≤
k−l1−l2

i=1
(α −I(fi; di,ε2)).
(13)
If I(fi; di,ε2) ≥β′ = β, then (13) becomes
M s ≤(k −l1 −l2)(α −β).
(14)
The generalization of the above two bounds for the partial collaborative case
is found in [20]. Code constructions, when available, are found in the respective
aforementioned papers. See also e.g. [3, 8, 29].

376
S. Liu and F. Oggier
3
Locally Repairable Codes
In the last section, we saw how regenerating codes minimize repair bandwidth by
contacting a large number of live nodes (preferably all the n −1 live nodes in the
case of one failure). One may argue that getting answers from all these nodes in
time to ensure an efﬁcient repair may not be easy: other nodes may just be busy
reading, writing, or managing their data. Locally repairable codes somehow stand in
an opposite corner of the code design spectrum, by focusing on reducing the number
d of live nodes to be contacted per repair. For a repetition code, d = 1 is achieved.
For other codes, we need at least d ≥2.
The idea that repair efﬁciency improves when a small number of nodes is con-
tacted appears in the construction of Pyramid codes [10]. Pyramid codes contain
information symbols, followed by redundancy symbols, and distinguish local and
global redundancy symbols, the local ones being those which are computed using
a small number of information symbols, while the global ones possibly need all
the information symbols to be computed. This can be achieved by taking a Reed–
Solomon code, then shortening it, and ﬁnally by adding some new symbols obtained
by encoding information symbols, part of them set to zero, e.g., to add two local sym-
bols, set the ﬁrst half and the second half respectively of the information symbols to
zero. For example, suppose a ﬁle f = (f1, . . . , f6) is encoded using a Reed–Solomon
code. Retain two parity symbols p1, p2 from it, then set f1 = f2 = f3 = 0 and obtain a
new Reed–Solomon codeword from which a parity p3 is kept, then alternate and set
f4 = f5 = f6 = 0 and keep a parity p4 from its Reed–Solomon codeword. This yields
a ﬁnal codeword (f1, . . . , f6, p1, p2, p3, p4) where p1, p2 are the global redundancy
symbols, and p3, p4 are the local ones. The motivation for this is to handle degraded
read, or how to read data when some of the symbols are missing. One solution is to
quickly compute the missing symbols of the data to be read using the local redun-
dancy symbols. This in turn implies that the local nodes can be repaired by contacting
a small number of live nodes. Local Reconstruction Codes form a class of codes for
distributed storage systems which optimize Pyramid codes, proposed by the same
research group, and which have been incorporated in Windows Azure [11].
In [24], minimizing the repair degree, that is the number of live nodes to be
contacted per repair, was proposed as a code design criterion, and self-repairing codes
were designed, which mimic the encoding of Reed–Solomon codes via polynomial
evaluation, but using linearized polynomials. A linearized polynomial p(X ) ∈Fq[X ]
satisﬁes that p(w + w′) = p(w) + p(w′) for w, w′ ∈Fq.
To be consistent with the existing literature, we will use in the following the
notation d for the minimum distance of a code, and k for its dimension (while d
was the repair degree, and k the number of nodes contacted to retrieve an object, for
regenerating codes).

An Overview of Coding for Distributed Storage Systems
377
3.1
A Singleton-Type Bound on Locality
In [7], the notion of locality was introduced. The ith coordinate of a codeword is
said to have locality r, if its value is determined by at most r other coordinates.
Codes that have a minimum Hamming distance of d but also have the property that
any information coordinate has locality r or less were proposed, and the following
Singleton-type bound was given. We state and prove it for linear codes, even though
it is known to hold for non-linear codes4 [6].
Theorem 6 Let C be an [n, k] linear code, that is a code of length n and dimension
k, with minimum distance d and locality r. Then
n −k + 1 −d ≥⌊k −1
r
⌋.
(15)
Proof [16] Let G be the generator matrix of C, and for a codeword in C, each of
its coefﬁcients is stored by a distinct node. Choose any ⌊k−1
r ⌋nodes, call these the
“leaders”. Each leader can be written as a linear combination of at most r other nodes,
call this set the “set of friends of the leader”. Now deﬁne N as the set of nodes which
is the union of all sets of friends of the leaders (at most r⌊k−1
r ⌋of them) but without
the leaders themselves. Then clearly N has at most r⌊k−1
r ⌋elements, thus less than k
elements so that the set of columns in G that corresponds to N spans a space of rank
< k. Since G has full rank it is possible to enlarge N to a set N of more than k −1
columns such that the rank of its corresponding columns equals exactly k −1. Note
that because the code has locality r, this enlargement operation can be done without
involving any of the leaders. Now deﬁne U as the union of N ′ and the set of leaders.
Then U has at least k −1 + ⌊k−1
r ⌋nodes but still, because the code has locality r,
the corresponding columns in G span a space of dimension < k. By deﬁnition of the
minimum distance, all (k × ·)-submatrices of G that have rank < k must have less
than n −d columns. It therefore follows that k −1 + ⌊k−1
r ⌋≤n −d, which proves
the theorem.
The bound (15) has been shown to be tight [7] over a large enough ﬁnite ﬁeld.
The term locally repairable code (LRC) was coined in [27] to refer to codes with
a prescribed repair degree, or locality. The term is reminiscent of the theoretical
computer science terminology “locally decodable” or “locally correctable” codes.
Describing possible technical connections among these families of codes is beyond
the scope of this survey.
By now, a locally repairable (or locally recoverable) code is a linear [n, k, r] code
that encode k information symbols into a codeword of length n, with the property
that for any symbol of the codeword, there exist at most r other symbols such that the
value of the symbol can be recovered from them. Then r is called the repair locality.
4In fact, we will not discuss non-linear codes, even though some works have been done on this
topic.

378
S. Liu and F. Oggier
For LRC codes, if a symbol is lost due to a node failure, its value can be recovered
by contacting at most r other nodes.
MDS codes are actually LRC codes, with locality r = k. MDS codes can recover
the largest possible number of erased symbols among all [n, k] codes, since their
Hamming distance is n −k + 1. Thus (15) for MDS codes becomes
n −k + 1 −(n −k + 1) ≥⌊k −1
k
⌋
and the bound is tight, even though r is high. An [n, k, r] LRC code that achieves the
bound (15) with equality is called an optimal LRC code. Pyramid codes are known
to yield LRC codes [7] whose information symbols have optimal repair locality. In
[31, 41], rank-metric codes are used to construct optimal LRCs, while [45] gave a
construction based on Reed–Solomon codes that is optimal for any 1 < r < k.
3.2
Code Constructions
We repeat the disclaimer used for regenerating codes: the literature on locally
repairable codes is vast, and we do not pretend to provide an exhaustive list of
constructions. Since MDS codes are optimal with repair locality r = k, we choose
to present a construction from [30], which uses generalized Reed–Muller codes, and
achieves r = 2 and r = 3.
LRC codes with locality 2. Let q be a prime. Consider an object f = (f1, . . . ,
fM ) ∈FM
q of length M = m, and the multivariate polynomial g in Fq[X1, . . . , Xm]
of degree 1 given by
g(X1, . . . , Xm) =
m

i=1
fiXi.
A codeword is obtained by evaluating g in the points
ai, ai + t((q −1)ai + aj) ∈Fm
q ,
for i = 1, . . . , N, 1 ≤i < j ≤N, 2 ≤t ≤1 + L, where N and L are designed
parameters. Each codeword coefﬁcient is stored in one node. Set h = (q −1)ai + aj,
then the polynomial is evaluated in the points
ai, aj, ai + th.
Since t goes from 2 to L + 1, and with ai, aj, there are L + 2 points on a line, that is
ai, ai + h, . . . , ai + (L + 1)h.

An Overview of Coding for Distributed Storage Systems
379
Suppose the node storing ai fails, the repair can be realized by contacting two other
nodes storing the values corresponding to two points on the same line, say the nodes
containing g(ai + t1h), g(ai + t2h) for L ≥1, t1 ̸= t2. Consider g as a polynomial
in t, then g has degree 1 in t, so by polynomial interpolation, the two values g(ai +
t1h), g(ai + t2h) are enough to compute g(ai + th), and evaluating it in t = 0 yields
back g(ai). This shows that this code has repair locality r = 2.
LRC codes with locality 3. Similarly, consider a ﬁle f = (f1, . . . , fM ) ∈FM
q of
length M =
m+2
m

, and the polynomial g in Fq[X1, . . . , Xm] of degree 2 given by
g(X1, . . . , Xm) =

i∈M
fiX αi,1
1
· · · X αi,m
m
,
where M is the index set for monomials in Fq[X1, . . . , Xm] of degree at most 2
arranged in lexical order. A codeword is obtained by evaluating g in the points
2ai, ai + aj, 2ai + t((q −1)ai + aj) ∈Fm
q ,
for i = 1, . . . , N, 1 ≤i < j ≤N, 3 ≤t ≤2 + L, where N and L are designed
parameters. Each coefﬁcient in the codeword is stored in one node. Again, set h =
(q −1)ai + aj, then the polynomial is evaluated in
2ai, ai + aj, 2aj, 2ai + th.
Since t goes from 3 to L + 2, and with 2ai, ai + aj, 2aj, there are L + 3 points on a
line, that is
2ai, 2ai + h, 2ai + 2h, . . . , ai + (L + 2)h.
Suppose the node storing 2ai fails, the repair can be realized by contacting three other
nodes storing the values corresponding to three points on the same line, say the nodes
containing g(2ai +t1h), g(2ai +t2h), g(2ai +t3h) for L ≥1, t1 ̸= t2 ̸= t3. Consider
again g as a polynomial in t, which this time has degree at most 2. By polynomial
interpolation, three values are enough to reconstruct the polynomial g(2ai +th), and
g(ai) is obtained by setting t = 0. This shows a repair locality of r = 3.
We note three directions that have been pursued in the design of LRC codes:
• To get practical codes, it is often desirable to have a small alphabet Fq, preferably in
characteristic 2. In [1], integrated interleaved codes have been studied and showed
to be good candidates to obtain LRC codes over F2b, for small values of b. In [44],
cyclic codes and subﬁeld subcodes of cyclic codes are considered as LRC codes,
where their minimum distance and locality are derived. In particular, the binary
case is treated.
• Suppose that one may want different codeword symbols to have different locality.
Bounds and constructions, optimal with respect to these bounds, for LRC codes
with different localities have been considered in [13, 49].

380
S. Liu and F. Oggier
• The security model presented in Sect.2.4 for regenerating codes has also been
considered for LRCs in [31]. Under the same eavesdropper threat, bounds on the
secure ﬁle size were computed. For a reference on Byzantine attacks for LRCs,
see e.g. [42].
3.3
LRC Codes with Multiple Recovering Sets
We have seen above that LRC codes have the local repair property that each symbol
can be recovered using at most r other symbols, so a natural question is whether
this set of at most r symbols, called recovering set is unique. When each symbol
has several recovering sets, then we may ask whether these sets are disjoint. These
questions are important for the health of the distributed storage system. If the node
that fails has a unique recovering set, and some other failures affect this set, then
the recovery set cannot be used, and local repair becomes impossible. Therefore it
is important to understand the structure of recovering sets.
As an illustration, consider the code constructions of the last subsection with
parameters L = 1 and N = 3. For the construction with locality 3, the evaluating
points of the polynomial g are
2a1, 2a2, 2a3,
a1 + a2, a1 + a3, a2 + a3,
a2 −a1, a3 −a1, a3 −a2,
and the points 2a1, a1 + a2, 2a2, a2 −a1 are actually on the same line. We similarly
list the points on the same line:
L1 : 2a1, a1 + a2, 2a2, a2 −a1,
L2 : 2a1, a1 + a3, 2a3, a3 −a1,
L3 : 2a2, a2 + a3, 2a3, a3 −a2.
Suppose a node stores g(2a1). Since there are two lines L1, L2 containing 2a1, the
symbol g(2a1) has two recovering sets, a1+a2, 2a2, a2−a1 and a1+a3, 2a3, a3−a1,
and they do not intersect. This is also true for the points 2a2 and 2a3. However, for
other points, they only have one recovering set.
In [26, 45], LRC codes with disjoint recovering sets are proposed. Tamo and Barg
[45] gave two methods to construct LRC codes with multiple recovering sets. One
use the concept of orthogonal partition, the second combines several LRC codes into
a longer multiple recovering code. In [47], codes providing δ −1 non-overlapping
local repair groups of size no more than r per coordinate were introduced. In [32],
recovering sets are studied using the concept of (r, t)-availability: a code symbol is
said to have (r, t)-availability if it can be rebuilt from t disjoint recovering sets, each
of size at most r.

An Overview of Coding for Distributed Storage Systems
381
4
Concluding Remarks
This chapter surveyed two main families of codes for distributed storage systems.
While we have already mentioned that the references in terms of code constructions
are far from exhaustive, we would like to conclude by also listing aspects of the topic
which have not been considered.
• Other design criteria, for codes to provide efﬁcient data insertion (e.g. [25]), data
update (e.g. [43]), or versioning (e.g. [9]), have not been covered.
• The view point of code design the way it was presented is looking at one snapshot
of the network, it is oblivious of the actual system, and does not take into account
the fact that a node actually stores many objects (e.g. [2]), which means that
data allocation, or management of metainformation is important. There have been
works looking at systems aspects and implementation of these codes (e.g. [17])
which we did not discuss either.
• Regarding security aspects, we only described information theoretical approaches,
while there are many works discussing cryptographic or system approaches to
secure code based distributed storage systems.
• Finally, there is a vast body of work coming from the storage systems and dis-
tributed systems community. They started discussing coding for distributed storage
systems before the information and coding community did (e.g. [18, 48]), and they
also have proposed many interesting code designs, often motivated by considera-
tions closer to working systems.
Acknowledgements This work is supported by the MoE Tier-2 grant eCODE: Erasure Codes for
Datacenter Environments.
References
1. M. Blaum, S.R. Hetzler, Integrated interleaved codes as locally recoverable codes: properties
and performance. Int. J. Inf. Coding Theory 3(4), 324 (2016)
2. A. Datta, L. Pamies-Juarez, F. Oggier, A study of the performance of novel storage-centric
repairable codes. Springer Comput. 98(3) (2015)
3. T.K. Dikaliotis, A.G. Dimakis, T. Ho, Security in distributed storage systems by communicating
a logarithmic number of bits, in Proceedings of the 2010 IEEE International Symposium on
Information Theory (ISIT) (2010), pp. 1948–1952
4. A.G. Dimakis, P.B. Godfrey, Y. Wu, M.J. Wainwright, K. Ramchandran, Network coding for
distributed storage systems. IEEE Trans. Inf. Theory 56(9) (2010)
5. I.M. Duursma, Shortened regenerating codes. CoRR (2015), arXiv:1505.00178
6. M. Forbes, S. Yekhanin, On the locality of codeword symbols in non-linear codes. Discret.
Math. 324, 78–84 (2014)
7. P. Gopalan, C. Huang, H. Simitci, S. Yekhanin, On the locality of codeword symbols. IEEE
Trans. Inf. Theory 58(11), 6925–6934 (2011)
8. Y.S. Han, R. Zheng, W.H. Mow, Exact regenerating codes for Byzantine fault tolerance in
distributed storage, in Proceedings of IEEE INFOCOM (2012), pp. 2498–2506
9. J. Harshan, F. Oggier, A. Datta, Sparsity exploiting erasure coding for distributed storage of
versioned data. Springer Comput. (2016)

382
S. Liu and F. Oggier
10. C. Huang, M, Chen, J. Li, Pyramid codes: ﬂexible schemes to trade space for access efﬁciency
in reliable data storage systems, in Sixth IEEE International Symposium on Network Computing
and Applications, July 2007, pp. 79–86
11. C. Huang, H. Simitci, Y. Xu, A. Ogus, B. Calder, P. Gopalan, J. Lin, S. Yekhanin, Erasure
coding in windows Azure storage, in 2012 USENIX Annual Technical Conference, 12–15 June
2012
12. K.A.S. Immink, Codes for Mass Data Storage Systems, Second fully revised edition (Shannon
Foundation Publishers, Eindhoven, 2004), http://www.turing-machines.com/pdf/codes_for_
mass_data2.pdf. ISBN 90-74249-27-2
13. S. Kadhe, A. Sprintson, Codes with unequal locality, in IEEE International Symposium on
Information Theory (ISIT) (2016), pp. 435–439
14. A.-M. Kermarrec, N. Le Scouarnec, G. Straub, Repairing multiple failures with coordinated
and adaptive regenerating codes, in The 2011 International Symposium on Network Coding
(NetCod 2011)
15. O.O. Koyluoglu, A.S. Rawat, S. Vishwanath, Secure cooperative regenerating codes for dis-
tributed storage systems. IEEE Trans. Inf. Theory 60(9), 5228–5244 (2014), arXiv:1210.3664
16. M. Kuijper, D. Napp, Erasure codes with simplex locality, in 21st International Symposium on
Mathematical Theory of Networks and Systems, Groningen, The Netherlands (2014)
17. M. Li, P.P.C. Lee, STAIR codes: a general family of erasure codes for tolerating device and
sector failures in practical storage systems, in Proceedings of the 12th USENIX Conference on
File and Storage Technologies (FAST’14), Santa Clara, CA (2014)
18. W.K. Lin, D.M. Chiu, Y.B. Lee, Erasure code replication revisited, P2P 2004
19. S. Liu, F. Oggier, On storage codes allowing partially collaborative repairs, in IEEE Interna-
tional Symposium on Information Theory (ISIT) 2014, pp. 2440–2444
20. S. Liu, F. Oggier, Partially collaborative storage codes in the presence of an eavesdropper. Int.
J. Inf. Coding Theory 3(3), 177–196 (2016)
21. S. Mohajer, R. Tandon, New bounds on the (n, k, d) storage systems with exact repair, in IEEE
International Symposium on Information Theory, ISIT 2015, Hong Kong, China, 14–19 June
2015, pp. 2056–2060
22. F. Oggier, A. Datta, Byzantine fault tolerance of regenerating codes, in The 11th IEEE Inter-
national Conference on Peer-to-Peer Computing (P2P 2011), Kyoto, arXiv:1106.2275
23. F. Oggier, A. Datta, Coding techniques for repairability in networked distributed storage sys-
tems, Foundations and Trends in Communications and Information Theory (Now Publishers,
Breda, 2013)
24. F. Oggier, A. Datta, Self-repairing homomorphic codes for distributed storage systems, INFO-
COM 2011
25. L.Pamies-Juarez,A.Datta,F.Oggier,RapidRAID:pipelinederasurecodesforfastdataarchival
in distributed storage systems, arXiv:1207.6744
26. L. Pamies-Juarez, H.D.L. Hollmann, F. Oggier, Locally repairable codes with multiple repair
alternatives, in IEEE International Symposium on Information Theory (ISIT) (2013), pp. 892–
896
27. D.S.Papailiopoulos,A.G.Dimakis,Locallyrepairablecodes,inIEEEInternationalSymposium
on Information Theory (ISIT) (2012), arXiv:1206.3804
28. S. Pawar, S. El Rouayheb, K. Ramchandran, Securing dynamic distributed storage systems
against eavesdropping and adversarial attacks. IEEE Trans. Inf. Theory (Spec. Issue Facet.
Coding Theory Algorithm Netw.) 57(9) (2011)
29. K.V. Rashmi, N.B. Shah, K. Ramchandran, P.V. Kumar, Regenerating codes for errors and
erasures in distributed storage, in Proceedings of the 2012 IEEE International Symposium on
Information Theory (ISIT) (2012), pp. 1202–1206
30. A.S. Rawat, S. Vishwanath, On locality in distributed storage systems, in IEEE Information
Theory Workshop (ITW) (2012), pp. 497–501
31. A.S. Rawat, O.O. Koyluoglu, N. Silberstein, S. Vishwanath, Optimal locally repairable and
secure codes for distributed storage systems. IEEE Trans. Inf. Theory 60(1), 212–236 (2014)

An Overview of Coding for Distributed Storage Systems
383
32. A.S. Rawat, D.S. Papailiopoulos, A.G. Dimakis, S. Vishwanath, Locality and availability in
distributed storage. IEEE Trans. Inf. Theory 62(8), 4481–4493 (2016)
33. I. Reed, G. Solomon, Polynomial codes over certain ﬁnite ﬁelds. J. Soc. Ind. Appl. Math. 8,
300–304 (1960)
34. B. Sasidharan, N. Prakash, M.N. Krishnan, M. Vajha, K. Senthoor, P.V. Kumar, Outer bounds
on the storage-repair bandwidth tradeoff of exact-repair regenerating codes. Int. J. Inf. Coding
Theory 3(4), 255–298 (2016)
35. B. Sasidharan, K. Senthoor, P.V. Kumar, An improved outer bound on the storage repair-
bandwidth tradeoff of exact-repair regenerating codes, in IEEE International Symposium on
Information Theory, ISIT 2014, pp. 2430–2434
36. K. Senthoor, B. Sasidharan, P.V. Kumar, Improved layered regenerating codes characterizing
the exact-repair storage-repair bandwidth tradeoff for certain parameter sets, in 2015 IEEE
Information Theory Workshop, ITW 2015, Jerusalem, Israel, 26 April–1 May 2015, p. 15
37. N.B. Shah, K.V. Rashmi, P.V. Kumar, Information theoretically secure regenerating codes for
distributed storage, in Proceedings of IEEE Globecom (2011)
38. K.W. Shum, Cooperative regenerating codes for distributed storage systems, in The Interna-
tional Conference on Communications (ICC 2011), Kyoto, arXiv:1101.5257
39. K.W. Shum, Y. Hu, Exact minimum-repair-bandwidth cooperative regenerating codes for dis-
tributed storage systems, in The International Symposium on Information Theory (ISIT 2011),
Saint-Petersburg
40. K.W. Shum, Y. Hu, Cooperative regenerating codes. IEEE Trans. Inf. Theory 59(11), 7229–
7258 (2013)
41. N. Silberstein, A.S. Rawat, O.O. Koyluoglu, S. Vishwanath, Optimal locally repairable codes
via rank-metric codes, in IEEE International Symposium on Information Theory (ISIT) (2013)
42. N. Silberstein, A.S. Rawat, S. Vishwanath, Error-correcting regenerating and locally repairable
codes via rank-metric codes. IEEE Trans. Inf. Theory 61(11), 5765–5778 (2015)
43. A. Singh Rawat, S. Vishwanat, A. Bhowmick, E. Soljanin, Update efﬁcient codes for distributed
storage, in IEEE International Symposium on Information Theory (ISIT) (2011)
44. I. Tamo, A. Barg, S. Goparaju, R. Calderbank, Cyclic LRC codes, binary LRC codes, and upper
bounds on the distance of cyclic clodes. Int. J. Inf. Coding Theory 3(4), 32 (2016)
45. I. Tamo, A. Barg, A family of optimal locally recoverable codes. IEEE Trans. Inf. Theory
60(8), 4661–4676 (2014)
46. C. Tian, Characterizing the rate region of the (4,3,3) exact-repair regenerating codes. IEEE J.
Sel. Areas Commun. 32(5), 967–975 (2014)
47. A. Wang, Z. Zhang, Repair locality with multiple erasure tolerance. IEEE Trans. Inf. Theory
60(11), 6979–6987 (2014)
48. H. Weatherspoon, J. Kubiatowicz, Erasure coding vs replication: a quantitative comparison,
Peer-to-Peer Systems, LNCS (2002)
49. A. Zeh, E. Yaakobi, Bound and constructions of codes with multiple localities, in IEEE Inter-
national Symposium on Information Theory (ISIT) (2016), pp. 641–644

Matroid Theory and Storage Codes: Bounds
and Constructions
Ragnar Freij-Hollanti, Camilla Hollanti and Thomas Westerbäck
Abstract Recent research on distributed storage systems (DSSs) has revealed inter-
esting connections between matroid theory and locally repairable codes (LRCs). The
goal of this chapter is to introduce the reader to matroids and polymatroids, and illus-
trate their relation to distributed storage systems. While many of the results are rather
technical in nature, effort is made to increase accessibility via simple examples. The
chapter embeds all the essential features of LRCs, namely locality, availability, and
hierarchy alongside with related generalised Singleton bounds.
1
Introduction to Locally Repairable Codes
In this chapter, we will discuss the theoretical foundations of locally repairable codes
(LRCs), which were introduced in chapter“An Overview of Coding for Distributed
Storage Systems”. While our main interest is in the codes and their applicability for
distributed storage systems, signiﬁcant parts of our machinery comes from matroid
theory. We will develop this theory to the extent that is needed for the applications,
and leave some additional pointers to interpretations in terms of graphs and projective
geometries.
The need for large-scale data storage is continuously increasing. Within the
past few years, distributed storage systems (DSSs) have revolutionised our tradi-
The authors gratefully acknowledge the ﬁnancial support from the Academy of Finland (grants
#276031 and #303819), as well as the support from the COST Action IC1104.
R. Freij-Hollanti (B) · C. Hollanti · T. Westerbäck
Department of Mathematics and Systems Analysis, Aalto University,
P.O. Box 11100, 00076 Aalto, Finland
e-mail: ragnar.freij@aalto.ﬁ
C. Hollanti
e-mail: camilla.hollanti@aalto.ﬁ
T. Westerbäck
e-mail: thomas.westerback@aalto.ﬁ
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_15
385

386
R. Freij-Hollanti et al.
tional ways of storing, securing, and accessing data. Storage node failure is a fre-
quent obstacle in large-scale DSSs, making repair efﬁciency an important objective.
A bottle-neck for repair efﬁciency, measured by the notion of locality [27], is the
number of contacted nodes needed for repair. The key objects of study in this paper
are locally repairable codes (LRCs), which are, informally speaking, storage systems
where a small number of failing nodes can be recovered by boundedly many other
(close-by) nodes. Repair-efﬁcient LRCs are already in use for large-scale DSSs used
by, for example, Facebook and Windows Azure Storage [40].
Another desired attribute, measured by the notion of availability [31], is the
property of having multiple alternative ways to repair nodes or access ﬁles. This
is particularly relevant for nodes containing so-called hot data that is frequently and
simultaneously accessed by many users. Moreover, as failures are often spatially
correlated, it is valuable to have each node repairable at several different scales. This
means that if a node fails simultaneously with the set of nodes that should normally
be used for repairing it, then there still exists a larger set of helper nodes that can
be used to recover the lost data. This property is captured by the notion of hierarchy
[10, 32] in the storage system.
Network coding techniques for large-scale DSSs were considered in [7]. Since
then,aplethoraofresearchonDSSswithafocusonlinearLRCsandvariouslocalities
has been carried out, see [13, 27, 30, 34, 39] among many others. Availability for
linear LRCs was deﬁned in [31]. The notion of hierarchical locality was ﬁrst studied
in [32], where bounds for the global minimum distance were also obtained.
Let us denote by (n, k, d,r, δ, t), respectively, the code length, dimension, global
minimum distance, locality, local minimum distance, and availability. Bold-faced
parameters (n, k, d, t) will be used in the sequel to refer to hierarchical locality
and availability. It was shown in [40] that the (r, δ = 2)-locality of a linear LRC
is a matroid invariant. The connection between matroid theory and linear LRCs
was examined in more detail in [47]. In addition, the parameters (n, k, d,r, δ) for
linear LRCs were generalised to matroids, and new results for both matroids and
linear LRCs were given therein. Even more generally, the parameters (n, k, d,r, δ, t)
were generalised to polymatroids, and new results for polymatroids, matroids and
both linear and nonlinear LRCs over arbitrary ﬁnite alphabets were derived in [46].
Similar methods can be used to bound parameters of batch codes [49], as discussed in
chapter“Batch and PIR Codes and Their Connections to Locally Repairable Codes”.
For more background on batch codes, see e.g. [16, 23]. Moreover, as certain speciﬁc
LRCs and batch codes1 belong to the class of private information retrieval (PIR)
codes as deﬁned in [9, Deﬁnition 4], the related LRC and batch code bounds also
hold for those PIR codes. See Sect.5.3 and chapter“Batch and PIR Codes and Their
Connections to Locally Repairable Codes” for more discussion.
The main purpose of this chapter is to give an overview of the connection between
matroid theory and linear LRCs with availability and hierarchy, using examples for
improved clarity of the technical results. In particular, we are focusing on how the
1To this end, we need to make speciﬁc assumptions on the locality and availability of the LRC [9,
Theorem 21], which also implies restrictions on the query structure of the batch code.

Matroid Theory and Storage Codes: Bounds and Constructions
387
parameters of a LRC can be analysed using the lattice of cyclic ﬂats of an associated
matroid, and on a construction derived from matroid theory that provides us with
linear LRCs. The matroidal results on LRCs reviewed here are mostly taken from
[10, 46, 47].
The rest of this chapter is organised as follows. In Sects.1.1 and 1.2, we introduce
distributed storage systems and how they can be constructed by using linear codes.
In particular, we consider locally repairable codes with availability. Section2 gives a
brief introduction to the concepts and features related to matroids relevant to LRCs. In
Sect.3, we summarise the state-of-the-art generalised Singleton bounds on the code
parameters for linear codes, as well as discuss existence of Singleton-optimal linear
codes and matroids. Section4 reviews some explicit (linear) code constructions. In
Sect.5, we go beyond linear codes and consider polymatroids and related generalised
Singleton bounds, which are then valid for all LRCs over any ﬁnite alphabet, and
also imply bounds for PIR codes when restricted to systematic linear codes. Section6
concludes the chapter and discusses some open problems. Further results in matroid
theory and especially their representability are given in appendix for the interested
reader. The following notation will be used throughout the paper:
F
: a ﬁeld;
Fq
: the ﬁnite ﬁeld of prime power size q;
E
: a ﬁnite set;
G
: a matrix over F with columns indexed by E;
G(X)
: the matrix obtained from G by restricting to the columns
indexed by X, where X ⊆E;
C(G)
: the vector space generated by the columns of G;
R(G)
: the vector space generated by the rows of G;
C
: linear code C = R(G) over F generated by G;
CX
: the punctured code of C on X, i.e., CX = R(G(X)), where
X ⊆E;
2E
: the collection of all subsets of a ﬁnite set E;
[ j]
: the set {1, 2, . . . , j} for a positive integer j;
n, k, d,r, δ, t, h
: code length, dimension, minimum distance, locality, failure
tolerance, availability, hierarchy, respectively;
[n, k, d] , (n, k, d)
: parameters of a linear/general code, respectively;
(n, k, . . .)i
: parameter values when we consider information symbols, e.g.,
information symbol locality;
(n, k, . . .)a
: parameter values when we consider all code symbols, e.g., all
symbol locality;
(n, k, . . .)s
: parameter values when we consider systematic code symbols,
e.g., systematic symbol locality;
(n, k, d, t)
: parameter values for different hierarchy levels.
Remark 1 Here, d denotes the minimum (Hamming) distance of the code, rather
than the number of nodes that have to be contacted for repair, as is commonplace in

388
R. Freij-Hollanti et al.
the theory of regenerating codes. In chapter“An Overview of Coding for Distributed
Storage Systems”, the minimum distance of the code was denoted by dH.
The motivation to study punctured codes arises from hierarchical locality; the
locality parameters at the different hierarchy levels correspond to the global param-
eters of the related punctured codes. The puncturing operation on codes corresponds
to the so-called restriction (or deletion) operation on matroids.
We also point out that G(E) = G and CE = C. We will often index a matrix G
by [n], where n is the number of columns in G.
1.1
Distributed Storage Systems from Linear Codes
A linear code C can be used to obtain a DSS, where every coordinate in C represents
a storage node in the DSS, and every point in C represents a stored data item. While
one often assumes that the data items are ﬁeld elements in their own right, no such
assumption is necessary. However, if C is a code over the ﬁeld F and the data items
are elements in an alphabet A, then we must be able to form the linear combinations
f1a1 + f2a2 for f1, f2 in F and a1, a2 in A. Moreover, if we know the scalar f , we
must be able to read off a from f a. This is achieved if A ∼= Fα is a vector space over
F, wherefore we must have |A| ≥|F|. Thus, the length of the data items must be at
least the number of symbols needed to represent a ﬁeld element. In particular if the
data items are measured in, e.g., kilobytes, then we are restricted to work over ﬁelds
of size not larger than about 28000. Beside this strict upper bound on the ﬁeld size, the
complexity of operations also makes small ﬁeld sizes — ideally even binary ﬁelds
— naturally desirable.
Example 1 Let C be the linear code generated by the following matrix G over F3:
G =
1 2 3 4 5 6 7 8 9
1 0 0 0 1 1 1 1 1
0 1 0 0 1 0 1 2 2
0 0 1 0 0 1 1 0 0
0 0 0 1 0 0 0 1 2
Then, C corresponds to a 9 node storage system, storing four ﬁles (a, b, c, d), each
of which is an element in Fα
3. In this system, node 1 stores a, node 5 stores a + b,
node 9 stores a + 2b + 2d, and so on.
Two very basic properties of any DSS are that every node can be repaired by some
other nodes and that every node contains some information.2 We therefore give the
following deﬁnition.
2We remark that if one takes into account queueing theoretic aspects, then data allocation may
become less trivial (some nodes may be empty). Such aspects are discussed, especially in a wireless
setting, in chapters“Opportunistic Network Coding” and “Coded Random Access”. However, these
considerations are out of the scope of this chapter.

Matroid Theory and Storage Codes: Bounds and Constructions
389
Deﬁnition 1 A linear [n, k, d]-code C over a ﬁeld is a non-degenerate storage code
if d ≥2 and there is no zero column in a generator matrix of C.
The ﬁrst example of a storage code, and the motivating example behind the notion
of locality, is the notion of a maximum distance separable (MDS) code. It has several
different deﬁnitions in the literature, here we list a few of them.
Deﬁnition 2 The following properties are equivalent for linear [n, k, d] storage
codes:
(i) n = k + d −1.
(ii) The stored data can be retrieved from any k nodes in the storage system.
(iii) To repair any single erased node in the storage system, one needs to contact k
other nodes.
A code that satisﬁes one (and therefore all) of the above properties is called an M DS
code.
By the Singleton bound, n ≥k + d −1 holds for any storage code, so by property
(i), MDS codes are “optimal” in the sense that they have minimal length for given
storage capacity and error tolerance. However, (iii) is clearly an unfavourable prop-
erty in terms of erasure correction. This is the motivation behind constructing codes
with small n −k −d, where individual node failures can still be corrected “locally”.
1.2
Linear Locally Repairable Codes with Availability
The very broad class of linear LRCs will be deﬁned next. It is worth noting that,
contrary to what the terminology would suggest, a LRC is not a novel kind of code,
but rather the “locality parameters” (r, δ) can be deﬁned for any code. What we call
a LRC is then only a code that is speciﬁcally designed with the parameters (r, δ) in
mind. While the locality parameters can be understood directly in terms of the storage
system, it is more instructive from a coding theoretic point of view to understand
them via punctured codes. Then, the punctured codes will correspond exactly to the
restrictions to “locality sets”, which can be used to locally repair a small number of
node failures within the locality set.
Deﬁnition 3 Let G be a matrix over F indexed by E and C the linear code generated
by G. Then, for X ⊆E, CX is a linear [nX, kX, dX]-code where
nX = |X|,
kX = rank(G(X)),
dX = min{|Y| : Y ⊆X and kX\Y < kX}.
Alternatively, one can deﬁne the minimum distance dX as the smallest support of
a non-zero codeword in CX = R(G(X)). We use Deﬁnition 3, as it has the advantage
of not depending on the linearity of the code.

390
R. Freij-Hollanti et al.
Example 2 Consider the storage code C from Example 1. Let Y1 = {1, 2, 3, 5, 6, 7},
X1 = {1, 2, 5} and X2 = {2, 6, 7}. Then CY1, CX1 and CX2 are storage codes with
[nY1, kY1, dY1] = [6, 3, 3] ,
[nX1, kX1, dX1] = [3, 2, 2] ,
[nX2, kX2, dX2] = [3, 2, 2] .
The parameter dX is the minimum (Hamming) distance of CX. We say that C is
an [n, k, d]-code with [n, k, d] = [nE, kE, dE].
We choose the following deﬁnition for general (n, k, d,r, δ, t)-LRCs (i.e., both
linear and nonlinear), which we will compare to known results for linear LRCs.
Deﬁnition 4 An (n, k, d)-code C over A is a nonempty subset C of An, where A is
a ﬁnite set of size s, k = logs(|C|), and d the minimum (Hamming) distance of the
code. For X = {i1, . . . , im} ⊆E, the puncturing CX is deﬁned as
CX = {(ci1, . . . , cim) : c ∈C}.
The code C is non-degenerate, if d ≥2 and |C{i}| > 1 for all coordinates i ∈[n].
Deﬁnition 5 A locally repairable code over A is a non-degenerate (n, k, d)-code C.
A coordinate x ∈[n] of C has locality (r, δ) and availability t if there are t subsets
R1, . . . , Rt of [n], called repair sets of x, such that for i, j ∈[t]
(i) x ∈Ri,
(ii) |Ri| ≤r + δ −1,
(iii) d(CRi) ≥δ,
(iv) i ̸= j
⇒
Ri ∩R j = {x}.
If every element x ∈X ⊆E has availability with parameters (n, k, d,r, δ, t) in
C, then we say that the set X has (n, k, d,r, δ, t)-availability in C. We will often
talk about codes with (n, k, d,r, δ)-locality, by which we mean a code that has
(n, k, d,r, δ, 1)-availability, so that symbols are not required to be included in more
than one repair set. If the other parameters are clear from the context, we may
shortly say that X has “locality (r, δ)” or “availability t”, along the lines of the above
deﬁnition.
An information set of a linear [n, k, d]-code C is deﬁned as a set X ⊆E such that
kX = |X| = k. Hence, X is an information set of C if and only if there is a generator
matrix G of C such that G(X) equals the identity matrix, i.e., C is systematic in
the coordinate positions indexed by X when generated by G. In terms of storage
systems, this means that the nodes in X together store all the information of the DSS.
Example 3 Two examples of an information set of the linear code C generated by
G in Example 1 are {1, 2, 3, 4} and {1, 2, 6, 8}.

Matroid Theory and Storage Codes: Bounds and Constructions
391
More formally we deﬁne:
Deﬁnition 6 Let C be an (n, k, d)-code and X a subset of [n]. Then X is an infor-
mation set of C if logs(|CX|) = k and logs(CY) < k for all Y ⊊X. Further, X is
systematic if k is an integer, |X| = k and CX = Ak. Also, X is an all-coordinate set
if X = [n].
Deﬁnition 7 A systematic-symbol, information-symbol, and all-symbol LRC,
respectively, is an (n, k, d)-LRC with a systematic, information set and all-coordinate
set X, such that every coordinate in X has locality (r, δ) and availability t. These are
denoted by
(n, k, d,r, δ, t)s-LRC, (n, k, d,r, δ, t)i-LRC, and (n, k, d,r, δ, t)a-LRC,
respectively. Further, when availability is not considered (t = 1), we get natural
notions of (n, k, d,r, δ)s, (n, k, d,r, δ)i, and (n, k, d,r, δ)a-LRCs.
2
Introduction to Matroids
Matroids were ﬁrst introduced by Whitney in 1935, to capture and generalise the
notion of linear dependence in purely combinatorial terms [48]. Indeed, the combi-
natorial setting is general enough to also capture many other notions of dependence
occurring in mathematics, such as cycles or incidences in a graph, non-transversality
of algebraic varieties, or algebraic dependence of ﬁeld extensions. Although the
original motivation comes from linear algebra, we will see that a lot of matroid
terminology comes from graph theory and projective geometry. More details about
these aspects of matroid theory are relegated to the appendix.
2.1
Deﬁnitions
We begin by presenting two equivalent deﬁnitions of a matroid.
Deﬁnition 8 (Rank function) A (ﬁnite) matroid M = (ρ, E) is a ﬁnite set E together
with a rank function ρ : 2E →Z such that for all subsets X, Y ⊆E
(R.1) 0 ≤ρ(X) ≤|X|,
(R.2) X ⊆Y
⇒
ρ(X) ≤ρ(Y),
(R.3) ρ(X) + ρ(Y) ≥ρ(X ∪Y) + ρ(X ∩Y).
An alternative but equivalent deﬁnition of a matroid is the following.
Deﬁnition 9 (Independent sets) A (ﬁnite) matroid M = (I , E) is a ﬁnite set E and
a collection of subsets I ⊆2E such that

392
R. Freij-Hollanti et al.
(I.1) ∅∈I ,
(I.2) Y ∈I , X ⊆Y ⇒X ∈I ,
(I.3) For all pairs X, Y ∈I with |X| < |Y|, there exists
y ∈Y \ X such that X ∪{y} ∈I .
The subsets in I are the independent sets of the matroid.
The rank function ρ and the independents sets I of a matroid on a ground set E
are linked as follows: For X ⊆E,
ρ(X) = max{|Y| : Y ⊆X and Y ∈I },
and X ∈I if and only if ρ(X) = |X|. It is an easy (but not trivial) exercise to show
that the two deﬁnitions are equivalent under this correspondence. Another frequently
used deﬁnition is in terms of the set of bases for a matroid, which are the maximal
independent sets. Further, we will also use the nullity function η : 2E →Z, where
η(X) = |X| −ρ(X) for X ⊆E.
Any matrix G over a ﬁeld F generates a matroid MG = (ρ, E), where E is the set
of columns of G, and ρ(I) is the rank over F of the induced matrix G(I) for I ⊆E.
Consequently, I ∈I precisely when I is a linearly independent set of vectors.
It is straightforward to check that this is a matroid according to Deﬁnition 8. As
elementary row operations preserve the row space R(G(I)) for all I ⊆E, it follows
that row equivalent matrices generate the same matroid.
Two matroids M1 = (ρ1, E1) and M2 = (ρ2, E2) are isomorphic if there exists a
bijection ψ : E1 →E2 such that ρ2(ψ(X)) = ρ1(X) for all subsets X ⊆E1.
Deﬁnition 10 A matroid that is isomorphic to MG for some matrix G over F is said
to be representable over F. We also say that such a matroid is F-linear.
Two trivial matroids are the zero matroid where ρ(X) = 0 for each set X ⊆E,
and the one where ρ(X) = |X| for all X ⊆E. These correspond to all-zeros matrices
and invertible n × n-matrices respectively. The ﬁrst non-trivial example of a matroid
is the following:
Deﬁnition 11 The uniform matroid U k
n = (ρ, [n]), where [n] = {1, 2, . . . , n}, is
given by the rank function ρ(X) = min{|X|, k} for X ⊆[n].
The following straightforward observation gives yet another characterisation of
MDS codes.
Proposition 1 G is the generator matrix of an [n, k, n −k + 1]-MDS code if and
only if MG is the uniform matroid U k
n .
2.2
Matroid Operations
For explicit constructions of matroids, as well as for analysing their structure, a
few elementary operations are useful. Here, we will deﬁne these in terms of the rank

Matroid Theory and Storage Codes: Bounds and Constructions
393
function, but observe that they can equally well be formulated in terms of independent
sets. The effect of these operations on the representability of the matroid is discussed
inappendix.Inadditiontotheoperationslistedhere,twootherveryimportantmatroid
operations are dualisation and contraction. As these are not explicitly used here to
understand locally repairable codes, we leave their deﬁnition to appendix.
Deﬁnition 12 The direct sum of two matroids M = (ρM, EM) and N = (ρN, EN) is
M ⊕N = (τ, EM ⊔EN),
where ⊔denotes the disjoint union, and τ : 2EM⊔EN →Z is deﬁned by τ(X) =
ρM(X ∩EM) + ρ(X ∩EN).
Thus, all dependent sets from M and N remain dependent in M ⊕N, whereas there is
no dependence between elements in M and elements in N. If M and N are graphical
matroids,3 then M ⊕N is graphical, and obtained from the disjoint union of the
graphs associated to M and N.
Deﬁnition 13 The restriction of M = (ρ, E) to a subset X ⊆E is the matroid
M|X = (ρ|X, X), where
ρ|X(Y) = ρ(Y), for Y ⊆X.
(1)
Obviously, for any matroid M with underlying set E, we have M|E=M. The
restriction operation is also often referred to as deletion of E \ X, especially if
E \ X is a singleton. Given a matrix G that represents M, the submatrix G(X) rep-
resents M|X.
Deﬁnition 14 The truncation of a matroid M = (ρ, E) at rank k ≤ρ(E) is Mk =
(ρ′, E), where ρ′(X) = min{ρ(X), k}.
Geometrically, the truncation of a matroid corresponds to projecting a point con-
ﬁguration onto a generic k-dimensional space. However, this does not imply that
truncations of F-linear matroids are necessarily F-linear, as it may be the case that
there exists no k-space that is in general position relative to the given point con-
ﬁguration. However, it is easy to see that Mk is always representable over some
ﬁeld extension of F. In fact, via a probabilistic construction, one sees that the ﬁeld
extension can be chosen to have size at most q
n
k

[17].
The relaxation is the elementary operation that is most difﬁcult to describe in
terms of rank functions. It is designed to destroy representability of matroids, and
corresponds to selecting a hyperplane in the point conﬁguration, and perturbing it
so that its points are no longer coplanar. To prepare for the deﬁnition, we say that a
circuit is a dependent set, all of whose subsets are independent. For any nonuniform
matroid M = (ρ, E), there are circuits of rank ρ(E) −1. This is seen by taking any
dependent set of rank ρ(E) −1, and deleting elements successively in such a way
that the rank does not decrease. We mention that a matroid that has no circuits of
3See appendix for the deﬁnition of graphical matroids.

394
R. Freij-Hollanti et al.
Fig. 1 The non-Pappus matroid, which is not representable over any ﬁeld. If there were a line
between the three points in the middle, then the ﬁgure would illustrate the matroid MG in Example 4.
Relaxation of the circuit {4, 5, 6} corresponds to deletion of this line in the ﬁgure
rank < ρ(E) −1 is called a paving matroid. It is conjectured that asymptotically (in
the size) almost all matroids are paving [24]. Recent research shows that this is true
at least on a “logarithmic scale” [28].
Deﬁnition 15 Let M = (I , E) be a matroid with rank function ρ, and let C be a
circuit of rank ρ(E) −1. The relaxation of M at C is the matroid (I ∪{C}, E).
Example 4 The ﬁrst example of a matroid constructed by relaxation is the non-
Pappus matroid of Fig.1. This is constructed by relaxing the circuit {4, 5, 6} from
the representable matroid MG, where
G =
1 2 3
4 5
6
7
8
9
1 0 −1 1/2 0 −1/2 1
0 −1
1 1 1
0 0
0
−1 −1 −1
1 1 1
1 1
1
1
1
1
and can be deﬁned over any ﬁeld of odd (or zero) characteristic, other than F3.
2.3
Matroid Invariants of Codes
There is a straightforward connection between linear codes and matroids. Indeed, let
C be a linear code generated by a matrix G. Then C is associated with the matroid
MG = (ρ, E).AstwodifferentgeneratormatricesofC havethesamerowspace,they
will generate the same matroid. Therefore, without any inconsistency, we denote the
associated linear matroid of C by MC = (ρC, E). In general, there are many different
codes C ̸= C′ with the same matroid structure MC = MC′. In the appendix, we will
see how this phenomenon can be interpreted as a stratiﬁcation of the Grassmannian
over a ﬁnite ﬁeld.
A property of linear codes that depends only on the matroid structure of the code
is called matroid invariant. For example, the collection of information sets and the
parameters [n, k, d] of a code are matroid invariant properties. This is the content of
the following easy proposition.

Matroid Theory and Storage Codes: Bounds and Constructions
395
Proposition 2 Let C be a linear [n, k, d]-code and X ⊆E. Then for MC = (ρC, E),
(i) nX = |X|,
(ii) kX = ρC(X),
(iii) dX = min{|Y| : Y ⊆X, ρC(X \ Y) < ρC(X)},
(iv) X is an information set of C ⇐⇒
X is a basis of MC ⇐⇒ρC(X) = |X| = k.
In addition to the parameters [n, k, d] of a linear code C, we are also interested in
thelength, rankandminimumdistanceof thepuncturedcodes, sincethesecorrespond
to the locality parameters at the different hierarchy levels, which we will discuss in
more detail in Sect.5.
Apuncturedcodecanbeanalysedusingmatroidrestrictions, since MC|X = MC|X
for every coordinate subset X. Thus, the parameters [nX, kX, dX] of CX are also
matroid invariant properties for C.
Example 5 Let C denote the [n, k, d]-code generated by the matrix G given in
Example 1. Then [n, k, d] = [9, 4, 3], where the value of d arises from the fact that
ρC([9] \ {i, j}) = 4 for i, j = 1, 2, . . . , 9, and ρC([9] \ {4, 8, 9}) = 3. Two informa-
tion sets of C are {1, 2, 3, 4} and {1, 2, 6, 8}, as we already saw before in Example
3.
It is rather easy to see that two different linear codes can have the same associated
matroid. As a consequence, not every property of a linear code is matroid invariant.
An example of a code invariant that is not matroid invariant is the covering radius
[5, 37]. Indeed, an [n, k, d]-MDS code, i.e., a realisation of the uniform matroid
U k
n , generically has covering radius d −1 = n −k, yet there exist MDS codes with
lower covering radii. An explicit example is given in [5].
2.4
The Lattice of Cyclic Flats
One matroid invariant that has singled out as essential for describing the repairability
of storage codes is the lattice of cyclic ﬂats. To deﬁne this, remember that X ⊆E is a
circuit in M = (I , E) if X is dependent, but all proper subsets of X are independent.
A cyclic set is a (possibly empty) union of circuits. Equivalently, X is cyclic if for
every x ∈X
ρ(X \ {x}) = ρ(X).
Let us deﬁne the operation cyc : 2E →2E by
cyc(X) = {x ∈X : ρ(X \ {x}) = ρ(X)}.
Then X is cyclic if and only if cyc(X) = X. We refer to cyc as the cyclic core operator.

396
R. Freij-Hollanti et al.
Dually, we deﬁne the closure of X to be
cl(X) = {y ∈E : ρ(X ∪{y}) = ρ(X)},
and notice that X ⊆cl(X) by deﬁnition. We say that X is a ﬂat if cl(X) = X. There-
fore, X is a cyclic ﬂat if
ρ(X \ {x}) = ρ(X) and ρ(X ∪{y}) > ρ(X)
for all x ∈X and y ∈E \ X. The set of ﬂats, cyclic sets, and cyclic ﬂats of M are
denoted by F(M), U (M), and Z (M), respectively.
It is not entirely obvious that the set of cyclic ﬂats is nonempty. However, it follows
from the matroid axioms that the closure operator cl preserves cyclicity, and that the
cyclic core operator cyc preserves ﬂatness. Thus we can consider cl and cyc as maps
cl :

2E →F(M)
U (M) →Z (M) ,
and
cyc :

2E →U (M)
F(M) →Z (M) .
In particular, for any set X ⊆E, we have cyc ◦cl(X) ∈Z (M) and cl ◦cyc(X) ∈
Z (M).
Let M[G] = (ρ, E) be a linear matroid, generated by G. Then X ⊆E is a cyclic
ﬂat if and only if the following two conditions are satisﬁed
(i) C(G(X)) ∩C(G(E \ X)) = 0
(ii) x ∈X ⇒C(G(X \ {x})) = C(G(X)).
In terms of storage codes, a cyclic ﬂat is thus a set X ⊆E of storage nodes such that
every node in X can be repaired by the other nodes in X, whereas no node outside
X can be repaired by X. This observation shows the relevance of cyclic ﬂats for
storage applications. The strength of using Z (M) as a theoretical tool comes from
its additional lattice structure, which we will discuss next.
A collection of sets P ⊆2E ordered by inclusion deﬁnes a partially ordered set
(poset) (P, ⊆). Let X and Y denote two elements of P. Z is the join X ∨Y if it is
the unique maximal element in {W ∈P : X ⊆W, Y ⊆W}. Dually, Z is the meet
X ∧Y if it is the unique minimal element in {W ∈P : X ⊇W, Y ⊇W}.
A pair of elements in an arbitrary poset does not need to have a join or a meet. If
(P, ⊆) is a poset such that every pair of elements in P has a join and a meet, then
P is called a lattice. The bottom and top elements of a ﬁnite lattice (P, ⊆) always
exist, and are denoted by 1P = 
X∈P X and 0P = 
X∈P X, respectively.

Matroid Theory and Storage Codes: Bounds and Constructions
397
Two basic properties of cyclic ﬂats of a matroid are given in the following propo-
sition.
Proposition 3 ([4]) Let M = (ρ, E) be a matroid and Z the collection of cyclic
ﬂats of M. Then,
(i) ρ(X) = min{ρ(F) + |X \ F| : F ∈Z }, for X ⊆E,
(ii) (Z , ⊆) is a lattice, X ∨Y = cl(X ∪Y) and
X ∧Y = cyc(X ∩Y) for X, Y ∈Z .
Proposition 3 (i) shows that a matroid is uniquely determined by its cyclic ﬂats
and their ranks.
Example 6 Let MC = (ρC, E) be the matroid associated to the linear code C gen-
erated by the matrix G given in Example 1. The lattice of cyclic ﬂats (Z , ⊆) of MC
is given in the ﬁgure below, where the cyclic ﬂat and its rank are given at each node.
An axiom scheme for matroids via cyclic ﬂats and their ranks was independently
given in [4, 35]. This gives a compact way to construct matroids with prescribed
local parameters, which we have exploited in [47].
Theorem 1 (see [4] Theorem 3.2 and [35]) Let Z ⊆2E and let ρ be a function
ρ : Z →Z. There is a matroid M on E for which Z is the set of cyclic ﬂats and ρ
is the rank function restricted to the sets in Z , if and only if
(Z0) Z is a lattice under inclusion,
(Z1) ρ(0Z ) = 0,
(Z2) X, Y ∈Z and X ⊊Y ⇒
0 < ρ(Y) −ρ(X) < |Y| −|X|,
(Z3) X, Y ∈Z ⇒ρ(X) + ρ(Y) ≥
ρ(X ∨Y) + ρ(X ∧Y) + |(X ∩Y) \ (X ∧Y)|.

398
R. Freij-Hollanti et al.
For a linear [n, k, d]-code C with MC = (ρC, E) and Z = Z (MC), and for a
coordinate x, we have
(i) d ≥2 ⇐⇒1Z = E,
(ii) C{x} ̸= {0F} for every x ∈E ⇐⇒0Z = ∅.
Hence, by Deﬁnition 1, we can describe non-degeneracy in terms of the lattice of
cyclic ﬂats, as follows.
Proposition 4 Let C be a linear [n, k, d]-code and Z denote the collection of cyclic
ﬂats of the matroid MC = (ρC, E). Then C is a non-degenerate storage code if and
only if 0Z = ∅and 1Z = E.
Proposition 5 Let C be a non-degenerate storage code and MC = (ρC, E). Then,
for X ⊆E, CX is a non-degenerate storage code if and only if X is a cyclic set of
MC.
As cyclic sets correspond to non-degenerate subcodes, and hence to systems
where every symbol is stored with redundancy, we will use these as our “repair sets”.
Therefore, we want to determine from the lattice of cyclic ﬂats, whether a set is cyclic
or not, which we achieve through the following theorem.
Theorem 2 Let M = (ρ, E) be a matroid with 0Z = ∅and 1Z = E where Z =
Z (M). Then, for any X ⊆E, X ∈U (M) if and only if the cyclic ﬂat
F X =

{F ∈Z : X ⊆F}
is such that
ρ(F) + |X \ F| > ρ(F X).
for all F ⊊F X in Z .
If this is indeed the case, then it is easy to verify that F X as deﬁned in Theorem
2 is indeed the closure cl(X) as deﬁned earlier. In order to analyze the parameters
[nX, kX, dX] of a punctured code CX, we will use the lattice of cyclic ﬂats of MC|X.
Theorem 3 Let M = (ρ, E) be a matroid with 0Z = ∅and 1Z = E where Z =
Z (M). Then, for X ∈U (M),
(i) Z (M|X) = {X ∩F ∈U (M) : F ∈Z , F ⊆F X},
(ii) Y ∈Z (M|X) ⇒ρ|X(Y) = ρ(FY).
Weremarkthatif X isacyclicﬂatofamatroid M,thenZ (M|X) = {F ∈Z (M) :
F ⊆X}.
Example 7 Let Z = Z (MC) be the lattice of cyclic ﬂats given in Example 6, where
MC = (ρC, E) is the matroid associated to the linear LRC C generated by the matrix

Matroid Theory and Storage Codes: Bounds and Constructions
399
G given in Example 1. Then, F X = FY = Y1 for X = {1, 2, 3, 7} and Y = {1, 2, 3}.
Further, X is a cyclic set but Y is not a cyclic set. The lattice of cyclic ﬂats (ZX, ⊆)
for MC|X = MC|X is shown in the following ﬁgure.
The very simple structure of ZX shows that CX has the very favourable property
of being an MDS code. Indeed, the following proposition is immediate from the
deﬁnitions of the involved concepts.
Proposition 6 Let C be a linear code of length n and rank k. The following are
equivalent:
(i) C is an [n, k, n −k + 1]-MDS code.
(ii) MC is the uniform matroid U k
n .
(iii) Z = Z (MC) is the two element lattice with 1Z = [n] and 0Z = ∅.
For linear LRCs we are also interested in when a coordinate set is an information
set, or equivalently, if it is a basis for the matroid. This property is determined by the
cyclic ﬂats as follows.
Proposition 7 Let C be a linear [n, k, d]-code with 0Z = ∅and 1Z = E where Z
is the collection of cyclic ﬂats of the matroid MC = (ρC, E). Then, for any X ⊆E,
X is an information set of C if and only if the following two conditions are satisﬁed,
(i) |X| = ρC(1Z ),
(ii) |X ∩F| ≤ρC(F) for every F ∈Z .
Example 8 Let C be the linear [n, k, d]-code generated by the matrix G given in
Example 1. Then, by the lattice of cyclic ﬂats for MC given in Example 6, C is a linear
LRC with all-symbol (2, 2)-locality. We notice that, by Proposition 7, {1, 2, 3, 4} is
an information set of C. This follows as it is not contained in either of Y1 and Y2,
while all its subsets are. On the other hand, {1, 2, 8, 9} is not an information set of
C, as it is itself a subset of Y2.
The parameters [n, k, d] of a linear LRC C and [nX, kX, dX] of a punctured code
CX that is a non-degenerate storage code can now be determined by the lattice of
cyclic ﬂats as follows.

400
R. Freij-Hollanti et al.
Theorem 4 Let C be a linear [n, k, d]-LRC, where Z = Z (MC) for the matroid
MC = (ρC, E). Then, for any X ∈U (MC), CX is a linear [nX, kX, dX]-LRC with
(i) nX = |X|,
(ii) kX = ρ(F X),
(iii) dX = nX −kX + 1 −max{η(Y) : Y ∈Z (MC|X) \ X}.
Example 9 Let Z = Z (MC) be the lattice of cyclic ﬂats given in Example 6, where
MC = (ρC, E) is the matroid associated to the linear [n, k, d]-LRC C generated
by the matrix G given in Example 1. Then by Example 7, X = {1, 2, 3, 7} is a
cyclic set, and by Theorem 4 CX is a linear [nX, kX, dX]-LRC with parameters
nX = 4, kX = 3 and dX = 4 −3 + 1 −0 = 2. Moreover, n = nE = 9, k = kE = 4
and d = dE = 9 −4 + 1 −3 = 3.
3
Singleton-Type Bounds
Many important properties of a linear code C are due to its matroid structure, which
is captured by the matroid MC. By the results in [10, 47], matroid theory seems
to be particularly suitable for proving Singleton-type bounds for linear LRCs and
nonexistence results of Singleton-optimal linear LRCs for certain parameters.
Even though matroids can be associated to linear codes to capture the key proper-
ties for linear LRCs, this cannot be done in general for nonlinear codes. Fortunately,
by using some key properties of entropy, any code (either linear and nonlinear) C
can be associated with a polymatroid PC so that PC captures the key properties of
the code when it is used as a LRC. A polymatroid is a generalisation of a matroid.
For any linear code C the associated polymatroid PC and matroid MC are the same
object. We will brieﬂy discuss the connection between polymatroids and codes in
Sect.5. Singleton-type bounds for polymatroids were derived in [46], and polyma-
troid theory for its part seems to be particularly suitable for proving such bounds for
general LRCs. In Sect.5 we will also review Singleton-type bounds for polymatroids
and general codes with availability and hierarchy.
3.1
Singleton-Type Bounds for Matroids and Linear LRCs
Matroid theory provides a uniﬁed way to understand and connect several different
branches of mathematics, for example linear algebra, graph theory, combinatorics,
geometry, topology and optimisation theory. Hence, a theorem proven for matroids
gives “for free” theorems for many different objects related to matroid theory. As
described earlier, the key parameters (n, k,r, d, δ, t) of a linear LRCs C are matroid
properties of the matroid MC and can therefore be deﬁned for matroids in general.

Matroid Theory and Storage Codes: Bounds and Constructions
401
Deﬁnition 16 Let M = (ρ, E) be a matroid and X ⊆E. Then
(i) nX = |X|,
(ii) kX = ρ(X),
(iii) dX = min{|Y| : Y ⊆X, ρ(X \ Y) < ρ(X)},
(iv) X is an information set of M if ρ(X) = kE and ρ(Y) < kE for all Y ⊊X,
(v) M is non-degenerate if ρ(x) > 0 for all x ∈E and dE ≥2.
Further, n = nE, k = kE and d = dE, and the deﬁnitions of repair sets, (r, δ)-
locality and t-availability for elements x ∈E, as well as the concepts of
(n, k, d,r, δ, t)i-matroids and (n, k, d,r, δ, t)a-matroids are directly carried over
from Deﬁnitions 5 and 7.
BeforestatingTheorem5below,itisnotatallclearthattheSingleton-typebounds,
already proven for linear LRCs, also hold for matroids in general. Especially, one
could doubt this generality of the bound because of the wide connection between
matroids and a variety of different mathematical objects, as well as for the sake of
the recently proven result, stated in Theorem 13 later on, that almost all matroids
are nonrepresentable. However, Theorem 5 gives a Singleton-type bound that holds
for matroids in general. This implies, as special cases, the same bound on linear
LRCs and other objects related to matroids, e.g., graphs, almost afﬁne LRCs, and
transversals. For the bound to make sense for various objects, a description of the
parameters (n, k, d,r, δ) has to be given for the objects in question. To give an
example, for a graph,
• n equals the number of edges,
• k equals the difference of the number of vertices and the number of connected
components,
• d is the smallest number of edges in an edge-cut (i.e., a set of edges whose removal
increases the number of connected components in the graph).
Recall that the Singleton bound [36] states that for any linear [n, k, d]-code we
have
d ≤n −k + 1.
(2)
In what follows, we state generalised versions of this bound, accounting for the
various parameters relevant for storage systems. We start with the general one for
matroids.
Theorem 5 ([47] Singleton-type bound for matroids)
Let M = (ρ, E) be an
(n, k, d,r, δ)i-matroid. Then
d ≤n −k + 1 −
	k
r

−1

(δ −1).
(3)
Theorem 5 was stated for all-symbol locality in [47]. However, the proof given
in [47] implies also information-symbol locality. As an illustration on how matroid

402
R. Freij-Hollanti et al.
theory and cyclic ﬂats can be useful for proving Singleton-type of bounds we will
here give a proof of Theorem 5.
Proof We know from Theorem 4 that d = n −k + 1 −max{η(Z) : Z ∈Z \ E}.
Hence to prove the theorem we need to show that there exists a cyclic ﬂat Z ̸= E in
M with η(Z) ≥
 k
r

−1

(δ −1).
Let B be an information set of M, i.e, B is a basis of M, such that M is an
(n, k, d,r, δ)i-matroid. For x ∈B let Rx denote the repair set of x. Since Rx is a
cyclic set of we obtain that Zx = cl(Rx) is a cyclic ﬂat of M with
ρ(Zx) = ρ(Rx) ≤r and η(Zx) ≥η(Rx) ≥dRx −1 ≥δ −1.
As ρ(B) = k we can choose a subset of cyclic ﬂats {Z1, . . . , Zm} ⊆{Zx : x ∈B}
such that we obtain a chain of cyclic ﬂats
∅= Y0 ⊊Y1 ⊊· · · ⊊Ym = E
with Yi = Yi−1 ∨Zi for i = 1, . . . , m. Since ρ(Y0) = η(Y0) = 0 and ρ(Ym) = k, the
theorem will now be proved if we can prove that ρ(Yi) −ρ(Yi−1) ≤r and η(Yi) −
η(Yi−1) ≥δ −1 for i = 1, . . . , m.
First, by the use of Axiom (R.3) and Proposition 3,
ρ(Yi) = ρ(cl(Yi−1 ∪Zi)) = ρ(Yi−1 ∪Zi) ≤ρ(Yi−1) + ρ(Zi) −ρ(Yi−1 ∩Zi)
≤ρ(Yi−1) + r.
Second, by Axiom (R.3), η(X) + η(Y) ≤η(X ∩Y) + η(X ∪Y) for X, Y ⊆E.
Further, we observe that, cyc(Yi−1 ∩Zi) and Zi are cyclic ﬂats of M|Zi and that
cyc(Yi−1 ∩Zi) ⊊Zi. Hence,
η(Yi) = η(cl(Yi−1 ∪Zi)) ≥η(Yi−1 ∪Zi) ≥η(Yi−1) + η(Zi) −η(Yi−1 ∩Zi)
= η(Yi−1) + η(Zi) −η(cyc(Yi−1 ∩Zi))
= η(Yi−1) + |Zi| −ρ(Zi) −η(cyc(Yi−1 ∩Zi)) ≥η(Yi−1) + dZi −1
≥η(Yi−1) + δ −1.
That dZi ≥δ follows from the fact that Zi = cl(Rx) for some x ∈B and therefore
dZi = dcl(Rx) = min{|Y| : Y ⊆cl(Rx), ρ(cl(Rx) \ Y) ≤ρ(cl(Rx)}
≥min{|Y| : Y ⊆Rx, ρ(Rx \ Y) ≤ρ(Rx)}
= dRx.
⊓⊔

Matroid Theory and Storage Codes: Bounds and Constructions
403
The Singleton bound given in (2) was generalised by Gopalan et al. in [13] as
follows. A linear (n, k, d,r)i-LRC satisﬁes
d ≤n −k + 1 −
	k
r

−1

.
(4)
The bound (4) shows that there is a penalty for requiring locality. That is, the smaller
the locality r the smaller the upper bound on d. By the deﬁnition of LRCs, any linear
[n, k, d]-code with locality r is also a linear [n, k, d]-code with locality k. Hence,
by letting the locality be k, the bound (4) implies (2).
The bound (4) was generalised in [30] as follows. A linear (n, k, d,r, δ)i-LRC
satisﬁes
d ≤n −k + 1 −
	k
r

−1

(δ −1).
(5)
The bound (5) again shows that there is a penalty on the upper bound for d depending
on the size of the local distance δ. This is, the bigger the local distance δ the smaller
the upper bound on the global distance d. However, we must remark that any linear
(n, k, d,r, δ)i-LRC satisﬁes d ≥δ, and this property also holds more generally for
matroids [47]. The bound (4) follows from the bound (5) by letting δ = 2.
A bound including availability was proven in [44]. This bound states that a linear
(n, k, d,r, t)i-LRC satisﬁes
d ≤n −k + 1 −
	t(k −1) + 1
t(r −1) + 1

−1

.
(6)
Again, the bound (4) follows from (6) above by letting t = 1.
The bounds (3)–(6) are stated assuming information-symbol locality. However,
since every matroid contains an information set, this implies that the bound is also
valid under the stronger assumption of all-symbol locality.
3.2
Stronger Bounds for Certain Parameter Values
A linear LRC, or more generally a matroid, that achieves any of the Singleton-type
bounds given above will henceforth be called Singleton-optimal.
Any (n, k, d,r, δ)i-matroid M satisﬁes that δ ≤d. Hence, by the bound (5), k ≤
n −(δ −1)⌈k
r ⌉for M. Thus, regardless of the global minimum distance d, any
(n, k, d,r, δ)-LRC with either information or all-symbol locality, has parameters
n, k,r, δ in the set

404
R. Freij-Hollanti et al.
P(n, k,r, δ) =

(n, k,r, δ) ∈Z4 : 2 ≤δ and 0 < r ≤k ≤n −(δ −1)
	k
r


.
(7)
A very natural question to ask then is for which parameters (n, k,r, δ) ∈P(n, k,r, δ)
there exists a Singleton-optimal matroid or linear LRC, regarding both informa-
tion and all-symbol locality. We remark that existence results on Singleton-optimal
linear LRCs imply existence results on Singleton-optimal matroids. Conversely,
nonexistence results on Singleton-optimal matroids implies nonexistence results on
Singleton-optimal linear LRCs.
When considering information-symbol locality it is known that the upper bound
for d given in (5) is achieved for all parameters (n, k,r, δ) ∈P(n, k,r, δ) by linear
LRCs over sufﬁcient large ﬁelds. This follows from [14], where a new class of codes
called pyramid codes was given. Using this class of codes, Singleton-optimal linear
(n, k, d,r, δ)i-LRCs can be constructed for all parameters in P(n, k,r, δ).
It is well known that Singleton-optimal linear (n, k, d,r, δ)a-LRCs exist whenr =
k.Namely,theLRCsinthesecasesarelinear [n, k, n −k + 1]MDS-codes.However,
existence or nonexistence results when r < k are in general not that easy to obtain. In
[38], existence and nonexistence results on Singleton-optimal linear (n, k, d,r, δ)a-
LRCs were examined. Such results were given for certain regions of parameters,
leaving other regions for which the answer of existence or nonexistence of Singleton-
optimal linear LRCs is not known. The results on nonexistence were extended to
matroids in [47]. All the parameter regions for the nonexistence of Singleton-optimal
linear LRCs in [47] were also regions of parameters for the nonexistence of Singleton
optimal matroids for all-symbol locality. Further, more regions of parameters for
nonexistence of Singleton-optimal matroids with all-symbol locality were given in
[47]. This implies new regions of parameters for nonexistence of Singleton-optimal
linear LRCs with all-symbol locality.
The nonexistence results for Singleton-optimal matroids were proven via the
following structure result in [47]. Before we state the theorem we need the concept
of nontrivial unions. Let M = (ρ, E) be a matroid with repair sets {Rx}x∈E. For
Y ⊆E, we say that
RY =

x∈Y
Rx
and
RY is a nontrivial union if Rx ⊈RY\{x} for every x ∈Y.
Theorem 6 ([47] Structure theorem for Singleton-optimal matroids)
Let M =
(ρ, E) be an (n, k, d,r, δ)a-matroid with r < k, repair sets {Rx}x∈E and
d = n −k + 1 −
	k
r

−1

(δ −1).
Then, the following properties must be satisﬁed by the collection of repair sets and
the lattice of cyclic ﬂats Z of M:

Matroid Theory and Storage Codes: Bounds and Constructions
405
(i) 0Z = ∅,
(ii) for each x ∈E,
a) Rx is an atom of Z ,
(i.e., Rx ∈Z , 0Z < Rx and ∄Z ∈Z such that 0Z < Z < Rx),
b) η(Rx) = δ −1,
(iii) for each Y ⊆E with RY being a nontrivial union,
c) |Y| < ⌈k
r ⌉
⇒
RY ∈Z ,
d) |Y| < ⌈k
r ⌉
⇒
ρ(RY) = |RY| −|Y|(δ −1),
e) |Y| ≤⌈k
r ⌉
⇒
|Rx
(RY\{x})| ≤|Rx| −δ, for each x ∈Y,
f ) |Y| ≥⌈k
r ⌉
⇒
{Z ∈Z : Z ⊇RY} = 1Z = E.
Conditions (i) and (ii) in the structure theorem above for Singleton-optimal
matroids show that each repair set Rx must correspond to a uniform matroid with |Rx|
elements and rank |Rx| −(δ −1). Further, condition (iii) gives structural properties
on nontrivial unions of repair sets. This can be viewed as structural conditions on
how nontrivial unions of uniform matroids need to be glued together in a Singleton-
optimal matroid, with the uniform matroids corresponding to repair sets. For
Singleton-optimal linear (n, k, d,r, δ)a-LRCs, the property of the repair sets being
uniformmatroidscorrespondstotherepairsetsbeinglinear[|Rx|, |Rx| −(δ −1), δ]-
MDS codes. We remark that structure theorems whenr|k for Singleton-optimal linear
(n, k, d,r, δ)a-LRCs and the special case of (n, k, d,r, δ = 2)a-LRCs are given in
[13, 18], respectively. These theorems show that the local repair sets correspond to
linear [r + δ −1,r, δ]-MDS codes that are mutually disjoint. This result is a special
case of Theorem 6.
Example 10 By Theorem 1, the poset with its associated subsets of E = [16] and
rank of these subsets in the ﬁgure below deﬁnes the set of cyclic ﬂats Z and the rank
function restricted to the sets in Z of a matroid M on E. From Theorem 4, we obtain
that (n, k, d) = (16, 7, 6) for the matroid M. Choosing repair sets R1 = · · · = R5 =
X1, R6 = · · · = R9 = X2, R10 = · · · = R13 = X3 and R14 = · · · = R16 = X4, we
obtain that M is an (n = 16, k = 7, d = 6,r = 3, δ = 3)a-matroid. It can easily be
checked that all the properties (i)–(iii) are satisﬁed by the matroid M and the chosen
repair sets. Further, we also have that M is Singleton-optimal as
n −k + 1 −
	k
r

−1

(δ −1) = 6 = d.

406
R. Freij-Hollanti et al.
4
Code Constructions
4.1
Constructions of (n, k, d, r, δ)a-Matroids via Cyclic
Flats
In [47], a construction of a broad class of linear (n, k, d,r, δ)a-LRCs is given via
matroid theory. This is generalised in [10, 46] to account for availability and hierar-
chy, respectively.
A construction of (n, k, d,r, δ)a-matroids via cyclic ﬂats:
Let F1, . . . , Fm be a collection of ﬁnite sets and E = m
i=1 Fi. Assign a function
ρ : {Fi} ∪{E} →Z satisfying
(i) 0 < ρ(Fi) < |Fi| for i ∈[m],
(ii) ρ(Fi) < ρ(E) for i ∈[m],
(iii) ρ(E) ≤|E| −
i∈[m] η(Fi),
(iv) j ∈[m] ⇒|F[m]\{ j} ∩Fj| < ρ(Fj),
(8)
where
η(Fi) = |Fi| −ρ(Fi) for i ∈[m] and
FI =

i∈I
Fi for I ⊆[m].

Matroid Theory and Storage Codes: Bounds and Constructions
407
Extend ρ to {FI} →Z by
ρ(FI) = min

|FI| −

i∈I
η(Fi), ρ(E)

(9)
and let Z be the following collection of subsets of E,
Z = {FI : I ⊆[m] and ρ(FI) < ρ(E)} ∪E.
(10)
Theorem 7 ([47] Construction of (n, k, d,r, δ)a-matroids) Let F1, . . . , Fm, be a
collection of ﬁnite sets with E = m
i=1 Fi and ρ : {Fi}i∈[m] →Z satisfying (8).
Then the pair (ρ, Z ), deﬁned in (9) and (10), deﬁnes a (n, k, d,r, δ)a-matroid
M(F1, . . . , Fm; ρ) on E for which Z is the collection of cyclic ﬂats, ρ is the rank
function restricted to the cyclic ﬂats in Z , F1, . . . , Fm, are the repair sets and
(i) n = |E|,
(ii) k = ρ(E),
(iii) d = n −k + 1 −max{
i∈I η(Fi) : FI ∈Z \ E},
(iv) δ = 1 + min{η(Fi) : i ∈[m]},
(v) r = max{ρ(Fi) : i ∈m}.
That M(F1, . . . , Fm; ρ) deﬁnes a matroid follows from a proof given in [47] that
the pair (ρ, Z ) satisﬁes the axiomatic scheme of matroids via cyclic ﬂats and their
ranks stated in Theorem 1. The correctness of the parameters (n, k, d,r, δ) when
F1, . . . , Fm are considered as the repair sets also follows from [47].
We remark, that the matroids constructed in Theorem 7 satisfy, for all unions of
repair sets FI with ρ(FI) < ρ(E), that
(i) FI is a cyclic ﬂat,
(ii) the nullity η(FI) of FI is as small as possible.
(11)
Properties (i) and (ii) above are trivially seen to be fulﬁlled by uniform matroids Uk,n,
where Z = {∅, E}, ρ(∅) = 0 and ρ(E) = k. However, uniform matroids cannot be
constructed by Theorem 7, since all constructed matroids by this theorem have r < k
and uniform matroids have r = k. Though both uniform matroids and the matroids
constructed in Theorem 7 satisfy properties (i) and (ii) in (11), we will consider them
in terms of a class of matroids M , deﬁned as follows:
M = {M = M(F1, . . . , Fm; ρ) : M is constructed in Theorem 7} ∪{Uk,n}. (12)
By the structure Theorem 6, the properties (i) and (ii) in (11) are necessary (but not
sufﬁcient) for Singleton-optimal (n, k, d,r, δ)a-matroids.
Example 11 Let
E = [12]
and
let
F1 = {1, . . . , 4},
F2 = {3, . . . , 6},
F3 =
{7, . . . , 10}, F4 = {10, . . . , 12} with ρ(F1) = ρ(F2) = ρ(F3) = 3, ρ(F4) = 2, and

408
R. Freij-Hollanti et al.
ρ(E) = 7. Then, by Theorem 7, M(F1, . . . , Fm; ρ) is an (n, k, d,r, δ)a-matroid over
E with (n, k, d,r, δ) = (12, 7, 3, 3, 2) and the following lattice of cyclic ﬂats and
their ranks.
Further, the matroid is not Singleton-optimal since
d = 3 < n −k + 1 −
	k
r

−1

(δ −1) = 4.
4.2
A Matroidal Construction of Linear all Symbol LRCs
As will be explained below, all matroids constructed in Theorem 6 are contained
in a class of matroids called gammoids. These matroids are linear, which especially
implies that all (n, k, d,r, δ)a-matroids constructed by Theorem 6 are matroids asso-
ciated with linear (n, k, d,r, δ)a-LRCs.
Deﬁnition 17 Any (ﬁnite) directed graph Γ = (V, D) and vertex subsets E, T ⊆V
deﬁne a gammoid M(Γ, E, T ), where M(Γ, E, T ) = (I , E) is a the matroid with
I = {X ⊆E : ∃a set of |X| vertex-disjoint paths from X to T }.

Matroid Theory and Storage Codes: Bounds and Constructions
409
Theorem 8 ([20]) Every gammoid M(Γ, E, T ) is Fq-linear for all prime powers
q ≥2|E|.
In [47], it is proven that the matroids constructed in Theorem 7 are indeed gam-
moids, and hence representable. This is achieved by explicitly constructing a triple
(Γ, E, T ) whose associated matroid is M(F1, . . . , Fm; ρ). The details of the con-
struction are left to Theorem 14 in the appendix. The essence of the argument is to
construct a graph of depth three, whose sources correspond to the ground set of the
matroid, and whose middle layer corresponds to the repair sets, with multiplicities
to reﬂect the ranks of the repair sets.
Example 12 ThefollowingdirectedgraphΓ = (V = E ∪H ∪T, D)isconstructed
in Theorem 14 from the matroid M(F1, . . . , Fm, E; k; ρ) given in Example 11.
In general it is extremely hard to prove that a matroid is linear (or the converse).
There is no known deterministic algorithm to solve this problem in general. However,
by combining the results given in Theorems 7–14, we obtain the following result.
Theorem 9 ([47] A matroidal construction of (n, k, d,r, δ)a-LRCs) For every
(n, k, d,r, δ)a-matroid M(F1, . . . , Fm, E; k; ρ) given by Theorem 7 and every prime
power q ≥2|E| there is a linear (n, k, d,r, δ)a-LRC C over Fq with repair sets
F1, . . . , Fm such that M(F1, . . . , Fm, E; k; ρ) = MC.
Example 13 The (12, 7, 3, 3, 2)a-matroid M(F1, . . . , Fm, E; k; ρ) given in Exam-
ple 11 equals the matroid MC = M[G], where G equals the following matrix over
F5:
G =
1 2 3 4 5 6 7 8 9 10 11 12
1 1 0 0 0 0 0 0 0 0
1
3
0 2 1 0 0 1 0 0 0 0
1
3
0 3 0 1 0 3 0 0 0 0
1
3
0 0 0 0 1 2 0 0 0 0
1
3
0 0 0 0 0 0 1 0 1 0
1
3
0 0 0 0 0 0 0 1 2 0
1
3
0 0 0 0 0 0 0 0 3 1
1
1
Hence, the code C generated by the rows of G is a linear (12, 7, 3, 3, 2)-LRC
over F5 with repair sets F1 = {1, 2, 3, 4}, F2 = {3, 4, 5, 6}, F1 = {7, 8, 9, 10} and
F1 = {10, 11, 12}.

410
R. Freij-Hollanti et al.
Note that the bound q ≥2|E| given in Theorem 9 is a very rough bound. There
are many matroids M(F1, . . . , Fm, E; k; ρ) = MC for linear LRCs C over Fq where
q ≪2|E|. In Example 13, for instance, we constructed a code over F5, while the
ﬁeld size predicted by Theorem 9 was 212 = 4096 ≫5. To construct an explicit
linear (n, k, d,r, δ)a-LRC from a matroid M(F1, . . . , Fm, E; k; ρ), one can use the
directed graph representation of the matroid given in Theorem 14, together with
results on how to construct a generator matrix from this representation [20].
As we saw earlier, it is known that there exists a Singleton-optimal linear
(n, k, d,r, δ)i-LRC for all parameters (n, k,r, δ) ∈P(n, k,r, δ) (cf. (7) for a def-
inition of P(n, k,r, δ)). Further, it is also known that if r = k, then all Singleton-
optimal linear LRCs are linear [n, k, n −k + 1]-MDS codes. In [38] existence and
nonexistence of Singleton-optimal linear (n, k, d,r, δ)a-LRCs were examined. The
parameter regions for existence given in [38] were both obtained and extended in
[47] by the construction of linear LRCs via matroid theory given in Theorem 9.
Hence, the results in [47] about nonexistence and existence of Singleton-optimal
linear (n, k, d,r, δ)a-LRCs settled large portions of the parameter regions left open
in [38] leaving open only a minor subregion. Some improvements of the results in
[38] were also given for δ = 2 in [45] via integer programming techniques.
For (n, k,r, δ) ∈P(n, k,r, δ) it is also very natural to ask what is the maximal
value of d for which there exist an (n, k, d,r, δ)a-matroid or a linear (n, k, d,r, δ)a-
LRC. We denote this maximal value by dmax(n, k,r, δ). In [47] it was proven that
dmax(n, k,r, δ) ≥n −k + 1 −
	k
r

(δ −1)
for linear LRCs. For matroids, this result is straightforward, as a matroid with
d = n −k + 1 −
 k
r

(δ −1) can be constructed as a truncation of the direct sum of
⌈
n
r+δ−1⌉uniform matroids of size si ≤r + δ −1 and rank si −δ + 1 ≤r. As repre-
sentability (over some ﬁeld) is preserved under direct sums and truncation, the result
follows for linear LRCs. However, with this straightforward argument, and with the
bound on the ﬁeld size of truncated matroids from [17], the ﬁeld size required could
be as large as
(r + δ −1) ·
r·⌈
n
r+δ−1⌉

i=k
n
i

.
Signiﬁcant work is needed in order to bound the ﬁeld size even in this special case.
This result was improved in [47] and further in [29]. Also, the parameter region
of Singleton-optimal linear (n, k, d,r, δ)-LRCs was also extended in [29]. The exis-
tence of Singleton-optimal linear LRCs obtained by the matroidal construction
described here depends mainly on the relation between the parameters a and b where
a = ⌈k
r ⌉r −k and b = ⌈
n
r+δ−1⌉(r + δ −1) −n. Thus, we can easily get Singleton-
optimal linear LRCs for all possible coding rates.

Matroid Theory and Storage Codes: Bounds and Constructions
411
4.3
Random Codes
An alternative way to design (n, k, d,r, δ)-LRCs with prescribed parameters is by
exploiting the fact that independence is a generic property for r- and k-tuples of
vectors over large ﬁelds. This allows us to use randomness to generate (n, k, d,r, δ)-
LRCs in a straightforward way, once the matroid structure of the code is prescribed.
This is the key element in [8]. As opposed to in the gammoid construction from the
last section, we will now consider the ﬁeld size q to be ﬁxed but large. Indeed, a
sufﬁciently large ﬁeld will be Fq with
q > (rδ)4rr
n + (rδ)(r−1)4r
k −1

.
For given (n, k,r, δ), we will construct (n, k, d,r, δ)-LRCs where
d ≥n −k + 1 −
	k
r

(δ −1).
Comparing this to the generalised Singleton bound (5), we notice that the codes we
construct are “almost Singleton-optimal”.
The underlying matroid will again be a truncation of
⌈
n
r+δ−1 ⌉

i=1
U si−δ−1
si
.
However, rather than ﬁrst representing this direct sum, which has rank

i
(si −δ + 1) = n −⌈
n
r + δ −1⌉(δ −1),
we will immediately represent its truncation as an n × k matrix. The random con-
struction proceeds as follows. Divide the columns [n] into locality sets Si of size si.
For each Si, we ﬁrst generate the ri = si −δ + 1 ﬁrst columns uniformly at random
from the ambient space Fk. This gives us an ri × k-matrix Gi. After this, we draw
δ −1 vectors from Fri, and premultiply these by Gi. The resulting ri + δ −1 = si
vectors will be in the linear span of the ri ﬁrst vectors, and so have rank ≤ri as a
point conﬁguration in Fk. We arrange the si vectors into a matrix G′
i of rank ≤ri in
Fsi×k. Let Ai be the event that all ri-tuples of columns in Gi are linearly independent.
It is easy to see that, if the ﬁeld size grows to inﬁnity, the probability of Ai tends to
one.

412
R. Freij-Hollanti et al.
Juxtaposing the matrices G′
i for i = 1, . . . , ⌈
n
r+δ−1⌉, we obtain a generator matrix
G for a code of length n. Let B be the event that G has full rank. Again, assuming the
ﬁeld size is large enough, the probability of B can be arbitrarily close to one. Now, the
randommatrix G generatesan(n, k, d,r, δ)-LRCifalltheevents A1, . . . , A⌈
n
r+δ−1 ⌉, B
simultaneously occur. A simple ﬁrst moment estimate shows that, if
q > (rδ)r4r n + (rδ)(r−1)4r
k −1

,
then the probability of this is positive, so there exists an (n, k, d,r, δ)-LRC.
4.4
Constructing LRCs as Evaluation Codes
As suggested in the previous sections, there are several assumptions that can be made
in order to give more explicit code constructions for optimal LRCs. Next, we will
follow [39, 40] in assuming that n is divisible by r + δ −1 and k is divisible by r.
Then, an optimal LRC with d = n −k −( k
r −1)(δ −1) + 1 exists for any choice
of k. We will also assume that n = q is a prime power, although this assumption can
easily be removed at the price of a more technical description of the code.
We will construct a Singleton-optimal code in this case as an evaluation code, gen-
eralising the construction of MDS codes as Reed-Solomon codes. The main philoso-
phy goes back to [40], but due to a technical obstacle, [40] still required exponential
ﬁeld size. This technicality was overcome by the construction in [39], which we will
present next. Evaluation codes have a multitude of favourable properties, not least
that the ﬁeld size can often be taken to be much smaller than in naïve random code
constructions. Moreover, the multiplicative structure used for designing evaluation
codes can also be exploited when one needs to do computations with the codes in
question.
Let A be a subgroup of Fq of size r + δ −1 and let g = 
i∈A(x −i) be the
polynomial of degree r + δ −1 that vanishes on A. We will construct a storage code
whose nodes are the elements of Fq and whose locality sets are the cosets of A.
Thus, there are
n
r+δ−1 locality sets, each of size r + δ −1. The codewords will be
the evaluations over Fq of polynomials of a certain form. As the rank of the code
that we are designing is k = r · k
r , we can write the messages as a r × k
r matrix
a =
⎛
⎜⎝
a0,0
· · ·
ar−1,0
...
...
...
a0, k
r −1 · · · ar−1, k
r −1
⎞
⎟⎠

Matroid Theory and Storage Codes: Bounds and Constructions
413
over Fq. Now consider the polynomial function
fa =

1 g(x) g(x)2 . . . g(x)
k
r −1
 
·
⎛
⎜⎝
a0,0
· · ·
ar−1,0
...
...
...
a0, k
r −1 · · · ar−1, k
r −1
⎞
⎟⎠·
⎛
⎜⎜⎜⎜⎜⎝
1
x
x2
...
xr−1
⎞
⎟⎟⎟⎟⎟⎠
.
Consider the code
C = { fa(x) : x ∈Fq, a ∈F
r× k
r
q
}.
By design, fa has degree
deg fa ≤(r + δ −1)
k
r −1

+ r −1 = k −1 + (δ −1)
k
r −1

,
and can therefore be computed for every point in Fq by evaluation on any k + (δ −
1)( k
r −1) points. Therefore, the code C protects against
d −1 = n −k −(δ −1)
k
r −1

+ 1
errors. It remains to see that it has locality (r, δ).
To this end, note that the row vector

1 g(x) g(x)2 . . . g(x)
k
r −1
 
·
⎛
⎜⎝
a0,0
· · ·
ar−1,0
...
...
...
a0, k
r −1 · · · ar−1, k
r −1
⎞
⎟⎠
of polynomials is constant over the subgroup A ⊆Fq and thus on all of its cosets by
construction of g. It follows that when restricted to any such coset, the function fa is
a polynomial of degree ≤r −1, and so can be extrapolated to all points in the coset
from any r such evaluation points. This proves the (r, δ)-locality.
As discussed, this construction depends on a collection of assumptions on the
divisibility of parameters that are needed for the rather rigid algebraic structures to
work. Some of these assumptions can be relaxed, using more elaborate evaluation
codes, such as algebraic geometry codes over curves and surfaces [2, 3]. While
this ﬁeld of research is still very much developing, it seems that the rigidity of the
algebraic machinery makes it less suitable for generalisations of the LRC concept,
for example when different nodes are allowed to have different localities.

414
R. Freij-Hollanti et al.
5
Beyond Linear Storage Codes
In this section we will introduce the notion of hierarchical codes, which are natural
generalisations of locally repairable codes. After this, we will brieﬂy describe the
connection between (n, k, d,r, δ, t)-LRCs and polymatroids given in [46].
5.1
Hierarchical Codes
Deﬁnition 18 Let h ≥1 be an integer, and let
(n, k, d, t) = [(n1, k1, d1, t1), . . . , (nh, kh, dh, th)]
be a h-tuple of integer 4-tuples, where ki ≥1, ni, di ≥2, and ti ≥1 for 1 ≤i ≤h.
Then, a coordinate x of a linear [n, k, d] = [n0, k0, d0]-LRC C indexed by E has h-
level hierarchical availability (n, k, d, t) if there are t1 coordinate sets X1, . . . , Xt1 ⊆
E such that
(i) x ∈Xi for i ∈[t1],
(ii) i, j ∈[t1], i ̸= j ⇒Xi ∩X j = {x},
(iii) nXi ≤n1, kXi = k1 and dXi ≥d1 for the punctured
[nXi, kXi, dXi]-code CXi , for i ∈[t1],
(iv) for i ∈[t1], x has (h −1)-level hierarchical availa-
bility [(n2, k2, d2, t2), . . . , (nh, kh, dh, th)] in CXi.
The code C above as well as all the related subcodes CXi should be non-degenerate.
For consistency of the deﬁnition, we say that any symbol in a non-degenerate storage
code has 0-level hierarchical availability.
Example 14 Let C be the code generated by the matrix G in Example 1 and let
x = 2. Then x has 2-level hierarchical availability
(n, k, d, t) = [(6, 3, 3, 1), (3, 2, 2, 2)] .
This follows from Example 2 where CY1 implies the (6, 3, 3, 1)-availability, and the
(3, 2, 2, 2)-availability is implied by CX1 and CX2.
The most general Singleton bound for matroids with hierarchy in the case t = 1
are the following given in [10, 32]:
di(M) ≤ni −ki + 1 −

j>i
(d j −d j+1)
	 ki
k j

−1

,
where we say dh+1 = 1.

Matroid Theory and Storage Codes: Bounds and Constructions
415
5.2
General Codes from Polymatroids
Deﬁnition 19 Let E be a ﬁnite set. A pair P = (ρ, E) is a (ﬁnite) polymatroid on
E with a set function ρ : 2E →R if ρ satisﬁes the following three conditions for all
X, Y ⊆E:
(R1) ρ(∅) = 0 ,
(R2) X ⊆Y ⇒ρ(X) ≤ρ(Y) ,
(R3) ρ(X) + ρ(Y) ≥ρ(X ∪Y) + ρ(X ∩Y) .
Note that a matroid is a polymatroid which additionally satisﬁes the following
two conditions for all X ⊆E:
(R4) ρ(X) ∈Z ,
(R5) ρ(X) ≤|X| .
Using the joint entropy and a result given in [11] one can associate the following
polymatroid to every code.
Deﬁnition 20 Let C be an (n, k)-code over some alphabet A of size s. Then PC =
(ρC, [n]) is the polymatroid on [n] with the set function ρC : 2[n] →R where
ρC(X) =

zX∈CX
|{c ∈C : cX = zX}|
|C|
logs

|C|
|{c ∈C : cX = zX}|

and ρC(∅) = 0.
We remark that for linear codes MC = PC. Using the above deﬁnition of PC, one
can now prove the following useful properties.
Proposition 8 LetC bean(n, k)-codeover A with|A| = s.Thenforthepolymatroid
PC = (ρC, [n]) and any subsets X, Y ⊆[n],
(i) PC(X) ≤|X|,
(ii) |CX∪Y| > |CX| ⇐⇒ρC(X ∪Y) > ρC(X),
(iii) |C| = sρC([n]),
(iv) |C|/|An| = sρC([n])−n.
We remark that, even though |C| = sρC([n]) for nonlinear codes and |CX| = sρC(X)
for all X for linear codes, it is not true in general that |CX| = sρC(X) for X ⊊[n]
for nonlinear codes. This stems from the fact that, for non-linear codes, the uniform
distribution over the code does not necessarily map to the uniform distribution under
coordinate projection.
After scaling the rank function of a ﬁnite polymatroid P = (ρ, E) by a constant
c such that cρ(X) ≤|X| for all X ⊆E, we obtain a polymatroid satisfying axiom
(R5). We will assume that such a scaling has been performed, so that all polymatroids
satisfy axiom (R5).

416
R. Freij-Hollanti et al.
We are now ready to deﬁne a cyclic ﬂat of a polymatroid P = (ρ, E), namely
X ⊆E is a cyclic ﬂat if
ρ(X ∪{e}) > ρ(X) for all e ∈E \ X and ρ(X) −ρ(X \ {x}) < 1 for all x ∈X.
Let P = (ρ, E) be a polymatroid and X ⊆E. The restriction of P to X is the
polymatroid P|X = (ρ|X, X) where ρ|X(Y) = ρ(Y) for Y ⊆X. We can now deﬁne
the distance of P|X as
d(P|X) = min{|Y| : Y ⊆X, ρ|X(X \ Y) < ρ|X(X)}.
Let Z denote the family of cyclic ﬂats of the polymatroid P. Assuming that
E ∈Z , we can deﬁne the parameters n, k, d of P via the cyclic ﬂats and their ranks,
namely
n = |E|, k = ρ(E) and d = ⌊n −k + 1 −max{|X| −ρ(X) : X ∈Z \ E}⌋.
The deﬁnitions of (n, k, d,r, δ, t)i and (n, k, d,r, δ, t)a-polymatroids are carried
over directly from Deﬁnition 16. In addition, the parameters (n, k, d,r, δ, t)i and
(n, k, d,r, δ, t)a of a LRC C are the same as the corresponding parameters for PC.
Using the cyclic ﬂats and similar methods as for matroids, Singleton-type bounds
can be proven for polymatroids in general, which then imply bounds on all objects
related to polymatroids, e.g., matroids, linear and nonlinear LRCs, and hypergraphs.
This is the content of the next section.
5.3
Singleton-Type Bounds for Polymatroids and General
LRCs
It is not clear whether the Singleton-type bounds given for linear LRCs in (2)–(6)
also hold for general LRCs — in general the upper bound on d might have to be
larger. As we will describe brieﬂy in Sect.5, any general LRC can be associated with a
polymatroid that captures the key properties of the LRC. Using this connection we are
able to deﬁne the (n, k, d,r, δ, t)-parameters and information-symbol, systematic-
symbol, and all-symbol locality sets for polymatroids in general.
The class of polymatroids is much bigger than the class of the polymatroids arising
from general LRCs. Hence, it is also not clear whether the Singleton-type bounds
given in (2)–(6) also hold for polymatroids in general. However, from [46], we
obtain a Singleton-type bound for polymatroids in Theorem 10 below. This theorem
shows that all the Singleton-type bounds given in (2)–(6) are polymatroid properties.
Further, the polymatroid result also extends all these bounds by including all the
parameters (n, k, d,r, δ, t) at the same time.

Matroid Theory and Storage Codes: Bounds and Constructions
417
The methods used to prove the Singleton-type bound given for polymatroids
in Theorem 10 are similar to those used for proving the Singleton-type bound for
matroids in Theorem 5. Especially, the notion of cyclic ﬂats is generalised to poly-
matroids and used as the key tool in the proof. However, some obstacles occur since
we are dealing with real-valued rank functions in the case of polymatroids instead
of integer-valued rank functions, which was the case for matroids. As a direct con-
sequence of Theorem 10, the Singleton-type bounds given in (2)–(6) are valid for all
objects associated to polymatroids.
Theorem 10 ([46] Singleton-type bound for polymatroids) Let P = (ρ, E) be an
information-set (n, k, d,r, δ, t)i-polymatroid. Then
d ≤n −⌈k⌉+ 1 −
	t(⌈k⌉−1) + 1
t(r −1) + 1

−1

(δ −1).
(13)
Theorem 10 is stated for information-symbol locality. This implies that the bound
(13) is also valid for systematic-symbol and all-symbol locality. Hence, as a direct
corollary, the bounds (2)–(13) hold for information-symbol, systematic-symbol, and
all-symbol locality for all objects associated to polymatroids, e.g., entropy functions,
general LRCs, hypergraphs, matroids, linear LRCs, graphs and many more. If we
restrict to systematic linear codes, then the bound also holds for PIR codes [9, Def-
inition 4]. The connection is not as straightforward in the nonlinear case, since the
deﬁnitions of a repair group are then slightly different for LRCs (as deﬁned here)
and PIR codes, while coinciding in the linear case.
The bound (4), for all-symbol LRCs (as subsets of size |B|K of Bαn, where B
is a ﬁnite set, A = Bα is the alphabet, and α and K are integers), follows from a
result given in [27]. The bound (5), for all-symbol LRCs (as a linear subspace of
Fαn
q with the alphabet A = Fα
q), is given in [34]. This result is slightly improved for
information-symbol locality in [18]. The bound (6), for (n, k, d,r, t)s-LRCs where
k is a positive integer, follows from a result given in [31]. The following bound for
(n, k, d,r, t)a-LRCs with integral k was given in [41],
d ≤n −k + 1 −
t
i=1
!k −1
ri
"
.
One parameter which has not been included above is the alphabet size. Small
alphabet sizes are important in many applications because of implementation and
efﬁciency reasons. The bound (14) below takes the alphabet size into account, but is
only inductively formulated. Before stating this bound we introduce the following
notation:
k(q)
opt(n, d) = max{k : C is an (n, k, d)-code over an alphabet of size q}.

418
R. Freij-Hollanti et al.
By [6], an all-symbol (n, k, d,r)-LRC over a ﬁnite alphabet A of size q satisﬁes
k ≤min
s∈Z+(sr + k(q)
opt(n −s(r + 1), d)).
(14)
It is a hard open problem in classical coding theory to obtain a value for the parameter
k(s)
opt(n, d) for linear codes. This problem seems to be even harder for codes in general.
However,byusingotherknownbounds,suchasthePlotkinboundorGreismerbound,
it is possible to give an explicit value for k(s)
opt(n, d) for some classes of parameters
(s, n, d). This has been done for example in [33].
We remark that when considering nonlinear LRCs, some extra care has to be taken
in terms of how to deﬁne the concepts associated with the LRCs. Two equivalent
deﬁnitions in the linear case may differ in the nonlinear case. In this chapter, we
have chosen to consider δ as a parameter for the local distance of the repair sets, i.e.,
any node in a repair set R can be repaired by any other |R| −δ + 1 nodes of R. The
condition used in [6, 27, 31, 41] is for δ = 2 only assuming that a speciﬁc node in
a repair set R can be repaired by the rest of the nodes of R. It is not assumed that
any node in R can be repaired by the other nodes of R, i.e., that the local distance is
2. A Singleton bound using the weaker condition of guaranteeing only repair of one
node in each repair set implies directly that the same upper bound on d is true for
the case with local distance 2.
6
Conclusions and Further Research
We have shown how viewing storage codes from a matroidal perspective helps
our understanding of local repairability, both for constructions and for fundamental
bounds. However, many central problems about linear LRCs boil down to notoriously
hard representability problems in matroid theory.
A famous conjecture, with several consequences for many mathematical objects,
is the so called MDS-conjecture. This conjecture states that, for a given ﬁnite ﬁeld
Fq and a given k, every [n, k, d]-MDS code over Fq has n ≤q + 1, unless in some
special cases. Currently, theconjectureis knowntoholdonlyifq is aprime[1]. Linear
Singleton-optimal LRCs may be seen as a generalisation of linear MDS codes. An
interesting problem would therefore be to consider an upper bound on n for linear
Singleton-optimal LRCs over a certain ﬁeld size q with ﬁxed parameters (k,r, δ, t).
In this setting, a sufﬁciently good upper bound on n would be a good result.
Instead of ﬁxing the Singleton-optimality and trying to optimise the ﬁeld size, we
could also ﬁx the ﬁeld Fq, and try to optimise the locality parameters. This would
give us bounds on the form
d ≤n −k + 1 −
	k
r

−1

(δ −1) −p(q, n, k,r, δ),

Matroid Theory and Storage Codes: Bounds and Constructions
419
wherethedependenceontheﬁeldsizeq isisolatedtoa“penalty”term p(q, n, k,r, δ).
Partial results in this direction are given by the Cadambe–Mazumdar bound [6], and
LRC versions of the Griesmer and Plotkin bounds [33]. However, the optimality of
these bounds is only known for certain ranges of parameters. Further research in this
direction is deﬁnitely needed, but seems to lead away from the most obvious uses of
matroid theory.
Finally, it would be interesting to characterise all Singleton-optimal LRCs up to
matroid isomorphism. The constructions discussed in this paper appear to be rather
rigid, and unique up to shifting a few “slack” elements between different locality
sets. However, it appears to be difﬁcult to prove that all Singleton-optimal matroids
must have this form. Once a complete characterisation of Singleton-optimal matroids
has been obtained, this could also be taken as a starting point for possibly ﬁnding
Singleton-optimal nonlinear codes in the parameter regimes where no Singleton-
optimal linear codes exist.
Appendix: More About Matroid Theory
A matroid realisation of an F-linear matroid M has two geometric interpretations.
Firstly, we may think of a matrix representing M as a collection of n column vectors
in Fk. As the matroid structure is invariant under row operations, or in other words
under change of basis in Fk, we tend to think of M as a conﬁguration of n points in
abstract projective k-space.
The second interpretation comes from studying the row space of the matrix, as
an embedding of Fk into Fn. Row operations correspond to a change of basis in
Fk, and hence every matroid representation can be thought of as a k-dimensional
subspace of Fn. In other words, a matroid representation is a point in the Grassman-
nian Gr(n, k; F), and Gr(n, k; F) has a stratiﬁcation as a union of realisation spaces
R(M), where M ranges over all F-representable matroids of size n and rank k. This
perspective allows a matroidal perspective also on the subspace codes discussed in
chapters“Codes Endowed with the Rank Metric”–“Generalizing Subspace Codes to
Flag Codes Using Group Actions”, where the codewords themselves are matroid
representations. However, so far this perspective has not brought any new insights
to the topic.
Another instance where matroids appear naturally in mathematics is graph theory.
Let Γ be a ﬁnite graph with edge set E. We obtain a matroid MΓ = (I , E), where
I ⊆E is independent if the subgraph ΓI ⊆Γ induced on I ⊆E is a forest, i.e.,
has no cycles. A matroid that is isomorphic to MΓ for some graph Γ is said to be a
graphical matroid.
Example 15 The matrix G and the graph Γ given below generate the same matroid,
regardless of the ﬁeld over which G is deﬁned.

420
R. Freij-Hollanti et al.
Some examples of independent sets in G and Γ are {3, 4, 6}, {1, 2, 3, 5}, {2, 3, 4, 6}.
The set X = {5, 6, 7} is dependent in MΓ as these edges form a cycle, and it is
dependent in MG as the submatrix
G(X) =
5
6
7
0
1
1
0
1
1
−1 −1 0
1
0 −1
has linearly dependent columns.
Indeed, graphical matroids are representable over any ﬁeld F. To see this, for a
graph Γ with edge set E, we will construct a matrix G(Γ ) over F with column set
E as follows. Choose an arbitrary spanning forest T ⊆E in Γ , and index the rows
of G(Γ ) by T . Thus G(Γ ) is a T × E-matrix. Choose an arbitrary orientation for
each edge in the graph. For e ∈T ⊆E and uv ∈E, the entry in position (e, {uv})
is 1 (respectively −1) if e is traversed forward (respectively backward) in the unique
path from u to v in the spanning forest T . In particular, the submatrix G(Γ )(T ) is
an identity matrix. It is straightforward to check that the independent sets in G(Γ )
are exactly the noncyclic sets in Γ .
Example 16 The matrix G in Example 15 is G(Γ ) where Γ is the graph in the same
example, and the spanning forest T is chosen to be {1, 2, 3, 4}.
The restriction to X ⊆E of a graphical matroid MΓ is obtained by the subgraph
of Γ containing precisely the edges in X.
A third example of matroids occurring naturally in mathematics are algebraic
matroids [22]. These are associated to ﬁeld extensions F : K together with a ﬁnite
point sets E ⊆K, where the independent sets are those I ⊆E that are algebraically
independent over F. In particular, elements that are algebraic over F have rank zero,
and in general ρ(I) is the transcendence degree of the ﬁeld extension F(I) : F.
It is rather easy to see that every F-linear matroid is also algebraic over F. Indeed,
let X1, . . . , Xk be indeterminates, and let
g : Fk →F(X1, . . . , Xk)

Matroid Theory and Storage Codes: Bounds and Constructions
421
Fig. 2 The Vamos matroid
of size 8 and rank 4, which is
not algebraically
representable
be given by ei →Xi for i = 1, . . . , k. Then J ⊆E is linearly independent over
F if and only if {g( j) : j ∈J} is algebraically independent over F. Over ﬁelds of
characteristic zero the converse also holds, so that all algebraic matroids have a linear
representation. However, in positive characteristic there exist algebraic matroids that
are not linearly representable. For example, the non-Pappus matroid of Example 4
is algebraically representable over F4, although it is not linearly representable over
any ﬁeld [21]. The smallest example of a matroid that is not algebraic over any ﬁeld
is the Vamos matroid, in Fig.2 [15].
Deﬁnition 21 The dual of M = (ρ, E) is M∗= (ρ∗, E), where
ρ∗(X) = |X| + ρ(E \ X) −ρ(E).
The deﬁnition of the dual matroid lies in the heart of matroid theory, and has pro-
found interpretations. In geometric terms, let M be represented by a k-dimensional
subspace V of Fn. Then, the matroid dual M∗is represented by the orthogonal com-
plement V ⊥⊆Fn. Surprisingly and seemingly unrelatedly, if Γ is a planar graph
and M = MΓ is a graphical matroid, then M∗= M ¯Γ , where ¯Γ is the planar dual
of Γ . Moreover, the dual M∗
Γ of a graphical matroid is graphical if and only if Γ is
planar.
Deﬁnition 22 The contraction of X ⊆E in the matroid M = (ρ, E) is M/X =
(ρ′, M \ X), where ρ′(Y) = ρ(Y ∪X) −ρ(X).
Contraction is the dual operation of deletion, in the sense that M/X = (M∗
|E\X)∗.
The terminology comes from graphical matroids, where contraction of the edge
e ∈E corresponds to deleting e and identifying its endpoints in the graph. Notice
that it follows directly from submodularity of the rank function that ρM/X(Y) ≤
ρM|E\X(Y) for every Y ⊆E \ X. In terms of subspace representations, contraction of
e ∈E corresponds to intersecting the subspace that represents M with the hyperplane
{xe = 0}.
As matroids are used as an abstraction for linear codes, it would be desirable to
have a way to go back from matroids to codes, namely to determine whether a given
matroid is representable, and when it is, to ﬁnd such a representation. Unfortunately,
there is no simple criterion to determine representability [25, 43]. However, there are
a plethora of sufﬁcient criteria to prove nonrepresentability, both over a given ﬁeld
and over ﬁelds in general. In recent years, these methods have been used to prove
two long-standing conjectures, that we will discuss in sections Rota’s Conjecture
and Most Matroids are Nonrepresentable respectively.

422
R. Freij-Hollanti et al.
Rota’s Conjecture
While there is no simple criterion to determine linear representability, the situation
is much more promising if we consider representations over a ﬁxed ﬁeld. It has
been known since 1958, that there is a simple criterion for when a matroid is binary
representable.
Theorem 11 ([42]) Let M = (ρ, E) be a matroid. The following two conditions are
equivalent.
1. M is linearly representable over F2.
2. There are no sets X ⊆Y ⊆E such that M|Y/X is isomorphic to the uniform
matroid U 2
4 .
In essence, this means that the only obstruction that needs to be overcome in
order to be representable over the binary alphabet, is that no more than three nonzero
points can ﬁt in the same plane. For further reference, we say that a minor of the
matroid M = (ρ, E) is a matroid of the form M|Y/X, for X ⊆Y ⊆E. Clearly, if
M is representable over F, then so is all its minors. Let L(F) be the class of matroids
that are not representable over F, but such that all of their minors are F-representable.
Then the class of F-representable matroids can be written as the class of matroids
that does not contain any matroid from L(F) as a minor. Gian-Carlo Rota conjectured
in 1970 that L(F) is a ﬁnite set for all ﬁnite ﬁelds F. A proof of this conjecture was
announced by Geelen, Gerards and Whittle in 2014, but the details of the proof still
remain to written up [12].
Theorem 12 For any ﬁnite ﬁeld F, there is a ﬁnite set L(F) of matroids such that
any matroid M is representable if and only if it contains no element from L(F) as a
minor.
Since the 1970s, it has been known that a matroid is representable over F3 if and
only if it avoids the uniform matroids U 2
5 , U 3
5 , the Fano plane P2(F2), and its dual
P2(F2)∗as minors. The list L(F4) has seven elements, and was given explicitly in
2000. For larger ﬁelds, the explicit list is not known, and there is little hope to even
ﬁnd useful bounds on its size.
Most Matroids are Nonrepresentable
For a ﬁxed ﬁnite ﬁeld F, it follows rather immediately from the minor-avoiding
description in the last section that the fraction of n-symbol matroids that is F-
representable goes to zero as n →∞. It has long been a folklore conjecture that
this is true even when representations over arbitrary ﬁelds are allowed. However, it
was only in 2016 that a veriﬁable proof of this claim was announced [26].

Matroid Theory and Storage Codes: Bounds and Constructions
423
Theorem 13
lim
n→∞
#linear matroids on n elements
#matroids on n elements
= 0.
The proof is via estimates of the denominator and enumerator of the expression
in Theorem13 separately. Indeed, it is shown in [19] that the number of matroids on
n nodes is at least Ω(2(2−ε)n) for every ε > 0. The proof of Theorem 13 thus boiled
down to proving that the number of representable matroids is O(2n3). This is in turn
achieved by bounding the number of so called zero-patterns of polynomials.
Gammoid Construction of Singleton-Optimal LRCs
For completeness, we end this appendix with a theorem that explicitly presents the
matroids constructed in Theorem 7 as gammoids. As discussed in Sect.4.2, this
proves the existence of Singleton-optimal linear LRCs whenever a set system satis-
fying (8) exists.
Theorem 14 ([47],
M(F1, . . . , Fm, E; k; ρ)-matroids
are
gammoids)
Let
M(F1, . . . , Fm; ρ) be a matroid given by Theorem 7 and deﬁne s : E →2[m] where
s(x) = {i ∈[m] : x ∈Fi}. Then M(F1, . . . , Fm, E; k; ρ) is equal to the gammoid
M(Γ, E, T ), where Γ = (V, D) is the directed graph with
(i) V = E ∪H ∪T where E, H, T are pairwise disjoint,
(ii) T = [k],
(iii) H equals the union of the pairwise disjoint sets
H1, . . . , Hm, H≥2, where
|Hi| = ρ(Fi) −|{x ∈Fi : |s(x)| ≥2}| for i ∈[m],
H≥2 = {hy : y ∈E, |s(y)| ≥2},
(iv) D = D1 ∪D2 ∪D3, where
D1 = 
i∈[m]{(−→
x, y) : x ∈E, s(x) = {i}, y ∈Hi},
D2 = {(−−→
x, hy) : x ∈E, hy ∈H≥2, s(x) ⊆s(y)},
D3 = {(−→
x, y) : x ∈H, y ∈T }.
References
1. S. Ball, On sets of vectors of a ﬁnite vector space in which every subset of basis size is a basis.
J. Eur. Math. Soc. 14, 733–748 (2012)
2. A. Barg, I. Tamo, S. Vl˘adu¸t, Locally recoverable codes on algebraic curves (2016),
arXiv:1603.08876
3. A. Barg, K. Haymaker, E. Howe, G. Matthews, A. Várilly-Alvarado, Locally recoverable codes
from algebraic curves and surfaces (2017), arXiv:1701.05212
4. J.E. Bonin, A. de Mier, The lattice of cyclic ﬂats of a matroid. Ann. Comb. 12, 155–170 (2008)

424
R. Freij-Hollanti et al.
5. T. Britz, C.G. Rutherford, Covering radii are not matroid invariants. Discret. Math. 296, 117–
120 (2005)
6. V. Cadambe, A. Mazumdar, An upper bound on the size of locally recoverable codes, in
International Symposium on Network Coding (2013), pp. 1–5
7. A. Dimakis, P.B. Godfrey, Y. Wu, M.J. Wainwright, K. Ramchandran, Network coding for
distributed storage systems. IEEE Trans. Inf. Theory 56(9), 4539–4551 (2010)
8. T. Ernvall, T. Westerbäck, R. Freij-Hollanti, C. Hollanti, Constructions and properties of linear
locally repairable codes. IEEE Trans. Inf. Theory 62, 5296–5315 (2016)
9. A. Fazeli, A. Vardy, E. Yaakobi, PIR with low storage overhead: coding instead of replication
(2015), arXiv:1505.06241
10. R. Freij-Hollanti, T. Westerbäck, C. Hollanti, Locally repairable codes with availability and
hierarchy: matroid theory via examples, in International Zürich Seminar on Communications
(IEEE/ETH, 2016), pp. 45–49
11. S. Fujishige, Polymatroidal dependence structure of a set of random variables. Inf. Control
39(1), 55–72 (1978)
12. J. Geelen, B. Gerards, G. Whittle, Solving Rota’s conjecture. Not. Am. Math. Soc. 61, 736–743
(2014)
13. P. Gopalan, C. Huang, H. Simitci, S. Yekhanin, On the locality of codeword symbols. IEEE
Trans. Inf. Theory 58(11), 6925–6934 (2012)
14. C. Huang, M. Chen, J. Lin, Pyramid codes: ﬂexible schemes to trade space for access efﬁciency
in reliable data storage systems, in International Symposium on Network Computation and
Applications (IEEE, 2007), pp. 79–86
15. A. Ingleton, R. Main, Non-algebraic matroids exist. Bull. Lond. Math. Soc. 7, 144–146 (1975)
16. Y. Ishai, E. Kushilevitz, R. Ostrovsky, A. Sahai, Batch codes and their applications, in The 36th
ACM Symposium on Theory of Computing (STOC) (2004)
17. R. Jurrius, R. Pellikaan, Truncation formulas for invariant polynomials of matroids and geo-
metric lattices. Math. Comput. Sci. 6, 121–133 (2012)
18. G.M. Kamath, N. Prakash, V. Lalitha, P.V. Kumar, Codes with local regeneration and erasure
correction. IEEE Trans. Inf. Theory 60(8), 4637–4660 (2014)
19. D. Knuth, The asymmetric number of geometries. J. Comb. Theory Ser. A 16, 398–400 (1974)
20. B. Lindström, On the vector representations of induced matroids. Bull. Lond. Math. Soc. 5,
85–90 (1973)
21. B. Lindström, On p-polynomial representations of projective geometries in algebraic combi-
natorial geometries. Math. Scand. 63, 36–42 (1988)
22. B. Lindström, On algebraic matroids. Discret. Math. 111, 357–359 (1993)
23. H. Lipmaa, V. Skachek, Linear batch codes, in The 4th International Castle Meeting on Coding
Theory and Applications (4ICMCTA) (2015)
24. D. Mayhew, M. Newman, D. Welsh, G. Whittle, On the asymptotic proportion of connected
matroids. Eur. J. Comb. 32(6), 882–890 (2011)
25. D. Mayhew, M. Newman, G. Whittle, Yes, the missing axiom of matroid theory is lost forever
(2015), arXiv:1412.8399
26. P. Nelson, Almost all matroids are non-representable, arXiv:1605.04288
27. D. Papailiopoulos, A. Dimakis, Locally repairable codes, in International Symposium on Infor-
mation Theory (IEEE, 2012), pp. 2771–2775
28. R. Pendavingh, J. van der Pol, On the number of matroids compared to the number of sparse
paving matroids. Electron. J. Comb. 22 (2015), 17pp
29. A. Pöllänen, T. Westerbäck, R. Freij-Hollanti, C. Hollanti, Improved singleton-type bounds for
locally repairable codes, in International Symposium on Information Theory (IEEE, 2016), pp.
1586–1590
30. N. Prakash, G.M. Kamath, V. Lalitha, P.V. Kumar, Optimal linear codes with a local-error-
correction property, in International Symposium on Information Theory (IEEE, 2012), pp.
2776–2780
31. A.S. Rawat, D. Papailiopoulos, A. Dimakis, S. Vishwanath, Locality and availability in dis-
tributed storage (2014), arXiv:1402.2011v1

Matroid Theory and Storage Codes: Bounds and Constructions
425
32. B. Sasidharan, G.K. Agarwal, P.V. Kumar, Codes with hierarchical locality (2015),
arXiv:1501.06683v1
33. N. Silberstein, A. Zeh, Optimal binary locally repairable codes via anticodes (2015),
arXiv:1501.07114v1
34. N. Silberstein, A.S. Rawat, O. Koyluoglu, S. Vishwanath, Optimal locally repairable codes
via rank-metric codes, in International Symposium on Information Theory (IEEE, 2013), pp.
1819–1823
35. J.A. Sims, Some problems in matroid theory. Ph.D. thesis, Oxford University (1980)
36. R.C. Singleton, Maximum distance q-nary codes. IEEE Trans. Inf. Theory 10(2), 116–118
(1964)
37. A. Skorobogatov, Linear codes, strata of Grassmannians, and the problems of Segre, in Inter-
national Workshop on Coding Theory and Algebraic Geometry (1992), pp. 210–223
38. W. Song, C. Yuen, S.H. Dau, T.J. Li, Optimal locally repairable linear codes. IEEE J. Sel. Areas
Commun. 32(5), 1019–1036 (2014)
39. I. Tamo, A. Barg, A family of optimal locally recoverable codes. IEEE Trans. Inf. Theory
60(8), 4661–4676 (2014)
40. I. Tamo, D. Papailiopoulos, A. Dimakis, Optimal locally repairable codes and connections to
matroid theory, in International Symposium on Information Theory (IEEE, 2013), pp. 1814–
1818
41. I. Tamo, A. Barg, A. Frolov, Bounds on the parameters of locally recoverable codes. IEEE
Trans. Inf. Theory 62(6), 3070–3083 (2016)
42. W. Tutte, A homotopy theorem for matroids, I, II. Trans. Am. Math. Soc. 88, 148–178 (1958)
43. P. Vámos, The missing axiom of matroid theory is lost forever. J. Lond. Math. Soc. 18, 403–408
(1978)
44. A. Wang, Z. Zhang, Repair locality with multiple erasure tolerance. IEEE Trans. Inf. Theory
60(11), 6979–6987 (2014)
45. A. Wang, Z. Zhang, An integer programming-based bound for locally repairable codes. IEEE
Trans. Inf. Theory 61(10), 5280–5294 (2015)
46. T. Westerbäck, R. Freij, C. Hollanti, Applications of polymatroid theory to distributed storage
systems, in Allerton Conference on Communication, Control, and Computing (2015), pp. 231–
237
47. T. Westerbäck, R. Freij-Hollanti, T. Ernvall, C. Hollanti, On the combinatorics of locally
repairable codes via matroid theory. IEEE Trans. Inf. Theory 62, 5296–5315 (2016)
48. H. Whitney, On the abstract properties of linear dependence. Am. J. Math. 57, 509–533 (1935)
49. H. Zhang, V. Skachek, Bounds for batch codes with restricted query size, in IEEE International
Symposium on Information Theory (ISIT) (2016)

Batch and PIR Codes and Their Connections
to Locally Repairable Codes
Vitaly Skachek
Abstract Tworelatedfamiliesofcodesarestudied:batchcodesandcodesforprivate
information retrieval. These two families can be viewed as natural generalizations of
locally repairable codes, which were extensively studied in the context of coding for
fault tolerance in distributed data storage systems. Bounds on the parameters of the
codes, as well as basic constructions, are presented. Connections between different
code families are discussed.
1
Introduction
In this chapter, we discuss two related families of codes: batch codes and codes
for private information retrieval (PIR codes). These two families can be viewed as
natural generalizations of locally repairable codes, which were extensively studied
in the context of coding for fault tolerance in distributed data storage systems.
Batch codes were ﬁrst presented in [15], where it was suggested to use them
for load balancing in the multi-server distributed data storage systems. It was also
suggested in [15] to use these codes in private information retrieval. A number
of constructions of batch codes were presented therein. Later, the authors of [33]
proposed to use so-called “switch codes” for facilitating the routing of data in the
network switches. It turns out, however, that switch codes are a special case of batch
codes.
Coding schemes for PIR were studied in [12]. The authors showed that a family of
codes, which is a relaxed version of batch codes, can be employed in classical linear
PIR schemes in order to reduce the redundant information stored in a distributed
server system. This relaxed version of the batch codes is termed PIR codes.
In these schemes, typically a distributed data storage system is considered. The
coded words are written across the block of disks (servers), where each disk stores
a single symbol (or a group of symbols). The reading of data is done by accessing
V. Skachek (B)
Institute of Computer Science, University of Tartu, 50409 Tartu, Estonia
e-mail: vitaly.skachek@ut.ee
© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_16
427

428
V. Skachek
a small number of disks. Mathematically, this can be equivalently represented by
the assumption that each information symbol depends on a small number of other
symbols. However, the type of requested queries varies in different code models.
Thus, in PIR codes several copies of the same information symbols are requested,
while in batch codes combinations of different symbols are also possible.
In this chapter, we mathematically deﬁne the corresponding families of codes, and
study their properties. We derive bounds on the parameters of such codes, and show
some basic constructions. We also show relations between different families of codes.
In Sect.3, we introduce various models of locally repairable codes. In Sect.4, we
deﬁne batch codes. In Sect.5, we discuss properties of linear batch codes. In Sect.6,
we introduce codes for private information retrieval. In Sect.7, we study connections
between locally repairable and batch/PIR codes. In Sects.8 and 9, we present bounds
on the parameters of various families of codes. In Sect.10, we pose some open
questions. For the sake of completeness, we introduce all necessary notations and
deﬁnitions, which are used in the sequel.
2
General Settings
Throughout this chapter, we denote by N the set of nonnegative integer numbers. For
n ∈N, deﬁne [n] ≜{1, 2, . . . , n}. Let ei be the row vector having one at position i
and zeros elsewhere (the length of vectors will be clear from the context).
LetΣ beaﬁnitealphabet.Letx = (x1, x2, . . . , xk) ∈Σk beaninformationvector.
The code is a set of coded vectors

y = (y1, y2, . . . , yn) = C (x) : x ∈Σk
⊆Σn ,
where C : Σk →Σn is a bijection, for some n ∈N. By slightly abusing the notation,
sometimes we denote the above set by C .
Let F = Fq be a ﬁnite ﬁeld with q elements, where q is a prime power. If C :
Fk →Fn is a linear mapping, then C is a linear [n, k, d] code over F. Here, d is the
minimum Hamming distance of C . In that case, the encoding can be viewed as a
multiplication by a k × n generator matrix G over F of an information vector x,
y = x · G .
(1)
The rate of the code is deﬁned as R ≜k/n.
3
Codes with Locality and Availability
Codes with locality were proposed for use in the distributed data storage systems [11].
In such systems, the data is stored in many disks (servers), and these servers may
fail from time to time. It is possible to use erasure-correcting codes, where parts of a

Batch and PIR Codes and Their Connections …
429
codeword are stored in different servers. A failure of one server can be viewed as an
erasure of a symbol or of a group of symbols. In order to repair the erased symbols,
there is a need to bring a few other symbols from other servers. In general, it would
be beneﬁcial to minimize the trafﬁc in the network. For an overview of coding for
distributed storage systems the reader is referred to chapter“An Overview of Coding
for Distributed Storage Systems”. We continue by recalling the deﬁnition of locally
repairable codes (LRCs).
Deﬁnition 1 The code C has locality r ≥1, if for any y ∈C , any symbol in y can
be recovered by using at most r other symbols of y.
Codes with low locality were extensively discussed, for example, in [11]. A some-
what similar family of codes, known as one-step majority-logic decodable codes, was
investigated in the classical literature [18]. Recently, the bounds on the parameters
of LRCs were derived in [14]. It was shown therein that the parameters of a linear
[n, k, d] code with locality r over F satisfy1:
n ≥k + d +
k
r

−2 .
(2)
This bound can be viewed as a reﬁnement of the classical Singleton bound, where
⌈k
r ⌉−1 is an additive penalty for locality of the code, when compared to the classical
Singleton bound. The proof is done by iterative expurgating of the code, and by taking
into account that there are dependencies between sets ofr + 1 symbols, which consist
of an arbitrary symbol in y and its recovery set. The bound in (2) is tight. In fact,
several known constructions attain it with equality (see, for example, [14, 26, 30]).
Assume that the linear code C is systematic, i.e. the matrix G contains a k × k
identity submatrix I. Then, the symbols of y corresponding to I are called information
symbols. It is possible to require recoverability of information symbols only (from
sets of size at most r). In that case, the code is said to have locality of information
symbols. Otherwise, if all symbols of y are recoverable from small sets, the code has
locality of all symbols.
The above model was extended to codes with locality and availability in [24].
Deﬁnition 2 The code C has locality r ≥1 and availability δ ≥1, if for any y ∈C ,
any symbol in y can be reconstructed by using any of δ disjoint sets of symbols, each
set is of size at most r.
In [34], the authors consider linear codes with locality r and availability δ of all
symbols. They derive the following bound on the parameters of the code:
n ≥k + d +
δ(k −1) + 1
δ(r −1) + 1

−2 .
(3)
1This result is proven in Theorem6, Chap.“An Overview of Coding for Distributed Storage Sys-
tems”.

430
V. Skachek
In [24], systematic codes (linear or non-linear) are considered, with locality r and
availability δ of information symbols. The authors show the bound analogues to (3)
for that case. In particular, we observe that when availability δ = 1, i.e. there is only
one recovery set for each symbol, then (3) coincides with (2). The proof technique
in both cases is based on the idea similar to that of [14].
Another related model is considered in [23]. In that model, several different sym-
bols are recovered from a small set of recovery symbols. By building on the ideas
in the previous works, the authors derive a variation of the bound (3) for the model
under consideration. Other related works, for example, include [6, 13, 19, 21, 29,
35, 36] and the references therein.2
4
Batch Codes
Batchcodeswereﬁrstpresentedinthecryptographiccommunityin[15].Inthatwork,
the authors proposed to use batch codes for load balancing in the distributed systems,
as well as for private information retrieval. The authors of [15] have also presented
a few constructions of various families of batch codes. Those constructions were
based on recursive application of simple batch codes (so-called “sub-cube codes”),
on classical Reed-Muller codes, on locally decodable codes, and others.
The following deﬁnition is based on [15].
Deﬁnition 3 Let Σ be a ﬁnite alphabet. We say that C is an (k, n, t, M, τ)Σ batch
code over a ﬁnite alphabet Σ if it encodes any string x = (x1, x2, . . . , xk) ∈Σk
into M strings (buckets) of total length n over Σ, namely y1, y2, . . . , yM, such that
for each t-tuple (batch) of (not necessarily distinct) indices i1, i2, . . . , it ∈[k], the
symbols xi1, xi2, . . . , xit can be retrieved by reading at most τ symbols from each
bucket.
More formally, by following the presentation in [31], we can state an equivalent
deﬁnition.
Deﬁnition 4 An (k, n, t, M, τ)Σ batch code C over a ﬁnite alphabet Σ is deﬁned
by an encoding mapping C : Σk →(Σ∗)M (there are M buckets in total), and a
decoding mapping D : Σn × [k]t →Σt, such that
1. The total length of all buckets is n;
2. For any x ∈Σk and
i1, i2, . . . , it ∈[k] ,
(4)
D (C (x), i1, i2, . . . , it) = (xi1, xi2, . . . , xit) ,
and D depends only on τ symbols in each bucket in C (x).
2In particular, the use of matroids in bounding the parameters of various families of codes with
locality is thoroughly treated in chapter“Matroid Theory and Storage Codes: Bounds and Construc-
tions”.

Batch and PIR Codes and Their Connections …
431
In particular, an interesting case for consideration is when τ = 1, namely only
at most one symbol is read from each bucket. If the requested information sym-
bols (xi1, xi2, . . . , xit) can be reconstructed from the data read by t different users
independently (i.e., the symbol xiℓis reconstructed by the user ℓ, ℓ= 1, 2, . . . , t,
respectively), and the sets of the symbols read by these t users are all disjoint, such
a model is called a multiset batch code.
In the sequel, we only consider multiset batch codes, and therefore we usually
omit the word “multiset” for convenience.
An important special case of batch codes is deﬁned as follows.
Deﬁnition 5 ([15]) A primitive batch code is a batch code, where each bucket con-
tains exactly one symbol. In particular, n = M.
Following the work [15], a number of subsequent papers have studied combi-
natorial batch codes. In combinatorial batch codes, a number of replicas of the
information symbols are stored in different positions in the codeword. Usually, the
symbols are associated with servers according to some optimal or sub-optimal com-
binatorial objects, such as block designs. Combinatorial batch codes were studied,
for example, in [2, 4, 5, 27, 28].
5
Linear Batch Codes
In what follows, we consider a special case of primitive multiset batch codes with
n = M and τ = 1. Under these conditions, each symbol can be viewed as a separate
bucket, and only one reading per bucket is allowed.
We assume that the information and the coded symbols are taken from the ﬁnite
ﬁeld F = Fq, where q is a prime power. Additionally, we assume that the encoding
mapping C : Fk →Fn is linear over F, and therefore the code C is a linear [n, k]
code over F. In that case, C falls under the linear coding framework deﬁned in (1).
We also refer to the parameter t as the size of a query of the code. The batch code
with the parameters n, k and t over Fq is denoted as [n, k, t]q-batch code (or simply
[n, k, t]-batch code) in the sequel.
This framework was ﬁrst considered in [17], and the similarities with locally
repairable codes were mentioned. The main difference between these two families,
however, is that the supported query types are different. In batch codes we are inter-
ested in reconstruction of the information symbols in x, while in locally repairable
codes the coded symbols in y are to be recovered.
The following simple result was established in [17, Theorem1].
Theorem 1 Let C be an [n, k, t]q batch code. It is possible to retrieve xi1, xi2, . . . , xit
by t different users in the primitive multiset batch code model (where the symbol xiℓ
is retrieved by the user ℓ, ℓ= 1, 2, . . . , t, respectively) if and only if there exist t
non-intersecting sets T1, T2, . . . , Tt of indices of columns in the generator matrix G,
and for each Tℓ, 1 ≤ℓ≤t, there exists a linear combination of columns of G indexed
by that set, which equals to the column vector eT
iℓ, for all ℓ∈[t].

432
V. Skachek
The reader can ﬁnd the proof of this theorem in [17]. Next, we show examples
that further illustrate this concept.
Example 1 ([15]) Consider the following binary 2 × 3 generator matrix of a batch
code C given as
G =
 1 0 1
0 1 1

.
Thecorrespondingcodeisasub-cubecodeconstructedin[15,Sect.3.2].Byusingthis
code,theinformationsymbols(x1, x2)areencodedinto(y1, y2, y3)=(x1, x2, x1+ x2).
Assume that the query contains two different symbols (x1, x2). Then, we can
retrieve these symbols directly by using the following equations:
 x1 = y1
x2 = y2 .
Alternatively, assume that the query contains two copies of the same symbol, for
example (x1, x1). Then, we can retrieve these symbols by using the following equa-
tions:
 x1 = y1
x1 = y2 + y3 .
Similarly, (x2, x2) can be retrieved. We conclude that C is a [3, 2, 2]2 batch code.
Example 2 ([17]) Pick the following binary 4 × 9 generator matrix of a batch code
C given as
G =
⎛
⎜⎜⎝
1 0 1 0 0 0 1 0 1
0 1 1 0 0 0 0 1 1
0 0 0 1 0 1 1 0 1
0 0 0 0 1 1 0 1 1
⎞
⎟⎟⎠.
The corresponding code is a second-order sub-cube code constructed as in [15,
Sect.3.2].
Assume that the query contains the information symbols (x1, x1, x2, x2). Then,
we can retrieve these symbols using the following equations:
⎧
⎪⎪⎨
⎪⎪⎩
x1 = y1
x1 = y2 + y3
x2 = y5 + y8
x2 = y4 + y6 + y7 + y9
.
It can be veriﬁed in a similar manner that any 4-tuple (xi1, xi2, xi3, xi4), where
i1, i2, i3, i4 ∈[4], can be retrieved by using the symbols of y, by using each symbol
at most once. We conclude that C is a [9, 4, 4]2 batch code.

Batch and PIR Codes and Their Connections …
433
Example 3 ([32]) Pick the following binary 3 × 7 generator matrix of a batch code
C given as
G =
⎛
⎝
1 0 0 1 1 0 1
0 1 0 1 0 1 1
0 0 1 0 1 1 1
⎞
⎠.
The corresponding code is a binary [7, 3, 4] classical error-correcting simplex code.
Assume that the query contains the information symbols (x1, x1, x2, x2). Then,
we can retrieve these symbols using the following equations:
⎧
⎪⎪⎨
⎪⎪⎩
x1 = y1
x1 = y2 + y4
x2 = y3 + y6
x2 = y5 + y7
.
It can be veriﬁed in a similar manner that any 4-tuple (xi1, xi2, xi3, xi4), where
i1, i2, i3, i4 ∈[4], can be retrieved by using the symbols of y, by using each symbol
at most once. We conclude that C is a [7, 3, 4]2-batch code. Moreover, it was shown
in [32] that all queries can be satisﬁed when each user reads at most r = 2 symbols
from y.
Constructions of linear batch codes using graphs without short cycles were
presented in [10]. A family of codes, related to batch codes, and corresponding
to the case t = k, termed switch codes, was studied in [8, 32, 33]. It was suggested
in [33] to use such codes for efﬁcient routing of data in the network switches.
The following property of batch codes was observed in [17] for binary linear
codes, and later generalized to nonbinary (and also to non-linear) codes in [40].
Theorem 2 Let C be an [n, k, t]q-batch code. Then, the minimum Hamming dis-
tance of C is at least t.
Proof Let y1 = C (x1) and y2 = C (x2) be two codewords of C , and x1 ̸= x2. Then,
x1 and x2 differ in at least one symbol, i.e. (x1)ℓ̸= (x2)ℓ, for some 1 ≤ℓ≤k. Con-
sider the query (xℓ, xℓ, . . . , xℓ



t
). The i-th copy of xℓis recovered from the set of
symbols indexed by the set Ti, 1 ≤i ≤t. Since x1 and x2 differ in the ℓ-th symbol,
the codewords y1 and y2 should differ in at least one symbol in each Ti, 1 ≤i ≤t.
The sets Ti are all disjoint, and therefore y1 and y2 differ in at least t symbols.
□
It follows that any [n, k, t]q-batch code is in particular a classical [n, k, ≥t]q
error-correcting code, and a variety of classical bounds, such as Singleton bound,
Hamming bound, Plotkin bound, Griesmer bound, Johnson bound, Elias-Bassalygo
bound, are all applicable to batch codes (when the minimum distance d is replaced
by the query size t).

434
V. Skachek
Example 4 Let m > 1 be an integer. A binary simplex [2m −1, m, 2m−1] code C is
deﬁned by its generator matrix
G =

g1 | g2 | · · · | g2m−1

,
where gi are all possible different binary nonzero column vectors of length m, i =
1, 2, . . . , 2m −1 [25, Problem2.18].
For a classical error-correcting [n, k, d] code over Fq, the Plotkin bound is deﬁned
as follows [20, Theorem2.2.29]:
if qd > (q −1)n, then qk ≤

qd
qd −(q −1)n

.
It is straightforward to see that, as an error-correcting code, the binary simplex
code as above (with q = 2) attains the Plotkin bound with equality [25, Problem
2.18] for all m ≥2.
As it was shown in [32], the code C is a [2m −1, m, 2m−1]2 batch code, with
t = 2m−1. Therefore, by Theorem2, it attains the corresponding Plotkin-based bound
qk ≤

qt
qt −(q −1)n

with equality, and therefore it is a Plotkin-optimal batch code.
In [38], a variation of batch codes with restricted size of reconstruction sets is
deﬁned. These codes are batch codes as in Deﬁnition3 with an additional property
that every queried information symbol xi is reconstructed from at most r ≥1 symbols
of y. This additional property can be viewed as analogous to locality of the LRCs.
Small size of reconstruction sets allows for recovering the requested data symbol
from a small number r of servers, thus reducing the trafﬁc and the load in the system.
For example, the binary simplex code C in the previous example was shown
in [32] to have the size of reconstruction sets of at most r = 2.
6
Codes for Private Information Retrieval
The topic of private information retrieval (PIR) protocols has been a subject of a lot
of research over the last two decades [9]. In the PIR scenario, the database is stored
in a number of servers in a distributed manner. The user is interested in reading an
item from the database without revealing to any server what item was read. In the
classical approach, the data is replicated, and the replicas are stored in a number of
different servers. The user accesses some of these servers, such that no server learns
what data the user is interested in (it is assumed that the servers do not collude).

Batch and PIR Codes and Their Connections …
435
A novel approach to PIR is based on coding, and it was studied, for example in
[1, 7, 16]. More speciﬁcally, assume that x = (x1, x2, . . . , xk) is an information
vector, which is encoded into C (x) = y = (y1, y2, . . . , yn). The symbols of y are
stored in different servers in a distributed manner.
In [7], the authors show that there is a fundamental trade-off between download
communication complexity of the protocol (the number of symbols or bits down-
loaded by the user from the database) and the storage overhead (the number of
redundant symbols or bits stored in the database). Later, the authors of [12] show
that it is possible to emulate many of the existing PIR protocols by using a code
of length n that approaches (1 + ε)k for vanishing ε (for sufﬁciently large k). This
approach leads to PIR schemes with storage data rate arbitrarily close to 1. The
authors deﬁne a special class of codes, which allows for such efﬁcient PIR protocols.
Deﬁnition 6 ([12]) An k × n binary matrix G has property At if for all i ∈[k], there
exist t disjoint sets of columns of G that add up to ei. A binary linear [n, k] code C
is called a t-server PIR code (or, simply, PIR code) if there exists a generator matrix
G for C with property At.
The batch codes turn out to be a special case of PIR codes, with a difference
that PIR codes support only queries of type (xi, xi, . . . , xi), i ∈[k], while batch
codes support queries of a more general form (xi1, xi2, . . . , xit), possibly for different
indices i1, i2, . . . , it ∈[k]. It follows that batch codes can be used as PIR codes.
Since for PIR codes (as well as for batch codes), the code rate R approaches
1 [15, 22] for large values of k, it is more appropriate to talk about redundancy (as
a function of k), rather than about the code rate. This is in contrast to PIR/batch
codes with restricted size of reconstruction sets, where the asymptotic loss of code
rate takes place. The redundancy of the codes will be deﬁned and analyzed in the
following sections.
Constructions of PIR codes were presented very recently, for example, in
[3, 12, 39].
7
Connections Between Batch/PIR Codes and General
LRCs
As it was mentioned above, there are two types of LRCs considered in the literature:
LRCs with locality of information symbols and LRCs with locality of all symbols.
In order to preserve the information symbols in the coded word, a code with
locality of information symbols has a systematic encoding matrix G = [I|A] for some
matrix A. Consider LRCs with locality r and availability δ = t −1 of information
symbols. Then, each information symbol yi, 1 ≤i ≤k, in y, can be recovered from δ
disjoint sets Ti of symbols, |Ti| ≤r. Such a code can also be viewed as a PIR code that
supports any query of t copies of an information symbol with locality r (including
one copy of the information symbol in the systematic part). Generally, it does not

436
V. Skachek
follow that such a code is a batch code, since there is no guarantee that mixed queries
of different information symbols are supported by disjoint reconstruction sets.
On the other hand, a systematic batch or PIR code with restricted size of recon-
struction sets allows to recover any query of t information symbols with recovery
sets of size r. Since in the systematic case, the information symbols are a part of
a coded word y, it follows that this code is an LRC with locality r and availability
δ = t −1 of information symbols.
We obtain the following corollary (see also Theorem21 in [12]).
Corollary 1 A linear systematic code C is an LRC with locality r and availability
δ = t −1 of information symbols if and only if C is a PIR code that supports queries
of size t with size of reconstruction sets at most r.
It follows that the bounds derived for the parameters of the LRCs with locality
and availability of information symbols can be applied also to systematic batch or
PIR codes.3
On the other hand, for the non-systematic case, there is no simple known connec-
tion between linear batch codes with restricted size of reconstruction sets and LRCs
with availability, as it is illustrated in the following examples.
Example 5 Let G be a k × (3k) generator matrix of a linear binary code C deﬁned
as follows:
G =
⎛
⎜⎜⎜⎜⎜⎝
1 0 . . . 0 1
1 0 . . . 0 1
1 0 . . . 0 1
0 1 . . . 0 1
0 1 . . . 0 1
0 1 . . . 0 1
0 0 ... 0 1
0 0 ... 0 1
0 0 ... 0 1
0 0 . . . 1 1
0 0 . . . 1 1
0 0 . . . 1 1
0 0 . . . 0 1
0 0 . . . 0 1
0 0 . . . 0 1
⎞
⎟⎟⎟⎟⎟⎠
.
Speciﬁcally, the binary information vector x = (x1, x2, . . . , xk) is encoded into the
codeword y, which consists of three copies of the same sub-vector,
y = (y1, y2, . . . , y3k)
= (x1, x2, . . . ,
k

i=1
xi, x1, x2, . . . ,
k

i=1
xi, x1, x2, . . . ,
k

i=1
xi) .
The code C , when viewed as an LRC, has locality r = 1 and availability δ = 2,
since every symbol in y can be recovered from a single symbol in y, and there are 2
different recovery sets.
On the other hand, the code C , when viewed as a batch or PIR code, must have
a maximal size of reconstruction sets at least k, since it is impossible to recover a
single information symbol xk from less than k coded symbols in y.
3Please note that generally it does not follow here that the bounds for LRCs with locality of all
symbols are applicable to systematic batch or PIR codes.

Batch and PIR Codes and Their Connections …
437
The following example shows that batch or PIR code with small size of recon-
struction sets is not necessarily LRC with all symbols locality, even in the systematic
case (the example can be also modiﬁed to a non-systematic case).
Example 6 Take G to be a binary 2κ × (3κ + 1) matrix, where κ is some integer,
as follows:
G =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
1 1 0
0 0 0
. . .
0 0 0
1
0 1 1
0 0 0
. . .
0 0 0
1
0 0 0
1 1 0
. . .
0 0 0
1
0 0 0
0 1 1
. . .
0 0 0
1
... ... ...
... ... ...
...
... ... ...
...
0 0 0
0 0 0
. . .
1 1 0
1
0 0 0
0 0 0
. . .
0 1 1
1
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
.
Here, k = 2κ. This matrix G is a diagonal block matrix, where each block is a 2 × 3
generator matrix of a basic sub-cube code in [15], with an additional all-ones column.
Let C be a binary linear code generated by this matrix.
The code C , when viewed as a batch code, supports any two queries of the form
(xi, x j) (1 ≤i ≤k, 1 ≤j ≤k), with size of reconstruction sets at most 2. Therefore,
C is a batch code with r = 2, t = 2. In particular, it is a PIR code with r = 2 and
t = 2.
On the other hand, the code C , when viewed as an LRC, has locality of at least
κ, since in order to recover yn = k
i=1 xk, one needs to combine at least κ other
symbols of y.
As we see, this batch code with r = 2 and t = 2 has locality at least k/2 = κ,
when used as an LRC with all symbols locality.
8
Bounds on the Parameters of PIR and Batch Codes
with Unrestricted Size of Reconstruction Sets
In [31], the systematic batch codes with unrestricted size of reconstruction sets are
considered.Thecodesunderconsiderationhaverestrictiononthevalueoft (typically,
it is a small constant), yet there is no restriction on r, so we can assume that r = n.
Deﬁne the parameters B(k, t) and P(k, t) to be the shortest length n of any linear
systematic batch and PIR code, respectively, for given values of k and t. Deﬁne the
optimal redundancy of systematic batch and PIR codes, respectively, as
rB(k, t) ≜B(k, t) −k
and rP(k, t) ≜P(k, t) −k .
It is known [31] that for any ﬁxed t,
lim
k→∞
B(k, t)
k
= 1 .

438
V. Skachek
In a case of switch codes, k = t, it is shown in [33] that B(k, k) = O

k2/ log(k)

.
A constructive proof showing that rP(k, t) = t ·
√
k(1 + o(1)) was given in [12]. As
for the lower bound on rP(k, t), it was recently shown in [22] (see also [37]) that
for a ﬁxed t ≥3, rP(k, t) = (k), thus establishing an asymptotic behavior for the
redundancy of the PIR codes.
Since every batch code is also a PIR code, it follows that B(k, t) ≥P(k, t), and
rB(k, t) ≥rP(k, t). The relations between B(k, t) and P(k, t) for speciﬁc choices
of t were extensively studied in [31]. Thus, for example, it was shown that B(k, t) =
P(k, t) for 1 ≤t ≤4, while for 5 ≤t ≤7,
rB(k, t) ≤rP(k, t) + 2⌈log(k)⌉· rP(k/2, t −2) .
It is quite straightforward to verify that rB(k, 1) = 0 and rB(k, 2) = 1 for any k. It
was additionally shown in [31] that
rB(k, t) = O(
√
k) for t = 3, 4 ,
rB(k, t) = O(
√
k · log(k)) for 5 ≤t ≤7 .
The following more general result was proven in [31].
Theorem 3 For all values of k and t, it holds
rB(k, t) ≤rP(k, t) +
 t
2
 ⎡
⎢⎢⎢
log

k
⌊t/2⌋

−log

1 −
⌊t/2⌋!
⌊t/2⌋⌊t/2⌋
 
⎤
⎥⎥⎥
· rP

k
⌊t/2⌋

, t −2

.
In particular, it follows from Theorem3 that for any ﬁxed t,
rB(k, t) = O
√
k · log(k)
 
.
9
Bounds on the Parameters of PIR and Batch Codes
with Restricted Size of Reconstruction Sets
In [38], the authors study linear batch codes with restricted size of reconstruction
sets. They aim at reﬁning the Singleton bound for that case by using ideas in [14] and
subsequent works. Note, however, that these ideas cannot be applied directly, because
in LRCs there are dependencies between different coded symbols, and expurgation of
the code in the proof of the bound (2) (and similar bounds) uses these dependencies.
Therefore, the authors of [38] consider a query of t copies of the same symbol (for
example, (x1, x1, . . . , x1)), and show that the symbols in different reconstruction
sets possess certain dependencies. By using this property, they apply an expurgation
technique similar to that of [14, 23, 24, 34], and obtain the following relation on

Batch and PIR Codes and Their Connections …
439
the parameters of batch codes with size of reconstruction sets restricted to r. The
proof actually only assumes property At, and therefore it is directly applicable to
PIR codes as well.
Theorem 4 ([38]) Let C be a linear [n, k, t]q-batch code (or PIR code) with the
size of reconstruction sets restricted to r. Then, it holds:
n ≥k + d + (t −1)

k
rt −t + 1

−1

−1 .
(5)
Now, observe that if the [n, k, t]q-batch code (or PIR code) allows for reconstruc-
tion of any batch of t symbols, then it also allows for reconstruction of any batch
of β symbols, 1 ≤β ≤t. Therefore, expression (5) in Theorem4 can be adjusted as
follows:
n ≥k + d +
max
1≤β≤t,β∈N

(β −1)

k
rβ −β + 1

−1
#
−1 .
(6)
If the code is systematic, then there is always a reconstruction set of size 1 for
one of the queried symbols. In that case, the last expression can be rewritten as:
n ≥k + d +
max
2≤β≤t,β∈N

(β −1)

k
rβ −β −r + 2

−1
 #
−1 .
(7)
The reader can refer to [38] for the full proofs.
Example 7 ([38]) Take r = 2 and t = β = 2. Then, the bound in (7) is attained with
equality by the linear systematic codes of minimum distance 2, deﬁned as follows:
• yi = xi for 1 ≤i ≤k, and y j = x2( j−k)−1 + x2( j−k) for k + 1 ≤j ≤k + k/2,
when k is even,
• yi = xi for 1 ≤i ≤k, y j = x2( j−k)−1 + x2( j−k) for k + 1 ≤j ≤k + (k −1)/2,
and yk+(k+1)/2 = xk, when k is odd.
In that case, d = 2, and we obtain
n = k + k/2
if k is even ,
n = k + (k + 1)/2
if k is odd .
In both cases, the bound (7) is attained with equality for all k ≥1.
Example 8 Consider the code C in Example3, which was studied in [32]. As dis-
cussed, C is a linear [7, 3, 4]2-batch code, with the size of reconstruction sets at most
r = 2. Its minimum Hamming distance is d = 4. We pick β = 2, and observe that
the right-hand side of Eq. (7) can be re-written as

440
V. Skachek
3 + 4 + (2 −1)

3
2 · 2 −2 −2 + 2

−1

−1 = 7 ,
and therefore the bound in (7) is attained with equality for the choice β = 2. The
code C in Example3 is optimal with respect to that bound. We note, however, that
general simplex codes (of larger length) do not attain (7) with equality.
A slight improvement to the above bounds for both batch and PIR codes can be
obtained, if one considers simultaneously reconstruction sets for, say, two queried
batches (x1, x1, . . . , x1) and (x2, x2, . . . , x2), and studies intersections of their recon-
structionsets. Theanalysis alongthoselines was donein[38], andthefollowingresult
was derived.
Assume that
k ≥2(rt −t + 1) + 1 .
(8)
Denote
A = A(k,r, d, β, ε) ≜k + d + (β −1)

k + ε
rβ −β + 1

−1

−1 ,
B = B(k,r, d, β, λ) ≜k + d + (β −1)

k + λ
rβ −β + 1

−1

−1 ,
C = C(k,r, β, λ, ε) ≜(rβ −λ + 1)k −
k
2

(ε −1) .
Theorem 5 ([38]) Let C be a linear [n, k, t]-batch code over F with the minimum
distance d and size of reconstruction sets at most t. Then,
n ≥
max
β∈N∩
$
1,min
%
t,
&
k−3
2(r−1)
'()

max
ε,λ∈N∩[1,rβ−β] {min {A, B, C}}
#
.
(9)
10
Open Questions
Below, we list some open questions related to batch and PIR codes.
1. Derive tighter bounds on the length or redundancy of batch and PIR codes, in
particular, for small alphabet size, for large values of t, or for bounded values of
r.
2. Construct new optimal or sub-optimal batch and PIR codes.
3. Do non-linear batch (or PIR) codes have better parameters than their best linear
counterparts?
4. Do non-systematic batch (or PIR) codes have better parameters than their best
systematic counterparts?
5. Propose batch and PIR codes that allow for efﬁcient reconstruction algorithms.

Batch and PIR Codes and Their Connections …
441
Acknowledgements The material in this chapter has beneﬁted a lot from discussions of the author
with his students and colleagues, including Venkatesan Guruswami, Camilla Hollanti, Helger Lip-
maa, Sushanta Paudyal, Eldho Thomas, Alexander Vardy, Hui Zhang and Jens Zumbrägel. This
work is supported in part by the grants PUT405 and IUT2-1 from the Estonian Research Council
and by the EU COST Action IC1104.
References
1. D. Augot, F. Levy-Dit-Vehel, A. Shikfa, A storage-efﬁcient and robust private information
retrieval scheme allowing few servers (2014), arXiv:1412.5012
2. S. Bhattacharya, S. Ruj, B. Roy, Combinatorial batch codes: a lower bound and optimal con-
structions. Adv. Math. Commun. 6(2), 165–174 (2012)
3. S.R. Blackburn, T. Etzion, PIR array codes with optimal PIR rates (2016), arXiv:1609.07070
4. R.A. Brualdi, K. Kiernan, S.A. Meyer, M.W. Schroeder, Combinatorial batch codes and
transversal matroids. Adv. Math. Commun. 4(3), 419–431 (2010)
5. C. Bujtás, Z. Tuza, Batch codes and their applications. Electron. Notes Discret. Math. 38,
201–206 (2011)
6. V. Cadambe, A. Mazumdar, An upper bound on the size of locally recoverable codes, in
Proceedings International Symposium on Network Coding (NetCod) (2013), pp. 1–5
7. T.H. Chan, S. Ho, H. Yamamoto, Private information retrieval for coded storage (2014),
arXiv:1410.5489
8. Y.M. Chee, F. Gao, S.T.H. Teo, H. Zhang, Combinatorial systematic switch codes, in Proceed-
ings IEEE International Symposium on Information Theory (ISIT), Hong Kong, China (2015),
pp. 241–245
9. B. Chor, E. Kushilevitz, O. Goldreich, M. Sudan, Private information retrieval, in Proceedings
36-th IEEE Symposium on Foundations of Computer Science (FOCS) (1995), pp. 41–50
10. A.G. Dimakis, A. Gál, A.S. Rawat, Z. Song, Batch codes through dense graphs without short
cycles (2014), arXiv:1410.2920
11. A.G. Dimakis, K. Ramchandran, Y. Wu, C. Suh, A survey on network codes for distributed
storage. Proc. IEEE 99(3) (2011)
12. A. Fazeli, A. Vardy, E. Yaakobi, PIR with low storage overhead: coding instead of replication
(2015), arXiv:1505.06241
13. M. Forbes, S. Yekhanin, On the locality of codeword sysmbols in non-linear codes. Discret.
Math. 324, 78–84 (2014)
14. P. Gopalan, C. Huang, H. Simitchi, S. Yekhanin, On the locality of codeword symbols. IEEE
Trans. Inform. Theory 58(11), 6925–6934 (2012)
15. Y. Ishai, E. Kushilevitz, R. Ostrovsky, A. Sahai, Batch codes and their applications, in Pro-
ceedings of the 36th ACM Symposium on Theory of Computing (STOC), June 2004, Chicago,
IL (2004)
16. S.Kopparty,S.Saraf,S.Yekhanin,High-ratecodewithsublinear-timedecoding,inProceedings
of the 43rd Annual ACM Symposium on Theory of Computing (STOC), New York, NY (2011),
pp. 167–176
17. H. Lipmaa, V. Skachek, Linear batch codes, in Proceedings 4th International Castle Meeting on
Coding Theory and Applications, Palmela, Portugal, September 2014 (2014), arXiv:1404.2796
18. J.L. Massey, Threshold decoding, Technical report TR-410, MIT (1963)
19. S. Paudyal, Multi-symbol locally repairable codes, Master’s thesis, University of Tartu, June
2015 (2015)
20. R. Pellikaan, X.-W. Wu, S. Bulygin, R. Jurrius, Error-correcting codes, http://www.win.tue.nl/
~ruudp/courses/2WC09/2WC09-book.pdf
21. N. Prakash, V. Lalitha, P.V. Kumar, Codes with locality for two erasures, in Proceedings IEEE
International Symposium on Information Theory (ISIT), June-July 2014 (2014), pp. 1962–1966

442
V. Skachek
22. S. Rao, A. Vardy, Lower bound on the redundancy of PIR codes (2016), arXiv:1605.01869
23. A.S. Rawat, A. Mazumdar, S. Vishwanath, Cooperative local repair in distributed storage.
EURASIP J. Adv. Signal Process. (2015)
24. A.S. Rawat, D.S. Papailiopoulos, A.G. Dimakis, S. Vishwanath, Locality and availability in
distributed storage. IEEE Trans. Inf. Theory 62(8), 4481–4493 (2016)
25. R.M. Roth, Introduction to Coding Theory (Cambridge University Press, Cambridge, 2006)
26. N. Silberstein, A.S. Rawat, O.O. Koyluoglu, S. Vishwanath, Optimal locally repairable codes
via rank-metric codes, in Proceedings IEEE International Symposium on Information Theory
(ISIT), Istanbul, Turkey (2013), pp. 1819–1823
27. N. Silberstein, A. Gál, Optimal combinatorial batch codes based on block designs. Des. Codes
Cryptogr. 78(2), 409–424 (2016)
28. D. Stinson, R. Wei, M. Paterson, Combinatorial batch codes. Adv. Math. Commun. 3(1), 13–17
(2009)
29. I. Tamo, A. Barg, Bounds on locally recoverable codes with multiple recovering sets, in Pro-
ceedingsIEEEInternationalSymposiumonInformationTheory(ISIT),Honolulu,HI,June-July
2014 (2014), pp. 691–695
30. I. Tamo, A. Barg, A family of optimal locally recoverable codes. IEEE Trans. Inf. Theory
60(8), 4661–4676 (2014)
31. A. Vardy, E. Yaakobi, Constructions of batch codes with near-optimal redundancy, in Proceed-
ings IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain (2016),
pp. 1197–1201
32. Z. Wang, H.M. Kiah, Y. Cassuto, Optimal binary switch codes with small query size, in Pro-
ceedings IEEE International Symposium on Information Theory (ISIT), Hong Kong, China
(2015), pp. 636–640
33. Z. Wang, O. Shaked, Y. Cassuto, J. Bruck, Codes for network switches, in Proceedings IEEE
International Symposium on Information Theory (ISIT), Istanbul, Turkey (2013), pp. 1057–
1061
34. A. Wang, Z. Zhang, Repair locality with multiple erasure tolerance. IEEE Trans. Inf. Theory
60(11), 6979–6987 (2014)
35. T. Westerbäck, R. Freij, C. Hollanti, Applications of polymatroid theory to distributed storage
systems, in Proceedings 53rd Allerton Conference on Communication, Control, and Comput-
ing, Allerton, IL, USA, September-October 2015 (2015), pp. 231–237
36. T. Westerbäck, R. Freij-Hollanti, T. Ernvall, C. Hollanti, On the combinatorics of locally
repairable codes via matroid theory. IEEE Trans. Inf. Theory 62(10), 5296–5315 (2016)
37. M. Wootters, Linear codes with disjoint repair groups, unpublished manuscript (2016)
38. H. Zhang, V. Skachek, Bounds for batch codes with restricted query size, in Proceedings
IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain (2016), pp.
1192–1196
39. Y. Zhang, X. Wang, H. Wei, G. Ge, On private information retrieval array codes (2016),
arXiv:1609.09167
40. J. Zumbrägel, V. Skachek, On bounds for batch codes, in Algebraic Combinatorics and Appli-
cations (ALCOMA), Kloster Banz, Germany (2015)

