Signals and Communication Technology
MarcusÂ Greferath
MarioÂ OsvinÂ PavÄeviÄ‡
NataliaÂ Silberstein
MarÃ­aÂ ÃngelesÂ VÃ¡zquez-Castro    Editors 
Network 
Coding and 
Subspace 
Designs

Signals and Communication Technology

More information about this series at http://www.springer.com/series/4748

Marcus Greferath
â€¢ Mario Osvin PavÄeviÄ‡
Natalia Silberstein
â€¢ MarÃ­a Ãngeles VÃ¡zquez-Castro
Editors
Network Coding
and Subspace Designs
123

Editors
Marcus Greferath
Department of Mathematics
and Systems Analysis
Aalto University
Espoo
Finland
Mario Osvin PavÄeviÄ‡
Faculty of Electrical Engineering
and Computing, Department
of Applied Mathematics
University of Zagreb
Zagreb
Croatia
Natalia Silberstein
Yahoo Research
Haifa
Israel
MarÃ­a Ãngeles VÃ¡zquez-Castro
Department of Telecommunications
and Systems Engineering
Universitat AutÃ²noma de Barcelona
Cerdanyola del VallÃ¨s, Barcelona
Spain
ISSN 1860-4862
ISSN 1860-4870
(electronic)
Signals and Communication Technology
ISBN 978-3-319-70292-6
ISBN 978-3-319-70293-3
(eBook)
https://doi.org/10.1007/978-3-319-70293-3
Library of Congress Control Number: 2017958828
Â© Springer International Publishing AG 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciï¬cally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microï¬lms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciï¬c statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made. The publisher remains neutral with regard to
jurisdictional claims in published maps and institutional afï¬liations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

This article/publication is based upon work from COST Action IC1104 Random
Network Coding and Designs over GF(q), supported by COST (European
Cooperation in Science and Technology).
COST (European Cooperation in Science and Technology) is a funding agency
for research and innovation networks. Our Actions help connect research initiatives
across Europe and enable scientists to grow their ideas by sharing them with their
peers. This boosts their research, career and innovation.
http://www.cost.eu
Funded by the Horizon 2020 Framework Programme
of the European Union
v

Foreword
The beautiful and the elegant are often inspired by the seemingly mundane.
The chapters of this book follow from a line of work rooted in a practical engi-
neering problem: namely, the efï¬cient transmission of information in packet net-
works. Traditional approaches to the operation of packet networks treat information
ï¬‚ow as commodity ï¬‚ow, emphasizing the efï¬cient routing of the information along
network pathways, while avoiding or cleverly resolving contention for transmission
resources. Network coding, introduced in 2000 in the seminal paper of Ahlswede,
Cai, Li, and Yeung, challenges this conventional approach.
Network coding is based on a simple, yet far-reaching, idea: Rather than simply
routing packets, intermediate nodes are permitted to â€œmixâ€ packets, transmitting
functions of the data that they receive. At the network boundary, received packets
are treated as evidence that must be gathered in sufï¬cient quantity so as to permit
decoding of the transmitted message.
A special case arises when the packets are interpreted as vectors of symbols
drawn from a ï¬nite ï¬eld, and the local mixing functions are chosen to be linear
transformations. From the 2003 paper of Li, Yeung, and Cai, it is known that such
linear network coding can achieve, when the underlying ï¬eld is large enough, the
so-called multicast capacity of a network, in which a single source wishes to
communicate the same message to a number of different terminals. An elegant
algebraic proof of this fact is given in the 2003 paper of KÃ¶tter and MÃ©dard via the
existence of a nonzero for a particular multivariate polynomial arising as a product
of matrix determinants. Indeed, as was demonstrated in the 2006 paper of Ho,
MÃ©dard, KÃ¶tter, Karger, Effros, Shi, and Leong, the multicast capacity of a network
is achieved, with high probability in a sufï¬ciently large ï¬eld, by a completely
random choice of local mixing functions, obviating the need for a deliberate
network-topology-dependent code design.
Such random linear network coding yields an interesting new type of data
transmission model. In this model, to send a message the transmitter injects into the
network a collection of vectors which propagate through intermediate nodes in the
network, where they are randomly linearly combined, before arriving at any given
terminal. A terminal observes a number of such vectors, from which the transmitted
vii

message must be inferred. Since the linear transformation by the channel of the
transmitted vectors is not known in advance by the transmitter or any of the
receivers, such a model is sometimes referred to as a noncoherent transmission
model (in contrast with a so-called coherent model, in which knowledge of the
channel transformation is assumed).
To achieve information transmission in this noncoherent model of random linear
network coding, one might seek a communication invariant: some property of the
transmitted vectors that is preserved by the operation of the channel. As observed in
my 2008 paper with Ralf KÃ¶tter, an essential invariantâ€”the key property preserved
by the random action of the channelâ€”is the vector space spanned by the trans-
mitted vectors. No matter the action of the channel, we are guaranteed (in the
absence of errors) that each of the vectors observed at any terminal belongs to the
space spanned by the transmitted vectors. Thus, we are naturally led to consider
information transmission not via the choice of the transmitted vectors themselves,
but rather by the choice of the vector space that they span.
Such a transmission model also lends itself to a concise description of the effects
of the injection (by an adversary, say) of erroneous vectors into the network: The
erroneous vectors combine linearly with the transmitted ones, resulting in a vector
space observed at any receiver that may differ from the transmitted one. Whenever a
space V is transmitted (by injection into the network of a basis for V), and a space U
is observed at a terminal (by observation of a basis for U), the transmitted V is
related to the received U via the direct sum U Â¼ HÃ°VÃ  E, where the operator H
selects some subspace of V and E is a suitable error space intersecting trivially with
V. This so-called operator channel takes in a vector space from the transmitter and
produces some vector space at any given receiver, where the received space may
suffer from erasures (deletion of vectors from the transmitted space) or errors
(addition of vectors to the transmitted space).
A coding theory for the operator channel thus presents itself very naturally. The
collection PÃ°WÃ of subspaces of the ambient packet space W plays the role of input
and output alphabets. One may deï¬ne metrics on PÃ°WÃ to measure the adversarial
effort required to convert a transmitted subspace V to a received one U; intuitively,
two spaces should be near each other if they intersect in a space of relatively large
dimension. One natural measure, which equally weights erasures and errors, is the
â€œsubspace
metricâ€
dSÃ°U; VÃ Â¼ dimÃ°U Ã¾ VÃ  dimÃ°U \ WÃ.
Another
measure,
introduced in my 2008 paper with Silva and KÃ¶tter, is the â€œinjection distanceâ€
dIÃ°U; VÃ Â¼ maxfdimÃ°UÃ; dimÃ°VÃg  dimÃ°U \ VÃ, which accounts for the possi-
bility that a single injection of a packet by an adversary may simultaneously case
the deletion of a dimension (an erasure) and the insertion of one (an error). These
two metrics coincide (except for a factor of two) in the case of constant dimension,
i.e., in the case when dimÃ°UÃ Â¼ dimÃ°VÃ.
A subspace code for the operator channel is then a nonempty subset of PÃ°WÃ,
i.e., a nonempty codebook of vector spaces, each a subspace of the ambient packet
space W. As in classical coding theory, the error- and erasure-correcting capability
of such a code is determined by the minimum distance between codewords, mea-
sured according to either the subspace distance or the injection distance. In the
viii
Foreword

important special case when the codewords all have the same dimension, a so-called
constant dimension code, an analog of a â€œconstant weight codeâ€ in classical coding
theory, arises.
Many very interesting mathematical and engineering questions arise immedi-
ately; indeed, the chapters of this book aim to pose, study, and answer some
of them.
As in classical coding theory, one can ask for extremal codes. For example,
when the ambient packet space is Fn
q, which codes with codewords of constant
dimension k have maximum codebook cardinality M while preserving minimum
injection distance d? Similarly, for a ï¬xed codebook cardinality M, which codes of
constant dimension k have largest possible minimum injection distance d? One
might also be interested in extremal codes with codewords not all of the same
dimension, in which case the distinction between the subspace distance and the
injection distance becomes important. Many classical coding theory bounds on
extremal codes (e.g., the Hamming bound, the Singleton bound, the Gilbert bound)
have analogs in the new setting of subspace codes.
One may also ask for code constructions that admit efï¬cient decoding algorithms.
In the case where k j n, the analog of a classical extremal code, the repetition code,
is now an extremal object in ï¬nite geometry: a spread, a collection of pairwise
trivially intersecting k-dimensional subspaces of Fn
q whose union is Fn
q. In our 2008
papers, we showed that constant dimension codes of very large (â€œnearlyâ€ extremal)
cardinality can be constructed by a â€œliftingâ€ of extremal codesâ€”such as the maxi-
mum rank-distance Delsarteâ€“Gabidulin codesâ€”constructed for the rank metric.
These codes consist of the row spaces of matrices of the form I j M
Â½
, where I is the
identity matrix and M is a matrix codeword of a rank-metric code. Furthermore, we
showed that efï¬cient analogs of classical bounded distance decoding algorithms for
Reedâ€“Solomon codes can be developed for such lifted Delsarteâ€“Gabidulin codes.
Closely related to the combinatorial questions of code construction, a large part
of combinatorial mathematics and ï¬nite geometry deals with the existence,
construction, and properties of so-called combinatorial designs: collections of sub-
sets of
some ambient set exhibiting particular balance or symmetry properties.
A prototypical example is a Steiner system: a collection of k-element subsets (called
blocks) of S Â¼ f1; . . .; ng with the property that each t-element subset of S is con-
tained in exactly one block. In this context of subspaces of a ï¬xed ambient space, one
can ask for q-analogs of such designs: namely, collections of subspaces of some
ambient space over Fq exhibiting particular balance or symmetry properties. For
example, the q-analog of a Steiner system would be a collection of k-dimensional
subspaces (blocks) of W Â¼ Fn
q with the property that each t-dimensional subspace of
W is contained in exactly one block. That nontrivial (t  2) q-Steiner systems even
exist was not known until the 2013 paper of Braun, Etzion, Ã–stergÃ¥rd, Vardy, and
Wassermann.
Written by leading experts in the ï¬eld, this book is an exploration of the
beautiful and elegant mathematical and engineering ideas that are related to network
coding. Here, you will ï¬nd new constructions of subspace codes of various types as
Foreword
ix

well as interesting generalizations. You will ï¬nd a deep discussion of rank-metric
codes and their properties, and you will ï¬nd connections made to ï¬nite geometry
and the theory of combinatorial designs, including a description of state-of-the-art
computational methods that can be used to search for designs. You will learn how
network coding is related to problems of broadcasting with side information at the
receivers, and how network coding can be applied in various wireless communi-
cation scenarios. Network coding ideas have also been used to determine bounds on
the parameters of codes that are useful in distributed storage systems. In this book,
you will ï¬nd a nice overview of the desirable featuresâ€”such as â€œlocalityâ€â€”that
such codes should possess, along with new constructions for locally repairable
codes, and codes that permit so-called private information retrieval from a dis-
tributed storage system.
That such a diversity of new ideas should arise from the problem of efï¬cient
transmission of information in a packet network suggests that the original problem
may not have been so mundane after all.
Toronto, Canada
Frank R. Kschischang
Dept. of Electrical & Computer Engineering
University of Toronto
x
Foreword

Preface
When the four editors authoring this short editorial came up with the plan for this
book project, the initial idea was to present, disseminate, and advertise for a large
collection of results of COST Action IC1104. This Action, named Random Network
Coding and Designs over GF(q), as granted by the European Science Foundation in
2011, supported 4 years of a joint endeavor in European research within the newly
established ï¬eld of network coding and subspace designs. When we look at the
collection of material of this book today, we recognize that this book has developed
to be much more: We feel that what we present here has become more signiï¬cant
than the Action itself in that it describes the state-of-the-art in many aspects of
network coding and related topics.
Historically, the new concepts and inventive ideas of the seminal paper
R. Koetter and F. R. Kschischang: Coding for errors and erasures in random network
coding, IEEE Transactions on Information Theory 54 (2008), 3579â€“3591.
attracted attention of scholars from many areas of coding theory and related sci-
entiï¬c disciplines. They felt that this endeavor allowed them to make original
contributions to their established knowledge and techniques. Algebraic coding
theorists, combinatorialists, computers scientists, and engineersâ€”they all saw their
opportunities to apply their skills and experience to an interdisciplinary work on the
introduced topics. So, it happened that the COST Action offered the perfect plat-
form at the right time for enabling fruitful discussions and exchange resulting in an
abundance of results by scientists all over the ï¬eld.
With growing enthusiasm, a competent union of more than hundred and twenty
scholars from 27 different countries joined actively the project illuminating different
directions, opening new questions, and connecting more and more branches of
science.
This book consists of 16 chapters by various protagonists of Action IC1104 and
a foreword by Frank Kschischang that brieï¬‚y provides conceptual framework,
initial information on the contents of the chapters, and points the coherence between
the
interdisciplinary
chapters.
Authors
are
invited
project
members
and
xi

internationally renowned experts who proved excellence in the ï¬eld, not only
within the 4 years of European support.
The chapters are as much self-contained as due and possible; they all start with
basics but come soon to the frontiers of knowledge without feeling obliged to
overdo in explaining too many details. Some of the chapters include respectable
new results that have not been published yet elsewhere, along with a list of open
problems and ideas for further research. This makes each of the chapters an
excellent start for Ph.D. students or newcomers to the ï¬eld who wish to commence
research on a particular topic connected with network coding or combinatorial
design theory. Since this research area is still growing and opening new problems
and topics, we sincerely hope that this book will provide ample and appropriate
guidance, when used by mathematicians as well as computer scientists and elec-
trical engineers.
We greatly appreciate the kindness of all the authors to cooperate and present the
chapters in such a useful review paper style. Our special thanks are addressed to the
European Science Foundation and its COST framework for the ï¬nancial support for
Action IC1104 and in particular for helping this book to come to existence.
Espoo, Finland
Marcus Greferath
Zagreb, Croatia
Mario Osvin PavÄeviÄ‡
Haifa, Israel
Natalia Silberstein
Cerdanyola del VallÃ¨s, Barcelona, Spain
MarÃ­a Ãngeles VÃ¡zquez-Castro
xii
Preface

Contents
Part I
Subspace Codes and Rank Metric Codes
Codes Endowed with the Rank Metric . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Elisa Gorla and Alberto Ravagnani
Constructions of Constant Dimension Codes . . . . . . . . . . . . . . . . . . . . .
25
Anna-Lena Horlemann-Trautmann and Joachim Rosenthal
Constructions of Cyclic Subspace Codes
and Maximum Rank Distance Codes . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
Kamil Otal and Ferruh Ã–zbudak
Generalizing Subspace Codes to Flag Codes
Using Group Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
Dirk Liebhold, Gabriele Nebe and MarÃ­a Ãngeles VÃ¡zquez-Castro
Multi-shot Network Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
Diego Napp and Filipa Santana
Part II
Finite Geometries and Subspace Designs
Geometrical Aspects of Subspace Codes . . . . . . . . . . . . . . . . . . . . . . . . .
107
Antonio Cossidente, Francesco Pavese and Leo Storme
Partial Spreads and Vector Space Partitions . . . . . . . . . . . . . . . . . . . . .
131
Thomas Honold, Michael Kiermaier and Sascha Kurz
q-Analogs of Designs: Subspace Designs . . . . . . . . . . . . . . . . . . . . . . . . .
171
Michael Braun, Michael Kiermaier and Alfred Wassermann
Computational Methods in Subspace Designs. . . . . . . . . . . . . . . . . . . . .
213
Michael Braun, Michael Kiermaier and Alfred Wassermann
xiii

Part III
Application of Network Coding
Index Coding, Network Coding and Broadcast
with Side-Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
247
Eimear Byrne and Marco Calderini
Implementation of Network Coding in Wireless Systems . . . . . . . . . . . .
295
Semiha Tedik Basaran, Ali Reza Heidarpour, Selahattin Gokceli,
Gunes Karabulut Kurt, Murat Uysal and Ibrahim Altunbas
Opportunistic Network Coding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
319
Kemal Alic and Ales Svigelj
Coded Random Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
339
ÄŒedomir StefanoviÄ‡ and Dejan VukobratoviÄ‡
Part IV
Codes for Distributed Storage Systems
An Overview of Coding for Distributed Storage Systems . . . . . . . . . . . .
363
Shiqiu Liu and FrÃ©dÃ©rique Oggier
Matroid Theory and Storage Codes: Bounds and Constructions . . . . . .
385
Ragnar Freij-Hollanti, Camilla Hollanti and Thomas WesterbÃ¤ck
Batch and PIR Codes and Their Connections
to Locally Repairable Codes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
427
Vitaly Skachek
xiv
Contents

Part I
Subspace Codes and Rank
Metric Codes

Codes Endowed with the Rank Metric
Elisa Gorla and Alberto Ravagnani
Abstract We review the main results of the theory of error-correcting codes with
the rank metric, introducing combinatorial techniques for their analysis. We study
their duality theory and MacWilliams identities, comparing in particular rank-metric
codes in vector and matrix representation. We then investigate the structure of MRD
codes and cardinality-optimal anticodes in the rank metric, describing how they relate
to each other.
Introduction
A q-ary rank-metric code is a set of matrices over Fq equipped with the rank distance,
which measures the rank of the difference of a pair of matrices. Rank-metric codes
were ï¬rst studied in [3] by Delsarte for combinatorial interest.
More recently, codes endowed with the rank metric have been re-discovered for
error correction in the context of linear network coding, and featured prominently in
the coding theory literature.
In linear network coding, a source attempts to transmit information packets to
multiple destinations via a network of intermediate nodes. The nodes compute and
forward in the direction of the sinks linear functions of the received packets, rather
than simply routing them. In [1, 9] it was shown that linear network coding achieves
the optimal multicast throughput over sufï¬ciently large alphabets.
Rank-metric codes were proposed in [8, 18] for end-to-end error correction in
noisy and adversarial networks. In this context, as shown in [17], the correction
capability of a rank-metric code is measured by a fundamental parameter, called the
minimum rank distance of the code.
In this chapter, we survey the main results of the mathematical theory of rank-
metric codes, with emphasis on their combinatorial structure.
E. Gorla
Institut de MathÃ©matiques, UniversitÃ© de NeuchÃ¢tel, NeuchÃ¢tel, Switzerland
e-mail: elisa.gorla@unine.ch
A. Ravagnani (B)
School of Mathematics and Statistics, University College Dublin,
Dublin, Ireland
e-mail: alberto.ravagnani@ucd.ie
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_1
3

4
E. Gorla and A. Ravagnani
In Sect.1 we introduce the most important parameters of a rank-metric code,
namely, the minimum distance, the weight distribution, and the distance distribution.
We then deï¬ne the trace-dual of a linear rank-metric code, and compare the duality
theories of codes in matrix and vector representation. In particular, we show that the
former generalizes the latter.
Section2 is devoted to the duality theory of codes endowed with the rank met-
ric. We study how combinatorial properties of a linear code relate to combinatorial
properties of the dual code. In particular, we show that the weight distribution of a
linear code and the weight distribution of its dual code determine each other via a
MacWilliams-type transformation. We also show an application of the MacWilliams
identities for the rank metric to an enumerative combinatorics problem.
In Sect.3 we study codes that have the largest possible cardinality for their param-
eters. These are called Maximum Rank Distance codes (MRD in short) and have
very remarkable properties. We ï¬rst show the existence of linear MRD codes for all
choices of the parameters and of the ï¬eld size. Then we prove that the dual of a linear
MRD code is MRD. Finally, we show that the distance distribution of a (possibly
non-linear) rank-metric code is completely determined by its parameters.
Section4 is devoted to rank-metric anticodes, i.e., sets of matrices where the
distance between any two of them is bounded from above by a given integer. We
study how codes and anticodes relate to each other, deriving in particular an upper
bound for the cardinality of any anticode of given parameters. We conclude the
section showing that the dual of an optimal linear anticode is an optimal anticode.
1
Rank-Metric Codes
Throughout this chapter, q denotes a ï¬xed prime power, and Fq the ï¬nite ï¬eld with
q elements. Moreover, k and m denote positive integers with k â‰¤m without loss
of generality, and FkÃ—m
q
is the space of k Ã— m matrices over Fq. Finally, for given
integers a, b âˆˆN we denote by
a
b

q
the q-ary binomial coefï¬cient of a and b, which counts the number of b-dimensional
subspaces of an a-dimensional space over Fq. See e.g. [19, Sect.1.7] for details.
Deï¬nition 1 The rank distance is the function d : FkÃ—m
q
Ã— FkÃ—m
q
â†’N deï¬ned by
d(M , N) = rk(M âˆ’N) for all M , N âˆˆFkÃ—m
q
.
It is easy to check that d is indeed a distance function on FkÃ—m
q
.
Deï¬nition 2 A (rank-metric) code over Fq is a non-empty subset C âŠ†FkÃ—m
q
. When
|C | â‰¥2, the minimum distance of C is the positive integer
d(C ) = min{d(M , N) | M , N âˆˆC , M Ì¸= N}.

Codes Endowed with the Rank Metric
5
A code C is linear if it is an Fq-linear subspace of FkÃ—m
q
. In this case its dual code
is deï¬ned as
C âŠ¥= {N âˆˆFkÃ—m
q
| Tr(MN t) = 0 for all M âˆˆC } âŠ†FkÃ—m
q
,
where Tr(Â·) denotes the trace of a square k Ã— k matrix.
The map (M , N) â†’Tr(MN t) âˆˆFq is a scalar product on FkÃ—m
q
, i.e., it is sym-
metric, bilinear and non-degenerate. In particular, the dual of a linear code is a linear
code of dimension
dim(C âŠ¥) = km âˆ’dim(C ).
Other fundamental parameters of a rank-metric code are the following.
Deï¬nition 3 The weight distribution and the distance distribution of a code C
are the collections {Wi(C ) | i âˆˆN} and {Di(C ) | i âˆˆN} respectively, where
Wi(C ) = |{M âˆˆC |rk(M ) = i}|,
Di(C ) = 1/|C | Â· |{(M , N) âˆˆC 2 |d(M , N) = i}|
for all i âˆˆN.
If C is a linear code, then for all P âˆˆC there are precisely |C | pairs (M , N) âˆˆC 2
such that M âˆ’N = P. Therefore
Di(C ) = 1/|C | Â·

PâˆˆC
rk(P)=i
|{(M , N) âˆˆC 2 | M âˆ’N = P}| = Wi(C )
for all i âˆˆN. Moreover, if |C | â‰¥2 then d(C ) = min{rk(M ) | M âˆˆC , M Ì¸= 0}.
In [5], Gabidulin proposed independently a different notion of rank-metric code,
in which the codewords are vectors with entries from an extension ï¬eld Fqm rather
than matrices over Fq.
Deï¬nition 4 The rank of a vector v = (v1, ..., vk) âˆˆFk
qm is the dimension of the
linear spaces generated over Fq by its entries, i.e., rkG(v) = dimFqâŸ¨v1, ..., vkâŸ©. The
rank distance between vectors v, w âˆˆFk
qm is dG(v, w) = rkG(v âˆ’w).
One can check that dG is a distance function on Fk
qm.
Deï¬nition 5 A vector rank-metric code over Fqm is a non-empty subset C âŠ†Fk
qm.
When |C| â‰¥2, the minimum distance of C is the positive integer
dG(C) = min{dG(v, w) | v, w âˆˆC, v Ì¸= w}.
The code C is linear if it is an Fqm-linear subspace of Fk
qm. In this case the dual of C
is deï¬ned as

6
E. Gorla and A. Ravagnani
CâŠ¥=

w âˆˆFk
qm |
k

i=1
viwi = 0 for all v âˆˆC

âŠ†Fk
qm.
The map (v, w) â†’ viwi is an Fqm-scalar product on Fk
qm. Therefore for all linear
vector rank-metric codes C âŠ†Fk
qm we have
dimFqm(CâŠ¥) = k âˆ’dimFqm(C).
Deï¬nition 6 The weight distribution and the distance distribution of a vector
rank-metric code C are the integer vectors (Wi(C) | i âˆˆN) and (Di(C) | i âˆˆN)
respectively, where
Wi(C) = |{v âˆˆC | rkG(v) = i}|,
Di(C) = 1/|C| Â· |{(v, w) âˆˆC2 | dG(v, w) = i}|
for all i âˆˆN.
There exists a natural way to associate to a vector rank-metric code a code in
matrix representation with the same cardinality and metric properties.
Deï¬nition 7 Let Î“ = {Î³1, ..., Î³m} be a basis of Fqm over Fq. The matrix associated
to a vector v âˆˆFk
qm with respect to Î“ is the k Ã— m matrix Î“ (v) with entries in Fq
deï¬ned by
vi =
m

j=1
Î“ (v)ijÎ³j
for all i = 1, ..., k.
The rank-metric code associated to a vector rank-metric code C âŠ†Fk
qm with respect
to Î“ is
Î“ (C) = {Î“ (v) | v âˆˆC} âŠ†FkÃ—m
q
.
Notice that in the previous deï¬nition the i-th row of Î“ (v) is the expansion of the
entry vi over the basis Î“ .
The proof of the following result is standard and left to the reader.
Proposition 1 For every Fq-basis Î“ of Fqm the map v â†’Î“ (v) is an Fq-linear
bijective isometry (Fk
qm, dG) â†’(FkÃ—m
q
, d).
In particular, if C âŠ†Fk
qm is a vector rank-metric code, then Î“ (C) has the same
cardinality, rank distribution and distance distribution as C. Moreover, if |C| â‰¥2
then dG(C) = d(Î“ (C)).
In the remainder of the section we compare the duality theories of matrix and vec-
tor rank-metric codes, showing that the former generalizes the latter. The following
results appear in [12].
Given an Fqm-linear vector rank-metric code C âŠ†Fk
qm and a basis Î“ of Fqm over
Fq, it is natural to ask whether the codes Î“ (CâŠ¥) and Î“ (C)âŠ¥coincide or not. The
answer is negative in general, as we show in the following example.

Codes Endowed with the Rank Metric
7
Example 1 Let q = 3, k = m = 2 and F32 = F3[Î·], where Î· is a root of the irre-
ducible primitive polynomial x2 + 2x + 2 âˆˆF3[x]. Let Î¾ = Î·2, so that Î¾ 2 + 1 = 0.
Set Î± = (Î¾, 2), and let C âŠ†F2
32 be the 1-dimensional vector rank-metric code gen-
erated by Î± over F32. Take Î“ = {1, Î¾} as basis of F32 over F3. One can check that
Î“ (C) is generated over F3 by the two matrices
Î“ (Î±) =
0 1
2 0

,
Î“ (Î¾Î±) =
âˆ’1 0
0 2

.
Let Î² = (Î¾, 1) âˆˆF2
32. We have Î±1Î²1 + Î±2Î²2 = 1 Ì¸= 0, and so Î² /âˆˆCâŠ¥. It follows
Î“ (Î²) /âˆˆÎ“ (CâŠ¥). On the other hand,
Î“ (Î²) =
0 1
1 0

,
and it is easy to see that Î“ (Î²) is trace-orthogonal to both Î“ (Î±) and Î“ (Î¾Î±). Therefore
Î“ (Î²) âˆˆÎ“ (C)âŠ¥, hence Î“ (C)âŠ¥Ì¸= Î“ (CâŠ¥).
Although the duality notions for matrix and vector rank-metric codes do not
coincide, there is a simple relation between them via orthogonal bases of ï¬nite
ï¬elds.
Let Trace : Fqm â†’Fq be the map deï¬ned by Trace(Î±) = Î± + Î±q + Â· Â· Â· + Î±qmâˆ’1
for all Î± âˆˆFqm. Bases Î“ = {Î³1, ..., Î³m} and Î“ â€² = {Î³ â€²
1, ..., Î³ â€²
m} of Fqm over Fq are
called orthogonal if Trace(Î³ â€²
i Î³j) = Î´ij for all i, j âˆˆ{1, ..., m}. It is well-known that
every basis Î“ of Fqm over Fq has a unique orthogonal basis Î“ â€² (see [10], p. 54).
Theorem 1 Let C âŠ†Fk
qm be an Fqm-linear vector rank-metric code, and let Î“ , Î“ â€²
be orthogonal bases of Fqm over Fq. We have
Î“ â€²(CâŠ¥) = Î“ (C)âŠ¥.
In particular, C has the same weight distribution as Î“ (C), and CâŠ¥has the same
weight distribution as Î“ (C)âŠ¥.
Proof Write Î“ = {Î³1, ..., Î³m} and Î“ â€² = {Î³ â€²
1, ..., Î³ â€²
m}. Let M âˆˆÎ“ â€²(CâŠ¥) and N âˆˆ
Î“ (C). There exist Î± âˆˆCâŠ¥and Î² âˆˆC such that M = Î“ â€²(Î±) and N = Î“ (Î²). By
Deï¬nition 7 we have
0 =
k

i=1
Î±iÎ²i =
k

i=1
m

j=1
MijÎ³ â€²
j
m

t=1
NitÎ³t =
k

i=1
m

j=1
m

t=1
MijNitÎ³ â€²
j Î³t.
(1)
Applying the function Trace : Fqm â†’Fq to both sides of Eq.(10) we obtain
0 = Trace
â›
â
k

i=1
m

j=1
m

t=1
MijNitÎ³ â€²
j Î³t
â
â =
k

i=1
m

j=1
m

t=1
MijNitTrace(Î³ â€²
j Î³t) = Tr(MNt).

8
E. Gorla and A. Ravagnani
Therefore Î“ â€²(CâŠ¥) âŠ†Î“ (C)âŠ¥. Proposition 1 implies that Î“ â€²(CâŠ¥) and Î“ (C)âŠ¥have
the same dimension over Fq. Hence the two codes are equal. The second part of the
statement follows from Proposition 1.
Theorem 1 shows that the duality theory of Fq-linear rank-metric codes in matrix
representation can be regarded as a generalization of the duality theory of Fqm-linear
vector rank-metric codes. For this reason, in the sequel we only treat rank-metric
codes in matrix representation.
Rank-metriccodes canbeusedtoconstruct several types of subspacecodes, aclass
of error-correcting codes introduced in [8] in the context of random linear network
coding. See chapters â€œConstructions of Constant Dimension Codesâ€, â€œConstructions
of Cyclic Subspace Codes and Maximum Rank Distance Codesâ€, â€œGeneralizing
subspace codes to ï¬‚ag codes using group actionsâ€, and â€œPartial spreads and vector
space partitionsâ€ for constructions of subspace codes, and chapter â€œGeometrical
aspects of subspace codesâ€ for their structural properties.
2
MacWilliams Identities for the Rank Metric
This section is devoted to the duality theory of codes endowed with the rank metric.
We concentrate on linear rank-metric codes, and show that the weight distributions
of a code C and its dual code C âŠ¥determine each other via a MacWilliams-type
transformation. This result was established by Delsarte in [3, Theorem 3.3] using
the machinery of association schemes, and may be regarded as the rank-analogue
of a celebrated theorem by MacWilliams on the weight distribution of linear codes
endowed with the Hamming metric (see [11]). In this section we present a lattice-
theoretic proof inspired by [13, Theorem 27].
Notation 1 We denote by colsp(M ) âŠ†Fk
q the Fq-space generated by the columns of
a matrix M âˆˆFkÃ—m
q
. Given a code C âŠ†FkÃ—m
q
and an Fq-subspace U âŠ†Fk
q, we let
C (U) = {M âˆˆC | colsp(M ) âŠ†U} âŠ†FkÃ—m
q
be the set of matrices in C whose columnspace is contained in U.
Note that for all M , N âˆˆFkÃ—m
q
we have colsp(M + N) âŠ†colsp(M ) + colsp(N).
As a consequence, if U âŠ†Fk
q is an Fq-linear subspace and C âŠ†FkÃ—m
q
is a linear code,
then C (U) is a linear code as well.
We start with a series of preliminary results. In the sequel we denote by U âŠ¥the
orthogonal (or dual) of an Fq-vector space U âŠ†Fk
q with respect to the standard inner
product of Fk
q. It will be clear from context if by â€œâŠ¥â€ we denote the trace-dual in
FkÃ—m
q
or the standard dual in Fk
q.
Lemma 1 Let U âŠ†Fk
q be a subspace. The following hold.
1. dim(FkÃ—m
q
(U)) = m Â· dim(U).

Codes Endowed with the Rank Metric
9
2. FkÃ—m
q
(U)âŠ¥= FkÃ—m
q
(U âŠ¥).
Proof
1. Let s = dim(U) and V = {(x1, ..., xk) âˆˆFk
q | xi = 0 for i > s} âŠ†Fk
q.
There exists an Fq-isomorphism g : Fk
q â†’Fk
q that mapsU to V . Let G âˆˆFkÃ—k
q
be
the invertible matrix associated to g with respect to the canonical basis {e1, ..., ek}
of Fk
q, i.e.,
g(ej) =
k

i=1
Gijei
for all j = 1, ..., k.
The map M â†’GM is an Fq-isomorphism FkÃ—m
q
(U) â†’FkÃ—m
q
(V ). Property 1
of the lemma now directly follows from the deï¬nition of FkÃ—m
q
(V ).
2. Let N âˆˆFkÃ—m
q
(U âŠ¥) and M âˆˆFkÃ—m
q
(U). Using the deï¬nition of trace-product one
sees that Tr(MN t) = m
i=1âŸ¨Mi, NiâŸ©, where âŸ¨Â·, Â·âŸ©is the standard inner product of
Fk
q, and Mi, Ni denote the i-th column of M and N (respectively). Each column of
N belongs to U âŠ¥, and each column of M belongs to U. Therefore Tr(MN t) = 0,
hence FkÃ—m
q
(U âŠ¥) âŠ†FkÃ—m
q
(U)âŠ¥. By property 1, the two spaces FkÃ—m
q
(U âŠ¥) and
FkÃ—m
q
(U)âŠ¥have the same dimension over Fq. Therefore they are equal.
The following result is [12, Lemma 28].
Proposition 2 Let C âŠ†FkÃ—m
q
be a linear code, and let U âŠ†Fk
q be a subspace of
dimension u over Fq. Then
|C (U)| =
|C |
qm(kâˆ’u) |C âŠ¥(U âŠ¥)|.
Proof We have C (U)âŠ¥= (C âˆ©FkÃ—m
q
(U))âŠ¥= C âŠ¥+ FkÃ—m
q
(U)âŠ¥= C âŠ¥+ FkÃ—m
q
(UâŠ¥), where
the last equality follows from part 2 of Lemma 1. Therefore
|C (U)| Â· |C âŠ¥+ FkÃ—m
q
(U âŠ¥)| = qkm.
(2)
On the other hand, part 1 of Lemma 1 gives
dim(C âŠ¥+ FkÃ—m
q
(U âŠ¥)) = dim(C âŠ¥) + m Â· dim(U âŠ¥) âˆ’dim(C âŠ¥(U âŠ¥)).
As a consequence,
|C âŠ¥+ FkÃ—m
q
(U âŠ¥)| =
qkm Â· qm(kâˆ’u)
|C | Â· |C âŠ¥(U âŠ¥)|.
(3)
Combining Eqs.(2) and (3) one obtains the proposition.
We will also need the following preliminary lemma, which is an explicit version
of the MÃ¶bius inversion formula for the lattice of subspaces of Fk
q. We include a short
proof for completeness. See [19, Sects.3.7â€“3.10] for details.

10
E. Gorla and A. Ravagnani
Lemma 2 Let P(Fk
q) be the set of all Fq-subspaces of Fk
q, and let f : P(Fk
q) â†’Z
be any function. Deï¬ne g : P(Fk
q) â†’Z by g(V ) = 
UâŠ†V f (U) for all V âŠ†Fk
q.
Then for all i âˆˆ{0, ..., k} and for any subspace V âˆˆP(Fk
q) with dim(V ) = i we
have
f (V ) =
i
u=0
(âˆ’1)iâˆ’uq(iâˆ’u
2 )

UâŠ†V
dim(U)=u
g(U).
Proof Fix an integer i âˆˆ{0, ..., k} and a vector space V âˆˆP(Fk
q) with dim(V ) = i.
We inductively deï¬ne a function Î¼ : {U âˆˆP(Fk
q) | U âŠ†V } â†’Z by Î¼(U) = 1 if
U = V , and Î¼(U) = âˆ’
UâŠŠSâŠ†V Î¼(S) if U âŠŠV . By deï¬nition of g we have

UâŠ†V
Î¼(U)g(U) =

UâŠ†V
Î¼(U)

SâŠ†U
f (S) =

SâŠ†V
f (S)

SâŠ†UâŠ†V
Î¼(U) = f (V ),
where the last equality immediately follows from the deï¬nition of Î¼. Therefore it
sufï¬ces to show that for all U âŠ†V we have
Î¼(U) = (âˆ’1)iâˆ’uq(iâˆ’j
2 ),
(4)
where u = dim(U). We proceed by induction on i âˆ’u. If i = u then Eq.(4) is trivial.
Now assume i > u. By deï¬nition of Î¼ and the induction hypothesis we have
Î¼(U) = âˆ’

UâŠŠSâŠ†V
Î¼(S) = âˆ’
i
s=u+1
(âˆ’1)iâˆ’sq(iâˆ’s
2 )
i âˆ’j
s âˆ’u

q
= âˆ’
i
s=u+1
(âˆ’1)iâˆ’sq(iâˆ’s
2 )
i âˆ’u
i âˆ’s

q
= âˆ’
iâˆ’u

s=0
(âˆ’1)sq(s
2)
i âˆ’u
s

q
+ (âˆ’1)iâˆ’uq(iâˆ’u
2 )
= (âˆ’1)iâˆ’uq(iâˆ’u
2 ),
where the last equality follows from the q-Binomial Theorem (see [19], p. 74).
We can now prove the main result of this section, ï¬rst established by Delsarte in
[3, Theorem 3.3]. A proof for the special case of Fqm-linear vector rank-metric codes
using different techniques can be found in [6].
Theorem 2 (MacWilliams identities for the rank metric) Let C âŠ†FkÃ—m
q
be an linear
rank-metric code. For all i âˆˆ{0, ..., k} we have

Codes Endowed with the Rank Metric
11
Wi(C âŠ¥) =
1
|C |
k

j=0
Wj(C )
k

u=0
(âˆ’1)iâˆ’uqmu+(iâˆ’u
2 )
k âˆ’u
k âˆ’i

q
k âˆ’j
u

q
.
Proof For all subspaces V âŠ†Fk
q deï¬ne
f (V ) = |{M âˆˆC âŠ¥| colsp(M ) = V }|,
g(V ) =

UâŠ†V
f (U) = |C âŠ¥(V )|.
By Lemma 2, for any i âˆˆ{0, ..., k} and for any vector space V âŠ†Fk
q of dimension i
we have
f (V ) =
i
u=0
(âˆ’1)iâˆ’uq(iâˆ’u
2 )

UâŠ†V
dim(U)=u
|C âŠ¥(U)|
=
i
u=0
(âˆ’1)iâˆ’uq(iâˆ’u
2 )

TâŠ†Fk
q
TâŠ‡V âŠ¥
dim(T)=kâˆ’u
|C âŠ¥(T âŠ¥)|
=
1
|C |
i
u=0
(âˆ’1)iâˆ’uqmu+(iâˆ’u
2 )

TâŠ†Fk
q
TâŠ‡V âŠ¥
dim(T)=kâˆ’u
|C (T)|,
where the last equality follows from Proposition 2. Now observe that
Wi(C âŠ¥) =

V âŠ†Fk
q
dim(V )=i
f (V )
=
1
|C |
i
u=0
(âˆ’1)iâˆ’uqmu+(iâˆ’u
2 )

V âŠ†Fk
q
dim(V )=i

TâŠ†Fk
q
TâŠ‡V âŠ¥
dim(T)=kâˆ’u
|C (T)|
=
1
|C |
i
u=0
(âˆ’1)iâˆ’uqmu+(iâˆ’u
2 )

TâŠ†Fk
q
dim(T)=kâˆ’u

V âŠ†Fk
q
V âŠ‡T âŠ¥
dim(V )=i
|C (T)|
=
1
|C |
i
u=0
(âˆ’1)iâˆ’uqmu+(iâˆ’u
2 )
k âˆ’u
i âˆ’u

q

TâŠ†Fk
q
dim(T)=kâˆ’u
|C (T)|.
(5)

12
E. Gorla and A. Ravagnani
On the other hand,

TâŠ†Fk
q
dim(T)=kâˆ’u
|C (T)| =

TâŠ†Fk
q
dim(T)=kâˆ’u
kâˆ’u

j=0

SâŠ†T
dim(S)=j
|{M âˆˆC | colsp(M ) = S}|
=
kâˆ’u

j=0

SâŠ†Fk
q
dim(S)=j

TâŠ†Fk
q
TâŠ‡S
dim(T)=kâˆ’u
|{M âˆˆC | colsp(M ) = S}|
=
kâˆ’u

j=0
k âˆ’j
u

q
Wj(C ).
(6)
Combining Eqs.(5) and (6) one obtains the desired result.
Example 2 Let q = 2, k = 2, m = 3. Let C âŠ†FkÃ—m
q
be the 2-dimensional linear
code generated over F5 âˆ¼= Z/5Z by the matrices
1 0 2
0 2 4

,
2 3 0
1 4 0

.
We have W0(C ) = 1, W1(C ) = 8 and W2(C ) = 16. Using Theorem 2 one computes
W0(C âŠ¥) = 1, W1(C âŠ¥) = 65 and W2(C ) = 560. Observe that C âŠ¥has dimension
6 âˆ’2 = 4, and that 1 + 64 + 560 = 625 = 54, as expected.
We now present a different formulation of the MacWilliams identities for the rank
metric. The following result is [12, Theorem 31].
Theorem 3 Let C âŠ†FkÃ—m
q
be a linear code. For all 0 â‰¤Î½ â‰¤k we have
kâˆ’Î½

i=0
Wi(C )
k âˆ’i
Î½

q
=
|C |
qmÎ½
Î½

j=0
Wj(C âŠ¥)
k âˆ’j
Î½ âˆ’j

q
.
Proof Proposition 2 gives

UâŠ†Fk
q
dim(U)=kâˆ’Î½
|C (U)|
=
|C |
qmÎ½

UâŠ†Fk
q
dim(U)=Î½
|C âŠ¥(U)|.
(7)
Observe that

UâŠ†Fk
q
dim(U)=kâˆ’Î½
|C (U)| = |{(U, M ) | U âŠ†Fk
q, dim(U) = k âˆ’Î½, M âˆˆC , colsp(M ) âŠ†U}|

Codes Endowed with the Rank Metric
13
=

M âˆˆC
|{U âŠ†Fk
q, dim(U) = k âˆ’Î½, colsp(M ) âŠ†U}|
=
k

i=0

M âˆˆC
rk(M )=i
|{U âŠ†Fk
q, dim(U) = k âˆ’Î½, colsp(M ) âŠ†U}|
=
k

i=0

M âˆˆC
rk(M )=i

k âˆ’i
k âˆ’Î½ âˆ’i

q
=
kâˆ’Î½

i=0
Wi(C )
k âˆ’i
Î½

q
.
(8)
Using the same argument with C âŠ¥and k âˆ’Î½ one shows that

UâŠ†Fk
q
dim(U)=Î½
|C âŠ¥(U)| =
kâˆ’Î½

j=0
Wj(C âŠ¥)
k âˆ’j
Î½ âˆ’j

q
.
(9)
The result now follows combining Eqs.(7), (8) and (9).
Remark 1 The two formulations of the MacWilliams identities for the rank metric
given in Theorems 2 and 3 are equivalent. See [6, Corollary 1 and Proposition 3] and
[12, Theorem 61] for details.
The next theorem is [2, Theorem 27], and shows that the weight distribution of a
linear code is determined by its parameters, together with the number of codewords
of small weight. We state it without proof. An application of this result will be given
in Sect.3 (see Corollary 3).
Theorem 4 Let C âŠ†FkÃ—m
q
be a linear code with 1 â‰¤dim(C ) â‰¤km âˆ’1, minimum
distance d = d(C ), and dual minimum distance dâŠ¥= d(C âŠ¥). Let Îµ = 1 if C is
MRD, and Îµ = 0 otherwise. For all 1 â‰¤i â‰¤dâŠ¥we have
Wkâˆ’dâŠ¥+i(C ) = (âˆ’1)iq(i
2)
kâˆ’d

u=dâŠ¥

u
dâŠ¥âˆ’i

q
u âˆ’dâŠ¥+ i âˆ’1
i âˆ’1

q
Wkâˆ’u(C )
+

k
dâŠ¥âˆ’i

q
iâˆ’1âˆ’Îµ

u=0
(âˆ’1)uq(u
2)
k âˆ’dâŠ¥+ i
u

q

qdim(C )âˆ’m(dâŠ¥âˆ’i+u) âˆ’1

.
In particular, k, m, t, d, dâŠ¥and Wd(C ), . . . , Wkâˆ’dâŠ¥(C ) completely determine the
weight distribution of C .
We conclude this section showing how MacWilliams identities for the rank metric
can be employed to solve certain enumerative problems of matrices over ï¬nite ï¬elds.
The following result is [13, Corollary 52].
Corollary 1 Let I âŠ†{(i, j) âˆˆ{1, ..., k} Ã— {1, ..., m} | i = j} be a set of diagonal
entries. For all 0 â‰¤r â‰¤k the number of k Ã— m matrices M over Fq having rank r
and Mij = 0 for all (i, j) âˆˆI is

14
E. Gorla and A. Ravagnani
qâˆ’|I|
k

t=0
|I|
t

(q âˆ’1)t
k

u=0
(âˆ’1)râˆ’u qmu+(râˆ’u
2 )
k âˆ’u
k âˆ’r

q
k âˆ’t
u

q
.
Proof Deï¬ne the linear code C = {M âˆˆFkÃ—m
q
| Mij = 0 for all (i, j) /âˆˆI} âŠ†FkÃ—m
q
.
Then dim(C ) = |I|, Wt(C ) = 0 for |I| < t â‰¤k, and
Wt(C ) =
|I|
t

(q âˆ’1)t
for 0 â‰¤t â‰¤|I|. Moreover, C âŠ¥= {M âˆˆFkÃ—m
q
| Mij = 0 for all (i, j) âˆˆI}. Therefore
the number of matrices M âˆˆFkÃ—m
q
having rank r and Mij = 0 for all (i, j) âˆˆI is
precisely Wr(C âŠ¥). The corollary now follows from Theorem 2.
3
MRD Codes
In this section we study rank-metric codes that have the largest possible cardinality
for their parameters. We start with a Singleton-type bound for the cardinality of a
rank-metric code of given minimum distance. A code is called MRD if it attains the
bound. We then show that for any admissible choice of the parameters there exists a
linear MRD code with those parameters.
In the second part of the section we study general structural properties of MRD
codes. We ï¬rst prove in Theorem 7 that the dual of a linear MRD code is MRD. Then
we show in Theorem 8 that the weight distribution of a possibly non-linear MRD
code C âŠ†FkÃ—m
q
with 0 âˆˆC is determined by k, m and d(C ). As a corollary, we
prove that these three parameters completely determine the distance distribution of
any MRD code. Our proofs are inspired by the lattice-theory approach to the weight
functions of coding theory proposed in [13, 14].
Theorem 5 (Singleton-like bound) Let C âŠ†FkÃ—m
q
be a rank-metric code with |C | â‰¥
2 and minimum distance d. Then |C | â‰¤qm(kâˆ’d+1).
Proof Let Ï€ : C â†’F(kâˆ’d+1)Ã—m
q
denote the projection on the last k âˆ’d + 1 rows.
Since C has minimum distance d, the map Ï€ is injective. Therefore
|C | = |Ï€(C )| â‰¤qm(kâˆ’d+1).
A code is MRD if its parameters attain the Singleton-like bound.
Deï¬nition 8 We say that C âŠ†FkÃ—m
q
is an MRD code if |C | = 1, or |C | â‰¥2 and
|C | = qm(kâˆ’d+1), where d = d(C ).
We now prove that for any choice of q, k, m and d there exists a linear rank-metric
code C âŠ†FkÃ—m
q
that attains the bound of Theorem 5. This result was ï¬rst shown by

Codes Endowed with the Rank Metric
15
Delsarte in [3], and rediscovered independently by Gabidulin in [5] and by KÃ¶tter
and Kschischang in [8] in the context of linear network coding.
Theorem 6 For all 1 â‰¤d â‰¤k there exists an Fqm-linear vector rank-metric code
C âŠ†Fk
qm with dG(C) = d and dimFqm(C) = k âˆ’d + 1. In particular, there exists a
linear MRD code C âŠ†FkÃ—m
q
with d(C ) = d.
We include an elegant proof for Theorem 6 from [8]. Recall that a linearized
polynomial p over Fqm is a polynomial of the form
p(x) = Î±0x + Î±1xq + Î±2xq2 + Â· Â· Â· + Î±sxqs,
Î±i âˆˆFqm, i = 0, ..., s.
The degree of p, denoted by deg(p), is the largest integer i â‰¥0 such that Î±i Ì¸= 0. The
Fqm-vector space of linearized polynomials over Fqm of degree at most s is denoted
by Linq(m, s). It is easy to see that dimFqm(Linq(m, s)) = s + 1.
Remark 2 The roots of a linearized polynomial p over Fqm form an Fq-vector sub-
space of Fqm (see [10], Theorem 3.50), which we denote by V (p) âŠ†Fqm in the sequel.
Clearly, for any non-zero linearized polynomial p we have dimFq V (p) â‰¤deg(p) by
the Fundamental Theorem of Algebra.
Proof (of Theorem 6) Let E = {Î²1, ..., Î²k} âŠ†Fqm be a set of Fq-independent ele-
ments. These elements exist as k â‰¤m by assumption. Deï¬ne the Fqm-linear map
evE : Linq(m, k âˆ’d) â†’Fk
qm,
evE(p) = (p(Î²1), ..., p(Î²k)) for p âˆˆLinq(m, k âˆ’d).
We claim that C = evE(Linq(m, k âˆ’d)) âŠ†Fk
qm is a vector rank-metric code with the
desired properties.
Clearly, C is Fqm-linear. Now let p âˆˆLinq(m, k âˆ’d) be a non-zero linearized
polynomial, and let W âŠ†Fqm denote the space generated over Fq by the eval-
uations p(Î²1), ..., p(Î²k). The polynomial p induces an Fq-linear evaluation map
p : âŸ¨Î²1, ..., Î²kâŸ©Fq â†’Fqm. The image of p is W, and therefore by the rank-nullity theo-
rem we have dimFq(W) = k âˆ’dimFq V (p). By Remark 2 we conclude dimFq(W) â‰¥
k âˆ’(k âˆ’d) = d. This shows that dG(C) â‰¥d. In particular, as d â‰¥1, the map evE
is injective, and the dimension of C is dimFqm(C) = k âˆ’d + 1. Combining Propo-
sition 1 and Theorem 5 we obtain dG(C) = d.
The second part of the theorem immediately follows from Proposition 1.
The MRD code construction in the proof of Theorem 6 was later generalized by
Sheekey in [15], introducing a new class of MRD codes. See chapter â€œConstructions
of Cyclic Subspace Codes and Maximum Rank Distance Codesâ€ for other construc-
tions of MRD codes.
The reminder of the section is devoted to the structural properties of MRD codes.
We start with a preliminary result from [14, Chap. 7].

16
E. Gorla and A. Ravagnani
Lemma 3 Let C âŠ†FkÃ—m
q
be an MRD code with |C | â‰¥2 and minimum distance d.
For all subspaces U âŠ†Fk
q with u = dim(U) â‰¥d âˆ’1 we have
|C (U)| = qm(uâˆ’d+1).
Proof As in Lemma 1, deï¬ne V = {(x1, ..., xk) âˆˆFk
q | xi = 0 for i > u} âŠ†Fk
q. Let
g : Fk
q â†’Fk
q be an Fq-isomorphism with f (U) = V . Denote by G âˆˆFkÃ—k
q
the matrix
associated to g with respect to the canonical basis of Fk
q. Deï¬ne the rank-metric code
D = GC = {GM | M âˆˆC }. Clearly, D has the same dimension and minimum
distance as C . In particular, it is MRD. Observe moreover that C (U) = D(V ).
Consider the maps
D
Ï€1
âˆ’â†’F(kâˆ’d+1)Ã—m
q
Ï€2
âˆ’â†’F(kâˆ’u)Ã—m
q
,
where Ï€1 is the projection on the last k âˆ’d + 1 coordinates, and Ï€2 is the projection
on the last k âˆ’u coordinates. Since d(D) = d, Ï€1 is injective. Since D is MRD, we
have logq(|D|) = m(k âˆ’d + 1). Therefore Ï€1 is bijective. The map Ï€2 is Fq-linear
and surjective. Therefore
|Ï€âˆ’1
2 (0)| = |Ï€âˆ’1
2 (M )| = qm(uâˆ’d+1) for all M âˆˆF(kâˆ’u)Ã—m
q
.
Since Ï€1 is bijective and Ï€2 is surjective, the map Ï€ = Ï€2 â—¦Ï€1 is surjective. Moreover,
|Ï€âˆ’1(0)| = |Ï€âˆ’1(M )| = qm(uâˆ’d+1) for all M âˆˆF(kâˆ’u)Ã—m
q
.
The lemma now follows from the identity C (U) = D(V ) = Ï€âˆ’1(0).
We can now show that the dual of a linear MRD code is MRD. The next funda-
mental result is [13, Theorem 5.5].
Theorem 7 Let C âŠ†FkÃ—m
q
be a linear MRD code. Then C âŠ¥is MRD.
Proof The result is immediate if dim(C ) âˆˆ{0, km}. Assume 1 â‰¤dim(C ) â‰¤km âˆ’1,
and let d = d(C ), dâŠ¥= d(C âŠ¥). Applying Theorem 5 to C and C âŠ¥we obtain
dim(C ) â‰¤m(k âˆ’d + 1),
dim(C âŠ¥) â‰¤m(k âˆ’dâŠ¥+ 1).
Therefore km = dim(C ) + dim(C âŠ¥) â‰¤2mk âˆ’m(d + dâŠ¥) + 2m, i.e.,
d + dâŠ¥â‰¤k + 2.
(10)
Let U âŠ†Fk
q be any Fq-subspace with dim(U) = k âˆ’d + 1. By Proposition 2 we
have
|C âŠ¥(U)| =
|C âŠ¥|
qm(dâˆ’1) |C (U âŠ¥)|.
(11)

Codes Endowed with the Rank Metric
17
Since dim(U âŠ¥) = d âˆ’1, by Lemma 3 we have |C (U âŠ¥)| = |C |/qm(kâˆ’d+1) = 1,
where the last equality follows from the fact that C is MRD. Therefore (11) becomes
|C âŠ¥(U)| =
|C âŠ¥|
qm(dâˆ’1) = qkm/qm(dâˆ’1)
qm(dâˆ’1)
= 1.
Since U is arbitrary with dim(U) = k âˆ’d + 1, this shows dâŠ¥â‰¥k âˆ’d + 2.
Using (10) we conclude dâŠ¥= k âˆ’d + 2. The theorem now follows from
dim(C âŠ¥) = km âˆ’dim(C ) = km âˆ’m(k âˆ’d + 1) = m(k âˆ’dâŠ¥+ 1).
The proof of Theorem 7 also shows the following useful characterization of linear
MRD codes in terms of their minimum distance and dual minimum distance.
Proposition 3 Let C âŠ†FkÃ—m
q
be a linear code with 1 â‰¤dim(C ) â‰¤km âˆ’1. The
following are equivalent.
1. C is MRD,
2. C âŠ¥is MRD,
3. d(C ) + d(C âŠ¥) = k + 2.
In the remainder of the section we concentrate on the weight and distance dis-
tributions of (possibly non-linear) MRD codes. We start with a result on the weight
distribution of MRD codes containing the zero vector (see [14, Theorem 7.46]).
Theorem 8 Let C be an MRD code with |C | â‰¥2 and 0 âˆˆC . Let d = d(C ). Then
W0(C ) = 1, Wi(C ) = 0 for 1 â‰¤i â‰¤d âˆ’1, and
Wi(C ) =
dâˆ’1

u=0
(âˆ’1)iâˆ’uq(iâˆ’u
2 )
k
i

q
i
u

q
+
i
u=d
(âˆ’1)iâˆ’uq(iâˆ’u
2 )+m(uâˆ’d+1)
k
i

q
i
u

q
for d â‰¤i â‰¤k.
Proof Since 0 âˆˆC , we have W0(C ) = 1 and Wi(C ) = 0 for 1 â‰¤i â‰¤d âˆ’1. For all
subspaces V âŠ†Fk
q deï¬ne
f (V ) = |{M âˆˆC | colsp(M ) = V }|,
g(V ) =

UâŠ†V
f (U) = |C (V )|.
Fix 0 â‰¤i â‰¤k and a vector space V âŠ†Fk
q of dimension i. By Lemma 2 we have
f (V ) =
i
u=0
(âˆ’1)iâˆ’uq(iâˆ’u
2 )

UâŠ†V
dim(U)=u
g(U).
Using Lemma 3 and the fact that C is MRD with 0 âˆˆC we obtain

18
E. Gorla and A. Ravagnani
g(U) =

1
if 0 â‰¤dim(U) â‰¤d âˆ’1,
qm(uâˆ’d+1) if d â‰¤dim(U) â‰¤k.
Therefore
f (V ) =
dâˆ’1

u=0
(âˆ’1)iâˆ’uq(iâˆ’u
2 )
i
u

q
+
i
u=d
(âˆ’1)iâˆ’uq(iâˆ’u
2 )+m(uâˆ’d+1)
i
u

q
.
The result now follows from the identity
Wi(C ) =

V âŠ†Fk
q
dim(V )=i
f (V ).
Different formulas for the weight distribution of linear MRD codes were obtained
in [4] employing elementary methods.
Theorem 8 implies the following [3, Theorem 5.6], which states that the distance
distribution of any MRD code is determined by its parameters.
Corollary 2 Let C âŠ†FkÃ—m
q
be an MRD code with |C | â‰¥2 and minimum distance
d. We have D0(C ) = 1, Di(C ) = 0 for 1 â‰¤i â‰¤d âˆ’1, and
Di(C ) =
dâˆ’1

u=0
(âˆ’1)iâˆ’uq(iâˆ’u
2 )
k
i

q
i
u

q
+
i
u=d
(âˆ’1)iâˆ’uq(iâˆ’u
2 )+m(uâˆ’d+1)
k
i

q
i
u

q
for d â‰¤i â‰¤k.
Proof Fix an i with d â‰¤i â‰¤k. For N âˆˆC deï¬ne C âˆ’N = {M âˆ’N | M âˆˆC }. By
deï¬nition of distance distribution we have
|C | Â· Di(C ) = |{(M , N) âˆˆC 2 | rk(M âˆ’N) = i}| =

NâˆˆC
Wi(C âˆ’N).
For all N âˆˆC the code C âˆ’N is MRD. Moreover, 0 âˆˆC âˆ’N. The result now easily
follows from Theorem 8.
Corollary 2 shows in particular that the weight distribution of a linear MRD
code is determined by k, m and d(C ). Recall from Proposition 3 that an MRD
code C âŠ†FkÃ—m
q
is characterized by the property d(C ) + d(C âŠ¥) = k + 2. We now
prove that the weight distribution of a linear code C with d(C ) + d(C âŠ¥) = k + 1
is determined by k, m and dim(C ). The following result is [2, Corollary 28].
Corollary 3 Let C âŠ†FkÃ—m
q
be a linear rank-metric code with 1 â‰¤dim(C ) â‰¤km âˆ’
1 and d(C ) + d(C âŠ¥) = k + 1. Then
dim(C ) Ì¸â‰¡0
mod m
and
d(C ) = k âˆ’âŒˆdim(C )/mâŒ‰+ 1.

Codes Endowed with the Rank Metric
19
Moreover, for all d â‰¤i â‰¤k we have
Wi(C ) =
k
i

q
iâˆ’d(C )

u=0
(âˆ’1)uq(u
2)
i
u

q

qdim(C )âˆ’m(k+uâˆ’i) âˆ’1

.
Proof Assume by contradiction that dim(C ) = Î±m for some Î±. Applying Theorem 5
to C and C âŠ¥we obtain
d(C ) â‰¤k âˆ’Î± + 1,
d(C âŠ¥) â‰¤Î± + 1.
(12)
By Proposition 3, the two inequalities in (12) are either both equalities, or both strict
inequalities. Since d(C ) + d(C âŠ¥) = k + 1 by assumption, they must be both strict
inequalities. Therefore
d(C ) â‰¤k âˆ’Î±,
d(C âŠ¥) â‰¤Î±,
hence d(C ) + d(C âŠ¥) â‰¤k, a contradiction. This shows that dim(C ) Ì¸â‰¡0 mod m.
Now write dim(C ) = Î±m + Î² with 1 â‰¤Î² â‰¤m âˆ’1. Applying again Theorem 5
to C and C âŠ¥one ï¬nds
d(C ) â‰¤k âˆ’
Î±m + Î²
m

+ 1 = k âˆ’Î±,
d(C âŠ¥) â‰¤k âˆ’
km âˆ’Î±m âˆ’Î²
m

= Î± + 1.
Since d(C ) + d(C âŠ¥) = k + 1, we must have
d(C ) = k âˆ’
Î±m + Î²
m

+ 1 = k âˆ’
dim(C )
m

+ 1,
as claimed. The last part of the statement follows from Theorem 4.
4
Rank-Metric Anticodes
This section is devoted to rank-metric anticodes, i.e., rank-metric codes in which the
distance between any two matrices is bounded from above by a given integer Î´.
In Theorem 9 we give a bound for the cardinality of a (possibly non-linear)
anticode, using a code-anticode-type bound. We also characterize optimal anticodes
in terms of MRD codes. Then we show that the dual of an optimal linear anticode is
an optimal linear anticode. The main results of this section appear in [12, 14].
Deï¬nition 9 Let 0 â‰¤Î´ â‰¤k be an integer. A (rank-metric) Î´-anticode is a non-
empty subset A âŠ†FkÃ—m
q
such that d(M , N) â‰¤Î´ for all M , N âˆˆA . We say that A
is linear if it is an Fq-linear subspace of FkÃ—m
q
.

20
E. Gorla and A. Ravagnani
Example 3 Any A âŠ†FkÃ—m
q
with |A | = 1 is a 0-anticode. The ambient space FkÃ—m
q
is a k-anticode. The vector space of k Ã— m matrices over Fq whose last k âˆ’Î´ rows
are zero is a linear Î´-anticode of dimension mÎ´.
In the sequel we work with a ï¬xed integer 0 â‰¤Î´ â‰¤k. Moreover, for A , C âŠ†FkÃ—m
q
we set A + C = {M + N | M âˆˆA , N âˆˆC }.
Theorem 9 Let A âŠ†FkÃ—m
q
be a Î´-anticode. Then |A | â‰¤qmÎ´. Moreover, if Î´ â‰¤k âˆ’
1 then the following are equivalent.
1. |A | = qmÎ´.
2. A + C = FkÃ—m
q
for some MRD code C with d(C ) = Î´ + 1.
3. A + C = FkÃ—m
q
for all MRD codes C with d(C ) = Î´ + 1.
Proof Let C âŠ†FkÃ—m
q
be any MRD code with d(C ) = Î´ + 1. Such a code exists by
Theorem 6. For all M âˆˆA let [M ] = M + C = {M + N | N âˆˆC }. Then [M ] âˆ©
[M â€²] = âˆ…for all M , M â€² âˆˆA with M Ì¸= M â€². Moreover, by deï¬nition of MRD code
we have |[M ]| = |C | = qm(kâˆ’Î´) for all M âˆˆA , hence
|FkÃ—m
q
| â‰¥


M âˆˆA
[M ]
 =

M âˆˆA
|[M ]| = |A | Â· |C | = |A | Â· qm(kâˆ’Î´).
Therefore |A | â‰¤qmÎ´, and equality holds if and only if
FkÃ—m
q
=

M âˆˆA
[M ] = A + C .
A similar argument shows that properties 1, 2 and 3 are equivalent.
Deï¬nition 10 We say that a Î´-anticode A is (cardinality)-optimal if it attains the
bound of Theorem 9.
Remark 3 Example 3 shows the existence of optimal linear Î´-anticodes for all
choices of Î´.
In the remainder of the section we prove that the dual of an optimal linear Î´-
anticode is an optimal (k âˆ’Î´)-anticode. The result may be regarded as the analogue
of Theorem 7 in the context of rank-metric anticodes. We start with a preliminary
result on the weight distribution of MRD codes.
Lemma 4 Let C âŠ†FkÃ—m
q
be an MRD code with 0 âˆˆC , |C | â‰¥2 and d(C ) = d.
Then Wd+â„“(C ) > 0 for all 0 â‰¤â„“â‰¤k âˆ’d.
Proof By Theorem 8, we shall prove the lemma for a given MRD code C âŠ†FkÃ—m
q
of our choice with |C | â‰¥2, minimum distance d, and 0 âˆˆC . We will ï¬rst produce
a convenient MRD code with the prescribed properties.

Codes Endowed with the Rank Metric
21
Let C âŠ†Fk
qm be the vector rank-metric code constructed in the proof of Theorem 6,
with evaluation set E = {Î²1, ..., Î²k} and evaluation map evE. Let Î“ be any basis of
Fqm over Fq. By Proposition 1, C = Î“ (C) âŠ†FkÃ—m
q
is a linear code with dim(C ) =
m(k âˆ’d + 1) and the same weight distribution as C. In particular, C is a non-zero
linear MRD code with minimum distance d.
Now we prove the lemma for the MRD code C constructed above. Fix â„“with
0 â‰¤â„“â‰¤k âˆ’d. Deï¬ne t = k âˆ’d âˆ’â„“, and letU âŠ†Fqm be the Fq-subspace generated
by {Î²1, ..., Î²t}. If t = 0 we set U to be the zero space. By [10], Theorem 3.52,
pU =

Î³ âˆˆU
(x âˆ’Î³ )
is a linearized polynomial over Fqm of degree t = k âˆ’d âˆ’â„“â‰¤k âˆ’d, i.e., by def-
inition, pU âˆˆLinq(n, k âˆ’d). Therefore by Proposition 1 it sufï¬ces to prove that
evE(pU) = (pU(Î²1), ..., pU(Î²k)) has rank d + â„“= k âˆ’t. Clearly, V (pU) = U. In
particular we have evE(pU) = (0, ..., 0, pU(Î²t+1), ..., pU(Î²k)). We will show that
pU(Î²t+1), ..., pU(Î²k) are linearly independent over Fq. Assume that there exist
at+1, ..., ak âˆˆFq such that k
i=t+1 aipU(Î²i) = 0. Then we have pU
k
i=t+1 aiÎ²i

=
0, i.e., k
i=t+1 aiÎ²i âˆˆV (pU) = U. It follows that there exist a1, ..., at âˆˆFq such
that t
i=1 aiÎ²i = k
i=t+1 aiÎ²i, i.e., t
i=1 aiÎ²i âˆ’k
i=t+1 aiÎ²i = 0. Since Î²1, ..., Î²k
are independent over Fq, we have ai = 0 for all i = 1, ..., k. In particular ai = 0
for i = t + 1, ..., k. Hence pU(Î²t+1), ..., pU(Î²k) are linearly independent over Fq, as
claimed.
The following proposition characterizes optimal linear anticodes in terms of their
intersection with linear MRD codes.
Proposition 4 Assume 0 â‰¤Î´ â‰¤k âˆ’1, and let A âŠ†FkÃ—m
q
be a linear code with
dim(C ) = mÎ´. The following are equivalent.
1. A is an optimal Î´-anticode.
2. A âˆ©C = {0} for all non-zero MRD linear codes C âŠ†FkÃ—m
q
with d(C ) = Î´ + 1.
Proof By Theorem 9, it sufï¬ces to show that if A âˆ©C = {0} for all non-zero MRD
linear codes C âŠ†FkÃ—m
q
with d(C ) = Î´ + 1, then A is a Î´-anticode.
By contradiction, assume that A is not a Î´-anticode. Since A is linear, by def-
inition of Î´-anticode there exists N âˆˆC with rk(N) â‰¥Î´ + 1. Let D be a non-zero
linear MRD code with d(D) = Î´ + 1 (see Theorem 6 for the existence of such a
code). By Lemma 4 there exists M âˆˆD with rk(M ) = rk(N). There exist invert-
ible matrices A and B of size k Ã— k and m Ã— m, resp., such that N = AMB. Deï¬ne
C = ADB = {APB | P âˆˆD}. Then C âŠ†FkÃ—m
q
is a non-zero linear MRD code with
d(C ) = Î´ + 1 and such that N âˆˆA âˆ©C . Since rk(N) â‰¥Î´ + 1 â‰¥1, N is not the
zero matrix. Therefore A âˆ©C Ì¸= {0}, a contradiction.
We conclude the section showing that the dual of an optimal linear anticode is an
optimal linear anticode.

22
E. Gorla and A. Ravagnani
Theorem 10 LetA âŠ†FkÃ—m
q
beanoptimallinearÎ´-anticode.ThenA âŠ¥isanoptimal
linear (k âˆ’Î´)-anticode.
Proof Let A âŠ†FkÃ—m
q
be an optimal linear Î´-anticode. If Î´ = k then the result is
trivial. From now on we assume 0 â‰¤Î´ â‰¤k âˆ’1. By Deï¬nition 10 we have dim(A ) =
mÎ´, hence dim(A âŠ¥) = m(k âˆ’Î´). Therefore by Proposition 4 it sufï¬ces to show
that A âŠ¥âˆ©C = {0} for all non-zero linear MRD codes C âŠ†FkÃ—m
q
with d(C ) =
k âˆ’Î´ + 1. Let C be such a code. Then
dim(C ) = m(k âˆ’(k âˆ’Î´ + 1) + 1) = mÎ´ < mk.
Combining Theorem 7 and Proposition 3 one shows that C âŠ¥is a linear MRD code
with d(C âŠ¥) = k âˆ’(k âˆ’Î´ + 1) + 2 = Î´ + 1. By Proposition 4 we have A âˆ©C âŠ¥=
{0}. Since dim(A ) + dim(C âŠ¥) = mÎ´ + m(k âˆ’(Î´ + 1) + 1) = mk, we have A âŠ•
C âŠ¥= FkÃ—m
q
. Therefore {0} = (FkÃ—m
q
)âŠ¥= (A âŠ•C âŠ¥)âŠ¥= A âŠ¥âˆ©C . This shows the
theorem.
References
1. R. Ahlswede, N. Cai, S.-Y.R. Li, R.W. Yeung, Network information ï¬‚ow. IEEE Trans. Inf.
Theory 46(4), 1204â€“1216 (2000)
2. J. De la Cruz, E. Gorla, H.H. LÃ³pez, A. Ravagnani, Rank distribution of Delsarte codes. Des.
Codes Cryptogr. (to appear)
3. P. Delsarte, Bilinear forms over a ï¬nite ï¬eld, with applications to coding theory. J. Comb.
Theory A 25(3), 226â€“241 (1978)
4. J.G. Dumas, R. Gow, G. McGuire, J. Sheekey, Subspaces of matrices with special rank prop-
erties. Linear Algebr. Appl. 433, 191â€“202 (2010)
5. E. Gabidulin, Theory of codes with maximum rank distance. Probl. Inf. Transm. 1(2), 1â€“12
(1985)
6. M. Gadouleau, Z. Yan, MacWilliams Identities for Codes with the Rank Metric. EURASIP J.
Wirel. Commun. Networ. (2008)
7. E. Gorla, A. Ravagnani, Subspace codes from Ferrers diagrams. J. Algebr. Appl. 16, 7 (2017)
8. R. KÃ¶tter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579â€“3591 (2008)
9. S.-Y.R. Li, R.W. Yeung, N. Cai, Linear network coding. IEEE Trans. Inf. Theory 49(2), 371â€“
381 (2003)
10. R. Lidl, H. Niederreiter, Finite Fields. Addison-Wesley Publishing Company (1983)
11. F.J. MacWilliams, A theorem on the distribution of weights in a systematic code. Bell Syst.
Tech. J. 42(1), 79â€“94 (1963)
12. A. Ravagnani, Rank-metric codes and their duality theory. Des. Codes Cryptogr. 80(1), 197â€“
216 (2016)
13. A.Ravagnani,Dualityofcodessupportedonregularlattices,withanapplicationtoenumerative
combinatorics. Submitted. Online preprint: https://arxiv.org/abs/1510.02383
14. A. Ravagnani, Properties and Constructions of Codes with the Rank and the Subspace Metric.
PhD thesis, UniversitÃ© de NeuchÃ¢tel, 2016
15. J. Sheekey, A new family of MRD codes. Adv. Math. Commun. 10, 3 (2016)
16. D. Silva, F.R. Kschishang, On metrics for error correction in network coding. IEEE Trans. Inf.
Theory 55(12), 5479â€“5490 (2009)

Codes Endowed with the Rank Metric
23
17. D. Silva, F.R. Kschischang, On metrics for error correction in network coding. IEEE Trans.
Inf. Theory 55(12), 5479â€“5490 (2009)
18. D. Silva, E.S. Rogers, F.R. Kschishang, R. Koetter, A Rank-Metric Approach to Error Control
in Random Network Coding. IEEE Trans. Inf. Theory 54(9), 3951â€“3967 (2008)
19. P. Stanley, Enumerative Combinatorics, vol. 1, Cambridge Stud. Adv. Math., vol. 49. Cam-
bridge University Press (2012)

Constructions of Constant Dimension Codes
Anna-Lena Horlemann-Trautmann and Joachim Rosenthal
Abstract Constant dimension codes are subsets of the ï¬nite Grassmann variety. The
subspace distance is a natural metric on the Grassmannian. It is desirable to have
constructions of codes with large cardinality and efï¬cient decoding algorithm for
all parameters. This article provides a survey on constructions of constant dimen-
sion codes with a prescribed minimum distance. The article starts with a review of
geometric properties of the Grassmann variety. We emphasize the classical PlÃ¼cker
embedding which shows that the Grassmannian describing all k-dimensional sub-
spaces of a vector space can be naturally embedded in a projective space and hence
has the structure of a projective variety itself. On the construction side we ï¬rst con-
centrate on the construction of equidistant codes, which include spreads and partial
spreads. Then we review constructions based on matrix codes equipped with the
rank metric, in particular those matrices whose non-zero entries constitute certain
Ferrers diagrams. A large part of the survey is then concerned with orbit codes, i.e.,
subsets of the Grassmannian that can be expressed as the orbit under an action of
an algebraic group. Finally we review several constructions of constant dimension
codes starting with another constant dimension code having good parameters. We
conclude by giving references to other results related to constant dimension codes
and references to results on constructions of mixed dimension codes.
A.-L. Horlemann-Trautmann (B)
Faculty of Mathematics and Statistics, University of St. Gallen,
Bodanstrasse 6, 9000 St. Gallen, Switzerland
e-mail: anna-lena.horlemann@unisg.ch
J. Rosenthal
Mathematics Institute, University of Zurich, Winterthurerstr 190,
8057 Zurich, Switzerland
e-mail: rosen@math.uzh.ch
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_2
25

26
A.-L. Horlemann-Trautmann and J. Rosenthal
1
Introduction
In this article we give an overview of general constructions of constant dimension
codes, also called Grassmannian codes.
The framework for these codes and their usage for error-correction in random (or
non-coherent) network coding was ï¬rst given in [42]. There a subspace code was
deï¬ned as a set of subspaces of Fn
q, Fq the ï¬nite ï¬eld of q elements, equipped with
the subspace distance, deï¬ned as
dS(U, V) := dim(U + V) âˆ’dim(U âˆ©V)
(1)
for U, V âŠ†Fn
q. For simplicity, one often restricts to constant dimension codes, where
all codewords have the same ï¬xed dimension k. Thus, a constant dimension code
is a subset C of the Grassmann variety Grass(k, Fn
q), which we will also denote by
Gq(k, n). Because of this constant dimension codes are also called Grassmannian
codes in the literature.
As in the classical literature on coding theory one deï¬nes the minimum distance
dist(C) of a code C as the minimal distance of two different code elements; in this case
the minimal subspace distance between two subspaces. The goal is once more the
construction of subspace codes with many code elements and prescribed minimum
distance. For the most part of this paper we will focus on constructions of constant
dimension codes; we give a short overview of mixed dimension code constructions
in the end.
The paper is structured in the following way. In Sect.2 we will collect some
background material on the geometry of the ï¬nite Grassmann variety, which serves
as the ambient space for constant dimension codes.
In Sect.3 we will cover spread codes, partial spread codes and equidistant codes.
Spread and partial spread codes are characterized by the property that they have the
maximal possible minimum distance 2k. Spread codes can be deï¬ned if k divides
n; they have maximal cardinality among all codes with this minimum distance. A
generalization of (partial) spreads are equidistant codes, where any two codewords
must have the same ï¬xed distance, but not necessarily distance 2k.
One of the most successful ways to construct constant dimension codes with large
minimum distance is through a lifting process starting with some rank-metric code
of a given minimum distance. In Sect.4 we will survey some of these constructions.
The general linear group GLn acts naturally and transitively on the Grassmannian.
In Sect.5 we will give an overview on constant dimension codes which are also orbits
of some subgroup G of GLn acting on the Grassmannian. Like classical linear codes
the class of orbit codes have a rich mathematical structure.
As it is the case for the construction of classical linear codes inside Fn
q there are
also several known techniques to come up with constructions of constant dimension
codes from known constant dimension codes of smaller parameters. These techniques
are surveyed in Sect.6.

Constructions of Constant Dimension Codes
27
The focus of our survey is on algebraic constructions of constant dimension codes.
Constructions from combinatorial designs will be covered in chapter â€œq-analogs
of Designs: Subspace Designsâ€ of this book. We also do not treat codes which were
derived by computer searches, but we give some references in this regard in the ï¬nal
remarks of this paper.
2
Remarks on the Geometry of the Finite Grassmann
Variety
Assume k < n are two integers. The set of all k-dimensional subspaces in Fn
q is called
the Grassmann variety or Grassmannian which we will denote by Gq(k, n). As the
name indicates the Grassmannian has a variety structure. To be more precise the set
Gq(k, n) can be embedded into a projective space using the PlÃ¼cker embedding:
Ï• : Gq(k, n) âˆ’â†’P(Î›kFn
q) = P(n
k)âˆ’1
span(u1, . . . , uk) âˆ’â†’Fq(u1 âˆ§. . . âˆ§uk).
The image of the map Ï• is described by a set of quadratic equations called shufï¬‚e
relations. In order to make this more precise we will introduce a basis and coordinate
functions. For this assume {e1, . . . , en} is the canonical basis of Fn
q. Then N kFn
q has
as a canonical basis
{ei1 âˆ§. . . âˆ§eik | 1 â‰¤i1 < . . . < ik â‰¤n}.
If an element of the Grassmannian Gq(k, n) is described by a full rank k Ã— n matrix
U then an elementary computation shows that the PlÃ¼cker coordinates of a subspace
rs(U) inside the projective space P(n
k)âˆ’1 are exactly the k Ã— k full size minors of the
k Ã— n matrix U.
In the sequel denote by U[i1, . . . , ik] the submatrix of U given by the columns
i1, . . . , ik. The numbers xi1,...,ik := det(U[i1, . . . , ik]) are then called the PlÃ¼cker
coordinates of the subspace rs(U). In terms of PlÃ¼cker coordinates the PlÃ¼cker
embedding is simply described through
rs(U) âˆ’â†’(x1,...,k : x1,...,kâˆ’1,k+1 : ... : xnâˆ’k+1,...,n).
A vector inside the projective space P(n
k)âˆ’1 is in the image of the PlÃ¼cker map
Ï• exactly when the coordinates satisfy the shufï¬‚e relations as formulated in the
following proposition:
Proposition 1 ([40, 47]) Consider x := [x1,...,k : Â· Â· Â· : xnâˆ’k+1,...,n] âˆˆP(n
k)âˆ’1. Then
there exists a subspace U âˆˆGq(k, n) such that Ï•(U) = x if and only if

28
A.-L. Horlemann-Trautmann and J. Rosenthal

jâˆˆ{i1,...,ik+1}
sgn(Ïƒ j)xi1,...,ik+1\ jx j,ik+2,...,i2k = 0
(2)
âˆ€(i1, . . . , ik+1) âˆˆ
 [n]
k+1

, (ik+2, . . . , i2k) âˆˆ
 [n]
kâˆ’1

, where sgn(Ïƒ j) denotes the sign of
the permutation such that
Ïƒiâ„“(i1, . . . , ik+1) = (iâ„“, i1, . . . , iâ„“âˆ’1, iâ„“+1, . . . , ik+1).
Note that the shufï¬‚e relations (2) form a set of quadratic equations in terms of the
PlÃ¼cker coordinates, and these equations describe exactly the image of the PlÃ¼cker
map Ï•. It follows that the Grassmannian Gq(k, n) has the structure of a projective
variety.
If one considers all subspaces rs(U) whose ï¬rst PlÃ¼cker coordinate x1,...,k is
nonzero one sees that this is a Zariski open set isomorphic to Fk(nâˆ’k)
q
, in particu-
lar the dimension of Gq(k, n) is equal to k(n âˆ’k).
The above dimension calculation is true over any base ï¬eld F. Over a ï¬nite ï¬eld
Gq(k, n) is a ï¬nite set and it is well-known that the cardinality of the Grassmannian
is given by the Gaussian binomial, i.e.,
|Gq(k, n)| =
n
j

q
=
kâˆ’1

i=0
qn âˆ’qi
qk âˆ’qi .
For the purpose of coding theory it is important to understand the set of all sub-
spaces V âˆˆGq(k, n) whose subspace distance (1) to a given subspace U is at most
t. In other words we are interested in the geometric structure of the ball of radius t
around a subspace U:
Bt := {V âˆˆGq(k, n) | dS(U, V) â‰¤t}.
The subsets Bt have classically been studied in the algebraic geometry literature and
as a matter of fact Bt is a special case of a so called Schubert variety.
In order to make this notion more precise one considers a so called ï¬‚ag F, this is
a sequence of nested linear subspaces
F : {0} âŠ‚V1 âŠ‚V2 âŠ‚. . . âŠ‚Vn = Fn
q,
where one requires that dim V j = j for j = 1, . . . , n. Denote by Î½ = (Î½1, . . . , Î½k)
an ordered index set satisfying
1 â‰¤Î½1 < . . . < Î½k â‰¤n.
For a given ï¬‚ag F one deï¬nes the Schubert variety
S(Î½; F) := {W âˆˆGq(k, n) | dim(W

Vvi) â‰¥i for i = 1, . . . , k}.
(3)

Constructions of Constant Dimension Codes
29
The Schubert varieties are sub-varieties of the Grassmannian Gq(k, n). The deï¬ning
equations of the Schubert variety S(Î½; F) in terms of PlÃ¼cker coordinates are on
one side the deï¬ning shufï¬‚e relations (2) describing the Grassmannian Gq(k, n). In
addition a set of linear equations (see [40]) have to be satisï¬ed. These equations
simplify if one wants to describe the ball Bt only and the interested reader will ï¬nd
more details in [48].
Using the natural inner product inside the vector space Fn
q one has a natural dual-
ity between a k-dimensional subspace U âˆˆGq(k, n) and the (n âˆ’k)-dimensional
subspace UâŠ¥âˆˆGq(n âˆ’k, n). This duality induces a duality between the Grassmann
variety Gq(k, n) and the Grassmannian Gq(n âˆ’k, n), in particular both these Grass-
mannians are isomorphic. In case C âŠ†Gq(k, n) is a subspace code it was pointed out
in [42, Sect.3.A] that the dual code CâŠ¥âŠ†Gq(n âˆ’k, n) has the same cardinality and
minimum subspace distance as C. For the purpose of studying codes it is therefore
enough to restrict the study to codes in Gq(k, n) with n â‰¥2k.
Grassmannians Gq(k, n) are also homogeneous spaces. For this note that the gen-
eral linear group GLn acts naturally and transitively on Gq(k, n) through â€˜right mul-
tiplicationâ€™:
Gq(k, n) Ã— GLn â†’Gq(k, n)
(rs(U), A) â†’rs(U A).
As a consequence the tangent space at every point of Gq(k, n) is isomorphic and it
follows that Gq(k, n) is also a smooth variety. If one restricts above GLn-action to
some subgroup G âŠ†GLn then one obtains a partition of Gq(k, n) into G-orbits. In
terms of coding theory a particular G-orbit deï¬nes a so called orbit code, which we
will say more about in Sect.5.
3
Spread Codes, Partial Spread Codes and Equidistant
Codes
The maximal possible distance two elements U, V âˆˆC âŠ†Gq(k, n) of a constant
dimension code can have is dS(U, V) = 2k and this happens exactly when
U âˆ©V = {0}.
As a consequence the maximal possible minimum distance a constant dimension
code C âŠ†Gq(k, n) can have is 2k.
Thenaturalquestionhenceariseswhatthemaximalcardinalityofnon-intersecting
k-dimensional subspaces in Fn
q can be?
When n is a multiple of k, i.e., n = rk for some natural number r, then it is a well
known result in ï¬nite geometry [34] that one has a collection of constant dimensional
subspaces in Fn
q having the property that any two subspaces intersect only in a trivial

30
A.-L. Horlemann-Trautmann and J. Rosenthal
manner and in addition every nonzero vector v âˆˆFn
q lies in one and only one subspace
of this collection.
Deï¬nition 2 Let n = rk. Then a set S âŠ†Gq(k, n) is called a spread if all elements
of S intersect only trivially and they cover the whole space Fn
q.
One immediately computes the cardinality of a spread as
qn âˆ’1
qk âˆ’1 = qk(râˆ’1) + qk(râˆ’2) + Â· Â· Â· + qk + 1.
i.e., a spread in Gq(k, n) is a constant dimension code with minimum distance 2k and
cardinality (qn âˆ’1)/(qk âˆ’1). In [44] constant dimension codes which also have the
structure of a spread were called spread codes. A concrete construction of spread
codes can be obtained in the following way:
Let P be the k Ã— k companion matrix of a monic and irreducible polynomial
p(x) âˆˆFq[x] of degree k. It is then well known (see e.g. [43]) that the Fq-algebra
Fq[P] âŠ‚FkÃ—k
q
is isomorphic to the ï¬nite ï¬eld Fqk. Denote by 0k, Ik âˆˆFkÃ—k
q
the zero
and the identity matrix respectively. Then one has the following theorem which was
proven in [44]:
Theorem 3 Let n = rk. The collection of subspaces
S :=
r	
i=1

rs

0k Â· Â· Â· 0k Ik Ai+1 Â· Â· Â· Ar

| Ai+1, . . . , Ar âˆˆFq[P]

âŠ‚Gq(k, n)
is a spread code with minimum distance 2k and cardinality (qn âˆ’1)/(qk âˆ’1).
Spreads are similar to classical MDS codes in the sense that they have maximal
possible minimum distance and at the same time maximal cardinality.
In [27] the authors studied the situation when k does not divide n. For these cases
spreads cannot exist but the construction of Theorem 3 can be done â€˜up to the last
blockâ€™ and this then leads to the notion of a partial spread code. The following
deï¬nition was inspired by work in ï¬nite geometry [7]:
Deï¬nition 4 ([27, 28]) A partial spread code in Gq(k, n) is a subspace code C âŠ‚
Gq(k, n) having minimum distance dist(C) = 2k.
In [27] a concrete construction of a partial spread code is provided whose cardi-
nality is maximal among all subspace codes of minimum distance 2k inside Gq(k, n).
For more information on partial spreads the reader is referred to chapters â€œGeo-
metrical Aspects Of Subspace Codesâ€ and â€œPartial Spreads And Vector Space
Partitionsâ€ of this book.
Spread codes and partial spread codes are special cases of equidistant subspace
codes â€“ these are codes where any two distinct code words have the same distance:
Deï¬nition 5 A code C âŠ†Gq(k, n) is an equidistant code if for any U, V âˆˆC
dS(U, V) = d for some ï¬xed d.

Constructions of Constant Dimension Codes
31
Note that for (partial) spread codes any two elements have distance d = 2k.
A special class of equidistant codes is the one of sunï¬‚owers, where all codewords
intersect in the same subspace of Fn
q. When the ambient vector space Fn
q is large it
was shown in [15] that an equidistant code of maximal cardinality is a sunï¬‚ower.
The paper [28] provides an almost complete classiï¬cation in case the ground ï¬eld
is sufï¬ciently large. The authors show that for most parameters an equidistant code
of maximal cardinality with minimum subspace distance less than 2k is either a
sunï¬‚ower or its dual is a sunï¬‚ower.
Any partial spread gives rise to a sunï¬‚ower in a larger ambient space, which gives
rise to the following result [28, Theorem 34]:
Theorem 6 Let c â‰¤k âˆ’1 be an integer. Write n âˆ’c = h(k âˆ’c) + r, with 0 â‰¤r â‰¤
k âˆ’c âˆ’1, h â‰¥2. Then there exist an equidistant code in Gq(k, n) with minimum
distance 2k âˆ’2c and cardinality (qnâˆ’c âˆ’qr)/(qkâˆ’c âˆ’1) âˆ’qr + 1.
The following result about equidistant codes follows from [30, Theorem 1]. The
correspondingcodesareconstructedfromosculatingsubspacesofVeronesevarieties.
Theorem 7 Let â„“, s, t be integers such that t/2 â‰¤â„“â‰¤t, and deï¬ne k :=
â„“+s
s

, n :=
t+s
s

. Then there exist an equidistant code in Gq(k, n) with minimum distance 2k âˆ’
2
2â„“âˆ’t+s
s

and cardinality (qs+1 âˆ’1)/(q âˆ’1).
Furthermore, one can construct non-sunï¬‚ower equidistant codes with minimum
distance 2k âˆ’2 with the help of the PlÃ¼cker embedding:
Theorem 8 [15, Theorem 15] For every k â‰¥2, there exists an equidistant code in
Gq(k,
k+1
2

) with minimum distance 2k âˆ’2 and cardinality (qk+1 âˆ’1)/(q âˆ’1).
More examples of equidistant codes which are different from sunï¬‚owers can be
found in [4].
4
Constructions Based on (Ferrers Diagram) Rank-Metric
Codes
Some of the ï¬rst constructions for subspace codes were based on rank-metric codes.
These codes are sets of matrices of a ï¬xed size over Fq, equipped with the rank
metric, which is deï¬ned as
dR(A, B) := rk(A âˆ’B),
A, B âˆˆFmÃ—n
q
.
The usefulness of rank-metric codes for the construction of subspace codes is due to
the following fact, which follows from [52, Proposition 4]:
Lemma 9 Let C âŠ†FkÃ—(nâˆ’k)
q
be a code with minimum rank distance d. Then the
lifted code

32
A.-L. Horlemann-Trautmann and J. Rosenthal
lift(C) := {rs[Ik | A] | A âˆˆC}
is a constant dimension code in Gq(k, n) with minimum subspace distance 2d and
cardinality |C|.
Note that geometrically the set of subspaces of the form rs[Ik | A] inside the
Grassmannian Gq(k, n) represents a subset isomorphic to the afï¬ne space FkÃ—(nâˆ’k)
q
.
Geometers also call this subset the â€˜thick open cellâ€™ of the Grassmannian Gq(k, n).
Constructions of optimal rank-metric codes are known for any set of parameters
(see e.g. [21]), the corresponding codes are called maximum rank distance (MRD)
codes. An MRD code C âŠ†FmÃ—n
q
with minimum rank distance d has cardinality
qmax(m,n)(min(m,n)âˆ’d+1). Therefore, a lifted MRD code C âŠ†Gq(k, n) with k â‰¤n/2
and minimum subspace distance 2d has cardinality q(nâˆ’k)(nâˆ’d+1).
For more information on partial spreads the reader is referred to chapters â€œGeo-
metrical Aspects Of Subspace Codesâ€ and â€œPartial Spreads And Vector Space
Partitionsâ€ of this book.
Inthefollowingweneedthenotionofanidentifyingvector v(U)ofasubspaceU âˆˆ
Gq(k, n), which is deï¬ned as the vector of length n that has a one in the coordinates
where the reduced echelon form of U has a pivot, and zeros elsewhere. It was shown
in [17, Lemma 2] that for U, V âˆˆGq(k, n) one has
dS(U, V) â‰¥dH(v(U), v(V)).
With this we can generalize the lifted MRD construction, as follows.
Theorem 10 [53, Theorem 2.9] Let C j be some MRD code with minimum rank
distance d in FkÃ—(nâˆ’kâˆ’jd)
q
for j = 0, . . . , âŒŠnâˆ’k
d âŒ‹. Deï¬ne
C j :=

rs
0kÃ— jd IkÃ—k A 
| A âˆˆC j

and
C :=
âŒŠnâˆ’k
d âŒ‹
	
j=0
C j.
Then C âŠ†Gq(k, n) has minimum distance 2d and cardinality
N =
âŒŠnâˆ’2k
d
âŒ‹

i=0
q(kâˆ’d+1)(nâˆ’kâˆ’di) +
âŒŠnâˆ’k
d âŒ‹

i=âŒŠnâˆ’2k
d
âŒ‹+1
âŒˆqk(nâˆ’k+1âˆ’d(i+1))âŒ‰.
Note that similar statements to the previous theorem can also be found in [20, 22].
One can generalize the lifting idea to general reduced row echelon forms of
matrices, where the unit column vectors are not necessarily in the ï¬rst k columns.
This idea was introduced in [16]. First, let us brieï¬‚y provide some deï¬nitions needed
for this construction. A Ferrers diagram F is a collection of dots such that the rows
have a decreasing and the columns have an increasing number of dots (from top to

Constructions of Constant Dimension Codes
33
bottom and from left to right, respectively). We denote the matrix representation of
a vector space U âˆˆGq(k, n) in reduced row echelon form by RE(U) âˆˆFkÃ—n
q
.
Deï¬nition 11 The Ferrers diagram form of a subspace U âˆˆGq(k, n), denoted by
F(U), is obtained from RE(U) by ï¬rst removing the zeros to the left of the leading
coefï¬cient from each row of RE(U), and then removing the columns which contain
the leading ones. All the remaining entries are shifted to the right. The Ferrers
diagram of U, denoted by FU, is obtained from F(U) by replacing the entries of
F(U) with dots.
Deï¬nition 12 Let F be a Ferrers diagram with k rows and n columns. A correspond-
ing Ferrers diagram code is a matrix code F âŠ†FkÃ—n
q
, such that all matrix entries not
in F are zero in all codewords. The minimum rank distance of a Ferrers diagram
code is deï¬ned as usual. Similarly, the lifting of a Ferrers diagram code is deï¬ned
analogously to the lifting of a rectangular rank-metric code, with a corresponding
reduced row echelon form.
We can now state the multi-level construction:
Theorem 13 Let C âŠ†Fn
2 be a binary block code of constant weight k and minimum
Hamming distance 2d. Use each codeword vi âˆˆC as the identifying vector of a
reduced row echelon form and construct the corresponding lifted Ferrers diagram
code Ci with minimum rank distance d. Then the constant dimension code C =
|C|
i=1 Ci âŠ†Gq(k, n) has minimum subspace distance 2d.
The size of these codes depends mainly on the size of the corresponding Ferrers
diagram codes, for which we do not have a general construction. In [17, Theorem 1]
an upper bound on the cardinality of linear Ferrers diagram codes with a prescribed
minimum rank distance is given. Moreover, code constructions for special types
of Ferrers diagrams attaining this bound are given. The authors conjecture that the
bound is always attainable, for any set of parameters. More constructions of codes
for certain Ferrers diagrams were derived in [14, 51].
It is an open question, which choice of the identifying vectors is optimal for the
multi-level construction. It was suggested in [17] that lexicographic binary constant
weight codes are the best choice. However, a counterexample for this statement is
given in [29, Example 57]. Furthermore, related results to lexicographic codes and
corresponding constant dimension codes found by computer search are presented in
[50].
As a next step, it was shown in [56] that one can construct larger codes than with
the multi-level construction, if one allows pending dots in the construction. We will
explain this pending dots construction in the following.
Deï¬nition 14 Let F be a Ferrers diagram. A dot of F is called a pending dot if the
maximal size of a Ferrers diagram code for F is the same as the maximal size of a
Ferrers diagram code for F without that dot.
We can now state the pending dots construction:

34
A.-L. Horlemann-Trautmann and J. Rosenthal
Theorem 15 Construct a constant weight-k code C âŠ†Fn
2 of identifying vectors as
follows:
1. Let v1 = (11...10...0) be the ï¬rst identifying vector in C.
2. Choose the next identifying vector such that dH(vi, v1) â‰¥2d and ï¬x the set of
pending dots (if there are any) of the corresponding Ferrers diagram as Î¼1.
3. For the next identifying vector choose the ï¬rst 1 in the same positions as before
and use the next lexicode element of distance â‰¥2d âˆ’2 from the other elements
with the same pending dots and â‰¥2d from any other element of C. Fix the pending
dots as a tuple Î¼i different from the tuples already used for echelon-Ferrers forms,
where the Hamming distance of the identifying vectors is 2d âˆ’2.
4. Repeat step 3 until no possibilities for a new skeleton code word with the ï¬xed 1
are left.
5. In the skeleton code choose the next vector in lexicographic order that has distance
â‰¥2d from all other skeleton code words and repeat steps 2,3,4 and 5.
Then construct a lifted Ferrers diagram code for all identifying vectors, with the
given assignments of the pending dots in the Ferrers diagram. The union of all these
codes is a constant dimension code C âŠ†Gq(k, n) with minimum subspace distance
2d.
One of the disadvantages of the multi-level and the pending dots construction is,
that there is no closed formula for the code cardinalities in general. Therefore, in [18,
51] the authors used the pending dots construction (or a slight generalization called
the pending blocks construction) to derive codes with a closed cardinality formula
for variable length n. To do so they gave a general construction of the constant weight
code for the identifying vectors and for the corresponding Ferrers diagram codes.
The results are given in the following theorems.
Theorem 16 [18, Theorem 16] Let k = 3 and q, n be such that
q2 + q + 1 â‰¥
n âˆ’3 n even
n âˆ’4 n odd .
Then the code C âŠ†Gq(3, n) obtained from Construction I in [18] with minimum
subspace distance 4 has cardinality q2(nâˆ’3) +
nâˆ’3
2

q.
A similar result for small q has also been given in [18, Theorem 17].
Theorem 17 [51, Theorem 19] Let k â‰¥4, s := k
i=3 i = k2+kâˆ’6
2
, n â‰¥s + 2 + k =
k2+3kâˆ’2
2
and q2 + q + 1 â‰¥â„“, where â„“:= n âˆ’s = n âˆ’k2+kâˆ’6
2
for odd n âˆ’s (or â„“:=
n âˆ’s âˆ’1 = n âˆ’k2+kâˆ’4
2
for even n âˆ’s). Then the code C âŠ†Gq(k, n) obtained from
Construction A in [51] has minimum subspace distance 2(k âˆ’1) and cardinality
q2(nâˆ’k) + q2(nâˆ’(k+(kâˆ’1))) + . . . + q2(nâˆ’k2+kâˆ’6
2
) +
n âˆ’k2+kâˆ’6
2
2

q
.

Constructions of Constant Dimension Codes
35
A similar result for small q has also been given in [51, Corollary 22].
Theorem 18 [51, Corollary 27] Let n â‰¥2k + 2. Then the code C âŠ†Gq(k, n)
obtained from Construction B (recursively applied) in [51] has minimum subspace
distance 4 and cardinality at least
âŒŠnâˆ’2
k âŒ‹âˆ’1

i=1

q(kâˆ’1)(nâˆ’ik) + (q2(kâˆ’2) âˆ’1)(q2(nâˆ’ikâˆ’1) âˆ’1)
(q4 âˆ’1)2
q(kâˆ’3)(nâˆ’ikâˆ’2)+4

.
Furthermore, two constructions for codes in Gq(4, n) and Gq(5, n) with minimum
subspace distance 4 with closed cardinality formula were presented in [51, Sect.
IV.B].
5
Orbit Codes
In this section we present several constructions for orbit codes. We will ï¬rst present
theory about single orbits in Gq(k, n), whereas in the second subsection we will
review constructions of unions of orbits with a prescribed minimum subspace dis-
tance.
Throughout the section we will make use of the isomorphism Fqn âˆ¼= Fn
q. By abuse
of notation we will change between the two representations with the same notation.
5.1
Single Orbits
The general linear group of order n with entries from Fq, denoted by GLn(q), deï¬nes
an action on Gq(k, n) as follows:
Gq(k, n) Ã— GLn(q) âˆ’â†’Gq(k, n)
U Ã— A âˆ’â†’rs(RE(U)A)
An orbit code C âŠ†Gq(k, n), in general, is deï¬ned as the orbit of a subgroup G â‰¤
GLn(q) with some initial point U âˆˆGq(k, n), i.e.,
C = UG := {U A | A âˆˆG}.
These codes can be seen as the analog of linear codes in the classical block coding
case, since linear block codes are orbit codes with respect to additive subgroups of
Fn
q (see e.g. [54, 55]). One of the consequences of this fact is, that the minimum
distance of an orbit code can be determined by comparing all elements of the orbit

36
A.-L. Horlemann-Trautmann and J. Rosenthal
with the initial point (instead of all possible pairs of codewords), as shown in [54,
Theorem 17]:
Lemma 19 Let U âˆˆGq(k, n) be an initial point, G â‰¤GLn(q) a subgroup and let
C = UG be an orbit code. Then
dS(C) = min{dS(U, U A) | A âˆˆG, A /âˆˆStabG(U)},
where StabG(U) := {A âˆˆG | U A = U}.
Of particular interest are cyclic orbit codes, where the deï¬ning subgroup G â‰¤
GLn(q) is cyclic, i.e., there is a matrix P âˆˆGLn(q) such that G = âŸ¨PâŸ©and therefore
C = UG = {U Pi | i = 0, . . . , ord(P) âˆ’1}.
Understood best is the case where P is the companion matrix of a monic irreducible
polynomial p(x) âˆˆFq[x] of degree n. These codes are also called irreducible cyclic
orbit codes [54]. If the irreducible polynomial is primitive, we call the corresponding
codes primitive cyclic orbit codes.
It is well-known that one can construct spread codes as primitive cyclic orbit
codes, see e.g. [49, Theorem 3]:
Theorem 20 Let k | n and p(x) âˆˆFq[x] be monic, primitive and of degree n, and
let Î± âˆˆFqn be a root of p(x). Denote by P âˆˆGLn(q) the companion matrix of p(x).
Then
U :=

Î±
i qnâˆ’1
qk âˆ’1 | i = 0, . . . , qk âˆ’2

âˆª{0}
is an element of Gq(k, n) and C = UâŸ¨PâŸ©is a spread in Gq(k, n).
Note that, in Theorem 20, U is the subï¬eld Fqk of Fqn. Moreover, one does not
need the companion matrix P in the description of the orbit, instead one can also
write C = {Î±iFqk | i = 0, . . . , (qn âˆ’1)/(qk âˆ’1) âˆ’1}. The previous construction
has been generalized in [6, Section3.B] as follows:
Theorem 21 Let d âˆˆN divide k and n. Then
C =
 k/d

i=1
Î±iFqd | Î±1, . . . , Î±k/d âˆˆFqn are linearly independent over Fqd

is a code in Gq(k, n) with minimum subspace distance 2d and cardinality
n/d
k/d

qd.
Furthermore, it is conjectured that for all parameters, except some border cases,
an irreducible cyclic orbit code of minimum subspace distance 2(k âˆ’1) exists:
Conjecture 22 For any k, q and n â‰¥6 there exists an irreducible orbit code
C âŠ†Gq(k, n) with minimum subspace distance 2(k âˆ’1) and cardinality (qn âˆ’1)/
(q âˆ’1).

Constructions of Constant Dimension Codes
37
This conjecture was stated for general n in [12, 54], but the case n = 8, k = 4
has been disproven in [25]. On the other hand, in [6, 45] it was shown that for any
q, k there exist inï¬nitely many n where the conjecture holds. The other parameter
sets remain as a conjecture.
In general, one can determine the minimum subspace distance of a cyclic orbit
code by just looking at the initial point U âˆˆGq(k, n) of the orbit. This was done in
[12, 41] for Singer subgroup orbits and, in more general, for any cyclic group in [54,
Sect.4]. This method was later on reï¬ned in [25, Theorem 4.11], where the authors
deï¬ned the best friend of a subspace U âˆˆGq(k, n) as the largest subï¬eld Fqr of Fqn
over which U is a vector space. With the help of the best friend one gets the following
estimates on cardinality and distance of the corresponding code (see [25, Corollary
3.13, Lemma 4.1]):
Theorem 23 Let U âˆˆGq(k, n) and P âˆˆGLn(q) be a companion matrix of a monic
primitive polynomial of degree n. Consider the orbit code C = UâŸ¨PâŸ©. If Fqr is the
best friend of U, then
|C| = qn âˆ’1
qr âˆ’1
and
2r â‰¤dS(C) â‰¤2k.
Based on the previously mentioned methods to determine the minimum subspace
distance of a cyclic orbit code, the paper [24] establishes a connection between the
choice of initial point of a cyclic orbit code and the construction of cyclic difference
sets of appropriate parameters. Moreover, in [2] some results related to irreducible
cyclic orbit codes are given.
5.2
Unions of Orbits
In [20] the notion of a cyclic subspace code was introduced. In our terminology, this
is a union of primitive cyclic orbit codes, although in its general form it could be
a union of primitive cyclic orbit codes of different dimensions. In [6] it was shown
how subspace polynomials can be used to construct good cyclic subspace codes.
Deï¬nition 24 Let U âŠ†Fqn be a Fq-subspace. The subspace polynomial of U is
deï¬ned as the monic (linearized) polynomial PU(x) of least degree, such that
PU(u) = 0 for any u âˆˆU.
Note that a subspace polynomial of some Fq-subspace of Fqn is always a linearized
polynomial, i.e., it is of the form m
i=0 aixqi with a0, . . . , am âˆˆFqn. The following
result, which is a reformulation of [6, Corollary 2], relates the shapes of two subspace
polynomials to the subspace distance of the corresponding subspaces:

38
A.-L. Horlemann-Trautmann and J. Rosenthal
Lemma 25 Let U, V âˆˆGq(k, n), with PU(x) = xqk + â„“
i=0 aixqi where aâ„“Ì¸= 0,
and PV(x) = xqk + m
i=0 bixqi where bm Ì¸= 0. Then
dS(U, V) â‰¥2 min(k âˆ’â„“, k âˆ’m).
Another useful fact is that one can describe the subspace polynomials of an orbit
with the help of the subspace polynomial of the initial point [6, Lemma 4]:
PÎ±U(x) = Î±qk PU(Î±âˆ’1x).
With the above tools one can derive the following code constructions.
Theorem 26 [6, Theorem 4] Let n be a prime and Î³ âˆˆFqn be primitive. If Fq N is the
splitting ï¬eld of PU(x) := xqk + Î³qxq + Î³x and U âˆˆGq(k, N) is the corresponding
subspace (i.e., the kernel of PU(x)), then
C :=
nâˆ’1
	
i=0
{Î±Uqi | Î± âˆˆFâˆ—
q N }
is a cyclic subspace code with minimum subspace distance 2k âˆ’2 and size n(q N âˆ’
1)/(q âˆ’1).
This construction was generalized in [45, Theorem 3] to more general trinomials
that can be used as subspace polynomials, which allows even larger code sizes.
Furthermore, a generalization to subspace polynomials with s + 2 summands (for
s > 1), such that the arising subspace code has minimum subspace distance 2k âˆ’2s,
is given in [45, Corollary 4].
For more information on rank-metric and MRD codes the reader is referred to
chapters â€œCodes Endowed With The Rank Metricâ€ and â€œConstructions of Cyclic
Subspace Codes and Maximum Rank Distance Codesâ€ of this book.
Besides the previous theoretical results, there are many related results using smart
computer searches to construct large codes, in particular cyclic subspace codes.
In [41] unions of irreducible cyclic orbit codes are found by solving linear
inequalities under Diophantine restrictions. This Diophantine system is only fea-
sible because the authors impose a prescribed automorphism group (namely the one
of irreducible cyclic orbit codes) on the solutions. The results of that paper are for
length 6 â‰¤n â‰¤14, dimension k = 3, and minimum subspace distance 4. Some of
these codes are still the best codes known for the given parameter sets.
In [20, SectionIII] optimal cyclic codes of length 8 and 9 are presented, in the
sense that there is no larger cyclic subspace code of the same length and distance.
These two computational methods prescribe Fqn as the automorphism group in
order to make the computer search feasible. Despite this restriction on unions of
primitive cyclic orbit codes, the codes found come quite close to known bounds.
This shows that cyclic orbit codes (or cyclic subspace codes) form a powerful class
of constant dimension codes.

Constructions of Constant Dimension Codes
39
6
New from Old Codes
There are several results about how to construct new constant dimension codes from
known constant dimension codes of smaller parameters.
A fairly simple, but very effective construction is given in Construction D of [51].
Theorem 27 [51, Theorem 37] Let Câ€² âˆˆGq(k, n) be a code with minimum subspace
distance 2d, let Î” â‰¥k, and let CR âŠ†FkÃ—Î”
q
be an MRD code of minimum rank
distance d. Deï¬ne the code
C := {rs[ RE(U)
A ] | U âˆˆCâ€², A âˆˆCR}.
Then C is a constant dimension code in Gq(k, n + Î”) with minimum subspace dis-
tance 2d and cardinality |Câ€²|qÎ”(kâˆ’d+1).
As noted in [51, Corollary 39], one can easily extend this construction by adding
constant dimension codes with prescribed zero columns in the beginning, analo-
gously to Theorem 10. This idea is the basis of the linkage construction of [26]:
Theorem 28 [26, Theorem 2.3] For i = 1, 2 let Ë†Ci âŠ†Gq(k, ni) with minimum sub-
space distance di. Furthermore, let CR âŠ†FkÃ—n2 be a linear rank-metric code with
minimum rank distance dR. Then the code C := C1 âˆªC2, where
C1 := {rs[ RE(U)
A ] | U âˆˆË†C1, A âˆˆCR},
C2 := {rs[ 0kÃ—n1
RE(U) ] | U âˆˆË†C2},
is a constant dimension code in Gq(k, n1 + n2), with minimum subspace distance
min{d1, d2, 2dR} and cardinality | Ë†C2| + | Ë†C1||CR|.
Notethat intheoriginal statement of this theorem, thematrixrepresentations of the
subspaces U do not necessarily have to be the reduced row echelon forms. Different
basis matrices will give different codewords in C3, but the cardinality and minimum
distance of the code remains the same. Furthermore note that this construction can
be used to construct good partial spreads [26, Sect.3].
The coset construction from [33] can be reformulated as follows, for which we
need the following map: Let U âˆˆGq(k, n) and F âˆˆFmÃ—(nâˆ’k)
q
, then Ï•U(F) is a matrix
M âˆˆFmÃ—n
q
, such that M has a zero column wherever RE(U) has a pivot and the other
columns of M are the columns of F.
Theorem 29 Let A, B be disjoint unions of sets Ai âŠ†Gq(kâ€², nâ€²), Bi âŠ†Gq(k âˆ’
kâ€², n âˆ’nâ€²), respectively. Moreover, let CF âŠ†Fkâ€²Ã—(nâˆ’nâ€²âˆ’k+kâ€²)
q
be an MRD code of min-
imum rank distance d. Let C be a subset of the set
	
i

rs
RE(U) Ï•U(F)
0
RE(V)

| U âˆˆAi, V âˆˆBi, F âˆˆCF


40
A.-L. Horlemann-Trautmann and J. Rosenthal
such that dS(U, Uâ€²) + dS(V, Vâ€²) â‰¥2d for any two elements of the above form in C.
Then C is a constant dimension code in Gq(k, n) with minimum subspace distance
2d.
Note that the sets Ai, Bi can be thought of as known constant dimension codes.
A very effective family of unions of subsets, that was used in [33] in the coset
construction are parallelisms, i.e., partitions of Gq(k, n) into spreads.
7
Final Remarks
Besides the constructions presented in detail in this survey one can ï¬nd more results
on subspace codes. E.g., a family of constant dimension codes called linear sub-
space codes was deï¬ned in [8]. More results on these codes were derived in [5, 46].
Furthermore, one can derive constant dimension codes from Riemann-Roch spaces,
as done in [3, 31]. Many results on constant dimension codes with certain ï¬xed
parameters, often based on smart computer search, can be found in the literature, see
e.g. in [1, 9â€“12, 35, 36] and references therein.
Moreover, results on non-constant dimension subspace codes, also called mixed-
dimension subspace codes, can be found in [17, 23, 37â€“39, 51]. Note that in the
non-constant dimension case there are two different metrics one can consider - the
subspace and the injection metric. The before mentioned results include results for
both metrics.
The best known subspace codes for given parameters can be looked up in the
online database [32] at
http://subspacecodes.uni-bayreuth.de.
Finally, some open problems on various aspects of subspace codes can be found
in the overview articles [13, 19].
Acknowledgements The authors were partially supported by COST â€“ European Cooperation
in Science and Technology. The second author was also supported by Swiss National Science
Foundation grant no. 169510.
References
1. J. Ai, T. Honold, H. Liu, The expurgation-augmentation method for constructing good plane
subspace codes (2016). arXiv:1601.01502 [math.CO]
2. F. Bardestani, A. Iranmanesh, Cyclic orbit codes with the normalizer of a singer subgroup. J.
Sci. Islam. Repub. Iran 26(1), 49â€“55 (2015)
3. D. Bartoli, M. Bonini, M. Giulietti, Constant dimension codes from Riemann-Roch spaces
(2015). arXiv:1508.01727
4. D. Bartoli, F. Pavese, A note on equidistant subspace codes. Discret. Appl. Math. 198, 291â€“296
(2016)

Constructions of Constant Dimension Codes
41
5. P. Basu, N. Kashyap. On linear subspace codes closed under intersection. In 2015 Twenty First
National Conference on Communications (NCC), pages 1â€“6, February 2015
6. E. Ben-Sasson, T. Etzion, A. Gabizon, N. Raviv, Subspace polynomials and cyclic subspace
codes. IEEE Trans. Inf. Theory 62(3), 1157â€“1165 (2016)
7. A. Beutelspacher, Blocking sets and partial spreads in ï¬nite projective spaces. Geom. Dedic.
9(4), 425â€“449 (1980)
8. M. Braun, T. Etzion, A. Vardy, Linearity and complements in projective space. Linear Algebr.
Appl. 438(1), 57â€“70 (2013)
9. M. Braun, P. Ã–stergard, A. Wassermann. New lower bounds for binary constant-dimension
subspace codes. Exp. Math. 1â€“5 (to appear)
10. A. Cossidente, F. Pavese. Subspace codes in PG(2n-1,q). Combinatorica (2016), p. 1â€“23
11. A. Cossidente, F. Pavese, Veronese subspace codes. Des. Codes Cryptogr. 81(3), 445â€“457
(2016)
12. A. Elsenhans, A. Kohnert, A. Wassermann. Construction of codes for network coding. In
Proceedings of the 19th International Symposium on Mathematical Theory of Networks and
Systems â€“ MTNS (Budapest, Hungary, 2010), pp. 1811â€“1814
13. T. Etzion. Problems on q-analogs in coding theory (2013). arXiv:1305.6126
14. T. Etzion, E. Gorla, A. Ravagnani, A. Wachter-Zeh, Optimal Ferrers diagram rank-metric codes.
IEEE Trans. Inf. Theory 62(4), 1616â€“1630 (2016)
15. T. Etzion, N. Raviv, Equidistant codes in the Grassmannian. Discret. Appl. Math. 186, 87â€“97
(2015)
16. T. Etzion, N. Silberstein. Construction of error-correcting codes for random network coding. In
IEEE 25th Convention of Electrical and Electronics Engineers in Israel, 2008. (IEEEI 2008)
(2008), pp. 070â€“074
17. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inf. Theory 55(7), 2909â€“2919 (2009)
18. T. Etzion, N. Silberstein, Codes and designs related to lifted MRD codes. IEEE Trans. Inf.
Theory 59(2), 1004â€“1017 (2013)
19. T. Etzion, L. Storme, Galois geometries and coding theory. Des. Codes Cryptogr. 78(1),
311â€“350 (2016)
20. T. Etzion, A. Vardy, Error-correcting codes in projective space. IEEE Trans. Inf. Theory 57(2),
1165â€“1173 (2011)
21. E.M. Gabidulin, Theory of codes with maximum rank distance. Problemy Peredachi Informatsii
21(1), 3â€“16 (1985)
22. E.M.Gabidulin,N.I.Pilipchuk.Multicomponent networkcoding.In Proceedingsof the Seventh
International Workshop on Coding and Cryptography (WCC) 2011, (Paris, France, 2011), pp.
443â€“452
23. A. Ghatak. Subspace codes for random networks based on PlÃ¼cker coordinates and Schubert
cells (2013). arXiv:1301.6362 [cs.IT]
24. A. Ghatak. Construction of Singer subgroup orbit codes based on cyclic difference sets. In
2014 Twentieth National Conference on Communications (NCC) (2014), pp. 1â€“4
25. H. Gluesing-Luerssen, K. Morrison, C. Troha, Cyclic orbit codes and stabilizer subï¬elds. Adv.
Math. Commun. 9(2), 177â€“197 (2015)
26. H. Gluesing-Luerssen, C. Troha, Construction of subspace codes through linkage. Adv. Math.
Commun. 10(3), 525â€“540 (2016)
27. E. Gorla, A. Ravagnani, Partial spreads in random network coding. Finite Fields Appl. 26,
104â€“115 (2014)
28. E. Gorla, A. Ravagnani, Equidistant subspace codes. Linear Algebr. Appl. 490, 48â€“65 (2016)
29. E. Gorla, A. Ravagnani. Subspace codes from Ferrers diagrams. J. Algebr. Appl. 1750131
(2016) (online)
30. J.P. Hansen, in Osculating spaces of varieties and linear network codes. Lecture Notes in
Computer Science, vol 8080, 83â€“88 (2013)
31. J.P. Hansen, Riemann-Roch spaces and linear network codes. Comput. Sci. 10(1), 1â€“11 (2015)

42
A.-L. Horlemann-Trautmann and J. Rosenthal
32. D. Heinlein, M. Kiermaier, S. Kurz, A. Wassermann. Tables of subspace codes (2016).
arXiv:1601.02864
33. D. Heinlein, S. Kurz. Coset construction for subspace codes (2015). arXiv:1512.07634
[math.CO]
34. J.W.P. Hirschfeld, Projective Geometries over Finite Fields, 2nd edn. (Oxford Mathematical
Monographs. The Clarendon Press, Oxford University Press, New York, 1998)
35. T. Honold, M. Kiermaier. On putative q-analogues of the Fano plane and related combinatorial
structures, in Dynamical Systems, Number Theory and Applications: A Festschrift in Honor of
Armin Leutbecherâ€™s 80th Birthday. (World Scientiï¬c, 2016), pp. 141â€“175
36. T. Honold, M. Kiermaier, S. Kurz. Optimal binary subspace codes of length 6, constant dimen-
sion 3 and minimum subspace distance 4. In Topics in ï¬nite ï¬elds, vol. 632 of Contemporary
Mathematics (American Mathematical Society, Providence, RI, 2015), pp. 157â€“176
37. T. Honold, M. Kiermaier, S. Kurz, Constructions and bounds for mixed-dimension subspace
codes. Adv. Math. Commun. 10(3), 649â€“682 (2016)
38. A. Khaleghi. Projective Space Codes for the Injection Metric. (Masters thesis, University of
Toronto, 2009)
39. A. Khaleghi, D. Silva, F.R. Kschischang. Subspace codes. In IMA International Conference
on Cryptography and Coding (2009), pp. 1â€“21
40. S.L. Kleiman, D. Laksov, Schubert calculus. Am. Math. Mon. 79, 1061â€“1082 (1972)
41. A. Kohnert, S. Kurz. Construction of large constant dimension codes with a prescribed mini-
mum distance. in MMICS eds. by J. Calmet, W. Geiselmann, J. MÃ¼ller-Quade. Lecture Notes
in Computer Science, vol. 5393 (Springer, Berlin, 2008), pp. 31â€“42
42. R. KÃ¶tter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Transac. Inf. Theory 54(8), 3579â€“3591 (2008)
43. R. Lidl, H. Niederreiter, Introduction to Finite Fields and their Applications (Cambridge Uni-
versity Press, Cambridge, London, 1986)
44. F. Manganiello, E. Gorla, J. Rosenthal. Spread codes and spread decoding in network coding.
In Proceedings of the 2008 IEEE International Symposium on Information Theory (Toronto,
Canada, 2008), pp. 851â€“855
45. K. Otal, F. Ã–zbudak, Cyclic subspace codes via subspace polynomials. Des. Codes Cryptogr.
1â€“14 (2016)
46. S. Pai, S. Rajan. On the bounds of certain maximal linear codes in a projective space. In IEEE
International Symposium on Information Theory (ISIT) (2015), pp. 591â€“595
47. C. Procesi. A Primer Of Invariant Theory. (Brandeis lecture notes, Brandeis University, 1982).
Notes by G. Bofï¬
48. J. Rosenthal, N. Silberstein, A.-L. Trautmann, On the geometry of balls in the Grassmannian
and list decoding of lifted Gabidulin codes. Des. Codes Cryptogr. 73(2), 393â€“416 (2014)
49. J. Rosenthal, A.-L. Trautmann, A complete characterization of irreducible cyclic orbit codes
and their PlÃ¼cker embedding. Des. Codes Cryptogr. 66(1â€“3), 275â€“289 (2013)
50. N. Silberstein, T. Etzion, Large constant dimension codes and lexicodes. Adv. Math. Commun.
5(2), 177â€“189 (2011)
51. N. Silberstein, A.-L. Trautmann, Subspace codes based on graph matchings, Ferrers diagrams,
and pending blocks. IEEE Trans. Inf. Theory 61(7), 3937â€“3953 (2015)
52. D. Silva, F. Kschischang, F. KÃ¶tter, A rank-metric approach to error control in random network
coding. IEEE Trans. Inf. Theory 54(9), 3951â€“3967 (2008)
53. A.-L. Trautmann. Constructions, Decoding and Automorphisms of Subspace Codes. PhD the-
sis, University of Zurich, 2013
54. A.-L. Trautmann, F. Manganiello, M. Braun, J. Rosenthal, Cyclic orbit codes. IEEE Trans.
Inform. Theory 59(11), 7386â€“7404 (2013)
55. A.-L. Trautmann, F. Manganiello, J. Rosenthal, Orbit codes - a new concept in the area of
network coding, in 2010 IEEE Information Theory Workshop (ITW) (Dublin, Ireland, 2010),
pp. 1â€“4
56. A.-L. Trautmann, J. Rosenthal. New improvements on the echelon-Ferrers construction. In
Proceedings of the 19th International Symposium on Mathematical Theory of Networks and
Systems â€“ MTNS (Budapest, Hungary, 2010), pp. 405â€“408

Constructions of Cyclic Subspace Codes
and Maximum Rank Distance Codes
Kamil Otal and Ferruh Ã–zbudak
Abstract This chapter is a survey of the recent results on the constructions of cyclic
subspace codes and maximum rank distance codes. Linearized polynomials are the
main tools used to introduce both constructions in this chapter. In the construction
of cyclic subspace codes, codewords are considered as the root spaces of some
subspace polynomials (which are a particular type of linearized polynomials). In
this set up, some algebraic manipulations on the coefï¬cients and degrees of such
polynomials are applied to provide a systematic construction of cyclic subspace
codes. In constructions of maximum rank distance codes, linearized polynomials
are used as codewords again, but in a different way. Codewords of rank metric
codes are considered as the linear maps that these polynomials represent. All known
constructions of maximum rank distance codes in the literature are summarized using
this linearized polynomial representation. Connections among the constructions and
further explanations are also provided.
1
Introduction
Subspace codes have an increasing interest in the last decade thank to their applica-
tions in random network coding. Similar to subspace codes, the theory of rank metric
codes have gained an increasing attraction due to their application to various areas
including subspace codes. Linearized polynomials are quite useful mathematical
tools to represent and solve some current problems within these areas.
In this chapter, the main goal is to provide all known advances in two recent prob-
lems: constructions of cyclic subspace codes and maximum rank distance codes.
In particular, Sect.1 is devoted to the brief introductions of linearized polynomials,
cyclic subspace codes and rank metric codes. Further details and an explicit construc-
K. Otal (B) Â· F. Ã–zbudak
Middle East Technical University, Ankara, Turkey
e-mail: kotal@metu.edu.tr
F. Ã–zbudak
e-mail: ozbudak@metu.edu.tr
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_3
43

44
K. Otal and F. Ã–zbudak
tion of cyclic subspace codes are introduced in Sect.2, whereas the constructions of
maximum rank distance codes in the literature are summarized in Sect.3.
1.1
Linearized Polynomials
We recall the deï¬nition and some basic properties of linearized polynomials before
to explain their applications mentioned above. Let Fq be a ï¬nite ï¬eld of q elements,
Fq N be its N-th degree ï¬eld extension and Fq be its algebraic closure. A polynomial
f (x) âˆˆFq N [x] of the form
f (x) =
l
i=0
Î±ixqi ,
(1)
for some non-negative integerl, is called a q-polynomial (or, a linearized polynomial)
over Fq N . In this representation, l is called the q-degree of f if Î±l Ì¸= 0. Some useful
properties of linearized polynomials of form (1) are listed below.
â€¢ f (cÎ± + Î²) = cf (Î±) + f (Î²) for all c âˆˆFq and Î±, Î² âˆˆFq.
â€¢ The multiplicity of each root of f in Fq is the same and equal to qr, where r is the
smallest integer satisfying Î±r Ì¸= 0.
â€¢ The set of roots of f in an extension of Fq N constitutes a vector space over Fq.
In particular, the set of roots of f in Fq N is a subspace of Fq N over Fq. This
set is called the kernel of f and denoted by ker( f ). The rank of f is given by
N âˆ’dim(ker( f )) and denoted by rank( f ).
These properties can be proved directly by using the deï¬nition. Further information
about linearized polynomials can be found, for example, in [19, Sect.3.4].
A monic q-polynomial is called a subspace polynomial if it splits completely over
Fq N (i.e. all roots are in Fq N ) and has no multiple roots (i.e. Î±0 Ì¸= 0). Therefore, there
is a one to one correspondence between an l-dimensional subspace U of Fq N and a
subspace polynomial f of q-degree l satisfying f (U) = {0}.
1.2
Subspace Codes
The set of all subspaces of Fq N is called the projective space of (vector) dimension
N over Fq and denoted by Pq(N). The set of all k dimensional elements of Pq(N)
is called Grassmannian space (or brieï¬‚y Grassmannian) over Fq and denoted by
Gq(N, k). The metric d given by
d(U, V ) := dim U + dim V âˆ’2 dim(U âˆ©V )

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
45
on Pq(N) is called the subspace distance. A subset C âŠ†Pq(N) including at
least two elements and equipped with this metric is called a subspace code. If
moreover C âŠ†Gq(N, k), then C is also called a constant dimension code (see
chapter â€œConstructions of Constant Dimension Codesâ€ for various constructions
of such codes). We naturally deï¬ne the minimum distance d(C ) of a code C
by d(C ) := min{d(U, V ) : U, V âˆˆC and U Ì¸= V }. A cyclic shift of a subspace
U âŠ†Fq N is given by Î±U := {Î±u : u âˆˆU}, where Î± âˆˆFâˆ—
q N . Observe that a cyclic
shift is a subspace of Fq N over Fq, and the dimension of the cyclic shift is the same
as the dimension of U. A subspace code C is called cyclic if Î±U âˆˆC for all U âˆˆC
and Î± âˆˆFâˆ—
q N , and quasi-cyclic if Î±U âˆˆC for all U âˆˆC and Î± âˆˆG, where G is a
multiplicative subgroup of Fâˆ—
q N . Quasi-cyclic codes are also known as â€œ(cyclic) orbit
codesâ€ (see, for example, [13, 35]).
Subspace codes are the main mathematical tools in random network coding due
to their error correction capabilities shown in [17]. Cyclic subspace codes have
a particular interest thank to their efï¬cient encoding and decoding algorithms. A
systematic construction of cyclic subspace codes including several orbits was given
in [1] using subspace polynomials. In [28], this construction was generalized and
improved by increasing the code size and the number of possible parameters. In
Sect.2, we aim to give this construction with some computational illustrations.
1.3
Rank Metric Codes
Let FmÃ—n
q
be the set of m Ã— n matrices over Fq. On FmÃ—n
q
Ã— FmÃ—n
q
, the function d
deï¬ned by
d(A, B) := rank(A âˆ’B),
which satisï¬es the usual axioms of a metric, is called the rank distance on FmÃ—n
q
.
Remark 1 Notice that we use d to denote both the subspace distance and the rank
distance together, since we think that there is a less possibility to confuse them in this
chapter. Observe that they are deï¬ned on different ambient spaces, also we examine
them in separate sections (Sects.2 and 3).
A subset C of FmÃ—n
q
including at least two elements and equipped with the rank
distance is called a rank metric code. The minimum distance d(C ) of a code C
is naturally deï¬ned by d(C ) := min{d(A, B) : A, B âˆˆC and A Ì¸= B}. Equivalence
between any two rank metric codes is determined considering the set of rank distance
preservingmapsunderthelightof[36,Theorem3.4]:TworankmetriccodesC , C â€² âŠ†
FmÃ—n
q
are called equivalent if there exist X âˆˆGL(m, Fq), Y âˆˆGL(n, Fq) and Z âˆˆ
FmÃ—n
q
such that
C â€² = XC ÏƒY + Z := {XCÏƒY + Z : C âˆˆC } when m Ì¸= n,
C â€² = XC ÏƒY + Z or C â€² = X(C t)ÏƒY + Z when m = n,
(2)

46
K. Otal and F. Ã–zbudak
for some automorphism Ïƒ acting on the entries of C âˆˆC , where the superscript t
denotes the transposition of matrices. If both C and C â€² are closed under addition,
then Z must be the zero matrix. Similarly, if both C and C â€² are linear over Fq, then
Ïƒ can be taken as the identity without loss of generality. This equivalence idea, in
different forms and scopes, is used in several studies [3, 20, 22, 23, 25â€“27, 31].
Rank metric codes have a well-known Singleton-like bound given in the follow-
ing proposition.
Proposition 1 ([5]) Assume m â‰¥n without loss of generality. Let C âŠ†FmÃ—n
q
be a
rank metric code with the minimum rank distance d. Then |C | â‰¤qm(nâˆ’d+1).
We may give an elementary proof for this proposition as follows.
Proof Let C â€² âŠ†FmÃ—(nâˆ’d+1)
q
be the set of matrices obtained by deleting the last d âˆ’1
columns of codewords in C . If A, B âˆˆC are distinct, then their images Aâ€², Bâ€² âˆˆC â€²
are also distinct since d(A, B) = rank(A âˆ’B) > d âˆ’1, hence |C | = |C â€²|. Also the
inclusion C â€² âŠ†FmÃ—(nâˆ’d+1)
q
implies |C â€²| â‰¤qm(nâˆ’d+1). That is, |C | â‰¤qm(nâˆ’d+1). â–¡
If the Singleton-like bound is met, then the code is called maximum rank distance
(MRD) code. MRD codes have a rich mathematical structure, inheriting the q-
analogue dimension of classical coding theory. Besides the theoretical importance,
they also have various applications, for example, in random network coding (e.g.,
[33]), space-time coding (e.g., [21, 34]) and cryptology (e.g., [29, 32]).
Finding new optimal codes, up to an equivalence notion, is one of the basic
problems in coding theory. Accordingly, the problem of ï¬nding new MRD codes
up to the equivalence relation given in (2) has gained interest especially in the last
decade. We may summarize the history of the results about this problem as follows.
â€¢ Linear MRD codes:
â€“ 1978, 1985 and 1991: Gabidulin codes in [5, 12, 30].
â€“ 2005: Generalized Gabidulin codes in [15] (brieï¬‚y called GG codes).
â€“ 2016: Twisted Gabidulin codes in [31] (brieï¬‚y called TG codes). A particular
case was also discovered independently in [25].
â€“ 2016: Generalized twisted Gabidulin codes in [20, 31] (brieï¬‚y called GTG
codes).
â€¢ Non-linear additive MRD codes:
â€“ 2017: Additive generalized twisted Gabidulin codes in [26] (brieï¬‚y called AGTG
codes).
â€¢ Non-additive (but closed under multiplication by a scalar) MRD codes:
â€“ 2016: A family for the m = n = 3 and d = 2 case in [4].
â€“ 2017: A generalization of [4] to the d = m âˆ’1 case in [7].
â€¢ Non-additive and not closed under multiplication by a scalar MRD codes:
â€“ 2017: A family for arbitrary d in [27].

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
47
In Sect.3 we give these constructions explicitly using their linearized polynomial
representation. Notice that all families listed above are constructed for m = n. From
a code C âŠ†FmÃ—m
q
of minimum distance d, by deleting last m âˆ’n rows (or columns),
we can obtain another code C â€² âŠ†FmÃ—n
q
of minimum distance larger than or equal
to d âˆ’m + n. The new code C â€² is called a punctured code. Remark that if a rank
metric code C is MRD then so is its punctured version C â€². However, punctured codes
are not involved in this chapter, since the m = n case may be considered the more
general case in this perspective.
2
Construction of Cyclic Subspace Codes
Let U âˆˆGq(N, k). We never consider the trivial cases, so assume 1 < k < N unless
otherwise stated. Here, U is a linear space over Fq, but U can be also a linear space
over Fqt for some t > 1 (observe that t always divides both N and k in this case).
Such a property affects some important parameters. In case we need to emphasize
this property, we brieï¬‚y say â€œFqâˆ’linearâ€ and â€œFqtâˆ’linearâ€ correspondingly.
The Orb(U) := {Î±U : Î± âˆˆFâˆ—
q N } set is called the orbit of U. The cardinality of
an orbit can be determined as in the following well-known theorem.
Theorem 1 Let U âˆˆGq(N, k). Then, Fqd is the largest ï¬eld over which U is linear
if and only if
|Orb(U)| = q N âˆ’1
qd âˆ’1 .
Similar versions of this theorem are available also in [1, 6, 13]. We may prove
this theorem in an elementary way as follows.
Proof (â‡’) : Let Fqd be the largest ï¬eld over which U is linear. Then we have
|Orb(U)| â‰¤q N âˆ’1
qdâˆ’1 since aU = U for all a âˆˆFqd. Assume that the equality does not
hold. Then there exists an Î± âˆˆFq N \ Fqd such that Î±U = U, by pigeon hole principle.
It implies U is also Fqd(Î±)âˆ’linear, but Fqd âŠŠFqd(Î±) since Î± /âˆˆFqd. Hence Fqd is not
the largest ï¬eld over which U is linear, contradiction. Therefore, the equality must
hold, i.e. |Orb(U)| = q N âˆ’1
qdâˆ’1 .
(â‡) : It can be shown by the (â‡’) part.
â–¡
If d = 1 in Theorem 1, then the orbit is called full length orbit. Otherwise, the
orbit is called degenerate orbit.
Remark 2 In case we need to study degenerate orbits, equivalently we can study full
length orbits over Fqd and then carry all the data from Gqd(N/d, k/d) to Gq(N, k).

48
K. Otal and F. Ã–zbudak
2.1
A Construction Including Many Full Length Orbits
The following theorem gives a systematic construction of cyclic subspace codes
including many full length orbits in Gq(N, k), when the minimum distance is 2k âˆ’2.
Theorem 2 ([28]) Consider r polynomials
Ti(x) := xqk + Î¸ixq + Î³ix âˆˆFqn[x],
1 â‰¤i â‰¤r
satisfying Î¸i Ì¸= 0 and Î³i Ì¸= 0 for all 1 â‰¤i â‰¤r, and
Î³i
Î³ j
Ì¸=

Î³i
Î³ j
 Î¸i
Î¸ j
âˆ’1 qk âˆ’1
qâˆ’1
when i Ì¸= j.
(3)
Also let
â€“ Ni be the degree of the splitting ï¬eld of Ti for 1 â‰¤i â‰¤r,
â€“ Ui âŠ†Fq Ni be the kernel of Ti for 1 â‰¤i â‰¤r,
â€“ N be a multiple of lcm(N1, . . . , Nr).
Then the code C âŠ†Gq(N, k) given by
C =
r
i=1
{Î±Ui : Î± âˆˆFâˆ—
q N }
is a cyclic code of size r q N âˆ’1
qâˆ’1 and of minimum distance 2k âˆ’2.
Proof Let Ci := {Î±Ui : Î± âˆˆFâˆ—
q N }, for 1 â‰¤i â‰¤r. Then C := r
i=1 Ci is a subset of
Gq(N, k) and it is obviously cyclic. To prove that |C | = r q N âˆ’1
qâˆ’1 and d(C ) = 2k âˆ’2,
it is enough to prove
dim(Î±Ui âˆ©Î²U j) â‰¤1 when i Ì¸= j or Î±
Î² /âˆˆFq.
(4)
Let Î¸ âˆˆÎ±Ui âˆ©Î²U j, where 1 â‰¤i, j â‰¤r. Then there exist u âˆˆUi (i.e. Ti(u) = 0) and
v âˆˆU j (i.e. Tj(v) = 0) such that Î¸ = Î±u = Î²v. Eliminating v by taking v = Î±
Î² u and
hence solving the system Ti(u) = 0 and Tj( Î±
Î² u) = 0 in terms of u, we obtain

(Î±qk
Î²qk )Î¸i âˆ’(Î±q
Î²q )Î¸ j

uq +

(Î±qk
Î²qk )Î³i âˆ’(Î±
Î² )Î³ j

u = 0.
(5)
The left hand side of equation (5) is a qâˆ’polynomial in terms of u. If we assume
that the left hand side is identically zero, then we obtain a contradiction with (3)

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
49
after eliminating Î± and Î² in (5). Hence, the polynomial on the left hand side of
(5) can not be identically zero. Conclusively, the fundamental theorem of algebra
implies (4).
â–¡
Remark 3 Let T (x) âˆˆFq N [x] be a subspace polynomial and U be the set of all
roots of T (x). We can determine another subspace U âŠ†Fq N associated with T (x)
as follows.
u âˆˆU â‡”T (x) =

xq âˆ’
1
uqâˆ’1 x

â—¦Q(x)
for some qâˆ’polynomial Q(x) over Fq N , where â—¦denotes the composition of poly-
nomials. This space can be also characterized by
u âˆˆU â‡”uq is a root of T (x) := (Î±0x)qk + Â· Â· Â· + (Î±kâˆ’1x)q + x,
where
T (x) = xqk + Î±kâˆ’1xqkâˆ’1 + Â· Â· Â· + Î±0x.
Here, U is called the adjoint space of U (see [24, Theorem 14, 15 and 16]
for the proofs of these facts). Therefore, corresponding to a code C obtained
in Theorem 2, we can construct another code C using the polynomials Ti(x) =
Î³ qk
i xqk + Î¸qkâˆ’1
i
xqkâˆ’1 + x instead of Ti(x) in Theorem 2. Both C and C have the
same parameters. We call C the adjoint code of C .
The following corollary, as a particular case of Theorem 2, shows that we can
construct cyclic subspace codes including up to (qn âˆ’1) orbits.
Corollary 1 If Î¸i = Î³ q
i for all 1 â‰¤i â‰¤r in Theorem 2, then (3) is satisï¬ed. If more-
over Î³i and Î³ j are conjugate as Î³i = Î³ ql
j
for some i, j and l, then Ui = U ql
j and
hence Ni = N j.
Proof The inequality (3) holds clearly when Î¸i = Î³ q
i for all 1 â‰¤i â‰¤r in Theorem 2.
NowletÎ¸i = Î³ q
i forall1 â‰¤i â‰¤r,andÎ³i = Î³ ql
j forsomei, j andl.Takeu âˆˆU ql
j ,then
u = vql forsomev âˆˆU j.Hence, Tj(v) = Tj(uqâˆ’l) = 0 whichimpliesthat Ti(u) = 0.
In that way, we see that Ti(u) = 0 and so U ql
j âŠ†Ui. It can be shown similarly that
Ui âŠ†U ql
j . Conclusively Ui = U ql
j and hence Ni = N j.
â–¡
Remark 4 A particular case of Corollary 1, the r = n and Î³i = Î³ qi case for some
primitive element Î³ of Fqn for all 1 â‰¤i â‰¤n, was given in [1].
Remark 5 What is done in Corollary 1 is to pick some (up to qn âˆ’1) full length
orbits satisfying the following.
â€¢ The minimum distance in an orbit is â‰¥2k âˆ’2,
â€¢ The minimum distance between any two orbits is â‰¥2k âˆ’2.

50
K. Otal and F. Ã–zbudak
At this point, it is natural to ask for the number of all full length orbits, i.e. the size
of the pool we pick orbits from. The next theorem from [6] answers this question.
Before stating it, we recall some basic deï¬nitions and facts:
â€¢ MÃ¶bius function Î¼ over the set of positive integers is given by
Î¼(n) =
â§
â¨
â©
1
if n = 1,
(âˆ’1)r if n is a product of r distinct primes ,
0
if n is divisible by a square of a prime .
â€¢ Gaussian coefï¬cient (or q-binomial coefï¬cient) is deï¬ned by
N
k

q
:=
kâˆ’1

i=0
q N âˆ’qi
qk âˆ’qi =
kâˆ’1

i=0
q Nâˆ’i âˆ’1
qkâˆ’i âˆ’1 .
The size of Gq(N, k) is actually
N
k

q.
Theorem 3 ([6]) Let d be a positive integer dividing both N and k. The number of
orbits in Gq(N, k) of size q N âˆ’1
qdâˆ’1 is
qd âˆ’1
q N âˆ’1

t:d|t and t| gcd(N,k)
Î¼(t/d)
N/t
k/t

qt.
(6)
The following corollary demonstrates the approximate density of the orbits used
in Corollary 1 in the set of all orbits. Similar approximations can be found also in
[18].
Corollary 2 Let r â‰¤qn âˆ’1 for some n dividing N as in Corollary 1. Also let s be
the number of positive integers dividing gcd(N, k). The ratio of the number of orbits
in the code obtained by Corollary 1 to the size of the whole set of full length orbits
is approximately
r
sq(Nâˆ’kâˆ’1)(kâˆ’1) .
Proof Taking d = 1 in Theorem 3, we see that there are s terms in the sum of (6),
and the absolute value of each one is less than or equal to
N
k

q
qâˆ’1
q N âˆ’1. On the other
hand, Corollary 1 gives r orbits. Hence the proportion is
r
s
N
k

q
qâˆ’1
q N âˆ’1
â‰ˆ
rq Nâˆ’1
sqkNâˆ’k(kâˆ’1)
2
âˆ’k(k+1)
2
=
r
sq(Nâˆ’kâˆ’1)(kâˆ’1) .
â–¡
Remark 6 Corollary 2 says that we pick only a small amount of orbits in Corollary
1 especially when N is large and k is close to N/2. Also, the s and r (and so n)
numbers play an important role.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
51
2.2
Generalization to Other Small Minimum Distances
Theorem 2 can be generalized for the codes of other minimum distances as in the
following corollary.
Corollary 3 Consider r polynomials
Ti(x) := xqk + Î³s,ixqs + Â· Â· Â· + Î³1,ixq + Î³0,ix âˆˆFqn[x],
1 â‰¤i â‰¤r
satisfying
â€¢ Î³0,i Ì¸= 0 for all 1 â‰¤i â‰¤r,
â€¢ there exist 0 â‰¤l1 < l2 â‰¤s such that
â€“ gcd(l1,l2) = 1,
â€“ l2 âˆ’l1 divides k âˆ’l2,
â€“ Î³l2,i Ì¸= 0 and Î³l1,i Ì¸= 0 for all 1 â‰¤i â‰¤r,
â€“ for all 1 â‰¤i â‰¤r, we have
Î³l1,i
Î³l1, j
Ì¸=
 Î³l1,i
Î³l1, j
( Î³l2,i
Î³l2, j
)âˆ’1
M
,
where
M = qkâˆ’l1 âˆ’1
ql2âˆ’l1 âˆ’1.
Also let
â€¢ Ni be the degree of the splitting ï¬eld of Ti, for 1 â‰¤i â‰¤r,
â€¢ Ui âŠ†Fq Ni be the kernel of Ti, for 1 â‰¤i â‰¤r,
â€¢ N be a multiple of lcm(N1, . . . , Nr).
Then the code C âŠ†Gq(N, k) given by
C =
r
i=1
{Î±Ui : Î± âˆˆFâˆ—
q N }
is a cyclic code of size r q N âˆ’1
qâˆ’1 and of minimum distance 2k âˆ’2s.
Proof The proof is similar to the proof of Theorem 2. There are a few things to notice
about the extra assumptions:
â€¢ We want qkâˆ’l1âˆ’1
ql2âˆ’l1âˆ’1 to be an integer, so we should have â€œl2 âˆ’l1 divides k âˆ’l1â€ or
equivalently â€œl2 âˆ’l1 divides k âˆ’l2â€.
â€¢ We want Ui to be a full length orbit for all 1 â‰¤i â‰¤r. Notice that U is Fqtâˆ’linear
if and only if the subspace polynomial of U is a qtâˆ’polynomial. Hence we
should take gcd(k âˆ’l2,l2 âˆ’l1,l1) = 1 to obtain only qâˆ’polynomials. The â€œl2 âˆ’

52
K. Otal and F. Ã–zbudak
l1 divides k âˆ’l2â€ property above implies that gcd(k âˆ’l2,l2 âˆ’l1,l1) = 1 if and
only if gcd(l1,l2) = 1.
â–¡
Remark 7 In case s > 1, we can choose the elements Î³ j,i âˆˆFqn freely, for j /âˆˆ
{0,l1,l2}. So r can be as many as qn(sâˆ’1)(qn âˆ’1) if l1 = 0, and qn(sâˆ’2)(qn âˆ’1)2
otherwise. Case s = 1, l1 = 0 and l2 = 1 is Theorem 2 in particular.
Remark 8 In case s > 1, if there exists an integer i such that 1 < i â‰¤s and i divides
k, then we can insert also degenerate orbits into the code. In that way we can improve
Corollary 3 further. We prefer to illustrate this further improvement by only an
example below.
Example 1 Let k = 6 and s = 3. For some positive integer n, consider r1 polyno-
mials
xq6 + Î³3,ixq3 + Î³2,ixq2 + Î³1,ixq + Î³0,ix âˆˆFqn,
1 â‰¤i â‰¤r1
as in Corollary 3 by taking l1 = 0 and l2 = 1. Using them, we can construct a cyclic
code C1 of size up to q2n(qn âˆ’1) q N1âˆ’1
qâˆ’1 and of minimum distance â‰¥2k âˆ’2s = 6 for
some suitable N1.
Consider r2 polynomials
xq6 + Î³2,ixq2 + Î³0,ix âˆˆFqn,
1 â‰¤i â‰¤r2
satisfying
â€¢ Î³0,i Ì¸= 0 and Î³2,i Ì¸= 0 for all 1 â‰¤i â‰¤r2,
â€¢
Î³0,i
Î³0, j Ì¸=

Î³0,i
Î³0, j ( Î³2,i
Î³2, j )âˆ’1M2 when i Ì¸= j,
where M2 = qkâˆ’1
q2âˆ’1. Using them in Theorem 2, we can construct a cyclic code C2 of
size up to (qn âˆ’1) q N2âˆ’1
q2âˆ’1 and of minimum distance â‰¥2k âˆ’2s = 6 for some suitable
N2.
Consider r3 polynomials
xq6 + Î³3,ixq3 + Î³0,ix âˆˆFqn,
1 â‰¤i â‰¤r3
satisfying
â€¢ Î³0,i Ì¸= 0 and Î³3,i Ì¸= 0 for all 1 â‰¤i â‰¤r3,
â€¢
Î³0,i
Î³0, j Ì¸=

Î³0,i
Î³0, j ( Î³3,i
Î³3, j )âˆ’1M3 when i Ì¸= j,
where M3 = qkâˆ’1
q3âˆ’1. Using them in Theorem 2 again, we can construct a cyclic code
C3 of size up to (qn âˆ’1) q N3âˆ’1
q3âˆ’1 and of minimum distance â‰¥2k âˆ’2s = 6 for some
suitable N3.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
53
Now consider râ€²
2 polynomials
xq6 + Î³3,ixq3 + Î³2,ixq2 + Î³0,ix âˆˆFqn,
1 â‰¤i â‰¤râ€²
2
satisfying
â€¢ Î³0,i Ì¸= 0, Î³2,i Ì¸= 0 and Î³3,i Ì¸= 0 for all 1 â‰¤i â‰¤râ€²
2,
â€¢
Î³2,i
Î³2, j Ì¸=

Î³2,i
Î³2, j ( Î³3,i
Î³3, j )âˆ’1Mâ€²
2 when i Ì¸= j,
where Mâ€²
2 = qkâˆ’2âˆ’1
qâˆ’1 . Using them in Corollary 1, we can construct a cyclic code C â€²
2
of size up to (qn âˆ’1)(qn âˆ’1) q N2âˆ’1
qâˆ’1
and of minimum distance â‰¥2k âˆ’2s = 6 for
some suitable N â€²
2.
Clearly C1, C2, C â€²
2 and C3 are disjoint (recall the uniqueness of subspace polyno-
mials), and the minimum distance between any two of them is greater than or equal
to 6 again. Therefore, we can construct a code C := C1 âˆªC2 âˆªC â€²
2 âˆªC3 of size up to
q2n(qn âˆ’1)q N âˆ’1
q âˆ’1 + (qn âˆ’1)(qn âˆ’1)q N âˆ’1
q âˆ’1 + (qn âˆ’1)q N âˆ’1
q2 âˆ’1 + (qn âˆ’1)q N âˆ’1
q3 âˆ’1
and of minimum distance 6, where N is a multiple of lcm(N1, N2, N â€²
2, N3).
2.3
Possible Values for the Length Parameter
Notice that parameter N in Theorem 2 is not chosen freely, it is depending on some
elements in Fqn. Accordingly, some N values can not be achievable.
In [35] it was conjectured that there exists a cyclic code of size q N âˆ’1
qâˆ’1 and of
minimum distance 2k âˆ’2 in Gq(N, k), for all positive integers N and k such that
k â‰¤N/2. In [13] it was proved by an exhaustive search that there are no cyclic
codes with parameters N = 8, k = 4 and q = 2; i.e. the conjecture is not true when
N = 2k.
In [1] the authors give an approach to determine a set of possible N values. Their
proof is given by considering Fq N0 which is the splitting ï¬eld of T (x) = xqk + xq +
x âˆˆFq[x]. Here, the set of inï¬nitely many N values is N0N := {N0, 2N0, . . .}. Hence
the proof can be completed using the proof of Theorem 2 taking n = 1, r = 1 and
Î³1 = 1.
Remark 9 When q > 2, the construction of a set of possible N values given in [1]
can be improved so that the set of possible N values is denser. It can be done by
taking the polynomials xqk + a1xq + a0x over Fq for all non-zero a1 and non-zero
a0 instead of taking only xqk + xq + x.
Proof Let T (x) := xqk + a1xq + a0x for some non-zero a1 and a0 in Fq. Let U
be its kernel in the splitting ï¬eld Fq N0 . It is easy to show that dim(Î±U âˆ©Î²U) â‰¤

54
K. Otal and F. Ã–zbudak
1 when Î±
Î² /âˆˆFq, as in the proof of Theorem 2. Later on, we take another polynomial
T â€²(x) by using another pair (aâ€²
1, aâ€²
0) and obtain N â€²
0. Taking the union N0N âˆªN â€²
0N, we
obtain an opportunity to enlarge the set of possible N values. Then, we take another
pair (aâ€²â€²
0, aâ€²â€²
1) and so on.
â–¡
We think that this basic observation is worth emphasizing because of its usefulness
that can be seen in the following example.
Example 2 Let q = 5 and k = 3. If we consider only T (x) = xqk + xq + x, then
we obtain N0 = 62. That is, N values can be chosen from 62N. In addition, by
considering xqk + xq + 4x we obtain 31N. Similarly, if we consider xqk + xq + 2x,
then we obtain 24N. By trying other non-zero couples, we get 31N âˆª24N âˆª20N as
a sample space for N.
Now,werecallsometoolsthatwecanusetofactorizesomelinearizedpolynomials
in an easier way.
Deï¬nition 1 [19, Deï¬nition 3.58] The polynomials
l(x) :=
N

i=0
Î±ixi and L(x) :=
N

i=0
Î±ixqi
over Fq N are called qâˆ’associates of each other. More speciï¬cally, l(x) is the con-
ventional qâˆ’associate of L(x) and L(x) is the linearized qâˆ’associate of l(x).
Lemma 1 ([19, Theorem 3.62]) Let L1(x) and L(x) be qâˆ’polynomials over Fq with
conventional qâˆ’associates l1(x) and l(x) respectively. Then L1(x) divides L(x) if
and only if l1(x) divides l(x).
Lemma 2 ([19, Theorem 3.63]) Let f (x) be irreducible over Fq and let F(x) be
its linearized qâˆ’associate. Then the degree of every irreducible factor of F(x)/x is
equal to the order of f (x).
Remark 10 The construction of the set of possible N values can be improved in the
following way: Factorize the conventional q-associate t(x) = xk + x + 1 and ï¬nd
the orders of its irreducible factors, then take the least common multiple of these
orders and thus determine N. In this way, the factorization cost can be decreased
signiï¬cantly.
The proof of Remark 10 is straightforward from Lemmas 1 and 2. In addition,
Remarks 9 and 10 can be combined to obtain larger sets in easier ways. We illustrate
the efï¬ciency of Remark 10 by the following example.
Example 3 Letq = 5 and k = 3 again. Instead of factorizing T (x) = x125 + x5 + x,
we can easily factorize t(x) = x3 + x + 1, it is actually irreducible since it has
no roots in F5, and its order can be only in {e âˆˆN : e|(53 âˆ’1) and e â‰¥k} =
{4, 31, 62, 124}. Notice that t(x) does not divide x4 âˆ’1 and x31 âˆ’1 but divides
x62 âˆ’1, thus we ï¬nd N0 = 62 easily.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
55
3
Construction of Maximum Rank Distance Codes
Note that chapter â€œCodes Endowed with the Rank Metricâ€ provides some essential
information about the analysis of rank metric codes in vector and matrix representa-
tion. In this section we just focus on the various constructions of MRD codes using
the linearized polynomial representation.
Let f (x) âˆˆFqn[x] be a qâˆ’polynomial of qâˆ’degree at most n âˆ’1. Let {Î´1, Î´2,
. . . , Î´n} and {Îµ1, Îµ2, . . . , Îµn} be two ordered bases of Fqn over Fq. Then, for any
Î± âˆˆFqn we have
f (Î±) = f (c1Î´1 + c2Î´2 + Â· Â· Â· + cnÎ´n)
= c1 f (Î´1) + c2 f (Î´2) + Â· Â· Â· + cn f (Î´n)
=
 f (Î´1) f (Î´2) . . . f (Î´n)  c1 c2 . . . cn
t
= [Îµ1 Îµ2 . . . Îµn]
â¡
â¢â¢â¢â£
f (Î´1)Îµ1 f (Î´2)Îµ1 . . . f (Î´n)Îµ1
f (Î´1)Îµ2 f (Î´2)Îµ2 . . . f (Î´n)Îµ2
...
...
...
...
f (Î´1)Îµn f (Î´2)Îµn . . . f (Î´n)Îµn
â¤
â¥â¥â¥â¦
â¡
â¢â¢â¢â£
c1
c2
...
cn
â¤
â¥â¥â¥â¦
(7)
for some ci âˆˆFq, for 1 â‰¤i â‰¤n; where f (Î´i)Îµ j denotes the coefï¬cient of Îµ j when
f (Î´i) is written as a linear combination of Îµ1, . . . , Îµn, for all 1 â‰¤i, j â‰¤n. Let
F denote the matrix given by F = [ f (Î´i)Îµ j] j,i âˆˆFnÃ—n
q
. Notice that there is a one
to one correspondence between f and F with respect to the ï¬xed ordered bases
{Î´1, Î´2, . . . , Î´n} and {Îµ1, Îµ2, . . . , Îµn}, also we have rank(F) = rank( f ). Moreover,
the algebra FnÃ—n
q
with the matrix addition and the matrix multiplication corresponds
to the algebra
Ln := {Î±0x + Î±1xq + Â· Â· Â· + Î±nâˆ’1xqnâˆ’1 : Î±0, . . . , Î±nâˆ’1 âˆˆFqn}
with the addition and the composition of polynomials modulo xqn âˆ’x, respectively.
Let f (x) = nâˆ’1
i=0 Î±ixqi âˆˆLn and let {Î´1, Î´2, . . . , Î´n} given above be a normal
basis. Also take Îµi = Î´i for all i = 1, . . . , n. Then, the correspondence f â†”F above
implies the correspondence f â†”Ft, where f is given by f (x) = nâˆ’1
i=0 Î±qi
nâˆ’ixqi
mod xqn âˆ’x and the subscript is for modulo n. Here, f is called the adjoint of f .
Consider the algebra Ln as the ambient space instead of the algebra FnÃ—n
q
while
studying on rank metric codes. In that way, we can inherit the equivalence notion as
follows. Let C and C â€² be non-empty subsets of Ln, then C and C â€² are equivalent if
and only if there exist g1, g2, g3 âˆˆLn such that g1(x) and g2(x) are invertible, and
C â€² = g1(x) â—¦C â—¦g2(x) + g3(x)
:= {g1(x) â—¦f (x) â—¦g2(x) + g3(x)
mod xqn âˆ’x : f (x) âˆˆC }, or
C â€² = g1(x) â—¦
C â—¦g2(x) + g3(x)
:= {g1(x) â—¦f (x) â—¦g2(x) + g3(x)
mod xqn âˆ’x : f (x) âˆˆC },
(8)

56
K. Otal and F. Ã–zbudak
where the â—¦operation denotes the composition. Notice also that, if C is closed under
addition, then the minimum distance d(C ) of C is indeed the minimum non-zero
rank of the elements in C .
In this section, we introduce all MRD codes in the literature. Before that, we give
a very useful lemma that efï¬ciently works to construct new MRD codes.
Lemma 3 ([14])
Let
f (x) = Î±0x + Î±1xq + Â· Â· Â· + Î±lxql âˆˆFqn[x]
be
a
qâˆ’
polynomial of qâˆ’degree l, where 0 < l < n. If Normqn/q(Î±l) Ì¸= (âˆ’1)nkNormqn/q
(Î±0), then dim(ker( f )) â‰¤l âˆ’1.
3.1
Linear MRD Codes
The ï¬rst examples of MRD codes were naturally linear ones. The largest family
including all known linear MRD codes can be stated as follows.
Theorem 4 ([20, 31]) Let n, k, s, h âˆˆZ+ satisfying gcd(n, s) = 1 and k < n âˆ’1.
Let Î· âˆˆFqn such that Normqn/q(Î·) Ì¸= (âˆ’1)nk. Then the set
Hn,k,s(Î·, h) := {Î±0x + Î±1xqs + Â· Â· Â· + Î±kâˆ’1xqs(kâˆ’1) + Î·Î±qh
0 xqsk : Î±0, Î±1, . . . , Î±kâˆ’1 âˆˆFqn}
is a linear MRD code of size qnk and minimum distance n âˆ’k + 1.
The codes constructed in Theorem 4 are called generalized twisted Gabidulin
codes (or brieï¬‚y GTG codes). The main tool used to prove the bound of minimum
rank distance of such codes is Lemma 3. Some subclasses of this family can be listed
as follows.
â€¢ The Î· = 0 and s = 1 case: Gabidulin codes, ï¬rstly given in [5, 12, 30].
â€¢ The Î· = 0 case: Generalized Gabidulin codes, ï¬rstly given in [15].
â€¢ The s = 1 case: Twisted Gabidulin codes, ï¬rstly given in [31]. A special case was
also discovered independently in [25].
Classiï¬cation of Hn,k,s(Î·, h) under the equivalence given in (8) is dependent on
parameters.Forexample,non-GabidulinexamplesofgeneralizedGabidulincodesdo
not appear for 1 â‰¤n â‰¤4. Similarly, the smallest non-Gabidulin example of linear
MRD codes for k = 2 is H3,2,1(2, 1). Notice also that there are no examples of
linear codes which are not generalized Gabidulin when q = 2. We give the following
theorem as an example of classiï¬cation of H4,2,1(Î·, 2) with respect to the proï¬le
of Î·.
Theorem 5 ([25]) Let Î·1, Î·2 âˆˆFq4 with Norm(Î·1) Ì¸= 1 and Norm(Î·2) Ì¸= 1, then
H4,2,1(Î·1, 2) and H4,2,1(Î·2, 2) are equivalent if and only if
Î·qi
1 = Î·2cq2âˆ’1 or Î·âˆ’qi
1
= Î·2cq2âˆ’1
for some c âˆˆFq4 and i âˆˆ{0, 1, 2, 3}.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
57
Proof (â‡’) : Assume there are invertible qâˆ’polynomials A(x) = a0x + a1xq +
a2xq2 + a3xq3 and B(x) = b0x + b1xq + b2xq2 + b3xq3 in Fq4[x] and an invertible
map Fq4 Ã— Fq4 â†’Fq4 Ã— Fq4 given by (Î±0, Î±1) â†’(Î²0, Î²1) such that
Î±0x + Î±1xq + Î·1Î±q2
0 xq2 â‰¡A(x) â—¦(Î²0x + Î²1xq + Î·2Î²q2
0 xq2) â—¦B(x)
mod xq4 âˆ’x,
or
Î±0x + Î±1xq + Î·1Î±q2
0 xq2 â‰¡A(x) â—¦(Î²0x + Î·q2
2 Î²0xq2 + Î²q3
1 xq3) â—¦B(x)
mod xq4 âˆ’x.
for all Î±0, Î±1 âˆˆFq4. Then we should have
(the coefï¬cient of xq3) â‰¡0
mod xq4 âˆ’x, and
(the coefï¬cient of xq2) â‰¡Î·1(the coefï¬cient of x)q2
mod xq4 âˆ’x,
on the right hand side. This property implies a system of 16 equations with 8
unknowns a0, a1, a2, a3, b0, b1, b2, b3. Some algebraic manipulations on the solu-
tion of this system yield the result. Simultaneously, an invertible map Fq4 Ã— Fq4 â†’
Fq4 Ã— Fq4 given by (Î±0, Î±1) â†’(Î²0, Î²1) can be constructed.
(â‡) : In each case, suitable invertible A(x) and B(x) couples can be deter-
mined computationally. Also an invertible map Fq4 Ã— Fq4 â†’Fq4 Ã— Fq4 given by
(Î±0, Î±1) â†’(Î²0, Î²1) can be constructed simultaneously. For example, consider case
Î·qi
1 = Î·2cq2âˆ’1 for some c âˆˆFq4 and i âˆˆ{0, 1, 2, 3}. Then A(x) = cxqi and B(x) =
xq4âˆ’i, which are clearly invertible, can be used to show the equivalence. Also we have
(Î±0, Î±1) = (cÎ²qi
0 , cÎ²qi
1 ).
â–¡
Theorem 5 says that H4,2,1(Î·1, 2) and H4,2,1(Î·2, 2) are equivalent when
Norm(Î·1) = Norm(Î·2). However, we can have both equivalence and inequivalence
when Norm(Î·1) = Norm(Î·2)âˆ’1 as we can observe in the following example.
Example 4 Let q = 5 and Fq4 = Fq(Î³ ), where Î³ is a primitive element satisfying
Î³ 4 + Î³ 2 + 2Î³ + 2 = 0.
1. Let Î·1 = Î³ 39 and Î·2 = Î³ 273. Then Norm(Î·1) = 3 and Norm(Î·2) = 2. Here,
Î·âˆ’1
1
= Î·2cq2âˆ’1 for c = Î³ 26. Hence H4,2,1(Î·1, 2) and H4,2,1(Î·2, 2) are equiva-
lent according to Theorem 5.
2. Let Î·1 = Î³ 39 and Î·2 = Î³ 253. Then Norm(Î·1) = 3 and Norm(Î·2) = 2, that is,
Norm(Î·1) = Norm(Î·2)âˆ’1. However, Î·qi
1 Ì¸= Î·2cq2âˆ’1 for all c âˆˆFq4 and i âˆˆZ.
Therefore, H4,2,1(Î·1, 2) and H4,2,1(Î·2, 2) are not equivalent according to Theo-
rem 5.

58
K. Otal and F. Ã–zbudak
3.2
Additive MRD Codes
Consider case q = qu
0 for some integer u > 1 and a prime power q0. A set of
qâˆ’polynomials, i.e. a rank metric code, can be Fq0âˆ’linear but does not have to
be Fqâˆ’linear. We can observe this situation in the following example.
Example 5 Consider case q0 = 2, u = 2, n = 2. Let F4 = F2(Ï‰) where Ï‰2 + Ï‰ +
1 = 0, and F42 = F4(Î¶) where Î¶ 2 + Î¶ + Ï‰ = 0. Then the set
{Î±x + (Ï‰Î± + Ï‰Î±2 + Ï‰2Î±4 + Ï‰2Î±8)x4 âˆˆF42[x] : Î± âˆˆF42}
is an MRD code with d = 2. Taking F4âˆ’bases (Îµ1, Îµ2) = (1, Î¶) and (Î´1, Î´2) = (1, Î¶)
as in (7), we can construct the matrix version of this code as follows.
C = SpanF2
 1 0
0 1

,
 1 1
1 0

,
 Ï‰ 0
1 Ï‰

,
 Ï‰ Ï‰
Ï‰ 1

as a subset of F2Ã—2
4
. Remark that this code is not linear (over F4), because
Ï‰
 1 0
0 1

=
Ï‰ 0
0 Ï‰

/âˆˆC .
At this point, we want to clarify a possible misunderstanding. Note that the ï¬eld
Fq = Fqu
0 is isomorphic to a suitable subset of FuÃ—u
q0 . This well-known fact is available
in [19, Sect.2.5]. Therefore, it seems that there is a natural and trivial lifting an MRD
code C âŠ†FnÃ—n
q
with the minimum rank distance d over Fq to another MRD code
C â€² âŠ†FnuÃ—nu
q0
with the minimum rank distance du over Fq0. It is actually true when
d = n as we can observe in Example 5 above, also there are some similar observations
in [3, 31] considering semiï¬elds. However, it is not true when d < n, as we can see
in the following proposition.
Proposition 2 Let q = qu
0 for some prime power q0 and integer u > 1. Let C âŠ†
FnÃ—n
q
be an MRD code with d(C ) = d. Let C â€² âŠ†FnuÃ—nu
q0
be the code obtained by
writing the entries of matrices from C in matrix representation. Then C â€² is a rank
metric code with d(C â€²) = du. Moreover, C â€² is an MRD code if and only if d = n.
Proof The ï¬rst part is clear from the isomorphism. The fact about being MRD can be
observed from the inequality of sizes qn(nâˆ’d+1) â‰¤qnu(nuâˆ’du+1)
0
, where the equality
holds only when d = n.
â–¡
Remark 11 When we lift a code C âŠ†FnÃ—n
q
to another code C â€² âŠ†FnuÃ—nu
q0
using
matrix representation, the distance function also changes from rank(A âˆ’B) to
rankFq0 (A âˆ’B) (i.e. the rank of A âˆ’B over Fq0). However, keeping it as rank(A âˆ’
B) does not change the value of the distance.
Now, we give a family of MRD codes which includes also non-linear but additive
MRD codes. Recall that Lemma 3 was used in [31] in order to construct Theorem

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
59
4. In case q is not a prime, it is possible to reinterpret this family by using another
basic observation, as demonstrated in the following theorem.
Theorem 6 ([26]) Let n, k, s, u, h âˆˆZ+ satisfying gcd(n, s) = 1, q = qu
0 and k <
n. Let Î· âˆˆFqn such that Normqn/q0(Î·) Ì¸= (âˆ’1)nku. Then the set
Hn,k,s,q0(Î·, h) = {Î±0x + Î±1xqs + Â· Â· Â· + Î±kâˆ’1xqs(kâˆ’1)
+Î·Î±
qh
0
0 xqsk : Î±0, Î±1, . . . , Î±kâˆ’1 âˆˆFqn}
is an Fq0âˆ’linear (but does not have to be linear) MRD code of size qnk and minimum
distance n âˆ’k + 1.
Proof Code size and Fq0âˆ’linearity are clear from the deï¬nition. The trick related to
Lemma 3 about the norm of Î· can be observed from the transitivity of norm function
(see, for example, [19, Theorem 2.29]).
â–¡
We call the code family obtained in Theorem 6 as additive generalized twisted
Gabidulin codes, or brieï¬‚y AGTG codes. Investigation of equivalence among such
codes and some further results are available in [26].
Remark 12 The Venn diagram of families of all known additive MRD codes has
been given in Fig.1. The conditions about the parameters can be summarized as
follows.
â€¢ When u divides h, an AGTG code is a GTG code.
â€¢ When u divides h and s = 1, an AGTG code is a TG code.
â€¢ When u divides h and Î· = 0, an AGTG code is a GG code.
â€¢ When u divides h, s = 1 and Î· = 0, an AGTG code is a Gabidulin code.
Now, we focus on the equivalence idea for additive codes. Consider f (x)pi :=
x pi â—¦f (x) mod xqn âˆ’x, where p is the prime dividing q. If we expand f (x)pi to
the corresponding matrix as in (7), then we obtain the matrix Bâˆ’1F pi A, where
A and B are invertible matrices satisfying [Î´ pi
1
. . . Î´ pi
n ]A = [Î´1 . . . Î´n] and
[Îµ pi
1
. . . Îµ pi
n ]B = [Îµ1 . . . Îµn]. That is, f (x)pi does not correspond to F pi directly. In
fact, f (x)pi is not a qâˆ’polynomial when i Ì¸â‰¡0 mod logp(q), so it corresponds to
another qâˆ’polynomial which has the matrix form Bâˆ’1F pi A when we ï¬x the ordered
bases {Îµ1, . . . , Îµn} and {Î´1, . . . , Î´n}. Therefore, in polynomial form, it makes sense
to write the equivalence between two additive codes C and C â€² as follows: C â‰¡C â€²
if and only if
C â€² = g â—¦C pi â—¦h := {g(x) â—¦f (x)pi â—¦h(x)
mod xqn âˆ’x : f (x) âˆˆC }, or
C â€² = g â—¦
C pi â—¦h := {g(x) â—¦f (x)pi â—¦h(x)
mod xqn âˆ’x : f (x) âˆˆC }
for some invertible qâˆ’polynomials g, h âˆˆFqn[x] and a non-negative integer i, even
if some elements are not qâˆ’polynomials.

60
K. Otal and F. Ã–zbudak
Fig. 1 Venn diagram of all
known additive MRD code
families
AGTG
GTG
TG
GG
Gabid.
Notice that Hn,k,s,q0(Î·, h) is not linear when uÌ¸ | h, hence an AGTG code is not
equivalent to a GTG code when uÌ¸ | h. It is because, a code which is equivalent to a
linear code must be linear, too. When h is a multiple of u, Hn,k,s,q0(Î·, h) is clearly
linear, and equivalent to a GTG code by a new h := h/u. This idea can be summed
up and summarized as follows.
Proposition 3 Let C1, C2 âŠ†FnÃ—n
q
be two additive rank metric codes and let Fq1, Fq2
be the largest subï¬elds of Fq such that C1 is Fq1âˆ’linear and C2 is Fq2âˆ’linear. If
q1 Ì¸= q2, then C1 and C2 are inequivalent.
In that way, when we compare two AGTG codes, we observe the following.
Corollary 4 Let q = qu1
1 = qu2
2 . Then Hn,k,s,q1(Î·, h) and Hn,k,s,q2(Î·, h) are not
equivalent when gcd(h, u1) Ì¸= gcd(h, u2).
3.3
A Family of Non-additive MRD Codes
Notice that being non-additive is not enough for a code to be new, since it can be
obtained by adding a ï¬xed non-zero element to each codeword in an additive code.
We call such codes afï¬ne codes. However, there are also some non-additive codes
which are not afï¬ne. In this section, we construct such a family of MRD codes. For
Î» âˆˆFqn \ {0}, let

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
61
Ï€Î» := {(Î±x) â—¦(x + Î»xq + Î»1+qxq2 + Â· Â· Â· + Î»1+q+Â·Â·Â·+qnâˆ’2xqnâˆ’1) â—¦(Î²x) :
Î±, Î² âˆˆFqn \ {0}},
JÎ» := {(Î±x) â—¦(x âˆ’Î»xqnâˆ’1) â—¦(Î²x) : Î±, Î² âˆˆFqn \ {0}},
A1 := {Î±x : Î± âˆˆFqn \ {0}},
A2 := {Î±xqnâˆ’1 : Î± âˆˆFqn \ {0}}.
Lemma 4 ([7]) Consider the deï¬nitions and notations above, then Ï€Î»1 = Ï€Î»2 and
JÎ»1 = JÎ»2 when Norm(Î»1) = Norm(Î»2).
Let Norm(Î») = a, Lemma 4 allows us to use Ï€a and Ja instead of using the
notations Ï€Î» and JÎ», respectively.
Theorem 7 ([7]) Let q > 2 and n â‰¥3. For any subset I of Fq \ {0, 1}, put I =

aâˆˆI Ï€a, I = 
bâˆˆFq\(Iâˆª{0}) Jb and set
An,I := I âˆªI âˆªA1 âˆªA2 âˆª{0} âŠ†Ln.
Then An,I is a non-additive and non-afï¬ne MRD code of minimum distance n âˆ’1.
Remark 13 Notice that An,I is closed under multiplication by scalars, see [7] also
for the geometric interpretation of Theorem 7.
Remark 14 Theorem 7 is a generalization of the result in [4] which presents the
particular case A3;I.
3.4
Another Family of Non-additive MRD Codes
Lemma 3 was used to construct AGTG codes. In this section, as a second application
of Lemma 3 to construct new MRD codes, we provide a family of non-additive MRD
codes.
Theorem 8 ([27]) Let I be a subset of Fq, k and s be positive integers such that
k < n and gcd(n, s) = 1. Also let
C (1)
n,k,s,I :=
kâˆ’1

i=0
Î±i xqsi
mod xqn âˆ’x : Î±0, . . . , Î±kâˆ’1 âˆˆFqn, Normqn/q(Î±0) âˆˆI

,
C (2)
n,k,s,I :=
 k

i=1
Î²i xqsi
mod xqn âˆ’x : Î²1, . . . , Î²k âˆˆFqn, Normqn/q(Î²k) /âˆˆ(âˆ’1)n(k+1)I

.
Then Cn,k,s,I := C (1)
n,k,s,I âˆªC (2)
n,k,s,I is an MRD code with d(Cn,k,s,I) = n âˆ’k + 1.
Proof Firstly notice that C (1)
n,k,s,I and C (2)
n,k,s,I are disjoint. We can observe it as follows.
In case 0 /âˆˆI, the coefï¬cient of x of each element of C (1)
n,k,s,I is non-zero, whereas

62
K. Otal and F. Ã–zbudak
the coefï¬cient of x of each element of C (2)
n,k,s,I is zero; therefore, C (1)
n,k,s,I and C (2)
n,k,s,I
do not have common elements. In case 0 âˆˆI, the coefï¬cient of xqk of each element
of C (2)
n,k,s,I is non-zero, whereas the coefï¬cient of xqk of each element of C (1)
n,k,s,I is
zero; therefore, C (1)
n,k,s,I and C (2)
n,k,s,I do not have common elements in this case, too.
In addition, recall that the norm function is a qnâˆ’1
qâˆ’1 to 1 function on the set of
non-zero elements of Fqn, and sends only zero to zero. Therefore, we observe that
|C (1)
n,k,s,I| = qn(kâˆ’1)|I|

qnâˆ’1
qâˆ’1

,
|C (2)
n,k,s,I| = qn(kâˆ’1) 
1 + (q âˆ’1 âˆ’|I|)

qnâˆ’1
qâˆ’1
 
if 0 /âˆˆI, or
|C (1)
n,k,s,I| = qn(kâˆ’1) 
1 + (|I| âˆ’1)

qnâˆ’1
qâˆ’1
 
,
|C (2)
n,k,s,I| = qn(kâˆ’1)(q âˆ’|I|)

qnâˆ’1
qâˆ’1

otherwise. In both cases,
|C (1)
n,k,s,I| + |C (2)
n,k,s,I| = qnk,
which is equal to |Cn,k,s,I| since C (1)
n,k,s,I and C (2)
n,k,s,I are disjoint.
Now, we need to show that rank( f âˆ’g) â‰¥n âˆ’k + 1 for all f, g âˆˆCn,k,s,I.
Let f (x) âˆ’g(x) = Î¸0x + Î¸1xq + Â· Â· Â· + Î¸kxqk for arbitrary f, g âˆˆCn,k,s,I. If f, g âˆˆ
C (1)
n,k,s,I (or f, g âˆˆC (2)
n,k,s,I), then the q-degree of f (x) âˆ’g(x) and the coefï¬cient of x
implies that dim(ker( f (x) âˆ’g(x))) â‰¤k âˆ’1. If f âˆˆC (1)
n,k,s,I and g âˆˆC (2)
n,k,s,I (or vice
verse), then we have Normqn/q(Î¸0) Ì¸= (âˆ’1)nkNormqn/q(Î¸k) since Normqn/q(Î¸0) âˆˆ
I whereas Normqn/q(Î¸k) âˆˆFq \ (âˆ’1)nk I; i.e. dim(ker( f (x) âˆ’g(x))) â‰¤k âˆ’1 by
Lemma 3.
Combining these four cases, we deduce that rank( f (x) âˆ’g(x)) â‰¥n âˆ’(k âˆ’1) =
n âˆ’k + 1 for all f, g âˆˆCn,k,s,I.
Conclusively, we have proved that |Cn,k,s,I| = qnk and d(Cn,k,s,I) = n âˆ’k + 1,
and hence Cn,k,s,I is an MRD code.
â–¡
The code Cn,k,s,I given in Theorem 8 is a generalized Gabidulin code when q = 2
or I = {0} or I = Fq \ {0}. However, Cn,k,s,I is not equivalent to any additive MRD
codes when q > 2, I Ì¸= {0} and I Ì¸= Fq \ {0}.
Theorem 9 The code Cn,k,s,I given in Theorem 8 has the following properties.
1. If q = 2 or I = {0} or I = Fq \ {0}, then Cn,k,s,I is a generalized Gabidulin code.
2. If q > 2 and I Ì¸= {0} and I Ì¸= Fq \ {0}, then Cn,k,s,I is not an afï¬ne code (i.e.,
not a translated version of an additively closed code).
When we take two arbitrary I and J subsets of Fq, we can not say anything about
the equivalence between Cn,k,s,I and Cn,k,s,J for now. However, we can see that they
are equivalent if J = Fq \ I, taking the adjoint polynomials into account.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
63
Corollary 5 Let I be a subset of Fq, k and s be positive integers such that k < n
and gcd(n, s) = 1. Then Cn,k,s,Fq\I is equivalent to Cn,k,s,I.
In addition, we can give another result about the equivalence between Cn,k,s,I and
Cn,k,s,J when both I and J include only one non-zero element.
Corollary 6 Let a and b be non-zero elements of Fq, k and s be positive integers
such that k < n and gcd(n, s) = 1. Then Cn,k,s,{a} is equivalent to Cn,k,s,{b}.
The Cn,k,s,I family in Theorem 8 is called partition codes.
Remark 15 Some properties of non-additive code families An,I constructed in The-
orem 7 and Cn,k,s,I constructed in Theorem 8 in comparison can be listed as follows.
â€¢ The construction of Cn,k,s,I works for all parameters, whereas the minimum dis-
tance of an An,I code is ï¬xed to be n âˆ’1.
â€¢ An An,I code is closed under multiplication by scalars, but a Cn,k,s,I code is not
always.
The following example provides partition codes which are not twisted (i.e., not
additively closed).
Example 6 â€¢ Let q = 5, n = 3, k = 2, s = 1 and I = {1, 2, 3}. Then,
C (1)
n,k,s,I = {Î±0x + Î±1xq : Î±0, Î±1 âˆˆFqn and Norm(Î±0) âˆˆ{1, 2, 3}},
C (2)
n,k,s,I = {Î²1xq + Î²2xq2 : Î²1, Î²2 âˆˆFqn and Norm(Î²2) âˆˆ{0, 1}}
and the resulting partition code Cn,k,s,I is not additively closed.
â€¢ Let q = 4, n = 5, k = 1, s = 2 and I = {1, u}, where u âˆˆFq satisï¬es u2 + u +
1 = 0. Then,
C (1)
n,k,s,I = {Î±0x : Î±0 âˆˆFqn and Norm(Î±0) âˆˆ{1, u}},
C (2)
n,k,s,I = {Î²1xqs : Î²1 âˆˆFqn and Norm(Î²1) âˆˆ{0, u + 1}}.
Similarly, the resulting partition code is not additively closed.
Example 7 Let q = 7, n = 3, k = 2, s = 1 and I = {1, 2}. Then,
C (1)
n,k,s,I = {Î±0x + Î±1xq : Î±0, Î±1 âˆˆFqn and Norm(Î±0) âˆˆ{1, 2}},
C (2)
n,k,s,I = {Î²1xq + Î²2xq2 : Î²1, Î²2 âˆˆFqn and Norm(Î²2) âˆˆ{0, 1, 2, 3, 4}}.
Remember that the norm function is multiplicative. Therefore, the resulting partition
code Cn,k,s,I is not closed under multiplication by a scalar (and also not closed under
addition).

64
K. Otal and F. Ã–zbudak
AGTG
Partition
GTG
GG
Gabid.
Fig. 2 Venn diagram of MRD code families
3.5
Some Concluding Remarks
We may give the Venn diagram of involvements for all MRD codes except Theorem
7 in Fig.2.
Singleton-like bound and Lemma 3 provide some connections with some certain
optimal sets as we can see in the following corollary.
Corollary 7 Let k be a positive integer. The size of the largest possible subset T âŠ†
Fqn Ã— Fqn satisfying
Î²1 âˆ’Î²2 = 0, or Î±1 âˆ’Î±2 = 0, or Norm(Î²1 âˆ’Î²2) Ì¸= (âˆ’1)nkNorm(Î±1 âˆ’Î±2)
for all (Î±1, Î²1), (Î±2, Î²2) âˆˆT is qn.
Example 8 Sheekeyâ€™s example from [31]: Let h be a positive integer and Î· âˆˆFqn
satisfying Norm Ì¸= (âˆ’1)nk. Then
TÎ·,h := {(Î±, Î·Î±qh) : Î± âˆˆFqn}
is an optimal set given as in Corollary 7.
Example 9 Example from the construction in Theorem 8: Let I be a subset of Fq.
Then
TI := {(Î±, 0), (0, Î²) : Î±, Î² âˆˆFqn, Norm(Î±) âˆˆI, Norm(Î²) /âˆˆ(âˆ’1)n(k+1)I}
is another optimal set given as in Corollary 7.

Constructions of Cyclic Subspace Codes and Maximum Rank Distance Codes
65
As observed in Examples 8 and 9, ï¬nding new optimal sets as in Corollary 7 gives
an opportunity to construct new MRD codes. However, testing the equivalence with
the existing codes should be taken into account, too. There are several such sets that
can be found by computation easily, but most of their MRD codes were equivalent
to some known codes.
Acknowledgements The authors thank COST for the support under Action IC 1104. The ï¬rst
author thanks also TÃœBË™ITAK for the support under the program BË™IDEB 2211.
References
1. E. Ben-Sasson, T. Etzion, A. Gabizon, N. Raviv, Subspace polynomials and cyclic subspace
codes. IEEE Trans. Inf. Theory 62, 1157â€“1165 (2016)
2. M. Braun, T. Etzion, P. Ostergard, A. Vardy, A. Wasserman, Existence of q-analogues of Steiner
systems. Forum Math. Pi 4, 14 (2016). https://doi.org/10.1017/fmp.2016.5
3. J. Cruz, M. Kiermaier, A. Wassermann, W. Willems, Algebraic structures of MRD codes. Adv.
Math. Commun. 10, 499â€“510 (2016)
4. A. Cossidente, G. Marino, F. Pavese, Non-linear maximum rank distance codes. Des. Codes
Cryptogr. 79, 597â€“609 (2016)
5. P. Delsarte, Bilinear forms over a ï¬nite ï¬eld, with applications to coding theory. J. Comb.
Theory A 25, 226â€“241 (1978)
6. K. Drudge, On the orbits of Singer groups and their subgroups. Electron. J. Comb. 9 (2002)
7. N. Durante, A. Siciliano, Non-linear maximum rank distance codes in the cyclic model for the
ï¬eld reduction of ï¬nite geometries, arXiv: 1704.02110 [cs.IT]
8. T. Etzion, Problems on q-analogs in coding theory, arXiv: 1305.6126 [cs.IT]
9. T. Etzion, E. Gorla, A. Ravagnani, A. Wachter-Zeh, Optimal Ferrers diagram rank-metric codes.
IEEE Trans. Inf. Theory 62, 1616â€“1630 (2016)
10. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inf. Theory 55, 2909â€“2919 (2009)
11. T. Etzion, A. Vardy, Error correcting codes in projective space. IEEE Trans. Inf. Theory 57,
1165â€“1173 (2011)
12. E.M. Gabidulin, The theory with maximal rank metric distance. Probl. Inform. Trans. 21, 1â€“12
(1985)
13. H. Gluesing-Luerssen, K. Morrison, C. Troha, Cyclic orbit codes and stabilizer subï¬elds. Adv.
Math. Commun. 25, 177â€“197 (2015)
14. R. Gow, R. Quinlan, Galois theory and linear algebra. Linear Algebra Appl. 430, 1778â€“1789
(2009)
15. A. Kshevetskiy, E.M. Gabidulin, The new construction of rank codes. In: Proceedings of the
IEEE International Symposium on Information Theory, 2105â€“2108 (2005)
16. A. Kohnert, S. Kurz, Construction of large constant dimension codes with a prescribed mini-
mum distance. Lect. Notes Comput. Sci. 5393, 31â€“42 (2008)
17. R. KÃ¶tter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54, 3579â€“3591 (2008)
18. A. Klein, K. Metsch, L. Storme, Small maximal partial spreads in classical ï¬nite polar spaces.
Adv. Geom. 10, 379â€“402 (2010)
19. R. Lidl, H. Niederreiter, Finite ï¬elds. In: Encyclopedia of Mathematics and its Applications,
vol. 20. Cambridge University Press, Cambridge (1997)
20. G. Lunardon, R. Trombetti, Y. Zhou, Generalized twisted Gabidulin codes, arXiv:
1507.07855v2 [math.CO]

66
K. Otal and F. Ã–zbudak
21. P.J. Lusina, E.M. Gabidulin, M. Bossert, Maximum rank distance codes as space-time codes.
IEEE Trans. Inf. Theory 49, 2757â€“2760 (2003)
22. K. Marshall, A.-L. Horlemann-Trautmann, New criteria for MRD and Gabidulin codes and
some rank-metric code constructions. Adv. Math. Commun. (to appear)
23. K. Morrison, Equivalence of rank-metric and matrix codes and automorphism groups of
Gabidulin codes. IEEE Trans. Inf. Theory 60, 7035â€“7046 (2014)
24. O. Ore, On a special class of polynomials. Trans. Am. Math. Soc. 35, 559â€“584 (1933)
25. K. Otal, F. Ã–zbudak, Explicit constructions of some non-Gabidulin linear MRD codes. Adv.
Math. Commun. 10, 589â€“600 (2016)
26. K. Otal, F. Ã–zbudak, Additive rank metric codes. IEEE Trans. Inf. Theory 63, 164â€“168 (2017)
27. K. Otal, F. Ã–zbudak, Some new non-additive maximum rank distance codes (submitted)
28. K. Otal, F. Ã–zbudak, Cyclic subspace codes via subspace polynomials. Des. Codes Cryptogr.
https://doi.org/10.1007/s10623-016-0297-1
29. R. Overbeck, Structural attacks for public key cryptosystems based on Gabidulin codes. J.
Cryptol. 21, 280â€“301 (2008)
30. R.M. Roth, Maximum-rank array codes and their application to crisscross error correction.
IEEE Trans. Inf. Theory 37, 328â€“336 (1991)
31. J. Sheekey, A new family of linear maximum rank distance codes. Adv. Math. Commun. 10,
475â€“488 (2016)
32. D. Silva, F.R. Kschischang, Universal secure network coding via rank-metric codes. IEEE
Trans. Inf. Theory 57, 1124â€“1135 (2011)
33. D. Silva, F.R. Kschischang, R. KÃ¶tter, A rank-metric approach to error control in random
network coding. IEEE Trans. Inf. Theory 54, 3951â€“3967 (2008)
34. V. Tarokh, N. Seshadri, A.R. Calderbank, Space-time codes for high data rate wireless commu-
nication: performance criterion and code construction. IEEE Trans. Inf. Theory 44, 744â€“765
(1998)
35. A.-L. Trautmann, F. Manganiello, M. Braun, J. Rosenthal, Cyclic orbit codes. IEEE Trans. Inf.
Theory 59, 7386â€“7404 (2013)
36. Z.-X. Wan, Geometry of matrices. In: Memory of Professor L.K. Hua (1910â€“1985). (World
Scientiï¬c, Singapore, 1996)

Generalizing Subspace Codes to Flag Codes
Using Group Actions
Dirk Liebhold, Gabriele Nebe and MarÃ­a Ãngeles VÃ¡zquez-Castro
Abstract In this chapter, we ï¬rst discuss structural properties of subspace codes
by applying group actions. We will see that the projective space, the Grassmannian
and the Schubert cells can be realized by looking at the orbits of certain linear
groups on matrices. The approach naturally leads to a generalization, where we
replace subspace codes with ï¬‚ag codes. We describe and analyze a channel model
for these new codes that is similar to the operator channel introduced by Koetter
and Kschischang, give examples of ï¬‚ag codes and discuss how to compute sphere
packing and sphere covering bounds for ï¬‚ag codes.
1
Introduction
Network Coding is by now a well-established theoretical concept for transmission
of information over a network. The main difference compared to routing is that in a
network coded network, nodes cannot only forward network information units but
can also perform linear operations on them.
In their seminal work [7], Koetter and Kschischang described such a network
coded network as an operator channel for which input and output alphabets are given
as subspaces. Their results triggered a wide research into the ï¬eld of subspace codes,
see for example [1, 2, 4, 10, 11].
In this work, we will analyze the structure of subspace codes using group actions.
This will suggest ï¬‚ag codes [9, 14] as a natural generalization of subspace codes and
D. Liebhold (B) Â· G. Nebe
RWTH Aachen, 52062 Aachen, Germany
e-mail: liebhold@mathb.rwth-aachen.de
G. Nebe
e-mail: nebe@math.rwth-aachen.de
M. Ã. VÃ¡zquez-Castro
Department of Telecommunications and Systems Engineering, Universitat AutÃ²noma de
Barcelona, Cerdanyola del VallÃ¨s, 08193 Barcelona, Spain
e-mail: angeles.vazquez@uab.cat
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_4
67

68
D. Liebhold et al.
we will therefore discuss such codes, introducing distance functions, cells, circles
and sphere packing bounds.
The chapter is structured as follows. In the ï¬rst section, we collect some results
on subspace codes. We describe the operator channel by Koetter and Kschischang
and the Ferrers diagram approach to the construction of subspace codes. Here we
also introduce the term of a cell in the set of subspaces. In the second section, we talk
about group actions. After brieï¬‚y introducing the concept and giving some examples,
we let certain groups act on matrices and on subspaces, giving us structural results.
For example, it will turn out that each cell is an orbit code in itself, that is an orbit
under a subgroup of the general linear group.1 These actions lead to the concept of
ï¬‚ags, which we then discuss in the third section. We extend the notion of cells to
the set of ï¬‚ags, discuss distance functions and show how the subspace case embeds
into this more general theory. In the fourth section, we brieï¬‚y discuss ï¬‚ag codes and
show how to alter the network model to allow for a ï¬‚ag to be transmitted rather than
a subspace. We also give sphere packing and sphere covering bounds in a special
case and discuss the â„“âˆ’dp polynomial, which allows us to read off these bounds,
although an efï¬cient algorithm for its computation is not yet known.
2
Preliminaries
In this section, we collect known results on subspace codes. We will start by brieï¬‚y
describing the network model introduced in [7], and then discuss how to use matri-
ces when working with subspaces, ï¬nishing with the Ferrers diagram construction
introduced in [1]. We will focus on the basic concepts, which will be reviewed later
on with the help of group actions and generalized from subspaces to ï¬‚ags. For a more
detailed overview see chapter â€œConstructions of Constant Dimension Codesâ€.
2.1
The Network Model for Subspace Codes
We consider the multicast scenario, having a single source and multiple receivers. A
ï¬nite ï¬eld Fq is ï¬xed and the source injects vectors (packets) of constant length m,
i.e. elements of Fm
q , into the network. These vectors are the information units that
are sent through the network to realize communication between the source and the
multiple receivers. We will denote such vectors as information packets. In-network
intermediate nodes form linear combinations (e.g. at random) of their received pack-
ets and forward the result and each receiver tries to recompute the original message
from his received vectors.
Now we assume that the process of communication consists of sending n con-
secutive packets. This set of packets is called â€œgenerationâ€ in the related literature,
1For more details on orbit codes, see chapter â€œConstructions of Constant Dimension Codesâ€ by
Horlemann-Trautmann and Rosenthal.

Generalizing Subspace Codes to Flag â€¦
69
with n being the generation size. The channel model introduced in [7] is based on
the fact that having a generation of n packets x1, x2, . . . xn âˆˆFm
q , what is left invari-
ant when forming linear combinations of these vectors is the corresponding vector
space, U := âŸ¨x1, x2, . . . , xnâŸ©. Assuming no errors or erasures, a receiver can recover
the subspace U â€“ or rather a reduced basis of U â€“ as soon as he has collected n
linearly independent vectors. Thus the operator channel given in [7] uses the set
P(Fm
q ) of all subspaces of Fm
q both as input and output alphabet. This set can be
further broken down into the Grassmannians, Grn(Fm
q ), the set of all subspaces of
dimension n of Fm
q .
As the codewords are full vector spaces in this setting, a bit-wise error count is
not reasonable; one should rather deï¬ne errors and erasures dimension-wise. Assume
that the space U was sent and a receiver observes a space W. Then the network can
be modeled as an operator channel as follows [7]
W = Hk(U) âŠ•E
where Hk(U) = W âˆ©U is a subspace of dimension k of U and E is some subspace
of W satisfying E âˆ©U = {0}. Therefore, Hk(U) is the part of U that was not erased
by the network and E is an error space. In this case, we say that the network has
introduced Ï := dim(U) âˆ’k erasures and t := dim(E) errors. Network erasures
model the loss of dimension of the original space, which is due to the fact that
the underlying protocols of the network erase packets, for example because they
are found corrupted. Network errors on the other hand model the injection into the
network of exogenous packets that were not contained in the original generation of
packets (that generate U). The distance function counting errors and erasures is the
Grassmannian distance,
Ï + t = dim(U + W) âˆ’dim(U âˆ©W).
As this is a distance function, it also obeys a triangle inequality. This allows to show
that given a set of subspaces with minimal distance dmin, a minimal distance decoder
can correct all errors and erasures as long as 2(Ï + t) < dmin [7, Theorem2].
2.2
Matricial Representation of Subspaces
In this subsection, we discuss the matricial representation of subspaces. We will
show how the structural properties of such a representation allow for both efï¬cient
computations and for the construction of subspace codes in matricial representation.
Most of the concepts for this subsection were introduced in [11] and reï¬ned and
used for code construction in [1].
Given a subspace U â‰¤Fm
q , there are different ways to represent it. First, it is a
ï¬nite set, so one could write down the elements. However, if d = dim(U) this would
be a set of size qd, which is often too big to handle efï¬ciently. A more efï¬cient way

70
D. Liebhold et al.
is by computing a basis of U. This would be a set of size d which can be computed
using Gaussian elimination. However, such a basis is not unique; the space U of
dimension d has dâˆ’1
i=0 (qd âˆ’qi) ordered bases. To achieve uniqueness, we look at
matrices in reduced row echelon form.
Deï¬nition 1 A matrix X âˆˆFdÃ—m
q
of full rank d â‰¤m is in reduced row echelon form,
if
1. For every 1 â‰¤i â‰¤d the ï¬rst non-zero entry in the ith row is a 1.
2. If ri is the column containing the ï¬rst non-zero entry of row i, then we have
r1 < r2 < . . . < rd.
3. The column ri does only contain the single 1 in row i; all other entries are zero.
The binary vector v(X) âˆˆFm
2 deï¬ned by v(X) j = 1 if j = ri for some 1 â‰¤i â‰¤d
and v(X) j = 0 otherwise, is called the identifying vector of X.
The reduced row echelon form is well-known as the form returned by the classical
Gaussian elimination. For a quick example consider
X =
â›
â
1 1 0 1 1 0
0 0 1 0 1 0
0 0 0 0 0 1
â
â .
This matrix is in reduced row echelon form and the corresponding identifying vector
is given by v(X) = (1, 0, 1, 0, 0, 1). By using Gaussian elimination, every matrix
can be transformed to a matrix in reduced row echelon form. As this transformation
only forms linear combinations of the rows, the row space of X does not change.
Hence, by writing an arbitrary basis of U as rows into a matrix and performing
Gaussian elimination, we get that every vector space U has a unique ordered basis
in reduced row echelon form.
Deï¬nition 2 Let U â‰¤Fm
q be a subspace having dimension d. A matrix X âˆˆFdÃ—m
q
is called the basis matrix of U, if X is in reduced row echelon form and the rows of
X form a basis of U. The identifying vector of U is then deï¬ned to be the identifying
vector of X, v(U) := v(X).
We now have a way to store the information of a subspace uniquely in a matrix.
Note that the Hamming weight of v(U) satisï¬es wH(v(U)) = dim(U). This will
become important when constructing codes later on.
To store the information of a subspace more compactly, we look at the free posi-
tions in X. As an example, take the matrix X from above, having as identifying vector
v(X) = (1, 0, 1, 0, 0, 1). Every matrix having this identifying vector is of the form
â›
â
1 â€¢ 0 â€¢ â€¢ 0
0 0 1 â€¢ â€¢ 0
0 0 0 0 0 1
â
â 

Generalizing Subspace Codes to Flag â€¦
71
where â€¢ can be any element of Fq and we can hence conclude that there are exactly
q5 subspaces of Fm
q having this identifying vector.
Deï¬nition 3 For a given binary vector w âˆˆFm
2 , the set of all subspaces of Fm
q having
this identifying vector is called the Schubert cell of w,
C(w) := {U â‰¤Fm
q | v(U) = w}.
In the case that the base ï¬eld might vary, we write Cq(w). To store all necessary
information for a subspace, we hence only need the identifying vector and the entries
for the free positions. The free positions in such a matrix form a Ferrers-diagram, in
the above case the diagram
â€¢ â€¢ â€¢
â€¢ â€¢
If all free entries are zero, we call the space the standard space with identifying vector
v, written as S(v).
Deï¬nition 4 Let n be a positive integer and n = n1 + n2 + . . . + nk be a partition of
n into positive integers, ordered such that n1 â‰¥n2 â‰¥. . . â‰¥nk. Then a representation
of this partition by patterns of dots such that the ith row has the same number of
dots as the ith term in the partition and in each row the dots are shifted to the right
is called a Ferrers diagram.
Note that such diagrams are closely related to Young tableaux. Taking a Ferrers
diagram, one can construct a Ferrers diagram rank metric code [1].
Deï¬nition 5 Let F be a Ferrers diagram with n rows and k columns. A subspace
C â‰¤FnÃ—k
q
is called a Ferrers diagram rank metric code with respect to F, if every
matrix in C has zeros in the positions where F has no dots.
The distance function on such a matrix code is called the rank metric. For two
matrices A, B it is deï¬ned as dr(A, B) := rk(A âˆ’B). We have seen that a subspace
U of Fm
q can be uniquely described through its identifying vector v(U) and a matrix
A with corresponding Ferrers diagram. Given an identifying binary vector v and the
corresponding matrix A, the subspace U := â„“(v, A) is called the lift of w and A. An
important relation regarding the distances was shown in [11].
Lemma 1 Let v âˆˆFn
2 and let A, B be matrices for the Ferrers diagram induced by
v. Then d(â„“(v, A), â„“(v, B)) = 2dr(A, B).
Thus the rank distance gives us the subspace distance as long as we are in the
same cell. To illustrate some ideas, we prove this lemma for the special case of
v = 1k0mâˆ’k = (1, 1, . . . , 1, 0, 0, . . . , 0). For given matrices A, B, the basis matrices
for the two subspaces U := â„“(v, A) and W := â„“(v, B) will be (Ik A) and (Ik B) and
the sum U + W is the row space of

72
D. Liebhold et al.
Ik B
Ik A

.
Using Gaussian elimination, we reduce this matrix to
Ik
B
0 A âˆ’B

and as dim(U + W) is the rank of this matrix, we see that
dim(U + W) = k + rk(A âˆ’B).
The well-known formula
dim(U + W) = dim(U) + dim(W) âˆ’dim(U âˆ©W)
now also allows us to compute dim(U âˆ©W), giving d(U, W) = 2dr(A, B)
in the end.
In general, given two vector spaces U and W by a matrix in reduced row echelon
formorbyanidentifyingvectorandamatrix,computingtherepresentationofU + W
can be done efï¬ciently by Gaussian elimination. A representation for U âˆ©W can be
obtained similarly using Zassenhausâ€™ algorithm.
2.3
Subspace Codes
Above, we saw that every subspace has an identifying vector and a Ferrers diagram.
Here, we will discuss a construction from [1], where a certain set of vectors is
prescribed and the problem of ï¬nding good Ferrers diagram rank metric codes is
tackled for every cell separately.
First, we ï¬x some notations. A subset C âŠ†P(Fm
q ) is called a subspace code. The
minimal distance of C is deï¬ned as
dmin(C ) := min{d(U, W) | U Ì¸= W âˆˆC }.
We say that C is a (m, logq(|C |), dmin) subspace code. Furthermore,
â€¢ if every space in C has the same dimension, we say that C is a constant
dimension code.
â€¢ if every space in C has the same identifying vector, we say that C is a
single cell code.
Note that every code is a disjoint union of constant dimension codes and every
constant dimension code is a disjoint union of single cell codes. The most common
example of a single cell code (see for example [7, Example1]) has as identifying

Generalizing Subspace Codes to Flag â€¦
73
vector v = 1k0nâˆ’k, the corresponding matrices are often taken from an MRD code.
When using a subspace code for transmission, the size of C gives a bound on how
muchinformationcanbeencoded.However,havingabigcodedoesnotautomatically
mean that much information can be sent at once; one would also need efï¬cient
encoding. The same holds for the distance. A big minimal distance theoretically
allows for good error correction in the sense that a minimal distance decoder can
correct all Ï erasures and t errors as long as 2(Ï + t) < d (see [7] for more details),
but a minimal distance decoder is not efï¬cient in general.
We have already seen that having two subspaces in the same cell, the distance is
determined by the rank distance of the corresponding matrices. Having two subspaces
in different cells, the identifying vectors give a bound on the distance.
Lemma 2 Let U, W â‰¤Fm
q be subspaces and u, w âˆˆFn
2 their corresponding identi-
fying vectors. Then d(U, W) â‰¥dH(u, w).
Thus, given a minimal distance d and the task to construct a constant dimension
subspace code with dimension k achieving this minimal distance with a big size,
we ï¬rst choose a constant weight code C âŠ†Fn
2 with Hamming distance d, the so
called skeleton code. For every vector v âˆˆC, we then construct a Ferrers diagram
rank metric code with minimal distance (in the rank metric) at least d/2. As the size
of a cell is strongly related to how far the ones in the identifying vector are to the
left, a skeleton code chosen for example in a lexicographic way leads to good results.
Finding big codes with a given Ferrers diagram is harder. An upper bound on the
size of such a code was given in [1, Theorem1] and codes achieving this bound were
constructed in many cases (see for instance [4, 10]) and properties of such maximal
codes were also discussed (e.g. in [2]). However, the question if this bound is always
achievable and the search for a general construction always achieving this bound are
still open.
Furthermore, even if these codes are very big, they do not always allow for efï¬cient
encoding and decoding. Using results from [1], one can reduce these problems to
the question of ï¬nding efï¬cient encoding and decoding algorithms for the skeleton
code and for every rank metric code used. A big class of important rank metric codes
for which efï¬cient algorithms are known (see for example [11]) are Gabidulin codes
[3], but not all Ferrers diagram constructions are based on such codes.
3
Group Actions
The above matricial representations of subspaces and constructions are related to the
structural properties of the input and output alphabet of the network, the set P(Fm
q )
of all subspaces of Fm
q . We propose to use group actions to identify further structural
properties that can be relevant for subspace codes and its possible generalization.
A group is a non-empty set of elements G together with a composition rule

74
D. Liebhold et al.
â—¦: G Ã— G â†’G,
such that for all a, b, c âˆˆG we have
â€¢ Associativity: a â—¦(b â—¦c) = (a â—¦b) â—¦c,
â€¢ a neutral element 1 âˆˆG, satisfying 1 â—¦a = a â—¦1 for all a âˆˆG,
â€¢ an inverse element aâˆ’1, satisfying a â—¦aâˆ’1 = aâˆ’1 â—¦a = 1.
Classical examples for groups are the general linear group GL(V ) of a vector
space V , the set of all invertible linear maps from V into itself, and Sm, the set of
all permutations on m points. A group G is said to act (from the left) on a set Î© if
there is a map âˆ—: G Ã— Î© â†’Î© satisfying 1 âˆ—Ï‰ = Ï‰ and g âˆ—(h âˆ—Ï‰) = (g â—¦h) âˆ—Ï‰
for all Ï‰ âˆˆÎ© and all g, h âˆˆG. Similarly, one can also deï¬ne the action on the
right. For example the two groups mentioned above come with a natural action:
GL(V ) acts on V by applying a map to a vector and Sm acts on a set of m points
by applying a permutation. Other actions are for example the multiplication in the
group itself, setting âˆ—:= â—¦and Î© := G, or the conjugation in the group, where we
set âˆ—: G Ã— G â†’G, g âˆ—h = ghgâˆ’1.
The acting groups induce structural properties in the sets acted upon, such as a
partition of the elements of the set into orbits. For an element Ï‰ âˆˆÎ©, the orbit of Ï‰
under G is deï¬ned as
G âˆ—Ï‰ := {g âˆ—Ï‰ | g âˆˆG}.
The set of all orbits, denoted by O, is a partition of Î©, being in the same orbit is an
equivalence relation on Î© and an action having only a single orbit is called transitive.
In order to understand the structural properties of the set given by the orbits, one looks
at invariants.
Deï¬nition 6 Let G be a group that acts on a set Î©, let O = {G âˆ—Ï‰ | Ï‰ âˆˆÎ©} be
the set of orbits and I a set. A map Ï• : Î© â†’I is called an invariant for the group
operation if Ï• is constant on the orbits, that is Ï•(gÏ‰) = Ï•(Ï‰) for all g âˆˆG and all
Ï‰ âˆˆÎ©. In this case the invariant induces a map
Î¦ : O â†’I, G âˆ—Ï‰ â†’Ï•(Ï‰)
and the invariant is called separating if Î¦ is injective.
Note that the set I can often be reduced to make Î¦ surjective, in this case a sepa-
rating invariant classiï¬es the orbits. Every action has a separating invariant by taking
I = O and Î¦ = id. However, other invariants might be more useful in understand-
ing the structure of orbits or to quickly decide if two given elements lie in the same
orbit or not.
As an example, take the set Î© to be acted on as the projective space P(K m) and
the group GLm(K) acting on the right by applying a linear transformation to every
vector of a subspace U âˆˆP(K m):

Generalizing Subspace Codes to Flag â€¦
75
P(K m) Ã— GLm(K) â†’P(K m), (U, g) â†’{ug | u âˆˆU}.
The orbits under this action are the Grassmannians Grn(K m), the set of subspaces
of dimension n of K m, i.e. in this case we have
O âˆ¼= {Grn(K m) | 0 â‰¤n â‰¤m}.
Therefore, a separating invariant of this action is the dimension of subspaces.
Now consider Î© as the matricial representation of subspaces of Fm
q , given as
rectangular matrices. In particular, let FnÃ—m,n
q
denote the set of n Ã— m matrices of
rank n. Then the action on the right
FnÃ—m,n
q
Ã— GLm(K) â†’FnÃ—m,n
q
, (M, g) â†’Mg
is transitive. Note that the rank of a matrix equals the dimension of its row space, and
thus we see how the abstract and matricial actions are related. However, there is not a
bijection between the elements of an orbit of the abstract action and the elements of
the orbit of the matricial action, as different matrices can have the same row space.
Another important action, relating matricial and abstract notion of subspaces, is
the action of GLn(Fq) on the left via matrix multiplication,
GLn(Fq) Ã— FnÃ—m,n
q
â†’FnÃ—m,n
q
, (g, M) â†’gM
which induces orbits of matrices that can be represented by the same reduced row
echelon form (Fig.1). Thus the map that takes a matrix to its reduced row echelon
form is a separating invariant of this action. But also the orbit generated by the rows
of the matrix can be used as a separating invariant. Therefore, there exists a bijection
between the elements of an orbit of the abstract action (i.e. subspaces) and the orbits
of the matricial action on the left (i.e. sets of matrices represented by a unique reduced
row echelon form). Note that in the matricial representation, similar to the action on
the left, we have an action on the right, giving us as invariants the column echelon
form and the column space â€“ looking at rows rather than columns is a convention,
not a restriction.
To join all these actions together, we ï¬ll a matrix of FnÃ—m,n
q
with redundant rows,
that is linear combinations of the given rows, to get a quadratic m Ã— m matrix. In
this manner, we can construct all m Ã— m matrices. Looking at the action
(GLm(Fq) Ã— GLm(Fq)) Ã— FmÃ—m
q
â†’FmÃ—m
q
, ((g, h), M) â†’gMhâˆ’1,
what is left invariant is the rank of the matrices. A set of representatives of the orbits
are the rank normal forms
In 0
0 0

for 0 â‰¤n â‰¤m.

76
D. Liebhold et al.
Fig. 1 Graphical illustration of the orbits of the abstract action P(K m) Ã— GLm(K) â†’P(K m)
and the correspondence of the elements of its orbits with the orbits of the matricial action GLn(Fq) Ã—
FnÃ—m,n
q
â†’FnÃ—m,n
q
We just saw that acting on both sides with the general linear group, only the rank
was left invariant. To get more structure, we introduce the groups of upper and lower
triangular matrices,
B := {X âˆˆGLm(Fq) | Xi j = 0 âˆ€i < j} and BT := {X âˆˆGLm(Fq) | Xi j = 0 âˆ€i > j}.
When acting with BT on P(Fm
q ) through
P(Fm
q ) Ã— BT â†’P(Fm
q ), (U, b) â†’{ub | u âˆˆU},
the orbits turn out to be the Schubert cells.
Theorem 1 The orbits of BT on P(Fm
q ) are the Schubert cells Cq(v) introduced in
Deï¬nition3.
Proof Let v âˆˆFm
2 be a vector having ones exactly at positions i1, i2, . . . in, U = S(v)
the corresponding standard space and X âˆˆBT a matrix with rows x1, x2, . . . , xm.
Then(xi1, xi2, . . . , xin) is a basis of U X, and as X is an upper triangular matrix, the
vector xi j has its ï¬rst non-zero entry at position i j for all j. Thus U X lies in the same
cell as U. On the other hand, every space W in the cell parametrized by v has a basis
(y1, y2, . . . , yn) where the ï¬rst non zero entry of y j is at position i j for all j. We can
thus deï¬ne a matrix Y âˆˆBT having y j as rows in the desired positions and ï¬lled up
with rows of the identity matrix. Thus W = UY and hence U BT is exactly the cell
as claimed.
â–¡

Generalizing Subspace Codes to Flag â€¦
77
We thus see that the orbits of GLm(Fq) Ã— BT on FmÃ—m
q
are in bijection to the cells,
in this case giving us
O âˆ¼= {C(v) | v âˆˆFm
2 }.
As these are indexed by binary vectors v âˆˆFm
2 , let Î¼(v) âˆˆFmÃ—m
q
be a matrix in
reduced row echelon form having ones at positions indexed by v and zeros at any
other position (meaning that S(v) is the row space of Î¼(v)). Then our results up to
now tell us that for every M âˆˆFmÃ—m
q
, there is a unique v âˆˆFm
2 , such that there exists
g âˆˆGLm(Fq) and b âˆˆBT with M = gÎ¼(v)b. This can be written as
FmÃ—m
q
=
	
vâˆˆFm
2
GLm(Fq)Î¼(v)BT .
Operating with B from the left also gives interesting results when extending from
subspaces to ï¬‚ags in the next section.
4
Flags
In this section, we introduce ï¬‚ags and generalize the results on subspaces discussed
above. We start by deï¬ning the basic terms.
Deï¬nition 7 A ï¬‚ag Î› is a chain of distinct, non-trivial, proper subspaces of Fm
q ,
Î› = {V1 < V2 < . . . < Vk}.
The tuple (dim(V1), dim(V2), . . . , dim(Vk)) is called the type of the ï¬‚ag and the ï¬‚ag
is said to be a full (or ï¬ne) ï¬‚ag if it is of type (1, 2, 3, . . . , m âˆ’1).
By F = F(m, Fq) we denote the set of all ï¬‚ags and by F f = F f (m, Fq) the
set of all full ï¬‚ags. The group G := GLm(Fq) acts on F from the right by applying
a linear transformation to every single subspace in a ï¬‚ag and the type is a separating
invariant of this action. Given a ï¬‚ag Î› and a g âˆˆG, we write Î› Â· g for this action.
In the next two sections, we will focus on full ï¬‚ags, returning to the general case
afterwards.
4.1
Cells and the Gaussâ€“Jordan Decomposition
Here we try to transfer the concept of cells â€“ indexed by pivot positions â€“ to the set
of ï¬‚ags. Note that our cells will not coincide with the Bruhat cells in the theory of
ï¬‚ags (see for example [12]) but rather with the cells for subspaces. The Bruhat cells
will be called â€œcirclesâ€ in this article and will be discussed in the next section.

78
D. Liebhold et al.
To talk about pivot positions, we ï¬rst need to deï¬ne the matricial representation of
a ï¬‚ag. Given a matrix X âˆˆG, the rows x1, x2, . . . , xm of X are linearly independent.
Thus the sequence of subspaces
âŸ¨x1âŸ©< âŸ¨x1, x2âŸ©< . . . < âŸ¨x1, x2, . . . , xmâˆ’1âŸ©
forms a full ï¬‚ag, which we will call Î”(X). Note that we do not need the last row of
X to deï¬ne the ï¬‚ag. If X = Im is the identity matrix, we write Î”0 := Î”(Im) and if
Ï€ âˆˆSm has the corresponding permutation matrix Î  âˆˆG, we write Î”Ï€ := Î”(Î ),
thus Î”0 = Î”id. The set A = {Î”Ï€ | Ï€ âˆˆSm} is called the standard apartment and
plays an important role when looking at cells and circles. Given X, Y âˆˆG, we get
that Î”(X) Â· Y = Î”(XY), thus explaining why we consider the right action on ï¬‚ags.
In fact, we can write Î”(X) = Î”0 Â· X for all X âˆˆG.
When discussing subspaces, we saw that Gaussian elimination does not change
the row space of a matrix. However, this is not true for the ï¬‚ag represented by a
matrix in general, e.g. it is easy to see that interchanging two rows of a matrix will
always change the full ï¬‚ag. The only operations in the Gaussian elimination that
leave the ï¬‚ag unchanged are multiplications of rows and adding rows downwards,
that is adding row i to row j for j > i. These operations can be represented by
triangular matrices of the already introduced group B, giving us the following result.
Lemma 3 Let X âˆˆG. Then Y âˆˆG represents the same full ï¬‚ag as X, if and only if
Y âˆˆBX = {bX | b âˆˆB}.
We thus see that operating with B on the left, what is left invariant is not only the
row space but the whole ï¬‚ag. Furthermore, we can conclude that
Î”0 Â· b = Î”(b) = Î”(b Â· Im) = Î”0
for all b âˆˆB. In fact, B is the stabilizer of Î”0 under the action of G on F.
For subspaces, we have the reduced row echelon form as a normal form under the
operation of G. For ï¬‚ags, we call a matrix X a basis matrix of a ï¬‚ag Î›, if Î› = Î”(X)
and X is reduced downwards, that is the ï¬rst non-zero entry in each row of X is a one
and below all these ones, which we once again call pivots, X has only zeros. The two
big differences to the classical reduced row echelon form are that we do not enforce
zeros above the pivots and that the pivot positions do not have to be ordered. As an
example, consider a permutation Ï€ âˆˆSm with permutation matrix Î  âˆˆG. Then Î 
is a basis matrix for Î”Ï€.
As the basis matrix is exactly what we get when reducing only downwards, we
get that every ï¬‚ag has a unique basis matrix, that is every B orbit on G (via left
multiplication) contains exactly one basis matrix. As all our matrices are invertible,
we have to have a pivot element in each row and each column. If pi denotes the
position of the pivot element in the ith row, we thus have that (p1, p2, . . . , pm) is a
permutation, an element of Sm (in list notation). This yields the deï¬nition of a cell
in the ï¬‚ag case.

Generalizing Subspace Codes to Flag â€¦
79
Deï¬nition 8 Let Î› be a ï¬‚ag with basis matrix X whose pivot positions yield the
permutation Ï€ âˆˆSm. Then we call Ï€ the identifying permutation of Î›, written as
Ï€ = perm(Î›). The cell of a permutation Ï€ âˆˆSm is deï¬ned as
C(Ï€) := {Î› âˆˆF f | perm(Î›) = Ï€}.
The biggest cell is C(id), having size qk with k = m(m âˆ’1)/2, the smallest cell
is C(w) where w : {1, 2, . . . , m} â†’{1, 2, . . . , m}, i â†’m âˆ’i + 1; this cell contains
only a single element. The general size of a cell will be computed in Sect.4.3. A
representation system for the cells is given by the standard apartment. Just as we did
with subspaces, one can show that the cells are exactly the orbits of BT â‰¤G under
the action of G on ï¬‚ags described above, i.e. C(Ï€) = Î”Ï€ Â· BT . Identifying Ï€ âˆˆSm
with its permutation matrix, we get the well-known Gaussâ€“Jordan decomposition
G =
	
Ï€âˆˆSm
BÏ€ BT .
4.2
Circles, Sm-valued Distance and the Gaussâ€“Bruhat
Decomposition
In the last section we saw that the action of BT on ï¬‚ags yields the Gaussâ€“Jordan
decomposition. Different from the subspace case, also the action of B on the right
yields interesting results for ï¬‚ags. The following decomposition of G is called
the Gaussâ€“Bruhat decomposition and will help us to analyze distance functions
on F f and F:
G =
	
Ï€âˆˆSm
BÏ€ B.
Using that B = wBT w where w is deï¬ned as above, this decomposition can also be
computed using Gaussian elimination. We now show how the orbits of B on F f
relate to distance functions.
Lemma 4 Let d : F f Ã— F f â†’Zâ‰¥0 be a distance function that is invariant under
the operation of G, i.e. d(Î›, Î“ ) = d(Î› Â· g, Î“ Â· g) for all Î›, Î“ âˆˆF f and all g âˆˆG.
Let further X, Y âˆˆG and Ï€ âˆˆSm such that there exist b1, b2 âˆˆB with XY âˆ’1 =
b1Î b2. Then d(Î”(X), Î”(Y)) depends only on Ï€.
Proof Write Î”(X) = Î”0 Â· X and Î”(Y) = Î”0 Â· Y. As d is assumed to be invariant
under the action of G, we have that
d(Î”(X), Î”(Y)) = d(Î”0 Â· (XY âˆ’1), Î”0) = d(Î”(b1Î b2), Î”0).

80
D. Liebhold et al.
Now b1 âˆˆB does not change the ï¬‚ag represented by the matrix Î b2 and b2 âˆˆB
satisï¬es Î”0 Â· bâˆ’1
2
= Î”0 and hence we get
d(Î”(b1Ï€b2), Î”0) = d(Î”Ï€, Î”0 Â· bâˆ’1
2 ) = d(Î”Ï€, Î”0)
and thus the value of d only depends on Ï€ as claimed.
â–¡
The assumption that d should be invariant under the operation allows for more
structure to be exploited. In fact, both distance functions that we will discuss in
Sect.4.3 will have this property. Each such distance is thus made up of two parts: A
function f : Sm â†’Zâ‰¥0 and the function that we call the Sm-valued distance function,
deï¬ned through
dSm(Î”(X), Î”(Y)) := Ï€ âˆˆSm
if there exist b1, b2 âˆˆB such that XY âˆ’1 = b1Ï€b2. As in this case we will have
dSm(Î”(Y), Î”(X)) = Ï€âˆ’1, the function f should be invariant under taking inverses.
Furthermore, to guarantee that f â—¦dSm has all properties of a distance function, it
should satisfy f (Ï€) = 0 if and only if Ï€ = id and f (Ï€Ï•) â‰¤f (Ï€) + f (Ï•) for all
Ï€, Ï• âˆˆSm.
The length and the depth are two such functions and will be discussed in
the next section.
Just as the Gaussâ€“Jordan decomposition gave us the cells, the Gaussâ€“Bruhat
decomposition gives us the circles.
Deï¬nition 9 For Ï€ âˆˆSm, the Ï€-circle around a ï¬‚ag Î› is deï¬ned as
CÏ€(Î›) := {Î“ âˆˆF f | dSm(Î“, Î›) = Ï€}.
Taking as center Î› = Î”0, the circles around that ï¬‚ag are exactly the B orbits on
F f and in this case, the standard apartment is once again a set of orbit representatives
through CÏ€(Î”0) = Î”Ï€ Â· B. As we assumed the original distance d to be invariant
under the action of G, one should assume the same to be true for dSm. Indeed,
taking two matrices X, Y âˆˆG and corresponding ï¬‚ags Î”(X), Î”(Y), we get the same
Sm-valued distance for Î”(X) Â· g = Î”(Xg) and Î”(Y) Â· g = Î”(Yg), due to the fact
that XY âˆ’1 = (Xg)(Yg)âˆ’1. Using this result and once again the relation B = wBT w,
we can show a relation between cells and circles.
Lemma 5 For every Ï€ âˆˆSm we have C(Ï€) = CÏ€w(Î”w).
Proof Let Î› âˆˆC(Ï€). Then there exists bT âˆˆBT such that Î› = Î”Ï€ Â· bT . Writ-
ing bT = wbâ€²w for some bâ€² âˆˆB, we get Î› = Î”Ï€w Â· bâ€²w. Thus Î› Â· w = Î”Ï€w Â· bâ€²
has Sm-distance dSm(Î›w, Î”0) = Ï€w and thus dSm(Î›, Î”w) = Ï€w, hence giving us
Î› âˆˆCÏ€w(Î”w). Retracing these steps, we also get the other inclusion and thus the
claimed equality.
â–¡

Generalizing Subspace Codes to Flag â€¦
81
4.3
Length and Depth of a Permutation and Corresponding
Distance Functions
The two functions on the symmetric group Sm that we introduce in this section are
the length and the depth. The length plays an important role when studying Sm as a
Coxeter group (see for example [12, 13]), but it also appears in other contexts. The
deï¬nition of the length is based on the fact that
S := {(1, 2), (2, 3), (3, 4), . . . , (m âˆ’1, m)}
is a generating set for the group Sm, that is every permutation can be constructed
by successively interchanging neighboring elements. The length of a permutation
Ï€ âˆˆSm is then deï¬ned as the length of a shortest word in Sâˆ—yielding Ï€, written as
â„“(Ï€). From this deï¬nition we can immediately conclude the desired properties of a
function f given at the end of the last section: As every transposition (i, i + 1) is
self-inverse, we get â„“(Ï€) = â„“(Ï€âˆ’1). We further get â„“(Ï€) = 0 if and only if Ï€ = id
and given a word w1 âˆˆSâˆ—for Ï€ and a word w2 âˆˆSâˆ—for a permutation Ï•, we get
that w1w2 is a representation of Ï€Ï• (although not necessarily a shortest one). Not
immediately clear, but also important, is the fact that the permutation w, mapping i
to m âˆ’i + 1, is the unique longest element of Sm, having length m(m âˆ’1)/2.
A well-known way to compute a shortest word for a permutation Ï€ â€“ given as a list
(Ï€(1), Ï€(2), . . . , Ï€(m)) â€“ is the bubble sort algorithm, as it only changes neighboring
elements. This fact yields the following formula for the length (see for instance [6]
for more details):
â„“(Ï€) =
m

i=1
|{1 â‰¤k â‰¤i | Ï€(k) > Ï€(i)}|.
This way to compute the length allows us to now introduce the depth, which looks
quite similar:
dp(Ï€) :=
m

i=1
|{1 â‰¤k â‰¤i | Ï€(k) > i}| =
m

k=1,k<Ï€(k)
Ï€(k) âˆ’k = 1
2
m

k=1
|Ï€(k) âˆ’k|.
Unlike the length, which has been used for several centuries already, the depth
of a permutation received some attention only recently in [5, 8], whereas twice the
depth â€“ called the sum of distances â€“ was studied in [6].
Given the similar sum notation of the length and the depth, one might conjecture
a relation between these two functions. In [8], such a relation was found, namely for
all Ï€ âˆˆSm we have
â„“(Ï€)
2
â‰¤dp(Ï€) â‰¤â„“(Ï€).

82
D. Liebhold et al.
We now introduce the corresponding distance functions on ï¬‚ags, starting with the
length of a permutation. As in the generating set S, only neighboring elements are
interchanged in one step, we ï¬rst deï¬ne neighboring ï¬‚ags, calling two ï¬‚ags
Î› = {V1 < V2 < . . . < Vmâˆ’1} and Î“ = {W1 < W2 < . . . < Wmâˆ’1}
neighbors, if they differ in exactly one space. Using this deï¬nition, we construct a
graph on the set F f , joining two ï¬‚ags by an edge if they are neighbors. A shortest
path from a ï¬‚ag Î› to a ï¬‚ag Î“ in this graph is called a gallery between Î› and Î“ , the
length of such a path is called the gallery distance of Î› and Î“ . This distance is the
classically used distance when working with (full) ï¬‚ags and it is well-known (see
for example [12, 13]) that this distance is invariant under the action of G and that
the gallery distance of Î”0 and Î”Ï€ is exactly â„“(Ï€).
If we look at ï¬‚ags as a generalization of subspaces, we would like a distance
function that is deï¬ned for all ï¬‚ags (not only full ones) such that the distance of
two ï¬‚ags of length one Î› = {U} and Î“ = {W} is exactly the Grassmannian dis-
tance dim(U + W) âˆ’dim(U âˆ©W). The length function, however, is classically only
deï¬ned for full ï¬‚ags and ï¬nding a generalization to arbitrary ï¬‚ags that is still easy
to compute seems to be difï¬cult. We thus take a different approach, generalizing the
Grassmannian distance to the set of all ï¬‚ags. This yields the Grassmannian distance
on ï¬‚ags, ï¬rst introduced in [9].
Deï¬nition 10 Let Î› = {V1 < V2 < . . . < Vk} and Î“ = {W1 < W2 < . . . < Wn}
be two ï¬‚ags. Fill the shorter one with Fm
q such that n = k and then deï¬ne the
Grassmannian distance
dG(Î›, Î“ ) :=
k

i=1
dim(Vi + Wi) âˆ’dim(Vi âˆ©Wi).
Following the proof from [7] that the Grassmannian distance for subspaces is a
distance, one can show that dG is a distance function. Note that dG can be extended to
a distance on the set of all sequences (not necessarily ordered as a ï¬‚ag) of subspaces.
As the Grassmannian distance on subspaces is invariant under the operation of
G, so is the distance dG. The corresponding map on Sm is twice the depth, i.e.
dG(Î”0, Î”Ï€) = 2 dp(Ï€), the factor two coming from the fact that the Grassmannian
distance of two subspaces of the same dimension is always even; hence also a sum
over such values is.
Using the length, we can now also compute the size of a cell and a sphere in F f .
The size of a circle â€“ what is called a Bruhat cell in the literature â€“ is well-known
(see for example [12, 13]) to be
|CÏ€(Î›)| = qâ„“(Ï€).

Generalizing Subspace Codes to Flag â€¦
83
The size of a cell then follows from Lemma5 as
|C(Ï€)| = qâ„“(Ï€w).
4.4
Non-full Flags
In this section, we brieï¬‚y translate the previous results to the case of non-full ï¬‚ags,
taking ï¬‚ags of length one as examples. We already mentioned before that ï¬‚ags of
length one are basically subspaces; now we will see that the concepts of cells and
distance translate properly.
For full ï¬‚ags, we looked at the stabilizer of the ï¬‚ag Î”0, which we called B. Taking
the same approach here, we ï¬x a type T = (d1, d2, . . . , dk) and for a matrix X âˆˆG
we let Î”T (X) be the corresponding ï¬‚ag of this type, i.e. we take the full ï¬‚ag Î”(X)
and drop all spaces but the ones that have dimension di for some i. By dropping
these spaces, the stabilizer of the standard ï¬‚ag of type T , Î”T (Im), gets bigger and
we get a so called standard parabolic group, which is the group of all block triangular
matrices, having block sizes di+1 âˆ’di. For example taking the type T = (n) and thus
ï¬‚ags of length one, the stabilizer of Î”T (Im) is
Pn :=
A 0
B C

| A âˆˆGL(n, Fq), C âˆˆGL(m âˆ’n, Fq), B âˆˆF(mâˆ’n)Ã—n
q

.
We can once again deï¬ne the cell of a permutation for such ï¬‚ags. However, different
permutations may yield the same cell. In fact, for a Ï€ âˆˆSm we have that the permu-
tation matrix Î  lies in Pn if and only if Ï€ maps {1, 2 . . . , n} âŠ†{1, 2, . . . , m} onto
itself. Two permutations Ï€, Ï• âˆˆSm will give the same cell if and only if Î Î¦âˆ’1 âˆˆPn.
We thus get that the number of cells for ï¬‚ags of type T = (n) is
|Sm|
|Sn Ã— Smâˆ’n| =
m!
n!(m âˆ’n)! =
m
n

,
which is exactly the number of weight n vectors in Fm
2 . This once again shows that
the deï¬nition of a cell in the ï¬‚ag case is a generalization of the deï¬nition in the
subspace case.
5
Flag Codes
In this section, we describe how to use ï¬‚ags in a network coded network, deï¬ne
basic properties of a ï¬‚ag code and take a look at sphere packing and sphere covering
bounds.

84
D. Liebhold et al.
A set of ï¬‚ags C âŠ†F(Fm
q ) is called a ï¬‚ag code. Similar to subspaces, we call
dmin := min{dG(Î›, Î“ ) | Î› Ì¸= Î“ âˆˆC }
the minimum distance of C and say that C is a (m, logq(|C |), dmin) ï¬‚ag code.
Furthermore,
â€¢ if every ï¬‚ag in C has the same type T , we say that C is a constant type code, if
T = (1, 2, . . . , m âˆ’1) is the type of full ï¬‚ags, we say that C is a full ï¬‚ag code.
â€¢ if C is a constant type code and every ï¬‚ag lies in the same cell, we say that C is a
single cell code.
The last ingredient we need to analyze ï¬‚ag codes is the rate of such a code. For
that, let dmax(C ) be the biggest dimension of a space in a ï¬‚ag in C . Then only the
ï¬rst m âˆ’dmax rows of a basis matrix contain information on a ï¬‚ag of C and hence
need to be sent, thus yielding a rate of
R(C ) :=
logq(|C |)
mdmax
.
If we take for example C = C(id) to be the biggest cell of full ï¬‚ags, we have a rate
of 1/2. Taking C = F f , the set of all full ï¬‚ags, the rate also converges towards 1/2
if we ï¬x m and increase q. On the other hand, ï¬xing q and looking at big m allows
for rates bigger than 1/2.
By introducing additional zeros in the biggest cell, we can get higher distances.
Take for example the set
Dk = {X âˆˆBT | Xii = 1 âˆ€i, Xi j = 0 âˆ€i < j â‰¤i + k}
of all strict upper triangular matrices having k secondary diagonals ï¬lled with zeros.
Then two different matrices of Dk always yield two different full ï¬‚ags and the
corresponding ï¬‚ag code has minimal distance 2(k + 1) and rate
(m âˆ’k)(m âˆ’k âˆ’1)
2m(m âˆ’1)
(see [9] for proofs). Furthermore, the set Dk forms a subgroup of BT , thus allowing
for easier computation of distances and structure. Error correction for example is
possible efï¬ciently using this code. A similar construction is also possible in other
cells,allowingustofurtherextendthiscode.Toknowwhichcellstochoose,wewould
like a result on the distance between two cells, similar to the one on subspaces.
Lemma 6 Let Î› âˆˆC(Ï€) and Î“ âˆˆC(Ï•) be two full ï¬‚ags. Then
dG(Î›, Î”) â‰¥2 dp(Ï•âˆ’1Ï€).

Generalizing Subspace Codes to Flag â€¦
85
Note that we use left convention, meaning that Ï•âˆ’1Ï€ is the permutation that maps
every i to Ï•âˆ’1(Ï€(i)).
Proof Let Î› = {V1 < V2 < . . . < Vmâˆ’1} and Î“ = {W1 < W2 < . . . Wm1}, and let
further 1 â‰¤i â‰¤m such that Ï•âˆ’1(Ï€(i)) = j > i. Then Vi is the ï¬rst space in Î›
having a pivot element at position Ï€(i) and W j is the ï¬rst space in Î“ containing a
pivot at the same position. Thus we have Vk Ì¸= Wk for all i â‰¤k < j and as these
spaces have the same dimension, they hence have subspace distance at least two. As
we sum over all subspace distances to form the Grassmannian distance, we hence
get a distance of at least 2( j âˆ’i) in this case, in total giving us
dG(Î›, Î”) â‰¥2
n

i=1,Ï•âˆ’1(Ï€(i))>i
Ï•âˆ’1(Ï€(i)) âˆ’i,
which is exactly the deï¬nition of twice the depth of Ï€Ï•âˆ’1.
â–¡
To see that this bound is tight, remember that Î”Ï€ âˆˆC(Ï€) and Î”Ï• âˆˆC(Ï•) have
exactly distance 2 dp(Ï•âˆ’1Ï€).
5.1
The Network Model for Flag Codes
In a network coded network, we assume a source to inject packets, that are then
linearly combined and forwarded by intermediate nodes. Looking at todayâ€™s net-
works (e.g. the Internet), there is, however, something else to exploit: a numbering
of packets. Assuming that we want to send a ï¬‚ag Î› = {V1 < V2 < . . . < Vk} of type
(d1, d2, . . . , dk) through a network. This ï¬‚ag is given to the transmitter in the form
of a basis matrix X and the transmitter then injects the rows of X into the network.
While doing so, the rows are numbered according to the current space Vi in the ï¬‚ag,
that is the ï¬rst d1 rows get the number one, the next d2 âˆ’d1 rows get number two, etc.
An intermediate node now forms and forwards linear combinations in a desired way
(e.g. at random) and marks the outgoing vector with the highest number of vectors
used in the linear combination. Therefore, a vector with number i always lies in Vi
and hence also in all Vj with j â‰¥i. Thus collecting enough vectors with different
numbers, a receiver can reconstruct X and hence also Î›. Just as constant dimension
subspace codes simplify this process in the subspace setting, constant type ï¬‚ag codes
allow the receiver in this setting to know when he has enough vectors. To assure that
every receiver gets enough vectors, a proper choice of type and transmission protocol,
one that might take into account the numbering of packets, is necessary.
To introduce errors and erasures, assume that the ï¬‚ag Î› as above was sent. The
receiver reconstructs the spaces Wi generated by all received vectors with number
j â‰¤i and thus gets a stuttering ï¬‚ag Î“ = {W1 â‰¤W2 â‰¤. . . â‰¤Wk}, the term stuttering
meaning that some of these spaces might coincide. Similar to the operator channel
model in [7], we say that an erasure occurred at some point i, if Wi does not contain

86
D. Liebhold et al.
all of Vi. An error occurred, if Wi contains elements that do not lie in Vi. Writing
Wi = Hri(Vi) âŠ•Ei, where Hr(Vi) = Wi âˆ©Vi is a subspace of Vi of dimension
ri and Ei is some subspace of Wi satisfying Ei âˆ©Vi = {0}, we thus have di âˆ’ri
erasures and dim(Ei) errors in the ith space. Then the total number of erasures is
Ï := k
i=1 di âˆ’ri and the total number of errors is t := k
i=1 dim(Ei). As these
deï¬nitions and the Grassmannian distance on ï¬‚ags are both generalizations of the
constructions for subspaces, we get the following result, analog to [7, Theorem2].
Theorem 2 Using a ï¬‚ag code C of minimal distance dmin for transmission, a mini-
mal distance decoder can correct all errors and erasures, as long as 2(Ï + t) < dmin.
The
proof
of
this
generalization
uses
the
triangle
inequality
and
can be found in [9].
5.2
Sphere Sizes and the â„“âˆ’dp Polynomial
In this section, we compute some sphere packing and sphere covering bounds for
full ï¬‚ags and compare them to the bounds on subspaces computed in [7]. To do so,
remember that a Ï€-circle around a full ï¬‚ag has exactly size qâ„“(Ï€) where â„“denotes
the length function on Sm. A sphere of radius 2t with regard to the Grassmannian
distance thus contains

Ï€âˆˆSm,dp(Ï€)â‰¤t
qâ„“(Ï€)
ï¬‚ags. To compute sphere sizes, it would therefore be helpful to be able to efï¬ciently
compute the â„“âˆ’dp polynomial
Pm(x, y) :=

Ï€âˆˆSm
xâ„“(Ï€)ydp(Ï€).
Computing this polynomial once, we can then read off sphere sizes by dropping
certain powers of y and then inserting (x, y) = (q, 1). However, an efï¬cient way to
compute this polynomial or a closed form is not yet known.
Using computed values of Pm, we can give sphere packing and sphere covering
bounds for full ï¬‚ag codes and compare them to subspace codes. The following ï¬gure
shows the bounds for full ï¬‚ag codes in the space F8
2 and compares them to the bounds
on constant dimension subspace codes of dimension 4 computed in [7]. Note that
ï¬‚ag codes are able to achieve minimal distances that are not reachable by subspace
codes (Fig.2).
We will now collect some properties of this polynomial. The special value
Pm(x, 1) is well-known to be the generating function of the length,
Pm(x, 1) =
m

i=1
xi âˆ’1
x âˆ’1 .

Generalizing Subspace Codes to Flag â€¦
87
Fig. 2 Sphere packing and sphere covering bounds
For the generating function of the depth, Pm(1, y), a continued fraction was found
recently in [5]. We will here show a nice property, regarding the alternating distribu-
tion of the depth.
Lemma 7 We have
Pm(âˆ’1, y) =

Ï€âˆˆSm
sign(Ï€)ydp(Ï€) = (1 âˆ’y)mâˆ’1.
Proof We will use the deï¬nition
dp(Ï€) = 1
2
m

k=1
|Ï€(k) âˆ’k|.
The ï¬rst equality is clear, as the length is one well-known way to compute the
signum of a permutation. We thus show the second equality by induction over m.
For m = 1 there is only the identity, having signum 1 and depth 0. Thus assume that
the claim holds for m âˆ’1. Let H â‰¤Sm be the stabilizer of the point m. Then H acts
on {1, 2, . . . , m âˆ’1} and is isomorphic to Smâˆ’1. We have

88
D. Liebhold et al.
Sm =
m
	
i=1
(i, m)H,
where (i, m) denotes the transposition interchanging i and m and (m, m) stands for
the identity. Now let i < m âˆ’1, let h âˆˆH be arbitrary and set f := (i, m)h and
g := (i, m)(i, m âˆ’1)h. We will now compute twice the depth of f and g, seeing
that they are the same.
2 dp( f ) :
Let j := hâˆ’1(i). Then f ( j) = m, f (m) = i and f (x) = h(x) for all other values
x. Thus we have to add these two terms for f and subtract the original ones for h,
getting
2 dp( f ) = 2 dp(h) + |m âˆ’j| + |i âˆ’m| âˆ’|i âˆ’j| âˆ’|m âˆ’m|
= 2 dp(h) + (m âˆ’j) + (m âˆ’i) âˆ’|i âˆ’j|
= 2(dp(h) + m âˆ’max(i, j)).
2 dp(g) :
Set j := hâˆ’1(i) and k := hâˆ’1(m âˆ’1). Then g( j) = m âˆ’1, g(k) = m, g(m) = i
and g(x) = h(x) for all other values of x. Thus we get
2 dp(g) = 2 dp(h) + |m âˆ’1 âˆ’j| + |m âˆ’k| + |i âˆ’m| âˆ’|i âˆ’j| âˆ’|m âˆ’1 âˆ’k|
= 2 dp(h) + (m âˆ’1 âˆ’j) + (m âˆ’k) + (m âˆ’i) âˆ’(m âˆ’1 âˆ’k) âˆ’|i âˆ’j|
= 2(dp(h) + m âˆ’max(i, j)).
As for i < m âˆ’1 we always have that (i, m âˆ’1) âˆˆH is a non-trivial transpo-
sition, the elements f and g are different, but in the same class (i, m)H. As they
have the same depth but opposite signum, the corresponding terms cancel out when
taking the sum. We thus only have to look at the cases i = m âˆ’1 and i = m. For
i = m we get the subgroup H itself, thus by induction hypothesis this case con-
tributes (1 âˆ’y)mâˆ’2 to the polynomial. For i = m âˆ’1 and h âˆˆH, we once again can
set f := (m âˆ’1, m)h and j := hâˆ’1(m âˆ’1). Using that m âˆ’1 â‰¥j, we then get
2 dp( f ) = 2 dp(h) + (m âˆ’j) âˆ’(m âˆ’1 âˆ’j) + (m âˆ’(m âˆ’1)) âˆ’(m âˆ’m) = 2 dp(h) + 2
and thus dp( f ) = dp(h) + 1. This gives us that the set (m âˆ’1, m)H contributes
âˆ’y(1 âˆ’y)mâˆ’2 to the sum, as the signum of every element of H switches and the
depth is increased by one. In total we thus get
Pm(âˆ’1, y) = âˆ’y(1 âˆ’y)mâˆ’2 + (1 âˆ’y)mâˆ’2 = (1 âˆ’y)mâˆ’1.
â–¡

Generalizing Subspace Codes to Flag â€¦
89
References
1. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inform. Theory 55(7), 2909â€“2919 (2009)
2. T. Etzion, E. Gorla, A. Ravagnani, A. Wachter-Zeh, Optimal Ferrers diagram rank-metric codes.
IEEE Trans. Inform. Theory 62(4), 1616â€“1630 (2016)
3. Ãˆ.M. Gabidulin, Theory of codes with maximum rank distance. Problemy Peredachi Informatsii
21(1), 3â€“16 (1985)
4. E. Gorla, A. Ravagnani, Subspace codes from Ferrers diagrams. J. Algebra Appl. (to appear)
5. M. Guay-Paquet, T. Kyle Petersen, The generating function for total displacement. Electron.
J. Combin. 21(3), Paper 3.37, 13 (2014)
6. D.E. Knuth, The Art of Computer Programming: Sorting and Searching, vol. 3 (Addison-
Wesley, Reading, 1998)
7. R. KÃ¶tter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inform. Theory 54(8), 3579â€“3591 (2008)
8. T. Kyle Petersen, B. Eileen Tenner, The depth of a permutation. J. Comb. 6(1â€“2), 145â€“178
(2015)
9. D.Liebhold,G.Nebe,A.Vazquez-Castro,Networkcodingwithï¬‚ags.Des.CodesandCryptogr.
(2017)
10. N. Silberstein, A.-L. Trautmann, Subspace codes based on graph matchings, Ferrers diagrams,
and pending blocks. IEEE Trans. Inform. Theory 61(7), 3937â€“3953 (2015)
11. D. Silva, F.R. Kschischang, R. KÃ¶tter, A rank-metric approach to error control in random
network coding. IEEE Trans. Inform. Theory 54(9), 3951â€“3967 (2008)
12. T.A. Springer, Linear Algebraic Groups, 2nd edn., Modern BirkhÃ¤user Classics (BirkhÃ¤user,
Boston, 2009)
13. D.E. Taylor, The Geometry of the Classical Groups, vol. 9, Sigma Series in Pure Mathematics
(Heldermann Verlag, Berlin, 1992)
14. M.A. Vazquez-Castro, A geometric approach to dynamic network coding, in 2015 IEEE Infor-
mation Theory Workshop - Fall (ITW) (2015), pp. 207â€“211

Multi-shot Network Coding
Diego Napp and Filipa Santana
Abstract The seminal paper of Koetter and Kschischang [11] introduced coding
concepts for errors and erasures in a random network coding setting and since then
has opened a major research area in communication technology. Here, the network is
allowed to change very quickly, which is the case in many mobile applications. The
problem is suitably modeled via the operator channel, which makes a very clear con-
nection between network coding and classical information theory. However, coding
can also be performed over multiple uses of the network, whose internal structure
may change at each shot, giving rise to the so-called multi-shot network coding.
Although the potential of using multi-shot network coding was already observed in
[11], only recently this more involved approach have been investigated. The general
idea stems from the fact that creating dependencies among the transmitted codewords
of different shots can improve the error-correction capabilities. A very natural way to
impose correlation of codewords(subspaces) over time is by means of convolutional
codes, originating the notion of rank metric convolutional codes. In this Chapter we
review some of the main results and ideas of multi-shot network coding, propose
new approaches and point out some avenues for future research.
1
Introduction
In many multicast communication networks, like the internet, wireless communi-
cation and cloud computing, a transmitter sends packets to several users through
a series of intermediate nodes. In 2008, a seminal and award winning paper [11]
provided the mathematical foundations for the case where the topology of the net-
D. Napp (B) Â· F. Santana
CIDMA - Center for Research and Development in Mathematics and Applications,
Department of Mathematics, University of Aveiro, Campus Universitario de Santiago,
3810 -193 Aveiro, Portugal
e-mail: diego@ua.pt
F. Santana
e-mail: vfssantana@ua.pt
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_5
91

92
D. Napp and F. Santana
work is unknown and the nodes perform a random linear combination of the packets
received and forward this random combination to adjacent nodes. If one considers
the transmitted packet as columns of a matrix with entries in a ï¬nite ï¬eld Fq, then the
linear combinations performed in the nodes are columns operations on this matrix.
If no errors occur during the transmission over such a network, the column space of
the transmitted matrix remains invariant. In such an scenario the problem of reliable
communication is suitably modeled via the operator channel, which makes a very
clear connection between network coding and classical information theory. The oper-
ator channel can be seen as a standard discrete memoryless channel with input and
output alphabets given by the projective space P(Fn
q), i.e., the set of all possible vec-
tor subspaces of the vector space Fn
q. To achieve a reliable communication over this
channel, matrix codes are employed forming the so-called rank metric codes [26].
Rank metric codes such as Gabidulin codes are known to be able to protect packets
in such a scenario. We call these codes one-shot codes, as they use the (network)
channel only once.
However, coding can also be performed over multiple uses of the network as it
has been recently shown by several authors, see for instance [2, 13, 16, 20, 28]. The
general idea stems from the fact that creating dependencies among the transmitted
codewords (subspaces) of different shots can improve the error-correction capabili-
ties of the code. In order to increase the error-correcting capabilities of a block code in
one single shot, one necessarily needs to increase the ï¬eld size or the packet size and
this might not be optimal or impossible in many applications and consequently one
must create dependencies across multiple nodes to approach the channel capacity.
Thus, multi-shot codes constitute an attractive class of codes for such situations.
There are mainly two approaches for building multi-shot codes: one using con-
catenation of codes and other using rank metric convolutional codes. In [20], a type
of concatenated n-shot codes (n â‰¥1) was proposed based on a multilevel code. In
[17], a concatenation scheme was presented using a Hamming metric convolutional
code as an outer code and a rank metric code as an inner code. A different type of
concatenation was introduced in [13] where the authors use codes that layer both
Maximum Sum Rank (MSR) codes and Gabidulin in order to achieve the streaming
capacity for the Burst Erasure Channel.
Apart from concatenated codes, another very natural way to spread redundancy
across codewords is by means of convolutional codes [3, 7, 10, 15, 18]. Adapting
this class of codes to the context of networks gave rise to rank metric convolutional
codes and interestingly there have been little research on these codes, see [2, 12, 13,
28]. The work in [28] was pioneer in this direction by presenting the ï¬rst class of
rank metric convolutional codes together with a decoding algorithm able to deal with
errors, erasures and deviations. However, the results were only valid for unit memory
convolutional codes and in [2, 12] (see also the references therein) an interesting
and more general class of rank metric convolutional codes was introduced to cope
with network streaming applications. For a more general theoretical framework to
rank metric convolutional codes, see [16] and for more information on new investi-
gations on rank metric codes properties the reader is also referred to chapters â€œCodes
Endowed with the Rank Metricâ€ and â€œConstructions of Cyclic Subspace Codes and
Maximum Rank Distance Codesâ€.

Multi-shot Network Coding
93
In this multi-shot setting a new distance, called sum rank distance, was introduced
as a generalization of the rank distance used for one-shot network coding. This new
distance has proven to be the proper notion in order to deal with delay-free networks,
i.e., assuming that the natural delay in the transmission (due, for instance, to the
delay of the nodes) is so small that can be disregarded. In this work we show that
in order to handle networks with delays, a new metric needs to be introduced: the
generalized sum rank distance.
Finally, we note that in the last years others papers have also appeared dealing
with convolutional network coding using very different approaches [8, 22]. These
codes do not transmit over the operator channel and therefore are not equipped with
the rank metric.
In this chapter, we aim to provide a general overview of the area of multi-shot
codes for network coding and indicate some open problems and avenues for further
research. We will review the approaches and results proposed so far and present
some new alternatives such as a new metric that can be considered as an analog of
the column distance of Hamming convolutional codes. We note that by no means it
is a complete review as important issues such as decoding are not included.
Notation: Denote a ï¬nite ï¬eld with q elements by Fq. For a given basis of Fq M
viewed as an M vector space over Fq, any element of Fq M can be seen as a vector in
FM
q . Analogously, any vector x of length n over Fq M can be regarded as an element
X in FMÃ—n
q
, the set of M Ã— n matrices over Fq. We commit a harmless abuse of
notation and deï¬ne the rank of a vector x âˆˆFn
q M as the rank of x as an M Ã— n matrix
over Fq. If each column of X represents a packet of length M then so it does xi, for
i âˆˆ{1, . . . n}, where x = (x1, . . . , xn). Throughout the paper we denote the vectors
in lower-case type whereas a matrix is identiï¬ed using upper-case type. We use them
interchangeably if no confusion arises.
2
Preliminaries
In order to state more precisely the results to be presented we introduce in this section
the necessary material and notation on standard theory of (one-shot) network coding
and convolutional codes.
2.1
One-Shot Network Coding
2.1.1
The Network Model
Let v âˆˆFn
q M (or equivalently V âˆˆFMÃ—n
q
) represents the n packets of length M to be
sent through the network at one time instance. We shall follow the approach proposed
in [11, 26] and consider the operator channel for one shot given by

94
D. Napp and F. Santana
x = vA + z,
(1)
where x âˆˆFn
q M represents the received packets, A âˆˆFnÃ—n
q
is the rank deï¬ciency
channelmatrixand z âˆˆFn
q M istheadditiveerror.Theadversariesofthematrixchannel
(1) come as rank deï¬ciency of the channel matrix and as the additive error matrix.
The channel matrix A correspond to the overall linear transformations applied by the
network over the base ï¬eld Fq and it is known by the receiver (as the combinations
are carried over in the header bits of the packets). For perfect communications we
have that z = 0 and rank(A) = n, but failing and deactivated links may cause a rank
deï¬cient channel matrix. We call n âˆ’rank(A) the rank deï¬ciency of the channel.
2.1.2
Rank Metric
A rank metric code C is deï¬ned as any nonempty subset of FMÃ—n
q
. A natural metric
for matrix codes is induced by the distance measure drank(V, W) = rank(V âˆ’W),
where V, W âˆˆFMÃ—n
q
[11]. In the context of the rank metric, a matrix code is called
rank metric code.
The rank distance of a code C âŠ‚FMÃ—n
q
is deï¬ned as
drank(C) =
min
V,WâˆˆC, V Ì¸=W drank(V, W).
Consider linear codes over Fq M and use k for the dimension of the linear code over
Fq M. To simplify presentation we will assume that M â‰¥n. In this case, for linear
(n, k) rank metric codes over Fq M the following analog of the Singleton bound holds:
drank(C) â‰¤n âˆ’k + 1.
A code that achieves this bound is called Maximum Rank Distance (MRD).
Gabidulin codes are a well-known class of MRD codes [6], see also [5, 9].
Although rank metric codes in FMÃ—n
q
are usually constructed as block codes of
length n over the extension ï¬eld Fq M [11] a more general construction was considered
in [16]. Here, an (Ëœn Ã— M, Ëœk) rank metric code C âŠ‚FËœnÃ—M
q
of rate Ëœk/ËœnM < 1 is seen
as an image of a monomorphism Ï• : FËœk
q â†’FËœnÃ—M
q
(Ï• = Ïˆ â—¦Î³ is a composition of an
isomorphism Ïˆ and a monomorphism Î³ ):
Ï• :FËœk
q
Î³
âˆ’â†’
FËœnM
q
Ïˆ
âˆ’â†’
FËœnÃ—M
q
u 	âˆ’â†’v = uG 	âˆ’â†’V = Ïˆ(v)
where G âˆˆFËœkÃ—ËœnM
q
and [Vi j] = vi+Ëœn j with 0 â‰¤i < Ëœn and 0 â‰¤j < M.

Multi-shot Network Coding
95
In [16, Theorem 3.1] the following upper bound on the rank distance of an (Ëœn Ã—
M, Ëœk) linear rank metric code was presented
drank(C) â‰¤Ëœn âˆ’
 Ëœk âˆ’1
M

= Ëœn âˆ’
 Ëœk
M

+ 1.
2.2
Convolutional Codes
As opposed to block codes, convolutional encoders take a stream of information
bits and converts it into a stream of transmitted bits (by means of shift registers) and
therefore they are very suitable for streaming applications. Mathematically speaking,
a convolutional code C of rate k/n is an Fq M[D]-submodule of Fq M[D]n of rank k.
A full row rank matrix G(D) âˆˆFq M[D]kÃ—n with the property that
C = imFqM [D]G(D) =

u(D)G(D) | u(D) âˆˆFk
q M[D]

,
is called a generator matrix. The degree Î´ of a convolutional code C is the maximum
of the degrees of the determinants of the k Ã— k sub-matrices of one, and hence any,
generator matrix of C.
A rate k/n code C with degree Î´ is called an (n, k, Î´)-convolutional code [15].
An (n, k) block code is an (n, k, Î´) convolutional code with Î´ = 0.
We say that a generator matrix G(D) is basic (see, e.g., [23, 25]) if it has a
polynomial right inverse.1
Let wt(vi) be the number of the nonzero components of a vector vi âˆˆFn
q M and
wt(v(D)) the Hamming weight of a polynomial vector v(D) = 
iâˆˆN
vi Di deï¬ned as
wt(v(D)) = 
iâˆˆN
wt(vi).
An important distance measure for a convolutional code C is its free distance or
Hamming distance dH(C) deï¬ned as
dH(C) = min {wt(v(D)) | v(D) âˆˆC and v(D) Ì¸= 0} .
Let v[0, j](D) = v0 + v1D + Â· Â· Â· + v j D j be the jth truncation of the codeword
v(D) = 
iâˆˆN
vi Di âˆˆC.
1Using a basic generator matrix it allows to avoid catastrophic situations in which a sequence u(D)
with an inï¬nite number of nonzero coefï¬cients can be encoded into a sequence v(D) with a ï¬nite
number of nonzero coefï¬cients; this case would decode ï¬nitely many errors on the received code
sequence into inï¬nitely many errors when recovering the original information sequence.

96
D. Napp and F. Santana
Another important distance measure for a convolutional code C is the jth column
distance dc
j(C), given by the expression
d j
H(C) = min
	
wt(v[0, j](D)) | v(D) âˆˆC and v0 Ì¸= 0

.
This notion is related to the free distance dH(C) in the following way
dH(C) = lim
jâ†’âˆd j
H(C).
3
Multi-shot Network Coding
In this section we explain how to extend the classical theory of (one-shot) network
coding to the context of multi-shot network coding. In fact, this is possible as each
packet carries a label identifying the shot (or generation) to which it corresponds.
Despite the little research in the area, this possibility was already observed in the
seminal papers [11, 26].
3.1
Encoder and Decoder
The transmitter receives at each time instance t a source packet ut âˆˆFk
q M (constituted
by a set of k packets) and a channel packet vt âˆˆFn
q M (constituted by a set of n packets)
is constructed using not only ut but also previous source packets u0, . . . , utâˆ’1.
A channel packet vt is sent through the network at each shot (time instance) t.
The receiver collects the packets xt as they arrive causally and tries to infer vt from
(x0, . . . , xt).
3.2
Channel Model
Following the operator channel in (1) at each shot t the received packets xt âˆˆFn
q M are
constituted by corrupted packets z and linear combinations of the packets of vt and,
if there is delay in the transmission, also of combinations of the previous packets
v0, . . . , vtâˆ’1. Hence, we have
x[0, j] = v[0, j] A[0, j] + z
(2)
where x[0, j]=(x1, x2, . . . , x j), v[0, j]=(v0, v1, . . . v j) âˆˆFn( j+1)
q M
, A[0, j]âˆˆFn( j+1)Ã—n( j+1)
q
is a block upper triangular truncated channel matrix and z âˆˆFn( j+1)
q M
the additive

Multi-shot Network Coding
97
error. So far this channel model has not been proposed nor addressed in the literature
in this generality and only the delay-free case has been considered, see [12] and
reference therein. In the delay-free case only combinations of packets of vt arrive
at time instance t and not of packets of vi, i < t and therefore in this case the rank
deï¬ciency matrix A[0, j] is a block diagonal matrix.
3.3
Distances
The sum rank distance is the distance that has been widely considered for multi-
shot network coding and can be seen as the analog of the rank distance for one-shot
network coding. This distance was ï¬rst introduced in [20] under the name of extended
rank distance and is deï¬ne as follows.
Let v = (v0, . . . , vt) and w = (w0, . . . , wt) be two t-tuples of vectors in Fn
q M. The
sum rank distance (SRD) between them is
dSR(v, w) =
t
i=0
rank(vi âˆ’wi).
Since the rank distance is a metric so it is the SRD and is obviously upper bound by
dSR(v, w) â‰¤(t + 1)(n âˆ’k + 1).
As we will see below, the SRD is a metric that can be used to fully characterize the
error-correctingcapabilitiesofmulti-shotcodesinthecontextofdelay-freenetworks.
For the general case we propose the following distance,
dGR(v, w) = rank(v âˆ’w) = rank((v0, . . . , vt) âˆ’(w0, . . . , wt)).
This is a straightforward generalization of the rank distance for one-shot network
codes but it is new in the context of multi-shot network codes. We call it generalized
rank distance (GRD). In the next section we will show that it is the proper metric
to deal with network that allows delays. Still, further research needs to be done to
understand this less investigated situation.
In the next two sections we present some of the approaches to deal with multi-shot
network coding.
4
Rank Metric Convolutional Codes
In the context of rank metric convolutional codes two different settings have been
proposed. Similarly as in the block code case, rank metric convolutional codes have
been typically constructed over the extension ï¬eld Fq M. However, a more general

98
D. Napp and F. Santana
framework was introduced in [16], where a rank metric convolutional code can be
deï¬ned for any given rate over the base ï¬eld Fq.
4.1
General Framework
A rank metric convolutional code C âŠ‚FËœnÃ—M
q
is deï¬ned as the image of an homomor-
phism Ï• : Fq[D]Ëœk â†’Fq[D]ËœnÃ—M and written as a composition of a monomorphism
Î³ and an isomorphism Ïˆ:
Ï• : Fq[D]
Ëœk
Î³
âˆ’â†’Fq[D]ËœnM
Ïˆ
âˆ’â†’Fq[D]ËœnÃ—M
u(D) 	â†’v(D)=u(D)G(D) 	â†’V (D)
(3)
where G(D) âˆˆFËœkÃ—ËœnM
q
is a full row rank polynomial matrix, called generator matrix
of C, and V (D) = [Vi j[D]], such that Vi j(D) = vMi+ j(D).
The sum rank distance of a rank metric convolutional code C is deï¬ned as
dSR(C) =
min
V (D),U(D)âˆˆC,V (D)Ì¸=U(D) dSR(V (D),U(D))
=
min
0Ì¸=V (D)âˆˆCrank

V (D)

.
In the next theorem authors establish the Singleton-like bound for rank metric
convolutional codes.
Theorem 1 ([16, Theorem 4.1]) Let C be a (Ëœn Ã— M, Ëœk, Î´)-rank metric convolutional
code. Then the sum rank distance of C is upper bounded by
dsumrank(C) â‰¤Ëœn
Î´
Ëœk

+ 1

âˆ’
â¡
â¢â¢â¢
Ëœk(

Î´
Ëœk

+ 1) âˆ’Î´
M
â¤
â¥â¥â¥
+ 1.
(4)
4.2
Usual Approach
Consider from now on the extension ï¬eld Fq M instead of Fq. This leads to the fol-
lowing deï¬nitions.
For an (n, k, Î´)-convolutional code C and v(D) = v0 + v1D + v2D2 + Â· Â· Â· âˆˆC
we deï¬ne its free sum rank distance as
dSR(C) = min

iâ‰¥0
rank(vi) | v(D) âˆˆC and v(D) Ì¸= 0

,

Multi-shot Network Coding
99
and its column sum rank distance as
d j
SR(C) = min

j

i=0
rank(vi) | v(D) âˆˆC and v0 Ì¸= 0

.
Moreover, based in the GRD we introduce a new distance for convolutional codes,
the generalized column rank distance, as follows:
d j
GR(C) = min
	
rank(v0, . . . , v j) | v(D) âˆˆC and v0 Ì¸= 0

.
Adapting (4) to the deï¬nitions considered in this paper, this bound reads as fol-
lows:
dSR(C) â‰¤(n âˆ’k)
Î´
k

+ 1

+ Î´ + 1.
(5)
Note that this bound coincides with the so-called generalized Singleton bound of
(Hamming) (n, k, Î´)-convolutional codes [21, 24]. Thus, the bound (5) could be
also derived from the fact that the rank distance is upper bounded by the Hamming
distance [6]. The problem of existence and construction of rank metric convolutional
codes whose free rank distance achieves the bound (5) remains open.
For the column SRD the following upper bound was presented in [14]:
d j
SR(C) â‰¤(n âˆ’k)( j + 1) + 1,
and moreover,

d j
SR(C) = (n âˆ’k)( j + 1) + 1

â‡’

di
SR(C) = (n âˆ’k)(i + 1) + 1 for i = 0, . . . , j

.
In [28], concrete decoding algorithms for unit memory rank metric convolutional
codes were presented using another distance, namely the active rank distance. How-
ever, in [14], it was shown that this metric fails to determine the error-correcting
capabilities of rank metric convolutional codes with arbitrary memory and the col-
umn SRD needs to be considered. In fact, necessary and sufï¬cient conditions were
inferred to recover rank deï¬ciencies within a given time interval in delay-free net-
works when no errors occur (i.e., when z = 0 in (2)).
Theorem 2 ([14, Theorem 2]) Let C be a (n, k, Î´) rank metric convolutional code
and v(D) = v0 + v1D + Â· Â· Â· âˆˆC with v0 Ì¸= 0. Assume a delay-free transmission
and let A[0,T ] = diag(A0, . . . , AT ) represent the block diagonal truncated channel
matrix with Ai âˆˆFnÃ—n
q
, i.e., x[0,T ] = v[0,T ]A[0,T ] is the received set of packets with
xi = vi Ai, i = 0, 1, . . . , T . Note that in this case rank(A[0,T ]) = T
j=0 rank(A j).
Then, we can recover v0 if

100
D. Napp and F. Santana
dT
SR(C) > n(T + 1) âˆ’rank(A[0,T ]).
(6)
Theorem 2 illustrates how the column SRD can characterize the rank deï¬ciency
correcting capabilities of a rank metric convolutional code in delay-free networks
within a time interval. The more column SRD a convolutional codes has the better
is its rank deï¬ciencies correcting capabilities.
Constructive constructions of convolutional codes having maximum column SRD
proï¬le were also presented in [14] using a superregular matrix derived in [1]. These
constructions are not optimal as they require very large ï¬nite ï¬elds. The problem of
deriving optimal constructions remains an interesting open problem for research.
Motivated by streaming applications, rank metric convolutional codes tailor-made
to cope with burst of rank deï¬ciency networks where studied in [13]. This can be
considered a generalization of the theory of burst erasure convolutional codes, from
a Hamming context to a network context. Concrete constructions of optimal rank
metric convolutional codes in this setting are not known yet.
The following example illustrates that, in the case the network has delays in the
transmission of packets, the previous theorem fails to characterize the rank deï¬ciency
correcting capability of C.
Example 1 Let G(D) = G0 + G1D âˆˆF26[D]2Ã—3 be a generator matrix of the con-
volutional code C âŠ‚F26[D]3, Î± a primitive element of F26 and
G0 =
1 0 0
1 Î± Î±2

, G1 =
 0
1
0
Î±3 Î±4 Î±5

.
It is easy to see that d1
SR(C) = 2 and that there exists a v(D) âˆˆC such that v[0,1] =
(1, 0, 0 | 0, 1, 0) âˆˆF6
26. Theorem 2 says that we can recover v0 if the 1th column SRD
of C is larger than the rank deï¬ciency of a delay-free channel in the window [0, 1], i.e.,
ifn(T + 1) âˆ’rank(A[0,T ]) = 6 âˆ’rank(A[0,T ]) â‰¤1orequivalently,ifrank(A[0,1]) â‰¥
5. However, in presence of delays in the network this does not necessarily hold. Take
A =
â›
âœâœâœâœâœâœâ
0 0 0 0 âˆ’1 0
0 1 0 0 0 0
0 0 1 0 0 0
0 0 0 1
0 0
0 0 0 0
1 0
0 0 0 0
0 1
â
âŸâŸâŸâŸâŸâŸâ 
âˆˆF6Ã—6
2
that has rank equal to 5 and yields v[0,1] A[0,1] = 0, i.e., v[0,1] is indistinguishable from
the zero sequence and therefore cannot be corrected.
The next result can be considered the analog of Theorem 2 for the general case in
which the network admits delay in the transmission.
Theorem 3 Let C be a (n, k, Î´) rank metric convolutional code, v(D) âˆˆC and A[0,T ]
be the truncated channel matrix. Then, we can recover v[0,T ] if

Multi-shot Network Coding
101
dT
GR(C) > n(T + 1) âˆ’rank(A[0,T ]).
(7)
Proof Let x[0,T ] = v[0,T ]A[0,T ]. Due to the linearity of the code it is enough to show
that all output channel sequence are distinguishable from the zero sequence, i.e.,
we need to prove that v[0,T ]A[0,T ] = 0 is impossible if rank(A[0,T ]) satisï¬es (7).
It is easy to see that rank(v[0,T ]) â‰¤n(T + 1) âˆ’rank(A[0,T ]). Using this, together
with assumption (7), it follows that rank(v[0,T ]) < dT
GR(C) which is impossible by
deï¬nition of dT
GR(C).
5
Concatenation Codes
In this section we brieï¬‚y comment on another alternative to construct multi-shot
codes: concatenated codes. A widely used class of concatenated codes in the Ham-
ming context is the one constituted by an inner convolutional code concatenated to
a outer block code (typically a Reed-Solomon code). The idea is that the Viterbi
decoder will clean up the channel by correcting most of the errors but will occa-
sionally output a burst of errors that will be handled by the Reed-Solomon code.
However, in the network coding context little is known about the decoding of rank
metric convolutional codes. Next, we present a class of concatenated codes obtained
by the concatenation of a Hamming metric outer convolutional code and a rank metric
inner block code. The idea is that the rank metric code deals with the possible errors
occurring in the network during the transmission at each shot and either delivers the
correct symbol or an erasure to the convolutional code. The reason for choosing this
non-standard scheme is twofold: Firstly, we want to exploit the fact that convolu-
tional codes perform very efï¬ciently when dealing only with erasures. It was recently
shown in [4, 27] that using the ï¬‚exibility of selecting different sliding windows in
convolutional codes allows to recover (using elementary linear algebra) patterns of
erasures that cannot be decoded by an MDS block code of the same rate. Secondly,
we want to exploit the existing efï¬cient decoding algorithms for rank metric codes.
It was shown in [17] that despite the simple way in which these codes add complex
dependencies to data streams, this concatenation scheme can exploit the potential of
both codes to produce a code that can correct a large number of error patterns.
Let CI be a linear (nI, kI) rank metric code with (rank) distance drank(CI) and
generator matrix G I. Let Co be a (no, ko, Î´) convolutional code over the ï¬eld Fq MkI
with (Hamming) distance dH(Co), column distance d j
H(Co) and a basic generator
matrix Go(D). The concatenation scheme is explain as follows.
Let u(D) = u0 + u1D + u2D2 + Â· Â· Â· âˆˆFq MkI [D]ko be the information sequence
of source packets. Encode it through Go(D) âˆˆFq MkI [D]koÃ—no to obtain
v(D) = v0 + v1D + v2D2 + Â· Â· Â· = u(D)Go(D) âˆˆCo âŠ‚Fq MkI [D]no.

102
D. Napp and F. Santana
We write
vi = (v0
i , v1
i , . . . , vnoâˆ’1
i
), v j
i âˆˆFq MkI .
We identify v j
i âˆˆFq MkI with a vector Î½ j
i âˆˆFkI
q M (for a given basis of Fq MkI over
Fq M) and write
Î½i = (Î½0
i , Î½1
i , . . . , Î½noâˆ’1
i
) âˆˆ(FkI
q M)no
and therefore
Î½(D) = Î½0 + Î½1D + Î½2D2 + Â· Â· Â· âˆˆFkI
q M[D]no.
Finally, the codewords c(D) of the concatenated code C are obtained through the
matrix G I âˆˆFkI Ã—nI
q M
in the following way:
c j
i = Î½ j
i G I âˆˆFnI
q M,
ci = (c0
i , c1
i , . . . , cnoâˆ’1
i
) âˆˆ(FnI
q M)no
and
c(D) = c0 + c1D + c2D2 + Â· Â· Â· âˆˆC âŠ‚FnI
q M[D]no.
Next, we present some of the distance properties of the concatenated code C as
described above.
Theorem 4 ([17]) The sum rank distance of the concatenated code C satisï¬es
dSR(C) â‰¥dH(Co)drank(CI)
and
d j
SR(C) â‰¥d j
H(Co)drank(CI).
Moreover,
dSR(C) â‰¤(nonI âˆ’kokI)
 Î´
ko

+ 1

+ Î´kI + 1.
In [17], decoding algorithms were also presented together with some performance
evaluation. Simulation results showed that this class of codes perform very efï¬ciently
when transmitting streaming data over a network.
Finally, it is worth mentioning the pioneer work of NÃ³brega et al. in [19, 20]
where for the ï¬rst time the general ideas of multi-shot code for network coding were
laid out. Moreover, the authors presented an n-shot code (for a ï¬xed n) by means
of a concatenated code using a multilevel construction. Some interesting upper and
lower bounds were derived.

Multi-shot Network Coding
103
Acknowledgements The authors are supported by Portuguese funds through the CIDMA - Center
for Research and Development in Mathematics and Applications, and the Portuguese Foundation
for Science and Technology (FCT-FundaÃ§Ã£o para a CiÃªncia e a Tecnologia), within project PEst-
UID/MAT/04106/2013.
References
1. P. Almeida, D. Napp, R. Pinto, A new class of superregular matrices and MDP convolutional
codes. Linear Algebra Appl. 439(7), 2145â€“2157 (2013)
2. A. Badr, A. Khisti, Wai-Tian. Tan, J. Apostolopoulos, Layered constructions for low-delay
streaming codes. IEEE Trans. Inform. Theory (2013)
3. J.J. Climent, D. Napp, C. Perea, R. Pinto, Maximum distance separable 2D convolutional codes.
IEEE Trans. Inf. Theory 62(2), 669â€“680 (2016)
4. J.J. Climent, D. Napp, R. Pinto, R. SimËœoes, Decoding of 2D convolutional codes over the
erasure channel. Adv. Math. Commun. 10(1), 179â€“193 (2016)
5. Ph Delsarte, Bilinear forms over a ï¬nite ï¬eld, with applications to coding theory. J. Comb.
Theory Ser. A 25(3), 226â€“241 (1978)
6. Ã‰.M. Gabidulin, Theory of codes with maximum rank distance. Prob. Inf. Transm. 21, 1â€“12
(1985)
7. H. Gluesing-Luerssen, J. Rosenthal, R. Smarandache, Strongly MDS convolutional codes.
IEEE Trans. Inf. Theory 52(2), 584â€“598 (2006)
8. W. Guo, X. Shi, N. Cai, M. Medard, Localized dimension growth: a convolutional random
network coding approach to managing memory and decoding delay. IEEE Trans. Commun.
61(9), 3894â€“3905 (2013)
9. A. Horlemann-Trautmann, K. Marshall, New criteria for MRD and gabidulin codes and some
rank-metric code constructions, arXiv: 1507.08641
10. R. Johannesson, KSh Zigangirov, Fundamentals of Convolutional Coding (IEEE Press, New
York, 1999)
11. R. KÃ¶tter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579â€“3591 (2008)
12. R. Mahmood, Rank Metric Convolutional Codes with Applications in Network Streaming.
Master of applied science (2015)
13. R. Mahmood, A. Badr, A. Khisti, Streaming-codes for multicast over burst erasure channels.
IEEE Trans. Inf. Theory 61(8), 4181â€“4208 (2015)
14. R. Mahmood, A. Badr, A. Khisti, Convolutional codes with maximum column sum rank for
network streaming. IEEE Trans. Inf. Theory 62(6), 3039â€“3052 (2016)
15. R.J.McEliece,Thealgebraictheoryofconvolutionalcodes,inHandbookofCodingTheory,vol.
1, ed. by V. Pless, W.C. Huffman (Elsevier Science Publishers, Amsterdam, The Netherlands,
1998), pp. 1065â€“1138
16. D. Napp, R. Pinto, J. Rosenthal, P. Vettori, Rank metric convolutional codes, in Proceedings of
the 22nd International Symposium on Mathematical Theory of Network and Systems (MTNS)
(Minnesota, USA, 2016)
17. D. Napp, R. Pinto, V.R. Sidorenko, Concatenation of convolutional codes and rank metric
codes for multi-shot network coding. submitted to Des. Codes Cryptogr
18. D. Napp, R. Pinto, T. Toste, On MDS convolutional codes over Zpr (Designs, Codes and
Cryptography, 2016), pp. 1â€“14
19. R.W. NÃ³brega, B.F. Uchoa-Filho, Multishot codes for network coding: Bounds and a multilevel
construction, in 2009 IEEE International Symposium on Information Theory (Seoul, South
Korea, 2009), pp. 428â€“432
20. R.W. NÃ³brega, B.F. Uchoa-Filho, Multishot codes for network coding using rank-metric codes,
in Wireless Network Coding Conference (WiNC) (IEEE 2010), pp. 1â€“6

104
D. Napp and F. Santana
21. F. Pollara, R.J. McEliece, K. Abdel-Ghaffar, Finite-state codes. IEEE Trans. Inf. Theory 34(5),
1083â€“1089 (1988)
22. K. Prasad, B.S. Rajan, Network error correction for unit-delay, memory-free networks using
convolutional codes. in 2010 IEEE International Conference on Communications (ICC) (2010),
pp. 1 â€“6
23. J. Rosenthal, Connections between linear systems and convolutional codes, in Codes, Systems
and Graphical Models, IMA, vol. 123, ed. by B. Marcus, J. Rosenthal (Springer, 2001). pp.
39â€“66
24. J. Rosenthal, R. Smarandache, Maximum distance separable convolutional codes. Appl. Alge-
bra Eng. Comm. Comput. 10(1), 15â€“32 (1999)
25. J. Rosenthal, E.V. York, BCH convolutional codes. IEEE Trans. Autom. Control 45(6), 1833â€“
1844 (1999)
26. D. Silva, R. KÃ¶tter, F.R. Kschischang, A rank-metric approach to error control in random
network coding. IEEE Trans. Inf. Theory 54(9), 3951â€“3967 (2008)
27. V. Tomas, J. Rosenthal, R. Smarandache, Decoding of convolutional codes over the erasure
channel. IEEE Trans. Inf. Theory 58(1), 90â€“108 (2012)
28. A. Wachter-Zeh, M. Stinner, V. Sidorenko, Convolutional codes in rank metric with application
to random network coding. IEEE Trans. Inf. Theory 61(6), 3199â€“3213 (2015)

Part II
Finite Geometries and
Subspace Designs

Geometrical Aspects of Subspace Codes
Antonio Cossidente, Francesco Pavese and Leo Storme
Abstract Subspace codes are codes whose codewords are equal to subspaces of a
ï¬nite vector space V (n, q). Since the geometry of the subspaces of a ï¬nite vector
space V (n, q) is equivalent to the geometry of the subspaces of a projective space
PG(n âˆ’1, q), problems on subspace codes can be investigated by using geometri-
cal arguments. Here, we illustrate this approach by showing some recent results on
subspace codes, obtained via geometrical arguments. We discuss upper bounds on
the sizes of subspace codes, by showing the link between the Johnson bound and
the size of partial spreads in ï¬nite projective spaces. We present geometrical con-
structions of subspace codes, and we also focus on subspace codes constructed from
Maximum Rank Distance (MRD) codes. Here, we also present geometrical links of
MRD codes to exterior sets of Segre varieties. Our aim is to motivate researchers on
subspace codes to also consider geometrical arguments when investigating problems
on subspace codes.
1
Introduction
The ï¬nite projective space PG(n âˆ’1, q) of dimension n âˆ’1 over the ï¬nite ï¬eld Fq
of order q is constructed from the vector space V (n, q) of dimension n over the
ï¬nite ï¬eld Fq of order q in the following way: an i-dimensional projective subspace
A. Cossidente (B)
Dipartimento di Matematica e Informatica, UniversitÃ  della Basilicata,
Contrada Macchia Romana, 85100 Potenza, Italy
e-mail: antonio.cossidente@unibas.it
F. Pavese
Dipartimento di Meccanica, Matematica e Management, Politecnico di Bari, Via Orabona 4,
70125 Bari, Italy
e-mail: francesco.pavese@poliba.it
L. Storme
Department of Mathematics, Ghent University, Krijgslaan 281, 9000 Ghent, Belgium
e-mail: leo.storme@ugent.be
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_6
107

108
A. Cossidente et al.
of PG(n âˆ’1, q) is deï¬ned by an (i + 1)-dimensional subspace of the vector space
V (n, q).
R. KÃ¶tter and F. Kschischang [31] proved that a very good way of transmission in
networksisobtainedifsubspacecodes areused.Here,thecodewordsaresubspacesof
the n-dimensional vector space V (n, q) over the ï¬nite ï¬eld Fq of order q. To transmit
a codeword, i.e. a k-dimensional vector space, through the network, it is sufï¬cient
to transmit a basis of this k-dimensional vector space. But a k-dimensional subspace
has different bases. KÃ¶tter and Kschischang proved that the transmission can be
optimalized if the nodes in the network transmit linear combinations of the incoming
basis vectors of the k-dimensional subspace which represents the codeword.
The geometry of the subspaces of a vector space over a ï¬nite ï¬eld can be inves-
tigated in the setting of ï¬nite projective spaces, also called Galois geometries. The
three standard references [24â€“26] to Galois geometries contain a wealth of infor-
mation on Galois geometries. In Galois geometries, geometrical methods, and also
other methods, such as polynomial methods and links with other domains, can be
used to investigate a great variety of problems on substructures of these ï¬nite pro-
jective spaces. Since a subspace code precisely is a substructure of a ï¬nite projective
space, this setting has, and still is able, to provide many new interesting results on
subspace codes.
This article wishes to highlight this fact. We present some constructions of, and
results on, subspace codes, which, presently, are among the best results, and which
match results that are found via other techniques. We have concentrated on the
constructions and results which can illustrate in an optimal way the ideas which have
been used, and which show that Galois geometries and geometrical techniques are of
great value for the study of subspace codes. We hope via these examples to motivate
many researchers to also investigate problems on subspace codes via geometrical
techniques, and to help showing that the study of Galois geometries is not only of
purely theoretical importance, but also of practical importance.
We ï¬rst present the basic ideas on Galois geometries to ï¬x notations and proper-
ties. We then present these particular examples of results on subspace codes, obtained
via geometrical arguments.
2
Preliminaries
Let Fq be the ï¬nite ï¬eld of order q and let V (n, q) be the vector space of dimen-
sion n over Fq. The 1-dimensional subspaces of V (n, q) are called vector lines,
the 2-dimensional subspaces are called vector planes. The number of k-dimensional
subspaces of V (n, q) is the q-binomial coefï¬cient
n
k

q
= (qn âˆ’1)(qnâˆ’1 âˆ’1) Â· Â· Â· (qnâˆ’k+1 âˆ’1)
(qk âˆ’1)(qkâˆ’1 âˆ’1) Â· Â· Â· (q âˆ’1)
.

Geometrical Aspects of Subspace Codes
109
The number of k-dimensional subspaces containing a ï¬xed t-dimensional sub-
space, t â‰¤k, is
n âˆ’t
k âˆ’t

q
.
The subspace distance between subspaces U and W of V (n, q) is deï¬ned by
d(U, W) = dim(U + W) âˆ’dim(U âˆ©W).
AsubspacecodeC isanon-emptycollectionofsubspacesof V (n, q).Acodeword
is an element of C . The minimum distance of C is deï¬ned by
d(C ) := min{d(U, W) | U, W âˆˆC ,U Ì¸= W}.
A code C is called an (n, M, d)-subspace code if C consists of subspaces of
V (n, q), is of cardinality M, and has minimum distance d. The maximal number of
codewords in an (n, M, d)-code, deï¬ned over Fq, is denoted by Aq(n, d). A constant
dimension subspace code is a code with all codewords of the same dimension. If all
codewords of an (n, M, d)-code C are k-dimensional subspaces of V (n, q), then we
say that C is an (n, M, d, k)-subspace code. The maximum number of codewords
in an (n, M, d, k)-code, deï¬ned over Fq, is denoted by Aq(n, d, k).
2.1
Codes in Projective Spaces
We will investigate subspace codes in the projective setting.
The projective space PG(n, q) of projective dimension n over Fq is the lattice of
subspaces of V (n + 1, q) with respect to set inclusion. In this article, a k-space, 0 â‰¤
k â‰¤n, is a subspace PG(k, q) of PG(n, q) of projective dimension k. This means that
a projective k-space is deï¬ned by a (k + 1)-dimensional subspace of V (n + 1, q),
but we interpret the vector lines contained in this (k + 1)-dimensional subspace as 0-
dimensional objects, called projective points. The dimension k of a projective space
PG(k, q) is called the projective dimension of this subspace PG(k, q).
Thenumberofprojectivepointsofak-spaceis
k+1
1

q.Ani-dimensionalprojective
spacePG(i, q),i = 1, 2, 3, n âˆ’1,iscalledaprojectiveline,aprojectiveplane,asolid
or a hyperplane of PG(n, q), respectively.
Alternatively, PG(n, q) can be deï¬ned as a point-line geometry [15]. Let Î” be
a k-space of PG(n, q). If the subspaces of PG(n, q) of dimension k + 1 and k + 2,
containing Î”, are considered as new points and lines, with inclusion as incidence,
then they correspond to a projective geometry PG(n âˆ’k âˆ’1, q), called the quotient
geometry of Î”. We shall denote the quotient geometry of Î” as PG(n âˆ’k âˆ’1, q)Î”.
An m-space of PG(n, q) that contains Î” has projective dimension m âˆ’k âˆ’1 in
PG(n âˆ’k âˆ’1, q)Î”.

110
A. Cossidente et al.
To illustrate the close links between subspace codes and ï¬nite projective spaces,
we illustrate how the study of the Johnson bound immediately relates to the study
of a geometrical object in ï¬nite projective spaces, called a partial spread, which is
already investigated for many years in Galois geometries.
3
Johnson Bound and Partial Spreads in Finite
Projective Spaces
3.1
The Johnson Bound and Partial Spreads
Deï¬nition 1 A (k âˆ’1)-spread of PG(n âˆ’1, q) is a partitioning of the point set of
PG(n âˆ’1, q) in (k âˆ’1)-spaces.
A partial (k âˆ’1)-spread S of PG(n âˆ’1, q) is a set of pairwise disjoint (k âˆ’1)-
spaces of PG(n âˆ’1, q).
A (k âˆ’1)-spread of PG(n âˆ’1, q) exists if and only if n â‰¡0 (mod k). Then, the
size of a (k âˆ’1)-spread is
n
1

q/
k
1

q.
Partial spreads are closely related to subspace codes. A (k âˆ’1)-spread of PG(n âˆ’
1, q) is a maximal (n, M, 2k, k)-code of cardinality
M = Aq(n, 2k, k) =
n
1

q
/
k
1

q
,
when n â‰¡0
(mod k).
A partial (k âˆ’1)-spread of PG(n âˆ’1, q), n â‰¡0 (mod k), of size M is also an
(n, M, 2k, k)-code, not necessarily of the maximal size.
When k does not divide n, the following lower bound on Aq(n, 2k, k) is known.
Theorem 1 ([6, 20]) Let n â‰¡r (mod k), 0 â‰¤r â‰¤k âˆ’1. Then for all q, we have
Aq(n, 2k, k) â‰¥qn âˆ’qk(qr âˆ’1) âˆ’1
qk âˆ’1
.
The following upper bound on Aq(n, 2k, k) is known.
Theorem 2 ([5, 17]) Let S be a partial t-spread in PG(d, q), where d = k(t +
1) âˆ’1 + r, 1 â‰¤r â‰¤t.
Let |S | = qr Â· qk(t+1)âˆ’1
qt+1âˆ’1 âˆ’s. Then
â€¢ s â‰¥q âˆ’1.
â€¢ s > qrâˆ’1
2
âˆ’q2râˆ’tâˆ’1
5
.

Geometrical Aspects of Subspace Codes
111
Since Theorem1 states that there exists an example with s = qr âˆ’1, we know
that
Aq(n, 2k, k) = qn âˆ’qk(qr âˆ’1) âˆ’1
qk âˆ’1
,
when r = 1.
For many years, it was conjectured that
Aq(n, 2k, k) = qn âˆ’qk(qr âˆ’1) âˆ’1
qk âˆ’1
,
so the lower bound of Theorem1 is sharp.
However, El-Zanati et al. [18] found a counter example: there is a partial 3-spread
in the ï¬nite vector space V (8, 2), which corresponds to a partial 2-spread in PG(7, 2),
of size 34, but there exists no example of size 35. So A2(8, 6, 3) = 34.
But, very recently, a major breakthrough has been made by E. NË˜astase and P.
Sissokho [37].
Theorem 3 ([37]) Let r â‰¡n (mod k). Then, if
k > qr âˆ’1
q âˆ’1 ,
the maximal size for a partial (k âˆ’1)-spread in PG(n âˆ’1, q) is equal to
qnâˆ’qk(qrâˆ’1)âˆ’1
qkâˆ’1
.
Consequently, if k > qrâˆ’1
qâˆ’1 , then
Aq(n, 2k, k) = qn âˆ’qk(qr âˆ’1) âˆ’1
qk âˆ’1
.
Similar results for q = 2 were recently also proven by Kurz [32].
We now make the link between the problem of the largest size of partial spreads
in ï¬nite projective spaces to the Johnson bound on subspace codes.
In general, in the terminology of projective geometry, an (n, M, d, k)-code C
can be viewed as a set of (k âˆ’1)-spaces of PG(n âˆ’1, q) of cardinality M with the
following property: t = k âˆ’d/2 + 1 is the smallest integer such that every (t âˆ’1)-
space of PG(n âˆ’1, q) is contained in at most one (k âˆ’1)-space of C . Equivalently,
any two distinct codewords of C intersect in at most a (t âˆ’2)-space. Hence, (k âˆ’1)-
spacesofC througha(t âˆ’2)-spaceÎ”formapartial(k âˆ’t)-spreadCÎ” inthequotient
geometry PG(n âˆ’t, q)Î” of Î”. Note that CÎ” is an (n âˆ’k + d/2, Mâ€², d, d/2)-code,
called the quotient code of Î”. Using this observation, the following upper bound
on the size of a constant dimension code was obtained. This upper bound is known
under the name Johnson bound.

112
A. Cossidente et al.
Theorem 4 (Johnson bound [20]) The maximal size Aq(n, d, k) of an (n, M, d, k)-
code satisï¬es the upper bound
Aq(n, d, k) â‰¤
 n
tâˆ’1

q
 k
tâˆ’1

q
Aq(n âˆ’k + d/2, d, d/2),
where t = k âˆ’d/2 + 1 and where Aq(n âˆ’k + d/2, d, d/2) is the maximal size of
a partial (d/2 âˆ’1)-spread in PG(n âˆ’k + d/2 âˆ’1, q).
Corollary 1 The maximal size Aq(n, d, k) of an (n, M, d, k)-code, with n âˆ’k +
d/2 â‰¡0 (mod d/2), satisï¬es the upper bound
Aq(n, d, k) â‰¤
n
t

q
k
t

q
.
The main problem is whether there exist constant dimension codes meeting the
Johnson bound.
For d = 2k, this is the classical partial spreads problem, mentioned above. This
shows that a particular problem on subspace codes is completely equivalent to a
geometrical problem, already for decades of interest and of importance in Galois
geometries. This is one of the classical examples of the close links between the
theory of subspace codes and the theory of Galois geometries.
For more detailed information on partial spreads in ï¬nite projective spaces, we
refer to Chap.â€œPartial Spreads and Vector Space Partitionsâ€ of this Springer special
volume.
3.2
Subspace Codes from Maximum Rank Distance Codes
Rank distance codes were introduced by Delsarte [14] and are suitable for error
correction in the case where the network topology and the underlying network code
are known (the coherent case).
The set MmÃ—n(q) of m Ã— n matrices over the ï¬nite ï¬eld Fq forms a metric space
with respect to the rank distance, deï¬ned by
dr(A, B) = rk(A âˆ’B).
The maximum size of a code of minimum distance d, 1 â‰¤d â‰¤min{m, n}, in
(MmÃ—n(q), dr) is qn(mâˆ’d+1) for m â‰¤n and qm(nâˆ’d+1) for m â‰¥n. A code A âŠ‚
MmÃ—n(q) attaining this bound is said to be an (m, n, k)q maximum rank distance
code (MRD code), where k = m âˆ’d + 1 for m â‰¤n and k = n âˆ’d + 1 for m â‰¥n. A
rank distance code A is called Fqâ€“linear if A is a subspace of MmÃ—n(q) considered
as a vector space over Fq. We can always assume that m â‰¤n.

Geometrical Aspects of Subspace Codes
113
In [40], the authors introduced a method, called the lifting process, to construct
a constant dimension subspace code from a maximum rank distance code. Let A be
an m Ã— n matrix over Fq, and let Im be the m Ã— m identity matrix. The rows of the
m Ã— (n + m)matrix(Im|A)canbeviewedascoordinatesofpointsingeneralposition
of an (m âˆ’1)â€“dimensional projective space of PG(n + m âˆ’1, q). This subspace is
denoted by L(A). Hence, the matrix A can be lifted to a subspace L(A). Let C be
an (m, n, k)q MRD code, and let A1 and A2 be two distinct matrices of C . Since
rk(A1 âˆ’A2) â‰¥d, we have that
rk
 Im A1
Im A2

= m + rk(A1 âˆ’A2) â‰¥m + d.
Hence, L(A1) meets L(A2) in at most an (m âˆ’d âˆ’1)â€“dimensional projective space
and {L(A) | A âˆˆC } is an (n + m, qnk, 2d, m) subspace code. A constant dimen-
sion subspace code such that all of its codewords are lifted codewords of an MRD
code is called a lifted MRD code.
This lifting process implies the following result.
Theorem 5 ([40])
Aq(n + m, 2d, m) â‰¥qn(mâˆ’d+1).
Although the size of a lifted MRD code equals the highest power of q in the
Johnson bound, it is known that it is not maximal and it can be extended to a larger
subspace code.
Several examples of linear (n, n, k)q MRD codes are known to exist (Gabidulin
codes [14, 22], twisted Gabidulin codes [39], generalized twisted Gabidulin
codes [35]).
3.3
Planes in PG(5, q) Pairwise Intersecting
in at Most a Point
Let us consider an other case for the Johnson bound.
Honold, Kiermaier, and Kurz proved that A2(6, 4, 3) = 77 and there are exactly
ï¬ve codes of size 77 [27].
Geometrically, this means that, in the projective space PG(5, 2), a set of projective
planes pairwise intersecting in at most one projective point, has size at most 77, and
there are exactly ï¬ve different examples of such sets of 77 planes.
Honold, Kiermaier, and Kurz managed to extend one of the ï¬ve examples to an
inï¬nite class of q6 + 2q2 + 2q + 1 planes in PG(5, q), pairwise intersecting in at
most one point.
Alternatively, Cossidente and Pavese [12] also constructed an inï¬nite class ofq6 +
2q2 + 2q + 1 planes in PG(5, q), pairwise intersecting in at most one point. We wish
to highlight this construction since it relies on many nice geometrical properties and

114
A. Cossidente et al.
results. This includes bundles of conics in a plane of PG(3, q), hyperbolic quadrics
in PG(3, q), and the Klein correspondence between the lines of PG(3, q) and the
Klein quadric Q+(5, q) of PG(5, q).
We now present the construction of a set of q6 + 2q2 + 2q + 1 planes in PG(5, q),
pairwise intersecting in at most one point, by Cossidente and Pavese. This leads to
the result
Theorem 6
q6 + 2q2 + 2q + 1 â‰¤Aq(6, 4, 3) â‰¤(q3 + 1)2.
TheconstructionofCossidenteandPaveseusestheKleincorrespondencebetween
lines of PG(3, q) and their PlÃ¼cker coordinates on the Klein quadric Q+(5, q) in
PG(5, q) [24, Sect.15.4].
We ï¬rst present the hyperbolic quadric Q+(3, q) of PG(3, q). This is the quadric
with standard equation Q+(3, q) : X0X2 âˆ’X1X3 = 0.
This quadric contains two particular sets of q + 1 lines, which play a symmetrical
role, and which are called a regulus R and its opposite regulus RâŠ¥.
Lines of a regulus are pairwise disjoint, while the lines of one regulus intersect
the lines of the opposite regulus in one point. Figure1 presents a drawing of a 3-
dimensional hyperbolic quadric, with three lines of every regulus.
We now introduce the basic facts of the Klein correspondence which plays a
central role in the construction of Cossidente and Pavese [24].
Deï¬nition 2 Consider a line â„“in PG(3, q) and suppose that y(y0, y1, y2, y3) and
z(z0, z1, z2, z3) are different points of â„“. Let pi j = yiz j âˆ’y jzi.
Fig. 1 The hyperbolic
quadric Q+(3, q)

Geometrical Aspects of Subspace Codes
115
Then the PlÃ¼cker coordinates of the line â„“are the 6-tuple (p01, p02, p03,
p23, p31, p12).
The PlÃ¼cker coordinates of a line â„“in PG(3, q) are well-deï¬ned. However, not
every 6-tuple is PlÃ¼cker coordinates of a line â„“of PG(3, q).
Theorem 7 The 6-tuple (p01, p02, p03, p23, p31, p12) is PlÃ¼cker coordinates of a
line â„“of PG(3, q) if and only if
p01 p23 + p02 p31 + p03 p12 = 0.
(1)
The set of points Q of PG(5, q), deï¬ned by the equation p01 p23 + p02 p31 +
p03 p12 = 0, is a hyperbolic quadric Q+(5, q) of PG(5, q), called the Klein quadric.
This hyperbolic quadric Q+(5, q) contains points, lines and planes. The planes of
the hyperbolic quadric Q+(5, q) are also called the generators of Q+(5, q). The link
with the corresponding sets of lines in PG(3, q) is deï¬ned in the following list [24,
Sect.15.4].
â€¢ Point of PG(5, q) on the Klein quadric deï¬nes a line â„“of PG(3, q).
â€¢ Line of PG(5, q) on the Klein quadric deï¬nes the set of q + 1 lines of PG(3, q)
through a ï¬xed point P in a ï¬xed plane Ï€.
â€¢ Planes of PG(5, q) on the Klein quadric deï¬ne either the set of all lines of PG(3, q)
through a ï¬xed point P, or the set of all lines of PG(3, q) lying in a ï¬xed plane Ï€.
A Greek plane is a plane contained in the Klein quadric, deï¬ning the lines of
PG(3, q) lying in a ï¬xed plane Ï€, and a Latin plane is a plane contained in the
Klein quadric, deï¬ning the lines of PG(3, q) through a ï¬xed point P.
â€¢ Greek planes, respectively Latin planes, on the Klein quadric pairwise intersect
in one point, while a Latin and a Greek plane either are skew to each other, or
intersect in a line.
â€¢ Consider a plane Ï€ of PG(5, q), intersecting the Klein quadric in a conic C. This
conic corresponds to a regulus R of a hyperbolic quadric Q+(3, q) in PG(3, q).
The polar plane Ï€âŠ¥of Ï€ with respect to the Klein quadric also intersects the Klein
quadric in a conic CâŠ¥, corresponding to the opposite regulus RâŠ¥of R of this
hyperbolic quadric Q+(3, q) in PG(3, q).
These two polar planes Ï€ and Ï€âŠ¥are skew to each other in PG(5, q).
In the preceding description, we recognize already the fact that the set of planes
of the Klein quadric can be partitioned into two equivalence classes. Two planes of
the Klein quadric are called equivalent when they are equal or intersect in a point
[26, p. 20]. This deï¬nition leads to an equivalence relation on the set of planes of
the Klein quadric, having two distinct equivalence classes. They are in the preceding
description respectively the class of the Greek planes and the class of the Latin planes.
The equivalence classes of the generators of the Klein quadric are also sometimes
called the systems of generators.

116
A. Cossidente et al.
The construction of Cossidente and Pavese of a set of q6 + 2q2 + 2q + 1 planes
of PG(5, q), pairwise intersecting in at most one point, starts by considering speciï¬c
structures in PG(3, q), and then transferring, via the Klein correspondence, to planes
in PG(5, q).
â€¢ Consider a ï¬xed plane Ï€ of PG(3, q).
â€¢ A bundle of conics B in this plane Ï€ is a set of q2 + q + 1 conics pairwise
intersecting in one point.
â€¢ Each conic of the bundle B is contained in q3(q âˆ’1)/2 hyperbolic quadrics
Q+(3, q) of PG(3, q).
This leads to (q6 âˆ’q3)/2 hyperbolic quadrics Q+(3, q) having q6 âˆ’q3 reguli,
and, by applying the Klein correspondence, to a set L1 of q6 âˆ’q3 planes of PG(5, q),
pairwise intersecting in at most one point.
Figure2 shows a drawing of the plane Ï€, together with two conics of the bundle
of conics B in this plane Ï€, and one hyperbolic quadric passing through each one
of these two conics.
In the second step of the construction of Cossidente and Pavese, consider this
ï¬xed plane Ï€ in PG(3, q), containing the bundle of conics B. This plane Ï€ deï¬nes
a Greek plane Î  on the Klein quadric.
Add the other q3 + q2 + q Greek planes on the Klein quadric to the set L1. This
leads to a larger set L2 of q6 + q2 + q planes of PG(5, q), pairwise intersecting in
at most one point.
In the third step, consider again the Greek plane Î  in PG(5, q), corresponding to
the plane Ï€ in PG(3, q), containing the bundle of conics B.
Fig. 2 The bundle of conics
and the hyperbolic quadrics
passing through the conics of
the bundle

Geometrical Aspects of Subspace Codes
117
Each line r of Î  lies in q âˆ’1 planes of PG(5, q) only intersecting the Klein
quadric in the line r.
For every line r of Î , select one such plane, and add it to the set L2. This gives
the desired set L of q6 + 2q2 + 2q + 1 planes of PG(5, q), pairwise intersecting in
at most one point.
3.4
Planes in PG(5, q) Pairwise Intersecting
in at Most a Point (Alternative Construction)
Let Ui = (0, . . . , 0, 1, 0, . . . , 0), i = 0, . . . , 5, be the vector with the one in the
(i + 1)-th position.
Let C be a linear (3, 3, 2)q MRD code. Let L = {L(A) | A âˆˆC } be the lifted
MRD code obtained by lifting the elements of C . Then L consists of q6 planes of
PG(5, q) mutually intersecting in at most a point. In particular, members of L are
disjoint from the special plane T = âŸ¨U3,U4,U5âŸ©and therefore every line covered
by an element of L is disjoint from T . Moreover, from [27, Lemma6], every line of
PG(5, q) disjoint from T is covered by a member of L exactly once. We denote by
T â€² the plane âŸ¨U0,U1,U2âŸ©. Since the zero matrix belongs to C , we have that T â€² âˆˆL .
Let S denote the set of q3 3 Ã— 3 skewâ€“symmetric matrices over Fq. Here, for q
even, the diagonal elements of a 3 Ã— 3â€“skew symmetric matrix are zeros. Since there
exists a linear (3, 3, 2)q MRD code containing S , we may assume that S âŠ‚C , see
[10, Proposition3.1].
Now, we introduce the nonâ€“degenerate hyperbolic quadric Q of PG(5, q) having
the following equation:
X0X3 + X1X4 + X2X5 = 0.
The planes T and T â€² are generators of Q. They belong to different systems of
generators of Q. Let M , M â€² be the system of generators of Q containing T , T â€²,
respectively.
It can be seen that if A is a 3 Ã— 3 skewâ€“symmetric matrix over Fq, then L(A) is
a generator of Q disjoint from T .
Remark 1 Since the number of generators of Q disjoint from T equals q3, we have
that each such a plane is of the form L(A), for some A âˆˆS . Note that, if A âˆˆS ,
then L(A) belongs to the system M â€² of generators containing T â€².
Let L â€² be the set consisting of the q3 planes obtained by lifting the matrices
of S . Then, the set (L \ L â€²) âˆªM consists of q6 + q2 + q + 1 planes mutually
intersecting in at most a point.
Corresponding to a line r of T , there corresponds a set Tr of q âˆ’1 planes of
PG(5, q) meeting Q exactly in r. Varying the line r over the line set of T and
choosing one of the planes in Tr, we obtain a set T of q2 + q + 1 planes mutually
intersecting in at most one point.

118
A. Cossidente et al.
Finally, we have that the set (L \ L â€²) âˆªM âˆªT is a set of q6 + 2q2 + 2q + 1
planes mutually intersecting in at most a point.
3.5
Solids in PG(7, q) Pairwise Intersecting in at Most a Line
Let C be a linear (4, 4, 3)q MRD code. Let L1 = {L(A) | A âˆˆC } be the lifted
MRD code obtained by lifting the elements of C . Then L1 consists of q12 solids
of PG(7, q) mutually intersecting in at most a line. In particular, members of L1
are disjoint from the special solid T = âŸ¨U4,U5,U6,U7âŸ©and therefore every plane
covered by an element of L1 is disjoint from T . Moreover, from [27, Lemma6],
every plane of PG(7, q) disjoint from T is covered by a member of L1 exactly once.
We denote by T â€² the solid âŸ¨U0,U1,U2,U3âŸ©. Since the zero matrix belongs to C , we
have that T â€² âˆˆL1.
Let Cr âŠ‚C be the set consisting of all the matrices of C having rank r, with
2 â‰¤r â‰¤4. From [22], it is known that a linear (4, 4, 3)q MRD code contains (q4 âˆ’
1)(q2 + 1)(q2 + q + 1) matrices of rank 2, (q4 âˆ’1)(q2 + 1)(q + 1)(q4 âˆ’q2 âˆ’q)
matrices of rank 3, and (q4 âˆ’1)q3(q5 âˆ’q4 âˆ’q3 + q + 1) matrices of rank 4.
Let A be an element of C2. As in Sect.3.2, the rows of the 4 Ã— 8 matrix (A|I4)
can be viewed as coordinates of points in general position of a solid, say Lâ€²(A),
of PG(7, q). The solid Lâ€²(A) is disjoint from T â€² and meets T in a line. Let L2 =
{Lâ€²(A) | A âˆˆC2} be the set of solids obtained from the elements of C2. Then we
have that L1 âˆªL2 is a set of q12 + (q4 âˆ’1)(q2 + 1)(q2 + q + 1) solids of PG(7, q)
mutually intersecting in at most a line.
Let S denote the set of q6 4 Ã— 4 skewâ€“symmetric matrices over Fq. Here, for q
even, the diagonal elements of a 4 Ã— 4â€“skew symmetric matrix are zeros. Since there
exists a linear (4, 4, 3)q MRD code containing S , we may assume that S âŠ‚C , see
[10, Proposition3.1].
Now, we introduce the non-degenerate hyperbolic quadric Q1 of PG(7, q) having
the following equation:
X0X4 + X1X5 + X2X6 + X3X7 = 0.
Here again, the solids (generators) of the hyperbolic quadric Q1 of PG(7, q) are
partitioned into two equivalence classes M1 and M â€²
1 [26]. Two generators Î 1 and
Î 2 are called equivalent when they are equal or intersect in a line. This relation is
again an equivalence relation, having two equivalence classes M1 and M â€²
1 on the set
of generators of the hyperbolic quadric Q1 of PG(7, q).
The solids T and T â€² are generators of Q1. They belong to the same system of
generators of Q1, say M1. Let D(X) and I (X) denote the set of generators in M1
disjoint from the solid X or meeting nonâ€“trivially X, respectively. Then
M1 = D(T ) âˆª(D(T â€²) âˆ©I (T )) âˆª(I (T â€²) âˆ©I (T )),
where D(T ), D(T â€²) âˆ©I (T ) and I (T â€²) âˆ©I (T ) are trivially intersecting sets.

Geometrical Aspects of Subspace Codes
119
It can be seen that if A is a 4 Ã— 4 skewâ€“symmetric matrix over Fq, then L(A)
(resp. Lâ€²(A)) is a generator of Q1 disjoint from T (resp. T â€²).
Remark 2 Since the number of generators of Q1 disjoint from T equals q6 [30,
Lemma3], we have that each such a solid is of the form L(A), for some A âˆˆS .
Note that, if A âˆˆS , then L(A) belongs to M1.
On the other hand, a solid Lâ€²(A) in D(T â€²) is disjoint from T if and only if A
is a skewâ€“symmetric matrix of rank 4. Therefore, the number of skewâ€“symmetric
matrices of rank 4 is equal to |D(T ) âˆ©D(T â€²)|. It follows that
|D(T â€²) âˆ©I (T )| = |D(T â€²)| âˆ’|D(T â€²) âˆ©D(T )| =
= q6 âˆ’(q âˆ’1)q2(q3 âˆ’1) = q2(q3 + q âˆ’1)
and
|I (T â€²) âˆ©I (T )| = |M1| âˆ’2q6 + (q âˆ’1)q2(q3 âˆ’1) = (q2 + 1)(q2 + q + 1).
Since S âŠ‚C , we have that D(T ) âŠ‚L1. Moreover, every element g âˆˆD(T â€²) âˆ©
I (T ) is of the form Lâ€²(A) for some skewâ€“symmetric matrix A having rank 2.
Hence, g âˆˆL2. The set L1 âˆªL2 âˆª(I (T â€²) âˆ©I (T )) consists of q12 + (q4 âˆ’1)(q2 +
1)(q2 + q + 1) + (q2 + 1)(q2 + q + 1) solids of PG(7, q) mutually intersecting in
at most a line.
Let Î³ be a nonâ€“zero element of Fq such that the polynomial X2 âˆ’X âˆ’Î³ is
irreducible over Fq. Let Q2 be the hyperbolic quadric of PG(7, q) having equation
X0X6 + X1X7 + Î³ âˆ’1(X2X4 + X3X5 + X2X6 + X3X7) = 0.
The hyperbolic quadrics Q1 and Q2 generate a pencil of hyperbolic quadrics of
PG(7, q), say F, containing q âˆ’1 other distinct quadrics, say Qi, 3 â‰¤i â‰¤q + 1,
none of which is degenerate. Let X be the base locus of F. Since the hyperbolic
quadrics of F cover all the points of PG(7, q), and any two distinct quadrics in F
intersect precisely in X , we have that |X | = (q + 1)(q2 + 1)2. There are 2(q2 + 1)
generators belonging to each hyperbolic quadric of the pencil F and they all belong
to the same system of generators with respect to each of the quadrics Qi in F, say
Mi. In particular, T and T â€² belong to each hyperbolic quadric of the pencil F. Let G
be the set of generators meeting both T and T â€² non-trivially, and belonging to each
hyperbolic quadric of the pencil F. We have that G âŠ‚Mi, for every 1 â‰¤i â‰¤q + 1,
and |G | = q2 + 1.
Let Ii(X) denote the set of solids in Mi meeting nonâ€“trivially X, 2 â‰¤i â‰¤q + 1.
Then G = q+1
i=2 (Ii(T ) âˆ©Ii(T â€²)) âˆ©(I (T ) âˆ©I (T â€²)).
The set L1 âˆªL2 âˆª(	q+1
i=2 (Ii(T ) âˆ©Ii(T â€²))) âˆª(I (T ) âˆ©I (T â€²)) is a set of q12 +
(q4 âˆ’1)(q2 + 1)(q2 + q + 1) + q(q + 1)2(q2 + 1) + (q2 + 1) solids of PG(7, q)
mutually intersecting in at most a line.

120
A. Cossidente et al.
The set G consists of q2 + 1 generators belonging to each hyperbolic quadric of
the pencil F such that every element in G meets both T and T â€² in a line. The set DT =
{A âˆ©T | A âˆˆG }, DT â€² = {A âˆ©T â€² | A âˆˆG } is a lineâ€“spread of T , T â€², respectively.
In particular, for a ï¬xed line â„“âˆˆDT , there exists a unique element in DT â€², say Aâ„“,
such that âŸ¨â„“, Aâ„“âŸ©is in G , and viceversa. Furthermore, if â„“âˆˆDT and B âˆˆDT â€² \ {Aâ„“},
then âŸ¨â„“, BâŸ©is a solid meeting a hyperbolic quadric of the pencil F in a 3-dimensional
hyperbolic quadric Q+(3, q). Let Dâ€² be the set of solids of the form âŸ¨â„“, BâŸ©, where
â„“âˆˆDT and B âˆˆDT â€² \ {Aâ„“}. Then Dâ€² is disjoint from G and |Dâ€²| = q2(q2 + 1). We
have that L1 âˆªL2 âˆª(	q+1
i=2 (Ii(T ) âˆ©Ii(T â€²))) âˆª(I (T ) âˆ©I (T â€²)) âˆªDâ€² âˆª{T } is a set
of solids mutually intersecting in at most a line, of size
q12 + (q4 âˆ’1)(q2 + 1)(q2 + q + 1) + (q3 + 3q2 + q + 1)(q2 + 1) + 1.
There exists a group H in the orthogonal group PGO+(8, q), stabilizing Q1, ï¬xing
both T , T â€², their lineâ€“spreads D(T ), D(T â€²), and permuting in a single orbit the
remaining lines of T (respectively T â€²). Let âŠ¥be the orthogonal polarity of PG(7, q)
associated with Q1. If râ€² is a line of T â€², then râ€²âŠ¥meets T in a line r. If râ€² belongs
to DT â€², then r belongs to DT . Assume that râ€² does not belong to DT â€². Of course, râ€²
meets q + 1 lines lâ€²
1, . . . ,lâ€²
q+1 of DT â€² and r meets q + 1 lines l1, . . . ,lq+1 of DT .
The group H contains a subgroup ï¬xing the lines lâ€²
1, . . . ,lâ€²
q+1 and having q(q âˆ’
1)/2 orbits of size q2 âˆ’q on the lines of T distinct from l1, . . . ,lq+1. Each one of
them, together with l1, . . . ,lq+1, is a lineâ€“spread of T , one of them being DT . Let E
be one of the orbits of size q2 âˆ’q disjoint from DT and let Y be the solid generated
by râ€² and a line of E . It is possible to prove that Y H is a set of q6 âˆ’q2 solids mutually
intersecting in at most a line.
Finally,wehavethatthesetL1 âˆªL2 âˆª(	q+1
i=2 (Ii(T ) âˆ©Ii(T â€²))) âˆª(I (T ) âˆ©I (T â€²))
âˆªDâ€² âˆªY H âˆª{T } is an (8, M, 4, 4)qâ€“subspace code, where
M = q12 + q2(q2 + 1)2(q2 + q + 1) + 1.
This leads to the following result.
Corollary 2
Aq(8, 4, 4) â‰¥q12 + q2(q2 + 1)2(q2 + q + 1) + 1.
Remark 3 The previous lower bound was obtained with different techniques in
[19], where the authors, among other interesting results, proved that q12 + q2(q2 +
1)2(q2 + q + 1) + 1 is also the maximum size of an (8, M, 4, 4)qâ€“subspace code
containing a lifted MRD code.
For more information on constant dimension codes, we also refer to
Chap.â€œConstructions of Constant Dimension Codesâ€ of this Springer special vol-
ume.

Geometrical Aspects of Subspace Codes
121
4
Optimal Mixed-Dimension Subspace Codes in PG(4, q)
Via geometrical arguments, it can be shown that Aq(5, 3) = 2(q3 + 1). Here, a
(5, 2(q3 + 1), 3)-code consists of subspaces of the vector space V (5, q), equiva-
lently, of subspaces of the projective space PG(4, q).
To give an idea which arguments are used to get geometrical insight in which
subspaces could be contained in a mixed-dimension (5, M, 3)-subspace code, we try
to see how the codewords of this code can intersect.
The vector space V (5, q) has four types of subspaces: vector lines, vector planes,
subspaces of dimension three, and subspaces of dimension four.
The formula for the subspace distance d(U,U â€²) = dim(U + U â€²) âˆ’dim(U âˆ©U â€²)
shows that a (5, M, 3)-subspace code with minimum distance 3:
1. cannot contain two vector lines, and cannot contain two subspaces of dimension
four,
2. two vector planes in the code should only intersect in the zero vector,
3. two subspaces of dimension three should only intersect in a vector line,
4. a vector line in the code cannot be contained in a vector plane or in a 3-dimensional
vector space belonging to the code, a vector plane in the code cannot be contained
in a 3-dimensional subspace or 4-dimensional subspace belonging to the code,
and a 3-dimensional subspace in the code cannot be contained in a 4-dimensional
subspace belonging to the code.
We now interpret these conditions in the geometrical setting, so we replace all
the codewords in the (5, 2(q3 + 1), 3)-code by their geometrical equivalents in the
projective space PG(4, q).
Condition (2) implies that two projective lines belonging to the code are skew to
each other. Hence, the projective lines belonging to the (5, 2(q3 + 1), 3)-code form
a partial line spread of PG(4, q).
From Theorem2, the largest partial line spread of PG(4, q) has size q3 + 1. So,
if C is an optimal (5, 3)q subspace code, then C contains at most q3 + 1 pairwise
skew lines. A dual argument shows that C contains at most q3 + 1 planes, and these
planes pairwise intersect in a projective point.
Hence, if C consists of projective lines and projective planes, we have that |C | â‰¤
2(q3 + 1) and, if |C | = 2(q3 + 1), then C consists of a set L of q3 + 1 pairwise
skew lines and of a set P of q3 + 1 planes mutually intersecting in exactly a point,
such that no line of L is contained in a plane of P.
Note that Condition (1) above states that C contains at most one point and, dually,
C contains at most one solid.
Counting arguments of [11] prove that if C contains a point, then C contains at
most q3 planes. Dually, if C contains a solid, then C contains at most q3 lines.
It follows from these arguments that Aq(5, 3) â‰¤2(q3 + 1) and there are four
possibilities for the code C :
(I) C consists of one point, q3 + 1 lines, and q3 planes;
(II) C consists of q3 lines, q3 + 1 planes, and one solid;

122
A. Cossidente et al.
(III) C consists of one point, q3 lines, q3 planes, and one solid;
(IV) C consists of q3 + 1 lines and q3 + 1 planes.
We present the construction for q odd, showing that Aq(5, 3) = 2(q3 + 1). A
similar construction exists for q even, but since it is more technical, we refer to [11]
for its description.
Let q = ph, where p is an odd prime. Let PG(4, q) be equipped with homoge-
neous coordinates (X0, X1, X2, X3, X4), let Ï€ be the projective plane with equations
X3 = X4 = 0 and let â„“be the line of Ï€ with equations X2 = X3 = X4 = 0. Let Ï‰
be a primitive element of Fq and denote by Î i the solid of PG(4, q) passing through
Ï€ with equation X3 = Ï‰iâˆ’1X4, if 1 â‰¤i â‰¤q âˆ’1, X3 = 0 if i = q, and X4 = 0 if
i = q + 1.
Let a, b, c be ï¬xed elements of Fq such that the polynomial X3 + aX2 + bX +
c = 0 is irreducible over Fq and consider the following matrices
Mr,s,t =
â›
âœâœâœâœâ
1 0 r r2 âˆ’ar + s
t
0 1 s
2rs âˆ’t
s2 + bs âˆ’cr
0 0 1
2r
2s
0 0 0
1
0
0 0 0
0
1
â
âŸâŸâŸâŸâ 
.
Then the group of projective transformations G = {x â†’Mr,s,t Â· x | r, s, t âˆˆFq} is
a p-group of order q3.
This group G has within the set of lines of PG(4, q), exactly q3 orbits of size q3,
each consisting of pairwise disjoint lines that are disjoint from Ï€. Similarly, every
plane of PG(4, q), intersecting the plane Ï€ in exactly one point, not belonging to the
line â„“, belongs to an orbit of G, consisting of q3 planes, pairwise intersecting in one
point.
Consider such an orbit under G of q3 planes intersecting the ï¬xed plane Ï€ in a
point not belonging to the line â„“. Such a plane contains q2 lines skew to Ï€. They
deï¬ne only q2 of the q3 orbits of lines that are disjoint from Ï€. Hence, by taking
one of the remaining q3 âˆ’q2 orbits of such lines, a set of q3 planes and q3 lines is
obtained forming a subspace code with minimum distance 3.
This (5, 2q3, 3)-code can be extended to a (5, 2(q3 + 1), 3)-code by adding a line
r of Ï€, r Ì¸= â„“, and a plane Î¾ through the line â„“, but with Î¾ Ì¸= Ï€, to this code. This
leads to an optimal (5, Aq(5, 3), 3)-code consisting of q3 + 1 lines and planes.
Figure3 presents the setting for this mixed dimension code in PG(4, q), q odd.
The drawing shows the plane Ï€, the line â„“with the plane Î¾ passing through â„“, and
the line r. Two of the q + 1 solids through the plane Ï€ are shown. They are denoted
by Î i and Î  j. The orbit of q3 lines skew to Ï€ is denoted by the three vertical lines,
sharing one point with the solids Î i and Î  j. Finally, one plane is drawn of the orbit
of q3 planes sharing one point with the plane Ï€, which does not belong to â„“, and
which are skew to the q3 lines of the selected orbit of lines.

Geometrical Aspects of Subspace Codes
123
Fig. 3 The mixed
dimension construction in
PG(4, q), q odd
In [11, Remark2.6], it is shown that minor changes can be made to the construc-
tion, to also construct optimal (5, Aq(5, 3), 3)-codes of type (I), (II), and (III).
5
Geometrical Links to Non-linear Maximum Rank
Distance Codes
In this context, we can make links to the Segre variety of PG(n2 âˆ’1, q) [13, 26].
The Segre map
Ïƒ : PG(n âˆ’1, q) Ã— PG(n âˆ’1, q) â†’PG(n2 âˆ’1, q),
takes a pair of points x = (x0, . . . , xnâˆ’1), y = (y0, . . . , ynâˆ’1) of PG(n âˆ’1, q) to their
product (x0y0, x0y1, . . . , xnâˆ’1ynâˆ’1) (the products xi y j are taken in lexicographical
order). The image of the Segre map is an algebraic variety of PG(n2 âˆ’1, q), called
the Segre variety, and is denoted by Snâˆ’1,nâˆ’1.
When n = 2, the Segre variety S1,1 of PG(3, q) is a nonâ€“degenerate hyperbolic
quadric Q+(3, q). In Sect.3.3, we deï¬ned the hyperbolic quadric as the quadric with
equation X0X2 âˆ’X1X3 = 0, but equivalently, this quadric is given as the zero locus
of the quadratic polynomial given by the determinant of the matrix
 x0y0 x0y1
x1y0 x1y1

.

124
A. Cossidente et al.
In the case n = 3, the Segre variety S2,2 of PG(8, q) is deï¬ned to be the zero
locus of all quadratic polynomials given by the determinants of the 2 Ã— 2 matrices
of the matrix
â›
â
x0y0 x0y1 x0y2
x1y0 x1y1 x1y2
x2y0 x2y1 x2y2
â
â .
In other terms, in the projective space PG(MnÃ—n(q)), if n = 2, the Segre variety
S1,1 of PG(3, q) is represented by all 2 Ã— 2 matrices of rank 1 and if n = 3, the
Segre variety S2,2 of PG(8, q) is represented by all 3 Ã— 3 matrices of rank 1.
The following deï¬nition considers a set of points that at ï¬rst sight is of purely
geometrical interest with respect to a Segre variety.
Deï¬nition 3 An exterior set with respect to a Segre variety Snâˆ’1,nâˆ’1 of PG(n2 âˆ’
1, q) is a set of points E of PG(n2 âˆ’1, q) \ Snâˆ’1,nâˆ’1 of size (qn2âˆ’n âˆ’1)/(q âˆ’1)
such that the line joining any two points of E is disjoint from Snâˆ’1,nâˆ’1.
But this deï¬nition and the previous observations give an immediate link with
maximum rank distance codes.
In general, an exterior set E of PG(n2 âˆ’1, q) with respect to a Segre variety
Snâˆ’1,nâˆ’1, of size (qn2âˆ’n âˆ’1)/(q âˆ’1), gives rise to a MRD code: this is done by
identifying a point of E and its nonzero scalar multiples together with the zero matrix
with members of MnÃ—n(q). This is also the key tool of our approach. We formulate
this in the next proposition.
Proposition 1 An exterior set with respect to Snâˆ’1,nâˆ’1 gives rise to an (n, n, n âˆ’1)
MRD code closed under Fqâ€“multiplication, and viceversa.
Corollary 3 An (n, n, n âˆ’1) Fq-linear Gabidulin code G is a certain subspace X
of PG(n2 âˆ’1, q) of dimension n2 âˆ’n âˆ’1 which is an exterior set with respect to
Snâˆ’1,nâˆ’1.
The preceding corollary is of particular interest since the maximum dimension of
a subspace of PG(n2 âˆ’1, q) disjoint from Snâˆ’1,nâˆ’1 is exactly n2 âˆ’n âˆ’1 [9].
5.1
The Case n = 2
In this subsection, we report the complete classiï¬cation of linear and nonâ€“linear
MRD codes that are closed under Fqâ€“multiplication when n = m = 2. We do this
because this is linked to the solution of a purely geometrical problem, related to the
hyperbolic quadric Q+(3, q) of the projective space PG(3, q), which is the smallest
example of a Segre variety.
A ï¬‚ock of the hyperbolic quadric Q+(3, q) of the ï¬nite projective space PG(3, q)
is a partition of Q+(3, q) consisting of q + 1 irreducible conics. A linear ï¬‚ock of
Q+(3, q) is a ï¬‚ock which consists of q + 1 irreducible conics, lying in the q + 1

Geometrical Aspects of Subspace Codes
125
planes through a ï¬xed line â„“skew to the hyperbolic quadric Q+(3, q). A maximal
exterior set (MES) with respect to the hyperbolic quadric Q+(3, q) is a set of q + 1
points of PG(3, q) such that the line joining any two of them has no point in common
with Q+(3, q). The polar planes, with respect to the polarity induced by Q+(3, q),
of the points of a MES, deï¬ne a ï¬‚ock, and conversely.
In [41], J.A. Thas proved that all ï¬‚ocks of Q+(3, q) are linear if q is even, and
that Q+(3, q) has nonâ€“linear ï¬‚ocks (called Thas ï¬‚ocks) if q is odd. Furthermore, he
showed that, for q = 3, 7 and q â‰¡1 mod 4, Q+(3, q) has only (up to a projectivity)
the linear ï¬‚ock and the Thas ï¬‚ock. For q = 11, 23, 59, other ï¬‚ocks of Q+(3, q) were
discovered, called exceptional ï¬‚ocks [1, 3, 29]. Finally, the combined results of Bader
and Lunardon [2] and Thas [42] proved that every ï¬‚ock of Q+(3, q), q odd, is linear,
a Thas ï¬‚ock or one of the exceptional ï¬‚ocks.
The classiï¬cation theorem is therefore as follows.
Theorem 8 Let E be a MES deï¬ned by a ï¬‚ock F of Q+(3, q) in the matrix model of
PG(3, q). Then, either q is even and E is a line, or q is odd and one of the following
possibilities occurs:
(1) E is a line;
(2) E consists of (q + 1)/2 points on two lines â„“, â„“âŠ¥, where âŠ¥is the polarity of
Q+(3, q);
(3) E is one of the sporadic examples.
In our setting, the linear MES corresponds to a (2, 2, 1) Fq-linear MRD-code. In
all the other instances (Theorem8 (2) and (3)), the MES corresponds to a (2, 2, 1)
non-linear maximum rank distance code.
5.2
The Case n = 3
A very useful model of S2,2 arises from the geometry of the Desarguesian projective
plane Ï€ := PG(2, q3). Indeed, each point P of PG(2, q3), when read over Fq, deï¬nes
a projective plane X(P) of the projective space PG(8, q), and the set D = {X(P) :
P âˆˆPG(2, q3)} is a Desarguesian spread of PG(8, q) [38, Sect.25]. The incidence
structure Ï€ := (D, L ), whose points are the elements of D and whose line set
L consists of the 5â€“dimensional projective subspaces of PG(8, q) joining any two
distinct elements of D, is isomorphic to PG(2, q3). The pair (D, L ) is called the
Fq-linear representation of PG(2, q3) (with respect to the Desarguesian spread D).
Let X0, X1, X2 denote projective homogeneous coordinates inÏ€ â‰ƒPG(2, q3) and
let Â¯Ï€ be a subplane of Ï€ of order q. Let G denote the stabilizer of Â¯Ï€ in PGL(3, q3).
Choose homogeneous coordinates in such a way that Â¯Ï€ := {(1, xq+1, xq) : x âˆˆ
Fq3 \ {0}, N(x) = 1}, where N(Â·) is the norm function from Fq3 over Fq. It turns
out that Â¯Ï€ is ï¬xed pointwise by the order three semilinear collineation of PG(2, q3)
given by Ï† : (X0, X1, X2) â†’(Xq
2, Xq
0, Xq
1).

126
A. Cossidente et al.
Let âŸ¨SâŸ©be a Singer cyclic group of G [28]. We can assume that S is given by
â›
â
Ï‰ 0
0
0 Ï‰q
0
0 0 Ï‰q2
â
â ,
where Ï‰ is a primitive element of Fq3.
Remark 4 The subgroup âŸ¨SâŸ©ï¬xes the three points E1 = (1, 0, 0), E2 = (0, 1, 0) and
E3 = (0, 0, 1) of Ï€, and hence the lines Ei E j, 1 â‰¤i < j â‰¤3. All the other orbits
are subplanes of order q of Ï€. Note that the line Ei E j is partitioned into the two
points Ei and E j, and into q âˆ’1 orbits of âŸ¨SâŸ©of size q2 + q + 1. The collineation
Ï† above normalizes âŸ¨SâŸ©.
The points of Â¯Ï€ correspond to the q2 + q + 1 planes ï¬lling the system of a Segre
variety S2,2 of PG(8, q) contained in the Desarguesian spread D. Also, the lines of
Ï€, arising from sublines of Â¯Ï€, yield a set of (q3 âˆ’q)(q2 + q + 1) points of Ï€ that
together with the points of Â¯Ï€ give rise to the points of the secant variety Î©(S2,2) of
S2,2 [33, 36].
Under the action of the stabilizer G of Â¯Ï€ in PGL(3, q3), the point set of Ï€ is
partitioned into three orbits corresponding to the points of Â¯Ï€, points of Ï€ \ Â¯Ï€ on
extended sublines of Â¯Ï€, and the complement. Under the same group, by duality, the
line set of Ï€ is partitioned into three orbits corresponding to sublines of Â¯Ï€, lines
meeting Â¯Ï€ in a point, and lines external to Â¯Ï€.
Proposition 2 In the linear representation of PG(2, q3), any line of Ï€ disjoint from
Â¯Ï€ corresponds to a 5-dimensional projective subspace of PG(8, q) disjoint from
S2,2.
Of course, any line of Ï€ disjoint from Â¯Ï€ gives rise to an exterior set with respect to
S2,2 and hence, from a coding theoretical point of view, a (3, 3, 2) Fqâ€“linear MRD
code.
Now let q > 2 and consider the set X of points of Ï€ whose coordinates satisfy
the equation X0Xq
1 âˆ’Xq+1
2
= 0. The set X has size q3 + 1 and it is ï¬xed by âŸ¨SâŸ©.
Also, it contains q âˆ’1 subplanes of order q, one of which is Â¯Ï€, and the points E1
and E2. More precisely, the subplanes of order q embedded in X are the subsets of
points of Ï€ given by
Ï€a := {(1, xq+1, xq) : x âˆˆFq3, N(x) = a},
where a is a nonzero element of Fq. In particular, Ï€1 = Â¯Ï€. From [16, Proposition3.1],
a line of Ï€ intersects X in 0, 1, 2 or q + 1 points, and the intersections of size q + 1
are actually lines of subplanes of order q of Ï€ embedded in X . We can assume
that the Segre variety corresponding to Â¯Ï€ = Ï€1 is the only Segre variety of PG(8, q)
corresponding to rank one matrices of order three.

Geometrical Aspects of Subspace Codes
127
We recall the following deï¬nition.
Deï¬nition 4 ([4]) Let â„“âˆbe a line of Ï€ disjoint from the subplane Â¯Ï€. The exterior
splash of Â¯Ï€ on â„“âˆis deï¬ned to be the set of q2 + q + 1 points of â„“âˆthat belong to
an extended line of Â¯Ï€.
The line E1E2 is disjoint from all the q âˆ’1 subplanes Ï€a, a âˆˆFq \ {0}, of Ï€
contained in X . Also, for each subplane Ï€a, with a âˆˆFq \ {0}, its exterior splash
on E1E2 is the set of q2 + q + 1 points of E1E2 given by
Za := {(1, x, 0) : x âˆˆFq3, N(x) = âˆ’a2}.
Such a set is a so-called Fq-linear set of pseudoregulus type. For further details on
these linear sets, see [16, 34, 36]. All these subplanes and splashes are of course
âŸ¨SâŸ©-orbits.
Now, let T be the fundamental triangle E1E2E3 of Ï€. One can prove that a
line of Ï€ is either a side of T , or it contains a vertex of T , or it induces a subline
of a unique subplane of order q of Ï€ invariant under âŸ¨SâŸ©. Consider now the set
K := (X \ {Ï€1}) âˆªZ1. It turns out that K is such that every line deï¬ned by any two
of its points is disjoint from Ï€1. Correspondingly, the set K â€² corresponding to K in
PG(8, q), q > 2, is an exterior set of size (q3 + 1)(q2 + q + 1) with respect to the
Segre variety S2,2 corresponding to Ï€1.
In terms of coding theory, we have the following result.
Theorem 9 There exists a (3, 3, 2) MRD non-linear code admitting a Singer cyclic
group of PGL(3, q), q > 2, as an automorphism group.
Remark 5 In [21], R. Figueroa presented a new class of non-Desarguesian projective
planes of order q3, q a prime power with q Ì¸â‰¡1 mod 3, q > 2. C. Hering and H.-J.
Schaffer in [23] improved and simpliï¬ed the construction for all prime powers q.
From [7, Corollary3], the set K constructed above represents a line in the Figueroa
plane of order q3.
Remark 6 When q = 2, some computer tests performed with MAGMA [8] give that
all subsets of PG(2, 8) yielding exterior sets with respect to a Segre variety S2,2 are
precisely the 24 lines disjoint from Â¯Ï€. When q = 2, no non-linear MRD codes arise
from our construction.
We also refer the readers to Chap.â€œCodes Endowed with the Rank Metricâ€ of this
Springer special volume, dedicated to rank metric codes, and to Chap.â€œConstructions
of Cyclic Subspace Codes and Maximum Rank Distance Codesâ€ of this special
volume on the construction of cyclic subspace codes and maximum rank distance
codes.

128
A. Cossidente et al.
References
1. L. Bader, Some new examples of ï¬‚ocks of Q+(3, q). Geom. Dedicata 27, 213â€“218 (1988)
2. L. Bader, G. Lunardon, On the ï¬‚ocks of Q+(3, q). Geom. Dedicata 29, 177â€“183 (1989)
3. R.D. Baker, G.L. Ebert, A nonlinear ï¬‚ock in the minkowski plane of order 11. Congr. Numer.
58, 75â€“81 (1987)
4. S.G. Barwick, W.-A. Jackson, Exterior splashes and linear sets of rank 3. Discret. Math. 339,
1613â€“1623 (2016)
5. A. Beutelspacher, Partial spreads in ï¬nite projective spaces and partial designs. Math. Z. 145,
211â€“229 (1975)
6. A. Beutelspacher, On t-covers in ï¬nite projective spaces. J. Geom. 12, 10â€“16 (1979)
7. J.M.N. Brown, Some partitions in Figueroa planes. Note Mat. 29, 33â€“43 (2009)
8. J. Cannon, C. Playoust, An introduction to MAGMA, University of Sydney, Sydney, Australia
(1993)
9. B.N. Cooperstein, External ï¬‚ats to varieties in PG(Mn,n(GF(q))). Linear Algebra Appl. 267,
175â€“186 (1997)
10. A. Cossidente, F. Pavese, Subspace codes in PG(2n âˆ’1, q). Combinatorica (to appear). https://
doi.org/10.1007/s00493-016-3354-5
11. A. Cossidente, F. Pavese, L. Storme, Optimal subspace codes in PG(4, q) (In preparation)
12. A. Cossidente, F. Pavese, On subspace codes. Des. Codes Cryptogr. 78, 527â€“531 (2016)
13. A. Cossidente, G. Marino, F. Pavese, Non-linear maximum rank distance codes. Des. Codes
Cryptogr. 79, 597â€“609 (2016)
14. P. Delsarte, Bilinear forms over a ï¬nite ï¬eld, with applications to coding theory. J. Combin.
Theory Ser. A 25, 226â€“241 (1978)
15. P. Dembowski, Finite Geometries (Springer, Berlin, 1968)
16. G. Donati, N. Durante, Scattered linear sets generated by collineations between pencils of lines.
J. Algebr. Combin. 40, 1121â€“1134 (2014)
17. J.Eisfeld,L.Storme,(Partial)t-spreadsandminimalt-coversinï¬niteprojectivespaces.Lecture
notes, Universiteit Gent (2000), http://cage.ugent.be/~fdc/courses/GGaGP2.php
18. S. El-Zanati, H. Jordon, G. Seelinger, P. Sissokho, L. Spence, The maximum size of a partial
3-spread in a ï¬nite vector space over GF(2). Des. Codes Cryptogr. 54, 101â€“107 (2010)
19. T. Etzion, N. Silberstein, Codes and designs related to lifted MRD codes. IEEE Trans. Inform.
Theory 59, 1004â€“1017 (2013)
20. T. Etzion, A. Vardy, Error-correcting codes in projective space. IEEE Trans. Inform. Theory
57, 1165â€“1173 (2011)
21. R. Figueroa, A family of not (V,l)-transitive projective planes of order q3,
and q>2. Math. Z. 181, 471â€“479 (1982)
22. E.M. Gabidulin, Theory of codes with maximum rank distance. Probl. Inform. Trans. 21, 1â€“12
(1985)
23. C. Hering, H.-J. Schaffer, On the new projective planes of R. Figueroa, Combinatorial Theory,
vol. 969, Lecture Notes in Mathematics (Springer, Berlin, 1982), pp. 187â€“190
24. J.W.P. Hirschfeld, Finite Projective Spaces of Three Dimensions (Oxford University Press,
Oxford, 1985)
25. J.W.P. Hirschfeld, Projective Geometries Over Finite Fields, 2nd edn. (Oxford University Press,
Oxford, 1998)
26. J.W.P. Hirschfeld, J.A. Thas, General Galois Geometries (Oxford University Press, Oxford,
1991)
27. T. Honold, M. Kiermaier, S. Kurz, Optimal binary subspace codes of length 6, constant dimen-
sion 3 and minimum distance 4. Contemp. Math. 632, 157â€“176 (2015)
28. B. Huppert, Endliche Gruppen, I, Die Grundlehren der Mathematischen Wissenschaften, Band
134 (Springer, Berlin, 1967)
29. N.L.Johnson,Flocksofhyperbolicquadricsandtranslationplanesadmittingafï¬nehomologies.
J. Geom. 34, 50â€“73 (1989)

Geometrical Aspects of Subspace Codes
129
30. A. Klein, K. Metsch, L. Storme, Small maximal partial spreads in classical ï¬nite polar spaces.
Adv. Geom. 10, 379â€“402 (2010)
31. R. KÃ¶tter, F. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inform. Theory 54, 3579â€“3591 (2008)
32. S. Kurz, Improved upper bound for partial spread. Des. Codes Cryptogr. 85, 97â€“106 (2017)
33. M. Lavrauw, G. Van de Voorde, Field reduction and linear sets in ï¬nite geometry. Contemp.
Math. 632, 271â€“293 (2015)
34. M. Lavrauw, C. Zanella, Subgeometries and linear sets on a projective line. Finite Fields Appl.
34, 95â€“106 (2015)
35. G. Lunardon, R. Trombetti, Y. Zhou, Generalized twisted Gabidulin codes, arXiv:1507.07855
36. G. Lunardon, G. Marino, O. Polverino, R. Trombetti, Maximum scattered linear sets of pseu-
doregulus type and the Segre Variety Sn,n. J. Algebr. Combin. 39, 807â€“831 (2014)
37. E. Nastase, P. Sissokho, The maximum size of a partial spread in a ï¬nite projective space.
J. Combin. Theory Ser. A 152, 353â€“362 (2017)
38. B. Segre, Teoria di Galois, ï¬brazioni proiettive e geometrie non desarguesiane. Ann. Mat. Pura
Appl. 64, 1â€“76 (1964)
39. J. Sheekey, A new family of linear maximum rank distance codes. Adv. Math. Commun. 10,
475â€“488 (2016)
40. D. Silva, F.R. Kschischang, R. Koetter, A rank-metric approach to error control in random
network coding. IEEE Trans. Inform. Theory 54, 3951â€“3967 (2008)
41. J.A. Thas, Flocks of non-singular ruled quadrics in PG(3, q). Atti Accad. Naz. Lincei Rend.
Cl. Sci. Fis. Mat. Natur. 59, 83â€“85 (1975)
42. J.A. Thas, Flocks, maximal exterior sets and inversive planes, Finite Geometries and Com-
binatorial Designs, vol. 111, Contemporary Mathematics (American Mathematical Society,
Providence, 1990), pp. 187â€“218

Partial Spreads and Vector Space Partitions
Thomas Honold, Michael Kiermaier and Sascha Kurz
Abstract Constant-dimension codes with the maximum possible minimum distance
have been studied under the name of partial spreads in Finite Geometry for several
decades. Not surprisingly, for this subclass typically the sharpest bounds on the
maximal code size are known. The seminal works of Beutelspacher and Drake &
Freeman on partial spreads date back to 1975 and 1979, respectively. From then until
recently, there was almost no progress besides some computer-based constructions
and classiï¬cations. It turns out that vector space partitions provide the appropriate
theoretical framework and can be used to improve the long-standing bounds in quite a
few cases. Here, we provide a historic account on partial spreads and an interpretation
of the classical results from a modern perspective. To this end, we introduce all
required methods from the theory of vector space partitions and Finite Geometry in
a tutorial style. We guide the reader to the current frontiers of research in that ï¬eld,
including a detailed description of the recent improvements.
1
Introduction
Let Fq be the ï¬nite ï¬eld with q elements, where q > 1 is a prime power. By Fv
q we
denote the standard vector space of dimension v â‰¥1 over Fq, whose vectors are the
v-tuples x = (x1, . . . , xv) with xi âˆˆFq. The set of all subspaces of Fv
q, ordered by
the incidence relation âŠ†, is called (v âˆ’1)-dimensional projective geometry over Fq
and denoted by PG(v âˆ’1, Fq). It forms a ï¬nite modular geometric lattice with meet
X âˆ§Y = X âˆ©Y, join X âˆ¨Y = X + Y, and rank function X â†’dim(X). Employing
this algebraic notion of dimension instead of the geometric one, we will use the term
T. Honold
Zhejiang University, Hangzhou 310027, China
e-mail: honold@zju.edu.cn
M. Kiermaier Â· S. Kurz (B)
University of Bayreuth, 95440 Bayreuth, Germany
e-mail: sascha.kurz@uni-bayreuth.de
M. Kiermaier
e-mail: michael.kiermaier@uni-bayreuth.de
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_7
131

132
T. Honold et al.
k-subspace to denote a k-dimensional vector subspace of Fv
q.1 The important geomet-
ric interpretation of subspaces will still be visible in the terms points, lines, planes,
solids, hyperplanes (denoting 1-, 2-, 3-, 4- and (v âˆ’1)-subspaces, respectively), and
in general through our extensive use of geometric language. For more geometrical
aspects we refer the reader to Chapter â€œGeometrical Aspects of Subspace Codesâ€.
In the same way as Fv
q, an arbitrary v-dimensional vector space V over Fq gives
rise to a projective geometry PG(V ), and the terminology introduced before (and
thereafter) applies to this general case as well. Since a vector space isomorphism
V âˆ¼= Fv
q induces a geometric isomorphism (â€œcollineationâ€) PG(V ) âˆ¼= PG(Fv
q) =
PG(v âˆ’1, Fq), we could in principle avoid the use of non-standard vector spaces,
but only at the expense of ï¬‚exibilityâ€”for example, the Singer representation of the
point-hyperplane design of PG(v âˆ’1, Fq) is best developed using the ï¬eld extension
Fqv/Fq as ambient vector space V (and not Fv
q, which would require a discussion of
matrix representations of ï¬nite ï¬elds).
The set of all k-subspaces of an Fq-vector space V will be denoted by
V
k

q.
The sets
V
k

q form ï¬nite analogues of the GraÃŸmann varieties studied in Algebraic
Geometry. In terms of v = dim(V ), the cardinality of
V
k

q is given by the Gaussian
binomial coefï¬cient
v
k

q
:=
 (qvâˆ’1)(qvâˆ’1âˆ’1)Â·Â·Â·(qvâˆ’k+1âˆ’1)
(qkâˆ’1)(qkâˆ’1âˆ’1)Â·Â·Â·(qâˆ’1)
if 0 â‰¤k â‰¤v;
0
otherwise,
which are polynomials of degree k(v âˆ’k) in q (if they are nonzero) and represent
q-analogues of the ordinary binomial coefï¬cients in the sense that limqâ†’1
v
k

q =
v
k

.
Their most important combinatorial properties are described in [2, Sect.3.3] and [66,
Chap. 24].
Making the connection with the main topic of this book, the geometry PG(v âˆ’
1, Fq) serves as input and output alphabet of the so-called linear operator chan-
nel (LOC), a clever model for information transmission in coded packet networks
subject to noise [43].2 The relevant metrics on the LOC are given by the subspace dis-
tance
dS(X, Y) := dim(X + Y) âˆ’dim(X âˆ©Y) = 2 Â· dim(X + Y) âˆ’dim(X) âˆ’
dim(Y), which can also be seen as the graph-theoretic distance in the Hasse diagram
of PG(v âˆ’1, Fq), and the injection distance dI(X, Y) := max {dim(X), dim(Y)} âˆ’
dim(X âˆ©Y). A set C of subspaces of Fv
q is called a subspace code and serves as a
channel code for the LOC in the same way as classical linear codes over Fq do for
the q-ary symmetric channel.3 The minimum (subspace) distance of C is given by
d = min{dS(X, Y) | X, Y âˆˆC , X Ì¸= Y}. If all elements of C have the same dimen-
1Using the algebraic dimension has certain advantagesâ€”for example, the existence criterion v =
tk for spreads (cf. Theorem 1) looks ugly when stated in terms of the geometric dimensions:
vâ€² = t(kâ€² âˆ’1) + 1.
2The use of distributed coding at the nodes of a packet-switched network, generally referred to as
Network Coding, is described in [27, 56, 70] and elsewhere in this volume.
3Except that attention is usually restricted to â€œone-shot subspace codesâ€, i.e. subsets of the alphabet,
which makes no sense in the classical case.

Partial Spreads and Vector Space Partitions
133
sion, we call C a constant-dimension code. For a constant-dimension code C we
have dS(X, Y) = 2dI(X, Y) for all X, Y âˆˆC , so that we can restrict attention to the
subspace distance. Constant-dimension codes are the most suitable for coding pur-
poses, and the quest for good system performance leads straight to the problem of
determining the maximum possible cardinality Aq(v, d; k) of a constant-dimension-
k code in Fv
q with minimum subspace distance d. For two codewords X and Y of
dimension k the inequality dS(X, Y) â‰¥d is equivalent to dim(X âˆ©Y) â‰¤k âˆ’d/2.4
Thus, the maximum possible minimum distance of a constant-dimension code with
codewords of dimension k is 2k. This extremal case has been studied under the name
â€œpartial spreadsâ€ in Finite Geometry for several decades. A partial k-spread in Fv
q is
a collection of k-subspaces with pairwise trivial, i.e., zero-dimensional intersection.
Translating this notion into Projective Geometry and identifying thereby, as usual,
subspaces of Fv
q with their sets of incident points, we have that a partial k-spread in
Fv
q is the same as a set of mutually disjoint k-subspaces, or (k âˆ’1)-dimensional ï¬‚ats
in the geometric view, of the geometry PG(v âˆ’1, Fq).5
With the history of partial spreads in mind, it comes as no surprise that the sharpest
bounds on the maximal code sizes Aq(v, d; k) of constant-dimension codes are typ-
ically known for this special subclass. The primary goal of this survey is to collect
all available information on the numbers Aq(v, 2k; k) and present this information
in an accessible way. Following standard practice in Finite Geometry, we will refer
to partial k-spreads of size Aq(v, 2k; k) as maximal partial k-spreads.6
In the case of a perfect packing, i.e., a partition of the point set of PG(v âˆ’1, Fq),
we speak of a k-spread. Partitions into subspaces of possibly different dimensions are
equivalent to vector space partitions. A vector space partition C of Fv
q is a collection
of nonzero subspaces with the property that every non-zero vector is contained in a
unique member of C . If C contains md subspaces of dimension d, then C is said to
be of type kmk Â· Â· Â· 1m1. Zero frequencies md = 0 are usually suppressed.7 So, partial
k-spreads are just the special case of vector space partitions, in which all members
have dimension either k or 1. For k â‰¥2 (the case k = 1 is trivial) the members of
dimension 1 correspond to points not covered by a k-subspace of the partial spread
and are called holes in this context.
Although vector space partitions can be seen as a mixed-dimension analogue of
partial spreads, they are not usable as subspace codes of their own.8 However, it
turns out that they provide an appropriate framework to study bounds on the sizes of
partial spreads.
4Note that the distance between codewords of the same dimension, and hence also the minimum
distance of a constant-dimension code, is an even integer.
5In other words, partial spreads are just packings of the point set of a projective geometry
PG(v âˆ’1, Fq) into subspaces of equal dimension.
6The weaker property of complete (i.e., inclusion-maximal) partial spreads will not be considered.
7Since 	
XâˆˆC dim(X) = 	
d dmd = v, the type of C can be viewed as an ordinary integer partition
of v.
8The subspace distance dS(X, Y) depends not only on dim(X âˆ©Y) but also on dim(X) and dim(Y),
which are not constant in this case.

134
T. Honold et al.
There is a vast amount of related work that we will not cover in this survey:
Partial spreads have also been studied for combinatorial designs and in polar spaces;
for the latter see, e.g., [5, 21]. In the special case v = 2k spreads can be used to
deï¬ne translation planes and provide a rich source for constructing non-desarguesian
projective planes [41, 42, 51]. Also motivated by this geometric point-of-view, partial
k-spreads in F2k
q of size close to the maximum size (given by Theorem 1) have been
studied extensively. Most of this research has focused on partial spread replacements
and complete partial spreads, while we consider only partial spreads of maximum
cardinality and hence do not touch the case v = 2k (except for Theorem 1). The
classiï¬cation of all (maximal) partial spreads up to isomorphism, see e.g. [55], is
also not treated here. Further, there is a steady stream of literature that characterizes
the existing types of vector space partitions in Fv
2 for small dimensions v. Here,
we touch only brieï¬‚y on some results that are independent of the ambient space
dimension v and refer to [30] otherwise.
The remaining part of this chapter is structured as follows. In Sect.2 we review
some, mostly classical, bounds and constructions for partial spreads. After intro-
ducing the concept of qr-divisible sets and codes in Sect.3, we are able to obtain
improved upper bounds for partial spreads in Theorems 9 and 10. Constructions for
qr-divisible sets are presented in Sect.4, some non-existence results for qr-divisible
sets are presented in Sect.5, and we close this survey with a collection of open
research problems in Sect.6.
2
Bounds and Constructions for Partial Spreads
Counting points in Fv
q and Fk
q gives the obvious upper bound Aq(v, 2k; k) â‰¤
v
1

q/
k
1

q = (qv âˆ’1) /

qk âˆ’1

for the size of a partial k-spread in Fv
q. Equality
corresponds to the case of spreads, for which a handy existence criterion is known
from the work of Segre in 1964.9
Theorem 1 ([62, Sect. VI], [17, p. 29]) Fv
q contains a k-spread if and only if k is a
divisor of v.
Since qvâˆ’1
qkâˆ’1 is an integer if and only if k divides v (an elementary number theory
exercise), only the constructive part needs to be shown. To this end we write v = kt
for a suitable integer t, take the ambient space V as the restriction (â€œï¬eld reductionâ€)
of (Fqk)t to Fq, which clearly has dimension v, and deï¬ne the k-spread S in V/Fq as
the set of 1-subspaces of V/Fqk. That S is indeed a k-spread, is easily veriï¬ed: Each
member of S has dimension k over Fq; the members form a vector space partition
of V (this property does not depend on the particular ï¬eld of scalars); and the size
t
1

qk = qvâˆ’1
qkâˆ’1 of S is as required.10
9Segre in turn built to some extent on work of AndrÃ©, who had earlier considered the special case
v = 2k in his seminal paper on translation planes [1].
10Alternatively, the member of S containing a nonzero vector x is the k-subspace Fqk x of V/Fq.

Partial Spreads and Vector Space Partitions
135
Example 1 We consider the parameters q = 3, v = 4, and k = 2. Using canonical
representatives in F9 â‰ƒF3[x]/(x2 + 1), the
2
1

9 = 10 points in F2
9 are generated by

0
1

,

1
0

,

1
1

,

1
2

,

1
x

,

1
x + 1

,

1
x + 2

,

 1
2x

,

1
2x + 1

,

1
2x + 2

.
The
particular
point
P = F9

1
x+1

=
 0
0

,

1
x+1

,

2
2x+2

,

x
x+2

,
 x+1
2x

,
 x+2
1

,

2x
2x+1

,
 2x+1
x

,
 2x+2
2

on the projective line PG(1, F9) deï¬nes a 2-
subspace of F2
9/F3 âˆ¼= F4
3, whose 4 associated points are F3x, x âˆˆP, x Ì¸=
 0
0

; and
similarly for the other points of PG(1, F9). These ten 2-subspaces form the 2-spread
S .
Using any F3-isomorphism F2
9/F3 âˆ¼= F4
3, we can translate S into a 2-spread S â€²
of the standard vector space F4
3. Taking, for example, coordinates with respect to the
basis (1, x) of F9/F3 and extending to F2
9 in the obvious way translates P into the
2-subspace of F4
3 with vectors
â›
âœâœâ
0
0
0
0
â
âŸâŸâ ,
â›
âœâœâ
1
0
1
1
â
âŸâŸâ ,
â›
âœâœâ
2
0
2
2
â
âŸâŸâ ,
â›
âœâœâ
0
1
2
1
â
âŸâŸâ ,
â›
âœâœâ
1
1
0
2
â
âŸâŸâ ,
â›
âœâœâ
2
1
1
0
â
âŸâŸâ ,
â›
âœâœâ
0
2
1
2
â
âŸâŸâ ,
â›
âœâœâ
1
2
0
1
â
âŸâŸâ ,
â›
âœâœâ
2
2
2
0
â
âŸâŸâ .
The other members of S â€² are obtained in the same way.
We remark that k-spreads are a special case of subspace designs, see chapters â€œq-
Analogs of Designs: Subspace Designsâ€ and â€œComputational Methods in Subspace
Designsâ€.
From now on we assume that k does not divide v and write v = tk + r with
1 â‰¤r â‰¤k âˆ’1. Since the cases t âˆˆ{0, 1} are trivial (Aq(r, 2k; k) = 0 and Aq(k +
r, 2k; k) = 1), we also assume t â‰¥2. The stated upper bound then takes the form
Aq(v, 2k; k) â‰¤
qv âˆ’1
qk âˆ’1

= qtk+r âˆ’qr
qk âˆ’1
+
qr âˆ’1
qk âˆ’1

=
tâˆ’1

s=0
qsk+r = qr
t
1

qk.
(2.1)
We also see from this computation that the number of holes of a partial k-spread
is at least qvâˆ’1
qâˆ’1 mod qkâˆ’1
qâˆ’1 = qrâˆ’1
qâˆ’1 . However, as we will see later, this bound can be
improved further.
In accordance with (2.1) we make the following deï¬nition (similar to that in [7]):
The number Ïƒ deï¬ned by Aq(v; 2k; k) = 	tâˆ’1
s=0 qsk+r âˆ’Ïƒ is called the deï¬ciency of
the maximal partial k-spreads in Fv
q.11 From (2.1) we have Ïƒ â‰¥0. In terms of the
deï¬ciency, the minimum possible number of holes is Ïƒ Â· qkâˆ’1
qâˆ’1 + qrâˆ’1
qâˆ’1 .
Our next goal is to derive a good lower bound for Aq(v, 2k; k) (equivalently, a
lowerboundforthecorrespondingdeï¬ciency)byconstructingalargepartialk-spread
11This makes sense also for r = 0: Spreads are assigned deï¬ciency Ïƒ = 0.

136
T. Honold et al.
in Fv
q. For this we will employ a special case of the echelon-Ferrers construction for
general subspace codes [24], which involves only standard maximum rank distance
codes of full row rank. More details on the echelon-Ferrers construction can be found
in Chapter â€œConstructions of Constant Dimension Codesâ€. For maximum rank dis-
tance codes see Chapters â€œCodes Endowed with the Rank Metricâ€ and â€œConstructions
of Cyclic Subspace Codes and Maximum Rank Distance Codesâ€.
To this end, recall that every k-subspace X of Fv
q is the row space of a unique
â€œgeneratingâ€ matrix A âˆˆFkÃ—v
q
in reduced row-echelon form, which can be obtained
by applying the Gaussian elimination algorithm to an arbitrary generating matrix of
X. This matrix A is called canonical matrix of X, and is uniquely speciï¬ed by its k
pivot columns 1 â‰¤j1 < j2 < Â· Â· Â· < jk â‰¤v (forming a k Ã— k identity submatrix of A)
and the complementary submatrix B âˆˆFkÃ—(vâˆ’k)
q
, which has zero entries in positions
(i, j) with j â‰¤ji âˆ’i but otherwise can be arbitrary. The k-set { j1, . . . , jk} will be
named pivot set of X. The positions of the unrestricted entries in B form the Ferrers
diagram of an integer partition, as shown in the following for the cases v = 8, k = 3,
(i1, i2, i3) = (1, 2, 3), (2, 4, 7).
matrix shape
Ferrers diagram
integer partition
â›
â
1
0
0
âˆ—
âˆ—
âˆ—
âˆ—
âˆ—
0
1
0
âˆ—
âˆ—
âˆ—
âˆ—
âˆ—
0
0
1
âˆ—
âˆ—
âˆ—
âˆ—
âˆ—
â
â 
â€¢ â€¢ â€¢ â€¢ â€¢
â€¢ â€¢ â€¢ â€¢ â€¢
â€¢ â€¢ â€¢ â€¢ â€¢
15 = 5 + 5 + 5
â›
â
0
1
âˆ—
0
âˆ—
âˆ—
0
âˆ—
0
0
0
1
âˆ—
âˆ—
0
âˆ—
0
0
0
0
0
0
1
âˆ—
â
â 
â€¢ â€¢ â€¢ â€¢
â€¢ â€¢ â€¢
â€¢
8 = 4 + 3 + 1
(2.2)
The following lemma is a special case of [24, Lemma 2].
Lemma 1 If subspaces X, Y of Fv
q have disjoint pivot sets, they are itself disjoint
(i.e., X âˆ©Y = {0}).
Proof A nonzero vector in X must have its pivot (ï¬rst nonzero position) in the pivot
set of X, and similarly for Y. The result follows.
â–¡
Now we focus on the special case in which the pivot set is {1, . . . , k}, i.e., the
canonical matrix has the â€œsystematicâ€ form A = (Ik|B). For matrices A, B âˆˆFkÃ—v
q
the rank distance is deï¬ned as dR(A, B) := rk(A âˆ’B). Codes based on the rank
distance are discussed in detail in Chapter â€œCodes Endowed with the Rank Metricâ€.
The subspace distance of two k-subspaces with pivot set {1, . . . , k} can be computed
from the rank distance of the corresponding canonical matrices:
Lemma 2 ([64, Proposition 4]) Let X, Xâ€² be k-subspaces of Fv
q with canonical
matrices (Ik|B) and (Ik|Bâ€²), respectively. Then dS(X, Xâ€²) = 2 Â· dR(B, Bâ€²). 12
12More generally, this formula holds if X and Xâ€² have the same pivot set and B, Bâ€² âˆˆFkÃ—(vâˆ’k)
q
denote the corresponding complementary submatrices in their canonical matrices; see e.g. [63,
Corollary 3].

Partial Spreads and Vector Space Partitions
137
Proof The matrix

Ik B
Ik Bâ€²

generates X + Xâ€² and reduces via Gaussian elimina-
tion to

Ik
B
0 Bâ€² âˆ’B

. Hence dim(X + Xâ€²) = k + rk(Bâ€² âˆ’B) = k + dR(B, Bâ€²) and
dS(X, Xâ€²) = 2 dim(X + Xâ€²) âˆ’2k = 2 dR(B, Bâ€²).
â–¡
The so-called lifting construction [64, Sect. IV.A] associates with a matrix code
B âŠ†FkÃ—(vâˆ’k)
q
the constant-dimension code C in Fv
q whose codewords are the k-
spaces generated by (Ik|B), B âˆˆB. By Lemma 2, the code C is isometric to B with
scale factor 2. In particular, C is a partial k-spread if and only if B has minimum
rank distance dR(B) = k.
Lemma 3 There exists a partial k-spread S of size qvâˆ’k in Fv
q whose codewords
cover precisely the points outside the (v âˆ’k)-subspace S = {x âˆˆFv
q; x1 = x2 =
Â· Â· Â· = xk = 0}.
Proof Write n = v âˆ’k and consider a matrix representation M : Fqn â†’FnÃ—n
q
,
obtained by expressing the multiplication maps Î¼Î± : Fqn â†’Fqn, x â†’Î±x (which are
linear over Fq) in terms of a ï¬xed basis of Fqn/Fq. Then M(Î± + Î²) = M(Î±) + M(Î²),
M(Î±Î²) = M(Î±)M(Î²), M(1) = In, and hence all matrices in M(Fqn) are invertible
and have mutual rank distance n.13
Now let B âŠ†FkÃ—n
q
be the matrix code obtained from M(Fqn) by deleting the last
n âˆ’k rows, say, of every matrix. Then #B = qn and dR(B) = k. Hence by applying
the lifting construction to B we obtain a partial k-spread S in Fv
q of size qn = qvâˆ’k
(Lemma 2).
The codewords in S cover only points outside S (compare the proof of Lemma 1).
It remains to show that every such point is covered. This can be done by a counting
argument or in the following more direct fashion: Let a âˆˆFk
q \ {0}, b âˆˆFvâˆ’k
q
be arbi-
trary vectors and consider the equation aX = b for X âˆˆB. Since rk(X âˆ’Xâ€²) = k
for X Ì¸= Xâ€², the qvâˆ’k elements aX, X âˆˆB, are distinct and hence account for
all elements in Fvâˆ’k
q
. Thus the equation has a solution B âˆˆB, and the point
P = Fq(a|b) = Fqa(Ik|B) is covered by the codeword in S with canonical matrix
(Ik|B).
â–¡
Now we are ready for the promised construction of large partial k-spreads.
Theorem 2 ([7]) Let v, k be positive integers satisfying v = tk + r, t â‰¥2 and 1 â‰¤
r â‰¤k âˆ’1. There exists a partial k-spread S in Fv
q of size
#S = 1 +
tâˆ’1

s=1
qvâˆ’sk = 1 +
tâˆ’1

s=1
qsk+r,
and hence we have Aq(v, 2k; k) â‰¥1 + 	tâˆ’1
s=1 qsk+r.
13In ring-theoretic terms, the matrices in M(Fqn) form a maximal subï¬eld of the ring of n Ã— n
matrices over Fq.

138
T. Honold et al.
The corresponding bound for the deï¬ciency is Ïƒ â‰¤qr âˆ’1. It depends only on k and
the residue r = v mod k.
It had been conjectured in [21, Sect.2.2] that Ïƒ = qr âˆ’1 in general, but this
conjecture was later disproved in [22] by exhibiting a maximal partial plane spread
of size 34 in F8
2, which has deï¬ciency 22 âˆ’2.
Proof The proof is by induction on t, using Lemma 2 and applying the inductive
hypothesis to S âˆ¼= Fvâˆ’k
q
. The case v = k + r, in which Aq(v, 2k; k) = 1, serves as
the anchor of the induction.
â–¡
The partial spread S exhibited in the proof of Theorem 2 consists of t âˆ’1 â€œlayersâ€
S1, â€¦, Stâˆ’1 of decreasing sizes #Ss = qvâˆ’sk, whose codewords are obtained from
matrix representations of Fqvâˆ’sk and have their pivots in positions (s âˆ’1)k + 1, (s âˆ’
1)k + 2, â€¦, sk (hence vanish on the ï¬rst (s âˆ’1)k coordinates). The union tâˆ’1
s=1 Ss
leaves exactly the points of a (k + r)-subspace S of Fv
q (the span of the last k + r
standard unit vectors) uncovered. Finally, one further k-subspace S0 of S is selected
to form S = tâˆ’1
s=1 Ss âˆª{S0}.14
Example 2 We consider the particular case q = 2, v = 5, k = 3, in which #S =
23 + 1 = 9. In this case there is only one layer S1, which can be obtained from a
matrix representation of F8 as follows: Representing F8 as F2(Î±) with Î±3 + Î± + 1 =
0, we ï¬rst express the powers Î± j, 0 â‰¤j â‰¤6 in terms of the basis 1, Î±, Î±2 of F8/F2,
as in the following matrix:
M =
Î±0 Î±1 Î±2 Î±3 Î±4 Î±5 Î±6 Î±0 Î±1
Î±0 1
0
0
1
0
1
1
1
0
Î±1 0
1
0
1
1
1
0
0
1
Î±2 0
0
1
0
1
1
1
0
0
(2.3)
The seven consecutive 3 Ã— 3 submatrices of this matrix, which has been extended to
the right in order to mimic the cyclic wrap-around, form a matrix ï¬eld isomorphic
to F8 (with 0 âˆˆF3Ã—3
2
added). Similarly, the code B âŠ‚F2Ã—3
2
is obtained by extracting
the ï¬rst seven consecutive 3 Ã— 2 submatrices, adding 0 âˆˆF3Ã—2
2
, and transposing; cf.
the proof of Lemma 3). Prepending the 2 Ã— 2 identity matrix then gives the canonical
matrices of the 8 codewords of S1:

 1 0 0 0 0
0 1 0 0 0

,

 1 0 1 0 0
0 1 0 1 0

,

 1 0 0 1 0
0 1 0 0 1

,

 1 0 0 0 1
0 1 1 1 0

,

 1 0 1 1 0
0 1 0 1 1

,

 1 0 0 1 1
0 1 1 1 1

,

 1 0 1 1 1
0 1 1 0 1

,

 1 0 1 0 1
0 1 1 0 0

.
Finally, from the seven lines in the plane S = {x âˆˆF5
2; x1 = x2 = 0} a 9th codeword
L0 (moving line) is selected to form S = S1 âˆª{L0}.
14The space S0 has been named moving subspace of S , since it can be freely â€œmovedâ€ within S
without affecting the partial spread property of S .

Partial Spreads and Vector Space Partitions
139
The partial line spread S is in fact maximal, as we will see in a moment,
and represents one of the 4 isomorphism types of maximal partial line spreads in
PG(F5
2) = PG(4, F2).15
Now we will reduce the upper bound (2.1) by a summand of q âˆ’1, which is
sufï¬cient to settle the caser = 1 and hence determine the numbers Aq(tk + 1, 2k; k).
The key ingredient will be the observation that a partial k-spread induces in every
hyperplane a vector space partition, whose members have dimension k, k âˆ’1, or
1. Before turning to the general case, which is a little technical, we continue the
preceding example and illustrate the method for partial line spreads in F5
2.
The geometry PG(4, F2) has 31 points, each line containing 3 points, and thus it
is conceivable that a partial line spread S of size 10 exists in PG(4, F2). But in fact it
does not. To prove this, consider a hyperplane (solid) H in PG(4, F2). If H contains
Î± lines of S , it meets the remaining #S âˆ’Î± lines in a point, giving the constraint
Î± Â· 3 + (#S âˆ’Î±) Â· 1 â‰¤15, the total number of points in H. This is equivalent to
#S â‰¤15 âˆ’2Î±. In order to complete the proof, we need to show that there exists
a hyperplane containing at least 3 lines of S . This can be done by an averaging
argument. On average, a hyperplane contains

H
#{L âˆˆS ; L âŠ‚H}
25 âˆ’1
=

LâˆˆS
#{H; H âŠƒL}
25 âˆ’1
= #S (23 âˆ’1)
25 âˆ’1
= 7
31 Â· #S
(2.4)
lines of S . If #S â‰¥9, this number is > 2, implying the desired conclusion Ïƒ â‰¥1.16
The general case is the subject of the following
Theorem 3 ([21, Theorem 2.7(a)]) The deï¬ciency of a maximal k-spread in Fv
q,
where k does not divide v, is at least q âˆ’1.
Proof Reasoning as in the preceding example gives Î± Â· qkâˆ’1
qâˆ’1 + (#S âˆ’Î±) qkâˆ’1âˆ’1
qâˆ’1
â‰¤
qtk+râˆ’1âˆ’1
qâˆ’1
and hence the bound
#S â‰¤qtk+râˆ’1 âˆ’1 âˆ’Î±(qk âˆ’qkâˆ’1)
qkâˆ’1 âˆ’1
(2.5)
for any partial k-spread S having a hyperplane incident with Î± members of S .
Now suppose #S = 1 + 	tâˆ’1
s=1 qsk+r, the same size as the partial k-spread in
Theorem 2. In this case the average number of codewords contained in a hyperplane is
15The full classiï¬cation, including also partial line spreads of smaller size, can be found in [26].
To our best knowledge there is only one further nontrivial parameter case, where a classiï¬cation of
maximal (proper) partial spreads is known, viz. the case of plane spreads in PG(6, F2), settled in
[38].
16In this particular case one may also argue as follows: If #S = 10 then there is only one hole and
the hyperplane constraint becomes 3Î± + (10 âˆ’Î±) + h = 15, where h âˆˆ{0, 1}. This forces Î± = 2
and h = 1, i.e., every hyperplane should contain the hole. This is absurd, of course.

140
T. Honold et al.
q(tâˆ’1)k+r âˆ’1
qtk+r âˆ’1

1 +
tâˆ’1

s=1
qsk+r

=
1
qtk+r âˆ’1
2tâˆ’2

s=t
qsk+2r âˆ’
tâˆ’2

s=1
qsk+r âˆ’1

=
1
qtk+r âˆ’1
2tâˆ’2

s=t
qsk+2r âˆ’
tâˆ’2

s=0
qsk+r + qr âˆ’1

=
tâˆ’2

s=0
qsk+r +
qr âˆ’1
qtk+r âˆ’1.
It follows that S , and likewise all partial k-spreads of deï¬ciency â‰¤qr âˆ’1, have a
hyperplane containing at least 1 + 	tâˆ’2
s=0 qsk+r codewords. Substituting this number
into (2.5) gives
#S â‰¤
1
qkâˆ’1 âˆ’1

qtk+râˆ’1 âˆ’1 âˆ’

1 +
tâˆ’2

s=0
qsk+r

(qk âˆ’qkâˆ’1)

=
1
qkâˆ’1 âˆ’1

qtk+râˆ’1 âˆ’1 âˆ’qk + qkâˆ’1 âˆ’
tâˆ’1

s=1
qsk+r +
tâˆ’2

s=0
qsk+r+kâˆ’1

= 1 +
tâˆ’2

s=1
qsk+r + qtk+râˆ’1 âˆ’qk âˆ’q(tâˆ’1)k+r + qr+kâˆ’1
qkâˆ’1 âˆ’1
= 1 +
tâˆ’1

s=1
qsk+r + qr+kâˆ’1 âˆ’qk
qkâˆ’1 âˆ’1
= 1 +
tâˆ’1

s=1
qsk+r + qr âˆ’q + qr âˆ’q
qkâˆ’1 âˆ’1
=
tâˆ’1

s=0
qsk+r âˆ’(q âˆ’1) + qr âˆ’q
qkâˆ’1 âˆ’1,
valid now for any partial k-spread S in Fv
q. Since the last summand is < 1, we obtain
the desired conclusion Ïƒ â‰¥q âˆ’1.
â–¡
Theorem 3 has the following immediate corollary, established by Beutelspacher
in 1975, which settles the case r = 1 completely.
Corollary 1 ([Theorem 4.1]; see also [7, 36] for the special case q = 2)
For
integers k â‰¥2 and v = tk + 1 with t â‰¥1 we have Aq(v, 2k; k) = 1 + 	tâˆ’1
s=1 qsk+1,17
with corresponding deï¬ciency Ïƒ = q âˆ’1.18
In particular, maximal partial line spreads in Fv
q, v odd (the case where no line
spreads exist), have size qvâˆ’2 + qvâˆ’4 + Â· Â· Â· + q3 + 1, deï¬ciency q âˆ’1, and q2 holes.
17This can also written as Aq(v, 2k; k) = q1 Â· qvâˆ’1âˆ’1
qkâˆ’1 âˆ’q + 1 = qvâˆ’qk+1+qkâˆ’1
qkâˆ’1
.
18The corresponding number of holes is qk.

Partial Spreads and Vector Space Partitions
141
In his original proof of the corollary Beutelspacher considered the set of holes
N and the average number of holes per hyperplane, which is less than the total
number of holes divided by q. An important insight was the relation #N â‰¡#(H âˆ©N)
(mod qkâˆ’1) for each hyperplane H, i.e., the number of holes per hyperplane satisï¬es
a certain modulo constraint. We will see this concept in full generality in Sect.3.
In terms of integer linear programming, the upper bound is obtained by an integer
rounding cut. The construction in [7, Theorem 4.2] recursively uses arbitrary kâ€²-
spreads, so that it is more general than the one of Theorem 2.
For a long time the best known upper bound on Aq(v, 2k; k), i.e., the best known
lower bound on Ïƒ, was the one obtained by Drake and Freeman in 1979:
Theorem 4 (Corollary 8 in [20]) The deï¬ciency of a maximal partial k-spread in Fv
q
is at least âŒŠÎ¸âŒ‹+ 1 = âŒˆÎ¸âŒ‰,19 where 2Î¸ =

1 + 4qk(qk âˆ’qr) âˆ’(2qk âˆ’2qr + 1).
The authors concluded from the existence of a partial spread the existence of
a (group-constructible) (s,r, Î¼)-net and applied [11, Theorem 1B]â€”a necessary
existence criterion formulated for orthogonal arrays of strength 2 by Bose and Bush
in 1952. The underlying proof technique can be further traced back to [60] and is
strongly related to the classical second-order Bonferroni Inequality [10, 25]; see also
[39, Sect.2.5] for an application to bounds for subspace codes.
Given Theorem 1 and Corollary 1, the ï¬rst open binary case is A2(8, 6; 3). The
constructionfromTheorem2givesapartialspreadofcardinality33,whileTheorem4
implies an upper bound of 34. As already mentioned, in 2010 El-Zanati et al. [22]
found a sporadic partial plane spread in F8
2 of cardinality 34 by a computer search.
Together with the following easy lemma, this completely answers the situation for
partial plane spreads in Fv
2; see Corollary 2 below.
Lemma 4 For ï¬xed q, k and r the deï¬ciency Ïƒ is a non-increasing function of
v = kt + r.
Proof Let S be a maximal partial k-spread in Ftk+r
q
and Ïƒ its deï¬ciency, so that
Aq(tk + r, 2k; k) = 	tâˆ’1
s=0 qsk+r âˆ’Ïƒ. We can embed S into F(t+1)k+r
q
by prepending
k zeros to each codeword. Then Lemma 3 can be applied and yields a partial k-
spread S â€² in F(t+1)k+r
q
of size qtk+r, whose codewords are disjoint from those in S .
This implies Aq((t + 1)k + r, 2k; k) â‰¥#S âˆªS â€² = 	t
s=0 qsk+r âˆ’Ïƒ, and hence the
deï¬ciency Ïƒ â€² of a maximal partial k-spread in F(t+1)k+r
q
satisï¬es Ïƒ â€² â‰¤Ïƒ.
â–¡
So, any improvement of the best known lower bound for a single parameter case
gives rise to an inï¬nite series of improved lower bounds. Unfortunately, so far, the
sporadic construction in [22] is the only known example being strictly superior to
the general construction of Theorem 2.
19Assuming 1 + 4qk(qk âˆ’qr) = 1 + 4qk+r(qkâˆ’r âˆ’1) = (2z âˆ’1)2 = 1 + 4z(z âˆ’1) for some
integer z > 1 implies qk+r | z or qk+r | z âˆ’1, so that z â‰¥qk+r, which is impossible for (k,r) Ì¸=
(1, 0). Thus, 2Î¸ /âˆˆZ, so that Î¸ /âˆˆZ and âŒŠÎ¸âŒ‹+ 1 = âŒˆÎ¸âŒ‰.

142
T. Honold et al.
Corollary 2 For each integer m â‰¥2 we have A2(3m, 6; 3) = 23mâˆ’1
7
, A2(3m +
1, 6; 3) = 23m+1âˆ’9
7
, and A2(3m + 2, 6; 3) = 23m+2âˆ’18
7
. The corresponding deï¬ciencies
are 0, 1 and 2, respectively.
Very recently, the case q = r = 2 was completely settled. For k = 3 the answer
is given in the preceding corollary, and for k â‰¥4 by the following
Theorem 5 ([46, Theorem 5]) For integers k â‰¥4 and v = tk + 2 with t â‰¥1 we
have Ïƒ = 3 and A2(kt + 2, 2k; k) = 1 + 	tâˆ’1
s=1 2tk+2 = 2kt+2âˆ’3Â·2kâˆ’1
2kâˆ’1
.20
The technique used to prove this theorem is very similar to the one presented in
the proof of Theorem 3.
Corollary 3 We
have
A2(4m, 8; 4) = 24mâˆ’1
15 .
A2(4m + 1, 8; 4) = 24m+1âˆ’17
15
,
A2(4m + 2, 8; 4) = 24m+2âˆ’49
15
, and 24m+3âˆ’113
15
â‰¤A2(4m + 3, 8; 4) â‰¤24m+3âˆ’53
15
for all
m â‰¥2. The corresponding deï¬ciencies are 0, 1, 3 and 3 â‰¤Ïƒ â‰¤7, respectively
As a consequence, the ï¬rst unknown binary case is now 129 â‰¤A2(11, 8; 4) â‰¤
133.21 For r = 2 and q = 3 the upper bound of Theorem 4 has been decreased by 1:
Lemma 5 (cf.[46, Lemma 4]) For integers t â‰¥2 and k â‰¥4, we have Ïƒ â‰¥5 and
A3(kt + 2, 2k; k) â‰¤3kt+2âˆ’32
3kâˆ’1
âˆ’5.
Again, the proof technique is very similar to that used in the proof of Theorem 3.
Theorem 2 is asymptotically optimal for k â‰«r = v mod k, as recently shown by
NË˜astase and Sissokho:
Theorem 6 ([59, Theorem 5]) If k >
r
1

q then Ïƒ = qr âˆ’1 and Aq(v, 2k; k) =
1 + 	tâˆ’1
s=1 qsk+r.22
Choosing q = r = 2, this result covers Theorem 5. The same authors have reï¬ned
their analysis, additionally using Theorem 14 from the theory of vector space par-
titions, to obtain improved upper bounds for some of the cases k â‰¤
r
1

q, see [58,
Theorem 6 and 7]. Using the theory of qr-divisible codes, presented in the next
section, we extend their results further in Corollary 7 and Theorem 10.
3
qr-divisible Sets and Codes
The currently most effective approach to good upper bounds for partial spreads
follows the original idea of Beutelspacher and considers the set of holes as a stand-
alone object. As it appears in the proof of Beutelspacher, the number of holes in a
20Thus in all these cases Ïƒ = 22 âˆ’1 and the partial spreads of Theorem 2 are maximal. This notably
differs from the case k = 3.
21The upper bound can be sharpened to 132, as we will see later.
22This corresponds again to the upper bound Ïƒ = qr âˆ’1.

Partial Spreads and Vector Space Partitions
143
hyperplane satisï¬es a certain modulo constraint. In this section we consider sets of
points in PG(v âˆ’1, Fq) having the property that modulo some integer Î” > 1 the
number of points in each hyperplane is the same. Such point sets are equivalent
to Î”-divisible codes [68, 69] with projectively distinct coordinate functionals (so-
called projective codes), and this additional restriction forces Î” to be a power of
the same prime as q. Writing q = pe, p prime, and Î” = p f , we have Î” = qr with
r = f/e âˆˆ1
eZ.
We will derive several important properties of these qr-divisible sets and codes
and in particular observe that the set of holes of a partial spread is exactly of this type.
Without the notion of qr-divisible sets and the reference to the linear programming
method, almost all results of this section are contained in [47, 48]. A more extensive
introduction to the topic, including constructions and relations to other combinatorial
objects, is currently in preparation [31].
In what follows, we denote the point set of PG(v âˆ’1, Fq) by P and call for
subsets C âŠ†P and subspaces X of Fv
q the integer #(C âˆ©X) = #{P âˆˆC ; P âŠ†X}
the multiplicity of X with respect to C .
Deï¬nition 1 Let Î” > 1 be an integer. A set C of points in PG(v âˆ’1, Fq) is called
weakly Î”-divisible if there exists u âˆˆZ with #(C âˆ©H) â‰¡u (mod Î”) for each
hyperplane H of PG(v âˆ’1, Fq). If u â‰¡#C (mod Î”), we call C (strongly) Î”-
divisible.
Trivial cases are C = âˆ…(strongly Î”-divisible for any Î”) and C = P (weakly Î”-
divisible for any Î”, with largest strong divisor Î” = qvâˆ’1).23
It is well-known (see, e.g., [18, 65, Proposition 1]) that the relation C â†’C , asso-
ciating with a full-length linear [n, v] code C over Fq the n-multiset C of points in
PG(v âˆ’1, Fq) deï¬ned by the columns of any generator matrix, induces a one-to-one
correspondence between classes of (semi-)linearly equivalent spanning multisets and
classes of (semi-)monomially equivalent full-length linear codes. Point sets corre-
spond in this way to projective linear codes, which are also characterized by the
condition d(CâŠ¥) â‰¥3. The importance of the correspondence lies in the fact that it
relates coding-theoretic properties of C to geometric or combinatorial properties of
C . An example is the formula
w(aG) = n âˆ’#{1 â‰¤j â‰¤n; a Â· g j = 0} = n âˆ’#(C âˆ©aâŠ¥),
(3.1)
where w denotes the Hamming weight, G = (g1| . . . |gn) âˆˆFvÃ—n
q
a generating matrix
of C, a Â· b = a1b1 + Â· Â· Â· + avbv, and aâŠ¥is the hyperplane in PG(v âˆ’1, Fq) with
equation a1x1 + Â· Â· Â· + avxv = 0.
A linear code C is said to be Î”-divisible (Î” âˆˆZ>1) if all nonzero codeword
weights are multiples of Î”. A lower bound on the cardinality of Î”-divisible point
sets in PG(v âˆ’1, Fq) has been given in [3]. Following the Gleason-Pierce-Ward
Theorem on the divisibility of self-dual codes (see, e.g., [40, Chap. 9.1]), a rich
theory of divisible codes has been developed over time, mostly by H. N. Ward; cf.
23This is also true for v = 1, where C = âˆ…, P exhausts all possibilities.

144
T. Honold et al.
his survey [69]. One of Wardâ€™s results implies that nontrivial weakly Î”-divisible point
sets in PG(v âˆ’1, Fq) are strongly Î” divisible and exist only in the case Î” = p f .
The proof uses the so-called standard equations for the hyperplane spectrum of C ,
which we state in the following lemma. The standard equations are equivalent to the
ï¬rst three MacWilliams identities for the weight enumerators of C and CâŠ¥(stated
as Equation (3.6) below), specialized to the case of projective linear codes. The
geometric formulation, however, seems more in line with the rest of the paper.
Lemma 6 Let C be a set of points in PG(v âˆ’1, Fq) with #C = n, and let ai hyper-
planes of PG(v âˆ’1, Fq) contain exactly i points of C (0 â‰¤i â‰¤n). Then we have
n

i=0
ai =
v
1

q
,
(3.2)
n

i=1
iai = n Â·
v âˆ’1
1

q
,
(3.3)
n

i=2

i
2

ai =

n
2

Â·
v âˆ’2
1

q
.
(3.4)
Proof Double-count24 incidences of the tuples (H), (P1, H), and ({P1, P2}, H),
where H is a hyperplane and P1 Ì¸= P2 are points contained in H.
â–¡
IntheproofofTheorem7wewillneedthat (3.2)and (3.3)remaintrueforanymultiset
C of points in PG(v âˆ’1, Fq), provided points are counted with their multiplicities
in C and the cardinality #C is deï¬ned in the obvious way. We will also need the
following concept of a quotient multiset. Let C be a set of points in PG(v âˆ’1, Fq)
and X a subspace of Fv
q. Deï¬ne the multiset C /X of points in the quotient geometry
PG(Fv
q/X) by assigning to a point Y/X of PG(Fv
q/X) (i.e., Y satisï¬es dim(Y/X) =
1) the difference #(C âˆ©Y) âˆ’#(C âˆ©X) = #(C âˆ©Y \ X) as multiplicity.25 With this
deï¬nition it is obvious that #(C /X) = #C âˆ’#(C âˆ©X). In particular, if C is an n-set
and X = P is a point then #(C /P) = n âˆ’1 or n, according to whether P âˆˆC or
P /âˆˆC , respectively.26
24The general (multiset) version of (3.4) has an additional summand of qvâˆ’2 Â· 	
PâˆˆP
C (P)
2

on
the right-hand side, accounting for the fact that â€œpairs of equal pointsâ€ are contained in
vâˆ’1
1

q
hyperplanes.
25This deï¬nition can be extended to multisets C by deï¬ning the multiplicity of Y/X in C /X as the
sum of the multiplicities in C of all points in Y \ X.
26If C â†”C then the multisets C /P, P âˆˆP, are associated to the (v âˆ’1)-dimensional subcodes
D âŠ‚C, and the n points P âˆˆC correspond to the n subcodes D of effective length n âˆ’1 (â€œD is C
shortenedat Pâ€).Thiscorrespondencebetweenpointsandsubcodesextendstoacorrelationbetween
PG(v âˆ’1, Fq) and PG(C/Fq), which includes the familiar correspondence between hyperplanes
and codewords as a special case; see [18, 65] for details.

Partial Spreads and Vector Space Partitions
145
Theorem 7 Let C Ì¸= âˆ…, P be a weakly Î”-divisible point set in PG(v âˆ’1, Fq), n =
#C , and C any linear [n, v]-code over Fq associated with C as described above.27
Then
(i) C is strongly Î”-divisible;
(ii) C is Î”-divisible;
(iii) Î” is a divisor of qvâˆ’2.
Proof (i) and (ii) are equivalent in view of (3.1).
First we prove (i). Let u be as in Deï¬nition 1. Choose a point P /âˆˆC and let
C â€² = C /P. Then C â€² is an n-multiset of points in PG(Fv
q/P) âˆ¼= PG(v âˆ’2, Fq) with
#(C â€² âˆ©H â€²) â‰¡u (mod Î”) for each hyperplane H â€² of PG(Fv
q/P). The hyperplane
spectrum (aâ€²
i) of C â€² satisï¬es (3.3) with v replaced by v âˆ’1. Multiplying the identity
for C â€² by q and subtracting from it the identity for C gives

iâ‰¥0
(u + iÎ”)(au+iÎ” âˆ’qaâ€²
u+iÎ”) = n

qvâˆ’1 âˆ’1
q âˆ’1
âˆ’qvâˆ’1 âˆ’q
q âˆ’1

= n.
Reading this equation modulo Î” and using (3.2) further gives
n â‰¡u

iâ‰¥0
(au+iÎ” âˆ’qaâ€²
u+iÎ”) = u

qv âˆ’1
q âˆ’1 âˆ’qv âˆ’q
q âˆ’1

= u
(mod Î”),
as desired. Thus (i) and (ii) hold.
For the proof of (iii) we use a point Q âˆˆC and its associated quotient multiset
C â€²â€² = C /Q, which satisï¬es #C â€²â€² = n âˆ’1 and #(C â€²â€² âˆ©H â€²â€²) â‰¡u âˆ’1 (mod Î”) for
each hyperplane H â€²â€² of PG(Fv
q/Q). Subtracting (3.3) for C â€² and C â€²â€² gives

iâ‰¥0
(u + iÎ”)aâ€²
u+iÎ” âˆ’

iâ‰¥0
(u âˆ’1 + iÎ”)aâ€²â€²
uâˆ’1+iÎ” = qvâˆ’2 âˆ’1
q âˆ’1 .
Again reading the equation modulo Î” and using (3.2) gives
qvâˆ’2 âˆ’1
q âˆ’1
â‰¡u

iâ‰¥0
aâ€²
u+iÎ” âˆ’(u âˆ’1)

iâ‰¥0
aâ€²â€²
uâˆ’1+iÎ” = qvâˆ’1 âˆ’1
q âˆ’1
(mod Î”)
or qvâˆ’2 â‰¡0 (mod Î”), as asserted.
â–¡
Let us remark that Part (ii) of Theorem 7 also follows from [68, Theorem 3], which
asserts that a not necessarily projective code C satisfying the assumption of the
theorem must be either Î”-divisible or the juxtaposition of a Î”-divisible code and a
v-dimensional linear constant weight code. Since the latter is necessarily a repetition
27It is not required that C is spanning; if it is not then (iii) sharpens to â€œÎ” is a divisor of qdimâŸ¨C âŸ©âˆ’2â€.

146
T. Honold et al.
of simplex codes, this case does not occur for projective codes. Our proofs of (i),
(iii) use the very same ideas as in [68], translated into the geometric framework.28
Part (iii) of Theorem 7 says that exactly Î”-divisible point sets in PG(v âˆ’1, Fq)
exist only if Î” = qr with r âˆˆ1
eZ and r â‰¤v âˆ’129; the whole point set P has Î” =
qvâˆ’1, and v âˆ’2 < r < v âˆ’1 does not occur. Conversely, it is not difï¬cult to see that
everydivisorÎ” > 1ofqvâˆ’2 isthelargestdivisorofsomepointsetinPG(v âˆ’1, Fq).30
In the proof of Theorem 7 we have used that the (weak) divisibility properties of
C and its quotient multisets C /X are the same. Now we consider the restrictions
C âˆ©X, which correspond to residual codes of the associated code C.
Lemma 7 Suppose that C is a qr-divisible set of points in PG(v âˆ’1, Fq) and X a
(v âˆ’j)-subspace of Fv
q with 1 â‰¤j < r. Then the restriction C âˆ©X is qrâˆ’j-divisible.
Proof By induction, it sufï¬ces to consider the case j = 1, i.e., X = H is a hyperplane
in PG(v âˆ’1, Fq).
The hyperplanes of PG(H) are the (v âˆ’2)-subspaces of Fv
q contained in H. Hence
the assertion is equivalent to #(C âˆ©U) â‰¡#C = u (mod qrâˆ’1) for every (v âˆ’2)-
subspace U âŠ‚Fv
q. By assumption we have #(C âˆ©Hi) â‰¡u (mod qr) for the q + 1
hyperplanes H1, . . . , Hq+1 lying above U. This gives
(q + 1)u â‰¡
q+1

i=1
#(C âˆ©Hi) = q Â· #(C âˆ©U) + #C â‰¡q Â· #(C âˆ©U) + u
(mod qr)
and hence u â‰¡#(C âˆ©U) (mod qrâˆ’1), as claimed.
â–¡
As mentioned at the beginning of this section, the set of holes of a partial spread
provides an example of a qr-divisible set. The precise statement is given in the
following theorem, which is formulated for general vector space partitions.
Theorem 8 (i) Let C be a vector space partition of Fv
q of type tmt Â· Â· Â· sms1m1 with
ms > 0 (i.e., C has a member of dimension > 1 and s chosen as the smallest
such dimension). Then the points (i.e., 1-subspaces) in C form a qsâˆ’1-divisible
set.
(ii) The holes of a partial k-spread in Fv
q form a qkâˆ’1-divisible set.
Proof It is immediate that (i) implies (ii). For the proof of (i) let H be a hyperplane
of PG(v âˆ’1, Fq). The points in P \ H are partitioned into the afï¬ne subspaces
X \ H for those X âˆˆC satisfying X âŠˆH. If such a t-subspace X is not a point, we
have t â‰¥s and hence #(X \ H) = qtâˆ’1 â‰¡0 (mod qsâˆ’1). Moreover, we also have
#(P \ H) = qvâˆ’1 â‰¡0 (mod qsâˆ’1). It follows that the number of points in C that
are not contained in H is divisible by qsâˆ’1 as well, completing the proof.
â–¡
28Readers may have noticed that, curiously, the 3rd standard equation (which characterizes projec-
tive codes) was not used at all in the proof.
29By this we mean that Î” is the largest divisor in the sense of Deï¬nition 1 or Theorem 7.
30If t = âŒŠrâŒ‹and râ€² âˆˆ{0, 1, . . . , e âˆ’1} is deï¬ned by r = t + râ€²/e, then the union of prâ€² parallel
afï¬ne subspaces of dimension t + 1 has this property.

Partial Spreads and Vector Space Partitions
147
Theorem 8 explains our motivation for studying qr-divisible points sets in PG(v âˆ’
1, Fq). Before delving deeper into this topic, we pause for a few example applications
to partial spreads, which may help advertising our approach.
First we consider the problem of improving the upper bound (2.1) for the size
of a partial k-spread in PG(v âˆ’1, Fq). The bound is equivalent to #C â‰¥qrâˆ’1
qâˆ’1 for
the corresponding hole sets, which are qkâˆ’1-divisible by Theorem 8(ii). But the
smallest nontrivial qkâˆ’1-divisible point sets in PG(v âˆ’1, Fq) are the k-subspaces
of Fv
q, since these are associated to the constant-weight-qkâˆ’1 simplex code.31 Thus
#C â‰¥qkâˆ’1
qâˆ’1 > qrâˆ’1
qâˆ’1 , and equality in (2.1) is not possible. Together with Theorem 2
this already gives the numbers A2(tk + 1, 2k; k).
The preceding argument gives A2(8, 6; 3) â‰¤35, and as a second application, we
now exclude the existence of a partial plane spread of size 35 in F8
2. As already
mentioned, this also follows from the Drake-Freeman bound (Theorem 4) and forms
an important ingredient in the determination of the numbers A2(v, 6; 3). The hole
set C of such a partial plane spread has size 28 âˆ’1 âˆ’35 Â· 7 = 10 and is 4-divisible,
i.e., it meets every hyperplane in 2 or 6 points.
We claim that dimâŸ¨C âŸ©= 4. The inequality dimâŸ¨C âŸ©â‰¥4 is immediate from #C =
10. The reverse inequality follows from the fact that the linear code C associated
with C is doubly-even, hence self-orthogonal, but cannot be self-dual.32
Given that dimâŸ¨C âŸ©= 4, the existence of C is readily excluded using the standard
equations:
a2 +
a6 = 15,
2a2 +
6a6 = 10 Â· 7,
2
2

a2 +
6
2

a6 =
10
2

Â· 3.
(3.5)
The unique solution of the ï¬rst two equations is a2 = 5, a6 = 10 (corresponding to
the 2-fold repetition of the [5, 4, 2] even-weight code), but it does not satisfy the
third equation (since this code is not projective).33
As already mentioned, the standard equations in Lemma 6 have a natural gen-
eralization in the language of linear codes. To this end let C be a point set of size
#C = n in PG(k âˆ’1, Fq), which is spanning,34 and C the corresponding projective
linear [n, k] code over Fq. The hyperplane spectrum (ai)0â‰¤iâ‰¤n of C and the weight
distribution (Ai)0â‰¤iâ‰¤n of C are related by Ai = (q âˆ’1)anâˆ’i for 1 â‰¤i â‰¤n (supple-
mented by A0 = 1, an = 0) and hence provide the same information about C . The
famous MacWilliams Identities, [53]
31This follows, e.g., by applying the Griesmer bound to the associated linear code, which has
minimum distance â‰¥qkâˆ’1 and dimension â‰¥k.
32Just recall that the length of any doubly-even self-dual binary code must be a multiple of 8.
33Adding 20 = 5 Â· 4, which accounts for the 5 pairs of equal points in the code, to the right-hand
side â€œcorrectsâ€ the third equation.
34This assumption is necessary for the relation Ai = (q âˆ’1)anâˆ’i to hold.

148
T. Honold et al.
nâˆ’i

j=0

n âˆ’j
i

A j = qkâˆ’i Â·
i
j=0

n âˆ’j
n âˆ’i

AâŠ¥
j
for 0 â‰¤i â‰¤n,
(3.6)
relate the weight distributions (Ai), (AâŠ¥
i ) of the (primal) code C and the dual code
CâŠ¥= {y âˆˆFn
q; x1y1 + Â· Â· Â· + xnyn = 0 for all x âˆˆC}. They can be solved for Ai (or
AâŠ¥
i ), resulting in linear relations whose coefï¬cients are values of Krawtchouk poly-
nomials; see, e.g., [40, Chap 7.2] for details. In our case we have AâŠ¥
1 = AâŠ¥
2 = 0,
since CâŠ¥has minimum distance dâŠ¥â‰¥3, and the ï¬rst three equations in (3.6) are
equivalent to the equations in Lemma 6.
Of course the Ai and the AâŠ¥
i in (3.6) have to be non-negative integers. Omitting the
integrality condition yields the so-called linear programming method, see e.g. [40,
Sect.2.6], where the Ai and AâŠ¥
i are variables satisfying the mentioned constraints.35
Given some further constraints on the weights of the code and/or the dual code, one
may check whether the corresponding polyhedron contains non-negative rational
solutions. In general, this is a very powerful approach and was used to compute
bounds for codes with a given minimum distance; see [15, 52]. Here we consider a
subset of the MacWilliams identities and use analytical arguments.36
By considering the average number of points per hyperplane, we can guarantee
the existence of a hyperplane containing a relatively small number of points of C . If
this number is nonzero, Lemma 7 allows us to lower-bound #C by induction.37
Lemma 8 Suppose that C Ì¸= âˆ…in PG(v âˆ’1, Fq) is qr-divisible with #C = a Â·
qr+1 + b for some a, b âˆˆZ and y âˆˆN0 with y â‰¡(q âˆ’1)b (mod qr+1). Then
there exists a hyperplane H such that #(C âˆ©H) â‰¤(a âˆ’1) Â· qr + b+y
q
âˆˆZ and
#(C âˆ©H) â‰¡b (mod qr).
Proof Set n = #C and choose a hyperplane H such that nâ€² := #(C âˆ©H) is minimal.
Then, by considering the average number of points per hyperplane, we have
nâ€² â‰¤
1
v
1

q
Â·

hyperplane Hâ€²
#(C âˆ©Hâ€²) = n Â·
v âˆ’1
1

q
/
v
1

q
< n
q = a Â· qr + b
q â‰¤a Â· qr + b + y
q
.
Since nâ€² â‰¡b â‰¡b+y
q
(mod qr), this implies nâ€² â‰¤(a âˆ’1)qr + b+y
q .
â–¡
Note that the stated upper bound does not depend on the speciï¬c choice of a and
b, i.e., there is no need to take a non-negative or small b. Choosing y as small as
35Typically, the AâŠ¥
i are removed from the formulation using the explicit formulas based on the
Krawtchouk polynomials, which may of course also be done automatically in the preprocessing
step of a customary linear programming solver.
36The use of a special polynomial, like we will do, is well known in the context of the linear
programming method, see e.g. [9, Sect.18.1].
37This result is not new at all. In [7] Beutelspacher used such an average argument in his upper
bound on the size of partial spreads. Recently, NË˜astase and Sissokho used it in [59, Lemma 9]. In
coding theory it is well known in the context of the Griesmer bound. One may also interpret it as
an easy implication of the ï¬rst two MacWilliams identities, see Lemma 20 and Corollary 9.

Partial Spreads and Vector Space Partitions
149
possible clearly gives the sharpest bound.38 If b â‰¥0, which one can always achieve
by suitably decreasing a, it is always possible to choose y = (q âˆ’1)b. However,
for q = 3, r = 2, and #C = 1 Â· 33 + 16 = 43, i.e., a = 1 and b = 16, Lemma 8
with y = (2 âˆ’1)16 = 16 provides the existence of a hyperplane H with nâ€² = #(C âˆ©
H) â‰¤0 Â· 32 + 16 = 16. Using y = 7 gives nâ€² â‰¤7 and nâ€² â‰¡7 (mod 32), so that nâ€² =
7. Applying the argument again yields a subspace of co-dimension 2 containing
exactly one hole. Indeed, Equation (3.4) is needed additionally in order to exclude
the possibility of nâ€² = 7, so that A3(8, 6; 3) â‰¤248, i.e., Ïƒ â‰¥4, cf. Theorem 4 stating
the same bound.
Corollary 4 Suppose that C Ì¸= âˆ…in PG(v âˆ’1, Fq) is qr-divisible with #C = a Â·
qr+1 + b for some a, b, y âˆˆZ with y â‰¡(q âˆ’1)b (mod qr+1) and y â‰¥1. Further,
let g âˆˆQ is the largest number with qg | y, and j âˆˆZ satisï¬es 1 â‰¤j < r + 1 âˆ’
max{0, g âˆ’1}. Then there exists a (v âˆ’j)-subspace U such that #(C âˆ©U) â‰¤(a âˆ’
j) Â· qr+1âˆ’j +
b+[ j
1]qÂ·y
q j
and #(C âˆ©U) â‰¡b (mod qr+1âˆ’j).
Proof In order to apply induction on j, using Lemmas 7 and 8, we need to ensure
nâ€² > 0 in all but the last step. The latter holds due to pqg âˆ¤b.39
â–¡
Choosing the same value of y in every step, in general is not the optimal way
to iteratively apply Lemma 8, even if y is chosen optimal for the ï¬rst step. To this
end, consider a 33-divisible set C âˆˆPG(v âˆ’1, F3) with #C = 31 Â· 34 + 49 = 2560,
which indeed exists as the disjoint union of 64 solids is an example. Here y = 17 with
y â‰¡(3 âˆ’1) Â· 49 (mod 34) is the optimal choice in Lemma 8, so that Corollary 4
guarantees the existence of a subspace U with co-dimension 3, #(C âˆ©U) â‰¤(31 âˆ’
3) Â· 34âˆ’3 +
49+[3
1]3Â·17
33
= 94 and #(C âˆ©U) â‰¡49 â‰¡1 (mod 31). However, applying
Corollary 4 with j = 2 and y = 17 guarantees the existence of a subspaceU â€² with co-
dimension 2, #(C âˆ©U â€²) â‰¤(31 âˆ’2) Â· 34âˆ’2 +
49+[2
1]3Â·17
32
= 29 Â· 32 + 13 = 30 Â· 32 +
4 = 274, and #(C âˆ©U â€²) â‰¡49 â‰¡4 (mod 9). Since C âˆ©U â€² is 31-divisible and 8 â‰¡
2 Â· 4 (mod 32), we can apply Lemma 8 with y = 8 and deduce the existence of a
hyperplane H of U â€² with #(C âˆ©(U â€² âˆ©H)) â‰¤29 Â· 31 + 4+8
3
= 91 and #(C âˆ©(U â€² âˆ©
H)) â‰¡4 â‰¡1 (mod 31), while U â€² âˆ©H has co-dimension 3.
In the context of partial spreads or, more generally, vector space partitions another
parametrization using the number of non-hole elements of the vector space partition
turns out to be very useful in order to state a suitable formula for y. In what follows
we will say that a vector space partition P of Fv
q has hole-type (t, s, m1) if P has
m1 holes (1-subspaces), 2 â‰¤s â‰¤t < v, and s â‰¤dim(X) â‰¤t for all non-holes in P.
Additionally, we assume that there is at least one non-hole.
Corollary 5 LetP beavectorspacepartitionofFv
q ofhole-type(t, s, m1),l, x âˆˆN0
with 	t
i=s mi = lqs + x, and b, c âˆˆZ with m1 = bqs + c â‰¥1. If x â‰¥2 and g is the
38Another parametrization for y is given by y = qbâ€² âˆ’b, where bâ€² âˆˆZ with bâ€² â‰¥b
q and bâ€² â‰¡b
(mod qr+1), so that y âˆˆN0. Due to bâ€² = b+y
q , y is minimal if and only if bâ€² is minimal.
39The proof shows that the second assertion of the Corollary is true for all (v âˆ’j)-subspaces U.

150
T. Honold et al.
largest integer such that qg divides x âˆ’1, then for each 0 â‰¤j â‰¤s âˆ’max{1, g}
there exists a (v âˆ’j)-dimensional subspace U containing 
m1 holes with 
m1 â‰¡c
(mod qsâˆ’j) and 
m1 â‰¤(b âˆ’j) Â· qsâˆ’j +c, where c =
c+[ j
1]qÂ·(xâˆ’1)
q j
âˆˆZ.
Proof We have
v
1

q = m1 + 	t
i=s mi
i
1

q. Multiplication by q âˆ’1 and reduction
modulo qs yields âˆ’1 â‰¡(q âˆ’1)c âˆ’x (mod qs), allowing us to apply Corollary 4
with x = y âˆ’1. Observe that the parameters g from Corollaries 4 and 5 differ by at
most 1 âˆ’1/e if q = pe.
â–¡
So far, we can guarantee that some subspace contains not too many holes, since
the average number of holes per subspace would be too large otherwise. The modulo-
constraints captured in the deï¬nition of a qr-divisible set enable iterative rounding,
thereby sharpening the bounds. First we consider the special case of partial spreads,
and then we will derive some non-existence results for vector space partitions with
few holes.
Lemma 9 Let P be a vector space partition of type kmk1m1 of Fv
q with mk =
lqk+x, where l = qvâˆ’kâˆ’qr
qkâˆ’1 , x â‰¥2, k =
r
1

q +1âˆ’z+u > r, qg | xâˆ’1, qg+1 âˆ¤xâˆ’1, and
g, u, z,r, x âˆˆN0.Formax{1, g} â‰¤y â‰¤k thereexistsa(v âˆ’k + y)-subspaceU with
L â‰¤(z + y âˆ’1 âˆ’u)q y + w holes, where w = âˆ’(x âˆ’1)
y
1

q and L â‰¡w (mod q y).
Proof Due to m1 =
v
1

q âˆ’mk Â·
k
1

q =
r
1

qqk âˆ’
k
1

q(x âˆ’1), we have m1 = bqk +
c for b =
r
1

q and c = âˆ’
k
1

q(x âˆ’1), where qgâ€² | x âˆ’1 if and only if qgâ€² | c. Setting
s = t = k and j = k âˆ’y, we observe 0 â‰¤j â‰¤k âˆ’max{1, g}, since max{1, g} â‰¤
y â‰¤k. With this, we apply Corollary 5 and obtain an (n âˆ’k + y)-subspace U with
L â‰¤(b âˆ’j) Â· qkâˆ’j +
c +
 j
1

q Â· (x âˆ’1)
q j
= (z + y âˆ’1 âˆ’u) Â· q y âˆ’(x âˆ’1) Â·
k
1

q âˆ’
kâˆ’y
1

q
qkâˆ’y
= (z + y âˆ’1 âˆ’u)q y âˆ’(x âˆ’1)
y
1

q
= (z + y âˆ’1 âˆ’u)q y + w
holes, so that L â‰¤(z + y âˆ’1 âˆ’u)q y + w and L â‰¡w (mod q y).
â–¡
The parameterl is chosen in such a way that mk = lqk + x matches the cardinality
of the partial k-spread given by the construction in Theorem 2 for x = 1. Thus the
assumption x â‰¥2 is no real restriction. Actually, the chosen parametrization using
x in Corollary 5 makes it very transparent why the construction of Theorem 2 is
asymptotically optimalâ€”as stated in Theorem 6. If the dimension k of the elements
of the partial spread is large enough, a sufï¬cient number of rounding steps can be
performed while the rounding process is stopped at x = 1 for the other direction. For
small k we will not reach the lower bound of the construction of Theorem 2, so that
there remains some room for better constructions.

Partial Spreads and Vector Space Partitions
151
Lemma 10 Let Î” = qsâˆ’1, m âˆˆZ, and P be a vector space partition of Fv
q
of hole-type (t, s, c). Then, Ï„q(c, Î”, m) Â· qvâˆ’2
Î”2 âˆ’m(m âˆ’1) â‰¥0 and Ï„q(c, Î”, m) â‰¥
0, where Ï„q(c, Î”, m) = m(m âˆ’1)Î”2q2 âˆ’c(2m âˆ’1)(q âˆ’1)Î”q + c(q âˆ’1)

c(q âˆ’
1) + 1

. If c > 0, then Ï„q(c, Î”, m) = 0 if and only if m = 1 and c =
s
1

q.
Proof Adding (c âˆ’mÎ”)

c âˆ’(m âˆ’1)Î”

times the ï¬rst, âˆ’

2c âˆ’(2m âˆ’1)Î” âˆ’1

times the second and twice the third standard equation from Lemma 6, and divid-
ing the result by Î”2/(q âˆ’1) gives (q âˆ’1) Â· 	âŒŠc/Î”âŒ‹
h=0 (m âˆ’h)(m âˆ’h âˆ’1)acâˆ’hÎ” =
Ï„q(c, Î”, m) Â· qnâˆ’2
Î”2 âˆ’m(m âˆ’1), due to the qsâˆ’1-divisibility. We observe ai â‰¥0 and
(m âˆ’h)(m âˆ’h âˆ’1) â‰¥0 for all m, h âˆˆZ. If m /âˆˆ{0, 1}, then Ï„q(c, Î”, m) > 0.
Solving Ï„q(c, Î”, 0) = 0 yields c âˆˆ

0, âˆ’qs+1
qâˆ’1

and solving Ï„q(c, Î”, 1) = 0 yields
c âˆˆ

0,
s
1

q

.
â–¡
We remark that, in the case of Ï„q(c, Î”, m) = 0, their are either no holes at all or
the holes form an s-subspace. [11, Theorem 1.B] is quite similar to Lemma 10 and
its implications. The multipliers used in the proof can be directly read off from the
inverse matrix of
A =
â›
â
1
1
1
a
b
c
a2 âˆ’a
b2 âˆ’b
c2 âˆ’c
â
â ,
which is given by
Aâˆ’1 =
1
(c âˆ’a)(c âˆ’b)(b âˆ’a)
â›
â
bc(c âˆ’b)
âˆ’(c + b âˆ’1)(c âˆ’b)
(c âˆ’b)
âˆ’ac(c âˆ’a)
(c + a âˆ’1)(c âˆ’a)
âˆ’(c âˆ’a)
ab(b âˆ’a)
âˆ’(b + a âˆ’1)(b âˆ’a)
(b âˆ’a)
â
â 
for distinct numbers a, b, c. With this, Lemma 10 can be derived in a conceptual
way. Consider the linear programming method with just the ï¬rst three MacWilliams
identities. For parameters excluded by Lemma 10 this small linear program is infea-
sible, which can be seen at a certain basis solution, i.e., a choice of linear inequal-
ities that are satisï¬ed with equality. Solving for these equations, i.e., a change of
basis, corresponds to a non-negative linear combination of the inequality system.40
In the parametric case we have to choose the basis solution also depending on the
parameters. Actually, we have implemented a degree of freedom in Lemma 10 using
the parameter m. Here, the basis consists of two neighboring non-zero ai-entries,
parametrized by m, and an arbitrary ai, which plays no role when the resulting equa-
tion is solved for all remaining ai-terms. In this way we end up with an equation of
40If we relax â‰¥0-inequalities by adding some auxiliary variable on the left hand side and the
minimization of this variable, we can remove the infeasibility, so that we apply the duality theorem
of linear programming. Then, the mentioned multipliers for the inequalities are given as the solution
values of the dual problem.

152
T. Honold et al.
the form 	âŒŠc/Î”âŒ‹
h=0 (m âˆ’h)(m âˆ’h âˆ’1)acâˆ’hÎ” = Î², where the ai and their coefï¬cients
are non-negative. The use of the underlying quadratic polynomial is well known and
frequently applied in the literature; see the remarks after Theorem 4.
Lemma 11 For integers v > k â‰¥s â‰¥2 and 1 â‰¤i â‰¤s âˆ’1, there exists no vector
space partition P of Fv
q of hole-type (k, s, c), where c = i Â· qs âˆ’
s
1

q + s âˆ’1.41
Proof Since we have c < 0 for i â‰¤0, we can assume i â‰¥1 in the following. Let,
to the contrary, P be such a vector space partition and apply Lemma 10 with m =
i(q âˆ’1) onto P. We compute Ï„q(c, qsâˆ’1, m) = (m âˆ’1 âˆ’a) qs + a(a + 1) using
c(q âˆ’1) = qs(m âˆ’1) + a, where a := 1 + (s âˆ’1)(q âˆ’1). Setting i = s âˆ’1 âˆ’y,
we have 0 â‰¤y â‰¤s âˆ’2 and Ï„q(c, qsâˆ’1, m) = âˆ’qs(y(q âˆ’1) + 2) + (s âˆ’1)2q2 âˆ’
q(s âˆ’1)(2s âˆ’5) + (s âˆ’2)(s âˆ’3). If q = 2, then y â‰¥0 and s â‰¥2 yields
Ï„2(c, 2sâˆ’1, m) = âˆ’2s(y + 2) + s2 + s â‰¤

s2 âˆ’s âˆ’2s
+

2s âˆ’2s
< 0.
If s = 2, then we have y = 0 and Ï„q(c, qsâˆ’1, m) = âˆ’q2 + q < 0. If q, s â‰¥3,
then we have q(2s âˆ’5) â‰¥s âˆ’3, so that Ï„q(c, qsâˆ’1, m) â‰¤âˆ’2qs + (s âˆ’1)2q2 â‰¤
âˆ’2 Â· 3sâˆ’2q2 + (s âˆ’1)2q2 due to y â‰¥0 and q â‰¥3. Since 2 Â· 3sâˆ’2 > (s âˆ’1)2 for
s â‰¥3, we have Ï„q(c, qsâˆ’1, m) < 0 in all cases. Thus, Lemma 10 yields a contra-
diction, since qnâˆ’2s > 0 and m(m âˆ’1) â‰¥0 for every integer m.
â–¡
Now we are ready to present the ï¬rst improved (compared to Theorem 4) upper
bound for partial spreads, which also covers Theorem 6 setting z = 0.
Theorem 9 For integers r â‰¥1, t â‰¥2, u â‰¥0, and 0 â‰¤z â‰¤
r
1

q/2 with k =
r
1

q +
1 âˆ’z + u > r we have Aq(v, 2k; k) â‰¤lqk + 1 + z(q âˆ’1), where l = qvâˆ’kâˆ’qr
qkâˆ’1
and
v = kt + r.
Proof Apply Lemma 9 with x = 2 + z(q âˆ’1) â‰¥2 in order to deduce the existence
of a (v âˆ’k + y)-subspace U with L â‰¤(z + y âˆ’1 âˆ’u)q y âˆ’(x âˆ’1)
y
1

q holes,
where L â‰¡âˆ’(x âˆ’1)
y
1

q (mod q y).Now,weset y = z + 1.Observethatqg | x âˆ’1
implies g â‰¤z < y and we additionally have 1 â‰¤y = z + 1 â‰¤
r
1

q + 1 âˆ’z â‰¤t. If
z = 0, then y = 1, x = 2, and L â‰¤âˆ’uq âˆ’1 < 0. For z â‰¥1, we apply Lemma 11
to the subspace U with s = y, c = (z+yâˆ’1âˆ’u)q y âˆ’(xâˆ’1)
y
1

q âˆ’jq y = (yâˆ’
1âˆ’j âˆ’u)q y âˆ’
y
1

q +yâˆ’1 for some j âˆˆN0, and i = y âˆ’1 âˆ’j âˆ’u âˆˆZ. Thus,
Aq(n, 2k; k) â‰¤lqk + x âˆ’1.
â–¡
The case z = 0 covers Theorem 6. The non-negativity of the number of holes in a
certain carefully chosen subspace is sufï¬cient to prove this fact. The case z = 1 was
announced in [59, Lemma 10] and proven in [58]. Since the known constructions
41For more general non-existence results of vector space partitions see e.g. [29, Theorem 1] and the
related literature. Actually, we do not need the assumption of an underlying vector space partition
of the mentioned type. The result is generally true for qsâˆ’1-divisible codes, since the parameter x
is just a nice technical short-cut to ease the notation.

Partial Spreads and Vector Space Partitions
153
for partial k-spreads give Aq(kt + r, 2k; k) â‰¥lqk + 1, see e.g. [7] or Theorem 2,
Theorem 9 is tight for k â‰¥
r
1

q + 1 and A2(8, 6; 3) = 34.
So far Lemma 10 was just applied in the case of Lemma 11 excluding the existence
of some very special vector space partitions. Next, we look at a subspace and consider
the number of holes, i.e., we apply Lemma 9 giving us the freedom to choose the
dimension of the subspace. Then Lemma 10, stating that a certain quadratic poly-
nomial is non-negative, can be applied. By minimizing this function in terms of the
free parameter m, we obtain the following result.
Theorem 10 For integers r â‰¥1, t â‰¥2, y â‰¥max{r, 2}, z â‰¥0 with Î» = q y, y â‰¤k,
k =
r
1

q + 1 âˆ’z > r, v = kt + r, and l = qvâˆ’kâˆ’qr
qkâˆ’1 , we have Aq(v, 2k; k) â‰¤lqk +
 
Î» âˆ’1
2 âˆ’1
2
âˆš1 + 4Î» (Î» âˆ’(z + y âˆ’1)(q âˆ’1) âˆ’1)
!
.
Proof From Lemma 9 we conclude L â‰¤(z + y âˆ’1)q y âˆ’(x âˆ’1)
y
1

q and L â‰¡
âˆ’(x âˆ’1)
y
1

q (mod q y) for the number of holes of a certain (vâˆ’k+y)-subspace
U. Using the notation of Lemma 9, P âˆ©U := {P âˆ©U | P âˆˆP} is of hole-type
(k, y, L) if y â‰¥2. Next, we will show that Ï„q(c, Î”, m) â‰¤0, where Î” = q yâˆ’1 and
c = iq y âˆ’(x âˆ’1)
y
1

q with 1 â‰¤i â‰¤z + y âˆ’1, for suitable integers x and m. Note
that, in order to apply Lemma 9, we have to satisfy x â‰¥2 and y â‰¥g for all integers
g with qg | x âˆ’1. Applying Lemma 10 then gives the desired contradiction, so that
Aq(n, 2k; k) â‰¤lqk + x âˆ’1.
We choose42 m = i(q âˆ’1) âˆ’(x âˆ’1) + 1, so that Ï„q(c, Î”, m) = x2 âˆ’(2Î» +
1)x + Î»(i(q âˆ’1) + 2). Solving Ï„q(c, Î”, m) = 0 for x gives x0 = Î» + 1
2 Â± 1
2Î¸(i),
where
Î¸(i) = âˆš1 âˆ’4iÎ»(q âˆ’1) + 4Î»(Î» âˆ’1).
We
have
Ï„q(c, Î”, m) â‰¤0
for
|2x âˆ’2Î» âˆ’1| â‰¤Î¸(i). We need to ï¬nd an integer x â‰¥2 such that this inequal-
ity is satisï¬ed for all 1 â‰¤i â‰¤z + y âˆ’1. The strongest restriction is attained for
i = z + y âˆ’1. Since z + y âˆ’1 â‰¤
r
1

q and Î» = q y â‰¥qr, we have Î¸(i) â‰¥Î¸(z +
y âˆ’1) â‰¥1, so that Ï„q(c, Î”, m) â‰¤0 for x =
 
Î» + 1
2 âˆ’1
2Î¸(z + y âˆ’1)
!
. (Observe
x â‰¤Î» + 1
2 + 1
2Î¸(z + y âˆ’1) due to Î¸(z + y âˆ’1) â‰¥1.) Since x â‰¤Î» + 1, we have
x âˆ’1 â‰¤Î» = q y, so that qg | x âˆ’1 implies g â‰¤y provided x â‰¥2. The latter is true
due to Î¸(z + y âˆ’1) â‰¤âˆš1 âˆ’4Î»(q âˆ’1) + 4Î»(Î» âˆ’1) â‰¤âˆš1 + 4Î»(Î» âˆ’2) < 2(Î» âˆ’
1), which implies x â‰¥
 3
2
!
= 2.
So far we have constructed a suitable m âˆˆZ such that Ï„q(c, Î”, m) â‰¤0 for
x =
 
Î» + 1
2 âˆ’1
2Î¸(z + y âˆ’1)
!
. If Ï„q(c, Î”, m) < 0, then Lemma 10 gives a con-
tradiction, so that we assume Ï„q(c, Î”, m) = 0 in the following. If i < z + y âˆ’1
we have Ï„q(c, Î”, m) < 0 due to Î¸(i) > Î¸(z + y âˆ’1), so that we assume i =
z + y âˆ’1. Thus, Î¸(z + y âˆ’1) âˆˆN0. However, we can write Î¸(z + y âˆ’1)2 = 1 +
4Î» (Î» âˆ’(z + y âˆ’1)(q âˆ’1) âˆ’1) = (2w âˆ’1)2 = 1 + 4w(w âˆ’1) for some integer
w. If w /âˆˆ{0, 1}, then gcd(w, w âˆ’1) = 1, so that either Î» = q y | w or Î» = q y |
w âˆ’1. Thus, in any case, w â‰¥q y, which is impossible since (z + y âˆ’1)(q âˆ’1) â‰¥1.
42 Solving âˆ‚Ï„q(c,Î”,m)
âˆ‚m
= 0, i.e., minimizing Ï„q(c, Î”, m), yields m = i(q âˆ’1) âˆ’(x âˆ’1) + 1
2 +
xâˆ’1
q y . For y â‰¥r we can assume x âˆ’1 < q y due to Theorem 2, so that up-rounding yields the
optimum integer choice. For y < r the interval

Î» + 1
2 âˆ’1
2Î¸(i), Î» + 1
2 + 1
2Î¸(i)

may contain no
integer.

154
T. Honold et al.
Finally, w âˆˆ{0, 1} implies w(w âˆ’1) = 0, so that Î» âˆ’(z + y âˆ’1)(q âˆ’1) âˆ’1 = 0.
Thus, z + y âˆ’1 =
y
1

q â‰¥
r
1

q since y â‰¥r. The assumptions y â‰¤k and k =
r
1

q +
1 âˆ’z imply z + y âˆ’1 =
r
1

q and y = r. This gives k = r, which is excluded.
â–¡
An example where Theorem 10 is strictly superior to the results of [58, Theo-
rems 6,7] is given by A3(15, 12; 6) â‰¤19695.43 Setting y = k, we obtain Theorem 4.
Compared to [11, 20], the new ingredients essentially are qr-divisible sets and Corol-
lary 5, which allows us to choose y < k. Theorem 4, e.g., gives A2(15, 12; 6) â‰¤516,
A2(17, 14; 7) â‰¤1028, and A9(18, 16; 8) â‰¤3486784442, while Theorem 10 gives
A2(15, 12; 6) â‰¤515, A2(17, 14; 7) â‰¤1026, and A9(18, 16; 8) â‰¤3486784420. For
2 â‰¤q â‰¤9, 5 â‰¤k â‰¤19, there are 66 improvements in total, i.e., almost 19%, and the
maximum gap is 22. Next, we provide an estimation of the bound of Theorem 4.
Lemma 12 For integers 1 â‰¤r < k and q â‰¥2 we have
2qk âˆ’qr âˆ’q2râˆ’k
b
<

1 + 4qk(qk âˆ’qr) â‰¤2qk âˆ’qr âˆ’q2râˆ’k
b
,
where b = 3+2
âˆš
2
2
> 2.91 and b = 16
3 < 5.34.
Proof Due to q â‰¥2 and k â‰¥r + 1 â‰¥2, we have
1 + 4qk(qk âˆ’qr) > 4qk(qk âˆ’qr) âˆ’q2r Â·
â‰¥0
"
#$
%

4
b âˆ’1 âˆ’2
bq âˆ’
1
b2q2

â‰¥4qk(qk âˆ’qr) âˆ’4
bq2r + q2r + 2
bq3râˆ’k + 1
b2 q4râˆ’2k =

2qk âˆ’qr âˆ’q2râˆ’k
b
2
.
Similarly, 1+4qk(qkâˆ’qr) â‰¤4qk(qkâˆ’qr) âˆ’q2r Â·

4
b âˆ’1

â‰¤

2qkâˆ’qr âˆ’q2râˆ’k
b
2
.
â–¡
Corollary 6 For integers 1 â‰¤r < k and t â‰¥2 we have Aq(kt + r, 2k; k) < lqk +
qr
2 + 1
2 +
q2râˆ’k
3+2
âˆš
2, where l = q(tâˆ’1)k+râˆ’qr
qkâˆ’1
. If k â‰¥2r, then Aq(kt + r, 2k; k) < lqk +
1 + qr
2 .
Corollary 7 For integers r â‰¥1, t â‰¥2, and u, z â‰¥0 with k =
r
1

q + 1 âˆ’z + u > r
we have Aq(v, 2k; k) â‰¤lqk + 1 + z(q âˆ’1), where l = qvâˆ’kâˆ’qr
qkâˆ’1
and v = kt + r.
Proof Using Corollary 6, we can remove the upper bound z â‰¤
r
1

q/2 from The-
orem 9. If z >
r
1

q/2, then z â‰¥
r
1

q/2 + 1/2, so that Aq(v, 2k; k) < lqk + 1 +
qr
2 â‰¤lqk + 1 + qrâˆ’1
2
+ qâˆ’1
2
â‰¤lqk + 1 + z(q âˆ’1) for k â‰¥2r. Thus, we can assume
43For 2 â‰¤q â‰¤9, 1 â‰¤v, k â‰¤100 the bounds of [58, Theorem 6,7] are covered by Theorem 10 and
Corollary 7. In many cases the bounds coincide.

Partial Spreads and Vector Space Partitions
155
r + 1 â‰¤k â‰¤2r âˆ’1 and r â‰¥2. With this, we have z â‰¥
r
1

q âˆ’2(r âˆ’1) and lqk +
1 + z(q âˆ’1) â‰¥lqk + qr âˆ’2(q âˆ’1)(r âˆ’1). It remains to show lqk + qr âˆ’2(q âˆ’
1)(r âˆ’1) â‰¥lqk + qr
2 + 1
2 +
q2râˆ’k
3+2
âˆš
2 â‰¥lqk + qr
2 + 1
2 +
qrâˆ’1
3+2
âˆš
2, i.e., qr â‰¥1 +
2qrâˆ’1
3+2
âˆš
2
+ 4(q âˆ’1)(r âˆ’1). The latter inequality is valid for all pairs (r, q) except (2, 2),
(2, 3), and (3, 2). In those cases it can be veriï¬ed directly that lqk + 1 + z(q âˆ’1) is
not strictly less than the upper bound of Theorem 4. Indeed, both bounds coincide.
â–¡
We remark that the ï¬rst part of Corollary 6 can be written as Ïƒ â‰¥qrâˆ’1
2
âˆ’
q2râˆ’k
3+2
âˆš
2. Unfortunately, Theorem 10 is not capable to obtain Ïƒ â‰¥âŒŠ(qr âˆ’1)/2âŒ‹. For
A2(17, 12; 6), i.e., q = 2 and r = 5, it gives Ïƒ â‰¥13 while âŒŠ(qr âˆ’1)/2âŒ‹= 15. In
Lemma 23 we give a cubic analog to Lemma 10, which yields Ïƒ â‰¥14 for these
parameters.
4
Constructions for qr-divisible Sets
First note that we can embed every Î”-divisible point set C in PG(v âˆ’1, Fq) into
ambient spaces with dimension larger than v and, conversely, replace Fv
q by the span
âŸ¨C âŸ©without destroying the Î”-divisibility. Since in this sense v is not determined by
C , we will refer to C as a Î”-divisible point set over Fq. In the sequel we develop
a few basic constructions of qr-divisible sets. For the statement of the ï¬rst lemma
recall our convention that subspaces of Fv
q are identiï¬ed with subsets of the point set
P of PG(v âˆ’1, Fq).
Lemma 13 Every k-subspace C of PG(v âˆ’1, Fq) with k â‰¥2 is qkâˆ’1-divisible.
Proof By the preceding remark we may assume k = v and hence C = P. In this
case the result is clear, since #P âˆ’#H = qvâˆ’1 for each hyperplane H.
â–¡
In fact a k-subspace of Fv
q is associated to the k-dimensional simplex code over Fq
and Lemma 13 is well-known.
For a point set C in PG(v âˆ’1, Fq) we denote by Ï‡C its characteristic function,
i.e., Ï‡C : P â†’{0, 1} âŠ‚Z with Ï‡C (P) = 1 if and only if P âˆˆC .
Lemma 14 Let Ci be Î”i-divisible point sets in PG(v âˆ’1, Fq) and ai âˆˆZ for
1 â‰¤i â‰¤m. If C âŠ†P satisï¬es Ï‡C = 	m
i=1 aiÏ‡C i then C is gcd(a1Î”1, . . . , amÎ”m)-
divisible.
Proof We have #C = 	m
i=1 ai Â· #Ci and #(C âˆ©H) = 	m
i=1 ai Â· #(Ci âˆ©H) for each
hyperplane H. Since #(Ci âˆ©H) â‰¡#Ci (mod Î”i), the result follows.
â–¡
Lemma 14 shows in particular that the union of mutually disjoint qr-divisible sets is
again qr-divisible. Another (well-known) corollary is the following, which expresses
the divisibility properties of the MacDonald codes.44
44The generalization to more than one â€œremovedâ€ subspace is also quite obvious and expresses the
divisibility properties of optimal linear codes of type BV in the projective case [4, 35, 50].

156
T. Honold et al.
Corollary 8 Let X âŠŠY be subspaces of Fv
q and C = Y \ X. If dim(X) = s then C
is qsâˆ’1-divisible.
In particular afï¬ne k-subspaces of Fv
q are qkâˆ’1 divisible.
Lemma 15 Let C1 âˆˆP1, C2 âˆˆP2 be qr-divisible point sets in PG(v1 âˆ’1, Fq),
respectively, PG(v2 âˆ’1, Fq). Then there exists a qr-divisible set C in PG(v1 + v2 âˆ’
1, Fq) with #C = #C1 + #C2.
Proof Embed the point sets C1, C2 in the obvious way into PG(Fv1
q Ã— Fv2
q ) âˆ¼=
PG(v1 + v2 âˆ’1, Fq), and take C as their union.
â–¡
Let us note that the embedding dimension v in Lemma 15 is usually not the smallest
possible, and the isomorphism type of C is usually not determined by C1 and C2.45
In analogy to the Frobenius Coin Problem, cf. [8, 13, 28], we deï¬ne F(q,r) as the
smallest positive integer such that a qr-divisible set over Fq (i.e., with some ambient
space Fv
q) with cardinality n exists for all integers n > F(q,r). Using Lemma 13,
Corollary 8, and Lemma 15, we conclude that F(q,r) â‰¤
r+1
1

q Â· qr+1 âˆ’
r+1
1

q âˆ’
qr+1, the largest integer not representable as a1
r+1
1

q + a2qr+1 with a1, a2 âˆˆZâ‰¥0.46
The bound may also be stated as F(q,r) â‰¤	2r+1
i=r+2 qi âˆ’	r
i=0 qi.
As the disjoint union of qr-divisible sets is again qr-divisible, one obtains a wealth
of constructions. Consequently, the qr-divisible point sets not arising in this way are
of particular interest. They are called indecomposable.
The next construction uses the concept of a â€œsunï¬‚owerâ€ of subspaces, which
forms the q-analogue of the Î”-systems, or sunï¬‚owers, considered in extremal set
theory [23].47
Deï¬nition 2 Let X be a subspace of Fv
q and t â‰¥2 an integer. A t-sunï¬‚ower in
Fv
q with center X is a set {Y1, . . . , Yt} of subspaces of Fv
q satisfying Yi Ì¸= X and
Yi âˆ©Y j = X for i Ì¸= j. The point sets Yi \ Xi are called petals of the sunï¬‚ower.
Lemma 16 (i) The union of the petals of a q-sunï¬‚ower in Fv
q with r-dimensional
center forms a qr-divisible point set.
(ii) The union of the petals and the center of a q + 1-sunï¬‚ower in Fv
q with r-
dimensional center forms a qr-divisible point set.
Proof (i) Let F = {Y1, . . . , Yq} and C = q
i=1(Yi \ Xi) =
 F

\ X. We have
Ï‡C = 	q
i=1 Ï‡Yi âˆ’qÏ‡X. Since dim(Yi) â‰¥r + 1, Yi is qr-divisible, and so is qÏ‡X.
Hence, by Lemma 14, C is qr-divisible as well.
(ii) follows from (i) by adding one further space Yq+1 to F.
â–¡
45If not both C1 and C2 are subspaces, then disjoint embeddings into a geometry PG(v âˆ’1, Fq)
with v < dimâŸ¨C1âŸ©+ dimâŸ¨C2âŸ©exist as well.
46Note that gcd
r+1
1

q, qr+1
= 1 and recall the solution of the ordinary Frobenius Coin Problem.
47Our sunï¬‚owers need not have constant dimension, however.

Partial Spreads and Vector Space Partitions
157
Lemma 17 Let r â‰¥1 be an integer and 1 â‰¤i â‰¤qr + 1. There exists a qr-divisible
set Ci over Fq with #Ci =
2r
1

q + i Â·

qr+1 âˆ’qr âˆ’
r
1

q

.
Proof Let Y = F2r
q and X1, . . . , Xqr+1 an r-spread in Y. After embedding Y in
a space Fv
q of sufï¬ciently large dimension v, it is possible to choose q-sunï¬‚owers
F1, . . . , Fqr+1 in Fv
q with the following properties: Y âˆˆFi for alli; dim(Z) = r + 1
for Z âˆˆFi \ {Y}; Fi has center Xi; petals in different sunï¬‚owers Fi and F j
are either equal (to Y) or disjoint. Having made such a choice, we set Ci =
 F1 âˆªÂ· Â· Â· âˆª Fi

\ (X1 âˆªÂ· Â· Â· âˆªXi)
for
1 â‰¤i â‰¤qr + 1.
Then
Ï‡C i =
	
ZâˆˆF 1âˆªÂ·Â·Â·âˆªFi Ï‡Z âˆ’qÏ‡X1 âˆ’Â· Â· Â· âˆ’qÏ‡Xi is qr-divisible (again by Lemma 14), and
#Ci is as asserted.
â–¡
Replacing S by some arbitrary q1-divisible set, we similarly obtain:
Lemma 18 Let C â€² be a q1-divisible set of cardinality n, then there exist q1-divisible
sets of cardinality n + i Â·

q2 âˆ’q âˆ’1

for all 0 â‰¤i â‰¤n.
Our last construction in this section uses the concept of a cone.
Deï¬nition 3 Let X, Y be complementary subspaces of Fv
q with dim(X) = s,
dim(Y) = t (hence v = s + t) and B a set of points in PG(Y). The cone with vertex
X and base B is the point set C = 
PâˆˆB(X + P).
Lemma 19 Let B be a qr-divisible point set in PG(v âˆ’1, Fq) with #B = m and
s â‰¥1 an integer.
(i) If m â‰¡0 (mod qr+1) then there exists a qr+s-divisible point set C in PG(v +
s âˆ’1, Fq) of cardinality #C = mqs.
(ii) If m(q âˆ’1) â‰¡âˆ’1 (mod qr+1) then there exists a qr+s-divisible point set C in
PG(v + s âˆ’1, Fq) of cardinality #C =
s
1

q + mqs.
Proof Embed Fv
q into Fv+s
q
as Y and consider a cone K in PG(v + s âˆ’1, Fq) with
base B and s-dimensional vertex X. The hyperplanes H âŠ‡X satisfy #(K \ H) =
qs Â· #(K \ H) â‰¡0 (mod qr+s). The hyperplanes H âŠ‰X intersect X + P, P âˆˆB,
in an s-subspace Ì¸= X, hence contain
 s
sâˆ’1

q = points in X and qsâˆ’1 points in K \ X.
It follows that #(K \ H) = qsâˆ’1 + m(qs âˆ’qsâˆ’1) = (1 + m(q âˆ’1))qsâˆ’1. Thus in
Case (ii) we can take C = K and in Case (i) we can take C = K \ X.48
â–¡
The preceding constructions can be combined in certain nontrivial ways to yield
further constructions of qr-divisible point sets. We will return to this topic in Sect.6.1.
Nonetheless, we are only scratching the surface of a vast subject. Projective two-
weight codes with weights w1, w2 satisfying w2 > w1 + 1 are qr-divisible by Del-
sarteâ€™s Theorem [16, Corollary 2]. This yields many further examples of qr-divisible
point sets; see [14] and the online-table at http://moodle.tec.hkr.se/~chen/research/
2-weight-codes. Codes meeting the Griesmer bound whose minimum distance is a
48Note that m(q âˆ’1) â‰¡0 (mod qr+1) is equivalent to m â‰¡0 (mod qr+1).

158
T. Honold et al.
multiple of q are qr-divisible [69, Proposition 13].49 Optimal codes of lengths strictly
above the Griesmer bound tend to have similar divisibility properties; see, e.g., Best
Known Linear Codes in Magma.
5
More Non-existence Results for qr-divisible Sets
For a point set C in PG(v âˆ’1, Fq) let T (C ) := {0 â‰¤i â‰¤c | ai > 0}, where ai
denotes the number of hyperplanes with #(C âˆ©H) = i.
Lemma 20 For integers u âˆˆZ, m â‰¥0 and Î” â‰¥1 let C in PG(v âˆ’1, Fq) be Î”-
divisible of cardinality n = u + mÎ” â‰¥0. Then, we have (q âˆ’1) Â· 	
hâˆˆZ,hâ‰¤m hau+hÎ”
= (u + mÎ” âˆ’uq) Â· qvâˆ’1
Î” âˆ’m, where we set au+hÎ” = 0 if u + hÎ” < 0.
Proof Rewriting the equations from Lemma 6 yields (q âˆ’1) Â· 	
hâˆˆZ,hâ‰¤m au+hÎ” =
q Â· qvâˆ’1 âˆ’1 and (q âˆ’1) Â· 	
hâˆˆZ,hâ‰¤m(u + hÎ”)au+hÎ” = (u + mÎ”)(qvâˆ’1 âˆ’1). u
times the ï¬rst equation minus the second equation gives Î” times the stated equation.
â–¡
Corollary 9 Let C in PG(v âˆ’1, Fq) satisfy n = #C = u + mÎ” and T (C ) âŠ†
{u, u + Î”, . . . , u + mÎ”}. Then u < n
q or u = n = 0.
WhilethequadraticinequalityofLemma10isbasedontheï¬rstthreeMacWilliams
identities, the linear inequality of Lemma 20 is based on the ï¬rst two MacWilliams
identities. Corollary 9 corresponds to the average argument that we have used in
the proof of Lemma 8. Lemma 10 can of course be applied in the general case
of qr-divisible sets. First we characterize the part of the parameter space where
Ï„q(c, Î”, m) â‰¤0 and then we analyze the right side of the corresponding interval,
Lemma 21 For m âˆˆZ, we have Ï„q(c, Î”, m) â‰¤0 if and only if (q âˆ’1)c âˆ’(m âˆ’
1/2)Î”q + 1
2 âˆˆ

âˆ’1
2 Â·

q2Î”2 âˆ’4qmÎ” + 2qÎ” + 1, 1
2 Â·

q2Î”2 âˆ’4qmÎ” + 2qÎ” + 1

.
(5.1)
The last interval is non-empty, i.e., the radicand is non-negative if and only if m â‰¤
âŒŠ(qÎ” + 2)/4âŒ‹. We have Ï„q(u, Î”, 1) = 0 if and only if u = (Î”q âˆ’1)/(q âˆ’1) or
u = 0.
Proof Solving Ï„q(c, Î”, m) = 0 for c yields the boundaries for c stated in (5.1)).
Inside this interval we have Ï„q(c, Î”, m) â‰¤0. Now, q2Î”2 âˆ’4qmÎ” + 2qÎ” + 1 â‰¥0
is equivalent to m â‰¤qÎ”
4 + 1
2 +
1
4qÎ”. Rounding downward the right-hand side, while
observing
1
4qÎ” < 1
4, yields âŒŠ(qÎ” + 2)/4âŒ‹.
â–¡
49In the case q = p, and in general for codes of type BV, such codes are even qe-divisible, where
qe is the largest power of p dividing the minimum distance [67, Theorem 1 and Proposition 2].

Partial Spreads and Vector Space Partitions
159
Lemma 22 For 1 â‰¤m â‰¤
&âˆš(q âˆ’1)qÎ” âˆ’q + 3
2
'
, we have (q âˆ’1)n âˆ’(m âˆ’1/2)
Î”q + 1
2 â‰¤1
2 Â·

q2Î”2 âˆ’4qmÎ” + 2qÎ” + 1, where n = m Â·
r+1
1

q âˆ’1 and Î” = qr.
Proof Plugging in yields 1
2 Â· (qÎ” + 3 âˆ’2m âˆ’2q) â‰¤1
2

q2Î”2 âˆ’(4m âˆ’2)qÎ” + 1,
so that squaring and simplifying gives m â‰¤âˆš(q âˆ’1)qÎ” + 1/4 âˆ’q + 3
2.
â–¡
Theorem 11 Let C in PG(v âˆ’1, Fq) be q1-divisible with 2 â‰¤n = #C â‰¤q2, then
either n = q2 or q + 1 divides n.
Proof First we show n /âˆˆ[(m âˆ’1)(q + 1) + 2, m(q + 1) âˆ’1] for 1 â‰¤m â‰¤q âˆ’
1. For m = 1 this statement follows from Lemmas 21 and 10. For m â‰¥2 let
(m âˆ’1)(q + 1) + 2 â‰¤n â‰¤m(q + 1) âˆ’1. Due to Lemma 10 it sufï¬ces to verify
Ï„q(n, q, m) â‰¤0. From n â‰¥(m âˆ’1)(q + 1) + 2 we conclude
(q âˆ’1)n âˆ’(m âˆ’1/2)Î”q + 1
2 â‰¥âˆ’1
2 Â·

q2 âˆ’4q + 1 + 2m

â‰¥âˆ’1
2 Â·

q2 âˆ’2m âˆ’3

â‰¥âˆ’1
2 Â·
(
q4 âˆ’4mq2 + 2q2 + 1 = âˆ’1
2 Â·
(
q2Î”2 âˆ’4qmÎ” + 2qÎ” + 1
and from n â‰¤m(q + 1) âˆ’1 we conclude
(qâˆ’1)n âˆ’(mâˆ’1/2)Î”q + 1
2 â‰¤1
2 Â·

q2âˆ’2mâˆ’2q+3
 â‹†â‰¤1
2 Â·
(
q2Î”2âˆ’4qmÎ”+2qÎ”+1.
With respect to the estimation â‹†, we remark that âˆ’4q3 + 8q2 âˆ’12q + 8 + 4m(m +
2q âˆ’3)
mâ‰¤qâˆ’1
â‰¤
âˆ’4(q âˆ’1)(q2 âˆ’4q + 6)
qâ‰¥2
â‰¤0. Thus, Lemma 21 gives Ï„q(n, q,
m) â‰¤0.
Applying Corollary 9 with u = m and Î” = q yields n Ì¸= (m âˆ’1)(q + 1) + 1 for
all 1 â‰¤m â‰¤q âˆ’1.
â–¡
Theexistenceofovoidsshowsthattheupperboundn â‰¤q2 issharpinTheorem11.
Theorem 12 For the cardinality n of a qr-divisible set C over Fq we have
n /âˆˆ
)
(a(q âˆ’1) + b)
r + 1
1

q
+ a + 1, (a(q âˆ’1) + b + 1)
r + 1
1

q
âˆ’1
*
,
where a, b âˆˆN0 with b â‰¤q âˆ’2, a â‰¤r âˆ’1, and r âˆˆN>0.
In other words, if n â‰¤rqr+1, then n can be written as a
r+1
1

q + bqr+1 for some
a, b âˆˆN0.
Proof We prove by induction on r, set Î” = qr, and write n = (m âˆ’1)
r+1
1

q + x,
where a + 1 â‰¤x â‰¤
r+1
1

q âˆ’1 and m âˆ’1 = a(q âˆ’1) + b for integers 0 â‰¤b â‰¤q âˆ’
2, 0 â‰¤a â‰¤r âˆ’1. The induction start r = 1 is given by Theorem 11.
Now, assume r â‰¥2 and conclude that for 0 â‰¤bâ€² â‰¤q âˆ’2, 0 â‰¤aâ€² â‰¤r âˆ’2 we
have nâ€² /âˆˆ
+
(aâ€²(q âˆ’1) + bâ€²)
r
1

q + aâ€² + 1, (aâ€²(q âˆ’1) + bâ€² + 1)
r
1

q âˆ’1
,
for the car-
dinality nâ€² of a qrâˆ’1-divisible set. If a â‰¤r âˆ’2 and x â‰¤
r
1

q âˆ’1, then bâ€² = b, aâ€² = a

160
T. Honold et al.
yields T (C ) âŠ†{u, u + Î”, . . . , u + (m âˆ’2)Î”} for u = Î” + (m âˆ’1)
r
1

q + x. We
compute (q âˆ’1)u = qr+1 âˆ’qr + (m âˆ’1)qr âˆ’(m âˆ’1) + (q âˆ’1)x
xâ‰¥a+1
â‰¥
(m âˆ’2)
qr + qr+1 > (m âˆ’2)Î”, so that we can apply Corollary 9. If a = r âˆ’1 and a + 1 â‰¤
x â‰¤
r
1

q âˆ’1, then bâ€² = b, aâ€² = a âˆ’1 yields T (C ) âŠ†{u, u + Î”, . . . , u + (m âˆ’
1)Î”} for u = (m âˆ’1)
r
1

q + x. We compute (q âˆ’1)u = (m âˆ’1)qr âˆ’(m âˆ’1) +
x(q âˆ’1) > (m âˆ’1)Î” using x â‰¥a + 1, so that we can apply Corollary 9. Thus,
we can assume
r
1

q â‰¤x â‰¤
r+1
1

q âˆ’1 in the remaining part. Additionally we have
m â‰¤r(q âˆ’1).
We aim to apply Lemma 21. Due to Lemma 22 for the upper bound of the interval
it sufï¬ces to show r(q âˆ’1) â‰¤
&âˆš(q âˆ’1)qÎ” âˆ’q + 3
2
'
. For q = 2 the inequality is
equivalent to r â‰¤
-âˆš
2r+1 âˆ’1
2
.
, which is valid for r â‰¥2. Since the right hand side
is larger then (q âˆ’1)(
âˆš
Î” âˆ’1), it sufï¬ces to show qr/2 âˆ’1 â‰¥r, which is valid for
q â‰¥3 and r â‰¥2. For the left hand side of the interval if sufï¬ces to show
(q âˆ’1)n âˆ’(m âˆ’1/2)Î”q + 1
2 â‰¥âˆ’1
2 Â·

(Î”q)2 âˆ’(4m âˆ’2)Î”q + 1,
which can be simpliï¬ed to Î”q + 2m âˆ’3 âˆ’2(q âˆ’1)x â‰¤

(Î”q)2 âˆ’(4m âˆ’2)Î”q + 1
using n = (m âˆ’1)
r+1
1

q + x. Since (q âˆ’1)x â‰¥qr âˆ’1 and m â‰¤r(q âˆ’1) it suf-
ï¬ces to show
âˆ’Î”2 + 2rqÎ” âˆ’2rÎ” âˆ’Î” âˆ’r + r2q âˆ’r2 â‰¤0.
(5.2)
For q = 2 this inequality is equivalent to âˆ’22r + r2r+1 + r2 âˆ’2 âˆ’2r â‰¤0, which
is valid for r â‰¥2. For r = 2 Inequality (5.2) is equivalent to âˆ’q4 + 4q3 âˆ’4q2 âˆ’
q2 + 4q âˆ’6, which is valid for q âˆˆ{2, 3} and q â‰¥4. For q â‰¥3 and r â‰¥3 we have
Î” â‰¥3rq, so that Inequality (5.2) is satisï¬ed.
â–¡
This classiï¬cation result enables us to decide the existence problem for qr-
divisible sets over Fq of cardinality n in many further cases. We restrict ourselves to
the cases q = 2, r âˆˆ{1, 2, 3}, and refer to [31] for further results.
Theorem 13 (i) 21-divisible sets over F2 of cardinality n exist for all n â‰¥3 and
do not exist for n âˆˆ{1, 2}; in particular, F(2, 1) = 2.
(ii) 22-divisible sets over F2 of cardinality n exist for n âˆˆ{7, 8} and all n â‰¥14,
and do not exist in all other cases; in particular, F(2, 2) = 13.
(iii) 23-divisiblesetsoverF2 ofcardinalityn existforn âˆˆ{15, 16, 30, 31, 32, 45, 46,
47, 48, 49, 50, 51}, for all n â‰¥60, and possibly for n = 59; in all other cases
they do not exist; thus F(2, 3) âˆˆ{58, 59}.
Proof (i) The non-existence for n âˆˆ{1, 2} is obvious. Existence for n â‰¥3 can be
shown by taking C as a projective basis in PG(n âˆ’2, Fq). The corresponding code
C is the binary [n, n âˆ’1, 2] even-weight code.

Partial Spreads and Vector Space Partitions
161
(ii) The non-existence part follows from Theorem 12. Existence for n âˆˆ{7, 8} is
shown by the [7, 3, 4] simplex code and its dual (the [8, 4, 4] extended Hamming
code). These two examples and Lemma 15 in turn yield examples of 4-divisible point
sets for n âˆˆ{14, 15, 16}.50 For n âˆˆ{17, 18, 19, 20} Lemma 17 provides examples.51
Together these represent all arithmetic progressions modulo 7, showing existence for
n > 20.
(iii) Existence of 8-divisible sets for the indicated cases with n â‰¤48 is shown
in the same way as in (ii). Examples for n = 49, n = 50, and n = 74 were found
by computer search; we refer to [31] for generator matrices of the corresponding
8-divisible codes. The binary irreducible cyclic [51, 8] code, which is a two-weight
code with nonzero weights 24 and 32 (see, e.g., [54]), provides an example for
n = 51.52
For n âˆˆ{63, . . . , 72} Lemma 17 provides examples. For n = 73, a suitable exam-
ple is given by the projective [73, 9] two-weight code with non-zero weights 32 and
40 in [44]. Together with the mentioned example for n = 74 these represent all
arithmetic progressions modulo 15, showing existence for n > 74.
The non-existence part follows for n â‰¤48 from Theorem 12 and for 53 â‰¤n â‰¤
58 from Lemma 10 with m = 4. It remains to exclude an 8-divisible point set in
PG(v âˆ’1, Fq)with#C = 52.Forthiswewilluseavariantofthelinearprogramming
method, which treats different ambient space dimensions simultaneously. Since C
is in particular 4-divisible, we conclude from Lemma 7 and Part (ii) that there are no
4- or 12-hyperplanes, i.e., A40 = A48 = 0. Using the parametrization y = 2vâˆ’3, the
ï¬rst four MacWilliams identities for the associated code C are
1 +
A8 +
A16 +
A24 +
A32 = 8y,
52 +
44A8 +
36A16 +
28A24 +
20A32 = 4y Â· 52,
52
2

+
44
2

A8 +
36
2

A16 +
28
2

A24 +
20
2

A32 = 2y Â·
52
2

,
52
3

+
44
3

A8 +
36
3

A16 +
28
3

A24 +
20
3

A32 = y
52
3

+ AâŠ¥
3

.
Substituting x = y AâŠ¥
3 and solving for A8, A16, A24, A32 yields A8 = âˆ’4 +
1
512 x +
7
64 y, A16 = 6 âˆ’
3
512 x âˆ’17
64 y, A24 = âˆ’4 +
3
512 x + 397
64 y,and A32 = 1 âˆ’
1
512 x + 125
64 y.
Since A16, x â‰¥0, we have y â‰¤384
17 < 23. On the other hand, since 3A8 + A16 â‰¥0,
we also have âˆ’6 + y
16 â‰¥0, i.e., y â‰¥96â€”a contradiction.
â–¡
50The three examples are realized in dimensions 6, 7 and 8, respectively. Alternative solutions for
n âˆˆ{15, 16}, having smaller ambient space dimensions, are the [15, 4, 8] simplex code and the
[16, 5, 8] ï¬rst-order Reed-Muller code.
51These examples can be realized in F6
2 for n âˆˆ{17, 18} and in F7
2 for n âˆˆ{19, 20}.
52It might look tempting to construct a projective 8-divisible binary code of length 50 by shortening
such a code C of length 51. However, this does not work: By Lemma 24, C is the concatenation
of an ovoid in PG(3, F4) with the binary [3, 2] simplex code. By construction, the corresponding
8-divisible point set C is the disjoint union of 17 lines. In particular, each point of C is contained
in a line in C . Consequently, shortening C in any coordinate never gives a projective code.

162
T. Honold et al.
The non-existence of a 23-divisible set of cardinality n = 52 implies the (com-
pared with Theorem 4) tightened upper bound A2(11, 8; 4) â‰¤13253 and can also be
obtained from a more general result, viz., Corollary 10 with t = 3. Combining the
ï¬rst four MacWilliams identities we obtain an expression involving a certain cubic
polynomial [31]:
Lemma 23 Let C be Î”-divisible over Fq of cardinality n > 0 and t âˆˆZ. Then
	
iâ‰¥1 Î”2(i âˆ’t)(i âˆ’t âˆ’1) Â· (g1 Â· i + g0) Â· AiÎ” + qhx = n(q âˆ’1)(n âˆ’tÎ”)
(n âˆ’(t + 1)Î”)g2,
where
g1 = Î”qh,
g0 = âˆ’n(q âˆ’1)g2,
g2 = h âˆ’(2Î”qt+
Î”q âˆ’2nq + 2n + q âˆ’2) and h = Î”2q2t2 + Î”2q2t âˆ’2Î”nq2t âˆ’Î”nq2 + 2Î”nqt
+ n2q2 + Î”nq âˆ’2n2q + n2 + nq âˆ’n.
Corollary 10 If there exists t âˆˆZ, using the notation of Lemma 23, with n/Î” /âˆˆ
[t, t+1], h â‰¥0, and g2 < 0, then there is no Î”-divisible set over Fq of cardinality n.
Applying Corollary 10 with t = 6 implies the non-existence of a 24-divisible
set C over F2 with #C = 200, so that A2(16, 12; 6) â‰¤1032, while Theorem 10
gives A2(16, 12; 6) â‰¤1033. There is no 85-divisible set C over F8 with #C =
6 Â· 86 + 3 = 1572867, which can be seen as follows. Corollary 4 implies the exis-
tence of a subspace U of co-dimension 4 such that C âˆ©U is 81-divisible, #C âˆ©U â‰¤
2 Â· 82 + 3 = 131, and #C âˆ©U â‰¡3 (mod 82). Applying Lemma 10 with m = 1
and m = 8 excludes the existence of a 81-divisible set with cardinality 3 or 67,
respectively. Cardinality 131 is ï¬nally excluded by Corollary 10 with t = 14. Thus,
A8(14; 12; 6) â‰¤16777237, while Theorem 10 gives A8(14, 12; 6) â‰¤16777238 and
Theorem 4 gives A8(14, 12; 6) â‰¤16777248. See also [33, 47] for a few more such
examples.
Most of the currently best known bounds for Aq(v, 2k; k) can also be directly
derived by linear programming; cf. the online tables at http://subspacecodes.uni-
bayreuth.de [33]. The following lemma gives a glimpse on coding-theoretic argu-
ments dealing with the MacWilliams equations and its non-negative integer solutions.
Lemma 24 Let C be a projective 8-divisible binary code of length n = 51. Then C
is isomorphic to the concatenation of an ovoid in PG(3, F4) with the binary [3, 2]
simplex code. The code C has the parameters [51, 8] and the weight enumerator
1 + 204X24 + 51X32.
Proof With the notation k = dim(C) and y = 2kâˆ’3, solving the equation system
of the ï¬rst three MacWilliams equations yields A0 = 1, A16 = âˆ’6 âˆ’3A8 + 3
16 y,
A24 = 8 + 3A8 + 49
8 y, and A32 = âˆ’3 âˆ’A8 + 27
16 y. Since A16 â‰¥0, we have y â‰¥32
and hence k â‰¥8. Plugging the stated equations into the fourth MacWilliams equation
and solving for A8 gives A8 = yAâŠ¥
3
512 + 47y
512 âˆ’4 and A16 = 6 âˆ’3yAâŠ¥
3
512 âˆ’45y
512. Since
A16 â‰¥0 and y AâŠ¥
3 â‰¥0, we have 6 âˆ’45y
512 â‰¥0, so that y â‰¤68 + 4
15 and therefore
k â‰¤9.
53Consequently, for all t â‰¥2 the upper bound for A2(4t + 3, 8; 4) is tightened by one; cf. Lemma 4.

Partial Spreads and Vector Space Partitions
163
For k = 9, i.e., y = 64, A16 â‰¥0 gives AâŠ¥
3 â‰¤1. AâŠ¥
3 = 0 leads to A8 = 15
8 , which
is impossible. For AâŠ¥
3 = 1 the resulting weight enumerator of C is 1 + 2X8 +
406X24 + 103X32. However, there is no such code, as the sum of the two code-
words of weight 8 would be a third non-zero codeword of weight at most 16, which
does not exist.
In the case k = 8, i.e., y = 32, the ï¬rst MacWilliams equation forces A16 =
A8 = 0. The resulting weight enumerator of C is given by 1 + 204X24 + 51X32. In
particular, C is a projective [51, 8] two-weight code. By [12], this code is unique.
The proof is concluded by the observation that an ovoid in PG(3, F4) is a projective
quaternary [17, 4] two-weight code, such that the concatenation with the binary [3, 2]
simplex code yields a projective binary [51, 8] two-weight code.
â–¡
6
Open Research Problems
In this closing section we have collected some open research problems within the
scope of this article. All of them presumably are accessible using the theoreti-
cal framework of qr-divisible sets. Considerably more challenging is the question
whether similar methods can be developed for arbitrary constant-dimension codes in
place of of partial spreads (or vector space partitions). We only mention the following
example: The proof of A2(6, 4; 3) = 77 still depends on extensive computer calcula-
tions providing the upper bound A2(6, 4; 3) â‰¤77 [37]. The known theoretical upper
bound of 81 may be sharpened to 77 (along the lines of [57]), if only the existence
of a (6, 81, 4; 3)2 code can be excluded. The 81 planes in such a code would form
an exact 9-cover of the line set of PG(5, F2).
6.1
Better Constructions for Partial Spreads
The only known cases in which the construction of Theorem 2 has been surpassed are
derived from the sporadic example of a partial 3-spread of cardinality 34 in F8
2 [22],
which has 17 holes and can be used to show A2(3m + 2, 6; 3) â‰¥(23m+2 âˆ’18)/7
by adding m âˆ’2 layers of lifted MRD codes; cf. Lemma 4 and Corollary 2. A ï¬rst
step towards the understanding of the sporadic example is the classiï¬cation of all
22-divisible point sets of cardinality 17 in PG(k âˆ’1, F2). It turns out that there are
exactly 3 isomorphism types, one conï¬guration Hk for each dimension k âˆˆ{6, 7, 8}.
Generating matrices for the corresponding doubly-even codes are

164
T. Honold et al.
â›
âœâœâœâœâœâ
10000110010101110
01000010111011100
00100100000011000
00010111001110100
00001001100111110
00000011100111011
â
âŸâŸâŸâŸâŸâ 
,
â›
âœâœâœâœâœâœâœâ
10000011110100110
01000001111111000
00100010000110000
00010010000101000
00001001001000100
00000101001000010
00000010101011111
â
âŸâŸâŸâŸâŸâŸâŸâ 
,
â›
âœâœâœâœâœâœâœâœâœâ
10000000111011110
01000000010110000
00100000011100000
00010000001110000
00001001100000010
00000101000001010
00000011000000110
00000001111011101
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
.
(6.1)
While the classiï¬cation, so far, is based on computer calculations,54 one can easily
see that there are exactly three solutions of the MacWilliams identities.
Lemma 25 Let C be a 22-divisible point set over F2 of cardinality 17. Then k =
dimâŸ¨C âŸ©âˆˆ{6, 7, 8}, and the solutions of the MacWilliams identities are unique for
each k: (k; a5, a9, a13; AâŠ¥
3 ) = (6; 12, 49, 2; 6), (7; 25, 95, 7; 2), (8; 51, 187, 17; 0).
Proof The unique solution of the standard equations is given by a5 = 13
16 Â· 2kâˆ’2 âˆ’1,
a9 = 23
8 Â· 2kâˆ’2 + 3, and a13 =
5
16 Â· 2kâˆ’2 âˆ’3. Hence k â‰¥6, since otherwise a13 < 0,
and k â‰¤8, since C is self-orthogonal.55
â–¡
Theholesetofthepartial3-spreadin[22]correspondstoH7.Ageometricdescription
of this conï¬guration is given in [49, p. 84]. We have computationally checked that
indeed all three hole conï¬gurations can be realized by a partial 3-spread of cardinality
34 in F8
2.56 All three conï¬gurations have a non-trivial automorphism group, and hence
there is a chance to ï¬nd a partial 3-spread with nontrivial symmetries and eventually
discover an underlying more general construction. 57 So far we can only describe the
geometric structure of H6, H7, H8.
The hole conï¬guration H6 consists of two disjoint planes E1, E2 in PG(5, F2) and
a solid S spanned by lines L1 âŠ‚E1 and L2 âŠ‚E2. The 17 = 4 + 4 + 9 points of H6
are those in E1 \ L1, E2 \ L2, and S \ (L1 âˆªL2). An application of Lemma 17 (the
case q = r = i = 2) gives that H6 is 4-divisible. In sunï¬‚ower terms, F1 = {S, E1},
F2 = {S, E2} with centers L1, L2, respectively.
The hole conï¬guration H7 can be obtained by modifying a 3-sunï¬‚ower F =
{E, S1, S2}, whose petals are a plane E and two solids S1, S2 and whose base is a line
L. By Lemma 16(ii), the point set E âˆªS1 âˆªS2, of cardinality 3 + 4 + 12 + 12 = 31
is 4-divisible. From this set we remove two planes E1 âŠ‚S1, E2 âŠ‚S2 intersecting L
in different points. This gives H7.
The hole conï¬guration H8 can be obtained by modifying the cone construc-
tion of Lemma 19. We start with a projective basis B in F4
2, i.e., m = 5 points
with no 4 of them contained in a plane. Such point sets B are associated to the
54See http://www.rlmiller.org/de_codes and [19] for the classiï¬cation of, possibly non-projective,
doubly-even codes over Fv
2.
55Alternatively, the 4th MacWilliams identity yields 64 âˆ’2kâˆ’2 = 2kâˆ’3 Â· AâŠ¥
3 and hence k â‰¤8.
56624 non-isomorphic examples can be found at http://subspacecodes.uni-bayreuth.de [33].
57In a forthcoming paper we classify the 2612 non-isomorphic partial 3-spreads of cardinality 34 in
F8
2 that admit an automorphism group of order exactly 8, which is possible for H6 only, and show
that the automorphism groups of all other examples have order at most 4.

Partial Spreads and Vector Space Partitions
165
[5, 4, 2]2 even-weight code and hence 2-divisible. Since m â‰¡1 (mod 4), the proof
of Lemma 19 shows that a generalized cone K over B with 1-dimensional ver-
tex Q of multiplicity âˆ’m(q âˆ’1) â‰¡âˆ’m â‰¡3 (mod 4) is 4-divisible. Working over
Z, we can set Ï‡K (Q) = âˆ’1 as well. Adding any 4-divisible point set D contain-
ing Q (i.e., Ï‡D (Q) = 1) to K then produces a 4-divisible multiset set C with
#C = 10 âˆ’1 + #D and Ï‡C (Q) = 0. By making the ambient spaces of K and C
intersect only in Q (which requires embedding the conï¬guration into a larger space
Fv
2), we can force C to be a set. The conï¬guration H8 is obtained by choosing D as
an afï¬ne solid.58
From the preceding discussion it is clear that all possible hole types of a partial
3-spread of cardinality 34 in F8
2 belong to inï¬nite families of qr-divisible sets. Can
further 22-divisible sets of small cardinality be extended to an inï¬nite family?
Construction 1 For integers r â‰¥1 and 0 â‰¤m â‰¤r let S be a 2r-subspace. By
F1, . . . , F[m
1]q we denote the (2r + 1)-subspaces of F2r+m that contain S and by
L1, . . . , L[m
1]q we denote a list of r-subspaces of S with pairwise trivial inter-
section. Let 0 â‰¤a â‰¤
m
1

q and 0 â‰¤bi â‰¤qrâˆ’1 âˆ’1 for all 1 â‰¤i â‰¤a. For each
1 â‰¤i â‰¤a we choose q âˆ’1 + biq =: ci different (r + 1)-subspaces Ei, j of Fi
with Fi âˆ©S = Li. With this, we set C =

S\ âˆªa
i=1 Li

âˆª

âˆªa
i=1 âˆªci
j=1

Ei, j\Li

and observe dim(C ) â‰¤2r + m, #C =
2r
1

q + a Â·

qr+1 âˆ’
r+1
1

q

+ b Â· qr+1, where
b = 	a
i=1 bi, and that C is qr-divisible.
Proof Apply Lemmas 13, 14 using Ï‡v
C = Ï‡v
S +
a	
i=1
ci	
j=1
Ï‡v
Ei, j âˆ’q
a	
i=1
(bi + 1)Ï‡v
Li. â–¡
We remark that the construction can easily be modiï¬ed to obtain qr-divisible sets of
cardinality n =
2r
1

q + a Â·

qr+1 âˆ’
r+1
1

q

+ b Â· qr+1 and dimension v for all 2r +
m â‰¤v â‰¤2r + a(q âˆ’1) + bq. Choosing m = r, a = qrâˆ’1, and b = 0 we obtain a
qr-divisible set C of cardinality n = q2r +
râˆ’1
1

q and dimension v = 3r. For which
parameters r and q do partial (r + 1)-spreads of cardinality q2r+1 + qrâˆ’1, with hole
conï¬guration C , in F3r+2
q
exist? So far, such partial spreads are known for r = 1,
(q,r) = (2, 2) and all further examples would be strictly larger than the ones from
Theorem 2.
For the corresponding parameters over the ternary ï¬eld we currently only know
the bounds 244 â‰¤A3(8, 6; 3) â‰¤248. A putative plane spread in F8
3 of size 248 would
have a 32-divisible hole conï¬guration H of cardinality 56. Such a point set is unique
up to isomorphism and has dimension k = 6. It corresponds to an optimal two-weight
code with weight distribution 013661645112. The set H was ï¬rst described by R. Hill
in [34] and is known as the Hill cap. A generator matrix for is
58Since punctured afï¬ne solids are associated to the [7, 4, 3]2 Hamming code, we may also think
of H8 as consisting of the 2-fold repetition of the [5, 4, 2]-code and the Hamming code â€œglued
togetherâ€ in Q. In fact the doubly-even [17, 8, 4]2 code associated with H8 is the code I (3)
17 in [61,
p. 234]. The glueing construction is visible in the generator matrix.

166
T. Honold et al.
â›
âœâœâœâœâœâœâœâ
1 0 0 0 0 0 2 2 1 1 0 1 0 0 1 1 0 2 0 2 1 1 1 1 0 0 1 0 1 2 0 1 0 2 1 2 1 1 1 1 1 2 2 0 0 1 2 0 0 2 0 1 2 2 1 1
0 1 0 0 0 0 1 1 1 0 1 2 1 0 1 0 1 1 2 1 1 2 0 0 1 0 2 1 1 2 2 2 1 1 1 2 1 0 0 0 0 2 1 2 0 2 2 2 0 0 2 2 2 0 1 0
0 0 1 0 0 0 2 2 2 2 0 2 2 1 0 2 0 0 1 1 2 0 0 1 0 1 1 2 0 0 2 0 2 0 2 0 0 2 1 1 1 2 2 1 2 1 1 2 2 2 0 0 1 1 1 2
0 0 0 1 0 0 1 0 1 1 2 2 2 2 0 2 2 1 0 2 0 0 2 2 1 0 0 1 0 1 0 1 0 0 2 2 2 2 1 0 0 2 2 2 1 1 2 1 2 2 2 2 1 2 0 0
0 0 0 0 1 0 2 0 1 2 1 0 2 2 1 1 2 1 1 2 0 0 1 0 2 1 1 0 2 2 1 1 1 2 1 0 0 0 0 2 1 2 0 2 2 2 0 2 1 2 2 0 1 0 0 1
0 0 0 0 0 1 1 2 2 0 2 0 0 2 2 0 1 0 1 2 1 2 2 0 0 2 0 1 1 0 2 0 1 2 1 2 2 2 2 2 1 2 0 0 2 1 0 0 2 0 2 1 1 2 2 2
â
âŸâŸâŸâŸâŸâŸâŸâ 
.
The automorphism group has order 40320. Given the large automorphism group of
H , is it possible to construct a partial plane spread in F8
3 with size larger than 244?
For q = 2, the ï¬rst open case is 129 â‰¤A2(11, 8; 4) â‰¤132. A putative partial 4-
spread of size 132 has a 23-divisible hole conï¬guration of cardinality 67. Such exist
for all dimensions 9 â‰¤k â‰¤11; cf. Theorem 13(iii). Can one such 23-divisible set be
completed to a partial 4-spread?
Already the smallest open cases pose serious computational challenges. A promis-
ing approach is the prescription of automorphisms in order to reduce the computa-
tional complexity; see, e.g., Chapter â€œComputational Methods in Subspace Designsâ€
and [45] for an application of this so-called Kramer-Mesner method to constant-
dimension codes. Of course, the automorphisms have to stabilize the hole conï¬g-
uration, whose automorphism group is known or can be easily computed in many
cases.
6.2
Existence Results for qr-divisible Sets
Even for rather small parameters q and r we cannot decide the existence question,
see Table1 and [32].
Table 1 Undecided cases for the existence of qr-divisible sets
q
r
n
2
3
59
2
4
130, 131, 163, 164, 165, 185, 215, 216, 232, 233, 244, 245, 246, 247
3
2
70, 77, 99, 100, 101, 102, 113, 114, 115, 128
4
2
129, 150, 151, 172, 173, 193, 194, 195, 215, 216, 217, 236, 237,238, 239, 251, 258,
259, 261, 272, 279, 280, 282, 283, 293, 301, 305, 313, 314, 322, 326, 333, 334,
335,. . .
5
1
40
7
1
75, 83, 91, 92, 95, 101, 102, 103, 109, 110, 111, 117, 118, 119, 125, 126, 127, 133,
134, 135, 142, 143, 151, 159, 167
8
1
93, 102, 111, 120, 121, 134, 140, 143, 149, 150, 151, 152, 158, 159, 160, 161, 167,
168, 169, 170, 176, 177, 178, 179, 185, 186, 187, 188, 196, 197, 205, 206, 214,
215, 223, 224, 232, 233, 241, 242, 250, 251
9
1
123, 133, 143, 153, 154, 175, 179, 185, 189, 195, 196, 199, 206, 207, 208, 209,
216, 217, 218, 219, 226, 227, 228, 229, 236, 237, 238, 239, 247, 248, 249, 257,
258, 259, 267, 268, 269, 277, 278, 279, 288, 289, 298, 299, 308, 309, 318, 319,
329, 339, 349, 359

Partial Spreads and Vector Space Partitions
167
6.3
Vector Space Partitions
The most general result on the non-existence of vector space partitions (without
conditions on the ambient space dimension v) seems to be:
Theorem 14 (Theorem 1 in [29])
Let C be a vector space partition of type
kz Â· Â· Â· d2bd1a of Fv
q, where a, b > 0.
(i) If qd2âˆ’d1 does not divide a and if d2 < 2d1, then a â‰¥qd1 + 1;
(ii) if qd2âˆ’d1 does not divide a and if d2 â‰¥2d1, then a > 2qd2âˆ’d1 or d1 divides d2
and a =

qd2 âˆ’1

/

qd1 âˆ’1

;
(iii) if qd2âˆ’d1 divides a and d2 < 2d1, then a â‰¥qd2 âˆ’qd1 + qd2âˆ’d1;
(iv) if qd2âˆ’d1 divides a and d2 â‰¥2d1, then a â‰¥qd2.
For the special case d1 = 1, Theorems 11 and 12, presented in Sect.5, pro-
vide tighter results. For d1 > 1 we can replace d1-subspaces by the correspond-
ing point sets and apply results for qr-divisible sets. For vector space partitions
of type kz Â· Â· Â· 4b2a in Fv
2 we obtain 23-divisible sets of cardinality n = 3a, so that
a âˆˆ{5, 10, 15, 16} or a â‰¥20 by Theorem13(iii). Theorem 14 gives a = 5 or a â‰¥9,
and 4 | a implies a â‰¥16. However, not all results of Theorem 14 can be obtained
that easy. For vector space partitions of type kz Â· Â· Â· 4b3a in Fv
2 we obtain 23-divisible
sets of cardinality n = 7a, giving a = 7 or a â‰¥9. Theorem 14 gives a â‰¥9, and 2 | a
implies a â‰¥10. In order to exclude a = 7 one has to look at hyperplane intersec-
tions in this new setting. So far, we have used #(H âˆ©C ) â‰¡#C (mod qr). The sets
H âˆ©C have to come as a partition of type sd(s âˆ’1)c, where c + d = a. Here the
possible values for c are restricted by the cases of qrâˆ’1-divisible sets admitting the
partition type (s âˆ’1)c. This further reduces the possible hyperplane types, so that
eventually the linear programming method can be applied. In our situation we have
T (C ) âŠ†{25, 49}, which is excluded by Lemma 20. For the general case we intro-
duce the following notation: A point set C in PG(v âˆ’1, Fq) admits the partition type
sms Â· Â· Â· 1m1 if there exists a vector space partition of Fv
q of type sms Â· Â· Â· 1m1 that covers
the points in C and no other points. In terms of this, we may restate the previous
result as â€œthere is no 23-divisible set admitting the partition type 37â€. However, we
are very far from the generality and compactness of Theorem 14. Nevertheless, the
sketched approach seems to be a very promising research direction (and a natural
extension of the study of qr-divisible sets).
Acknowledgements The authors would like to acknowledge the ï¬nancial support provided by
COST â€“ European Cooperation in Science and Technology. The ï¬rst author was also supported by
the National Natural Science Foundation of China under Grant 61571006. The third author was
supported in part by the grant KU 2430/3-1 â€“ Integer Linear Programming Models for Subspace
Codes and Finite Geometry from the German Research Foundation.

168
T. Honold et al.
References
1. J. AndrÃ©, Ãœber nicht-desarguessche Ebenen mit transitiver Translationsgruppe. Mathematische
Zeitschrift 60(1), 156â€“186 (1954)
2. G. Andrews, The Theory of Partitions, 2nd edn. (Cambridge University Press, Cambridge,
1998)
3. S. Ball, A. Blokhuis, A. GÃ¡cs, P. Sziklai, Z. Weiner, On linear codes whose weights and length
have a common divisor. Adv. Math. 211(1), 94â€“104 (2007)
4. B.I. Belov, V.N. Logachev, V.P. Sandimirov, Construction of a class of linear binary codes
achieving the Varshamov-Griesmer bound. Probl. Inf. Transm. 10, 211â€“217 (1974)
5. J.D. Beule, A. Klein, K. Metsch, Substructures of ï¬nite classical polar spaces. In Beule and
Storme [6]
6. J.D. Beule, L. Storme (eds.), Current Research Topics in Galois Geometry (Nova Science
Publishers, 2011)
7. A. Beutelspacher, Partial spreads in ï¬nite projective spaces and partial designs. Mathematische
Zeitschrift 145(3), 211â€“229 (1975)
8. A. Beutelspacher, Partitions of ï¬nite vector spaces: an application of the Frobenius number in
geometry. Archiv der Mathematik 31(1), 202â€“208 (1978)
9. J. Bierbrauer, Introduction to Coding Theory (2005)
10. C. Bonferroni, Libreria internazionale Seeber, Teoria Statistica Delle Classi e Calcolo Delle
ProbabilitÃ  (1936)
11. R. Bose, K. Bush, Orthogonal arrays of strength two and three. Ann. Math. Statistics, 508â€“524
(1952)
12. I. Bouyukliev, V. Fack, W. Willems, J. Winne, Projective two-weight codes with small param-
eters and their corresponding graphs. Des. Codes Cryptogr. 41(1), 59â€“78 (2006)
13. A. Brauer, On a problem of partitions. Am. J. Math. 64(1), 299â€“312 (1942)
14. R. Calderbank, W. Kantor, The geometry of two-weight codes. Bull. Lond. Math. Soc. 18(2),
97â€“122 (1986)
15. P. Delsarte, Bounds for unrestricted codes, by linear programming. Philips Res. Rep 27,
272â€“289 (1972)
16. P. Delsarte, Weights of linear codes and strongly regular normed spaces. Discret. Math. 3,
47â€“64 (1972)
17. P. Dembowski, Finite Geometries: Reprint of the 1968 Edition (Springer Science and Business
Media, 2012)
18. S. Dodunekov, J. Simonis, Codes and projective multisets. Electron. J. Comb. 5(R37), 1â€“23
(1998)
19. C. Doran, M. Faux, S. Gates, T. HÃ¼bsch, K. Iga, G. Landweber, R. Miller, Codes and super-
symmetry in one dimension. Adv. Theor. Math. Phys. 15(6), 1909â€“1970 (2011)
20. D. Drake, J. Freeman, Partial t-spreads and group constructible (s,r, Î¼)-nets. J. Geom. 13(2),
210â€“216 (1979)
21. J. Eisfeld, L. Storme, t-spreads and minimal t-covers in ï¬nite projective spaces. Lecture Notes,
29 (2000)
22. S. El-Zanati, H. Jordon, G. Seelinger, P. Sissokho, L. Spence, The maximum size of a partial
3-spread in a ï¬nite vector space over GF(2). Des. Codes Cryptogr. 54(2), 101â€“107 (2010)
23. P. ErdËos, R. Rado, Intersection theorems for systems of sets. J. Lond. Math. Soc. (1) 35(1),
85â€“90 (1960)
24. T. Etzion, N. Silberstein, Error-correcting codes in projective spaces via rank-metric codes and
Ferrers diagrams. IEEE Trans. Inf. Theory 55(7), 2909â€“2919 (2009)
25. J. Galambos, Bonferroni inequalities. Ann. Probab. 577â€“581 (1977)
26. N.A. Gordon, R. Shaw, L.H. Soicher, Classiï¬cation of partial spreads in PG(4, 2) (2004). www.
maths.qmul.ac.uk/~leonard/partialspreads/PG42new.pdf
27. X. Guang, Z. Zhang, Linear Network Error Correction Coding (Springer, SpringerBriefs in
Computer Science, 2014)

Partial Spreads and Vector Space Partitions
169
28. O. Heden, The Frobenius number and partitions of a ï¬nite vector space. Archiv der Mathematik
42(2), 185â€“192 (1984)
29. O. Heden, On the length of the tail of a vector space partition. Discret. Math. 309(21), 6169â€“
6180 (2009)
30. O. Heden, A survey of the different types of vector space partitions. Discret. Math. Algorithms
Appl. 4(1), 14 (2012). nr. 1250001
31. D. Heinlein, T. Honold, M. Kiermaier, S. Kurz, A. Wassermann, On projective qr-divisible
codes. In preparation (2016)
32. D. Heinlein, T. Honold, M. Kiermaier, S. Kurz, A. Wassermann, Projective divisible binary
codes (2017). Preprint at arXiv: 1703.08291
33. D. Heinlein, M. Kiermaier, S. Kurz, A. Wassermann, Tables of subspace codes (2015). http://
subspacecodes.uni-bayreuth.de
34. R. Hill, Caps and codes. Discret. Math. 22(2), 111â€“137 (1978)
35. R. Hill, Optimal linear codes, in Cryptography and Coding II, ed. by C. Mitchell (Oxford
University Press, Oxford, 1992), pp. 75â€“104
36. S. Hong, A. Patel, A general class of maximal codes for computer applications. IEEE Trans.
Comput. 100(12), 1322â€“1331 (1972)
37. T. Honold, M. Kiermaier, S. Kurz, Optimal binary subspace codes of length 6, constant dimen-
sion 3 and minimum distance 4. Contemp. Math. 632, 157â€“176 (2015)
38. T. Honold, M. Kiermaier, S. Kurz, Classiï¬cation of large partial plane spreads in PG(6, 2) and
related combinatorial objects (2016). Preprint at arXiv: 1606.07655
39. T. Honold, M. Kiermaier, S. Kurz, Constructions and bounds for mixed-dimension subspace
codes. Adv. Math. Commun. 10(3), 649â€“682 (2016)
40. W. Huffman, V. Pless, Fundamentals of Error-Correcting Codes (Cambridge University Press,
Cambridge, 2003)
41. D.R. Hughes, F.C. Piper, Graduate Texts in Mathematics, 6th edn., Graduate Texts in Mathe-
matics (Springer, 1973)
42. N.L. Johnson, V. Jha, M. Biliotti, Handbook of Finite Translation Planes (CRC Press, 2007)
43. R. Koetter, F. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579â€“3591 (2008)
44. A. Kohnert, Constructing two-weight codes with prescribed groups of automorphisms. Discret.
Appl. Math. 155(11), 1451â€“1457 (2007)
45. A. Kohnert, S. Kurz, Construction of large constant dimension codes with a prescribed mini-
mum distance, Mathematical Methods in Computer Science (Springer, 2008), pp. 31â€“42
46. S. Kurz, Improved upper bounds for partial spreads. Designs, Codes and Cryptography (2016).
published online on Oct 25 (2016)
47. S. Kurz, Improved upper bounds for partial spreads. Des. Codes. Cryptogr. 85(1), 97â€“106
(2017â€“10). https://doi.org/10.1007/s10623-016-0290-8
48. S. Kurz, Packing vector spaces into vector spaces. Australas. J. Comb. 68(1), 122â€“130 (2017)
49. L. Lambert, Random network coding and designs over Fq. Ph.D. thesis, Ghent University,
Master Thesis, 2013
50. I.N. Landjev, Linear codes over ï¬nite ï¬elds and ï¬nite projective geometries. Discret. Math.
213, 211â€“244 (2000)
51. M. Lavrauw, O. Polverino, Finite semiï¬elds. In Beule and Storme [6], chapter 6, pp. 129â€“157
52. S. Lloyd, Binary block coding. Bell Syst. Tech. J. 36(2), 517â€“535 (1957)
53. F.J. MacWilliams, A theorem on the distribution of weights in a systematic code. Bell Syst.
Tech. J. 42(1), 79â€“94 (1963)
54. F.J. MacWilliams, J. Seery, The weight distributions of some minimal cyclic codes. IEEE Trans.
Inf. Theory 27, 796â€“806 (1981)
55. Z. Mateva, S. Topalova, Line spreads of PG(5, 2). J. Combin. Des. 17(1), 90â€“102 (2009)
56. M. MÃ©dard, A. Sprintson, Network Coding: Fundamentals and Applications (Elsevier, 2012)
57. A. NakiÂ´c, L. Storme, On the extendability of particular classes of constant dimension codes.
Des. Codes Cryptogr. 79(3), 407â€“422 (2016)

170
T. Honold et al.
58. E. NË˜astase, P. Sissokho, The maximum size of a partial spread II: upper bounds. Discret. Math.
340(7), 1481â€“1487 (2017). https://doi.org/10.1016/j.disc.2017.02.001
59. E.L. NË˜astase, P.A. Sissokho, The maximum size of a partial spread in a ï¬nite projective space.
J. Comb. Theor. Ser. A 152, 353â€“362 (2017â€“11). https://doi.org/10.1016/j.jcta.2017.06.012
60. R. Plackett, J. Burman, The design of optimum multifactorial experiments. Biometrika 33(4),
305â€“325 (1946)
61. V. Pless, N. Sloane, On the classiï¬cation and enumeration of self-dual codes. J. Comb. Theory
Ser. A 18(3), 313â€“335 (1975)
62. B.Segre,Teoriadigalois,ï¬brazioniproiettiveegeometrienondesarguesiane.AnnalidiMatem-
atica Pura ed Applicata 64(1), 1â€“76 (1964)
63. N. Silberstein, T. Etzion, Large constant dimension codes and lexicodes. Adv. Math. Commun.
5(2), 177â€“189 (2011)
64. D. Silva, F. Kschischang, R. Koetter, A rank-metric approach to error control in random network
coding. IEEE Trans. Inf. Theory 54(9), 3951â€“3967 (2008)
65. M.A. Tsfasman, S.G. VlË˜aduÂ¸t, Geometric approach to higher weights. IEEE Trans. Inf. Theory
41, 1564â€“1588 (1995)
66. J.H. van Lint, R.M. Wilson, A Course in Combinatorics (Cambridge University Press, Cam-
bridge, 1992)
67. H. Ward, Divisibility of codes meeting the griesmer bound. J. Comb. Theory Ser. A 83(1),
79â€“93 (1998)
68. H. Ward, An introduction to divisible codes. Des. Codes Cryptogr. 17(1), 73â€“79 (1999)
69. H. Ward, Divisible codes - a survey. Serdica Math. J. 27(4), 263pâ€“278p (2001)
70. R.W. Yeung, S.-Y.R. Li, N. Cai, Z. Zhang, Network coding theory. Found. Trends Commun.
Inf. Theory 2(4/5), 241â€“381 (2006)

q-Analogs of Designs: Subspace Designs
Michael Braun, Michael Kiermaier and Alfred Wassermann
Abstract For discrete structures which are based on a ï¬nite ambient set and its
subsets there exists the notion of a â€œq-analogâ€: For this, the ambient set is replaced
by a ï¬nite vector space and the subsets are replaced by subspaces. Consequently,
cardinalities of subsets become dimensions of subspaces. Subspace designs are the
q-analogs of combinatorial designs. Introduced in the 1970s, these structures gained
a lot of interest recently because of their application to random network coding. In
this chapter we give a thorough introduction to the subject starting from the sub-
space lattice and its automorphisms, the Gaussian binomial coefï¬cient and counting
arguments in the subspace lattice. This prepares us to survey the known structural
and existence results about subspace designs. Further topics are the derivation of
subspace designs with related parameters from known subspace designs, as well as
inï¬nite families, intersection numbers, and automorphisms of subspace designs. In
addition, q-Steiner systems and so called large sets of subspace designs will be cov-
ered. Finally, this survey aims to be a comprehensive source for all presently known
subspace designs and large sets of subspace designs with small parameters.
1
Introduction
Concepts, theories, and discrete structures based on ï¬nite sets and their subsets turn
into a combinatorial â€œq-analogâ€ if they are considered over vector spaces over a ï¬nite
ï¬eld Fq with q elements. In this case, â€œsubsetsâ€ of a ï¬nite set become â€œsubspacesâ€
M. Braun (B)
Faculty of Computer Science, Darmstadt University of Applied Sciences, 64295 Darmstadt,
Germany
e-mail: michael.braun@h-da.de
M. Kiermaier Â· A. Wassermann
Department of Mathematics, University of Bayreuth, 95440 Bayreuth, Germany
e-mail: michael.kiermaier@uni-bayreuth.de
A. Wassermann
e-mail: alfred.wassermann@uni-bayreuth.de
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_8
171

172
M. Braun et al.
of a vector space and â€œcardinalitiesâ€ of subsets become â€œdimensionsâ€ of subspaces.
In fact, combinatorics on ï¬nite sets can be considered as the limiting case â€œq tends
to 1â€ of combinatorics on vector spaces over Fq, see Tits [1] and Sect.2.2.
A very prominent example is the â€œq-analog of a combinatorial t-designâ€â€”the
major object of this chapter. We start with the well-known deï¬nition of a combina-
torial design.
Deï¬nition 1 Let V be a set of size v, 0 â‰¤t â‰¤k â‰¤v integers and Î» a non-negative
integer. A pair D = (V, B), where B a (multi-)set of k-subsets (blocks) of V , is
called a t âˆ’(v, k, Î») design on V , if each t-subset of V is contained in exactly Î»
blocks.
If B is a set, i.e. if every k-subset appears at most once in B, the design is called
simple.
For a t-(v, k, Î») design, the integer Î» is the index of the design and t is called its
strength. Combinatorial designs have a long history starting in the 19th century with
the works of PlÃ¼cker, Kirkman and Steiner. There are many prominent applications
of designs, among them are design of experiments and coding theory, to name the
most prominent ones. See the voluminous books Design Theory [2] and Handbook
of Combinatorial Designs [3] for a comprehensive overview.
Now, we turn to the q-analogs of combinatorial designs. Throughout this chapter,
q will be a prime power and V a vector space over the ï¬nite ï¬eld Fq of ï¬nite
dimension v. Subspaces of dimension k will be called k-subspaces. Then, the q-
analog of a design is deï¬ned as follows.
Deï¬nition 2 Let 0 â‰¤t â‰¤k â‰¤v be integers and Î» a non-negative integer. A pair
D = (V, B), where B is a collection of k-subspaces (blocks) of V , is called a t-
(v, k, Î»)q subspace design on V if each t-subspace of V is contained in exactly Î»
blocks.
If B is a set, i.e. if every k-subset appears at most once in B, the design is called
simple.
We will see that combinatorial designs can be seen as the case q = 1 of subspace
designs. Consequently, a t-(v, k, Î») design may also be denoted as a t-(v, k, Î»)1
design, see Sect.2.2.
In the following, all subspace designs will be assumed to be simple unless explic-
itly stated otherwise. If we allow multiple occurrence of k-subspaces in the set of
blocks we speak of non-simple (subspace) designs.
A particular class of subspace designs are t-(v, k, 1)q designs which are called
q-analogs of Steiner systems or simply q-Steiner systems. Analogously to ordinary
Steiner systems on sets, we use the notation S(t, k, v)q in order to indicate a q-Steiner
system with parameters t-(v, k, 1)q. An important subclass is given by the q-Steiner
triple systems STS(v)q, which are Steiner systems with the parameters S(2, 3, v)q.
Viewed as subspace codes, q-Steiner system are diameter perfect codes, see [4]. For
more information on subspaces codes the reader is referred to part I, in particular to
chapters â€œCodes Endowed with the Rank Metricâ€â€“â€œConstruction of Cyclic Subspace
Codes and Maximum Rank Distance Codesâ€, and for geometric aspects to chapters

q-Analogs of Designs: Subspace Designs
173
â€œGeometrical Aspects of Subspace Codesâ€ and â€œPartial Spreads and Vector Space
Paritionsâ€.
Remarkably, many different names for q-analogs of designs can be found in the
literature including
â€¢ subspace designs,
â€¢ designs over ï¬nite ï¬elds,
â€¢ designs over Fq,
â€¢ q-designs,
â€¢ geometric designs,
â€¢ designs in vector spaces, and
â€¢ designs in the q-Johnson scheme.
The name â€œsubspace designâ€ has the advantage of being short and not involving
symbols like q. Furthermore, it nicely ï¬ts the closely related terms â€œsubspace latticeâ€
and â€œsubspace codeâ€.
2
The Subspace Lattice
A closer look at Deï¬nition 1 reveals that the deï¬nition of a combinatorial design can
entirely be expressed in terms of the subset lattice of the v-element set V . The idea
behind q-analogs in combinatorics is to replace the subset lattice by the subspace
lattice of a v-dimensional Fq-vector space V .
An introduction to the theory of lattices can be found in the classical textbooks
by Birkhoff [5] and Stanley [6].
We denote the set of all subspaces of V by L (V ). The set of all k-subspaces of
V is called the GraÃŸmannian and denoted by
V
k

q (Fig.1).
The partially ordered set (poset) (L (V ), â‰¤) forms a latticeâ€”the subspace lat-
ticeâ€”with containment â€œâ‰¤â€ of subspaces as partial order relation, intersection â€œâˆ©â€
of subspaces as meet and sum â€œ+â€ of subspaces as join operator. Moreover, the
subspace lattice is graded with the dimension â€œdimâ€ of subspaces as rank function.
The dimension formula
dim(U) + dim(U â€²) = dim(U âˆ©U â€²) + dim(U + U â€²) for all U,U â€² âˆˆL (V )
implies that L (V ) is a modular lattice.
Projective Geometry
From a slightly different point of view, for v â‰¥2 the lattice L (V ) is also known as
the projective geometry PG(V ). As the projective geometric dimension is always one
less then the corresponding algebraic dimension, k-subspaces are called (k âˆ’1)-ï¬‚ats,
and the isomorphism class of the ï¬nite geometry PG(V ) is denoted by PG(v âˆ’1, q).
The 1-subspaces of V are called points, the 2-subspaces lines, the 3-subspaces planes,
the 4-subspaces solids and the (v âˆ’1)-subspaces hyperplanes.

174
M. Braun et al.
0000
V
0

2
0001
V
1

2
0010
0001
V
2

2
0100
0010
0001
V
3

2
1000
0100
0010
0001
V
4

2
Fig. 1 Subspace lattice of F4
2
Coordinates
After a choice of a basis, from now on we may identify V with Fv
q, whose elements
will be considered as row vectors. Now, subspaces U âˆˆL (V ) may be represented
as the row space of a dim(U) Ã— v generator matrix A. To get a unique matrix, the
reduced row echelon form of A may be used.
Example 1 The following ï¬ve matrices whose rows form bases of 2-dimensional
subspaces deï¬ne a set of 2-subspaces of the standard vector space F4
2 yielding a
1-(4, 2, 1)2 design:
0110
0001

,
1000
0010

,
1100
0011

,
1001
0100

,
1011
0101

.
As can be seen in Fig.2, every 1-subspace is contained in exactly one block of the
design.
2.1
Automorphisms
Lattice Automorphisms
A bijection Ï† : L â†’L on a lattice (L , â‰¤, âˆ¨, âˆ§) is an automorphism of L if one
of the following equivalent conditions is satisï¬ed for all subspaces x, y âˆˆL :

q-Analogs of Designs: Subspace Designs
175
Fig. 2 A 1-(4, 2, 1)2 design in the subspace lattice of F4
2
â€¢ x â‰¤y if and only if Î±(x) â‰¤Î±(y),
â€¢ Î±(x âˆ¨y) = Î±(x) âˆ¨Î±(y),
â€¢ Î±(x âˆ§y) = Î±(x) âˆ§Î±(y).
Moreover, Ï† is an antiautomorphism of L if one of the following equivalent condi-
tions is satisï¬ed for all subspaces:
â€¢ x â‰¤y if and only if Î±(y) â‰¤Î±(x),
â€¢ Î±(x âˆ¨y) = Î±(x) âˆ§Î±(y),
â€¢ Î±(x âˆ§y) = Î±(x) âˆ¨Î±(y).
The lattice L is called self-dual if and only if there exists an antiautomorphism of L .
The set of all automorphisms of L is a subgroup of the symmetric group on L . It is
called the automorphism group of L and denoted by Aut(L ). As the composition
of two antiautomorphisms is always an automorphism, we see that the set of all
automorphisms and antiautomorphisms forms a group, too, containing Aut(L ) as a
normal subgroup of index 1 or 2. The second case occurs if and only if # L â‰¥2 and
L is self-dual.
Group Actions
Let G be a group acting on a set X. The action is said to be transitive if there is only
a single orbit, so for each x âˆˆX we have {Î±(x) : Î± âˆˆG} = X. The kernel of the
action is deï¬ned as
G X = {Î± âˆˆG | Î±(x) = x for all x âˆˆX} .

176
M. Braun et al.
The action is called faithful if G X = {1}. The stabilizers of elements in the same
orbit are related by the formula
GÎ±(x) = Î±GxÎ±âˆ’1.
(1)
Automorphisms of the Subspace Lattice
As usual, the group of all linear bijective mappings on V is denoted by GL(V ),
and the group of all semilinear bijective mappings on V is denoted by L(V ). GL(V )
is a normal subgroup of L(V ) and L(V ) âˆ¼= Aut(Fq) â‹ŠGL(V ).
Now, the groups GL(V ) and L(V ) act transitively and faithfully on the elements
of V . However in general, the induced actions on L (V ) are neither transitive nor
faithful. The orbits of the action of these groups on subspaces of V are given by
V
k

q
with k âˆˆ{0, . . . , v}. In both cases, the kernel of the action is the set C = {v â†’Î»v |
Î» âˆˆFq}, which equals the center of GL(V ).1 So we arrive at the groups PGL(V ) =
GL(V )/C and PL(V ) = L(V )/C which act faithfully on L (V ). Again, PGL(V )
is a normal subgroup of PL(V ) and PL(V ) âˆ¼= Aut(Fq) â‹ŠPGL(V ).
The elements of PGL(V ) will be called the linear elements of PL(V ). In the
case that q is prime, the group PL(V ) equals PGL(V ), and for the important case
q = 2, it reduces further to GL(V ). As the mappings in PGL(V ) and PL(V ) are
already determined by their images on the point set
V
1

q, we may consider them as
permutations of
V
1

q.
The following famous result which is called the â€œFundamental Theorem of Pro-
jective Geometryâ€ can be found for instance in Artinâ€™s book [7].
Theorem 1 For v â‰¥3 the automorphism group of the lattice (L (V ), â‰¤) is given
by the natural action of PL(V ) on L (V ).
In this way, the group PL(V ) (and its subgroup PGL(V )) provide a notion of
(linear) automorphisms and (linear) equivalence on L (V ) and on derived sets like
the power set of L (V ).
The group GL(V ) is represented by the group GL(v, q) of all invertible v Ã— v
matrices over Fq, via assigning the map x â†’xA to the matrix A âˆˆGL(v, q). More-
over, L(V ) is represented by the set L(v, q) of the pairs (A, Ïƒ) âˆˆGL(v, q) Ã—
Aut(Fq) via x â†’Ïƒ(x)A, where Ïƒ is applied simultaneously to all entries of x. By
composition of the represented maps (acting from the right), L(v, q) carries the
structure of a semidirect product GL(v, q) â‹ŠAut(Fq), where the explicit multipli-
cation law is given by
(A, Ïƒ) Â· (Aâ€², Ïƒ â€²) = (Ïƒ â€²(A)Aâ€², Ïƒ â—¦Ïƒ â€²).
The center of GL(v, q) is the set Fq Iv of the scalar matrices (Iv denoting the v Ã— v
identitymatrix).Therefore,PGL(V )isrepresentedbyPGL(v, q) = GL(v, q)/(Fq Iv)
and PL(V ) by PL(v, q) = L(V, q)/(Fq Iv, idFq).
1We would like to point out that the center of L(V ) is smaller, as it consists only of the elements
of C where Î» is an element of the prime ï¬eld of Fq.

q-Analogs of Designs: Subspace Designs
177
Duality
We ï¬x some non-singular bilinear form Î² : V Ã— V â†’Fq. For V = Fv
q, the standard
inner product (x, y) â†’v
i=1 xi yi may be taken. The dual subspace of U âˆˆL (V )
is deï¬ned as
U âŠ¥= {x âˆˆV | Î²(x, y) = 0 for all y âˆˆU}.
For all U âˆˆL (V ), (U âŠ¥)âŠ¥= U. In particular, U â†’U âŠ¥is a bijection on L (V ).
Moreover, for all U1,U2 âˆˆL (V ) we have
(U1 âˆ©U2)âŠ¥= U âŠ¥
1 + U âŠ¥
2
and (U1 + U2)âŠ¥= U âŠ¥
1 âˆ©U âŠ¥
2 .
Thus, the mapping U â†’U âŠ¥is an antiautomorphism of L (V ), showing that the
subspace lattice is self-dual.
2.2
The Gaussian Binomial Coefï¬cient
A complete chain in the subspace lattice of V has the form
{0} = U0 < U1 < U2 < . . . < Uv = V
with dim(Ui) = i.
To count the number of complete chains, we denote the number of partial chains
U0 < U1 < . . . < Uk with dim(Ui) = i by ak. For k â‰¥1, Uk = âŸ¨Ukâˆ’1 âˆª{x}âŸ©for any
x âˆˆV \ Ukâˆ’1. As there are qv âˆ’qkâˆ’1 = qkâˆ’1(qvâˆ’k+1 âˆ’1) vectors x âˆˆV \ Uk, and
any qk âˆ’qkâˆ’1 = qkâˆ’1(q âˆ’1) vectors x yield the same space Uk, we see that
ak = qvâˆ’k+1 âˆ’1
q âˆ’1
akâˆ’1 .
Now inductively,
ak =
k	
i=1
qvâˆ’i+1 âˆ’1
q âˆ’1
=
v	
i=vâˆ’k+1
qi âˆ’1
q âˆ’1
and therefore the number of complete chains of V is the q-factorial
[v]q! := av =
v	
i=1
qi âˆ’1
q âˆ’1 .
The name q-factorial stems from the observation that the complete ï¬‚ags of the
subset lattice of a v-element set V correspond to the permutations of V and therefore,

178
M. Braun et al.
their number is the ordinary factorial v!. This can be carried a step further: Accepting
[v]q = qvâˆ’1
qâˆ’1 as the q-analog of the non-negative integer v, the q-factorial [v]q! =

v
i=1[i]q arises in the very same way from the q-numbers as the ordinary factorial
from ordinary numbers. For a deeper discussion ofq-analogs of permutations, see [6].
LetUk âˆˆ
V
k

q andlet H = V/Uk = {v + Uk | v âˆˆV }bethecorrespondingfactor
vector space. It is easy to see that the mapping
{J âˆˆ
V
j

q
| Uk â‰¤J} â†’
 H
j âˆ’k

q
, J â†’J/Uk = {v + Uk | v âˆˆJ}
is a well-deï¬ned bijection.
Next, we derive a formula for the number
v
k

q of k-subspaces of V . For this
purpose, we count the complete chains U0 < . . . < Uk < . . . < Uv of V in a second
way: There are
v
k

q possibilities for the choice of Uk. For ï¬xed Uk, the number of
possible head parts U0 < . . . < Uk is given by [k]q!. Modding out Uk,2 the possible
tail parts Uk < . . . < Uv = V uniquely correspond to the complete chains of V/Uk,
whose number is [v âˆ’k]q!. So,
[v]q! =
v
k

q
Â· [k]q! Â· [v âˆ’k]q! ,
and therefore
#
V
k

q
=
v
k

q
=
[v]q!
[k]q![v âˆ’k]q!.
The expression
v
k

q is known as the Gaussian binomial coefï¬cient or also as q-
binomial coefï¬cient, as it arises from the q-factorial in the usual way. If clear from
the context, the index q may be dropped from
v
k

q or
V
k

q for simplicity. Like for the
ordinary binomial coefï¬cient, it is convenient to deï¬ne
v
k

q = 0 for integers k < 0
or k > v.
Many well-known formulas for binomial coefï¬cients have q-analogs, and quite
often, bijective proofs can be q-analogized. As easy examples, we mention
v
k

=

v
v âˆ’k

and
v
h
v âˆ’h
k

=
v
k
v âˆ’k
h

,
and for v â‰¥1 the q-Pascal triangle identities
2For a subspace U of V , the quotient space is given by V/U = {v + U | v âˆˆV } with the associated
canonical projection Ï€ : V â†’V/U, v â†’v + U. Extending the domain to the set of subspaces of
V , Ï€ provides an lattice isomorphism between the lattice interval [U, V ] = {Uâ€² âˆˆL (V ) | U â‰¤
Uâ€² â‰¤V } and the subspace lattice L (V/U).

q-Analogs of Designs: Subspace Designs
179
v
k

q
=
v âˆ’1
k âˆ’1

q
+ qk
v âˆ’1
k

q
= qvâˆ’k
v âˆ’1
k âˆ’1

q
+
v âˆ’1
k

q
.
The expressions [v]q = 1 + q + . . . + qvâˆ’1 and [v]q! are polynomials in Z[q] of
degrees v âˆ’1 and v(v âˆ’1)/2, respectively. By the formula
v
k

q
=
k	
i=1
qvâˆ’i+1 âˆ’1
qi âˆ’1
,
it is checked that
v
k

q is a polynomial in q, too, and its degree is
vâˆ’1
kâˆ’1

. The factoriza-
tion of Xn âˆ’1 in the UFD Z[X] is given by 
d Î¦d, where d runs over the positive
divisors of n and Î¦d âˆˆZ[X] denotes the d-th cyclotomic polynomial. Therefore,
q-numbers and q-binomial coefï¬cients factor into a product of pairwise distinct
cyclotomic polynomials Î¦d with d â‰¥2.
Remark 1 According to [8], q-analog numbers were introduced in [9] and their
binomial coefï¬cients in [10]. For a deeper discussion, see [6, 8, 11â€“13].
2.3
Counting Subspaces
The number of k-subspaces of V is given by
v
k

q. Applying this argument to the
quotient space V/U for some U âˆˆ
V
u

q, we see that the number of k-subspaces K
with U â‰¤K â‰¤V equals
vâˆ’u
kâˆ’u

q.
Every k-subspace K of V has a complement, that is a subspace U âˆˆL (V ) with
K âˆ©U = {0} and K + U = V . By the dimension formula, dim(U) = v âˆ’k. An
important difference to the subset lattice is that in general, the complement is not
unique. More precisely, K has exactly qk(vâˆ’k) complements in V . For this, one
checks that after picking some complement U of K in L (V ), the complements
of K in L (V ) bijectively correspond to the homomorphisms Ï† âˆˆHom(U, K) via
Ï† â†’im(id +Ï†). Now the claim follows as
dim(Hom(U, K)) = dim(U) dim(K) = (v âˆ’k)k .
Alternatively, after the choice of a suitable basis the subspace U can be represented
as the row space of the k Ã— v-matrix (0 | Ik). One checks that the complements of U
are given by the row spaces of the k Ã— v matrices (A | I) with A âˆˆF(vâˆ’k)v
q
, whose
number is qk(vâˆ’k).
Lemma 1 Let J â‰¤K â‰¤V be a chain of Fq-vector spaces of ï¬nite dimensions j, k
and v. The number of u-subspaces U of V with U âˆ©K = J is

180
M. Braun et al.
q(kâˆ’j)(uâˆ’j)
v âˆ’k
u âˆ’j

q
.
Proof By the dimension formula, dim(U + K) = u + k âˆ’j. So the possibilities
for U + K are given by the
vâˆ’k
uâˆ’j

q intermediate spaces W of K â‰¤V of dimension
u + k âˆ’j. Now modding out J, the u-subspaces U of V with U âˆ©K = J and
U + K = W correspond to the complements of K/J in W/J. Their number is
qdim(K/J)(dim(W/J)âˆ’dim(K/J)) = q(kâˆ’j)(uâˆ’j).
â–¡
2.4
q-Analogs of Combinatorial Structures
As already discussed, we consider the subspace lattice L (V ) of a vector space
V of dimension v as the q-analog of the subset lattice of a v-element set V . In
Sect.2.2 we have used this approach to derive q-analog numbers, factorials and
binomial coefï¬cients, which are polynomials in Z[q]. For q = 1, they reduce to
ordinary numbers, factorials and binomial coefï¬cients. Hence the subset lattice may
be considered as the limit case q = 1 of a subspace lattice over Fq. For a deeper
discussion see [11], where even the notion of an unary â€œï¬eldâ€ F1 is used.
Many combinatorial areas, like design theory and coding theory, are based on
the subset lattice of a v-element ambient set V . Given such a class of combinatorial
objects, we may deï¬ne its q-analog by replacing the subset lattice by the subspace
lattice of some Fq-vector space V of dimension v. Thereby, all notions depending
on the subset lattice get replaced by the corresponding counterpart in the subspace
lattice. Some of these correspondents are shown in Table2.4. The original class of
objects is then considered as the case q = 1 of the q-analog classes. An important
part of the theory of q-analogs is the investigation of results in the set-theoretic case
for their applicability in the q-analog case.
q = 1
q-analog
v-element set V
v-dim. Fq vector space V
elements of V (points) 1 âˆ’subspaces of V (points)
subset lattice of V
subspace lattice of V
V
k

V
k

q
v
k

v
k

q
cardinality
dimension
âˆ©
âˆ©
âˆª
+

q-Analogs of Designs: Subspace Designs
181
3
Subspace Designs
For all suitable parameters there exist always at least two designs. First, for all
t âˆˆ{0, . . . , k} and B = âˆ…, (V, B) is a t-(v, k, 0)q subspace design. Second, (V, B)
with B being the full GraÃŸmannian, i.e. B =
V
k

, is also a design for all t â‰¤k,
called the complete design.
Lemma 2 For 0 â‰¤t â‰¤k â‰¤v, (V,
V
k

q) is a t-(v, k,
vâˆ’t
kâˆ’t

q)q subspace design.
Proof As we have seen in Sect.2.3, any t-subspace T of V is contained in exactly
vâˆ’t
kâˆ’t

k-subspaces of V . This number is independent of the choice of T .
â–¡
Both designs are called trivial. Since the full GraÃŸmannian
V
k

is the design with
the largest possible value of Î» among all simple designs with block dimension k, we
deï¬ne
Î»max =
v âˆ’t
k âˆ’t

q
.
It is clear that for any t-(v, k, Î»)q subspace design D = (V, B), the supplementary
design (V,
V
k

\ B) is again a subspace design with the parameters t-(v, k,
vâˆ’t
kâˆ’t

q âˆ’
Î»)q. The empty set and the full GraÃŸmannian are supplementary to each other.
The earliest reference for q-analogs of designs we are aware of, is from Ray-
Chaudhuri [14], stated in the problem section of the Hypergraph Seminar at Ohio
State University 1972. One year later, Cameron [15] presented the same problem at
the British Combinatorial conference. The origin of the idea is unclear, since it is
stated there that â€œSeveral people have observed that the concept of a t-design can be
generalized [...]â€. Subspace designs have also been mentionedâ€”independentlyâ€”in
a more general context by Delsarte in [16].
The existence of nontrivial subspace designs with t â‰¥2 was open for more than
a decade, until in [17] subspace designs with the parameters 2-(v, 3, 7)2 and v â‰¡
1, 5 mod 6, v â‰¥7 have been constructed. This construction was generalized to 2-
(v, 3, q2 + q + 1)q designs for arbitrary q in [18, 19]. In [20] a 3-(8, 4, 11)2 design
was given, the ï¬rst nontrivial subspace design with t = 3. Until now, no explicit
example with t â‰¥4 is known.
3.1
Divisibility Conditions
The following statement is the q-analog of a well-known property of combinatorial
designs and was ï¬rst shown in [21, Lemma 4.1(1)].
Lemma 3 Let
D = (V, B)
be
a
t-(v, k, Î»)q
subspace
design.
For
each
s âˆˆ{0, . . . , t}, D is an s-(v, k, Î»s)q subspace design with

182
M. Braun et al.
Î»s =
vâˆ’s
tâˆ’s

q
kâˆ’s
tâˆ’s

q
Â· Î» =
vâˆ’s
kâˆ’s

q
vâˆ’t
kâˆ’t

q
Â· Î».
In particular, the number of blocks is given by #B = Î»0.
Proof Let s âˆˆ{0, . . . , t}, S âˆˆ
V
t

q and Î»S the number of blocks of D containing S.
We count the set X of all pairs (T, B) âˆˆ
V
t

q Ã— B with S â‰¤T â‰¤B in two ways:
There are
vâˆ’s
tâˆ’s

q subspaces T containing S, and by the design property each T
is contained in Î» blocks K. So #X =
vâˆ’s
tâˆ’s

q Â· Î». On the other hand, there are Î»S
blocks B âˆˆB containing S, each containing
kâˆ’s
tâˆ’s

q subspaces T âˆˆ
V
t

q. This shows
#X = Î»S Â·
kâˆ’s
tâˆ’s

q. The proof is concluded by equalizing these two expressions for
#X.
â–¡
Deï¬nition 3 For s = t âˆ’1, the resulting design of Lemma 3 is called the reduced
design of D.
Furthermore,byLemma3,theexistenceofat-(v, k, Î»)q designimpliestheintegrality
conditions
Î»s âˆˆZ, i.e.
v âˆ’s
t âˆ’s

q
Â· Î» â‰¡0
(mod
k âˆ’s
t âˆ’s

q
)
for all s âˆˆ{0, . . . , t}. Without requiring the actual existence of a corresponding
design,anyparametersett-(v, k, Î»)q fulï¬llingtheintegralityconditionswillbecalled
admissible. Moreover, it will be called realizable if a t-(v, k, Î»)q design does actually
exist. Of course, realizability implies admissibility. For q = 1, counterexamples are
known showing that the contrary is not always true. For q â‰¥2, this is an open
question.
It is easily seen that a 1-(v, k, Î»)q design is admissible if and only if k | v. In fact,
for Î» = 1, all those subspace designs are realizable:
Lemma 4 There exists a 1-(v, k, 1)q design if and only if k divides v.
Proof The direction â€œâ‡’â€ follows from the integrality conditions. For â€œâ‡â€, let v be
a multiple of k. Then
Fqv
1

qk forms a 1-(v, k, 1)q design on the Fq-vector space Fqv.
â–¡
The above result has been shown in [22] (see also [23] for the case v = 2k) in
geometric terms: A 1-(v, k, 1)q design is known as a (k âˆ’1)-spread in PG(v âˆ’1, q).
The admissibility of a Steiner triple system STSq(v) (v â‰¥3) depends on the
numbers Î»1 = [vâˆ’1]q
Î¦2
and Î»0 = [vâˆ’1]q[v]q
Î¦2Î¦3
(see Example 4) being integers. The result-
ing condition is that STSq(v) is admissible if and only if v â‰¡1 (mod 6) or v â‰¡3
(mod 6). This condition does not depend on q and coincides with the admissibility
in the case q = 1 of a combinatorial Steiner triple system STS(v).

q-Analogs of Designs: Subspace Designs
183
The smallest admissible parameter set of a q-analog of a Steiner system with
t â‰¥2 is the Steiner triple system STSq(7) or, in other words, a 2-(7, 3, 1)q design.
For q = 1, there is a unique design with these parameters, namely the Fano plane.
Arguably, the most important open problem in the theory of subspace designs is the
question for the existence of a 2-(7, 3, 1)q design, also known as a q-analog of the
Fano plane. This question was already stated in 1972, in the introduction on subspace
designs by Ray-Chaudhuri in [14].
The only q-analog of a Steiner triple system known to be realizable is STS(13)2,
see Sect.6.1.
3.2
New Designs from Old Ones
Lemma 5 (Suzuki [21]) Let D = (V, B) be a t-(v, k, Î»)q-design. For subspaces
I â‰¤J â‰¤V , let i = dim(I), j = dim(V/J) and
Î›I,J = {B âˆˆB | I â‰¤B â‰¤J} .
If i + j â‰¤t, the number
Î»i, j := #Î›I,J
only depends on the dimensions i and j, but not on the exact choice of I and J. The
numbers Î»i, j are determined by the recurrence formula
Î»i,0 = Î»i
and Î»i, j = Î»i, jâˆ’1 âˆ’qvâˆ’kâˆ’j+1Î»i+1, jâˆ’1.
In closed form,
Î»i, j = Î»
vâˆ’iâˆ’j
kâˆ’i

q
vâˆ’t
kâˆ’t

q
.
Proof Let i + j â‰¤t. We proceed by induction over j.
For j = 0, we have J = V and #Î›I,J = Î»i is independent of the choice of I.
Now assume j â‰¥1 and let Ë†J be a superspace of J with dim( Ë†J/J) = 1. We count the
set X of all pairs ( Ë†I, B) âˆˆ
 V
i+1

q Ã— B with Ë†I â‰¤B â‰¤Ë†J and Ë†I âˆ©J = I in two ways.
By Lemma 1, the number of Ë†I âˆˆ

Ë†J
i+1

q with Ë†I âˆ©J = I is q((vâˆ’j)âˆ’i)((i+1)âˆ’i) =
qvâˆ’jâˆ’i. By the induction hypothesis, for each such subspace Ë†I there are Î»i+1, j+1
blocks B âˆˆB with Ë†I â‰¤B â‰¤Ë†J. So,
#X = qvâˆ’jâˆ’iÎ»i+1, jâˆ’1 .
Again by the induction hypothesis, there are Î»i, jâˆ’1 blocks B with I â‰¤B â‰¤Ë†J. By
the dimension formula, those blocks have either

184
M. Braun et al.
B â‰¤J
or
dim(J âˆ©B) = k âˆ’1 .
The blocks of the ï¬rst kind are the blocks in Î›I,J, which do not have a suitable
subspace Ë†I.
For each of the Î»i, jâˆ’1 âˆ’#Î›I,J blocks B of the second kind, Lemma 1 gives the
number of choices for Ë†I âˆˆ
 B
i+1

q with Ë†I âˆ©J = Ë†I âˆ©(B âˆ©J) as q((kâˆ’1)âˆ’i)((i+1)âˆ’i) =
qkâˆ’iâˆ’1. So,
#X = (Î»i, jâˆ’1 âˆ’#Î›I,J)qkâˆ’iâˆ’1 .
Equalizing these two expressions for #X yields
#Î›I,J = Î»i, jâˆ’1 âˆ’qvâˆ’kâˆ’j+1Î»i+1, jâˆ’1,
which only depends on i and j. The closed formula is readily checked by induction.
â–¡
The â€œreï¬nedâ€ Î»â€™s of the above lemma are a q-analog of the values b j
i in [24]. Lemma 5
has originally been proven as [21, Lemma 4.1] (in the notation Î³ j
i ).
Example 2 If we look at the 1-(4, 2, 1)2 design from Example 1 and take as I the
trivial subspace I = {0} and as J an arbitrary hyperplane, i.e. i = 0 and j = 1, then
of course all blocks of the design contain I. But moreover, from
4 âˆ’0 âˆ’1
2 âˆ’0

2
/
4 âˆ’1
2 âˆ’1

2
= 1
we can conclude that every hyperplane J contains exactly one block of the design.
Deï¬nition 4 Let D = (V, B) be a t-(v, k, Î»)q design.
(a) For any point P âˆˆ
V
1

, we deï¬ne
DerP(D) = (V/P, {B/P | B âˆˆB, P â‰¤B}) .
DerP(D) is called the derived design of D with respect to P.
(b) For any hyperplane H âˆˆ
 V
vâˆ’1

, we deï¬ne
ResH(D) = (H, {B | B âˆˆB, B â‰¤H}) .
ResH(D) is called the residual design of D with respect to H.
(c) The dual design of D is deï¬ned by
DâŠ¥= (V, {BâŠ¥| B âˆˆB}) .
Different choices for the point P and the hyperplane H may lead to non-
isomorphic derived and residual designs. In contrast, up to isomorphism, the def-
inition of the dual design does not depend on the choice of the bilinear form Î².

q-Analogs of Designs: Subspace Designs
185
For the special case of Steiner systems, the derived design shows up in [4, The-
orem 2]. The residual design was introduced in [25] and the dual design in [21,
Lemma 4.2].
Deï¬nition 4 is a q-analog of the established notions of the derived, the residual
and the complementary design of a combinatorial block design. However, for q = 1
the residual design is usually deï¬ned as
(V \ {P}, {B âˆˆB|P /âˆˆB})
(2)
for a point P of V . For q = 1, (2) is equivalent to Deï¬nition 4 via H = V \ {P}. This
shows that for q = 1, the derived and the residual design with respect to the same
point P provide a decomposition of the original t-design into two (t âˆ’1)-designs. In
particular, #D = # Der(D) + # Res(D). Unfortunately, this property is not true for
q â‰¥2. One might try to preserve the decomposition property by deï¬ning theq-analog
of the residual design directly via (2). However, this is out of question as for q â‰¥2,
the base set V \ {B} is not a vector space, and staying with the original ambient space
V , the resulting set of blocks is not necessarily a design anymore. Deï¬nition 4 of
the residual design is further backed by all the properties stated below, which are all
q-analogs of well-known properties of classical combinatorial designs:
Theorem 2 Let D = (V, B) be a t-(v, k, Î»)q design, P âˆˆ
V
1

and H âˆˆ
 V
vâˆ’1

.
(a) The derived design DerP(D) is a design on V/P with the parameters
(t âˆ’1)-(v âˆ’1, k âˆ’1, Î»)q.
(b) The residual design ResH(D) is a design on H with the parameters
(t âˆ’1)-(v âˆ’1, k, qvâˆ’k âˆ’1
qkâˆ’t+1 âˆ’1Î»)q .
(c) The dual design DâŠ¥is a design on V with the parameters
t-(v, v âˆ’k,
vâˆ’t
k

vâˆ’t
kâˆ’t
 Î»)q .
Proof (a) We see that for any t-subspace T containing P, the blocks B âˆˆB passing
through T uniquely correspond to the blocks B/P of DerU(D) passing through T/P.
(b) The Î»-value of ResH(D) is given by the number Î»tâˆ’1,1 of Lemma 5.
(c) For T âˆˆ
V
t

, the blocks BâŠ¥of DâŠ¥passing through T uniquely correspond to
the blocks B âˆˆB contained in T âŠ¥. By dim(T âŠ¥) = v âˆ’t, the Î»-value of DâŠ¥is the
number Î»0,t of Lemma 5.
â–¡

186
M. Braun et al.
We would like to mention the following straightforward relations:
(DâŠ¥)âŠ¥= D,
DerP(D)âŠ¥= ResPâŠ¥(D) and
ResH(D)âŠ¥= DerH âŠ¥(D).
The numbers Î»i, j are nicely visualized in triangle form:
Î»0,0
Î»1,0
Î»0,1
Î»2,0
Î»1,1
Î»0,2
...
...
...
...
Î»t,0
Î»tâˆ’1,1
. . .
Î»1,tâˆ’1
Î»0,t
In this way, the Î»i, j-triangles of various modiï¬cations can be read off directly:
â€¢ Reduced design: The upper sub-triangle (arising after the deletion of the last row).
â€¢ Derived design: The lower left sub-triangle.
â€¢ Residual design: The lower right sub-triangle.
â€¢ Dual design: The left-right mirror image.
Example 3 The parameters 3-(8, 4, 1)q are admissible for any q, but known to be
realizable only in the ordinary case q = 1. Below, the Î»i, j-triangle for these param-
eters is shown, for q = 2 and for general q.
6477
381
381
21
45
21
1
5
5
1
Î¦6Î¦7Î¦8
Î¦6Î¦7
Î¦6Î¦7
Î¦3Î¦6
Î¦2Î¦4Î¦6
Î¦3Î¦6
1
Î¦4
Î¦4
1
The symmetry of the triangles reï¬‚ects the property of the parameters being self-dual,
meaning that the dual design would have the same parameters. As the q-analog of
the Fano plane has the derived parameters of 3-(8, 4, 1)q, its triangle can be found
as the lower left sub-triangle.
Example 4 The Î»i, j-triangle for a Steiner triple system STSq(v) (a 2-(v, 3, 1)q
design) is:
[vâˆ’1]q[v]q
Î¦2Î¦3
[vâˆ’1]q
Î¦2
[vâˆ’3]q[vâˆ’1]q
Î¦2Î¦3
1
[vâˆ’3]q
Î¦2
[vâˆ’4]q[vâˆ’3]q
Î¦2Î¦3
By construction, for a design its derived and residual designs exist. It may be
surprising that also the converse is true, but not necessarily for the designs itself
but for the parameter sets. The following statements are the q-analogs of results

q-Analogs of Designs: Subspace Designs
187
independently found by Tran van Trung [26], van Leijenhorst [27] and Driessen [28].
It has been shown in [25, Lemma 4.1 and Theorem 1].
Theorem 3 Let t-(v, k, Î»)q be some parameters.
(a) If the derived and the residual parameters are admissible, then the parameters
t-(v, k, Î»)q are admissible, too.
(b) If the derived and the residual parameters are realizable, then the parameters
(t âˆ’1)-(v, k, Î»tâˆ’1)q, i.e. the parameters of the reduced design, are realizable,
too.
Further, there are cases where the derived parameters are realizable and the resid-
ual parameters coincide with the parameters of the dual of the derived design. Then,
the realizability of derived parameters sufï¬ces to get the following corollary.
Corollary 1 ([25, Corollary 2]) The realizability of the parameters
t-(2k âˆ’1, k âˆ’1, Î»)q
implies the realizability of the parameters
t-(2k, k, Î» Â· (q2kâˆ’t âˆ’1)/(qkâˆ’t âˆ’1))q .
3.3
Intersection Numbers
Now we discuss intersection numbers, which describe the intersection sizes of the
blocks of a design with a ï¬xed subspace S and can be seen as an extension of the
numbers Î»i, j (Lemma 6). For combinatorial designs they have been originally deï¬ned
in [29] for blocks S and independently as â€œi-Trefferâ€ for general sets S in [30]. We
follow [31], where intersection numbers for subspace designs have been introduced.
Deï¬nition 5 Let D = (V, B) be a t-(v, k, Î»)q subspace design. For any subspace
S of V and i âˆˆ{0, . . . , k}, we deï¬ne the i-th intersection number of S in D as
Î±i(S) = # {B âˆˆB | dim(B âˆ©S) = i} .
If the set S is clear from the context, we use the abbreviation Î±i = Î±i(S).
If Î±âŠ¥denotes the intersection numbers of the dual design, by the dimension
formula and the properties of the dual we have
Î±i(S) =

0,
if i > s or k âˆ’i > v âˆ’s;
Î±âŠ¥
(vâˆ’s)âˆ’(kâˆ’i)(SâŠ¥), otherwise.

188
M. Braun et al.
The following lemma shows that if the dimension or the codimension of S in V is
at most t, the intersection numbers are uniquely determined and closely connected
to the numbers Î»i, j.
Lemma 6 ([31, Lemma 2.3])
Î±i(S) =
s
i

q Â· Î»i,sâˆ’i,
if dim(S) â‰¤t;
qskâˆ’ivvâˆ’s
kâˆ’i

q Â· Î»kâˆ’i,(vâˆ’s)âˆ’(kâˆ’i), if dim(S) â‰¥v âˆ’t.
Proof The ï¬rst case is shown by double counting the set of all (I, B) âˆˆ
S
i

q Ã— B
with B âˆ©S = I. The second case follows by making use of the dual design.
â–¡
Theorem 4 ([31, Theorem 2.4], q-analog of the Mendelsohn equations [29, Theo-
rem 1]) Let D be a t-(v, k, Î»)q subspace design, S a subspace of V and s = dim(S).
For i âˆˆ{0, . . . , t} we have the following equation on the intersection numbers of S
in D:
s

j=i
 j
i

q
Î± j =
s
i

q
Î»i
(3)
Proof Wecounttheset X ofallpairs(I, B) âˆˆ
V
i

q Ã— B with I â‰¤B âˆ©S intwoways:
On the one hand, there are
s
i

q possibilities for the choice of I âˆˆ
S
i

q. By Lemma 3,
there are Î»i blocks B such that I â‰¤B, which shows that #X equals the right hand
side of Eq. (3). On the other hand, ï¬xing a block B, the number of i-subspaces I
of B âˆ©S is
dim(Bâˆ©S)
i

q. Summing over the possibilities for j = dim(B âˆ©S), we see
that #X also equals the left hand side of Eq.(3).
â–¡
The Mendelsohn equations can be read as a linear system of equations Ax = b on
the intersection vector x = (Î±0, Î±1, . . . , Î±k). The left (t + 1) Ã— (t + 1) square part
of the matrix A = (
 j
i

q)i j (i âˆˆ{0, . . . , t} and j âˆˆ{0, . . . , k}) is called the upper
triangular q-Pascal matrix, which is known to be invertible with inverse matrix

(âˆ’1) jâˆ’iq( jâˆ’i
2 ) j
i

q

i j. Left-multiplication of the equation system with this inverse
yields a parameterization of the intersection numbers Î±0, . . . , Î±t by Î±t+1, . . . , Î±k. In
this way, we get:
Theorem 5 ([31, Theorem 2.6], q-analog of the KÃ¶hler equations [32, Satz 1])
Let D be a t-(v, k, Î»)q subspace design, S a subspace of V and s = dim(S). For
i âˆˆ{0, . . . , t}, a parametrization of the intersection number Î±i by Î±t+1, . . . , Î±k is
given by
Î±i =
s
i

q
t
j=i
(âˆ’1) jâˆ’iq( jâˆ’i
2 )
s âˆ’i
j âˆ’i

q
Î» j
+(âˆ’1)t+1âˆ’iq(t+1âˆ’i
2 )
k

j=t+1
 j
i

q
 j âˆ’i âˆ’1
t âˆ’i

q
Î± j.

q-Analogs of Designs: Subspace Designs
189
3.4
Combinatorial Designs from Subspace Designs
By identifying the blocks of a subspace design with its set of points, we can construct
combinatorial designs.
Theorem 6 Let D = (V, B) be a t-(v, k, Î»)q subspace design. We deï¬ne the fol-
lowing two combinatorial designs:
â€¢ Projective version: Let Dp = (
V
1

q, {
B
1

q | B âˆˆB})
â€¢ Afï¬ne version: For any ï¬xed hyperplane H âˆˆ
 V
vâˆ’1

q let
Da =
V
1

q
\
H
1

q
,
B
1

q
\
H
1

q
| B âˆˆB, B â‰°H

Ift = 2,thenDp isacombinatorial2-(
v
1

q,
k
1

q, Î»)designandDa isacombinatorial
2-(qvâˆ’1, qkâˆ’1, Î») design. In the case q = 2 and t = 3, Da is even a combinatorial
3-(qvâˆ’1, qkâˆ’1, Î») design.
Proof Let T be a 2-subset of
V
1

q. By the deï¬nition of Dp, each block consists of
the set of points of a certain k-subspace. Hence, any block containing the elements
of T has to contain all the points in the 2-subspace âŸ¨T âŸ©. By the design property of
D, there are exactly Î» blocks of D (and hence of Dp) with this property.
In the afï¬ne case, the proof is similar as by deï¬nition, any block of Da containing
a 2-subset T of
V
1

q \
H
1

q has to contain the points in the afï¬ne line âŸ¨T âŸ©\
H
1

q, too,
and each block Ba of Da uniquely determines the corresponding block B = âŸ¨BaâŸ©of
D. For q = 2 and t = 3, a triple T of points in
V
1

q \
H
1

q cannot be collinear, as
afï¬ne lines consist of q = 2 points only. Hence dim(âŸ¨T âŸ©) = 3 and the claim follows
in an analogous way.
â–¡
The key of the above proof is that dim(âŸ¨T âŸ©) is uniquely determined independently
of the choice of the t-subset T . This shows that the preconditions cannot be relaxed,
as in the projective version, this property is not true any more for t â‰¥3 (triples of
points may be collinear or not), and in the afï¬ne situation the only exception is the
special case q = 2, t = 3 of Theorem 6 (where triples cannot be collinear). The
projective version of Theorem 6 is already mentioned in [33, Sect.1]. For the case
of Steiner systems, the afï¬ne version is found in [4, Theorems 7 and 8].
3.5
On Automorphism Groups of Designs
As the deï¬nition of a subspace design can entirely be expressed in terms of the sub-
space lattice L (V ), the design property is invariant under the action of Aut(L (V )).
Thus, Aut(L (V )) provides a notion of isomorphism of designs: Two designs

190
M. Braun et al.
D = (V, B) and Dâ€² = (V, Bâ€²) on V are called isomorphic if and only if they
are contained in the same orbit of Aut(L (V )) or equivalently, if there exists an
Î± âˆˆAut(L (V )) such that Î±(B) = Bâ€². The stabilizer of B with respect to the action
of Aut(L (V )) is called the automorphism group of D, that is
Aut(D) = Aut(L (V ))B = {Î± âˆˆAut(L (V )) | Î±(B) = B} .
For any subgroup G of Aut(D), D is called G-invariant.
By Formula (1), the question for the existence of a G-invariant t-(v, k, Î»)q design
D = (V, B) only depends on the conjugacy class of G in Aut(L (V )). Hence in
order to choose possible groups of automorphisms for a t-(v, k, Î»)q design, it is
sufï¬cient to take only one representative of each conjugacy class of subgroups of
Aut(L (V )).
From the orbit-stabilizer-theorem of group actions, see [34, Sect.1.2], we also
get a one-to-one correspondence of the set of isomorphic designs of B with the set
of cosets of the automorphism group of B within Aut(L (V )). More formally, the
mapping
Aut(L (V ))(B) â†’Aut(L (V ))/ Aut(L (V ))B, Î±(B) â†’Î± Aut(L (V ))B
is a bijection.
In chapter â€œComputational Methods in Subspace Designsâ€ on computer construc-
tion of subspace designs it is explained in detail how to construct subspace designs
with a prescribed group of automorphisms by computer. This is the so called Kramer-
Mesner method.
Theorem 7 (Kramer, Mesner [35]) Let G â‰¤PL(V ). There exists a G-invariant
t-(v, k, Î»)q design if and only if there is a 0/1-vector x satisfying
AG
t,k Â· x =
â›
â
Î»
...
Î»
â
â .
(4)
Details on the matrix AG
t,k can be found in the chapter â€œComputational Methods in
Subspace Designsâ€. In general, our aim in that chapter is to prescribe certain groups
of automorphisms which arise as subgroups G of the general linear group GL(V ).
The corresponding images Â¯G in PGL(V ) â‰¤Aut(L (V )) are the groups to prescribed.
When it comes to the question which groups may occur as automorphism groups
of designs, one group stands out, which is the normalizer of a Singer cycle group: At
present, most of the successful computer searches for subspace designs have been
performed by prescribing this group or a subgroup of small index, see Sect.4.
Let Ï† âˆˆGL(V ) and âŸ¨Ï†âŸ©= {idV , Ï†, Ï†2, Ï†3, . . .} be the cyclic subgroup of GL(V )
generated by Ï†. By Cayleyâ€“Hamilton, the minimal polynomial of Ï† has at most
degree v, implying that the linear hull of âŸ¨Ï†âŸ©has at most dimension v. As 0 /âˆˆâŸ¨Ï†âŸ©,

q-Analogs of Designs: Subspace Designs
191
we get that âŸ¨Ï†âŸ©contains at most qv âˆ’1 distinct elements. In other words, the element
order of Ï† is at most qv âˆ’1.
An element of GL(V ) of order qv âˆ’1 is called a Singer cycle, and a cyclic sub-
group of order qv âˆ’1 is called a Singer cycle group. Indeed, Singer cycles and Singer
cycle groups do always exist: To see this, we equip V with a ï¬eld multiplication,
by setting V = Fqv. For any primitive element Î± of Fqv (that is, Î± is a generator of
the cyclic unit group FÃ—
qv), Ïƒ : V â†’V , x â†’Î±x is an Fq-linear mapping of order
#FÃ—
q = qv âˆ’1 and thus a Singer cycle.
To get a matrix representation of Ïƒ in GL(v, q), we can proceed as follows: Let
f = a0 + a1x + a2x2 + . . . + anâˆ’1xnâˆ’1 + xn âˆˆFq[x] be the minimal polynomial
of Î± over Fq. Then f is a primitive irreducible polynomial of degree v. With respect
to the Fq-basis (1, Î±, Î±2, . . . , Î±vâˆ’1) of V = Fqv, the transformation matrix of Ïƒ is
given by the companion matrix of f , which is
â›
âœâœâœâœâ
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
âˆ’a0 âˆ’a1 âˆ’a2 . . . âˆ’avâˆ’1
â
âŸâŸâŸâŸâ 
.
By [36, Sect.7], any two Singer cycle subgroups of GL(V ) are conjugate. We
point out that, in general, this is not true for Singer cycles: For example, the Singer
cycles in GL(2, 3) and GL(3, 2) both fall into 2 conjugacy classes.3
The Galois group Gal(Fqv/Fq) of the ï¬eld extension Fqv/Fq, i.e. the group of all
ï¬eld automorphisms of Fqv element-wise ï¬xing Fq, is known to be cyclic of order v
and generated by the mapping F : x â†’xq. F is called Frobenius automorphism. It
is easily seen that F normalizes the Singer cycle group S = âŸ¨ÏƒâŸ©, showing that âŸ¨Ïƒ, FâŸ©
is contained in the normalizer NGL(V )(S) of S in GL(V ). In fact, both groups are
equal [36, Satz 7.3], so
NGL(V )(S) = âŸ¨Ïƒ, FâŸ©= Gal(Fqv/Fq) â‹ŠS.
In particular, the normalizer NGL(V )(S) is of order v(qv âˆ’1) and the quotient of S
in its normalizer is cyclic of order v.
In the following, S(v, q) (and N(v, q)) will denote the conjugacy class of all
(normalizers of) Singer cycle groups in GL(v, q).
3For a singer cyclic subgroup S, we have [NGL(V )(S) : S] = v (see below), so under the action of
NGL(V )(S), the Ï•(qv âˆ’1) Singer cycles in S fall into Ï•(qvâˆ’1)
v
orbits of length v (Ï• denoting the
Eulerâ€™s phi function). From this, we get that the number of conjugacy classes of Singer cycles in
GL(v, q) equals Ï•(qvâˆ’1)
v
.

192
M. Braun et al.
4
Examples
In order to represent a G-invariant design it is sufï¬cient to list G by its generators
and the set of representatives of the selected orbits of G on
V
k

. For a compact
representation we will write all Î± Ã— Î² matrices X over Fq with entries xi, j, whose
indices are numbered from 0, as vectors of integers
â¡
â£
j
x0, jq j, . . . ,

j
xÎ±âˆ’1, jq j
â¤
â¦.
Example 5 The ï¬rst nontrivial simple subspace design for t = 3 was constructed by
Braun, Kerber, and Laue [20]. It has parameters 3-(8, 4, 11)2 and is invariant under
the normalizer of the Singer cycle group N(8, 2) = âŸ¨Ïƒ, FâŸ©. The order of the group
is 2040, generators are
Ïƒ = [2, 4, 8, 16, 29, 32, 64, 128],
F = [1, 4, 16, 19, 29, 64, 116, 205] .
The design can be constructed from the following orbit representatives.
[28, 32, 64, 128], [2, 32, 64, 128],
[10, 32, 64, 128], [6, 32, 64, 128],
[22, 32, 64, 128],
[5, 32, 64, 128],
[8, 16, 64, 128],
[6, 16, 64, 128],
[33, 16, 64, 128], [3, 16, 64, 128],
[7, 16, 64, 128],
[39, 16, 64, 128], [47, 16, 64, 128], [2, 48, 64, 128],
[38, 48, 64, 128],
[14, 48, 64, 128], [37, 48, 64, 128], [13, 48, 64, 128], [38, 8, 64, 128],
[22, 8, 64, 128],
[54, 8, 64, 128],
[54, 40, 64, 128], [1, 24, 64, 128],
[51, 24, 64, 128], [39, 24, 64, 128],
[6, 56, 64, 128],
[35, 56, 64, 128], [59, 36, 64, 128], [34, 20, 64, 128], [59, 20, 64, 128],
[25, 12, 64, 128], [34, 28, 64, 128], [43, 28, 64, 128], [61, 42, 64, 128], [21, 62, 64, 128],
[105, 50, 84, 128]
In Tables1,2,3 and4 we list sets of parameters for subspace designs which are
known to be realizable. The subspace designs were either by the Kramer-Mesner
method and by the methods described in Sects.5 and 7 or by combining existing
subspace designs to get new ones, as described in Theorem 3 and Corollary 1.
Due to the existence of dual and supplementary designs we restrict the lists to
t-(v, k, Î»)q designs satisfying 1 < t < k â‰¤v/2 and 1 â‰¤Î» â‰¤Î»max/2.
Given a prime power q and integers 0 < t < k < v, the smallest positive integer
value of Î» for which t-(v, k, Î»)q is admissible is denoted by Î»min. By Lemma 3, the
set of all Î» such that t-(v, k, Î»)q is admissible is given by {Î»min, 2Î»min, . . . , Î»max}.
As superscripts of the Î»-values we give the earliest reference we are aware of.
The references are encoded by the following letters:

q-Analogs of Designs: Subspace Designs
193
Table 1 Parameters of simple t-(v, k, Î»)2 designs known to be realizable
t-(v, k, Î»)q
Î»min
Î»max
Î»
2-(6, 3, Î»)2
3
15
3a, 6b. Open: â€“
2-(7, 3, Î»)2
1
31
3c, 4a, 5c, 6a, 7d, 8a, 9b, 10c, 11b, 12c, 14c, 15b. Open: 1,
2
2-(8, 3, Î»)2
21
63
21b. Open: â€“
2-(8, 4, Î»)2
7
651
7e, 14e, 21b, 35 f , 49e, 56g, 63âˆ—, 70g, 84âˆ—, 91b, 98e, 105g,
112e, 126g, 133g, 140b, 147âˆ—, 154e, 161g, 168âˆ—, 175g,
189âˆ—, 196g, 203e, 210b, 217h, 231b, 245g, 252âˆ—, 259e,
266g, 273âˆ—, 280 f , 294âˆ—, 301b, 308e, 315g. Open: 28, 42,
77, 119, 182, 224, 238, 287, 322
3-(8, 4, Î»)2
1
31
11a, 15i. Open: 1, â€¦, 10, 12, 13, 14
2-(9, 3, Î»)2
1
127
7e, 12e, 19e, 21g, 22g, 24e, 31e, 36e, 42g, 43g, 48e, 49m,
55e, 60e, 63g
2-(9, 4, Î»)2
7
2667
21 f , 63 f , 84 f , 126 f , 147 f , 189 f , 210 f , 252 f , 273 f ,
315 f , 336 f , 378 f , 399 f , 441b, 462 f , 504 f , 525 f , 567 f ,
588 f , 630b, 651 f , 693 f , 714 f , 756 f , 777 f , 819b, 840 f ,
882 f , 889h, 903 f , 945 f , 966 f , 1008 f , 1029 f , 1071 f ,
1092 f , 1134 f , 1155 f , 1197 f , 1218 f , 1260b, 1281 f ,
1323 f
3-(9, 4, Î»)2
21
63
Open: 21
2-(10, 3, Î»)2
3
255
15b, 30b, 45k, 60 j, 75 j, 90 j, 105 j, 120b
2-(10, 4, Î»)2
5
10795
595âˆ—, 1020âˆ—, 1615âˆ—, 1785âˆ—, 1870âˆ—, 2040âˆ—, 2635âˆ—, 3060âˆ—,
3570âˆ—, 3655âˆ—, 4080âˆ—, 4165âˆ—, 4675âˆ—, 5100âˆ—, 5355âˆ—
3-(10, 4, Î»)2
1
127
â€“
2-(10, 5, Î»)2
15
97155
765âˆ—, 4590âˆ—, 5355âˆ—, 6885âˆ—, 7650âˆ—, 9180âˆ—, 9945âˆ—, 2295âˆ—,
3060âˆ—, 11475âˆ—, 12240âˆ—, 13770âˆ—, 14535âˆ—, 16065âˆ—, 16830âˆ—,
18360âˆ—, 19125âˆ—, 20655âˆ—, 21420âˆ—, 22950âˆ—, 23715âˆ—,
25245âˆ—, 26010âˆ—, 27540âˆ—, 28305âˆ—, 29835âˆ—, 30600âˆ—,
32130âˆ—, 32385h, 32895âˆ—, 34425âˆ—, 35190âˆ—, 36720âˆ—,
37485âˆ—, 39015âˆ—, 39780âˆ—, 41310âˆ—, 42075âˆ—, 43605âˆ—,
44370âˆ—, 45900âˆ—, 46665âˆ—, 48195âˆ—
3-(10, 5, Î»)2
21
63
Open: 21
2-(11, 3, Î»)2
7
511
7d, 245e, 252e
2-(11, 4, Î»)2
35
43435
â€“
2-(11, 5, Î»)2
5
788035
43435âˆ—, 74460âˆ—, 117895âˆ—, 130305âˆ—, 136510âˆ—, 148920âˆ—,
192355âˆ—, 223380âˆ—, 260610âˆ—, 266815âˆ—, 297840âˆ—, 304045âˆ—,
341275âˆ—, 372300âˆ—, 390915âˆ—
2-(12, 3, Î»)2
3
1023
â€“
2-(12, 4, Î»)2
7
174251
â€“
2-(12, 5, Î»)2
465
6347715
â€“
2-(12, 6, Î»)2
31
53743987
2962267âˆ—, 5078172âˆ—, 8040439âˆ—, 8886801âˆ—, 9309982âˆ—,
10156344âˆ—, 13118611âˆ—, 15234516âˆ—, 17773602âˆ—,
18196783âˆ—, 20312688âˆ—, 20735869âˆ—, 23274955âˆ—,
25390860âˆ—, 26660403âˆ—
3-(12, k, Î»)2
â€“
2-(13, 3, Î»)2
1
2047
1l, 2q, â€¦, 6q, 7d, 8qâ€¦, 1023q. Open: â€“

194
M. Braun et al.
Table 2 Parameters of simple t-(v, k, Î»)3 designs known to be realizable
t-(v, k, Î»)q
Î»min
Î»max
Î»
2-(6, 3, Î»)3
4
40
8e, 12e, 16 f , 20b. Open: 4
2-(7, 3, Î»)3
1
121
5c, 6b, â€¦, 12b, 13n, 14b, â€¦, 40b, 41e, 42b, â€¦, 60b.
Open: 1, â€¦, 4
2-(8, 3, Î»)3
52
364
52g, 104 f , 156 f . Open: â€“
2-(8, 4, Î»)3
13
11011
91 Â· 5âˆ—, 91 Â· 6âˆ—, â€¦, 91 Â· 60âˆ—
2-(10, 3, Î»)3
4
3280
1640â—¦
2-(11, 3, Î»)3
13
9841
13n
2-(13, 3, Î»)3
1
88573
13n
Table 3 Parameters of simple t-(v, k, Î»)4 designs known to be realizable
t-(v, k, Î»; q)
Î»min
Î»max
Î»
2-(6, 3, Î»)4
5
85
10e, 15e, 25e, 30e, 35e. Open: 5, 40
2-(7, 3, Î»)4
1
341
21p
2-(8, 4, Î»)4
21
93093
5733âˆ—
Table 4 Parameters of simple t-(v, k, Î»)5 designs known to be realizable
t-(v, k, Î»; q)
Î»min
Î»max
Î»
2-(6, 3, Î»)5
6
78
78â—¦. Open: 6, 12, â€¦, 72
2-(7, 3, Î»)5
1
781
31n
2-(8, 4, Î»)5
31
508431
20181âˆ—
2-(10, 3, Î»)5
6
97656
48828â—¦
a: Braun, Kerber, Laue (2005) [20],
b: Braun (2005) [37],
c: Miyakawa, Munemasa, Yoshiara (1995) [38],
d: Thomas (1987) [17],
e: Braun (2015) presentation at ALCOMA 2015,
f: S. Braun (2010) [39],
g: S. Braun (2009) [40],
h: Kiermaier, Laue, Wassermann (2016) [41],
i:
Braun (2013) [42],
j:
Braun (2011) presentation at Fq10,
k: Braun (2016) [43],
l:
Braun, Etzion, Ã–stergÃ¥rd, Vardy, Wassermann (2016) [44]
m: Braun (2017) [45],
n: Suzuki (1992) [19],
o: Braun, Kiermaier, Kohnert, Laue (2017)[46],
p: Suzuki (1990) [18],
q: Braun, Wassermann (2017) [47],
âˆ—: Kiermaier, Laue (2015) [25], see Theorem 3 and Corollary 1
In case there are only few remaining open cases, we list the Î»-values in question.

q-Analogs of Designs: Subspace Designs
195
4.1
Special Subspace Designs
Designs for t = 2
A considerable part of the literature on combinatorial designs studies balanced
incompleteblockdesigns (BIBD)whichare2-(v, k, Î»)designs.Thenumberofblocks
is denoted with b = Î»0 and each point appears in r = Î»1 blocks. Let M be the v Ã— b
incidence matrix of the points and the blocks of a BIBD.
The results in the following theorem are classical and can be found e.g. in [2,
Chap. II, Sects.1 and2].
Theorem 8 For a 2-(v, k, Î») design it holds
(a) bk = vr,
(b) b â‰¥rank(M) = v. (Fisherâ€™s inequality)
From the deï¬nitions of b and r it follows immediately that the q-analog of equation
(a) for 2-(v, k, Î»)q subspace design is
[k]qb = [v]qr.
The incidence matrix M between the points, i.e. the 1-subspaces, and the blocks of
the designs has size [v]q Ã— b. The q-analog of Fisherâ€™s inequality is
b â‰¥rank(M) = [v]q,
see [15, 48].
Symmetric Designs
If a (combinatorial) 2-(v, k, Î») design attains the bound in Fisherâ€™s inequality, i.e. if
v = b, the design is called symmetric. One consequence is that two different blocks
of a symmetric 2-(v, k, Î») design always intersect in exactly Î» points, compare [2,
Chap.II, Sect.3]. That is, for B âˆˆB, Î±Î»(B) is the only nonzero intersection num-
ber. Symmetric designs are especially interesting because of their relation to ï¬nite
projective planes.
It was shown already in [49] that symmetric subspace designs are always trivial.
To be precise, only the complete design (V,
 V
vâˆ’1

q) is symmetric, the intersection
of two different blocks always has dimension Î». We note however, that the resulting
combinatorial design of a symmetric subspace design is in general nontrivial.
Quasi-symmetric Designs
As seen above, symmetric designs are not interesting in the context of subspace
designs. Thus, one might relax the condition that two blocks always intersect in a
Î»-dimensional subspace and allow two intersection numbers. Combinatorial designs
with this property are called quasi-symmetric. However, we are not aware of any
work about quasi-symmetric subspace designs.

196
M. Braun et al.
Signed Designs
Up to now, designs were either simple or non-simple, depending if the multiplicities
of all blocks of the design are one or larger than one. If one allows the multiplicity
of block to be also negative, the design is called a signed design. In [50] it is shown
that all admissible designs are realizable as signed designs. This is the q-analog of a
result by Wilson [51], which is a key ingredient in the proof of Keevash [52].
Generalized Subspace Designs
In [53, 54], Guruswami et al. give a more general deï¬nition of subspace designs.
They deï¬ne an (s, Î»)-subspace design to be a collection of subspaces B1, . . . , Bb of
V such that for every t-subspace T â‰¤V at most Î» blocks Bi intersect T nontrivially.
4.2
Asymptotic Existence Results
For combinatorial designs, Teirlinck [55] showed that for all integers t > 0 there exist
simple t-designs for v, k, Î» sufï¬ciently large. In 2013, Fazeli, Lovett and Vardy [56]
succeeded in proving a similar result for subspace designs, with the difference that
the proof in [55] is constructive, but the proof in [56] is not.
Theorem 9 (Fazeli, Lovett, Vardy) Simple nontrivial t-(v, k, Î»)q designs exist for
all q and t, and all k > 12(t + 1) provided that v â‰¥ckt for a large enough absolute
constant c. Moreover, these t-(v, k, Î»)q designs have at most q12(t+1)v blocks.
In 2014, the long-standing question, whether Steiner systems over sets exist for all
integerst > 0, couldbeansweredafï¬rmativelyinacelebratedresult byKeevash[52].
The non-constructive proof relies heavily on an asymptotic approximation by Frankl
and RÃ¶dl [57].
For the time being, there is not such a result for q-Steiner systems. But in [57]
the asymptotic approximation result is also shown in the subspace case.
Theorem 10 (Frankl-RÃ¶dl) Let 0 < t < k be integers. Then for v â†’âˆthere exists
a set B âŠ‚
V
k

such that
#B = (1 âˆ’o(1))
v
t

q
/
k
t

q
and dim(K â€² âˆ©K â€²â€²) < t for all distinct K â€², K â€²â€² âˆˆB.

q-Analogs of Designs: Subspace Designs
197
5
Inï¬nite Series of Subspace Designs
5.1
On Suzukiâ€™s Construction
In 1987 Thomas [17] constructed the ï¬rst nontrivial simple t-subspace designs for
t = 2. More precisely, for all v â‰¥7 with (v, 4!) = 1 a Singer-invariant 2-(v, 3, 7)2
design was constructed.
Suzuki [18, 19] extended Thomasâ€™ family using the following construction: For
any natural number r â‰¥2 we deï¬ne the following map:
Lr :
V
2

â†’L (V ),
T â†’âŸ¨b0 Â· b1 Â· . . . Â· brâˆ’1 | {b0, . . . , brâˆ’1} âŠ‚T âŸ©.
The image of Lr is the set of blocks
Br :=

Lr(T ) | T âˆˆ
V
2

.
Suzuki proved that for (v, (2r)!) = 1 the mapping T â†’Lr(T ) deï¬nes an embedding
from
V
2

into
 V
r+1

implying #Br =
v
2

q. Furthermore, if Br becomes a 2-(v,r +
1, Î»)q design it has to satisfy Î» =
r+1
2

q. For r = 2, Suzuki could prove that B2
deï¬nes a design. In addition, Abe and Yoshiara [58] determined a nontrivial group
of automorphisms of Suzukiâ€™s design.
Theorem 11 (Suzuki, Abe, Yoshiara) For any prime power q and any integer v â‰¥7
satisfying (v, 4!) = 1 the set B2 of blocks deï¬nes an N(v, q)-invariant 2-(v, 3, q2 +
q + 1)q design.
Abe and Yoshiara also tried to generalize Suzukiâ€™s construction to values r > 2.
But so far, computer experiments for q = 2 and small parameters failed for r â‰¥3.
The only exception is the case v = 7 and r = 3 which yields a 2-(7, 4, 35)2 design
B3, the dual design to Thomasâ€™ 2-(7, 3, 7)2 design.
5.2
On Itohâ€™s Construction
In 1998 Itoh [59] gave a construction of a 2-(â„“m, 3, Î»)q design invariant under the
special linear group G = SL(m, qâ„“) â‰¤GL(â„“m, q) for all m â‰¥3, assuming the exis-
tence of certain S(â„“, q)-invariant 2-(â„“, 3, Î»)q designs.
The major step Itoh did was the examination of the matrix AG
2,3. The structure
of this matrix turned out to be of the following shape consisting of four blocks of
columns

198
M. Braun et al.
ASL(m,qâ„“)
2,3
=
â¡
â¢â¢â£
a
0
AS(â„“,q)
2,3
...
0
0
0
a
0
X
Y
Z
â¤
â¥â¥â¦,
where X, Y, Z are submatrices with exactly one row deï¬ned by
X =

(q + 1)2, . . . , (q + 1)2, q + 1

, if 2 | â„“;

(q + 1)2, . . . , (q + 1)2
,
else,
Y =

q(q + 1)(q3 âˆ’1), . . . , q(q + 1)(q3 âˆ’1), q(q2 âˆ’1)

, if 3 | â„“;

q(q + 1)(q3 âˆ’1), . . . , q(q + 1)(q3 âˆ’1)

,
else,
Z =

q2â„“âˆ’2, . . . , q2â„“âˆ’2
, if m = 3;

q2â„“âˆ’2 q(mâˆ’2)â„“âˆ’1
qâˆ’1

,
if m > 3.
Additionally, we have a = qâ„“âˆ’2(q(mâˆ’1)â„“âˆ’1)/(q âˆ’1).
Now, the following extension result is immediate from inspection of the matrix. If
we have a selection of columns of AS(â„“,q)
2,3
with constant row sum we can extend this
to a selection of columns of AG
2,3 with constant row sum by taking the right amount
of columns of the third block of columns.
Lemma 7 (Itoh) If there exists a S(â„“, q)-invariant 2-(â„“, 3, Î»)q design with
Î» = q(q + 1)(q3 âˆ’1)s + q(q2 âˆ’1)t
for some integer s â‰¥0 and
t âˆˆ

{0, 1}, if 3 | â„“;
{0},
else,
then there exists an SL(m, qâ„“)-invariant 2-(â„“m, 3, Î»)q design.
Moreover, Itoh noticed that this lemma is also true for the GL(m, qâ„“) action. There-
fore S(â„“, q)-invariant designs also imply families of GL(m, qâ„“)-invariant designs.
Since the publication of Itohâ€™s paper several S(v, q)-invariant subspace designs
with index values Î» of the required form for Itohâ€™s lemma have been constructed by
computer. These are listed in the sequel.
In the binary case we need a 2-(â„“, 3, Î»)q design with index
Î» = 2(2 + 1)(23 âˆ’1)s + 2(22 âˆ’1)t = 42s + 6t
and over the ternary ï¬eld we need
Î» = 3(3 + 1)(33 âˆ’1)s + 3(32 âˆ’1)t = 312s + 24t,

q-Analogs of Designs: Subspace Designs
199
Table 5 Simple subspace designs from Itohâ€™s lemma
t-(v, k, Î»)q
Parameters
Group of automorphisms
2-(8m, 3, 42)2
m â‰¥3
SL(m, 28)
2-(9m, 3, 42s)2
m â‰¥3, 1 â‰¤s â‰¤2
SL(m, 29)
2-(10m, 3, 210)2
m â‰¥3
SL(m, 210)
2-(13m, 3, 42s)2
m â‰¥3, 1 â‰¤s â‰¤2
SL(m, 213)
2-(8m, 3, 312)2
m â‰¥3
SL(m, 38)
where in both cases s â‰¥0 and t is 0 or 1 if â„“is divisible by 3 or t is 0 otherwise.
All of the following given groups of automorphisms of the corresponding
2-(â„“, 3, Î»)q designs contain the Singer cycle group S(â„“, q) as subgroup and therefore
the designs also admit this group as group of automorphisms.
â€¢ In [60] three disjoint N(8, 2)-invariant 2-(8, 3, 21)2 designs are given. Combining
two of them yields an N(8, 2)-invariant design of the supplementary parameters
2-(8, 3, 42)2.
â€¢ In Table1 there are N(3, 23)-invariant 2-(9, 3, Î»)2 designs. The supplementary
design of the 2-(9, 3, 43)2 design has parameters 2-(9, 3, 42 Â· 2)2.
â€¢ Also in Table1 there is an N(10, 2)-invariant 2-(10, 3, 45)2 design. The supple-
mentary design has parameters 2-(10, 3, 42 Â· 5)2.
â€¢ In Table2 there is a N(8, 3)-invariant 2-(8, 3, 52)3 design. The supplementary
design is has the parameters 2-(8, 3, 312)3.
â€¢ There exist at least 586 pairwise disjoint N(13, 2)-invariant subspace designs with
parameters 2-(13, 3, 1)2 [44]. The union of these designs yields 2-(13, 3, 42s)2
designs for 1 â‰¤s â‰¤13.
By Itohâ€™s Lemma 7 these designs turn immediately into new families of inï¬nite
series [43] (Table5).
6
q-Analogs of Steiner Systems
Among subspace designs the case Î» = 1 is of particular interest. Such a design is
called q-Steiner system. For t = 1, the existence of q-Steiner systems is already
answered by Lemma 4, such designs are called spreads.
It was a long standing open question whether q-Steiner systems exist at all for t â‰¥
2. There was already the conjecture that such structures do not exist [61]. Especially,
the smallest nontrivial set parameters 2-(7, 3, 1)2 (an STS(7)q) attracted quite a lot
of interest.

200
M. Braun et al.
6.1
q-Steiner Systems in Dimension 13
While the existence of a q-analog of the Fano plane is still undecided, meanwhile
the ï¬rst q-Steiner system for t â‰¥2 has been found, namely an S(2, 3, 13)2, see [44].
For the construction, the authors used the method of Kramer and Mesner. They
prescribed the normalizer N(13, 2) of a Singer subgroup of Aut(L (V )) as a group of
automorphisms. The group order is 106 483 and the Kramer-Mesner matrix AN(13,2)
2,3
has size 105 Ã— 30 705.
With the algorithm dancing links by Knuth [62] meanwhile 1316 mutually disjoint
solutions have been determined [47]. That is, among 1 â‰¤Î» â‰¤1316 mutually disjoint
designs, no block appears twice. Therefore, the union of their block sets gives a 2-
(13, 3, Î»)2 design.
Together with their supplementary designs and noting that Î»max = 2047, this
implies that all possible design parameters
2-(13, 3, Î»)2,
1 â‰¤Î» â‰¤2047,
are realizable.
6.2
q-Analog of the Fano Plane
Arguably, one of the most tantalizing open problems in this ï¬eld is the question for
the existence of a q-analog of the Fano plane which was asked already in 1972 by
Ray-Chaudhuri [14]. Its existence is still open over any ï¬nite base ï¬eld Fq. The most
important single case is the binary case q = 2, as it is the smallest one. Nonetheless,
so far the binary q-analog of the Fano plane has withstood all computational or
theoretical attempts for its construction or refutation.
Following the approach for other notorious putative combinatorial objects as, e.g.,
a projective plane of order 10 or a self-dual binary [72, 36, 16] code, the possible
automorphisms of a binary q-analog of the Fano plane have been investigated in [63,
64]. As a result, its automorphism group is at most of order 2.
For the groups of order 2, the above result was achieved as a special case of a more
general result on restrictions of the automorphisms of order 2 of a binary q-analog
of Steiner triple systems [63, Theorem 2].
Finally, the combination of the results of [63, 64] yields
Theorem 12 The automorphism group of a binary q-analog of the Fano plane is
either trivial or of order 2. In the latter case, up to conjugacy in GL(7, 2) the auto-
morphism group is represented by
"â›
âœâ
0 1 0 0 0 0 0
1 0 0 0 0 0 0
0 0 0 1 0 0 0
0 0 1 0 0 0 0
0 0 0 0 0 1 0
0 0 0 0 1 0 0
0 0 0 0 0 0 1
â
âŸâ 
#
.

q-Analogs of Designs: Subspace Designs
201
7
â€œLarge Setsâ€ of Subspace Designs
In 1861 Sylvester [65] asked if it is possible to partition the set of 455 3-subsets
on 15 points into 13 resolvable 2-(15, 3, 1) designs. His question was answered
afï¬rmatively by Denniston [66] as late as in 1974. Later on, a partition of the k-subsets
into disjoint (combinatorial) t-(v, k, Î») designs was sometimes called packing. In the
1970s the term large set of disjoint designs evolved, nowadays such a partition into
designs is simply called a large set of designs.
In the q-analog situation, a large set of subspace designsâ€”denoted by
LSq[N](t, k, n)â€”is a partition of the whole set
V
k

of all k-dimensional subspaces of
V into N disjoint t-(v, k, Î»)q designs. Obviously, the complete t-(v, k, Î»max)q design
forms an LSq[N](t, k, v) large set for N = 1 which is called trivial.
The parameter N determines the index Î», since it must be
Î» Â· N =
v âˆ’t
k âˆ’t

= Î»max .
If N = 2 we speak of a halving.
As for subspace designs, we call a set of parameters LSq[N](t, k, v) admissible
if the parameters are admissible, i.e. if N divides Î»max and if the design parameters
t-(v, k, Î»max/N)q are admissible. Using the second equation in Lemma 3 it is easy
to see that this is equivalent to
v âˆ’s
k âˆ’s

q
â‰¡0
(mod N) for 0 â‰¤s â‰¤t.
If a large set with this parameters exists, it is called realizable (Fig.3).
Many results for subspace designs also hold true for their large sets. The following
results are from [25, 46].
Lemma 8 If LSq[N](t, k, v) is realizable, then for each divisor d | N, the parame-
ters LSq[d](t, k, v) are realizable, too.
Lemma 9 If there exists an LSq[N](t, k, v) for t â‰¥1 then there exists
(a) the dual large set LSq[N](t, v âˆ’k, v);
(b) the reduced large set LSq[N](t âˆ’1, k, v);
(c) the derived large set LSq[N](t âˆ’1, k âˆ’1, v âˆ’1);
(d) a residual large set LSq[N](t âˆ’1, k, v âˆ’1).
Lemma 10 ([25, Corollary 4]) If there exists an LSq[N](t, k âˆ’1, v âˆ’1) and an
LSq[N](t, k, v âˆ’1), then there exists an LSq(t, k, v).
A group G â‰¤Aut(L (V )) is called the automorphism group of the large set
{D1, D2, . . . , DN} if
G = Aut(L (V )){D1,D2,...,D N }

202
M. Braun et al.
Fig. 3 An LS2[7](1, 2, 4) in the subspace lattice of F4
2
Table 6 Known parallelisms, given by their subspace design parameters
t-(v, k, Î»)
Constraints
Source
1-(2i, 2, 1)q
i â‰¥2
Denniston [69], Beutelspacher [69]
1-(v, 2, 1)q
v â‰¥3 odd
Baker [70], Wettl [71]
1-(6, 2, 1)3
Etzion, Vardy [72]
1-(6, 3, 1)2
Hishida, Jimbo [73], Sarmiento [74]
A large set {D1, D2, . . . , DN} is said to be uniformly-G if the designs D1, D2, . . .,
DN are G-invariant.
For ordinary combinatorial t-designs, large sets with t = 1 exist if and only if k
divides v [67]. In the q-analog case, this question is wide open, as it includes the
question for the existence of parallelisms in projective geometries: A large set of
1-(v, k, 1)q designs (i.e. spreads) is known as a (k âˆ’1)-parallelism of the projective
geometry PG(v âˆ’1, q). By admissibility, necessarily k | v. To our knowledge, the
only known existence results are the following: If v â‰¥2 is a power of 2, then all 1-
parallelisms do exist [68, 69]. Furthermore, for q = 2 and v even, all 1-parallelisms
do exist [70, 71]. In [72], a 1-parallelism of PG(5, 3) is given. The only known
parallelism for k â‰¥3 is a 2-parallelism of PG(5, 2) [73, 74] (Table6).

q-Analogs of Designs: Subspace Designs
203
Chapter â€œComputational Methods in Subspace Designsâ€ contains a summary of
methods how to construct large sets of subspace designs by computer. For the time
being, there are not many examples for t â‰¥2 where this succeeded.
In [37] a 2-(6, 3, 20)3 design and in [46] a 2-(6, 3, 78)5 design has been presented
which were detected by computer search. In both cases, the supplementary designs
have exactly the same parameters. Thus, the design and itâ€™s supplementary designs
form a large set for N = 2.
In [60] an LS2[3](2, 3, 8) was constructed. It is the ï¬rst large set with t â‰¥2 and
N â‰¥3. More large sets with the same parameters were constructed in [75]. Later on,
in [41] an LS2[3](2, 4, 8) was presented (Table7).
Table8 contains the complete listing of these few large sets found by computer.
7.1
Inï¬nite Series of Large Sets
BasedonideasofTeirlinck[76],Ajoodani-NaminiandKhosrovshahihavedeveloped
a rich framework of recursive constructions of large sets of combinatorial designs
[77â€“79]. For a survey see [80]. Recently, a q-analog version of parts of this theory
was found [46]. The basic idea is to decompose the GraÃŸmannian into joins of
smaller large sets. In this way, given a suitable set of starting large sets, an inï¬nite
series of large sets with increasing values of v and k and constant values of N and t.
Principally, the method can be applied in a variety of situations. The problem is the
current shortage of starting large sets on which the recursion can be founded.
As a detailed description of this theory is beyond the scope for this chapter, we
conï¬ne ourselves to the presentation of the newly constructed large sets (and thus,
subspace designs). The following theorems were tailored to ï¬t the ï¬ve known large
sets from Table8.
Theorem 13 ([46, Theorem 6.4, Corollary 6.6]) If there exists an LSq[N](2, 3, 6),
then there exists an LSq[N](2, k, v) for all integers v and k with v â‰¥6, v â‰¡2
(mod 4), 3 â‰¤k â‰¤v âˆ’3 and k â‰¡3 (mod 4). In particular, all these large sets exist
for q âˆˆ{3, 5} and N = 2.
An overview of the resulting large sets is given in Table9.
Theorem 14 Let q and N such that there exist large sets with parameters
LS2[N](2, 3, 8) and LS2[N](2, 4, 8). Let v and k be integers with v â‰¥8 and
0 â‰¤k â‰¤v such that
(a) v â‰¡2 mod 6 and k â‰¡3, 4, 5 mod 6 or
(b) v â‰¡3 mod 6 and k â‰¡4, 5 mod 6 or
(c) v â‰¡4 mod 6 and k â‰¡5 mod 6.

204
M. Braun et al.
Table 7 Admissible large set parameters for small values. All possible values of N > 1 are given
in brackets. Additionally, the design parameters for the largest given value of N is listed. Large set
parameters which are known to be are realizable are printed in boldface
LSq[N](t, k, v)
t-(v, k, Î»)
LS2[5](2, 3, 6)
2-(6, 3, 3)2
LS2[31](2, 3, 7)
2-(7, 3, 1)2
LS2[3](2, 3, 8)
2-(8, 3, 21)2
LS2[3, 31, 93](2, 4, 8)
2-(8, 4, 7)2
LS2[31](3, 4, 8)
3-(8, 4, 1)2
LS2[127](2, 3, 9)
2-(9, 3, 1)2
LS2[3, 127, 381](2, 4, 9)
2-(9, 4, 7)2
LS2[3](3, 4, 9)
3-(9, 4, 21)2
LS2[5, 17, 85](2, 3, 10)
2-(10, 3, 3)2
LS2[17, 127, 2159](2, 4, 10)
2-(10, 4, 5)2
LS2[127](3, 4, 10)
3-(10, 4, 1)2
LS2[73](2, 3, 11)
2-(11, 3, 7)2
LS2[17, 73, 1241](2, 4, 11)
2-(11, 4, 35)2
LS2[17](3, 4, 11)
3-(11, 4, 15)2
LS2[11, 31, 341](2, 3, 12)
2-(12, 3, 3)2
LS2[11, 31, 73, 341, 803, 2263, 24893](2, 4, 12)
2-(12, 4, 7)2
LS2[73](3, 4, 12)
3-(12, 4, 7)2
LS2[23, 89, 2047](2, 3, 13)
2-(13, 3, 1)2
LS3[2, 5, 10](2, 3, 6)
2-(6, 3, 4)3
LS3[11, 121](2, 3, 7)
2-(7, 3, 1)3
LS3[7](2, 3, 8)
2-(8, 3, 52)3
LS3[7, 11, 77, 121, 847](2, 4, 8)
2-(8, 4, 13)3
LS3[11, 121](3, 4, 8)
3-(8, 4, 1)3
LS4[17](2, 3, 6)
2-(6, 3, 5)4
LS4[11, 31, 341](2, 3, 7)
2-(7, 3, 1)4
LS4[13](2, 3, 8)
2-(8, 3, 105)4
LS4[11, 13, 31, . . . , 4433](2, 4, 8)
2-(8, 4, 21)4
LS5[2, 13, 26](2, 3, 6)
2-(6, 3, 6)5
LS5[11, 71, 781](2, 3, 7)
2-(7, 3, 1)5
LS5[3, 7, 21](2, 3, 8)
2-(8, 3, 186)5
LS5[7, 11, . . . , 71, . . . , 16401](2, 4, 8)
2-(8, 4, 31)5

q-Analogs of Designs: Subspace Designs
205
Table 8 Large sets of simple subspace designs by computer construction
LS[N]q(t, k, v)
G
#AG
t,k
LS[2]3(2, 3, 6)
âŸ¨Ïƒ 2, F2âŸ©
25 Ã— 76
LS[2]3(2, 3, 6)
S(5, 3) Ã— 1
51 Ã— 150
LS[2]5(2, 3, 6)
N(6, 5)
53 Ã— 248
LS[3]2(2, 3, 8)
S(8, 2)
43 Ã— 381
LS[3]2(2, 4, 8)
âŸ¨Ïƒ 5, F2âŸ©
69 Ã— 1061
Then there exists an LSq[N](2, k, v). In particular, all these large sets exist for q = 2
and N = 3.
An overview of the resulting large sets is given in Table10.
8
Open Problems
The subject of subspace designs is still in its infancy and there are many questions
which wait for an answer, see [81, 82]. The most tantalizing open problems seem to
be:
â€¢ Is there a q-analog of the Fano plane? (subspace design with the parameters 2-
(7, 3, 1)q)
â€¢ Is there a geometric or algebraic description of the 2-(13, 3, 1)2 designs?
â€¢ Find more q-analogs of Steiner systems!
â€¢ Find a concrete construction of a subspace design with t â‰¥4!
â€¢ Do q-Steiner systems exist for all t, i.e. is there a q-analog of Keevashâ€™ theo-
rem [52]?
â€¢ Are the parameters 2-(7, 3, 2)2 realizable?
â€¢ Is LS2[5](2, 3, 6) realizable?
â€¢ Are the halvings LSq[2](2, 3, 6) realizable for odd q > 5?
â€¢ For combinatorial designs, the halving conjecture states that all admissible designs
with Î» = Î»max/2 (i.e., halvings LS[2](t, k, v)q) are realizable [83, Sect.5]. For
t = 2, the conjecture has been proven in [84]. Can anything be said about this
conjecture in the q-analog case?

206
M. Braun et al.
Table 9 Admissibility and realizability of LSq[2](2, k, v) for q âˆˆ{3, 5}. An integer value k means
LS2[3](2, k, v) is realizable for these k, v. â€œ-â€ means the parameter set is not admissible, and â€œ?â€
means the parameter set is admissible but not known to be realizable
v
k
3
6
-
7
-
-
8
-
-
9
3
?
?
10
-
?
?
11
-
-
?
?
12
-
-
-
?
13
3
-
-
-
7
14
-
-
-
-
-
15
-
-
-
-
-
-
16
-
-
-
-
-
-
17
3
?
?
?
7
?
?
18
-
?
?
?
?
?
?
19
-
-
?
?
?
?
?
?
20
-
-
-
?
?
?
?
?
21
3
-
-
-
7
?
?
?
11
22
-
-
-
-
-
?
?
?
?
23
-
-
-
-
-
-
?
?
?
?
24
-
-
-
-
-
-
-
?
?
?
25
3
?
?
?
7
-
-
-
11
?
?
26
-
?
?
?
?
-
-
-
-
?
?
27
-
-
?
?
?
-
-
-
-
-
?
?
28
-
-
-
?
?
-
-
-
-
-
-
?
29
3
-
-
-
7
-
-
-
11
-
-
-
15
30
-
-
-
-
-
-
-
-
-
-
-
-
-
31
-
-
-
-
-
-
-
-
-
-
-
-
-
-
32
-
-
-
-
-
-
-
-
-
-
-
-
-
-
33
3
?
?
?
7
?
?
?
11
?
?
?
15
?
?
34
-
?
?
?
?
?
?
?
?
?
?
?
?
?
?
35
-
-
?
?
?
?
?
?
?
?
?
?
?
?
?
?
36
-
-
-
?
?
?
?
?
?
?
?
?
?
?
?
?
37
3
-
-
-
7
?
?
?
11
?
?
?
15
?
?
?
19
38

q-Analogs of Designs: Subspace Designs
207
Table 10 Admissibility and realizability of LS2[3](2, k, v). An integer value k means
LS2[3](2, k, v) is realizable for these k, v. â€œ-â€ means the parameter set is not admissible, and
â€œ?â€ means the parameter set is admissible but not known to be realizable
v
k
-
6
-
7
3
4
8
-
4
9
-
-
5
10
-
-
-
11
-
-
-
-
12
-
-
-
-
13
3
4
5
-
-
14
-
4
5
-
-
15
-
-
5
-
-
-
16
-
-
-
-
-
-
17
-
-
-
-
-
-
-
18
-
-
-
-
-
-
-
19
3
4
5
?
?
?
9
10
20
-
4
5
?
?
?
?
10
21
-
-
5
?
?
?
?
?
11
22
-
-
-
?
?
?
?
?
?
23
-
-
-
-
?
?
?
?
?
?
24
-
-
-
-
-
?
?
?
?
?
25
3
4
5
-
-
-
9
10
11
?
?
26
-
4
5
-
-
-
-
10
11
?
?
27
-
-
5
-
-
-
-
-
11
?
?
?
28
-
-
-
-
-
-
-
-
-
?
?
?
29
-
-
-
-
-
-
-
-
-
-
?
?
?
30
-
-
-
-
-
-
-
-
-
-
-
?
?
31
3
4
5
-
-
-
9
10
11
-
-
-
15
16
32
-
4
5
-
-
-
-
10
11
-
-
-
-
16
33
-
-
5
-
-
-
-
-
11
-
-
-
-
-
17
34
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
35
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
36
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
37
3
4
5
?
?
?
9
10
11
?
?
?
15
16
17
-
-
38
-
4
5
?
?
?
?
10
11
?
?
?
?
16
17
-
-
39
-
-
5
?
?
?
?
?
11
?
?
?
?
?
17
-
-
-
40

208
M. Braun et al.
References
1. J. Tits, Sur les analogues algÃ©briques des groupes semi-simples complexes, in Colloque
dâ€™algÃ¨bre supÃ©rieure, tenu Ã  Bruxelles du 19 au 22 dÃ©cembre 1956, Centre Belge de Recherches
MathÃ©matiques (Ã‰tablissements Ceuterick, Louvain; Librairie Gauthier-Villars, Paris 1957),
pp. 261â€“289
2. T. Beth, D. Jungnickel, H. Lenz, Design Theory, 2nd edn. (Cambridge University Press, Cam-
bridge, 1999)
3. C.J. Colbourn, J.H. Dinitz, Handbook of Combinatorial Designs, 2nd edn., Discrete Mathe-
matics and Its Applications (Chapman & Hall/CRC, Boca Raton, 2006)
4. M. Schwartz, T. Etzion, Codes and anticodes in the Grassman graph. J. Comb. Theory Ser. A
97(1), 27â€“42 (2002). https://doi.org/10.1006/jcta.2001.3188
5. G, Birkhoff, Lattice theory, Colloquium Publications, vol 25, 3rd edn. American Mathematical
Society (1967)
6. R.P. Stanley, Enumerative Combinatorics, 2nd edn., Cambridge Studies in Advanced Math-
ematics, vol. 1 (Cambridge University Press, Cambridge, 2012). https://doi.org/10.1017/
CBO9781139058520
7. E. Artin, Geometric Algebra (Wiley classics library, Interscience Publishers Inc., New York,
1988). https://doi.org/10.1002/9781118164518.ch1
8. R.D. Fray, Congruence properties of ordinary and q-binomial coefï¬cients. Duke Math. J. 34(3),
467â€“480 (1967). https://doi.org/10.1215/S0012-7094-67-03452-7
9. F.H. Jackson, q-difference equations. Am. J. Math. 32(3), 305â€“314 (1910). https://doi.org/10.
2307/2370183
10. M. Ward, A calculus of sequences. Am. J. Math. 58(2), 255â€“266 (1936). https://doi.org/10.
2307/2371035
11. H. Cohn, Projective geometry over F1 and the Gaussian binomial coefï¬cients. Am. Math. Mon.
111(6), 487â€“495 (2004). https://doi.org/10.2307/4145067
12. J. Goldman, G.C. Rota, On the foundations of combinatorial theory IV ï¬nite vector spaces and
Eulerian generating functions. Stud. Appl. Math. 49(3), 239â€“258 (1970)
13. G. PÃ³lya, G. Alexanderson, Gaussian binomial coefï¬cients. Elem. Math. 26, 102â€“109 (1971),
http://eudml.org/doc/1410
14. C. Berge, D. Ray-Chaudhuri, Unsolved problems, in Hypergraph Seminar: Ohio State Uni-
versity 1972, Lecture Notes in Mathematics, ed. by C. Berge, D. Ray-Chaudhuri (Springer,
Berlin, 1974), pp. 278â€“287. https://doi.org/10.1007/BFb0066199
15. P.J. Cameron, Generalisation of Fisherâ€™s inequality to ï¬elds with more than one element, in
Combinatorics - Proceedings of the British Combinatorial Conference 1973, London Mathe-
matical Society Lecture Note Series, ed. by T.P. McDonough, V.C. Mavron (Cambridge Uni-
versity Press, Cambridge, 1974), pp. 9â€“13. https://doi.org/10.1017/CBO9780511662072.003
16. P. Delsarte, Association schemes and t-designs in regular semilattices. J. Comb. Theory Ser.
A 20(2), 230â€“243 (1976). https://doi.org/10.1016/0097-3165(76)90017-0
17. S. Thomas, Designs over ï¬nite ï¬elds. Geom. Dedicata 24(2), 237â€“242 (1987). https://doi.org/
10.1007/BF00150939
18. H. Suzuki, 2-designs over GF(2m). Graphs Comb. 6(3), 293â€“296 (1990). https://doi.org/10.
1007/BF01787580
19. H. Suzuki, 2-designs over GF(q). Graphs Comb. 8(4), 381â€“389 (1992). https://doi.org/10.
1007/BF02351594
20. M. Braun, A. Kerber, R. Laue, Systematic construction of q-analogs of t-(v, k, Î»)-designs.
Des. Codes Cryptogr. 34(1), 55â€“70 (2005). https://doi.org/10.1007/s10623-003-4194-z
21. H. Suzuki, On the inequalities of t-designs over a ï¬nite ï¬eld. Eur. J. Comb. 11(6), 601â€“607
(1990). https://doi.org/10.1016/S0195-6698(13)80045-5
22. B. Segre, Teoria di galois, ï¬brazioni proiettive e geometrie non desarguesiane. Ann. Mat. Pura
Appl. 4 64(1), 1â€“76 (1964). https://doi.org/10.1007/BF02410047
23. J. AndrÃ©, Ãœber nicht-Desarguessche Ebenen mit transitiver Translationsgruppe. Math. Z. 60(1),
156â€“186 (1954). https://doi.org/10.1007/BF01187370

q-Analogs of Designs: Subspace Designs
209
24. D.K. Ray-Chaudhuri, R.M. Wilson, On t-designs. Osaka J. Math. 12(3), 737â€“744 (1975)
25. M. Kiermaier, R. Laue, Derived and residual subspace designs. Adv. Math. Commun. 9(1),
105â€“115 (2015). https://doi.org/10.3934/amc.2015.9.105
26. T.V. Trung, On the construction of t-designs and the existence of some new inï¬nite families of
simple 5-designs. Arch. Math. 47(2), 187â€“192 (1986). https://doi.org/10.1007/BF01193690
27. D.C. van Leijenhorst, Orbits on the projective line. J. Comb. Theory Ser. A 31(2), 146â€“154
(1981). https://doi.org/10.1016/0097-3165(81)90011-X
28. L.M.H.E. Driessen, t-designs, t â‰¥3, Technical Report, Technische Universiteit Eindhoven,
1978
29. N.S. Mendelsohn, Intersection numbers of t-designs, in Studies in Pure Mathematics, ed. by
L. Mirsky (Academic Press, London, 1971), pp. 145â€“150
30. W. Oberschelp, Lotto-Garantiesysteme und BlockplÃ¤ne. Math.-Phys. Semesterber. 19, 55â€“67
(1972)
31. M. Kiermaier, M.O. PavË‡ceviÂ´c, Intersection numbers for subspace designs. J. Comb. Des. 23(11),
463â€“480 (2015). https://doi.org/10.1002/jcd.21403
32. E. KÃ¶hler, Allgemeine Schnittzahlen in t-Designs. Discret. Math. 73(1â€“2), 133â€“142 (1988â€“
1989). https://doi.org/10.1016/0012-365X(88)90141-0
33. S. Thomas, Designs and partial geometries over ï¬nite ï¬elds. Geom. Dedicata 63, 247â€“253
(1996)
34. A. Kerber, Applied Finite Group Actions, Algorithms and Combinatorics, vol 19 (Springer,
Berlin, 1999). https://doi.org/10.1007/978-3-662-11167-3
35. E.S. Kramer, D.M. Mesner, t-designs on hypergraphs. Discret. Math. 15(3), 263â€“296 (1976).
https://doi.org/10.1016/0012-365X(76)90030-3
36. B. Huppert, I. Endliche Gruppen, Grundlehren der Mathematischen Wissenschaften (Springer,
Berlin, 1967), http://opac.inria.fr/record=b1108495
37. M. Braun, Some new designs over ï¬nite ï¬elds. Bayreuth. Math. Schr. 74, 58â€“68 (2005)
38. M. Miyakawa, A. Munemasa, S. Yoshiara, On a class of small 2-designs over GF(q). J. Comb.
Des. 3(1), 61â€“77 (1995). https://doi.org/10.1002/jcd.3180030108
39. S, Braun, Construction of q-analogs of combinatorial designs, Presentation at the conference
Algebraic Combinatorics and Applications (ALCOMA10). (Thurnau, Germany, 2010)
40. S, Braun, Algorithmen zur computerunterstÃ¼tzten Berechnung von q-Analoga kombina-
torischer Designs. Diplomathesis UniversitÃ¤t Bayreuth (2009)
41. M. Kiermaier, R. Laue, A. Wassermann, A new series of large sets of subspace designs over
the binary ï¬eld. Des. Codes Cryptogr. (2016). https://doi.org/10.1007/s10623-017-0349-1
42. M. Braun, New 3-designs over the binary ï¬eld. Int. Electron. J. Geom. 6(2), 79â€“87 (2013)
43. M. Braun, New inï¬nite series of 2-designs over the binary and ternary ï¬eld. Des. Codes
Cryptogr. 81(1), 145â€“152 (2016). https://doi.org/10.1007/s10623-015-0133-z
44. M. Braun, T. Etzion, P.R.J. Ã–stergÃ¥rd, A. Vardy, A. Wassermann, Existence of q-analogs of
Steiner systems. Forum Math. 4(7), (2016). https://doi.org/10.1017/fmp.2016.5
45. M. Braun, Designs over the binary ï¬eld from the complete monomial group. Australas. J.
Comb. 67(3), 470â€“475 (2017)
46. M. Braun, M. Kiermaier, A. Kohnert, R. Laue, Large sets of subspace designs. J. Comb. Theory
Ser. A 147, 155â€“185 (2017). https://doi.org/10.1016/j.jcta.2016.11.004
47. M. Braun, A. Wassermann, Disjoint q-Steiner systems in dimension 13, UniversitÃ¤t Bayreuth,
Bayreuth, Technical Report, 2017
48. H. Suzuki, Five days introduction to the theory of designs (1989), http://subsite.icu.ac.jp/
people/hsuzuki/lecturenote/designtheory.pdf
49. P.J. Cameron, Locally symmetric designs. Geom. Dedicata 3, 65â€“76 (1974)
50. D. Ray-Chaudhuri, N. Singhi, q-analogues of t-designs and their existence. Linear Algebra
Appl. 114â€“115, 57â€“68 (1989). https://doi.org/10.1016/0024-3795(89)90451-5
51. R.M. Wilson, The necessary conditions for t-designs are sufï¬cient for something. Util. Math
4, 207â€“215 (1973)
52. P. Keevash, The existence of designs. arXiv identiï¬er 1401.3665 (2014)

210
M. Braun et al.
53. V. Guruswami, S. Kopparty, Explicit subspace designs, in 2013 IEEE 54th Annual Sympo-
sium on Foundations of Computer Science, pp. 608â€“617 (2013). https://doi.org/10.1109/FOCS.
2013.71
54. V. Guruswami, C. Xing, List decoding Reed-Solomon, algebraic-geometric, and Gabidulin
subcodes up to the singleton bound, in Proceedings of the Forty-ï¬fth Annual ACM Symposium
on Theory of Computing, STOC â€™13 (ACM, New York, NY, USA, 2013), pp. 843â€“852. https://
doi.org/10.1145/2488608.2488715
55. L. Teirlinck, Non-trivial t-designs without repeated blocks exist for all t. Discret. Math. 65(3),
301â€“311 (1987). https://doi.org/10.1016/0012-365X(87)90061-6
56. A. Fazeli, S. Lovett, A. Vardy, Nontrivial t-designs over ï¬nite ï¬elds exist for all t. J. Comb.
Theory Ser. A 127, 149â€“160 (2014)
57. P. Frankl, V. RÃ¶dl, Near perfect coverings in graphs and hypergraphs. Eur. J. Comb. 6(4),
317â€“326 (1985)
58. T. Abe, S. Yoshiara, On Suzukiâ€™s construction of 2-designs over GF(q). Sci. Rep. Hirosaki
Univ. 10, 119â€“122 (1993)
59. T. Itoh, A new family of 2-designs over GF(q) admitting SLm(ql). Geom. Dedicata 69(3),
261â€“286 (1998). https://doi.org/10.1023/A:1005057610394
60. M. Braun, A. Kohnert, P.R.J. Ã–stergÃ¥rd, A. Wassermann, Large sets of t-designs over ï¬nite
ï¬elds. J. Comb. Theory Ser. A 124, 195â€“202 (2014). https://doi.org/10.1016/j.jcta.2014.01.
008
61. K. Metsch, Boseâ€“Burton Type Theorems for Finite Projective, Afï¬ne and Polar Spaces, in
Surveys in Combinatorics, Lecture Notes Series, ed. by Lamb, Preece (London Mathematical
Society, 1999)
62. D.E. Knuth, Dancing links, in Millennial Perspectives in Computer Science, Cornerstones of
Computing, ed. by A.W. Roscoe, J. Davies, J. Woodcock (Palgrave, 2000), pp. 187â€“214
63. M. Braun, M. Kiermaier, A. NakiÂ´c, On the automorphism group of a binary q-analog of the
Fano plane. Eur. J. Comb. 51, 443â€“457 (2016). https://doi.org/10.1016/j.ejc.2015.07.014
64. M. Kiermaier, S. Kurz, A. Wassermann, The order of the automorphism group of a binary
q-analog of the fano plane is at most two. Des. Codes Cryptogr. (2017). https://doi.org/10.
1007/s10623-017-0360-6
65. J.J.Sylvester,Noteonthehistoricaloriginoftheunsymmetricalsixvaluedfunctionofsixletters.
Philos. Mag. Ser. 4 21(141), 369â€“377 (1861). https://doi.org/10.1080/14786446108643072
66. R.H. Denniston, Sylvesterâ€™s problem of the 15 schoolgirls. Discret. Math. 9(3), 229â€“233 (1974).
https://doi.org/10.1016/0012-365X(74)90004-1
67. Z. Baranyai, On the factorization of the complete uniform hypergraph, in Inï¬nite and ï¬nite
Sets, Colloquia Mathematica Societatis JÃ¡nos Bolyai, vol. 1, ed. by A. Hajnal, R. Rado, V.T.
SÃ³s (Bolyai JÃ¡nos Matematikai TÃ¡rsulat and North-Holland, Budapest and Amsterdam, 1975),
pp. 91â€“107
68. A. Beutelspacher, On parallelisms in ï¬nite projective spaces. Geometriae Dedicata 3(1), 35â€“40
(1974)
69. R.H.F. Denniston, Some packings of projective spaces. Atti Accad. Naz. Lincei Rend. Cl. Sci.
Fis. Mat. Natur. 52(8), 36â€“40 (1972)
70. R.D. Baker, Partitioning the planes of AG2m(2) into 2-designs. Discret. Math. 15(3), 205â€“211
(1976)
71. F. Wettl, On parallelisms of odd dimensional ï¬nite projective spaces. Period. Polytech. Transp.
Eng. 19(1â€“2), 111 (1991)
72. T. Etzion, A. Vardy, Automorphisms of codes in the Grassmann scheme. arXiv identiï¬er
1210.5724 (2012)
73. T. Hishida, M. Jimbo, Cyclic resolutions of the bib design in PG(5, 2). Australas. J. Comb.
22, 73â€“79 (2000)
74. J.F. Sarmiento, Resolutions of PG(5, 2) with point-cyclic automorphism group. J. Comb.
Des. 8(1), 2â€“14 (2000). https://doi.org/10.1002/(SICI)1520-6610(2000)8:1<2::AID-JCD2>3.
0.CO;2-H

q-Analogs of Designs: Subspace Designs
211
75. M.R. Hurley, B.K. Khadka, S.S. Magliveras, Some new large sets of geometric designs of type
[3][2, 3, 28]. J. Algebra Comb. Discret. Struct. Appl. 3(3), 165â€“176 (2016). https://doi.org/10.
13069/jacodesmath.40139
76. L. Teirlinck, Locally trivial t-designs and t-designs without repeated blocks. Discret. Math.
77(1â€“3), 345â€“356 (1989). https://doi.org/10.1016/0012-365X(89)90372-5
77. G. B. Khosrovshahi, S. Ajoodani-Namini, Combining t-designs. JCTSA 58(1), 26â€“34 (1991).
https://doi.org/10.1016/0097-3165(91)90071-N
78. S. Ajoodani-Namini, Extending large sets of t-designs. J. Comb. Theory Ser. A 76(1), 139â€“144
(1996). https://doi.org/10.1006/jcta.1996.0093
79. S. Ajoodani-Namini, G. Khosrovashahi, More on halving the complete designs. Discret. Math.
135(1â€“3), 29â€“37 (1994). https://doi.org/10.1016/0012-365X(93)E0096-M
80. G.B. Khosrovshahi, B. Tayfeh-Rezaie, Trades and t-designs, Surveys in Combinatorics 2009,
London Mathematical Society Lecture Note Series (Cambridge University Press, Cambridge,
2009), pp. 91â€“111. https://doi.org/10.1017/CBO9781107325975.005
81. T. Etzion, Problems on q-analogs in coding theory. arXiv identiï¬er 1305.6126 (2013)
82. T. Etzion, L. Storme, Galois geometries and coding theory. Des. Codes Cryptogr. 78(1), 311â€“
350 (2016). https://doi.org/10.1007/s10623-015-0156-5
83. A. Hartman, Halving the complete design. Ann. Discret. Math. 34, 207â€“224 (1987). https://
doi.org/10.1016/S0304-0208(08)72888-3
84. S. Ajoodani-Namini, All block designs with b =
v
k

/2 exist. Discret. Math. 179(1â€“3), 27â€“35
(1998). https://doi.org/10.1016/S0012-365X(97)00024-1

Computational Methods in Subspace Designs
Michael Braun, Michael Kiermaier and Alfred Wassermann
Abstract Subspace designs are the q-analogs of combinatorial designs. Introduced
in the 1970s, these structures gained a lot of interest recently because of their appli-
cation to random network coding. Compared to combinatorial designs, the number
of blocks of subspace designs are huge even for the smallest instances. Thus, for
a computational approach, sophisticated algorithms are indispensible. This chapter
highlights computational methods for the construction of subspace designs, in par-
ticular methods based on group theory. Starting from tactical decompositions we
present the method of Kramer and Mesner which allows to restrict the search for
subspace designs to those with a prescribed group of automorphisms. This approach
reduces the construction problem to the problem of solving a Diophantine linear
system of equations. With slight modiï¬cations it can also be used to construct large
sets of subspace designs. After a successful search, it is natural to ask if subspace
designs are isomorphic. We give several helpful tools which allow to give answers in
surprisingly many situations, sometimes in a purely theoretical way. Finally, we will
give an overview of algorithms which are suitable to solve the underlying Diophan-
tine linear system of equations. As a companion to chapter â€œq-Analogs of Designs:
Subspace Designsâ€ this chapter provides an extensive list of groups which were used
to construct subspace designs and large sets of subspace designs.
M. Braun (B)
Faculty of Computer Science, Darmstadt University of Applied Sciences,
64295 Darmstadt, Germany
e-mail: michael.braun@h-da.de
M. Kiermaier Â· A. Wassermann
Department of Mathematics, University of Bayreuth, 95440 Bayreuth, Germany
e-mail: michael.kiermaier@uni-bayreuth.de
A. Wassermann
e-mail: alfred.wassermann@uni-bayreuth.de
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_9
213

214
M. Braun et al.
1
Introduction
Combinatorial design theory has a long and venerable history starting in the middle
of the 19th century. Combinatorial designs have many applications and there exists
a huge amount of literature. For a comprehensive overview we recommend the two
books [3, 29].
If one replaces in the deï¬nition of a combinatorial design set of points by vector
space and cardinality by dimension one gets the deï¬nition of a subspace design.
Subspace designs, also called q-analogs of designs, designs over ï¬nite ï¬elds,
or designs in vector spaces were introduced in the early 1970s independently by
Ray-Chaudhuri [2], Cameron [25, 26] and Delsarte [31]. While receiving only occa-
sionally attention by relatively few research groups until 10 years ago, the situation
has changed a lot since then. Subspace designs have found much increased interest
now due to the connection to random network coding pointed out by KÃ¶tter and
Kschischang [64]. For an in-depth introduction to subspace designs the reader is
referred to chapter â€œq-Analog of Designs: Subspace Designâ€.
In terms of random network coding, one is mainly interested in very speciï¬c
subspaces designs, namely q-Steiner systems. The reason is that q-Steiner systems
are the best possible constant-dimension codes for random network coding. To be
precise, they are diameter-perfect constant-dimension codes. This is analog to the
situation in â€œclassicalâ€ coding theory, where (combinatorial) Steiner systems are
the best possible constant-weight codes for a given length and minimum distance.
For more information on constant-dimension codes the reader is referred to chapters
â€œConstruction of Constant Dimension Codesâ€ and â€œConstruction of Cyclic Subspace
Codes and Maximum Rankâ€.
Subspace designs and subspace codes with t = 1 and Î» = 1 are better known as
(partial) spreads, which have been studied in ï¬nite geometry since many decades.
However, the ï¬rst subspace design for t â‰¥2 was found only in 1987 [92], when the
explicit question for their existence has been open for already about 15 years. For
moreinformationongeometricaspectsthereaderisreferredtochaptersâ€œGeometrical
Aspects of Subspace Codesâ€ and â€œPartial Spreads and Vector Space Paritionsâ€.
Systematic computer search for subspace designs started in the 1990s [81]. Since
then, quite a few subspace designs could be constructed, the most prominent being
designs for t = 3 [17] and the ï¬rst q-Steiner systems for t = 2 [16].
In this chapter we will study computational methods to construct subspace designs
andsocalledlargesetsofsubspacedesigns.Foranin-depthstudyofsubspacedesigns
the reader is referred to chapter â€œq-Analog of Designs: Subspace Designsâ€. In par-
ticular, chapter â€œq-Analog of Designs: Subspace Designsâ€ contains comprehensive
tables of all known simple subspace designs for small dimensions and t â‰¥2.
Much more detailed information on construction and classiï¬cation algorithms of
combinatorial objects can be found in the book by Kaski and Ã–stergÃ¥rd [53] and in
the chapter on computer construction in the Handbook of combinatorial designs [42].

Computational Methods in Subspace Designs
215
2
Preliminaries
This is an overview in compressed form about subspace designs. The deï¬nitions
and results can be found in more details and together with references in chapter
â€œq-Analogs of Designs:Subspace Designâ€.
Throughout this chapter, V will be a vector space of ï¬nite dimension v over a
ï¬nite ï¬eld Fq. Subspaces of dimension k will be called k-subspaces. Sometimes,
1-subspaces will be denoted as points. If the dimension k is clear from the context,
k-subspaces will occasionally be called blocks.
For an integer 0 â‰¤k â‰¤v the set
V
k

q consisting of all k-subspaces of V is called
GraÃŸmannian. Its cardinality is determined by the q-binomial coefï¬cient
#
V
k

q
=
v
k

q
= (qv âˆ’1) Â· Â· Â· (qvâˆ’k+1 âˆ’1)
(qk âˆ’1) Â· Â· Â· (q âˆ’1)
.
If clear from the context, we will omit the index q from
V
k

q and
v
k

q for sake of
readability. The q-analog of a combinatorial design is deï¬ned as follows.
Deï¬nition 1 Let q be a prime power, V an Fq-vector space of ï¬nite dimension v,
0 â‰¤t â‰¤k â‰¤v integers and Î» a non-negative integer. A pair D = (V, B), where B
is a collection of k-subspaces (blocks) of V , is called a t-(v, k, Î»)q subspace design
on V if each t-subspace of V is contained in exactly Î» blocks.
If B is a set, i.e. if every k-subset appears at most once in B, the design is called
simple.
A t-(v, k, 1)q design is also called S(t, k, v)q q-Steiner system.
If the strict equality conditions #{B âˆˆB | T âŠ‚B} = Î» for all T âˆˆ
V
t

q in
Deï¬nition1 is relaxed to â€œâ‰¤â€, the structure is called packing design, whilst the
relaxation to â€œâ‰¥â€ is called covering design. Of course, the question is to maximize
(minimize) the number of blocks in a packing (covering) design. From the viewpoint
of random network coding, packing designs with Î» = 1 are the same as constant-
dimension subspace codes of minimum subspace distance 2(k âˆ’t âˆ’1).
If not explicitly stated otherwise, for the rest of the chapter all designs will be
simple designs. The empty set and the full GraÃŸmannian are designs for all values
of 0 â‰¤t â‰¤k, called trivial designs. The parameters of the GraÃŸmannian
V
k

q as a
t-design are t-(v, k,
vâˆ’t
kâˆ’t

q)q. Thus, for ï¬xed values of t, v, k, the largest possible
value for Î» is Î»max :=
vâˆ’t
kâˆ’t

q.
Lemma 1 ([91]) Let D = (V, B) be a t-(v, k, Î»)q subspace design. For each s âˆˆ
{0, . . . , t}, D is an s-(v, k, Î»s)q subspace design with
Î»s =
vâˆ’s
tâˆ’s

q
kâˆ’s
tâˆ’s

q
Â· Î» =
vâˆ’s
kâˆ’s

q
vâˆ’t
kâˆ’t

q
Â· Î».

216
M. Braun et al.
In particular, the number of blocks is given by
#B = Î»0 = Î» Â·
v
t

q
/
k
t

q
.
A consequence of this lemma is that every 1-subspace is contained in
Î»1 = Î» Â·
vâˆ’1
tâˆ’1

q
kâˆ’1
tâˆ’1

q
blocks of a t-(v, k, Î»)q design.
A set t-(v, k, Î»)q of design parameters is called admissible if for all 0 â‰¤s â‰¤t the
divisibility conditions
v âˆ’s
t âˆ’s

q
Â· Î» â‰¡0
(mod
k âˆ’s
t âˆ’s

q
)
are fulï¬lled. If a t-(v, k, Î»)q design exists, the parameters are called realizable.
For ï¬xed t, k, v the divisibility conditions imply a minimum Î»min that fulï¬lls the
conditions. It is easy to see that all admissible values of Î» are multiples of Î»min.
If a t-(v, k, Î»)q design is realizable, then also the dual design with parame-
ters t-(v, v âˆ’k,
vâˆ’t
k

/
vâˆ’t
kâˆ’t

Î»)q and the supplementary design with parameters t-
(v, k, Î»max âˆ’Î»)q are realizable. Therefore, it is usually enough to restrict the search
for designs to 2 â‰¤k â‰¤v/2 and 1 â‰¤Î» â‰¤Î»max/2.
A celebrated, recent result by Fazeli, Lovett, and Vardy [36] is that there exist
subspace designs for every value of t and q if the parameters v, k, Î» are large enough.
However, their proof is not constructive.
An automorphism of a subspace design D = (V, B) is a bijective mapping g âˆˆ
PL(V ) such that Bg = B. Under the composition of mappings, the set of all
automorphisms of a design forms a group, the automorphism group Aut(D) of the
design D. For every subgroup G of its automorphism group a design is said to be
G-invariant.
The action of PL(V ) on the subspace lattice of V preserves containment, that
is, for all g âˆˆPL(V ) and all subspaces S, T â‰¤V ,
S â‰¤T if and only if Sg â‰¤T g.
(1)
In particular, for 0 â‰¤s â‰¤v and S âˆˆ
V
s

the image Sg is again in
V
s

.
For computational purposes we will restrict ourselves to automorphisms from
GL(V ) which is represented by the group GL(v, q) of all invertible v Ã— v matrices
over Fq, via assigning the map x â†’xA to the matrix A âˆˆGL(v, q).
Let G be a group acting on a set X via x â†’xg. The stabilizer of x in G is given
by Gx = {g âˆˆG | xg = x}, and the G-orbit of x is given by xG = {xg | g âˆˆG}. For

Computational Methods in Subspace Designs
217
two elements x, xâ€² âˆˆX in the same orbit, we write x âˆ¼xâ€². Obviously, x âˆ¼xâ€² if and
only if there exists an element g âˆˆG with xâ€² = xg. The relation âˆ¼is an equivalence
relation on X. Therefore, by the action of G, the set X is partitioned into orbits.
For all x âˆˆX, there is the correspondence xg â†’Gxg between the orbit xG and the
set Gx\G of the right cosets of the stabilizer Gx in G. For ï¬nite orbit lengths, this
implies the orbit-stabilizer theorem stating that #xG = [G : Gx]. In particular, the
orbit lengths #xG are divisors of the group order #G. The stabilizers of elements in
the same orbit are related by the formula
Gxg = gâˆ’1Gxg.
(2)
A partition of the GraÃŸmannian into N disjoint designs with the same parameters
is called large set of designs and denoted by LSq[N](t, k, v). It is clear that
N Â· Î» = Î»max.
that is, N has to divide Î»max and N determines Î». The large set parameters
LSq[N](t, k, v) are called admissible if
v âˆ’s
k âˆ’s

q
â‰¡0
(mod N) for 0 â‰¤s â‰¤t.
If an LSq[N](t, k, v) exists the parameters are called realizable.
If for a group G âˆˆPL(v, q) and a large set with parameters LSq[N](t, k, v) all
its designsâ€”having parameters t-(v, k, Î»max/N)qâ€”are G-invariant, then the large
set is called uniformly-G.
3
Computer Construction
The computational approaches to construct subspace designs and combinatorial
designs are mostly the same. This is not a big surprise since both, combinatorial
designs and subspace designs, are ï¬nite incidence structures.
The main difference to combinatorial designs is that the cardinalities of the objects
which have to be considered for subspace designs are way larger than for combi-
natorial designs. As a consequence, so far only for comparatively small parameters
subspace designs could be constructed by computer.
Now, the question is how can a computer be instructed to ï¬nd t-(v, k, Î»)q designs?
The most naive approach would be the following algorithm.

218
M. Braun et al.
Algorithm 1 Naive algorithm to search for a simple t-(v, k, 1)q design.
B â†âˆ…, T â†
V
t

, T â†âˆ…
success â†true
while success do
Search B âˆˆ
V
k

such that for T âˆˆT : T Ì¸âŠ‚B
if B exists:
B â†B âˆª{B}
for T âŠ‚B:
T â†T \ {T }
T â†T âˆª{T }
else:
success â†false
end while
return B // return packing design
Thus, this simple, greedy algorithm packs blocks into the design until no more
block can be found that consists solely of t-subspaces which are not covered yet.
Surprisingly enough, an analysis by Frankl and RÃ¶dl [40] shows that asymptotically
for v â†’âˆ, the set of blocks returned by Algorithm1 is expected to come quite close
to a Steiner system.
Theorem 1 (Frankl and RÃ¶dl) Suppose integers t, k are given, 0 < t < k < v. Then
for v â†’âˆAlgorithm1 is expected to return a set B âŠ‚
V
k

such that
#B = (1 âˆ’o(1))
v
t

q
/
k
t

q
and dim(K â€² âˆ©K â€²â€²) < t for all distinct K â€², K â€²â€² âˆˆB.
An alternative description of Algorithm1 is the following: We ï¬x an order on all
subspaces T âˆˆ
V
t

and K âˆˆ
V
k

and deï¬ne the matrix At,k = (ai, j) by
ai, j =

1,
if Ti âŠ‚K j;
0,
else.
That is, the matrix At,k is of size
v
t

Ã—
v
k

. Now, if the resulting selection of blocks
in Algorithm1 even forms a q-Steiner system then this selection can be expressed
as a 0/1-vector x of length
v
k

such that
At,k Â· x =
â›
âœâ
1
...
1
â
âŸâ .
(3)

Computational Methods in Subspace Designs
219
Example 1 For a really small example we look at combinatorial designs instead of
subspace designs. That is, V is a set of points and the blocks are k-element subsets
of V .
In our example we want to cover every vertex (i.e. 1-subset) of the following
graph by exactly one edge (i.e. 2-subset). The result is a 1-(4, 2, 1) (combinatorial)
design.
a
b
c
d
1
2
3
4
5
6
It is easy to see that there are the following three solutions:
a
b
c
d
1
3
a
b
c
d
2
4
a
b
c
d
5
6
The matrix A1,2 together with the three solution vectors xâŠ¤looks as follows.
vertices\edges 1 2 3 4 5 6
a
1 0 0 1 1 0
b
1 1 0 0 0 1
c
0 1 1 0 1 0
d
0 0 1 1 0 1
design1
1 0 1 0 0 0
design2
0 1 0 1 0 0
design3
0 0 0 0 1 1
The three designs consist of the block sets {{a, b}, {c, d}}, {{a, d}, {b, c}}, and
{{a, c}, {b, d}}.
It turns out that problem (3) is well-known in computer science. It is called exact
cover problem and is known to be NP-complete [52]. In the general case of searching
for a t-(v, k, Î»)q design we get a generalized exact cover problem of the form
At,k Â· x =
â›
âœâ
Î»
...
Î»
â
âŸâ .
(4)
For the construction of packing designs, the â€œ=â€ in Eq.(4) has to be replaced by a
â€œâ‰¤â€, for covering designs it has to be replaced by a â€œâ‰¥â€.
There is a plethora of algorithms available to solve the exact cover problem and
its generalizations. We will discuss a few solving strategies in Sect.6.

220
M. Braun et al.
But even if there are powerful algorithms available to solve these problems, the
biggest obstacle to this strategy for constructing subspace designs is that the sizes of
the problem instances will be prohibitively large even for small parameters.
Example 2 To ï¬nd the binary analog of the Fano plane, i.e. a 2-(7, 3, 1)2 design, the
matrix A2,3 has 2 667 rows and 11 811 columns. The design would consist of 381
3-subspaces.
Although being the smallest open parameter set for subspace designs, the problem
is still out of reach for all known computer algorithms.
4
Using Groups
A possible strategy to tackle even very large instances is not to select individual
blocks but to choose whole â€œchunksâ€ of blocks which ï¬t together well. For this,
group theory comes in handy.
The idea to use groups to ï¬nd combinatorial objects can be traced back at least to
Dembowski [32], Parker [86] in the 1950s, and even to Moore [82] in 1896.
Dembowski [32] studied tactical decompositions via group actions and found
additional necessary conditions for combinatorial objects having such groups as
automorphism groups. Later on, Kramer and Mesner [65] had the idea to prescribe
an automorphism group and search by computer for combinatorial designs with this
automorphism group. The same approach has been used before the work of Kramer
and Mesner at least by Magliveras [77] and Klin [57] in their PhD theses. In fact, the
method is a systematic version of ï¬nding a tactical decomposition of a structure by
means of the automorphism group of the structure.
So, with tactical decompositions as well as with the Kramerâ€“Mesner method
we choose a group G and search for G-invariant designs. The resulting computer
problem will be smaller and thus in many cases solvable by computer hardware. But
we must be aware that those designs which are not G-invariant will not be found by
this approach.
4.1
Tactical Decompositions
Tactical decompositions of combinatorial designs, mostly symmetric designs, were
studied already by Dembowski [32, 33]. In [68, 83] tactical decompositions of sub-
space designs are introduced.
An incidence structure is a triple (P, B, I) with P âˆ©B = âˆ…and an incidence
relation I âŠ‚P Ã— B. The elements of P are called points and the elements of B
are called blocks.

Computational Methods in Subspace Designs
221
An incidence structure is called tactical conï¬guration if there is a number râ€²
such that #{B âˆˆB | (P, B) âˆˆI} = râ€² for all points P âˆˆP and if there is a number
kâ€² such that #{P âˆˆP | (P, B) âˆˆI} = kâ€² for all B âˆˆB. Counting the incidences
(P, B) in two ways, we get the equation kâ€²#B = râ€²#P.
Therefore, t-(v, k, Î»)q subspace designs are tactical conï¬gurations with the blocks
of the design being the blocks of the tactical conï¬guration. As points of the tactical
conï¬gurations one can take one of the GraÃŸmannians
V
s

, 0 â‰¤s â‰¤t. The incidence
relation is given by â€œâ‰¤â€. Then, for the tactical conï¬guration we have kâ€² =
k
s

and
râ€² = Î»s.
Deï¬nition 2 A decomposition of a tactical conï¬guration is a partition of the points
P = P1 âŠ”. . . âŠ”Pm and the blocks B = B1 âŠ”. . . âŠ”Bn.
A decomposition is tactical if there exist non-negative integers Ïi, j, Îºi, j, 1 â‰¤i â‰¤
m, 1 â‰¤j â‰¤n, such that
1. every P âˆˆPi is contained in exactly Ïi, j blocks in B j,
2. every block in B j contains Îºi, j points in Pi.
The matrices (Ïi, j) and (Îºi, j) are called tactical decomposition matrices.
In other words, a tactical decomposition is a partition P = P1 âŠ”. . . âŠ”Pm and
B = B1 âŠ”. . . âŠ”Bn of the points and blocks of a tactical conï¬guration such that
each pair (Pi, B j) itself is a tactical conï¬guration with regard to the incidence
relation I.
A tactical conï¬guration has always two trivial decompositions. One is the partition
of P, B into one set each, i.e. m = n = 1. The other one is the partition of P, B
into 1-element subsets.
Furthermore, the action of a subgroup G â‰¤Aut(D) yields a tactical decomposi-
tion which in general is nontrivial.
Theorem 2 (Dembowski [32]) Let G be a group of automorphisms of an incidence
structure (P, B, I). Then the orbits of G on the set of points P and the orbits of
G on the blocks B form a tactical decomposition.
Proof The statement follows immediately from (1) and from the fact that automor-
phisms map points to points and blocks to blocks.
âŠ“âŠ”
Remark 1 In [32] it was also observed that there are nontrivial tactical decomposition
which do not stem from group actions.
The deï¬nition of the tactical decomposition matrices leads directly to the follow-
ing equations for t-(v, k, Î»)q designs and 0 â‰¤s â‰¤t:
m

i=1
Îºi, j =
k
s

,
n

j=1
Ïi, j = Î»s.
(5)

222
M. Braun et al.
Furthermore, for all i âˆˆ{1, . . . , m} and j âˆˆ{1, . . . , n} we have
#Pi Â· Ïi, j = #B j Â· Îºi, j,
(6)
since (Pi, B j) forms a tactical conï¬guration.
In [83] the following further relations are stated.
Theorem 3 (NakiÂ´c, PavË‡ceviÂ´c) Let 0 â‰¤s â‰¤t. Suppose that
V
s

= P1 âŠ”. . . âŠ”Pm,
B = B1 âŠ”. . . âŠ”Bn
is a tactical decomposition of a 2-(v, k, Î»)q design. Let (Ïi, j) and (Îºi, j) be the asso-
ciated decomposition matrices. Then, for all pairs of rows 1 â‰¤l,r â‰¤m,
n

j=1
Ïl, jÎºr, j =

Î» Â· #Pr,
l Ì¸= r;
Î»s + Î» Â· (#Pr âˆ’1), l = r.
(7)
In the same paper there are more, reï¬ned equations and inequalities for the special
case q = 2. The preprint [30] generalizes the above equations for subspace designs
with t = 3.
Algorithmic application
An algorithm to ï¬nd subspace designs with the help of tactical decompositions can
be the following approach. If we know the lengths of the block orbits then from
Eq.(6) we see that it is enough to work with one of the matrices (Ïi, j) or (Îºi, j).
Algorithm 2 Choose a â€œpromisingâ€ group G â‰¤PL(v, q) and ï¬nd 2-(v, k, Î»)q
designs by using tactical decomposition matrices (Ïi, j).
1. Search for tentative tactical decomposition matrices: Computeâ€”up to permuta-
tions of rows and columnsâ€”all possible matrices (Ïi, j) having nonnegative inte-
ger entries which satisfy the Eqs.(5) and (7) (and further equations or inequalities
if available, see [83]).
2. Indexing phase:
for all matrices (Ïi, j) from 2.:
for 1 â‰¤i â‰¤m, 1 â‰¤j â‰¤n:
replace all entries (i, j) of (Ïi, j) by 0/1-matrices of size #Pi Ã— #B j
â€“ having Ïi, j ones in each row and
â€“ being invariant under the simultaneous action of G on its rows and
columns.
if successful:
output incidence matrix of 2-(v, k, Î»)q design

Computational Methods in Subspace Designs
223
Remark 2 Not every orbit matrix from Step 1 will give rise to subspace designs. In
contrast, a single matrix from Step 1 may produce more than one nonisomorphic
designs.
Example 3 WewanttoconstructacombinatorialdesignfromExample1byprescrib-
ing a cyclic symmetry, e.g. the mapping Ïƒ : (a, b, c, d) â†’(b, c, d, a). The induced
mapping on the edges maps (1, 2, 3, 4, 5, 6) â†’(2, 3, 4, 1, 6, 5). Under the action
of the group âŸ¨ÏƒâŸ©the set of vertices is a single orbit {a, b, c, d} and the set of Edges
Is Partitioned Into the two orbits {1, 2, 3, 4} and {5, 6}.
a
b
c
d
1
2
3
4
5
6
Recall that we are searching for a 1-(v, 2, 1) design. We know, that such a design
consists of Î»0 = 1
4
1

/
2
1

= 2 blocks and every point appears in Î»1 = 1
3
0

/
1
0

= 1
blocks.
Therefore, we try to build our design by taking a block orbit of length two (there is
only one choice in this small case). Since there is just one point orbit, the only choice
in Step 1 is to take a trivial decomposition matrix consisting of the single entry, i.e.
n = m = 1. Equation (5) for combinatorial designs give immediately Îº1,1 = 2 and
Ï1,1 = 1. Note, that we can not use the combinatorial design versions of Eq.(7) in
this case, since we are searching for a 1-design. Thus, the only possible matrix in
Step 1 is equal to (1).
In Step 2 we ï¬nd that up to the action of âŸ¨ÏƒâŸ©just one 4 Ã— 2-matrix having a single
one in every row:
â›
âœâœâ
1 0
0 1
1 0
0 1
â
âŸâŸâ 
It is the incidence matrix of the blocks points a, b, c, d and the blocks 5, 6. Therefore,
the blocks 5, 6 form a âŸ¨ÏƒâŸ©-invariant 1-(4, 2, 1) design.
4.2
The Method of Kramer and Mesner
Similar as in the previous section we choose a group G and search for G-invariant
designs. Thus, instead of searching for individual k-subspaces as in (4) the design
has to be composed of G-orbits on the k-subspaces. This approach applied to com-
binatorial designs is commonly attributed to Kramer and Mesner [65] and has been
used there with great success.
The set of blocks B of a G-invariant t-(v, k, Î»)q design (G â‰¤Aut(L(V ))) is
the disjoint union of orbits of G on the set
V
k

of k-dimensional subspaces of V .

224
M. Braun et al.
To obtain an appropriate selection of orbits of G on
V
k

we consider the incidence
matrix AG
t,k whose rows are indexed by the G-orbits on the set of t-subspaces of V
and whose columns are indexed by the orbits on k-subspaces. The entry aG
T,K of AG
t,k
corresponding to the orbits T G and K G is deï¬ned by
aG
T,K := #{K â€² âˆˆK G | T â‰¤K â€²}.
In other words, the matrix AG
t,k is the tactical decomposition matrix (Ïi, j) for the
tacticaldecompositionofthepoints
V
t

andtheblocks
V
k

ofthetrivialt-(v, k, Î»max)q
design into orbits on the t-subspaces and k-subspaces.
Since AG
t,k is a tactical decomposition of the complete design, i.e. a tactical conï¬g-
uration with #{B âˆˆB | P â‰¤T } = Î»max for all T âˆˆ
V
t

, we can search for a subset
of Bâ€² âŠ‚B such that #{B âˆˆBâ€² | T â‰¤Bâ€²} = Î» < Î»max for all T âˆˆ
V
t

, which is a
tactical decomposition of a t-(v, k, Î»)q design. Therefore, the following theorem is
obvious.
Theorem 4 (Kramer, Mesner [65]) Let G â‰¤PL(v, q). There exists a G-invariant
t-(v, k, Î»)q design if and only if there is a 0/1-vector x satisfying
AG
t,k Â· x =
â›
âœâ
Î»
...
Î»
â
âŸâ .
(8)
Example 4 We look again at the combinatorial design from Example1 and 3 and
prescribe again the mapping Ïƒ : (a, b, c, d) â†’(b, c, d, a). Counting how often a
representative of the point orbit {a, b, c, d} appears in each of the two orbits on lines,
we get the following table.
{1, 2, 3, 4} {5, 6}
{a, b, c, d}
2
1
That is, using the Theorem of Kramer and Mesner the matrix A1,2 is condensed to the
smaller matrix AâŸ¨ÏƒâŸ©
1,2 = (2 1). Now, if we choose the orbit {5, 6} as the set of blocks,
we get a 1-(4, 2, 1) design. If we choose the other orbit we get a 1-(4, 2, 2) design.
Note that the other two designs in Example1 are not found by this prescription of
automorphisms.
Remark 3 From Eq.(6) it is clear that AG
t,k can either be computed by determining
(Ïi, j) or by computing (Îºi, j).
In some cases it is faster to compute (Îºi, j) and then determine (Ïi, j) by (6). The
relation between these two matrices is also referred to as Alltopâ€™s lemma [1].

Computational Methods in Subspace Designs
225
4.3
Promising Groups
In general, our approach in Sects.4.1 and 4.2 is to prescribe certain groups of auto-
morphisms which arise as subgroups G of the general linear group GL(V ). When it
comes to the question which groups may occur as automorphism groups of designs,
one group stands out. At least up to now, most successful computer searches for sub-
space designs with prescribed automorphism groups used this group or subgroups
thereof, see Sect.4.4. This group is the normalizer of a Singer cycle group. In the
following we will describe this group in more detail and explain why it is a promising
candidate for prescribing it as an automorphism group.
It will turn out to be helpful to apply the general linear group GL(v, q) in matrix
representation. In our notation, multiplication by group elements will be from the
right. Furtherâ€”when appropriateâ€”we will switch between the vectors of the vector
space V = Fv
q and the corresponding elements of the ï¬eld Fqv. The multiplicative
group (Fâˆ—
qv, Â·) consisting of the nonzero elements of Fqv is known to be cyclic,
generators are called primitive elements of Fqv.
Any cyclic subgroup of order qv âˆ’1 of GL(V ) is called a Singer cycle group.
By setting V = Fqv it can be seen that Singer cycle groups do always exist: For any
primitive element Î± of Fqv, the mapping Ïƒ : V â†’V , x â†’Î±x is Fq-linear and of
order #Fâˆ—
q = qv âˆ’1 and thus generates a Singer cycle group.
To get a matrix representation of Ïƒ in GL(v, q), we can proceed as follows: Let
f = a0 + a1x + a2x2 + . . . + anâˆ’1xnâˆ’1 + xn âˆˆFq[x] be the minimal polynomial
of Î± over Fq. Then f is a primitive irreducible polynomial of degree v. With respect
to the Fq-basis (1, Î±, Î±2, . . . , Î±vâˆ’1) of V = Fqv, the transformation matrix of Ïƒ is
given by the companion matrix of f , which is
â›
âœâœâœâœâœâ
0
1
0
. . .
0
0
0
1
. . .
0
...
...
...
...
...
0
0
0
. . .
1
âˆ’a0 âˆ’a1 âˆ’a2 . . . âˆ’avâˆ’1
â
âŸâŸâŸâŸâŸâ 
.
By [49, Sect.7], any two Singer cycle subgroups of GL(V ) are conjugate.
The Galois group Gal(Fqv/Fq) of the ï¬eld extension Fqv/Fq, i.e. the group of all
ï¬eld automorphisms of Fqv element-wise ï¬xing Fq, is known to be cyclic of order v
and generated by the mapping F : x â†’xq. F is called Frobenius automorphism.
It is shown in [49, Satz 7.3] that the normalizer NGL(V )(S) of the Singer cycle
group S = âŸ¨ÏƒâŸ©is given by
NGL(V )(S) = âŸ¨Ïƒ, FâŸ©= Gal(Fqv/Fq) â‹ŠS
and is of order v(qv âˆ’1).
In the following, S(v, q) (and N(v, q)) will denote the conjugacy class of all
(normalizers of) Singer cycle groups in GL(v, q).

226
M. Braun et al.
For a matrix group G â‰¤GL(v, q) we denote with G Ã— n the group
M 0
0 In

| M âˆˆG

,
embedded into GL(v + n, q).
If one looks at the groups which have been used in the computer searches so far,
then this normalizer of a Singer cycle group, subgroups thereof, and embeddings into
higher dimensions are the predominant groups. Is there a reason for â€œthe successâ€ of
the normalizer of a Singer cycle group?
A possible answer can be found when looking to the analog situation for com-
binatorial designs. There, many designs have been found which have a transitive
automorphism group. In fact, a very successful approach is to search for designs
having an automorphism group which is transitive on the t-subsets of the point set. If
this is the case, then the Kramerâ€“Mesner matrix of Sect.4.2 shrinks down to one row
and every collection of columns trivially fulï¬lls the matrix equation of Theorem4
and therefore gives a t-design.
But for subspace designs we face a slightly different situation as for combinatorial
designs. We say that a group G acts t-transitively on a vector space V if the set of
t-subspaces is a single orbit. Now, one might expect to construct a t-(v, k, Î»)q design
by prescribing a t-transitive group for t â‰¥2. Unfortunately, by the following theorem
from [27, Prop. 8.4] this is only possible for the trivial design.
Theorem 5 (Cameron, Kantor) Let G â‰¤PL(v, q) be t-transitive with 2 â‰¤t â‰¤
v âˆ’2. Then G is k-transitive for all 1 â‰¤k â‰¤v âˆ’1.
That is, every group which is at least 2-transitive would shrink down the Kramerâ€“
Mesner matrix not only to one row, but also to one column. But then, the only possible
choices are the trivial designs consisting of all k-subspaces or the empty design.
Nevertheless, when prescribing an automorphism group in the search for subspace
designs, choosing a 1-transitive group seems to be reasonable.
In [81] a list of all 1-transitive subgroups of GL(v, q) is given, based on the work
of [46, 47, 76].
Theorem 6 (Hering, Liebeck, see [81]) If G â‰¤GL(v, q) acts 1-transitively on the
1-subspaces of Fv
q with v â‰¥6, then one of the following holds:
(a) G â‰¤N(v, q),
(b) SL(a, qv/a) âŠ´G,
where a | v, a â‰¤2,
(c) Sp(2a, qv/2a) âŠ´G,
where 2a | v,
(d) G2(qv/6) âŠ´G < Sp(6, qv/6),
where q = 2m and 6 | v,
(e) G âˆ¼= U(3, 3) if q = 2 and v = 6,
(f) G âˆ¼= SL(2, 13) < Sp(6, 3) if q = 3 and v = 6.
Here, Sp(2n, q) denotes the symplectic group Sp(2n, Fq), U(n, q) are the unitary
groups, and G2(2n) are the Chevalley groups.

Computational Methods in Subspace Designs
227
In the special case that v is prime, the possible 1-transitive automorphism groups are
exactly the subgroups of the normalizer of a Singer cycle group.
Corollary 1 If G is a transitive automorphism group of a non-trivial subspace
design (Fv
q, B) with v prime, then G is a subgroup of N(v, q).
4.4
Results
In [16] the ï¬rst q-Steiner system for t â‰¥2, an S(2, 3, 13)2, has been constructed.
Since it was found with the method of Kramer and Mesner, this is a good chance to
demonstrate the power of this approach.
Without using groups the system (3) would have
13
2

2 = 11 180 715 rows and
13
3

2 = 3 269 560 515 columns. A q-Steiner system, i.e. a selection of columns such
that every row is covered exactly once has to consist of precisely
13
2

2/
3
2

2 =
1 597 245 columns. However, ï¬nding a selection of that many columns is by far
out of reach of existing computer algorithms.
Instead, we prescribe the normalizer N(13, 2) of a Singer cycle group as automor-
phism group. Speciï¬cally, in [16] the Singer cycle group S(13, 2) for the polynomial
f (x) = x13 + x12 + x10 + x9 + 1 has been used.
In order to represent a G-invariant design it is sufï¬cient to list G by its genera-
tors and a set of representatives of the selected orbits of G on
V
k

. For a compact
representation we will write all n Ã— m matrices X over Fq with entries xi, j, whose
indices are numbered from 0, as vectors of integers
â¡
â£
mâˆ’1

j=0
x0, jq j, . . . ,
mâˆ’1

j=0
xnâˆ’1, jq j
â¤
â¦.
The order of the normalizer of the Singer cycle groups is #N(13, 2) = 13

213 âˆ’
1

= 106 483. Using compressed notation, one pair of generators is
[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 27] and
[1, 4, 16, 64, 256, 1024, 4096, 54, 216, 864, 3456, 5659, 6234].
The orbits of 2-subspaces and 3-subspaces under the action of N(13, 2) are all
full-length, resulting in a Kramerâ€“Mesner matrix AN(13,2)
2,3
with
13
2

2/106 483 = 105
rows and
13
3

2/106 483 = 30 705 columns. Now, we need to ï¬nd a solution of the
Eq.(8) consisting of
13
2

2/
3
2

2
#N(13, 2) = 15

228
M. Braun et al.
columns of AN(13,2)
2,3
. Luckily, it turns out that this problem is in the reach of contem-
porary computer algorithms and hardware. It can be solved e.g. with the algorithm
dancing links by Knuth [59]. One solution corresponds to the 15 orbit representatives
listed below:
[416, 2048, 4096],
[32, 3072, 4096],
[1344, 512, 4096],
[3440, 1536, 4096], [8, 3328, 4096],
[3284, 3840, 4096],
[3428, 128, 4096],
[617, 2176, 4096], [1038, 3200, 4096],
[1113, 2688, 4096], [1338, 576, 4096], [3389, 2368, 4096],
[317, 2880, 4096],
[1448, 192, 4096], [774, 3232, 4096].
Meanwhile, 1316 mutually disjoint solutions have been determined with the algo-
rithm from Sect.5.1 [23]. Therefore, the union of 1 â‰¤Î» â‰¤1316 of their block sets
gives a 2-(13, 3, Î»)2 design. Together with their supplementary designs and noting
that Î»max = 2047, this implies that all possible design parameters
2-(13, 3, Î»)2,
1 â‰¤Î» â‰¤2047,
are realizable.
Chapter â€œq-Analog of Designs: Subspace Designsâ€ in this book contains tables
of all known subspace designs with small parameters. We conclude this section with
a list of those designs from these table which are constructed by computer and give
the prescribed groups as well as the sizes of the resulting Kramerâ€“Mesner matrices.
The list contains one group which is not a subgroup of N(v, q), namely the
monomial group M(3, 23), see [15].
q = 2:
2-(6, 3, Î»)2: For all designs âŸ¨Ïƒ 7âŸ©was used. Matrix size: 77 Ã— 155.
2-(7, 3, Î»)2: All known 2-(7, 3, Î»)2 designs can be constructed by prescribing
S(7, 2). Matrix size: 3 Ã— 15.
N(7, 2) for Î» = 3, 5, 7, 10, 12, 14. Matrix size: 21 Ã— 93.
2-(8, 3, 21)2: N(4, 22). Matrix size: 15 Ã— 105.
2-(8, 4, Î»)2: N(4, 22) for Î» = 21, 35, 56, 70, 91, 105, 126, 140, 161, 175, 196, 210,
231, 245, 266, 280, 301, 315. Matrix size: 15 Ã— 217.
N(7, 2) Ã— 1 for Î» = 7, 14, 49, 56, 63, 98 105, 112, 147, 154, 161, 196, 203, 210,
245, 252, 259, 294, 301, 308. Matrix size: 13 Ã— 231.
âŸ¨Ïƒ 5, Ï†âŸ©for Î» = 217, 224. Matrix size: 35 Ã— 531.
3-(8, 4, Î»)2: N(4, 22) for Î» = 11, 15. Matrix size: 105 Ã— 217.
N(8, 2): Î» = 11. Matrix size: 53 Ã— 109.
2-(9, 3, Î»)2: N(3, 23) for Î» = 21, 22, 42, 43, 63. Matrix size: 31 Ã— 529.
N(8, 2) Ã— 1 for Î» = 7, 12, 19, 24, 31, 36, 43, 48, 55, 60. Matrix size: 28 Ã— 408.
M(3, 23) for Î» = 49. Matrix size: 40 Ã— 460.
2-(9, 4, Î»)2: N(9, 2). Matrix size: 11 Ã— 725.
2-(v, 3, Î»)2, v = 10, 11, 13: N(v, 2). Matrix sizes: 20 Ã— 633 for v = 10, 31 Ã— 2263
for v = 11, 105 Ã— 30705 for v = 13.

Computational Methods in Subspace Designs
229
q = 3:
2-(6, 3, Î»)3: âŸ¨Ïƒ 13, Ï†âŸ©for Î» = 16. Matrix size: 93 Ã— 234.
S(5, 3) Ã— 1 for Î» = 8, 16, 20. Matrix size: 51 Ã— 150.
âŸ¨Ïƒ 2âŸ©Ã— 1 for Î» = 8, 12, 16, 20. Matrix size: 91 Ã— 280.
2-(v, 3, Î»)3, v = 7, 8: N(v, 3).Matrixsizes:13 Ã— 121forv = 7,41 Ã— 977forv = 8.
q = 4:
2-(6, 3, Î»)4: âŸ¨Ïƒ 3, Ï†âŸ©for Î» = 15, 35. Matrix size: 51 Ã— 161
âŸ¨Ïƒ 3, Ï†âŸ©Ã— 1, designs for Î» = 10, 25, 30, 35. Matrix size: 57 Ã— 229.
q = 5:
2-(6, 3, 78)5: âŸ¨Ïƒ 2, Ï†âŸ©. Matrix size: 53 Ã— 248.
4.5
Non-existence Results
In [16] a list of non-existence results for prominent design parameters is given. Their
results show that q-Steiner systems with the following parameters and automor-
phisms do not exist:
S(2, 3, 7)2, Galois group F(7, 2) (order 7)
S(3, 4, 8)2, Singer subgroup (order 255)
S(2, 4, 10)2, normalizer of Singer subgroup (order 10 230)
S(2, 4, 13)2, normalizer of Singer subgroup (order 106 483)
S(3, 4, 10)2, normalizer of Singer subgroup (order 10 230)
S(2, 3, 7)3, Singer subgroup (order 2 186)
S(2, 3, 7)3, normalizer of Singer subgroup (order 546 868)
This extends upon the previous work on non-existence of q-Steiner systems [34, 63,
92]. For example, it was shown in [92] that there is no Singer-invariant q-Steiner sys-
tem S(2, 3, 7)2.
In [19, 55], a systematic exclusion of automorphisms of an S(2, 3, 7)2 has been
performed. For the question of the existence of such a G-invariant design, the sub-
groups of PL(7, 2) = GL(7, 2) only need to be considered up to conjugacy, see
Eq.(2). The result is that the automorphism group of an S(2, 3, 7)2 q-Steiner system
is either trivial or of order two. In the latter case, group is conjugate to
â›
âœâ
0 1 0 0 0 0 0
1 0 0 0 0 0 0
0 0 0 1 0 0 0
0 0 1 0 0 0 0
0 0 0 0 0 1 0
0 0 0 0 1 0 0
0 0 0 0 0 0 1
â
âŸâ 

.

230
M. Braun et al.
Interestingly, also a 2-(7, 3, 2)2 design is not known yet. For the automorphism
group of a design with these parameters, the authors were able to exclude all sub-
groups of GL(7, 2) except
â€¢ three conjugacy classes of groups of order 2,
â€¢ two conjugacy classes of groups of order 3,
â€¢ two conjugacy classes of groups of order 7.
4.6
Generation of the Kramerâ€“Mesner Matrix
Computing orbit representatives for matrix groups can be very time consuming even
for small parameters. One way to do this is to keep the bases of the subspaces in row
reduced echelon form and the group action is realized as multiplication of matrices
followed by Gauss elimination.
A fast method relying on the subgroup lattice to compute orbit representatives
was developed by [89] for combinatorial designs. This approach was generalized
to subspace designs by [13, 17, 24]. Recently, Koch [62] improved this method
considerably by removing the high memory consumption of the original algorithm.
In case the prescribed group is the Singer cycle group or its normalizer the com-
putation of the Kramerâ€“Mesner matrix can be sped up enormously by considering
vectors in Fv
q as elements of the ï¬nite ï¬eld Fqv. We use this to show how to classify the
subspaces of Fv
q into orbits under the action of Singer cycle group or its normalizer,
see [16, 35].
We ï¬x a primitive element Î± of Fqv, and write a k-subspace X of Fv
q as
X = {0, Î±x1, Î±x2, . . . , Î±xm}, where m = qk âˆ’1 and x1, x2, . . . , xm âˆˆZqvâˆ’1. In other
words, we represent all nonzero vectors in Fv
q by their discrete logarithm with regard
to basis Î±.
For x âˆˆZqvâˆ’1, let Ï(x) be the minimal cyclotomic representative for x, that is
Ï(x) = min{xqi mod (qv âˆ’1) | 0 â‰¤i â‰¤v âˆ’1}. We deï¬ne
invF(X) := {Ï(xi) : 1 â‰¤i â‰¤m},
invS(X) := {xi âˆ’x j : 1 â‰¤i, j â‰¤m with i Ì¸= j},
invN(X) := {Ï(xi âˆ’x j) : 1 â‰¤i, j â‰¤m with i Ì¸= j}.
Lemma 2
1. If two k-subspaces X, Y of Fv
q are in the same orbit under the action
of the Galois group F(v, q) then invF(X) = invF(Y).
2. If two k-subspaces X, Y of Fv
q are in the same orbit under the action of the Singer
cycle group S(v, q) then invS(X) = invS(Y).
3. If two k-subspaces X, Y of Fv
q are in the same orbit under the action of the
normalizer N(v, q) of the Singer cycle group then invN(X) = invN(Y).

Computational Methods in Subspace Designs
231
Proof Let X = {0, Î±x1, Î±x2, . . . , Î±xm} be a k-subspace of Fv
q, with x1, x2, . . . , xm in
Zqvâˆ’1. The action of the generator of S(v, q) on X increases x1, x2, . . . , xm by one
modulo qv âˆ’1, thereby preserving the differences between them.
The action of the Frobenius automorphism Ï† on X multiplies each xi by q modulo
qv âˆ’1, thereby leaving it in the same cyclotomic coset.
âŠ“âŠ”
So, instead of using costly matrix multiplication we can compute the orbit repre-
sentatives with simple arithmetics modulo qv âˆ’1.
In the special situation that qv âˆ’1 is a prime we can speed up the computation of
invN even further. One example is q = 2 and v = 13. Instead of working in the ï¬nite
ï¬eld Zqvâˆ’1 we take once more the discrete logarithms and work modulo qv âˆ’2. By
doing this, the action of the Frobenius automorphism Ï† reduces to an addition by
(qv âˆ’2)/v. Thus, the numbers in invN are considered modulo (qv âˆ’2)/v.
4.7
Isomorphism Problems for Subspace Designs
Whenever subspace designs are constructed, immediately the natural question arises
which of them are isomorphic. The abstract formulation of this problem is the fol-
lowing: Given the action of a group G on a set X, and x, xâ€² âˆˆX, how can we decide
if x âˆ¼xâ€²? In our situation of subspace designs, the group G typically is GL(v, q) or
PGL(v, q) or PL(v, q) etc., and the set X is the power set of
V
k

.
A ï¬rst approach is the computation of invariants. Invariants are functions i :
X â†’Î© with some set Î© which are constant on the orbits, that is, x âˆ¼xâ€² implies
i(x) = i(xâ€²). In the case i(x) Ì¸= i(xâ€²), we know that x â‰xâ€². However, in general an
invariant cannot prove that x âˆ¼xâ€², so we need further methods which we apply in
the case i(x) = i(xâ€²). A good invariant should be reasonably efï¬cient to compute
and not too often evaluate to the same expression if x and xâ€² are from different orbits.
A suitable source of invariants are the intersection numbers of blocks [56].
Sometimes, the following pragmatic approach can be applied: The isomorphism
problem is transformed into a graph theoretic problem and then fed into the software
nauty and its successors by McKay [80] to solve the graph isomorphism problem.
Furthermore, we would like to mention the algorithm of [38] (based on [37], see
also [39]), which is specialized for isomorphism problems on sets of subspaces of a
vector space.
Now we focus on the quite common situation that our designs have been con-
structed by subscribing some subgroup H of G, for example by the method of
Kramerâ€“Mesner. Compared to the above situation, now we have the additional infor-
mation H âŠ†Gx and H âŠ†Gxâ€². To take advantage of this extra knowledge, the theory
of group actions comes in handy. By theoretical arguments, often it is possible to
simplify or even solve the isomorphism problem.
For combinatorial designs, this approach was described by Laue et. al. [44, 71,
72], see also [53]. It involves the normalizers of certain groups. For a group G with
subgroup H, the normalizer of H in G will be denoted by NG(H).

232
M. Braun et al.
Lemma 3 Let G be a group acting on a set X. For any x âˆˆX,
NG(Gx) = {g âˆˆG | Gx = Gxg}.
Proof This is a direct consequence of Eq.(2) Gxg = gâˆ’1Gxg.
âŠ“âŠ”
The above lemma has the following intuitive interpretation: The normalizer of the
stabilizer of x consists of all elements of G which preserve the symmetries of x.
As a consequence, to investigate two elements x, xâ€² with the same stabilizer H for
x âˆ¼xâ€², it is enough to consider the action of the subgroup NG(H) instead of the full
group G. Depending on the group orders, this may be a signiï¬cant reduction of the
computational complexity. Unfortunately, in general this is not directly applicable
in our situation: Typically, we only know that x and xâ€² are H-invariant, but we donâ€™t
know the full stabilizers Gx and Gxâ€², which may well be larger and not identical to
each other.
However, if we are in the comfortable situation that H is a maximal (but proper)
subgroupof G,theninallcasesofinterest, H hastobethefullautomorphismgroupof
H-invariant designs (as otherwise, the full automorphism group would be G, which
acts transitively on
V
k

and therefore only admits trivial solutions). If additionally
H is non-normal in G, then NG(H) = H and hence by Lemma3, any two distinct
H-invariant designs are non-isomorphic (with respect to the action of G). In the
case that the maximal group H is a normal subgroup of G, we have NG(H) = G.
Now by Lemma3 we get that each H-invariant design will appear in exactly [G : H]
isomorphic copies among the set of all H-invariant designs.
Example 5 The q-Steiner system 2-(13, 3, 1)2 has been found by prescribing the
normalizer N = N(13, 2) of a Singer cycle group in GL(13, 2). As N is a non-normal
maximal subgroup of GL(13, 2), any two different solutions of the Kramerâ€“Mesner
system describe non-isomorphic designs. In this way, we know that in fact there are
thousands of non-isomorphic q-Steiner systems 2-(13, 3, 1)2.
If the prescribed group H is a proper subgroup of its normalizer N = NG(H),
this can be exploited algorithmically. For example, if we force one orbit K H to be in
the design, and the solving algorithm shows that there is no solution which contains
this orbit, all K-orbits in (K H)N can be excluded from being part of a solution, i.e.
the corresponding columns of the Kramerâ€“Mesner matrix can be removed.
For algorithmic purposes also the Sylow subgroups of G and H are very valuable.
The following theorem is a slight generalization of [49, Hilfssatz IV 2.5] and [10,
Theorem3.1].
Theorem 7 Let G be a group acting on a set X, x, xâ€² âˆˆX with x âˆ¼xâ€² and P
a common Sylow subgroup of Gx and Gxâ€². Then there exists an n âˆˆNG(P) with
xâ€² = xn.
Proof Let g âˆˆG with xâ€² = xg. From gâˆ’1Pg âŠ†gâˆ’1Gxg = Gxg = Gxâ€², both groups
P and gâˆ’1Pg are Sylow subgroups of Gxâ€². As any two Sylow subgroups of the same
order are conjugate, there is a h âˆˆGxâ€² with

Computational Methods in Subspace Designs
233
P = hâˆ’1(gâˆ’1Pg)h = (gh)âˆ’1P(gh).
Now n = gh âˆˆNG(P) satisï¬es xn = (xg)h = (xâ€²)h = xâ€².
âŠ“âŠ”
By Lemma3, we saw that in the case Gx = Gxâ€², the investigation of x âˆ¼xâ€² may be
done using the action of the subgroup N(Gx) instead of G, which potentially provides
a huge improvement in terms of computational complexity. Now by Theorem7, the
knowledge of a common Sylow subgroup P of Gx and Gxâ€² is enough to provide
a similar simpliï¬cation. In this case, the acting group G may be replaced by the
subgroup NG(P).
Example 6 We illustrate the above theorem with 2-(9, 4, 21)2 designs.
Prescribing N(9, 2) in the Kramerâ€“Mesner method gives many solutions, which
are N(9, 2)-invariant 2-(9, 4, 21)2 designs. We can prove that all these designs are
mutually non-isomorphic without having knowledge of their full automorphism
groups. Let us point out that N(9, 2) is not maximal in GL(9, 2), so the argument of
Example5 doesnâ€™t work in this case.
We have #N(9, 2) = (29 âˆ’1) Â· 9 = 32 Â· 7 Â· 73. Let P be a Sylow-73 subgroup
of N(9, 2). Then #P = 73, and by # GL(9, 2) = 8
i=0(29 âˆ’2i) = 236 Â· 35 Â· 52 Â·
73 Â· 17 Â· 31 Â· 73 Â· 127, P is also a Sylow-73 subgroup of GL(9, 2). Hence, P is
a Sylow-73 subgroup of the full automorphism group of any N(9, 2)-invariant
design. With the above theorem we can conclude that if two N(9, 2)-invariant
designs D1 = (V, B1), D2 = (V, B2) are isomorphic there would be an element
n âˆˆNGL(9,2)(P) with Bn
1 = B2. But NGL(9,2)(P) = N(9, 2) and we know that both
designs are N(9, 2)-invariant. Therefore, D1 and D2 are non-isomorphic.
For the cases where Theorem7 is not applicable, further theoretical results exist,
see [72]. One example is the following theorem.
Theorem 8 Let G â‰¤GL(v, q) and let Î” be the set of G-invariant t-(v, k, Î»)q
designs. Let P be a Sylow p-subgroup of G. Then after removing every design
from Î” that is invariant under any subgroup H such that either
â€¢ G < H < NGL(v,q)(G) or
â€¢ H = âŸ¨G, GnâŸ©for some n âˆˆNGL(v,q)(P) with Gn Ì¸= G
two designs in Î” are isomorphic if and only if some element from NGL(v,q)(G) maps
one onto the other.
5
Constructing â€œLarge Sets of Designsâ€ by Computer
The method of Kramerâ€“Mesner can also be adapted to construct large sets of designs.
This is explained for combinatorial designs in Chee [28]. In fact, the authors describe
three approaches based on the Kramerâ€“Mesner theorem.

234
M. Braun et al.
1. Use t-homogeneous groups, i.e. the Kramerâ€“Mesner matrix shrinks down to
a single row. This is not possible for subspace designs with t â‰¥2 because of
Theorem5.
2. Recursive approach. Construct a design from the Kramerâ€“Mesner matrix, remove
the columns of the matrix which correspond to the design orbits and recurse.
3. Isomorphic designs. Search for uniformly-G large set consisting of N isomorphic
designs.
For the time being, large sets with t â‰¥2 could only be constructed by computer with
the second approach. Sarmiento [88] used an hybrid approach mixing methods 2 and
3 to classify all LS3[155](1, 3, 6) consisting of 155 point-transitive, uniformly-G
1-(6, 3, 1)3 designs.
5.1
Recursive Approach
The following algorithm describes a basic approach to ï¬nd large sets. A version of
this algorithm for large sets of combinatorial designs can be found in [28, 73, 74].
The algorithm computes an LSq[N](t, k, v) large set L consisting of N G-
invariant t-(v, k, Î»)q designs. Either the algorithm terminates with a large set or
it ends without any statement about the existence.
Algorithm 3
1. [Initialize.] Set Î© as the complete set of G-orbits on
V
k

and set
L := âˆ….
2. [Solve.] Find a random t-(v, k, Î»)q design D = (V, B)) consisting of orbits of
Î©. If such a t-design exists insert D into L and continue with 3. Otherwise
terminate without a large set.
3. [Remove.] Remove the selected orbits in B from Î©. If Î© = âˆ…then terminate
with a large set L . Otherwise go to 2.
The described algorithm can be implemented by a slight modiï¬cation of the Kramerâ€“
Mesner approach. We just have to add a further row to the Diophantine system of
Eq.(8) in the following way:
â›
âœâœâ
AG
t,k
Â· Â· Â· y Â· Â· Â·
â
âŸâŸâ Â· x =
â›
âœâœâœâ
Î»
...
Î»
0
â
âŸâŸâŸâ 
The vector y is indexed by the G-orbits on
V
k

corresponding to the columns of AG
t,k.
The entry indexed by the G-orbit containing K is deï¬ned to be one if the orbit of K
has already been covered by a selected t-(v, k, Î»)q design. Otherwise it is zero. In
every iteration step the vector y has to be updated.

Computational Methods in Subspace Designs
235
Remark 4 Another approach is to compute all 0/1-vectors which are solutions of the
Kramerâ€“Mesner system (8) for a given group G. Every solution vector corresponds
to a design.
In a second step we try to ï¬nd a subset of N disjoint solution vectors. This is again
an exact cover problem.
5.2
Large Sets from Isomorphic Designs
This approach is described in detail in [28] for combinatorial designs. The task will be
to search for a uniformly-G large set LSq[N](t, k, v), where G â‰¤H â‰¤PL(v, q).
Moreover, the designs of the large set will not only be G-invariant, but also mutually
isomorphic.
Let nG
k and nH
k be the number of orbits of G and H acting on
V
k

and ï¬x some
order K G
j , 1 â‰¤j â‰¤nG
k , and K H
i , 1 â‰¤i â‰¤nH
k , on the G-orbits and H-orbits acting
on
V
k

.
The fusion matrix F G,H
k
= ( fi, j) is the nH
k Ã— nG
k matrix deï¬ned by
fi, j =

1,
if K G
j âŠ†K H
i ;
0,
else.
We want to ï¬nd a large set consisting of designs D1, D2, . . . , DN such that each
design Di is G-invariant. Suppose further that we want an isomorphism g âˆˆPL(V )
of order N such that
D gi
1 = Di,
0 â‰¤i < N.
Let H = âŸ¨G, ÏƒâŸ©. Then, an orbit of H on k-subspaces is the union of (disjoint) G-
orbits on k-subspaces.
As a consequence, if we are able to ï¬nd a design (V, B1) that contains exactly one
G-orbit from every H-orbit, then {Bgi
1 | 0 â‰¤i < N} gives rise to disjoint designs,
i.e. a large set of designs. This can be summarized in the following theorem.
Theorem 9 (Chee [28]) Suppose that Ïƒ âˆˆPL(V ) with ord(Ïƒ) = N and G â‰¤
PL(V ). Let H = âŸ¨G, ÏƒâŸ©.
There exists a uniformly-G large set LSq[N](t, k, v) if there is a 0/1-vector x
satisfying
 AG
t,k
F G,H
k

Â· x =
â›
âœâœâœâœâœâœâœâœâ
Î»
...
Î»
1
...
1
â
âŸâŸâŸâŸâŸâŸâŸâŸâ 
.

236
M. Braun et al.
6
Solving Algorithms
Solving Eq.(8) is a special instance of the multi-dimensional subset sum problem
which is known to be NP-complete [41]. Since problem (8) can be reduced to many
other NP-hard problems it is no surprise that there are many solving algorithms
available. In this section we will give an overview of the so far most promising
strategies to ï¬nd subspace designs. For a survey, see also [42, 53, 78].
6.1
Backtracking
The problem (8) for Î» = 1 is known as the exact cover problem. A common approach
to ï¬nd all solution of an exact cover problem is to systematically test all combinations
of block orbits. Walker [93] was the ï¬rst to call such an approach back-track.
A backtracking algorithm for solving the system (8) for Î» = 1 and Kramerâ€“
Mesner matrix A = (ai, j) is quite simple and straight forward to describe:
Algorithm 4 Choose columns of A to ï¬nd a solution of (8) for Î» = 1.
1. If A has no columns, the problem is solved; terminate successfully.
2. Otherwise choose a row r with the least number of nonzero entries.
3. for each column c such that ar,c = 1:
include c in the partial solution
for each i such that ai,c = 1
delete row i from the matrix A;
for each j such that ai, j = 1,
delete column j from the matrix A.
4. Repeat this algorithm recursively on the reduced matrix A.
In [58] the strategy of Step 2 to choose those rows ï¬rst which have the least number
of nonzero entries is justiï¬ed. If the goal is to ï¬nd all solutions then the order in
which the columns in Step 3 taken is irrelevant. This may be different if one wants
to ï¬nd one solution at all.
The speed of this algorithm is largely determined by the choice of the data struc-
tures. In [59] Knuth uses doubly linked lists, all the navigation through the matrix is
done via pointers. By a trick due to Hitotumatu and Noshita [48], the use of pointers
enables a very fast recovering of the original data after stepping back from recursion.
The algorithm is called dancing links.
In [95] a parallel version of dancing links is described. [55] uses a brute force
parallelization which is better suited for batch system on computing clusters.
For problem instances with Î» > 1 the situation changes. The dancing links algo-
rithm can be adapted to this case. The library libexact [54] contains an imple-
mentation, see also [79].

Computational Methods in Subspace Designs
237
6.2
Maximum Clique Algorithms
A weighted graph G = (V, E) is a set of vertices V together with a set of edges
E which are 2-element subsets of V . Additionally, every vertex carries a (nonzero)
weight, i.e. there is a mapping wgt : V â†’Zâ‰¥0.
A clique of a graph G is a set of vertices C âŠ‚V such that {v, w} âˆˆE for all
v, w âˆˆC, v Ì¸= w.
The following decision problem is NP-complete: Given a weighted graph G and
an integer k, is there a clique in G with weight at least k? Although no polynomial-
time algorithm is known for the maximum weight clique problem, various algorithms
have been developed as these have many important applications. cliquer [85] is
one freely available software package that solves instances of the maximum weight
clique problem.
For Î» = 1 problem (8) can be formulated as maximum weight clique problem.
The vertices of the graph are the block orbits. Their weights are given by the orbit
lengths. Two orbits share an edge if and only if they cover disjoint sets of t-subspaces.
This approach is promising if the cardinality of a maximum clique can be expected
to be reasonably small. The advantage of the method is that it can tackle instances
with very many block orbits.
If one is interested in improving the known bounds for packing designs, i.e. con-
stant dimension subspace codes, then it is sometimes good enough to ï¬nd approxi-
mate solutions of the maximum clique problem. In such a situation one may resort
to stochastic methods.
Stochasticalgorithmsforï¬ndingcliqueshavebeenthoroughlystudied,butmostof
the studies consider unweighted graphs. For some recent results, see [87]. Typically,
a stochastic algorithm proceeds by adding and removing single vertices in a speciï¬c
manner, when building up a large clique.
Lower bounds for constant dimension subspace codes could be improved by such
a stochastic algorithm in [21].
For the time being, no q-Steiner systems could be found by this approach. In [35]
it is reported that with a weighted clique approach 14 of the necessary 15 orbits could
be packed together in the search for 2-(13, 3, 1)2 design.
6.3
Lattice Point Enumeration
When one attempts to solve systems of type (8) for large values of Î» a detour via
lattices proves to be worthwhile.
Suppose that b1, b2, â€¦, bn âˆˆQm. The integer span of these vectors, i.e.
L = {
n

i=1
uibi | ui âˆˆZ}

238
M. Braun et al.
is called lattice. Given a lattice, central problems are to ï¬nd shortest nonzero lattice
vectors with regard to various norms âˆ¥.âˆ¥and to ï¬nd a basis of L consisting of short
vectors with regard to âˆ¥.âˆ¥2. We will not dive further into this subject and not give a
precise deï¬nition what a â€œbasis of short vectorsâ€ exactly is. The reader is referred to
[84] for an extensive overview.
In 1982, Lenstra, Lenstra and LovÃ¡sz [75] gave a celebrated methodâ€”LLL algo-
rithmâ€”which produces approximate solutions to both problems in polynomial time.
The LLL algorithm does lattice basis reduction â€“ it takes a lattice basis as input
and outputs a reduced basis of the lattice, hopefully consisting of short vectors. The
amazing power of the LLL algorithm is that it performs much better than the the-
oretical analysis predicts and in many practical cases the output bases are already
solutions of the above problems.
The ï¬rst ones to use lattice basis reduction for the search of combinatorial designs
were Kreher and Radziszowski [66, 67]. They used the original LLL algorithm as
proposed in [75] and the formulation of problem (8) as lattice problem from Lagarias
and Odlyzko [69].
Since then, this approach could be improved in many aspects. With improved
variants of the LLL algorithm much smaller basis vectors can be achieved, see [84].
In [94] an improved lattice formulation of problem (8) is given. For this lattice, a
solution of (8) corresponds to a shortest nonzero lattice vector in âˆ¥.âˆ¥âˆnorm. This
was generalized in [96] to non-simple designs.
Further, the lattice basis reduction algorithms behave somewhat random. But [90]
proposes a method to ï¬nd a shortest vector for the Euclidean norm from an LLL
reduced lattice basis by exhaustive enumeration. This was generalized by [51] to
arbitrary norms.
Combining these improvements many combinatorial designs for t = 6, 7, 8, 9
were found [4, 5, 7â€“12, 70, 71, 94]. The algorithm is used in a software system called
DISCRETA [6] which allows the user to easily prescribe automorphism groups and
try to solve the corresponding Kramerâ€“Mesner system of equations.
The algorithm was also the method of choice to construct subspace designs in
many publications, see [13, 14, 17â€“20, 24] for an incomplete list.
Let A be an l Ã— s Kramerâ€“Mesner matrix from (8). The corresponding lattice
proposed in [94] is generated by the linearly independent columns of the matrix
L =
â›
âœâœâœâœâœâœâœâœâœâœâœâ
c Â· Î»
c Â· A
...
c Â· Î»
2
0
1
...
...
0
2
1
0 . . . 0
1
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
,
(9)

Computational Methods in Subspace Designs
239
consisting of s + 1 column vectors with l + s + 1 rows. The constant c is chosen
large enough such that the output of the lattice basis reduction looks like
 0 âˆ—
B âˆ—

and B has size (s + 1) Ã— (s + 1 âˆ’rk(A)).
In the second phase of the algorithm we search with the enumeration algorithm
from [51] for all nonzero lattice vectors b of the lattice spanned by the columns of
B such that âˆ¥bâˆ¥âˆ= 1. The integer vectors b = (b1, . . . , bs, bs+1)âŠ¤of the lattice
spanned by the columns of B fulï¬ll the equation
A Â·
â›
âœâ
(b1 âˆ’bs+1)/2
...
(bs âˆ’bs+1)/2
â
âŸâ = âˆ’bs+1
â›
âœâ
Î»
...
Î»
â
âŸâ .
The condition âˆ¥bâˆ¥âˆ= 1 ensures that bs+1 = Â±1 and that bs+1 Â· (bi âˆ’bs+1)/2 âˆˆ
{0, 1} for 1 â‰¤i â‰¤s.
The big advantage of this method is that the size of Î» has not much inï¬‚uence on
the runtime. This is in strong contrast with the backtracking approach above which
is best for Î» = 1.
The height of the search tree in the second phase is determined by the number of
columns of B, i.e. it is roughly the difference between the number of unknowns and
the number of equations. As a consequence, having many equations is good for the
runtime of the algorithm and the number of orbits which have to be selected has not
much inï¬‚uence on the runtime.
The disadvantage of this lattice based approach is that the lattice basis reduction
in the ï¬rst phaseâ€”albeit having polynomial runtimeâ€”takes prohibitively long time
for systems when the number of unknowns exceeds 3 000 (as a rule of thumb).
6.4
Counting Algorithms
If the design parameters are small enough it may be easy to ï¬nd one solution and one
is tempted to try to count all designs having automorphisms. Schmalz [89] developed
a graph theoretical approach to enumerate all solutions of (8) implicitly.
A similar approach is known in computer science as binary decision diagrams
and related data structures, see [60]. In [61, Exercise 50] Knuth describes a binary
method to count all solutions.

240
M. Braun et al.
6.5
Integer Linear Programming
The system of Eq.(8) can be regarded as integer linear programming problem. One
possible formulation is
max

i
xi
such that
AG
t,k Â· x =
â›
âœâ
Î»
...
Î»
â
âŸâ ,
xi âˆˆ{0, 1}.
There are a many software systems available to solve integer linear programming
problems. Among the most powerful and popular are CPLEX [50] and Gurobi [43].
It seems that for problems of type (8) integer linear programming algorithms are
still inferior to lattice basis reduction algorithms. But often the linear programming
partâ€”i.e. using the relaxation xi âˆˆ[0, 1] âŠ‚Râ€”of these solvers is sufï¬cient to show
nonexistence of solutions.
Moreover, these solving algorithms show their power when it comes to ï¬nd pack-
ing designs, i.e. replacing â€œ=â€ by â€œâ‰¤â€. The online tables for the best bounds on
subspace codes1 contain many example where lower bounds were constructed by
using integer linear programming, compare [45, 63].
6.6
Other Algorithms
Asalreadymentioned,sinceproblem (8)isanNP-completeproblemitcanbereduced
to other NP-hard problems. Recently, randomized algorithms were successful for
related packing problems, e.g. [22, 97]. Other randomized algorithms are simulated
annealing, tabu search, hill climbing, see [42]. But also constraint logic algorithms
and SAT algorithms are candidates to be tried out.
References
1. W.O. Alltop, On the construction of block designs. J. Comb. Theory 1, 501â€“502 (1966)
2. C. Berge, D. Ray-Chaudhuri, in Unsolved problems, ed. by C. Berge, D. Ray-Chaudhuri.
Hypergraph Seminar: Ohio State University 1972, in Lecture Notes in Mathematics, vol. 411
(Springer, Berlin, 1974), pp. 278â€“287. https://doi.org/10.1007/BFb0066199
1http://subspacecodes.uni-bayreuth.de.

Computational Methods in Subspace Designs
241
3. T. Beth, D. Jungnickel, H. Lenz, Design Theory, vol. 1, 2, 2nd edn. (Cambridge University
Press, London, 1999)
4. A. Betten, A. Kerber, A. Kohnert, R. Laue, A. Wassermann, The discovery of simple 7-designs
with automorphism group PL(2,32), in AAECC 11, Lecture Notes in Computer Science, vol.
948 (Springer, Heidelberg, 1995), pp. 131â€“145
5. A. Betten, A. Kerber, R. Laue, A. Wassermann, Simple 8-designs with small parameters. Des.
Codes Cryptogr. 15(1), 5â€“27 (1998). https://doi.org/10.1023/A:1008263724078
6. A. Betten, R. Laue, A. Wassermann, DISCRETA â€“ A tool for constructing t-designs. Lehrstuhl
II fÃ¼r Mathematik, UniversitÃ¤t Bayreuth, http://www.mathe2.uni-bayreuth.de/discreta/
7. A. Betten, R. Laue, A. Wassermann, Simple 6 and 7-designs on 19 to 33 points. Congr. Numer.
123, 149â€“160 (1997)
8. A. Betten, R. Laue, A. Wassermann, Some simple 7-designs, eds. by. J.W.P. Hirschfeld, S.S.
Magliveras, M.J. de Resmini Geometry, Combinatorial Designs and Related Structures, Pro-
ceedings of the First Pythagorean Conference, London Mathematical Society Lecture Notes,
vol. 245, pp. 15â€“25 (1997)
9. A. Betten, R. Laue, A. Wassermann, New t-designs and large sets of t-designs. Discret. Math.
197/198, 83â€“109 (1999). Also appeared in the special volume Discrete Mathematics, Editorâ€™s
Choice, Edition 1999
10. A. Betten, R. Laue, A. Wassermann, Simple 7-designs with small parameters. J. Comb. Des.
7, 79â€“94 (1999)
11. A. Betten, R. Laue, A. Wassermann, Simple 8-(40, 11, 1440) designs. Discret. Appl. Math.
95, 109â€“114 (1999)
12. A. Betten, R. Laue, A. Wassermann, A Steiner 5-design on 36 points. Des. Codes Cryptogr.
17, 181â€“186 (1999)
13. M. Braun, Konstruktion diskreter Strukturen unter Verwendung von Operationen linearer Grup-
pen auf dem linearen Verband, Ph.D. thesis, University of Bayreuth, Germany (2004)
14. M. Braun, Some new designs over ï¬nite ï¬elds. Bayreuth. Math. Schr. 74, 58â€“68 (2005)
15. M. Braun, Designs over the binary ï¬eld from the complete monomial group. Australas. J.
Comb. 67(3), 470â€“475 (2017)
16. M. Braun, T. Etzion, P.R.J. Ã–stergÃ¥rd, A. Vardy, A. Wassermann, Existence of q-analogs of
steiner systems. Forum Math. Pi 4(e7), 14 (2016). https://doi.org/10.1017/fmp.2016.5
17. M. Braun, A. Kerber, R. Laue, Systematic construction of q-analogs of t-(v, k, Î»)-designs.
Des. Codes Cryptogr. 34(1), 55â€“70 (2005). https://doi.org/10.1007/s10623-003-4194-z
18. M. Braun, M. Kiermaier, A. Kohnert, R. Laue, Large sets of subspace designs. J. Comb. Theory
Ser. A 147, 155â€“185 (2017). https://doi.org/10.1016/j.jcta.2016.11.004
19. M. Braun, M. Kiermaier, A. NakiÂ´c, On the automorphism group of a binary q-analog of the
fano plane. Eur. J. Comb. 51, 443â€“457 (2016). https://doi.org/10.1016/j.ejc.2015.07.014
20. M. Braun, A. Kohnert, P.R.J. Ã–stergÃ¥rd, A. Wassermann, Large sets of t-designs over ï¬nite
ï¬elds. J. Comb. Theory Ser. A 124, 195â€“202 (2014). https://doi.org/10.1016/j.jcta.2014.01.
008
21. M. Braun, P.R.J. Ã–stergÃ¥rd, A. Wassermann, New lower bounds for binary constant-dimension
subspace codes. Exp. Math. 1â€“5 (2016). https://doi.org/10.1080/10586458.2016.1239145
22. M. Braun, J. Reichelt, q-analogs of packing designs. J. Comb. Des. 22(7), 306â€“321 (2014).
https://doi.org/10.1002/jcd.21376
23. M. Braun, A. Wassermann, Disjoint q-Steiner systems in dimension 13 UniversitÃ¤t Bayreuth,
Bayreuth, Technical Report (2017)
24. S. Braun, Algorithmen zur computerunterstÃ¼tzten Berechnung von q-Analoga kombina-
torischer Designs. Diplomathesis UniversitÃ¤t Bayreuth (2009)
25. P.J. Cameron, Generalisation of Fisherâ€™s inequality to ï¬elds with more than one element. eds.
by T.P. McDonough, V.C. Mavron. Combinatorics - Proceedings of the British Combinatorial
Conference 1973, London Mathematical Society Lecture Note Series, vol. 13 (Cambridge
University Press, Cambridge, 1974), pp. 9â€“13. https://doi.org/10.1017/CBO9780511662072.
003
26. P.J. Cameron, Locally symmetric designs. Geom. Dedicata 3, 65â€“76 (1974)

242
M. Braun et al.
27. P.J. Cameron, W.M. Kantor, 2-transitive and antiï¬‚ag transitive collineation groups of
ï¬nite projective spaces. J. Algebra 60(2), 384â€“422 (1979). https://doi.org/10.1016/0021-
8693(79)90090-5
28. Y.M. Chee, C.J. Colbourn, S.C. Furino, D.L. Kreher, Large sets of disjoint t-designs. Australas.
J. Comb. 2, 111â€“119 (1990)
29. C.J. Colbourn, J.H. Dinitz, in Handbook of Combinatorial Designs, 2nd edn, Discrete Mathe-
matics and Its Applications. (Chapman and Hall/CRC , 2006)
30. M. De Boeck, A. NakiÂ´c, Necessary conditions for the existence of 3-designs over ï¬nite ï¬elds
with nontrivial automorphism groups. ArXiv e-prints arXiv:1509.09158 (2015)
31. P. Delsarte, Association schemes and t-designs in regular semilattices. J. Comb. Theory Ser.
A 20(2), 230â€“243 (1976). https://doi.org/10.1016/0097-3165(76)90017-0
32. P. Dembowski, Verallgemeinerungen von TransitivitÃ¤tsklassen endlicher projektiver Ebenen.
Math. Z. 69, 59â€“89 (1958)
33. P. Dembowski, Finite Geometries: Reprint of the 1968 Edition. (Springer, 2012)
34. T. Etzion, A. Vardy, On q-analogs of Steiner systems and covering designs. Adv. Math. Com-
mun. 5(2), 161â€“176 (2011). https://doi.org/10.3934/amc.2011.5.161
35. T. Etzion, A. Vardy, Automorphisms of codes in the Grassmann scheme. ArXiv e-prints
arXiv:1210.5724 (2012)
36. A. Fazeli, S. Lovett, A. Vardy, Nontrivial t-designs over ï¬nite ï¬elds exist for all t. J. Comb.
Theory Ser. A 127, 149â€“160 (2014)
37. T. Feulner, The automorphism groups of linear codes and canonical representatives of their
semilinear isometry classes. Adv. Math. Commun. 3(4), 363â€“383 (2009). https://doi.org/10.
3934/amc.2009.3.363
38. T. Feulner, Canonical forms and automorphisms in the projective space (2013)
39. T. Feulner, Eine kanonische Form zur Darstellung Ã¤quivalenter Codes â€“ ComputergestÃ¼tzte
Berechnung und ihre Anwendung in der Codierungstheorie, Kryptographie und Geometrie.
Ph.D. thesis, UniversitÃ¤t Bayreuth (2013)
40. P. Frankl, V. RÃ¶dl, Near perfect coverings in graphs and hypergraphs. Eur. J. Comb. 6(4),
317â€“326 (1985)
41. M.R. Garey, D.S. Johnson, Computers and Intractability: A Guide to the Theory of NP-
Completeness (W.H Freeman and Company, New York, 1979)
42. P.B Gibbons, P.R.J Ã–stergÃ¥rd, in Computational methods in design theory,eds. by C.J. Col-
bourn, J.H. Dinitz. Handbook of Combinatorial Designs, 2 edn., chap. VII.6, (Chapman and
Hall/CRC, 2007), pp. 755â€“783
43. I. Gurobi Optimization, Gurobi optimizer reference manual (2016), http://www.gurobi.com
44. E. Haberberger, A. Betten, R. Laue, Isomorphism classiï¬cation of t-designs with group theo-
retical localisation techniques applied to some Steiner quadruple systems on 20 points. Congr.
Numer. 75â€“96 (2000)
45. D. Heinlein, M. Kiermaier, S. Kurz, A. Wassermann, Tables of subspace codes. ArXiv e-prints
arXiv:1601.02864 (2016)
46. C. Hering, Transitive linear groups and linear groups which contain irreducible subgroups of
prime order. Geom. Dedic. 2(4), 425â€“460 (1974). https://doi.org/10.1007/BF00147570
47. C. Hering, Transitive linear groups and linear groups which contain irreducible sub-
groups of prime order. II. J. Algebra 93(1), 151â€“164 (1985). https://doi.org/10.1016/0021-
8693(85)90179-6
48. H. Hitotumatu, K. Noshita, A technique for implementing backtrack algorithms and its applica-
tion. Inf. Process. Lett. 8(4), 174â€“175 (1979). https://doi.org/10.1016/0020-0190(79)90016-
4
49. B. Huppert, Endliche Gruppen I, in Grundlehren der mathematischen Wissenschaften, vol. 134
(Springer, Heidelberg, 1967)
50. IBM:
ILOG
CPLEX
Optimizer
(2010),
http://www-01.ibm.com/software/integration/
optimization/cplex-optimizer/
51. M. Kaib, H. Ritter, Block reduction for arbitrary norms UniversitÃ¤t Frankfurt, Preprint (1995)

Computational Methods in Subspace Designs
243
52. R.M. Karp, Reducibility among combinatorial problems, eds. by R.E. Miller, J.W. Thatcher,
J.D. Bohlinger. Complexity of Computer Computations: Proceedings of a symposium on the
Complexity of Computer Computations, March 20â€“22, 1972, (Springer, Boston, 1972), pp.
85â€“103. https://doi.org/10.1007/978-1-4684-2001-2_9
53. P. Kaski, P.R. Ã–stergÃ¥rd, Classiï¬cation Algorithms for Codes and Designs (Springer, Berlin,
2006). https://doi.org/10.1007/3-540-28991-7
54. P. Kaski, O. Pottonen, libexact userâ€™s guide version 1.0. Technical Report 2008-1, Helsinki
University of Technology (2008)
55. M. Kiermaier, S. Kurz, A. Wassermann, The order of the automorphism group of a binary
q-analog of the fano plane is at most two. Designs, Codes and Cryptography (2017). To appear
https://doi.org/10.1007/s10623-017-0360-6
56. M. Kiermaier, M.O. PavË‡ceviÂ´c, Intersection numbers for subspace designs. J. Comb. Des. 23(11),
463â€“480 (2015). https://doi.org/10.1002/jcd.21403
57. Klin, M.H.: Investigations of algebras of invariant relations of certain classes of permutation
groups. Ph.D. thesis, Nikolaev (1974). In russian
58. D.E. Knuth, Estimating the efï¬ciency of backtrack programs. Math. Comp. 29(129), 121â€“136
(1975)
59. D.E Knuth, Dancing links, eds. by A.W. Roscoe, J. Davies, J. Woodcock. Millennial perspec-
tives in computer science, Cornerstones of computing, (Palgrave, 2000), pp. 187â€“214
60. D.E. Knuth, The art of computer programming, vol. 4A (Addison-Wesley, New Jersey, 2011)
61. D.E Knuth, Dancing links. Technical Report Fasc 5c, Stanford University (2017)
62. M. Koch, Neue Strategien zur LÃ¶sung von Isomorphieproblemen. Ph.D. thesis, University of
Bayreuth, Germany (2016)
63. A. Kohnert, S. Kurz, Construction of large constant dimension codes with a prescribed min-
imum distance, eds. by J. Calmet, W. Geiselmann, J. MÃ¼ller-Quade. Mathematical Methods
in Computer Science: Essays in Memory of Thomas Beth, (Springer, Heidelberg, 2008), pp.
31â€“42. https://doi.org/10.1007/978-3-540-89994-5_4
64. R. KÃ¶tter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory 54(8), 3579â€“3591 (2008). https://doi.org/10.1109/TIT.2008.926449
65. E.S. Kramer, D.M. Mesner, t-designs on hypergraphs. Discret. Math. 15(3), 263â€“296 (1976).
https://doi.org/10.1016/0012-365X(76)90030-3
66. D.L. Kreher, S.P. Radziszowski, The existence of simple 6-(14, 7, 4) designs. J. Comb. Theory
Ser. A 43, 237â€“243 (1986)
67. D.L. Kreher, S.P. Radziszowski, Constructing 6-(14,7,4) designs. Contemp. Math. 111, 137â€“
151 (1990)
68. V. KrË‡cadinac, A. NakiÂ´c, M.O. PavË‡ceviÂ´c, The Kramerâ€“Mesner method with tactical decompo-
sitions: some new unitals on 65 points. J. Comb. Des. 19(4), 290â€“303 (2011). https://doi.org/
10.1002/jcd.20277
69. J.C. Lagarias, A.M. Odlyzko, Solving low-density subset sum problems. J. Assoc. Comp.
Mach. 32, 229â€“246 (1985). Appeared already in Proc. 24th IEEE Symp. Found. Comp. Sci.
(1983), 1â€“10
70. R. Laue, Halvings on small point sets. J. Comb. Des. 7, 233â€“241 (1999)
71. R. Laue, Constructing objects up to isomorphism, simple 9-designs with small parameters, in
Algebraic Combinatorics and Applications, (Springer, New York, 2001), pp. 232â€“260
72. R. Laue, Solving isomorphism problems for t-designs, ed by W.D. Wallis. Designs 2002:
Further Computational and Constructive Design Theory (Springer US, Boston, MA , 2003),
pp. 277â€“300. https://doi.org/10.1007/978-1-4613-0245-2_11
73. R. Laue, S. Magliveras, A. Wassermann, New large sets of t-designs. J. Comb. Des. 9, 40â€“59
(2001)
74. R. Laue, G.R. Omidi, B. Tayfeh-Rezaie, A. Wassermann, New large sets of t-designs with
prescribed groups of automorphisms. J. Comb. Des. 15(3), 210â€“220 (2007). https://doi.org/10.
1002/jcd.20128
75. A.K. Lenstra, H.W. Lenstra Jr., L. LovÃ¡sz, Factoring polynomials with rational coefï¬cients.
Math. Ann. 261, 515â€“534 (1982)

244
M. Braun et al.
76. M.W. Liebeck, The afï¬ne permutation groups of rank three. Proc. Lond. Math. Soc. (3) 54(3),
477â€“516 (1987). https://doi.org/10.1112/plms/s3-54.3.477
77. S.S Magliveras, The subgroup structure of the Higman-Sims simple group. Ph.D. thesis, Uni-
versity of Birmingham (1970)
78. R. Mathon, Computational methods in design theory, ed. by A.D. Keedwell. Surveys in combi-
natorics, Proceeding 13th Br. Combinatorial Conference, London Mathematical Society Lec-
ture Notes, vol. 166 (Guildford/UK, 1991), pp. 101â€“117
79. R. Mathon, Searching for spreads and packings, eds by J.W.P. Hirschfeld, S.S. Magliveras, M.J.
de Resmini. Geometry, Combinatorial Designs and Related Structures, Proceedings of the ï¬rst
Pythagorean conference, Mathematical Society Lecture Notes, vol. 245, (London, 1997), pp.
161â€“176
80. B.D.McKay,A.Piperno,Practicalgraphisomorphism,II.J.Symb.Comput. 60,94â€“112(2014).
https://doi.org/10.1016/j.jsc.2013.09.003
81. M. Miyakawa, A. Munemasa, S. Yoshiara, On a class of small 2-designs over GF(q). J. Comb.
Des. 3(1), 61â€“77 (1995). https://doi.org/10.1002/jcd.3180030108
82. E.H. Moore, Tactical memoranda i-iii. Am. J. Math. 18(4), 264â€“303 (1896)
83. A. NakiÂ´c, M.O. PavË‡ceviÂ´c, Tactical decompositions of designs over ï¬nite ï¬elds. Des. Codes
Cryptogr. 77(1), 49â€“60 (2015). https://doi.org/10.1007/s10623-014-9988-7
84. P.Q Nguyen, B. VallÃ©e, in The LLL Algorithm: Survey and Applications, 1st edn. Information
Security and Cryptography. (Springer, Heidelberg, 2009). https://doi.org/10.1007/978-3-642-
02295-1
85. S. Niskanen, P.R.J Ã–stergÃ¥rd, Cliquer userâ€™s guide, version 1.0. Technical Report T48, Helsinki
University of Technology (2003)
86. E.T. Parker, On collineations of symmetric designs. Proc. Am. Math. Soc. 8(2), 350â€“351 (1957).
http://www.jstor.org/stable/2033742
87. W. Pullan, Optimisation of unweighted/weighted maximum independent sets and minimum
vertex covers. Discret. Optim. 6(2), 214â€“219 (2009). https://doi.org/10.1016/j.disopt.2008.12.
001
88. J.F. Sarmiento, Resolutions of PG(5, 2) with point-cyclic automorphism group. J.
Comb. Designs 8(1), 2â€“14 (2000). https://doi.org/10.1002/(SICI)1520-6610(2000)8:1<2::
AID-JCD2>3.0.CO;2-H
89. B. Schmalz, t-Designs zu vorgegebener automorphismengruppe. Bayreuth. Math. Schr 41,
1â€“164 (1992). Ph.D thesis, UniversitÃ¤t Bayreuth
90. C.P Schnorr, M. Euchner, Lattice basis reduction: Improved practical algorithms and solving
subset sum problems, in Proceedings of Fundamentals of Computation Theory â€™91, Lecture
Notes in Computer Science, vol. 529, (Springer, Heidelberg, 1991), pp. 68â€“85
91. H. Suzuki, On the inequalities of t-designs over a ï¬nite ï¬eld. Euro. J. Comb. 11(6), 601â€“607
(1990). https://doi.org/10.1016/S0195-6698(13)80045-5
92. S. Thomas, Designs over ï¬nite ï¬elds. Geom. Dedic. 24(2), 237â€“242 (1987). https://doi.org/
10.1007/BF00150939
93. R.J. Walker, An enumerative technique for a class of combinatorial problems. Proc. Sympos.
Appl. Math. 10, 91â€“94 (1960). American Mathematical Society, Providence, R.I. (1960)
94. A.Wassermann,Findingsimplet-designswithenumerationtechniques.J.Comb.Des.6(2),79â€“
90 (1998). https://doi.org/10.1002/(SICI)1520-6610(1998)6:2<79::AID-JCD1>3.0.CO;2-S
95. A. Wassermann, Covering the Aztec diamond with one-sided tetrasticks. Bull.Inst. Comb. Appl.
(ICA) 32, 70â€“76 (2001)
96. A. Wassermann, Attacking the market split problem with lattice point enumeration. J. Comb.
Optim. 6(1), 5â€“16 (2002)
97. J. Zwanzger, A heuristic algorithm for the construction of good linear codes. IEEE Trans. Inf.
Theory 54(5), 2388â€“2392 (2008). https://doi.org/10.1109/TIT.2008.920323

Part III
Application of Network Coding

Index Coding, Network Coding
and Broadcast with Side-Information
Eimear Byrne and Marco Calderini
Abstract Index coding, the problem of efï¬cient broadcast to many receivers with
side-infomation, is a rich and active research area. It has applications to a range of
multi-user broadcast scenarios such as video-on-demand and satellite communica-
tions. It has attracted signiï¬cant theoretical interest both as a hard problem in its
own right and due to its connections to other network capacity problems. The central
problem of index coding, that of determining the optimal rate of an index code, is
still open. We describe recent advances on the index coding problem and its general-
izations in the context of broadcast with side-information. The two main approaches
to bounding the optimal rate of an index code, namely rank-minimization methods
and linear programming models, are discussed in detail. The latter of these, based on
graph-theoretical ideas in the classical case, can be extended even to generalizations
of the index coding problem for which there is no associated side-information hyper-
graph. We discuss error-correction in the index coding problem, the corresponding
bounds on the optimal transmission rate and decoding algorithms. We also illustrate
the connections to network coding, interference alignment and coded caching.
1
Introduction
Broadcast with side-information describes a number of problems in network informa-
tion theory, including index coding, network coding, coded caching and interference
alignment. The equivalences and connections between these different topics has been
observed in the literature [18, 19, 27, 28]. The problem has several applications, such
as for satellite communications, distribution of media ï¬les (eg. video-on-demand),
topological interference alignment and distributed caching.
E. Byrne (B)
School of Mathematics and Statistics, University College Dublin, Dublin, Ireland
e-mail: ebyrne@ucd.ie
M. Calderini
Deptartment of Mathematics, University of Trento, Trento, Italy
e-mail: marco.calderini@unitn.it
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_10
247

248
E. Byrne and M. Calderini
Thecanonicalexampleofthebroadcastwithside-informationproblemisprovided
by index coding and is the main focus of this chapter. Birk and Kol in [6] introduced
the index coding (with side-information) problem as an aspect of informed source
coding on demand. One of ï¬rst appearances of the term â€˜index codingâ€™ was in [2].
It relates to a problem of source coding with side-information, in which receivers
have partial information of a broadcast prior to its transmission. The problem for the
sender is to exploit knowledge of the usersâ€™ side-information in order to optimize
the transmission rate. The problem has since become a subject of several studies and
generalizations, including error-correction, privacy and secrecy [1, 3â€“5, 12â€“14].
The index coding problem may be described informally as follows. A single
sender has a set of data packets. There is a set of some m clients each of whom
already possesses some packets of the senderâ€™s data. Each receiver sends a request
to the sender for a single packet and these requests may differ from client to client.
The task for the sender is to satisfy all usersâ€™ demands using a minimum number of
transmissions. If the sender only transmits uncoded data packets, then the number of
transmissions required is simply the number of different requests of all users, and all
users will receive the requests of the other users. However, if data coding is permitted,
that is if the broadcaster transmits functions of its packets, then the number of required
transmissions can be greatly reduced. The main problem of index coding is the
determination of this minimum transmission rate, or the minimum number of packet
transmissions required by the sender in order to satisfy all usersâ€™ requests. Given an
ICSI instance, we also seek to obtain an explicit optimal encoding function, which is
computationally very hard. Therefore we seek bounds on the optimal transmission
rate and algorithms that generate good but possibly sub-optimal encoding functions.
It was shown in [2] that the best rate of a scalar linear binary index code is char-
acterized by the minrank of a graph, which is NP-hard to compute [29]. Clearly, any
encoding function for an instance necessarily gives an upper bound on the optimal
length of an index code for that instance. There have been a number of papers address-
ing this aspect of the problem, in fact ï¬nding sub-optimal but feasible solutions, using
linear programming methods to obtain partitions of the users into solvable subsets.
Such solutions involve obtaining clique covers, partial-clique covers, multicast par-
titions and some variants of these [5, 30, 33, 36]. Other than these LP approaches,
low-rank matrix completion methods may also be applied. This was considered for
index coding over the real numbers in [22], but the problem is essentially still open
for index coding over ï¬nite ï¬elds.
In Sect.2 we describe the general problem of broadcast with side information.
This is a problem with two fundamental aspects, namely that of delivery and place-
ment. The delivery problem is essentially a generalization of index coding, while the
placement problem is a generalized coded-caching problem. In Sect.3 we introduce
the classical index coding problem and describe the known efforts to estimate the
optimal transmission rate for an arbitrary instance, including approaches from graph
theory and algebraic approaches. In Sect.4 we describe a generalized version of the
index coding problem, namely that for coded side-information. We outline how many
of the graph-theoretic bounds can be extended to this more general case. In addition,
we consider the problem of error correction, when the senderâ€™s transmission is sub-

Index Coding, Network Coding and Broadcast with Side-Information
249
ject to noise. We give bounds on the transmission rate in this context and describe a
decoding method for Hamming like errors. Finally, in Sect.5 we discuss connections
of the classical index coding problem to other problems of network communications,
such as its equivalence to network coding, relation to interference alignment and to
the coded-caching problem.
1.1
Notation
For any positive integer n, we let [n] := {1, . . . , n}. We write Fq to denote the ï¬nite
ï¬eld of order q and use FnÃ—t
q
to denote the vector space of all n Ã— t matrices over Fq.
Given a matrix X âˆˆFnÃ—t
q
we write Xi and X j to denote the ith row and jth column
of X, respectively. More generally, for subsets S âŠ‚[n] and T âŠ‚[t] we write XS
and XT to denote the |S | Ã— t and n Ã— |T | submatrices of X comprised of the rows
of X indexed by S and the columns of X indexed by T respectively. We write âŸ¨XâŸ©
to denote the row space of X.
2
Broadcast with Side-Information
We present a general scenario, by which we deï¬ne an instance of the broadcast with
side-information problem over Fq. The main ingredients are as follows.
â€¢ There is a single sender and m receivers (or users).
â€¢ X âˆˆFnÃ—t
q
is the uncoded data held by the sender.
â€¢ User i has side information (V (i), V (i)X), for some matrix V (i) âˆˆFviÃ—n
q
of rank vi.
â€¢ User i has request matrix Ri, for some Ri âˆˆFriÃ—n
q
of rank ri.
â€¢ User i demands the request packet Ri X âˆˆFriÃ—t
q
.
The task of the sender is to ensure that each user i can combine its side-information
with the senderâ€™s broadcast to decode to its demanded packet Ri X. We assume that
each ith user can generate all linear combinations of the rows of V (i), so it effectively
possesses this vi-dimensional space. The sender, after receiving each request Ri, may
send Y âˆˆFNÃ—t
q
, a function of X, say Y = E(X) for some map E : FnÃ—t
q
âˆ’â†’FNÃ—t
q
.
We say that the encoding E realizes a length N code for this problem if indeed each
user can retrieve its demand Ri X for any source data matrix X, given knowledge
of E, Y, V (i), V (i)X. Therefore, the source data matrix X should be thought of as
a variable of the above instance. Unless stated otherwise, we will assume that E is
Fq-linear, so that for all X, E(X) = L X for some N Ã— n matrix L over Fq. Then we
say that L realizes the given instance if each user can retrieve its demand Ri X for
any source data matrix X, given knowledge of L, Y = L X, V (i), V (i)X. If such an
L exists, we say that the length N is achievable for the given instance. Finding such
an L (and indeed the length N) is computationally hard and the central problem of
broadcast with side-information.

250
E. Byrne and M. Calderini
User i can retrieve its demand Ri X, for all possible choices of X if and only if
there exist matrices Ai, Bi satisfying
Ri = AiV (i) + Bi L,
(1)
from which it computes Ri X, knowing V (i)X (as its side information) and L X (which
was transmitted) [4]. It is generally assumed that a user does not demand Ri X if it
already has it in its cache. Therefore, we assume that no row of Ri is contained in
the row space of V (i).
Remark 1 The uncoded downlink cost is nt, which is the cost of sending the full data
matrix X. The total coded downlink cost is N(n + t), which is the cost of transmitting
L and Y = L X. Therefore there is a coding gain only if t >
Nn
nâˆ’N .
We now describe this in terms of a matrix code. First let r = m
j=1 r j and let R
be the r Ã— n matrix
R = [RT
1 , RT
2 , ..., RT
m]T .
We call R the request matrix. For each i, let
Ci = {AV (i) : A âˆˆFriÃ—vi
q
} âŠ‚FriÃ—n
q
.
Ci is a vector space of ri Ã— n matrices for the scalars Fq. It can be thought of as ri
copies of the length n linear code generated by the rows of V (i). Now deï¬ne
C =

[U T
1 ,U T
2 , ...,U T
m ]T : Ui âˆˆCi

âŠ‚FrÃ—n
q
,
which is a vector space of r Ã— n matrices for the scalars Fq.
We say that the pair (C , R) is an instance of the broadcast with side-information
problem and we call the matrix code C the side-information code of the instance.
The problem of determining the optimal code length of the instance (C , R) and a
corresponding encoding matrix L is a delivery problem.
It can be shown, using (1), that the minimum length of a code for (C , R) is
Îº(C , R) := min{rank(R + C) : C âˆˆC },
which is called the minrank of the instance (R, C ) [4]. The block length t does not
affect the minrank parameter, however, due to overhead transmission costs, the gains
of coding are greater as t increases. The set R + C := {R + C : C âˆˆC } is a coset
or translate of C , so Îº(R + C ) is the minimum rank of any member of this coset.
It is also the rank distance of the matrix R to the side information code C . This
generalizes the minrank of a side-information graph or hypergraph, as it arises in the
index coding problem (cf. [3, 4, 13, 25]). Implicit in this is the fact that any full-rank
matrix L that realizes the instance (C , R) can be obtained by rank-factorization of a
member of R + C . Note that

Index Coding, Network Coding and Broadcast with Side-Information
251
dim C =

iâˆˆ[m]
rivi
over Fq, so |R + C | = qs where s = 
iâˆˆ[m] rivi â‰¤rn.
For a given side-information code C , the sender can satisfy any set of requests in
at most
Ï(C ) := max{Îº(C , R) : R âˆˆFmÃ—n
q
}
transmissions, which is the rank-metric covering radius of the code C . So if the
side-information code C has low covering radius, then all instances (C , R) require
a small number of transmissions.
This relates to a placement problem: that of determining side-information codes
C with least maximal minrank Îº(C , R) for some ï¬xed set of request matrices R in
FrÃ—n
q
.
The delivery problem of broadcast with side-information is essentially the index
coding problem and its generalizations. The placement problem is central to coded-
caching. The main focus of this chapter will be an account of the former. We remark
that with respect to delivery, there is no loss of generality in assuming that each
request matrix Ri is a single row vector; for example, if the user m has 2 Ã— n request
matrix Rm then the instance can be equivalently represented by one for which user m
is now represented by two users m and m + 1, each with the same side-information
Cm. User mâ€™s request vector is the ï¬rst row of Rm and the request vector of user
m + 1 is the 2nd row of Rm. Observe that both instances are represented by the same
pair (R, C ), and have the same minrank.
3
Index Coding with Side-Information
We start with the classical index coding (ICSI) with side information problem. In
this case it is assumed that the side-information held by the users is uncoded, so each
user has a subset of the data packets held by the broadcaster, and each user requests a
single other packet from the sender. As we will see below, a prominent characteristic
of the ICSI problem is that it can be identiï¬ed with a unique directed hypergraph.
The unique sender has a data matrix X âˆˆFnÃ—t
q
. There are m receivers, each with a
request for a data packet Xi, and it is assumed that each receiver has a subset of mes-
sages XX i, for a subset Xi âŠ†[n]. The requested packets of the users are described by
a surjection f : [m] â†’[n], such that the packet requested by i is denoted by X f (i),
and it is assumed that f (i) /âˆˆXi for all i âˆˆ[m]. With respect to this viewpoint, the
side-information and requested data are represented as subsets of [n], the index set of
the data matrix X. Hence the term index coding. This description (see [13]), is indeed
a special case of the broadcast with side-information problem as given in Sect.2. To
translate back to this setting, set the side information codes Ci to be generated by
matrices V (i) whose rows are standard basis vectors and the request matrices to be
the standard basis vectors Ri = e f (i).

252
E. Byrne and M. Calderini
S
U4
has x2
requests x1
U3
has x1,x2
requests x3
U1
has x3
requests x1
U2
has x1,x3
requests x2
(a) ICSI problem
1
2
3
U1
U4
U2
U2
U3
U3
(b) Side information hypergraph H
Fig. 1 The ICSI problem of Example 1
For the remainder, let us ï¬x t, m, n to denote those parameters as described
above. Then for any X = (X1, . . . , Xn), Xi âŠ‚[n] and map f : [m] â†’[n], the
corresponding instance of the ICSI problem (or the ICSI instance) is denoted by
I = (X , f ).
The index coding problem given by an instance I can be described by a
side-information (directed) hypergraph [1]. We deï¬ne a directed hypergraph H =
(V , E ), where the set of vertices is V = [n]. Each vertex i of H corresponds to the
data packet Xi. The set E is composed by the hyper-edges of type ( f (i), Xi).
Example 1 Consider the ICSI instance with n = 3 (three messages), m = 4 (four
users), f (1) = 1, f (2) = 2, f (3) = 3, f (4) = 1, X1 = {3}, X2 = {1, 3}, X3 =
{1, 2}, and X4 = {2}. The hypergraph H that describes this instance has three ver-
tices 1, 2, 3, and has four hyperarcs. These are e1 = (1, {3}), e2 = (2, {1, 3}), e3 =
(3, {1, 2}), and e4 = (2, {2}). This hypergraph is depicted in Fig.1.
When m = n we assume that f (i) = i for all i âˆˆ[n], and the corresponding side
information hypergraph has precisely n hyperarcs, each with a different origin vertex.
It is simpler to describe such an ICSI instance as a digraph G = ([n], E ), the so-
called side information (di)graph [2]. For each hyperarc (i, Xi) of H , are |Xi| arcs
(i, j) of G , for j âˆˆXi. Equivalently, E = {(i, j) : i, j âˆˆ[n], j âˆˆXi}.
We now formally deï¬ne what is meant by a code for an instance of the ICSI
problem.
Deï¬nition 1 Given an instance of the ICSI problem described by an hypergraph H .
Let N be a positive integer. We say that the map
E : FnÃ—t
q
â†’FN
q ,
is an Fq-code of length N for the instance described by H if for each i âˆˆ[m] there
exists a decoding map
Di : FN
q Ã— F|X i|
q
â†’Ft
q,

Index Coding, Network Coding and Broadcast with Side-Information
253
satisfying
âˆ€X âˆˆFnÃ—t
q
: Di(E(X), XX i ) = X f (i),
in which case we say that E is an H -IC. E is called an Fq-linear I -IC if E(X) = L X
for some L âˆˆFNÃ—n
q
, in which case we say that L represents the code E. If t = 1 it is
called scalar linear.
3.1
Bounding the Optimal Rate of the Index Coding Problem
Bar-Yossef et al. showed [2, 3] that (for a given ï¬eld size), the optimal length of
a scalar linear index code is equal to the minrank of the associate side-information
graph. The notion of minrank for an undirected graph G was ï¬rst considered by
Haemers [21] in 1978 to obtain a bound for the Shannon graph capacity.
Such a result was extended to the more general case with m â‰¥n in [13]. Therefore,
minrank characterizes the best possible scalar linear index code for a given ï¬nite ï¬eld.
Let p be a ï¬xed prime. The broadcast rate of an IC-instance I is deï¬ned as
follows [1].
Deï¬nition 2 Let H be a side-information hypergraph. We denote by Î²t(H ) the
minimalnumberofsymbolsrequiredtorealizeanindexcodinginstanceI associated
to H for block length t, over all possible extensions of Fp. That is,
Î²t(H ) = inf
q {N | âˆƒa q-ary index code of length N for I }.
Moreover we denote by Î²(H ) the limit
Î²(H ) = lim
tâ†’âˆ
Î²t(H )
t
= inf
t
Î²t(H )
t
.
In the following we will consider the scalar case, i.e. t = 1, moreover we report
the results on the minrank in the more general case of the hypergraphs.
3.1.1
Algebraic Methods
Deï¬nition 3 Let H be the side-information hypergraph of an instance of the IC
problem. A matrix M = (mi, j) âˆˆFmÃ—n
q
ï¬ts the hypergraph if
mi, j =

1 if j = f (i)
0 if j does not lie in Xi

254
E. Byrne and M. Calderini
The min-rank of H over Fq is deï¬ned to be
minrkq(H ) = min{rankq(M) : M ï¬ts H }
Example 2 Consider the ICSI instance given in Example 1. Then we have that a
matrix M that ï¬ts the hypergraph H is of type
M =
U1
U2
U3
U4
X1 X2 X3
â¡
â¢â¢â£
1 0 âˆ—
âˆ—1 âˆ—
âˆ—âˆ—1
1 âˆ—0
â¤
â¥â¥â¦
where the symbol â€œâˆ—â€ may be replace by an arbitrary element of the ï¬eld Fq.
The following lemma speciï¬es a sufï¬cient condition on a matrix L to correspond
to a H -IC. This result was implicitly formulated by Bar-Yossef et al. [2, 3] for the
case where m = n, f (i) = i for all i âˆˆ[n], and q = 2, then generalized to the case
m â‰¥n for any q by [13].
Let Supp(v) denotes the support of a vector v âˆˆFn
q.
Lemma 1 A I (X , f )-IC of length N over Fq has a linear encoding map if and
only if there exists a matrix L âˆˆFNÃ—n
q
such that for each i âˆˆ[m], there exists a vector
u(i) âˆˆFn
q satisfying
Supp(u(i)) âŠ†Xi
(2)
u(i) + e f (i) âˆˆâŸ¨LâŸ©.
(3)
The lemma above implies the existence of a vector b(i) âˆˆFN
q such that b(i)L =
u(i) + e f (i), in which case the receiver at i retrieves
x f (i) = e f (i)X = b(i)L X âˆ’u(i)X = b(i)Y âˆ’u(i)XX i,
(4)
where Y is the message sent by the source over the broadcast channel.
As consequence we obtain the following
Theorem 1 Let I = (X , f ) be an instance of the ICSI problem, and H its
side information hypergraph. Then the optimal length of a q-ary linear H -IC is
minrkq(H ).
Therefore, min-rank characterizes the best possible scalar linear index code for a
given ï¬nite ï¬eld.
Theorem 2 Let H be a side-information hypergraph, for any q we have
Î²(H ) â‰¤minrkq(H ).

Index Coding, Network Coding and Broadcast with Side-Information
255
Example 3 Consider the instance given by Example 1. It is easy to check that a
matrix that ï¬ts the hypergraph has at least rank 2 (see Example 2). Thus
M =
â¡
â¢â¢â£
1 0 1
1 1 0
1 0 1
1 1 0
â¤
â¥â¥â¦
achieves the minimum rank possible 2. Now if we consider 2 linear independent
rows of M, suppose
L =
 1 0 1
1 1 0

.
Take into account receiver 1, that requested X1 and knows X3. Encoding X with L
we obtain
L X = [X1 + X3, X1 + X2]T .
So, deleting X3 from X1 + X3 receiver 1 obtain X1. Similarly for the other receivers.
Thus, do ï¬nd an encoded matrix we need to select the linear independents rows
of a ï¬tting matrix of the hypergraph.
The authors of [2] proved that in various cases, linear codes are optimal, so their
main conjecture was that linear index coding is always optimal, that is Î²(G ) =
minrk2(G ) for any graph G . This conjecture was later disproved by Lubetzky and
Stav in [26]. The authors show that for any positive Îµ > 0 there exist graphs, of
order n, where every linear index code requires at least n1âˆ’Îµ bits, whereas a given
non-linear index code utilizes only nÎµ bits.
However, as shown by Peeters [29], computing the minrank of a general graph
is a hard task. More speciï¬cally, Peeters showed that deciding whether a graph has
min-rank three is an NP-complete problem.
DuetotheresultgiveninTheorem1,wehavethattheproblemofï¬ndalinearindex
code is equivalent to a rank minimization problem over a ï¬nite ï¬eld. An approach
to the minimum rank matrix completion problem over ï¬nite ï¬elds representing the
linear index coding problem was studied in [17].
In [17] ï¬rst the complete sub-matrix of highest rank is identiï¬ed, using a heuristic
scheme of polynomial complexity and then by using row (column) projection to
expand the complete sub-matrix iteratively. The goal of the projection step is to ï¬nd
possible completions of an incomplete row or column such that they are in the span of
the complete sub-matrix. The steps of row and column projections are administered
over a decision tree.
To identify the maximal complete sub-matrix of M of highest rank, a heuristic
algorithm, starting with an initial complete sub-matrix, tries to improve it iteratively.
The row-improving step is performing in the following way, supposing that we
have the complete sub-matrix M J
I :

256
E. Byrne and M. Calderini
â€¢ Let Â¯I = [m] \ I, select a row of M J
Â¯I with fewer erasures (that is, stars â€œâˆ—â€).
â€¢ Suppose i is selected, consider M J
Iâˆª{i} and remove the incomplete columns in it.
â€¢ If the rank of the resulting matrix is greater than M J
I , update the select I and J.
A similar approach is applied to improve the set of columns.
Data: Incomplete matrix M
Result: I, J such that the complete sub-matrix M J
I is of maximal rank
I â†{1, ..., m};
J â†âˆ…;
k â†0;
N â†100;
while No change detected over N iterations in sequence do
th â†|I|/(|I| + |J|);
if rand([0, 1]) > th then
perform rows improvement
else
perform columns improvement
end
Mâ€² â†the matrix obtain from the improvement;
if rk(Mâ€²) > k then
Update I and J
end
end
Algorithm 1: Complete sub-matrix
It is preferred to identify the maximal complete sub-matrix of highest rank within
the matrix M, however we can proceed to the subsequent steps for matrix completion
even with a sub-optimal choice. Thus, we may limit the number of iterations in
Algorithm 1 to N iterations.
The completion of the matrix M is done by alternating projection steps on rows
and columns. The goal of this step is to ï¬nd possible completions of an incomplete
row (column) such that it in the span of the complete sub-matrix. The row and column
projections are administered over a decision tree.
Here we describe the horizontal projection (that is, on the rows) in a branch. It is
similar for the columns. There are three possible cases (Fig.2).
1. There are one or more incomplete rows that may be completed in a unique way in
the subspace spanned by the rows of the current complete sub-matrix. In this case
we complete these rows and update the complete sub-matrix. Then we switch the
projection direction over the next branch.
2. There is no row that may be completed uniquely, but there are some rows that
are in the subspace spanned by the rows of the complete sub-matrix. In this case,
we choose the incomplete row with minimum possible solutions. Then, for each
solution we analyze the consequent matrix completion, over multiple subsequent
branches, continuing the procedure in the alternate direction of projection.

Index Coding, Network Coding and Broadcast with Side-Information
257
Fig. 2 A sample structure
for the decision tree
3. The last case is when no row can be completed with a vector of the span of
the complete sub-matrix. Thus, the rank of the solution is to be increased. If the
increased rank is larger than the rank of the previously completed branches, the
current branch is eliminated; otherwise, all the possible solutions are examined
over multiple subsequent branches.
Step 2, described above, can be performed using erasure decoding techniques. Con-
sider a generator matrix G of the code spanned by the complete submatrix and its
parity check matrix H. Then suppose to have selected the row Mi restricted to the
column of the complete sub-matrix (the symbols stars now represent our variables).
We verify the solution of the system Mi Â· H = 0.
At each iteration, the branch with â€˜maximum opportunityâ€™ is selected, which
is quantiï¬ed by a metric deï¬ned by the ratio of the completion percentage of the
matrix with respect to the rank of its complete sub-matrix. The branch with minimum
achieved rank identiï¬es the solution.
Note that the growth of the tree due to a rank increment, that is the number of
new branches, is bounded above by qe, where e is the maximum number of erasures
that we have in the rows or in the columns. Moreover, in a path of the tree we could
increment the rank at most minrk(H ) âˆ’k times, where k is the rank of the starting
complete submatrix.
Furthermore, the growth due to the multiple allowed combinations for completing
a row or (column) is bounded above by qmax(n,m)âˆ’k for each projection.
For large incomplete matrices the authors in [17] propose a sub-optimum algo-
rithm. Speciï¬cally, whenever the number of branches goes beyond a pre-set thresh-
old, we prune the branches having a small value with respect to the metric described
above.
In [31] the authors propose a linear algebraic algorithm to complete M (over F2)
given a random subset of its entries. They establish some conditions on the row and
column spaces of M which guarantee that the algorithm runs in polynomial time.
Moreover a linear programming-based extension is proposed.
In particular, given a matrix M âˆˆFnÃ—n
2
of rank r and a random subset of its
entries Î©, we can complete successfully M with high probability in time O(n2r+3),
whenever the cardinality of the set Î© is at least 
Î©

n2âˆ’
1
r+1

.

258
E. Byrne and M. Calderini
Data: Incomplete matrix M
Result: Complete matrix with minimum possible rank
Find maximal complete sub-matrix M J
I ;
while incomplete branches > 0 do
Choose the branch with maximum opportunity;
Perform projection in the proper direction;
Based on projection results add more branches or
eliminate current one if necessary ;
if matrix is complete in this branch then
if achieved rank < minimum achieved rank then
Update minimum achieved rank
end
end
end
Algorithm 2: Complete matrix
There have been several hardness results for matrix completion over ï¬nite ï¬elds.
Tan et al. [34] studied the more general problem where, instead of entries, random
linear combinations of the entries are observed. They give various information-
theoretic bounds on the number of measurements necessary for low rank matrix
recovery.
The matrix completion problem over the reals seems to behave rather differently
and techniques do not appear to transfer to the ï¬nite ï¬eld case. A method for matrix
completion over the real numbers is given in [22]. Note that linear index codes
over the reals have applications to topological interference management in wireless
networks [23, 27].
The method developed in [22] is based on an alternating projection (AP) approach.
As it is shown in the paper, completing the index coding matrix M by choosing values
for the symbols â€œâˆ—â€ such that M has a low rank r can be thought of as ï¬nding the
intersection of two regions C and D in RnÃ—n deï¬ned by,
C = {M âˆˆRnÃ—n | rk(M) â‰¤r},
and
D = {M âˆˆRnÃ—n | mi j = 0 if (i, j) âˆˆE (G ) and mii = 1, i âˆˆ[n]}.
C is not convex and therefore convergence of the AP method is not guaranteed.
However, the AP method can give a certiï¬cate that a certain rank r is achievable.
Therefore we can use the AP method as a heuristic. This AP method, in some cases,
leads to up to 13% average savings in broadcast messages compared to graph coloring
(see next section).
The authors in [22] compare the AP methods also to the well studied Alternating
Minimization (AltMin) algorithm [20, 41, 42]. Jain et al. [41] gave one of the ï¬rst
performance guarantees of AltMin, in particular the authors proved that by observing
|Î©| = O

Ïƒ1
Ïƒr n log n log(r||M||F/Îµ)

random entries of an incoherent M, AltMin

Index Coding, Network Coding and Broadcast with Side-Information
259
can recover M in O(log(1/Îµ)) steps. Here Ïƒ1 and Ïƒr denote the largest and smallest
singular values of M, respectively, and || Â· ||F is the Frobenius norm. However in this
context the authors in [22] show that AltMin does not perform as well as AP.
CandÃ¨s and Recht in [10] showed that replacing the rank function by the nuclear
norm leads to ï¬nding the minimum rank with high probability (under certain condi-
tions). However, these results do not carry over directly to the index coding problem
because the model in [10] assumes the location of the ï¬xed entries is chosen uni-
formly at random. In the index coding problem the matrix M has a speciï¬c structure,
that is, all the diagonal entries have to be equal to one. Indeed, as noted in [22] the
approach in [10] always output the maximum rank n.
In the analysis of the performance of these algorithms it is always assumed that
the set Î© is given at random. However, in the index coding problem, also in the case
of random graph, the diagonals entries are ï¬xed to one, so it is not guaranteed that
this algorithms performs well.
3.1.2
Graph Theoretic Methods
Graph theoretic methods start from the well-known fact that all the users forming a
clique in the side information digraph can be simultaneously satisï¬ed by transmitting
the XOR of their packets. Indeed, for such a graph we have that Xi = [n] \ {i}. Thus
sending Y = 
i Xi, any receiver retrieves its requested packet.
Moreover, from the fact that for a graph G that is a union of disjoint graphs,
i.e. G = G1 âˆªÂ· Â· Â· âˆªGs, it holds that minrk(G ) = 
i minrk(Gi), we have that an
achievable scheme for index coding on graphs is the number of disjoint cliques
required to cover G [2]. This number is called the clique-covering number cc(G ),
which is equal to the chromatic number of the complement graph Ï‡(G ). This is
because all the vertices assigned to the same color cannot share an edge and hence
must form a clique on the complement graph.
In [2] the authors prove that for an acyclic graph G of order n the optimal broadcast
rate is n. Therefore if Î±(G ) is the order of the maximum acyclic induced subgraph of
G then Î±(G ) â‰¤Î²(G ). In particular, when G is symmetric, Î±(G ) is the independence
number of G . These two results give the so-called sandwich property on the optimal
broadcast rate.
Theorem 3 ([2])
Î±(G ) â‰¤Î²(G ) â‰¤cc(G ).
Example 4 Consider the graph G in Fig.3. We can see that any clique partition of
G is composed of at least 3 cliques, e.g. {{1, 2}, {3, 4}, {5}}. Thus cc(G ) = 3, and an
encoded scheme for the instance associated to G is Y = [X1 + X2, X3 + X4, X5].
An other scheme given in [2] is based on the concept of partial-clique.
Deï¬nition 4 A graph G is called a k-partial clique if for all node i we have
degOut(i) â‰¥n âˆ’k âˆ’1 and there exists at least one node for which the equality

260
E. Byrne and M. Calderini
Fig. 3 The graph G of
Example 4
1
2
3
4
5
holds. Here degOut(i) denotes the out-degree of the node i, that is, the edges outgo-
ing from i.
Note that a 0-partial clique is a usual clique.
The nodes contained in a partial clique correspond to a set n of clients, each
missing at most k packets of the n âˆ’1 packets requested by the other receivers of the
set, and at least one client missing exactly k of those blocks. To satisfy the requests
of a k-partial clique we can use an (n, k + 1)-MDS code, e.g. Reed-Solomon codes.
Indeed suppose G is generator matrix, over a sufï¬cient large ï¬eld, of an MDS code
of length n and dimension k + 1. Now we can broadcast the message Y = GX. Now
any receiver is able to delete at least n âˆ’k âˆ’1 columns of G from Y. So since every
set of k + 1 columns of G are linearly independent, we can retrieve the requested
packet. So, instead of partitioning a graph in clique we can use partial-clique.
Theorem 4 ([2]) Let G a side-information graph and let G1, ..., Gr be a partition in
partial clique whose parameters are k1, ..., kr. Then
Î²(G ) â‰¤
r

i=1
ki + 1.
Example 5 Consider the instance given by the side information graph G in Fig.4.
We can see that using the scheme based on the clique cover we need 3 transmissions.
Using the partial clique scheme we can use 2 transmissions. In fact each receiver
knows one packet, so G is a 1-partial clique. Consider the matrix
G =
 1 0 1
0 1 1

Fig. 4 The graph G of
Example 5
1
2
3

Index Coding, Network Coding and Broadcast with Side-Information
261
which represents a (3, 2)-MDS code over F2. We can encode X = [X1, X2, X3]T
using G,thatisY = GX = [X1 + X3, X2 + X3].Itiseasytocheckthateachreceiver
can retrieve the requested packet.
It turns out that the idea based on partitioning with cliques leads to a family of
stronger bounds, starting with an LP relaxation called the fractional clique covering
number. It can be readily checked that this rate is the solution to the integer program
min

CâˆˆC
yC
s.t.

C: jâˆˆC
yC = 1 for all j âˆˆ[n]
yC âˆˆ{0, 1} for all C âˆˆC .
(5)
where C is the collection of all cliques in G .
Blasiak, Kleinberg, and Lubetzky [7] extended the clique covering bound to the
fractional clique covering bound, namely, the solution to the linear program obtained
by relaxing the integer constraint yC âˆˆ{0, 1} to yC âˆˆ[0, 1] in (5). This scheme
corresponds to an achievable (vector-linear) index code.
Example 6 Consider the graph G given in Example 4. A possible fractional partition
of the nodes is given by {{1, 2}, {2, 3}, {3, 4}, {4, 5}, {5, 1}}. Any node is contained
in two sets of the fractional partition. So if we consider a data matrix X composed
by two sub-packets for each packet, i.e.
X
â¡
â¢â¢â¢â¢â£
X11 X12
X21 X22
X31 X32
X41 X42
X51 X52
â¤
â¥â¥â¥â¥â¦
.
Sending Y = [X11 + X21, X31 + X41, X12 + X51, X22 + X32, X42 + X52] we sat-
isfy all the requests, achieving a rate of 5/2.
Theorem 5 ([7]) The optimal broadcast rate is upper bounded by the optimal solu-
tion cc f (G ) of the LP relaxation of (5),
Î²(G ) â‰¤cc f (G ) â‰¤cc(G ).
In [40], Shanmugam, Dimakis, and Langberg showed, extending the clique cov-
ering scheme, that if the users are partitioned in cliques and the packets encoded for
each clique with the XOR as before, then we can reduce the number of transmissions
by applying an MDS code and using side information to recover them. Just as Birk
and Kol reduced the number of message transmissions with partial-clique [2].

262
E. Byrne and M. Calderini
The coding scheme given in [40] achieves the local clique covering number of G ,
denoted by ccl(G ) [16]. Further extending this scheme with fractional coloring, we
can establish the following.
Theorem 6 ([40]) The optimal broadcast rate is upper bounded by the optimal
solution ccl f (G ) of the LP relaxation of
min k
s.t.

C:Câˆ©X jÌ¸=âˆ…
yC â‰¤k for all j âˆˆ[n]

C: jâˆˆC
yC = 1 for all j âˆˆ[n]
yC âˆˆ{0, 1} for all C âˆˆC .
(6)
Example 7 Consider the instance with n = m = 6, f (i) = i for all i and
X1 = {2, 3, 4}, X2 = {1, 3, 4},
X3 = {4, 5, 6}, X4 = {3, 5, 6},
X5 = {1, 2, 6}, X6 = {1, 2, 5}.
We associate the graph G given in Fig.5 with this instance, where an edge from
one clique to another means that all the nodes in a clique are connected to all the
nodes in the other clique. Using the scheme based on clique covering requires us to
use at least three transmissions. With local clique covering, we ï¬rst encode using
clique covering to obtain Y â€² = [X1 + X2, X3 + X4, X5 + X6]. Then, exploiting the
side information, we can encode Y â€² using the MDS code also used in Example 5 to
obtain Y = [X1 + X2 + X5 + X6, X3 + X4 + X5 + X6]. Then all receivers are able
to decode ther requested packets.
This linear programming approach was then used to extend these bounds to the
more general case of the hypergraphs. Blasiak, Kleinberg, and Lubetzky in [7] intro-
duced the concept of a hyperclique.
Fig. 5 The graph G for the
ICSI instance in Example 7
1
2
3
4
5
6

Index Coding, Network Coding and Broadcast with Side-Information
263
Deï¬nition 5 Let H a side-infromation hypergraph. A subset S âŠ†[m] is a hyper-
clique if for every pair of distinct elements i, j âˆˆS f (i) âˆˆX j âˆª{ f ( j)}.
As in the graph case we can satisfy the requests of all the receivers in a hyperclique
by just sending the XOR of all packets. We deï¬ne the hyperclique covering number
Ïˆ(H ) as the optimal solution of
min

CâˆˆC
yC
s.t.

C: jâˆˆC
yC = 1 for all j âˆˆ[m]
yC âˆˆ{0, 1} for all C âˆˆC .
(7)
The solution of the LP relaxation of (7) is denoted by Ïˆ f (H ).
Theorem 7 ([7]) The optimal broadcast rate is upper bounded by Ïˆ f (H )
Î²(G ) â‰¤Ïˆ f (H ) â‰¤Ïˆ(H ).
In the work of Tehrani, Dimakis and Neely [36] the authors extend the idea of the
partial clique to the case m â‰¥n, introducing the multicast partition.
As noted in [36], if we have a side-information hypergraph H and each receiver
knows at least k packets (i.e. |Xi| â‰¥k), then we can use the same approach as in the
partial-clique case, namely, to use the generator matrix of an MDS code to encode
the packets.
Theorem 8 ([36]) Let Ïˆ p(H ) the optimal solution of
min

M
aMdm
s.t.

M: jâˆˆM
aM = 1 for all j âˆˆ[m]
aM âˆˆ{0, 1} for all M âŠ†[m],
dm = |R(M)| âˆ’max
jâˆˆM |R(M) âˆ©X j|,
(8)
where R(M) = { f (i) | i âˆˆM}.
Then Î²(H ) â‰¤Ïˆ p(H ).
Later, Shanmugam, Dimakis, and Langberg [30] proved that the fractional version
of this parameter provides an upper bound for the optimal rate.
In [30] the authors extended their previous result, deï¬ning the local hyperclique
covering number Ïˆl(H ) of an hypergraph as the optimal solution of the integer
program

264
E. Byrne and M. Calderini
min k
s.t.

C:Câˆ©U jÌ¸=âˆ…
yC â‰¤k for all j âˆˆ[m]

C: jâˆˆC
yC = 1 for all j âˆˆ[m]
yC âˆˆ{0, 1} for all C âˆˆC ,
(9)
where U j = {i âˆˆ[m] | f (i) /âˆˆX j}. The LP relaxation of (9) is deï¬ned to be the
fractional local hyperclique cover, denoted Ïˆl f (H ).
Theorem 9 ([30]) The optimal broadcast rate is upper bounded by Ïˆl f (H )
Î²(G ) â‰¤Ïˆl f (H ) â‰¤Ïˆl(H ).
In [30], another parameter, called the partitioned local hyperclique cover and its
fractional version for the groupcast setting is deï¬ned. This pararameter is stronger
than those based on local hyperclique covering and partition multicast.
Deï¬nition 6 The partitioned local hyperclique cover number of H , denoted
Ïˆ p
l (H ), is given by the following integer program:
min

M
aMkM
s.t.

C:Câˆ©U jâˆ©MÌ¸=âˆ…
yC â‰¤kM for all j âˆˆM

M: jâˆˆM
aM = 1 for all j âˆˆ[m]

C: jâˆˆC
yC = 1 for all j âˆˆ[m]
yC âˆˆ{0, 1} for all C âˆˆC , aM âˆˆ{0, 1} for allM âŠ†[m].
(10)
The fractional version Ïˆ p
l f (H ) is given by the LP relaxation of (10).
Theorem 10 ([30])
Î²(G ) â‰¤Ïˆ p
l f (H ) â‰¤Ïˆ p
l (H ).
However this new scheme is within a factor e from the fractional hyperclique
cover (implying the same for all previous bounds as well).
Theorem 11 ([30])
Ïˆ f (H ) â‰¤eÏˆ p
l f (H ).
In Fig.6 we report the comparison of all these parameters.

Index Coding, Network Coding and Broadcast with Side-Information
265
Fig. 6 Comparison of graph theoretic bounds for the ICSI problem. u â†v means u â‰¤v
4
Generalizations of the Index Coding
Problem - Coded-Side Information
In[12, 33]theauthorsgiveageneralizationoftheindexcodingprobleminwhichboth
demanded packets and locally cached packets may be linear combinations of some
set of data packets. We refer to this as the index coding with coded side information
problem (ICCSI). This represents a signiï¬cant departure from the ICSI problem in
that an ICCSI instance no longer has an obvious association to a graph, digraph or
hypergraph, as in the ICSI case. However, as we show here, it turns out that many of
the results for index coding have natural extensions in the ICCSI problem.
One motivation for the ICCSI generalization is related to the coded-caching prob-
lem. The method in [28] uses uncoded cache placement, but the authors give an
example to show that coded cache placement performs better in general. In [8], it is
shown that in a small cache size regime, when the number of users is not less than
the number of ï¬les, a scheme based on coded cache placement is optimal. Moreover
in [39] the authors show that the only way to improve the scheme given in [28] is by
coded cache placement.
Another motivation is toward applications for wireless networks with relay helper
nodes and cloud storage systems [12] (Fig.7).
Fig. 7 State of the network
after the 6th time slot
X1 +X2 +X3 +X4
U1
has X2, X3 +X4
wants X1
U2
has X1, X3 +X4
wants X2
U3
has X4, X1 +X2
wants X3
U4
has X3, X1 +X2
wants X4

266
E. Byrne and M. Calderini
Table 1 Illustration of utilizing coded packets as side information
Time slot
Packet sent
Received by
U1?
Received by
U2?
Received by
U3?
Received by
U4?
1
X1
No
Yes
No
No
2
X2
Yes
No
No
No
3
X3
No
No
No
Yes
4
X4
No
No
Yes
No
5
X1 + X2
No
No
Yes
Yes
6
X4 + X3
Yes
Yes
No
No
7
X1 + X2 + X3 + X4
Yes
Yes
Yes
Yes
Consider the example in Table1. We have a scenario with one sender and four
receivers U1, U2, U3 and U4. The source node has four packets X1, X2, X3 and X4
and for i = 1, ..., 4 user Ui wants packet Xi. The transmitted packet is subject to
independent erasures. It is assumed that there are feedback channels from the users,
informing the transmitting node which packets are successfully received. At the
beginning, in time slot 1, 2, 3 and 4 the source node transmits packets X1, X2, X3
and X4, respectively. After time slot 4 we have the following setting: U1 has packet
X2, U2 has packet X1, U3 has packet X4 and U4 has packet X3. Now from the classical
ICSI problem we have that receivers U1 and U2 form a clique, in the associated graph,
and then we can satisfy their request sending X1 + X2. Similarly for U3 and U4 we
can use X3 + X4. So, the source node in time slot 5 and 6 transmits the coded packet
X1 + X2 and X3 + X4, intending that users receive the respective packet. However,
U1 and U2 receive the coded packet X3 + X4 and U3 and U4 receive X1 + X2.
At this point if only the uncoded packets in their caches are used, we still need to
send two packets. If all packets in their caches are used, the source only needs to
transmit one coded packet X1 + X2 + X3 + X4 in time slot 7. If all four users can
receive this last transmission successfully, then all users can decode the required
packets by linearly combining with the packets received earlier.
We now describe an instance of index coding with coded-side information. As for
the uncoded case we have a data matrix X âˆˆFnÃ—t
q
and a set of m receivers. For each
i âˆˆ[m], the ith user seeks some linear combination of the rows of X, say Ri X for
some Ri âˆˆFn
q. We will refer to Ri as the request vector and to Ri X as the request
packet of User i. In this scenario a userâ€™s cache is represented by a pair of matrices
V (i) âˆˆFdiÃ—n
q
and Î›(i) âˆˆFdiÃ—t
q
related by the equation
Î›(i) = V (i)X.
It is assumed that any vector in the row spaces of V (i) and Î›(i) can be generated at the
ith receiver. We denote these respective row spaces by X (i) := âŸ¨V (i)âŸ©and L (i) :=

Index Coding, Network Coding and Broadcast with Side-Information
267
âŸ¨Î›(i)âŸ©for each i. The side information of the ith user is (X (i), L (i)). Similarly, the
sender S has the pair of row spaces (X (S), L (S)) for matrices
V (S) âˆˆFdSÃ—n
q
and Î›(S) = V (S)X âˆˆFdSÃ—t
q
and does not necessarily possess the matrix X itself.
The ith user requests a coded packet Ri X âˆˆL (S) with Ri âˆˆX (S)\X (i). We
denote by R the m Ã— n matrix over Fq with each ith row equal to Ri. The matrix R
thus represents the requests of all m users.
Example 8 Consider the instance given by the example represented in Fig.4. Then
we have q = 2, m = n = 4, t = 1 and Ri = ei for all i âˆˆ[4] and X (S) = F4
2. The
side information are given by the following matrices
V (1) =
 0 1 0 0
0 0 1 1

, V (2) =
 1 0 0 0
0 0 1 1

,
V (3) =
 1 1 0 0
0 0 0 1

, V (4) =
 1 1 0 0
0 0 1 0

.
Remark 2 The reader will observe that the classical ICSI problem is indeed a special
case of the index coding problem with coded side information. Setting V (S) to be the
n Ã— n identity matrix, Ri = e f (i) âˆˆFn
q and V (i) to be the di Ã— n matrix with rows
V (i)
j
= ei j for each i j âˆˆXi, yields X (i) = âŸ¨e j : j âˆˆXiâŸ©. Then User i has the rows
of X indexed by Xi and requests X f (i).
Remark 3 The case where the sender does not necessarily possess the matrix X
itself can be applied to the broadcast relay channel, as described in [33]. The authors
consider a channel as in Fig.8, and assume that the relay is close to the users and
far away from the source, and in particular that all relay-user links are erasure-free.
Each node is assumed to have some storage capacity and stores previously received
data in its cache. The packets in the cache of the relay node are obtained as previous
broadcasts, hence it may contain both coded and uncoded packets. The relay node,
playing the role of the sender, transmits packets obtained by linearly combining
Fig. 8 A schematic for the
broadcast relay channel

268
E. Byrne and M. Calderini
the packets in its cache, depending on the requests and coded side information of
all users. It seeks to minimize the total number of broadcasts such that all usersâ€™
demands are met.
We denote by
X := {A âˆˆFmÃ—n
q
: Ai âˆˆX (i), i âˆˆ[m]},
so that X = âŠ•iâˆˆ[m]X (i) is the direct sum of the X (i) as a vector space over Fq. For
the remainder, we let X , X (S), R be as deï¬ned above and write I = (X , X (S), R)
to denote an instance of the ICCSI problem for these parameters.
The deï¬nition of an index code is similar to that of the ICSI case.
Deï¬nition 7 Let N be a positive integer. We say that the map
E : FnÃ—t
q
â†’FNÃ—t
q
,
is an Fq-code for I of length N if for each ith receiver, i âˆˆ[m] there exists a
decoding map
Di : FNÃ—t
q
Ã— X (i) â†’Ft
q,
satisfying
âˆ€X âˆˆFnÃ—t
q
: Di(E(X), A) = Ri X,
for some vector A âˆˆX (i), in which case we say that E is an I -IC. E is called an
Fq-linear I -IC if E(X) = LV (S)X for some L âˆˆFNÃ—dS
q
, in which case we say that
L represents the code E, or that the matrix L realizes E. If t = 1, we say that L
represents a scalar linear index code. If t > 1 we say that the code is vector linear.
We write L to denote the space âŸ¨LV (S)âŸ©.
As before, for the ICCSI instance Î²t(I ) denotes the minimum broadcast rate for
block-length t where the encoding is over all possible extensions of Fp. That is, for
I = (X , X (S), R)
Î²t(I ) = inf
q {N | âˆƒa q-ary index code of length N for I }.
and the optimal broadcast rate is given by the limit
Î²(I ) = lim
tâ†’âˆ
Î²t(I )
t
= inf
t
Î²t(I )
t
.

Index Coding, Network Coding and Broadcast with Side-Information
269
4.1
Bounding the Optimal Rate with Coded-Side Information
Asshownin[4],itturnsoutthatalsoforthecaseofcodedsideinformationtheoptimal
length of a scalar linear index code is linked to a problem of rank minimization.
The result of Lemma 1 is generalized by the following
Lemma 2 ([4]) Let L âˆˆFNÃ—dS
q
. Then L represents an Fq-linear I -IC index code
of length N if and only if for each i âˆˆ[m], Ri âˆˆL + X (i).
So Lemma 2 gives necessary and sufï¬cient conditions for a matrix L to represent
a linear code of the instance I . The sufï¬ciency of the statement of Lemma 2 has
already been noted in [33]).
Remark 4 If the equivalent conditions of the above lemma hold we have that for each
i âˆˆ[m], Ri = b(i)LV (S) + a(i)V (i) for some vectors a(i), b(i). So User i decodes its
request by computing
Ri X = b(i)LV (S)X + a(i)V (i)X = b(i)Y + a(i)Î›(i),
where Y is the received message.
The analogue of the min-rank is as follows:
Deï¬nition 8 ([4]) The min-rank of the instance I = (X , X (S), R) of the ICCSI
problem over Fq is
Îº(I ) = min

rank(A + R) :
A âˆˆFmÃ—n
q
,
Ai âˆˆX (i) âˆ©X (S), âˆ€i âˆˆ[m]

.
Let
Ëœ
X = {Z âˆˆFmÃ—n
q
: Zi âˆˆX (S)}. We observe that the quantity Îº(I ) is drk
(R, X âˆ©
Ëœ
X ),whichistherank-distanceof R âˆˆFmÃ—n
q
totheFq-linearcodeX âˆ©
Ëœ
X ,
or equivalently the minimum rank-weight of the coset R + (X âˆ©
Ëœ
X ) âŠ‚FmÃ—n
q
.
As consequence of Lemma 2 we have
Theorem 12 ([4]) The length of an optimal Fq-linear I -IC is Îº(I ). In particular
Î²(I ) â‰¤Îº(I ).
Similarly to the classical ICSI, we have that optimal linear index coding matrix
can be obtained by solving a matrix completion problem over a ï¬nite ï¬eld. However,
this matrix completion problem is different from the conventional matrix completion
problem. This comes from the fact that, in this more general problem, the rows of
the matrix have to lie in the spaces X (i)â€™s. In [25] it is proposed a random greedy
algorithm (over F2) that minimizes the rank of the derived matrix.
As said before an ICCSI instance no longer has an obvious association to a com-
binatorial structure such as a graph or hypergraph. However, all the bounds given

270
E. Byrne and M. Calderini
in Sect.3.1 can be generalized to the ICCSI case adopting a Linear Programming
approach.
We start with the following deï¬nition, introduced in [33] as a coding group,
wherein a procedure to detect such as subset is given. It is easy to see that this
deï¬nition generalizes the deï¬nition of a hyperclique given in Sect.3.1.
Deï¬nition 9 Let I = (X , X (S), R) be an instance of the ICCSI problem. A subset
of receivers C âŠ†[m] is called generalized clique if there exists v âˆˆX (S) such that
Ri âˆˆâŸ¨vâŸ©+ X (i) for all i âˆˆC.
For simplicity in the following we refer to a generalized clique just as a clique.
Note that demand Ri X of each user i of a clique can be met by sending the message
vX, that is one packet as for the classical case. Hence a set of â„“cliques that partitions
the set [m] ensures that all requests can be delivered in at most â„“transmissions.
We denote by C the set of all cliques of I = (X , X (S), R).
Deï¬nition 10 We deï¬ne the generalized clique cover number of I , denoted by
Ï•(I ), to be the optimal solution of the following integer program:
min

CâˆˆC
yC
s.t.

C: jâˆˆC
yC = 1 for all j âˆˆ[m]
yC âˆˆ{0, 1} for all C âˆˆC .
(11)
The LP relaxation of (11) (so with the relaxed constraint 0 â‰¤yC â‰¤1 for all C)
is the fractional generalized clique cover number Ï• f (I ).
Theorem 13 ([5]) Let I = (X , X (S), R). There exist achievable Fq-linear index
codes corresponding to Ï•(I ) and Ï• f (H ). In particular, we have
Î²(I ) â‰¤Ï• f (I ) â‰¤Ï•(I ).
For each clique C âˆˆC deï¬ne the set
R(C) := {v âˆˆFn
q | Ri âˆˆâŸ¨vâŸ©+ X (i) âˆ€i âˆˆC}.
That is, R(C) contains all the vectors that we can use to encode X in order that all
receivers in C can decode correctly.
Deï¬nition 11 For each C âˆˆC ï¬x a vector vC âˆˆR(C). We deï¬ne the following
integer program with respect to the vectors vC.

Index Coding, Network Coding and Broadcast with Side-Information
271
min k
s.t.

C:vC /âˆˆX ( j)
yC â‰¤k for all j âˆˆ[m]

C: jâˆˆC
yC = 1 for all j âˆˆ[m]
yC âˆˆ{0, 1}for all C âˆˆC and k âˆˆN.
(12)
We denote by Ï†l(I , (vC âˆˆR(C) : C âˆˆC )) the optimal solution of (12), depend-
ing on the ï¬xed vCâ€™s. The minimum over all possible vCâ€™s is called the local gener-
alized clique cover number
Ï•l(I ) =
min
(vCâˆˆR (C):CâˆˆC ) Ï†l(I , (vC : C âˆˆC )).
This is an extension of the local hyperclique cover: for a set of ï¬xed vC, given
user j âˆˆ[m] and some feasible solution to (11), count number of cliques C in that
generalized clique cover such that vC is not contained in the side-information X ( j)
and let k be the maximum number of such cliques for each j. The optimal solution
of (12) is the minimum value of k over all possible solutions of (11) and all choices
of vC. The minimum of the LP relaxation of (12) over all possible vCâ€™s is called
the fractional local generalized clique cover number Ï•l f (I ). Clearly the optimal
solution of (12) depends on the choice of vectors vC.
Theorem 14 ([5]) Let I = (X , X (S), R). There are achievable linear index codes
corresponding to Ï•l(I ) and Ï•l f (I ) implying Î²(I ) â‰¤Ï•l f (I ) â‰¤Ï•l(I ).
In the multicast partition scheme for the ICSI case we want to ï¬nd a partition
where the knowledge, i.e. the cardinality of Xi, of the users among the sets of the
partition is maximized. Now, the knowledge of a user is given by the dimension of
the space X (i), so we obtain the following
Deï¬nition 12 We deï¬ne the partition generalized multicast number, Ï• p(I ) to be
the optimal solution of the following integer program
min

MâŠ‚[m]
aMdM
s.t.

M: jâˆˆM
aM = 1 for all j âˆˆ[m]
aM âˆˆ{0, 1} for all M âŠ‚[m], M Ì¸= âˆ….
and dM = dim(âŸ¨RMâŸ©) âˆ’min
jâˆˆM dim(âŸ¨RMâŸ©âˆ©X ( j)).
(13)
The LP relaxation of (13) is called the fractional partition generalized multicast
number, Ï• p
f (I ).
We brieï¬‚y justify the above: each user is assigned to exactly one multicast group
M, so the selected groups M form a partition of [m]. Each member j of a multicast

272
E. Byrne and M. Calderini
group M âŠ‚[m] already has access to at least dim(âŸ¨RMâŸ©âˆ©X ( j)) independent vectors
in âŸ¨RMâŸ©, so a coding scheme can be applied to ensure delivery of all remaining
requests within a group using at most dM transmissions. In fact as it is shown in [4]
we have
Proposition 1 Let I = (X , X (S), R). If q > m then Îº(I ) â‰¤max{n âˆ’di : i âˆˆ
[m]}. For any q, Îº(I ) â‰¤rank(R).
The essential content of the proof of Proposition 1 is that there exists an N Ã—
n matrix L realizing I for N â‰¤max{n âˆ’di : i âˆˆ[m]}, which corresponds to a
multicast solution, so every user can retrieve any linear combination of the Xi. In
this case the matrix L is such that L + X (i) = Fn
q for each i.
Theorem 15 ([5]) Let I = (X , X (S), R). There are achievable linear index codes
of lengths Ï• p(I ) and Ï• p
f (I ), which implies that Î²(I ) â‰¤Ï• p
f (I ) â‰¤Ï• p(I ).
The ï¬nal approach considered combines partition multicast and local clique cov-
ering. The users are partitioned into multicast groups and independently covered by
generalized cliques. Each multicast group offers a reduced ICCSI problem to which
a restricted local clique cover is applied.
Deï¬nition 13 Deï¬ne the following integer program
min

MâŠ‚[m]
aMkM
s.t.

C:vC /âˆˆX ( j)
Câˆ©MÌ¸=âˆ…
yC â‰¤kM for all j âˆˆM

M: jâˆˆM
aM = 1,

C: jâˆˆC
yC = 1 for all j âˆˆ[m]
aM, yC âˆˆ{0, 1} for all C âˆˆC , M âŠ‚[m] and tM âˆˆN.
(14)
We denote by Ï† p
l (I , (vC âˆˆR(C) : C âˆˆC )) the optimal solution of (14) with
respect to (vC âˆˆR(C) : C âˆˆC ) ï¬xed. The minimum over all possible choices of
vC is called the partitioned local generalized clique cover number
Ï• p
l (I ) =
min
(vCâˆˆR (C):CâˆˆC ) Ï† p
l (I , (vC âˆˆR(C) : C âˆˆC )).
The minimum of the LP relaxation of (14) over all possible choices of vC is called
the fractional partitioned local generalized clique cover number Ï• p
l f (I ).
Theorem 16 ([5]) There are achievable linear index codes corresponding to Ï• p
l (I )
and Ï• p
l f (I ) implying Î²(I ) â‰¤Ï• p
l f (I ) â‰¤Ï• p
l (I ).
The comparison between the parameter introduced in Sect.3.1 (see Fig.6) are no
more valid in this contest, as shown in the following remarks.

Index Coding, Network Coding and Broadcast with Side-Information
273
Remark 5 The parameters Ï• p and Ï• p
l are not comparable. From the parameters given
in [30] we have that there exist instances of the ICSI problem for which Ï• p(I ) â‰¥
Ï• p
l (I ). Now, consider the ICCSI instance with m = n = 3, q = 2, X (S) = F3
2.
V (1) = [0 1 1]
V (2) = [1 1 1]
V (3) = [1 1 1],
and R1 = 100, R2 = 010, R3 = 001.
In order to satisfy the request of a receiver using only one vector then the coding
vectors should be
â€¢ v1 = 100 or vâ€²
1 = 111 for User 1;
â€¢ v2 = 010 or vâ€²
2 = 101 for User 2;
â€¢ v3 = 001 or vâ€²
3 = 110 for User 3.
Then the set of all cliques is C = {{1}, {2}, {3}}. Moreover we can see that vi, vâ€²
i /âˆˆ
X (1) for all i. Now, if we consider the multicast group M = {1, 2, 3} we can note
that dM = 2 and that kM = 3 because none of the six vectors above is in the space
X (1). Then we have 2 = Ï• p(I ) â‰¤Ï• p
l (I ) = 3.
Remark 6 The parameters Ï• p and Ï• are not comparable. From the parameters given
in [30], there exist instances of the ICSI problem for which Ï•(I ) â‰¥Ï• p(I ). Now
consider the ICCSI instance with m = n = 2, q = 2, X (S) = F2
2.
V (1) = [1 1]
V (2) = [0 0],
and R1 = 10, R2 = 01. It is easy to check that using the multicast group partition
we need two transmissions, but it can be seen that {1, 2} is a clique and that v{1,2} =
01 âˆˆR({1, 2}), yielding 1 = Ï•(I ) â‰¤Ï• p(I ) = 2.
Remark 7 We have Ï• p
l (I ) â‰¤Ï•l(I ) â‰¤Ï•(I ). It is easy to check that Ï•l(I ) â‰¤
Ï•(I ) as k is at most equal to the number of cliques that form a partition of [m].
Then we have also Ï• p
l (I ) â‰¤Ï•l(I ). In fact, among the possible optimal solutions
we have those where M = [m] and in that case we obtain exactly Ï•l(I ).
It is possible to introduce a weak deï¬nition of clique. C âŠ†[m] is called weak
clique if for all i, j âˆˆC we have R j âˆˆX (i) or âŸ¨R jâŸ©= âŸ¨RiâŸ©. Using this deï¬nition,
it is possible to introduce the notion of a weak clique cover, local weak clique cover
and partitioned local weak clique cover with respective corresponding parameters
wÏ•(I ), wÏ•l(I ) and wÏ• p
l (I ) along with their fractional counterparts. Note that if
C is a weak clique then it is also a generalized clique. In fact we can encode the
message using the sum of distinct requests as vector vC.
Moreover from the deï¬nition of weak clique, if we consider a clique as a multicast
group M then it results dM = 1. Therefore Ï• p(I ) â‰¤wÏ•(I ) and the same holds for
the fractional parameters. However, also in this case, the partitioned local weak clique
cover and the partitioned multicast cover are not comparable (see example in Remark
5) (Fig.9).

274
E. Byrne and M. Calderini
Fig. 9 ICCSI bounds introduced in this section. Smaller quantities are placed to the left and the
weakest bound is placed to the rightmost of the ï¬gure. Arrows indicate the relationship they satisfy
4.2
Error Correction
Error correction in the index coding problem has been considered in [4, 14]. In this
model it is assumed that some erroneous packets have been transmitted among N
coded packets E(X), that is the users receive a transmission Y = E(X) + W, for
some error matrix W. The question is now to determine the shortest possible length
N of a linear index code such that each receiver can recover its demanded packet,
assuming that E(X) has been corrupted by noise.
This problem was introduced in [14] for the case of uncoded side information
and extended in [4] to include the coded-side information case. For the case of
Hamming errors, it is shown that ideas from classical coding theory can be adapted
to the linear index coding problem to obtain bounds on the transmission rate where
at most Î´ rows of E(X) have been affected by noise. For linear index codes, generic
decoding algorithms based on syndrome decoding can be applied. Rank-metric error
correction was also considered in [4]. In this exposition, for brevity we will describe
the Hamming case only.
The Hamming distance dH(Z, Zâ€²) between a pair of matrices Z, Zâ€² is the number
of non-zero rows of their difference Z âˆ’Zâ€², which is also the Hamming weight
wH(Z âˆ’Zâ€²).
The formal notion of a Î´-error correcting index code is as follows.
Deï¬nition 14 Let I be an instance of an ICCSI problem and let N be a positive
integer. We say that the map
E : FnÃ—t
q
â†’FNÃ—t
q
,
is a Î´-error correcting code for I of length N, and say that E is an (I , Î´)-ECIC, if
for each ith receiver there exists a decoding map

Index Coding, Network Coding and Broadcast with Side-Information
275
Di : FNÃ—t
q
Ã— X (i) â†’Ft
q,
satisfying
Di(E(X) + W, A) = Ri X
for all X, W âˆˆFNÃ—t
q
, wH(W) â‰¤Î´ for some vector A âˆˆX (i). E is called a linear
code for I , or an Fq-linear I -ECIC if E(X) = LV (S)X for some L âˆˆFNÃ—dS
q
, in
which case we say that L represents the linear (I , Î´)-ECIC E.
Theorem 17 Let I be an instance of an ICCSI problem and let N be a positive
integer. A matrix L âˆˆFNÃ—dS
q
represents a linear (I , Î´)-ECIC if and only if for all
i âˆˆ[m] it holds that
wH

LV (S)(X âˆ’Xâ€²)

â‰¥2Î´ + 1,
for all X, Xâ€² âˆˆM such that V (i)X = V (i)Xâ€², Ri X Ì¸= Ri Xâ€².
4.2.1
Bounds on the Transmission Rate of an (I , Î´)-ECIC
We denote by N (I , Î´) the optimal length of an Fq-linear Hamming metric (I , Î´)-
ECIC and by N(k, d) the optimal length â„“of an Fq-[â„“, k, d] code, i.e. a k-dimensional
Fq-linear code in Fâ„“
q of minimum Hamming distance d.
Deï¬nition 15 We denote by Î±(I ) the maximum dimension of any subspace U of
Fn
q such that every member u of U satisï¬es V (i)u = 0 and Riu Ì¸= 0 for some i âˆˆ[m].
That is,
Î±(I ) := max{dim U | U < Fn
q : âˆ€u âˆˆU \ {0}âˆƒi âˆˆ[m] s.t. V (i)u = 0, Riu Ì¸= 0}
Example 9 Let q = 2, m = 6, n = 4. Let
V (1) =
 1 0 1 0
0 0 0 1

, V (2) =
 1 0 0 0
0 0 1 1

, V (3) =
 1 0 0 0
0 1 0 0

,
V (4) =
 0 1 0 1
0 0 1 0

, V (5) =
 1 0 1 0
0 0 0 1

, V (6) =
0 1 0 0
0 0 0 1

,
and let the request vectors be given by
R1 = 1100, R2 = 0111, R3 = 1010, R4 = 1001, R5 = 0100, R6 = 1111.
Then the set of vectors of F4
q such that V (i)u = 0 and Riu Ì¸= 0 for some i âˆˆ[4] is
given by
{1000, 0100, 0010, 1010, 0101, 0011, 1101, 1110, 0111},

276
E. Byrne and M. Calderini
which, after including the zero vector, contains the subspace {0000, 1010, 0100,
1110}, and no larger subspace. It follows that Î±(I ) = 2.
Theorem 18 (Î±-bound) Let I be an instance of the ICCSI problem. Then
N(Î±(I ), 2Î´ + 1) â‰¤N (I , Î´).
The argument used in the proof of the Î±-bound may be sketched as follows. We
let CU := {LV (S)u : u âˆˆU} for U of maximum dimension as described above. If
L realizes an (I , Î´)-ECIC then CU is an Fq-linear [N, Î±, 2Î´ + 1] code, so that the
ECIC necessarily has length at least Î±(I ). We give sufï¬cient conditions for tightness
of the Î±-bound.
Let U âŠ¥denotes the orthogonal space of U with respect to the usual scalar product
in Fn
q.
Corollary 1 Let I be an instance of the ICCSI problem. If there exists a matrix
B âˆˆFÎ±(I )Ã—dS
q
satisfying BV (S)âŠ¥âˆ©V (i)âŠ¥âŠ‚Ri âŠ¥for all i âˆˆ[m] then
N(Î±(I ), 2Î´ + 1) = N (I , Î´).
Setting Î´ = 0 gives the following lower bound on the min-rank of an instance as
an immediate consequence of the Î±-bound and Corollary 1.
Corollary 2 Let I be an instance of the ICCSI problem. Then
Î±(I ) â‰¤Îº(I ),
with equality occurring if there exists L âˆˆFÎ±(I )Ã—dS
q
satisfying LV (S)âŠ¥âˆ©V (i)âŠ¥âŠ‚
Ri âŠ¥for all i âˆˆ[m].
Theorem 19 (Îº-bound) Let I be an instance of the ICCSI problem. Then
N (I , Î´) â‰¤N(Îº(I ), 2Î´ + 1).
In the proof of the Îº bound, a matrix realizing an (I , Î´)-ECIC is found as the
product L = L2L1 where L1 is a Îº(I ) Ã— dS matrix realizing an optimal I -IC and
the column space of L2 is an optimal Fq-[N, Îº(I ), 2Î´ + 1] code.
A Singleton-like bound is deduced by observing that deleting any 2Î´ rows of a
matrix L that realizes an (I , Î´)-ECIC results in an I -IC.
Theorem 20 (Singleton bound) Let I be an instance of the ICCSI problem. Then
Îº(I ) + 2Î´ â‰¤N (I , Î´).
Example 10 Let m = 6, n = 5, q = 2 and let X (S) = F5
q. Suppose that X (i) has
dimension di = 2 for each i âˆˆ{1, ..., 6}. Let I be the instance deï¬ned by user
side-information

Index Coding, Network Coding and Broadcast with Side-Information
277
V (1) =
 0 1 1 1 0
0 0 1 1 1

, V (2) =
 1 0 0 0 1
0 0 1 1 0

, V (3) =
 1 1 1 1 0
0 0 0 1 1

,
V (4) =
 1 0 0 1 0
0 1 1 1 1

, V (5) =
 0 0 1 1 0
0 0 0 1 1

, V (6) =
 1 0 0 1 0
0 0 1 1 0

,
and request vectors
R1 = 10000, R2 = 10000, R3 = 00101, R4 = 10001, R5 = 11000, R6 = 00111.
It can be checked that Îº(I ) = 3 and that Î±(I ) = 3. It follows from the Î±-
bound that 6 = N(3, 3) = N(Î±(I ), 3) â‰¤N (I , 1). From the Îº-bound we have
6 = N(3, 3) = N(Îº(I ), 3) â‰¥N (I , 1).
We construct a matrix L that realizes a 1-error correcting ECIC for this instance
as
L =
â¡
â¢â¢â¢â¢â¢â¢â£
10000
01000
00011
01011
11000
11011
â¤
â¥â¥â¥â¥â¥â¥â¦
=
â¡
â¢â¢â¢â¢â¢â¢â£
100
010
001
011
110
111
â¤
â¥â¥â¥â¥â¥â¥â¦
â¡
â£
10000
01000
00011
â¤
â¦= L2L1,
where L2 has column space a [6, 3, 3] binary linear code and L1 realizes an optimal
code I -IC.
If q â‰¥Îº(I ) + 2Î´ âˆ’1 then there exists an Fq-linear [q + 1, Îº(I ), 2Î´ + 1] opti-
mal code (in fact a maximum distance separable code), so the Îº and Singelton bounds
combine to give the following result.
Corollary 3 Let I be an instance of the ICCSI problem. If q â‰¥Îº(I ) + 2Î´ âˆ’1
then
N (I , Î´) = Îº(I ) + 2Î´.
We let Vq(n,r) denote the size of a Hamming sphere of radius r in Fn
q.
Theorem 21 Let I be an instance of the ICCSI problem. Let L âˆˆFNÃ—dS
q
be selected
uniformly at random over Fq. The probability that L corresponds to a Hamming
metric Fq-linear (I , Î´)-ECIC is at least
1 âˆ’
m

i=1
qnâˆ’diâˆ’1(q âˆ’1)Vq(N, 2Î´)
q N
.

278
E. Byrne and M. Calderini
In particular there exists an Fq-linear (I , Î´)-ECIC of length N if
N > n âˆ’d âˆ’1 + logq(m(q âˆ’1)Vq(N, 2Î´)),
where d = min{di : i âˆˆ[m]}.
Let Hq denote the q-ary entropy function:
Hq : (0, 1) â†’R : x â†’x logq(q âˆ’1) âˆ’x logq(x) âˆ’(1 âˆ’x) logq(1 âˆ’x).
It is well known that the function Hq(x) is continuous and increasing on (0, 1 âˆ’
(1/q)) and that Vq(n, Î»n) â‰¤q Hq(Î»)n [24].
Corollary 4 Let I be an instance of the ICCSI problem with. Let Î» âˆˆQ such
that 0 < Î» < 1 âˆ’1/q and let N âˆˆZ satisfy Î»N âˆˆZ Then, choosing the entries of
L âˆˆFNÃ—dS
q
uniformly at random over the ï¬eld Fq, the probability that L corresponds
to a Hamming metric Fq-linear (I , Î´)-ECIC, with Î´ =
 Î»N
2

, is at least
1 âˆ’(q âˆ’1)

iâˆˆË†m
q(nâˆ’diâˆ’1)
q N(1âˆ’Hq(Î»)) .
In particular there exists an Fq-linear Hamming metric (I , Î´)-ECIC if
m < q N(1âˆ’Hq(Î»))âˆ’(nâˆ’dâˆ’1)
q âˆ’1
,
where d = min{di : i âˆˆ[m]}.
Remark 8 TheÎ± andSingletonboundshaverank-metricanalogues,asdoesTheorem
21. The interested reader is referred to [4] for further details.
4.2.2
Decoding an (I , Î´)-ECIC
For the remainder of this section, we let L âˆˆFNÃ—dS
q
be a matrix corresponding to an
(I , Î´)-ECIC. Suppose that for some i âˆˆ[m] the ith user, receives the message
Y(i) = LV (S)X + W(i) âˆˆFNÃ—t
q
,
where LV (S)X is the codeword transmitted by S and W(i) is the error vector in FN
q .
Since Ri /âˆˆX (i), there exists an invertible matrix M(i) âˆˆFnÃ—n
q
such that
V (i)M(i) = [I|0] where I is the identity matrix in FdiÃ—di, and Ri M(i) = edi+1.

Index Coding, Network Coding and Broadcast with Side-Information
279
Now deï¬ne Xâ€² := Mâˆ’1
(i) X âˆˆFnÃ—t
q
. Then we have
V (i)
j X = e j Mâˆ’1
(i) X = Xâ€²
j for j âˆˆ[di]
and
Ri X = edi+1Mâˆ’1
(i) X = Xâ€²
di+1.
Let Lâ€² = LV (S)M(i) and let [s] := [n] \ [s]. Consider the following two codes. We
deï¬ne C (i)âŠ‚FN
q to be the column space of the matrix [Lâ€²di+1|Lâ€²[di+1]] âˆˆFNÃ—n
q
and
we deï¬ne C(i)âŠ‚FN
q to be the subspace of C (i) spanned by the columns of Lâ€²[di+1].
For each i âˆˆ[m], we have C(i) âŠ†C (i) with dim(C (i)) = dim(C(i)) + 1. As usual,
for an Fq-linear code C âˆˆFN
q we write CâŠ¥:= {y âˆˆFN
q : x Â· y = 0} to denote its
dual code. Then we have C (i)âŠ¥âŠ†C(i)
âŠ¥with ri = dim(C(i)
âŠ¥) = dim(C (i)âŠ¥) + 1 for
some ri. Let H(i) be a parity check matrix of C(i) of the form
H(i) =
 h(i)
H (i)

âˆˆFriÃ—N
q
,
(15)
where H (i) is a parity check matrix of C (i) and h(i) âˆˆC(i)
âŠ¥\ C (i)âŠ¥.
Then
H(i)Lâ€²di+1 = [sdi+1, 0, . . . , 0]T
for some sdi+1 âˆˆFq \ {0}.
We now outline a procedure for decoding the demand Ri X at the ith receiver,
which is based on syndrome decoding. In the ï¬rst step we compute syndrome, of H(i),
in which is embedded a syndrome of H (i). In the second step a table of syndromes
is computed for the code C (i). Finally, in the third step the output Ri X is computed.
Theorem 22 If wH(W(i)) â‰¤Î´ then Algorithm 3 has output Ë†Xdi+1 = Xâ€²
di+1 = Ri X.
Example 11 Let q = 2, m = n = 4, t = 1, Î´ = 1 and Ri = ei for all i âˆˆ[4] and
X (S) = F4
2.
Let the side-information for this instance be encoded according to the matrices:
V (1) =
 0 1 1 0
0 0 1 0

, V (2) =
 1 0 0 0
0 0 1 1

, V (3) =
 1 0 0 0
0 0 0 1

, V (4) =
 1 1 0 1
0 1 1 0

.
The vectors in F4
2 in V (i)âŠ¥\RâŠ¥
i for some i âˆˆ[4] comprise the set
S = {1001, 1000, 0111, 0100, 0010, 0110}.

280
E. Byrne and M. Calderini
Data: Erroneous Transmission Y(i) = LV (S)X + W(i) âˆˆFNÃ—t
q
Output: Requested data Ri X
Step I:
Compute
H(i)(Y(i) âˆ’Lâ€²[di ]Xâ€²
[di ]) =

Î±i
Î²i

âˆˆFri Ã—t
q
(16)
Step I I:
Find Îµ âˆˆFNÃ—t
q
with wH(Îµ) â‰¤Î´ such that
H(i)Îµ = Î²i âˆˆF(ri âˆ’1)Ã—t
q
.
(17)
Step I I I: Compute
Ë†Xdi +1 = (Î±i âˆ’h(i)Îµ)/sdi +1.
(18)
Result: Ri X = Ë†Xdi +1
Algorithm 3: Correcting Î´ erroneous packets
It is easy to check that Î±(I ) = 2 and Îº(I ) = 2, so from the Î± and Îº bounds we
have
N (I , 1) â‰¤N(Îº(I ), 3) = 5 = N(2, 3) = N(Î±(I ), 3) â‰¤N (I , 1).
We claim that the matrix
L =
â¡
â¢â¢â¢â¢â£
1 0 1 0
0 1 1 1
1 1 0 0
1 1 1 0
0 0 1 0
â¤
â¥â¥â¥â¥â¦
represents an optimal linear (I , 1)-ECIC. Since no element of S is in the null space
of L, any 4 Ã— t matrix Z satisfying V (i)Z = 0 and Ri Z Ì¸= 0 has at least one column
from S . Lv has weight at Hamming weight least 3 for any v âˆˆS , and hence L Z
has minimum Hamming weight at least 3.
Now suppose t = 1 and let X = [1111]T . The sender broadcasts L X. Suppose
one Hamming error occurs and U4 receives the vector
Y4 = L X + W(4) = [01010]T + [00010]T = [01001]T .
Let
M(4) =
â¡
â¢â¢â£
1 0 1 1
0 0 0 1
0 1 0 1
0 0 1 0
â¤
â¥â¥â¦
and
Lâ€² = LM(4) =
â¡
â¢â¢â¢â¢â£
1 1 1 0
0 1 1 0
1 0 1 0
1 1 1 1
0 1 0 1
â¤
â¥â¥â¥â¥â¦

Index Coding, Network Coding and Broadcast with Side-Information
281
We obtain a parity check matrix of C(4), as in (15)
H(4) =
â¡
â¢â¢â£
0 0 0 1 1
1 0 0 1 1
0 1 0 1 1
0 0 1 1 1
â¤
â¥â¥â¦.
Applying Step I of Algorithm 3 we obtain
H(4)(Y âˆ’Lâ€²[2]Xâ€²
[2]) =
â¡
â¢â¢â£
0 0 0 1 1
1 0 0 1 1
0 1 0 1 1
0 0 1 1 1
â¤
â¥â¥â¦
â¡
â¢â¢â¢â¢â£
1
1
1
1
1
â¤
â¥â¥â¥â¥â¦
=
â¡
â¢â¢â£
0
1
1
1
â¤
â¥â¥â¦.
Therefore Î±4 = 0 and Î²4 = [111]T . Now from Step II, we obtain that the vector
Îµ = [00001]T is a solution of (3) and in Step III we obtain
Ë†X3 = (0 âˆ’[00011] Â· [00001])/1 = 1 = X4.
5
Connections
The simplicity of the ICSI problem as a problem of multi-user communication, the
fact that it is a network with a single coding point or common link, has encouraged
many researchers to study capacity problems from the index coding point of view
[17, 18, 23, 27, 35, 38]. In this section we consider some connections of index
coding to other network communication problems.
5.1
Equivalence to Network Coding
The equivalence of the index and network coding problems is important, particularly
in relation to the fundamental question of determining the capacity of an arbitrary
network coding instance.
An instance of the index coding problem may be viewed as an instance of network
coding in which there is a single internal node of in-degree greater than one, i.e. a
single coding point, whose outgoing edge has some capacity cB, which represents
the broadcast rate. We illustrate this connection by an example shown in the Fig.5.1
below, where the index coding instance on the left is the same as that of Fig.1 and the
ï¬gure on the right is the corresponding network coding instance. The edges outgoing
from the source nodes all have unit capacity, whilst all other edges have capacity cB.
An edge joining an ith source node with a jth sink node (shown below in red) exists

282
E. Byrne and M. Calderini
S
has x1, x2, x3
1
has x3
requests x1
2
has x1, x3
requests x2
3
has x1, x2
requests x3
4
has x2
requests x1
edge capacities cB
x1
x2
x3
x1
x2
x3
x1
Fig. 10 Index coding as an instance of network coding
in the network coding representation if Receiver j possesses source xi as part of its
side-information (Fig.10).
This equivalence was described in [18, 19]. In [19] the authors establish this
equivalence for both scalar linear and vector linear coding, while in [18] is shown
that this equivalence holds in general. Explicitly, given a network coding instance, the
authors show how to reduce this to an index coding problem, showing that a solution
to the index coding problem also yields one for the network coding problem.
Recall that in describing an instance of index coding we have ï¬xed n as the number
of sources and m as the number of users. We give a slight generalization of the index
coding problem to describe this equivalence: we will assume now that each receiver
may demand more than one row of X. As noted before, this can be easily translated to
the problem of single requests by adding new users with identical side information.
An instance of the index coding problem is given by I = (X , R) where X =
(Xi : i âˆˆ[n]) for Xi âŠ‚[n] corresponding to the side infomation held by each ith
receiver and R = (Ri : i âˆˆ[m]) for Ri âŠ‚[n] corresponding to the requests of each
receiver.
Then I -IC is realized by (E, D) with D = {Di : i âˆˆ[m]} if
E : FnÃ—t
q
â†’FN
q and Di : FN
q Ã— F|X i|
q
â†’Ft
q
are maps such that
Di(E(X), XX i) = (X j : j âˆˆRi)
for each X âˆˆFnÃ—t
q
and i âˆˆ[m].
We now describe an instance of the network coding problem as a tuple I â€² =
(G, S,U, B), where G = (V , E ) is a directed acyclic graph, S is a set of source
nodes (those with in-degree 0), U is a set of receiver nodes (those with out-degree
0) and B is an |S| Ã— |U| matrix with entry Bu
s = 1 if receiver u requests data from
source s and 0 otherwise.
We let In(v) and In(e) deonte the edges incoming to a node v or an edge e.
Deï¬ne some local encoding functions F = {Fe : e âˆˆE } and decoding functions

Index Coding, Network Coding and Broadcast with Side-Information
283
Dâ€² = {Dâ€²
u : u âˆˆU} such that the arguments of Fe and Dâ€²
u respectively are the outputs
of edges incoming to e and u. The acyclic structure of G means that F yields a well-
deï¬nedsetofglobalencodingfunctions P = {Pe : e âˆˆE },sothat Pe(X)istheoutput
of edge e for any transmitted X = (Xs : s âˆˆS). More precisely, for any e âˆˆE , we
have
Pe(X) = Fe(Peâ€²(X) : eâ€² âˆˆIn(e)).
A network code for the instance I â€² is realized by (F, Dâ€²) if
Dâ€²
u(Pe(X) : e âˆˆIn(u)) = (Xs : Bu
s = 1),
that is, if the output of Dâ€²
u is (Xs : Bu
s = 1) for any transmitted X.
We now outline the reduction of a network coding instance I â€² to an index coding
instance I .
â€¢ n := |S| + |E |.
For any X âˆˆFnÃ—t
q
, the ï¬rst |S| rows of X are enumerated by S and the remaining
rows are enumerated by |E |.
â€¢ m := |U| + |E | + 1
The m receivers are given by the set {tu : u âˆˆU} âˆª{te : e âˆˆE} âˆª{t0}.
â€¢ Foreachu âˆˆU,assigntheside-informationXu := {e : e âˆˆIn(u)}andtherequests
Ru := {s : Bu
s = 1} to receiver tu.
â€¢ For each e âˆˆE , assign the side-information Xe := {eâ€² : eâ€² âˆˆIn(e)} and the request
Re = {e} to receiver te.
â€¢ Assign the side-information X0 := S and the requests R0 = E to receiver t0.
â€¢ N := |E |.
The main result of [18] shows that a network code (F, Dâ€²) exists for I â€² if and only
if an index code (E, D) of length N exists for I constructed from I â€² as outlined
above.
Let (F, Dâ€²) be network code for the instance I â€² with corresponding matrix B,
indicating the requests of each user u âˆˆU. For each edge e âˆˆE , the global encoding
functions Pe have argument X S and
Xe = Pe(X S) = Fe(Peâ€²(X S) : eâ€² âˆˆIn(e)).
The decoding functions Dâ€²
u satisfy
Dâ€²
u(Pe(X S) : e âˆˆIn(u)) = (Xs : Bu
s = 1),
for each u âˆˆU. Deï¬ne a map by
E : FnÃ—t
q
âˆ’â†’FNÃ—t
q
: X â†’E(X) := (Ee(X) : e âˆˆE ) = (Xe + Pe(X S) : e âˆˆE ).
WeclaimthatforeachreceiverofthecorrespondinginstanceI therehaveadecoding
map that outputs its request vector.

284
E. Byrne and M. Calderini
â€¢ For each u âˆˆU, deï¬ne
Du(E(X), XX u ) := Dâ€²
u((Ee(X) : e âˆˆXu) âˆ’XX u) = Dâ€²
u((Ee(X) : e âˆˆIn(u)) âˆ’XIn(u))
= Dâ€²
u(Xe + Pe(XS) âˆ’Xe : e âˆˆIn(u)) = Dâ€²
u(Pe(XS) : e âˆˆIn(u))
= (Xs : Bu
s = 1) = X Ru,
so receiver tu recovers its requested data.
â€¢ For each e âˆˆE , deï¬ne
De(E(X), XX e) := Fe((Eeâ€²(X) : eâ€² âˆˆXe) âˆ’XX e)
= Fe(Peâ€²(X S) : eâ€² âˆˆIn(e))
= Pe(X S) = Xe,
which is the data requested by te.
â€¢ For terminal t0, deï¬ne
D0(E(X), XX 0) := (Ee(X) : e âˆˆE ) âˆ’(Pe(XX 0) : e âˆˆE )
= (Xe + Pe(X S) : e âˆˆE ) âˆ’(Pe(X S) : e âˆˆE )
= XE ,
as requested by user t0.
Therefore the network code (F, Dâ€²) for I â€² yields an index code for the instance
I .
Conversely, suppose there is a code (E, D) of length N = |E | for the index
coding instance I . We will construct a code (F, Dâ€²) for the network coding instance
I â€². Given any Y âˆˆIm E âŠ‚FNÃ—t
q
, the existence of D0 means that for each W âˆˆ
F|S|Ã—t
q
there exists unique Z âˆˆFNÃ—t
q
satisfying D0(Y, W) = Z; equivalently, such
that E(W, Z) = Y.
Then choose Y âˆˆIm E. Let X S be the source data to be transmitted. Then XE =
(Xe : e âˆˆE ) := D0(Y, X S). For each e âˆˆE , deï¬ne recursively a local and global
encoding functions as follows.
â€¢ If e is incident with a source node s âˆˆS then
Xe = Pe(X S) = Fe(Xs) := De(Y, Xs) = Xs.
â€¢ For every e âˆˆE , deï¬ne
Xe = Pe(X S) = Fe(XIn(e)) := De(Y, XIn(e)).
So Fe(XIn(e)) = Fe(Peâ€²(X S) : eâ€² âˆˆIn(e)) for each e âˆˆE not incident with a source
node.

Index Coding, Network Coding and Broadcast with Side-Information
285
Fig. 11 The butterï¬‚y
network
s1
s1
u2
u1
e1
e2
e3
e4
e5
e6
e7
For each u âˆˆU, deï¬ne a decoding function:
Dâ€²
u(XIn(u)) := Du(Y, XIn(u)) = (Xs : Bu
s = 1).
The index code (E, D) for the instance I thus yields the network code (F, Dâ€²) for
the network coding instance I â€².
We summarize this in the following theorem, which is a simpliï¬ed version of
[18, Theorem 1], in which we assume constant rate of all sources and a zero-error
solution. The reader is referred to [18] for further details.
Theorem 23 Let I â€² be an instance of the network coding problem. Let I be the
corresponding instance of the index coding problem of length N. Then there exists
a network code for I â€² if and only if there exists an index code for I for the same
packet length t.
Example 12 We construct an index coding instance I from the instance of the
Butterï¬‚y Network, as shown below (Fig.11).
User 1 wants Y1 and User 2 wants Y2 for the sources transmitting Y1 and Y2
respectively, so B = I2.
â€¢ n := 2 + 7 = 9.
For any X âˆˆF7Ã—t
q
, the ï¬rst 2 rows of X are enumerated by {1, 2} and the remaining
rows are enumerated by {e1, ..., e7}.
â€¢ m := 2 + 7 + 1 = 10
We label the 10 receivers by the set {tu1, tu2, te1, ..., te7, t0}.
â€¢ The side infomation sets are given by:
Xu1 = {e4, e7}, Xu2 = {e1, e6}, Xe1 = Xe2 = {1}, Xe3 = Xe4 = {2},
Xe5 = {e2, e3}, Xe6 = Xe7 = {e5}, X0 = {1, 2}.
â€¢ The request sets are given by:
R0 = {e1, ..., e7}, Ru1 = {1}, Ru2 = {2}, Rei = {ei}, i âˆˆ[7].
â€¢ N := 7.

286
E. Byrne and M. Calderini
We remark that the set of all F2-linear feasible solutions for this index coding
problem are matrices with the same row space as one of the form
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
1 0 0 0 0 âˆ—0 0 âˆ—
0 1 âˆ—0 0 0 âˆ—0 0
âˆ—0 1 0 0 0 0 0 0
âˆ—0 0 1 0 0 0 0 0
0 âˆ—0 0 1 0 0 0 0
0 âˆ—0 0 0 1 0 0 0
0 0 0 âˆ—âˆ—0 1 0 0
0 0 0 0 0 0 âˆ—1 0
0 0 0 0 0 0 âˆ—0 1
âˆ—âˆ—1 1 1 1 1 1 1
â¤
â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¦
(19)
where âˆ—may be replace by an arbitrary element of F2. It can be checked that the least
F2-rank any such matrix may have is 7, so the optimal length of an F2-linear index
code of I is 7.
Of course there exists a linear network code over F2 for the instance I â€² illustrated
by the butterï¬‚y network. For Y âˆˆF2
2, the global encoding functions given by:
Pe1(Y) = Pe2(Y) = Y1, Pe3(Y) = Pe4(Y) = Y2, Pe5(Y) = Pe6(Y) = Pe7(Y) = Y1 + Y2
realize a a network code, with the decoding functions:
Dâ€²
u1(Y) = Pe7(Y) âˆ’Pe4(Y) = Y1 and Dâ€²
u2(Y) = Pe6(Y) âˆ’Pe1(Y) = Y2.
The claim is now that there exists a length 7 index code for the instance described.
Deï¬ne a map E : F9
2 âˆ’â†’F7
2 by
E(X) = (Ee1(X), ..., Ee7(X)), with Eei(X) := Xei + Pei(X1, X2).
A matrix representing the linear map E is given by
L =
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â£
1 0 1 0 0 0 0 0 0
1 0 0 1 0 0 0 0 0
0 1 0 0 1 0 0 0 0
0 1 0 0 0 1 0 0 0
1 1 0 0 0 0 1 0 0
1 1 0 0 0 0 0 1 0
1 1 0 0 0 0 0 0 1
â¤
â¥â¥â¥â¥â¥â¥â¥â¥â¦
,

Index Coding, Network Coding and Broadcast with Side-Information
287
which can be checked to be an F2-linear I -IC. For example,
Du1(L X, X{e4,e7}) = Dâ€²
u1(Le4 Â· X âˆ’Xe4, Le7 Â· X âˆ’Xe7)
= Dâ€²
u1(X2 + Xe4 âˆ’Xe4, X1 + X2 + Xe7 âˆ’Xe7)
= Dâ€²
u1(X2, X1 + X2) = X1 + X2 âˆ’X2 = X1,
which is the demand of tu1.
D0(L X, X{1,2}) = L X âˆ’(Pe(X{1,2}) : e âˆˆ{e1, ..., e7})
= L X âˆ’(X1, X1, X2, X2, X1 + X2, X1 + X2, X1 + X2)
= (Xe1, Xe2, Xe3, Xe4, Xe5, Xe6, Xe7),
which is the demand of t0.
Conversely, we know that the instance of the index coding problem I is real-
ized by a code of length 7; a linear one in fact. Let E(X) = L X for the matrix
L given above. Then the column space of [L1, L2] is contained in the column
space of [Le1, ..., Le7], so for any choice of X1, X2 there exist Xe1, ..., Xe7 such that
[L1, L2]X{1,2} = [Le1, ..., Le7]X{e1,...,e7}, i.e. such that L X = 0. Moreover, the exis-
tence of the decoding function D0 for t0 ensures that the Xe1, ..., Xe7 are uniquely
determined by X1, X2. The decoding functions for the index coding instance are
given by:
Du1(L X, Xe4,e7) = X1, Du2(L X, Xe1,e6) = X2, D0(L X, X1,2) = X{e1,...,e7}
De1(L X, X1) = Xe1, De2(L X, X1) = Xe2, De3(L X, X2) = Xe3, De4(L X, X2) = Xe4
De5(L X, Xe2,e3) = Xe5, De6(L X, Xe5) = Xe6, De7(L X, Xe5) = Xe7.
If we set L X = 0, then any pair X1, X2 âˆˆF2 determines a unique set of values
Xe1, ...Xe7, so we may deï¬ne the local encoding functions for the edges e1, ..., e7 by
Fe1(X1) = De1(0, X1) = Xe1, Fe2(X1) = De2(0, X1) = Xe2, Fe3(X2) = De3(0, X2) = Xe3,
Fe4(X2) = De4(0, X2) = Xe4, Fe5(X{e2,e3}) = De5(0, X{e2,e3}) = Xe5,
Fe6(Xe5) = De6(0, Xe5) = Xe6, Fe7(Xe5) = De7(0, Xe5) = Xe7.
The decoding functions for u1 and u2 are given by
Dâ€²
u1(X{e4,e7}) := Du1(0, X{e4,e7}) = X1 and Dâ€²
u2(X{e1,e6}) := Du2(0, X{e1,e6}) = X2.
The stronger version of the equivalence between network and index coding is
given by the following.
Theorem 24 ([18, Theorem 1]) Let I â€² be an instance of the network coding prob-
lem. Let I be the corresponding instance of the index coding problem with broadcast

288
E. Byrne and M. Calderini
rate cB. For any rate vector R, any integer t, and any Îµ â‰¥0 it holds that I â€² is (Îµ, Râ€², t)
feasible if and only if I is (Îµ, R, cB, t) feasible.
Here Râ€² = (Rs : s âˆˆS) âˆˆâ„œ|S| is a rate vector for I â€², indicating a transmission
rate of Rs for each source s âˆˆS, and R = (Râ€², ce : e âˆˆE ) âˆˆâ„œn represents a rate
vector for I , where ce is the capacity of edge e in the network. The quantity cB is
the sum of the edge capacities: cB = 
eâˆˆE ce. As before t is the block length. The
instance I â€² (respectively I ) is called (Îµ, Râ€², t)-feasible (respectively (Îµ, R, cB, t)-
feasible) if each terminal node can retrieve its required data with probability at least
1 âˆ’Îµ. The capacity region of the instance I â€² is the set of Râ€² such that for any Îµ, Î´ â‰¥0
the instance I â€² is (Îµ, (1 âˆ’Î´)Râ€², t)-feasible for some blocklength t.
In spite of the equivalence demonstrated in Theorem 24, it is not known whether or
not the network coding capacity region of I â€² can be obtained by solving the capacity
region of the index coding instance I . This is referred to as capacity equivalence.
While this equivalence holds for linear codes, and for certain network topologies the
question of capapcity equivalence for general networks is unknown. The question
has an interesting connection to the edge removal problem.
5.2
Interference Alignment
Interference alignment is a technique used to manage interfering signals between
multiple sender-receiver pairs sharing the same channel. It has applications to dis-
tributed storage problems in network coding [9]. Such interference is common
in wireless networks, where topological interference management (TIM) may be
viewed as an index coding problem, with multiple data streams competing for a
common communication link [23, 27]. The term alignment comes from the fact that
the method exploits communication differences between clients, so that alignment of
signals for one user may yield orthogonality at another. The index coding analogue
is that diversity of side information among different users means that even though
alignment occurs at the broadcast, different users can still decode their own different
demands. In several cases, as shown in [27], optimal solutions of the index coding
problem provide optimal solutions of the TIM problem. We brieï¬‚y outline how the
scalar-linear (t = 1) ICSI problem may be viewed as a TIM problem, as described
in [27].
A scalar-linear index coding scheme of length N for an instance I = (X , f )
can be described as follows. There are
â€¢ precoding vectors L1, ..., Ln âˆˆFNÃ—1
q
and
â€¢ for each pair (k,r = f (k)), receiver combining vectors Ur,k âˆˆF1Ã—N
q
, satisfying
Ur,kLi = 0 if i Ì¸= r and i /âˆˆXk and is non-zero if i = r.
The sender then transmits
L X = [L1, ..., Ln][X T
1 , ..., X T
n ]T .

Index Coding, Network Coding and Broadcast with Side-Information
289
If r = f (k) then User k retrieves its demand Xr via
(Ur,kLr)âˆ’1Ur,k(L X âˆ’

iâˆˆX k
Li Xi) = (Ur,kLr)âˆ’1Ur,k(

i /âˆˆX k
Li Xi)
=

i /âˆˆX k
(Ur,kLr)âˆ’1(Ur,kLi)Xi
= Xr +

i /âˆˆX k,iÌ¸=r
(Ur,kLr)âˆ’1(Ur,kLi)Xi
= Xr.
Choosing b(k) = (U f (k),kL f (k))âˆ’1U f (k),k and u(k) = (U f (k),kL f (k))âˆ’1U f (k),kLX k
yields a solution to the index coding problem as given in (4).
The alignment property corresponds to linear dependence among the columns
of L, which results in reduction of broadcast rate. If all columns of L are linearly
independent, N = n and the transmission rate is the same as for routing, that is,
where every transmitted symbol occupies a different time-slot. In TIM, the side-
information, Xi, of the ith user is called an antidote for the messages {X j, j âˆˆXi}.
User i uses its antidotes to effectively cancel |Xi| columns of L and to hence observe
a linear combination of n âˆ’|Xi| âˆ’1 interfering vectors in the column space of the
remaining columns of L, i.e. in the column space of L[n]\(X iâˆªf (i)). Therefore, a
necessary condition for decoding at the ith receiver is that the column space of
L f (i) has trivial intersection with the column space of L[n]\(X iâˆªf (i)). In particular,
resolvability for User i requires the dimension of the space spanned by the interfering
columns of L, those indexed by [n]\(Xi âˆªf (i)) should be no more than n âˆ’1, in
which case the interfering vectors must align in an n âˆ’1 dimensional space.
In Fig.5.2, the diagram on the left is the index coding instance shown already
in Fig.5.1. The image on the right is a related interference alignment problem. The
upper nodes represent transmitters and the lower nodes are receivers. In the TIM
graph shown a receiver node is connected to a sender node if the receiver lies within
the transmission range of the sender. In the corresponding index coding problem,
there is a link from a source node to a receiver if and only if it is absent in the TIM
graph (Fig.12).
An optimal solution to the toy index coding instance shown above (for which
receivers 1, ..., 4 demand X1, X2, X3, X1 respectively) is given by
L = [L1, L2, L3] =
 100
011

.
In the language of TIM, we say that there is alignment with respect to L2 and L3.
The vectors
U1,1 = [1 0],U2,2 = [0 1],U3,3 = [0 1],U4,1 = [1 0],

290
E. Byrne and M. Calderini
edge capacities cB
x1
x2
x3
x1
x2
x3
x1
S1
S2
S3
R1
R2
R3
R4
Fig. 12 Topological interference management and index coding
satisfy the conditions as described above, so each kth user can decode its demand
X f (k). For example,
X f (1) =

[1 0]
 1
0

[1 0]
â›
â
 100
011
 â¡
â£
X1
X2
X3
â¤
â¦âˆ’X3
 0
1
â
â = X1
5.3
The Coded Caching Problem
The canonical coded-caching problem [28] corresponds to the placement phase of
a special class of the instances (C , R), as introduced in Sect.2. First it is assumed
that the n packets of X comprise k blocks X(i), ..., X(k) of size â„“(so that n = kâ„“)
and that each ith user wants some complete block, say X( j), after delivery. So Ri is
an ri Ã— n matrix of the form
Ri = [O Â· Â· Â· H Â· Â· Â· O]
for some ri Ã— â„“matrix H with standard basis vectors of length â„“as rows. Each user
has a subset of some number of packets from each block and the same number of
packets v in total. In terms of (C , R), this imposes the constraints that for each i,
â€¢ V (i) is an v Ã— n matrix,
â€¢ Ri and V (i) have standard basis vectors as rows,
â€¢ the jth block of â„“columns of V (i) has some â„“âˆ’ri standard basis vectors of length
â„“as columns that complete H to a basis of Fâ„“
q.
If a subset of users wish to receive the same block, the delivery to that set of users
becomes a local multicast problem.
The main difference between the coded-caching problem and the index coding
problem is the role of the sender in the placement phase. The index coding problem

Index Coding, Network Coding and Broadcast with Side-Information
291
is essentially one of delivery for given (C , R); the placement is not necessarily
controlled by the sender. However, in the coded caching problem, we seek an optimal
placement of the side-information code C in advance of knowing the usersâ€™ request
matrix R. The sender tries to choose C in such a way that for any R all usersâ€™ demands
can be met with a small number of transmissions. More precisely, the coded caching
problem seeks to ï¬nd, or obtain bounds on:
min{max{Îº(R, C ) : R âˆˆFrÃ—n
q
} : C = C1 âŠ•Â· Â· Â· Cm, dimCi = riv}.
In [28] the authors use the cut-set bound to derive a lower bound on the optimal
storage memory rate trade-off. Furthermore, they devise a scheme that achieves
this rate within a constant factor. So asymptotically, the canonical coded caching
problem is solved. Moreover, it was shown in [39] that improvements to the scheme
presented in [28] can only be achieved by considering caching schemes with coded
side-information.
For example, the matrices V (i) may have rows that are not standard basis vectors,
which corresponds to the cache data (the side-information) being encoded. Then Ci
is an arbitrary nv-dimensional matrix code for each i. In [35] the authors propose a
scheme for coded-caching with coded side-information using MDS and rank metric
codes. Their scheme delivers an improvement in the memeory-rate trade-off of sev-
eral known schemes and are in some cases optimal. However, their scheme requires
large ï¬eld sizes.
References
1. N. Alon, A. Hassidim, E. Lubetzky, U. Stav, A. Weinstein, Broadcasting with side information,
in Proceedings 49th Annual IEEE Symposium on Foundation of Computer Science (FOCS)
(2008), pp. 823â€“832
2. Z. Bar-Yossef, Z. Birk, T.S. Jayram, T. Kol, Index coding with side information, in Proceedings
of 47th Annual IEEE Symposium Foundations of Computer Science (2006), pp. 197â€“206
3. Z. Bar-Yossef, Z. Birk, T.S. Jayram, T. Kol, Index coding with side information. IEEE Trans.
Inf. Theory 57(3), 1479â€“1494 (2011)
4. E. Byrne, M. Calderini, Error correction for index coding with coded side information, in
IEEE Transactions on Information Theory, vol. 63(6), published online, 27 March 2017, pp.
3712â€“3728. https://doi.org/10.1109/TIT.2017.2687933
5. E. Byrne, M. Calderini, Bounding the Optimal Rate of the ICSI and ICCSI Problems, SIAM
J. Discret. Math. 31(2), 1403â€“1427 (2017). arXiv:1604.05991
6. Y. Birk, T. Kol, Informed source coding on demand (ISCOD) over broadcast channels, in
Proceedings of IEEE Conference on Computer Communication (San Francisco, CA, 1998),
pp. 1257â€“1264
7. A. Blasiak, R. Kleinberg, E. Lubetsky, Broadcasting with side information: bounding and
approximating the broadcast rate. IEEE Trans. Inf. Theory 59(9), 5811â€“5823 (2013)
8. Z. Chen, P. Fan, K.B. Letaief, Fundamental limits of caching: improved bounds for users with
small buffers. IET Commun. 10(17), 2315â€“2318 (2016)
9. V.R. Cadambe, S.A. Jafar, H. Maleki, K. Ramchandran, C. Suh, Asymptotic interference align-
ment for optimal repair of MDS codes in distributed storage. IEEE Trans. Inf. Theory 59(5),
2974â€“2987 (2013)

292
E. Byrne and M. Calderini
10. E.J. CandÃ¨s, B. Recht, Exact matrix completion via convex optimization. Found. Comput.
Math. 9(6), 717â€“772 (2009)
11. T.H. Cormen, C. Stein, R.L. Rivest, C.E. Leiserson, Introduction to Algorithms, 2nd edn.
(McGraw-Hill Higher Education, New York, 2001)
12. M. Dai, K.W. Shum, C.W. Sung, Data dissemination with side information and feedback. IEEE
Trans. Wireless Commun. 13(9), 4708â€“4720 (2014)
13. S.H. Dau, V. Skachek, Y.M. Chee, On the security of index coding with side information. IEEE
Trans. Inf. Theory 58(6), 3975â€“3988 (2012)
14. S.H. Dau, V. Skachek, Y.M. Chee, Error correction for index coding with side information.
IEEE Trans. Inf. Theory 59(3), 1517â€“1531 (2013)
15. S.H. Dau, V. Skachek, Y.M. Chee, Optimal index codes with near-extreme rates. IEEE Trans.
Inf. Theory 60, 1515â€“1527 (2014)
16. P. ErdÃ¶s, Z. FÃ¼redi, A. Hajnal, P. Komjaâ€™th, V. RÃ¶dl, A. Seress, Coloring graphs with locally
few colors. Discret. Math. 59(1), 21â€“34 (1986)
17. H. Esfahanizadeh, F. Lahouti, B. Hassibi, A matrix completion approach to linear index coding
problem, in Information Theory Workshop (ITW) (IEEE, 2014), pp. 531â€“535
18. M. Effros, S. El Rouayheb, M. Langberg, An equivalence between network coding and index
coding. IEEE Trans. Inf. Theory 61(5), 2478â€“2487 (2015)
19. A. El Rouayheb, A. Sprintson, C. Georghiades, On the index coding problem and its relation
to network coding and matroid theory. IEEE Trans. Inf. Theory 56(7), 3187â€“3195 (2010)
20. M. Fazel, H. Hindi, S. Boyd, Rank minimization and applications in system theory in American
Control Conference, vol. 4 (IEEE, 2004), pp. 3273â€“3278
21. W. Haemers, An upper bound for the Shannon capacity of a graph. Colloq. Math. Soc. JÃ nos
Bolyai 25 (1978)
22. X. Huang, S. El Rouayheb, Index coding and network coding via rank minimization, in IEEE
Information Theory Workshop (ITW) (2015), pp. 14â€“18
23. S.A. Jafar, Topological interference management through index coding. IEEE Trans. Inf. The-
ory 60(1), 529â€“568 (2014)
24. H. Loeliger, An upper bound on the volume of discrete spheres. IEEE Trans. Inf. Theory 40(6),
2071â€“2073 (1994)
25. N. Lee, A.G. Dimakis, R.W. Heath Jr, Index coding with coded side-information. IEEE Com-
mun. Lett. 19(3)(2015)
26. Eyal Lubetzky, Uri Stav, Nonlinear index coding outperforming the linear optimum. IEEE
Trans. Inf. Theory 55(8), 3544â€“3551 (2009)
27. H. Maleki, V.R. Cadambe, S.A. Jafar, Index coding - an interference alignment perspective.
IEEE Trans. Inf. Theory 60(9), 5402â€“5432 (2014)
28. M. Maddah-Ali, U. Niesen, Fundamental limits of caching. IEEE Trans. Inf. Theory 60(5),
2856â€“2867 (2014)
29. R. Peeters, Orthogonal representations over ï¬nite ï¬elds and the chromatic number of graphs.
Combinatorica 16(3), 417â€“431 (1996)
30. K. Shanmugan, A. Dimakis, M. Langberg, Graph theory versus minimum-rank for index cod-
ing, in Proceedings of the 2014 IEEE International Symposium on Information Theory (ISIT)
(2014), pp. 291â€“295. arXiv:1402.3898.v1
31. J. Saunderson, M. Fazel, B. Hassibi, Simple algorithms and guarantees for low rank matrix
completion over F2. IEEE Int. Symp. Inf. Theory (ISIT). Barcelona 2016, 86â€“90 (2016)
32. D. Silva, F.R. Kschischang, R. Koetter, Communication over ï¬nite-ï¬eld matrix channels. IEEE
Trans. Inf. Theory 56(3), 1296â€“1305 (2010)
33. K.W. Shum, D. Mingjun, C. Sung, Broadcasting with coded side information. 2012 IEEE 23rd
Int. Symp. Pers. Indoor Mobile Radio Commun. (PIMRC) 89(94), 9â€“12 (2012)
34. V.Y.F. Tan, L. Balzano, S.C. Draper, Rank minimization over ï¬nite ï¬elds: fundamental limits
and coding-theoretic interpretations. IEEE Trans. Inf. Theory 58(4), 2018â€“2039 (2012)
35. C. Tian, J. Chen, Caching and delivery via interference elimination, in 2016 IEEE International
Symposium on Information Theory (ISIT) (2016), pp. 830â€“834

Index Coding, Network Coding and Broadcast with Side-Information
293
36. A.S. Tehrani, A.G. Dimakis, M.J. Neely, Bipartite index coding, in Proceedings of the IEEE
2012 International Symposium on Information Theory (ISIT) (Boston, 1-6 Jul 2012), pp. 2246â€“
2250
37. J.I. Tamir, E.R. Elenberg, A. Banerjee, S. Vishwanath, Wireless index coding through rank
minimization, in IEEE ICC 2014 - Wireless Communications Symposium (2014), pp. 5209â€“
5214
38. M.F. Wong, M. Langberg, M. Effros, On a capacity equivalence between network and index
coding and the edge removal problem, in 2013 IEEE International Symposium on Information
Theory (2013), pp. 972â€“976
39. K. Wan, D. Tuninetti, P. Piantanida, On the optimality of uncoded cache placement, in 2016
IEEE Information Theory Workshop (ITW) (2016), pp. 161â€“165
40. K. Shanmugam, A.G. Dimakis, M. Langberg, Local graph coloring and index coding, in 2013
IEEE International Symposium on Information Theory Proceedings (ISIT) (2013), pp. 1152â€“
1156
41. P. Jain, P. Netrapalli, S. Sanghavi, Low-rank matrix completion using alternating minimization,
in Proceedings of the forty-ï¬fth annual ACM symposium on Theory of computing (ACM, 2013),
pp. 665â€“674
42. M. Hardt, Understanding alternating minimization for matrix completion, in IEEE 55th Annual
Symposium on Foundations of Computer Science (FOCS) (2014), pp. 651â€“660

Implementation of Network Coding
in Wireless Systems
Semiha Tedik Basaran, Ali Reza Heidarpour, Selahattin Gokceli,
Gunes Karabulut Kurt, Murat Uysal and Ibrahim Altunbas
Abstract In this chapter, we target to give extensive performance analyses about
application of network coding (NC) in wireless systems, referred to as network
coded cooperation (NCC), brings both diversity and multiplexing gains. We use
the diversity-multiplexing trade-off (DMT) to determine performance bounds of
NCC systems. Within the scope of this study, NCC is integrated with orthogo-
nal frequency division multiple access (OFDMA) and the corresponding system
model is characterized by speciï¬cally focusing on frequency diversity gain. DMT
expressions of the NCC-OFDMA system is given. A real-time implementation of
the NCC-OFDMA system is presented by creating a testbed NI USRP-2921, NI
PXIe-5644R, NI PXI-6683H software deï¬ned radio (SDR) modules and LabVIEW
software. Obtained real-time performance measurements are essential to demon-
strate the practical advantages or disadvantages of the usage of the NCC-OFDMA
system. Overall, we aim to present a detailed overview of the fundamental perfor-
mance bounds of NCC and its extension to the practical applicability of NCC in
wireless networks.
S. Tedik Basaran (B) Â· S. Gokceli Â· G. K. Kurt Â· I. Altunbas
Department of Communications and Electronics Engineering, Istanbul Technical University,
3469 Istanbul, Turkey
e-mail: tedik@itu.edu.tr
S. Gokceli
e-mail: gokcelis@itu.edu.tr
G. K. Kurt
e-mail: gkurt@itu.edu.tr
I. Altunbas
e-mail: ibraltunbas@itu.edu.tr
A. R. Heidarpour
Department of Electrical and Computer Engineering, University of Alberta, Edmonton,
AB T6G 2R3, Canada
e-mail: alirezaheidarpour@ualberta.ca
M. Uysal
Department of Electrical and Electronics Engineering, Ozyegin University,
34794 Istanbul, Turkey
e-mail: murat.uysal@ozyegin.edu.tr
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_11
295

296
S. Tedik Basaran et al.
1
Introduction
In classical routing applications, intermediate nodes simply store and forward the
received symbol to the destinations or other intermediate nodes without modifying
the content of received packets. As 5G and beyond 5G communication technologies
target high data rate and low delay demands based on real-time applications in dense
network scenarios, the efï¬cient usage of network resources (bandwidth, power, and
time) becomes critical at intermediate nodes to jointly increase the throughput and
reduce the delay. Network coding (NC) is proposed as a smart routing solution which
meets high throughput and low latency demands [1].
The transmission process of NC systems is completed in two orthogonal phases;
the broadcast phase and the relaying phase. In the broadcast phase, information
symbols are radiated from source nodes and received by intermediate nodes (referred
to relay nodes hereafter). Relay nodes typically decode the received symbols and
combine symbols from multiple sources to obtain network coded symbols. In the
relaying phase, each relay node determines the NC coefï¬cients based on the selected
coding type for all symbols and encodes the detected source symbols. Then, relay
nodes forward the encoded symbols to destination nodes. Each destination node
needs to receive several coded symbols, at least as many as the number of source
nodes, to successfully decode the transmitted symbols.
In classical routing schemes, relay nodes sequentially send the received symbols,
which may cause a high delay and a low data rate. Hence, by using NC, the data
rate can be increased while obtaining low transmission latency. NC has a ï¬‚exible
nature for an extension to multiple source and multiple relay cases by determining
different code sets for each relay. Hence, we can use NC as a smart routing tool, by
efï¬ciently serving dense network users, furthermore it can be used as a solution for
the scalability problem in dense networks. We focus on linear NC in this chapter, but
there are also some works about non-linear mapping schemes on received bits [2].
The application of NC in wireless networks inherently holds one advantage and
one disadvantage. Firstly, there may be direct links that may be used to provide
an improved error performance, between source and destination pairs due to the
broadcast nature of wireless channel. On the other hand, error propagation may
emerge at destination node due to wireless channel impairments. Whether a direct
link, also termed as cooperation link, is present or not depends on the corresponding
link qualities. These links provide additional cooperative diversity to improve the
error performance [3]. Hence, when the implementation of NC in wireless networks
is designed by considering cooperation links, the system is named as network coded
cooperation (NCC). NCC has higher diversity gain and increased spectral efï¬ciency
when compared to NC with the help of cooperation links.
Wireless networks are more prone to transmission errors when compared to wired
counterparts due to channel impairments. In the early works on NC, only error-free
cases are considered [1]. Although this is a valid assumption for wired networks,
it is not realistic for wireless networks. As mentioned above, different from NC,
in NCC, destination nodes use the source symbols that are received through direct

Implementation of Network Coding in Wireless Systems
297
links in the broadcast phase to improve the error performance. Hence, destination
nodes have multiple received symbols in both broadcast and relaying phases. The
symbols received in the relaying phase are encoded by using the selected network
code. A combining procedure at destination nodes needs to be used to exploit full
diversity. As the combining procedure, there are two frequently used detector types;
the rank-based detector [4] and the maximum likelihood (ML) [5] detector.
Diversity-multiplexing trade-off (DMT) is a tool that determines the set of diver-
sity and multiplexing gain pairs that can be obtained simultaneously for commu-
nication systems. DMT can be used to assess the performance of NCC systems.
The asymptotic DMT of NCC systems is studied in [6, 7]. These works focus on
time-division multiple access (TDMA) to preserve orthogonality among different
source and relay transmissions. On the other hand, [8] considers an efï¬cient multi-
ple access technique, orthogonal-frequency division multiple access (OFDMA), to
provide orthogonality while providing frequency diversity gain. This system model
is called as NCC-OFDMA.
The theoretical DMT results of NCC-OFDMA system which is superior accord-
ing to benchmark systems is presented in [8]. In [9], an NCC-OFDMA framework is
established to evaluate its performance by using software deï¬ned radio (SDR) nodes.
The results show that NCC-OFDMA system enables easy implementation and pro-
vides higher reliability against wireless channel errors, leading to higher throughput
when compared to its NC counterpart. Through implementation, real-time issues are
analyzed and insights about a more comprehensive deployment are shared.
The aim of this chapter is to show with theoretical analysis and practical applica-
tion scenarios, that NCC is a strong candidate for next generation wireless systems.
We address the theoretical performance bounds of NCC through DMT analyses and
highlight practical application challenges with real-time implementation by using
SDR nodes. In order to evaluate the system performance, bit error rate (BER), error
vector magnitude (EVM) and signal-to-noise ratio (SNR) metrics are used.
The rest of this chapter is organized as follows. In Sect.2, the signalling model
of NCC-OFDMA system and coding details are given. After that, DMT results of
NCC system are given in comparison with the state-of-the-art studies in Sect.3. In
Sect.4, implementation and test results of NCC-OFDMA system are presented. The
beneï¬ts of NCC-OFDMA are emphasized in Sect.5.
2
Basic Principles
System models of NC and NCC are given in Fig.1 a, b, respectively. Both two
systems include P source nodes, M relay nodes, and a single destination node. The
main advantage of NCC different from NC is the exploitation of direct transmission
links between source and destination pairs, as shown in the ï¬gure. In the linear NC
system, the destination node has M network-coded symbols, composed of linear
combinations of P source symbols. In order to recover all P source symbols, the
destination node needs at least P symbols, hence, we need to satisfy P â‰¤M the

298
S. Tedik Basaran et al.
(a)
(b)
Fig. 1 a Block diagram of NC system. b Block diagram of NCC system with the presence of direct
source to destination links
constraint in an NC system. On the other hand, this necessity is eliminated due to the
presenceofdirecttransmissionlinksintheNCCsystem.Thedirecttransmissionlinks
assist the relay-aided communication by providing additional cooperative diversity
gain.
NCC systems using TDMA strategy are generally planned for multiple users. To
exploit frequency diversity gain while ensuring orthogonality among multiple users,
OFDMA technique is considered for multiple access for NCC systems, referred to
as NCC-OFDMA. The transmission process of the NCC-OFDMA system is also
completed in two orthogonal phases: broadcast and relaying phases. In the broadcast
phase, all source nodes emit their own signals. The signals of the sources can be
captured jointly by the relay nodes and the destination node because of the broadcast
nature of wireless channel. In the wireless systems, the transmission qualities of
source-relay links are generally considered to be higher than the source-destination
links. Therefore, the subcarrier assignment process is performed according to the
attributes of the source-destination links. Following the broadcast phase, the relay
nodes demodulate the signals when they received during the broadcast phase and
combine them by using the coefï¬cients of the selected network code. The combined
symbols formed at the relay nodes are called network coded symbols. After that, in
the relaying phase, relay nodes transmit the network coded symbols to the destination
nodes.
Let the frequency domain representation of the nth subcarrier channel gain of link
t be given by Ht[n], where t âˆˆ{sid, sir j, r jd}, i = 1, . . . , P, j = 1, . . . , M, n âˆˆ
Ft with Ft is the set of the assigned subcarriers of the transmitter of link t. The number
of subcarriers is equal to N. All transmissions are carried out with unit power in the
system. The received signal from jth relay node of ith source node in the broadcast
phase is given as:
Ysir j[n] = Hsir j[n]Xi[n] + Wsir j[n],
(1)
where Wsir j[n] represents the additive white Gaussian noise (AWGN) at the jth
relay node. jth relay node detects Xi[n] by using Ysir j[n], and the detected symbol

Implementation of Network Coding in Wireless Systems
299
is denoted by ËœXi j[n]. The network code coefï¬cients indicated by Î±i j can be selected
from a maximum distance separable (MDS) code satisfying the Singleton bound
[10], maximum rank distance (also called Gabidulin) codes [11] or can be generated
randomly in random network coding (RNC). By using ËœXi j[n] and Î±i j values the
network coded symbol at jth relay node is calculated as:
C j[n] = Î±1 j ËœX1 j[n]âœ¢Î±2 j ËœX2 j[n] . . . , âœ¢Î±Pj ËœX Pj[n]
(2)
where âœ¢denotes the summation operator in the ï¬eld, GF(q), where q is the size of
the ï¬eld. Source and network coded signals received by the destination node in two
phases from the source and relay nodes are deï¬ned as follows:
Ysid[n] = Hsid[n]Xi[n] + Wsid[n]
Yr jd[n] = Hr jd[n]C j[n] + Wr jd[n],
(3)
where AWGN components at the destination node in the broadcast and relaying
phases are denoted by Wsid[n] and Wr jd[n], respectively.
If we assume error-free transmission among source-relay pairs, ( ËœXi j = Xi), to
simplify the expressions, the vector notation of received signals can be given as:
â¡
â¢â¢â¢â¢â¢â¢â¢â¢â¢â¢â£
Ys1d
Ys2d
...
YsPd
Yr1d
...
YrMd
â¤
â¥â¥â¥â¥â¥â¥â¥â¥â¥â¥â¦
=
â¡
â¢â¢â¢â£
a1 0 Â· Â· Â· 0
Î±11 Â· Â· Â· Î±1M
0 a2 Â· Â· Â· 0
Î±21 Â· Â· Â· Î±2M
...
... ... ...
...
...
...
0 0 Â· Â· Â· aP Î±P1 Â· Â· Â· Î±PM
â¤
â¥â¥â¥â¦
T â¡
â¢â¢â¢â£
X1
X2
...
X P
â¤
â¥â¥â¥â¦,
(4)
which can be also expressed as y = Zx. The ï¬rst P entries of y represent the received
symbols of the direct transmission links among source and destination nodes. If the
ith direct transmission link is available, ai is equal to 1, otherwise it is equal to 0. Î±i j
is generated from GF(q) according to the current coding scheme in the relay nodes.
The last M entries of y denote the received encoded symbols from M relay nodes.
Z indicates the global coding matrix of NCC, consisting of direct link and relay link
coefï¬cients. The aim of destination node is to recover x from y thanks to Z. Detailed
explanations and comparisons about signal modeling of NC and NCC can be found
in [12]. We explain the detection methods of NCC in detail to show effect of the
detector on the system in the next subsection.

300
S. Tedik Basaran et al.
2.1
Detector Design
There are two receiver strategies of NC depending on the availability of the global
coding matrix (Z) at destination node: coherent and non-coherent NC. Most of NC
and NCC works assume that destination node knows the coding coefï¬cients [4, 13],
andthisstrategyisnamedascoherentNC.Ontheotherhand,ifcodingcoefï¬cientsare
not available at the destination node, the destination node can obtain the coefï¬cients
through transmitting pilot symbols. This second approach is called non-coherent
NC [14]. In order to recover source symbols, a new coding metric based on sub-
spaces is proposed against erasures and errors of non-coherent RNC. To obtain x,
Gaussâ€“Jordan elimination method can be used to solve the set of linear equations of
NCC over GF(q) [4, 13]. To apply Gaussâ€“Jordan elimination for obtaining P source
symbols, we need at least P independent equations. This condition corresponds to
Z to be of full rank. In addition to performance corruptions due to wireless channels
as mentioned above, incorrect estimations of Xi at relay nodes may cause error
propagation at destination node.
2.2
Code Design
Coding coefï¬cients, Î±i j, can be selected from different linear code sets like as MDS
[10], maximum rank distance (also called Gabidulin) codes [11] or be produced
randomly [4, 13]. MDS codes achieve equality in Singleton bound [11], and are
preferred in different applications as error correction and storage. MDS codes are
accepted as an important coding class due to their capabilities about error detection
and error correction based on the Hamming distance criterion. The redundancy-
reliability ratio of MDS codes is the optimal.
The other class of coding includes rank distance approach. In the rank distance
approach, the code construction is based on detecting and correcting of rank errors
by supplementing redundancy [11]. Instead of selecting from predetermined code
sets, in RNC, network code coefï¬cients can be generated randomly. In RNC, cod-
ing coefï¬cients have a uniform distribution and independently chosen from GF(q).
RNC yields ï¬‚exible scheduling opportunity to NCC systems based on dynamically
changing network components with improving the efï¬ciency of the NCC systems.
To obtain more information about the dynamic coding according to wireless channel
can be found in chapter â€œOpportunistic Network Codingâ€.
2.3
On the Resource Usage of NCC
In both NC and NCC, broadcast and relaying phases are completed in P and M
orthogonal transmission blocks, respectively. TDMA, which causes undesired delay
for dense networks, can be used to provide orthogonality between transmission links.
On the other hand, multiplexing gain can be obtained by allocating transmission

Implementation of Network Coding in Wireless Systems
301
links in frequency domain thanks to OFDMA. At the same time, OFDMA provides
additional frequency diversity gain through assigning different subcarriers to users
according to channel quality of each subcarrier to the corresponding user. There are
also joint resource allocation schemes to unify assigning of various limited resources
as power, subcarrier, and bits. Employing subcarrier allocation processes can improve
the efï¬ciency of the system. The comparative theoretical performance bounds of
various NCC schemes will be assessed in the following section by providing DMT
results.
3
Performance Limitations and DMT Analysis of NCC
Due to occurence at the same time, there is a fundamental trade-off referred to as
DMT between diversity and multiplexing gains of a communication systems. DMT
is an appropriate tool to evaluate performance of NCC-OFDMA system.
3.1
DMT of NCC Systems and Comparison with Cooperative
Communication Protocols
Figure2 depicts diversity gain d versus multiplexing gain r for various cooperative
communication protocols. It is known that conventional cooperative (CC) systems
including space-time coding [3] and opportunistic relaying [15] achieve the same
DMT of d(r) = (M + 1)(1 âˆ’2r), r âˆˆ(0, 0.5).
In [6], Peng et al. consider a NCC system which consists of P source-destination
pairs and M relay nodes with dynamic coding (DC-NCC). Particularly, the â€œbestâ€
relay (which has the best end-to-end path between source and destination) among the
set of M available relay nodes are selected and then the relay dynamically employs
XOR operation on the source packets based on instantaneous source to relay channel
quality. It is shown that the DC-NCC system can achieve a full diversity gain of
M + 1. However, diversity gain of M + 1 can only be obtained under the assumption
where the destination can successfully overhear the data from other source nodes. If
this optimistic assumption is removed, the achievable diversity gain of the DC-NCC
system reduces to only two and does not improve by increasing the number of relay
candidates.
In an effort to improve the diversity gain, random NCC (RNCC) system and
deterministic NCC (DNCC) system are presented in [7], where relay nodes encode
the sourcesâ€™ packets using an encoding matrix of size (P + M) Ã— P. As described
in the previous section, in this setup, the ï¬rst P rows form an identity sub-matrix,
corresponding to the direct transmissions in the broadcasting phase. In addition, the
remaining columns and rows correspond to the packets transmitted by relays in the
relaying phase. In DNCC system the coefï¬cients in the encoding matrix are preset
while in RNCC system are drawn randomly from ï¬nite ï¬eld. The associated DMT

302
S. Tedik Basaran et al.
1
P
P
P
P
M
1
0.5
r
( )
d r
1
M
2
1
Non-Cooperative
Repetition Coding
DC-NCC
DNCC, RNCC
CC 
Space-Time Coding,
 Opportunistic Relaying
1
1
M
Ideal
Fig. 2 DMT comparison for different cooperative communication protocols
analysis reveals that a full diversity gain of M + 1 can be maintained through the
use of MDS codes typically used for point to point channels.
The DMT expressions of DC-NCC and DNCC/RNCC systems are given in [7].
As can be seen from Fig.2, CC and RNCC/DNCC systems can achieve full diversity
gain of M + 1 whenr = 0. However, DNCC/RNCC systems outperform CC systems
in terms of multiplexing gain and offer higher diversity gain than that of CC systems
for the same spectral efï¬ciency. On the other hand, in comparison to other schemes,
DC-NCC systems have the highest multiplexing gain and offer more diversity gain
as r increases. This is due to the fact that only one relay XORâ€™es source packets
and therefore the overall transmission takes place in P + 1 orthogonal time slots. It
is worth mentioning that as P increases the spectral efï¬ciency of the NCC systems
movestowardstheidealcase.Therefore,NCCsystemshavebetterDMTperformance
and outperform CC systems. On the other hand, repititon coding which is based on
simply repeating the data bits, has the worst DMT performance.
3.2
Extension to CC-OFDMA
In CC systems, relay nodes either amplify and transmit (amplify-and-forward relay-
ing) or decode and retransmit (decode-and-forward relaying) the source signals to
the destination without any combining operation. It is shown that both protocols can
achieve full diversity gains [16] and therefore CC with OFDMA, referred to as CC-

Implementation of Network Coding in Wireless Systems
303
OFDMA systems are expected to extract both frequency and spatial diversity. In the
literature, DMT performance of CC-OFDMA system has been studied in [17]. The
underlying assumption in [17] is that the subcarriers are independent. Furthermore,
just one subcarrier is allocated to each source node. The derived DMT expression is
given by [17]
d(r) = N(M + 1)(1 âˆ’2r),r âˆˆ(0, 0.5).
(5)
The maximum diversity gain is obtained when multiplexing gain r = 0, i.e., N(M +
1). This means that both frequency and spatial diversity can be achieved in CC-
OFDMA. On the other hand, the maximum multiplexing gain can be obtained when
d(r) = 0, i.e., r = 0.5.
3.3
Extension to NCC-OFDMA
The aforementioned NCC systems [6, 7] build upon the assumption of TDMA. To
exploit the multipath diversity gains and have further gains over NCC systems, the
combination of OFDM with NCC has been investigated in the literature. More specif-
ically, in [8] the DMT performance of NCC-OFDMA system is studied. In the system
under consideration, the transmission rate for all nodes is equal to R0. There is L
number of coherence bandwidths due to the frequency selective channel. Further-
more, K1 = N/P and K2 = N/M are the numbers of subcarriers assigned to each
source and each relay in the broadcasting phase and the relaying phase, respectively.
This leads to different transmission rates for subcarriers in these two phases i.e.,
Rs1 = R0/K1 for the broadcasting phase and Rs2 = R0/K2 for the relaying phase.
By using Marcum Q-function of order one represented by Q1(Â·, Â·), the outage prob-
abilities of subcarriers in the broadcasting phase for S â†’D links over Rician fading
channels are given by [8]
Pout SD
sub (K1) = 1 âˆ’Q1 (Î±, Î²SD) ,
(6)
where Î± =
âˆš
2k and Î²SD =

2 (1 + k)
	
2Rs1 Ë†N âˆ’1

 
Ï GSD. Ï is SNR and G XY is
normalized path loss expressions with respect to S â†’D links. Similarly, for S â†’R
links, the outage probability of the subcarriers is given by
Pout SR
sub (K1) = 1 âˆ’Q1 (Î±, Î²SR) ,
(7)
where Î²SR =

2 (1 + k)
	
2Rs1 Ë†N âˆ’1

 
Ï GSR.
In Eqs.(6) and (7), k is Rician factor, Ë†N is the number of subcarriers within the
coherence bandwidth while calculating as Ë†N=N/L. On the other hand, the outage
probability of subcarriers in the relaying phase (i.e., R â†’D links) can be obtained as

304
S. Tedik Basaran et al.
Pout RD
sub (K2) = 1 âˆ’Q1 (Î±, Î²RD) ,
(8)
where Î²RD =

2 (1 + k)
	
2Rs2 Ë†N âˆ’1

 
Ï G RD.
3.4
Relaying Strategies
Relay nodes which successfully decode all of their received packets from P source
nodes are allowed to participate in the relaying phase and the rows of the encoding
matrix corresponding to the relays with erroneous decisions are discarded. The DMT
expression of NCC-OFDMA system is given by [8]
d(r) =L(M + 1)

1 âˆ’P + M
P
max {P, M}
L
r

, r âˆˆ

0,
P
P + M
L
max {P, M}

.
(9)
As expected, NCC-OFDMA systems are capable to fully extract both frequency
and spatial diversity and signiï¬cantly outperform NCC systems which build upon
TDMA. The DMT of CC-OFDMA system with the same system conï¬guration is
given by [8]
d (r) = L (M + 1)

1 âˆ’(M + 1) max{P, M}
L
r

, r âˆˆ

0,
1
M + 1
L
max{P, M}

where all relay nodes transmit in the relaying phase or
d (r) = L (M + 1)

1 âˆ’2max{P, M}
L
r

, r âˆˆ

0, 0.5
L
max{P, M}

where selection relaying is considered. As can be seen from Fig.3, both CC-OFDMA
and NCC-OFDMA systems achieve full diversity gain of L(M + 1) when r = 0.
However, maximum multiplexing gain of CC-OFDMA systems is always lower than
that of NCC-OFDMA systems indicating multiplexing gain loss in CC systems.
As another transmission strategy, if relay can decode even one packet correctly
from one of P source packets, it is allowed to participate in the relaying phase. In
this case, only the coefï¬cients in the encoding matrix corresponding to the erroneous
packets would be zero instead of discarding the whole row. Let Popt
out denote the
outage probability of the system under this assumption. A lower bound on the outage
probability Plow
out is the case when all the relays decode all P packets correctly and can
participate in the relaying phase i,e., m = 0 (see Eq.(14) of [8]) and the probability
that any relay successfully decodes all P packets received during the broadcasting
phase PR is equal to 1. Therefore, Pout in (16) of [8] is reduced to

Implementation of Network Coding in Wireless Systems
305
0.5 max{ ,
}
L
P M
r
( )
d r
NCC-OFDMA 
 CC-OFDMA
 (Relay Selection)
CC-OFDMA 
(All Relays Participate)
(
1)
L M +
+
1
   1 max{ ,
}
L
M
P M
  
max{ ,
}
P
L
P
M
P M
+
Fig. 3 DMT comparison for CC-OFDMA and NCC-OFDMA systems
Plow
out =
M

j=0
M
j

P Mâˆ’j
outRD

1 âˆ’PoutRD
 j
Pâˆ’1âˆ’j

i=0
P
i

P Pâˆ’i
outSD

1 âˆ’PoutSD
i .
(10)
The lower bound of the outage probability in high SNR regime can be obtained as
lim
Î²â†’0 Plow
out = Câ€²

exp

âˆ’Î±2
2
 Î²2
2
L(M+1)
,
(11)
where Câ€² = M
j=0
M
j

P
Pâˆ’1âˆ’j

Gâˆ’L(Mâˆ’j)
RD
Gâˆ’L( j+1)
SD
.
Note that, Plow
out < Popt
out < Pout. Using squeezing theorem [18], we have
L(M + 1) < âˆ’lim log(Popt
out )
log(Ï)
< L(M + 1).
(12)
Therefore, one can conclude that the slopes of outage probability in log-log scale
for Plow
out , Popt
out , and Pout are identical and the achievable diversity gain of the system
remains the same regardless of which relaying strategy is used. Therefore, the DMTs
under two relaying strategies are identical.

306
S. Tedik Basaran et al.
4
Practical Implementation of NCC
NCC-OFDMA system gives full diversity gain when multiplexing gain is equal
to zero and maximum multiplexing gain performance among the other fundamen-
tal systems while no diversity gain. In order to test its high theoretical capability,
the real time implementation of NCC-OFDMA system is necessary. To perform
the implementation of NCC-OFDMA system, SDR implementation is used. SDR
implementations of various wireless communication techniques have been realized
recently. This trend continues to grow because of the beneï¬ts of SDR implemen-
tations over simulations. Modeling a transmission environment in simulation is not
realistic in most cases because hardware related issues show random characteristics
at each transmission and appropriate modeling of these becomes impossible.
CC structure that is inherent to NCC systems, may complicate the implementation
of NCC models in real-time. Such an implementation requires the realization of
multiple nodes in addition to proper communication between these nodes. As a
natural consequence of these requirements, accurate synchronization of these nodes
is a must in order to operate them cooperatively. Beyond these necessities, a ï¬‚exible
design is also necessary to deploy algorithms to hardware without any problem.
In order to create a functional NCC testbed, an SDR based testbed is implemented
in [9] by considering the mentioned aspects. A testbed was created for the real-time
implementation of proposed NCC model in order to observe performance from a dif-
ferent perspective and validate simulation results. As SDR components, LabVIEW,
NI USRP-2921 nodes, NI PXI-6683H module, and NI PXIe-5644R Vector Signal
Transceiver (VST) are used. NCC testbed is implemented with 5 NI USRP-2921 SDR
nodes where three of them are used as source nodes and other two nodes are used as
destination. We used two physically separated receivers to seperately examine their
performances. For relay node, NI PXIe-5644R VST module is utilized which can
operate in 65MHz to 6GHz frequency range and can support 80MHz instantaneous
bandwidth. Moreover, NI PXI-6683H timing and synchronization module which
includes a TCXO oscillator is used as synchronization source. All PXI modules are
managed via NI PXIe-1082 chassis. LabVIEW is used as software tool due to its
easy programming and SDR compatibility features.
As an expected necessity, NCC testbed needs a proper synchronization solution
for the robust performance due to its cooperative setup. Main component of this
solution is NI PXI-6683H module which provides 10MHz clock signal. This signal
is distributed to one destination and two source nodes via RF cables. Other nodes
receive this signal with MIMO cables from synchronized nodes. Due to initial con-
nection of VST module to the chassis, relay node is also synchronized with the same
synchronization resource. One drawback of this setup is the limitation of distances
between nodes due to limited lengths of cables. These cables are used because of
their sufï¬cient RF performances, longer cables have higher losses. This limitation
makes observing the effects of different distances on the system performance difï¬-
cult, however we overcome this drawback by conï¬guring source gains properly. By
conï¬guring the hardware in LabVIEW code, synchronization solution is generated.

Implementation of Network Coding in Wireless Systems
307
In hardware side, RF cables are used to distribute synchronization signals to two
sources and one destination. Remaining pairs receive these signals via pair-wise
cables. In the software side, these cable connections are indicated by conï¬guring
corresponding settings and a code is used in order to start and manage the distribu-
tion of synchronization signals. For source, relay and destination functionalities, the
codes are prepared for each operation in LabVIEW. NCC related functions are also
implemented and necessary codes are prepared. In the end, a ï¬‚exible combination
of codes is obtained, where possible modiï¬cations about algorithm can easily be
realized.
A physical view of the testbed is shown in Fig.4. The measurement parameters of
the given implementation setup are deï¬ned in Table1. It can be seen from Fig.4 that
physical distances between nodes are limited in the testbed. However, conï¬gured
distances as well as transmission gains provide realistic transmission environment.
Therefore,aproperbalancebetweendistanceandrealistictransmissionisempirically
determined and nodes are located accordingly. It is noteworthy to state that during
experiments, distances between nodes were longer, distances between source and
destination nodes were around 250cm. Particularly low transmission gains provide
more realistic transmission circumstances. In this case, a limited distance up to 1m is
sufï¬cient to separate nodes and obtain realistic transmission qualities which are also
veriï¬ed with real-time experiments. It should be highlighted that two experimenta-
tion setups are considered. These two setups are differentiated with the link quality
between source and destination nodes, and relayâ€™s transmission quality. In the ï¬rst
setup, source nodes have a lower path loss, and transmission quality between source
and relay as well as destination nodes is sufï¬cient, as will be shown via measurement
results. However, in the second setup source nodes cannot properly communicating
Fig. 4 Created testbed of NCC system

308
S. Tedik Basaran et al.
Table 1 The measurement parameters of the given setup
Carrier frequency
2.45 GHz
I/Q data rate
Megasamples/sec
Number of bits used in one frame
2080 bits
Number of 4-QAM symbols
1040 samples
Total number of subcarriers of the one user data
portion
320 samples
Number of reference subcarriers
40 samples
Number of source nodes
3
Number of relay node
1
Number of destination nodes
2
Zero padding length
120 samples
DFT length (N)
1200 samples
CP length samples
300
with destination nodes. Moreover, relayâ€™s link quality is subject to a higher path loss,
when compared to the ï¬rst setup. When experiment results are evaluated, transmis-
sion gain levels also need to be considered with distance conï¬gurations.
4.1
Software Description
As mentioned, code of NCC-OFDMA system is prepared by using LabVIEW. In Lab-
VIEW, smaller code fragments known as subVIs are used to increase functionality.
Hence, the code includes several SubVI components for source, relay and destina-
tion nodes which are managed from a timed ï¬‚ad structure. Relay network coding
SubVI implements network coding to data received by relay node and includes cor-
responding GF(4) multiplication and addition SubVI. In this SubVI, ï¬rstly received
source symbols from source nodes by the relay node are multiplied with correspond-
ing coefï¬cients iSR that represent whether data is received properly or not by the
relay node. Then these multiplication outputs are multiplied with Î±i j in GF(4) by
using GF(4) multiplication SubVI. The coding matrix consists of Î±i j which can be
deï¬ned as:
Z =
â¡
â£
1 0 0 1 0 0
0 1 0 0 1 0
0 0 1 1 1 1
â¤
â¦
T
.
(13)
Note that although only a single physical device is used as a relay node, there are three
linear components of the received source symbols are generated at the relay node.
Then, results of these are summed in GF(4) by using GF(4) addition SubVI for
each data loop. In result, three separate network coded symbols are obtained which
are transmitted by relay nodeâ€™s transmitter in corresponding frequency resources.

Implementation of Network Coding in Wireless Systems
309
Fig. 5 Block diagram of the relay network coding SubVI
In multiplication and addition SubVI, GF(4) multiplication and addition tables are
implemented by using multiple array functions and case structures. An exemplary
view of relay network coding SubVI can be seen in Fig.5. With corresponding input-
output conï¬gurations, NCC-OFDMA code is obtained.
In order to measure the performance of our system, real-time tests are exper-
imented. As explained earlier, two different setups are created, where difference
between the setups are the different distance conï¬gurations between nodes. The
quality of each link between nodes is measured. Both NC and NCC results are mea-
sured to compare their performances. The results of all types of links are shown in
this section, except source-relay links because of their superior performances. For
measuring the link performance, EVM, SNR and BER metrics are measured for each
link. EVM and SNR metrics are measured in terms of percentage and dB respec-
tively, and given with these units in the tables. The EVM value of the ith source for
single OFDMA frame can be calculated as:
EV Mi =

1
|Fsi d|

nâˆˆFsi d
	
Ii[n] âˆ’ËœIi[n]

2
+
	
Q[n] âˆ’ËœQ[n]

2
|vmax|
,
(14)
where Ii[n] ( ËœIi[n]) and Qi[n] ( ËœQi[n]) denote the real and imaginary components of
the Xi[n] ( ËœXi[n]). |Fsid| represents the cardinality of the subcarrier set, where |vmax|
denotes the maximum absolute value of Xi[n].
For the ï¬rst setup, three different relay transmit gain levels are experimented
for each destination nodes. Because of directional differences between source-
destination pairs due to location differences, error performance of the sources can be
quite different from each other. In order to approximate error performances, source
gains are selected differently for each source node. However, diversiï¬ed source per-
formances can provide more comprehensive results. Therefore, locations and gains
of sources are organized in a way that clear performance differences can be observed.
The source transmission gains of S1, S2 and S3 are set as 14, 8 and 6 dB respec-
tively.Thesegainshavenotbeenchangedduringtheexperiments.Asstated,theeffect

310
S. Tedik Basaran et al.
of source gain changes on the overall performance is observed with two setups. Each
one has a different location-gain adjustment. As the ï¬rst step, ï¬rst setup is experi-
mented. Firstly, source-destination link performances are evaluated to analyze per-
formance differences between source nodes. For D1, S2 has the worst transmission
performance where the S1 is the best one, as demonstrated in Table3. EVM and
BER results can be used for this analysis. EVM and BER results are obtained as
26.71% and 1.5 Ã— 10âˆ’3 for the data transmitted by the S2 where results are lower for
the S1 nodeâ€™s transmitted data, which are 15.09% and 1 Ã— 10âˆ’6 respectively. SNR
results show similar differences, which can be observed from the Table3. EVM,
BER and SNR metrics are obtained as 18.73%, 4.5 Ã— 10âˆ’4 and 14.82 dB for the data
transmitted by S3. As explained, transmission gains of source nodes are not changed
during each setup, however, usage of two different setups allows us to understand
the effect of different source node gains on the performance. This effect will be dis-
cussed when source-destination link performances of the second setup will be given.
If similar error performance evaluation is done for the D2, it can be observed from
the Table3 that S2 has the worst transmission performance and S1 has the best trans-
mission performance similar to results obtained for the D1. One difference is the fact
that error performance is slightly better for the S2, however, this is not valid for other
source nodes and their transmission performances slightly worse for the D2. EVM
and BER results for the transmission of S2 are obtained as 25.11% and 1.3 Ã— 10âˆ’3
respectively. These values are obtained as 16.15% and 6 Ã— 10âˆ’5 for the transmission
of S1 and 19.02% and 7 Ã— 10âˆ’4 for the transmission of S3. Secondly, error perfor-
mance results of relay-destination links are obtained which are shown in Table2, and
performance results for the overall NC and NCC operations are obtained as in Table4.
Table 2 Relay-destination performances for the ï¬rst setup
Destination
Source
BER
EVM
SNR
D1
S1
1 Ã— 10âˆ’6
15.09
15.72
S2
1.5 Ã— 10âˆ’3
26.71
13.39
S3
4.5 Ã— 10âˆ’4
18.73
14.82
D2
S1
6 Ã— 10âˆ’5
16.15
15.31
S2
1.3 Ã— 10âˆ’3
25.11
13.40
S3
7 Ã— 10âˆ’4
19.02
14.38
Table 3 Source-destination link performances for the ï¬rst setup
Destination
Relay gain (dBm) BER
EVM
SNR
D1
âˆ’12
1 Ã— 10âˆ’7
13.60
18.80
âˆ’16
1.6 Ã— 10âˆ’4
15.59
15.57
âˆ’20
4.2 Ã— 10âˆ’3
33.01
10.40
D2
âˆ’12
0
8.91
18.13
âˆ’16
9 Ã— 10âˆ’5
14.71
16.50
âˆ’20
1 Ã— 10âˆ’3
25.60
12.12

Implementation of Network Coding in Wireless Systems
311
Table 4 NC and NCC performances for the ï¬rst setup
Destination
Source
Relay gain (dBm) NC-BER
NCC-BER
D1
S1
âˆ’12
1.4 Ã— 10âˆ’4
0
âˆ’16
5.5 Ã— 10âˆ’4
2 Ã— 10âˆ’5
âˆ’20
3.6 Ã— 10âˆ’3
2.7 Ã— 10âˆ’4
S2
âˆ’12
8.6 Ã— 10âˆ’4
4.7 Ã— 10âˆ’4
âˆ’16
1.3 Ã— 10âˆ’3
8 Ã— 10âˆ’4
âˆ’20
6.5 Ã— 10âˆ’3
3.3 Ã— 10âˆ’3
S3
âˆ’12
3.3 Ã— 10âˆ’4
1.9 Ã— 10âˆ’4
âˆ’16
5.5 Ã— 10âˆ’4
3.4 Ã— 10âˆ’4
âˆ’20
6 Ã— 10âˆ’3
8 Ã— 10âˆ’4
D2
S1
âˆ’12
0
0
âˆ’16
2.9 Ã— 10âˆ’5
1 Ã— 10âˆ’6
âˆ’20
7 Ã— 10âˆ’4
4 Ã— 10âˆ’5
S2
âˆ’12
6 Ã— 10âˆ’4
6 Ã— 10âˆ’4
âˆ’16
8 Ã— 10âˆ’4
1 Ã— 10âˆ’4
âˆ’20
1.7 Ã— 10âˆ’3
8 Ã— 10âˆ’4
S3
âˆ’12
0
0
âˆ’16
7.9 Ã— 10âˆ’5
1.4 Ã— 10âˆ’5
âˆ’20
1.1 Ã— 10âˆ’3
4 Ã— 10âˆ’4
For the D1, at âˆ’12 dBm relay transmit gain, EVM results for the relay-destination
links are obtained as 13.29, 13.74 and 13.78% respectively. BER results for the same
components are obtained as 1 Ã— 10âˆ’7 on average. At the same relay transmit gain,
NC operationâ€™s BER results for the transmissions of S1, S2 and S3 are obtained as
1.4 Ã— 10âˆ’4, 8.6 Ã— 10âˆ’4 and 3.3 Ã— 10âˆ’4 respectively. When compared to the source-
destination link results, slight performance improvement can be observed. However,
NCC operation improves error performances further, where these error performances
for the source nodes are obtained as 0, 4.7 Ã— 10âˆ’4 and 1.9 Ã— 10âˆ’4 respectively. As
shown, NCC operation is quite effective and error performance for the transmission
of ï¬rst source node decreases to 0.
For the âˆ’16 dBm relay transmit gain, relay-destination link EVM results are
obtained as 15.14, 16.07 and 15.57% respectively. BER performance of the same
links are obtained as 1.6 Ã— 10âˆ’4 on average. At the same conï¬guration, NC opera-
tionâ€™s BER results increase and obtained as 5.5 Ã— 10âˆ’4, 1.3 Ã— 10âˆ’3 and 5.5 Ã— 10âˆ’4
respectively. BER values decrease with the NCC operation, obtained as 2 Ã— 10âˆ’5,
8 Ã— 10âˆ’4 and 3.4 Ã— 10âˆ’4 respectively.
For the âˆ’20 dBm relay transmit gain, error performances decrease further. For
this gain, BER results for the relay-destination links are obtained as 4.2 Ã— 10âˆ’3 on
average and EVM results are obtained as 32.38, 32.66 and 34% respectively. At this
gain, BER results for the NC operation are obtained as 3.6 Ã— 10âˆ’3, 6.5 Ã— 10âˆ’3 and
6 Ã— 10âˆ’3 respectively. Better performances are observed with NCC operation where

312
S. Tedik Basaran et al.
BER results are obtained as 2.7 Ã— 10âˆ’4, 3.3 Ã— 10âˆ’3 and 8 Ã— 10âˆ’4 respectively. It
is clear that performances of relay transmissions are critical for robust NC or NCC
operation and if low relay transmit gain is used, reliable performance cannot be
obtained.
For the D2, at âˆ’12 dBm relay transmit gain, BER results of NC operation for
the transmissions of S1 and S3 are obtained as 0, where related value is 6 Ã— 10âˆ’4
for the S2. NCC operation does not create any improvement, as the same BER val-
ues are obtained. Error performance results are better for the D2, compared to the
D1. This is due to better relay-destination link performances which create effective
improvements. EVM results of relay-destination links are obtained as on average
8.91% and transmissions are completed without any bit error in these links. At
the âˆ’16 dBm relay transmit gain, BER results of NC operation are obtained as
2.9 Ã— 10âˆ’5, 8 Ã— 10âˆ’4 and 7.9 Ã— 10âˆ’5 for source nodes, respectively. For these relay
experiments, NCC operation creates clear performance improvements as correspond-
ing BER values are obtained as 10âˆ’6, 1 Ã— 10âˆ’4 and 1.4 Ã— 10âˆ’5 respectively. EVM
results are obtained as 14.71% and BER results are obtained as 9 Ã— 10âˆ’5 on average
for relay-destination link transmissions. At the âˆ’20 dBm relay transmit gain, for
relay-destination links, EVM results and BER results are obtained as 25.6% and
1 Ã— 10âˆ’3 on average, respectively. At the same gain, BER results of NC operation
are obtained as 7 Ã— 10âˆ’4, 1.7 Ã— 10âˆ’3 and 1.1 Ã— 10âˆ’3 for source nodes, respectively.
Moreover, BER results of NCC operation are obtained as 4 Ã— 10âˆ’5, 8 Ã— 10âˆ’4 and
4 Ã— 10âˆ’4 respectively and clear performance improvements are observed. In result,
when compared to the previous results, relay-destination links are important espe-
cially for NCC operationâ€™s performance and certain improvements can be observed.
As a common observation, as relay transmission performance becomes better, NC
and NCC operations can decrease source-destination errors effectively.
As mentioned, one more setup is conï¬gured in order to create worse source-
destination and relay-destination link performances compared to the ï¬rst setup. For
this setup, two relay transmit gains are experimented because, performance results
of good relay transmit gain levels are evaluated in the ï¬rst setup and relay transmit
gain can be decreased to the minimum of âˆ’15 dBm, conï¬gurations below this value
results in poor performance results. It is noteworthy that gain level is a parameter
conï¬gured in the LabVIEW, performance of relay or source nodes should also be
evaluated by considering distances to destination nodes.
Asï¬rststep,source-destinationlinkperformancesaremeasuredwhicharedemon-
strated in Table5. For the D1, again, worst performance is performed by the S2 and the
S1 has the best performance. BER results for source nodes are obtained as 7 Ã— 10âˆ’4,
2.2 Ã— 10âˆ’3 and 1 Ã— 10âˆ’3 respectively. Similarly, EVM results for source nodes are
obtained as 29.20, 35.64 and 34.97% respectively. SNR results verify error perfor-
mances and obtained as 11.41, 10.61 and 10.66 dB respectively. Same measure-
ments are also performed for the D2. BER results for source nodes are obtained as
2.3 Ã— 10âˆ’3, 3.6 Ã— 10âˆ’3 and 4.6 Ã— 10âˆ’3 respectively. EVM measurement is also per-
formedandEVMresults areobtainedas 31.05, 35.45and39.11%respectively. More-
over, SNR values are measured as 11.16, 10.09 and 9.67 dB respectively. Therefore,
it is clear that S3 has the worst performance where the S1 has the best performance.

Implementation of Network Coding in Wireless Systems
313
Table 5 Source-destination link performances for the second setup
Destination
Source
BER
EVM
SNR
D1
S1
7 Ã— 10âˆ’4
29.20
11.41
S2
2.2 Ã— 10âˆ’3
35.64
10.61
S3
1 Ã— 10âˆ’3
34.97
10.66
D2
S1
2.3 Ã— 10âˆ’3
31.05
11.16
S2
3.6 Ã— 10âˆ’3
35.45
10.09
S3
4.6 Ã— 10âˆ’3
39.11
9.67
Table 6 Relay-destination performances for the second setup
Destination
Relay gain (dBm) BER
EVM
SNR
D1
âˆ’13
3 Ã— 10âˆ’5
14.64
17.08
âˆ’15
7 Ã— 10âˆ’4
18.59
14.55
D2
âˆ’13
8 Ã— 10âˆ’5
19.29
14.29
âˆ’15
2.5 Ã— 10âˆ’3
22.05
13.13
Table 7 NC and NCC performances for the second setup
Destination
Source
Relay gain (dBm) NC-BER
NCC-BER
D1
S1
âˆ’13
3 Ã— 10âˆ’5
1 Ã— 10âˆ’5
âˆ’15
7 Ã— 10âˆ’4
3 Ã— 10âˆ’4
S2
âˆ’13
5.3 Ã— 10âˆ’4
5 Ã— 10âˆ’4
âˆ’15
1.7 Ã— 10âˆ’3
5 Ã— 10âˆ’4
S3
âˆ’13
5 Ã— 10âˆ’4
4.6 Ã— 10âˆ’4
âˆ’15
1.6 Ã— 10âˆ’3
1 Ã— 10âˆ’3
D2
S1
âˆ’13
3 Ã— 10âˆ’4
1.7 Ã— 10âˆ’4
âˆ’15
2.5 Ã— 10âˆ’3
1 Ã— 10âˆ’3
S2
âˆ’13
5 Ã— 10âˆ’4
2.5 Ã— 10âˆ’4
âˆ’15
3.5 Ã— 10âˆ’3
1.2 Ã— 10âˆ’3
S3
âˆ’13
6.5 Ã— 10âˆ’4
3 Ã— 10âˆ’4
âˆ’15
4.2 Ã— 10âˆ’3
2.4 Ã— 10âˆ’3
As second step, performances of relay-destination links with error performance
results for the overall NC and NCC operations are measured as shown in Tables6 and
7. For the D1, at âˆ’13 dBm relay transmit gain, BER results of the NC operation are
obtained as 3 Ã— 10âˆ’5, 5.3 Ã— 10âˆ’4 and 5 Ã— 10âˆ’4 respectively. With NCC operation,
these performances are improved and results are obtained as 1 Ã— 10âˆ’5, 5 Ã— 10âˆ’4
and 4.6 Ã— 10âˆ’4 respectively. BER results and EVM results for relay-destination
links are measured as 3 Ã— 10âˆ’5 and 14.64% on average. For the same setup, at
âˆ’15 dBm relay transmit gain, BER results of the NC operation are obtained as
7 Ã— 10âˆ’4, 1.7 Ã— 10âˆ’3 and 1.6 Ã— 10âˆ’3 respectively. Similarly, NCC operationâ€™s BER
results are measured as 3 Ã— 10âˆ’4, 5 Ã— 10âˆ’4 and 1 Ã— 10âˆ’3 respectively. When relay-

314
S. Tedik Basaran et al.
destination link performances are measured, BER and EVM results are obtained as
7 Ã— 10âˆ’4 and 18.59% on average. Same observations are also done for the D2. At âˆ’13
dBm relay transmit gain, BER results for NC operation are measured as 3 Ã— 10âˆ’4,
5 Ã— 10âˆ’4 and 6.5 Ã— 10âˆ’4 respectively. Accordingly, BER results for NCC operation
areobtainedas1.7 Ã— 10âˆ’4,2.5 Ã— 10âˆ’4 and3 Ã— 10âˆ’4 respectively.Furthermore,BER
and EVM results for relay-destination links are obtained as 8 Ã— 10âˆ’5 and 19.29% on
average. Similarly, at âˆ’15 dBm relay transmit gain, BER results for NC operation
are measured as 2.5 Ã— 10âˆ’3, 3.5 Ã— 10âˆ’3 and 4.2 Ã— 10âˆ’3 respectively. Accordingly,
BER results for NCC operation are obtained as 1 Ã— 10âˆ’3, 1.2 Ã— 10âˆ’3 and 2.4 Ã— 10âˆ’3
respectively. Thus, improvement that is obtained with NCC operation, is observed
similar to previous results. Furthermore, BER and EVM results for relay-destination
links are obtained as 2.5 Ã— 10âˆ’3 and 22.05% on average.
In order to verify results demonstrated in the tables, individual BER and EVM
results obtained at each of 20 tests are given by bar charts. Firstly, BER results
obtained for the link between S2 and D1 that are obtained with ï¬rst setup at âˆ’16
dBm relay transmit gain, are given in Fig.6. Secondly, BER results obtained for
the link between S3 and D2 that are obtained with the second setup at âˆ’15 dBm
relay transmit gain, are given in Fig.7. It can be observed that individual results also
represent overall results given in the tables.
Moreover, EVM results obtained for the links between each source node and relay
nodes, are shown in Fig.8. As mentioned, these links have very good performances.
As the last observation, individual EVM results obtained at each test are shown in
Fig.9, where links between source nodes and D1 are considered with the second
setup. Similar to BER charts, EVM charts also show consistency of results shown in
the tables.
The usage of OFDMA is vital to analyze realistic usage scenarios of NCC opera-
tion. By evaluating multiple user scenarios with OFDMA, this NCC implementation
0
2
4
6
8
10
12
14
16
18
20
0
1
2
3
4
5
6
x 10
âˆ’3
Link error performances, S2âˆ’D1, at âˆ’16 dBm with first setup.
Bit Error Rate
Test Index
Sâˆ’D
NC
NCC
Fig. 6 BER results obtained during consecutive tests for the ï¬rst setup

Implementation of Network Coding in Wireless Systems
315
0
2
4
6
8
10
12
14
16
18
20
0
1
2
3
4
5
6
7
8
x 10
âˆ’3
Link error performances, S3âˆ’D2, at âˆ’15 dBm with second setup.
Bit Error Rate
Test Index
Sâˆ’D
NC
NCC
Fig. 7 BER results obtained at consecutive tests for the second setup
0
2
4
6
8
10
12
14
16
18
20
0
2
4
6
8
10
12
14
16
18
20
Link error performances, Sâˆ’R, with first setup.
Error Vector Magnitude (%)
Test Index
S1
S2
S3
Fig. 8 EVM results obtained for the source-relay links
shows how resources can be divided and managed. Validating theoretical components
in real-time with realistic transmission environment and hardware issues is the most
crucial outcome of the implementation. It is shown that with a ï¬‚exible design of such
a testbed, NCC operation in real-time can be easily realized and error performance
can be improved signiï¬cantly. Beyond NCC, NC performance is also measured in
real-time. NC also improves error performance, but NCC has clear beneï¬ts espe-
cially in terms of error performance. As future mobile networks will include massive
number of devices, it will be more challenging to obtain desired error performances.
Thus, relay-based communication would be very beneï¬cial in terms of the error per-

316
S. Tedik Basaran et al.
0
2
4
6
8
10
12
14
16
18
20
20
25
30
35
40
45
Link error performances, Sâˆ’D1, with second setup.
Error Vector Magnitude (%)
Test Index
S1
S2
S3
Fig. 9 EVM results obtained at consecutive tests
formances. NCC is a suitable candidate for such dense network scenarios and tight
system requirements resulting from increasing usage rates can be overcome with
easy deployment and cost efï¬ciency of NCC.
5
Conclusion
NCC is a candidate for smart routing application, that can be used in 5G or beyond
technologies. Due to its natural characteristics as allowing scalability and providing
robustness to channel impairments, NCC can be easily adapted to the target network,
alleviating the expected implementation issues in dense network deployments. In
this chapter, we present the theoretical DMT bounds in comparison with the state-
of-the-art design solutions and details of implementation setup of an NCC system.
We show that NCC is a convenient smart routing approach to satisfy requirements of
next generation communication systems by performing both of theoretical analyses
and real-time implementation.
References
1. R. Ahlswede, N. Cai, S.Y. Li, R.W. Yeung, Network information ï¬‚ow. IEEE Trans. Inf. Theory
46(4), 1204â€“1216 (2000)
2. R. Dougherty, C. Freiling, K. Zeger, Insufï¬ciency of linear coding in network information ï¬‚ow.
IEEE Trans. Inf. Theory 51(8), 2745â€“2759 (2005)
3. J.N. Laneman, G.W. Wornell, Distributed space-time-coded protocols for exploiting coopera-
tive diversity in wireless networks. IEEE Trans. Inf. Theory, 49(10), 2415â€“2425 (2003)

Implementation of Network Coding in Wireless Systems
317
4. T. Ho, M. Mdard, R. Koetter, D.R. Karger, M. Effros, J. Shi, B. Leong, A random linear network
coding approach to multicast. IEEE Trans. Inf. Theory, 52(10), 4413â€“4430 (2006)
5. M. Di Renzo, M. Iezzi, F. Graziosi, On diversity order and coding gain of multisource multirelay
cooperative wireless networks with binary network coding. IEEE Trans. Veh. Tech. 62(3),
1138â€“1157 (2013)
6. C. Peng, Q. Zhang, M. Zhao, Y. Yao, W. Jia, On the performance analysis of network-coded
cooperation in wireless networks. IEEE Trans. Wireless Commun. 7, 3090â€“3097 (2008)
7. H. Topakkaya, Z. Wang, Wireless network code design and performance analysis using
diversity-multiplexing tradeoff. IEEE Trans. Commun. 59(2), 488â€“496 (2011)
8. A.R. Heidarpour, G.K. Kurt, M. Uysal, Finite-SNR diversity-multiplexing tradeoff for network
coded cooperative OFDMA Systems. IEEE Trans. Wirel. Commun. 16(3), 1385â€“1396 (2017)
9. S. Gokceli, H. Alakoca, S.T. Basaran, et al., EURASIP J. Adv. Sig. Process. 2016(8) (2016)
10. F.J. MacWilliams, N.J.A. Sloane, The Theory of Error-Correcting Codes. North-Holland
Mathematical Library (North-Holland Publishing Company, Amsterdam, 1977)
11. E.M. Gabidulin, Theory of codes with maximum rank distance. Problemy Peredachi Informat-
sii, 21(1), 3â€“16 (1985)
12. S.T. Basaran, G.K. Kurt, M. Uysal, I. Altunbas, A tutorial on network coded cooperation. IEEE
Commun. Surv. Tutor. 18(4), 2970â€“2990 (2016)
13. P.A. Chou, Y. Wu, K. Jain, Practical network coding. in Proceedings of the Annual Allerton
Conference on Communication Control and Computing, vol. 41, No. 1, (2003) pp. 40â€“49
14. R. Koetter, F.R. Kschischang, Coding for errors and erasures in random network coding. IEEE
Trans. Inf. Theory, IEEE, 54, 3579â€“3591 (2008)
15. A. Bletsas, A. Khisti, D.P. Reed, A. Lippman, A simple cooperative diversity method based on
network path selection. IEEE J. Sel. Areas Commun. 24(3), 659â€“672 (2006)
16. J.N. Laneman, Network coding gain of cooperative diversity. in Proceedings of IEEE MILCOM,
vol. 1, (2004) pp. 106â€“112
17. B. Bai, W. Chen, K.B. Letaief, Z. Cao, Joint relay selection and sub-channel allocation for
amplify-and-forward OFDMA cooperative networks. in Proceedings of IEEE International
Communications Conference (ICCâ€™2012) (2012) pp. 4192â€“4196
18. M. Gromov, Pseudo holomorphic curves in symplectic manifolds. Invent. Math. 82(2), 307â€“347
(1985)

Opportunistic Network Coding
Kemal Alic and Ales Svigelj
Abstract In this chapter we describe a practical view of the usage of the network
coding theory over realistic communication networks. In particular, we introduce
opportunistic network coding, which can be applied to wireless networks with mesh
topologies and multiple unicast streams. With the term opportunistic we describe
the opportunistic nature of this type of coding, as packets are encoded only if the
opportunity arises and there are no mechanisms within it to increase the number of
coding opportunities. Different coding approaches have been proposed that cover
different network conï¬gurations and trafï¬c patterns. In particular, we focused on the
main design aspects of BON and COPE, the two opportunistic network coding proce-
dures that perform network coding on the packet level and can signiï¬cantly improve
the network throughput. In addition, we are also describing performance metrics,
which are found suitable for performance evaluation of network coding algorithms.
For illustration purposes we also show typical results for the above mentioned algo-
rithms. The results show that opportunistic network coding can signiï¬cantly improve
the wireless mesh network performance in terms of throughput and delay.
Introduction
The network coding beneï¬ts are not limited to either wireline networks or multicast
applications. The opportunistic network coding which is investigated in this chapter
shows, how beneï¬ts can be achieved also in the wireless networks and with multiple
unicast streams.
The term opportunistic network coding describes the opportunistic nature of this
type of coding, as packets are encoded only if the opportunity arises and there are
no mechanisms to increase the number of coding opportunities. Packets are coded
for one hop only, where they are decoded. In general coding of different and same
streams is possible, though we can expect only coding of different streams.
K. Alic (B) Â· A. Svigelj
Jozef Stefan Institute, Ljubljana, Slovenia
e-mail: kemal.alic@ijs.si
A. Svigelj
e-mail: ales.svigelj@ijs.si
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_12
319

320
K. Alic and A. Svigelj
Fig. 1 Example of how
opportunistic network coding
increases the throughput
Vj
Vi
p2
VR
p2
p1
p1
Vj
Vi
p2
VR
p1
pR = p1
 p2
Network coding approach
No coding approach
Opportunistic network coding beneï¬ts can be best explained with the help of the
simple example depicted in Fig.1. Consider a three-node chain topology where node
V1 hasapacket p1 destinedfornode V2,andnode V2 hasapacket p2 forthedestination
node V1. The two nodes can exchange their packets through an intermediate relay
node VR. Hence, nodes V1 and V2 send packets p1 and p2 to VR. In a conventional
systemwherenetworkcodingisnotused, VR ï¬rsttransmits p1,whichisthenfollowed
by the p2. In the case where a network coding procedure is applied, the VR performs
an algebraic operation over the two packets (e.g., XOR) and sends out an encoded
packet pR = p1 âŠ•p2. Upon reception, node V1 XORs the received encoded packet
pR with the sent packet p1 and obtains the packet p2. The same procedure is used
on node V2. V2 is familiar with the content of p2 and XORs it with the just-received
packet pR, thus obtaining p1 ofï¬cially destined to it. By using network coding the
number of transmissions that all three nodes need to perform in order to deliver both
packets to their destinations has been reduced from 4 to 3.
The example in Fig.1 presents a topology that is suitable for the chain-structure
coding, i.e., a topology where the two packets are travelling in the opposite directions
and get encoded in the intermediate node(s). In such a case, all the recipient nodes
have sufï¬cient information for successful packet decoding without packet overhear-
ing. Furthermore, packet retransmission may appear only due to the unsuccessful
delivery of the encoded packet to one of the recipient nodes.
A more interesting case arises with a more general network deployment. In such
a case, the question is which packets the coding node should encode together in such
a way that the recipient nodes will be able to decode the encoded packet. When a
node has a packet to forward, it needs to know whether encoding of this packet with
other queued packet(s) might save bandwidth, i.e., it needs to determine whether the
receivers can decode the encoded packets. Consider the situation in Fig.2. Nodes V1
and V2 are sending packets p13 and p24 via the relay node VR to the nodes V3 and V4,
respectively. If VR creates an encoded packet from p13 and p24, e.g., pR = p13 âŠ•p24,
thereceivingnode V3 willbeabletodecodetheencodedpacket pR if V3 hasoverheard

Opportunistic Network Coding
321
Fig. 2 General relaying
scenario in which network
coding can be used
V3
V4
p24
p13
p24
p13
VR
V1
V2
the p24 transmission from V2 to VR. The situation is similar for V4, which needs to
overhear the p13 transmission from V1 to R.
Let us highlight why the coding packets that travel in the opposite directions are
preferred. Assume the situation presented in Fig.1 where packets pn and pm travel
in the opposite directions, i.e. pn from Vj via VR to node Vi and pm via versa. If we
describe the links between nodes with packet delivery probabilities, i.e. probability
that packets are successfully transmitted between two links, then we can estimate the
chances that the encoded packet pnâŠ•pm will be successfully received and decoded
on the two nodes is
P = PVRVj PVRVi,
(1)
where PVRVj and PVRVi are the probabilities that packets are successfully transmitted
from node VR to node Vj and to node Vi, respectively.
In a more general situation where packet pn travels from Vi to Vj and pm from
Vk to Vl, then the probability that the encoded packet pnâŠ•pm will be successfully
received and decoded on the two recipient nodes is:
P = PVRVj PVRVi PVi Vl PVkVjÂ·
(2)
The difference to the ï¬rst case is that also two overhearing events need to take place
for each of the receiving nodes to have sufï¬cient information to perform decoding.
Information Required in the Opportunistic Coding Process
The more packets we encode together the looser the conditions in coding process are,
and with that the higher the possibility that receiving nodes will not be able to decode
those packets. However, if coding conditions are hard to meet, then there are only few
coding opportunities and low bandwidth saving beneï¬ts. Good opportunistic coding
algorithm does not only attempt to encode as many packets as possible, but rather
makes sure that the encoded packets are very likely to be decoded. Making incorrect

322
K. Alic and A. Svigelj
coding decisions leads to unnecessary retransmissions, which results in wasting of the
wireless resources. Therefore, an important development issue is ï¬nding a balance
between the number of coded packets and the successful decoding rate, by using
small network coding overhead.
Coding decisions can be based on knowledge, e.g. each node records the state of
the trafï¬c for its neighbouring nodes, although as shown in [1â€“3] this is only sufï¬cient
for a portion of coding decisions. Thus, guessing mechanism needs to be used in the
coding decision process. The guessing can be based on the information that is already
available on the node, and was collected by some protocol. For example, the COPE
build on the information already available on the node and acquire the information
gathered by the routing protocol. This is an excellent option as no new additional
overhead is introduced to the network [4, 5]. The drawback with this solution is that
the routing information has to be available in the layer where coding procedure is
implemented. With communication components available on the market this is not
always possible. An alternative is to acquire an estimation of coding possibilities
through own network coding evaluation. This could be performed through (i) trans-
mitting the probe (measurement) packets; or (ii) by estimating the coding success of
the regularly encoded packets. The ï¬rst option introduces additional overhead to the
network. By collecting the required information through measurements scheduled
periodically we introduce additional overhead, thus lowering goodput and beneï¬ts
of network coding. With the second option the data is collected by just observing
the trafï¬c going through the network coding module e.g. collecting the statistics
on which packets have been encoded and how many retransmissions were needed.
The main drawback of such an approach is that there is a rather small portion of
packets that get encoded. Collecting them over longer periods of time is in general
not acceptable as this would make the system slow and unable to adapt to the fast
changes on wireless links. Practical value of such approach is low for general network
performance since the number of coding options (combinations of packetâ€™s previous
hop and packetâ€™s next hop) grows with the number of neighbours a node has i.e.
faster than exponentially (i.e. N!/2). In practice, there are too many possibilities to
provide a reliable estimation on which node pairs provide good coding matches. In
addition, the ongoing measurements should be able to detect the changes in wireless
links conditions and react fast in case of their degradation. The subset of possible
coding matches should be made in order to provide reliable decision process and
react to changes in wireless environment.
Living Environment for Opportunistic Network Coding
Opportunistic network coding works well in wireless mesh networks. With this term
we describe networks where nodes connect to each other via multi-hop wireless links.
Usually we consider them to be self-sustainable, i.e. adaptive and self-organised in
order to be able to maintain connectivity.
Wireless mesh networks are very limited in capacity. E.g. the 802.11 family of
products are advertised to support data rate of up to 54Mbps. Still, â€œprotectionâ€
mechanisms such as binary exponential backoff, rate adaptation, and protocol over-
heads, cut the throughput by 50%. Moreover, owing to backward compatibility with

Opportunistic Network Coding
323
802.11b and 802.11g is encumbered with legacy issues that reduce throughput by an
additional âˆ¼20%. Besides, the actual bandwidth available to individual clients can
be even much lower due to the shared nature of the wireless medium. Also, mesh net-
works usually operate in the unlicensed 2.45GHz Industrial, Scientiï¬c and Medical
(ISM) frequency band. Hence, bandwidth is shared also with other networks or net-
work devices, e.g. Bluetooth peripheral devices, spread-spectrum cordless phones,
or microwave ovens. Interference affects the quality of a wireless link and, conse-
quently, its error rate and achievable capacity.
Regardless of their capacity limitations wireless mesh networks are appealing in
areas with scarce wired infrastructure. Such places can be found in less developed
areas or in places such as tunnels, battleï¬elds, on board of public transportation etc.
Furthermore, due to low operational and deployment costs commercial deployment
can also be found in urban areas with the main application of offering cheap Internet
connectivity.
In a mesh network, each router can be seen as part of a backbone infrastructure
and also as an access point for end users. In this chapter we see mesh routers as
access points that offer end-users access, hence trafï¬c generated on nodes can be
considered aggregated from multiple users.
The network coding procedures discussed in this work are positioned between the
network and the link layer.
Routing-path selection also inï¬‚uences the performance of network coding. Rout-
ing that takes into account also network coding can further boost the network per-
formance, as can poorly selected routing in combination with network coding result
even in poorer network performance. The proposed BON procedure works as an
independent layer, but its performance is indirectly still related to the performance
of routing [1, 2].
In this chapter we consider the link-state routing protocol that is widely adopted
in the wireless mesh networks. We adopted symmetric routing (with symmetric we
refer to path selection of trafï¬c ï¬‚ows that travel in the opposite directions).
Wireless mesh networks were initially based on the IEEE 802.11 standard. There-
fore, we provide a brief overview of general properties of the standard important from
the opportunistic network coding perspective.
The standard offers mechanisms for packet distribution to the nodes within their
communication range. Unicast inherently assure reliable delivery of packets to the
next hop while broadcast offers distribution of data to multiple users. With network
coding we want all the nodes to listen to all the transmissions. To this end, the
broadcast mechanism in the link layer seems a suitable solution at a ï¬rst glance.
However, due to the absence of collision detection and backoff on the source node the
reliability of broadcast is questionable. For this purpose we adopt pseudo broadcast
ï¬rst presented in [1] and discussed in this chapter.
The Coding Algorithms
The general COPE and BON architecture is shown in Fig.3. Packets arriving from the
network layer are placed into the network coding queues. Both coding procedures

324
K. Alic and A. Svigelj
          Network coding layer
Packet decoding
Packet pool
Link layer
Network layer
P
Queues
Packet Coding 
ACK & Ret. 
management
Fig. 3 Opportunistic network coding architecture
foresee use of FIFO queues, but also other queue scheduling can be used. When
the node is granted access to the wireless channel the coding process takes the ï¬rst
packer from the queues and searches for coding opportunities amongst remaining
packets in the output queue. If there are no coding opportunities identiï¬ed, the packets
are sent out as they are. None of the two algorithms deliberately delays packets
for the purpose of ï¬nding additional coding opportunities. If packet coding ï¬nds
coding opportunities, the outgoing packets are coded into one encoded packet and
retransmissions are scheduled for each individual native packet.
All the received packets go ï¬rst through the decoding process. If packets are suc-
cessfully decoded each native packet coded in the encoded packet is stored into the
packet pool. If any of the native packets are destined to the recipient node acknowl-
edgement message is sent out. If received packet is acknowledgement type of packet
the scheduled retransmission is cancelled. Packets with next hop address the same
as the recipient node are also sent to network layer for further processing.
COPE
All the received packets go ï¬rst through the decoding process. If packets are suc-
cessfully decoded each native packet coded in the encoded packet is stored into the
packet pool. If any of the native packets are destined to the recipient node acknowl-
edgement message is sent out. If received packet is acknowledgement type of packet
the scheduled retransmission is cancelled. Packets with next hop address the same
as the recipient node are also sent to network layer for further processing.
In COPE the coding process depends on the nodesâ€™ knowledge on what infor-
mation (which packets) its neighbouring nodes have. Based on this knowledge the

Opportunistic Network Coding
325
coding process is straightforward and the decoding process will have a high suc-
cess rate. Due to the nature of wireless communications and imposed delays that
comes with this knowledge can be used only to ï¬nd a small portion of all possible
coding opportunities. Hence, the COPE coding process also uses guessing which is
done through the delivery probability that is calculated in all of the ETX (Expected
Transmissions Count) based routing protocols. COPE incorporates two techniques to
support such coding process, namely opportunistic listening and learning neighbour
state:
â€¢ opportunistic listening and
â€¢ learning neighbour state
â€¢ guessing
Opportunistic Listening
In COPE the coding process depends on the nodesâ€™ knowledge on what information
(which packets) its neighbouring nodes have. Based on this knowledge the coding
process is straightforward.
COPE foresees that all the nodes listen to all transmissions. As already mentioned
all the packets carry potentially useful information that can be used in the decoding
process. COPE also uses information obtained for the coding process. When a packet
is received on the node the sender and recipient node information is extracted and
noted. The node that overheard the transmission now knows that the two nodes have
the packet.
Learning Neighbour State
COPE procedure also foresees the use of the reception reports. All the nodes in the
network send out reports in which information on the received packets is stored.
Reports are broadcasted periodically or when opportunity arises they are attached to
the regular outgoing packets.
Guessing
In a network where we do not want to delay packets and Quality of Service (QoS)
should be at least considered, relying solely on the knowledge on the state of the
network would miss a great deal of coding opportunities. Hence, COPE foresees
also guessing, when information on the state of the network, i.e. whether the packet
under the question was received by the node.
The well-known COPE algorithm guessing relies on the information gathered in
the network layer, i.e. the expected transmission count matrix (ETX):
ETX =
1
PVi Vl PVl Vi
(3)
With this metric each link between two nodes is described with the inverse of the
packet delivery probability and its successful acknowledgement. Information can be
used in a way that it reï¬‚ects the probability that a node received certain packet.

326
K. Alic and A. Svigelj
The COPE Coding Algorithm
The node estimates probability that the node N has packet p by looking at the delivery
probability for the link between packetâ€™s previous hop and node N.
With all the needed information, the node can code together as many packets
(p1, . . . , pn) as possible provided that none of the packets have been created on
the coding node, all the packets have different next hops and that there is a strong
possibility that all next hops will be able to decode the packet. The next hop can
decode the packet if it has already received all but one of the packets coded together.
Let the probability that a next hop has heard packet pm be Pm. Then, the probability,
PD, that it can decode its native packet is equal to the probability that it has heard all
of the n âˆ’1 native packets encoded with its own, i.e.,
PD = P1P2 . . . Pnâˆ’1
(4)
The coding algorithm assures that the decoding probability PD for all the next hops
for a given combination of encoded packets is above the threshold G.
BON
With BON assumptions that each node has positions of all of its neighbouring nodes,
and that nodes have ï¬xed locations are made. Algorithm makes coding decisions
based solely on the information about the packetâ€™s previous and next hop node posi-
tion, hence, it acts completely independently of all other communication layers, and
is completely protocol agnostic.
The BON Coding Algorithm
The decision making on which packets to encode together can be based on the
information already available on the node or the required information needs to be
gathered.
The coding process is based on the local bearing (as used in the navigation)
of the packet, which is deï¬ned on the relay node and depends on the positions of
the packetâ€™s previous hop and the packetâ€™s next hop [2, 3]. Packets that have not
travelled at least one hop are not codable, and so a bearing is not deï¬ned for them.
Let us use the example from Fig.4a to explain the deï¬nition of bearing. A packet
pi j (R) has been transmitted from the node Vi to the relay node VR and its next hop is
Vj. Locations of nodes Vi and Vj are known and are given in Cartesian coordinate
system as (Xi, Yi)(X j, Y j). We deï¬ne bearing for the packet pi j (R) on the relay node
VRas a unit vector calculated as:
â‡€
bi j =
(X j âˆ’Xi, Y j âˆ’Yi)
âˆ¥(X j âˆ’Xi, Y j âˆ’Yi)âˆ¥,
(5)
and translated into three dimensional space where also the node elevation (Z) is
taken into account:

Opportunistic Network Coding
327
Vj
pij
(R)
VR
Vi
pij
(R)
pji
(R)
pij
(R)
VR
Vi
pij
(R)
pji
(R)
Vj
bij
â†’
Vj
pij
(R)
VR
pij
(R)
Îµij
(R)
Vi
Îµij
(R)
(a)
(b)
(c)
bij
â†’
bij
â†’
bji
â†’
Fig. 4 Graphical presentation of a a bearing, b bearings for two packets travelling in the opposite
direction and c the vicinity for packet pi j (R) in the shape of an inï¬nite cone
â‡€
bi j =
(X j âˆ’Xi, Y j âˆ’Yi, Z j âˆ’Zi)
âˆ¥(X j âˆ’Xi, Y j âˆ’Yi, Z j âˆ’Zi)âˆ¥.
(6)
In the coding process we are primarily interested in packets that are travelling
in opposite directions. Without loss of generality we build on a two-dimensional
example presented in Fig.4b where the packet pi j (R) has the same next hop as was the
packet p ji (R)â€™s previous hop and vice versa (the case of the so-called chain topology).
In such a case, the bearings of the two packets are
â‡€
bi j âˆ’
â‡€
b ji =
â‡€
0. The two packets can
beseenasrepresentativesofthetwoï¬‚owsthataretravellingintheoppositedirections.
Coding of such packets is an ideal combination as no overhearing between the nodes
is needed and the recipient nodes can always decode the encoded packet.
Since such opportunities (i.e. when packets travel in exactly opposite directions)
do not provide a sufï¬cient number of coding opportunities, the coding opportunities
need to be searched for also amongst other packets. In general, we can assume that
the nodes that are located in the vicinity of the transmitting node have a better chance
of successfully overhearing the packet transmission than nodes that are located far
from it. Thus, they also provide a possibly good coding opportunity. With the coding
algorithm we are looking for packets (pkl(R)) that are codeable with the transmitting
packet (pi j (R)) on the relay node. We consider pkl(R) to be codable with pi j (R), if
the pkl(R) destination node Vl is in the vicinity of the pi j (R) source node Vi and vice
versa.
Deï¬nition 1 With BON the vicinity of the node Vj for packet pi j (R) on the relay
node VR is described as an area within the shape of an inï¬nite cone with the apex in
the packet source Vi, and cone axis with the direction
â‡€
bi j and the aperture 2Îµi j (R).

328
K. Alic and A. Svigelj
Example of such an area for a packet pi j (R) that is on the node VR, with the
previous hop Vi and the next hop Vj is shown in Fig.4c, where the cone has the apex
in node Vi and the aperture 2Îµi (R). The node Vj lies directly on the cone axes. With
Îµi (R) we deï¬ne how large the vicinity for packet pi j (R) is, hence we refer to it as
tolerance angle.
Deï¬nition 2 With BON coding the packets pi j (R) and pkl(R) are codeable on the
relay node if previous hop of pi j (R) (Vi) is in the vicinity of the next hop of pkl(R) (Vl)
and vice versa, where vicinity of nodes for packets pi j (R) and pkl(R) is set according
to the Deï¬nition 1 with Îµi j (R) and Îµ ji (R) accordingly.
Let us illustrate using general two-dimensional examples from Fig.5a, b where
matching and a non-matching packet pairs are presented respectively. In both pre-
sented cases the initial situation is the same. Let us point out that the location of
the VR has no impact on the coding decision, and its location is changed only for
the reasons of graphical presentation. Packets pi j (R) and pkl(R) are both on the relay
node VR. Vi and Vj are the previous and the next hop for pi j (R) and Vk and Vl are the
previous and the next hop for pkl(R). Îµi j (R) and Îµkl(R) are tolerance angles that relate
to packetsâ€™ previous hops on the relay VR.
In Fig.5a we can see that the node Vi is located in the vicinity of the node Vl for
packet pkl(R) and the similar goes for the node Vk, which is in the vicinity of the node
Vj for packet pi j (R). Since we want that the condition in Deï¬nition 2 is met for both
situations in the given example, the two packets are codeable.
In Fig.5b we can see that the node Vi is located in the vicinity of the node Vl for
packet pkl(R) and the node Vk is outside the vicinity of the node Vj for packet pi j (R).
pkl
(R)
pkl
(R)
Vj
pij
(R)
VR
pij
(R)
Vl
Vi
Vk
â†’
pkl
(R)
Vj
VR
Vl
Vk
Vi
bij
â†’
bij
â†’
bkl    
â†’
bkl
kl
(R)
kl
(R)
ij
(R)
ij
(R)
pij
(R)
pij
(R)
pkl
(R)
Fig. 5 Graphical presentation of general coding case for a a matching packet pair and b of a general
coding case for a non-matching coding pair

Opportunistic Network Coding
329
Since we want that the condition is met for both situations in the given example
the two packets are not codeable. Packets pi j (R) and pkl(R) would be codeable if
Îµi j was larger. By increasing the tolerance angle we cover a larger area and thus
increase probability that packets will meet the conditions. However, by increasing
the tolerance angle parameter, the probability that the receiver will not be able to
decode the packet is also increased. By reducing the parameter Îµ towards zero, the
coding opportunities are reduced, but the probability of a successful packet decoding
on the receiving nodes is increased.
By further generalization the BON coding procedure allows also coding of mul-
tiple packets. Multiple packets are encoded into one encoded packet when all packet
pairs and their corresponding nodes are within the vicinity area. The higher the Îµ
values, the higher the possibility of coding multiple packets on the other hand, if
at least one Îµ = 0 only two packets can be encoded. In BON coding the balance
between coding opportunities and successful packet decoding is set through the
parameter Îµ, which is adapted automatically on every node. The algorithm handling
self-adjustment is presented in Algorithm 1.

330
K. Alic and A. Svigelj
Integration into the Communication Stack
In order to make use of the opportunistic network coding process, several supporting
mechanisms are required to be implemented on the nodes. Using the opportunis-
tic network coding, the nodes change the way packets are processed after being
received and a new signalization is required. Moreover, the opportunistic network
coding requires that the nodes are put in a broadcast receiving mode, while a pseudo-
broadcast mechanism is used for sending the packets.
All the nodes in the network listen to all the transmissions and try to overhear as
many packets as possible â€“ including the ones that are not addressed to them. All the
overheard packets are saved into the packet pool for decoding purposes. A copy of a
received packet (i.e., a packet headed to the node) is also stored in the packet pool,
while the original is forwarded to the network layer.
Packet Queues
BON and COPE procedures use different outgoing queues for different packet types
i.e.:
â€¢ ACK packets. These are standalone acknowledgement messages that are created
only when no opportunity has been found to add them as a header to regular
outgoing packets.
â€¢ Retransmitted (native) packets dedicated queue is used in BON only. Packets are
placed in special sub-queue to prevent coding the same packet set together again
and thus trying to avoid the possible mistake in the coding process.
â€¢ Regular outgoing (native) packets that have arrived from the network layer and
have arrived from one of the neighbouring nodes or have their origin on this node.
COPE uses this queue also for retransmitted packets, which are placed at the top
of the queue and thus processed ï¬rst.
When there are packets present in one of the output queues, the BON and COPE
procedure signal the link layer that the access to the wireless media is required. When
the link layer signals that it has successfully gained access to the channel, the queue
is selected depending on its priority. If we are dealing with retransmitted or regular
queue, the coding procedure is initiated.
Coding Procedure
The coding process using the FIFO system always takes the packet p0 that is at the
head of the output queue (retransmission or regular) and searches for possible coding
opportunities with the other packets in the regular outgoing queue. If there are no
coding options found, the packet is sent out as-is (Fig.6).
Signalization
The two algorithms under the spotlight use two types of signalization, namely
acknowledgement messages and reception reports. The acknowledgements in BON
and COPE have the same structure, while reception reports are unique to COPE only.

Opportunistic Network Coding
331
Fig. 6 A ï¬‚ow chart of the
BON and COPE coding
process
Access to the 
channel gained
Take packet from 
the head of the 
output queue
Encoded?
Encode if possible
Add
acknowledgements 
to headers
Send to wireless 
device
No
Schedule
retransmissions
Yes
Acknowledgement messages in the network coding layer are used only for native
packets that have been received as part of the encoded packet. Acknowledgement
messages are generated by the receiving node, designated as a packetâ€™s next hop.
Please note that we are discussing only the acknowledgement messages in the net-
work coding layer, while acknowledgements in the other layers remain as they were.
The acknowledgement message in the network coding layer is required to indicate
the success in the packet decoding procedure.
Cumulative acknowledgement in a structure proposed in [1] are used. Acknowl-
edgement massages are sent in a bulk every time an opportunity arises and when there
are new messages in the pool. The latest received packet sequence number is used
for reference. This is followed by a sequence of Boolean values that also indicates
status of the received packets for the packets with lower sequence number. E.g. an
entry {A, 50, 01011111} conï¬rms that packets 50, 48, 46-42 have been received and
that packets 49 and 47 are still missing.

332
K. Alic and A. Svigelj
To make this operate, packet sequence number needs to be recorded. Each node
indexes outgoing packet per each neighbour individually and the same holds true for
all the received packets.
Acknowledgement messages conï¬rm reception for every received native packet
that has been received as part of the encoded packet. Cumulative acknowledgement
report messages are broadcasted periodically, every Tu (referred to as acknowledge-
ment packets). If the opportunity arises, the acknowledgement messages are attached
to the regular outgoing packets. In this case cumulative acknowledgement can be
seen only as an additional header, thus introducing less overhead. In case that the
upper limit of acknowledged packets per is reached, the acknowledgement process is
triggered and acknowledgement massages are sent out as individual packet. Cumu-
lative acknowledgement messages reduce the overhead compared to the individual
acknowledgement messages.
Reception reports are messages used in COPE only. With these nodes inform
their neighbours on which packets they have received Also reports are sent out when
opportunity arises or in the absence of those periodically. Similar as acknowledge-
ments, also reports are compact. They are formed as headers, where ï¬rst information
on number of reports in the header is given. One report is used for each neighbour
with updated status. Second information in the header is address of the neighbour that
transmitted the packet, followed by the last packet id received from that node. This
is followed by a sequence of Boolean values that also indicates status of the received
packets for the packets with lower sequence number. Reports include information
on the packet ID and neighbour address because both data are needed to identify the
packet in a unique way. More can be read in [1].
Packet Reception
In addition to handling acknowledgement packets, the recipient node needs to be able
to also handle native and encoded packets, which both can carry additional header
that contains acknowledgement massages.
Packet reception process is presented in Fig.7. Upon packet reception in the
network coding module, further actions depend on whether the packet is encoded
or native. In the case when an encoded packet (consisting of M native packets) is
received,theprocesschecksthepacketpoolwhereallthereceived,sentandoverheard
packets are stored for decoding purposes. The encoded packet can be decoded if a
node has in its packet pool at least Mâˆ’1 packets. The process has to determine
whether it has already received Mâˆ’1 of the packets encoded in the encoded packet.
If not, the encoded packet cannot be decoded and it is simply dropped. If the node
has at least the required Mâˆ’1 packets, i.e., sufï¬cient information, it decodes the
encoded packet using these packets with the XOR operations, thus obtaining a native
packet that has not been received before. From here on the process is the same as
upon receiving a native packet. If the packet is new (i.e. newer received before),
its copy is inserted into the packet pool for decoding purposes. It does so for every
received native packet, as all the received packets are potentially needed for further
decoding purposes. The process checks whether the node is the next hop of the
native packet. If so, and if the packet has been a part of the encoded packet, an

Opportunistic Network Coding
333
Fig. 7 A ï¬‚ow chart of the
BON and COPE reception
process
Packet arrival
Extract 
acknowledgements, 
update
retransmissions
Encoded?
Drop packet
Decodable?
Decode and schedule 
acknowledgements 
Add packet(s) to 
packet pool
Am I 
next-hop?
Drop packet
Send packet to 
routing module
No
Yes
Yes
No
No
acknowledgement message is scheduled and the packet is sent to the network layer
for further processing.
Packet Retransmission
If an ACK message is not received within a predetermined time, the retransmission
event is triggered. A native packet that has been sent out as part of the encoded packet
and has not been acknowledged, is placed in the retransmission output queue.
Packets require retransmissions for two reasons. Packets cannot be decoded on
the recipient node (i) because there are not enough packets in the packet pool, and
(ii) because packets get lost in the transmission/reception procedure.
The packets in the retransmissions queue can be coded again. However, coding
opportunities are searched for only within the packets in the regular output queue.

334
K. Alic and A. Svigelj
This mechanism ensures that it is not possible for the same set of packets to be coded
again. Hence, the situation where the same set of packets is encoded again is avoided.
With every packet retransmission we want to increase the probability of successful
packet decoding on the recipient node. and we can do so by decreasing the parameter
Îµ. Hence, we foresee that with every packet retransmission parameter Îµ is decreased.
Pseudo Broadcast
With network coding we need to overhear as many transmissions as possible for the
network coding mechanisms to seize their full potential. Hence, a natural approach
would be to use a broadcast mechanism. As shown in [1] this does not work due to
poor reliability and lack of backoff and they propose a pseudo broadcast mechanism
which unicasts packets that are meant for the broadcast.
The link-layer destination ï¬eld is set to the MAC address of one of the intended
recipients. Since all the nodes are set in the promiscuous mode, they can overhear
packets not addressed to them. When a node receives a packet with a MAC address
that is identical to its own, it sends an ACK message to the sender. Regardless of
the address of the next hop of the packet, the node sends the packet to the network
coding module.
Performance Metrics for Network Coding Procedures
Network coding is a relatively new approach; whose fundaments we are still learning.
With opportunistic network coding we may claim the same, as knowledge in what
kind of networks and with which trafï¬c distributions we can expect beneï¬ts and how
does the new layer affect the performance of applications with high QoS demands has
not yet been obtained. Depending on what we wanted to show, we adopted different
metrics, and on the high level we can group them into two categories:
â€¢ Performance metrics that capture the detailed network response on the use of
network coding. Corresponding set of results is shown against the network load,
which is always measured over longer periods. Network load was selected as the
key inï¬‚uence for the network coding performance as it can be measured in a
straight-forward manner and there is a strong correlation between performance
beneï¬ts and load.
â€¢ Performance metrics that allow higher level conclusions such as the inï¬‚uence
of the network topology on the performance of the network. The main issue in
showing such results is in deï¬ning a performance metric that is only dependant
on the parameter under scope.
Thus, in the following we are presenting some performance metrics, which we found
suitable for performance evaluation of opportunistic network coding algorithms. In
addition, we also show some illustrative results. As the elementary metric reï¬‚ecting
the quantity of service we can observe the network goodput (g), which is the number
of useful information bits delivered by the network to a certain destination per unit
of time. The goodput in graphs can be shown as a sum of all the goodput on all
the network nodes at particular network scenario e.g. particular load g(i) or plain as
current goodput on node or network.

Opportunistic Network Coding
335
Fig. 8 Goodput (g) with
respect to the network load
for COPE, BON and the case
when coding is not used
Fig. 9 Gain (G) with respect
to the network load for
COPE, BON and the case
when coding is not used
Example of goodput deï¬ned as a sum of all the goodput on all the network nodes at
particular network load is shown in Fig.8. Goodput is shown for the two opportunistic
coding procedures and reference scenario, where coding is not used.
We further deï¬ne the gain G(i) in ith simulation run as the relative increase of
goodput obtained with network coding with respect to goodput without network
coding:
G(i) = gNC(i) âˆ’gno coding(i)
gno coding(i)
100%
(7)
where gain can be observed for the whole trafï¬c in the network or just on the individ-
ual ï¬‚ow level. Similar as goodput also gain can be observed for particular scenarios.
Example graph for gain for the same case scenario as presented in Fig.8 is shown in
Fig.9.
As a typical QoS metric we measure End-to-End Delay and jitter at the application
layer. Both ETE delay and jitter are measured for each particular ï¬‚ow separately and
for all the ï¬‚ows. Regardless of the case, we can write the following:

336
K. Alic and A. Svigelj
Fig. 10 End-to-end delay
(ETE) with respect to the
network load for COPE,
BON and the case when
coding is not used
ET E(i) =
Ka(i)
nâˆ’1 dn
Ka(i)
(8)
where dn is the ETE delay of the nth packet and Ka(i) is the number of packets
received in the application layer.
Jitter is the standard deviation from true periodicity of a presumed periodic signal.
We measure jitter only for ï¬‚ows with constant interarrival packet rates:
jitter(i) =
1
F(i)
F(i)

f =1
1
K f (i)
K f (i)

n=1
(dnf âˆ’ET E f (i))2
(9)
where F is the number of ï¬‚ows, K f is the number of packets received in the appli-
cation layer belonging to the f th ï¬‚ow, and ETE f is ETE for f th ï¬‚ow. Where we
are interested in jitter of only one particular ï¬‚ow, this same equations is used for
calculation and F(i) = 1.
Typical delay results are presented in Fig.10. On the ï¬gure values for COPE,
BON and reference scenario where coding is not used are shown.
Opportunistic network coding performance primarily depends on the quantity of
load and also on different parameters. When analysis or evaluation on of the inï¬‚uence
of different network and trafï¬c characteristics on the performance efï¬ciency of the
network coding needs to be performed we require a load independent metric to
quantify the result, in particular, if we want to access the dependency of gain on
other parameters (e.g. queue length, packet length, topology, etc.). Thus, we propose
MaxGain, which is calculated as the average of the 3 highest gain values obtained
among results for a given set of parameter values. We ï¬rst sort vector G(i) where i =
{1, 2,â€¦, I} and I is the number of simulation runs from the highest to lowest value:
Gs = sort{G(1), G(2),
. . . , G(I)}
(10)

Opportunistic Network Coding
337
Fig. 11 MaxGain with
respect to the trafï¬c
symmetry ratio for COPE
and BON
and then the MaxGain is:
MaxGain = 1
3(Gs(1) + Gs(2) + Gs(3))
(11)
For example in Fig.11 we show dependency of opportunistic network coding
performance against trafï¬c symmetry ratio. In a network limited number of node
pairs were selected. Trafï¬c between the two loads was generated, while the symmetry
between the two ï¬‚ows in the load pair was changing.
Summary
In this chapter we show how coding theory can be used in existing communication
networks. We introduced opportunistic network coding which can be applied to the
wireless networks and to multiple unicast streams. The term opportunistic describes
the opportunistic nature of this type of coding, as packets are encoded only if the
opportunity arises and there are no mechanisms within it to increase the number of
coding opportunities.
Different coding approaches have been proposed that cover different network
conï¬gurations and trafï¬c patterns. The core of all opportunistic network coding
approaches is which packets the coding (i.e. relaying) node should code together
in such a way that the recipient nodes will be able to decode the encoded packet.
In this chapter we focus on design aspects of two typical opportunistic network
coding representatives namely BON and COPE. Both are positioned between the
network and link layers and are performing network coding on the packet level
and can signiï¬cantly improve the network throughput. As the network coding is
a relatively new approach, we are also describing performance metrics, which we
found suitable for performance evaluation of network coding algorithms. For the
illustration purposes we also show some typical result for the above mentioned
algorithms. The results show, that opportunistic network coding can signiï¬cantly
improve the wireless mesh network performance in terms of throughput and delay.

338
K. Alic and A. Svigelj
References
1. S. Katti, H. Rahul, W. Hu, D. Katabi, M. MÃ©dard, J. Crowcroft, XORs in the air: practical
wireless network coding. IEEE/ACM Trans. Netw. 16, 497â€“510 (2008)
2. K. Alic, E. Pertovt, A. Svigelj, Bearing-opportunistic network coding. Int. J. Comput. Commun.
Control. 10, 154â€“164 (2015)
3. K. Alic, A. Svigelj, A one-hop opportunistic network coding algorithm for wireless mesh net-
works, Wirel. Netw. (2016) https://doi.org/10.1007/s11276-016-1384-y
4. K. Alic, A. Svigelj, Self-adaptive practical opportunistic network-coding procedure for static
wireless mesh networks, Ad Hoc Sens. Wirel. Netw. 36(1â€“4), 87â€“105 (2017)
5. S. Katti, D. Katabi, W. Hu, H. Rahul, M. Medard, The importance of being opportunistic:
practical network coding for wireless environments. Presented at the 43rd Allerton conference
on communication, control, and computing, 2005

Coded Random Access
Ë‡Cedomir StefanoviÂ´c and Dejan VukobratoviÂ´c
Abstract This chapter presents an overview of coded slotted ALOHA (CSA), which
is a slotted ALOHA-based random access scheme with iterative interference can-
cellation. The iterative reception algorithm of CSA is analogous to the iterative
belief-propagation erasure-decoding, motivating the use of the tools from codes-on-
graphs to design and analyze CSA schemes. The asymptotic performance analysis
of CSA for the collision channel model is derived using the and-or tree evaluation
and instantiated for the case of frameless ALOHA. The and-or tree evaluation is then
adapted to the case of block-fading channels and threshold-based reception criterion,
which is another frequently used model in wireless systems. Finally, the performance
of CSA is assessed in multi access point scenario for the collision channel model,
assuming different variants of cooperation among the access points.
1
Introduction
The problem of random access arises in communication scenarios in which multiple
users (i.e., terminals) have to access the common access point (AP) over the shared
communication medium, see Fig.1, but the activation patterns of the terminals (i.e.,
instances of when the terminals will initiate the access) and, perhaps, even the number
of the accessing terminals are not known a-priori. A typical example can be found
in the connection establishment procedure taking place between a mobile phone and
a base station in a cellular network, with the purpose of initiating a call. The typical
approach in such case is to employ a decentralized algorithm that distributes the
Ë‡C. StefanoviÂ´c (B)
Department of Electronic Systems, Aalborg University (Copenhagen Campus), Frederikskaj 12,
2450 Copenhagen, Denmark
e-mail: cs@cmi.aau.dk
D. VukobratoviÂ´c
Faculty of Technical Sciences, Department of Power, Electronics
and Communication Engineering, University of Novi Sad,
21000 Novi Sad, Serbia
e-mail: dejanv@uns.ac.rs
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_13
339

340
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
Fig. 1 The random access
protocols are used for the
scenarios in which the
a-priori unknown subset of
users attempts access to the
common access point over
shared medium
time-instants in which users attempt the access in a random manner; the aim is to
avoid the interference among the users, as it may prevent successful reception of
their access requests by the AP.
Slotted ALOHA (SA) is a prominent example of a random access protocol, used,
e.g., in RFID networks, satellite networks, and as the basis for the connection estab-
lishment in cellular access networks. In its original form, SA assumes that the time
is divided in equal-length slots and that users are slot-synchronized, i.e., there is a
certain level of coordination among the users, provided by the AP that broadcasts
time-references. Each accessing user, independently and uncoordinatedly, decides on
the slot-basis with a certain probability whether to transmit. From the AP perspective,
a slot can be an idle (i.e., containing no transmission), a singleton (i.e., containing
a single transmission) or a collision slot (i.e., containing multiple transmissions).
The SA performance is standardly assessed on the collision channel model, which
assumes that (i) transmissions occurring in singleton slots are successfully received
(i.e., decoded) with probability 1, and (ii) any transmission occurring in a collision
slot is not received with probability 1. One of the basic performance metrics of SA is
the expected throughput, denoted by T , which is the measure of the efï¬ciency of the
use of the slots. Speciï¬cally, the expected throughput can be deï¬ned as the average
number of transmissions (i.e., user packets) that can be successfully decoded in a
slot, which, for the collision channel model, is equal to the probability that the slot
is singleton. Denoting the slot access probability by pA, the throughput is computed
as
T = Pr{slot is singleton} =
N
1

pA(1 âˆ’pA)Nâˆ’1 â‰ˆNpAeâˆ’Npa,
(1)
where N denotes the number of accessing users, and where the approximation holds
as N â†’âˆ, and NpA = Î², where Î² is a constant. Obviously, in order to boost the
throughput of SA for the collision channel model, one should maximize the proba-
bility that an observed slot is singleton, which is done by optimizing the slot-access
probability pA. It is easy to verify that, asymptotically, the limit on the maximum
expected throughput is 1
e packet/slot, achieved when pA = 1
N (i.e., Î² = 1).

Coded Random Access
341
Fig. 2 Frame slotted
ALOHA: The users perform
access by transmitting in
randomly selected slots of
the frame
A scheme closely related to SA is the so-called framed slotted ALOHA (FSA),
where the time-slots are organized into frames, and the users are both frame- and
slot-synchronized. In FSA, a user attempts the access by transmitting in a randomly
selected slot in the frame, see Fig.2. Using similar arguments as in case of SA, it is
easy to verify that asymptotic limit on the maximum expected throughput of FSA
for the collision channel model is again 1
e, achieved when the number of the slots in
the frame, denoted by M, is equal to the number of accessing users N.
The collision channel model may serve as a valid approximation only for narrow-
band, single antenna systems, in which powers of the signals transmitted by users
are the same at the point of reception and in which the impact of the noise can be
neglected. On the other hand, the collision channel fails to accurately model the cases
when the signal powers at the point of reception are unequal, which may happen due
to fading and shadowing â€“ the phenomena characteristic for wireless transmissions,
and/or when the noise power is substantial relative to the received signal power. In
particular, in the former case, the capture effect may occur in collision slots, when
one of the signals involved in a collision is sufï¬ciently stronger then the interfering
signals and the noise combined, and thus becomes successfully decoded; in other
words, the existence of the capture effect removes the assumption of collision slots
being unusable by default. In the latter case, the noise may prevent receiving a signal
in a singleton slot; i.e., the singleton slots may not be usable by default.
A model often used due to its simplicity and analytical tractability is the threshold-
based capture model, according to which a signal is successfully received (i.e., cap-
tured) in a slot if its signal-to-interference-and-noise ratio (SINR) is above a certain
threshold. Speciï¬cally, by the threshold-based capture model, the capture occurs if
PS
PN + PI
â‰¥b,
(2)
where PS, PN and PI are the signal power, the noise power and the combined power
of the interfering signals, respectively, and b is the capture threshold. It is typically
assumed that b does not depend on the SINR. Also, note that in the case when PI = 0,
which holds for singleton slots, the signal has to capture the slot against the noise.

342
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
Fig. 3 Example of FSA with iterative IC: Initially, packet 2 is decoded in singleton slot 3. In
the next step, the replica of packet 2 is cancelled from slot 1. Slot 1 now becomes singleton and
packet 1 becomes decoded. The replica of packet 1 is cancelled from slot 4, slot 4 becomes sin-
gleton and packet 3 becomes decoded. The throughput in this example is 3/4 packet/slot, while the
throughput of standard FSA would be 1/4 packet/slot
Fig. 4 Graph representation of the example in Fig.3: The decoding and the removal of replicas
correspond to the removal of the graph edges
2
Coded Slotted ALOHA
A substantial improvement of FSA performance can be achieved by modifying the
scheme such that (i) a user accesses the shared medium by sending replicas of its
packet in multiple slots of the frame, where each replica embeds a pointer to all
other replicas, and (ii) when a replica is decoded, it is removed from the slot as well
as all other replicas from the corresponding slots using an interference cancellation
(IC) algorithm.1 During this modiï¬ed reception procedure, some of the slots affected
by the IC may provide for the decoding of new packets, propelling new iterations
of the IC, etc., as depicted in Fig.3. The ultimate result is that the overall number
of successfully received packets may signiï¬cantly increase in comparison to FSA
without IC, implying better slot utilization, and hence, larger throughputs. The price
to pay is that the scheme requires buffering of the (composite) signals received in
the slots, as well as additional signal processing in order to perform the IC.
The iterative decoding of usersâ€™ packets and application of IC can be represented
via removal of the edges on the corresponding graph, see Fig.4. Moreover, for the
collision channel model, this graph representation is completely analogous to the
graph representation of the iterative belief-propagation of erasure-correcting codes.
In other words, the theory and tools of codes-on-graphs can be applied to the analysis
and design of SA-based schemes that exploit iterative (i.e., successive) IC, referred
1Throughout the text it is assumed that the IC is perfect, i.e., the signal affected by the IC is perfectly
â€œerasedâ€ from the slot.

Coded Random Access
343
Fig. 5 Bipartite graph
representation of the access
scheme
to with an umbrella term Coded Slotted ALOHA (CSA). CSA schemes can asymp-
totically achieve throughput of 1 packet per slot on the collision channel, which is
the ultimate bound for this channel model.
2.1
Graph Representation
The contention process of CSA can be represented via a bipartite graph, see Fig.5,
standardly used for the representation of codes-on-graphs. The nodes on the left
represent users, the nodes on the right represent slots, and an edge that connects a
user node with a slot node corresponds to a transmission of the user packet replica.2
The number of edges incident to a user node u is called user degree, denoted by |u|.
Correspondingly, the number of edges incident to a slot node s is called slot degree
|s|.
In the basic version of frame-based CSA, so-called Irregular Repetition Slot-
ted ALOHA (IRSA), each user randomly and independently selects its degree,
i.e., number of replicas to be sent, from a predeï¬ned probability distribution Î›k,
k = 1, . . . , M,
Î›k = Pr{|u| = k},
(3)
where Î± = M
k=1 kÎ›k is the average user degree. In the next step, each user u ran-
domly, independently and without repetition chooses |u| out of M slots from the
frame, in which it sends replicas of its packet. In this way, the bipartite graph is
created.
It is easy to verify the slot degrees are independent and identically distributed
(i.i.d.) binomial random variables. In particular,
Î©l = Pr{|s| = l} =
N
l
  Î²
N
l 
1 âˆ’Î²
N
Nâˆ’l
,
(4)
2In the rest of text, the terms user/user node, slot/slot node, and edge/replica will be used inter-
changeably.

344
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
where Î² = Î±N
M is the average slot degree,3 and Î²
N is the probability that a user chooses
a particular slot when transmitting a replica. Letting M, N â†’âˆ, and M âˆN, (5)
becomes
Î©l = Î²l
l! eâˆ’Î²,
(5)
i.e., |s| becomes a Poisson distributed random variable. For the ease of exposition,
it is customary to use polynomial notation to denote the user and the slot degree
distributions:
Î›(x)
def
=
M

k=1
Î›kxk,
(6)
Î©(x)
def
=
N

l=1
Î©lxl â‰ˆeâˆ’Î²(1âˆ’x),
(7)
where (7) follows from (5). Strictly speaking, Î›(x)/Î©(x) are referred to as node-
oriented user/slot degree distributions. There are also edge-oriented user/slot degree
distributions, which correspond to probabilities that a randomly chosen edge is con-
nectedtoauser/slotnodeofacertaindegree.Speciï¬cally,denotebyÎ»k theprobability
that an edge is connected to a user node of degree k and by Ï‰l the probability that an
edge is connected to a slot node of degree l. Î»k can be computed as
Î»k = kÎ›k N
NÎ±
= kÎ›k
Î± , k = 1, . . . , M,
(8)
where kÎ›k N is the number of edges incident to user nodes of degree k and NÎ± is
the total number of edges. Similarly, Ï‰l can be computed as
Ï‰l = lÎ©l
Î²
â‰ˆ
Î²lâˆ’1
(l âˆ’1)!eâˆ’Î², l = 1, . . . , N.
(9)
The edge-oriented user/slot degree distributions are compactly written as
Î»(x)
def
=
M

k=1
Î»kxkâˆ’1 = 1
Î±
M

k=1
kÎ›kxkâˆ’1 = Î›â€²(x)
Î±
,
(10)
Ï‰(x)
def
=

l=1
NÏ‰lxlâˆ’1 = 1
Î² =
N

l=1
lÎ©lxlâˆ’1 = Î©â€²(x)
Î²
â‰ˆeâˆ’Î²(1âˆ’x),
(11)
where Fâ€²(x) denotes the derivative of F(x), and where (11) follows from (7).
3It is easy to verify that Î² = N
l=1 lÎ©l.

Coded Random Access
345
Fig. 6 The tree
representation of the iterative
reception algorithm of CSA
2.2
Asymptotic Performance Evaluation
There is an elegant way to perform the asymptotic performance evaluation of IRSA
on the collision channel, derived from the so-called and-or tree evaluation. The
underlying assumption is that, as M, N â†’âˆ, the bipartite graph of the scheme does
not contain loops and can be unfolded into a rooted tree, see Fig.6. The evaluation
models the iterative reception algorithm and is concerned with the iterative updates
of the probabilities that: (i) an edge incident to a slot node is not removed,4 denoted
by pi, and (ii) the an edge incident to user node is not removed, denoted by qi,
where i denotes the iteration of the IC. Note that a single iteration consists of two
probability updates.
Pick an edge incident to a slot of degree l in the i-the iteration of the and-or tree
evaluation, and designate it as the reference edge. For the collision channel model,
the probability that the reference edge is removed is
1 âˆ’p(l)
i
= (1 âˆ’qiâˆ’1)lâˆ’1,
(12)
i.e., the edge is removed if and only if all the other l âˆ’1 edges incident to the
slot node have been removed via interference cancellation in previous iteration,
which happens with probability (1 âˆ’qiâˆ’1)lâˆ’1.5 Averaging over the edge-oriented
slot degree distribution yields
pi =

l
Ï‰l p(l)
i
= 1 âˆ’

l
Ï‰l(1 âˆ’qiâˆ’1)lâˆ’1 = 1 âˆ’Ï‰(1 âˆ’qiâˆ’1) = 1 âˆ’eâˆ’Î²qiâˆ’1.
(13)
Similarly, pick an edge user node of degree k in the i-the iteration of the and-
or tree evaluation, and designate it as the reference edge. The probability that the
reference edge is not removed is equal to
4I.e., the corresponding packet replica is not decoded.
5Obviously, the recovery of the user packet in a slot can be modeled as logical â€˜andâ€™ operation.

346
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
q(k)
i
= pkâˆ’1
i
,
(14)
i.e., the edge is not removed only if none of the other edges incident to a user node
has been removed in the iteration.6 Averaging over the user edge-oriented degree
distribution yields
qi =

k
Î»kq(k)
i
=

k
Î»k pkâˆ’1
i
= Î»(pi) = Î»(1 âˆ’eâˆ’Î²qiâˆ’1).
(15)
The initial value is q0 = 1; i.e., initially, all edges are present in the graph. The output
of the evaluation is the probability that a user packet is recovered
PR = 1 âˆ’lim
iâ†’âˆqi.
(16)
The throughput can be calculated as
T = N PR
M
= G PR,
(17)
where G = N
M is the load of the scheme.
Evidently, from (15)â€“(17), the asymptotic performance crucially depends on the
choice of Î»(x) and the average slot degree Î², where Î² = GÎ±. On the other hand, both
Î»(x) and the average user degree Î± depend on Î›(x). Therefore, the performance of
the scheme ultimately depends on Î›(x) and the load G. The threshold of the scheme,
denoted by Gâˆ—, is deï¬ned as the maximum value of the load for which the following
condition holds
q > Î»(1 âˆ’eâˆ’qGÎ±), âˆ€q âˆˆ(0, 1].
(18)
Comparing (18) with (15) reveals that, for given Î›(x), Gâˆ—is the maximum load for
which the probability of not recovering user packet will decrease over the iterations
of the reception algorithm. In other words, for given Î›(x) and when G â‰¤Gâˆ—, the
probability of user recovery PR tends to 1, and, thus, T becomes equal to G, see
(17). Finally, it can be proven the upper bound on the achievable threshold, denoted
by Gmax for any user degree distribution whose average degree is Î± is given by
Gmax = 1 âˆ’eâˆ’GmaxÎ±.
(19)
6I.e., a packet is recovered if any of its replicas is decoded, which can be modeled via logical â€˜orâ€™.

Coded Random Access
347
2.3
Frameless ALOHA
Frameless ALOHA is a variant of CSA that has two distinctive features: (i) frame-
length is not a-priori deï¬ned, but determined on-the-ï¬‚y such that the instantaneous
throughput is maximized, and (ii) like in the original SA framework, each user
independently decides whether to transmit its packet replica on the slot basis using
a predeï¬ned slot access probability.
Assume that the slot access probability pA is uniform for all users and over all
slots
pA = Î²
N ,
(20)
where N denotes the number of users. Assume that all users are synchronized, such
that they start contending from the ï¬rst slot of the frame and denote the current length
of the frame as M. The probability the a user degree is equal to k, k = 0, . . . , M, is
Î›(k) =
M
k

pk
A (1 âˆ’pA)Mâˆ’k =
M
k
  Î²
N
k 
1 âˆ’Î²
N
Mâˆ’k
â‰ˆ

Î²
G
k
k!
eâˆ’Î²
G ,
(21)
where G here denotes the current load. Thus, the edge-oriented user degree distribu-
tion (10) becomes
Î»(x) = eâˆ’Î²
G (1âˆ’x),
(22)
while (15) evaluates to
qi = eâˆ’Î²
G eâˆ’Î²qiâˆ’1 .
(23)
Asymptotic performance of frameless ALOHA cannot reach the one of IRSA,
due to the simplicity of the scheme. In fact, the probability of a user not transmitting
at all is
Î›0 â‰ˆeâˆ’Î²
G ,
(24)
which also implies that a user packet can not be recovered at least with the same
probability. In other words, PR â‰¥1 âˆ’Î›0, and Î›0 â†’0 only when G â†’âˆ. How-
ever, the key strength of frameless ALOHA is the capability to adapt to the actual
evolution of the iterative reception algorithm, attempting to terminate the contention
when the instantaneous throughput is maximized. The instantaneous throughput is
deï¬ned as
TI = NR
M ,
(25)

348
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
Fig. 7 Frameless ALOHA:
An example of the evolution
of the instantaneous
throughput TI and the
instantaneous fraction of
resolved users FI as the
number of the slots in the
frame increases M
0
25
50
75
100
125
150
M
0
0.2
0.4
0.6
0.8
1
=2.7, N = 100
TI
FI
where NR is the current number of recovered users and M denotes the current frame
length. Similarly, the instantaneous fraction of resolved users is deï¬ned as
FI = NR
N .
(26)
Figure7 shows an example how TI and FI change with M for an instance of frameless
ALOHA. For this instance, the optimum frame length that maximizes the throughput
is when M = 120 and TI = 0.8. An optimal contention-termination criterion has to
identify when the maximum TI has been reached in every instance of the contention,
where both the slot-position of the maximum and the value of the maximum vary
across the instances.
2.4
Performance of CSA on Block Fading Channels with the
Threshold-Based Capture Model
Assume that the wireless links between the users and the AP are affected with block-
fading and noise, such that the composite signal received in slot sm, denoted by Sm
is
Sm =

nâˆˆA m
hm,nUn + Zm, m = 1, . . . , M,
(27)
where Am is the set of the indices of the users active in sm, hm,n is the channel
coefï¬cient between the user un and the AP that describes the impact of the block-
fading, Un is the signal (i.e., packet replica) of user un, and Zm is the additive white
Gaussian noise. The total received power in sm is

Coded Random Access
349
Rm =

nâˆˆA m
||hm,nUn||2 + PN,
(28)
where the expected noise power PN is constant for all slots. A frequent assumption
is that the users are able to perform long-term power control, such that the expected
powers of their transmissions at the point of reception are the same and equal to some
constant P. Further, assuming that hm,n are i.i.d. random variables for every m and
nm, (28) can be transformed to
Rm =

nâˆˆA m
Xn P + PN,
(29)
where Xn is the random variable with unit power describing the impact of fading.
In the threshold-based model, the capture of signal U j in slot sm occurs if
X j
k
nâˆˆA m,nÌ¸= j Xn + PN/P
â‰¥b,
(30)
c.f. (2). Moreover, the use of IC potentially enables the iterative recovery of col-
lided signals within sm. Speciï¬cally, if (30) is satisï¬ed and U j recovered, then U j
is removed from sm (as well as all other slots where its replicas appear) and the
condition (30) may become satisï¬ed for some of the signals remaining in sm. In
other words, besides inter-slot IC, the fading and capture effect also enable intra-
slot IC; note that the latter is not possible for the collision channel model. In terms
of the asymptotic performance evaluation, the possibility of performing intra-slot IC
impacts the probability of user recovery (12) in the following way
p(l)
i
= 1 âˆ’
lâˆ’1

t=0
C(t)
l âˆ’1
t

qt
iâˆ’1(1 âˆ’qiâˆ’1)lâˆ’tâˆ’1,
(31)
where C(t) is the probability that the reference edge is removed in slot of degree l
where l âˆ’t âˆ’1 edges have been removed via inter-slot IC in the previous iteration
(i.e., t + 1 edges remain in the slot).7 Assuming that b â‰¥1, i.e., that the receiver is
able to decode a single transmission at a time, C(t) can be further decomposed into
C(t) =
t
r=0
C(t,r)
(32)
where C(t,r) is the probability that the reference edge is recovered after r applica-
tions of the intra-slot IC.
7Note that for the collision channel model, it is implicitly assumed that C(0) = 1 and C(t) = 0,
t = 1, . . . ,l âˆ’1.

350
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
Without loss of generality and the slight abuse of notation, label the edges remain-
ing in slot sm at the start of the iteration i in the following way: (i) the ï¬rst r are
arranged by their powers in the descending order, (ii) the rest have their powers lower
than the power of the edge r but do not feature any particular arrangement, (iii) the
reference edge is labeled by r + 1, and (iv) the remaining t âˆ’r edges are labeled
arbitrarily. Then, the probability C(t,r) is equal to
C(t,r) =
t!
(t âˆ’r)!Ã—
Ã— Pr

X1
t+1
j=2 X j + PN/P
â‰¥b;
X2
t+1
j=3 X j + PN/P
â‰¥b; . . . ;
Xr+1
t+1
j=r+2 X j + PN/P
â‰¥b
	
,
(33)
where Xi is the power of the ith edge, and where
t!
(tâˆ’r)! is the number of realizations
in which the power of the reference edge is not among r largest.8
If the coefï¬cients hm,n are i.i.d. Rayleigh distributed random variables, which is an
often used model in wireless communications, the probability distribution function
of X j is given by
pX j(x) = eâˆ’x, x â‰¥0, j = 1, . . . , t + 1.
(34)
It can be shown that in this case (33) evaluates to
C(t,r) =
t!
(t âˆ’r)!
eâˆ’1
Î³ ((1+b)r+1âˆ’1)
(1 + b)(r+1)(t+1âˆ’r+2
2 ) ,
(35)
where Î³ =
P
PN is the expected signal-to-noise ratio.
Combining (35), (33) and (31) produces
p(l)
i
= 1 âˆ’
lâˆ’1

t=0
t
r=0
t!
(t âˆ’r)!
eâˆ’1
Î³ ((1+b)r+1âˆ’1)
(1 + b)(r+1)(t+1âˆ’r+2
2 )
l âˆ’1
t

qt
iâˆ’1(1 âˆ’qiâˆ’1)lâˆ’tâˆ’1
(36)
= 1 âˆ’
lâˆ’1

t=0
t
r=0
l âˆ’1!
(t âˆ’r)!(l âˆ’t âˆ’1)!
eâˆ’1
Î³ ((1+b)r+1âˆ’1)
(1 + b)(r+1)(t+1âˆ’r+2
2 ) qt
iâˆ’1(1 âˆ’qiâˆ’1)lâˆ’tâˆ’1,
(37)
and averaging over the edge-oriented slot degree distribution yields
8It is assumed that the all realizations in terms of the ordering of the powers are a priori equally
likely.

Coded Random Access
351
pi =

l
Ï‰l p(l)
i
= 1 âˆ’

l
Î²lâˆ’1
(l âˆ’1)! p(l)
i
(38)
= 1 âˆ’eâˆ’Î² 
l
Î²lâˆ’1
lâˆ’1

t=0
t
r=0
eâˆ’1
Î³ ((1+b)r+1âˆ’1)
(t âˆ’r)!(l âˆ’t âˆ’1)!
qt
iâˆ’1(1 âˆ’qiâˆ’1)lâˆ’tâˆ’1
(1 + b)(r+1)(t+1âˆ’r+2
2 ) .
(39)
As an example, for frameless ALOHA with Î² = 7.21, capture threshold b = 1,
and the expected signal-to-noise-ratio Î³ = 10, the maximum throughput that can be
achieved is 2.37 packet/slot, which is signiï¬cantly above the absolute upper bound
of 1 packet/slot that holds for the collision channel.
3
Coded Slotted ALOHA for Multi-AP Scenario
ThepreviouspartofthechapterconsideredtheCSAschemeinthesingleAPscenario.
However, in many wireless communication scenarios of interest, a user transmission
can be detected at multiple APs. Examples include satellite communication networks,
networks of WiFi APs, or dense deployment of cellular base stations in urban areas,
including e.g., the cellular small cell networks. One such scenario is illustrated in
Fig.8, where a large number of sensors attempt to upload their packets to a network
of APs.
In multi-AP scenarios, as introduced earlier, each AP can exploit the temporal
diversity of userâ€™s packet replicas via IC across the time slots. However, the CSA
scheme can also exploit the spatial diversity, where IC is done across multiple APs
in a single time slot. More precisely, due to limited range of user transmissions, a
packet replica of a transmitting user may appear as a singleton slot at one of the
surrounding APs, while at the same time being a collision slot at other surrounding
Fig. 8 Multi-AP communication scenario

352
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
APs. In that case, an AP decoding a clean packet replica in a singleton slot can
(spatially) cooperate with neighboring APs by sharing the decoded packet replica,
thus allowing them to use IC to remove the replica from their collision slots.
In the rest of this chapter, we formalize more precisely the model for multi-
AP scenario and provide a brief review of some of the recent results and possible
directions for further study.
3.1
System Model for CSA in Multi-AP Scenario
We consider a scenario with N contending users and M APs, where both users and
APs are placed independently and uniformly at random in a unit-square area. The
time domain is slotted and slots are organized into frames containing Ï„ slots per
frame. The system is both frame- and slot-synchronous across all APs and all users.
As in CSA, each user transmits packet replicas in one or more randomly selected
slots within the frame, where the number of transmitted replicas is governed by the
(temporal) degree distribution Î›(x) = 
i Î›ixi, and Î›i is the probability of sending
i replicas. However, unlike in the single-AP model, in the multi-AP model we assume
that a user transmission is of limited range, so that the userâ€™s signal can be detected
only by APs that lie in a circle of radius r centered at the user. The system load is
deï¬ned as the number of users per AP per slot: G = N/(MÏ„).
After users transmit their replicas in a given frame, the decoding process at all
the APs is initiated. We consider two decoding models: (i) non-cooperative, where
APs do not cooperate during the decoding process, and (ii) cooperative, where APs
cooperate by exchanging decoded usersâ€™ replicas during the decoding process. Note
that the cooperative case requires that if two APs exchange information, i.e., if they
share common users, then they have to be connected via a backhaul link. After the
decoding process is ï¬nished, each user is decoded if and only if it is decoded by
any of the APs in the network (thus we assume no explicit user-to-AP association).
We are interested in the two main performance metrics: (i) the probability that an
arbitrary user is recovered, denoted as PR, and (ii) the system throughput T deï¬ned
as T = G Â· PR, both of which depend on the system load G.
For convenience, it is useful to introduce a graph representation of the multi-
AP setup. To this end, we deï¬ne two different but related graph models. The
ï¬rst model illustrates the connectivity between the users and the APs. Let U =
{U1,U2, . . . ,UN} represents the set of user nodes, and B = {B1, B2, . . . , BM} rep-
resent the set of AP nodes. An edge of the graph connects the user node Ui and the
AP node B j iff the jth AP is within the range r of the ith user. The resulting graph
G = (U âˆªB, EG ) is a random bipartite geometric graph. We denote the (spatial)
degree distributions of user and AP nodes as Q(x) = 
i Qixi and R(x) = 
i Rixi,
respectively, where Qi (resp. Ri) is the probability a user (resp. AP) node is of
degree i.
The second graph model reï¬nes the previous spatial model by introducing the
temporal dimension. In other words, it expands each AP node into Ï„ slot nodes

Coded Random Access
353
observed at the AP during a frame of duration Ï„. Thus, apart from the set U , we
now have the set S of slot nodes Sj,t, 1 â‰¤j â‰¤M, 1 â‰¤t â‰¤Ï„, representing the tth
time slot at the jth AP. An edge of the graph connects the user node Ui and the
slot node Sj,t if and only if: (i) the ith user transmitted a replica in the tth time
slot, and (ii) the jth AP is within the range r from the ith user. The resulting graph
H = {U âˆªS , EH } is a random bipartite geometric graph. We denote the degree
distributions of the user and the slot nodes in H as U(x) and S(x), and note that
they are easily derived from Î›(x), Q(x) and R(x).
Figure9 illustrates an example of the graph representation of the multi-AP system
from Fig.8, for a simple case when the frame contains a single slot, i.e., Ï„ = 1. Note
that, in this case, the two graph models G and H are equivalent. Figure10 illustrates
an example of the same multi-AP scenario for the frame length equal Ï„ = 3 slots. In
this case, Fig.10 represents the graph H , while the underlying graph G remains the
same as in Fig.9.
Similarlyasinthesingle-APmodel,thegraphmodelH isusefulforformalization
of the iterative IC decoding algorithm. We also consider the iterative IC decoding that
resembles the iterative graph-peeling erasure decoder for LDPC codes. However, the
Fig. 9 Graph representation of the multi-AP model (Ï„ = 1)
Fig. 10 Graph representation of the multi-AP model (Ï„ = 3)

354
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
IC decoder now operates on the graph H of the multi-AP model. Due to the fact that
this graph is based on the random bipartite geographic graph model, analyzing the
decoding performance is considerably more challenging for the multi-AP scenario.
Unfortunately, asymptotic analysis based on the density evolution method, which is
a standard tool for analyzing the IC decoders on sparse random graphs, does not hold
here. This follows from the fact that the probability of appearance of small cycles in
the underlying (geometric) graph does not vanish asymptotically with the size of the
graph.
In the following subsection, we discuss the performance of the IC decoding over
the graph models for the multi-AP scenario. We consider four different decoding
scenarios depending on the assumptions if the APs cooperate during the decoding
process and if each AP performs temporal IC decoding.
3.2
Performance of CSA in Multi-AP Scenario
In this section, we consider the performance of the iterative IC decoder in the multi-
AP scenario under the asymptotic setting. We let the number of user nodes N â†’âˆ
and the number of APs M = M(N) â†’âˆ, the number of slots in the frame Ï„ â†’âˆ
and the transmission range r â†’0, under constraints that the average number of APs
within the range of a user: Mr2Ï€ â†’Î´, and the load: N/(MÏ„) â†’G, where Î´ and G
are positive constants. We ignore the edge-effects of users/APs placed close to the
edges of the unit-square area as they asymptotically vanish.
In the asymptotic setup, it is easy to show that the spatial degree distribution of
users Q(x) is a Poisson distribution with parameter Î´. Thus an upper limit on PR is the
probability that a user is not heard by any AP, which equals PR â‰¤1 âˆ’exp(âˆ’Î´). For
different decoding scenarios, we will be interested in the (asymptotic) user recovery
probability PR and the system throughput T . We will be also interested in threshold
phenomena involving the system load G; namely, the maximum load Gâ‹†(Î´) for which
the decoding scheme is still able to achieve the upper bound:Gâ‹†(Î´) = sup{G â‰¥0 :
PR â†’1 âˆ’eâˆ’Î´}.
Case 1: Non-cooperative Decoding Without Temporal IC - In this model,
each AP follows standard SA protocol without IC decoding across the time slots.
In addition, APs do not communicate and exchange information with each other. In
this case, it is sufï¬cient to observe the decoder operation on a multi-AP graph with
a frame length Ï„ = 1 (as in Fig.9). Note that the decoding process will be able to
collect all the users that have at least one edge incident to a degree one AP. However,
characterizing the number of such users is a rather challenging task.
â€¢ Recovery probability:
PR â†’
âˆ

k=1
(âˆ’1)kâˆ’1 Î´k
k!

 4
1
eâˆ’aÎ´GdÎ¼k(a),
(40)

Coded Random Access
355
where Î¼k is the probability distribution of Î±k: the area covered by the union of
k circles randomly thrown in a circle of radius r, normalized by Ï€. However,
although above equation provides exact asymptotic limit, calculating PR as above
is a tedious task, albeit solvable using numerical methods.
â€¢ Throughput: Let Îµ = exp(âˆ’Î´), then the peak normalized (per AP) throughput is
lower-bounded as T â‹†â‰¥1
e
1âˆ’Îµ
ln(1/Îµ).
â€¢ Threshold load: Gâ‹†(Î´) = 0. In other words, PR splits away from 1 âˆ’exp(âˆ’Î´)
exactly at G = 0.
Case 2: Cooperative Decoding Without Temporal IC - Performance improve-
ment over the previous case is obtained if the APs are allowed to share decoded userâ€™s
replicas. As in the previous case, it is sufï¬cient to observe the decoder operation on
a multi-AP graph with Ï„ = 1 (Fig.9). The cooperative decoding reduces to the iter-
ative graph-peeling erasure decoder on the underlying random bipartite geometric
graph G . Unfortunately, as noted earlier, rich asymptotic analysis tools from coding
theory do not directly apply to this scenario, due to the fact that very short cycles do
not asymptotically vanish.
â€¢ Recovery probability:
PR â‰¤1 âˆ’eâˆ’Î´ âˆ’(1 âˆ’eâˆ’Î´/4)eâˆ’2Î´(1 âˆ’eâˆ’GÎ´/4).
(41)
The above bound follows from analyzing the probability of occurrence of the
stopping sets of size two in an underlying random bipartite geometric graph.
â€¢ Threshold load: Gâ‹†(Î´) = 0. As in the previous case, PR splits away from 1 âˆ’
exp(âˆ’Î´) at G = 0, however, compared to Case 1, the negative slope of decay at
G = 0 is signiï¬cantly lower, thus providing better performance of spatial cooper-
ation over non-cooperative case.
The above two cases show that, without temporal IC across the time slots at each
AP, it is difï¬cult to exploit the full power of IC decoding due to the structure of the
underlying geometric graphs.
Case 3: Non-cooperative Decoding with Temporal IC - In this scenario, we
observe a system of M APs distributed in a unit-square area that do not cooperate, but
independently run the CSA across time slots of a frame. If observed independently,
the performance of each AP depends only on the temporal degree distribution Î›(x)
the users apply to generate replicas. More precisely, for a given Î›(x) and the load
H (number of users per slot), let P S
R(H) be the user recovery probability in the
asymptotic setup (where the number of users and slots tend to inï¬nity, but their ratio
tends to H). Then, a threshold load H â‹†exists such that, for H â‰¤H â‹†, it holds that
P S
R(H) = 1. As we present next, using the performance of CSA in the single-AP
case, we can express the performance of non-cooperative decoding with temporal IC
in the multi-AP case.
â€¢ Recovery probability:
PR â‰¤(1 âˆ’eâˆ’Î´)P S
R(H = 8eÎ´G).
(42)

356
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
â€¢ Throughput: Let Îµ = exp(âˆ’Î´), then the peak normalized (per AP) throughput is
lower-bounded as T â‹†â‰¥H â‹†
8 e
1âˆ’Îµ
ln(1/Îµ).
â€¢ Threshold load: Gâ‹†(Î´) â‰¥
1
8e
H â‹†
Î´ . In other words, the recovery probability stays at
the maximal possible value 1 âˆ’exp(âˆ’Î´) at least in the range G âˆˆ[0, 1
8e
H â‹†
Î´ ].
Case 4: Cooperative Decoding with Temporal IC - Performance-wise, this case
is the most powerful decoding scenario, where the IC decoder operates across the
complete spatio-temporal graph H (such as the one in Fig.10). However, compared
to the Case 3, no stronger results exist for this case (note that the bounds for Case 3
also hold for Case 4). In the following, we differentiate the performance of Case 4
from the previous cases using simulations.
Numerical results: In the simulation setup, we set the number of base stations
M = 40, and the number of slots in the frame to Ï„ = 40. We simulate the recovery
probability PR versus G = N/(MÏ„) by varying N. We perform Monte Carlo simu-
lations where for each N, we generate 30 random placements of users and APs. For
the cases with temporal IC, we apply the temporal degree distribution Î›(x) = x2
(i.e., each user generates two replicas per frame).
Figure11 plots the normalized throughput T (G) versus normalized load G for the
four decoding cases, assuming Î´ = 6. We can see that the Case 4 (spatio-temporal
cooperation) achieves much higher peak normalized throughput than the remaining
three schemes.
Fig. 11 Performance comparison of multi-AP decoding schemes

Coded Random Access
357
3.3
Discussion and Open Problems
In the case of CSA in Multi-AP scenario, a number of open problems arise that yet
have to be solved. Note that even the simplest extension to Multi-AP scenario, the
case of SA without cooperation and without temporal IC (Case 1) lacks an elegant
and closed-form solution for the average system throughput. In the following, we
provide several scenarios which we ï¬nd relevant and which are subject of our current
study.
Different Multi-AP Models; The Multi-AP model presented in this chapter is
mainly motivated by applications in dense cellular systems where APs correspond to
small base stations. In this case, the geometric graph model is a reasonable approxi-
mation of a user to AP coverage and connectivity. However, in certain scenarios such
as satellite networks, all users might be heard at all satellites, although with different
channel conditions (e.g., some user-to-AP channels being exposed to harsh fading
while others not). This has led to slightly different and analytically more tractable
model, wherein underlying graph representation follows random graph model (unlike
random geometric graph model).
Asynchronous System Operation: In reality, signals transmitted from users will
travel different distances to different neighbouring APs, thus arriving at APs with
different delay. This delay variability may vary from rather small in dense small cell
networks, to very large in multi-AP satellite systems. Thus the assumption that the
system is perfectly slot synchronized across all users and all APs might be impossi-
ble to achieve in practice. In more realistic model, we might explore the scenario in
which users are asynchronous and send their packet replicas in arbitrary time instants
which are not aligned to slot boundaries. Such a system may still employ IC decod-
ing and may still provide signiï¬cant performance improvements over traditional
ALOHA. Thus the performance of asynchronous ALOHA in Multi-AP scenario is
an interesting and relevant research direction.
Multi-AP Models with Directional Antennas: The latest trends in wireless com-
munications advocate shifting the operational communications band to higher fre-
quencies above 6GHz into the so called mmWave band. In such an environment, to
overcome high signal attenuation, typical transmission strategies involve directional
antennas in which the transmitted signal is emitted as a focused and narrow-angle
beaminacertaindirection.AninterestingextensiontoCSAinMulti-APenvironment
would be to observe how the system throughput changes with the transition towards
mmWave communications and narrow-beam antennas. Our preliminary results show
that this should help improving the system throughput in ultra-dense deployments
since users transmitting in narrow beams could better avoid interfering each other,
which in terms of the underlying graph representation means that the occurrence
of short cycles could be signiï¬cantly reduced, leading to better performance of the
iterative IC decoding.

358
Ë‡C. StefanoviÂ´c and D. VukobratoviÂ´c
4
Literature Review
The performance of slotted ALOHA was analyzed in [13]. Framed slotted ALOHA
was proposed in [9]. The threshold-based capture model was topic of multitude
works, c.f. [8, 17â€“19].
There is an abundance of literature related to CSA. In the following, some of
notable works are brieï¬‚y mentioned. An accessible overview of CSA is presented
in [12]. FSA with iterative IC was originally proposed in [1], assuming that each
user sends two replica in randomly selected slots of the frame and showing that the
maximum expected throughput on the collision channel is 0.55 packet/slot [1]. IRSA
was introduced in [4], where it was also shown how to design user degree distributions
whose thresholds are close to 1. The upper bound on the threshold of any user degree
distribution with a given average degree was derived in [10]. A generalization of
the scheme, in which users contend with segments produced by applying a linear
segment-oriented code on the segments of the user packet, is introduced and analyzed
in [11].
Frameless ALOHA was inspired by the rateless coding paradigm [5]; it was
introduced and its asymptotic performance analyzed in [15]. The optimization of the
termination criterion that maximizes expected throughput of the scheme in scenarios
with ï¬nite number of users was addressed in [14].
Derivation of the and-or tree evaluation for the threshold-based capture model
was performed in [16]; the same work also addresses the performance of frameless
ALOHA for Rayleigh black-fading channel with the threshold-based capture effect.
Design of the user degree distributions for IRSA on Rayleigh black-fading channel
with threshold-based capture was assessed in [2].
The and-or tree evaluation was originally conceived in [6].
CSA in Multi-AP scenario is introduced and analyzed in [3]. The exposition in
this chapter follow this approach. Somewhat different model and overview of results
is also presented in [7].
References
1. E. Casini, R.D. Gaudenzi, O. del Rio Herrero, Contention resolution diversity slotted ALOHA
(CRDSA): an enhanced random access scheme for satellite access packet networks. IEEE
Trans. Wirel. Commun. 6(4), 1408â€“1419 (2007)
2. F. Clazzer, E. Paolini, I. Membeli, C. Stefanovic, Irregular repetition slotted ALOHA over the
Rayleigh block fading channel with capture, in Proceedings of IEEE ICC 2017. Paris, France
(2017)
3. D. Jakovetic, D. Bajovic, D. Vukobratovic, V. Crnojevic, Cooperative slotted ALOHA for
multi-base station systems. IEEE Trans. Commun. 63(4), 1443â€“1456 (2015)
4. G. Liva, Graph-based analysis and optimization of contention resolution diversity slotted
ALOHA. IEEE Trans. Commun. 59(2), 477â€“487 (2011)
5. M. Luby, LT codes, in Proceedings of 43rd IEEE FOCS. Vancouver, BC, Canada (2002)
6. M.G. Luby, M. Mitzenmacher, A. Shokrollahi, Analysis of random processes via And-Or tree
evaluation, in Proceedings of 9th ACM-SIAM SODA. San Francisco, CA, USA (1998)

Coded Random Access
359
7. A.Munari,F.Clazzer,G.Liva,MultireceiverALOHA:asurveyandnewresults,in Proceedings
of IEEE ICC 2015 - MASSAP Workshop. London, UK (2015)
8. G.D. Nguyen, A. Ephremides, J.E. Wieselthier, On capture in random-access systems, in Pro-
ceedings of IEEE ISIT 2006. Seattle, WA, USA (2006)
9. H. Okada, Y. Igarashi, Y. Nakanishi, Analysis and application of framed ALOHA channel
in satellite packet switching networks - FADRA method. Electron. Commun. Jpn. 60, 60â€“72
(1977)
10. E. Paolini, G. Liva, M. Chiani, Graph-based random access for the collision channel without
feed-back: capacity bound, in Proceedings of IEEE Globecom 2011. Houston, TX, USA (2011)
11. E. Paolini, G. Liva, M. Chiani, Coded slotted ALOHA: a graph-based method for uncoordinated
multiple access. IEEE Trans. Inf. Theory 61(12), 6815â€“6832 (2015)
12. E. Paolini, C. Stefanovic, G. Liva, P. Popovski, Coded random access: how coding theory helps
to build random access protocols. IEEE Commun. Mag. 53(6), 144â€“150 (2015)
13. L.G. Roberts, ALOHA packet system with and without slots and capture. SIGCOMM Comput.
Commun. Rev. 5(2), 28â€“42 (1975)
14. C. Stefanovic, P. Popovski, ALOHA random access that operates as a rateless code. IEEE
Trans. Commun. 61(11), 4653â€“4662 (2013)
15. C. Stefanovic, P. Popovski, D. Vukobratovic, Frameless ALOHA protocol for wireless net-
works. IEEE Commun. Lett. 16(12), 2087â€“2090 (2012)
16. C. Stefanovic, M. Momoda, P. Popovski, Exploiting capture effect in frameless ALOHA for
massive wireless random access, in Proceedings of IEEE WCNC 2014. Istanbul, Turkey (2014)
17. A. Zanella, M. Zorzi, Theoretical analysis of the capture probability in wireless systems with
multiple packet reception capabilities. IEEE Trans. Commun. 60(4), 1058â€“1071 (2012)
18. M. Zorzi, Capture probabilities in random-access mobile communications in the presence of
Rician fading. IEEE Trans. Veh. Technol. 46(1), 96â€“101 (1997)
19. M. Zorzi, R.R. Rao, Capture and retransmission control in mobile radio. IEEE J. Sel. Areas
Commun. 2(4), 1289â€“1298 (1994)

Part IV
Codes for Distributed
Storage Systems

An Overview of Coding for Distributed
Storage Systems
Shiqiu Liu and FrÃ©dÃ©rique Oggier
Abstract This chapter provides a short survey of coding for distributed storage
systems. It describes the code design criteria for such codes, emphasizing what
makes them different from traditional codes for communication. It then focuses
on two large families of codes, regenerating codes and locally repairable codes,
including a discussion on how these codes are used in an adversarial setting.
1
Distributed Storage Systems and Erasure Codes
A distributed storage system consists of a set of hard drives (disks), or nodes, which
is used to store data in a distributed manner: the same ï¬le could be stored multiple
times, one copy per hard drive, over a set of two, three, or more hard drives, or pieces
of the same ï¬le could be stored across a set of hard drives. Reasons why one may
want to store data in a distributed manner (rather than on a single disk) include
â€¢ ease of scale: if the system runs out of memory, one just adds more disks to the
storage system,
â€¢ reliability: if there is a single disk, and it fails, the stored data is lost, while if there
are several disks containing the same data, the data will have chances of surviving,
depending on the failure(s), and on how the data is stored.
If there are several disks, but each ï¬le is stored only on a single disk, then reliability
cannot be achieved, because in the event of this speciï¬c disk failure, data will be lost.
This is why redundancy is needed. The simplest form of redundancy is replication.
Two or three copies of a ï¬le are made, and they are all stored in different disks. The
S. Liu (B)
Institute of Network Coding-The Chinese University of Hong Kong,
Hong Kong, China
e-mail: sqliu@inc.cuhk.edu.hk
F. Oggier
Division of Mathematical Sciences, School of Physical and Mathematical
Sciences, Nanyang Technological University, Singapore, Singapore
e-mail: frederique@ntu.edu.sg
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_14
363

364
S. Liu and F. Oggier
notion of redundancy has been well studied in the context of noisy communication,
via coding theory: a signal is transmitted over a noisy channel, because of the noise,
part of the signal will be lost, so redundancy is added to the transmitted signal, to
help the receiver recover the transmitted signal, despite it being distorted through the
communication channel. The process of adding redundancy to the transmitted signal
is called â€œencodingâ€.
We will assume throughout this chapter that data can be modeled as a vector with
coefï¬cients in some ï¬nite ï¬eld Fq, for q a prime power. Encoding thus consists of
mapping a vector f âˆˆFM
q to a vector x âˆˆFn
q, called codeword, where n > M . The
set of codewords is called a code. If this mapping is linear, we can write x = fG for
some M Ã— n matrix G of rank M , and we speak of a linear code, with parameters
[n, M ], where n is the length and M the dimension. The simplest example of linear
code is the repetition code with parameters [n, 1] which maps f to a vector containing
n copies of f: (f, . . . , f). The repetition code corresponds to a replication scheme for
storage: there are n copies of f, each of them are stored on a different disk, over n
disks. This scheme is very reliable: there are n copies of f, therefore nâˆ’1 disk failures
can happen, and still the data will survive. The same is true for communication over
a noisy channel: up to nâˆ’1 transmitted signals can be lost, the intended message will
still be communicated reliably. The problem with this scheme is that its rate M /n is
poor, respectively its storage overhead n/M is high.
The trade-off between reliability and rate is well known in coding theory, and
is characterized by the Singleton bound. Reliability is captured by the minimum
Hamming distance dH of a code C:
dH(C) = min
xÌ¸=xâ€² d(x, xâ€²)
where d(x, xâ€²) counts in how many coefï¬cients the vectors x and xâ€² differ. The
minimum Hamming distance tells us that given a codeword in C, we can lose up to
dH(C)-1 coefï¬cients, and still be able to recover our data. This is because any x
differs in at least dH(C) coefï¬cients from any other xâ€². Now the Singleton bound
tells us, given n and M , what is the maximum possible dH.
Proposition 1 Given a code C of size |C| = qM , we have dH(C) â‰¤n âˆ’M + 1.
Proof Take the qM codewords of C, and look at their ï¬rst M âˆ’1 coefï¬cients. Since
we can have at most qM âˆ’1 distinct vectors of length M âˆ’1, among the vectors
obtained by looking at the ï¬rst M âˆ’1 coefï¬cients of qM vectors, there must be at
least two vectors which are the same by the pigeon hole principle, corresponding to
two codewords x Ì¸= xâ€² which are equal on their ï¬rst M âˆ’1 coefï¬cients, implying
that they can different at most on n âˆ’(M âˆ’1) coefï¬cients, which completes the
proof.
Codes reaching the Singleton bound are called maximum distance separable
(MDS) codes. The most famous class of MDS codes is the class of Reedâ€“Solomon
codes [33]. A Reedâ€“Solomon code C can be described as

An Overview of Coding for Distributed Storage Systems
365
C = {(p(w1), p(w2), . . . , p(wn)) : p(X ) =
M âˆ’1

i=0
piX i âˆˆFq[X ]}
(1)
wherew1, . . . , wn arendistinctelementsofFq (andthusn â‰¤q).Fromthedescription,
a codeword is made of n evaluations of a polynomial of degree M âˆ’1. Polynomial
interpolation tells us that we can recover the polynomial as long as we still have the
evaluation of p(X ) in at least M points, which means that we can lose at most nâˆ’M
of them, corresponding to a Hamming distance of n âˆ’M + 1.
Reedâ€“Solomon codes have been used for communications, and for storage appli-
cations such as CDs [12]. In the context of distributed storage systems, they are also
optimal when it comes to trade reliability and storage overhead. Why then not just
adopt Reedâ€“Solomon codes as such1 instead of researching novel coding strategies
for distributed storage systems?
The reason is that coding for distributed storage includes one more dimension, on
top of reliability and storage overhead, namely that of maintenance or repairability.
In a communication scenario, a signal is transmitted, and received at a given point
of time. Once the signal is received, it must be recovered taking into account lost
information due to channel noise, but this degradation is now given, it will not
change. This is a main difference with a distributed storage scenario. Suppose a disk
has failed at a given point of time, nothing prevents another disk to fail later on,
in fact, the failure of one disk may trigger other disk failures. Therefore, without a
maintenance mechanism, the data will eventually be lost, because no coding solution
can protect against an arbitrarily large amount of failures. What maintenance does is
illustrated on an example with two copies of a ï¬le f. If the ï¬rst copy is lost because
of a disk failure, a disk or node which is still alive make a new copy of f, so that the
storage system still has two copies overall, despite one failure. In fact, keeping three
copies of f is somewhat even more prudent, because once the ï¬rst failure occurred,
there is no more protection. Having three copies allows to lose one, start recreating
a new copy, and tolerate one more failure in the process of creating a new copy
(which may take time). Suppose now a Reedâ€“Solomon codeword is used to encode
f, each codeword coefï¬cient is stored on a distinct disk, across n different disks. In
the event of one failure, recovering the one missing coefï¬cient is asking for a lot
of resources: data needs to be transferred from M nodes, the codeword needs to be
recomputed, the missing coefï¬cient is then recovered, but at a high cost in terms of
both communication and computation costs. If the system were to wait for several
failures to happen before starting this repair procedure, the cost would be amortized,
but at the risk of losing the data if the system waits for too long.
Research on coding for distributed storage has thus focused on getting codes with
â€¢ high reliability (fault tolerance),
1We are not claiming that Reedâ€“Solomon codes are not used in distributed storage systems, we
added â€œas suchâ€ as a way to say that something else has to be taken into account in all cases, even
if one wants to use Reedâ€“Solomon codes.

366
S. Liu and F. Oggier
â€¢ low storage overhead (if storage overhead is not an issue, replication is a great
practical solution),
â€¢ good maintenance mechanisms.
What good maintenance means is still under discussion, but in this chapter, we
will focus on two aspects, low communication costs in Sect.2, and a low number of
live nodes to be contacted during repair in Sect.3. Other aspects are also discussed
in [23].
2
Regenerating Codes
When a node failure happens in a distributed storage system, a maintenance mech-
anism tries to replace the lost data using data available in the system. This involves
downloading data from live nodes, which incurs communication costs, referred to as
repair bandwidth.
In [4], Dimakis et al. introduced a min-cut max-ï¬‚ow technique from network
coding to the setting of distributed storage to optimize the repair bandwidth. The
result of their analysis is a trade-off bound between storage and repair bandwidth,
and codes achieving this bound are called regenerating codes. In [4], the scenario
of only one single failure repair at a time is treated. The main idea of regenerating
codes is that they could satisfy an MDS-like property (the ï¬le can be retrieved by
contacting any choice of k nodes, where k is a ï¬xed threshold, not necessarily the code
dimension), and in the repair process, many nodes could be contacted (typically all
but the failed one) and less symbols downloaded, in turn reducing the cost of repairing
one single failure.
2.1
Parameters of Regenerating Codes and Min-Cut Bound
Considering a network of N nodes, a ï¬le f of length M stored in n of these N nodes.
Each node is assumed to have the same storage capacity Î±, that is Î± symbols are
stored in each of the nodes. When a failure occurs, a live node (called newcomer)
among these N nodes, which does not yet store data from f, is joining the repair
process. The newcomer contacts d live nodes and downloads Î² symbols from each
of them, to repair the data lost by the failed node, as shown on Fig.1. The newcomer
thus downloads Î³ = dÎ² amount of data, which constitutes the total repair bandwidth.
To analyze the trade-off between storage capacity Î± and repair bandwidth Î², a min-
cut bound is computed [4] in an information ï¬‚ow graph, where the data ï¬‚ows from
a source S, into the storage system, through different nodes when repair happens, to
a data collector DC which wants to retrieve the data back.
Theorem 1 ([4]) Consider a directed information ï¬‚ow graph, with a source S and
a sink as data collector. Every node (apart the source and the sink) has a storage

An Overview of Coding for Distributed Storage Systems
367
Fig. 1 Four nodes, labelled from 1 to 4 failed. Four other nodes in the center with the same labels
are repairing the lost data by contacting live nodes 5, 6, 8, 9. We have d = 2, e.g., node 3 downloads
data from nodes 5 and 9. In the original regenerating code case, the four failures will be repaired
sequentially. In the collaborative case discussed next, nodes 1, 2, 3, 4 involved in the repair are
exchanging data as well
capacity of Î±. When a failure occurs, a newcomer connects to d â‰¥k live nodes and
obtains Î² symbols from each of them. Suppose that a data collector DC connects to
k nodes which were all involved in different phases of repair. Then a min-cut bound
between the source S and the data collector DC is given by
mincut(S, DC) â‰¥
kâˆ’1

i=0
min{(d âˆ’i)Î², Î±}.
(2)
Proof Let xi denote the newcomer during the ith repair, i â‰¥0. Write xi as a logical
pair (xin
i , xout
i
) formed by an incoming node, so that an edge between xin
i and xout
i
models the storage capacity Î±. Consider a data collector that connects to k output
nodes, say{xout
i
: i = 0, 1, . . . , k âˆ’1}. We show that any cut between S and DC in
the graph has a capacity that satisï¬es (2). Since we may assume that outgoing edges
of S and incoming edges of DC have inï¬nite capacity, we only need to consider cuts
(U,U), S âˆˆU and DC âˆˆU, where these inï¬nite capacity edges do not participate.
Let C denote the edges in the cut.
Let (xin
0 , xout
0 ) be the ï¬rst repair node. We have two cases: (1) If xin
0 âˆˆU, then the
edge with weight Î± between xin
0 and xout
0
must be in the cut C. (2) If xin
0 âˆˆU, then the
cut contains d edges carrying Î² coefï¬cients. Thus the ï¬rst node brings a contribution
of c0 â‰¥min{dÎ², Î±} to the cut.
Let us consider the second repair node (xin
1 , xout
1 ). There are again two cases:
(1) xin
1 âˆˆU, then the edge with weight Î± is again in the cut. (2) If xin
1 âˆˆU, then
at most one of its incoming edges could be from xout
0 , thus at least d âˆ’1 edges
carrying Î² coefï¬cients are in the cut. The min-cut contribution from the second node
is c1 â‰¥min{(d âˆ’1)Î², Î±}.

368
S. Liu and F. Oggier
In general, for the ith repair node (xin
iâˆ’1, xout
iâˆ’1), case 1) involves cutting the storage
capacity link, while for the second case, there are at most i âˆ’1 incoming edges
from nodes in U, thus at least d âˆ’i + 1 edges carrying Î² coefï¬cients, yielding
ciâˆ’1 â‰¥min{(d âˆ’i + 1)Î², Î±}.
Summing these contributions leads to (2).
Using the Minimum cut-Maximum ï¬‚ow Theorem, we get that the initial ï¬le size M
must satisfy
M â‰¤
kâˆ’1

i=0
min{(d âˆ’i)Î², Î±}.
Thus the largest that M can get is M = kâˆ’1
i=0 min{(d âˆ’i)Î², Î±}, and codes
reaching this bound are called regenerating codes. We may now ask to minimize
Î± = Î±(d, Î³ ) subject to the aforementioned constraint on the size of M , which can
equivalently be stated as a function of Î³ instead of Î²: M = kâˆ’1
i=0 min{(1âˆ’i/d)Î³, Î±}.
This optimization problem can be easily solved in closed form. This is because
(1âˆ’(k âˆ’1)/d)Î³ < (1âˆ’(k âˆ’2)/d)Î³ < Â· Â· Â· < (1âˆ’1/d)Î³ < Î³ . Since Î± must belong
to any of these intervals, the constraints can be restated removing all the minima, and
the minimum value of Î± is found. Suppose for example that Î± â‰¤(1 âˆ’(k âˆ’1)/d)Î³ ,
then the constraint becomes kÎ± = M , for which Î³ â‰¥Î±
d
dâˆ’(kâˆ’1) =
M
k
d
dâˆ’(kâˆ’1).
Similarly, if Î± â‰¥Î³ , we get
M =
kâˆ’1

i=0
(1 âˆ’i/d)Î³ =

k âˆ’1
d
(k âˆ’1)k
2

Î³ = k
2d âˆ’(k âˆ’1)
2d

Î³,
showing that Î³ = M
k
2d
2dâˆ’(kâˆ’1). Then Î± â‰¥Î³ gives Î± = Î³ for minimum value of Î±.
The other regimes in between are obtained similarly, which show that the optimal is
a piece wise linear function, which forms a trade-off between Î± and Î³ , as illustrated
on Fig.2 for k = 4 and d = 5.
The smallest value of Î±, corresponding to
(Î±, Î³ ) =
M
k , M
k
d
d âˆ’(k âˆ’1)

,
(3)
is indeed characterizing the smallest possible value for Î±, since we have the constraint
that any k nodes should be able to retrieve the ï¬le f, thus no node can store less than
M /k symbols. This point of the trade-off is called the minimum storage regenerating
point (MSR). Then the other extreme point
(Î±, Î³ ) =
M
k
2d
2d âˆ’(k âˆ’1), M
k
2d
2d âˆ’(k âˆ’1)

,
(4)
says that Î± = Î³ , which minimizes the repair bandwidth in absolute, irrespectively of
Î±. This point is thus called the minimum repair bandwidth regenerating point (MBR).

An Overview of Coding for Distributed Storage Systems
369
0.2
0.3
0.4
0.5
0.6
0.2
0.3
0.4
0.5
alpha
gamma
Fig. 2 Two trade-off curves, with Î± on the x-axis, and Î³ = Î³ (Î±) on the y-axis. The outer line
corresponds to t = 1 failure repair. The inner one corresponds to t = 3 simultaneous repairs using
a collaborative strategy. The parameters are set to be k = 4, d = 5 and we normalized the ï¬le size.
We observe that t = 3 yields a better trade-off than t = 1
It is also clear from this formula that d = n âˆ’1 brings most beneï¬ts in terms of
bandwidth savings.
No matter how many failures occurred in the storage system, the strategy that we
just analyzed holds for one failure repair at a time, so multiple failures are handled
by performing multiple repairs sequentially.
To repair more than one failure simultaneously, two independent works [14, 38]
introducedcollaborative(coordinated,cooperative)regeneratingcodes,whichallow
repairs using the data not only from live nodes, but also from all nodes currently being
repaired. This strategy introduces a collaborative phase, on top of the download phase
done previously. The analysis generalized the one presented above: a min-cut bound
is computed, taking into account the collaboration, and a trade-off for collaborative
regenerating codes is obtained, between storage and repair bandwidth, where repair
bandwidth takes into account that data is exchanged during collaboration.
Theorem 2 ([14, 38]) Consider an information ï¬‚ow graph, where every node has
a storage capacity of Î±, and repairs are performed by a group of t nodes, that is
the system triggers a repair when t failures occur. Suppose that a data collector DC
connects to a subset of k nodes which were all involved in different phases of repairs,
where each phase involves a group of ui nodes, 1 â‰¤ui â‰¤t, and k = gâˆ’1
i=0 ui. Then
a min-cut bound for collaborative repair is

370
S. Liu and F. Oggier
M â‰¤
gâˆ’1

i=0
ui min
â§
â¨
â©Î±,
â›
âd âˆ’
iâˆ’1

j=0
â
â Î² + (t âˆ’ui)Î²â€²
â«
â¬
â­,
(5)
where Î²â€² is the exchange repair bandwidth, that is each of the repairing nodes
exchanges Î²â€² symbols with every other t âˆ’1 repair nodes.
Solving the problem of minimizing Î± under the constraints given by the above
bound now becomes difï¬cult, the interested reader may refer to [40] for the compu-
tations. An example of the trade-off curve obtained for t = 3 is shown in Fig.2. It
turns out that increasing t actually improves the trade-off between storage and repair
bandwidth.
Both scenarios are included as particular cases of partially collaborative regen-
erating codes, proposed in [19]. The idea is to introduce freedom in the extent of
collaboration, by allowing repair nodes to exchange data with only a subset of the
nodes currently being repaired. A min-cut bound is available, however determining
the corresponding trade-off curve is open.
Theorem 3 ([19]) For partial collaboration, the repair process of t failures involves
t nodes, which will all download Î² amount of data from d live nodes, and exchange
Î²â€² amount of data with a subset of t âˆ’s nodes, 1 â‰¤s â‰¤t. Then the min-cut bound is
M â‰¤min
uâˆˆP
â›
â
iâˆˆI
ui min
â§
â¨
â©Î±,
â›
âd âˆ’
iâˆ’1

j=0
uj
â
â Î² + (t âˆ’s + 1 âˆ’ui)Î²â€²
â«
â¬
â­
+

iâˆˆÂ¯I
ui min
â§
â¨
â©Î±,
â›
âd âˆ’
iâˆ’1

j=0
uj
â
â Î²
â«
â¬
â­
â
â 
(6)
where I = {i, t âˆ’s + 1 âˆ’ui â‰¥0}, Â¯I = {i, t âˆ’s + 1 âˆ’ui < 0} and P = {u =
(u0, . . . , ugâˆ’1), 1 â‰¤ui â‰¤t and gâˆ’1
i=0 ui = k}.
When s = t, there is no collaboration, and (6) simpliï¬es to (2). When s = 1, the
collaboration phase involves all the other t âˆ’s = t âˆ’1 nodes, and we ï¬nd (5) again.
2.2
Functional Versus Exact Repair
The above bounds and trade-offs all address the preservation of data through different
repair phases. Suppose a node contains the piece fi2 of a ï¬le f, and after repair, afi
is being stored, for a Ì¸= 0. For example, using the alphabet F3 = {0, 1, 2}, a node
storing the coefï¬cient 1 fails, is repaired, but the value after repair is now 2, not 1.
2The same example can be done on a linear combination of fi.

An Overview of Coding for Distributed Storage Systems
371
In terms of recovering fi, both fi and afi play the same role (since a Ì¸= 0, aâˆ’1 exists
and computing aâˆ’1afi gives back fi, in the example, 2 Â· 2 gives back 1). However,
they are not bitwise the same data. Therefore, we distinguish exact repair, where lost
data is exactly recovered bit by bit, from functional repair, where the data itself is
not the same, but the information contained in the data is maintained. Exact repair is
often preferred, since it is easier to keep track of the data with respect to functional
repair, where transformation of the data should also be available. The above bounds
however hold for functional repair.
The question thus becomes that of achievability of these trade-offs for exact repair.
It is known that the extreme points (MSR and MBR) are achievable, and we will give
some example for these two cases in the next subsection. How to characterize the
interior points for exact repair remains open in general. We summarize some of
the results known so far. It was ï¬rst shown in [46], using a particular code with
parameters n = 4, k = 3, d = 3, that the exact repair trade-off lies strictly away
from the functional repair trade-off. In [35], it was more generally shown that the
exact repair trade-off lies strictly above the functional trade-off for any values n, k, d.
From these results, it became clear that one would have to address the question
of ï¬nding trade-off bounds for exact repair. However, the exact repair trade-off for a
ï¬xed (n, k, d) varies with the ï¬le size M , making it more natural to consider instead
the normalized pairs (Î±/M , Î²/M ).3 In this case, we refer to the normalized exact
repair (ER) trade-off. In [34, TheoremIII.4], an upper bound on the normalized ER
trade-off is computed for every choice of parameters n, k, d. This upper bound can
be combined with the code construction proposed in [36] for k = 3 and d = n âˆ’1,
for any n, to fully characterize the normalized ER tradeoff for this set of parameters.
In the introduction, we discussed linear codes, but so far, nothing was mentioned
about whether codes are linear or not. This is because the properties of information
preservation, or that of data recovery, are independent of the regenerating code being
linear. However, linear codes are of course nicer than non-linear ones, because they
have been better studied, they come with easier encoding and decoding algorithms.
So one may wonder whether adding the constraint of linearity might help in under-
standing the normalized ER trade-off. In [5], a non-explicit upper bound is given
for the general ER trade-off case, which, when applied to the special case of linear
codes, gives an explicit upper bound for the ER linear trade-off problem, for any
parameter n, k, d. In [21], another upper bound is given for the ER linear codes case,
which turns out to be optimal for the parameters k = n âˆ’1, d = n âˆ’1 for any n, but
for the limited region where Î²/M â‰¤2Î±/Mk. For an improvement of this bound, as
well as comparisons between the different bounds discussed, we refer to [34].
3Since Î³ = dÎ², we may consider the trade-off in terms of either (Î±, Î³ ) or (Î±, Î²).

372
S. Liu and F. Oggier
2.3
MSR and MBR Code Constructions
We next present two code constructions, one at MSR point, and one at MBR point.
Construction of MSR codes. This construction is actually illustrating how an MDS
code can be used for storage, in the setting of regenerating codes. Consider a ï¬le f
of length M = k with coefï¬cients in Fq, q a prime power. Set the parameters of the
regenerating code to be
d = k, n â‰¥k + 1, M = k.
Let G be a generator matrix of an (n, k) MDS code over Fq, say that of a Reedâ€“
Solomon code, and denote by gi the ith column of G, i = 1, . . . , n, that is G =
[g1, . . . , gn]. By the MDS property, any k columns of G form an invertible matrix.
We denote the data ï¬le f by a k-dimensional row vector, f = (f1, . . . , fk). Suppose
the ith node store fgi, that is Î± = 1.
Recovery.Thedatacanberecoveredbycontactingnodes i1, . . . , ik.Theil-thnode
contains fgil, for l = 1, . . . , k, for a total of k coefï¬cients, by the MDS property, the
data ï¬le can be retrieved.
Repair phase. Suppose that the ith node has failed. A newcomer connects to
d = k live nodes say i1, . . . , id and downloads fgil for l = 1, . . . , d from each of the
nodes, thus Î² = 1. By the MDS property, the newcomer can compute f.
The total number of coefï¬cients involved in the repair is dÎ² = k, that is the repair
bandwidth is k, and the construction indeed achieves the MSR point, since
(Î±MSR, Î³MSR) =
M
k , M
k
d
d âˆ’k + 1

= (1, k).
Construction of MBR codes [39]. This time, consider a data ï¬le f of length M =
k(k + 1) with coefï¬cients in Fq. Set the parameters of the regenerating code to be
d = k, n = k + 1, M = k(k + 1).
The object f can be written as f = (f1, . . . , fk+1) where fi = (f(iâˆ’1)k, . . . , fikâˆ’1) has
length k, 1 â‰¤i â‰¤n = k + 1.
Let g1, . . . , gnâˆ’1 be n âˆ’1 = k independent column vectors of length k over Fq.
For i = 1, 2, . . . , n, the content of node i consists of the k coefï¬cients of fi, and
of the n âˆ’1 parity-check coefï¬cients
fi+1g1, . . . , fi+(nâˆ’1)gnâˆ’1,
computed from other groups fi+j, j = 1, . . . , nâˆ’1. Node i thus stores Î± = k+nâˆ’1 =
2k coefï¬cients of the form fi+jgj where i + j and j are understood modulo n.
Recovery. Suppose without loss of generality that a data collector connects to
nodes 1, . . . , k, and downloads f1, f1+kgk from node 1,â€¦, fk, fk+1g1 from node k.
Thecoefï¬cientsoffk+1 canbecomputedfromfk+1Â·gk, . . . , fk+1Â·g1 sinceg1, . . . , gnâˆ’1
are linearly independent.

An Overview of Coding for Distributed Storage Systems
373
Repair process. Suppose that node j failed. The newcomer downloads fi Â·gi+(nâˆ’j)
and fj Â· gj+(nâˆ’i) from node i, i = 1, . . . , n, i Ì¸= j. Thus the parity-check coefï¬cients
stored in node j can be recovered directly from fi Â· gi+(nâˆ’j) with i = 1, . . . , n, i Ì¸=
j, while fj is recovered from fj Â· gj+(nâˆ’i), using that the gj involved are linearly
independent. The total number of coefï¬cients involved in the repair is 2k, that is the
repair bandwidth is 2k = 2d, and the construction indeed achieves MBR point, since
(Î±MBR, Î³MBR) =
M
k
2d
2d âˆ’k + 1, M
k
2d
2d âˆ’k + 1

= (2k, 2k).
There have been many works containing code constructions for regenerating
codes, the above two examples were meant to give an illustration, and are in no
way representative of the richness of the literature on this topic. Maybe the most
complete reference is http://storagewiki.ece.utexas.edu/doku.php.
2.4
Security
Once constructions and fault tolerance of regenerating codes have been well studied,
it became natural to wonder about their performance in the presence of an adversary.
The security of storage systems using (collaborative) regenerating codes has been
considered, both against passive adversaries, or eavesdroppers, who can only read
the data but not modify it, and active, or Byzantine attackers, who on the contrary
are able to corrupt data.
The techniques used in the context of secure regenerating codes are similar to
those discussed in the previous section: an information ï¬‚ow graph is considered,
this time taking into account the presence of an adversary, and a min-cut bound is
computed. We present next one such analysis [28], for the passive adversary case.
As before, a ï¬le f âˆˆFM
q is encoded into n pieces f1, . . . , fn, and each piece is stored
at a distinct node. We label the nodes such that the ith node xi stores fi, i = 1, . . . , n.
As in Theorem1, we represent the node xi by (xin
i , xout
i
), with an edge of capacity Î±
in between. Assume that nodes x1, . . . , xk have failed, and have been repaired by the
newcomers xn+1, . . . , xn+k. In the presence of a passive eavesdropper, data objects
are encrypted for ensuring their conï¬dentiality. We therefore distinguish the secure
ï¬le fs of size M s from its encrypted version, the ï¬le f of size M . Encoding is then
done on top of the encrypted ï¬le f.
Denote by fÎµ the encoded data stored in nodes belonging to the set Îµ. An eaves-
dropper who can read up to l, l < k, nodes among all the n storage nodes, possibly
at different time instances as the system evolves, accesses the l input nodes in the set
Îµ1 = {xin
n+1, . . . , xin
n+l} while they were being repaired.
Theorem 4 Consider a secure object f of secure ï¬le size M s, i.e., M s = H(fs), the
entropy of fs. Suppose that over time, k nodes have failed and been repaired at nodes
xn+1, . . . , xn+k. An eavesdropper has accessed the set of nodes Îµ1 = {xin
n+1, . . . , xin
n+l}.

374
S. Liu and F. Oggier
Consider a data collector DC that collects data from the k output nodes Îµ =
{xout
n+1, . . . , xout
n+k}. We have
M s â‰¤
k

j=l+1
min{(d + i âˆ’1)Î², Î±}.
Proof That fs remains conï¬dential despite the knowledge of fÎµ1 is modeled by
H(fs|fÎµ1) = H(fs). Thus
M s = H(fs) = H(fs|fÎµ1)
= H(fs|fÎµ1) âˆ’H(fs|fÎµ)
(7)
= I(fs; fÎµ\Îµ1|fÎµ1)
(8)
â‰¤H(fÎµ\Îµ1|fÎµ1)
(9)
=
k

i=l+1
H(fn+i|fn+1, . . . , fn+iâˆ’1)
(10)
â‰¤
k

i=l+1
min{(d âˆ’i + 1)Î², Î±}
(11)
where (7) holds since |Îµ| = k, which is enough to retrieve f by deï¬nition of k.
Then since mutual information satisï¬es I(X ; Y|Z) = H(X |Z) âˆ’H(X |Y, Z), (8)
follows. Alternatively, I(X ; Y|Z) = H(X , Z) âˆ’H(Z) âˆ’H(X , Y, Z) + H(Y, Z) =
H(X , Z) âˆ’H(X , Y, Z) + H(Y|Z) â‰¤H(Y|Z), from which (9) is derived, and the
Chain rule for entropy H(X1, . . . , Xn|Y) = n
i=1 H(Xi|X1, . . . , Xiâˆ’1, Y) implies
(10). Finally, each node has a storage capacity of Î±, for each repair node H(fi) â‰¤dÎ²,
and from the proof of Theorem1, the repair node xin
n+i downloads Î² symbols from
each output node xout
n+1, . . . , xout
n+iâˆ’1, yielding (11).
Corollary 1 At the minimum storage repair point (MSR), the secure ï¬le size M s is
upper bounded by
M s â‰¤(k âˆ’l)Î±.
Corollary 2 At the minimum repair bandwidth point (MBR) with d = n âˆ’1, the
secure ï¬le size M s is upper bounded by
M s â‰¤
k

i=l+1
(n âˆ’i)Î².
The above analysis was extended to the collaborative case [22], in particular
in the presence of rogue nodes which voluntarily corrupt the data that they transmit
during repair. It was shown that the repair bandwidth obtained to secure (information
theoretically) collaborative regenerating codes from Byzantine attacks is worse than

An Overview of Coding for Distributed Storage Systems
375
having no collaboration at all. This is a rational drawback of collaboration, since a
single corrupted node can pollute all other honest nodes involved in the repair.
In [37], Shah et al. gave a bound on the secure ï¬le size considering a passive
eavesdropper model that generalizes the model in [28], in that the eavesdropper can
access not only the stored data in nodes that have been repaired, l1 of them from a set
Îµ1, but also the data which is downloaded during the repair of l2 nodes from the set
Îµ2. This makes a difference, since more data may be in transit in nodes being repaired
than what will actually be stored. Code constructions of secure codes are given both
at MBR and MSR points. Rawat et al. [31] tightened the bound given in [37] at MSR
point, and also provided secure MSR codes for d = n âˆ’1. Finally, Koyluoglu et al.
[15] extended the bound in [31] to collaborative regenerating codes. A bound is also
available for partial collaboration [20].
Theorem 5 ([15, 20]) Consider a secure object f of secure ï¬le size M s, i.e., M s =
H(fs). Consider an eavesdropper who has access to the set of nodes Îµ1, Îµ2, |Îµ1| = l1,
|Îµ2| = l2, then
H(fs) â‰¤

jâˆˆR
H(fj|fn+1, . . . , fjâˆ’1, fÎµ1, dÎµ2),
with R = {n + 1, . . . , n + k}\(Îµ1 âˆªÎµ2), and dÎµ2 denotes the downloaded data in the
set of nodes Îµ2.
As a consequence of the above min-cut bound, we obtain bounds on the secure
ï¬le size:
Proposition 2 ([15, Propositions5 and 9]) For a collaborative regenerating code at
the minimum repair bandwidth point (MBR), with Î² = 2Î²â€², Î± = Î³ = (2d +t âˆ’1)Î²â€²,
and ï¬le size M = k(2d âˆ’k + t)Î²â€², the secure ï¬le size M s is upper bounded by
M s â‰¤(k âˆ’l1)(2d + t âˆ’k âˆ’l1)Î²
2 .
(12)
At the minimum storage repair point (MSR), with by Î² = Î²â€², Î± = (d âˆ’k + t)Î²
for a ï¬le of size M = k(d âˆ’k + t)Î², the secure ï¬le size M s is upper bounded by
M s â‰¤
kâˆ’l1âˆ’l2

i=1
(Î± âˆ’I(fi; di,Îµ2)).
(13)
If I(fi; di,Îµ2) â‰¥Î²â€² = Î², then (13) becomes
M s â‰¤(k âˆ’l1 âˆ’l2)(Î± âˆ’Î²).
(14)
The generalization of the above two bounds for the partial collaborative case
is found in [20]. Code constructions, when available, are found in the respective
aforementioned papers. See also e.g. [3, 8, 29].

376
S. Liu and F. Oggier
3
Locally Repairable Codes
In the last section, we saw how regenerating codes minimize repair bandwidth by
contacting a large number of live nodes (preferably all the n âˆ’1 live nodes in the
case of one failure). One may argue that getting answers from all these nodes in
time to ensure an efï¬cient repair may not be easy: other nodes may just be busy
reading, writing, or managing their data. Locally repairable codes somehow stand in
an opposite corner of the code design spectrum, by focusing on reducing the number
d of live nodes to be contacted per repair. For a repetition code, d = 1 is achieved.
For other codes, we need at least d â‰¥2.
The idea that repair efï¬ciency improves when a small number of nodes is con-
tacted appears in the construction of Pyramid codes [10]. Pyramid codes contain
information symbols, followed by redundancy symbols, and distinguish local and
global redundancy symbols, the local ones being those which are computed using
a small number of information symbols, while the global ones possibly need all
the information symbols to be computed. This can be achieved by taking a Reedâ€“
Solomon code, then shortening it, and ï¬nally by adding some new symbols obtained
by encoding information symbols, part of them set to zero, e.g., to add two local sym-
bols, set the ï¬rst half and the second half respectively of the information symbols to
zero. For example, suppose a ï¬le f = (f1, . . . , f6) is encoded using a Reedâ€“Solomon
code. Retain two parity symbols p1, p2 from it, then set f1 = f2 = f3 = 0 and obtain a
new Reedâ€“Solomon codeword from which a parity p3 is kept, then alternate and set
f4 = f5 = f6 = 0 and keep a parity p4 from its Reedâ€“Solomon codeword. This yields
a ï¬nal codeword (f1, . . . , f6, p1, p2, p3, p4) where p1, p2 are the global redundancy
symbols, and p3, p4 are the local ones. The motivation for this is to handle degraded
read, or how to read data when some of the symbols are missing. One solution is to
quickly compute the missing symbols of the data to be read using the local redun-
dancy symbols. This in turn implies that the local nodes can be repaired by contacting
a small number of live nodes. Local Reconstruction Codes form a class of codes for
distributed storage systems which optimize Pyramid codes, proposed by the same
research group, and which have been incorporated in Windows Azure [11].
In [24], minimizing the repair degree, that is the number of live nodes to be
contacted per repair, was proposed as a code design criterion, and self-repairing codes
were designed, which mimic the encoding of Reedâ€“Solomon codes via polynomial
evaluation, but using linearized polynomials. A linearized polynomial p(X ) âˆˆFq[X ]
satisï¬es that p(w + wâ€²) = p(w) + p(wâ€²) for w, wâ€² âˆˆFq.
To be consistent with the existing literature, we will use in the following the
notation d for the minimum distance of a code, and k for its dimension (while d
was the repair degree, and k the number of nodes contacted to retrieve an object, for
regenerating codes).

An Overview of Coding for Distributed Storage Systems
377
3.1
A Singleton-Type Bound on Locality
In [7], the notion of locality was introduced. The ith coordinate of a codeword is
said to have locality r, if its value is determined by at most r other coordinates.
Codes that have a minimum Hamming distance of d but also have the property that
any information coordinate has locality r or less were proposed, and the following
Singleton-type bound was given. We state and prove it for linear codes, even though
it is known to hold for non-linear codes4 [6].
Theorem 6 Let C be an [n, k] linear code, that is a code of length n and dimension
k, with minimum distance d and locality r. Then
n âˆ’k + 1 âˆ’d â‰¥âŒŠk âˆ’1
r
âŒ‹.
(15)
Proof [16] Let G be the generator matrix of C, and for a codeword in C, each of
its coefï¬cients is stored by a distinct node. Choose any âŒŠkâˆ’1
r âŒ‹nodes, call these the
â€œleadersâ€. Each leader can be written as a linear combination of at most r other nodes,
call this set the â€œset of friends of the leaderâ€. Now deï¬ne N as the set of nodes which
is the union of all sets of friends of the leaders (at most râŒŠkâˆ’1
r âŒ‹of them) but without
the leaders themselves. Then clearly N has at most râŒŠkâˆ’1
r âŒ‹elements, thus less than k
elements so that the set of columns in G that corresponds to N spans a space of rank
< k. Since G has full rank it is possible to enlarge N to a set N of more than k âˆ’1
columns such that the rank of its corresponding columns equals exactly k âˆ’1. Note
that because the code has locality r, this enlargement operation can be done without
involving any of the leaders. Now deï¬ne U as the union of N â€² and the set of leaders.
Then U has at least k âˆ’1 + âŒŠkâˆ’1
r âŒ‹nodes but still, because the code has locality r,
the corresponding columns in G span a space of dimension < k. By deï¬nition of the
minimum distance, all (k Ã— Â·)-submatrices of G that have rank < k must have less
than n âˆ’d columns. It therefore follows that k âˆ’1 + âŒŠkâˆ’1
r âŒ‹â‰¤n âˆ’d, which proves
the theorem.
The bound (15) has been shown to be tight [7] over a large enough ï¬nite ï¬eld.
The term locally repairable code (LRC) was coined in [27] to refer to codes with
a prescribed repair degree, or locality. The term is reminiscent of the theoretical
computer science terminology â€œlocally decodableâ€ or â€œlocally correctableâ€ codes.
Describing possible technical connections among these families of codes is beyond
the scope of this survey.
By now, a locally repairable (or locally recoverable) code is a linear [n, k, r] code
that encode k information symbols into a codeword of length n, with the property
that for any symbol of the codeword, there exist at most r other symbols such that the
value of the symbol can be recovered from them. Then r is called the repair locality.
4In fact, we will not discuss non-linear codes, even though some works have been done on this
topic.

378
S. Liu and F. Oggier
For LRC codes, if a symbol is lost due to a node failure, its value can be recovered
by contacting at most r other nodes.
MDS codes are actually LRC codes, with locality r = k. MDS codes can recover
the largest possible number of erased symbols among all [n, k] codes, since their
Hamming distance is n âˆ’k + 1. Thus (15) for MDS codes becomes
n âˆ’k + 1 âˆ’(n âˆ’k + 1) â‰¥âŒŠk âˆ’1
k
âŒ‹
and the bound is tight, even though r is high. An [n, k, r] LRC code that achieves the
bound (15) with equality is called an optimal LRC code. Pyramid codes are known
to yield LRC codes [7] whose information symbols have optimal repair locality. In
[31, 41], rank-metric codes are used to construct optimal LRCs, while [45] gave a
construction based on Reedâ€“Solomon codes that is optimal for any 1 < r < k.
3.2
Code Constructions
We repeat the disclaimer used for regenerating codes: the literature on locally
repairable codes is vast, and we do not pretend to provide an exhaustive list of
constructions. Since MDS codes are optimal with repair locality r = k, we choose
to present a construction from [30], which uses generalized Reedâ€“Muller codes, and
achieves r = 2 and r = 3.
LRC codes with locality 2. Let q be a prime. Consider an object f = (f1, . . . ,
fM ) âˆˆFM
q of length M = m, and the multivariate polynomial g in Fq[X1, . . . , Xm]
of degree 1 given by
g(X1, . . . , Xm) =
m

i=1
fiXi.
A codeword is obtained by evaluating g in the points
ai, ai + t((q âˆ’1)ai + aj) âˆˆFm
q ,
for i = 1, . . . , N, 1 â‰¤i < j â‰¤N, 2 â‰¤t â‰¤1 + L, where N and L are designed
parameters. Each codeword coefï¬cient is stored in one node. Set h = (q âˆ’1)ai + aj,
then the polynomial is evaluated in the points
ai, aj, ai + th.
Since t goes from 2 to L + 1, and with ai, aj, there are L + 2 points on a line, that is
ai, ai + h, . . . , ai + (L + 1)h.

An Overview of Coding for Distributed Storage Systems
379
Suppose the node storing ai fails, the repair can be realized by contacting two other
nodes storing the values corresponding to two points on the same line, say the nodes
containing g(ai + t1h), g(ai + t2h) for L â‰¥1, t1 Ì¸= t2. Consider g as a polynomial
in t, then g has degree 1 in t, so by polynomial interpolation, the two values g(ai +
t1h), g(ai + t2h) are enough to compute g(ai + th), and evaluating it in t = 0 yields
back g(ai). This shows that this code has repair locality r = 2.
LRC codes with locality 3. Similarly, consider a ï¬le f = (f1, . . . , fM ) âˆˆFM
q of
length M =
m+2
m

, and the polynomial g in Fq[X1, . . . , Xm] of degree 2 given by
g(X1, . . . , Xm) =

iâˆˆM
fiX Î±i,1
1
Â· Â· Â· X Î±i,m
m
,
where M is the index set for monomials in Fq[X1, . . . , Xm] of degree at most 2
arranged in lexical order. A codeword is obtained by evaluating g in the points
2ai, ai + aj, 2ai + t((q âˆ’1)ai + aj) âˆˆFm
q ,
for i = 1, . . . , N, 1 â‰¤i < j â‰¤N, 3 â‰¤t â‰¤2 + L, where N and L are designed
parameters. Each coefï¬cient in the codeword is stored in one node. Again, set h =
(q âˆ’1)ai + aj, then the polynomial is evaluated in
2ai, ai + aj, 2aj, 2ai + th.
Since t goes from 3 to L + 2, and with 2ai, ai + aj, 2aj, there are L + 3 points on a
line, that is
2ai, 2ai + h, 2ai + 2h, . . . , ai + (L + 2)h.
Suppose the node storing 2ai fails, the repair can be realized by contacting three other
nodes storing the values corresponding to three points on the same line, say the nodes
containing g(2ai +t1h), g(2ai +t2h), g(2ai +t3h) for L â‰¥1, t1 Ì¸= t2 Ì¸= t3. Consider
again g as a polynomial in t, which this time has degree at most 2. By polynomial
interpolation, three values are enough to reconstruct the polynomial g(2ai +th), and
g(ai) is obtained by setting t = 0. This shows a repair locality of r = 3.
We note three directions that have been pursued in the design of LRC codes:
â€¢ To get practical codes, it is often desirable to have a small alphabet Fq, preferably in
characteristic 2. In [1], integrated interleaved codes have been studied and showed
to be good candidates to obtain LRC codes over F2b, for small values of b. In [44],
cyclic codes and subï¬eld subcodes of cyclic codes are considered as LRC codes,
where their minimum distance and locality are derived. In particular, the binary
case is treated.
â€¢ Suppose that one may want different codeword symbols to have different locality.
Bounds and constructions, optimal with respect to these bounds, for LRC codes
with different localities have been considered in [13, 49].

380
S. Liu and F. Oggier
â€¢ The security model presented in Sect.2.4 for regenerating codes has also been
considered for LRCs in [31]. Under the same eavesdropper threat, bounds on the
secure ï¬le size were computed. For a reference on Byzantine attacks for LRCs,
see e.g. [42].
3.3
LRC Codes with Multiple Recovering Sets
We have seen above that LRC codes have the local repair property that each symbol
can be recovered using at most r other symbols, so a natural question is whether
this set of at most r symbols, called recovering set is unique. When each symbol
has several recovering sets, then we may ask whether these sets are disjoint. These
questions are important for the health of the distributed storage system. If the node
that fails has a unique recovering set, and some other failures affect this set, then
the recovery set cannot be used, and local repair becomes impossible. Therefore it
is important to understand the structure of recovering sets.
As an illustration, consider the code constructions of the last subsection with
parameters L = 1 and N = 3. For the construction with locality 3, the evaluating
points of the polynomial g are
2a1, 2a2, 2a3,
a1 + a2, a1 + a3, a2 + a3,
a2 âˆ’a1, a3 âˆ’a1, a3 âˆ’a2,
and the points 2a1, a1 + a2, 2a2, a2 âˆ’a1 are actually on the same line. We similarly
list the points on the same line:
L1 : 2a1, a1 + a2, 2a2, a2 âˆ’a1,
L2 : 2a1, a1 + a3, 2a3, a3 âˆ’a1,
L3 : 2a2, a2 + a3, 2a3, a3 âˆ’a2.
Suppose a node stores g(2a1). Since there are two lines L1, L2 containing 2a1, the
symbol g(2a1) has two recovering sets, a1+a2, 2a2, a2âˆ’a1 and a1+a3, 2a3, a3âˆ’a1,
and they do not intersect. This is also true for the points 2a2 and 2a3. However, for
other points, they only have one recovering set.
In [26, 45], LRC codes with disjoint recovering sets are proposed. Tamo and Barg
[45] gave two methods to construct LRC codes with multiple recovering sets. One
use the concept of orthogonal partition, the second combines several LRC codes into
a longer multiple recovering code. In [47], codes providing Î´ âˆ’1 non-overlapping
local repair groups of size no more than r per coordinate were introduced. In [32],
recovering sets are studied using the concept of (r, t)-availability: a code symbol is
said to have (r, t)-availability if it can be rebuilt from t disjoint recovering sets, each
of size at most r.

An Overview of Coding for Distributed Storage Systems
381
4
Concluding Remarks
This chapter surveyed two main families of codes for distributed storage systems.
While we have already mentioned that the references in terms of code constructions
are far from exhaustive, we would like to conclude by also listing aspects of the topic
which have not been considered.
â€¢ Other design criteria, for codes to provide efï¬cient data insertion (e.g. [25]), data
update (e.g. [43]), or versioning (e.g. [9]), have not been covered.
â€¢ The view point of code design the way it was presented is looking at one snapshot
of the network, it is oblivious of the actual system, and does not take into account
the fact that a node actually stores many objects (e.g. [2]), which means that
data allocation, or management of metainformation is important. There have been
works looking at systems aspects and implementation of these codes (e.g. [17])
which we did not discuss either.
â€¢ Regarding security aspects, we only described information theoretical approaches,
while there are many works discussing cryptographic or system approaches to
secure code based distributed storage systems.
â€¢ Finally, there is a vast body of work coming from the storage systems and dis-
tributed systems community. They started discussing coding for distributed storage
systems before the information and coding community did (e.g. [18, 48]), and they
also have proposed many interesting code designs, often motivated by considera-
tions closer to working systems.
Acknowledgements This work is supported by the MoE Tier-2 grant eCODE: Erasure Codes for
Datacenter Environments.
References
1. M. Blaum, S.R. Hetzler, Integrated interleaved codes as locally recoverable codes: properties
and performance. Int. J. Inf. Coding Theory 3(4), 324 (2016)
2. A. Datta, L. Pamies-Juarez, F. Oggier, A study of the performance of novel storage-centric
repairable codes. Springer Comput. 98(3) (2015)
3. T.K. Dikaliotis, A.G. Dimakis, T. Ho, Security in distributed storage systems by communicating
a logarithmic number of bits, in Proceedings of the 2010 IEEE International Symposium on
Information Theory (ISIT) (2010), pp. 1948â€“1952
4. A.G. Dimakis, P.B. Godfrey, Y. Wu, M.J. Wainwright, K. Ramchandran, Network coding for
distributed storage systems. IEEE Trans. Inf. Theory 56(9) (2010)
5. I.M. Duursma, Shortened regenerating codes. CoRR (2015), arXiv:1505.00178
6. M. Forbes, S. Yekhanin, On the locality of codeword symbols in non-linear codes. Discret.
Math. 324, 78â€“84 (2014)
7. P. Gopalan, C. Huang, H. Simitci, S. Yekhanin, On the locality of codeword symbols. IEEE
Trans. Inf. Theory 58(11), 6925â€“6934 (2011)
8. Y.S. Han, R. Zheng, W.H. Mow, Exact regenerating codes for Byzantine fault tolerance in
distributed storage, in Proceedings of IEEE INFOCOM (2012), pp. 2498â€“2506
9. J. Harshan, F. Oggier, A. Datta, Sparsity exploiting erasure coding for distributed storage of
versioned data. Springer Comput. (2016)

382
S. Liu and F. Oggier
10. C. Huang, M, Chen, J. Li, Pyramid codes: ï¬‚exible schemes to trade space for access efï¬ciency
in reliable data storage systems, in Sixth IEEE International Symposium on Network Computing
and Applications, July 2007, pp. 79â€“86
11. C. Huang, H. Simitci, Y. Xu, A. Ogus, B. Calder, P. Gopalan, J. Lin, S. Yekhanin, Erasure
coding in windows Azure storage, in 2012 USENIX Annual Technical Conference, 12â€“15 June
2012
12. K.A.S. Immink, Codes for Mass Data Storage Systems, Second fully revised edition (Shannon
Foundation Publishers, Eindhoven, 2004), http://www.turing-machines.com/pdf/codes_for_
mass_data2.pdf. ISBN 90-74249-27-2
13. S. Kadhe, A. Sprintson, Codes with unequal locality, in IEEE International Symposium on
Information Theory (ISIT) (2016), pp. 435â€“439
14. A.-M. Kermarrec, N. Le Scouarnec, G. Straub, Repairing multiple failures with coordinated
and adaptive regenerating codes, in The 2011 International Symposium on Network Coding
(NetCod 2011)
15. O.O. Koyluoglu, A.S. Rawat, S. Vishwanath, Secure cooperative regenerating codes for dis-
tributed storage systems. IEEE Trans. Inf. Theory 60(9), 5228â€“5244 (2014), arXiv:1210.3664
16. M. Kuijper, D. Napp, Erasure codes with simplex locality, in 21st International Symposium on
Mathematical Theory of Networks and Systems, Groningen, The Netherlands (2014)
17. M. Li, P.P.C. Lee, STAIR codes: a general family of erasure codes for tolerating device and
sector failures in practical storage systems, in Proceedings of the 12th USENIX Conference on
File and Storage Technologies (FASTâ€™14), Santa Clara, CA (2014)
18. W.K. Lin, D.M. Chiu, Y.B. Lee, Erasure code replication revisited, P2P 2004
19. S. Liu, F. Oggier, On storage codes allowing partially collaborative repairs, in IEEE Interna-
tional Symposium on Information Theory (ISIT) 2014, pp. 2440â€“2444
20. S. Liu, F. Oggier, Partially collaborative storage codes in the presence of an eavesdropper. Int.
J. Inf. Coding Theory 3(3), 177â€“196 (2016)
21. S. Mohajer, R. Tandon, New bounds on the (n, k, d) storage systems with exact repair, in IEEE
International Symposium on Information Theory, ISIT 2015, Hong Kong, China, 14â€“19 June
2015, pp. 2056â€“2060
22. F. Oggier, A. Datta, Byzantine fault tolerance of regenerating codes, in The 11th IEEE Inter-
national Conference on Peer-to-Peer Computing (P2P 2011), Kyoto, arXiv:1106.2275
23. F. Oggier, A. Datta, Coding techniques for repairability in networked distributed storage sys-
tems, Foundations and Trends in Communications and Information Theory (Now Publishers,
Breda, 2013)
24. F. Oggier, A. Datta, Self-repairing homomorphic codes for distributed storage systems, INFO-
COM 2011
25. L.Pamies-Juarez,A.Datta,F.Oggier,RapidRAID:pipelinederasurecodesforfastdataarchival
in distributed storage systems, arXiv:1207.6744
26. L. Pamies-Juarez, H.D.L. Hollmann, F. Oggier, Locally repairable codes with multiple repair
alternatives, in IEEE International Symposium on Information Theory (ISIT) (2013), pp. 892â€“
896
27. D.S.Papailiopoulos,A.G.Dimakis,Locallyrepairablecodes,inIEEEInternationalSymposium
on Information Theory (ISIT) (2012), arXiv:1206.3804
28. S. Pawar, S. El Rouayheb, K. Ramchandran, Securing dynamic distributed storage systems
against eavesdropping and adversarial attacks. IEEE Trans. Inf. Theory (Spec. Issue Facet.
Coding Theory Algorithm Netw.) 57(9) (2011)
29. K.V. Rashmi, N.B. Shah, K. Ramchandran, P.V. Kumar, Regenerating codes for errors and
erasures in distributed storage, in Proceedings of the 2012 IEEE International Symposium on
Information Theory (ISIT) (2012), pp. 1202â€“1206
30. A.S. Rawat, S. Vishwanath, On locality in distributed storage systems, in IEEE Information
Theory Workshop (ITW) (2012), pp. 497â€“501
31. A.S. Rawat, O.O. Koyluoglu, N. Silberstein, S. Vishwanath, Optimal locally repairable and
secure codes for distributed storage systems. IEEE Trans. Inf. Theory 60(1), 212â€“236 (2014)

An Overview of Coding for Distributed Storage Systems
383
32. A.S. Rawat, D.S. Papailiopoulos, A.G. Dimakis, S. Vishwanath, Locality and availability in
distributed storage. IEEE Trans. Inf. Theory 62(8), 4481â€“4493 (2016)
33. I. Reed, G. Solomon, Polynomial codes over certain ï¬nite ï¬elds. J. Soc. Ind. Appl. Math. 8,
300â€“304 (1960)
34. B. Sasidharan, N. Prakash, M.N. Krishnan, M. Vajha, K. Senthoor, P.V. Kumar, Outer bounds
on the storage-repair bandwidth tradeoff of exact-repair regenerating codes. Int. J. Inf. Coding
Theory 3(4), 255â€“298 (2016)
35. B. Sasidharan, K. Senthoor, P.V. Kumar, An improved outer bound on the storage repair-
bandwidth tradeoff of exact-repair regenerating codes, in IEEE International Symposium on
Information Theory, ISIT 2014, pp. 2430â€“2434
36. K. Senthoor, B. Sasidharan, P.V. Kumar, Improved layered regenerating codes characterizing
the exact-repair storage-repair bandwidth tradeoff for certain parameter sets, in 2015 IEEE
Information Theory Workshop, ITW 2015, Jerusalem, Israel, 26 Aprilâ€“1 May 2015, p. 15
37. N.B. Shah, K.V. Rashmi, P.V. Kumar, Information theoretically secure regenerating codes for
distributed storage, in Proceedings of IEEE Globecom (2011)
38. K.W. Shum, Cooperative regenerating codes for distributed storage systems, in The Interna-
tional Conference on Communications (ICC 2011), Kyoto, arXiv:1101.5257
39. K.W. Shum, Y. Hu, Exact minimum-repair-bandwidth cooperative regenerating codes for dis-
tributed storage systems, in The International Symposium on Information Theory (ISIT 2011),
Saint-Petersburg
40. K.W. Shum, Y. Hu, Cooperative regenerating codes. IEEE Trans. Inf. Theory 59(11), 7229â€“
7258 (2013)
41. N. Silberstein, A.S. Rawat, O.O. Koyluoglu, S. Vishwanath, Optimal locally repairable codes
via rank-metric codes, in IEEE International Symposium on Information Theory (ISIT) (2013)
42. N. Silberstein, A.S. Rawat, S. Vishwanath, Error-correcting regenerating and locally repairable
codes via rank-metric codes. IEEE Trans. Inf. Theory 61(11), 5765â€“5778 (2015)
43. A. Singh Rawat, S. Vishwanat, A. Bhowmick, E. Soljanin, Update efï¬cient codes for distributed
storage, in IEEE International Symposium on Information Theory (ISIT) (2011)
44. I. Tamo, A. Barg, S. Goparaju, R. Calderbank, Cyclic LRC codes, binary LRC codes, and upper
bounds on the distance of cyclic clodes. Int. J. Inf. Coding Theory 3(4), 32 (2016)
45. I. Tamo, A. Barg, A family of optimal locally recoverable codes. IEEE Trans. Inf. Theory
60(8), 4661â€“4676 (2014)
46. C. Tian, Characterizing the rate region of the (4,3,3) exact-repair regenerating codes. IEEE J.
Sel. Areas Commun. 32(5), 967â€“975 (2014)
47. A. Wang, Z. Zhang, Repair locality with multiple erasure tolerance. IEEE Trans. Inf. Theory
60(11), 6979â€“6987 (2014)
48. H. Weatherspoon, J. Kubiatowicz, Erasure coding vs replication: a quantitative comparison,
Peer-to-Peer Systems, LNCS (2002)
49. A. Zeh, E. Yaakobi, Bound and constructions of codes with multiple localities, in IEEE Inter-
national Symposium on Information Theory (ISIT) (2016), pp. 641â€“644

Matroid Theory and Storage Codes: Bounds
and Constructions
Ragnar Freij-Hollanti, Camilla Hollanti and Thomas WesterbÃ¤ck
Abstract Recent research on distributed storage systems (DSSs) has revealed inter-
esting connections between matroid theory and locally repairable codes (LRCs). The
goal of this chapter is to introduce the reader to matroids and polymatroids, and illus-
trate their relation to distributed storage systems. While many of the results are rather
technical in nature, effort is made to increase accessibility via simple examples. The
chapter embeds all the essential features of LRCs, namely locality, availability, and
hierarchy alongside with related generalised Singleton bounds.
1
Introduction to Locally Repairable Codes
In this chapter, we will discuss the theoretical foundations of locally repairable codes
(LRCs), which were introduced in chapterâ€œAn Overview of Coding for Distributed
Storage Systemsâ€. While our main interest is in the codes and their applicability for
distributed storage systems, signiï¬cant parts of our machinery comes from matroid
theory. We will develop this theory to the extent that is needed for the applications,
and leave some additional pointers to interpretations in terms of graphs and projective
geometries.
The need for large-scale data storage is continuously increasing. Within the
past few years, distributed storage systems (DSSs) have revolutionised our tradi-
The authors gratefully acknowledge the ï¬nancial support from the Academy of Finland (grants
#276031 and #303819), as well as the support from the COST Action IC1104.
R. Freij-Hollanti (B) Â· C. Hollanti Â· T. WesterbÃ¤ck
Department of Mathematics and Systems Analysis, Aalto University,
P.O. Box 11100, 00076 Aalto, Finland
e-mail: ragnar.freij@aalto.ï¬
C. Hollanti
e-mail: camilla.hollanti@aalto.ï¬
T. WesterbÃ¤ck
e-mail: thomas.westerback@aalto.ï¬
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_15
385

386
R. Freij-Hollanti et al.
tional ways of storing, securing, and accessing data. Storage node failure is a fre-
quent obstacle in large-scale DSSs, making repair efï¬ciency an important objective.
A bottle-neck for repair efï¬ciency, measured by the notion of locality [27], is the
number of contacted nodes needed for repair. The key objects of study in this paper
are locally repairable codes (LRCs), which are, informally speaking, storage systems
where a small number of failing nodes can be recovered by boundedly many other
(close-by) nodes. Repair-efï¬cient LRCs are already in use for large-scale DSSs used
by, for example, Facebook and Windows Azure Storage [40].
Another desired attribute, measured by the notion of availability [31], is the
property of having multiple alternative ways to repair nodes or access ï¬les. This
is particularly relevant for nodes containing so-called hot data that is frequently and
simultaneously accessed by many users. Moreover, as failures are often spatially
correlated, it is valuable to have each node repairable at several different scales. This
means that if a node fails simultaneously with the set of nodes that should normally
be used for repairing it, then there still exists a larger set of helper nodes that can
be used to recover the lost data. This property is captured by the notion of hierarchy
[10, 32] in the storage system.
Network coding techniques for large-scale DSSs were considered in [7]. Since
then,aplethoraofresearchonDSSswithafocusonlinearLRCsandvariouslocalities
has been carried out, see [13, 27, 30, 34, 39] among many others. Availability for
linear LRCs was deï¬ned in [31]. The notion of hierarchical locality was ï¬rst studied
in [32], where bounds for the global minimum distance were also obtained.
Let us denote by (n, k, d,r, Î´, t), respectively, the code length, dimension, global
minimum distance, locality, local minimum distance, and availability. Bold-faced
parameters (n, k, d, t) will be used in the sequel to refer to hierarchical locality
and availability. It was shown in [40] that the (r, Î´ = 2)-locality of a linear LRC
is a matroid invariant. The connection between matroid theory and linear LRCs
was examined in more detail in [47]. In addition, the parameters (n, k, d,r, Î´) for
linear LRCs were generalised to matroids, and new results for both matroids and
linear LRCs were given therein. Even more generally, the parameters (n, k, d,r, Î´, t)
were generalised to polymatroids, and new results for polymatroids, matroids and
both linear and nonlinear LRCs over arbitrary ï¬nite alphabets were derived in [46].
Similar methods can be used to bound parameters of batch codes [49], as discussed in
chapterâ€œBatch and PIR Codes and Their Connections to Locally Repairable Codesâ€.
For more background on batch codes, see e.g. [16, 23]. Moreover, as certain speciï¬c
LRCs and batch codes1 belong to the class of private information retrieval (PIR)
codes as deï¬ned in [9, Deï¬nition 4], the related LRC and batch code bounds also
hold for those PIR codes. See Sect.5.3 and chapterâ€œBatch and PIR Codes and Their
Connections to Locally Repairable Codesâ€ for more discussion.
The main purpose of this chapter is to give an overview of the connection between
matroid theory and linear LRCs with availability and hierarchy, using examples for
improved clarity of the technical results. In particular, we are focusing on how the
1To this end, we need to make speciï¬c assumptions on the locality and availability of the LRC [9,
Theorem 21], which also implies restrictions on the query structure of the batch code.

Matroid Theory and Storage Codes: Bounds and Constructions
387
parameters of a LRC can be analysed using the lattice of cyclic ï¬‚ats of an associated
matroid, and on a construction derived from matroid theory that provides us with
linear LRCs. The matroidal results on LRCs reviewed here are mostly taken from
[10, 46, 47].
The rest of this chapter is organised as follows. In Sects.1.1 and 1.2, we introduce
distributed storage systems and how they can be constructed by using linear codes.
In particular, we consider locally repairable codes with availability. Section2 gives a
brief introduction to the concepts and features related to matroids relevant to LRCs. In
Sect.3, we summarise the state-of-the-art generalised Singleton bounds on the code
parameters for linear codes, as well as discuss existence of Singleton-optimal linear
codes and matroids. Section4 reviews some explicit (linear) code constructions. In
Sect.5, we go beyond linear codes and consider polymatroids and related generalised
Singleton bounds, which are then valid for all LRCs over any ï¬nite alphabet, and
also imply bounds for PIR codes when restricted to systematic linear codes. Section6
concludes the chapter and discusses some open problems. Further results in matroid
theory and especially their representability are given in appendix for the interested
reader. The following notation will be used throughout the paper:
F
: a ï¬eld;
Fq
: the ï¬nite ï¬eld of prime power size q;
E
: a ï¬nite set;
G
: a matrix over F with columns indexed by E;
G(X)
: the matrix obtained from G by restricting to the columns
indexed by X, where X âŠ†E;
C(G)
: the vector space generated by the columns of G;
R(G)
: the vector space generated by the rows of G;
C
: linear code C = R(G) over F generated by G;
CX
: the punctured code of C on X, i.e., CX = R(G(X)), where
X âŠ†E;
2E
: the collection of all subsets of a ï¬nite set E;
[ j]
: the set {1, 2, . . . , j} for a positive integer j;
n, k, d,r, Î´, t, h
: code length, dimension, minimum distance, locality, failure
tolerance, availability, hierarchy, respectively;
[n, k, d] , (n, k, d)
: parameters of a linear/general code, respectively;
(n, k, . . .)i
: parameter values when we consider information symbols, e.g.,
information symbol locality;
(n, k, . . .)a
: parameter values when we consider all code symbols, e.g., all
symbol locality;
(n, k, . . .)s
: parameter values when we consider systematic code symbols,
e.g., systematic symbol locality;
(n, k, d, t)
: parameter values for different hierarchy levels.
Remark 1 Here, d denotes the minimum (Hamming) distance of the code, rather
than the number of nodes that have to be contacted for repair, as is commonplace in

388
R. Freij-Hollanti et al.
the theory of regenerating codes. In chapterâ€œAn Overview of Coding for Distributed
Storage Systemsâ€, the minimum distance of the code was denoted by dH.
The motivation to study punctured codes arises from hierarchical locality; the
locality parameters at the different hierarchy levels correspond to the global param-
eters of the related punctured codes. The puncturing operation on codes corresponds
to the so-called restriction (or deletion) operation on matroids.
We also point out that G(E) = G and CE = C. We will often index a matrix G
by [n], where n is the number of columns in G.
1.1
Distributed Storage Systems from Linear Codes
A linear code C can be used to obtain a DSS, where every coordinate in C represents
a storage node in the DSS, and every point in C represents a stored data item. While
one often assumes that the data items are ï¬eld elements in their own right, no such
assumption is necessary. However, if C is a code over the ï¬eld F and the data items
are elements in an alphabet A, then we must be able to form the linear combinations
f1a1 + f2a2 for f1, f2 in F and a1, a2 in A. Moreover, if we know the scalar f , we
must be able to read off a from f a. This is achieved if A âˆ¼= FÎ± is a vector space over
F, wherefore we must have |A| â‰¥|F|. Thus, the length of the data items must be at
least the number of symbols needed to represent a ï¬eld element. In particular if the
data items are measured in, e.g., kilobytes, then we are restricted to work over ï¬elds
of size not larger than about 28000. Beside this strict upper bound on the ï¬eld size, the
complexity of operations also makes small ï¬eld sizes â€” ideally even binary ï¬elds
â€” naturally desirable.
Example 1 Let C be the linear code generated by the following matrix G over F3:
G =
1 2 3 4 5 6 7 8 9
1 0 0 0 1 1 1 1 1
0 1 0 0 1 0 1 2 2
0 0 1 0 0 1 1 0 0
0 0 0 1 0 0 0 1 2
Then, C corresponds to a 9 node storage system, storing four ï¬les (a, b, c, d), each
of which is an element in FÎ±
3. In this system, node 1 stores a, node 5 stores a + b,
node 9 stores a + 2b + 2d, and so on.
Two very basic properties of any DSS are that every node can be repaired by some
other nodes and that every node contains some information.2 We therefore give the
following deï¬nition.
2We remark that if one takes into account queueing theoretic aspects, then data allocation may
become less trivial (some nodes may be empty). Such aspects are discussed, especially in a wireless
setting, in chaptersâ€œOpportunistic Network Codingâ€ and â€œCoded Random Accessâ€. However, these
considerations are out of the scope of this chapter.

Matroid Theory and Storage Codes: Bounds and Constructions
389
Deï¬nition 1 A linear [n, k, d]-code C over a ï¬eld is a non-degenerate storage code
if d â‰¥2 and there is no zero column in a generator matrix of C.
The ï¬rst example of a storage code, and the motivating example behind the notion
of locality, is the notion of a maximum distance separable (MDS) code. It has several
different deï¬nitions in the literature, here we list a few of them.
Deï¬nition 2 The following properties are equivalent for linear [n, k, d] storage
codes:
(i) n = k + d âˆ’1.
(ii) The stored data can be retrieved from any k nodes in the storage system.
(iii) To repair any single erased node in the storage system, one needs to contact k
other nodes.
A code that satisï¬es one (and therefore all) of the above properties is called an M DS
code.
By the Singleton bound, n â‰¥k + d âˆ’1 holds for any storage code, so by property
(i), MDS codes are â€œoptimalâ€ in the sense that they have minimal length for given
storage capacity and error tolerance. However, (iii) is clearly an unfavourable prop-
erty in terms of erasure correction. This is the motivation behind constructing codes
with small n âˆ’k âˆ’d, where individual node failures can still be corrected â€œlocallyâ€.
1.2
Linear Locally Repairable Codes with Availability
The very broad class of linear LRCs will be deï¬ned next. It is worth noting that,
contrary to what the terminology would suggest, a LRC is not a novel kind of code,
but rather the â€œlocality parametersâ€ (r, Î´) can be deï¬ned for any code. What we call
a LRC is then only a code that is speciï¬cally designed with the parameters (r, Î´) in
mind. While the locality parameters can be understood directly in terms of the storage
system, it is more instructive from a coding theoretic point of view to understand
them via punctured codes. Then, the punctured codes will correspond exactly to the
restrictions to â€œlocality setsâ€, which can be used to locally repair a small number of
node failures within the locality set.
Deï¬nition 3 Let G be a matrix over F indexed by E and C the linear code generated
by G. Then, for X âŠ†E, CX is a linear [nX, kX, dX]-code where
nX = |X|,
kX = rank(G(X)),
dX = min{|Y| : Y âŠ†X and kX\Y < kX}.
Alternatively, one can deï¬ne the minimum distance dX as the smallest support of
a non-zero codeword in CX = R(G(X)). We use Deï¬nition 3, as it has the advantage
of not depending on the linearity of the code.

390
R. Freij-Hollanti et al.
Example 2 Consider the storage code C from Example 1. Let Y1 = {1, 2, 3, 5, 6, 7},
X1 = {1, 2, 5} and X2 = {2, 6, 7}. Then CY1, CX1 and CX2 are storage codes with
[nY1, kY1, dY1] = [6, 3, 3] ,
[nX1, kX1, dX1] = [3, 2, 2] ,
[nX2, kX2, dX2] = [3, 2, 2] .
The parameter dX is the minimum (Hamming) distance of CX. We say that C is
an [n, k, d]-code with [n, k, d] = [nE, kE, dE].
We choose the following deï¬nition for general (n, k, d,r, Î´, t)-LRCs (i.e., both
linear and nonlinear), which we will compare to known results for linear LRCs.
Deï¬nition 4 An (n, k, d)-code C over A is a nonempty subset C of An, where A is
a ï¬nite set of size s, k = logs(|C|), and d the minimum (Hamming) distance of the
code. For X = {i1, . . . , im} âŠ†E, the puncturing CX is deï¬ned as
CX = {(ci1, . . . , cim) : c âˆˆC}.
The code C is non-degenerate, if d â‰¥2 and |C{i}| > 1 for all coordinates i âˆˆ[n].
Deï¬nition 5 A locally repairable code over A is a non-degenerate (n, k, d)-code C.
A coordinate x âˆˆ[n] of C has locality (r, Î´) and availability t if there are t subsets
R1, . . . , Rt of [n], called repair sets of x, such that for i, j âˆˆ[t]
(i) x âˆˆRi,
(ii) |Ri| â‰¤r + Î´ âˆ’1,
(iii) d(CRi) â‰¥Î´,
(iv) i Ì¸= j
â‡’
Ri âˆ©R j = {x}.
If every element x âˆˆX âŠ†E has availability with parameters (n, k, d,r, Î´, t) in
C, then we say that the set X has (n, k, d,r, Î´, t)-availability in C. We will often
talk about codes with (n, k, d,r, Î´)-locality, by which we mean a code that has
(n, k, d,r, Î´, 1)-availability, so that symbols are not required to be included in more
than one repair set. If the other parameters are clear from the context, we may
shortly say that X has â€œlocality (r, Î´)â€ or â€œavailability tâ€, along the lines of the above
deï¬nition.
An information set of a linear [n, k, d]-code C is deï¬ned as a set X âŠ†E such that
kX = |X| = k. Hence, X is an information set of C if and only if there is a generator
matrix G of C such that G(X) equals the identity matrix, i.e., C is systematic in
the coordinate positions indexed by X when generated by G. In terms of storage
systems, this means that the nodes in X together store all the information of the DSS.
Example 3 Two examples of an information set of the linear code C generated by
G in Example 1 are {1, 2, 3, 4} and {1, 2, 6, 8}.

Matroid Theory and Storage Codes: Bounds and Constructions
391
More formally we deï¬ne:
Deï¬nition 6 Let C be an (n, k, d)-code and X a subset of [n]. Then X is an infor-
mation set of C if logs(|CX|) = k and logs(CY) < k for all Y âŠŠX. Further, X is
systematic if k is an integer, |X| = k and CX = Ak. Also, X is an all-coordinate set
if X = [n].
Deï¬nition 7 A systematic-symbol, information-symbol, and all-symbol LRC,
respectively, is an (n, k, d)-LRC with a systematic, information set and all-coordinate
set X, such that every coordinate in X has locality (r, Î´) and availability t. These are
denoted by
(n, k, d,r, Î´, t)s-LRC, (n, k, d,r, Î´, t)i-LRC, and (n, k, d,r, Î´, t)a-LRC,
respectively. Further, when availability is not considered (t = 1), we get natural
notions of (n, k, d,r, Î´)s, (n, k, d,r, Î´)i, and (n, k, d,r, Î´)a-LRCs.
2
Introduction to Matroids
Matroids were ï¬rst introduced by Whitney in 1935, to capture and generalise the
notion of linear dependence in purely combinatorial terms [48]. Indeed, the combi-
natorial setting is general enough to also capture many other notions of dependence
occurring in mathematics, such as cycles or incidences in a graph, non-transversality
of algebraic varieties, or algebraic dependence of ï¬eld extensions. Although the
original motivation comes from linear algebra, we will see that a lot of matroid
terminology comes from graph theory and projective geometry. More details about
these aspects of matroid theory are relegated to the appendix.
2.1
Deï¬nitions
We begin by presenting two equivalent deï¬nitions of a matroid.
Deï¬nition 8 (Rank function) A (ï¬nite) matroid M = (Ï, E) is a ï¬nite set E together
with a rank function Ï : 2E â†’Z such that for all subsets X, Y âŠ†E
(R.1) 0 â‰¤Ï(X) â‰¤|X|,
(R.2) X âŠ†Y
â‡’
Ï(X) â‰¤Ï(Y),
(R.3) Ï(X) + Ï(Y) â‰¥Ï(X âˆªY) + Ï(X âˆ©Y).
An alternative but equivalent deï¬nition of a matroid is the following.
Deï¬nition 9 (Independent sets) A (ï¬nite) matroid M = (I , E) is a ï¬nite set E and
a collection of subsets I âŠ†2E such that

392
R. Freij-Hollanti et al.
(I.1) âˆ…âˆˆI ,
(I.2) Y âˆˆI , X âŠ†Y â‡’X âˆˆI ,
(I.3) For all pairs X, Y âˆˆI with |X| < |Y|, there exists
y âˆˆY \ X such that X âˆª{y} âˆˆI .
The subsets in I are the independent sets of the matroid.
The rank function Ï and the independents sets I of a matroid on a ground set E
are linked as follows: For X âŠ†E,
Ï(X) = max{|Y| : Y âŠ†X and Y âˆˆI },
and X âˆˆI if and only if Ï(X) = |X|. It is an easy (but not trivial) exercise to show
that the two deï¬nitions are equivalent under this correspondence. Another frequently
used deï¬nition is in terms of the set of bases for a matroid, which are the maximal
independent sets. Further, we will also use the nullity function Î· : 2E â†’Z, where
Î·(X) = |X| âˆ’Ï(X) for X âŠ†E.
Any matrix G over a ï¬eld F generates a matroid MG = (Ï, E), where E is the set
of columns of G, and Ï(I) is the rank over F of the induced matrix G(I) for I âŠ†E.
Consequently, I âˆˆI precisely when I is a linearly independent set of vectors.
It is straightforward to check that this is a matroid according to Deï¬nition 8. As
elementary row operations preserve the row space R(G(I)) for all I âŠ†E, it follows
that row equivalent matrices generate the same matroid.
Two matroids M1 = (Ï1, E1) and M2 = (Ï2, E2) are isomorphic if there exists a
bijection Ïˆ : E1 â†’E2 such that Ï2(Ïˆ(X)) = Ï1(X) for all subsets X âŠ†E1.
Deï¬nition 10 A matroid that is isomorphic to MG for some matrix G over F is said
to be representable over F. We also say that such a matroid is F-linear.
Two trivial matroids are the zero matroid where Ï(X) = 0 for each set X âŠ†E,
and the one where Ï(X) = |X| for all X âŠ†E. These correspond to all-zeros matrices
and invertible n Ã— n-matrices respectively. The ï¬rst non-trivial example of a matroid
is the following:
Deï¬nition 11 The uniform matroid U k
n = (Ï, [n]), where [n] = {1, 2, . . . , n}, is
given by the rank function Ï(X) = min{|X|, k} for X âŠ†[n].
The following straightforward observation gives yet another characterisation of
MDS codes.
Proposition 1 G is the generator matrix of an [n, k, n âˆ’k + 1]-MDS code if and
only if MG is the uniform matroid U k
n .
2.2
Matroid Operations
For explicit constructions of matroids, as well as for analysing their structure, a
few elementary operations are useful. Here, we will deï¬ne these in terms of the rank

Matroid Theory and Storage Codes: Bounds and Constructions
393
function, but observe that they can equally well be formulated in terms of independent
sets. The effect of these operations on the representability of the matroid is discussed
inappendix.Inadditiontotheoperationslistedhere,twootherveryimportantmatroid
operations are dualisation and contraction. As these are not explicitly used here to
understand locally repairable codes, we leave their deï¬nition to appendix.
Deï¬nition 12 The direct sum of two matroids M = (ÏM, EM) and N = (ÏN, EN) is
M âŠ•N = (Ï„, EM âŠ”EN),
where âŠ”denotes the disjoint union, and Ï„ : 2EMâŠ”EN â†’Z is deï¬ned by Ï„(X) =
ÏM(X âˆ©EM) + Ï(X âˆ©EN).
Thus, all dependent sets from M and N remain dependent in M âŠ•N, whereas there is
no dependence between elements in M and elements in N. If M and N are graphical
matroids,3 then M âŠ•N is graphical, and obtained from the disjoint union of the
graphs associated to M and N.
Deï¬nition 13 The restriction of M = (Ï, E) to a subset X âŠ†E is the matroid
M|X = (Ï|X, X), where
Ï|X(Y) = Ï(Y), for Y âŠ†X.
(1)
Obviously, for any matroid M with underlying set E, we have M|E=M. The
restriction operation is also often referred to as deletion of E \ X, especially if
E \ X is a singleton. Given a matrix G that represents M, the submatrix G(X) rep-
resents M|X.
Deï¬nition 14 The truncation of a matroid M = (Ï, E) at rank k â‰¤Ï(E) is Mk =
(Ïâ€², E), where Ïâ€²(X) = min{Ï(X), k}.
Geometrically, the truncation of a matroid corresponds to projecting a point con-
ï¬guration onto a generic k-dimensional space. However, this does not imply that
truncations of F-linear matroids are necessarily F-linear, as it may be the case that
there exists no k-space that is in general position relative to the given point con-
ï¬guration. However, it is easy to see that Mk is always representable over some
ï¬eld extension of F. In fact, via a probabilistic construction, one sees that the ï¬eld
extension can be chosen to have size at most q
n
k

[17].
The relaxation is the elementary operation that is most difï¬cult to describe in
terms of rank functions. It is designed to destroy representability of matroids, and
corresponds to selecting a hyperplane in the point conï¬guration, and perturbing it
so that its points are no longer coplanar. To prepare for the deï¬nition, we say that a
circuit is a dependent set, all of whose subsets are independent. For any nonuniform
matroid M = (Ï, E), there are circuits of rank Ï(E) âˆ’1. This is seen by taking any
dependent set of rank Ï(E) âˆ’1, and deleting elements successively in such a way
that the rank does not decrease. We mention that a matroid that has no circuits of
3See appendix for the deï¬nition of graphical matroids.

394
R. Freij-Hollanti et al.
Fig. 1 The non-Pappus matroid, which is not representable over any ï¬eld. If there were a line
between the three points in the middle, then the ï¬gure would illustrate the matroid MG in Example 4.
Relaxation of the circuit {4, 5, 6} corresponds to deletion of this line in the ï¬gure
rank < Ï(E) âˆ’1 is called a paving matroid. It is conjectured that asymptotically (in
the size) almost all matroids are paving [24]. Recent research shows that this is true
at least on a â€œlogarithmic scaleâ€ [28].
Deï¬nition 15 Let M = (I , E) be a matroid with rank function Ï, and let C be a
circuit of rank Ï(E) âˆ’1. The relaxation of M at C is the matroid (I âˆª{C}, E).
Example 4 The ï¬rst example of a matroid constructed by relaxation is the non-
Pappus matroid of Fig.1. This is constructed by relaxing the circuit {4, 5, 6} from
the representable matroid MG, where
G =
1 2 3
4 5
6
7
8
9
1 0 âˆ’1 1/2 0 âˆ’1/2 1
0 âˆ’1
1 1 1
0 0
0
âˆ’1 âˆ’1 âˆ’1
1 1 1
1 1
1
1
1
1
and can be deï¬ned over any ï¬eld of odd (or zero) characteristic, other than F3.
2.3
Matroid Invariants of Codes
There is a straightforward connection between linear codes and matroids. Indeed, let
C be a linear code generated by a matrix G. Then C is associated with the matroid
MG = (Ï, E).AstwodifferentgeneratormatricesofC havethesamerowspace,they
will generate the same matroid. Therefore, without any inconsistency, we denote the
associated linear matroid of C by MC = (ÏC, E). In general, there are many different
codes C Ì¸= Câ€² with the same matroid structure MC = MCâ€². In the appendix, we will
see how this phenomenon can be interpreted as a stratiï¬cation of the Grassmannian
over a ï¬nite ï¬eld.
A property of linear codes that depends only on the matroid structure of the code
is called matroid invariant. For example, the collection of information sets and the
parameters [n, k, d] of a code are matroid invariant properties. This is the content of
the following easy proposition.

Matroid Theory and Storage Codes: Bounds and Constructions
395
Proposition 2 Let C be a linear [n, k, d]-code and X âŠ†E. Then for MC = (ÏC, E),
(i) nX = |X|,
(ii) kX = ÏC(X),
(iii) dX = min{|Y| : Y âŠ†X, ÏC(X \ Y) < ÏC(X)},
(iv) X is an information set of C â‡â‡’
X is a basis of MC â‡â‡’ÏC(X) = |X| = k.
In addition to the parameters [n, k, d] of a linear code C, we are also interested in
thelength, rankandminimumdistanceof thepuncturedcodes, sincethesecorrespond
to the locality parameters at the different hierarchy levels, which we will discuss in
more detail in Sect.5.
Apuncturedcodecanbeanalysedusingmatroidrestrictions, since MC|X = MC|X
for every coordinate subset X. Thus, the parameters [nX, kX, dX] of CX are also
matroid invariant properties for C.
Example 5 Let C denote the [n, k, d]-code generated by the matrix G given in
Example 1. Then [n, k, d] = [9, 4, 3], where the value of d arises from the fact that
ÏC([9] \ {i, j}) = 4 for i, j = 1, 2, . . . , 9, and ÏC([9] \ {4, 8, 9}) = 3. Two informa-
tion sets of C are {1, 2, 3, 4} and {1, 2, 6, 8}, as we already saw before in Example
3.
It is rather easy to see that two different linear codes can have the same associated
matroid. As a consequence, not every property of a linear code is matroid invariant.
An example of a code invariant that is not matroid invariant is the covering radius
[5, 37]. Indeed, an [n, k, d]-MDS code, i.e., a realisation of the uniform matroid
U k
n , generically has covering radius d âˆ’1 = n âˆ’k, yet there exist MDS codes with
lower covering radii. An explicit example is given in [5].
2.4
The Lattice of Cyclic Flats
One matroid invariant that has singled out as essential for describing the repairability
of storage codes is the lattice of cyclic ï¬‚ats. To deï¬ne this, remember that X âŠ†E is a
circuit in M = (I , E) if X is dependent, but all proper subsets of X are independent.
A cyclic set is a (possibly empty) union of circuits. Equivalently, X is cyclic if for
every x âˆˆX
Ï(X \ {x}) = Ï(X).
Let us deï¬ne the operation cyc : 2E â†’2E by
cyc(X) = {x âˆˆX : Ï(X \ {x}) = Ï(X)}.
Then X is cyclic if and only if cyc(X) = X. We refer to cyc as the cyclic core operator.

396
R. Freij-Hollanti et al.
Dually, we deï¬ne the closure of X to be
cl(X) = {y âˆˆE : Ï(X âˆª{y}) = Ï(X)},
and notice that X âŠ†cl(X) by deï¬nition. We say that X is a ï¬‚at if cl(X) = X. There-
fore, X is a cyclic ï¬‚at if
Ï(X \ {x}) = Ï(X) and Ï(X âˆª{y}) > Ï(X)
for all x âˆˆX and y âˆˆE \ X. The set of ï¬‚ats, cyclic sets, and cyclic ï¬‚ats of M are
denoted by F(M), U (M), and Z (M), respectively.
It is not entirely obvious that the set of cyclic ï¬‚ats is nonempty. However, it follows
from the matroid axioms that the closure operator cl preserves cyclicity, and that the
cyclic core operator cyc preserves ï¬‚atness. Thus we can consider cl and cyc as maps
cl :

2E â†’F(M)
U (M) â†’Z (M) ,
and
cyc :

2E â†’U (M)
F(M) â†’Z (M) .
In particular, for any set X âŠ†E, we have cyc â—¦cl(X) âˆˆZ (M) and cl â—¦cyc(X) âˆˆ
Z (M).
Let M[G] = (Ï, E) be a linear matroid, generated by G. Then X âŠ†E is a cyclic
ï¬‚at if and only if the following two conditions are satisï¬ed
(i) C(G(X)) âˆ©C(G(E \ X)) = 0
(ii) x âˆˆX â‡’C(G(X \ {x})) = C(G(X)).
In terms of storage codes, a cyclic ï¬‚at is thus a set X âŠ†E of storage nodes such that
every node in X can be repaired by the other nodes in X, whereas no node outside
X can be repaired by X. This observation shows the relevance of cyclic ï¬‚ats for
storage applications. The strength of using Z (M) as a theoretical tool comes from
its additional lattice structure, which we will discuss next.
A collection of sets P âŠ†2E ordered by inclusion deï¬nes a partially ordered set
(poset) (P, âŠ†). Let X and Y denote two elements of P. Z is the join X âˆ¨Y if it is
the unique maximal element in {W âˆˆP : X âŠ†W, Y âŠ†W}. Dually, Z is the meet
X âˆ§Y if it is the unique minimal element in {W âˆˆP : X âŠ‡W, Y âŠ‡W}.
A pair of elements in an arbitrary poset does not need to have a join or a meet. If
(P, âŠ†) is a poset such that every pair of elements in P has a join and a meet, then
P is called a lattice. The bottom and top elements of a ï¬nite lattice (P, âŠ†) always
exist, and are denoted by 1P = 
XâˆˆP X and 0P = 
XâˆˆP X, respectively.

Matroid Theory and Storage Codes: Bounds and Constructions
397
Two basic properties of cyclic ï¬‚ats of a matroid are given in the following propo-
sition.
Proposition 3 ([4]) Let M = (Ï, E) be a matroid and Z the collection of cyclic
ï¬‚ats of M. Then,
(i) Ï(X) = min{Ï(F) + |X \ F| : F âˆˆZ }, for X âŠ†E,
(ii) (Z , âŠ†) is a lattice, X âˆ¨Y = cl(X âˆªY) and
X âˆ§Y = cyc(X âˆ©Y) for X, Y âˆˆZ .
Proposition 3 (i) shows that a matroid is uniquely determined by its cyclic ï¬‚ats
and their ranks.
Example 6 Let MC = (ÏC, E) be the matroid associated to the linear code C gen-
erated by the matrix G given in Example 1. The lattice of cyclic ï¬‚ats (Z , âŠ†) of MC
is given in the ï¬gure below, where the cyclic ï¬‚at and its rank are given at each node.
An axiom scheme for matroids via cyclic ï¬‚ats and their ranks was independently
given in [4, 35]. This gives a compact way to construct matroids with prescribed
local parameters, which we have exploited in [47].
Theorem 1 (see [4] Theorem 3.2 and [35]) Let Z âŠ†2E and let Ï be a function
Ï : Z â†’Z. There is a matroid M on E for which Z is the set of cyclic ï¬‚ats and Ï
is the rank function restricted to the sets in Z , if and only if
(Z0) Z is a lattice under inclusion,
(Z1) Ï(0Z ) = 0,
(Z2) X, Y âˆˆZ and X âŠŠY â‡’
0 < Ï(Y) âˆ’Ï(X) < |Y| âˆ’|X|,
(Z3) X, Y âˆˆZ â‡’Ï(X) + Ï(Y) â‰¥
Ï(X âˆ¨Y) + Ï(X âˆ§Y) + |(X âˆ©Y) \ (X âˆ§Y)|.

398
R. Freij-Hollanti et al.
For a linear [n, k, d]-code C with MC = (ÏC, E) and Z = Z (MC), and for a
coordinate x, we have
(i) d â‰¥2 â‡â‡’1Z = E,
(ii) C{x} Ì¸= {0F} for every x âˆˆE â‡â‡’0Z = âˆ….
Hence, by Deï¬nition 1, we can describe non-degeneracy in terms of the lattice of
cyclic ï¬‚ats, as follows.
Proposition 4 Let C be a linear [n, k, d]-code and Z denote the collection of cyclic
ï¬‚ats of the matroid MC = (ÏC, E). Then C is a non-degenerate storage code if and
only if 0Z = âˆ…and 1Z = E.
Proposition 5 Let C be a non-degenerate storage code and MC = (ÏC, E). Then,
for X âŠ†E, CX is a non-degenerate storage code if and only if X is a cyclic set of
MC.
As cyclic sets correspond to non-degenerate subcodes, and hence to systems
where every symbol is stored with redundancy, we will use these as our â€œrepair setsâ€.
Therefore, we want to determine from the lattice of cyclic ï¬‚ats, whether a set is cyclic
or not, which we achieve through the following theorem.
Theorem 2 Let M = (Ï, E) be a matroid with 0Z = âˆ…and 1Z = E where Z =
Z (M). Then, for any X âŠ†E, X âˆˆU (M) if and only if the cyclic ï¬‚at
F X =

{F âˆˆZ : X âŠ†F}
is such that
Ï(F) + |X \ F| > Ï(F X).
for all F âŠŠF X in Z .
If this is indeed the case, then it is easy to verify that F X as deï¬ned in Theorem
2 is indeed the closure cl(X) as deï¬ned earlier. In order to analyze the parameters
[nX, kX, dX] of a punctured code CX, we will use the lattice of cyclic ï¬‚ats of MC|X.
Theorem 3 Let M = (Ï, E) be a matroid with 0Z = âˆ…and 1Z = E where Z =
Z (M). Then, for X âˆˆU (M),
(i) Z (M|X) = {X âˆ©F âˆˆU (M) : F âˆˆZ , F âŠ†F X},
(ii) Y âˆˆZ (M|X) â‡’Ï|X(Y) = Ï(FY).
Weremarkthatif X isacyclicï¬‚atofamatroid M,thenZ (M|X) = {F âˆˆZ (M) :
F âŠ†X}.
Example 7 Let Z = Z (MC) be the lattice of cyclic ï¬‚ats given in Example 6, where
MC = (ÏC, E) is the matroid associated to the linear LRC C generated by the matrix

Matroid Theory and Storage Codes: Bounds and Constructions
399
G given in Example 1. Then, F X = FY = Y1 for X = {1, 2, 3, 7} and Y = {1, 2, 3}.
Further, X is a cyclic set but Y is not a cyclic set. The lattice of cyclic ï¬‚ats (ZX, âŠ†)
for MC|X = MC|X is shown in the following ï¬gure.
The very simple structure of ZX shows that CX has the very favourable property
of being an MDS code. Indeed, the following proposition is immediate from the
deï¬nitions of the involved concepts.
Proposition 6 Let C be a linear code of length n and rank k. The following are
equivalent:
(i) C is an [n, k, n âˆ’k + 1]-MDS code.
(ii) MC is the uniform matroid U k
n .
(iii) Z = Z (MC) is the two element lattice with 1Z = [n] and 0Z = âˆ….
For linear LRCs we are also interested in when a coordinate set is an information
set, or equivalently, if it is a basis for the matroid. This property is determined by the
cyclic ï¬‚ats as follows.
Proposition 7 Let C be a linear [n, k, d]-code with 0Z = âˆ…and 1Z = E where Z
is the collection of cyclic ï¬‚ats of the matroid MC = (ÏC, E). Then, for any X âŠ†E,
X is an information set of C if and only if the following two conditions are satisï¬ed,
(i) |X| = ÏC(1Z ),
(ii) |X âˆ©F| â‰¤ÏC(F) for every F âˆˆZ .
Example 8 Let C be the linear [n, k, d]-code generated by the matrix G given in
Example 1. Then, by the lattice of cyclic ï¬‚ats for MC given in Example 6, C is a linear
LRC with all-symbol (2, 2)-locality. We notice that, by Proposition 7, {1, 2, 3, 4} is
an information set of C. This follows as it is not contained in either of Y1 and Y2,
while all its subsets are. On the other hand, {1, 2, 8, 9} is not an information set of
C, as it is itself a subset of Y2.
The parameters [n, k, d] of a linear LRC C and [nX, kX, dX] of a punctured code
CX that is a non-degenerate storage code can now be determined by the lattice of
cyclic ï¬‚ats as follows.

400
R. Freij-Hollanti et al.
Theorem 4 Let C be a linear [n, k, d]-LRC, where Z = Z (MC) for the matroid
MC = (ÏC, E). Then, for any X âˆˆU (MC), CX is a linear [nX, kX, dX]-LRC with
(i) nX = |X|,
(ii) kX = Ï(F X),
(iii) dX = nX âˆ’kX + 1 âˆ’max{Î·(Y) : Y âˆˆZ (MC|X) \ X}.
Example 9 Let Z = Z (MC) be the lattice of cyclic ï¬‚ats given in Example 6, where
MC = (ÏC, E) is the matroid associated to the linear [n, k, d]-LRC C generated
by the matrix G given in Example 1. Then by Example 7, X = {1, 2, 3, 7} is a
cyclic set, and by Theorem 4 CX is a linear [nX, kX, dX]-LRC with parameters
nX = 4, kX = 3 and dX = 4 âˆ’3 + 1 âˆ’0 = 2. Moreover, n = nE = 9, k = kE = 4
and d = dE = 9 âˆ’4 + 1 âˆ’3 = 3.
3
Singleton-Type Bounds
Many important properties of a linear code C are due to its matroid structure, which
is captured by the matroid MC. By the results in [10, 47], matroid theory seems
to be particularly suitable for proving Singleton-type bounds for linear LRCs and
nonexistence results of Singleton-optimal linear LRCs for certain parameters.
Even though matroids can be associated to linear codes to capture the key proper-
ties for linear LRCs, this cannot be done in general for nonlinear codes. Fortunately,
by using some key properties of entropy, any code (either linear and nonlinear) C
can be associated with a polymatroid PC so that PC captures the key properties of
the code when it is used as a LRC. A polymatroid is a generalisation of a matroid.
For any linear code C the associated polymatroid PC and matroid MC are the same
object. We will brieï¬‚y discuss the connection between polymatroids and codes in
Sect.5. Singleton-type bounds for polymatroids were derived in [46], and polyma-
troid theory for its part seems to be particularly suitable for proving such bounds for
general LRCs. In Sect.5 we will also review Singleton-type bounds for polymatroids
and general codes with availability and hierarchy.
3.1
Singleton-Type Bounds for Matroids and Linear LRCs
Matroid theory provides a uniï¬ed way to understand and connect several different
branches of mathematics, for example linear algebra, graph theory, combinatorics,
geometry, topology and optimisation theory. Hence, a theorem proven for matroids
gives â€œfor freeâ€ theorems for many different objects related to matroid theory. As
described earlier, the key parameters (n, k,r, d, Î´, t) of a linear LRCs C are matroid
properties of the matroid MC and can therefore be deï¬ned for matroids in general.

Matroid Theory and Storage Codes: Bounds and Constructions
401
Deï¬nition 16 Let M = (Ï, E) be a matroid and X âŠ†E. Then
(i) nX = |X|,
(ii) kX = Ï(X),
(iii) dX = min{|Y| : Y âŠ†X, Ï(X \ Y) < Ï(X)},
(iv) X is an information set of M if Ï(X) = kE and Ï(Y) < kE for all Y âŠŠX,
(v) M is non-degenerate if Ï(x) > 0 for all x âˆˆE and dE â‰¥2.
Further, n = nE, k = kE and d = dE, and the deï¬nitions of repair sets, (r, Î´)-
locality and t-availability for elements x âˆˆE, as well as the concepts of
(n, k, d,r, Î´, t)i-matroids and (n, k, d,r, Î´, t)a-matroids are directly carried over
from Deï¬nitions 5 and 7.
BeforestatingTheorem5below,itisnotatallclearthattheSingleton-typebounds,
already proven for linear LRCs, also hold for matroids in general. Especially, one
could doubt this generality of the bound because of the wide connection between
matroids and a variety of different mathematical objects, as well as for the sake of
the recently proven result, stated in Theorem 13 later on, that almost all matroids
are nonrepresentable. However, Theorem 5 gives a Singleton-type bound that holds
for matroids in general. This implies, as special cases, the same bound on linear
LRCs and other objects related to matroids, e.g., graphs, almost afï¬ne LRCs, and
transversals. For the bound to make sense for various objects, a description of the
parameters (n, k, d,r, Î´) has to be given for the objects in question. To give an
example, for a graph,
â€¢ n equals the number of edges,
â€¢ k equals the difference of the number of vertices and the number of connected
components,
â€¢ d is the smallest number of edges in an edge-cut (i.e., a set of edges whose removal
increases the number of connected components in the graph).
Recall that the Singleton bound [36] states that for any linear [n, k, d]-code we
have
d â‰¤n âˆ’k + 1.
(2)
In what follows, we state generalised versions of this bound, accounting for the
various parameters relevant for storage systems. We start with the general one for
matroids.
Theorem 5 ([47] Singleton-type bound for matroids)
Let M = (Ï, E) be an
(n, k, d,r, Î´)i-matroid. Then
d â‰¤n âˆ’k + 1 âˆ’
	k
r

âˆ’1

(Î´ âˆ’1).
(3)
Theorem 5 was stated for all-symbol locality in [47]. However, the proof given
in [47] implies also information-symbol locality. As an illustration on how matroid

402
R. Freij-Hollanti et al.
theory and cyclic ï¬‚ats can be useful for proving Singleton-type of bounds we will
here give a proof of Theorem 5.
Proof We know from Theorem 4 that d = n âˆ’k + 1 âˆ’max{Î·(Z) : Z âˆˆZ \ E}.
Hence to prove the theorem we need to show that there exists a cyclic ï¬‚at Z Ì¸= E in
M with Î·(Z) â‰¥
 k
r

âˆ’1

(Î´ âˆ’1).
Let B be an information set of M, i.e, B is a basis of M, such that M is an
(n, k, d,r, Î´)i-matroid. For x âˆˆB let Rx denote the repair set of x. Since Rx is a
cyclic set of we obtain that Zx = cl(Rx) is a cyclic ï¬‚at of M with
Ï(Zx) = Ï(Rx) â‰¤r and Î·(Zx) â‰¥Î·(Rx) â‰¥dRx âˆ’1 â‰¥Î´ âˆ’1.
As Ï(B) = k we can choose a subset of cyclic ï¬‚ats {Z1, . . . , Zm} âŠ†{Zx : x âˆˆB}
such that we obtain a chain of cyclic ï¬‚ats
âˆ…= Y0 âŠŠY1 âŠŠÂ· Â· Â· âŠŠYm = E
with Yi = Yiâˆ’1 âˆ¨Zi for i = 1, . . . , m. Since Ï(Y0) = Î·(Y0) = 0 and Ï(Ym) = k, the
theorem will now be proved if we can prove that Ï(Yi) âˆ’Ï(Yiâˆ’1) â‰¤r and Î·(Yi) âˆ’
Î·(Yiâˆ’1) â‰¥Î´ âˆ’1 for i = 1, . . . , m.
First, by the use of Axiom (R.3) and Proposition 3,
Ï(Yi) = Ï(cl(Yiâˆ’1 âˆªZi)) = Ï(Yiâˆ’1 âˆªZi) â‰¤Ï(Yiâˆ’1) + Ï(Zi) âˆ’Ï(Yiâˆ’1 âˆ©Zi)
â‰¤Ï(Yiâˆ’1) + r.
Second, by Axiom (R.3), Î·(X) + Î·(Y) â‰¤Î·(X âˆ©Y) + Î·(X âˆªY) for X, Y âŠ†E.
Further, we observe that, cyc(Yiâˆ’1 âˆ©Zi) and Zi are cyclic ï¬‚ats of M|Zi and that
cyc(Yiâˆ’1 âˆ©Zi) âŠŠZi. Hence,
Î·(Yi) = Î·(cl(Yiâˆ’1 âˆªZi)) â‰¥Î·(Yiâˆ’1 âˆªZi) â‰¥Î·(Yiâˆ’1) + Î·(Zi) âˆ’Î·(Yiâˆ’1 âˆ©Zi)
= Î·(Yiâˆ’1) + Î·(Zi) âˆ’Î·(cyc(Yiâˆ’1 âˆ©Zi))
= Î·(Yiâˆ’1) + |Zi| âˆ’Ï(Zi) âˆ’Î·(cyc(Yiâˆ’1 âˆ©Zi)) â‰¥Î·(Yiâˆ’1) + dZi âˆ’1
â‰¥Î·(Yiâˆ’1) + Î´ âˆ’1.
That dZi â‰¥Î´ follows from the fact that Zi = cl(Rx) for some x âˆˆB and therefore
dZi = dcl(Rx) = min{|Y| : Y âŠ†cl(Rx), Ï(cl(Rx) \ Y) â‰¤Ï(cl(Rx)}
â‰¥min{|Y| : Y âŠ†Rx, Ï(Rx \ Y) â‰¤Ï(Rx)}
= dRx.
âŠ“âŠ”

Matroid Theory and Storage Codes: Bounds and Constructions
403
The Singleton bound given in (2) was generalised by Gopalan et al. in [13] as
follows. A linear (n, k, d,r)i-LRC satisï¬es
d â‰¤n âˆ’k + 1 âˆ’
	k
r

âˆ’1

.
(4)
The bound (4) shows that there is a penalty for requiring locality. That is, the smaller
the locality r the smaller the upper bound on d. By the deï¬nition of LRCs, any linear
[n, k, d]-code with locality r is also a linear [n, k, d]-code with locality k. Hence,
by letting the locality be k, the bound (4) implies (2).
The bound (4) was generalised in [30] as follows. A linear (n, k, d,r, Î´)i-LRC
satisï¬es
d â‰¤n âˆ’k + 1 âˆ’
	k
r

âˆ’1

(Î´ âˆ’1).
(5)
The bound (5) again shows that there is a penalty on the upper bound for d depending
on the size of the local distance Î´. This is, the bigger the local distance Î´ the smaller
the upper bound on the global distance d. However, we must remark that any linear
(n, k, d,r, Î´)i-LRC satisï¬es d â‰¥Î´, and this property also holds more generally for
matroids [47]. The bound (4) follows from the bound (5) by letting Î´ = 2.
A bound including availability was proven in [44]. This bound states that a linear
(n, k, d,r, t)i-LRC satisï¬es
d â‰¤n âˆ’k + 1 âˆ’
	t(k âˆ’1) + 1
t(r âˆ’1) + 1

âˆ’1

.
(6)
Again, the bound (4) follows from (6) above by letting t = 1.
The bounds (3)â€“(6) are stated assuming information-symbol locality. However,
since every matroid contains an information set, this implies that the bound is also
valid under the stronger assumption of all-symbol locality.
3.2
Stronger Bounds for Certain Parameter Values
A linear LRC, or more generally a matroid, that achieves any of the Singleton-type
bounds given above will henceforth be called Singleton-optimal.
Any (n, k, d,r, Î´)i-matroid M satisï¬es that Î´ â‰¤d. Hence, by the bound (5), k â‰¤
n âˆ’(Î´ âˆ’1)âŒˆk
r âŒ‰for M. Thus, regardless of the global minimum distance d, any
(n, k, d,r, Î´)-LRC with either information or all-symbol locality, has parameters
n, k,r, Î´ in the set

404
R. Freij-Hollanti et al.
P(n, k,r, Î´) =

(n, k,r, Î´) âˆˆZ4 : 2 â‰¤Î´ and 0 < r â‰¤k â‰¤n âˆ’(Î´ âˆ’1)
	k
r


.
(7)
A very natural question to ask then is for which parameters (n, k,r, Î´) âˆˆP(n, k,r, Î´)
there exists a Singleton-optimal matroid or linear LRC, regarding both informa-
tion and all-symbol locality. We remark that existence results on Singleton-optimal
linear LRCs imply existence results on Singleton-optimal matroids. Conversely,
nonexistence results on Singleton-optimal matroids implies nonexistence results on
Singleton-optimal linear LRCs.
When considering information-symbol locality it is known that the upper bound
for d given in (5) is achieved for all parameters (n, k,r, Î´) âˆˆP(n, k,r, Î´) by linear
LRCs over sufï¬cient large ï¬elds. This follows from [14], where a new class of codes
called pyramid codes was given. Using this class of codes, Singleton-optimal linear
(n, k, d,r, Î´)i-LRCs can be constructed for all parameters in P(n, k,r, Î´).
It is well known that Singleton-optimal linear (n, k, d,r, Î´)a-LRCs exist whenr =
k.Namely,theLRCsinthesecasesarelinear [n, k, n âˆ’k + 1]MDS-codes.However,
existence or nonexistence results when r < k are in general not that easy to obtain. In
[38], existence and nonexistence results on Singleton-optimal linear (n, k, d,r, Î´)a-
LRCs were examined. Such results were given for certain regions of parameters,
leaving other regions for which the answer of existence or nonexistence of Singleton-
optimal linear LRCs is not known. The results on nonexistence were extended to
matroids in [47]. All the parameter regions for the nonexistence of Singleton-optimal
linear LRCs in [47] were also regions of parameters for the nonexistence of Singleton
optimal matroids for all-symbol locality. Further, more regions of parameters for
nonexistence of Singleton-optimal matroids with all-symbol locality were given in
[47]. This implies new regions of parameters for nonexistence of Singleton-optimal
linear LRCs with all-symbol locality.
The nonexistence results for Singleton-optimal matroids were proven via the
following structure result in [47]. Before we state the theorem we need the concept
of nontrivial unions. Let M = (Ï, E) be a matroid with repair sets {Rx}xâˆˆE. For
Y âŠ†E, we say that
RY =

xâˆˆY
Rx
and
RY is a nontrivial union if Rx âŠˆRY\{x} for every x âˆˆY.
Theorem 6 ([47] Structure theorem for Singleton-optimal matroids)
Let M =
(Ï, E) be an (n, k, d,r, Î´)a-matroid with r < k, repair sets {Rx}xâˆˆE and
d = n âˆ’k + 1 âˆ’
	k
r

âˆ’1

(Î´ âˆ’1).
Then, the following properties must be satisï¬ed by the collection of repair sets and
the lattice of cyclic ï¬‚ats Z of M:

Matroid Theory and Storage Codes: Bounds and Constructions
405
(i) 0Z = âˆ…,
(ii) for each x âˆˆE,
a) Rx is an atom of Z ,
(i.e., Rx âˆˆZ , 0Z < Rx and âˆ„Z âˆˆZ such that 0Z < Z < Rx),
b) Î·(Rx) = Î´ âˆ’1,
(iii) for each Y âŠ†E with RY being a nontrivial union,
c) |Y| < âŒˆk
r âŒ‰
â‡’
RY âˆˆZ ,
d) |Y| < âŒˆk
r âŒ‰
â‡’
Ï(RY) = |RY| âˆ’|Y|(Î´ âˆ’1),
e) |Y| â‰¤âŒˆk
r âŒ‰
â‡’
|Rx
(RY\{x})| â‰¤|Rx| âˆ’Î´, for each x âˆˆY,
f ) |Y| â‰¥âŒˆk
r âŒ‰
â‡’
{Z âˆˆZ : Z âŠ‡RY} = 1Z = E.
Conditions (i) and (ii) in the structure theorem above for Singleton-optimal
matroids show that each repair set Rx must correspond to a uniform matroid with |Rx|
elements and rank |Rx| âˆ’(Î´ âˆ’1). Further, condition (iii) gives structural properties
on nontrivial unions of repair sets. This can be viewed as structural conditions on
how nontrivial unions of uniform matroids need to be glued together in a Singleton-
optimal matroid, with the uniform matroids corresponding to repair sets. For
Singleton-optimal linear (n, k, d,r, Î´)a-LRCs, the property of the repair sets being
uniformmatroidscorrespondstotherepairsetsbeinglinear[|Rx|, |Rx| âˆ’(Î´ âˆ’1), Î´]-
MDS codes. We remark that structure theorems whenr|k for Singleton-optimal linear
(n, k, d,r, Î´)a-LRCs and the special case of (n, k, d,r, Î´ = 2)a-LRCs are given in
[13, 18], respectively. These theorems show that the local repair sets correspond to
linear [r + Î´ âˆ’1,r, Î´]-MDS codes that are mutually disjoint. This result is a special
case of Theorem 6.
Example 10 By Theorem 1, the poset with its associated subsets of E = [16] and
rank of these subsets in the ï¬gure below deï¬nes the set of cyclic ï¬‚ats Z and the rank
function restricted to the sets in Z of a matroid M on E. From Theorem 4, we obtain
that (n, k, d) = (16, 7, 6) for the matroid M. Choosing repair sets R1 = Â· Â· Â· = R5 =
X1, R6 = Â· Â· Â· = R9 = X2, R10 = Â· Â· Â· = R13 = X3 and R14 = Â· Â· Â· = R16 = X4, we
obtain that M is an (n = 16, k = 7, d = 6,r = 3, Î´ = 3)a-matroid. It can easily be
checked that all the properties (i)â€“(iii) are satisï¬ed by the matroid M and the chosen
repair sets. Further, we also have that M is Singleton-optimal as
n âˆ’k + 1 âˆ’
	k
r

âˆ’1

(Î´ âˆ’1) = 6 = d.

406
R. Freij-Hollanti et al.
4
Code Constructions
4.1
Constructions of (n, k, d, r, Î´)a-Matroids via Cyclic
Flats
In [47], a construction of a broad class of linear (n, k, d,r, Î´)a-LRCs is given via
matroid theory. This is generalised in [10, 46] to account for availability and hierar-
chy, respectively.
A construction of (n, k, d,r, Î´)a-matroids via cyclic ï¬‚ats:
Let F1, . . . , Fm be a collection of ï¬nite sets and E = m
i=1 Fi. Assign a function
Ï : {Fi} âˆª{E} â†’Z satisfying
(i) 0 < Ï(Fi) < |Fi| for i âˆˆ[m],
(ii) Ï(Fi) < Ï(E) for i âˆˆ[m],
(iii) Ï(E) â‰¤|E| âˆ’
iâˆˆ[m] Î·(Fi),
(iv) j âˆˆ[m] â‡’|F[m]\{ j} âˆ©Fj| < Ï(Fj),
(8)
where
Î·(Fi) = |Fi| âˆ’Ï(Fi) for i âˆˆ[m] and
FI =

iâˆˆI
Fi for I âŠ†[m].

Matroid Theory and Storage Codes: Bounds and Constructions
407
Extend Ï to {FI} â†’Z by
Ï(FI) = min

|FI| âˆ’

iâˆˆI
Î·(Fi), Ï(E)

(9)
and let Z be the following collection of subsets of E,
Z = {FI : I âŠ†[m] and Ï(FI) < Ï(E)} âˆªE.
(10)
Theorem 7 ([47] Construction of (n, k, d,r, Î´)a-matroids) Let F1, . . . , Fm, be a
collection of ï¬nite sets with E = m
i=1 Fi and Ï : {Fi}iâˆˆ[m] â†’Z satisfying (8).
Then the pair (Ï, Z ), deï¬ned in (9) and (10), deï¬nes a (n, k, d,r, Î´)a-matroid
M(F1, . . . , Fm; Ï) on E for which Z is the collection of cyclic ï¬‚ats, Ï is the rank
function restricted to the cyclic ï¬‚ats in Z , F1, . . . , Fm, are the repair sets and
(i) n = |E|,
(ii) k = Ï(E),
(iii) d = n âˆ’k + 1 âˆ’max{
iâˆˆI Î·(Fi) : FI âˆˆZ \ E},
(iv) Î´ = 1 + min{Î·(Fi) : i âˆˆ[m]},
(v) r = max{Ï(Fi) : i âˆˆm}.
That M(F1, . . . , Fm; Ï) deï¬nes a matroid follows from a proof given in [47] that
the pair (Ï, Z ) satisï¬es the axiomatic scheme of matroids via cyclic ï¬‚ats and their
ranks stated in Theorem 1. The correctness of the parameters (n, k, d,r, Î´) when
F1, . . . , Fm are considered as the repair sets also follows from [47].
We remark, that the matroids constructed in Theorem 7 satisfy, for all unions of
repair sets FI with Ï(FI) < Ï(E), that
(i) FI is a cyclic ï¬‚at,
(ii) the nullity Î·(FI) of FI is as small as possible.
(11)
Properties (i) and (ii) above are trivially seen to be fulï¬lled by uniform matroids Uk,n,
where Z = {âˆ…, E}, Ï(âˆ…) = 0 and Ï(E) = k. However, uniform matroids cannot be
constructed by Theorem 7, since all constructed matroids by this theorem have r < k
and uniform matroids have r = k. Though both uniform matroids and the matroids
constructed in Theorem 7 satisfy properties (i) and (ii) in (11), we will consider them
in terms of a class of matroids M , deï¬ned as follows:
M = {M = M(F1, . . . , Fm; Ï) : M is constructed in Theorem 7} âˆª{Uk,n}. (12)
By the structure Theorem 6, the properties (i) and (ii) in (11) are necessary (but not
sufï¬cient) for Singleton-optimal (n, k, d,r, Î´)a-matroids.
Example 11 Let
E = [12]
and
let
F1 = {1, . . . , 4},
F2 = {3, . . . , 6},
F3 =
{7, . . . , 10}, F4 = {10, . . . , 12} with Ï(F1) = Ï(F2) = Ï(F3) = 3, Ï(F4) = 2, and

408
R. Freij-Hollanti et al.
Ï(E) = 7. Then, by Theorem 7, M(F1, . . . , Fm; Ï) is an (n, k, d,r, Î´)a-matroid over
E with (n, k, d,r, Î´) = (12, 7, 3, 3, 2) and the following lattice of cyclic ï¬‚ats and
their ranks.
Further, the matroid is not Singleton-optimal since
d = 3 < n âˆ’k + 1 âˆ’
	k
r

âˆ’1

(Î´ âˆ’1) = 4.
4.2
A Matroidal Construction of Linear all Symbol LRCs
As will be explained below, all matroids constructed in Theorem 6 are contained
in a class of matroids called gammoids. These matroids are linear, which especially
implies that all (n, k, d,r, Î´)a-matroids constructed by Theorem 6 are matroids asso-
ciated with linear (n, k, d,r, Î´)a-LRCs.
Deï¬nition 17 Any (ï¬nite) directed graph Î“ = (V, D) and vertex subsets E, T âŠ†V
deï¬ne a gammoid M(Î“, E, T ), where M(Î“, E, T ) = (I , E) is a the matroid with
I = {X âŠ†E : âˆƒa set of |X| vertex-disjoint paths from X to T }.

Matroid Theory and Storage Codes: Bounds and Constructions
409
Theorem 8 ([20]) Every gammoid M(Î“, E, T ) is Fq-linear for all prime powers
q â‰¥2|E|.
In [47], it is proven that the matroids constructed in Theorem 7 are indeed gam-
moids, and hence representable. This is achieved by explicitly constructing a triple
(Î“, E, T ) whose associated matroid is M(F1, . . . , Fm; Ï). The details of the con-
struction are left to Theorem 14 in the appendix. The essence of the argument is to
construct a graph of depth three, whose sources correspond to the ground set of the
matroid, and whose middle layer corresponds to the repair sets, with multiplicities
to reï¬‚ect the ranks of the repair sets.
Example 12 ThefollowingdirectedgraphÎ“ = (V = E âˆªH âˆªT, D)isconstructed
in Theorem 14 from the matroid M(F1, . . . , Fm, E; k; Ï) given in Example 11.
In general it is extremely hard to prove that a matroid is linear (or the converse).
There is no known deterministic algorithm to solve this problem in general. However,
by combining the results given in Theorems 7â€“14, we obtain the following result.
Theorem 9 ([47] A matroidal construction of (n, k, d,r, Î´)a-LRCs) For every
(n, k, d,r, Î´)a-matroid M(F1, . . . , Fm, E; k; Ï) given by Theorem 7 and every prime
power q â‰¥2|E| there is a linear (n, k, d,r, Î´)a-LRC C over Fq with repair sets
F1, . . . , Fm such that M(F1, . . . , Fm, E; k; Ï) = MC.
Example 13 The (12, 7, 3, 3, 2)a-matroid M(F1, . . . , Fm, E; k; Ï) given in Exam-
ple 11 equals the matroid MC = M[G], where G equals the following matrix over
F5:
G =
1 2 3 4 5 6 7 8 9 10 11 12
1 1 0 0 0 0 0 0 0 0
1
3
0 2 1 0 0 1 0 0 0 0
1
3
0 3 0 1 0 3 0 0 0 0
1
3
0 0 0 0 1 2 0 0 0 0
1
3
0 0 0 0 0 0 1 0 1 0
1
3
0 0 0 0 0 0 0 1 2 0
1
3
0 0 0 0 0 0 0 0 3 1
1
1
Hence, the code C generated by the rows of G is a linear (12, 7, 3, 3, 2)-LRC
over F5 with repair sets F1 = {1, 2, 3, 4}, F2 = {3, 4, 5, 6}, F1 = {7, 8, 9, 10} and
F1 = {10, 11, 12}.

410
R. Freij-Hollanti et al.
Note that the bound q â‰¥2|E| given in Theorem 9 is a very rough bound. There
are many matroids M(F1, . . . , Fm, E; k; Ï) = MC for linear LRCs C over Fq where
q â‰ª2|E|. In Example 13, for instance, we constructed a code over F5, while the
ï¬eld size predicted by Theorem 9 was 212 = 4096 â‰«5. To construct an explicit
linear (n, k, d,r, Î´)a-LRC from a matroid M(F1, . . . , Fm, E; k; Ï), one can use the
directed graph representation of the matroid given in Theorem 14, together with
results on how to construct a generator matrix from this representation [20].
As we saw earlier, it is known that there exists a Singleton-optimal linear
(n, k, d,r, Î´)i-LRC for all parameters (n, k,r, Î´) âˆˆP(n, k,r, Î´) (cf. (7) for a def-
inition of P(n, k,r, Î´)). Further, it is also known that if r = k, then all Singleton-
optimal linear LRCs are linear [n, k, n âˆ’k + 1]-MDS codes. In [38] existence and
nonexistence of Singleton-optimal linear (n, k, d,r, Î´)a-LRCs were examined. The
parameter regions for existence given in [38] were both obtained and extended in
[47] by the construction of linear LRCs via matroid theory given in Theorem 9.
Hence, the results in [47] about nonexistence and existence of Singleton-optimal
linear (n, k, d,r, Î´)a-LRCs settled large portions of the parameter regions left open
in [38] leaving open only a minor subregion. Some improvements of the results in
[38] were also given for Î´ = 2 in [45] via integer programming techniques.
For (n, k,r, Î´) âˆˆP(n, k,r, Î´) it is also very natural to ask what is the maximal
value of d for which there exist an (n, k, d,r, Î´)a-matroid or a linear (n, k, d,r, Î´)a-
LRC. We denote this maximal value by dmax(n, k,r, Î´). In [47] it was proven that
dmax(n, k,r, Î´) â‰¥n âˆ’k + 1 âˆ’
	k
r

(Î´ âˆ’1)
for linear LRCs. For matroids, this result is straightforward, as a matroid with
d = n âˆ’k + 1 âˆ’
 k
r

(Î´ âˆ’1) can be constructed as a truncation of the direct sum of
âŒˆ
n
r+Î´âˆ’1âŒ‰uniform matroids of size si â‰¤r + Î´ âˆ’1 and rank si âˆ’Î´ + 1 â‰¤r. As repre-
sentability (over some ï¬eld) is preserved under direct sums and truncation, the result
follows for linear LRCs. However, with this straightforward argument, and with the
bound on the ï¬eld size of truncated matroids from [17], the ï¬eld size required could
be as large as
(r + Î´ âˆ’1) Â·
rÂ·âŒˆ
n
r+Î´âˆ’1âŒ‰

i=k
n
i

.
Signiï¬cant work is needed in order to bound the ï¬eld size even in this special case.
This result was improved in [47] and further in [29]. Also, the parameter region
of Singleton-optimal linear (n, k, d,r, Î´)-LRCs was also extended in [29]. The exis-
tence of Singleton-optimal linear LRCs obtained by the matroidal construction
described here depends mainly on the relation between the parameters a and b where
a = âŒˆk
r âŒ‰r âˆ’k and b = âŒˆ
n
r+Î´âˆ’1âŒ‰(r + Î´ âˆ’1) âˆ’n. Thus, we can easily get Singleton-
optimal linear LRCs for all possible coding rates.

Matroid Theory and Storage Codes: Bounds and Constructions
411
4.3
Random Codes
An alternative way to design (n, k, d,r, Î´)-LRCs with prescribed parameters is by
exploiting the fact that independence is a generic property for r- and k-tuples of
vectors over large ï¬elds. This allows us to use randomness to generate (n, k, d,r, Î´)-
LRCs in a straightforward way, once the matroid structure of the code is prescribed.
This is the key element in [8]. As opposed to in the gammoid construction from the
last section, we will now consider the ï¬eld size q to be ï¬xed but large. Indeed, a
sufï¬ciently large ï¬eld will be Fq with
q > (rÎ´)4rr
n + (rÎ´)(râˆ’1)4r
k âˆ’1

.
For given (n, k,r, Î´), we will construct (n, k, d,r, Î´)-LRCs where
d â‰¥n âˆ’k + 1 âˆ’
	k
r

(Î´ âˆ’1).
Comparing this to the generalised Singleton bound (5), we notice that the codes we
construct are â€œalmost Singleton-optimalâ€.
The underlying matroid will again be a truncation of
âŒˆ
n
r+Î´âˆ’1 âŒ‰

i=1
U siâˆ’Î´âˆ’1
si
.
However, rather than ï¬rst representing this direct sum, which has rank

i
(si âˆ’Î´ + 1) = n âˆ’âŒˆ
n
r + Î´ âˆ’1âŒ‰(Î´ âˆ’1),
we will immediately represent its truncation as an n Ã— k matrix. The random con-
struction proceeds as follows. Divide the columns [n] into locality sets Si of size si.
For each Si, we ï¬rst generate the ri = si âˆ’Î´ + 1 ï¬rst columns uniformly at random
from the ambient space Fk. This gives us an ri Ã— k-matrix Gi. After this, we draw
Î´ âˆ’1 vectors from Fri, and premultiply these by Gi. The resulting ri + Î´ âˆ’1 = si
vectors will be in the linear span of the ri ï¬rst vectors, and so have rank â‰¤ri as a
point conï¬guration in Fk. We arrange the si vectors into a matrix Gâ€²
i of rank â‰¤ri in
FsiÃ—k. Let Ai be the event that all ri-tuples of columns in Gi are linearly independent.
It is easy to see that, if the ï¬eld size grows to inï¬nity, the probability of Ai tends to
one.

412
R. Freij-Hollanti et al.
Juxtaposing the matrices Gâ€²
i for i = 1, . . . , âŒˆ
n
r+Î´âˆ’1âŒ‰, we obtain a generator matrix
G for a code of length n. Let B be the event that G has full rank. Again, assuming the
ï¬eld size is large enough, the probability of B can be arbitrarily close to one. Now, the
randommatrix G generatesan(n, k, d,r, Î´)-LRCifalltheevents A1, . . . , AâŒˆ
n
r+Î´âˆ’1 âŒ‰, B
simultaneously occur. A simple ï¬rst moment estimate shows that, if
q > (rÎ´)r4r n + (rÎ´)(râˆ’1)4r
k âˆ’1

,
then the probability of this is positive, so there exists an (n, k, d,r, Î´)-LRC.
4.4
Constructing LRCs as Evaluation Codes
As suggested in the previous sections, there are several assumptions that can be made
in order to give more explicit code constructions for optimal LRCs. Next, we will
follow [39, 40] in assuming that n is divisible by r + Î´ âˆ’1 and k is divisible by r.
Then, an optimal LRC with d = n âˆ’k âˆ’( k
r âˆ’1)(Î´ âˆ’1) + 1 exists for any choice
of k. We will also assume that n = q is a prime power, although this assumption can
easily be removed at the price of a more technical description of the code.
We will construct a Singleton-optimal code in this case as an evaluation code, gen-
eralising the construction of MDS codes as Reed-Solomon codes. The main philoso-
phy goes back to [40], but due to a technical obstacle, [40] still required exponential
ï¬eld size. This technicality was overcome by the construction in [39], which we will
present next. Evaluation codes have a multitude of favourable properties, not least
that the ï¬eld size can often be taken to be much smaller than in naÃ¯ve random code
constructions. Moreover, the multiplicative structure used for designing evaluation
codes can also be exploited when one needs to do computations with the codes in
question.
Let A be a subgroup of Fq of size r + Î´ âˆ’1 and let g = 
iâˆˆA(x âˆ’i) be the
polynomial of degree r + Î´ âˆ’1 that vanishes on A. We will construct a storage code
whose nodes are the elements of Fq and whose locality sets are the cosets of A.
Thus, there are
n
r+Î´âˆ’1 locality sets, each of size r + Î´ âˆ’1. The codewords will be
the evaluations over Fq of polynomials of a certain form. As the rank of the code
that we are designing is k = r Â· k
r , we can write the messages as a r Ã— k
r matrix
a =
â›
âœâ
a0,0
Â· Â· Â·
arâˆ’1,0
...
...
...
a0, k
r âˆ’1 Â· Â· Â· arâˆ’1, k
r âˆ’1
â
âŸâ 

Matroid Theory and Storage Codes: Bounds and Constructions
413
over Fq. Now consider the polynomial function
fa =

1 g(x) g(x)2 . . . g(x)
k
r âˆ’1
 
Â·
â›
âœâ
a0,0
Â· Â· Â·
arâˆ’1,0
...
...
...
a0, k
r âˆ’1 Â· Â· Â· arâˆ’1, k
r âˆ’1
â
âŸâ Â·
â›
âœâœâœâœâœâ
1
x
x2
...
xrâˆ’1
â
âŸâŸâŸâŸâŸâ 
.
Consider the code
C = { fa(x) : x âˆˆFq, a âˆˆF
rÃ— k
r
q
}.
By design, fa has degree
deg fa â‰¤(r + Î´ âˆ’1)
k
r âˆ’1

+ r âˆ’1 = k âˆ’1 + (Î´ âˆ’1)
k
r âˆ’1

,
and can therefore be computed for every point in Fq by evaluation on any k + (Î´ âˆ’
1)( k
r âˆ’1) points. Therefore, the code C protects against
d âˆ’1 = n âˆ’k âˆ’(Î´ âˆ’1)
k
r âˆ’1

+ 1
errors. It remains to see that it has locality (r, Î´).
To this end, note that the row vector

1 g(x) g(x)2 . . . g(x)
k
r âˆ’1
 
Â·
â›
âœâ
a0,0
Â· Â· Â·
arâˆ’1,0
...
...
...
a0, k
r âˆ’1 Â· Â· Â· arâˆ’1, k
r âˆ’1
â
âŸâ 
of polynomials is constant over the subgroup A âŠ†Fq and thus on all of its cosets by
construction of g. It follows that when restricted to any such coset, the function fa is
a polynomial of degree â‰¤r âˆ’1, and so can be extrapolated to all points in the coset
from any r such evaluation points. This proves the (r, Î´)-locality.
As discussed, this construction depends on a collection of assumptions on the
divisibility of parameters that are needed for the rather rigid algebraic structures to
work. Some of these assumptions can be relaxed, using more elaborate evaluation
codes, such as algebraic geometry codes over curves and surfaces [2, 3]. While
this ï¬eld of research is still very much developing, it seems that the rigidity of the
algebraic machinery makes it less suitable for generalisations of the LRC concept,
for example when different nodes are allowed to have different localities.

414
R. Freij-Hollanti et al.
5
Beyond Linear Storage Codes
In this section we will introduce the notion of hierarchical codes, which are natural
generalisations of locally repairable codes. After this, we will brieï¬‚y describe the
connection between (n, k, d,r, Î´, t)-LRCs and polymatroids given in [46].
5.1
Hierarchical Codes
Deï¬nition 18 Let h â‰¥1 be an integer, and let
(n, k, d, t) = [(n1, k1, d1, t1), . . . , (nh, kh, dh, th)]
be a h-tuple of integer 4-tuples, where ki â‰¥1, ni, di â‰¥2, and ti â‰¥1 for 1 â‰¤i â‰¤h.
Then, a coordinate x of a linear [n, k, d] = [n0, k0, d0]-LRC C indexed by E has h-
level hierarchical availability (n, k, d, t) if there are t1 coordinate sets X1, . . . , Xt1 âŠ†
E such that
(i) x âˆˆXi for i âˆˆ[t1],
(ii) i, j âˆˆ[t1], i Ì¸= j â‡’Xi âˆ©X j = {x},
(iii) nXi â‰¤n1, kXi = k1 and dXi â‰¥d1 for the punctured
[nXi, kXi, dXi]-code CXi , for i âˆˆ[t1],
(iv) for i âˆˆ[t1], x has (h âˆ’1)-level hierarchical availa-
bility [(n2, k2, d2, t2), . . . , (nh, kh, dh, th)] in CXi.
The code C above as well as all the related subcodes CXi should be non-degenerate.
For consistency of the deï¬nition, we say that any symbol in a non-degenerate storage
code has 0-level hierarchical availability.
Example 14 Let C be the code generated by the matrix G in Example 1 and let
x = 2. Then x has 2-level hierarchical availability
(n, k, d, t) = [(6, 3, 3, 1), (3, 2, 2, 2)] .
This follows from Example 2 where CY1 implies the (6, 3, 3, 1)-availability, and the
(3, 2, 2, 2)-availability is implied by CX1 and CX2.
The most general Singleton bound for matroids with hierarchy in the case t = 1
are the following given in [10, 32]:
di(M) â‰¤ni âˆ’ki + 1 âˆ’

j>i
(d j âˆ’d j+1)
	 ki
k j

âˆ’1

,
where we say dh+1 = 1.

Matroid Theory and Storage Codes: Bounds and Constructions
415
5.2
General Codes from Polymatroids
Deï¬nition 19 Let E be a ï¬nite set. A pair P = (Ï, E) is a (ï¬nite) polymatroid on
E with a set function Ï : 2E â†’R if Ï satisï¬es the following three conditions for all
X, Y âŠ†E:
(R1) Ï(âˆ…) = 0 ,
(R2) X âŠ†Y â‡’Ï(X) â‰¤Ï(Y) ,
(R3) Ï(X) + Ï(Y) â‰¥Ï(X âˆªY) + Ï(X âˆ©Y) .
Note that a matroid is a polymatroid which additionally satisï¬es the following
two conditions for all X âŠ†E:
(R4) Ï(X) âˆˆZ ,
(R5) Ï(X) â‰¤|X| .
Using the joint entropy and a result given in [11] one can associate the following
polymatroid to every code.
Deï¬nition 20 Let C be an (n, k)-code over some alphabet A of size s. Then PC =
(ÏC, [n]) is the polymatroid on [n] with the set function ÏC : 2[n] â†’R where
ÏC(X) =

zXâˆˆCX
|{c âˆˆC : cX = zX}|
|C|
logs

|C|
|{c âˆˆC : cX = zX}|

and ÏC(âˆ…) = 0.
We remark that for linear codes MC = PC. Using the above deï¬nition of PC, one
can now prove the following useful properties.
Proposition 8 LetC bean(n, k)-codeover A with|A| = s.Thenforthepolymatroid
PC = (ÏC, [n]) and any subsets X, Y âŠ†[n],
(i) PC(X) â‰¤|X|,
(ii) |CXâˆªY| > |CX| â‡â‡’ÏC(X âˆªY) > ÏC(X),
(iii) |C| = sÏC([n]),
(iv) |C|/|An| = sÏC([n])âˆ’n.
We remark that, even though |C| = sÏC([n]) for nonlinear codes and |CX| = sÏC(X)
for all X for linear codes, it is not true in general that |CX| = sÏC(X) for X âŠŠ[n]
for nonlinear codes. This stems from the fact that, for non-linear codes, the uniform
distribution over the code does not necessarily map to the uniform distribution under
coordinate projection.
After scaling the rank function of a ï¬nite polymatroid P = (Ï, E) by a constant
c such that cÏ(X) â‰¤|X| for all X âŠ†E, we obtain a polymatroid satisfying axiom
(R5). We will assume that such a scaling has been performed, so that all polymatroids
satisfy axiom (R5).

416
R. Freij-Hollanti et al.
We are now ready to deï¬ne a cyclic ï¬‚at of a polymatroid P = (Ï, E), namely
X âŠ†E is a cyclic ï¬‚at if
Ï(X âˆª{e}) > Ï(X) for all e âˆˆE \ X and Ï(X) âˆ’Ï(X \ {x}) < 1 for all x âˆˆX.
Let P = (Ï, E) be a polymatroid and X âŠ†E. The restriction of P to X is the
polymatroid P|X = (Ï|X, X) where Ï|X(Y) = Ï(Y) for Y âŠ†X. We can now deï¬ne
the distance of P|X as
d(P|X) = min{|Y| : Y âŠ†X, Ï|X(X \ Y) < Ï|X(X)}.
Let Z denote the family of cyclic ï¬‚ats of the polymatroid P. Assuming that
E âˆˆZ , we can deï¬ne the parameters n, k, d of P via the cyclic ï¬‚ats and their ranks,
namely
n = |E|, k = Ï(E) and d = âŒŠn âˆ’k + 1 âˆ’max{|X| âˆ’Ï(X) : X âˆˆZ \ E}âŒ‹.
The deï¬nitions of (n, k, d,r, Î´, t)i and (n, k, d,r, Î´, t)a-polymatroids are carried
over directly from Deï¬nition 16. In addition, the parameters (n, k, d,r, Î´, t)i and
(n, k, d,r, Î´, t)a of a LRC C are the same as the corresponding parameters for PC.
Using the cyclic ï¬‚ats and similar methods as for matroids, Singleton-type bounds
can be proven for polymatroids in general, which then imply bounds on all objects
related to polymatroids, e.g., matroids, linear and nonlinear LRCs, and hypergraphs.
This is the content of the next section.
5.3
Singleton-Type Bounds for Polymatroids and General
LRCs
It is not clear whether the Singleton-type bounds given for linear LRCs in (2)â€“(6)
also hold for general LRCs â€” in general the upper bound on d might have to be
larger. As we will describe brieï¬‚y in Sect.5, any general LRC can be associated with a
polymatroid that captures the key properties of the LRC. Using this connection we are
able to deï¬ne the (n, k, d,r, Î´, t)-parameters and information-symbol, systematic-
symbol, and all-symbol locality sets for polymatroids in general.
The class of polymatroids is much bigger than the class of the polymatroids arising
from general LRCs. Hence, it is also not clear whether the Singleton-type bounds
given in (2)â€“(6) also hold for polymatroids in general. However, from [46], we
obtain a Singleton-type bound for polymatroids in Theorem 10 below. This theorem
shows that all the Singleton-type bounds given in (2)â€“(6) are polymatroid properties.
Further, the polymatroid result also extends all these bounds by including all the
parameters (n, k, d,r, Î´, t) at the same time.

Matroid Theory and Storage Codes: Bounds and Constructions
417
The methods used to prove the Singleton-type bound given for polymatroids
in Theorem 10 are similar to those used for proving the Singleton-type bound for
matroids in Theorem 5. Especially, the notion of cyclic ï¬‚ats is generalised to poly-
matroids and used as the key tool in the proof. However, some obstacles occur since
we are dealing with real-valued rank functions in the case of polymatroids instead
of integer-valued rank functions, which was the case for matroids. As a direct con-
sequence of Theorem 10, the Singleton-type bounds given in (2)â€“(6) are valid for all
objects associated to polymatroids.
Theorem 10 ([46] Singleton-type bound for polymatroids) Let P = (Ï, E) be an
information-set (n, k, d,r, Î´, t)i-polymatroid. Then
d â‰¤n âˆ’âŒˆkâŒ‰+ 1 âˆ’
	t(âŒˆkâŒ‰âˆ’1) + 1
t(r âˆ’1) + 1

âˆ’1

(Î´ âˆ’1).
(13)
Theorem 10 is stated for information-symbol locality. This implies that the bound
(13) is also valid for systematic-symbol and all-symbol locality. Hence, as a direct
corollary, the bounds (2)â€“(13) hold for information-symbol, systematic-symbol, and
all-symbol locality for all objects associated to polymatroids, e.g., entropy functions,
general LRCs, hypergraphs, matroids, linear LRCs, graphs and many more. If we
restrict to systematic linear codes, then the bound also holds for PIR codes [9, Def-
inition 4]. The connection is not as straightforward in the nonlinear case, since the
deï¬nitions of a repair group are then slightly different for LRCs (as deï¬ned here)
and PIR codes, while coinciding in the linear case.
The bound (4), for all-symbol LRCs (as subsets of size |B|K of BÎ±n, where B
is a ï¬nite set, A = BÎ± is the alphabet, and Î± and K are integers), follows from a
result given in [27]. The bound (5), for all-symbol LRCs (as a linear subspace of
FÎ±n
q with the alphabet A = FÎ±
q), is given in [34]. This result is slightly improved for
information-symbol locality in [18]. The bound (6), for (n, k, d,r, t)s-LRCs where
k is a positive integer, follows from a result given in [31]. The following bound for
(n, k, d,r, t)a-LRCs with integral k was given in [41],
d â‰¤n âˆ’k + 1 âˆ’
t
i=1
!k âˆ’1
ri
"
.
One parameter which has not been included above is the alphabet size. Small
alphabet sizes are important in many applications because of implementation and
efï¬ciency reasons. The bound (14) below takes the alphabet size into account, but is
only inductively formulated. Before stating this bound we introduce the following
notation:
k(q)
opt(n, d) = max{k : C is an (n, k, d)-code over an alphabet of size q}.

418
R. Freij-Hollanti et al.
By [6], an all-symbol (n, k, d,r)-LRC over a ï¬nite alphabet A of size q satisï¬es
k â‰¤min
sâˆˆZ+(sr + k(q)
opt(n âˆ’s(r + 1), d)).
(14)
It is a hard open problem in classical coding theory to obtain a value for the parameter
k(s)
opt(n, d) for linear codes. This problem seems to be even harder for codes in general.
However,byusingotherknownbounds,suchasthePlotkinboundorGreismerbound,
it is possible to give an explicit value for k(s)
opt(n, d) for some classes of parameters
(s, n, d). This has been done for example in [33].
We remark that when considering nonlinear LRCs, some extra care has to be taken
in terms of how to deï¬ne the concepts associated with the LRCs. Two equivalent
deï¬nitions in the linear case may differ in the nonlinear case. In this chapter, we
have chosen to consider Î´ as a parameter for the local distance of the repair sets, i.e.,
any node in a repair set R can be repaired by any other |R| âˆ’Î´ + 1 nodes of R. The
condition used in [6, 27, 31, 41] is for Î´ = 2 only assuming that a speciï¬c node in
a repair set R can be repaired by the rest of the nodes of R. It is not assumed that
any node in R can be repaired by the other nodes of R, i.e., that the local distance is
2. A Singleton bound using the weaker condition of guaranteeing only repair of one
node in each repair set implies directly that the same upper bound on d is true for
the case with local distance 2.
6
Conclusions and Further Research
We have shown how viewing storage codes from a matroidal perspective helps
our understanding of local repairability, both for constructions and for fundamental
bounds. However, many central problems about linear LRCs boil down to notoriously
hard representability problems in matroid theory.
A famous conjecture, with several consequences for many mathematical objects,
is the so called MDS-conjecture. This conjecture states that, for a given ï¬nite ï¬eld
Fq and a given k, every [n, k, d]-MDS code over Fq has n â‰¤q + 1, unless in some
special cases. Currently, theconjectureis knowntoholdonlyifq is aprime[1]. Linear
Singleton-optimal LRCs may be seen as a generalisation of linear MDS codes. An
interesting problem would therefore be to consider an upper bound on n for linear
Singleton-optimal LRCs over a certain ï¬eld size q with ï¬xed parameters (k,r, Î´, t).
In this setting, a sufï¬ciently good upper bound on n would be a good result.
Instead of ï¬xing the Singleton-optimality and trying to optimise the ï¬eld size, we
could also ï¬x the ï¬eld Fq, and try to optimise the locality parameters. This would
give us bounds on the form
d â‰¤n âˆ’k + 1 âˆ’
	k
r

âˆ’1

(Î´ âˆ’1) âˆ’p(q, n, k,r, Î´),

Matroid Theory and Storage Codes: Bounds and Constructions
419
wherethedependenceontheï¬eldsizeq isisolatedtoaâ€œpenaltyâ€term p(q, n, k,r, Î´).
Partial results in this direction are given by the Cadambeâ€“Mazumdar bound [6], and
LRC versions of the Griesmer and Plotkin bounds [33]. However, the optimality of
these bounds is only known for certain ranges of parameters. Further research in this
direction is deï¬nitely needed, but seems to lead away from the most obvious uses of
matroid theory.
Finally, it would be interesting to characterise all Singleton-optimal LRCs up to
matroid isomorphism. The constructions discussed in this paper appear to be rather
rigid, and unique up to shifting a few â€œslackâ€ elements between different locality
sets. However, it appears to be difï¬cult to prove that all Singleton-optimal matroids
must have this form. Once a complete characterisation of Singleton-optimal matroids
has been obtained, this could also be taken as a starting point for possibly ï¬nding
Singleton-optimal nonlinear codes in the parameter regimes where no Singleton-
optimal linear codes exist.
Appendix: More About Matroid Theory
A matroid realisation of an F-linear matroid M has two geometric interpretations.
Firstly, we may think of a matrix representing M as a collection of n column vectors
in Fk. As the matroid structure is invariant under row operations, or in other words
under change of basis in Fk, we tend to think of M as a conï¬guration of n points in
abstract projective k-space.
The second interpretation comes from studying the row space of the matrix, as
an embedding of Fk into Fn. Row operations correspond to a change of basis in
Fk, and hence every matroid representation can be thought of as a k-dimensional
subspace of Fn. In other words, a matroid representation is a point in the Grassman-
nian Gr(n, k; F), and Gr(n, k; F) has a stratiï¬cation as a union of realisation spaces
R(M), where M ranges over all F-representable matroids of size n and rank k. This
perspective allows a matroidal perspective also on the subspace codes discussed in
chaptersâ€œCodes Endowed with the Rank Metricâ€â€“â€œGeneralizing Subspace Codes to
Flag Codes Using Group Actionsâ€, where the codewords themselves are matroid
representations. However, so far this perspective has not brought any new insights
to the topic.
Another instance where matroids appear naturally in mathematics is graph theory.
Let Î“ be a ï¬nite graph with edge set E. We obtain a matroid MÎ“ = (I , E), where
I âŠ†E is independent if the subgraph Î“I âŠ†Î“ induced on I âŠ†E is a forest, i.e.,
has no cycles. A matroid that is isomorphic to MÎ“ for some graph Î“ is said to be a
graphical matroid.
Example 15 The matrix G and the graph Î“ given below generate the same matroid,
regardless of the ï¬eld over which G is deï¬ned.

420
R. Freij-Hollanti et al.
Some examples of independent sets in G and Î“ are {3, 4, 6}, {1, 2, 3, 5}, {2, 3, 4, 6}.
The set X = {5, 6, 7} is dependent in MÎ“ as these edges form a cycle, and it is
dependent in MG as the submatrix
G(X) =
5
6
7
0
1
1
0
1
1
âˆ’1 âˆ’1 0
1
0 âˆ’1
has linearly dependent columns.
Indeed, graphical matroids are representable over any ï¬eld F. To see this, for a
graph Î“ with edge set E, we will construct a matrix G(Î“ ) over F with column set
E as follows. Choose an arbitrary spanning forest T âŠ†E in Î“ , and index the rows
of G(Î“ ) by T . Thus G(Î“ ) is a T Ã— E-matrix. Choose an arbitrary orientation for
each edge in the graph. For e âˆˆT âŠ†E and uv âˆˆE, the entry in position (e, {uv})
is 1 (respectively âˆ’1) if e is traversed forward (respectively backward) in the unique
path from u to v in the spanning forest T . In particular, the submatrix G(Î“ )(T ) is
an identity matrix. It is straightforward to check that the independent sets in G(Î“ )
are exactly the noncyclic sets in Î“ .
Example 16 The matrix G in Example 15 is G(Î“ ) where Î“ is the graph in the same
example, and the spanning forest T is chosen to be {1, 2, 3, 4}.
The restriction to X âŠ†E of a graphical matroid MÎ“ is obtained by the subgraph
of Î“ containing precisely the edges in X.
A third example of matroids occurring naturally in mathematics are algebraic
matroids [22]. These are associated to ï¬eld extensions F : K together with a ï¬nite
point sets E âŠ†K, where the independent sets are those I âŠ†E that are algebraically
independent over F. In particular, elements that are algebraic over F have rank zero,
and in general Ï(I) is the transcendence degree of the ï¬eld extension F(I) : F.
It is rather easy to see that every F-linear matroid is also algebraic over F. Indeed,
let X1, . . . , Xk be indeterminates, and let
g : Fk â†’F(X1, . . . , Xk)

Matroid Theory and Storage Codes: Bounds and Constructions
421
Fig. 2 The Vamos matroid
of size 8 and rank 4, which is
not algebraically
representable
be given by ei â†’Xi for i = 1, . . . , k. Then J âŠ†E is linearly independent over
F if and only if {g( j) : j âˆˆJ} is algebraically independent over F. Over ï¬elds of
characteristic zero the converse also holds, so that all algebraic matroids have a linear
representation. However, in positive characteristic there exist algebraic matroids that
are not linearly representable. For example, the non-Pappus matroid of Example 4
is algebraically representable over F4, although it is not linearly representable over
any ï¬eld [21]. The smallest example of a matroid that is not algebraic over any ï¬eld
is the Vamos matroid, in Fig.2 [15].
Deï¬nition 21 The dual of M = (Ï, E) is Mâˆ—= (Ïâˆ—, E), where
Ïâˆ—(X) = |X| + Ï(E \ X) âˆ’Ï(E).
The deï¬nition of the dual matroid lies in the heart of matroid theory, and has pro-
found interpretations. In geometric terms, let M be represented by a k-dimensional
subspace V of Fn. Then, the matroid dual Mâˆ—is represented by the orthogonal com-
plement V âŠ¥âŠ†Fn. Surprisingly and seemingly unrelatedly, if Î“ is a planar graph
and M = MÎ“ is a graphical matroid, then Mâˆ—= M Â¯Î“ , where Â¯Î“ is the planar dual
of Î“ . Moreover, the dual Mâˆ—
Î“ of a graphical matroid is graphical if and only if Î“ is
planar.
Deï¬nition 22 The contraction of X âŠ†E in the matroid M = (Ï, E) is M/X =
(Ïâ€², M \ X), where Ïâ€²(Y) = Ï(Y âˆªX) âˆ’Ï(X).
Contraction is the dual operation of deletion, in the sense that M/X = (Mâˆ—
|E\X)âˆ—.
The terminology comes from graphical matroids, where contraction of the edge
e âˆˆE corresponds to deleting e and identifying its endpoints in the graph. Notice
that it follows directly from submodularity of the rank function that ÏM/X(Y) â‰¤
ÏM|E\X(Y) for every Y âŠ†E \ X. In terms of subspace representations, contraction of
e âˆˆE corresponds to intersecting the subspace that represents M with the hyperplane
{xe = 0}.
As matroids are used as an abstraction for linear codes, it would be desirable to
have a way to go back from matroids to codes, namely to determine whether a given
matroid is representable, and when it is, to ï¬nd such a representation. Unfortunately,
there is no simple criterion to determine representability [25, 43]. However, there are
a plethora of sufï¬cient criteria to prove nonrepresentability, both over a given ï¬eld
and over ï¬elds in general. In recent years, these methods have been used to prove
two long-standing conjectures, that we will discuss in sections Rotaâ€™s Conjecture
and Most Matroids are Nonrepresentable respectively.

422
R. Freij-Hollanti et al.
Rotaâ€™s Conjecture
While there is no simple criterion to determine linear representability, the situation
is much more promising if we consider representations over a ï¬xed ï¬eld. It has
been known since 1958, that there is a simple criterion for when a matroid is binary
representable.
Theorem 11 ([42]) Let M = (Ï, E) be a matroid. The following two conditions are
equivalent.
1. M is linearly representable over F2.
2. There are no sets X âŠ†Y âŠ†E such that M|Y/X is isomorphic to the uniform
matroid U 2
4 .
In essence, this means that the only obstruction that needs to be overcome in
order to be representable over the binary alphabet, is that no more than three nonzero
points can ï¬t in the same plane. For further reference, we say that a minor of the
matroid M = (Ï, E) is a matroid of the form M|Y/X, for X âŠ†Y âŠ†E. Clearly, if
M is representable over F, then so is all its minors. Let L(F) be the class of matroids
that are not representable over F, but such that all of their minors are F-representable.
Then the class of F-representable matroids can be written as the class of matroids
that does not contain any matroid from L(F) as a minor. Gian-Carlo Rota conjectured
in 1970 that L(F) is a ï¬nite set for all ï¬nite ï¬elds F. A proof of this conjecture was
announced by Geelen, Gerards and Whittle in 2014, but the details of the proof still
remain to written up [12].
Theorem 12 For any ï¬nite ï¬eld F, there is a ï¬nite set L(F) of matroids such that
any matroid M is representable if and only if it contains no element from L(F) as a
minor.
Since the 1970s, it has been known that a matroid is representable over F3 if and
only if it avoids the uniform matroids U 2
5 , U 3
5 , the Fano plane P2(F2), and its dual
P2(F2)âˆ—as minors. The list L(F4) has seven elements, and was given explicitly in
2000. For larger ï¬elds, the explicit list is not known, and there is little hope to even
ï¬nd useful bounds on its size.
Most Matroids are Nonrepresentable
For a ï¬xed ï¬nite ï¬eld F, it follows rather immediately from the minor-avoiding
description in the last section that the fraction of n-symbol matroids that is F-
representable goes to zero as n â†’âˆ. It has long been a folklore conjecture that
this is true even when representations over arbitrary ï¬elds are allowed. However, it
was only in 2016 that a veriï¬able proof of this claim was announced [26].

Matroid Theory and Storage Codes: Bounds and Constructions
423
Theorem 13
lim
nâ†’âˆ
#linear matroids on n elements
#matroids on n elements
= 0.
The proof is via estimates of the denominator and enumerator of the expression
in Theorem13 separately. Indeed, it is shown in [19] that the number of matroids on
n nodes is at least Î©(2(2âˆ’Îµ)n) for every Îµ > 0. The proof of Theorem 13 thus boiled
down to proving that the number of representable matroids is O(2n3). This is in turn
achieved by bounding the number of so called zero-patterns of polynomials.
Gammoid Construction of Singleton-Optimal LRCs
For completeness, we end this appendix with a theorem that explicitly presents the
matroids constructed in Theorem 7 as gammoids. As discussed in Sect.4.2, this
proves the existence of Singleton-optimal linear LRCs whenever a set system satis-
fying (8) exists.
Theorem 14 ([47],
M(F1, . . . , Fm, E; k; Ï)-matroids
are
gammoids)
Let
M(F1, . . . , Fm; Ï) be a matroid given by Theorem 7 and deï¬ne s : E â†’2[m] where
s(x) = {i âˆˆ[m] : x âˆˆFi}. Then M(F1, . . . , Fm, E; k; Ï) is equal to the gammoid
M(Î“, E, T ), where Î“ = (V, D) is the directed graph with
(i) V = E âˆªH âˆªT where E, H, T are pairwise disjoint,
(ii) T = [k],
(iii) H equals the union of the pairwise disjoint sets
H1, . . . , Hm, Hâ‰¥2, where
|Hi| = Ï(Fi) âˆ’|{x âˆˆFi : |s(x)| â‰¥2}| for i âˆˆ[m],
Hâ‰¥2 = {hy : y âˆˆE, |s(y)| â‰¥2},
(iv) D = D1 âˆªD2 âˆªD3, where
D1 = 
iâˆˆ[m]{(âˆ’â†’
x, y) : x âˆˆE, s(x) = {i}, y âˆˆHi},
D2 = {(âˆ’âˆ’â†’
x, hy) : x âˆˆE, hy âˆˆHâ‰¥2, s(x) âŠ†s(y)},
D3 = {(âˆ’â†’
x, y) : x âˆˆH, y âˆˆT }.
References
1. S. Ball, On sets of vectors of a ï¬nite vector space in which every subset of basis size is a basis.
J. Eur. Math. Soc. 14, 733â€“748 (2012)
2. A. Barg, I. Tamo, S. VlË˜aduÂ¸t, Locally recoverable codes on algebraic curves (2016),
arXiv:1603.08876
3. A. Barg, K. Haymaker, E. Howe, G. Matthews, A. VÃ¡rilly-Alvarado, Locally recoverable codes
from algebraic curves and surfaces (2017), arXiv:1701.05212
4. J.E. Bonin, A. de Mier, The lattice of cyclic ï¬‚ats of a matroid. Ann. Comb. 12, 155â€“170 (2008)

424
R. Freij-Hollanti et al.
5. T. Britz, C.G. Rutherford, Covering radii are not matroid invariants. Discret. Math. 296, 117â€“
120 (2005)
6. V. Cadambe, A. Mazumdar, An upper bound on the size of locally recoverable codes, in
International Symposium on Network Coding (2013), pp. 1â€“5
7. A. Dimakis, P.B. Godfrey, Y. Wu, M.J. Wainwright, K. Ramchandran, Network coding for
distributed storage systems. IEEE Trans. Inf. Theory 56(9), 4539â€“4551 (2010)
8. T. Ernvall, T. WesterbÃ¤ck, R. Freij-Hollanti, C. Hollanti, Constructions and properties of linear
locally repairable codes. IEEE Trans. Inf. Theory 62, 5296â€“5315 (2016)
9. A. Fazeli, A. Vardy, E. Yaakobi, PIR with low storage overhead: coding instead of replication
(2015), arXiv:1505.06241
10. R. Freij-Hollanti, T. WesterbÃ¤ck, C. Hollanti, Locally repairable codes with availability and
hierarchy: matroid theory via examples, in International ZÃ¼rich Seminar on Communications
(IEEE/ETH, 2016), pp. 45â€“49
11. S. Fujishige, Polymatroidal dependence structure of a set of random variables. Inf. Control
39(1), 55â€“72 (1978)
12. J. Geelen, B. Gerards, G. Whittle, Solving Rotaâ€™s conjecture. Not. Am. Math. Soc. 61, 736â€“743
(2014)
13. P. Gopalan, C. Huang, H. Simitci, S. Yekhanin, On the locality of codeword symbols. IEEE
Trans. Inf. Theory 58(11), 6925â€“6934 (2012)
14. C. Huang, M. Chen, J. Lin, Pyramid codes: ï¬‚exible schemes to trade space for access efï¬ciency
in reliable data storage systems, in International Symposium on Network Computation and
Applications (IEEE, 2007), pp. 79â€“86
15. A. Ingleton, R. Main, Non-algebraic matroids exist. Bull. Lond. Math. Soc. 7, 144â€“146 (1975)
16. Y. Ishai, E. Kushilevitz, R. Ostrovsky, A. Sahai, Batch codes and their applications, in The 36th
ACM Symposium on Theory of Computing (STOC) (2004)
17. R. Jurrius, R. Pellikaan, Truncation formulas for invariant polynomials of matroids and geo-
metric lattices. Math. Comput. Sci. 6, 121â€“133 (2012)
18. G.M. Kamath, N. Prakash, V. Lalitha, P.V. Kumar, Codes with local regeneration and erasure
correction. IEEE Trans. Inf. Theory 60(8), 4637â€“4660 (2014)
19. D. Knuth, The asymmetric number of geometries. J. Comb. Theory Ser. A 16, 398â€“400 (1974)
20. B. LindstrÃ¶m, On the vector representations of induced matroids. Bull. Lond. Math. Soc. 5,
85â€“90 (1973)
21. B. LindstrÃ¶m, On p-polynomial representations of projective geometries in algebraic combi-
natorial geometries. Math. Scand. 63, 36â€“42 (1988)
22. B. LindstrÃ¶m, On algebraic matroids. Discret. Math. 111, 357â€“359 (1993)
23. H. Lipmaa, V. Skachek, Linear batch codes, in The 4th International Castle Meeting on Coding
Theory and Applications (4ICMCTA) (2015)
24. D. Mayhew, M. Newman, D. Welsh, G. Whittle, On the asymptotic proportion of connected
matroids. Eur. J. Comb. 32(6), 882â€“890 (2011)
25. D. Mayhew, M. Newman, G. Whittle, Yes, the missing axiom of matroid theory is lost forever
(2015), arXiv:1412.8399
26. P. Nelson, Almost all matroids are non-representable, arXiv:1605.04288
27. D. Papailiopoulos, A. Dimakis, Locally repairable codes, in International Symposium on Infor-
mation Theory (IEEE, 2012), pp. 2771â€“2775
28. R. Pendavingh, J. van der Pol, On the number of matroids compared to the number of sparse
paving matroids. Electron. J. Comb. 22 (2015), 17pp
29. A. PÃ¶llÃ¤nen, T. WesterbÃ¤ck, R. Freij-Hollanti, C. Hollanti, Improved singleton-type bounds for
locally repairable codes, in International Symposium on Information Theory (IEEE, 2016), pp.
1586â€“1590
30. N. Prakash, G.M. Kamath, V. Lalitha, P.V. Kumar, Optimal linear codes with a local-error-
correction property, in International Symposium on Information Theory (IEEE, 2012), pp.
2776â€“2780
31. A.S. Rawat, D. Papailiopoulos, A. Dimakis, S. Vishwanath, Locality and availability in dis-
tributed storage (2014), arXiv:1402.2011v1

Matroid Theory and Storage Codes: Bounds and Constructions
425
32. B. Sasidharan, G.K. Agarwal, P.V. Kumar, Codes with hierarchical locality (2015),
arXiv:1501.06683v1
33. N. Silberstein, A. Zeh, Optimal binary locally repairable codes via anticodes (2015),
arXiv:1501.07114v1
34. N. Silberstein, A.S. Rawat, O. Koyluoglu, S. Vishwanath, Optimal locally repairable codes
via rank-metric codes, in International Symposium on Information Theory (IEEE, 2013), pp.
1819â€“1823
35. J.A. Sims, Some problems in matroid theory. Ph.D. thesis, Oxford University (1980)
36. R.C. Singleton, Maximum distance q-nary codes. IEEE Trans. Inf. Theory 10(2), 116â€“118
(1964)
37. A. Skorobogatov, Linear codes, strata of Grassmannians, and the problems of Segre, in Inter-
national Workshop on Coding Theory and Algebraic Geometry (1992), pp. 210â€“223
38. W. Song, C. Yuen, S.H. Dau, T.J. Li, Optimal locally repairable linear codes. IEEE J. Sel. Areas
Commun. 32(5), 1019â€“1036 (2014)
39. I. Tamo, A. Barg, A family of optimal locally recoverable codes. IEEE Trans. Inf. Theory
60(8), 4661â€“4676 (2014)
40. I. Tamo, D. Papailiopoulos, A. Dimakis, Optimal locally repairable codes and connections to
matroid theory, in International Symposium on Information Theory (IEEE, 2013), pp. 1814â€“
1818
41. I. Tamo, A. Barg, A. Frolov, Bounds on the parameters of locally recoverable codes. IEEE
Trans. Inf. Theory 62(6), 3070â€“3083 (2016)
42. W. Tutte, A homotopy theorem for matroids, I, II. Trans. Am. Math. Soc. 88, 148â€“178 (1958)
43. P. VÃ¡mos, The missing axiom of matroid theory is lost forever. J. Lond. Math. Soc. 18, 403â€“408
(1978)
44. A. Wang, Z. Zhang, Repair locality with multiple erasure tolerance. IEEE Trans. Inf. Theory
60(11), 6979â€“6987 (2014)
45. A. Wang, Z. Zhang, An integer programming-based bound for locally repairable codes. IEEE
Trans. Inf. Theory 61(10), 5280â€“5294 (2015)
46. T. WesterbÃ¤ck, R. Freij, C. Hollanti, Applications of polymatroid theory to distributed storage
systems, in Allerton Conference on Communication, Control, and Computing (2015), pp. 231â€“
237
47. T. WesterbÃ¤ck, R. Freij-Hollanti, T. Ernvall, C. Hollanti, On the combinatorics of locally
repairable codes via matroid theory. IEEE Trans. Inf. Theory 62, 5296â€“5315 (2016)
48. H. Whitney, On the abstract properties of linear dependence. Am. J. Math. 57, 509â€“533 (1935)
49. H. Zhang, V. Skachek, Bounds for batch codes with restricted query size, in IEEE International
Symposium on Information Theory (ISIT) (2016)

Batch and PIR Codes and Their Connections
to Locally Repairable Codes
Vitaly Skachek
Abstract Tworelatedfamiliesofcodesarestudied:batchcodesandcodesforprivate
information retrieval. These two families can be viewed as natural generalizations of
locally repairable codes, which were extensively studied in the context of coding for
fault tolerance in distributed data storage systems. Bounds on the parameters of the
codes, as well as basic constructions, are presented. Connections between different
code families are discussed.
1
Introduction
In this chapter, we discuss two related families of codes: batch codes and codes
for private information retrieval (PIR codes). These two families can be viewed as
natural generalizations of locally repairable codes, which were extensively studied
in the context of coding for fault tolerance in distributed data storage systems.
Batch codes were ï¬rst presented in [15], where it was suggested to use them
for load balancing in the multi-server distributed data storage systems. It was also
suggested in [15] to use these codes in private information retrieval. A number
of constructions of batch codes were presented therein. Later, the authors of [33]
proposed to use so-called â€œswitch codesâ€ for facilitating the routing of data in the
network switches. It turns out, however, that switch codes are a special case of batch
codes.
Coding schemes for PIR were studied in [12]. The authors showed that a family of
codes, which is a relaxed version of batch codes, can be employed in classical linear
PIR schemes in order to reduce the redundant information stored in a distributed
server system. This relaxed version of the batch codes is termed PIR codes.
In these schemes, typically a distributed data storage system is considered. The
coded words are written across the block of disks (servers), where each disk stores
a single symbol (or a group of symbols). The reading of data is done by accessing
V. Skachek (B)
Institute of Computer Science, University of Tartu, 50409 Tartu, Estonia
e-mail: vitaly.skachek@ut.ee
Â© Springer International Publishing AG 2018
M. Greferath et al. (eds.), Network Coding and Subspace Designs,
Signals and Communication Technology,
https://doi.org/10.1007/978-3-319-70293-3_16
427

428
V. Skachek
a small number of disks. Mathematically, this can be equivalently represented by
the assumption that each information symbol depends on a small number of other
symbols. However, the type of requested queries varies in different code models.
Thus, in PIR codes several copies of the same information symbols are requested,
while in batch codes combinations of different symbols are also possible.
In this chapter, we mathematically deï¬ne the corresponding families of codes, and
study their properties. We derive bounds on the parameters of such codes, and show
some basic constructions. We also show relations between different families of codes.
In Sect.3, we introduce various models of locally repairable codes. In Sect.4, we
deï¬ne batch codes. In Sect.5, we discuss properties of linear batch codes. In Sect.6,
we introduce codes for private information retrieval. In Sect.7, we study connections
between locally repairable and batch/PIR codes. In Sects.8 and 9, we present bounds
on the parameters of various families of codes. In Sect.10, we pose some open
questions. For the sake of completeness, we introduce all necessary notations and
deï¬nitions, which are used in the sequel.
2
General Settings
Throughout this chapter, we denote by N the set of nonnegative integer numbers. For
n âˆˆN, deï¬ne [n] â‰œ{1, 2, . . . , n}. Let ei be the row vector having one at position i
and zeros elsewhere (the length of vectors will be clear from the context).
LetÎ£ beaï¬nitealphabet.Letx = (x1, x2, . . . , xk) âˆˆÎ£k beaninformationvector.
The code is a set of coded vectors

y = (y1, y2, . . . , yn) = C (x) : x âˆˆÎ£k
âŠ†Î£n ,
where C : Î£k â†’Î£n is a bijection, for some n âˆˆN. By slightly abusing the notation,
sometimes we denote the above set by C .
Let F = Fq be a ï¬nite ï¬eld with q elements, where q is a prime power. If C :
Fk â†’Fn is a linear mapping, then C is a linear [n, k, d] code over F. Here, d is the
minimum Hamming distance of C . In that case, the encoding can be viewed as a
multiplication by a k Ã— n generator matrix G over F of an information vector x,
y = x Â· G .
(1)
The rate of the code is deï¬ned as R â‰œk/n.
3
Codes with Locality and Availability
Codes with locality were proposed for use in the distributed data storage systems [11].
In such systems, the data is stored in many disks (servers), and these servers may
fail from time to time. It is possible to use erasure-correcting codes, where parts of a

Batch and PIR Codes and Their Connections â€¦
429
codeword are stored in different servers. A failure of one server can be viewed as an
erasure of a symbol or of a group of symbols. In order to repair the erased symbols,
there is a need to bring a few other symbols from other servers. In general, it would
be beneï¬cial to minimize the trafï¬c in the network. For an overview of coding for
distributed storage systems the reader is referred to chapterâ€œAn Overview of Coding
for Distributed Storage Systemsâ€. We continue by recalling the deï¬nition of locally
repairable codes (LRCs).
Deï¬nition 1 The code C has locality r â‰¥1, if for any y âˆˆC , any symbol in y can
be recovered by using at most r other symbols of y.
Codes with low locality were extensively discussed, for example, in [11]. A some-
what similar family of codes, known as one-step majority-logic decodable codes, was
investigated in the classical literature [18]. Recently, the bounds on the parameters
of LRCs were derived in [14]. It was shown therein that the parameters of a linear
[n, k, d] code with locality r over F satisfy1:
n â‰¥k + d +
k
r

âˆ’2 .
(2)
This bound can be viewed as a reï¬nement of the classical Singleton bound, where
âŒˆk
r âŒ‰âˆ’1 is an additive penalty for locality of the code, when compared to the classical
Singleton bound. The proof is done by iterative expurgating of the code, and by taking
into account that there are dependencies between sets ofr + 1 symbols, which consist
of an arbitrary symbol in y and its recovery set. The bound in (2) is tight. In fact,
several known constructions attain it with equality (see, for example, [14, 26, 30]).
Assume that the linear code C is systematic, i.e. the matrix G contains a k Ã— k
identity submatrix I. Then, the symbols of y corresponding to I are called information
symbols. It is possible to require recoverability of information symbols only (from
sets of size at most r). In that case, the code is said to have locality of information
symbols. Otherwise, if all symbols of y are recoverable from small sets, the code has
locality of all symbols.
The above model was extended to codes with locality and availability in [24].
Deï¬nition 2 The code C has locality r â‰¥1 and availability Î´ â‰¥1, if for any y âˆˆC ,
any symbol in y can be reconstructed by using any of Î´ disjoint sets of symbols, each
set is of size at most r.
In [34], the authors consider linear codes with locality r and availability Î´ of all
symbols. They derive the following bound on the parameters of the code:
n â‰¥k + d +
Î´(k âˆ’1) + 1
Î´(r âˆ’1) + 1

âˆ’2 .
(3)
1This result is proven in Theorem6, Chap.â€œAn Overview of Coding for Distributed Storage Sys-
temsâ€.

430
V. Skachek
In [24], systematic codes (linear or non-linear) are considered, with locality r and
availability Î´ of information symbols. The authors show the bound analogues to (3)
for that case. In particular, we observe that when availability Î´ = 1, i.e. there is only
one recovery set for each symbol, then (3) coincides with (2). The proof technique
in both cases is based on the idea similar to that of [14].
Another related model is considered in [23]. In that model, several different sym-
bols are recovered from a small set of recovery symbols. By building on the ideas
in the previous works, the authors derive a variation of the bound (3) for the model
under consideration. Other related works, for example, include [6, 13, 19, 21, 29,
35, 36] and the references therein.2
4
Batch Codes
Batchcodeswereï¬rstpresentedinthecryptographiccommunityin[15].Inthatwork,
the authors proposed to use batch codes for load balancing in the distributed systems,
as well as for private information retrieval. The authors of [15] have also presented
a few constructions of various families of batch codes. Those constructions were
based on recursive application of simple batch codes (so-called â€œsub-cube codesâ€),
on classical Reed-Muller codes, on locally decodable codes, and others.
The following deï¬nition is based on [15].
Deï¬nition 3 Let Î£ be a ï¬nite alphabet. We say that C is an (k, n, t, M, Ï„)Î£ batch
code over a ï¬nite alphabet Î£ if it encodes any string x = (x1, x2, . . . , xk) âˆˆÎ£k
into M strings (buckets) of total length n over Î£, namely y1, y2, . . . , yM, such that
for each t-tuple (batch) of (not necessarily distinct) indices i1, i2, . . . , it âˆˆ[k], the
symbols xi1, xi2, . . . , xit can be retrieved by reading at most Ï„ symbols from each
bucket.
More formally, by following the presentation in [31], we can state an equivalent
deï¬nition.
Deï¬nition 4 An (k, n, t, M, Ï„)Î£ batch code C over a ï¬nite alphabet Î£ is deï¬ned
by an encoding mapping C : Î£k â†’(Î£âˆ—)M (there are M buckets in total), and a
decoding mapping D : Î£n Ã— [k]t â†’Î£t, such that
1. The total length of all buckets is n;
2. For any x âˆˆÎ£k and
i1, i2, . . . , it âˆˆ[k] ,
(4)
D (C (x), i1, i2, . . . , it) = (xi1, xi2, . . . , xit) ,
and D depends only on Ï„ symbols in each bucket in C (x).
2In particular, the use of matroids in bounding the parameters of various families of codes with
locality is thoroughly treated in chapterâ€œMatroid Theory and Storage Codes: Bounds and Construc-
tionsâ€.

Batch and PIR Codes and Their Connections â€¦
431
In particular, an interesting case for consideration is when Ï„ = 1, namely only
at most one symbol is read from each bucket. If the requested information sym-
bols (xi1, xi2, . . . , xit) can be reconstructed from the data read by t different users
independently (i.e., the symbol xiâ„“is reconstructed by the user â„“, â„“= 1, 2, . . . , t,
respectively), and the sets of the symbols read by these t users are all disjoint, such
a model is called a multiset batch code.
In the sequel, we only consider multiset batch codes, and therefore we usually
omit the word â€œmultisetâ€ for convenience.
An important special case of batch codes is deï¬ned as follows.
Deï¬nition 5 ([15]) A primitive batch code is a batch code, where each bucket con-
tains exactly one symbol. In particular, n = M.
Following the work [15], a number of subsequent papers have studied combi-
natorial batch codes. In combinatorial batch codes, a number of replicas of the
information symbols are stored in different positions in the codeword. Usually, the
symbols are associated with servers according to some optimal or sub-optimal com-
binatorial objects, such as block designs. Combinatorial batch codes were studied,
for example, in [2, 4, 5, 27, 28].
5
Linear Batch Codes
In what follows, we consider a special case of primitive multiset batch codes with
n = M and Ï„ = 1. Under these conditions, each symbol can be viewed as a separate
bucket, and only one reading per bucket is allowed.
We assume that the information and the coded symbols are taken from the ï¬nite
ï¬eld F = Fq, where q is a prime power. Additionally, we assume that the encoding
mapping C : Fk â†’Fn is linear over F, and therefore the code C is a linear [n, k]
code over F. In that case, C falls under the linear coding framework deï¬ned in (1).
We also refer to the parameter t as the size of a query of the code. The batch code
with the parameters n, k and t over Fq is denoted as [n, k, t]q-batch code (or simply
[n, k, t]-batch code) in the sequel.
This framework was ï¬rst considered in [17], and the similarities with locally
repairable codes were mentioned. The main difference between these two families,
however, is that the supported query types are different. In batch codes we are inter-
ested in reconstruction of the information symbols in x, while in locally repairable
codes the coded symbols in y are to be recovered.
The following simple result was established in [17, Theorem1].
Theorem 1 Let C be an [n, k, t]q batch code. It is possible to retrieve xi1, xi2, . . . , xit
by t different users in the primitive multiset batch code model (where the symbol xiâ„“
is retrieved by the user â„“, â„“= 1, 2, . . . , t, respectively) if and only if there exist t
non-intersecting sets T1, T2, . . . , Tt of indices of columns in the generator matrix G,
and for each Tâ„“, 1 â‰¤â„“â‰¤t, there exists a linear combination of columns of G indexed
by that set, which equals to the column vector eT
iâ„“, for all â„“âˆˆ[t].

432
V. Skachek
The reader can ï¬nd the proof of this theorem in [17]. Next, we show examples
that further illustrate this concept.
Example 1 ([15]) Consider the following binary 2 Ã— 3 generator matrix of a batch
code C given as
G =
 1 0 1
0 1 1

.
Thecorrespondingcodeisasub-cubecodeconstructedin[15,Sect.3.2].Byusingthis
code,theinformationsymbols(x1, x2)areencodedinto(y1, y2, y3)=(x1, x2, x1+ x2).
Assume that the query contains two different symbols (x1, x2). Then, we can
retrieve these symbols directly by using the following equations:
 x1 = y1
x2 = y2 .
Alternatively, assume that the query contains two copies of the same symbol, for
example (x1, x1). Then, we can retrieve these symbols by using the following equa-
tions:
 x1 = y1
x1 = y2 + y3 .
Similarly, (x2, x2) can be retrieved. We conclude that C is a [3, 2, 2]2 batch code.
Example 2 ([17]) Pick the following binary 4 Ã— 9 generator matrix of a batch code
C given as
G =
â›
âœâœâ
1 0 1 0 0 0 1 0 1
0 1 1 0 0 0 0 1 1
0 0 0 1 0 1 1 0 1
0 0 0 0 1 1 0 1 1
â
âŸâŸâ .
The corresponding code is a second-order sub-cube code constructed as in [15,
Sect.3.2].
Assume that the query contains the information symbols (x1, x1, x2, x2). Then,
we can retrieve these symbols using the following equations:
â§
âªâªâ¨
âªâªâ©
x1 = y1
x1 = y2 + y3
x2 = y5 + y8
x2 = y4 + y6 + y7 + y9
.
It can be veriï¬ed in a similar manner that any 4-tuple (xi1, xi2, xi3, xi4), where
i1, i2, i3, i4 âˆˆ[4], can be retrieved by using the symbols of y, by using each symbol
at most once. We conclude that C is a [9, 4, 4]2 batch code.

Batch and PIR Codes and Their Connections â€¦
433
Example 3 ([32]) Pick the following binary 3 Ã— 7 generator matrix of a batch code
C given as
G =
â›
â
1 0 0 1 1 0 1
0 1 0 1 0 1 1
0 0 1 0 1 1 1
â
â .
The corresponding code is a binary [7, 3, 4] classical error-correcting simplex code.
Assume that the query contains the information symbols (x1, x1, x2, x2). Then,
we can retrieve these symbols using the following equations:
â§
âªâªâ¨
âªâªâ©
x1 = y1
x1 = y2 + y4
x2 = y3 + y6
x2 = y5 + y7
.
It can be veriï¬ed in a similar manner that any 4-tuple (xi1, xi2, xi3, xi4), where
i1, i2, i3, i4 âˆˆ[4], can be retrieved by using the symbols of y, by using each symbol
at most once. We conclude that C is a [7, 3, 4]2-batch code. Moreover, it was shown
in [32] that all queries can be satisï¬ed when each user reads at most r = 2 symbols
from y.
Constructions of linear batch codes using graphs without short cycles were
presented in [10]. A family of codes, related to batch codes, and corresponding
to the case t = k, termed switch codes, was studied in [8, 32, 33]. It was suggested
in [33] to use such codes for efï¬cient routing of data in the network switches.
The following property of batch codes was observed in [17] for binary linear
codes, and later generalized to nonbinary (and also to non-linear) codes in [40].
Theorem 2 Let C be an [n, k, t]q-batch code. Then, the minimum Hamming dis-
tance of C is at least t.
Proof Let y1 = C (x1) and y2 = C (x2) be two codewords of C , and x1 Ì¸= x2. Then,
x1 and x2 differ in at least one symbol, i.e. (x1)â„“Ì¸= (x2)â„“, for some 1 â‰¤â„“â‰¤k. Con-
sider the query (xâ„“, xâ„“, . . . , xâ„“



t
). The i-th copy of xâ„“is recovered from the set of
symbols indexed by the set Ti, 1 â‰¤i â‰¤t. Since x1 and x2 differ in the â„“-th symbol,
the codewords y1 and y2 should differ in at least one symbol in each Ti, 1 â‰¤i â‰¤t.
The sets Ti are all disjoint, and therefore y1 and y2 differ in at least t symbols.
â–¡
It follows that any [n, k, t]q-batch code is in particular a classical [n, k, â‰¥t]q
error-correcting code, and a variety of classical bounds, such as Singleton bound,
Hamming bound, Plotkin bound, Griesmer bound, Johnson bound, Elias-Bassalygo
bound, are all applicable to batch codes (when the minimum distance d is replaced
by the query size t).

434
V. Skachek
Example 4 Let m > 1 be an integer. A binary simplex [2m âˆ’1, m, 2mâˆ’1] code C is
deï¬ned by its generator matrix
G =

g1 | g2 | Â· Â· Â· | g2mâˆ’1

,
where gi are all possible different binary nonzero column vectors of length m, i =
1, 2, . . . , 2m âˆ’1 [25, Problem2.18].
For a classical error-correcting [n, k, d] code over Fq, the Plotkin bound is deï¬ned
as follows [20, Theorem2.2.29]:
if qd > (q âˆ’1)n, then qk â‰¤

qd
qd âˆ’(q âˆ’1)n

.
It is straightforward to see that, as an error-correcting code, the binary simplex
code as above (with q = 2) attains the Plotkin bound with equality [25, Problem
2.18] for all m â‰¥2.
As it was shown in [32], the code C is a [2m âˆ’1, m, 2mâˆ’1]2 batch code, with
t = 2mâˆ’1. Therefore, by Theorem2, it attains the corresponding Plotkin-based bound
qk â‰¤

qt
qt âˆ’(q âˆ’1)n

with equality, and therefore it is a Plotkin-optimal batch code.
In [38], a variation of batch codes with restricted size of reconstruction sets is
deï¬ned. These codes are batch codes as in Deï¬nition3 with an additional property
that every queried information symbol xi is reconstructed from at most r â‰¥1 symbols
of y. This additional property can be viewed as analogous to locality of the LRCs.
Small size of reconstruction sets allows for recovering the requested data symbol
from a small number r of servers, thus reducing the trafï¬c and the load in the system.
For example, the binary simplex code C in the previous example was shown
in [32] to have the size of reconstruction sets of at most r = 2.
6
Codes for Private Information Retrieval
The topic of private information retrieval (PIR) protocols has been a subject of a lot
of research over the last two decades [9]. In the PIR scenario, the database is stored
in a number of servers in a distributed manner. The user is interested in reading an
item from the database without revealing to any server what item was read. In the
classical approach, the data is replicated, and the replicas are stored in a number of
different servers. The user accesses some of these servers, such that no server learns
what data the user is interested in (it is assumed that the servers do not collude).

Batch and PIR Codes and Their Connections â€¦
435
A novel approach to PIR is based on coding, and it was studied, for example in
[1, 7, 16]. More speciï¬cally, assume that x = (x1, x2, . . . , xk) is an information
vector, which is encoded into C (x) = y = (y1, y2, . . . , yn). The symbols of y are
stored in different servers in a distributed manner.
In [7], the authors show that there is a fundamental trade-off between download
communication complexity of the protocol (the number of symbols or bits down-
loaded by the user from the database) and the storage overhead (the number of
redundant symbols or bits stored in the database). Later, the authors of [12] show
that it is possible to emulate many of the existing PIR protocols by using a code
of length n that approaches (1 + Îµ)k for vanishing Îµ (for sufï¬ciently large k). This
approach leads to PIR schemes with storage data rate arbitrarily close to 1. The
authors deï¬ne a special class of codes, which allows for such efï¬cient PIR protocols.
Deï¬nition 6 ([12]) An k Ã— n binary matrix G has property At if for all i âˆˆ[k], there
exist t disjoint sets of columns of G that add up to ei. A binary linear [n, k] code C
is called a t-server PIR code (or, simply, PIR code) if there exists a generator matrix
G for C with property At.
The batch codes turn out to be a special case of PIR codes, with a difference
that PIR codes support only queries of type (xi, xi, . . . , xi), i âˆˆ[k], while batch
codes support queries of a more general form (xi1, xi2, . . . , xit), possibly for different
indices i1, i2, . . . , it âˆˆ[k]. It follows that batch codes can be used as PIR codes.
Since for PIR codes (as well as for batch codes), the code rate R approaches
1 [15, 22] for large values of k, it is more appropriate to talk about redundancy (as
a function of k), rather than about the code rate. This is in contrast to PIR/batch
codes with restricted size of reconstruction sets, where the asymptotic loss of code
rate takes place. The redundancy of the codes will be deï¬ned and analyzed in the
following sections.
Constructions of PIR codes were presented very recently, for example, in
[3, 12, 39].
7
Connections Between Batch/PIR Codes and General
LRCs
As it was mentioned above, there are two types of LRCs considered in the literature:
LRCs with locality of information symbols and LRCs with locality of all symbols.
In order to preserve the information symbols in the coded word, a code with
locality of information symbols has a systematic encoding matrix G = [I|A] for some
matrix A. Consider LRCs with locality r and availability Î´ = t âˆ’1 of information
symbols. Then, each information symbol yi, 1 â‰¤i â‰¤k, in y, can be recovered from Î´
disjoint sets Ti of symbols, |Ti| â‰¤r. Such a code can also be viewed as a PIR code that
supports any query of t copies of an information symbol with locality r (including
one copy of the information symbol in the systematic part). Generally, it does not

436
V. Skachek
follow that such a code is a batch code, since there is no guarantee that mixed queries
of different information symbols are supported by disjoint reconstruction sets.
On the other hand, a systematic batch or PIR code with restricted size of recon-
struction sets allows to recover any query of t information symbols with recovery
sets of size r. Since in the systematic case, the information symbols are a part of
a coded word y, it follows that this code is an LRC with locality r and availability
Î´ = t âˆ’1 of information symbols.
We obtain the following corollary (see also Theorem21 in [12]).
Corollary 1 A linear systematic code C is an LRC with locality r and availability
Î´ = t âˆ’1 of information symbols if and only if C is a PIR code that supports queries
of size t with size of reconstruction sets at most r.
It follows that the bounds derived for the parameters of the LRCs with locality
and availability of information symbols can be applied also to systematic batch or
PIR codes.3
On the other hand, for the non-systematic case, there is no simple known connec-
tion between linear batch codes with restricted size of reconstruction sets and LRCs
with availability, as it is illustrated in the following examples.
Example 5 Let G be a k Ã— (3k) generator matrix of a linear binary code C deï¬ned
as follows:
G =
â›
âœâœâœâœâœâ
1 0 . . . 0 1
1 0 . . . 0 1
1 0 . . . 0 1
0 1 . . . 0 1
0 1 . . . 0 1
0 1 . . . 0 1
0 0 ... 0 1
0 0 ... 0 1
0 0 ... 0 1
0 0 . . . 1 1
0 0 . . . 1 1
0 0 . . . 1 1
0 0 . . . 0 1
0 0 . . . 0 1
0 0 . . . 0 1
â
âŸâŸâŸâŸâŸâ 
.
Speciï¬cally, the binary information vector x = (x1, x2, . . . , xk) is encoded into the
codeword y, which consists of three copies of the same sub-vector,
y = (y1, y2, . . . , y3k)
= (x1, x2, . . . ,
k

i=1
xi, x1, x2, . . . ,
k

i=1
xi, x1, x2, . . . ,
k

i=1
xi) .
The code C , when viewed as an LRC, has locality r = 1 and availability Î´ = 2,
since every symbol in y can be recovered from a single symbol in y, and there are 2
different recovery sets.
On the other hand, the code C , when viewed as a batch or PIR code, must have
a maximal size of reconstruction sets at least k, since it is impossible to recover a
single information symbol xk from less than k coded symbols in y.
3Please note that generally it does not follow here that the bounds for LRCs with locality of all
symbols are applicable to systematic batch or PIR codes.

Batch and PIR Codes and Their Connections â€¦
437
The following example shows that batch or PIR code with small size of recon-
struction sets is not necessarily LRC with all symbols locality, even in the systematic
case (the example can be also modiï¬ed to a non-systematic case).
Example 6 Take G to be a binary 2Îº Ã— (3Îº + 1) matrix, where Îº is some integer,
as follows:
G =
â›
âœâœâœâœâœâœâœâœâœâ
1 1 0
0 0 0
. . .
0 0 0
1
0 1 1
0 0 0
. . .
0 0 0
1
0 0 0
1 1 0
. . .
0 0 0
1
0 0 0
0 1 1
. . .
0 0 0
1
... ... ...
... ... ...
...
... ... ...
...
0 0 0
0 0 0
. . .
1 1 0
1
0 0 0
0 0 0
. . .
0 1 1
1
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
.
Here, k = 2Îº. This matrix G is a diagonal block matrix, where each block is a 2 Ã— 3
generator matrix of a basic sub-cube code in [15], with an additional all-ones column.
Let C be a binary linear code generated by this matrix.
The code C , when viewed as a batch code, supports any two queries of the form
(xi, x j) (1 â‰¤i â‰¤k, 1 â‰¤j â‰¤k), with size of reconstruction sets at most 2. Therefore,
C is a batch code with r = 2, t = 2. In particular, it is a PIR code with r = 2 and
t = 2.
On the other hand, the code C , when viewed as an LRC, has locality of at least
Îº, since in order to recover yn = k
i=1 xk, one needs to combine at least Îº other
symbols of y.
As we see, this batch code with r = 2 and t = 2 has locality at least k/2 = Îº,
when used as an LRC with all symbols locality.
8
Bounds on the Parameters of PIR and Batch Codes
with Unrestricted Size of Reconstruction Sets
In [31], the systematic batch codes with unrestricted size of reconstruction sets are
considered.Thecodesunderconsiderationhaverestrictiononthevalueoft (typically,
it is a small constant), yet there is no restriction on r, so we can assume that r = n.
Deï¬ne the parameters B(k, t) and P(k, t) to be the shortest length n of any linear
systematic batch and PIR code, respectively, for given values of k and t. Deï¬ne the
optimal redundancy of systematic batch and PIR codes, respectively, as
rB(k, t) â‰œB(k, t) âˆ’k
and rP(k, t) â‰œP(k, t) âˆ’k .
It is known [31] that for any ï¬xed t,
lim
kâ†’âˆ
B(k, t)
k
= 1 .

438
V. Skachek
In a case of switch codes, k = t, it is shown in [33] that B(k, k) = O

k2/ log(k)

.
A constructive proof showing that rP(k, t) = t Â·
âˆš
k(1 + o(1)) was given in [12]. As
for the lower bound on rP(k, t), it was recently shown in [22] (see also [37]) that
for a ï¬xed t â‰¥3, rP(k, t) = (k), thus establishing an asymptotic behavior for the
redundancy of the PIR codes.
Since every batch code is also a PIR code, it follows that B(k, t) â‰¥P(k, t), and
rB(k, t) â‰¥rP(k, t). The relations between B(k, t) and P(k, t) for speciï¬c choices
of t were extensively studied in [31]. Thus, for example, it was shown that B(k, t) =
P(k, t) for 1 â‰¤t â‰¤4, while for 5 â‰¤t â‰¤7,
rB(k, t) â‰¤rP(k, t) + 2âŒˆlog(k)âŒ‰Â· rP(k/2, t âˆ’2) .
It is quite straightforward to verify that rB(k, 1) = 0 and rB(k, 2) = 1 for any k. It
was additionally shown in [31] that
rB(k, t) = O(
âˆš
k) for t = 3, 4 ,
rB(k, t) = O(
âˆš
k Â· log(k)) for 5 â‰¤t â‰¤7 .
The following more general result was proven in [31].
Theorem 3 For all values of k and t, it holds
rB(k, t) â‰¤rP(k, t) +
 t
2
 â¡
â¢â¢â¢
log

k
âŒŠt/2âŒ‹

âˆ’log

1 âˆ’
âŒŠt/2âŒ‹!
âŒŠt/2âŒ‹âŒŠt/2âŒ‹
 
â¤
â¥â¥â¥
Â· rP

k
âŒŠt/2âŒ‹

, t âˆ’2

.
In particular, it follows from Theorem3 that for any ï¬xed t,
rB(k, t) = O
âˆš
k Â· log(k)
 
.
9
Bounds on the Parameters of PIR and Batch Codes
with Restricted Size of Reconstruction Sets
In [38], the authors study linear batch codes with restricted size of reconstruction
sets. They aim at reï¬ning the Singleton bound for that case by using ideas in [14] and
subsequent works. Note, however, that these ideas cannot be applied directly, because
in LRCs there are dependencies between different coded symbols, and expurgation of
the code in the proof of the bound (2) (and similar bounds) uses these dependencies.
Therefore, the authors of [38] consider a query of t copies of the same symbol (for
example, (x1, x1, . . . , x1)), and show that the symbols in different reconstruction
sets possess certain dependencies. By using this property, they apply an expurgation
technique similar to that of [14, 23, 24, 34], and obtain the following relation on

Batch and PIR Codes and Their Connections â€¦
439
the parameters of batch codes with size of reconstruction sets restricted to r. The
proof actually only assumes property At, and therefore it is directly applicable to
PIR codes as well.
Theorem 4 ([38]) Let C be a linear [n, k, t]q-batch code (or PIR code) with the
size of reconstruction sets restricted to r. Then, it holds:
n â‰¥k + d + (t âˆ’1)

k
rt âˆ’t + 1

âˆ’1

âˆ’1 .
(5)
Now, observe that if the [n, k, t]q-batch code (or PIR code) allows for reconstruc-
tion of any batch of t symbols, then it also allows for reconstruction of any batch
of Î² symbols, 1 â‰¤Î² â‰¤t. Therefore, expression (5) in Theorem4 can be adjusted as
follows:
n â‰¥k + d +
max
1â‰¤Î²â‰¤t,Î²âˆˆN

(Î² âˆ’1)

k
rÎ² âˆ’Î² + 1

âˆ’1
#
âˆ’1 .
(6)
If the code is systematic, then there is always a reconstruction set of size 1 for
one of the queried symbols. In that case, the last expression can be rewritten as:
n â‰¥k + d +
max
2â‰¤Î²â‰¤t,Î²âˆˆN

(Î² âˆ’1)

k
rÎ² âˆ’Î² âˆ’r + 2

âˆ’1
 #
âˆ’1 .
(7)
The reader can refer to [38] for the full proofs.
Example 7 ([38]) Take r = 2 and t = Î² = 2. Then, the bound in (7) is attained with
equality by the linear systematic codes of minimum distance 2, deï¬ned as follows:
â€¢ yi = xi for 1 â‰¤i â‰¤k, and y j = x2( jâˆ’k)âˆ’1 + x2( jâˆ’k) for k + 1 â‰¤j â‰¤k + k/2,
when k is even,
â€¢ yi = xi for 1 â‰¤i â‰¤k, y j = x2( jâˆ’k)âˆ’1 + x2( jâˆ’k) for k + 1 â‰¤j â‰¤k + (k âˆ’1)/2,
and yk+(k+1)/2 = xk, when k is odd.
In that case, d = 2, and we obtain
n = k + k/2
if k is even ,
n = k + (k + 1)/2
if k is odd .
In both cases, the bound (7) is attained with equality for all k â‰¥1.
Example 8 Consider the code C in Example3, which was studied in [32]. As dis-
cussed, C is a linear [7, 3, 4]2-batch code, with the size of reconstruction sets at most
r = 2. Its minimum Hamming distance is d = 4. We pick Î² = 2, and observe that
the right-hand side of Eq. (7) can be re-written as

440
V. Skachek
3 + 4 + (2 âˆ’1)

3
2 Â· 2 âˆ’2 âˆ’2 + 2

âˆ’1

âˆ’1 = 7 ,
and therefore the bound in (7) is attained with equality for the choice Î² = 2. The
code C in Example3 is optimal with respect to that bound. We note, however, that
general simplex codes (of larger length) do not attain (7) with equality.
A slight improvement to the above bounds for both batch and PIR codes can be
obtained, if one considers simultaneously reconstruction sets for, say, two queried
batches (x1, x1, . . . , x1) and (x2, x2, . . . , x2), and studies intersections of their recon-
structionsets. Theanalysis alongthoselines was donein[38], andthefollowingresult
was derived.
Assume that
k â‰¥2(rt âˆ’t + 1) + 1 .
(8)
Denote
A = A(k,r, d, Î², Îµ) â‰œk + d + (Î² âˆ’1)

k + Îµ
rÎ² âˆ’Î² + 1

âˆ’1

âˆ’1 ,
B = B(k,r, d, Î², Î») â‰œk + d + (Î² âˆ’1)

k + Î»
rÎ² âˆ’Î² + 1

âˆ’1

âˆ’1 ,
C = C(k,r, Î², Î», Îµ) â‰œ(rÎ² âˆ’Î» + 1)k âˆ’
k
2

(Îµ âˆ’1) .
Theorem 5 ([38]) Let C be a linear [n, k, t]-batch code over F with the minimum
distance d and size of reconstruction sets at most t. Then,
n â‰¥
max
Î²âˆˆNâˆ©
$
1,min
%
t,
&
kâˆ’3
2(râˆ’1)
'()

max
Îµ,Î»âˆˆNâˆ©[1,rÎ²âˆ’Î²] {min {A, B, C}}
#
.
(9)
10
Open Questions
Below, we list some open questions related to batch and PIR codes.
1. Derive tighter bounds on the length or redundancy of batch and PIR codes, in
particular, for small alphabet size, for large values of t, or for bounded values of
r.
2. Construct new optimal or sub-optimal batch and PIR codes.
3. Do non-linear batch (or PIR) codes have better parameters than their best linear
counterparts?
4. Do non-systematic batch (or PIR) codes have better parameters than their best
systematic counterparts?
5. Propose batch and PIR codes that allow for efï¬cient reconstruction algorithms.

Batch and PIR Codes and Their Connections â€¦
441
Acknowledgements The material in this chapter has beneï¬ted a lot from discussions of the author
with his students and colleagues, including Venkatesan Guruswami, Camilla Hollanti, Helger Lip-
maa, Sushanta Paudyal, Eldho Thomas, Alexander Vardy, Hui Zhang and Jens ZumbrÃ¤gel. This
work is supported in part by the grants PUT405 and IUT2-1 from the Estonian Research Council
and by the EU COST Action IC1104.
References
1. D. Augot, F. Levy-Dit-Vehel, A. Shikfa, A storage-efï¬cient and robust private information
retrieval scheme allowing few servers (2014), arXiv:1412.5012
2. S. Bhattacharya, S. Ruj, B. Roy, Combinatorial batch codes: a lower bound and optimal con-
structions. Adv. Math. Commun. 6(2), 165â€“174 (2012)
3. S.R. Blackburn, T. Etzion, PIR array codes with optimal PIR rates (2016), arXiv:1609.07070
4. R.A. Brualdi, K. Kiernan, S.A. Meyer, M.W. Schroeder, Combinatorial batch codes and
transversal matroids. Adv. Math. Commun. 4(3), 419â€“431 (2010)
5. C. BujtÃ¡s, Z. Tuza, Batch codes and their applications. Electron. Notes Discret. Math. 38,
201â€“206 (2011)
6. V. Cadambe, A. Mazumdar, An upper bound on the size of locally recoverable codes, in
Proceedings International Symposium on Network Coding (NetCod) (2013), pp. 1â€“5
7. T.H. Chan, S. Ho, H. Yamamoto, Private information retrieval for coded storage (2014),
arXiv:1410.5489
8. Y.M. Chee, F. Gao, S.T.H. Teo, H. Zhang, Combinatorial systematic switch codes, in Proceed-
ings IEEE International Symposium on Information Theory (ISIT), Hong Kong, China (2015),
pp. 241â€“245
9. B. Chor, E. Kushilevitz, O. Goldreich, M. Sudan, Private information retrieval, in Proceedings
36-th IEEE Symposium on Foundations of Computer Science (FOCS) (1995), pp. 41â€“50
10. A.G. Dimakis, A. GÃ¡l, A.S. Rawat, Z. Song, Batch codes through dense graphs without short
cycles (2014), arXiv:1410.2920
11. A.G. Dimakis, K. Ramchandran, Y. Wu, C. Suh, A survey on network codes for distributed
storage. Proc. IEEE 99(3) (2011)
12. A. Fazeli, A. Vardy, E. Yaakobi, PIR with low storage overhead: coding instead of replication
(2015), arXiv:1505.06241
13. M. Forbes, S. Yekhanin, On the locality of codeword sysmbols in non-linear codes. Discret.
Math. 324, 78â€“84 (2014)
14. P. Gopalan, C. Huang, H. Simitchi, S. Yekhanin, On the locality of codeword symbols. IEEE
Trans. Inform. Theory 58(11), 6925â€“6934 (2012)
15. Y. Ishai, E. Kushilevitz, R. Ostrovsky, A. Sahai, Batch codes and their applications, in Pro-
ceedings of the 36th ACM Symposium on Theory of Computing (STOC), June 2004, Chicago,
IL (2004)
16. S.Kopparty,S.Saraf,S.Yekhanin,High-ratecodewithsublinear-timedecoding,inProceedings
of the 43rd Annual ACM Symposium on Theory of Computing (STOC), New York, NY (2011),
pp. 167â€“176
17. H. Lipmaa, V. Skachek, Linear batch codes, in Proceedings 4th International Castle Meeting on
Coding Theory and Applications, Palmela, Portugal, September 2014 (2014), arXiv:1404.2796
18. J.L. Massey, Threshold decoding, Technical report TR-410, MIT (1963)
19. S. Paudyal, Multi-symbol locally repairable codes, Masterâ€™s thesis, University of Tartu, June
2015 (2015)
20. R. Pellikaan, X.-W. Wu, S. Bulygin, R. Jurrius, Error-correcting codes, http://www.win.tue.nl/
~ruudp/courses/2WC09/2WC09-book.pdf
21. N. Prakash, V. Lalitha, P.V. Kumar, Codes with locality for two erasures, in Proceedings IEEE
International Symposium on Information Theory (ISIT), June-July 2014 (2014), pp. 1962â€“1966

442
V. Skachek
22. S. Rao, A. Vardy, Lower bound on the redundancy of PIR codes (2016), arXiv:1605.01869
23. A.S. Rawat, A. Mazumdar, S. Vishwanath, Cooperative local repair in distributed storage.
EURASIP J. Adv. Signal Process. (2015)
24. A.S. Rawat, D.S. Papailiopoulos, A.G. Dimakis, S. Vishwanath, Locality and availability in
distributed storage. IEEE Trans. Inf. Theory 62(8), 4481â€“4493 (2016)
25. R.M. Roth, Introduction to Coding Theory (Cambridge University Press, Cambridge, 2006)
26. N. Silberstein, A.S. Rawat, O.O. Koyluoglu, S. Vishwanath, Optimal locally repairable codes
via rank-metric codes, in Proceedings IEEE International Symposium on Information Theory
(ISIT), Istanbul, Turkey (2013), pp. 1819â€“1823
27. N. Silberstein, A. GÃ¡l, Optimal combinatorial batch codes based on block designs. Des. Codes
Cryptogr. 78(2), 409â€“424 (2016)
28. D. Stinson, R. Wei, M. Paterson, Combinatorial batch codes. Adv. Math. Commun. 3(1), 13â€“17
(2009)
29. I. Tamo, A. Barg, Bounds on locally recoverable codes with multiple recovering sets, in Pro-
ceedingsIEEEInternationalSymposiumonInformationTheory(ISIT),Honolulu,HI,June-July
2014 (2014), pp. 691â€“695
30. I. Tamo, A. Barg, A family of optimal locally recoverable codes. IEEE Trans. Inf. Theory
60(8), 4661â€“4676 (2014)
31. A. Vardy, E. Yaakobi, Constructions of batch codes with near-optimal redundancy, in Proceed-
ings IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain (2016),
pp. 1197â€“1201
32. Z. Wang, H.M. Kiah, Y. Cassuto, Optimal binary switch codes with small query size, in Pro-
ceedings IEEE International Symposium on Information Theory (ISIT), Hong Kong, China
(2015), pp. 636â€“640
33. Z. Wang, O. Shaked, Y. Cassuto, J. Bruck, Codes for network switches, in Proceedings IEEE
International Symposium on Information Theory (ISIT), Istanbul, Turkey (2013), pp. 1057â€“
1061
34. A. Wang, Z. Zhang, Repair locality with multiple erasure tolerance. IEEE Trans. Inf. Theory
60(11), 6979â€“6987 (2014)
35. T. WesterbÃ¤ck, R. Freij, C. Hollanti, Applications of polymatroid theory to distributed storage
systems, in Proceedings 53rd Allerton Conference on Communication, Control, and Comput-
ing, Allerton, IL, USA, September-October 2015 (2015), pp. 231â€“237
36. T. WesterbÃ¤ck, R. Freij-Hollanti, T. Ernvall, C. Hollanti, On the combinatorics of locally
repairable codes via matroid theory. IEEE Trans. Inf. Theory 62(10), 5296â€“5315 (2016)
37. M. Wootters, Linear codes with disjoint repair groups, unpublished manuscript (2016)
38. H. Zhang, V. Skachek, Bounds for batch codes with restricted query size, in Proceedings
IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain (2016), pp.
1192â€“1196
39. Y. Zhang, X. Wang, H. Wei, G. Ge, On private information retrieval array codes (2016),
arXiv:1609.09167
40. J. ZumbrÃ¤gel, V. Skachek, On bounds for batch codes, in Algebraic Combinatorics and Appli-
cations (ALCOMA), Kloster Banz, Germany (2015)

