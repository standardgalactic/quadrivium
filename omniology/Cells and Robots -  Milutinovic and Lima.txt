Springer Tracts in Advanced Robotics
Volume 32
Editors: Bruno Siciliano · Oussama Khatib · Frans Groen

Dejan Lj. Milutinovi´c and Pedro U. Lima
Cells and Robots
Modeling and Control of Large-Size
Agent Populations
ABC

Professor Bruno Siciliano, Dipartimento di Informatica e Sistemistica, Universitá di Napoli Federico II, Via
Claudio 21, 80125 Napoli, Italy, E-mail: siciliano@unina.it
Professor Oussama Khatib, Robotics Laboratory, Department of Computer Science, Stanford University,
Stanford, CA 94305-9010, USA, E-mail: khatib@cs.stanford.edu
Professor Frans Groen, Department of Computer Science, Universiteit vanAmsterdam, Kruislaan 403, 1098
SJ Amsterdam, The Netherlands, E-mail: groen@science.uva.nl
Authors
Dejan Lj. Milutinovi´c
Duke University Laboratory of
Computational Immunology
Hock Plaza, Suite G06
2424 Erwin Road,
Durham, NC 27705, USA
E-mail: dejan.m@duke.edu
Pedro U. Lima
Institute for Systems and Robotics
Instituto Superior Técnico
Av. Rovisco Pais
1049-001 Lisbon
Portugal
E-mail: pal@isr.ist.utl.pt
Library of Congress Control Number: 2007925208
ISSN print edition: 1610-7438
ISSN electronic edition: 1610-742X
ISBN-10 3-540-71981-4 Springer Berlin Heidelberg New York
ISBN-13 978-3-540-71981-6 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microﬁlm or in any other way, and storage in data banks. Duplication of this publication or
parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965, in
its current version, and permission for use must always be obtained from Springer. Violations are liable for
prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springer.com
c⃝Springer-Verlag Berlin Heidelberg 2007
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply,
even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and
regulations and therefore free for general use.
Typesetting: Digital data supplied by editor.
Data-conversion and production: SPS, Chennai, India
Printed on acid-free paper
SPIN: 11903550
89/SPS
5 4 3 2 1 0

Editorial Advisory Board
Herman Bruyninckx, KU Leuven, Belgium
Raja Chatila, LAAS, France
Henrik Christensen, Georgia Institute of Technology, USA
Peter Corke, CSIRO, Australia
Paolo Dario, Scuola Superiore Sant’Anna Pisa, Italy
Rüdiger Dillmann, Universität Karlsruhe, Germany
Ken Goldberg, UC Berkeley, USA
John Hollerbach, University of Utah, USA
Makoto Kaneko, Hiroshima University, Japan
Lydia Kavraki, Rice University, USA
Sukhan Lee, Sungkyunkwan University, Korea
Tim Salcudean, University of British Columbia, Canada
Sebastian Thrun, Stanford University, USA
Yangsheng Xu, Chinese University of Hong Kong, PRC
Shin’ichi Yuta, Tsukuba University, Japan
STAR (Springer Tracts in Advanced Robotics) has been promoted
under the auspices of EURON (European Robotics Research Network)
ROBOTICS
Research
Network
European
EURON
*
*
*
*
*
*
*
*
*
*
*
*

To my mother Duˇsanka and in memory of my father Ljubomir
D.M.
To my parents, Arlette and Manuel
P.L.

Preface
The text that is lying in front of you is based on my PhD thesis which I wrote
in Lisbon between 2000-2004 AD. I call it simply ”my thesis”, or sometimes
”my Lisbon story”1 instead of using the long original title ”Stochastic Model of
Micro-Agent Populations”. In recent years, I have had several opportunities to
give talks about this work. Due to diﬀerent time constraints on these talks, I had
to tell the story in ninety, thirty or ﬁfteen minutes. However, if I were to give a
ﬁve-second talk, it would come down to these three words ”Cells and Robots”,
the most appropriate title for this book.
In ”Cells and Robots” we are presenting a theoretical framework in which both
biological cell populations and large-size mobile robot teams can be modeled and
analyzed. We assume that behavior of individual agents can be described by
hybrid automata and we try to come up with mathematical objects appropriate
for the description of the population state and its evolution. This makes our eﬀort
to study multi-agent systems diﬀerent from computational models attempting
to model individual agents in detail. The signiﬁcance of our modeling framework
for real agent populations is similar to the signiﬁcance of thermodynamic laws
for ideal gases in Physics of real gases.
Using the presented theoretical development, we are able to give an alternative
and deeper insight into the expression dynamics of cell surface receptors. We also
provide one solution to the problem of controlling large-size robotic populations.
Although we see the true value of the book only in its wholeness, a reader
who is more concerned with biological applications can skip chapter 7. Similarly,
a reader who is more interested in Robotics can skip chapter 5. The reader
needs to have a prior knowledge of ordinary and partial diﬀerential equations
and a basic knowledge of the theory of probability and stochastic processes. The
reader should also be familiar with the numerical solution of partial diﬀerential
equations. Knowledge of optimization and optimal control theory is helpful for
the understanding of chapter 7.
The book is interesting for researchers and postgraduate students in the area
of Multi-Agent systems, including natural and artiﬁcial agents, such as cells and
1 After the name of the movie ”Lisbon Story” by Wim Wenders, 1994.

XII
Preface
robots, respectively. This includes researchers working in the area of the immune
system modeling, Computational Biology, Bio-Medical Engineering, Robotics,
Nano-Robotics, molecular devices, nano-technology and aero-space applications.
The monograph includes results related to stochastic hybrid systems and the
application of optimal control for partial diﬀerential equations. Therefore, it is
of certain interest to engineers and mathematicians working in the theoretical
development of control theory and its applications.
My hope is that this book will inspire readers in their own research.
Acknowledgments
I wrote this book with Prof. Pedro Lima, who not only supervised me and
helped me during the time I was working on my PhD thesis, but has also given
me continuous support in recent years. I am grateful for his strong belief that our
results have simultaneous relevance for Robotics and Biology. In recent years,
we shared some diﬃcult time trying to publish our papers resulting from my
thesis. After two-three years spent in rewriting, we ﬁnally succeeded in reaching
our goals. Then, to our great surprise, my thesis was also selected as one of the
best PhD thesis in European Robotics.
I would like to thank Prof. Michael Athans, Emeritus Professor at MIT and
currently with the Institute for Systems and Robotics in Lisbon, because I am
aware that without his help my thesis, and the same goes for this book, would
never have been written. It came as a result of the small project we had started
in my spare time, which set up my mind to interesting research topics. I am
grateful for his scientiﬁc lectures, including the one in meaning of good research.
He also introduced me to the people interested in my results in their early phase
and gave me the strong motivation to work on diﬃcult problems.
During the writing of my thesis, I got exceptional help from Prof. Michael
Athans and Dr. Jorge Carneiro, from Gulbenkian Science Foundation in Lisbon,
who played an active role in the revising of the thesis text and their contribution
is included in this book in many places. Prof. Michael Athans’ major contribu-
tions are in chapters 2, 5, 6 and partly in chapter 7, while Dr Jorge Carneiro
contributed to chapters 2 and 5.
Thanks also to Dr Jorge Carneiro for all of his biological lessons and interesting
discussions after which I always had something new to do, including forgetting
what I had previously done because it did not have a biological meaning. He
motivated me to reconsider my mathematical knowledge until we reached the
point of having the results meaningful to biologists. When working with him, I
always felt like I spent time with a friend rather than worked hard.
Specially, I would like to thank Prof. Jo˜ao Sentieiro for the invitation to come
to Lisbon and start my PhD studies, as well as for his friendly support and help
on the way.
I would not like to forget ˇZeljko Djurovi´c for his precious friendship from
the day I came to Lisbon and Prof. Naim Afgan for his company and reading
of the ﬁrst draft of my thesis. My warm appreciation goes to Lionel Lapierre

Preface
XIII
and Didik Soetanto for all after-lunch discussions about science and on general
topics. Parts of these discussions have found their place in the text of my thesis.
Another special ’thank you’ to my colleagues, S´onia Marques, Paulo Alvito,
Jo˜ao Fraz˜ao, and Rodrigo Ventura. I was really happy working with them, shar-
ing the oﬃce, the experience of learning and living in a great city called Lisbon.
My appreciation must go to Prof. Bruno Siciliano for his kind invitation to
publish this book and his help along the way.
Last, but not least, I would like to express my warmest ﬁlial feelings for my
parents, Duˇsanka and Ljubomir Milutinovi´c, for giving me their constant support
and help, without imposing any goals on my work and education. Unfortunately,
during my PhD studies my father died and will never be able to witness the
publishing of my work. Thanks to my brother Milan Milutinovi´c for his unselﬁsh
help during all these years spent around the world. And huge thanks to my wife
Dragana Milutinovi´c for her understanding, patience, emotional support and the
book proofreading.
This research was supported by the Institute for System and Robotics, Insti-
tuto Superior T´ecnico, Lisbon and grant SFRH/BD/2960/2000 from Funda¸c˜ao
para Ciˆencia e a Tecnologia (FCT), Portugal, as well as partially supported by
ISR/IST pluriannual funding from FCT, through the POS Conhecimento Pro-
gram that includes FEDER funds.
Durham, North Carolina, USA
Dejan Milutinovi´c
February 2007

Preface
This book is the nice result of a very fruitful multi-disciplinar work which in-
volved researchers from diﬀerent areas and, sometimes, considerably diﬀerent
approaches to similar problems. I use to tell my students that the beneﬁts of
such an approach clearly outstand the possible drawbacks, such as the time taken
to explain to others concepts which are more or less straightforward for experts
in our area, and this work is a clear example of such a statement.
Dejan’s thesis was also a good example of a typical PhD student work path.
When he started working with me, I gave him a topic related to robotic task
modeling by discrete event systems. He actually did some work in that direction
and we even published a paper about it, but ﬁnally he felt he should get involved
in something that would provide a clear contribution for humankind, e.g., on
health-related issues. And so he did: motivated by some class work done with
Michael Athans and under the advice of Jorge Carneiro, he explored the immune
system world and managed to excite me about it as well. After the thesis and
the antithesis, the synthesis ﬁnally came when, one day, discussing his work,
we thought that exploring a mix of discrete event and continuous state space
time-driven modeling might be the right way to go to model cell population
dynamics. We even went back to Robotics, when we ﬁnally concluded that what
Dejan had developed could deﬁnitely be applied to the modeling and control of
robotic swarms!
Overall, it was a great experience to supervise Dejan and his enthusiasm about
his work. I hope this book will encourage others to pursue this research line, and
act as a showcase of our friendship.
Lisboa, Portugal
Pedro U. Lima
February 2007

Foreword
At the dawn of the new millennium, robotics is undergoing a major transforma-
tion in scope and dimension. From a largely dominant industrial focus, robotics
is rapidly expanding into the challenges of unstructured environments. Interact-
ing with, assisting, serving, and exploring with humans, the emerging robots will
increasingly touch people and their lives.
The goal of the new series of Springer Tracts in Advanced Robotics (STAR) is
to bring, in a timely fashion, the latest advances and developments in robotics on
the basis of their signiﬁcance and quality. It is our hope that the wider dissemina-
tion of research developments will stimulate more exchanges and collaborations
among the research community and contribute to further advancement of this
rapidly growing ﬁeld.
The monograph written by Dejan Milutinovi´c and Pedro Lima presents an
original theoretical framework in which both biological cell populations and
large-size mobile robot teams can be modeled and analyzed. This unique inter-
disciplinary work has explored methods for discrete-event and time-continuous
systems, leading to useful results for modelling and control of robot swarms. As
such, the book has a wide interest for scholars in the area of multi-agent systems,
including computational biology, biomedical engineering, nanorobotics and even
aerospace engineering.
Remarkably, the doctoral thesis at the basis of this monograph was a ﬁnalist
for the Fifth EURON Georges Giralt PhD Award devoted to the best PhD thesis
in Robotics in Europe. A very ﬁne addition to the series!
Naples, Italy
Bruno Siciliano
March 2007
STAR Editor

Contents
1.
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Analogy Between an Individual Robot and a Cell . . . . . . . . . . . . .
2
1.2
Robot Teams and Cell Populations . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.3
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.4
Book Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.
Immune System and T-Cell Receptor Dynamics of a
T-Cell Population . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
2.1
Surface T-Cell Receptor Dynamics in a Mixture of Interacting
Cells . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
2.2
T-Cell Receptor Triggering Experimental Setup . . . . . . . . . . . . . .
12
2.3
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
3.
Micro-Agent and Stochastic Micro-Agent Models . . . . . . . . . . .
15
3.1
Problem Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
3.2
T-Cell Hybrid Automaton Model . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
3.3
T-Cell Population Hybrid System Model . . . . . . . . . . . . . . . . . . . .
18
3.4
Micro-Agent Individual Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
3.5
Stochastic Micro-Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
4.
Micro-Agent Population Dynamics . . . . . . . . . . . . . . . . . . . . . . . . .
25
4.1
Statistical Physics Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
4.2
Micro-Agent Population Dynamic Equations . . . . . . . . . . . . . . . . .
27
4.3
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
5.
Stochastic Micro-Agent Model of the T-Cell Receptor
Dynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
5.1
T-Cell Receptor Dynamics: A Numerical Example . . . . . . . . . . . .
35
5.2
Micro-Agent vs. Ordinary Diﬀerential Equation Model . . . . . . . .
40
5.3
T-Cell Receptor Expression Dynamics Model Test . . . . . . . . . . . .
42
5.4
T-Cell Receptor Dynamics in Conjugated State . . . . . . . . . . . . . .
46

XVIII
5.4.1
Model Hypothesis Test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
5.4.2
Parameter Identiﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
5.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
6.
Stochastic Micro-Agent Model Uncertainties . . . . . . . . . . . . . . .
53
6.1
Discrete Parameter Uncertainty Case . . . . . . . . . . . . . . . . . . . . . . .
54
6.2
Continuous Parameter Uncertainty Case. . . . . . . . . . . . . . . . . . . . .
60
6.3
Numerical Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
6.4
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
7.
Stochastic Modeling and Control of a Large-Size Robotic
Population. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
7.1
Robotic Population Mission Scenario . . . . . . . . . . . . . . . . . . . . . . . .
68
7.2
Robotic Population Position Prediction . . . . . . . . . . . . . . . . . . . . .
71
7.3
Robotic Population Optimal Control Problem . . . . . . . . . . . . . . . .
73
7.4
Example of Using the PDE Minimum Principle for Robotic
Population Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
7.4.1
Complexity of Numerical Optimal Control . . . . . . . . . . . . .
82
7.4.2
Numerical Optimal Control . . . . . . . . . . . . . . . . . . . . . . . . . .
84
7.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
8.
Conclusions and Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
A.
Stochastic Model and Data Processing of Flow Cytometry
Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
A.1 Probability Density Estimation Algorithm . . . . . . . . . . . . . . . . . . .
99
A.2 Richardson-Lucy Deconvolution Algorithm. . . . . . . . . . . . . . . . . . .
103
B.
Estimated T-Cell Receptor Probability Density Function . . .
107
C.
Steady State T-Cell Receptor Probability Density
Function and Average Amount . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
111
D.
Optimal Control of Partial Diﬀerential Equations . . . . . . . . . . .
113
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
117

1. Introduction
Understanding development and functions of living organisms continuously occu-
pies the attention of science. Consequently, mathematical modeling of biological
systems is a recurrent topic in research. Recently, this ﬁeld has become even
more attractive due to technological improvements on data acquisition that pro-
vide researchers a further insight into such systems. Technology to read DNA
sequences, or to observe protein structures along with a variety of microscopy
methods, has enabled collecting large amounts of data around and inside the
cell, classically considered as the smallest chunk of life.
In this book, we are particularly concerned with cells that have an active role
protecting living organisms from infections caused by foreign bodies, constituting
the immune system. The role of the immune system is to continuously monitor
the organism, to recognize an invader, to generate a response that will clear the
invader and to help healing the damaged tissues. The major components of this
chain of action are motile cells. Cells motility1 is a property intrinsic to their
function, i.e., to ﬁght against infections in the right place at the right time during
an immune response. While we are quite certain about the places where cells are
produced and where they reside during their life cycle, the question of how they
modulate their motion and bio-chemical activity against external stimuli still
presents an active ﬁeld of research.
Apparently, the immune system cells are autonomous agents. On the other
hand, an autonomous mobile robot can be seen as the most natural mechanic
analogy of the cell. Hence, we ﬁnd studies about the cell bio-chemical signal pro-
cessing, intercellular communication and cell reactive behavior in close relation
to signal processing, communication and control for mobile robots. Investiga-
tion of the cell-robot analogy has the potential to inﬂuence future biological
research, but also to provide the guidelines for the development of a system-
based approach to describe and analyze complex multi-agent/robot systems.
In the theoretical development presented in this book, we investigate one
aspect of the cell-robot analogy, providing a novel approach to the study of
large-size agent populations. Our approach points at understanding how individ-
ual agent dynamical behavior propagates to the population dynamics. The pre-
sented concepts and mathematical tools are general enough and provide results
1 Motility - ability to move spontaneously and independently [22].
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 1–8, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

2
1. Introduction
of potential interest for multi-agent system applications. Multi-Agent systems
(MAS), dealing with either virtual or real (robotic) agent populations, are cur-
rently a subject of major interest in engineering and computer science literature.
Consequently, biological experiments involving cell populations, that are com-
monly used to understand cell properties, can be considered as test beds for the
control strategy development for large-size agent populations. Conversely, tests
that would not be possible on real organisms, can be made on robots whose
behavior is designed to approximate biological models of biological populations
behavior.
1.1
Analogy Between an Individual Robot and a Cell
To illustrate the analogy between an autonomous mobile robot and a motile
immune system cell, we will consider a robot which is able to avoid obstacles
while moving towards a goal location, and a cell which is able to move in the
direction of a chemokine source. The basis for consideration of this analogy is
the similarity between the ultrasonic sensor system of a mobile robot and cell
receptors expressed on the cell surface.
Fig. 1.1. Mobile robot endowed with ultrasonic sensors and an omnidirectional vision
system. a) The robot b) Birds-eye view inside of the robot. (Institute for Systems and
Robotics, Lisbon).
Figure 1.1 shows the robot equipped with a ring array of ultrasonic sensors.
This system measures the proximity of the robot to obstacles in all directions.
Due to its robustness and simplicity, this sensor system is usually installed on
mobile robots to supplement more sophisticated vision systems.
Each ultrasonic sensor of the array is installed on the robot surface (see
Figure 1.1) and the robot on-board computer reads distance measurements from
each ultrasonic sensor. For each sensor in the array, the robot keeps the informa-
tion about the direction and the measured distance to obstacles. The measure-
ments are always positive and limited by some maximal distance. If the maximal

1.1 Analogy Between an Individual Robot and a Cell
3
distance is measured by a sensor, then the measurement is interpreted as ”no
obstacle in that direction”.
The cell senses the environment using the receptors expressed on the surface
(see Figure 1.2). Diﬀerent type of receptors are sensitive to diﬀerent kinds of
bio-chemical environmental substances. Here, we speak only about the receptors
with ability to sense chemokines. The chemokine is a substance that attracts the
cell, which following the chemokine traces ﬁnds its way to diﬀerent organs in the
body. When, for example, the cell ”decides” to move towards the lymph node,
it expresses receptors that can sense the corresponding chemokine, showing the
direction to its destination. Similarly, if the cell ”wants” to leave the lymph
node, then the cell expresses its receptors and, after some fumbling around,
ﬁnds its way out. This explanation corresponds to the widely accepted idea that
expressed receptor types correlate with the cell behavior. Therefore, the cell
function is mainly recognized based on the receptors it expresses.
Fig. 1.2. T-cell structure: the T-cell receptors are expressed on the cell surface; the
ﬁgure is based on a general cell structure [30]
The working principles of the presented robot and the cell sensory systems are
quite diﬀerent. However, in both cases, the sensory systems are omnidirectional,
i.e., they sense the direction of the space in which the robot and the cell can
move; in other words, they provide the same type of information. In the mobile
robot case, the robot takes an action based on all available information, includ-
ing the ultrasonic sensory system and decision making process corresponding
to the robot mission task. We speculate that the cell does the similar kind of
information processing before it performs an action.
This is along the idea of reverse engineering of intracellular processes. In order
to understand the cellular behavior, experimental immunologists consider cells
of speciﬁc phenotype and follow their behavior within a controlled scenario.
Mostly they follow the cell division, cell receptors or some bio-chemical marker
expression. Based on collected data, they try to understand how the cell behaves.
The reverse engineering of intracellular processes directing the cell behavior is
diﬃcult, and this diﬃculty is easy to explain based on the analogy between the
robot and the cell.
Let us imagine that someone provides us a brand new mobile robot and asks
us to understand in full detail how it works without even telling us what kind
of tasks the robot is able to perform. While the mechanical structure of the

4
1. Introduction
robot has some relevance in inferring the kind of applications which the robot is
designed for, the electronic hardware structure and the relation among electrical
signals controlling the robot, provide a little insight into the structure of the
robot control software.
Although reverse engineering of an individual cell seems important, it ignores
the fact that cells are rarely under physiological conditions isolated from other
cells. To have a complete picture of the cell functionality, its communication and
cooperative behavior with other cells must be considered as well. In the next
section, we deal with cell population models and the similarity between robot
teams and cell populations.
1.2
Robot Teams and Cell Populations
One way to disclose the analogy between a robot team and a cell population
is through ordinary diﬀerential equation (ODE) models which are exploited to
describe the population dynamics in both cases. Inspired by the Lotka-Voltera
predator-prey equation, ODEs are used to model anti-viral immune responses
where, in the simplest form, the immune system cells play the predator’s role and
the virus or infected cells play the prey’s role. More realistic ODE models of the
immune system response include diﬀerent cell types playing the roles of eﬀector
cells, memory cells, helper cells, naive cells, etc. These ODE models describe
the cell amounts in each speciﬁc cell type, each of them dedicated to a speciﬁc
task. The cell, just like a robot, can switch from one task to another. Hence,
the similarity of the immune response ODE models to models of task allocation
among the robots of a robot team is not surprising. Likewise, the analogy between
the cell death and the robot failure is not unexpected; in both cases the agent
remains dysfunctional. The major diﬀerence between the robot team and the cell
population is the result of the state-of-the-art electro-mechanical robot design
not enabling a property similar to the cell division.
Figure 1.3a is a computer-generated image2 of the lymph node, as seen by
the use of two-photon microscopy [51, 52]. It shows a dendritic cell which is an
antigen-presenting cell (APC) and T-cells. The APC expresses, on its surface,
pieces of pathogen protein, so-called antigen, signaling the presence of pathogen,
for example of virus or bacteria. The contact of APCs and their interaction with
T-cells is of vital importance for the start of the immune system response. With-
out any infection, the T-cell moves randomly around the lymph node and scans
APCs for the presence of the antigen. However, when an infection is present,
APCs bearing antigen peptides drain to the lymph node, causing a great chance
of a T-cell meeting such APCs. When this happens, the T-cell matures and
starts the immune response, but this does not happen straightforwardly. Actu-
ally, it seems that the T-cell must conjugate to more APCs, before it develops a
longer-lasting contact to the APC, stimulating the T-cell enough to develop an
2 The image cells morphology is modeled by the point light sources convoluted with
the samples of 2D Gaussian distribution. The source positions are sampled from the
numerical solution of 2D stochastic diﬀerential equations.

1.3 Related Work
5
Fig. 1.3. a) Computer-generated image of a cellular interaction inside the lymph-
node: T-cells (red) scan dendritic cells (green) (computer simulation by D. Milutinovi´c)
b) Robotic team (red) collecting pucks (green)
immune response. Consequently, the more the T-cells, the faster they scan the
APCs inside the lymph node, and the earlier they recognize the presence of the
antigen and possibly develop a strong immune response. However, while scan-
ning, T-cells also compete for APC surface sites providing stimulating signals
to them. It is also worth mentioning that sometimes T-cells are not able to get
straight to the APC sites because they must avoid other T-cells.
A similar kind of scenario is studied in Robotics [44] in order to understand
the cooperative behavior and task allocation of a robotic team (see Figure 1.3b).
In this scenario, robots are moving inside a limited operating space. The robot
team mission is to locate and collect pucks that are distributed over the operat-
ing space. To succeed in that task, they should also avoid collisions with their
teammates and conﬂicts regarding common resources.
The main distinction between biological and robotic examples lies in the fact
that cells move in three dimensions while agents in the robotic case move in a
two dimensional space. In all other aspects, biological and robotic examples are
analogous, since the cell division, a major diﬃculty in the cell-robot analogy, does
not appear in the early phase of the immune response we described in this section.
1.3
Related Work
Social insect communities, such as ant and bee colonies, are among the ﬁrst
investigated large-scale multi-agent systems [11, 17]. They are an example of self-
organized systems [59], where the colony behavior emerges from the behavior of
individual insects. The main property of the insect colonies is that not only does
their behavior seem intelligent, but also robust to environment changes and the
colony size. This motivated the research on virtual [23, 65, 84] and robot [4, 6]
agents which applies concepts found in biological systems to multi-agent systems.

6
1. Introduction
For the analysis of large-size robotic populations [32], control performance
[74] and formation feasibility [73], deterministic models are used. These models
are related to the robotic formation, i.e., the relative positions of the robots
in the operating space. On the other hand, the task allocation and the task
performance of groups of robots are modeled under a probabilistic framework in
[1, 10, 29, 48, 71]. The ODE models resulting from this framework are in close
relation to the ODE models used in the immune system modeling. To illustrate
this, we use, in the previous section, the robotic scenario from [43, 44, 49], where
the same framework is applied.
The modeled level is the main source of diﬀerence among alternative immune
system modeling approaches. The immune system behavior can be modeled at
the level of bio-molecular interactions, signal transduction, cell-to-cell interac-
tion, lymphocyte population dynamics, or the immune response to virus and bac-
teria infections. ODE models are used to model the anti-viral immune response
[9, 60, 61, 82], population dynamics of lymphocytes in which the interaction
is based on idiotypic networks [58, 62, 72, 80], resource competition, or more
complex resource competition and suppression interaction [7, 12, 37, 41, 42].
In the case when immune system phenomena show dependence on spatial
heterogeneity, partial diﬀerential equation (PDE) models are applied, such as
in the modeling of immunological synapses [14, 83] or repertoire dynamics in
”shape space” [67]. Wide use of ODE and PDE models is preferable because of
developed and well-known mathematical properties of their solutions. However,
the problem with diﬀerential equation models is a large number of (physically
meaningful) parameters. Moreover, the parameter values strongly depend on
the proper scaling of variables, and some of them are diﬃcult to identify by
experiments.
Assuming that the parameters of interaction are not of great importance in
understanding robust immune system mechanisms, which might be correct in the
case of signal transduction and cells activation, networks of interconnected au-
tomata, i.e., Boolean network models, have been introduced [36]. Using Boolean
network, feedback loops and stationary shapes of those loops can be calculated.
Along this line of reasoning, in the case of spatial heterogeneity, cellular au-
tomata models are used in [16, 40, 70]. In immunological synapse modeling, the
space is physical space and in idiotypic networks, the space is ”shape space”.
The list of references relating to modeling of multi-agent systems and the im-
mune system presented above is far from being complete, but it gives a ﬂavor of the
state-of-the-art in both ﬁelds. In this book we use a hybrid system approach [76]
to modeling. This approach has been used to model intra-cellular bio-molecular
interactions [3]. The model employed is a deterministic hybrid system model of
a single interaction, and the authors conclude that studying the bio-molecular
interaction using stochastic hybrid systems [35] is a challenging issue.
One of the major problems of modeling in immunology is to derive macro-
scopic properties of the system from the properties and interactions among the
elementary components [62]. The hybrid system approach presented in this
monograph is an approach to such problems. The motivation for studying this

1.4 Book Outline
7
problem comes from the modeling of T-cell receptors (TCR) expression dynam-
ics. The available models of TCR expression of the T-cell population interacting
with APCs are ODE models [5, 69, 83].
Inspired by the analogy between a biological cell and a robot, we also ﬁnd
challenging to exploit the hybrid system modeling approach for a model-based
controller of a large-size robotic population. As a result, we obtain the centralized
controller which is based on the Pontryagin-Hamiltonian [21] optimal control
theory for PDEs [46] and provides control of the population space distribution
shape. The centralized optimal controller we introduce here is based on a new
concept for the control of one class of stochastic hybrid automata, where the
state probability density function of stochastic hybrid automaton is controlled.
The controller is truly optimal and is not based on discrete approximations [35]
or piecewise aﬃne approximations [57]. However, as in classical optimal control
[50], it is an open-loop controller and there is no warranty that the control can
be expressed analytically. For the numerical computation of optimal control,
discrete approximations in time and space are necessary.
1.4
Book Outline
The presented research has a strong multi-disciplinary character. It is motivated
by the investigation of the TCR expression dynamics of a T-cell biological popu-
lation and the results are extended towards a system approach to study the pop-
ulation composed of a large number of individual agents. A brief summary of the
contents of the eight book chapters, besides the current Introduction, follows:
Chapter 2. Immune system and TCR dynamics of a T-cell population.
This chapter introduces the problem which motivated this work. The basic bi-
ological facts about the TCR expression and previous modeling eﬀorts based
on ODE equations are described. We conclude that existing ODE models are
unsatisfactory in relating the modeled dynamics of the average TCR expression
of the T-cell population and the TCR expression dynamics of the individual
T-cells. We also present the experimental setup which is used in the veriﬁcation
of those ODE models. Taking into account that by using only average values of
measurements we throw away potentially useful information, we again arrive to
the conclusion that for getting better insight into the TCR expression dynamics
a diﬀerent modeling approach has to be examined.
Chapter 3. Micro-Agent and Stochastic Micro-Agent Models. Given the
biological facts, the hybrid systems framework appears as a natural framework
for modeling of the TCR expression dynamics. In this chapter, hybrid system
models of a T-cell and of a T-cell population are introduced. The model of the
T-cell motivates the formal deﬁnition of a Micro-Agent. We use the Micro-Agent
model of an individual T-cell to build a T-cell population model, where the T-cell
dynamics of individual cells is decoupled from the complex population dynamics.
By applying a stochastic approximation to this population model, a Stochastic
Micro-Agent model of the population is developed.

8
1. Introduction
Chapter 4. Micro Agent Population Dynamic Equations. In this chap-
ter, we discuss the Maxwell-Boltzmann distribution to relate micro- and macro-
dynamics of interactions. The idea underlying the probabilistic description of
the relation between micro- and macro-dynamics is borrowed from statistical
physics and is used for the development of the mathematical analysis of the
agents population. The PDE describing the probability density function dy-
namics of a Stochastic Micro-Agent, whose discrete state can be modeled as a
Markov Chain, designated as a Continuous Time Markov Chain Micro-Agent
(CT MCμA), is derived.
Chapter 5. Stochastic Micro-Agent Model of TCR dynamics. The ap-
plication of the developed theory to study the TCR expression dynamics is pre-
sented in this chapter. First, we present a numerical example which illustrates
the application of the PDE derived in Chapter 4. Using this example we discuss
the qualitative diﬀerence between the results obtained by the ODE and PDE
models based on the same physical assumption regarding TCR dynamics. Next,
we perform the steady state analysis of the PDE which provides us with the
capability to predict the TCR steady state distribution of the T-cell popula-
tion. The predicted steady state is compared with experimental data. Finally,
we analyze experimental data which allows us to study only the TCR expression
down-regulation. Using our model, we test linear and quadratic hypotheses of
the TCR down-regulation and we identify the parameters of the dynamics.
Chapter 6. Stochastic Micro-Agent Model Uncertainties. In this chapter,
motivated by the problem of modeling diversity in the T-cell APC interaction,
we develop a method to handle a CT MCμA continuous dynamics parameter un-
certainty. The method is developed towards the systematic modiﬁcation of the
original CT MCμA to the CT MCμA model which incorporates the parameter
uncertainty. The parameter uncertainty is described by its probability density
function (PDF). Discrete and continuous parameter uncertainties are discussed.
Chapter 7. Stochastic Modeling of a Large Size Robotic Population.
Here we apply our approach to the modeling of a large population of robots.
To motivate this development, we introduce an example of a robotic population
modeled by a Stochastic Micro-Agent. For this example, we predict the evolution
of the robots position probability density function. This prediction illustrates
that diﬀerent parameters of the stochastic behavior lead to diﬀerent densities of
the robotic population in probabilistic space. Based on this, we introduce the
optimal control problem of controlling the shape of robots position PDF, and
the application of Minimum Principle for PDEs to this problem is discussed.
Chapter 8. Conclusions and Future Work. In this chapter, we present the
conclusions of this research and some possible directions for future work based
on the theory and examples given in this book.

2. Immune System and T-Cell Receptor
Dynamics of a T-Cell Population
Figure 2.1 presents the two parts of the immune system [33]. The Innate immune
system is made of cells and molecules that are genetically encoded and co-evolve
with pathogens1. It is inherited as such and it represents the ﬁrst line of the
organism defense. It can recognize some pathogen, such as virus or bacterium,
Fig. 2.1. Innate and Adaptive Immune System
and remove them within several hours. However, the diversity of pathogens it
can recognize is limited and some pathogen can escape the defenses of the innate
immune system. Then the pathogens are faced with the response of the adap-
tive immune system. The adaptive part is able to recognize a larger diversity of
possible antigen2 carried by pathogen. During the invasion phase the population
1 Pathogen - any disease-producing agent (especially a virus or bacterium or other
microorganism) [22].
2 Antigen - any substance (as a toxin or enzyme) that stimulates an immune response
in the body (especially the production of antibodies) [22]. In our context, piece of
protein constituting a pathogen.
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 9–14, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

10
2. Immune System and T-Cell Receptor Dynamics of a T-Cell Population
of pathogen increases. The adaptive immune system is programmed to recog-
nize the antigen and produce enough eﬀector cells, speciﬁc to the pathogen,
to suppress and eliminate the pathogen population. That process typically takes
several days. During this time, the pathogen could be causing considerable harm,
and that is why the innate immunity is so essential.
The adaptive immunity is orchestrated by diﬀerent types of T-cells . The
life-history of these cells is critically dependent on signals via their receptors
expressed on the cell surface. T-cell receptor (TCR) signals are involved in the
positive and negative selection of immature T-cells in the thymus [77], and also in
the survival, activation, diﬀerentiation, and cell cycle progression of mature cir-
culating T-cells [63, 81]. Understanding of immune responses and the dynamics
of T-cell populations, therefore, requires a basic understanding of the signaling
processes.
An antigen-presenting cell (APC) is the immune system cell which processes
an antigen and transfers information about it to the T-cell. Using this informa-
tion, the T-cell builds an immune response which generate the cells able to clear
the pathogen. The mechanism initiating this information transfer is called TCR
triggering and its place in the immune system feedback loop is illustrated by the
circle in Figure 2.1. As a consequence of this ”information transfer”, the TCR
expression level of the T-cell surface decreases. The amount of TCRs on the sur-
face of the T-cell is a measure of the intensity of this interaction. This amount
changes with time and understanding of the dynamics of this change is an im-
portant step towards understanding of the immune response dynamics. To study
the TCR triggering mechanism and dynamics of the TCR down-regulation, biol-
ogists use populations of T-cells exposed to APCs. In this book, we deal with the
modeling of the TCR expression level dynamics of such populations. Throughout
the book we will call the TCR expression level shortly as TCR expression and
its corresponding dynamics TCR expression dynamics, or just TCR dynamics.
This chapter starts by the description of a minimal biological system featur-
ing the TCR triggering dynamics and referencing the works concerned on the
modeling of TCR down-regulation dynamics of T-cell population in Section 2.1.
In Section 2.2 we continue with the explanation of the experimental setup which
is used for the veriﬁcation of the proposed models.
2.1
Surface T-Cell Receptor Dynamics in a Mixture of
Interacting Cells
T-cell receptor signals are triggered by TCR-ligands, MHC-peptide complexes,
which are membrane molecules presented by specialized cells, called antigen-
presenting cells (APCs), see Figure 2.2. TCR triggering requires that the T-cell
and the APC form a conjugate which enables that the receptor and the ligand
interact with each other. Thus, a realistic model of TCR signaling should take
into account not only the dynamics of the components of the signaling cascades,
but also the dynamics of the processes of APC-T-cell conjugate formation and
conjugate dissociation.

2.1 Surface T-Cell Receptor Dynamics in a Mixture of Interacting Cells
11
Fig. 2.2. T-cell receptor triggering: T-cell, T-cell receptor (TCR), antigen-presenting
cell (APC), peptide-MHC complex
The minimal biological system with the properties we are interested in is
a homogeneous mixture of interacting T-cells and APCs which present TCR-
ligands, depicted in Figure 2.3. In order to model biological experiments, we
consider that the T-cells and APCs are moving randomly under the forces that
are the result of intra-cellular or environmental conditions. Because of that, we
assume that T-cells and APCs form transient conjugates. We should point that
when we have started our theoretical development, this assumption was not
based on ﬁrm biological evidences. Therefore, it was under question whether our
theoretical work had any value in describing biological reality. However, recent in
vivo experiments, where a two-photon microscopy has been exploited to observe
the motion of T-cells inside the lymph node [51, 52], has resolved this issue. In
physiological conditions of the lymph node, the T-cells move randomly and form
transient conjugates with APCs.
The consequence of the TCR signaling, that can take place after the conju-
gate formation, is a decrease in the cell surface, i.e., the cell membrane TCR
expression resulting from internalization of those membrane TCRs that have
been triggered by the ligand. When the two cells dissociate, the TCR amount is
slowly restored or remains constant.
In an attempt to understand the eﬀects of the recurrent APC-T-cell interac-
tions in the induction of self-tolerance and in the regulation of T-cell population
sizes this kind of processes has been simulated [68]. Although this analysis pro-
vided some insight into these processes, the scope of conclusions was limited by
the fact that no fully analytical model was derived.
Available analytical models are ODE models of the average TCR expression
of the population [5]. To derive such a type of model, PDE equations [83] and
a mean ﬁeld approach [69] are used. However, in both models the assumption
that the dynamics of the T-cell population can be explained using the concept of
an average cell is used. This means that the population TCR average expression
dynamics is considered equivalent to the dynamic responses of an average cell. As
this assumption is unrealistic, diﬀerent modeling approaches, which will properly
treat relations between the TCR expression dynamics of individual T-cell and
the TCR average expression of the population, must be considered.

12
2. Immune System and T-Cell Receptor Dynamics of a T-Cell Population
not conjugated
conjugated
not conjugated
T-Cell
APC
Legend:
Fig. 2.3. T-cell population surrounded by the APCs: T-cells can be conjugated or
non conjugated to APC [53, 54, 56], c⃝2003 IEEE
The models in [69] and [83] are tested against experimental data [75], where
the CD3 receptors expression level is used as an indirect measure of the amount
of all receptors present on the T-cell surface. The experimental setup which is
used to produce experimental data analyzed in this book is described in [45, 75]
and presented in the following section.
2.2
T-Cell Receptor Triggering Experimental Setup
The biological experimental setup, which is used for TCR expression dynamics
recording, consists of a few identical samples of T-cell-APC population and a
special device called Flow Cytometry scanner (FCS). The experimental setup, as
well as the Flow Cytometry scanner working principle, are depicted in Figure 2.4.
The Flow Cytometry scanner has a special construction which exposes one cell
at a time to the laser light. For diﬀerent type of analysis, diﬀerent wavelengths
can be applied. The intensity of scattered light, or light emitted by the cell
after exposure (ﬂuorescence), can be recorded in digital format after an analog
to digital conversion. In our experimental setup, this ﬂuorescence intensity has
a particular meaning because the TCR molecules are labeled by a ﬂuorescent
probe. Therefore, the ﬂuorescence intensity corresponds to the TCR amount
expressed on the T-cell. By exposing all the cells from the sample to the scanner,
the TCR expression of each cell and the average expression of the TCRs within
the sample can be estimated.
Fluorescent light intensity measurements of the population can be represented
in the form of the distribution where on the x axis is the light intensity and y
axis is the quantity of T-cells with a given light intensity x. An example of T-cell
population measurements is given in Figure 2.5.
Once the sample has been exposed to the FCS, it is destroyed and cannot be
re-used for another measurement. Therefore, experimentalists make a series of
identical T-cell-APC mixtures. Interaction within all the samples start at the

2.2 T-Cell Receptor Triggering Experimental Setup
13
Fig. 2.4. Experimental setup and Flow Cytometry scanner working principle :
W - T-cell container, S - scattered light, T - transmitted light, E - emitted light,
A/D - analog to digital converter, t1, t2,. . . tK- the samples which are exposed to the
scanner at time t1, t2,. . . tK
Fig. 2.5. Flow Cytometry measurements distribution of one T-cell population, by Lino
[45]; the full scale from 0-1023 covers 4 decades
same time. Under these conditions, we assume that exposing the ﬁrst sample to
FCS at time t1, the second sample at time t2 etc., produces a sequence equivalent
to the non-destructive observation of a single sample at times t1, t2,. . . tK. See
Figure 2.4.
Using this experiment, the average TCR expression sequence at times t1,
t2,. . . tK is calculated and compared to the sequences predicted by the ODE
models. It is obvious that data samples used in the ODE models parameter
identiﬁcation are the average of TCR expression of a few thousand cells, i.e., the
average of a few thousand measurements. Considering only the average value of
measurements means that we throw away a lot of potentially useful information

14
2. Immune System and T-Cell Receptor Dynamics of a T-Cell Population
which is part of the Flow Cytometry measurement distribution of the cell popu-
lation. To incorporate such information in a mathematical model, we come again
to the conclusion that a diﬀerent approach to the study of TCR expression dy-
namics should be considered.
2.3
Summary
In this chapter, the basic biological facts about TCR triggering and TCR down-
regulation are presented. The previous studies are based on the ODE models of
the average TCR expression of the population. To verify this kind of models,
the average value of a large amount of data is considered. Therefore, we ﬁnd
interesting to exploit these data and investigate how the biological facts about
the individual dynamics of TCR expression can be used to make inference about
the average TCR expression dynamics of the population.

3. Micro-Agent and Stochastic Micro-Agent
Models
In this chapter, a hybrid automata approach to the modeling of individual agents
and population behavior is presented. A hybrid system consists of an event-
driven discrete state component and a time-driven continuous-state component
[76]. Hybrid automata are particular cases of hybrid systems, where the discrete-
state dynamics is modeled by a ﬁnite-state automaton. The application of a hy-
brid automata approach is motivated by the discussion in Section 3.1. The model
of an individual agent is called Micro-Agent [53, 56]. This model is illustrated
by the T-cell hybrid automaton model [54] in Section 3.2. This biologically in-
spired modeling problem is resumed in Section 3.3, where the Micro-Agent-based
model of a T-cell population is presented. This population model includes the
full population complexity. Approximating this complexity by stochastic model-
ing leads to a Stochastic Micro-Agent model. Biologically motivated Micro-Agent
and Stochastic Micro-Agent are formally deﬁned in Section 3.4 and Section 3.5,
respectively.
3.1
Problem Formulation
Our problem is motivated by the search for modeling methods which will give us
better insight into the relation between dynamics of individual cells and cell pop-
ulation dynamics. In the problem formulated below, we withdraw the average cell
concept and propose to replace it by population macro-dynamics, which results
from the propagation of the individual cell dynamics, i.e., micro-dynamics.
Interaction between T-cell and APC starts when they become conjugated
due to a random encounter. Thus, considering single T-cell, the event conjugate
formation, is a random event. Similarly, T-cell and APC are also subject to the
opposite process, dissociation, when the interaction between T-cell and APC
ends. Although we can not easily conclude whether dissociation is a random
or deterministic process, we still can deﬁne event conjugate dissociation, which
happens at the time point when the interaction between T-cell and APC ceases.
Based on this discussion, it is clear that the behavior of an individual T-cell can
be described by a hybrid automaton with discrete states conjugated and free. In
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 15–23, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

16
3. Micro-Agent and Stochastic Micro-Agent Models
each discrete state the TCR expression of an individual T-cell changes and the
transition between the discrete state is the result of conjugate formation and
conjugate dissociation events.
The complete TCR expression dynamics of the T-cell population is com-
posed of TCR expression dynamics of each individual T-cell and the dynamics
of the cell motion, which leads to conjugate formation and conjugate dissocia-
tion events. Therefore, the TCR expression dynamics of the T-cell population
is complex due to the amount of variables necessary to describe the state of
the complete population. If we assume a 3D model of motion, we need 6 state
variables per T-cell just to explain the position and velocity of T-cell. We need
also at least one state variable, if the state of TCR expression dynamics is the
amount of TCRs, for TCR expression dynamics state, and one discrete variable
that contains information on whether the T-cell is conjugated or free. In total,
this means, at least, 8 state variables per T-cell. A population of 1000 T-cells
requires a state vector of the dimension 8000. Therefore, to make a detailed
simulation of the 1000 T-cell population, we need to update, at each step, 8000
variables. However, the problem of how the individual cell TCR expression dy-
namics propagates to the population statistics, such as the average value or the
variance of the population TCR expression, could still be answered.
The problem of matching the individual state of TCR dynamics to the pop-
ulation observation data is even more diﬃcult than the problem of simulation.
Taking into account only a discrete part of the state space, the population can
be in about 10300 diﬀerent states. If we would like to match some experimental
data to our model, we should estimate in which of these 10300 states our system
is, at each time instant, clearly an impossible task.
From a system theory point of view, the relation between the individual be-
havior of the TCR expression level, after the triggering, and its link to the
observation of the experiments made with the T-cell population, leads to the
following question:
How do the individual cell dynamics aggregate to the macro dynamics
of the population and experimental measurements?
Since the individual dynamics describes the population behavior at the micro
level, the individual dynamics will be called micro-dynamics in the sequel. A sys-
tematic approach to study the relation between the micro- and macro-dynamics
of a large population of individuals, such as biological cell populations or multi-
robot populations, is a major problem investigated in this work.
3.2
T-Cell Hybrid Automaton Model
Considering the TCR expression dynamics, the state of the T-cell is composed
of continuous and discrete states. The continuous state x is related to the TCR
expression dynamics while the discrete state q describes whether the T-cell is
conjugated to an APC, or not. Thus, hybrid automata methodology appears as
a natural modeling framework for the biological T-cell population.

3.2 T-Cell Hybrid Automaton Model
17
Fig. 3.1. Hybrid automaton model of the T-cell - APC interaction, x(t) - TCRs
expression level, u(t) - event sequence, discrete states q: 1 - never conjugated, 2 -
conjugated, 3 - free; events: a - conjugate formation, b - conjugate dissociation; fq(x) -
the TCR expression dynamics of discrete state q, q = 1, 2, 3 [54]
The hybrid automaton model of the T-cell is presented in Figure 3.1. By
this model, the T-cell can be in one of three discrete states: never conjugated,
conjugated and free. This is a consequence of T-cell expression dynamical be-
havior we expect in this biological system. The state never conjugated means
that T-cell has never been conjugated to any APC. The state conjugated means
that the T-cell is currently conjugated to an APC and free means that T-cell
has been conjugated before with some APC, but then becomes free. Transitions
among the discrete states are consequence of the T-cell and APC motion dynam-
ics. In this modeling approach, we assume that motion dynamics produces the
time sequence of the events u(t) which changes the discrete state of the T-cell.
This time event sequence is deﬁned at each time instant and takes value a, b or ε.
The symbol a and b stands for conjugate formation and conjugate dissociation
event respectively. Symbol ε is introduced to describe no event, which means
that the discrete state is not changing.
The discrete states are introduced to model diﬀerent TCR expression vari-
ations of the T-cell, when the T-cell is conjugated to APC or free. The TCRs
expression dynamics of each discrete state is assumed to obey an ODE of the
type
˙x(t) = fq(x), q = 1, 2, 3
(3.1)
where x is the expression level of TCRs and fq(x) deﬁnes the TCR dynamics
in each discrete state, q = 1, 2, 3 ,i.e., never conjugated, conjugated and free
discrete state, respectively. The time event sequence u(t) is a mapping
u(t) : R →{a , b , ε}, t ∈R (t is a real number representing time)
(3.2)
At this modeling level, it is not important what the functions fq are and whether
the sequence u(t) is deterministic or stochastic. However, it is important to note

18
3. Micro-Agent and Stochastic Micro-Agent Models
Fig. 3.2. Micro-Agent model of the T-cell ; u(t) - event sequence; events: a - conjugate
formation, b - conjugate dissociation; x - expression level of TCRs; x0 - initial expression
level of TCRs, q0 - initial discrete state [54]
that the T-cell hybrid system model (Figure 3.1) is a deterministic model. Given
an initial state (x0, q0) and a time sequence u(t), the expression level of TCRs
x(t) and the discrete state q(t) can be calculated in a deterministic way.
Taking into account its deterministic nature, each T-cell model can be repre-
sented as a deterministic single-input, singe-output (SISO) system, as in
Figure 3.2. The input to this system is a sequence of the events u(t) and the
output is the expression level of TCRs x(t), which is a continuous time function.
This input −output representation will be designated as a Micro-Agent (μA)
model of the T-cell .
3.3
T-Cell Population Hybrid System Model
The complete population model can be derived by modeling each T-cell of the
population by a T-cell Micro-Agent model. However, simple collection of the
Micro-Agent models will not reﬂect the TCR dynamic of the biological popula-
tion. The part of biological population complex dynamics which is not covered
by this collection reﬂects the complex dynamics of the population producing
the conjugate formation and conjugate dissociation of T-cells and APC. This
complex dynamics makes the diﬀerence between the TCR dynamics of a collec-
tion of separate T-cells and the TCR dynamics of a T-cell biological population
(Figure 3.3).
The conjugate formation and conjugate dissociation events, of T-cells in
the population, are result of a complex dynamics which depends on the amount
of the cells, their position, speed, orientation, geometry, etc. In the model of
a T-cell population we are proposing, this complex dynamics is represented by
the Population Event Generator (PEG) block in Figure 3.3 . The PEG has
as many outputs as Micro-Agents (T-cells) and generates the events sequences
(u1, u2, . . . uN, Figure 3.3) exactly in the same way as they appear in the biolog-
ical population. This is graphically depicted in Figure 3.3 by the arrows pointing
from the cells in the population to the Micro-Agents input. The introduction of

3.3 T-Cell Population Hybrid System Model
19
μA
μA
μA
Population Event
Generator
T-Cells Dynamics
u1(t)
u2(t)
uN(t)
x1(t)
x2(t)
xN(t)
(PEG)
Fig. 3.3. T-cell population hybrid system model, ui - event sequence input to the ith
T-cell, xi - the TCR expression level of the ith T-cell, i = 1, 2 . . . , N [54]
the PEG in the model makes a strong practical point in the decomposing of the
TCR population TCR dynamics into [54]:
•
a deterministic part (Micro-Agents), which describes the behavior of the
individual T-cell TCR expression dynamics,
•
a stochastic part, related to the complex dynamics of massive random en-
counters of T-cells and APCs (PEG).
The event generation has a complex dynamic process which depends on many
variables in the population. An approach to model this complexity is to apply a
stochastic approach, where the full complexity of the interactions is described by the
probability that an event happens [54]. The population we are considering consists
of individuals of the same nature and we expect that the event sequences ui(t),
i = 1, 2, ...N, generated by the PEG, are of the same stochastic nature as well.
Under the assumption that the event sequences are mutually independent, the
PEG can be decomposed into the set of parallel Micro-Agent Event Generators
Micro Agent Event Generator
μA
μA
μA
Population Event
Generator
T-Cells Dynamics
Micro Agent Event Generator
Micro Agent Event Generator
u1(t)
u2(t)
uN(t)
x1(t)
x2(t)
xN(t)
(PEG)
Fig. 3.4. T-cell population hybrid system model, where the Population Event Gener-
ator (PEG) is decomposed into several Micro-Agent Event Generators (MAEG). The
serial connection of MAEG and Micro-Agents is named a ”Stochastic Micro-Agent”
(SμA); ui - event sequence input to the ith T-cell, xi - the TCR expression level of the
ith T-cell, i = 1, 2 . . . N [54].

20
3. Micro-Agent and Stochastic Micro-Agent Models
(MAEG), as it is presented in Figure 3.4. Each of the MAEGs produces an
event sequence to the input of one Micro-Agent. We name the serial connec-
tion of MAEG and Micro-Agent a ”Stochastic Micro-Agent”. The output of the
Stochastic Micro-Agent is a continuous time stochastic process.
The hybrid-system model of the biological population we are proposing is a
collection of Stochastic Micro-Agents, Figure 3.4. In the following section we will
introduce the formal deﬁnition of the Micro-Agent, μA, and Stochastic Micro-
Agent, SμA.
3.4
Micro-Agent Individual Model
The aim of this section is to introduce a formal mathematical deﬁnition of the
population building block, denoted as Micro-Agent. The Micro-Agent is a hy-
brid automaton [53, 54, 56]. Therefore, the deﬁnition of a hybrid automaton is
introduced ﬁrst. The abstract deﬁnition of a Micro-Agent is necessary in order
to develop the system theory approach of this monograph.
Deﬁnition 1 [76]. A hybrid automata H is a collection H=(Q, X, Init, f, Inv,
E, G, R), where:
- Q is a ﬁnite set of discrete states,
- X ⊆Rn the continuous state space,
- Init ⊆Q × X is the set of initial states,
- f : Q × X →T X assigns to each q ∈Q a vector ﬁeld f(x, q),
- Inv : Q →2X assigns to each q ∈Q an invariant set; as long as the discrete
state is q ∈Q, then the continuous state x ∈Inv(q),
- E ⊆Q × Q is a collection of edges (discrete transitions),
- G : E →2X assigns to e ∈E a guard set, representing the collection of the
discrete transitions allowed by the state vector,
- Rs : X ×E →X assigns to e ∈E and x ∈X a reset map, describing jumps
in the continuous state space due to event e.
Deﬁnition 2 [53, 54, 56]. A Micro-Agent μA is a single-input multi-output
hybrid automaton, deﬁned as a collection μA = (H, U, τ, Y ), where:
- H is a hybrid automaton H = (Q, X, Init, f, Inv, E, G, R) that satisﬁes the
following properties:
- X = Rn, the state space of the continuous piece of H,
- Inv(q) = X, ∀q ∈Q, i.e., for any discrete state q ∈Q, the invariant is
the full continuous state space,
- G(e) = X, ∀e ∈E, i.e., all deﬁned transitions are allowed,
- Rs(e, x) = x, ∀(e ∈E ∧x ∈X), i.e., the transition e does not change
the continuous state x,
- U is a ﬁnite set of input discrete events, including the nil event ε,

3.5 Stochastic Micro-Agent
21
- τ : U × Q →E assigns to the pair formed by the discrete event u ∈U and
discrete state q ∈Q the transition e = (q, q′) ∈E, where τ(ε, q) = (q, q),
- Y = Rm is the output state, a μA output y ∈Y is a function of the
continuous state x, y = g(x).
Remark 1. The Micro-Agent state is a pair (x, q) ∈X × Q. This couple consists
of continuous x ∈X and discrete q ∈Q state components.
The properties of hybrid automaton H in Deﬁnition 2 mean that, for a μA, its
discrete and continuous dynamics can evolve in a free manner. However, jumps
in the continuous state space part are not allowed. The previously introduced T-
cell model can be derived from this abstract deﬁnition taking the output y equal
to the state variable x, which is the TCR amount. It is important to note that
a Micro-Agent is a deterministic system. This means, given an initial condition
and an event sequence, that Micro-Agent output is completely deﬁned.
3.5
Stochastic Micro-Agent
In the previous section, the Micro-Agent model is deﬁned. Here, a Stochastic
Micro-Agent model will be introduced [53, 56]. First, the Micro-Agent Stochastic
Execution is deﬁned. Diﬀerent assumptions about the MAEG generated sequence
lead to diﬀerent Micro-Agents Stochastic Executions. The concept of stochastic
execution [35] is used in the deﬁnition of Stochastic Micro-Agents. Particular
attention is paid to the case when the MAEG generates events such that the
discrete states of a Stochastic Micro-Agent are a Markov Chain.
Deﬁnition 3 [35]. (Micro-Agent Stochastic Execution) A stochastic process
(x(t), q(t)) ∈X × Q is called a Micro-Agent Stochastic Execution, if and only
if a Micro-Agent stochastic input event sequence u(τn), n ∈N, τ0 = 0 ≤τ1 ≤
τ2 ≤. . . generates transitions such that in each interval [τn, τn+1), n ∈N,
q(t) ≡q(τn).
Remark 2. The x(t) of a Stochastic Execution is a continuous time function since
the transition changes only the discrete state of the Micro-Agent.
Deﬁnition 4 [35, 53, 54, 56]. (Micro-Agent Continuous Time Markov Chain
Execution) A Micro-Agent Stochastic Execution (x(t), q(t)) ∈X × Q is called a
Micro-Agent Continuous Time Markov Chain Execution if the input stochastic
event sequence u(τn), n ∈N, τ0 = 0 ≤τ1 ≤τ2 ≤. . . generates transitions
whose conditional probability satisﬁes: P[q(τk+1) = qk+1|q(τk) = qk, q(τk−1) =
qk−1 . . . q(τ0) = q0] = P[q(τk+1) = qk+1|q(τk) = qk.
Remark 3. The q(t) of a Micro-Agent Continuous Markov Chain Execution is a
Continuous Time Markov Chain.

22
3. Micro-Agent and Stochastic Micro-Agent Models
Fig. 3.5. T-cell Micro-Agent and T-cell CTMCμA model: continuous state x - the
TCR expression level; output y(t) is equal to the state x(t); discrete states q: 1 -
never conjugated, 2 -conjugated, 3 - free; events: a - conjugate formation, b - conjugate
dissociation, λij - transition rate from the discrete state i to the discrete state j
Deﬁnition 5 [53, 54, 56]. (Stochastic Micro-Agent, SμA) A Stochastic Micro-
Agent is a pair SμA = (μA, u(t)), where μA is a Micro-Agent and u(t) is a
stochastic input event sequence such that the stochastic process (x(t), q(t)) ∈
X × Q is a Micro-Agent Stochastic Execution.
Deﬁnition 6 [53, 54, 56]. A Stochastic Micro-Agent (SμA) is called a Contin-
uous Time Markov Chain Micro-Agent (CT MCμA) if the input event sequence
u(t) is such that the state evolution (x, q) ∈X ×Q is a Micro-Agent Continuous
Time Markov Chain Execution.
In our deﬁnition of a Stochastic Micro-Agent and CT MCμA we do not specify
the properties of the stochastic event sequence u(t), but in order to apply the
deﬁnition, this sequence should be characterized.
An example of a CT MCμ with 3 discrete states, where the sequence u(t)
produces the random transitions in such a way that probabilities of the discrete
states 1, 2 and 3, P1, P2 and P3, respectively, satisfy the following ODE
⎡
⎢⎢⎢⎣
˙P1(t)
˙P2(t)
˙P3(t)
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
−λ12
0
0
λ12 −λ23 λ32
0
λ23 −λ32
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
P1(t)
P2(t)
P3(t)
⎤
⎥⎥⎥⎦
(3.3)
is illustrated in Figure 3.5. In the left column two equivalent graphical
representations of the T-cell Micro-Agent are depicted. The block diagram rep-
resentation is important in denoting the single-input-single-output nature of the

3.6 Summary
23
Micro-Agent, while the state diagram representation is important in describing
the internal structure of the Micro-Agent. The right column contains two equiv-
alent descriptions of the CT MCμA model. The block diagram denotes that the
event sequence generator is the part of the Stochastic Micro-Agent. The state
diagram presents the internal structure of the Stochastic Micro-Agent and also
the Markov Chain nature of the stochastic transition over the discrete states,
denoted by the transition rate diagram.
3.6
Summary
In view of biological facts, we introduce in this section the Micro-Agent model of
the T-cell. This is a single-input, single-output hybrid automaton-based model
and we use this model as a building block of the T-cell population model. The
hybrid automata modeling framework provides us the explicit modeling of cell-
to-cell conjugation and dissociation and molecular processes they control. Using
the stochastic assumption for the event generation mechanism, the Stochastic
Micro-Agent and the CT MCμA model of the T-cell in the population are de-
ﬁned. Abstract deﬁnitions of the biologically inspired models are introduced
using the hybrid automata framework. This section deﬁnes the basis for the
system-theoretical approach to study Micro-Agent populations which is devel-
oped in this work.
Key points
• The proposed model of the population is a collection of Stochastic Micro-
Agents.
• The question is how to aggregate their individual behavior in a mathemati-
cally tractable way.

4. Micro-Agent Population Dynamics
A mathematical approach to study the relation between the micro- and macro-
dynamics of a Micro-Agent population will be developed in this chapter. The
approach is motivated by the results of Kinetic Gas Theory [39]. Kinetic Gas
Theory deals with a model in which a gas consists of a very large number of small
particles in motion. The motivation to exploit this statistical physics reasoning
originates from the consideration of a gas as a population of individual particles.
A straightforward application of this theory to a general Micro-Agent population
is not possible. However, it provides us with an insight on how to make a bridge
between the micro-dynamics of the individual Micro-Agent and the Micro-Agent
population macro-dynamics.
In Section 4.1, the statistical physics reasoning for the description of the
relation between micro- and macro-dynamics of the Micro-Agent population,
using a probability density function (PDF), is presented. In Section 4.2, we are
concerned with a Continuous Time Markov Chain Micro-Agent (CT MCμA)
stochastic model of the Micro-Agent population and we introduce theorems on
the state PDF time evolution. This dynamics is described by a system of partial
diﬀerential equations (PDE).
4.1
Statistical Physics Background
The Kinetic Gas Theory [39] assumes that a gas is composed of a large number
of small particles. One of the most interesting results of this theory, for the prob-
lem investigated in this work, is the Maxwell-Boltzmann formula. This formula
relates the PDF of the gas particle velocity and the temperature as follows:
f(v) = 4π

m
2πkT
 3
2 v2exp
−mv2
2kT

(4.1)
where v is the particle velocity, m is the mass of gas molecules, k is the Boltzmann
constant and T is the absolute temperature. The probability density function
f(v) relates the dynamics of the individual particle (micro-dynamics), repre-
sented by the particle velocity v, to the particle population macro-measurement,
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 25–34, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

26
4. Micro-Agent Population Dynamics
the temperature T . This probability density function(4.1) has two interpreta-
tions.
The ﬁrst interpretation is that equation (4.1) deﬁnes the probability density
function of the velocity v of one particle. Thus, for a single particle, f(v) deﬁnes
the probability that this particle will have the velocity v.
Second, if we know the temperature T , equation (4.1) determines the velocity
distribution of the particles. This is actually a normalized distribution of the
particles over the space of v. Let us suppose that we observe some volume V of
the gas with a total number of particles N at time instant t. If we have counted
how many particles have the velocity v and this number is N(v), then
f(v) = 4π

m
2πkT
 3
2 v2exp
−mv2
2kT

≃N(v)
N
(4.2)
The dual meaning of the PDF (4.1) has its roots in the dual nature of the
probability. From one perspective, it can be understood as a frequency of some
output from repeated experiments. On the other hand, it represents the state of
knowledge, or belief, about an experiment output, before an actual observation
is made. Regardless of its meaning, the PDF (4.1) contains the complete infor-
mation about the system, which in a probabilistic way describes the relation
between the states of the individual particles and macroscopic observations.
In a very broad sense, the Maxwell-Boltzmann relation inspired our mathe-
matical formulation of the answer to the question:
How does the individual Micro-Agent dynamics aggregate to the Macro-
Agent population measurements?
This is the most important step of the theoretical development presented in
this monograph. In the formulation of the answer, we are using the PDF of the
Micro-Agent state because it is a way to preserve the complete information about
the dynamical system state. Using this (complete) information, any kind of the
population macro-measurements can be calculated. The proposed answer is:
The individual Micro-Agent dynamics and the dynamics of the Micro-
Agents population measurements are linked through the probability den-
sity function of the Micro-Agent state in that population.
Although this answer is of a philosophical nature, it provides us with the in-
tuition on how to look for a mathematically tractable answer. In the Kinetic Gas
Theory, the PDF (4.1), which connects micro- and macro-dynamics, is inferred
using the so-called Maximum Entropy Principle [34]. However, this principle is
only valid in the case of the equilibrium state of a thermodynamic system. In
general case, for non−equilibrium thermodynamics, the Liouville equation [39],
which describes the time-evolution of the PDF, must be applied. This equation
cannot be applied directly to the state PDF evolution of a Micro-Agent pop-
ulation, where the state is composed of discrete and continuous variables. The
result we derive in the following section can be viewed as an extension of the
Liouville equation under a Continuous Time Markov Chain assumption about
the stochastic Micro-Agent execution (Section 3.5, Deﬁnition 4).

4.2 Micro-Agent Population Dynamic Equations
27
4.2
Micro-Agent Population Dynamic Equations
In the previous section, we conclude that the relation between the micro- and
macro-dynamics of a Micro-Agent population can be described using the state
PDF. Here, this idea will be extended using the assumption that the complexity
of interaction in the population produces a Micro-Agent Stochastic Execution.
This assumption is used due to the complex and unobservable nature of the
interaction between individuals. Considering the dual meaning of PDF under
this assumption, we can state:
The individual Micro-Agent dynamics and the Micro-Agents population
measurements dynamics are connected through the probability density
function of the Stochastic Micro-Agent state.
The Stochastic Micro-Agent state PDF represents the state probability of one
Micro-Agent. Simultaneously, looking at the population of Micro-Agents, this
PDF shows the relative frequency of the state occupancy by individual Micro-
Agents. Because of this, we consider a Stochastic Micro-Agent as a stochastic
population model.
Relations regarding the Stochastic Micro-Agent state PDF might be diﬃcult
to ﬁnd in general case. However, in the case of CT MCμA, the system of PDE
which describes the time evolution of the state PDF can be found. One of the
main outcoming results is presented in the following theorem.
Theorem 1 [53, 54, 56]. For a CT MCμA with N discrete states and discrete
state probabilities satisfying
˙P(t) = LT P(t)
(4.3)
where P(t) = [P1(t) P2(t) . . . PN(t)]T , Pi is the probability of discrete state
i, L = [λij]T
N×N, is a transition rate matrix and λij is the transition rate from
discrete state i to discrete state j, the state PDF is given by the vector
ρ(x, t) = [ρ1(x, t), ρ2(x, t), . . . , ρN(x, t)]T
(4.4)
where ρi(x, t) is the PDF of state (x, i) at time t, satisfying the following
equation:
∂ρ(x, t)
∂t
= LT ρ(x, t) −
⎡
⎢⎢⎢⎢⎢⎢⎣
∇· (f1(x)ρ1(x, t))
∇· (f2(x)ρ2(x, t))
...
∇· (fN(x)ρN(x, t))
⎤
⎥⎥⎥⎥⎥⎥⎦
(4.5)
where
∇· (fi(x)ρi(x, t)) =
n

j=1
ρi(x, t)∂f j
i (x)
∂xj
+ f j
i
∂ρi(x, t)
∂xj
(4.6)

28
4. Micro-Agent Population Dynamics
Fig. 4.1. Micro-Agent state space: xk-kth dimension of the continuous state space,
q-discrete state, fi(x)-vector ﬁeld at x ∈X for q = i, V -trajectory volume
and f j
i (x) is the jth component of vector ﬁeld fi(x) at state (x, i), x ∈X,
X = Rn,i = 1, 2, . . . N.
[end of theorem]
Proof. The state space X × Q of the Stochastic Micro-Agent is illustrated in
Figure 4.1. By xk, we denote the kth dimension of the continuous state space
X, q is the discrete state space and fi(x) is the vector ﬁeld at x ∈X for the
discrete state q = i.
During the time interval [τn, τn+1), for the discrete state q = i, the Stochas-
tic Micro-Agent dynamics trajectory x(t) evolves according to the diﬀerential
equation ˙x(t) = fi(x). At the time instant τn+1, the trajectory jumps to any of
the other discrete states with the probability given by (4.3). This jump does not
change x(t), since it is a continuous time function, i.e., x(t−) = x(t+) = x(t).
The probability pV,i that the Micro-Agent state (x, q) ∈Vi, Vi = {(x, q)|x ∈
V, q = i} is given by
pV,i =

V
ρi(x, t)dV
(4.7)
where ρi(x, t) is the probability density function of the state (x, i) which is inside
the arbitrary chosen volume V in X. The time derivative of pV,i is:
˙pV,i(t) =

V
∂ρi(x, t)
∂t
dV
(4.8)
Figure 4.2 illustrates trajectories in volume V and discrete state i, i=1, 2, . . ., N.
Let us deﬁne the volume VB, which is a subset of volume V containing the
portions of the trajectories crossing the surface S of the volume V in the time
interval [t, t + Δt). The volume VB is:
VB =

S,ΔS→0
fi(x)Δt · s0ΔS =

S
fi(x)ΔtdS
(4.9)

4.2 Micro-Agent Population Dynamic Equations
29
Fig. 4.2. Trajectory volume V : S-surface of the volume V , s0-vector of the surface
S, VI-volume of the trajectories not crossing surface S in the time interval [t, t + Δt),
VB-volume of the trajectories crossing surface S in the time interval [t, t + Δt)
where ΔS is an element of the surface S and s0 is a vector of this element. The
volume VI in Figure 4.2 is the volume of the trajectory portions which do not
leave the volume V , i.e.,
VI = V −VB
(4.10)
The probability increase ΔpVI inside the volume VI during the time interval
[t, t + Δt), is:
ΔpVI = Δt
N

k=1
λkipVI,k = Δt
N

k=1
λki

VI
ρi(x, t)dV
(4.11)
A portion of the trajectory inside VI does not leave the volume V, and x(t) is
a continuous time function, so there is no change of the probability in VI due
to the vector ﬁeld fi(x). However, changes at discrete times can happen due
to the Markov Chain transitions and the overall increase ΔpVI is due to these
transitions.
To calculate the increase of the probability inside the volume VB during the
time interval [t, t+Δt), we will use Figure 4.3. This ﬁgure shows an inﬁnitesimally
small volume ΔVB = ΔSΔx. The volume of VB is given by:
VB = lim
ΔS→0

S
ΔSΔx
(4.12)
where ΔS is an inﬁnitely small element of the surface S and Δx, the depth of
the volume VB. The depth of VB can be calculated to be:
Δx = s0 · fi(x)Δt = Δt(s0 · fi(x)) = Δtv
(4.13)
where v is the fi(x) projection on the volume V surface vector at element ΔS,
s0. The probability increase inside ΔVB during the time interval [t, t + Δt) at
time instant t + τ, τ ∈[0, Δt) is:

30
4. Micro-Agent Population Dynamics
Fig. 4.3. Element of the volume VB, ΔS - element of the surface S, v - vector ﬁeld
fi(x) projection on the surface vector s0, Δx - length vΔt
ΔpΔVB(t, τ) = −ρi(x, t)ΔSvτ + ˙ρi(x, t)τΔS(Δx −vτ)
(4.14)
The ﬁrst term of expression (4.14) presents the probability decrease due to the
trajectory outﬂow. Before the trajectories leave the volume ΔVB at time t + τ,
they produce an increase of the probability due to the random transition over
the discrete states. This increase is given by the second term of expression (4.14).
The time derivative of pV,i is:
˙pV,i(t) = lim
τ→0
1
τ
⎡
⎣ΔpVI +

S,ΔS→0
 τ
0
ΔpΔVB(t, s)ds
⎤
⎦
(4.15)
where s is the integration variable. Since the limiting values are:
lim
τ→0
1
τ ΔpVI =
N

k=1
λki

VI
ρk(x, t)dV
(4.16)
lim
τ→0
1
τ [−ΔSv
 τ
0
ρi(x, t)dt] = −ΔSvρi(x, t)
(4.17)
lim
τ→0
1
τ
 τ
0
˙ρi(x, t)ΔSΔx = lim
τ→0
1
τ [ΔS
N

k=1
λki
 τ
0
ρk(x, t)Δxdt] = . . .
ΔSΔx
N

k=1
λkiρk(x, t)
(4.18)
lim
τ→0
1
τ
 τ
0
˙ρi(x, t)(−vτ) = lim
τ→0
1
τ [ΔS
N

k=1
λik
 τ
0
ρk(x, t)(−vs))ds] = 0
(4.19)

4.2 Micro-Agent Population Dynamic Equations
31
we conclude that
˙pV,i(t) =
N

k=1
λki

VI
ρi(x, t)dV +

S,ΔS→0
[−ΔSvρi(x, t) + ΔSΔx
N

k=1
λkiρk(x, t)]
(4.20)
but, because

S,ΔS→0
−ΔSvρi(x, t) = −

S
fi(x)ρi(x, t)dS
(4.21)
and

S,ΔS→0
ΔSΔx
N

k=1
λkiρk(x, t) =

VB
N

k=1
λkiρk(x, t)dV =
N

k=1
λki

VB
ρk(x, t)dV
(4.22)
we obtain
˙pV,i(t) =
N

k=1
λki

VI
ρi(x, t)dV +
N

k=1
λki

VB
ρk(x, t)dV −

S
fi(x)ρi(x, t)dS
(4.23)
i.e.,
˙pV,i(t) =
N

k=1
λki

V
ρi(x, t)dV −

S
fi(x)ρi(x, t)dS
(4.24)
Using Gauss’ theorem [20]:
˙pV,i(t) =

V
 N

k=1
λkiρ(x, i) −∇· (fi(x)ρi(x, t))

dV
(4.25)
and taking the small volume limit of equations (4.8) and (4.25)
lim
V →0 ˙pV,i = lim
V →0

V
∂ρi(x, t)
∂t
= lim
V →0

V
 N

k=1
λkiρ(x, i) −∇· (fi(x)ρi(x, t))

dV
(4.26)
we obtain
∂ρi(x, t)
∂t
=
N

k=1
λkiρi(x) −∇· (fi(x)ρi(x, t))
(4.27)
Using ρ(x, t) = [ρ1(x), t), ρ2(x, t), . . . , ρN(x, t)]T , the equation system (4.27) be-
comes
∂ρ(x, t)
∂t
= LT ρ(x, t) −
⎡
⎢⎢⎢⎢⎢⎢⎣
∇· (f1(x)ρ1(x, t))
∇· (f2(x)ρ2(x, t))
...
∇· (fN(x)ρN(x, t))
⎤
⎥⎥⎥⎥⎥⎥⎦
(4.28)
Q.E.D

32
4. Micro-Agent Population Dynamics
To show that equation (4.2) is an extension of Liouville’s equation [39], we will
consider the Micro-Agent which has only one discrete state. The state space of
such a reduced Micro-Agent is X, instead of X ×Q, and by virtue of Theorem 1,
the state PDF evolution dynamics reduces to:
∂ρ(x, y)
∂t
= −∇· (f(x)ρ(x, t))
(4.29)
which is the Liouville equation.
The solution of the partial diﬀerential equation (4.2) is the vector of time
functions representing the time evolution of the CT MCμA state PDF. To solve
this equation, the region of interest Ω ∈X and boundary condition should be
deﬁned [20]. An example of the boundary condition is ρ(x, t) = 0 for all x ∈∂Ω.
Speciﬁcation of the boundary condition depends on the problem which is de-
scribed by equation (4.2) and can strongly inﬂuence the solution [20]. Numerical
methods for solving this type of equation are discussed in [85].
The following theorem focuses on is about the time derivatives of the PDE
solution:
Theorem 2. For a CT MCμA with N discrete states and state probability
given by:
˙P(t) = LT P(t)
(4.30)
where P(t) = [P1(t) P2(t) . . . PN(t)]T , Pi is the probability of the discrete state
and L = [λij]T
N×N, λij, a transition rate form discrete state i to discrete state j.
The state vector of probability density functions:
ρ(x, t) = [ρ1(x, t) ρ2(x, t) . . . ρN(x, t)]T
(4.31)
where ρi(x, t), the probability density function of state (x, i) at time t, satisﬁes:
dρ(x, t)
dt
= LTρ(x, t) −
⎡
⎢⎢⎢⎢⎢⎢⎣
ρ1(x, t)∇· f1(x)
ρ2(x, t)∇· f2(x)
...
ρN(x, t)∇· fN(x)
⎤
⎥⎥⎥⎥⎥⎥⎦
(4.32)
where fi(x) is the vector ﬁeld value at state (x, i).
Proof. By Theorem 1
∂ρi(x, t)
∂t
=
N

k=1
λkiρi(x) −∇· (fi(x)ρi(x, t))
(4.33)
The total time-derivative of ρi(x, t) is:
dρi(x, t)
dt
= ∂ρi(x, t)
∂t
+ ∇ρi(x, t) · fi(x)
(4.34)

4.2 Micro-Agent Population Dynamic Equations
33
Using equation (4.33) and (4.34), we obtain:
dρi(x, t)
dt
=
N

k=1
λkiρi(x) −∇· (fi(x)ρi(x, t)) + ∇ρi(x, t) · fi(x)
(4.35)
then, by equation (4.6):
∇· (fi(x)ρi(x, t)) = ∇ρi(x, t) · fi(x) + ρi(x, t)∇· fi(x)
(4.36)
Finally,
dρi(x, t)
dt
=
N

k=1
λkiρi(x) −ρi(x, t)∇· fi(x)
(4.37)
i.e.,
dρ(x, t)
dt
= LTρ(x, t) −
⎡
⎢⎢⎢⎢⎢⎢⎣
ρ1(x, t)∇· f1(x)
ρ2(x, t)∇· f2(x)
...
ρN(x, t)∇· fN(x)
⎤
⎥⎥⎥⎥⎥⎥⎦
(4.38)
Q.E.D
Theorems 1 and 2 relate to the dynamics of the CT MCμA state PDF.
Theorem 1 is of special importance. Given an initial state PDF, we can use the
theorem to predict the state PDF evolution. In the case of the CT MCμA T-cell
population model, this theorem can be used to predict the TCR distribution
over the T-cell population. It enables us to test diﬀerent hypotheses about the
T-cell micro-dynamics against experimental data, using a mathematical model.
Although the state PDF contains the complete information about population
measurements, the experimental test can only be made using the Micro-Agent
output PDF η(y, t). For an arbitrarily chosen output y ∈Y , the output PDF is:
η(y, t) =

Vx→y

i
ρi(x, t)dVx→y
(4.39)
where Vx→y is the volume of points x ∈X that satisfy y = g(x) (Section 3.4,
Deﬁnition 2). Unfortunately, solving this integral can be very complex. In the
rest of the chapters, we will consider the case when the output vector is equal
to the state vector:
y = x = [x1 x2 . . . xN]T
(4.40)
in which case, we obtain
η(y, t) = η(y = x, t) =

i
ρi(x, t), i = 1, 2, . . .N
(4.41)
meaning that the output PDF η(y, t) can be directly calculated using the state
PDFs.

34
4. Micro-Agent Population Dynamics
4.3
Summary
The mathematical framework for the study of the relation between the micro-
and macro-dynamics of the Micro-Agent population is developed in this chap-
ter. The approach is based on linking micro- and macro-dynamics using the state
probability density function. Inspired by results of statistical physics, we derive
a PDE system that describes the state probability density function dynamics of
a Stochastic Micro-Agent with a continuous time Markov Chain discrete state
sequence.
Key points
• Through the statistical physics reasoning, the Stochastic Micro-Agent models
of an individual agent and an agent population are equivalent.
• For the CT MCμA model, the evolution of the state probability density func-
tion is determined by a system of partial diﬀerential equations.

5. Stochastic Micro-Agent Model of the T-Cell
Receptor Dynamics
This chapter addresses the TCR expression dynamics investigation using the the-
oretical results developed in the previous chapters. It is focused on the qualita-
tive and quantitative diﬀerence between the results received from the Stochastic
Micro-Agent and ODE models of TCR dynamics. Particular attention is paid to
the capability of comparing the model-predicted TCR distribution to available
experimental data.
The numerical example of Section 5.1 is designed to show how the dynamical
equation of the PDF evolution can be applied to the T-cell CT MCμA model
of the population. In this example, all necessary information about the model
is assumed to be based on biological facts, and numerical solutions for three
parameter cases are discussed. The diﬀerence of the results and the analysis
using the CT MCμA model instead of the ordinary diﬀerential equation (ODE)
model, which describes the TCR expression mean value dynamics, is discussed
in Section 5.2.
In the ﬁrst two sections, we discuss technical aspects of using the CT MCμA
to investigate TCR expression dynamics. However, it is not clear if this model
provides any result similar to real data. Using the model structure shown in
Figure 5.1 and experimental data, we carry out such a test in Section 5.3. This
test shows that the model constraints and experimental data provide us the
capability to make inferences about the unknown functions that are part of the
individual T-cell TCR dynamics.
In the last section, one part of the CT MCμA dynamics is tested against
experimental data. This part describes the dynamics of the TCR down-regulation
due to the contact with an antibody. We expect this down-regulation to have
the same dynamics as the down-regulation during the interaction with the APC.
Using the experimental data we identify the parameters of this dynamics.
5.1
T-Cell Receptor Dynamics: A Numerical Example
In this section a numerical example based on the CT MCμA population of
T-cells (Figure 5.1) is studied. This model is not based on any real data, but
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 35–52, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

36
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
Fig. 5.1. Hybrid automaton model of the T-cell - APC interaction: 1 - never conju-
gated, 2 - conjugated, 3 - free, a - conjugate formation, b - conjugate dissociation, λij -
transition rate from discrete state i to discrete state j [53], c⃝2003 IEEE
on biological facts and includes the essential properties of the TCR expression
dynamics. The numerical example is designed to illustrate the application of
Theorem 1, which is derived in Chapter 4.
The Stochastic Micro Agent model of the T-cell population we are considering
is already introduced as an illustrative example in Chapter 3. For the purpose of
clarity, we present this model again. The CT MCμA is a stochastic Micro-Agent
model of the T-cell population regarding the TCR expression dynamics. The T-
cell can be in one of the three discrete states: never conjugated, conjugated and
free. In each of these states, the TCR expression x changes. Using biological
facts, we know that, in the conjugated state, the TCR expression decreases and,
in the free state, the expression increases, so we assume that the dynamics
of the increase and decrease can be modeled by ˙x = f2(x) and ˙x = f3(x),
respectively. We also assume that the TCR expression of the T-cell, which is
never conjugated to the APC, remains unchanged, i.e., ˙x = 0. The output of
Micro-Agent y is the TCR expression, i.e., y = x. This simpliﬁes the problem
of calculating the output PDF η(y, t), which is necessary to make a test of the
predicted TCR distribution against experimental data. According to this model,
each cell in the population changes its discrete state, from state i to state j, with
probabilistic rate λij.
To make it simpler, all the dynamics in the numerical example presented
below are ﬁrst order linear dynamics:
f1(x, t) = 0; f2(x, t) = −k2x; f3(x, t) = k3x
(5.1)
Moreover, to underline that the predictions we make in this section do not relate
to experimental data, the TCR expression level is entitled the TCR quantity.
According to Theorem 1, Chapter 4, the probability density function of the
state (x, i) satisﬁes:

5.1 T-Cell Receptor Dynamics: A Numerical Example
37
∂
∂t
⎡
⎢⎢⎣
ρ1(x, t)
ρ2(x, t)
ρ3(x, t)
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
−λ12
0
0
λ12 −λ23 λ32
0
λ23 −λ32
⎤
⎥⎥⎦
⎡
⎢⎢⎣
ρ1(x, t)
ρ2(x, t)
ρ3(x, t)
⎤
⎥⎥⎦−
⎡
⎢⎢⎣
0
−k2x ∂ρ2(x,t)
∂x
−k2ρ2(x, t)
k3x ∂ρ3(x,t)
∂x
+ k3ρ3(x, t)
⎤
⎥⎥⎦
(5.2)
In sequel, we will numerically solve this system of partial diﬀerential equations
for the three sets of parameters given in Table 5.1. The parameter values of this
numerical example are chosen to illustrate state PDF evolution in the following
cases:
- Case I, there is no transitions to free state
- Case II, the increase rate k3 is much lower than the decrease rate k2
- Case III, the increase rate k3 is of the same order of magnitude as
the decrease rate k2
In all these cases, the increase rate k3 is assumed to be lower than the decrease
rate k2.
Table 5.1. T-cell CTMCμA model parameter values [h−1]
Case λ12 λ23 λ32 k2
k3
I
0.9
0
0.9 0.5 0.25
II
0.9 0.8 0.9 0.5 0.05
III
0.9 0.8 0.9 0.5 0.25
To solve this system of partial diﬀerential equations, the domain of the so-
lution, initial and boundary conditions have to be deﬁned [20]. For the do-
main of the solution, we take the region 0 ≤x ≤2. The initial condition is
chosen as:
ρ1(x, 0) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0,
x ≤0.2
1
√
2πσ2 exp

−(x−1)2
2σ2

, σ = 0.1, 0.2 < x < 1.8
0,
x ≥1.8
ρ2(x, 0) = 0
(5.3)
ρ3(x, 0) = 0
and the boundary condition is:
⎡
⎢⎢⎣
ρ1(0, t)
ρ2(0, t)
ρ3(0, t)
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
ρ1(2, t)
ρ2(2, t)
ρ3(2, t)
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
0
0
0
⎤
⎥⎥⎦
(5.4)

38
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
If the initial and boundary conditions impose contradictory constraints, the
solution of the PDE does not exist [20]. To avoid this problem, it is useful
to exploit the physical meaning of the PDE problem we are solving [20]. The
boundary condition (5.4) imposes that the probability of the T-cell having the
TCR quantity x = 0 or x = 2 is zero, for every t which is of interest. Because
of that, we shall solve the PDE system for the ﬁnite time interval. Considering
the parameter values from Table 5.1, any T-cell having the TCR quantity with
the non zero probability at time t = 0, i.e., x ∈[0.2, 1.8], cannot reach the x = 0
or x = 2 in, e.g., 4h. Therefore, the boundary condition is not in contradiction
with the PDE we are solving if we choose t ∈[0, T ], T = 4h.
Fig. 5.2. Solution of the PDE system for the T-cell CTMCμA model Case I: top-
left ρ1(x, t), top-right ρ2(x, t), down-left ρ3(x, t), down-right η(x, t); x - TCR quantity,
normalized values
Case I (Table 5.1)
The solution of equation (5.2) under conditions (5.3)–(5.4) and parameter Case I
(5.1) is shown in Figure 5.2. This ﬁgure presents the values of probability den-
sity function for each discrete state ρi(x, t), i = 1, 2, 3, as well as total TCR
distribution η(x, t) deﬁned as:
η(x, t) = ρ1(x, t) + ρ2(x, t) + ρ3(x, t)
(5.5)
This example is interesting because the assumed model has the three discrete
states, but with the transition rate from the discrete state q = 2 to the discrete
state q = 3, λ23 = 0. Since the initial condition in the discrete state q = 3 is

5.1 T-Cell Receptor Dynamics: A Numerical Example
39
Fig. 5.3. Hybrid Automaton model representing the Micro-Agent model of the T-cell
in Case I states: 1 - never conjugated, 2 - conjugated; event: a - conjugate formation
zero, ρ3(x, 0) = 0, the probability density function ρ3(x, t) = 0,∀t. We should
notice that the results for ρ1(x, t) and ρ2(x, t) are equal to the results calculated
for the reduced Micro-Agent presented in Figure 5.3.
Case II (Table 5.1)
This example is diﬀerent from the previous one, since λ23 ̸= 0 and the dynamics
in the discrete state q = 3 produce an increase of the TCR quantity x. The
increase rate k3 is just 10% of the decrease rate k2. Despite that, ρ2(x, t) is
ﬂatter than in the Case I. The solution of PDE system (5.2) is presented in
Figure 5.4.
Case III (Table 5.1)
In this example, the transition rate between the discrete states q = 2 and q = 3
is diﬀerent from zero, λ23 ̸= 0, and it is the same as in Case II. However, the
increase parameter in the discrete state q = 3, k3 , is 50% of k2 (parameter for
Fig. 5.4. Solution of the PDE system for the T-cell CTMCμA model Case II: (a)
ρ1(x, t), (b) ρ2(x, t), (c) ρ3(x, t), (d) η(x, t); x - TCR quantity, normalized values

40
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
Fig. 5.5. Solution of the PDE system for the T-cell CTMCμA model Case III: (a)
ρ1(x, t), (b) ρ2(x, t), (c) ρ3(x, t), (d) η(x, t); x - TCR quantity, normalized values
the discrete state q = 2). This larger parameter k3 makes ρ2(x, t) ﬂatter than
in Case II. This is because, comparing to Case II, and due to the higher rate of
increase k3, more T-cells in the population have a larger quantity of TCRs. The
solution of PDE system (5.2) in Case III is presented in Figure 5.5.
From the results of the numerical example, we can conclude that the solu-
tion of the PDE system (5.2) is composed of three functions ρi(x, t), i = 1, 2, 3,
representing the PDF state of T-cell CT MCμA model. For the same initial and
boundary conditions, the shape of the solution depends on the individual T-cell
TCR quantity dynamics parameters and the rate of discrete state transitions. In
Section 5.3 and Section 5.4, we will exploit this conclusion to test the hypothesis
about individual T-cell TCR expression dynamics based on the TCR expression
steady state distributions of the T-cell population.
5.2
Micro-Agent vs. Ordinary Diﬀerential Equation
Model
In this section, we will present the study of a hypothetical T-cell, which is al-
ready presented in Section 5.1 as the numerical example (Case I in Table 5.1).
We choose this simplest case on purpose to underline the potential diﬀerences
between results of the ODE models [69] and the CT MCμA model of the popu-
lation TCR expression dynamics.

5.2 Micro-Agent vs. Ordinary Diﬀerential Equation Model
41
Let us suppose that biological facts tell us that, after the T-cell APC conju-
gation, the TCR quantity decreases following the linear ODE law:
˙x(t) = −k2x(t)
(5.6)
where x is the quantity of expressed TCRs and k2 is the reaction rate constant.
If this model is valid for all T-cells, then for the known initial TCR average
expressed quantity xe(0), the TCR average quantity xe can be predicted by the
ODE model :
˙xe(t) = −k2xe(t)
(5.7)
Let us assume now that not only the initial average quantity of the expressed
TCRs is known, but also the overall TCR distribution over the T-cell population.
If the TCR distribution is normalized, then we get the TCR PDF. To simplify,
we assume that the initial TCR PDF is Gaussian with the variance σ2(0). The
TCR PDF variance evolution is the solution of the Lyapunov equation [26]:
˙σ2(t) = −2k2σ2(t)
(5.8)
Since equation (5.6) is linear, the distribution of the TCRs over the T-cell
population will be Gaussian at each time instant. The ODE predicted average
Fig. 5.6. Average value of the TCR quantity over the T-cell population obtained by
ODE and Case I CTMCμA models (the TCR quantity is normalized)
Fig. 5.7. Standard deviation of the TCR quantity over the T-cell population obtained
by ODE and Case I CTMCμA models (the TCR quantity is normalized)

42
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
Fig. 5.8. TCR PDF time evolution computed by the CTMCμA models (the TCR
quantity is normalized)
TCR amount and the standard deviation, for xe(0) = 1, k2 = 0.5 and σ(0) = 0.1,
are presented in Figures 5.6 and 5.7.
The individual T-cell dynamics of TCR decrease in the CT MCμA model
(Case I, Table 5.1) is the same as in (5.6). However, opposite to the ODE model,
in which the TCR decrease starts at the same time instant for all the T-cells,
in the CT MCμA model we have the rate of the conjugate formation, i.e., the
rate of the TCR decrease start. Although the individual T-cell TCR decrease
dynamics is the same for both of the models, the CT MCμA model predicted
average value and the variance do not follow the ﬁrst order ODE dynamics, due
to the rate of the conjugate formation, as shown in Figures 5.6 and 5.7. The eﬀect
of the rate of the conjugate formation results in the loss of Gaussian property
for the TCR PDF. This is illustrated in Figure 5.8, where the TCR PDF at
diﬀerent time points is presented.
This numerical example illustrates the importance of considering the variance
of population measurements in the model identiﬁcation. Assuming that experi-
mental average values follow the plot corresponding to the CT MCμA model in
Figure 5.6, this smooth line can be ﬁtted by an ODE model with an appropriate
parameter adjustment. However, the associated variance dynamics cannot be
explained by the same ODE model. This is because the variance contains the
additional information about the individual dynamics of the population. By our
Stochastic Micro-Agent modeling approach, we can even go one step further,
because we can predict the complete measurement distribution and compare it
to the experimentally obtained distribution of measurements.
5.3
T-Cell Receptor Expression Dynamics Model Test
The study of the TCR expression dynamics has motivated the Micro-Agent
model development. In the introductory section of this chapter, we propose the
T-cell Micro-Agent model (Figure 5.1) based on biological facts. In this sec-
tion, the theoretically predicted TCR expression distribution will be matched to
experimental data [53].

5.3 T-Cell Receptor Expression Dynamics Model Test
43
The basis for this analysis is the experimental data in [75]. The experiment
therein shows that after long enough time, the TCR distribution remains practi-
cally unchanged [75]. This constant distribution will be designated in the sequel
by the steady state distribution. It is worth mentioning that, due to the lack
of data, we are not able to fully justify the application of our model to the
data from this experiment, so the steady state assumption might be incorrect.
However, our intention here is less ambitious. We would like to see if the model
we are considering can produce some reasonable prediction of TCR expression
distribution. After we normalize experimentally recorded TCR distribution, so
that the integral of the distribution is unity, we can compare it to the T-cell
CT MCμA output PDF. The role of this example is also to show that, using the
steady state TCR expression distribution, we are able to get a further insight
into the dynamics of the TCR expression decrease and increase.
Ultimately, the TCR expression level reﬂects the number, or the amount, of
the TCRs expressed on the T-cell surface. To underline that we are dealing
with experimental data, we use the term ”TCR amount” referring to the TCR
expression level.
Let us assume that the transition rates of the proposed T-cell Micro Agent
model λ12, λ23, λ32 are constant. As explained earlier, f1(x, t) = 0. However, we
do not know the continuous dynamics of conjugated and free states. Therefore,
we will assume that they depend only on x and not on t, i.e., the continuous
dynamics of the discrete states of the T-cell CT MCμA model are
f1(x, t) = 0; f2(x, t) = f2(x); f3(x, t) = f3(x)
(5.9)
Due to the reasons explained in Chapter 4, the equation which describes the
evolution of the PDF over the CT MCμA state space (Theorem 1) is given
by [53, 54]:
∂ρ1
∂t = −λ12ρ1 −∇· (f1ρ1)
(5.10)
∂ρ2
∂t = λ12ρ1 −λ23ρ2 + λ32ρ3 −∇· (f2ρ2)
(5.11)
∂ρ3
∂t = λ23ρ2 −λ32ρ3 −∇· (f3ρ3)
(5.12)
where ρi = ρi(x, t). Since the output y = x, the PDF of the CT MCμA output
η(x, t) is given by:
η(x, t) = ρ1(x, t) + ρ2(x, t) + ρ3(x, t)
(5.13)
Taking the limit, t →∞, the steady state of (5.10)-(5.12) is:
0 = −λ12ρs
1 −∇· (f1ρs
1)
(5.14)
0 = λ12ρs
1 −λ23ρs
2 + λ32ρs
3 −∇· (f2ρs
2)
(5.15)
0 = λ23ρs
2 −λ32ρs
3 −∇· (f3ρs
3)
(5.16)

44
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
where ρs
i = ρs
i(x) denotes the steady-state. Since f1 = 0, we can conclude that
ρs
1(x) = 0 and transform the system of equations (5.14)-(5.15) to the equiva-
lent one:
0 = −λ23ρs
2 + λ32ρs
3 −∇· (f2ρs
2)
(5.17)
0 = ∇· (f2ρs
2 + f3ρs
3) ⇔f2ρs
2 + f3ρs
3 = const
(5.18)
Since the functions ρs
i are PDFs, then ρs
i (x) ≥0, ∀x ∈R. The amount of TCRs
cannot be negative, thus the PDFs ρs
2 and ρs
3 of any negative TCR amount are
zero. Therefore, there exists a point x0 < 0, where ρs
2(x0) = ρs
3(x0) = 0, and
equations (5.17)-(5.18) are
0 = −λ23ρs
2 + λ32ρs
3 −∇· (f2ρs
2)
(5.19)
0 = f2ρs
2 + f3ρs
3
(5.20)
After substituting ρs
3(x) = ηs(x) −ρs
2(x), the solution for the steady state of
equations (5.10)-(5.13) is equivalent to the solution of the following ordinary
diﬀerential equation [53, 54]:
dηs
dx = −
 f3f2
f3 −f2
−1 d
dx
 f3f2
f3 −f2

+ λ23
f2
+ λ32
f3

ηs
(5.21)
The solution of this equation is [20]:
ηs(x) = c

1
f3(x) −
1
f2(x)
 e−
 
λ23
f2(x) + λ32
f3(x)

dx
(5.22)
where c has such a value that
 ∞
∞ηs(x)dx = 1. Equation (5.22) deﬁnes the shape
of the TCR amount distribution. This result is very important because it shows
that the TCR amount distribution contains the information about the individual
T-cell TCR expression dynamics.
In Figure 5.9, the T-cell - APC interaction experimental data of Valitutti et
al. [75] of the initial η(x, 0) and the steady state ηs
exp(x) distribution of TCRs
over the T-cell population are approximated by log-normal distributions [53]:
η(x, 0) =
1
2σ0x

(π)
e
−(M0−ln(x))2
2σ2
0
(5.23)
ηs
exp(x) =
1
2σ∞x

(π)
e
−(M∞−ln(x))2
2σ2∞
(5.24)
where M0 = log10(100), σ0 = 0.19 and M∞= log10(50), σ∞= 0.27. In order
to match steady state distribution (5.22) to equation (5.24), we make the ﬁrst
derivatives in the exponent equal:
λ23
f2(x) + λ32
f3(x) = d
dx
(ln(x) −M∞)2
2σ2∞
(5.25)

5.3 T-Cell Receptor Expression Dynamics Model Test
45
10
0
101
102
103
0.005
0.01
0.015
0.02
0.025
0.03
0.035
Amount of TCRs (x)
η(x,0)
s(x)
η
0
Fig. 5.9.
Steady state and initial TCR PDF, based on [75]: ηs(x) - the CTμA
model-predicted steady state distribution (solid) [53], ηs
exp(x) - normalized smoothed
experimental steady state TCR PDF (dashed) [53], η(x, 0) - normalized smoothed
experimental initial TCR PDF [53], c⃝2003 IEEE
After the diﬀerentiation in (5.25), we have:
λ23
f2(x) + λ32
f3(x) = −M∞
σ2∞
1
x +
1
σ2∞
ln(x)
x
(5.26)
The solution of equation (5.26) is composed of 1/x and ln(x) functions, and is
not unique. We should take into account that f2 describes the decrease of TCRs,
so we should have f2(x) < 0, ∀x > 0. For the same reason f3 > 0, ∀x > 0, since it
describes an increase of TCRs. Following the idea that the increase and decrease
dynamics follow diﬀerent dynamical behavior, one possible solution is [53]:
f2(x) = −k2x
(5.27)
f3(x) = k3
x
ln(x)
(5.28)
where:
k2 = σ2
∞λ23
M∞
, k3 = σ2
∞λ32
(5.29)
The previous relations show that the micro dynamics parameters k2 and k3
functionally depend on the conjugate formation and conjugate dissociation rates,
λ32 and λ23, respectively. If the dissociation rate is higher, then the decreasing
rate of TCR, k2 should be higher, too, i.e., TCR triggering signaling should
be more eﬃcient. Similar conclusions can be made about parameter k3. This
functional dependence has been recently reported [13].
Besides the steady state values, the experimental data [75] also contain the
time record of the average value of TCRs during the experiment (Figure 5.10).
Taking into account the biological fact that the decrease dynamics rate of the

46
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
Fig. 5.10. Average amount of TCRs (relative to the initial TCRs amount) [53]: ηexp(t)-
experimentally obtained values (o) [75], η(t)-the model-predicted average values, c⃝
2003 IEEE
TCRs is much higher than the increase dynamics rate, we assume k2 ≃100k3.
To predict higher TCR distribution, the following parameters are chosen:
λ12 = λ32 = 7, λ23 = 7000, M∞= log10(50), σ∞= 0.27
(5.30)
The parameters unit is min−1. The predicted steady state TCR distribution
ηs(x) and the average value ηs(t) are presented in Figures 5.9 and 5.10,
respectively.
We can see that the TCR PDF predicted from the T-cell CT MCμ model
and given parameters cannot be distinguished from the experimental steady
state TCR PDF ηs
exp(x). The predicted average values ﬁt well the experimental
average values as well [75].
We do not like to give the impression that the identiﬁed model parameters
correspond exactly to the parameters of physical reality. We rather conclude
that, for proposed mapping of biological knowledge to the T-cell, the Micro-
Agent model produces reasonable and meaningful results. This is not obvious
from the Micro-Agent model structure and gives us conﬁdence that our line
of reasoning of modeling TCR expression dynamics of the T-cell population is
reasonable.
5.4
T-Cell Receptor Dynamics in Conjugated State
In this section we are analyzing data received from the experiment by Lino [45],
which is similar to Valitutti’s experiment [75]. In this experiment, the T-cell
population is exposed to a large amount of antibodies. Antibodies are the sol-
uble molecules which play the role of MHC peptides on the surface of APCs.
The T-cell suspension is added to a solution of antibodies and stirred in seconds.
Under these conditions, we can assume that all the T-cells start to interact with
the antibodies immediately at the beginning of the experiment at time t = 0 and

5.4 T-Cell Receptor Dynamics in Conjugated State
47
Fig. 5.11. Experimental data TCR PDF estimation [54], ρexp(x, tj), j = 1, 2, . . . 8,
Flow Cytometry data from [45]
that there is no conjugate dissociation afterwards. Thus, all of the T-cells in
the population are in the single conjugated state. Expecting that the T-cells
react in the same way either to APC or antibodies, this experiment provides
us a source of data which can be used to identify the dynamics of the individ-
ual T-cell in the conjugated state [54], i.e., the individual T-cell TCR decrease
dynamics.
Since all the T-cells in the population follow dynamics f2 (see Figure 5.1)
of the conjugated state, the PDE system, which describes the evolution of the
state PDF, reduces to a single PDE, i.e., to the Liouville equation:
∂ρ(x, t)
∂t
= −∇· (f2(x)ρ(x, t))
(5.31)
Regarding the individual T-cell TCR dynamics decrease, we pose two hypothe-
ses. The ﬁrst hypothesis is linear:
f2(x) = −k2x
(5.32)
while the second hypothesis is quadratic:
f2(x) = −k2x2
(5.33)
Both of the hypotheses have been used in the literature, where the ODE dynam-
ics of the average amount of the TCRs is considered [69].
The experimentally estimated TCR PDF ρexp(x, t) evolution received from
our T-cell-antibody experiment is presented in Figure 5.11. The TCR PDF is
estimated at t1 = 0, t2 = 1, t3 = 15, t4 = 30, t5 = 45, t6 = 59, t7 = 93 and
t8 = 122 min., after the experiment start. Since the TCR PDF contains the
important information about the individual T-cell TCR dynamics, as one part
of this work, a novel algorithm for estimation of TCR PDF from Flow Cytometry
measurements is proposed (see Appendix A). The experimental data presented
in Figure 5.11 are produced by this algorithm. The estimated PDF ρexp, in a log

48
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
Fig. 5.12. Distance JKL(t) computed for the linear hypothesis [54]. The local minima
signaled by the arrows correspond to the time points τk when p(x, t) is close to some
of the experimental TCR PDF, pexp(x, tj), j = 1, 2, . . . 8.
scale, is given in Appendix B. The algorithm is based on a stochastic model of
the Flow Cytometry measurement of T-cells, QQ-plot PDF estimation [18, 19]
and Richardson-Lucy (RL) deconvolution algorithm [47, 66] (see Appendix A).
The ﬁrst part of the analysis in Section 5.4.1 is concerned with the hypothesis
testing using the experimental data plotted in Figure 5.11. The second part
of analysis, Section 5.4.2, is concerned with the parameter identiﬁcation of the
individual T-cell TCR expression dynamics.
5.4.1
Model Hypothesis Test
To test the hypotheses of linear and quadratic models of the individual T-cell
TCR expression dynamics, we will compare the evolution of the predicted TCR
PDF ρ(x, t) using (5.31) the experimentally received TCR PDF ρexp(x, tj), j =
1, 2, . . .8 [54]. The initial condition for the prediction is ρ(x, 0) = ρexp(x, 0). The
shape of the evolution ρ(x, t), calculated by (5.31) at diﬀerent times, does not
depend on parameter k2, either for the linear or for the quadratic hypotheses.
It is because the parameter k2 in equation (5.31), for both linear and quadratic
case, only scales the time. This allows us to take k2 = 1 and compare the shapes
in the prediction ρ(x, t) to the shapes in the experimental data ρexp(x, tj). Using
k2 = 1, we should keep in mind that t and tj are not measured within the same
time frame.
However, to compare the shape of the prediction ρ(x, t) to the experimental
data ρexp(x, tj), we need to choose the times τk, k = 1, 2, . . . at which we are
comparing ρ(x, τk) to ρexp(x, tj). We determine τk as the times when the model
predicted PDF ρ(x, t) is the most similar to some of the experimentally received
PDF ρexp(x, tj), j = 1, 2, . . . 8. To ﬁnd τk, we use the distance which compares
the PDFs in terms of the Kullback-Leibler [KL] distance [15]:
JKL(ρ(t), ρexp) = min
j

i
ρ(xi, t) log
ρ(xi, t)
ρexp(xi, tj)
(5.34)

5.4 T-Cell Receptor Dynamics in Conjugated State
49
measuring the distance between the predicted PDF at time t, ρ(x, t) and the
set of experimentally received measurements ρexp [54], computed as a minimal
value of KL distance between ρ(x, t) and ρexp(x, tj), j = 1, 2, . . . 8. The Kullback-
Leibler distance is the entropy-based distance commonly used to measure the
similarity between the two PDFs. The distance JKL(ρ(t), ρexp) computed for
the linear hypothesis PDF prediction is presented in Figure 5.12. It is small
whenever ρ(x, t) is similar to some of the ρexp(x, tj), j = 1, 2, . . . 8. Therefore,
the time points τk, k = 1, 2, . . . correspond to the local minima of JKL(ρ(t), ρexp),
which are signaled by the arrows in Figure 5.12.
The TCR PDF evolution for the linear hypothesis, calculated by (5.31) at the
time points τk, k = 1, 2, . . . 6, is plotted in Figure 5.13. From the ﬁgure, we can
see that the linear hypothesis shape of ρ(x, t) evolution corresponds to the shape
of the experimental TCR PDF pretty well.
Similar analysis can be made for the quadratic hypothesis. However, this
makes little sense, since in the quadratic case, the TCR PDF evolution does not
TCR PDF
Fig. 5.13. Time evolution of TCR PDF, linear hypothesis [54]: model-predicted
ρ(x, t)(solid, computed at time τk), the experimental TCR PDF ρexp(x, tj) (dashed),
j = 1, 2, . . . 8, Flow Cytometry data from [45]
Fig. 5.14. Time evolution of TCR PDF, quadratic hypothesis [54]: model-predicted
ρ(x, t)(solid), the experimental TCR PDF ρexp(x, tj) (dashed), j = 1, 2, . . . 8, Flow
Cytometry data from [45]

50
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
produce the shapes of ρ(x, t) which approximate closely the experimental TCR
PDF, Figure 5.14.
Based only on the shapes in ρ(x, t) evolution, we can conclude that the in-
dividual T-cell TCR expression dynamics of the conjugated state is closer to
the linear hypothesis. This conclusion corresponds to the result of the analysis
presented in the previous section.
5.4.2
Parameter Identiﬁcation
In Figures 5.13 and 5.14, the TCR PDF prediction and the experimental TCR
PDF are not compared under the same time frame. This is allowed because our
hypothesis test takes into account only the shape of the model predicted TCR
PDF evolution, which does not depend on the parameter k2. In the following
analysis, we will estimate this parameter comparing ρ(x, t) and ρexp(x, tj), where
t and tj are measured under the same time frame.
We ﬁrst introduce a cost function J which depends on k2:
J(k2) =

tj

i
ρ(xi, tj|k2) log ρ(xi, tj|k2)
ρexp(xi, tj)
(5.35)
where ρ(xi, t|k2) is the value of ρ(x, t) calculated for the parameter k2 at x = xi,
and ρexp(xi, tj) is the value of ρexp(x, tj) at x = xi. This function is a sum of KL-
based distances between the predicted PDF at time tj, for the given parameter
k2 and the experimentally observed ρexp(xi, tj).
The minimum of the function J(k2) means that the predicted PDF evolution
of ρ(x, t|k2) is the closest possible to the experimentally received PDFs ρexp at
each sampling instant tj. The function J(k2) computed for the linear hypothe-
sis and experimental data is presented in Figure 5.15. Using this ﬁgure, we can
conclude that k2 = 0.015. The corresponding time evolution of ρ(x, t|k2) is pre-
sented in Figure 5.16. The reason why the TCR PDF prediction, k2 = 0.015,
Fig. 5.15. Distance between the model prediction and experimental data against the
parameter k2

5.5 Summary
51
Fig. 5.16. Predicted TCR PDF for k2 = 0.015(solid line), experimental TCR PDF
ρexp(x, tj) (dashed), j = 1, 2, . . . 8, Flow Cytometry data from [45]
does not match better the experimental TCR PDF can be ascribed to the fol-
lowing reasons:
• The individual T-cell TCR dynamics is more complex than the time invariant
linear one. For example, the parameter k2 depends on time.
• The experimental TCR PDFs are estimated incorrectly due to the incorrect
stochastic measurement model.
• The experimental TCR PDFs are estimated using very similar, but not iden-
tical, T-cell populations. It can be the reason why the experimentally received
distributions are interlaced with the predicted TCR PDFs. Because of the
same reason, the experimental distributions at 93rd min and 122nd min ( see
Figure 5.11 and Figure 5.16 (dashed) ) are equally close to the prediction at
122nd min ( Figure 5.16, solid).
Investigation of these sources of uncertainty and understanding of their inﬂu-
ence on the diﬀerence between predicted and experimental data is essential for
future work.
At the end of this section, it is worth saying that in the case of the linear
decrease dynamics and when only one discrete state exists, the evolution of
the PDF mean value and variance can be described by the corresponding ODE
model. Thus, the parameter k2 can be obtained from ﬁtting the data to the
ODE model. However, in the case of nonlinear hypothesis, the complete machin-
ery used to measure the distance between the time evolution of predicted and
experimentally received PDFs has to be applied. Our analysis shows that mak-
ing the prediction of TCR expression distribution measurements and comparing
these distributions to experimental data can be very eﬃcient in eliminating any
wrong hypothesis about TCR expression dynamics.
5.5
Summary
The application of a CT MCμA stochastic micro agent model to the investiga-
tion of individual T-cell TCR expression dynamics is presented in this chapter.

52
5. Stochastic Micro-Agent Model of the T-Cell Receptor Dynamics
We propose the CT MCμA T-cell model and we show that the TCR PDF pre-
dicted by this model contains the information about the individual T-cell TCR
dynamics. Making hypothesis about the individual dynamics, we ﬁnd that our
CT MCμA can explain experimental data well and we conclude that the TCR
dynamics decrease of an individual T-cell, due to the contact of the T-cell to the
APC or antibodies, is almost linear.
Using a CT MCμA instead of an ODE model, we can match the TCR distribu-
tion to the experimental data instead of matching only the average TCR amount.
Matching distributions places strong constraints on the hypothesis for the TCR
expression dynamics of the individual T-cell. It provides a qualitatively better
insight into the individual T-cell TCR expression dynamics, which is based on
the experimentally received TCR distribution of the T-cell population.
Key points
• The numerical example illustrates an application of mathematical develop-
ment of CT MCμA mathematical developments.
• The CT MCμA model is employed to explain the steady state in T-cell-APC
experimental data of Valitutti et al. [75].
• The dynamics of conjugated state is investigated comparing the evolution of
the predicted TCR PDF to the experimental data from the T-cell-antibody
experiment by Lino [45].

6. Stochastic Micro-Agent Model Uncertainties
The T-cell population models presented in Chapter 5 are based on the simpliﬁed
assumption that the continuous dynamics of all individual Micro-Agents of the
population is identical. Motivated by the problem of modeling the diversity in
biological interactions, we describe here a method of dealing with the parameter
uncertainty of the CT MCμA continuous dynamics. This method is focused on a
systematic procedure that modiﬁes the original CT MCμA state PDF dynamics
equations to a set of equations that incorporate the parameter uncertainty. Our
discussion in this chapter is limited to the case of a CT MCμA single parameter
uncertainty. However, the suggested procedure is general enough to be applied
to more complex cases, involving several uncertain parameters.
In the case of the T-cell CT MCμA model (Chapter 4), this single parameter is
the rate of the TCR expression decrease while the T-cell and the APC are conju-
gated. This parameter is uncertain because it depends on the APC characteristics.
Diﬀerent APCs expose diﬀerent amounts of MHC-peptide complexes on their sur-
faces. Although the parameter is uncertain, it is constant while the cells are conju-
gated. This kind of the CT MCμA parameter uncertainty will be analyzed below.
From the CT MCμA deﬁnition (Chapter 3), the continuous dynamics fi are de-
ﬁned for each discrete state i ∈Q, where Q is the set of CT MCμA discrete states.
In the single parameter uncertainty case, among all discrete states Q, there exists
only one discrete state (say, w ∈Q) with the continuous dynamics (fw) dependent
on an uncertain scalar parameter b. This parameter b is unknown, but constant,
during the time intervals when the CT MCμA is in the discrete state w. Each time
the CT MCμA enters the state w, the parameter b can have a new constant random
value. Assuming that the parameter b is a scalar-valued random variable, deﬁned
by its PDF p(b), two types of parameter uncertainty can be distinguished:
- The discrete parameter uncertainty, for which the parameter b is random,
but the values it can take are from a ﬁnite set {b1, b2, . . . bD}, where D is
the number of all the possible parameter values, see Figure 6.1a.
- The continuous parameter uncertainty, for which the parameter b is random
and it takes the value from some range in R1; and the PDF p(b) is a
continuous function, see Figure 6.1b.
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 53–66, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

54
6. Stochastic Micro-Agent Model Uncertainties
The PDF examples in the case of the discrete parameter uncertainty (DP
uncertainty) and the continuous parameter uncertainty (CP uncertainty) are
presented in Figure 6.1. We will analyze both uncertainty cases in the following
sections.
Fig. 6.1. Two cases of the parameter uncertainty: (a) The PDF of the discrete param-
eter uncertainty, bd-parameter values, d = 1, 2, . . . D, D-the number of possible values.
(b) The PDF of the continuous parameter b.
6.1
Discrete Parameter Uncertainty Case
To explain the methodology that we develop, the deﬁnitions of input and out-
put state sets of a discrete state are introduced ﬁrst. Then, the basic idea of our
method is explained and we derive a theorem which states the conditions for the
invariance of the discrete state probability under the discrete state splitting of a
given Continuous Markov Chain. Using this theorem, the method that modiﬁes
the original CT MCμA and generates a new CT MCμA model, that incorporates
the parameter uncertainty (denoted by CT MCμA), is introduced.
Deﬁnition 6. Given a Continuous Markov Chain, with the transition matrix
LT = [λij]N×N, where N = |Q|, Q is the set of discrete states and λij, the
transition rate from state i ∈Q to state j ∈Q, we deﬁne:
- In(w) - the set of input states of the discrete state w by
In(w) = {q|λqw > 0, q ∈Q}
(6.1)
- Out(w) - the set of output states of the discrete state w by
Out(w) = {q|λwq > 0, q ∈Q}
(6.2)
In other words, the set In(w) is the set of discrete states from which the state
w can be reached after one transition. Similarly, Out(w) denotes the set of the
discrete states that can be reached from the discrete state w after one transition.
In Figure 6.2a, this part of a CT MCμA is illustrated. The discrete state w is
the one which contains the uncertain parameter b, while the states j ∈In(w)
and k ∈Out(w) are chosen from non-empty In(w) and Out(w) sets.
The basic idea of modifying the CT MCμA to the CT MCμA is depicted in
ﬁgure 6.2b. Let us assume that the CT MCμA has just the vector ﬁeld fw, which
depends on b ∈{b1, b2, . . . , bD}. This means, that after transition to the state w,

6.1 Discrete Parameter Uncertainty Case
55
Fig. 6.2. CTMCμA modiﬁcation: (a) part of the original CTMCμA (b) the splitting
of the state w, which is the state with the parameter uncertainty
the trajectory of the CT MCμA changes in one of D directions, given by fw,bd ,
d ∈{1, 2, . . .D}. The direction to follow is chosen based on the parameter b,
which is a discrete-valued random variable determined by its PDF p(b). Since
p(b) is a set of Dirac impulses, the probability of the bd realization is denoted by
p(bd) to simplify the notation (reserving the capital letter P for discrete state
probabilities).
If we split the discrete state w into the states (w, d), each of them assigned
to one vector ﬁeld fw,bd , this results in a CT MCμA, which incorporates the
b parameter uncertainty of the original CT MCμA model. However, to make
this modiﬁcation correctly, the input rate λj(w,d) and the output transition rate
λ(w,d)k of the introduced states have to be determined so that the modiﬁcation
does not inﬂuence the rest of discrete state probabilities. In other words, for the
rest of the discrete state dynamics, the state w division has to be ”invisible”.
The discrete dynamics of a CT MCμA is described by a Markov Chain, which
satisﬁes:
˙P(t) = LT P(t)
(6.3)
where P(t) is the vector (P(t) = [P1, . . . Pw . . . PN]T ) of discrete state probabili-
ties and L is the transition rate matrix. Mathematically, the state w splitting is
“invisible” if the complete evolution of P(t) is invariant under this modiﬁcation.
The following theorem provides the conditions for this invariance to hold for a
continuous time Markov Chain.
Theorem 1. If the evolution of the Continuous Markov Chain discrete state
probabilities vector P(t) is given by:
˙P(t) = LT P(t)
(6.4)
where L = [λij] is the matrix of transition rates from the discrete state i ∈Q
to the discrete state j ∈Q and one of the discrete states, w, is split into (w, d),

56
6. Stochastic Micro-Agent Model Uncertainties
d = 1, 2, . . .D discrete states, then under this modiﬁcation, P(t) is invariant
∀P(0) ∈Rn and ∀t if all the following conditions hold:
(A)
Pw(0) =
D

d=1
P(w,d)(0)
(6.5)
(B)
λjw =
D

d=1
λj(w,d)
(6.6)
(C)
|Out(w)|

k=1
λ(w,d)k = |Out(w)|λwk
(6.7)
where |Q| is the cardinality of the discrete state set Q.
Proof. After the discrete state w is decoupled, P(t) is invariant if
Pw(t) =
D

d=1
P(w,d)(t)
(6.8)
(A) The equation (6.8) should be satisﬁed at t = 0, because of:
Pw(0) =
D

d=1
P(w,d)(0)
(6.9)
(B) The probability increase of Pw, which results from the transition from
state j ∈Q and is denoted by ΔPw|j(t), is given by:
ΔPw|j(t) = lim
Δt→0 λjwPj(t)Δt
(6.10)
because Pw|j(t) is the conditional probability increase of Pw due to the state j.
Using the same reasoning, the increase of the probability of the discrete state
(w, d), due to the transition from the state j ∈Q, P(w,d)|j, is given by:
ΔP(w,d)|j(t) = lim
Δt→0 λj(w,d)Pj(t)Δt
(6.11)
For P(t) to be invariant, Pw(t) must be invariant and also its increase must be
invariant, i.e.,
ΔPw|j(t) =
D

d=1
ΔP(w,d)|j(t)
(6.12)
which requires:
λjw =
D

d=1
λj(w,d)
(6.13)
that proves the condition (B) of the theorem, equation (6.6).

6.1 Discrete Parameter Uncertainty Case
57
(C) Let us write the expression for the probability increase of the discrete
state w. According to the theorem statement, we have:
˙Pw(t) =

j∈In(w)
λjwPj(t) −

k∈Out(w)
λwkPw(t)
(6.14)
We write the set of equations which describe the time increase of the state PDF
corresponding to the introduced D discrete states (w, d):
˙P(w,1)(t) =

j∈In(w)
λj(w,1)Pj(t) −

k∈Out(w)
λ(w,1)kP(w,1)(t)
(6.15)
˙P(w,2)(t) =

j∈In(w)
λj(w,2)Pj(t) −

k∈Out(w)
λ(w,2)kP(w,2)(t)
(6.16)
. . .
. . .
(6.17)
˙P(w,D)(t) =

j∈In(w)
λj(w,D)Pj(t) −

k∈Out(w)
λ(w,D)kP(w,D)(t)
(6.18)
Having satisﬁed (6.8), the following also holds:
˙Pw(t) =
D

d=1
˙P(w,d)(t)
(6.19)
and, using equations (6.15)-(6.18), this time derivative is:
˙Pw(t) =
D

d=1
⎡
⎣
j∈In(w)
λj(w,d)Pj(t) −

k∈Out(w)
λ(w,d)kP(w,d)(t)
⎤
⎦
(6.20)
Making this equation equal to (6.14), we have
D

d=1
⎡
⎣

k∈Out(w)
λ(w,d)kP(w,d)(t) −

j∈In(w)
λj(w,d)Pj(t)
⎤
⎦+ . . .

j∈In(w)
λjwPj(t) −

k∈Out(w)
λwkPw(t) = 0
(6.21)
and by re-arranging summation in this expression, we obtain:

j∈In(w)
λjwPj(t) −

k∈Out(w)
λwkPw(t) −

j∈In(w)
Pj(t)
D

d=1
λj(w,d) + . . .
D

d=1
⎡
⎣

k∈Out(w)
λ(w,d)kP(w,d)(t)
⎤
⎦= 0
(6.22)
From the proven condition (B), the following equation is true:
−

k∈Out(w)
λwkPw(t) +
D

d=1
⎡
⎣

k∈Out(w)
λ(w,d)kP(w,d)(t)
⎤
⎦= 0
(6.23)

58
6. Stochastic Micro-Agent Model Uncertainties
in view of equation (6.8):

k∈Out(w)
λwk
 D

d=1
P(w,d)(t)

−
D

d=1
⎡
⎣

k∈Out(w)
λ(w,d)kP(w,d)(t)
⎤
⎦= 0
(6.24)
Collecting together all the results dependent on k, we ﬁnally obtain:
D

d=1
⎡
⎣

k∈Out(w)
(λ(w,d)k −λwk)
⎤
⎦P(w,d)(t) = 0
(6.25)
This equation has to be satisﬁed for all t, including t = 0 and all the initial
conditions P(w,i)(0). This is possible only if

k∈Out(w)
λ(w,d)k =

k∈Out(w)
λwk = |Out(w)|λwk
(6.26)
which proves the condition (C) of the theorem, (6.7).
Q.E.D.
We should notice that Theorem 6.1 conditions are actually the constraints on
how the set of input (λj(w,d)) and output (λj(w,d)) transition rates and initial
conditions (P(w,d)) (d = 1, 2, . . . D) have to be chosen. The available degrees
of freedom in the parameter selection can be used for appropriate modeling
purposes.
The same degree of freedom does not exist if the input transition rates are
not dependent on d. In that case we have:
λj(w,d) = λjwp(bd),
j ∈In(w)
(6.27)
which satisﬁes Theorem 6.1. Similarly, for the output transition independent of
d, the only thing we can conclude is that:
λ(w,1)k = λ(w,2)k = . . . = λ(w,2)D,
k ∈Out(w)
(6.28)
Thus, if the P(t) is invariant under the state w splitting, the application of the
Theorem 6.1 condition (C) yields:
λ(w,d)k = λwk, d = 1, 2, . . .D
(6.29)
Theorem 6.1 is valid for Markov Chains and it can be, therefore, applied to
the Markov Chain which is embedded in the CT MCμA. However, in the case
of the original CT MCμA, we have:
Pw(0) =
	
X
ρw(x, 0)dx
(6.30)
where ρw(x, 0) is the initial PDF of the CT MCμA in the discrete state w. After
the state w decomposition, we have:
Pw(0) =
D

d=1
P(w,d)(0) =
D

d=1
	
X
ρ(w,d)(x, 0)
(6.31)

6.1 Discrete Parameter Uncertainty Case
59
Table 6.1. Constraints for the CTMCμA to CTMCμA modiﬁcation in the case of
the discrete parameter uncertainty: w - the CTMCμA discrete state with parameter b
dependence (b ∈{b1, b2, . . . bD}), λjw,λwk and ρw(x, 0) - the input transition rate, the
output transition rate and the initial PDF at discrete state w; (w, d) - the introduced
discrete states of the CTMCμA, λj(w,d ), λ(w,d)k and ρ(w,d)(x, 0) - the input transition
rate, the output transition rate and the initial PDF at discrete state (w, d); j ∈In(w),
k ∈Out(w), d = 1, 2, . . . D
Parameter dependent
Parameter independent
Input transition rates
λjw = PD
d=1 λj(w,d)
λj(w,d) = λjwp(bd)
Output transition rates |Out(w)|λwk = P
k∈Out(w) λ(w,d)k
λwk = λ(w,d)k
Initial probability
ρw(x, 0) = PD
d=1 ρ(w,d)(x, 0)
ρ(w,d)(x, 0) = ρw(x, 0)p(bd)
i.e., the condition (A) of Theorem 6.1 is satisﬁed only if:
ρw(x, 0) =
D

d=1
ρ(w,d)(x, 0)dx
(6.32)
If ρw,d(x, 0) does not depend on parameter b, then:
ρw(x, 0) =
D

d=1
ρ(w,d)(x, 0), d = 1, 2 . . . , D
(6.33)
which is satisﬁed because 
D
d=1 p(bd) = 1
Table 6.1 presents the conditions that must be satisﬁed to split the discrete
state w into the new discrete states (w, d). In this table, the cases, when the input
and output transition rates and the initial probability are dependent and when
they are independent on the uncertain parameter b, are listed in the separate
columns. The previous discussion about handling the discrete parameter uncer-
tainty in the state w is summarized in the three-step procedure listed bellow.
The three-step procedure for including the Discrete Parameter
uncertainty into the CT MCμA model
Step 1) Apply Theorem 1 ( Chapter 4) to the CT MCμA as if it is the case
without uncertainty.
Remark: The ith row of the PDE system that corresponds to the discrete state
i ∈Q is:
∂ρi(x, t)
∂t
=
N

j=1
λjiρj(x, t) −∇· (fi(x)ρi(x, t)) i = 1, 2, . . . N
(6.34)

60
6. Stochastic Micro-Agent Model Uncertainties
Step 2) Split the discrete state w, which depends on the parameter b, into the
discrete states (w, bd), which correspond to one of the possible realizations of the
parameter b ∈{b1, b2, . . . D}, d = 1, 2, . . .D. Then apply the results in Table 6.1
and update the transition rates. This substitution produces the CT MCμA.
Remark: The corresponding PDE system is
∂ρi(x, t)
∂t
=
N

j=1,j̸=w
λjiρj(x, t)−
D

d=1
λ(w,d)iρ(w,d)(x, t)−∇·(fi(x)ρi(x, t)) (6.35)
for all i ̸= w and instead of one equation for w, we now have D equations for
the discrete states (w, d)
∂ρ(w,d)(x, t)
∂t
=
N

j=1,j̸=w
λj(w,d)ρj(x, t) +
N

k=1,j̸=w
λ(w,d)kρ(w,d)(x, t) −. . .
∇· (fw,bd (x)ρ(w,d)(x, t)
(6.36)
Step 3) Re-index the discrete state, so that the new index includes the following
discrete states:
1, 2, . . . , w −1, (w, 1), (w, 2), . . . , (w, D), w + 1, . . . , N
(6.37)
The total number of the CT MCμA discrete states is now N + D −1.
The above procedure explains how to deal with the discrete parameter uncer-
tainty which appears in a single discrete state. If the parameter b is a vector,
then the original model must be extended with the number of discrete states
which correspond to the number of all possible vector values given their PDF
(p(b)). In the case when this type of uncertainty appears in more than one state,
each discrete state with uncertainty must be substituted by the discrete states
corresponding to each possible parameter value. The input and output rates
have to be arranged in the same way as it is explained above. The easiest way
to handle this case is to apply the three step procedure only to a single state
with uncertainty, obtain the associated CT MCμA, and then, with this model,
apply the same procedure on the next discrete state with uncertainty. Thus, we
conclude that the derived three-step procedure is general enough to be applied
in all cases of the CT MCμA with discrete parameter uncertainties.
6.2
Continuous Parameter Uncertainty Case
The approach to continuous parameter uncertainty of a CT MCμA is completely
based on the result derived in the previous section. We assume that the uncertain
parameter b takes the value from a range B ∈R1 with a probability given by
the PDF p(b). The development is based on the discretization of the range B. It
produces an CT MCμA with an inﬁnite number of discrete states. In the limit,
as the discretization step approaches zero, a system of equations, which incorpo-
rates the continuous parameter b, is derived. Using this system of equations, the

6.2 Continuous Parameter Uncertainty Case
61
Fig. 6.3. CTMCμA modiﬁcation: (a) part of the original CTMCμA (b) the state
w division using the parameter b discretization, w - the state with the parameter
uncertainty, ϵ −discretization step
systematic procedure to transform the CT MCμA state PDF dynamics equation
to a set of equations, which incorporates the parameter uncertainty, is obtained.
Figure 6.3a presents the original CT MCμA. The discrete state w is the one in
which the continuous dynamics depends on the parameter b. By discretizing the
range B, we can split the state w into the discrete states (w, d), d = 1, 2, . . . D,
each of them assigned to the parameter b ∈(bd −ϵ/2, bd + ϵ/2], where ϵ is
the discretization step. The system of equations that describes the CT MCμA
state PDF is the same as the one in step 2 of the three-step procedure from the
previous section. Denoting explicitly the continuous state space of the operator
∇by ∇x, the step 2 equations are :
∂ρi(x, t)
∂t
=
N

j=1,j̸=w
λjiρj(x, t) −
D

d=1
λ(w,d)iρ(w,d)(x, t) −. . .
∇x · (fi(x)ρi(x, t)), i ̸= w
(6.38)
∂ρ(w,d)(x, t)
∂t
=
N

j=1,j̸=w
λj(w,d)ρj(x, t) +
N

k=1,k̸=w
λ(w,d)kρ(w,d)(x, t) −. . .
∇x · (fw,bd (x)ρ(w,d)(x, t)
(6.39)
Taking into account that:
λj(w,d) =
	 bd +ϵ/2
bd −ϵ/2
λjw(b)db and λ(w,d)i =
	 bd +ϵ/2
bd −ϵ/2
λwi(b)db
(6.40)
equations (6.38) and (6.39) can be written as:
∂ρi(x, t)
∂t
=
N

j=1,j̸=w
λjiρj(x, t) −
D

d=1
	 bd +ϵ/2
bd −ϵ/2
λwi(b)ρ(w,d)(x, t)db −. . .
∇x · (fi(x)ρi(x, t)), i ̸= w
(6.41)

62
6. Stochastic Micro-Agent Model Uncertainties
∂ρw(x, bd, t)
∂t
=
N

j=1,j̸=w
λjw(bd)ρj(x, t) + . . .
N

k=1
λwi(bd)ρ(w,d)(x, t)db −∇x · (fw,bd (x)ρw(x, bd, t))
(6.42)
In equation (6.42), the following substitution is made:
ρ(w,d)(x, t) = ρw(x, bd, t)
(6.43)
which is a simple change of the notation, where the index d is substituted with
the corresponding parameter value bd, which is the parameter of ρw. Taking into
account that:
lim
ϵ→0
D

d=1
	 bd +ϵ/2
bd −ϵ/2
λwi(b)db =
	
B
λwi(b)db
(6.44)
and taking the limit ϵ →0 of equations (6.41) and (6.42) that also corresponds
to D →∞and bd →b, we obtain :
∂ρi(x, t)
∂t
=
N

j=1,j̸=w
λjiρj(x, t) −
	
B
λwi(b)ρw(x, b, t)db −. . .
−∇x · (fi(x)ρi(x, t)), i ̸= w
(6.45)
∂ρw(x, b, t)
∂t
=
N

j=1,j̸=w
λjw(b)ρj(x, t) +
N

k=1,k̸=w
λwi(b)ρw(x, b, t) −. . .
∇x · (fw,b(x)ρw(x, b, t)), ∀b ∈B
(6.46)
This system of PDE equations describes the CT MCμA PDF dynamics in
the presence of the parameter with the continuous parameter uncertainty of b.
This is a system with an inﬁnite number of equations because the integral in the
equation (6.45) can be solved only if the equation (6.46) is solved for each value
of the parameter b ∈B. One way to approach this problem is to approximate
the integral in (6.46) and to solve a large ﬁnite number of the equations (6.46).
The transition rates and the initial condition in the previous equations have to
satisfy the conditions given in Table 6.2. This table includes the cases when the
input and/or the output transitions of the state w are dependent or independent
on the parameter b.
The way to deal with the continuous parameter uncertainty presented above
represents the case when the uncertainty appears in a single discrete state. If this
type of uncertainty appears in more than one state, then the set of equations
(6.45) has as many integral terms as the discrete states with uncertainty. To each
integral term, i.e., to each discrete state with uncertainty, a system of equations
of the type (6.46), is assigned.

6.3 Numerical Example
63
Table 6.2. Constrains on the equation set that incorporates the continuous parameter
uncertainty: w - the CTMCμA discrete state with the parameter b ∈B λjw,λwk and
ρw(x, 0) - the input transition rate, the output transition rate and the initial PDF at the
discrete state w; λjw(b), λwk(b) and ρw(x, b, 0) - parameters and the initial condition
of the new set of equations that incorporates uncertainty. j ∈In(w), k ∈Out(w)
Parameter dependent
Parameter independent
Input transition rates
λjw =
R
B λjw(b)db
λjw(b) = λjwp(b)
Output transition rates |Out(w)|λwk = P
k∈Out(w) λwk(b)
λwk = λwk(b)
Initial probability
ρw(x, 0) =
R
B ρw(x, b, 0)db
ρw(x, b, 0) = ρw(x, 0)p(b)
6.3
Numerical Example
In this section, we will apply the theory developed in this chapter to the TCR trig-
gering dynamics model of Section 5.1. To clarify, we depict this model again in
Figure 6.4. To this model, we apply the assumption that the TCR dynamics of a
T-cell, while it is conjugated to the APC, is identical for all the T-cells in the pop-
ulation. However, the intensity of the individual T-cell TCR internalization in the
T-cell-APC conjugate depends on how many MHC-peptide complexes are present
on the surface of the APC. Because of that, we should take into account the pa-
rameter uncertainty of the TCR dynamics in the conjugated discrete state.
The model depicted in Figure 6.4 is also used in Section 5.3 for the analysis
of experimental data. There we concluded that TCR PDF is equivalent to the
normalized TCR distribution, and that steady state TCR PDF and dynamics
of the average TCR amount can be explained using the following continuous
dynamics of discrete states (Section 5.3, Equations (5.27)-(5.29)) :
f2(x) = −k2x ,
f3(x) = k3
x
ln(x)
(6.47)
where:
k2 = σ2
∞λ23
M∞
,
k3 = σ2
∞λ32
(6.48)
and
λ12 = λ32 = 7, λ23 = 7000, M∞= log10(50), σ∞= 0.27
(6.49)
The parameter unit is min−1. The predicted steady state TCRs PDF ηs(x)
and average value η(t), using these parameter values and equations from Ap-
pendix C, are presented in Figures 6.6 and 6.7, respectively.

64
6. Stochastic Micro-Agent Model Uncertainties
Fig. 6.4. CTMCμA model of the T-cell - APC interaction: 1 -never conjugated,
2 -conjugated, 3 -free, a - conjugate formation, b - conjugate dissociation [53], c⃝2003
IEEE
The uncertain parameter of conjugated discrete state is k2. To describe its
uncertainty, the values and the probability of k2 realization, when the T-cell
enters the conjugated discrete state, must be speciﬁed. We will assume that
uncertain parameter k2 can take the three discrete values k1
2, k2
2, k3
2 with the
probability:
p(k1
2) = p(k2
2) = p(k3
2) = 1
3
(6.50)
This reﬂects our assumption that all the three values are equally probable when
T-cell enters the conjugated state.
Applying the results summarized in Table 6.1, we can derive the model
CT MCμA, which includes the parameter k2 uncertainty, presented in Figure
6.5. This model has ﬁve discrete states. The states (2, 1), (2, 2) and (2, 3) are
the result of the state 2 splitting, and the dynamics of each state resulting from
state 2 are f 1
2 (x), f 2
2(x) and f 3
2 (x), respectively. Based on Table 6.1, we can ﬁnd
that the transition rates of the CT MCμA model are:
λ1(2,1) = λ1(2,2) = λ1(2,1) = λ12/3
(6.51)
λ(2,1)3 = λ(2,2)3 = λ(2,3)3 = λ23
(6.52)
λ3(2,1) = λ3(2,2) = λ3(2,1) = λ32/3
(6.53)
Using the equations for the CT MCμA model (Figure 6.5), given in Appendix
C, we can predict the steady state TCR PDF and the average value of the TCRs
for the two cases of parameter k2 uncertainty, where k2
2 = k2. In the ﬁrst case,
parameter values k1
2 and k3
2 deviate 10% from the value of k2, which means that
k1
2 = 0.9k2 and k3
2 = 1.1k2. In the second case, parameter values deviate 20%
from the value of k2, meaning that k1
2 = 0.8k2 and k3
2 = 1.2k2. The results of the
prediction for these two cases will have superscript 10% and 20%, respectively.
The prediction of the steady state TCR PDF η10%(x) and η20%(x) are pre-
sented in Figure 6.6 and the average amount TCR predictions ¯η10%(t) and

6.3 Numerical Example
65
q=1
u(t)=b
1
x(t) = f (x)
y(t)=x(t)
q={2,1}
x(t)=f  (x)
2
y(t)=x(t)
x(t) = f (x)
3
q=3
y(t)=x(t)
q={2,2}
x(t)=f  (x)
2
y(t)=x(t)
q={2,3}
2
y(t)=x(t)
1{2,1}
x(t)=f  (x)
.
.
.
.
.
1{2,2}
1{2,3}
3{2,1}
3{2,2}
3{2,3}
{2,3}3
{2,2}3
{2,1}3
2
1
3
Fig. 6.5. CTMCμA model of the T-cell - APC interaction, which includes the pa-
rameter k2 uncertainty: 1 - never conjugated; (2, i) - conjugated with the dynamics
f i
2(x) corresponding to parameter value ki
2, i = 1, 2, 3; 3 -free; a - conjugate formation;
b - conjugate dissociation
3
10
0
101
102
10
Amount of TCRs (x)
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
s(x)
20%
(x)
10%
(x)
(x,0)
Fig. 6.6. Steady state and the initial TCR PDF, based on [75]: ηs(x) - the CTMCμA
model predicted steady state distribution (dotted) [53]; η(x, 0) - normalized smoothed
initial TCR PDF [53]; η10%(x) - steady state prediction with 10% deviation of parame-
ter values k1
2 and k3
2; η20%(x) - steady state prediction with 20% deviation of parameter
values k1
2 and k3
2, c⃝2003 IEEE
¯η20%(t) can be seen in Figure 6.7. From these results, we can see that the pre-
diction based on the original model without uncertainty, CT MCμA, and on
the model with uncertainty, CT MCμA, are slightly diﬀerent. Therefore, we can
conclude that predictions based on the original model are not very sensitive to
the k2 parameter uncertainty in this case.

66
6. Stochastic Micro-Agent Model Uncertainties
Time [min]
t
10%
20%
Fig. 6.7. Average amount of TCRs (relative to the initial TCR amount) [53]:
ηexp(t)-experimentally obtained values (o) [75], η(t)-the model predicted average val-
ues, η10%(t), η20%(t)-the model predicted average values with 10% and 20% deviation
of parameter values k1
2 and k3
2, c⃝2003 IEEE
6.4
Summary
In this section we present an approach to dealing with parameter uncertain-
ties of the CT MCμA continuous dynamics with the parameter uncertainty de-
scribed by its PDF. Both discrete and continuous parameter uncertainties are
considered. The method to handle the parameter uncertainty is developed by the
modiﬁcation of the original CT MCμA model to the CT MCμA model, which
incorporates the parameter uncertainty. In the case of a discrete parameter, the
three step procedure, which yields this modiﬁcation, is derived. In the continuous
parameter uncertainty case, the same approach leads us to a system of partial
diﬀerential equations with the integral terms that include state variables.
Key point
• The three step procedure that modiﬁes the original CT MCμA model to the
CT MCμA model which includes discrete parameter uncertainty.

7. Stochastic Modeling and Control of a
Large-Size Robotic Population
By studying the problem of modeling biological systems, a more general approach
to study a system composed of a large population of individuals is developed.
We ﬁnd this approach general enough to provide results of potential interest
in engineering applications concerning Multi-Agent systems (MAS). The main
motivation of our approach is to provide fundamental principles of modeling and
control for large-size populations, providing math-based tools for the analysis
and control design from speciﬁcations.
Here we assume that the robotic population can execute primitive tasks driven
by individual robot controllers and the local information. For example, each
primitive task may correspond to one motion primitive. We introduce a model
of robotic population which is based on the Micro-Agent modeling approach,
leading to a system of partial diﬀerential equations (PDE) that describes the
evolution of the population state. Our model describes not only the task alloca-
tion among the robots, but also the distribution of the robots over the operating
space [56]. Such model can be used to predict the evolution of the population
and, subsequently, design controllers or supervisors capable of changing the pop-
ulation behavior by the suitable adjustment of appropriate control parameters.
The state-of-the-art in multi-robot system control research concerns research
on distributed robot control. It has been shown that distributed control in
Robotics and distributed decision making in social insects leads to robust re-
sponses to environmental conditions or the population size. However, this work
concerns the centralized control of robotic populations, as we claim that central-
ized control is important for achieving a controllable composition of the popu-
lation behavior.
The meaning of central control of population is that the human operator, or
centralized controller, can send commands for task execution, task cancellation
or task switching. This way the population is controllable as a single conven-
tional general purpose robot. The execution of a primitive task sequence ensures
that the population can accomplish more complex tasks. The centralized control
strategy for the large-size robotic population must take into account the uncer-
tainty of each individual robot reaction, due to communication problems, local
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 67–89, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

68
7. Stochastic Modeling and Control of a Large-Size Robotic Population
characteristics of the surrounding environment, etc. This uncertainty is included
in our modeling approach and the PDE system that describes the state evolu-
tion of a robotic population. The proposed centralized controller is based on the
Pontryagin-Hamiltonian optimal control theory for PDEs [21, 46], and provides
control of the population space distribution shape.
To motivate our modeling approach to a large size robotic population, we
introduce an example in Section 7.1. This example shows a scenario where the
robots in the population are receiving commands to change their behavior, but
their response is a stochastic process. In Section 7.2, we illustrate the capability
of our modeling approach to predict the robotic population position PDF. Ap-
plication of our modeling approach to the robotic population control problem
is discussed in Section 7.3, where we assume that the stochastic parameters of
robots are control inputs to the robotic population. We introduce the optimal
control problem which aims at maximizing the presence of a robotic population
in a given region. We apply Minimum Principle for PDE to this problem and
present the developed theory in Section 7.4 [55].
Fig. 7.1. a) Robotic population controlled by three aerial robots (sources), b) the
vector ﬁelds created by control signal sources [56], c⃝2003 IEEE
7.1
Robotic Population Mission Scenario
The scenario we use here introduces the modeling and control approach which
assumes a robotic population of large number of small mobile robots. The term
small is applied here to explain that the robot dimension is signiﬁcantly small
compared to the dimensions of the region where the robot is operating. We also
assume that the robotic population is sparse and, therefore, no local interaction
among the robots is considered.
The robots are initially concentrated on a location over an unexplored terrain
(e.g., a mission command station) and controlled by the signals produced by
signal sources, e.g., aerial robots (Figure 7.1). The active signal of each source is
a command to the robots to change behavior, which in our case means to change

7.1 Robotic Population Mission Scenario
69
the motion direction. Under this scenario, each robot in the population moves
in the direction of an active signal source. Under the assumption that the signal
sources are far away from the population and that the velocity of the robot is a
constant unit (v = 1), the robotic motion model is:
˙x1(t) = cosθ(t)
(7.1)
˙x2(t) = sinθ(t)
(7.2)
where θ is an angle of the motion produced by the signals. In our scenario,
we have three signal sources, which means three possible angles of motion,
i.e., three possible discrete states of the robot. Each discrete state corresponds
to one signal source, i.e., one value of motion angle θ. Considering the plane
x1 × x2 (Figure 7.1b), we assume that Source 1 produces motion with angle
θ = π/4, Source 2 straight motion θ = 0 and Source 3 produces motion with
angle θ = −π/4.
There are good reasons for considering that the commands sent to the robots
in the population produce the stochastic change of their discrete state, i.e.,
change of their motion direction. The common denominator for these reasons
is that each robot in the population we are considering is an independent device
with its own task priorities. Because of that, every robot will not react imme-
diately to the command it receives. The actual reaction of the robot to the
command depends on many uncertain factors such as terrain obstacles, commu-
nication visibility, etc., and these factors can be roughly divided into the two
classes of reasons:
• physical constraints to the robot;
• limitation of robot resources.
The ﬁrst class contains factors like the existence of a physical barrier between
the speciﬁc robot and the signal source, or an obstacle in the direction of the
commanded motion. In the latter case, the reaction does not happen even if the
command is received correctly.
The second class is related to limited robotic resources. We would like to steer
the whole population of robots with an external command. However, not all of
the robots will react in the same time. For example, the robot endowed with
solar-light re-chargeable batteries might rest till its batteries have been fully
re-charged, and would not react to commands meanwhile.
To model the robot which changes the discrete states stochastically, we can
use the Micro-Agent based modeling approach. In our examples, we assume
that stochastic transitions over diﬀerent robotic behaviors, i.e., transitions over
discrete states, can be modeled as a continuous time Markov Chain. Because of
this assumption, we can use the CT MCμA depicted in Figure 7.2 to model the
robotic population of our example.
The discrete state of the robot depends on the active signal source which
forces the robot to move under the vector ﬁeld fi(x) = [cos(θi) sin(θi)]T ; in
this example θ1 = −π/4, θ2 = 0, θ3 = π/4. The stochastic transition from the
discrete state i to the discrete state j is described by the transition rate λij,

70
7. Stochastic Modeling and Control of a Large-Size Robotic Population
Fig. 7.2. Stochastic Micro-Agent model of an individual robot. The robot can be in
one of the discrete states q. In each state, it has diﬀerent motion deﬁned by the state
variable x = [x1 x2]. Position y = [x1 x2] is the output of the model. The input is the
stochastic sequence of events, which generates the transitions from the state i to the
state j, λij [56], c⃝2003 IEEE.
i, j = 1, 2, 3. Therefore, if we deﬁne the vector of the Micro-Agent discrete
state probabilities P = [P1 P2 P3]T , the evolution of that vector obeys
˙P = LT P(t)
(7.3)
where the Markov Chain transition matrix L is given by:
LT =
⎡
⎢⎢⎢⎣
−λ12
λ21
0
λ12 −λ21 −λ23 λ32
0
λ23
λ32
⎤
⎥⎥⎥⎦
(7.4)
The CT MCμA state PDF is a vector of the three functions:
ρ(x, t) = [ρ1(x, t) ρ2(x, t) ρ3(x, t)]T
(7.5)
where x = [x1 x2]T is the vector of the robot position. The vector element
ρi(x, t), i = 1, 2, 3 is the PDF of the robots in the discrete state i at the position
x. The time evolution of the CT MCμA state PDF satisﬁes the following system
of PDEs:
⎡
⎢⎢⎢⎣
ρ1(x, t)
ρ2(x, t)
ρ3(x, t)
⎤
⎥⎥⎥⎦= LT
⎡
⎢⎢⎢⎣
ρ1(x, t)
ρ2(x, t)
ρ3(x, t)
⎤
⎥⎥⎥⎦−
⎡
⎢⎢⎢⎣
∇· (f1(x)ρ1(x, t))
∇· (f2(x)ρ2(x, t))
∇· (f3(x)ρ3(x, t))
⎤
⎥⎥⎥⎦
(7.6)
The PDF of the robot position η(x, t) at position x and time t is given by
the “total mass” of the probability given x and t, i.e, it is the sum of state PDF
components ρi(x, t)
η(x, t) = ρ1(x, t) + ρ2(x, t) + ρ3(x, t)
(7.7)

7.2 Robotic Population Position Prediction
71
The equations (7.6) and (7.7) give us the capability to predict the time evolution
of the robots position PDF.
The robotic scenario we introduce here is the simpliﬁed version of possible real-
world examples. One major simpliﬁcation is that the communication among the
robots is not considered. This helps us achieve a mathematical description suit-
able to model large-size robotic populations which can be exploited for model-
based control design. The local coordination among the robots may be included
in the model through the vector ﬁelds fi or the transition matrix L that can
depend on ρ and its derivatives, i.e., ∂ρ
∂t . Taking into account that L depends on
the position x, diﬀerent environmental conditions in the operating region can be
included. For example, in the rocky part of the operating region we would ex-
pect that the probability of changing the motion direction would be considerably
higher than on the ﬂat part of the terrain.
7.2
Robotic Population Position Prediction
To illustrate our modeling approach to the robotic population of the previous
section, we predict here the evolution of the robotic population position PDF. In
order to predict the position PDF evolution, we should know the initial PDF and
the discrete state transition rates. By using these data, we can generate the posi-
tion PDF prediction by solving equation (7.6) and, then, applying equation (7.7).
We consider below the prediction of robots position PDF for the model de-
picted in Figure 7.2 and the two sets of transition rate parameters. The vector
of the initial state PDFs is
ρ(x, 0) =
⎡
⎢⎢⎢⎣
ρ1(x, 0)
ρ2(x, 0)
ρ3(x, 0)
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
0
N

02×1, diag(σ2, σ2)
	
0
⎤
⎥⎥⎥⎦
(7.8)
which means that at the time t = 0 all of the robots are moving straight and
their distribution is 2D Gaussian N

02×1, diag(σ2, σ2)
	
, with zero mean and
diagonal covariance matrix with σ = 0.1. This choice of the initial condition
means that the initial discrete state probabilities are given by
P(0) = [P1(0) P2(0) P3(0)]T = [0 1 0]T
(7.9)
To solve the PDE system (7.6), we need boundary conditions. They should
be carefully chosen in order to avoid a conﬂict between the PDE solution and
the boundary condition constraint. The useful direction to solve this conﬂict is
to understand the physics of the problem which is described by the PDE [20].
In our case, we are using the boundary condition
ρ(x, t) = [0 0 0]T , ∀t ∈[0, T ], x ∈∂X
(7.10)
where set ∂X refers to the points on the boundary of the region in which we
are solving our PDE system and T denotes the terminal time of our solution.

72
7. Stochastic Modeling and Control of a Large-Size Robotic Population
This condition make sense if the set ∂X region cannot be reached in the state
space during the time interval [0, T ]. In our case, the terminal time T is 2h. The
transition parameters used for the prediction of the position PDF in two cases
(I) and (II) are given in Table 7.1
Fig. 7.3. PDF of the robot population states ρi(x, t), the PDF of the robots position
η(x, t), the transition rates Case I, Table 7.1, the plots shown at time instants
t = 0, 0.39, 0.79, 1.18, 1.57, 1.96h (from the left to the right in the picture) [56], c⃝
2003 IEEE
Table 7.1. CTMCμA model parameter values [h−1]
Case λ12 λ21 λ23 λ32
I
0.1 0.9 0.1 0.5
II
0.4 0.5 0.5 0.1
The evolution of the robotic population state and the position PDF in Case
I are presented in Figure 7.3. As it can be seen in the ﬁgure, the population
dominantly moves in the direction of the vector ﬁeld f1(x). The PDF of discrete
state 2, ρ2(x, t) has some initial inﬂuence on the shape of the position PDF
η(x, t) at the beginning of the observed time interval, but then this inﬂuence
diminishes. Since the contour shape of ρ3(x, t) has little inﬂuence on the shape
of the contour plot η(x, t), we can conclude that the inﬂuence of vector ﬁeld f3(x)
on the population position PDF shape is insigniﬁcant. Both of these conclusions
are reasonable and also come from the comparison of the transition rates.
In Case II, the state PDF of the CT MCμA states over the discrete space is
more uniform. This explains why η(x, t) has a more symmetrical shape than in
Case I. However, it could be noticed from the density of the contours that the
probability of the CT MCμA remaining in state 3 is slightly higher than any
other. The analysis of the transition rate values shows that this is due to the
discrete state probability P3(t) being slightly higher than P1(t) and P2(t).

7.3 Robotic Population Optimal Control Problem
73
From the previous results, we may conclude that, in these examples, the dom-
inant direction of the population motion is directed by the vector ﬁeld fi(x) of
the most probable discrete state i. However, the population spreading shape
depends in general on the initial PDF and transition matrix L.
Fig. 7.4. PDF of the robots population states ρi(x, t), the PDF of the robots position
η(x, t), the transition rates Case II, Table 7.1, the plots shown at time instants
t =
0, 0.39, 0.79, 1.18, 1.57, 1.96h (from the left to the right in the picture) [56], c⃝2003
IEEE
The capability to predict the inﬂuence of random changes of robotic behavior
in the population and the population position PDF is interesting for the pur-
pose of analysis, but also for the design of control algorithms for large robotic
populations.
7.3
Robotic Population Optimal Control Problem
Considering the results of the previous section, we will now introduce an optimal
control problem for a large-size robotic population [55]. Let us suppose that the
region Ω ∈X in Figure 7.3 and 7.4 is of some particular interest for our robotic
mission task and that we want a maximum possible number of robots at time
instant T in that region. It is obvious that the set of the transition rates in Case
I, Table 7.1, satisﬁed better our preference than the set of the transition rates
in Case II, Table 7.1. Assuming that the transition rate matrix depends on a
control vector u(t) = [u1(t) u2(t) u3(t) u4(t)]T as λ12(t) = u1(t), λ21(t) = u2(t),
λ23(t) = u3(t), λ32(t) = u4(t), we can formulate the optimal control problem
to ﬁnd a control u(t) such that the probability of robotic position η(x, T ) is
maximal, i.e., the following cost function is minimal:
J(u) = −

Ω
η(x, T)dx = −

Ω
(ρ1(x, T) + ρ2(x, T) + ρ3(x, T ))dx
(7.11)
In this optimal control problem, the transition rates are the result of the en-
vironment and limited robot resources. We assume that we can control these

74
7. Stochastic Modeling and Control of a Large-Size Robotic Population
rates. For example, if the commands to the population are re-sent with some
frequency, we can control the transition rates by controlling this frequency. A
higher re-sending frequency increases the probability that the robot will receive
the command correctly. This is an open loop control problem and we do not take
into account how the changes of transition rates due to uncertain environment
changes should be compensated.
Criterion (7.11) can be rewritten in a more general form as:
J(u) = −

X
wT (x)ρ(x, T )dx
(7.12)
where u is a vector of the population parameters that may be set externally by
an appropriate command sent to the population and w(x) = [w1(x) w2(x) w3(x)]
is a vector of weighting functions:
wi(x) =
⎧
⎨
⎩
1,
x ∈Ω
0, otherwise
, i = 1, 2, 3
(7.13)
The vector of weighting functions is introduced because it allows us to specify
the other types of optimal criterion we can minimize. Two other examples of
weighting functions are:
wi(x) =
⎧
⎨
⎩
1,x ∈Ω1 ∪Ω2, Ω1, Ω2 ∈Ω
0,
otherwise
(7.14)
wi(x) =
⎧
⎨
⎩
e(x−x)T Σ−1(x−x),
x ∈Ω
0,
otherwise
(7.15)
Using the weighting (7.14) in criterion (7.12) means the maximization of the
probability over the region composed of two parts which are not necessarily
connected. Obviously the value of the weighting function can be diﬀerent from
either 0 or 1. Using a weighting function such as (7.15) also deﬁnes a preferred
PDF shape in the region Ω.
In the text below, we will assume that our robotic population can be modeled
by a CT MCμA which can be controlled and its state PDF evolution is given by
the following PDE system:
∂ρ(x, t)
∂t
= LT (u)ρ(x, t) −
⎡
⎢⎢⎢⎢⎢⎢⎣
∇· (f1(x)ρ1(x, t))
∇· (f2(x)ρ2(x, t))
...
∇· (fN(x)ρN(x, t))
⎤
⎥⎥⎥⎥⎥⎥⎦
(7.16)
where u is a control input which is a time function
u : [0, T ] →U and u ∈Uad(0, T ; U)
(7.17)

7.3 Robotic Population Optimal Control Problem
75
inﬂuencing the transition matrix L(u), where Uad(0, T ; U) is a set of admissible
control functions taking values in the set U. We also assume that the initial con-
dition ρ(x, 0) is given, as well as the boundary condition ρ(x, t) = 0, ∀t ∈[0, T ],
∀x ∈∂X, where ∂X is the set of boundary points of the region X. This boundary
condition says that the boundary region cannot be reached in the state space
by any means during the time interval [0, T ], which is reasonable for conve-
niently chosen vector ﬁelds describing the continuous dynamics of each discrete
state.
The system of PDEs (7.16) can be written as:
∂ρ(x, t)
∂t
= F(u)ρ(x, t)
(7.18)
where F is a linear operator:
F(u) = LT (u) −diag(φ1, φ2, . . . φN)
(7.19)
φk =
n

j=1
∂f j
k(x)
∂xj
+ f j
k(x) ∂
∂xj
, k = 1, 2, . . .N
(7.20)
where f j
i (x) is the jth component of the vector fi(x) = [f 1
i (x) f 2
i (x) . . . f n
i (x)].
The index is j = 1, 2, . . . n since x ∈Rn.
The optimal control problem can be summarized as to determine the optimal
control u = u∗which minimizes the objective function:
J(u) = −

X
w(x)T ρ(x, T)dx
(7.21)
under the constraint
∂ρ(x, t)
∂t
= F(u)ρ(x, t)
(7.22)
where w(x)T = [w1(x) w2(x) . . . wN] is a vector of weighting functions, and T is
a time instant when the objective function should be minimal. We should not
forget that under this condition, the corresponding initial ρ(x, 0) and boundary
ρ(x, t), x ∈∂X conditions must be satisﬁed.
The optimal control problem (7.16)-(7.21) is a PDE optimal control problem.
To solve this problem, the Minimum Principle for PDE [21] can be exploited in
a similar way as Pontryagin Minimum Principle can be exploited to solve ODE
optimal control problems [50]. Along this line of reasoning, our control problem
can be considered as a special case of a more general optimal control problem of
the evolution equation (D.1) (see Appendix D), where:
ρ′(t) = ∂ρ(x, t)
∂t
(7.23)
f(ρ(t), u(t), t) = F(u(t))ρ(x, t)
(7.24)
Considering the criterion (D.2) that must be minimized in the general problem
formulation (Appendix D), we can ﬁnd that

76
7. Stochastic Modeling and Control of a Large-Size Robotic Population
f0(ρ(t, u), u(t), t) = 0
(7.25)
ρ0(T, u) = g0(ρ, ρ(T, u)) = J(u) = ⟨−w(x), ρ(x, T)⟩
(7.26)
where the scalar product of the two functions, say φ(x) and ψ(x), is denoted as
⟨φ, ψ⟩and deﬁned as
⟨φ, ψ⟩=

X
φT (x)ψ(x)dx
(7.27)
Since the operator F(u) is linear and f0(ρ(t), u(t), t) = 0, the Fr´echet derivatives
of f(ρ(t), u(t), t) and f0(ρ(t), u(t), t), regarding ρ, are given by:
∂ρf(ρ(t), u(t), t) = F(u(t)) ,
∂ρf0(ρ(t), u(t), t) = 0
(7.28)
Thus, under the condition that the linear F(u) operator is bounded, ∥F(u(t))∥<
∞, we have satisﬁed all the conditions (D.11)-(D.14) and we can apply the
corresponding Minimum Principle, (Theorem D.1 in Appendix D). This the-
orem ensures the existence of the scalar z0 and the vector functions z(x) =
[z1(x) z2(x) zN(x)]T such that the optimal control satisﬁes:
u∗= arg min
u∈Uad H(ρ∗(x, t), u(t), t) = arg min
u∈Uad⟨π, Fρ∗⟩
(7.29)
where π(x, t) is the solution of the adjoint equation that depends on z0 and z:
∂π(t)
∂t
=
−F T (u∗)π(t)
(7.30)
π(T )
=
z −z0w(x)
(7.31)
and ρ∗(x, t) is the solution of the equation when the optimal control u∗is applied,
i.e.:
∂ρ∗(x, t)
∂t
= F(u∗(t))ρ∗(x, t), ρ∗(x, 0) = ρ(x, 0)
(7.32)
Since in our problem formulation we do not have a target condition, which must
be satisﬁed at time T , Theorem 4 can be applied with:
z0 = 1, z(x) = 0
(7.33)
Then the adjoint equation becomes
∂π(t)
∂t
= −F T (u∗)π(t) ,
π(T ) = −w(x)
(7.34)
To solve the optimal control problem, we should search for the control u∗
which simultaneously satisﬁes Equations (7.29), (7.32), and (7.34). In ODE
optimal control theory this problem is the so-called two-point-boundary-value
problem, and in some cases that problem can be handled either analytically or
numerically. Solving the PDE optimal control is even more diﬃcult because the
“values” at two points are functions. Still, similarly as in the case of ODE opti-
mal control, it is possible that, based on this equation, we can ﬁnd an optimal
control. However, it is also possible that (7.29), (7.32), and (7.34) are in such
forms that we cannot infer what the optimal control is. This is a problem of “sin-
gular controls” within the optimal control problem which has to be investigated
carefully. In the following section, we will present an example that illustrates the
previously presented modeling and optimal control theory.

7.4 Example of Using the PDE Minimum Principle for RPC
77
7.4
Example of Using the PDE Minimum Principle for
Robotic Population Control
The example presented here is very similar to the one presented in the introduc-
tory Section 7.1. However, for the purposes of simplicity, we assume that each
robot can move only in one dimension, which means that they can move left,
right or stop [55]. Therefore, a one dimensional robots position distribution will
be considered. Robots are controlled by three signals L, R and S (Fig. 7.5a). If
the signal L is active, it attracts robots to move left. Signal R attracts robots
to move right and signal S send a stop command. Obviously, each robot in the
population can be either in state 1 = move left, 2 = move right or 3 = stop. If
the discrete dynamics of these three states can be described by a Markov Chain,
the full state of this robot population can be described by a CT MCμA, see
ﬁgure 7.5b. The transition rates u1(t), u2(t) and u3(t) are the control variables
and we assume that u1(t), u2(t), u2(t) ∈[0, umax].
To formulate the control problems, we will assume that:
• the motion to the left is given by
˙x(t) = f1(x, t) = k1, k1 = 0.5
(7.35)
• the motion to the right is given by
˙x(t) = f2(x, t) = k2, k2 = −0.25
(7.36)
• and obviously, the stop motion is given by
˙x(t) = 0
(7.37)
The initial robotic distribution, i.e., the PDF of the robot positions η(x, 0), is
η(x, 0) = ρ1(x, 0) + ρ2(x, 0) + ρ2(x, 0)
(7.38)
where ρ1(x, 0), ρ2(x, 0) and ρ3(x, 0) are the initial PDFs of the robots moving
left, moving right and not moving, ρ1(x, 0) = 0, ρ2(x, 0) = 0 and
ρ3(x) =
⎧
⎨
⎩
1
√
0.02πexp(−(x−2.5)2
0.02
),
2 < x < 3
0,
otherwise
(7.39)
Fig. 7.5. a) A robotic population controlled by three signal sources, b) The robotic
population Micro-Agent model [55], c⃝2006 IEEE

78
7. Stochastic Modeling and Control of a Large-Size Robotic Population
respectively. Deﬁning the time duration of the robotic mission as T = 3h and
the weighting function
w3(x) =
⎧
⎨
⎩
1
√
0.01πexp(−(x−1.75)2
0.01
),
1.25 < x < 2.25
0,
otherwise
(7.40)
the optimal control problem is to ﬁnd the optimal transition rates u1(t), u2(t),
u3(t) ∈[0, umax], umax = 2, such that the objective function
J = −

X
[0 0 w3(x)]



wT
ρ(x, T)dx,
X = [xa, xb], xa = 0, xb = 5
(7.41)
is minimal. The motivation for the weighting function w3(x) choice is to compute
a control that will move the center of the robotic distribution 2.5 to 1.75, and
make the distribution slightly sharper.
The following system of equations describes the state PDF evolution of a
robotic CT MCμA
⎡
⎢⎢⎢⎣
∂ρ1(x,t)
∂t
∂ρ2(x,t)
∂t
∂ρ3(x,t)
∂t
⎤
⎥⎥⎥⎦= (Fu(u(t)) + F∂)
⎡
⎢⎢⎢⎣
ρ1(x, t)
ρ2(x, t)
ρ3(x, t)
⎤
⎥⎥⎥⎦
(7.42)
with
Fu(u) =
⎡
⎢⎢⎢⎣
−u2 −u3
u1
u1
u2
−u1 −u3
u2
u3
u3
−u1 −u2
⎤
⎥⎥⎥⎦
(7.43)
F∂= diag(−k1
∂
∂x, −k2
∂
∂x, 0)
(7.44)
where u(t) = [u1(t) u2(t) u3(t)]T and t in u(t) is omitted in (7.43). Equation
(7.42) can be taken in the form of equation (7.18), i.e.:
F(u(t)) = Fu(u(t)) + F∂
(7.45)
To apply Theorem D.1, in Appendix D, we should ﬁrst deﬁne a state space for
ρ and its co-state π. We will assume that the solutions ρ, π of (7.42) and (7.34),
respectively, are from the same set of functions E that satisﬁes:
ρ, π ∈E
(7.46)
ρ, π
:
X →L2 × L2, ∂X →0
(7.47)
d(ρ2
i ), d(π2
i )
:
Lebesgue integrable, i = 1, 2
(7.48)

7.4 Example of Using the PDE Minimum Principle for RPC
79
The symbol L2 stands for the set of Lebesgue measurable functions (see Ap-
pendix D) and symbol d for the diﬀerentiation. Therefore, we take xa = 0,
xb = 5 in X = [xa, xb] and assume the boundary conditions
ρ(0, t) = ρ(5, t) = π(0, t) = π(5, t), t ∈[0, T ].
(7.49)
The nonzero intervals of w3(x) and ρ3(x, 0) ensure that these boundary condi-
tions are satisﬁed, i.e., due to the ﬁnite movement speed there is not a single
robot from the population that has time to reach the space X boundary position
xa or xb.
Using the scalar product deﬁned by (7.27), the space E is a Hilbert space with
the norm:
∥ρ∥E = ⟨ρ, ρ⟩
1
2
(7.50)
Therefore, from (7.24), we have
∥f(x, ρ, u)∥= ∥F(u)ρ∥= ⟨F(u)ρ, F(u)ρ⟩
(7.51)
and the operator norm
∥F(u)∥= max
∥ρ∥≤1 ∥F(u)ρ∥
(7.52)
To show that the operator F(u) is bounded, we use the triangular inequality:
∥F(u)∥= ∥Fu(u) + F∂∥≤∥Fu(u)∥+ ∥F∂∥
(7.53)
The linear operator F∂is symmetric and we will use it to ﬁnd its norm as:
∥F∂∥= max
∥ρ∥≤1 |⟨ρ, F∂ρ⟩|
(7.54)
Applying the deﬁnition of scalar product (7.27), we have
|⟨ρ, F∂ρ⟩| =


 xb=5
xa=0
−k1ρ1
∂ρ1
∂x dx +

 xb=5
xa=0
−k2ρ2
∂ρ2
∂x dx

(7.55)
where the term with k3 does not appear, since k3 = 0. By virtue of the space E
property (7.47):

 5
0
1
2ρi
∂ρi
∂x =

 5
0
d(ρ2
i ) = ρ2
i (xb, t) −ρ2
i (xa, t) = 0, i = 1, 2
(7.56)
|⟨ρ, F∂ρ⟩| = 0, ∀ρ
(7.57)
we can conclude that
∥F∂∥= 0
(7.58)
Fu(u) is a matrix with ﬁnite real coeﬃcients corresponding to the values in the
admissible set of the control Uad. For any choice of admissible control values,
there exists a maximal singular value σmax(Fu(u)), which is a ﬁnite number.
Therefore we can draw out the conclusion that the operator F(u) is bounded, i.e.:
∥F(u)∥≤
max
u1,u2,u3∈Uad ∥Fu(u)∥
(7.59)
and we can exploit Theorem D.1, in Appendix D, to ﬁnd the optimal control.

80
7. Stochastic Modeling and Control of a Large-Size Robotic Population
According to (7.34) and noting that:
F T
∂= −F∂
(7.60)
the system of equations which describes the evolution of the co-state is:
⎡
⎢⎢⎢⎣
∂π1(x,t)
∂t
∂π2(x,t)
∂t
∂π3(x,t)
∂t
⎤
⎥⎥⎥⎦= −(F T
u (u∗(t)) −F∂)
⎡
⎢⎢⎢⎣
π1(x, t)
π2(x, t)
π3(x, t)
⎤
⎥⎥⎥⎦
(7.61)
π1(x, t) = π2(x, t) = 0, π3(x, t) = −w3(T )
(7.62)
and the optimal control u∗(t) = [u∗
1(t) u∗
2(t) u∗
3(t)]T satisﬁes:
u∗(t) = arg min
u∈Uad H(t, ρ∗, u)
(7.63)
Using the deﬁnition of scalar product (7.27)
u∗(t) = arg min
u∈Uad

X
π(t)(Fu(u) + F∂)ρ∗(t)dx
(7.64)
Since in this expression only Fu depends on u, we have
u∗= arg min
u∈Uad

 xb=5
xa=0
π(t)(Fu(u))ρ∗dx
(7.65)
which can be presented in a linear form as
u∗= arg min
u∈Uad [u1(t)I1(t) + u2I2(t) + u3(t)I3(t)]
(7.66)
where
I1(t) =

 5
0
(π1 −π2)ρ∗
2 + (π1 −π3)ρ∗
3dx
I2(t) =

 5
0
(π2 −π1)ρ∗
1 + (π2 −π3)ρ∗
3dx
(7.67)
I3(t) =

 5
0
(π3 −π1)ρ∗
1 + (π3 −π2)ρ∗
2dx
and ρ∗
i = ρ∗
i (x, t), πi = πi(x, t) are computed for u∗. If we can compute I1(t),
I2(t) and I3(t), then the optimal control u∗(t) will be deﬁned as follows:
u∗
i =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
0,
Ii(t) > 0
umax
i
,
Ii(t) < 0
u∗
i ∈Uad,
Ii(t) = 0
, i = 1, 2, 3
(7.68)

7.4 Example of Using the PDE Minimum Principle for RPC
81
To compute the optimal control using this expression, we should prove that
either Ii(t) ̸= 0, ∀t[0, T ], or that Ii(t) = 0 only for a discrete set of time instants
tk. Otherwise, we can conclude that expression (7.66) is still valid, but cannot
help us calculate the control ui(t), because for Ii(t) = 0, the control can take
any value from the admissible set Uad. This is the “singular control” problem. In
that case some further structural properties of PDE systems (7.42) and (7.61)
must be examined [55].
One way to deal with the “singular control” problem is to modify the cost
function (7.41) adding the term which depends on control u and is penalized by
parameter ε > 0. This results in [55]
Jε = −

X
wT ρ(x, T ) + ε

 T
0
u2
1(t) + u2
2(t) + u2
3(t)dt
(7.69)
Using a small ε, we have J ≈Jε. Applying the Minimum Principle, the optimal
control u∗should satisfy
u∗(t) = arg min
u∈Uad

X
π(t)(Fu(u) + F∂)ρ∗(t) + εuTu
(7.70)
that, similarly as in equation (7.66), results in
u∗= arg min
u∈Uad

u1(t)I1(t) + u2I2(t) + u3(t)I3(t) + ε(u2
1 + u2
2 + u2
3)

(7.71)
i.e.,
u∗= arg min
u∈Uad Hε(t, ρ∗, u)
(7.72)
since the Hamiltonian Hε, corresponding to the problem with the cost func-
tion Jε, is
Hε(t) = H(t) + ε(u2
1(t) + u2
2(t) + u2
3(t))
(7.73)
The ﬁrst partial derivative of this Hamiltonian regarding the control compo-
nent ui(t) is
∂Hε(t)
∂ui(t) = Ii(t) + 2εui(t)
(7.74)
and solving ∂Hε(t)
∂ui(t) = 0, we ﬁnd that the optimal control can be expressed as
u∗
i =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
0,
−Ii(t)
2ε
< 0
umax
i
,
−Ii(t)
2ε
> umax
−Ii(t)
2ε ,
elsewhere
, i = 1, 2, 3
(7.75)
Now, the problem of the singular control does not exist. The above expression
is exact, but u∗
i can be computed only when Ii is known at each point. Since
we do not have an expression for Ii, and it also depends on u∗, the only way to
compute the optimal control is to apply some iterative numerical procedure that

82
7. Stochastic Modeling and Control of a Large-Size Robotic Population
will compute u∗, which simultaneously satisﬁes (7.42), (7.61), (7.67) and (7.72).
Avoiding the “singular control” problem presented here results in an iterative
numerical algorithm for computing the optimal control, proposed in the next
section, that will not indeﬁnitely stop at the points where Ii(t) = 0, without
warranty that the computed control is optimal. The price paid is that we are
not solving the original control problem, but the control problem with the cost
function Jε.
7.4.1
Complexity of Numerical Optimal Control
To solve the optimal control problem of the previous section numerically, we
can deal with the discrete approximations of the control u(t) and the functions
ρ(x, t), π(x, t) and w(x). This also results in dealing with the approximative val-
ues of the cost function ˆJε and the corresponding Hamiltonian ˆHε. The control
computed in this way is so-called numerical optimal control [78].
The time discretization of control u(t) results in
ˆu(k) = u(kΔT ), k = 0, 1, 2, ...K −1
(7.76)
and we can use it to approximate the control as
u(t) ≈ˆu(k), kΔT < t < (k + 1)ΔT,
(7.77)
where ˆu(k) are the values of the sequence ˆu approximating control and ΔT is
the discretization time step. If T is the interval of time for which we compute the
optimal control, then the sequence ˆu has the ﬁnite length K = T/ΔT . Similarly,
the discretization of ρ(x, t) and w(x) results in
ˆρ(m, k) = ρ(mΔX, kΔT ),
k = 0, 1, 2, . . .K
(7.78)
ˆπ(m, k) = π(mΔX, kΔT ),
m = 1, 2, . . .M
(7.79)
ˆw(m) = w(mΔX)
(7.80)
with ΔX, which is the space discretization step. In our case, X = [xa, xb] and,
naturally, M = 1 + (xb −xa)/ΔX. From the control vectors ˆu(k), we can build
the 3K × 1 vector ˆu. Similarly, from the vectors ˆρ(m, k) and ˆπ(m, k), we can
build the 3M ×1 vectors ˆρ(k) and ˆπ(k). In this and the next section, we will use
the vectors ˆu, ˆρ(k) and ˆπ(k) whenever it is convenient, in order to simplify the
notation.
The numerical optimal control problem is to ﬁnd the optimal control sequence
values ˆu∗(k) = [u∗
1(k) u∗
2(k) u∗
3(k)]T which minimize the cost function ˆJε. This
cost function is the cost function Jε computed based on the discrete approxima-
tions listed above. The optimal control problem can be written as
ˆu∗= arg min
ˆu∈Uad
ˆJε(ˆu)
(7.81)
and one can try to solve this problem using some standard iterative numerical
minimization algorithm [8]. Usually, in each iteration j, the algorithm applies

7.4 Example of Using the PDE Minimum Principle for RPC
83
some update rule producing the “better” control ˆuj, such that the cost function
based on this control ˆJε(ˆuj) is smaller then the cost function from the previous
iteration j −1, i.e., ˆJε(ˆuj) < ˆJε(ˆuj−1). We say usually, because the update rule
can also choose another direction for the control update in order to increase
the chance of reaching the minimum described by the equation (7.81). In any
case, the iterative procedures always produce the sequence of control ˆuj, which
converges to ˆu∗, such that ˆu∗= arg minˆu(k)∈Uad ˆJε(ˆu∗)
Let us assume that the iterative procedure only needs the ﬁrst order deriva-
tives of ˆJε, i.e., its gradient ∇ˆu ˆJε. To compute the derivatives ∂ˆJε(ˆu)/∂ˆu(0), we
need to know the value of ˆJε(ˆu). For computing this value, we need to compute
ˆρ(m, K), ∀m = 1, . . . M, which can be computed only when ˆρ(m, K −1), ∀m is
known; but to obtain this, we need the value of ˆρ(m, K −2) ∀m, etc. To obtain
the value of ˆJ(ˆu) in our example, we have to evaluate K · 3M · N values. The
same number of values must be evaluated for ˆJε when each of the three com-
ponents of ˆu(0) = [ˆu1(0) ˆu2(0) ˆu3(0)]T is perturbed. Therefore, for computing
∂ˆJε(ˆu)/∂ˆu(0), it is necessary to evaluate 3(K +1)NM values. For any additional
derivative ∂ˆJε(ˆu)/∂ˆu(k), it is necessary to evaluate additional 3(K −k)NM val-
ues. In summary, to evaluate all the components of the gradient ∇ˆu ˆJε, of the
cost function ˆJε, the number of evaluated values Cp is
Cp = 3

1 + K(K + 1)
2

NM
(7.82)
The number Cp can be used as a measure of the computational complexity
of the numerical algorithm, since computing ρ(m, k) resulting from the PDE
system brings a major computational load. To provide a realistic approximation
of the control u(t), the time step ΔT should be small. In other words, the
sequence length K should be large. The numerical complexity Cp of the presented
approach, in the simplest form, scales with K2 and it is the major obstacle for
its implementation.
Exploiting the Hamiltonian for solving the optimal control problem can reduce
the computational complexity. The simplest way to do that is to use iterations
that minimize the Hamiltonian ˆHε(k) at each time point, i.e., for each k. In
other words, for a given control sequence in the iteration j, ˆuj(k), we should
perform all the necessary computation to obtain ˆHε(uj(k)), for each k. Then, we
update the value of control ˆuj(k), so that the updated value ˆuj+1(k) minimizes
ˆHε(uj(k)). We expect that the vector of control ˆuj converges to ˆu∗, such that
the corresponding control sequence satisﬁes
ˆu∗(k) = arg
min
ˆ
u(k)∈Uad
ˆHε(ˆu∗(k)), ∀k
(7.83)
For computing the Hamiltonian ˆHε(uj(k)) for each k = 0, 1, . . . K, it is necessary
to compute ρ(m, 1), . . . ρ(m, K) and π(m, K −1), . . . , π(m, 1), ∀m = 1, . . . M.
This means that we need to evaluate 2K · N · M values. The computational
complexity of this Hamiltonian-based approach scales with K.
We use this approach in [55] with the discrete time step ΔT = 0.03, K = 100,
M = 500 and the parameter ε = 10−7. The chosen value for ε depends on how

84
7. Stochastic Modeling and Control of a Large-Size Robotic Population
0
10
20
30
40
−1.5
−1
−0.5
0
Cost function ˆJε
Iteration
Fig. 7.6. Cost function ˆJε computed in each iteration of the algorithm (solid) and
computed by the simpler algorithm [55], c⃝2006 IEEE
close to J we want Jε to be; the smaller the ε, the closer Jε to J. For the decimal
precision of dp, the term which penalizes the control in Jε must be smaller than
10−dp. Since we know the maximal values of control umax, this can be expressed
by [55]:
10−dp > J −Jε = ε

 T
0
3

i=1
u2
maxdt = 3T u2
max ⇒ε <
10−dp
3T u2max
(7.84)
However, ε cannot be inﬁnitely small because the algorithm convergence may be
inﬂuenced when the minimization problem is close to the original problem with
the “singular control”.
For the initial guess for the optimal control in [55], we use ˆu1(k) = [0.5 0.5 0.5]
∀k. To illustrate the convergence, in each iteration j, we also compute the value
of the cost function ˆJε. These values are shown in ﬁgure 7.6 using a dotted line.
In this example, the algorithm reaches the optimal control after 40 iterations. We
are not illustrating the shape of the computed optimal control at the moment. It
is because the following section describes another algorithm that also has a linear
scaling of the complexity Cp with K, and, for the same example, it converges to
the same optimal control much faster.
7.4.2
Numerical Optimal Control
We search for the optimal control ˆu∗that is the stationary point of the iteration
ˆuj+1 = ˆuj + αjdj
(7.85)
and ˆu ∈Uad. The variable αj is the scalar for which ˆJε(uj + αjdj) < ˆJε(uj)
and dj is the search vector in the jth iteration. This vector, for example, can
be the negative gradient of the cost function, i.e., dj = −∇ˆJε(uj). The gradient

7.4 Example of Using the PDE Minimum Principle for RPC
85
vector dimension is dim(∇ˆJε) = dim(dj) = dim(ˆuj) = 3K. In fact, after the
discretization, we deal with the discrete time optimal control problem. Therefore,
this gradient can be completely computed using the Hamiltonian values due to
the relation ∇ˆu(k) ˆJε = ∇ˆu(k) ˆHε for the given point at time k [8]. The dimension
of these derivatives is dim(∇ˆu(k) ˆJε) = dim(∇ˆu(k) ˆHε = 3). On the other side,
search for the value of αj along the direction dj is computationally expensive,
since the cost ˆJε evaluation requires the PDE system solution. Therefore, we
ﬁnd the scalar value αj as the value, providing that the gradient at the point
ˆuj + αjdj is orthogonal to the direction dj, i.e.,
[∇ˆJε(ˆuj + αjdj)]T dj = 0
(7.86)
which, due to the quadratic form of the Hamiltonian ˆHε, has a closed form
solution. The minimization based on the iterations with dj = −∇ˆJε(uj) can
have a poor convergence [8]. The numerical algorithm used here is based on
Nonlinear Conjugate Gradient Method with the Polak-Ribi`ere for the direction
dj generation [64]. While we have explained the main idea of the algorithm we
applied ˆuj and dj, in the following detail algorithm description, we will use
ˆuj(k) = [uj
1(k) uj
2(k) uj
3(k)]T and dj(k) = [dj
1(k) dj
2(k) dj
3(k)]T , representing
the control at time point k in the jth iteration and the corresponding update
direction, respectively. The algorithm steps are:
Step 1) Guess the control sequence ˆu1(k), k = 0, 1, 2, . . .K −1 and set the iter-
ation counter j = 1.
Step 2) Compute ˆρj(m, k), the discrete approximation of the solution ρ(x, t) in
the jth iteration, k = 0, 1, . . ., K, m = 1, 2, . . ., M. This computation is based
on the control sequence ˆuj(k), starting from the initial value ˆρj(m, 0) forward
in time.
Step 3) Compute ˆπj(m, k), the discrete approximation of the solution π(x, t) in
the jth iteration k = K, K −1, . . . , 0, m = 1, 2, . . ., M. This is computed based
on the control sequence ˆuj(k), starting from the initial value ˆπj(m, K) = ˆw(m)
backward in time.
Step 4) Using the values from the previous step, compute the discrete approx-
imations ˆIj
1(k), ˆIj
2(k), ˆIj
2(k) of the integrals composing the Hamiltonian in the
jth iteration
ˆHε(k)j = ˆuj
1(k)ˆIj
1(k) + ˆuj
2(k)ˆIj
2(k) + ˆuj
3(k)ˆIj
3(k)
(7.87)
Step 5) Compute the negative gradient gj(k) = −∇ˆuj(k) ˆHε(k)j for each k =
0, 1, . . .K −1, that is
gj(k) = −∇ˆuj(k) ˆHε(k)j =
⎡
⎢⎢⎢⎣
−ˆI1(k) −2εˆu1(k)
−ˆI2(k) −2εˆu2(k)
−ˆI2(k) −2εˆu2(k)
⎤
⎥⎥⎥⎦
(7.88)

86
7. Stochastic Modeling and Control of a Large-Size Robotic Population
Step 6) If j = 1, set the direction d1(k) = gj(k) for each k = 0, 1, . . . K −1 and
set the scalar value β1 = 0. In all other cases compute
βj = max
gj(k)T (gj(k) −gj−1(k))
gj−1(k)T gj−1(k)
, 0

(7.89)
also whenever gj−1(k)T gj−1(k) = 0 set the βj = 0. Then set the directions
dj(k) = gj(k) + βjdj−1(k), k = 0, 1, 2, . . .K −1
(7.90)
Step 7) Compute the discrete approximations ˆIj
1(k), ˆIj
2(k), ˆIj
2(k) of the integrals
composing the Hamiltonian Hε. Using these values, compute αj using the closed
form solution of [∇ˆJε(ˆuj + αjdj)]T dj = 0, which is
αj = −
K−1
k=0 uj(k)T dj(k)
K−1
k=0 dj(k)T dj(k)
−−
K−1
k=0
3
i=1 ˆIj
i (k)dj
i (k)
2ε K−1
k=0 dj(k)T dj(k)
(7.91)
Step 8) Update the control sequence, for the next iteration
uj+1
i
(k) =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
0
uj
i(k) + αjdj
i(k) < 0
umax
uj
i(k) + αjdj
i(k) > umax
uj
i(k) + αjdj
i (k),
elswhere
(7.92)
where i = 1, 2, 3 and k = 0, 1, 2, . . .K −1. Then, jump to Step 2 until the control
sequence does not change any more.
It is worth mentioning that during the algorithm development, we notice that
a poor discretization with small K and M leads to a poor approximation of the
integrals for computing the Hamiltonian. Consequently, the algorithm does not
converge as we expect. To improve its robustness, we use the following formula
for integrals necessary for the Hamiltonian computation

X πi(x, kΔT)ρj(x, kΔT)dx ≈
ΔX
6
M
m=1 πi(m, k)(2ρj(m, k) + ρj(m + 1, k))+
ΔX
6
M
m=1 πi(m + 1, k)(ρj(m, k) + 2ρj(m + 1, k))
(7.93)
This formula is derived using the following approximations for x = mΔX and
x + δx ∈[mΔX, (m + 1)ΔX]
ρ(x + δx, kΔT ) ≈ρi(m) + ρi(m + 1) −ρi(m)
Δx
δx
π(x + δx, kΔT ) ≈πi(m) + πi(m + 1) −πi(m)
Δx
δx

7.4 Example of Using the PDE Minimum Principle for RPC
87
Fig. 7.7. Components of control ˆu∗= [ˆu∗
1 ˆu∗
2 ˆu∗
3]T . This control is computed for the
cost function ˆJε, ε = 10−7, ΔT = 0.03h, ui ∈[0, 2], i = 1, 2, 3 [55], c⃝2006 IEEE.
Fig.
7.8.
State PDF evolution of the robots moving left
ρ1(x, t) for t
=
0.6, 1, 1.2, 1.8, 2.4h, ui ∈[0, 2], i = 1, 2, 3 [55], c⃝2006 IEEE
We apply this more eﬃcient gradient-based algorithm to our example under
the same conditions, i.e., ΔT = 0.03, K = 100, M = 500, the parameter ε =
10−7 and the initial guess ˆu1(k) = [0.5 0.5 0.5] ∀k. The convergence of the control
sequence iterations towards the stationary point is improved. Now, the optimal
control is reached after 22 iterations (see ﬁgure 7.6, solid line). This improvement

88
7. Stochastic Modeling and Control of a Large-Size Robotic Population
Fig. 7.9. State PDF evolution of stopped robots ρ3(x, t) for t = 0.6, 1.2, 1.8, 2.4h,
ui ∈[0, 2], i = 1, 2, 3 [55], c⃝2006 IEEE
is reached without involving the cost function, or its second order derivatives.
The numerical complexity of this algorithm also scales with K.
The obtained control is identical to the one obtained for the simpler al-
gorithm [55] shortly described in the previous subsection. Therefore, we will
describe the control as in [55].
The components of control ˆu∗are given in Fig. 7.7. The ﬁrst component ˆu∗
1 starts
with zero value, then it changes at t = 0.21h to 2. Before it turns to 0 again, the
control ˆu∗
3 has already changed from 0 to 2. Thus, between t = 1.71h and t =
1.74h, ˆu∗
1 and ˆu∗
3 are both 2. This can be understood as an eﬀective slowdown of the
velocity of moving to the left, since each robot makes a transition to the move left
and stop states with the highest possible rates. After t = 1.74h, ˆu∗
1 is 0 and ˆu∗
3 is 2
by the end of the time interval [0, T ]. All the time, in this interval, ˆu∗
2 is zero, i.e.,
the optimal control does not include transitions to the discrete state move right.
Since the initial PDF of robots moving right is ρ2(x, 0) = 0, we can conclude that
this PDF will be zero all the time, i.e, ρ2(x, t) = 0, ∀t ∈[0, T ]. Therefore, only the
evolution of ρ1(x, t) and ρ3(x, t) are presented in Fig. 7.8 and Fig. 7.9, respectively.
Starting with the initial PDFs ρi(x, 0), i = 1, 2, 3, the control ˆu∗produces
distribution evolutions such that, at the terminal time T = 3h, the PDF ρ3(x, t =
T ), depicted in Fig. 7.9, has one peak value at the same position as w3(x) peak.
The transition rates are limited, therefore, there are robots that have never
moved from the discrete state stop at the terminal time T . This is shown in the
plot of ρ3(x, T), where a small plateau exists for the x values corresponding to
ρ3(x, 0) maximum.

7.5 Summary
89
We can see from Fig. 7.9 that our original intuition to produce a sharper robot
distribution in the terminal time in comparison to the distribution in the initial
time has failed. This is because the evolution of ρ3(x, t) is constrained by the
population dynamics, i.e., the PDE system (7.18) and the corresponding initial
condition (7.39).
The presented numerical example along with the derivation of this section
shows that the Minimum Principle for partial diﬀerential equations can be ex-
ploited for the computation of the robotic population optimal control in the
same way as Pontryagin Minimum Principle is used for the ODE optimal con-
trol computation [50], [78].
7.5
Summary
In this chapter we introduce the CT MCμA of a large size robotic population. We
present the capability of our modeling approach to predict the position PDF of
the robotic population. This gives us motivation to formulate an optimal control
problem in which the position PDF of the robotic population can be maximized
over a region of robots operating space for a given time T . This optimal con-
trol problem is deﬁned using the objective function based on the position PDF
which must be minimized. We discuss the application of the Minimum Principle
for PDEs to solve this optimal control problem.
Key points
• Modeling of the large size robotic population by a stochastic CT MCμA
model.
• Robotic population optimal control problem and the application of the Min-
imum Principle for partial diﬀerential equations to this problem.

8. Conclusions and Future Work
In this book we have explored common grounds for studying multi-agent popu-
lations of biological cells and robotic teams. The main motivation for this eﬀort
comes from the observation that both cells and robots are sophisticated agents
with ability to sense the environment, analyze signals and act individually, or in
cooperation with their teammates.
Our main concern in this monograph is the question on how dynamics of
an individual agent propagates to the population dynamics. An answer to this
question can provide an insight into behavior of individual agents from the
measurements of the population properties. This opens an opportunity for a
smart manipulation of the population properties. Therefore, the question we ap-
proached in this book is important for understanding biological data, as well
as the manipulation, i.e., control of multi-agent systems, such as biological cell
populations and large-size robotic teams.
The original contributions of this book can be shortly summarized in the
following points:
•
Development of the Micro-Agent model of individual agents and Stochastic
Micro-Agent model of the agent population. This includes:
- System of partial diﬀerential equations describing the state probability
density function of a population which can be modeled by a Continuous Time
Markov Chain Micro-Agent.
- Modeling approach to the parameter uncertainty of the Micro-Agent
continuous dynamics.
•
Hybrid system approach to the modeling of TCR expression dynamics of an
individual T-cell and T-cell populations. As part of this contribution, a novel
data processing algorithm, which is able to reject the T-cell autoﬂuorescence
from the Flow Cytometry measurements, has been developed.
•
Modeling a large-size robotic population, including the formulation of an
optimal control problem taking the population to a desired location with the
maximal probability; the algorithm for computing numerical optimal control
for this problem.
In the rest of this chapter, we summarize our conclusions and discuss some pos-
sible future work related to the theoretical development of the modeling frame-
work, the modeling of biological cell populations and the potential application to
the modeling and control of large-size robotic populations.
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 91–95, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

92
8. Conclusions and Future Work
Modeling framework: In the approach to the modeling and analysis of a large
population of agents we have presented here, each individual agent is described
by a deterministic Hybrid Automaton model, named a Micro-Agent. This model
describes an agent behavior which obeys ordinary diﬀerential equation dynamics
in each discrete state. However, the discrete state can change as a result of an
input event sequence and, independently, of the state of continuous dynamics.
Application of this model to an individual robot or a cell describes them as
deterministic devices. To model the complex environment surrounding agents we
have assumed that their input event sequences are stochastic and we introduced
a Stochastic Micro-Agent model of the population.
To answer the question about the relation between the individual agent dy-
namics and the macro-dynamics of the population observations, we found useful
to apply statistical physics reasoning. Motivated by this reasoning, we described
this relation by the agent state probability density function (PDF). The goal
of our theoretical work was to infer the state PDF of the agent population and
then, based on this PDF, to ﬁnd the PDF of the population macro-observations.
This resulted in a system of partial diﬀerential equations (PDE) describing the
evolution of the state PDF when the Stochastic Micro-Agent population dis-
crete state is modeled by a Markov Chain. Using the state PDF, we predicted
the macro-observation PDF as the output PDF, in the case when it can be
calculated as a sum of the state PDFs.
For the same case of Markov Chain discrete state transitions, we also intro-
duced an approach to handle the problem of the parameter uncertainty of the
Continuous Time Markov Chain (CT MC)μA. The approach aims towards a
systematic procedure that transforms Hybrid Automata models without the un-
certainty to models that include the uncertainty description. While we succeeded
in the formulation of how to handle some types of the parameter uncertainty,
which is described by a discrete PDF, we found it diﬃcult to manage the pa-
rameter uncertainty, which is deﬁned by a continuous PDF.
Extending the theory to the modeling of the agent population described
by general Hybrid Automata, dealing with a more complex macro-observation
model, or a proper treatment of the parameter uncertainty given by a contin-
uous PDF are some possible directions for further theoretical development. We
believe that, in this development, potentials of using tools for describing non-
stationary thermodynamic systems have to be considered. A very interesting
eﬀort for further research would be the formulation of thermodynamic laws for
the agent population described by Hybrid Automata.
Modeling a biological cell population: We applied the presented modeling
approach to the membrane T-Cell Receptor (TCR) density dynamics of a T-cell
population interacting with ligand-bearing APCs. Available analytical models
are ordinary diﬀerential equation models of the TCR average amount of the
population. These models assume that the population average amount dynamics
is equivalent to the dynamics response of an average cell. Using only the average

8. Conclusions and Future Work
93
value of the measurements means that a lot of potentially useful information,
being part of the experimental data, is discarded.
Our modeling approach incorporates all of this information into the model,
in which each individual T-cell is described by a deterministic Micro-Agent.
Under a stochastic assumption about the Micro-Agent input event sequence,
the Stochastic Micro-Agent model of the T-cell population was introduced. The
relationship between the proposed model and the time evolution of the state
PDF provides us with the ability to predict the experimental membrane TCR
amount distribution. This prediction is tested against the experimental data.
The predicted distribution should not only match the mean value, but the overall
shape of the experimentally obtained distributions. Therefore, we are capable of
deciding what kind of functions should describe continuous dynamics of discrete
states. In other words, we identify them within a function space.
Using the experimental data of interactions between T-Cells and antibodies
under the conditions where only one discrete state exists, we tested linear and
quadratic hypotheses of TCR expression decrease dynamics. We concluded that
this dynamics should be described by the same linear function as the one we
found in the previous T-Cell-APC experiment. Finally, we could identify the
parameters of the dynamics.
In order to identify parameters, we relied on the Flow Cytometry, i.e., type
of microscopy which provides the laser scan of each cell from the cell popula-
tion sample. To measure the TCR amount level, the TCRs are labeled. After
their exposition to the laser light, the cells emit the intensity of the light cor-
responding to the TCR amount. However, one part of this light is due to the
autoﬂuorescence. To obtain the shape of TCR amount distributions of the cell
population, the autoﬂuorescence component must be rejected. This algorithm is
based on the QQ-plot for estimating distributions and the stable Richardson-
Lucy deconvolution method.
During the development of the TCR expression model, we have made a few
simpliﬁcations that are not free from controversy on biological grounds. First, we
assumed that conjugate life-times and the waiting time for conjugation are both
exponentially distributed. This assumption is reasonable for the waiting time,
since T-cells and APCs seem to perform random walks, at least in vitro. As to
the distribution of conjugate life-times, it seems to be akin to an exponential
under some experimental settings [27], while in other conditions, it is more bell-
shaped, with the mean of a few hours [31].
Another assumption, that is worth discussing, concerns the initial PDF of the
T-cells that never conjugated. This initial membrane TCR density has already
some variance, in contrast to the Dirac pulse one would expect according to
the model of a T-cell that would always be free. This means that there is some
stochastic process, which can be an interaction, as we modeled here, but that is,
most likely, intrinsic to the internal machinery of the T-cell. In the latter scenario,
the values of the rates of the conjugate formation and dissociation we obtained
are most likely under-estimated. Note that one can compensate the presence of
extra sources of variance by reducing the variance due to the stochasticity in the

94
8. Conclusions and Future Work
APC conjugated formation and dissociation, which is achieved by increasing the
rates of these processes.
Potential future theoretical work along these research lines includes an ex-
tension to T-cell population dynamics, where the life-history parameters, such
as death and proliferation, are themselves functions of the TCR signaling. Also,
initial and steady state distributions may be more carefully studied using bet-
ter approximations or including better hypothesis about the TCR dynamics in
the absence of APCs and extra sources of the variance in the membrane TCR
density. On experimental grounds, it would be interesting to test the proposed
model using experimentally obtained statistics of the stochastic event sequence.
The theory presented here can be used to provide additional insights into other
biological phenomena, where cells or other biological agents alternate among dis-
crete states.
Modeling and control of a robotic population: Here we have given a moti-
vation for the application of our modeling approach to the modeling of large-size
robotic populations. The proposed model of a large-size robotic population con-
siders not only the probabilistic description of the task allocation, but also the
distribution of the population over the operating space. The models of large-size
populations used previously in the literature are related either to robotic forma-
tions, i.e., relative positions of the robots in the operating space, or to the task
allocation and the task performance modeled under the probabilistic framework.
The motivating example we introduced illustrates that diﬀerent model param-
eters lead to diﬀerent densities of the robotic population in probabilistic space.
Based on this, we formulated an optimal control problem in which an objective
function includes the population state PDF. In this problem, the objective func-
tion reﬂects the mission goal. A possible choice for the objective function is the
one which maximizes the robotic presence in a deﬁned region. Since the time
evolution of the state PDF obeys a PDE, this controller design is a PDE optimal
control problem. To solve this problem, the Minimum Principle for PDEs [21],
similar to Pontryagin Minimum Principle for ODE, can be applied.
The diﬃculty we faced in the application of the Minimum Principle for PDE
originates from the problem of solving the PDE two-point-boundary-value prob-
lem and the singular condition for optimal control. Therefore, we also considered
the possibility to solve the optimal control problem numerically. After discussing
the complexity of possible solutions, we exploited results obtained from the ap-
plication of the Minimum Principle to solve the problem numerically eﬃciently.
The result presented in this book opens the door to an opportunity to extend
the research in several directions, including the single robot task composition,
communication among the robots and extension of the modeling and control
approach. It is worth mentioning that the distribution of the population evolves
in the same way as the probability density function of a single robot. There-
fore, the results presented here can be used for the modeling and control of one
robot in probabilistic sense. This can be used for the trajectory planning and
composition of robot task sequences in order to satisfy the mission objective.

8. Conclusions and Future Work
95
In the case of a two-robot team, our model can explicitly include the rates of
receiving information from the other robot. This can be exploited to estimate
the necessary intensity of the communication between the two robots, while the
two-robot team mission remains successful. Here we developed a full analytical
model for the case when all the transitions over discrete states can be described
by a Markov chain. The transition rates are equal for overall population. How-
ever, the transition rates can depend on the robot position, e.g., the intensity of
communication errors depends on the relative position between the robot and
the command source. In that sense, it would be of certain interest to extend our
work to the case when the transition rates are fast-changing and unpredictable
functions of the robot position.
In this work we only considered the centralized control of a robotic popula-
tion and we designed the best controller having applied this strategy. For further
improvement of the control performance, the local robot controllers have to be
taken into account. Possibly, the best control strategy would be a centralized
optimal control that provides coherent behavior of the population, and local
robot controllers (decentralized control) to provide the performance improve-
ment and robustness. As our future work, we are considering designing such a
kind of controller under the framework introduced in this paper. We are also
giving attention to extending the application of the PDE Minimum Principle to
other types of optimal criteria, e.g., optimal control with inﬁnite terminal time
and diﬀerent cost functions, which can control the shape of the state probability
density function.
The ﬁnal conclusion regarding the contents of this book is that we have made
a step towards a mathematically tractable way of describing and possibly con-
trolling complex systems composed of a large amount of agents. This step shows
that cells and robot teams can be studied within the same theoretical framework.
At this moment we can hardly say what the impact of the presented theory on
the immune system or multi-agent (robotic) systems research will be. However,
we are sure that our eﬀort to exploit the cell-robot analogy can inspire future
research in Biology and Multi-Agent systems. This can include understanding of
spatio-temporal formations of cell populations, comprehending extra- and intra-
cellular communication pathways, centralized versus decentralized decision mak-
ing trade-oﬀin Multi-Agent systems, design of energy eﬃcient robot populations,
as well as design of advanced medical treatments.

A. Stochastic Model and Data Processing of
Flow Cytometry Measurements
Flow Cytometry is an observation method which is used to measure the TCR
amount. This method is implemented in special devices, so-called Flow Cytom-
etry scanners. There are prescribed cell treatments invented to increase the cor-
relation between the scanner measurements and the observed quantitative prop-
erty of the cells. The Flow Cytometry scanner working principle is depicted in
Figure A.1.
Fig. A.1. Flow Cytometry scanner working principle: W-T-cell container S-scattered
light, T-transmitted light, E-emitted light, A/D-analog to digital converter
The vessel W contains the T-cells in suspension. The scanner has a special
construction which allows it to sample exactly one cell and expose it to the
laser light. For a diﬀerent type of analysis a diﬀerent wavelength can be applied.
The intensity of the scattered light or the light emitted by the cell after the
exposure (ﬂuorescence) can be recorded in digital format after an analog to
digital conversion. In our case the TCR molecules are labeled by ﬂuorescent
probe. Therefore, the ﬂuorescence intensity has particular meaning because it
corresponds to the TCR amount. Let us denote the intensity of the ﬂuorescence
intensity with z, then we can write:
z = αx + θ
(A.1)
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 97–105, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

98
A. Stochastic Model and Data Processing of Flow Cytometry Measurements
where x is the amount of TCRs, α is a constant parameter and θ is the T-cell
autoﬂuorescence component of the measured signal. The Flow Cytometry result
is a distribution Nm of the signal z measurements over the T-cell population.
An example of real data Nm is given in Figure A.2. In this ﬁgure, the values
of the signal z are ampliﬁed by a logarithmic ampliﬁer sampled by 10bits A/D
converter. The horizontal axis in this ﬁgure is a log10-scale intensity of the ﬂuo-
rescence light and the vertical axis is the quantity of cells given the intensity of
the light. Using the observation of the T-cell without the TCRs with the ﬂuo-
rescent probe, the T-cell autoﬂuorescence distribution Nθ can be measured. An
example of this measurement is presented in Figure A.2.
0
200
400
600
800
1000
0
20
40
60
80
100
Log scale intensity (0−1023)
Cells Quantity
Nθ
Nm
Fig. A.2. Flow Cytometry measurements: Nm and Nθ, by Lino [45]; the full scale
from 0–1023 covers 4 decades
Taking the distributions measured by Flow Cytometry, Nm and Nθ, we can
estimate the PDFs of the measured signal z (pm) and autoﬂuorescence signal θ
(pθ). There are diﬀerent algorithms which can be used for that estimation and, in
the sequel, we present one of the methods we ﬁnd suitable. However, to test our
CT MCμA model, we should compare our prediction of TCR PDF to TCR PDF
which is estimated from experimental data. Therefore, we have the following
problem: How to estimate the unknown TCR PDF px given pm and pθ?
The starting point to solve this problem is equation (A.1). Assuming that
α = 1, then:
z = x + θ
(A.2)
from which we conclude that:
pm(z) =
 +∞
−∞
pθ(z −x)px(x)dx = pθ(z) ∗px(z)
(A.3)
The PDF of the measured signal is the result of the convolution (symbol *)
between autoﬂuorescence and TCRs PDF. To calculate px(z) we should pro-
vide an algorithm which causes deconvolution of the noise PDF (pθ) from the
measurement signal PDF (pm). Deconvolution is an operation and its solution

A.1 Probability Density Estimation Algorithm
99
can be non-unique. Because of that the numerical algorithm which solves the
deconvolution can be very sensitive to small diﬀerence in input data. In this
section, we will present an algorithm for the stable deconvolution, called the
Richardson-Lucy deconvolution algorithm [47, 66].
The complete algorithm to estimate TCRs PDF px based on the Nm and Nθ
experimental data is depicted in Figure A.3. Using the rough experimental data
the PDF pm and pθ should be estimated, then the deconvolution algorithm,
which takes out pθ from pm, produces the TCRs PDF px. In the rest of this
section, the PDF estimation and deconvolution algorithm we are using will be
presented.
Deconvolution
PDF estimation
PDF estimation
N
m
N
p
pm
px
Fig. A.3. The Flow Cytometry data processing measurements: Nm - ﬂuorescence
distribution, Nθ - autoﬂuorescence distribution, pm - estimated PDF of ﬂuorescence,
pθ - estimated autoﬂuorescence PDF
A.1
Probability Density Estimation Algorithm
The probability density estimation algorithm used in this work is based on the
so-called QQ-plot [18, 19]. This algorithm estimates the PDF as a weighted sum
of the kernel probability density functions:
ˆp =
l

k=1
ckϕ(mk, σk)
(A.4)
where ck is a weighting coeﬃcient and ϕ(mk, σk) is a PDF with a given mean
value mk and variance σk. Although the PDF parameters are its mean value and
variance, this algorithm is not constrained to the case where ϕ is Gaussian. The
type of kernel functions can be chosen appropriately, while the number of kernel
functions is computed using an optimization procedure. Since this algorithm
computes a number of kernel functions automatically, we ﬁnd this algorithm
suitable for our application. In the following text we will describe the algorithm
to compute unknown parameters ck, mk and σk given data samples and PDF ϕ.
Let us assume that the data samples are given by the sequence of measure-
ments {xi}, i = 1, 2, . . .I. By sorting this sequence of real numbers in nonde-
creasing order, we can produce an ordered sample sequence {yi}, which satisﬁes
i < j ⇒yi ≤yj ∀i, j ∈{1, 2, . . .I}. To generate QQ-plot, the data samples
PDF p(·), i.e., corresponding cumulative distribution P, have to be assumed.
The QQ-plot is the plot of ordered sequence {yi} versus P −1(ri), where:
ri = i −1
I −1
(A.5)

100
A. Stochastic Model and Data Processing of Flow Cytometry Measurements
The probability that some observation ν will have index i, in the ordered sample
sequence {yi} is:
Pr(i|ν) =
⎛
⎝I −1
i −1
⎞
⎠P i−1(ν)(1 −P(ν))i−i
(A.6)
and the expected value of index i, given observation ν, is:
mi|ν = E{i|ν} = 1 + (I −1)P(ν)
(A.7)
If ν = yi, then
i ≈mi|yi = 1 + (I −1)P(yi) ⇒yi = P −1
 i −1
I −1
	
(A.8)
Equation (A.8) shows why the QQ-plot is originally introduced as a test of data
samples cumulative distribution hypothesis P. If the hypothesis P is correct,
then the QQ-plot is a straight line. In the case of the zero mean hypothesis,
with unit variance P0 for the random variable yi−m
σ
, where m = E{yi} and
σ = E{(yi −m)2}, the equation (A.8) is:
yi −m
σ
= P −1
0
(ri)
(A.9)
i.e.,
yi = m + σP −1
0
(ri)
(A.10)
Given an ordered data sample sequence and P0 hypothesis, Equation (A.10)
can be used to estimate the PDF using the least squares (LS) algorithm. If the
QQ-plot is linear, the estimated value m and σ together with P0 deﬁne the
estimated PDF. In the non-linear case, the algorithm [18, 19] makes the piece-
wise linear approximation of the QQ-plot and applies LS estimation (A.10) to
each plot segment. The result is a sequence of mk and σk corresponding to
linear segments sequence a∗= a∗
k. The ﬁrst and the last point of each linear
segment are (P0(rs∗
k), ys∗
k) and (P0(re∗
k), ye∗
k), where s∗
k and e∗
k are the ﬁrst and
the last index of the data corresponding to linear segment a∗
k. If P0 is ϕ(0, 1),
the estimated PDF is
ˆp =
l

k=1
ckϕ(mk, σk)
(A.11)
where
ck = e∗
k −s∗
k
I −1
=
n∗
k
I −1
(A.12)
so that the weighting factor ck is the ratio between the number of points inside
the linear segment a∗
k ( n∗
k = e∗
k −s∗
k ) and I which is the total number of points
composing the QQ-plot.
Obviously, the piece-wise linear approximation is not unique. The complete
solution of the piece-wise approximation is to decide the number of segments, as

A.1 Probability Density Estimation Algorithm
101
well as the ﬁrst and the last point of each segments. The proposed suboptimal
algorithm [18, 19] computes the optimal approximation a∗, which minimizes the
criterion very similar to the minimum description length criterion (MDL):
J =
na

k=1
d(ak, QQ) + γna log I
(A.13)
where
d(ak, QQ) = 1
nk
nk

p=1

aj
k(P −1
0
(rp)) −QQ(P −1
0
(rp))
2
(A.14)
d(ak, QQ) is a distance between linear segment ak and QQ-plot, nk denotes the
number of QQ-plot points inside the k-th linear segment and γ is a positive
weighting parameter to the number of linear segments . If the parameter γ = 0,
the criterion minimizes the distance between the piece-wise linear approximation
and the QQ-plot, which results in a large number of the linear segments con-
taining few data points. The piece-wise linear approximation is very good, but
the mean value and variance of the linear segments are not statistically justiﬁed
because of the few data points segment. Giving weight to the second term of
criterion, na log I, the trade-oﬀbetween the number of linear segments and the
number of points per segment can be made. An extensive numerical simulation
suggests γ ∈(0, 0.05) [18, 19]. The complete QQ-plot based PDF estimation
algorithm can be described as follows[18, 19]:
step 1) in the initial step (j = 1), the QQ-plot is approximated by only one lin-
ear a1
1 = (1, I) segment determined by the ﬁrst and the last point of the QQ-plot.
step 2) among all the segments in the segmentation ﬁnd the segment which is
the worst approximation of the QQ-plot. The rule is to calculate the distance
d(aj
k, QQ) to each segment, where aj
k is the kth linear segment of the jth itera-
tion. Denote by M the index of the segment corresponding to the maximal value
of distance d(aj
k, QQ):
d(aj
k, QQ) ≤d(aj
M, QQ), ∀k, k, M ∈1..nj
a
(A.15)
where nj
a is the number of linear segments in the iteration j. Now, divide the
linear segment aj
M into two segments. The point which divides the new segments
is given by the index:
id = int

sj
M + ej
M
2

(A.16)
where sj
M and ej
M are the indexes of the ﬁrst and the last point of the segment
aj
M and int is the function which calculates the integer value of a real number.
The new linear segment sequence aj+1 have nj+1
a
= nj
a + 1 linear segments.

102
A. Stochastic Model and Data Processing of Flow Cytometry Measurements
Fig. A.4. Suboptimal algorithm for the piece-wise linear approximation of the QQ-
plot [18]
step 3) compute the criterion of the jth Jj and of j + 1-th iteration Jj+1, if the
Jj > Jj+1, go to step 2) and increase counter j by 1; otherwise, ﬁnish the
algorithm and stop procedure with a∗= aj.
Figure A.4 illustrates this algorithm. The QQ-plot is composed of 15 data
points. In the initial iteration, the QQ-plot is approximated by only one linear
segment. This linear segment is divided into two segments with equal number
of points. In the second iteration, the distance of the linear segments to the
QQ-plot (A.14) is calculated for each segment. The segment a2
1, with the larger
distance, is split in two for the next iteration. The same is applied in the third
iteration, and so forth.
An example of the PDF estimation applied to Flow Cytometry measurements
is presented in Figure A.5. As it is already explained in this section, the Nm
and Nθ are measured using the logarithm log10 of intensity. Therefore the QQ
estimates are denoted by plog
m and plog
θ . The parameters ck,mk and σk determined
for the distributions are given in Tables B.2 and B.1(Appendix B), respectively.
However, we should notice that the deconvolution algorithm is applicable only
to the PDFs deﬁned over a linear scale. The transformation which converts the
PDF in log10 scale plog to the PDF in linear scale p is:
p(z) =
1
z ln 10plog(logz)
(A.17)
The ﬁrst and the last points to which we apply this transformation are logz = 0
and logz = 1023 corresponding to z = 1 and z = 104, respectively. The es-
timated PDF pm and pθ corresponding plog
m
and plog
θ
(A.5) are presented in
Figure A.6.

A.2 Richardson-Lucy Deconvolution Algorithm
103
Fig. A.5. Example of the PDF estimation: plog
m
- PDF which corresponds to non-
stimulated T-cells, plog
θ
- PDF of autoﬂuorescence; the dotted lines in the background
are the normalized Nm and Nθ measurements
Fig. A.6. Example of the PDF estimation: pm - PDF which corresponds to non-
stimulated T-cells, pθ - PDF of autoﬂuorescence
A.2
Richardson-Lucy Deconvolution Algorithm
There are diﬀerent deconvolution methods that can be used to compute the un-
known distribution px of TCR receptors using the PDF of measurements pm
and the autoﬂuorescence PDF pθ. Most of the methods are developed for the
restoration of the astronomical images degraded due to the optical eﬀects. This
problem and its possible solution are presented in [66], which introduces the
Richardson-Lucy (RL) iterative scheme used in our work. In [47], some prop-
erties of this algorithm are derived. We choose to apply this algorithm as it is
numerically stable [28].
The RL method is based on Bayes rule. Writing the TCRs PDF as follows:
px(x) =
 ∞
−∞
p(x|z)pm(z)dz
(A.18)

104
A. Stochastic Model and Data Processing of Flow Cytometry Measurements
and applying Bayes rule:
p(x|z) =
p(z|x)px(x)
 ∞
−∞p(z|x)p(x)dx
(A.19)
and substituting in equation (A.18), we have
px(x) =
 ∞
∞
p(z|x)px(x)

p(z|x)px(x)pm(z)dz
(A.20)
On the right side of equation (A.20), px(x) is also the solution we need. In many
applications of Bayes theorem, when the term px(x) is not initially known, an
accepted practice is to make the best of a bad situation and use an initial estimate
of the px(x) [66]. When this practice is applied to the equation (A.20), we obtain
the iterative formula:
pr+1
x
(x) = pr
x(x)
 ∞
−∞
p(z|x)

p(z|x)pj
x(x)
pm(z), r = 0, 1, 2, . . .
(A.21)
where pr
x(x) is the PDF of the rth iteration. To start the iteration, the initial
PDF p0
x(x) should be estimated. In the absence of any information about p0
x(x),
the uniform distribution can be taken. Using the PDF data samples at xi and
zk, the iterative algorithm is:
pr+1
x
(xi) = pr
x(xi)

k
p(zk|xi)

j p(zk|xj)prx(xj)pm(zk),
(A.22)
r = 0, 1, 2, . . .,
i = {1, I},
j = {1, J},
k = {1, K}
Considering the ﬁnite data samples of the PDF p(zk|xi) = pθ(zk −xi) = Sk−i+1,
we can write:
pr+1
x
(xi) = pr
x(xi)
c

k=i
Sk−i+1pm(zk)
b
j=a Sk−j+1prx(xj)
(A.23)
where a = max(1, k −J + 1), b = min(k, I), c = i + J −1. When the uniform
distribution is used for the initial estimate, equation (A.23) becomes:
p1
x(xi) =
c

k=i
Sk−i+1pm(zk)
b
j=a Sk−j+1
(A.24)
In our application, pm is a smooth function which is the result of the QQ-plot-
based estimation. The result of rth iteration is also a smooth function and since
the iteration (A.23) converges [47] to obtain the result of deconvolution, the it-
eration (A.23) has to be repeated till some criterion for stopping the iteration is
satisﬁed. In our work, we are using 800 data samples (I=K=800) and 10 itera-
tions to compute a result. The maximum of diﬀerence between the results after
the 10th and 11th iteration is 10−3, which can be neglected. In the above dis-
cussion, we assume that α = 1. If this is not the case, then px is the distribution
of αx, where x is the amount of TCRs and α is a constant parameter. The px
computed by the RL deconvolution of pθ from pm (Figure A.6) is presented in
Figure A.7.

A.2 Richardson-Lucy Deconvolution Algorithm
105
Fig. A.7. Example of the PDF deconvolution: px is received by the deconvolution
of pθ from pm, Figure A.6: pm- PDF which corresponds to non-stimulated T-cells,
px-TCR PDF (α = 1)

B. Estimated T-Cell Receptor Probability
Density Function
In this appendix, the ﬂuorescence intensity PDF estimations received from the
experiment, where the T-cell population is exposed to 0.1μg of antibodies, are
listed [45]. The experimental PDF of TCRs in Chapter 5.4, (Figure 5.11) are
estimated using the data presented in the tables below and the algorithm in
appendix A.
The PDF which corresponds to T-cell autoﬂuorescence PDF plog
θ
and TCR
distribution PDF plog
m
are estimated on a scale 0-1023 which covers 4 decades
of the ﬂuorescence intensity. The PDF estimation is received using the QQ-plot
algorithm and the following form of PDF:
ˆp =
l

k=1
ckN(mk, σk)
(B.1)
where ˆp is the PDF estimation, ck is the weighting coeﬃcient and N(mk, σk) is
Gaussian PDF with mean value mk, variance σk.
Data on TCR triggering and down-regulation mediated by anti-CD3 have
been provided by Andreia Lino and Jorge Carneiro (for experimental details
see [45]).
Table B.1. Estimated T-cell autoﬂuorescence PDF, plog
θ
k
ck
mk
σk
1 0.500000 219.006973 44.737006
2 0.250000 218.719874 35.587063
3 0.125000 219.067239 34.202273
4 0.062500 219.924756 33.367209
5 0.031153 221.148242 32.757356
6 0.015576 206.667384 40.546449
7 0.007788 214.446946 36.930977
8 0.007983 130.596407 70.848579
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 107–110, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

108
B. Estimated T-Cell Receptor Probability Density Function
Table B.2. Estimated initial TCR PDF, plog
m
k
ck
mk
σk
1 0.499923 516.100516 33.092744
2 0.249962 515.060709 31.559593
3 0.124981 513.274641 33.801055
4 0.062490 512.669595 34.009551
5 0.031245 511.963582 34.266822
6 0.015700 509.312369 35.669370
7 0.007850 519.009316 31.150042
8 0.007850 345.113316 100.441415
Table B.3. Estimated TCR PDF plog
m after 1min
k
ck
mk
σk
1 0.500000 508.674885 32.344656
2 0.250000 508.235393 33.070512
3 0.125000 508.423846 33.333285
4 0.062500 503.789116 37.341254
5 0.031088 509.100424 33.824941
6 0.015544 496.492949 40.325155
7 0.015868 398.519407 83.520207
Table B.4. Estimated TCR PDF plog
m after 15min
k
ck
mk
σk
1 0.499811 476.475513 28.399256
2 0.250094 476.402118 27.760191
3 0.125047 474.160060 30.816296
4 0.062335 472.857118 32.543326
5 0.031356 481.272582 27.090544
6 0.015489 449.662944 44.245995
7 0.007934 477.490225 31.282866
8 0.003778 420.698779 54.453897
9 0.004156 242.619046 120.385419

B. Estimated T-Cell Receptor Probability Density Function
109
Table B.5. Estimated TCR PDF plog
m after 30min
k
ck
mk
σk
1 0.500000 438.626824 35.477503
2 0.249827 434.936595 28.304885
3 0.125087 435.563738 27.357542
4 0.062370 435.810992 27.617439
5 0.031185 414.737111 41.013147
6 0.015593 412.453985 43.053564
7 0.007970 348.147525 72.945346
8 0.007970 234.637843 117.938257
Table B.6. Estimated TCR PDF plog
m after 45min
k
ck
mk
σk
1 0.499821 429.523135 38.074392
2 0.250089 426.046057 26.932232
3 0.125045 424.542408 28.127297
4 0.062522 423.186385 29.312424
5 0.031083 417.914223 33.319361
6 0.015720 410.279816 37.692587
7 0.007860 376.560978 53.633988
8 0.007860 148.905367 147.066739
Table B.7. Estimated TCR PDF plog
m after 59min
k
ck
mk
σk
1 0.499826 406.815745 36.499304
2 0.249913 404.534681 28.818082
3 0.125130 404.078543 29.496719
4 0.062565 401.795267 31.496399
5 0.031283 409.086035 26.897037
6 0.015641 395.824537 34.568911
7 0.007647 343.507064 58.044419
8 0.003823 243.562673 100.770476
9 0.004171
5.746770
195.479308

110
B. Estimated T-Cell Receptor Probability Density Function
Table B.8. Estimated TCR PDF plog
m after 93min
k
ck
mk
σk
1 0.500000 346.909437 47.118715
2 0.249847 342.256061 35.006830
3 0.124923 340.608304 37.285647
4 0.062462 344.673575 34.043459
5 0.031231 320.589365 49.688884
6 0.015615 305.059566 57.427922
7 0.015922 62.725415 166.291622
Table B.9. Estimated TCR PDF plog
m after 122min
k
ck
mk
σk
1 0.062341 380.768122 66.164479
2 0.062659 347.193873 45.427253
3 0.125000 338.657707 37.990182
4 0.250000 339.129183 38.576072
5 0.250000 339.083687 36.432553
6 0.125000 339.533806 35.380050
7 0.062341 335.337432 38.774265
8 0.031170 333.030683 39.699283
9 0.015585 336.137351 38.725043
10 0.007952 330.261145 41.846466
11 0.007952 142.109024 119.229166

C. Steady State T-Cell Receptor Probability
Density Function and Average Amount
In this appendix, the equations which are used in the TCR PDF prediction of
Sections 5.3 and 6.3 are presented. First, we show the set of equations describing
the output PDF and the state PDF evolution of the original CT MCμA model,
then we show the same type of results for the CT MCμA model, which includes
the parameter k2 discrete parameter uncertainty.
In the case of the CT MCμA without uncertain parameter k2 (see Figure 6.4),
the TCR distribution is calculated as:
η(x, t) =
3

i=1
ρi(x, t)
(C.1)
where the state PDF ρ(x, t) = [ρ1(x, t) ρ2(x, t) ρ3(x, t)]T satisﬁes:
∂ρ1
∂t = −λ12ρ1 −∇· (f1ρ1)
(C.2)
∂ρ2
∂t = λ12ρ1 −λ23ρ2 + λ32ρ3 −∇· (f2ρ2)
(C.3)
∂ρ3
∂t = λ23ρ2 −λ32ρ3 −∇· (f3ρ3)
(C.4)
and the initial condition
ρ(x, 0) = [1 0 0]T
1
2σ0x

(π)
e
−(M0−ln(x))2
2σ2
0
(C.5)
where
M0 = ln(100), σ0 = 0.19
(C.6)
In the case of CT MCμA model where k2 parameter uncertainty is included
(see Figure 6.5), the TCR distribution is calculated as:
η(x, t) = ρ1(x, t) + ρ3(x, t) +
3

i=1
ρi{2,i}(x, t)
(C.7)
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 111–112, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

112
C. Steady State T-Cell Receptor Probability Density Function
where evolution of the state PDF ρ(x, t) = [ρ1(x, t) ρ2(x, t) ρ3(x, t) ρ4(x, t)
ρ5(x, t)]T satisﬁes:
∂ρ1
∂t = −(λ1{2,1} + λ1{2,2} + λ1{2,3})ρ1 −∇· (f1ρ1)
(C.8)
∂ρ{2,1}
∂t
= λ1{2,1}ρ1 −λ{2,1}3ρ{2,1} + λ3{2,1}ρ3 −∇· (f 1
2 ρ{2, 1})
(C.9)
∂ρ{2,2}
∂t
= λ1{2,2}ρ1 −λ{2,2}3ρ{2,2} + λ3{2,2}ρ3 −∇· (f 2
2 ρ{2,2})
(C.10)
∂ρ{2,3}
∂t
= λ1{2,3}ρ1 −λ{2,3}3ρ{2,3} + λ32,3}ρ3 −∇· (f 3
2 ρ{2,3})
(C.11)
∂ρ3
∂t = λ{2,1}3ρ{2,1} + λ{2,2}3ρ{2,2} + λ{2,3}3ρ{2,3}
(C.12)
−(λ3{2,1} + λ3{2,2} + λ3{2,3})ρ3 −∇· (f3ρ3)
and the initial condition :
ρ(x, 0) =

1 0 0 0 0]T
1
2σ0x

(π)
e
−(M0−ln(x))2
2σ2
0
(C.13)
The boundary condition in both cases is
ρ(0, t) = ρ(103, t) = 0, ∀t
(C.14)
and the prediction of the steady state ηs(x) is computed by brute force, leaving
that t in the computations takes a large value. The average TCR amount ¯η(t) is
calculated using
¯η(t) =
 ∞
−∞
xη(x, t)dx
(C.15)
where η(x, t) is computed for all t by (C.1) and (C.7) taking into account
corresponding state PDF evolution for CT MCμA (C.2)–(C.4) and CT MCμA
(C.8)–(C.12), respectively.

D. Optimal Control of Partial Diﬀerential
Equations
Since the state PDF evolution of the robotic population CT MCμA model is
described by a system of PDEs, the optimal control problem introduced in
Section 7 should be considered as an optimal control problem of PDEs. The
main result regarding this optimal control problem is the so-called Minimum
Principle for PDEs.
In our case, we consider a more speciﬁc control problem PDE system which
is in the form of the Evolution equation:
ρ′(t) = A(t)ρ(t) + f(ρ(t), u(t), t), ρ(0) : given
(D.1)
and an objective function to be maximized
ρ0(u, T ) = g0(ρ, ρ(u, T )) +
 T
0
f0(ρ(u, τ), u(τ), τ)dτ
(D.2)
The PDE, as well as the objective function are written using the notation em-
ployed in the control theory of PDE [21], namely the abstract form, where ρ′(t)
is the time derivative of ρ(t) and ρ(t) is not only a function of time but also a
function of the space variable. With some exceptions, where we use the reference
for PDE [20], all the results presented in this appendix are from [21].
First, we will introduce the deﬁnitions and the hypothesis which are neces-
sary to deﬁne the properties of the Evolution equation for which the Minimum
Principle can be applied.
Deﬁnition D.1 [20]. The Lp(X) space of functions is
Lp(X) = {ρ : X →R| is Lebesgue meas., ∥ρ∥Lp < ∞}
(D.3)
where
∥ρ∥Lp =

X
|ρ|2dx
 1
2
, 1 < p < ∞
(D.4)
Deﬁnition D.2 [21]. Tangent cone TYρ(¯ρ) to Yρ at ¯ρ consists of all ω such that,
for every sequence {hk} ⊂R+ with hk →0 and for every sequence { ¯ρk} ⊂Yρ
with ¯ρk →¯ρ, there exists a sequence {ρk} ⊂Yρ with ρk →¯ρ and
D. Milutinovic and P. Lima: Cells & Robots, STAR 32, pp. 113–116, 2007.
springerlink.com
c
⃝Springer-Verlag Berlin Heidelberg 2007

114
D. Optimal Control of Partial Diﬀerential Equations
ρk −¯ρk
hk
→ω as k →∞
(D.5)
Deﬁnition D.3 [21]. Negative polar cone of subset Z ∈E is the subset Z−of
the dual space ET deﬁned by
Z−= {ρT ∈ET ; ⟨ρT , ρ⟩≤0, ρ ∈Z}
(D.6)
where symbol ⟨·, ·⟩is the duality pairing of E and ET .
Deﬁnition D.4 [21]. Normal cone NYρ ⊂E∗to Yρ at ¯ρ is the (closed,convex)
cone deﬁned by
NYρ(¯ρ) = TYρ(¯ρ)−
(D.7)
Deﬁnition D.5 [21]. Normal cone NYρ ⊂E∗to Yρ at ¯ρ is the (closed,convex)
cone deﬁned by
NYρ(¯ρ) = TYρ(¯ρ)−
(D.8)
Deﬁnition D.6 [21]. (Patch complete) The set of admissible control in the time
interval [0, T ] taking values from the set U, Cad(0, T ; U) is patch complete if
every patch perturbation of the control u ∈Cad(0, T ; U) with arbitrary m and
v = (v1, v2, . . . , vm), vk ∈Cad(0, T ; U) belongs to Cad(0, T ; U).
The patch perturbation of the control u corresponding to e and v is:
ue,v(t) =
⎧
⎨
⎩
vj(t), t ∈ej, j = 1, 2, . . ., m
u(t)
elsewhere
(D.9)
Deﬁnition D.7 [21]. (Saturated space) The sequence of control un⊂Cad(0, T ; U)
is stationary if there exists a set e with |e| = 0 such that for every t ∈[0, T ]\e
there exists n (depending on t) such that un(t) = un+1(t) = un+2(t) = . . .. The
space Cad(0, T ; U) is called saturated if the limit of every stationary sequence
belongs to Cad(0, T ; U).
Deﬁnition D.8 [21]. (Spike complete) The set of admissible control in the
time interval [0, T ] taking values from set U, Cad(0, T ; U) is spike complete if
every spike perturbation of the control u ∈Cad(0, T ; U).
The spike perturbation of the control u corresponding to s, h and v is:
us,h,v(t) =
⎧
⎨
⎩
v, s −h < t ≤s
u(t)
elsewhere
(D.10)
where 0 < s ≤T , 0 ≤h ≤s and v is element of U.
Deﬁnition D.9 [20]. Set E is separable if E contains a countable dense subset.

D. Optimal Control of Partial Diﬀerential Equations
115
Deﬁnition D.10 [21]. (Regular set) Let φ(t, v) be a Banach space valued func-
tion deﬁned in [0, T ] × U such that φ(t, v) is integrable for v ﬁxed. The left
Lebesgue set of φ(t, U) is the set d of all t ∈[0, T ] such that t is a left Lebesgue
point of φ(t, v) for every v ∈U. The φ(t, v) is regular in U if its left Lebesgue
set has full measure in [0, T ].
Hypothesis under which Theorem D.1 is valid : The Fr´echet derivative
∂ρf0(ρ, u, t) and ∂ρf(ρ, u, t) exist in [0, T ] × E. The function f0(ρ, u, t) is mea-
surable, f(ρ, u, t) is strongly measurable in t for ρ ﬁxed and continuous in ρ for
t ﬁxed. For every c > 0 there exists K0(t, c), L0(t, c) ∈L1(0, T ) such that
f0(ρ, u, t) ≤K0(t, c),
(0 ≤t ≤T, y ≤c)
(D.11)
∂ρf0(ρ, u, t) ≤L0(t, c),
(0 ≤t ≤T, y ≤c)
(D.12)
f(ρ, u, t) ≤K(t, c),
(0 ≤t ≤T, y ≤c)
(D.13)
∂ρf(ρ, u, t) ≤L(t, c),
(0 ≤t ≤T, y ≤c)
(D.14)
Finally, we assume that the Fr´echet derivative ∂ρg0(ρ, u, t) exists in [0, T ] × E.
All this properties do not depend on the control u which is in the set of admis-
sible control.
Theorem D.1 [21]. (The Minimum Principle for general control problems.)
Let us assume that the target set Yρ is closed and that Cad(0, T ; U), the set of
admissible control in the time interval [0, T ] taking values from set U, is patch
complete and saturated. Then, if u∗is an optimal control in 0 ≤t ≤T there
exists (z0, z1) ∈R × E, z0 ≥0, z ∈NYρ(ρ∗) = normal cone to Yρ at ρ(T, u∗)
such that, if π(s) is the solution of
∂tπ(s)=−[A(s) + ∂ρf(ρ(u, s), u(s), s)]T π(s)
(D.15)
−z0∂ρf0(ρ(u∗, s), u∗(s), s)
π(t)=z + z0∂ρg0(ρ(u∗, T ), T )
(D.16)
in 0 ≤s ≤T
0 ≤z0
 T
0
{[f0(ρ(u∗, σ), v(σ), σ) −f0(ρ(σ, u∗), u∗(σ), σ)]
+ ⟨π(σ), f(ρ(σ, u∗), v(σ), σ) −f(ρ(σ, u∗), u∗(σ), σ)⟩} dσ
(D.17)
for all v ∈Cad(0, T ; U). If E is separable, for f0(ρ(t, u∗), v(t), t) and f(ρ(t, u∗),
v(t), t) are regular in U and Cad(0, T ; U) is spike complete, then
z0f0(ρ(u∗, s), u∗(s), s) + ⟨π(s), f(ρ(u∗, s), u∗(s), s)⟩=
min
v∈U z0f0(ρ(u∗, s), v, s) + ⟨π(s), f(ρ(s, u∗), v, s)⟩
(D.18)
i.e., in 0 ≤s ≤T

116
D. Optimal Control of Partial Diﬀerential Equations
Remark. Introducing the Hamiltonian H:
H(ρ∗, v, t) = z0f0(ρ(u∗, t), v, t) + ⟨π(t), f(ρ(u∗, t), v, t)⟩
(D.19)
expressions (D.17) and (D.18) can be written, respectively, as:
u∗= min
v∈Cad
 T
0
H(ρ∗, v, σ)dσ
(D.20)
u∗(t) = min
v(t)∈U H(σ, ρ∗, v(t))dσ
(D.21)

References
1. W. Agassounon, A. Martinoli, and K. Easton, Macroscopic Modeling of Ag-
gregation Experiments using Embodied Agents in Teams of Constant and Time-
Varying Sizes, Autonomous Robots, 17 (2004), pp. 163–192.
2. R. Albert and A. Barabasi, Statistical Mechanics of Complex Networks, Re-
views of Modern Physics, 74 (2002), pp. 47–97.
3. R. Alur, C. Belta, F. Ivancic, V. Kumar, M. Mintz, G. J. Pappas, H. Rubin,
and J. Schug, Hybrid Modeling and Simulation of Biomolecular Networks, Hybrid
Systems: Computation and Control, Lecture Notes in Computer Science, 2034
(2001), p. 19.
4. R. Arkin, Behavior-Based Robotics, The MIT Press, 1998.
5. M. F. Bachmann, M. Salzmann, A. Oxenius, and P. S. Ohashi, Formation
of TCR dimers/trimers as a crucial step for T cell activation, Eur. J. Immunol.,
28 (1998), pp. 2571–2579.
6. T. Balch and L. Parker, Robot Teams: From Diversity to Polymorphism, AK
Peters, 2002.
7. C. Bergmann, J. L. Van Hemmen, and L. A. Segel, Th1 or Th2: how an
appropriate T helper response can be Made, Bull. Math. Biol., 63 (2001), pp. 405–
430.
8. D. Bertsekas, Nonlinear Programming, Athena Scientiﬁc, 1999.
9. G. Bocharov et. al., Underwhelming the Immune Response: Eﬀect of Slow
Virus Growth on CD8+-T-Lymphocyte Responses, Journal of Virology, 78 (2004),
pp. 2247–2254.
10. E. Bonabeau, G. Theraulaz, and J. Deneubourg, Group and Mass Recruit-
ment in Ant Colonies: the Inﬂuence of Contact Rates, J. Theor. Biol., 195 (1998),
pp. 157–166.
11. E. Bonabeau, G. Theraulaz, J.-L. Deneubourg, S. Aron, and S. Camazine,
Self-Organization in social insects, Trends Ecol. Evol., 12 (1997), pp. 188–193.
12. J. Carneiro, J. Stewart, A. Coutinho, G. Coutinho, and C. Martinez-A,
The ontogeny of class-regulation of CD4+ T lymphocyte populations, Int. Immunol,
7 (1995), pp. 1265–1277.
13. A. Chakraborty, Lighting Up TCR Takes Advantage of Serial Triggering, Nature
Immunology, 3 (2002), pp. 895–896.
14. D. Coombs, M. Dembo, C. Wofsy, and B. Goldstein, Equilibrium thermody-
namics of cell-cell adhesion mediated by multiple ligand-receptor pairs, Biophysical
Journal, 86 (2004), pp. 1408–1423.

118
References
15. T. Cover and J. Thomas, Elements of Information Theory, Wiley-Interscience,
New York, 1991.
16. R. J. De Boer, L. A. Segel, and A. S. Perelson, Pattern formation in one-
and two-dimensional shape-space models of the immune system, J. Theor. Biol.,
155 (1992), pp. 295–333.
17. C. Detrain, J. L. Deneubourg, and J. M. Pasteels, Information Processing
in Social Insects, Birkhauser, 1999.
18. Z. Djurovi´c and B. Kovaˇcevi´c, Bandwidth selection for kernel density estima-
tion based on QQ-plot, WSEAS Trans. on Circuits and Systems, 3 (2004), pp. 679–
687.
19. Z. Djurovi´c, B. Kovaˇcevi´c, and V. Barroso, QQ-plot Based Probability Den-
sity Function Estimation, Proc. 10-th Workshop Stat. Sig. and Array Processing,
Pocono Manor, PA, USA, (2000).
20. L. C. Evans, Partial Diﬀerential Equations, American Mathematical Society,
Providence, 1998.
21. H. O. Fattorini, Inﬁnite Dimensional Optimization and Control Theory, Cam-
bridge University Press, 1999.
22. C. Fellbaum, WordNet: An Electronic Lexical Database, Bradford Books, 1998.
23. J. Ferber, Multi-Agent Systems: An Introduction to Distributed Artiﬁcial Intelli-
gence , Addison-Wesley Longman, 1999.
24. D. Flamm, History and Outlook of Statistical Physics, ArXiv Physics e-prints,
http://www.citebase.org/abstract?id=oai:arXiv.org:physics/9803005, 1998.
25. C. W. Gardiner, Handbook of Stochastic Methods for Physics, Chemistry and the
Natural Sciences, Springer, second ed., 1985.
26. A. Gelb, Applied Optimal Estimation, The MIT Press, 1974.
27. M. Gunzer and A. Schafer et al., Antigen presentation in extracellular matrix:
Interactions of T cells with dendritic cells are dynamic, short lived, and sequential,
Immunity, 13 (2000), pp. 323–332.
28. S. Harsdorf and R. Reuter, Stable Deconvolution of Noisy Lidar Signals,
EARSeL eProceedings, 1 (2001), pp. 88–95.
29. A. Hirsh and D. Gordon, Distributed problem solving in social insects, Annals
of Mathematics and Artiﬁcial Intelligence, 31 (2001), pp. 199–221.
30. http://www.training.seer.cancer.gov, funded by the U.S. National Cancer
Institute’s Surveillance, Epidemiology and End Results (SEER) Program, via con-
tract number N01-CN-67006, with Emory University, Atlanta SEER Cancer Reg-
istry, Atlanta, Georgia, U.S.A.
31. J. B. Huppa and M. M. Davis, T-cell-antigen recognition and the immunological
synapse, Nat. Rev. Immunol., 3 (2003), pp. 973–983.
32. A. Jadbabaie, J. Lin, and A. S. Morse, Coordination of Groups of Mobile
Autonomous Agents Using Nearest Neighbor Rules, IEEE Trans. on Automatic
Control, 48 (2003), pp. 988–1001.
33. C. A. Janeway and P. Travers, Immunobiology, Blackwell Scientiﬁc Publica-
tion, 1994.
34. E. T. Jeynes, Information Theory and Statistical Mechanics, Physical Review,
106 (1957), pp. 620–630.
35. H. Jianghai, J. Lygeros, and S. Sastry, Towards a Theory of Stochastic Hybrid
Systems, Hybrid Systems: Computation and Control, Lecture Notes in Computer
Science, 1790 (2000), pp. 160–173.
36. M. Kaufman, F. Andris, and O. Leo, A Logical Analysis of T Cell Activation
and Anergy, Immunology, Proc. Natl. Acad. Sci. USA, 96 (1999), pp. 3894–3899.

References
119
37. T. B. Kepler and A. S. Perelson, Somatic Hypermutation in B Cells: An
Optimal Control Treatment, J. Theor. Biol., 164 (1993), pp. 37–64.
38. H. Kitano, Computational Systems Biology, Nature, 420 (2002), pp. 206–210.
39. L. D. Landau and E. M. Lifshitz, Statistical Physics, Pergamon Press, 1959.
40. K. H. Lee and A. R. Dinner et al., The Immunological Synapse Balances T
Cell Receptor Signaling and Degradation, Science, 302 (2003), pp. 1218–1222.
41. K. L´eon, A. Lage, and J. Carneiro, Tolerance and immunity in a mathematical
model of T-cell mediated suppression, J. Theor. Biol., 255 (2003), pp. 107–126.
42. K. L´eon, R.Perez, A.Lage, and J.Carneiro, Three-cell interactions in T cell
mediated suppression? A mathematical analysis of its quantitative implications, J.
Immunol., 166 (2001), pp. 5356–5365.
43. K. Lerman and A. Galstyan, Mathematical Model of Foraging in a Group of
Robots: Eﬀect of Interference, Autonomous Robots, 13 (2002), pp. 127–141.
44. K. Lerman, C. Jones, A. Galstyan, and M. J. Matari´c, Analysis of Dynamic
Task Allocation in Multi-Robot Systems, Int. J. of Robotics Research, 25 (2006),
pp. 225–242.
45. A. Lino, Caracteriza¸c˜ao do mecanismo molecular de activa¸c˜ao de linfocitos T,
Relat´orio Final de Curso Bioqimica, Faculdade de Ciˆencias da Univesidade de
Lisboa, Lisboa pp.47, 2000.
46. J. L. Lions, Optimal Control of Systems Governed by Partial Diﬀerential Equa-
tions, Springer-Verlag, 1971.
47. L. B. Lucy, An Iterative Technique for the Rectiﬁcation of Observed Distributions,
Astronomical Journal, 79 (1974), pp. 745–754.
48. A. Martinoli, K. Easton, and W. Agassounon, Modeling Swarm Robotic Sys-
tems: A Case Study in Collaborative Distributed Manipulation, Int. Journal of
Robotics Research, 23 (2004), pp. 415–436.
49. A. Martinoli, A. J. Ijspeert, and L. M. Gambardella, A Probabilistic Model
for Understanding and Comparing Collective Aggregation Mechanisms, Proceed-
ings of the 5th European Conference on Advances in Artiﬁcial Life (ECAL-99),
volume of LNAI, 1674 (1999), pp. 575–584.
50. M.Athans and P. Falb, Optimal Control: An Introduction to the Theory and its
Applications, McGraw Hill, New York, 1966.
51. T. R. Mempel, S. E. Henrickson, and U. H. Von Andrian, T cell priming by
dendritic cells in lymph nodes occurs in three distinct phases, Nature, 427 (2004),
pp. 154–159.
52. M. J. Miller, S. H. Wei, I. Parker, and M. D. Cahalan, Two-photon imaging
of lymphocyte motility and antigen response in intact lymph node, Science, (2002),
pp. 1869–1873.
53. D. Milutinovi´c, J. Carneiro, M. Athans, and P. Lima, A Hybrid Automata
Modell of TCR Triggering Dynamics, Proceedings of the 11th IEEE Mediterranean
Conference on Control and Automation (MED2003), Rhodes, Greece, (2003).
54. D. Milutinovi´c and J. Carneiro et al., Modeling Dynamics of Cell Population
Molecule Expression Distribution, accepted for publishing by Nonlinear Analysis:
Hybrid Systems, Elsevier, (2007).
55. D. Milutinovi´c and P. Lima, Modeling and Optimal Centralized Control of
a Large-Size Robotic Population, IEEE Transactions on Robotics, 22 (2006),
pp. 1280–1285.
56. D. Milutinovi´c, P. Lima, and M. Athans, Biologically Inspired Stochastic Hy-
brid Control of Multi-Robot Systems, Proceedings of the 11th International Con-
ference on Advanced Robotics (ICAR), University of Coimbra, Portugal, (2003).

120
References
57. M. Morari, Hybrid system analysis and control via mixed integer optimization,
IFAC Symposium on Dynamics and Control of Process Systems, 1 (2002), pp. 1–12.
58. A. U. Neumann and G. Weisbuch, Dynamics and topology of idiotypic networks,
Bull. Math. Biol., 54 (1992), pp. 699–726.
59. G. Nicolis and I. Prigogine, Self-Organization in Nonequilibrium Systems, John
Wiley and Sons Inc., 1977.
60. M. A. Nowak and R. M. May, Virus Dynamics: Mathematical Principles of
Immunology and Virology, Oxford University Press, 2000.
61. A. S. Perelson and P. W. Nelson, Mathematical Analysis of HIV-1 Dynamics
in Vivo, SIAM Review, 41 (1999), pp. 3–44.
62. A. S. Perelson and G. Weisbuch, Immunology for Physicists, Reviews of Mod-
ern Physics, 69 (1997), pp. 1219–1268.
63. B. Polic, D. Kunkel, A. Scheffold, and K. Rajewsky, How alpha beta T
cells deal with induced TCR alpha ablation, Proc. Natl. Acad. Sci. USA, 98 (2001),
pp. 8744–8749.
64. M. J. D. Powell, Restart procedures for the conjugate gradient method, Mathe-
matical Programming, 12 (1977), pp. 241–254.
65. C. W. Reynolds, Flocks, herds and schools: A distributed behavioral model, Com-
puter Graphics, 21 (1987), pp. 25–34.
66. W. H. Richardson, Bayesian-Based Iterative Method of Image Restoration, Jour-
nal of the Optical Society of America, 62 (1972), pp. 55–59.
67. L. Segel and A. Perelson, Shape space: An Approach to the Evaluation of Cross-
Reactivity Eﬀects, Stability and Controllability in the Immune System, Immunol
Lett., 22 (1989), pp. 91–99.
68. J. Sousa, Modeling the antigen and cytokine receptors signaling processes and their
propagation to lymphocyte population dynamics, PhD Dissertation, University of
Lisbon, Portugal, 2003.
69. J. Sousa and J. Carneiro, A Mathematical Analysis of TCR Serial Triggering
and Down-Regulation, Eur. J. Immunol., 30 (2000), pp. 3219–3227.
70. J. Stewart and F. J. Varela, Morphogenesis in shape-space. Elementary meta-
dynamics in a model of the immune network, J. Theor. Biol., 153 (1991), pp. 477–
498.
71. K. Sugawara and M. Sano, Cooperative acceleration of task performance: Forag-
ing behavior of interacting multi-robot system, Physica D, 100 (1997), pp. 343–354.
72. B. Suzer, J. L. van Hemmen, A. U. Neumann, and U. Behn, Memory in id-
iotypic networks due to competition between proliferation and diﬀerentiation, Bull.
Math. Biol., 55 (1993), pp. 1133–1182.
73. P. Tabuada, G. J. Pappas, and P.Lima, Feasible formations of multi-agent sys-
tems, Proc. American Control Conf. Arlington, 1 (2001), pp. 56–61.
74. H. G. Tanner, G. J. Pappas, and V. Kumar, Leader-to-Formation Stability,
IEEE Trans. on Robotics and Automation, 20 (2004), pp. 443–455.
75. S. Valitutti, S. Muller, M. Cella, E. Padovan, and A. Lanzavecchia,
Serial Triggering of Many T-cell Receptors by a Few Peptide-MHC Complexes,
Nature, 375 (1995), pp. 148–151.
76. A. J. van der Schaft and J. M. Schumacher, An Introduction to Hybrid
Dynamical Systems, Springer-Verlag, 2000.
77. H. von Boehmer and I. Aifantis et al., Thymic selection revisited: how essen-
tial is it?, Immunol. Rev., 191 (2003), pp. 62–78.
78. O. von Stryk and R. Bulirsch, Direct and Indirect Methods for Trajectory
Optimization, Annals of Operations Research, 37 (1992), pp. 357–373.

References
121
79. L. M. Wein, S. A. Zenios, and M. A. Nowak, Dynamic Multidrug Therapies
for HIV: A Control Theoretic Approach, J. Theor. Biol., 185 (1997), pp. 15–29.
80. G. Weisbuch, R. J. De Boer, and A. S. Perelson, Localized memories in
idiotypic networks, J. Theor. Biol., 146 (1990), pp. 483–499.
81. D. Witherden and N. van Oers et al., Tetracycline-controllable selection of
CD4(+) T cells: half-life and survival signals in the absence of major histocompat-
ibility complex class II molecules, J. Exp. Med., 191 (2000), pp. 355–364.
82. D. Wodarz, K. M. Page, R. A. Arnaout, A. R. Thomsen, J. D. Lifson, and
M. A. Nowak, A New Theory of Cytotoxic T-lymphocyte Memory: Implication for
HIV Treatment, Philos. Trans. Royal Soc. Lond. B Biol. Sci., 355 (2000), pp. 329–
343.
83. C. Wofsy and B. Goldstein, Eﬀective Rate Models for Receptors Distributed in
a Layer above a Surface: Application to Cells and Biacore, Biophysical Journal, 82
(2002), pp. 1743–1755.
84. M. Wooldridge, An Introduction to MultiAgent Systems, John Wiley and Sons,
2002.
85. O. C. Zienkiewicz and R. L. Taylor, The Finite Element Method - Fluid Dy-
namics, vol. 3, Butterworth-Heinemann, 2000.

Index
Anti-viral immune response, 6
Antibody, 35, 46
Antigen, 4, 9
Boltzmann constant, 25
Boolean network models, 6
Cell
antigen-presenting (APC), 4, 10
dendritic, 4
eﬀector, 4
helper, 4
memory, 4
motile, 1
naive, 4
receptor, 2, 3
sensory system, 3
T-cell, 10
Cellular automata, 6
Centralized control, 7, 67
Chemokine, 3
source, 2
Computational complexity, 83
Continuous Time Markov Chain
Micro-Agent, 25
Control approximation, 82
Decision making, 3
Distributed control, 67
Eﬃcient gradient based algorithm, 87
Evolution equation, 75, 113
Flow Cytometry scanner (FCS), 12, 97
Gauss theorem, 31
Hamiltonian, 81, 82, 116
Hilbert space, 79
Hybrid automaton, 15
T-cell model, 17, 36
Hybrid system, 15
deterministic, 6
stochastic, 6
T-cell population, 18, 19
Idiotypic network, 6
Immune system, 1, 9
adaptive, 9
innate, 9
Immunological synapse, 6
Kinetic Gas Theory, 25
Kullback-Leibler distance, 48
Large-scale multi-agent systems, 5
Large-size robotic population, 67
Lebesgue
integrable, 79
measurable, 79, 113
Linear hypothesis, 47
Liouville equation, 26, 32, 47
Log-normal distribution, 44
Lotka-Voltera, 4
Lyapunov equation, 41
Lymph node, 4
Maximum Entropy Principle, 26
Maxwell-Boltzmann formula, 25
MHC-peptide complex, 10

124
Index
Micro-Agent
CTMCμA, 22, 27, 35
Continuous Time Markov Chain
Execution, 21
deﬁnition, 20
Event Generator (MAEG), 19
model of the T-cell, 18
population state, 26
Stochastic, 20
Stochastic Execution, 21, 27
Stochastic, deﬁnition, 22
Minimum description length, 101
Minimum Principle, 68, 75, 76
Mobile robot, 1, 2
Multi-Agent systems, 2, 67
Nonlinear Conjugate Gradient Method,
85
Numerical optimal control, 82
Omnidirectional, 3
Parameter uncertainty
continuous, 53, 60
discrete, 53, 54
Phenotype, 3
Polak-Ribi`ere update rule , 85
Pontryagin Minimum Principle, 75
Pontryagin-Hamiltonian, 7, 68
Population complexity, 16
Population Event Generator, 18
Probability density function (PDF)
Micro-Agents output, 33
duality, 26
dynamics, 27
estimation algorithm, 99
Stochastic Micro-Agent state, 27
QQ-plot, 56, 100
PDF estimation, 48, 101
Quadratic hypothesis, 47
Reverse engineering, 3, 4
Richardson-Lucy deconvolution, 48, 103
Robot
agent, 5
discrete states, 69
team, 4, 5
Robotic population
mission scenario, 68
optimal control criterion, 74
optimal control problem, 73
position prediction, 71
Self-organized systems, 5
Shape space, 6
Singular control problem, 81, 84
Social insects, 5
Statistical physics, 25
Stochastic Micro-Agent, 27
Individual robot, 70
Model Uncertainties, 53
State space, 28
T-cell receptor (TCR), 3, 7, 10
down-regulation, 10, 35
dynamics, 10
dynamics of conjugated state, 46
dynamics,numerical examples , 35
expression
dynamics, 10, 35, 36
steady state distribution, 40, 43, 45
ligand, 10
quantity, 36
triggering, 10
Task allocation, 4–6
Task performance, 6
Three-step procedure, 59
Two-photon microscopy, 4, 11
Two-point-boundary-value problem, 76
Ultrasonic sensor, 2
Uncertain factors, 69
Virtual agent, 5

Springer Tracts in Advanced Robotics
Edited by B. Siciliano, O. Khatib and F. Groen
Vol. 32: Milutinovi´c, D.; Lima, P.
Cells and Robots: Modeling and Control of
Large-Size Agent Populations
124 p. 2007 [978-3-540-71981-6]
Vol. 31: Ferre, M.; Buss, M.; Aracil, R.;
Melchiorri, C.; Balaguer C. (Eds.)
Advances in Telerobotics
500 p. 2007 [978-3-540-71363-0]
Vol. 30: Brugali, D. (Ed.)
Software Engineering for Experimental Robotics
490 p. 2007 [978-3-540-68949-2]
Vol. 29: Secchi, C.; Stramigioli, S.; Fantuzzi, C.
Control of Interactive Robotic Interfaces – A
Port-Hamiltonian Approach
225 p. 2007 [978-3-540-49712-7]
Vol. 28: Thrun, S.; Brooks, R.; Durrant-Whyte, H.
(Eds.)
Robotics Research – Results of the 12th
International Symposium ISRR
602 p. 2007 [978-3-540-48110-2]
Vol. 27: Montemerlo, M.; Thrun, S.
FastSLAM – A Scalable Method for the
Simultaneous Localization and Mapping
Problem in Robotics
120 p. 2007 [978-3-540-46399-3]
Vol. 26: Taylor, G.; Kleeman, L.
Visual Perception and Robotic Manipulation – 3D
Object Recognition, Tracking and Hand-Eye
Coordination
218 p. 2007 [978-3-540-33454-5]
Vol. 25: Corke, P.; Sukkarieh, S. (Eds.)
Field and Service Robotics – Results of the 5th
International Conference
580 p. 2006 [978-3-540-33452-1]
Vol. 24: Yuta, S.; Asama, H.; Thrun, S.;
Prassler, E.; Tsubouchi, T. (Eds.)
Field and Service Robotics – Recent Advances in
Research and Applications
550 p. 2006 [978-3-540-32801-8]
Vol. 23: Andrade-Cetto, J.; Sanfeliu, A.
Environment Learning for Indoor Mobile Robots
– A Stochastic State Estimation Approach
to Simultaneous Localization and Map Building
130 p. 2006 [978-3-540-32795-0]
Vol. 22: Christensen, H.I. (Ed.)
European Robotics Symposium 2006
209 p. 2006 [978-3-540-32688-5]
Vol. 21: Ang Jr., H.; Khatib, O. (Eds.)
Experimental Robotics IX – The 9th International
Symposium on Experimental Robotics
618 p. 2006 [978-3-540-28816-9]
Vol. 20: Xu, Y.; Ou, Y.
Control of Single Wheel Robots
188 p. 2005 [978-3-540-28184-9]
Vol. 19: Lefebvre, T.; Bruyninckx, H.;
De Schutter, J. Nonlinear Kalman Filtering
for Force-Controlled Robot Tasks
280 p. 2005 [978-3-540-28023-1]
Vol. 18: Barbagli, F.; Prattichizzo, D.;
Salisbury, K. (Eds.)
Multi-point Interaction with Real
and Virtual Objects
281 p. 2005 [978-3-540-26036-3]
Vol. 17: Erdmann, M.; Hsu, D.; Overmars, M.;
van der Stappen, F.A (Eds.)
Algorithmic Foundations of Robotics VI
472 p. 2005 [978-3-540-25728-8]
Vol. 16: Cuesta, F.; Ollero, A.
Intelligent Mobile Robot Navigation
224 p. 2005 [978-3-540-23956-7]
Vol. 15: Dario, P.; Chatila R. (Eds.)
Robotics Research – The Eleventh
International Symposium
595 p. 2005 [978-3-540-23214-8]
Vol. 14: Prassler, E.; Lawitzky, G.; Stopp, A.;
Grunwald, G.; Hägele, M.; Dillmann, R.;
Iossiﬁdis. I. (Eds.)
Advances in Human-Robot Interaction
414 p. 2005 [978-3-540-23211-7]
Vol. 13: Chung, W.
Nonholonomic Manipulators
115 p. 2004 [978-3-540-22108-1]
Vol. 12: Iagnemma K.; Dubowsky, S.
Mobile Robots in Rough Terrain –
Estimation, Motion Planning, and Control
with Application to Planetary Rovers
123 p. 2004 [978-3-540-21968-2]
Vol. 11: Kim, J.-H.; Kim, D.-H.; Kim, Y.-J.;
Seow, K.-T.
Soccer Robotics
353 p. 2004 [978-3-540-21859-3]

Vol. 10: Siciliano, B.; De Luca, A.; Melchiorri, C.;
Casalino, G. (Eds.)
Advances in Control of Articulated and
Mobile Robots
259 p. 2004 [978-3-540-20783-2]
Vol. 9: Yamane, K.
Simulating and Generating Motions
of Human Figures
176 p. 2004 [978-3-540-20317-9]
Vol. 8: Baeten, J.; De Schutter, J.
Integrated Visual Servoing and Force
Control – The Task Frame Approach
198 p. 2004 [978-3-540-40475-0]
Vol. 7: Boissonnat, J.-D.; Burdick, J.;
Goldberg, K.; Hutchinson, S. (Eds.)
Algorithmic Foundations of Robotics V
577 p. 2004 [978-3-540-40476-7]
Vol. 6: Jarvis, R.A.; Zelinsky, A. (Eds.)
Robotics Research – The Tenth
International Symposium
580 p. 2003 [978-3-540-00550-6]
Vol. 5: Siciliano, B.; Dario, P. (Eds.)
Experimental Robotics VIII – Proceedings
of the 8th International Symposium ISER02
685 p. 2003 [978-3-540-00305-2]
Vol. 4: Bicchi, A.; Christensen, H.I.;
Prattichizzo, D. (Eds.)
Control Problems in Robotics
296 p. 2003 [978-3-540-00251-2]
Vol. 3: Natale, C.
Interaction Control of Robot Manipulators –
Six-degrees-of-freedom Tasks
120 p. 2003 [978-3-540-00159-1]
Vol. 2: Antonelli, G.
Underwater Robots – Motion and Force Control
of Vehicle-Manipulator Systems
268 p. 2006 [978-3-540-31752-4]
Vol. 1: Caccavale, F.; Villani, L. (Eds.)
Fault Diagnosis and Fault Tolerance for
Mechatronic Systems – Recent Advances
191 p. 2003 [978-3-540-44159-5]

