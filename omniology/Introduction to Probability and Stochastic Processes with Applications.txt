
Introduction to Probability 
and Stochastic Processes 
with Applications 

Introduction to Probability 
and Stochastic Processes 
with Applications 
Liliana Blanco Castaneda 
National University of Colombia 
Bogota, Colombia 
Viswanathan Arunachalam 
Universidad de los Andes 
Bogota, Colombia 
Delvamuthu Dharmaraja 
Indian Institute of Technology Delhi 
New Delhi, India 
WILEY 
A JOHN WILEY & SONS, INC., PUBLICATION 

Copyright © 2012 by John Wiley & Sons, Inc. All rights reserved 
Published by John Wiley & Sons, Inc., Hoboken, New Jersey 
Published simultaneously in Canada 
No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form 
or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as 
permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior 
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to 
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax 
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should 
be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 
07030, (201) 748-6011, fax (201) 748-6008, or online at http://www.wiley.com/go/permission. 
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in 
preparing this book, they make no representations or warranties with respect to the accuracy or 
completeness of the contents of this book and specifically disclaim any implied warranties of 
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales 
representatives or written sales materials. The advice and strategies contained herein may not be 
suitable for your situation. You should consult with a professional where appropriate. Neither the 
publisher nor author shall be liable for any loss of profit or any other commercial damages, including 
but not limited to special, incidental, consequential, or other damages. 
For general information on our other products and services or for technical support, please contact our 
Customer Care Department within the United States at (800) 762-2974, outside the United States at 
(317) 572-3993 or fax (317) 572-4002. 
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may 
not be available in electronic formats. For more information about Wiley products, visit our web site at 
www.wiley.com. 
Library of Congress Cataloging-in-Publication Data: 
Blanco Castaneda, Liliana. 
Introduction to probability and stochastic processes with applications / Liliana Blanco Castaneda, 
Viswanathan Arunachalam, Selvamuthu Dharmaraja. 
p. cm. 
Includes bibliographical references and index. 
ISBN 978-1-118-29440-6 (hardback) 
1. Probabilities—Textbooks. 2. Stochastic processes—Textbooks. I. Arunachalam, Viswanathan, 
1969- II. Dharmaraja, Selvamuthu, 1972- III. Title. 
QA274.B53 2012 
519.2—dc23 
2012002024 
Printed in the United States of America. 
10 9 8 7 6 5 4 3 2 1 

To Sebastian and Paula 
L.B.C. 
To Akshaya and Abishek 
V.A. 
To Kathiravan and Madhuvanth 
S.D. 

CONTENTS IN BRIEF 
1 
Basic Concepts 
1 
2 
Random Variables and Their Distributions 
51 
3 
Some Discrete Distributions 
115 
4 
Some Continuous Distributions 
145 
5 
Random Vectors 
191 
6 
Conditional Expectation 
265 
7 
Multivariate Normal Distributions 
295 
8 
Limit Theorems 
313 
9 
Introduction to Stochastic Processes 
339 
10 
Introduction to Queueing Models 
417 
11 Stochastic Calculus 
461 
12 
Introduction to Mathematical Finance 
497 
vii 

CONTENTS 
Foreword 
Preface 
Acknowledgments 
Introduction 
1 
Basic Concepts 
1.1 
1.2 
1.3 
1.4 
Probability Space 
Laplace Probability Space 
Conditional Probability and Event Independence 
Geometric Probability 
Exercises 
2 
Random Variables and Their Distributions 
2.1 
2.2 
2.3 
2.4 
Definitions and Properties 
Discrete Random Variables 
Continuous Random Variables 
Distribution of a Function of a Random Variable 
xiii 
XV 
xvii 
xix 
1 
1 
14 
19 
35 
37 
51 
51 
62 
67 
72 

X 
CONTENTS 
2.5 
Expected Value and Variance of a Random Variable 
80 
Exercises 
101 
3 
Some Discrete Distributions 
115 
3.1 
Discrete Uniform, Binomial and Bernoulli Distributions 
115 
3.2 
Hypergeometric and Poisson Distributions 
123 
3.3 
Geometric and Negative Binomial Distributions 
133 
Exercises 
138 
4 
Some Continuous Distributions 
145 
4.1 
Uniform Distribution 
145 
4.2 
Normal Distribution 
151 
4.3 
Family of Gamma Distributions 
161 
4.4 
Weibull Distribution 
170 
4.5 
Beta Distribution 
172 
4.6 
Other Continuous Distributions 
175 
Exercises 
181 
5 
Random Vectors 
191 
5.1 
Joint Distribution of Random Variables 
191 
5.2 
Independent Random Variables 
210 
5.3 
Distribution of Functions of a Random Vector 
217 
5.4 
Covariance and Correlation Coefficient 
228 
5.5 
Expected Value of a Random Vector and Variance-
Covariance Matrix 
235 
5.6 
Joint Probability Generating, Moment Generating and 
Characteristic Functions 
240 
Exercises 
251 
6 
Conditional Expectation 
265 
6.1 
Conditional Distribution 
265 
6.2 
Conditional Expectation Given a σ-Algebra 
280 
Exercises 
287 
7 
Multivariate Normal Distributions 
295 
7.1 
Multivariate Normal Distribution 
295 

CONTENTS 
XI 
7.2 
Distribution of Quadratic Forms of Multivariate Normal 
Vectors 
302 
Exercises 
308 
8 
Limit Theorems 
313 
8.1 
The Weak Law of Large Numbers 
313 
8.2 
Convergence of Sequences of Random Variables 
319 
8.3 
The Strong Law of Large Numbers 
323 
8.4 
Central Limit Theorem 
329 
Exercises 
333 
9 
Introduction to Stochastic Processes 
339 
9.1 
Definitions and Properties 
340 
9.2 
Discrete-Time Markov Chain 
344 
9.2.1 
Classification of States 
353 
9.2.2 
Measure of Stationary Probabilities 
368 
9.3 
Continuous-Time Markov Chains 
371 
9.4 
Poisson Process 
381 
9.5 
Renewal Processes 
389 
9.6 
Semi-Markov Process 
400 
Exercises 
406 
10 
Introduction to Queueing Models 
417 
10.1 
Introduction 
417 
10.2 
Markovian Single-Server Models 
419 
10.2.1 
M/M/l/oo 
Queueing System 
419 
10.2.2 
M/M/l/N 
Queueing System 
427 
10.3 
Markovian MultiServer Models 
431 
10.3.1 
M/M/c/oo 
Queueing System 
431 
10.3.2 
M/M/c/c 
Loss System 
436 
10.3.3 
M/M/c/K 
Finite-Capacity Queueing System 
438 
10.3.4 
M/M/oo Queueing System 
439 
10.4 
Non-Markovian Models 
440 
10.4.1 
M/G/l 
Queueing System 
441 
10.4.2 
GI/M/1 Queueing System 
445 
10.4.3 
M/G/l/N 
Queueing System 
448 
10.4.4 
GI/M/1/N 
Queueing System 
452 
Exercises 
457 

xii 
CONTENTS 
11 
Stochastic Calculus 
461 
11.1 
Martingales 
461 
11.2 
Brownian Motion 
472 
11.3 
Itö Calculus 
481 
Exercises 
491 
12 
Introduction to Mathematical Finance 
497 
12.1 
Financial Derivatives 
498 
12.2 
Discrete-Time Models 
504 
12.2.1 The Binomial Model 
509 
12.2.2 
Multi-Period Binomial Model 
512 
12.3 
Continuous-Time Models 
517 
12.3.1 
Black-Scholes Formula European Call Option 
521 
12.3.2 
Properties of Black-Scholes Formula 
525 
12.4 
Volatility 
527 
Exercises 
529 
Appendix A: Basic Concepts on Set Theory 
533 
Appendix B: Introduction to Combinatorics 
539 
Exercises 
546 
Appendix C: Topics on Linear Algebra 
549 
Appendix D: Statistical Tables 
551 
D.l 
Binomial Probabilities 
551 
D.2 
Poisson Probabilities 
557 
D.3 
Standard Normal Distribution Function 
559 
D.4 
Chi-Square Distribution Function 
560 
Selected Problem Solutions 
563 
References 
577 
Glossary 
581 
Index 
585 

FOREWORD 
Probability theory is the fulcrum around which the present-day mathematical 
modeling of random phenomena revolves. Given its broad and increasing 
application in everyday life-trade, manufacturing, reliability, or even biology 
and psychology, there is an ever-growing demand from researchers for strong 
textbooks expounding the theory and applications of probabilistic models. 
This book is sure to be invaluable to students with varying levels of skill, 
as well as scholars who wish to pursue probability theory, whether pure or 
applied. It contains many different ideas and answers many questions fre-
quently asked in classrooms. The extent of the exercises and examples chosen 
from a multitude of areas will be very helpful for students to understand the 
practical applications of probability theory. 
The authors have extensively documented the origins of probability, giving 
the reader a clear idea of the needs and developments of the subject over 
many centuries. They have taken care to maintain an approach that is math-
ematically rigorous but at the same time simplistic and thus appealing to 
students. 
Although a wide array of applications have been covered in various chap-
ters, I must make particular mention of the chapters on queueing theory and 
financial mathematics. While the latter is an emerging topic, there is no limit 
on the applicability of queueing models to other diverse areas. 
xiii 

XIV 
FOREWORD 
In all, the present book is the result of a long and distinguished teaching 
experience of probability, queueing theory, and financial mathematics, and 
this book is sure to advance the readers' knowledge of this field. 
Professor Alagar Rangan 
Eastern Mediterranean University 
North Cyprus 

PREFACE 
This text is designed for a first course in the theory of probability and a 
subsequent course on stochastic processes or stochastic modeling for students 
in science, engineering, and economics, in particular for students who wish to 
specialize in probabilistic modeling. The idea of writing this book emerged 
several years ago, in response to students enrolled in courses that we were 
teaching who wished to refer to materials and problems covered in the lectures. 
Thus the edifice and the building blocks of the book have come mainly from 
our continuously updated and expanded lecture notes over several years. 
The text is divided into twelve chapters supplemented by four appendices. 
The first chapter presents basic concepts of probability such as probability 
spaces, independent events, conditional probability, and Bayes' rule. The sec-
ond chapter discusses the concepts of random variable, distribution function 
of a random variable, expected value, variance, probability generating func-
tions, moment generating functions, and characteristic functions. In the third 
and fourth chapters, we present the distributions of discrete and continu-
ous random variables, which are frequently used in the applications. The fifth 
chapter is devoted to the study of random vectors and their distributions. The 
sixth chapter presents the concepts of conditional probability and conditional 
expectation, and an introduction to the study of the multivariate normal dis-
tribution is discussed in seventh chapter. The law of large numbers and limit 
xv 

XVI 
PREFACE 
theorems are the goals of the eighth chapter, which studies four types of con-
vergence for sequences of random variables, establishes relationships between 
them and discusses weak and strong laws of large numbers and the central 
limit theorem. The ninth chapter introduces stochastic processes with discrete 
and continuous-time Markov chains as the focus of study. The tenth chapter is 
devoted to queueing models and their applications. In eleventh chapter eleven 
we present an elementary introduction to stochastic calculus where martin-
gales, Brownian motion, and Ito integrals are introduced. Finally, the last 
chapter is devoted to the introduction of mathematical finance. In this chap-
ter, pricing methods such as risk-neutral valuation and Black-Scholes formula 
are discussed. 
In the appendices, we summarize a few mathematical basics needed for 
the understanding of the material presented in the book. These cover ideas 
from set theory, combinatorial analysis, and linear algebra. Finally, the last 
appendix contains tables of standard distributions, which are used in appli-
cations. The bibliography is given at the end of the book, though it is not a 
complete list. 
At the end of each chapter there is a list of exercises to facilitate under-
standing of the main body of each chapter, and in some cases, additional 
study material. Most of the examples and exercises are classroom tested in 
the courses that we taught over many years. We have also benefited from var-
ious books on probability and statistics for some of the examples and exercises 
in the text. To understand this text, the reader must have solid knowledge of 
differential and integral calculus and some linear algebra. 
We do hope that this introductory book provides the foundation for stu-
dents to learn other subjects in their careers. This book is comprehensible to 
students with diverse backgrounds. It is also well balanced, with lots of mo-
tivation to learn probability and stochastic processes and their applications. 
We hope that this book will serve as a valuable text for students and refer-
ence for researchers and practitioners who wish to consult probability and its 
applications. 
L. BLANCO, V. ARUNACHALAM, S. DHARMARAJA 
Bogota, Colombia 
December, 2011 

ACKNOWLEDGMENTS 
We are grateful to Professor Ignacio Mantilla for providing us with motiva-
tion, academic support, and advice for this book project. We are grateful 
to Professor Alagar Rangan for his encouragement and careful reading of the 
draft of this book and offering invaluable advice. This book has greatly bene-
fited from his comments and suggestions. We thank Professor Diego Escobar 
for his useful suggestions. Our sincere thanks to Dr. Liliana Garrido for 
her careful reading as well as her suggestions. We record our appreciation 
to Laura Vielma, Christian Bravo, and Hugo Ramirez for their assistance in 
typing this book. We thank our students for their feedback, incisive questions 
and enthusiasm, and this has served as the platform for this project. We 
acknowledge National University of Colombia, Universidad de los Andes, and 
Indian Institute of Technology Delhi for the institutional support. 
It is a pleasure to thank our Editor, Ms. Susanne Steitz-Filler, John Wiley h 
Sons, and her colleagues for providing advice and technical assistance. 
Finally, last but foremost, we thank our family for their love and support. 
They were instrumental in bringing this book to fruition. 
L.B.C, V.A. and S.D. 
xvii 

INTRODUCTION 
Since its origin, probability theory has been linked to games of chance. In fact 
by the time of the first roman emperor, Augustus (63 B.C.-14 A.D.), random 
games were fairly common and mortality tables were being made. This was 
the origin of probability and statistics. Later on, these two disciplines started 
drifting apart due to their different objectives but always remained closely 
connected. In the sixteenth century philosophical discussions around proba-
bility were held and Italian philosopher Gerolamo Cardano (1501-1576) was 
among the first to make a mathematical approach to randomness. In the sev-
enteenth and eighteenth centuries major advances in probability theory were 
made due in part to the development of infinitesimal calculus; some outstand-
ing results from this period include: the law of large numbers due to James 
Bernoulli (1654-1705), a basic limit theorem in modern probability which can 
be stated as follows: if a random experiment with only two possible outcomes 
(success or failure) is carried out, then, as the number of trials increases the 
success ratio tends to a number between 0 and 1 (the success probability); 
and the DeMoivre-Laplace theorem (1733, 1785 and 1812), which established 
that for large values of n a binomial random variable with parameters n and 
p has approximately the same distribution of a normal random variable with 
mean np and variance np(l —p). This result was proved by DeMoivre in 1733 
for the case p = | and then extended to arbitrary 0 < p < 1 by Laplace in 
xix 

XX 
INTRODUCTION 
1812. In spite of the utmost importance of the aforementioned theoretical 
results, it is important to mention that by the time they were stated there 
was no clarity on the basic concepts. Laplace's famous definition of probabil-
ity as the quotient between cases in favor and total possible cases (under the 
assumption that all results of the underlying experiment were equally prob-
able) was already known back then. But what exactly did it mean "equally 
probable"? In 1892 the German mathematician Karl Stumpf interpreted this 
expression saying that different events are equally probable when there is no 
knowledge whatsoever about the outcome of the particular experiment. In 
contrast to this point of view, the German philosopher Johannes von Kries 
(1853-1928) postulated that in order to determine equally probable events, 
an objective knowledge of the experiment was needed. Thereby, if all the 
information we possess is that a bowl contains black and white balls, then, 
according to Strumpf, it is equally probable to draw either color on the first 
attempt, while von Kries would admit this only when the number of black 
and white balls is the same. It is said that Markov himself had trouble re-
garding this: according to Krengel (2000) in Markov's textbook (1912) the 
following example can be found: "suppose that in an urn there are balls of 
four different colors 1,2,3 and 4 each with unknown frequencies a, b, c and d, 
then the probability of drawing a ball with color 1 equals \ since all colors 
are equally probable". This shows the lack of clarity surrounding the mathe-
matical modeling of random experiments at that time, even those with only 
a finite number of possible results. 
The definition of probability based on the concept of equally probable led 
to certain paradoxes which were suggested by the French scientist Joseph 
Bertrand (1822-1900) in his book Calcul des probabüites (published in 1889). 
One of the paradoxes identified by Bertrand is the so-called paradox of the 
three jewelry boxes. In this problem, it is supposed that three jewelry boxes 
exist, A, B and C, each having two drawers. The first jewelry box contains 
one gold coin in each of the drawers, the second jewelry box contains one silver 
coin in each of the drawers and in the third one, one of the drawers contains 
a gold coin and the other a silver coin. Assuming Laplace's definition of 
probability, the probability of choosing the third jewelry box would be | . Let 
us suppose now that a jewelry box is randomly chosen and when one of the 
drawers is opened a gold coin is found. Then there are two options: either the 
other drawer contains a gold coin (in which case the chosen jewelry box would 
be A) or the other drawer contains a silver coin, which means the chosen 
jewelry box is C. If the coin originally found is silver, there would be two 
options: either the other drawer contains a gold coin, which means the chosen 
jewelry box is C, or the other drawer contains a silver coin, which would mean 
that the chosen jewelry box is B. Hence the probability of choosing C is \. 
Bertrand found it paradoxical that opening a drawer changed the probability 
of choosing jewelry box C. 
The first mathematician able to solve the paradox of the three jewelry 
boxes, formulated by Bertrand, was Poincare, who got the following solution 

INTRODUCTION 
XXI 
as early as 1912. Let us assume that the drawers are labeled (in a place we 
are unable to see) as a and ß and that the gold coin of jewelry box C is in 
drawer a. Then the following possibilities would arise: 
1. Jewelry box A, drawer a: gold coin 
2. Jewelry box A, drawer ß: gold coin 
3. Jewelry box B, drawer a: silver coin 
4. Jewelry box B, drawer ß: silver coin 
5. Jewelry box C, drawer a: gold coin 
6. Jewelry box C, drawer ß: silver coin 
If when opening a drawer a gold coin is found, there would be three possible 
cases: 1, 2 and 5. Of those cases the only one that favors is case 5. Hence 
P(C) = \. 
At the beginning of the twentieth century and despite being the subject 
of works by famous mathematicians such as Cardano, Fermat, Bernoulli, 
Laplace, Poisson and Gauss, probability theory was not considered in the 
academic field as a mathematical discipline and it was questioned whether it 
was a rather empirical science. In the famous Second International Congress 
of Mathematicians held in Paris in 1900, David Hubert, in his transcendental 
conference of August 8, proposed as part of his sixth problem the axioma-
tization of the calculus of probabilities. In 1901 G. Bohlmann formulated a 
first approach to the axiomatization of probability (Krengel, 2000): he defines 
the probability of an event E as a nonnegative number p(E) for which the 
following hold: 
i) If E is the sure event, then p(E) = 1. 
ii) If Ei and E2 are two events such that they happen simultaneously 
with zero probability, then the probability of either E\ or E2 happening 
equals ρ(£Ί) + p(E2). 
By 1907 the Italian Ugo Broggi, under Hubert's direction, wrote his doc-
toral dissertation titled "Die Axiome der Wahrscheinlichkeitsrechnung" (The 
Axioms of the Calculus of Probabilities). The definition of event is presented 
loosely and it is asserted that additivity and σ-additivity are equivalent (the 
proof of this false statement contains so many mistakes that it is to be as-
sumed that Hubert did not read it carefully). However, this work can be 
considered as the predecessor of Kolmogorov's. 
At the International Congress of Mathematicians in Rome in 1908, Bohlmann 
defined the independence of events as it is currently known and showed the 
difference between this and 2 x 2 independence. It is worth noting that a 
precise definition of event was still missing. 

xxii 
INTRODUCTION 
According to Krengel (2000), in 1901 the Swedish mathematician Anders 
Wiman (1865-1959) used the concept of measure in his definition of geometric 
probability. In this regard, Borel in 1905 says: "When one uses the convention: 
the probability of a set is proportional to its length, area or volume, then one 
must be explicit and clarify that this is not a definition of probability but a 
mere convention". 
Thanks to the works of Frechet and Caratheodory, who "liberated" mea-
sure theory from its geometric interpretation, the path to the axiomatization 
of probability as it is currently known was opened. In the famed book Grund-
begriffe der Wahrscheinlichkeitsrechnung (Foundations of the Theory of Proba-
bility), first published in 1933, the Russian mathematician Andrei Nikolaevich 
Kolmogorov (1903-1987) axiomatized the theory of probability by making use 
of measure theory, achieving rigorous definitions of concepts such as proba-
bility space, event, random variable, independence of events, and conditional 
probability, among others. While Kolmogorov's work established explicitly 
the axioms and definitions of probability calculus, it furthermore laid the 
ground for the theory of stochastic processes, in particular, major contribu-
tions to the development of Markov and ramification processes were made. 
One of the most important results presented by Kolmogorov is the consis-
tency theorem, which is fundamental to guarantee the existence of stochastic 
processes as random elements of finite-dimensional spaces. 
Probability theory is attractive not only for being a complex mathematical 
theory but also for its multiple applications to other fields of scientific interest. 
The wide spectrum of applications of probability ranges from physics, chem-
istry, genetics and ecology to communications, demographics and finance, 
among others. It is worth mentioning that Danish mathematician, statisti-
cian and engineer Agner Krarup Erlang (1878-1929) for his contribution to 
queueing theory. 
At the beginning of the twentieth century, one of the most important scien-
tific problems was the understanding of Brownian motion, named so after the 
English botanist Robert Brown (1773-1858), who observed that pollen parti-
cles suspended in a liquid, move in a constant and irregular fashion. Brown 
initially thought that the movement was due to the organic nature of pollen, 
but later on he would refute this after verifying with a simple experiment that 
the same behavior was observed with inorganic substances. 
Since the work done by Brown and up to the end of the nineteenth century 
there is no record of other investigations on Brownian motion. In 1905 in his 
article "Über die von der molekularkinetischen Theorie der Warme gefordete 
Bewegung von in ruhenden Flüssigkeiten suspendierten Teilchen" (On the 
movement of small particles suspended in a stationary liquid demanded by 
the molecular-kinetic theory of heat; (see Kahane, 1997) German theoretical 
physicist Albert Einstein (1879-1955) published the main characteristics of 
Brownian motion. He proved that the movement of the particle at instant t 
can be modeled by means of a normal distribution and concluded that this 
motion is a consequence of continuous collisions between the particle and the 

INTRODUCTION 
XXÜi 
molecules of the liquid in which it is suspended. It is worth pointing out, 
however, that Einstein himself said he did not know Brown's works (Nelson, 
1967). The first mathematical research regarding Brownian motion was car-
ried out by French mathematician Louis Bachelier (1870-1946), whose 1900 
doctoral dissertation "Theorie de la speculation" (Speculation theory) sug-
gested the Brownian motion as a model associated with speculative prices. 
One of the imperfections of such a model laid in the fact that it allowed prices 
to take negative values and therefore was forgotten for a long time. In 1960 
the economist Samuelson (who received the Nobel Prize in Economics in 1970) 
suggested the exponential of the Brownian motion to model the behavior of 
prices subject to speculation. 
The mathematical structure of Brownian motion, as it is known today, 
is due to the famed North American mathematician Norbert Wiener (1894-
1964). For this reason Brownian motion is also called the Wiener process. 
The first articles about Brownian motion by Wiener are rather hard to follow 
and only the French mathematician Paul Levy (1886-1971) was able to rec-
ognize its importance. Paul Levy notably contributed to the development of 
probability by introducing the concept of the martingale, the Levy processes 
among which we find the Brownian motion and the Poisson processes and the 
theorem of continuity of characteristic functions. Furthermore, Levy deduced 
many of the most important properties of Brownian motion. It is said (see 
Gorostiza, 2001) that many times it has happened that major discoveries in 
probability theory believed to be new were actually somehow contained in 
Levy's works. 
During the 1970s, the Black-Scholes and Merton formula, which allows the 
pricing of put and call options for the European market, was written. For this 
work Scholes and Merton were awarded the 1997 Nobel Prize in Economics 
(Black's death in 1995 rendered him ineligible). Nevertheless, the research 
carried out by Black-Scholes and Merton would have been impossible without 
the previous works done by the Japanese mathematician Kiyoshi Ito (1915-
2008), who in 1940 and 1946 published a series of articles introducing two of 
the most essential notions of modern probability theory: stochastic integrals 
and stochastic differential equations. These concepts have become an influ-
ential tool in many mathematical fields, e.g., the theory of partial differential 
equations, as well as in applications that go beyond financial mathematics 
and include theoretical physics, biology, and engineering, among others (see 
Korn and Korn, 2000). 

CHAPTER 1 
BASIC CONCEPTS 
During the early development of probability theory, the evolution was based 
more on intuition rather than mathematical axioms. The axiomatic basis 
for probability theory was provided by A. N. Kolmogorov in 1933 and his 
approach conserved the theoretical ideas of all other approaches. This chapter 
is based on the axiomatic approach and starts with this notion. 
1.1 
PROBABILITY SPACE 
In this section we develop the notion of probability measure and present its 
basic properties. 
When an ordinary die is rolled once, the outcome cannot be accurately pre-
dicted; we know, however, that the set of all possible outcomes is {1,2,3,4,5,6}. 
An experiment like this is called a random experiment. 
Definition 1.1 (Random Experiment) An experiment is said to be ran-
dom if its result cannot be determined beforehand. 
It is assumed that the set of possible results of a random experiment is 
known. This set is called a sample space. 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
1 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley &; Sons, Inc. 

2 
BASIC CONCEPTS 
Definition 1.2 (Sample Space) The set Ω of all possible results of a ran-
dom experiment is called a sample space. An element ω G Ω is called an 
outcome or a sample point. 
■ EXAMPLE 1.1 
Experiment: Flipping a fair coin. The possible results in this case are 
"head" =if and "tail"=T. That is, Ω = {H,T}. 
▲ 
■ EXAMPLE 1.2 
Experiment: Rolling an ordinary die three consecutive times. In this 
case the possible results are triplets of the form (a, b, c) with a,b,c G 
{1,2,3,4,5,6}. That is: 
Ω = {(a,b,c):a,b,c€ 
{1,2,3,4,5,6}}. 
A 
■ EXAMPLE 1.3 
Experiment: Items coming off a production line are marked defective 
(D) or nondefective (N). Items are observed and their condition noted. 
This is continued until two consecutive defectives are produced or four 
items have been checked, which ever occurs first. In this case: 
Ω = {DD, NDD, NDND, NNDD, NNDN, 
NNNN, 
NNND, 
NDNN, DNNN, DNDN, DNND, DNDD}. 
▲ 
■ EXAMPLE 1.4 
Experiment: Observe the number of ongoing calls in a particular tele-
phone exchange switch. In this case Ω = {0,1,2, · · · }. 
▲ 
We notice that the elements of a sample space can be numbers, vectors, sym-
bols, etc. and they are determined by the experiment being considered. 
Definition 1.3 (Discrete Sample Space) A sample space Ω is called dis-
crete if it is either finite or countable. A random experiment is called finite 
(discrete) if its sample space is finite (discrete). 
Going back to Example 1.2, a question that arises naturally is: what's the 
"chance" of a given "event" such as "the sum of the results obtained is greater 

PROBABILITY SPACE 
3 
than or equal to 2"? In other words, what is the "chance" of 
A := {(a, b, c) e Ω : a + b + c > 2} 
happening? 
Now, what is an event? Following the aforementioned idea, we can expect 
an event merely to be a subset of the sample space, but in this case, can we 
say that all subsets of the sample space are events? The answer is no. The 
class of subsets of the sample space for which the "chance" of happening is 
defined must have a σ-algebra structure, a concept we will further explain: 
Definition 1.4 (σ-Algebra) Let Ω φ 0. A collection 9 of subsets of Ω is 
called a σ-algebra (or a σ-field) over Ω: 
(i) / / f i e S . 
(ii) IfAeS, 
thenAc€<3. 
oo 
(Hi) IfAi,A2,---£%, 
then \J At € 3. 
i=l 
The elements o / 9 are called events. 
■ EXAMPLE 1.5 
Consider Example 1.1. Ω = {H,T}. 
Then T = {0,Ω} is a trivial 
σ-algebra over Ω, whereas Q = {0, {H}} is not a σ-algebra over Ω. 
A 
■ EXAMPLE 1.6 
Consider a random experiment of flipping two fair coins. 
Ω = {HH, HT, TH, TT}. Then J" = {0, {HH, HT}, {TH, TT}, Ω} is a 
σ-algebra over Ω. 
▲ 
■ EXAMPLE 1.7 
Consider Example 1.2. Ω = {(a,b,c) : a,b,c e {1,2,3,4,5,6}}. Then 
J"= {0,{(1,2,3)},Ω\{(1,2,3)},Ω} is a σ-algebra over Ω whereas 
Q = {(1,2,3), (1,1,1)} is not a σ-algebra over Ω. 
A 

4 
BASIC CONCEPTS 
■ EXAMPLE 1.8 
Let Ω φ 0. Then 9f0 = {0, Ω} and ρ(Ω) := {A: ACfl} 
are σ-algebras 
over Ω. 9o is called the trivial σ-algebra over Ω while ρ(Ω) is known as 
the total σ-algebra over Ω . 
A 
■ EXAMPLE 1.9 
Let Ω = {1,2,3}. Then 3 = {0, {1}, {2,3}, Ω} is a σ-algebra over Ω but 
the collection Q = {0, {1}, {2}, {3}, Ω} is not a σ-algebra over Ω. 
A 
■ EXAMPLE 1.10 
Let Ω φ 0 be finite or countable, and let 3 be a σ-algebra over Ω 
containing all subsets of the form {ω} with ω G Ω. Then 9 = ρ(Ω). 
A 
oo 
Theorem 1.1 // Ω φ 0 and Qfi, 3?2i ■ · · are σ-algebras over Ω, then f\ 3j is 
t = l 
abo a σ-algebra over Ω. 
Proof: Since Ω G 3^ for every j , this implies that Ω G p|j % . Let A G |~| · %, 
then A G 3fj for all j , this means that Ac € Sj for all j . Hence Ac G f~L 3 j . 
Finally, let Αχ, Α2, · · · G Π? ^j· Then Ai 6 Qj-, for all i and j , hence 
U< Λ G 9j for all j . Thus we conclude that U ^ i M G f|j ^ j - 
■ 
Note that, in general, the union of σ-algebras over Ω is not a σ-algebra 
ονβΓΩ. For example, Ω = {1,2,3}, ^ = {0,Ω,{1}, {2,3}} and 
$2 = {0, Ω, {1,2}, {3}}. Clearly 3i and S 2 are σ-algebras over Ω, but 3i U3 2 
is not a cr-algebra over Ω. 
Definition 1.5 (Generated σ-Algebra) Let Ω φ 0 and let Abe a collec-
tion of subsets of Ω. Let M. = {9 : 3; is a σ-algebra over Ω containing A}. 
Then, the preceding example implies that σ(Α) := 
Γ) 3? is the smallest σ-
36Λ1 
algebra over Ω containing A. σ{Α) is called the σ-algebra generated by A. 
■ EXAMPLE 1.11 
Borel σ-Algebra 
The smallest σ-algebra over R containing all intervals of the form (—00, a] 
with a G R is called the Borel σ-algebra and is usually written as B. If 
A G B, then A is called a Borel subset of R. Since B is a σ-algebra, if 

PROBABILITY SPACE 
5 
we take a, b € R with a <b, then the following are Borel subsets of R: 
(a,oo) = R \ (—00,a] 
(a, b] = (—00, b] (Ί (a, oo) 
°° ( 
1 
(—00, a) = I I I - 0 0 , a 
1 V 
n 
n=l 
x 
[a,00) = R \ (—00,a) 
(a,b) = 
[a,b} = 
{*} = 
N = 
Q = 
= (-00, b) n 
= R \ ( ( - o o , 
= [a, a] 
OO 
n=0 
■ u 
m, n € Z 
(a, 00) 
a) U (6, 
{=} 
»)) 
Qc = R \ Q. 
▲ 
Can we say, then, that all subsets of R are Borel subsets? The answer to this 
question is no; see Royden (1968) for an example on this regard. 
■ EXAMPLE 1.12 
Borel σ-Algebra over Rn 
Let a = (ai, ■ ■ ■ , an) and b = (&i, · · · , bn) be elements of Rn with a< b, 
that is, Oj < bi for all i — 1,··· ,n. The σ-algebra, denoted by Bn, 
generated by all intervals of the form 
(a,b] := {x = (xi,··· ,x„) e Rn : Oj < Xi < b,,i — 1,·· · ,n} 
is called the Borel σ-algebra over Rn. 
▲ 
Definition 1.6 (Measurable Space) Let Ω φ 0 and let 3 be a σ-algebra 
overil. 
The couple (Ω,Ο) is called a measurable space. 
It is clear from the definition that both Ω and 0 belong to any σ-algebra 
defined over Ω. 0 is called the impossible event, Ω is called the sure event. 
An event of the form {ω} with ω € Ω is called a simple event. 
We say that the event A happens if after carrying out the random experi-
ment we obtain an outcome in A, that is, .A happens if the result is a certain 
ω with ω € A. Therefore, if A and B are two events, then: 
(i) The event AUfl happens if and only if either A or B or both happen. 

6 
BASIC CONCEPTS 
(ii) The event An B happens if and only if both A and B happen. 
(iii) The event Ac happens if and only if A doesn't happen. 
(iv) The event A \ B happens if and only if A happens but B doesn't. 
■ EXAMPLE 1.13 
If in Example 1.2 we consider the events: A ="the result of the first toss 
is a prime number" and B = "the sum of all results is less than or equal 
to 4". Then 
AllB 
= {(a,b,c) e Ω : a e {2,3,5} or (a + 6 + c) < 4}, 
so (2,1,1), (5,3,4), (1,1,1) are all elements of A U B. In addition: 
AnB 
= {{a,b,c) : a e {2,3,5} and (a + b + c) < 4} = {(2,1,1)}. 
The reader is advised to see what the events A \ B and Ac are equal to. 
Definition 1.7 (Mutually Exclusive Events) Two events A and B 
are said to be mutually exclusive if ΑΠΒ 
= 0. 
■ EXAMPLE 1.14 
A coin is flipped once. Let A ="the result obtained is a head" and 
B ="the result obtained is a tail". Clearly the events A and B are 
mutually exclusive. 
A 
■ EXAMPLE 1.15 
A coin is flipped as many times as needed to obtain a head for the first 
time, and the number of tosses required is being counted. If 
A := "no heads that are obtained before the third toss" = {3,4,5, · · · } and 
B := "no heads that are obtained before the second toss" = {2,3,4, · · ■ } 
then A and B are not mutually exclusive. 
A 
Our goal now is to assign to each event A a nonnegative real number indicating 
its "chance" of happening. Suppose that a random experiment is carried out 
n times keeping its conditions stable throughout the different repetitions. 
Definition 1.8 (Relative Frequency) For each event A, the number 
fr(A) := ^ ^ is called the relative frequency of A, where n (A) indicates the 
number of times the event A happened in the n repetitions of the experiment. 

PROBABILITY SPACE 
7 
EXAMPLE 1.16 
Suppose a coin is flipped 100 times and 60 of the tosses produced a 
"head" as a result; then the relative frequencies of the events A :="the 
result is head" and B :="the result is tail" are respectively | and \. 
EXAMPLE 1.17 
A fair die is rolled 500 times and in 83 of those tosses the number 3 was 
obtained. In this case the relative frequency of the event 
A := "the result obtained is 3" 
equals ^ . 
Unfortunately for each fixed A , fr(A) is not constant: its value depends on 
n; it has been observed, however, that when a random experiment is repeated 
under almost the same conditions for a large number of times, the relative 
frequency fr(A) stabilizes around a specific value between 0 and 1. 
■ EXAMPLE 1.18 
Suppose a die is tossed n times and let: 
A := "the result obtained is 3". 
The following table summarizes the values obtained: 
1 n 
| loo 
| 200 
| 300 
| 400 
| 500 
| frequency 
1 
14 
| 
29 
1 
51 
| 
65 
| 
83 
relative frequency | 
0.14 
| 
0.145 
| 
0.17 
| 
0.1625 
| 
0.166 
| 
The stabilization of the relative frequency is known as "statistic regularity" 
and this is what allows us to make predictions that eliminate, though partially, 
the uncertainty present in unforeseeable phenomena. 
The value P(A) around which the relative frequency of an event stabilizes 
indicates its "chance" of happening. We are interested now in describing 
the properties that such a number should have. First, we observe that since 
n(A) > 0 then P(A) must be greater than or equal to zero, and because 

8 
BASIC CONCEPTS 
η(Ω) = n, / Γ ( Ω ) = 1 and therefore Ρ(Ω) = 1. Furthermore, if A and B 
are mutually exclusive events, then n(A U ß ) = n(A) + n(B) and therefore 
fr(ALiB) 
= fr(A) + fr(B), 
which in turn implies that whenever A n B = 0 
then P(A U B) = P(A) + P(B). 
These considerations lead us to state the 
following definition: 
Definition 1.9 (Probability Space) Let (Ω,3ί) be a measurable space. A 
real-valued function P defined over 3 satisfying the conditions 
(i) P(A) > 0 for all A € S (nonnegative property) 
(ii) Ρ(Ω) = 1 (normed property) 
(iii) if Αι,Αζ,··· 
are mutually exclusive events in 9, that is, 
Ai C\Aj = 0 for all i φ j , 
then 
(
oo 
\ 
oo 
\JAi 
I = 2jP(v4j) 
(countable additivity) 
i=l 
) 
i=l 
is called a probability measure over (Ω, 3). The triplet (Ω, 9, P) is called a 
probability space. 
■ EXAMPLE 1.19 
Consider Example 1.9. Let Ω = {1,2,3}, 9 = {0, {1}, {2,3},Ω} and P 
be the following map over S for any i g 3 : 
"M-U « 
3 6 , 4 
It is easy to verify that P is indeed a probability measure over (Ω, S). 
A 
EXAMPLE 1.20 
Consider Example 1.4. Let Ω = {0,1, ■ · · }, 3? = ρ(Ω) and P be defined 
on {i}: 
P({i}) = (1 - <?)<?% i = 0 , l , · · · , 
0 < 9 < l . 
Since all three properties of Definition 1.9 are satisfied, P is a probability 
measure over (Ω, 9). 
▲ 

PROBABILITY SPACE 
9 
1 
3 
2 
3 
1 
iiA = {l} 
i£A = {2} 
if A = {1,2}. 
EXAMPLE 1.21 
Let Ω = {1,2}, 3? = ρ(Ω) and let P be the map over 3 defined by: 
0 
if Λ = 0 
P(A) 
P is a probability measure. 
A 
Next we establish the most important properties of a probability measure P. 
Theorem 1.2 Let (Ω,3, Ρ) be a probability space. Then: 
1. P(0) = 0. 
2. IfA,B£%andAnB 
= <l), then P(AU B) = P(A) + P(B). 
3. For any AeQ, 
P(AC) = 1 - 
P(A). 
4. If A C B, then P{A) < P(B) 
and P(B \ A) = P{B) - P(A). 
In 
particular P(A) < 1 for all A € 3°. 
5. For any A,B€%, 
P(A U B) = P{A) + P(B) - P(A Π B). 
6. Let {An)n be an increasing sequence of elements in 9, that is, An € 3i 
and An C An+\ for alln= 
1,2,···; then 
P( lim An) = lim P{An) 
where lim An := \J An. 
n=\ 
7. Let {An)n 
be a decreasing sequence of elements in 3 , that is, An G Ö 
and An D An+\ for all n = 1,2, · · ·; then 
P{ lim An) = lim 
P(An) 
where lim An := f] An. 
n^°° 
n=l 
Proof: 
1. 1 = Ρ(Ω) = Ρ(Ω U 0 U 0 U · · ·) = Ρ(Ω) + P(0) + P(0) + · · ·. Then 
0 > P(0) > 0 and therefore P(0) = 0. 
2. Α υ Β = Λ υ Ρ υ 0 υ 0 υ · · · . Thus, the proof follows from property iii 
from the definition of probability measure and the previous result. 

10 
BASIC CONCEPTS 
3. P{A) + P{AC) = P(A U Ac) = Ρ(Ω) = 1. 
4. B = A U (B \ A). We obtain P{B) = P(A) + P(B \A)> P{A) by 
applying 2. 
5. As an exercise for the reader. 
6. Let C\ = A\, C2 = Ai \ A\, · ■■ ,C„ = An \ An-i. It is clear that: 
00 
00 
\JCn= \jAn. 
n=l 
n = l 
Furthermore, since C, Π Cj = 0 for all i φ j , it follows from property iii 
of probability measures that: 
i>(u^Vp(u^) 
00 
n = l 
n 
= lim V>(C f c) 
\ n = l 
/ 
\ n = l 
00 
n—too* 
limPlMCfc 
i-yoo 
\ v - ' 
U=l 
/ 
lim P(A n) . 
7. Left as an exercise for the reader. 
Note 1.1 Let A,B and C be events. Applying the previous theorem: 
P(A U B U C) = P{A) + P(B U C) - P(A il(BU C)) 
= P(A) + Piß) + P(C) - P{B Π C) - P(A Π B) 
-p(AnC) 
+ 
P(AnBnC). 
An inductive argument can be used to see that if Ai,Ä2,- ■ ■ ,An are events, 
then 
P(Ai u A2 U · ■ · U An) 
n 
= Σρ(Α*) - Σ p(^i n A**) + ■■■ + (- χ) Γ + 1 
Σ 
p ( ^ i n Ai, n ■ · · n A^.) 
»=1 
*1<»2 
t i < t 2 < - < t r 
+ · · · + (-ΐ)η+1ρμι n ,42 n · · · n An) 

PROBABILITY SPACE 
1 1 
where the sum 
Σ P(4n4n-n4) 
t i < i a < - " < t r 
is taken over all possible subsets of size r of the set {1,2,· ■■ ,n}. 
Note 1.2 Let (Ω,3;, P) be a probability space with finite or countable Ω and 
9 = ρ(Ω). Let 0 φ A e $. It is clear that 
A= (JM 
u>eA 
and therefore 
P(A) = £Ρ(ω) 
ω£Α 
where P(ui) := Ρ({ω}). ΤΤιαί is, P is completely determined by pj := P(i*)j), 
where ω^ with j = 1,2, · ■ · denote the different elements of Ω. 
Clearly, the |Ω|-dimensional vector p := (pi,P2> · · ·) (where |Ω| is ίΛε n«m-
ber of elements of il) satisfies the following conditions: 
(i) Pj > 0. 
oo 
(ii) Y,pj = 1 . 
i=i 
A vector p satisfying the above conditions is called a probability vector. 
Note 1.3 Let Ω = {ω\,u)2, ■ ■ ■ } be a (nonempty) finite or countable set, p(Ω) 
the total σ-algebra over Ω andp a |Ω|-dimensional probability vector. It is easy 
to verify that the mapping P defined over ρ(Ω) by 
P(0) = 0 
P{uj)=Pj 
, 3 = 1,2,· ■· 
P{A)= Y^Pj 
forQ^ACQ 
{j : ωα€Α} 
is a probability measure. The probability space (Ω, ρ(Ω),Ρ) obtained in this 
fashion is called a discrete probability space. 
■ EXAMPLE 1.22 
Let (Ω, 9, P) be a probability space with: 
Ω = {1,2,3,4} 
9 = {0, Ω, {1}, {2,3}, {4}, {1,2,3}, {2,3,4}, {1,4}} 
Λ{1}) = ^ 
P({2,3}) = i , 
P({4}) = i . 

1 2 
BASIC CONCEPTS 
Then: 
P({1,2,3}) = | 
^({2,3,4}) = 1 
P({l,4}) = i . 
A 
■ EXAMPLE 1.23 
Let (Ω, ρ(Ω),Ρ) be a discrete probability space with Ω — {a,b,c} and 
P given by the probability vector p = (j, | , | ) . Then: 
P({a,6}) = ^, 
P({6,C}) = ^, 
P ( { a , c } ) = * . 
A 
■ EXAMPLE 1.24 
Let (Ω, 3, P) be a probability space. If A and B are events such that 
P{A) = p, P(B) = g and P{A U B) = r, then: 
P ( A n ß ) =p + 
q-r 
P(A\B) 
= 
r-q 
P(AC tlBc) = l - r 
P(A U Bc) = p - r + 1 . 
▲ 
■ EXAMPLE 1.25 
Consider three wireless service providers Vodafone, Aircel, and Reliance 
mobile in Delhi. For a randomly chosen location in this city, the proba-
bility of coverage for the Vodafone (V), Aircel(A), and Reliance mobile 
(Pc) are P{V) = 0.52, P{A) = 0.51, P(R) = 0.36, respectively. We also 
know that P(V UA)= 0.84, P(A UR) = 0.76 and P(A Π R Π V) = 0.02. 
What is the probability of not having coverage from Reliance mobile? 
Aircel claims it has better coverage than Vodafone. Can you verify this? 
If you own two cell phones, one from Vodafone and one from Aircel, 
what is your worst case coverage? 

PROBABILITY SPACE 
13 
Solution: Given: 
P{V) 
P(A) 
P(R) 
P(V U A) 
P{A U R) 
P(AilRnV) 
= 
0.52 
= 
0.51 
= 
0.36 
= 
0.84 
= 
0.84 
= 
0.02. 
Using the above information, the probability of not having coverage from 
Reliance mobile is: 
P(R) = 1 - P(R) = 1 - 0.36 = 0.64. 
Aircel's claim is incorrect as P{A) < P(V). The worst case coverage is: 
P(Är\V) 
= 
l-P(AöV) 
= 
1 - 0.84 
= 
0.16. 
▲ 
■ EXAMPLE 1.26 
Let (Ω, Qi, P) be a probability space, and let A and B be elements of 3 
with P{A) = \ and P(B) = \. Then 
l-<P{AnB)<\ 
since P{A i l ß ) < P(A) = | and P(A U B) < 1 . 
A 
■ EXAMPLE 1.27 
A biased die is tossed once. Suppose that: 
j | l | 2 | 3 | 4 | 5 | 6 
Pi 
1 
32 
5 
32 
7 
32 
3 
32 
8 
32 
8 
32 
Then, the probability of obtaining a number not divisible by 3 and whose 
square is smaller than 20 equals ^ , while the probability of getting a 
number i such that \i — 5| < 3 equals | | . 
A 

14 
BASIC CONCEPTS 
1.2 
LAPLACE PROBABILITY SPACE 
Among random experiments, the easiest to analyze are those with a finite 
number of possible results with each of them having the same likelihood. 
These experiments are called Laplace experiments. The tossing of a fair coin or 
a fair die a finite number of times is a classic example of Laplace experiments. 
Definition 1.10 (Laplace Probability Space) A probability space 
(Ω, 3f, P) with finite Ω, 9 = ρ(Ω) and Ρ(ω) = TL· for all ω € Ω is called a 
Laplace probability space. The probability measure P is called the uniform or 
classic distribution on Ω. 
Note 1.4 // (Ω, 3f, P) is a Laplace probability space and A C Ω, then: 
J_=\A\ 
|Ω| 
|Ω|' 
™«ρ(υω] = Σϊέί = |Λ| 
In other words: 
"number of cases favorable to A " 
P(A) 
"number of possible cases" 
This last expression is in no way a definition of probability, but only a conse-
quence of assuming every outcome of the experiment to be equally likely and 
a finite number of possible results. 
Thereby, in a Laplace probability space we have that probability calculus 
is reduced to counting the elements of a finite set, that is, we arrive to a 
combinatorial analysis problem. For readers not familiarized with this topic, 
Appendix B covers the basic concepts and results of this theory. 
EXAMPLE 1.28 
In a certain lottery six numbers are chosen from 1 to 49. The probability 
that the numbers chosen are 1,2,3,4,5 and 6 equals: 
- s ^ = 7.1511 x 1(T8. 
(4
6
9) 
Observe that this is the same probability that the numbers 4,23,24,35,40 
and 45 have been chosen. 
The probability p of 44 being one of the numbers chosen equals: 
lU= 
0-12245. 

LAPLACE PROBABILITY SPACE 
1 5 
EXAMPLE 1.29 
There are five couples sitting randomly at a round table. The probability 
p of two particular members of a couple sitting together equals: 
2!8! 
2 
EXAMPLE 1.30 
In an electronics repair shop there are 10 TVs to be repaired, 3 of which 
are from brand A, 3 from brand B and 4 from brand C. The order in 
which the TVs are repaired is random. The probability p\ that a TV 
from brand A will be the first one to be repaired equals: 
3 9! 
nn 
Ρ1 = ΊΟΓ=0·3· 
The probability pi that all three TVs from the brand A will be repaired 
first equals: 
_ 3-2-7! _ J _ 
^ 2 - 
10! 
~ Ϊ20' 
The probability pz that the TVs will be repaired in the order 
C ABC ABC ABC equals: 
_ 4 · 33 · 23 _ 
1 
P 3 _ 
10! 
~ 4200' 
A 
EXAMPLE 1.31 
In a bridge game, the whole pack of 52 cards is dealt out to four players. 
We wish to find the probability that a player receives all 13 spades. 
In this case, the total number of ways in which the pack can be dealt 
out is 
52 
,13,13,13,13, 
and the total number of ways to divide the pack while giving a single 
player all spades equals: 
^13> 
,13, 
Therefore, the probability p we look for is given by: 
4 
,9 
— - = fi 9QQ1 v If» - 1 2 
o 
=(X)(X 
(O(X)G 
p = —^- = 6.2991 x 10" 

16 
BASIC CONCEPTS 
■ EXAMPLE 1.32 
Suppose that all 365 days of the year are equally likely to be the day 
a person celebrates his or her birthday (we are ignoring leap years and 
the fact that birth rates aren't uniform throughout the year). The prob-
ability p that, in a group of 50 people, no two of them have the same 
birthday is: 
_ 365 x 364 x · · · x (365 - 5 0 + 1) 
P ~ 
36550 
= (1-äb)(1-4)-(1-^)· A 
■ EXAMPLE 1.33 
Urn Models 
An urn has N balls of the same type, R of them are red color and N — R 
are white color, n balls are randomly drawn from the urn. We wish 
to find the probability that exactly k < n of the balls drawn are red in 
color. 
To simplify the argument, it will be assumed that the balls are num-
bered from 1 to N in such a way that the red balls are all numbered 
from 1 to R. We distinguish between two important cases: draw without 
replacement and draw with replacement. In the first case we must also 
consider two more alternatives: the balls are drawn one by one and the 
balls are drawn at the same time. 
1. Draw without replacement (one by one): The n balls are extracted one 
by one from the urn and left outside of it. In this case the sample space 
is given by: 
Ω = {(αι,α 2,··· ,αη) : α, € {1,2, ·■■ ,N},a,i φ αά 
for a l l i ^ j , j = 1,2,··· ,η}. 
Let: 
Ak := "exactly k < n of the balls drawn are red". 
Clearly Ak is made of all the n-tuples from Ω with exactly k 
components less than or equal to R. Therefore 
|Ω| = N x (N - 1) x · · · x (JV - (n - 1)) =: (N)n 

LAPLACE PROBABILITY SPACE 
1 7 
and 
\Ak\= 
( " j Ä x {R-l) 
x ■·■ x (R- 
k + 1) x (N - R)x 
■■■x{N-R-n 
+ k + l) 
= (fy(R)kx(N-R\n_k). 
Then: 
τ>( A \ — l^fcl _ 
\k)\n-k) 
p{Ak) - w ~~o~-
2. Draw without replacement (at the same time): In this case the sample 
space is: 
Ω = {T : T C {1,2, · · · , N} with \T\ = n}. 
Here Ak consists of all the elements of Ω having exactly k elements less 
than or equal to R. Therefore: 
»i-CO - MX-"** 
Thus: 
PiΔ 
\ _ l^fcl _ 
(fc)(n-fc) 
p{Ak) - mi - 
a 
· 
As it can be seen, when the balls are drawn without replacement, it 
is irrelevant for the calculus of the probability whether the balls were 
extracted one by one or all at the same time. 
3. Draw with replacement: In this case, each extracted ball is returned to 
the urn, and after mixing the balls, a new one is randomly drawn. The 
sample space is then given by: 
Ω = {(α 1,α 2,··· ,αη):αό 
e { l , 2 , · · · ,N}, j = l,2,··· 
,N}. 
The event Ak consists of all n-tuples from Ω with k components less 
than or equal to R. Then, 
M -(;)*( 
|Ω|=ΛΓη 
and 
\Ak\ = [ 
)Rk(N - R) \n—k 
and accordingly: 
|i4fc| _ 
W ~ \kjr " 
*~ N 
P(Ak) = ^Γ= 
(fc)p^ n _ f c 
w h e r e P = ΊΓτ 
a n d 
9 = 1 - P· 

18 
BASIC CONCEPTS 
EXAMPLE 1.34 
A rectangular box contains 4 Toblerones, 8 Cadburys and 5 Perks choco-
lates. A sample of size 6 is selected at random without replacement. 
Find the probability that the sample contains 2 Toblerones, 3 Cadbury 
and 1 Perk chocolates. 
Solution: |Ω| = (^7) where Ω is the set of possible outcomes. \E\ = 
(2) (3) (1) w n e r e E is the event of interest: 
G)®(?) 
P\E\ 
(Ϊ) 
If in the above problem the sample is to be drawn with replacement, 
then the required probability is: 
( 4 + 2 - 1 ) ! 
( 8 + 3 - 1 ) ! 
( 5 + 1 - 1 ) ! 
5! v 
10! v 
5! 
2! 
* 
3! 
1! 
2! * 
3! * 1! 
A 
(17+6-1)! 
22! 
6! 
6! 
EXAMPLE 1.35 
(Hoel et al., 1971) Suppose that n balls are distributed in n urns in such 
a way that all the nn possible arrangements are equally likely. Find the 
probability that only the first urn is empty. 
Solution: Let A be the event of having only the first urn empty. This 
event happens only if the n balls are distributed in the n — 1 remaining 
urns in such a way that none of them are empty. That means one of 
those n — 1 urns must contain exactly two balls while the other n — 2 
must have one ball each. For j = 2, · · · , n, let Bj be the event of having 
two balls in the urn j and exactly one ball in each of the other n — 2 urns. 
Clearly the events Bj are mutually exclusive and their union yields the 
event A. To calculate P(Bj), 
we observe that the two balls placed in 
the urn j can be chosen in (!J) ways and the remaining n — 2 balls can 
be distributed in the remaining urns in (n — 2)! ways. Then, 
and therefore: 
Ρ(Β,, = β % ^ 1 
P(A) = 
J£P(BJ) 
j=2 
= ( η - 1 ) β ) ( η - 2 ) ! 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
1 9 
EXAMPLE 1.36 
A wooden cube with painted faces is sawed up into 1000 little cubes all 
of the same size. The little cubes are then mixed up, and one is chosen 
at random. Find the probability that the selected cube has only two 
painted faces. 
Solution: The probability that the selected cube has only two painted 
faces is: 
12 x 8 
96 
= 
= 0.096. 
A 
1000 
1000 
1.3 
CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
Many times, partial information about a random experiment can be obtained 
before its actual result is known. Resting upon this information, it is com-
mon to change the random experiment result's probabilistic structure. For 
example, a poker player can at some point peek at a rival's cards. Suppose he 
only managed to see that all cards had a red suit, that is, hearts or diamonds. 
Then our player knows his partner can't have all four kings, an event that 
previously had a positive probability. On the other hand, he suspects that the 
event "having all cards of the same suit" is more likely than before getting 
the extra information. 
Following, we are going to analyze the situation from the relative frequen-
cies perspective. Let B be an event whose chance of happening must be 
measured under the assumption that another event A has been observed. If 
the experiment is then repeated n times under the same circumstances, then 
the relative frequency of B under the condition A is defined as 
rf(B\A):=^li{n{A)>0 
where n(A Π B) indicates the number of favorable cases to A ΓΊ B. 
It is clear that rf(B \ A) depends on n. However, when the experiment is 
performed for a large enough number of times, the relative frequencies tend 
to stabilize around a specific value between 0 and 1, known as the conditional 
probability of the event B under the condition A. 
We observe that: 
r^B^^ 
= ^ 
= JVf{A) 
if ^ ) > 0 · 
n 
For large enough n, the numerator from the former expression tends to 
P(AnB) 
while the denominator tends to P{A). This motivates the following 
definition: 

20 
BASIC CONCEPTS 
Definition 1.11 (Conditional Probability) Let (Ω,3, P) be a probability 
space. If A,B e 3 with P(A) > 0, then the probability of the event B under 
the condition A is defined as follows: 
P(B | A) - 
-ρζχγ-
EXAMPLE 1.37 
Two fair dice are rolled once. The probability that at least one of the 
results is 6 given that the results obtained are different equals | , as the 
following reasoning shows: Let A be the event "the results are different" 
and B the event "At least one of the results is 6". It is clear that: 
A = {(a, b) : a, b € {1,2, · · · , 6}, a φ 6} 
and 
B = { ( o > 6 ) : o e { l , 2 , . · · ,6}} U {(6,6) : b € {1,2,· · ■ ,6}}. 
Then: 
Γ(Β\Λ) 
P{AnB) 
« 
1 
A 
P{B\A)- 
p{A) 
- g j - 3 · 
* 
EXAMPLE 1.38 
An urn contains 12 balls, 8 of which are white color. A sample of size 
4 is taken without replacement. Then, the probability that the first 
and third balls extracted are white given that our sample contains three 
white balls equals | . To this effect, let's assume the balls are numbered 
from 1 to 12; then: 
Ω — {(01,02,03,04) : Oj G {1,2, ...,12}, α» φ a,· for all i ψ j}. 
Let: 
A :— "Exactly three of the balls extracted are white". 
B := "The first and the third balls removed are white". 
It is straightforward that: 
P(„ I Λλ = Ρ{ΑΠΒΪ 
= " ^ Γ 1
 = Π(ΛΠΒ) 
_ Q8.6.7.4 
1 
ry° 
I Ai 
P{A) 
^ 
n{A) 
(4)4.8.7.6 
2 · 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
2 1 
EXAMPLE 1.39 
Let (Ω, 3, P) be a probability space with 
Ω = {a, b, c, d, e, / } , 3 = ρ(Ω) 
and 
\a 
\b 
\c 
\d 
\e 
\ f 
Ρ(ω) 
1 
16 
1 
16 
1 
8 
3 
16 
1 
4 
5 
16 
Let A = {a, c, e}, B = {c, d, e, / } and C = {b, c, / } . Then: 
P(A Π {Bc U C)) 
P{A\BCUC) 
= 
P(BC U C) 
P({a,c}) 
P({a,b,c,f}) 
1 
EXAMPLE 1.40 
Consider the nights starting from Bogota to Medellin. In these flights, 
90% leave on time and arrive on time, 6% leave on time and arrive late, 
1% leave late and arrive on time and 3% leave late and arrive late. What 
is the probability that, given a flight leaves late, it will arrive on time? 
solution: Given: 
P(Flight leaves on time and arrives on time) 
= 
0.9 
P(Flight leaves on time and arrives late) 
= 
0.06 
P(Flight leaves late and arrives on time) 
= 
0.01 
P(Flight leaves late and arrives late) 
= 
0.03. 
Now: 
P(Flight leaves late) 
= 
P(Flight leaves late and arrives on time) + 
P(Flight leaves late and arrives late) 
= 
0.01 + 0.03 
= 
0.04. 

22 
BASIC CONCEPTS 
Therefore: 
P(Flight leaves late and arrives on time) 
P(Flight arrives on time | it leaves late) 
= 
P(Flight leaves late) 
0.01 
ÖÖ4 
= 
0.25. 
▲ 
The next theorem provides us with the main properties of conditional proba-
bility: 
Theorem 1.3 (Conditional Probability Measure) Let(il, 9, P) be a prob-
ability space, and let A € 9i with P(A) > 0. Then: 
1. P{ · | A) is a probability measure over Ω centered on A, that is, P(A \ 
A) = l. 
2. IfAnB 
= 9, then P{B 
\A)=0. 
3. P{B Π C | A) = P (B | A n C) P{C | A) if P(A Π C) > 0. 
4. IfA1,A2,--- 
, 4 e 3 with P{AX Π Α2 Π ■ ■ · Π An_i) > 0, then 
p{Ai n A2 n · · ■ n An) = P(A1)P(A2 \ A1)P(A3 
\ Αλ η A2) · · ■ 
p(An\A1nA2n---nAn_1). 
Proof: 
1. The three properties of a probability measure must be verified: 
(i) Clearly P(B \A)>0 
for all B € Of. 
(ii) Ρ(Ω | A) = pffiff> = ^ 
= 1. Therefore, we also have that 
P{A \A) = 1. 
(iii) Let Αχ,Α2,··· 
be a sequence of disjoint elements from 9. Then: 
/» 
x 
p(An(lJA,)) 
\t=l 
pfJj^nA)^ 
1~Ύ(Α) 
oo ΣΡ^ηΑ) 
i=l 
P(A) 
00 
= Σ Ρ ( 4 | Α ) . 
i = l 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
2 3 
2. Left as an exercise for the reader. 
3. 
P(BnC\A) 
P{B n c n A) 
P(A) 
_ P{BncnA) 
P(Cn A) 
P{Cr\A) 
X 
P{A) 
= 
P(B\AnC)P(C\A). 
4. Left as an exercise for the reader. 
EXAMPLE 1.41 
An urn contains 12 balls, 4 of which are black while the remaining 8 are 
white. The following game is played: the first ball is randomly extracted 
and, after taking note of its color, it is then returned to the urn along 
with a new pair of balls of the same color. Find the probability that in 
the first three rounds of the game all the balls drawn are black. 
Solution: For i = 1,2,3 we define: 
Ai := "a black ball was extracted on the ith round of the game". 
Clearly: 
Ρ(Λι Π Α2 Π A3) = P{A3 | A2 Π Al)P{A2 
I Ai)P(i4i) 
- Ä A 
4 
~ Ϊ 6 Χ Ϊ 4 Χ Ϊ 2 
1 
= Ϊ4· 
Α 
EXAMPLE 1.42 
Three teenagers want to get into an R-rated movie. At the box of-
fice, they are asked to produce their IDs; after the clerk checks them 
and denies them the entrance, he returns the IDs randomly. Find the 
probability that none of the teenagers get their own ID. 
Solution: Let: 
A := "None of the teenagers get their own ID". 
Bi := "The ith teenager gets his own ID". 

24 
BASIC CONCEPTS 
Clearly, the probability we look for is: 
P{A) = P(Bi n Bl n B|) 
= 
1 - P(Bi U B2 U P3) 
+P{B2 n B3) + P(ßi n B3) - Pißi n B2 n B3). 
Since there are three possible cases and only one is favorable: 
P(Bi) = ^ for i = 1,2,3. 
On the other hand, for any i φ j , 
P(Bi n Bj) = P(Bi)P{Bj 
| Pi) = i x ^ = | 
seeing that, after giving the ith teenager the right ID, for the jth teenager 
there is only one favorable option from two possible ones. In a similar 
fashion: 
ρ{Βχ n ß 2 n B 3 ) = P(ß!)P(P 21 B I ) P ( B 3 I # i n P 2 ) 
1
1
,
1 
3 
2 
6 
Therefore: 
P(A) = \ . 
A 
The reliability of a device or its separate units is understood as the probability 
of their trouble-free operation without failure. 
■ EXAMPLE 1.43 
Let us consider a system composed of n units. It is assumed that unit 
fails independently of another unit. A series system is one in which all 
units must operate successfully. On the other had, a parallel system is 
one that will fail only if all its units fail. Let reliability of each unit be 
P-
Then, the reliability of series system Pi is given by: 
P i = p " . 
Similarly, the reliability of parallel system R2 is given by: 
P 2 = l - ( l - p ) n . 
▲ 
In the following example, we illustrate the reliability of a non-series/parallel 
system. 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
2 5 
Chennai 
(I) 
Bengaliini 
(2) 
Hyderabad 
(3) 
Mumbai 
w 
Delhi 
(5) 
Figure 1.1 
A communication network system 
EXAMPLE 1.44 
Consider a communication network system in India with five network 
switches placed as shown in Figure 1.1. Suppose that the probability 
that each network switch will perform a required function without fail-
ure, i.e., reliability of each network switch, is R\ = 0.98, R2 — 0.99, R3 = 
0.99, R4 = 0.96 and R& — 0.95. Assume that each network switch is 
functioning independently. Find the reliability of the communication 
network system. 
Solution: For i = 1,2, · · · , 5 let: 
Ai := "The ith. network switch functioning". 
We define: 
Ri = P(Ai) 
for t = l,2,··· ,5. 
The reliability of the communication network system is: 
R = P (Ay n (A2 u A3) n A4 n A5) 
= 
P(Al)P(A2UA3)P(Ai)P(A5) 
= Ri (R2 + i?3 — .R2-R3) R4R5 
= 0.98 x 0.9999 x 0.96 x 0.95 
= 0.8937. 
A 
The following results are vital for applications: 
Theorem 1.4 (Total Probability Theorem) Let Αχ,Αι,···, 
be a finite 
00 
or countable partition of Ω, that is, AiC\Aj=% 
for all ιφ j and |J Aj = Ω; 
i=l 
such that P{Ai) > 0 for all Ai e 9. Then, for any B € S: 
P{B) = ΣΡ{Β 
I Ai)P{Ai). 

26 
BASIC CONCEPTS 
Proof: We observe that 
= uZ1(BnAi) 
and hence, 
P(B) = YtP{BnAi) 
i 
= J2P(B\Ai)P(Ai), 
i 
which proves the theorem. 
■ 
As a corollary to the previous theorem we obtain a result known as Bayes' 
rule, which constitutes the base for an important statistical theory called 
Bayesian theory. 
Corollary 1.1 (Bayes' Rule) Let Αχ,Αϊ, ■ ■ ■ be a finite or countable parti-
tion of Ω with P{Ai) > 0 for all i; then, for any B s 9 with P(B) > 0: 
DfA i m 
p(Ai)P(B 
| At) 
. 
.. . 
m | ß ) =EWW / o r ö l h· 
j 
Proof: 
P(Ai n B) 
P(Ai\B) = 
P(B) 
PjA^PjBlAj) 
P(B) 
P{Ai)P(B\Ai) 
Υ,Ρ{Β\Αά)Ρ{Α5) 
■ 
3 
To give an interpretation of Bayes' rule, suppose that the events Λχ, Α2, ■ ■ ■ 
are all possible causes, mutually exclusive, of a certain event B. Under the 
assumption that we have indeed observed the event B, Bayes' formula allows 
us to know which of these causes is most likely to have produced the event B. 
■ EXAMPLE 1.45 
Mr. Rodriguez knows that there is a chance of 40% that the company 
he works with will open a branch office in Montevideo (Uruguay). If 
that happens, the probability that he will be appointed as the manager 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
27 
in that branch office is 80%. If not, the probability that Mr. Rodriguez 
will be promoted as a manager to another office is only 10%. Find the 
probability that Mr. Rodriguez will be appointed as the manager of a 
branch office from his company. 
Solution: Let: 
M := "Mr. Rodriguez is appointed as a manager". 
N := "The company opens a new branch office in Montevideo". 
Then: 
P(M) = P{M | N)P(N) + P(M | NC)P(NC) 
= 0.8x0.4 + 0.10x0.60 
= 0.38. 
A 
EXAMPLE 1.46 
In the previous example, if we know that Mr. Rodriguez was indeed 
appointed manager of an office from the company he works for, what is 
the probability that the company opened a new office in Montevideo? 
Solution: From Bayes' rule, is clear that: 
_ 0.4 x 0.8 
~ 
0.38 
= 0.84211. 
A 
EXAMPLE 1.47 
A signal can be green or red with probability | or ^, respectively. The 
probability that it is received correctly by a station is | . Of the two 
stations A and B, the signal is first received by A and then station A 
passes the signal to station B. If the signal received at station B is green, 
then find the probability that the original signal was green? 
Solution: Let: 
BG(BR) 
:= "Signal received at station B is Green (Red)", 
AG{AR) 
:= "Signal received at station A is Green (Red)", 

28 
BASIC CONCEPTS 
Then from Bayes' rule, it is clear that: 
P(BGnAG) 
P(AG\Bo)- 
p{Bc) 
. 
Now: 
π / π 
. x 
4 
3 
3 
4 
1 
1 
Ρ(ΒαηΑα) 
= - χ - χ ι 
+ - χ - χ -
„
.
„
.
4
3
3
4
1
1
1
3
1
1
1
3 
5
4
4
5
4
4
5
4
4
5
4
4 
Hence: 
40 
P{AO\BG) 
= Ü- 
* 
■ EXAMPLE 1.48 
It is known that each of four people A, B, C, D tells the truth in a given 
instance with probability | . Suppose A makes a statement, and D says 
that C says that B says that A was telling the truth. What is the 
probability that A was actually telling the truth? 
Solution: Let: 
T := "A speaks the truth". 
E := "D says the statement". 
Then: 
pen = J. 
The required probability is P(T\E). 
Now: 
P{E\T) 
= 
Probability that D speaks the truth to C and 
C speaks truth to B and B speaks the truth, 
+D speaks truth to C, C lies to B and B lies, 
+D lies to, C, C speaks truth to B, B lies, 
+D lies to C and C lies to B and B speaks truth. 
Hence: 
n , „ l r w n 
(\ 
1 1\ 
(\ 
2 2\ 
(1 
1 2\ /2 2 1\ 
v ' ; V3 3 3j \3 3 3j \3 3 37 V3 3 3/ 
_ 13 
~ 27 
„,„1TOX 
(2 
2 
1 \ 
/ 2 
1 
1 \ 
/ l 
2 
1 \ 
/ l 
1 
2 \ 
Ρ £ Γ 
= 
- x - x - 
+ 
- x - x - 
+ 
- x - x - 
| 
- x - x -
v ' ; 
V3 
3 
3/ 
V3 
3 
3 / 
\3 3 37 V3 
3 
3/ 
_ 10 
~ 27 ' 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
29 
Prom Bayes' rule: 
P(E\T)P(T) 
P(T\E) 
P(E\T)P{T) 
+ 
P(E\TC)P(TC) 
13 y 
I 
27 * 3 
(27 
X 3) + V27 
X 
3) 
13 
P™=13 + 28 
P(T\E) = g . 
A 
EXAMPLE 1.49 
A quarter of a population is vaccinated against a certain contagious 
disease. During the course of an epidemic due to such disease, it is 
observed that from every 5 sick persons only 1 was vaccinated. It is also 
known that from every 12 vaccinated people, only 1 is sick. We wish to 
find the probability that a nonvaccinated person is sick. 
Solution: Let: 
V := "The person is vaccinated". 
S := "The person is sick". 
Prom the information, we have: 
P(V \S) = l 
Pis\v) = ± 
Thus 
and therefore 
x := P(S | Vc) 
_ P(VC I S)P(S) 
P(VC) 
_ 
5V12-4 ^ 
ΑΧ) 
~ 
3 
' 
4 
1 
X=9- 
A 

30 
BASIC CONCEPTS 
EXAMPLE 1.50 
It is known that the population of a certain city consists of 45% females 
and 55% males. Suppose that 70% of the males and 10% of the females 
smoke. Find the probability that a smoker is male. 
Solution: Let S be the event that a person is a smoker, M be the event 
that a person is male and F be the event that a person is female: 
P{M) 
= 
P(F) 
= 
P(S\M) 
= 
The required probability is: 
P{S\M)P(M) 
55 
100 
45 
100 
70 
1ÖÖ 
P(M\S) 
{P{S\M )P{M) + 
P{S\F)P{F) 
_ 
Uoo/ * Uoo/ 
= 
0.895. 
A 
EXAMPLE 1.51 
Dunlop tire Company produces tires which pass through an automatic 
testing machine. It is observed that 5% of the tires entering the testing 
machine are defective. However, the automatic testing machine is not 
entirely reliable. If a tire is defective, there is 0.04 probability that it 
is not to be rejected. If a tire is not defective there is 0.06 probability 
that it will be rejected. What is the probability that the tires rejected 
are actually not defective. Also, what fraction of those not rejected are 
defective? 
Solution: Let D be the event that the tire is defective and R be the 
event that the tire is rejected: 
P{D) = 0.05, P(DC) = 1 - P{D) = 0.95. 
It is given that: 
P{RC | D) = 0.04 and P{R \ Dc) = 0.06. 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
3 1 
Therefore: 
P<No»defeCi», | Rejected) 
= 
p ( p e ) p^f^p(R , p ) 
P(DC) P(R 1 £>c) 
P{DC) P(R | £>c) + P(D) (1 - P ( ß c | D)) 
0.95(0.06) 
0.95(0.06) + 0.05(1 - 0.04) 
= 
0.542. 
Similarly: 
P(Defective | Not Rejected) 
= 
p ( g ) p ( / [ g }
 P ^
p
{
R
c 
, 
^ 
0.05(0.04) 
0.05(0.04) + 0.95(1 - 0.06) 
= 
0.002. 
▲ 
Definition 1.12 (A Priori and A Posteriori Distributions) Let 
Ai,A2, ■ · · be a finite or countable partition of Ω with P(Ai) > 0 for all i. 
If B is an element from 3 with P(B) > 0, then (P(A„))„ is called the "a 
priori"distribution, 
that is, before B happens, and {P(An \ B))n is called the 
"a posteriori"distribution, 
that is, after B has happened. 
■ EXAMPLE 1.52 
In a city, tests are taken to detect a certain disease. Suppose that 1% 
of the healthy people are registered as sick, 0.1% of the population is 
actually ill and 90% of the sick are reported as such. We wish to calculate 
the probability that a randomly chosen person reported as ill is indeed 
sick. 
If we define the events 
S := "the person is indeed sick" 
R := "the person is reported as sick" 
from the information stated above, we know that: 
P(S) = 0.001 
P (R | Sc) = 0.01 
P(R\S)= 
0.9. 

32 
BASIC CONCEPTS 
Therefore: 
P(R | S)P(S) 
P(S\R) 
P(R | SC)P(SC) + P(R | S)P(S) 
0.9 x 0.001 
0.01 x 0.999 + 0.9 x 0.001 
8.2645 x 10~2 « 0.083. 
In this case: 
A priori distribution = {P{S),P(SC)) 
= (0.001,0.999) 
A posteriori distribution = (F(S | R), P(SC | R)) = (0.083,0.917). 
A 
Sometimes the occurrence of an event B does not affect the probability of an 
event A, that is: 
P(A | B) = P(A). 
(1.1) 
In this case, we say the event A is "independent" from event B. The 
"definition" (1.1) requires the condition that P(B) > 0. To avoid this condi-
tion, we define independence as follows: 
Definition 1.13 (Independent Events) Two events A and B are said to 
be independent if and only if: 
P(AnB) 
= P(A)P{B) 
. 
On the contrary, if the previous condition is not met, the events are said to 
be dependent. 
EXAMPLE 1.53 
Suppose a fair die is rolled two times. Let: 
A := "The sum of the results obtained is an even number". 
B := "The result from the second roll is even". 
In this case: 
P{A) = P{B) = \ 
Furthermore, P(A Π B) = j . Accordingly, the events are independent. 

CONDITIONAL PROBABILITY AND EVENT INDEPENDENCE 
33 
■ EXAMPLE 1.54 
A die is biased in such a way that the probability of obtaining an even 
number equals | . Let A and B be defined as in the preceding example. 
Under these conditions we have: 
P(B) = | 
P(AnB) = ±. 
Thus, A and B are not independent. 
A 
Note 1.5 A mistake that is commonly made is to assume that two events are 
independent if they are mutually exclusive. Note that this is not the case. For 
example, if a fair coin is flipped once and we consider the events 
A := "the result obtained is head" 
B := "the result obtained is tail" 
then, clearly, A and B are mutually exclusive. They are however not inde-
pendent, since: 
0 = P(A Π B) φ J = P(A)P(B) . 
Theorem 1.5 Let A and B be independent events. Then: 
1. A and Bc are two independent events (and hence by symmetry Ac and 
B are two independent 
events). 
2. Ac and Bc are two independent events. 
Proof: 
1. 
P{A) = P{A n Bc) + P{A n B) 
= P(A Π Bc) + 
P(A)P(B), 
Therefore: 
P(A n Bc) = P(A)[1 - P{B)} = 
P{A)P(BC). 

34 
BASIC CONCEPTS 
2. 
P(AC Π Bc) = 1 - P(A U B) 
= 1 - P(A) - P(B) + P(A Π B) 
= 1 - P{A) - P(B) + 
P(A)P(B) 
= 
[l-P(A)][l-P(B)} 
= 
P(AC)P(BC). 
■ 
In many cases it is necessary to analyze the independence of two or more 
events. In this context a broader definition of independence must be given. 
Definition 1.14 (Independent Family) A family of events {Ai : i € /} is 
said to be independent if 
P \Γ\Αή = ΠΡ(^) 
\ieJ 
) 
ieJ 
for every finite subset 0 φ J of I. 
These events are mutually 
independent 
events. 
Definition 1.15 (Pairwise Independent Events) A family of events 
{Ai : i £ 1} is said to be pairwise (2 x 2) independent if: 
P(Ai Π Aj) = P{Ai)P{Aj) 
for all i φ j . 
Pairwise independence does not imply the independence of the family or 
mutually independent events, as the following example shows: 
■ EXAMPLE 1.55 
A fair die is rolled two consecutive times. Let A, B and C be the events 
defined as follows: 
A 
B 
C 
= "A 2 was obtained in the first toss". 
= "A 5 was obtained in the second toss". 
= "The sum of the results is 7". 
Clearly: 
P(A) = P{B) = P(C) 
P(A nß) = P(A π c) = P(B n c) 
1 
36 
P(A n B n c) = 36 

GEOMETRIC PROBABILITY 
35 
Figure 1.2 
Sample and event space 
The events are therefore pairwise independent, but they are however not 
mutually independent because: 
P(A(lB(lC)^ 
P{A)P{B)P{C) 
. 
▲ 
1.4 
GEOMETRIC PROBABILITY 
Let (Ω, 3ί) be a measurable space, and assume that a geometric measure m, 
such as length, area or volume, is defined over (Ω, 3). We define the geometric 
probability of an event A as follows: 
P{A) := ΞϊΜ 
v 
; 
τη(Ω) 
Next, we give some examples showing geometric probability calculus. 
■ EXAMPLE 1.56 
Find the probability that a point chosen at random lies on a line segment 
AC of a line AS (see Figure 1.2). 
Solution: 
„ , . . , . 
r , 
. 
-ΓΡϊ 
Length of AC 
Probability of the point is on AC 
= 
Length of AB 
4 
= 
Ϊ6- 
A 
EXAMPLE 1.57 
Maria Victoria and Carlos agreed to meet downtown between 12 noon 
and 1 PM. They both get there at any moment in that time interval. 
Assuming their arrival times to be independent, find: 
(i) The probability that Carlos and Maria Victoria will meet if both of them 
waits for the other 10 minutes at most. 

36 
BASIC CONCEPTS 
Figure 1.3 
Event space for case (i) 
(ii) The probability that Carlos and Maria Victoria will meet if Maria Vic-
toria waits 5 minutes but Carlos waits 20. 
Solution: (i) Let X and Y be events denned as follows: 
X :— "Maria Victoria's arrival time" 
Y := "Carlos' arrival time". 
The sample space in this case is given by: 
Ω := {(x,y) e K2 : 0 < x < 60, 0 < y < 60} . 
We wish to measure the probability of the event: 
T = 
{{x,y)efl:\x-y\<W}. 
Therefore (see Figure 1.3): 
= area of T = 11 
area of Ω 
36 
(ii) The set of points T representing the arrival times of Carlos and 
Maria Victoria that allow them to meet is represented in Figure 1.4. 
Thus, the probability we wish to find equals: 

EXERCISES 
37 
Figure 1.4 
Event space for case (ii) 
v ' 
288 
EXERCISES 
1.1 
A fair coin is flipped three times in a row. Let: 
A := "The result of the first toss is head". 
B := "The result of the third toss is tail". 
Describe in words the events AnB, 
Ali B, Ac, Ac (Ί Bc, A Π Bc and find 
its elements. 
1.2 
Let A, B and C be three arbitrary events. Give in terms of set opera-
tions of the following events: 
a) A and B but not C. 
b) All three of them. 
c) Only A. 

38 
BASIC CONCEPTS 
d) At least one of them. 
e) At most one of them. 
f) At most two of them. 
1.3 
A fair die is rolled twice in a row. Let A, B and C be the events given 
by: 
A := "The first result obtained is an even number". 
B := "The sum of the results is less than 7". 
C := "The second result obtained is a prime number". 
List the elements belonging to the following events: 
a) 
AnBnC. 
b) 
Bl>(Ar\Cc). 
c) (AnC)n[{AuB)c}. 
1.4 
A random experiment consists in extracting three light bulbs and clas-
sifying them as defective "D" or nondefective "N". Consider the events: 
Ai := "The ith light bulb removed is defective", 
i =.1,2,3. 
a) Describe the sample space for this experiment. 
b) List all the results in Ai, A2, A\ U A3, A\ Π Α\ (Ί A3 and 
{Ax U Αξ) Π A3. 
1.5 
A worker makes n articles. The event "The ith article is defective" will 
be notated as Ai with i = 1,2, ■ · ■ , n. Describe the following events using the 
sets Ai and the usual operations between events: 
a) B := "At least an article is defective". 
b) C := "None of the n articles is defective". 
c) D := "Exactly one article is defective". 
d) E := "At most one article is defective". 
1.6 
Let A, B and C be arbitrary events. Depict the following events in 
terms of A, B and C: 
a) Ei := "At least one of the events A, B, C happens". 
b) E2 := "Exactly two of the events A, B, C happen". 

EXERCISES 
39 
c) E3 := "At least two of the events A, B, C happen". 
d) £4 := "At most one of the events A, B, C happens". 
1.7 
Suppose that 35% of the students of a university are taking English, 
7% are taking German and 2% are taking both English and German. What 
percentage of the student population is taking English but not German? What 
percentage of the students are taking neither English nor German? 
1.8 
Let Ω φ 0 and let 3 be a σ-algebra over Ω. Prove: 
00 
a) If Ai,A2, 
· · · G 3 , then f]Ai 
€ 3 . 
i=l 
b) If A,B e 9, then Al)B, 
ΑΓιΒ, 
A\ B and A Δ B all belong to 9. 
1.9 
Let Ω = {1,2,3,4}. Find four different σ-algebras {3 n} for n = 1,2,3,4 
such that 9i C 3 2 C 3 3 C Q4-
1.10 
Let Ω and Ω be nonempty sets and 9i a σ-algebra over Ω. If T : Ω —> Ω 
is a function, then prove that the collection T-1(Qi) = {T~l(A) 
: A € 3} is a 
σ-algebra over Ω. 
1.11 
Let Ω φ 0 and Ω be a nonempty subset of Ω. If 9 is a σ-algebra over 
Ω, then prove that Qf = {A Π Ω : A € 9} is a σ-algebra over Ω called the trace 
of 3 on Ω. 
1.12 
Let Αχ,Αζ,··· 
, An be events in the probability space (Ω, 9, P). Prove 
that: 
n 
1 = 1 
' 
* 
i=l 
1.13 
a) Find the σ-algebra over Ω = {1,2,3} generated by {{2}, {3}}. 
b) Let C and V be two families of subsets from a nonempty set Ω with 
C C V. Is a{C) C σ{Ό)Ί Explain. 
c) Let Ω = {1,2}, 9 = {0, Ω, {1}, {2}} and μ defined over 3 by: 
μ(0) = 0 
μ(Ω) = 1 
A*({1» = \ 
M({2}) = | . 
Is (Ω, 3, μ) a probability space? Explain. 

40 
BASIC CONCEPTS 
1.14 
Let Ω = {a, 6, c, d}, 3 = {0, Ω, {a}, {6, c}, {d}, {a, b, c}, {6, c, d}, {a, d}} 
and P a map of Of on [0,1] with P({a}) = f, P({6, c}) = | and P({d}) = a. 
a) Determine the value that a should take in order for P to be a probability 
measure over (Ω, 3f). 
b) Find P({a,b,c}), 
P({b,c,d}) 
and 
P({a,d}). 
1.15 
Let (Pn)n6N be a sequence of probability measures over a measur-
able space (Ω,Οί), (an)neN a sequence of nonnegative real numbers such that 
ΣΓ=ι an = 1 and P : 3 -)■ R defined by: 
P(A) := J2anPn(A) 
for all A € 3. 
Prove that P is a probability measure over (Ω, 3). 
1.16 
Indicate whether the following statements are true or false. Give a 
brief account of your choice: 
a) If P{A) = 0, then A = 0. 
b) If P{A) = P{B) = 0, then P(A U B) = 0. 
c) If P(A) = \ and P{B) = ±, then i < P(,4 U B) < | . 
d) If P(A) = P(B) = p, then P(A 
f)B)<p2. 
e) P(A Δ B) = P{A) + P(B) - 2P(A Π B). 
f) If P(A) = 0.5, P(B) = 0.4 and Ρ(Λ U B) = 0.8, then P(AC n B ) = 0.1 
g) If .A and P are independent events and A C B, then P(A) = 0 or 
P(B) = 1. 
1.17 
Prove that P{A U P U C) = P{A) + P(AC C\B) + P{AC Π P c Π C). 
1.18 
Let ,4 and B be two events with P(A) = \ and P(PC) = \. Can >1 
and B be mutually exclusive events? Justify. 
1.19 
A die is biased in such a way that the probability of getting an even 
number is twice that of an odd number. What is the probability of obtaining 
an even number? A prime number? An odd prime number? 
1.20 
From the 100 students majoring in philology and classic languages in 
the linguistics department of a certain University 28 take Latin classes, 26 take 
Greek, 16 Hebrew, 12 both Latin and Greek, 4 Latin and Hebrew and 6 Greek 
and Hebrew. Furthermore, 2 are taking all the aforementioned subjects. 
a) If a philology and classic languages student is randomly chosen, what is 
the probability that he or she is taking only Hebrew? 

EXERCISES 
4 1 
b) If a philology and classic languages student is randomly chosen, what 
is the probability that he or she is taking Greek and Hebrew but not 
Latin? 
c) If two philology and classic languages students are randomly chosen, 
what is the probability that at least one of them is attending one of the 
classes? 
1.21 
A company was hired to poll the 1000 subscribers of a magazine. The 
data presented on their report indicate that 550 subscribers are professional, 
630 are married, 650 are over 35 years of age, 127 are professional and over 
35, 218 are married and over 35, 152 are professional and married and 100 are 
married, professional and over 35. Is the data presented in the report right? 
Explain. 
1.22 
A fair coin is nipped n times. Let 
Ak := "The first head was obtained in the fcth toss" 
where k = 1,2, · ·· , n. What is P(Ak) equal to? 
1.23 
Ten distinguishable balls are randomly distributed on 7 distinguishable 
urns. What is the probability that all urns have at least one ball? What is 
the probability that exactly two urns are left empty? 
1.24 
A group of 40 students is made from 20 men and 20 women. If this 
group is then divided in two equal groups, what is the probability that each 
group has the same number of men and women? 
1.25 
Let w b e a complex cube root of unity with w ψ 1. A fair die is 
thrown three times. If x, y and z are the numbers obtained on the die. Find 
the probability that wx + wy + wz = 0. 
1.26 
The coefficients a, b and c of the quadratic equation ax2+bx+c = 0 are 
determined by rolling a fair die three times in a row. What is the probability 
that both roots of the equation are real? What is the probability that both 
roots of the equation are complex? 
1.27 
What is the chance that a leap year selected at random has 53 Sun-
days? 
1.28 
There are two urns A and B. Urn A contains 3 red and 4 black balls 
while urn B contains 5 red and 7 black balls. If a ball is randomly drawn 
from each urn, what is the probability that the balls have the same color? 
1.29 
An urn contains 3 red and 7 black balls. Players A and B consecutively 
extract a ball each until a red one is drawn. What is the probability that player 
A will remove the red ball from the urn? Assume the extraction is carried 
without replacement and player A starts the game. 

42 
BASIC CONCEPTS 
1.30 
There are 200 ornamental fishes in a lake; 50 of them are captured and 
tagged and then returned to the lake. A few days later 40 fishes are captured. 
What is the probability that 20 out of the 40 are tagged already? 
1.31 
Five men and 5 women are ordered according to their grades in a test. 
Suppose that no two grades are the same and that all 10! arrangements are 
equally likely. What is the probability that the best position achieved by a 
man is the fourth one? 
1.32 
In Bogota, the father of a certain family decides to plan weekend 
activities with his children according to the result of the roll of a fair die. 
If the result is equal to or less than 3, he will take his children to their 
grandmother's house; if the result is 4 he will take them to the beach in the 
city of Cartagena; and if the result is 5 or 6, he will stay at home to watch 
movies with his children. 
In order to have an idea of how his weekend activities are shaping up to be, 
the father decides to divide the year in 13 periods of 4 weeks each and is 
interested in the probability of the following events: 
a) Go at least one trip to Cartagena. 
b) Stay twice at home. 
c) Go at least three times to grandmother's house. 
d) Do each activity at least once. 
Calculate the probability of these events? 
1.33 
In order to illuminate a stairway 7 lamps have been placed and labeled 
with letters from A to G. To guarantee a proper lighting, lamps Αοτ Β must 
work along with lamps F or G, or any of the lamps C, D or E must be working. 
The probability that any given lamp will be working is | . 
a) What is the probability that the stairway will be well lit? 
b) How does the probability from part i) change if the lamp D is never 
used? 
1.34 
What is the probability that among a group of 25 people at least 2 
have the same birthday? Assume that the year has 365 days and that all of 
them are equally likely to be somebody's birthday. 
1.35 
There are n people at a Christmas party, each carrying a gift. All the 
presents are put in a bag and mixed, then each person randomly takes one. 
What is the probability that no one gets their own present? 
1.36 
In a bridge game, the whole pack of 52 cards is dealt between 4 players. 
a) What is the probability that each player gets an ace? 

EXERCISES 
43 
b) What is the probability that one player gets 5 spades while another one 
receives the remaining 8? 
1.37 
An urn contains 15 balls, 9 of which are red and the other 6 are white. 
The following game is played: a ball is randomly extracted and, after taking 
note of its color, it is returned to the urn along with a new pair of balls of the 
same color. Find the probability that in the first three rounds of the game all 
the balls drawn are white. 
1.38 
Find the probability that in a group of 13 cards, from a pack of 52, 
there are exactly two kings and an ace. What is the probability that in such 
a group there is exactly one ace given that the group contains exactly two 
kings? 
1.39 
Let A and B be events such that P(A) = 0.5, P(B) = 0.3 and 
P(A n ß ) = 0.1. Find P(A \ B), P(A \ Bc), P(A \ A Π B), P(AC 
\AöB) 
a n d P ( A n S 
\AUB). 
1.40 
A math student must take on the same day a probability and an 
algebra exam. Let: 
A := "The student fails the probability exam". 
B := "The student fails the algebra exam". 
Let P(A) = 0.4, P(B) = 0.3 and P(A Π B) = 0.2. What is the probability 
that the student passes the algebra exam given that he passed the probability 
one? What is the probability that the student passes the probability exam 
given that he failed the algebra one? 
1.41 
A survey was taken in a certain city producing the following results: 
90% of the families owns both a radio and a TV. 
8% of the families owns a radio but not a TV. 
2% of the families owns a TV but not a radio. 
95% 
of the families that owns a radio and a TV 
knows who the city mayor is. 
80% of the families that owns a radio but not a 
TV knows who the city mayor is. 
1% of the families that owns a TV but not a 
radio does not know who the city mayor is. 
A family is randomly chosen in this city. Consider the events: 
T := "The family owns a TV" 
R := "The family owns a radio" 
B :— "The family knows who is the city mayor". 

44 
BASIC CONCEPTS 
Find the following probabilities: 
a) 
P(TöR). 
b) 
P{B<lT). 
c) P(T | B). 
1.42 
Consider a population that develops according to the following rules: 
an initial individual constitutes the Oth generation and it can have 0, 1 or 
2 descendants with probabilities of g, § and | , respectively. After giving 
its offspring, the individual dies. Each descendant reproduces independently 
from one another and the family history, following the same rule as the original 
individual. The first generation will be made from the children of the first 
individual, the second generation will be made from its grandchildren, and so 
on. Given that there is only one individual in the second generation, what 
is the probability that the first generation had two individuals? What is the 
probability that there is at least one individual in the second generation? 
1.43 
Consider two urns A and B. Urn A contains 7 red balls and 5 white 
ones while urn B contains 2 red balls and 4 white ones. A fair die is rolled, 
if we obtain a 3 or a 6 a ball is taken from B and put into A and, after this, 
a ball is extracted from A. If the result is any other number, a ball is taken 
from A and put into B and then a ball is extracted from B. What is the 
probability that both balls extracted are red? 
1.44 
Suppose that you ask a classmate to sign you up for the class "Mathe-
matics with no effort" that is being offered for the next term. If your classmate 
forgets to make the registration by the deadline set by the Mathematics De-
partment, the probability that the class won't have its quota filled and you 
can therefore register is 2%; on the other hand, if your classmate registers 
you on time, the probability that the class won't have its quota filled is 80%. 
You are 95% sure that your classmate will register you on time. What is the 
probability that your classmate forgot to sign you up for the class if you could 
not register? 
1.45 
The probability that in a twin's birth both babies are males is 0.24, 
while the probability that they are both females is 0.36. What is the proba-
bility that in a twin's delivery the second baby born is a boy given that the 
first one was a boy? Suppose that it is equally likely for the first baby to be 
either male or female. 
1.46 
A particle starts at the origin and moves to and from on a straight line. 
At any move it jumps either 1 unit to the right or 1 unit to the left each with 
probability \. All successive moves are independent. Given that the particle 
is at the origin at the completion of the 6th move, find the probability that 
it never occupied a position to the left of the origin during previous moves. 

EXERCISES 
45 
1.47 
An investor is considering buying a large number of shares of a com-
pany. The stock quote of the company in the past 6 months is of great interest 
to him. Based on this information, he observes that the share price is closely 
related to the gross national product (GNP): if the GNP goes up, the proba-
bility that the share price will rise as well is 0.7; if the GNP remains stable, 
the probability that the share price will increase is just 0.2; if the GNP falls, 
however, the probability that the price share will go up is only 0.1. If the prob-
abilities that the GNP increases, remains the same or decreases are 0.5, 0.3 
and 0.2, respectively, what is the probability that the shares will go up? If 
the shares rose their stock quote, what is the probability that the GNP had 
increased as well? 
1.48 
A person wrote n letters, sealed them in n envelopes and wrote the n 
different addresses randomly one on each of them. Find the probability that 
at least one of the letters reaches its correct destination. 
1.49 
Suppose that 15 power plants are distributed at random among 4 
cities. What is the probability that exactly 2 cities will receive none. 
1.50 
Suppose that in answering a question on a multiple-choice test an 
examinee either knows the answer or he guesses. Let p be the probability 
that he will know the answer, and let 1 — p be the probability that he will 
guess. Assume that the probability of answering a question correctly is unity 
for an examinee who knows the answer and ^ for an examinee who guesses, 
where m is the number of multiple-choice alternatives. Find the conditional 
probability that an examinee knew the answer to a question given that he has 
correctly answered it. 
1.51 
There are eight coins in an urn. Two of them have two tails, three are 
fair coins and three are biased in such a way that the probability of getting 
a tail equals | . A coin is randomly drawn from the urn. If flipping the coin 
produced a head, what is the probability that the coin drawn was a common 
one? 
1.52 
Let Ω = {a, b, c}, 3 = ρ(Ω) and Ρ(ω) = \ for all ω € Ω. Let 
A = {b, c}. Find all the elements B s 9 such that A and B are independent. 
1.53 
Let Ω = {1,2,3,4,5,6}, 3 = ρ(Ω) and Ρ(ω) = ± for all ω e Ω. Prove 
that if A and B are independent elements in 9? and A has 3 elements, then B 
must have an even number of elements. 
1.54 
Let Ω = {1,2,3,4,5,6}, 3 = ρ(Ω) and P be a probability measure 
with P({1}) = P({2}) = £,P({3}) = P({4}) = \. Find P({5}) and P({6}) 
if the events {1,3,4} and {1,2,3,5} are independent. 
1.55 
Cards are taken out of a standard deck of 52 cards. Let event A b e a 
card with a spade and event B a king. Are A and B independent events? 

46 
BASIC CONCEPTS 
1.56 
Prove that if A = B and A and B are mutually independent (that is, 
A is independent of itself), then P{A) = 0 or P(A) = 1. 
1.57 
Let A be an event. Prove that the following conditions are equivalent: 
a) A and B are independent for any event B. 
b) P(A) = 0 or P(A) = 1. 
1.58 
Let A, B and C be independent events. Prove that A and BliC; 
A 
and B C\C\ A and (B \ C) are independent. 
1.59 
Suppose that each of three men at a party throws his hat into the 
center of the room. The hats are first mixed up and then each man randomly 
selects a hat. What is the probability that none of the men selects his own 
hat? 
1.60 
Prove that events A\, A2, ■ · · ,An are independent if and only if 
P{BX n ß 2 n - n ß „ ) = P(B1)P(B2) 
■ ■ ■ P{Bn) 
for all possible choices of BX,B2,· ■ ■ ,Bn with Bi = Ai or Bi = A\ for all 
z = 1,2,··· , n. 
1.61 
A fair coin is flipped three times in a row. Consider the following 
events: 
A := "The results of flips 1 and 2 are different". 
B := "The results of flips 2 and 3 are different". 
C := "The results of flips 1 and 3 are different". 
a) Verify that P(A) = P(A \ B) = P{A \ C) and that P(A) φ P(A | 
BnC). 
b) Are A, B and C 2 x 2 independent? Are A, B and C independent? 
Explain your answers. 
1.62 
Let us pick one of the four points (1,0,0), (0,1,0), (0,0,1) and (1,1,1) 
at random with probability \ each. Define, for k = 1,2,3: 
Α^ = {the fcth coordinate equals 1}. 
Show that the events Αχ, Α-χ and A3 are pairwise independent but not inde-
pendent. 
1.63 
Let A, B and C be independent events with P(A) = P{B) = P(C) = 
| . Find the probability that: 
a) At least one event happens. 

EXERCISES 
47 
b) At least two events happen. 
c) Exactly two of the events happen. 
1.64 
Find the probability that among seven people: 
a) No two of them were born the same day of the week (Sunday, Monday, 
Tuesday, etc.). 
b) At least two of them were born the same day. 
c) Two were born on Sunday and two on Tuesday. 
1.65 
In a town of n + 1 inhabitants, a person tells a rumor to a second 
person, who in turn repeats it to a third person, etc. At each step, the 
recipient of the rumor is chosen at random from the n people available. Find 
the probability that the rumor will be told r times without returning to the 
originator. 
1.66 
Suppose that an urn contains N balls numbered from 1 to N. A ran-
dom sample of size n is taken without replacement, and the numbers obtained 
are taken down. After returning the balls to the urn, a second sample of size 
m(> 1) is extracted without replacement. Find the probability that both 
samples have k balls in common. 
1.67 
An urn contains balls numbered from 1 to TV. A ball is randomly 
drawn. 
a) What is the probability that the number on the ball is divisible by 3 or 
4? 
b) What happens to the probability from the previous question when n —► 
oo? 
1.68 
Pick a number x at random out of the integers 1 through 30. Let A 
be the event that x is even, B that x is divisible by 3 and C that x is divisible 
by 5. Are the events A, B and C independent? 
1.69 
Let Q = (x, y) be a point chosen at random in a unit disc centered in 
(0,0) and with radius 1. Calculate the probabilities that Q is within 0.5 of 
the center; that y > A?; that both || x — y ||< 1 and || x + y ||< 1. 
1.70 
Suppose that a straight line is randomly subdivided into three parts. 
What is the probability that these parts can be assembled into a triangle? 
1.71 
An omnibus company always requires its drivers to wait for 10 minutes 
at a particular bus stop. The bus you hope to get arrives at this stop anywhere 
between noon and 1 PM. Assume that you arrive at the stop randomly between 
12:30 PM and 1:30 PM and plan to spend at most 10 minutes waiting for the 
bus. What is the probability that you catch your bus on any day? 

4 8 
BASIC CONCEPTS 
Figure 1.5 
A system with five components 
Figure 1.6 
Sample space 
1.72 
Consider a system consisting of five independently functioning compo-
nents as shown in Figure 1.5. Suppose that the reliability of the components 
is Ri = 0.95, i = 1,2,·· ,5. Find the reliability of the system. 
1.73 
A point is randomly chosen from a disk of radius R. Calculate the 
probability that the point is closer to the circle than to the center. 
1.74 
Along a line segment ab two points I and m are randomly marked. 
Find the probability that I is closer to a than m. 
1.75 
There is a circular dartboard (see Figure 1.6). It costs $5000 to throw 
a dart. You win $10,000 if you hit the square outside of the circle. The radius 
of the circle is 20 cm. How long should the side of the square be made to 
make this game fair? 
1.76 
A point Q is selected at random in the square ABCD and it is con-
structed a rectangle AMPN 
(see Figure 1.7). Calculate the probability that 
the perimeter of the rectangle is less than the length of the square's side. 
1.77 
A communication system consists of n components, each of which will 
independently function with probability p. The total system will be able 
to operate effectively if at least half of its components function. For what 
values of p is a five-component system more likely to operate effectively than 
a three-component system? 

EXERCISES 
49 
M 
N 
D 
Figure 1.7 
Sample space 
1.78 
Suppose a long-haul airplane has four engines and needs three or more 
engines to work in order to fly. Another airplane has two engines and needs 
one engine to fly. Assume that the engines are independent and suppose each 
has a constant probability p of staying functional during a flight. Find the 
reliability of both flights and conclude which one is safer. 
1.79 
A technological system consists of n units, the reliability of each unit 
being p. The failure of at least one unit results in the failure of the entire 
system. To increase the reliability of the system, it is duplicated by n similar 
units. Which way of duplication provides higher reliability: (a) the duplication 
of every unit (i.e., series of n units, each with duplication); (b) the duplication 
of the whole system (i.e., parallel system with n units in series). 

CHAPTER 2 
RANDOM VARIABLES AND THEIR 
DISTRIBUTIONS 
In a random experiment, frequently there has been greater interest for certain 
numerical values that can be deduced from the results of the random exper-
iment than the experiment itself. Suppose, for example, that a fair coin is 
tossed consecutively six times and that we want to know the number of heads 
obtained. In this case, the sample space is equal to: 
Ω = {(αι,α2,α3,α4,α5,α6) : a, € {H, T},i = 1, · ■ · ,6}. 
If we define X := "number of heads obtained", then we have that X is a 
mapping of Ω to {1,2, · ■ · , 6}. Suppose, for example, we have 
X({H, H, T, H, H, T)) = 4. The mapping X is an example of a random vari-
able. That is, a random variable is a function defined on a sample space. We 
will explain this concept in this chapter. 
2.1 
DEFINITIONS AND PROPERTIES 
Definition 2.1 (Random Variable) Lef (Ω, 3f, P) be a probability space. A 
(real) random variable is a mapping X : Ω —> R 
such that, for all A € B, 
Χ~λ{Α) 
€ 3 , where B is the Borel σ-algebra over R. 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
51 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley &: Sons, Inc. 

5 2 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
Note 2.1 Let (Ω, 3 , P) be an arbitrary probability space. Given that the σ-
algebra of Borel B inM. is generated by the collection of all the intervaL· of the 
form (—οο,χ] with x £ K, it can be demonstrated that a function X : Ω —> R 
is a random variable if and only if Χ~λ((—oo, x]) € S for all x € R. 
EXAMPLE 2.1 
Let Ω = {a, b, c}, 5 = {0, {a}, {b, c}, Ω}, P be an arbitrary probability 
measure defined over Qi. Assume X : Ω —> R given by: 
Χ(ω) = i ° if ω = α 
^ ' 
\ 1 if ω = b or ω = c 
is a random variable since 
(
0 
if 
i < 0 
{a} 
if 0 < x < 1 
Ω 
if x > 1 
while the mapping Y : Ω —> K given by 
v / 
. 
/ 0 if u = b 
Υ(ω) = < 
.. 
v / 
1^1 
it ω = a or ω = c 
is not a random variable because: 
y- 1((-co,x]) = { 6 } ^ 3 , 
i f O < x < l 
If Qi = {0, {6}, {a, c},Q} 
is taken as a σ-algebra over Ω, then Y is a 
random variable. 
▲ 
EXAMPLE 2.2 
Consider the rolling of two dice. Ω = {(i, j), i, j = 1,2, · · · , 6} is the set 
of all possible outcomes. Take 9 = ρ(Ω). Let X defined by 
Χ(ω) = i+jiiüJ 
= (i,j) € Ω 
be a random variable, due to X-1((—oo, x]) G Qf for all i g R . 
▲ 
EXAMPLE 2.3 
A light bulb is manufactured. It is then tested for its lifetime X by 
inserting it into a socket and the time elapsed (in hours) until it burns out 

DEFINITIONS AND PROPERTIES 
53 
is recorded. In this case, Ω = {t: t > 0}. Take σ-algebra 3 = ß(R Π Ω) 
(see Example 1.11 and Exercise 9.1). Define: 
X : Ω ->· R given by X(w) =w, w € Ω. 
Then: 
v - i r , 
n 
/ 0, 
if x <0 
X 
{(-οο,ζ]} = j 
{0χ] 
.f 
χ ^ 0 
Hence, the lifetime X is a random variable. 
A 
EXAMPLE 2.4 
Consider Example 2.3. Assume that the light bulbs so manufactured are 
being sold in the market and from past experience it is known that there 
will be a profit of $ 1.00 per bulb if the lifetime is less than 50 hours, a 
profit of $ 2.00 per bulb if the lifetime is between 50 and 150 hours and 
a profit of US$ 4.00 if the lifetime is more than 150 hours. Let Y be the 
profit function. Using the solution of Example 2.3, the profit function 
Y : X -> R is given by: 
1 
if t < 50 
Y(t) = { 2 if 50 < t < 150 
4 if t > 150. 
Since Y satisfies Y~l ((—oo, x}) € 3 for all x 6 R, Y is a random variable. 
EXAMPLE 2.5 
Let (Ω, 3, P) be a probability space and A € 9 fixed. The function 
XA : Ω —> R given by 
XAM = { J ί 
ω € A 
ω £ A 
is a real random variable. Indeed, if a € R, then: 
if 
a<0 
{ω e Ω : ΧΑ(ω) < a} = { Ac 
if 0 < a < 1 . 
if a> 1 
The function XA is called an indicator function of A. Other notations 
frequently used for this function are IA and \A. 
A 

5 4 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
Notation 2.1 Let X be a random variable defined over the probability space 
(Ω, 9, P). It is also defined in the set notation form 
{X e B) := {ω e Ω : Χ(ω) € B} 
with B € B. 
Theorem 2.1 Suppose that X is a random variable defined over the proba-
bility space (Ω, 3, P). The function Ρχ defined over the σ-algebra B through 
PX{B) := P({X e B}) for all B G B 
is a probability measure over (R , B) 
called the distribution of the random 
variable X. 
Proof: It must be verified that Ρχ satisfies the three conditions that define 
a probability measure: 
1. It is clear that, for all B € B, Ρχ{Β) > 0. 
2. PX{R ) = Ρ({ω e Ω : Χ(ω) € R } = Ρ(Ω) = 1. 
3. Let Ai, A2, ■ ■ · be elements of B with Ai Π Aj — 0 for all i φ 3. Then: 
/oo 
> 
= 
p[\J{XeAi} 
\ t = l 
) 
00 
= 
J£p({XeAi}) 
ΐ = 1 
oo 
= Y/Px(Ai). 
t = l 
EXAMPLE 2.6 
Let Ω = {a, b, c}, Q = {0, {a}, {b, c}, Ω} and P be given by: 
P(0) = 0 
P({a}) = I 
P({b,c}) = l 
Ρ(Ω) = 1. 
Let X : Ω —► R 
be given by: 
, . 
f 1 if ω = a 
XW-{ 
2 if 
u, = b or 
w = c. 

DEFINITIONS AND PROPERTIES 
55 
Then in this case we have, for example, that: 
Px(9) 
= 
0 
PxiW) 
= P{{a}) 
=1 
PX({2}) 
= 
P({b,c}) 
=\ 
Px(M) 
= 
1. 
Definition 2.2 (Distribution Function) Let X be a real random variable. 
The function Fx 
defined over R through 
Fx(x) 
~ 
Px((-oo,x}) 
= P(X < x) 
is called the distribution function (or cumulative distribution function 
(cdf)) 
of the random variable X. 
■ EXAMPLE 2.7 
Consider Example 2.6. The distribution function of the random variable 
X is equal to: 
0 
if x < 1 
Fx{x) 
= { 
| 
if 
1 < I < 2 
A 
1 
if 
x>2. 
EXAMPLE 2.8 
Let (Ω, 9, P) be a probability space and A € 9 be fixed. The distribu-
tion function Fx of the random variable XA is given by: 
0 
if x < 0 
Fx{x) = { P(AC) 
i f O < x < l 
▲ 
1 
if x > 1. 
EXAMPLE 2.9 
Consider the tossing of a fair coin three times and let X be a random 
variable denned by: 
X := "number of heads obtained". 

5 6 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
FM 
-0.5 
0 
0.5 
1 
1.5 
2 
2.5 
3 
3.5 
4 
4.5 
X 
Figure 2.1 
Distribution function for Example 2.9 
In this case, the distribution function of X is equal to 
Fx{x) = < 
0 
if x < 0 
| 
if 0 < x < 1 
\ 
if 
1 < x < 2 
| 
if 2 < x < 3 
1 
if x > 3 
and its graph is shown in Figure 2.9. 
A 
EXAMPLE 2.10 
Suppose a fair die is thrown two consecutive times. Let Z be a random 
variable given by: 
Z := "absolute difference of the results obtained". 
That is: 
Z{{x, y)) = \x-y\ 
with x, y € {1,2,3,4,5,6}. 

DEFINITIONS AND PROPERTIES 
57 
F ^ 
,. 
• 
o 
0 
1 
2 
3 
4 
5 
6 
7 
X 
Figure 2.2 
Distribution function for Example 2.10 
In this case the distribution function of the random variable Z is given 
by 
r o 
Fz{z) 
if 
z < 0 
if 
0 < z < 1 
_6_ 
36 
M if 
l<z<2 
24 
j f 
36 
u 
30 
36 
34 
36 
if 
if 
2<Z<3 
3 < 2 < 4 
4 < z < 5 
if 
z>5 
and its graph is presented in Figure 2.10. 
▲ 
An important result of probability theory establishes that the distribution 
Ρχ of a real random variable X is completely determined by its distribution 
function Fx (see Munoz and Blanco, 2002). The proof of this result is beyond 
the scope of the objectives of this book. Because of this, in the case of real 
random variables, it is common to identify the distribution of the variable as 
seen before as a probability measure over (R, B) with its distribution function. 
It can be seen, in the previous examples, that the distribution functions 
of the random variables considered have certain common characteristics. For 
example, all of them are nondecreasing and right continuous and the limit 

5 8 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
when x tends to oo in all cases is 1; the limit when x tends to —coin all cases 
is equal to 0. These properties are characteristics of all distribution functions 
as it is stated in the next theorem. 
Theorem 2.2 Let X be a real random variable defined over (Ω,3, P). The 
distribution function Fx satisfies the following conditions: 
1. Ifx < y, then Fx(x) < 
Fx(y). 
2. Fx{x+) 
:= lim Fx(x + h) = Fx(x) 
for all xeR. 
h-vO+ 
3. MmFx{x) 
= l. 
X—»-OO 
4. lim Fx(x) = 0 . 
Proof: 
1. If x < y, then: 
{ω € Ω : Χ(ω) < x} C {ω € Ω : Χ(ω) < y} 
Fx(x) 
= P(X <x)< P(X <y)= 
Fx(y). 
2. Let x e R b e fixed. Suppose that (x„)„ is a decreasing sequence of real 
numbers with limit x. That is: 
%\ > #2 > · · · > x and 
lim xn = x. 
n—*oo 
It can be seen that 
{X < x i } 2 {X <ΧΊ} 2 ··· 
and that 
oo 
Π {X < χη} = {Χ< Χ}. 
n=l 
Therefore, from the probability measure P, it follows that: 
Fx(x+)= 
l i m F x ( x n ) = l i m P ( X < x n ) = P(JS£:<x) = F x(x). 
n^oo 
n-t-oo 
3. It is evident that for all n € N it is satisfied that 
{X <n}C{X 
< ( n + l ) } 
and 
oo 
Ω = (J {X < n}. 
n=l 

DEFINITIONS AND PROPERTIES 
59 
So: 
lim Fx{x) = lim Fx(n) = lim P{X < n) = P{ü) = 1. 
x—foo 
n—foo 
n—»oo 
4. It is clear that, for all n G N, it is satisfied that 
{X <-n}D{X 
< - ( n + l ) } 
and in addition that 
oo 
n = l 
Concluding: 
lim F x(x) = lim Fx{-n) 
= lim P(X < - n ) = P(0) = 0. 
x—►—oo 
n—κχ> 
n—voo 
■ 
It can be shown that any function F(x) satisfying conditions {1} — {4} of 
Theorem 2.2 is the distribution function of some random variable X. 
Corollary 2.1 Let X be a real random variable defined over (Ω,3?, Ρ), 
F\ 
its distribution function and a, b 6 R with a < b; then: 
1. Fx(x~) 
:= lim Fx(x -h)= 
P(X < x). 
2. P{a < X < b) = Fx{b) - 
Fx{a~). 
3. P(a < X < b) = Fx{b) - 
Fx(a). 
4. P{a < X < b) = Fx{b-) 
- 
Fx{a~). 
5. P{a < X < b) = Fx(b-) 
- 
Fx(a). 
6. P(X = a) = Fx(a) - 
Fx(a-). 
7. If P(a < X < b) = 0, then Fx 
is constant in the interval 
(a,b). 
Proof: Proof of the items 1 and 2 will be elaborated while the rest are left 
as exercises. 
1. Let x £ R be fixed. Suppose that (x n) n is an increasing sequence of real 
numbers with limit x. That is: 
xi < X2 < ■ ■ < x 
and 
lim xn = x. 
n—>oo 
It is clear that 
{X < x i } C {X <x2} C ■·· 
and 
oo 
U {X < *»} = {X < x}-
n = l 

6 0 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
Due to this: 
Fx-(aT) = lim Fx(xn) 
= lim P(X < xn) = P(X < x). 
n—yoo 
n—*oo 
2. Given: 
Ω = {X < a} U {a < X < b} U {X > b}. 
It is obtained: 
1 = P(X <a) + P{a<X<b} 
+ P(X > b). 
That is: 
P{a < X < b} = P(X <b)- P{X <a) = Fx(b) - 
Fx{a~). 
EXAMPLE 2.11 
Which of the following functions can represent the cdf of a random 
variable ΧΊ 
(a) 
(b) 
0 
if x < f 
F(x) = ^ sinx if f < x < ^f 
1 
if x> χ . 
0 
if x < 0 
F{x) = { 2sinx if 0 < x < f 
1 
if x > f · 
(c) 
0 
if x < 0 
F(x) = { >/2sinx if 0 < x < f 
1 
if x > f · 
Solution: We will check all the four properties of -F(x). For all three 
functions: 
lim F(x) = 0 and 
lim F{x) = 1. 
X—►— OO 
X—> + 0O 
(a) The function F(x) is not a nondecreasing function. 
(b) The function F(x) is not a nondecreasing function. 

DEFINITIONS AND PROPERTIES 
6 1 
(c) The function F(x) satisfies all the four properties. 
Hence, F(x) in (c) represents a cdf but F(x) in (a) and (b) does not. 
The random variables are classified according to their distribution function. 
If the distribution function Fx of the random variable X is a step function, 
then it is said that X is a discrete random variable. If Fx is an absolutely 
continuous function, then it is said that X is a continuous random variable. 
And if Fx can be expressed as a linear combination of a step function and 
a continuous function, then it is said that X is a rawed random variable. 
■ EXAMPLE 2.12 
Let X be a real random variable whose distribution function is given by: 
0 
if x < - \ / 2 
Fx{x) = < f 
i f - \ / 2 < x < 7 r 
if X > 7Γ. 
Then X is a discrete random variable. Notice that X 
takes only the 
values — \/2 and π with probability I and I, respectively. 
A 
EXAMPLE 2.13 
Let X be a random variable whose distribution function is given by 
Fx{x) = < 
0 
if 
x < 0 
, 2 
4 
if 
0 < x < 2 
1 
if 
x > 2 
given that Fx is a continuous function. Then X is a continuous random 
variable. 
A 
EXAMPLE 2.14 
Let X be a random variable whose distribution function is given by 
Fx(x) = | 0 
if x < 0 
q + {Ϊ - q)(l - e~x) 
if x > 0 
where 0 < q < 1. The distribution function has a jump at 0 since 
X takes the value 0 with probability q. Hence, X is a mixed random 
variable. 
A 

6 2 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
Note 2.2 If X is a real continuous random variable defined over the proba-
bility space (Ω, 3, P), then P(X = a) = 0 for all a € R. 
2.2 
DISCRETE RANDOM VARIABLES 
The distribution of a discrete random variable has discontinuities that are 
called jumps. The corresponding points at which the jumps occur are called 
jump points. This concept will be established in a more precise way in the 
following definition. 
Definition 2.3 Let X be a real random variable and Fx its distribution func-
tion. It is said that Fx presents a jump at the point a € R if: 
Fx(a)-Fx(a-)^0. 
The difference Fx(a) — Fx(a~) 
is called the magnitude of the jump or the 
jump value and by the properties developed previously it is equal to P(X = a). 
EXAMPLE 2.15 
In Example 2.10, it can be seen that the random variable Z has jump 
points z = i with i = 0,1, · · · ,5. The jump values are, g, ^ , | , | , § and 
j£, respectively. 
A 
Note 2.3 If X is a real continuous random variable, then the collection of 
jump points of Fx is an empty set. 
The following result is very important since it guarantees that the number 
of jumps in a discrete real random variable is at most countable. 
Theorem 2.3 Let X 
be a discrete real random variable defined over the 
probability space (Ω, 9;, P) and Fx its distribution function. Then the number 
of jumps of Fx is at most countable. 
Proof: 
(Hernandez, 2003) Given that the magnitude of each jump is an 
element belonging to the interval (0,1] and the collection of intervals J„ with 
the form 
= 
(—-
with n = 0,1, · 
forms a partition of (0,1], it is obtained that the magnitude of each jump 
must belong to one of the intervals /„. Because the magnitudes of the jumps 

DISCRETE RANDOM VARIABLES 
63 
are probabilities, it is clear that at most there is a jump whose magnitude is 
in the interval IQ, there are at most three jumps whose magnitudes are in the 
interval Ιχ, there are at most seven jumps with magnitudes in the interval I2 
and in general, there are at most 2 n + 1 — 1 jumps whose magnitudes are in the 
interval Jn. Therefore, due to the existence of a countable number of intervals 
In and at most 2 n + 1 — 1 jumps in the interval In, 
it is concluded that the 
number of jumps is at most countable. 
■ 
From the previous result it is concluded that the range of a discrete real 
random variable is at most a countable set. 
Let X be a discrete real random variable and suppose that X takes the 
values x\,X2,-· · (all different). Let a; be a real arbitrary number. Then: 
Fx{x) = 
P{X<x) 
= P I U (X = Xi) 
= '£p(x 
= xi). 
Xi<X 
That is, the distribution function of X is completely determined by the values 
of pi with i = 1,2, · ■ · where pi := P{X = Xj). This observation motivates the 
following definition: 
Definition 2.4 (Probability Mass Function) 
Let X 
be a discrete real 
random variable with values x\, #2i · ■ · (oM different). The function ρχ defined 
in R through 
PxK 
> 
\ 0 
otherwise 
is called a probability mass function (pmf) of the discrete random variable X. 
The following properties hold for the pmf: 
1. p(xi) > 0 for all i and 
2. Σ>(χΟ - 1 . 
EXAMPLE 2.16 
Suppose that a fair die is tossed once and let X be a random variable 
that indicates the result obtained. In this case the possible values of X 
obtained are 1, · ■ · ,6. The probability mass function of X is given by: 
f I 
if x = l , 2 , · · · , 
Px[x) = \ 
y 0 
otherwise. 
6 

6 4 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
It has been seen that the probability mass function of the discrete random 
variable X determines completely its distribution function. Conversely, it is 
obtained that for any x G R it is satisfied that: 
P(X = x) = 
Fx(x)-Fx(x-). 
That is, the distribution function of the discrete random variable X deter-
mines completely its probability mass function. 
■ EXAMPLE 2.17 
Let X be a random variable whose distribution function is given by: 
FX(x) 
( 0 
if 
x < - 2 
\ 
if 
- 2 < x < \ 
| 
if 
\ < x < y/2 
1 
if x > y/2. 
In this case, the probability mass function of the random variable X is 
given by: 
if x = - 2 
f 
1 
7 
Px{x) 
f 
if x = A 
f 
if x 
V2 
. 0 
otherwise. 
EXAMPLE 2.18 
Let X be a discrete random variable with probability mass function 
given by: 
if x = - 1 
f 
5 
9 
Px(x) = < 
0 
otherwise. 
In this case, the distribution function of the random variable X is given 
by: 
r o 
if x < - l 
Fx(x) 
= « I ^ -1 < x < 
k 1 
if x > 2 -

DISCRETE RANDOM VARIABLES 
65 
EXAMPLE 2.19 
Let X be a discrete random variable with values {0, ±1,±2}. Suppose 
that P(X = -2) = P(X 
= -1) and P(X = 1) = P(X = 2) with 
the information that P(X 
> 0) = P{X 
< 0) = P(X 
= 0). Find 
the probability mass function and distribution function of the random 
variable X. 
Solution: Let 
P(X = -2) = P(X = -1) = a and P(X = 1) = P{X = 2) = ß. 
P(X > 0) 
= 
P(X = 1) + P{X = 2) = Ίβ 
P(X<0) 
= 
Ρ(Χ = -1) + Ρ(Χ = - 2 ) = 2 α . 
Given: 
P{X > 0) = P{X < 0) = P(X = 0) . 
Hence, 2a = 2/3. Therefore: 
P(X > 0) = 2a, P(X < 0) = 2a and P(X = 0) = 2a. 
Assuming total probability is 1, a = | . The probability mass function 
of the random variable X is given by: 
r i 
if i = ± i , ± 2 
P(X = i)= 
1 1 
if i = o 
[ 0 
otherwise. 
The distribution function of the random variable X is given by: 
( 0 
x < - 2 
I 
- 2 < x < - l 
i 
- K x < 0 
F(x) = { 
| 
0 < x < 1 
I 
1 <x<2 
1 
x > 2 . 

6 6 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
EXAMPLE 2.20 
A fair coin is tossed two times. Let X be the number of heads obtained. 
1. Find the probability mass function of the random variable X. 
2. Determine P(0.5 < X < 4),P(-1.5 < X < 1) and P(X < 2). 
Solution: 
1. The random variable X takes values 0, 1 and 2: 
P(X = 0) 
= 
P({T,T}) = i 
P(X = 1) = 
P({T,H}) 
+ P({H,T}) 
= \ + \ = \ 
P(X = 2) 
= 
P({H,H}) 
= ±. 
The probability mass function of the random variable X is given by 
0 
1 
2 | 
px(x) 
\ 
\ 
\ 
2. 
P(0.5 < X < 4) 
= 
P{X = 1) + P(X = 2) = ^ 
P(-1.5 < X < 1) 
= 
P(X = 0) = \ 
P(X<2) 
= 
P(X = 0) + P(X = l) + P{X = 2) = l. 
A 
EXAMPLE 2.21 
A random variable X can take all nonnegative integer values and 
P(X = TO) is proportional to am{0 < a < 1). Find P{X = 1). 
Solution: Let pm — P(X = m) = kam where A; is a constant. Also 
since pm is a pro/, we have: 
oo 
m=0 
oo 
Σ fc«m = i 
m=0 
1 
1 - a 
Pi = k · a = (1 — a)a. 

CONTINUOUS RANDOM VARIABLES 
67 
2.3 
CONTINUOUS RANDOM VARIABLES 
In the study of continuous random variables, special emphasis is paid to the 
absolutely continuous random variables defined as follows: 
Definition 2.5 (Absolute Continuous Random Variables) 
Let X 
be a real random variable defined over the probability space (Ω, 3ί, P). 
It is said that X is absolutely continuous if and only if there exists a nonneg-
ative and integrable real function 
fx such that for all x € R it is satisfied 
that: 
Fx(x) = Γ fx(t)dt. 
(2.1) 
J—oo 
The function fx 
receives the name probability density function (pdf) or sim-
ply density function of the continuous random variable X. 
Note 2.4 A probability density function f satisfies the following properties: 
(a) f(x) > 0 for all possible values of x. 
ß) 
jr^mdx^i. 
Property (a) follows from the fact that F(x) is nondecreasing and hence its 
derivative f(x) > 0, while (b) follows from the condition that lim F(x) = 1. 
x—yoo 
It is clear that any real-valued function satisfying the above two properties will 
be a probability density function of some continuous random variable. 
EXAMPLE 2.22 
Let X be a random variable with distribution function given by: 
0 
if x < 0 
Fx{x) = { x 
if 0 < x < 1 
1 
if x > 1. 
The function fx defined by 
, , , _ i 
1 
i f O < x < l 
IxW 
-
j
0 otherwise 
is a pdf of the random variable X. 

6 8 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
EXAMPLE 2.23 
Let X be a random variable with distribution function given by: 
0 
if x < 0 
Fx(x) 
\ 
if 0 < x < 2 
1 
if x > 2. 
It is easy to verify that the function fx given by 
f f 
if 0 < x < 2 
^ 0 
otherwise 
is a pdf of the random variable X. 
A 
Suppose that X is an absolutely continuous random variable with probability 
density function fx. Some properties that satisfy this function will be deduced 
shortly. 
It is known that: 
/
OO 
[X 
fx(t)dt= 
lim / 
fx(t)dt 
-oo 
'-""J-oo 
= \imFx{x) 
= 1. 
If a, 6 € K, then: 
P(a<X<b) 
= 
Fx(b)-Fx(a) 
/
b 
pa 
fx(x)dx- 
/ 
fx{x)dx 
-oo 
J — oo 
= / 
fx(x)dx. 
Ja 
Notice that because Fx is a continuous function, the previous integral is also 
equal to P(a < X < b), P(a < X < b) and P{a < X < b). Moreover, it is 
obtained that 
P(X EB)= 
f fx(x)dx 
(2.2) 
JB 
for all Borel sets B. The proof of this result is beyond the scope of this text. 
It is clear that the integral given in (2.2) must be interpreted as a Lebesgue 
integral given that the Riemannn integral is not defined for all Boolean sets. 
Nevertheless, if B is an interval or a union of intervals, it makes sense that, 
for practical effects, the Riemann integral is sufficient. 
Since Fx(x) is absolutely continuous, it is differentiable at all x except 
perhaps at a countable number of points. Using the fundamental theorem of 

CONTINUOUS RANDOM VARIABLES 
69 
integrals, we have fx (x) = 
F^x' 
for all x where Fx (x) is differentiable. For 
the points 0,1,0,2,··· ,an, ■ ■ ·, where Fx{x) is not differentiable, we define: 
dFx(x) 
dx 
With this we can conclude that: 
= 0. 
dFx{x) 
fx(x) 
= — τ ^ 
for 
all x. 
ax 
This last property implies that, for Ax « 0, it is obtained that: 
P(x-Ax<X<x 
+ Ax) = Fx(x + Ax) - Fx(x - Ax) 
« 2 Δ χ / χ ( χ ) . 
That is, the probability that X belongs to an interval of small length around 
x is the same as the probability density function of X evaluated in x times 
the interval's length. 
When the context in which the random variable is referenced is clear, we 
will eliminate the subscript X in the distribution function as well as in the 
density function. 
■ EXAMPLE 2.24 
Let X be a random variable with density function given by: 
, M _ ί kx (1 - x) 
if 0 < x < 1 
^ ' 
1^ 
0 
otherwise. 
Determine: 
1. The value of k. 
2. The distribution function of the random variable X. 
3. P ( - 1 < X < 
\). 
Solution: 
1. Given that 
f(x)dx = k 
(x — x2)dx = k-. 
-00 
JO 
" 
It is obtained that k — 6. 
2. 
F(x) = Γ f(t)dt 
J—00 
0 
if 
x < 0 
= { 3x2 - 2x3 
if 0 < x < 1 
1 
if 
x > 1. 

7 0 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
3. 
p ( - l < X < i ) = F ( i ) - F ( - l ) 
EXAMPLE 2.25 
Consider Example 2.3. Let X be the random variable representing the 
lifetime of the light bulb. The cdf of X is given by: 
(
0 
x<0 
kx 
0 < x < 100 
1 
x > 100. 
1. Determine k. 
2. Find the probability that the light bulb lasts more than 20 hours but 
no more than 70 hours. 
Solution: 
1. Since F(x) is a cumulative distribution function of the continuous ran-
dom variable X, it is a continuous function. Applying right continuity 
at x = 100, we get: 
lOOfc = 
1 
k 
= 
löö· 
2. The probability that the light bulb lasts more than 20 hours but no 
more than 70 hours is given by: 
P(20 < X < 70) 
= 
F(70) - F(20) 
= 
0.5. 
A 
EXAMPLE 2.26 
Let X be a random variable whose distribution function is given by: 
F(x\ 
= { 1 - (1 + Φ~χ 
if a; > 0 
^ ' 
y 0 
otherwise. 

CONTINUOUS RANDOM VARIABLES 
7 1 
1. Determine the density function of X. 
2. Calculate P{X 
<\). 
Solution: 
1. 
2. 
/(*) -{ 
P[X< 
I) 
xe 
0 
= 
= 
= 
,-x 
Ί 
1 -
if x>0 
otherwise. 
3) 
4 r 
4.4625 
1 
3 
x 1(T2. 
EXAMPLE 2.27 
A continuous random variable X has density function given by 
t(\—f 
kxe~Xx 
if x > 0 
^ ' 
\ 0 
otherwise 
where λ > 0. 
1. Determine k. 
2. Find the distribution function of X. 
Solution: 
1. Given that 
/
oo 
roo 
JU 
f(x)dx 
= k 
xe~Xxdx 
= 
-^. 
-oo 
7θ 
λ 
It is obtained that fc = λ2. 
2. 
F(x) = /" 
f(u)du 
J — OO 
_ f -λ(χβ- λ χ) + 1 - e-A:c 
if i > 0 
^ 0 
otherwise. 

7 2 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
2.4 
DISTRIBUTION OF A FUNCTION OF A RANDOM VARIABLE 
Suppose that X is a real random variable defined over the probability space 
(Ω, 3, P) and let g be a function such that Y = g(X) 
is a random vari-
able defined over (Ω, 3 , P). We are interested in determining (if possible) the 
distribution function of the random variable Y in terms of the distribution 
function of the random variable X. 
■ EXAMPLE 2.28 
Let X be a random variable and Y be defined as Y =| X |. We know 
that the modulus function is continuous and hence Y is also a random 
variable. Let Fx be the cdf of X. The cdf of Y is given by: 
P(Y<y) = P(\X\<y) 
= 
P(-y<X<y) 
= P(X <y)- P(X < -y) + P(X = -y) 
= 
Fx(y) - Fx(-y) 
+ P(X = -y). 
If X is a continuous random variable, then P(X = —y) = 0. When 
X is a continous random variable, the cdf of Y is given by: 
F („\ = ί Fx^ - Fx(-y) 
if y > ° 
YKy> 
\ 0 
otherwise. 
When X is a discrete random variable, the cdf of Y is given by: 
Fv(v) = I Fx{y) ~ Fx{~v) + P{X = ~V) if V > ° 
A 
yy> 
\ 0 
otherwise. 
EXAMPLE 2.29 
.2 
Let X be a random variable with cdf Fx(x) = -4= f_ooe 
2 dt. Find 
the cd/of F = X+. 
Solution: We know that: 
= *+ = {o
X' ί 
X>0 
<0. 

DISTRIBUTION OF A FUNCTION OF A RANDOM VARIABLE 
7 3 
The cdf of Y is given by: 
FY(y) 
= 
P(Y<y) 
= 
P(X+<y) 
0 
if y < 0 
P{X<0) 
if y = 0 
P(X <0) + P(0<X 
<y) 
if 
2/>0 
t 0 
if t/ < 0 
4 = f° e-^di 
if 
j/ = 0 
*Wv) = < 
\/2π J-oo 
-4- Γ 
e-Vdi 
if y > 0. 
The distribution function of V has a jump at 0. Hence, Y is a mixed 
random variable. 
▲ 
EXAMPLE 2.30 
Let X be a discrete or continuous real random variable. Find the cdf of 
Y := aX + b where a, b € R and α ^ 0. 
Solution: It is clear that: 
= P ( a X + 6 < y ) 
= < 
P (X < *=*) 
if a > 0 
■P (X > *=*) 
if a < 0 
"x (·?) 
if 
a > 0 
1 - Ρ χ ( ( ^ ) ~ ) 
if 
a < 0 . 
EXAMPLE 2.31 
Let X be a real random variable with density function given by: 
fx(x) 
= 
\ 
if - 1 < x < 1 
0 
otherwise. 

7 4 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
{ 
Let Y = \X\. Then: 
FY(y) = P(Y < y) 
P(\X\<y) 
if J / > 0 
0 
if j / < 0 
_ f P{-y<x<y) 
if y>o 
~ \ 0 
if y < 0 
_ f Fx(y)-Fx(-y) 
if v > 0 
i 0 
if 
j/ < 0. 
Therefore, the density function of the random variable Y is given by: 
My> ~ { 0 
if y < 0 
= f 1 i f 0 < y < l 
A 
I 0 otherwise. 
EXAMPLE 2.32 
Let X be a real random variable with density function given by: 
. / x J 1 
i f 0 < x < l 
/ x W - \ 0 otherwise. 
Let Y = ex. In this case, it is obtained that: 
FY{y) = P(Y < y) 
P(X<\ny) 
if y>0 
0 
if y < 0 
Fx(lny) 
if y > 0 
0 
if 2/ < 0. 
Therefore, the density function of the random variable Y is given by: 
ly) if y > 0 
-{ 
( 
-{ 
i 
if 0 < l n y < 1 
/y(y) 
. 
otherwise 
0 
otherwise. 

DISTRIBUTION OF A FUNCTION OF A RANDOM VARIABLE 
7 5 
EXAMPLE 2.33 
The distribution of a random variable X is given by: 
0 
x < 0 
6 + 3° 
Fx(x) = { h + hx 
0 < x < l 
x> 1. 
Find the distribution of Y = aX + ß, a > 0. 
Solution: Since the distribution function of X has jumps at 0 and 1, 
X is a mixed random variable. Using Y = aX + ß, the distribution 
function of Y is given by: 
FY(y) 
= 
P(Y<y) 
= P(aX + 
ß<y) 
= 
P\X<y Ή 
0 
y<ß 
i + i ^ 
ß<y<a+ß 
1 
a + ß < y. 
Note that the distribution function of Y has jumps at ß and a + ß. 
Hence, Y is also a mixed random variable. 
▲ 
EXAMPLE 2.34 
Let X be a discrete random variable with probability mass function 
given by: 
| x 
| - l | o | i | 2 | 3 | 
i px(*) \k i ? m ? i H 
Let Y = X2. It can be seen that the possible values of Y are 0,1,4 and 
9. Additionally: 
y 
I o I i I 4 I 9 
P<Y = V)\ I I f If I I 

7 6 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
The corresponding distribution functions of X and of Y are: 
0 
if x < - 1 
Fx(x) 
FY(y) 
if 
- 1 < x < 0 
if 0 < x < 1 
if 
1 < x < 2 
if 2 < x < 3 
if 
x > 3 
f 0 
if x < 0 
f 
if 0 < x < 1 
| 
if 
1 < x < 4 
f 
if 4 < x < 9 
1 
if x > 9. 
EXAMPLE 2.35 
Let X be a random variable with probability mass function 
P{X = x) = ( n J ρχ(1-ρ)η-χ, 
x = 0,1, · · · , n. Find the distribution 
of Y = n - X. 
Solution: The pmf of Y is given by: 
P(Y = y) 
= 
P(n-X 
= y) 
= 
P(X = 
n-y) 
-,n-v(\ _ 
(I-P) 1 
( JJ )(1-P)V-", ί/ = 0,1,···,η. 
EXAMPLE 2.36 
Let X be a random variable with distribution over the set of integers 
{ - η , - ( η - Ι ) , · · · ,-1,0,1,··· , ( n - l ) , n } given by: 
P(X = x) = {0-+1 
^ x = 0,±l,±2,··· ,±n 
otherwise. 

DISTRIBUTION OF A FUNCTION OF A RANDOM VARIABLE 
7 7 
Find the distribution of 
(i) 
| X | and (ii) 
X2. 
Solution: (i) 
Let Y =\ X |. For values of X, the corresponding values 
of Y are given in the following table: 
| X | -n,n 
| - ( n - l ) , n - l | ··· | -1, 1 | 0 | 
| Y | 
n 
| 
n - 1 
| ··· | 
1 
| 0 | 
For y = 0: 
P ( F = 0) = P(X = 0) 
P(Y = y) = P(X = -y) + P(X = y) 
For j / = 1,2,··· ,n: 
2n + l 
1 
+ 
1 
2 n + l 
2n + 1 
2n + 1 
Hence, the probability mass function of Y is given by: 
ί ώ 
if K = 0 
P(l r = y ) = ^ 
2^T 
if 
» = 1 , 2 , · · · , η 
[ 0 
otherwise. 
(ii) 
Let Y = X2. 
Using a similar approach, the probabiUty mass 
function of Y is given by 
1 
P(Y = y) = { 
a„+i 
if y = 0 
2 
jf 
?/ _ 
l 2 o2 Q2 . 
2 n + l 
u 
£/ — 1 ) z 
i"3 i 
0 
otherwise. 
,η' 
EXAMPLE 2.37 
Suppose that X is a continuous random variable. Define: 
Y 
f l 
if 
\ 
- i 
if 
X > 0 
X < 0 . 
Find the cdf of Y. 
Solution: 
Therefore: 
P(Y = 1) 
= 
P(X > 0) 
P{Y = -1) 
= 
P(X < 0). 
0 
y < - l 
P(Y<y)={ 
P(X<0) 
-l<y<l 
1 
1 < y < oo. 

7 8 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
In this example, note that X is a continuous random variable while Y 
is a discrete random variable. 
▲ 
Theorem 2.4 Let X be an absolutely continuous real random variable with 
density function fx.Ifhisa 
strictly monotonous and differentiable function, 
then the probability density function of the random variable Y = h(X) is given 
by 
/x(/i_1(i/)) ^n^(y) 
if y = h(x) for some x 
0 
if y Φ h(x) for all x 
where /ι_1(·) is the unique inverse function 
ofh(-). 
fr(y) 
Proof: Suppose that h is a strictly increasing function and let y € K such 
that y = h{x) for some x. 
Then: 
FY(y) = P{Y < y) 
= P(h(X) < y) 
= 
P(X<h-\y)) 
= 
Fxih-'iy)). 
Differentiating yields 
fy(y) = 
fx(h-1(y))-j^h-1(y) 
= 
fx(h-1(y)) dy h-\y) 
given that the derivative of h is positive. 
Let / i b e a strictly decreasing function and y € K such that y = h(x) for 
some x. Then: 
FY(y) = 
P(Y<y) 
= P(h(X) < y) 
= 
P{X>h-\y)) 
= 
l-Fx(h-\y)). 
Differentiating yields 
fy{y) = 
-fx{h-\y))-h-\y) 
fx{h~\y)) 
dy h-Hv) 

DISTRIBUTION OF A FUNCTION OF A RANDOM VARIABLE 
7 9 
because in this case the derivative of h is negative. 
If y G K is such that y φ h(x) for all x, then, Fy(y) = 0 or Fy(y) = 1, 
that is, fy(y) = 0. 
■ 
Corollary 2.2 Let h be piecewise strictly monotone and continuously differ-
entiable, that is, there exist intervals Ii,l2,··· 
,In which partition R such that 
h is strictly monotone and continuously differentiable on the interior of each 
Ii. Let Y = h(X). 
Then the density of Y exists and is given by 
fy(y) = 
^Mhk1(y)) 
fc=l 
dK\y) 
dy 
where hk
 1 is the inverse of h in Ik-
■ EXAMPLE 2.38 
Let X denote the measurement error in a certain physical experiment 
and let Y denote the square of the denned random variable X. Given 
that the pdf of X is known, find the pdf of Y. 
Solution: Given that X is a continuous random variable and it denotes 
the error in the physical experiment. In order to find the pdf of the 
newly defined random variable Y, we shall first obtain the cdf of Y and 
then by differentiating the cdf we will obtain the corresponding pdf. 
Let Fx(x) denote the cdf of the given random variable X. The cdf 
of Y is given by: 
P(Y<y) 
= 
P(X2<y) 
= 
P{-y/y 
< X < y/y) 
= 
P(X < y/y) - P(X < -y/y) 
= 
Fx(y/y) 
- Fx{-y/y) 
. 
Thus, we have obtained the cdf of the newly defined random variable 
Y. Now, by differentiating the cdf of Y, we get the pdf of Y: 
Mv) J
^ 
[fx(Vy) + fx(-Vv)] if y > o 
I 0 
otherwise. 
EXAMPLE 2.39 
Let X be a random variable with distribution 
fx(x) 
= —;=e 
2 , —oo < x < oo. 
Define Y = ex. Find the pdf of Y. 

8 0 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
Solution: Consider Y = h(X) = ex is a strictly increasing function of 
x and also h(X) is differentiate. Now: 
y = h(x) = ex. 
Then: 
/i_1(y) = x = lny 
dh-\y) = 1 
dy 
y' 
Since Y = ex satisfies all the conditions of Theorem 2.4, we get: 
My) = fx(h~\y)) 
Hence, the pdf of Y is given by: 
dh-\y) 
dy 
1
 
ze-W*vYl 
y/2n 
y' 
l = e-3(' n3/) 2 
if y > 0 
I/V2-7T 
My) = ; 
0 
otherwise. 
2.5 
EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
Let X be a real random variable. It is known that its probabilistic-type 
properties are determined by its distribution function Fx(-). Nevertheless, it 
is important to know a group of values that "summarize" in a certain way 
this information. For example, we want to define an "average" of the values 
taken by X and a measurement that "quantifies" by how much the values of 
X vary with respect to that value. This information will be given by two real 
values called expected value (average) and variance of the random variable, 
respectively. These concepts are stated precisely in the next definitions. 
Definition 2.6 (Expected Value) Let X be a real random variable defined 
over the probability space (Ω, 3 , P). 
1. If X is a discrete random variable with values x\,X2,···, 
it is said that 
X has an expected value if: 
J2\xk\P(X 
= 
xk)<oo. 
fc=l 
In such a way, the expected value E(X) 
(mathematical expectation, av-
erage) of X is determined as: 
oo 
E(X) = 5>feP(X = xk). 
fc=l 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
8 1 
2. If X 
is a continuous random variable with density function fx, it is 
said that X has an expected value if: 
f 
J — ( 
\x\fx{x)dx 
< oo. 
In this case, the expected value E(X) 
(mathematical expectation, aver-
age) of X is determined as: 
/
oo 
Xfx{x)dx. 
-oo 
Note 2.5 If X 
is a real random variable that takes only a finite number of 
values, then E(X) always exists. 
EXAMPLE 2.40 
Suppose that a normal die is thrown once and let X 
be a random 
variable that represents the result obtained. It is clear that: 
fc=l 
EXAMPLE 2.41 
Let (Ω, 3 , P) be an arbitrary probability space and 4 e S fixed. It is 
known that X :— XA is a discrete random variable that only takes the 
values 0 and 1 with probability P(AC) and P(A), respectively. Therefore, 
E{X) exists and it is equal to P{A). 
▲ 
EXAMPLE 2.42 
Let X be a discrete random variable with pmf given by: 
, , 
ί e~% 
if x = 0,l,2,··-
p(x) = i 
I 0 
otherwise. 

8 2 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
Then: 
°° 
qfe 
Ε{Χ) = Σ>"-*% 
°° 
ofe 
= e"3 V—-
j = o ·>■ 
= 3e~3e3 = 3. 
▲ 
EXAMPLE 2.43 
Let X be a continuous random variable with pdf given by: 
2e-2x 
if x > 0 
0 
otherwise. 
,, . 
Γ 2e-2x 
if x > 0 
Given that: 
/
oo 
ΛΟΟ 
-I 
|x|/(x)dx = / 
2xe~2x = -. 
-oo 
JO 
2 
It is concluded that the expected value of X exists and it is equal to 
i 
A 
EXAMPLE 2.44 
Let X be a random variable with values in Z. Suppose that 
3*0 
f F 
if 
[ 0 
if j = 0 
where c > 0 is a constant such that 
Σ3-»· 
Given that 
£(X) does not exist. 
▲ 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
83 
■ EXAMPLE 2.45 
Let X be an absolutely continuous random variable with density function 
given by 
f{*) =-ΓΓΓ-2\ 
i f i e R 
π(α* + χ') 
where a > 0 is a constant. 
Then 
Jx\f(x)dx 
= -Jo 
- ? _ ? e f a = oo, 
which means that E(X) does not exist. 
A 
The following result allows us to find the expected value of an absolutely 
continuous random variable from its distribution function. 
Theorem 2.5 Let Y be an absolutely continuous random variable with den-
sity function f. If E(Y) exists, then: 
E(Y) = / 
[1 - FY{y)]dy - / 
FY(-y)dy 
. 
Jo 
Jo 
Proof: 
Γ°° 
E(Y) = / 
xf(x)dx 
J—oo 
/•oo 
ΛΟ 
= / 
xf(x)dx 
+ / 
xf(x)dx 
Jo 
J-oo 
= lo°° (j[ X d») f{x)dx - J 
^
X 
dy^j f(x)dx 
ΛΟΟ 
ΛΟΟ 
ΛΟΟ 
r—y 
— \ 
\ 
f{x)dxdy — I 
/ 
f(x)dxdy 
JO 
Jy 
Jo 
J—oo 
/•oo 
/·οο 
= / 
P(Y > y)dy - 
P(Y< 
-y)dy 
Jo 
Jo 
= / 
[l-FY(y)]dy- 
FY(-y)dy 
. 
Jo 
Jo 
This is illustrated in Figure 2.3. 
■ 
Sometimes we are faced with a situation where we must deal not with the 
random variable whose distribution is known but rather with some function 
of the random variable as discussed in the previous section. 
Suppose that X is a random variable. Let g : R —¥ R be a function such 
that Y = g(X) is also a random variable and whose expected value exists. It 
is clear that, to calculate E(Y), we need to find the density function of the 
random variable Y. However, fortunately there is a method that allows us to 

8 4 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
F(y) 
^—-—^^^ 
(-) 
(+) 
^ 
^~~~~ 
y 
Figure 2.3 
Illustration of expectation value for continuous random variable 
do the calculations in a simpler way, known as the "law of the unconscious 
statistician". This method has been stated in the following theorem. 
Theorem 2.6 Let X be a real random variable with density function fx and 
g : K —> R a function such that Y = g(X) is a random variable. Then 
yj<7(x)px(x) 
if X is a discrete random variable 
E(g(X)) = { f_oog(x)fx(x)dx 
if X is an absolutely continuous 
random variable 
whenever the sum, in the discrete case, or the integral in the continuous case 
converges absolutely. 
Proof: 
1. Suppose that X is a discrete random variable that takes the values 
x\,X2,··· 
■ In this case the probability mass function of X is given by: 
Px(x) = I o 
P(X = x) 
if χ = χι,#2>·· 
otherwise. 
The random variable Y = g(X) takes the values g{xi),g(x2), ■ · · . It is 
clear that some of these values can be the same. Let us suppose that yj 
with j > 1 represents different values of g{xi). Then, grouping all the 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
8 5 
g(xi) that have the same value, it can be obtained that: 
i 
3 i:ff(x;)=ifj 
= Σ^ Σ M*«) 
j 
i:g(xi)=yj 
= Συ3Ρ(9(Χ) = vA 
= YjviP{Y = vA 
3 
= E(Y) = 
E(g(X)). 
2. Let X be an absolutely continuous random variable with density func-
tion fx. Suppose that g is a nonnegative function. Then 
ΛΟΟ 
ΛΟΟ 
E(g(X)) = / 
P(g(X) > y)dy - / 
P(g(X) < -y)dy 
Jo 
Jo 
/>00 
= / 
P(g(X) > y)dy 
Jo 
=Γ 
{L
fx{x)dx)
dy 
where B := {x : g(x) > y}. Therefore: 
«•oo 
rg{x) 
pco 
pg(x) 
E(g(X)) = / 
/ 
fx(x)dydx 
Jo Jo 
/•oo 
= / 
g{x)fx{x)dx. 
Jo 
The proof for the general case requires results that are beyond the scope 
of this text. The interested reader may find them in the text of Ash 
(1972). 
EXAMPLE 2.46 
Let X be a continuous random variable with density function given by: 
, . _ f 2x if 0 < x < 1 
■^ 
\ 0 
otherwise. 

8 6 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
Then: 
/
OO 
x3f{x)d. 
-OO 
= / 
2x4dx 
Jo 
2 
= 5- 
A 
Next, some important properties of the expected value of a random variable 
are presented. 
Theorem 2.7 Let X 
be a real random variable. 
1. IfP(X 
> 0) = 1 and E(X) exists, then, E{X) > 0. 
2. E(a) = a for every constant a. 
3. If X is bounded, that is, there exists a real constant M > 0 such that 
P{\X\ < M) = 1, then E(X) 
exists. 
4- If a and ß are constants and if g and h are functions such that g{X) and 
h(X) are random variables whose expected values exist, then the expected 
value of (ag(X) + ßh{X)) 
exists and: 
E(ag(X) 
+ ßh{X)) = aE(g(X)) 
+ 
ßE(h(X)). 
5. If g and h are functions such that g(X) and h(X) 
are random variables 
whose expected values exist and if g(x) < h(x) for all x, then: 
E{g{X)) < 
E(h{X)). 
In particular: 
\E{X)\ < E{\X\) . 
Proof: 
1. Suppose that X is a discrete random variable that takes the values 
#i,X2,··· · Given that P(X 
< 
0) 
= 
0, it is obtained that 
P{X = Xj)=0 
for all Xj < 0. Therefore: 
E(X) = Y^XiP(X = Xi) 
i 
= Σ 
XiP(X = Xi) > 0 . 
i:xi>0 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
8 7 
If X is an absolutely continuous random variable with density function 
/, then: 
ί·00 
ί·00 
E{X) = / 
[1 - Fx(x)}dx 
- / 
Fx(-x)dx 
Jo 
Jo 
= / 
[1-Fx(x))dx 
Jo 
/•OO 
= / 
P(X > x)dx > 0 . 
Jo 
2. 
E(a) = aP{X = a) 
= a . 
3. If X 
is a discrete random variable that takes values Xi,X2> ■ · · > then, 
because P(|X| > M) = 0, it can be supposed that {x\,X2,···} 
C 
[—M,M]. In conclusion: 
5 3 las.l P{X = Xi) < Μγ^Ρ(Χ 
= Xi) = 
M<oo. 
i 
i 
If X is an absolutely continuous random variable with density function 
/, then, given that P(|X| > M) = 0, it can be supposed that f(x) = 
0 for all x $ [-M, M]. Therefore: 
/
OO 
rM 
\x\ f(x)dx = I 
\x\ f(x)dx 
-oo 
J — M 
/
M 
f(x)dx = M 
■M 
4. The proof for the continuous case is elaborated here while the discrete 
case is left as an exercise. If X is an absolutely continuous random 
variable with density function /, then: 
/
OO 
ΛΟΟ 
\ag{x) + ßh{x)\ f{x)dx < / 
\ag(x)\ 
f(x)dx 
-oo 
J — oo 
/
oo 
\ßh{x)\f{x)dx 
-oo 
/ o o 
\g(x)\f{x)dx 
-oo 
/ o o 
|/i(x)|/(x)dx<cc. 
-oo 

8 8 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
The expected value of (ag(X) + ßh(X)) exists and it is clear that: 
/
OO 
ΛΟΟ 
i»00 
\ag{x) + ßh(x)]f(x)dx 
= / 
[ag(x)]f(x)dx + / 
[ßh{x)]f{x)dx 
-oo 
J — oo 
J— oo 
= aE(g(X)) 
+ 
ßE(h(X)). 
5. The proof for the continuous case is elaborated here while the discrete 
case is left as an exercise. If X is an absolutely continuous random 
variable with density function /, then: 
/
OO 
ΛΟΟ 
g{x)f(x)dx 
< / 
h(x)f(x)dx 
= 
E(h(X)). 
-oo 
«/— oo 
- | X | < X < | X | 
Given that 
it is obtained that: 
That is: 
E(- \X\) < E{X) < E \X\ 
-E(\X\)<E(X)<E(\X\). 
\E(X)\<E(\X\). 
The expected value of the random variable is the "first central moment" of 
a variable around zero. In general, central moments around zero of random 
variables are the expected values of the power of the variable. More precisely: 
Definition 2.7 (Central Moment Around Zero) 
Let X be a real random variable. The rth central moment of X around zero, 
denoted by μΓ, is defined as 
μτ := 
E(Xr) 
whenever the expected value exists. 
The following result allows to confirm that if s < r and μτ exists, then 
μ3 exists. 
Theorem 2.8 If X 
is a random variable such that μτ exists, then μ3 exists 
for all s < r. 
Proof: 
Proof for the continuous case is elaborated here while the discrete 
case is left for the reader. 
Given that 
Ι χ Ί < 1 + |χΊ 
f o r x e R 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
8 9 
it is obtained that: 
poo 
/
OO 
ΛΟΟ 
\x°\fx(x)dx 
< 
/ 
[l + 
\xr\\fx(x)dx 
-oo 
J—oo 
/
OO 
\xr\fx(x)dx 
< oo. 
■oo 
Definition 2.8 (Central Moment Around the Average) Let X be a real 
random variable whose expected value exists. The rth central moment of X 
around E(X) is defined as 
μΓ := E{[X - 
E{X)Y) 
whenever the expected value exists. 
The following result allows to relate the rth order moments around the 
mean with the rth order moments around the origin. 
Theorem 2.9 Let X 
be a random variable whose expected value exists. If 
μτ exists, then: 
Proof: 
= 
E{X-E{X))T 
= 
£ ( χ - μ ' ι ) Γ 
-
 E έ(;Κ*'.>'-' 
fc=0 
r-fc 
fc=0 X ' 
= Σ(>*(-"ί) 
r-k 
fc=0 
Note that for any random variable whose expected value exists it is satisfied 
that μο = 1 and μι = 0. The second central moment of X, around the mean, 
receives the name of variance of the random variable X 
and it is generally 
denoted by σχ; the square root of the variance is called standard deviation 
of X and it is denoted usually by σχ. Other notations with frequent use for 
the variance of X are Var(X) and V(X). In this text, any of these notations 
will be used indistinctively. 

9 0 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
The variance measures the dispersion of the values of the variable around 
its mean. The term (X — E(X))2 
is the square of the distance from X to 
E(X) and therefore, E(X — E(X))2 
represents the average of the squares of 
the distances of each value from X to E(X). Then, if a random variable has a 
small variance, the possible values of X will be very close to the mean, while 
if X has large variance, then the values of X 
tend to be far away from the 
mean. 
In the applications (see Ospina, 2001) a measure of relative dispersion is 
commonly used. It is called variation coefficient and is denned as: 
CV(X):=^ifE(X)*0. 
When |£(X)| is not near zero, CV (X) is used as an indicator of how large 
the variance is. Empirically, it has been seen that when |CV(X)| < 0.1 the 
variance generally is small. 
Some important properties of the variance of a random variable are pre-
sented next. 
Theorem 2.10 Let X 
be a random variable whose expected value exists and 
a, ß € R are constants. 
Then: 
1. Var{X) > 0. 
2. Var(a) = 0. 
3. Var{aX) 
= 
a2Var{X). 
4. Var{X + ß) = 
Var(X). 
5. Var(X) = 0if and only if P{X = E(X)) = 1. 
Proof: 
1. It is clear from the definition of variance and from the properties of the 
expected value. 
2. 
Var{a) = E(a - E(a))2 = E{0) = 0. 
3. 
Var{aX) 
= E[aX - 
E{aX)]2 
= E(aX - 
aE(X))2 
= a2E{X - 
E{X))2 
- 
a2Var(X). 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
9 1 
4. 
Var(X + ß) = E[(X + ß) - E(X + ß)}2 
= E[X + ß- 
E{X) - ß}2 
= 
Var{X). 
5. (a) If X = E{X) 
with probability 1, it is clear that Var(X) = 0. 
(b) Suppose that Var(X) = 0, and let a := E(X). 
If P(X =. a) < 1, then c > 0 exists such that 
P((X - a)2 > c) > 0 
given that 
(x-a)2 
> cA,
{(x_a)2>c}. 
Then 
E(X-a)2>E{cX{{x_ay>c}) 
Var(X) 
> 
cE(X{(X-a)2>c}) 
Var{X) > cP((X - a)2 > c) > 0, 
which is a contradiction. Therefore P(X — E(X)) = 1. 
■ 
To calculate the variance of a random variable, the following result will be 
very useful. 
Theorem 2.11 Let X be a random variable whose E(X2) 
exists. Then: 
Var(X) = E{X2) - 
{E{X))2. 
Proof: 
Var(X) 
= 
E(X - 
E(X))2 
= 
E(X2-2XE{X) 
+ 
(E(X))2) 
= 
E{X2) - 2E(X)E(X) 
+ 
E{E(X))2 
= 
E(X2) - 2(E(X))2 
+ 
(E(X))2 
= 
E{X2)-{E(X))2. 
■ 

9 2 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
EXAMPLE 2.47 
Suppose that a fair die is thrown once and let X be a random variable 
21 
6 
6 
'6'" 
6 
that represents the result obtained. It is known that E(X) = 4r- and: 
fc=l 
Then: 
Var(X) = — « 2.92 . 
A 
EXAMPLE 2.48 
Let X be defined as in Example 2.41. Then: 
E{X2) = P(X = 1) = P(A). 
Therefore: 
Var(X) = P(A) - [P(A)}2 
= P(A)P(AC). 
A 
EXAMPLE 2.49 
Let X be defined as in Example 2.42. Then in this case: 
°° 
ofc 
E(X>) = Σ^- 3|τ 
fe=0 
= «-8Eü+1)V 
= e-3[9e3+3e3] 
= 12. 
Therefore: 
Var(X) = 12 - 9 = 3. 
▲ 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
9 3 
EXAMPLE 2.50 
Let X be denned as in Example 2.43. Then: 
Therefore: 
/
oo 
x2f(x)dx 
-OO 
/•OO 
= / 
2x2e~2xdx 
Jo 
1 
Var(X) = \ ~ \ = \ 
The probability generating function {pgf) plays an important role in many 
areas of applied probability, in particular, in stochastic processes. In this 
section we will discuss py/'s, which are defined only for nonnegative integer 
valued random variables. 
Definition 2.9 (Probability Generating Functions) Let X be a 
nonnegative integer-valued random variable and let pk = P(X = fc), k = 
0,1,2, · · ■ with XlfcLoPk = 1· The pgf of X is defined as: 
OO 
Gx(s) = E{sx)=Y/pksk, 
H<1. 
fe=0 
Since Gx(l) = 1, the series converges for \s\ < 1. 
EXAMPLE 2.51 
For λ > 0, let X be a discrete random variable with probability mass 
function given by: 
P(fc) = ^ | — , k = 0,1,2,···. 
Then: 
αχ(,) = 
Ε(,χ)~·£*-χτϊ* 
fe=0 
fc! 
fc! 
e - * $ > S 
fe=0 
= 
eA(.-l) > 

9 4 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
EXAMPLE 2.52 
Let X be a discrete random variable with probability mass function 
given by 
p(x) = { O P ^ - P ) " " * * * = 0,l,---,n 
' 
\ 0 
otherwise 
where n is a positive integer and p € (0,1). Then: 
Gx(s) 
= E[sx] 
έ(:)»ν-
u—n \ 
/ 
ksk 
fc=0 
% j rJ(p*)V 
fc=o KK 
(ps + q)r 
Note 2.6 If X andY 
havepgf's 
Gx(s) andGy(s), 
respectively, then 
Gx(«) = GY(S) if and only if X = Y. 
Theorem 2.12 Let X be a nonnegative integer-valued random variable with 
E{\X\k) < oo for all k = 1,2, · ■ ·. Then, G ^ ( l ) = £ [ X ( X - 1 ) · · ■ 
(X-r+l)} 
where G^ (1) is the rth derivative of its pgf Gx(s) at s = 1. 
Proo/; 
oo 
Gx(s) = $ > „ * " 
(H< 1) 
n=0 
with p n = P(X = n), n = 0,1, ■ · ■. Differentiate with respect to s, and it is 
assumed that the order of summation and differentiation can be interchanged. 
We have: 
When s = 1: 
In general: 
n=l 
oo 
Gx(l) = Σ>Ρ" = £;(*) = ^ 1 ) · 
n = l 
G?(S) = ^[Gx(S)] 
.n=0 
= X ] Pr.n(n - 1) ■ · · (n - r + l)i 
ra=0 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
9 5 
Since the series is convergent for \s\ < 1 and using Abel's lemma: 
(?£>(!) = E[X(X - 1)... (X - r + 1)], 
r > 1. 
■ EXAMPLE 2.53 
If Gx{s) = exl'-1\ 
H < 1 , then: 
G'x(s) = λβ λ(- 1) 
E(X) = G'x(l) = X 
Gf(s) = AV'-1) 
Var(X) = λ2 - λ2 + λ = λ. 
A 
The moments of a random variable X have a very important role in statistics 
not only for the theory but also for applied statistics. Due to this, it is very 
convenient to have mechanisms that allow easy calculations for the moments 
of the random variable. This mechanism is provided by the so-called moment 
generating function which will be as follows. 
Definition 2.10 (Moment Generating Function) Let X be a random vari-
able such that E(etx) 
is finite for all t € (—a,a) with real positive a. 
The 
moment generating function (mgf) of X, 
denoted by τηχ(·), is defined as: 
mx(t) 
= E(etx) 
withte(-a,a). 
That is: 
X is a discrete random variable 
with pmf ρχ (x) 
X is a continuous random variable 
with pdf f{x). 
It is important to notice that not all probability distributions have moment 
generating functions associated with them. Later on some examples will be 
given that ratify this statement. 
Before giving the important properties of the mgf of a random variable 
X, some examples are presented. 
Y^etx"px{xk) if 
mx{t) 
= < 
STLe^fWdx if 

96 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
EXAMPLE 2.54 
Let X be a discrete random variable with probability mass function 
given by 
v*(x)-l 
CM 1-*)""* 
if * = 0,1,·■·,»» 
p x w 
- \ 0 
otherwise 
where n is a positive integer and p £ (0,1). 
In this case: 
"»x(0 = 2.e**( Jp*(l-p) 
fc=0 
n—k 
-t(; 
οί^/Ί 
^\n—k 
KpeT(l-p)" 
ί Λ: / 
fc=0 
(pee + <?)" where q := 1 —p. 
A 
Note 2.7 77ie distribution shown in Example 2.54 receives the name of bi-
nomial distribution with parameters n and p. In the next chapter, this distri-
bution will be studied in detail. 
EXAMPLE 2.55 
Let X be the random variable as in Example 2.42. In this case: 
fc=o 
K-
_ -3f(3e? 
~ 
^ 
k\ 
fc=0 
= e_3exp(3e') 
= exp(3(e* - 1)). 
A 
EXAMPLE 2.56 
Let X be a random variable with density function given by: 
,. , 
f 2e- 2 x 
if x > 0 
0 
otherwise. 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
9 7 
It is clear that: 
mx 
/•OO 
(i) = / 
etx2e~2xdx 
Jo 
1 
- " - > 
with t < 2. 
EXAMPLE 2.57 
Let X be a random variable with density function given by 
χ) i^-p{-l[M^] 2} if*>0 
/(*) 
0 
otherwise 
where μ € K and σ > 0 are constants. 
Then: 
E(etx) = - 4 = Γ ~ 
σ·ν/2π Jo 
x 
With a change of variable 
exp < tx - - ln(a;) — μ 
dx. 
u = 
ln(x) — μ 
it is obtained that: 
£<e") = i/>'
,{
,e'
+"-f}'
i" 
Given that εχρ(σω) > ^f- 
it is deduced that for t > 0: 
Γίβ^σ3 
t e ^
0 
u2 
u2 
- i t - 1 
Therefore, if u > tJiai 
is taken, it is obtained that 
- u - 1 
> 1 
Thus by taking 
a = te^a3 

98 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
we obtain: 
1 
f°° 
II2 
E{e ]>-w*L 
«XT'*-
This means that there does not exist a neighborhood of the origin in 
which E(etx) 
is finite and in consequence the moment generating func-
tion of X does not exist. 
▲ 
The existence of the moment generating function of a random variable X 
guarantees the existence of all the rth order moments around zero of X. If the 
moment generating function exists, then it is differentiable in a neighborhood 
of the origin and satisfies 
a¥mx{t) 
= E(Xr). 
t=o 
More precisely, the next two theorems state this and the proofs can be found 
in Hernandez (2003). 
Theorem 2.13 If X is a random variable whose moment generating function 
exists, then E(Xr) 
exists for all r e N. 
It is important to clarify that the converse of the previous theorem is not 
valid: the fact that all the rth order moments of a random variable X exist 
does not guarantee the existence of the mgf of the variable. For example, for 
the random variable in Example 2.57, it is known that for all r € N : 
E(Xr)=exp\rß+^£\. 
Theorem 2.14 If X is a random variable whose moment generating function 
τηχ{.) exists, then, h E (0, oo) exists such that: 
fc=0 
Therefore: 
mx(t) = ^2E(Xk) 
— ; 
forallt€{-h,h). 
E(Xr) 
= ^ m x ( i ) 
t=o 
An important property of the mgf of a random variable is that, when it 
exists, it characterizes the distribution of the variable. More precisely, the 
following theorem is obtained. Its proof is beyond the scope of this text. The 
interested reader may refer to Ash (1972). 
Theorem 2.15 Let X and Y be random variables whose moment generating 
functions exist. If 
τηχ (t) = πΐγ (f) for all t, 

EXPECTED VALUE AND VARIANCE OF A RANDOM VARIABLE 
9 9 
then X and Y have the same distribution. 
As it can be seen, the moment generating function of a random variable, 
when it exists, is a very helpful tool to calculate the rth order moments around 
zero of a variable. Unfortunately, this function does not always exist, and thus 
it is necessary to introduce a new class of functions that are equally useful 
and always exist. 
Definition 2.11 (Characteristic Function) Let X be a random variable. 
The characteristic function of X is the function ψχ : R —> C defined by: 
AtX 
ψχ{ϊ) := E(eltx) 
= E(costX) 
+ iE(smtX) 
where i = V=l. 
EXAMPLE 2.58 
Let X be a random variable with: 
P(X = 1)=P(X 
= -1) = ^. 
Then: 
1 
i 
<Px{t) = -(cost + cos(-f)) + -(sint + sin(-t)) 
= cosi. 
A 
EXAMPLE 2.59 
Let X 
be a discrete random variable with probability mass function 
given in Example 2.42. Then: 
itX\ 
<^(t) = £(e*tA) 
0 0 
qfc 
= V e i t f c e - 3 -
rz 
fc! 
e 'Σ- fc! 
fe=0 
= e-3exp(3ei4) 
= exp[3(eif - 1)]. 

100 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
EXAMPLE 2.60 
Let X be a continuous random variable with density function / 
given 
by: 
, , , _ ί 1 if 0 < x < 1 
^ ' 
\ 0 otherwise. 
Then, for t φ 0 
ψχ (*) — I cos(tx)dx + i I 
sin(tx)dx 
Jo 
Jo 
= - (sin t — ι cos t + i) 
and for ί = 0 
Φ*-1* 
<^x(0) = £;(eo) 
Next, some principal properties of the characteristic function, without proof, 
will be presented. The interested reader may consult these proofs in Grimmett 
and Stirzaker (2001) and Hernandez (2003). 
Theorem 2.16 If X is a discrete or absolutely continuous random variable, 
then E(eitx) 
exists for all t e R . 
Theorem 2.17 Let X be a random variable. 
The characteristic 
function 
ψχ{·) of X satisfies: 
1. φχ(0) = 1. 
2. \<Px{t)\ < 1 for all t. 
3. If E(Xk) 
exists, then: 
^x(t)\t=0=ikE(Xk). 
Finally, it is important to notice that the characteristic function of a ran-
dom variable, as in the case of mgf (when it exists), determines the distribu-
tion of the variable. That is, it satisfies: 
Theorem 2.18 If X and Y are random variables and 
ψχ{ί) = ψγ(ί) for all f, 
then X and Y have the same distribution. 

EXERCISES 
101 
EXERCISES 
2.1 
Let Ω = {1,2,3}, 9 = {0,{1},{2,3},Ω}. Let us define, for A 6 9 : 
™=-{ίϊ! 
eA 
iA. 
Is X : Ω —> R defined by Χ(ω) = ω2 a real random variable? Justify. 
2.2 
Let Ω = {1,2,3,4}. Determine the least σ-algebra over Ω so that 
Χ(ω) := ω + 1 is a real random variable. 
2.3 
A coin is biased in such a way that P(H) = | and P(T) = | . Suppose 
that the coin is tossed three consecutive times and let X be the random 
variable that indicates the number of heads obtained. Find the distribution 
function of the random variable X and calculate 
E(X). 
2.4 
The sample space of a random experiment is Ω — {a, b, c, d, e, / } and 
each result is equally probable. Let us define the random variable X as follows: 
I " 
\ a \ b \ c \ d \ e 
1 / | 
| Χ(ω) | 0 | 0 | 1 | 1 | - 1 | 2 | 
Calculate the following probabilities: 
a) P(X = 1). 
b) P ( | X - 1 | < 1 ) . 
c) P(X > 0 or X < 2). 
2.5 
Prove that if all values of a real random variable X are in the interval 
[a, b] with a <b, then Fx (x) = 0 for all x < a and Fx (x) = 1 for all x > b. 
2.6 
A fair coin is tossed four consecutive times. Let X be the random 
variable that denotes the number of heads obtained. Find the distribution 
function of the random variable Y := X — 2 and graph it. 
2.7 
Let (Ω, 3, P) be a probability space defined as follows: 
Ω := {(1,2,3), (2,3,1), (3,1,2)} , 3 := p (Ω) and Ρ(ω) := 1 
for all ω € Ω. Consider the random variables Xn defined over Ω, as: 
Xn (ω) = ωη for n = 1,2,3 and ω = (ωι,ω2,ω3) € Ω. 
a) Determine the set of values 5 taken by the random variable Xn. 
b) Verify that: 
P(X3 = 3 | X2 € {1,2}, X1 = 3) φ P(X3 = 3 | X2 e {1,2}). 

102 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
2.8 
A box contains 5 white balls and 10 black ones. A die is thrown. A 
number of balls equal to the result obtained in the die are taken out of the 
box. What is the probability that all balls taken out of the box are white 
balls? What is the probability that the result obtained when throwing the die 
is 3 if all the balls taken out of the box are white? 
2.9 
Let X be a random variable with density function given by: 
( 0.2 
if - 1 < x < 0 
0.2 + ex 
if 0 < x < 1 
0 
otherwise. 
a) Determine the value of c. 
b) Obtain the distribution function of the random variable X. 
c) Calculate P(0 < X < 0.5). 
d) Determine P{X > 0.5 | X > 0.1). 
e) Calculate the distribution function and the density function of the ran-
dom variable Y :=2X + 3. 
2.10 
Let X be a random variable with density function given by: 
c(2 - x) 
if 0 < x < 1 
/(*) = { 
a) Calculate the value of c. 
b) Determine the distribution function of the random variable X. 
c) Calculate P(\X\ > 0.2). 
2.11 
The cumulative distribution function of a random variable X is given 
by: 
{
0 
if x < 0 
2x - x2 
if 0 < x < 1 
1 
if x > 1. 
a) Calculate P (X > §) and P (-2 < X < §). 
b) Determine the density function 
fx(·)-
2.12 
Let X, Y and Z be random variables whose distribution functions are 
respectively: 
' 0 
if - oo < x < - 1 
0.2 
if - 1 < x < 0 
Fx(x) 
= \ 0.7 
if 0 < x < 1 
0.8 
if 1 < x < 2 
1 
if x > 2 

EXERCISES 
103 
{
0 
if - oo < a; < 0 
\ + \x 
if 0 < x < 1 
1 
if x > 1 
( 0 
if - oo < x < - 1 
\ + \x 
if - 1 < x < 1 
1 
if x > 1 . 
a) Which variables are discrete variables? Which variables are continuous 
variables? Explain. 
b) Calculate P(X = 0), P{\ < X < 2) and P(X > 1.5). 
c) Calculate P(Y = 0), P{\ < Y < 2) and P{Y > 0). 
d) Calculate P{Z = 0), P{-\ 
< Z < \) and P(Z > 2). 
2.13 
A circular board with radius 1 is sectioned in n concentric discs with 
radii £, ^, · · · , 1. A dart is thrown randomly inside the circle. If it hits the ring 
between the circles with radii ^ and ^ 
for i — 0, · · · , n — 1, n — i monetary 
units are won. Let X be the random variable that denotes the amount of 
money won. Find the probability mass function of the random variable X. 
2.14 
(Grimmett and Stirzaker, 2001) In each of the following exercises de-
termine the value of the constant C so that the functions given are probability 
mass functions over the positive integers: 
a) p(x) = C2~x . 
b) p(x) = e r i . 
c) p(x) = Cx~2 . 
d) P{x) = ψ ■ 
2.15 
(Grimmett and Stirzaker, 2001) In each of the following exercises de-
termine the value of the constant C so that the functions given are probability 
mass functions: 
a) p(x) = C{x(l -x)}~i, 
0 < x < 1. 
b) p(x) = Cexp(-x - e~x), x e K . 
2.16 
An absolutely continuous random variable X takes values in the in-
terval [0,4] and its density function is given by: 
f(x) 
=2~cx. 

104 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
a) Determine the value of c. 
b) Calculate P{\ < X < 3). 
2.17 
Let X 
be an absolutely continuous random variable with density 
function /. 
Prove that the random variables X and 
—X have the same 
distribution function if and only if f(x) = f(—x) for all x € R. 
2.18 
In the following cases, determine the distribution function of the dis-
crete random variable X whose probability mass function is given by: 
a) P(X = k)= pqk~x, k = 1,2, · · · with p 6 (0,1) fixed and q := 1 - p. 
b) 
P(X = k)= 
. 
° . ^ 1 V fc = l,---,n. 
n(n+ l)(2n + 1) 
2.19 
A person asks for a key ring that has seven keys but he does not know 
which is the key that will open the lock. Therefore, he tries with each one of 
the keys until he opens the lock. Let X be the random variable that indicates 
the number of tries needed to achieve the goal of opening the lock. 
a) Determine the density function of the random variable X. 
b) Calculate P(X < 2) and P(X = 5). 
2.20 
Four balls are taken out randomly and without replacement from each 
box that contains 25 balls numbered from 1 to 25. If you bet that at least 
1 of the 4 balls taken out has a number less than or equal to 5, what is the 
probability that you win the bet? 
2.21 
A player takes out, simultaneously and randomly, 2 balls from a box 
that contains 8 white balls, 5 black balls and 3 blue balls. Suppose that the 
player wins 5000 pesos for each black ball selected and loses 3000 pesos for 
every white ball selected. Let X be the random variable that denotes the 
player's fortune. Find the density function of the random variable X. 
2.22 
A salesman has two different stores where he sells computers. The 
probability that he sells, in one day, a computer in the first store is 0.4 and 
independently, the probability that he sells, in one day, a computer in the 
second store is 0.7. Additionally, suppose that it is equally probable that he 
sells a computer of type 1 or type 2. A type 1 computer costs $1800 while 
the type 2 computer, with the same specifications, costs $1000. Let X be the 
amount, in dollars, that the salesman sells in one day. Find the distribution 
of the random variable X. 
2.23 
Prove that 
/
oo 
exp(—x2)dx = \[π 
-oo 

EXERCISES 
105 
and use the above result to show that 
'«-^"»{-^}· *eR' 
is a density function if σ > 0. 
2.24 
Suppose that / and g are density functions and that 0 < λ < 1 is 
a constant. Is Xf + (1 — X)g a density function? Is fg a density function? 
Explain. 
2.25 
Let X 
be a random variable with cumulative distribution function 
given by: 
" 0 
if x < 1 
Fx{x)={ 
\x+\ 
if 
l < x < 2 
1 
if x > 2 
0 
if x < 1 
Fc(x) = { x - 1 if 1 < x < 2 
1 
if x > 2. 
Determine a cumulative discrete distribution function Fd{·) and one continu-
ous Fc(·) and the constants a and β with α + β = 1 such that: 
Fx(x) = aFd(x) + ßEc(x). 
2.26 
Let X be a random variable with cumulative distribution function 
given by: 
0 
if x < 1 
Fx(x) = < 
h 
if 1 < a: < 2 
x2 
if 2 < x < | 
if x > f. 
Determine the cumulative discrete distribution function Fd{·) and one contin-
uous Fc(·) and the constants a and /3 with a + ß = 1 such that: 
F x(x) = aF d(x)+/3F c(x). 
2.27 
We say that a discrete real random variable X has Fisher logarithmic 
distribution with parameter Θ if its density function is given by 
p{x) = 
|ln(l-0)| x 
« 
J· — l,Z, 
0 
otherwise 
with Θ e (0,1). Verify that p is a probability mass function. 

106 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
2.28 
Let X be a random variable with distribution function given by: 
F(x) = { 
0 
if x < 1 
j 2 - ^ + 2 
if 1 < x < 2 
if x > 2. 
Calculate 
Var(X). 
2.29 
Let X and V be two nonnegative continuous random variables having 
respective cdf's Fx and Fy. 
Suppose that for some constants a > 0 and 
6 > 0 : 
Fx{x) = FY 
Determine E(X) in terms of E(Y). M 
2.30 
Let X be a continuous random variable with strictly increasing dis-
tribution function F. What type of distribution have the random variable 
Y := -ln(Fx 
(X))? 
2.31 
Let X be a random variable which can only take values -1,0,1 and 2 
with P (X = 0) = 0.1, P (X = 1) = 0.4 and P (X = 2) = \P {X = -1). Find 
E{X). 
2.32 
An exercise on a test for small children required to show the corre-
spondence between each of three animal pictures with the word that identifies 
the animal. Let us define the random variable Y as the number of correct 
answers if a student assigns randomly the three words to the three pictures. 
a) Find the probability distribution of Y. 
b) Find E(Y) and 
Var(Y). 
2.33 
Let X be a random variable with density function given by: 
f{x) = 
C—L^ifxeR. 
1 + xz 
a) Determine the value of C. 
b) Calculate P(X > 0). 
c) Find (if they exist) E{X) and 
Var(X). 
d) Find the distribution function of X. 

EXERCISES 
107 
2.34 
A die is tossed two times. Let X and Y be the random variables 
defined by: 
X := "result of the first throw". 
Y := "result of the second throw". 
Calculate E (max {X, Y}) and E (min {X, Y}). 
2.35 
Let X be a random variable with density function given by: 
{
x3 
if 0 < x < 1 
(2 - x)3 
if 1 < x < 2 
0 
otherwise. 
a) Calculate μ := E(X) and σ2 := Var 
(X). 
b) Find P {μ - 2σ < X < μ + 2σ). 
2.36 
Let X be a random variable with density function given by: 
"{ 
f( ) _ i 
1 2* 3 - 21x2 + 10x 
if 0 < x < 1 
' 0 
otherwise. 
a) Calculate μ := E{X) and σ2 := Var {X). 
b) Determine the value of c so that P (X > c) = j ^ . 
2.37 
Let X be a random variable with density function given by: 
,, \ _ $ Csin (g7rx) 
if 0 < x < 5 
^ ' 
\ 0 
otherwise. 
a) Determine the value of C. 
b) Find (if they exist) the mean and variance of X. 
2.38 
Suppose that X is a continuous random variable with pdf fx(x) 
— e~x 
for x > 0. Find the pdf for the random variable Y given by: 
v _ j X 
if X < 1 
I ± 
if X > 1· 
2.39 
Let X b e a random variable with continuous and strictly increasing 
cumulative distribution function. 
a) Determine the density function of the random variable Y := \X\. 
b) Find the cumulative distribution function of the random variable Y := 
X3. 

108 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
2.40 
There are three boxes A, B and C. Box A contains 5 red balls and 4 
white balls, box B contains 8 red balls and 5 white balls and box C contains 
2 red balls and 6 white ones. A ball is taken out randomly from each box. 
Let X be the number of white balls taken out. Calculate the probability mass 
function of X. 
2.41 
Let X be a random variable with P(X = 0) = 0 and such that 
E(X) 
exits and is different from zero. 
a) Is it valid to say, in general, that: 
b) Is there a random variable X 
such that equation (2.3) is satisfied? 
Explain. 
2.42 
Let X be a discrete random variable with values in the nonnegative 
integers and such that E(X) and E(X2) 
exist. 
a) Prove that: 
oo 
E(X) = ΣΡ(Χ 
> k). 
fc=0 
b) Verify that: 
oo 
^kP(X>k) 
= -(E(X2)-E(X)) 
. 
k=0 
2.43 
Determine if the following propositions are true or false. Justify your 
answer. 
a) If P{X > Y) = 1, then E(X) > E{Y). 
b) If E(X) > E(Y), then P(X > Y) = 1. 
c) If Y = X + 1, then Fx (x) = FY (x + 1) for all x. 
2.44 
Let X be a random variable such that: 
p {X = l) = p = l - p (X = - l ) . 
Find a constant c φ 1 such that E (c*) = 1. 
2.45 
Let X be a random variable with values in Z+with P (X 
a) Determine the value of C. 
b) Find (if it exists) 
E(X). 
= *) = £· 

EXERCISES 
109 
2.46 
Let X 
be a random variable with values |^, k — 0,1, · · ■, and such 
that P (x = §£) = 2*ττ. Does E(X) exist? Does Var(X) exists? Explain. 
2.47 
(Markov's Inequality) Let X be a real random variable with X > 0 and 
such that E(X) exists. Prove that, for all a > 0, it is satisfied that: 
P ( X > a ) < f f i ) . 
a 
2.48 
(Chebyschev's Inequality) Let X be a random variable with mean 
μ and variance σ2. 
a) Prove that for all e > 0 it is satisfied that: 
P(\X-ß\>e)<^. 
b) If μ = σ2 = 20, what can be said about P (0 < X < 40)? 
2.49 
Let X 
be a random variable with mean 11 and variance 9. Use 
Chebyschev's inequality to find (if possible): 
a) A lower bound for P (6 < X < 16). 
b) The value of k such that P (\X - 11| > k) < 0.09. 
2.50 
(Meyer, 1970) Let A" be a random variable with mean μ and variance 
σ2. Suppose that H is a function two times differentiable in x = μ and that 
Y := H (X) is a random variable such that E(Y) and E(Y2) 
exist. 
a) Prove the following approximations for E(Y) and Var (Y) : 
Ε(Υ)*Η(μ) 
+ 
?ψ)-σ
2 
ναΓ(Υ)π{Η'{μ))2σ2 
. 
b) Using the result in part (a), calculate (in an approximate way) the mean 
and variance of the random variable 
Y :=2(1-0.005X) 1· 2 
where X is a random variable whose density function is given by: 
/ χ(χ)=3000χ- 4Λ[ 1 0,οο)(*) · 
2.51 
Find the characteristic function of the random variable X with prob-
ability function P(X = 1) = f and P(X = 0) = f. 

110 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
2.52 
Determine the characteristic function of the random variable X with 
density function given by 
,, . 
f τ-^— if a < x < b 
fix) = < °~ ° 
— 
— 
\ 0 
otherwise 
where a, b 6 R and a < b. 
2.53 
Determine the characteristic function of the random variable X with 
density function given by: 
,, , 
ί 1 - \x\ 
if - 1 < x < 1 
/(*) = ( o 0 
otherwise. 
2.54 
(Quartile of order q) For any random variable X, aquartileoforder 
q with 0 < q < 1, is any number denoted by xq that satisfies simultaneously 
the conditions 
(i) 
P(X<xq)>q 
(ii) 
P{X>xq)<l-q. 
The most frequent quartiles are x0.5, a;o.25 and Xo.75, named, respectively, 
median, lower quartile and upper quartile. 
A quartile xq is not necessarily unique. 
When a quartile is not unique, 
there exists an interval in which every point satisfies the conditions (i) and 
(ii). 
In this case, some authors suggest to consider the lower value of the 
interval and others suggest the middle point of the interval (see Hernandez, 
2003). Taking into account this information, solve the following exercises: 
a) Let X be a discrete random variable with density function given by: 
fXix)={ οω
χω
5 _ χ * *=o,-,5 
\ 0 
otherwise. 
Determine the lower quartile, the upper quartile and the median of X. 
b) Let X be a random variable with density function given by: 
fv<x\ 
= { 8ÖöexP(-8Üö) 
if 
x > 0 
JX 
K ' 
\ 0 
otherwise. 
Determine the mean and median of X. 
c) Let X be a random variable with density function given by: 
fx(x) = i $ 
if * > 1 0 
JXK 
' 
\ 0 
otherwise. 
Determine (if they exist) the mean and the median of X. 

EXERCISES 
1 1 1 
2.55 
(Mode) Let X 
be a random variable with density function /(.). A 
mode of X (if it exists) is a real number ζ such that: 
/ ( 0 > f(x) for all x € R. 
a) Let X be a discrete random variable with density function given by 
1 
| 2 | 3 | 4 | 5 | 6 
Ρ ί ν - τ ΐ 
| Ι | ί | ί | Ι | 1 | Ι 
-r ^ 
— J.) 
| 
4 0 
| 
5 
| 
8 
| 
8 
| 
2 0 
| 
4 0 
Find (if it exists) the mode of X. 
b) Suppose that the random variable X with density function given by 
y ( x ) = ) ίφ) (λ*) Γ - 1 exp (-Ax) 
if x > 0 
! 0 
otherwise 
where r > 0 and λ > 0 are constants and Γ is the function defined by: 
)dt . 
Γ(Γ) := / 
t r _ 1exp(-t)< 
Jo 
If E(X) = 28 and the mode is 24, determine the values of r and λ. 
c) Verify that if X is a random variable with density function given by 
f(x) 
= { bh 
if 0 < x < 6 
\ 0 
otherwise 
with a, b € R, a < b, then any ζ 6 (a, b) is a mode for X. 
d) Verify that if X is a random variable with density function given by 
j-/ \ 
I hx~^exO\— χ5) 
if x > 0 
/ (x) = i 
2 
*- V 
y 
^ 0 
otherwise 
then the mode of X does not exist. 
2.56 
Suppose that the time (in minutes) that a phone call lasts is a random 
variable with density function given by: 
f(t) = i έβχΡ(ΐ) 
if ί > 0 
K ' 
\ 0 
otherwise . 
a) Determine the probability that the phone call: 
i) Takes longer than 5 minutes. 

112 
RANDOM VARIABLES AND THEIR DISTRIBUTIONS 
ii) Takes between 5 and 6 minutes. 
iii) Takes less than 3 minutes. 
iv) Takes less than 6 minutes given that it took at least 3 minutes. 
b) Let C(t) 
be the amount (in pesos) that must be paid by the user for 
every call that lasts t minutes. Assume: 
(
500 
if 0 < ί < 5 
750 
if 
5 < i < 1 0 
100* if t > 10 . 
Calculate the mean cost of a call. 
2.57 
Let A" be a nonnegative integer-valued random variable with distribu-
tion 
P(X = 2n) = - · P(X = 2n - 1) 
= | · Ρ ( Λ : = 2η + 1) 
with P(X = 0) = \ ■ P(X = 1). 
o 
Find the pgf of X. 
2.58 
Find the pgf, if it exists, for the random variable with pmf 
a) p(n) = i^zry, 
n = l,2,... 
b) Ρ(η) = ^ϊ+Γ)> 
« = 1 , 2 , . . . · 
2.59 
Let X be a continuous random variable with pdf 
fx(x) = i ^ 
ii0<X 
JXK 
' 
\ 0 
otherwisi 
< oo 
otherwise . 
Find the moment generating function of X. 
2.60 
Find the characteristic function of X if X is a random variable with 
probability mass function given by 
« = {<>* 
„M=J w/C-f)" 
if 
* = 0 , l , - - , n 
' 
' 
n 
otherwise 
where n is a positive integer and 0 < p < 1. 
2.61 
Find the characteristic function of X if X is a random variable with 
pdf given by 
"{ 
t ( \ — ) λβχρ(—λχ) 
if x > 0 
jxyx> - \ o 
otherwise 

EXERCISES 
113 
where λ > 0. 
2.62 
Let X be a random variable with characteristic function given by: 
Determine: 
a) 
P{-l<X<\). 
b) 
E{X). 
2.63 
Let X be a random variable. Show that 
<Px(t) = 
ipx(-t) 
where z denote the complex conjugate of z. 
2.64 
Let X be a random variable. Show that ψχ (t) is a real function if and 
only if X and —X have the same distribution. 
2.65 
Let X be a random variable with characteristic function given by: 
<px(t) = <?«"-». 
Determine E{2X2 -5X+ 
1). 
2.66 
Let X be a random with characteristic function <fx{t). Find the char-
acteristic function of Y := 2X — 5. 

CHAPTER 3 
SOME DISCRETE DISTRIBUTIONS 
In this chapter we present some frequently used discrete distributions. 
3.1 
DISCRETE UNIFORM. BINOMIAL AND BERNOULLI 
DISTRIBUTIONS 
Definition 3.1 (Discrete Uniform Distribution) A random variable X 
has a discrete uniform distribution with N points, where N is a positive integer 
with possible distinct values x$, i = 1,2, · · · , N, if its probability mass function 
is given by: 
v 
\ 0 
otherwise . 
If in particular Xi = i, i = 1,2,·· ■ ,N, the probability mass function is shown 
in Figure 3.1. 
Theorem 3.1 (Properties of a Discrete Uniform Random Variable) 
If X is a random variable having a discrete uniform distribution with N points, 
then: 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
115 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

1 1 6 
SOME DISCRETE DISTRIBUTIONS 
Pix) 
1/N 
1
2 
3 
. . . 
N
x 
Figure 3.1 
Probability mass function for a discrete uniform distribution 
'•*w =4 f>-
« = 1 
N 
*·£(*Γ) = ^Σ<· 
t = l 
N 
3. mx(t) = J27?etXi-
t = l 
Corollary 3.1 If Xk = k, k — 1,2, ■ · · , N, then: 
N + l 
1. E{X) 
2. 
Var{X) 
2 
' 
N2-l 
12 
ΛΓ 
3. mx{t) = 
^ekK 
fe=l 

DISCRETE UNIFORM, BINOMIAL AND BERNOULLI DISTRIBUTIONS 
117 
Proof: 
1. 
N ' 
* 
N(N + l) 
N + l 
*i*>-Es-wx 
2. Left as an exercise for the reader. 
3. Follows from the definition of the mgf. 
m 
■ EXAMPLE 3.1 
A fair die is tossed. The sample space Ω = {1,2,3,4,5,6} and each event 
occurs with probability | . Therefore we have a uniform distribution 
with: 
p(n) = -, 
n= 1,2,3,4,5,6 
fiW 
= 1 + 2 + 3 + 4 + 6 + 6 
= 3 5 
6 
Var(X) = 
*-. 
A 
Definition 3.2 (Binomial and Bernoulli Distributions) A random vari-
able X is said to have a binomial distribution viith parameters n and p if its 
probability mass function is given by 
{ c y 
p(x) = < Vx^ e(l-P) n- X 
if 
* = 0,1,·· 
K 
' 
n 
otherwise 
where n is a positive integer and 0 < p < 1. 
If n = 1, the binomial distribution is called a Bernoulli distribution with 
parameter p. 
The probability mass function of a binomial distribution with parameters 
n = 6, p = 0.5 is shown in Figure 3.2. 
Notation 3.1 We shall write X = B(n,p) to indicate that the random vari-
able X has a binomial distribution with parameters n and p. 
The binomial distribution is frequently used to describe experiments whose 
outcome can be regarded in terms of the occurrence or not of a certain phe-
nomenon. If the random variable X denotes the number of successes achieved 
after carrying out n independent repetitions of the experiment, then X has a 
binomial distribution with parameters n and p, where p is the probability of 
success, that is, the probability that the desired phenomenon is observed; the 
probability of failure 1 — p is usually referred to with the letter q. 

118 
SOME DISCRETE DISTRIBUTIONS 
P(x) 
0.45 
0.4 
0.35 
0.3 
0.25 
0.2 
0.15 
0.1 
0.05 
0 
, 
■ 
T 
■ 
1 
■ 
T 
Figure 3.2 
Probability mass function of a binomial distribution 
EXAMPLE 3.2 
A fair die is rolled five consecutive times. Let X be the random variable 
representing the number of times that the number 5 was obtained. Find 
the probability mass function of X. 
Solution: The random variable X has a binomial distribution with 
parameters 5 and g. Therefore: 
^ =
 0> = (ο)*(δ)
0 χ(ίϊ)'
 = 0 ·
4 0 1 8 8 
P W T - D - Q x ( 1 ) ' x ( | ) ' - 0.40188 
P(X = 2 ) = Q ) x ( I ) 2 x ( 5 ) 3 = 0,6075 

DISCRETE UNIFORM, BINOMIAL AND BERNOULLI DISTRIBUTIONS 
119 
P^ = 3 ^ ( 3 )
X G )
3 > < ©
2 = 0·
03215 
P(X = 4)= Q * ( I / * (!)'= 3.215 
x 10-» 
Ρ(Χ = 5 ) = ( 5 )
Χ 0 )
5 χ ©
0 = 1·
286Χ10"
4· Α 
■ EXAMPLE 3.3 
A salesman from a travel agency knows from experience that the oppor-
tunity to sell a travel package is greater when he makes more contact 
with potential buyers. He has established that the probability that a 
costumer will buy a package after a visit is constant and equal to 0.01. 
If the set of visits done by the salesman constitute an independent set 
of trials, how many potential buyers must he visit in order to guarantee 
that the probability of selling at least a travel package will equal 0.85? 
Solution: Let: 
X := "Number of people that buy a travel package after 
the salesman's visit". 
We have that X = B(n, 0.01) and wish to find n such that 
P(X > 1) = 0.85 
or equivalently: 
0.85 = 1 - P(X = 0) 
= 1 - f " ) (0.01)°(0.99)n. 
Therefore: 
(0.99)n 
nln(0.99) 
n 
= 0.15 
= ln(0.15) 
= 111(015) 
ln(0.99) 
Consequently, the salesman must visit at least 189 people to achieve his 
goal. 
▲ 

120 
SOME DISCRETE DISTRIBUTIONS 
EXAMPLE 3.4 
Paula's best friend invited her to a party. Since Paula is still very young, 
her parents conditioned their consent to Paula's brother going along 
with her. Paula's brother proposes the following deal to her: "You pick 
a number, whichever you like, from 1 to 6; you then roll a fair die four 
times, and if the number you picked appears at least twice, then I will 
come with you. Otherwise, I won't". What is the probability that Paula 
is going to the party? 
Solution: Let: 
X := "Number of times the number chosen by Paula appears". 
Clearly X = ß(4, g). Then, the required probability equals: 
P{X > 2) = 1 - P(X = 0) - P(X = 1) 
-(«'-cr-cKy-ay 
= 1 
= 0.13194. 
EXAMPLE 3.5 
A player bets on a number from 1 to 6. Once he has bet, three fair dice 
are rolled. If the number chosen by the player appears i times, with 
i = 1,2,3, then the player is rewarded with 2i money tokens. If the 
number bet does not appear on any die, the player loses 3 tokens. Is 
this game fair to the player? Explain your answer. 
Solution: Let X be the random variable representing the fortune of the 
player. The values X can take are —3,2,4 and 6. We have that: 
125 
216 
2 
^ - G ) " G ) » ( ! ) -
^-«-cKy-Gy-ä 
^-«-cKy-cy 
«"«-©"Gy-Gy-ä 
15 
216 
216 
Accordingly: 
_ . v , 
(-3) x 125 + 2 x 75 + 4 x 15 + 6 
-159 
E{X) 
= 
216 
" 
W 

DISCRETE UNIFORM, BINOMIAL AND BERNOULLI DISTRIBUTIONS 
1 2 1 
This indicates that in the long run the player loses 159 tokens for every 
216 games played. Therefore, the game does not favor him. 
▲ 
EXAMPLE 3.6 
(Hoel et al., 1971) Suppose that n balls are randomly distributed in r 
urns. Find the probability that exactly fc balls were put in the first r\ 
urns. 
Solution: Let X := "number of balls in the first ri urns". Since 
X = B (n, p) with p = ^ , then: 
■(*-*)-(;) (τ)* ( ' - Ϊ Γ · 
■ EXAMPLE 3.7 
Consider the fc-out-of-n structure which is a special case of parallel re-
dundant system. This type of configuration requires that at least fc 
components succeed out of the total n parallel components for the sys-
tem to succeed. The problem is to compute the system reliability given 
the component reliabilities Pi. The reliability of a fc-out-of-n structure of 
independent components, which all have the same reliability p, equals: 
Reliability = ^ ( " V t 1 -p)"_<· 
This formula holds since the sum of n random variables has a Bernoulli 
distribution with parameters n and p under given assumptions. 
A 
Next, we present some properties of the binomial distribution. 
Theorem 3.2 (Properties of the Binomial Distribution) Let X be a 
random variable having a binomial distribution with parameters n and p. 
Then: 
1. E{X) = np. 
2. Var(X) = npq, where q := 1 — p. 
3. mx(t) 
= {pet + q)n. 
Proof: In Example 2.54 we verified that the mgf of a random variable with 
binomial distribution of parameters n and p is given by τηχ (t) = (pe( + q) . 
Thus: 
E(X) = Tmx(t) 
= npet(pet+q)n-1 
| t = 0 = np. 
at 
t=o 

122 
SOME DISCRETE DISTRIBUTIONS 
Furthermore, we have: 
E(X2) = 
^mx(t) 
ατ 
t=o 
= [n(n - 1)(ρβ*)2(ρβ* + 9) n" 2 + "ρβ*(ρβ* + 
q)n-%=0 
= n(n — l)p2 + np. 
Hence, we obtain: 
Var(X) = n2p2 — np2 + np — n2p2 
= np{\ - p) 
= npq. 
Note 3.1 Suppose that X is a random variable with a binomial distribution 
of parameters n and p. Let: 
B(k) := (£)pV-fc ■ 
Seeing that 
/ n \ 
n — fc + 1 / n \ 
\k) 
= 
k 
\k 
-1) 
then for k = 1, · ·· ,n: 
_... 
n-k + 1 f n \ 
fc_, 
„_fc +i 
1 
n- k + \ ( n \ 
fc_i 
—k—{k-i)px^x^ 
= 
n - f c ± l > < p x 
fc 
q 
Hence, starting with B(0) = qn the values of B(k) for k = 1, · · ■ ,n can be 
recursively obtained. 
Algorithm 3.1 
Input: p, n, where n is the number of terms. 
Output: B(k) for fc = 0(l)n. 
Initialization: q := (1 — p), 
B(0) := qn. 
Iteration: For fc = 0(l)n - 1 do: 
B(fc + l) = ^ x 2 x B ( f c ) 
A 

HYPERGEOMETRIC AND POISSON DISTRIBUTIONS 
123 
Using the last algorithm we obtain, for example, for n = 5 and p = 0.3: 
I k | B(k) | 
| 0 | 0.16807 | 
| 1 | 0.36015 | 
| 2 | 0.30870 | 
| 3 | 0.13230 | 
| 4 | 0.02835 | 
| 5 | 0.00243 | 
Note 3.2 Prom the previous remark, we have that: 
, n 
B(k) > B(k — 1) if and only if 
That is: 
fc+1 
p 
k 
q 
B(k) > B(k - 1) if and only if (n + l)p > k. 
Thus, ifX = B(n,p), then P(X = k) increases monotonically until it reaches 
a maximum for k = \_{n + l)p\ (where [a\ denotes the integer part or floor of 
a) and, after this value, it decreases monotonically. 
3.2 
HYPERGEOMETRIC AND POISSON DISTRIBUTIONS 
In Chapter 1, we saw that if an urn contains N balls, R of which are red and 
N — R white, and a sample of size n is extracted without substitution, then 
the probability P(Ak) that exactly k of the extracted balls are red equals: 
P(k) := P(Ak) 
\k)\n-k) 
If we are only interested in the number k of red balls among the n balls 
extracted, then P(k) := P{Ak) defines a probability measure over the set 
{0,1,··· ,n} called the hypergeometric distribution with parameters n, R 
and N. More precisely, we have: 
Definition 3.3 (Hypergeometric Distribution) A random variable X is 
said to have a hypergeometric distribution with parameters n, R and N if its 
probability mass function is given by 
Px(x) 
-
(R)(N~R) 
0 
if x — 0,1, · 
otherwise 

124 
SOME DISCRETE DISTRIBUTIONS 
P(x) 
Figure 3.3 
Probability mass function of a hypergeometric distribution 
where N is a positive integer, R is a nonnegative integer less than or equal to 
N and n is a positive integer less than or equal to N. 
The probability mass function of a hypergeometric distribution with pa-
rameters n = 4, R = 7 and N = 20 is shown in Figure 3.3. 
Notation 3.2 The expression X = Hg(n, R, N) means that the random vari-
able X has a hypergeometric distribution with parameters n, R and N. 
EXAMPLE 3.8 
The surveillance division of a university has acquired 50 communication 
devices in order to optimize the security in the campus. Eight of them 
are randomly selected and tested to identify any possible flaws. If 3 
of the 50 devices are defective, what is the probability that the sample 
contains at most two defective devices? 
Solution: Let X := "number of defective devices found in the sample". 
It follows that X = Hg(8,3,50). 
Therefore: 
P {X < 2) 
= 
P(X = 0) + P(X = 1) + P(X = 2) 
_ 
PC4/) , (Pi4/) , @(467) 
(58°) 
(58°) 
(58°) 
= 
0.99714. 
▲ 

HYPERGEOMETRIC AND POISSON DISTRIBUTIONS 
125 
EXAMPLE 3.9 
A work team established by the Department of the Environment pro-
grammed inspection of 25 factories in order to investigate possible vi-
olations to the environmental contamination act. Nevertheless, cuts in 
budget have substantially reduced the work team size, so that only 5 
out of 25 factories are going to be inspected. If it is known that 10 of 
the factories are working outside the environmental contamination act, 
find the probability that at least one of the factories sampled is working 
against the regulations. 
Solution: Let X :— "number of factories operating in contravention of 
the environmental contamination act". It is straightforward that 
X = Hg(5,10,25), 
whereupon we have: 
P(X > 1) 
= 
1 - P(X = 0) 
_ , 
Co
0) * ft") 
" 
(255) 
= 
0.94348. 
A 
Note 3.3 Suppose that the size N of the population is unknown, but we wish 
to find it without counting one by one each individual. A way of doing this 
is the so-called capture-recapture method, which consists in capturing R in-
dividuals from the population, tagging them and then returning them to the 
population. Once the tagged and untagged individuals have mixed, a sample 
of size n is taken. Let X be the random variable representing the number of 
tagged individuals in the sample. Clearly X = Hg(n,R,N). 
Suppose that the 
observed value of X is k. Then Pk{N) := P(X = k) represents the probability 
that the sample contains k tagged individuals when the population has size N. 
So we will estimate N as the value N for which the probability that X equals 
k is maximum. Such a value is known as the maximum likelihood estimate of 
N. To find it, we observe that: 
Pk(N) > Pk{N - 1) if and only if ^ ' f ^ ^ 
> 1 · 
That is, 
Pk(N) >Pk(N- 
1) if and only if ^ - ^ > N 
and thereby: 
cT 
\Rxn~ 
N = —;— . 

126 
SOME DISCRETE DISTRIBUTIONS 
EXAMPLE 3.10 
To establish the number of fishes in a lake the following procedure is 
followed: 2000 fishes are captured, tagged and then returned to the 
lake. Days after, 350 fishes are captured and it is observed that 50 of 
them are tagged. Then, according to the previous remark, the maximum 
likelihood estimate of the size N of the population is: 
N = 2000 x 350 
50 
= 12,727. 
Below we present some of the properties of the hypergeometric distribution. 
Theorem 3.3 (Properties of the Hypergeometric Distribution) Let 
X = Hg{n,R,N). 
Then: 
1. E(X) = ψ. 
2. Var{X) = n x § x ^ x 
$ 5 * . 
Proof: 
1. 
n 
(R\ 
(N~R) 
E(X) = Σχ 
,η 
x=0 
_ V-* 
"■ 
\x-l)\n-x) 
~ h > (
N
n--D 
n NZ2- 
(N-ix 
fc=0 
V n - l / 
R 
= 
nN> 
where we used the following identity: 
yi/fl-l\/ N-R 
\ = 
(N-1\ 
L·^ 
fc 
){n-k-l)~\n-l)· 
2. Seeing that 
Var(X) 
= E(X(X 
- 1)) + E(X) - 
(Ε(Χ)γ 

HYPERGEOMETRIC AND POISSON DISTRIBUTIONS 
127 
it suffices to find E(X(X 
- 1)). Thus: 
n 
E(X(X 
- 1)) = Y^x(x 
- 1)P(X = x) 
n 
-Σ 
x=2 
■ , 
^ 
R(R-l)(R-2)\ 
(R - x)\x{x - l)(x - 2)\ 
(N - n)\n{n - 1)( 
N(N - 1)(N 
)(n-2)\ 
(N-RV 
- 2 ) ! 
\ n - x j 
= n(n — 1) 
= n(n — 1) 
= n(n — 1) 
R(R - 1) 
N(N-l)^ 
R(R - 1) 
Σ 
x=2 
n-2 
(*:2
2)(ΐ:*) 
N{N-l) 
R(R - 1) 
2V(JV - 1) 
fc=o 
(R-2\( 
N-R 
\ 
\ 
k 
)\n-k-2) 
Using the relation 
We obtain 
y ? / Ä - 2\ / TV - R \ = (N - 2\ 
^Q\ 
k 
) \ n - k - 2 ) - \ n - 2 ) -
{N-R){N-n)~ 
= n 
R 
N 
N{N - 1) 
Next we will see that if the population size N is large enough in comparison 
to the sample size n, then the hypergeometric distribution can be approxi-
mated by a binomial distribution. More precisely, we have the following result: 
Theorem 3.4 Let 0 < p < 1. If N,R —>· 00 in such a way that ^ —> p, 
then: 
Hg(n,R,N)(k) 
:= ( f c ) ("- f c ) - > B(n,p)(k) 
:= (fypk(l 
-p)"- f c. 

128 
SOME DISCRETE DISTRIBUTIONS 
Proof: Observing that ^-^ —> (1 — p) = q > 0 when N, R —> oo, we see 
that (N - R) —> oo when N —> oo. Therefore: 
a 
n\ R{R - 1) · · · (R - k + 1)(N - R) ■ ■ ■ (N - R - (n - k) + 1) 
k) 
N{N-l)---{N-n 
+ l) 
-c 
n~k R(R-l)---(R-k 
+ l) 
Rk 
K(N-R)-(N-R-(n-k) 
+ l) κ 
Ν« 
N,fi—>oo 
(ΛΓ - Ä)»-* 
N{N - 1) · · · (JV - n + 1) 
Q/(l-p)"-fc. 
EXAMPLE 3.11 
In a city with 2 million inhabitants, 60% belong to political party A. 
One hundred people are randomly chosen from the inhabitants. The 
distribution of the number of people, among the 100 drawn who belong 
to party A is hypergeometric with parameters 100,1200000 and 2000000. 
Applying the previous result we can approximate this distribution by a 
binomial with parameters n = 100 and p = 0.6. That way, for example, 
the probability that among the 100 people chosen exactly 40 belong to 
party A equals: 
O 
6)40 (0.4)60 = 2.4425 x 10~5. 

HYPERGEOMETRIC AND POISSON DISTRIBUTIONS 
pW 
0.35 
0.3 
0 25 
0.2 
0.15 
0.1 
0.05 
0 
_ 
τ 
τ 
! 
τ 
Figure 3.4 
Probability mass function of a Poisson distribution 
The following table compares the binomial and hypergeometric distributions: 
k 
/fg(4,60,100) Hg{4,600,1000) 
Hg(A, 6000,10,000) ß (4, §) 
0 
0.02331 
0.02537 
0.02558 
0.0256 | 
1 
0.15118 
0.15337 
0.15358 
0.1536 
| 2 
0.35208 
0.34624 
0.34566 
0.3456 
3 
0.34907 
0.34595 
0.34563 
0.3456 
4 
0.12436 
0.12908 
0.12955 
0.1296 
Definition 3.4 (Poisson Distribution) A random variable X is said to 
have a Poisson distribution with parameter \> 0 if its probability mass func-
tion is given by: 
p(x) -{? 
if 
x = 0,1,· 
otherwise 
The probability mass function of a Poisson distribution with parameter 
λ = 2 is shown in Figure 3.4. 
Notation 3.3 Let X be a random variable. We write X = V{\) to indicate 
that X has a Poisson distribution with parameter X. 

130 
SOME DISCRETE DISTRIBUTIONS 
Note 3.4 Let X = V(X) and V{X){k) := P(X = k). It is straightforward 
that, for k = 1,2, · · ·: 
P(X)(k) = 
±P(X)(k-i). 
Hence, starting with V(X)(0) = e~x the values ofV{\){k) 
can be recursively 
obtained for k = 1,2,···. 
A simple algorithm to calculate the values of the Poisson distribution mak-
ing use of the previous expression is given by: 
Algorithm 3.2[Calculus of V(X)(k)} 
Input: λ, η, with n being the number of terms. 
Output: V(X)(k) for k = 0(l)n. 
Initialization: V{X){0) = e~x. 
Iteration: 
For k = 0(l)n — 1 do: 
V(\)(k + l) = j£iV(X)(k). 
A 
Analyzing the graph of the probability mass function from a random vari-
able with Poisson distribution, we observe that the individual probabilities 
become smaller as the variable takes larger values. This is precisely one of 
the general characteristics of the Poisson distribution. Other properties of the 
Poisson distribution are given in the following theorem. 
Theorem 3.5 Let X be a random variable with Poisson distribution of pa-
rameter X. Then: 
1. E(X) = X. 
2. Var{X) = X. 
3. mx(t) 
= exp(A(e* - 1)). 
Proof: We start by proving 3 and by applying the properties of the mgf we 
deduce 1 and 2. Accordingly: 
m*W = f V f e e - ^ 
fc=0 
r-Ay(Ae*) f c 
fc=0 
= exp (A(e* - 1)). 

HYPERGEOMETRIC AND POISSON DISTRIBUTIONS 
131 
Thus 
E(X) = ftmx(t) 
\t=0 
= λε' exp (A(e< - 1)) | t = 0 
= λ . 
Also 
E{X2) = -^rnx(t) 
\t=0 
= [Xe* exp (λ(β* - 1)) + A2e2t exp (A(e* - 1))] | t = 0 
= λ(λ+1), 
which yields 
Var{X) = X. 
The property E(X) = Var(X) 
holds only for Poisson distribution and is a 
characterizing property of the distribution. 
■ 
■ EXAMPLE 3.12 
The number of patients who come daily to the emergency room (E.R.) of 
a certain hospital has a Poisson distribution with mean 10. What is the 
probability that, during a normal day, the number of patients admitted 
in the emergency room of the hospital will be less than or equal to 3? 
Solution: Let X := "number of patients who come daily to the E.R.". 
From the data supplied by the statement of the problem, we know that 
X = 7>(10). Therefore: 
P{X < 3) = P(X = 0) + P(X = 1) + P(X = 2) + P(X = 3) 
- e"10 + 10e-10 + 50e-10 + i29°e-10 
6 
= 1.0336 x 10~2. 
▲ 
It will be proved below that for large enough n and suitably small p a bino-
mial distribution with parameters n and p can be approximated by a Poisson 
distribution of parameter λ = np; that is, under these circumstances, the 
Poisson distribution is a limit of the binomial distribution. 
Theorem 3.6 Jfp(n) is a sequence satisfying 0 < p(n) < 1 and 
n x (p(n)) 
> X, then: 
n—>oo 
Bn<p{n)(k):=(fy(p(n))k(l-p(n))n-k 
-^-> β" λ^ =: V(X)(k). 

132 
SOME DISCRETE DISTRIBUTIONS 
Proof: Let λ„ = n x (p(n)). Then: 
a 
ru\ 
1 
n 
n-k 
+ 1 
k 
( 
λ „ \ η 
/ 
\n\~ 
Sn,p(n)(fc) = ^ x - x - - . x - ^ ^ x A * x ^ - - j 
x ( l - - J 
· 
Taking the limit when n —> oo we see that the quotients ^, · ■ · , n~*+1 as well 
as the factor (l — ^f·) 
tend to 1, while the expression (l — ^ ) 
tends to 
e ~ \ As a result: 
ß„,p(n)(fc) 
► V(X)(k). 
The following table shows how good the approximation is when λ = np = 1: 
k 
0 
1 
2 
3 
4 
Ρ(λ)(*) 
0.3678 
0.3679 
0.1839 
0.0613 
0.0153 
ßioo.^*) 
0.3660 
0.3697 
0.1848 
0.0610 
0.0149 
βιο,Α(*) 
0.3487 
0.3874 
0.1937 
0.0574 
0.0112 
Assume p(n) = p, i.e., the probability that the success in any trial is p and 
all the trials are independent for finite n. For large n, the sum of Bernoulli 
random variables with parameters n and p tends to Poisson random variable 
with parameter λ = np. 
The preceding theorem implies that the Poisson distribution offers a good 
probabilistic model for those random experiments where there are indepen-
dent repetitions and only two possible outcomes, success or failure, with small 
probability of success, and where the main interest lies on knowing the num-
ber of successes obtained after a large enough number of repetitions of the 
experiment. Empirically, it has been determined that the approximation can 
be safely used if n > 100, p < 0.01 and np < 20. 
EXAMPLE 3.13 
There are 135 students inside a conference hall. The probability that one 
of the students celebrates his or her birthday today equals ggg. What is 
the probability that two or more students from the conference hall are 
celebrating their birthdays today? 
Solution: Let X := "number of students celebrating their birthdays 
today". It is known that X = #(135, 5^5); however, this distribution 
can be approximated by means of a Poisson distribution with parameter 

GEOMETRIC AND NEGATIVE BINOMIAL DISTRIBUTIONS 
133 
λ = | | . Thereby: 
P{X > 2) = 
1 - P(X = 0) - P(X = 1) 
_27 
2 7 _ 27 
= 
1 — e ™ 
e *s 
73 
= 
5.3659 x ΗΓ 2. 
A 
3.3 
GEOMETRIC AND NEGATIVE BINOMIAL DISTRIBUTIONS 
When working with a binomial distribution we proceeded as follows: a random 
experiment was repeated n times and the probability of obtaining exactly k 
successes was found. In this case, the number of repetitions remains constant 
while the number of successes is random. Instead suppose the question is the 
following: What is the probability that the experiment has to be repeated n 
times to obtain exactly k successes? That is, now the number of successes 
remains constant while the number of repetitions is a random variable X. 
What is the probability that X takes the values j = k, k+1, · · · ? If X = j , 
then the jth result was necessarily a success and therefore the other k — 1 
successes are obtained in the remaining j — 1 repetitions of the experiment. 
That is, 
P ( x = j ) =(jfc-i) p f c ( 1" p ) i" f c' J' = fc.fc + 1 ' · " . 
where 0 < p < 1 is the success probability. 
Definition 3.5 (Geometric and Negative Binomial Distributions) A ran-
dom variable X is said to have a negative binomial distribution with parame-
ters k and p if its probability mass function is given by: 
p[x) = { G:i)p*(i-P)x-fc 
if * = *,A + I , -
\ 0 
otherwise . 
In the special case where k = 1 it is said that the random variable has a 
geometric distribution with parameter p. 
The probability mass function of a negative binomial distribution with 
parameters k = 2 and p = \ is shown in Figure 3.5. 
Notation 3.4 The expressions X = BN{k,p) 
and X = G{p) mean that X 
has a negative binomial distribution with parameters k and p and X has a 
geometric distribution of parameter p. 
Note 3.5 Suppose that we are interested not in the num^ 
of repetitions 
required to obtain k successes but in the number of failures Y that happened 

134 
SOME DISCRETE DISTRIBUTIONS 
0.35 
0.3 
0.25 
0.2 
0.15 
0.1 
0.05 
n 
1 
' 
■ 
■ 
< 
< 
' 
I 
' 
3 
4 
5 
6 
7 
X 
Figure 3.5 
Probability mass function of a negative binomial distribution 
before we obtained exactly k successes. In this case we have that X = k + Y 
and therefore: 
P(Y = j)=(k~lJ_~iyk(l-p)J 
wüh j = 0,1,2,··· . 
Some authors call this last distribution the negative binomial and the one 
defined before as the Pascal distribution. 
EXAMPLE 3.14 
In a quality control department, units coming from an assembly line are 
inspected. If the proportion of defective units is 0.03, what is the proba-
bility that the twentieth unit inspected is the third one found defective? 
Solution: Let X := "number of units necessary to inspect in order to 
obtain exactly three defective ones". Clearly X = BN(3,0.03). 
Hence: 
P{X = 20) = (™λ (0.03)3 (1 - 0.03)17 
= 2.7509 x 10 - 3. 
▲ 
Below, we find the mean and variance of a random variable having a negative 
binomial distribution. 

GEOMETRIC AND NEGATIVE BINOMIAL DISTRIBUTIONS 
135 
Theorem 3.7 Let X be a random variable having a negative binomial distri-
bution with parameters k and p. Then: 
1. E(X) = $. 
2. Var(X) = 
! ^ . 
3.mx(t)=[T^^]k. 
Proof: The rth moment of X around the origin is given by 
E(xr) = f^r(i-_^)pk(i-Py-k 
oo 
fc-1, 
3—ft 
where Y = ΒΝ(ΙΪ +1,ρ). 
Therefore 
and 
E(X) = -
P 
which yields: 
E{X2) = -E(Y 
- 1) 
P 
k 
P 
fc + 1 - 1 
fc fc+1-p 
= - x 
P 
P 
1/ 
fv\ 
k2 + k-kp 
fc2 
Var{X) 
= 
_ 
fc(l-p) 

136 
SOME DISCRETE DISTRIBUTIONS 
On the other hand, 
oo 
/ · _ 1 \ 
mx(t) = J2etJ[i_l)Pk(l-p)J-k 
j=k 
^ 
' 
where: 
= etfcEet/(zl^1)pfc(1-p)i 
= ettf)(-l)'(-*y((l-p)e*),
> 
Using the Taylor series expansion of the function g(x) := (1 — a;) k about the 
origin, we obtain: 
Accordingly: 
<'->-'-£(-, V 
mx(t) = ( p e t ) f c ( l - ( l - p ) e t ) -
pe' 
l - ( l - p ) e 4 . 
Corollary 3.2 J/X is a random variable having a geometric distribution with 
parameter p, then: 
1. E{X) = l. 
2. 
Var(X)^1-^. 
3. mx(t) 
= 
_££_ 
l - ( l - p ) e ' 
Note 3.6 For the random variable Y = X — k we have: 
E ( y ) = * _ f c = M W ) 
p 
p 
Var(Y) = Var(X) = 
Μ ί ^ 
mY(t) 
= l - ( l - p ) e ' _ 

GEOMETRIC AND NEGATIVE BINOMIAL DISTRIBUTIONS 
137 
Note 3.7 Suppose that the size N of a population is unknown. 
We wish to 
determine N without counting each of the individuaL·. One way of doing this 
is the so-called inverse capture-recapture method, which consists in capturing 
R individuaL· from the population and returning them to it after they have been 
properly tagged. Once the tagged and nontagged individuaL· are homogeneously 
mixed, a new sample is taken from the population drawing one individual at 
a time until a predetermined number of tagged individuaL· k is reached. Let 
X be the random variable representing the number of necessary extractions to 
obtain k tagged individuaL·. Clearly X = #ΛΓ(&,Ρ), where p = j ^ . Suppose 
that the observed value X equaL· j . Then Pk(N) := P(X = j) represents 
the probability that j extractions were required in order to obtain exactly k 
tagged individuaL· when the population size is N. Therefore, we can take as 
an estimator N of N the value for which the probability that X equals j is 
maximum. Such an estimator is called a maximum likelihood estimate of N 
and equaL·: 
EXAMPLE 3.15 
To establish the number of fishes in a lake, it is proceeded as follows: 
1000 fishes are captured and tagged, then returned to the lake. Days 
after, fishes are captured until 15 of them are tagged. If it was necessary 
to make 120 extractions to obtain the desired number of marked fishes, 
then according to the previous remark, the maximum likelihood estimate 
of the population size is: 
N = 
1000 x 120 
15 
= 8000. 
Note 3.8 Let X be a random variable having a negative binomial distribution 
with parameters k and p, and let Y be a random variable having a binomial 
distribution with parameters n and p. Then: 
oo 
P(X>n)= Σ 
P(X^j) 
j=n+l 
-t(i:',y «'-"'■' 
j=0 
^J ' 
= P(Y < k). 

138 
SOME DISCRETE DISTRIBUTIONS 
EXERCISES 
3.1 
A fair coin is flipped an even number of times. What is the probability 
that half the times the result obtained is a "head" ? 
3.2 
In a national automobile club a telephonic campaign is started in order 
to increase the number of its members. FVom previous experience, it is known 
that one out of every 10 people called actually join the club. If in a day 20 
people are called, what is the probability that at least two of them join the 
club? What is the expected number? 
3.3 
A fair die is rolled 10 consecutive times. Find the probability that the 
number 5 is obtained at least 3 times. 
3.4 
In the computer room of an educational center there are 20 computers. 
The probability that any given computer is being used in peak hours is 0.9. 
What is the probability that at least one computer is available in peak hours? 
What is the probability that all the computers are being used? 
3.5 
An airline knows that 5% of the people making reservations on a certain 
flight will not show up. Consequently, their policy is to sell 52 tickets for a 
flight that can hold only 50 passengers. Assume that passengers who come 
to the airport are independent with each other. What is the probability that 
there will be a seat available for every passenger who shows up? 
3.6 
Find the probability distribution of a binomial random variable X with 
parameters n and p truncated to the right at X — r, r > 0. 
3.7 
Let X be a random variable having a binomial distribution with pa-
rameters n and p. Suppose that E (X) = 12 and Var (X) — 4. Find n and 
P-
3.8 
A coin is flipped as many times as needed to obtain a head for the first 
time. 
a) Describe the sample space of this experiment. 
b) Let X be the random variable representing the required number of 
tosses. Find P {X > 1) and P (X < n). 
3.9 
Assume that the number of clients X arriving in an hour at a bank is a 
Poisson random variable and P(X = 0) = 0.02. Find the mean and variance 
ofX. 
3.10 
Let X be a random variable having a Poisson distribution with pa-
rameter A. If P{X = 0) = 0.4, find P(X < 3). 
3.11 
Let X be a Poisson random variable with parameter λ. Assume P(X = 
2) = 2P(X = 1). Find P(X = 0). 
3.12 
The quality control department of a factory inspects the units finished 
by the assembly line. It is believed that the proportion of defective units 

EXERCISES 
139 
equals 0.01. What is the probability that the fifth unit inspected is the second 
defective one? 
3.13 
Casinos use roulettes with 38 pockets, of which 18 are black, 18 are 
red and 2 are green. Let X be the random variable representing the number 
of times it is necessary to spin the wheel to obtain a red number for the first 
time. Find the probability mass function of X. 
3.14 
A number from the interval (0,1) is randomly chosen. What is the 
probability that: 
a) The first decimal digit is 1. 
b) The second decimal digit is 5. 
c) The first decimal digit of its square root is 3. 
3.15 
A multiple-choice test contains 30 questions, each with four possible 
options. Suppose that a student only guesses the answers: 
a) What is the probability that the student answers right more than 20 
questions? 
b) What is the probability that the student answers less than 3 questions 
right? 
c) What is the probability that the student answers all the questions wrong? 
3.16 
Recent studies determined that the probability of dying due to a cer-
tain flu vaccine is 0.00001. If 200,000 people are vaccinated, and we assume 
that each person can be regarded as an independent trial, what is the proba-
bility that no one dies because of the vaccine? 
3.17 
A professor wishes to set up the final examination with multiple-choice 
test. The examination must have 15 questions, and on account of internal 
regulations, a student approves if he or she answers at least 10 questions right. 
To minimize the "risk" of a student approving the examination by guessing 
the answers, the teacher wishes to put k possible choices to each question with 
only one being correct. What value must k have so that a student randomly 
answering the test has a probability of passing equal to 0.001? 
3.18 
Fifteen daltonic people are required for a medical experiment. If it 
is known that only 0.1% of the population has this condition, what is the 
expected number of interviews that must be carried out to find the 15 people 
required? 
3.19 
There are N fishes in a lake from which R (< N) are tagged. Assume 
that n (< R) fishes are caught one by one without replacement and let 7* := 
"the ith fish captured is tagged" for i = 1,2, · · · , n. What is ρ(Τί) equal to? 
Are Τχ and T3 independent? 

140 
SOME DISCRETE DISTRIBUTIONS 
3.20 
At a certain governmental institution, the probability that a call is 
answered in less than 30 seconds is 0.25. Assume the calls to be independent. 
a) If someone calls 10 times, what is the probability that 9 calls are an-
swered in less than 30 seconds? 
b) If someone calls 20 times, what is the average number of calls that are 
going to be answered in less than 30 seconds? 
c) What is the average number of calls that have to be made in order to 
get an answer in less than 30 seconds? 
d) What is the probability that 6 calls have to be made to get 2 of them 
answered in less than 30 seconds? 
3.21 
Suppose that 5% of the articles produced in a factory are defective. If 
15 articles are randomly chosen and inspected, what is the probability that 
there are at most 3 defective articles in the sample? 
3.22 
Suppose that X is a random variable having a geometric distribution 
with parameter p. Find the probability mass function of X2 and X + 3. 
3.23 
Three copies of the book "Get rich in less than 24 hours" in a library 
are lent to users for a day. The number of daily requests for a copy is a Poisson 
random variable with mean 5. Find: 
a) The proportion of days wherein the demand of a copy of the book is 
zero. 
b) The proportion of the days wherein the demand of a copy of the book 
surpasses the supply. 
3.24 
A certain system of a spacecraft must work correctly in order for the 
ship to make a safe entry to the atmosphere. A component of such a system 
operates without complications only 85% of the time. With the purpose of 
increasing the reliability of the system, four of these components are installed 
in such a way that the system will function properly if at least one of the 
components operates without complications. 
a) What is the probability that the system will malfunction? Assume that 
the components operate independently from each other. 
b) If the system fails, what can be inferred from the alleged 85% probability 
of success of a single component? 
3.25 
The records of an insurance company show that only 0.1% of the 
population suffers from a certain type of accident each year. If 10,000 people 
are randomly selected to be insured, what is the probability that no more 
than 5 of those clients have that type of accident next year? 

EXERCISES 
141 
3.26 
There are 20 spectacled bears in a forest, 5 of which are captured, 
tagged and then released. Weeks later 4 of the 20 bears are captured again. 
Find the probability that at most 2 of the captured bears are tagged. 
3.27 
A company analyzes the shipments from its suppliers to detect prod-
ucts that do not comply with the minimum quality specifications required. 
It is known that 3% of such products do not meet the quality standards of 
the company. What size must a sample have in order to have at least a 0.90 
probability that at least one article selected does not comply with the quality 
requirements? Suppose that in this case the hypergeometric distribution can 
be approximated by a binomial distribution. 
3.28 
A 300-page book has 253 typographical errors. Assuming that each 
page has 5000 characters, what is the probability that there are no typos on 
the first page? What is the probability that there is at least one typo on the 
first page? 
3.29 
A factory makes ink cartridges for stylographic pens. One out of every 
30 cartridges made by the factory turns out to be defective. The cartridges 
are packed in six-unit boxes. Find the expected number of boxes that contain, 
respectively, no defective cartridges, 1 defective cartridge, 2 or more defective 
cartridges, in a shipment of 1000 boxes. 
3.30 
The police suspect that in a truck loaded with 40 rice bundles there 
might be cocaine packages camouflaged. To confirm their suspicion, the police 
randomly pick 5 bundles to be inspected. If indeed, 10 from the 40 bundles 
contain cocaine camouflaged, what is the probability that at least 1 of the 
inspected bundles has cocaine? 
3.31 
At a TV contest the following game is played: the contestant must 
simultaneously extract 3 ballots from an urn containing 5 ballots marked 
with a prize and 9 unmarked ballots. If the 3 ballots drawn are marked, 
the contestant has two choices: he or she can either pick one of the marked 
prizes and retire or repeat the extraction three more times, and if in those 
repetitions all three extracted ballots are marked, then the contestant will 
win, in addition to all prizes marked in the ballots, a brand new car. If a 
contestant chooses this last alternative, what is the probability that he or she 
has of winning? 
3.32 
(Ross, 1998) The number of times a person suffers from a cold in a year 
is a random variable having a Poisson distribution with parameter λ = 3/year. 
Suppose that there is a new medicine (based on large quantities of vitamin C) 
that reduces the Poisson parameter to λ — 2/year on 85% of the population 
and has no major effects on preventing colds for the remaining 15%. If a 
given person takes the medicine throughout a year and during that time has 
2 colds, what is the probability that the medicine did not have an effect on 
that person? 

142 
SOME DISCRETE DISTRIBUTIONS 
3.33 
Determine the expected value and the variance of the number of times 
that is necessary to roll a fair die until the result "1" happens 4 consecutive 
times. 
3.34 
A player has the following strategy in the roulette: He bets two tokens 
to the red color. If on the first spin of the wheel appears a red number, he 
takes the money won and retires; if on the first spin of the wheel appears a 
black or green number, he spins the wheel two more times betting two tokens 
to the red color each time and then retires. Let X be the random variable 
representing the fortune of the player. Find E(X) (see Exercise 3.13). 
3.35 
To pay for his college fees, a young man has decided to sell cheese and 
ham sandwiches. The money needed to make each sandwich is $0.50 and he 
expects to sell them at $1.50 each. However, the sandwiches that are not sold 
on any day cannot be sold on the next day. If the daily demand of sandwiches 
is a random variable having a binomial distribution with parameters n = 20 
and p = | , how many sandwiches must he make to maximize his expected 
daily income? 
3.36 
A fair coin is flipped as many times as necessary to obtain "head" for 
the first time. Let X be the number of required flips. 
a) 
¥maE(X). 
b) Find E(2X) (if it exists). 
3.37 
A coin is biased in such a way that the probability of obtaining a 
"head" equals 0.4. Use Chebyschev's inequality to determine how many times 
must the coin be flipped in order to have at least a 0.9 probability that the 
quotient between the number of heads and the number of total flips lies be-
tween 0.3 and 0.5. 
3.38 
Let X be a random variable having a Poisson distribution with pa-
rameter A. Find the value of λ for which P(X = k) is maximum. 
3.39 
A company rents out time on a computer for periods of t hours, for 
which it receives $400 an hour. The number of times the computer breaks 
down during t hours is a random variable having the Poisson distribution with 
λ = (0.8)ί, and if the computer breaks down x times it costs 50a; dollars to fix 
it. How should the company select t in order to maximize its expected profit? 
3.40 
A film supplier produces 10 rolls of a specifically sensitized film each 
year. If the film is not sold within a year it must be discarded. Past experience 
indicates that D, the small demand for the film, is a Poisson-distributed 
random variable with parameter 8. If a profit of $7 is made on every roll 
which is sold, while a loss of $2 is incurred on every roll which must be 
discarded, compute the expected profit which the supplier may realize on the 
10 rolls which he produces. 

EXERCISES 
143 
3.41 
Let X be a random variable having a Poisson distribution with pa-
rameter λ. Prove the following: 
1 
f°° 
P ( X < n ) = — / 
e~xxndx, 
n = 0 , l , · · · . 
n] Jx 
3.42 
Let X be a random variable having a binomial distribution with pa-
rameters n and p. Prove that: 
/ 
1 
\ _ l - ( l - p ) " + 1 
\X + l) 
(n + l)p 
3.43 
Let X be a random variable having a binomial distribution with pa-
rameters n and p. Find the value of p that maximizes P(X — k) for k = 
0,1,·· · ,n. 
3.44 
Let X be a random variable having a hypergeometric distribution with 
parameters n, R and N. 
a) Prove that: 
b) Verify 
P(X = j + 
l)>P{X=j) 
if and only if 
( n + l ) ( f l + l) _ 
J 
7V + 2 
3.45 
Let X be a random variable having a Poisson distribution with pa-
rameter λ. Prove that: 
E (Xn) = XE ({X + l)"" 1) 
3.46 
Let X be a random variable having a geometric distribution with pa-
rameter p. Prove that: 
P{X = n + k\X 
>n) = P(X = k) . 
3.47 
Let X be a random variable having a geometric distribution with pa-
rameter p. Find E (jf )· 
3.48 
Let X be a random variable having a Poisson distribution with pa-
rameter λ. Prove: 

144 
SOME DISCRETE DISTRIBUTIONS 
a) E{X2) = \E (X + 1). 
b) If λ = 1, t h e n £ ( | X - l | ) = §. 
3.49 
Find the characteristic function of a random variable having a binomial 
distribution with parameters n and p. 
3.50 
Find the characteristic function of a random variable having a Poisson 
distribution with parameter A. 
3.51 
How many children must a couple have so that, with a 0.95 probability, 
she gives birth to at least one boy and one girl? 
3.52 
A reputed publisher claims that in the handbooks published by them 
misprints occur at the rate of 0.0024 per page. What is the probability that 
in a randomly chosen handbook of 300 pages, the third misprint will occur 
after examining 100 pages? 

CHAPTER 4 
SOME CONTINUOUS DISTRIBUTIONS 
In this chapter we will study some of the absolute continuous-type distribu-
tions most frequently used. 
4.1 
UNIFORM DISTRIBUTION 
Suppose that a school bus arrives always at a certain bus stop between 6 
AM and 6:10 AM and that the probability that the bus arrives in any of 
the time subintervals, in the interval [0,10], is proportional to the length 
of the subinterval. This means it is equally probable that the bus arrives 
between 6:00 AM and 6:02 AM as it is that it arrives between 6:07 AM and 
6:09 AM. Let X be the time, measured in minutes, that a student must 
wait in the bus stop if he or she arrived exactly at 6:00 AM. If throughout 
several mornings the time of the bus arrival is measured carefully, with the 
data obtained, it is possible to construct a histogram of relative frequencies. 
From the previous description it can be noticed that the relative frequencies 
observed of X between 6:00 and 6:02 AM and between 6:07 and 6:09 AM are 
practically the same. The variable X is an example of a random variable with 
uniform distribution. More precisely it can be defined in the following way: 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
145 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

146 
SOME CONTINUOUS DISTRIBUTIONS 
fix) 
l/(b-a) 
Figure 4.1 
Density function of a uniform distribution 
Definition 4.1 (Uniform Distribution) It is said that a random variable 
X is uniformly distributed over the interval [a, b], with a < b real numbers, if 
its density function is given by: 
f(x) 
= { bh if a<x<b 
\ 0 
otherwise . 
The probability density function of a uniform distribution over the interval 
[a,b] is shown in Figure 4.1. 
Notation 4.1 The expression X = U\a, b] means that the random variable 
X has a uniform distribution over the interval [a,b\. 
It is easy to verify that if X = U[a, b], then the cumulative distribution 
function of X is given by: 
r o 
F(x) 
if x < a 
f=4 
if a < x < b 
o—a 
— 
I i 
if x > b . 
The distribution function of a random variable with uniform distribution 
over the interval [a, b] is shown in Figure 4.2. 

UNIFORM DISTRIBUTION 
147 
F(X) 
Figure 4.2 
Distribution function of a random variable with uniform distribution 
over the interval [a, b] 
EXAMPLE 4.1 
Let X = U[-3,2]. Calculate: 
1. P{X > 0) . 
2. P ( - 5 < X < i ) . 
Solution: In this case the density function of the random variable X is 
given by: 
f(x) 
= { I if - 3 < x < 2 
' 
\ 0 
otherwise . 
Therefore, 
f2 1 
2 
Jo 5 
5 
and 
'(-**si)=/>-KH 
10' 

148 
SOME CONTINUOUS DISTRIBUTIONS 
rb 
kdx 
Ό 
EXAMPLE 4.2 
Let a, b € K be fixed, with a < b. A number X is chosen randomly in the 
interval [a, b]. This means that any subinterval of [a, b] with length τ has 
the same probability of containing X. Therefore, for any a < x < y < b, 
we have that P (x < X < y) depends only on (y — x). If / is the density 
function of the random variable X, then: 
kdx = P(x<X<x 
+ dx) = f(x)dx 
. 
This means f(x) = k being k an appropriate constant. Given that 
/
oo 
fb 
f(x)dx = / 
-oo 
Ja 
it can be deduced that k = 53^. This is, X = U[a, b]. 
EXAMPLE 4.3 
A number is randomly chosen in the interval [1,3]. What is the prob-
ability that the first digit to the right side of the decimal point is 5? 
What is the probability that the second digit to the right of the decimal 
point is 2? 
Solution: Let X := "number randomly chosen in the interval [1,3]". 
The density function of the random variable X according to the previous 
example is: 
f(x) 
= I \ 
if 1 < * < 3 
Jy ' 
\ 0 
otherwise . 
Therefore, 
P( "first digit to the right side of the decimal point of X is 5") 
= P(1.5 < X < 1.6) + P (2.5 < X < 2.6) 
rl.6 1 
/·2·6 
= / 
-dx + / 
-dx = 0.1 
Λ.5 
2 
J2.5 2 
and 
P( "second digit to the right of the decimal point of X is 2") 
= P ( X € ( J {[1.Λ2, l.fc3) U [2.fc2,2.fc3)} ] 
V 
fc=o 
/ 
= 20 x - x 0.01 = 0.1 . 
A 
2 

UNIFORM DISTRIBUTION 
149 
EXAMPLE 4.4 
A point X is chosen at random in the interval [—1,3]. Find the pdf of 
Y = X2. 
Solution: For y < 0, FY(y) = 0. For y £ [0,1): 
FY(y) = P(Y < y) 
= P{X2 < y) 
= P(-Vy <*<Vy) 
-i 
s/v i 
-dx 
Vv4 
2 ' 
For y e [1,9): 
FY{y) = 
±dx+ 
-dx 
2 
4 
' 
For y € [9, oo), FY(y) = 1. Hence, the pdf of Y is: 
fy(y) = < 
φ 
if 0 < y < l 
sjg 
if K»<9 
0 
otherwise . 
EXAMPLE 4.5 
An angle Θ is chosen randomly on the interval (0, ^). What is the 
probability distribution of X = tan 0? What would be the distribution 
of X if Θ was to be chosen from (—π/2, π/2)? 
Solution: Given that Θ = U[0, §]: 
■"H ; 
\ 0 
otherwise . 
Let Λ" = tanö. Since tan0 is a strict monotonous and differentiable 
function in Θ 6 (0, f), by applying Theorem 2.4: 
/x(x) = /e(tan- 1(x))x dtan 
1(x)\ 
dx 

150 
SOME CONTINUOUS DISTRIBUTIONS 
After simplifications, we get: 
f*<*) = { I 
-jT 
if 0 < x < oo 
(l+x2) 
otherwise 
When Θ is randomly chosen on the interval (—π/2,π/2), 
W ) = { 0* ot 
4 
:f 
- f < Θ < f 
otherwise . 
tanö is again a strict monotonous and difFerentiable function. By ap-
plying Theorem 2.4, we get: 
fx{x) = n(ilx>y -°0<a;<00· 
A 
Theorem 4.1 If X 
is a random variable with uniform distribution over the 
interval [a,b], then: 
1. E(X) = a±*. 
2. Var(X) = 
^ ^ . 
Proo/: 
1. 
£(*) = /" x—!—cte 
a + b 
2. 
Therefore: 
12 
3. Follows from the definition of the mgf. 
E(X2) 
Vnr(X\ 
2 
Ja 
-?- 
dx 
b — a 
b2+ab + a2 
b2-
(b-
3 
- 2ab + a2 
12 
-a)2 

NORMAL DISTRIBUTION 
151 
EXAMPLE 4.6 
Suppose that X = U[a, b] and that E(X) 
= 2 and Var(X) = § . 
Calculate P{X < 1). 
Solution: We have that ^ 
= 2 and ^ = | ^ = f. Due to this, a = \ 
and 6 = \. Then: 
ρ(χ<ΐ) = /;ΐώ = 1. 
Note 4.1 Suppose that X is a continuous random variable with increasing 
distribution function Fx{x). 
Let Y be a random variable with uniform dis-
tribution in the interval (0,1) and let Z be a random variable defined as 
Z := F^1 (Y). The distribution function of the random variable Z is given 
by: 
Fz(z) = 
P(Z<z) 
= 
P(Fx\Y)<z) 
= 
P(Y<Fx(z)) 
= FX (z). 
That is, the random variables X and Z have the same probability distribution. 
4.2 
NORMAL DISTRIBUTION 
The normal distribution is one of the most important and mainly used not 
only in probability theory but also in statistics. Some authors name it Gaus-
sian distribution in honor of Gauss, who is considered the "father" of this 
distribution. The importance of the normal distribution is due to the famous 
central limit theorem, which will be discussed in Chapter 8. 
Definition 4.2 It is said that a random variable X has normal distribution 
with parameters μ and σ, where μ is a real number and σ is a positive real 
number, if its density function is given by: 
f(x) = —^= exP 
2 \ 
σ 
) 
, x G R . 
It is left as an exercise for the reader to verify that / is effectively a density 
function. That is, / is nonnegative and: 
J —( f(x)dx = 1. 

152 
SOME CONTINUOUS DISTRIBUTIONS 
1 
0.9 
0.8 
0.7-
0.6 
<g;0.5h 
0.4 
0.3 
0.2 
0.1 
0 
σ=1/2 
^ σ=2 
-3 
-2 
-1 
0 
1
2 
3 
4 
x 
Figure 4.3 
Probability density function of normal distribution with μ = 0 and 
different values of σ 
The parameters μ and σ are called location parameter and scale parameter, 
respectively. We precisely give the concepts to follow. 
Definition 4.3 (Location and Scale Parameters) Let Y 
be a random 
variable. It is said that θ\ is a location parameter if for allc&R 
we have that 
a random variable Z :=Y + c has parameter 0i + c . That is, if /y(·; 0i, 02) 
is the density function of Y, then the density function of Z is fz(·', &i + ci ·)· 
It is said that 02 *s a scale parameter if 02 > 0 and for all c € R the random 
variable W := cY has parameter |c|02· That is, i//y(-;0i>02) is the density 
function of Y, then the density function of W is fw(·', ·, |c| Ö2)-
Notation 4.2 We write X = Ν(μ,σ2) 
to indicate that X is a random vari-
able with normal distribution with parameters μ and σ. 
Figure 4.3 shows the density function of the random variable X with normal 
distribution with μ = 0 and different values of σ. 
In Figure 4.4, it can be seen the density function of the random variable 
X = Λ/"(μ, σ2) for σ = 1.41 and different values of μ. 

NORMAL DISTRIBUTION 
153 
0.25 r 
Figure 4.4 
Probability density function of normal distribution with σ = 1.41 and 
different values of μ 
The distribution function of the random variable X = Λ/"(μ, σ2) is given 
by: 
The graph of F, with μ = 0 and σ = 1, is given in Figure 4.5. 
Definition 4.4 (Standard Normal Distribution) If X — λί(0,1), 
then 
it is said that X has a standard normal distribution. 
The density function 
and the distribution function of the random variable are denoted by φ{·) and 
Φ(·), respectively. 
Note 4.2 The density function of a standard normal random variable is sym-
metric with respect to the y axis. Therefore, for all z < 0 it is satisfied that: 
Φ(ζ) = 1 - Φ ( - ζ ) . 
Note 4.3 Let X = λί{μ, σ2) and let Y := aX + b where a and b are real 
constants with a Φ 0. As seen in Chapter 2, it is known that the density 
F( 
1 
f 
x) = — 7 = / 
σγ2π 7-oc exp 

154 
SOME CONTINUOUS DISTRIBUTIONS 
F(x) 
1 
0.9 
0.8 
0.7 
0.6 
0.5 
0.4 
0.3 
0.2 
0.1 
0 
-
■ 
-
-
-
-
-
-4 
-3 
Figure 4.5 
Standard normal distribution function with μ = 0 and σ = 1 
function of the random variable Y is given by: 
1 1 
Γ 1 / x - ίαμ + b)\2' 
— ΤΊ 
i 
e xP —«I 
) 
\a\ \?2πσ 
2 \ 
ασ 
) 
This means Y has a normal distribution with location parameter αμ + b and 
scale parameter \α\σ. Particularly, if X = Ν{μ,σ2), 
then Y = ^—^ has a 
standard normal distribution. 
That is, in order to know the values of the 
random variable's distribution function with arbitrary normal distribution, it 
is sufficient to know the values of the random variable with standard nor-
mal distribution. In Appendix D.3 the table of values of the standard normal 
distribution are provided. 
EXAMPLE 4.7 
Let X = M (1,4). Calculate: 
1. Ρ ( 0 < Λ " < 1 ) . 
2. P (X2 > 4). 

NORMAL DISTRIBUTION 
155 
Solution: It is known that 
P(0<X<l) = p ( - ± < ^ = i < 0 ) 
and 
= Φ(0) -H) 
0.5 - 0.30854 
0.19146 
P ( X 2 > 4 ) =1-P(\X\ 
<2) 
= 1 - P ( - 2 < X < 2 ) 
-'-[•G)-(-D: 
= 1 - [0.69146 - 0.06681] 
= 0.37535 . 
A 
EXAMPLE 4.8 
Let X = 7V(12,4). Find the value of c such that P(X > c) = 0.10. 
Solution: 
P(X > c) = 1 - P{X < c) 
- ' " ' ( 
1 - Φ 
X - 1 2 
c - 1 2 v 
That is: 
Φ 
So that the values given in the table we have that: 
^ 
= 1.285. 
and c = 14.57. 
▲ 

156 
SOME CONTINUOUS DISTRIBUTIONS 
■ EXAMPLE 4.Θ 
Suppose that the life lengths of two electronic devices say, D\ and D2, 
have normal distributions jV(40,36) and Λ/"(45,9), respectively. If a 
device is to be used for 45 hours, which device would be preferred? If it 
is to be used for 42 hours, which one should be preferred? 
Solution: Given that Dx = Λ/"(40,36) and D2 = ΛΑ(45,9). We will find 
which device has greater probability of lifetime more than 45 hours: 
„ , ^ 
.^ 
„fDi-40 
4 5 - 4 0 \ 
- ' - ( S ) 
= 1 - 0.7995 
= 0.2005. 
Also: 
Λ*>«,-Ρ(^>^) 
= 1 - Φ (0) 
= 1-0.5 
= 0.5. 
Hence, in this case, the device D2 will be preferred. Now, we will find 
which device has greater probability of lifetime more than 42 hours. 
Similar calculation yields: 
P(D1 > 42) = 1 - Φ Q ) 
= 0.3707 
P{D2 > 42) = 1 - Φ (-1) 
= 0.8413. 
In this case also, the device D2 will be preferred. A 
■ EXAMPLE 4.10 
Let X denote the length of time (in minutes) an automobile battery will 
continue to crank an engine. Assume that X ~ Λ/"(10,4). What is the 
probability that the battery will crank the engine longer than 10 + x 
minutes given that it is still cranking at 10 minutes? 

NORMAL DISTRIBUTION 
157 
Solution: We want to find: 
P(X > 10 + x | X > 10) 
= 
P(X > 10 + x) 
P(Z > x/2) 
P(X > 10) 
1/2 
For a specific choice x = 2, we get: 
P{X > 10 + x | X > 10) = 2[1 - φ(1)} = 0.3174. 
A 
Note 4.4 Suppose that X = ΛΓ(μ,σ2). T/ien 
Ρ( /χ-3σ<Χ< /χ + 3σ) = ρ ί / χ - 3 σ - / ' < ^ ^ < Μ + 3 σ - / Λ 
\ 
σ 
σ 
σ 
J 
= Φ(3) - Φ(-3) 
= 0.99865 - 0.00135 
- 0.9973 
or equivalents P (\X -μ\> 
3σ) = 0.0027. 
Next, we will find the expected value, the variance and the moment gener-
ating function of a random variable with normal distribution. 
Theorem 4.2 Let X =Μ{μ,σ2). 
Then: 
1. E(X) = μ. 
2. Var(X) = σ2. 
3. m x ( i ) = e x p [ / i i + ^ ] . 
Proof: We will calculate the moment generating function. Prom it, we can 
easily find the expected value and the variance: 
1 
f°° 
mx (t) 
= 
-=- 
/ 
exp tx — (χ-μ) 
·\/2π< 
1 
l 
r° 
2πσ J-, exp 
2σ2 
{x - μ - 
a2t)2 
dx 
2*21 
2σ2 
+ μί-\- σΗ 
dx 
2+2 
■ exp μ£ + σΗ 
>/2_7 — r ^. 
. 
2 
σ2ί2" 
ί 
J — c 
exp 
(χ-{μ + σ2*})2 
2σ2 
dx 
exp μί + 

158 
SOME CONTINUOUS DISTRIBUTIONS 
Hence 
E(X) = [μ + a2t] exp 
2+21 
μί + σΗ 
= μ 
t=o 
and 
E(X2) = (σ2 +[μ + a2t}2) exp L 
+ 
2+2 η 
σΗ 
σ2+μ2 
t=o 
we get: 
Var(X) = σ2. 
Note 4.5 It can be verified that the characteristic function of the random 
variable X with normal distribution with parameters μ and σ is given by: 
Φχ(ί) = exp 
2+2 
ίμί 
σΗ 
Note 4.6 The normal distribution is another limit form of the binomial dis-
tribution only if the following conditions over the parameters n and p are 
satisfied in the binomial distribution: n —> oo and if neither p nor q = 1 — p 
is very small. 
Suppose that X = B(n,p). 
Then: 
P(X = x) = ( " V ( l - P) n _*, x = 0,1, · · · , n . 
When n —^ oo, we have that x —> oo and additionally: 
n\ « ν/2πβ _ ηη η + 5 
(Stirling's formula) . 
Therefore: 
V /2^e- nn n +5p x(l 
-p)n~x 
lim 
n—yoo O-
PY 
— lim 
n - v c o v / 2 ^ e - x x * + i v
/ 2 ^ e - ( n - x ) ( r l - 
x)(n~x)+h 
= lim 
nn+ipx(l 
-p)n-xy/np(\ 
-p) 
η-κχ> y/2Tvxx+i ( n - x)("-*)+ i 
^np(l-p) 
lim 
(ηρ) Χ +^(η(1-ρ))"" Χ + έ 
n->oo y/2^x*H 
(n - χ)(η-χ)+5 
y/np(l-p) 
1 
/np\x+h 
/ n ( l — p)\ 
n^°°V2n\/np(l-p) 
V x > 
\ n-x 
J 
( n - i ) + i 

NORMAL DISTRIBUTION 1 5 9 
Let 77 := (lf Γ+* (^fe?1)^ X)+5 · lt is clear that: 
*H-('+k)*{k) + {°-'+\)b{$r5ij) ■ 
(41) 
If we take Z := . ~np , we have that Z takes the values z = 
x~nP , 
y/np(l-p) 
y'np(l-p) 
When considering the limit when n —► oo, we have that Z takes all of the 
values between —oo and oo. Isolating x in the previous equation it is obtained 
that x = Zy/np(l —p) + np. Replacing in (4-1) we get: 
IniV = (z^nW^P) 
+nP+ \) In H " *
1 ^ 
^
) 
/ 
/ . 
x l\ 
(n- (z^np(l~p)+np) 
+ (n-(z^np(l-p) + np) + -)ln\ 
^ _ p) 
= I np + z^np{\-p) 
+ - J In (1 + z J —- J 
+ (»(1 - P) - zVM^p) 
+ I) In (l - ζ^φ^) 
Developing the function h(x) — ln(l + x), it is obtained: 
IniV = [z^np{l - p) + »p + | ) [ , ^ Ο - i ^ (L_P) + .. 
+ ί «(1 - P) ~ V ^ i - P ) + 2 j 
*2(i - p ) - i 3 / O J I P ) ! + ^ n p ( 1 _ p ) _ i 2 ( 1 _ p ) 
2 υ np 
I 
2 y np 4 \ np J 
+ 
4 U(l-P)/ 
ΤΤιαί is: 
In »--k'+'+MFF+ypi)^-

160 
SOME CONTINUOUS DISTRIBUTIONS 
Therefore, 
and hence: 
Given that 
lim lnJV = -z2 
n—>oo 
2 
lim N = e*z . 
P(X = x) = P(x <X <x + dx) 
_
/ 
x — np 
X — np 
x + dx — np\ 
\y/np(l-p) 
y/np(l -p)~ 
y/np(l 
-p)J 
= P(z < Z <z + dz) 
« g(z)dz 
where g(-) is the density function of the random variable Z, and 
g(z) = lim —== x — 
η-^«>·ν/2π 
Ν 
fc
expH
z2) 
ν/2π 
That is, Z = J\f(0,1). In other words, if n is sufficiently large B(n,p) 
w 
Λ/"(ηρ, np(l — p)). /n practice, the approximation is generally acceptable when 
p 6 (0, \) and np (1 — p) > 9 or np > 5, or ifp e (5,1) and n (1 — p) > 5. In 
ί/ie case of p = \ it is obtained that the approximation is quite good even in 
the case in which n is "small" (see Hernandez, 2003). 
The result that has recently been deduced is known as the Moivre-Laplace 
theorem and as it will be seen later on that it is a particular case of the central 
limit theorem. 
■ EXAMPLE 4.11 
A normal die is tossed 1000 consecutive times. Calculate the probability 
that the number 6 shows up between 150 and 200 times. What is the 
probability that the number 6 appears exactly 150 times? 
Solution: Let X := "Number of times the number 6 is obtained as a 
result". It is clear that X = B(1000, | ) . According to the previous result, 
it can be supposed that X has a normal distribution with parameters 

FAMILY OF GAMMA DISTRIBUTIONS 
1 6 1 
μ = ψ and σ2 = ±ψ. Therefore: 
, 150 - ψ 
X - ψ 
200 - ψ 
P (150 < X < 200) = P 
= = J - < —-j=^- < 
a 
/l250 
/l250 
/l250 
V -^ - 
V"5" 
V -» -
= P (-1.14142 < Z < 2.8284) where Z = 7V(0,1) 
= Φ(2.8284) - Φ(-1.14142) 
= 0.9976 - 0.07927 
= 0.91833. 
▲ 
To answer the second part of the question, it may be seen that because 
the binomial distribution is discrete and the normal distribution is a 
continuous one, an appropriate approximation is obtained as below: 
P(X = 150) = P (149.5 < X < 150.5) 
/l49.5_5Q0 
X _ 5 Q 0 
150.5-52Q 
= P[ 
j=J-<—r=^-< 
r=2-
\ 
/1250 
/1250 
/1250 
\ 
V"5" 
V~*~ 
\~9~ 
= P (-1.4566 < Z < -1.3718) 
= Φ(-1.3718) - Φ(-1.4566) 
= 0.08534 - 0.07215 
= 0.01319 . ▲ 
4.3 
FAMILY OF GAMMA DISTRIBUTIONS 
Some random variables are always nonnegative and they have distributions 
that are biased to the right, that is, the greater part of the area below the 
graph of the density function is close to the origin and the values of the 
density function decrease gradually when x increases. An example of such 
distributions is the gamma distribution whose density function is shown in 
Figure 4.6. 
The gamma distribution is used in an extensive way in a variety of areas as, 
for example, to describe the intervals of time between two consecutive failures 
of an airplane's motor or the intervals of time between arrivals of clients to a 
queue in a supermarket's cashier point. 
The gamma distribution is the generalization of three particular cases that, 
historically, came first: the exponential function, the Erlang function and the 
chi-square distribution. 

162 
SOME CONTINUOUS DISTRIBUTIONS 
Figure 4.6 
Probability density function of a gamma distribution with parameters 
r = 2 and λ = 1 
Definition 4.5 (Gamma Distribution) It is said that the random variable 
X 
has gamma distribution with parameters r > 0 and X > 0 if its density 
function is given by 
/ ( x) = i φ> (λχ)Γ * exP (-λχ) if x > ° 
0 
otherwise 
(4.2) 
where Γ(·) is the gamma function, that is: 
Γ(Γ) := / 
t r _ 1 exp(-*)A. 
Jo 
The order of the parameters is important due to the fact that r is the shape 
parameter while X is the scale parameter. 
The verification that / is a density function is left as an exercise for the 
reader. 
Figure 4.7 shows the gamma density function for λ = 1 and different values 
of r. 
Figure 4.8 shows the form of the gamma density function for r = 1.5 and 
different values of λ. 
Notation 4.3 The expression X — Γ(Γ, λ) means that X 
has a gamma dis-
tribution with parameters r and X. 

FAMILY OF GAMMA DISTRIBUTIONS 
163 
0.45 
0.4 
0.35 
0.3 
£.0.25 
0.2 
0.15 
0.1 
0.05 
I 
I 
I 
I 
I 
I 
I 
- / \ 
r= 1.5 
7 \ 
' 
V 
r=2 
' 
\ x 
' 
\ N 
< 
V'\".. 
r=3 
/ \CX-.. 
/ 
\ \ 
\x'vx 
.' 
/ 
■''' 
\
\ 
''"··.. 
V
v v 
■; / 
/ 
\
χ 
\ 
v - v / - 4 
ΐ 
^ 
^**^. 
^· ^ 
' ' ■· . 
~* · ^ 
/ 
— ^ _ ~ · -~^ 
-
-
-
■ 
-
~ 
-
— · , 
Figure 4.7 
Probability density function of a gamma density function for λ = 1 and 
different values of r 
£ 
U.OO 
0.3 
0.25 
0.2 
0.15 
0.1 
0.05 
n 
/Λλ=1.5 
/ 
\ 
./ 
λ=2 
\ 
/ 
# * * " " * 
*"*■ 
\ 
/ 
>- \ 
\ ' 
-> \ 
/ 
/ 
N 
\ 
/ 
S \ 
1 
\ 
,' .' "λ=3 "" " \ ^ 
/ 
\-i· 
' / 
\ ^ 
1 
\ 
^ 
^*Χ. 
^** 
""*'** 
\ ^ 
**" ^ 
"*' — . „ -
^^^—-^_ 
~" """ ~" 
■ 
■
)
■
!
■
■ 
Figure 4.8 
Probability density function of a gamma density function for r = 1.5 
and different values of λ 

164 
SOME CONTINUOUS DISTRIBUTIONS 
The distribution function of the random variable X with gamma distribu-
tion with parameters r and λ is given by: 
F(x) = Γ 
Jo V(r) 
ρλχ 
1 
f 
= = ^ 
/ 
ωΓ_1 
exp{-u)du. 
r(r) Jo 
When r is a positive integer, it is known that T(r) = (r — 1)! using which we 
get: 
" 
]{\x)k 
F(x) = l-exp(-Aa?)J3-
fc=0 fc! 
It can be seen that the right side of the above equation corresponds to P(Y > 
r) where Y = V(Xx). In Chapter 9 we will see that there is a relationship 
between the Poisson distribution and the gamma distribution. 
In the following theorem we will determine the expected value, the vari-
ance and the moment generating function of a random variable with gamma 
distribution. 
Theorem 4.3 If X = Γ(τ-,λ), then: 
1. E(X) = ^. 
2. Var(X) = £ . 
3- mx(t) 
= ( ) & ) ' i f 
t<X-
Proof: 
We mil calculate the moment generating function of X and then, 
from it, we will find E(X) 
and Var(X). 
It is known that: 
f°° 
X 
mx(i) 
= 
/ 
exp(ix)—Γ-Τ- (Ax)r_1exp(-Ax)cZx 
Jo 
Γ(Γ) 
{x=i) l 
Γ(Γ) 
// (λ - t) > 0, then 
r 
/.oo (x 
_.\r 
K 
' ar p- 1exp(-(A-t)x)dx. 
g (x) := 
' xr 
x exp(-(A - 
t)x)X{o,oo)(x) 
is gamma density function, and therefore: 
-x r _ 1 exp(—(λ — t)x)dx = 1. 
/ 
Jo 
( λ - * ) ' 
r-l. 
Γ(Γ) 

FAMILY OF GAMMA DISTRIBUTIONS 
165 
Then: 
Further: 
te) 
"»*(*) = [^-.) 
ift<X-
E(X) = 
imx(t) 
E(X*) 
= 
^mx(t) 
dt 
dt2' 
t=o 
r 
λ 
r2 +r 
t=o 
λ 2 
In particular cases, r — 1 and λ > 0 , λ = | and r = \ 
with k positive 
integer, and r > 1 and λ > 0 , we get,respectively, the exponential distri-
bution, the chi-square distribution with k degrees of freedom and the Erlang 
distribution. 
Notation 4.4 The expression X = Exp(X) indicates that X has an exponen-
tial distribution with parameter X. 
The expression X = X?k-, indicates that X has a chi-square distribution 
with k degrees of freedom. 
The expression X = Erlang(r, X) indicates that X has an Erlang distribu-
tion with parameters r and X. 
EXAMPLE 4.12 
The time (in minutes) required to obtain a response in a human exposed 
to tear gas A has a gamma distribution with parameter r = 2 and 
λ = \. The distribution for a second tear gas B is also gamma but has 
parameters r = 1 and λ = \. 
1. Calculate the mean time required to get a response in a human exposed 
to each tear gas formula. 
2. Calculate the variance for both distributions. 
3. Which tear gas is more likely to cause a human response in less than 1 
minute? 
Solution: Let X\ X<i be response times from tear gas A and B, respec-
tively. 
1. Mean: 
E{Xi) = 4; 
E{X2) = 4. 

166 
SOME CONTINUOUS DISTRIBUTIONS 
2. Variance: 
Var(Xi)=8; 
Var(X2) 
= 16. 
3. We need to evaluate P(Xi < 1), i = 1,2. 
3 
P(Xi < 1) 
1 
2yß 
P(X2 < 1) 
= 
1 - e~ 
= 0.0902 
0.9817 . 
Hence the second tear gas is more likely to cause a human response. 
In the next example, we will prove that if Z = Λ/"(0,1) then Z2 = χ2. 
■ EXAMPLE 4.13 
If Z is a standard normal random variable, find the pdf oiY = Z2. 
Solution: The cdf of Y is given by: 
FY(y) 
= 
PlY<y) 
= P[Z2<y} 
= 
Pl-jy<Z<^i\ 
= 
Φ ( ^ ) - Φ ( - ^ ) = Φ ( ν ^ ) - ( 1 - Φ ( ν ^ ) ) · 
Hence, 
FY(y) = 2*{y/y) - 1 
where Φ(ζ) is the cdf of Z. By differentiating the above equation, we 
obtain: 
Mv) 
= 2 
1 
2y/V 
1 
fz(Vy) 
-J//2 
Hence, the pdf of Y is given by: 
Mv) 
-y/2 
if y > 0 
otherwise. 
Therefore, from equation (4.2) with λ = \ and r = \, we conclude 
that Υ has a chi-square distribution with 1 degree of freedom. This 
problem can also be solved using Corollary 2.2. Since y = z2, then 
Zl = y/V, 22 = 
-y/V-
My) 
= fziy/v) d(W) 
dy 
+ fz(-Vy) d(-W) 
dy 
h=e-vl2 
if v > 0 
0 
otherwise. 

FAMILY OF GAMMA DISTRIBUTIONS 
167 
Note 4.7 IfX = Exp(X), then E{X) = \; Var(X) = ^ and 
™>x(t) = j£~i fort < X. 
IfX = Xfk), then E(X) = k; Var(X) = 2k and mx(t) = (1 - 2i)~ = 
for t < \ 
The exponential distribution is frequently used as a model to describe the 
distribution of the time elapsed between successive occurrences of events, as 
in the case of the clients who arrive at a bank, calls that enter a call-center, 
etc. It is also used to model the distribution of the lifetime of components 
that do not deteriorate or get better through time, that is, those components 
whose distribution of the remaining lifetime are independent of the actual 
age. Therefore, this model adjusts to reality only if the distribution of the 
component's remaining lifetime does not depend on its age. More precisely, 
we have the following result: 
Theorem 4.4 Let X be a random variable such that P{X > 0) > 0. Then 
X = Exp(X)if 
and only if P(X > x+ t\ X > t) = P(X > x) 
for all x,t € [0, oo). 
Proof: =*>) Suppose that X = Exp(X). 
Then: 
P(X>x 
+ t) 
P(X>x 
+ t\X>t) 
= 
P(X > t) 
exp(—X(x +1)) 
exp(—λί) 
— exp(—λχ) 
= P(X > x). 
<=) Let G(x) = P(X > x). Then, by hypothesis, 
G(x + t) = G(x)G(t) 
which implies that G(x) = exp(—λχ) with X being a constant greater than 0. 
Indeed: 
e(i+i+...+i)_0(iWiy..0(iy 
\n 
n 
n) 
\n) 
\n) 
\n) 
■· 
v 
' 
N 
v 
' 
n times 
n times 
Thus, 
G\ G) 
G(l) = 
or equivalently: 
[G(l)]* 
G) 

168 
SOME CONTINUOUS DISTRIBUTIONS 
In the same way, we can obtain for τη, n 6 N the following result: 
C(?)-KD: 
= |G(1)] - · 
As G is a continuous function to the right, it can be concluded that: 
G(x) = [G(l)]* . 
On the other hand, we have that 0 < G(l) < 1. Indeed, if G(l) = 1, then 
G (x) = 1, which contradicts that G (oo) = 0. IfG (1) = 0 then G (^) = 0 and 
due to the continuity to the right it can be concluded that G (0) = 0, which 
contradicts the hypothesis. Therefore, we can take λ := — In [G(l)] in order to 
obtain the result. 
m 
The exponential distribution is used in some cases to describe the lifetime 
of a component. Let T be the random variable that denotes the lifetime of 
a given component and let / be its density function. It is clear that T is 
nonnegative. The reliability function of the device is defined by 
R{t) = P(T>t) 
= l - 
FT(t) 
where Fr(t) is the distribution function of the random variable T. The mean 
time to failure (MTTF) is defined to be the expected lifetime of the device: 
ΛΟΟ 
ΛΟΟ 
E[T] = / 
P(T >t)= 
R(t)dt. 
Jo 
Jo 
Suppose that we want to know the probability that the component fails 
during the next Δί units of time given that it is working correctly until time 
t. If F is the distribution function of the random variable T and if F(t) < 1, 
then: 
nn 
A , „, 
^ 
P(t < T < t + At) 
P(t<T<t 
+ At\T>t) 
= 
K ~ 
~ 
' 
l-P{T< 
t) 
„ W)At - 
X(t)At 
~ l - F ( t ) - m A t 
F(t) 
The function λ(ί) is known as the risk function or failure rate associated with 
the random variable T. The function R(t) :— 1 — F(t) is also known as the 
confiability function. The previous expression indicates that if we know the 
density function of the lifetime of the component, then we know its failure 
rate. Next, we will see that the converse is also valid. Writing λ(ί) as 
m-i-F(ty 

FAMILY OF GAMMA DISTRIBUTIONS 
169 
I n ( l - F ( i ) ) = - / X(s)ds + C. 
Jo 
and integrating on both sides, we obtain 
f* 
/o 
That is: 
F(t) = 1 - exp(C)exp (- 
f X(s)ds) . 
It is reasonable to suppose that F(0) = 0, that is, that the probability of 
instant failure of the component is zero. In such cases, we have that C = 0 
and therefore 
F{t)= 
1 - exp ( - /„* X(s)ds) 
if t > 0. 
which let us know the distribution function of the random variable T from 
the risk function. If the failure rate is assumed to be a constant and equal to 
λ > 0, it can be seen that for t > 0 : 
F(t) = 1 - βχρ(-λί). 
This indicates that the random variable T has an exponential distribution 
with parameter λ. 
■ EXAMPLE 4.14 
The length of lifetime T, in hours, of a certain device has an exponential 
distribution with mean 100 hours. Calculate the reliability at time t — 
200 hours. 
Solution: The density function of the random variable T is given by: 
/(*) = ϊ50βχρ(-ϊοο*);,;,(ο.οο)(*)· 
Therefore: 
P{T> 
200) = 1 - P (T < 200) 
r200 
' dt 
= l - [ - e x p ( - 2 ) + l] 
= exp(-2) = 0.13534 . 

170 
SOME CONTINUOUS DISTRIBUTIONS 
EXAMPLE 4.15 
Let X be the lifetime of an electron tube and suppose that X may 
be represented as a continuous random variable which is exponentially 
distributed with parameter λ. Let Pj = P(j < X < j· + 1). Prove that 
Pj is of the form (1 — a)^ and determine a. 
Solution: For j = 0,1,... 
Pi = P(j <X<j 
+ l) 
Xe~Xxdx 
I 
= e~jX - e" ( j + 1 ) A 
= e~jX{l - e~x) 
= 
aj(l-a) 
where a = e~~x. Hence we have the result. 
■ EXAMPLE 4.16 
Let X be a uniformly distributed random variable on the interval (0,1). 
Show that Y = —A_12n(l — X) has an exponential distribution with 
parameter λ > 0. 
Solution: We observe that Y is a nonnegative random variable implying 
FY(V) = 0 for y < 0. For y > 0, we have: 
FY(y) 
= 
P[Y<y}=P[-\-1ln(l-X)<y} 
= 
P[ln(l -X)> 
-Xy] 
= 
P[(l — X) > e~Xy] (since ex is an increasing function of x) 
= 
P[X < 1 - e~Xy] 
= 
Fx(l- 
e-A«) . 
Since X = U[0,1], Fx(x) 
= x, 0 < x < 1. Thus: 
FY(y) = 
l-e-Xv, 
so that Y is exponentially distributed with parameter λ. 
▲ 
4.4 
WEIBULL DISTRIBUTION 
The WeibuU distribution is widely used in engineering as a model to describe 
the lifetime of a component. This distribution was introduced by a Swedish 

WEIBULL DISTRIBUTION 
1 7 1 
scientist Weibull who proved that the effort to which the materials are subject 
to may be modeled through this distribution. 
Suppose now that the risk function of a random variable T is given by 
λ(ί) = 
aßtß~x 
where a and ß are positive constants. In such a case we have that: 
F ( t ) = f 1 - exp ( - /„' aßs^ds) 
if t > 0 
\ 0 
if t < 0 
{ 
1 - exp(-ai^) 
if t > 0 
0 
if * < 0 
The density function of T is given by: 
t/Λ-ί 
a/ 3^ - 1 exp(-ai^) 
if t > 0 
; w - \ o 
if t < o. 
A random variable with the above density function receives a special name: 
Definition 4.6 (Weibull Distribution) It is said that a random variable 
X has Weibull distribution with parameters a and ß if its density function 
is given by: 
., . 
f αβχΡ-1 βχρ(-αχΡ) 
if 
x > 0 
/ ( X ) = ( 
0 
if * < ~ 0 . 
Notation 4.5 The expression X — W(a, β) indicates that the random vari-
able X has a Weibull distribution with parameters a and β. 
Figure 4.9 shows the graph of the Weibull distribution for a = 1 and 
different values of β. 
Theorem 4.5 Let X = W(a,ß). 
Then: 
1. £(X) = ( i ) * r ( l + i ) . 
2. yar(X) = ( i ) * [ r ( l + f ) - r 2 ( l + i)] . 
Proof: Left as an exercise. 
■ 
Note 4.8 Some authors, for example, Ross (1998) and Hernandez (2003), 
define the density function of a Weibull distribution considering three param-
eters, a location parameter c, a scale parameter a and a form parameter b, 
and they say that the random variable X has a Weibull distribution with pa-
rameters a, b and c if its density function is given by: 
f{x) = { M ^ e x p H ^ ) " ] if *>c 
1 
0 
if 
x<c. 

172 
SOME CONTINUOUS DISTRIBUTIONS 
Figure 4.9 
Probability density function of a Weibull distribution for a = 1 and 
different values of ß 
However, in the majority of the applications it is a common practice to make 
c = 0, having as a result the density function considered initially by taking 
a= [i] 6 andß = b. 
4.5 
BETA DISTRIBUTION 
The distribution that will be presented here is used frequently as a mathemat-
ical model that represents physical variables whose values are restricted to an 
interval of finite length or as a model for fractions such as purity proportions 
of a chemical product or the fraction of time that takes to repair a machine. 
Definition 4.7 (Beta Distribution) It is said that the random variable 
X has a beta distribution with parameters a > 0 and b > 0 if its density 
function is given by 
/ ( X ) = Έ^ο~)χα~1{1 
~ *)6_1*(o,i)(z) 
where B(a, b) is the beta function. 
That is: 
B(a,b)= 
[ 
x^il-xf^dx 
Jo 

BETA DISTRIBUTION 
173 
Figure 4.10 
Probability density function of a beta distribution for a = 2 and 
different values of b 
Notation 4.6 The expression X — ß(a, b) means that X has a beta distribu-
tion with parameters a and b. 
The beta and gamma functions are related through the following expres-
sion: 
R(n 
M - 
r ( f l ) r W 
so that the density function can be expressed in the form 
If o and b are positive integers, then: 
Figure 4.10 shows the graphs of the beta density function for a = 2 and 
different values of b. 
Figure 4.11 shows the graph of the beta density function with b = 3 and 
different values of a. It is clear that if a = b = 1, then the beta distribution 
coincides with the uniform distribution over the interval (0,1). In addition to 
this, we have that: 

174 
SOME CONTINUOUS DISTRIBUTIONS 
4.5 
4 
3.5 
3 
ξ2.5 
2 
1.5 
1 
0.5 
n 
i 
1 
"I 
i a = 0.8 
- 1 \ \ \ \ \ \ 
^ 
a = 1.5 
.,a = 4 
' 
/ 
^ 
'^ 
\ 
. 
v ' 
** 
^ ■ 
\ 
/ 
"*■ - ^ 
\ 
' 
^ ^ ^ 
^ ~~ ^ - 
"" '~· 
Ν. 
« - r ^ ^ 
i 
i 
i 
I 
I 
I 
~ ~ I 
"-1»-· -
-
■ 
-
-
-
-
0 
0.1 
0.2 
0.3 
0.4 
0.5 
0.6 
0.7 
0.8 
0.9 
1 
x 
Figure 4.11 
Probability density function of beta density function with 6 = 3 and 
different values of a 
1. If a > 1 and b > 1, the function / has a global maximum. 
2. If a > 1 and b < 1, the function / is an increasing function. 
3. If a < 1 and 6 > 1, the function / is a decreasing function. 
4. If a < 1 and b < 1, the graph of / has a U form. 
The distribution function of the random variable with beta distribution is 
given by: 
F(x) = fiP1"'1-""* <*(o,i)(x) + -*Ίι,οο)0*0 · 
The moment generating function of a random variable with beta distribu-
tion does not have a simple form. Due to this, it is convenient to find its 
moments from the definition. 
Theorem 4.6 Let X = ß(a,b). 
Then: 
1. E{X) = ^ 
. 
%■ Var{X) = (a+H.ff(a+6)ä · 

OTHER CONTINUOUS DISTRIBUTIONS 
175 
Proof: 
E{Xk) 
Therefore: 
E(X) 
B(a,b)Jo 
^ 
*> 
B{a + k,b) 
B{a,b) 
Γ(α + k)T(a + b) 
T(a + k + b)T(a)' 
Γ(α + 1)Γ(α + b) 
Γ(α + 1 + 6)Γ(ο) 
αΓ(α)Γ(α + b) 
(a + b)T{a + b)T{a) 
a 
E{X2) 
= 
a + b 
T{a + 2)Γ(α + b) 
Γ(α + 2 + b)T(a) 
α(α + 1) 
(a + b) (a + b + 1)' 
EXAMPLE 4.17 
(Wackerly et al, 2008) A gas distributor has storage tanks that hold a 
fixed quantity of gas and that are refilled every Monday. The proportion 
of the storage sold during the week is very important for the distributor. 
Through observations done during several weeks, it was found that an 
appropriate model to represent the required proportion was a beta dis-
tribution with parameters a = 4 and 6 = 2. Find the probability that 
the distributor sells at least 90% of his stored gas during a given week. 
Solution: Let X := "proportion of the stored gas that is sold during the 
week". Given that X = /?(4,2) we have that: 
P(X > 0.9) = 1 - P(X < 0.9) 
/•0.9 
= 1 - / 
20x 3(l-x)dx 
Jo 
= 0.08146 . 
▲ 
4.6 
OTHER CONTINUOUS DISTRIBUTIONS 
Definition 4.8 (Cauchy Distribution) It is said that a random variable 
X has a Cauchy distribution with parameters Θ and β, Θ e R and ß e R +, if 

176 
SOME CONTINUOUS DISTRIBUTIONS 
Figure 4.12 
Probability density function of a Cauchy distribution for Θ = 0 and 
some values of ß 
its density function is given by: 
πβ 1 + M 
2' 
xeK. 
When Θ — 0 and β = 1, it is obtained that 
/(*) 
π(1+χ 2)' 
which is known as the standardized Cauchy density function. 
Figure 4.12 shows the graphs of / for Θ = 0 and some values of β. 
Figure 4.13 shows the graphs of / for β = 1 and some values of Θ. 
The distribution function of the random variable with Cauchy distribution 
is given by: 
τ,, ^ 
1 
1 
ίΧ~θ\ 
F(x) = _ + _ a r c t a n ^ _ _ j . 
The Cauchy distribution has the characteristic of heavy tails. This means that 
the values that are farthest away from Θ have high probabilities of occurrence. 
That is why this distribution presents atypical behavior in several ways and is 

OTHER CONTINUOUS DISTRIBUTIONS 
177 
£ 
0.3 
0.25 
0.2 
0.15 
0.1 
0.05 
■ 
■ 
• 
• / 
1 
1 
1 
1 
1 
1 
1 
1 
1 
/ 
/ \ θ = - 1 
/ 
f" 
\ 
\ 
V 
\ 
\ \ 
\ 
Q=2f\ 
j 
1 
I 
1 
1 
1 
/ 
1 
I 
1 
1 
1 
I 
1 
1 
1 
/ 
1 
' 
/ 
/ 
^ · ■ „ 
/ 
1 
1 
1 
- · -
\ θ = 3 . 
\ 
\ 
» -
y 
\ 
-
. 
Figure 4.13 
Probability density function of a Cauchy distribution for β = 1 and 
some values of Θ 
an excellent counterexample for various assertions that in the beginning might 
seem reasonable. Remember, for example, that in Chapter 2 it was proven 
that the expected value of the random variable with Cauchy distribution does 
not exist. 
Definition 4.9 (Laplace Distribution) It is said that a random variable 
X has a Laplace distribution or double exponential with parameters a, β if its 
density function is given by 
/./ \ 
1 
( 
\x — 
a\\ 
/(x)=2^exH—ß-)' 
where a e K and ß e R+. 
Figure 4.14 shows the graphs of a Laplace density function with a = 0 and 
different values of ß. 
Definition 4.10 (Exponential Power) It is said that a random variable 
X 
distributes with an exponential power with parameters α,β and 7 with 
a G R and ß, -y 6 R + if its density function is given by: 
m 
2/3Γ (l + I ) exp 
x — a 
ß 

178 
SOME CONTINUOUS DISTRIBUTIONS 
1 
0.9 
0.8 
0.7 
0.6 
0.5 
0.4 
0.3 
0.2 
0.1 
0 
■ 
-
■ 
__ 
^ ^ • - Ό — 
—:—^Γ^- -
1 
;V
0·
5 
ι ι 
1 
1 
1 
1 
1 
I 
1 
1 
ι 
ι 
1 
1 
' Λ ι 
' / \ > 
' / \ v 
' / 
\ > 
/ P=1 x, 
"~ ~. —^Γ^—r-
-
-
■ 
—- _ 
Figure 4.14 
Probability density function of a Laplace density function with a 
0 and different values of β 
Figure 4.15 
Probability density function of an exponential power distribution for 
a = 0, β = 1 and different values of 7 

OTHER CONTINUOUS DISTRIBUTIONS 
179 
Figure 4.16 
Probability density function of a lognormal distribution for μ = 0 and 
different values of σ 
Figure 4.15 shows the graphs of a density function of a random variable 
with exponential power distribution for a — 0, β — 1 and different values of 
7. If 7 = 2, then 
2' 
/(*) 
1 
yßß exp 
Ix — a V 
\n~) 
that is, we obtain the density function of a random variable with normal 
distribution with parameters μ = α and σ = ■£-. If 7 = 1 we have that 
'<^X-^)· 
which is the Laplace density function with parameters a and β. 
Definition 4.11 (Lognormal Distribution) LetX 
be a nonnegative vari-
able and Y := In X. If the random variable Y has a normal distribution with 
parameters μ and σ, then it is said that X has a lognormal distribution with 
parameters μ and σ. 
It is clear that if X has lognormal distribution, its density function is given 
by: 
/(*) 
■*/2πσχ 
,o 
exp 
(
Ins—μ \ 
V2o ) 
if 
x > 0 
otherwise 

180 
SOME CONTINUOUS DISTRIBUTIONS 
Figure 4.17 
Probability density function of a logistic distribution for a = 0 and 
different values of ß 
Figure 4.16 shows the graph of a lognormal density function for μ = 0 and 
different values of σ. 
Definition 4.12 (Logistic Distribution) It is said that a random variable 
X has a logistic distribution with parameters a and β with a s R and β € R + 
if its density function is given by: 
/(*) = ^ 
exp [-(■?)] 
" I1+-[-(■?)]]' 
x G 
The distribution function of the random variable with logistic distribution 
of parameters a and β is given by: 
F(x) 
1 
1 +exp [-(■?)] 
Figure 4.17 shows the graph of the logistic density function for a = 0 and 
different values of β. 
In this chapter we have seen some important distributions of continuous 
random variables which are frequently used in applications. To conclude this 
chapter, we now present the relation between various continuous distributions 
which is illustrated in Figure 4.18. 

EXERCISES 
181 
Exponential^ 
λ 
Uniform(V) 
ft* 
b-a 
V = (b-a)U + a 
Uniforntft/; 
0,1 
W=\(-ln(U» 
o = l 
WeibullW 
α.λ 
Figure 4.18 
Relationship between distributions 
EXERCISES 
4.1 
Let X be a random variable with continuous uniform distribution in 
the interval [-5,5] · 
a) Calculate: mean, variance and standard deviation of X. 
b) Determine the value of x so that P (\X\ < x) = 0.9. 
4.2 
A number is randomly chosen in the interval (0,1). Calculate: 
a) The probability that the first digit to the right of the decimal point is 
6. 
b) The probability that the second digit to the right of the decimal point 
is 1. 
c) The probability that the second digit to the right of the decimal point 
is 8 given that the first digit was 3. 
4.3 
Let X = U (a, b). If E{X) = 2 and Var (X) = | , which are the values 
of the parameters a and 6? 
4.4 
A student arrives at the bus station at 6:00 AM sharp knowing that 
the bus will arrive any moment, uniformly distributed between 6:00 AM and 

182 
SOME CONTINUOUS DISTRIBUTIONS 
6:20 AM. What is the probability that the student must wait more than 5 
minutes? If at 6:10 AM the bus has not arrived yet, what is the probability 
that the student has to wait at least 5 more minutes? 
4.5 
A bus on line A arrives at a bus station every 4 minutes and a bus on 
line B every 6 minutes. The time interval between an arrival of a bus for line 
A and a bus for line B is uniformly distributed between 0 and 4 minutes. Find 
the probability: 
a) That the first bus that arrives will be for line A. 
b) That a bus will arrive within 2 minutes (for line A or B). 
4.6 
Assume that N stars are randomly scattered, independently of each 
other, in a sphere of radius R (measured in parsecs). 
a) What is the probability that the star nearest to the center is at a distance 
at least r? 
b) Find the limit of the probability in (a) if R —> oo and 
N/R3 -> 4πλ/3 where λ ~ 0.0063. 
4.7 
Consider a random experiment of choosing a point in an annular disc 
of inner radius r\ and outer radius Γ2 (ΤΊ < Γ2). Let X be the distance of a 
chosen point from the annular disc to the center of the annular disc. Find the 
pdf of X. 
4.8 
Let X be an exponentially distributed random variable with parameter 
b. Let Y be defined by Y = i for i = 0,1,2, · · · whenever i < X < i + 1. Find 
the distribution of Y. Also obtain the variance of Y if it exists. 
4.9 
Let X be a uniformly distributed random variable on the interval (0,1). 
Define: 
Y = a+(b- 
a)X, 
a<b. 
Find the distribution of Y. 
4.10 
Suppose that X is a random variable with uniform distribution over 
the interval (0,4). Calculate the probability that the roots of the equation 
2x2 + 2xX + X + 1 = 0 are both complex. 
4.11 
Let X be a random variable with uniform distribution over (—2,2). 
Find: 
a ) P ( | X | < ± ) . 
b) A density function of the random variable Y = \X\. 
4.12 
Let X be a random variable with uniform distribution over (0,1). Find 
the density functions for the following random variables: 

EXERCISES 
183 
a) Y := lnX. 
b) Z := X 3 + 2. 
c) W := * . 
4.13 
A player throws a dart at a dartboard. Suppose that the player receives 
10 points for his throw if it hits 2 cm from the center, 5 points if it lands 
between 2 and 6 cm from the center and 3 points if it hits between 6 and 
10 cm from the center. Find the expected number of points obtained by the 
player knowing that the distance from the place where the dart hits and the 
center of the board is a random variable with uniform distribution in (0,10). 
4.14 
Let X = N (0,1). Calculate: 
a) P ( - K X < 1 . 2 ) . 
b) P ( - 0 . 3 4 < X < 0 ) . 
c) P ( - 2 . 3 2 < X 
<2A). 
d) P ( X > 1 . 4 3 ) . 
e) P ( | X - 1 | < 0 . 5 ) . 
4.15 
Let X = λί(3,16). 
In each of the following exercises, obtain the value 
of x that solves the equation: 
a) 
P{X>x)=0.5. 
b) P ( x < X < 5 ) = 0.1. 
c) P ( A " > z ) = 0.01. 
4.16 
In the following exercises, find the value of c that will satisfy the 
equalities. 
a) P(W<c) 
= 0.95 if W = X?0. 
b) P ( L Y - l | < 3 ) = c i f X = . / V ( l , 9 ) . 
c) P(W>c) 
= 0.25 if W = X%. 
d) P(X <c) = 0.990 if X = *| 5. 
e) P {Xl <c)= 
0.005 for k = 3,7,27. 
4.17 
Suppose that the marks on an examination are distributed normally 
with mean 76 and standard deviation 15. Of the best students 15% obtained 
A as grade and of the worst students 10% lost the course and obtained P. 

184 
SOME CONTINUOUS DISTRIBUTIONS 
a) Find the minimum mark to obtain A as a grade. 
b) Find the minimum mark to pass the test. 
4.18 
The lifetime of a printer is a normal random variable with mean 5.2 
years and standard deviation 1.4 years. What percentage of the printers have 
a lifetime less than 7 years? Less than 3 years? Between 3 and 7 years? 
4.19 
Let X be a random variable with normal distribution with mean μ and 
variance σ2. Find the distribution of the random variable Y := 5X — 1. 
4.20 
Suppose that the lifespan of a certain type of lamp is a random variable 
having a normal distribution with mean 180 hours and standard deviation 20 
hours. A random sample of four lamps is taken. 
a) What is the probability that all four lamps have a lifespan greater than 
200 hours? 
b) All four lamps of the random sample are placed inside an urn. If one 
lamp is then randomly selected, what is the probability that the ex-
tracted lamp has a lifespan greater than 200 hours? 
4.21 
Let X be a random variable with binomial distribution with parame-
ters n = 30 and p = 0.3. Is it reasonable to approximate this distribution to 
a normal with parameter μ = 9 and variance σ2 = 6.3? Explain. 
4.22 
A fair die is tossed 1000 consecutive times. Calculate the probability 
that the number 3 is obtained less than 500 times given that the number 1 
was obtained exactly 200 times. 
4.23 
Let X = Λ/"(3,4). Find the number a so that: 
P{X>a)=l-P{X<a). 
4.24 
Determine the tenths of the standard normal distribution, that is, the 
values xo.i, xo.2> ■ ■ ■ , £0.9, so that Φ (xo.i) = O.i for i = 1, · · · , 9. 
4.25 
Consider a nonlinear amplifier whose input X and output Y are related 
by its transfer characteristic: 
| I 5 
if X > 0 
~ \ 
- | X | i 
if X < 0 . 
Find the pdf of Y if X has Λ/"(0,1) distribution. 
4.26 
Let X be a continuous random variable with distribution function F 
and pdf /(#). The truncated distribution of X to the left at X = a and to 

EXERCISES 
185 
the right at X = ß is defined as: 
g(x) = [ F(0)-k°) 
i{ 
<*<X<ß 
1 0 
otherwise . 
Find the pdf of a truncated normal Αί(μ, σ2) random variable truncated to 
the left at X — a and to the right at X = β. 
4.27 
A marketing study determined that the daily demand for a recognized 
newspaper is a random variable with normal distribution with mean μ = 
50,000 and standard deviation σ = 12,500. Each newspaper sold leaves 500 
Colombian pesos as revenue, while each paper not sold gives 300 Colombian 
pesos as loss. How many newspapers are required in order to produce a 
maximum expected revenue? 
4.28 
Let X be a random variable with: 
a) Uniform distribution over [—1,1]. 
b) Exponential distribution with parameter λ. 
c) Normal distribution with parameters μ and σ. 
Calculate the distribution function Fy and the density function /y of the 
random variable Y = aX + b, where a and b are real numbers and 
αφθ. 
4.29 
In the claim office of a public service enterprise, it is known that the 
time (in minutes) that the employee takes to take a claim from a user is a 
random variable with exponential distribution with mean 15 minutes. If you 
arrive at 12 sharp to the claim office and in that moment there is no queue 
but the employee is taking a claim from a client, what is the probability that 
you must wait for less than 5 minutes to talk to the employee? 
4.30 
Suppose that the number of kilometers that an automobile travels 
before its battery runs out is distributed exponentially with a mean value of 
10,000 km. If a person wants to travel 5,000km, what is the probability that 
the person finishes his trip without having to change the battery? 
4.31 
The time that has elapsed between the calls to an office has an expo-
nential distribution with mean time between calls of 15 minutes. 
a) What is the probability that no calls have been received in a 30-minute 
period of time? 
b) What is the probability of receiving at least one call in the interval of 
10 minutes? 
c) What is the probability of receiving the first call between 5 and 10 
minutes after opening the office? 

186 
SOME CONTINUOUS DISTRIBUTIONS 
4.32 
The length of time T of an electronic component is a random variable 
with exponential distribution with parameter λ. 
a) Determine the probability that the electronic component works for at 
least until t = 3A_1 . 
b) What is the probability that the electronic component works for at least 
until t — k\_1 
if it work's until time t = (k — 1)λ_1 ? 
4.33 
Let X be a random variable having an exponential distribution with 
parameter λ = | . Compute: 
a) P (X > 3) . 
b) P (X > 6 | X > 3) . 
c) P (X > t + 3 | X > t) . 
4.34 
Let X be a random variable with exponential distribution with pa-
rameter λ. Find the density functions for the following random variables: 
a) Y :=lnX. 
b) Z := X 2 + 1. 
c)W:=±. 
4.35 
a) 
In 1825 Gompertz proposed the risk function λ (t) given by 
λ (t) = α/3*;Τ(οι0θ) (ί) with a > 0 and β > 1 
to model the lifetime of human beings. Determine the distribution func-
tion F corresponding to the failure function λ (t). 
b) In the year 1860 Makeham modified the risk function proposed by Gom-
pertz and suggested the following: 
λ (f) = (7 + αβι) Λ^ο,οο) (t) with a,ßeM.+ 
and ß > 1. 
Determine the distribution function F corresponding to the failure func-
tion λ (t) (this distribution is also known as the Makeham distribution). 
4.36 
Calculate the failure function of the exponential distribution with pa-
rameter μ. 
4.37 
Determine the distribution of F whose failure distribution is given by 
λ(ί) = a + ßt,t > 0 , 

EXERCISES 
187 
where a and ß are constants. 
4.38 
Suppose that T denotes the lifetime of a certain component and that 
the risk function associated with T is given by: 
λ(ί) = (ί + 1 ) ' 
Find the distribution of T. 
4.39 
Suppose that T denotes the lifetime of a certain component and that 
the risk function associated with T is given by 
λ (t) = atß 
where a > 0 and ß > 0 are constants. Find the distribution of T. 
4.40 
Let X be a Weibull distribution. Prove that Y = bX for some b > 0 
has the exponential distribution. 
4.41 
The lifetime of a certain electronic component has a Weibull distribu-
tion with ß = 0.5 and a mean life of 600 hours. Calculate the probability that 
the component lasts at least 500 hours. 
4.42 
The time elapsed (in months after maintenance) before a fail in a 
vigilance equipment with closed circuit in a beauty shop has a Weibull distri-
bution with a — ψξ and β = 2.2. If the shop wants to have a probability of 
damage before the next programmed maintenance of 0.04, then what is the 
time elapsed of the equipment to receive maintenance? 
4.43 
A certain device has the Weibull failure rate 
r(t) = Xpt"-1, 
t>0. 
a) Find the reliability R(t). 
b) Find the mean time to failure. 
c) Find the density function 
fr(t). 
4.44 
A continuous random variable X is said to have Pareto distribution if 
it has density function 
θ 
/ χ η \ β + 1 
f(x;a) 
= — 
— 
, 
x > x 0 , 
& > 0. 
The Pareto distribution is commonly used in economics. 
a) Find the mean and variance of the distribution. 
b) Determine the density function of Z = InX. 

188 
SOME CONTINUOUS DISTRIBUTIONS 
4.45 
A certain electrical component of a mobile phone has the Pareto failure 
rate 
r(t) = { * 
if l ~ to 
(4.3) 
w 
\ 0 
otherwise. 
a) Find the reliability R(t) for t > 0. 
b) Sketch R(t) for i0 = 1 and a = 2. 
c) Find the mean time to failure if a > 0. 
4.46 
Let X be a random variable with standard normal distribution. Find 
E{\X\). 
4.47 
Consider Note 4.1. Let X be a continuous random variable with 
strictly increasing distribution function F. Let Y = Fx (X). Prove that Y 
has uniform distribution over (0,1). 
4.48 
Let X be a random variable with uniform distribution over (0,1). 
Find the function g : R —► R, so that Y = g (X) has a standard normal 
distribution. 
4.49 
Prove that if X 
is a random variable with Erlang distribution with 
parameters r and λ, then: 
Fx(x) = l-Y^ (Xx)3 exp (—Ax) 
i=o 
^ 
4.50 
Prove that Γ (±) = yß. 
4.51 
Prove that: 
B{a'b) = T(^TW 
4.52 
Let X be a random variable with standard Cauchy distribution. Prove 
that E(X) 
does not exist. 
4.53 
Let X be a random variable with standard Cauchy distribution. What 
type of distribution has the random variable Y := -^? 
4.54 
Let X be a normal random variable with parameters 0 and σ2. Find 
a density function for: 
a) Y = \X\ . 
b) 
Y=y/\X\-
4.55 
Let X be a continuous random variable with pdf 
ϊχ(Χ) 
= 
~ΓΓι 
2 ^ ' 
- 0 0 < £ < C X D . 
7Τ(1 + 
X1) 

EXERCISES 
189 
Find the distribution of: 
r x, 
\x\>2 
1 0, 
I X |< 2 . 
4.56 
Let X be a random variable with standard normal distribution. Prove 
that 
(x _ 1 - a r 3 ) e x p ( - - x 2 ) < V2n[P{X 
> X)\ < x _ 1exp (--x2 
j 
for x > 0. 

CHAPTER 5 
RANDOM VECTORS 
In the previous chapters, we have been concentrating on a random variable 
defined in an experiment, e.g., the number of heads obtained when three coins 
are tossed. In other words, we have been discussing the random variables but 
one at a time. In this chapter, we learn how to treat two random variables, of 
both the discrete as well as the continuous types, simultaneously in order to 
understand the interdependence between them. For instance, in a telephone 
exchange, the time of a call arrival X and a call duration Y or the shock 
arrivals X and the consequent damage Y are of interest. One of the questions 
which also comes to mind is, can we relate two random variables defined on 
the same sample space, or in other words, can two random variables of the 
same spaces be correlated? Some of these questions will be discussed and 
answered in this chapter. 
5.1 
JOINT DISTRIBUTION OF RANDOM VARIABLES 
In many cases it is necessary to consider the joint behavior of two or more 
random variables. Suppose, for example, that a fair coin is flipped three 
Introduction to Probability and Stochastic Processes with Applications, 
First Edition. 
191 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

192 
RANDOM VECTORS 
consecutive times and we wish to analyze the joint behavior of the random 
variables X and Y defined as follows: 
X := "Number of heads obtained in the first two flips". 
Y := "Number of heads obtained in the last two flips". 
Clearly: 
p(x = o,y = o) = p((T,r,T)) = g 
P(X = 0,Y=1) 
= P((T,T,H)) 
= ± 
P(X = 1,Y = 0) = P((H,T,T)) 
= ^ 
P(X = l,Y = l) = P({(H,T,H), 
(T,H,Γ)}) 
= \ 
P(X = 1,Y = 2) = P((T,H,H)) 
= ± 
P(X = 2,Y=l) 
= P((H,H,T)) 
= ± 
P(X = 2,Y = 2) = P((H,H,H)) 
= ±. 
This information can be summarized in the following table: 
X\Y 
0 
1 
2 
0 
1 
8 
1 
8 
0 
1 
1 
8 
1 
4 
1 
8 
2 
0 
1 
8 
1 
8 
Definition 5.1 (n-Dimensional Random Vector) LetXi,X2,· 
· · ,Xn be 
n real random variables defined over the same probability space (Ω, 9, P). The 
function X : Ω —> Rn defined by 
Χ(ω):=(Χ1(ω),---,Χη(ω)) 
is called an n-dimensional random vector. 
Definition 5.2 (Distribution of a Random Vector) Let X be an n-dimensional 
random vector. The probability measure defined by 
Px(B) := P(X € B) ; B e Bn 
is called the distribution of the random vector X. 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
193 
Definition 5.3 (Joint Probability Mass Function) Let 
X = (Xi,X2,·" 
<Xn) be an n-dimensional random vector. If the random 
variables Xi, with i — 1, · · · , n, are all discrete, it is said that the random 
vector X is discrete. In this case, the probability mass function of X, also 
called the joint distribution function of the random variables Χι, X2, · ■ ■ , Xn, 
is defined by: 
- ( : 
. P(X = x) 
if 
x belongs to the image of X 
Px(x) := < 0 
otherwise . 
Note 5.1 Let X\ and X2 be discrete random variables. Then: 
p(Xr = x) = p( (x1 = x) n U(*2 = y)\ 
= p{\J{Xi=x,X2 
= y)\ 
= YiP{Xl=x,X2 
= y). 
y 
In general, we have: 
Theorem 5.1 Let X = (Χι,Χ^,··· 
,Χη) 
be a discrete n-dimensional ran-
dom vector. Then, for all j = 1, · · · , n we have: 
P(Xj =x) = ^ . · · Σ 
Σ 
■■■ΣΡ(Χι 
= χ ΐ ' · · · >χ3-ι =Xj-i,Xj 
=x, 
Xj+1 = Xj+1, ■ · · , Xn = Xn) ■ 
The function 
I P(Xj = x) 
if 
x belongs to the image of Xj 
ρχ. (x) := < 
10 
otherwise 
is called the marginal distribution of the random variable Xj. 
EXAMPLE 5.1 
Let X and Y be discrete random variables with joint distribution given 
by: 
X\Y 
0 
1 2 
3 

194 
RANDOM VECTORS 
The marginal distributions of X and Y are given, respectively, by: 
X 
P(X = x) 
- 1 
10 
16 
1 
6 
16 
y 
P{Y = y) 
0 
2 
16 
1 
6 
16 
2 
3 
16 
3 
5 
16 
EXAMPLE 5.2 
Suppose that a fair coin is flipped three consecutive times and let X and 
Y be the random variables defined as follows: 
X := "Number of heads obtained". 
Y := "Flip number where a head was first obtained" (if there are none, 
we define Y = 0). 
1. Find the joint distribution of X and Y. 
2. Calculate the marginal distributions of X and Y. 
3. Calculate P(X <2,Y= 
1), P{X < 2,Y < 1) and P(X < 2 or Y < 1). 
Solution: 
1. The joint distribution of X and Y is given by: 
X\Y 
0 
1 
2 
3 
0 
1 
8 
0 
0 
0 
1 
0 
1 
8 
2 
8 
1 
8 
2 
0 
1 
8 
1 
8 
0 
3 
0 
1 
8 
0 
0 
2. The marginal distributions of X and Y are presented in the following 
tables: 
! ° 
1 1 
\ 
8 
1 
1 3 
1 8 
2 
1 3 
1 8 
3 1 
1 1 1 
1 8 1 
P(X = x) 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
195 
y 
P(Y = v) 
0 
1 
8 
1 
1 
2 
2 
1 
4 
3 
1 
8 
3. It follows from the previous items that: 
P (X < 2, Y = 1) = P (X = 0, Y = 1) + P {X = 1, Y = 1) 
+ P(X = 2,Y = l) 
_ 3 
_ 8 
P(X < 2,Y < 1) = P(X < 2,Y = 1) + P(X < 2,Y = 0) 
3 
8 + P (X = 0, Y = 0) + P (X = 1, Y = 0) 
+ p(x = 2,y = o) 
_ 1 
~ 2 
P (X < 2 or Υ < 1) = P (X < 2) + P (Y < 1) - P {X < 2, Y < 1) 
= P (X = 0) + P (X = 1) + P {X = 2) 
+ P(Y = 0) + P(Y = 
l)-± 
7 
5 
1 , 
= 8 + 8 - 2 = 1 · 
A 
EXAMPLE 5.3 
A box contains three nails, four drawing-pins and two screws. Three 
objects are randomly extracted without replacement. Let X and Y be 
the number of drawing-pins and nails, respectively, in the sample. Find 
the joint distribution of X and Y. 
Solution: Since 
P(X = x,Y = y)=KxnvJ^-x-y) 
for 
x,y = 0,1,2,3, 
the joint distribution of the variables X and Y is given by: 

196 
RANDOM VECTORS 
trib 
X\Y 
0 
1 
2 
3 
0 
0 
4 
84 
12 
84 
4 
84 
1 
3 
84 
24 
84 
18 
84 
0 
2 
6 
84 
12 
84 
0 
0 
utions of X and Y are 
X 
P{X = x) 
0 
10 
84 
1 
40 
84 
2 
30 
84 
3 
1 
84 
0 
0 
0 
resp< 
3 
4 
84 
y 
P(Y = y) 
0 
20 
84 
1 
45 
84 
2 
18 
84 
3 
1 
84 
EXAMPLE 5.4 
A fair dice is rolled twice in a row. Let: 
X\ := "Greatest value obtained". 
Xi := "Sum of the results obtained". 
The density function of the random vector X = (X\,X·^) is given by: 
* i \ X 2 
1 
2 
2 
1 
36 
0 
3 
0 
2 
36 
4 
0 
1 
36 
5 
0 
0 
6 
0 
0 
7 
0 
0 
8 
0 
0 
9 
0 
0 
10 
0 
0 
11 
0 
0 
12 
0 
0 
o 
o 
£ 
£ 
i 
o 
o 
o 
o 
o 
o 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
197 
The marginal distributions of Χχ and X2 are, respectively: 
X l 
P(Xi=xi) 
1 
1 
36 
2 
3 
36 
3 
5 
36 
4 
7 
36 
5 
9 
36 
6 
11 
36 
X2 
P(X2 = Xl) 
2 
1 
36 
3 
2 
36 
4 
3 
36 
5 
4 
36 
6 
5 
36 
7 
6 
36 
8 
5 
36 
9 
4 
36 
10 
3 
36 
11 
2 
36 
12 
1 
36 
Furthermore, we have that 
P (X! <\,X2< 
y ) =P(Xi 
= l.Xa = 2) + P(X1 = 1,X2 
3) 
1 
36 
P(Xx < ir,X2 <2) = P{Xi 
= 1,X2 = 2) + P(X1 = 2,X2 - 2) 
+ P ( X i = 3 , X 2 = 2) 
1 
~ 36 
and in general: 

198 
RANDOM VECTORS 
*2\Xl 
( - 0 0 , 2 ) 
[2,3) 
[3,4) 
[4,5) 
[5,6) 
[6,7) 
(7,8) 
[8,9) 
[9,10) 
[10,11) 
[11, 12) 
[12,oo) 
(-oo,l) 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
[1,2) 
0 
1 
36 
1 
36 
1 
36 
1 
36 
1 
36 
1 
36 
1 
36 
1 
36 
1 
36 
1 
36 
1 
36 
[2,3) 
0 
1 
36 
3 
36 
4 
36 
4 
36 
4 
36 
4 
36 
4 
36 
4 
36 
4 
36 
4 
36 
4 
36 
[3,4) 
0 
1 
36 
3 
36 
6 
36 
8 
36 
9 
36 
9 
36 
9 
36 
9 
36 
9 
36 
9 
36 
9 
36 
[4,5) 
0 
1 
36 
3 
36 
6 
36 
10 
36 
13 
36 
15 
36 
16 
36 
16 
36 
16 
36 
16 
36 
16 
36 
[5,6) 
0 
1 
36 
3 
36 
6 
36 
10 
36 
15 
36 
19 
36 
22 
36 
24 
36 
25 
36 
25 
36 
25 
36 
[6,00) 
0 
1 
36 
3 
36 
6 
36 
10 
36 
15 
36 
21 
36 
26 
36 
30 
36 
33 
36 
35 
36 
1 
Each entry in the table represents the probability that 
P{Xi 
<Xi,X 2<X2) 
for the values xi and X2 indicated in the first row and column, respec-
tively. 
▲ 
The previous example leads us to the following definition: 
Definition 5.4 (Joint Cumulative Distribution Function) Let 
X = (ΧΙ,ΧΪ,- 
■ ■ ,Xn) 
be an n-dimensional 
random vector. 
The function 
defined by 
F(xi,x 2,·-· ,x„) := P{Xi 
< xi,^2 < %2, · ■ · 
,Xn<xn), 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
199 
for all (xi,x2, · · · ,xn) € K" is called the joint cumulative distribution func-
tion of the random variables X\,X2,· 
■ ■ , Χη, or simply the distribution func-
tion of the n-dimensional random vector X. 
Note 5.2 Just like the one-dimensional case, we have that the distribution of 
the random vector X is completely determined by its distribution 
function. 
Note 5.3 Let X\ and X2 be random variables with joint cumulative distribu-
tion function F. Then: 
FXl(x) 
= 
P(X1<x) 
= 
p((X1<x)n\J(X2<y)\ 
= 
p(\J(Xi<x,X2<y)\ 
= lim P (Xi <x,X2< 
y) 
= \im 
F{x,y). 
Likewise, we have that Fx2(y) = lim F(x,y). 
This can be generalized in the 
X—»OO 
following theorem: 
Theorem 5.2 Let X = (Χι, X2, · · ■ > Xn) be an n-dimensional random vector 
with joint cumulative distribution function F. 
For each j = 1,··· ,n, the 
cumulative distribution function of the random variable Xj is given by: 
FxAx) = lim ··· 
lim 
lim 
·■· lim F(x\,··· 
,xn) . 
X l — f O O 
Xj — χ—►OOXj + l—»OO 
X n—VOO 
The distribution function Fxd is called the marginal cumulative 
distribution 
function of the random variable Xj. 
The previous theorem shows that if the cumulative distribution function of 
the random variables Xi,··· 
,Xn, is known, then the marginal distributions 
are also known. The converse however does not always hold. 
Next we present some of the properties of the joint distribution function. 
Theorem 5.3 Let X = (X, Y) be a two-dimensional random vector. 
The 
joint cumulative distribution function F of the random variables X, Y has the 
following properties: 
1. 
Ab
aF := F(b1,b2) + F(a1,a2) 
- F(a 1 ;6 2) - F(bua2) 
> 0 
where a — (01,02), b = (61,62) £ K2 with ai < b\ and a2 < b%. 

200 
RANDOM VECTORS 
lim F(x,y) = 
F(x0,y) 
x\,xo 
lim F(x,y) = 
F(x,y0). 
y\yo 
(5 
(5 
4-
lim F(x, y) = 0 and 
lim F(x, y) = 0. 
:—► —oo 
y—►—oo 
lim 
F(x,y) = 1. 
(x,y)-y(oo,oo) 
Proof: 
1. Let a = (01,02), & = (ί>ι,ί>2) with ai < &i, a2 < b2 and: 
C 
D 
= 
{{x,y)eR2:x<b1,y<b2} 
= {(x,y) e R 2 : x <ai,y 
< a2} 
= {(x,y) e i 2 
:x<a1,y<b2} 
= {(x,y) e l 2 
:x<bi,y<a2}. 
If J := (A - C) - {D - B), then, clearly: 
0 < Ρχ(/) = (PK(A) 
- ftc(C)) - (Ρχ(£>) - Px(ß)) 
= ΡΧ(Λ) + Ρχ(Β) - Px(C) - Ρχ(£>) 
= F(6i,6a) + F(ai,a2) - F{ai,b2) 
~ P(&i,a2) 
= Δ^Ρ. 
2. We prove (5.1) and leave (5.2) as an exercise for the reader: 
lim F(x, y) = lim P {X < x, Y < y) 
x\tXo 
X*\XQ 
= P( 
lim (X <x,Y 
<y)) 
\x\xo 
) 
= 
P(X<x0,Y<y) 
= 
F(x0,y). 
3. Since 
lim [X < x, Y < y] = lim ([X < x] Π [Y < y}) 
x\t—oo 
x\^—oo 
= 0 n [Y < y] = 0, 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
2 0 1 
we have: 
lim P[X <x,Y <y]=p( 
lim 
[X<x,Y<yU 
: \ — oo 
\^c\(—oo 
J 
= P(0) = 0. 
Analogously, we can verify that: 
lim P [X < x, Y < y] = 0. 
y\-oo 
4. It is straightforward that: 
lim 
F(x,y) = lim ( lim P{X < χ,Υ < y)) 
(x,y)-v(oo,oo) 
x->oo yy-*oo 
J 
= lim P{X <x) = l. 
The following theorem is the general case for n-dimensional random vectors 
of the above theorem which can be proved in a similar fashion. 
Theorem 5.4 Let X = (Χι,-Χ^ι · · · ,Χη) be an n-dimensional random vec-
tor. The joint cumulative distribution function F of the random variables 
Xi, Xi, · · · , Xn has the following properties: 
1. Ab
aF > 0 for all a = (ai, · · · , an), b = (&i, ■ · · , &„) € Rnwith a < b, 
where: 
Ab
aF:= 
Σ 
(-1) V=i 7 F (€ια! + (1-€!)&!, •••,e„a n 
( ί 1 , " , £ η ) € { 0 , 1 } " 
+(1 - 
en)bn). 
2. F is right continuous on each component. 
3. For all a\,··· 
, aj_i, ai+i, · · · an € 1R with i = 1, · · · , n, we have: 
( 
lim F 
ai,··· 
,a,i-i, 
x 
,a i +i,· · · ,a n | = 0. 
\ 
ith position 
lim 
^X^i,· · · ,xn) = 1-
(xi,··· ,xn)->(oo,··· ,cx>) 

202 
RANDOM VECTORS 
EXAMPLE 5.5 
Check whether the following functions are joint cumulative distribution 
functions: 
1. 
3. 
4. 
n/ 
N 
fe-<s+») 
if 0 < x < o o , 0 < y < o o 
F(x, y) = < 
10 
otherwise. 
F(xV) = l· ^ + ^
1 
{X'y) 
\ 0 
ifx + 2 j / < l . 
I 1 if x + y > 0. 
C 
„, 
, 
. . - e~x - e -» + β-(χ+») 
if 
x > 0 , i / > 0 
F(x, y) = < 
0 
otherwise. 
Solution: 
1. 
lim 
F(x,y) 
= 
lim 
e-(x+s/> 
x—foo,2/—^oo 
x—+oo,i/—+oo 
X—VOO.J/—>00 
lim e _ x. lim e_i/ 
x—t-oo 
y—>oo 
= 
0 x 0 = 0 ^ 1 . 
F(x, y) is not a joint cumulative distribution function. 
2. For instance, take x\ = | , x2 = 1, i/i = \, V2 = 1· 
P Q < X < I , J < W < I ) 
= 
F ( I , I ) - F ( I , J ) 
= 
1 - 1 - 1 + 0 = - 1 < 0 . 
F(x, y) is not a joint cumulative distribution function. 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
2 0 3 
3. For instance, take x\ = — | , x2 = 0, yi = 0, 2/2 = 5 
p(-\<X,o,o<y<_\) 
- 
r ( , i ) - , ( - i . i ) 
-F{0,0) 
+ 
F ( - ± , 0 ) 
= 
1 - 1 - 1 + 0 = - K 0 . 
F(x, y) is not a joint cumulative distribution function. 
4. Since all the four properties of Theorem 5.3 are satisfied, F(x, y) is a 
joint cumulative distribution function. 
▲ 
Definition 5.5 (Jointly Continuous Random Variables) Let 
-ΧΊ) -X2) · · ■ > Xn be n real-valued random variables defined over the same prob-
ability space. It is said that the random variables are jointly continuous, if 
there is an integrable function f : Rn —► [0, +00) such that for every Borel 
setC o/R": 
P((X. ,X2,··· 
,Xn) € C) = / ·'· / f{xi,X2,· 
·· ,Xn)dXldX2 
■■■ dxn 
The function f is called the joint probability density function of the random 
variables X\, Χ2, · · · , Xn ■ 
Note 5.4 From the definition above, we have, in particular: 
1. 
I '" I f(xi:x2r 
· · ,Xn)dxi dx-χ ■ ■ ■ dxn = 1. 
Rn 
2. 
P(Xl <Xl,X2 
<Z2,··· .-X"n < Xn) 
= /
·
"
/ 
//(*ι.*3,···,«η)ΛιΑ2 · -dtn 
. 
(5.3) 
—oo 
—oo —oo 
The previous remark shows that if the joint probability density function / of 
the random variables Χχ, Χ2,·" ->Xn is known, then the joint distribution 
function F is also known. This raises the question: Does the converse hold as 
well? That is, is it possible, starting with the joint distribution function F, 
to find the joint probability density function / ? The answer is given in the 
next theorem: 
Theorem 5.5 Let X and Y be continuous random variables having a joint 
distribution function F. Then, the joint probability density function f is 
/ ( J 
)=PF(,x,y) 
=#F{x,y) 
dxdy 
dydx 

204 
RANDOM VECTORS 
for all the points (x, y) where f(x, y) is continuous. 
Proof: By applying the fundamental theorem of calculus to (5.3), we obtain 
dF(x,y) 
_ 
fy 
dx 
and therefore: 
rv 
/ 
f(x,v)dv 
J—oo 
d 
fdF(x,y)\ 
äy{-^x-)=f^y)-
Si n c e 
dxdy 
an(^ 
dvdx 
e xi s* anQl a r e both continuous, then 
d2F(x,y) 
= 
d2F(x,y) 
dxdy 
dydx 
' 
which completes the proof of the theorem. 
■ 
Furthermore, if X\, ■ · ■ , Xn are n continuous random variables with joint 
distribution function F, then the function g(-, ■■■ ,·) defined over Rn by 
{
F(xi,x2,--,xn) 
jf t n e paj^ial derivative exits 
dx1dx2-dxn 
\(XuX2,...,Xn) 
= (Ul,...,Un) 
derivative exists 
0 
otherwise 
is a joint probability density function of the random variables Xi,·· ■ , Xn-
Suppose now that X and Y are continuous random variables having joint 
probability density function / , and let g be the function defined by: 
/
oo 
f(x,y)dy. 
-OO 
Clearly: 
/
X 
pX 
rOO 
g(u)du= 
/ 
/ 
f(u,y)dydu 
-oo 
J — oo J — oo 
/
X 
ft 
I 
f{u,y)dydu 
0 0 . / - 0 0 
= limF(x,t) = 
Fx(x). 
t—HX 
Moreover, since 
/
OO 
ΛΟΟ 
i»00 
g(x)dx= 
/ 
f{x,y)dydx 
= 1 , 
-oo 
J — oo J—oo 
g is the density function of the random variable X called the marginal density 
function of X and is commonly notated as 
fx(x). 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
205 
In similar fashion, 
/
oo 
f(x,y)dx 
-oo 
is the density function of the random variable Y. 
In general, we have the following result: 
Theorem 5.6 If X\,X2, 
· · ■ ,Xn are n real-valued random variables, having 
joint pdf f, then 
/
OO 
ί Ό Ο 
· · - / 
/( χι>· ·■ , ^ - ι , ζ , χ ^ + ι , · · · ,xn)dxi 
■■■dxj-idxj+i 
•■■dxn 
-oo 
J — oo 
is the density function of the random variable Xj for j = 1,2, · · · , n. 
■ EXAMPLE 5.6 
Let X and Y be random variables with joint pdf given by: 
0 < x < l , 
0 < y < l 
f6xy2 
if 
C ' y ) = \ 0 
oti 
" 
otherwise 
1. Calculate P ( | < X < f, 0 < Y < | ) . 
2. Compute P{\ < X < f). 
Solution: 
1. 
P^<X<lo<Y<l)=m\xyUxdy 
= 1.1574 x 10"2 . 
(\<x<l)=J*l1tey2dydx 
= 0.3125 . 
A 

206 
RANDOM VECTORS 
EXAMPLE 5.7 
Let X and Y be random variables with joint pdf given by: 
f2*£ if 0 
f(x,y) = {n
v 
[0 
other 
< x < 1; y > 2 
otherwise . 
1. Calculate P (X < \ \ Y > 6). 
2. Find the marginal density functions of X and F. 
Solution: 
1. 
H y >6 
p ( x < | , y > 6 ) 
P{Y > 6) 
Jo* JT ΊΓ^* 
ΙΓΙίψαχάν' 
1.3889 x 10 
0.1111 
- 2 
= 0.125. 
2. 
/
OO 
/(x, y) eiy 
-OO 
' 
/ Ό Ο 
/ 
^ d y 
if 
0 < x < l 
0 
otherwist 
i3x2 
if 0 < x < 1 
Ίθ 
otherwise 
My) = / 
f{x,y)dx 
J—oo 
= ' f ^-dx 
if y>2 
Jo 
0 
otherwise 
J £ 
if 
y>2 
1 0 
otherwise . 
▲ 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
207 
EXAMPLE 5.8 
Let X and Y be random variables with joint probability density function 
given by: 
{i: 
f(x,y) = r 
+ y) if 
0<x<1'>
0<v
<1 
" 
otherwise . 
Find: 
1. The joint cumulative distribution function of X and Y. 
2. The marginal density functions of X and Y. 
Solution: 
1. 
F{x,y) = 
/ 
f(u,t)dtdu 
J — oo J —oo 
2 
x 2+x 
2 
y+y2 
2 
1 
.0 
- if 
0 < x < l ; 0 < y < l 
if 
0 < X < 1 ; J / > 1 
if 
x > l ; 0 < j / < l 
if x > 1; y > 1 
otherwise . 
2. 
ί χ + i 
if 0 
10 
other 
" 
otherwise 
fy(y) = ly + " if ° < y < 1 
0 
otherwise. 
EXAMPLE 5.9 
Let X and Y be random variables with joint probability density function 
given by: 
_ j
k if 0 < x < 1; 0 < y < 1 and 3j/ < x 
I 0 otherwise . 

208 
RANDOM VECTORS 
Find: 
1. The value of the constant k. 
2. The joint cumulative distribution function of X and Y. 
3. The marginal density functions of X and Y. 
4. P(2Y < X < 5Y). 
Solution: 
1. 
/
oo 
roo 
/.l 
/·§ 
/ 
f(x, y)dxdy = I I kdydx -
-oo J — oo 
JO 
JO 
so that k = 6. 
2. 
/
x 
»y 
/ 
f{u,t)dtdu 
-oo J — oo 
k 
6 
= < 
0 
6x1/ - 8y2 
X 2 
6y - 9j/2 
X 2 
1 
if x < 0 or y < 0 
if 0 < x < 1, 0 < y < \, 3y < x 
i f 0 < x < l , 
%<y<\ 
i f x > l , 
0<y<l 
if 0 < x < 1, 
y > | 
if x > 1, y > I ■ 
3. 
J j 3 My if 0 < x < l 
otherwise 
0 
2x 
if 0 < x < 1 
0 
otherwise 
I / 6dx if 0 < y < | 
otherwise 
=1 
0 
6(1 - 3 » ) 
if 0 < y < i 
0 
otherwise 
P(2Y <X<5Y)= 
f I f* 6 dy ) dx = 0.4. 

JOINT DISTRIBUTION OF RANDOM VARIABLES 
209 
EXAMPLE 5.10 
The system analyst at an email server in a university is interested in 
the joint behavior of the random variable X, defined as the total time 
between an email's arrival at the server and departure from the service 
window, and Y, the time an email waits in the buffer before reaching 
the service window. Because X includes the time an email waits in the 
buffer, we must have X > Y. 
The relative frequency distribution of 
observed values of X and Y can be modeled by the joint pdf 
/o *.»)={; 
■X 
if 0 <y < x < oo 
otherwise 
with time measured in seconds. 
1. Find Ρ(Χ < 2, y >1). 
2. Find P(X > 2Y). 
3. F i n d P ( X - y >1). 
Solution: 
1. 
P(X < 2, Y > 1) = if 
f(x, y)dxdy = 0. 
J J {(x,y):x<2,y>\} 
P(X>2Y) 
= f f 
f(x,y)dxdy 
J 
J{(x,y):x>2y} 
roo 
i-x/1 
e~xdydx 
>o Jo 
1 
/■OO 
pz 
JO 
JO 
3. 
P(X-Y>1) 
= Π 
f(x, 
J 
J{(x,y):x-y>l} 
y)dxdy 
fOO 
yOO 
r,— X , 
/•oo 
re 
= 
I 
I 
e~xdxdy 
Jo 
Jy+l 
= 
e- 1. 
A 

210 
RANDOM VECTORS 
5.2 
INDEPENDENT RANDOM VARIABLES 
Definition 5.6 (Independent Random Variables) Let X and Y be two 
real-valued random variables defined over the same probability space. If for 
any pair of Borel sets A and B ofRwe 
have 
P(X GA,YeB) 
= P(X € A)P(Y e B), 
then X and Y are said to be independent. 
We say that X and Y are independent and identically distributed (i.i.d.) 
random variablesif X and Y are independent random variables and have the 
same distributions. 
Note 5.5 (Independent Random Vectors) The previous definition can 
be generalized to random vectors as follows: Two n-dimensional random vec-
tors X and Y defined over the same probability space (Ω, 3, P) are said to be 
independent, if for any A and B Borel subsets ofW1 they satisfy: 
P(XeA, 
Y£B) 
= P(XeA)P(Y 
eB) 
. 
Assume that X and Y are independent random variables. Then it follows 
from the definition above that: 
F(x,y) = P(X <x,Y<y) 
= P(X < x)P{Y < y) for all x,y G R. 
That is: 
F(x,y) = Fx{x)FY{y) 
for all x, y G R. 
(5.4) 
Conversely, if the condition (5.4) is met, then the random variables are inde-
pendent. 
Suppose now that X and Y are independent discrete random variables. 
Then 
P(X = x,Y = y) = P(X = x)P(Y = y) 
(5.5) 
for all x in the image of X and all y in the image of Y. Conversely, if the 
condition (5.5) is met, then, the random variables are independent. 
If X and Y are independent random variables with joint density function 
f{x,y), 
then: 
P(x < X < x+dx, 
y <Y < y+dy) = P(x < X < x+dx)P(y 
< Y < y+dy). 
That is: 
f{x,y) 
= fx{x)fv(y) 
forallx,j/GR. 
(5.6) 
Conversely, if the condition (5.6) is satisfied, then the random variables are 
independent. In conclusion, we have that the random variables X and Y are 
independent if and only if its joint density function f(x, y) can be factorized 
as the product of their marginal density functions fx{x) 
and 
fy(y). 

INDEPENDENT RANDOM VARIABLES 
2 1 1 
EXAMPLE 5.11 
There are nine colored balls inside an urn, three of which are red while 
the remaining six are blue. A random sample of size 2 (with replacement) 
is extracted. Let X and Y be the random variables defined by: 
X := 
if the first extracted ball is red 
if the first extracted ball is blue 
if the second extracted ball is red 
if the second extracted ball is blue . 
Are X and Y independent? Explain. 
Solution: The joint distribution function of X and Y is given by: 
X\Y 
0 
1 
0 
4 
9 
2 
9 
1 
2 
9 
1 
9 
It can be easily verified that for any choice of x,y € {0,1}: 
P(X = x,Y 
= y) = P(X = x)P(Y 
= y). 
That is, X and Y are independent random variables, which was to be 
expected since the composition of the urn is the same for each extraction. 
EXAMPLE 5.12 
Solve the previous exercise, now under the assumption that the extrac-
tion takes place without replacement. 
Solution: In this case, the joint distribution function of X and Y is 
given by: 
X\Y 
0 
1 
0 
5 
12 
3 
12 
1 
3 
12 
1 
12 
Given: 
P(X = o,F = 0) = ^ φ | x | = P(X = 0)P(Y = 0). 

212 
RANDOM VECTORS 
Then X and Y are not independent. 
A 
EXAMPLE 5.13 
Let X and Y be independent random variables with density functions 
given by: 
x2 
f(x) = -g-*(o,3)(a0 
g(y) = y_2^(i,oo)(y)· 
Find P{XY > 1). 
Solution: Since X and Y are independent, their joint density function 
is given by: 
., 
, 
iw 
if 0<^<3; y>l 
I 0 
otherwise . 
Accordingly: 
I —j dxdy = 0.99074 . 
A 
Note 5.6 Lei X and Y be independent discrete random variables with values 
in N. Clearly: 
P(X + Y = z) = J2P 
(X = x,Y 
= 
z-x) 
x=0 
z 
= Y^P(X 
= x)P(Y = z-x), 
ze 
x=0 
EXAMPLE 5.14 
Suppose that X and Y are independent random variables with X — V(X) 
and Y = V{ß). Find the distribution of Z = X + Y. 
Solution: The random variables X and Y take the values 0,1,···, 
and therefore the random variable Z also takes the values 0,1, · · ·. Let 

INDEPENDENT RANDOM VARIABLES 
213 
z € {0,1, · · · }. Then: 
Z 
P(Z = z) = ΣΡ(Χ 
= x ) P ( y = z~x) 
x=0 
λ* _-„ μ' 
*-~L 
x! 
(z-
x=0 
- 1ρ-(λ+μ) 
_ Z[ 
x = 0 
= l_e -(λ+μ)( Α + μ)* 
z! 
( z - x ) ! 
έ(:>ν-
That is, Z = V{\ + μ). 
▲ 
Note 5.7 Suppose that X and Y are independent random variables having 
joint probability density function f(x,y) 
and marginal density functions fx 
and fy, respectively. The distribution function of the random variable 
Z = X + Y can be obtained as follows: 
Fz(z) = P(Z < z) 
f(x,y)dxdy 
-11 
-II 
fx{x)fv{y)dxdy 
x+y< 
z} 
oo 
t-z—y 
/
oo 
pz—y 
I 
fx(x)fy(y)dxdy 
-oo J — oo 
= / ° ° ( / * * 
fx(x)dx)fy(y)dy 
/
oo 
Fx(z-y)fy{y)dy. 
(5.7) 
-OO 
Upon derivation, equation (5.7) yields the density function of the random 
variable Z as follows: 
J 
ΛΟΟ 
fz{z) = fa 
Fx{z- y)fv{y) dy 
-I 
oo 
oo 
faFx(z-y)fy(y)dy 
/
OO 
fx(z-y)Mv)dy. 
(5.8) 
-oo 
The density function of the random variable Z is called the convolution of the 
density functions fx and fy and is notated fx * fy. 

214 
RANDOM VECTORS 
EXAMPLE 5.15 
Let X and Y be i.i.d. random variables having an exponential distribu-
tion of parameter λ > 0. The density function of Z = X + Y is given 
by: 
fz(z) = 
(fx*fY)(z) 
/
OO 
λ ε-λ(ζ-« ) Α. ( ο ^ 
_ u ) Ae-Au#(0,oo)(u) d« 
-OO 
/ O O 
X2e~XzX(p,ao)(z - u)X(o,oo)(u)du. 
-OO 
Given: 
Then : 
■«)«*(o,oo)(«) = |
0 
^ 
. 
. ^ if z > u > 0 
* ( 0 . α ο ) ( * - « ) * < 0 . ο ο ) ( « ) Η η 
o t h e r w i s e . 
(fx*fy)(z) 
= 
X2ze-x*X(0,oo)(z) 
= Γ^(λ2ί)β- λ'^(ο,οο)(«). 
That is, Ζ = Γ(2,λ). 
A 
EXAMPLE 5.16 
Let X and Y be independent random variables such that X = U[—l, 2] 
and Y = Exp(l). 
Calculate P(X + Y > 1). 
Solution: The joint probability density function of X and Y is given 
by 
t\e-y 
if 
- l < x < 2 ; y > 0 
10 
otherwise 
so that: 
P(X + Y>1)= 
JJ 
f(x,y)dxdy 
{(x,y).x+V>l} 
= I Γ \e~Vdydx + J f°°\e-ydydx 
= 0.62155 

INDEPENDENT RANDOM VARIABLES 
215 
Below, the notion of independence is generalized to n random variables: 
Definition 5.7 (Independence of n Random Variables) n real-valued ran-
dom variables Χχ, Χ2," 
iXn defined over the same probability space are 
called independent if and only if for any collection of Borel subsets A\, A2, ■ · ■ ,An 
of R the following condition holds: 
p(x1eA1,---,xnGAn) 
= 
P(x1eA1)---P(xneAn). 
Note 5.8 (Independence of n Random Vectors) The definition above can 
be extended to random vectors in the following way: n k-dimensional 
random 
vectors Χχ, Χ2, · · · , Xn> defined over the same probability space (Ω, 9, P), 
are said to be independent if and only if they satisfy 
P(Xi 6 Au ■ ■ ■ , X n € An) = P(Xi € A1) ■ ■ -P(Xn 
6 An) 
for any collection of Borel subsets Αχ,Αϊ,··· 
,Αη of Rfc. 
EXAMPLE 5.17 
Distribution of the Maximum and Minimum 
Let X\, ■ ■ ■ , Xn be n real-valued random variables defined over (Ω, 9, P) 
and consider the random variables Y and Z defined as follows: 
Y: 
and 
Z : 
Clearly, 
and: 
= max(Xi, 
= min(Xi, 
FY(V) : 
· ■· , * » ) : 
Ω 
ω 
■· ■, * » ) : 
Ω 
ω 
= P(Y <y) = 
zl 
Ζί 
Ρ(Χι 
R 
max(Xi(o;),··· 
,Χη(ω)) 
R 
min(Xi(w),··· 
,Χη(ω)) 
< y, ■ ■ ■, Xn 
< y) 
Fz(z) 
:= P{Z<z) 
= l - P{Xi > z, ■ ■ ■ ,Xn > z). 
Therefore, if the random variables X\, · · · , Xn are independent, then 
FY(y) = Πρ(χ* ^ v) = ΪΙρχΛν) 
n 
Fz(z) = l-H[l-P{Xk< 
z)\ 
fc=l 
= 1 - Π [ 1 - ^ ( ζ ) ] 
fc=l 
where Fxk (·) is the distribution function of the random variable Xk for 
k = 1,· · · ,n. 
▲ 

216 
RANDOM VECTORS 
EXAMPLE 5.18 
Let X and Y be independent and identically distributed random vari-
ables having an exponential distribution of parameter a. Determine the 
density function of the random variable Z := max{X, Y3} . 
Solution: The density function of the random variable U = Y3 is given 
by: 
Ιθ 
otherwisi 
otherwise . 
Since the random variables X and Y3 are independent, it follows from 
the previous example that Z — max{X, Y3} has the following cumula-
tive distribution function: 
Fz{z) = 
Fx(z)FY3(z). 
Therefore, the density function of Z is given by: 
fz(z) 
= fx(z)FY3(z) 
+ 
Fx(z)fY*(z). 
That is: 
iae-az 
1° 
/*w=r 
+ ^
e ~
a r z "
α ( 1 + ^
) e " ° ^ if z > ° 
otherwise . 
Note 5.9 If X\, X2, ··· , Xn o.re n independent random variables, then 
Χι,Χ?,·" 
i-Xfc with k <n are also independent. To this effect, let 
A\, 
A2, ■ ■ ■ ,Ak be Borel subsets ofR. 
Then: 
P{Xi e Ax, ■ ■ ■ ,Xk e Ak) = p(x1 e Au■ ■ ■ ,Xk e Ak,Xk+1 e R, 
= 
P(XleAl)---P(XkeAk)P(Xk+1eR) 
■■■P(XneR) 
= 
P(XleA1)---P(XkeAk). 
Suppose that X\,X2 
and X3 are independent discrete random variables 
and let Yx := Χχ + X2 and Y2 := A"f. Then: 
P(Yi = z,Y2 = w) = 5^P(Xi =x,X2 
= z-x,X% 
= w) 
X 
= ΣΡ(Χι 
= χ)ρ(χ2 
=z- 
x)P(X» = ±y/w) 
x 
= P(X3 = ±ν^)ΣΡ(χι 
= χ)ρ(χ2 
= 
z-x) 
x 
= P(X1+X2 
= z)P(Xl 
= w). 

DISTRIBUTION OF FUNCTIONS OF A RANDOM VECTOR 
217 
That is, Y\ :— X\ + X2 and Y^ := X | are independent random variables. 
Does this result hold in general? The answer to this question is given by the 
following theorem whose demonstration is omitted since it relies on measure-
theoretic results. 
Theorem 5.7 Let X\,··· 
,Xn, be n independent random variables. Let Y 
be a random variable defined in terms of Xi,· ■ ■ ,Xk and let Z be a random 
variable defined in terms of Xk+i, · · · ,Xn, 
where 1 < k < n. Then Y and Z 
are independent. 
■ EXAMPLE 5.19 
Let Χχ,- ■ ■ ,Χδ be independent random variables. By Theorem 5.7, it 
is obvious that Y = X\X-z + X3 and Z = ex& sinXi are independent 
random variables. 
A 
3 
DISTRIBUTION OF FUNCTIONS OF A RANDOM VECTOR 
Let X = (X\,X2, · ■ ■ , Xn) be a random vector and let g%(·, ■ ■ ■ ,·)»*"> 
gic(-, ■ · ■ , ■) be real-valued functions defined over A C Rn. Consider the fol-
lowing random variables: Y\ := gi(Xi, · · · , Xn), 
·■ ,Yk '·= 9k(Xi, ··■ , Xn)· 
We wish to determine the joint distribution of Y\, · · · , Ifc in terms of the joint 
distribution of the random variables Χχ,··· 
, Χη· 
Suppose that the random variables X\, · · · , Xn are discrete and that their 
joint distribution is known. Clearly: 
P (Yi = vi, ■ ■ ■, Yk = yk) = P{gi(Xi, · · ·, Xn) = vi, · · ·, 9k(Xi, ■ · ·, xn) = Vk) 
= 
Σ 
P(Xi =xi,··· ,Xn 
=xn). 
( n , - , i „ ) 6 R n : 
9i(xi,-- 
,xn)=yi 
9*(*1.— 
,*n)=Vk 
■ EXAMPLE 5.20 
Let X\ and X2 be random variables with joint distribution given by: 
Xi\X* 
0 
1 

218 
RANDOM VECTORS 
Let gi(x\,X2) 
'■= xi + X2 and 52(2:1,2:2) = X1X2· Clearly, the random 
variables 
Y1:=g1(Xl,X2)=X1+X2 
and Y* := &(Χι, X2) = XiX7 
take, respectively, the values —1,0,1,2 and —1,0,1. The joint distribu-
tion of Y\ and F2 is given by: 
Yi\Y* 
- 1 
0 
1 
2 
- 1 
0 
1 
7 
0 
0 
0 
1 
7 
2 
7 
2 
7 
0 
1 
0 
0 
0 
1 
7 
EXAMPLE 5.21 
Let Χχ, Χ2 and X3 be random variables having joint distribution func-
tion given by: 
X = 
( x i , X 2 , X 3 ) 
P((Xi,Xa,Xs) = x) 
(0,0,0) 
1 
8 
(0,0,1) 
3 
8 
(0,1,1) 
1 
8 
(1,0,1) 
1 
8 
(1,1,0) 
1 
8 
(1,1,1) 
1 
8 
Let 5i(xi, 22,2:3) :=Χι+Χ2+Χ3, 52(^1,Χ2,Χ3) = |aj3 — ar2|- The joint 
distribution of Υχ :— gi(Xi,X2,X3) 
and Y2 := 52(^1,-^2,-^3) is given 
by: 
Ya\Yi 
0 
1 
0 
1 
8 
0 
1 
0 
3 
8 
2 
1 
8 
2 
8 
3 
1 
8 
0 
In the case of absolutely continuous random variables, we have the following 
result. The interested reader can consult its proof in Jacod and Protter (2004). 
Theorem 5.8 (Transformation Theorem) Let X = (Χχ,Χ2, ■ ■ ■ ,Xn) be 
a random vector with joint density function / χ . Let g : Rn —> Rn be an 

DISTRIBUTION OF FUNCTIONS OF A RANDOM VECTOR 
219 
injective map. Suppose that both g and its inverse h : Rn —> Rn are con-
tinuous. If the partial derivatives of h exist and are continuous and if their 
Jacobian J is different from zero, then the random vector Y := g(X.) has joint 
density function / γ given by: 
f (y) = J V M I / x i M y ) ) 
if Υ i s °n d's range 
JO 
otherwise . 
EXAMPLE 5.22 
Let X = (Xi,X2) 
be a random vector having joint probability density 
function given by: 
[0 otl 
, . 
. 
. ~ ~ 0 < xi < 1, 0 < x2 < 1 
fx(xi,X2) 
= i n 
., 
. 
otherwise . 
Find the joint probability density function of Y = (Yj, i^), where 
Yi=Xi+ 
X2 and Y2=X1- 
X2. 
Solution: In this case we have 
g(xi,xi) = {gi{xi,x2),g2{xi,x2)) = (an +χ2,χι 
-χ2) 
and the inverse transformation is given by: 
fxi +x2 
xi-x2\ 
h{x1,X3)={—£-,—j—). 
The Jacobian J of the inverse transformation would then equal: 
1 
1 
2 
1 
2 
1 
2 
1 
2 
J= 
, 
, 
2. 
Therefore, the joint probability density function of Y is: 
h{y\,V2) 
= 
_ A 
if 0 < 2/i + 2/2 < 2 , 0 < j/i - y2 < 2 
0 
otherwise . 
A 
In general we have the following result for distribution of the sum and the 
difference of random variables. 
Theorem 5.9 Let X and Y be random variables having joint probability den-
sity function f. Let Z := X+Y 
and W := X—Y. 
Then the probability density 
functions of Z and W are given by 
/
oo 
f(z - u, u) 
-oo 
du 

220 
RANDOM VECTORS 
and 
/
oo 
f(u + w, u) du, 
-oo 
respectively. 
Proof: Just like in the previous example, we have that 
g(x,y) := (x + 
y,x-y) 
and the inverse transformation h is given by: 
s 
fx + y 
x-y\ 
Therefore, the joint probability density function of Z and W equals 
1 
fz + w 
z-w\ 
from which we obtain that: 
/
oo 
/(u, z — u) du 
-oo 
/ o o 
/(^ — u, u)du. 
-oo 
In a similar fashion: 
t 
( \ 
ϊ°° 
λ t fz + w 
z-w\ 
fwiw)=L 
2f {—' 
—)dz 
/
oo 
f(u, u — w)du 
-oo 
/ o o 
f(u + w, u) du . 
-oo 
Note 5.10 In the particular case where the random variables X and Y are 
independent, the density function of the random variable Z := X + Y is given 
by 
/
OO 
ΛΟΟ 
fx(u)fY(z-u)du= 
/ 
fx{z-u)fY(u)du, 
(5.9) 
-oo 
J—oo 
where fx(-) and fy(-) represent the density functions of X and Y respectively. 
The expression given in (5.9) is the convolution of fx 
and fy, notated as 
fx * /y [compare with (5.8)]. 

DISTRIBUTION OF FUNCTIONS OF A RANDOM VECTOR 
2 2 1 
EXAMPLE 5.23 
Let X and Y be independent random variables having density functions 
given by: 
2 < x < 3 
otherwise 
10 
otherwise 
Determine the density function of Z = X + Y. 
Solution: We know that: 
/
oo 
fx(u)fY{z-u)du. 
-oo 
Since 
z < 9 + u 
f. 
we obtain: 
. , , , , 
, 
ί A i f 2 < u < 3 a n d 7 + u < 
■x{vL)fY(z-u)=\* 
. 
10 
otherwise 
fz(z) = { 
(\{z-S) 
if 9 < z < 10 
\ 
if 10 < z < 11 
i ( 1 2 - z ) 
if 11 <z< 
12 
0 
otherwise . 
▲ 
EXAMPLE 5.24 
Let X and Y be random variables having the joint probability density 
function given by: 
,, 
, 
(3x 
if 0 < y < x < 1 
f(x, y) = \ 10 
otherwise . 
Find the density function of W :~ X — Y. 
Solution: According to Theorem 5.9: 
/
oo 
f(u,u — w)du. 
-oo 
Here: 
\Zu 
if 0 < u - w < u < 1 
f(u,u — w) — < 
10 
otherwise . 

222 
RANDOM VECTORS 
Then: 
/
i 
3 
3uX[0A]{w)du 
= -(1 - w2)X[0A](w) 
. 
A 
Theorem 5.10 (Distribution of the Product of Random Variables) Let 
X and Y be random variables having joint probability density function f. Let 
Z := XY. 
Then the density function of Z is given by: 
Proof: We introduce W := Y. Let g be the function defined by: 
g(x,y) := (gi(x,y),g2{x,v)) = (xy,y)-
The inverse transformation equals: 
h(x,y)= 
\~^y)-
The Jacobian of the inverse transformation is: 
J{x,y) --
1 
1 
y' 
Therefore, the joint probability density function of Z and W is given by: 
1 
fzw{z,w) 
w '(?·) 
Now, we obtain the following expression for the density function of Z = XY: 
fz{z)= 
—f(-,w)dw 
J-oo \w\ 
VW 
) 
= I 
Tif (u' ~) du-
EXAMPLE 5.25 
Let X and Y be two independent and identically distributed random 
variables, having uniform distribution on the interval (0,1). According 
to the previous example, the density function of Z := XY is given by 
=£R/*W/I·©""' 

DISTRIBUTION OF FUNCTIONS OF A RANDOM VECTOR 
223 
where fx and fy represent the density functions of X and Y respectively. 
Since 
1 if 0 < u < 1 and 0 < z < u 
otherwise 
'*«*(;) = {; 
then: 
0<z 
< 1 
= {!tldu if 
[0 
otl 
otherwise 
I - In z 
if 0 < 2: < 1 
10 
otherwise . 
A 
Theorem 5.11 (Distribution of the Quotient of Random Variables) 
Let X and Y be random variables having joint probability density function 
f. 
Let Z := γ [which is well defined if P(Y = 0) = 0)]. 
Then the density 
function of Z is given by: 
/
oo 
\w\ f (zw, w) dw. 
-00 
Proof: We introduce W :=Y. Now, consider the function 
g(x,y) := (gi(x,y),g2(x,y)) 
= ( - , » ] · 
The inverse transformation is then given by: 
h(x,y) = {xy,y). 
Its Jacobian equals: 
y 
x 
0 
1 
y-
J(x,y) 
Then the joint density function of Z and W is given by: 
fzw{z,w) 
= 
\w\f(zw,w). 
Therefore, a density function of Z is: 
/
oo 
\w\f(zw,w) 
dw. 
-00 

224 
RANDOM VECTORS 
EXAMPLE 5.26 
Let X and Y be two independent and identically distributed random 
variables having uniform distribution on the interval (0,1). According 
to the previous example, the density function of Z := y is given by 
/
oo 
\w\ f (zw, w) dw 
-oo 
,oc 
= / 
\w\fx(zw)fy{w) 
dw 
J—oo 
where fx and /y represent the density functions of X and Y, respec-
tively. Since 
, / 
w 
/ x 
i 1 
if 0<ZW < 1 
fx(zw)fY(w) 
= < 
. 
10 
otherwise 
and 0 < w < 1 
then: 
fz(z) = { 
j 0 wdw 
if 0 < z < 1 
/0
l wdw 
if z > 1 
0 
otherwise 
1 
2*(o,i)(*) + ^ϊ^ΐι.οο)^) 
EXAMPLE 5.27 
Assume that the lifetime X of an electric device is a continuous random 
variable having a probability density function given by: 
fix) 
ίψ 
if x> 
Ι θ 
otherw 
1000 
otherwise . 
Let X\ and X2 be the life spans of two independent devices. Find the 
Xi 
x2-
density function of the random variable Z — ^ 
Solution: It is known that: 
Since 
/
oo 
\v\f(vz)f(v)dv. 
■00 
[0 
otherwii 
f(vz) 
1000 
otherwise 

DISTRIBUTION OF FUNCTIONS OF A RANDOM VECTOR 
225 
then: 
(i) If z > 1, then f(vz)f(v) 
does not equal zero if and only if v > 1000. 
Thus: 
, , , 
f°° 1000 1000 , 
(1000)2 f°° dv 
1 
Viooo v z 
v 
z 
Jiooo v 
zz 
(ii) If 0 < z < 1, then f(vz)f(v) 
does not equal zero if and only if 
vz > 1000 if and only if v > ^ . 
Therefore: 
r , . 
r°° looo looo J 
l 
fz(Z)= 
-2-2 · - ö ~ v d v = -
That is: 
r i 
2z
5 
/zW = { 
if z > 1 
\ 
if 0 < z < 1 
0 
otherwise . 
▲ 
EXAMPLE 5.28 
t-Student Distribution 
Let X and Y be independent random variables such that X = λί(0,1) 
and Y = <*(£)· Consider the transformation 
The inverse transformation is given by 
whose Jacobian is: 
J(x,y) 
Therefore, the joint probability density function of Z := -4= and 
VTE-
W := Y is given by 
fzw(z, w) = yjf(zy^'w)' 
w > °> 
where: 
'"··<>-τζ*'™ 
1 
fc 

226 
RANDOM VECTORS 
Integration of fzw{z,w) 
with respect to w yields the density function 
of the random variable Z which is then given by: 
'^M^m 
[1 + Ϊ1 
k+ 
2 - 1 2 
r ; z e R . 
(5.10) 
A real-valued random variable Z is said to have a i-Student distribution 
with k degrees of freedom, notated as Z = t^k), if its density function is 
given by (5.10). 
▲ 
■ EXAMPLE 5.29 F Distribution 
Let X and Y be independent random variables such that X = X?m\ and 
Y = X?}. Consider the map 
<?(*,!/) : = ( f , i / ) · 
The inverse of g is given by 
h(x,y) = (—xy,y) 
and has a Jacobian equal to J(x, y) = ^y. Therefore, the joint proba-
bility density function of Z := *j£ and W := Y is given by: 
fzw(z,w) = 
r J
W
M 
(ΙΫ 
(lY 
(-zwf-'w^eH^^)], 
z>0,w>0. 
r ( f ) r ( f ) V 2 y 
V2/ 
Vn 
; 
Integrating with respect to w we find that the density function of Z 
is given by the following expression: 
m _ i 
nW-r(=±=)[r(=)r (=)]- {<rtf-^, 
»o. 
(5.11) 
A random variable Z is said to have an F distribution, with m degrees of 
freedom on the numerator and n degrees of freedom in the denominator, 
notated as Z = F™, if its density function is given by (5.11). 
▲ 
The transformation theorem can be generalized in the following way: 
Theorem 5.12 Let X = (Χι,Χζ,··· 
,Χη) be a random vector with joint 
probability density function /χ. Let g be a map ofW1 into itself. Suppose 

DISTRIBUTION OF FUNCTIONS OF A RANDOM VECTOR 
227 
that Rn can be partitioned in k disjoint sets A\, ■ ■ ■ ,Ak in such a way that 
the map g restricted to Ai for i = 1, · · · ,k is a one-to-one map with inverse hi. 
If the partial derivatives of hi exist and are continuous and if the Jacobians 
Ji are not zero on the range of the transformation for i = 1, · · · , k, then the 
random vector Y := g(X) has joint probability density function given by: 
k 
/Y(y) = £|.My)l/x(My))· 
i=l 
Proof: Interested reader may refer to Jacod and Protter (2004) for the above 
theorem. 
■ 
■ EXAMPLE 5.30 
Let X be a random variable with density function fx. Let g : R —> R 
be given by g(x) = x4. Clearly R = (—oo, 0) U [0, oo) and the maps 
Ai : [0,oo) 
—► R 
g2 : (-oo,0) 
—y 
R 
X 
I 
> 
X 4 
have respectively the inverses 
hi : [0, oo) 
—► [0, oo) 
X 
I > 
\fx 
h2: 
(0,oo) 
—► (-οο,Ο) 
X 
I > 
—\fx . 
The Jacobians of the inverse transforms are given, respectively, by: 
Λ ( Χ ) = τ χ _ ϊ 
and 
J2(x) 
=—-x~*. 
Therefore, the density function of the random variable Y = X4 is given 
by: 
My) = Y,\My)\fx(hi{y)) 
i = l 
1 
3 
1 _ a 
= ^y 
4 / χ ( ^ ) + 4?/ 
4/χ(-ψϋ)-

228 
RANDOM VECTORS 
5.4 
COVARIANCE AND CORRELATION COEFFICIENT 
Next, the expected value of a function of an n-dimensional random variable 
is defined. 
Definition 5.8 (Expected Value of a Function of a Random Vector) 
Let (Xi,X2, · · · ,Xn) be an n-dimensional random vector and let g(-, ■ ■ ■ , ·) 
be a real-valued function defined over R n. The expected value of the function 
g{Xi, ■ ■ ■ ,Xn), 
notated as E(g(Xi, 
■ ■ ■ ,Xn)), 
is defined as 
E(g(Xir--,Xn)):= 
ΣΧι···Σ,Χη9{χι,··· 
,χη)Ρ(Χι 
= x i , · · · ,Xn = xn), 
discrete random variables 
J^0
00---J^0
oog(xi,·-- 
,Xn)f(xi,··· 
,xn)dxi 
··· dxn, 
continuous random variables 
provided that the multiple summation in the discrete case or the multiple in-
tegral in the continuous case converges absolutely. 
■ EXAMPLE 5.31 
Suppose that a fair dice is rolled twice in a row. Let X :="the maximum 
value obtained" and Y := "the sum of the results obtained". In this case, 
Ε(ΧΥ) = ψ . 
A 
■ EXAMPLE 5.32 
Let (X, Y, Z) be a three-dimensional random vector with joint probabil-
ity density function given by: 
[Sxyz 
if 0 < x < 1; 0 < y < 1 and 0 < z < 1 
f(x,y,z) 
= < 
10 
otherwise . 
Thea E(5X-2Y+ 
Z) = * sad E(XY) 
= ±. 
▲ 
Theorem 5.13 If X andY are random variables whose expected values exist, 
then the expected value ofX + Y also exists and equals the sum of the expected 
values of X and Y. 
Proof: We prove the theorem for the continuous case. The discrete case can 
be treated analogously. 
Suppose that / is the joint probability density function of X and Y. Then: 
/ 
\x + y\f{x,y)dxdy 
< / 
/ 
(|x| + \y\) 
f(x,y)dxdy 
-oo J—oo 
J—oo J — oo 

COVARIANCE AND CORRELATION COEFFICIENT 
2 2 9 
/
OO 
ΛΟΟ 
/»O0 /»OO 
/ 
\x\f(x,y)dxdy 
+ / 
/ 
|y| 
f(x,y)dxdy 
-OO */ —OO 
J— OO J — OO 
/
OO 
/ 
/«OO 
\ 
ΛΟΟ 
/ 
/»OO 
\ 
M ( / 
/·>, 2/) dy) dx+ / 
|y| ( / 
/(x,2/)dx) dy 
■oo 
\J—oo 
/ 
J—oo 
\J—oo 
/ 
/
OO 
ΛΟΟ 
|x| /Λ-(Χ) dx + 
/ 
|j/| / y(y) 
dy < oo . 
■oo 
J—oo 
Therefore, £J(X + Y) exists. 
Furthermore: 
/
OO 
ΛΟΟ 
/ 
(x + 
y)f(x,y)dxdy 
-oo «/—oo 
/
OO 
/ 
ΛΟΟ 
\ 
i>00 
/ 
/ Ό Ο 
\ 
^ ( / 
f{x, y)dy\ dx+ 
yl 
f(x, y) dx) dy 
-oo 
\J — oo 
/ 
J—oo 
\J—oo 
/ 
/
OO 
/»OO 
x/x(x)tix+ / 
yfy(y)dy 
■OO 
J — OO 
E{X) + E(Y) . 
Note 5.11 7/X is a discrete random variable and Y is a continuous random 
variable, the previous result still holds. 
In general we have the following: 
Theorem 5.14 IfXi, X2, ··· , Xn ore n random variables whose expected val-
ues exist, then the expected value of the sum of the random variables exists as 
well and equaL· the sum of the expected values. 
Proof: Left as an exercise for the reader. 
■ 
EXAMPLE 5.33 
An urn contains N balls, R of which are red-colored while the remaining 
N—R are white-colored. A sample of size n is extracted without replace-
ment. Let X be the number of red-colored balls in the sample. Prom the 
theory described in Section 3.2, it is known that X has a hypergeometric 
distribution of parameters n, R and N; therefore E(X) = ^ . We are 
now going to deduce the same result by writing X as the sum of random 
variables and then applying the last theorem. 
Let Xi, with i = 1, · - · , n, be the random variables defined as follows: 
_ j 1 if the ith ball extracted is red 
Xi :— \ 0 if the ith ball extracted is white. 

230 
RANDOM VECTORS 
Clearly: 
i=l 
Accordingly: 
E(X) = ±E(Xi) = ±§ = f . 
A 
i=l 
i=l 
Theorem 5.15 If X and Y are independent random variables whose expected 
values exist, then the expected value of XY also exists and equals the product 
of the expected values. 
Proof: We prove the theorem for the continuous case. The discrete case can 
be treated analogously. 
Suppose that / is the joint probability density function of X and Y. Then: 
/
OO 
ΛΟΟ 
/«OO 
fOO 
/ 
\xy\f(x,y)dxdy= 
/ 
/ 
\x\\y\fx(x)fY(y)dxdy 
-OO J — OO 
J — OO */— OO 
= £° M (^°° Ivl Mv) «to) fx{x) dx 
= ( / 
\x\fx(x)dx) 
( 
\y\fY(y)dyj 
<oo . 
That is, E{XY) 
exists. 
Suppressing the absolute-value bars on the previous proof, we obtain: 
E(XY) = E{X)E{Y). 
Two random variables can be independent or be closely related to each 
other. It is possible, for example, that the random variable Y will increase 
as a result of an increment of the random variable X or that Y will increase 
as X decreases. The following quantities, known as the covariance and the 
correlation coefficient, allow us to determine if there is a linear relationship of 
this type between the random variables under consideration. 
Definition 5.9 (Covariance) Let X and Y be random variables defined 
over the same probability space and such that E(X2) 
< oo and E(Y2) 
< oo. 
The covariance between X and Y is defined by: 
Cov(X, Y) := E ((X - E(X))(Y 
- 
E(Y))). 
Note 5.12 Let X and Y be random variables defined over the same probabil-
ity space and such that E(X2) 
< oo and E(Y2) < oo. Since \X\ < l+X2, 
then 

COVARIANCE AND CORRELATION COEFFICIENT 
2 3 1 
it follows that E(X) exists. On the other hand, \XY\ < X2 + Y2 implies the 
existence of the expected value of the random variable (X — E(Y))(Y 
— E(Y)). 
Theorem 5.16 Let X and Y be random variables defined over the same prob-
ability space and such that E(X2) 
< oo and E(Y2) < oo. Then: 
(i) Cov{X,Y) 
= E(XY) 
- 
E(X)E(Y). 
(ii) Cov(X,Y) 
= 
Cov(Y,X). 
(in) VarX = 
Cov(X,X). 
(iv) Cov{aX + b,Y) = aCov(X,Y) 
for any 
a,beR. 
Proof: We prove (iv) and leave the others as exercises for the reader: 
Cov(aX + b,Y) = E (((aX + b)- E(aX + b))(Y - 
E(Y))) 
= E((aX + b- aE{X) - b){Y - 
E(Y))) 
= 
aCov{X,Y). 
Note 5.13 Prom the first property aL·ve, it follows that if X and Y are 
independent, then Cov(X, Y) = 0. The converse, however, does not always 
hold, as the next example illustrates. 
■ EXAMPLE 5.34 
Let Ω = {1,2,3,4}, 3 = ρ(Ω) and let P : 3 -> [0,1] be given by 
P(l) = P(2) := f, P(3) = P(4) := ^ . The random variables X and Y 
defined by X(l) = Y{2) := 1, X(2) = Y(l) := - 1 , X(3) = Y(3) := 2 
and X(4) = F(4) := —2 are not independent in spite of the fact that 
Cov(X, Y) = 0. 
A 
Theorem 5.17 (Cauchy-Schwarz Inequality) Let X and Y be random 
variables such that E(X2) 
< oo and E(Y2) < oo. Then 
\E{XY)\2 
< (E(X2))(E(Y2)). 
Furthermore, the equality holds if and only 
if there are real constants a and b, not both simultaneously zero, such that 
P(aX + bY = 0) = l. 
Proof: Let a = E(Y2) 
and β = -E(XY). 
Clearly a > 0. Since the result 
is trivially true when a = 0, let us consider the case when a > 0. We have: 
0 < E((aX + βΥ)2) = E{a2X2 + 2αβΧΥ 
+ 
β2Υ2) 
= a(E(X2)E(Y2) 
- 
E(XY)E(XY)). 
Since a > 0, the result follows. 

232 
RANDOM VECTORS 
If {EXY)2 
= E(X2)E(Y2), 
then E(aX + ßY)2 
= 0. Therefore, with 
probability 1, we have that (aX + ßY) = 0 . If a > 0, we can take a = a and 
b = β. If a = 0, then we can take a = 0 and 6 = 1 . 
Conversely, if there are real numbers a and 6 not both of them zero such 
that with probability 1 (aX + bY) = 0, then, aX — —bY with probability 1, 
and in that case it can be easily verified that \E{XY)\2 
= E(X2)E(Y2). 
u 
Note 5.14 Taking \X\ and \Y\ instead of X and Y in the previous theorem 
yields: 
E \XY\ < s/E{X*)yjE{Y2) 
. 
Applying this last result to the random variables X — E(X) and Y — E(Y) we 
obtain \Cov(X,Y)\ 
< 
y/Var(X)^/Var(Y). 
Theorem 5.18 // X and Y are real-valued random variables having finite 
variances, then Var(X + Y) < oo and we have: 
Var{X + Y) = Var{X) + Var(Y) + 2Cov(X, Y). 
(5.12) 
Proof: To see that Var(X + Y) < oo it suffices to verify that: 
E{X + Y)2 <oo . 
To this effect: 
E(X + Y)2 = E(X2) + 2E(XY) 
+ E(Y2) 
< E{X2) + 2E \XY\ + E(Y2) 
< 2(E(X2) + E(Y2)) 
< oo. 
Applying the properties of the expected value, we arrive at (5.12). 
■ 
In general we have: 
Theorem 5.19 If X\, Χ2, · · · , Xn are n random variables having finite vari-
ances, then Var I Σ,Χ, I < 00 and: 
Var (itXi) 
= T,Var(Xi) 
+ 
YfY,Cov(Xi,Xj). 
\ t = l 
/ 
i=l 
i^j 
Proof: Left as an exercise for the reader. 
■ 
Note 5.15 Since each pair of indices i,j with i φ j appears twice in the 
previous summation, it is equivalent to: 
Var (itX<) = JlVar(Xi) + 2££Cot;(Xi,Xj). 

COVARIANCE AND CORRELATION COEFFICIENT 
2 3 3 
// X\, X2, ■ ■ ■ , Xn are n independent random variables with finite variances, 
then: 
Var 
ΣΧ< 
= YyariXi) 
. 
EXAMPLE 5.35 
A person is shown n pictures of babies, all corresponding to well-known 
celebrities, and then asked to whom they belong. Let X be the random 
variable representing the number of correct answers. Find E{X) and 
Var{X). 
Solution: Let: 
c=il 
ifl 
*· 
\ 0 
ot] 
Y 
_ . - 
--' the person correctly identifies the ith picture 
otherwise. 
Then: 
X = ±Xi. 
i=l 
Hence: 
E(X) = f > ( X i ) = f^P(Xi = 1) = n i = 1 . 
t=l 
i=l 
On the other hand, we have that: 
Var ( Σ * ) = flVar(Xii + 2 Σ T,Cm(xi> Xi)-
Noting that 
and 
E(XiXj) 
= P(Xi = l,Xj 
= l) 
= P(Xj = 1 I Jf4 = l)P(Xi = 1) 
1 
1 
x 
n — 1 
n' 
it follows that 
Coo(Xi,Xi) 
= E(XiXj) 
- 
(E(Xi))(E(Xj)) 
1 
1 
1 
x 
n — 1 
n 
nz 
- \ 
l 
n [n(n — 1) 

234 
RANDOM VECTORS 
Thus: 
I r 
.,„. 
n(n — 1) 
Λ / η \ 
1 
n — 1 
1 
The covaxiance is a measure of the linear association between two random 
variables. A "high" covaxiance means that with probability 1 there is a lin-
ear relationship between the two variables. But what exactly does it mean 
that the covaxiance is "high"? How can we qualify the magnitude of the co-
vaxiance? In fact, property (iv) of the covaxiance shows that its magnitude 
depends on the measure scale used. For this reason, it is difficult in concrete 
cases to determine by inspection if the covaxiance between two random vari-
ables is "high" or not. In order to get rid of this complication, the English 
mathematician Karl Pearson, who developed most of the modern statistical 
techniques, introduced the following concept: 
Definition 5.10 (Correlation Coefficient) LetX andY be real-valued ran-
dom variables with 0 < Var(X) < oo and 0 < Var{Y) < oo. The correlation 
coefficient between X and Y is defined as follows: 
P(X,Y):=- 
C ^
X ^ 
^Var(X)s/Var(Y) 
' 
Theorem 5.20 Let X and Y be real-valued random variables with 
0 < Var{X) < oo and 0 < Var{Y) < oo. 
(i) p(X,Y) 
= 
p(Y,X). 
(ii) 
\p(X,Y)\<l. 
(Hi) p(X,X) 
= 1 and p(X, -X) 
= - 1 . 
(iv) p(aX + b, Y) = p(X, Y) for any a,b&R 
with a > 0. 
(v) \p{X; Y)\ = 1 if and only if there are constants a, b 6 R not both of them 
zero and c e R such that P{aX + bY = c) = 1. 
Proof: We prove (ii) and (v) and leave the others as exercise for the reader. 
(ii) Let: 
y > . 
X-E(X) 
^Var(X) 
Y - E{Y) 
Y* :-- y/Var{Y) 

EXPECTED VALUE OF A RANDOM VECTOR AND VARIANCE-COVARIANCE MATRIX 
2 3 5 
Clearly E(X') 
= E(Y*) = 0 and Var(X*) = Var(Y*) = 1. Therefore 
p(X* ,Y") = 
E{X*Y*) 
_ E(XY) 
- 
E{X)E{Y) 
~ 
y/Var(X)y/Var(Y) 
and 
0 < Var{X*±Y*) 
= Var(X*)±2Cav(X*,Y*)+Var(Y*) 
= 
2(l±p(X,Y)). 
Hence, it follows that: 
\P(X,Y)\<1. 
(v) Let X* and Y* be defined as in (ii). Clearly 
p(X,Y) 
= l 
^ * 
p{X\Y*) 
= l 
(E(X*Y*))2 
= 
E(X*)2E(Y*f 
There exist α, β where a φ 0 or β φ 0 
such that P{aX* + βΥ* = 0) = 1 
P{aX + bY = c) = l, 
where: 
a 
- - 
, 
β 
- - - - - 
a
E ^ 
i 
ß
E ^ 
y/Var{X)' 
y/Var(y) 
y/Var{X) 
y/Var(Y) 
' 
The case p(X, Y) = — 1 can be handled analogously. 
Part (v) above indicates that if \p(X, Y)\ « 1, then Υ(ω) « αΧ(ω) + b 
for all ω € Ω. In practice, a "high" absolute-value correlation coefficient 
indicates that Y can be predicted from X and vice versa. 
5.5 
EXPECTED VALUE OF A RANDOM VECTOR AND 
VARIANCE-COVARIANCE MATRIX 
In this section we generalize the concepts of expected value and variance of a 
random variable to a random vector. 
Definition 5.11 (Expected Value of a Random Vector) Let 
X = (X\,X2,· 
■■ ,Xn) 
be a random vector. The expected value (or expecta-
tion) o/X, notated as E(X), is defined as 
E(X) := 
(E(X1),E(X2),---,E(Xn)) 

236 
RANDOM VECTORS 
subject to the existence of E(Xj) for allj = l,··· 
,n. 
This definition can be extended even further as follows: 
Definition 5.12 (Expected Value of a Function of a Random Vector) 
Let X = (Xi,^2) · · ■ j Xn) be a random vector and let h : Rn —> Rm be the 
function given by 
h(xi,-·- 
,Xn) 
= (hl(xi,··· 
,Xn),··· 
,hm(xi,··· 
>xn)) 
where hi, for i = 1, ■ · · ,τη, are real-valued functions defined over R™. The 
expected value of /i(X) is given by 
E(h(X)) 
:= (£;(/u(X)),··· 
,E(hm(X))) 
subject to the existence of E(hj(X.)) for all j = 1, · · · , m. 
Definition 5.13 (Expected Value of a Random Matrix) IfXij, 
with 
i = 1, · · · , m and j = 1, · · ■ , n, are real-valued random variables defined over 
the same probability space, then the matrix A = (Xij)mxn 
is called a random 
matrix, and its expected value is defined as the matrix whose entries correspond 
to the expectations of the random variables Xij, that is 
E(A) := (ϋ?(Χ0)) 
mxn 
subject to the existence of E(Xij) for all i = 1, ■ · · , m and all j = 1, · · · , n. 
Definition 5.14 (Variance-Covariance Matrix) LefX= 
(X\,X2,· 
■ ■ ,Xn) 
be a random vector such that E(X?) < oo for all j = 1, ■ · ■ , n. The variance-
covariance matrix, notated 52, of X is defined as follows: 
Σ== 
/ 
VariXi) 
Cov{XuX2) 
■■■ Cov(Xx,Xn) 
\ 
Cov(X2,Xi) 
Var{X2) 
■■■ 
Cov{X2,Xn) 
\ C<wpTn,Xi) 
Cov(Xn,X2) 
■■■ 
Var(Xn) 
J 
Note 5.16 Observe that ]T = E([X-E(X.)f 
[X-£(X)]). 
EXAMPLE 5.36 
Let Xi and X2 be discrete random variables having the joint distribution 
given by: 
Xi\X2 
- 1 
0 
1 

EXPECTED VALUE OF A RANDOM VECTOR AND VARIANCE-COVARIANCE MATRIX 
2 3 7 
Clearly, the expected value of X = (Xi,X2) equals 
and the variance-covariance matrix is given by: 
Σ-
For any a = (01,02) we see that: 
a~Y^aT = {ai,a2) I 
* 
1 
j _ 
4 
12 
_L il 
12 
36 
1 
J_ 
4 
12 
__ 
II 
12 
36 
1 2 
1 
17 2 
4
α ι 
+ 6 α ι α 2 + 36°» 
Ol 
θ 2 
That is, the matrix Σ ' s positive semidefinite. 
A. 
EXAMPLE 5.37 
Let X = (X, y) be a random vector having the joint probability density 
function given by: 
'<*·»>-(: " °
< ! · *
1 ·
0 < ' * ' 
10 
otherwise . 
In this case we have: 
E{XY) 
E{X) 
E{Y) 
E(X2) 
E(Y2) 
= / 
/ xy-dydx= 
-
Jo Jo 
^ 
6 
= / 
x-dxdy= 
-
Jo Jy 
* 
2 
= / 
/ y-dydx 
= -
Jo Jo 
x 
4 
= / 
/ x2 -dydx = -
Jo Jo 
x 
0 
= 
y2-dydx= 
-
Jo Jo 
x 
9 

238 
RANDOM VECTORS 
12 
24 
24 
144 
Therefore, the expected value of X is given by 
and its variance-covariance matrix equals: 
Σ 
And for any a = (αχ, a?) € R2 we have: 
αΎ^ατ 
= (αι, α2) 
1 
( 
2 
~ ! 
! 
2 
! 
2 
7 
2 \ 
= 12 l ß l + 2 2 a i < 1 2 + I " 2 ~ 4 a 2 + Ϊ 2 α 2 / 
= lHai + 2
a2J
 
+ 3 6
α 2 - ° · 
That is, the matrix Σ is positive semidefinite. 
▲ 
In general, we have the following result: 
Theorem 5.21 Let X = (X\, ■ · ■ ,Xn) 
be an n-dimensional random vector. 
If E(X?) < co for all j = 1, · · · , n, then the variance-covariance matrix Σ °f 
X is positive semidefinite. 
Proof: 
Let a = (oi,··· ,an) be any vector in Mn. Consider the random 
variable Y defined as follows: 
Y 
:= 
(Xi,··· 
,Xn)(ai,·-· 
,an) 
n 
= ΣαίΧ* ■ 
t = l 
Since Var(Y) > 0, it suffices to verify that Var(Y) = a^2,aT. 
Indeed: 
Var(Y) = 
E{[Y-E(Y)}2). 
n 
Seeing that, E(Y) = ΣαίΕ(Χί) 
= ß0?\ where μ := E(X), we have: 
i=l 
Var{Y) 
= 
E([XaT 
- ματ] [Χατ - 
ματ]) 
= 
E ([aX T - αμτ] [Χατ - ματ]) 
= 
Ε(α[Χ-μ]Τ[Χ-μ]ατ) 
= 
αΕ([Χ-μ\τ[Χ-μ})ατ 
= 
αΣατ 
. 

EXPECTED VALUE OF A RANDOM VECTOR AND VARIANCE-COVARIANCE MATRIX 
2 3 9 
Note 5.17 Clearly, from the definition of the variance-covariance matrix Σ> 
if the random variables Xi, X2, ■ ■ ■ , Xn are independent, then Σ is a matrix 
whose diagonal elements correspond to the variances of the random variables 
Xj for j = 1,··· ,n. 
We end this section by introducing the correlation matrix, which plays an 
important role in the development of the theory of multivariate statistics. 
Definition 5.15 (Correlation Matrix) Let X = {Xi,X2,··· 
,Xn) 
be a 
random vector with 0 < Var(Xj) 
< 00 for all j = 1,··· ,n. 
The correla-
tion matrix of X, notated as R, is defined as follows: 
R:= 
/ 
1 
P(Xi,X2) 
p{X2,Xi) 
1 
V p(Xn,Xl) 
p(Xn,X2) 
p(Xi,Xn) 
\ 
p(X2,Xn) 
EXAMPLE 5.38 
Let X = (X, Y) be a two-dimensional random vector with joint proba-
bility density function given by: 
We have 
and 
10 otherwise . 
0 < y < 1 
E(X)= 
[ 
[ 
2xdxdy 
Jo Jo 
E{Y)-fJl 
2y dy dx 
1 
3 
2 
Var(X) = J
£ 
2(x - ^) 2 dxdy = ^ 
Var(Y) = £ £ 2(y - \f dydx=± 
Coo(X,Y) = J 
jV2{x-\){y-\)dxdy=±{ 

240 
RANDOM VECTORS 
Therefore the correlation matrix is given by: 
-
(
;
!
)
■ 
■ 
Note 5.18 The correlation matrix R inherits all the properties of the variance-
covariance matrix Σ because 
R = diag ( — , · · · , — ) ·Ύ\·diag 
( — , · · · , — ) 
where Oj := yjVarXj 
for j — 1, · · · , n. 
Therefore, R is symmetric and positive semidefinite. Furthermore, if Oj > 
0 for all j — 1,· ■■ , n, then R is nonsingular if and only ifΣ 
*s nonsingular. 
5.6 
JOINT PROBABILITY GENERATING, MOMENT GENERATING 
AND CHARACTERISTIC FUNCTIONS 
This section is devoted to the generalization of the concepts of probability 
generating, moment generating and characteristic functions, introduced in 
Chapter 2 for the one-dimensional case, to n-dimensional random vectors. 
Now, we define the joint probability generating function for n-dimensional 
random vectors. 
Definition 5.16 Let X = (Χι,Χϊ,··· 
,Χη) 
be an n-dimensional 
random 
vector with joint probability mass function Ρχ1,χ2,---,χη(χι,Χ2, 
· ·· ,^η)· Then 
the pgf of a random vector is defined as 
GX(si,S2,··· 
,Sn)= 
Σ 
ΡΧι,Χ2,",χΛχ1'Χ2'··· 
> Zn)«? 1 · · ■ s£" 
for |si| < 1, \s2\ < 1, · · · , |s n| < 1 provided that the series is convergent. 
Theorem 5.22 The pgf of the marginal distribution of Xi is given by 
GXi=Gx(l,l,---,Si,---,l) 
and the pgf of X\ + X2 + 
l· 
Xn is given by 
H{s) = Gx(s,s,··· 
,s). 
Proof: Left as an exercise. 
■ 
Now, we present the pgf for the sum of independent random variables. 

JOINT PROBABILITY GENERATING, MOMENT GENERATING AND CHARACTERISTIC FUNCTIONS 
2 4 1 
Theorem 5.23 Let X and Y be independent nonnegative integer-valued ran-
dom variables with pgf's Px(s) 
and Py(s), respectively, and let Z = X + Y-
Then: 
Gz(s) = Gx+Y(s) 
= Gx(s) ■ GY(s). 
Proof: 
Gz(s) = E[sz) 
= 
E[sx+Y] 
= E[sx] ■ E[sY] 
given that X and Y are independent 
= GX(S) ■ Gy(s) . 
Corollary 5.1 IfXx,X2,··- 
,Xn are independent nonnegative integer-valued 
random variables with pgf 's Gx1 (s), · · · , Gxn (s) respectively, then: 
GXl+...+Xn(s) 
= 
GXl(S),---,Gxn(S) 
i=l 
■ EXAMPLE 5.39 
Find the distribution of the sum of n independent random variables 
Xi, i = 1,2, · · ■ , n, where Xi = Poisson(A) . 
Solution: GXi(s) = e ^ · " 1 ) . So 
n 
- 1 ) 
GXl+...+Xn(s) = Y[e^°-V 
= 
β(λι+· ·+λη)(«-1) 
This means that: 
n 
^ 
Xi ~ Poisson(Ai H 
h λη) 
i = l 
2_]Xi ~ Poisson I y j A» I . 
▲ 
i=l 
\ t = l 
/ 
If Xi, X2! · · ■ , Xn are i.i.d. random variables, then: 
GXl+X2+...+Xn(s) 
= (GXi(s)Y 

242 
RANDOM VECTORS 
Theorem 5.24 Let X\,X2, 
■ ■ ■ be a sequence of i.i.d. random variables with 
pgf P(s). 
We consider the sum Sw = Xi + X2 + ■ ■ ■ + XN where N is a 
discrete random variable independent of the Xi's with distribution given by 
P(N = n) = gn. The pgf of N is G(s) = Σ η 9nSn \s\ < 1. 
We prove that the pgf of SM is H{s) = G(P(s)). 
Proof: 
H(s) 
= 
E[SSN] 
OO 
= Σ 
EISSN \N = n]P(N = n) 
00 
= j2EisSn]p(N 
= n) 
n=0 
00 
= Σ(Ρ{3))ηΡ(Ν 
= η) 
n=0 
00 
= $>„(p(e)) n 
n=0 
= G(P(s)) 
. 
■ 
From the above result, we immediately obtain: 
1. E{SN) = E(N)E(X) 
. 
2. Var(SN) 
= E(N)Var(X) 
+ Var(N)[E(X)]2 
. 
Now we generalize the concept of mgf for random vectors. 
Definition 5.17 (Joint Moment Generating Function) Let 
X = (Xi, ■ ■ ■ ,Xn) 
be an n-dimensional random vector. If there exist M > 0 
such that £'(exp(Xt )) is finite for all t = (ii, · · · , tn) € M.n with 
iitii := φι+···+ίΐ 
< M, 
then the joint moment generating function o/X, notated as mx(t), is defined 
as: 
m x(t) := £(exp(Xt T)) 
for ||t|| < M . 
■ EXAMPLE 5.40 
Let Xi and X2 be discrete random variables with joint distribution given 
by: 

JOINT PROBABILITY GENERATING, MOMENT GENERATING AND CHARACTERISTIC FUNCTIONS 
243 
Xl\X2 
1 
2 
- 1 
1 
6 
1 
6 
0 
2 
6 
1 
6 
1 
0 
1 
6 
The joint moment generating function of X = (Xi,X2) 
is given by: 
m x(t) = 
E(exp((X1,X2)(t1,t2f)) 
= E(exp{X1t1 
+ X2t2)) 
= Y^2exp(tixi 
+ t2x2)P(Xi 
= xi,X2 = X2) 
= - exp(ii - t2) + - exp(2ti - t2) + - exp(ii) 
+ - exp(2i!) + - exp(2ii +t2) . 
0 
o 
Notice that the moment generating functions of X\ and X2 also exist 
and are given, respectively, by 
m X l(i 1) = £;(exp(i1X1)) 
= ^exp(iiXi)P(Xi = xi) 
X l 
= 2 e x P ( i i ) + 2 e xP( 2 i l) 
and 
mX2{t2) = 
E{exp{t2X2)) 
= ^exp(i2a;2)-P(^'2 = ^2) 
X2 
1 
x 
1 
/ x 
1 
= 3 exp(-i 2) + g exp(i2) + ^ 
In general we have the following result: 
Theorem 5.25 Let X = (Xi, ■ ■ ■ ,Xn) be an n-dimensional random vector. 
The joint moment generating function of X exists if and only if the marginal 
moment generating functions of the random variables Xi for i = 1,·-· ,n 
exist. 
Proof: 
==$■) Suppose initially that the joint moment generating function of X 
exists. In that case, there is a constant M > 0 such that mx(t) = 

244 
RANDOM VECTORS 
2?(exp(XtT)) < oo for all t with ||t|| < M. Then, for alii = 1,· ■ ■ ,n we 
have: 
mXi(ti) 
= 
E(exp(tiXi)) 
= £ ( β χ ρ ( Χ · · · ( 0 , 0 , · · · , 
U 
,0,···,0) Τ)) 
ith 
position 
= τ η χ ( ( 0 , · · · , ί ί , · · · , 0 ) τ ) 
< oo whenever \U\ < M . 
That is, the moment generating function of Xi for i = 1, · · ■ , n exist. 
<= ) Suppose now that the moment generating functions of the random 
variables X, for i = 1, · · · , n exist. Then, for each i — 1, · · · , n there exist 
Mi > 0 such that mx^U) 
= E(exp(tiXi)) 
< oo whenever |£j| < Mj. Let 
h : Rn —> R be defined by: 
h(t) := exp (t · a T) 
for a € Rn 
The function h so defined is convex, and consequently, if x» 6 Rn, for i — 
m 
1,··· , TO, and we choose ctj £ (0,1) for i = 1,· · · ,m such that ] ζ α ί = 1' 
i=l 
then, we must have that: 
(
m 
\ 
τη 
Σ
α*
χ«) - Σ
α*
 h(
Xi) · 
Therefore: 
exp < I Σ
α ί Xi ) aT f - Σα'exp (
Xi a T) · 
In particular, for a = X = (Χχ, · · · , Xn)i 
xt = (0, · · · , 0, 
U 
, 0, · · · , 0) and 
t 
ith 
position 
n = m, the preceding expression yields: 
{ 'YjXiUXi 
\ < ^aiexpiUXi) 
. 
i=l 
J 
t=l 
exp 
Taking expectations we get: 
E ( exp 1 Σαί li Xi f I - Σ
α ί mx< (**) · 
. t=l 
) / 
i=l 
Therefore, if for a fixed choice of a» G (0,1), i = 1, · ■ · , n, satisfying 
ΣΓ=ια» = 1) we define ft by 
R : = { u = ( i i i , - - , t i n ) e R n : tij =oiiii, with |ij| < Mi} 

JOINT PROBABILITY GENERATING, MOMENT GENERATING AND CHARACTERISTIC FUNCTIONS 
2 4 5 
then for all u 6 Tl we have 
£(exp(XuT)) < oo 
and furthermore, by taking M := min{aiMi, · · · , anMn}, 
for all t 6 K™ with 
||t|| < M we can guarantee that: 
£(exp(Xt T)) < oo . 
That is, the joint moment generating function of X exists. 
■ 
The previous theorem establishes that the joint moment generating func-
tion of the random variables Xi,··· 
,Xn, exists if and only if the marginal 
moment generating functions also exist; nevertheless, it does not say that the 
joint moment generating function can be found from the marginal distribu-
tions. That is possible if the random variables are independent, as stated in 
the following theorem: 
Theorem 5.26 Let X = (Xi, · · · ,Xn) 
be arc n-dimensional random vector. 
Suppose that for alii = 1, · · · , n there exists Mi > 0 such that: 
mXi(t) 
:= E(exp(tXi)) 
< oo if \t\ < Mi. 
// the random variables X\, ■ ■ ■ , Xn are independent, then τηχ (t) < oo for all 
t = (ti, · · · , tn) with ||t|| < M, where M := min{Mi, · · · , M n } . Moreover: 
n 
Wlx(t) = Π«ϊΧ4(*ί) · 
i=l 
Proof: We have that: 
m x(t) = £(exp(Xt T)) 
= Ehxp(f2tixM 
= E 
lf[exp{UXi)\ 
n 
= Y\E(exp(tiXi)) 
(since, X^s are independent random variables) 
t = l 
n 
= 
]\rnXi(ti). 
t = l 
Just like the one-dimensional case, the joint moment generating function 
allows us, when it exists, to find the joint moment of the random vector X 
around the origin in the following sense: 

246 
RANDOM VECTORS 
Definition 5.18 (Joint Moment) LetX. = (X\, ■ · · ,Xn) be ann-dimensional 
random vector. The joint moment of order k\,-■■ ,kn, 
with kj € N, of X 
around the point a = (αχ, · · · , an) is defined by 
i=\ 
provided that the expected value above does exist. 
The joint moment of order fci, · · · , kn of X around the origin is written 
Note 5.19 If X and Y are random variables whose expected values exist, 
then the joint moment of order 1,1 of the random vector X = (X, Y) around 
a = {EX, EY) is: 
μ η = E((X - EX){Y 
- EY)) = Cov{X, Y) . 
EXAMPLE 5.41 
Let X\ and X^ be the random vectors with joint distribution given by: 
* i \ * - a 
1 
2 
- 1 
1 
6 
1 
6 
0 
2 
6 
1 
6 
1 
0 
1 
6 
We have: 
μ'12 = 
Ε{ΧλΧ2
2) 
= ΣΣΧΙ 
X2 ^(-^l = Χ 1 ' *2 = Χ2) 
Χ\ 
ΧΊ 
5 
6 " 
On the other hand: 
mx(t) 
= - exp(<i - t2) + -z exp(2ii - t2) + - exp(ix) 
b
o
o 
+ - exp(2i!) + - exp(2i! +12) 
O 
0 

JOINT PROBABILITY GENERATING, MOMENT GENERATING AND CHARACTERISTIC FUNCTIONS 
2 4 7 
Furthermore, it can be easily verified that: 
d 3m x(ii,t 2) 
dt\dt?ßti 
(ti,t2)=(0,0) 
- exp(ii - f2) + - exp(2ij - t2) + - exp(2ii +12) 
Ό 
ά 
6 
(ti,t2)=(0,0) 
= g = μ«· 
The property observed in the last example holds in more general situations, 
as the following theorem (given without proof) states. 
Theorem 5.27 Let X = (X\, · · ■ ,Xn) 
be an n-dimensional random vector. 
Suppose that the joint moment generating function mx(t) o/X exists. Then 
the joint moments of all orders, around the origin, are finite and satisfy: 
Qki+-+k„ 
r'ki-'-kn 
fu.k\ 
mi1--- dt& 
k„ m x(t) 
(tl>-,tn) = (0,-,0) 
We end this section by presenting the definition of the joint characteristic 
function of a random vector. 
Definition 5.19 (Joint Characteristic Function) LeiX = (Xi, ■ ■ ■ ,Xn) 
be an n-dimensional random vector and t = (ti,··· ,tn) 
€ R". 
The joint 
characteristic function of a random vector X, notated as yx(t), is defined by 
¥>x(t) := E exp K)] 
where i 
1. 
Just like the univariate case, the joint characteristic function of a random 
vector always exists. Another property carried over from the one-dimensional 
case is that the joint characteristic function of a random vector completely 
characterizes the distribution of the vector. That is two random vectors X and 
Y will have the same joint distribution function if and only if they have the 
same joint characteristic function. In addition, it can be proved that successive 
differentiation of the characteristic function followed by the evaluation at the 
origin of the derivatives thus obtained yield the presented below expression 
for the joint moments, around the origin, 
_ 
1 
Mfc1...fc„ — jfci+-+fcn 
ßki+—+kn 
dt*-****® 
(ίι,···,ί„)=(0.···,0). 
whenever the moment is finite. 

248 
RANDOM VECTORS 
The proofs of these results given are beyond the scope of this text and the 
reader may refer to Hernandez (2003). 
Suppose now that X and Y are independent random variables whose mo-
ment generating functions do exist. Let Z := X + Y. Then, we have that: 
mz(t) 
= 
E{exptZ) 
= E(exp {tX + tY)) 
= £J(exp(iX)exp(iy)) 
= 
E(exp{tX))E(exp(tY)) 
= 
mx(t)mY(t). 
That is, the moment generating function of Z exists and it is equal to the 
product of the moment generating functions of X and Y. 
In general we have that: 
Note 5.20 IfXi, ■ ■ ■ , Xn are n independent random variables whose moment 
generating functions do exist, then the moment generating function of the 
random variable Z := Χ\Λ 
V Xn also exists and equals the product of the 
moment generating functions of X\,· ■■ ,Xn. 
A similar result holds for the 
characteristic functions and for the probability generating functions. 
EXAMPLE 5.42 
Let Xi, Χ2, ■ ■ ■ , Xn be n independent and identically distributed random 
variables having an exponential distribution of parameter λ > 0. Then 
Z := X\ + ■ ■ ■ + Xn has a gamma distribution of parameters n and λ. 
Indeed, the moment generating function of Z := X\ H 
+ Xn is given 
by 
mz(t) 
= 
E(exptZ) 
n 
= Y[E(exptXk) 
fc=l 
ΙΝΪΓΪ) 
'»<* 
fc=l 
λ - ί 
if t < X, 
which corresponds to the moment generating function of a gamma dis-
tributed random variable of parameters n and λ. 
A 

JOINT PROBABILITY GENERATING, MOMENT GENERATING AND CHARACTERISTIC FUNCTIONS 
2 4 9 
■ EXAMPLE 5.43 
Suppose you participate in a chess tournament in which you play n 
games. Since you are an average player, each game is equally likely to 
be a win, a loss or a tie. You collect 2 points for each win, 1 point 
for each tie and 0 points for each loss. The outcome of each game is 
independent of the outcome of every other game. Let Χχ be the number 
of points you earn for game i and let Y equal the total number of points 
earned over the n games. Find the moment generating function τηχί (s) 
and my(s). Also, find E(Y) and 
Var(Y). 
Solution: The probability distribution of Xi is: 
| Xi 
1 ° 
| i 
1 2 
1 ΡχΛ*) 1 
1 1 1 
1 
3" 1 
1 
1 
1 
1 
3 
1 
So the moment generating function of Xi is: 
mXi(s) 
= ±(l + e° + e2a). 
Since it is identical for all i, we refer to it as mx(s). 
The mgf of Y is: 
mY(s) 
= (Mx(s))n 
= -^(1 + es + e 2 s) n . 
Further: 
E{Y) = n, Var(Y) = \n . 
A 
ό 
■ EXAMPLE 5.44 
Let Xi, X2, ■ · · ,Xn be n independent and identically distributed ran-
dom variables having a standard normal distribution and let: 
Z:=X\ + --- + Xl. 
It is known that if a random variable has a standard normal distribution, 
then its square has a chi-squared distribution with one degree of freedom. 

250 
RANDOM VECTORS 
Therefore, the moment generating function of Z is given by 
n 
mz{t) 
= 
J\mXk{t) 
that is, Z = X*n) . 
A 
EXAMPLE 5.45 
Let Xi, X2, ■ ■ · , Xn be n independent random variables. Suppose that 
Xk = Λ/"(μ&, σ2.) for each fc = 1, · · · , n. Let c*i, · · · , α„ b e n real con-
stants. Then the moment generating function of the random variable 
Z := ctiX\ + 
h anXn is given by: 
mz(t) = E (expt 
(j^akXkj) 
= E i j ] exp(iafcXfe) J 
n 
= 
Y[E(exp{takXk)) 
n 
fe=l 
= Πexp (
tctktik + a
2
fc σΐ) 
(
n 
t2 n 
\ 
t*T (akßk) + — Σ 
(.(XkOkf I · 
fc=l 
fc=l 
/ 
d 
n 
n 
1 
Hence, Z =Αί(μ,σ2), 
where μ := Σ (akßk) anda 2 := Σ (ctkVk) · A 
fc=l fc=l 

EXERCISES 
251 
EXAMPLE 5.46 
Let Χι, Χ2, ■ ■ ■ ,Xn be n independent and identically distributed ran-
dom variables having a normal distribution of parameters μ and σ2. The 
random variable X defined by 
X 
1 
n 
:= ±Σ> 
has a normal distribution with parameters μ and ^-. Consequently: 
ΣΧί 
~ημ 
i = 1 
-1Λ/"(Ο,Ι). 
A 
Oy/n 
EXERCISES 
5.1 
Determine the constant h for which the following gives a joint proba-
bility mass function for {X, Y): 
ppr = x,y = v) = j £ 
x + l)(y + l)h 
if a; = 0,1,2; » = 0,1,2,3 
otherwise . 
Also evaluate the following probabilities: 
a) P{X < 1, Y < 1) b) P(X + r < 1) c) P(XY 
> 0). 
5.2 
Suppose that in a central electrical system there are 15 devices of which 
5 are new, 4 are between 1 and 2 years of use and 6 are in poor condition and 
should be replaced. Three devices are chosen randomly without replacement. 
If X represents the number of new devices and Y represents the number of 
devices with 1 to 2 years of use in the chosen devices, then find the joint 
probability distribution of X and Y. Also, find the marginal distributions of 
X a n d F . 
5.3 
Prove that the function 
0 
x < 0 o r y < 0 
F(x,y) — { x + y 
x + y < l,x >0,y 
> 0 
1 
x + y > l , x > 0 , 2 / > 0 
has the properties 1, 2, 3 and 4 of Theorem 5.3 but it is not a cdf. 
5.4 
Let (X, Y) a random vector with joint pdf 
3(x 2+j/ 2) 
i f 0 < x < l , 0 < j / < l 
fix,y) 
I 0 
otherwise. 

252 
RANDOM VECTORS 
Show that the cdf is: 
F{x,y) = < 
0 
x < 0 or y < 0 
±(x3y + xy3) 
0<x<l,0<y<l 
±(x3+x) 
0<x<l,y>l 
^(y + y3) 
o<y<i,x>i 
i 
χ> i,v> 
i · 
f(XuX2)(Xl,X2) 
f 4a 
5.5 
Let X\ and X2 be two continuous random variables with joint proba-
bility density function 
4xiX2 
if 0 < xi < 1,0 < X2 < 1 
otherwise . 
Find the joint probability density function of Yi = X2 and Y2 = XiX2-
5.6 
(BufFon Needle Problem) Parallel straight lines are drawn on the 
plane R2 at a distance d from each other. A needle of length L is dropped at 
random on the plane. What is the probability that the needle shall meet at 
least one of the lines? 
5.7 
Let A, B and C be independent random variables each uniformly dis-
tributed on (0,1). What is the probability that Ax2 + Bx + C = 0 has real 
roots? 
5.8 
Suppose that a two-dimensional random variable (X, Y) has joint prob-
ability density function 
f 
„-(*+t/)_8 4 
r-*- 
if 0 < x < o o , 0 < i / < o o 
otherwise . 
fx,Y(x,v) 
= < 0
 
8!4! 
a) Find the pdf of U = £ . 
b) Find E{U). 
5.9 
Suppose that the joint distribution of the random variables X and Y is 
given by: 
X\Y 
1
2 
3 
4 
0 
0.1 
0 
0 
0 
- 1 
0.1 
0.1 
0 
0 
- 2 
0.1 
0.1 
0.1 
0 
0.1 
0.1 
0.1 
0.1 

EXERCISES 
253 
Calculate: 
a) P{X>-2,Y 
>2). 
b) P{X>-2 
or Y >2). 
c) The marginal distributions of X and Y. 
d) The distribution of Z := X + Y. 
5.10 
Suppose that two cards are drawn at random from a deck of cards. 
Let X be the number of aces obtained and Y be the number of queens ob-
tained. Find the joint probability mass function of (X, Y). Also find their 
joint distribution function. 
5.11 
Assume that X and Y are random variables with the following joint 
distribution: 
X\Y 
0 
1
2 
1 
0.2 
a 
ß 
2 
7 
0.1 
5 
3 
η 
κ 
0.3 
Find the values of a, β, η, δ, η and κ, so that the conditions below will hold: 
P(X = l) = 0.51, P(X = 2) = 0.22, P(Y = 0) = 0.33 andP(Y = 2) = 0.62 . 
5.12 
An urn contains 11 balls, 4 of them are red-colored, 5 are black-colored 
and 2 are blue-colored. Two balls are randomly extracted from the urn with-
out replacement. Let X and Y be the random variables representing the 
number of red-colored and black-colored balls, respectively, in the sample. 
Find: 
a) The joint distribution of X and Y. 
b) E(X) and E(Y). 
5.13 
Solve the previous exercise under the assumption that the extraction 
takes place with replacement. 
5.14 
Let X, Y and Z be the random variables with joint distribution given 
by: 
x = (x,y,z) 
(1,2,3) 
(2,1,3) 
(3,2,1) 
(1,3,2) 
(3,1,2) 
(2,3,1) 
P r X - v " » 
i 
i 
i 
i 
i 
i 
^ v - ^ - · ^ / 
6 
6 
6 
6 
6 
6 

254 
RANDOM VECTORS 
Find: 
a) E(X + Y + Z). 
b) 
E(XYZ). 
5.15 
(Multinomial Distribution) Suppose that there are fc + l different 
results of a random experiment and that pt is the probability of obtaining 
fc+l 
the ith result for i = 1, · · · , fc + 1 (note that Σ,Ρί 
= !)■ Let Xi be the 
t = l 
number of times the ith result is obtained after n independent repetitions of 
the experiment. Verify that the joint density function of the random variables 
Xi,··· 
,Xk+i is given by 
/ ( X l , · · · ,Xfc+l) = 
n! 
fc+l 
fc+l 
i=l 
IR 
where Xi = 0, ■ 
fc+l 
, n and Σ x» = n-
i=l 
5.16 
Surgeries scheduled in a hospital are classified into 4 categories ac-
cording to their priority as follows: "urgent", "top priority", "low priority" 
and "on hold". The hospital board estimates that 10% of the surgeries belong 
to the first category, 50% to the second one, 30% to the third one and the 
remaining 10% to the fourth one. Suppose that 30 surgeries are programmed 
in a month. Find: 
a) The probability that 5 of the surgeries are classified in the first category, 
15 in the second, 7 in the third and 3 in the fourth. 
b) The expected number of surgeries of the third category. 
5.17 
Let X and Y be independent random variables having the joint dis-
tribution given by the following table: 
X\Y 
0 
1 
2 
- 1 
1 
6 
a 
b 
0 
d 
e 
/ 
1 
1 
6 
k 
h 
If P(X = 1) = P(X = 2) = ^ find the values missing from the table. Calcu-
late 
E(XY). 

EXERCISES 
255 
5.18 
A bakery sells an average of 1.3 doughnuts per hour, 0.6 bagels per 
hour and 2.8 cupcakes per hour. Assume that the quantities sold of each 
product are independent and that they follow a Poisson distribution. Find: 
a) The distribution of the total number of doughnuts, bagels and cupcakes 
sold in 2 hours. 
b) The probability that at least two of the products are sold in a 15-minutes 
period. 
5.19 
Let X and Y be random variables with joint distribution given by: 
X\Y 
0 
1 
2 
- 1 
1 
16 
3 
16 
1 
16 
0 
1 
4 
1 
8 
1 
16 
1 
0 
3 
16 
1 
16 
Find the joint distribution of Z := X + Y and W := X - Y. 
5.20 
Let X and Y be discrete random variables having the following joint 
distribution: 
X\Y 
1 
2 
3 
- 1 
1 
18 
1 
9 
0 
0 
3 
18 
0 
2 
9 
2 
1 
9 
1 
6 
1 
6 
Compute Cov(X,Y) 
and 
p{X,Y). 
5.21 
Suppose X has a uniform distribution on the interval (—π, π). Define 
Y = cos X. Show that Cov(X, Y) = 0 though X, Y are dependent. 
5.22 
An urn contains 3 red-colored and 2 black-colored balls. A sample of 
size 2 is drawn without replacement. Let X and Y be the numbers of red-
colored and black-colored balls, respectively, in the sample. Find p(X, Y). 
5.23 
Let X and Y be independent random variables with X = B (3, 5) and 
Y = B (2, \). Calculate P(X = Y). 
5.24 
Let Xi,X2i ■ ■ ■ ^ 5 be i.i.d. random variables with uniform distribu-
tion on the interval (0,1). 

256 
RANDOM VECTORS 
a) Find the probability that min(Xi,X2, · · · ,X5) lies between (\, | ) . 
b) Find the probability that X\ is the minimum and X5 is the maximum 
among these random variables. 
5.25 
Let X and Y be independent random variables having Bernoulli distri-
butions with parameter | . Are Z := X + Y and W :— \X — Y\ independent? 
Explain. 
5.26 
Consider an "experiment" of placing three balls into three cells. De-
scribe the sample space of the experiment. Define the random variables 
N 
= 
number of occupied cells 
Xi 
= 
number of balls in cell number i (i = 1,2,3). 
a) Find the joint probability distribution of 
(Ν,Χχ). 
b) Find the joint probability distribution of ( Χ χ , ^ ) · 
c) W h a t i s C o t ^ X i ) ? 
d) WhatisC<w(Xi,X2)? 
5.27 
Let Χι, Χ2 and X3 be independent random variables with finite posi-
tive variances σ\, σ\ and σ|, respectively. Calculate the correlation coefficient 
between X\ — X2 and X2+ 
X3. 
5.28 
Let X and Y be two random variables such that p(X, Y) = | , Var(X) 
= 
1 and Var(Y) = 2. Compute Var(X - 2Y). 
5.29 
Given the uncorrelated random variable X\,X2,X$ 
whose means are 
2, 1 and 4 and whose variances are 9, 20 and 12: 
a) Find the mean and the variance of Xi — 2X<i + 6X3. 
b) Find the covariance between X\ + 5X2 and 2X2 — X3 + 5. 
5.30 
Let X, Y, Z be i.i.d. random variables each having uniform distribution 
in the interval (1,2). Find Var ( | f + | | ) . 
5.31 
Let X and Y be independent random variables. Assume that both 
variables take the values 1 and —1 each with probability \. Let Z := XY. Are 
X, Y and Z pair-wise independent? Are X, Y and Z independent? Explain. 
5.32 
A certain lottery prints n > 2 lottery tickets m of which are sold. 
Suppose that the tickets are numbered from 1 to n and that they all have the 
same "chance" of being sold. Calculate the expected value and the variance 
of the random variable representing the sum of the numbers of the lottery 
tickets sold. 

EXERCISES 
257 
5.33 
What is the expected number of days of the year for which exactly k 
of r people celebrate their birthday on that day? Suppose that each of the 
365 days is just as likely to be the birthday of someone and ignore leap years. 
5.34 
Under the same assumptions given in problem 5.33, what is the ex-
pected number of days of the year for which there is more than one birthday? 
Verify with a calculator that this expected number is, for all r > 29, greater 
than 1. 
5.35 
Let X and Y be random variables with mean 0, variance 1 and corre-
lation coefficient p. Prove that: 
E (max {X2, Y2}) < 1 + y/l - p2 . 
Hint: max{u,v} 
= | (u + v) + \ \u — v\. Use Cauchy-Schwarz inequality. 
5.36 
Let X and Y be random variables with mean 0, variance 1 and corre-
lation coefficient p. 
a) Show that the random variables Z := X — pY and Y are not correlated. 
b) Compute E(Z) and 
Var(Z). 
5.37 
Let X, Y and Z be random variables with mean 0 and variance 1. Let 
pi := p(X, Y), p2 := p{Y, Z) and p3 := p(X, Z). Prove that: 
ΡΆ > P1P2 ~ y 1 - Pi \j 1 - p\ ■ 
Hint: 
XZ = [PlY + (X - PlY)\ [frY + (Z- 
p2Y)). 
5.38 
Let X = U (0,1) and Y = X2. 
a) Find 
p{X,Y). 
b) Are X and Y independent? Explain. 
5.39 
Let X and Y be random variables with joint probability density func-
tion given by: 
s_jc 
i f 0 < x < 4 , 0<y 
and (x - 1) < y < (x +. 1) 
1 0 otherwise . 
a) Find the value of the constant c. 
b) Compute P (X < ±, Y < ±) and P (X < §). 
c) Calculate E{X) and 
E(Y). 

258 
RANDOM VECTORS 
5.40 
Ten costumers, among them John and Amanda, arrive at a store be-
tween 8:00 AM and noon. Assuming that the clients arrive independently 
and that the arrival time of each of them is a random variable with uniform 
distribution on the interval [0,4]. Find: 
a) The probability that John arrives before 11:00 AM. 
b) The probability that John and Amanda both arrive before 11:00 AM. 
c) The expected number of clients arriving before 11:00 AM. 
5.41 
Let X and Y be random variables with joint cumulative distribution 
function given by: 
{! 
F ( X i 2 / ) = ; ( 1 - e x P ( - a ; ) ) ( i + itan"12/) 
if *>0 
n 
otherwise . 
Does a joint probability density function of X and Y exist? Explain. 
5.42 
Let X and Y be random variables having the following joint probability 
density function: 
i,y) = {o 
sin (x + y) 
if 0 < x, y < ^ 
I 0 
otherwise . 
Compute: 
a) The value of the constant c. 
b) The marginal density functions of X and Y. 
5.43 
Let X and Y be random variables with joint probability density func-
tion given by: 
if 0 < a; < 1, 
Ky 
otherwise . 
Find: 
a) 
b) 
p(h 
P(Y 
<X < 
>5). 
/ (χ, y) = < 
f, o<y< 
I F 
1° 
§)■ 
5.44 
Andrew and Sandra agreed to meet between 7:00 PM and 8:00 PM 
in a restaurant. Let X be the random variable representing the arrival time 
(in minutes) of Andrew and let Y be the random variable representing the 
arrival time (in minutes) of Sandra. Suppose that X and Y are independent 
and identically distributed with a uniform distribution over [7,8]. 

EXERCISES 
259 
a) Find the joint probability density function of X and Y. 
b) Calculate the probability that both Andrew and Sandra arrive at the 
restaurant between 7:15 PM and 8:15 PM. 
c) If the first one waits only 10 minutes before leaving and eating else-
where, what is the probability that both Sandra and Andrew eat at the 
restaurant initially chosen? 
5.45 
The two-dimensional random variable (X, Y) has the following joint 
probability density function: 
1 
_ Ι Λ Ί - » ) ' + ( ' ^ ) ' ] 
f{ti,t2) 
= τ^-e 
2V 
" 
/ , -oo < ίι,ί 2 < oo. 
Ιοπ 
Find: 
a) The marginal density functions fx and fy. 
b) E{X) and E{Y). 
c) Var(X) and 
Var(Y). 
d) Cov(X,Y) 
andp(X,Y). 
5.46 
Let (X, Y) be the coordinates of a point randomly chosen from the 
unit disk. That is, X and Y are random variables with joint probability 
density function given by: 
z,y) = < π 
yJ 
[0 otl 
i, 
N 
i *· 
- 
0 < x 2 + j/
2 < 1 
otherwise . 
Compute P(X < Y). 
5.47 
A point Q with coordinates (X, Y) is randomly chosen from the square 
[0,1] x [0,1]. Find the probability that (0,0) is closer to Q than (5,5). 
5.48 
Let X and Y be independent random variables with X = U (0,1) and 
Y=U(0,2). 
Calculate: 
a) P([X + 
Y]>1). 
b) P(Y<X2 
+ 1). 
5.49 
Let X and Y be independent and identically distributed random vari-
ables having a uniform distribution over the interval (0,1). Compute: 
a) 
P(\X-Y\<\). 

260 
RANDOM VECTORS 
b ) P ( | * - l | < i ) · 
c) 
P(Y<X\X<±). 
5.50 
Let X and Y be random variables having the following joint probability 
density function: 
f/x 
) = i e xp[-(^ + y)] if χ>ο, y>o 
Ί 0 
otherwise . 
Calculate: 
a) P(±<X 
+ 
Y<5). 
b) P{X <Y + 
3\X>2Y). 
c ) P ( Y > ± ) . 
5.51 
A certain device has two components and if one of them fails the 
device will stop working. The joint pdf of the lifetime of the two components 
(measured in hours) is given by: 
f ( x v ) - i 
Ψ 
if 
0 < x < 3 , 0 < j / < 3 
nx,V)-\ 0 
otherwise. 
Compute the probability that the device fails during the first operation hour. 
5.52 
Let X and Y be independent random variables. Assume that X has 
an exponential distribution with parameter λ and that Y has the density 
function given by / (x) = 2xX^^) 
(x). 
a) Find a density function for Z := X + Y. 
b) Calculate Cov 
{X,Z). 
5.53 
Prove or disprove: If X and Y are random variables such that the char-
acteristic function of X + Y equals the product of the characteristic functions 
of X and Y, then X and Y are independent. Justify your answer. 
5.54 
Let X\ and X2 be two identical random variables which are binomial 
distributed with parameters n and p. Find the Cov{X\ — X2,X\ + ΧΊ)· 
5.55 
Let X and Y be independent and identically distributed random vari-
ables having an exponential distribution with parameter λ. Find the density 
functions of the following random variables: 
a) 
Z:=\X-Y\. 
b) 
W:=min{X,Y3}. 

EXERCISES 
261 
5.56 
Let X, Y and Z be independent and identically distributed random 
variables having a uniform distribution over the interval [0,1]. 
a) Find the joint density function of W := XY and V := Z2. 
b) Calculate P(V 
<W). 
5.57 
Let X and Y be independent and identically distributed random vari-
ables having a standard normal distribution. Let Y\ = X + Y and Y^ — X/Y. 
Find the joint probability density function of the random variables Y\ and Y^. 
What kind of distribution does Y2 have? 
5.58 
Let X and Y be random variables having the following joint probability 
density function: 
ί \xy 
if x > 0 y > 0 and x + y < 2 
f(x,y) = \ 10 
otherwise . 
Find the joint probability density function of X2 and Y2. 
5.59 
Let X and Y be random variables having the joint probability density 
function given below: 
[cx2y2 
if 0 < x < 1 and 0 < y < 1 
f(x,y) 
= < 10 
otherwise . 
Calculate the constant c. Find the joint probability density function of X3 
andF 3. 
5.60 
Let X\ < X2 < X3 be ordered observations of a random sample of 
size 3 from a distribution with pdf 
,, , _ f 2x 
if 0 < x < 1 
^ 
\ 0 
otherwise . 
Show that Y\ = Xi/X2, Yi = X2/X3 and Y3 = X3 are independent. 
5.61 
Let X, Y and Z be random variables having the following joint prob-
ability density function: 
if x > 0, y > 0, z > 0 
f(x,y,z)= 
. 
otherwise 
Find /t/, where 1/ := x+%"+z. 
5.62 
Let X and Y be random variables with joint probability density func-
tion given by: 
ίψ 
i f 0 < x < l and - x < y < x 
f(x,y) 
= < 0 
otherwise . 

262 
RANDOM VECTORS 
Find fz, where Z = X - Y. 
5.63 
Suppose that X = F™. Find the value x for which: 
a) P{X <x) = 0.99 with m = 7, n = 3. 
b) P(X <x)= 
0.005 with m = 20, n = 30. 
c) P{X <x) = 0.95 with m = 2, n = 9. 
5.64 
If X = tn, what kind of distribution does X2 have? 
5.65 
Prove that, if X = F™, then E(X) = ^ _ forn > 2 and 
Var(X) = 
2" 2 ( mt"~ 2 ) 
νατ\Λ) 
- 
m ( n_2)2( n_4)· 
i/ini: Suppose that X = ^ 7 , where U and V are independent, U = Λ^ and 
V i Λ"2. 
V/n ' 
5.66 
Let X be a random variable having a i-Student distribution with k 
degrees of freedom. Compute E(X) and 
Var(X). 
5.67 
Let X be a random variable having a standard normal distribution. 
Are X and \X\ independent? Are they not correlated? Explain. 
5.68 
Let X be an n-dimensional random vector with variance-covariance 
matrix ]T. Let A be a nonsingular square matrix of order n and let Y := X A 
a) Prove that E(Y)=E 
(X) A. 
b) Compute the variance-covariance matrix of Y. 
5.69 
If the Yi's, i = 1, · · · ,n, are independent and identically distributed 
continuous random variables with probability density /(j/i), then prove that 
the joint density of the order statistics Y(i),Y(2), ··· , Y(n) ls: 
n 
f(yi, V2, · ■ ■, yn) = n! Yl f{yi), 
2/1 < V2 < ■ ■ ■ < yn-
i=l 
Also, if the Yi, i = 1, · · · , n, are uniformly distributed over (0, t), then prove 
that the joint density of the order statistics is: 
/(yi,i/2,··· ,yn) = —, 
yi<V2<--<yn-
5.70 
Let X and Y be independent random variables with moment generat-
ing functions given by: 
mx (t) = exp (2e* - 2) 
and 
mY (t) = - (l + 2e _ t + 2e') . 

EXERCISES 
263 
Find: 
a) P([X + 
Y]=2). 
b) 
E{XY). 
5.71 
Let Χχ,Χζ,··· 
,Χη be i.i.d. random variables with a Λί(μ,σ2) 
dis-
tribution. What kind of distribution do the random variables defined by 
Zi := Z±f±, for i = 1,2, · · · , n, have? What is the distribution of Z2+- ■ -+Z%? 
5.72 
Let Χχ,Χϊ, ■ ■ ■ , Xn be i.i.d. random variables with a Μ(μ,σ2) 
distri-
bution. Let 
i = l 
where: 
1 
n 
X :=-£>. 
t = l 
What kind of distribution does ^n~Ji— have? Explain. 
5.73 
The tensile strength for a certain kind of wire has a normal distri-
bution with unknown mean μ and unknown variance σ2. Six wire sections 
were randomly cut from an industrial roll. Consider the random variables 
Yi :— "tensile strength of the ith segment" for i = 1,2, · · · ,6. The population 
mean μ and variance σ2 can be estimated by Y and S2, respectively. Find 
the probability that Y is at most at a ^ 
distance from the real population 
mean μ. 
5.74 
Let X\,X2, 
■ · ■ , Xn be i.i.d. random variables with a Αί(μ,σ2) 
distri-
bution. What kind of distribution does the following random variable have: 
^η(η-1)(Χ-μ) 
? 
Explain. 

CHAPTER 6 
CONDITIONAL EXPECTATION 
One of the most important and useful concepts of probability theory is the 
conditional expected value. The reason for it is twofold: in the first place, 
in practice usually it is interesting to calculate probabilities and expected 
values when some partial information is already known. On the other hand, 
when one wants to find a probability or an expected value, many times it is 
convenient to condition first with respect to an appropriate random variable. 
6.1 
CONDITIONAL DISTRIBUTION 
The relationship between two random variables can be seen by finding the 
conditional distribution of one of them given the value of the other. In Chapter 
1, we defined the conditional probability of an event A given another event B 
as: 
P(A | B) := ^ P - , 
P(B) > 0 . 
It is natural, then, to have the following definition: 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
265 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

266 
CONDITIONAL EXPECTATION 
Definition 6.1 (Conditional Probability Mass Function) LetX 
andY 
be two discrete random variables. The conditional probability mass function 
of X given Y = y is defined as 
Px\y (x\y):=P(X 
= x\Y 
= y) = P{ ρ^}
= 
V) 
for all y for which P (Y = y) > 0. 
Definition 6.2 (Conditional Distribution Function) The conditional dis-
tribution function of X given Y = y is defined as 
FX[Y (x\y)~P(X<x\Y 
= y) = J > x | y (* I v) 
k<x 
for all y for which P(Y = y) > 0. 
Definition 6.3 (Conditional Expectation) The conditional expectation of 
X given Y = y is defined as: 
Ε{Χ\Υ 
= ν):=ΣχρΧ\Υ{χ\ν) 
. 
X 
The quantity E(X \ Y = y) is called the regression of X onY = y. 
■ EXAMPLE 6.1 
A box contains five red balls and three green ones. A random sample of 
size 2 (without replacement) is drawn from the box. Let: 
. ^ J the first ball taken out is red 
" 
'" the first ball taken out is green 
r i 
if i 
\ 0 if i 
_ r i 
if i 
: _ \ 0 
if' 
v 
. ^ .x the second ball taken out is red 
" 
" the second ball taken out is green . 
The joint probability distribution of the random variables X and Y is 
given by: 
| x\Y 
| o | l | 

CONDITIONAL DISTRIBUTION 
267 
Hence: 
PX\Y(X 
1 0) = < 
PX\Y(X 
1 1) = < 
FX\Y(X 
1 0) = < 
E{X\Y 
= y) = l[ 
f -$-
21 
15 
> 
2 1 
ί ^ 
I * 
' 0 
6 
21 
. 1 
' 
15 
Γ 
if 
if 
if 
if 
if 
if 
if 
if 
if 
x = 0 
x = l 
x = 0 
x = l 
x < 0 
0 < x < 1 
x > 1 
y = 0 
y = \ . 
EXAMPLE 6.2 
Let X and Y be independent Poisson random variables with parameters 
λι and Ä2, respectively. Calculate the expected value of X under the 
condition that X + Y = n, where n is a nonnegative fixed integer. 
Solution: Let: 
Px\x+Y (x \ n) = P (X = x \ X + Y = n) 
P(X = x,Y = n - x) 
P(X + Y = n) 
\x) \\ι+\2) 
νλι + λ2; 
That is, X has, under the condition X + Y = n, a binomial distribution 
with parameters n and p :— Λ *'Λ . Therefore: 
ΕίΧ\Χ 
+ Υ = η)=η(^). 
A 
Definition 6.4 (Conditional Probability Density Function) LetX and 
Y be continuous random variables with joint probability density function 
f. 
The conditional probability density function of X given Y = y is defined as 
fx\Y (x I V) ■= f(*,y) 
My) 
for all y with fy(y) > 0. 

268 
CONDITIONAL EXPECTATION 
Definition 6.5 (Conditional Distribution Function) The conditional dis-
tribution function of X given Y = y is defined as 
FX\Y (x\y):=P(X<x\Y 
= y)= 
[ 
fX\Y 
(t \ y)dt 
J — CO 
for all y with fy (y) > 0. 
Definition 6.6 (Conditional Expectation) The conditional expectation of 
X given Y = y is defined as 
/
oo 
xfx\Y{x\y)dx 
-oo 
for all y with fy(y) > 0. 
EXAMPLE 6.3 
Let X and Y be random variables with joint probability density function 
given by: 
/ / 
\ - i
x 
+ V i f 0 < x < l , 
0 < J / < 1 
J(x,V)-\ 
0 
other cases. 
For 0 < y < 1 we can obtain that: 
(x|v) = ( 0-' 
I o 
, 
, , , 
, Ä 
if 
0 < x < l 
fx\Y {* " 
other cases 
FX\Y 
(x I y) = < 
0 
if x < 0 
^ ( 4 + x y ) 
if 0<X<1 
{ 1 
if x > 1 
EXAMPLE 6.4 
Let X and Y be random variables with joint probability density function 
given by 
,, 
, 
ί X2e~Xy if 0 < x < y 
f{x,v) = < 0 
other cases 

CONDITIONAL DISTRIBUTION 
269 
where λ > 0. For y > 0 we obtain: 
0 < x < 
j i » 
{ 0 
otl 
fx\Y 
{x\y) 
other cases 
f 
if 
0 < x < y 
^x-|y (x | y) = < 
1/ 
1 
if x > 0, x > y 
0 
other cases 
£ ( Χ | Υ = 2/) = | . 
A 
EXAMPLE 6.5 
Let X and Y be random variables with joint probability density function 
given by: 
,, 
x _ / 6 - a; - y if 0 < x < 2 and 2 < y < 4 
other cases. 
Calculate fx\Y(x 
\ y) and E{X \Y = y). 
Solution: The marginal density function of Y is equal to: 
/
oo 
f(x,y)dx 
-oo 
f2 
= / (§ - x - y)X{2A){y)dx 
Jo 
= 
(lO-2y)X{2A)(y). 
Then, for 2 < y < 4, we obtain that: 
fx\Y (x\y)= 
( I Q ! 2 / ) 
^
0 ·
2 ^ 
/
OO 
*/x|y(* I w)dc 
-oo 
J0 
\l0-2y) 
_ 
28-6y 
~ 3 ( 1 0 - 2 y ) " 
A 

270 
CONDITIONAL EXPECTATION 
Note 6.1 For all y, with fy(y) > 0 and all Borel set A in R, it can be said 
that: 
P(X€A\Y 
= y) = J fxlY(x 
| y)dx . 
■ EXAMPLE 6.6 
If X and Y are random variables with joint probability density function 
given by 
f{x,y) 
= 
«*(0,oo)0»0<*'(0,oo)(i/)i 
then P{X > 1 | Y = §) = e~2. 
▲ 
Note 6.2 If X and Y are independent random variables, then the conditional 
density of X given Y = y is equal to the density of X. 
Note 6.3 (Bayes' Rule) 
ίχ\γ(χ\ν) = ψτΙ 
iffv(y)>o. 
As f{x,y) = fx(x)fY\x(y 
\ x) and fY(y) 
= J^°oof(x,y)dx, 
then 
fx(x)fY\x(y 
I a) 
fx\r(x 
I y) = !_00fx{x)fY\x{y\x)dx 
So far we have defined the conditional distributions when both the random 
variables under consideration are either discrete or continuous. Suppose now 
that X is an absolutely continuous random variable and that N is a discrete 
random variable. In this case: 
, 
, , , 
,. 
P{x < X < x + Ax | N = n) 
fxlN(x 
| „) = Ahmo 
— 
P(N = n\x 
<X <x + Ax) P{x < X < x + Ax) 
— i i m 
—,-- 
^ 
1 
Δχ->ο 
P(N = n) 
Δχ 
P(N = n\X 
= x) 
P(N = n) 
-fx(x) ■ 
EXAMPLE 6.7 
Let X be a random variable with uniform distribution over the interval 
(0,1) and N, a binomial random variable with parameters n + m and 

CONDITIONAL DISTRIBUTION 
2 7 1 
X. Then, for 0 < x < 1, we have that 
P(JV = n | X = s ) , 
-p(N 
= n)X(1 
X) 
= Cxn(l - 
x)m 
where C = Pi^=n) 
(""£m) · That is, under the condition N = n, X has 
a beta distribution with parameters n + 1 and m + 1. 
▲ 
EXAMPLE 6.8 
Let Y be a Poisson random variable with parameter Λ, where the pa-
rameter Λ itself is distributed as Γ(α, β). Calculate f\\y(X 
\ y). 
Solution: It is known that: 
0 
other cases . 
Then: 
Given that: 
/(A,y)=iV| A(y|A)/ A(A) 
f / A ( A ) ^ 
if y = 0,i,·· 
I 0 
other cases . 
^A"- 1exp(-A^) 
/A (A) = 
ρ ^ 
<*(0,oo)(A) 
it is obtained that: 
PY(V)= 
Λ- -■ 
^-*-y 
- ^ / ^ _ r _ d A 
Jo 
r00 ^ Λ " - 1 exp(-Aft) A*e~A 
/o 
Γ(α) 
y! 
/?' - r / 
A04*"1 exp(-A(/3 + 
l))d\ 
<*) Jo 
wire 
/3"Γ(α + y) 
y!(/3 + l) Q + IT(a) " 

272 
CONDITIONAL EXPECTATION 
Consequently, for λ > 0 and y a nonnegative integer: 
/A,y(A I y) = 
^ 
1 
pv(y) 
_ ßa\a+y-ly\{ß 
+ 1)α+3Τ(α) exp(-A(j3 + 1)) 
y\ß*Tia)T{a 
+ y) 
_(ß 
+ l)a+y 
λ"^-1 
exp(-AQ3 + 1)) 
Γ(α + y) 
That is, under the condition Y = y, Λ has a gamma distribution with 
parameters a + y and β + 1. 
▲ 
Definition 6.7 Let X and Y be real random variables and h a real function 
such that h(X) is a random variable. Define 
E(h(X) \Y = y):={ 
YJi{x)P(X = x | Y = y) 
if X and Y are discrete 
X 
random variables 
f^° 
h(x)fx\y(x 
| y)dx 
if X and Y are continuous 
random variables 
for all values y ofY for which P{Y = y) > 0 in the discrete case and fy(y) > 
0 in the continuous case. 
EXAMPLE 6.9 
Let X and Y be random variables with joint probability density function 
given by: 
t,V) = \ 
a 
N 
J exp(_2/) 
if 
x > °; y > x 
f(x,y) = { 
0 
other cases . 
We have that: 
/
oo 
/(x,y)dx 
-OO 
ΛΟΟ 
= / 
βχρ(-2/)Λ(ο,οο)(ί/)<ώ; 
Jo 
= ye vX(o,oo){y) ■ 
Therefore, for y > 0, we have: 
fx\y(x 
I y) = -X(p,y){x) ■ 

CONDITIONAL DISTRIBUTION 
273 
Now, it can be deduced that: 
E (exp ( γ ) I ^ = l ) = f ° exp ( | ) fx\Y(x 
\ l)dx 
= ^ 
exp ( | ) dx 
= 2 . 
A 
Prom the previous definition, a new random variable can be defined as follows: 
Definition 6.8 (Conditional Expectation) Let X and Y be real random 
variables defined over (Ω, 9, P) and h a real-valued function such that h(X) 
is a random variable. The random variable E(h(X) 
\ Y) defined by 
E(h(X) 
| Y) : Ω —► 
R 
ω 
»—> E{h(X) 
| Y = Υ{ω)) 
is called the conditional expected value of h(X) given Y. 
■ EXAMPLE 6.10 
Let Ω = {a,b,c}, 
3 = ρ(Ω) and Ρ[ω) = | for all ω € Ω. 
Consider the random variables X and Y defined as follows: 
Χ(ω) 
( 1 if ω = a, I 
\ 0 if ui = c 
Then: 
π 
if ω = ο 
* » = <{ i 
if 
ω = 6 
— 1 if ω = c . 
Ε(Χ\Υ 
= π) 
if w = a 
E(X | Y) = { E{X \Y = \) 
if ω = 6 
£ p f j y = -1) 
if ω = c . 
It is obtained that: 
£(X | y = π) = ΣχΡ(Χ 
= χ\Υ = ν) 
X 
= P(X = 1 I r = π) 
Ρ(Χ = ί,Υ = π) 
P(Y = π) 
= Ρ(α) = Ί 

274 
CONDITIONAL EXPECTATION 
In the same way, it can be verified that: 
*("-s)-l-' 
Then: 
*vm-{l Hz? 
It may be observed, additionally, that: 
E (E(x 
| Y)) = ΣΕ(Χ 
IY = y)P(Y = y) 
E(X) . 
▲ 
v 
2 
3 = 
The above result of the example is proved in the following theorem in a general 
setup. 
Theorem 6.1 Let X ,Y 
be real random variables defined over (Ω, $, P) and 
h a real-valued function such that h(X) is a random variable. IfE(h(X)) 
exists, 
then: 
E(h(X)) 
= E(E(h(X)) 
| Y) . 
Proof: Suppose that X and Y are discrete random variables. Then: 
E(E(h(X))\Y) 
= 
Y/E(h(X)\Y 
= y)P(Y = y) 
v 
= 
Y^h{x)P{X 
= x\Y 
= y)P(Y = y) 
V 
x 
y 
x 
x 
\ v 
/ 
= 
Ση(χ)Ρ(Χ 
= χ) 
X 
= 
E(h(X)). 

CONDITIONAL DISTRIBUTION 
275 
If X and Y are random variables with joint probability density function /, 
then: 
/
oo 
E(h(X)\Y 
= 
y)My)dy 
-oo 
= 
/ 
\J 
Η(χΜχ\γ(χ I y)dx) 
fY(y)dy 
/
OO 
ί·00 
/ 
h(x)f(x,y)dxdy 
-oo J—oo 
= 
/ 
h(x)( 
f{x,y)dyjdx 
/
oo 
h(x)fx{x)dx 
-oo 
= 
E(h(X)). 
EXAMPLE 6.11 
The number of clients who arrive at a store in a day is a Poisson random 
variable with mean λ = 10. The amount of money (in thousands of pesos) 
spent by each client is a random variable with uniform distribution over 
the interval (0,100]. Determine the amount of money that the store is 
expecting to collect in a day. 
Solution: Let X and M be random variables defined by: 
X := "Number of clients who arrive at the store in a day". 
M := "Amount of money that the store collects in a day". 
It is clear that 
x 
M = J2Mi -
where: 
Mi := "Amount of money spent by the ith client". 
According to the previous theorem, it can be obtained that: 
E{M) = E{E{M | X)) . 

276 
CONDITIONAL EXPECTATION 
Given: 
E(M\X 
= k)=E( 
Y^Mi j 
= 5>(Mi) 
i=l 
= 50fc. 
Then: 
E(M) = E(50X) = 50E(X) = 500,000 pesos. 
A 
Note 6.4 In particular it is said that, if (Ω, 9, P) is an arbitrary probability 
space and if A g 3 is fixed, then: 
P(A) = 
E(XA) 
= 
E[E(XA\Y)} 
{
Σ,Ρ (A | Y = y) P (Y = y) 
if Y is a discrete random variable 
f^° 
P (A | Y = y) fy(y)dy 
if Y is a random variable with 
pdffy. 
■ EXAMPLE 6.12 
Let X and Y be independent random variables with densities fx and 
fy, respectively. Calculate P(X < Y). 
Solution: Let A := {X < Y}. Then 
P(A) = 
E(XA) 
= E(E(XA 
| Y)) 
/
oo 
E(XA | Y = 
y)fY(y)dy 
-OO 
/ O O 
P(X < Y I Y = 
y)fY{y)dy 
■OO 
/ O O 
P(X < 
y)fY{y)dy 
-OO 
/ O O 
Fx(y)fY(y)dy 
-OO 
where Fx(.) 
is the distribution function of X. 
▲ 
Theorem 6.2 IfX, Y and Z are real random variables defined over (Ω, 9ί, Ρ) and 
if h is a real function such that h(Y) 
is a random variable, then the condi-
tional expected value satisfies the following conditions: 

CONDITIONAL DISTRIBUTION 
277 
1. E{X \Y)>0 
ifX>0 
a.s. 
2. £7(1 | Y) = 1. 
3. If X and Y are independent, then E(X | Y) = 
E(X). 
4. E{Xh{Y) 
| Y) = h{Y)E(X 
| Y). 
5. E(aX + ßY\Z) 
= aE(X 
\ Z) + βΕ(Υ \ Z) for a, β £ R. 
Proof: We present the proof for the discrete case. Proof for the continuous 
case can be obtained in a similar way. 
1. Suppose 
that 
X 
takes 
the 
values 
χχ,χ^,··· 
■ Given 
that 
P{X < 0) = 0, then P(X = Xj)=0 for χά < 0. Therefore, 
E(X\Y 
= y) = Σ,ΧίΡ(Χ 
= Xj\Y 
= y) 
j 
= Σ 
xip(x 
= Xj\Y = v)>0 
j:Xj>0 
and in consequence E(X \ Y) > 0. 
2. Let X := 1. Then: 
E{X\Y 
= y) = 1P(X = l\Y 
= y) = l. 
3. As X and Y are independent, it is obtained that 
P(X = x\Y 
= y) = P(X = x) 
for all y with P(Y = y) > 0. Therefore: 
E(X\Y 
= y) = ΣχΡ{Χ 
= x\Y 
= y) 
X 
= Σχρ(χ = *) 
X 
= 
E(X). 
4. 
E (Xh(Y) 
\Y = y) = ^xh(y)P(X 
= x\Y 
= y) 
X 
= h{y)E(X 
\Y = y) 
and we have: 
E(Xh(Y) 
| Y) = h(Y)E{X 
| Y). 

278 
CONDITIONAL EXPECTATION 
5. 
E(aX 
+ ßY | Z = z) = Σ(ax 
+ ßy)P(X 
= x,Y = y \ Z = z) 
= aY^xP 
(X = x,Y = y\Z 
= z) 
x,y 
+ ßJ2yP(X = x,Y = y\Z = z) 
= α Σ χ Σ ρ ( χ = x,Y = y\Z = z) 
x 
y 
+^>Σ ρ(* = x'y = *Ί z = *) 
y 
x 
= αγ^χΡ{Χ 
= χ\Ζ 
= ζ) 
X 
+ ßY^yP(Y = y\Z = z) 
y 
= aE(X 
\Z = z)+ ßE{Y \Z = z). 
Therefore: 
E(aX + ßY\Z)= 
aE(X | Z) + βΕ(Υ \ Z). 
EXAMPLE 6.13 
Consider the n + m Bernoulli trials, each trial with success probability 
p. Calculate the expected number of success in the first n attempts. 
Solution: Let Y := "total number of successes" and, for each 
i = l,··· , n, let: 
L , 
, «f-, 
c ■= { l 
if 
ίι- \ o 
Y 
_ i ^ 
" 
success is obtained in the ith attempt 
1 ' 
" 
otherwise . 
It is clear that: 
X := 2_]Xi — "number of successes in the first n attempts". 
i = l 
As 
E(X) = E(E(X 
| Y)) 

CONDITIONAL DISTRIBUTION 
279 
and 
E(X\Y 
= k) = El J^Xi \Y = k 
n 
= Y^EiXi \Y = k) 
i=l 
n 
i=l 
kn 
n + m 
then: 
E(X) = E (-^—λ 
= —?—E(Y) 
= — — ρ ( η + m) = np. 
v ' 
\n + mj 
n + m 
K ' 
n + mK 
' 
■ EXAMPLE 6.14 
The number of customers entering a supermarket in a given hour is a 
random variable with mean 100 and standard deviation 20. Each cus-
tomer, independently of the others, spends a random amount of money 
with mean $100 and standard deviation $50. Find the mean and stan-
dard deviation of the amount of money spent during the hour. 
Solution: Let N be the number of customers entering the supermarket. 
Let Xi be the amount spent by the ith customer. Then the total amount 
of money spent is Z = 5Zt=i x*· The m e a n is: 
= 
E(100N) = 10,000. 
Using 
Var(X) = E{Var{X\Y)) 
+ 
Var{E{X\Y)) 
we get: 
Varl^xA 
= ElvarlYxi\N 
= n))+Var\Elit,Xi\N 
= n 
= 
E(50N) + 
Var(l00N) 
= 
5000 + 10,400 
= 
15,400. 
Hence the standard deviation is 124.0967. 
▲ 

280 
CONDITIONAL EXPECTATION 
EXAMPLE 6.15 
A hen lays iV eggs, where N has a Poisson distribution with mean λ. 
The weight of the nth egg is Wn, where W\, W2, ■ ■ ■ are independent 
and identically distributed random variables with common probability 
generating function G. Prove that the probability generating function 
of the total weight W = Σ?=ι Wi is exp(-A(l - G(s))). 
Solution: The pgf of the total weight is: 
/ A λ 
s « = l 
E(sw) 
\ 
I 
E I f±w. 
E 
, t = l 
N = n 
V V 
/ 
E [Π?=1£? (sWi \N = n)] 
\ 
E 
00 
£(G"(.)) = ^ G " ( . ) / M ( n ) 
Σ· 
n=0 
,(AGW)" 
n=0 
= 
exp(-A(l-G(e))). 
6.2 
CONDITIONAL EXPECTATION GIVEN A σ-ALGEBRA 
In this section the concept of conditional expected value of a random variable 
with respect to a σ-algebra will be worked which generalizes the concept of 
conditional expected value developed in the previous section. 
Definition 6.9 (Conditional Expectation of X Given B) Let X 
be a 
real random variable defined over (Ω, S, P) and let B € 3 with P(B) > 0. 
The conditional expected value of X given B is defined as 
E(X I B) := E(XXB) 
P(B) 
if the expected value of Y :— XXB exists. 

CONDITIONAL EXPECTATION GIVEN A «7-ALGEBRA 
2 8 1 
EXAMPLE 6.16 
A fair die is thrown twice consecutively. Let X be a random variable 
that denotes the sum of the results obtained and B be the event that 
indicates that the first throw is 5. Calculate E(X | B). 
Solution: The sample space of the experiment is given by: 
Ω = {(α,6):ο,6ε{1,···,6}}. 
It is clear that: 
(a, b) = | 
(**B)(«,6)H l + b 
i f « = 5 , 6 € {!,··· ,6} 
v 
' v 
' 
' 0 
other cases . 
Then 
E(XXB) 
= Σ (5 + b) P{XXB = 5 + 6) 
b=l 
6 
-sS<«+'> 
and 
Therefore: 
36 
6=1 
51 
36 
PiB) = \ 
51 
n 
Ε(Χ\Β) = ψ = ^- = 8.5. 
6 
6 
EXAMPLE 6.17 
Let X be a random variable with exponential distribution with param-
eter λ. Calculate E(X 
\{X>t}). 
Solution: Given that X = Exp(X) we have that the density function is 
given by: 
"{ί' 
Therefore: 
P{X>t) 
= l - P(X < t) 
f 1 - /o \exp(-Xx)dx 
if t > 0 
\ 1 
if t < 0 
_ ί βχρ(-λί) if ί > 0 
1 1 
if t < 0 . 
t ( \ _ ) λεχρ(—\χ) 
if x > 0 
/xlxj - \ n 
other cases . 

282 
CONDITIONAL EXPECTATION 
On the other hand, 
/t°° x\exp(-\x)dx 
if 
i > 0 
E(XX{x>t}) 
= ^ 
j ~ x X e x p { _ X x ) d x 
if 
i < 0 
ί βχρ(-λί) + l βχρ(-λί) 
if t > 0 
λ 
i 
if t < 0 
and we obtain: 
t+j 
if t > 0 
E(X | {X > * » = < , 
.f 
t < 0 i 
EXAMPLE 6.18 
Let X, Y and Z be random variables with joint distribution given by: 
| x:=(z,J/,z) | 
1 ^(Χ = χ) I 
(0,0, 
1 
9 
Calculate E{X \ Y = 
Solution: 
E{X\ \y = 
,o) | (o 
I 
= o,z = 
o,z = 
,0,1) 
2 
9 
= 
! ) ■ 
i) = 
| (ο,ι,ΐ) | (ΐ,ι,ΐ) | (ΐ,ι,ο) | (ΐ,ο, 
1 \ 1 
: ΣΧΡ{Χ 
X 
■■ P(X 
= 1 | 
P(X = 1, 
P{Y = 
ΣΡ(Χ = 
X 
1 
: 2 · 
Α 
2 
1
1
1
2 
9 
1 
9 
1 
9 
= x | y = o,z = i) 
\Y = 0,Z = 1) 
Y = 0,Z = 1) 
= 0 , Z = 1 ) 
2 
9 
x,y = o,z = i) 
Dl 
1 
Definition 6.10 (Conditional Expectation of X Given Q) Let X 
be a 
real random variable defined over (Ω, 9, P) for which E(X) exists. Let Q be 
a sub-σ-algebra o/9f. The conditional expected value of X given Q, denoted by 
E(X \Q), is a random variable Q-measurable so that: 
E {[X - E {X | g)} XG) = 0 for all Geg. 
(6.1) 

CONDITIONAL EXPECTATION GIVEN A σ-ALGEBRA 
283 
EXAMPLE 6.19 
Let Ω = {a,b,c}, 
ξ> = ρ(Ω) and Ρ{ω) = \ for all ω 6 Ω. 
Suppose that X is a real random variable given by 
XM = ( ° !? ω = α'6 
v ' 
\ 2 if ω = c 
and let Q := {0, {a}, {6, c}, Ω}. 
We have y given by 
, . 
/ 0 if ω = a 
y ( w ) = \ 1 if u, = b,c 
which is equal to ^ ( X | Q). Indeed: 
1. Y is (/-measurable, due to the fact that: 
0 
if x < 0 
y - 1 ( ( - o o , x ] ) = { {a} 
if 
0 < x < l 
Ω 
if x > 1 . 
2. y satisfies condition (6.1) because: 
0 
if ω — a 
(X -Υ)(ω)={ 
- 1 
if ω = 6 
1 
if w = c . 
Therefore, 
(x-y)-f{a} = o = (x-y),f0 
(x - y) ^{6,c} = (x - Y) = (x - Y) xn 
and we obtain: 
E [(X - y ) X{a}] =0 = E[{X-Y) 
X9\ 
E[(X-Y)X{btC]]=E[(X-Y)Xa] 
= 
E[(X-Y)} 
= (-l)P(6) + lP(c) = 0 . 
▲ 

284 
CONDITIONAL EXPECTATION 
■ EXAMPLE 6.20 
Let Ω = {a, b, c}, 3 = ρ(Ω) and Ρ(ω) = | for all ω € Ω. Suppose that 
X is a real random variable given by 
{
0 
if ω = a 
- 1 
if w = 6 
1 
if u/ = c 
and let £ := {0,Ω]. 
It is easy to verify that Z :— 0 is ^-measurable and that it satisfies 
condition (6.1). Therefore, Z = E(X | </). 
A 
Definition 6.11 We define: 
L\ 
:= {X : X is a real random variable defined over (Ω, 9, P) 
and with E {\X\) < oo} . 
In continuation we present some important properties of conditional expecta-
tion with respect to a σ-algebra: 
Theorem 6.3 Let Q be a sub-a-algebra of 9. We have: 
1. IfX,YeL! 
anda,ßeR, 
then E(aX + ßY) = aE(X) + 
ßE(Y). 
2. If X is Q-measurable and in L\, 
then E(X \ Q ) = X. In particular, 
E (c | Q ) = c for all c real constant. 
3. E{X\{®,n}) 
= E(X). 
4.IfX>0 
andX e Lu then E(X \g 
)>0. 
5. IfX,Ye 
^ 
and X <Y, then E (X \ Q ) < E {Y | Q ). 
6. If Q\ C Qi C 3i, then for all X E L\ we have that: 
E(E(x\g2 
)\Gi) = E{x\g1 
) = E(E(x\g1 
)\g2). 
7. If X€Llt 
then\E{X 
\Q)\< 
E{\X\ \Q ). 
Proof: 
1. Since Z = E(X \G) 
and W = E (Y \ g ) are 0-measurable, then 
aZ + ßW are also (/-measurable. Prom the definition of the conditional 
expectation, we have that for all A € £: 
E {{aZ + ßW) XA) = E (aZXA + ßWXA) 
= 
aE{ZXA)+ßE{WXA) 
= aE(XXA) 
+ 
ßE(YXA) 
= E((aX + 
ßY)XA). 

CONDITIONAL EXPECTATION GIVEN A σ-ALGEBRA 
285 
2. By the hypothesis X 
is (/-measurable, and from the definition of con-
ditional expectation, if Z := E (X | Q ), then for all A € G : 
E(ZXA) 
= 
E(XXA). 
3. It is clear that Z — E (X) 
is measurable with respect to 3o = {0, Ω} . 
On the other hand, if A € {0, Ω} we have that E (ZXA) = E (XXA) ■ 
4. Let Z=E(X\Q). 
By the definition, we have that, for all A € G, 
E(ZXA) 
= 
E(XXA)>0 
since XXA > 0 because of Z > 0. 
5. This result follows from the linearity of expectation and the previous re-
sult. It is clear that E (X | Q\ ) is Q\-measurable. Let Z = E (X \ Q2 ) 
and W = E {Z \ & ). If A € Qu then: 
E(ZXA) 
= 
E(WXA). 
Since Q\ CQ2, then A G Gz, and it follows that: 
E(ZXA) 
= 
E(XXA). 
Therefore, for all A e G\: 
E(XXA) 
= E(WXA) 
. 
That is, 
W = 
E(X\Gi) 
and we get: 
E(X\Gi 
) = E(E(X\g2)\gi) 
■ 
Similarly, HY = E(X\Gi) 
and R = E (Y \ Gi ), then for all A € G\ 
it is true that: 
E(XXA) 
= 
E(YXA). 
Since A € G2 > we have: 
E{RXA) 
= 
E(YXA). 
Because of this, for all A € G\ we have: 
E(RXA) 
= 
E(XXA). 
Thus: 
E(X\Gi) 
= 
E{E{X\Gi)\G2). 
In particular, if £x = {0, Ω} , then E(E{X\ 
Q2)) = 
E(X). 

286 
CONDITIONAL EXPECTATION 
6. Let X+ and X 
be the positive and negative parts of X, respectively. 
That is: 
X + := max (X, 0) and X ~ := max (—X, 0). 
Because 
\X\ = X + + X ~ and X = X + 
-X~ 
we have: 
\E(x\g)\ 
= \E(x + - x - 
\g)\ 
= \E(X 
+ 
\G)-E(X 
<E(x 
+ \g) + 
E(x-
= E{X 
+ 
+X-\Q) 
= 
E{\X\\Q). 
Finally we have the following property whose proof is beyond the scope of 
this text. Interested readers may refer to Jacod and Protter (2004). 
Theorem 6.4 Let (Ω, 9, P) 
be a probability space and let Q be a sub-σ-
algebra o/Qi. If X e L\ and (Xn)n>i 
is an increasing sequence of nonnegative 
real random variables defined over Ω that converges to X a.s., that is, 
lim Xn (ω) = X (ω) with probability 1, 
n—►oo 
then{E(Xn\g))n> 
x is an increasing sequence of random variables that con-
verges to E {X | Q ^ ■ 
Theorem 6.5 Let (Ω, Ö, P) be a probability space and let g be a sub-σ-
algebra of 3i. // (-Xn)n>1 is a sequence of real random variables in L\ that 
converge in probability to 1 and if \Xn\ < Z for all n, where Z is a random 
variable in L\, then: 
E ( lim Xn I g) = lim E (Xn I Q) with probability 1 . 
\n-*oo 
/ 
n—►<» 
Notation 6.1 Let X, Υχ,··· ,Υη be the real random variables. The expec-
tation E(X | σ(Υι,··· 
,V^i)), where σ(ΥΊ,··· ,Υη) is the smallest σ-algebra 
with respect to random variables Υχ,·-· ,Yn, is usually denoted by E{X \ 
Yl,---,Yn). 
Note 6.5 Conditional expectation is a very useful application in Bayesian 
theory of statistics. A classic problem in this theory is obtained when observing 
data X := (ΛΊ, · · · , Xn) whose distribution is determined from the conditional 
distribution of X given θ = Θ, where Θ is considered as a random variable 
with a specific priori distribution. 
Using as a base the value of the data X, 
1^)1 

EXERCISES 
287 
the interesting problem is to estimate the unknown value of Θ. An estimator 
of Θ can be any function d(X) of the data. In Bayesian theory we look for 
choosing d(X) 
in such a way that the conditional expected value of the square 
of the distance between the estimator and the parameter is minimized. 
In 
other words we look for minimizing Ε([θ — d(X)] 
| X). 
Conditioning on X leaves us with a constant d(X). Along with this and the 
fact that for any random variable W we have that E (W — c) 
is minimized 
when c = E(W), 
we conclude that the estimator minimizing Ε([θ — d(X)] | 
X) is given by d (X) = E {Θ | X). 
This estimator is called the Bayes esti-
mator. 
EXAMPLE 6.21 
The height reached by the son of an individual with a height of x cm is a 
random variable with normal distribution with mean x + 3 and variance 
2. Which is the best prediction of the height that is expected for the 
son of the individual with height 170 cm? 
Solution: let X be the random variable that denotes the height of the 
father and let Θ be the random variable that denotes the height of the 
son. According to the information provided, θ = λί (X + 3,2). Due to 
the previous observation, it is known that the best possible predictor 
of the son's height is d {X) = E {Θ | X). Therefore, if X = 170, then 
0 = A/"(173,2) and: 
Ε{Θ\Χ 
= 170) = 173 cm 
EXERCISES 
6.1 
Consider a sequence of Bernoulli trials. If the probability of success is 
a random variable with uniform distribution in the interval (0,1), what is the 
probability that n trials are needed? 
6.2 
Let X be a random variable with uniform distribution over the interval 
(0,1) and let Y be a random variable with uniform distribution over (0, X). 
Determine: 
a) The joint probability density function of X and Y. 
b) The marginal density function of Y. 
6.3 
Let Y be a random variable with Poisson distribution with parameter 
λ. Suppose that Z is a random variable defined by 
Y 
Z := 5 > 
t = l 

288 
CONDITIONAL EXPECTATION 
where the random variables X\, X2, ■ ■ ■ are mutually independent and inde-
pendent of Y. Further, suppose that the random variables X\,X2,··· 
are 
identically distributed with Bernoulli distribution with parameter p € (0,1). 
Find E(Z) and Var (Z). 
6.4 
Let X and Y be random variables uniformly distributed over the trian-
gular region limited by x = 2, y = 0 and 2y — x, that is, the joint density 
function of the random variables X and Y is given by: 
/ (χ, y) 
f 
1 
J 
area of th< 
I 0 
the triangle 
if (*, y) is in the triangle 
other cases . 
Calculate: 
a ) P ( y < f ) . 
b) P(Y 
>0.5). 
c) P ( X < 1 . 5 | r = 0.5). 
6.5 
The joint density function of X and Y is given by 
/(*,V) = { 
xe-x(v+i) 
if x > 0 and y > 0 
0 
other cases. 
Find the conditional density function of X given that Y = y and the condi-
tional density function for Y given that X = x. 
6.6 
Let X = (X, Y) be a random vector with density function given by: 
f(x,y) 
= 
1 
2π x 0.6 exp 
((* - 3)2 - 1.6 (x - 3) (y - 3) + (y - 3)2) 
2 x 0.36 
Calculate: 
a) The marginal density functions of X and Y. 
b) The conditional density function fy\x (y \ X = 2). 
c) The value of c so that P (Y > c \ X = 2) = 0.05. 
6.7 
Suppose that X and Y are discrete random variables with joint proba-
bility distribution given by: 
1 χ\γ 
1 1 
12 
13 
14 
1 
1 
16 
0 
0 
0 
2 
1 
16 
2 
16 
0 
0 
3 
1 
16 
1 
16 
3 
16 
0 
4 | 
1 1 
16 1 
1 1 
16 1 
1 1 
16 1 
4 1 
16 1 

EXERCISES 
289 
a) Calculate distributions of X and Y. 
b) Determine E(X \Y=1) 
and E(Y \ X = 1). 
6.8 
Suppose that X and Y are discrete random variables with joint proba-
bility distribution given by: 
1 X\Y 
| 1 
| 2 
13 
| i 
1 
1 
1 12 
1 ° 
l£ 
| 2 
1 2 
1 12 
1 4 
1 12 
1* 
13 1 
| o | 
1 h 1 
1 A 1 
Verify that E(E(X\ 
Y)) = E{X) and E(E(Y\ 
X)) = E(Y). 
6.9 
A fair die is tossed twice consecutively. Let X be a random variable 
that denotes the number of even numbers obtained and Y the random vari-
able that denotes the number of results obtained that are less than 4. Find 
E(XE{Y\X)). 
6.10 
If E[Y/X] = 1, show that: 
Var[XY] > Var[X]. 
6.11 
A box contains 8 red balls and 5 black ones. Two consecutive extrac-
tions are done without replacement. In the first extraction 2 balls are taken 
out while in the second extraction 3 balls are taken out. Let X be the random 
variable that denotes the number of red balls taken out in the first extraction 
and Y the random variable that denotes the number of red balls taken out in 
the second extraction. Find E (Y | X = 1). 
6.12 
A player extracts 2 balls, one after the other one, from a box that 
contains 5 red balls and 4 black ones. For each red ball extracted the player 
wins two monetary units, and for each black ball extracted the player loses 
one monetary unit. Let X be a variable that denotes the player's fortune and 
Y be a random variable that takes the value 1 if the first ball extracted is 
red and the value 0 if the first ball extracted is black. 
a) Calculate 
E{X\Y). 
b) Use part (a) to find E{X). 
6.13 
Assume that taxis are waiting in a queue for passengers to come. Pas-
sengers for these taxis arrive independently with interarrival times that are 
exponentially distributed with mean 1 minute. A taxi departs as soon as two 
passengers have been collected or 3 minutes have expired since the first pas-
senger has got in the taxi. Suppose you get in the taxi as the first passenger. 
What is your average waiting time for the departure? 

290 
CONDITIONAL EXPECTATION 
6.14 
Suppose you are in Ooty, India, as a tourist and lost at a point with 
five roads. Out of them, two roads bring you back to the same point after 1 
hour of walk. The other two roads bring you back to the same point after 3 
hours of travel. The last road leads to the center of the city after 2 hours of 
walk. Assume that there are no road sign. Assume that you choose a road 
equally likely at all times independent of earlier choices. What is the mean 
time until you arrive at the city? 
6.15 
Suppose that X is a discrete random variable with probability mass 
function given by ρχ (x) = | , x = 1,2 and Y is a random variable such that: 
PY\X (y I x) = f ) ( 2 ) for 
j/ = 0, · · · , x and x = 1,2 . 
Find: 
a) The joint distribution of X and Y. 
b) 
E(X\Y). 
6.16 
If X has a Bernoulli distribution with parameter p and E (Y \ X = 0) = 
1 and E{Y\X 
= 1)=2, 
what is E{Y)? 
6.17 
Suppose that the joint probability density function of the random vari-
ables X and Y is given by: 
, , 
\ _ / 
e~v 
if x > 0, y > x 
J \x> V) — | Q 
other cases . 
a) Calculate P(X > 2 | Y < 4). 
b) Calculate E(X \Y = y). 
c) Calculate E(Y \ X = x). 
d) Verify that E(X) = E(E(X 
\ Y)) and E{Y) = E{E(Y \ X)). 
6.18 
Let X and Y be independent random variables. Prove that: 
E(Y\X=x) 
= E{Y) 
for all x. 
6.19 
Prove that if E (Y \ X = x) = E(Y) for all x, then X and Y are 
noncorrelated. Give a counterexample that shows the reciprocal is not true. 
Suggestion: You can use the fact that E (XY) = E (XE (Y \ X)). 
6.20 
Let X and Y be random variables with joint probability density func-
tion given by: 
f(xv)-i 
t ( x + y2) 
i f 0 < x < 2 , 0 < y < l 
J v ,y) 
\ 0 
other cases. 

EXERCISES 
291 
Calculate E{X | Y = \). 
6.21 
The conditional variance of Y given X = x is defined by: 
Var(Y 
\ X = x) := E {Y2 \ X = x) - (E(Y | X = x)f 
. 
Prove that: 
Var{Y) = E {Var (Y | X)) + Var (E (Y | X)) . 
6.22 
Let X and V be random variables with joint distribution given by: 
1 χ\γ 
1 ° 
| i 
|2 
1 ° 
11 
1° 
1° 
|i 
1 1 
1 8 
1 1 
1 8 
1 ° 
|2 | 
1 1 1 
1 8 1 
1 1 1 
I I I 
Find Var (Y | X). 
6.23 
Let X and Y be random variables with joint probability density func-
tion given by: 
*(~ ,,\-[ 
i (χ2 - y2) βχρ (-χ) 
if * > ° > \y\<x 
J K ' y ) 
\ 0 
other cases . 
Calculate E(X 
\Y=1). 
6.24 
Let (X, Y) be two-dimensional random variables with joint pdf given 
by: 
< x <y < oo 
otherwise . 
,, 
. 
/ e~y 
if 0 
/ ( x ' y ) = \ 0 
other 
a) Find the conditional distribution of Y given X = x. 
b) Find the regression of F on X. 
c) Show that variance of Y for given X = x does not involve x. 
6.25 
Suppose that the joint probability density function of the random vari-
ables X and Y is given by: 
ft 
\ = ί Κ χ 2 + ^ ) 
i f 0 < x < l , 0 < y < 2 
1 [X,y> 
\ 0 
other cases. 
Calculate E(X \Y = y). 
6.26 
Let (X, Y) be a random vector with uniform distribution in a triangle 
limited by x > 0, y > 0 and x + y < 2. Calculate E(y\X 
= x). 

292 
CONDITIONAL EXPECTATION 
6.27 
Let X and Y be random variables with joint probability density func-
tion given by: 
f(xv) 
= i 
8xy 
i{0<y<x<l 
J v ' y ' 
\ 0 
other cases . 
Calculate: 
a) E(X\Y 
= y). 
b) E(X* \Y = y). 
c) Var(X \Y = y). 
6.28 
Two fair dice are tossed simultaneously. Let X be the random variable 
that denotes the sum of the results obtained and B the event defined by 
B :="the sum of the results obtained is divisible by 3". Calculate E (X \ B). 
6.29 
Let X and Y be i.i.d. random variables each with uniform distribution 
over the interval (0,2). Calculate: 
a) P(X>l\{X 
+ 
Y)<3). 
b) E(X\(X 
+ 
Y)<3). 
6.30 
Let X and Y be random variables with joint density function given 
by: 
exp (—x — y) 
if x > 0 and y > 0 
, , 
. _ J exp (—x — y) 
if x > 0 an< 
/ l * . W - | 
0 
other cases. 
Calculate E (X + Y | X < Y). 
6.31 
A fair die is thrown in a successive way. Let X and Y be random 
variables that denote, respectively, the number of throws required to obtain 
2 and 4. Calculate: 
a) E(X) . 
b) E(X\Y=1) 
. 
c) E{X\Y 
= S) . 
6.32 
A box contains 6 red balls and 5 white ones. Two samples are extracted 
in a consecutive way without replacement of sizes 3 and 5. Let X be the 
number of white balls in the first sample and Y the number of white balls in 
the second sample. Calculate E (X \ Y = k) for k = 1,2,3,4,5. 
6.33 
Let X be a random variable whose expected value exists. Prove that: 
E(X) 
= E(X\X< 
y)P(X 
< y) + E(X 
\X>y)P(X>y) 
. 

EXERCISES 
293 
6.34 
The conditional covariance of X and Y given Z is denned by: 
Cov (X, Y\Z):=E[(X~E(X\ 
Z)) (Y - E (Y \ Z)) \ Z] . 
a) Prove that: 
Cov {X, Y | Z) = E (XY \Z)-E{X\Z)E(Y\Z) 
. 
b) Verify that: 
Cov {X, Y) = E [Cov (X, Y | Z)} + Cov (E [X \ Z], E [Y | Z}) . 
6.35 
Let X\ and Xi be a two i.i.d. random variables each Af(0,1) dis-
tributed. 
a) Are X\ + Xi and X\ — Xi independent random variables? Justify your 
answers. 
b) Obtain E\X\ + X\ \ Xx + X2 = t}. 
6.36 
Let (X, Y) be two-dimensional random variable with joint pdf 
t 
, 
\ 
f hye~xy 
if 0 < x < o o , 0 < 2 / < 2 
fx,y(x,v) 
= { 0
2 
otherwise. 
a) Compute E[(2X + l)\Y 
= y]. 
b) Find the standard deviation of [X \ Y = y}. 
6.37 
For n > 1, let Yj 
, Y2: ,... be i.i.d. random variables with values in 
N0, n e N. Suppose that m := Ε(Υλ
{η)) < oo 
and 0 < σ2 := Var{Y^n)) 
< 
oo. Let ZQ := 1 and: 
?n+i := S ΥΪη) + y2
(n) + ·■ · + yfe
(n) 
if zn = k,k>o 
0 
if 
Zn = 0. 
a) Calculate E {Zn+1 \ Zn) and 
E(Zn). 
b) Let f{s) 
:= E (sZl) 
= Σρ(ζι 
= k)sk 
w i t h \s\ < !. t h e probability 
k 
generating function of Z\ . Calculate /n(«) := E(sZn) 
in terms of /. 
c) Find Var(Zn) 
. 

CHAPTER 7 
MULTIVARIATE NORMAL 
DISTRIBUTIONS 
The multivariate normal distributions is one of the most important multidi-
mensional distributions and is essential to multivariate statistics. The mul-
tivariate normal distribution is an extension of the univariate normal distri-
bution and shares many of its features. This distribution can be completely 
described by its means, variances and covariances given in this chapter. The 
brief introduction to this distribution given will be necessary for students 
who wish to take the next course in multivariate statistics but can be skipped 
otherwise. 
7.1 
MULTIVARIATE NORMAL DISTRIBUTION 
Definition 7.1 (Multivariate Normal Distribution) An n-dimensional 
random vector X = (Χχ, · ■ ■ , Xn) is said to have a multivariate normal distri-
n 
bution if any linear combination 2_,aJ -^3 ^ ^ ° ω™υαΓ*α*ε normal distribution 
3 = 1 
(possibly degenerated, as happens, for example, when oij = 0 for all j). 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
295 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

296 
MULTIVARIATE NORMAL DISTRIBUTIONS 
EXAMPLE 7.1 
Suppose that Χχ, ■ ■ ■ , Xn are n independent random variables such that 
n 
Xj = N{ßj,a?) 
for j = 1, · · · , n. Then, if Y = Tjctj -^j> w e n a v e 
3 = 1 
<pY(t) = 
E(eitY) 
n 
J"=l 
JJexp 
3 = 1 
ißj ctj t 
a]t2a) 
= exP I Σ 
α?ί2σ? 
»Mi a j * - 
3
2
 
J 
exp (ißt — -σ212 
where 
μ := Σμι αί 
and 
°"
2 := Σ
α ? CTi · 
j=l 
j=l 
In other words, Y = Λ/"(μ, σ2). 
Therefore, the vector X : = (X\,· ■ ■ ,Xn) has a multivariate normal 
distribution. 
▲ 
Note 7.1 In this chapter, the vector in E n is represented by a row vector. 
Theorem 7.1 Let X : = (Χχ,··· 
,Χη) 
be a random vector. X has multi-
variate normal distribution if and only if its characteristic function has the 
form 
y>x(t) = exp i (t, At) — - (t, tE) 
where μ G E", Σ is a positive semidefinite symmetric square matrix and (·, ·) 
represents the usual inner product o/E". 

MULTIVARIATE NORMAL DISTRIBUTION 
297 
Proof: 
and 
) Let Y := Σαί 
Xi- Clearly 
3 = 1 
= (a, μ), where μ := E(X) 
and a := (αι, · · · , a n ) , 
Var(y) = Var ( j ^ a j X,· 
u = i 
- Σ 
Var (a,· X,) + 2 ^ ^Cov 
(a, X0-, a, X,) 
J = l 
j < » 
= J ^ a » Var (X,) + 2 ^ ^ a , a* Cot; 
(Xj,Xi) 
3 = 1 
j<i 
= (α,άΣ) 
, 
where a := (c*i, · · · , an) and Σ is the variance-covariance matrix of X. 
Therefore, the characteristic function of Y equals: 
φγ{ί) = exp it (a, μ) - — {a, αΣ) 
Then: 
<px(a) = E [exp (iXa T)] 
= E exp | i 2_,a3 Xj 
3=1 
φγ(1) 
exp *(">/*)- 2 ( α ' α Σ ) 

298 
MULTIVARIATE NORMAL DISTRIBUTIONS 
by 
) Let Y := 2~]aj Xj- The characteristic function of Y is then given 
j = l 
<pY(t) = 
E[exp(üY)] 
E 
= E 
exp I 
ityajXj 
3 = 1 
exp 0
X"
T)] 
where ß := ta. That is: 
φγ(ί) 
= ip}i(ß) = <px(ta) 
= exp 
= exp 
i {ta, μ) — — {ta, ta Σ) 
it {a, μ) - — t2 {a, a Σ) 
Then Y has a univariate normal distribution with parameters (α,μ) and 
{α,αΣ). 
Therefore, X is multivariate normal. 
■ 
Note 7.2 It can be easily verified that the vector μ and the matrix Σ from the 
previous theorem correspond to the expected value and the variance-covariance 
matrix o/X, respectively. 
Notation 7.1 7/X has a multivariate normal distribution with mean vector 
μ and variance-covariance matrix Σ, then we write X = Αί{μ, Σ). 
Our next theorem states that any multivariate normal distribution can 
be obtained by applying a linear transformation to a random vector whose 
components are independent random variables having all univariate normal 
distributions. In order to prove this result, the following lemma is required: 
Lemma 7.1 Let X : = (Χχ,··· 
,Χη) 
be a random vector such that X = 
Ν(μ, Σ). The components Xj, j = 1, · · · ,n, are independent if and only if 
the matrix Σ is diagonal. 
Proof: 
) See the result given in (5.17). 

MULTIVARIATE NORMAL DISTRIBUTION 
299 
) Suppose that the matrix Σ is diagonal. Since X = Ν(μ, Σ), then: 
Vx(t) = exp 
= exp 
i ( t , M ) - - ( t , t E ) 
j=l 
j=\ 
Σ(^^_2"σ^?) 
JJexp (ΐμ, tj - — σ31) \ 
= exp 
Therefore, the random variables Xj for j = 1, · · · , n, are independent. 
Theorem 7.2 Lei X := (X\, ■ ■ ■ ,Xn) be a random vector such that X = 
•Λ/"(μ, Σ). Then there exist an orthogonal matrix A and independent random 
variables Y\,··· , Yn such that either Yj: = 0 or Yj = M (0, Aj) /or j = 1, · · · , n 
so that X = μ + Y A 
Proof: 
Since Σ is a positive semidefinite symmetric matrix, there exist a 
diagonal matrix Λ whose entries are all nonnegative and an orthogonal matrix 
A such that: 
Σ = 
AAAT. 
Let Y := (X — μ)Ατ. 
Since X is multivariate normal, so is Y. Additionally, 
Λ is the variance-covariance matrix of Y. Since this matrix is diagonal, it 
follows from the previous lemma that the components of Y are independent. 
Finally we have: 
X = μ + YA . 
Suppose that X = (Xi, · · ■ ,Xn) is an n-dimensional random vector and 
that the random variables X\, · · · , Xn are independent and identically dis-
tributed having a standard normal distribution. The joint probability density 

300 
MULTIVARIATE NORMAL DISTRIBUTIONS 
function of X\, ■ ■ ■ , Xn is given by: 
/(Xl,··· ,Xn) = 
fXl(xl)---fxn(xn) 
1 
/ 
1 
h
exp{-\
xl) 
^ - e x p ( - - x x i J 
, where x :=(xi,··· ,x n) . 
In addition, it is clear that the vector X has a multivariate normal distribution. 
The natural question that arises is: If X is a random vector with multivariate 
normal distribution, under what conditions can the existence of a density 
function for the vector X be guaranteed? The answer is given in the following 
theorem: 
Theorem 7.3 Let X = Λ/"(μ, Σ). If Σ is a positive definite matrix, then X 
has a density function given by: 
/(x) = —^-n-(detE) *exp 
(2π)* 
Α(χ-μ)Σ-\*-μ)τ 
Proof: Since Σ is a positive definite matrix, all its eigenvalues are positive. 
Moreover, there exists an orthogonal matrix U such that 
UTU1 
where Λ = diag(Xi) and λχ, · ■ · , λη are the eigenvalues of Σ. In other words, 
Λ is the diagonal matrix whose entries on the diagonal are precisely the eigen-
values of Σ. 
Let A := Udiag(y/Xl)UT'. 
Clearly Ä1A 
= Σ and A is also a positive 
definite matrix. Let h : R l x n —► R l x n be defined by h(x) = x.A + μ. The 
inverse function of h would then be given by h _ 1(x) = (x — μ)Α~1. 
The 
transformation theorem implies that the density function of X := Y.A + μ, 
where Y = (Y\,--- ,Yn), is an n-dimensional random vector such that the 
random variables Y\, · · · , Y„ are independent and identically distributed with 

MULTIVARIATE NORMAL DISTRIBUTION 
a standard normal distribution and is given by: 
dh-1 
/ X ( X ) = / Y ( / I - 1 ( X ) ) 
= —L·- exp(-± [(χ-μμ-1] [ ( χ - μ μ - f ) IdetA-1! 
= ^
- 
exp ( - 1 [(x - μ) (ATA)'1 
(x - μ)*]) IdetA"1! 
=(2^j*
exp H[(x"μ)Σ_1(χ"
 μ ) Γ0 |det ^-1' 
(2π) 
ä-(detE) 
2exp 
4(Χ-Μ)Σ- 1(Χ-Μ) Τ 
Note 7.3 (Bivariate Normal Distribution) As a particular case of 
theorem above, suppose that 
where 
Χ = 
(Χ1,Χ2)=Λί(μ,'Σ) 
\ σ2ι 
σ$ ) 
μ = (μι,/ί2), μι-=ΕΧι, 
μ2:=ΕΧ2 
σ\ 
:= Vor p d ) , σ| := Vor (X2) 
(Τΐ2 
= Ccw (Χχ, Χ2) = σ2ι = ρσισ2 
wii/i /> representing the correlation coefficient. Therefore: 
and 
/(x) = -^(detE) * exp - ^ ( χ - ^ Σ - ^ χ - μ ) 1 " 
Since 
and 
det Σ = σ2σ2 - <τ2
2 = σ2σ2 (l - p2) 
v-i 
=
 
1 
f 
σ2 
_ σ ΐ 2 ^ 
^ 2 2 ( 1 - P 2 ) V -^21 
σ\ 
) 

302 
MULTIVARIATE NORMAL DISTRIBUTIONS 
we obtain: 
/(xi,x 2) = 
2πσισ 2νΊ — P2 exp 
+ ^ )
2 } ] · 
We also have that: 
/
oo 
f(xi,x2)dx2 
-oo 
2πσι 
oo 
exp (^y 
/
oo 
f{xi,x2)dx 
-OO 
OO 
1 
λ/27Γσ 2 exp 
(
^ 
In other words, the marginal distributions of X = (.ΧΊ,-Χ^) are univariate 
normal. 
In general, we have: 
Theorem 7.4 ΛίΖ ί/ie marginal distributions o/X = Λ/"(μ, Σ) are multivariate 
normal. 
Proof: Suppose that X = (Χχ, · · · , Xn) and let 
X : = (Xki,··-
 
; ^ f c i ) 
where {fci, ■ · · , fc;} is a subset of {1, · · · ,n}. The characteristic function of X 
is given by: 
ψχ 
(«fc, , · ■· , * * , ) = £ ; ( 
» J ^ ' f c r ^ » r 
j 
= ψ-χ. (*i, ■ · · , in) , where t, = 0 if j £ {fci, ■ · ■ , fc(} . 
Therefore X has a multivariate normal distribution. 
7.2 
DISTRIBUTION OF QUADRATIC FORMS OF MULTIVARIATE 
NORMAL VECTORS 
Let Xi, i = 1,2, · · · , n be independent normal random variables with λί(μί,σ2), 
i 
1,2,··· , n. It is known that: 
γ=Έ 
(Xj — /ij) 
d_ v 2 
12 
- * ( η ) · 
i = l 

DISTRIBUTION OF QUADRATIC FORMS OF MULTIVARIATE NORMAL VECTORS 
3 0 3 
Suppose now an n-dimensional random vector X = (X\,X2,··· 
,Xn) having 
multivariate normal distribution with mean vector μ and variance and covari-
ance matrix Σ. Suppose that Σ is a positive definite matrix. Prom Theorem 
7.3, it is known that X has the density function given by 
/xW 
1 
(2π) 3- (detE) 
2 exp ±(χ-μ)Σ-1(χ-μ)τ 
with x € Rn. Now we are interested in finding the distribution of W = 
(Χ-μ)Σ _ 1(Χ—μ) τ. In order to do so, we need to find the moment generating 
function of W. We have: 
mw{t) 
= 
E(ewt) 
= 
/"e t( x-^ E" 1( x-") T/ x(x)dx 
{2n)^VdefT, exp - - ( χ - μ ^ χ - μ ^ 
dx. 
/
OO 
ΛΟΟ 
-I 
-oo 
J — 0 0 
exp \t(x — μ)Σ~1(χ — μ)τ — -~(x — μ)Σ~ι(χ 
— μ)Ί 
/
OO 
y»00 
-I 
- 0 0 
«/—oo 
dxi,dx2, · · · ,dxn 
exp 
-(χ-μ)Σ-ι(χ-μ)τ(1-2ί) 
dx\, dx2, ■ · ■ ,dxn 
This last integral exists for all values of t < ^. 
Now the matrix (1 — 2ί)Σ _ 1, < < ^, is positive definite given that Σ is 
also a positive definite matrix. 
On the other hand, 
det [(1 - 2ί)Σ_1] = (1 - 
2t)ndet(E~l) 
and consequently the function 
( 2 * ) » ) / ^ 
exp · 
- ( χ - μ ) Σ - 1 ( χ - μ ) Τ ( 1 - 2 ί ) 
is the density function of the multivariate normal random variable. When 
multiplying and dividing the denominator by (1 — 2i) n/ 2 in the expression 

304 
MULTIVARIATE NORMAL DISTRIBUTIONS 
given for m(t) we obtain 
m{t) 
/
OO 
ΛΟΟ 
-I 
· · ■/ 
Ί
— 
{Μ^Μ} ώ ι, ώ 2,.., ώ„. 
exp 
= 
( l - 2 i ) - t 
1 
1 
~ 
( 1 - 2 * ) * ' 
t < ^ 
which corresponds to the mgf of a random variables with X?·, distribution. 
We also have that W = X? %. 
(n) 
Suppose that X\,X2,··· 
,Xn 
are independent with normal distribution 
7V(0,σ2). Let X = (ΛΊ, X2) · · · ,Xn) and suppose that A is a real symmetric 
matrix of order n. We want to find the distribution of XAXT. 
In order to 
find this distribution, the mgf of the variable x/j£ 
must be considered. It 
is clear that: 
m(t) = E 
I 
e 
<>* {2π)*^/dΊtä: 
dx 
Given that the random variables Xi,X2,·· 
■ Xn are independent with nor-
mal distribution Λ/"(0, σ2), we have in this case that 
0 
0 
, detE = σ2η 
and 
Σ" 1 = —I 
where In is the identity matrix of order n. 
Therefore: 
/
OO 
p 
-OO 
J — 
/
OO 
JOO 
-i 
-oo 
7-00 (σν^π)' 
(σν^ϊ)' exp 
exp 
txAxT 
X · X .n 
2σ2 
- x ( J - 2L4)x: Π 
2σ2 
dxi,dx2,· 
■ ■ ,dxn 
dx\,dx2, · · · ,dxn . 
Given that / — 2tA is a positive definite matrix and if |i| is sufficiently 
small, let's say |t| < h, we have that the function 
(2π)ϊ y/det((I 
-2tA)~1a2) exp 
x(J - 2tA)*.7 
2σ2 

DISTRIBUTION OF QUADRATIC FORMS OF MULTIVARIATE NORMAL VECTORS 
3 0 5 
is the density function of the multivariate normal distribution. Thus: 
m(t) = [det(I - 2tA)]~? 
with 
\t\ < h . 
Suppose now that λι,λ2,··· ,λ η are eigenvalues of A and let L be an 
orthogonal matrix of order n such that LTAL = diag{\\, X2, ·■■ , λ η). Then 
Ί - 2ίλι 
LT{I - 2tA)L = 
and therefore: 
Given that 
det (LT{I - 2tA)L) = JJ(1 - 2t\j) 
det (LT(I - 2tA)L) = det(I - 2tA) 
and because L is an orthogonal matrix, we have 
n 
det (1 - 2tA)) = J J ( 1 - 
2t\j) 
from which we obtain that: 
m(t) 
IJ(1 - 2tXj) 
, 1*1 <Λ 
Suppose that r is the rank of matrix A with 0 < r < n. Then we have 
that exactly r of the numbers λχ, λ2, · ■ · , λη, let's say λι, · · · , λΓ, are different 
from zero and the remaining n — r of them are zero. Therefore: 
m(t) = [(l-2t\1)---(l-2t\r)}~* 
with 
\t\ < h . 
Under which conditions does the previous mgf correspond to the mgf of 
a random variable with chi-squared distribution of k degrees of freedom? If 
this is to be so, then we must have: 
τη(ί) = [ ( 1 - 2 ί λ ι ) · · · ( 1 - 2 ί λ Γ ) ] _ 5 = ( i _ 2 t ) - * 
with 
|t| < ft . 
This implies (1 — 2t\\) · · · (1 — 2t\r) = (1 — 2t)k and in consequence k = r 
and λι = λ2 = ·■ · = λΓ = 1. That is, matrix A has r eigenvalues equal to 1 
and the other n — r equal to zero, and the rank of the matrix A is r. This 
implies that matrix A must be idempotent,th&t is, A2 = A. 

306 
MULTIVARIATE NORMAL DISTRIBUTIONS 
Conversely, if matrix A has rank r and is idempotent, then A has r eigen-
values equal to 1 and n — r real eigenvalues equal to zero and in consequence 
the mgf of 
i 
is given by: 
m(t) = ( l - 2 i ) " 2 
if 
t< 1 
In summary: 
Theorem 7.5 Let Xi,X2,·- 
■ ,-^n be i.i.d. random variables with 
λί(0,σ2). 
Let X = (Xi, X2) · · · , Xn) and A be a symmetric matrix of order n with rank 
r. Suppose that Y := XAXT. 
Then: 
Y 
±X2 
-g ~ -V) 
iff A2 = A 
EXAMPLE 7.2 
Let Y = X\X2~ X^XA where Χχ, X2, X3, X4 are i.i.d. random variables 
with JV(0, σ2). Is the distribution of the random variable J^ a chi-square 
distribution? Explain. 
Solution: It is clear that Y = XAXT 
with: 
0 \ 
0 
_ i 
2 
0 / 
The random variable -3 does not have X2 distribution because A2 φ A. 
0 
1 
2 0 
\o 
1 
2 0 
0 
0 
0 
0 
0 
1 
2 
Suppose that Χχ, Χ2, ··· , Xn are i.i.d. random variables with Λί(0, er2). Let 
A and B be two symmetric matrices of order n and consider the quadratic 
forms XAXT 
and XBXT. 
Under what conditions are these quadratic forms 
independent? To answer this question we must consider the joint mgf of 
XAXT „„A XBXT 
and 
-. We have then: 
/ 
t1XAXT 
, tnXBXT 
\ 
(tut2) = E le^t— + ^ ^ J 
/
t1XAXT 
. t-jXBXT 
1 
/ 
e°* 
+ " ^ J
 
Γ exp -
(2π)*(Λ*Σ)4 
V 
χ Σ - 1 χ Τ Ν 
dx . 

DISTRIBUTION OF QUADRATIC FORMS OF MULTIVARIATE NORMAL VECTORS 
3 0 7 
In this case, we have that detT, = σ 
and Σ 
= ^1. So that: 
f 
«1χΛ* Τ+ί 2«Β« Τ 
1 
/ 
X X
T \ 
m(ii'i2) = r 
- 
(7^r e x pr^"j d x 
1 
ΛΟΟ 
/-OO 
/ t , x A x T 
t a x B » T 
* * ^ \ 
= 
. 
/-Λη 
/ 
·■·/ 
e ™ 
^ ~ 
'^rJdx1,dx2,---,dxn 
(σν2π) J-oo ./-oo 
i 
/·οο 
/·οο 
/ 
x(f-2ti A-ataB)x T'\ 
= 
7—ι=ςη 
· · · / 
e ^ 
2" 
'dxi,dx2,··· 
,dxn . 
\σ\/2π) 
J-ao 
J-oo 
The matrix 7 - 2ii.A — 2i 2# is a positive definite matrix if |ii| and |*21 are 
sufficiently small, for example, |ii| < hi and |<2| < h2 with hi, h2 > 0. Hence: 
m{ti,t2) 
= [det(I - 2txA - 2t2B)]~* 
. 
If XAXT and XBXT 
are stochastically independent, then AB — 0. Indeed, 
if XAXT 
and XBXT 
are independent, then m(ii,i2) = Tn(ti,0) m(0, t2) for 
all ti,<2 with |ίχ| < hi and \t2\ < h2. That is, 
det(I - 2tiA - 2t2B) = det(I - 2txA) ■ det(I - 2t2B) 
where ti,t2 satisfy |ii| < hi and \t2\ < h2. 
Let r = rank(A) and suppose that λχ, \2,..., 
λΓ are r eigenvalues of A 
different than zero. Then there exists an orthogonal matrix L such that: 
Suppose that LTBL 
— ( „ η 
,..12 1 = D. Then, the equation 
\ ^ 2 1 
^ 2 2 / 
det{I - 2tiA - 2t2B) = det(I - 2txA) ■ det(I - 2t2B) 
may be rewritten as 
det{LT)det{I 
- 2tiA - 2t2B)det{L) 
= det(LT)det{I 
- 2tiA)(detL) ■ 
det(LT)det{I 
- 
2t2B)detL 
or equivalently: 
det (LT(I - 2tiA - 2t2B)L) = det{LT{I - 2tiA)L)det{LT(I 
- 2t2B)L) . 
That is: 
det(I - 2txC - 2t2D) = det(I - 2tiC)det(I - 2t2D) . 

308 
MULTIVARIATE NORMAL DISTRIBUTIONS 
Given that the coefficient of (—2ti)r on the right side of the previous equation 
is λιλ2 · ■ · \Tdet(I — 2t2D) and the coefficient of (—2ti)r on the left side of 
the equation is 
λχλ2 · · · Xrdet(In-r 
— 2i2-Ö22) 
where In-\ is the (n — r)-order identity matrix, then, for all t2 with \t2\ < h2, 
det(I — 2t2D) = det(In-r 
— 2t2D22) must be satisfied and consequently the 
nonzero eigenvalues of the matrices D and D22 are equal. 
On the other hand, if A = (a.ij)nxn 
is a symmetric matrix, then / ^ / J a f , 
3 
i 
is equal to the sum of the squares of the eigenvalues of A. Indeed, let L be 
such that LTAL = diag(\i,\2, 
■ · ■ , λ η). Then: 
tr (LTAL)(LTAL)) 
= tr(LTA2L) 
= tr{A2) = £
^
4 ■ 
3 
i 
Therefore, the sum of the squares of the elements of matrix D is equal to the 
sum of the squares of the elements of matrix D22· Thus: 
D=(° 
° V 
[p 
D22)· 
Now 0 = CD = LTAL ■ LTBL = LTABL 
and in consequence AB = 0. 
Suppose now that AB = 0. Let us verify that 
XJj£ 
and XBJi 
are 
stochastically independent. We have that: 
(I - 2hA){I - 2t2B) 
= I - 2t2B - 2 M + 
Aht2AB 
= I-2t2B-2hA 
. 
That is: 
det(I - 2t2B - 2hA) = det(I - 2hA)det(I 
- 2t2B) . 
Therefore: 
m(ti,t2) 
= m(ii,0) · m(0, t2) . 
In summary, we have the following result: 
Theorem 7.6 Let X\,X2,··· 
,Xn - i.i.d. random variables with 
Af(0,σ2). 
Let A and B be symmetric matrices and X = (Xi,X2, ■ ■ ■ ,Xn)- 
Then, the 
quadratic forms XAXT 
and XBXT 
are independent if and only if AB = 0. 
EXERCISES 
7.1 
Let X = (X, Y) be a random vector having a bivariate normal distri-
bution with parameters μχ = 2, μγ = 3.1, σχ = 0.001, σγ = 0.02 and p = 0. 
Find: 
Ρ (1.5 < X < 2.3, 7.3 < Υ < 7.8) . 

EXERCISES 
309 
7.2 
Suppose that ΛΊ and X2 are independent λί(0,1) 
random variables. 
Let ΥΊ = λΊ + 3λ"2 - 2 and Y2 = Xi - 2X2 + 1. Determine the distribution 
ofY = (r 1,r 2). 
7.3 
Let X = (λ"ι, X2) be a multivariate normal with μ = (5,10) and Σ — 
[\ 
aA. If Y1 = 2ΛΊ + 2X2 + 1 and Y2 = 3Xi - 2 * 2 - 2 are independent, 
determine the value of a. 
7.4 
Let X = (Xi, ■ · ■ ,Xn) 
be an n-dimensional random vector such that 
X = Λί (μ, Σ), where Σ is a nonsingular matrix. Prove that 
Y := (X - μ) W~x 
is a random vector with a Af (0, /) distribution, where / is the identity matrix 
of order n and W is a matrix satisfying W2 = Σ. In this case, we say that 
the vector Y has a standard multivariate normal distribution. 
7.5 
Let X = (X, Y) be a random vector with bivariate normal distribution. 
Prove that the conditional distribution of Y, given that X — x, is normal with 
parameters μ given by 
μ = E (Y) + p (X, Y) ^
Ξ 
(X - EX) 
and σ2 given by 
a2 = (VarX)(l-p(X,Y)) 
. 
7.6 
Let X = (Χχ,Χ2) 
be multivariate normal with μ = (1,-1) and Σ = 
Let Y1=X1-X2-2 
and Y2=Xi+ 
X2. 
(Π)· 
a) Find the distribution of Y = (ΥΊ, Y2). 
b) Find the density function /y(j/i,j/2)· 
7.7 
Suppose that X is multivariate normal λί(μ, Σ) where μ — 1 and: 
CO-
Find the conditional distribution of X\ + X2 given X\— X2= 0. 
7.8 
Let X = {Xi,X2,X$) 
be a random vector with normal multivariate 
distribution of parameters μ = 0 and Σ given by: 

310 
MULTIVARIATE NORMAL DISTRIBUTIONS 
Find P{XX > Q,X2 > 0,X3 > 0). 
7.9 
Let X — (X\,X2,X3) 
be a random vector with normal multivariate 
distribution of parameters μ = 0 and Σ given by: 
5 
2 
2 
6 
- 2 
3 
- 2 
3 
8 
Find the density function / (#ι, x2, Χ3) of X. 
7.10 
The random vector X has three-dimensional normal distribution with 
mean vector 0 and covariance matrix Σ given by: 
2 
0 
-1 
0 
3 
1 
1 
5 
1 
2 
-1 
2 
4 
0 
0 
7 
Find the distribution of X2 given that X\ — ΧΆ = 1 and X2+ X3 = 0. 
7.11 
The random vector X has three-dimensional normal distribution with 
expectation 0 and covariance matrix Σ given by: 
Σ = 
Find the distribution of X3 given that X\ = 1. 
7.12 
The random vector X has three-dimensional normal distribution with 
expectation 0 and covariance matrix Σ given by: 
Σ = 
Find the distribution of X2 given that X\ + X3 = 1. 
7.13 
Let X = λί{μ, Σ), where: 
2 
1 
-1 
1 
3 
0 
0 
5 
3 
-2 
1 
- 2 
2 
0 
0 
2 
(2 
0 
1) 
and 
Σ 
Determine the conditional distribution of X\ — X3 given that X2 = —1. 
7.14 
The random vector X has three-dimensional normal distribution with 
mean vector μ and covariance matrix Σ given by: 
μ = (1 0 
-2) 
and 
Σ = 

EXERCISES 
3 1 1 
Find the conditional distribution of X\ given that Xi = —X2-
7.15 
The random vector X has three-dimensional normal distribution with 
expectation 0 and covariance matrix Σ given by: 
Σ = 
Find the distribution of X2 given that Xi = X2 = Xs-

CHAPTER 8 
LIMIT THEOREMS 
The ability to draw conclusions about a population from a given sample and 
determine how reliable those conclusions are plays a crucial role in statistics. 
On that account it is essential to study the asymptotic behavior of sequences 
of random variables. This chapter covers some of the most important results 
within the limit theorems theory, namely, the weak law of large numbers, 
the strong law of large numbers, and the central limit theorem, the last one 
being called so as a way to assert its key role among all the limit theorems in 
probability theory (see Hernandez and Hernandez, 2003). 
8.1 
THE WEAK LAW OF LARGE NUMBERS 
When the distribution of a random variable X is known, it is usually possi-
ble to find its expected value and variance. However, the knowledge of these 
two quantities do not allow us to find probabilities such as P (\X — c\ > e) 
for e > 0. In this regard, the Russian mathematician Chebyschev proved 
an inequality, appropriately known as Chebyschev's inequality (compare with 
exercise 2.48 from Chapter 2), which offers a bound for such probabilities. 
Introduction to Probability and Stochastic Processes with Applications, 
First Edition. 
313 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

314 
LIMIT THEOREMS 
Even though in practice it is seldom used, its theoretical importance is un-
questionable, as we will see later on. 
Chebyschev's inequality is a particular case of Markov's inequality (com-
pare with exercise 2.47 from Chapter 2), which we present next. 
Lemma 8.1 (Markov's Inequality) If X is a nonnegative random variable 
whose expected value exists, then, for all a > 0, we have: 
P(X>a)<^^-. 
(8.1) 
Proof: Consider the random variable / defined by: 
_ i l 
if 
X>a 
1 0 
otherwise 
Since X > 0, then I < —, and taking expectations on both sides of this 
inequality we arrive at the desired expression. 
■ 
■ EXAMPLE 8.1 
Prom past experience, a teacher knows that the score obtained by a 
student in the final exam of his subject is a random variable with mean 
75. Find an upper bound to the probability that the student gets the 
score greater than or equal to 85. 
Solution: Let X be the random variable defined as follows: 
X := "Score obtained by the student in the final exam". 
Since X is nonnegative, Markov's inequality implies that: 
P (X > 85) < 0.88235 . 
▲ 
EXAMPLE 8.2 
Suppose that X is a random variable having a binomial distribution with 
parameters 5 and | . Use Markov's inequality to find an upper bound to 
P(X > 2). Compute P(X > 2) exactly and compare the two results. 
Solution: We know that E(X) 
= §, and therefore, from Markov's 
inequality: 
P(X>2)<1-

THE WEAK LAW OF LARGE NUMBERS 
3 1 5 
On the other hand: 
P {X > 2) = 1 - P (X = 0) - P (X = 1) 
= 0.53909 . 
These results show that Markov's inequality can sometimes give a rather 
rough estimate of the desired probability. ▲ 
In many cases there is no specific information about the distribution of the 
random variable X and it is in those cases where Chebyschev's inequality can 
offer valuable information about the behavior of the random variable. 
Theorem 8.1 (Chebyschev's Inequality) Let X be a random variable such 
that Var (X) < oo. Then, for any e > 0, we have: 
P{\X-E{X)\>e)<^Var(X). 
Proof: Let Y := \X — E(X)\ 
and a = e2. Markov's inequality yields 
E(\X-E(X)\2) 
! 
P(\X - E(X)\ >e)< -Λ 
_ 
L = -Var(X) , 
(8.2) 
which completes the proof. 
■ 
Clearly, (8.2) is equivalent to: 
P (\X - E{X)\ < e) > 1 - ^Var (X). 
Likewise, taking e := ak, with k > 0 and σ :— y/Var (X), we obtain: 
P(\X-E(X)\>ak)<±. 
If in (8.2) E(X) is replaced by a real number C, we obtain: 
E(\X-C\2) 
The above expression is also called "Chebyschev's inequality" (see Meyer, 
1970). 
Note 8.1 In (8.1) and (8.2) we can replace P{X > a) and P{\X - E(X)\ > 
e) with P(X > a) and P(\X — E(X)\ > e), respectively, and the inequalities 
will still hold. 

316 
LIMIT THEOREMS 
■ EXAMPLE 8.3 
Is there any random variable X for which 
Ρ(μχ 
-2σχ<Χ<μχ+ 
2σχ) = 0.6 
(8.3) 
where μχ and σχ are the expected value and standard deviation of X, 
respectively? 
Solution: It follows from Chebyschev's inequality that: 
Ρ(μχ 
-2σχ<Χ<μχ+ 
2σχ) = P(\X- 
μχ\ < 2σχ) > | . 
Hence, there cannot be a random variable X satisfying (8.3). 
A 
■ EXAMPLE 8.4 
Show that if Var (X) = 0, then P (X = E(X)) = 1. 
Solution: Chebyschev's inequality implies that for any n > 1: 
P(\X-E(X)\ 
> - ) 
= 0 . 
Taking the limit when n —> co, we get: 
0 = lim P (\X - E(X)\ > - ) = P ( lim ί\Χ-Ε(Χ)\> 
-X) 
n-too 
γ 
nj 
\n-+oo \ 
n)J 
= Ρ{ΧφΕ{Χ)) 
. 
In other words, P (X = E(X)) = 1 . 
▲ 
The weak law of large numbers can be obtained as an application of 
Chebyschev's inequality. This is one of the most important results in probabil-
ity theory and was initially demonstrated by Jacob Bernoulli for a particular 
case. The weak law of large numbers states that the expected value E(X) of a 
random variable X can be considered an "idealization", for "large enough" n, 
of the arithmetic mean X := X'~l"'n'+X", where X\,··· 
,Xn are independent 
and identically distributed random variables with the same distribution of X. 
In order to state this law, we need the following concept: 
Definition 8.1 (Identically Distributed Random Variables) Χχ,Χι, 
■ ■ ■ 
is said to be a sequence of independent and identically distributed random vari-
ables if: 
1. For any n £ Z + we have that Χχ, ■ · ■ , Xn are independent random vari-
ables. 
2. For any i,j € Z +, Xi and Xj have the same distribution. 

THE WEAK LAW OF LARGE NUMBERS 
317 
Note 8.2 The previous definition can be generalized to random vectors as 
follows: It is said that Xi, X2, ■ ■ ■ is a sequence of independent and identically 
distributed random vectors if: 
1. For any n € Z + we have that Xi, · · · ,X„ are independent random vec-
tors. 
2. For any i,j G Z + , X* and Xj have the same distribution. 
Theorem 8.2 (The Weak Law of Large Numbers (WLLN)) Let 
Xi,X2,··· 
be a sequence of independent and identically distributed random 
variables with mean μ and finite variance σ2. Then, for any e > 0, we have 
that 
z 
(* 
/ 
ne* 
from which we obtain that for any e > 0: 
l i m P 
n—voo 
n 
> e 
0 . 
Proof: Let Xn := χ»+·^·+χ" be the arithmetic mean of the first n random 
variables. Clearly E (Xn) — μ and Var {Xn) = ^-. Chebyschev's inequality 
implies that for any e > 0 we must have: 
Var(JQ 
P{\Xn-E(Xn)\>e)< 
which is exactly what we wanted to prove. 
■ 
Note 8.3 It is possible to prove the weak law of large numbers without the 
finite variance hypothesis. 
That result, due to the Russian 
mathematician 
Alexander Khinchin (1894-1959), states the following [see Hernandez (2003) 
for a proof]: 
If X\, X2, ·■ ■ is a sequence of independent and identically distributed ran-
dom variables with mean μ, then, for any e > 0, we have that: 
lim P | 
n—>oo 
Χι + ··· + Χη -p 
> ■) - 0 
As a special case of the weak law of large numbers we obtain the following 
result: 
Corollary 8.1 (Bernoulli's Law of Large Numbers) Let Χ-ι,Χ^, ■ · · be 
a sequence of independent and identically distributed random variables having 
a Bernoulli distribution with parameter p. Then, for any e > 0, we have 
OH*«) 
> e 
< 4ne2 
(8.4) 

318 
LIMIT THEOREMS 
where Kn :— X\ + ■ ■ ■ + Xn-
Proof: The weak law of large numbers implies that: 
GH*·) 
>e) < p(l-p) 
ne' 
Since p € (0,1), then p (1 — p) < | and consequently (8.4) holds. 
■ 
Note 8.4 Bernoulli's law states that when a random experiment with only 
two possible results, success or failure, is carried out for a number of times 
large enough, then, for any e > 0, the set of results for which the proportion of 
successes is at a distance greater than e of the probability of success p tends to 
zero. Observe that Bernoulli's law does not assert that the relative frequency 
of successes converges to the success probability as the number of repetitions 
increases. Even when the latter is true, it cannot be directly inferred from 
Bernoulli's law. 
Note 8.5 Bernoulli's law was proved by means of the weak law of large num-
bers, which in turn rests upon Chebyschev's inequality. However, the original 
proof given by Bernoulli states that, for arbitrary e > 0 and 0 < δ < 1, we 
have 
where n > 
n > 12416 mplie. 
' ( 
Kn 
n -p 
< e J > 1 - δ 
In (|) + j . For example, if e = 0.03 and δ = 
s: 
' ( 
Kn 
n - -p < 0.03 j > 0.99998 . 
= 0.00002, then 
That is, if the experiment is repeated at least 12,416 times, we can be at least 
99.998% sure that the success ratio will be less than 3% away from the success 
probability p. 
According to Hernandez (2003), Italian mathematician 
Francesco Paolo 
Cantelli (1875-1966) proved an even stronger result, namely, that if n > 
(^)^(^)+2:=N,then 
n 
n=N 
Kn 
-p 
< e 
>1-δ 
and thus, for e = 0.03 and δ = 0.00002, n > 42711 implies that: 
Kn 
n 
< 0.03 
> 0.99998 . 

CONVERGENCE OF SEQUENCES OF RANDOM VARIABLES 
319 
8.2 
CONVERGENCE OF SEQUENCES OF RANDOM VARIABLES 
Let X, X\, X2, ■ ■ ■ be real-valued random variables all defined over the same 
probability space. In this section three important and common modes of 
convergence of the sequence (-^n)n to X will be defined. It is important, 
however, to clarify that there exist other modes of convergence different from 
those studied here (in this regard, see, Bauer, 1991). 
Definition 8.2 (Convergence in Probability) Let Χ,Χχ,Χ^,··· 
be real-
valued random variables defined over the same probability space (Ω, Q, P). It 
is said that (Xn)n 
converges in probability to X and write 
X
n - ^ X 
if, for any e > 0, the following condition is met: 
limP(\Xn-X\ 
> e ) = 0 . 
n—yoo 
Note 8.6 Making use of the last definition, we can express the weak law of 
large numbers as follows: If X\,X2, 
■· ■ is a sequence of independent and 
identically distributed random variables with mean μ and finite variance σ2, 
then 
Xn 
>μ , 
n—>oo 
where Xn represents the arithmetic mean of the first n random variables. 
■ EXAMPLE 8.5 
Let (Xn)n&z+ 
D e a s eq u e nce of random variables such that 
P ( X n = 0) = 1 - £ and P{Xn=n) 
= £, for n= 1,2,···. Let e > 0. 
Then: 
P(\Xn\>e) = {l 
*
e <
n . 
10 
if e > n 
Therefore: 
limPflXnl >e) = 0 . 
n—yoo 
Thus: 
Xn —^-v 0 . 
A 
n—yoo 

320 
LIMIT THEOREMS 
EXAMPLE 8.6 
A fair dice is thrown once. For each n = 1,2, · · ·, we define the random 
variable Xn by 
J 1 if the result obtained is tail 
10 if the result obtained is head 
and let X be the random variable given by: 
' the result obtained is head 
fl 
ifi 
~ [0 
if 1 
X 
the result obtained is tail . 
Clearly, for all n = 1,2, · ■ ·, we have: 
\Xn~X\ = l-
Hence 
and therefore: 
(i*. x | > i | = i 
Xn-$^X 
. 
η—ϊοο 
A useful result to establish the convergence of a sequence of random variables 
is the following theorem, whose proof is omitted. We encourage the interested 
reader to see Jacod and Protter (2004) for a proof. 
Theorem 8.3 Let X, X\, X2, ■ ■ ■ be real-valued random variables defined over 
the same probability space 
following expression holds: 
p 
the same probability space (Ω,Ο, Ρ). 
Then Xn 
> X if and only if the 
n-yoo 
\ \ + 
\Xn-X\) 
Definition 8.3 (Convergence in Lr) LetX,Xi,X2,·" 
be real-valued ran-
dom variables defined over the same probability space (Ω,3, P). 
Let r be 
a positive integer such that E(\X\r) 
< 00 and E(\Xn\r) 
< 00 Vn. 
Then 
If 
Xn 
> X if and only if the following expression holds: 
n—*oo 
lim E (\Xn - X\r) = 0 . 

CONVERGENCE OF SEQUENCES OF RANDOM VARIABLES 
321 
EXAMPLE 8.7 
Let Χι,Χϊ,··· 
be a sequence of independent and identically distributed 
random variables with mean μ and finite variance σ2. Let 
-γ 
X\ + · · · + Xn _ Sj^ 
n 
n 
where Sn = Χχ Η 
h Xn- Now: 
E 
Sn 
μ 
Hence: 
E 
(Sn - ημ)' 
1 
= 
^Var(Sn) 
= -^ησ 2 
> 0 . 
1 
X 
> μ. 
EXAMPLE 8.8 
Consider Example 8.5. Since P (Xn = 0) = 1 - \ and P (Xn = n) = £, 
for n = 1,2, · · · , we get E(Xn) 
= 1. Hence, Xn 
/ 
> 0 whereas 
Xn 
->0. 
Theorem 8.4 Let r > 0, X,Xi,X2,... 
be a sequence of random variables 
Lr 
P 
such that Xn 
> X- This implies Xn 
> X. 
n—>oo 
n—*oo 
Proof: Chebyschev's inequality implies that for any e > 0 we must have: 
E{\Xn-X\r) 
P{\Xn-X\>t)< 
Hence, the proof. 
-+0 . 
EXAMPLE 8.9 
Let (Ω, 9, P) = ([0,1], B([0,1]), λ([0,1])) where ß([0,1]) is the Borel σ-
algebra on [0,1] and λ([0,1]) is the Lebesgue measure on [0,1]. Let 
v ( \ _ / 
2" 
if 0 < ω < 1/n 
*n{W) - j 
0 
Q t h e r w i s e 

322 
LIMIT THEOREMS 
Then for all e > 0: 
P (|*»| > c) = P ((0,1/n)) = - 
► 0 . 
n 
n—voo 
That is, Xn
 
P > 0. But: 
n—»oo 
£?(|Χ„Γ) = 2 η Γ - 
>oo. 
▲ 
n 
n—yoo 
Another mode of convergence that will be covered in this section is almost 
sure convergence, a concept defined below. 
Definition 8.4 (Almost Sure Convergence) Let X, Χχ, X?,· ■ ■ be 
real-valued random variables defined over the same probability space (Ω, 3 , P). 
We say that (Xn)n 
converges almost surely (or with probability I) to X and 
write 
X
n - ^ X 
n—>-oo 
if the following condition is met: 
p(]imXn 
= 
x)=l. 
In other words, if A := {ω € Ω : Xn (ω) —> X (ω)}, then: 
Xn -
^ 
X 
if and only if P(A) = 1 . 
EXAMPLE 8.10 
Let (Ω,3ί, Ρ) be an arbitrary probability space and let (Xn)n be the 
sequence random variables defined over (Ω, 3 , P) as follows: 
Xn : Ω —> 
R 
ω 
—► 1 + 1 
Clearly, for all ω 6 Ω, we have: 
lim Xn (ω) = 1. 
Therefore, 
Ρ({ω € Ω : Xn (ω) —> 1}) = Ρ(Ω) = 1 , 
which implies: 
Xn - ^ ^ 1 . 
A 

THE STRONG LAW OF LARGE NUMBERS 
323 
8.3 
THE STRONG LAW OF LARGE NUMBERS 
The following result, known as the strong law of large numbers, states that 
the average of a sequence of independent and identically distributed random 
variables converges, with probability 1, to the mean of the distribution. 
The proof of this law requires the following lemma [see Jacod and Protter 
(2004) for a demonstration]: 
Lemma 8.2 Let Xi,Ä2,··· 
be a sequence of random variables. 
We have 
that: 
1. If all the random variables Xi are positive, then 
(
oo 
\ 
oo 
Σ*η 
) = $ > ( * „ ) 
(8.5) 
n=l 
/ 
n=l 
where the expressions in (8.5) are either both finite or both infinite. 
oo 
oo 
2. If yjiTQ-Xnl) < oo, then /"_]-Xn converges almost surely and (8.5) 
n = l 
n = l 
holds. 
Theorem 8.5 (The Strong Law of Large Numbers (SLLN)) Let 
Xi) -^2! · · · be a sequence of independent and identically distributed random 
variables with finite mean μ and finite variance σ2. 
Then: 
-=— 
X\ + X2 + · · ■ + Xn 
a.s. 
Xn = 
> μ. 
Proof: (Jacod and Protter, 2004) Without loss of generality, we can assume 
that μ = 0. 
Since E ( JQ ) = 0, 
and E (XjXk) 
= 0 for j φ k, then (9.7) equals: 
B{m2) = ±±EW) 
σ 
n 
2 
Therefore: 
WmE([X^]2)=Q. 

324 
LIMIT THEOREMS 
Moreover, E I [ Xn ] J = ^- implies that: 
oo 
c_ 
oo 
2 
n=l 
Prom Lemma 8.2, we have 
n = l 
y] [ Xna ] < oo with probability 1 
n = l 
and consequently lim Xna = 0 with probability 1. 
n—>oo 
Let n G N and A;n be an integer such that: 
[knf <n<[kn 
+ l] 2 . 
Then 
so that: 
-γτ- 
[kn\ -y— 
1 
^-v 
j=k*+l 
£ 
A n 
—A f c3 
n 
"~*£ga 
2fcn + l 
2 
- 
2 
° 
2y^T+l 
2 
- 
2 
σ 
3σ2 
vV 
Accordingly, 
Σ* 
n=l 
[fcn 
Ί 2 \ 
- ^ f c ä 
^ 3 < τ
2 
< 2 ^ ^ 7 = F 
< 0 0 
n = l ' 
and another application of Lemma 8.2 yields 
from which: 
Σ 
n=l 
lim 
n—voo 
~γ~ ft" I -γ 
A „ 
Afc2 
n 
"v^~ 
ί"-η] "V— 
Λ « 
Afc2 
< oo with probability 1 
0 
with probability 1 . 

THE STRONG LAW OF LARGE NUMBERS 
325 
Since lim X& = 0 and lim ^-!LL- = 1 then, with probability 1, we conclude 
n—»co 
" 
n—>oo 
n 
that lim Xn = 0, which completes the proof for the case μ = 0. If μ φ 0, it 
π—κχ> 
suffices to consider the random variables defined, for i = 1,2,···, by 
Zi := Xi - μ 
and apply the result to the sequence thus obtained. 
■ 
The last mode of convergence presented in this text, known as convergence 
in distribution, is most widely used in applications. 
Definition 8.5 (Convergence in Distribution) LetX, Χχ,Χ^, · · · be real-
valued random variables with distribution functions F, Fi, F?, · · ·, respectively. 
It is said that (Xn)n 
converges in distribution to X, written as 
Xn 
► X ! 
n—*oo 
if the following condition holds: 
lim Fn (x) = F (x) 
for any point x where F is continuous 
n—ioo 
or, equivalently, 
Xn ——> X 
if and only if 
lim P {Xn < x) = P (X < x) 
n—»oo 
n—>oo 
for any point x where F is continuous. 
Note that convergence in distribution, just like the other modes of conver-
gence previously discussed, reduces itself to the convergence of a sequence of 
real numbers and not to the convergence of a sequence of events. 
■ EXAMPLE 8.11 
Let (Ω, 3, P) be a probability space, (Xn)n 
be the sequence of random 
variables over (Ω, 3, P) defined as 
Xn : Ω —> R 
« 
—► k 
n 
and X = 0. Assume: 
„ . . 
fl 
if 
x > i 
Fn (x) 
= 
< 
~ n 
I 0 
otherwise 
π , . 
fl 
if 
x>0 
F(x) 
= < 
0 
otherwise 

326 
LIMIT THEOREMS 
We have for each x φ 0: 
lim Fn (x) 
=F(x). 
In other words: 
X„ -J-^ 
0 . 
A 
n—»oo 
Note 8.7 If Χ,Χχ,Χ2, 
· · ■ are random variables with values in N, then: 
Xn —^—>■ X 
if and only if 
lim P (Xn = k) = P (X = k) for all 
keN. 
n—yoo 
n—voo 
The following theorem relates convergence in distribution with convergence 
of the characteristic functions. Its proof is beyond the scope of this text and 
the reader may refer to Hernandez (2003) or Rao (1973). 
Theorem 8.6 (Levy and Cramer Continuity Theorem) Let 
X,ΧΙ,ΧΪ,··· 
be real-valued random variables defined over the same prob-
ability space (Ω,9ί,Ρ) and having the characteristic functions φ,φ\,φ2,· 
■ ■ 
respectively. Then: 
Xn 
> X if and only if lim φη (t) = φ (t) for all t 6 K . 
n—voo 
n—foo 
We proceed now to establish the major links between the convergence 
modes defined so far, namely, we will see that: 
Xn -^-+ 
X => Xn —£-► X => Xn —^ 
X . 
n—>oo 
n—>oo 
n—»oo 
Theorem 8.7 Let Χ,Χχ,Χ^,··· 
be real-valued random variables defined over 
the same probability space (Ω, 3, P). 
Then: 
Xn -^-+ 
X => Xn —?-> X . 
n—yoo 
n—foo 
Proof: Let e > 0. The sets 
Ak := {ω e Ω : \X„ (ω) - X (ω)\ < e for all 
n>k} 
form an increasing sequence of events whose union 
Ax> := \jAk 
fc=l 
contains the set 
A := ίω e Ω : lim Xn («) = X (ω)\ 

THE STRONG LAW OF LARGE NUMBERS 
327 
By hypothesis P (A) = 1, from which we infer that P (A») = 1. On the other 
hand, it follows from the continuity of P that: 
limP(Ak) 
= P(AOU) = l . 
k—yoo 
Since 
0<P(\Xk-X\>e)<P(Ac
k) 
and 
limP(Ac
k)=0 
Ac—»oo 
we conclude that: 
Xn-^X 
. 
n—>oo 
Theorem 8.8 Let X, Χι, Χ2, · · · be real-valued random variables defined over 
the same probability space (Ω, 3 , P) with distribution functions F, F\, F2, ■ ■ ■ 
respectively. Then: 
Xn — 
^ X ^^" Xn 
—^ X ■ 
n—yoo 
n—KX) 
Proof: Let i b e a point of continuity of F. We need to prove that 
lim Fn (x) = F (x). Since F is continuous at x, then, for any e > 0, there 
n—»-oo 
exists a i > 0 such that: 
F(x + 
S)-F(x)<e-
F ( x ) - F ( x - i ) < | . 
p 
On the other hand, since Xn 
> X, then there exists n (e) € N such that, 
for n > n (e), the following condition is satisfied: 
Ρ{\Χη-Χ\>δ)<1· 
Furthermore, we have that: 
(*„ < χ) = [(Xn < χ) n (\xn -x\< 
δ)} u [(xn <χ)η (\χη -χ\> δ)} 
c (x < x + δ) u {\xn - x\ > δ) . 
Analogously: 
{X < x - δ) C (Xn < x) U (|X„ - X\ > δ) . 

328 
LIMIT THEOREMS 
Almost 
Convergence 
Convergence 
in Probability 
Convergence 
in Distribution 
Convergence in L· 
Convergence in L 
<c 
means: X„ -^- χ then there exists a subsequence nk 
such that „ U ^ * " * almost surely 
Figure 8.1 Relationship between the different modes of convergence 
Thus: 
F{x)-e<F(x-o)-
<Ρ(Χη<χ) 
+ 
Ρ(\Χη-Χ\>δ)--
<P(Xn<x) 
<F(x + 6) + -
<F(x) + e . 
That is, for all n > n (e), we have that 
\Fn(x)-F(x)\<e 
and consequently: 
lim Fn (x) = F (x) . 
Note 8.8 The converse of the above theorem is not, in general, true. Con-
sider, for example, the random variables given in Example 8.6. In that case, 
we have Xn 
> X, but Xn —/—> X. 
n—κχ> 
n—yoo 
Figure 8.1 summarizes the relationship between the different modes of con-
vergence. In this figure, the dotted arrow means that the convergence in prob-
ability does not imply the convergence in almost surely. However, we can 

CENTRAL LIMIT THEOREM 
329 
prove that there is a subsequence of the original sequence that converges al-
most surely. 
All the definitions given so far can be generalized to random vectors in the 
following way: 
Definition 8.6 (Convergence of Random Vectors) Let X, Xi, X2, 
■be 
k-dimensional random vectors, k € N, having the distribution 
functions 
Fx, Fxi, F x 2 1 ' ' ' > respectively. Then, it is said that: 
1. (X„)„ converges in probability to X, written as X n 
> X, if the ith 
n—>oo 
component o/X n converges in probability to the ith component o/X for 
each i = 1,2, · · · ,k. 
2. (X„)n converges almost surely (or with probability I) to X, written as 
X n —'——> X, if the ith component o/X n converges almost surely to the 
n—foo 
ith component of X for each i = 1,2, · · · , k. 
3. (Xn)„ converges in distribution to X, written as X n 
> X, if 
n-KX> 
limn_+00 Fx n (x) = Fx (x) for all points x = (xi, ■ · · ,Xk) € Rk of con-
tinuity of Fx (·). 
8.4 
CENTRAL LIMIT THEOREM 
This section is devoted to one of the most important results in probability 
theory, the central limit theorem, whose earliest version was first proved in 
1733 by the French mathematician Abraham DeMoivre. In 1812 Pierre Simon 
Laplace, also a French mathematician, proved a more general version of the 
theorem. The version known nowadays was proved in 1901 by the Russian 
mathematician Liapounoff. 
The central limit theorem states that the sum of independent and identi-
cally distributed random variables has, approximately, a normal distribution 
whenever the number of random variables is large enough and their variance 
is finite and different from zero. 
Theorem 8.9 (Univariate Central Limit Theorem (CLT)) Let 
^i!-^2, · · · be a sequence of independent and identically distributed random 
n 
variables with mean μ and finite variance σ2. Let Sn := / J ^ j 
and Yn '■= 
i=i 
n
a~J£'■ Then, the sequence of random variables Yi,Y2,··· converges in dis-
tribution to a random variable Y having a standard normal distribution. 
In 
other words: 
lim P ( 
η~™μ 
<χ] 
= φ(χ) for all x € R . 

330 
LIMIT THEOREMS 
Proof: 
Without loss of generality, it will be assumed that μ = 0. Let φ 
be the characteristic function of the random variables X\, X2, ■ ■ · · Since the 
random variables are independent and identically distributed, we have that: 
<t>Yn(t) = 
E(exp\itYn]) 
E (exp it-
E ΠβχΡ 
U=i 
it xj -
Oy/n 
j = l 
V 
Xj 
it -*-
Cy/n 
Φ 
Expansion of φ in a Taylor series about zero yields: 
φ(ί) = 
Ε(βΗΧ) 
v 
t2X2 
it3X* 
Ell 
+ itX 
—- + 
—r-
(' 
- 0 
2,2 
a't 
1+0 
— + t2o(t) . 
Thus: 
φγη (t) 
1 - τ ( ^ ) 2 + (^)2°(')_ 
- ( I - T ( ^ ) , - ( ^ ) " · « ; 
= exp 
Taking the limit when n —► 00 we get: 
lim φγη (t) = exp 
n—voo 
*21 
The Levy-Cramer continuity theorem implies that 
Yn 
->Y, 
where Y is a random variable having a standard normal distribution. 

CENTRAL LIMIT THEOREM 
3 3 1 
Note 8.9 The de Moivre-Laplace theorem (4-6) is a particular case of the 
central limit theorem. Indeed, if X\, Xi, · · · are independent and identically 
distributed random variables having a Bernoulli distribution of parameter p, 
then the conditions given in (8.9) are satisfied. 
Note 8.10 Let X\,X2, 
■ · ■ be a sequence of independent and identically dis-
tributed random variables with mean μ and finite positive variance σ2. 
The 
central limit theorem asserts that, for large enough n, the random variable 
n 
Sn := /J-Xj has, approximately, a normal distribution with parameters ημ 
3 = 1 
and ησ2. 
Note 8.11 The central limit theorem can be applied to most of the classic 
distributions, namely: binomial, Poisson, negative binomial, gamma, Weibull, 
etc., since all of them satisfy the hypotheses required by the theorem. How-
ever, it cannot be applied to Cauchy distribution since it does not meet the 
requirements of the central limit theorem. 
Note 8.12 There are many generalizations of the central limit theorem, among 
which the Lindenberg-Feller theorem stands out in that it allows for the se-
quence Xi, ^ 2 J · ·' of independent random variables with different means Ε{Χΐ) -
ßi and different variances Var(X{) = σ2. 
Note 8.13 (Multivariate Centred Limit Theorem) The central limit 
theorem can be generalized to sequences of random variables as follows: 
Let Xi,X2, · · · be a sequence of k-dimensional independent and identically 
distributed random vectors, with k € N, having mean vector μ and variance-
covariance matrix Σ, where Σ is positive definite. Let 
γ - _ Xi + X2 + 
l· 
X n 
n 
be the vector of arithmetic means. Then 
s/n (X^ - μ) 
>■ X , 
n—>-oo 
where X is a k-dimensional random vector having a multivariate normal dis-
tribution with mean vector 0 and variance-covariance matrix Σ. (See Her-
nandez, 2003). 
Some applications of the central limit theorem are given in the examples 
below. 
■ EXAMPLE 8.12 
A fair dice is tossed 1000 times. Find the probability that the number 
4 appears at least 150 times. 

332 
LIMIT THEOREMS 
Solution: Let X :— "Number of times that the number 4 is obtained". 
We know that X = B (1000, | ) . Applying the de Moivre-Laplace theo-
rem, we can approximate this distribution with a normal distribution of 
mean ±^°- and variance ^fj0-. Therefore: 
(
X _ 5Q0 
i en 
500 \ 
« 1 - Φ ( - 1 . 4 1 4 2 ) 
« 1 - 0.07865 
» 0.9213 . 
A 
■ EXAMPLE 8.13 
Suppose that for any student the time required for a teacher to grade 
the final exams of his probability course is a random variable with mean 
1 hour and standard deviation 0.4 hours. If there are 100 students in 
the course, what is the probability that he needs more than 110 hours 
to grade the exam? 
Solution: Let Xi be the random variable representing the time required 
by the teacher to grade the ith student of his course. We need to calcu-
100 
late the probability that T := Σ^ί 
greater than 110. By the central 
i=l 
limit theorem, we have: 
P(T>no) 
= p(J~m 
> 
n°-100) 
K 
' 
\>/100x0.4 
VIOO x 0.4/ 
» 
1-Φ(1.5811) 
« 
1 - 0.9429 
« 
0.0571 . 
■ EXAMPLE 8.14 
(Wackerly et al., 2008) Many raw materials, like iron ore, coal and un-
refined sugar, are sampled to determine their quality by taking small 
periodic samples of the material as it moves over a conveyor belt. Later 
on, the small samples are gathered and mixed into a compound sample 
which is then submitted for analysis. Let Yi be the volume of the ith 
small sample in a particular lot, and assume that Yi, Y2, ■ · ■ , Yn is a ran-
dom sample where each Yi has mean μ (in cubic inches) and variance 

EXERCISES 
333 
σ2. The average volume of the samples can be adjusted by changing 
the settings of the sampling equipment. Suppose that the variance σ2 
of the volume of the samples is approximately 4. The analysis of the 
compound sample requires that, with a 0.95 probability, n = 50 small 
samples give rise to a compound sample of 200 cubic inches. Determine 
how the average sample volume μ must be set in order to meet this last 
requirement. 
Solution: The random variables ΪΙ,Υ^,··· ,Υ$ο are independent and 
identically distributed having mean μ and variance σ2 = 4. By the cen-
50 
tral limit theorem, J2 ^ί has, approximately, a normal distribution with 
i=l 
/ 5 0 
\ 
mean 50μ and variance 200. We wish to find μ such that P I Σ ^ΐ > 200 1 
0.95. Accordingly: 
0.95 = P ( Y^Yi > 200 J 
/ 50 
\ 
ΣΥί-50μ 
\ 
> 
V 
1 - Φ 
200 - 50/x 
ΙΟν^ 
" 
ΙΟν^ 
'200-50/xN 
/200-50/x\ 
V 10V2 
) ' 
That is, 
which in turn implies 
^ /200 - 50/Λ 
„ „„ 
Φ 
fJ- 
» 0.05 , 
V 
ΙΟν^ 
) 
200 - 50μ 
10^2 
-1.64 , 
from which we obtain: 
μ « 4.46 . 
EXERCISES 
8.1 
Suppose that 50 electronic components say D\, D2, · ■ · , D$o, are used in 
the following manner. As soon as D\ fails, £>2 becomes operative. When D? 
fails, D3 becomes operative, etc. Assume that the time to failure of Dj is an 
exponentially distributed random variable with parameter 0.05 per hour. Let 
T be the total time of operation of the 50 devices. Compute the approximate 
probability that T exceeds 500 hours using the central limit theorem? 

334 
LIMIT THEOREMS 
8.2 
Let X\,X2, 
· ■ ■ , Xn be n independent Poisson distributed random vari-
ables with means 1,2,·· , n, respectively. Find an x in terms of t such that 
i n 
2" 
n 
< t I « Φ(χ) for sufficiently large n 
where Φ is the cdf of JV(0, 1). 
8.3 
Suppose that Xi,i = 1,2,··· ,450, are independent random variables 
each having a distribution Λ/"(0,1). Evaluate P(X% + X\ + · ■ · + X450 > 495) 
approximately. 
8.4 
Let Y be a gamma distributed random variable with pdf 
f(y) = { J^' 
rfce-vy"-1 
if y > 0 
otherwise 
Find the limiting distribution of 
, 
' ' as p —> 00. 
8.5 
Let X ~ ß(n,p). Use the CLT to find n such that: 
P[X > n/2] > 1 - a. 
Calculate the value of n when a = 0.90 and p — 0.45. 
8.6 
A fair coin is flipped 100 consecutive times. Let X be the number of 
heads obtained. Use Chebyschev's inequality to find a lower bound for the 
probability that -^ differs from | by less than 0.1. 
8.7 
Let Χχ, X2, · · · , Χ50 be independent and identically distributed random 
variables having a Poisson distribution with mean 2.5. Compute: 
50 
Σ 
p (Σχ< >25 
8.8 
(Chernoff Bounds) Suppose that the moment generating function 
τηχ (t) of a random variable X exists. Use Markov's inequality to show that 
for any a € R the following holds: 
a) P(X>a)< 
exp (-ία) τηχ (t) for all t > 0. 
b) P{X <a) < exp (-ta) mx (t) for all t < 0. 
8.9 
(Jensen Inequality) Let / be a twice-differentiable convex real-valued 
function, that is, / (x) > 0 for all x. Prove that if X is a real-valued random 
variable, then 
E(f(X))>f(E{X)) 

EXERCISES 
335 
subject to the existence of the expected values. 
Hint: Consider the Taylor polynomial of / about μ = 
E(X). 
8.10 
If X is a nonnegative random variable with mean 2, what can be said 
about £(X 3) and £(lnX). 
8.11 
Let X,Χχ,Χ2,··· 
be real-valued random variables defined over the 
same probability space (Ω, 3, P). Show the following properties about con-
vergence in probability: 
a) Xn —£-► X if and only if (Xn - X) —^-> 0. 
n-*oo 
n—»oo 
b) If Xn —£-► X and X n —£-> y, then P(X = Y) = 1. 
n—too 
n—too 
c) If Xn —^-> X, then (Xn - X m) 
£—> 0. 
n—ί-οο 
η,τη—voo 
d) If X„ —£-► X and Yn —^-> y, then (Xn + Yn) —^-> (X -I- F). 
n—»-oo 
π—>οο 
η—»οο 
e) If Xn 
> X and k is a real constant, then kXn 
> kX. 
n—ί-oo 
n—*-oo 
f) If Xn —£-> X and y n —^-> y, then XnYn —£-> XT. 
n—>oo 
n—»oo 
n—foo 
8.12 
Let X,Xi,X2,··· be real-valued random variables denned over the 
same probability space (Ω, 9, P). Prove that: 
a) If X n - ^ - > X and Yn -=±-> y , then (Xn + y„) -^->· (X + Y). 
n—*oo 
n—»oo 
η—>οο 
b) If X n -^->· X and yn - ^ - > Y, then X ny n - ^ - > X y . 
8.13 
Let / be a continuous real-valued function and let X,Χχ,Χ2, · · · be 
real-valued random variables over the same probability space (Ω, 9f, P). Show 
that if X n - ^ - > X, then / (Xn) -^->- / (X). 
n - t o o 
n—»oo 
Note: The result still holds if almost sure convergence is replaced by conver-
gence in probability. 
8.14 
Let X,X!,X2,··· be real-valued random variables defined over the 
same probability space (Ω, S, P). Show that if X n 
> k, where A; is a real 
n—yoo 
p 
constant, then X„ 
> k. 
n—Kx> 
8.15 
Suppose that a Bernoulli sequence has length equal to 100 with a 
success probability of p = 0.7. Let X := "Number of successes obtained". 
Compute P ( X e [65,80]). 

336 
LIMIT THEOREMS 
8.16 
A certain medicine has been shown to produce allergic reactions in 
1% of the population. If this medicine is dispensed to 500 people, what is the 
probability that at most 10 of them show any allergy symptoms? 
8.17 
A fair dice is rolled as many times as needed until the sum of all the 
results obtained is greater than 200. What is the probability that at least 50 
tosses are needed? 
8.18 
A Colombian coffee exporter reports that the amount of impurities 
in 1 pound of coffee is a random variable with mean 3.4 mg and standard 
deviation 4 mg. In a sample of 100 pounds of coffee from this exporter, what 
is the probability that the sample mean is greater than 4.5 mg? 
8.19 
(Ross, 1998) Let X be a random variable having a gamma distribution 
with parameters n and 1. How large must n be in order to guarantee that: 
( — - 1 > 0.01 j < 0.01 ? 
8.20 
How many tosses of a fair coin are needed so that the probability that 
the average number of heads obtained differs at most 0.01 from 0.5 is at least 
0.90? 
8.21 
Let X be a nonnegative random variable. Prove: 
E{X)< 
[Ε{Χ2)γ 
< [Ε(Χ3)γ 
< · · · . 
8.22 
Let (-Xn)n>i be a sequence of random variables, and let c be a real 
constant verifying, for any e > 0, the following condition: 
l i m P ( | A - n - c | > e ) = 0 . 
n—voo 
Prove that for any bounded continuous function g we have that: 
lim£(<,(J»L-n))=fl(c) . 
8.23 
Examine the nature of convergence of {Xn} 
defined below for the 
different values of k for n = 1,2, · · ·: 
P(Xn =nk) = -n 
P(Xn = 0) = 1 - -n 
P(Xn = -nk) 
= - . 
n 

EXERCISES 
337 
8.24 
Show that the convergence in the rth mean does not imply almost sure 
convergence for the sequence {Xn} denned below: 
P(Xn = 0) = 1 - -n 
P(X„ = - n * ) = - . 
n 
Σ n 
t=0 
8.26 
Let (Xn)n 
be a sequence of random variables such that Xn = Exp (n). 
Show that Xn - A 0. 
8.27 
For each n > 1 , let Xn 
be an uniformly distributed random variable 
over set {0, £ , £ , · · · , ~ , l } , that is: 
p(xn = -\ = 4 τ - Α = 0,1,···,η. 
\ 
n) 
n+1 
Let U be a random variable with uniform distribution in the interval [0,1]. 
Show that Xn A 
U. 
8.28 
Let {Xn)n 
be a sequence of i.i.d. random variables with E{X{) — 
Var (Xi) = λ € (0, oo) and P (Χχ > 0) = 1. Show that, for n -+ oo , 
v / H · ^ ^ -ΛΛΓ(Ο,Ι) 
where: 
1 
n 
yn = - ] [ > . 
"fei 
8.29 
Let (Xn)n 
be a sequence of random variables such that Xn = Exp (n). 
Show that Xn A 
0. 
8.30 
Let (Ω, 9, P) = ([0,1], B (R) Π [0,1], W ([0,1])). Prove the following 
statements: 
a) If (Xn) n is a sequence of random variables with Xn —U{\^ — ^, 5 + ^ ]) > 
then X n - A x 
with X = ±. 
b) The sequence (Xn)n 
with X n = XtQ 1 + Ai 
converges in distribution 
but does not converge in probability t o X = A'r l li. 

338 
LIMIT THEOREMS 
8.31 
Let (Xn)n 
be a sequence of i.i.d. random variables with P (Xn — 1) = 
P(Xn 
= -1) = \. Show that 
1 
" 
j = l 
converges in probability to 0 . 

CHAPTER 9 
INTRODUCTION TO STOCHASTIC 
PROCESSES 
In the last eight chapters, we have studied probability theory, which is the 
mathematical study of random phenomena. A random phenomenon occurs 
through a stochastic process. In this chapter we introduce stochastic processes 
that can be defined as a collection of random variables indexed by some pa-
rameter. The parameters could be time (or length, weight, size, etc.). The 
word "stochastic1" means random or chance. The theory of stochastic pro-
cesses turns out to be a useful tool in solving problems belonging to diverse 
disciplines such as engineering, genetics, statistics, economics, finance, etc. 
This chapter discusses Markov chains, Poisson processes, and renewal pro-
cesses. In the next chapter, we introduce some important stochastic processes 
for financial mathematics, Wiener processes, martingales, and stochastic in-
tegrals. 
lrThe word stochastic comes from Greek 
stokhastikos. 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
339 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

340 
INTRODUCTION TO STOCHASTIC PROCESSES 
20 
40 
60 
80 
July 13, 2011-Dec.30,2011 
100 
120 
Figure 9.1 
Sample path for the U.S. dollar value of 10,000 Colombian pesos 
9.1 
DEFINITIONS AND PROPERTIES 
Definition 9.1 (Stochastic Process) A real stochastic process is a collec-
tion of random variables {Xt; t 6 T} defined on a common probability space 
(Ω, 9, P) with values in R. T is called the index set of the process or paramet-
ric space, which is usually a subset of R. The set of values that the random 
variable Xt can take is called the state space of the process and is denoted by 
S. 
The mapping defined for each fixed ω 6 Ω, 
Χ{ω) 
: 
T^S 
t ■-> Xt(uj) 
is called a sample path of the process over time or a realization of the stochastic 
process. 
EXAMPLE 9.1 
The U.S. dollar value of 10,000 Colombian pesos at the end of each day 
is a stochastic process {Xt,t 
£ T}. 
The sample path of {Xt,t 
€ T} 

DEFINITIONS AND PROPERTIES 
3 4 1 
between July 13, 2011 and December 30, 2011, is shown in Figure 9.1. 
▲ 
Stochastic processes are classified into four types, depending upon the nature 
of the state space and parameter space, as follows: 
■ EXAMPLE 9.2 
1. Discrete-state, discrete-time stochastic process 
(a) The number of individuals in a population at the end of year t can 
be modeled as a stochastic process {Xt\t 
€ T}, where the index 
set T = {0,1,2, · · · } and the state space S = {0,1,2, · · · }. 
(b) A motor insurance company reviews the status of its customers 
yearly. Three levels of discounts are possible (0,10%, 25%) depend-
ing on the accident record of the driver. Let Xt be the percent-
age of discount at the end of year t. Then the stochastic process 
{Xt; t e T} has T = {0,1,2, · · · } and S = {0,10,25}. 
2. Discrete-state, continuous-time stochastic process 
(a) The number of incoming calls Xt in an interval [0,i]. Then the 
stochastic processes {Xt\t 
€ T} has T = {t : 0 < t < oo} and 
5 = { 0 , 1 , · · · } . 
(b) The number of cars Xt parked at a commercial center in the time 
interval [0,t\. Then the stochastic processes {Xt\t E T} has T = 
{t : 0 < t < oo} and S = {0,1, · · · }. 
3. Continuous-state, discrete-time stochastic process 
(a) The share price for an asset at the close of trading on day t with 
T = {0,1,2, ·· · } and S = {x : 0 < x < oo}. Then it is a discrete-
time stochastic process with the continuous-state space. 
4. Continuous-state, continuous-time stochastic process 
(a) The value of the Dow-Jones index at time t where T = {t : 0 < 
t < oo} and S = {x : 0 < x < oo}. Then it is a continuous-time 
stochastic process with the continuous-state space. 
A 
Definition 9.2 (Finite-Dimensional Distributions of the Process) Let 
{Xt',t € T} be a stochastic process and {ίι,ί2, ■ · · ,tn} C T where t\ < ti < 
■■ ■ <tn. 
The finite dimensional distribution of the process is defined by: 
Ftl...tn(xi,--- 
,xn) :=P(Xtl 
< x i , · · · ,Xtn 
<xn), 
Xi e R, i = 1,··· ,n . 

342 
INTRODUCTION TO STOCHASTIC PROCESSES 
The family of all finite-dimensional distributions determines many impor-
tant properties of the stochastic process. Under some conditions it is pos-
sible to show that a stochastic process is uniquely determined by its finite-
dimensional distributions (advanced reader may refer to Breiman, 1992). 
We now discuss a few important characteristics and classes of stochastic 
processes. 
Definition 9.3 (Independent Increments) If,forallto,ti,ti,··· 
,tn such 
that to < t\ < £2 < · · · < tn, 
the random variables Xt0,Xt! 
— XtQ, 
Xt3 — Xti, · · · , Xt„ — Xtn-i 
are independent (or equivalently Xt+T — XT is 
independent of Xs for s < τ), then the process {Xt',t € T} is said to be a 
process with independent 
increments. 
Definition 9.4 (Stationary Increments) A stochastic process {Xt',t & T} 
is said to have stationary increments if Xt2+T — Xu+τ has the same distribu-
tion as -Xt2 — Xtl for all choices oft\,t2 
and τ > 0. 
Definition 9.5 (Stationary Process) If for arbitrary ti,t2,··· 
,tn, 
such 
that t\ < t-i < ■ · ■ < tn, the joint distributions of the vector random vari-
ables (Xtl ,Xt3,·-· 
1 xtn) 
and {Xtl+h, Xt2+h, ··· , Xtn+h) are the same for all 
h > 0, then the stochastic process {Xt,t 
€ T} is said to be a stationary 
stochastic process of order n (or simply a stationary process). The stochas-
tic process {Xt,t £ T} is said to be a strong stationary stochastic process or 
strictly stationary process if the above property is satisfied for all n. 
■ EXAMPLE Θ.3 
Suppose that {Xn',n > 1} is a sequence of independent and identically 
distributed random variables. We define the sequence {Yn; n > 1} as 
Yn = Xn + 
aXn-i 
where a is a real constant. Then it is easily seen that {V„;n > 1} is 
strictly stationary. 
▲ 
Definition 9.6 (Second-Order Process) A stochastic process {Xt\t G Γ} 
is called a second-order process if E ((Xt)2) < 00 for all t € T. 
■ EXAMPLE 9.4 
Let Z\ and Zi be independent normally distributed random variables, 
each having mean 0 and variance σ2. Let λ € K and: 
Xt = Zx cos(Ai) + Z2 sin(At), t € R. 
{Xt\ t £ T} is a second-order stationary process. 
▲ 

DEFINITIONS AND PROPERTIES 
343 
Definition 9.7 (Covariance Stationary Process) A second-order stochas-
tic process {Xt',t € T} is called covariance stationary or weakly stationary if 
its mean function m(t) = E[Xt] is independent of t and its covariance func-
tion Cov(Xs,Xt) 
depends only on the difference \t — s\ for all s,t e T. That 
is: 
Cov(Xs,Xt) 
= f(\t-s\) 
. 
■ EXAMPLE 9.5 
Let {Xn;n 
> 1} be uncorrelated random variables with mean 0 and 
variance 1. Then Cov(Xm, Xn) = E (XmXn) 
equals 0 if m φ n and 1 
if m = n. Then this shows that {Xn', n > 1} is a covariance stationary 
process. 
A 
Definition 9.8 (Evolutionary Process) A stochastic process which is 
not stationary (in any sense) is said to be an evolutionary stochastic process. 
■ EXAMPLE 9.6 
Consider the process {Xt',t > 0}, where Xt = A\ + A?.t, A\ and A^ 
are independent random variables with Ε(Αΐ) = μ», Var(Ai) = af for 
i = 1,2. It easy to see that: 
E{Xt) 
= 
μ ι + μ 2 ί 
Var(Xt) 
= 
a\ + alt2 
Cov(Xs,Xt) 
= 
σ\ + sta% . 
These are functions of t and the process is evolutionary. 
▲ 
The class of processes defined below, known as Markov processes is a very 
important process both in applications as well as in the development of the 
theory of stochastic processes. 
Definition 9.9 (Markov Process) Let {Xt t > 0} be a stochastic process 
defined over a probability space (Ω, 3 , P) and with state space (R, B). We say 
that {Xt t > 0} is a Markov process if for any 0 < <i < £2 < · · · < tn and for 
any B € B: 
P{Xtn €B\Xtl,--- 
,Xtn_,) 
=P{XtneB\ 
X t n_J . 
Note 9.1 
1. Roughly a Markov process is a process such that, given the value Xs, the 
distribution of Xt for t > s does not depend on the values of Xu, u < s. 

344 
INTRODUCTION TO STOCHASTIC PROCESSES 
2. Any stochastic process which has independent increments is a Markov 
process. 
A discrete-state Markov process is known as a Markov chain. Based on 
the values of the index set T, the Markov chain is classified as a discrete-time 
Markov chain (DTMC) or a continuous-time Markov chain (CTMC). 
In the next section we will work with discrete-time parameter Markov pro-
cesses and with discrete-state space, that is, we will continue our study of the 
so-called Markov chains with discrete-time parameter. 
9.2 
DISCRETE-TIME MARKOV CHAIN 
This section intends to present the basic concepts and theorems related to 
the theory of discrete-time Markov chains with examples. This section was 
inspired by the class notes of the courses Stochastik I und II given by Professor 
H.J. Schuh at the Johannes Gutenberg Universität (Mainz, Germany). 
Definition 9.10 (Discrete-Time Markov Chain) A sequence of random 
variables (X„)n6N with discrete-state space is called a discrete-time Markov 
chain if it satisfies the conditions 
P{Xn+l 
= j | Xn = h Xn-1 
= *n-l> · · · , Xo = U)) = 
P(Xn+1 
= j | Xn = i) 
(9.1) 
for alln € N and for all io,ii, · · · ,in-it 
i,jES 
with: 
P(X0 = io, · · · , Xn - in) > 0. 
In other words, the condition (9.1) implies the following: if we know the 
present state "Xn = i", the knowledge of past history "Xn-i,Xn-2, 
· · · , Xo "has 
no influence on the probabilistic structure of the future state Xn+i-
■ EXAMPLE 9.7 
Suppose that a coin is tossed repeatedly and let: 
Xn := "number of heads obtained in the first n tosses". 
It is clear that the number of heads obtained in the first n + 1 tosses 
only depends on the knowledge of the number of heads obtained in the 
first n tosses and therefore: 
P(Xn+l 
—j\Xn=l, 
^"n-l = « n - 1 , · · · , Xl 
= ή ) = P(Xn+l 
= j \ Xn 
= 
l) 
for all n € N and for all i, j , i„_i, ■ · · , ii 6 N. 
▲ 

DISCRETE-TIME MARKOV CHAIN 
345 
■ EXAMPLE 9.8 
Three boys A, B and C throw a ball to each other. A always throws the 
ball to B and B always throws the ball to C where C is equally likely 
to throw the ball to A or B. Let Xn := "the boy who has the ball in 
the nth throw". The state space of the process is S — {A,B,C} 
and it 
is clear that {Xn',n > 0} is a Markov chain, since the person throwing 
the ball is not influenced by those who previously had the ball. 
A 
■ EXAMPLE 9.9 
Consider a school which consists of 400 students with 250 of them being 
boys and 150 girls. Suppose that the students are chosen randomly one 
followed by the other for a medical examination. Let Xn be the sex of 
the nth student chosen. It is easy to see that {Xnl " = 1,2,···, 400} is 
not a discrete-time Markov chain. 
A 
■ EXAMPLE 9.10 
Let YQ, Υχ, ■ ■ ■ , Yn be nonnegative, independent and identically distributed 
random variables. The sequence {Xn; n > 0} with 
Xo := YQ 
Xn := X0 + Yi + · · ■ + Yn for n > 1 
is a Markov chain because: 
P(Xn+l = j | Xn = i, Xn-1 = in-l, ' * ■ ,Xl =Η,Χθ 
= io) 
_ 
P(Xn+l — j,Xn = i,Xn-l 
= in-l,·-- 
>Xl = Π,Χθ = ig) 
P{Xn = i,Xn-i 
= in-i,··· 
,Xi = h,Xo — io) 
= 
P{XQ = io,Yi=ii-io,··· 
,Yn = i - *η-ι> γη+ι = J - ») 
P(X0 = io,Yi = t i - t o , · · · ,^n = 
i-in-i) 
p(x0 
= tp)P(yi = t! - to) · · · P(Yn = i - i n_ 1)P(y n + 1 
=j-i) 
P(X0 = i0)P(Yi = ti - to) · · · P(Yn = i - 
in-i) 
= 
P(Yn+1=j-i) 
= P(Xn+1=j\Xn 
= i). 
A 
■ EXAMPLE 9.11 
A Simple Queueing Model 
Let 0,1,2, · · · be the times at which an elevator starts. It is assumed 
that the elevator can transport only one person at a time. Between 

346 
INTRODUCTION TO STOCHASTIC PROCESSES 
the times n and n + 1, Yn people who want to get into the elevator 
arrive. Also assume that the random variables Yn, n = 0,1,2, · ■ ·, are 
independent. The queue length Xn immediately before the start of the 
elevator at time n is equal to: 
Xn = max(0,X n-i - 1) + Yn-i, 
n>\. 
Suppose that Xo = 0. Since Xi with i < n can be expressed in terms 
of Υι, Υ2, ■ · · , Yn-i, we have that Yn is independent of (XQ, X\, ■ ■ ■ , Xn) 
as well. Thus: 
1. If in > 1, then: 
P(Xn+l 
= in+1 I Xn = in, Xn-1 
= i n - 1 , " " " ,-Xp = ip) 
_ 
P(^n+1 
= in+l,Xn 
= in, Xn-1 
— i n - 1 , ' ' ' ,-Xp = ip) 
P(Xn 
= in, Xn-1 
= in-1,' 
'■ , Xp = ip) 
= 
P(Yn = in+l -in 
+ l)P(Xn 
= in, ■ ' ■ , -Xp = ip) 
P{Xn 
= in,··· 
,-ΧΌ = ip) 
= 
P(Yn 
= in+1 - i n + 1) 
= 
P(Xn+l 
= in+1 I Xn = *n) · 
The second equality follows from the fact that in > 1, then in+\ = 
-X„+i = X n — 1 + Yn, which implies that Yn = in+i — -Xn + 1· 
2. If in — 0, then Xn+i = Yn, and in this case: 
P{Xn+l 
= in+1 I Xn = in,-Xn-1 = i n - 1 , ■ · ■ , Xp = *θ) 
_ 
f ( ^ n = in+l,-Xn = in,' ' ' ,-Xp = ip) 
ί*(-Χη = in, · · · , -Xp = ip) 
= 
P{Xn+l = in+1 \Xn = 0). 
A 
Lemma 9.1 // {Xn;n 
> 0} is a Markov chain, then for all n and for all 
ip, ii, · · · , in S S we have: 
P(X0 = i0, Xi = ii, · ■ · , Xn = in) 
= 
P{Xp = ip)P(Xi =ii\Xp= 
ip) 
■ ■ · P(Xn = in I -Xn-1 = in-l) · 
Proof: 
P(X0 = ip)P(Xi = <i I Xp = ip) · · ■ P(Xn = i n I Xn-i 
= i n-i) 
_ 
p/v 
_ · \ρ(χι 
=ii»^Xo = io) 
P(X 0 = ip,-Xi = i i , · · · ,Xn = in) 
K °~l0) 
P(X0 = ip) 
'" P{X0 = io,Xi = iu···, 
Xn-i 
=in-i) 
= 
P(Xp = ϊρ,Χΐ = ii,··" ,-Xn = in) ■ 

DISCRETE-TIME MARKOV CHAIN 
347 
The previous lemma states that to know the joint distribution of 
X0,X\,··· 
jXn, it is enough to know P(Xo = io), P{Xi 
— i\ \ Xo = *o), 
etc. Moreover, for any finite set {ji,J2, · · · , ji} of subindices, any probability 
that involves the variables Xji,Xj2,··· 
,Χμ with j \ < 32 < ·■■ < ji, I = 
1,2, · ■ ■ , n, can be obtained from: 
P(Xo = io,·· 
,Xn = in)-
Then it follows that one can know the joint distribution of the random vari-
ables Xji, Xj2, ··· , Xji from the knowledge of the values of P(Xo = io), 
P(Xi = i\ I Xo = io), etc. These probabilities are so important that they 
have a special name. 
Definition 9.11 (Transition Probability) Let {Xn;n 
> 0} be a Markov 
chain. The probabilities 
Pij := P{Xn+l =j \Xn = i) 
(if defined) are called transition probabilities. 
Definition 9.12 A Markov chain {Xn',n 
> 0} is called homogeneous or a 
Markov chain with stationary probabilities if the transition probabilities do 
not depend on n. 
Note 9.2 In this book we only consider homogeneous Markov chains unless 
otherwise specially mentioned. 
Definition 9.13 The probability distribution π := (n^igs with 
m := P(X0 = i) 
is called the initial distribution. 
Because of the dual subscripts it is convenient to arrange the transition 
probabilities in a matrix form. 
Definition 9.14 (Transition Probability Matrix) The matrix 
/Poo 
P01 
P02 
\ 
P = (Pij) = 
P10 
P11 
P12 
P20 
P21 
P22 
7 
\ : 
: 
: 
is called the transition probability matrix or stochastic matrix. Note that: 
Pij 
> 
0 for all i,j € S 
2_J Pij 
= 
1 for all i € S . 

348 
INTRODUCTION TO STOCHASTIC PROCESSES 
■ EXAMPLE 9.12 
Prom Example 9.11 we have that: 
Pij = P(Xn+1 =j\Xn 
= i) = P(Yn = j - i + 1) for i > 0 
p0j = P(Yn = j) for i = 0 . 
If we define pj := P(Yn = j), then the transition probability matrix P 
of the Markov chain is given by: 
{Po 
Pi 
P2 P3 - · Λ 
Po 
Pi 
P2 P3 
··· 
P
= 
0 
po Pl 
P2 
· · · 
· 
A 
V 
J 
■ EXAMPLE 9.13 
On any given day Gary is cheerful (C), normal (N) or depressed (D). If he 
is cheerful today, then he will be C, N or D tomorrow with probabilities 
0.5, 0.4, 0.1, respectively. If he is feeling so-so today, then he will be C, 
N or D tomorrow with probabilities 0.3, 0.4, 0.3. If he is glum today, 
then he will be C, N, or D tomorrow with probabilities 0.2, 0.3, 0.5. 
Let Xn denote Gary's mood on the nth day. Then {Xn; n > 0} is a 
three-state discrete-time Markov chain (state 0 = C, state 1 = N, state 
2 = D) with transition probability matrix 
/0.5 0.4 0.l\ 
P= 
0.3 0.4 0.3 
. 
A 
\0.2 
0.3 0.5/ 
■ EXAMPLE 9.14 Simple Random Walk Model 
A discrete-time Markov chain whose state space is given by the integers 
i = 0, ±1, ±2, - i s said to be a random walk if for some number 0 < 
p < 1: 
Pi,i+i = p = 1 -Pi,i-i, 
i = 0,±1,±2, ··· . 
The preceding DTMC is called a simple random walk for we may think 
of it as being a model for an individual walking on a straight line who 
at each point of time either takes one step to the right with probability 
p or one step to the left with probability 1 — p. The one-step transition 

DISCRETE-TIME MARKOV CHAIN 
349 
probability matrix is given by: 
/ : 
: 
: 
P = 
\ 
■ 
0 
1 - p 
0 
p 
0 
0 
1 - p 
0 
p 
'J 
EXAMPLE 9.15 
Gambler's Ruin 
Suppose that we have two players A and B and that player A who 
started a game has a capital of x € N dollars and player B has a capital 
of y 6 N dollars. Let a := x + y. In each round of the game, either A 
wins one dollar from B with probability p or B wins one dollar from A 
with probability q, with p + q = 1. The game goes on until one of the 
players loses all of his capital, that is, until Xn = 0 or Xn = a, since 
Xn = "The capital of the player A in the nth round". In this case we 
have T = N and 5 = {0,1, ■ · · , a}. It is easy to verify that {Xn; n > 0} 
is a Markov chain. Next, we will see its initial distribution and transition 
matrix. We have that P(Xo = x) = 1, and hence 
π = (0,··· ,0,1,0,··· , 0 ) = : e , 
where the 1 appears in the xth component and the matrix P is equal to: 
P = 
9.16 
(1 
Q 
0 
\o 
0 
0 
0 
p 
q 0 
0 
0 
0 
.. 
0 . 
p 
.. 
0 
. 
• °\ 
. 
0 
. 
0 
• V 
Let {Xn; n > 0} be a Markov chain with states 0,1,2 and with transition 
probability matrix 
Ό.75 
0.25 
0 
P = ( 0.25 
0.5 
0.25 
0 
0.75 
0.25; 

350 
INTRODUCTION TO STOCHASTIC PROCESSES 
The initial distribution is P(XQ = i) = \, i = 0,1,2. Then: 
P(X1 = 1 | X0 = 2) 
P{X2 = 2 | X! = 1) 
P(X2=2,X1 
= 1\X0 
= 2) 
= 
0.75 
= 
0.25 
= 
P(X2 = 2 I Xi = l)P(Xi 
= 1 | Xo = 2) 
3 
= 
16 · 
A 
We now explain how Markov chains can be represented as graphs. In a Markov 
chain, a set of states can be represented by a "network" in which states are 
vertices and one-step transitions between states are represented by directed 
arcs. Each of the transitions corresponds to a probability. This graphical 
representation for the Markov chain is called a state transition diagram. 
If 
for some transition the probability of occurrence is zero, then it indicates that 
the transition is not possible and the corresponding arc is not drawn. 
For example, if {Xn;n 
> 1} is a Markov chain with S = {0,1,2,3} and 
transition probability matrix 
/ * 
P = 
0 
2 
5 
0 
I 
2 
υ 
4 
4 
1 
o 
o 
i 
JL 
JL 
JL 
JL 
13 
13 
13 
13 
then the state transition diagram is shown in Figure 9.2. In the study of 
Markov chains the following equations, called Chapman-Kolmogorov equa-
tions are very important. 
Theorem 9.1 (Chapman-Kolmogorov Equations) If the sequence of ran-
dom variables {Xn] n>0} 
is a Markov chain and if k < m < n, then we have 
for all h, j G 5: 
P(Xn = j\Xk 
= h) = Y^P{Xn 
=j\Xm= 
i)P(Xm =i\Xk 
= h). 
ies 
Proof: 
P(Xk = h,Xn= 
j) = Σ P{*k = h,Xrn= i, Xn = j) 
= J2 ρ(χκ 
= h,Xm = i)P{Xn =j\Xk 
= h,Xm = i) 
ieS 
= Σ P(Xrn =i,Xk= 
h)P{Xn 
=j\Xm=i) 
ies 
= Σ P(Xm = i\Xk 
= h)P(Xk = h)P(Xn 
=j\Xm=i). 
ies 

DISCRETE-TIME MARKOV CHAIN 
3 5 1 
3/13 
5/13 
Figure 9.2 State transition diagram 
That is: 
P(Xk = 
h,Xn=j) 
P{Xk = ft) 
= YdP{Xm 
= i\Xk = h)P(Xn=j 
\Xm = i) 
i€S 
To give an interpretation to the Chapman-Kolmogorov equations, we in-
troduce the following concept: 
Definition 9.15 The probability 
p\f 
= P(Xn+m 
=j\Xn 
= i),me 
N, i, j e S, 
is the m-step transition probability from i to j : 
pf:=P(Xn^j\Xn=i) 
= l· ifi={ 
=:Sij 
I 0 if i φ J 
where Sij is Kronecker's delta. The matrix p( m) := [p\j ) 
is the m-step 
transition matrix. 
EXAMPLE 9.17 
Consider the simple random walk of Example 9.14. The state transition 
diagram is shown in Figure 9.3. Assume that the process starts at the 

352 
INTRODUCTION TO STOCHASTIC PROCESSES 
• · 
· 
origin. We have: 
l-p 
Figure 9.3 State transition diagram 
n+j — i 
n — j + i 
(n+j-ijp 
2 q 2 
!f n + j - t i s e v e n 
0 
otherwise. 
This can be seen by noting that there will be n + | ~ ' positive steps and 
n~2+l 
negative steps in order to go from state i to j in n steps when 
n + j — i is even. 
▲ 
Corollary 9.1 The m-step transition probability matrix is the mth power of 
the transition matrix P. 
Corollary 9.2 Let {Xn\n > 0} be a Markov chain with transition probability 
matrix P and initial distribution π. Then for each n > 1 and for each k € S 
we have: 
P(Xn = k) = 
J2P%)*j. 
jes 
Proof: 
P(Xn = k) = J2 Ρ(χη = k,X0= 
j) 
jes 
= Σ P&n = k\X0= 
j)P(X0 = j) 
Σ
( η ) 
jes 
Note 9.3 The Chapman-Kolmogorov equations provide a procedure to com-
pute the n-step transition probabilities. Indeed it follows that: 
oo 
p(n+m) 
= £ p ( n ) p g O 
for an n, T O > o, all i,j e S . 
fc=0 
In matrix form, we can write these as 
p(n+m) 
_ pin) 
_ pirn) 

DISCRETE-TIME MARKOV CHAIN 
353 
where ■ denotes matrix multiplication. Here, P^ 
is the matrix consisting of 
n-step transition probabilities. 
Note that beginning with 
p(2) _ p(l+l) _ p . p _ pi 
and continuing by induction, we can show that the n-step transition matrix 
can be obtained by multiplying matrix P by itself n times, that is: 
p(n) 
_ p ( n - l + l) _ p ( n - l ) . p _ 
pn 
■ EXAMPLE 9.18 
Let {X„;n > 1} be a Markov chain with state space S = {0,1}, initial 
distribution π = (§, f) and transition matrix 
/0.1 
0.9\ 
\0.3 
0.7J " 
Then 
p(x3=o) = x;P;2
0V] 
with 
/0.28 
0.72N 
\0.24 
0.76^ 
so that: 
P(X3 = 0) = 0.26 . 
▲ 
9.2.1 
Classification of States 
One of the fundamental problems in the study of Markov chains is the analysis 
of its asymptotic behavior. As we will see later, it depends on whether the 
chain returns to its starting point with probability 1 or not. For this analysis 
we need to classify the states, which is the objective of this section. 
Definition 9.16 (Accessibility) State j is said to be accessible from state 
i in n > 0 steps if p\" > 0. This is written as i -> j[n]. We say that state j 
is accessible from state i if there exists n > 0 such that p\™ > 0. In this case 
we write i —l· j . 
Lemma 9.2 The relation "-►" is transitive. 
Proof: Suppose that i —¥ j and j —> k. Then there exist nonnegative integers 
r and / such that: 
p\? > 0 and pfk > 0. 

354 
INTRODUCTION TO STOCHASTIC PROCESSES 
Prom the Chapman-Kolmogorov equation, we have: 
Therefore, i —>· k. 
Definition 9.17 States i and j communicate if i —>j and j 
written as i +-> j . 
i. This is 
It is easy to verify that "i o j " is an equivalence relation over S and thus the 
equivalence classes 
C{i):={jeS:i^j}, 
ieS 
, 
form a partition of S. 
Definition 9.18 A Markov chain is said to be irreducible if the state space 
consists of only one class, that is, all states communicate with each other. 
A Markov chain for which there is only one communication class is called 
an irreducible Markov chain: Note that, in this case, all states communicate. 
■ EXAMPLE 9.19 
Let {Xn'i n > 0} be a Markov chain with state space S = {1,2,3}, initial 
distribution π = (1,0,0) and transition matrix 
/o f \\ 
Ϊ o \ 
\ \ 
0 
0 / 
It is to be observed that C(l) = C(2) = C(3) = {1,2,3}, that is, 
{Xn)n>o is an irreducible Markov chain. 
A 
Definition 9.19 (Absorbing State) A state i is said to be an absorbing 
state ifpu = 1 or equivalently pij — 0 for all j 
φι. 
EXAMPLE 9.20 
Consider a Markov chain consisting of the four states 0, 1, 2, 3 and 
having transition probability matrix 
fi 
1 
2 
1 
4 
\o 
I 
2 
1 
2 
1 
4 
0 
0 
0 
1 
4 
0 
o\ 
0 
1 
4 
1/ 

DISCRETE-TIME MARKOV CHAIN 
355 
Figure 9.4 
State transition diagram for Example 9.20 
The state transition diagram for this Markov chain is shown in Figure 
9.4. The classes of this Markov chain are {0,1} and {3}. Note that 
while state 0 (or 1) is accessible from state 2, the reverse is not true. 
Since state 3 is an absorbing state, that is, P33 = 1, no other state is 
accessible from it. 
▲ 
Definition 9.20 Let i E S fixed. The period ofi is defined as follows: 
λ(») := GCD {n > 1 : p™ > o} 
where GCD stands for greatest common divisor. Ifp\" 
= 0 for all 
n > 1, then we define X(i) := 0. 
Definition 9.21 (Aperiodic) State i is called aperiodic when \(i) = 1. 
Definition 9.22 A Markov chain with all states aperiodic is called an aperi-
odic Markov chain. 
■ EXAMPLE 9.21 
In the example of the gambler's ruin, we have that: 
λ(0) = GCD {n>l:pj$> 
o} 
= 1 - GCD {n > 1 : p<>> > o} = λ(α) 
λ(1) - GCD In > 1 : pfr> > o} = 2 . 

356 
INTRODUCTION TO STOCHASTIC PROCESSES 
1/3 
1 
2/3 
Figure 9.5 
State transition diagram for Example 9.22 
The following theorem states that if two states are communicating 
with each other, then they have the same period. 
▲ 
Theorem 9.2 If i «->· j , then X(i) = X(j). 
Proof: 
Suppose that j —► j[n] and let k,m 6 N such that i —> j[k] and 
j —> i[m\. Then i —»■ i\m + k] and i —> i[m + n + k]. Therefore, X(i) divides 
both m + k and m + n + k and from this it follows that X(i) divides n. That 
is, λ(ζ) is a common divisor for all n such that j —> j[n] and this implies that 
λ(ί) < X(j)- Similarly it can be shown that X(j) < X(i). 
m 
EXAMPLE 9.22 
Let {Xn;n 
> 1} be a Markov chain with state space S 
and transition matrix 
/0 
1 
0 
0 
θ\ 
{0,1,2,3,4} 
P = 
1 0 
0 
0 
0 
o \ o i o 
o o I \ o 
\0 
0 
0 
1 
0/ 
The graphical representation of the chain is shown in Figure 9.5. Then: 
C(0) = C(1) = {0,1} 
C(2) = C(3) = {2,3} 
C(4) = {4} . 
It is clear that: 
λ(0) 
= λ(1) = 2 
λ(2) 
= λ(3) = 1 
λ(4) 
= 0 . 
▲ 

DISCRETE-TIME MARKOV CHAIN 
357 
Suppose that the Markov chain {Xn;n 
> 0} starts with the state j . Let rk 
be the first passage time to state k: 
Tk = min{n > 1 : X„ — k} . 
If {n > 1 : Xn = k} = 0, we define τ* = oo. For n > 1, define: 
4 n ) 
= 
P(rfc = n | X 0 = j ) 
= 
P{Xn = k,Xv^k,u 
= l,·-· 
, n - l | X 0 = j ' } ■ 
Let Pjl be the probability that the chain reaches the state k (not necessarily 
for the first time) after n transitions. A relation between /■£' and pfi.' is as 
follows. 
Theorem 9.3 (First Entrance Theorem) 
P$ = Σ ft ώ"Γ) 
(9-2) 
r=0 
where ffi = 0, 
pj^ = 1, 
/ ^ } = pjk . 
If j ; = k we refer to /j™' as the probability that the first return to state j 
occurs at time n. By definition, we have ff) 
= 0. 
For fixed states j and k, we have 
oo 
f» = Σ iif. 
(9·3) 
n=l 
which is the probability that starting with state j the system ever reaches 
state k. If j = k, we let fjj = Y^=l 
/ ) " to denote the probability of 
ultimately returning to state j . 
Definition 9.23 (Recurrent State) A state j is said to be persistent 
or 
recurrent if fjj = 1 (i.e., return to state j is certain). 
Definition 9.24 (Transient State) A state j is said to be transient if 
fjj < 1 (i.e., return to state j is uncertain). 
■ EXAMPLE 9.23 
Consider the Markov chain with state space S = {0,1,2,3} and transi-
tion matrix 
/ 0.8 
0 0.2 
0 \ 
0 
0 
1
0 
1
0 
0 
0 
\ 0.3 0.4 
0 0.3 / 

358 
INTRODUCTION TO STOCHASTIC PROCESSES 
Figure 9.6 
State transition diagram for Example 9.23 
The state transition diagram for this Markov chain is shown in Figure 
9.6. 
In this case: 
/oo — 
/ l l 
= 
Jll 
= 
/33 
= 
/oo 
f(2) 
+ /oo + /oo 
(3) + 
0.8 + (0.2)(1.0) + 0 = l 
f(2) 
(3) 
J22 + ill 
+ ill 
+ ' " " 
0 + (1.0)(0.2) + (1.0)(0.8)(0.2) + (1.0)(0.8)2(0.2) + · · · = 1 
fW 
, f(2) , 
f 
/ 33 + /33 + /; 
i3
3) + --- = 0.3. 
We have C(0) = {0,2}, C(l) = {1}, C(3) = {3}. The states 0 and 2 are 
recurrent and states 1 and 3 are transient. 
▲ 
EXAMPLE 9.24 
Consider the Markov chain with state space S = {1,2,3,4,5} and tran-
sition matrix 
/ 0.5 
0 
0 0.5 
0 \ 
0 
0.6 
0 
0 
0.4 
0.3 
0 0.7 
0 
0 
0 
0 
1
0 
0 
\ 
0 
1 
0 
0 
0 / 
In this case, using Definition 9.17, C(l) = {1,3,4}, C(2) = {2,5}. All 
the states are recurrent. 
▲ 

DISCRETE-TIME MARKOV CHAIN 
359 
Note 9.4 The transition matrix of a finite Markov chain can always be writ-
ten in the form 
R 
- ( " ' , ) 
(9.4) 
where R corresponds to the submatrix that gives the probability of transition 
between recurrent states, A is the submatrix whose components are the prob-
abilities of transition from transient states to recurrent states, 0 is the zero 
matrix and B is the submatrix of transition probabilities between transient 
states. If among the recurrent states there is an absorbing state, it is placed 
first in this reordering of the states. 
This representation of the transition 
matrix is known as the canonical form of the transition matrix. 
P = 
EXAMPLE 9.25 
Consider the Markov chain with state space S = {0,1,2,3} and transi-
tion matrix 
/ 0.8 
0 0.2 
0 \ 
0 
0 
1
0 
1
0 
0 
0 
\ 0.3 0.4 
0 0.3 / 
We have the canonical form of the transition matrix: 
/ 0.8 0.2 
0 
0 \ 
1
0 
0 
0 
0 
1 0 
0 
\ 0.3 
0 0.4 0.3 ) 
Note 9.5 In the study of finite Markov chains, we are interested in answering 
questions such as: 
1. What is the probability that starting from a transient state i, the chain 
reaches the recurrent state j at least once? 
2. Given that the chain is in a transient state, what is the mean number of 
visits to another transient state j before reaching a recurrent state? 
To answer these questions we introduce some results (without proof). The 
interested reader may refer to Bhat and Miller (2002). 
Definition 9.25 (Fundamental Matrix) The matrix M = (I — B)~l, 
as 
in (9.4), is called the fundamental 
matrix. 

360 
INTRODUCTION TO STOCHASTIC PROCESSES 
Theorem 9.4 For a finite Markov chain with transition matrix P partitioned 
as (9.4), we have that (I — B)_1 exists and is equal to: 
oo 
(/ - B)-1 =I + B + B2+-=Y^Br 
. 
r=0 
Proof: we have 
(I-B)(I + B + --- + Bn-1) = I-Bn 
(9.5) 
and since Bn —> 0, then: 
n-+oo 
det (I-Bn) 
—> 1 . 
n—►oo 
Thus for sufficient large n, we have that det(7 — Bn) φ 0 and consequently 
det ((/ - Β){1 + Β + --- + B"- 1)) φ 0 
so that det(J - B) ^ 0, which implies that (I — B)~l exists. 
Multiplying (9.5) by (I — B)~l we obtain 
I + B + --+ Bn~l = (I - B)~l{I - Bn) 
and thus, letting n tend to oo, we get: 
oo 
ΣΐΤ = 
(Ι-Β)-1. 
r=0 
Definition 9.26 Let i,j be transient states. Suppose that the chain starts 
from the state i and let Nij be the random variable defined as: Nij = "The 
number of times the chain visits state j before reaching possibly a recurrent 
state". We define: 
My = E{Ntj) . 
Theorem 9.5 Let i,j e T where T denotes the set of transient states. Then 
the fundamental matrix M is given by: 
M 
= 
(ßij)i,j€T 
EXAMPLE 9.26 
Let us consider a Markov chain with states space S = {0,1,2,3} and 
probability transition matrix 
/0 i 0 i \ 
p = 
5 ° 2 0 
o o \ \ 
\o o \ \) 

DISCRETE-TIME MARKOV CHAIN 
3 6 1 
For a Markov chain, starting from state 0, determine the expected num-
ber of visits that the chain makes to state 0 before reaching a recurrent 
class. 
Solution: It can be easily seen that the chain classes are given by 
C(2) = {2,3} and C(0) = {0,1}, the transient states are 0 and 1 and 
the recurrent states are 2 and 3. Recognizing matrix P (with the order 
of states 2301) we have: 
P = 
That is, 
R 4 I)·
A 
and: 
M = {I-B)~l 
= 
Hence, μοο = - . 
A 
Definition 9.27 gij is the probability that starting from the transient state i 
the chain reaches the recurrent state j at least once. We define: 
G = (fly) . 
Theorem 9.6 Let M and A be the matrices defined earlier. Then the matrix 
G defined above satisfies the relation 
G = MA . 
■ EXAMPLE Θ.27 
Consider the education process of a student after schooling. The student 
begins with a bachelor's program and after its completion, proceeds to 
1 
2 
1 
2 
0 
1 
2-
£ 
0 
0\ 
0 
0 
0 
2" 
i o 
0/ 
B 
(c ΗΪ or 

362 
INTRODUCTION TO STOCHASTIC PROCESSES 
1 
1 
Figure 9.7 
State transition diagram for Example 9.27 
a master's program. On completion of the bachelor's program, the stu-
dent can join job A whereas on completion of the master's program, the 
student joins job B. The education of the student is modeled as a stochas-
tic process {Xt;t > 0} with state space S = {0,1,2,3,4} where states 
0, 1 and 2 represent the stages of educational qualification achieved in 
chronological order and states 3 and 4 represent job A and job B, respec-
tively. The corresponding state transition diagram is shown in Figure 
9.7. 
(i) Obtain the expected number of visits before being absorbed in job A 
or job B. 
(ii) Find the probabilities of absorption in job A and job B. 
Solution: The education of a student is modeled as a stochastic process 
{X„;n > 0} with state space S = {0,1,2,3,4} where states 0, 1 and 2 
represent the stages of educational qualification achieved in chronological 
order and states 3 and 4 represent job A and job B, respectively. The 
state transition diagram is shown in Figure 9.7. The states 0,1,2 are 
transient states and states 3 and 4 are absorbing states. 
The probability transition matrix for this model is given by 
/ 1 
0 
0 
1 
3 
V ° 
0 
1 
0 
0 
3 
4 
0 
0 
1 
2 
0 
0 
0 
0 
1 
2 
1 
3 
0 
o\ 
0 
0 
1 
3 
\ ) 

DISCRETE-TIME MARKOV CHAIN 
363 
where the submatrix / gives the probability of transition between re-
/ 0 
0 \ 
current states 3 and 4, the submatrix A = 
I 
0 I gives the proba-
bilities of transition from transient states 0, 1 and 2 to recurrent states 3 
(\ 
\ 
0 \ 
and 4 and the submatrix B = 
0 
| 
| 
of transition probabilities 
between transient states 0, 1 and 2. 
(i) From Theorem 9.4, since the probability of transition from i to j in 
exactly k steps is the (i, j)th component of Bk, it is easy to see that: 
M 
/ 
2 
2 
2 
' 
z 
2 
3 
0 
3 
2 
U 
2 
3 
\ 0 
0 
(ii) From Theorem 9.6, we get the probability of absorption: 
G = 
Definition 9.28 For i,j € S and 0 < s < 1 we define: 
oo 
n=0 
c» 
r(") „" 
n=0 
iVoie ί/iot/ij =F i :,(l). 
Definition 9.29 
where i,j € 5. 
The following note provides an interpretation of the p*.. 
Ρ«:=Σ#=Ρ«(1). 
n = 0 

364 
INTRODUCTION TO STOCHASTIC PROCESSES 
Note 9.6 
p*j = J2P(Xn=j\X0 
= i) 
n=0 
oo 
= E£(*U.-i>l*o = i) 
n=0 
= E Ιγ^Λ!{χη=.} 
\Χ0 = 
n=0 
\n=0 
/ 
"expected number of visits that the chain makes to the state j 
starting at i" . 
The theorem presented below, along with its corollary, provides a criterion 
for determining whether or not a state is recurrent. 
Theorem 9.7 
Pij(s) - Si:i = Fij(s)pjj(s), 
i,j € S. 
In particular: 
Pii{s) = rnw)'l G s-
Proof: 
Pii = Σ Ρ ( Χ " =3'Xk= 
3,Xi ^jioT&l\0<l<k-l\X0 
= i) 
fc=l 
n 
= ΣΡ(Χη=3 
| Xk = j)P(Xk 
= j,Xi Φ3 for all 0 < I < k - 1 | X0 = i) 
fc=l 
= 
\^n(n-k)Ak) 
Z_^Vjj 
Jij 
fc=l 
fc=0 

DISCRETE-TIME MARKOV CHAIN 
365 
Then: 
Pij(s) 
-
n=0 
oo 
^ 
(«) n 
n=\ 
oo 
Γ T» 
-Σ Σ Ό Γ 
n=\ Lfc=0 
s n 
oo 
oo 
fc=0 
n=fc 
\fc=0 
/ 
\n=0 
= *ly(*)Pii(*)· 
Corollary 9.3 Let i € S. Then state i is recurrent if and only if p£ = oo or 
equivalently: i is transient if and only ifp« < oo. 
Proof: 
OO 
n=0 
1 - F«(l) 
1 - /„ 
\ 
n=0 
oo 
if i is recurrent 
< oo if i is transient 
Definition 9.30 A property of states is called a solidarity or class property, if 
whenever the state i has property i +-> j , then the state j also has the property. 
The following theorem proves that the recurrence, transience and period of 
a state are class properties. 
Theorem 9.8 Suppose that ΐ ■*-> j . Then i is recurrent if and only if j is 
recurrent. 
Proof: Since i o j , there exist m, n > 0 such that: 
i 4 n ) > 0 
and 
j # ° > 0 . 
Assuming that i is recurrent, then 
oo 
oo 
oo 
ph = Σ^? * EpS+m+fc) > EiMW*. 
fc=0 fc=0 fc=0 

366 
INTRODUCTION TO STOCHASTIC PROCESSES 
that is: 
* ^ 
("*) (n) * 
Pji ^ Pji Pij P« ■ 
Therefore, if p^ = oo, then pj · = oo. 
■ EXAMPLE 9.28 
Let {Xn\ n > 0} be a random walk in Z defined as 
n 
XQ := 0 and 
Xn := / ] ^ j , 
i=i 
where Yi,Y2,··· 
are independent and identically distributed random 
variables with: 
P(Y1 = l)=p 
and 
P{Y1 = -l) = l-p=:q 
with 
0 < p < 1 . 
It is clear that (Xn)n>o is a Markov chain with state space S = Z. For 
all i, j e S, we have that i <-> j . Therefore, {Xn', n > 0} is an irreducible 
Markov chain. Now 
p(2n) = f2^\p»q" 
and pgn+1) 
= 0 for all n > 1 . 
Stirling's formula (see Feller, 1968 Vol. I, page 52) shows that 
/ - — / n \ n 
n! ~ v 2πη I — I , 
where an ~ bn implies that Ιΐπΐη-κχ, ?»· = 1. Using Stirling's formula in 
the above expression for Poo > w e obtain: 
pgn) ~ -^=(4 M) n · 
i n 
If we have p φ q, then Apq < 1, and therefore pjo < °°> t n a t is, if p ^ q, 
the chain is transient. However, if p = q = | , then ρ$0 = oo, that is, if 
p = q = | , the chain is recurrent. 
A 
The following theorem proves that if the state j is transient, then the expected 
number of visits by the chain to the state j is finite, regardless of the state 
from which the chain has started. 
Theorem 9.9 If j is transient, then p*j < oo for i € S . 
Proof: We know that 
Pij(s)-Sij 
= 
Fij^pjjis) 

DISCRETE-TIME MARKOV CHAIN 
367 
for all 0 < s < 1. Then 
Pij ~ SiJ = fijPjj 
< °° 
since j is transient. Therefore, p^ < oo. 
■ 
Prom the above theorem, it follows that, if j is transient, then: 
lim p<?> = 0 . 
n—K» 
J 
The following question arises naturally: What happens to limn-too p\j 
when 
state j is recurrent? To answer this question, we require the following concepts 
Definition 9.31 For i £ S, define: 
μ. : = EtT.\ 
= | Σ Γ = ι "/« n ) 
if* » recurrent 
1 oo 
i/i is iransieni . 
That is, ßi represents the expected return time of the chain to state i given 
that the chain started from state i. 
Definition 9.32 The recurrent state i is said to be positive recurrent if 
ßi < oo and is said to be null recurrent if ßi = oo. It is clear from the 
definition of Fu(s) that: 
dFajs) 
s=l 
EXAMPLE 9.29 
Let us consider Example 9.28, with p = q = \. In this case, it is known 
that: 
-if-OG) -<-<*>-G) 
Therefore: 
Poo 
n=0 
Thus, 
(*) = Σ(Λ-
1)
η β 2 Λ = (
1-
β2)"*-
Fm(s) - 1 - v / l - s 2 
and it follows that 0 is a null recurrent state. 
▲ 
Theorem 9.10 Let i G S be a recurrent state with X(i) = 1. Then: 
1· 
(») 
1 
hm p^ 
= — . 
n-N» 
μι 

368 
INTRODUCTION TO STOCHASTIC PROCESSES 
Therefore, ifi is null recurrent, then p\™' -> 0 as n —> oo. 
Proof: For the proof, the reader is refer to Resnick (1994). 
■ 
It is to be observed that if i € S is a null recurrent state with X(i) = 1, 
then: 
lim pln) = 0 . 
n—>oo 
Theorem 9.11 If j —> i and j is recurrent, then it satisfies: 
1. fij = I-
2. p*j = oo. 
Proof: 
1. Suppose that p?' > 0, with r being the least positive number with this 
property. We have: 
fij = P(Xn = j fo'r some n\X0 
= i). 
Therefore: 
0 < pg5(1 - fa) < P(Xn φ j for all n\X0=j)= 
0. 
Which implies: 
PS;)(I-^)=O. 
Since p^ > 0, it follows that fij = 1. 
2- P*j = fijPjj = °°; t h e n Pij = °°-
■ 
Theorem 9.12 Let {Xn] n>0} 
be an irreducible Markov chain whose states 
are recurrent and aperiodic. Then 
1· 
(") 
1 
hm p> 
= — 
n—yoc 
J 
ßj 
independent of the initial state i. 
Proof: For the proof, the reader is refer to Resnick (1994). 
■ 
9.2.2 
Measure of Stationary Probabilities 
To complete the count of significant results in the context of the theory of 
Markov chains, we present the concept of invariant probability measure on the 
state space S and give a necessary and sufficient condition for the existence 
of such a measure. 

DISCRETE-TIME MARKOV CHAIN 
369 
Definition 9.33 Let {Xn\n 
> 0} be a Markov chain with state space S. A 
probability measure π — (n^hes 
over S is called invariant or stationary if 
■Kj = ^2 πφ^ 
(9.6) 
i€S 
for all j e S. In other words, π is invariant if π = πΡ. 
Theorem 9.13 Let {Xn;n 
> 0} be an irreducible, aperiodic Markov chain 
with state space S. Then there exists an invariant probability measure over 
S if and only if the chain is positive recurrent. 
The determined probability 
measure is unique and satisfies the condition (9.6). 
Without loss of generality we assume that S = N. 
Proof: Let us assume that there exists an invariant probability measure π 
over S that satisfies (9.6) since π = πΡ. Then π = πΡη. That is: 
Σ
(η) 
If the states of a Markov chain are transient or null recurrent, then 
lim p£> = 0 
and therefore π, = 0 for all j , which is absurd, since ΣΠΙι πί = 1· 
Suppose that the chain is positive recurrent and let: 
ITJ := — j e S. 
1. Since the matrix Pn is stochastic: 
\ A / 
l i t 
lib 
n—>oo 
j=0 
j=0 
j=0 
Therefore, Y^LQTTJ < 1. 
On the other hand, using the Chapman-Kolmogorov equation: 
fc=0 
Then TTJ > Σ™=0 i^kPkj for all m. That is: 
oo 
Σ 
nkPkj < TTj for all j G S. 
fe=o 

370 
INTRODUCTION TO STOCHASTIC PROCESSES 
Suppose that for some j we have Y^kLo^kPkj 
< π3· Then 
oo 
oo 
Σ ^ > Σ Σ
 π*^ = Σ
π* Σ ^ = Σ
 π«=' 
j=o 
j=ofc=o 
fe=o 
j=o 
fc=o 
which contradicts the fact that j is recurrent. Therefore, for all j it 
satisfies: 
oo 
Tj =y^7TfcPfcj. 
fc=0 
That is, πΡ = π. Hence if πΡη = π and 
^■ = Σ π * ί , δ ) v j e 5 , V n > i , 
fc=0 
then for all e > 0 there exists no > 1 such that: 
oo 
» 
Σ
(") ^ 
k=no+l 
Hence: 
fe=0 fc=0 
no 
«o 
fc=0 fc=0 
Since e > 0 is arbitrary, (9.7) and (9.8) imply that 
oo 
π3 = 7 Γί'Σ 7 Γ' !' 
fc=0 
that is, Efclo71"*: = 1· 
2. If it is assumed that there exists another stationary distribution {rk)k€S, 
then it is obtained similarly that: 
*ν=ΣΓ*ρ'Μ 
fc=0 
Now taking the limit as n —► oo, we obtain: 
oo 
r3 
fc=0 fc=0 
= Σ
 r f c 7 rJ
= πί Σrfc = π ί
V j e s-

CONTINUOUS-TIME MARKOV CHAINS 
3 7 1 
EXAMPLE 9.30 
Let {Xn;n 
> 0} be a Markov chain with state space S ~ {1,2,3} and 
transition matrix 
/ 0 
1 
2 
V i 
{Xn;n 
> 0} is an irreducible, aperiodic Markov chain, and also S is 
finite so that the chain is positive recurrent. Thus, there exists a sta-
tionary probability measure π = (^j)jes 
oyer S. Find these stationary 
probabilities π^. 
Solution: Since πΡ = n, we obtain from the system: 
7Γι + Έ2 + 7Γ3 = 
1 
1"1 = 
5 π 2 + 
π 3 
7Γ2 = 
f 7Γι 
.π3 
= 4 π 1 + 271"2-
Solving the system, we obtain: 
8 
6 
5 
7Γι 
= 
It is known that 
π ι = Ϊ 9 ' 7 Γ 2 = Ϊ 9 ' 7 Γ 3 ^ 1 9 · 
h m 
p), 
= -Kj 
for j = 1,2,3 independent of i; this implies, in particular, that the 
probability that, for some n sufficiently large, the chain is in state 1 
given that it started from state i is equal to ^ independent of the 
initial state i. 
A 
9.3 
CONTINUOUS-TIME MARKOV CHAINS 
In the previous section it was assumed that the time parameter t was dis-
crete. This assumption may be appropriate in some cases, but in situations 
such as queueing models, the time parameter should be considered as con-
tinuous because the process evolves continuously over time. In probability 
theory, a continuous-time Markov process is a stochastic process {Xt; t > 0} 
that satisfies the Markov property. It is the continuous-time adaptation of a 
Markov chain and hence it is called a continuous-time Markov chain (CTMC). 
In this section we are going to study the definition and basic properties of the 
CTMC with some examples. 
Definition 9.34 Let X = {Xf,t > 0} be a stochastic process with countable 
state space S. We say that the process is a continuous-time Markov chain if: 
P {XU = 3 I *ti = h, · ■ ■ , Xtn-! = in-l) = P {Xtn = j I Xtn-i = in-l) 

372 
INTRODUCTION TO STOCHASTIC PROCESSES 
for all j,i,··· 
, i n-i € S and for all 0 < t\ < t-i < ■ ■ ■ < tn. 
For Markov chains with discrete-time parameter we saw that the n-step 
transition matrix can be expressed in terms of the transition matrix raised to 
the power of n. In the continuous-time case there is no exact analog of the 
transition matrix P since there is no implicit unit of time. We will see in this 
section that there exists a matrix Q called the infinitesimal generator of the 
Markov chain which plays the role of P. 
Definition 9.35 We say that the continuous-time Markov chain is homoge-
neous if and only if the probabilities P(Xt+e = j' | Xs = i) is independent of 
s for all t. 
Definition 9.36 The probability 
Pij(t) = P(Xt+t=j\Xs 
= i) 
where s,t > 0 is called the transition probability for the 
continuous-time 
Markov chain. 
Let pij (t) be the probability of transition from state i to state j in an interval 
of length t. We denote: 
P{t) = (P«(*)) 
f o r all t, j € 5 . 
We say that P(t) is a transition probability matrix. It is easy to verify that 
it satisfies the following conditions: 
1. pij(0) = δίά. 
2. limt_x)+ pij(t) = 6ij. 
3. For any t > 0, i, j € 5, 0 < p y(t) < 1 and EjtesPifcW = *· 
4. For all i,j € 5, for any s, t > 0: 
p«(* + «) = Swfc(t)-p*j(«)- 
<9·9) 
fc€5 
The above equation is called a Chapman-Kolmogorov equation for continuous-
time Markov chains. 
Note 9.7 
1. From part 2 of the above observation we get 
lim P(t) = I 
t-X)+ 
where I is the identity matrix. 

CONTINUOUS-TIME MARKOV CHAINS 
373 
2. From part 4 of the above observation we get 
P(s + t) = 
P(s).P(t), 
that is, the family of transition matrices forms a semigroup. 
(9.10) 
Note 9.8 The following properties of transition probabilities are extremely 
important for applications of continuous-time Markov chains. They are out-
lined here without proof and the reader may refer to Resnick (1994). 
1. Pij(t) is uniformly continuous on [0, oo). 
2. For each i £ S we have that 
hm 
—— = qi 
t-+o+ 
t 
exists (but may be equal to +00,). 
3. For all i,j e S with ιψ j , we have that the following limit exists: 
1· 
Ptj(*) 
hm 
J 
= qa < 00 . 
t-vo+ 
t 
J 
Definition 9.37 The matrix 
Q = 
—Qo 9oi 
902 
9io 
-91 
912 
920 
921 
—92 
is called the infinitesimal generator of the Markov chain {Xt\ t > 0}. 
Since P(0) = I, we conclude that: 
Q = P'(0). 
Note 9.9 Suppose that S is finite or countable. The matrix Q = 
{qij)ii€S 
satisfies the following properties: 
1. qa < 0 for all i. 
2. qij > 0 for all i φ j . 
3- Yllij 
= 0 for all i. 
The infinitesimal generator Q of the Markov chain {Xt\t 
> 0} plays an 
essential role in the theory of continuous-time Markov chains as will be shown 
in what follows. 

374 
INTRODUCTION TO STOCHASTIC PROCESSES 
Definition 9.38 
1. A state i ε S is called an absorbing state if qi = 0. 
2. If qi < oo and qi = Y^j^qij, 
^en the state i is called stable or regular. 
3. A state i G S is called an instantaneous state if qi = oo. 
Theorem 9.14 Suppose that g, < oo for each i € S. 
Then the transition 
probabilities Pij(t) are differentiable for allt>0 
and i,j 6 S and satisfy the 
following equations: 
1. (Kolmogorov forward equation) 
Pij(t) = -qjPij(t) + ^2qkjPik{t) ■ 
2. (Kolmogorov backward equation) 
or equivalently: 
Pij(t) = -QiPij(t) + 
Y^qikPkj(t) 
k^i 
P(t) 
= 
P(t)Q 
P(t) 
= 
QP(t). 
The initial condition for both the equations is P(0) = I. 
Proof: For h > 0 and ί > 0 it is satisfied that: 
= 
^ ipu(h)Pij(t) - Pij(t)) + - \J2 
Pik{h)pkj(t) 
,fces 
If h 10, then we have 
,. 
Pij{h + t) -pij(t) 
.. 
^ 
. . 
hi0 
h 
kTs 
~Y^QikPkj{t) 
kes 
where qu = -qi. 

CONTINUOUS-TIME MARKOV CHAINS 
375 
Formally the solution of the above equations can be cast in the form 
tnQn 
P(t) = e^ = I + J2 
i 
n ! 
' 
n=l 
If Q is a finite-dimensional matrix, the above series is convergent and has 
a unique solution for the system of equations. If Q is infinite dimensional 
we cannot say anything. Suppose that Q is a finite-dimensional matrix and 
diagonalizable and let ßo, ßi, ■ ■ ■ ,ßn be the distinct eigenvalues of the matrix 
Q. Then there exists a matrix A such that 
ßo 
0 
\ 
0 
ep 
Note 9.10 For a given matrix Q we can define a stochastic matrix P as 
follows: 
1- 
lfqi¥=0, 
\ 0 , 
i = j 
2. If qi= 0, then Pij := Sij . 
EXAMPLE 9.31 
Let: 
Then: 
Since 
we have, for example: 
-5 
3 
2 
Q = | 
1 
- 2 
1 
4 
0 - 4 
0 
3 
2 
i 
5 
5 
- 
0 
-
2 
U 
2 
1 
0 0 
9i = Y^qij = 5 
912 
Λ 
Pl2 = 
= ■=· 
qi 
o 

376 
INTRODUCTION TO STOCHASTIC PROCESSES 
Figure 9.8 
State transition diagram for Example 9.32 
EXAMPLE 9.32 
Consider a two-unit system. Unit A has a failure rate λ^ and unit B has 
failure rate λβ. There is one repairman and the repair rate of each of 
the units is μ. When both the machines fail, the system comes to a stop. 
In this case, {Xt',t > 0} is a continuous-time Markov chain with state 
space 5 = {0,1,4, Iß, 2} where 0 denotes both the units have failed, \A 
denotes unit A is working and unit B has failed, Iß denotes unit A has 
failed and unit B is working and 2 denotes both the units are working. 
The corresponding infinitesimal generator matrix is given by: 
Q = 
The state 0 is an absorbing state. The state transition diagram for this 
Markov chain is shown in Figure 9.8. 
Then the transition probability matrix P is: 
/ o 
XA 
λ β 
V ° 
0 
- ( Α Λ + μ) 
0 
AB 
0 
0 
- ( λ β + μ ) 
ΑΛ 
0 
\ 
Μ 
μ 
-(λ Λ + λβ) ) 
( 
Ρ = 
1 
λΛ+μ 
AB 
λ Β+μ 
0 
0 
0 
0 
λΛ+Af 
0 
0 
0 
λΑ+λΒ 
ο 
\ 
λΑ+μ 
λ Β+μ 
0 
Definition 9.39 Let {Xt',t > 0} be a continuous-time Markov chain with 
transition probability matrix {P{t))t>0. 
A measure μ defined over the state 
space S is called an invariant measure for {Xt;t > 0} if and only if, for all 

CONTINUOUS-TIME MARKOV CHAINS 
377 
ί > 0, μ satisfies 
μ = μΡ(ϊ) 
that is, for each j € S, μ satisfies: 
ies 
If Σ/jes ^U) = 1, then μ is called a stationary 
distribution. 
■ EXAMPLE 9.33 
Let {Xt\t 
> 0} be a continuous-time Markov chain with state space 
5 = {0,1} and transition matrix given by: 
P{t) = M I f -3t ? , f-3t 
■ 
\ 
3 
3 C 
3 ~ 3 C 
/ 
It is easy to verify that μ = ( | , | ) is a stationary distribution for 
{Xt;t>0}. 
A 
Definition 9.40 Let {Xt;t 
> 0} be a continuous-time 
Markov chain with 
infinitesimal generator Q and initial probability distribution X on S. 
The discrete-time Markov chain with initial probability distribution X and tran-
sition probability matrix P [given by (9.11)] is called the embedded Markov 
chain. 
Now we will make use of the embedded Markov chain to give conditions that 
will guarantee the existence and uniqueness of a stationary distribution. 
Theorem 9.15 Let {Xt',t 
> 0} be a continuous-time 
Markov chain with 
infinitesimal matrix Q and let {Yn',n ε Ν} be the corresponding embedded 
Markov chain. 
If {Yn;n 
e N} is irreducible and positive recurrent with 
X := inf{Xi 
: i € S} > 0, then there exists a unique stationary distribu-
tion for 
{Xt;t>0}. 
Proof: Prom the theory developed for discrete-time Markov chains, we have 
that the transition matrix Ργ of the embedded Markov chain {Fn;n € N} has 
a unique stationary distribution v with νΡγ ~ v. The infinitesimal generator 
Q satisfies: 
Q = A(Py - Is). 
Since Is is the identity matrix of order \S\ and 
Λ = diag(Aj : i € S) 

378 
INTRODUCTION TO STOCHASTIC PROCESSES 
then μ := vA * is a stationary measure for the process {Xt',t > 0}. Because 
λ > 0, by hypothesis, μ is finite. Let π = {KJ : j € S) be defined by 
7Γ. 3 ·-
or equivalently: 
ies 
Thus we obtain a stationary distribution for {Xt; t > 0} which is unique since t; 
is unique. In addition, from the relation between {Yn; n € N} and {Xt; t > 0} 
and from the way the invariant measure {V^,;n € N} was constructed, we 
conclude that: 
lim P (Xt 
t-+oo 
J)=Kj, 
J€S-
EXAMPLE 9.34 
Birth-and-Death Processes 
A birth-and-death process (BDP) 
is a continuous-time Markov chain 
{Xt; t > 0} with state space S = N such that the elements qi,i-i,qu and 
qi,i+i of the intensity matrix Q are the only ones that can be different 
from zero. Let 
λχ := 9i,i+i 
and 
Mi := 9»,i-i 
be the birth and death rates, respectively, as they are known. The 
matrix Q is given by: 
Q = 
' — λο 
λο 
μι 
- ( λ ι + Μ ι ) 
0 
Μ2 
V 
0 
0 
0 
λι 
0 
0 
-(λ 2+μ 2) 
λ2 
0 
. . . \ 
/ 
It is clear that \h 4- o(h) represents the probability of a birth in the 
interval of infinitesimal length (i, t+h) given that Xt = i. Similarly ßih+ 
o(h) represents the probability of a death in the interval of infinitesimal 
length (t,t + h) given that Xt = i. Prom the Kolmogorov backward 
equations, we obtain: 
Pojit) 
= 
-*oPoj{t) + AoPij(i), j = 0,1,2, · ■ · 
Pij(t) 
= 
-(A» + Mi)Pii(i) + A ip i +i, i(i)+/i ip j-i,j(i) for i > 1. 

CONTINUOUS-TIME MARKOV CHAINS 
3 7 9 
Similarly, for the forward Kolmogorov equations, we obtain: 
Patt) 
= -λοΡ»ο(*) + μιΡϋ(ί), 
i&S 
Pij(t) 
= -(λ; + Hj)Pij(t) + xJ-iPi,j-i(t) 
+ ßj+iPi,j+i(t) for j > 1 . 
These equations can be solved explicitly for some special cases, as we 
will show later. 
Next we will suppose that the state space 5 is finite and that \ > 
0, μί > 0 for i £ S. The embedded Markov chain is irreducible and posi-
tive recurrent. Hence there exists a stationary distribution for {Xt',t > 0}, 
say π = (πο, πι, · · · , 7rm). π is the solution of the system π<2 = 0, which 
is given by: 
λολι···λί-ι 
7Tj = 
7Γο, 
t = Ι,Ζ,- 
■ · , m . 
μιμ2···μί 
Also Σ Χ 0 7^ = 1. Then: 
1 
7Γ0 = 
ι + Σ 
λολι···λ<_1 
EXAMPLE 9.35 Linear Pure Death Process 
In the previous example of a birth-and-death process, suppose that λο = 
λι = ■ · · = 0 and that μ* = ίμ. Let us assume that the initial size of 
the population is N > 0. Then the backward and forward Kolmogorov 
equations are respectively 
p'i:j(t) 
= 
iß (pi_i j(t) - pi:i(t)), 
j<i<N 
ρ'Η{ί) 
= 
-*μρ«(ί) 
i<N 
and 
Pi>(*) = 
J>(ft-ij(*)-Pij(*)), 
3<i<N 
p'u(t) 
= 
-ίμρ»(*) 
» < # · 
We obtain that 
Py(*) = (*) (^"T (1 - e-" 1)^ , 
0 < j < i , 
and therefore: 
N 
P(Xt = k)= pNk(t) 
= (^ 
(e-^)k 
(1 - e-"t)N-k 
, k = 0,1, · · · , 
In other words, Xt has a binomial distribution with parameters N and 

380 
INTRODUCTION TO STOCHASTIC PROCESSES 
EXAMPLE 9.36 Poisson Process 
Suppose that in the birth-and-death process we assume that μ\ = μι = 
• ■ · = 0 and Aj = λ for all i € S. Further we assume that XQ = 0 and 
Pi(t) — P (Xt = i | XQ = 0). We obtain both Kolmogorov equations as 
follows: 
p'0(t) 
= 
-λρο(ί) 
p'jit) 
= 
-XPj(t) 
+ Xpj-xit) . 
By solving the above systems of equations, we obtain: 
Ρ ( Χ ί = η ) = ε - λ ί ^ , 
71 = 0,1,2,.·· . 
n! 
The random variable Xt has a Poisson distribution with parameter Xt. 
The process {Xf,t > 0} is called a Poisson process with parameter λ. 
▲ 
EXAMPLE 9.37 
Assume that individuals remain healthy for an exponential time with 
mean j before becoming sick. Assume also that it takes an exponential 
time to recover from sick to healthy again with mean sick time of ^. 
If the individual starts healthy at time 0, then we are interested in the 
probabilities of being sick and healthy in future times. Let state 0 denote 
the healthy state and state 1 denote the sick state. 
We have a birth-and-death process with 
λο = λ, and μι = μ 
and all other Χί,μί are zero. 
From the Kolmogorov backward equations, we have: 
Ροο(0 = λριο(ί) - λροο(ί) 
PioW = Woo(i) - ΑΦιο(ί) 
p'm(t) = Apu(i) - Xpoi(t) 
P'IIW =μΡοι(*)-ΑΦιι(ί) 

POISSON PROCESS 
381 
It can be shown that: 
PDOW = 
- ^ Τ + 
^
6
"
^ 
μ + λ 
μ + A 
The stationary probability for the above equation is 
7T0 = lim ροο(ί) = — — 
t->oo 
/i + A 
and 
Ti-j = lim pn(i) = — — . 
▲ 
t->oo 
μ + A 
9.4 
POISSON PROCESS 
In Example 9.36 of the previous section, we defined the Poisson process. This 
process, named after the French mathematician Simeon Denis Poisson (1781-
1840), is one of the most widely used mathematical models. This process 
was also used by the Swedish mathematician Filip Lundberg (1876-1965) in 
1903 in his doctoral thesis "Approximerad framställning af sannolikhetsfunk-
tionen/ Äterförsäkring af kollektivrisker" (Approximations of the probability 
function/ Reinsure of collective risks) to determine the ruin probability of an 
insurance company. Later the Swedish mathematician, actuary, and statisti-
cian Harald Cramer (1893-1985) and his pupils developed the ideas of Lund-
berg and constructed the so-called ruin process or Cramer-Lundberg model, 
which allows us to describe, at each instant, the reserve of an insurance com-
pany. Poisson processes have applications not only in risk theory but also in 
many other areas, for example, reliability theory and queueing theory. 
Note 9.11 Let {Nt; t > 0} be a Poisson process with parameter A > 0. Then 
it satisfies the following conditions: 
1. N0 = 0. 
2. It has independent and stationary 
increments. 
3. It has unit jumps, i.e., 
P(Nh = l) 
= 
Xh + o{h) 
P(Nh>2) 
= 
o(h) 
where Nh := Nt+h - Nt . 
The interested reader may refer to Hoel et al. (1972). 

382 
INTRODUCTION TO STOCHASTIC PROCESSES 
■ EXAMPLE Θ.38 
The examples for the Poisson processes are as follows: 
1. The number of particles emitted by a certain radioactive material un-
dergoing radioactive decay during a certain period. 
2. The number of telephone calls originated in a given locality during a 
certain period. 
3. The occurrence of accidents at a given road over a certain period. 
4. The breakdowns of a machine over a certain period of time. 
▲ 
EXAMPLE 9.39 
Suppose that accidents in Delhi roads involving Blueline buses obey a 
Poisson process with 9 accidents per month of 30 days. In a randomly 
chosen month of 30 days: 
1. What is the probability that there are exactly 4 accidents in the first 15 
days? 
2. Given that exactly 4 accidents occurred in the first 15 days, what is the 
probability that all 4 occurred in the last 7 days out of these 15 days? 
Solution: Let Nt := "number of accidents in the time interval (0, £]" 
where the time t is measured in days. 
Given that Nt = P(ggt), the probability of exactly 4 accidents in the 
first 15 days is: 
P(jV15 - 4) = e ~ 4 · 5 ^ - = 0.1898. 
Now: 
P(4 accidents occurred in last 7 days | 4 accidents occurred in 15 days) 
_ 
P(4 accidents in 15 days where all 4 are in the last 7 days) 
P(4 accidents in 15 days) 
P(no accident in the first 8 days and 4 accidents in the next 7 days) 
P(4 accidents in 15 days) 
Assume: 
P(no accident in 8 days) 
= 
P{N(8) = 0) 
= 
e~&8 = 0.0.0907 
P(4 accidents in 7 days) 
= 
P(N(7) = 4) 
= 
,30 ' = 0.0992 , 

P0ISS0N PROCESS 
383 
the required probability is: 
0.3247 x 0.0315 
0.1898 
= 0.0474 
EXAMPLE 9.40 
Suppose that incoming calls in a call center arrive according to a Poisson 
process with intensity of 30 calls per hour. What is the probability that 
no call is received in a 3-minute period? What is the probability that 
more than 5 calls are received in a 5-minute interval? 
Solution: Let Nt := "number of calls received in the time interval (0, t]" 
where the time t is measured in minutes. 
Prom the data given above, it is known that Nt = V(\t). 
Therefore: 
P(N3 = 0) 
= 
e - ° - 5 x 3 = 0.22313 
P(7V5>6) 
= 
f > - 2 - 5 ^ j ^ = 0.042. 
A 
Definition 9.41 Let {Nt; t > 0} be a Poisson process with parameter λ > 0. 
IfTn is the time between the (n — l)th and nth event, then {T„; n = 1,2,···} 
are the interarrival times or holding times 
of Nt, and Sn — Σ™=1 T*, for 
n > 1 is the arrival time of the nth event or the waiting time to the nth event. 
Theorem 9.16 The T{ 's have an exponential distribution with expected value 
1 
A ' 
Proof: Let T\ is the time of the first event. Then: 
Ρ{Τλ >t) = P(Nt = 0) = e~xt . 
Thus T\ has an exponential distribution with expected value j . Now: 
P(T2 > ί|Γι = s) = P(0 events in (s, s +1]]^ = s) 
= P(0 events in (s, s + i\) 
(independent increments) 
= P(0 events in (0, t]) 
(stationary increments) 
= e-xt . 
Thus Ti also has an exponential distribution with expected value \ . Note also 
that T\ and Γ2 are independent and in general we have that the interarrival 
times Tn, n = 1,2, · · ·, are independent and identically distributed random 
variables each with expected value j . 
m 

384 
INTRODUCTION TO STOCHASTIC PROCESSES 
Note 9.12 From the above theorem we have that Sn, the arrival time of the 
nth event, has a gamma(n, X) distribution. Therefore the probability distribu-
tion function of Sn is given by: 
/5„(ί) = λ ε - λ ί £ ^ - , 
t>0. 
( n - 1 ) ! ' 
EXAMPLE 9.41 
Suppose that people immigrate into a territory at a Poisson rate λ = 1 
per day. 
1. What is the expected time until the tenth immigrant arrives? 
2. What is the probability that the elapsed time between the tenth and 
the eleventh arrival exceeds two days? 
Solution: 
E(S10) = f = W days. 
P(Tn 
> 2) = e-2A = e~2 » 0.1353 . 
▲ 
Suppose that exactly one event of a Poisson process occurs during the interval 
(0, t]. Then the conditional distribution of ΤΊ given that Nt = 1 is uniformly 
distributed over the interval (0, t] is: 
P(T1<s\Nt 
= l) 
= 
P(Tl<s,Nt 
= l) 
P(Nt = 1) 
P(N8 = 
l,Nt-a=0) 
P(Nt = 1) 
P(N. = l)P(Nt-, 
= 0) 
P(Nt = 1) 
Xte~xt 
Generally: 
Theorem 9.17 Let Nt be a Poisson process with parameter X. Then the joint 
conditional density of T\, T2, ■ ■ ■ ,Tn given Nt = n is 
/r1,Ta....,Tf.|Art=n(ti,ia,··· ,*n) = I ^n
 
othe 
<ti 
<t2 
<■■■ 
<tn<t 
other cases . 
Proof: Left as an exercise. 
An application of the previous theorem is as follows: Consider a Poisson 
process {Nt; t > 0} with intensity λ > 0. Suppose that if an event occurs, it is 

P0ISS0N PROCESS 
385 
classified as a type-I event with probability p(s), where s is the time at which 
the event occurs, otherwise it is a type-II event with probability 1 — p(s). We 
now prove the following theorem. 
Theorem 9.18 (Ross, 1996) If N^' represents the number of type-i events 
that occur in the interval (0, t] with i = 1,2, then N^ ' and N{ ' are indepen-
dent Poisson random variables having parameters Xp and λ(1— ρ), respectively, 
where: 
1 /·* 
P = j J p{s)ds . 
Proof: In the interval (0, t], let there be n type-I events and m type-II events, 
so that we have a total of n + m events in the interval (0, i]: 
P(N[1) 
= n, ΛΓ(
(2) =τη) = Σ 
Ρ(Ν^ 
= n> Μ^ =m\Nt 
= k)P(Nt = k) 
k 
= P(Nt
(1) = n, 7Vt
(2) = m\Nt 
= n + m)P(Nt = n + m) 
( 2 ) _ _ 
I ΛΓ _ „ 
■ _ Λ β - λ ί ( λ ί ) 
= P{N^] 
= n, ATt
(2) = m | Nt = n + m)e 
n+m 
(n + m)\ 
We consider an arbitrary event that occurred in the interval (0, t]. If it has 
occurred at time s, the probability that it would be a type-I event is p(s). In 
other words, we know that the time at which this event occurs is uniformly 
distributed in the interval (0, t]. Therefore, the probability that it will be a 
type-I event is 
p 
:= 
P("type-1") 
= 
E(P("type-l" | T = s) 
I 
1 
i 
p(s)-ds 
o 
t 
independently of other events. Hence P(N^ ' = n,N; ' = m \ Nt = n + m) 
is the probability of n successes and m failures in a Bernoulli experiment of 
n + m trails with probability of success p in each trial. We get 
P(N^=n,N^=m) 
= 
( n + 
m ) p V c-xtWn+m 
(n + m)\ 
= 
c - A P t ( ^ ) " c - A ( i - p ) t ( A ( l - p ) < r 
n! 
m! 
EXAMPLE 9.42 
If immigrants arrive to area A at a Poisson rate of ten per week and 
each immigrant is of English descent with probability ^ , then what is 

386 
INTRODUCTION TO STOCHASTIC PROCESSES 
the probability that no person of English descent will emigrate to area 
A during the month of February? 
Solution: By the previous proposition it follows that the number of 
Englishmen emigrating to area A during the month of February is Pois-
son distributed with mean 4 · 10 · ^ = ψ. Hence the desired probability 
- 1 0 
is e 3 . 
A 
In the following algorithm, we simulate the sample path for the Poisson process 
using interaxrival times which are i.i.d. exponentially distributed random 
variables. 
Algorithm 9.1 
Input: A, T, where T is the maximum time unit. 
Output: PP{k) for k = 0(1 )T. 
Initialization: 
PP(0) := 0. 
Iteration: 
For k = 0(1)T - 1 do: 
U{k + 1) = rand{0,1) 
PP{k + l) = PP(k) - { x log(l - U(k + 1)) . 
where rand(0,1) is the uniform random number generated in the interval 
(0,1). Using the previous algorithm we obtain the sample path of Poisson 
process as shown in Figure 9.9 for λ = 2.5 and T = 10. 
In the Poisson process, we assume that the intensity λ is a constant. If we 
assume a time-dependent intensity, that is, λ = λ(ί), we get a nonhomoge-
neous Poisson process. More precisely, we have the following definition: 
Definition 9.42 (Nonhomogeneous Poisson Process) A Markov process 
{Nt; t > 0} is a nonhomogeneous Poisson process with intensity function 
\{t), 
t > 0, if: 
1. N0 = 0. 
2. {Nt;t > 0} has independent 
increments. 
3. For 0 < s < t, the random variable Nt — Na has a Poisson distribution 
with parameter J3 \(u)du. 
That is, 
(f*X(u)du)k 
P(Nt -N. 
= k)= 
V " 
,, 
; e- /.' ^">d" 
k' 
fork = 0,1,2,··· 
. 

POISSON PROCESS 
387 
δ1 
ä 
c 
S> 
a 
.■> 
™ 
*-« 
•g 
ID 
J3 
E 
I 
30 
25 
20 
15 
10 
5 
1 
1 
1 
1 
J — ^ 
J 
( \ 
H 
Γ* Γ 
f 
r-J 
1 
1 
I 
| 
1 
ΐ 
1 
4 
6 
Time 
10 
Figure 9.9 
Sample path of Poisson process 
Definition 9.43 The function 
m(t) = / 
X(u)du 
Jo 
is called the mean value function 
Note 9.13 If {Nt;t > 0} is a nonhomogeneous Poisson process with mean 
value function m(t), then {Nm-i(ty,t 
> 0} is a homogeneous Poisson process 
with intensity λ = 1. This follows since Nt is a Poisson random variable 
with mean m(t), and if we let Xt = ATm-i(t), then Xt is Poisson with mean 
m(m-x(t)) 
=t. 
EXAMPLE 9.43 
(Ross, 2007) John owns a cafeteria which is open from 8 AM. Prom 8 AM 
to 11 AM, the arrival rate of customers grows linearly from 5 customers 
per hour at 8 AM to 20 customers per hour at 11 AM. From 11 AM to 1 
PM the arrival rate of customers is 20 customers per hour. From 1 PM 
to 5 PM the arrival rate of customers decreases linearly until it reaches 
a value of 12 customers per hour. If we assume that customers arrive 
at the cafeteria in nonoverlapping time intervals and are independent of 
each other, then: 

388 
INTRODUCTION TO STOCHASTIC PROCESSES 
1. What is the probability that no customer arrives at the cafeteria between 
8:30 AM and 9:30 AM? 
2. What is the expected number of customers in the same period of time? 
Solution: Let Nt = "Number of customers arriving to the cafeteria in 
the time interval (0, i\". 
An adequate model for this situation is the nonhomogeneous Poisson 
process with intensity function X(t) given by 
λ(ί) 
5 + 5ί 
if 0 < ί < 3 
20 
if 3 < t < 5 
2 0 - 2 ( i - 5 ) 
if 
5 < t < 9 
andA(i) = A(9-i)fori>9. Since (iV| -ΛΓι) = P (m (^ ) - " 1 ( 5 ) ) 
where m(t) = I X(s) ds, then: 
Jo 
p ( i V § - i V i = o ) = e - 1 0 . 
The expected number of clients in this period of time is 10. 
A 
Definition 9.44 (Compound Poisson Process) A stochastic process 
{Xt; t > 0} is a compound Poisson process if 
Nt 
t = l 
where {Nt;t > 0} is a Poisson process and {Yi\ i = 1,2, · · · } are independent 
and identically distributed random variables. 
Note 9.14 
1. IfYt = l, then Xt = Nt is a Poisson process. 
2. 
E(Xt) 
= 
E(E(Xt\Nt)) 
= 
E\E ßH) 
- 
E(NtE(Yi)) 
= 
XtE(Yi) . 

RENEWAL PROCESSES 
389 
3. 
Var(Xt) 
= 
E(Var(Xt\Nt)) 
+ 
Var(E(Xt\Nt)) 
= 
E (NtVar(Yi)) 
+ Var 
(NtE(X)) 
= 
XtVar(Yi) + E{Yi)2Xt 
= 
XtiVarW 
+ EiYi)2) 
= *t(E(Y?)) . 
■ EXAMPLE 9.44 
In life insurance, total claims are often modeled using a compound Pois-
son distribution. Claim numbers are usually assumed to occur according 
to a Poisson process and claim amounts have an appropriate density such 
as a log-normal or gamma. 
A 
■ EXAMPLE 9.45 
Suppose that buses arrive at a sporting event in accordance with a Pois-
son process, and suppose that the numbers of customers in each bus are 
assumed to be independent and identically distributed. Then {Xt; t > 0} 
is a compound Poisson process where Xt denotes the number of cus-
tomers who have arrived by t. In equation (9.12), Vj represents the 
number of customers in the ith bus. 
▲ 
■ EXAMPLE 9.46 
Suppose customers leave a supermarket in accordance with a Poisson 
process. If Yi: the amount spent by the ith customer, i = 1,2,···, are 
independent and identically distributed, then {Xt : t > 0} is a compound 
Poisson process where Xt denotes the total amount of money spent by 
time t. 
A 
9.5 
RENEWAL PROCESSES 
The stochastic process {Nt; t > 0} is called a counting process if Nt represents 
the number of events that have occurred up to time t. 
In the previous section we dealt with the Poisson process, which is a count-
ing process for which the periods of time between occurrences are i.i.d. random 
variables with exponential distribution. A possible generalization is to con-
sider a counting process for which the periods of time between occurrences are 

390 
INTRODUCTION TO STOCHASTIC PROCESSES 
i.i.d. random variables with arbitrary distribution. Such counting processes 
are known under the name renewal processes. 
We have the following formal definition: 
Definition 9.45 Let {Tn;n > 1} be an i.i.d sequence of nonnegative random 
variables with common distribution F, where F (0) = P(Tn = 0) < 1. 
The process {5„; n > 1} given by 
S0 
: 
= 0 
Sn 
: = Τ 1 + Γ 2 + ··· + Τη 
is called a renewal process with duration or length-of-life distribution F. 
If we interpret Tn as the period of time between the (n — l)th and the nth 
occurrence of a certain event, then the random variable Sn represents the nth 
holding time. Therefore, if we define the process {Nt : t > 0} as 
Nt := sup {n: Sn< 
t} 
then it is clear that Nt represents the number of events that have occurred 
(or renewals) up to time t. 
Prom now on we will call, indistinctly, the processes {Sn;n > 1} and 
{Nt;t > 0} as renewal processes. 
■ EXAMPLE 9.47 
The well-known example of renewal processes is the repeated replace-
ment of light bulbs. It is supposed that as soon as a light bulb burns 
out, it is instantaneously replaced by a new one. We assume that succes-
sively replaced bulbs are random variables having the same distribution 
function F. Let Sn = T\ + ■■■ + Tn , where TVs are the random life 
of the bulb with distribution function F. We have a renewal process 
{Nt;t > 0} where Nt represents the number of bulbs replaced up to 
time t. 
A 
In the next theorem, we give a relation between the distributions of Nt and 
Theorem 9.19 For k 6 N and t > 0 we have that: 
{Nt > k} if and only if {Sk < t} . 
Proof: It is clear that Nt > k if and only if in the time interval [0, t] at least 
k renewals have occurred, which in turn occurs if and only if the kth renewal 
has occurred on or before t, that is, if (Sk <t). 
■ 
From the previous result, it follows for t > 0 and k = 1,2, · · · that 
P(Nt = k) = P(Nt>k)-P{Nt>k 
+ l) 
- 
P(Sk<t)-P(Sk+1<t) 
= 
Ffc (t) - Ffc+i (t) 

RENEWAL PROCESSES 
391 
where Fk denotes the fcth convolution of F with itself. 
Similarly, the expected number of renewals up to time t follows from the 
next expression: 
oo 
m(t) := E(Nt) = J2kP(Nt 
= k) 
k=l 
oo 
oo 
oo 
= 5>w >*) = 5>(s* <t) = 5>(*) · 
fc=l fc=l fc=l 
The function m (t) is called the mean value function or renewal function. 
■ EXAMPLE 9.48 
Consider {Tn;n = 1,2,···} with P(Tn = i) = p(l - p ) i _ 1 . Here, T„ 
denotes the number of trials until the first success. Then Sn is the 
number of trials until the nth success: 
P(5 n = 
fc)=(^:1
1)P«(l-; pf-n, 
k>n. 
The renewal process {Nt; t > 0}, expressing the number of successes, is 
given by: 
W 
W 
P(ATt = n) = 53 P(Sn = k) - Σ 
P{Sn+i = k). 
k=n 
fc=n+l 
After simplification, we have 
P{Nt=n)=^_1^(l-p)^-n 
where [i] denotes the greatest integer function of t. 
A 
EXAMPLE 9.49 
Consider a renewal process {Nt;t > 0} with interarrival time distribu-
tion F. Suppose that the interarrival time has a uniform distribution 
between 0 and 1. Then the n-fold convolution of F is given by 
Fn(t) 
= 
P{Sn<t) 
t 
χη-2 
, P(tn <t-x) 
-r:dx 
o 
(n ~ 2)'· 
i" 
= 
-r, 0 < ί < 1 . 
n! 
/ 
Jo 

392 
INTRODUCTION TO STOCHASTIC PROCESSES 
The renewal function for 0 < t < 1 is given by: 
m(t) = V — = e ' - l . 
A 
w 
f-^ n! 
It can be shown that the renewal function m(t), 0 < t < oo, uniquely deter-
mine the interarrival time distribution F. 
In order to describe more accurately a renewal process we will introduce 
the following concepts: 
Definition 9.46 For t > 0 define: 
1. The age: 
St:=t- 
5JV,· 
2. Residual lifetime or overshoot: 
It ■= SWt+i _ *· 
3. Total lifetime: 
ßt--=St+lt-
For instance, consider the case of an individual who arrives, at time t, at 
a train station. Trains arrive at the station according to a renewal process 
{Nt; t > 0}. In this case j t represents the waiting time of the individual at the 
station until the arrival of the train, <St the amount of time that has elapsed 
since the arrival of the last train and the arrival of the individual at the station 
and ßt the total time elapsed between the train that the individual could not 
take and the arrival of the train that he is expected to take. 
Definition 9.47 (Renewal Equation) Suppose {Nt\t > 0} is a renewal pro-
cess and T\ denotes the first renewal time. If T\ has density function f, then: 
m(t) 
= 
E(Nt) 
= 
£?(£(iV t|Ti)) 
= 
f 
[l + 
E{Nt-y)]f{y)dy. 
Jo 
That is, 
m(t) = F(t)+ 
[ 
m{t-y)f(y)dy 
Jo 
where F denotes the distribution function of T\. The above equation is known 
as the renewal equation. In the discrete case, the renewal equation is: 
W 
m(t) = F(t) + J2m(t-k)P(T1 
= k) . 
fc=0 

RENEWAL PROCESSES 
393 
■ EXAMPLE 9.50 
Consider the residual lifetime 7t at time t. Let g(t) = Ε(^(ί)). 
Using 
the renewal equation, we can find g{t). Conditioning on T\ gives: 
g(t)= 
/ 
E(>y(t)\Ti=x)dF(x). 
Jo 
Now, 
E (7(4) | Ti = x > t) = x - t 
while for Ti = x <t: 
E(7(t) 
\T1=x<t)=g(t-x). 
Hence, 
/
OO 
ft 
{x - t)dF(x) + 
g(t- 
x)dF{x) 
is the renewal equation for g(t). 
A 
■ EXAMPLE 9.51 
Consider a maintained system in which repair restores the system to as 
good as new condition and repair times are negligible in comparison to 
operating times. Let T», i = 1,2, · · ■, represent the successive lifetimes of 
a system that, upon failure, is replaced by a new one or is overhauled to 
as-new condition. Let N(t) be the number of failures that have occurred 
up to time t, i.e., Nt = max{n : Τχ + T2 -t 
h Tn < t). 
The renewal function m(t) = E(Nt) is the expected number of failures 
that have occurred by time t. It satisfies the equation 
m(t) = F{t) + [ m(t- 
u)dF(u). 
Jo 
Suppose Ti, i — 1,2,···, follows exponential distribution with parameter 
λ so that F(t) = 1 - e_At, t > 0. Then the renewal process {Nt;t> 
0} 
is a Poisson process with 
P(Nt=k)=(^fe-xt, 
* = 0,1,··· 
and m(t) — \t. 
A 
Next we will discuss the asymptotic behavior of a renewal process. In the first 
place, we will see that, with probability 1, the total number of renewals, as 
the time tends to infinity, is infinity. As a matter of fact: 

394 
INTRODUCTION TO STOCHASTIC PROCESSES 
Theorem 9.20 For each renewal process {Nt : t > 0} we have that: 
p(limNt=oo) 
=1 . 
\t->oo 
/ 
Proof: For alln> 
1, we have 
1 = 
lim P (Sn < t) 
t—>oo 
= 
lim P (Nt > n) 
t—>oo 
= 
P ( lim Nt > n) 
\t-KX3 
/ 
so that: 
P ( lim Nt = oo) = 1 . 
\t->oo 
/ 
■ 
Theorem 9.21 With probability 1, we have 
Nt 
1 
> — when t —> oo 
t 
μ 
where 
μ:=Ε{Τ{). 
Proof: Since for any t > 0 
Nt=n 
<*=> Sn < t < Sn+1 
then: 
SNt 
t 
SNt+1 Nt + 1 
Nt ~ Nt 
Nt + 1 Nt 
' 
By using the strong law of large numbers, we have that: 
hm -~ = μ . 
t-s-oo Nt 
Then: 
lim — = μ . 
t-yoo Nt 
m 
Our next goal is to prove that the expected number of renewals per unit 
time tends to μ when t —> oo. We could think that this result is a con-
sequence of the previous theorem. Unfortunately that is not true, since if 
Y, Yi, Y2, ■ ■ ■ are random variables such that Yn —> Y with probability 1, we 
do not necessarily have that E (Yn) —> E (Y). 
Theorem 9.22 (The Elementary Renewal Theorem) Let {Nt;t > 0} 
be a renewal process. Then: 
m(t) 
E(Nt) 
t 1 
= 
> — when t —> 00 . 
t 
t 
μ 

RENEWAL PROCESSES 
395 
Proof: We have that: 
E(SNt+1) 
= 
f?(iVt + l)£?(Ti) 
= 
(m(i) + l ) / i . 
It follows that: 
m W _ 
1
F(c 
rt 
. ! 
! 
Because 5jvt+i > i, we have (m (i) + 1) μ > £ (ί) = t, and we obtain that: 
liminf—^ > - . 
t->oo 
ί 
μ 
Since 
«SjVt+i — ί < Sjvt+i - SJV, = ΪΛΓ,+Ι , 
it follows that 
mit) 
l 
1 „,„, 
ί 
μ 
μί 
If the random variables ΤΊ, Γ2, · ■ · are uniformly bounded, then there exists 
a number M > 0 such that 
P ( T n < M ) = l . 
Thus E (T/vt+i) < M and we obtain 
mit) 
1 
hmsup 
< — 
t-»oo 
ί 
A* 
completing the proof in this case. 
If the variables are not bounded, we can consider a fixed number K and 
construct the truncated process (T„) 
given by 
_ / Tn 
-{ 
K 
if 
Tn<K 
if 
Tn>K 
for n = 1,2, · · ·. It is clear that T„ /* Tn as Ä" —► 00. For the renewal process 
{Nt;t > 0} is determined by the process (Tn)n>1 
and consequently we have: 
mit) 
1 
hmsup 
< —==r- . 
t->oo 
t 
- E (Ti) 
Since 
mit) 
<m(t) 
it follows that: 
mit) 
1 
hmsup—— < —=■ 
. 
t-yao 
t 
E[li) 

396 
INTRODUCTION TO STOCHASTIC PROCESSES 
Allowing K —> oo and using the monotone convergence theorem, it follows 
that: 
E (%) S μ ■ 
Next, we will show that Nt has, asymptotically, a Gaussian distribution. 
Theorem 9.23 Suppose μ = Ε (Τχ) and σ2 = Var (ΤΊ) are finite. Then: 
Um P I ^ΙΖΆ < y ) = 1 f 
exp (_^\ 
dx . 
Proof: Fix x and let n —► oo and t —> oo so that: 
f — nu 
Observing that Τ\,Τ-χ,■ ■ ■ are i.i.d. random variables, the central limit theo-
rem implies that: 
lim P (Sn > t) 
= 
lim P (Sn > ημ — xay/n) 
n—>oo 
n—>οο 
= 
l i m p (Sn^W 
> 
_χ 
ay/n 
„2* 
Since 
we have 
χσ 
y/n 
= 
— 
= vfc/-*
expH)
du 
= i/ooeXPH)dU-
+ \]{χσγ + 4ίμ 
2μ 
n — τ. 
M μ3 
— = Χ\ 
I 
Λ 
xay/n\ 
x \
l
+ t ) 
when t —> oo. Therefore 
Nt-i- 
n - M 
Nt-L 
P(Nt<n) 
= P\ —j^- 
< —jL· 
\ ^ P \ 
- ^ = £ < x 
rr 
I t 
„ 
t 
I 
\ 
_ 
/ t 
and it follows that: 

RENEWAL PROCESSES 
397 
Definition 9.48 A nonnegative random variable X is said to be a lattice if 
there exists d>0 
such that: 
oo 
Σρ (X = nd) = 1 . 
n=0 
That is, X is a lattice if it only takes on integral multiples of some nonnegative 
number d. The largest d having this property is called the period of X. If X 
is a lattice and F is the distribution function of X, then we say that F is a 
lattice. 
■ EXAMPLE 9.52 
(a) If P (X = 2) = P (X = 4) = \, then X is a lattice with period 2. 
(b) UP{X = 4π) = P (X = 6π) = \, then X is a lattice with period 2π. 
(c) If P (X = V2) = P (X = VE) = | , then X is not a lattice. 
(d) If X = exp (λ), then X is not a lattice. 
▲ 
We will now state a result known as BlackwelPs theorem without proof. If F 
is not a lattice, then the expected number of renewals in an interval of length 
a from the origin is approximately - . In the case of F being a lattice with 
period d, the Blackwell theorem asserts that the expected number of renewals 
up to nd tends to - as n —► oo. 
Theorem 9.24 Let {Nt;t > 0} be a renewal process having renewal function 
m(t). 
(a) If F is not a lattice, then 
lim (m(t + a) — m(t)) = — 
t—>oo 
μ 
for a > 0 fixed. 
(b) If F is a lattice with period d, then 
lim E (Rn) = -
n—>oo 
n 
where Rn is a random variable denoting the number of renewals up to 
nd. 

398 
INTRODUCTION TO STOCHASTIC PROCESSES 
The Blackwell theorem is equivalent to the following theorem, known as 
the key renewal theorem (Smith, 1953), and will be stated without proof. 
Theorem 9.25 Let F be the distribution function of a positive random vari-
able with mean μ. Suppose that h is a function defined on [0, oo) such that: 
(1) h(t)>0 
for all t > 0. 
(2) h (t) is nonincreasing. 
(3) I 
h (t) dt < oo 
Jo 
and let Z be the solution of the renewal equation 
Z(t) = h(t)+ 
f Z(t- 
x) dF (x) . 
Jo 
Then: 
(a) If F is not a lattice: 
[ 
0 
if μ = 
l
i
m
Z
r 
, 
, 
. . ! - , - . 
»j 
^ < 0 O 
t—»oo 
= OO . 
(b) If F is a lattice with period d, then for 0 < c < d we have that: 
1 °° 
— T J / I (C + nd) 
if 
μ < oo 
lim Z (c + nd) = < ^n=0 
0 
if μ — oo . 
Next we are going to use the key renewal theorem to find the distributions 
of the random variables 6t := t — SN( (age) and ßt (total lifetime). 
Theorem 9.26 For t S (x, oo) we have the function z(t) = P (St > x) satis-
fying the equation 
z(t) = l-F(t 
+ x)+ 
[ 
z{t-u)dF(u) 
Jo 
so that, if μ < oo, then: 
1 
f°° 
lim z(t) = - 
(1-F(y))dy 
for x > 0 . 
^°° 
μ Jx 
Proof: Conditioning on the value of ΤΊ, we have for fixed x > 0: 
P(St>x) 
= E(E(X{St>x}\T1)) 
. 

RENEWAL PROCESSES 
399 
Since 
E {X{St>x} | ΪΊ = u) 
= 
P{6t > x | Ti = u) 
1 
if u > t + x 
= 
< 0 
if t <u<t 
+ x 
P(St-u>x) 
iiO 
<u<t 
we write: 
P(5t>x) 
= 
/ 
P(St>x\Ti=u) 
dF (u) 
Jo 
= 
l-F(t 
+ x)+ 
[ P (St-u > x) dF (u) . 
Jo 
Thus 
z(t) = 
l-F {t + x)+ [ 
Jo 
z{t-u) 
dF (u) 
so that the function h(t) := 1 — F(t + x) satisfies the key renewal theorem 
conditions, and as a consequence: 
1 f°° 
If00 
lim z(t) = - 
(l-F(u 
+ x))du=- 
(1 - F (y))dy ■ 
Theorem 9.27 The function g (t) = P(ßt > x) satisfies the renewal equation 
g(t) = l-F{tVx)+ 
[ 
g(t-u)dF(u) 
Jo 
where t V x := max (t, x). 
Consequently, 
1 
f00 
lim fl (*) = - / 
ydF(y) 
i/μ < oo. 
Proof: Since 
and 
^ {X{ßt>x} \T1=u) 
= i 
1 
if u > x V ί 
g(t - u) 
if u < ί 
0 
otherwise 
we have that: 
g (t) = 1 - F (i V x) + [ g{t-u)dF{u) 
. 
Jo 

400 
INTRODUCTION TO STOCHASTIC PROCESSES 
Applying the key renewal theorem with /i(i) = l - F ( < V i ) we obtain: 
j 
ΛΟΟ 
1 /·°° 
lim g(t) = - 
[l-F(TVx)]dT=- 
ydF (y) . 
t-yoo 
μ J0 
μ Jx 
9.6 
SEMI-MARKOV PROCESS 
In this section, we give a brief account of the semi-Markov process (SMP) and 
the Markov regenerative process (MRGP). Knowledge of these concepts are 
required for building queueing models, introduced in the next chapter. 
Definition 9.49 (Semi-Markov Process) Let {Yn;n € N} be a stochastic 
process with state space S — N and {Vn\n £ N} a sequence of nonnegative 
random variables. Let 
U0 := 0 
t/i 
:= V1 
n 
Un := £V* for n>2 
and 
U(t) := max{n >l:Un<t}, 
t > 0 . 
The continuous-time stochastic process {Xt',t > 0} defined by 
Xt '■= Yu(t): 
t>0, 
is called a semi-Markov process if the following properties hold: 
(a) For all n > 0: 
P(Yn+l = j,Vn+1 
<t\Yn 
= in,--· ,Y0 = io,Vn<tn,··· 
,Vi <U) 
= P(Yn+i = j , Vn+i <t\Yn 
= in) (Markov property) . 
w 
P(Yn+i = j , Vn+i < t | Yn = i) = P(Yi = j , Vi < t | Y0 = i) (time homogeneity) . 
The semi-Markov process {Xt',t > 0} is also known as a Markov renewal 
process. 
Note 9.15 {Yn,n G N} is a homogeneous Markov chain with transition prob-
abilities given by: 
Pij = lim P(Yn+1 = j,Vn+1 
<t\Yn=i). 
t—>oo 

SEMI-MARKOV PROCESS 
401 
{Υη,η 
€ N} is known as the embedded Markov chain of the semi-Markov 
process {Xt;t > 0}. 
Definition 9.50 M(t) — {mij(t))ijes 
with 
πιφ) 
:= P(Yn+1 = j , Vn+1 
<t\Yn=i) 
is called the semi-Markov kernel. 
Definition 9.51 Let {Xt',t > 0} be a semi-Markov process. Then: 
1. The sojourn time distribution for the state i defined as: 
Hi{t) := P(Vn+1 <t\Yn=i) 
= J2mij{t) ■ 
its 
2. The mean sojourn time in state i is defined as: 
Mi : = < 
/ 0 xhi(x)dx 
if the sojourn time distribution 
is continuous 
Y^j XjP(Vn+i 
= Xj \Yn = i) 
if the sojourn time distribution 
is discrete. 
3. 
F^t) 
= P{Vn+l <t\Yn 
= i,Yn+1 = j) . 
Note 9.16 For i,j £ S, we have: 
Note 9.17 A continuous-time Markov chain is a semi-Markov process with: 
Fij(t) = 1 -e~Xit, 
i > 0 . 
Therefore: 
Hi(t) 
= 
^rrnjit) 
jes 
= 
l - e - A « * 
f°° 
1 
ßi 
= 
Xihi(t)dt = — 
Jo 
·*» 

402 
INTRODUCTION TO STOCHASTIC PROCESSES 
0 
if 
i - 2 
if 
1 
if 
t < 2 
2 < f < 3 
3 < t <oo . 
EXAMPLE 9.53 
Consider a stochastic process {Xt; t > 0} with state space S = {1,2,3,4}. 
Assume that the time spent in states 1 and 2 follow exponential distri-
butions with parameter λι = 2 and λ2 = 3, respectively. 
Further, 
assume that the time spent in states 3 and 4 follow general distributions 
with distribution function H3(t) and Hi(t) (sojourn time distribution) 
respectively and are given by: 
0 
if 
t < 1 
H3(t) = { t - 1 if 
1 < t < 2 
HA{t) = 
1 
if 
2 < t < oo; 
From Definition 9.49, {Xt, ;f > 0} is a semi-Markov process with state 
space S. 
▲ 
The following theorem describes the limiting behaviour of SMPs (see Cinlar, 
1975). 
Theorem 9.28 Let {Xt;t 
> 0} be a SMP with {Yn;n € N} its embedded 
Markov chain. Suppose that {Yn',n S N} is irreducible, aperiodic and positive 
recurrent. Then 
lim P(Xt = j) = 
*>μ1 
(9.13) 
where μ^ is the mean sojourn time in state j and (TTj)jes is the stationary 
distribution of {Yn;n € N}. 
EXAMPLE 9.54 
Consider Example 9.53. Find the steady-state distribution of {Xt;t > 
0}. 
Solution: {Xt;t 
> 0} is a SMP with state space S = {1,2,3,4}. 
{Yn',n € N} is a homogeneous Markov chain with transition probability 
matrix 
" 0 1 0 0 
0 
0 
1 0 
0 
0 0 
1 
1 0 
0 0 
Since {V„;n e N} is irreducible, aperiodic and positive recurrent, the 
stationary distribution π = (^), es exists and is obtained by solving 
π = πΡ and V_] π, = 1 
ies 
to get 
""I = 
7Γ2 = 
7Γ3 = 
7Γ4 = 
- . 

SEMI-MARKOV PROCESS 
403 
D(T) 
Figure 9.10 
State transition diagram for Example 9.55 
The mean sojourn times for states i = 1,2,3,4 are given by: 
1
1
3 
5 
Mi = 2' ^2 = 3 ; ^ 3 = 2' 
μ4=2' 
Using equation (9.13), the steady-state probabilities for the SMP are 
given by: 
limP(X t = l) = A 
t-voo 
2\) 
lim P(Xt = 2) 
2 
29 
l i m P ( X t = 3 ) 
= | -
\imP(Xt=4) = ^ 
t->oo 
zy 
EXAMPLE 9.55 
Consider a system with two components. Each component can fail with 
failure time exponentially distributed with parameter λ. The system 
has one repair unit and the repair time is constant with time T. Note 
that when both the components fail the system will be completely down. 
Assume that both the components can be repaired simultaneously and 
the repair time for both the components is a constant T. Let Xt denote 
the number of components working at time t. Figure 9.10 shows the 
state transition diagram for this model. 
From Definition 9.49, we conclude that {Xt',t > 0} is a semi-Markov 
process. Now: 
= i) 
-2\t 
Kitj(t) 
= P(Xi=j,V! 
<t\X0 
0 
l - e " 2 A t 
0 
±£e-xtdt 
0 
ψ(1-β-
1
0 
0 
xt\ 
By using the steps in Theorem 9.28, the steady state probabilities can 
be obtained. 
A 

4 0 4 
INTRODUCTION TO STOCHASTIC PROCESSES 
Definition 9.52 (Markov Regenerative Process) Let {Yn; n € N} be a 
stochastic process with state space S = N and {Vn;n 
€ N} a sequence of 
nonnegative random variables. Let 
U0 
:= 
0 
Ui 
:= 
V1 
n 
Un := Y^Vi 
for n>2 
i=l 
and 
U(t) := max{n >l:Un<t}, 
t > 0 , 
The process {Xt\t > 0} given by 
Xt '■= Yu(t), 
t>0, 
is called a Markov regenerative process if: 
(a) There exists S C S such that {Yn;n 
€ N} is a homogeneous Markov 
chain with state space S . 
(b) For all n > 0: 
P(Yn+1=j, 
Vn+1 <t\Yn=i,--- 
,Y0=io,Vn<tn,--- 
,Vi < i i ) 
= P(Yn+i = j , Vn+i < t | Yn — i) (Markov property) 
= P(Yi — j,Vi <t\Yo 
= i) (time homogeneity) . 
(c) P(XVn+t=j\Xu,0<u<Vn,Yn 
= i) = P(Xt=j\Y0 
= i) . 
Note 9.18 {Yn',n G N} is a homogeneous Markov chain with state space S . 
Its transition probabilities are given by: 
Pij = lim P(Yn+i 
= j , Vn+l <t\Yn 
= i), 
i,j £ S' . 
t—»oo 
Definition 9.53 K(t) = {kij(t))iJeS> 
with 
kij(t):=P(Y1=j,V1<t\Yo 
= i) 
is called the global kernel of MRGP. 
Definition 9.54 E(t) = (eij(t))ieS'jeS 
with 
eij(t):=P(Y1=j,V1>t\Y0=i) 
is called the local kernel of MRGP. The matrix E(t) describes the behavior 
of the MRGP between two regeneration epochs of the embedded Markov chain 
{Yn,neN}. 

SEMI-MARKOV PROCESS 
405 
Figure 9.11 
State transition diagram for Example 9.56 
Definition 9.55 Let {Xt',t > 0} be a Markov regenerative process. Then: 
1. The sojourn time distribution for state i is defined as: 
Hi(t) := P(Vn+1 <ί\Υη=ί)=Σ 
M*). * e S' ■ 
jes' 
2. The mean sojourn time in state j € S between two successive regenera-
tion epochs given that it started in state i € S after the last regeneration 
is defined as: 
ctij 
:= E(time in state j during (0, Vi) | V"o = Ό 
= 
/ 
eij{t)dt,ieS',j£S 
. 
(9.14) 
Jo 
3. The mean sojourn time in state j € S between two successive regenera-
tion epochs is defined as: 
μ, = Σ 
« i j . 3 e S- 
(9·15) 
ies' 
The following theorem describes the limiting behavior of MRGPs (see Cin-
lar, 1975). 
Theorem 9.29 Let {Xt\t > 0} be a MRGP with state space S and {Yn',n €E 
N} its embedded Markov chain with state space S C S. Suppose that {Yn;n 6 
N} is irreducible, aperiodic and positive recurrent. Then 
lim P(Xt = j) = Z*s'***kJt 
j e S ^ 
( 9 1 6 ) 
*->oo 
lakes' 
nkßk 
where (^k)kes' 
™ the stationary distribution of {Yn;n £ N}, μ& is defined in 
equation (9.15) and ctkj is defined in equation (9.14). 
Markov regenerative processes have wide applications in queueing models 
which are presented in the next chapter. 

406 
INTRODUCTION TO STOCHASTIC PROCESSES 
MRGP - Markov Regenerative Process 
SMP - Semi-Markov Process 
MP - Markov Process 
BDP - Birth-and-death Process 
PP - Poisson Process 
RP - Renewal Process 
CP - Counting Process 
Figure 9.12 
Relationship between various stochastic processes 
■ EXAMPLE 9.56 
Consider Example 9.55. Assume that when both the components fail, 
they cannot be repaired simultaneously. Assume that repair time is 
constant with time T. Let Xt denote the number of components working 
at time t. Figure 9.11 shows the state transition diagram for this model. 
Based on the transition of the system moving from one state to other 
states, we conclude that {Xt',t > 0} is a regenerative process. By using 
the steps in Theorem 9.29, the steady state probabilities can be obtained. 
▲ 
To conclude this chapter, we present Figure 9.12 to indicate the relationship 
of inclusion and exclusion among various important stochastic processes. For 
more details, readers may refer to Grimmett and Stirzaker (2001), Karlin and 
Taylor (1975), Medhi (1994), Lawler (2006), Resnick (1994), Ross (1996), and 
Ross (2007). 
EXERCISES 
9.1 
Let Xt = Acos^t 
+ φ) be a cosine process, where Α,η are real-valued 
random variables and φ is uniformly distributed over (0,2π) and is indepen-
dent of A and η. 

EXERCISES 
407 
a) Compute the covariance function of the process {Xt\t € R}. 
b) Is {Xt',t € R} covariance stationary. 
9.2 
Consider the process Xt = Acos(wt) + Bsin(wt) 
where A and B are 
uncorrelated random variables with mean 0 and variance 1 and w is a positive 
constant. Is {Xt\t > 0} covariance/wide-sense stationary? 
9.3 
Show that an i.i.d. sequence of continuous random variables with com-
mon density function / is strictly stationary. 
9.4 
Show that a stochastic process with independent increments has the 
Markov property. 
9.5 
Suppose that a taxi continuously moves between the airport and two 
hotels according to a Markov chain with a transition probability matrix given 
by: 
Airport 
HotelA 
HotelB 
p _ Airport 
/ 0 
0.6 
0.4\ 
~ HotelA 
0.8 
0 
0.2 
. 
HotelB 
\0.9 
0.1 
0 / 
a) Argue that this Markov chain has a stationary distribution. 
b) In the long run, what proportion of time will the taxi be in each of the 
three locations? 
c) Suppose that you are at the airport and just about to get into this taxi 
when a very rude person barges ahead of you and steals the cab. If each 
transition that the taxi makes takes 25 minutes, how long do you expect 
to have to wait at the airport until the taxi returns? 
9.6 
One way of spreading information on a network uses a rumor-spreading 
paradigm. Suppose that there are 5 hosts currently on the network. Initially, 
one host begins with a message. In every round, each host that has the 
message contacts another host chosen independently and uniformly at random 
from the other 4 hosts and sends the message to that host. The process stops 
when all hosts have the message. 
a) Model this process as a discrete-time Markov chain. 
b) Find the transition probability matrix for the chain. 
c) Classify the states of the chain as transient, recurrent or null recurrent. 

408 
INTRODUCTION TO STOCHASTIC PROCESSES 
9.7 
Consider a Markov chain with state space {0,1,2,3,4} and transition 
matrix 
/ l 
0 
0 
0 
0 \ 
0 
\ 
f 
0 
0 
0 
I 
§ 0 0 
I 
ί 
0 
^ 
i 
4 
4 
u 
4 
4 
\o o o I 1/ 
a) Classify the states of the chain. 
b) Determine the stationary distribution for states 1 and 2. 
c) For the transient states, calculate μ^, the expected number of visits to 
transient state j , given that the process started in transient state i. 
d) Find P{X5 = 2\X3 
= 1). 
9.8 
The transition probability matrix of a discrete-time Markov chain {Xn; n ■■ 
1,2,···} having three states 1, 2 and 3 is 
P = 
0.3 
0.4 
0.3 
0.6 
0.2 
0.2 
0.5 
0.4 
0.1 
and the initial distribution is 
π = (0.7,0.2,0.1) . 
Find: 
a) P(X2 = 3) . 
b) P(X3 = 2,X2 = 3,Xi = S,X0 = 2) . 
9.9 
Consider a DTMC model which arises in an insurance problem. To 
compute insurance or pension premiums for professional diseases such as sili-
cosis, we need to compute the average degree of disability at preassigned time 
periods. Suppose that we retain m degrees of disability 5i, ^2, · · · , Sm- As-
sume that an insurance policy holder can go from degree Si to degree Sj with 
a probability pij. This strong assumption leads to the construction of the 
DTMC model in which P = [p^·] is the one-step transition probability matrix 
related to the degree of disability. Using real observations recorded in India, 
we considered the following transition matrix P: 
P = 
f 0.90 
0 
0 
0 
K° 
0.10 
0.95 
0 
0 
0 
0 
0.05 
0.90 
0 
0.05 
0 
0 
0.05 
0.90 
0.05 
0 
0 
0.05 
0.10 
0.90 
\ 

EXERCISES 
409 
a) Classify the states of the chain as transient, positive recurrent or null 
recurrent along each period. 
b) Find the limiting distribution for the degree of disability. 
9.10 
Let poo = 1 a nd, for j > 0, pjj = p, Pj,j-i = q where p + q = 1, define 
the transition probability matrix of DTMC. 
a) Find /-Q , the probability that absorption takes place exactly at the nth 
step given that the initial state is j . 
b) Find the expectation of this distribution. 
9.11 
Assume a DTMC {Xn; n = 1,2,···} with state space E = {0,1,2} 
and transition probability matrix P given by: 
p=\ 
\ 
* 
\ 
0 
1 0 
i 
0 i 
2 
υ 
2 
0 
1 0 
a) Classify the states of the Markov chain. 
b) Find the distribution of Xn given that the initial probability vector is 
(I I I) 
V3' 3' 3'· 
c) Examine whether there exists a limiting distribution for this Markov 
chain. 
9.12 
Consider a time homogeneous discrete-time Markov chain with tran-
sition probability matrix P and states {0,1,2,3,4} where: 
/ 0.5 
0 
0.5 
0 
0 
\ 
0.25 
0.5 
0.25 
0 
0 
P= 
0.5 
0 
0.5 
0 
0 
0 
0 
0 
0.5 
0.5 
\ 0 
0 
0 
0.5 
0.5 J 
a) Classify the states of the Markov chain as positive recurrent, null recur-
rent or transient. 
b) Discuss the behavior of p^ 
as n —>■ oo for all i, j = 0,1, · · · ,4. 
9.13 
Consider a DTMC with states {0,1,2,3,4}. Suppose p0,4 = 1 a nd 
suppose that when the chain is in state i, i > 0, the next state is equally 
likely to be any of the states 0,1, · · · , i — 1. 
a) Discuss the nature of the states of this Markov chain. 

410 
INTRODUCTION TO STOCHASTIC PROCESSES 
b) Discuss whether there exists a limiting distribution and find it if it exists. 
9.14 
A factory has two machines and one repair crew. Assume that proba-
bility of any one machine breaking down on a given day is a. Assume that if 
the repair crew is working on a machine, the probability that they will com-
plete the repairs in one more day is ß. For simplicity, ignore the probability 
of a repair completion or a breakdown taking place except at the end of a day. 
Let Xn be the number of machines in operation at the end of the nth day. 
Assume that the behavior of Xn can be modeled as a DTMC. 
a) Find the transition probability matrix for the chain. 
b) If the system starts out with both machines operating, what is the prob-
ability that both will be in operation two days later? 
9.15 
Consider a gambler who at each play of the game has probability p 
of winning one unit and probability q = 1 — p of losing one unit. Assume 
that successive plays of the game are independent. Suppose the gambler's 
fortune is presently i, and suppose that we know that the gambler's fortune 
will eventually reach N (before it goes to 0). Given this information, show 
that the probability he wins the next game is: 
l-(,/p). 
l r 
VT 
2 
< 
i^ 1 
if Ώ = i 
9.16 
Consider a DTMC on the nonnegative integers such that, starting from 
i, the chain goes to state i + 1 with probability p, 0 < p < 1, and goes to state 
0 with probability 1 — p. 
a) Show that this DTMC is irreducible and recurrent. 
b) Show that this DTMC has a unique steady state distribution π and find 
7Γ. 
9.17 
Suppose a virus can exist in 3 different strains and in each generation 
it either stays the same or, with probability p, mutates to another strain, 
which is chosen at random. What is the probability that the strain in the nth 
generation is the same as that in the 0th? 
9.18 
There are two drive-through service windows at a very busy restaurant, 
in series, served by a single line. When there is a backlog of waiting cars, two 
cars begin service simultaneously. Out of the two cars being served, the front 
customer can leave if he finishes service before the rear customer, but the rear 
customer has to wait until the first customer finishes service. Consequently, 
each service window will sometimes be idle if their customer completes service 

EXERCISES 
4 1 1 
before the customer at the other window. Assume there is an infinite backlog 
of waiting cars and that service requirements of the cars (measured in seconds) 
are exponential random variables with a mean of 120 seconds. Draw the state 
transition diagram that describes whether each service window is busy. What 
is the stationary probability that both service windows are busy? 
9.19 
Consider a taxi station where taxis and customers arrive independently 
in accordance with Poisson processes with respective rates of one and two per 
minute. A taxi will wait no matter how many other taxis are in the system. 
However, an arriving customer that does not find a taxi waiting leaves. Note 
that a taxi can accommodate only one customer. Let {Xt',t > 0} denote the 
number of taxis waiting for customers at time t. 
a) Draw the state transition diagram for this process. 
b) Find the average time a taxi waits in the system. 
c) Find the proportion of arriving customers that get taxis. 
9.20 
A particle starting at position A makes a random to-and-from motion 
in a circle over A, B, C, D, A such that if it reaches a position I{= A, B, C 
or D) at any step, in the next step, either it stays in the same position with 
probability h or else jumps to the right (clockwise) or left (anticlockwise) with 
probability | or g respectively. 
a) Draw the state transition diagram for the process. 
b) Determine the probability that the process will never return to state A 
having started at A initially. Give justification. 
c) Find the limiting distribution for the process. 
9.21 
Customers arrive at a bank at a Poisson rate X. Suppose two customers 
arrive in the first hour. What's the probability that: 
a) Both arrived in the first 20 minutes? 
b) At least one arrived in the first 20 minutes? 
9.22 
An insurance company pays out claims on its life insurance policies in 
accordance with a Poisson process having rate λ = 5 per week. If the amount 
of money paid on each policy is exponentially distributed with mean $2000, 
what is the mean and variance of the amount paid by the insurance company 
in a four-week span? 
9.23 
Show that if N\(t) and Λ^ί) are independent Poisson processes with 
rate X\ and Ä2, respectively, then Nt = N\(t) + A^t) is a Poisson process 
with rate λι + Χ^. 

412 
INTRODUCTION TO STOCHASTIC PROCESSES 
9.24 
Let {Nt\t > 0} be a Poisson process with intensity parameter X. Sup-
pose each arrival is "registered" or recorded with probability p, independent of 
other arrivals. Let Mt be the counting process of registered or recorded events. 
Show that Mt is a Poisson process with parameter Xp. 
9.25 
Consider the IIT Delhi Open House program. Assume that students 
from various schools arrive at the reception at the instants of a Poisson process 
with rate 2 per minute. 
At the reception main door, two program represen-
tatives separately explain the program to students entering the hall. 
Each 
explanation takes a time (in minutes) which is assumed to be exponentially 
distributed with parameter 1 and is independent of other explanations. 
After 
the explanation, the students enter the hall. If both representatives are busy 
the student goes directly into the hall. Let Xt be the number of busy repre-
sentatives at time t. 
Without loss of generality, assume that the system is 
modeled as a birth-and-death process. 
a) Write the generator matrix Q. 
b) Write the forward Kolmogorov equations for the birth-and-death process 
{Xt;t>0}. 
c) Derive the stationary distribution of the process. 
9.26 
Consider the New Delhi International Airport. 
Suppose that it has 
three runways. Airplanes have been found to arrive at the rate of 20 per hour. 
It is estimated that each landing takes 3 minutes. Assume a Poisson process 
for arrivals and an exponential distribution for landing times. Without loss 
of generality, assume that the system is modeled as a birth-and-death process. 
a) What is the steady state probability that there is no waiting time to land? 
b) What is the expected number of airplanes waiting to land? 
c) Find the expected waiting time to land? 
9.27 
A cable car starts off with n riders. The times between successive stops 
of the car are independent exponential random variables, each with rate X. At 
each stop, one rider gets off. This takes no time and no additional riders get 
on. Let Xt denote the number of riders present in the car at time t. 
a) Write down the Kolmogorov forward equations for the process 
{Xf,t>0}. 
b) Find the mean and variance of the number of riders present in the car 
at any time t. 
9.28 
Let {Xt; t > 0} be a pure birth process with Xn = nX, n = 1,2, · ■ ·, 
λ0 = λ; μη = 0, n = 1,2, · · ·. 

EXERCISES 
413 
a) Find the conditional probability that Xt = n given that XQ = i 
(1 <i 
<n). 
b) Find the mean of this conditional distribution. 
9.29 
Suppose that an office receives two different types of inquiry: persons 
who walk in off the street and persons who call by telephone. Suppose the two 
types of arrival are described by independent Poisson processes with rate a\ 
and c*2 for walk-in and the callers, respectively. What is the distribution of 
the number of telephone calls received before the first walk-in customer. 
9.30 
An insurance company wishes to test the assumption that claims of 
a particular type arrive according to a Poisson process model. The times of 
arrival of the next 20 incoming claims of this type are to be recorded, giving a 
sequence Τχ,··· ,Τ20. 
a) Give reasons why tests for the goodness of fit should be based on the 
interarrival times Xi = Ti — Τί_ι rather than on the arrival times Ti. 
b) Write down the distribution of the interarrival times if the Poisson pro-
cess model is correct and state one statistical test which could be applied 
to determine whether this distribution is realized in practice. 
c) State the relationship between successive values of the interarrival times 
if the Poisson process model is correct and state one method which could 
be applied to determine whether this relationship holds in practice. 
9.31 
Let us consider that the buses arrive at a particular stop according to 
a Poisson process with rate 10 per hour. A student starts waiting at the stop 
at 1:00. 
a) What is the probability that no buses arrive in the next half-hour? 
b) How many buses are expected to arrive in 2 hours? 
c) What is the variance of the number of buses that arrive over a 5-hour 
period? 
d) What is the probability that no buses arrive in the next half-hour given 
that one hasn't arrived for over 2 hours? 
e) If you wait until 2 o 'clock and no buses have arrived, what is the prob-
ability that a student still has to wait at least a further half-hour before 
one comes? 
9.32 
According to an interest rate model which operates in continuous time, 
the interest rate rt may change only by upward jumps of fixed size j u or 
by downward jumps of fixed size jd (where jd < 0), occurring independently 
according to Poisson processes Nu(t) (with rate \u) and Nd{t) (with rate Xd). 

414 
INTRODUCTION TO STOCHASTIC PROCESSES 
μ 
Figure 9.13 
State transition diagram for Exercise 9.33 
Let Tu denote the time of the first up jump in the interest rate, Td the time 
of the first down jump, T — min(Tu,Td) 
the time of the first jump. 
Further, 
let I be defined as an indicator taking the value 1 if the first jump is an up 
jump or 0 otherwise. 
a) Determine expressions for the probabilities P{TU > t},P{Td 
> t} and 
P{T > t}. 
b) Determine the distribution of I. 
c) Show, by evaluating P{T > t and 1 = 1}, that I and T are independent 
random variables. 
d) Calculate the expectation and variance of the interest rate at time t given 
the current rate ro- Hint: rt = ro + juNu(t) 
+ jdNd(t) 
e) Show that {r<;i > 0} is a process with stationary and independent in-
crements. 
9.33 
Consider Example 9.32. Assume that both units have a failure rate X. 
The state transition diagram is shown in Figure 9.13. 
a) Write the forward Kolmogorov equations for this system. 
b) Determine the reliability of the system. 
9.34 
Consider an n-unit system in which 1 unit is active and the other n—\ 
units are inactive. There is one repairman and the repair rate of each unit is 
μ. The failure and repair rates are X and μ, respectively. This system can be 
modeled as a birth-and-death process {Xt;t > 0}. The state of the system is 
the number of working components. Determine the steady state probabilities 
of the states of the underlying system. 
9.35 
Consider a service station with two identical computers and two tech-
nicians. 
Assume that when both computers are in good condition, most of 
the work load is on one computer, exposed to a failure rate X = 1, while the 
other computer's failure rate is X = 0.5. Further assume that, if one of the 
computer fails, the other one takes the full load, thus exposed to a failure rate 
X — 2. Among the technicians, one is with repair rate μ = 2 while the second 
is with repair rate μ = 1. // both work simultaneously on the same computer, 

EXERCISES 
415 
the total repair rate is μ = 2.5. Note that, at any given moment, they work 
so that their repair rate is maximized. 
a) Determine the infinitesimal generator matrix Q. 
b) Draw the state transition diagram of the system. 
c) Determine the steady state probabilities and the system availability. 
9.36 
Consider a service station with two computers and a technician. Sup-
pose that computer A fails on the average once per hour and computer B twice 
per hour. The technician can repair a computer in 3 minutes on average. 
a) Determine the infinitesimal generator matrix Q. 
b) Draw the state transition diagram of the system. 
c) Determine the steady state probabilities and the system availability. 
9.37 
The occurrences of successive failures can be described by a Poisson 
process with mean time between arrivals of 50 minutes. 
a) What is the probability that exactly 3 failures occur in the first 1000 
minutes ? 
b) Find the probability of no failure in the first 500 minutes. 
c) What is the probability that the first failure occurs after 400 minutes? 
d) Compute the probability that the 4th failure occurs after 2000 minutes? 
9.38 
Consider an n-unit parallel redundant system. The system is operates 
when at least one of the n units is operating. Then the system fails when 
all units are down simultaneously. It will begin to operate again immediately 
by replacing all failed units with new ones. Assume that each unit operates 
independently. Also assume that each unit has an identical failure distribution 
which follows exponential distribution with parameter X. Obtain the renewal 
function. 
9.39 
Consider Example 9.34- Suppose that Markov chain {Xt',t > 0} with 
state space S is irreducible and positive recurrent. Determine the stationary 
distribution. 

CHAPTER 10 
INTRODUCTION TO QUEUEING 
MODELS 
10.1 
INTRODUCTION 
The queueing theory is considered to be a branch of applied probability the-
ory and is often used to describe the more specialized mathematical models 
for waiting lines or queues. The concept of queueing theory has been devel-
oped largely in the context of telephone traffic engineering originated by A. 
K. Erlang in 1909. Queueing models find applications in a wide variety of sit-
uations that may be encountered in health care, engineering, and operations 
research (Gross and Harris, 1998). In this chapter, the reader is introduced 
to the fundamental concepts of queueing theory and some of the basic queue-
ing models which are useful in day-to-day real life. Important performance 
measures such as queue length, waiting time and loss probability are studied 
for some queueing models. 
Queueing systems are comprised of customer(s) waiting for service and 
server(s) who serve the customer. They are frequently observed in some areas 
of day-to-day life, for example: 
1. People waiting at the check-in counter of an airport 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
417 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

418 
INTRODUCTION TO QUEUEING MODELS 
2. Aeroplanes arriving in an airport for landing 
3. Online train ticket reservation system 
4. People waiting to be served at a buffet 
5. Customers waiting at a barber shop for a hair cut 
6. Sequence of emails awaiting processing in a mail server 
▲ 
Certain factors which affect the performance of queueing systems are as 
follows: 
1. Arrival pattern 
2. Service pattern 
3. Number of servers 
4. Maximum system capacity 
5. Population size 
6. Queue discipline 
To incorporate these features, David G. Kendall introduced a queueing nota-
tion A/B/C/X/Y/Z 
in 1953 where: 
A 
is the interarrival time distribution 
B 
is the service time distribution 
C 
is the number of servers 
X 
is the system capacity 
Y 
is the population size 
Z 
is the queue discipline 
The symbols traditionally used for some common probability distributions for 
A and B are given as: 
D 
Deterministic (constant) 
Ek 
Erlang-k 
G 
General service time 
GI 
General independent interarrival time 
Hk fc-Stage hyperexponential 
M 
Exponential (Markovian) 
PH 
Phase type 
In this chapter, an infinite customer population and service in the order of 
arrival [first-in first-out (FIFO)] are default assumptions. Hence, for example 
M/M/l/oo, where M stands for Markovian or memoryless. The first M 
denotes arrivals following a Poisson process, the second M denotes service 

MARKOVIAN SINGLE-SERVER MODELS 
419 
arrivals 
departure 
3 2 1 
server 
queue 
Figure 10.1 
M/M/l/oo queueing system 
time following exponential distribution, 1 refers to a single server and oo refers 
to infinite system capacity. Also there is an additional default assumption: 
interarrival and service times are independent. In a GI/D/c/N 
queueing 
model, GI denotes a general independent interarrival time distribution, D 
denotes a deterministic (constant) service time distribution, c denotes the 
number of servers and N refers to the number of waiting spaces including one 
in service. 
The queueing systems in real life are quite complex as compared to the 
existing basic queueing models. As the real-life system complexity increases, 
it becomes more difficult to analyze the corresponding queueing system. A 
model should be made as simple as possible but at the same time it should 
be close to reality. In this chapter, we describe simple queueing models and 
analyze them by studying their desired characteristics. The real-world phe-
nomenon can be popularly mapped to one of these queueing models. 
10.2 
MARKOVIAN SINGLE-SERVER MODELS 
10.2.1 
Μ/Μ/1/οο 
Queueing System 
Definition 10.1 {M/M/l/oo 
Queueing System) The M/M/l/oo 
or sim-
ply M/M/l 
queueing system describes a queueing system with both interarrival 
and service times following exponential distribution with parameters X and μ, 
respectively, one server, unlimited queue size with FIFO queueing discipline 
and unlimited customer population. It is shown in Figure 10.1 with arrival 
rate X and service rate μ. 
Theorem 10.1 Let Xt be a random variable denoting the number of cus-
tomers in the M/M/l 
queueing system at any time t. Define: 
Pn(t) = P(Xt = n), n = 0,1,2, · · · , t > 0 . 
Let Χ/μ = p. When p < 1, the steady state probabilities are given by: 
Pn= 
\imP(Xt=n) 
= {l-p)pn, 
n = 0,l,2,··· . 
t—*oo 
Proof: 
The state transition diagram for the M/M/l 
queueing system is 
shown in Figure 10.2. The stochastic process {Xt',t > 0} in the 
M/M/l 

420 
INTRODUCTION TO QUEUEING MODELS 
λ 
λ 
λ 
0COCGC··· 
l·1 
μ 
μ 
Figure 10.2 
State transition diagram for M/M/l/oo 
queueing system 
queueing system can be modeled as a homogeneous continuous-time Markov 
chain (CTMC) (refer to Section 9.3). In particular, this system can be mod-
eled by a birth-and-death process (BDP) with birth rates λη = λ, η = 0,1, · · ·, 
and death rates μ„ = μ, η = 1,2, · ■ ■. When p < 1, the underlying CTMC 
is irreducible and positive recurrent and has stationary distribution. Note 
that the stationary distribution holds good only for the system in equilib-
rium, which is attained asymptotically. Moreover, when the process attains 
equilibrium, its behavior becomes independent of time and its initial state. 
Hence, the steady state balance equations can be obtained as discussed in 
Section 9.4 and is given by: 
0 
= 
-ΧΡο+μΡι 
0 
= 
ΧΡη-1-(Χ 
+ μ)Ρη + μΡη+1, 
η = 1 , 2 , · · · . 
Solving the above equations, we get 
Pi 
= 
-Po 
μ 
Ρη+Ϊ 
= 
-Pn,n 
= 
l,2,··· 
μ 
so that: 
/ λ \ η + 1 
Pn+1= 
f - J 
P0, n = l,2,··· . 
The value of Po can be computed by using the fact that the sum of all the 
probabilities must be equal to 1, i.e., Σ™=0 Pn = 1· Hence, when p < 1: 
The steady state probabilities are given by: 
Pn = (l-p)pn, 
n = 0,1,2,··· . 
(10.1) 
Note 10.1 Equation (10.1) represents the probability mass function of a dis-
crete random variable denoting the number of customers in the system in the 

MARKOVIAN SINGLE-SERVER MODELS 
421 
long run. Clearly this distribution follows a geometric distribution with pa-
rameter I—p. Moreover, as t —> oo, the system state depends neither on t nor 
on the initial state. The sequence {Pn, n = 0,1, · · · } is called the steady state 
or stationary distribution. Here, p < 1 is a necessary and sufficient condition 
for the steady state solution to exist; otherwise the size of the queue will in-
crease without limit as time advances and therefore steady state solution will 
not exist. 
Note 10.2 In case the arrivals follow a Poisson process, a customer arriving 
to the queue in the steady state sees exactly the same statistics of the number 
of customers in the system as for "real random times". In a more condensed 
form, this is expressed as Poisson ArrivaL· See Time Averages, abbreviated 
PASTA (Wolff, (1982)). Since M/M/l 
queueing system satisfies the PASTA 
property, an arriving customer finds n customers in the system with probability 
Pn-
Theorem 10.2 Let Ls be the average number of customers in the M/M/l 
queueing system and Lq be the average number of customers in the queue. 
Then: 
μ — A 
1 — p 
1 — p 
Proof: Using (10.1), the mean number of customers can be found. Note that 
the number of customers in the system is the sum of the number of customers 
in the queue and the number of customers in service. Hence: 
oo 
oo 
LB = Σ nPn = Σ n(l - p)pn . 
(10.2) 
n=0 
n=l 
After simple calculations, we get: 
L - 
X 
- 
p 
μ — A 
1 — p 
As expected, these equations show that with increasing load, i.e., as p —► 1, 
the mean number of customers in the system grows and the probability of 
an idle system decreases. Similarly, the average number of customers in the 
queue can be computed as: 
oo 
Lq = 5 > - l ) P n 
n=l 
= 
La-(1-P0) 
P2 
l-p-
■ 

422 
INTRODUCTION TO QUEUEING MODELS 
Note 10.3 The probability that the server is busy is another performance 
measure of the queueing system. The probability that the server is busy when 
the system is in equilibrium is known as the utilization factor p. Clearly, this 
utilization factor for the M/M/l 
queue is equal to 1 — PQ = p, which is also 
the traffic intensity. 
Note 10.4 The number of customers in the system is of importance from the 
management's perspective and interest. Besides, the average queue size and 
average system size are also important parameters that represent the quality 
of service. Two more measures important from the customer's point of view 
are the average time spent in the system (Ts) and the average time spent in 
the queue (Tq). One of the most significant contributions in queueing theory 
is Little's formula, which gives the relation between the average number of 
customers in the system (Ls) and the average time spent in the system (Ts) 
and also between the average number of customers in the queue (Lq) and Tq: 
L3 = \TS; 
Lq = XTq . 
(10.3) 
It is justified that, using the average time spent in the system, Tg, the average 
number of the customers during this time is XTS, where λ is the average num-
ber of arrivals per unit time. It is very important to note that no assumption 
is made on the interarrival distribution, the service time distribution and the 
queue discipline. The first formal proof for Little's result appeared in Little 
(1961). Usually the average waiting time of a customer is difficult to calculate 
directly. Relation (10.3) comes to our rescue, because the evaluation of mean 
number of customers in the system is relatively easy. As an example, it is 
derived for the M/M/l 
queueing system from (10.2): 
T= 
P 
= - J _ 
8 
λ(1-ρ) 
μ-λ 
It can be deduced that: 
Ts = Tq + - . 
μ 
Note 10.5 The variance of the four measures are given by (left as an exercise 
for the reader): 
Var(Number of customers in the system) 
Var(Number of customers in the queue) 
Var( Waiting time of customers in the system) 
Var( Waiting time of customers in the queue) 
(10.4) 
P 
(1-P) 2 
p{l + p- 
p2) 
( i - p ) 2 
1 
(W)V 
P(2-P) 
( I - P ) V ' 

MARKOVIAN SINGLE-SERVER MODELS 
423 
Theorem 10.3 Let W be the random variable which denotes the waiting time 
of a customer in the M/M/1 
queueing system. 
Then, the distribution of 
waiting time is: 
{
0 
if t < 0 
1-/9 
if t = 0 
(10.5) 
1 - pe-if-V* 
if t > 0 . 
Proof: 
An arriving customer has to wait only when there is one or more 
customer in the system. Hence the waiting time of the customer will be 0 if 
the system is empty. Thus, the probability of the event W = 0 is equivalent 
to the probability of the system being empty, i.e.: 
P(W = 0) = P(system is empty) = 1 — p . 
When the system is not empty, i.e., there is one or more customers in the sys-
tem, say n, then the arriving customer has to wait until all the n customers get 
serviced. Note that as the service time follows exponential distribution with 
parameter μ, which has the memory less property, the residual (remaining) 
service time of the customer in service also follows exponential distribution 
with parameter μ. Hence, the waiting time of a customer who arrives when 
n customers are already in the system follows a gamma distribution with 
parameters n and μ. Thus: 
oo 
P(0 < W < t) = Σ P(0 < W < t I N = n)P{N = n) . 
(10.6) 
n=l 
We know that: 
P(N = n) 
= 
(l-p)pn 
(10.7) 
P(0<W<t\N 
= n) 
= 
/ !=-. 
77—dx, t > 0. 
(10.8) 
Jo 
{n ~ I)' 
Substituting (10.7) and (10.8) in (10.6), we get: 
= 
p ( l - β-("-λ>') . 
Hence: 
P(W <t) = P(W = Q)+P(Q<W<t) 
= l - pe~^-x)t 
. 
Similarly, we obtain the distribution of the total time spent by a customer 
in the system. 

424 
INTRODUCTION TO QUEUEING MODELS 
Theorem 10.4 Let T denote the random variable for the total time spent by 
a customer in the M/M/l 
queueing system. 
Then the distribution of total 
time spent is given by: 
P(0<T<t) 
= 
1 - e - ^ 1 - ' ) ' . 
Proof: As we evaluate the waiting time distribution, we have: 
oo 
P(0 < T < t) = Σ 
P(T ^t\N 
= n)P(N = n) 
= 
1 - e~^l~p)t 
. 
Note 10.6 This shows that T has an exponential distribution with parameter 
μ — λ. Hence, the average total time spent by a customer in the system is 
given by: 
Ts = E(T) = —!— . 
fi — A 
The above result is the same as that obtained in equation (10.4) using Little's 
formula. It can also be verified that Ts = Tq + -. 
■ EXAMPLE 10.1 
Consider a unisex hair salon where customers are served on a first-come, 
first-served basis. The data show that customers arrive according to 
a Poisson process with a mean arrival rate of 5 customers per hour. 
Because of its excellent reputation, customers are always willing to wait. 
The data further show that the customer processing time is exponentially 
distributed with an average of 10 minutes per customer. This system 
can be modeled as a M/M/l 
queueing system. Then, in the long run: 
(a) What is the average number of customers in the shop? 
(b) What is the average number of customers waiting for a haircut? 
(c) What is the probability that an arrival can walk right in without having 
to wait at all? 
Solution: Let Xt be the random variable denoting the number of cus-
tomers in the salon at any time t. Then the system can be modeled as a 
M/M/l 
queueing system with {Xt;t > 0} as the underlying stochastic 
process. Here λ = 5 per hour and μ = 6 per hour. Hence, p = | . 

MARKOVIAN SINGLE-SERVER MODELS 
425 
(a) The average number of customers in the shop: 
Ls = - ^ = 5 . 
1 - / 9 
(b) The average number of customers waiting for a haircut: 
L -L 
- λ _ 2 6 
(c) The probability that an arrival can walk right in without having to wait 
at all: 
P0 = 1 - p = 0.1667 . 
A 
■ EXAMPLE 10.2 
Consider the New Delhi International Airport. Assume that it has one 
runway which is used for arrivals only. Airplanes have been found to 
arrive at a rate of 10 per hour. The time (in minutes) taken for an 
airplane to land is assumed to follow exponential distribution with mean 
3 minutes. Assume that arrivals follow a Poisson process. Without loss 
of generality, assume that the system is modeled as a M / M / l queueing 
system. 
(a) What is the steady state probability that there is no waiting time to 
land? 
(b) What is the expected number of airplanes waiting to land? 
(c) Find the expected waiting time to land. 
Solution: We model the given problem as a M/M/l 
queueing system 
where each state represents the number of airplanes landing. The arrival 
rate is 10 per hour and the service rate is 20 per hour. 
(a) The required probabihty that an airplane does not have to wait to land 
is: 
P(runway is available) = Po = 1 — p = 0.5 . 
(b) From equation (10.3), the expected number of airplanes waiting to land 
is: 
Lq = 0.5 . 
(c) Using Little's formula, the expected waiting time to land is: 
Tq = 0.05 hours . 
A 

426 
INTRODUCTION TO QUEUEING MODELS 
■ EXAMPLE 10.3 
Consider the online ticket reservation system of Indian Railways. As-
sume that customers arrive according to a Poisson process at an average 
rate of 100 per hour. Also assume that the time taken for each reser-
vation by a computer server follows an exponential distribution. Find 
out at what average rate the computer server should issue an e-ticket 
in order to ensure that a customer will not wait more than 45 seconds 
with a probability of 0.95. 
Solution: P(W < 45) = 0.95. Using equation (10.5), 1 - pe" 4 5^-*) = 
0.95 where λ = 6o°g0 = ^ per second. From the stability condition, 
μ > j^j = 0.02778. Simple calculations yield: 
λ6-45("-λ) 
= 
0.05 
μ 
45μ + ^ μ 
= 
0.9947. 
Solving, we get: 
μ = 0.0508 . 
Hence, the server issues the e-ticket at an average 19.685 seconds in 
order to ensure that a customer does not wait more than 45 seconds.. 
▲ 
■ EXAMPLE 10.4 
In a mobile handset manufacturing factory, components arrive accord- * 
ing to a Poisson process with rate λ. Assume that the testing time of 
the components is exponential with mean l/μ and there is one testing 
machine for the testing purpose. During the testing period, with prob-
ability p the product is considered to be faulty and sent back to the 
production unit queue. 
(a) Determine the number of handsets in the queue of the production unit 
on average in the steady state. 
(b) Find the average response time of a production unit in the steady state. 
Solution: This system can be modeled as a M/M/l 
queueing model 
with retrials. The state transition diagram for the underlying queueing 
model is shown in Figure 10.3. 
The balance equations for this queueing model are: 
AP0 
= 
(1-ρ)μΡι 
(\ + {1-ρ)μ)ΡΗ 
= 
XPk-i + {I -P)ßPk+1, fc = 1,2, ·- . 

MARKOVIAN SINGLE-SERVER MODELS 
427 
0 
'^XU^^Z 
(1-ρ)μ 
<1-ρ)μ 
(Ι-ρ)Ιί 
Figure 10.3 
State transition diagram 
λ 
λ 
λ 
λ 
χ 
μ 
μ 
μ 
μ 
μ 
Figure 10.4 
Μ/Μ/ί/Ν 
queueing system 
(a) The average number of customers in the queue is given by: 
where p = j
^
. 
(b) The average response time is given by: 
1 
Ta = ( 1 - ρ ) μ - λ 
10.2.2 
M/M/l/N 
Queueing System 
We consider the single-server Markovian queueing system in which only a 
finite number of customers are allowed. 
Definition 10.2 (M/M/l/N 
Queueing System) This system is a type of 
M/M/l/oo 
queue with at most N customers allowed in the system. 
When 
there are N customers in the system, i.e., one customer is under service 
and the remaining N — 1 customers are waiting in the queue, new arriving 
customers are blocked. The state transition diagram for this system is shown 
in Figure 10.4-
Theorem 10.5 The state probabilities in equilibrium for the M/M/l/N 
queue-
ing system are given by: 
{1-P)pn 
., 
. . 
Pn = { 
n = 0,l,---,N. 
(10.9) 
ϊνΤΤ 
* > = 1· 

428 
INTRODUCTION TO QUEUEING MODELS 
Proof: Let Xt be a random variable denoting the number of customers in 
the system at any time t. For the M/M/l/N 
queueing system, {Xt\t > 0} 
is a BDP with birth rates λη = λ, η = 0,1,··· ,7V — 1, and death rates 
μη = μ, η = 1,2, · · · , TV. Since the BDP {Xt; t > 0} with finite state space 
S = {0,1, · ■ · , N} is irreducible and positive recurrent, the equilibrium prob-
abilities, denoted by (Pi)ies, exist (refer to Example 9.34). Hence (Pi)ies are 
given by: 
λ 0 λ ι ■•■Aj_i 
Pi = 
P 0, 
» = 1,2,··· ,7V, 
μιμ2···μί 
with: 
ft 
N 
A Q A I - A J - I 
Substituting λη = λ, n = 0,1, · · · , TV — 1, and μη = μ, η = 1,2, · · · , N, in 
the above equations, we obtain the state probabilities in equilibrium. 
■ 
Note 10.7 The state probability Pjv is called the blocking probability since 
the customers are blocked when the system is in state N. In this finite-state 
queueing model, the effective arrival rate is given as Xejf = λ(1 — P/v)· 
Note 10.8 Using the state probabilities, one can compute the average number 
of customers in the system, which is given by: 
N 
L» = Σ
n P n = 
n=0 
I 
N 
_p 
(TV + 
l)pN+1 
l - p 
1 - 
pN+1 
2 
if 
ρφ\ 
if 
p=l. 
Using Little's formula, the average time spent by a customer in the system 
can be calculated as 
T — ^s 
Kff 
where λ ε// is the effective arrival rate to the system. 
The waiting time distribution for this M/M/l/N 
queueing system is left 
as an exercise for the reader. 
■ 
E X A M P L E 10.5 
Consider a message switching center in Vodafone. Assume that traf-
fic arrives as a Poisson process with average rate of 180 messages per 
minute. The line has a transmission rate of 600 characters per second. 
Suppose that the message length discipline follows an exponential distri-
bution with an average length of 176 characters. The arriving messages 
are buffered for transmission where buffer capacity is, say, N. What is 
the minimum N to guarantee that P/v < 0.005. 

MARKOVIAN SINGLE-SERVER MODELS 
429 
Solution: This system can be modeled as a M/M/l/N 
queueing sys-
tem, where each state represents the number of messages in the switching 
center. In this example, λ = 3 x 176 = 528 characters per second and 
μ = 600 characters per second. Hence, p = £ = 0.88. Prom equation 
(10.9), the probability that all the buffers are filled is: 
PN 
1 - 
pW 
The above equation can be solved for PN 
obtain N = 26. 
▲ 
= 0.005 with p = 0.88 to 
EXAMPLE 10.6 
Consider a M/M/l/2 
queueing system. Let Pn(t) be the probability 
that there are n customers in the system at time t given that there was 
no customers at time 0. Find the time-dependent probabilities Pn{t) for 
n = 0,1,2 . 
Solution: The Kolmogorov forward equations for the M/M/l/2 queue-
ing system are: 
Po(t) 
= 
-Apo(*)+Wi(*) 
p'i(t) 
= 
λ ρ 0 ( ί ) - ( λ + μ)ρι(<)+ΜΡ2(ί) 
p'2{t) 
= 
XPl(t) - pp2(t) . 
Taking the Laplace transform on both sides with the initial condition 
that the system begins in state 0, we obtain: 
spZ(s) - 1 = 
-ApJ(e) + μρϊ(β) 
pl(s) 
= 
λρ5(β)-(λ + Αΐ)ί>ϊ(β) + μι>5(β) 
pl{a) 
= 
Xpl{s) - ßpz(s) . 
In matrix form 
A(s) 
' P*o(s) ' 
Pl(s) 
P*2(S) 
= 
' 1 " 
0 
0 
where: 
A(s) 
s + \ 
-X 
0 
-μ 
s + X + μ 
-X 
0 
-ß 
s + μ 
For λ φ μ, the roots of det(A(s)) = 0 are: 
s0 = 0; Si — X + μ- 
τ/Χμ; 
s2 = X + μ+ γ λ μ 

430 
INTRODUCTION TO QUEUEING MODELS 
Solving the above equations for P^(s),n 
— 0,1,2, by using matrix in-
version, we get: 
λ2 
Po(s) 
= 
Pl(s) 
= 
ri(*) = 
s{s2 + 2δμ + 2Xs + μ2 + \μ + X2) 
A(s + μ) 
s(s2 + 2 * βμ + 2Xs + μ2 + Χμ + λ2) 
s2 + 2βμ + sX + μ2 
s{s2 + 2βμ + 2Xs + μ2 + Χμ + λ2) ' 
Applying partial fraction techniques and then taking the inverse Laplace 
transform, for λ φ μ, we get: 
Po(t) 
λ2+λμ+μ2 
+ 
+ 
2Χμ - 2(λ + μ)^/Xμ 
X2 
-(λ+μ-\Λμ> 
-(λ+μ+ν^μ)* 
2λμ + 2(λ + μ) ν
/λμ 
Χμ 
PlW 
= λ*+>£+μ* 
+ 
Α(-Α +-ν/Λμ") 
(Λ+μ-ν%ΐ)ί 
Ρ2(ί) 
2λμ - 2(λ + 
μ)νΧμ 
X-y/) 
2(Χ + μ 
μ2 
A-y/Αμ 
λ 2 + ^ + " 2 
2λμ - 2(λ + μ) ν
/λμ £ 
Λ(-Λ - y/Ä/I) 
c_ ( A + M + s A i I ) t 
2 λ μ - 2 ( λ + μ) ν
/λμ 
+ 
Χ\/Χμ 
2λμ-2(λ + μ)λ/λμ 
-(λ+μ-ν/Χμ)ί 
-(λ+μ+νΛμ> 
EXAMPLE 10.7 
A person repairing motor cars finds that the time spent on repairing 
a motor car follows an exponential distribution with mean 40 minutes. 
The shop can accommodate a maximum of 7 motor cars including the 
one under repair. The motor cars are repaired in the order in which 
they arrive, and the arrivals can be approximated by a Poisson process 
with an average rate of 15 per 10-hour day. What is the probability of 
the repair person being idle in the long run? Also, find the proportion 
of time the shop is not full in the long run. 
Solution: This repair system can be modeled as a M/M/l/N 
queueing 
model where each state of the system represents the number of motor 
cars being repaired. Here N 
equation (10.9), we get: 
Po 
7, X 
1 
N + l 
40 
1 
= 8" 
and μ 
40-
Hence, from 

MARKOVIAN MULTISERVER MODELS 
4 3 1 
λ 
• · · 
μ 
2μ 
3μ 
εμ 
ομ 
c\i 
ΘΟΘΟΘΖ: · · - 3 3 3 S O 
Figure 10.5 
M/M/c/oo queueing system 
Further, the expected idle time of the repair person is PQ. The propor-
tion of time that the shop is not full is: 
Thus, the shop is not full 87.5% of the time in the long run. 
A 
10.3 
MARKOVIAN MULTISERVER MODELS 
10.3.1 
M/M/c/oo 
Queueing System 
We consider a multiserver queueing system M/M/c/oo. 
The state transition 
diagram for this system is shown in Figure 10.5. The corresponding steady 
state equations are given by: 
0 = 
ΧΡο-μΡι 
0 = λΡ„_ι-(λ + ημ)Ρη + (η+1)μΡ η +ι,η=1,2,··· , c - l 
0 
= 
XPn-i - {X + cμ)Pn + cμPn+ι,n 
= c,c+ί,■■■ 
. 
The steady state probabilities will exist for p < 1, where p = —. Solving the 
above equations, we get the steady state probabilities 
Using the fact that Y^L0 P„ = 1, we get: 
Po = <H>! \ß) 
2-" cn-°c\\u) 
,n=0 
x 
' 
n = c 
\r 
/ 
(10.11) 
Note 10.9 The probability that an arriving customer has to wait is given by 
n = c 
n=c 
\r-/ 
where P 0 is given by (10.11). This is known as the Erlang-C formula. 

432 
INTRODUCTION TO QUEUEING MODELS 
Note 10.10 The average number of customers in the queue is given by: 
Lq = S ( n _ c ) P n = 
5
^
y 
ft. 
(10.12) 
n=c+l 
v 
r/ 
\ ^ ' 
Using Little's formula we evaluate Tq, Ts and Ls: 
La = Lg + ^ = — ^ ( * Y p 0 + * . 
(10.15) 
■ EXAMPLE 10.8 
Consider Example 10.2. Further assume that it has three runways. In 
this scenario, assume that the arrival rate is 20 per hour and the service 
rate is 20 per hour. Without loss of generality, assume that the system 
is modeled as a M/M/Z 
queueing system. 
(a) What is the steady state probability that there is no waiting time to 
land? 
(b) What is the expected number of airplanes waiting to land? 
(c) Find the expected waiting time to land. 
Solution: We model the problem as a M/M/Z 
queueing system where 
each state represents the number of airplanes landing. The arrival rate 
is 20 per hour and the service rate is 20 per hour. 
(a) The required probability that an airplane does not have to wait to land 
is 
P(at least one runway is available) 
= 
P(Less than 3 airplanes are landing) 
= 
P 0 + P i + P 2 
where P, is the steady state probability of the system being in state i. 
Substituting the values of Pj using equations (10.10) and (10.11), the 
desired probability is 0.909 . 
(b) From equation (10.12), the expected number of airplanes waiting to land 
is: 
00 
Lq = ^2(n- 3)P„ = 0.04535 . 
n=4 

MARKOVIAN MULTISERVER MODELS 
4 3 3 
(c) From equation (10.13), the expected waiting time to land is: 
Tq = 0.0022725 . 
▲ 
■ EXAMPLE 10.9 
Consider Walmart supermarket with 7 counters. Assume that 9 cus-
tomers arrive on an average every 5 minutes while each cashier in the 
counter can serve on an average three customers in 5 minutes. Assume 
that arrivals follow a Poisson process and service times follow exponen-
tial distribution. Find: 
(a) Average number of customers in the queue 
(b) Average time a customer spends in the system 
(c) Average number of customers in the system 
(d) Optimal number of counters so that the proportion of time a customer 
has to wait is at most 10 seconds 
Solution: This system is modeled as a M/M/7/oo queueing system. 
Here, λ = | and μ = | . The state probabilities are given by: 
ρ_ίΜ-μ)ηΡο 
1 < η < 7 
l τ*Μί)"*> n>7. 
Using the fact Σ™=ο pn = !> w e Set po = 0.0496. 
(a) Average number of customers in the queue: 
oo 
Lq = Y^(n- l)Pn = 0.02825 . 
n=8 
(b) Average time a customer spends in the system: Ta = 0.015694 . 
(c) Average number of the customers in the system: L8 — 3.02825 . 
(d) Using the fact that -£- < 1, we get c > 3. Further, since it is required 
that Tq < 10 seconds = 0.1667 minutes, by trial and error, we get that, 
for c = 4, Tq = 0.2121 and, for c = 5, Tq = 0.0786. Hence the optimal 
number of servers that must be installed in order that Tq < 10 seconds 
is c = 5. 
A 

434 
INTRODUCTION TO QUEUEING MODELS 
■ EXAMPLE 10.10 
Suppose that Air India airlines is planning a new customer service center 
at London. Assume that each agent can serve a caller with an exponen-
tially distributed service time with an average of 4 minutes. Also assume 
that calls arrive randomly as a Poisson process at an average rate of 30 
calls per hour. Also assume that the system has a large message buffer 
system to hold calls that arrive when no agents are free. How many 
agents should be provided so that the average waiting time for those 
who must wait does not exceed 2 minutes? 
Solution: This system can be modeled as a M/M/c/oo 
queueing system 
where λ = \ and μ = \. We require that for such a system to be stable, 
^ < 1 => c > 2. By trial and error, we obtain, for c = 3, Tq — 0.5925. 
Hence the number of agents who must be provided so that the average 
waiting time Tq < 2 is c = 3. 
▲ 
■ EXAMPLE 10.11 
A situation in which a customer refuses to enter a queueing system 
because the queue is too long is said to be balking. On the other hand, 
a customer who enters the system but leaves the queue after some time 
without receiving service because of excessive waiting time is said to be 
reneging. Assume that any customer who leaves the system and then 
decides to return after some time is a new arrival. Consider the 
M/M/c 
queueing system with the following: 
1. (Balking) An arriving customer who finds that all the servers are busy 
may join the system with probability p or balk (does not join) with 
probability 1 — p. 
2. (Reneging) A customer already in the queue may renege, i.e., leave the 
system without obtaining service. It is assumed that the time spent by 
such a customer in the system follows an exponential distribution with 
parameter β. 
Find the steady state probability of the M/M/c 
system with: 
(a) Only balking is possible. 
(b) Only reneging is possible. 
(c) Both balking and reneging are possible. 
Solution: 
(a) Consider the M/M/c 
with balking. Note that the arriving customer will 
enter the system if any server is not busy. This model can be viewed 

MARKOVIAN MULTISERVER MODELS 
435 
μ 
2μ 
3μ 
c\l 
cH 
Figure 10.6 M/M/c queueing system with balking 
l·1 
2^ 
3μ 
φ 
τμ+β 
Figure 10.7 
M/M/c queueing system with reneging 
as a birth-and-death process with the arrival rate for the system being 
λη = λ, η = 0,1, · · · , c — 1, λη = ρλ, η = c, c + 1, · · ·. The service rate 
is μη = ημ, η = 1,2,··· , c, μη = ομ, η — c + 1, c + 2, · · ·. The state 
transition diagram for this model is shown in Figure 10.6. 
The steady state probability is given as: 
Pn 
Kn<c 
M?rC (£)"*) n>c 
(b) Consider the M/M/c 
system with reneging. In this case, the customer 
will not leave the system when the customer is under service. Hence, 
the arrival rate is λη = λ, η = 0,1, · · ·. But the service rate is μη = 
ημ, η = 1,2, · · · , c, μη = (n — c)ß + c/x, n — c + 1, c + 2, · · ·. The state 
transition diagram for this model is shown in Figure 10.7. Accordingly, 
the steady state probability is given as: 
Pn=< 
n! {μ) 
Kn<c 
. c^c"-"^+(n-c)ß)n-<:^'0 
n
>
c -
(c) Consider the M/M/c 
with both balking and reneging. In this case, the 
arrival rate is λη = λ, η = 0,1, · ■ · , c — 1, λη = ρλ, η = c, c + 1, · · · . 
The service rate is μη = ημ, η = 1,2, · ■ · , c, μη = (n — c)ß + cμ,n = 
c + 1, c + 2, · · · . Hence, the steady state probability is given as 
f n = < ii(i)"* 
Kn<c 
c\ßccn~c 
(ομ+(η-ο)β)η 
-Ρθ 
Π> C 
oo 
where Po is obtained from the fact that y j Pn = 1. 
▲ 
n=0 

436 
INTRODUCTION TO QUEUEING MODELS 
λ 
λ 
λ 
λ 
0CXDCXD3 · · · CO 
μ 
2μ 
3μ 
εμ 
Figure 10.8 
M/M/c/c loss system 
10.3.2 
M/M/c/c 
Loss System 
This loss system is also known as the Erlang loss system. The state transition 
diagram for this loss system is shown in Figure 10.8. Solving the balance 
equations for steady state probabilities, we get 
_ 
Pn/n\ 
n = 0 1 . . . 
c 
where p = —. 
The above state probabilities indicate that the system state follows a trun-
cated Poisson distribution with parameter p. The average number of cus-
tomers in the system is given by: 
c 
n=0 
Definition 10.3 (Erlang-B Formula) The blocking probability Pc is also 
called the Erlang-B formula and is given by: 
B{c,p) = Pc= 
?,C\ 
. 
(10.16) 
Σ ί = ο Ρ / ί ! 
Note 10.11 It is a fundamental result used for telephone traffic engineering 
problems and can be used to select the appropriate number of trunks (servers) 
needed to ensure a small proportion of lost calls (customers). Observe that the 
steady state distribution depends on the service time distribution only through 
its mean (since p = Χ/μ). 
Hence, the Erlang-B formula also holds good for 
the M/G/c/c 
loss system where service time follows a general distribution. 
The important property of B(c,p) 
is illustrated in Figures 10.9 and 10.10. 
From Figure 10.9, for a fixed p, blocking probability, B(c,p) 
monotonically 
decreases to zero as the number of servers increases. 
From Figure 10.10, 
for a fixed number of servers c, the blocking probability B(c, p) monotonically 
increases to unity as p increases. 

MARKOVIAN MULTISERVER MODELS 
437 
Figure 10.9 
Erlang-B formula versus number of servers 
Traffic fniMMity 
Figure 10.10 
Blocking probability versus p 

438 
INTRODUCTION TO QUEUEING MODELS 
EXAMPLE 10.12 
A rural telephone switch has C circuits available to carry C calls. A new 
call is blocked if all circuits are busy. Suppose calls have duration (in 
minutes) which has exponential distribution with mean 1 and interarrival 
time (in minutes) of calls is also exponential with mean 1. Assume 
that calls arrive independently. Given that A = 1 and μ = 1, so that 
p = £ = 1. Using Erlang-B formula given in (10.16), the probability 
that the system is blocked in the steady state is: 
Pc 
_1_ 
C! 
t=0 
EXAMPLE 10.13 
Suppose that Spencer supermarket in Chennai has decided to construct 
a parking system in the supermarket. An incoming four wheeler is not 
allowed inside the parking system when all the lots are in use. On 
average 100 four wheelers arrive to the system per hour following a 
Poisson process and the average time that the four wheeler spends in 
the parking lot is 4 minutes. Enough parking lots are to be provided 
to ensure that the probability of the system being full does not exceed 
0.005. How many lots should be constructed? 
Solution: This system can be modeled as a M/G/c/c 
system with: 
100 
p = —— x 4 = 6.67 erlangs. 
60 
Using the Erlang-B formula in equation (10.16), we obtain the blocking 
probability 
D 
f 0.0104 
when c = 13 
-tt 005 
when c = 14 . 
The smallest c such that PB < 0.005 is 14. Hence, we conclude that 14 
lots are required. 
A 
10.3.3 
M/M/c/K 
Finite-Capacity Queueing System 
In this queueing model, the system has a finite capacity of size K and we 
assume that c < K. The departure rates are state dependent and axe given 
by: 
ημ, 
n — 1,2,· ■ · ,c— 1 
ομ, 
n> c . 
Mn = | 

MARKOVIAN MULTISERVER MODELS 
439 
QCGCQC · · - 0 3 0 3 0 · -03 
μ 
2μ 
3μ 
ομ 
ομ 
ομ 
cμ 
Figure 10.11 
M/M/c/K 
queueing system 
The state transition diagram for this system is shown in Figure 10.11. 
As evaluated before, the steady state probability of the system is given by: 
cn~°cl 
\ μ 
(£)nP0 c<n<K 
. 
Using the fact Ση=ο i n = 1, we get 
Po_ ί (Σ=1 ά (ί)" + 4(ί)"ι=ί?1)- 
« „ i 
\ (ΣΓ.Όά(έ)" + έ(έ)°^-« + ») 
if o = i 
where p = —. 
Further, the average number of customers in the queue is given by: 
K 
L* = Σ ("-
C)
P" 
n=c+l 
= T^T^F[1" pK~c+1 ~(1"p)(*"c+^-'1 
· 
Using Little's formula, we can evaluate 
Γ 
— T 
-L 
e / / 
T 
— 
B 
rp _rp 
1 
μ 
Xeff 
μ 
where Ae// = λ(1 - PK)-
10.3.4 
M/M/oo 
Queueing System 
This is a Markovian queueing model without any queue. There are infinitely 
many servers such that every incoming customer finds an idle server imme-
diately. The state transition diagram for this loss system is shown in Figure 
10.12. 
One can easily obtain the stationary distribution Pn as given by: 
P„ = £ - j - , n = 0,l,··· . 
n! 
This follows a Poisson distribution with parameter p. Hence, the mean and 
variance of the number of customers in the steady state are the same as p. 

440 
INTRODUCTION TO QUEUEING MODELS 
Figure 10.12 
M/M/oo system 
Since there is no queueing in the M/M/oo 
system, all waiting times are zero 
and the mean sojourn time in the system equals l/μ. This means that all cus-
tomers passing through such a system independently spend an exponentially 
distributed time. 
One can observe that the expression of PQ for the M/M/oo 
queue is the 
limit of the respective expression for the M/M/c/c 
model as c tends to infinity. 
Further, the stationary distribution for the M/M/c/c 
queue converges to the 
stationary distribution of M/M/oo 
for increasing c. 
■ EXAMPLE 10.14 
Consider a buffet served in a large area. The diners serve themselves. 
It is observed that a diner arrives every 10 seconds following a Poisson 
process and it takes about | of a minute on average for the diner to 
serve himself. Find the average number of customers serving themselves 
and the average time spent. 
Solution: According to the question, A = 6 per minute and μ = 8 per 
minute. Hence p = | = 0.75. The steady state probability of the system 
is: 
(0.75)"e-°·75 
Pn = 
j 
,n = 0,l,··· . 
n! 
Hence the average number of customers serving themselves is: 
Ls= p = 0.75 . 
The average time spent in the system is: 
T. = 0.1250 minutes . 
▲ 
10.4 
NON-MARKOVIAN MODELS 
In the previous sections, various characteristics for Markovian models were 
studied. In Markovian models, the analysis is conducted using the memoryless 
property of exponential distribution. In this section, we study non-Markovian 
models which exhibit a memoryless property only at certain time epochs. 
These random time epochs at which the system probabilistically restarts itself 

N0N-MARK0VIAN MODELS 
4 4 1 
are known as regeneration time points. At regeneration time points, the 
memory of the elapsed time is erased. The times between the regeneration 
time points constitute an embedded renewal sequence. We deal with specific 
non-Markovian models such as M/G/l, 
GI/M/1, 
M/G/l/N 
and 
GI/M/l/N, 
where G represents a general or arbitrary distribution. 
10.4.1 
M/G/l 
Queueing System 
Definition 10.4 ( M / G / l Queueing System) This system is a type of 
M/M/l/oo 
queue where service times follow a general distribution. 
Assume 
that the interarrival time follows an exponential distribution with mean j and 
the distribution of service time is F(t) with pdf f(t) and mean ^. 
Theorem 10.6 Consider Xt as the number of customers in the system at 
time t in the M/G/l 
queueing system. Let p = £. Prove that, for p < 1, the 
generating function V(z) for the steady state probabilities are given by: 
_ 
(1-ρ)(ζ-1)Γ(λ{1-ζ)) 
V{z)- 
z-f*Mi-Z)) 
This is known as the Pollaczek-Khinchin 
(P-K) formula. 
Proof: Observe that the state of the system after an arrival of a customer 
depends not only on the number of the customers Xt at that time but also 
on the remaining service time of the customer receiving service, if any. Also 
note that the state of the system after a service completion depends only on 
the state of the system at that time. 
Let Xn be the number of customers in the system at the departure instant 
of the nth customer. Let tn denote the departure instant of the nth customer. 
Suppose Yt = Xn, 
tn < t < i n +i. Then, by Definition 9.49, {Yt;t > 0} 
will be a semi-Markov process having embedded discrete-time Markov chain 
(DTMC){X n,n = 0 , l , · · · } . 
To obtain steady state probabilities of Yt, we need to compute the transition 
probabilities of the embedded DTMC {X„;n = 0,1, · · · }. Since these points 
tn are the regeneration points of the process {Xt',t > 0}, the sequence of 
points {tn; n = 0,1, · · · } forms a renewal process. 
Let An be a random variable denoting the number of customers who arrive 
during the service time of the nth customer. We have: 
1+1 — Ϊ 
■v- 
_ i ·<4η+1) 
Xn — 0 
Xn — 1 + An+i, 
Xn > 1 
Since service times of all the customers, denoted by S, have the same distri-
bution, the distribution of An is the same for all n. Denote, for all n, 
aT 
= 
P(An = r) 
= 
Γ 
6"At(Af)rdF(t), r = 0,l,··· ■ 
(10.17) 
Jo 
r-

442 
INTRODUCTION TO QUEUEING MODELS 
Therefore: 
Ρίό 
= 
P(Xn+1 = j I Xn = i) 
a-j 
if j ' > 0, i = 0 
0 
-i+i 
if 
i > l , j > » - l 
if i > l,j < i - 1 . 
Denoting P = [Pij], we have: 
P = [Pa] = 
αο a\ θ2 
ao ai θ2 
0 
ao ai 
(10.18) 
Note that {Xn, n = 0,1, ■ · · } is an irreducible Markov chain. When p = ^ < 1, 
the chain is positive recurrent. Hence the Markov chain is ergodic. The 
limiting probabilities 
Vj= lim P$\ 
j = 0,1,2,··-, 
n—»oo 
J 
exist and are independent of the initial state i. The probability vector v = 
[VQ,V\,· ■■] is given as the unique solution of v = uP and £ · wj = 1· The 
solution can be obtained by using the generating functions of Vj's and Oj's. 
Define: 
oo 
oo 
A(z) = "Y^ajZ* and V(z) = y^,VjZj 
j=o 
j=o 
A(z) = X]ai 
j=o 
oo 
- Σ-
3=0 
/•OO 
= 
/ 
e 
Jo 
= Γ(λ 
(Γ 
-t(A-A 
-Az) . 
e-xt{\ty 
ß 
z)f(t)dt 
dF(t) 
Here, f*(s) is the Laplace transform of /(£). 

NON-MARKOVIAN MODELS 
4 4 3 
The expected number of arrivals is given by: 
A-m - 
±m z=l 
- -λέ(Γ»-'^/,„ο 
-λ (f-'fWt) 
λ 
= 
~ =P 
From v = vP, we get: 
Vj = v0aj + Σ"tOj-t+i, 
j = 0,1,2,· ■■ . 
t=0 
Multiplying by Zj on both sides and taking the sum, we get: 
oo 
oo 
/ 
oo 
j = 0 
t = l 
\ j = i - l 
= 
v0A(z) + 
-[V(z)-v0}A{z) 
z 
= 
VoA(z)(z 
1) 
z - A(z) 
Using V(l) = A(l) = 1, 
= 
^pA(l) 
= 
v0 
1-A'(1) 
l - i 4 ' ( l ) 
provided A'(l) is finite and less than 1. Taking p = A'{1) < 1 we get u0 = l—p. 
Hence* 
_ ( l - p ) ( z - l ) / * ( A ( l - - z ) ) 
K
(
2
) - 
ζ - / · ( λ ( 1 - ζ ) ) 
Note 10.12 The average number of customers in the system in the steady 
state is given by: 
dV{z) 
\2E(S2) 
Ls = 
dz 
P + 
,=i 
H 
2(1 -p) ■ 
This is known as the P-K mean value formula. Here, E(S2) is the second-
order moment about the origin for the service time. This result holds true for 

444 
INTRODUCTION TO QUEUEING MODELS 
all scheduling disciplines in which the server is busy if the queue is nonempty. 
When σ | is the variance of the service time distribution, we get: 
Note 10.13 In this derivation, we assume FIFO scheduling to simplify the 
analysis. However, the above formulas are valid for any scheduling discipline 
in which the server is busy if the queue is nonempty, no customer departs from 
the queue before completing service and the order of service is not dependent on 
the knowledge about service times. Hence, using Little's formula, the average 
time spent in the system can be calculated. 
Note 10.14 Using the P-K mean value formula, other measures such as Lq, 
Tq and Ts can be obtained as follows: 
Lq = Ls-XE{S), 
E(S) = -
ß 
T — hi 
T — _ 
"~ 
λ ' 
° - 
λ ■ 
The formula states that mean waiting time is given by: 
_ p(l + μ2σ2
8) 
" 
2μ(1-ρ) 
■ 
Hence, the average time spent in the system is Ts = Tq + j^, i.e.: 
_ 1 + / ζ 2 σ | 
1 
8 
2 ( μ - λ ) + μ · 
Note 10.15 (M/D/1 
Queue) When the service time is a constant, i.e., the 
service time follows a deterministic distribution, σ | = 0 and the P-K formula 
reduces to 
where p — λ/μ and l/μ is the constant service time. 
Note 10.16 (M/M/1 
Queue) When service time is exponentially distributed 
I and °2s = j? 
2p2 
with mean τ. and c | = A ■' 
2(1 - p) 
1-p 

N0N-MARK0VIAN MODELS 
445 
■ EXAMPLE 10.15 
Consider Example 10.3. Assume that customers arrive in a Poisson 
process at an average rate of 100 per hour. Also assume that the time 
taken (in seconds) for each reservation by a computer server follows a 
uniform distribution with parameters 20 and 30. 
(a) Find the average waiting time of the customers. 
(b) Find the probability that the system is empty in the long run. 
Solution: The arrival rate is λ = ^ and the average service time is 
^ = 25 seconds. Hence p — | | . 
(a) By using the P-K mean formula and Little's formula, the average waiting 
time evaluates to 42.044 . 
(b) The probability that the system is empty in the long run is: 
Vo = l-p 
= 0.30556. 
A 
■ EXAMPLE 10.16 
Consider an automatic transaction machine (ATM) with only one counter. 
Assume that the customers arrive according to a Poisson process with 5 
customers per hour and may wait outside the counter if the ATM is busy. 
If the service time for the customers follows Weibull{2, ^ ) , determine 
Ls and Tq. 
Solution: This problem is modeled as a M/G/l 
queueing system with 
λ = 5 per hour and l/μ = 0.0886. In this case, service time S fol-
lows Weibull(2, ±). 
Using Theorem 4.5, we have E(S) = 0.0886 and 
Var{S) = 0.01785. 
Using the P-K mean formula in equation (10.19), we get: 
Ls = 1.02 . 
Then, using Little's formula, we get: 
Tq = h 
= hl^E. 
= 0.Π35 . 
A 
A 
A 
10.4.2 
GI/M/1 
Queueing System 
The model to be studied next is the GI/M/1 
model in which the arrivals are 
independent and interarrival times follow a general distribution, but service 

446 
INTRODUCTION TO QUEUEING MODELS 
times follow a Markovian property. Assume that the cdf of the interarrival 
time is F(t) with mean j . Consider Xt as the number of customers in the 
system at time t. Note that the state of the system after the service completion 
of a customer depends not only on the state of the system Xt at that time 
but also on the remaining arrival time of the next customer, if any. However, 
the state of the system after the arrival of a customer depends only on the 
state of the system at that time. 
Let Xn be the number of customers in the system at the arrival instant of 
the nth customer. Suppose tn is the instant at which the nth customer arrives. 
Since these points tn are the regeneration points of the process {Xt; t > 
0}, the sequence of points {tn; n = 0,1,2,···} forms a renewal process. 
Then {Xn\ n = 0,l,---}isan embedded Markov chain with state space S = 
{1,2, · · · }. By Definition 9.52, {Xt; t > 0} is a Markov regenerative process 
having embedded Markov chain {Xn; n = 0,1, · · · }. 
Let An be the number of customers served during the interarrival time of 
the (n + l)th arrival. We then have: 
X n +i = Xn + 1 - An 
where An < Xn + 1, Xn > 0. 
Since the interarrival times are assumed to be independent and have the same 
distribution, the distribution of An is the same for all n. Denote for all n: 
= 
P{An=r) 
f 
Jo 
-μΐ (μί)' dF(t), 
r = 0,l,2,· 
Therefore: 
= 
P(Xn+i 
=j\Xn 
— i) 
bi+i-j 
i + 1 > 3 > 1 
ι-Σί=<Α 
J = O,»>O 
0 
i + 1 < j or i < 0 or j < 0 . 
The transition probability matrix is given by: 
/ 1 - b0 
60 
0 
1 - EiLo bk 
bi 
bo 
[Pa] 
1 - Efc=0 bk 
b2 
h 
0 
0 
&0 
V 
/ 
When the embedded DTMC is irreducible and ergodic, the limiting probabil-
ities that an arrival finds n in the system, denoted by π η, n = 0,1,2, · · · are 
given as the unique solutions of 
πΡ = π and y j π^ = 1, 
fc=o 

NON-MARKOVIAN MODELS 
447 
which gives: 
j=0 
\ 
k=0 
/ 
oo 
1"i 
= 
2_/7Ti+fc-l&A; ) ί > 1 · 
Denoting ζπ< = 7Tf+i, we obtain for i > 1: 
πί_ι(ζ — 6o — z&i - ^2^2 - · · · ) = 0 . 
Thus, for a nontrivial solution 
oo 
z - ^ 6 n Z " = 0, . 
n=0 
it becomes 
G{z) = z 
where G{z) is the probability generating function of the {bn}. It can be shown 
that G(z) = F*(ß(l — z)), where F*(z) is the Laplace-Steiltjes transform of 
the interarrival time cdf F(t). Hence, the above equation may also be written 
as: 
F*(ß{l-z))=z 
. 
(10.20) 
The condition p = - < 1 is a necessary and sufficient condition for the 
existence of the stationary solution (refer to Gross and Harris, 1998). When 
p < 1, the stationary probability of n in the system just prior to an arrival is 
given by 
TTj = ( 1 - r o K , 
i = 0,l,2,..., 
where ro is the positive root between 0 and 1 of equation (10.20). 
Note 10.17 It may be noted that this state distribution will be the equilibrium 
distribution that will be seen if the system is examined just before the instant 
of arrival of a customer to the system. 
Note 10.18 Consider an arrival to the GI/M/1 
queue. Let W be a random 
variable denoting the waiting time in the queue. It takes the value zero if an 
arriving customer finds the system to be empty on arrival (with probability πο). 
If an arriving customer finds n jobs in the system (including the one currently 
in service), then the customer must wait for all of them to get served before 
his own service can begin. Note that the residual service time for the job 
that is currently in service also follows an exponential distribution. The mean 
waiting time in the queue, denoted by Tq, is given by: 
oo 
ro 
Tq = Y,7M~roK = 
^ μ - 
- ' ■" 
M(l-r 0) 

448 
INTRODUCTION TO QUEUEING MODELS 
Note that the mean results will be the same regardless of the service discipline 
being followed other than the FIFO discipline. 
The waiting time distribution can be obtained using conditional distribu-
tions. Note that a customer who finds n customers in the system (including 
the one in service) on his/her arrival will encounter a random waiting time 
that will be equal to the sum ofn independent exponentially distributed random 
variables. From this conditional distribution, the waiting time distribution is 
given by: 
(
0 
if 
t<0 
1 - r o 
if t = 0 
(10.21) 
1 - τ·0β-"(1-Γ°)ί 
if t > 0 . 
■ EXAMPLE 10.17 
In a mobile handset manufacturing factory, a component arrives for 
testing every 3 seconds. It is assumed that the time (in seconds) for 
testing the component is exponentially distributed with parameter 4. 
(a) Find the waiting time distribution of a component in the queue. 
(b) Find the probability that there are no components available for testing 
in the long run. 
Solution: Given λ = | and μ = 4. 
(a) Using equation (10.21), the probability distribution of the waiting time 
of a component in the queue is: 
P(W<t) 
= 
l-^e-«W. 
(b) The long-run probability that the system is empty is πο = (1 — bo) where 
6o = /0
3
 e-Atdt = 0.25 . 
▲ 
10.4.3 
M/G/l/N 
Queueing System 
The non-Markovian queueing model to be discussed next is a finite-capacity 
non-Markovian queueing model. The first model in this list is the 
M/G/l/N 
queueing model. This is similar to M/G/l, 
but now the system capacity is 
restricted to N. 
The analysis of the M/G/l/N 
queue is similar to that of the 
M/G/l/oo 
queue. But the main results of the M/G/l/oo 
queue will not be apphcable 
to the M/G/l/N 
queue. Let us examine the results for the M/G/l/N 
queue 
in detail. Let Xt denote the number of customers in the system at time t. 
Let T„, n = 1,2,···, be the random variable denoting the departure time 
instants of the nth customer. 

N0N-MARK0VIAN MODELS 
4 4 9 
The P-K formula will no longer be applicable to the M/G/l/N 
queue as 
the expected number of arrivals during a service period will depend on the 
system size. Note that the number of customers in the M/G/l/N 
system 
constitutes a Markov regenerative process {Xt; t > 0} with S = {0,1, ■ ■ · , N} 
and embedded Markov chain {Xt+; n = 0,1, · · · } where tn is the nth customer 
departure instant and Xt+ = Xn the corresponding number of customers left 
behind in the system by the departing customer. {Xn;n 
= 0,1, ■ · · } is an 
embedded Markov chain (EMC) with state space S = {0,1,2, · · · , N — 1}. 
The one-step transition probability matrix is now truncated at N — 1 since 
we are observing the state just after a departure. Using P given in (10.18), it 
is given by 
/ 
P = [Pij] = 
ao αχ θ2 
ao 
ai 
θ2 
0 
ao 
ai 
0 
0 
a0 
\ 
0 
0 
0 
1 - Σ„=ο α« Ν 
1 - 2^„=ο a« 
1 
v->Af-3 
1 - Ζ^„=ο a« 
1 - Ζ.„=ο α " 
1 - a 0 
/ 
where the a's are defined in (10.17). Assume that {Xn,n 
= 1)2,···} is irre-
ducible, aperiodic and positive recurrent. Then the steady state probability 
vector v = (vk) of the embedded Markov chain is given by 
vP, Σ Vk 
kes' 
1, 
where P = K(oo) is the transition probability matrix of the EMC. Define the 
matrix (Eij(t))ieS> 
e S as follows: 
Ei:j(t) = P(Xt =j,T!>t\Xo 
= i) 
Oij = E[time spent in j during (Ο,Γχ) \X0 = i]= / 
Eij(t)dt 
. 
(10.22) 
Jo 
Finally, the steady state probabilities for M/G/l/N 
are 
Ekes' ufc«fcj 
■Kj = lim P{Xt = j) = 
t->oo 
Yokes' 
vkßk 
where ßk = 
T,iesak,i-

450 
INTRODUCTION TO QUEUEING MODELS 
EXAMPLE 10.18 
A machine is used for packing items. The machine can pack at most 2 
items at a time. Items arrive as a Poisson process with rate λ = 2. The 
time required for packing an item follows a general distribution. Find 
the steady state probability of the system when the time required for 
packing follows a 
Weibull(2,l/2). 
Solution: Let Xt be the number of items for packing at time t. The 
system can be modeled as a M/G/l/2 
queueing system where each state 
represents a number of items for packing. Using the MRGP theory as 
defined in Section 9.4, we obtain the steady state probabilities. In this 
model, service completion time instants are the only regeneration time 
points. Hence, the time points of entering into states 0 and 1 are the 
only regeneration time instants. Therefore, in this case S = {0,1} and 
S = {0,1,2}. When service time follows a Weibull(2, | ) : 
F(t) = 8ie~ 4 t\ i > 0 . 
Define the stochastic process {Yt,t > 0} during two successive regener-
ative time instants. Then {Yt; t > 0} is a CTMC which is known as the 
subordinated CTMC of the Markov regenerative process {Xt]t > 0}. 
Let Pij(t) be the probability that Vt = j given that YQ = i. We first 
obtain the global and local kernel. The global kernel is defined as 
*■(<) = [*y(t)],»,jeS\ 
where 
k^t) 
= 
P(X1 =j,T1<t\X0 
= i), i,j e S' 
I 
t 
(Poo(z) + Poi(z)) dF(x), 
i, j = 0 
o 
/ Pij+i(x)dF(x), 
i,j e S' 
Jo 
and the local kernel is given by E(t) — [eij(t)]ieS' 
j € S , where: 
εφ) 
= P(Xi =j,T1>t\X0 
= i)= Pij(t){l - F(t)), i e S', j 6 5 . 
Here F(t) is the cumulative distribution function of the general distribu-
tion and Pij(t) are the time-dependent probabilities of the subordinated 
CTMC and are evaluated as: 
P(t) = 
e-xt 
0 
0 
e-xt 
0 
1-- e~xt - Xte~xt 
1 - e~M 
1 

N0N-MARK0VIAN MODELS 
4 5 1 
With this, the elements of K(t) are evaluated as: 
rt 
koo(t) 
= 
/ 8x (λχ + 1) 
ε-λχ-4χ2άχ 
Jo 
rt 
k0l(t) 
= 
/ 8x (1 - e~Xx - Xxe~Xx) 
e'^dx 
Jo 
feio 
ku 
Substituting λ 
i(*) 
(*) 
= 2, 
= 
= 
we 
/ 
8 χ β " λ χ -
Jo 
1 8x(l - < 
Jo 
iget: 
lim feoo(i) 
t—KX) 
lim koi(t) 
t—»oo 
-Ax'dx 
Γλχ)ε-4χ2ά 
= 
0.7728 
= 
0.2272 
lim fcio(i) = 
0.4544 
t—>oo 
lim fcn(i) = 
0.5456 . 
t—*-oo 
Then the steady state probability vector v = (vk) of the EMC is 
v = vP, Σ 
vk = 1, 
kes' 
where P = K(oo) is the transition probability matrix of the EMC. 
Solving, we get VQ = V\ = 1/2. 
Now, the matrix E = [β<^(ί),ϊ E S ,j E S]: 
eoo(i) 
= 
β- λ ί-« 2 
eoi(i) 
= 
\te-xt-ie 
e02(i) 
= 
( l - e - ^ - A i e - A t ) e - 4 t 2 
eio(i) 
= 
0 
en(i) 
= 
e~xt~^ 
ei2(t) 
= 
(1 - e~xt)e-it2 
. 
Substituting λ = 2 and using c*ij = J0 eij(t)dt, 
we get: 
aoo 
= 
0.2728 
αοι 
= 
0.1136 
«02 
= 
0.0567 
c*io = 
0 
a n 
= 
0.2728 
ai2 
= 
0.1703 . 

452 
INTRODUCTION TO QUEUEING MODELS 
Finally, we compute the steady state probabilities for the M/G/l/N 
as 
given below: 
= Zfces' VkC*k,j 
where ßo = β\ = ·ν/2π/8. Hence: 
7Γ0 = 0.3078, 7Γι = 0.436, π2 = 0.2562 . 
▲ 
10.4.4 
GI/M/1/N 
Queueing System 
This queueing model is similar to GI/M/1, 
but now the system capacity is 
restricted to N. Let Xt denote the number of customers in the system at 
time t. Let T„, n = 1,2,···, be the random variable denoting the arrival 
time instant of the nth customer. Here, the arrival time instants are the only 
regeneration time epochs. Hence, {Xt',t > 0} is not a semi-Markov process, 
but a MRGP with {Xn', n = 1,2, · · · } is an embedded Markov chain. S = 
{0,1,2,··· , N} is the set of states at all time instants, and S = { 1 , 2 , · · · , N} 
is the set of states only at regeneration time instants. Following the theory of 
MRGP, we now proceed to determine the global kernel K(t) and local kernel 
E(t) matrices for the process. The elements of the global and local kernel are 
defined as: 
kij(t) = P{XX =j,T1<t\X0 
= i), i,j e 5' 
eij(t) = P(XX =j,T1>t\X0 
= i), ieS, 
j&S 
. 
The global kernel matrix is 
K{t) 
( ku(t) 
k12(t) 
0 
0 
fcai(t) M 0 
M«) 
0 
fcsiW 
*32(0 
*33(t) 
Μ ί ) 
M0 M0 M0 M0 
\ kN1(t) 
kN2(t) 
kN3(t) 
fcjviv(0 / 
where 
/ pij-i{x)dF(x) 
, 
i,j€S' 
kij(t) = \ 
Jft 
/ {pNN-i{x)+PNN(x))dF(x) 
, 
i,j = N 
v Jo 
and the pij's are the transition probabilities of the subordinated CTMC. The 
state transition diagram for the subordinated CTMC is shown in Figure 10.13. 
The local kernel matrix is 

NON-MARKOVIAN MODELS 
453 
,N, 
μ 
μ 
μ 
μ 
Figure 10.13 
Subordinated CTMC 
E(t) 
I e10(i) 
en(t) 
0 
0 
0 
e2o(i) 
e21(i) 
e22(i) 
0 
0 
β3θ(ί) 
e3i(i) 
e32(i) 
e33(i) 
0 
0 
0 
0 
eNN(t) 
) 
\ ejvo(i) 
eNi(t) 
eN2(t) 
eN3(t) 
ßN4(t) 
where ey(t) = Pij(l — F(t)). 
The limiting behavior is obtained by taking the limit as t approaches in-
finity. We require two new process characteristics to be defined, i.e., ay, the 
mean time spent by the MRGP in state j between two successive regeneration 
instants, given that it started in state i after the last regeneration, 
/•OO 
ay = E[time in j during (0, ΧΊ) | Xo = i] = I 
eij(t)dt, 
Jo 
and the steady state probability vector t; = [vk] of the EMC, 
N 
v = vP and J J Vk = 1 
fe=l 
where P = K(oo) is the transition probability matrix of the embedded Markov 
chain. Then the steady state probability of the MRGP is given by 
Σ
Ν 
„ 
_ 
fc=l 
Vkakj 
Efc=i vkPk 
where β = Σ?=ο aki ■ 
Now, let us discuss the time-dependent behavior of the G/M/l/N 
queueing 
system. Define V(t) = (Vij(t)) as the matrix of conditional state probabilities 
of the MRGP and the following equations for V(t) are matrix equations and 
Vy (t) = P{Xt = j | Xo - Yo = <}, t, j e S, 
where {Yn, n > 0} is the embedded Markov chain of the MRGP {Xt; t > 0}. 
Also, 
V(t) 
= 
E(t) + [ dK{s)V(t - s) 
Jo 
= 
E(t) + 
K{t)*V{t) 

454 
INTRODUCTION TO QUEUEING MODELS 
where * denotes the convolution operator. The solution method for the time-
dependent state distribution is outlined below: 
1. Calculate K(t) and E(t). 
2. Compute K(s) and E(s) where K(s) and E(s) are the Laplace-Steiltjes 
transform obtained as: 
/•OO 
/ΌΟ 
K(s) = / 
e-atdK(t) 
and E(s) = / 
β~ΗάΕ(ί) 
. 
Jo 
Jo 
3. Solve the following linear system for V(s) : 
[I - K(s)]V(s) 
= E(s) 
where 
/•OO 
V{s) = / 
e-atdV(t) 
. 
Jo 
4. Using inverse Laplace transforms, invert V(s) to obtain V(t). 
5. Using p(i)ixs = p(0)i xs' ^(0s'xs> obtain the time-dependent state 
probabilities of the MRGP. 
■ EXAMPLE 10.19 
Consider a system of two communicating satellites. The lifetime of a 
satellite follows an exponential distribution with parameter λ whereas 
the time to repair and resend the satellite follows a general distribution 
with mean l/μ. Our interest is to determine the steady state probabili-
ties when time to repair and resend the satellite follows a 
Weibull(2,l/2) 
distribution. Next we analyze a special case of the GI/M/l/N 
queue 
with N = 2. In this queueing model the arrival time instants are the 
only regeneration time instants. Hence, the time points of entering into 
the states 1 and 2 are the only regeneration time instants. Therefore, in 
this case S' = {1,2} and S = {0,1,2}. We solve this MRGP by taking 
F as Weibull(2, ^). Here interarrival time is Weibull(2, | ) . Hence: 
F(f) = 8ie - 4 t 2, i > 0 . 
Proceeding as above, we first evaluate the global and local kernel for 
this MRGP. The global kernel is defined as 
K(t) = [kijit)}, i, 
jeS', 

NON-MARKOVIAN MODELS 
455 
where 
( 
ή 
kij(t) = < 
f Vii-i{x)dT{x) 
, 
(<,.;) = (1,1), (1,2), (2,1) 
Jo 
[ (P2i(x)+P22)(x)dT(x) 
, 
(i,j) = (2,2) 
V Jo 
and the local kernel is given by 
E(t) = [eij(t)]€S.i 
j e s , 
where 
e«(t)=fti(*)(l--F(i))· 
Here F(t) is the cumulative distribution function of the Weibull distribu-
tion and Pij (t) are the time-dependent probabilities of the subordinated 
CTMC and are evaluated as: 
/ 
1 
0 
0 
Pit) = 
e-^ 
1 - β~μ1 
0 
V e-f* 
μίβ-μ1 
1 - e""' - 
μίβ~μί 
With this, the elements of K(t) are evaluated as: 
M O 
= 
/ 
( l - e ^ e x e ^ ' d x 
Jo 
rt 
M O 
= 
/ 8χε-μ3:-4χ2(ίχ 
Jo 
rt 
M O 
= 
/ (1 - e-"x - μχβ-μχ) 8χβ"4χ2ώ 
Jo 
= 
(l - e4'2) - /" (e-"* + /zxe-"x) 8χβ4χ2<& 
M O 
= 
Βμχ2ε-μχ-4χ2άχ+ 
8χβ-μχ-4χ2άχ. 
Jo 
Jo 
Substituting μ = 2, we get: 
lim jfcn(i) 
= 
0.5456 
t—too 
lim ku(t) 
= 
0.4544 
t—>oo 
lim M O 
= 
0.2172 
t—>oo 
lim MO = °·7728 · 
t—»oo 

456 
INTRODUCTION TO QUEUEING MODELS 
Then the steady state probability vector v = (vk) of the EMC is 
v = υΡ, Σ 
vk = 1, 
kes' 
where P = K(oo) is the transition probability matrix of the EMC. 
Solving, we get VQ = v\ = 1/2. Now, the matrix E — [ej j(t),i € S ,j G 
S\: 
ew(t) 
= 
(l-e-^e-^ 
en(t) 
= 
e - ^ - « 2 
ei2(t) 
= 
0 
em(t) 
= 
(1 - e-"* - μίβ""*) e"4'2 
e21(t) 
= 
/xte""4"4'2 
e22(f) 
= 
e-"*- 4* 2. 
Substituting μ = 2 and using a,j = J0 eij(t)dt, 
we get: 
OJIO 
= 
0.1703 
a n 
= 
0.2728 
a12 
= 
0 
«20 
= 
0.0567 
a2i 
= 
0.1136 
a22 
= 
0.2728 . 
The steady state probabilities for the GI/M/1/2 
are given as 
_ E f c €s' Vkakj 
Efc€s' 
υ Ά 
where βο= β\ = \/2π/&. Hence: 
π0 = 0.2561, 7Γι = 0.436, π2 = 0.3078 . 
▲ 
Queueing modeling is an important tool used to evaluate system performance 
in communication networks. It has a wide spectrum of applications in sci-
ence and engineering. In this chapter we have studied some simple queueing 
models. For advanced queueing models such as non-Markovian, bulk and pri-
ority queues and queueing networks, the reader may refer to Gross and Harris 
(1998), Medhi (2003), Bhat (2008), and Bolch et al. (2006). 

EXERCISES 
457 
EXERCISES 
10.1 
Find the service rate for a M/M/l 
queue where customers arrive at a 
rate of 3 per minute, given that 95% of the time the queue contains less than 
10 customers. 
10.2 
The arrival of a patient at a doctor's clinic follows a Poisson process 
with rate 8 per hour. The time taken by the doctor to examine a patient 
is exponential distribution with mean 6 minutes. Given that no patients are 
returned, find: 
a) Probability that the patient has to wait on arrival. 
b) Expected total time spent (including the service time) by any visiting 
patient. 
10.3 
It is assumed that the duration (in minutes) of a telephone conversa-
tion at a telephone booth consisting of only one telephone follows an exponen-
tial distribution with parameter μ = \. If a person arrives at the telephone 
booth 3 minutes after a call started, then find his expected waiting time. 
10.4 
There are two servers at a service center providing service at an expo-
nential rate of two services per hour. If the arrival rate of customers is 3 per 
hour and the system capacity is at most 3, then: 
a) Find the fraction of potential customers that enter the system? 
b) If there was only a single server with service rate twice as fast, i.e., μ=4, 
then what will be the value of part (a)? 
10.5 
There are N spaces in a parking lot. Traffic arrives in a Poisson process 
with rate λ, but only as long as empty spaces are available. The occupancy 
times have an exponential distribution with mean l/μ. 
If Xt denotes the 
number of occupied parking spaces at any time t, then: 
a) Determine infinitesimal generator matrix Q and the forward Kolmogorov 
equations for the Markov process {Xt',t > 0}. 
b) Determine the limiting probability distribution of the stochastic process 
{Xf,t>0}. 
10.6 
An automobile emission inspection station has three inspection stalls, 
each with room for only one car. It is assumed that when a stall becomes 
vacant, the car standing first in the waiting line pulls up to it.Only four cars 
are allowed to wait at a time (seven in the station). Arrival occurs in a Poisson 
way with mean of one car per minute during the peak periods. The service 
time is exponential with mean 6 minutes. 
1. Determine the average number of cars in the system during peak periods. 

458 
INTRODUCTION TO QUEUEING MODELS 
2. Determine the average waiting time (including service). 
10.7 
Show that the average time spent in a M/M/l 
system with arrival 
rate λ and service rate 2μ is lesser than the average time spent in a 
M/M/2 
system with arrival rate λ and each having service rate μ which is lesser than 
the average time spent in two independent M/M/l 
queues with each having 
arrival rate λ/2 and equal service rate μ. 
10.8 
Suppose that you arrive at an ATM to find seven others, one being 
served (first-come-first-service basis) and the other six waiting in line. You 
join the end of the line. Assume that service times are independent and 
exponentially distributed with rate μ. 
a) Model this situation as a birth-and-death process. 
b) What is the expected amount of time you will spend in the ATM? 
10.9 
A telephone switching system consists of c trunks with an infinite 
caller population. Calls arrive in a Poisson process with rate λ and each call 
holding time is exponentially distributed with average l/μ. Let p = λ/μ. 
It 
is assumed that an incoming call is lost if all the trunks are busy. 
a) Draw the state transition diagram for the system. 
b) Derive an expression for π η, the steady state probability that n trunks 
are busy. 
c) Also find the number of trunks n, such that π η < 0.001. 
10.10 
For the M/M/l/N 
queueing system, show that as limit N —> oo 
there are two possibilities: either p < 1 and P converges to the stationary 
distribution of the M/M/l 
queue or p > 1 and P goes to infinity. 
10.11 
Consider a telephone switching system with N subscribers. Each 
subscriber can attempt a call from time 0. Assume that there are c (< N) 
channels in the telephone switching system to handle the calls and assume 
that each call needs one channel. Assume that the arrival of a call from each 
customer follows a Poisson process with rate λ and each call duration follows 
an independent exponential distribution with rate μ. 
a) Draw the state transition diagram for this queueing system. 
b) Suppose that c = 10. Find λ such that no call is waiting. 
10.12 
For an M/M/c/co 
queue, prove that the distribution of waiting time 
in the queue is given by 
oo 
Ρ[ν, = 0] = 
1-ψ— 
1 - p 

EXERCISES 
459 
and 
fWq(t)=cß 
Pce-^~x)t, 
0<t<oo. 
10.13 
A toll bridge with c booths at the entrance can be modeled as a 
c server queue with infinite capacity. Assuming the service times are inde-
pendent exponential random variables with mean 1 second, sketch the state 
transition diagram for a continuous-time Markov chain for the system. Find 
the limiting state probabilities. What is the maximum arrival rate such that 
the limiting state probabilities exist? 
10.14 
Assume that taxis are waiting outside a station, in a queue, for pas-
sengers to come. Passengers for these taxis arrive according to a Poisson 
process with an average of 60 passengers per hour. A taxi departs as soon 
as two passengers have been collected or 3 minutes have expired since the 
first passenger has got in the taxi. Suppose you get in the taxi as the first 
passenger. What is your average waiting time for the departure? 
10.15 
Consider a Markovian queueing model with finite population, say N. 
In reliability theory, this model is known as the machine repair problem. In 
this case, customers are treated as N machines which are prone to failure. 
The lifetime of each machine is assumed to be exponentially distributed with 
parameter λ. There are c repairmen who repair the broken machines sequen-
tially. The repair times are assumed to be exponential distributions with 
parameter μ. Obtain the steady state probabilities for this system. 
10.16 
For an M/M/l/N 
queueing system, show that the waiting time dis-
tribution W(t) is 
where P n, n = 0,1, · · · ,N — 1, is the steady state probability. 
10.17 
Find the stationary distribution for a M/M/c/c/K 
loss system with 
K population. 
10.18 
Consider a M/Ek/l 
queueing system with arrival rate λ and mean 
service time - . Let p—-. 
Then show that the probability generating function 
of the distribution of the system state in equilibrium is given by: 
_ 
( l - p ) ( l - z ) 
1 - 2 
1 + 
£ ü - l 

CHAPTER 11 
STOCHASTIC CALCULUS 
Stochastic calculus plays an essential role in modern mathematical finance 
and risk management. The objective of this chapter is to develop concep-
tual ideas of stochastic calculus in order to provide a motivational framework. 
This chapter presents an informal introduction to martingales, Brownian mo-
tion, and stochastic calculus. Martingales were first defined by Paul Levy 
(1886-1971). The mathematical theory of martingales has been developed by 
American mathematician Joseph Doob (1910-2004). We begin with the basic 
notions of martingales and its properties. 
11.1 
MARTINGALES 
The martingale is a strategy in a roulette game in which, if a player loses a 
round of play, then he doubles his bet in the following games so that if he 
wins he would recover from his previous losses. Since it is true that a large 
losing sequence is a rare event, if the player continues to play, it is possible for 
the player to win, and thus this is apparently a good strategy. However, the 
player could run out of funds as the game progresses, and therefore the player 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
461 
By Liliana Blanco Castafieda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

462 
STOCHASTIC CALCULUS 
cannot recover the losses he has previously accumulated. One must also take 
into account the fact that casinos impose betting limits. 
Formally, suppose that a player starts a game in which he wins or loses 
with the same probability of | . The player starts betting a single monetary 
unit. The strategy is progressive where the player doubles his bet after each 
loss in order to recoup the loses. A possible outcome for the game would be 
the following: 
Bet 
1 
2 
4 
8 
16 
1 
1 
Outcome 
F 
F 
F 
F 
W
W
F 
Profit 
-1 
-3 
-7 
-15 
1 
2 
1 
Here W denotes "Win" and F denotes "Failure". This shows that every time 
the player wins, he recovers all the previous losses and it is also possible to 
increase his wealth to one monetary unit. Moreover, if he loses the first n bets 
and wins the (n + l)th, then his wealth after the nth bet is equal to: 
n - l 
- 1 - 2 - 22 
2 n - 1 + 2n = - ^ 2 * + 2n = 1. 
fc=0 
This would indicate a win for the player. Nevertheless, as we shall see later, to 
carry out this betting strategy successfully, the player would need on average 
infinite wealth and he would have to bet infinitely often (Rincon, 2011). 
In probability theory, the notion of a martingale describes a fair game. 
Suppose that the random variable Xm denotes the wealth of a player in the 
mth round of the game and the σ-field 3fm has all the knowledge of the game 
at the mth round. The expectation of Xn (with n>m), 
given the information 
in S m, is equal to the fortune of the player up to time m. Then the game is 
fair. Using probability terms, we have, with probability 1: 
E (Xn | 3fm) = Xm for all 
m<n. 
A stochastic process {Xt',t > 0} satisfying the above equation is called a 
discrete-time martingale. Formally we have the following definitions: 
Definition 11.1 Let (Ω,9, Ρ) be a probability space. A filtration is a collec-
tion of sub-σ-algebras (9„) n > 0 o/3 such that S m C 9 n for allm < n. We say 
that the sequence {Xn', n > 0} is adapted to the filtration (9n)n>o *// o r e a c^ n 
the random variable Xn is Qn-measurable, that is, {ω € Ω : Χη(ω) < a} € $« 
for all a 6 R. 
Definition 11.2 Let {Xn;n 
> 0} be a sequence of random variables defined 
on the probability space (Ω, Qf, P) and (3 n) n> 0 &e a filtration in 9. Suppose 
that {Xn', n > 0} is adapted to the filtration ( 5 n ) n > 0 and E(Xn) 
exists for all 
n. We say that: 
(a) {Xn; n > 0} is a ($ln)n-martingale 
if and only if E{Xn 
\ S m) — Xm 0-S-
for all m <n. 

MARTINGALES 
463 
(b) {Xn;n 
> 0} is a {^n)n-submartingale 
if and only if E(Xn 
\ 3 m) > Xm 
a.s. for all m < n. 
(c) {Xn',n > 0} is a {$Sn)n-supermartingale 
if and only if E(Xn 
| 3 m) < 
Xm a.s. for all m <n. 
Note 11.1 The sequence {Xn;n 
> 0} is obviously adapted to the canonical 
filtration or natural filtration. That is to say that the filtration (9n)n>o *s 
given by Qn = σ (Χι,Χ2, ■ ■ ■ ,Xn), 
where σ (Χι,Χ2, · · · , Xn) is the smallest 
σ-algebra with respect to which the random variables Χχ,Χ2,... 
,Xn are S n-
measurable. When we speak of martingales, supermartingales and submartin-
gales, with respect to the canonical filtration, we will not explicitly mention 
it. In other words, if we say: "{Xn)n 
is a (sub-, super-) martingale" and we 
do not reference the filtration, it is assumed that the filtration is the canonical 
filtration. 
Note 11.2 If {Xn;n 
>0} is a ($Sn)n-martingale, it is enough to see that: 
E (Xn+1 
| S n) = Xn for all n s N . 
Note 11.3 // {Xn;n 
> 0} is a (S$n)n-submartingale, 
then {—Xn;n > 0} is 
a C^n)n-supermartingale. 
Thus, in general, with very few modifications, ev-
ery proof made for submartingales is also valid for supermartingales and vice 
versa. 
■ EXAMPLE 11.1 
Let {Xn',n > 0} be a martingale with respect to (3in)n>o a nd (Qn)n>o 
be a filtration such that Qn C SJn for all n. If Xn is 3n-measurable, then 
{Xn',n > 0} is a martingale with respect to (Qn)n- Indeed: 
E (X n +i \gn) 
= 
E (E (Xn+1 
| 3 n) | Qn) 
= 
E(xn\gn) 
= xn. 
Therefore, every ((?n)„-martingale is a martingale with respect to the 
canonical filtration. 
▲ 
■ EXAMPLE 11.2 
Random Walk Martingale 
Let Z\, Z2, ■ ■ ■ be a sequence of i.i.d. random variables on a probability 
space (Ω, 3, P) with finite mean μ = E (Z\), and let 9„ = σ(Ζ\, ■■· , Zn), 

464 
STOCHASTIC CALCULUS 
n > 1. Let Xn = Zx + ■ ■ ■ + Zn, n > 1. Then, for all n > 1, 
E(Xn+1\Zn) 
= 
E(Xn 
+ 
= 
E(Xn\Zn) 
+ 
E(Zn+l\$tn) 
= 
Xn + 
E{Zn+i) 
= 
Χη + μ 
so that: 
E(Xn+1\<3n) 
= 
Xn 
if 
μ = 0 
> 
Xn 
if 
μ > 0 
< 
Xn 
if 
μ < 0. 
Thus, {Xn',n > 1} is a martingale if μ = 0, a submartingale if μ > 0 
and a supermartingale if μ < 0. 
▲ 
■ EXAMPLE 11.3 
Second-Moment Martingale 
Let Zi, Z2, · ■ · be a sequence of i.i.d. random variables on a probability 
space (Ω, 3, P) with finite mean μ = E (Z{) and variance σ1 = 
Var(Zi). 
n 
Let 3 n = σ(Ζι,··· ,Zn), 
n > 1. Let yn = ^ 
(Z» - μ)2 and r n = 
t = l 
Yn — ησ2. It is easily verified that {Yn;n > 1} is a submartingale and 
\ Υη',η > If is a martingale. Assume: 
E (y n + 1 I 3f„) 
= 
E (Yn+1 - (n + 1)σ2 | 9f„) 
= 
£;(Κη + ( Ζ η + 1 - μ ) 2 | 9 η ) - ( η + 1 ) σ 2 
= 
Ε(Υη\Ζη)+Ε((Ζη+1-μ)2)-(η+1)σ2 
= 
Υη-ησ2 
= Ϋη. 
k 
■ EXAMPLE 11.4 
Let Χ\,Χ2,·'Φ 
be a sequence of independent random variables with 
E(Xn) 
= 1 for all n. Let {Yn;n > 1} be: 
n 
^n = ]JXi 
t = l 

MARTINGALES 
465 
If Qin = σ(Χι, ■ ■ ■ , Xn), it is clear that: 
E(Yn+1\%n) 
= 
E(YnXn+1\Zn) 
= 
YnE (Xn+1 I ^>n) 
= 
YnE(Xn+i) 
= Yn. 
That is, {Yn;n > 1} is a martingale with respect to (Q;„)n. 
A 
EXAMPLE 11.5 
Polya Urn Model 
Suppose that an urn has one red ball and one black ball. A ball is 
drawn at random from the urn and is returned along with a ball of the 
same color. The procedure is repeated many times. Let Xn denote the 
number of black balls in the urn after n drawings. Then XQ = 1 and 
{Xn', n > 0} is a Markov chain with transitions 
P(Xn+1=k 
+ l\Xn 
= k) 
= 
P(Xn+1=k\Xn 
= h) 
= 
E(Xn+1\Zn)=Xn 
+ 
n + 2 
n + 2 
and 
n + 2 
Xn 
n + 2 
Let Mn = ^£2 be the proportion of black balls after n drawings. Then 
{Mn;n > 0} is a martingale, since: 
£ ( M n + 1 | 3 n ) 
= 
E 
U{Xn + nT2) 
n + 3 
Xn 
n + 2 = Mn. 
EXAMPLE 11.6 
Doob's Martingale 
Let X b e a random variable with £7 (|A"|) < 00, and let { S n } n > 1 be a 
filtration. 
Define Xn = E{X | 3f„) for n > 1. Then {Xn,n 
>~0} is a 
martingale with respect to { S n } n > 0 : 
E(\Xn\) 
= 
E{\E(X\3tn)\) 
< 
E(E(\X\)) 
= 
E(\X\)<oo. 

466 
STOCHASTIC CALCULUS 
Also, 
E (Xn+1 
I 9„) 
= 
E {E (X | 9fn+1) | 9fn) 
= 
E{X\$tn) 
= 
Xn- 
A 
As we know that every martingale is also a submartingale and a supermartin-
gale, the following theorem provides a method for getting a submartingale 
from a martingale. 
Theorem 11.1 Let {Mn;n > 0} be a martingale with respect to the filtration 
(ön)„>o· If φ{·) is a convex function with Ε(\φ(Μη)\) 
< oo for all n, then 
{φ(Μη);η 
> 0} is a submartingale. 
Proof: By Jensen's inequality (Jacod and Protter, 2004): 
E (φ (M n +i) | 3 n) 
> 
φ (Ε (M n + 1 | 3 n)) 
> 
Φ(Μη). 
EXAMPLE 11.7 
Let {Mn; n > 0} be a nonnegative martingale with respect to the filtra-
tion (9 n) n> 0. Then {M%;n > 0} and {— log Mn;n > 0} are submartin-
gales. 
▲ 
EXAMPLE 11.8 
Let {Yn',n > 1} be an arbitrary collection of random variables with 
E[\Yn\] < oo for all n > 1. Let 3„ = σ (Yu ■ ■ ■ , Yn), n > 1. For n > 1, 
define 
n 
Ι η = ^ [ 7 3 - £ Κ | 3 Η ) ] 
(11-1) 
i=\ 
where Q?o = {0>Ω}. Then, for each n > 1, Xn is 3in-measurable with 
E[\Xn\] < oo. Also, for n > 1: 
n+1 
E (Xn+1 | 9 n) 
= 
£ 
£7 (ft- - £ (Yj | 9 ^ 0 ] | 9fn) 
n 
+ [ s ( y n + i | 9 „ ) - f ; ( r n + i | 9 f n ) ] 

MARTINGALES 
467 
Hence {Xn;n > 1} is a martingale. Thus, it is possible to construct 
a martingale sequence starting from any arbitrary sequence of random 
variables. 
A 
■ EXAMPLE 11.9 
Let {Xn\n 
> 0} be a martingale with respect to the filtration (S n) n > 0 
and let {Yn; n > 0} be defined by: 
Yn+i := Xn+i — Xn, n = 0,1,2, · · · . 
It is clear that: 
£ ( y n + 1 | 3 n ) = 0 V n = 0,l,2,··· . 
Suppose that {Cn;n > 1} is a predictable stochastic process, that is, Cn 
is a Qin_i-measurable random variable for all n. We define a new process 
{Zn;n > 0} as: 
Zo 
:= 
0 
n 
Zn := Y^QYi, n > 1. 
t = l 
The process {Zn; n > 0} is a martingale with respect to filtration {9n}n>o 
and is called a martingale transformation 
of the process Y, denoted by 
Z = C ■ Y. 
The martingale transforms are the discrete analogues of 
stochastic integrate. They play an important role in mathematical fi-
nance in discrete time(see Section 12.3). 
L 
Note 11.4 Suppose that {Cn; n > 1} represents the amount of money a player 
bets at time n and Yn := Xn — Xn-i 
is the amount of money he can win or 
lose in each round of the game. If the bet is a monetary unit and Xo is the 
initial wealth of the player, then Xn is the player's fortune at time n and Zn 
represents the player's fortune by using the game strategy {Cn;n > 1}. The 
previous example shows that if {-X"n;n > 0} is a martingale and the game is 
fair, it will remain so no matter what strategy the player follows. 
■ EXAMPLE 11.10 
Let ξι,ξζ,··· 
be i.i.d. random variables and suppose that for a fixed f: 
m(t) :=Ε(ειξι) 
< oo. 
The sequence of random variables {Xn~, n > 0} with Xo '■= 1 and 
Xn = Xn (t) := 
n exp I ί^ξ,· J , n > 1, 

468 
STOCHASTIC CALCULUS 
is a martingale. 
■ EXAMPLE 11.11 
Let £1,62,··· a nd Xn (t) be as in the example above. We define the 
random variables 
W 
= Y<ik) (t) := ^
^ 
|t=o 
We have that i Yn 
: n > 1 f is a martingale. 
▲ 
Definition 11.3 A random variable τ with values {1,2, · · · } U {00} is a stop-
ping time with respect to the filtration (3f
n)„>i if {r <n} 
€ 3„ for each 
n> 1. 
Note 11.5 The condition given in the previous definition is equivalent to 
{τ = n} £ 9 n for each n > 1. 
■ EXAMPLE 11.12 
First Arrival Time 
Let X\,X2, 
■ ■ · be a sequence of random variables adapted to the fil-
tration (9η)„>ι· Suppose that A is a Borel set of K and consider the 
random variable defined by 
r := min {n > 1 : Xn 6 A} 
with min (0) := CXD. It is clear that τ is a stopping time since: 
{r = n} = {Xi i A) n · · · Π {Χη-ι 
φΑ}η 
{Xn e A} e 3„. 
In particular we have that, for the gambler's ruin case, the time r at 
which the player reaches the set A = {0, a} for the first time is a stopping 
time. 
A 
EXAMPLE 11.13 
Martingale Strategy 
Previously we observed that if a player who follows the martingale strat-
egy loses the first n bets and wins the (n + l)th bet, then his wealth 
Xn+i after the (n -I- l)th bet is: 
n - l 
-1 - 2 - 22 
2n_1 + T = - V V + T = 1. 
fc=l 

MARTINGALES 
469 
Suppose that r is the stopping time at which the player wins for the 
first time. It is of our interest to know what is, on average, his deficit 
for that time. That is, we want to determine the value E(XT-i) 
from 
the previous equation. We have: 
oo 
1 
£(XT_1) = ^ ( - l - 2 - 2 2 
2- 1)— T = -oo. 
n=0 
Δ 
Therefore, on average, a player must have an infinite capital to fulfill 
the strategy. 
▲ 
Let {Xn;n > 1} be a martingale with respect to the filtration (3 η) η>ι· We 
know that E(Xn) = Ε(Χχ) for any n > 1. Nevertheless, if r is a stopping 
time, it is not necessarily satisfied that E (XT) = E (Xi). Our next objective 
is to determine the conditions under which E {XT) = E (Xi), where r is the 
stopping time. 
Definition 11.4 Let τ be a stopping time with respect to the filtration (3ί«)η>ο 
and let {Xn',n > 0} be a martingale with respect to the same filtration. We 
define the stopped process {ΧΤΛη', η > 0} as follows: 
Xr/\n{u) 
— Χη{ω)Χ{τ(ω)>η} 
+ 
^τ(ω)Χ{τ{ω)<η}· 
Theorem 11.2 If {X„;n > 1} is a martingale with respect to (9n)n>o «"^ 
if T is a stopping time with respect to (3η)η>ο> then {Χ τ Λ η;η > 0} is a mar-
tingale. 
Proof: Refer to Jacod and Protter (2004). 
■ 
Theorem 11.3 (Optional Stopping Theorem) Let {Xn',n > 0} be a mar-
tingale with respect to the filtration ( ö n ) n > 1 and let τ be a stopping time with 
respect to ($«)„>i· # 
1. T < ooa.s., 
2. E{XT)and 
< oo 
3. 
l i m £ ( X n * { T > n } ) = 0 , 
then E {XT) = E (Xn) for 
alln>l. 
Proof: Since for any n > 1 it is satisfied that 
XT = ΧτΛη + {Χτ — Xn) 
X{r>n) 
and since the process {X„;n > 0} and {XT/\n',n > 0} are both martingales, 
we have: 
E(XT) 
= E(XTAn) 
+ 
E((XT-Xn)X{T>n}) 
= E(Xn) + E(XTX{T>n})-E(XnX{T>n}). 
(11.2) 

470 
STOCHASTIC CALCULUS 
On the other hand by the hypothesis 
lim E (XnX{T>n}) 
= 0 
and 
(
oo 
\ 
oo 
j=l 
J 
j=l 
it follows that the tail of the series, which is E (ΧτΧ{τ>η}) > tends to zero as 
n tends to oo. Therefore, taking the limit as n —> oo in (11.2), we obtain: 
E (XT) = E (Xn) for all n > 1. 
Note 11.6 Suppose that {Xn;n 
>0} is a symmetric random walk in Z unth 
Xo := 0 and that N is a fixed positive integer and let τ be the stopping time 
defined by: 
τ:=πήη{η> 1 : \Xn\ = N} . 
It is easy to verify that the process {Xn; n > 0} and the process {X% — n; n > 0} 
are martingales. Moreover, it is possible to show that the stopping theorem 
hypotheses are satisfied. Consequently, we get 
E(X2
T-T)=E 
(Xl 
- 
1) = 
0 
from which we have: 
Ε(τ) = Ε{Χΐ) 
=E(\XT\2^ 
=E(N2)=N2. 
That is, the random walk needs on average N2 steps to reach the level N. 
The following results on convergence of martingales, which we state with-
out proof, provide many applications in stochastic calculus and mathematical 
finance. 
Theorem 11.4 Let {Xn;n 
> 0} be a submartingale with respect to (3n)n>o 
such that supn E (|^ n|) < oo. Then there exists a random variable X having 
E(\X\) 
< oo such that: 
lim Xn = X 
a.s. 
n—>oo 
Note 11.7 There is a similar result for supermartingales because if{Xn; n > 0} 
is a supermartingale with respect to (3n)„>o> then {—Xn;n > 0} is a sub-
martingale with respect to (ön)n>o· The previous theorem implies in addition 
that every nonnegative martingale converges almost surely. The following ex-
ample shows that, in general, there is no convergence in the mean. 

MARTINGALES 
471 
■ EXAMPLE 11.14 
Suppose that {Yn',n > 1} is a sequence of i.i.d random variables with 
normal distribution each having mean 0 and variance σ2. Let: 
X0 
:= 
1 
Xn 
'■= 
It is easy to prove that {Xn;n 
> 0} is a nonnegative martingale. By 
using the strong law of large numbers we obtain that Xn ^ > 0. Never-
theless, Xn -A 0 since E (Xn) = 1 for all n. 
▲ 
Now we present a theorem which gives a sufficient condition to ensure the 
almost sure convergence and convergence in the r-mean. Its proof is beyond 
the scope of this text, (refer to Williams, 2006). 
Theorem 11.5 If {Xn;n 
> 0} is a martingale with respect to (9 n) n 6 N such 
that sup.E(|Xn|r) < oo for some r > 1, then there is a random variable X 
n 
such that 
Xn —> X 
converges almost surely and in the r-mean. 
Next, we give a brief account of continuous-time martingales. Many of 
the properties of martingales in discrete time are also satisfied in the case of 
martingales in continuous time. 
Definition 11.5 Let (Ω,3, Ρ) be a probability space. A filtration is a family 
of sub-σ-algebras {^t)teT 
such that 9 S C 9 t for all s <t. 
Definition 11.6 A stochastic process {Xt',t ε T} is said to be adapted to the 
filtration (^t)teT tf Xt is 9^ -measurable for each t 
€T. 
Definition 11.7 Let f l ^ T C I . A process {Xt; t € T} is called a martingale 
with respect to the filtration (3ft)feT if: 
1. {Xt;t €T} 
is adapted to the filtration (3it)teT· 
2. E{\Xt\) 
< oo for all 
teT. 
3. E (Xt | Ss) = Xa a.s. for all 
s<t. 
Note 11.8 
a. If condition 3 is replaced by: E (Xt | 3 a) > Xa o..s. for all s <t, then the 
process is called a submartingale. 

472 
STOCHASTIC CALCULUS 
b. If condition 3 is replaced by: E (Xt | 9S) < Xs as. for all s <t, then the 
process is called a supermartingale. 
Note 11.9 Condition 3 in the previous definition is equivalent to: 
E {Xt - Xs | 3S) = 0 a.s. for all 
s<t. 
Note 11.10 The sequence {Xt;t £ T} is clearly adapted to the canonical fil-
tration, that is, to the filtration (3 t) t 6 T, where 9 t = σ (Xs, s <t) is the small-
est σ-algebra with respect to which the random variables Xs with s < t are 
measurable. 
■ EXAMPLE 11.15 
Let {Xt;t > 0} be a process with stationary and independent incre-
ments. Assume S t = σ (Xa, s <t) and E (Xt) = 0 for all t > 0. Then: 
E(Xt\%) 
= E(Xt-Xs 
+ 
Xs\%) 
= 
E{Xt-Xs\%) 
+ 
E(Xs\%) 
= E(Xt-Xs) 
+ Xs 
= E(Xt-3) 
+ Xa 
= 
Xs. 
That is, {Xt\t > 0} is a martingale with respect to (9t) t > 0 ■ 
A 
Note 11.11 If in the above example we replace the condition "E (Xt) = 0 for 
all t > 0" by "E (Xt) > 0 for all t > 0" ["E (Xt) < 0 for all t > 0"] we find 
that the process is a submartingale (a supermartingale). 
■ EXAMPLE 11.16 
Let {Nt;t > 0} be a Poisson process with parameter λ > 0. The process 
{Nt;t > 0} has independent and stationary increments and in addition 
E (Nt) = Xt > 0. Hence, {Nt; t > 0} is a submartingale. 
However, the process {Nt — Xt;t> 0} is a martingale and is called a 
compensated Poisson process. 
A 
11.2 
BROWNIAN MOTION 
The Brownian motion is named after the English botanist Robert Brown 
(1773-1858) who observed that pollen grains suspended in a liquid moved 
irregularly. Brown, as his contemporaries, assumed that the movement was 

BROWNIAN MOTION 
4 7 3 
due to the life of these grains. However, this idea was soon discarded as the 
observations remained unchanged by observing the same movement with inert 
particles. Later it was found that the movement was caused by continuous 
particle collisions with molecules of the liquid in which it was embedded. 
The first attempt to mathematically describe the Brownian motion was made 
by the Danish mathematician and astronomer Thorvald N. Thiele (1838-
1910) in 1880. Then in the early twentieth century, Louis Bachelier (1900), 
Albert Einstein (1905) and Norbert Wiener (1923) initiated independently the 
development of the mathematical theory of Brownian motion. Louis Bachelier 
(1870-1946) used this movement to describe the behavior of stock prices in 
the Paris stock exchange. Albert Einstein (1879-1955) in 1905 published 
his paper "Über die von der molekularischen Theorie der Wärme gefordete 
Bewegung von in ruhenden Flüssigkeiten suspendierten Teilchen" in which he 
showed that at time t, the erratic movement a particle can be modeled by 
a normal distribution. The American mathematician Norbert Wiener (1894-
1964) was the first to perform a rigorous construction of Einstein's model of 
Brownian motion, which led to the definition of the so-called Wiener measure 
in the space of trajectories. In this section we introduce Brownian motion 
and present a few of its important properties. 
Definition 11.8 The stochastic process B = {Bt,t > 0} is called a standard 
Brownian motion or simply a Brownian motion if it satisfies the following 
conditions: 
1. B0 = 0. 
2. B has independent and stationary 
increments. 
3. For s <t, every increment {Bt — Bs} is normally distributed with mean 
0 and variance (t — s). 
4- Sample paths are continuous with probability 1. 
Note 11.12 
1. The Brownian motion is a Gaussian process. This is because the dis-
tribution of a random vector of the form {Btx, Bti, · · · , Btn) is a linear 
combination of the vector (Btl, Bt3 — Btl ,·■■ , Btn — Btn_1) 
which has 
normal distribution. 
2. The Brownian motion is a Markov process with transition probability 
density function 
P (Bt edy\B3=x)= 
pxy{t - s)dy = 
e~^Tdy 
1/2π(ί - s) 
for any x, y € R and 0 < s < t. 

STOCHASTIC CALCULUS 
Figure 11.1 
Sample path of Brownian motion 
3. The probability density function of Bt is given by: 
fBt(x) = 
1 
!2id 
In the following algorithm, we simulate the sample path for the Brownian 
motion. This involves repeatedly generating independent standard normal 
random variables. 
Algorithm 11.1 
Input: T, N where T is the length of time interval and N is the time steps. 
Output: BM(k) for k = 0(1)JV. 
Initialization: 
BM(0) := 0 
Iteration: 
For jfc = 0(1)N - 1 do: 
Z(k + 1) = 
stdnormal(rand(0,1)) 
BM(k + 1) = BM(K) 
+ y/Ψ/Ν x Z(k + 1) 
where stdnormal(rand(Q, 1)) is the value of the standard normal random vari-
able using the random number generated in the interval (0,1). Using this 
algorithm, we obtain the sample path of Brownian motion as shown in Figure 
11.1 for T = 10 and N = 1000. 
Now we will discuss some simple and immediate properties of the Brownian 
motion: 

BROWNIAN MOTION 
475 
1. E(Bt) 
=0ϊοτ 
alli > 0. 
2. E (Bf) = t for all t > 0. 
3. The covariance of Brownian motion C(s, t) = min (s, t). This is because, 
if s < t, then: 
C{s,t) 
= 
Cov(Bt,Ba) 
= 
E(BtBa)-E(Bt)E(Ba) 
= 
E([(Bt-B.) 
+ 
Be]B.) 
= 
E((Bt-Ba)Ba) 
+ E(B2
a) 
= 
0 + s = min (s, f). 
Similarly, if t < s, we get C(s,t) = i. Hence, the covariance of Brownian 
motion C(s, t) = min (s, t). 
Theorem 11.6 Let {Bt;t > 0} be a Brownian motion. 
Then the following 
processes are ateo Brownian motions: 
1. Shift Property: For any s > 0, B\X) = Bt+S - Bs is a Brownian motion. 
2. Symmetry Property: B\ ' — — Bt is a Brownian motion. 
3. Scaling Property: For any constant c> 0, B\' 
= Λ/CBI 
is a Brownian 
c 
motion. 
4- Time Reversal Property: B\ ' — tBi for ί > 0 with Bo = 0 is a Brow-
nian motion. 
Proof: It is easy to check that {B{
tf';t > 0} for i — 1,2,3,4 are processes 
with independent increments with BQ = 0. Also the increments are normally 
distributed with mean 0 and variance (t — s). 
m 
Brownian Motion as a Limit of Random Walks 
Let {Xt,t 
> 0} be 
the stochastic process representing the position of a particle at time t. We 
assume that the particle performs a random walk such that in a small interval 
of time of duration Δί the particle moves forward a small distance Δχ with 
probability p or moves backward by a small distance Ax with probability 
q = 1 — p, where p is independent of x and i. Suppose that the random 
variable Yk denotes the length of the kth step taken by the particle in a small 
interval of time Δί and the V^'s are independent and identically distributed 
random variables with P{Yk = +Δχ) = p — 1 — P(Yk = —Ax). 
Suppose that the interval of length t is divided into n equal subintervals of 
length Δί. Then n · (Δί) = t, and the total displacement Xt of the particle is 
the sum of n i.i.d. random variables Yk, so that 

476 
STOCHASTIC CALCULUS 
Xt(U):=Y,Yi 
i=l 
with n = [n(t)] and n(t) = t/At for each t > 0. As a function of t, for each 
ω, Xt is a step function where steps occur every At units of time and steps 
are of magnitude Δχ. We have: 
E{Yi) = (p - q)Ax 
and 
Var(Yi) = 4pq{Ax)2 . 
Then: 
E(Xt) = n(p - q)Ax 
and 
Var{Xt) 
= Anpq(Ax)2 . 
Substituting n = ^ , w e have: 
Λτ 
(Ax)2 
E(Xt) = t{p -q)— 
and 
Var(Xt) 
= ApqtK-^- 
. 
When we allow Ax —> 0 and Δί —^ 0, the corresponding steps n tend to 
oo. We assume that the following expressions have finite limits: 
Δτ 
E{Xt) = t{p-q)—^ßt 
(11.3) 
and 
Var{Xt) 
= Apqt^- 
-» σΗ 
(11.4) 
where μ and σ are constants. Since the Y^'s are i.i.d. random variables, 
using the central limit theorem, for large n = n(t) the sum ]^" = 1 Yi = Xt is 
asymptotically normal with mean μί and variance a2t. That is, 
where Z is a standard normal random variable. 
Various Gaussian and non-Gaussian stochastic processes of practical rel-
evance can be derived from Brownian motion. We introduce some of those 
processes which will find interesting applications in finance. 
■ EXAMPLE 11.17 
Let {Bt;t > 0} be a Brownian motion. The stochastic process {Rt,t > 
0} defined by 
>0 
^ - 1 ^ 1 = 1 JBt \iB\<Q 

BROWNIAN MOTION 
477 
is called a Brownian motion reflected at the origin. The mean and vari-
ance of Rt are given by: 
E{Rt) 
= 
/ 
Jo 
Ί 
Jo 
00 
, 
1 
_ ^ 
x 
. 
e 2* 
/2πί 
OO 
°° 
1 
_*£ 
2 / 
x , 
e 2» 
0 
\/2πί 
27 
Var(Ät) 
= 
£(ß?)-[£(fl t)] 2 
π / 
EXAMPLE 11.18 
Let {Bt;t > 0} be a Brownian motion. The stochastic process {At;t > 
0} is defined by 
i ß t 
i f t < r 0 
\ 0 
i f i > T 0 
where T0 = inf{t 
> 0 : Bt = 0} is the hitting time at 0. Then At is 
called the absorbed Brownian motion. 
▲ 
EXAMPLE 11.19 
The stochastic process {Ut;0 <t < I}, defined as 
Ut=Bt- 
tB1 , 
is called a Brownian bridge or the tied-down Brownian motion. 
The name Brownian bridge comes from the fact that it is tied down 
at both ends t = 0 and t = 1 since UQ — U\ = 0. In fact, the Brownian 
bridge {Ut;0 <t < 1} is characterized as being a Gaussian process with 
continuous sample paths and the covariance function 
Cov(Us,Ut) 
= s(l-t), 
0<s<t<l. 
If {Ut; 0 < t < 1} is a Brownian bridge, then it can be shown that the 
stochastic process 
Bt = (l+t)U_i_, 
t>0, 

478 
STOCHASTIC CALCULUS 
is the standard Brownian motion. 
▲ 
■ EXAMPLE 11.20 
Let {Bt; t > 0} be a Brownian motion. For μ G K and σ > 0, the process 
B? = μί + aBt, 
t > 0, 
is called a Brownian motion with drift μ. It is easy to check that Βμ is 
a Gaussian process with mean μί and covariance C(s,t) — 
o2min(s,t). 
▲ 
■ EXAMPLE 11.21 
Let {Bt\ t > 0} be a Brownian motion. For μ G K and σ > 0, the process 
Xt = exp (μί + aBt), 
t>0, 
is called a geometric Brownian motion. 
▲ 
This process has been used to describe stock price fluctuations (see next chap-
ter for more details). It should be noted that Xt is not a Gaussian process. 
Now we will give the mean and covariance for the geometric Brownian motion. 
Using the moment generating function of the normal random variable (4.2), 
we get: 
E{Xt) = εμίΕ (e"Bt) = e^E (eaViz\ = e^+^K 
(11.6) 
Similarly we obtain the covariance of the geometric Brownian motion for s < t, 
Cau(s, t) = e(»+h°2)(t+°) (e-2* _ i ) , 
(11.7) 
and the variance is given by: 
Var {Xt) = ε(2μ+σ2)1 
( β Λ - l ) . 
(11.8) 
The previous section discussed continuous-time martingales. Presently we 
will see a Brownian motion as an example of a continuous-time martingale. 
Theorem 11.7 Suppose that {Bt;t > 0} is a Brownian motion with respect 
to filtration 3;t, where 3 t := σ(Β„; s < t). Then 
1. {Bt} is a martingale, 
2. {Bf — i) is a martingale and 

BR0WNIAN MOTION 
4 7 9 
3. for σ € R, {exp(aBt — (σ2/2)ί)} is a martingale (called an exponential 
martingale). 
Proof: 
1. It is clear that, for every t > 0, Bt is adapted to the filtration (9t) t > 0 
and E(Bt) exists. For any s, t > 0 such that s < t: 
E(Bt\%a) 
= 
E([Bt-Ba 
+ 
Ba\Xa) 
= 
E(Bt-Ba\%) 
+ 
E(Ba\%) 
= 
E(Bt-Ba) 
+ Ba 
= 
Ba. 
2. 
E (B2 - B2
a | 3.) 
= 
E((Bt-Ba)2 
+ 
2Ba(Bt-Ba)\Za) 
= 
E ((Bt - Baf 
| %) + 2BaE ((Bt - B.) | 9f.) 
= 
t-s. 
Thus: 
E (B2 - t | 3.) = E (B2 - B2 + 
B2-(t-s)-s\%) 
= (t-a)+ 
B2
a-(t-s)-s 
= B2 
-s. 
3. The moment generating function of {Bt; t > 0} is given by: 
τηΒ(σ) 
= 
E(e"Bt) 
eaxf(x\0,t)dx 
f. 
I 
— oo 
°° 
1 
_xi 
e"x 
e 
*dx 
oo 
ν2πί 
oo 
[°° 
1 
_<-«»)3 , 
«i t 
= 
/ 
. 
e 
2' 
<Zx · e 2 
7-00 ν/^τΓ 
= 
e 2 \ 
'lid 
Therefore E (e<Tßt~^~<) = 1 and ε σ 5 ' _ τ ' is integrable. Now: 
E (e»B.+.-£<*+·) | 9ft) 
= 
£? (fBt 
■ e"(ß'+»-ß<) | St) e" £<*+·> 
= 
β σ β Έ Ce<7(ßt+·-'8')) e-4(*+ s) 
= 
εσΒ<Ε(εσΒ>)ε-^+*ϊ 
„cBt-gt 

480 
STOCHASTIC CALCULUS 
Note 11.13 Let {Xt; t > 0} be a stochastic process with respect to filtration 
(^>t)t>o- Then {Xt', t > 0} is a Brownian motion if and only if it satisfies the 
following conditions: 
1. XQ = 0 a.s. 
2. {Xt',t > 0} is a martingale with respect to filtration Qf 
3. {X? — t;t > 0} is a martingale with respect to filtration S t. 
4- With probability 1, the sample paths are continuous. 
The above result is known as Levy's characterization of a Brownian motion 
(see Mikosh, 1998). 
The possible realization of a sample path's structure and its properties play 
a crucial role and are the subject matter of deep study. Brownian motion has 
the continuity of the sample path by definition. Another important property 
is that it is nowhere diiferentiable with probability 1. The mathematical proof 
of this property is beyond the scope of this text. For rigorous mathematical 
proof, the reader may refer to Karatzas and Shreve (1991) or Breiman (1992). 
Now we will see an important and interesting property of a Brownian mo-
tion called quadratic variation. In the following, we define the notion of 
quadratic variation for a real-valued function. 
Definition 11.9 Let f(t) be a function defined on the interval [0, T]. The 
quadratic bounded variation of the function f is 
where τη is a partition of the interval [0,T], 
τη : 0 = t0 < ii < ■ · ■ < tn = T 
with: 
\\τη\\ = max (ti — fi_i) —t 0 as n —>· oo. 
\<i<n 
Theorem 11.8 The quadratic variation of the sample path of a Brownian 
motion over the interval [0, T] converges in mean square to T. 
Proof: Let τ η be a partition of the interval [0, T] : 
τη : 0 = t0 < tx < ■ ■ ■ < tn = T. 
Let 
n 
Qn:=Yi(Bti-Bti_1)2. 
i=l 

ITO CALCULUS 
481 
Then for each n we have: 
n 
E(Qn) = ΣΕ (Bti - 
B^f 
i = l 
n 
t = l 
= 
T. 
Also: 
Var(Qn) 
= 
< 
< 
We conclude that: 
lim E ((Qn - T)f) 
= 0. 
Thus we have proved that Qn converges to T in mean square. 
■ 
We can also prove Qn converges to T with probability 1. This proof can be 
found in Breiman (1992) and Karatzas and Shreve (1991) (see Chapter 8 for 
different types of convergence of random variables). 
As we have seen in this section, the sample path of Brownian motion is 
nowhere differentiable. 
Because the stochastic processes which are driven 
by Brownian motion are also not differentiable, we cannot apply classical 
calculus. In the following section we introduce the stochastic integral or Ito 
integral with respect to Brownian motion and its basic rules. We will do 
so using an intuitive approach which is based on classical calculus. For a 
mathematically rigorous approach on this integral see Karatzas and Shreve 
(1991) or Oksendal (2006). 
11.3 
ITO CALCULUS 
The stochastic calculus or Itö calculus was developed during the year 1940 
by Japanese mathematician K. Itö and is similar to the classical calculus of 
Newton which involves differentials and integrals of deterministic functions. 
In this section, we will study the stochastic integral of the process {Xt; t > 0} 
with respect to a Brownian motion, that is, we adequately define the following 
expression: 
It := I(Xt) = f XsdBs. 
(11.9) 
Jo 
n 
YyariBu-Bt^f 
t = l 
n 
3 ] T {U - ii_i) 2 
since E{B$) = 3i2 
t = l 
3T ||τη|| -»■ 0 where ||rn|| -»· 0. 

482 
STOCHASTIC CALCULUS 
In the classical calculus, the equations which consist of the expressions of the 
form dx are known as differential equations. If we replace the term dx by an 
expression of the form dXt, the equations are known as stochastic differential 
equations. Formally, a stochastic differential equation has the form 
dXt=ß(t,Xt)dt + a(t,Xt)dBt 
(11.10) 
where μ(χ,ί) and σ(χ, t) are given functions. Equation (11.10) can be written 
in integral form: 
Χι(ω)=Χ0{ω)+ 
ί μ(3,Χβ(ω))ά8+ 
ί σ{8,Χ3(ω))άΒ3(ω). 
(11.11) 
Jo 
Jo 
The first integral is a Riemann integral. How can we interpret the second 
integral? Initially we could take our inspiration from ordinary calculus in 
defining this integral as a limit of partial sums, such as 
n 
5>(*i.*ti)(£t 4 - Bti_r) 
t\ e \u-x -U] 
i=l 
provided the sum exists. Unlike the Riemann sums, the value of the sum 
here depends on the choice of the chosen points ij's. In the case of stochastic 
integrals, the key idea is to consider the Riemann sums where the integrand 
is evaluated at the left endpoints of the subintervals. That is: 
n 
^afo-uXu-JiBtt-Bt^) 
»=i 
Observing that the sum of random variables will be another random variable, 
the problem is to show that the limit of the above sum exists in some suitable 
sense. The mean square convergence (see Chapter 8 for the definition) is 
used to define the stochastic integral. We establish the family of stochastic 
processes for which the Itö integral can be defined. 
Definition 11.10 Let L2 be the set of all the stochastic processes {Xt',t > 0} 
such that: 
(a.) The process X = {Xt',t > 0} is progressively measurable with respect 
to the given filtration Ö = (^st)t>o- This means that, for every t, the 
mapping (s,u>) —> Xs(u) on every set [0,t] x Ω is measurable. 
(b.) E f I 
Xfdt) 
< oo for all T > 0. 
Now we give the definition of the Itö integral for any process {Xt; t > 0} € L2. 

ιτό CALCULUS 
483 
Definition 11.11 Let {Xf,t 
> 0} be a stochastic process in L2 and T > 0 
fixed. We define the stochastic integral or ltd integral of Xt with respect to 
Brownian motion Bt over the interval [0, T] as 
[ 
Xt(u)dBt(w)= 
lim YlXti.1{u){Btj{u)-Btj_1(U)) 
(U-12) 
Jxi 
j=l 
where τη is a partition of the interval [0, T] such that 
τη : 0 = i 0 < h < ■ ■ ■ < tn = T 
with: 
Notation: 
||rn|| = max (h — ii_i) -4 0 as n —»· oo. 
\<i<n 
IT(X) = I Xt{u)dBt{u,) . 
Jo 
EXAMPLE 11.22 
Consider the stochastic integral 
IT(B) = [ 
Bt{w)dBt{w) 
Jo 
where Bt is a Brownian motion. Let 0 = to <h <t2 < ■ ■ ■ <tn = T be 
a partition of the interval [0, T]. Prom the definition of the stochastic 
integral, we have: 
f Bt(U)dBt(U) = J^X**-, (B*< ~ B"-) ■ 
Jo 
n 
°° i = 1 
By the use of the identity 
a{b-a) = 
\{b2-a2)-\{b-af 
we get: 
jT BtMdBtiw) = \imJ2 [\ (Bl - Bl_) - \ (Bti - BUJ 
\B2
T - \T. 
A 
2 
T 
2 

484 
STOCHASTIC CALCULUS 
The stochastic integral (11.12) for all T > 0 satisfies the following properties: 
1. 
Zero mean: 
E Of 
XtdBt 
0. 
2. Ito isometry: 
E (C
x'
dB)]'
E{£
x'
dt)-
3. Martingale: For t <T, 
E f 
Jo 
XadB3 I 3 , 
/ ' 
Jo 
XadB,,. 
4. Linearity: For {Xt;t >0},{Yt;t>0} 
£ L2, 
f 
(aXt + ßYt) dBt = a f 
XtdBt 
+ β ί 
YtdBt. 
Jo 
Jo 
Jo 
Proof: We now prove only the martingale property of the Itö integral. For 
proofs of the remaining properties, the reader may refer to Karatzas and 
Shreve (1991). Consider 
EU 
XsdBs\%\ 
= EU 
X3dB9+ 
ί 
XsdBs\%) 
= E(( 
XsdBs\%}+EU 
= 
ί XsdBs + EU 
-I 
XsdBs + E\ 
/ 
XsdBs 
XsdBa I S t 
XsdBs 
where the above equality follows by the zero mean property. 
■ EXAMPLE 11.23 
Let Xt — \ eBtdBt 
be an Ito integral. We have E (Xt) = 0 by property 
Jo 
(11.22). The variance is calculated by use of the mgf of Brownian 
motion and Itö isometry. We have: 
E I 
t 
-.2N 
eB°dB, 
f 
E (e2B°) ds = f e2sds = J (e2t - l ) . 
Jo 
Jo 
2 

ITÖ CALCULUS 
485 
In the context of ordinary calculus, the Ito formula is also known as the 
change of variable or chain rule for the stochastic calculus. 
Theorem 11.9 (Ito's Formula) Let f : R -¥ R be a twice-differentiable 
function and let B = {Bt;t > 0} be a Brownian motion that starts at XQ, 
that is, Bo = XQ. Then 
f (Bt) = / (x0) + I f (Ba) dBa + \J f" (Ba) ds 
or in the differential form: 
df(Bt) = f'(Bt)dBt 
+ 
\f"{Bt)dt. 
Proof: Fix t > 0. Let τη : 0 = to < t\ < ■ ■ · < tn = t be & partition of [0, t]. 
By Taylor's theorem, we have: 
f(Bt)-f(B0) 
= E[m<)-/(*««-i)] 
i=l 
+ 
1-f"(Btj_l)(Btj-Btj_1)2 + ... . 
Taking the limit n —► oo when Δί —► 0, we find that the first sum of the right-
hand side converges to the Ito integral and the second sum on the right-hand 
side converges to ^ j*0 f"(Bs)ds 
because of mean square convergence. We get: 
/ {Bt) - f (B0) = J f'{Bs)dBs +l-J 
f"(Bs)ds. 
Thus: 
f{Bt) = /(ar0) + J f'{B8)dBs + \ j 
f"(Bs)ds 
■ EXAMPLE 11.24 
Let f (x) = x2 and B = {Bt;t > 0} be a standard Brownian motion. 
The Ito formula establishes that: 
B2 = f 2BadB„ + \ ( 2ds. 
Jo 
* Jo 
That is: 
J BadB8 = \B2 - it. ▲ 

486 
STOCHASTIC CALCULUS 
EXAMPLE 11.25 
Let f (x) = x3 and B = {Bt;t > 0} be a standard Brownian motion. 
The Ito formula establishes that: 
Bf = I ZBidBs + 3 / 
Bsds. 
That is: 
33 = f 3B2dBs + 3 f . 
Jo 
Jo 
J B2
adBs = \ B
3 - J Bads. A 
■ EXAMPLE 11.26 
Let ßn(t) = E(B?) for a Brownian motion {Bt;t > 0} with B0 = 0. 
Prove that 
1 
f* 
ßn(t) = ^n(n - 1) / ßn-2(s)ds, 
n > 2 , 
^ 
Jo 
and hence find E(Bf) and E{Bf). 
Solution. By the Itö's formula, we have: 
B? = nj 
B^dB, 
+ l-n{n -I) J 
B^ds 
Taking expectation we have: 
1 
/"' 
ßn(t) = -n(n - 1) y 
ßn-2(s)ds 
Since ß2(t) = t, we get: 
1 
/"' 
ß4(t) 
= 
- ■ 4-3 · 
sds = 3t2 
2 
Jo 
1 
/"' 
ß6(t) 
= 
- ■ 6 · 5 · / 3s2 ds = 15i3. 
A 
2 
Jo 
Definition 11.12 For a fixed T > 0, the stochastic process {Xt;0 
<t<T} 
is called an Ito process if it has the form 
Xt = X0+ 
[ Ysds + [ ZsdBs, 
0<t<T, 
(11.13) 
Jo 
Jo 
where Xo is ^Q-measurable and the processes Yt and Zt are SSt-adapted such 
that, for all t > 0, β(|1(|) < oo and E(\Zt\2) 
< oo. An Itö process has the 
differential form 
dXt = Ytdt + ZtdBt. 
(11.14) 

ITÖ CALCULUS 
487 
We now give the Ito formula for an Ito process. 
Theorem 11.10 (Ito's Formula for the General Case) Let {Xt;t > 0} 
be an Ito process given in (11.14)- Suppose that f (t, x) is a twice continuously 
differentiable function with respect to x and t. Then f(t,Xt) 
is abo an Itö 
process and: 
f(t,Xt) 
= f(0,Xo) + 
JtZs
dHs
d'x
Xs)dBs 
[<\θί(8,χ.) 
df(s,xs) , i„2a2/(*,xa) 
J0 [ 
dt 
+ " 
dx 
+2Z° 
dx* 
ds. 
Proof: See Oksendal (2006). 
Note 11.14 We introduce the notation 
(dXt)2 = (Zt
2) dt 
which is computed using the following multiplication rules: 
1 · 
| dt 
| dBt 
\dt 
0 
1 o 
dBt | 
o I 
dt | 
The Ito formula then can be expressed in the following form: 
df(t,Xt) = 
Zt
d-l^^dBt 
+ df(t,xt) , „df(t,xt) , i„2a2/(t,xt) 
+ Yt"-^E^ + -zt 
dt 
τ 
dx 
2 * 
dx2 
Note 11.15 Ito's formula can also be expressed in differentials as: 
dt. 
Μ(+ΥΛ 
d/(*>*t),, 
df(t,Xt) 
ld2f(t,Xt) 
a 
df (t, Xt) = —g^-dt 
+ — ^ d X t 
+ - 
9χ2 
(dXt) 
EXAMPLE 11.27 
Let Xt = t and / (t, x) = g (x) be a twice-differentiable function. It is 
easy to see that: 
Xt = 0 + / ds+ I 
0dBs. 
Jo 
Jo 
Thus, applying Ito's formula, we get: 
g(t)-g(0)= 
f 
g'(s)ds. 
Jo 

488 
STOCHASTIC CALCULUS 
That is, the fundamental theorem of calculus is a particular case of Ito's 
formula. 
A 
EXAMPLE 11.28 
Let Xt = h (t) where h is a, differentiate function and let / (t, x) = 
g (x) be a twice-differentiable function. It is easy to check that: 
Xt = h(0)+ 
( h,(s)ds+ 
I 
0dBa. 
Jo 
Jo 
Applying Ito's formula, we obtain : 
g(h(t))-g(h(0))= 
f 
h'(s)g'(h(s))ds. 
Jo 
In this case also, the substitution theorem of calculus is a particular case 
of Ito's formula. 
▲ 
EXAMPLE 11.29 
Let {Bt; t > 0} be a Brownian motion and consider the following differ-
ential equation: 
dYt = ßYtdt + oYtdBt. 
(11.15) 
Let Zt = log(Yi). Then, by Ito's formula, we have: 
1 
Thus: 
dZt= 
[μ- 
^σ2 ) dt + adBt. 
dlog(Yt) = ( μ - ^σ 2 ) dt + adBt . 
Integrating we get 
log(yt) - log(r0) = (μ - \σ2\ 
t + aBt 
so that the solution of equation (11.15) is: 
Yt = Y0 exp ((μ- 
^σΛ + σβλ . 
▲ 

ITÖ CALCULUS 
489 
EXAMPLE 11.30 
Consider the Langevin equation 
dXt = -ßXtdt 
+ adBt 
where a i l and ß > 0. The process {Xt\ t > 0} with Xo = xo can be 
written as: 
Xt=xo 
+ aBt - ß / 
Xsds. 
Jo 
Let / (t, x) = eßtx. Applying Ito's formula, we get: 
d(eßtXt) 
= ßeßtXtdt 
+ eßtdXt 
= 
ßeßtXtdt 
+ eßt (-ßXtdt 
+ adBt) 
= 
aeßtdBt. 
Integration of the above equation gives for s < t: 
Xt = e-ßtX0 + af 
e-W-°UBa. 
Jo 
The solution of the Langevin equation with initial condition Xo = %o is 
called an Ornstein-Uhlenbeck process. A 
We complete this chapter with the Ito formula for functions of two or more 
variables. 
Multidimensional ltd Formula 
We now give the Ito formula for functions of two variables. Consider a two-
dimensional process 
dXt = ßtdt + atdB^ 
(11.16) 
dYt = atdt + ßtdB™ 
(11.17) 
where {B\ '\t > 0} and {B\ ';t > 0} are two Brownian motions with their 
covariances given by 
Cav(B^,B^)=E(B^.B^)=pt 
(11.18) 
where p is the correlation coefficient of the two Brownian motions. Let 
g(t,x,y) 
be a twice-differentiable function and let Zt = g(t,Xt,Yt). 
Then 
Zt is also an Ito process and satisfies: 
dZt = ^(t, Xt, Yt)dt + | ^ ( i , Xu Yt)dXt + |^(f, Xu Yt)dYt 
+l^(t,XuYt)(dXt)2 
+ 
^(t,Xt,Yt)(dYt)2 
2dx2X ' " I M w 2dy 
+jj^{t,Xt,Yt)(dXt){dYt). 

490 
STOCHASTIC CALCULUS 
For the proof, the reader may refer to Karatzas and Shreve (1991). 
Note 11.16 For any two ltd processes {Xt]t > 0} and {Yt\t > 0}, we have 
the following product rule for the differention: 
d(XtYt) 
= XtdYt + YtdXt + (dXt)(dYt). 
(11.19) 
T h e o r e m l l . i l Let Xt and Yt be two Ito processes suchthat E I / 
Xfdt I < 
oo and E I / 
Y?dt I < oo. Then: 
T 
> 
XtYtdt 
E{[
x'
dB-[
Y'
iB)'
E(L 
Proof: Let h= 
I 
XtdBt 
and J2 = / 
YtdBt. 
Jo 
Jo 
By using the identity 
hh = \{{h + h? 
-il-il) 
and taking expectation, we get: 
E (hl2) = \ (E (h + hf 
- E{ll) - E{I2
2j) . 
By use of Itö's isometry property we get the desired result. 
■ EXAMPLE 11.31 
Suppose that Xt = tBt. Use of product rule (11.19) gives us: 
dXt = tdBt + Btdt. 
A 
■ EXAMPLE 11.32 
Suppose that Xt = tBt and Yt satisfies the stochastic differential equa-
tion 
dYt = ^Ytdt + YtdBu 
Y0 = 1. 
We know that Yt = eBt is a geometric Brownian motion. Then the use 
of product rule (1149) gives us: 
d (XtYt) = XtdYt + YtdXt + tYtdt. 

EXERCISES 
491 
This is because: 
(dXt){dYt) 
= (tdflt + Btdt) (\Ytdt 
+ YtdBA 
= tYtdt. 
A 
EXAMPLE 11.33 
Suppose that 
dXt = adBt + ßdWt 
(11.20) 
with Xo=0,a,ßeM. 
and {Bt; t > 0} and {Wt; t > 0} are two Brownian 
motions. Let f(t,x) 
= x2. Then, from Itö's formula, 
dX2 = (a2 + ß2)dt + 2aXtdBt 
+ 2ßXtdWt 
(11.21) 
with X$ = 0. Note that Xt = aBt + ßWt and: 
I 
*άΧ2
8=Χ2-Χ2 
= Χ2. 
(11.22) 
o 
From equations (11.21) and (11.22), we get: 
(aBt + ßWtf 
= (a2 + ß2)t + 2 / aXsdBs 
+ 2β ί 
XsdWs. 
Jo 
Jo 
Using the relation 
rt 
B2 
t 
B,dBs — — 
, 
we have the following interesting result: 
Jo 
2BtWt = f BsdWs + f WsdBa. 
▲ 
Jo 
Jo 
Without recourse to measure theory, we have presented various tools necessary 
in dealing with financial models with the use of stochastic calculus. This 
chapter does not make a full-fledged analysis and is intended as a motivation 
for the further study. For a more rigorous treatment, the reader may refer 
to Grimmett and Stirzaker (2001), Oksendal (2005), Mikosch (2002), Shreve 
(2004), and Karatzas and Shreve (1991). 
EXERCISES 
11.1 
In Example 11.11 verify 

492 
STOCHASTIC CALCULUS 
and 
^n(2)= ( £ & - £ & ) ) ) 
-ηναν(ξ1). 
11.2 
Let {Xn', n > 0} be a martingale (supermartingale) with respect to the 
filtration (9 n) n > 0. Prove that 
E (Xn+k I 9n) = Xn 
(< for supermantingale) 
for all k > 0. 
11.3 
Let {Xn', n > 0} be a martingale (supermartingale) with respect to the 
filtration (3 n) n > 0. Prove that: 
E(Xn) 
= E(Xk) 
(< for supermantingale) 
for all 0 < k < n 
11.4 
Let {Xn', n > 0} be a martingale with respect to the filtration (3fn)n>o 
and assume / to be a convex function. Prove that {f(Xn);n 
> 0} is a sub-
martingale with respect to the filtration (9fn)n>0. 
11.5 
If {Xt; t > 0} is a martingale with respect to (3?t)t>o ani^ if Λ : R —> R 
is a convex function such that E(\h(Xt)\) 
< oo for all i > 0, show that 
{h (Xt); t > 0} is a submartingale with respect to (3?t)t>0-
11.6 
Let ξι,ξ2,· ■ · be i.i.d. random variables, such that P (ξη — 1) = p and 
P (ξη = —1) = 1 — p for some p in (0,1). Prove that {Mn; n > 0} with 
M0 
: 
= 1 
- ■ -(?)* 
is a martingale with respect to (3fn)n>o> where 9o — {0)Ω} and 3 n = 
σ(ξι,ξ2,··· ,ξη) for n > 1. 
11.7 
Let Xi,X2, ■■ ■ be a sequence of i.i.d. random variables satisfying 
Let M0 := 0, Mn := ΧγΧ2 ■ ■ ■ Xn and 3 n = σ (Xi,X2, · · · ,Xn)· Is {Mn; n > 0} 
a martingale with respect to (Sn)n>o? Explain. 
11.8 
Let X\, X2, · ·■ be a sequence of random variables such that E (Xn) = 
0 for all n = 1,2, · ■ · and suppose E (eXn) exists for all n = 1,2, · · · . 
a) Is the sequence {Yn;n > 1} with Yn := exp ί ^Χ, 
I a submartingale 
with respect to (ön)n>i, where S n = σ(Χι,Χ2,· 
■ ■ ,Xn) 
for n > 1? 
Explain. 

EXERCISES 
493 
b) Find (if possible) constants an such that the sequence {Zn;n > 1} with 
Zn := exp I 5^Xj — a„ 1 is a martingale with respect to (3n)n>i> where 
3fn = σ (Χι,Χ2, ■·■ , Xn) for n > 1. 
11.9 
(Doob's descomposition) Let {Yn;n > 0} be a submartingale with 
respect to the filtration (3n)n>o· Show that 
n 
Mn = Y0 + Σ (Yn - E (Yn I 9n_0) 
fc=l 
for n = 1,2, · · · is a martingale with respect to (3fn)n>o a n (i * n at the sequence 
-4n := Yn — Mn, n = 1,2, · · ·, satisfies 0 < Αχ < A% < · · ■. Is An measurable 
with respect to 3 n_i? Explain. 
11.10 
Let X\, X2, · ■ · be a sequence of independent random variables such 
that E (Xn) exists for all n = 1,2,··· and suppose Sn := X\ -\ 
\-Xn, 
n = 
1,2,···. Is {Sn',n > 1} a submartingale? If it is so, then determine the 
process {An; n > 1} as in the exercise above. 
11.11 
Let {Xn\ n> 1} be a sequence of random variables adapted to the fil-
tration (5η)η>ι· Suppose that τ\ is the time at which the process {Xn; n > 1} 
reaches for the first time the set A and let: 
T2 := min {η>τ\: 
Χη € ^4} . 
Show that T2 is a stopping time. What does τ^ represent? 
11.12 
Let r be a stopping time with respect to the filtration (9 η) η>ι 
a nd 
k be a fixed positive integer. Show that the following random variabTes are 
stopping times: r Λ k, τ V k, τ + k. 
11.13 
Let {Xn;n > 1} be the independent random variables with ß[Xn] = 
0 and Var(Xn) 
= σ2 for all n > 1. Set M0 = 0 and Mn = S% — ησ2, where 
Sn = X\ + X2 + ■ ■ ■ + Xn- Is {Mn; n > 1} a martingale with respect to the 
sequence Xn? 
11.14 
Let {Nt;t > 0} be a Poisson process with rate λ and fäut > 0} is 
a filtration associated with iVt. Write down the conditional distribution of 
Nt+s — Nt given 3 t , where s > 0, and use your answer to find E\9Nt-· 
\ 3fe]. 
11.15 
(Lawler, 1996) Consider the simple symmetric random walk model 
Yn = X\ + X2 + ... + Xn with ΥΌ = 0, where the steps X^s are independent 
and identically distributed with P[Xk = 1] = 1/2 and P[Xk = -1] = 1/2 for 
all A;. Let T := inf{n 
: Yn = —1} denote the hitting time of —1. We know 
that P[T < 00] = 1. Show that if s > 0, then Mn :— j^ypr with M0 = 1 is a 
martingale, where <fi(s) := (s2 + l)/2s. 

494 
STOCHASTIC CALCULUS 
11.16 
Let Xi, X21 · ■ · be independent random variables such that 
an 
with probability —n~2 
Xn = \ 
0 
with probability 1 — n~2 
—an 
with probability 
„n2, 
where a\ = 2 and an = ΣΓ=α ai- Is ^η = ΣΓ=ι -^» a martingale? 
11.17 
Let Bt be a Brownian motion. Find E {{Bt - 
Bs)4). 
11.18 
Let {Bt;t > 0} and {B't;t > 0} be two independent Brownian mo-
tions. Show that 
is also a Brownian motion. Find the correlation between Bt and Xt. 
11.19 
Let Bt be a Brownian motion. Find the distribution of B\ + Bo + 
B3 + B4-
11.20 
Let {Bt;t > 0} be a Brownian motion. Show that e~atBe2ct 
is a 
Gaussian process. Find its mean and covariance functions. 
11.21 
Let {Bt; t > 0} be a Brownian motion. Find the distribution for the 
integral 
/ 
sdBs. 
Jo 
11.22 
St has the following differential equations: 
dSt = ßStdt + aStdBt. 
Find the equation for the process Yt = St
_1. 
11.23 
Use the Ito formula to write down the stochastic differential equa-
tions for the following equations. {Bt; t > 0} is a Brownian motion process. 
a) Xt = Bf. 
b) Yt = tBt. 
c) Zt = exp(ci + aBt). 
11.24 
Let: 
It(B) 
= [ eB'dBt 
. 
Jo 
Find E(It{B)) 
and 
E(It(B)2). 

EXERCISES 
495 
11.25 
Evaluate the integral 
rt 
,. 
^Bl"B-
Jo 1 + 1 
11.26 
Evaluate the integral 
Jo 
11.27 
Suppose that Xt satisfies: 
Xt = 2 / (3s + es)ds + / cos(s)dBs . 
Jo 
Jo 
Let Yt = f(t, Xt) = (2t + 3)Xt + 4t2. Find Yt. 
11.28 
Use Ito's formula to show that: 
e s'-l= ftLB'da+ 
f<P'dB„. 
Jo 2 
Jo 
11.29 
Consider the stochastic differential equation 
dXt = 
--dt+-dBt 
o 
£ 
with Xo = 0. 
a) Find Xt. 
b) Let Zt = eXt. Find the stochastic differential equation for Zt using Ito's 
formula 
11.30 
Find the solution of the stochastic differential equation 
dZt = Ztdt + 2ZtdBt 
. 
11.31 
Solve the following stochastic differential equation for the spot rate 
of interest: 
drt = (b - rt)dt + adBt 
where rt is an interest rate, fcsi and σ > 0. 
11.32 
Suppose that Xt follows the process dXt = 0MXtdt 
+ 
0.25XtdBt. 
Using Ito's lemma find the equation for process Yt — logXt Zt = Xf-

CHAPTER 12 
INTRODUCTION TO MATHEMATICAL 
FINANCE 
Mathematical finance is the study of financial markets and is one of the rapidly 
growing subjects in applied mathematics. This is due to the fact that in 
recent years mathematical finance has become an indispensable tool for risk 
managers and investors. The fundamental problem in the mathematics of 
financial derivatives is the pricing and hedging. During the years 1950-1960, 
the research focus was basically on the resolution of problems in economics and 
statistics. However, many researchers were concerned with the problem that 
was initiated in the early 20th century by Bachelier, the father of modern 
mathematical finance: what is the fair price for an option on a particular 
stock? The answer to this question was given in 1973 by researchers Fisher 
Black and Myron Scholes. They argued that a rational investor does not 
wait passively until the expiry of the contract but, in contrast, invests in a 
portfolio consisting of a risk-free asset and a risky stock, so that the value 
of this portfolio will be equal to the value of the option. Therefore, the fair 
price of the option is the present value of the portfolio. To obtain this value 
they generated a partial differential equation whose solution is known as the 
"Black-Scholes formula". 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
497 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

498 
INTRODUCTION TO MATHEMATICAL FINANCE 
The initial focus on the valuations of financial derivatives was to describe 
the appropriate movements of stock prices and solving partial differential 
equations. However, another purely probabilistic approach was developed by 
Cox et al. (1979) among others, who considered the discrete case. Harrison 
and Kreps (1979) observed that for a market model to be sensible from the 
economic point of view, the discounted stock price process should be a mar-
tingale under an appropriate change of measure. This viewpoint was further 
expounded by Harrison and Pliska (1981) who observed that by making use 
of the Itö representation theorem, the present value of the price of an option 
can be characterized by a stochastic integral and the discounted price of the 
stock can be transformed into a martingale by a suitable change of measure. 
This approach is also known as the martingale pricing method or risk-neutral 
valuation. The objective of this chapter is to introduce risk-neutral valuation 
within the framework of financial derivatives. We will keep this chapter as 
simple as possible to present the basic modeling approach for the financial 
derivatives. In the next section we review the technical terminology used in 
the financial derivatives. Interested reader may refer to Hull (2009) for more 
details. 
12.1 
FINANCIAL DERIVATIVES 
Definition 12.1 A financial derivative, or contingent claim, is a financial 
contract whose value at expiration date T is determined exactly by the price 
of the underlying financial asset at time T. 
The financial derivatives or financial securities are financial contracts whose 
value is derived from some underlying assets. The assets could be stocks, cur-
rencies, equity indices, bonds, interest rates, exchange rates, and commodi-
ties. There are different types of financial markets, namely stock markets, 
bond markets, currency markets, and commodity markets. In general, fi-
nancial derivatives can be grouped into three groups: options, forwards, and 
futures. The options constitute an important building block for pricing finan-
cial derivatives. Now we give a formal definition for an option. 
Definition 12.2 An option is a contract that gives the holder the right but 
not the obligation to undertake a transaction at a specified price at a future 
date. 
Note 12.1 A specific or prescribed price is called a strike price, denoted by 
K. A specific or a future time is called an expiry date, denoted by T. 
There are two main types of option contracts: call options and put options. 
1. A call option gives one the right to buy an asset at a specific price within 
a specific time period. 

FINANCIAL DERIVATIVES 
499 
2. A put option gives the right to sell an asset at a specific price within a 
specific time period. 
A call option is the right to buy (not an obligation). When a call is ex-
ercised, the buyer pays the writer (the other party of the contract, who does 
have a potential obligation that he must sell the asset if the holder chooses to 
buy) the strike price and gives up the call in exchange for the asset. 
The contract for a call (put) option specifies: 
1. The company whose shares are to be bought (sold) 
2. The number of shares that can be bought (sold) 
3. The purchase (selling) price 
4. The date when the right to buy (sell) expires 
Based on how they are exercised, options can be divided into two types: 
1. European option that can be exercised only at the time of expiry of the 
contract. 
2. An American option that can be exercised at any time up to the expiry 
date. 
The call or put option described above is also called a simple or vanilla 
option. An option which is not a vanilla option is called an exotic option. 
The well-known exotic option is a path-dependent option where the payoff 
depends on the past and present values of an underlying asset. The following 
exotic options are widely used. 
1. An Asian option is a type of option whose payoff function is determined 
by the average price of an underlying asset over some period of time 
before expiry. 
2. A barrier option is a type of option whose payoff depends on whether or 
not the underlying asset has reached or exceeded a predetermined price 
3. A lookback option is an option whose payoff is determined by the maxi-
mum or minimum of the underlying asset. 
4. A perpetual option has no expiry date (that is, it has an infinite time 
horizon). 
In the following sections some financial terms are used. The practical 
meaning of these terms are as follows: 
1. Intrinsic value: At time t <T, the intrinsic value of a call option with 
strike price K is equal to max(St — K, 0). Similarly for a put option, 
the intrinsic value is max(K — St,0). 

500 
INTRODUCTION TO MATHEMATICAL FINANCE 
2. Time value: The time value of an option is the difference between the 
price of the option and its intrinsic value. That is, for a European call 
option, the time value is C(St,t) 
= max(5t — K,0). 
3. Long position: A party assumes a long position by agreeing to buy an 
asset for the strike price K at expiry date T because he anticipates the 
price to go up. That is, one can have positive amounts of an asset by 
buying assets that one does own. 
4. Short position: The opposite of assuming a long position in which one 
party agrees to sell the asset because he anticipates the price to decline. 
That is, one can have negative amounts of an asset by selling assets that 
one does not own. 
5. Arbitrage: This refers to buying an asset at one place and selling it for 
a profit at another place without taking any risk. We will give a precise 
mathematical definition in the next section. 
6. Hedging: This is the concept of elimination of risk by taking opposite 
positions in two assets whose prices are correlated. 
Forwards and Futures 
Forwards and futures are both contracts to deliver a specific asset at an agreed 
date in the future at a fixed price. Unlike an option, there is no choice involved 
as to whether the contract is completed. 
Definition 12.3 A forward contract is an agreement to buy or sell an asset 
S at certain future date T for a certain price K. 
A forward contract is usually between large and sophisticated financial agents 
(banks, institutional investors, large corporations and brokerage firms) and is 
not traded in an exchange. The agent who agrees to buy the underlying asset 
is said to have a long position while the other agent assumes a short position. 
The settlement date is called delivery date and the specified price is referred 
to as the delivery price. 
Two persons or parties can enter into a forward contract to buy or sell 
Colombian coffee at any time with any delivery date and delivery price they 
choose. When a forward contract is created at time 0 with delivery date T 
for delivery price K, this delivery price is also referred as the forward price 
at time 0 for delivery date T. At the time t between 0 and T, it would be 
possible to create a new forward contract with the same delivery date T. The 
delivery price of this new contract is also called the forward price at the time 
t with delivery date T and might not be the same as the delivery price K 
which was the delivery price with delivery date T on the contract that was 
set up at time t = 0. 

FINANCIAL DERIVATIVES 
5 0 1 
The disadvantage of forwards is that they are hardly traded at exchanges, 
the reason being the individual, nonstandardized character of the contract, 
and that they are exposed to the risk of default by their counter parties. 
Therefore, there are significant costs in finding a partner for the contract. 
These problems lead to standardization with the aim of making trading at an 
exchange possible. 
A futures contract, although like a forward contract, differs from it as 
shown below. 
1. A forward is an over-the-counter agreement between two individuals. In 
contrast, a future is a trade organized by an exchange. 
2. A forward is settled on the delivery date. That is, there is a single 
payment made when the contract is delivered. The profit/loss on a 
future is settled on a daily basis to avoid default. The exchange acts 
as an intermediary between the long and short parties and insists on 
maintained margins. 
A basket of forwards and/or options with different delivery or expiry dates 
is called a swap, which is a more complex financial derivative. A swap is 
an agreement where two parties undertake to exchange, at known dates in 
the future, various financial assets (or cash flows) according to a prearranged 
formula that depends on the value of one or more underlying assets. The two 
commonly used swaps are interest rate swaps and currency swaps. 
The focus of this chapter will be on the pricing and hedging of options. 
We will restrict ourselves to European and American call and put options. 
The option buyer has the right but not the obligation, which puts him in a 
privileged position. The option seller, that is, the option writer, provides the 
privilege which the buyer holds. We have seen two types of options, namely, 
option to buy, a call option, and option to sell, a put option. Using asymmetry 
in rights, there are four possibilities: 
1. Buy an option to buy, i.e., buy call 
2. Buy an option to sell, i.e., buy put 
3. Sell an option to buy, i.e., write call 
4. Sell an option to sell, i.e., write put 
The payoff, or the value, of an option depends on the value of an underlying 
asset at a future time T. Consider a European call option with strike price 
K. Let ST be the price of the underlying asset at the time of expiry T. If 
ST < K, that is the option is expiring out-of-money, then the holder can 
buy the asset in the market at ST, a cost less than the strike price K. The 
terminal payoff of the long position in a European call option is 0. But if, 
at time T, ST > K, that is the option expires in-the-money, then the holder 
of the call option will choose to exercise the option. The holder can buy the 

502 
INTRODUCTION TO MATHEMATICAL FINANCE 
Payoff 
Payoff 
Call Option 
Payoff 
Payoff 
Put Option 
Figure 12.1 
Payoff diagram of call and put options 
asset at a price K and sell it at a higher price ST- The net profit will be 
ST — K. Both cases can be summarized mathematically as: 
C{St,T) 
= max(ST - K,0) 
or C(St,T) 
= (ST - 
K)+, 
where (x)+ = max(a;,0). An argument similar to the value of a call option 
leads to the payoff for a put option at expiry date T and is given by: 
P{St,T) 
= max{K-ST,0) 
or P(St,T) 
= (K - ST)+■ 
A chart of the profits and losses for a particular option is called a payoff 
diagram and is a plot of the expected profit or loss against the price of the 
underlying asset on the same future date. The payoff diagrams for call and 
put options are given in Figure 12.1. 
For European options, there is a simple theoretical relationship between the 
prices of the corresponding call and put options. This important relationship 
is known as put-call parity and may be expressed as: 
C(St,T) 
-St 
= P(SUT) 
- 
tfe-r<T-*>, 

FINANCIAL DERIVATIVES 
503 
where K is the strike price of the underlying stock S, T is the expiry date 
and r is the constant interest rate; sometimes we use C = C(St,T) 
and 
P = 
P(SUT) 
■ EXAMPLE 12.1 
Suppose that a share of a certain stock is worth $100 today for a strike 
price of $110 with one year expiry date. The difference between the costs 
of put and call options is $5. The interest rate is calculated by using 
put-call parity. We have: 
S + P-C 
= 
Ke~rt 
100 + 5 = 
110e_r 
r 
= 
0.0465 = 4.65%. 
A 
The main assumptions of the options are: 
1. There are some market participants. 
2. There are no transaction costs. 
3. All trading profits (net of trading losses) are subject to the same tax 
rate. 
4. Borrowing and lending at the risk-free rate are possible. 
We now establish an interesting result between European and American call 
options. 
Theorem 12.1 With a nonnegative interest rate r, it is not optimal to ex-
ercise early an American call option on a non-dividend paying asset with the 
same strike price and expiry date. 
Proof: Suppose that it is optimal to exercise the American call option before 
expiry date. 
Let CA and CE be the value of the European and American options, re-
spectively. It is easily seen that the payoff value of the European call options: 
CE = S - 
Ke-rV-*\ 
We know that: 
CA > CE 
This is because an American option has the benefits of having the right of 
early exercise. Also, we have: 
CA > S - 
Ke-rV-'\ 

504 
INTRODUCTION TO MATHEMATICAL FINANCE 
Since r > 0, it follows that CA > S — K. An American option will always 
be worth at least its payoff S — K. However, the previous equation shows 
that CA > S — K. Thus, we have a contradiction based on the assumption 
that it is optimal to exercise early. Hence the value of the American option 
must be equal to the value of the European call option. However, it can be 
advantageous to exercise an American put option on a non-dividend paying 
asset. 
■ 
In the continuation we present a discrete-time model and a continuous-time 
model for the valuation of financial derivatives. We closely follow the approach 
presented by Lamberton and Lapeyre (1996), Bingham and Kiesel (2004), and 
Williams (2006). 
12.2 
DISCRETE-TIME MODELS 
In this section we give a brief introduction to discrete-time models of a finite 
market, Λ4, that is, models with a finite number of trading dates in which 
all asset prices take a finite number of values. The finite market model is 
considered on a finite probability space (Ω, 9, P), where Ω = {u>i, o>2, · · · , ω„}, 
3f is a σ-algebra consisting of all subsets of Ω and P is a probability measure on 
(Ω, 3;) such that P ({ω}) > 0, Vw € Ω. We assume that there is a finite number 
of trading dates t = 0,1,2, · · · , N where N < co at which trades occur. The 
time N is the terminal date or maturity of the financial contract considered. 
We now use a finite filtration (^tn)n>o = {^ni^ = 0, · · · ,N} to model the 
information flow over time. Further, 9o = {0, Ω} and 3ijv = S n = P{ty-
We assume that the market consists of k + 1 assets whose prices at time 
n are given by the nonnegative random variables Rn, Sn, ■ ■ ■ ,S„ which are 
measurable with respect to (3fn)^>0- We assume that there exists one risk-
free asset on the money market, known as a bond, R, and A; risky assets or 
stocks on the financial market, 5 = (5 1,5 2, · · · , Sh). 
Definition 12.4 A numeraire is a price process {Xn\n 
= 0, · · · ,N} which 
is strictly positive for all n = 0,1, · · · , N. 
For example, suppose that RQ = 1. If the return of a bond over a period is a 
constant r, then Rn = (1 +r)n. 
The coefficient -—- = (1 + r)~n is interpreted 
Rn 
as the discount factor. For i = 1,2, · · · , k, we define: 
Sl = §^ 
forn 
= 0,l,---,JV 
tin 
Then Sn — (S^,S%,·-· 
, S£ 1 is the vector of discounted stock prices at time 
n. The investors are interested in creating a dynamic portfolio which involves 
trading strategies and a portfolio process. Hence we now give the definition 
of the trading strategies and portfolio or wealth processes. 

DISCRETE-TIME MODELS 
505 
Definition 12.5 A trading strategy in the finite market model is a collection 
of k + 1 random variables φ = {φ^,φ^,· 
■ · ,φ„) where ψι
η is a real-valued 
3in_i measurable random variable for i = 0,1, · · · , k. We interpret ψι
η as the 
number of shares of asset i to be held over the time (n — l,n]. 
■ EXAMPLE 12.2 
For a financial market model with a single bond and a single stock, the 
trading strategy is a collection of pairs of random variables 
φ = {(αη,βη);η 
= 0,1,--- 
,Ν}. 
The random variable an represents the number of shares of stock to 
be held over the time interval (n — l,n], and the random variable βη 
represents the number of units of the bond to be held over the same 
time interval. Here both an and βη are 3 n_i measurable and hence are 
called predictable random variables. 
▲ 
Definition 12.6 (Value of Portfolio or Wealth Process) The value of the 
portfolio or wealth process νη(φ) of a trading strategy ψ at time n equals: 
k 
νη = νη(φ)=φ°ηΙΙη + 
ΣφΆ 
The discounted values are given by Vn = -g-Vn(<p). 
For simplicity we consider the case of two assets in our model, a risk-free 
money market account, a bond R, and a risky asset, the stock S. We assume 
that the stock price is adapted to the filtration (Qn) for the trading dates 
n = 0,1,2,··· ,7V. 
Definition 12.7 A trading strategy is called self-financing if for all n = 
Ι,-..,/V: 
Vn = ßnRn 
+ anSn = ßn+iRn 
+ an+iSn. 
(12-1) 
This implies that no funds are withdrawn from or added the strategy. 
Theorem 12.2 A trading strategy φ is self-financing if and only if we have 
for alln= 
1, · · · , N: 
n 
n 
νη(φ) = ν0(φ) + Σ ßi (ßi - ßi-i) + Σ ai Φ " V i ) · 
(12·2) 
3=1 
j=\ 
Hence the value of a self-financing strategy consists of the initial investment 
VQ and the gains (or losses) from the trade stock and money market account. 

506 
INTRODUCTION TO MATHEMATICAL FINANCE 
Proof: Prom the definition of the value of a portfolio we get that: 
νη+ι(φ) - νη{ψ) = ßn+iRn+i + an+iSn+i 
- ßnRn - anSn. 
(12.3) 
Now ψ is self-financing if and only if ßn+\Rn 
+ an+iSn 
= ßnRn 
+ <*nSn for 
all n = 1, ■ · ■ ,7V. Substituting this into (12.3) gives: 
νη+1(φ) 
- νη(φ) = ßn+1{Rn+1 
-Rn) + an+1(Sn+i 
- Sn). 
(12.4) 
As νη+ι(φ) 
= ν0(φ) + £ " = 0 Vi+i(<p) - Vi(ip), the lemma follows by summing 
over (12.4). 
■ 
We give a similar characterization of a self-financing strategy in terms of the 
discounted value process. 
Theorem 12.3 A trading strategy is self-financing if and only if we have for 
alln = 1, · · · ,N: 
n 
Ϋη(φ) = ν0(φ) + Σ«i (Sj ~ Sj-ή . 
(12.5) 
J'=l 
Proof: The proof of this theorem is omitted as it is similar to the proof of 
the previous theorem. 
■ 
Definition 12.8 A trading strategy φ — {φη; η = 1, · · · , N} is called admis-
sible if it is self-financing with Vn((p) > 0 for n = 1,2, · · · , TV. 
Definition 12.9 (Arbitrage Opportunity) An arbitrage opportunity 
in 
the financial markets is a trading strategy φ such that Vo(y) = 0, VXr(<p) > 0 
αηάΕ{νΝ{ψ)) 
> 0. 
Definition 12.10 A finite market model M. is called viable or arbitrage-free, 
if there are no arbitrage opportunities. 
Note 12.2 (European Contingent Claim) The value of the European con-
tingent claim (ECC) H > 0 with expiry date N is an 9fjv measurable random 
variable. The random variable H is a known payoff of the claim. For example, 
a European call option with strike price K and expiry date N is: 
H = 
max(SN-K,0). 
Definition 12.11 (Attainable or Replicating Strategy) Given a finite 
market model M., a contingent claim H with maturity N is called attain-
able if there is an admissible, self-financing strategy ψη = (ctn,ßn) 
such that 
VN(V) = H; ψ is called a replicating strategy for the derivative. 
Definition 12.12 A finite market M. is called complete if every contingent 
claim is attainable or equivalently, if for every 3JV-measurable random variable 
H there exists at least one trading strategy ψ such that VN(<P) = H. 

DISCRETE-TIME MODELS 
507 
The completeness of the finite market model is a highly desirable property. 
Under market completeness, any European or American contingent claim can 
be priced by an arbitrage-free and self-financing strategy. If the market is not 
complete, then it is called an incomplete market model. 
In order to characterize arbitrage-free markets, we use the concept of equiv-
alent martingale measures. 
Definition 12.13 Let A4 be a finite market model. A probability measure Q 
on (Ω, 3) such that 
1. Q is equivalent to P, i.e., for all A € 9 we have Q(A) = 0 « P{A) = 0, 
and 
2. the discounted stock price S is a martingale under measure Q 
is called an equivalent martingale measure or a risk-neutral measure for M. 
Note 12.3 
1. The measure Q is said to be absolutely continuous with respect to P, 
i.e., for all Ae% we have P(A) = 0 =>· Q{A) = 0. 
2. A martingale under measure Q is referred as a Q-martingale. 
Theorem 12.4 Let Q be an equivalent martingale measure for the market M. 
Consider a self-financing, admissible trading strategy ψ. Then the discounted 
process Ϋη(φ) is a Q-martingale. 
Proof: As ψ is self-financing, we get from Theorem 12.3: 
n 
Ϋ{ψ) = ν0(φ) + Σαά 
(Sj - Sj-ί) = νη(φ) + an+1 (sn+1 - S n) . 
As φ is admissible, φη+\ is 3in-measurable and S is a Q-martingale: 
EQ 
n 
)|3„) 
= 
an+iEQ 
(S„+i - Sn | 3 nJ = 0. 
■ 
Theorem 12.5 // an equivalent martingale measure exists for the finite mar-
ket model M, then the model M. is arbitrage-free. 
Proof: Consider a self-financing strategy φ with Vjv(v) >0,E 
(VAT(V)) > 0. 
We will show that the existence of an equivalent martingale measure Q gives 
Vo(v) > 0, which implies that the finite market model M. is arbitrage-free. 
If VN{<P) and ΫΝ(Ψ) 
have the same sign, then it follows that V/v(y?) > 0 and 

508 
INTRODUCTION TO MATHEMATICAL FINANCE 
E (yN{<pj) > o. 
We have that the measure Q is equivalent to P, which implies that Q (V}v(</>) > 0 
0 and this gives EQ{VM{^)) 
> 0. We know that {Vn(ip));n = 1, · · · ,N} is a 
Q-martingale, which shows that Vo{<p) = EQ (V/V(¥>)) > 0, and therefore, we 
conclude that Vo(<^) > 0. 
■ 
We now state the first fundamental theorem of asset pricing . 
Theorem 12.6 A finite market M is arbitrage-free if and only if there is 
a probability measure Q equivalent to P such that the discounted asset price 
processes are Q-martingales. 
Proof: For the proof, see Williams (2006). 
■ 
Theorem 12.7 Let M. be an arbitrage-free market with an attainable con-
tingent claim H and replicating strategy φ. If Q is an equivalent martingale 
measure for M, then the fair price of the claim H at time n < N is given by 
νη(φ) = EQ ((1 + r)-("-">ii | 9f„) 
(12.6) 
and, in particular, we have: 
V0(<p) = EQ{(l + r)-NH). 
(12.7) 
Proof: From the replicating strategy φ of the claim, we have V/v(y) = H 
and hence (1 + r)~NH = νΝ(φ). 
We know that {νη(φ); n = 0, · · · , N} is a 
Q-martingale, and hence by Theorem 12.4, we have: 
EQ ((1 + r)~NH \ 9 n) = EQ (ΫΝ(φ) | 9fn) = Vn{<p) = (1 + r)-nVn(<p). 
(12.8) 
Therefore, Vn(<p) = EQ ((1 + r ) - ^ " " ) f f | 9 n ) . 
■ 
We have seen in the first fundamental theorem of asset pricing that the 
existence of an equivalent martingale measure implies that the finite market 
model is arbitrage-free. We will now state without proof a second funda-
mental theorem of asset pricing which gives us the necessary and sufficient 
condition for the existance of complete market [see Harrison and Kreps (1979), 
and Harrison and Pliska (1981)]. 
Theorem 12.8 An arbitrage-free market M. is complete if and only if there 
exists a unique equivalent martingale measure Q. 
Proof: For a proof we refer to Williams (2006). 
■ 
As an example we now present the binomial model of Cox et al. (1979). 
This simple model provides a useful computing method for pricing financial 
derivatives. 

DISCRETE-TIME MODELS 
509 
12.2.1 
The Binomial Model 
This section considers a single discrete-time financial market model known 
as the binomial model or Cox-Ross-Rubinstein 
(CRR) model. In this model, 
we assume that there are a finite number of trading times t = 1,2,·· ,N, 
where N < oo. At each of these time instants, the values of two assets are 
observed. The risky asset is called a stock and the risk-free asset a bond. The 
bond is assumed to yield a deterministic rate of return r over each time period 
(n— 1, n]. We assume that the bond is valued at $1 at time n = 0, i.e., RQ = 1. 
The value of the bond at any time n is given by 
Rn = (l+r)n 
for n = 0,1,2,·· · ,/V 
(12.9) 
We suppose that the stock prices in each time interval are independent and 
identically distributed random variables each of which goes up by a factor u 
or down by a factor d. We assume the stock price as a random walk such that 
S„ = S„_iCn 
for n = 1,2,··· ,7V 
(12.10) 
where {Cf,j = 1,··· ,/V} is a sequence of independent and identically dis-
tributed random variables with 
P(b=u) 
= P 
P(Q=d) 
= q 
such that p + q = 1. The binomial tree for the stock price process {Sn;n = 
0,1, · · · , N} for N = 4 is represented in Figure 12.2. 
We assume that there exists a money market so that one can invest or borrow 
money with a fixed interest rate r such that 0 < d < 1 + r < u. This condition 
is necessary to avoid arbitrage opportunities in the market model. Equation 
(12.10) can be written as: 
n 
Sn = S(>r[<i 
for 
n = 1,2,··· ,/V. 
(12.11) 
For the binomial model, one can easily enumerate the probability space 
(Ω, 3, P). The sample space consists of 2^ possible outcomes for the values of 
the sequence {Ci5 C2, · ■ · , Gv}· The σ-algebra 3 contains all possible subsets of 
Ω and P is the probability measure associated with TV independent Bernoulli 
trials, each with probability p. In the context of the previous chapter, 3fn := 
"■(Ci) C2) · ■ · , Cn) for 1 < n < N and (9fn)^=1 is the filtration. 
We use a simple model to explain the important results in pricing financial 
derivatives. Consider a European contingent claim H. Suppose that we have 
a single stock with price So at time n — 0. Assume that there is a single 
period to the expiry of the European contingent claim H. 

510 
INTRODUCTION TO MATHEMATICAL FINANCE 
Figure 12.2 
Binomial tree for N = 4 
The fundamental assumption of the binomial model is that the price of the 
stock may take one of the two values at the expiration date. Either it will 
be USQ with probability p or it will be dSo with probability q = 1 — p where 
0 < d < u. If there is a risk-free asset with interest rate r, as we remarked 
earlier, we assume that 0 < d < l + r < u t o avoid arbitrage opportunities in 
the market model. 
The objective is to find a strategy φ = (αι,βι) 
where c*\,ßi € R such that 
Vx{<p) = 
alSx+ßxRl=H 
where Rx = (1 + r) and S\ = SoCi with 
P ( C i = « ) 
= 
p 
P(Ci=d) 
= 
q 
such that p + q = 1. 
The European contingent claim H takes two positive values Hu and Hd 
respectively when ζι = u and ζι = d: 
Hu 
= 
axSou + ß^l + r) 
Hd 
= 
axSod + ßxil + r) . 
(12.12) 
Solving the above system of equations for the two unknowns (αχ,βι), we get: 
Hu-Hd 
ai 
~ 
(u-d)S0 
1 
fuHd-dHu\ 
ft 
~ 
l + r \ 
u-d 
) ' 

DISCRETE-TIME MODELS 
5 1 1 
Set: 
P* = 
^
^ 
(12-13) 
u — a 
«* = "^ττ1 
(
12·
14) 
u — a 
H* 
= 
-^— 
. 
(12.15) 
1 + r 
v 
' 
Then the initial wealth required to finance a strategy which results in values 
Hu and Hd is given by 
ν0(φ) 
= 
aiS0+ßiRo 
Hu -Hd 
„ 
1 
(uHd - dHu 
-S0 + 
(u — d)So 
1+r 
\ 
u — d 
1 
(1+r-d 
u-{l+r) 
Λ 
l + r\{u-d) 
u-d 
) 
1 
(p*Hu + q*Hd) 
1+r 
Vo = 
EQ(H·) 
where EQ(-) denotes the expectation with respect to the measure Q = (p*,q*)· 
The initial wealth Vb is also known as the manufacturing cost of the contingent 
claim. The measure Q = {p*,q*) is called the risk-neutral probability. The 
above equation suggests that the value of the European contingent claim is 
a discounted expectation of the final value under the probability measure Q. 
Hence it is called a risk-neutral valuation. Here we wish to note that the 
actual probabilities of the stock price do not appear in the valuation formula 
of the European contingent claim. 
Note 12.4 An investor could be classified according to his preference for risk 
taking: 
1. An investor who prefers to take the expected value of a payoff to the 
random payoff is said to be risk averse. 
2. An investor who prefers the random payoff to the expected payoff is said 
to be risk preferring. 
3. An investor who is neither risk averse nor risk preferring is said to be 
risk-neutral. 
Theorem 12.9 The discounted stock price process {(l+r)~nSn; 
n = 0,1, · · · , iV} 
is a martingale under measure Q. 
Proof: Since 
EQ(Sn+1\Zn) 
= (p*u + q*d)Sn, 
p*=1 
+ V~d, 
<z* = M ~ ( 1 + r ) , 
u — a 
u — d 

512 
INTRODUCTION TO MATHEMATICAL FINANCE 
we have: 
M ( l + r ) - n S n | 9 n _ i ) 
= 
(H-r)- n(p*tt + 9*d)S„-i 
= 
(1 + r) 
l~u+ 
, 
'd]Sn-i 
\ 
u — a 
u — a 
) 
= 
(l + r ) - ^ " 1 ) ^ - ! . 
Thus we proved that {(1 + r)~nSn; n = 0,1, ■ · · , N} is a martingale under 
measure Q. 
■ 
12.2.2 
Multi-Period Binomial Model 
We now extend a one-period binomial model to an ΛΓ-period model. The state 
space Ω = {u, d}N is such that the elements of Ω are JV-tuples with {u, d}. 
For 1 < n < N, we now show that there is a replication strategy for a 
European contingent claim H. Let φ = {(an, βη) : n = 1, · · · , JV} such that: 
νΝ(φ) = aNSN + ßNRN 
= H. 
(12.16) 
Let VN = H where H is an 9^-measurable random variable. Consider the 
time period (N — 1, N] by using a single period model as before. We obtain 
Vu — Vd 
- - (ÄS&T 
<12'17) 
ft, . ^-(ψψ) 
(12.18) 
1 + r V (u-d) 
) 
and 
VN-i = T^—EQ 
(VN | 9fjv-i) 
(12.19) 
1 + r 
where Q is the risk-neutral measure. 
We can find a trading strategy φ = {(αη, βη) : n = 1, · · · , N} with value 
process Vn(<p) such that V^ = H. We do this by working backward through 
the binomial tree. 
For n = 1,2, · · · , N—l, we assume that the self-financing strategies {(an, βη) 
n = 1, · · · , N} have been determined during the time interval (n — 1, n] with 
value process Vi, V2, · · ■ , VN-I such that 
V = 
h^EQiH^) 
for m = n, n + 1, · · · , N — 1. 

DISCRETE-TIME MODELS 
513 
Let V™ and V* be the two possible values of Vn. We define 
Vu — Vd 
(u - 
d)bn-i 
ßn 
~ 
( l + r ) - V 
(u-d) 
) 
( 1 2 · 2 1 ) 
and 
Vn-\ 
= 
1
 
:EQ (Vn | 9f„_i) 
1 + r 
Y^EQ 
(EQ (Vn+1 | 9fn) | 9 n_!) 
K - : 
= 
(i + r ^ - n + i ^ Q ^ l ^ n - i ) 
( s i n c e ^ 
= *0· 
In particular: 
EXAMPLE 12.3 
v° = jrhw
EQ{H)- 
(12,22) 
We now give an example of a multiperiod pricing formula for a European 
call option. We suppose as before that the stock prices in each time 
interval are independent and identically distributed random variables 
each of which goes up by a factor u with probability p or down by a 
factor d with probability q. We know now how to price a contingent 
claim in a one-period model. 
A European call option has a payoff at the time of expiry N as H = 
max(5jv — K,0). The value of the European call option Cn = 
C(Sn,n) 
at time 0 < n < N is given by: 
Vn = (1 + r ) " - " ^ {H ' 9 n ) 
As we illustrated earlier in Figure 12.2 for N = 4, the pricing formula 
for n = 0,1, · · · , N — 1, we have 
C„ = (1 + r)-N+n 
Σ 
(SnuidN-n-i 
-K)(N~ 
n V V " ~ n _ < , 
teß(n) 
\ 
l 
/ 

514 
INTRODUCTION TO MATHEMATICAL FINANCE 
where E(n) is the set of indices i for which SnuldN 
n * > K. Notice 
that E(n) is possibly empty in {0, · · · ,N — n). Set an = minE(n) to 
get: 
Cn = 
(l+r)-N+nY/(SnuidN-n-i-K)(N~n)p*iq*N-n-i 
i=an 
^ 
' 
= (1 + r)~N+n 5f(5„uidiV-"-i -K)(N~ "jp'V"-"-* 
i—an 
- K{\ + r)n~N Σ (N 7 " V V"""1-4· 
(12-23) 
The above formula is known as the CRR formula for binomial pricing 
models. We observe that both sums in equation (12.23) can be expressed 
in terms of binomial probabilities. Let II(fc, pu, a) be the probability that 
the cumulative binomial probability B(k,pu) 
is larger than or equal to 
a with pu = ^ _ . Then equation (12.23) can be rewritten as: 
Cn = Snn(N-n,pu,an)-K(l+r)n-Nn(N-n,qd,an). 
▲ 
(12.24) 
Note 12.5 Let us assume that trading takes place during the interval [0, T]. 
We consider the stock price process introduced earlier for the fixed time interval 
[0, T] divided into N subintervals of equal length AN with AN = jj. 
We let 
the parameters depend on N as follows. For a given volatility of the stock, 
σ > 0, the step interest rate up and down factors are given by: 
rN 
= 
exp(rAN) 
- 1 
(12.25) 
uN 
= 
εχρ(σ·ν/Δ^) 
(12.26) 
dN 
= 
exp(-a-v/ÄJv)· 
(12.27) 
.Assume N —>■ oo. At any time, the fair price of a European call option with 
payoff max.(SN (T) — K,0) has the limiting value 
5Φ((ίι(ί)) - ΛΓβ-Γ(τ-')φ(ίί2(ί))) 
(12.28) 
where: 
d ( ) 
= 
log(S/K) + 
(r+^)(T-t) 
d2(£) 
= 
di(t)-aVT-t 
. 
Equation (12.28) is the famous Black-Scholes formula. For more details see 
Bingham and Kiesel (200J^). 

DISCRETE-TIME MODELS 
515 
Figure 12.3 
Binary tree 
■ EXAMPLE 12.4 
[Williams (2006), page 28]. Consider a European call option in the CRR 
model with N = 2, 5 0 = $100 and Si = $200 or Si = $50 with strike 
price K = $80 and expiry date TV = 2. Assume the risk-free interest 
rate r = 0.1. 
(a) Calculate the arbitrage-free price for the European call option at time 
n = 0. 
(b) Find the hedging strategy for this option. 
(c) Suppose that the call option is initially priced $2 below the arbitrage-free 
price. Describe a strategy that gives an arbitrage. 
(d) Using put-call parity, find the value of the European put option at time 
n = 0. 
Solution: We have N = 2, S0 = $100, u = 2, d = \, r = 0.1 and 
K = $80. We calculate the risk-neutral probability 
„ _ 1+r-d 
_ 1.1-0.5 _ 2 
P ~ 
u-d 
~ 2 - 0 . 5 
~ 5" 
The binary tree for the stock price is given in Figure 12.3. 
(a) The possible values for European call option H = max(52 — K, 0) are 
$0, $20, $320 respectively. By using the CRR formula for the European 

516 
INTRODUCTION TO MATHEMATICAL FINANCE 
call option, we have: 
C° 
= 
JV^rYEQ{H) 
= 
-f~y 
( P * 2 ( 3 2 0 ) + 2pV(20) + <?*>)) 
6080 
„ 
= Ί2Γ = $ 5 0· 2 5· 
(b) Using expressions (12.20) and (12.21) we calculate 
d 
4 
8000 
d 
2000 
4 
a2 = l,a2 = - . f t = - _ , ft = - j ^ - . e i = g 
and 
10800 
β1 = ——— = -29.752 . 
H 
363 
Hence: 
C0 = c*iSo + ßiRo = 7(100) + (-29.752)(1) = $50.25 . 
5 
(c) We suppose that the value of the call option is priced at $48.25. Then 
one can buy the option at $48.25 and invest $2 in the bond. At time 
N = 2, he earns the profit of $2(1.1)2 = $2.42 > 0, which gives an 
arbitrage opportunity. 
(d) The value of the put option is calculated from (a) using put-call parity: 
Co — PQ 
= 
So — 7——Γ2 
(1 + T·)2 
Po ~ 
CQ — So + (l + r)2 
1 
50.25-100 + 80., 1λ9 
(l.l) 2 
16.37. 
Note 12.6 Now we will explain briefly how to use a CRR binomial tree to 
value American options. 
The interested reader may refer to Bingham and 
Kiesel (2004) or Williams (2006). 
An American contingent claim X is represented by a sequence of random 
variables X = {Xn;n 
= 0,1,··· ,N} such that Xn is ^n-i-measurable 
for 

CONTINUOUS-TIME MODELS 
5 1 7 
n = 0,1,··· ,N. 
For the American call option on the stock S with strike 
price K, Xn = max(5„ — K, 0). To define the price of the contingent claim 
associated with {Xn;n 
= 0,1,··· ,N}, 
we proceed with backward induction 
starting at time N. Let Um be the minimum amount of money required for 
the writer of the American contingent claim at time m to cover the payoff at 
time N if a buyer decides to claim at time 0 < m < N. 
The time m is a 
random variable and is aho known as a stopping time. 
A self-financing strategy is called a super hedging for the writer if ψ — 
{(αη, βη); η = 1,2, ■ · ■ , N} with value νη(φ) at time n such that Un < Vn(<p) 
for n = 0,1, · · · , N. 
We assume that UN = XN- 
The minimum amount of 
money required at time N — 1 to cover the payoff of the American contingent 
claim at time N is: 
^—EQ 
(UN | 9,v-i) · 
1 + r 
But in the case of the holder exercising his right at time N — 1, he will earn 
XN-I- 
Hence the value of the American contingent claim at time N — 1 is: 
UN-I = max ixN-!, Y^EQ (UN I 9^_i)|. 
By induction, we can see that the value of the American contingent claim for 
n = 1,2,··· ,N is: 
i/n_i = max 
(12.29) 
12.3 
CONTINUOUS-TIME MODELS 
We will discuss the continuous-time modeling of financial derivatives. We 
consider a finite time interval [0,T] for 0 < T < oo. The continuous-time 
market modeled by a probability space (Ω, 9, P) and a filtration (%)t<T = 
{3ft! 0 < t < T} is the standard filtration generated by a Brownian motion 
{Bt;0 < t < T}. 
As in the case of discrete-time, we consider a financial 
market consisting of a risky asset, namely a stock with price process S = 
{St;0 <t<T} 
and a risk-free asset with price process R = {Rt; 0 < t < T}. 
As suggested by Black-Scholes (1973), we assume that the behavior of the 
strike price is determined by the stochastic differential equation 
dSt = ßStdt + aStdBt 
(12.30) 
where μ and σ are two constants and Bt is a Brownian motion. We also assume 
that a bond is risk-free, which yields interest at rate r, where the constant r 
is the continuously compounding rate of return. The price dynamics of the 
bond takes the form 
dRt = rRtdt. 
(12.31) 

518 
INTRODUCTION TO MATHEMATICAL FINANCE 
The solution of equations (12.30) and (12.31) are easily computed to obtain 
St = S0e^-^)t+,TBt 
(12.32) 
and 
Rt = ert 
(12.33) 
for 0 < t < T. 
Note 12.7 The stock price process described in equation (12.32) implies that 
the log-returns 
Η
σ2)
(τ-
log(ST) ~ log(St) =σ(Βτ- 
Bt) + U - -σ2\ 
(Τ - t) 
are normally distributed with mean (μ — \σ2) (Τ — t) and variance σ2(Τ — t). 
The parameter σ is also called the volatility of the stock. Hence, the stock 
price St has a log-normal distribution. 
We now define the trading strategy and value of the portfolio process for 
the continuous-time models. 
Definition 12.14 A trading strategy is a stochastic process φ = {</?t = (at, ßt) · 
0 < t < T} satisfying the following conditions: 
1. i^:[0,T]xQ-> R2 is (Βτ Χ 3Τ)-measurable where ψ(ί,ω) = ψ^) 
for 
each 0 <t <T and ω e Ω. 
2. y>t is ^it-adapted for each 0 <t 
<T. 
3. I 
a2dt < oo and l 
\ßt\dt 
Jo 
Jo 
< oo a.s. 
As before ctt and ßt represent the number of units of shares and bonds respec-
tively. 
The value process or value of the portfolio at time t is given by: 
Vt{tp) = 
aiSt+ßtRt. 
In the discrete-time models we have seen self-financing strategies. Similarly 
the trading strategy φ is called a self-financing strategy if 
VtM = ν0(φ) + f audSu + f 
ßudRu 
Jo 
Jo 
for all 0 < t < T, or equivalently 
dVt(<p) = atdSt + ßtdRt 
for all 0 < t < T. 

CONTINUOUS-TIME MODELS 
519 
Now we define discounted price processes for the stock and value processes. 
The discounted stock price process is given by 
St = e~rtSt 
for 0 < t < T 
and the discounted value process is given by 
Vt(<p) = e-rtVt(<p) 
for 0 < t < T . 
By use of Ito's formula: 
dSt 
= 
d(Ste-rt) 
= 
-rSte~rtdt 
+ e~rt (ßStdt + 
oStdBt) 
= 
(μ - r)e-rtStdt 
+ 
ae-rtStdBt. 
Thus: 
dSt = (μ - r)Stdt + 
aStdBt. 
In integral form this is 
St = S0 + f 
({μ -r)- 
^σΑ 
Sudu + ί 
aSudBu 
since So = SQ. 
Theorem 12.10 A trading strategy ψ is self-financing if and only if the dis-
counted process Vt(<p) can be expressed for all t 6 [0, T] as: 
r* 
Vt(ip) = ν0(ψ) + / audSu . 
(12.34) 
Jo 
Proof: We know that 
dVt((p) = atdSt + ßtdRt 
so that: 
d(yt{<pj) 
= 
d{e-rtVt(<p)) 
= 
-re-rtVt(<p) 
+ e-rtdVt(<p) 
= 
-re~rt 
(atSt + ßtRt) 
+ e~rt (atdSt + ßtdRt) 
= 
e-rt(ß-r)atStdt 
+ 
e-rtaatStdBt 
= 
atdSt. 
Hence 
Vt{fp) = ν0(ψ) + / 
audSu 
Jo 

520 
INTRODUCTION TO MATHEMATICAL FINANCE 
for 0 < t < T. Conversely suppose that (12.34) holds. Then 
d(Vt{<p)) 
= 
atdSt 
= 
e-rtat(-rStdt 
+ dSt) 
= 
e~rt {-rVt(<p)dt + atdSt + 
ßtdRt). 
Again by Itö's formula 
d(yt(<pj) = d(e-rtvtM) 
= 
-re-rtVt(<p)dt 
+ e-rtdVt(<p) 
= 
atdSt + ßtdRt 
and hence ψ is a self-financing strategy. 
■ 
Definition 12.15 A self-financing strategy φ is called an arbitrage opportu-
nity if 
ν0(φ) = 0, 
ντ(φ) 
> 0 
and 
E (VT(<p)) > 0. 
We now introduce an equivalent martingale measure. 
Definition 12.16 A probability measure Q is called an equivalent martingale 
measure or risk-neutral measure if: 
1. Q is equivalent to measure P. 
2. The discounted stock price process St = {e _ r t5 t,0 < t <T} 
is a mar-
tingale under measure Q, i.e., EQ (St | 3ft_i) = St-i for allO <t 
<T. 
We now give the valuation formula for a European contingent claim under a 
risk-neutral measure. 
Theorem 12.11 Consider a European contingent claim H which is a 3 T -
measurable random variable such that EQ (\H\) < oo. Then the fair price or 
arbitrage-free price for the European contingent claim H at time t equals: 
Vt=EQ(e-«T-t>H\%). 
Proof: Let us assume that there exists an admissible trading strategy φ = 
{(at,ßt);0 
< t < T} that replicates a European contingent claim. Then the 
value of the replicating portfolio at time t is: 
Vt = atSt + ßtRt-
The discounted value process at time t is: 
Vt 
= 
e~rtVt 
Vt 
= 
atSt + ßt. 

CONTINUOUS-TIME MODELS 
5 2 1 
Since no funds are added or removed from the replicating portfolio and the 
portfolio is self-financing, by Theorem 12.10 we can write the portfolio as: 
Vt(<p) = ν0(ψ) + / 
audSu. 
Jo 
10 
Also H can be replicated by self-financing strategy ψ and the value process 
{Vt;t>0}. 
We have H = VT and hence: 
H = e-rTH = VT. 
Now let Mt — I a^dSu be a martingale under measure Q. We have: 
Jo 
rT 
It 
Hence: 
EQ If 
audSu \%)=EQ 
{MT - Mt | %) = 0 
EQ (e~rtH | %) =Vt= 
e~rtVt. 
Therefore: 
Vt = EQ ( e - ^ - O t f | %) 
12.3.1 
Black-Scholes Formula European Call Option 
In this section we derive Black-Scholes formula for European call option using 
two different approaches. In the first approach we apply the results of the 
risk-neutral measure for a European call option. 
Let us consider a European call option on a stock with strike price K. The 
claim has a payoff function H = max(Sr — K, 0) at expiry time T. The strike 
price follows the geometric Brownian motion 
dSt = ßStdt + aStdBt 
where μ € R and σ > 0. 
Theorem 12.12 Suppose that the stock follows the geometric Brownian mo-
tion described above with strike price K and expiry date T. Then the value of 
the European call option at time t is given by 
C = S^di) - Ke-rV-^^di) 
(12.35) 
where 
di = Mf)+^')(r-t) 
{12M) 
di _ ^)°(r-W)(T-t)=di_aVT-tt 
(123T) 
σ^/Τ — t 

522 
INTRODUCTION TO MATHEMATICAL FINANCE 
where Φ(.) is the cumulative normal distribution and r is the risk-neutral 
interest rate. 
Proof: We know that St satisfies the equation 
dSt = μ-Stdt + aStdBt 
where Bt is a Brownian motion. Thus St is of the form 
ST = 5 0β( Γ-5 σ 2) τ + σ β Γ 
where SQ is the price of the stock at time t = 0. 
Under a risk-neutral measure the fair price of the call option is: 
Ct = EQ(e-^T-^ 
max(ST - K, 0) | %) . 
Without loss of generality, we assume that t = 0. We have: 
Co = 
EQ(e-rTmax{ST-K,0)) 
= 
EQ (e-rTSTX{ST>K}) 
- Ke~rTEQ 
(X{ST>K}) 
= 
(i)-(H)-
First we evaluate the term (II). We have: 
EQ(X{ST>K}) 
= 
Q(ST>K) 
= 
Q(lnST>\nK) 
= Q(Bl- 
^K-^so-(r+W)A 
But we know that, under measure Q, Bt = Z = Λ/"(0,ί) and Q{Z > x) = 
Q{Z < -x). Hence 
= Φ(*) 
where 
log(f) + ( r - ^ ) ( T - 0 

CONTINUOUS-TIME MODELS 
523 
Now we compute the term (/): 
EQ(e-rTSTX{ST>K}) 
= 
EQ[Soe-^T+"B-X{sT>K}) 
Λ/2ΤΓΤ J-d2
 
V 
' 
V2nT J-dh 
1 
f°° 
_si 
i— 
= 
So 
/ 
e 
2 
(since x = y — σ v T) 
\/2πΤ J-di-ay/T 
= 
Φ (d2 + σν/τ) 
*(di) 
where: 
dj = d2 + σ\/Γ. 
Thus for any 0 < t < T we have 
Ct = St*(di) - 
Ä e - ^ - ^ c f c ) 
where di and cfo are given in equations (12.36) and (12.37). 
■ 
We will prove the previous theorem by the partial differential equation ap-
proach proposed by Black-Scholes (1973). We consider the stock price process 
that follows geometric Brownian motion 
dSt 
= 
ßStdt + aStdBt 
(12.38) 
where μ £ M and σ > 0 and Bt is a Brownian motion. Consider a portfolio 
at time t which consists of at shares on stock and Bt units of bonds with value 
Rt. The bond is assumed to be risk-free with deterministic equation 
dRt 
= 
rRtdt 
(12.39) 
where r > 0 is the interest rate. At time t, the value of the portfolio is: 
Vt 
= 
atSt + ßtRt- 
(12-40) 
The portfolio is supposed to hedge a European call option with value C = 
Ct = C(St,t). 
The European call option with strike price K and expiry date 
T has pay-off value Ct = max(Sx — K,0). 
Prom Ito's formula for the call 
option C, we have: 
% + *ΊΒ + ϊ>*ΐ£)* 
+ "%'Β- 
<
12·
41» 

524 
INTRODUCTION TO MATHEMATICAL FINANCE 
The value of the portfolio satisfies: 
dVt 
= 
atdSt + ßtdRt 
= 
at {ßStdt + aStdBt) + 
BtrRtdt 
= 
(aßSt + ßrRt)dt + ataStdBt. 
(12.42) 
Under a self-financing strategy, equation (12.42) must coincide with equation 
(12.41). Since terms dt and dBt are independent, the respective coefficients 
must be equal. Otherwise there shall be an arbitrage opportunity. Therefore: 
atSt + ßtRt 
= 
Ct 
dC 
dC 
1 
αμβ + ßrR 
= 
- + , * — + -* 
ασβ 
= 
aS^. 
From (12.45), we have: 
dc 
a = äs' 
Substituting (12.46) in (12.43), we have: 
' - Kc-'£)· 
2 5 : ,ß2C 
es2 
(12.43) 
(12.44) 
(12.45) 
(12.46) 
(12.47) 
Again substituting equations (12.46) and (12.47) in (12.44), we get: 
Thus we have shown that the value of a call option satisfies the above partial 
differential equation. This equation is also known as the Black-Scholes equa-
tion, which can be solved under appropriate conditions. Equation (12.48) can 
be solved for the final condition 
CT = C(ST, T) = max(5T - K, 0) 
along with the boundary conditions 
C(0, t) = 0 and C{S, t) -> S as 5 -»■ oo. 
Finding the solution of equation (12.48) is a long computational procedure 
and the reader may refer to Wilmott et al. (1995). The solution of (12.48) for 
the value of a European call option at time T with strike price K, underlying 
stock price S, risk-free interest rate r and volatility σ starting from time t is 
given as 
C(St,t) 
= 5Φ (di) - Ke-rlT-t)* 
(da) 

CONTINUOUS-TIME MODELS 
525 
where: 
di 
= 
\og(S/K) + (r + σ2/2)(Τ 
- t) 
ay/T-t 
log(S/K) + (r - σ2/2)(Γ - t) 
aVT-t 
EXAMPLE 12.5 
Consider a European call option with strike price $105 and three months 
to expiry. The stock price is $110 and risk-free interest rate is 8% per 
year, and the volatility is 25% per year. 
Thus we have 5 0 = 110, K = 105, T = 0.25, r = 0.08 and σ = 0.25. 
From equations (12.36) and (12.37) we get: 
d 
log (gj) + (0.08 +|(0.3) 2) (0.25) 
^
^ 
1 
0.3VÖ25 
d2 = d1- 0.3>/ä25 = 0.4697 
The value of the European call option calculated by using the Black-
Scholes formula (12.35) is: 
C0 
= 
5Φ (di) - Κε-ΓΤΦ 
(d2) 
= 
110Φ (0.5947) - 1056'ο·08(ο·25)Φ (0.4697) 
= 
9.5778. 
A 
12.3.2 
Properties of Black-Scholes Formula 
The option pricing formula depends on five parameters, namely 
S,K,T,r 
and σ. It is important to analyze the change or variations of option price 
with respect to these parameters. These variations are known as Greek-letter 
measures or simply Greeks. We now give a brief description of these measures. 
Delta 
The delta of a European call option is the rate of change of its value with 
respect to the underlying asset price: 
Since 0 < Φ(άχ) < 1, it follows that Δ > 0, and hence the value of a Euro-
pean call option is always increasing as the underlying asset price increases. 

526 
INTRODUCTION TO MATHEMATICAL FINANCE 
Using the information from Example 12.5, Δ = 0.724, which means that the 
call price will increase (decrease) with about $0,724 if the underlying asset 
increases (decreases) by one dollar. The delta of the put option is also given 
by the option's first derivative with respect to the underlying asset price. The 
delta of the put option is given by: 
Δ Ρ = Φ(ά1) - 1 < 0. 
Gamma: The Convexity Factor 
The gamma (Γ) of a derivative is the sensitivity of Δ with respect to S: 
d2C 
Γ = as2 
The concept of gamma is important when the hedged portfolio cannot be 
adjusted continuously in time according to Δ(5(ί)). If gamma is small, then 
delta changes only slowly and adjustments in the hedge ratio need only be 
made infrequently. However, if gamma is large, then the hedge ratio delta is 
highly sensitive to changes in the price of the underlying security. According 
to the Black-Scholes formula, we have: 
1 
exp(-d?/2) . 
Sy/2na\/T 
- 1 
Notice that Γ > 0 so that the Black-Scholes formula is always concave up 
with respect to 5. Note the relation of a delta hedged portfolio to the option 
price due to concavity. The call and put options have the same gamma. For 
Example 12.5, the gamma for the European call option is Γ = 0.0243, which 
means that the rise (fall) in the underlying asset price by one dollar yields a 
change in the delta from 0.724 to 0.724+0.0243 = 0.7476 (0.6990). 
Theta: The Time Decay Factor 
The theta (Θ) of a European claim with value function C(St,t) is defined as: 
By defining the rate of change with respect to the real time, the theta of a 
claim is sometimes referred to as the time decay of the claim. For a European 
call option on a non-dividend-paying stock: 
Note that Θ for a European call option is negative, so that the value of a 
European call option is a decreasing function of time. Theta does not act 

VOLATILITY 
527 
like a hedging parameter as is the case for delta and gamma. This is because 
although there is some uncertainty about the future stock price, there is no 
uncertainty about the passage of time. It does not make sense to hedge against 
the passage of time on an option. 
Rho: The Interest Rate Factor 
The rho (p) of a financial derivative is the rate of change of the value of 
the financial derivative with respect to the interest rate. It measures the 
sensitivity of the value of the financial derivative to interest rates. For a 
European call option on a non-dividend paying stock, 
p = K(T -1) exp(-r(T - ί))Φ(ά2) . 
We see that p is always positive. An increase in the risk-free interest rate 
means a corresponding increase in the derivative. 
Vega: The Volatility Factor 
The Vega (v) of a financial derivative is the rate of change of value of the 
derivative with respect to the volatility of the underlying asset. Here we wish 
to note that vega is not the name of any Greek letters, while the names of 
other options sensitivities have corresponding Greek letters. For a European 
call option on a non-dividend-paying stock, 
v = SVT - t—j= exp(-d?/2) 
ν2π 
so that the vega is always positive and is identical for call and put options. 
An increase in the volatility will lead to an increase in the call option value. 
See Hull (2009) for more details. 
Note 12.8 We wish to note that the Black-Scholes partial differential equa-
tion can also be written as: 
Θ + rSA + )-a2S2T 
= rC. 
12.4 
VOLATILITY 
We have seen that the Black-Scholes formula does not depend on the drift 
parameter μ of the stock and depends only on the parameter σ, the volatility 
that appears in the formula. In order to use the Black-Scholes formula, one 
must know the value of the parameter σ of the underlying stock. We end this 
chapter by giving a brief description of how to estimate the volatility of stock. 
The volatility is a crucial component for pricing finance derivatives and esti-
mating the value σ is the subject of study in financial statistics. One method 

528 
INTRODUCTION TO MATHEMATICAL FINANCE 
to estimate volatility is the historical volatility whose estimates require the use 
of appropriate statistical estimators, usually an estimator of variance. One of 
the main problems in this regard is to select the sample size, or the number 
of observations that will be used to estimate σ. Different observations tend 
to give different volatility estimates. 
To estimate the volatility of a stock price empirically, the stock price is 
observed at regular intervals, such as every day, every week or every month. 
Define: 
1. The number of observations n + 1 
2. Si, i = 0,1,2,3, · · · , n, the stock price at the end of the zth interval 
3. r, the length of each time interval (in years). 
Let 
Ui = ln(Si) - 1η(^_!) = In (J±-\ 
for i = 1,2,3, · · · be the increment of the logarithms of the stock prices. We 
are assuming that the stock price acts as a geometric Brownian motion, so 
that ln(Si) - ln(Si_i) ~ 
Ν{ττ,σ2τ). 
Since Si = Si-\eUi, 
Ui is the continuously compounded return (not annual-
ized) in the ith interval. Then the usual estimate s of the standard deviation 
of the ttj's is given by 
1 
n 
where u is the mean of the Uj's. Sometimes it is more convenient to use the 
equivalent formula 
^^rig^-^iylE«* 
As usual, we assume the stock price varies as a geometric Brownian mo-
tion. That means that the logarithm of the stock price is a Brownian motion 
with the same drift and in the period of time r would have a variance σ2τ. 
Therefore, s is an estimate of ay/i. It follows that σ can be estimated as: 
s 
0~ Ri — = . 
Choosing an appropriate value for n is not easy because σ does change 
over time and data that are too old may not be relevant for the present or the 
future. A compromise that seems to work reasonably well is to use closing 
prices from daily data over the most recent 90 to 180 days. Empirical research 

EXERCISES 
529 
indicates that only trading days should be used, so days when the exchange 
is closed should be ignored for the purposes of the volatility calculation. 
Another method is known as implied volatility, which is the numerical value 
of the volatility parameter that makes the market price of an option equal to 
the value from the Black-Scholes formula. We have known that it is not 
possible to "invert" the Black-Scholes formula to explicitly express σ as a 
function of the other parameters. Therefore, one can use numerical techniques 
such as the bisection method or Newton-Raphson method to solve for σ. The 
efficient method is to use the Newton-Raphson method, which is an iterative 
method to solve the equation 
f(a,S,K,r,T-t)-C 
= 0, 
where C is the market price of an option and /(.) is a pricing model that 
depends on σ. Prom an initial guess of σο, the iteration function is: 
ffi+i = σί - 
f(ai)/(df(ai)/da). 
This means that one has to differentiate the Black-Scholes formula with re-
spect to σ. This derivative is known as vega. A formula for nu for a European 
call option is 
¥- = 5Λ/5^ίΦ'(<ίι)βχρ(-Γ(Τ - t))· 
ασ 
With the help of software such as MATlab or Matematica one can solve the 
above equation. Implied volatility is a "forward-looking" estimation tech-
nique, in contrast to the "backward-looking" historical volatility. That is, 
it incorporates the market's expectations about the prices of securities and 
their derivatives. In general volatility need not be a constant and could depend 
on the price of the underlying stock. These models are known as stochastic 
volatility models. As we stated in the introduction, we presented only a simple 
modeling approach for mathematical finance. Interested readers are advised 
to take a proper course on stochastic analysis which will take them to a more 
formal theory of mathematical finance, (see Williams (2006), Bingham and 
Kiesel (2004), and Lamberton and Lapeyre (1996). 
EXERCISES 
12.1 
If a stock sells for $100, the value of the call option is $6, the value of 
the put option is $4 and both options have the same strike price, $100, what 
is the risk-free interest rate. 
12.2 
Suppose that an investor buys a European call option on certain un-
derlying stock ABC with a $75 strike price and sells a European put option 
on ABC with the same strike price. Both options will expire in 3 months. 
Describe the investor position. 
12.3 
Suppose that a stock price is $120 and in the next year it will either 
be up by 10% or fall by 20%. The risk-free interest rate is 6% per year. 

530 
INTRODUCTION TO MATHEMATICAL FINANCE 
A European call option on this stock has a strike price of $130. Find the 
probability that the stock price will rise and also the value of a call option. 
12.4 
Consider a European call option with 6 months to expiration. The 
underlying stock price is $100, strike price is $100, the risk-free interest rate 
is 6% and volatility is 30% . Find the risk-neutral probability and the value 
of the European call option using the CRR binomial model for N = 4. 
12.5 
Consider an American put option with 6 months to expiration. The 
underlying stock price is $100, the strike price is $95, the risk-free interest rate 
is 8% and the volatility is 30%. Find the value of the American put option at 
n = 0 using the CRR binomial model for N = 5. 
12.6 
Consider a one-period binomial model with SO = $40, Si = $44 or 
Si = $36, K = 42. The risk-free interest rate r = 12%. Find the risk-neutral 
probability and calculate the value of the three-month European call option 
12.7 
(Williams, 2006) Consider the CRR binomial model for N = 3 with 
So = $50, u = 2, d = \ and risk-free interest rate r = 7%. The value of the 
European contingent claim at time N = 3 is given by: 
tf = max(So,Si,S2,S3). 
a) Find the arbitrage-free initial price of the European call option at time 
n = 0. 
b) Determine the hedging strategy for this option. 
c) Suppose that the option in (12.7) is initially priced $2 below the arbitrage-
free price. Describe a strategy that gives an arbitrage. 
12.8 
As one increases the strike price K (keeping all other parameters fixed), 
does the value of a call option increase? Briefly justify your answer. 
12.9 
Find the expression for the delta of the put option. 
12.10 
Assume single-period binomial model with So = $10, S„ = 12, S<j = 9 
and r = 0.5. A call option on this stock has an expiry date 5 months from 
today and a strike price of $10. Find the value of this option. 
12.11 
Consider a two-period CRR model with N — 2, So = $40 and strike 
price K = $42. In each of the next 3-month periods, the stock is expected to 
go up by 10% or down by 10%. The risk-free interest rate is 10% per year. 
a) What is the value of a 6-month European put option? 
b) What is the value of a 6-month American put option? 
12.12 
Consider a European call option with expiry date t = n and strike 
price K. Let CQ denote its price at time ί = 0. Argue that Co < So; the price 

EXERCISES 
531 
of any such option is always less than or equal to the price of the stock at 
time t = 0. 
12.13 
Use the Black-Scholes formula to price a European call option for a 
stock whose price today is $20 with expiry date 6 months from now, strike 
price $22 and volatility 20%. The risk-free interest is 5% per year. Find the 
value of the call option halfway to expiry if the stock price at that time is $21. 
12.14 
Use the Black-Scholes formula to price a European call option for a 
stock whose price today is $75 with expiry date 3 months from now, strike 
price $70 and volatility 20%. The risk-free interest is 7% per year. 
a) Find the value of the European call option and compute delta and 
gamma for this option. 
b) Find the value of the European put option and compute delta and 
gamma for this option. 
12.15 
Let r denote the risk-free (annual nominal) interest rate. Suppose 
that we consider the stock under its risk-neutral measure, that is, when μ is 
replaced by μ* = r — σ2/2. Show that the expected rate of return now is r, 
the same as the risk-free interest rate. Explain why this makes sense. 
12.16 
Suppose that the observations on a stock price (in dollars) at the 
end of each of 15 consecutive weeks are as follows: 100.50, 102, 101.25, 101, 
100.25, 100.75, 100.65, 105, 104.75, 102, 103.5, 102.5, 103.25, 104.5, 104.25. 
Estimate the stock price volatility. 
12.17 
Suppose that a call option on an underlying stock SQ = 36.12 that 
pays no dividends for 6 months has a strike price of $35 with market price of 
$2.15 and expiry date of 7 weeks. The risk-free interest rate r = 7%. Find 
the implied volatility of this stock? 
12.18 
A call option on a non-dividend paying stock has a market price of 
$2.50. The stock price is $15, the exercise price is $13, the time to maturity is 
3 months and the risk-free interest rate is 5% per annum. What is the implied 
volatility? 

APPENDIX A 
BASIC CONCEPTS ON SET THEORY 
In this appendix we present some basic concepts and results from set theory 
that have been used throughout the book. Intuitively, a set is a well-defined 
grouping of objects. The objects belonging to the set are called elements. 
Sets are represented with uppercase Latin letters: A, B, C, M, X, ■ ■ ■ while 
the elements of a set are usually represented with lowercase Latin letters: a, 
b, c, m, x, ■ ■ · . To indicate that an element x belongs to the set A, we write 
x e A, and if x is not an element of the set A, then we write x $. A. 
Sets can be described by enumerating all of their elements or by enunciating 
properties that those elements must have. In the first case we say that the set 
is determined by extension and in the second case we say the set is determined 
by comprehension. Thus, we have, for example, that the set 
A = {1,3,5,9} 
is described by extension, while the set 
B = {x : x is a rational number less than or equal to 5} 
has been defined by comprehension. 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
533 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

534 
BASIC CONCEPTS ON SET THEORY 
A set whose elements correspond to nonnegative integers is called finite. A 
set that does not have any elements is called an empty set and is notated 0. 
A set is said to be infinite if it is not finite. 
Two sets are said to be equal if and only if they have exactly the same 
elements. If all the elements of a set A are also elements of a set B we say 
that A is contained in B (alternatively, B contains A or A is a subset of B) 
and write AC. B (or B D A). Prom this definition, it is clear that every set 
is a subset of itself and 0 is a subset of every set. 
If A is a subset of B and there is at least an element in B that does not 
belong to A, we say that A is a proper subset of B and write A C B. 
Applications of set theory usually consider all sets to be subsets of one 
single set called the universe, represented as U. 
The union of two sets A and B, written A U B, is the set of all elements 
belonging to either A or B or both. That is: 
AUB 
:={x: 
xeA 
V x € B} . 
In a similar way, if {Aj}i€/ is a family of sets and J Q I, then: 
\\Ai 
:= {x : x € Ai for at least one i G J} . 
The intersection of two sets A and B, represented as A Π B, is the set of 
elements belonging to both A and B. That is: 
AnB 
:={x: 
xeA 
Λ x e B} . 
In a similar way, if {Aj}jej is a family of sets and J C. I, then: 
P|-At := {x : x G Ai for all i G J} . 
ieJ 
If A and B do not have elements in common, that is, if A Π B = 0, it is said 
that they are mutually exclusive or disjoint. 
The difference of two sets A and B, notated as A — B, is the set of all 
elements belonging to A but not to B; in other words: 
A-B:={x: 
x€A 
A x φ Β) . 
The complement of a set A, notated as Ac, is the difference between the 
universe U and A; in other words: 
Ac:={x: 
xeU 
Λ x £ A} . 
Next, we present, without demonstration, the basic properties of the set 
operations defined above. The interested reader can find the proofs in Munoz 
(2002). 

BASIC CONCEPTS ON SET THEORY 
535 
Theorem A.l Let A, B and C be subsets of a universe U. Then: 
1. (Commutative Laws) 
(a) A U B = B U A 
(b) A Π B = B Π A 
2. (Associative Laws) 
(a) A\J{BuC) 
= 
(AoB)uC 
(b) Ar\{BDC) 
= 
(Ar\B)ilC 
3. (Distributive Laws) 
(a) An(BuC) 
= 
(AnB)\j(AnC) 
(b) Au{BnC) 
= {Al>B)n{Al>C) 
4- (Complement Laws) 
(a) A U Ac = U 
(b) AC)Ac = 0 
(c) A\JU = U 
(d) AC\U = A 
(e) A U 0 = A 
(f) AC\0 = 0 
5. (Difference Laws) 
(a) A-B 
= A(1BC 
(b) A - B = A - {An B) = (A\J B) - B 
(c) A - (B - C) = (A - B) U (A Π C) 
(d) 
(Al)B)-C=(A-C)U(B-C) 
(e) A-(BuC) 
= 
(A-B)n(A-C) 
(f) (Ar\B)U{A-B) 
= A 
(g) (ΑΓ\Β)η(Α-Β) 
= 0 
6. (De Morgan Laws) 
(a) {A Π B)c = {Ac U Bc) 
(b) (A U B)c = (Ac Π Bc) 
7. (Involutive Law) (A°Y = A 
8. (Idempotence Laws) 

536 
BASIC CONCEPTS ON SET THEORY 
(a) A U A = A 
(b) A n A = A 
Next, we present one of the most important concepts in mathematics: If for 
each element of a set A we establish a well-defined association with a unique 
element of a set B then, that association is a function from A to B. Notating 
such association with / , we write: 
/ : A^B 
. 
The set A is called the domain of the function and the set B is called the 
codomain of / . If a € A, then the element of B that / associates with a is 
notated as f(a) and is called the image of a. 
If / is a function from A to B and b € B, we define the preimage (or inverse 
image) of 6 as the set of all elements belonging to A that have b as their image; 
in other words: 
f-\b):={a&A: 
f(a) = b}. 
Furthermore, if C is a subset of B, then the set of all elements in A whose 
images under / are in C is called the preimage (or inverse image) of C under 
/ and is notated as f~l{C). 
That is: 
f-\C):={a€A: 
f(a)eC}. 
Analogously, if D is a subset of A, then the subset of B whose elements are 
images of elements belonging to D under / is called the image (or direct 
image) of D under / and is commonly notated as f{D). That is: 
/(£>) :={beB: 
b= f(a) for a a € D} 
= {/(a) : a e D} . 
Some of the most important properties of the inverse and direct images of sets 
under a given function are summarized in the next theorem, whose proof can 
be checked in Mufioz (2002). 
Theorem A.2 If f : A —> B is a function and Νι, N2 and N are subsets of 
B and M is a subset of A, then: 
1. Γ\ΝΧ 
U N2) = Γ\Νχ) 
U 
f-\N2). 
2. NiQN2^ 
f-'iNt) 
C r 1 ^ ) · 
3. ri(NinN2) = rl(N1)nri(N2). 
i f(r1(N)) = N-
5. Μ ς / - ! ( / ( Μ ) ) . 

BASIC CONCEPTS ON SET THEORY 
537 
A set A is said to be countable if and only if there is a function / from A 
to the set of natural numbers N satisfying: 
1. / is one to one or injective, that is, for any x, y G A with x φ y, 
2. / is onto or surjective, that is, / (.A) = N. 

APPENDIX B 
INTRODUCTION TO COMBINATORICS 
In Chapter 1 we saw that probability in Laplace spaces reduces itself to count-
ing the number of elements of a finite set. The mathematical theory dealing 
with counting problems of that sort is formally known as combinatorial anal-
ysis. All the counting techniques are based on the following fundamental 
principle. 
Theorem B.l (The Basic Principle of Counting) Suppose that two ex-
periments are carried out. The first one has m possible results and for each 
result of this experiment there are n possible results of the second experiment. 
Then, the total number of possible results of the two experiments, when carried 
out in the indicated order, is run. 
Proof: 
The basic principle of counting can be proved by enumerating all 
possible results in the following way: 
(1,1) 
(1,2) 
··· 
(l,n) 
(2,1) 
(2,2) 
··· 
(2,n) 
(m, 1) 
(m, 2) 
··· 
(m,n) 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
539 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley h Sons, Inc. 

540 
INTRODUCTION TO COMBINATORICS 
This array consists of m rows and n columns and therefore has mn entries. ■ 
■ EXAMPLE B.l 
There are 10 professors in the statistics department of a University, each 
with 15 graduate students under their tutelage. If one professor and one 
of his students are going to be chosen to represent the department at an 
academic event, how many different ways can the selection be made? 
In this case there are 10 possible ways to pick the professor and, 
once chosen, 15 ways of choosing the student. By the basic principle of 
counting there are 150 ways of selecting the pair that will represent the 
department. 
▲ 
The basic principle of counting can be generalized as follows: 
Theorem B.2 (Generalization of the Basic Principle of Counting) // 
r experiments are carried out in such a way that the first one has n\ possi-
ble outcomes, for each of those n\ results there are ri2 possible results for 
the second experiment, for each outcome of the second experiment there are 
ri3 possible results of the third experiment, and so on, then the total number 
of results when the r experiments are carried put in the indicated order is 
«i x ri2 x ■ · · x nr. 
Proof: Left as an exercise for the reader. 
■ 
■ EXAMPLE B.2 
The total number of automobile plate numbers that can be made if each 
plate number consists of three different letters and five numbers equals 
26 x 25 x 24 x 105 = 1.56 x 109. 
A 
■ EXAMPLE B.3 
If a fair dice is rolled four consecutive times, then the total number of 
possible results of this experiment is 64 = 1296. 
▲ 
■ EXAMPLE B.4 
Suppose that there are n distinguishable balls and r distinguishable urns. 
Then the number of ways in which the balls can be put inside the urns 
equals rn. Indeed, the first ball can be placed in any of the r urns, the 
second ball can be placed in any of the r urns, and so on; therefore, 

INTRODUCTION TO COMBINATORICS 
5 4 1 
there are 
Γ Χ Γ Χ · · · Χ Γ = 
Γ η 
> 
v 
' 
n times 
ways to put the balls inside the urns. 
▲ 
■ EXAMPLE B.5 
Permutations 
A permutation is an arrangement of objects from a given set in a par-
ticular order. For example, the permutations of the letters a, b, and c 
are abc, acb, bac, bca, cab, and cba. That is, there are six permutations 
of the three letters. 
The total number of permutations of the objects belonging to a given 
set can be found without having to explicitly write down each possible 
permutation by reasoning as follows: Suppose that a set containing n 
elements is given, then the first position can be filled with any of the n 
numbers, the second position with any of the remaining n — 1 elements, 
the third position with any of the n — 2 remaining elements, and so on. 
Therefore, the total number P(n, n) of permutations of the n elements 
is: 
P(n, n) = n{n - l)(n - 2) · · · 1. 
Since the product of a positive integer n with all the positive integers 
preceding is notated as n! and called n factorial, we can write: 
P(n,n) — n\ 
Remember that, by definition, 0! := 1. 
A permutation of n objects taken r < n at a time is defined as 
an arrangement of r of the n objects in a particular order. Thus, the 
permutations of the letters a, b, c, and d taken two at a time are ab, ba, ac, 
ca, ad, da, be, cb, bd, db, cd, and dc. That is, there are 12 permutations 
of the letters a, b, c and d taken two at a time. The total number P(n, r) 
of permutations of n objects taken r at a time can be found as follows: 
There are n objects that can be chosen for the first position, there are 
n — 1 objects that can be chosen for the second position, and so on, 
until we reach the rth position, for which there will be n — r +1 possible 
objects to choose from. In other words: 
P{n, r) = n(n — 1) · ■ ■ (n — r + 1) 
n! 
= 7 
a! 
r<n 
A 
(n — ry. 

542 
INTRODUCTION TO COMBINATORICS 
■ EXAMPLE B.6 
Suppose that four girls and three boys have to be seated in a row. If the 
boys and girls can be seated in any order, then we would have 7! = 5040 
ways to do so. If we wish that the boys and girls are alternated in the 
row, then there would be 
4 x 3 x 3 x 2 x 2 x 1 x 1 = 144 
ways to seat them. If we wish that the boys and the girls are seated 
together (boys with boys, girls with girls) then, there would be 2 x 4! x 
3! = 288 ways to seat them. 
A 
■ EXAMPLE B.7 
A student wishes to put 4 calculus, 2 physics, 5 probability, and 3 algebra 
books on a shelf in such a way that all books belonging to the same 
subject are grouped together. There are 4! x 2! x 5! x 3! ways to place 
the books if the first ones are calculus books, then the physics books 
followed by the probability books and the algebra books. Since there 
are 4! ways to organize the subjects, there is a total of 
4! x 4! x 2! x 5! x 3! = 8.2944 x 105 
ways to put the books on the shelf. 
▲ 
■ EXAMPLE B.8 
We wish to calculate the number of ways in which 3 Mexican, 4 Egyp-
tian, 3 English and 5 Chinese people can be seated at a round table 
if individuals of the same nationality insist on sitting together. In this 
case we have four groups of people: Mexicans, Egyptians, Englishmen, 
and Chinese. The number of ways to place this groups around the table 
is 3!. The Mexicans can be seated in 3! ways, the Egyptians in 4! ways, 
the English in 3! ways and the Chinese in 5! ways. Therefore, there are 
3! x 3! x 4! x 3! x 5! = 6.2208 x 105 
ways to seat the people around the table. 
▲ 

INTRODUCTION TO COMBINATORICS 
543 
EXAMPLE B.9 
Let N be the number of different permutations of the letters in the word 
" experiment'1''. If all the letters were different, then the total number 
of permutations would be 10!, but since the three "e" can be permuted 
between them in 3! ways, then 3\N = 10!. That is: 
In general we have that the total number N of different permutations of 
n objects, of which «i, fi2, · · · ,nr are equal between them, is: 
N = 
m!ri2! · · ·η Γ! 
EXAMPLE B.10 
Combinations 
Suppose that there are n different objects. Each possible election of 
r < n of the objects is called a combination of order r. In other words, 
a combination of order r from a set 5 with n elements is a subset of S 
having exactly r elements. For example, the combinations of order 2 of 
the letters a,b,c and d are {a,b}, {a,c}, {a,d}, {b,c}, {b,d} and {c, d}; 
that is, there are six possible combinations of order 2 of the letters a, b, c 
and d. To determine the number of combinations C(n, r) of order r taken 
from n objects, we observe that if we took the elements in order there 
would be P(n, r) ways of choosing the r objects, and since r objects can 
be permuted in r! ways, then: 
r\C(n,r) 
= P{n,r) 
C(n,r) 
(n — r)\r\ 
The number C(n, r) is called "n choose r" and is written as ("). It is 
further defined that: 
Ö-» 
r < 0 or r > n. 
EXAMPLE B.ll 
Five couples, each couple a man and a woman, must be chosen for a 
dance from a group consisting of 10 women and 12 men. We wish to 
determine the number of possible selections. 

544 
INTRODUCTION TO COMBINATORICS 
We have that there are ('g2) ways to pick the men, and after they are 
chosen we select the women, which can be done in ( 5) different ways. 
Therefore, there are 
COCO-
1"·«* 
ways to pick the five couples. 
▲ 
■ EXAMPLE B.12 
A committee of 3 people must be formed by selecting its members from 
a group of 5 men and 3 women. How many possible committees are 
there? How many if the committee must have at least a woman? How 
many if two men do not get along and therefore cannot both be part of 
the committee? How many if there is a man-woman couple that would 
only accept to join the committee if they both belong to it? 
First, we have that there are (I) = 56 different ways of selecting the 
committee members. 
Now, if the committee must have at least a woman, then there are 
ways of selecting the committee. 
In the case where two men do not get along, there are two options: 
either one of them is included or both are excluded, which means that 
there are 
ways of selecting the committee. 
Finally, in the last case we have two options, either both members of 
the couple are included or both are excluded, yielding 
©♦©-
ways of selecting the committee. 
A 
■ EXAMPLE B.13 
A set of n elements is to be partitioned in m different groups of sizes 
ri,r2,··· 
,rm, where: 
r\ + r2 H 
1- rm = n. 

INTRODUCTION TO COMBINATORICS 
545 
We wish to find the number of different possible ways to accomplish this 
task. We observe that there are (") ways of selecting the first group, for 
every possible choice of the first group there are (η~Γι) ways of selecting 
the second group, and so on. Therefore, there are 
/ n \ / Π - Γ Λ 
/ n - r i - r 2 
rm-A 
n! 
V V V r2 
/ 
V 
rm 
) 
Hi xr 2! x ··· x rm! 
ways of selecting the groups. This number is called the multinomial 
coefficient and is notated as: 
\ r i , r 2 , · · · 
,rmJ 
EXAMPLE B.14 
Thirty students in a third-grade class must be split in 5 groups, each 
having 12, 5, 3, 6 and 4 students, respectively. How many possible 
partitions are there? According to the previous example, we have that 
there are 
30! 
( 
3° ) 
Vl2,5,3,6,4; 
= 4.4509 x 1016 
12! x 5! x 3! x 6! x 4! 
possible ways to split the class. 
▲ 
EXAMPLE B.15 
Suppose that there are n indistinguishable balls. How many ways are 
there to distribute the n balls in r urns? 
The result of this experiment can be described by a vector (xi, · · · , x r) 
where #j represents the number of balls placed on the tth urn. This 
allows us to reduce the problem to finding all the vectors (xi, · · ■ ,x r) 
with nonnegative integer entries such that Xi + 
\- xr = n. 
To solve this problem, suppose that the objects are put in a horizontal 
line and then divided in r groups by proceeding as follows: from the n— 1 
spaces separating the objects we choose r — 1 and trace dividing lines 
there; by doing this we get r nonempty groups. That is, there are ("Zi) 
vectors (xi, · · · , xr) with positive components satisfying xi-| 
\-xr = n. 
Since the number of nonnegative solutions of xi H 
1- x r = n equals 
the number of positive solutions of j/i H 
\- yr = n + r with j/j = Xj + 1 
for i = 1,2, ■ ·· ,r, then the total number of ways to distribute the n 
indistinguishable balls inside the r urns is: 
n + r — Λ 

546 
INTRODUCTION TO COMBINATORICS 
■ EXAMPLE B.16 
Twelve gifts are divided between 7 children. How many different dis-
tributions are possible? How many if each kid must get at least one 
present? 
According to the previous example, there are (12^7^-1) = (g8) = 
18,564 ways of distributing the gifts between the children. 
If, furthermore, each kid must receive at least one present, then, the 
number of possible distributions reduces to (^Ζχ) = (V) = 462. 
▲ 
EXERCISES 
B.l 
How many three-digit numbers less than 500 with all digits different 
from each other can be formed with the digits 1,2,3,4,5,6 and 7? 
B.2 
How many three-digit numbers can be formed with the digits 1,4,8 
and 5 if: 
1. The three digits are different? 
2. The numbers must be odd? 
3. The numbers must be divisible by 5? 
B.3 
How many ways are there to seat in a row four boys and four girls 
if they must be seated alternated? How many if the boys and the girls are 
seated together? How many if only the girls are seated together? 
B.4 
An inspector checks six different machines during the day. In order to 
avoid the operators knowing when those inspections are going to be made, he 
varies the order each time. In how many ways can he do this? 
B.5 
A group of 5 German, 6 Australian, 4 Japanese and 6 Colombian people 
must be seated at a round table. How many ways are there to do this? How 
many if people having the same nationality must be together? How many if 
the Colombians must stay together? 
B.6 
How many different arrangements can be formed with the letters in the 
word "successes"? 
B.7 
In a probability exam, a student must answer 10 out of 13 questions. 
How many ways of answering the exam does the student have? How many if 
he must answer at least 3 from the first 5 questions? How many if he must 
answer exactly 3 of the first 5 questions? 
B.8 
The effects of two medications A and B are going to be compared in 
a pharmaceutical study involving 50 volunteers. Twenty volunteers receive 

EXERCISES 
547 
medication A, another 20 receive medication B and the remaining 10 take 
a placebo. How many different ways of distributing the medications and 
placebos between the volunteers are there? 
B.9 
The statistics department of a university has 33 professors who must 
be divided into four groups of 15, 8, 7 and 3 members. How many possible 
partitions are there? How many if the 5 marked members of the advisor 
committee must be in the first group? 
B.IO 
In how many ways can 7 gifts be divided between three children if one 
child must receive 3 of them and the other two kids must get 2 each? 
B . l l 
The sciences faculty of a university has received 30 identical computers 
to be split between the 7 departments of the faculty. How many different 
distributions are possible? How many if each department must get at least 2 
computers? 
B.12 
An investor has $600,000 to invest in six possible bonds. Each invest-
ment has to be made in thousands of dollars. How many investment strategies 
are possible? 

APPENDIX C 
TOPICS ON LINEAR ALGEBRA 
This appendix presents some of the results from linear algebra used through-
out the book. It is assumed that the reader has some knowledge of basic 
matrix theory. The reader interested in further reading on this topics is re-
ferred to Searle (1982). 
1. The vectors in Rn are considered to be row-vectors. If x = (xi, · · · , x„) 
and y = (j/i, ■ · ■ , yn) are vectors in Rn, then their inner product is de-
fined as: 
n 
(x,y) = YjXiVi-
« = 1 
The Euclidean norm of a vector x = (x\,■■■ ,xn) of Rn is the real 
number ||x|| := ^/(x,x). 
2. The determinant of a square matrix A is notated det (A). 
3. The trace of a square matrix A is written tr (A). 
4. The transpose of a matrix A is notated Ä1'. 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
549 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

550 
TOPICS ON LINEAR ALGEBRA 
5. A square matrix is said to be diagonal if all the off-diagonal elements 
are equal to zero. 
6. A diagonal matrix having only l's in its main diagonal is called the 
identity of order n (n being the size of the matrix) and is written as 7„. 
7. A square matrix A is said to be symmetric if it is equal to its transpose. 
8. A square matrix of order n is said to be orthogonal if AAT = ATA = In. 
9. The eigenvalues of a matrix A of order n are the solutions to det (A — \In) 
= 
0 where A is a real or complex number 
10. An eigenvector of the square matrix A of order n associated with the 
eigenvalue λ is a vector 0 / v € l " such that xA = λν. 
11. A square matrix A is said to be singular if and only if it has 0 as an 
eigenvalue. A square matrix that is not singular is called nonsingular. 
12. A square matrix of order n is said to be positive-definite if for any vector 
x in E n with x / O w e have that xAx T > 0. 
13. A square matrix of order n is said to be positive-semidefinite if for any 
vector x in Rn with x ^ O w e have that xAx T > 0. 
The following theorem presents some of the interesting properties of sym-
metric and positive-definite matrices: 
Theorem C.l Let A be a symmetric and positive-definite matrix. Then: 
1. There is a matrix W such that A = 
WWT. 
2. The eigenvalues of A are all positive (and therefore the matrix A is 
nonsingular). 
3. The inverse matrix of A is symmetric and positive-definite. 
4- There exist square matrices A and V such that A = VAVT, where A is 
a diagonal matrix whose entries correspond to the eigenvalues of A and 
V is an orthogonal matrix whose columns are the vectors A , with v 
an eigenvector of A. (This still holds if A is just 
symmetric.) 

APPENDIX D 
STATISTICAL TABLES 
D.l 
BINOMIAL PROBABILITIES 
[*] 
p(x<i) = £ ( " V ( i - P r x 
x=l ^ ' 
n 
[t] 
0.05 
0.1 
0.15 
0.20 
0.30 
0.40 
0.50 
2 
0 
1 
2 
3 
0 
1 
2 
3 
0.9025 
0.9975 
1.0000 
0.8574 
0.9927 
0.9999 
1.0000 
0.8100 
0.9900 
1.0000 
0.7290 
0.9720 
0.9990 
1.0000 
0.7225 
0.9775 
1.0000 
0.6141 
0.9392 
0.9966 
1.0000 
0.6400 
0.9600 
1.0000 
0.5120 
0.8960 
0.9920 
1.0000 
0.4900 
0.9100 
1.0000 
0.3430 
0.7840 
0.9730 
1.0000 
0.3600 
0.8400 
1.0000 
0.2160 
0.6480 
0.9360 
1.0000 
0.2500 
0.7500 
1.0000 
0.1250 
0.5000 
0.8750 
1.0000 
(continued) 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
551 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

552 
STATISTICAL TABLES 
(continued) 
n 
[t] 0.05 
0.1 
0.15 
4 
0 0.8145 0.6561 0.5220 
1 0.9860 0.9477 0.8905 
2 0.9995 0.9963 0.9880 
3 
1.0000 0.9999 0.9995 
4 
1.0000 1.0000 1.0000 
5 
0 0.7738 0.5905 0.4437 
1 0.9774 0.9185 0.8352 
2 0.9988 0.9914 0.9734 
3 
1.0000 0.9995 0.9978 
4 
1.0000 1.0000 0.9999 
5 
1.0000 1.0000 1.0000 
6 
0 0.7351 0.5314 0.3771 
1 0.9672 0.8857 0.7765 
2 0.9978 0.9842 0.9527 
3 0.9999 0.9987 0.9941 
4 
1.0000 0.9999 0.9996 
5 
1.0000 1.0000 1.0000 
6 
1.0000 1.0000 1.0000 
7 
0 0.6983 0.4783 0.3206 
1 0.9556 0.8503 0.7166 
2 0.9962 0.9743 0.9262 
3 0.9998 0.9973 0.9879 
4 
1.0000 0.9998 0.9988 
5 
1.0000 1.0000 0.9999 
6 
1.0000 1.0000 1.0000 
7 
1.0000 1.0000 1.0000 
8 
0 0.6634 0.4305 0.2725 
1 0.9428 0.8131 0.6572 
2 0.9942 0.9619 0.8948 
3 0.9996 0.9950 0.9786 
4 
1.0000 0.9996 0.9971 
5 
1.0000 1.0000 0.9998 
6 
1.0000 1.0000 1.0000 
7 
1.0000 1.0000 1.0000 
8 
1.0000 1.0000 1.0000 
9 
0 0.6302 0.3874 0.2316 
1 0.9288 0.7748 0.5995 
2 0.9916 0.9470 0.8591 
3 0.9994 0.9917 0.9661 
4 
1.0000 0.9991 0.9944 
5 
1.0000 0.9999 0.9994 
6 
1.0000 1.0000 1.0000 
0.20 
0.30 
0.40 
0.50 
0.4096 0.2401 0.1296 0.0625 
0.8192 0.6517 0.4752 0.3125 
0.9728 0.9163 0.8208 0.6875 
0.9984 0.9919 0.9744 0.9375 
1.0000 1.0000 1.0000 1.0000 
0.3277 0.1681 0.0778 0.0313 
0.7373 0.5282 0.3370 0.1875 
0.9421 0.8369 0.6826 0.5000 
0.9933 0.9692 0.9130 0.8125 
0.9997 0.9976 0.9898 0.9687 
1.0000 1.0000 1.0000 1.0000 
0.2621 0.1176 0.0467 0.0156 
0.6554 0.4202 0.2333 0.1094 
0.9011 0.7443 0.5443 0.3438 
0.9830 0.9295 0.8208 0.6563 
0.9984 0.9891 0.9590 0.8906 
0.9999 0.9993 0.9959 0.9844 
1.0000 1.0000 1.0000 1.0000 
0.2097 0.0824 0.0280 0.0078 
0.5767 0.3294 0.1586 0.0625 
0.8520 0.6471 0.4199 0.2266 
0.9667 0.8740 0.7102 0.5000 
0.9953 0.9712 0.9037 0.7734 
0.9996 0.9962 0.9812 0.9375 
1.0000 0.9998 0.9984 0.9922 
1.0000 1.0000 1.0000 1.0000 
0.1678 0.0576 0.0168 0.0039 
0.5033 0.2553 0.1064 0.0352 
0.7969 0.5518 0.3154 0.1445 
0.9437 0.8059 0.5941 0.3633 
0.9896 0.9420 0.8263 0.6367 
0.9988 0.9887 0.9502 0.8555 
0.9999 0.9987 0.9915 0.9648 
1.0000 0.9999 0.9993 0.9961 
1.0000 1.0000 1.0000 1.0000 
0.1342 0.0404 0.0101 0.0020 
0.4362 0.1960 0.0705 0.0195 
0.7382 0.4628 0.2318 0.0898 
0.9144 0.7297 0.4826 0.2539 
0.9804 0.9012 0.7334 0.5000 
0.9969 0.9747 0.9006 0.7461 
0.9997 0.9957 0.9750 0.9102 
(continued) 

BINOMIAL PROBABILITIES 
553 
(continued) 
n 
[t] 0.05 
7 
8 
9 
10 0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 0 
1 
2 
1.0000 
1.0000 
1.0000 
0.5987 
0.9139 
0.9885 
0.9990 
0.9999 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.5688 
0.8981 
0.9848 
0.9984 
0.9999 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.5404 
0.8816 
0.9804 
0.9978 
0.9998 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.5133 
0.8646 
0.9755 
(continued) 
0.1 
0.15 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.3487 0.1969 
0.7361 0.5443 
0.9298 0.8202 
0.9872 0.9500 
0.9984 0.9901 
0.9999 0.9986 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.3138 0.1673 
0.6974 0.4922 
0.9104 0.7788 
0.9815 0.9306 
0.9972 0.9841 
0.9997 0.9973 
1.0000 0.9997 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.2824 0.1422 
0.6590 0.4435 
0.8891 0.7358 
0.9744 0.9078 
0.9957 0.9761 
0.9995 0.9954 
0.9999 0.9993 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.2542 0.1209 
0.6213 0.3983 
0.8661 0.6920 
0.20 
0.30 
1.0000 0.9996 
1.0000 1.0000 
1.0000 1.0000 
0.1074 0.0282 
0.3758 0.1493 
0.6778 0.3828 
0.8791 0.6496 
0.9672 0.8497 
0.9936 0.9527 
0.9991 0.9894 
0.9999 0.9984 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
0.0859 0.0198 
0.3221 0.1130 
0.6174 0.3127 
0.8389 0.5696 
0.9496 0.7897 
0.9883 0.9218 
0.9980 0.9784 
0.9998 0.9957 
1.0000 0.9994 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.0687 0.0138 
0.2749 0.0850 
0.5583 0.2528 
0.7946 0.4925 
0.9274 0.7237 
0.9806 0.8822 
0.9961 0.9614 
0.9994 0.9905 
0.9999 0.9983 
1.0000 0.9998 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.0550 0.0097 
0.2336 0.0637 
0.5017 0.2025 
0.40 
0.50 
0.9962 0.9805 
0.9997 0.9980 
1.0000 1.0000 
0.0060 0.0010 
0.0464 0.0107 
0.1673 0.0547 
0.3823 0.1719 
0.6331 0.3770 
0.8338 0.6230 
0.9452 0.8281 
0.9877 0.9453 
0.9983 0.9893 
0.9999 0.9990 
1.0000 1.0000 
0.0036 0.0005 
0.0302 0.0059 
0.1189 0.0327 
0.2963 0.1133 
0.5328 0.2744 
0.7535 0.5000 
0.9006 0.7256 
0.9707 0.8867 
0.9941 0.9673 
0.9993 0.9941 
1.0000 0.9995 
1.0000 1.0000 
0.0022 0.0002 
0.0196 0.0032 
0.0834 0.0193 
0.2253 0.0730 
0.4382 0.1938 
0.6652 0.3872 
0.8418 0.6128 
0.9427 0.8062 
0.9847 0.9270 
0.9972 0.9807 
0.9997 0.9968 
1.0000 0.9998 
1.0000 1.0000 
0.0013 0.0001 
0.0126 0.0017 
0.0579 0.0112 

554 
STATISTICAL TABLES 
(continued) 
n 
[t] 0.05 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
0.9969 
0.9997 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.4877 
0.8470 
0.9699 
0.9958 
0.9996 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.4633 
0.8290 
0.9638 
0.9945 
0.9994 
0.9999 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
(continued) 
0.1 
0.15 
0.9658 0.8820 
0.9935 0.9658 
0.9991 0.9925 
0.9999 0.9987 
1.0000 0.9998 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.2288 0.1028 
0.5846 0.3567 
0.8416 0.6479 
0.9559 0.8535 
0.9908 0.9533 
0.9985 0.9885 
0.9998 0.9978 
1.0000 0.9997 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.2059 0.0874 
0.5490 0.3186 
0.8159 0.6042 
0.9444 0.8227 
0.9873 0.9383 
0.9978 0.9832 
0.9997 0.9964 
1.0000 0.9994 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.20 
0.30 
0.7473 0.4206 
0.9009 0.6543 
0.9700 0.8346 
0.9930 0.9376 
0.9988 0.9818 
0.9998 0.9960 
1.0000 0.9993 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.0440 0.0068 
0.1979 0.0475 
0.4481 0.1608 
0.6982 0.3552 
0.8702 0.5842 
0.9561 0.7805 
0.9884 0.9067 
0.9976 0.9685 
0.9996 0.9917 
1.0000 0.9983 
1.0000 0.9998 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.0352 0.0047 
0.1671 0.0353 
0.3980 0.1268 
0.6482 0.2969 
0.8358 0.5155 
0.9389 0.7216 
0.9819 0.8689 
0.9958 0.9500 
0.9992 0.9848 
0.9999 0.9963 
1.0000 0.9993 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.40 
0.50 
0.1686 0.0461 
0.3530 0.1334 
0.5744 0.2905 
0.7712 0.5000 
0.9023 0.7095 
0.9679 0.8666 
0.9922 0.9539 
0.9987 0.9888 
0.9999 0.9983 
1.0000 0.9999 
1.0000 1.0000 
0.0008 0.0001 
0.0081 0.0009 
0.0398 0.0065 
0.1243 0.0287 
0.2793 0.0898 
0.4859 0.2120 
0.6925 0.3953 
0.8499 0.6047 
0.9417 0.7880 
0.9825 0.9102 
0.9961 0.9713 
0.9994 0.9935 
0.9999 0.9991 
1.0000 0.9999 
1.0000 1.0000 
0.0005 0.0000 
0.0052 0.0005 
0.0271 0.0037 
0.0905 0.0176 
0.2173 0.0592 
0.4032 0.1509 
0.6098 0.3036 
0.7869 0.5000 
0.9050 0.6964 
0.9662 0.8491 
0.9907 0.9408 
0.9981 0.9824 
0.9997 0.9963 
1.0000 0.9995 
1.0000 1.0000 
1.0000 1.0000 

BINOMIAL PROBABILITIES 
555 
(continued) 
n 
[t] 0.05 
16 0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 0 
1 
2 
3 
4 
5 
6 
0.4401 
0.8108 
0.9571 
0.9930 
0.9991 
0.9999 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.4181 
0.7922 
0.9497 
0.9912 
0.9988 
0.9999 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.3972 
0.7735 
0.9419 
0.9891 
0.9985 
0.9998 
1.0000 
(continued) 
0.1 
0.15 
0.1853 0.0743 
0.5147 0.2839 
0.7892 0.5614 
0.9316 0.7899 
0.9830 0.9209 
0.9967 0.9765 
0.9995 0.9944 
0.9999 0.9989 
1.0000 0.9998 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.1668 0.0631 
0.4818 0.2525 
0.7618 0.5198 
0.9174 0.7556 
0.9779 0.9013 
0.9953 0.9681 
0.9992 0.9917 
0.9999 0.9983 
1.0000 0.9997 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.1501 0.0536 
0.4503 0.2241 
0.7338 0.4797 
0.9018 0.7202 
0.9718 0.8794 
0.9936 0.9581 
0.9988 0.9882 
0.20 
0.30 
0.0281 0.0033 
0.1407 0.0261 
0.3518 0.0994 
0.5981 0.2459 
0.7982 0.4499 
0.9183 0.6598 
0.9733 0.8247 
0.9930 0.9256 
0.9985 0.9743 
0.9998 0.9929 
1.0000 0.9984 
1.0000 0.9997 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.0225 0.0023 
0.1182 0.0193 
0.3096 0.0774 
0.5489 0.2019 
0.7582 0.3887 
0.8943 0.5968 
0.9623 0.7752 
0.9891 0.8954 
0.9974 0.9597 
0.9995 0.9873 
0.9999 0.9968 
1.0000 0.9993 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
1.0000 1.0000 
0.0180 0.0016 
0.0991 0.0142 
0.2713 0.0600 
0.5010 0.1646 
0.7164 0.3327 
0.8671 0.5344 
0.9487 0.7217 
0.40 
0.50 
0.0003 0.0000 
0.0033 0.0003 
0.0183 0.0021 
0.0651 0.0106 
0.1666 0.0384 
0.3288 0.1051 
0.5272 0.2272 
0.7161 0.4018 
0.8577 0.5982 
0.9417 0.7728 
0.9809 0.8949 
0.9951 0.9616 
0.9991 0.9894 
0.9999 0.9979 
1.0000 0.9997 
1.0000 1.0000 
1.0000 1.0000 
0.0002 0.0000 
0.0021 0.0001 
0.0123 0.0012 
0.0464 0.0064 
0.1260 0.0245 
0.2639 0.0717 
0.4478 0.1662 
0.6405 0.3145 
0.8011 0.5000 
0.9081 0.6855 
0.9652 0.8338 
0.9894 0.9283 
0.9975 0.9755 
0.9995 0.9936 
0.9999 0.9988 
1.0000 0.9999 
1.0000 1.0000 
1.0000 1.0000 
0.0001 0.0000 
0.0013 0.0001 
0.0082 0.0007 
0.0328 0.0038 
0.0942 0.0154 
0.2088 0.0481 
0.3743 0.1189 

556 
STATISTICAL TABLES 
(continued) 
n 
[t] 0.05 
0.1 
0.15 
7 
1.0000 0.9998 0.9973 
8 
1.0000 1.0000 0.9995 
9 
1.0000 1.0000 0.9999 
10 1.0000 1.0000 1.0000 
11 1.0000 1.0000 1.0000 
12 1.0000 1.0000 1.0000 
13 1.0000 1.0000 1.0000 
14 1.0000 1.0000 1.0000 
15 1.0000 1.0000 1.0000 
16 1.0000 1.0000 1.0000 
17 1.0000 1.0000 1.0000 
18 1.0000 1.0000 1.0000 
19 
0 0.3774 0.1351 0.0456 
1 0.7547 0.4203 0.1985 
2 0.9335 0.7054 0.4413 
3 0.9868 0.8850 0.6841 
4 0.9980 0.9648 0.8556 
5 0.9998 0.9914 0.9463 
6 
1.0000 0.9983 0.9837 
7 1.0000 0.9997 0.9959 
8 
1.0000 1.0000 0.9992 
9 
1.0000 1.0000 0.9999 
10 1.0000 1.0000 1.0000 
11 1.0000 1.0000 1.0000 
12 1.0000 1.0000 1.0000 
13 1.0000 1.0000 1.0000 
14 1.0000 1.0000 1.0000 
15 1.0000 1.0000 1.0000 
16 1.0000 1.0000 1.0000 
17 1.0000 1.0000 1.0000 
18 1.0000 1.0000 1.0000 
19 1.0000 1.0000 1.0000 
20 
0 0.3585 0.1216 0.0388 
1 0.7358 0.3917 0.1756 
2 0.9245 0.6769 0.4049 
3 0.9841 0.8670 0.6477 
4 0.9974 0.9568 0.8298 
5 0.9997 0.9887 0.9327 
6 
1.0000 0.9976 0.9781 
7 1.0000 0.9996 0.9941 
8 1.0000 0.9999 0.9987 
9 
1.0000 1.0000 0.9998 
(continued) 
0.20 
0.30 
0.40 
0.50 
0.9837 0.8593 0.5634 0.2403 
0.9957 0.9404 0.7368 0.4073 
0.9991 0.9790 0.8653 0.5927 
0.9998 0.9939 0.9424 0.7597 
1.0000 0.9986 0.9797 0.8811 
1.0000 0.9997 0.9942 0.9519 
1.0000 1.0000 0.9987 0.9846 
1.0000 1.0000 0.9998 0.9962 
1.0000 1.0000 1.0000 0.9993 
1.0000 1.0000 1.0000 0.9999 
1.0000 1.0000 1.0000 1.0000 
1.0000 1.0000 1.0000 1.0000 
0.0144 0.0011 0.0001 0.0000 
0.0829 0.0104 0.0008 0.0000 
0.2369 0.0462 0.0055 0.0004 
0.4551 0.1332 0.0230 0.0022 
0.6733 0.2822 0.0696 0.0096 
0.8369 0.4739 0.1629 0.0318 
0.9324 0.6655 0.3081 0.0835 
0.9767 0.8180 0.4878 0.1796 
0.9933 0.9161 0.6675 0.3238 
0.9984 0.9674 0.8139 0.5000 
0.9997 0.9895 0.9115 0.6762 
1.0000 0.9972 0.9648 0.8204 
1.0000 0.9994 0.9884 0.9165 
1.0000 0.9999 0.9969 0.9682 
1.0000 1.0000 0.9994 0.9904 
1.0000 1.0000 0.9999 0.9978 
1.0000 1.0000 1.0000 0.9996 
1.0000 1.0000 1.0000 1.0000 
1.0000 1.0000 1.0000 1.0000 
1.0000 1.0000 1.0000 1.0000 
0.0115 0.0008 0.0000 0.0000 
0.0692 0.0076 0.0005 0.0000 
0.2061 0.0355 0.0036 0.0002 
0.4114 0.1071 0.0160 0.0013 
0.6296 0.2375 0.0510 0.0059 
0.8042 0.4164 0.1256 0.0207 
0.9133 0.6080 0.2500 0.0577 
0.9679 0.7723 0.4159 0.1316 
0.9900 0.8867 0.5956 0.2517 
0.9974 0.9520 0.7553 0.4119 

POISSON PROBABILITIES 
557 
(continued) 
n 
[t] 
0.05 
0.1 
0.15 
0.20 
0.30 
0.40 
0.50 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9994 
0.9999 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9829 
0.9949 
0.9987 
0.9997 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.8725 
0.9435 
0.9790 
0.9935 
0.9984 
0.9997 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.5881 
0.7483 
0.8684 
0.9423 
0.9793 
0.9941 
0.9987 
0.9998 
1.0000 
1.0000 
1.0000 
D.2 
POISSON PROBABILITIES 
P(X<t) = £ e 
[ t l 
Λ
^ 
fc! 
fc=0 
\[t] 
0.1 
0.2 
0.3 
0.4 
0.5 
0.6 
0.7 
0.8 
0.9 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
2.5 
3.0 
3.5 
4.0 
5.0 
0 
0.9048 
0.8187 
0.7408 
0.6703 
0.6065 
0.5488 
0.4966 
0.4493 
0.4066 
0.3679 
0.3012 
0.2466 
0.2019 
0.1653 
0.1353 
0.0821 
0.0498 
0.0302 
0.0183 
0.0067 
1 
0.9953 
0.9825 
0.9631 
0.9384 
0.9098 
0.8781 
0.8442 
0.8088 
0.7725 
0.7358 
0.6626 
0.5918 
0.5249 
0.4628 
0.4060 
0.2873 
0.1991 
0.1359 
0.0916 
0.0404 
2 
0.9998 
0.9989 
0.9964 
0.9921 
0.9856 
0.9769 
0.9659 
0.9526 
0.9371 
0.9197 
0.8795 
0.8335 
0.7834 
0.7306 
0.6767 
0.5438 
0.4232 
0.3208 
0.2381 
0.1247 
3 
1.0000 
0.9999 
0.9997 
0.9992 
0.9982 
0.9966 
0.9942 
0.9909 
0.9865 
0.9810 
0.9662 
0.9463 
0.9212 
0.8913 
0.8571 
0.7576 
0.6472 
0.5366 
0.4335 
0.2650 
4 
1.0000 
1.0000 
1.0000 
0.9999 
0.9998 
0.9996 
0.9992 
0.9986 
0.9977 
0.9963 
0.9923 
0.9857 
0.9763 
0.9636 
0.9473 
0.8912 
0.8153 
0.7254 
0.6288 
0.4405 
5 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9999 
0.9998 
0.9997 
0.9994 
0.9985 
0.9968 
0.9940 
0.9896 
0.9834 
0.9580 
0.9161 
0.8576 
0.7851 
0.6160 
6 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9999 
0.9997 
0.9994 
0.9987 
0.9974 
0.9955 
0.9858 
0.9665 
0.9347 
0.8893 
0.7622 
(continued) 

558 
STATISTICAL TABLES 
(continued) 
6.0 
7.0 
8.0 
9.0 
10.0 
15.0 
20.0 
0.0025 
0.0009 
0.0003 
0.0001 
0.0000 
0.0000 
0.0000 
λ \ 
0.0174 
0.0073 
0.0030 
0.0012 
0.0005 
0.0000 
0.0000 
7 
0.0620 
0.0296 
0.0138 
0.0062 
0.0028 
0.0000 
0.0000 
8 
0.1512 
0.0818 
0.0424 
0.0212 
0.0103 
0.0002 
0.0000 
9 
1C 
0.2851 
0.1730 
0.0996 
0.0550 
0.0293 
0.0009 
0.0000 
1 
11 
0.4457 
0.3007 
0.1912 
0.1157 
0.0671 
0.0028 
0.0001 
12 
0.6063 
0.4497 
0.3134 
0.2068 
0.1301 
0.0076 
0.0003 
0.1 
0.2 
0.3 
0.4 
0.5 
0.6 
0.7 
0.8 
0.9 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
2.5 
3.0 
3.5 
4.0 
5.0 
6.0 
7.0 
8.0 
9.0 
10.0 
15.0 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9999 
0.9997 
0.9994 
0.9989 
0.9958 
0.9881 
0.9733 
0.9489 
0.8666 
0.7440 
0.5987 
0.4530 
0.3239 
0.2202 
0.0180 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9999 
0.9998 
0.9989 
0.9962 
0.9901 
0.9786 
0.9319 
0.8472 
0.7291 
0.5925 
0.4557 
0.3328 
0.0374 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9997 
0.9989 
0.9967 
0.9919 
0.9682 
0.9161 
0.8305 
0.7166 
0.5874 
0.4579 
0.0699 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9999 
0.9997 
0.9990 
0.9972 
0.9863 
0.9574 
0.9015 
0.8159 
0.7060 
0.5830 
0.1185 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9999 
0.9997 
0.9991 
0.9945 
0.9799 
0.9467 
0.8881 
0.8030 
0.6968 
0.1848 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
1.0000 
0.9999 
0.9997 
0.9980 
0.9912 
0.9730 
0.9362 
0.8758 
0.7916 
0.2676 
20.0 
0.0008 0.0021 0.0050 0.0108 0.0214 0.0390 

STANDARD NORMAL DISTRIBUTION FUNCTION 
559 
D.3 
STANDARD NORMAL DISTRIBUTION FUNCTION 
Φ{ζ) = P{Z < z) = --L [ 
e'^dt 
z 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
0.6 
0.7 
0.8 
0.9 
1.0 
1.1 
1.2 
1.3 
1.4 
1.5 
1.6 
1.7 
1.8 
1.9 
2.0 
2.1 
2.2 
2.3 
2.4 
2.5 
2.6 
2.7 
2.8 
2.9 
3.0 
.00 
.5000 
.5398 
.5793 
.6179 
.6554 
.6915 
.7257 
.7580 
.7881 
.8159 
.8413 
.8643 
.8849 
.9032 
.9192 
.9332 
.9452 
.9554 
.9641 
.9713 
.9772 
.9821 
.9861 
.9893 
.9918 
.9938 
.9953 
.9965 
.9974 
.9981 
.9987 
.01 
.5040 
.5438 
.5832 
.6217 
.6591 
.6950 
.7291 
.7611 
.7910 
.8186 
.8438 
.8665 
.8869 
.9049 
.9207 
.9345 
.9463 
.9564 
.9649 
.9719 
.9778 
.9826 
.9864 
.9896 
.9920 
.9940 
.9955 
.9966 
.9975 
.9982 
.9987 
.02 
.5080 
.5478 
.5871 
.6255 
.6628 
.6985 
.7324 
.7642 
.7939 
.8212 
.8461 
.8686 
.8888 
.9066 
.9222 
.9357 
.9474 
.9573 
.9656 
.9726 
.9783 
.9830 
.9868 
.9898 
.9922 
.9941 
.9956 
.9967 
.9976 
.9982 
.9987 
.03 
.5120 
.5517 
.5910 
.6293 
.6664 
.7019 
.7357 
.7673 
.7967 
.8238 
.8485 
.8708 
.8907 
.9082 
.9236 
.9370 
.9484 
.9582 
.9664 
.9732 
.9788 
.9834 
.9871 
.9901 
.9925 
.9943 
.9957 
.9968 
.9977 
.9983 
.9988 
.04 
.5160 
.5557 
.5948 
.6331 
.6700 
.7054 
.7389 
.7704 
.7995 
.8264 
.8508 
.8729 
.8925 
.9099 
.9251 
.9382 
.9495 
.9591 
.9671 
.9738 
.9793 
.9838 
.9875 
.9904 
.9927 
.9945 
.9959 
.9969 
.9977 
.9984 
.9988 
.05 
.5199 
.5596 
.5987 
.6368 
.6736 
.7088 
.7422 
.7734 
.8023 
.8289 
.8531 
.8749 
.8944 
.9115 
.9265 
.9394 
.9505 
.9599 
.9678 
.9744 
.9798 
.9842 
.9878 
.9906 
.9929 
.9946 
.9960 
.9970 
.9978 
.9984 
.9989 
.06 
.5239 
.5636 
.6026 
.6406 
.6772 
.7123 
.7454 
.7764 
.8051 
.8315 
.8554 
.8770 
.8962 
.9131 
.9279 
.9406 
.9515 
.9608 
.9686 
.9750 
.9803 
.9846 
.9881 
.9909 
.9931 
.9948 
.9961 
.9971 
.9979 
.9985 
.9989 
.07 
.5279 
.5675 
.6064 
.6443 
.6808 
.7157 
.7486 
.7794 
.8078 
.8340 
.8577 
.8790 
.8980 
.9147 
.9292 
.9418 
.9525 
.9616 
.9693 
.9756 
.9808 
.9850 
.9884 
.9911 
.9932 
.9949 
.9962 
.9972 
.9979 
.9985 
.9989 
.08 
.5319 
.5714 
.6103 
.6480 
.6844 
.7190 
.7517 
.7823 
.8106 
.8365 
.8599 
.8810 
.8997 
.9162 
.9306 
.9429 
.9535 
.9625 
.9699 
.9761 
.9812 
.9854 
.9887 
.9913 
.9934 
.9951 
.9963 
.9973 
.9980 
.9986 
.9990 
.09 
.5359 
.5753 
.6141 
.6517 
.6879 
.7224 
.7549 
.7852 
.8133 
.8389 
.8621 
.8830 
.9015 
.9177 
.9319 
.9441 
.9545 
.9633 
.9706 
.9767 
.9817 
.9857 
.9890 
.9916 
.9936 
.9952 
.9964 
.9974 
.9981 
.9986 
.9990 

560 
STATISTICAL TABLES 
D.4 
CHI-SQUARE DISTRIBUTION FUNCTION 
2 e 
2 dx = 7 
Tabulated Val·« 
Λ^ 
0.995 
0.990 
0.975 
0.950 
0.900 
0.750 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
40 
50 
60 
70 
80 
90 
7.8794 
10.5966 
12.8382 
14.8603 
16.7496 
18.5476 
20.2777 
21.9550 
23.5894 
25.1882 
26.7568 
28.2995 
29.8195 
31.3193 
32.8013 
34.2672 
35.7185 
37.1565 
38.5823 
39.9968 
41.4011 
42.7957 
44.1813 
45.5585 
46.9279 
48.2899 
49.6449 
50.9934 
52.3356 
53.6720 
66.7660 
79.4900 
91.9517 
104.2149 
116.3211 
128.2989 
6.6349 
9.2103 
11.3449 
13.2767 
15.0863 
16.8119 
18.4753 
20.0902 
21.6660 
23.2093 
24.7250 
26.2170 
27.6882 
29.1412 
30.5779 
31.9999 
33.4087 
34.8053 
36.1909 
37.5662 
38.9322 
40.2894 
41.6384 
42.9798 
44.3141 
45.6417 
46.9629 
48.2782 
49.5879 
50.8922 
63.6907 
76.1539 
88.3794 
100.4252 
112.3288 
124,1163 
5.0239 
7.3778 
9.3484 
11.1433 
12.8325 
14.4494 
16.0128 
17.5345 
19.0228 
20.4832 
21.9200 
23.3367 
24.7356 
26.1189 
27.4884 
28.8454 
30.1910 
31.5264 
32.8523 
34.1696 
35.4789 
36.7807 
38.0756 
39.3641 
40.6465 
41.9232 
43.1945 
44.4608 
45.7223 
46.9792 
59.3417 
71.4202 
83.2977 
95.0232 
106.6286 
118.1359 
3.8415 
5.9915 
7.8147 
9.4877 
11.0705 
12.5916 
14.0671 
15.5073 
16.9190 
18.3070 
19.6751 
21.0261 
22.3620 
23.6848 
24.9958 
26.2962 
27.5871 
28.8693 
30.1435 
31.4104 
32.6706 
33.9244 
35.1725 
36.4150 
37.6525 
38.8851 
40.1133 
41.3371 
42.5570 
43.7730 
55.7585 
67.5048 
79.0819 
90.5312 
101.8795 
113.1453 
2.7055 
4.6052 
6.2514 
7.7794 
9.2364 
10.6446 
12.0170 
13.3616 
14.6837 
15.9872 
17.2750 
18.5493 
19.8119 
21.0641 
22.3071 
23.5418 
24.7690 
25.9894 
27.2036 
28.4120 
29.6151 
30.8133 
32.0069 
33.1962 
34.3816 
35.5632 
36.7412 
37.9159 
39.0875 
40.2560 
51.8051 
63.1671 
74.3970 
85.5270 
96.5782 
107,5650 
1.3233 
2.7726 
4.1083 
5.3853 
6.6257 
7.8408 
9.0371 
10.2189 
11.3888 
12.5489 
13.7007 
14.8454 
15.9839 
17.1169 
18.2451 
19.3689 
20.4887 
21.6049 
22.7178 
23.8277 
24.9348 
26.0393 
27.1413 
28.2412 
29.3389 
30.4346 
31.5284 
32.6205 
33.7109 
34.7997 
45.6160 
56.3336 
66.9815 
77.5767 
88.1303 
98.6499 
(continued) 

CHI-SQUARE DISTRIBUTION FUNCTION 
5 6 1 
(continued) 
Λ 1 
100 
200 
500 
1000 
0.995 
140.1695 
255.2642 
585.2066 
1118.9481 
0.990 
135.8067 
249.4451 
576.4928 
1106.9690 
0.975 
129.5612 
241.0579 
563.8515 
1089.5309 
0.950 
124.3421 
233.9943 
553.1268 
1074.6794 
0.900 
118.4980 
226.0210 
540.9303 
1057.7239 
0.750 
109.1412 
213.1022 
520.9505 
1029.7898 
V 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
40 
50 
60 
70 
80 
90 
100 
200 
500 
1000 
0.500 
0.455 
1.386 
2.366 
3.357 
4.351 
5.348 
6.346 
7.344 
8.343 
9.342 
10.341 
11.340 
12.340 
13.339 
14.339 
15.338 
16.338 
17.338 
18.338 
19.337 
20.337 
21.337 
22.337 
23.337 
24.337 
25.336 
26.336 
27.336 
28.336 
29.336 
39.335 
49.335 
59.335 
69.334 
79.334 
89.334 
99.334 
199.334 
499.333 
999.333 
0.250 
0.102 
0.575 
1.213 
1.923 
2.675 
3.455 
4.255 
5.071 
5.899 
6.737 
7.584 
8.438 
9.299 
10.165 
11.037 
11.912 
12.792 
13.675 
14.562 
15.452 
16.344 
17.240 
18.137 
19.037 
19.939 
20.843 
21.749 
22.657 
23.567 
24.478 
33.660 
42.942 
52.294 
61.698 
71.145 
80.625 
90.133 
186.172 
478.323 
969.484 
0.100 
0.016 
0.211 
0.584 
1.064 
1.610 
2.204 
2.833 
3.490 
4.168 
4.865 
5.578 
6.304 
7.042 
7.790 
8.547 
9.312 
10.085 
10.865 
11.651 
12.443 
13.240 
14.041 
14.848 
15.659 
16.473 
17.292 
18.114 
18.939 
19.768 
20.599 
29.051 
37.689 
46.459 
55.329 
64.278 
73.291 
82.358 
174.835 
459.926 
943.133 
0.050 
0.004 
0.103 
0.352 
0.711 
1.145 
1.635 
2.167 
2.733 
3.325 
3.940 
4.575 
5.226 
5.892 
6.571 
7.261 
7.962 
8.672 
9.390 
10.117 
10.851 
11.591 
12.338 
13.091 
13.848 
14.611 
15.379 
16.151 
16.928 
17.708 
18.493 
26.509 
34.764 
43.188 
51.739 
60.391 
69.126 
77.929 
168.279 
449.147 
927.594 
0.025 
0.001 
0.051 
0.216 
0.484 
0.831 
1.237 
1.690 
2.180 
2.700 
3.247 
3.816 
4.404 
5.009 
5.629 
6.262 
6.908 
7.564 
8.231 
8.907 
9.591 
10.283 
10.982 
11.689 
12.401 
13.120 
13.844 
14.573 
15.308 
16.047 
16.791 
24.433 
32.357 
40.482 
48.758 
57.153 
65.647 
74.222 
162.728 
439.936 
914.257 
0.010 
0.000 
0.020 
0.115 
0.297 
0.554 
0.872 
1.239 
1.646 
2.088 
2.558 
3.053 
3.571 
4.107 
4.660 
5.229 
5.812 
6.408 
7.015 
7.633 
8.260 
8.897 
9.542 
10.196 
10.856 
11.524 
12.198 
12.879 
13.565 
14.256 
14.953 
22.164 
29.707 
37.485 
45.442 
53.540 
61.754 
70.065 
156.432 
429.388 
898.912 
0.005 
0.000 
0.010 
0.072 
0.207 
0.412 
0.676 
0.989 
1.344 
1.735 
2.156 
2.603 
3.074 
3.565 
4.075 
4.601 
5.142 
5.697 
6.265 
6.844 
7.434 
8.034 
8.643 
9.260 
9.886 
10.520 
11.160 
11.808 
12.461 
13.121 
13.787 
20.707 
27.991 
35.534 
43.275 
51.172 
59.196 
67.328 
152.241 
422.303 
888.564 

SELECTED PROBLEM SOLUTIONS 
SOLUTIONS FOR CHAPTER 1 
1.1 ΑΠΒ = {(Η,Η,Τ),(Η,Τ,Τ)}; 
AöB = {(Η,Η,Η),(Η,Τ,Η), 
(Τ,Η,Τ), 
(T,T,T),(H,H,T),(H,T,T)};AC 
= 
{(T,H,H),(T,T,H),(T,H,T),(T,T,T)}; 
AcnBc 
= {(T, H, H), (T, T, H)}- AnBc 
= {(H, T, H), (H, H, H)} 
1.2 a) A ΓΊ B Π Cc b) A Π B Π C c) A Π Bc Π Cc d) Λ U B U C e) E = 
{AnBcr\Cc)\j(AcnBnCc) 
u(AcnßcnC)u(AcnßcnCc) f) D = ELi{AnBnCc) 
u(Ac n B n C) u(A n Bc n C) 
1.3 a){(2,2),(2,3),(4,2)}c)0 
1.5 a) ß = U?=1Ai b) C = D?=1i4? c) D = υ?=1 Π?=1 (Λ nAj) d ) ß = CUD 
1.6 a)£i = A u s u C b ) i ; 2 = ( J4nßnC c)u(Anß cnC)u( J4 cnBnC)c) 
£ 3 = ß2U(AnßnC) d) EA = (AnBcnCc) 
u(A cnßnC c) 
u(AcnBcnC) 
u(Ac n ß c n cc) 
1.7 33%; 60% 
1.9 Qi = {0,Ω}; ξ>2 = {0,{1},{2,3,4},Ω}; 3 3 = {0, {1},{2}, {1,2}, {3,4}, 
{2,3,4}, {1,3,4}, Ω}; 3 4 = {0, {1},{2},{3}, {4}, {1,2}, {1,3}, {1,4}, {2,3}, 
{2,4},{3,4}, {2,3,4}, {1,3,4}, {1,2,4}, {1,2,3},Ω} 
563 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition.
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu
a 
Copyright © 2012 John Wiley &: Sons, Inc. 

564 
SELECTED PROBLEM SOLUTIONS 
1.13 a) <r({2}, {3}) = {0, Ω, {1}, {2}, {3}, {2,3}, {1,3}, {1,2}} b) Yes 
1 14 a) a= ^ b) M-45. 35 
±.ί·± 
a) Lt 
g 3 u) g 3 , g 3 , g 3 
1.18 No 
1 19 2 -4.2 
1.20 a) ygg b) jpg c) jgg 
1.21 No 
1.22 P(Afc) = £forfc = l,2, 
1.23 1 - Tilii-l)*-1® 
(1 - I)'"; 0-37937 
1.24 0.24763 
1 96 -^3-· Π5 
■ι··ώ" 216' 216 
1-28 
i 
1.29 0.583 
1.30 8.3479 x 10"5 
1-31 & 
1.33 a) 1 - p5(2 - p2) b) 1 - p4(2 - p2) where 
p=\ 
1.34 0.5687 
,10 
1.35 1 - 1 + i - Jf + · 
1 <17 
6 w 8 w 10 
i.o/ 
15 x 17 x 19 
.. + < ; _ 1 » 
n! 
- e - 1 
1.38 9.3778 x 10^; 0.43925 
i qq I- 4. i. 2. I 
3 ' 7 ' 
' 7 ' 7 
1.40 
1.41 
1.42 
1.43 
1.44 
5. 
6' 
a) 
1 
13 
2 
6 
1 
3 
1 b) 0.8748 
; 0.7159 
X 13 X 6 + 
0.205 
c) 
7 
12 
0.9318 
X 7 X 6 

SELECTED PROBLEM SOLUTIONS 
565 
13 
1.45 
1.46 \ 
1.47 0.43; §§ 
1.51 § 
1.52 
{V),{a,b},{a,c},{b,c},n} 
1.54 
1.63 
1.64 
13. JL 
84' 28 
a) 0.703704 b) 0.25926 c) 0.2 
a) 6.12 x 10"3 b) 0.9938 c) 3.1874 x 10~2 
1.66 
1-67 a) I ( [ f ] + [ | ] - [ £ ] ) b ) I 
SOLUTIONS FOR CHAPTER 2 
2.1 No 
2.2 ρ(Ω) 
2.3 E(X) = f 
2.4 a) | b) | c) 
' 0 
if y < - 2 
^ 
if - 2 < i/ < - 1 
2.6 Fy(y) = { 
A 
if 
- l < y < 0 
ϊδ 
if 0 < y < 1 
if 
if 1 < y < 2 
1 
if y > 2 
2.7 a) S = {1,2,3} 
b ) P ( X 3 = 3 | X 2 e { l , 2 } , X i = 3 ) = 0 a n d P ( X 3 = 3 | X 2 6 { l , 2 } ) 
2.8 7.5758 x 10"2; 4.8351 x 10"2 

566 
SELECTED PROBLEM SOLUTIONS 
2.9 a) c = 1.2 c) 0.25 d) 0.710 
0 
2.10 a ) c = f b ) F x ( x ) = \ 
f x - ^ 
i f 0 < x < l 
c) 0.74667 
if x <0 
if 
0<x 
if x> 1 
2.11 a) 0; 0.9375 b) /. *(*) = { 
2 - 2x 
if 0 < £ < 1 
0 
otherwise 
2.12 a) X is discrete; Y is mixed and Z is continuous b) 0.5; 0.3; 0.2 c) 0.5; 
0.75; 0.5 d) 0; 0.5; 0 
2.13 P(X = k)= 
2{n'J)+1, 
* = 1 , 2 , · · · , η 
2.14 a) c = 1 b) c"1 = In2 c) c"1 = ^ d ) c"1 = e2 - 1 
2.15 a) c = 7r"1 b) c = l 
2.16 a) c- 1 = 8 b) 0.70313 
2.18 a) Fx(x) = E i l o P ^ - 1 b) Fx(x) 
= 
' ' ^ ( f f i ^ 
2.19 a) P(X = i) = i, i = 1,2, · · · , 7 b) P(X < 2) = §; P(X = 5) = \ 
2.20 0.617 
2.21 P(X = -6000) = 0.23333, P(X = -3000) = 0.2, P(X = 0) = 0.025, 
P(X = 2000) = 0.33333, P(X = 5000) = 0.125, P(X = 10000) = 0.08334 
2.22 P(X = 0) = 0.18, P(X = 1000) = 0.27, P{X = 1800) = 0.27, P(X = 
2000) = 0.07, P(X = 2800) = 0.14, P(X = 3600) = 0.07 
2.24 Yes; No 
2.26 
Fd(x) 
= 
< 
0 
si 
x < I 
Φ si S - a ; < I 
s 
si 
τ^χ<1 
1 
si 
0 
Fc(x) 
= 
5x 
si 
x < | 
2 - i 
- 
§<*<§ 
1 
si 
x > | 
2.31 
Ε(Χ)=0Λ 
2.33 a) C~l = π b) 0.5 c) £(X) and VaT^A-) does not exist d) Fx(x) 
= 
Htan^x+f) 

SELECTED PROBLEM SOLUTIONS 
567 
2.34 lei- si 
*"3* 
36 ' 36 
2.35 a) μ = 1, σ2 = 0.0667 b) 0.94536 
2.36 a) μ = §§, σ2 = 6.6389 x 10~2 b) c = 0.5 
2.37 a ) c = i b ) E(X) = § and Var(X) = 50 ( | - £ ) 
2.40 Ρ(Χ = 0) = 0.08546, P(X = 1) = 0.37821, P(X 
= 2) = 0.40812, 
P(X = 3) = 0.12821 
2.45 a) C = 2 b) 1.5 
2.46 £(X) exist, Var(X) does not exist 
2.48 b) P(0 < X < 40) > ±§ 
2.49 a) if b) fc = 10 
2.50 b) E{Y) ~ 1.82, Var(y) ~ 0.003489 
2.51 ^ ( ί ) = | β " + § 
2.52 <px(t) = jj^i 
{eitb - eita) if t φ 0, <px(t) = 1 if t = 0 
2.53 vjx(i) = 1 if ί = 0, </?χ(ί) = 2=lcost if t φ 0 
2.54 a) Lower quartile =2; upper quartile =3; median lies in [2,3] c) E(X) 
does not exist, median = 5 
2.55 a) Mode 1 b) r = 7, λ = \ 
SOLUTIONS FOR CHAPTER 3 
s.i (;)(*)" 
3.2 0.608; 2 
3.3 0.2248 
3.4 0.87842; 0.12158 
3.9 E(X) = Var{X) = 3.9 
3.10 0.98752 
3.11 0.4335 
3.12 3.8812 x 10~4 

568 
SELECTED PROBLEM SOLUTIONS 
3.13X±g{±) 
3.15 a) 3.8305 x 10"8 b) 4.4179 x 10"2 c) 1.2379 x 10"3 
3.16 e"2 
3.17 5 
3.18 15,000 
3.20 a) 2.861 x 10"5 b) 5 c) 4 d) 9.8877 x 10~2 
3.21 0.9945 
3.22 P(X2 
= j) = pq^~\ 
j = 1,4,9, · · ·; P(X + 3 = j) = rf-*, j = 
4,5,6,··· 
3.23 a) 0.674% b) 73.5% 
3.24 a) 5.06 x 10 - 4 b) It is not correct 
3.25 0.0671 
3.26 0.96801 
3.27 76 
3.28 0.43; 0.57 
3.29 816; 169; 15 
3.30 0.78343 
3.31 2.07 x 10"5 
3.33 20; 120 
3.34 E{X) = -0.27154 
3.35 13 
3.36 a) 2 b) Does not exist 
3.37 240 
3.38 λ = k 
3.43 p = £ 
3.47 
-*±£ 
3.49 φχ(ί) = (ς + ρε«)η 
3.50 ipx{t) = βχρ(λ(εί( - 1)) 
3.51 6 

SELECTED PROBLEM SOLUTIONS 
569 
SOLUTIONS FOR CHAPTER 4 
4.1 a)i;i;^b):r = 1.3 
4.2 a) 0.1 b) 0.1 c) 0.1 
44 3. l 
4.10 0.6830 
4.11 a) i b) /y(y) = ±#(0,2)(y) 
4.12 a) /y(y) = exp(y)X^oofi)(y) 
b) /z(z) = \{ζ-2)~ϊΧ{2,φ) 
c) /w(u>) 
^^(l,<x>)H 
4.13 5.2 
4.14 a) 0.7265 b) 0.1337 c) 0.98163 d) 0.07636 e) 0.24173 
4.15 a) 3 b) 5.8896 c) 6.3556 
4.16 a) 18.307 b) 0.68268 c) 6.6257 d) 44.3141 e) 0.072; 0.989; 11.808 
4.17 a) 92 b) 57 
4.18 89.97%; 5.82%; 84.2% 
4.19 Normal distribution with mean 5μ — 1 and variance 25σ2 
4.21 No, calculate, for example, P(4 < X < 9) 
4.22 0.17619 
4.23 a = 3.87 
4.27 54,000 
4.29 0.28347 
4.30 0.60653 
4.32 a) e~3 b) e"1 
4.34 a) fY(y) = Xexp(y - Aexp(y)), y € R 
4.35 a) F(t) = 1 
■iftW'-i) X[0,oo)(t) 
b) F(t) 
l-e-Tt-rftV'-V 
^[Ο,οο) W 

570 
SELECTED PROBLEM SOLUTIONS 
4.38 F(t)=(l-ik)*[0,oo)(i) 
4.39 F(t) = [l -exp ( - ^ + i ) ] 
Xp^t) 
4.41 0.275 
4-46 yfi 
4.48 g is the inverse of the standard normal probability density function 
4.53 Standard Cauchy distribution 
SOLUTIONS FOR CHAPTER 5 
5.9 a) 0.3 b) 0.9 d) P(Z = -2) = 0.1, P(Z = -1) = 0.2, P(Z = 0) = 
0.3,P(Z=1) = 0.4 
5.11 a = 0.01, ß = 0.3, 7 = 0.1, η = 0.03, κ = 00.04, δ = 0.02 
5.12 a) P(X = Ο,Υ = 0) = ^ , Ρ(Χ = Ο,Υ = 1) = £ , Ρ(Χ = 0,Γ = 2) = 
£ , ρ ( χ = i , r = ο) = jjL, Ρ ( Χ = i , y = ΐ) = ±, Ρ(Χ = 2,Υ = ο) = £ b) 
£ ( * ) = &, Ε{Υ) = if 
5.13 b) £(X) = ^ , Ε(Κ) = ±Α2 
5.14 a) 6 b) 6 
5.16 a) 3.7308 χ 10"2 b) 9 
5.17 a = b = k = h=±,d=\, 
e = f = ±; E{XY) = 0 
5.18 a) P(9.4) b) 0.29 
5.19 P(Z = - 1 , W = 1) = ^ , P(Z = 0,W = 0) = \, P(Z = 0,W = 2) = 
£ , P(Z = 1, W = 1) = I P(Z = 1, W = 3) = i , P(Z = 2,W = 0) = &, 
P(Z = 2,W = 2) = ^ , P ( Z = 3 , W = 1 ) = ^ 
5.20 ^ ; 0.1251 
5.22 -1 
5.23 0.35185 
5.25 No 

SELECTED PROBLEM SOLUTIONS 
571 
5.28 9 - 2 ^ 2 
5.32 £7(ΛΓ) = m (=±i) 
5.33 E(X) = Q (^)*"1 
(my-k 
5.34 £(X) 
= 365-(^-(iD^-rdltr1 
5.41 Yes, f(x,y) 
= ^ ^ η , 
x>0,yeR 
5.42 a) \ b) fx(x) 
= fY{x) = ±(cosx + sinx), x € (0, f) 
5.43 b) £ 
5.44 b) 0.25 c) 0.30556 
5.46 0.5 
5.47 i 
5.48 a) | b) | 
5.52 a) fz(z) 
= 2 [z - \ (l - e~x*)] *(0,ι)(ζ)+2λβ-λ* [±ex - £ ( e A - 1)] X[1<oo)(z) 
*>)£ 
5.55 a) fz(z) 
= λβχρ(-λ | z \)X{0,oo)(z) b) / f f W = λ (l + ^
) 
e x p ( - A ^ -
5.56 b) | 
5.57 Cauchy 
5.59 f(yi,y2) 
= <*(o,i)(3/i)X(o,i)(2/2) 
5.61 fv{x) = l(3x)2 
exp(-3x)X(0iOu)(x) 
5.62 /*0»0 = ϊ ( ΐ - τ ) * ( ο . 2 ) ( * ) 
5.63 a) 27.7 b) 0.32 c) 4.26 
5.64 F^ 
5.71 Xl 
5.72 
Λ ^ 
5.73 0.5464 
5.74 ί ( η_ υ 

572 
SELECTED PROBLEM SOLUTIONS 
SOLUTIONS FOR CHAPTER 6 
6.2 a) /(x,y) = { | 
l ^
c H
X 
< * b) fY(y) = -(lnx) X ( 0, 1 ) (y) 
6.3 E{Z) =ρλ = Var (Z) 
6.4 a) | b) I c) i 
_ „ , 
, , , 
( xe~xy 
if x > 0 and y > 0 
6.5 / y | x (ι,Ιζ) = | 
0 
Q t h e r c a s e s 
(y + l) 2xe- x^ + 1' 
if x > 0 and y > 0 
fx\y (x\y) - Ί 0 
o t h e r c a s e s 
6.6 a) X L M(3,1); Y ± AT(3,1) b) fY]x(y\2) 
= 5 ^ 6 ) e xP {" 2*536 (» " 2· 2) 2} 
c) c = 3.187 
6.7 b) £ ( X I y = 1) = 1; E{Y \ X = 1) = § 
6.9 § 
6.11 1.909 
6.12 a) £ (X | Y = 0) = - | ; £ ( X | Y = 1) = § b) £(X) = | 
6.15 a ) p x , y ( x , y ) = ( * ) ( i ) x § for y = 0, · · · ,x and x = 1,2 b) £ (X | Y = 0) = 
f; E (X I Y = 1) = §; E (X \ Y = 2) = 2 
6.16 1 + p 
6.17 a) 8.8492 x 10"2 b) § for y > 0 c) (x + 1) for x > 0 
6.20 1.3137 
6.22 Var (Y \ X = 0) = §; Var (Y | X = 1) = ±; Var (Y | X = 2) = 0 
6.23 f 
6.25 £(X|Y = y) = f±f* 
6.26 Ε(Υ\Χ 
= 
χ)-*=ζ 
4+3y 
—a 
2 
6.27 a) E(X \ Y = y) = 2 % ^ b) E(X* \ Y = y) = 1(1 + y2) c) 
l+J/) 2-8( 
18(1+1/)* 
Var(X I Y = y) = 2 i l ± ^ Ü ^ M i ± ^ ! l ! 
6.28 7 
6.29 a) | b) |f 
6.30 2 
6.31 a) 6 b) 7 c) 5.8192 
12. 9. 6. 3. 
5 ' 5' 5' 5' 
" • " ^ 
s> si s ' S' 
u 

SELECTED PROBLEM SOLUTIONS 
573 
SOLUTIONS FOR CHAPTER 7 
7.2 Y = λί(μ, Σ) where μ = (-2,1) and Σ = (™ 
~E 
7.3 a = - 2 
7.6 a) Y = 7V(/i, Σ) where μ = (0,0) and Σ = (_^ 
"* J 
7.8 P (X > 0, Y > 0, Z > 0) = | + ± {sin-1 pi + sin - 1 p2 + sin - 1 p3} 
7.9 / {x, y, z) = 2KJ230K 
exp {-555 (39x2 + 36y2 + 26z2 - Uxy + 36xz - 38y2) } 
7.12 7V(0,3) 
7.13 7V(2,1) 
7.15 7V(0,1) 
SOLUTIONS FOR CHAPTER 8 
8.6 f 
8.10 E{X3) > 8; E(\nX) 
< In 2 
8.15 0.8475 
8.16 0.99324 
8.17 0.9922 
8.18 0.003 
8.19 66564 
8.20 4096 
SOLUTIONS FOR CHAPTER 9 
9.1 a) Cov{Xs,Xt) 
= E (^- cos^t 
- sj\ b) Yes 
9.2 Yes 

574 
SELECTED PROBLEM SOLUTIONS 
9.7 a) 0 - absorbing, {1,2} - positive recurrent, {3,4} - transient b) ( π ^ ) = 
( § i ) d ) * 
9.8 a) 0.212 b) 0.0032 
9.9 a) {5i,5a} - Transient, class of positive recurrent {53,54,5s}, λ(53) 
IS 
20 
15-1 
45' 45' 45 I 
A(54) = A(55) = l b ) ( 0 , 0 , i 2 , i , i | ) 
9.10 a) i\f 
= p » - V for j < n b) Ä
Ä 
+ -5* 
j0 
~ V 
^ 
1 U I J - " "' (p-q)(10pq) 
"·" p(l-pq) 
9.11 a) C(0) = {0,1,2} is a class with positive recurrent states b) Pn = 
3 0 ° \ 
( ° ! ° \ 
0 
1 0 I if n is even, P n = I | 
0 
\ 
I if n is odd c) Does not exist 
\ o \ ) 
\o 
i o / 
9.12 a) C(0) = {1} - transient, C(l) = {0,2} - class of positive recurrents, 
C(2) = {3,4} - class of positive recurrents b) (±,0, 5,0,0); (0,0,0, \, \) 
9.13 a) All states are positive recurrent, aperiodic b) (||, ^ , ^ , ^ , p ) 
/ ( 1 - α ) 2 
2 α ( 1 - α ) 
a2 
9.14 a) Ρ = 
0 ( 1 - α ) 
( 1 - α ) ( 1 - 0 ) + α£ 
α(1 - /3) | b) (1-α) 2[(1-
\ 0 
0 
1-/3 
α)2 + 2α/3] 
9.16 b) f f i = ^ ( T § 5 ) ' , i = 0,l,-
α ' " ' 
W V 24' 24' 24' 2 4 / 
9.21 a ) e - 2 ^ ^ - b ) l - e - 2 0 A 
- 2 
2 
0 
1 ,Λ ι _ _ _ , 
^5' 5 ' 5' 
9.25 a ) Q = I 1 
- 3 
2 
1 c) (± §,§) 
0 
2 - 2 
9.26 a) 0.909 b) f c) 
^ 
9.28 a) (£)(1 - e-At)fce-(n-fc)At) fc = 0,1, ■ · · ,n b) ne~xt 
9.31 a) e- 5 b) 20 c) 50 
9.33 b) αι,α, 
= - ( ^ )
±
v f ^ ^ . reliability = 
1
-
^
-
;
^
^
-
l*i 
( 
» 2 ( 0 2 — 0 1 ) 

SELECTED PROBLEM SOLUTIONS 
SOLUTIONS FOR CHAPTER 10 
10.1 4.047 
10.2 a) 0.0223 b) 0.1705 
10.3 4 minutes 
10.4 a) 2.81 b) 2.5371 
10.5 Pn=<£?$/a, 
n = 0,l,··· ,c where p = ± 
10.6 a) 6.06 cars b) 12.3 minutes 
10.8 ^ 
10.9 b) πη - ^o_'pi/v, 
n = 0,1, · · · ,c where p ■■ 
SOLUTIONS FOR CHAPTER 11 
11.13 Yes 
11.16 Yes 
11.17 
3(t-s)2 
11.19 Λ/"(0,30) 
11.21 
λί(0,£) 
11.23 a) dXt = 3B2dBt + \Btdt 
b) dYt = Btdt + tdBt 
(c + \a2) Ztdt + 
aZtdBt 
11.24 E{It(B)) = 0 and E(It(B)2) 
= I (e4 - l) 
11.25 arctanßt + /0' (1+^2)2da 
11.26 e ß'-5' - 1 
11.28 yt - r0 + 4i2 + /„' £ sds + /0'(2s + 3)dBe 
11.29 a) Xt = - | t + | B t , b) dZt = ±ZtdBt 
11.30 Zt = 
Z0e-t+2Bt 
11.31 rt = r0e-* + 6 ( 1 - e _ t) + σ /„* e-<*-*>dBe 

576 
SELECTED PROBLEM SOLUTIONS 
SOLUTIONS FOR CHAPTER 12 
12.1 r = 8% 
12.3 0.8667 and $1.64 
12.4 p* = 0.541 and C0 = 7.44 
12.5 P0 = 4.92 
12.6 p* = 0.6523 and C0 = 1.266 
12.7 a) V0 = 142.15 
b) «i = 1.09 and βι = 36.37 
12.11 a) 2.1183 
b) 2.5372 
12.13 0.5373 
12.14 a) Call option value is $7.5133, Δ = 0.7747 and Γ = 0.0320 
b) Put option value is $1.3, Δ = -0.2253 and Γ = 0.0320 
12.17 0.2509 

REFERENCES 
1. Ash, R. (1972), Real Analysis and Probability, Academic Press, New York. 
2. Bauer, H. (1991), Wahrscheinlichkeitstheorie, 
Walter de Gruyter, Berlin. 
3. Bhat, U.N. (2008), An introduction to Queueing Theory: Modeling and Anal-
ysis in Applications, Springer, Boston. 
4. Bhat and Miller (2002), Elements of Applied Stochastic Processes, Wiley, 3rd 
edition, New Jersey. 
5. Bingham, N.H. and R. Kiesel (2004), Risk-Neutral 
Valuation: Pricing and 
Hedging of Financial Derivatives, Springer, New York. 
6. Black, F. and M. Scholes (1973), The pricing of options and corporate liabil-
ities, Journal of Political Economy, 81, 637-654. 
7. Bolch, G., S. Greiner, H. Meer and K.S. Trivedi (2006), Queueing Networks 
and Markov Chains: Modeling and Performance Evaluation with Computer 
Science Applications, John Wiley & Sons, 2nd edition, New Jersey. 
8. Brieman, J. (1992), Probability, SIAM, Philadelphia, PA. 
9. Cinlar, E. (1975), Introduction to Stochastic Processes, Prentice Hall, Engle-
wood Cliffs, New Jersey. 
10. Cox, J.C., S.A. Ross and M. Robinstein (1979), Option pricing: A simplified 
approach, Journal of Financial Economics, 7,229-263. 
11. Feller, W. (1968), An Introduction to Probability Theory and Its Applications, 
Volume I, John Wiley &; Sons, 3rd edition, New York. 
Introduction to Probability and Stochastic Processes with Applications, First Edition. 577 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

578 
REFERENCES 
12. Gorostiza, L.G. (2001), La probabilidad del siglo XX, Miscelänea Matemätica, 
No. 33, Sociedad Matemätica Mexicana, Mexico. 
13. Grimmett, G. and D. Stirzaker (2001), Probability and Random 
Processes, 
Oxford University Press, New York. 
14. Gross, D. and C M . Harris (1998), Fundamentals of Queueing Theory, Wiley, 
2nd edition, New York. 
15. Harrison, J.M. and D.M.Kreps (1979), Martingales and arbitrage in multi-
period securities markets, Journal of Economic Theory,20 , 381-408. 
16. Harrison, J.M. and D.M.Kreps (1981) Martingales and stochastic integrals in 
the theory of continuous trading, stochastic processes and their applications, 
11, 215-260 
17. Hernandez, A. and O. Hernandez (2003), Elementos de Probabilidad y Es-
tadistica, Textos 21, Sociedad Matemätica Mexicana, Mexico. 
18. Hernandez, F.M. (2003), Calculo de Probabilidades, Textos 25, Nivel Elemen-
tal, Sociedad Matemätica Mexicana, Mexico. 
19. Hoel, P., S.C. Port and C.J. Stone (1971) Introduction to Probability Theory, 
Houghton Mifflin Company, Boston, MA. 
20. Hoel, P., S.C. Port and C.J. Stone (1972), Introduction to Stochastic Pro-
cesses, Waveland Press, Prospect Heights, IL. 
21. Hull, J.C. (2009), Options, Futures, and Other Derivatives, Prentice Hall, 
seventh edition, New Jersey. 
22. Jacod, J. and P. Protter (2004), Probability Essentials, Springer-Verlag, 2nd 
edition, New York. 
23. Kahane, J.A. (1997), A century of interplay between Taylor series, Fourier 
series and Brownian motion, Bulletin of the London Mathematical 
Society, 
29, 257-279. 
24. Karatzas, I. and S. Shreve (1991), Brownian Motion and Stochastic Calculus, 
Springer, New York. 
25. Karlin, S. and H.M. Taylor (1975), A First Course in Stochastic Processes, 
Academic Press, 2nd edition, New York. 
26. Korn, R. and E. Korn (2000), Option Pricing and Portafolio 
Optimization, 
American Mathematical Society Providence, RI. 
27. Krengel, U. (2000), Einführung in die Wahrscheinlichkeitstheorie 
und Statis-
tik, Vieweg Verlag, Braunschweig. 
28. Lamberton, D. and B. Lapeyre (1996), Introduction to Stochastic 
Calculus 
Applied to Finance, CRC Press, London, 
29. Lawler, G.F. (2006), Introduction to Stochastic Processes, Chapman & Hall, 
Boca Raton, FL. 
30. Little, J. (1961) A proof for the queueing formula: L = XW, 
Operations 
Research, 9, 383-387. 
31. Medhi, J. (1994), Stochastic Processes, New Age International, New Delhi. 
32. Medhi, J. (2002), Stochastic Models in Queueing Theory, Academic Press, 
2nd edition, San Diego, CA. 

REFERENCES 
579 
33. Meyer, P.L. (1970), Introductory probability and statistical applications, Ad-
dison Wesley, Boston, MA. 
34. Mikosch, T. (1998), Elementary Stochastic Calculus, World Scientific, Singa-
pore. 
35. Munoz, J.M. (2002), Introduccion a la teoria de conjuntos, Facultad de Cien-
cias, Universidad Nacional de Colombia, Bogota, Colombia. 
36. Munoz, M. and L. Blanco (2002), Introduccion a la teoria avanzada de la 
probabilidad, Coleccion Textos, Unibiblos, Universidad Nacional de Colombia, 
Bogota, Colombia. 
37. Nelson, E. (1967), Dinamical Theories of Brownian Motions, Princeton Uni-
versity Press, Princeton, NJ. 
38. Oksendal, B. (2006), Stochastic Differential Equations: An Introduction with 
Applications, Springer, 6th edition, Berlin, Heidelberg. 
39. Ospina, D. (2001), Introduccion al muestreo, Facultad de Ciencias, Universi-
dad Nacional de Colombia. Bogota, Colombia. 
40. Rao, C.R. (1973), Linear Statistical Inference and Its Applications, John Wi-
ley & Sons, New York. 
41. Resnick, S.I. (1994), Adventures in Stochastic Processes, Birkhuser, Boston, 
MA. 
42. Rincon, L. (2011), Introduccion a los procesos estocasticos, Facultad de Cien-
cias, UNAM, Mexico. 
43. Ross, S.M. (1996), Stochastic Processes, John Wiley & Sons, New York. 
44. Ross, S.M. (1998), A First Course in Probability, Prentice Hall, New Jersey. 
45. Ross, S.M. (2007), Introduction to Probability Models, Academic Press, San 
Diego, CA. 
46. Royden, H.L. (1968), Real Analysis, Macmillan, New York. 
47. Schuh, H.J. (1986-1987) Stochastik I und II, Vorlesungsskript, Johannes 
Gutenberg-Universität Mainz. 
48. Searle, S.R. (1982), Matrix Algebra Useful for Statistics, John Wiley & Sons, 
New York. 
49. Shreve, S.E. (2004), Stochastic Calculus for Finance II: 
Continuous-Time 
Models, Springer, New York. 
50. Wackerly, D.D., W. Mendenhall and R. L. Scheaffer (2008), Mathematical 
Statistics with Applications, Cengage Learning, Belmont, CA. 
51. Williams, R.J. (2006), Introduction to the Mathematics of Finance, American 
Mathematical Society, Providence, RI. 
52. Willmott. P., S. Howison and J. Dewynne. (1995), The Mathematics of Fi-
nancial Derivatives: 
A Student Introduction, 
Cambridge University Press, 
New York. 
53. Wolff, R.W. (1982), Poisson arrivals see time averages, Operations Research, 
30, 223-231. 

GLOSSARY 
\a\ 
Absolute value of the number a. 
a « b 
a is approximately equal to b. 
A\ B 
Difference of the sets A and B. 
A U B 
Union of the sets A and B. 
An B 
Intersection of the sets A and B. 
Ac 
Complement of the set A. 
\A\ 
Number of elements of the set A. 
AT 
Transpose of the matrix A. 
(aij)mxn 
Matrix of size ra x n whose element in the ith row and 
jth column is a.ij. 
B 
Borel σ-algebra over M. 
Bn 
Borel σ-algebra over R". 
(™) 
n choose r (or combinatory n, r). 
C 
Set of complex numbers. 
EX 
Expected value of the random variable X. 
E (X | Y) 
Expected value of the random variable X given the random variable Y. 
E (X | B) 
Expected value of the random variable X given the event B. 
E (X | Q) 
Expected value of the random variable X given the σ-algebra Q. 
det(^4) 
Determinant of the matrix A. 
■j^f (x) 
Derivative of order r of the function / . 
Introduction to Probability and Stochastic Processes with Applications, First Edition. 581 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

582 
GLOSSARY 
/(·) 
Function of a real variable. 
fx\Y (· I v) 
Density function of the random variable X given Y = y. 
FX\Y (· | y) 
Conditional distribution function of the random variable X 
given Y = y. 
f(x+) 
Right-hand limit of f(x). 
f(x~) 
Left-hand limit of /(x). 
φχ (·) 
Characteristic function of the random variable X. 
Φ (·) 
Standard normal distribution function. 
φ (·) 
Standard normal density function. 
XA (·) 
Characteristic function of the set A. 
ln(x) 
Natural logarithm of x. 
τηχ(-) 
Moment generating function of the random variable X. 
μτ 
rth central moment around zero. 
μΓ 
rth central moment around the mean. 
N 
Set of natural numbers: {0,1,2, · · · }. 
P (A) 
Probability of the event A. 
P (A | B) 
Conditional probability of the event A given the event B. 
(x,y) 
Inner product of the vectors x , y 6 l ° . 
Q 
Set of rational numbers. 
R 
Set of real numbers. 
rf (A) 
Relative frequency of the event A. 
Variance of the random variable X. 
Standard deviation of the random variable X. 
Smallest σ-algebra containing the collection L. 
integer part, or floor, of t. 
Trace of the matrix A. 
Absolute value of the random variable X. 
Sequence of real numbers. 
Indicates that the random variables X and Y both have the 
same distribution. 
Indicates that the random variable X has a binomial distribution 
with parameters n and p. 
Indicates that the random variable X has a hypergeometric distribution 
with parameters n, R and N. 
Indicates that the random variable X has a Poisson distribution 
with parameter λ. 
Indicates that the random variable X has a negative binomial 
distribution with parameters k and p. 
Indicates that the random variable X has a geometric distribution 
with parameter p. 
Indicates that the random variable X has a uniform distribution 
over the interval [a,b]. 
σχ 
σχ 
a(L) 
[t] 
tr(A) 
1*1 
(Xn)neN 
X = Y 
X = 
B(n,p) 
X = Hg (n, R, 
X = 
V{\) 
X = 
BN{k,p) 
X = G{p) 
X=U[a, b] 
N) 

GLOSSARY 
583 
Λί(μ,σ2) 
Γ(Γ,λ) 
Εχρ (λ) 
Λ"2 
ß(a,b) 
Weibull (a ,ß) 
I(k) 
Indicates that the random variable X has a normal distribution 
with mean μ and variance σ2. 
Indicates that the random variable X has a gamma distribution 
with parameters r and λ. 
Indicates that the random variable X has an exponential distribution 
with parameter λ. 
Indicates that the random variable X has a chi-squared distribution 
with k degrees of freedom. 
Indicates that the random variable X has a beta distribution 
with parameters a and b. 
Indicates that the random variable X has a Weibull distribution 
with parameters a and β. 
Indicates that the random variable X has a ί-Student distribution 
with k degrees of freedom. 
F™ 
Indicates that the random variable X has an F distribution 
with m degrees of freedom on the numerator and 
n degrees of freedom on the denominator. 
M (μ, Σ) 
Indicates that the random vector X has a multivariate 
normal distribution with mean vector μ and 
variance-covariance matrix Σ. 
Euclidean norm of the vector X. 
► X 
Almost sure (or with probability 1) convergence of the sequence of 
- t o o 
random variables {Xn)n 
to the random variable X. 
► X 
Convergence in distribution of the sequence of 
—*-oo 
random variables (Xn)n 
to the random variable X. 
p 
► X 
Convergence in probability of the sequence of random variables 
—>oo 
(Xn)„ to the random variable X. 
Set of integer numbers. 
Set of positive integer numbers {1,2,3, · ■ · }. 
Replaces the symbol "=" in assignations or definitions. 

Index 
absorbed Brownian motion, 477 
absorbing state, 354 
aperiodic, 355 
aperiodic Markov chain, 355 
arbitrage, 500 
arbitrage opportunity, 506 
arithmetic mean, 317 
asset pricing 
first fundamental theorem, 508 
second fundamental theorem, 508 
basic principle of counting, 539 
generalization, 540 
Bayes estimator, 287 
Bayes' rule, 26, 270 
birth-and-death process, 378, 420 
Black-Scholes equation, 524 
Borel 
σ-algebra, see σ-algebra of Borel 
subset of R, 4 
Brownian motion, 473 
Levy's characterization, 480 
standard, 473 
Brownian motion reflected at the origin, 
477 
Brownian motion with drift, 478 
canonical filtration, 463 
canonical form of the transition matrix, 
359 
central moment 
around the mean, 89 
around zero, 88 
Chapman-Kolmogorov equations, 350 
Chernoff bounds, 334 
coefficient of variation, 90 
combinations, 543 
conditional expectation 
of a random variable 
given a σ-algebra, 282 
given an event, 280 
contingent claim, 498 
European, 506 
convergence 
almost sure, 322 
of random vectors, 329 
in ΙΛ, 320 
in distribution, 325 
of random vectors, 329 
in probability, 319 
of random vectors, 329 
convolution of density functions, 213 
correlation coefficient, 234 
Introduction 
to Probability and Stochastic Processes with Applications, 
First Edition. 
585 
By Liliana Blanco Castaneda, Viswanathan Arunachalam and Selvamuthu Dharmaraja 
Copyright © 2012 John Wiley & Sons, Inc. 

586 
INDEX 
covariance, 230 
covariance stationary process, 343 
determinant of a matrix, 549 
distribution 
i-Student, 225 
a posteriori, 31 
a priori, 31 
Bernoulli, 117 
beta, 172 
binomial, 96, 117 
negative, 133 
Cauchy, 175 
chi-square, 165 
discrete uniform, 115 
double exponential, 177 
Erlang, 165 
exponential, 165 
F (of Fisher), 226 
gamma, 161 
geometric, 133 
hypergeometric, 123 
Laplace, 177 
logistic, 180 
lognormal, 179 
Makeham, 186 
marginal, 193 
multinomial, 254 
normal, 151 
bivariate, 301 
multivariate, 295 
standard multivariate, 309 
of a random variable, 54 
of a random vector, 192 
of the difference of random vari-
ables, 219 
of the maximum and minimum, 215 
of the product of random variables, 
222 
of the quotient of random variables, 
223 
of the sum of random variables, 219 
Pareto, 187 
Poisson, 129 
standard normal, 153 
stationary, 377 
uniform, 146 
Weibull, 171 
eigenvalues of a matrix, 550 
eigenvector of a matrix, 550 
Erlang-B formula, 436 
Erlang-C formula, 431 
event, 3 
impossible, 5 
independent, 32 
mutually exclusive, 6 
simple, 5 
sure, 5 
events 
mutually independent, 34 
pairwise independent, 34 
evolutionary process, 343 
expectation 
conditional, 273 
of a continuous random variable, 
268 
of a discrete random variable, 
266 
of a function of a random vari-
able, 272 
expected value 
of a function of a random vector, 
228, 236 
of a random matrix, 236 
of a random variable, 80 
of a random vector, 235 
expiry date, 498 
exponential power, 177 
failure rate, 168 
filtration, 
462 
financial derivative, 498 
finite-dimensional 
distributions of the pro-
cess, 341 
formula 
Black-Scholes, 514 
CRR, 514 
Little's, 422 
Stirling, 158 
forward, 500 
function 
beta, 172 
characteristic, 99 
joint, 247 
conditional density 
of continuous random variables, 
267 
conditional distribution 
of continuous random variables, 
268 
of discrete random variables, 266 
conditional mass 
of discrete random variables, 265 
confiability, 168 
cumulative distribution 
joint, 198 
marginal, 199 

INDEX 
587 
density 
Standarized Cauchy, 176 
distribution, 55 
generating 
probability, 293 
indicative, 53 
moment generating, 95 
joint, 242 
probabibility mass, 63 
probability density 
joint, 203, 204 
marginal, 204 
probability generating, 93 
probability mass 
joint, 192 
risk, 168 
future, 501 
geometric Brownian motion, 478 
greeks, 525 
delta, 525 
gamma, 526 
rho, 527 
theta, 526 
Vega, 527 
hedging, 500 
independence 
of n random variables, 215 
of n random vectors, 215 
independent family, 34 
independent random vectors, 210 
inequality 
Cauchy-Schwarz, 231 
Chebyschev's, 313, 315 
Jensen, 334 
Markov's, 314 
initial distribution, 347 
inner product, 549 
interarrival time, 383 
intrinsic value, 499 
Ito process, 486 
joint moment, 246 
Kendall notation, 418 
Langevin equation, 489 
law of large numbers 
Bernoulli, 317 
strong, 323 
weak, 313, 316, 317 
law of the unconscious statistic, 84 
Loss system, 436 
machine repair problem, 459 
market 
arbitrage-free, 506 
complete, 506 
finite, 504 
incomplete, 507 
viable, 506 
Markov chain, 344 
continuous-time, 344, 371, 420 
discrete-time, 344, 347 
embedded, 377 
homogeneous, 347 
irreducible, 354 
Markov process, 343 
Markov regenerative process, 404 
martingale, 461 
Q - , 507 
continuous-time, 471 
discrete-time, 462 
martingale transformation, 467 
matrix 
correlation, 239 
diagonal, 550 
fundamental, 359 
nonsingular, 550 
orthogonal, 550 
positive-definite, 550 
positive-semidefinite, 550 
singular, 550 
symmetric, 550 
variance-covariance, 236 
mean value function, 387 
measure 
conditional probability, 22 
equivalent martingale, 507, 520 
invariant, 376 
invariant probability, 369 
probability, 8 
risk-neutral, 507, 520 
median, 110 
mode of a random variable, 111 
Model 
Polya Urn, 465 
model 
binomial, 509 
CRR, 509 
multi-period, 512 
urn, 16 
multinomial coefficient, 545 
natural filtration, 463 
norm of a vector, 549 
numeraire, 504 

588 
INDEX 
option, 498 
American, 499, 516 
Asian, 499 
barrier, 499 
call, 498 
European, 499 
lookback, 499 
perpetual, 499 
put, 499 
P-K formula, 441 
parameter 
location, 152 
scale, 152 
parametric space, 340 
PASTA, 421 
payoff, 501 
diagram, 502 
period of state, 355 
permutations, 541 
Poisson process, 380, 381 
compensated, 472 
compound, 388 
nonhomogeneous, 386 
position 
long, 500 
short, 500 
price process, 504 
stock, 509 
discounted, 511, 519 
probability 
conditional, 20 
geometric, 35 
probability vector, 11 
pure birth process, 412 
pure death process, 379 
put-call parity, 502 
quartile, 110 
lower, 110 
upper, 110 
queueing system 
G / / M / 1 , 445 
GI/M/l/N, 
452 
M / G / l , 441 
M/G/l/JV, 448 
M / M / l , 419 
M/M/l/N, 
427 
M/M/c, 
431 
M/M/c/c, 
436 
random experiment, 1 
discrete, 2 
random matrix, 236 
random variable, 51 
continuous, 61, 67 
discrete, 61 
mixed, 61 
random variables 
continuous, 203 
independent, 210 
independent and identically distributed, 
210, 316 
random vector 
n-dimensional, 192 
continuous, 203 
discrete, 192 
relative frequency, 6 
renewal equation, 392 
sample path, 340 
second-order process, 342 
semi-Markov process, 400 
sequence 
decreasing, of events, 9 
increasing, of events, 9 
σ-algebra, 3 
generated, 4 
of Borel over R, 4 
of Borel over E n, 5 
total, 4 
trivial, 4 
σ-field, see σ-algebra 
space 
measurable, 5 
probability, 8 
discrete, 11 
Laplace, 14 
sample, 2 
discrete, 2 
standard deviation 
of variation, 89 
state 
recurrent, 357 
null, 367 
positive, 367 
transient, 357 
state space, 340 
state transition diagram, 350 
stationary process, 342 
stochastic differential equations, 482 
stochastic matrix, 347 
stochastic process, 340 
strategy 
admissible, 506 
arbitrage opportunity, 506 
attainable, 506 
replicating, 506 
self-financing, 505, 518 

super hedging, 517 
trading, 505, 518 
strike price, 498 
submartingale, 463 
supermartingale, 463 
swap, 501 
theorem 
central limit, 160 
multivariate, 331 
univariate, 329 
continuity, 326 
Moivre-Laplace, 160 
total probability, 25 
transformation, 218 
time value, 500 
trace of a matrix, 549 
transition probabilities, 347 
transition probability matrix, 347 
m-step, 351 
one-step, 349 
transpose of a matrix, 549 
value 
portfolio, 505, 518 
value process, 518 
discounted, 519 
variance, 89 
conditional, 291 
volatility, 518 
historical, 528 
implied, 529 
waiting time, 383 
wealth process, 505 

