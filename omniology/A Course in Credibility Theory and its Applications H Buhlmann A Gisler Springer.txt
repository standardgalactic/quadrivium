
Hans Bühlmann
Alois Gisler
A Course
in Credibility Theory
and its Applications
ABC

Professor Hans Bühlmann
Swiss Federal Institute
of Technology Zurich
ETH Zentrum, HG
Rämistrasse 101
8092 Zürich
Switzerland
E-mail: hbuhl@math.ethz.ch
Professor Alois Gisler
Winterthur Insurance Company
WSAN
Römerstrasse 17
8401 Winterthur
Switzerland
E-mail: alois.gisler@winterthur.ch
Mathematics Subject Classiﬁcation: 91B30, 62P05, 62J05, 62C10, 62C12
Library of Congress Control Number: 2005930887
ISBN-10 3-540-25753-5 Springer Berlin Heidelberg New York
ISBN-13 978-3-540-25753-0 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microﬁlm or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9,
1965, in its current version, and permission for use must always be obtained from Springer. Violations are
liable for prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springeronline.com
c⃝Springer-Verlag Berlin Heidelberg 2005
Printed in The Netherlands
The use of general descriptive names, registered names, trademarks, etc. in this publication does not imply,
even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws
and regulations and therefore free for general use.
Typesetting: by the authors and TechBooks using a Springer LATEX macro package
Cover design: design & production GmbH, Heidelberg
Printed on acid-free paper
SPIN: 11320753
41/TechBooks
5 4 3 2 1 0

Dedicated to Gerdi and Marlis

Preface
The topic of credibility theory has been for many years — and still is — one of
our major interests. This interest has led us not only to many publications,
but also has been the motivation for teaching many courses on this topic
over more than 20 years. These courses have undergone considerable changes
over time. What we present here, “A Course in Credibility Theory and its
Applications”, is the ﬁnal product of this evolution.
Credibility theory can be seen as the basic paradigm underlying the pricing
of insurance products. It resides on the two fundamental concepts “individual
risk” and “collective” and solves in a rigorous way the problem of how to
analyse the information obtained from these sources to arrive at the “insurance
premium”. The expression “credibility” was originally coined for the weight
given to the experience from the “individual risk”.
Credibility theory as a mathematical discipline borrows its methods from
many ﬁelds of mathematics, e.g. Bayesian statistics, L2 Hilbert space tech-
niques, least squares, and state space modelling to mention only the most
important ones. However, credibility theory remains a lifeless topic if it is not
linked closely with its applications. Only through these applications has cred-
ibility won its status in insurance thinking. The present book aims to convey
this dual aspect of credibility and to transmit the ﬂavour of the insurance
applications also to those readers who are not directly involved in insurance
activities. In particular we are convinced that many insurance applications
have the potential to be powerful tools that could also be used in the wider
area of ﬁnance.
The present text would have never been completed without the great help
we received from many colleagues, friends and coworkers. In the ﬁrst place
we want to mention Paul Embrechts, who encouraged us to write this book.
Without his constant support and advice we probably would never have suc-
ceeded in ﬁnishing this text. During the time of writing and rewriting our
(several) manuscripts we proﬁted from discussions with colleagues in Win-
terthur and Zürich, especially Anne Sheehy, Mario Wüthrich, Peter Eberle,
Graham Masters, Werner Stahel and Peter Bühlmann. Anne translated a ﬁrst

VIII
Preface
German version into English, she and Mario assisted us in the summer school
where the text was tested, Peter E. was a big support for conceiving the exer-
cises, Graham has checked the English language in the ﬁnal manuscript, and
Werner and Peter B. provided advice on statistical issues whenever needed.
Also the referees who judged an earlier version, have taken great care in read-
ing our text and making valuable suggestions. A great “thank you“ goes also
to Howard Waters and to Heriot-Watt University. It provided the good at-
mosphere for a two-month sabbatical for one of the authors to write part of
the book.
Our book would not have been possible without the great community of
researchers who have worked in the area of credibility. Some names of these
researchers appear in the bibliography of our book, but many do not, since
we have only listed those publications which are related to our text. We want
to remember explicitly those researchers who are already dead but have had
a decisive inﬂuence in the ﬁeld: Charles A. Hachemeister, William S. Jewell,
Etienne de Vylder and Erwin Straub.
The physical writing of this book was done by Elisabeth Werner. She typed
and retyped all our versions and was a wonderful support for improving the
script quality of the presentation. We owe her a very special “thank you”.
We also proﬁted from the generosity of our employers, ETH Zürich and
Winterthur Insurance Company. These two institutions have provided us with
the logistics necessary for the whole book project. The sustained support given
by Winterthur to the actuarial programme at ETH is an excellent example of
a fruitful cooperation between academia and practice.
Writing this book turned out to be much more time consuming than an-
ticipated. This time was mainly taken to the detriment of our families. As a
sign of gratitude we therefore want to dedicate this book to our wives Gerdi
and Marlis. Their support goes, of course, far beyond this project. They have
given to us lasting companionship, sharing with us happy and di!cult times.
Hans Bühlmann and Alois Gisler
August 2005

Notes and Comments
Notes on Chapter 1 and Chapter 2
These two chapters give the basic framework for the whole book: Chapter 1
does so using common language, Chapter 2 uses mathematical modelling.
The basic understanding of insurance risk is built upon two fundamental
concepts, the individual risk and the collective. The insurer has typically little
knowledge about the individual risk, but quite extensive statistical informa-
tion about the collective and possibly about subcollectives. The theoretical
concept of a homogeneous collective is a ﬁction. Credibility theory relies on
the more realistic concept of a heterogeneous collective.
The fundamental mathematical paradigm underlying credibility theory is
the “two-urn model”: ﬁrst the characteristics of the individual model (para-
meter &) are drawn using a distribution U from the collective population. The
claims produced by the individual risk are then generated by a claims distri-
bution F&. This paradigm coincides — in abstract analogy — with the Bayes
model in mathematical statistics.
It is interesting to note that the Poisson—Gamma model appeared as early
as 1929 in [Kef29], where it is used for pricing of group life insurance. Ove
Lundberg [Lun40] and Arthur Bailey [Bai50] seem to be the ﬁrst actuaries to
recognize the general Bayesian structure. It is not clear how they interpreted
the role of the prior distribution U. But it is obvious that in insurance ap-
plications the prior distribution must be understood as the description of the
collective. The method of how to infer the distribution U from collective data
has — in the abstract context — been advocated by Herbert Robbins [Rob55]
under the heading “empirical Bayes”.
Whoever is looking for a concise description of credibility theory should
read Ragnar Norberg’s article in the actuarial encyclopedia [Nor04]. This ar-
ticle reduces credibility to its essential mathematical structure, hence giving
an excellent insight into the subject from a theoretical point of view.
As a textbook on Bayesian statistics we recommend DeGroot [DeG70].
The explicit calculation of the posterior mean is one of the standard tasks

X
in Bayesian statistics. In an actuarial context such calculations date back to
Ove Lundberg [Lun40], Arthur Bailey [Bai50], Bruno De Finetti [DF64] and
for the general formulation in the case of conjugate exponential families to
William S. Jewell [Jew74a].
In the early sixties, the Poisson—Gamma model served as the mathematical
basis for the development of Bonus—Malus systems in motor liability insurance
(see [Bic64], [Del65]), which form one of the most prominent applications of
Bayesian statistics in the insurance context.
Notes on Chapter 3 and Chapter 4
For practical use it is convenient to require that the estimates for the individ-
ual premium be linear in the data. There is a considerable freedom of choice
for this linearity, as it may refer to transformations of any kind of the original
data.
In a simple context (Bühlmann model) this linear estimate turns out to
be a weighted average between the individual and the collective mean. Such
weighted means (credibility formulae) were already used by American actuar-
ies at the beginning of the 19th century (Whitney [Whi18], Perryman [Per32])
in the context of workmen’s compensation insurance. The link with Bayesian
statistics was made by Arthur Bailey [Bai50] (see also notes on Chapters 1
and 2).
Mowbray [Mow14], [Mow27] tried to derive credibility formulae on purely
classical statistics arguments using conﬁdence bounds to arrive at “full credi-
bility” (i.e. giving weight 1 to the individual estimate). If n0 observations give
you full credibility, the weight
p
n/n0 is given to the individual estimator if
you have only n < n0 observations. This rather heuristic approach is called
“limited ﬂuctuation theory”. According to our view it is only of historical
interest. See also Longley and Cook [LC62] for a description of this method.
The model treated in Chapter 4 (Bühlmann—Straub) is widely used in
practice. The reason is that it combines credibility thinking with the concept of
the loss ratio, which is one of the most frequently used statistics in insurance.
For surveys on credibility theory we recommend W.S. Jewell [Jew76b], and
M.J. Goovaerts and W.J. Hoogstad [GH87]. An extensive bibliography is given
by DePril, D’Hooge and Goovaerts [DPDG76] and in De Wit [Wi86]. Recent
textbooks on credibility theory are [DKG96] and [Her99].
Notes and Comments

XI
Notes on Chapter 5
As credibility theory deals with estimators which are linear in the data or
in transformed data, the question arises of how to choose such transforma-
tions. This chapter studies the transformation by truncation. Truncating is
very useful in the presence of large claims. The general idea of using trans-
formations goes back to de Vylder [DV76b], [DVB79]. His goal was the search
for transformations which are optimal within the least squares framework.
Theoretically this goal can be achieved by solving an integral equation of the
Fredholm type. Gisler’s [Gis80] approach to restrict the transformations to
simple truncations turns out to be more fruitful in practice. In this approach
the truncation point is the only one-dimensional parameter to be optimized.
From a pragmatic point of view even this optimization may often be left aside.
The truncation point is then chosen by pure a priori judgement. The point is
that truncation avoids considerable premium jumps due to one or a few large
claims. Such premium jumps are very often considered as violating the very
purpose of insurance.
Other possibilities in the framework of one-dimensional methods of deal-
ing with large claims such as combining credibility and robust statistics are
mentioned at the end of Chapter 5 without going into details and referring
to the literature. The topic of treating large claims is resumed under multidi-
mensional credibility in Chapter 7.
Notes on Chapter 6
Hierarchical models generalize the “two-urn model” into a “many-urn model”.
In such models the risk characteristics of the individual risk are drawn from
a collective urn whose risk characteristics are drawn from a further parent
urn etc. Such hierarchies appear very naturally in the tari structure of an
insurance company.
Jewell [Jew75c] and Taylor [Tay79] have introduced the concept of hierar-
chical credibility. Sundt [Sun80] and Norberg [Nor86] have clariﬁed the basic
model assumptions and given important insights into the model structure.
In the context of hierarchical credibility the Hilbert space technique proves
particularly useful as it replaces tedious calculations by the use of the more
intuitive projection operator. The iterativity property of this operator is cru-
cial in this context. This route of description of the hierarchical credibility
model is followed in this text. It essentially summarizes Bühlmann and Jewell
[BJ87].
Notes and Comments

XII
Notes on Chapter 7 and Chapter 8
The basic set-up is the idea that we have to estimate a real-valued vector
µ () = (µ1 () , . . . , µn ())
0
.
In the abstract setting of Chapter 7 we assume that we have an observation
vector of the same dimension
X = (X1, . . . , Xn)
0
such that
E [X |] = µ () .
This vector X may be obtained by data compression from the raw data. Such
an abstract set-up is convenient and covers most practical applications. It
does not include the case where we have fewer observations than parameters
to estimate. This case is, however, treated in Chapters 9 and 10 and is also
intuitively much easier to understand in a recursive estimation procedure as
treated there. In the multidimensional philosophy of Chapters 7 and 8 regres-
sion can be treated as a special case of data compression.
Multidimensional credibility was introduced by Jewell [Jew73]. By the ap-
propriate use of matrix notation, the Jewell extension inherits the weighted
average structure of the credibility estimator from the simple model.
Hachemeister’s credibility regression model [Hac75] is an extension of mul-
tidimensional regression as treated in classical statistics. The regression para-
meters become random. In this view it is natural to keep the classical assump-
tion of a design matrix of full rank smaller than the number of observations.
Already Jewell [Jew76a] has pointed out that in Bayesian regressions this as-
sumption could be dropped. He then continues: “However, to relate our results
to classical theory we shall. . . [keep the restriction]”. As already mentioned,
we follow here the route of Jewell, whereas in Chapters 9 and 10 the restriction
is dropped.
Although it is well known in classical statistics that one should work with
an orthogonal design matrix — whenever feasible — this pragmatic rule was
originally disregarded in the actuarial literature. This led the practitioners not
to use the credibility regression model as it often produced “strange results”.
This handicap is overcome by using orthogonal design matrices (see [BG97]).
Of course the corresponding orthogonal transformation may in some cases
produce parameters that are di!cult to interpret.
Finally it should be noted that in our approach (which is essentially Jew-
ell’s) the credibility regression model is a special case of multidimensional
credibility. One could as well have introduced multidimensional credibility as
a special case of the credibility regression model.
Notes and Comments

XIII
Notes on Chapter 9 and Chapter 10
The recursive procedure for credibility estimators is naturally tied to evolu-
tionary models: the parameters to be estimated vary in time. In such evo-
lutionary models our understanding of the collective as an urn, from which
the individual risk characteristics are drawn independently, reaches its limits.
If changes in risk parameters derive from common causes, the independence
assumptions can no longer hold. It is quite natural that the question of how
to model the collective recurs throughout these two chapters.
Early actuarial papers devoted to recursive credibility are [GJ75a], [GJ75b],
[Kre82], [Sun81], [Sun82]. The Kalman Filter was developed originally in an
engineering context [Kal60]. Its applicability in the insurance area has been
advocated e.g. by Mehra [Meh75], Zehnwirth [Zeh85], Neuhaus [Neu87]. Most
texts start with the most general form of the Kalman Filter and then specialize
the assumptions to obtain the credibility type formulae. In these two chapters
we go the opposite route. We build successively the understanding of the pro-
cedure by starting ﬁrst in a one-dimensional world and proceed from there to
more complicated models. This route shows quite clearly the connection with
the static (non-evolutionary) credibility models. It is important to note that
not all static credibility models can be evaluated recursively. The condition
(in a somewhat dierent setting) under which this is possible goes back to
Gerber and Jones [GJ75b].
Notes and Comments

Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Rating of Risks and Claims Experience in Insurance . . . . . . . . .
1
1.2
Mathematical Formulation of the Problem of Rating Risks . . . .
7
1.2.1
Individual Risk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.2.2
The Correct Individual Premium . . . . . . . . . . . . . . . . . . . .
8
1.2.3
The Risk Rating Problem in the Collective . . . . . . . . . . .
9
1.2.4
Formulating the Rating Problem in the Language of
Bayesian Statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
1.2.5
Summary. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
2
The Bayes Premium . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
2.1
Basic Elements of Statistical Decision Theory . . . . . . . . . . . . . . . 15
2.2
Bayes Risk and Bayes Estimator . . . . . . . . . . . . . . . . . . . . . . . . . . 16
2.3
Bayesian Statistics and the Premium Rating Problem . . . . . . . . 18
2.4
The Bayes Premium in Three Special Cases . . . . . . . . . . . . . . . . 21
2.4.1
The Poisson—Gamma Case. . . . . . . . . . . . . . . . . . . . . . . . . . 21
2.4.2
The Binomial—Beta Case . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
2.4.3
The Normal—Normal Case . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.4.4
Common Features of the Three Special Cases Considered 36
2.5
Conjugate Classes of Distributions . . . . . . . . . . . . . . . . . . . . . . . . . 38
2.5.1
The Exponential Class and Their Associated
Conjugate Families . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
2.5.2
Construction of Conjugate Classes . . . . . . . . . . . . . . . . . . . 46
2.6
Another Type of Example: the ParetoGamma Case . . . . . . . . 47
2.7
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
2.8
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
3
Credibility Estimators
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.1
Credibility Estimators in a Simple Context . . . . . . . . . . . . . . . . . 56
3.1.1
The Credibility Premium in a Simple Credibility Model
56
3.1.2
A General Intuitive Principle . . . . . . . . . . . . . . . . . . . . . . . 58

XVI
Contents
3.1.3
The Quadratic Loss of the Credibility Premium . . . . . . . 59
3.1.4
The Simple Bühlmann Model and the Homogeneous
Credibility Estimator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
3.2
Credibility Estimators in a General Set-Up . . . . . . . . . . . . . . . . . 64
3.2.1
Credibility Estimators as Orthogonal Projections in
the L2 Hilbert Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
3.3
Orthogonality Conditions and Normal Equations . . . . . . . . . . . . 71
3.4
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
4
The Bühlmann—Straub Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
4.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
4.2
Model Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
4.3
The Credibility Premium in the Bühlmann—Straub Model . . . . 81
4.4
Discussion and Interpretation of the Credibility Estimator
. . . 84
4.5
Quadratic Loss of the Credibility Estimator . . . . . . . . . . . . . . . . . 86
4.6
The Homogeneous Credibility Estimator in the Bühlmann—
Straub Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
4.7
Quadratic Loss of the Homogeneous Credibility Estimator . . . . 91
4.8
Estimation of the Structural Parameters 2 and  2 . . . . . . . . . . 93
4.9
Empirical Credibility Estimator . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
4.10 Credibility for Claim Frequencies . . . . . . . . . . . . . . . . . . . . . . . . . . 97
4.11 Credibility for Claim Sizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
4.12 Credibility for Risk Groups of Known Individual Contracts . . . 110
4.13 Modiﬁcation for the Case of Known a Priori Dierences . . . . . . 111
4.14 Example of Another Kind of Application
. . . . . . . . . . . . . . . . . . 113
4.15 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
5
Treatment of Large Claims in Credibility . . . . . . . . . . . . . . . . . . 125
5.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
5.2
Semi-Linear Credibility with Truncation in the Simple
Bühlmann Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
5.3
Semi-Linear Credibility with Truncation in a Model with
Weights . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
5.4
Further Methods for Treating Large Claims . . . . . . . . . . . . . . . . . 135
5.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
6
Hierarchical Credibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
6.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
6.2
The Hierarchical Credibility Model . . . . . . . . . . . . . . . . . . . . . . . . 145
6.3
Relevant Quantities and Notation . . . . . . . . . . . . . . . . . . . . . . . . . 146
6.4
Credibility Estimator in the Hierarchical Model . . . . . . . . . . . . . 148
6.5
Quadratic Loss in the Hierarchical Model . . . . . . . . . . . . . . . . . . . 159
6.6
Estimation of the Structural Parameters in the Hierarchical
Model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
6.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165

Contents
XVII
7
Multidimensional Credibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
7.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
7.2
The Abstract Multidimensional Credibility Model . . . . . . . . . . . 169
7.2.1
Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
7.2.2
The (Inhomogeneous) Multidimensional Credibility
Estimator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
7.2.3
The Homogeneous Credibility Estimator . . . . . . . . . . . . . 173
7.2.4
The Quadratic Loss of the Multidimensional
Credibility Estimators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
7.3
The Multidimensional Bühlmann—Straub Model
. . . . . . . . . . . . 177
7.3.1
Motivation and Interpretation. . . . . . . . . . . . . . . . . . . . . . . 177
7.3.2
Deﬁnition of the Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
7.3.3
Credibility Formulae in the Multidimensional
Bühlmann—Straub Model . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
7.3.4
Quadratic Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
7.3.5
Estimation of Structural Parameters . . . . . . . . . . . . . . . . . 185
7.4
General Remarks About Data Compression and Its
Optimality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
7.4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
7.4.2
General Multidimensional Data Structure . . . . . . . . . . . . 187
7.4.3
Optimal Data Compression . . . . . . . . . . . . . . . . . . . . . . . . . 189
7.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
8
Credibility in the Regression Case . . . . . . . . . . . . . . . . . . . . . . . . . 199
8.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
8.2
The Classical Statistics Point of View . . . . . . . . . . . . . . . . . . . . . . 199
8.3
The Regression Credibility Model . . . . . . . . . . . . . . . . . . . . . . . . . 201
8.3.1
The Standard Regression Model . . . . . . . . . . . . . . . . . . . . . 202
8.3.2
The General Regression Case (Hachemeister) . . . . . . . . . 205
8.3.3
Homogeneous Credibility Estimator and Quadratic Loss 208
8.4
The Simple Linear Regression Case (Linear Trend Model) . . . . 208
8.5
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
9
Evolutionary Credibility Models and Recursive Calculation 219
9.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
9.2
Recursive Credibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
9.3
Evolutionary Credibility Models . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
9.4
Evolutionary Models and Recursive Credibility . . . . . . . . . . . . . . 226
9.5
Recursive Calculation Method (Kalman Filter) . . . . . . . . . . . . . . 230
9.6
The Evolutionary Credibility Regression Model. . . . . . . . . . . . . . 238
9.7
Recursive Calculation in the Evolutionary Regression Model . . 239

XVIII
Contents
10.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
10.2 On the Embedding of the Individual Risk in a Collective . . . . . 252
10.3 Multidimensional Evolutionary Models . . . . . . . . . . . . . . . . . . . . . 253
10.4 Modelling a Collective with Both Joint and Individual
Movements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
10.5 Multidimensional Evolutionary Regression Models . . . . . . . . . . . 262
10.6 Decomposition into an Individual and a Common Component . 264
A
Appendix A:
Basic Elements from Probability Theory . . . . . . . . . . . . . . . . . . . 275
A.1 Random Variables, Distribution Functions and Moments . . . . . 275
A.2 Special Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
A.3 Multidimensional Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
A.4 Conditional Probability and Conditional Expectation . . . . . . . . 278
A.5 Two Useful Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280
B
Appendix B:
The Hilbert Space L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
C
Appendix C:
Solutions to the Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
C.1 Exercises to Chapter 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
C.2 Exercises to Chapter 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
C.3 Exercises to Chapter 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
C.4 Exercises to Chapter 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
C.5 Exercises to Chapter 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
C.6 Exercises to Chapter 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
C.7 Exercises to Chapter 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329
10
Multidimensional Evolutionary Models and Recursive
Calculation
251
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1
Introduction
1.1 Rating of Risks and Claims Experience in Insurance
The basic idea underlying insurance is that individuals, who have the “same”
exposure to a particular risk, join together to form together a “community-
at-risk” in order to bear this perceived risk. In modern society, this idea is
most often realized in the form of insurance. On payment of a premium,
the individuals in the “community-at-risk” transfer their risk to an insurance
company.
We consider an insurance company with a portfolio consisting of I insured
risks numbered i = 1, 2, . . . , I. In a well-deﬁned insurance period, the risk i
produces
•
a number of claims Ni,
•
with claim sizes Y ()
i
( = 1, 2, . . . , Ni),
•
which together give the aggregate claim amount Xi = PNi
=1 Y ()
i
.
We will refer to the premium payable by the insured to the insurer, for
the bearing of the risk, as the gross premium. The premium volume is the
sum, over the whole portfolio, of all gross premiums in the insurance pe-
riod. The basic task underlying the rating of a risk is the determination of
the so-called pure risk premium Pi = E [Xi]. Often, we use just the term
“risk premium”. The classical point of view assumes that, on the basis of
some objectively quantiﬁable characteristics, the risks can be classiﬁed into
homogeneous groups (risk classes), and that statistical data and theory (in
particular, the Law of Large Numbers) then allow one to determine the risk
premium to a high degree of accuracy.
In reality, of course, it is clear that a huge number of factors contribute to
the size of the risk premium. In order to have reasonably homogeneous risk
classes, one would have to subdivide the portfolio into a very large number
of classes. For example, if we were to use four characteristics to rate the risk,
then assuming that each characteristic had 10 possible values, this would lead

2
1 Introduction
to 10 000 risk classes. Many of these classes, by their very deﬁnition, will
contain very few risks and will therefore provide little statistical information
for rating future risks. On the other hand, if we subdivide the portfolio into
larger classes, the assumption of homogeneous risk proﬁles within the classes
becomes a ﬁction. In fact, it is clear that no risk is exactly the same as an-
other. For example, every car driver is an individual with his own personal
associated risk which is inﬂuenced by many factors, not least his particular
character and constitution. This observation leads to the following thesis.
Thesis: There are no homogeneous risk classes in insurance.
Indeed in practice, relatively few so-called risk characteristics are explicitly
used in the rating of risks. The segmentation of risk classes is relatively coarse.
There are a number of reasons why some characteristics, which would perhaps
be useful in determining the quality of a risk, are not considered.
a) They are not objectively quantiﬁable: for example, the temperament of a
car driver, or the work atmosphere in a ﬁrm.
b) They are di!cult to check: for example, the total number of kilometres
driven by an individual, or his abstinence from alcohol.
c) They are politically delicate: for example, sex, nationality, or mother-
tongue.
d) They would lead to excessive administrative work.
e) They would make the rating structure overly complicated and, as dis-
cussed above, the accurate estimation of the premium may be impossible
due to limited statistical information.
In general, we need to know what one should do, and indeed, what one can
do, in order to ﬁnd “fair” premiums. The following pragmatic considerations
can guide us:
•
The speciﬁc risk exposure of each risk has an impact on the observed
individual claim experience of that risk. However, the observed claim ex-
perience of an individual is too limited in order to be statistically reliable.
•
Every individual risk is part of a risk collective. The collective claim ex-
perience, for large collectives, does provide reliable statistical information.
This can be used to calculate the expected value of the average (over the
risk collective) aggregate claim amount per risk. However, for the assess-
ment of the quality of a given individual risk, this information is only of
limited use.
•
Intuitively, it seems obvious that both sources of information should be
used for a fair rating of risks.

1.1 Rating of Risks and Claims Experience in Insurance
3
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
1
2
3
loss ratio
2
20
200
premium volume 1000's of  CHF per year:  
Fig. 1.1. Average loss ratio of a ﬁctitious portfolio of nine contracts
Let us consider the following ﬁctional example (Figure 1.1). We have data
on a portfolio consisting of nine group health insurance contracts, giving the
claim experience and gross premiums over a period of 5 years. The observed
loss ratio over the 5 years (the aggregate claim amount divided by the gross
premium for this period) is 50% for contracts 13, 75% for contracts 46 and
100% for contracts 79. The break-even aggregate loss ratio (the percentage
of the premium which should be used for covering claim amounts) is 75%,
that is, 25% of the premiums are needed for administrative costs and other
loadings. New premiums are to be calculated for each of these contracts for
the coming period. In particular, the loss ratio for each of these contracts,
assuming the existing premiums, needs to be forecast. Note that the premium
volume of the contracts also varies from one contract to another. In assessing
these contracts on the basis of their individual loss ratios over the last 5-year
period, two extreme points of view are possible.
a) The dierences in the observed loss ratios between the individual contracts
are entirely the result of the inherently random nature of the occurrence
of claims. No contract is a better or worse risk than another. With this
point of view, the best forecast that we can make of the future loss ratio of
a given contract, on the basis of the available data, is equal to the average
observed loss ratio over all nine contracts, that is, 75%. Hence, no change
to the existing premium level is necessary.

4
1 Introduction
0%
50%
100%
150%
200%
loss ratio
contract 1             
contract 4              
contract 7
5-year
average
Fig. 1.2. yearly loss ratios of the small contracts
b) The dierences in the observed loss ratios are not random, they are sys-
tematic. They are due to the varying risk proﬁles across the contracts. As
a consequence, with this point of view, the premiums for the ﬁrst three
contracts should be decreased by 1/3, while those of the last three should
be increased by 1/3.
The truth probably lies somewhere between the two extremes.
For a more reﬁned analysis we consider next the yearly loss ratios separately
for the small, medium and large contracts.
Figure 1.2 shows the yearly loss ratios of contracts 1, 4 and 7, each of
which has a yearly premium volume of CHF 2 000. We see that the variability
of the yearly loss ratios is high. One might seriously ask whether the observed
dierences in the 5-year loss ratios should be attributed to random ﬂuctuations
only. This fact decreases our conﬁdence in the accuracy of this average as a
reﬂection of the long-term average.
Figure 1.3 shows the analogous picture for the medium-sized contracts
with a yearly premium volume of CHF 20 000. The yearly variability is still
considerable, but it appears doubtful that the dierences between the observed
average loss ratios are purely the result of random events.
Finally, in Figure 1.4, we see displayed the yearly loss ratios for the three
largest contracts 3, 6 and 9 (yearly premium volume of CHF 200 000). It seems
clear that there are real dierences in the risk proﬁles of the three contracts.

1.1 Rating of Risks and Claims Experience in Insurance
5
0%
50%
100%
150%
200%
loss ratio
contract 2                            contract 5               
contract 8
5-year
average
Fig. 1.3. Yearly loss ratios of the medium-sized contracts
0%
50%
100%
150%
200%
loss ratio
contract 3                            contract 6               
contract 9
5-year
average
Fig. 1.4. Yearly loss ratios of the large contracts

6
1 Introduction
Let us look again at contracts 13 (see Figure 1.5). For all three contracts,
the average loss ratio over the past 5 years is 50%. However, at least intu-
itively, the data suggest that the “best” forecast should not be the same for
all three. Should we use a forecast of 50% (the average observed loss ratio of
the individual contracts) or one of 75% (the average loss ratio over the whole
portfolio)? For contract 1, because of the high volatility in the yearly observed
loss ratios, we would not have much conﬁdence in the accuracy of the average
of these as a forecast of future loss ratios, and would be inclined to use the
average over all nine contracts, 75%, as our forecast. On the other hand, for
contract 3, the information from its individual claim experience seems reliable
and one would be inclined to use a ﬁgure in the neighbourhood of the observed
average of 50% as our forecast. For contract 2, our forecast would probably
lie somewhere between that for contracts 1 and 3.
0%
50%
100%
150%
200%
loss ratio
contract 1                            contract 2               
contract 3
average portfolio loss ratio
average individual loss ratio
Fig. 1.5. Yearly loss ratios of contracts 133
Credibility theory provides a sound mathematical basis for the intuitive
ideas and heuristic arguments sketched above.
Credibility theory:
•
is the mathematical tool to describe heterogeneous collectives;
•
answers the question of how one should combine individual and collective
claims experience;
•
belongs mathematically to the area of Bayesian statistics;

1.2 Mathematical Formulation of the Problem of Rating Risks
7
•
is motivated by questions arising in insurance practice.
Credibility theory is one of the basic tools that every modern actuary should
know and understand.
1.2 Mathematical Formulation of the Problem of Rating
Risks
1.2.1 Individual Risk
The individual risk can be regarded as a black box that produces aggregate
claim amounts Xj (j = 1, 2, . . . , n), where Xj denotes the claim amount in
year j (or in some other well-speciﬁed time period j). Examples of the “black
box” associated with an individual risk include:
•
an individual driver in third-party motor liability insurance,
•
a group of insured individuals in life insurance,
•
all employees of a ﬁrm in collective workman’s compensation insurance,
•
a ceding company in reinsurance.
Observe: Xj (j = 1, 2, . . . , n) are, mathematically, interpreted as random vari-
ables. This interpretation holds also for past periods (the observed values could
have been dierent).
On the basis of the observations in the previous periods, X = (X1, . . . , Xn)0,
we want to determine the risk premium for the aggregate claims in a future
period, for example, Xn+1. In order to do this, we must make certain assump-
tions about the distribution function of the random variables Xj. The simplest
standard assumptions are:
Assumption 1.1
A1: Stationarity: All the Xj’s are identically distributed with (conditional)
distribution function F (x).
A2: (Conditional) Independence: The random variables Xj, j = 1, 2, . . . , are
(conditionally) independent (given the distribution F (x)).
Remarks:
•
In this text we often use the symbols g (y) when referring to the func-
tion g with argument y, e.g. F (x) instead of F in Assumptions 1.1, thus
highlighting the argument x.
•
The stationarity assumption allows one to establish a relationship between
the past and the future. A (possibly weaker) assumption of stationarity
is always needed for the calculation of insurance premiums on the basis

8
1 Introduction
of historical data. The (strong) stationarity assumption A1 will later be
weakened and generalized. In practice, stationarity can often be achieved
by making adjustments for inﬂation, indexing, as-if-statistics, trend elim-
ination, and so on.
•
Precisely what we mean in Assumption A2 by (conditional) independence
(given the distribution F (x)), will be explained shortly (see page 12). We
will also encounter models where this independence assumption is weak-
ened.
Typically, in insurance practice, we have to deal with the following situa-
tion:
i) F is unknown,
ii) F varies from risk to risk.
In order to formalize i) and ii) more clearly, we use the common notation
from mathematical statistics: we index F by a parameter & and write F&
(instead of F) and say
i) & is unknown,
ii) & varies from risk to risk.
Remarks:
•
Parameterization is always possible (in the most extreme case, one can
choose the distribution function itself as the parameter). In general, we
write that & is an element of some abstract space .
•
& can be thought of as the “risk proﬁle”.
1.2.2 The Correct Individual Premium
By a premium calculation principle H, we mean a function that assigns a real
number to a random variable X having distribution function F, i.e.
X 7$ H (X) ,
or indicating that the value of H depends only on F,
F 7$ H (F) .
Some of the more well-known “classical” premium calculation principles are:
Expectation principle:
X 7$ (1 + ) E [X]
 > 0;
Standard deviation principle: X 7$ E [X] +  (X)  > 0;
Variance principle:
X 7$ E [X] + 2 (X)  > 0;
Exponential principle:
X 7$ 1
 ln E
£
eX¤
 > 0.

1.2 Mathematical Formulation of the Problem of Rating Risks
9
For each of these principles the premium H (X) can be decomposed into the
pure risk premium E [X] and a positive so-called risk loading determined by
the parameters , , , and . Note also that the pure risk premium is obtained
by the expectation principle with  = 0.
Remark:
•
The economic necessity of a risk loading is given by the fact that insur-
ance companies need risk-bearing capital to cope with the volatility of the
insurance results and in order to be able to fulﬁl the obligations towards
the insured in an unfavourable year. The investors should be compensated
for exposing their capital to risk. The risk loading compensates for this
risk and can be seen as the cost of risk capital.
By applying the risk calculation principle H the resulting correct individual
premium (for a risk with risk proﬁle &) would be H (F&). In this book we limit
ourselves to the discussion of the pure risk premium. Thus, we arrive at the
following deﬁnition of the correct individual premium.
Deﬁnition 1.2. The correct individual premium of a risk with risk proﬁle &
is
P ind (&) = E [Xn+1 |&] =: µ (&) .
(1.1)
The correct individual premium is also referred to as the fair risk premium. In
order to simplify notation we will, in the following, often write E& [·] instead
of E [· |F& ] or E [· |&] .
The individual rating problem can then be described as the determination
of the quantity µ (&) . However, in insurance practice, both & and µ (&) are
unknown. Therefore we have to ﬁnd an estimator [
µ (&) for µ (&).
1.2.3 The Risk Rating Problem in the Collective
An insurance company insures many kinds of risks. For the purpose of rating
risks, these risks are grouped into classes of “similar risks”, on the basis of so-
called “objective” risk characteristics. In motor insurance, examples of such
risk characteristics are cylinder capacity, make of car and power/weight ratio,
as well as individual characteristics such as the driver’s age, sex and region.
In industrial ﬁre insurance, important characteristics might be the type of
construction of the insured building, the kind of business conducted in the
building, or the ﬁre extinguishing facilities in the building. How exactly such
groups are constructed is important in practice, but will not be part of our
discussion in this book. Important for the credibility theory framework is that
we do not consider each risk individually but that we rather consider each risk
as being embedded in a group of “similar” risks, called the collective.
In the language of Subsection 1.2.2 we consider the following situation:
every risk i in the collective is characterized by its individual risk proﬁle &i.

10
1 Introduction
These parameters &i are elements of a set , where  is the set of all potential
and possible values of the (unknown) risk proﬁles of the risks in the collective.
In the special case of a homogeneous collective,  consists of just one element.
This corresponds to the classical point of view of insurance: every member
of the collective has exactly the same risk proﬁle and therefore the same
distribution function for its corresponding aggregate claim amount. However,
the risk groups or collectives considered in insurance are mostly heterogeneous.
In other words, the &-values of the dierent risks in the collective are not all
the same, they are rather samples taken from a set  with more than one
element. But while the risks in the collective are dierent, they also have
something in common: they all belong to the same collective, i.e. they are
drawn from the same set . This situation is referred to when we say that the
risks in the collective are similar.
The speciﬁc &-values attached to the dierent risks in the collective are
typically unknown to the insurer. But, on the basis of a priori knowledge and
statistical information, the insurer does know something about the structure
of the collective. He knows, for example, that most car drivers are “good” risks
and seldom make a claim, while a small percentage of drivers make frequent
claims. Formally (at least intellectually), this information can be summarized
by a probability distribution U (&) over the space .
Deﬁnition 1.3. The probability distribution U (&) is called the structural
function of the collective.
We can interpret U (&) in a number of ways:
•
In the frequentist interpretation, we consider the &’s in the collective as
being a random sample from some ﬁxed set ; then the function U (&)
describes the idealized frequencies of the &’s over . This interpretation is
called empirical Bayes and it is the predominant view taken in this text.
•
In the pure Bayesian interpretation we consider the distribution function
U (&) as a description of the personal beliefs, a priori knowledge, and
experience of the actuary.
In Subsection 1.2.2 we deﬁned the correct individual premium. Now, we
will deﬁne the collective premium.
Deﬁnition 1.4. The collective premium is deﬁned by
P coll =
Z

µ (&) dU (&) =: µ0.
(1.2)
Let us summarize the two kinds of premiums that we have so far considered:
•
The “correct” individual premium P ind (&) = µ (&) = E& [Xn+1] .
This corresponds to the expected claim amount of the individual risk
(given the individual risk proﬁle &) for the rating period n + 1. Since

1.2 Mathematical Formulation of the Problem of Rating Risks
11
& is unknown to the insurer, µ (&) is also unknown. In order to estimate
this premium, in the best case, the insurer has at his disposal the infor-
mation about the claim experience of this risk over the past few periods.
However, more often than not, this information is very limited and has
little predictive value.
•
The collective premium P coll = µ0 =
R

µ (&) dU (&) .
This corresponds to the average, over all risks of the collective, of the ex-
pected claim amount per individual risk. In most cases, this quantity is also
unknown to the insurer. However, for most reasonably sized collectives, in
contrast to the individual premium, this premium can be estimated with
considerable accuracy on the basis of observations from the past.
It is of central importance for an insurance company to be able to calculate
the collective premium (also known as the tari level). If the insurer demands
the same premium, P coll, from every member of the collective, the books will
be balanced, that is, over the whole collective, the premiums will be equal to
the aggregate claim amount (in expected value). One could then ask why an
insurance company is so interested in the “correct” individual premium. The
answer is simple and can be most clearly expressed by the following thesis.
Thesis: The most competitive rate is the correct individual premium.
It is competition that forces companies to oer the fairest rates possible.
If a company sets rates at the same level for all risks in a heterogeneous
collective, the good risks will pay too much and the bad ones too little. If a
competing company then oers rates which are more dierentiated and fair,
then its premiums for the good risks will be cheaper. In comparison to the ﬁrst
company, this competing company will be more attractive to the good risks
and less attractive to the bad ones. This can have disastrous consequences for
the ﬁrst company: it loses good risks and has an increase in bad risks. Insurers
refer to such an eect as anti-selection. In the language of this section this
means that the collective changes, and the structural function of the insurer
becomes less favourable.
1.2.4 Formulating the Rating Problem in the Language of
Bayesian Statistics
Mathematically, the collective rating problem sketched in Subsection 1.2.3
can be most elegantly described in the language of Bayesian statistics. In the
simple case considered so far this can be demonstrated with a two-urn model
(see Figure 1.6).

12
1 Introduction
Fig. 1.6. Two-urn model
The ﬁrst urn represents the urn containing the collective with distribu-
tion function U. From this urn, we select the individual risk, or equivalently
its risk proﬁle &. This & then determines the content of the second urn, or
equivalently the distribution function F&. From this urn we select the values
of the random variables X1, X2, . . . , which are thus independent and identi-
cally distributed with distribution function F&. This results in the following
mathematical structure.
Every risk is characterized by its individual risk proﬁle &, which is itself
the realization of a random variable , and the following holds:
i) Conditional on the event  = &, X1, X2, . . . are i.i.d. (independent and
identically distributed) with distribution function F&.
ii)  is itself a random variable with distribution function U.
Remarks:
•
This model describes in mathematical language exactly the scenario which
we considered in Section 1.1. The risks in the collective dier from each
other. Each has its own risk proﬁle &. The risks do, however, have some-
thing in common. The risk parameters of the individual risks are them-
selves realizations of random variables. They are all independently drawn
from the same urn with distribution function U.
•
In this interpretation, the individual premium itself becomes a random
variable µ (). We do not know the correct value of the individual pre-
mium. We do, however, know something about the possible values of µ ()
and with what probability these values occur. It is therefore natural to
model µ () as a random variable.
•
We therefore denote the individual premium by
P ind = µ () := E [Xn+1 |] ,

1.2 Mathematical Formulation of the Problem of Rating Risks
13
which is a conditional expectation and therefore a random variable. Note
the change of notation and interpretation from the correct individual pre-
mium as deﬁned in (1.1).
•
Notice also, that a priori, all risks are equal. We know that there are better
and worse risks in the portfolio. But we cannot, a priori, see to which
class a particular risk belongs. Only a posteriori, after observations on the
individual risk have been made, we can draw conclusions. This remark
formalizes our intuition about the collective as a group of dierent, but
similar risks.
•
In contrast, the collective premium is
P coll = µ0 =
Z

µ (&) dU (&) = E [Xn+1] ,
an unconditional expectation, and therefore a ﬁxed number.
•
Notice also that X1, X2, . . . are only conditionally independent, given .
Unconditionally, they are positively correlated. This is clear from the fol-
lowing:
Cov (X1, X2) = E [Cov (X1, X2 |)] + Cov (E [X1 |] , E [X2 |])
= Cov(µ () , µ ())
= Var [µ ()] .
It is now clear what was intended on page 7 when we talked about “condi-
tional independence” in Assumption A2. Within the Bayesian framework,
we have now described this in a mathematically exact way.
Remark on the notation:
•
Earlier we denoted the space of the possible & values by , while in this
section  was used to denote the random variable from which & is ob-
served. This imprecision is deliberate. In order to reduce the number of
symbols in our notation, we will in general use the same symbol to denote
both the random variable and the space of its possible realizations.
Our goal is to estimate, for each risk, the correct premium µ () as pre-
cisely as possible. One potential estimator is the collective premium µ0, i.e.
the premium for the considered particular risk is estimated by the “average”
expected value over the whole collective. This estimator is appropriate when
we are considering a new risk, about which there is no pre-existing claim ex-
perience. It takes into account the fact that the risk belongs to the collective
and that its risk proﬁle was selected at random from the “collective urn” U.
However, this estimator does not take the individual claim experience into ac-
count. If we have observed the risk over a period of n years and if X denotes
the vector of aggregate claim amounts associated with this period, then this
information should contribute to the estimation process. This brings us to the

14
1 Introduction
concept of experience rating. The best experience premium depending on the
individual claim experience vector X is called the Bayes premium, which we
will now deﬁne. The sense in which it is “best” and the reason why it is called
the Bayes premium will be explained in Chapter 2.
Deﬁnition 1.5. The Bayes premium ( = best experience premium) is deﬁned
by
P Bayes = ^
µ () := E [µ()| X] .
(1.3)
1.2.5 Summary
We have so far encountered the following premium types:
•
The individual premium
P ind = µ() = E [Xn+1| ] .
It should be noted here, that in this interpretation P ind, contrary to
P ind (&) , is a random variable and not a “true” premium, i.e. P ind is
not a real number, that assigns a ﬁxed cost for assuming a given risk. It
is more a sort of “ﬁctional” premium, from which we could derive the size
of the “true” premium if we knew the value & of the random variable .
•
The collective premium
P coll = µ0 =
Z

µ (&) dU (&) = E [Xn+1] .
•
The Bayes premium (= best experience premium)
P Bayes = ]
µ() = E [µ()|X] .
Here, it should be noted that the experience premium is a random variable
(it is a function of the observation vector X), the values of which are known
at the time at which the risk is to be rated. The Bayes premium is thus a
“true” premium, the value of which depends on the claim experience.

2
The Bayes Premium
In this chapter we will study the best experience premium or Bayes premium,
which we deﬁned in (1.3),
P Bayes := ]
µ() = E [µ()| X] .
To do this, we will use concepts from statistical decision theory. In particular,
we will see in exactly which sense P Bayes is “best” and why it is called the
Bayes premium.
2.1 Basic Elements of Statistical Decision Theory
Here we will give an overview of the elements of statistical decision theory
which will be necessary for our exposition. For a comprehensive study of
statistical decision theory, see for example Lehmann [Leh86]. The raw material
for a statistical decision is the observation vector X = (X1, X2, . . . , Xn)0. The
distribution function
F&(x) = P& [X  x]
is completely or partly unknown. (Equivalently: The parameter & is completely
or partly unknown.) We are interested in the value of a speciﬁc functional
g(&) of the parameter &. We seek a function T(X), which depends only on
the observation vector X, which will estimate g(&) “as well as possible”. The
function T(X) is called an estimator for g(&). We will formulate this problem
in the following way:
& 5 : The set of parameters, which contains the true value of &,
T 5 D: The set of functions to which the estimator function must belong.
T is a map from the observation space Rn into the set of all possible values
of the functional g, that is, the set {g(&) : & 5 }.

16
2 The Bayes Premium
The idea of “as well as possible” is made precise by the introduction of a
loss function:
L(&, T(x)) : loss, if & is the “true” parameter and
T(x) is the value taken by the estimator when the value
x is observed.
From this we derive the risk function of the estimator T
RT (&) := E& [L(&, T)] =
Z
Rn L(&, T(x)) dF&(x).
(2.1)
(Only such functions T and L are allowed for which the right-hand side of (2.1)
exists.) The goal then is to ﬁnd an estimator T 5 D, for which the risk RT (&)
is as small as possible. In general, it is not possible to do this simultaneously
for all values of &. In other words, in general there is no T which minimizes
RT (&) uniformly over &. In Figure 2.1 we see an example, where depending
on the value of &, T1 or T2 has the smaller value of the risk function.
)
(
1 -
T
R
)
(
2 -
T
R
-
Fig. 2.1. Risk functions RT1 and RT2 for T1 and T2
2.2 Bayes Risk and Bayes Estimator
In Bayesian statistics, a smoothed average of the curve RT(&) is considered,
where the average is weighted by means of a probability distribution U(&)
(called an a priori distribution for ). In other words, we consider the ex-
pected value of RT (), by regarding & as the realization of a random variable
 with probability distribution U.

2.2 Bayes Risk and Bayes Estimator
17
Deﬁnition 2.1. We deﬁne the Bayes risk of the estimator T with respect to
the a priori distribution U(&) as
R(T) :=
Z

RT (&)dU(&).
Assuming that the deﬁned integral makes sense, with this criterion we can
always rank estimators by increasing risk. In other words, there is a complete
ordering on the set of estimators.
In this book we will use the following notation:
If ex 5 D and g (ex)  g (x) for all x 5 D,
we write ex = arg min
x5D
g (x) .
Deﬁnition 2.2. We deﬁne the Bayes estimator eT as
eT := arg min
T5D1
R(T),
(2.2)
where D1 is the set of all mathematically allowable estimators (that is, those
estimators with integrable risk functions).
The estimator eT is that estimator (2.2) which minimizes the Bayes risk R(·).
Without further ado, we assume that minT5D1 R(T) is attained (this will
indeed always be the case in the situations that we consider here in this
book).
A remark on the notation: We use P to denote the joint distribution of
(, X), F to denote the marginal distribution of X and Ux to denote the
conditional distribution of , given X = x.
In order to construct the Bayes estimator, we consider the following se-
quence of equations:
R(T) =
Z

RT (&)dU(&) =
Z

E& [L(&, T)] dU(&)
=
Z

Z
Rn L(&, T(x))dF&(x)dU(&)
=
Z
Rn
Z

L(&, T(x))dUx(&)dF(x).
From this we deduce the following rule for constructing the Bayes estimator:
Theorem 2.3. For every possible observation x, ]
T(x) takes the value which
minimizes R
 L(&, T(x))dUx(&). In other words, for every possible observation
x, ]
T(x) is the Bayes estimator with respect to the distribution Ux(&).
Terminology: In Bayesian statistics, U(&) is called the a priori distribution
of  (before observations have been made), Ux(&) is called the a posteriori
distribution of  (after observations have been made).

18
2 The Bayes Premium
2.3 Bayesian Statistics and the Premium Rating
Problem
It is clear from the overview given in Sections 2.1 and 2.2 that we have used
Bayesian thinking to formulate the premium rating problem in Chapter 1.
In order to express our concepts as introduced in Chapter 1 with Bayesian
modelling, it su!ces to consider the following correspondences:
functional of interest g(&) ' correct individual premium µ(&),
 = set of possible
'  = set of possible
parameter values
individual risk proﬁles &.
In later parts of the text the estimand g (&) might be chosen in a more general
way.
As in Chapter 1, we use  also as a symbol for a random variable with
distribution function U(&). Hence, in the credibility context, we interpret the
a priori distribution U(&) as the structural distribution on the space .
We now choose a particular form for the loss function, namely
L(&, T(x)) = (µ(&)  T(x))2
(quadratic loss function).
We thus have the following ordering on the space of all estimators for µ():
Deﬁnition 2.4. An estimator [
µ() is at least as good as another estimator
[
µ()

if
E
·³
[
µ()  µ()
´2¸
 E
·³
[
µ()

 µ()
´2¸
.
E
·³
[
µ()  µ()
´2¸
is called the quadratic loss of the estimator [
µ().
The following theorem holds:
Theorem 2.5. The Bayes estimator with respect to the quadratic loss func-
tion is given by
^
µ () = E [µ()| X] .
(2.3)
Remark:
•
This theorem makes precise what we meant in Deﬁnition 1.5, when we
said that P Bayes = ]
µ() is the best possible experience premium.
Proof of Theorem 2.5: Let [
µ() be an estimator of µ() and ]
µ() be its
a posteriori expectation E [µ()| X]. Then

2.3 Bayesian Statistics and the Premium Rating Problem
19
E
h
([
µ()  µ())2i
= E
h
E
h
([
µ()  ]
µ() + ]
µ()  µ())2¯¯¯ X
ii
= E
h
([
µ()  ]
µ())2i
+ E
h
(]
µ()  µ())2i
.
We thus have that, of all estimators for µ(), the estimator ]
µ() = E [µ()| X]
has the smallest quadratic loss. This proves Theorem 2.5.
¤
Why do we use the quadratic loss function?
We have seen that the quadratic loss function implies that the best premium
is the a posteriori expectation of the individual premium µ(). This estimator
has another very important property. We write P for the joint distribution of
(, X) so that
dP(&, x) := dF&(x)dU(&).
C
X
-
Fig. 2.2. Areas of balance between premiums and claims
For every measurable set C 5 Bn := (X1, . . . , Xn) (see Figure 2.2) we have,
by deﬁnition of the conditional expectation of a random variable (see Appen-
dix A) that
A :=
Z

Z
C
g
µ(&) dP(&, x) =
Z

Z
C
µ(&) dP(&, x) =: B.
(2.4)
We can interpret these equations in the following way: if we set our received
premium to be equal to the Bayes premium, then A is the amount taken
in from the subcollective with observations X 5 C. On the other hand, B
is the expected aggregate claim amount paid out to the subcollective with
observations X 5 C. This means that, over every (measurable) subcollective

20
2 The Bayes Premium
deﬁned in terms of past claims experience, (in expectation) the amount taken
in is equal to the amount paid out. Naturally, equation (2.4) is also true for
C = Rn, that is, with respect to the whole collective.
Remarks:
•
According to the RadonNikodym Theorem ]
µ() is the only Bn-measurable
function with the property (2.4).
•
The quadratic loss function also leads to the collective premium (resp.
the individual premium), namely in the case where no loss experience is
available (resp. in the case where  is known).
•
The balance argument (2.4) is a strong reason for using the quadratic
loss function. One might advocate other reasons. Economically, the use of
a symmetric loss function charging gains and losses with equal penalties
expresses a situation of equal bargaining power of the insurer on the one
hand and the insured on the other. The resulting premium can therefore
be considered as fair for both parts.
•
One might argue that, from the insurance company’s unilateral point of
view, it would be more dangerous to use too low a premium than too high
a premium, and that, hence, the loss function should not be symmetri-
cal around the estimand. However, we concentrate here on the pure risk
premium. As pointed out in Subsection 1.2.2, the premium to be charged
to the policy holder will also contain a risk loading. The riskiness of the
underlying business has to be taken into account by this risk loading.
Theorem 2.6.
i) The quadratic loss of the Bayes premium is
E
h
(]
µ()  µ())2i
= E [Var [µ()| X]] .
(2.5)
ii) The quadratic loss of the collective premium is
E
£
(µ0  µ())2¤
= Var [µ()]
(2.6)
=
E [Var(µ() |X)]
|
{z
}
ﬁrst variance component
+
Var(E [µ() |X])
|
{z
}
second variance component
.
Proof: The proof of (2.5) follows directly from the deﬁnition of the conditional
variance. (2.6) is the well-known decomposition of the variance (see Appendix
A).
¤

2.4 The Bayes Premium in Three Special Cases
21
Remark:
•
Note that the quadratic loss of the Bayes premium is equal to the ﬁrst
variance component of the quadratic loss of the collective premium.
2.4 The Bayes Premium in Three Special Cases
In order to determine the Bayes premium, we must ﬁrst specify
i) the structural function U (&) and
ii) the family of conditional distributions F := {F& (x) : & 5 } .
2.4.1 The Poisson—Gamma Case
Motivation: F. Bichsel’s Problem
At the end of the 1960s, a Bonus—Malus system was introduced in Switzer-
land for third-party liability motor insurance. The mathematical arguments
underpinning this system are described in the paper of F. Bichsel [Bic64].
The Bonus—Malus system was created in response to the following set of
circumstances. In the 1960s, insurers requested approval for the increase of
premium rates, claiming that the current level was insu!cient to cover their
risks. The supervision authority was prepared to give approval only if the rates
took into account individual claims experience. It was no longer acceptable
that “good” risks, who had never made a claim, should continue to pay pre-
miums which were at the same level as those drivers who had made numerous
claims.
At the time, the premium level was based on the horsepower of the car. It
was clear, however, that there were huge dierences between risks having the
same value of this criterion. F. Bichsel was the ﬁrst non-life actuary in Switzer-
land, and he was given the task of constructing a risk rating system which
was better adjusted to the individual risk proﬁles. He conjectured that dif-
ferences between individual risk proﬁles were best summarized by dierences
in individual numbers of claims, while claim size, because of the very high
variability in the amounts involved, was probably of little predictive value.
Mathematical Modelling
Let Nj be the number of claims made by a particular driver in year j. Its
corresponding aggregate claim amount is Xj. The model used by Bichsel was
based on the following implicit assumption:
Model Assumptions 2.7 (implicit assumption of Bichsel)
Given the individual risk proﬁle & of the driver, the following holds for the
aggregate claim amount Xj:

22
2 The Bayes Premium
E [Xj | = &] = CE [Nj | = &]
(j = 1, 2, . . .) ,
where C is a constant depending only on the horsepower of the car
and where E [Nj | = &] depends only on the driver of the car.
Remarks:
•
Assumptions 2.7 hold for any compound model with claim size distribution
depending on the horsepower of the car only and claim frequency not
depending on the horsepower of the car.
•
The assumption that the claim frequency does not depend on the horse-
power of the car is a simpliﬁcation not fully reﬂecting reality.
Because of Model Assumptions 2.7 it su!ces to model the number of
claims. The model used by Bichsel for the claim number is based on the
following:
Model Assumptions 2.8 (Poisson—Gamma)
PG1: Conditionally, given  = &, the Nj’s
(j = 1, 2, . . . , n) are independent
and Poisson distributed with Poisson parameter &, i.e.
P (Nj = k|  = &) = e& &k
k! .
PG2:  has a Gamma distribution with shape parameter  and scale parameter
, i.e. the structural function has density
u (&) =

 ()&1e&,
&  0.
Remarks:
•
The ﬁrst two moments of the Gamma-distributed random variable  are
E [] = 
 ,
Var [] = 
2 .
•
In this book a dot in the index means summation over the corresponding
index, for instance
N• =
Xn
j=1 Nj.
Proposition 2.9. Under Model Assumptions 2.8 we have for the claim fre-
quency (denoted by F)
F ind = E [Nn+1 |] = ,
F coll = E [] = 
 ,
(2.7)
F Bayes =  + N•
 + n = N + (1  )
 ,
(2.8)
where
 =
n
n +  ,
N = 1
n
n
X
j=1
Nj.

2.4 The Bayes Premium in Three Special Cases
23
The quadratic loss of F Bayes is
E
£
(F Bayes  )2¤
= (1  ) E
£
(F coll  )2¤
(2.9)
=  E
£
(N  )2¤
.
(2.10)
Remarks:
•
The quantities P ind, P coll and P Bayes can be obtained by multiplying F ind,
F coll and F Bayes by the constant C.
•
The quadratic loss of F Bayes (resp. P Bayes) is equal to the minimum Bayes
risk. Note that the quadratic loss of P Bayes is
E
£
(P Bayes  P ind)2¤
= C2E
£
(F Bayes  F ind)2¤
.
•
The Bayes premium CF Bayes is a linear function of the observations (claim
numbers). As we shall see later, this is an example of a credibility premium.
•
F Bayes is an average of
N = observed individual claim frequency and

 = E [] = a priori expected claim frequency
(= expected claim frequency over the whole collective).
•
 = n/(n + ) is called the credibility weight. The greater the number of
observation years, n, the larger will be this weight. Similarly, the larger
 = E [] /Var [] is, the smaller this weight will be. This makes intuitive
sense: the more information we have on an individual, the greater the
weight we are ready to attach to his individual claim experience, while
the more homogeneous our collective is, the more we are ready to use the
collective claim experience for the rating of the individual risk.
•
(2.9) and (2.10) mean that
quadratic loss of F Bayes = (1  ) · quadratic loss of F coll,
quadratic loss of F Bayes =  · quadratic loss of N.
The credibility weight  can thus be interpreted as the factor by which
the quadratic loss is reduced if we use the Bayes premium rather than
the collective premium or as the factor by which the quadratic loss has to
be multiplied if we use F Bayes rather than the observed individual claim
frequency N. Note that F coll is the estimator based only on the a priori
knowledge from the collective and neglecting the individual claims experi-
ence, whereas N is the estimator based only on the individual claims ex-
perience and neglecting the a priori knowledge. F Bayes takes both sources
of information into account, and we see that the quadratic loss of F Bayes
is smaller than the quadratic losses of both F coll and N.

24
2 The Bayes Premium
•
The quadratic loss of F coll is
E
h¡
F coll  
¢2i
= E
"µ
  
¶2#
= Var [] =

2 .
(2.11)
The quadratic loss of N is
E
n
E
h¡
N  
¢2¯¯¯ 
io
= E
©
Var
¡
N
¯¯ 
¢ª
= E []
n
= 1
n

 .
(2.12)
Since the quadratic loss of F Bayes is smaller than the quadratic loss for N
we also see that
E
h¡
F Bayes  
¢2i
$ 0
for n $ 4.
Proof of Proposition 2.9:
F ind and F coll follow directly from the model assumptions. To obtain F Bayes,
we derive ﬁrst the a posteriori density of  given N:
u (&| N) =

 ()&1e& Qn
j=1 e& &Nj
Nj!
R

 ()&1e& Qn
j=1 e& &Nj
Nj! d&
2 &
+
n
P
j=1
Nj1
e(+n)&,
where 2 is the proportionality operator, i.e. the right-hand side is equal to
the left-hand side up to a multiplicative constant not depending on &. We
see from the right-hand side of the above equation that u (&| N) is again the
density of a Gamma distribution with the updated parameters
0 =  + N•,
0 =  + n.
From this we arrive directly at the formula (2.8).
From (2.5) and the fact that the a posteriori distribution of  given N is
again a Gamma distribution with updated parameters 0 and 0, we get
E
£
(F Bayes  )2¤
= E [Var d| N]]
= E
"
 + N•
( + n)2
#
=

(n + )2
µ
1 + n

¶
= 

1
n + 
= 
2 (1  )
= 1
n

 .

2.4 The Bayes Premium in Three Special Cases
25
The last equation is obtained by inserting the expression for  into the second
to last equation. Since
E
h¡
F coll  
¢2i
=

2 ,
E
h¡
F coll  N
¢2i
=
µ 1
n


¶
,
(2.9) and (2.10) are shown. This ends the proof of Proposition 2.9.
¤
Estimating the Structural Parameters
The Bayes estimator e depends on the structural function U(&): in the ex-
ample here, this means that it depends on the unknown parameters  and .
These parameters need to be estimated and we now consider the problem of
how this should best be done. Not surprisingly, we use data from the collective:
The following table shows the data, generated by Swiss automobile drivers
from the year 1961, which were available to F. Bichsel:
k
0
1
2
3
4
5
6 Total
# of policies
with k claims 103 704 14 075 1 766
255
45
6
2 119 853
Table: data of Swiss automobile drivers available to F. Bichsel
The table can be read in the following way. There are 119 853 “repetitions” of
the two-urn experiment, so that for each of the 119 853 drivers, an individual
risk proﬁle is drawn from the ﬁrst urn and then the corresponding number of
claims is selected from the second urn, the composition of which depends on
the ﬁrst selection. Intellectually then we have a set of tuples {
¡
1, N (1)¢
, . . . ,
¡
i, N(i)¢
, . . . ,
¡
I, N (I)¢
} with I = 119 853. Thus i is the index for the
individual driver and N (i) denotes the number of claims for the driver i in the
year 1961.
There are a number of dierent ways that we can use the above data
to estimate the structural parameters  and . Bichsel used the so-called
method of moments. Assuming that the pairs of random variables
©¡
i, N (i)¢
:
i = 1, 2, . . . , I} are independent and identically distributed, the following em-
pirical moments are unbiased estimators:
bµN = N1961 = 1
I
I
X
i=1
N(i) = 0.155
and
b2
N =
1
I  1
I
X
i=1
³
N(i)  N 1961
´2
= 0.179.

26
2 The Bayes Premium
On the other hand, if we calculate the two ﬁrst moments of the random
variable N, based on the model assumptions, we get
µN = E [N] = E [E [N |]] = E [] = 
 ,
2
N = Var [N] = E [Var [N |]] + Var [E [N |]]
= E [] + Var [] = 

µ
1 + 1

¶
.
The method of moments uses as estimators for the unknown parameters those
values which would lead to the identities
bµN = µN
and
b2
N = 2
N,
so that we have in this example
b
b
= 0.155,
b
b
µ
1 + 1
b
¶
= 0.155
µ
1 + 1
b
¶
= 0.179,
b = 1.001
and
b = 6.458.
Empirical Bayes Estimator
If we replace the unknown structural parameters  and  in the formula for
the Bayes estimator by the values b and b estimated from the collective we
get the empirical Bayes estimator
\
F Bayes
emp
=
n
n + b
N +
b
n + b
b
b
,
where N = 1
n
n
X
j=1
Nj.
Remark:
It is usual in the calculation of the Bayes premium that we have to proceed
in two steps:
•
Derivation of P Bayes under the assumption that the structural parameters
are known.
•
Estimation of the structural parameters using data from the collective.
Distribution of the Risk in the Collective
How well does the model ﬁt the data of the table on page 25? To check this,
we have to ﬁrst calculate the unconditional distribution of N. In the above
example, we can explicitly derive this distribution:

2.4 The Bayes Premium in Three Special Cases
27
P (N = k) =
Z
P (N = k|  = &) u(&)d&
=
Z
e& &k
k!

()&1e&d&
=

()
1
k!
Z
e(+1)&&+k1d&
|
{z
}
=
 (+k)
(+1)+k
= ( + k)
()k!
µ

 + 1
¶ µ
1
 + 1
¶k
=
µ + k  1
k
¶
p (1  p)k ,
with p =

 + 1,
which is a negative binomial distribution.
We can now compare the observed data with the values we would expect
if the data satisﬁed the model assumption of the two-urn Poisson—Gamma
model (ﬁtted negative binomial distribution). We also compare the observed
data with the model assumption of a homogeneous portfolio, where all policies
are assumed to have the same Poisson parameter (ﬁtted Poisson distribution).
Poisson
Negative binomial
k
observed ( = 0.155) ( = 1.001,  = 6.458)
0
103 704
102 629
103 757
1
14 075
15 922
13 934
2
1 766
1 234
1 871
3
255
64
251
4
45
3
34
5
6
0
5
6
2
0
1
Total
119 853
119 853
119 853
Table: Number of policies with k claims: observed, expected (ﬁtted) Poisson
and expected (ﬁtted) negative binomial
The above table shows that the negative binomial distribution gives a much
better ﬁt.
Application
As explained above, this model and the above data served F. Bichsel as the
basis for the construction of the Bonus—Malus system in third-party liability
motor insurance in Switzerland. His goal was to adjust the individual premium
according to the estimated expected claim frequency of the individual driver.
The idea was that, if a given risk was expected to make twice as many claims

28
2 The Bayes Premium
as the average driver, then such a person should pay a premium twice as high
as that of an “average” risk (malus of 100%). If, on the other hand, a driver
was expected to make only half as many claims as the average, he should
receive a bonus of 50%.
Based on the mathematical model and data presented above, the formula
for the Bonus—Malus factor (the factor by which the collective premium should
be multiplied) is:
Bonus—Malus factor =
\
F Bayes
0
,
where 0 = 0.155 = average observed claim frequency. Tabulated below are
the values of the Bonus—Malus factor derived for this example. In 1964, this
table formed the basis of the Bonus—Malus system in Switzerland.
n\k
0
1
2
3
1
87% 173% 260% 346%
2
76% 153% 229% 305%
3
68% 136% 205% 273%
4
62% 123% 185% 247%
5
56% 113% 169% 225%
6
52% 104% 155% 207%
Table: Bonus—Malus factor, where n = number of observation years, k =
number of observed claims
Remarks:
•
The Bonus—Malus system introduced in 1964 used other factors. The mod-
iﬁcations were due to the desire for a recursive premium on the one hand
and solidarity considerations on the other.
•
In Bichsel’s work, it is implicitly assumed that the a priori claim number
distribution does not depend on the horsepower class, which is of course a
simplifying assumption not fully reﬂecting reality.
•
Nowadays the taris are more reﬁned and based on many rating factors.
However, experience shows that the individual claim experience still re-
mains one of the most signiﬁcant variables for predicting future claims.
But, in calculating the Bayes premium the dierentiation of the tari
based on the other explanatory variables has to be taken into account (see
[Gis89]).
A Model Where the a Priori Expected Claim Frequencies Dier
Between Years and Risks
In the model used by Bichsel it was assumed that all drivers are a priori
equal risks, i.e. that they all have the same a priori expected claim frequency.
However, in many situations in practice this is not the case. For instance, if the
risks considered are ﬂeets of cars, then the a priori expected claim frequency

2.4 The Bayes Premium in Three Special Cases
29
will depend on the composition of the types of car of the ﬂeet and possibly
on other explanatory variates like region or mileage. Or if we want to make
individual estimates of mortality or disability rates in group life or group
accident insurance, then the a priori expected rates will depend on things like
age and sex structure of the considered group. There might also be changes
or trends in the claim frequencies over the years. The Poisson—Gamma model
can, however, also be used for such situations after a slight modiﬁcation and
extension. Applications in group life insurance of this model can be found e.g.
in [Kef29] and [Nor89]. It is worthwhile to mention that the Poisson—Gamma
model was known in the insurance ﬁeld as early as in 1929 [Kef29].
Before we do the modiﬁcation of the Poisson—Gamma model to the case of
known dierences of the a priori claim frequencies, it is worthwhile to recon-
sider Model Assumptions 2.8 and to write them in a slightly dierent way.
The following assumptions are equivalent to Model Assumptions 2.8:
PG1: Conditionally, given  = &, the Nj’s (j = 1, 2, . . . , n) are independent
and Poisson distributed with Poisson parameter & · 0, where 0 = 
 = a
priori expected claim frequency.
PG2:  has a Gamma distribution with E [] = 1 and shape parameter .
Remarks:
•
From E [] = 1 it follows that the scale parameter of the Gamma distrib-
ution must be equal to . Note that  = 0 and that
Var [] = 1
 .
•
Note also that
F ind = E [Nj| ] = 0 .
In the problem and terminology of Bichsel,  denotes directly the Bonus—
Malus factor.
•
A good intuitive measure for the heterogeneity of the portfolio is the co-
e!cient of variation CoVa
¡
F ind¢
. Note that in this model CoVa
¡
F ind¢
=
p
Var [] and that the parameter  has now a direct interpretation, since
 =
¡
CoVa(F ind¢
)2.
•
For estimating  it is natural to consider in addition or instead of the
“absolute” claim numbers Nj the “relative” claim frequencies
eFj = Nj
0
.
Note that
eF ind = E
h
f
Fj
¯¯¯ 
i
= .

30
2 The Bayes Premium
•
By dividing F Bayes from (2.8) by 0, we directly obtain
eF Bayes = e = E [| N] = 1 + 
µN•
•
 1
¶
,
(2.13)
where
N• =
Xn
j=1 Nj = observed number of claims,
• = n · 0 = a priori expected number of claims,
 =
•
• + 0 =
•
• +  .
Note also that
N•
•
= eF := 1
n
n
X
j=1
eFj,
and hence
e = 1 + 
³
eF  1
´
.
We now consider the situation where the a priori expected claim frequencies
vary between years and between risks in the portfolio. We consider a particular
risk and we denote by Nj the observed and by j the a priori expected number
of claims of that particular risk in year j. Of course j may now depend on
exogenous and explanatory variables like the composition of the particular
ﬂeet or the sex and age structure of the particular risk group in question. We
make the following assumptions:
Model Assumptions 2.10 (Poisson—Gamma model II)
PG1 0: The claim numbers Nj, j = 1, 2, . . . , are conditionally, given , inde-
pendent and Poisson distributed with Poisson parameter  j, where j is
the a priori expected claim number in year j.
PG2 0:  has a Gamma distribution with E [] = 1 and shape parameter .
Proposition 2.11. Under Model Assumptions 2.10 we have
eF Bayes = e = E [| N] = 1 + 
µN•
•
 1
¶
,
(2.14)
where
N• =
Xn
j=1 Nj = observed number of claims,
• =
Xn
j=1 j = a priori expected number of claims,
 =
•
• +  .

2.4 The Bayes Premium in Three Special Cases
31
Remarks:
•
Note that formula (2.14) is identical to formula (2.13). The interpretation
has, however, become wider: • may now vary between risks and depend
on explanatory variables as for instance on the composition of the types
of car for ﬂeets of cars or sex and age structure in group life insurance.
•
Formula (2.14) is a very convenient and intuitive one. It says that eF Bayes
is equal to one plus a correction term and the correction term is equal to
the credibility weight  times the deviation of the ratio “observed number
of claims divided by expected number of claims” from one. The constant 
in the denominator of  is the coe!cient of variation of F ind to the power
minus 2.
Proof of Proposition 2.11:
The proof is analogous to the proof of Proposition 2.9.
2.4.2 The Binomial—Beta Case
Motivation
In group life insurance or group accident insurance we are, among other things,
interested in the number of disability cases or equivalently, the disability fre-
quency for a particular group. For simplicity we assume that each member of
the group has the same probability of disablement and that individual dis-
abilities occur independently. Let us also assume that disabled members leave
the group.
Deﬁne the following random variables for each year j = 1, 2, . . .:
Nj = number of new disabilities occurring in the group
in the year j,
Vj = number of (not disabled) members of the
group at the beginning of year j,
Xj := Nj
Vj = observed disablement frequency
in year j.
At time n all random variables with indices  n are known and we are inter-
ested in
Xn+1 = Nn+1
Vn+1
.
Observe that on the right-hand side of the last equation only Nn+1 is not yet
known, hence we need to model only Nn+1.
Model Assumptions 2.12 (Binomial—Beta)
BB1: Conditionally, given  = &, Nj (j = 1, 2, . . . ) are independent and bi-
nomial distributed, i.e.

32
2 The Bayes Premium
P [Nj = k|  = &] =
µ Vj
k
¶
&k (1  &)Vjk .
BB2:  has a Beta(a, b) distribution with a, b > 0, equivalently, the structural
function has density
u (&) =
1
B (a, b)&a1 (1  &)b1 ,
0  &  1,
where
B (a, b) =  (a)  (b)
 (a + b) .
Remarks:
•
The ﬁrst two moments of the Beta-distributed random variable  are
E [] =
a
a + b,
Var [] =
ab
(1 + a + b) (a + b)2 .
•
Note that  is the “true” underlying disablement probability we want to
determine.
•
The family of the Beta distributions for the structure function is quite
large. The density functions for dierent values of the structural parame-
ters a and b can be seen from Figure 2.3.
Proposition 2.13. Under Model Assumptions 2.12 we have for the frequency
F ind = E [Xn+1 |] = ,
F coll = E [] =
a
a + b,
(2.15)
F Bayes =
a + N•
a + b + V•
= N + (1  )
a
a + b,
(2.16)
where N = N•
V•
,
 =
V•
a + b + V•
.
The quadratic loss of F Bayes is
E
£
(F Bayes  )2¤
= (1  ) E
£
(F coll  )2¤
(2.17)
=  E
£
(N  )2¤
.
(2.18)
Proof:
F ind and F coll follow directly from the model assumptions. To obtain F Bayes,
we derive the posterior density of  given N1, N2, . . . , Nn
u (&| N) 2
nQ
j=1
&Nj (1  &)VjNj &a1 (1  &)b1
= &a+N•1 (1  &)b+V•N•1 .

2.4 The Bayes Premium in Three Special Cases
33
0.000
3.500
0
1
0.000
6.000
0
1
0.000
7.000
0
1
0.000
1.000
2.000
3.000
4.000
5.000
6.000
7.000
8.000
9.000
0
1
0.000
1.200
0
1
0.000
1.600
0
1
0.000
3.000
0
1
0.000
1.400
0
1
0.000
1.800
0
1
0.000
1.800
0
1
0 <  b < 1
0 <  a < 1
a = 1
a > 1
 a > 2
 b = 1
 b > 2
b > 1
Fig. 2.3. Beta densities for dierent parameter values a and b
Hence the posterior distribution is again Beta, but with updated parameter
values
a0 = a + N•,
b0 = b + V•  N•.
Hence
F Bayes = e := E [| N] =
a0
a0 + b0 ,
which is the same as (2.16) .
For the quadratic loss of F Bayes we obtain

34
2 The Bayes Premium
E
·³
e  
´2¸
= E
·
E
·³
e  
´2
|
¸¸
= 2 E
£
Var
£
N |
¤¤
+ (1  )2 Var [] .
E
£
Var
£
N |
¤¤
= 1
V•
E [ (1  )]
= 1
V•
¡
E []  Var []  E2 []
¢
= 1
V•
Ã
ab
(a + b)2  Var []
!
= 1
V•
(a + b) Var [] .
Hence
E
·³
e  
´2¸
=
V•
(a + b + V•)2 (a + b) Var [] +
a + b
(a + b + V•)2 Var [] ,
=
a + b
a + b + V•
Var [] ,
= (1  ) Var [] ,
which is the same as (2.17) . From the above equations and the expression for
 we also get
a + b
a + b + V•
Var [] =  E
£
Var
£
N |
¤¤
.
Noting that
E
£
Var
£
N |
¤¤
= E
h¡
N  
¢2i
,
we see that (2.18) is also fulﬁlled, which ends the proof of Proposition 2.13.¤
2.4.3 The Normal—Normal Case
We will present this model here without any practical motivation.
Let us again consider an individual risk and let X = (X1, X2, . . . , Xn)0 be
the observation vector, where Xj is, for example, the aggregate claim amount
in the jth year.

2.4 The Bayes Premium in Three Special Cases
35
Model Assumptions 2.14 (normal—normal)
•
Conditionally, given  = &, the Xj’s (j = 1, 2, . . . , n) are independent and
normally distributed, that is,
Xj  N
¡
&, 2¢
.
•
  N
¡
µ,  2¢
, that is the structural function has density
u (&) =
1
s
2 e 1
2( &µ
 )
2
.
Remark:
•
Insurance data are mostly not normally distributed. However, because
of the Central Limit Theorem, Model Assumptions 2.14 are sometimes
appropriate for a portfolio of large risk groups.
Proposition 2.15. Under Model Assumptions 2.14 we have
P ind = E [Xn+1 |] = ,
P coll = E [] = µ,
(2.19)
P Bayes =  2 µ + 2X•
 2 + n 2
= X + (1  ) E [] ,
(2.20)
where  =
n
n + 2
 2
,
X = 1
nX•.
The quadratic loss of P Bayes is
E
£
(P Bayes  )2¤
= (1  ) E
£
(P coll  )2¤
(2.21)
=  E
£
(X  )2¤
.
(2.22)
Proof:
P ind and P coll follow directly from the model assumptions. To obtain P Bayes =
e := E [| X], we derive the a posteriori density of  given X
u (& | X) 2
1
s
2 e 1
2( &µ
 )
2
n
Y
j=1
µ
1
s
2 e 1
2
³ Xj &

´2¶
.
(2.23)
For the exponents on the right-hand side of (2.23) we get (1 and 2 denote
the terms, which are independent of &):
1
2
©¡
 2 + n2¢
&2  2
¡
 2µ + n2X
¢
& + 1
ª
= 1
2
¡
 2 + n2¢
(µ
&   2 µ + n 2 X
 2 + n 2
¶2
+ 2
)
= 1
2
¡
 2 + n2¢
(µ
&  2 µ + n  2 X
2 + n  2
¶2
+ 2
)
.

36
2 The Bayes Premium
From this, it is obvious that the a posteriori distribution of  given X is again
a normal distribution, but with updated parameters
µ0 = 2 µ + n  2 X
2 + n  2
,
( 0)2 =
 22
2 + n 2 .
From the identity
2 µ + n  2 X
2 + n  2
=
n
n + 2
2
X +
Ã
1 
n
n + 2
2
!
µ
we get the formula for P Bayes.
For the quadratic loss of P Bayes we get
E
·³
e  
´2¸
= E [Var [ |X]]
= ( 0)2
= (1  )  2,
which is the same as (2.21). From
(1  )  2 =
2
n + 2
2
= 2
n
and
E
£
(X  )2¤
= E
©
E
£
(X  )2¯¯ 
¤ª
= 2
n
follows that (2.22) is also fulﬁlled, which ends the proof of Proposition 2.15. ¤
Figures 2.4 and 2.5 illustrate the conversion of the a priori distribution into
the a posteriori distribution. Notice the shift in the expected value and the
fact that the variance decreases with increasing n.
2.4.4 Common Features of the Three Special Cases Considered
i) In all three cases, the Bayes premium is a linear function of the observa-
tions and is therefore a credibility premium.
ii) In all three cases, P Bayes can be expressed as a weighted mean, that is,
P Bayes =  X + (1  ) P coll.
(2.24)
iii) In all three special cases we see that the weight  is given by
 =
n
n +  ,
where  is an appropriate constant.
(2.25)

2.4 The Bayes Premium in Three Special Cases
37
0.00
0.05
0.10
0.15
0.20
0.25
0.00
5.00
10.00
15.00
20.00
Fig. 2.4. A priori distribution of W: W ; normal
¡
µ = 10,  2 = 32¢
0.00
0.05
0.10
0.15
0.20
0.25
0.00
5.00
10.00
15.00
20.00
Fig. 2.5. A posteriori distribution of W, given 5 observations with X = 15 and
j2 = 52
iv) In all three cases the quadratic loss of the Bayes premium is given by
E
h¡
P Bayes  
¢2i
= (1  ) E
h¡
P coll  
¢2i
=  E
h¡
X  
¢2i
.
v) In all three cases, we ﬁnd that the a posteriori distribution of  belongs
to the same family as the a priori distribution. We will see in the following
section that this did not happen purely by chance.

38
2 The Bayes Premium
2.5 Conjugate Classes of Distributions
The above three cases are contained in the general framework that we are
going to discuss in this section. Let the observation vector X have indepen-
dent components, which — up to some weighting — have the same conditional
distribution F& given  = &. We look at the family of possible marginal dis-
tributions F = {F& : & 5 }. In insurance practice, the speciﬁcation of the
family F is in itself a problem. Sometimes, there are indications about which
families might be appropriate. For example, for modelling the random vari-
able of the number of claims, the Poisson distribution is often a reasonable
choice. However, in many situations, we have no idea about the distribution
of the observations and specifying F is very problematic. How we deal with
such situations will be discussed in Chapter 3.
The choice of the family F is not easy, but the choice of the structural
function U(&), or more precisely, the choice of a family U = {U(&) | 5  }
of structural functions indexed with the hyperparameter  5 , to which U(&)
belongs, is even more di!cult.
The following conditions should be satisﬁed so that the whole framework
provides an instrument which is suitable for use in practice:
i)
The family U must be big enough so that it contains su!ciently many
distributions which could, in reality, describe the collective.
ii)
The family U should be as small as possible to reﬂect our understanding
of the collective.
iii) Ideally, the families F and U should be chosen so that the model is math-
ematically tractable and in particular, so that the Bayes premium can be
written in an analytic form.
In order to guarantee such behaviour, a useful concept is that of conjugate
families of distributions.
Deﬁnition 2.16. The family U is conjugate to the family F if for all  5 
and for all realizations x of the observation vector X there exists a 0 5 
such that
U (&| X = x) = U0(&)
for all & 5 ,
(2.26)
i.e. the a posteriori distribution of  given X is again in U for every a priori
distribution from U.
Remarks:
•
The biggest possible family U (that which contains all distribution func-
tions) is conjugate to any given family F. However, in order that our
resulting model be useful, it is important that U should be as small as
possible, while still containing the range of “realistic” distributions for the
collective.
•
In Section 2.4 we saw three examples of conjugate classes of distributions
(Poisson—gamma, binomial—beta, normal—normal).

2.5 Conjugate Classes of Distributions
39
2.5.1 The Exponential Class and Their Associated Conjugate
Families
Deﬁnition 2.17. A distribution is said to be of the exponential type, if it can
be expressed as
dF(x) = exp
·x&  b(&)
2/w
+ c(x, 2/w)
¸
d(x), x 5 A  R.
(2.27)
In (2.27)  denotes either the Lebesgue measure or counting measure, b(·) is
some real-valued twice-dierentiable function of &, and w and 2 are some
real-valued constants.
Deﬁnition 2.18. The class of distributions of the exponential type as deﬁned
in (2.27) is referred to as the one (real-valued) parameter exponential class
Fexp = {F& : & 5 } .
(2.28)
Remarks:
•
The one parametric exponential class Fexp covers a large class of fami-
lies of distributions. It includes, among others, the families of the Poisson,
Bernoulli, gamma, normal and inverse-Gaussian distributions. It plays a
central role in the framework of general linear models (GLM), which it-
self belongs to the standard repertoire of tools used in the calculation of
premiums depending on several rating factors.
•
Each of such families within Fexp is characterized by the speciﬁc form of
b (.) and c (., .) . We will denote such a speciﬁed family by Fb,c
exp.
•
The above parameterization of the density is the standard notation used in
the GLM literature (see, for example, McCullagh and Nelder [MN89] or the
description of the GENMOD procedure [SAS93]), and is often referred to
as the natural parametrization. The term 2/w in (2.27) could be replaced
by a more general function a(2). In the literature, the exponential class is
often deﬁned in this slightly more general way. However, this more general
form is of a rather theoretical nature, since in practical applications and
also in the GENMOD procedure, it is almost always true that a(2) =
2/w.
•
The parameter & is referred to as the canonical parameter. In our context,
& is to be interpreted as the risk proﬁle taking values in . Observe that & is
here one-dimensional and real. The parameter 2 is called the dispersion
parameter, assumed to be ﬁxed. Lastly, the quantity w denotes a prior
known weight (w = weight) associated with the observation. Whereas the
dispersion parameter 2 is constant over observations, the weight w may
vary among the components of the observation vector.
•
Another interesting parametrization can be found in [Ger95].
Let us now take a speciﬁc family Fb,c
exp 5 Fexp characterized by the speciﬁc
form of b (.) and c (., .) .

40
2 The Bayes Premium
Theorem 2.19. We assume that for a given &, the components of the vector
X = (X1, . . . , Xn) are independent with distribution F& 5 Fb,c
exp, each with the
same dispersion parameter 2 and with weights wj, j = 1, 2, . . . , n.
We consider the family
Ub
exp =
©
u(&) :  =
¡
x0,  2¢
 R × R+ª
,
(2.29)
where
u(&) = exp
·x0&  b(&)
 2
+ d(x0,  2)
¸
, & 5 ,
(2.30)
are densities (with respect to the Lebesgue measure).
Then it holds that Ub
exp is conjugate to Fb,c
exp.
Remarks:
•
x0 and  2 are hyperparameters.
•
Note that exp
£
d(x0,  2)
¤
in (2.30) is simply a normalizing factor.
•
Note that the family conjugate to Fb,c
exp depends only on the function b (&)
and not on c
¡
x, 2/w
¢
.
Proof of Theorem 2.19:
For the a posteriori density of  given X we get
u (&| X = x) 2
n
Y
j=1
exp
·xj&  b(&)
2/wj
¸
· exp
·x0&  b(&)
 2
¸
= exp
5
97
h
2
 2 + w•
i1 h
2
2 x0 + w•x
i
&  b(&)
2/
¡ 2
 2 + w•
¢
6
:8 ,
where x =
Xn
j=1
wj
w•
xj
and
w• =
Xn
j=1 wj.
We see immediately that with the a priori distribution (with the hyperpara-
meters x0,  2) the a posteriori distribution, given X = x, is again in Ub
exp,
with updated hyperparameters
x0
0 =
µ2
 2 x0 + w•x
¶ µ2
 2 + w•
¶1
and
 02 = 2
µ2
 2 + w•
¶1
.
(2.31)
This proves Theorem 2.19.
¤
We now want to determine P ind, P coll and P Bayes.

2.5 Conjugate Classes of Distributions
41
Theorem 2.20. For the family Fb,c
exp and its conjugate family Ub
exp we have
i)
P ind (&) = b0(&) and
Var [Xj|  = &, wj] = b00(&)2/wj.
(2.32)
If the region  is such that exp [x0&  b(&)] disappears on the boundary of 
for each possible value x0, then we have
ii)
P coll = x0,
(2.33)
iii)
P Bayes = X + (1  )P coll,
(2.34)
where
X =
X
j
wj
w•
Xj,
 =
w•
w• + 2
 2
.
Remarks:
•
Note that P Bayes is a weighted average of the individual claims experience
and the collective premium. It is a linear function of the observations, and
therefore a credibility premium. The case where P Bayes is of a credibility
type is often referred to as exact credibility in the literature.
•
The credibility weight  has the same form as in (2.25) and w• now plays
the role of the number of observation years.
Proof of Theorem 2.20:
For the proof of (2.32) we consider the moment-generating function of X given
 = & and given the weight w.
mX (r) = E
£
erX¯¯  = &]
=
Z
erx exp
·x&  b (&)
2/w
+ c
¡
x, 2/w
¢¸
d (x)
=
Z
exp
"
x
¡
& + r2/w
¢
 b
¡
& + r2/w
¢
2/w
+ c
¡
x, 2/w
¢
#
d (x)
× exp
"
b
¡
& + r2/$
¢
 b (&)
2/w
#
= exp
"
b
¡
& + r2/w
¢
 b (&)
2/w
#
,

42
2 The Bayes Premium
where the last equality follows because the integral term is equal to 1 (inte-
gration of a probability density function). The cumulant-generating function
is therefore given by
kX(r) := ln mX(r) = b
¡
& + r2/w
¢
 b (&)
2/w
.
From this we get
P ind (&) :=
E [X| = &] = k0
X(0) = b0 (&) ,
Var [X|  = &] = k00
X(0) = b00(&) 2/w.
We have thus proved (2.32).
For the proof of (2.33) we see that
P coll =
Z

µ (&) exp
·x0&  b (&)
 2
¸
d& · exp
©
d
¡
x0,  2¢ª
=
Z

b0 (&) exp
·x0&  b (&)
 2
¸
d& · exp
©
d
¡
x0,  2¢ª
= x0 
Z

(x0  b0 (&)) exp
·x0&  b (&)
 2
¸
d& · exp
©
d
¡
x0,  2¢ª
= x0   2 exp [x0&  b (&)]|C ,
(2.35)
where C denotes the boundary of . The choice of the parameter region
 turns out to be crucial. Under the technical assumption made in Theorem
2.20, that  has been chosen in such a way, that the boundary term disappears
for every x0, we get
P coll = x0,
so that we have proved (2.33).
From the proof of Theorem 2.19, where we showed that the a posteriori
distribution of  given X = x also belongs to Ub
exp with hyperparameters
x0
0 =
µ2
 2 x0 + w•x
¶ µ2
 2 + w1
•
¶1
,
 02 = 2
µ2
 2 + w•
¶1
,
we get without further ado
P Bayes = ^
µ () = E [µ () |X] = X + (1  ) x0,
where X =
n
X
j=1
wj
w•
Xj,
w• =
n
X
j=1
wj,
 =
w•
w• + 2/ 2 .

2.5 Conjugate Classes of Distributions
43
This proves (2.34) and thus ends the proof of Theorem 2.20.
¤
Under the following special assumptions, we get the classical examples
(including those already seen in Section 2.4):
a) Poisson—Gamma: We have frequency observations Xj = Nj
wj , where, con-
ditional on &, Nj is Poisson distributed with parameter j = wj&. The
density of Xj is then given by
f& (x) = ewj& (wj&)wjx
(wjx)!
for x = k
wj
, k 5 N0.
This can be written in the form (2.27) as follows:
e& = log &,
b
³
e&
´
= exp
³
e&
´
,
e2 = 1,
ew = wj,
c
³
x, e2/ ew
´
=  log (( ewx)!) + ewx log ew.
To ﬁnd the conjugate family of prior distributions Ub
exp we insert e& and
b
³
e&
´
into (2.30) and we get
u(e&) 2 exp
5
7
x0e&  exp
³
e&
´
 2
6
8 .
This density, expressed in terms of the original variable & rather than e&,
becomes
u(&) 2 1
& · exp
·
log
³
&x0/ 2´
 &
 2
¸
(2.36)
= &
x0
2 1e 1
2 &.
Note that by the change of variables from e& to & we have to take into
account the ﬁrst derivative de&/d& (term 1/& on the right-hand side of
(2.36)).
Hence
Ub
exp =
n
u (&) : u (&) 2 &
x0
2 1e 1
2 &; x0,  2 > 0
o
,
which is the family of the Gamma distributions.
For P coll we get
P coll = E [] = x0
 2  2 = x0,
hence (2.33) is fulﬁlled.

44
2 The Bayes Premium
b) Binomial—Beta: We have frequency observations Xj = Nj
wj , where condi-
tional on &, Nj has a Binomial distribution with n = wj and p = &. The
density of Xj is then given by
f& (x) =
µ wj
wjx
¶
&wjx (1  &)wjwjx for x = k/wj, k = 0, . . . , wj, wj 5 N.
This can be written in the form of (2.27) as follows:
e& = log
³
&
1&
´
,
b
³
e&
´
= log
³
1 + ee&´
,
e2 = 1,
ew = wj,
c
³
x, e2/ ew
´
= log
¡ ew
ewx
¢
.
From (2.30) we get
Ub
exp =
n
u (&) : u (&) b &
x0
2 1 (1  &)
1x0
2
1 ;
0 < x0 < 1,  2 > 0
o
,
which is the family of beta distributions.
For P coll, we get
P coll = E [] =
x0
 2
x0
2 + 1x0
2
= x0.
c) Gamma—Gamma: We have observations Xj, that are, conditional on &,
Gamma distributed with shape parameter wj and scale parameter wj&,
where wj is the weight associated with Xj. In particular, this is the case
if the observations Xj are the average of wj independent claim sizes, each
of them Gamma distributed with shape parameter  and scale parameter
&. The density of Xj is then given by
f&(x) = (wj&)wj
 (wj) xwj1ewj&x.
This can be written in the form (2.30) as follows:
e& = &,
b
³
e&
´
=  log
³
e&
´
,
e2 = 1,
ew = wj,
c
³
x, e2/ ew
´
= ( ew  1) log (x)  log ( ( ew)) + ew log ( ew) .
Note that
µ (&) := E& (Xj) = &1.
From (2.30) we get
Ub
exp =
n
u (&) : u (&) 2 &
1
2 e x0
2 &;
 2 5 (0, 1) , x0 > 0
o
,
which is the family of gamma distributions.
One can easily check that
P coll = E [µ ()] = x0.

2.5 Conjugate Classes of Distributions
45
d) NormalNormal: We have observations Xj that are, conditional on &,
normally distributed with expected value & and variance 2/wj. The den-
sity of Xj is then given by
f&,,wj (x) = (22/wj)1/2 exp
(
(x  &)2
22/wj
)
.
This can be written in the form of (2.27) as follows:
e& = &,
b
³
e&
´
= e&
2/2,
e2 = 2,
ew = wj,
c
³
x, e2/ ew
´
=  1
2
³
x2
e2/ ew + log
³
2e2/ ew
´´
.
From (2.30) we get that
Ub
exp =
(
u (&) : u (&) 2 exp
Ã
(&  x0)2
2 2
!
;
x0,  2  R × R+
)
,
i.e. the family of conjugate distributions is the family of normal distribu-
tions. From this we can immediately see that
P coll = E [] = x0.
e) GeometricBeta: We have observations Xj, that are, conditional on &,
distributed with a geometric distribution with parameter & (i.e. without
weights, or equivalently, all weights wj are equal to 1). The density of Xj
is then given by
f& (x) = (1  &)x &,
x 5 N.
This can be written in the form of (2.27) as follows:
e& = log (1  &) ,
b
³
e&
´
=  log
³
1  ee&´
,
e2 = 1,
ew = 1,
c
³
x, e2/ ew
´
= 0.
Note that
µ (&) = E& (Xj) = 1  &
&
.
From (2.30) we get that
Ub
exp =
n
u (&) : u (&) 2 (1  &)
x0
2 1 &
1
2 ;
x0 >  2, 0 <  2 < 1
o
,
which is the family of the Beta distributions.
Again, one can easily verify, that
P coll = E [µ ()] = x0.

46
2 The Bayes Premium
2.5.2 Construction of Conjugate Classes
The following theorem is often helpful when we are looking for a conjugate
family U to the family F = {F& : & 5 }.
Theorem 2.21.
Assumptions: F and U satisfy the following conditions:
i) The likelihood functions l(&) = f&(x), x ﬁxed, are proportional to an ele-
ment of U, i.e. for every possible observation x 5 A, there exists a ux 5 U,
such that ux(&) = f&(x)
¡R
f&(x)d&
¢1.
ii) U is closed under the product operation, i.e. for every pair u, v 5 U we
have that u(·)v(·)
¡R
u(&)v(&)d&
¢1 5 U.
Then it holds that U is conjugate to F.
Proof: Given X = x, we ﬁnd the following a posteriori distribution:
u (& | x) =
f&(x)u(&)
R f&(x)u(&)d&
=
R
f&(x)d&
R
f&(x)u(&)d& ux(&) u(&) 5 U.
This proves Theorem 2.21.
¤
Theorem 2.21 indicates how we should construct a family U, which is con-
jugate to the family F. Deﬁne
U0 =
(
ux : ux(&) = f&(x)
µZ
f&(x)d&
¶1
, x 5 A
)
.
If U0 is closed under the product operation then U0 is conjugate to F. If not,
it can often be extended in a natural way.
Example:
Let F be the family of binomial distributions
F = {f& (x) : & 5 [0, 1]} with
f& (x) =
µn
x•
¶
&x• (1  &)nx• ,
x• =
nP
j=1
xj,
xj 5 {0, 1}.
Then we see that U0 consists of the Beta distributions with (a, b) 5 {(1, n+1),
(2, n), (3, n  1),. . . , (n + 1, 1)}.
U0 is not closed under the product operation. A natural extension is
U = {Beta (a, b) : a, b > 0} .
It is easy to check that U is closed under the product operation and that U is
therefore, by Theorem 2.21, conjugate to F.

2.6 Another Type of Example: the Pareto3Gamma Case
47
2.6 Another Type of Example: the ParetoGamma Case
The model and the results of this section are taken from [Ryt90].
Motivation
A frequent assumption in the practice of reinsurance is that the claim amounts
of those claims which exceed a given limit x0 are Pareto distributed. Typically,
based on information from numerous portfolios, the reinsurer has an “a priori”
idea about the level of the “Pareto parameter” &. He also collects information
from the primary insurer about all claims exceeding a particular limit c0, and
he can also use this information to estimate &. The question then arises as to
how he can best combine both sources of information in order to estimate &
as accurately as possible.
Let X0 = (X1, . . . , Xn) be the vector of observations of all the claim sizes, of
those claims belonging to a given contract, whose size exceeds x0. We assume
that the Xj (j = 1, . . . , n) are independent and Pareto distributed,
Xj  Pareto (x0, &),
(2.37)
with density and distribution function
f&(x) = &
x0
µ x
x0
¶(&+1)
and
F& (x) = 1
µ x
x0
¶&
for x  x0, (2.38)
and with moments
µ(&) = x0
&
&  1,
if & > 1,
2(&) = x2
0
&
(&  1)2(&  2),
if & > 2.
In order to incorporate the a priori knowledge, we further assume that
the Pareto parameter & is itself the realization of a random variable  with
distribution function U (&). In order to specify an appropriate class U of a pri-
ori distributions, to which U(&) belongs, we use the technique from Theorem
2.21.
The likelihood function leads to the following family:
U0 =
;
?
=ux : ux(&) 2 &n exp
3
C
3
C
n
X
j=1
ln
µxj
x0
¶4
D &
4
D
<
@
> .
The elements of U0 are Gamma distributions. The natural extension of U0 is
therefore the family of the Gamma distributions, i.e.
U =
½
distributions with densities u(&) =

()&1 exp{&}
¾
.
(2.39)

48
2 The Bayes Premium
Since the family U is closed with respect to the product operation, we have
that U is conjugate to
F = {Pareto(x0, &) : &, x0 > 0} .
We are looking for the best estimator of the Pareto parameter .
From the form of the likelihood function (2.38) and with the form of the a
priori distribution (2.39) we get for the a posteriori density of  given x
ux (&) 2 &+n1 exp
;
?
=
3
C +
n
X
j=1
ln
µxj
x0
¶4
D &
<
@
> .
We see that ux(&) is again the density of a Gamma distribution with updated
parameters
0 =  + n
and
0 =  +
Xn
j=1 ln
µxj
x0
¶
.
The Bayes estimator for  is therefore given by
e = E [|X] =
 + n
 +
nP
j=1
ln
³
Xj
x0
´.
(2.40)
Formula (2.40) can be written in another, more easily interpretable form. In
order to do this, we ﬁrst consider the maximum-likelihood estimator for the
Pareto parameter &, i.e. the estimator that one might use if we only had data
and no a priori information. This is given by
b&MLE =
n
nP
j=1
ln
³
Xj
x0
´.
(2.40) can now be written as
e =  · b&MLE + (1  ) · 
 ,
where
 =
3
C
n
X
j=1
ln
µXj
x0
¶4
D
3
C +
n
X
j=1
ln
µXj
x0
¶4
D
1
.
The Bayes estimator for  is therefore a weighted average of the maximum-
likelihood estimator and the a priori expected value E [] = /, where,
however, in contrast to the earlier examples, the weight  depends on the
observations and is not a credibility weight in the strict sense of Theorem
2.20.

2.7 Summary
49
2.7 Summary
Here, we give a short summary of the results of this chapter.
Bayes model:
•
F = {F& : & 5 }: family of distributions indexed with the parameter
& 5 .
•
U(&): structural function, the a priori distribution of .
•
P Bayes = ]
µ() = E [µ()| X]: Bayes estimator (with respect to the
quadratic loss function).
In a number of well-structured models, it is possible to explicitly calculate
the Bayes estimator, and in some of these cases (one-dimensional exponential
families and conjugate families, see Section 2.5) this estimator has a linear
form, i.e. it is a credibility estimator. We refer to such cases as exact credibility.
If the structural function U is not known exactly, and we only know that U
belongs to a certain family U of distributions, it may be possible to estimate
the unknown parameters of the distribution from the data of the collective
(empirical Bayes).
Various open questions:
•
In the cases studied in this chapter, we could write down, in closed form,
formulae for the Bayes premium. Typically, however, this is not the case.
Usually the Bayes estimator can be calculated only using relatively com-
plicated numerical procedures.
•
How restrictive are the assumptions that we have made about the distri-
bution functions (e.g. PoissonGamma)? Do we really need to know the
whole distribution function or would it be enough to know only the ﬁrst
and second moments?
Requirements and constraints in practice:
•
Simplicity: The formula for the premium should be as simple and as in-
tuitive as possible. This is in general not the case for the exact Bayes
estimator.
•
Structure: In order to calculate the Bayes estimator we would need to spec-
ify the family of conditional distributions F and the structural function U,
respectively the family U of structural functions, from which U comes. In
practice such a speciﬁcation is either quite artiﬁcial (in the case where U
and F are small) or not helpful (in the case where U and F are large). In
other words: in practice we usually know neither F nor U, respectively U.
In general, we must content ourselves with being able to make reasonable
estimates of the ﬁrst few moments of the distributions.
In practice then, the exact Bayes formula is often not a realistic method.
One way out of this dilemma is the credibility technique, which will be intro-
duced in the next chapter.

50
2 The Bayes Premium
2.8 Exercises
Exercise 2.1
We consider an individual risk which can produce a total claim amount in one
year of either 10 000 or 0 (claim free year).
This individual risk is taken from a collective, which contains three types
of risks: good (65%), medium (30%), bad (5%). The conditional probabilities
are given in the following table:
Conditional probabilities
Total claim amount Good Medium
Bad
0
97%
95%
90%
10 000
3%
5%
10%
a) Calculate P ind and P coll.
b) There is one year’s claim experience.
Calculate P Bayes for all possible observations (claim amount 0 or 10 000).
c) Calculate P Bayes for all possible observations in the case where we have
two years’ claim experience, and under the usual assumption, the claims in
the two years are conditionally independent, given the risk parameter .
Exercise 2.2
A company wants to introduce a no-claims discount in household insurance:
the insured gets a discount of 15% after three consecutive claim-free years.
The premium is proportional to the sum insured and it is assumed that
the following assumptions hold true:
•
The claim number Nij of the insured i in year j is Poisson distributed
with Poisson parameter i. This Poisson parameter does not depend on
the sum insured, and it is assumed that the claim numbers Nij satisfy the
assumptions of the PoissonGamma model (Model Assumptions 2.8).
•
Claim number and claim sizes are independent.
•
The expected value of the claim size is proportional to the sum insured.
The following statistical data are available:
k
0
1
2
3
4
= 5
Total
# of policies
with k claims
in one year
143 991 11 588 1 005 85
6
2
156 677
a) Fit a negative binomial distribution to the observations of the above table.
b) Calculate the coe!cient of variation CoVa(i), which is a good measure
of the heterogeneity of the portfolio.

2.8 Exercises
51
c) Calculate the impact of the introduction of such a no-claims discount on
the premiums (premium reduction in % due to the no claims discount). For
simplicity reasons we assume that all policies have an observation period
of = 3 years.
d) Is the discount rate of 15% for three claim free years reasonable? Compare
it with the value obtained for the corresponding empirical Bayes estimator.
Exercise 2.3
In group life insurance, for an age segment of interest (e.g. ages between 25
and 65) and for larger collectives, we would like to use “individual mortality
tables”. In order to model this, we assume that the age proﬁle in the individ-
ual mortality table is equal to that in the “basis mortality table” multiplied
by a factor i (so that e.g. qind
x
= iqx). We further assume that i has a
Gamma distribution with expected value 1 and a coe!cient of variation of
20%.
We have the following observations from the past:
observed number of years at risk: 6 500
expected number of deaths based on the basis mortality table: 25
observed number of deaths: 15
Find the associated Bayes estimator Bayes
i
of i.
Exercise 2.4
We consider a ﬂeet of cars. On the basis of suitable statistics, we know the
expected “a priori” claim frequencies. On the other hand, factors such as
driver education, deadline expectations and car equipment have an inﬂuence
on the claim frequency and lead to large dierences between the risk quality
of dierent ﬂeets. We assume that the assumptions of the PoissonGamma
model II (Model Assumptions 2.10) are fulﬁlled and we estimate that the
dierences between the risk quality of dierent ﬂeets is about ± 20% (i.e.
CoVa () = 20%).
a) Determine the formula for the Bayes premium based on the total claim
numbers in one year of an entire ﬂeet with the following vehicles: 30 lorries,
30 delivery vans, 10 passenger cars. The a priori claim frequencies for the
dierent vehicle types are
Vehicle type
“a priori” frequency in %0
Lorry
300
Delivery van
100
Passenger car
75

52
2 The Bayes Premium
b) How big is the “experience correction” in %, if
—
16 claims are observed in one year,
—
20 claims are observed in two years.
c) Make a graphical display of the a priori distribution of  and of the a
posteriori distribution of  given 20 observed claims in two years.
Exercise 2.5
In workers’ compensation (collective accident insurance), the probability of
disability is of interest. For a particular portfolio of collective policies, we know
that, on average, the probability of disability is p0 = 10 %o. The probabilities
however dier between types of business. We use the Beta—Binomial model,
and we assume that the coe!cient of variation of i is 50%.
a) Determine the parameters of the a priori distribution and make a graph
of the a priori density u(&).
b) Find the Bayes estimator Bayes
i
for business type i where we have observed
15 disability cases out of 1 000 observed insured.
c) A company would like to divide all business types into three groups and
apply to them the following tari rules:
—
a surcharge of 20%, if E [i |Ni, wi ]  1.3 p0,
—
a rebate of 20%, if E [i |Ni, wi ]  0.7 p0,
where Ni is the observed number of disability cases, wi the observed
number of years at risk and p0 the a priori probability of disability.
What is the corresponding decision rule expressed in the observed number
of disability cases
i)
for a business with 500 observed years at risk,
ii) for a business with 2 000 observed years at risk?
Exercise 2.6
An actuary in a reinsurance company has to quote an excess of loss reinsurance
cover with retention 2 Millions CHF and no upper limit for a particular ceding
company in the motor liability line. For this purpose he assumes that the
claims above 1 Million CHF are Pareto distributed, and he wants to estimate
the Pareto parameter .
During the last three years ten claims exceeding 1 Million CHF (statistical
limit) have been observed with the following (inﬂation adjusted) claim sizes
in Millions CHF: {1.1, 1.2, 1.2, 1.4, 1.5, 1.8, 2.0, 2.4, 3.0, 4.2}. We estimate the
expected number of claims above this statistical limit of 1 Million as 3.5 for
the next year to be quoted.
In addition, from experience with lots of such treaties, the following a priori
information is available: E [] = 2.5,  () = 0.5.

2.8 Exercises
53
a) Calculate
b&MLE (maximum-likelihood estimator) and Bayes (Bayes estimator of 
based on the Pareto—Gamma model (see Section 2.6)).
b) Calculate the pure risk premium for the excess of loss cover with retention
2 Millions based on the Pareto distribution with Bayes, b&MLE and coll.
Exercise 2.7
In the accident line of business, we would like to determine the expected
average claim amount for various risk classes. The data can be well described
by a Lognormal distribution. In the model we assume that the coe!cient
of variation is the same for all risk classes and has the value 4, but that
the expected values dier from one class to another. We therefore assume,
conditionally on i, that the claim amounts have a lognormal distribution
with parameters i and .
a) Find the natural conjugate family.
b) Denote by Y ()
i
,  = 1, 2, ..., n the observed claim amounts of risk class i.
Find the Bayes estimator for i with the a priori distribution from the
natural conjugate family and under the assumptions that E [i] = 7.3
and that the coe!cient of variation of i is 10%. Compare it with the
maximum-likelihood estimator (for  known, & unknown).
c) For two classes i = 1, 2 we have observed the following claim amounts Y ()
i
:
 =
1
2
3
4
5
Y ()
1
125 187
210
326
470
Y ()
2
161 1 100 1 899 6 106
7 469
 =
6
7
8
9
10
Y ()
1
532 1 001 1 095 9 427 140 591
Estimate the expected value of the claim size for each of the two classes
by estimating the parameter i of the lognormal distribution and insert-
ing this estimate into the formula of the ﬁrst moment of the Lognormal
distribution. Estimate i by three dierent methods: b&
MLE
i
(maximum-
likelihood estimate), coll
i
, Bayes
i
. Make a table of the obtained estimates
of the expected value of the claim amount and the observed mean of the
claim amounts. Comment on the results.
Exercise 2.8
Consider the family F = {f& (k) |& 5 (0, 1)} of negative binomial distribu-
tions, where f& (k) = P& (X = k) b & (1  &)k and where  is ﬁxed.

54
2 The Bayes Premium
i)
Find the family U conjugate to F.
ii) Assume that {Xj : j = 1, 2, . . . , n} have, conditionally on  = &, a neg-
ative binomial distribution with density f& (k) and that they are condi-
tionally independent. It is further assumed that  has a Beta distribution
with parameters (a, b). Derive the Bayes estimator for .
Exercise 2.9
Consider the standard model:
•
X1, X2 . . . are conditionally on  = & independent and identically distrib-
uted.
•
 is a random variable with distribution U (&).
We deﬁne the Bayes predictor XBayes
n+1
of Xn+1 based on the observations X1,
. . . , Xn as the best predictor of Xn+1 with respect to expected quadratic
loss.
Show that the Bayes predictor of Xn+1 is identical to the Bayes estimator
of µ () = E [Xn+1 |].

3
Credibility Estimators
We have seen that the Bayes premium ]
µ() = E [µ()| X] is the best possi-
ble estimator in the class of all estimator functions. In general, however, this
estimator cannot be expressed in a closed analytical form and can only be cal-
culated by numerical procedures. Therefore it does not fulﬁl the requirement
of simplicity. Moreover, to calculate ]
µ(), one has to specify the conditional
distributions as well as the a priori distribution, which, in practice, can often
neither be inferred from data nor guessed by intuition.
The basic idea underlying credibility is to force the required simplicity of
the estimator by restricting the class of allowable estimator functions to those
which are linear in the observations X = (X1, X2, . . . , Xn)
0. In other words,
we look for the best estimator in the class of all linear estimator functions.
“Best” is to be understood in the Bayesian sense and the optimality crite-
rion is again quadratic loss. Credibility estimators are therefore linear Bayes
estimators.
In the previous chapters X stands for the observations of the individual
risk and µ() for the individual premium. Also, until now, we have essentially
worked under the rather simple Assumption 1.1, which in the language of
Bayesian statistics (see Subsection 1.2.4) means that the components of X
are, conditional on  = &, independent and identically distributed.
In this chapter we will ﬁrst continue within this framework, but later (see
Subsection 3.2.1 and further) we shall pass to a more general interpretation
and we shall deﬁne the credibility estimator in a general set-up. We will also
see that the credibility estimators can be understood as orthogonal projections
in the Hilbert space of square integrable random variables, and we will prove
some general characteristics and properties.

56
3 Credibility Estimators
3.1 Credibility Estimators in a Simple Context
3.1.1 The Credibility Premium in a Simple Credibility Model
We consider the following simple credibility model:
Model Assumptions 3.1 (simple credibility model)
i) The random variables Xj (j = 1, . . . , n) are, conditional on  = &, inde-
pendent with the same distribution function F& with the conditional mo-
ments
µ(&) = E [Xj|  = &] ,
2(&) = Var [Xj|  = &] .
ii)  is a random variable with distribution U(&).
In this model we have
P ind = µ () = E [Xn+1| ] ,
P coll = µ0 =
Z

µ (&) dU(&).
Our aim is again to ﬁnd an estimator for the individual premium µ (),
but now we concentrate on estimators, which are linear in the observations.
We will denote the best estimator within this class by P cred or [
[
µ(), which
we are going to derive now.
By deﬁnition, [
[
µ() has to be of the form
[
[
µ() = ba0 +
n
X
j=1
bajXj,
where the real coe!cients ba0,ba1, . . . ,ban need to solve
E
5
97
3
Cµ()  ba0 
n
X
j=1
bajXj
4
D
26
:8 =
min
a0,a1,...,an5R E
5
97
3
Cµ()  a0 
n
X
j=1
ajXj
4
D
26
:8 .
Since the probability distribution of X1, . . . , Xn is invariant under permuta-
tions of Xj and [
[
µ() is uniquely deﬁned it must hold that
ba1 = ba2 = · · · = ban,
i.e. the estimator [
[
µ() has the form

3.1 Credibility Estimators in a Simple Context
57
[
[
µ() = ba + bb X,
where
X = 1
n
n
X
j=1
Xj
and where ba and bb are the solution of the minimizing problem
E
·³
µ()  ba  bb X
´2¸
= min
a,b5R E
h¡
µ()  a  b X
¢2i
.
Taking partial derivatives with respect to a, resp. b, we get
E
£
µ()  a  bX
¤
= 0,
Cov
¡
X, µ()
¢
 b Var
¡
X
¢
= 0.
From the dependency structure imposed by Model Assumptions 3.1 we have
Cov
¡
X, µ()
¢
= Var (µ()) =:  2,
Var
¡
X
¢
= E
£
2()
¤
n
+ Var (µ()) =: 2
n +  2,
from which we get
b =
 2
 2 + 2/n =
n
n + 2/ 2 ,
a = (1  b) µ0.
We have thus proved the following theorem:
Theorem 3.2. The credibility estimator under Model Assumptions 3.1 is
given by
[
[
µ() =  X + (1  ) µ0,
(3.1)
where
µ0 = E[µ()],
(3.2)
 =
n
n + 2/ 2 .
(3.3)
Remarks:
•
In Theorem 3.2 we have found a formula for the credibility premium, the
structure of which we have already seen for the Bayes premium in various
speciﬁc cases, where the distribution of the Xj was assumed to belong to
an exponential family (see Chapter 2).
•
P cred is a weighted mean of P coll and the individual observed average X.

58
3 Credibility Estimators
•
The quotient  = 2/ 2 is called the credibility coe!cient, which can also
be written as  = (/µ0)2 (/µ0)2 . Note that /µ0 is the coe!cient
of variation of µ(), which is a good measure for the heterogeneity of
the portfolio, whereas /µ0 =
p
E [Var [Xj| ]]/E [Xj] is the expected
standard deviation within risk divided by the overall expected value, which
is a good measure for the within risk variability.
•
The credibility weight  increases as
-
the number of observed years n increases,
-
the heterogeneity of the portfolio (as measured by the coe!cient of
variation /µ0) increases,
-
the within risk variability (as measured by /µ0) decreases.
•
The formula for P cred involves the structural parameters 2,  2 and µ0. If
there exists a collective composed of similar risks, these parameters can be
estimated using the data from this collective (empirical Bayes procedure).
In the next chapter we will propose estimators for these parameters in
a more general model. The sizes of the structural parameters could also
be intuitively “decided” using the a priori knowledge of an experienced
actuary or underwriter (pure Bayesian procedure).
•
The class of estimators that are linear in the observations is a subclass
of the class of all estimators based on the observations. Hence the Bayes
estimator is equal to the credibility estimator, if the former is linear. We
refer to such cases as exact credibility.
3.1.2 A General Intuitive Principle
The credibility premium as a weighted mean of P coll and X can also be
interpreted as follows:
General Intuitive Principle 3.3
•
P coll = µ0 is the best estimator based on the a priori knowledge alone. It
has the quadratic loss
E
h
(µ0  µ())2i
= Var (µ()) =  2.
•
X is the best possible linear and individually unbiased (i.e. conditionally
unbiased given ) estimator, based only on the observation vector X. It
has the quadratic loss
E
h¡
X  µ()
¢2i
= E
£
2()/n
¤
= 2/n.
•
P cred is a weighted mean of these two, where the weights are proportional
to the inverse quadratic loss (precision) associated with each of the two
components, i.e.

3.1 Credibility Estimators in a Simple Context
59
[
[
µ() = X + (1  )µ0,
where  =
n/2
n/2 + 1/ 2 =
 2
 2 + 2/n =
n
n + 2/ 2 .
This is a very intuitive principle. For the estimation of the pure risk premium,
two sources of information are available, namely, a) the a priori knowledge and
b) the individual observations. First, one looks and sees what one can learn
from each of these two sources on its own. The a priori knowledge contains
information about the collective and the best estimator that we can derive
from this information is the a priori expectation µ0. On the other hand, the
observations contain information about the individual risk and the individual
risk proﬁle . It is reasonable here to consider linear estimators that are
individually, i.e. conditionally, unbiased and to choose from these the one with
the greatest precision, i.e. the smallest variance. Finally, we have to weight
the estimators derived from each of these information sources. It is intuitively
reasonable to weight them according to their precision, respectively the inverse
value of the quadratic loss.
This simple principle applies also in more general probability frameworks
and will be a big help in ﬁnding the credibility estimator in the more compli-
cated models.
3.1.3 The Quadratic Loss of the Credibility Premium
Theorem 3.4. The quadratic loss of the credibility estimator [
[
µ() found in
Theorem 3.2 is given by
E
"µ[
[
µ()  µ()
¶2#
= (1  )  2
(3.4)
=  2
n .
(3.5)
Remarks:
•
Note that  2 is equal to the quadratic loss of P coll (best estimator based
only on the a priori knowledge and neglecting the individual claims expe-
rience) and that 2/n is equal to the quadratic loss of X (best estimator
based only on the individual claims experience and neglecting the a priori
knowledge). We can see from Theorem 3.4 that the quadratic loss of the
credibility estimator is smaller than the quadratic loss of both P coll and
X.
•
We have already encountered these shrinkage formulae in Chapter 2,
Propositions 2.9, 2.13, 2.15.

60
3 Credibility Estimators
Proof of Theorem 3.4:
By straightforward calculations we ﬁnd
E
"µ
µ()  [
[
µ()
¶2#
= E
h¡

¡
µ()  X
¢
+ (1  ) (µ()  µ0)
¢2i
= 2 2
n + (1  )2 2
=
µ
n
n + 2/ 2
¶2 2
n +
µ
2/ 2
n + 2/ 2
¶2
 2
=
2
n + 2/ 2 =  2
n
=
2/ 2
n + 2/ 2  2 = (1  )  2.
¤
The following corollary gives an overview of the quadratic loss of the dif-
ferent estimators for µ():
Corollary 3.5. With Model Assumptions 3.1 we have:
Premium
Quadratic loss
a)
P coll = µ0,
Var (µ()) ,
b)
P cred = [
[
µ(),
(1  ) Var (µ()) ,
c)
P Bayes = ]
µ(),
E [Var (µ()| X)] .
For the quadratic loss we have that a)  b)  c). The improvement from a)
to b) is, as a rule, considerable. The closer that the Bayes premium is to a
function which is linear in the observations, the smaller is the improvement
from b) to c). The advantage of the credibility premium is its simplicity and
the fact that, contrary to P Bayes, we don’t have to specify the family of kernel
distributions and the prior distribution, a speciﬁcation which would imply an
additional model risk. The somewhat greater loss associated with b) over c)
has therefore to be looked at in relative terms and is often acceptable.
3.1.4 The Simple Bühlmann Model and the Homogeneous
Credibility Estimator
So far we have only considered one particular risk and we have derived the
credibility estimator based only on the observations of this particular risk. In

3.1 Credibility Estimators in a Simple Context
61
practice, however, one usually has observations of a whole portfolio of similar
risks numbered i = 1, 2, . . . , I.
We denote by Xi = (Xi1, Xi2, . . . , Xin)0 the observation vector of risk i and
by i its risk proﬁle. We now assume that for each risk in the portfolio, i
and Xi fulﬁl Model Assumptions 3.1 of the simple credibility model, i.e. i
and Xi are the outcomes of the two-urn model described in Subsection 1.2.4
applied independently to all risks i. We then arrive at the simple Bühlmann
model published in the seminal paper “Experience Rating and Credibility”
[Büh67].
Model Assumptions 3.6 (simple Bühlmann model)
B1: The random variables Xij (j = 1, . . . , n) are, conditional on i = &,
independent with the same distribution function F& and the conditional
moments
µ(&) = E [Xij| i = &] ,
2(&) = Var [Xij| i = &] .
B2: The pairs (1, X1) , . . . , (I, XI) are independent and identically distrib-
uted.
Remark:
•
By Assumption B2, a heterogeneous portfolio is modelled. The risk proﬁles
1, 2, . . . , I are independent random variables drawn from the same urn
with structural distribution U (&). Hence the risks in the portfolio have
dierent risk proﬁles (heterogeneity of the portfolio). On the other hand,
the risks in the portfolio have something in common: a priori they are
equal, i.e. a priori they cannot be recognized as being dierent.
We now want to ﬁnd the credibility estimator in the simple Bühlmann
model. The ﬁrst question is: the credibility estimator of what? Of course, we
want to estimate for each risk i its individual premium µ (i). Hence there is
not just one credibility estimator, but rather we want to ﬁnd the credibility
estimators \
\
µ (i) of µ (i) for i = 1, 2, . . . , I. By deﬁnition, these credibility
estimators \
\
µ (i) have to be linear functions of the observations. But here
the second question arises: linear in what? Should the credibility estimator
of µ (i) just be a linear function of the observations of risk i, or should we
allow for linear functions of all observations in the portfolio? Hence there are
always two items to be speciﬁed with credibility estimators: the quantity that
we want to estimate and the statistics that the credibility estimator should
be based on.
Generally, the credibility estimator is deﬁned as the best estimator which
is a linear function of all observations in the portfolio, i.e. the credibility
estimator \
\
µ (i) of µ (i) is by deﬁnition the best estimator in the class

62
3 Credibility Estimators
;
?
=
\
µ (i) : \
µ (i) = a +
I
X
k=1
n
X
j=1
bkjXkj;
a, bkj 5 R
<
@
> .
We now want to derive the formula for \
\
µ (i). By the same invariance and
permutation argument as in the derivation of Theorem 3.2 we ﬁnd that \
\
µ(i)
must be of the form
\
\
µ(i) = ba(i)
0 +
I
X
k=1
bb(i)
k Xk
where Xk = 1
n
n
X
j=1
Xkj.
To ﬁnd the coe!cients ba(i)
0
and bb(i)
k
we have to minimize
E
5
7
Ã
µ(i)  a(i)
0 
I
X
k=1
b(i)
k Xk
!26
8 .
Taking partial derivatives with respect to b(i)
k and a(i)
0
we ﬁnd
Cov
¡
µ (i) , Xk
¢
= b(i)
k Var
£
Xk
¤
.
Since the left-hand side is equal to zero for i 6= k, it follows that bb(i)
k
= 0 for
k 6= i. Hence in this model the credibility estimator of µ (i) depends only on
Xi, the observed mean of risk i, and not on the observations of the other risks
in the collective. Therefore it coincides with the credibility estimator found in
Theorem 3.2, i.e.
\
\
µ(i) =  Xi + (1  ) µ0,
(3.6)
where  is given by (3.3). But note the dierence to Theorem 3.2: we have now
proved that \
\
µ(i) given by formula (3.6) is not only the credibility estimator
based on Xi, but also the credibility estimator based on all observations of
the portfolio, i.e. based on the observation vector X = (X0
1, X0
2, . . . , X0
I)0.
Given a whole portfolio of risks, we can also consider another type of credi-
bility estimator, which is referred to in the literature as the homogeneous cred-
ibility estimator. We deﬁne the homogeneous credibility estimator of µ (i) as
the best estimator in the class of collectively unbiased estimators
;
?
=
\
µ (i) : \
µ (i) =
I
X
k=1
n
X
j=1
bkjXkj,
E
h
\
µ (i)
i
= E [µ (i)] , bkj 5 R
<
@
> .

3.1 Credibility Estimators in a Simple Context
63
We denote this estimator by \
\
µ(i)
hom
. Contrary to \
\
µ(i), the homogeneous
estimator \
\
µ(i)
hom
does not contain a constant term, but it is required that
\
\
µ(i)
hom
be unbiased over the collective, a condition which is automatically
fulﬁlled for the inhomogeneous credibility estimator.
To ﬁnd \
\
µ(i)
hom
we have to solve the minimization problem
E
5
97
3
Cµ (i) 
I
X
k=1
n
X
j=1
bkjXkj
4
D
26
:8 = min!
(3.7)
under the side constraint
I
X
k=1
n
X
l=1
bkl = 1.
(3.8)
The side constraint follows from the unbiasedness requirement
E
"
\
\
µ(i)
hom#
= E [µ (i)]
and the fact that
E [µ (i)] = E [Xkj] = µ0
for all i, j, k.
Instead of formally solving (3.7) , we take a closer look at \
\
µ(i) given by
(3.6). In order to transfer this (inhomogeneous) credibility estimator to a
homogeneous one, we have to replace the constant term (1  ) µ0 in (3.6) by
a suitable linear function of all observations. It is very natural to replace the
overall expected value µ0 by the observed collective mean
X = 1
I n
I
X
i=1
n
X
j=1
Xij
in the portfolio. One can easily check that the resulting estimator is indeed
the solution of the minimizing problem (3.7) and hence the homogeneous
credibility estimator. Another formal proof for this statement can also be
found in the next chapter: take all weights equal to one in Theorem 4.4. The
following theorem summarizes the results found in this subsection:
Theorem 3.7. The (inhomogeneous) credibility estimator \
\
µ(i) and the ho-
mogeneous credibility estimator \
\
µ(i)
hom
in the simple Bühlmann model
(Model Assumptions 3.1) are given by

64
3 Credibility Estimators
\
\
µ(i) =  Xi + (1  ) µ0,
(3.9)
\
\
µ(i)
hom
=  Xi + (1  ) X,
(3.10)
where
 =
n
n + 2
2
,
Xi = 1
n
n
X
j=1
Xij,
X =
1
I n
I
X
i=1
n
X
j=1
Xij.
Remark:
•
Note that the homogeneous credibility estimator (3.10) contains a built-in
estimator for the overall mean µ0.
3.2 Credibility Estimators in a General Set-Up
We have already seen in the simple Bühlmann model (Subsection 3.1.4) that
there are always two items to be speciﬁed with credibility estimators:
i)
The credibility estimator of what? What quantity do we want to estimate?
ii) What statistics should the credibility estimator be based on? Credibility
estimators are linear estimators, but linear in what?
Usually the quantity to be estimated will be the individual premium in
some future period of a particular risk, which we denote by µ (). For instance,
if we consider the particular risk i in the simple Bühlmann model, then this
quantity is µ () = µ (i) = E [Xi,n+1 |i ].
The data available to the insurer are usually some claims data of a port-
folio of similar risks. Therefore, the underlying statistics for the credibility
estimator will usually be the vector X containing the observations from a
whole portfolio of risks (cf. simple Bühlmann model, Subsection 3.1.4).
In the simple Bühlmann model, the quantity to be estimated and the obser-
vation vector X were well deﬁned, and their probability structure was speciﬁed
by Model Assumptions 3.6.
In the general set-up, the task remains the same, namely to ﬁnd the credi-
bility estimator of µ () based on some observation vector X. However, we do
not deﬁne µ () and X exactly, nor do we specify their probability structure.
Hence the only mathematical structure in the general set-up is that we want
to estimate some unknown real-valued random variable µ () based on some
known random vector X = (X1, . . . , Xn)0.

3.2 Credibility Estimators in a General Set-Up
65
Remarks:
•
Other interpretations of µ () (quantity to be estimated) than the one
given above will occur occasionally (see e.g. Section 4.14).
•
We will also encounter examples where the elements of the vector X are not
the original claim observations but rather transformations of the original
data or where the elements of X are maximum-likelihood estimators.
•
To make precise exactly what the quantity to be estimated and the vector
X are, as well as to specify their probability structure, will be the content
of the speciﬁc credibility models treated in subsequent chapters.
•
The mathematical structure of the general set-up also allows us to replace
µ () by any other square integrable random variable Y (most general
set-up). Indeed, all results in this and the following two subsections are
still valid if we replace µ () by Y .
Credibility estimators are always the best estimators in an a priori given
class. Given the vector X we deﬁne below two such classes L (X, 1) and Le (X)
and their corresponding credibility estimators.
Deﬁnition 3.8. The credibility estimator of µ() based on X is the best pos-
sible estimator in the class
L (X, 1) :=
n
[
µ() : [
µ() = a0 +
X
j ajXj,
a0, a1, · · · 5 R
o
.
In the following we will use P cred or [
[
µ() to denote this estimator. We there-
fore have
P cred = [
[
µ() =
arg min
[
µ()5L(X,1)
E
h
([
µ()  µ())2i
.
(3.11)
In order to make a clear distinction from the homogeneous credibility estima-
tor (deﬁned below), this estimator is often referred to in the literature as the
inhomogeneous credibility estimator.
Deﬁnition 3.9. The homogeneous credibility estimator of µ() based on X
is the best possible estimator in the class of collectively unbiased estimators
Le (X) :=
n
[
µ() : [
µ() =
X
ajXj, a1, a2, · · · 5 R, E
h
([
µ()
i
= E[µ()]
o
.
In the following we will use P credhom or [
[
µ()
hom
to denote this estimator.
Note that, in contrast to the inhomogeneous estimator, it has no constant
term a0, and that the deﬁnition requires that it be unbiased over the collective.
However, it is not required that the estimator be unbiased for any individual
value of &. Formally we write

66
3 Credibility Estimators
P credhom = [
[
µ()
hom
=
arg min
[
µ()5Le(X)
E
h
([
µ()  µ())2i
.
(3.12)
Whereas Deﬁnition 3.8 poses no problems, one has to be careful with Def-
inition 3.9 for the following reasons:
•
The class Le (X) in Deﬁnition 3.9 is the class of all collectively unbiased
estimators for µ(). More explicitly this means that the unbiasedness con-
dition should be read as follows:
EP
h
[
µ()
i
= EP [µ()]
for all model consistent probability measures
dP (&, x) = dF& (x) dU (&) .
It follows that the estimator [
[
µ()
hom
may not depend on P. In particular,
if
[
[
µ()
hom
=
X
bajXj,
then the coe!cients baj are not allowed to depend on
µ0 = EP [µ ()] .
•
It may of course happen that no collectively unbiased estimator exists.
Then Le (X) is empty, and no homogeneous credibility estimator as deﬁned
in Deﬁnition 3.9 exists.
•
In later chapters we will also consider situations where µ() is a linear
function of other variables, i.e.
µ() =
p
X
l=1
yl l () .
Then (see Exercise 3.1)
[
[
µ()
hom
=
p
X
l=1
yl \
\
l ()
hom
,
i.e. we can ﬁnd the homogeneous estimator of µ() from the homogeneous
estimators of l () l = 1, 2, . . . , p.
•
The homogeneous credibility estimator only makes sense if the observation
vector X incorporates collateral data, i.e. data of a portfolio of similar risks
(and not only data of one particular risk).
•
Forcing the constant term to be zero, together with the collectively unbi-
asedness condition, automatically implies a built-in estimator of µ0, which
is the main reason for considering the homogeneous credibility estimator.

3.2 Credibility Estimators in a General Set-Up
67
•
The above Deﬁnition 3.9 of the homogeneous credibility estimator is dier-
ent to the one usually found in the literature (see e.g. [DKG96], [DV76b],
[DV81a], [Hac75], [GH87]). Often it is only required that
E
h
([
µ()
i
= E[µ()],
but not that this equation should be fulﬁlled whatever the value of E[µ()]
or whatever the probability measure dP (&, x) might be. But then the coef-
ﬁcients baj of the homogeneous estimator deﬁned in such a way may depend
on the overall mean µ0. However, a homogeneous estimator depending on
µ0 is not of much use. If µ0 is known, we would better use the inho-
mogeneous estimator. For a more thorough discussion on homogeneous
credibility estimators we refer to Sundt [Sun98].
3.2.1 Credibility Estimators as Orthogonal Projections in the
L2 Hilbert Space
The estimators [
[
µ() and [
[
µ()
hom
, deﬁned in (3.11) and (3.12) as a solution
to the least squares problem, are most elegantly understood as projections
in the Hilbert space of all square integrable functions L2. One of the ﬁrst
to have this idea in the context of credibility was F. De Vylder [DV76a]. A
good introduction into Hilbert spaces can be found in Kolmogorov and Fomin
[KF70].
However, in the following we will not assume a special knowledge of the
theory of Hilbert spaces, so that the derivations and proofs can also be under-
stood by the reader who does not have an extensive mathematical background.
Of course, the least squares problems could always be solved by purely com-
putational techniques. As we shall see, this involves typically the inversion of
a large matrix. As soon as one goes beyond very simple model structures this
matrix inversion is not only cumbersome, but entails the loss of intuitive in-
sight for the resulting credibility formulae. The advantage of applying Hilbert
space theory to credibility is that we can then immediately apply our intu-
itive understanding of the properties of linear vector spaces to the credibility
problem. In this way, certain features of credibility theory come much closer
to our intuition.
A concise summary of those properties of Hilbert space and in particular
of L2, which are necessary for the understanding of credibility theory, is given
in Appendix B. We quickly review here those points that we will need in this
section.
We deﬁne
L2 :=
½
X : X = random variable with E[X2] =
Z
X2dP < 4
¾
.
Two random variables X and X0 with E
h
(X  X0)2i
= 0 will be considered to
be identical: in other words, we do not dierentiate between random variables

68
3 Credibility Estimators
diering from each other only on a set of measure 0. If X and Y belong to L2
then the inner product associated with the Hilbert space is given by
< X, Y >:= E[XY ]
and the corresponding norm is
kXk :=< X, X >1/2= E[X2]1/2.
We consider the random variables
µ() 5 L2
the individual premium to be estimated,
X
0
= (X1, X2, . . . , Xn) the observation vector with elements
Xj 5 L2,
as elements of the Hilbert space L2 with the corresponding moments
µ0 : = E [µ()] ,
µ
0
X : = (µX1, . . . , µXn) = (E [X1] , . . . , E [Xn])
and the covariance matrix of X
	X := Cov (X, X0)
=
3
E
E
E
E
E
E
E
E
C
Var [X1]
Cov (X1, X2) . . .
Cov (X1, Xn)
Cov (X2, X1)
Var [X2]
Cov (X2, Xn)
...
...
...
...
...
Cov (Xn, X1)
. . .
. . .
Var [Xn]
4
F
F
F
F
F
F
F
F
D
.
Deﬁnition 3.10.
i) Two elements X and Y 5 L2 are orthogonal (X B Y ), if the inner
product <X, Y > equals 0.
ii) For a closed subspace (or a closed a!ne subspace) M  L2 we deﬁne
the orthogonal projection of Y 5 L2 on M as follows: Y  5 M is the
orthogonal projection of Y on M (Y  = Pro (Y | M)) if Y Y  B M,
i.e. Y  Y  B Z1  Z2 for all Z1, Z2 5 M.
One can prove that the random variable Y  always exists and is unique.
Theorem 3.11. The following statements are equivalent:
i) Y  = Pro(Y | M).
(3.13)
ii) Y  5 M and <Y  Y , Z  Y > = 0
for all Z 5 M.
(3.14)
iii) Y  5 M and kY  Y k  kY  Zk
for all Z 5 M.
(3.15)

3.2 Credibility Estimators in a General Set-Up
69
Remarks:
•
We call (3.14) the orthogonality condition.
•
If M is a subspace, then the condition (3.14) can also be written as
<Y  Y , Z> = 0 for all Z 5 M.
(3.16)
•
Remember the deﬁnition of the following spaces (Deﬁnitions 3.8 and 3.9):
L(X, 1) :=
n
[
µ() : [
µ() = a0 + P ajXj,
a0, a1, · · · 5 R
o
,
Le(X) :=
n
[
µ() : [
µ() = P ajXj, a1, a2, · · · 5 R, E
h
\
µ ()
i
= E[µ()]
o
.
We further introduce
G(X) := {Z : Z = g(X), g = real-valued function and g(X)
square integrable}.
L(X, 1) and G(X) are closed subspaces, Le(X) is a closed a!ne subspace
of L2.
Using this notation and these results, we can now reformulate the deﬁnition of
the credibility estimator as well as that of the Bayes premium. The following
alternative deﬁnitions of the credibility estimators and the Bayes premium
are direct consequences of Theorem 3.2.1 and Deﬁnitions 3.8 and 3.9.
Deﬁnition 3.12 (credibility estimators as orthogonal projections).
i) The (inhomogeneous) credibility estimator of µ () based on X is deﬁned
as
[
[
µ() = Pro(µ()| L(X, 1)).
(3.17)
ii) The homogeneous credibility estimator of µ () based on X is deﬁned as
[
[
µ()
hom
= Pro(µ()| Le(X)).
(3.18)
iii) The Bayes premium (of µ () based on X) is deﬁned as
]
µ() = Pro(µ()| G(X)).
(3.19)
We thus interpret both the credibility estimator and the Bayes premium as
orthogonal projections of the (unknown) individual premium µ () on appro-
priately deﬁned subspaces (respectively a!ne subspaces) of L2.
A property of the projection operator which is generally valid, and one
which is easy to understand in the case of linear vector spaces, is given here
without proof. This result will be used frequently in the rest of this section
and in later chapters.

70
3 Credibility Estimators
Theorem 3.13 (iterativity of projections). Let M and M 0 be closed sub-
spaces (or closed a!ne subspaces) of L2 with M  M0, then we have
Pro (Y |M ) = Pro (Pro (Y |M 0 ) |M )
(3.20)
and
kY  Pro (Y |M )k2 = kY  Pro (Y | M0)k2
(3.21)
+ kPro (Y |M0 )  Pro (Y |M )k2 .
Note, that geometrically (3.21) corresponds to the Theorem of Pythagoras.
To ﬁnish this section we state a result about the relationship between the
credibility estimators and the Bayes premium.
Theorem 3.14. It holds that:
i) The credibility premium [
[
µ() is the best linear approximation to the Bayes
premium ]
µ().
ii)
E
·
([
[
µ()  µ())2
¸
|
{z
}
00total error00
= E
·
([
[
µ()  ]
µ())2
¸
|
{z
}
00approximation error00
+ E
h
(]
µ()  µ())2i
|
{z
}
00Bayes risk00
.
iii) The homogeneous credibility premium [
[
µ()
hom
is the best homogeneous
linear approximation to the credibility premium [
[
µ() as well as to the
Bayes premium ]
µ().
Proof: G(X) and L(X,1) are subspaces of L2 and L(X,1)  G(X). From
Deﬁnition 3.12 and Theorem 3.13 it follows directly that
[
[
µ() = Pro(µ()| L(X, 1))
= Pro(Pro (µ()| G(X))
|
{z
}
= ]
µ()
|L(X, 1)),
so that i) is proved. From Theorem 3.13 it then also follows that
°°°°
[
[
µ()  µ()
°°°°
2
=
°°°µ()  ]
µ()
°°°
2
+
°°°°]
µ()  [
[
µ()
°°°°
2
.
iii) follows analogously to i) and from the fact that Le(X) is a subspace of
L(X, 1). This proves Theorem 3.14.
¤

3.3 Orthogonality Conditions and Normal Equations
71
3.3 Orthogonality Conditions and Normal Equations
Theorem 3.15 (orthogonality conditions for the credibility estima-
tor). [
[
µ() is the (inhomogeneous) credibility estimator for µ() based on X,
if and only if the following orthogonality conditions are satisﬁed:
i) < µ()  [
[
µ(), 1> = 0,
(3.22)
ii) < µ()  [
[
µ(), Xj> = 0
for j = 1, 2, . . . , n.
(3.23)
Theorem 3.16 (orthogonality conditions for the homogeneous credi-
bility estimator). [
[
µ()
hom
is the homogeneous credibility estimator of µ()
based on X, if and only if the following orthogonality conditions are satisﬁed:
i) <µ()  [
[
µ()
hom
, 1> = 0,
(3.24)
ii)<µ()  [
[
µ()
hom
, [
µ()  [
[
µ()
hom
> = 0
for all [
µ() 5 Le(X).
(3.25)
Remark:
•
The credibility estimator and the homogeneous credibility estimator are
both unbiased in the collective (this follows from (3.22) and (3.24)). For
the homogeneous credibility estimator, however, the collective unbiased-
ness, i.e. the condition (3.24), is forced by the deﬁnition, while this follows
automatically for the (inhomogeneous) credibility estimator.
Proof of Theorem 3.15:
Since [
[
µ() = Pro(µ()| L(X, 1)) we can apply Theorem 3.2, formula (3.14).
Observe that it is su!cient to check the validity of (3.14) for 1, X1, . . . , Xn
which form a basis of L(X, 1).
¤
Proof of Theorem 3.16:
Analogously as for Theorem 3.15.
¤
The above orthogonality conditions can also be written in a somewhat
dierent form, which are called the normal equations in the literature and
which play a central role in abstract least squares theory.
Corollary 3.17 (normal equations). [
[
µ() is the (inhomogeneous) credibil-
ity estimator of µ() based on X, if and only if the following normal equations
are satisﬁed:

72
3 Credibility Estimators
i) E
·\
\
µ ()  µ()
¸
= 0,
(3.26)
ii) Cov [µ(), Xj] = Cov
·\
\
µ (), Xj
¸
for j = 1, 2, . . . , n.
(3.27)
Remarks:
•
Let ba0 and ba = (ba1, . . . ,ban)0 be the coe!cients of the credibility estimator
[
[
µ(), that is
[
[
µ() = ba0 +
n
X
j=1
bajXj.
Then the normal equations (3.26) and (3.27) can be written as
i)
ba0 = µ0 
n
X
j=1
baj µXj,
(3.28)
ii)
n
X
j=1
bajCov (Xj, Xk) = Cov(µ(), Xk),
k = 1, . . . , n.
(3.29)
(3.28) and (3.29) explain why we use the term “normal equations” for
Corollary 3.17.
•
As [
[
µ() is by deﬁnition a linear combination of X1, . . . , Xn, it follows
from (3.27), that
Var
·[
[
µ()
¸
= Cov
µ
µ(), [
[
µ()
¶
.
•
The normal equations imply that the credibility estimator depends only on
the ﬁrst two moments of the joint distribution of µ() and X. We do not
need to know the full distributions {F& : & 5 } or the a priori distribution
U(&). This is an enormous advantage in practice. For credibility one only
needs to know the ﬁrst- and second-order moments (or estimates of them).
•
The normal equations hold very generally. We have not assumed any spe-
cial structure, not even a Bayes structure with an a priori distribution and
conditional distributions. The result is also true when instead of µ(),
some other random variable from L2 is to be predicted, and also, when
the Xj’s are any random variables from L2.
•
From the normal equations follows that the “residual” [
[
µ()  µ() is
uncorrelated with the components of the observation vector X.
Proof of Corollary 3.17: From Theorem 3.15 it follows that
<\
\
µ ()  µ(), 1> = 0 +, E
·\
\
µ ()  µ()
¸
= 0.

3.3 Orthogonality Conditions and Normal Equations
73
For the proof of (3.27) we have
<\
\
µ ()  µ(), Xj> = 0
+,
<\
\
µ ()  µ(), Xj  µXj> = 0
+,
<(\
\
µ ()  µ0)  (µ()  µ0), Xj  µXj> = 0
+,
Cov(\
\
µ (), Xj) = Cov(µ(), Xj).
This ends the proof of Corollary 3.17.
¤
Corollary 3.18. If the covariance matrix 	X is non-singular, then it follows
that
[
[
µ() = µ0 + c
0 	1
X (X  µX),
where c
0 = (Cov (µ(), X1) , . . . , Cov(µ(), Xn)) .
Proof: Let [
[
µ() = ba0 + ba0 X be the credibility estimator. Then condition ii)
of the normal equations written in matrix notation is
ba
0	X = c
0.
For 	X non-singular we get ba
0 = c
0	1
X . This expression substituted in con-
dition i) of the normal equations gives ba0 = µ0  c
0	1
X µX. This proves
Corollary 3.18.
¤
Corollary 3.19 (normal equations for the homogeneous credibility
estimator).
[
[
µ()
hom
is the homogeneous credibility estimator of µ() based on X, if and
only if the following equations are satisﬁed:
i) E
"
\
\
µ ()
hom
 µ()
#
= 0,
ii) Cov
Ã
\
\
µ ()
hom
 µ(), \
\
µ ()
hom!
= Cov
Ã
\
\
µ ()
hom
 µ(), [
µ()
!
for all \
µ () 5 Le (X) .
We state this corollary without proof, which is similar to the reasoning for
Corollary 3.17.

74
3 Credibility Estimators
Summary Discussion:
This section has provided us with a wide range of tools for ﬁnding the cred-
ibility formulae. Corollary 3.17 gives the computational approach. As stated
earlier, usually we shall not follow this route. Instead, our derivation of cred-
ibility formulae follows the more intuitive way:
i)
Try to identify a credibility formula by intuitive reasoning, which will often
be based on the General Intuitive Principle 3.3.
ii) Check the correctness of such formulae by verifying that they fulﬁl the or-
thogonality conditions or the normal equations (Theorem 3.15 or Corollary
3.17).
In the following chapters we shall discuss speciﬁc model assumptions and
the corresponding credibility formulae.
3.4 Exercises
Exercise 3.1 (linearity property)
Let
µ() =
p
X
k=1
akµk()
(3.30)
and let \
\
µk()
Ã
resp. \
\
µk()
hom!
be the credibility estimators (resp. the ho-
mogeneous credibility estimators) of µk() based on X = (X1, X2, ..., Xn)0.
Show that the following linearity properties are satisﬁed:
a) linearity property for the credibility estimator:
[
[
µ() =
p
X
k=1
ak \
\
µk().
(3.31)
b) linearity property for the homogeneous credibility estimator:
[
[
µ()
hom
=
p
X
k=1
ak \
\
µk()
hom
.
Remark:
We will encounter situations with (3.30) in the multidimensional and in the
regression case (Chapters 7 and 8), where the quantities to be estimated are
linear functions of other quantities.

3.4 Exercises
75
Exercise 3.2 (independence property)
Let µ() be the quantity to be estimated and X = (X0
1, X0
2)0 , where X2 is in-
dependent of X1 and µ(). Show that the credibility estimator \
\
µ () depends
on X only through X1.
Exercise 3.3
Consider the simple credibility model (Model Assumptions 3.1) and denote by
bb
Xn+1 the best linear predictor of Xn+1 with respect to quadratic loss. Show
that
a)
bb
Xn+1 = \
\
µ (),
b)
E
"µ
bb
Xn+1  Xn+1
¶2#
= 2 ³
1 + 
n
´
.
Exercise 3.4
Consider the situation of Exercise 2.1. Calculate the credibility premium P cred
for all possible observations:
a) if there is only one year’s claim experience;
b) if there are two years’ claim experience.
c) Compare with the results with P Bayes obtained in Exercise 2.1 and com-
ment on the ﬁndings.
Exercise 3.5
In many lines of business, a small number of “large claims” are responsible
for more than half of the total claims load. In this context an actuary wants
to estimate for a particular risk the probability  that a (randomly drawn)
claim is a large claim.
From portfolio information he knows that about 2% of the claims are large
claims, but that this proportion varies quite a lot between the risks. Based on
this portfolio information he makes the following a priori assumptions:
E [] = 2%,
p
Var () = 1%.
For a particular risk, there were six large claims observed out of a total
number of 120 observed claims. Determine the credibility estimator bb of 
for that particular risk based on this information.

4
The Bühlmann—Straub Model
This model, which was developed by Bühlmann and Straub in 1970 (see
[BS70]) in connection with determining claims ratios in reinsurance, has over
time found a multitude of applications in insurance practice: in life and non-
life insurance, in primary insurance as well as in reinsurance. It is still by
far the most used and the most important credibility model for insurance
practice.
4.1 Motivation
We consider the situation where an actuary has to rate a risk in motor third-
party liability insurance. On the basis of certain risk characteristics, the risks
have been grouped into various risk classes (tari positions) and now a risk
premium must be calculated for each of these classes.
Statistical information from this branch is available. Typically, for the ith
risk class we have the following information:
Sij
aggregate claim amount in year j,
Vij
number of years at risk in year j
(contracts which were in force for the whole year
count as one, the others pro rata temporis),
Xij = Sij/Vij average claim costs per year at risk in year j (claims ratio),
Nij
number of claims in year j,
Fij = Nij/Vij claim frequency in year j,
Yij = Sij/Nij average claim size in year j.
The actuary’s task consists of calculating for the ith risk class the “true”
individual pure risk premium for a future period. This may be done directly
on the basis of the observations Xij, or indirectly, by analysis and calculation
of the two components “claim frequency” and “average claim size”. To ﬁx the
idea, we work in the following with the average claim costs Xij.

78
4 The Bühlmann—Straub Model
Assume as in the simple Bühlmann model (Model Assumptions 3.6) that
each risk class i is then characterized by its speciﬁc risk parameter i. Observe,
however, that the assumption Var [Xij |i ] = 2(i) is no longer reasonable.
The variance should depend on the volume measure Vij. Let us look at the
special case where each risk has been in force for a full year, so that the
volume measure, i.e. the number of years at risk, is a whole number. Notice
that in this case Xij =
1
Vij
PV ij
=1 S()
ij , where S()
ij
is the aggregate claim
amount of the th risk in the class i. Since the Xij is an average of Vij risks,
which can be considered as, conditionally, independent of each other, we have
Var [Xij |i ] = 2 (i) /Vij. It is reasonable to model the conditional variance
as inversely proportional to the known volume measure (here, the number of
years at risk) also in the case where Vij is the sum of parts of years at risk
(because some contracts have been in force only for part of the ith year). If
we are interested in the average claim size or in the claim frequency, we have
the same type of behaviour, except that in the ﬁrst case, the volume measure
is the observed number of claims nij.
We should also note that in the above example, the total pure risk pre-
mium for the risk class i is the product of the number of years at risk times
E [Xij|i]. In other words, the total risk premium grows linearly with the
volume measure.
That the premium grows linearly with the size of the insured unit, as
quantiﬁed by an appropriate volume measure, is a feature that is common
to many other lines of business. For example, the premium in ﬁre insurance
depends on the insured value of the building and on the insured value of its
contents. In collective accident insurance by which all the employees of a ﬁrm
are insured against accidents, the size of the ﬁrm must be taken into account,
in some fashion, in order to set the premium.
Indeed in many lines of business, the premiums are calculated as “volume
measure” times “premium rate” where the volume measure is appropriately
chosen for the particular line of business under consideration.
Practical examples of volume measures:
•
number of years at risk in motor insurance,
•
total amount of annual (or monthly) wages in the collective health or
collective accident insurance,
•
sum insured in ﬁre insurance,
•
annual turnover in commercial liability insurance,
•
annual premium written (or earned) by the ceding company in excess of
loss reinsurance.
For the calculation of the premium rate it is important to consider the claim
amounts in relation to the volume measure, that is, to consider the quantities
Xij = Sij/Vij. These are called claims ratios (or loss ratios) and can be
regarded as “standardized” aggregate claim amounts. For each risk i, we have
to determine the corresponding individual claims ratio µ (i) = E [Xij| i],

4.2 Model Assumptions
79
where here and otherwise in this book, the term risk is used to describe either
an individual risk in the physical sense or a risk class.
4.2 Model Assumptions
We are given a portfolio of I risks or “risk categories”, and we use the notation
Xij claims ratio (other possible interpretations are claim frequency or
average claim size) of the risk i in year j,
wij associated known weight.
The weights wij are in general interpreted as volume measures as described
in Section 4.1. However, other interpretations are possible. To indicate such
wider interpretations we use the symbol wij instead of Vij.
Model Assumptions 4.1 (Bühlmann—Straub model)
The risk i is characterized by an individual risk proﬁle &i, which is itself the
realization of a random variable i, and we have that:
BS1: Conditionally, given i, the {Xij : j = 1, 2, . . . , n} are independent with
E [Xij |i ] = µ (i) ,
(4.1)
Var [Xij |i ] = 2(i)
wij
.
(4.2)
BS2: The pairs (1, X1), (2, X2) , . . . are independent, and 1, 2, . . . are
independent and identically distributed.
Technical Remark:
•
The number of observation years n may also vary between risks. This
could be formally expressed by setting wij = 0 for non-observed years.
Note, however, that the estimator of the structural parameters needs to
be changed in this case (see Section 4.11).
Remarks on Model Assumptions 4.1:
•
The Bühlmann—Straub model is a two-urn model (see Figure 1.6 on page
12). From the ﬁrst urn we draw the risk proﬁle i, which determines the
“content” of the second urn. In the second step, a random variable Xij is
drawn from the second urn. In this way, a heterogeneous portfolio is mod-
elled. The risks in the portfolio have dierent risk proﬁles (heterogeneity in
the group). But the risks in the portfolio also have something in common:
a priori, they cannot be recognized as being dierent (short terminology:
they are a priori equal). This is modelled by the fact that the risk proﬁles
i are all drawn from the same urn.

80
4 The Bühlmann—Straub Model
•
The conditional independence condition in BS1 can be weakened. All re-
sults in this chapter also hold if the entries of the vector Xi are on the
average conditionally uncorrelated, i.e. if E [Cov (Xik, Xil |i )] = 0 for
k 6= l.
•
Comments on Assumption BS2:
a)
The risks are independent, i.e. random variables that belong to dierent
contracts are independent. This assumption, as a rule, is not a problem
in practice.
b)
The risks are a priori equal:
This assumption is not always valid in practice and in concrete appli-
cations we need to consider if this is reasonable. For example, in ﬁre
insurance, we know by common sense and without looking at data,
that for instance a carpenter’s workshop is a greater risk than an of-
ﬁce building. In Section 4.13 we will see what can be done in such
situations, and how known a priori dierences can be built into the
model.
•
Comments on Assumption BS1:
a)
The “true” individual claims ratio µ (i) is constant over time:
We have again an assumption about homogeneity over time, although
it is weaker than that made in the simple Bühlmann model, in that the
variance is allowed to change with varying values of the volume mea-
sure. In practice, it is often the case that the assumption of a constant
claims ratio over time is not valid, for example when the Xij’s under
consideration depend on inﬂation or when insurance conditions have
changed during the observation period. Sometimes, one can eliminate
this problem by an as-if transformation of the data.
b)
The conditional variance is inversely proportional to the known weight
wij. In many applications in insurance practice we can write the Xij
as Xij = Sij/Vij, where Sij is the aggregate claim amount and Vij is a
given volume measure (see Section 4.1). In general, these volume mea-
sures Vij are then used as weights wij. If, as in the example of Section
4.1, the Xij can be written as Xij =
1
Vij
PVij
=1 S()
ij , that is, as some
observed average of conditionally independent random variables, then
(4.2) is an appropriate assumption. In other situations, for example in
ﬁre insurance, where mostly the insured sum is taken as the volume
measure, it is not so obvious that Vij is also the appropriate weight
wij and one can consider choosing wij dierent from Vij, for instance
a linear function of Vij.
Further remark:
•
Assume that the aggregate claim amount Sij in cell ij is conditionally
compound Poisson distributed with parameter ij(i, wij) and claim size
Y whose distribution FY does not depend on i. Let Xij = Sij/wij. If
ij (wij,i) = wij (i) , then we have

4.3 The Credibility Premium in the Bühlmann—Straub Model
81
E [Xij| i] =  (i) E [Y | i]
and
Var [Xij| i] =
1
wij
 (i) E
£
Y 2¯¯ i
¤
.
Thus, with µ (i) =  (i) E [Y | i] and 2 (i) =  (i) E
£
Y 2¯¯ i
¤
,
conditions (4.1) and (4.2) are satisﬁed.
The following quantities are of interest:
risk i
collective/portfolio
µ (i) := E [Xij| i] ,
µ0 := E [µ (i)] ,
2 (i) := wijVar [Xij| i] .
2 := E
£
2 (i)
¤
,
 2 := Var [µ (i)] .
Interpretation:
Interpretation:
µ (i) :
individual risk premium,
2 (i) : variance within individual
risk (normalized for
weight 1).
µ0: collective premium,
2: average variance within
individual risk (normalized
for weight 1; ﬁrst variance
component),
 2: variance between individual
risk premiums (second
variance component).
4.3 The Credibility Premium in the Bühlmann—Straub
Model
We want to estimate for each risk i its individual claims ratio µ (i) .
We have available to us the data D = {Xi : i = 1, 2, . . . , I}, where Xi =
(Xi1, Xi2, . . . , Xin)
0
is the observation vector of the ith risk. We seek the
credibility estimator based on the data D from all the risks in the portfolio.
It is easy to see that the credibility estimator for µ (i) depends only on
the observations from the ith risk. Let
\
\
µ (i) = ai0 +
X
j aijXij
(4.3)
be the credibility estimator based on Xi. Because of the independence of the
risks, it follows that for k 6= i and all l
Cov
µ \
\
µ (i), Xkl
¶
= Cov(µ (i) , Xkl) = 0,
(4.4)

82
4 The Bühlmann—Straub Model
i.e. the normal equations (Corollary 3.17) are satisﬁed and \
\
µ (i) is therefore
the credibility estimator based on all data.
That the credibility premium of the risk i depends only on the individual
claim experience, and not on the claim experience of the other risks, is intu-
itively obvious. If we know the a priori expected value µ0 (collective premium),
then the other risks cannot supply any extra information, because they are
independent of the risk being rated. In practice, however, µ0 is usually un-
known. The other risks then contain information for the estimation of this a
priori expected value. We will learn more of this later when we discuss the
homogeneous credibility estimator.
Here and in the following we will use the notation that a point in the
subscript denotes summation over the corresponding subscript, so that for
example wi• = P
j wij. According to (4.1) and (4.2) the observations Xij
are individually (i.e. conditionally, given i) unbiased, with a conditional
variance that is inversely proportional to the weights wij. It is easy to check
that the best linear estimator, which is individually unbiased and which has
the smallest conditional variance, is given by the weighted average
Xi =
X
j
wij
wi•
Xij.
For Xi we have
E [Xi| i] = µ (i) ,
Var [Xi| i] =
X
j
µwij
wi•
¶2
Var [Xij| i] = 2 (i)
wi•
.
As a further useful property we record that Xi is also the homogeneous
credibility estimator based on the observation vector Xi, because
Xi = Pro (µ (i) |Le (Xi)) .
(4.5)
We now derive the credibility estimator based on Xi and then show that
this is also the credibility estimator based on all data. This then also implies
that the compressed data {Xi : i = 1, 2, . . . , I} is a linear su!cient statistic,
i.e. the credibility estimator depends only on the observations via Xi. Because
of the normal equations (Corollary 3.17) and the fact that E [Xi] = µ0, the
credibility estimator must be of the form (4.6) and satisfy (4.7),
\
\
µ(i) = i Xi + (1  i) µ0,
(4.6)
Cov
µ\
\
µ(i), Xi
¶
= i Cov(Xi, Xi) = Cov(µ (i) , Xi).
(4.7)
From the fact that

4.3 The Credibility Premium in the Bühlmann—Straub Model
83
Var [Xi] = E [Var [Xi| i]] + Var [E [Xi| i]]
= 2
wi•
+  2,
Cov(µ (i) , Xi) = E [Cov(µ (i) , Xi| i)] + Cov (µ (i) , E [Xi| i])
= 0 + Var [µ (i)]
=  2,
it follows that
i =
 2
2
wi• +  2 =
wi•
wi• + 2
 2
.
(4.8)
Now we want to show that \
\
µ(i) is also the credibility estimator for the
risk i based on all data, which, based on the properties given above for Xi,
we would expect. We have already shown on page 81 that the credibility
estimator of risk i depends only on the data of risk i (this follows also from
the independence property shown in Exercise 3.2 on page 75). Hence it remains
to show that
Cov
µ\
\
µ(i), Xij
¶
= Cov(µ (i) , Xij) =  2
for j = 1, 2, . . . , n.
(4.9)
It holds that
Cov
µ\
\
µ(i) , Xij
¶
= i
µX
k
wik
wi•
Cov(Xik, Xij)
¶
= i
µX
k
wik
wi•
( 2
wik
kj +  2)
¶
= i
µX
k
wik
wi•
 2 + 2
wi•
¶
=  2,
where kj =
½1 for k = j
0 otherwise.
In the last step we have used the explicit form of i given by (4.8).
Hence (4.9) holds true, and we have thus proved the following result:
Theorem 4.2 (credibility estimator). The (inhomogeneous) credibility es-
timator in the Bühlmann—Straub model (Model Assumptions 4.1) is given by
\
\
µ(i) = iXi + (1  i) µ0 = µ0 + i (Xi  µ0) ,
(4.10)

84
4 The Bühlmann—Straub Model
where
Xi =
X
j
wij
wi•
Xij,
wi• =
X
j wij,
i =
wi•
wi• + 2
 2
=
wi•
wi• + .
Remarks:
•
 = 2/ 2 is called the credibility coe!cient.
•
Note that the credibility estimator has the same form as the Bayes estima-
tor in Theorem 2.20. This means that the credibility estimator coincides
with the Bayes estimator for exponential families with priors within the
associated conjugate family.
4.4 Discussion and Interpretation of the Credibility
Estimator
We can give a very nice and intuitive interpretation for the form of the cred-
ibility estimator given in Theorem 4.2.
•
µ0 is the best estimator based only on the a priori knowledge and has the
quadratic loss
E
h
(µ0  µ(i))2i
= Var (µ(i)) =  2.
•
Xi is the best linear and individually unbiased estimator based only on
the observation vector Xi and has the quadratic loss
E
h
(Xi  µ(i))2i
= E
(
E
"µX
j
wij
wi•
(Xij  µ(i))
¶2¯¯¯¯¯ i
#)
= E
£
2(i)/wi•
¤
= 2/wi• .
•
The credibility estimator is a weighted mean of the two estimators where
the weight assigned to each summand is proportional to its inverse quadratic
loss (precision), i.e.
\
\
µ(i) = iXi + (1  i)µ0,
where
i =
¡
2/wi•
¢1
( 2)1 + (2/wi•)1 .
The General Intuitive Principle 3.3, which we already stated for the simple
Bühlmann Model (Model Assumptions 3.6), is therefore also valid here.

4.4 Discussion and Interpretation of the Credibility Estimator
85
Remarks:
•
The credibility coe!cient can also be written as
 = (/µ0)2
(/µ0)2 .
Note that:
-
/µ0 is the coe!cient of variation (standard deviation divided by the
expected value) of µ (i), which is a good measure for the heterogeneity
of the portfolio, or in other words, a good measure for the between risk
variability.
-
 is the average standard deviation within risk normalized for weight 1,
and µ0 is the expected value averaged over the whole portfolio. Hence
/µ0 can be interpreted as some kind of an average within risk coe!-
cient of variation and is a good measure of the within risk variability.
•
From the formula for the credibility weight i we see that (Figure 4.1):
-
the greater the weight wi•, summed over the years, the greater is i
(notice also that wi• assumes the role of the number of observation
years n in the simple Bühlmann model),
-
the smaller the credibility coe!cient  = 2/ 2, the greater is i.
Di
w i •
N
Di
Fig. 4.1. Credibility weights as a function of the parameters
•
E
·\
\
µ(i)
¸
= µ0, i.e. on average, over the collective, we have correctly
rated the risk (unbiased in the collective).
•
For the credibility estimator, we need, besides the observed claims ratios
Xij and their corresponding weights wij, the so-called structural para-
meters µ0, 2 and  2. These can be determined based either on a priori
knowledge, for example from the opinions of experts (pure Bayesian pro-
cedure), or they can be determined from observations of a collective of
similar risks (empirical Bayes). Estimators for the structural parameters
when we are in the latter situation are given below.

86
4 The Bühlmann—Straub Model
•
In the Bühlmann—Straub model, if we were to replace the variance con-
dition (4.2) by the condition Var [Xij| i] = 2
i /wij, thus modelling the
conditional variances normalized for weight 1 as constants 2
i , this would
result in the term 2
i appearing in the credibility weight instead of 2.
In this way, the risk-speciﬁc variability of the claims ratios Xij would be
taken into account, whereas in the Bühlmann—Straub credibility estima-
tor only the “average” of this variability over the collective is used. The
risk-speciﬁc approach means that, for risks with more stable claims ra-
tios, more weight is given to the individual experience and vice versa. At
ﬁrst glance, this appears to be intuitively reasonable. This would, with-
out doubt, also be the case, if the structural parameters 2
i were known.
As a rule, however, they are not known, and in such a modiﬁed model,
instead of the single unknown structural parameter 2 we would have a
considerably larger number I of unknown structural parameters 2
i , all of
which would have to be estimated. The increase of the estimation error
resulting from the necessity of estimating so many structural parameters
will typically not be oset by the improved optimality of the credibility
estimator.
4.5 Quadratic Loss of the Credibility Estimator
Theorem 4.3. Given Model Assumptions 4.1 we have that the quadratic loss
of the credibility estimator (4.10) is given by
E
"µ \
\
µ (i)  µ (i)
¶2#
= (1  i) 2 = i
2
wi•
.
(4.11)
Proof: The proof is left to the reader as an exercise. It is analogous to the
proof in the Bühlmann model.
¤
Remarks:
•
Note that  2 is the quadratic loss of the collective premium µ0. By the use
of the credibility estimator instead, this quadratic loss is reduced by the
factor 1  i.
•
Note also that 2/wi• is the quadratic loss of Xi, which is the best lin-
ear estimator, when looking only at the data. When using the credibility
estimator instead, this quadratic loss is reduced by the factor i.
4.6 The Homogeneous Credibility Estimator in the
Bühlmann—Straub Model
Since the homogeneous credibility estimator has no constant term, the overall
expected value µ0 appearing in the inhomogeneous credibility estimator (4.10)

4.6 The Homogeneous Credibility Estimator in the Bühlmann—Straub Model
87
must be replaced by a collectively unbiased estimator bµ0, which is a linear
function of the observations. Intuitively, we might ﬁrst think of using the
weighted average of the observed claims ratios,
X :=
P
i,j wijXij
w••
,
where w•• = P
ij wij. But here, as we shall see, intuition fails.
From Theorem 3.14 iii) (iterativity of projections) we have
\
\
µ (i)
hom
= Pro
µ \
\
µ(i)
¯¯¯¯ Le(D)
¶
,
where D = {Xij, i = 1, 2, . . . , I, j = 1, 2, . . . , n} .
From the normed linearity property in a!ne subspaces (see Theorem B.11 of
Appendix B), we have
\
\
µ (i)
hom
= iPro(Xi| Le(D)) + (1  i) Pro (µ0| Le(D)).
The individual mean Xi is in Le(D), since E [Xi] = E{E [Xi| i]} =
E [µ (i)] = µ0. Hence
\
\
µ (i)
hom
= iXi + (1  i) c
c
µ0,
where
c
c
µ0 = Pro(µ0| Le(D)).
In Section 4.4 we have seen that Xi is the best linear, individually unbi-
ased estimator of µ (i) based on the individual observation vector Xi. One
would presume then, that Xi contains all the information in Xi relating to
µ (i), that one can derive from a linear estimator. It seems reasonable then to
suppose that c
c
µ0 depends only on the data {Xi : i = 1, 2, . . . , I} . We proceed
therefore by ﬁrst determining
c
µ0 = Pro(µ0| Le(X1, . . . , XI))
(4.12)
and then showing that
c
µ0 = c
c
µ0 = Pro (µ0| Le(D)).
(4.13)
Let c
µ0 = P
i aiXi = Pro (µ0| Le(X1, . . . , XI)). Because of the unbiasedness
in the collective, we must have
X
i ai = 1.
(4.14)
Because of (4.12) it must also be true that
µ0  c
µ0 B Xk  Xr for k, r = 1, 2, . . . , I,
(4.15)

88
4 The Bühlmann—Straub Model
which is equivalent to
Cov(c
µ0, Xk) = Cov(c
µ0, Xr).
From this we get directly that
aiVar [Xi] = const.
(4.16)
The weights ai are therefore inversely proportional to Var [Xi]. Notice also
that
Var [Xi] = E
h
(Xi  µ0)2i
.
The variance therefore corresponds to the quadratic loss of Xi as an estimator
of the quantity µ0. In this way, we again ﬁnd a result which is analogous to
that which we had for the credibility estimator: the weights are proportional
to the precisions, which are deﬁned as the inverse of the quadratic loss. From
the equation
Var [Xi] = E [Var [Xi| i]] + Var [E [Xi| i]]
it also follows that
Var [Xi] =  2 + 2
wi•
=  2
µwi• 2 + 2
wi• 2
¶
(4.17)
=  2 1
i .
From (4.16) and (4.17) it follows that the optimal weights are proportional to
the credibility weights i, and from (4.14) that
c
µ0 =
X
i
i
•
Xi,
where • = P
i i.
Lastly, we must show that c
µ0 satisﬁes (4.13), i.e. that
µ0  c
µ0 B Xkl  Xrs
for all k, l, r and s.
Because
µ0  c
µ0 =
X
i
i
•
(µ0  Xi) ,
this is equivalent to
µ0  Xi B Xkl  Xrs
for i, k, l, r, s.
(4.18)
The right-hand side of (4.18) can be written as
(Xkl  Xk) + (Xk  Xr) + (Xr  Xrs) .

4.6 The Homogeneous Credibility Estimator in the Bühlmann—Straub Model
89
Because of the independence of Xi and Xk for i 6= k we have
µ0  Xi B Xkl  Xk
for k 6= i.
Moreover,
µ0  c
µ0 B (Xk  Xr)
because of (4.15). Hence it remains to show that
µ0  Xi B Xij  Xi.
Since Xi is the homogeneous credibility estimator of µ (i) based on Xi (see
(4.5)), we have that
µ (i)  Xi B Xij  Xi
for j = 1, 2, . . . , n.
If we write µ0  Xi = (µ0  µ (i)) + (µ (i)  Xi) it remains to show that
µ0  µ (i) B Xij  Xi
for j = 1, 2, . . . , n,
which is obvious by conditioning on i.
Thus we have proved the following result:
Theorem 4.4 (homogeneous credibility estimator). The homogeneous
credibility estimator of µ (i) in the Bühlmann—Straub model (Model Assump-
tions 4.1) is given by
\
\
µ (i)
hom
= iXi + (1  i) c
c
µ0 = c
c
µ0 + i
³
Xi  c
c
µ0
´
,
(4.19)
where c
c
µ0 =
I
X
i=1
i
•
Xi,
i =
wi•
wi• + 2
 2
and
• =
I
X
i=1
i.
Remarks:
•
Intuition failed us. As an estimator for µ0 we should not use the observed
average
X =
XI
i=1
wi•
w••
Xi,
but rather the credibility weighted average
c
c
µ0 =
XI
i=1
i
•
Xi.
If we look at si := wi•/w•• as sample weights, then i/• will be closer
to si the closer the si are to the uniform sample weights. Also, given

90
4 The Bühlmann—Straub Model
{si : i = 1, 2, . . . , I}, i/• $ si for w•• $ 0 and i/• $ 1/I for
w•• $ 4.
It is important to note that it may happen that \
\
µ (i)
hom
> Xi, even
though X < Xi , i.e. the homogeneous credibility estimator is not neces-
sarily between the observed individual and the observed collective mean.
•
In contrast to the (inhomogeneous) credibility estimator, we use for the
homogeneous estimator the observations from the entire collective (and
not only those from the ith contract): they are needed for the estimation
of µ0.
•
In practice, the homogeneous estimator is as important (if not more im-
portant) than the inhomogeneous estimator, because the estimation of µ0
is automatically built in to the formula for the homogeneous estimator.
•
Notice:
For the calculation of the homogeneous credibility estimator we proceed
as follows (compare with Figure 4.2):
—
ﬁrst calculate Xi and c
c
µ0 “bottom up” (from the bottom to the top);
—
then calculate \
\
µ (i)
hom
by inserting the top value c
c
µ0 (“top down”).
This “bottom up” and “to down” procedure will become more apparent
in the hierarchical credibility model (see Chapter 6).
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
X11
X12
X1j
X1n      X21
X22
X2j
X2n   
Xi1
Xi2
Xij
Xin   
XI1
XI2
XIj
XIn
Fig. 4.2. Tree structure of the Bühlmann—Straub model
There is another noteworthy property of the homogeneous credibility esti-
mator, which from the point of view of practitioners is important and which
we will now formulate as a theorem.

4.7 Quadratic Loss of the Homogeneous Credibility Estimator
91
Theorem 4.5 (balance property). Given Model Assumptions 4.1 we have
for the homogeneous credibility estimator in the Bühlmann—Straub model
X
i,j wij \
\
µ(i)
hom
=
X
i,j wijXij.
(4.20)
Remarks:
•
In practice, wij is mostly identical with the underlying tari volume mea-
sure Vij. Then the left-hand side of the above equation corresponds ex-
actly to the (total) credibility premium which would have resulted over
the whole portfolio if the credibility premium had been applied over the
entire past observation period. On the right-hand side we have the total
aggregate claim amount over the past observation period. The equation
therefore says that with respect to the past observation period and in total
over the whole portfolio, the resulting total credibility premium and the
aggregate claim amount are equal. This is true independent of the choice,
respectively the estimates, of the structural parameters 2 and  2.
•
Naturally the equality will not be exact for the future period for which
we must rate the risks. It does, however, indicate that, under stationary
conditions, the premium level over the whole portfolio will be fair even if
not all model assumptions are strictly satisﬁed.
•
Under the above conditions, the balance property of the homogeneous
credibility estimator may be reinterpreted as a so-called redistribution of
the total aggregate claim amount S•• = P
i wi•Xi•. The observed aggre-
gate claim amount wi•Xi for the ith risk is “replaced” by wi• \
\
µ (i)
hom
.
The resulting total aggregate claim amount over the whole portfolio and
the whole observation period remains unchanged by this replacement.
Proof of Theorem 4.5: From wi• (1  i) =
¡
2/ 2¢
i it follows that
X
i
wi•
Ã
\
\
µ (i)
hom
 Xi
!
=
X
i
wi•
³
 (1  i) Xi + (1  i) c
c
µ0
´
= 2
 2
X
i
i( c
c
µ0  Xi) = 0,
where in the last step we have used the identity c
c
µ0 = P iXi/•. This con-
cludes the proof of Theorem 4.5.
¤
4.7 Quadratic Loss of the Homogeneous Credibility
Estimator
In this section we calculate the quadratic loss of the homogeneous credibility
estimator (4.19) in the Bühlmann—Straub model.

92
4 The Bühlmann—Straub Model
Theorem 4.6. Given Model Assumptions 4.1 we have for the quadratic loss
of the homogeneous credibility estimator (4.19):
E
5
7
Ã
\
\
µ (i)
hom
 µ (i)
!26
8 =  2 (1  i)
µ
1 + 1  i
•
¶
.
(4.21)
Proof: By iteratively applying the projection operator
\
\
µ (i)
hom
= Pro {Pro (µ (i)| L (X, 1) )| Le (X))}
we get
E
5
7
Ã
\
\
µ (i)
hom
 µ (i)
!26
8
= E
"µ \
\
µ (i)  µ (i)
¶2#
+ E
5
7
Ã
\
\
µ (i)  \
\
µ (i)
hom!26
8 .
From Theorem 4.3 we have that
E
"µ \
\
µ (i)  µ (i)
¶2#
=  2 (1  i) .
For the second term we have that
E
5
7
Ã
\
\
µ (i)  \
\
µ (i)
hom!26
8 = (1  i)2 E
h
( c
µ0  µ0)2i
and
E
h
( c
µ0  µ0)2i
= E
5
7
ÃX
i
i
•
(Xi  µ0)
!26
8
=
X
i
µ i
•
¶2
E
h
(Xi  µ0)2i
|
{z
}
= 2
wi• + 2
=
X
i
µ i
•
¶2 µ2 + wi• 2
wi• 2
¶
|
{z
}
=1
i
 2 =  2
•
.
Hence we get

4.8 Estimation of the Structural Parameters j2 and  2
93
E
5
7
Ã
\
\
µ (i)
hom
 µ (i)
!26
8 =  2 (1  i) + (1  i)2  2
•
=  2 (1  i)
µ
1 + 1  i
•
¶
,
which concludes the proof of Theorem 4.6.
¤
4.8 Estimation of the Structural Parameters 2 and  2
We have seen that the formula for the (inhomogeneous) credibility estimator
involves the three structural parameters µ0, 2,  2. An estimate for µ0 is
already built in to the formula for the homogeneous credibility estimator, so
that only the two structural parameters 2 and  2 remain to be determined.
In practice, these two parameters are also unknown and must be estimated
from the data of the collective. Various articles are to be found in the actuar-
ial literature about the estimation of such parameters (e.g. Dubey and Gisler
[DG81], Norberg [Nor82]). However, none of the various considered alterna-
tives has proved to be generally better than that suggested by Bühlmann and
Straub in their original work. We will now present that estimator here.
Estimation of 2: For the variance within the ith contract we consider
Si :=
1
n  1
n
X
j=1
wij (Xij  Xi)2 .
If we write
Si =
1
n  1
n
X
j=1
wij (Xij  µ (i) + µ (i)  Xi)2
=
1
n  1
;
?
=
n
X
j=1
wij (Xij  µ (i))2  wi• (µ (i)  Xi)2
<
@
> ,
we see immediately that
E [Si| i] = 2 (i) ,
and therefore
E [Si] = E {E [Si| i]} = E
£
2 (i)
¤
= 2.
(4.22)
Each of the random variables Si is therefore an unbiased estimator for 2, and
the question is, how should they be weighted? For example, we could simply
take the arithmetic mean (each Si is given the same weight). Or should the
larger contracts have a greater weight?

94
4 The Bühlmann—Straub Model
The theoretically optimal weights would be proportional to the precisions
³
E
h¡
Si  2¢2i´1
. This expression, however, depends on moments up to
the fourth order which are also unknown and would have to be estimated.
The estimation of these would involve new structural parameters, so that we
see that this line of thinking is not helpful.
In order to get more insight, we consider the special case, where the Xij
are conditionally on i normally distributed. Then we have
E
h¡
Si  2¢2i
= E
h¡
Si  2(i) + 2(i)  2¢2i
=
2
n  1E
£
4 (i)
¤
+ E
h¡
2(i)  2¢2i
,
(4.23)
which does not depend on i. In this case, it is therefore optimal to weight all
Si’s equally and to take their arithmetic mean as estimator of 2.
Obviously, most of the insurance data are not normally distributed. On the
other hand, other weights which would be better in a multitude of situations
are not known. It is therefore reasonable to use as an estimator
c
2 = 1
I
I
X
i=1
1
n  1
n
X
j=1
wij (Xij  Xi)2 .
(4.24)
This estimator has the following properties:
•
Unbiasedness, i.e. E
h
b2i
= 2. This follows directly from (4.22).
•
Consistency, i.e. b2
P$
I$4 2. This follows from Chebychev’s inequality.
Estimation of  2: For didactic reasons, we ﬁrst consider the case where we
have equal aggregate weights for all risks and having done that, we will then
consider the more general case.
a) w1• = w2• = · · · = wI•:
Consider
T =
1
I  1
I
X
i=1
¡
Xi  X
¢2 ,
where X = 1
I
I
X
i=1
Xi.
Since
E [T] = Var [ Xi] = 2
wi•
+  2,
we get that
bb
2 =
1
I  1
I
X
i=1
¡
Xi  X
¢2  b2
wi•
(4.25)
is an unbiased estimator of  2.

4.9 Empirical Credibility Estimator
95
b) General case:
We deﬁne
T =
I
I  1
I
X
i=1
wi•
w••
¡
Xi  X
¢2 ,
where X =
X
i
wi•
w••
.
After some calculation we get the following, unbiased estimator:
bb
2 = c ·
(
I
I  1
I
X
i=1
wi•
w••
¡
Xi  X
¢2  Ic
2
w••
)
,
(4.26)
where
c = I  1
I
( I
X
i=1
wi•
w••
µ
1  wi•
w••
¶)1
.
Remarks:
—
c =
½= 1 if w1• = w2• = · · · = wI•,
> 1 otherwise.
—
Of course, (4.26) coincides with (4.25) in the case of identical aggregate
weights wi•.
The estimator bb
2 has the following properties:
—
Unbiasedness, i.e. E
h
bb
2i
=  2. This is easily checked.
—
Consistency, i.e. bb
2
P$
I$4  2, if no one of the risks is “dominating” (i.e.
if P
i
³
wi•
w••
´2
$ 0
for
I $ 4). A proof can be found for instance in
[DG81].
—
bb
2can possibly be negative. This means that there is no detectable dier-
ence between the risks. This point will become more clear below. Naturally,
in this case we put b 2 = 0. Hence, we ﬁnally use as estimator
b 2 = max
³
bb
2, 0
´
,
(4.27)
where bb
2 is given by (4.26).
Of course, b 2 is no longer unbiased.
4.9 Empirical Credibility Estimator
The empirical credibility estimator is obtained from the homogeneous cred-
ibility formula by replacing the structural parameters 2 and  2 by their
estimators derived in Section 4.8.

96
4 The Bühlmann—Straub Model
\
\
µ (i)
emp
= biXi + (1  bi) c
c
µ0,
where
bi =
wi•
wi• + b,
b =
c
2
b 2 ,
c
c
µ0 =
P
i biXi
P
i bi
.
Observe that bi = 0, if b 2 = 0. In this case c
c
µ0 is deﬁned by c
c
µ0 =
P
i (wi•/w••) Xi.
More insight and a better understanding of the credibility weight bi can
be gained by the following considerations making use of the decomposition of
the sum of squares known from classical statistics. We deﬁne
SStot =
I
X
i=1
n
X
j=1
wij
¡
Xij  X
¢2
(sum of squares total),
SSw =
I
X
i=1
n
X
j=1
wij (Xij  Xi)2
(sum of squares within groups),
SSb =
I
X
i=1
wi•
¡
Xi  X
¢2
(sum of squares between groups).
It is well known and easy to show that
SStot = SSw + SSb.
We now have
if b 2 = 0, then bi = 0,
if b 2 > 0, then bi =
wi•
wi• + b2
b2
=
wi•
wi• + b,
where b can be rewritten as follows:
b = b2
bb
2
= c1 · w••
I
·
(
SSb
I  1 ·
µ
SSw
I · (n  1)
¶1
 1
)1
= c1 · w••
I
· {F  1}1 ,
(4.28)
where
c = I  1
I
( I
X
i=1
wi•
w••
µ
1  wi•
w••
¶)1
,
F =
µ SSb
I  1
¶ µ
SSw
I (n  1)
¶1
.

4.10 Credibility for Claim Frequencies
97
Remarks:
•
Note that F is just the test statistic used in classical statistics for testing
whether the means of observations from normally distributed random vari-
ables are all the same. Indeed, if the Xij were conditionally, given the i,
normally distributed with the same mean and the same normalized vari-
ance
¡
Var (Xij| i, wij) = 2/wij
¢
, then F would have an F-distribution
with I  1 degrees of freedom in the nominator and I · (n  1) degrees of
freedom in the denominator. A negative value of bb
2is equivalent to F < 1,
in which case the F-test would never reject the hypothesis of all means
being equal. This explains the remark made at the end of Section 4.8, that
a negative outcome of bb
2 should be interpreted as there were no detectable
dierences in the expected value between the risks.
•
In general, \
\
µ (i)
emp.
is no longer unbiased.
Although the estimators for the structural parameters are “almost” un-
biased (i.e. aside from the exception that no negative values for  2 are
allowed), in general this is not true for the empirical credibility estimator.
•
If no contract dominates (i.e. if P
i (wi•/w••)2 $ 0 for I $ 4), then we
have
\
\
µ (i)
emp.
P
$ \
\
µ (i)
for I $ 4,
E
· \
\
µ (i)
emp.¸
$ µ0
for I $ 4.
•
Since Theorem 4.5 holds true independent of the choice of the structural
parameters 2 and  2, it also holds true for the empirical credibility estima-
tor, that is, the premium resulting from the empirical credibility estimator
if applied over the past observation period and over the whole portfolio is
equal to the observed total claim amount over the same period and over
the whole portfolio.
•
From this it also follows that
E
" I
X
i=1
wi•
w••
\
\
µ (i)
emp.#
= µ0,
i.e. the weighted average of the empirical credibility estimator taken over
the whole portfolio is unbiased.
These last two points indicate that the premium resulting from the empirical
credibility estimator over the whole portfolio is on the right level.
4.10 Credibility for Claim Frequencies
Claim frequencies play a central role in the calculation of a multivariate tari
as well as for Bonus—Malus systems. A frequently made assumption is that

98
4 The Bühlmann—Straub Model
the claim numbers can be modelled as random variables having a conditional
Poisson distribution. Thus we have more structure, and this special structure
should be taken into account in credibility calculations. This section focuses
on this set-up.
Again we consider the situation where we have a portfolio of risks (or risk
groups) and associated observations, namely
Nij
number of claims of risk i in year j,
wij
associated weight, e.g. years at risk,
Fij = Nij/wij claim frequency.
Analogously to the Bühlmann—Straub model we get the following:
Model Assumptions 4.7 (claim frequency)
The risk i is characterized by its individual risk proﬁle &i, which is itself the
realization of a random variable i, and we assume that:
Fr1: Given i the Nij (j = 1, 2, . . . ) are independent and Poisson distributed
with Poisson parameter ij (i) = wiji0;
Fr2: The pairs (1, N1) , (2, N2) , . . . are independent, and 1, 2, . . . are
independent and identically distributed with E [i] = 1.
Remark:
•
The i reﬂect the frequency structure between the risks, whereas 0 is
the overall frequency level, in analogy to the distinction between tari
structure and tari level, which is quite common in insurance practice.
We will come back to this point below.
Model Assumptions 4.7 imply that
E [Fij| i] = i0,
Var [Fij| i] = i0
wij
.
The conditions of the Bühlmann—Straub model (Model Assumptions 4.1) are
therefore satisﬁed for the claim frequencies with
µ(i) =  (i) = i0,
2 (i) = i0.
The structural parameters are
0 : = E [ (i)] ,
2 : = E
£
2 (i)
¤
= 0,
 2 : = Var [ (i)] = 2
0 Var [i] .
We therefore have:

4.10 Credibility for Claim Frequencies
99
Corollary 4.8 (claim frequency). The credibility estimator and the homo-
geneous credibility estimator for the (absolute) claim frequency under Model
Assumptions 4.7 are given by
\
\
(i) = iFi + (1  i) 0 = 0 + i (Fi  0) ,
where Fi =
X
i
wij
wi•
Fij,
i =
wi•
wi• + ,
(4.29)
 = 0
 2 = (0 Var [i])1 .
\
\
(i)
hom
= iFi + (1  i) c
c
0 = c
c
0 + i
µ
Fi  c
c
0
¶
,
where c
c
0 =
X
i
i
•
Fi.
Remarks:
•
Note that
p
Var [i] is equal to the coe!cient of variation (= standard
deviation divided by expected value) of the individual claim frequency
F ind
i
=  (i) = i0.
•
By multiplying the numerator and denominator on the right-hand side of
formula (4.29) by 0 we see that the credibility weight can also be written
as
i =
i•
i• + e,
(4.30)
where i• = 0wi• = a priori expected number of claims,
e =
1
Var [i] =
£
CoVa
¡
F ind
i
¢¤2 .
e has now a direct interpretation: it is the coe!cient of variation of the
individual claim frequency F ind
i
=  (i) to the power minus two. In many
applications in practice, one has some feeling about CoVa(F ind
i
), which is
often in the range between 10% and 50% with a resulting e in the range
between 100 and 4.
•
If the observed claim numbers in the individual cells are large (several
hundred claims), the credibility weights are also very large and lie in the
neighbourhood of 1. In such cases one can simply rely on the observed
individual claim frequency and there is hardly a need for credibility, since
the results of the credibility estimates deviate very little from the observed
individual claim frequencies. Example 4.1 on page 103 shows a numerical
illustration. However, credibility for claim frequencies makes sense in sit-
uations with a small number of claims, for instance if one is interested

100
4 The Bühlmann—Straub Model
in the claim frequency of large claims (large claims are small in number,
but are often responsible for half or even more of the claims load). For a
numerical illustration, see Example 4.2 on page 104. Credibility for claim
frequencies is also used for Bonus—Malus systems where an individual risk
in the physical sense is considered or where the risk classes considered are
rather small (e.g. a particular ﬂeet of cars).
•
From Theorem 4.5 it follows that
X
ij wij \
\
(i)
hom
=
X
i,j wij Fij = N••,
respectively
X
ij
wij
w••
\
\
(i)
hom
=
X
ij
wij
w••
Fij = F.
Whereas the structural parameter 0 represents the overall frequency level
and will be crucial for the tari level, the random variables i show the
structure of the portfolio with regard to claim frequency and are important
for the tari structure. A value of say 1.2 for i means that the frequency of
risk i is 20% higher than the average. Often one is directly interested in this
structure and hence in estimating the random variables i. Of course, because
of the linearity property of the credibility estimators (see Exercise 3.1), the
credibility estimator of i is immediately obtained by dividing \
\
(i) from
Corollary 4.8 by 0. Therefore it is natural to consider the “standardized”
claim frequencies
F st
ij : = Fij
0
= Nij
ij
,
where ij = wij0 = a priori expected claim number.
Considering standardized frequencies has a further big advantage: in Model
Assumptions 4.7 it was assumed that the a priori claim frequency is the same
for all risks and for all observation years. However, there are situations in
practice where this assumption is not meaningful. For instance, if we consider
ﬂeets of cars, then the a priori claim frequency will depend on the types of
cars in the ﬂeet and possibly on other explanatory variables. Sometimes one
also ﬁnds trends over the years, such that time homogeneity does not hold
true either. But if we consider standardized frequencies, we can easily deal
with such situations. Formally, we replace Fr1 in Model Assumptions 4.7 by
the following weaker and more general condition:
•
Fr1 0:Given i the Nij (j = 1, 2, . . . ) are independent and Poisson distrib-
uted with Poisson parameter ij(i) = iij, where ij is the a priori
expected claim number of risk i in year j.
Note that the standardized frequencies

4.10 Credibility for Claim Frequencies
101
F st
ij := Nij
ij
all have an a priori expected value of one. Note also that we are in the same
formal situation as in Model 4.7: we just have to put there 0 = 1 and wij =
ij. We therefore have:
Corollary 4.9 (standardized claim frequency). The credibility estimator
for the standardized claim frequency i under Model Assumptions 4.7 is given
by
c
c
i = 1 + i
¡
F st
i  1
¢
,
where F st
i
=
X
j
ij
i•
F st
ij ,
i =
i•
i• + e,
e = (Var [i])1 .
Remark:
•
Under Model Assumptions 4.7 we have
ij = wij0,
ij
i•
= wij
wi•
,
and e has a direct interpretation: it is the coe!cient of variation of the
individual claim frequency F ind to the power 2.
In the homogeneous case, the a priori expected claim numbers ij are only
known up to a constant factor. For instance, under Model Assumptions 4.7,
ij = wij0 depends on 0, which is unknown and which has to be estimated
from the data too. The question arises, how we should then deﬁne standardized
frequencies?
We suggest standardizing in the homogeneous case in such a way that the
resulting numbers eij satisfy the condition
e•• = N••.
(4.31)
This means that the unknown multiplicative factor is chosen in such a way
that, over the whole portfolio, there is equality between the a priori expected
claim number and the observed claim number. Under Model Assumptions 4.7
eij = wijF,
where F is the observed claim frequency over the whole portfolio. Note that
in this case

102
4 The Bühlmann—Straub Model
F st
ij = Fij
F ,
which is very natural to look at.
The rule (4.31) has the advantage that the numbers eij are known at the
very beginning and do not depend on parameters to be estimated. With this
rule it also follows that
X
i
ei•
e••
c
c
i
hom
= 1.
Corollary 4.8 still holds for the standardized frequencies and corresponding
“weights” eij fulﬁlling (4.31) , and we get:
Corollary 4.10 (hom. estimator of the standardized frequency). The
homogeneous credibility estimator of i is given by
c
c
i
hom
= c
c
&0 + i
µ
F st
i  c
c
&0
¶
,
where i =
i•
i• + e,
e = (Var [i])1 ,
c
c
&0 =
X
i
i
•
F st
i .
Remarks:
•
Under Model Assumptions 4.7, we have
c
c
i
hom
=
\
\
(i)
hom
F
,
and hence
c
c
&0 =
c
c
0
F .
Estimation of structural parameters:
A consequence of the Poisson assumption is that the structural parameters
2 and 0 are equal. To have this equality also for the estimated structural
parameters, we can use the following iterative procedure:
First we deﬁne
c := I  1
I
½X
i
wi•
w••
µ
1  wi•
w••
¶¾1
,
T :=
I
I  1 ·
X
i
wi•
w••
¡
Fi  F
¢2 ,
where F =
X
i
wi•
w••
Fi.

4.10 Credibility for Claim Frequencies
103
Then we start with
(0)c
c
0 = F,
(0)b 2 = c
(
T  I(0)b0
w••
)
.
(4.32)
The iteration from step n to step n + 1 is
(n)b =
(n)c
c
0
(n)b 2 ,
(n)i =
wi•
wi• + (n)b,
(n+1)c
c
0 =
X
i
(n)i
(n)•
Fi,
(n+1)b 2 = c ·
;
?
=T  I(n+1)c
c
0
w••
<
@
> .
Remarks:
•
The same procedure for estimating the structural parameters also applies
for estimating the structural parameters for the “standardized” frequency.
Then we have simply to replace the weights wij by ij (ij = wijF under
Model Assumptions 4.7), and instead of c
c
0, we estimate c
c
&0.
•
Note that it is su!cient to know the multiyear claim frequencies Fi and
that we do not need the yearly observations to estimate the structural
parameters.
Example 4.1 (frequency of “normal” claims)
The table below shows the number and frequencies of normal claims of a
motor liability portfolio for 21 regions.
With the recursive procedure for estimating the structural parameters we
obtain after two recursion steps:
c
c
0 = 88.3%o,
b 2 = 2.390 · 104,
with a resulting
b = 370 (relating to the number of risks),
and an estimated coe!cient of variation
\
CoVa ((i)) = b
c
c
0
= 17.5%,

104
4 The Bühlmann—Straub Model
or for the standardized frequency i:
c
c
&0 = 0.976,
be
2 = 2.923 · 102,
with a resulting
be = 33 (relating to the a priori expected claim number),
and an estimated coe!cient of variation
\
CoVa (i) =
c
c
&0
be
= 17.5%.
Of course, CoVa ((i)) must be identical to CoVa (i), which must also hold
for the estimated values.
Group number of
credibility weight
i
risks
a priori
observed
expected
      %o
standardized
 %
%o
1
 50 061
 4 534
 3 880
77.5
0.86
99.3
77.6
0.86
2
 10 135
  918
  794
78.3
0.86
96.5
78.7
0.87
3
 121 310
 10 987
 8 941
73.7
0.81
99.7
73.7
0.81
4
 35 045
 3 174
 3 448
98.4
1.09
99.0
98.3
1.09
5
 19 720
 1 786
 1 672
84.8
0.94
98.2
84.9
0.94
6
 39 092
 3 541
 5 186
132.7
1.47
99.1
132.2
1.46
7
 4 192
  380
  314
74.9
0.83
91.9
76.0
0.84
8
 19 635
 1 778
 1 934
98.5
1.09
98.2
98.3
1.09
9
 21 618
 1 958
 2 285
105.7
1.17
98.3
105.4
1.16
10
 34 332
 3 109
 2 689
78.3
0.86
98.9
78.4
0.87
11
 11 105
 1 006
  661
59.5
0.66
96.8
60.5
0.67
12
 56 590
 5 125
 4 878
86.2
0.95
99.4
86.2
0.95
13
 13 551
 1 227
 1 205
88.9
0.98
97.3
88.9
0.98
14
 19 139
 1 733
 1 646
86.0
0.95
98.1
86.0
0.95
15
 10 242
  928
  850
83.0
0.92
96.5
83.2
0.92
16
 28 137
 2 548
 2 229
79.2
0.87
98.7
79.3
0.88
17
 33 846
 3 065
 3 389
100.1
1.11
98.9
100.0
1.10
18
 61 573
 5 577
 5 937
96.4
1.06
99.4
96.4
1.06
19
 17 067
 1 546
 1 530
89.6
0.99
97.9
89.6
0.99
20
 8 263
  748
  671
81.2
0.90
95.7
81.5
0.90
21
 148 872
 13 483
 15 014
100.9
1.11
99.8
100.8
1.11
Total
 763 525
 69 153
69 153
90.6
1.00
90.6
1.00
Frequency
Cred. Estimator
standardized
number of claims
Table: Claim frequency of “normal” claims
The results show, that the deviations between the credibility estimates and
the observed individual frequencies are very small and negligible for practical
purposes, such that credibility gives very little additional insight.
Example 4.2 (frequency of large claims)
The table below shows the number of large claims (claims above CHF 50 000)
and the corresponding claim frequencies for the same motor liability portfolio
as in Example 4.1. The number of large claims is rather small compared to

4.10 Credibility for Claim Frequencies
105
the number of “normal” claims. However, they make more than half of the
claims load, and therefore it can be crucial in tari making, to estimate as
precisely as possible the frequency of large claims.
Group number of
credibility weight
i
risks
a priori
observed
expected
      %o
standardized
 %
%o
1
 50 061
45
42
0.84
0.93
62.5
0.86
0.95
2
 10 135
9
5
0.49
0.55
25.2
0.79
0.88
3
 121 310
109
105
0.87
0.96
80.1
0.87
0.97
4
 35 045
32
32
0.91
1.01
53.8
0.90
1.00
5
 19 720
18
32
1.62
1.80
39.6
1.18
1.31
6
 39 092
35
37
0.95
1.05
56.5
0.92
1.02
7
 4 192
4
7
1.67
1.85
12.2
0.99
1.10
8
 19 635
18
16
0.81
0.90
39.5
0.86
0.96
9
 21 618
20
18
0.83
0.92
41.8
0.87
0.96
10
 34 332
31
30
0.87
0.97
53.3
0.88
0.98
11
 11 105
10
7
0.63
0.70
27.0
0.82
0.91
12
 56 590
51
52
0.92
1.02
65.3
0.91
1.01
13
 13 551
12
10
0.74
0.82
31.1
0.85
0.94
14
 19 139
17
15
0.78
0.87
38.9
0.85
0.94
15
 10 242
9
14
1.37
1.51
25.4
1.01
1.12
16
 28 137
25
20
0.71
0.79
48.3
0.81
0.89
17
 33 846
31
17
0.50
0.56
53.0
0.69
0.76
18
 61 573
56
37
0.60
0.67
67.2
0.70
0.77
19
 17 067
15
21
1.23
1.36
36.2
1.02
1.13
20
 8 263
7
9
1.09
1.21
21.6
0.94
1.04
21
 148 872
134
163
1.09
1.21
83.2
1.06
1.18
Total
 763 525
689
689
0.90
1.00
0.90
1.00
Frequency
Cred. Estimator
standardized
number of xs-claims
Table: Claim frequency of large claims
With the recursive procedure we obtain (after two recursion steps) the
following estimates for the structural parameters:
b0 = 0.90%o
b 2 = 2.978 · 108
with a resulting
b = 30 058 (relating to the number of risks),
and an estimated coe!cient of variation
\
CoVa ((i)) = b
c
c
0
= 19.3%,
or for the standardized frequency i:
c
c
&0 = 0.992,
be
2 = 3.657 · 102,
with a resulting
be = 27 (relating to the a priori expected claim number),

106
4 The Bühlmann—Straub Model
and an estimated coe!cient of variation
\
CoVa (i) =
c
c
&0
be
= 19.3%.
Note that the heterogeneity (in terms of CoVa) is about the same as in Ex-
ample 4.1. This is reﬂected in the values of e (kappa for the standardized
frequency), which are very close to each other in Examples 4.1 and 4.2. How-
ever, this is not the case for the values of  (kappa value for the absolute
claim frequency). Indeed, the value of  is more di!cult to interpret and is
determined by the observed over all claim frequency F, whereas e has a very
direct meaning, as it denotes the number of expected claims to give a credibil-
ity weight of 50%. Note also, that c
c
&0 is close to one in both examples, which
is usually the case in practical applications.
From the above table we can see that the deviation between the credibility
estimates and the individual observations is far from negligible.
4.11 Credibility for Claim Sizes
Frequently, in the calculation of premiums, the expected values of claim fre-
quencies and claim sizes are determined and modelled separately. Our interest
is in the risk premium which is a product of both of these quantities. For this
reason we might ask if it really makes sense to consider the claim frequency
and the average claim size separately.
For each risk i, we assume that the following amounts over a given obser-
vation period (one year or several years) are known:
Ni
claim number,
wi
associated weight or volume (e.g. number
of years at risk),
Fi = Ni
wi
claim frequency,
Y ()
i
,  = 1, 2, . . . , Ni claim sizes, claim amounts,
Si =
Ni
P
=1
Y ()
i
total aggregate claim amount,
Yi = Si
Ni
average claim size, average claim amount,
Xi = Fi · Yi = Si
wi
claims ratio.
Again, we want to calculate the pure risk premium
E [Xi| i] = E [Fi · Yi| i] .
A “factorization” into frequency and average claim amount is allowable if
E [Xi| i] = E [Fi| i] · E [Yi| i] .

4.11 Credibility for Claim Sizes
107
This is the case if claim number and claim sizes are conditionally independent.
Note that only conditional, and not unconditional, independence is required.
The conditional independence is an assumption which is frequently appropri-
ate in many situations in insurance practice.
We can now estimate E [Fi| i] and E [Yi| i] separately and then multiply
the two estimators to get an estimate of E [Xi| i]. E [Fi| i] and E [Yi| i]
are possibly not independent. If this were the case, this would mean, that
we could possibly learn something from the claim frequency with respect to
the expected value of the claim size and vice versa. When estimating claim
frequency and claim averages separately, we ignore this additional informa-
tion. In Chapter 7 we will present a technique to show how this additional
information could be taken into account in a credibility frame work.
The ﬁrst factor, the claim frequency, was the subject of the previous section.
In this section, we concern ourselves with the second part, the determination
of the expected value of the individual claim size.
For claim sizes, we make the following assumptions:
Model Assumptions 4.11 (claim sizes)
Conditional on i, the claim sizes Y ()
i
,  = 1, 2, . . . , Ni, are independent and
identically distributed with the same distribution as the random variable Y
and the conditional moments
µ(i) = E [Y | i] ,
2(i) = Var (Y | i) .
Note that Model Assumptions 4.11 imply the following conditional moments
for the average claim sizes Yi:
E [Yi| i] = µ(i),
(Var [Yi| i, Ni = ni]) = 2 (i)
ni
.
We need to estimate µ(i) = E [Y | i]. This situation also ﬁts in very nicely
with the Bühlmann—Straub model (Model Assumptions 4.1). We must (men-
tally) substitute the year index j by the “count index” . The weights wi are
1, and instead of the number of observation years n we have the number ni of
observed claims. The point is that both  and j denote the index numbering
the observations of the same risk. This index is often interpreted as time, but
of course, as this example shows, other interpretations are possible.
Corollary 4.12. The credibility estimator of µ(i) is given by
\
\
µ(i) = µ0 + i (Yi  µ0) ,
where i =
ni
ni + 2
 2
.

108
4 The Bühlmann—Straub Model
Remarks:
•
We obtain for the credibility coe!cient
 = µ2
0
 2 · 2
µ2
0
,
= µ2
0
 2 ·
µ2 +  2
µ2
0
¶
 1,
= {CoVa (µ (i))}2 · (CoVa (Y ))2  1.
(4.33)
•
The coe!cient of variation of the individual claim size µ (i) is often in
the range between 10% and 30%, whereas the (unconditional) coe!cient
of variation of the claim size (CoVa (Y )) depends on the line of business
and the claim segments (all claims, normal claims, large claims). These
values are often known in insurance practice (see table below).
Line of business
Coe!cient of variation (CoVa (Y ))
all claims
claims
claims
< CHF 50 000 = CHF 50 000
motor liability
9.0
1.7
1.5
motor hull
2.0
general liability
7.5
2.5
2.0
workmen compensation
9.0
2.5
1.2
in case of accident
workmen compensation
2.5
in case of sickness
industry ﬁre
7.0
2.0
2.0
household
2.0
Table: Claim sizes: coe!cient of variation from a Swiss insurance company
For instance, in the motor liability line and for CoVa (µ (i)) = 20%, we
obtain, using formula (4.33), that  = 2 000 for all claims,  = 50 for nor-
mal claims and  = 30 for large claims. If we consider all claims, we need
about 2 000 claims for a credibility weight i of 50%. However, if we separate
“normal” and “large” claims, we often have a similar situation to the claim
frequencies: for the large mass of normal claims, the credibility estimators
for the average claim size will often dier little from the observed individual
average claim amount.
In contrast to the usual situation in the Bühlmann—Straub model, the
modelling of the claim size has to describe a situation where the number ni can
be substantially dierent from one unit to be rated to another. This requires
a modiﬁcation to the estimation procedure for the structural parameter 2.
Again let

4.11 Credibility for Claim Sizes
109
Si =
1
ni  1
ni
X
=1
³
Y ()
i
 Yi
´2
,
where
Yi = 1
ni
ni
X
=1
Y ()
i
.
The random variables Si (i = 1, 2, . . . ) are all unbiased and independent esti-
mators for 2. Again the question arises as to how they should be weighted.
The considerations already discussed on page 94 can help us again here. In the
case of normally distributed random variables, according to (4.23), we have
E
h¡
Si  2¢2i
=
2
ni  1E
£
4 (i)
¤
+ E
h¡
2(i)  2¢2i
.
If we ignore the second summand, we should choose the weights proportional
to ni  1. Alternatives, i.e. weights which would be better in the majority of
cases, are not available. On the basis of these considerations, the following
estimator is a reasonable choice:
c
2 =
1
n•  I
I
X
i=1
ni
X
=1
³
Y ()
i
 Yi
´2
.
(4.34)
Remark:
•
It may happen that ni is equal to one or zero for some risk groups. These
risk groups do not contribute to the estimation of the “within” variance
component 2. To be strict, we should then use I = number of risks
groups with ni > 2 instead of I in formula (4.34). However, the dierence
in the results when using I instead of I in such situations will often be
so small that it can be ignored.
For estimating  2 we can use the usual estimator of Section 4.8, formula
(4.27), that is
b 2 = max
³
bb
2, 0
´
,
where bb
2 = c ·
(
I
I  1
I
X
i=1
ni
n•
¡
Yi  Y
¢2  Ib2
n•
)
,
(4.35)
Y =
I
X
i=1
ni
n•
Yi,
c = I  1
I
( I
X
i=1
ni
n•
µ
1  ni
n•
¶)1
.
As an alternative, it is sometimes convenient to make use of the decompo-
sition of the sum of squares, which are in this case:

110
4 The Bühlmann—Straub Model
SStot =
I
X
i=1
ni
X
=1
³
Y ()
i
 Y
´2
(sum of squares total),
SSw =
I
X
i=1
ni
X
=1
³
Y ()
i
 Yi
´2
(sum of squares within groups),
SSb =
I
X
i=1
ni
¡
Yi  Y
¢2
(sum of squares between groups).
It holds again that
SStot = SSw + SSb.
Analogously to (4.28) we can write
b = b2
bb
2
= c1 · n•
I ·
½ SSb
SSw
· n•  I
I  1  1
¾1
.
(4.36)
Remarks:
•
The coe!cient of variation of the claim size is usually estimated by
\
CoVa (Y ) =
r
1
n•1
PI
i=1
Pni
=1
³
Y ()
i
 Y
´2
Y
.
Hence
SStot = (n•  1) Y
2
\
CoVa (Y )
2
.
(4.37)
•
Sometimes, there are only available summary statistics with the observed
average claim size Yi, but not the individual claim amounts Y ()
i
. But on
the other hand, one has from other sources an estimation of the coe!cient
of variation
\
CoVa (Y ). Then one can still use formula (4.36) by setting
SSw = SStot  SSb and by estimating the “unknown” SStot by
[
SStot = (n•  1) Y
2
\
CoVa (Y )
2
.
•
If one knows the observed average claim amounts Yij of several years j =
1, 2, . . . , n as well as the corresponding numbers of claims nij, then one can
of course also estimate the structural parameters by the usual estimators
of Section 4.8 and by taking the number of observed claims as weights.
4.12 Credibility for Risk Groups of Known Individual
Contracts
Assume that we have a portfolio of risk groups i = 1, 2, . . . , I, each of them
consisting of ni individual contracts with observations X()
i
,  = 1, 2, . . . ,

4.13 Modiﬁcation for the Case of Known a Priori Dierences
111
ni, and corresponding individual weights wi. We further assume that these
individual observations fulﬁl the Bühlmann—Straub model conditions. We then
have the following model:
Model Assumptions 4.13
i) Conditional on i, the observations X()
i
,  = 1, 2, . . . , ni, are independent
with
E
h
X()
i
¯¯¯ i
i
= µ(i),
Var
³
X()
i
¯¯¯ i
´
= 2 (i)
wi
.
ii) The pairs (1, X1), (2, X2) , . . . are independent, and 1, 2, . . . are
independent and identically distributed.
Here, the elements of the vectors Xi are the observations of the individual
contracts, that is X0
i =
³
X(1)
i
, X(2)
i
, . . . , X(ni)
i
´
.
Again, this model is in line with the Bühlmann—Straub model, and we just
have to substitute the year index j in Model Assumptions 4.1 by the “count
index” . As for the claim sizes, the only dierence to the usual set-up is that
the number of contracts (resp. observations) ni dier between risk groups,
which requires a modiﬁcation of the estimation of 2. The estimators of the
structural parameters are the same as the ones encountered in Section 4.11.
We have simply to replace Y ()
i
, Yi, Y in the formulae (4.34) and (4.35) by
X()
i
, Xi, and X.
4.13 Modiﬁcation for the Case of Known a Priori
Dierences
The model assumption of the Bühlmann—Straub model, that the risks are “a
priori equal”, is a strong condition that is not fulﬁlled in many situations
in insurance practice. Often, we have available “a priori” information about
dierences between the expected risk premiums of the individual risks. For
example, the current premium could provide such information. The dieren-
tiation between risk premiums based on current rates can be used as an a
priori dierentiation for the new rating of premiums based on newly available
statistics and data. Another example is the situation where technical experts
make a classiﬁcation of the risks based on their knowledge and judgement.
Examples of such a priori information are the car classiﬁcation in motor hull
insurance or the grouping of businesses into danger classes in collective acci-
dent insurance.
In all these cases, the Bühlmann—Straub model is not directly applicable.
However, a minor modiﬁcation of the model assumptions allows us to use this

112
4 The Bühlmann—Straub Model
model also in such situations which enormously increases the applicability of
the Bühlmann—Straub model in practice.
Model Assumptions 4.14 (a priori dierentiation)
The risk i is characterized by its individual risk proﬁle &i, which is itself the
realization of a random variable i, and:
BS1 0:the observations {Xij : j = 1, 2, . . . , n} are, conditional on i, indepen-
dent with
E [Xij |i ] = ai µ(i),
(4.38)
Var [Xij |i ] = 2 (i) /
µwij
ai
¶
,
(4.39)
where the ai’s are known constants.
BS2 0:the same condition as in the Bühlmann—Straub model (Model Assump-
tions 4.1), i.e. the pairs (1, X1), (2, X2) , . . . are independent and 1,
2, . . . are independent and identically distributed.
For the transformed random variables Yij = Xij /ai we then have
E [Yij |i ] = µ(i),
(4.40)
Var [Yij| i] = 2(i)/ (aiwij) ,
(4.41)
i.e. the transformed variables Yij together with the transformed weights
w
ij = aiwij satisfy the conditions of the Bühlmann-Straub model (Model
Assumptions 4.1). Therefore the credibility estimator of µ (i) based on the
Yij’s is given by
\
\
µ(i) = iYi + (1  i) µ0,
where Yi =
X
j
wij
wi•
Yij
and
i =
aiwi•
aiwi• + 2
 2
.
Applying the linearity property of projections we immediately obtain the cred-
ibility estimator for µX (i) := aiµ (i), namely:
Corollary 4.15 Given Model Assumptions 4.14, the (inhomogeneous) credi-
bility estimator is given by
\
\
µX(i) = ai \
\
µ(i) = iXi + (1  i) µi,
where
µi = aiµ0,
i =
aiwi•
aiwi• + 2
 2
.

4.14 Example of Another Kind of Application
113
Remarks:
•
Note that the ai must be known only up to a constant factor; only “rela-
tive” dierences between the risks play a role.
•
The whole argument also works when, instead of, or in addition to the a
priori dierentiation between the risks, we have an a priori dierentiation
which is year dependent (instead of the constants ai, we have constants aj
or aij).
•
The balance property stated in Theorem 4.5 (balance between aggregated
premiums and claim amounts) continues to be valid, because
X
i,j
wij \
\
µX (j)
hom
=
X
i,j
ajwij \
\
µ (j)
hom
=
X
i,j
ajwijYij =
X
i,j
wijXij.
(4.42)
Hence, if the weights wij are the volume measure of the underlying tari,
which is the standard case, then the resulting credibility premium aggre-
gated over the whole portfolio and applied to the past observation period
would exactly match the observed total aggregate claim amount.
•
The variance condition (4.41) is motivated by the following considerations:
—
If Xij = Sij/wij and the Sij are conditionally Poisson distributed with
Poisson parameter ij(i) = aiwij(i), then we have directly (4.39).
—
The form of the conditional variance as in (4.41) is necessary to retain
the above-stated convenient practical property (4.42).
4.14 Example of Another Kind of Application
Credibility and the Bühlmann—Straub model can also be used in situations
other than the direct calculation of the pure risk premium. In this section we
show an interesting application of the Bühlmann—Straub model to estimate
the parameter of the Pareto distribution (see [Ryt90]).
In excess of loss reinsurance, the primary insurer pays claims up to an
agreed threshold (called retention) c > 0, and the excess part (often cut o
at an upper limit) is paid by the reinsurer. As usual we assume that the
claim amounts are i.i.d.. In addition we assume that the claims exceeding the
retention limit c have a Pareto distribution, i.e.
P (Y > y) =
³y
c
´&
.
Observe that under the Pareto law, the distribution of claim amounts exceed-
ing any higher limit c0 is also Pareto with parameters & and c0. Hence & is
independent of the retention limit.

114
4 The Bühlmann—Straub Model
The problem is to estimate the parameter &.
We consider the reinsurance contract i, and let Y ()
i
( = 1, 2, . . . , ni) be
the claim amounts (reindexed) of all claims which have exceeded the threshold
ci. It is easy to see that
ln
Ã
Y ()
i
ci
!
is exponentially distributed with parameter &i.
(4.43)
From this we get the maximum-likelihood estimator
b&
MLE
i
=
Ã
1
ni
ni
X
=1
ln
Ã
Y ()
i
ci
!!1
.
From (4.43) and the (conditional) independence of the individual claim
amounts it follows that
ni
X
=1
ln
Ã
Y ()
i
ci
!
is Gamma distributed with density
&ni
i
(ni  1)! yni1 e&iy.
After some calculation we get
E
h
b&
MLE
i
i
=
ni
ni  1&i,
Var
h
b&
MLE
i
i
=
µ
ni
ni  1
¶2
&2
i
ni  2.
With appropriate normalization we derive from the maximum-likelihood esti-
mator the unbiased estimator
b&
MLE
i
= ni  1
ni
b&
MLE
i
,
with
E
·
b&
MLE
i
¸
= &i,
(4.44)
Var
·
b&
MLE
i
¸
=
&2
i
ni  2,
(4.45)
CoVa
µ
b&
MLE
i
¶
=
1
sni  2.
(4.46)
The number of observed “excess claims” ni is often very small. This means
that the estimator b&
MLE
i
has a large coe!cient of variation and is therefore
rather unreliable. We can get more reliable information when studying a port-
folio of similar excess of loss contracts. This calls for credibility methods and
brings us to the following:

4.14 Example of Another Kind of Application
115
Model Assumptions 4.16 (credibility model for Pareto)
The risk i is characterized by its individual risk proﬁle &i, which is itself the
realization of a random variable i, and it holds that:
•
Y ()
i
( = 1, 2, . . . , ni) are conditionally (given i = &i) independent and
Pareto(ci, &i) distributed;
•
1, 2, . . . , I
are independent and identically distributed with E [i] =
&0 and Var [i] =  2.
According to (4.44) and (4.45) it holds that
E
·
b&
MLE
i
¯¯¯¯ i
¸
= i,
Var
·
b&
MLE
i
¯¯¯¯ i
¸
=
2
i
(ni  2).
From this it is obvious that the modiﬁed (unbiased) ML-estimators
½
b&
MLE
i
: i = 1, 2, . . . , I
¾
satisfy Model Assumptions 4.1 of the Bühlmann—
Straub model with
µ (i) = i,
2(i) = 2
i ,
weight wi = ni  2.
The structural parameters in this Pareto credibility model are
&0 = E [i] ,
2 = E
£
2
i
¤
=  2 + &2
0,
 2 = Var [i] .
With this we have derived the following result:
Corollary 4.17. Under Model Assumptions 4.16, the credibility estimator
(based on the statistics of the modiﬁed ML-estimators b&
MLE
i
: i = 1, . . . , I)
is given by
bi = i b&
MLE
i
+ (1  i) &0,
where
i =
ni  2
ni  1 + &2
0
 2
.
Remarks:
•
Note that &2
0/ 2 = CoVa2(i).

116
4 The Bühlmann—Straub Model
•
From the experience with many excess-of-loss portfolios, an experienced
underwriter often has an a priori idea about the values of &0 and CoVa2(i),
which he can use in the application of the credibility formula (pure
Bayesian procedure). We can, however, also estimate these structural pa-
rameters from the data (empirical credibility).
•
Compare the result of Corollary 4.17 with the Bayes estimator (2.40).
In the following we show how we can use the data from the collective to
estimate the structural parameters &0 and . To simplify the notation we write
Xi := b&
MLE
i
.
We also assume that ni > 2 for i = 1, 2, . . . , I.
First, we consider the random variable
T =
1
I  1
X
i
i
³
Xi  b&0
´2
,
(4.47)
where
b&0 =
X
i
i
•
Xi.
(4.48)
Observe that, contrary to the usual volume weights, the credibility weights
are taken in (4.47) and that these credibility weights depend on the structural
parameters we want to estimate. Hence T is a pseudo estimator.
Lemma 4.18. If we knew the correct credibility weights i, then
E [T ] =  2.
Proof: We rewrite T and get
E [T] = E
"
1
I  1
(X
i
i (Xi  &0)2  •
³
b&0  &0
´2
)#
=
1
I  1
(X
i
i( 2 + 2
wi•
)  •Var
h
b&0
i)
=
1
I  1{I 2   2}
=  2.
The lemma is thus proved.
¤
We estimate now the structural parameters &0 and  2 so that
T
³
b&0, b 2´
= b 2.
(4.49)
These estimators, as is the case for many maximum-likelihood estimators, are
deﬁned by an implicit equation. This can be most easily solved by a recursive

4.15 Exercises
117
procedure. Let &(0)
0
and
¡
 2¢(0) be sensibly chosen starting values and let (0)
i
be the credibility weights based on these values. (4.47) and (4.48) then give
new estimators &(1)
0 and
¡
 2¢(1). This is repeated until (4.49) is satisﬁed with
the desired accuracy. As a simple starting value we could use, e.g.
&(0)
0
= 1
I
X
i
Xi
¡
 2¢(0) =
1
I  1
X
i
³
Xi  &(0)
0
´2
.
4.15 Exercises
Exercise 4.1
The following table shows the observations of a ﬁre portfolio consisting of ﬁve
risk groups, where
w = weight = sum insured in millions,
S = total claim amount in thousands,
X = S/w = claims ratio in %o
(= total claim amount per unit sum insured).
risk groups / years
1
2
3
4
5
Total
group 1
w
  729
  786
  872
  951  1 019
 4 357
S
  583  1 100
  262
  837  1 630
 4 412
X
0.80
1.40
0.30
0.88
1.60
1.01
group 2
w
 1 631  1 802  2 090  2 300  2 368  10 191
S
  99  1 298
  326
  463
  895
 3 081
X
0.06
0.72
0.16
0.20
0.38
0.30
group 3
w
  796
  827
  874
  917
  944
 4 358
S
 1 433
  496
  699  1 742  1 038
 5 408
X
1.80
0.60
0.80
1.90
1.10
1.24
group 4
w
 3 152  3 454  3 715  3 859  4 198  18 378
S
 1 765  4 145  3 121  4 129  3 358  16 518
X
0.56
1.20
0.84
1.07
0.80
0.90
group 5
w
  400
  420
  422
  424
  440
 2 106
S
  40
  
  169  1 018
  44
 1 271
X
0.10
0.00
0.40
2.40
0.10
0.60
Total
w
 6 708
 7 289
 7 973
 8 451
 8 969  39 390
S
 3 920
 7 039
 4 577
 8 189
 6 965  30 690
X
0.58
0.97
0.57
0.97
0.78
0.78
We want to estimate for each risk group i = 1, 2, . . . , 5 the corresponding
individual claims ratio µ (i).

118
4 The Bühlmann—Straub Model
a) Calculate the homogeneous credibility estimates based on the Bühlmann—
Straub model (Model Assumptions 4.1) with  = 3 000 mio.
b) As a) but with  = 6 000 mio.
c) As a) but estimate  (resp. 2 and  2) from the data (empirical credibility
estimator).
d) Check that (4.20) of Theorem 4.5 is fulﬁlled, i.e. show, that for all homoge-
neous credibility estimators obtained in a)—c) it holds that the credibility
premium obtained by applying the credibility rates over the past observa-
tion period coincides in total over the whole portfolio with the observed
claim amount.
e) The old tari (based on earlier observation periods and a priori knowledge)
had the following relative structure:
risk group
1
2
3
4
5
a priori premium factor
0.70 0.80 1.50 1.00 0.50
Calculate the pure risk premiums based on the (empirical) homogeneous
credibility estimators by using the above factors as a priori dierences be-
tween risks (Model Assumptions 4.14).
Compare the relative structure of the old and the new tari obtained
with e) and c) (normalizing factors such that group 4 has a factor equal
to one).
Exercise 4.2
The following table shows the risk exposure, the total claim amount and the
average claim amount per risk of a motor portfolio, both for normal and large
claims (below/above a certain threshold).
region
# of years
at risk
(yr)
total 
average
total 
average
total 
average
in 1 000
per yr
in 1 000
per yr
in 1 000
per yr
1
 41 706
 17 603
422
 7 498
180
 10 105
242
2
 9 301
 5 822
626
 1 900
204
 3 922
422
3
 33 678
 15 033
446
 7 507
223
 7 526
223
4
 3 082
  758
246
  560
182
  198
64
5
 27 040
 11 158
413
 4 142
153
 7 016
259
6
 44 188
 25 029
566
 7 928
179
 17 101
387
7
 10 049
 5 720
569
 1 559
155
 4 161
414
8
 30 591
 14 459
473
 6 568
215
 7 891
258
9
 2 275
  329
145
  329
145
0
0
10
 109 831
 54 276
494
 21 859
199
 32 417
295
Total
 311 741
 150 187
482
 59 850
192
 90 337
290
all claims
normal claims
large claims
claim amount 

4.15 Exercises
119
a) Calculate the pure risk premium, i.e. the values of the (empirical) homo-
geneous credibility estimator based on the ﬁgures in column 4 (all claims,
average claims cost per year at risk).
b) Calculate the pure risk premium for the claims cost of normal claims, i.e.
the values of the (empirical) homogeneous credibility estimator based on
the ﬁgures in column 6 (normal claims, average claims cost per year at
risk).
c) As b) for the large claims.
d) Compare the pure risk premium obtained by adding the results of b) and
c) with those obtained in a).
Exercise 4.3
The following table shows the number and the claim frequencies of normal
and large claims of the same motor portfolio as in Exercise 4.2. Calculate the
values of the credibility estimator for the normal and the large claim frequency
(absolute and relative values) under Model Assumptions 4.7.
region
# of years
at risk
number
frequency
number
frequency
%o 
%o 
1
 41 706
 2 595
62.2
21
0.50
2
 9 301
  763
82.0
8
0.86
3
 33 678
 3 302
98.0
26
0.77
4
 3 082
  233
75.6
1
0.32
5
 27 040
 1 670
61.8
15
0.55
6
 44 188
 3 099
70.1
33
0.75
7
 10 049
  631
62.8
12
1.19
8
 30 591
 2 428
79.4
25
0.82
9
 2 275
  116
51.0
0
0.00
10
 109 831
 8 246
75.1
84
0.76
Total
 311 741
 23 083
74.0
225
0.72
normal claims
large claims
Exercise 4.4
The following table shows for each region i the observed average claim amount
Xi, the observed empirical standard deviation i of the claim amounts and
the observed empirical coe!cient of variation CoVai = i/Xi, both for normal
and large claims of the same motor portfolio as in Exercises 4.2 and 4.3.
a) Calculate the values of the (empirical) homogeneous credibility estimator
of the severity of claims under Model Assumptions 4.11.
b) Dito for the large claims.

120
4 The Bühlmann—Straub Model
region
claim  
claim  
number
number
Xi
(n)
Vi
(n)
CoVai
(n)
Xi
(l)
Vi
(l)
CoVai
(l)
1
 2 595
 2 889
 4 867
1.7
21
481
523
1.1
2
  763
 2 490
 4 704
1.9
8
490
522
1.1
3
 3 302
 2 273
 3 681
1.6
26
289
457
1.6
4
  233
 2 403
 4 143
1.7
1
198         -
 -
5
 1 670
 2 480
 3 885
1.6
15
468
478
1.0
6
 3 099
 2 558
 4 232
1.7
33
518
743
1.4
7
  631
 2 471
 4 493
1.8
12
347
309
0.9
8
 2 428
 2 705
 4 671
1.7
25
316
363
1.1
9
  116
 2 836
 4 724
1.7
0         -
        -
 -
10
 8 246
 2 651
 4 152
1.6
84
386
505
1.3
Total
 23 083
 2 593
 4 255
1.6
225
401
522
1.3
normal claims
large claims
claim amounts
claim amounts
in CHF
in CHF 1 000
Exercise 4.5
Assume that the number of claims and the claim sizes are conditionally in-
dependent given i. Estimate the individual pure risk premium µ (i) by
multiplying the estimates of the claim frequency (Exercise 4.3) and the esti-
mates of the severity (Exercise 4.4). Compare the results with those obtained
in Exercise 4.2.
Exercise 4.6
In motor liability, the risks in a speciﬁc subportfolio are cross-classiﬁed accord-
ing to two tari criteria: use of car (A and B) and type of car (ﬁve dierent
car types numbered 1,. . . , 5).
The following data and summary statistics, which will also be used in later
exercises in connection with other credibility models, are available:
risk class
A1
A2
A3
A4
A5
B1
B2
B3
B4
B5
Total
year
1
 3 767
 9 113
  683  1 288
 4 923
  57  1 234
  84
  352
 3 939
 25 440
2
 3 877
 9 305
  751  1 158
 4 995
  61  1 133
  81
  317
 4 121
 25 799
3
 3 492
 8 322
  619
  920
 3 874
  50
  909
  63
  229
 3 108
 21 586
4
 3 243
 7 743
  514
  742
 3 170
  51
  733
  52
  164
 2 445
 18 857
5
 2 930
 6 963
  389
  583
 2 374
  41
  663
  46
  154
 1 793
 15 936
Total
 17 309  41 446  2 956  4 691  19 336
  260  4 672   326  1 216  15 406  107 618
years at risk

4.15 Exercises
121
risk class
A1
A2
A3
A4
A5
B1
B2
B3
B4
B5
Total
year
1
  507
  599
  207
  419
 1 171
  538
  617   206  3 499
 1 206
  810
2
  465
  631
  172  1 401
 1 384
  293  1 448   332
  859
 1 307
  918
3
  173
  520
  201
  456
  953
  898  1 441   215
  436
 1 719
  740
4
  627
  512
  475  2 339
 1 104  1 216  1 825   590  3 209
 2 035
  976
5
 1 041
  752
  166
  304
 1 004
  306  1 444   278  1 041
 1 898
  970
Total
  543
  600
  238
  958
 1 151
  646  1 286   310  1 884
 1 549
  875
average claims cost per year at risk
claim number and claim amounts, years 1-5
Ni = number of claims, Yi = observed average claim amount, 
Vi = empirical standard deviation of the claim amounts, CoVai =Vi/Yi=coefficient of variation
risk class
A1
A2
A3
A4
A5
B1
B2
B3
B4
B5
Total
all claims
Ni
 1 058
 3 146
  238
  434
 2 481
  35
  825
  32
  180
 2 577  11 006
Yi
 8 885
 7 902
 2 959  10 355
 8 971
 4 801
 7 281
 3 163  12 725
 9 259
 8 554
Vi
 65 747  59 267
 2 959  72 482  52 931
 6 241  47 326
 3 163  75 077  54 631  59 022
CoVai
7.4
7.5
1.0
7.0
5.9
1.3
6.5
1.0
5.9
5.9
6.9
normal claims
Ni
 1 043
 3 106
  238
  429
 2 446
  35
  815
  32
  174
 2 547  10 865
Yi (in CHF)
 3 179
 3 481
 2 959
 4 143
 4 804
 4 801
 3 518
 3 163
 3 786
 5 579
 4 267
Vi (in CHF) 
 3 814
 4 177
 2 959
 4 972
 5 765
 6 241
 4 222
 3 163
 3 786
 6 695
 5 121
CoVai
1.2
1.2
1.0
1.2
1.2
1.3
1.2
1.0
1.0
1.2
1.2
large claims
Ni
15
       
40
       
-
         
5
         
35
       
-
         
10
       
-
         
6
         
30
       
141
     
Yi (in 1000 CHF)
406
     
351
     
-
         
543
     
300
     
-
         
314
     
-
         
272
     
322
     
339
     
Vi (in 1000 CHF) 
365
     
386
     
-
         
435
     
360
     
-
         
314
     
-
         
218
     
386
     
373
     
CoVai
0.9
      
1.1
      
   -
0.8
      
1.2
      
-
1.0
      
-
0.8
      
1.2
      
1.1
      
Assume that each of the risk classes i = A1, A2, . . . , B1, . . . , B5 is character-
ized by its own risk proﬁle i and denote by µ (i) the individual premium
given i, by µF (i) the claim frequency and by µY (i) the average claim
amount.
Assume that the conditions of the Bühlmann—Straub model are fulﬁlled
for the observed average claims cost per year at risk as well as for the claim
frequencies and the average claim amounts.
a) Estimate µ (i) (in absolute and relative terms) based on the statistics of
the observed claims cost per year at risk.
To get an idea about the heterogeneity of the portfolio, give also an esti-
mate of the heterogeneity parameter CoVa(µ(i)).
b) Make the usual assumption that the number of claims and the claim sizes
are conditionally independent. Then
µ (i) = µF (i) · µY (i) .
(4.50)

122
4 The Bühlmann—Straub Model
For estimating µ (i), use (4.50) and determine the credibility estimator
of the claims frequency µF (i) based on the observed claim numbers
(all claims) under Model Assumptions 4.7 and the credibility estimator of
µD (i) based on the observed average claim amounts (all claims) under
Model Assumptions 4.11.
To get an idea about the heterogeneity of the portfolio with respect to the
claim frequency as well as the average claim size, give also an estimate of
the heterogeneity parameters CoVa (µF (i)) and CoVa (µY (i)) .
c) As b) but now separately for normal and large claims. Sum up the results
for normal and large claims to determine the total pure risk premiums.
d) Compare the results and comment.
Exercise 4.7
region # of claims
total
average
claim
claim
amount
amount
1
5'424
24'914'365
4'593
2
160
723'410
4'514
3
885
3'729'472
4'216
4
10'049
43'242'683
4'303
5
2'469
10'739'070
4'350
6
1'175
5'402'705
4'598
7
2'496
12'221'317
4'897
8
7'514
34'956'886
4'652
9
482
2'424'411
5'030
10
2'892
13'570'966
4'693
11
839
4'276'629
5'097
12
3'736
15'787'934
4'226
13
2'832
13'820'842
4'879
14
548
2'521'255
4'603
15
406
1'847'533
4'555
16
6'691
31'168'608
4'658
17
1'187
5'616'656
4'734
18
2'105
9'396'649
4'463
19
1'533
7'193'857
4'693
20
2'769
13'594'889
4'909
21
5'602
28'446'646
5'078
22
283
1'256'937
4'443
23
9'737
49'778'011
5'112
24
2'839
14'722'732
5'187
25
1'409
6'357'640
4'513
25
20'267
93'827'437
4'630
26
6'977
32'464'942
4'653
Total
103'303
484'004'484
4'685
The table gives summary statistics for the average claim amount in motor
hull insurance. We also know that for this line of business the coe!cient of

4.15 Exercises
123
variation of the claim amounts is about 2.0. Estimate the expected value of
the claims’ severity for each region based on this information.
Hint: consider the decomposition of the sum of squares as described at the
end of Section 4.11 and use formula (4.37) for estimating SStot.
Exercise 4.8
For car ﬂeets, a company uses experience rating based on the observed num-
ber of claims. The starting point is a basic premium calculated on the basis
of estimated (a priori) claim frequencies and average claim amounts for the
dierent types of vehicles. The a priori values are taken from suitable claims
statistics (containing the whole motor portfolio, not just ﬂeets). Depending on
the composition of the ﬂeet, one can then calculate for each ﬂeet i the a priori
expected claim number i. It is then assumed that the individual expected
claim number of the ﬂeet i is i · i with E [i] = 1. Estimate for each ﬂeet
i = 1, . . . , 10 the experience factor i based on the statistics given below.
fleet
# of years
at risks
observed
a priori
expected
1
 103
 18
 23
2
 257
 27
 16
3
 25
 2
 4
4
 84
 20
 17
5
 523
 109
 120
6
2 147
 518
 543
7
 72
 11
 10
8
 93
 16
 13
9
 154
 116
 129
10
 391
 156
 118
Total
3 849
 993
 993
# of claims
Exercise 4.9
Show that formula (4.26),
bb
2 = c ·
(
I
I  1
I
X
i=1
wi•
w••
¡
Xi  X
¢2  Ic
2
w••
)
,
where
c = I  1
I
( I
X
i=1
wi•
w••
µ
1  wi•
w••
¶)1
,

124
4 The Bühlmann—Straub Model
is an unbiased estimator for  2.
Exercise 4.10
In the general liability line we assume that the claims exceeding 200 000 CHF
are Pareto distributed. In order to calculate the premiums for dierent upper
limits of the insurance cover, we want to estimate the Pareto parameter for
each of the six risk groups based on the data given below and assuming that
Model Assumptions 4.16 are fulﬁlled.
group
1
2
3
4
5
6
214 266
201 015
208 415
201 232
201 991
210 000
215 877
215 670
208 791
260 000
290 190
210 150
220 377
221 316
210 232
272 856
339 656
225 041
230 501
241 750
213 618
395 807
349 910
226 312
241 872
249 730
216 678
736 065
385 545
253 700
245 992
258 311
227 952
776 355
443 095
280 000
260 000
260 000
237 824
890 728
480 712
315 055
260 000
265 696
240 500
1 005 186
714 988
335 000
263 214
268 880
247 000
800 000
340 000
263 497
273 000
255 879
1 280 928
354 929
278 934
296 245
279 284
1 361 490
382 500
290 000
299 000
279 376
2 112 000
450 000
290 452
363 744
300 398
500 000
292 500
382 581
319 141
500 000
301 636
400 000
321 628
500 000
312 920
400 000
400 465
500 000
319 757
477 581
401 461
700 000
340 733
640 131
404 027
729 000
384 489
656 086
405 576
810 000
392 437
800 000
472 138
900 000
397 649
1014 262
632 161
900 000
400 000
1046 388
671 758
1 500 000
400 000
1 231 272
2 000 000
400 000
1 303 129
3 000 000
400 000
1 500 929
400 000
2 400 644
415 178
2 485 646
433 144
451 256
464 000
478 146
640 000
720 000
880 000
# of claims
 34
 22
 27
 8
 12
 24
Table: observed claim sizes above 200 000 CHF of a liability portfolio

5
Treatment of Large Claims in Credibility
5.1 Motivation
In applying the Bühlmann—Straub model to calculate risk premiums in col-
lective health insurance, practitioners noticed the following points:
•
Because of the possible occurrence of large claims, the credibility weights
are rather small for small and medium-sized insurance contracts.
•
Despite the small credibility weights, a single large claim during the obser-
vation period can cause a considerable jump in the credibility premium.
This is perceived by the insured as unfair, and is indeed questionable, since
occasionally large claims are usually not very informative about the true
risk proﬁle.
•
Due to the small credibility weights, credibility premiums vary little from
one insurance contract to another if there are no large claims during the
observation period.
The reason for these di!culties results from a high within risk variance com-
ponent 2. Indeed, the potential occurrence of big claims contributes heavily
to 2 due to the chosen quadratic loss function.
In order to avoid the di!culties mentioned, we look for transformations of
the data. The credibility estimator is then applied to the transformed data.
One approach is to truncate either the aggregate or the individual claims.
This is the topic of the next two sections. In a further section, we will indicate
other ways of dealing with large claims, but without going into details.
5.2 Semi-Linear Credibility with Truncation in the
Simple Bühlmann Model
We again consider the simple Bühlmann model without volume measures (see
Model Assumptions 3.6 or 4.11 for claim sizes). This could for instance mean

126
5 Treatment of Large Claims in Credibility
that we consider aggregate claims in situations where the risks considered
have all the same volume, or that we want to estimate the expected value of
the claim size and that we consider the individual claim sizes. In the latter
case, the number of observations ni varies between risks.
The basic idea then is not to consider the original data Xij, but rather ﬁrst
to transform this data (e.g. by truncation). De Vylder [DV76b] was the ﬁrst
to have this idea, and he named this credibility estimation technique based
on transformed data semi-linear credibility.
We consider then the transformed random variables Yij = f (Xij), where f
is some arbitrary transformation. However, as before, our goal is to estimate
the individual premium
P ind = µX (i) = E [Xij| i]
for the random variables Xij.
Deﬁnition 5.1. The semi-linear credibility estimator of µX (i) based on the
transformed data Yij = f (Xij) is the best estimator of the form
\
µX (i) =
a0 + P
ij aijYij. In order to indicate the dependence of the estimator on the
transformation f, we use the notation bbµ
(f)
X (i).
Remark:
•
The random variables Yij also satisfy the conditions of the simple Bühlmann
model. The formula for the credibility estimator for µY (i) := E [Yij |i ]
is therefore given by Theorem 3.7. However, we want to estimate µX (i)
(and not µY (i)) from the observations Yij.
Theorem 5.2. The semi-linear credibility estimator of µX (i) in the simple
Bühlmann model, based on the transformed data Yij = f (Xij), is given by
bbµ
(f)
X (i) = µX +  XY
 2
Y
(i)
Y (Yi  µY )
= µX +  X
 Y
XY (i)
Y (Yi  µY ) ,
(5.1)
where
µX = E [µX (i)] ,
µY = E [µY (i)] ,
 2
Y = Var [µY (i)] ,
 2
X = Var [µX (i)] ,
 XY = Cov(µX (i) , µY (i)),
XY = Corr(µX (i) , µY (i)) =  XY
 X Y
,
2
Y = E [Var [Yij| i]] ,
(i)
Y =
ni
ni + Y
, where Y = 2
Y
 2
Y
,
Yi = 1
ni
Xni
j=1 Yij.

5.2 Semi-Linear Credibility with Truncation in the Simple Bühlmann Model
127
Proof: As in the Bühlmann—Straub model, the credibility estimator
bbµ
(f)
X (i) = Pro (µX (i)| L (1, Y1, . . . , YI))
does not depend on the data from other risks, i.e.
bbµ
(f)
X (i) = Pro (µX (i)| L (1, Yi)) .
(5.2)
We write (5.2) in a slightly more complicated way:
bbµ
(f)
X (i) = Pro(Pro(µX (i)| L (1, Yi, µY (i)) | L (1, Yi)) .
(5.3)
The inner projection µ0
X (i) := Pro (µX (i)| L (1, Yi, µY (i)) must satisfy
the normal equations (Corollary 3.17), i.e.
E [µ0
X (i)] = E [µX (i)] = µX,
(5.4)
Cov (µX (i) ,Yij) = Cov (µ0
X (i) , Yij) ,
(5.5)
Cov (µX (i) ,µY (i)) = Cov (µ0
X (i) , µY (i)) .
(5.6)
It is intuitively clear, that the inner projection µ0
X (i) does not depend on
the variables Yij, since the Yij merely contain information on µY (i) and
since µY (i) is already included as an explanatory variable. Indeed, if
µ0
X (i) = a0
0 + a0
1 µY (i)
satisﬁes(5.6), then (5.5) is automatically satisﬁed, since E [µX (i) · Yij] =
E [E {µX (i) · Yij| i}] = E [µX (i) · µY (i)]. This implies that µ0
X (i)
does not depend on the observations Yij, but only on µY (i) . This is easy
to understand, since the Yij merely contain information on the µY (i), and
µY (i) is already included as an explanatory variable in µ0
X (i). Thus, we
have
µ0
X (i) = a0
0 + a0
1 µY (i) .
From (5.6) and (5.4) it follows that
Cov (µX (i) ,µY (i)) = a0
1 Var [µY (i)] ,
µ0
X (i) = µX + Cov (µX (i) ,µY (i))
Var [µY (i)]
(µY (i)  µY ) .
Using the iterative procedure (5.3) and denoting by
\
\
µY (i) the credibility
estimator for µY (i) based on the simple Bühlmann model (Model Assump-
tions 3.6), we obtain

128
5 Treatment of Large Claims in Credibility
bbµ
(f)
X (i) = µX + Cov (µX (i) , µY (i))
Var [µY (i)]
µ \
\
µY (i)  µY
¶
= µX +  XY
 2
Y
(i)
Y (Yi  µY ) ,
which ends the proof of Theorem 5.2.
¤
The quadratic loss is also easy to calculate and has a similar form to that
of formula (4.11).
Theorem 5.3. The quadratic loss of the semi-linear credibility estimator is
given by
E
"µ
bbµ
(f)
X (i)  µX (i)
¶2#
=  2
X
³
1  2
XY (i)
Y
´
,
(5.7)
where XY = Corr (µX (i) ,µY (i)) .
Proof:
E
"µ
bbµ
(f)
X (i)  µX (i)
¶2#
= E
h
(µX (i)  µ0
X (i))2i
+ E
"µ
µ0
X (i)  bbµ
(f)
X (i)
¶2#
=
Ã
 2
X  2  XY
 2
Y
 XY +  2
XY
( 2
Y )2  2
Y
!
+  2
XY
( 2
Y )2  2
Y (1  (i)
Y )
=  2
X   2
XY
 2
Y
(i)
Y .
This proves Theorem 5.3.
¤
An obvious idea when dealing with the problem of large claims is to trun-
cate the claims at some suitable chosen truncation point m (see [Gis80]), i.e.
to choose the function
f (X) = min (X, m)
as the transformation. The semi-linear credibility estimator with truncation
depends on the selected point of truncation and is given by
bbµ
(m)
X
(i) = µX +  X
 Y
XY (i)
Y (Yi  µY ) .
In this formula, the observed average Yi of the truncated claims appears. No-
tice that the excess part of the claim amount above the truncated point is

5.2 Semi-Linear Credibility with Truncation in the Simple Bühlmann Model
129
taken into account by the semilinear credibility premium, since the start-
ing point is given by µX, the mean over the whole collective of the ex-
pected claim amount before truncation. Only the “experience correction”
( X/ Y ) XY (i)
Y (Yi  µY ) is based, not on the original data, but rather on
the truncated data. Notice also that the weight ( X/ Y ) XY (i)
Y
associated
with the observed deviation of the observed truncated claim amount from the
expected truncated claim amount (the term (Yi  µY )) can in principle be
greater than 1, because of the term ( X/ Y ) XY .
When using credibility with truncation, we must decide how to choose
the truncation point. The optimal truncation point m is that which mini-
mizes the quadratic loss, respectively maximizes R(m) = 2
XY (i)
Y . This op-
timal truncation point may be at inﬁnity, which means that no truncation
is needed. How to calculate the theoretically optimal truncation point can
be found in Gisler [Gis80]. However, in practice the choice of the truncation
point is often based on some priori knowledge of the claim distribution and
is not calculated theoretically. This is justiﬁable because the quadratic loss
as a function of the truncation point is relatively ﬂat over a large range, and
therefore one doesn’t lose much if the truncation point is not fully optimal
(as an example see Exercise 5.1).
As in the Bühlmann—Straub model, the semi-linear credibility estimator
also depends on structural parameters, in this case on µX, µY ,  XY ,  2
Y , 2
Y .
These can again be estimated on the basis of data from the collective. Below
we list the estimators analogous to the Bühlmann—Straub model.
We introduce the following quantities:
SX =
1
n•  I
X
i
X
j
(Xij  Xi)2,
where n• =
X
i
ni,
SXY =
1
n•  I
X
i
X
j
(Xij  Xi)(Yij  Yi),
SY =
1
n•  I
X
i
X
j
(Yij  Yi)2,
TX =
I
I  1
X
i
ni
n•
(Xi  X)2,
TXY =
I
I  1
X
i
ni
n•
(Xi  X)(Yi  Y ),
TY =
I
I  1
X
i
ni
n•
(Yi  Y )2,
c = I  1
I
(X
i
ni
n•
µ
1  ni
n•
¶)1
.

130
5 Treatment of Large Claims in Credibility
The following parameter estimators are analogous to the parameter estimators
in the Bühlmann—Straub model:
c
2
Y = SY ,
c
2
X = SX,
c
 2
Y = max
Ã
c ·
Ã
TY  I · c
2
Y
n•
!
, 0
!
,
c
 2
X = max
Ã
c ·
Ã
TX  I · c
2
X
n•
!
, 0
!
,
d
 XY = signum
µ
TXY  I · SXY
n•
¶
·
s
min
½
c 2 · (TXY  I · SXY
n•
)2,
³c
 2
Y · c
 2
X
´¾
,
c
µX =
³X
i (i)
X Xi
´ ³X
i (i)
X
´1
,
c
µY =
³X
i (i)
Y Yi
´ ³X
i (i)
Y
´1
.
5.3 Semi-Linear Credibility with Truncation in a Model
with Weights
We turn next to the question of whether the techniques which were discussed
in Section 5.2 can be carried over to the Bühlmann—Straub model with ar-
bitrary volume measures. The answer is no, and the reason for this is that
the transformed random variables Zij = min (Xij, m), where Xij is the ratio
of the aggregate claim amount and the corresponding volume, do not satisfy
the assumptions of the Bühlmann—Straub model. For example, the quantity
E [Zij| i] depends on the weight wij. In most cases, the bigger wij, the big-
ger is E [Zij| i] (since the expected value of the part which has been cut o
decreases with increasing volume).
It would, however, be useful in many cases in insurance practice, if the idea
of the truncation of single claims could also be carried over to models with
volume measures. Group accident insurance, or group health insurance are
two such cases. In both cases, the policy holder is a ﬁrm, and all employees of
that ﬁrm are covered by the insurance contract. The insurance provides bene-
ﬁts if any one of these employees has an accident or becomes sick. The volume
or weight wij is then typically the size of the payroll of the ith ﬁrm in year j.
Without truncation, we can consider the conditions for the Bühlmann—Straub
model as being satisﬁed. In order to be able to apply credibility with trunca-
tion, however, we need an extended model with somewhat more structure.
Let

5.3 Semi-Linear Credibility with Truncation in a Model with Weights
131
Sij =
Nij
P
 =1
Y ()
ij
where Sij = aggregate claim amount, Nij = number
of claims, Y ()
ij
= individual claim sizes,
wij
weights (e.g. amount of payroll),
Xij = Sij/wij
claims ratios.
Model Assumptions 5.4 (volume-dependent model with truncation)
The ith risk is characterized by its individual risk proﬁle &i, which is itself the
realization of a random variable i, and it holds that:
Gi1: Conditionally, given i, the random variables
Nij, Y ()
ij
(j = 1, 2, . . . , n;  = 1, 2, . . .) are independent,
(5.8)
Nij  Poisson (wij  (i)) ,
(5.9)
Y ()
ij
(j = 1, 2, . . . , n ;  = 1, 2, . . .) are independent
(5.10)
and identically distributed with distribution Fi(y).
Gi2: The pairs (1, X1), (2, X2) , . . . are independent, and 1, 2, . . . are
independent and identically distributed.
Under the above model assumptions we have:
E [Xij| i] =  (i) E
h
Y ()
ij
¯¯¯ i
i
=: µX (i) ,
(5.11)
Var [Xij| i] =
1
wij
 (i) E
h
Y ()2
ij
¯¯¯ i
i
=:
1
wij
2
X (i) ,
(5.12)
i.e. the claims ratios Xij satisfy the model assumptions of the Bühlmann—
Straub model (Model Assumptions 4.1).
Remarks:
•
It is only assumed that the number of claims and the claim sizes are
conditionally independent given i. However,  (i) and µX (i) and/or
µY (i) may be correlated.
•
All the results of this section also hold, when the Poisson assumption for
the number of claims is replaced by the following weaker assumption:
E [Nij| i] = wij  (i) ,
Var [Nij| i] b wij  (i) .
This weaker assumption is satisﬁed, in particular, if the claim numbers are
Negative Binomial distributed, under the additional assumption that the
quotient of the expected value and the variance does not depend on i.
We use the notation

132
5 Treatment of Large Claims in Credibility
G()
ij = min
³
Y ()
ij , m
´
the claim sizes truncated at m,
Tij = PNij
=1 G()
ij
aggregate claim amounts after truncation of the
individual claims,
Zij = Tij/wij
claims ratios after truncation of the individual
claim sizes.
Clearly G()
ij , Tij and Zij depend on the selected truncation point m, and
are therefore also functions of this truncation point. However, in order to
keep the notation simple, we do not explicitly indicate this dependence.
The ﬁrst two conditional moments of the claims ratios Zij after truncation
are given by
E [Zij| i] =: µZ (i) =  (i) · E
h
G()
ij
¯¯¯ i
i
,
(5.13)
Var [Zij| i] =: 2
Z (i)
wij
,
(5.14)
where 2
Z (i) :=  (i) E
h
G()2
ij
¯¯¯ i
i
.
(5.15)
The claims ratios Zij also satisfy (just as the original claims ratios Xij) the
model assumptions of the Bühlmann—Straub model. In the following only the
structure given by (5.13)—(5.15) is relevant.
The structural parameters in this model are:
original data
transformed data
µX = E [µX (i)],
µZ = E [µZ (i)],
2
X = E
£
2
X (i)
¤
,
2
Z = E
£
2
Z (i)
¤
,
 2
X = Var [µX (i)] ,
 2
Z = Var [µZ (i)] ,
 XZ = Cov (µX (i) , µZ (i)).
By the semi-linear credibility estimator of µX (i) with truncation we mean
the credibility estimator of µX (i) based on the statistics {Z1, Z2, . . . , ZI},
which corresponds exactly to the content of the following deﬁnition.
Deﬁnition 5.5. The semi-linear credibility estimator of µX (i) with trun-
cation of the individual claims at the point m is the best estimator of the
form
\
µX (i) = a0 + P
ij aijZij. In order to indicate its dependence on the
truncation point m, we use the notation bbµ
(m)
X
(i).
With exactly the same proof as in Theorem 5.2 we get the following result.
Theorem 5.6. Under Model Assumptions 5.4, the semi-linear credibility es-
timator with truncation of the individual claims at the point m is given by:
bbµ
(m)
X
(i) = µX +  X
 Z
XZ(i)
Z (Zi  µZ) ,
(5.16)

5.3 Semi-Linear Credibility with Truncation in a Model with Weights
133
where (i)
Z =
wi•
wi• + 2
Z
 2
Z
,
XZ = Corr (µX (i) , µZ (i)) ,
Zi =
X
j
wij
wi•
Zij.
Remarks:
•
To apply formula (5.16) one does not need to know all individual claim
sizes. It is su!cient to know, for each contract i, the total aggregate claim
amount plus the individual claim sizes of the few claims exceeding the
truncation point.
•
The above result also holds when, instead of truncation, any other trans-
formation of the individual claim amounts is used. The random variables
Zij are then simply otherwise deﬁned.
•
Notice the dierent kind of truncation used in each of the models:
—
truncation of the original X-variable in the model without volumes,
—
truncation of the individual claim amounts and construction of a claims
ratio from the truncated data in the model with volumes.
With the same proof as in Theorem 5.3 we get the following result for the
quadratic loss.
Theorem 5.7. The quadratic loss is given by
E
"µ
bbµ
(m)
X
(i)  µX (i)
¶2#
=  2
X
³
1  2
XZ(i)
Z
´
.
(5.17)
The truncation point m is a “parameter”, the value of which we can
freely choose. The optimal truncation point is again that which minimizes the
quadratic loss, respectively maximizes the function R (m) = ( X/ Z) 2
XZ(i)
Z .
Remarks:
•
One can show that in the special case where only the number of claims
but not the claim sizes Y ( )
ij
depend on the risk proﬁle i, the optimal
truncation point m is such that all truncated claim sizes become equal.
The resulting semi-linear credibility formula is then given by
bbµ
(m)
X
(i) = µY · \
\
µF (i),
where
\
\
µF (i) is the credibility estimator for the claim frequency based
on the statistic of the number of claims.

134
5 Treatment of Large Claims in Credibility
•
In general, the optimal truncation point depends on the volumes wi•. As
a rule, the bigger these volumes are, the greater is the optimal truncation
point. In insurance practice it is usually enough to form a few volume
categories and to choose the truncation points for these categories sensibly,
e.g. based on the estimated function R (m).
The following estimators for the structural parameters are quite analogous
to the ones given on page 130, but now with volume measures and with the
same number n of observation years for all risks. We introduce the following
quantities:
SX = 1
I
X
i
1
n  1
X
j
wij (Xij  Xi)2,
where Xi =
X
j
wij
wi•
Xij,
SXZ = 1
I
X
i
1
n  1
X
j
wij (Xij  Xi)(Zij  Zi),
SZ = 1
I
X
i
1
n  1
X
j
wij (Zij  Zi)2,
TX =
I
I  1
X
i
wi•
w••
(Xi  X)2,
where X =
X
i
wi•
w••
Xi,
TXZ =
I
I  1
X
i
wi•
w••
(Xi  X)(Zi  Z),
TZ =
I
I  1
X
i
wi•
w••
(Zi  Z)2,
c = I  1
I
( I
X
i=1
wi•
w••
µ
1  wi•
w••
¶)1
.
As in Section 5.2 we can deﬁne the following estimators for the structural
parameters.
c
2
Z = SZ,
c
2
X = SX,
c
 2
Z = max
Ã
c ·
Ã
TZ  I · c
2
Z
w••
!
, 0
!
,
c
 2
X = max
Ã
c ·
Ã
TX  I · c
2
X
w••
!
, 0
!
,
d
 XZ = signum
µ
TXZ  I · SXZ
w••
¶
·
v
u
u
tmin
(
c2 ·
µ
TXZ  I · SXZ
w••
¶2
,
³c
 2
Z · c
 2
X
´1/2
)
,

5.4 Further Methods for Treating Large Claims
135
c
µX =
³X
i (i)
X Xi
´
/
³X
i (i)
X
´
,
c
µZ =
³X
i (i)
Z Zi
´
/
³X
i (i)
Z
´
.
5.4 Further Methods for Treating Large Claims
In this section we want to mention other methods for the treatment of large
claims within the credibility framework. It is beyond the scope of this book to
treat these approaches in detail and so we will merely sketch the basic ideas
here and point to the corresponding literature (or later chapters in this book).
As discussed in the previous sections, in semi-linear credibility, the original
data is ﬁrst transformed, and because we were treating the problem of large
claims, we considered truncation transformations. The truncated part of the
claim is implicitly included by the semi-linear credibility formula in the term
µX. But the “experience correction” at the level of the individual contract, re-
spectively the dependence of the credibility premium on the individual claim
experience, is only calculated from the claims experience after truncation,
hence the part of the claims experience which has been cut o, the observed
“excess claim amount”, has no inﬂuence on the credibility premium. Another
possibility that suggests itself, is not to completely discard the observed “ex-
cess” or “large claim amounts”, and to take account of both the large claims
as well as the normal claims, in parallel. This is a special application of multi-
dimensional credibility, and will later be discussed in greater detail in Chapter
7.
By deﬁnition, credibility theory is limited to linear estimators. This has the
big advantage that the credibility premiums have a simple form and depend
only on the ﬁrst two moments of the data, which can be easily estimated.
However, this linearity can also have disadvantages, as we already saw in our
treatment of large claims. Since credibility theory leaves open which random
variables are considered (with respect to which the estimator must be linear),
we can use this freedom to our advantage. In the previous sections the ap-
proach consisted of truncating the original data. In Section 4.14 the random
variables under consideration were maximum-likelihood estimators.
It was in considering the treatment of large claims that Künsch [Kün92]
ﬁrst had the idea of applying credibility to robust estimators. The basic idea
is to replace the observed individual mean by a robust estimator (robust in
the sense of classical robust statistics) and then to use credibility estimators
based on the statistics of the robust means. This idea was further developed by
Gisler and Reinhard [GR93]. An advantage of this approach is that it can be
applied directly to claims ratios. For example, this might be a useful approach
for ﬁre insurance.
A further approach to the treatment of large claims is given by “robust
Bayesian statistics”. This has been propagated in the actuarial literature by

136
5 Treatment of Large Claims in Credibility
Schnieper [Sch04] in connection with large claims. Although the name is very
similar to “robust credibility”, the two concepts have little in common. Robust
Bayesian statistics has nothing to do with classical robust statistics. It belongs
to the framework of Bayesian statistics. Robust indicates merely that the
conditional distributions and their associated a priori distributions are chosen
in such a way that the resulting Bayes estimator is automatically robust. As a
consequence the treatment of outliers is driven by the observations themselves.
The disadvantage is that the distributions and the estimators (in contrast to
the credibility approach) need to be determined numerically and do not have
a simple form.
5.5 Exercises
Exercise 5.1
trunc.point
m
VZ
2
WZ
2
NZ=Vz
2/WZ
2 WX/WZ
WXZ
UXZ
PZ
f
15 531
0.0895
173 531
1.0
0.0895 100.0%
1.000
 100 000
14 465
0.0891
162 346
1.0
0.0888
99.4%
0.994
 95 000
14 339
0.0894
160 391
1.0
0.0889
99.4%
0.992
 90 000
14 171
0.0896
158 158
1.0
0.0889
99.3%
0.991
 85 000
13 995
0.0900
155 500
1.0
0.0890
99.2%
0.989
 80 000
13 828
0.0904
152 965
1.0
0.0891
99.1%
0.988
 75 000
13 672
0.0908
150 573
1.0
0.0892
98.9%
0.987
 70 000
13 489
0.0912
147 906
1.0
0.0893
98.8%
0.985
 65 000
13 222
0.0914
144 661
1.0
0.0893
98.7%
0.983
 60 000
12 834
0.0908
141 344
1.0
0.0889
98.6%
0.977
 55 000
12 370
0.0904
136 836
1.0
0.0886
98.5%
0.972
 50 000
11 758
0.0893
131 669
1.0
0.0880
98.4%
0.964
 45 000
10 917
0.0879
124 198
1.0
0.0872
98.3%
0.954
 40 000
9 944
0.0854
116 440
1.0
0.0858
98.1%
0.939
 35 000
8 970
0.0823
108 991
1.0
0.0838
97.6%
0.921
 30 000
7 993
0.0761
105 033
1.1
0.0808
97.9%
0.900
 25 000
7 047
0.0708
99 534
1.1
0.0778
97.7%
0.876
 20 000
6 089
0.0645
94 403
1.2
0.0734
96.6%
0.848
 15 000
5 002
0.0589
84 924
1.2
0.0690
95.0%
0.810
 10 000
3 874
0.0523
74 073
1.3
0.0625
91.4%
0.755
 5 000
2 570
0.0429
59 907
1.4
0.0525
84.7%
0.657
estimates of 
Consider the group health insurance for daily allowances. In this line of busi-
ness, the policy holders are ﬁrms which buy insurance for workmen compensa-
tion in case of sickness. We consider the portfolio of policies with the following
coverage: if an employee can’t go to work because of sickness, the insurance

5.5 Exercises
137
company pays, after a waiting period of three days, 80% of the salary for the
duration of the sickness up to a maximum of two years. The basic tari pre-
mium is calculated by a premium rate times the total salary of all employees
in the company.
The claims experience varies substantially between ﬁrms, which is not sur-
prising, since individual hidden factors like working climate and control of
absences have a considerable inﬂuence on the claims load. For that reason an
insurance company introduces an experience rating scheme based on the model
introduced in Section 5.3, Model Assumptions 5.4. The pure risk premiums
of the basic tari denoted by Pi are taken as weights. At every renewal of a
contract, the observed claims experience over the last three years is taken into
account by a correction factor applied to the basic premium rate. We assume
that the basic premium rate is at the right level, i.e. that E [Xi] = µX = 1. The
goal is to estimate the correction factor µX (i) by applying the semilinear
credibility formula with truncation of the individual claims.
The structural parameters were estimated from the observations of the
whole portfolio. The table below shows the estimated values bµZ, b2
Z, b 2
Z,
bZ = b2
Z/b 2
Z, bXZ = b XZ/(b X ·b Z) in dependence of the truncation point m.
a) To get an idea where to choose the truncation point depending on the size
of the contract, display the function bR (m) = b2
XZ · b(i)
Z (see formula (5.17)
on page 133) for contracts with P = 60 000, 300 000, 500 000 and where
P denotes the pure risk premium obtained with the basic tari over the
observation period of three years.
b) The company chooses the following truncation points m:
m = 15 000 if 20 000  P < 100 000,
m = 30 000 if 100 000  P < 1 000 000,
m = 4
if P  1 000 000.
policy 1: P = 20 000,
S = 0
policy 2: P = 20 000,
S = 36 000,
whereof no claim > 15 000.
policy 3: P = 20 000,
S = 36 000,
whereof one claim > 15 000: 32 000.
policy 4: P = 300 000,
S = 300 000,
whereof no claim > 30 000.
policy 5: P = 300 000,
S = 360 000,
whereof two claims > 30 000: 38 000, 162 000.
Calculate the resulting experience correction factors for the above con-

138
5 Treatment of Large Claims in Credibility
tracts, where P is deﬁned as above and where S denotes the total aggre-
gate claim amount over the last three years:
Exercise 5.2
# of 
Correlation
region
claims
Xi
VX
(i)
CoVaX
(i)
Yi
VY
(i)
CoVaY
(i) Corr(X,Y)(i)
1
1 785 11 224
83 141
7.4
4 760 7 760
1.6
54.7%
2
 37
6 348
16 893
2.7
4 887 8 420
1.7
97.5%
3
 280 21 273 175 132
8.2
4 932 8 351
1.7
55.3%
4
3 880 11 754
91 977
7.8
4 631 8 008
1.7
52.6%
5
 846
6 559
30 280
4.6
4 275 7 285
1.7
71.5%
6
 464 10 045
71 253
7.1
5 071 8 521
1.7
48.8%
7
 136
5 968
24 890
4.2
4 174 6 945
1.7
75.8%
8
 853
5 407
24 070
4.5
3 974 6 155
1.5
70.2%
9
2 151
5 483
21 465
3.9
4 135 6 470
1.6
74.7%
10
 155
5 133
16 294
3.2
4 139 6 746
1.6
83.1%
11
 653
6 815
30 508
4.5
4 504 7 693
1.7
70.1%
12
 252 13 161
74 342
5.6
4 877 8 494
1.7
70.9%
13
1 228
8 670
47 897
5.5
4 849 7 827
1.6
62.4%
14
 865
6 780
32 290
4.8
4 482 7 326
1.6
67.0%
15
 145
6 273
18 310
2.9
4 949 7 958
1.6
84.7%
16
 127
6 694
33 779
5.0
4 070 7 144
1.8
71.5%
17
2 151
8 757
46 631
5.3
4 624 7 573
1.6
69.4%
18
 449
6 535
27 296
4.2
4 514 7 013
1.6
73.8%
19
 784
7 068
51 113
7.2
4 191 6 954
1.7
50.7%
20
 438 15 453 126 781
8.2
5 243 8 447
1.6
49.4%
21
1 011
9 010
41 405
4.6
5 224 8 722
1.7
68.0%
22
1 692
7 666
48 000
6.3
4 671 7 443
1.6
53.5%
23
 82
8 856
51 853
5.9
3 710 5 900
1.6
90.2%
24
2 813
5 967
62 570
10.5
4 094 6 001
1.5
32.5%
25
 729
9 213
77 005
8.4
4 523 7 520
1.7
46.7%
26
 329
6 727
20 080
3.0
5 157 8 444
1.6
83.7%
27
5 743
8 279
49 575
6.0
4 686 7 231
1.5
60.0%
28
3 002
8 149
57 186
7.0
4 491 7 370
1.6
52.4%
Total
33 080
8 486
61 189
7.2
4 555 7 389
1.6
original claims data
trunc. claims data
Table: average claim amounts of a motor liability portfolio
The table above shows, for a motor liability portfolio and for dierent regions,
the number ni of claims, the average claim amount Xi, the empirical standard
deviations (i)
X and the empirical coe!cients of variation CoVa(i)
X = (i)
X /Xi
and analogously Yi, (i)
Y , CoVa(i)
Y
for the truncated claim amounts (trun-
cation at 50 000). In addition the empirical correlations Corr(X, Y )(i) be-

5.5 Exercises
139
tween the original claim amounts Xi and the truncated claim amounts Yi
( = 1, 2,..., ni) are given. The aim is to estimate for each region its individual
expected value of the claim size µ (i) = E [Xi| i].
a) Estimate µ (i) by applying the Bühlmann—Straub model based on the
original data Xi (see Section 4.11).
b) Estimate µ (i) using the credibility model with truncation at 50 000 (see
Section 5.2) based on the Yi.
Exercise 5.3
The table below shows for 10 risk groups the number of claims ni, the average
claim amounts Xi and the coe!cients of variation CoVai of the claim amounts.
The actuary knows from other sources that a lognormal distribution ﬁts
fairly well as a claim size distribution in this line of business. Therefore, he
also considers besides the original claim sizes the logarithms Yi = ln(Xi). In
the table below, the same summary statistics are given for the original claim
sizes and for the logarithms Yi.
risk
# of
group
claims
i
ni
Xi
CoVaX
(i)
Yi
CoVaY
(i)
1
 92
3 478
7 079
6.47
0.31
2
 542
5 204
17 179
6.78
0.28
3
 57
2 092
3 340
6.45
0.29
4
 317
4 437
13 419
6.73
0.28
5
 902
4 676
20 391
6.59
0.29
6
 137
6 469
19 147
6.60
0.35
7
 48
12 285
50 875
7.30
0.27
8
 528
3 717
12 349
6.40
0.31
9
 183
14 062
87 300
7.25
0.28
10
 365
9 799 136 098
6.33
0.31
Total
3 171
5 825
53 294
6.62
0.30
claim amounts
original data
logarithms
a) Estimate µ (i) by applying the Bühlmann—Straub model based on the
original data Xi.
b) Make use of the a priori knowledge that a lognormal distribution ﬁts well
as a claim size distribution in this line of business.
Denote by µY (i) and by 2
Y (i) the parameters of the lognormal distri-
bution given i. We further assume that 2
Y (i) = 2
Y for all i, which is
equivalent to the assumption that the coe!cient of variation of the origi-
nal claim sizes Xi,  = 1, 2, . . . is the same for all risk groups i. Estimate

140
5 Treatment of Large Claims in Credibility
µY (i) and 2
Y with the technique described in Section 4.11. Then es-
timate the expected value of the original claim size µ (i) by taking the
ﬁrst moment of the Lognormal distribution, i.e. use the estimator
\
µ (i) = exp
Ã
\
µZ (i) + b2
Z
2
!
.
c) Make a table showing the observed average claim sizes and the estimates
of the expected values obtained with the two methods. Make also a table
with the relative values (ratio of \
µ (i) divided by the resulting average
over the whole portfolio).
Exercise 5.4
The table below shows, for each risk group i, the number of claims ni, the
average claim size Xi and the coe!cient of variation CoVai of the individual
claim sizes. These ﬁgures are given for the category of all claims as well as for
normal claims (pure physical damage) and large claims (bodily injury claims).
The data are the same as those considered in Exercise 4.4. The aim is again
to estimate for each risk group i the expected value µ (i) = E [Xi| i] of the
claim size.
risk
group
ni
Xi
CoVai
ni
(n)
Xi
(n)
CoVai
(n)
ni
(l)
Xi
(l)
CoVai
(l)
in 1'000
1
2 616
6 727
9.5
2 595
2 889
1.7
21
481
1.09
2
 771
7 548
9.5
 763
2 490
1.9
8
490
1.06
3
3 328
4 513
10.5
3 302
2 273
1.6
26
289
1.58
4
 234
3 239
4.2
 233
2 403
1.7
1
198
0.00
5
1 685
6 624
9.5
1 670
2 480
1.6
15
468
1.02
6
3 132
7 989
11.6
3 099
2 558
1.7
33
518
1.43
7
 643
8 901
7.6
 631
2 471
1.8
12
347
0.89
8
2 453
5 898
8.3
2 428
2 705
1.7
25
316
1.15
9
 116
2 836
1.7
 116
2 836
1.7
0
0
0.00
10
8 330
6 517
9.9
8 246
2 651
1.6
84
386
1.31
Total 23 308
6 443
10.1 23 083
2 593
1.6
225
401
1.30
all claims
normal claims
large claims
a) Estimate µ (i) by applying the Bühlmann—Straub model to the observed
average claim amounts of the category of all claims.
b) Another idea for estimating µ (i) is to estimate the expected value of the
claim severities of the normal and large claims
¡
µ(n) (i) and µ(l) (i)
¢
and the percentage of the large claims.
For estimating µ(n) (i) and µ(l)(i), proceed as in a).

5.5 Exercises
141
For estimating the percentage of large claims for each risk group i, denote
by i the probability that a claim is a large claim (bodily injury). Then
the number of large claims N (l)
i
is conditionally, given i and ni, binomial
distributed with parameter nii. Approximate the Binomial distribution with
the Poisson distribution with parameter i = nii and estimate i with the
technique and the model of Section 4.10.
Finally estimate µ (i) by
\
µ (i) =
³
1  bi
´
\
µ(n) (i) + bi
\
µ(l) (i).

6
Hierarchical Credibility
6.1 Motivation
In practice, we often encounter hierarchical structures, both in statistical data
analysis and in the calculation of premiums.
Insurance data frequently have a hierarchical structure. The individual
risks are classiﬁed according to their “tari positions”, tari positions are
grouped together into “subgroups”, subgroups into “groups”, groups into
“main groups”, which together make the total of a line of business. In the
statistical interpretation, this structure will be constructed in reverse order.
One is ﬁrst interested in the development of a line of business as a whole, then
in the development of the main groups, and so on.
Not infrequently, a hierarchical procedure is also used in the calculation of
premiums, whereby the reasoning follows a hierarchical tree. By this is meant
a “top down” procedure, in that ﬁrst the expected aggregate claim amount for
the whole line of business is ascertained and then this amount is successively
“distributed” over the lower levels. Consider the following two examples:
•
Example 1: Group accident insurance in Switzerland, premium for acci-
dents at work (Figure 6.1).
In Switzerland, each ﬁrm has to buy a workers’ compensation insurance.
The premium calculation scheme used by the private insurers is basically
as follows: the individual ﬁrms are grouped together according to their
type of business (e.g. banks, hospitals), and these types of business are
grouped into danger classes (groups of types of business). The premium
calculation is carried out by ﬁrst ﬁxing the “tari level” for the various
danger classes, then within the danger classes for the types of business.

144
6 Hierarchical Credibility
group accident insurance
danger classes
data
types of business
Fig. 6.1.
•
Example 2: Industrial ﬁre insurance in Germany (Figure 6.2).
For a long time, the premium calculation of industrial ﬁre insurance in
Germany followed a hierarchical procedure: ﬁrst the expected aggregate
claim amount for the whole line of business is calculated and this is then
successively broken down into “books”, within the “books” into “groups
of statistical accounts”, and then within the groups into the individual
accounts.
industrial fire insurance
books
groups of statistical accounts
individual accounts
data
Fig. 6.2.
Such a hierarchical system has the advantage of leading to a well-founded,
properly balanced distribution of the burden of claims, in particular of large
claims, within the collective. In the following we will incorporate the idea of a
hierarchical structure into the credibility framework along the lines presented
in the paper by Bühlmann and Jewell [BJ87].

6.2 The Hierarchical Credibility Model
145
6.2 The Hierarchical Credibility Model
For didactic reasons, we will consider in the following a model with ﬁve levels.
However, the generalization of this model to an arbitrary order is obvious and
straightforward.
The structure of the model can be visualized most easily using Figure 6.3.
data
4
line of business
2
1
0
3
classes
risk groups
individual risks
g
h
i
ij
possible                                           
indices of
Level       interpretations                           tree structure                  variables     variables    
Fig. 6.3. Tree structure of the hierarchical credibility model
In order to keep the number of indices small, we will use the following
notation:
 (g) = set of ’s, that stem from g,
D (h) = set of observations Xij, that stem from h,
etc.
Model Assumptions 6.1 (hierarchical credibility)
The probability structure in the hierarchical model is obtained by “drawing”
the individual variables top down:
•
Level 3
The random variables g (g = 1, 2, . . . , |G|) are independent and identi-
cally distributed (i.i.d.) with density r3 (#) .

146
6 Hierarchical Credibility
•
Level 2
Given g the random variables h 5  (g) are i.i.d. with the conditional
density r2 (*| g).
•
Level 1
Given h the random variables i 5  (h) are i.i.d. with the conditional
density r1 (&| h).
•
Level 0
Given i the observations Xij 5 D (i) are conditionally independent
with densities r0 (x| i, wij), for which
E [Xij| i] = µ (i) ,
Var [Xij| i] = 2 (i) /wij,
where wij = known weights.
The similarity to the structure of the Bühlmann—Straub model is obvious. The
Bühlmann—Straub model also has a tree structure (see Figure 4.2 on page 90),
though only with levels zero, one and two. Hierarchical models of higher or-
ders are therefore nothing more than generalizations of the Bühlmann—Straub
model to an increased number of levels. In this connection, it is useful to review
the calculation of the homogeneous credibility estimator in the Bühlmann—
Straub model. As demonstrated in Theorem 4.4, this is done by a bottom-up,
followed by a top-down procedure: First the quantities Xi (data compression,
linear su!cient statistic) and c
c
µ0 are calculated bottom up, and then the ho-
mogeneous credibility estimator \
\
µ(i)
hom
is calculated top down. As we will
see, this method is “inherited” by hierarchical models of higher order.
Notice also that the conditional densities depend only on the variables in
the next higher level and not on those from levels higher than that. Mathe-
matically we express this by saying that the random variables g, h, i, Xij
(listed in decreasing order of the tree) possess the Markov property.
6.3 Relevant Quantities and Notation
As before, the goal is to estimate the correct individual premium µ (i) for
each of the contracts, or more speciﬁcally to ﬁnd the credibility estimator for
µ (i).
It is, however, useful to deﬁne the analogous quantities for the higher lev-
els of the hierarchical tree, where we have on top, at the level of the whole
collective, the collective premium. We use the following notation:
µ0 := E [Xij] ,
(collective premium)
(6.1)
µ (g) := E [Xij |g ] ,
where Xij 5 D (g) ,
µ (h) := E [Xij |h ] ,
where Xij 5 D (h) ,
µ (i) := E [Xij| i] ,
where Xij 5 D (i) .

6.3 Relevant Quantities and Notation
147
It holds that
µ0 = E [µ (g)] ,
µ (g) = E [µ (h)| g] ,
where h 5  (g) ,
µ (h) = E [µ (i)| h] ,
where i 5  (h) .
This follows easily from the model assumptions and properties of the condi-
tional expectation, as is illustrated in the following for µ (h):
µ (h) = E [Xij| h] = E [E [Xij| i, h]| h]
(6.2)
= E [E [Xij| i]| h]
(6.3)
= E [µ (i)| h] ,
where (6.2) follows from properties of the conditional expectation and equa-
tion (6.3) follows from the model assumptions (Markov property).
Next we want to introduce the structural parameters of the hierarchical
credibility model. These are the a priori expected value µ0 = E [Xij] (cf. (6.1))
and the variance components
at level 0
2 := E
£
2 (i)
¤
,
at level 1
 2
1 := E [Var [µ (i)| h]] = E
£
 2
1 (h)
¤
,
at level 2
 2
2 := E [Var [µ (h)| g]] = E
£
 2
2 (g)
¤
,
at level 3
 2
3 := Var [µ (g)] .
These quantities can also be visualized by a tree (see Figure 6.4).
conditional 
variance
components 
variance
components
Fig. 6.4. Tree structure with structural parameters

148
6 Hierarchical Credibility
It follows directly from the properties of the conditional expectation that
2 = E
£
wij(Xij  µ (i))2¤
,
 2
1 = E
h
(µ (i)  µ (h))2i
,
 2
2 = E
h
(µ (h)  µ (g))2i
,
 2
3 = E
h
(µ (g)  µ0)2i
.
Notice further that
µ0 = E [µ (g)] = E [µ (h)] = E [µ (i)] .
It is also easy to show that the following equations hold for the unconditional
variance
Var [µ (i)] =  2
1 +  2
2 +  2
3,
Var [µ (h)] =  2
2 +  2
3.
6.4 Credibility Estimator in the Hierarchical Model
Our goal is to ﬁnd the credibility estimators \
\
µ(i) for the individual premium
µ (i) for i = 1, 2, . . . I. We shall see that this will also necessitate that we ﬁnd
the credibility estimators \
\
µ (h), h = 1, 2, . . . , H and \
\
µ (g), g = 1, 2, . . . , G
and (in the homogeneous case) also c
c
µ0 .
Let us start by representing both the quantities to be estimated and the
data by a tree (see Figure 6.5).
In Figure 6.5 we have located all quantities in such a way that all possible con-
ditional expected values of them can be read as ancestors. All the credibility
estimators can then be understood as linear combinations of the “tree father”
µ0 and all “descendent data” Xij. In the hierarchical set-up, the Hilbert space
technique (i.e. our understanding of the estimators as projections) is particu-
larly useful. Especially, we shall use the iterativity property of the projection
operator.
By deﬁnition
\
\
µ(i) = Pro(µ (i)| L (D, 1)).
We now use the trick of ﬁrst projecting onto a bigger space, i.e. we write
\
\
µ(i) = Pro(Pro(µ (i)| L (D, µ (h) , 1))| L (D, 1)),
(6.4)
where i 5  (h) .

6.4 Credibility Estimator in the Hierarchical Model
149
Fig. 6.5. Tree structure with conditional expected values
Note that, for the inner projection, µ (h) is known. Intuitively, it suggests
that
\
µ(i)
0
:= Pro(µ (i)| L (D, µ (h) , 1))
must be of the form
\
µ(i)
0
= (1)
i B(1)
i
+ (1  (1)
i )µ (h) ,
(6.5)
where B(1)
i
are the compressed data from D (i) and (1)
i
are suitable credi-
bility weights. Below we will prove that our intuition is correct and that (6.5)
holds true. From (6.4) and (6.5) we then get that
\
\
µ(i) = (1)
i B(1)
i
+ (1  (1)
i ) \
\
µ (h).
In order to determine \
\
µ (h) we can repeat the same calculation at the next
higher level (iteration of the idea above):
\
\
µ (h) = Pro(Pro(µ (h)| L (D, µ (g) , 1))| L (D, 1)),
where h 5  (g) ,
\
µ(h)
0
:=
Pro(µ (h)| L (D, µ (g) , 1))
= (2)
h B(2)
h
+ (1  (2)
h )µ (g) ,
(6.6)
where B(2)
h
are the compressed data from D (h), and therefore

150
6 Hierarchical Credibility
\
\
µ(h) = (2)
h B(2)
h
+ (1  (2)
h ) \
\
µ (g).
Finally, for the credibility estimator of µ (g) it must be true that
\
\
µ (g) = (3)
g B(3)
g
+ (1  (3)
g )µ0.
Hence, in order to calculate the credibility premium for µ(i) (at the risk
level) we must also ﬁnd the credibility premium for the higher levels. In order
to do this we need to ﬁnd formulae for the compressed data B(1)
i
, B(2)
h , B(3)
g
and the corresponding credibility weights (1)
i , (2)
h
and (3)
g .
As to the question of the data compression, we have to ask at each level and
at each node, what is the best we can do based only on the data stemming from
that node. The obvious candidates are the best linear, individually unbiased
estimators, which are again orthogonal projections on a!ne subspaces. These
estimators, which we choose as data compressions, are given by
B(1)
i
:= Pro(µ(i)| Lind
e
(D(i))),
B(2)
h
:= Pro(µ(h)| Lind
e
(D(h))) ,
B(3)
g
:= Pro(µ (g))| Lind
e
(D(g))) ,
(6.7)
where for instance Lind
e
(D(h)) is deﬁned by
Lind
e
(D(h)) :=
n
\
µ(h) : \
µ(h) =
X
{i,j: Xij5D(h)}
aijXij,
aij 5 R, E
h
\
µ(h)
¯¯¯ h
i
= µ(h)
o
.
Remarks:
•
Note the dierence between Lind
e
(.) (e.g. Lind
e
(D(h))) and Le (.) (e.g.
Le (X) in (3.18) on page 69). Lind
e
(.) is an a!ne subspace of individually
unbiased estimators, whereas Le (.) is an a!ne subspace of collectively
unbiased estimators (see also Deﬁnition 3.9 on page 65).
•
Lind
e
(.) does not explicitly reﬂect what quantity we want to estimate and
hence what the unbiasedness condition exactly means. However, whenever
Lind
e
(.) appears, this becomes clear from the context. For instance, it is
clear, how Lind
e
(D(h)) in Pro(µ(h)| Lind
e
(D(h))) has to be interpreted:
it is the a!ne subspace of the estimators linear in the data D(h) and
whose conditional expected value given h is equal to µ(h).
We now prove — as an example — formula (6.6). The analogous results hold
for all d
µ(.)
0
on the various hierarchical levels.

6.4 Credibility Estimator in the Hierarchical Model
151
Lemma 6.2. It holds that
\
µ(h)
0
= (2)
h B(2)
h
+ (1  (2)
h )µ (g) ,
(6.8)
where (2)
h
=
 2
2
 2
2 + E
·³
µ(h)  B(2)
h
´2¸.
(6.9)
Remarks:
•
An easy calculation shows that the right-hand side of (6.9) can also be
written as
(2)
h
=
½
E
·³
B(2)
h
 µ (h)
´2¸¾1
½
E
·³
B(2)
h
 µ (h)
´2¸¾1
+
n
E
h
(µ (h)  µ (g))2io1 .
Hence \
µ(h)
0
is again a weighted mean with the precisions as weights (cf.
General Intuitive Principle 3.3).
Proof of Lemma 6.2: We show that:
i)
\
µ(h)
0
is the credibility estimator based on the “compressed observation
value” B(2)
h
and µ (g),
ii) \
µ(h)
0
is the credibility estimator based on the set D of all observations
and µ (g).
Proof of i): We must show that the normal equations are satisﬁed, i.e. that
E
·
\
µ(h)
0¸
= E [µ(h)] ,
(6.10)
Cov
µ
\
µ(h)
0
, µ (g)
¶
= Cov (µ(h), µ (g)) ,
(6.11)
Cov
µ
\
µ(h)
0
, B(2)
h
¶
= Cov
³
µ(h), B(2)
h
´
.
(6.12)
Obviously, equation (6.10) is satisﬁed since
E
h
B(2)
h
i
= E [µ(h)] = E [µ (g)] = µ0.
If we use the identity Cov(X, Y ) = E [Cov(X, Y | Z)]+Cov(E [X| Z] , E [Y | Z]),
and if we condition on the random variable g in (6.11), then we get, both
on the left-hand side as well as on the right-hand side, the value Var [µ (g)] .
Analogously, we ﬁnd that equation (6.12) is equivalent to

152
6 Hierarchical Credibility
(2)
h E
h
Var
h
B(2)
h
¯¯¯ g
ii
= E [Var [µ(h)| g]] ,
and hence
(2)
h
= E [Var [µ(h)| g]]
E
h
Var
h
B(2)
h
¯¯¯ g
ii =
E
h
(µ (h)  µ (g))2i
E
·³
B(2)
h
 µ (g)
´2¸
=
E
h
(µ (h)  µ (g))2i
E
·³
B(2)
h
 µ (h)
´2¸
+ E
h
(µ (h)  µ (g))2i
=
 2
2
 2
2 + E
·³
µ(h)  B(2)
h
´2¸.
Thus we have shown i).
Proof of ii): We must show that µ(h) \
µ(h)
0
B Xij for all observations in
the lowest level.
•
Xij /5 D(h):
E
·½
µ(h)  \
µ(h)
0¾
Xij
¸
= (2)
h E
h³
µ(h)  B(2)
h
´
Xij
i
+ (1  (2)
h )E [(µ(h)  µ (g)) · Xij] .
In the ﬁrst term on the right-hand side of the equation, we condition on
the set of all h and in the second term we condition on the set of all h
and on the set of all g. Using the conditional independence assumed in
Model Assumptions 6.1 we see immediately that both terms are equal to
zero.
•
Xij 5 D(h):
We must show that µ(h)  \
µ(h)
0
B Xij =
³
Xij  B(2)
h
´
+ B(2)
h .
Since \
µ(h)
0
is the credibility estimator based on B(2)
h
and µ (g), it follows
that µ(h)  \
µ(h)
0
B B(2)
h .
To show orthogonality with respect to Xij  B(2)
h
we write
µ(h)  \
µ(h)
0
= (2)
h
· (µ(h)  B(2)
h ) + (1  (2)
h ) · (µ(h)  µ (g)).
The deﬁnition of B(2)
h
(see (6.7)) as optimal compressed data implies that
µ(h)  B(2)
h
B Xij  B(2)
h . Conditioning on h and g, we see im-
mediately that E
h
(µ(h)  µ (g)) ·
³
Xij  B(2)
h
´i
= 0. Thus we have
µ(h)  \
µ(h)
0
B Xij  B(2)
h .

6.4 Credibility Estimator in the Hierarchical Model
153
This concludes the proof of Lemma 6.2.
¤
Lemma 6.2 describes the relevant elements for evaluating a hierarchical
credibility model. Still there are two questions to be answered before we can
numerically proceed in this evaluation:
a) Formula (6.9) contains the quadratic error E
·³
µ(h)  B(2)
h
´2¸
. How do
we ﬁnd the value for this error term?
b) We understand B(2)
h
as the projection on an appropriate a!ne subspace.
How do we numerically ﬁnd the value of this estimator?
Both these questions are answered by the following lemma, which is formulated
and proved for the data compression on level 3, but which holds analogously
for the other levels.
Lemma 6.3. It holds that
i)
B(3)
g
=
X
h5Hg
(2)
h
w(3)
g
B(2)
h ,
(6.13)
where Hg
= {h : h 5  (g)},
w(3)
g
=
P
h5Hg
(2)
h ,
ii)
E
·³
B(3)
g
 µ (g)
´2¸
=  2
2
w(3)
g
.
(6.14)
Proof:
First we note that
B(3)
g
= Pro
£
Pro
£
µ (g)| Lind
e
(D(g), {µ (h) : h 5 Hg})
¤¯¯ Lind
e
(D(g))
¤
.
(6.15)
It is intuitively clear that the inner projection does not depend on Le (D(g)) .
Indeed, given {µ (h) : h 5 Hg}, the data D(g) cannot provide more informa-
tion with regard to µ (g) than that already contained in {µ (h) : h 5 Hg}.
Formally this can be checked using the orthogonality condition of projection.
Conditionally, given g, {µ (h) : h 5 Hg} are independent with the same con-
ditional variance. Hence we have for the inner projection
Pro
£
µ (g)| Lind
e
(D(g)) , {µ (h) : h 5 Hg}
¤
=
1
|Hg|
X
h5Hg µ (h) ,
(6.16)
where |Hg| denotes the number of nodes stemming from g.
From (6.15) and (6.16) we get

154
6 Hierarchical Credibility
B(3)
g
= Pro
·
1
|Hg|
X
h5Hg µ (h)
¯¯¯¯ Lind
e
(D(g))
¸
.
(6.17)
We also have that
Pro
£
µ (h)| Lind
e
(D(g))
¤
= Pro
£
µ (h)0¯¯ Lind
e
(D(g))
¤
= (2)
h B(2)
h
+
³
1  (2)
h
´
B(3)
g .
(6.18)
Combining (6.17) and (6.18) we get
B(3)
g
=
1
|Hg|
X
h5Hg
n
(2)
h B(2)
h
+
³
1  (2)
h
´
B(3)
g
o
,
and
0 =
1
|Hg|
X
h5Hg
n
(2)
h B(2)
h
 w(3)
g B(3)
g
o
,
respectively
B(3)
g
=
X
h5Hg
(2)
h
w(3)
g
B(2)
h ,
which proves (6.13).
For (6.14) we calculate
E
·³
B(3)
g
 µ (g)
´2¸
=
X
h5Hg
3
E
C
³
(2)
h
´2
³
w(3)
g
´2 E
·³
B(2)
h
 µ (g)
´2¸
4
F
D ,
(6.19)
E
·³
B(2)
h
 µ (g)
´2¸
= E
·³
B(2)
h
 µ (h) + µ (h)  µ (g)
´2¸
,
= E
·³
B(2)
h
 µ (h)
´2¸
+ E
h
(µ (h)  µ (g))2i
,
= E
·³
B(2)
h
 µ (h)
´2¸
+  2
2.
(6.20)
From Lemma 6.2, respectively formula (6.9), it holds that
(2)
h
=
 2
2
 2
2 + E
·³
µ (h)  B(2)
h
´2¸.
(6.21)
(6.21) and (6.20) plugged into (6.19) yields
E
·³
B(3)
g
 µ (g)
´2¸
=  2
2
w(3)
g
.
(6.22)

6.4 Credibility Estimator in the Hierarchical Model
155
This concludes the proof of Lemma 6.3.
¤
Analogously we have
E
·³
B(2)
h
 µ (h)
´2¸
=
 2
1
w(2)
h
,
E
·³
B(1)
i
 µ (i)
´2¸
= 2
wi•
.
Note that the last equation is the same as in the Bühlmann—Straub model.
On the basis of Lemmas 6.2 and 6.3 we can now proceed to the numerical
evaluation of the data compression and of the credibility weights at the various
levels. This is summarized in the following theorem.
Theorem 6.4 (data compression and credibility weights).
The best,
individually unbiased estimator (and the credibility weights for the various
levels) can be calculated from bottom to top as follows:
B(1)
i
=
X
j
wij
wi•
Xij,
where wi• =
X
j wij,
(1)
i
=
wi•
wi• + 2
 2
1
,
B(2)
h
=
X
i5Ih
(1)
i
w(2)
h
B(1)
i
,
where Ih = {i : i 5  (h)} ,
w(2)
h
=
X
i5Ih (1)
i ,
(2)
h
=
w(2)
h
w(2)
h
+  2
1
 2
2
,
B(3)
g
=
X
h5Hg
(2)
h
w(3)
g
B(2)
h ,
where Hg = {h : h 5  (g)} ,
w(3)
g
=
X
h5Hg (2)
h ,
(3)
g
=
w(3)
g
w(3)
g
+ (2)2
(3)2
,
c
c
µ0 =
X
g
(3)
g
w(4) B(3)
g ,
where w(4) =
X
g (3)
g .

156
6 Hierarchical Credibility
Remarks:
i)
Since the credibility estimator depends only on these “optimally com-
pressed” data {B(1)
i
, B(2)
h , B(3)
g }, we also call them a linear su!cient sta-
tistics.
ii) Note: the estimator of the next higher level is always the weighted average
(weighted with the credibility weights) of the current level, e.g. B(2)
h
is the
weighted average of the B(1)
i
’s, where the weights are the (1)
i ’s.
iii) The following formulae for the error terms have already been proved:
E
·³
B(1)
i
 µ (i)
´2¸
= 2
wi•
,
E
·³
B(2)
h
 µ (h)
´2¸
=
 2
1
w(2)
h
,
E
·³
B(3)
g
 µ (g)
´2¸
=
 2
2
w(3)
g
.
iv) We also have that
E
·³
B(1)
i
 µ (h)
´2¸
=  2
1
(1)
i
,
(6.23)
E
·³
B(2)
h
 µ (g)
´2¸
=  2
2
(2)
h
,
(6.24)
E
·³
B(3)
g
 µ0
´2¸
=  2
3
(3)
g
,
(6.25)
i.e. the credibility weights are proportional to the “precisions” with re-
spect to the quantities to be estimated on the next higher level. From this
it becomes intuitively clear that, e.g. B(2)
h
is the credibility weighted mean
of {B(1)
i
: i 5 Ih}.
The validity of (6.23)—(6.25) is easy to check. For instance
E[(B(2)
h
 µ(g))2] = E[(B(2)
h
 µ(h) + µ(h)  µ(g))2],
=
 2
1
w(2)
h
+  2
2,
=  2
2
(2)
h
.
The discussion at the beginning of this section together with Theorem 6.4
provide the basis for the calculation of the credibility estimator at the various
hierarchical levels. The result is summarized in the following theorem.

6.4 Credibility Estimator in the Hierarchical Model
157
Theorem 6.5 (credibility estimator).
The (inhomogeneous) credibility
estimators d
d
µ (·) can be determined top down as follows:
\
\
µ (g) = (3)
g B(3)
g
+
³
1  (3)
g
´
µ0,
\
\
µ (h) = (2)
h B(2)
h
+
³
1  (2)
h
´ \
\
µ (g),
h 5  (g) ,
\
\
µ (i) = (1)
i B(1)
i
+
³
1  (1)
i
´ \
\
µ (h),
i 5  (h) .
Remarks:
•
The credibility weights (the ’s) as well as the best, individually unbiased
estimators (the B’s), were deﬁned and calculated in Theorem 6.4.
•
The credibility estimators depend on the data only through the B-values.
These are linear su!cient statistics. The method for compressing the data
is the same as that which we met earlier, namely the best, individually
unbiased estimator based on the underlying data.
•
Notice also that the procedure for calculating the credibility estimator is
exactly analogous to that for the homogeneous credibility estimator in the
Bühlmann—Straub model. This is a two-step procedure, where ﬁrst the
linear su!cient statistic (data compression) is calculated from bottom to
top and then the credibility estimator is determined top down.
Proof of Theorem 6.5:
The theorem follows directly from the discussion at the beginning of the sec-
tion as well as from Theorem 6.4.
¤
With exactly the same arguments we also get (“for free”, so to speak) the
homogeneous credibility estimator in the hierarchical model. The results in
the following theorem are obvious.
Theorem 6.6 (homogeneous credibility estimator). The homogeneous
credibility estimator d
d
µ (·)
hom
can be calculated top down as follows:
\
\
µ (g)
hom
= (3)
g B(3)
g
+
³
1  (3)
g
´ c
c
µ0,
\
\
µ (h)
hom
= (2)
h B(2)
h
+
³
1  (2)
h
´ \
\
µ (g)
hom
,
h 5  (g) ,
\
\
µ (i)
hom
= (1)
i B(1)
i
+
³
1  (1)
i
´ \
\
µ (h)
hom
,
i 5  (h) .

158
6 Hierarchical Credibility
Remarks:
•
As in the Bühlmann—Straub model, the homogeneous estimator is found
by replacing µ0 with the best linear estimator c
c
µ0.
•
The calculation and deﬁnition of c
c
µ0 is given in Theorem 6.4.
The remarkable property of the homogeneous credibility estimator, namely
to deﬁne a tari which can be seen as a redistribution of total observed claims,
which was already found for the Bühlmann—Straub model (cf. Theorem 4.5)
also holds in the hierarchical model and is stated in the following theorem.
Theorem 6.7 (balance property). For the homogeneous credibility estima-
tor in the hierarchical model it holds that
X
i,j
wij \
\
µ(i)
hom
=
X
i,j
wijXij.
Remark:
•
This property does not, however, hold for the credibility estimator for
higher levels. For example, in general we have
X
h
wh• \
\
µ(h)
hom
6=
X
i,j
wijXij,
where wh• =
X
{i,j: Xij5D(h)}
wij.
We must therefore be careful in interpreting d
d
µ(·) for higher levels: It may
not be interpreted as the “average premium amount” resulting for the
higher levels.
Proof of Theorem 6.7: With Theorem 6.4 we ﬁnd that
X
i,j
wij( \
\
µ(i)
hom
 Xij) =
X
i
wi•( \
\
µ(i)
hom
 B(1)
i
)
=
X
i
wi•
³
1  (1)
i
´ Ã
\
\
µ(h)
hom
 B(1)
i
!
= 2
 2
1
X
h
w(2)
h
Ã
\
\
µ(h)
hom
 B(2)
h
!
= 2
 2
1
X
h
w(2)
h
³
1  (2)
h
´ Ã
\
\
µ(g)
hom
 B(2)
h
!

6.5 Quadratic Loss in the Hierarchical Model
159
= 2
 2
2
X
g
w(3)
g
Ã
\
\
µ(g)
hom
 B(3)
g
!
= 2
 2
2
X
g
w(3)
g
³
1  (3)
g
´ ³ c
c
µ0  B(3)
g
´
= 2
 2
3
X
g
(3)
g
³c
c
µ0  B(3)
g
´
= 0.
In the third, ﬁfth and seventh equations we use the fact that
wi•(1  (1)
i ) = 2
 2
1
(1)
i ,
w(2)
h (1  (2)
h ) =  2
1
 2
2
(2)
h ,
w(3)
g (1  (3)
g ) =  2
2
 2
3
(3)
g .
This completes the proof of Theorem 6.7.
¤
6.5 Quadratic Loss in the Hierarchical Model
The quadratic loss in the hierarchical credibility model can also be best cal-
culated using a recursive procedure.
Theorem 6.8 (quadratic loss of the credibility estimator). The
quadratic loss of the credibility estimator can be determined top down as fol-
lows:
q(3)
g
:=
E
"µ\
\
µ (g)  µ (g)
¶2#
=  2
3
³
1  (3)
g
´
,
(6.26)
q(2)
h
:=
E
"µ \
\
µ (h)  µ (h)
¶2#
=  2
2
³
1  (2)
h
´
+ q(3)
g
³
1  (2)
h
´2
,
(6.27)
q(1)
i
:=
E
"µ \
\
µ (i)  µ (i)
¶2#
=  2
1
³
1  (1)
i
´
+ q(2)
h
³
1  (1)
i
´2
.
(6.28)
Proof: At the top level we ﬁnd

160
6 Hierarchical Credibility
q(3)
g
= E
·n
(3)
g (B(3)
g
 µ(g)) + (1  (3)
g )(µ0  µ(g))
o2¸
=
3
C
w(3)
g
w(3)
g
+ 2
2
2
3
4
D
2
 2
2
w(3)
g
+
3
C
 2
2
 2
3
w(3)
g
+ 2
2
2
3
4
D
2
 2
3
(6.29)
=  2
3
 2
2
 2
3
w(3)
g
+  2
2
 2
3
=  2
3(1  (3)
g ).
Because of the iterative property of projections we have that
q(2)
h
= E
"µ \
\
µ (h)  µ (h)
¶2#
= E
"µ
\
µ(h)
0
 µ(h)
¶2#
+ E
"µ
\
µ(h)
0
 \
\
µ(h)
¶2#
.
(6.30)
A calculation analogous to (6.29) shows that
E
"µ
\
µ(h)
0
 µ(h)
¶2#
= E
·n
(2)
h
³
B(2)
h
 µ(h)
´
+ (1  (2)
h )(µ(g)  µ(h))
o2¸
=  2
2 (1  (2)
h ).
For the last term in (6.30) we get
E
"µ
\
µ(h)
0
 \
\
µ(h)
¶2#
=
³
1  (2)
h
´2
E
"µ\
\
µ (g)  µ (g)
¶2#
,
=
³
1  (2)
h
´2
q(3)
g .
Thus (6.27) is proved. The proof of (6.28) is analogous. This ends the proof
of Theorem 6.8.
¤
Theorem 6.9 (quadratic loss of the hom. credibility estimator). The
quadratic loss of the homogeneous credibility estimator can be calculated from
top down as follows:
q(4)
hom := E
·³c
c
µ0  µ0
´2¸
=  2
3
(3)
•
,
q(3)
g,hom := E
5
7
Ã
\
\
µ (g)
hom
 µ (g)
!26
8
=  2
3
³
1  (3)
g
´
+ q(4)
hom
³
1  (3)
g
´2
,
(6.31)

6.5 Quadratic Loss in the Hierarchical Model
161
q(2)
h,hom := E
5
7
Ã
\
\
µ (h)
hom
 µ (h)
!26
8
=  2
2
³
1  (2)
h
´
+ q(3)
g,hom
³
1  (2)
h
´2
,
(6.32)
q(1)
i,hom := E
5
7
Ã
\
\
µ (i)
hom
 µ (i)
!26
8
=  2
1
³
1  (1)
i
´
+ q(2)
h,hom
³
1  (1)
i
´2
.
(6.33)
Proof:
E
·³c
c
µ0  µ0
´2¸
=
X
g
Ã
(3)
g
(3)
•
!2
E
·³
B(3)
g
 µ0
´2¸
=
X
g
Ã
(3)
g
(3)
•
!2
 2
3
(3)
g
=  2
3
(3)
•
.
(6.34)
Remark:
•
Note that (6.34) is of the same structure as formulae (6.23)—(6.25).
It follows from Theorem 3.14 that
E
5
7
Ã
\
\
µ (g)
hom
 µ (g)
!26
8 = E
5
7
Ã
\
\
µ (g)
hom
 \
\
µ (g)
!26
8
+ E
"µ\
\
µ (g)  µ (g)
¶2#
.
(6.31) then follows from
E
5
7
Ã
\
\
µ (g)
hom
 \
\
µ (g)
!26
8 =
³
1  (3)
g
´2
E
·³c
c
µ0  µ0
´2¸
=
³
1  (3)
g
´2  2
3
(3)
•
and (6.26).
(6.32) and (6.33) can be proved in exactly the same way as (6.27) and
(6.28) by just replacing everywhere d
d
µ (.) by d
d
µ (.)
hom
. This completes the proof
of Theorem 6.9.
¤

162
6 Hierarchical Credibility
6.6 Estimation of the Structural Parameters in the
Hierarchical Model
The estimator for µ0 has been given by the homogeneous credibility estimator.
In the following, we give estimators for the components of variance.
For the two lowest levels, i.e. for the estimation of 2 and  2
1, we could
use estimators analogous to those found for the Bühlmann—Straub model (see
Section 4.8). For the higher levels of the hierarchy, i.e. for the estimation of
 2
2 and  2
3 in the model of order 3, another approach will be recommended.
We have already introduced the sets of indices Ih and Hg (Theorem 6.4).
For the following it is useful to introduce the sets of nodes in the hierarchical
tree:
G := {g : g 5 (µ0)} ,
H :=
[
g5G
Hg,
I :=
[
h5H
Ih.
Further, we denote the number of elements in a set with | · |.
Examples:
•
|Ih| = Number of nodes at the -level, which stem from h.
•
|I| = Total number of nodes at the -level.
•
|G| = Total number of nodes at level 3.
We denote the number of observations for the ith risk by ni.
i)
Estimation of 2:
As in the Bühlmann—Straub model, we consider
Si =
1
ni  1
X
j
wij
³
Xij  B(1)
i
´2
.
S =
X
i5I
ni  1
n•  |I|Si =
1
n•  |I|
X
i,j
wij
³
Xij  B(1)
i
´2
.
Note that E [Si |i ] = 2 (i) and hence E [S] = 2.
We choose
c
2 = S
as an estimator for 2.
ii) Estimation of  2
1:
We also use here estimators which are analogous to those used in the
Bühlmann—Straub model. Consider the following random variables:

6.6 Estimation of the Structural Parameters in the Hierarchical Model
163
d
T (1)
h
= ch ·
(
|Ih|
|Ih|  1
X
i5Ih
wi•
z(1)
h
³
B(1)
i
 B
(1)
h
´2
 |Ih| · c
2
z(1)
h
)
,
where
z(1)
h
=
X
i5Ih
wi•,
B
(1)
h
=
X
i5Ih
wi•
z(1)
h
B(1)
i
,
ch = |Ih|  1
|Ih|
(X
i5Ih
wi•
z(1)
h
Ã
1  wi•
z(1)
h
!)1
.
It holds again that
E
· d
T (1)
h
|h
¸
=  2
1 (h) ,
E
h
T (1)
h
i
=  2
1.
We choose
c
 1
2 =
1
|H|
X
h5H
max{ d
T (1)
h , 0}
as estimator for  2
1.
iii) Estimation of  2
2:
We deﬁne the following random variables:
T (2)
g
= cg ·
;
?
=
|Hg|
|Hg|  1
X
h5Hg
w(2)
h
z(2)
g
³
B(2)
h
 B
(2)
g
´2
 |Hg|  2
1
z(2)
g
<
@
> ,
where
z(2)
g
=
X
h5Hg
w(2)
h ,
w(2)
h
was deﬁned in Theorem 6.4,
B
(2)
g
=
X
h5Hg
w(2)
h
z(2)
g
B
(2)
h ,
cg = |Hg|  1
|Hg|
;
?
=
X
h5Hg
w(2)
h
z(2)
g
Ã
1  w(2)
h
z(2)
g
!<
@
>
1
.
It is easy to show that the random variables T (2)
g
, g = 1, 2, . . . , |G|, are
again unbiased estimators for  2
2. However, T (2)
g
depends on the structural

164
6 Hierarchical Credibility
parameters 2 and  2
1 through w(2)
h
and for  2
1 also directly. But these were
already estimated in steps i) and ii) and so we substitute the structural
parameters in the formula for T (2)
g
by their estimates. Of course the re-
sulting random variables d
T (2)
g
are no longer unbiased. This procedure leads
then to the following estimator:
c
 2
2 =
1
|G|
X
g5Hg
max{ d
T (2)
g
, 0}.
iv) Estimation of  2
3:
This follows the same scheme as the estimation of  2
2.
T (3) = c ·
;
?
=
|G|
|G|  1
X
g5G
w(3)
g
z(3)
³
B(3)
g
 B
(3)´2
 |G| ·  2
2
z(3)
<
@
> ,
where
z(3) =
X
g5G
w(3)
g ,
w(3)
g
was deﬁned in Theorem 6.4,
B
(3) =
X
g5G
w(3)
g
z(3) B(3)
g ,
c = |G|  1
|G|
;
?
=
X
g5G
w(3)
g
z(3)
Ã
1  w(3)
g
z(3)
!<
@
>
1
.
Again, T (3) is an unbiased estimator and depends on the structural pa-
rameters 2,  2
1 and  2
2. These have been estimated in steps i) to iii) and
so we replace these values by their estimators in the formula for T (3). We
denote the resulting random variable by d
T (3). This leads to the following
estimator:
c
 3
2 = max{ d
T (3), 0}.
General remarks:
•
The estimation of the structural parameters follows a bottom-up procedure
in parallel with the estimation of the su!cient statistics (see Theorem 6.4).
•
The extension of this procedure to models of higher order is obvious.
•
Observe that the number of parameters to be estimated increases with
the number of levels of the hierarchical model. This means that in prac-
tice one should be parsimonious when choosing the number of levels in a
hierarchical model.
•
If we modiﬁed Model Assumptions 6.1, modelling all variances as con-
stants, i.e. Var [Xij |wij ] = 2
i /wij, Var [µ (i)] =  2
1h for i 5  (h) ,

6.7 Exercises
165
Var [µ (h)] =  2
2g for h 5 g, these constants would appear in the credi-
bility formulae instead of the “averaged” variance components 2,  2
1,  2
2. If
for instance a speciﬁc risk group showed more stable results than another,
this speciﬁc risk group would be given a bigger credibility weight. The
situation is the same as already discussed in the Bühlmann—Straub model
in the last point of the remarks on pages 85—86. The point is that these
constants would have to be estimated from the data and the imposed es-
timation error would typically oset the “theoretical” improvement of the
credibility estimator if the constants were known. This eect of estimation
errors is inherent in each level of the hierarchical model.
6.7 Exercises
Exercise 6.1
An insurance company wants to calculate the expected value of the claims
ratio (claim amount divided by a suitable weight) for dierent risk categories
in a certain line of business. The company’s own data are available as well
as “industry-wide” data (i.e. pooled data delivered to a statistics bureau by
several companies) for an observation period of n years. The table below gives
the following data:
•
the observed average of the claims ratio Xi,
•
the empirical within-risk variance 2
i of the yearly claims ratios Xij given
by
2
i =
1
n  1
n
X
j=1
wij (Xij  Xi)2 ,
•
the weight wi• over the whole observation period.
risk
group
Xi
Vi
2
wi.
Xi
Vi
2
wi.
1
0.81
42.30
3 847
0.75
43.60 14 608
2
0.94
31.60
1 150
0.86
27.10
3 081
3
0.93
27.20
2 843
1.06
49.30
4 644
4
1.14
49.25
1 123
0.89
17.30
3 487
5
0.73
16.40
 532
1.01
23.90
9 004
6
1.04
37.65
1 309
0.86
27.45
4 467
7
1.48
39.60
1 332
1.19
46.60
4 536
8
1.10
21.60
 923
0.79
23.35
2 718
total
0.98
13 059
0.90
46 545
own company
other companies
a) Calculate the values of the (empirical) homogeneous credibility estimator
using the hierarchical model with the dierent risk groups on level 2 and
the distinction between the data of the own and the data of the other

166
6 Hierarchical Credibility
companies on level 1.
Beside the point estimates, give also an indication of the precisions of
these estimates. As a measure of the precision, take the square root of the
quadratic loss obtained by inserting the estimated structural parameters
into the formula of the quadratic loss.
Remark: Be aware that the estimated quadratic loss obtained by this pro-
cedure does not contain the estimation error of the structural parameters.
b) Do the same but with the distinction between own/other companies on
level 2 and the dierent risk groups on level 1.
c) Discuss shortly the dierence between the two models a) and b).
Remark: We will use the same data set in Exercise 7.1 in connection with
multidimensional credibility.
Exercise 6.2
Consider the same data set as in Exercise 4.6 and treat them within a hier-
archical framework of order two, where the ﬁve dierent types of car are on
level one and the use of car (A or B) are on level two.
a) Calculate the values of the (empirical) hierarchical credibility estimator
of the claim frequencies, both for normal and large claims. Compare the
results with the results obtained in Exercise 4.6 and comment brieﬂy on
the results.
b) The same for the claim severities.
c) The same for the average claims cost per risk directly. Discuss the dier-
ences in the pure risk premiums obtained by combining a) and b) on the
one hand and the results obtained by c) on the other.

7
Multidimensional Credibility
7.1 Motivation
The following three examples are a selection of typical situations which pricing
actuaries working in practice are confronted with. The list could easily be
extended.
•
“Normal” claims load, “large” claims load.
In many lines of business (e.g. motor liability, general liability, industry
ﬁre), one or two percent of the largest claims are responsible for more
than half of the total claims load. This means that more than half of the
pure risk premium stems from a rather small number of claims, or in other
words, there is relatively little statistical information concerning half of
the pure risk premium. The question arises, whether and how much we
can learn from the bulk of normal claims, where we have a huge number of
observations and a lot of statistical information, with respect to the large
claims load. The distinction between the two categories of “normal” and
“large” claims can be either the size of the claims or any other criterion,
for instance “pure physical damage” and “bodily injury” claims in motor
liability.
•
Claim frequencies, claim sizes.
It is standard in the pricing of insurance products to analyse claim fre-
quencies and claim amounts separately and then to derive from these two
quantities the expected average claims load per risk. However, there might
be dependencies between frequencies and claim sizes. For instance the mo-
tor accidents in towns are often greater in number but smaller in the
average claim size compared to rural areas.
•
Own data, pool data.
In many countries there are summary statistics from a data pool (industry-
wide or several companies) available. A company actuary, faced with the
problem of calculating a tari for the own company, has two sources of
statistical information: the company’s own data and the pool data. He

168
7 Multidimensional Credibility
is then confronted with the question of how much he should rely on the
company’s own statistics and how much he should take into account the
information from the pool statistics.
•
Group accident insurance (workers’ compensation) in Switzerland.
In Switzerland, employers are obliged to insure all their employees against
accidents both at work and “not at work” by means of group accident
insurance policies. In the resulting statistics we can dierentiate between
accidents occurring at work and those occurring “not at work” and, within
each of these classiﬁcations, between long-term beneﬁts (for disability or
dependents) and short-term beneﬁts (medical costs, wage payment inter-
ruptions). Again the question arises, whether and how much we can learn
from the observations of the one category of claims with respect to the
other categories.
As an example let us consider the problem of “pure physical damage (nor-
mal)” and “bodily injury (large) claims” in motor liability rate-making. As-
sume that, as a ﬁrst step, we are interested in the corresponding claim fre-
quencies. For each risk i and each year we have a two-dimensional vector of
observations, namely the frequency of “normal” claims and the frequency of
“large” claims. The expected value of the observation vector, given the risk
characteristic , is the vector
µ0 () = (µ1 () , µ2 ()) .
Primarily we are interested in the pure risk premium. We make the usual
assumption that conditionally on  the number of claims and the claim sizes
are independent. For simplicity, we further assume that the distribution of the
claim sizes does not depend on . Then the pure risk premium is given by
µ () = 1µ1 () + 2µ2 () ,
where 1 resp. 2 are the expected values of the claim severities of “normal”
resp. “large” claims. Because of the linearity property of the credibility esti-
mator, we have
\
\
µ () = 1
\
\
µ1 () + 2
\
\
µ2 ().
In order to ﬁnd the credibility estimator for µ () for all possible severities,
we need to determine the credibility estimator of the vector µ (), i.e.
\
\
µ ()
0
=
µ \
\
µ1 (), \
\
µ2 ()
¶
.
Here, the vector µ () is two-dimensional. In the group accident example
mentioned above, µ () would be a vector with dimension four. The point
is that the quantity to be estimated is multidimensional and hence the title
multidimensional credibility.

7.2 The Abstract Multidimensional Credibility Model
169
We might ﬁrst ask ourselves if it would make sense to estimate each of the
components of the vector separately on the basis of each of the associated ob-
servations (= corresponding components of the observation vector) and in this
way reduce the problem to two one-dimensional problems. We could do that,
if the components of the vector µ () were independent. However, in most
practical situations there is no a priori evidence that they are independent.
On the contrary, there is mostly some evidence that there are dependences
between the components and that we can therefore learn something from the
observations of one component with respect to the others. For instance, in the
example of group accident insurance, it is known that people who live “dan-
gerously” professionally, tend also to take more risks in their free time. There
is therefore a correlation between accidents at work and “not at work”. This in
turn means that we can learn something about the expected aggregate claim
amount for accidents at work from the claim experience of accidents “not at
work”, and vice versa.
The essential point of multidimensional credibility is not only to estimate a
multidimensional vector µ (), but also to use for this estimation all available
observations simultaneously.
7.2 The Abstract Multidimensional Credibility Model
In this section we concentrate on the mathematical structure which is essential
for the results of this chapter. This structure is very general. It also covers
the credibility regression model which will be the subject of Chapter 8, where
we can use the results derived in this chapter. A concrete multidimensional
model will be considered in Section 7.3.
7.2.1 Model
As already explained, one essential feature of multidimensional credibility is
that the quantity µ () to be estimated is multidimensional, i.e. a vector of
length p.
In the abstract multidimensional credibility model, we assume that there
is a random vector X with the same dimension as µ (), which is individually
unbiased, i.e. for which E [X| ] = µ (). The goal is to ﬁnd the credibility
estimator based on X.
The vector X considered here must not be the same as the observation
vector and, as a rule, this is not the case. As we will see, X is in general a
compression of the original observations. For the moment, we leave open the
question of how the appropriate compression of the data is determined. This
problem will be treated in Section 7.4.
The vector µ(), which we want to estimate, is also not further speciﬁed
here. In most concrete applications this arises in a very natural way.

170
7 Multidimensional Credibility
In the following, we just want to derive the form of the credibility estimator
for µ () based on this simple structure as just deﬁned. For the homogeneous
credibility estimator we need a corresponding collective. We will assume that
we have a portfolio of contracts having the required structure. This leads us
to the following:
Model Assumptions 7.1 (abstract multidimensional credibility)
For each risk i we are given a p-dimensional vector Xi, for which it holds that
i) Conditionally, given i,
E [X0
i| i] = µ (i)0 = (µ1 (i) ,µ2 (i) , . . . ,µp (i)),
(7.1)
Cov(Xi, X0
i| i) = 	i (i) .
(7.2)
ii) The pairs (1, X1), (2, X2),. . . are independent, and 1, 2,. . . are in-
dependent and identically distributed.
Note that no assumptions are made about the conditional probability struc-
ture within Xi, i.e. 	i (i) in (7.2) can be any covariance matrix.
For each risk i, we are interested in estimating the associated vector µ (i).
As in the earlier models, this estimator will depend on the values of
the structural parameters. The structural parameters of the multidimensional
credibility model are
µ := E [µ (i)] ,
(7.3)
Si := E [	i (i)] ,
(7.4)
T := Cov
¡
µ (i) , µ (i)0¢
.
(7.5)
Remarks:
•
µ is a vector of dimension p, Si and T are p × p matrices.
•
For the models used in insurance, it is almost always true that Si can be
obtained from a common matrix S and appropriately chosen weights.
•
On the basis of the model assumptions, the dierent contracts or risks
are considered a priori equal, i.e. a priori no dierences among them are
recognized.
7.2.2 The (Inhomogeneous) Multidimensional Credibility
Estimator
The multidimensional credibility estimator is deﬁned componentwise. We thus
have to ﬁnd, for each component of the vector µ (i), the associated credibility
estimator.
As in the Bühlmann—Straub model, one easily sees that the credibility
estimator for µ (i) depends only on the components of the vector Xi and
not on those associated with the other contracts. In order to simplify the
notation in this section we omit the subscript i.

7.2 The Abstract Multidimensional Credibility Model
171
By deﬁnition
[
[
µ() := Pro(µ()| L(X, 1)),
where the projection operator should be understood componentwise and
L (X, 1) is the linear subspace spanned by 1 and the components of the vector
X (cf. Deﬁnition 3.8).
Now, for k = 1, 2, . . . , p, let
\
\
µk () = ak0 +
p
X
j=1
akjXj
be the credibility estimator for the components of µ (). Any such estimator
must satisfy the normal equations (see Corollary 3.17):
µk = ak0 +
p
X
j=1
akjµj,
(7.6)
Cov(µk(), Xm) =
p
X
j=1
akjCov(Xj, Xm)
for m = 1, 2, . . . , p.
(7.7)
More elegantly, using matrix notation we can write
[
[
µ() = a + A · X,
where
a =
3
E
E
E
E
E
E
C
a10
...
ak0
...
ap0
4
F
F
F
F
F
F
D
,
A =
3
E
E
E
E
E
E
C
a11, a12, . . . , a1p
...
ak1, ak2, . . . , akp
...
ap1, ap2, . . . , app
4
F
F
F
F
F
F
D
.
The normal equations (7.6) and (7.7) in matrix notation are given by
µ = a + A · µ,
(7.8)
Cov(µ(), X0) = A · Cov(X, X0).
(7.9)
Since
Cov(µ(), X0) = E [Cov(µ(), X0| )] + Cov(µ(), E [X0| ])
= Cov
£
µ(), µ ()0¤
= T,
Cov(X, X0) = E [Cov(X, X0| )] + Cov(E [X| ] , E [X0| ])
= S + T,

172
7 Multidimensional Credibility
we get from (7.9)
T = A (T + S) ,
and therefore
A = T (T + S)1 .
Thus we have derived the following multidimensional credibility formula:
Theorem 7.2 (credibility estimator). The (inhomogeneous) multidimen-
sional credibility estimator is given by
\
\
µ(i) = AiXi + (I  Ai) µ,
(7.10)
where µ, T, Si were deﬁned in (7.3)—(7.5), and
Ai = T (T + Si)1 .
Remarks:
•
Ai is called the credibility matrix.
•
The matrix T + Si is a covariance matrix and is therefore regular for
linearly independent components of the vector X.
•
Since T and Si are symmetric, we also have that A0
i = (T + Si)1 T.
Notice, however, that, in general, Ai 6= A0
i, i.e. the credibility matrix Ai is
not necessarily symmetric, even though T and Si are symmetric.
•
The estimator \
\
µ(i) is a weighted average of Xi and µ. The weighting
results from the credibility matrix Ai and its complement I  Ai. It also
holds that
Ai =
h
T (T + Si)1 Si
i
S1
i
=
¡
T 1 + S1
i
¢1 S1
i
,
(7.11)
I  Ai =
¡
T 1 + S1
i
¢1 T 1.
(7.12)
The weights are again “proportional” to their precision (inverse of the
squared error matrix). In particular, we have that
T = E [(µ  µ (i))(µ  µ (i))0]
(7.13)
= quadratic loss matrix of µ with respect to µ (i) ,
Si = E [(Xi  µ (i))(Xi  µ (i))0]
(7.14)
= quadratic loss matrix of Xi with respect to µ (i) .
The proportionality factor
¡
T 1 + S1
i
¢1 is to be multiplied from the
left.

7.2 The Abstract Multidimensional Credibility Model
173
7.2.3 The Homogeneous Credibility Estimator
In this section we will derive the homogeneous multidimensional credibility
estimator. In contrast to the inhomogeneous estimator, this estimator has
no constant term µ, i.e. the homogeneous credibility estimator contains an
“automatically built-in estimator” for the a priori expected value µ.
By deﬁnition
[
[
µ()
hom
:= Pro(µ()| Le(X1, . . . , XI)),
(7.15)
where the projection operator is to be understood componentwise, and Le(X1,
. . . , XI) is again the a!ne subspace, spanned by the components of the vectors
Xi with the corresponding side constraint (componentwise unbiasedness over
the collective).
Theorem 7.3 (homogeneous credibility estimator). The homogeneous
multidimensional credibility estimator is given by
\
\
µ(i)
hom
= Ai Xi + (I  Ai) bbµ,
(7.16)
where T, Si were deﬁned in (7.4)—(7.5), and
Ai = T (T + Si)1 ,
(7.17)
bbµ =
Ã I
X
i=1
Ai
!1
I
X
i=1
AiXi.
(7.18)
Remark:
•
As an estimator of µ we again take the credibility-weighted mean.
Proof of Theorem 7.3: Because of the iterative property of projection op-
erators and since Le(X1, . . . , XI)  L(X1, . . . , XI, 1), we have that
\
\
µ(i)
hom
= Pro (µ(i)| Le(X1, . . . , XI))
= Pro (Pro (µ(i)| L(X1, . . . , XI, 1))| Le(X1, . . . , XI))
= Pro (AiXi + (I  Ai) µ| Le(X1, . . . , XI))
= AiXi + (I  Ai) Pro (µ| Le(X1, . . . , XI)) .
It remains then to show that
bbµ := Pro (µ| Le(X1, . . . , XI)) =
Ã I
X
i=1
Ai
!1
I
X
i=1
AiXi.

174
7 Multidimensional Credibility
We check the normal equations for the homogeneous credibility estimator (see
Corollary 3.3), i.e. we must show that for all PI
i=1 BiXi with PI
i=1 Bi = I it
holds that
Cov
3
Cbbµ,
Ã I
X
i=1
BiXi
!04
D = Cov
³bbµ, bbµ
0´
.
(7.19)
Because Cov(Xi, X0
i) = T +Si and because of the independence of the Xi we
have that
Cov
³
bbµ, bbµ
0´
=
Ã I
X
i=1
Ai
!1 Ã I
X
i=1
Ai Cov (Xi, X0
i) A0
i
! Ã I
X
i=1
A0
i
!1
=
Ã I
X
i=1
Ai
!1 Ã I
X
i=1
T A0
i
! Ã I
X
i=1
A0
i
!1
=
Ã I
X
i=1
Ai
!1
T .
(7.20)
Since Cov
³
bbµ, bbµ
0´
is symmetric, we also have
Cov
³bbµ, bbµ
0´
= T
Ã I
X
i=1
A0
i
!1
.
(7.21)
Analogously (because PI
i=1 Bi = I)
Cov
3
Cbbµ,
Ã I
X
i=1
BiXi
!04
D =
3
C
I
X
j=1
Aj
4
D
1 Ã I
X
i=1
Ai Cov (Xi, X0
i) B0
i
!
=
3
C
I
X
j=1
Aj
4
D
1
I
X
i=1
(T B0
i)
=
3
C
I
X
j=1
Aj
4
D
1
T,
(7.22)
with which we have shown (7.19). This ends the proof of Theorem 7.3.
¤
7.2.4 The Quadratic Loss of the Multidimensional Credibility
Estimators
As a rule, we are not primarily interested in the individual components of the
vector µ(), but rather in a linear combination

7.2 The Abstract Multidimensional Credibility Model
175
µ() :=
p
X
k=1
akµk () = a0 µ () .
Let
\
µ() :=
p
X
k=1
ak \
µk () = a0 \
µ ()
be an estimator for µ (). This has the quadratic loss
E
·³
\
µ ()  µ ()
´2¸
= E
·³X
ak
³
\
µk ()  µk ()
´´2¸
= a0 E
·³
\
µ ()  µ ()
´
·
³
\
µ ()  µ ()
´0¸
a
= a0 V 2 a.
It makes sense then to deﬁne the quadratic loss of the vector \
µ () by means
of the matrix V 2.
Deﬁnition 7.4. The quadratic loss matrix of the estimator \
µ () is deﬁned
as
V2 := E
·³
\
µ ()  µ ()
´
·
³
\
µ ()  µ ()
´0¸
,
where the expected value is to be understood componentwise.
We have the following result for the credibility estimator:
Theorem 7.5. The quadratic loss matrix of the multidimensional credibility
estimator \
\
µ(i) (cf. (7.10)) is given by
E
"µ\
\
µ(i)  µ(i)
¶
·
µ\
\
µ(i)  µ(i)
¶0#
= (I  Ai) T = AiSi.
(7.23)
Remarks:
•
Note the similarity between formula (7.23) (multidimensional case) and
formula (4.11) (one dimensional case).
•
Note also, that T and Si are respectively the quadratic loss matrices of µ
and Xi with respect to µ (i) (cf. (7.13) and (7.14)).
Proof of Theorem 7.5: We calculate the quadratic loss matrix:
E
"µ\
\
µ(i)  µ(i)
¶
·
µ\
\
µ(i)  µ(i)
¶0#
= Ai E
£
(Xi  µ(i)) · (Xi  µ(i))0¤
A0
i
+ (I  Ai) E
£
(µ  µ(i)) · (µ  µ(i))0¤
(I  Ai)0
(7.24)
= T (T + Si)1 Si (T + Si)1 T + Si (T + Si)1 T (T + Si)1 Si
= Si (T + Si)1 T = (I  Ai) T,

176
7 Multidimensional Credibility
where we have used in the last step the fact that
Si (T + Si)1 T = T (T + Si)1 Si.
(7.25)
One sees this directly by taking Si and T inside the brackets on both sides,
giving
¡
T 1 + S1
i
¢1 on both sides. Note also, that the right-hand side of
(7.25) is equal to AiSi. This completes the proof of Theorem 7.5.
¤
Theorem 7.6. The quadratic loss matrix of the homogeneous multidimen-
sional credibility estimator is given by
E
"Ã
\
\
µ(i)
hom
 µ(i)
!
·
Ã
\
\
µ(i)
hom
 µ(i)
!0#
= (I  Ai) T
5
7I +
Ã I
X
i=1
A0
i
!1
(I  Ai)0
6
8 .
(7.26)
Remark:
•
Note again the similarity between (7.26) (multidimensional quadratic loss)
and (4.21) (one-dimensional quadratic loss).
Proof of Theorem 7.6: Take µ (i) = a0µ (i) . From Theorem 3.14 we
have
E
5
7
Ã
\
\
µ(i)
hom
 µ(i)
!26
8
= E
"µ\
\
µ(i)  µ(i)
¶2#
+ E
5
7
Ã
\
\
µ(i)  \
\
µ(i)
hom!26
8 .
(7.27)
Since (7.27) holds for all vectors a, we must have for the loss matrices
E
5
7
Ã
\
\
µ(i)
hom
 µ(i)
!
·
Ã
\
\
µ(i)
hom
 µ(i)
!06
8
= E
"µ\
\
µ(i)  µ(i)
¶
·
µ\
\
µ(i)  µ(i)
¶0#
+ E
5
7
Ã
\
\
µ(i)
hom
 \
\
µ(i)
!
·
Ã
\
\
µ(i)
hom
 \
\
µ(i)
!06
8 .
For the ﬁrst summand we have from Theorem 7.5

7.3 The Multidimensional Bühlmann—Straub Model
177
E
"µ\
\
µ(i)  µ(i)
¶
·
µ\
\
µ(i)  µ(i)
¶0#
= (I  Ai) T.
(7.28)
For the second summand, applying (7.16) and (7.20) we get
E
ÃÃ
\
\
µ(i)
hom
 \
\
µ(i)
!
·
Ã
\
\
µ(i)
hom
 \
\
µ(i)
!0!
= (I  Ai) Cov
³
bbµ, bbµ
0´
(I  Ai)0
= (I  Ai) T
3
C
I
X
j=1
A0
j
4
D
1
(I  Ai)0.
Theorem 7.6 is thus proved.
¤
7.3 The Multidimensional Bühlmann—Straub Model
7.3.1 Motivation and Interpretation
In the Bühlmann—Straub model, we have associated with each risk i one-
dimensional observations Xij (j = 1, 2, . . . , n) satisfying certain model as-
sumptions (see Model Assumptions 4.1). In the multidimensional Bühlmann—
Straub model, these observations are multidimensional, i.e. the observation
associated with risk i in year j is itself a vector
X0
ij = (X(1)
ij , X(2)
ij , . . . , X(p)
ij ).
Example 7.1 (layering)
X0
ij = (X(1)
ij , X(2)
ij , . . . , X(p)
ij ),
where
X(1)
ij = the claims ratio (or the claim frequency or the claims average) associ-
ated with the claims in layer 1 (e.g. claims less than CHF 1 000),
X(2)
ij = the claims ratio (or the claim frequency or the claims average) asso-
ciated with the claims in layer 2 (e.g. claims between CHF 1 000 and CHF
50 000),
and so on.
A special case of this example would be the simple dierentiation between
normal claims and large claims, which is equivalent to a two-layer system
(claims under and over a speciﬁc, ﬁxed amount).
An example of claim types are the distinction between pure physical damage
and bodily injury claims in motor liability. Then one might consider

178
7 Multidimensional Credibility
X0
ij =
³
X(1)
ij , X(2)
ij
´
,
where
X(1)
ij = the claims ratio (or the claim frequency) associated with pure physical
damage and
X(2)
ij = the claims ratio (or the claim frequency) associated with bodily injury
claims.
Example 7.2 (dierentiation according to classes)
X0
ij = (X(1)
ij , X(2)
ij , . . . , X(p)
ij ),
where
X(1)
ij = claims ratio in the ﬁrst class,
X(2)
ij = claims ratio in the second class,
and so on.
7.3.2 Deﬁnition of the Model
We are given a portfolio of I risks or “risk categories”, and let
X0
ij = (X(1)
ij , X(2)
ij , . . . , X(p)
ij )
= observation vector (of length p) of the ith risk in year j,
w0
ij = (w(1)
ij , w(2)
ij , . . . , w(p)
ij )
= associated vector of known weights.
Remark:
•
Here, w(k)
ij
denotes the weight associated with the kth component of the
vector Xij. Possibly, w(k)
ij = wij for k = 1, 2, . . . , p, i.e. the weights for the
dierent components can be all the same. This will typically be the case if
we consider claim frequencies, burning costs or claims ratios for dierent
layers numbered 1, 2, . . . , p.
Model Assumptions 7.7 (multidim. Bühlmann-Straub model)
The risk i is characterized by its individual risk proﬁle &i, which is itself the
realization of a random variable i, and we have that:
A1:Conditionally, given i, the Xij, j = 1, 2, . . . , n, are independent with
E [Xij | i] = µ (i)
(vector of length p),
(7.29)
Cov
³
Xij, X
0
ij | i
´
=
3
E
E
E
E
E
E
E
C
2
1(i)
w(1)
ij
0 · · ·
0
0
...
...
...
...
0
0
· · ·
0
2
p(i)
w(p)
ij
4
F
F
F
F
F
F
F
D
.
(7.30)

7.3 The Multidimensional Bühlmann—Straub Model
179
A2: The pairs {(i, Xi) : i = 1, 2, . . . , I}, where X0
i =(X0
i1, X0
i2, . . . , X0
in), are
independent, and 1, 2, . . . are independent and identically distributed.
Remarks:
•
According to (7.30), the components of Xij are assumed to be condition-
ally, given i, uncorrelated. This is the standard case most often encoun-
tered in practice. In the remainder of Section 7.3 we will refer to (7.30) as
the standard assumption.
•
However, if one considers for instance claims ratios of dierent layers, then
this standard assumption is not fulﬁlled any more. In this case, however,
the weights of the dierent components will be identical. Fortunately, all
results of Section 7.3 (multidimensional Bühlmann—Straub) also hold true
under the following:
Alternative assumption to (7.30):
the weights for the dierent components are all the same (w(k)
ij
= wij for
k = 1, 2, . . . , p) and
Cov
³
Xij, X
0
ij | i
´
=
1
wij
P (i) ,
(7.31)
where P (i) is any covariance matrix and not necessarily diagonal. In the
remainder of Section 7.3 we will refer to (7.31) as the alternative standard
assumption.
•
The standard assumption and the alternative standard assumption cover
most cases encountered in practice.
•
A more general assumption on the conditional covariance structure would
be
Cov
³
X(k)
ij , X(l)
ij | i
´
=
Ã
kl (i)
(w(k)
ij w(l)
ij )1/2
!
.
(7.32)
Under this more general assumption, however, the following results are not
generally valid.
Notation:
In the following we will denote by Wij, W 1/2
ij
, W 1
i• , etc. diagonal p × p
matrices with corresponding elements in the diagonal, e.g.
Wij =
3
E
E
C
w(1)
ij
0
...
0
w(p)
ij
4
F
F
D ,
W 1
i• =
3
E
E
E
C
³
w(1)
i•
´1
0
...
0
³
w(p)
i•
´1
4
F
F
F
D .
(7.33)

180
7 Multidimensional Credibility
Remarks:
•
All of the above assumptions on the conditional covariance structure
((7.30), (7.31), (7.32)) can also be written in the following way:
Cov
¡
Xij, X0
ij | i
¢
= W 1/2
ij
	(i) W 1/2
ij
(p × p matrix).
•
The functions µ(·) and 	(·) are independent of i and j. The uncondi-
tional covariance matrix of Xij depends on the individual risk only via
the weights w(k)
ij .
•
It is straightforward to check that in the case where the observations
are one-dimensional, the assumptions of the one-dimensional Bühlmann—
Straub model are satisﬁed.
•
The multidimensional Bühlmann—Straub model does not fully ﬁt into the
framework of the abstract multidimensional credibility model described
in Section 7.2 in that not just one, but many vectors of observations are
available for the ith risk. In order that we can use the results derived in
Section 7.2, we must ﬁrst compress the data in an appropriate manner so
that we have one single observation vector for each risk i.
The following quantities are of interest:
Risk i
Collective/Portfolio
µ (i) = E [Xij| i] ,
µ := E [µ (i)] ,
	 (i) =
¡
WijE
£
Cov
¡
Xij, X0
ij
¯¯ i
¢¤
Wij
¢
, S := E [	 (i)] ,
T := Cov
¡
µ (i) , µ (i)0¢
.
Note that 	 (i) is the conditional covariance normalized for unit weights.
7.3.3 Credibility Formulae in the Multidimensional
Bühlmann—Straub Model
In order to be able to apply Theorem 7.2, for each risk i, we use instead of
Xi1, . . . , Xin (sequence of multidimensional one-period claims ratios) a com-
pressed observation vector Bi (single, multidimensional n-period claims ratio).
We explicitly choose
Bi =
ÃX
j
w(1)
ij
w(1)
i•
X(1)
ij , . . . ,
X
j
w(p)
ij
w(p)
i•
X(p)
ij
!0
,
the average over time of the observations. This choice is intuitive. Also, it is
easy to check (from Theorem A.3 of Appendix A), that
Bi = Pro (µ(i)| Lind
e
(Xi)),

7.3 The Multidimensional Bühlmann—Straub Model
181
where
Lind
e
(Xi) =
n
\
µ(i) : µk(i) =
X
j a(k)
ij Xij for k = 1, . . . , p;
E
h
\
µ(i)
¯¯¯ i
i
= µ(i).
o
Remark:
•
As in Chapter 4 (see remarks on page 150) we denote by Lind
e
(.) the space
of individually unbiased estimators. What that means exactly becomes al-
ways clear from the context. For instance, Lind
e
(Xi) in Pro(µ(i)| Lind
e
(Xi))
is the space of estimators which are linear in the components of Xi and
whose conditional expected value given i is equal to µ(i).
We will see later, that Bi is indeed an allowable compression, i.e. that the
inhomogeneous as well as the homogeneous credibility estimator depend on
the data only via Bi.
In matrix notation
Bi = W 1
i•
n
X
j=1
Wij Xij.
For the compressed data Bi we have that
E [Bi| i] = µ(i),
(7.34)
Cov (Bi, B0
i| i) = W 1
i•
3
C
n
X
j=1
Wij E
£
Cov
¡
Xij, X0
ij
¯¯ i
¢¤
Wij
4
D W 1
i•
= W 1
i• · W 1/2
i•
· 	(i) · W 1/2
i•
· W 1
i•
(7.35)
= W 1/2
i•
	(i) W 1/2
i•
.
Remark:
•
Equation (7.35) would not be generally valid under the general conditional
covariance structure (7.32), but holds true under the standard assumptions
(7.30) or the alternative standard assumption (7.31).
We can now apply Theorem 7.2 to Bi.
Theorem 7.8 (credibility estimator). The (inhomogeneous) credibility es-
timator in the multidimensional Bühlmann—Straub model (Model Assumptions
7.7 or the alternative standard assumption (7.31)) is given by
\
\
µ(i) = Ai Bi + (I  Ai) µ ,
(7.36)
where
Ai = T
³
T + W 1/2
i•
S W 1/2
i•
´1
.
(7.37)

182
7 Multidimensional Credibility
Remarks:
•
Note that under the standard assumption (7.30)
W 1/2
i•
S W 1/2
i•
=
3
E
E
E
C
2
1
w(1)
i•
0
...
0
2
p
w(p)
i•
4
F
F
F
D ,
(7.38)
and that under the alternative standard assumption (7.31)
W 1/2
i•
S W 1/2
i•
=
1
wi•
S,
(7.39)
where
S = E [	(i)] .
•
The credibility matrix is not so easy to interpret. As an example consider
the case where the observation vector is of dimension 2 and where the ﬁrst
component is the frequency of “normal” claims and the second compo-
nent is the frequency of “large” claims. Then a small number in the left
lower corner of the credibility matrix does not necessarily mean that the
inﬂuence of the observed normal claim frequency on the estimated large
claim frequency is small. The reason is that the “normal” claim frequency
might be 100 times bigger than the large claim frequency. In order that
the credibility matrix gives a better picture of the inﬂuence of the dier-
ent observation components on the credibility estimates, it is advisable to
ﬁrst bring the dierent components of the observation vector on the same
scale, i.e. to consider instead of the original observations the normalized
or relative observation vectors
Y0
ij = (Y (1)
ij , Y (2)
ij , . . . , Y (p)
ij ),
where
Y (k)
ij
:=
X(k)
ij
µk
.
Then the entries of the credibility matrix reﬂect much better the inﬂuence
of the corresponding observation components and the credibility estimator
becomes
\
\
µ(i) = Ai Bi + (I  Ai) 1.
•
Explicit formulae of the credibility matrix in the case of two dimensions
can be found in Exercise 7.3 and in Exercise 7.4.
Proof of Theorem 7.8:
From Theorem 7.2 we know that \
\
µ(i) is the credibility estimator based on
Bi. It remains to show that \
\
µ(i) is also the credibility estimator based on

7.3 The Multidimensional Bühlmann—Straub Model
183
all data (admissibility of the compression Bi). To do this we must check the
orthogonality conditions
µ(i)  \
\
µ(i) B Xkj
for all k, j.
(7.40)
For k 6= i we have that (7.40) holds because of the independence of the risks.
It then remains to show (7.40) for k = i,
E
£
(µ(i)  AiBi  (I  Ai) µ) · X0
ij
¤
= AiE
£
(µ(i)  Bi) X0
ij
¤
+ (I  Ai)E
£
(µ(i)  µ) X0
ij
¤
.
(7.41)
From
Bi = Pro(µ(i)| Lind
e
(Xi))
it follows that
E
£
(µ(i)  Bi) X0
ij
¤
= E [(µ(i)  Bi) B0
i]
= E
£
(µ(i)  Bi) (Bi  µ(i))0¤
= E [Cov (Bi, B0
i| i)]
= W 1/2
i•
S W 1/2
i•
.
(7.42)
For the second summand in (7.41), we get by conditioning on i
E
£
(µ(i)  µ) X0
ij
¤
= E [(µ(i)  µ) µ(i)0]
= E
£
(µ(i)  µ) (µ(i)  µ)0¤
= T.
(7.43)
Plugging (7.42) and (7.43) into (7.41) we see that
E
£
(µ(i)  AiBi  (I  Ai) µ) · X0
ij
¤
= Ai
³
W 1/2
i•
S W 1/2
i•
+ T
´
+ T
= T + T
= 0.
This completes the proof of Theorem 7.8.
¤
Theorem 7.9 (homogeneous credibility estimator). The homogenous
credibility estimator in the multidimensional Bühlmann—Straub model (Model
Assumptions 7.7 or the alternative assumption (7.31)) is given by
\
\
µ (i)
hom
= Ai Bi + (I  Ai) bbµ,
(7.44)
where
bbµ =
Ã I
X
i=1
Ai
!1
I
X
i=1
AiBi.
(7.45)

184
7 Multidimensional Credibility
Proof:
It follows from Theorem 7.3 that (7.44) is the homogeneous credibility esti-
mator based on the statistic of the Bi. We will show later, in a more general
framework (cf. Section 7.4, Theorem 7.14), that the Bi are a linear su!cient
statistic, which means that the credibility estimators depend on the data only
through this statistic. This concludes the proof of Theorem 7.9.
¤
The next theorem shows that the balance property of the homogeneous
credibility estimator formulated in Theorem 4.5 holds also componentwise in
the multidimensional model.
Theorem 7.10 (balance property). Given Model Assumptions 7.7 or the
alternative standard assumption (7.31) we have for each component
X
ij w(k)
ij
\
\
µk (i)
hom
=
X
ij w(k)
ij X(k)
ij
for k = 1, 2, . . . , p.
(7.46)
Remark:
•
As an example, assume that we want to estimate the burning cost (or the
claim frequency or the claim average) for “normal” and “large” claims.
Theorem 7.10 then guarantees that the homogeneous credibility estimator
applied to the past observation period and weighted over the whole port-
folio coincides with the observed average burning cost (claim frequency,
claim average) for each component (e.g. normal and large claims).
Proof of Theorem 7.10:
(7.46) is equivalent to
I
X
i=1
W 1/2
i•
Ã
\
\
µ (i)
hom
 Bi
!
W 1/2
i•
= 0.
I
X
i=1
W 1/2
i•
Ã
\
\
µ (i)
hom
 Bi
!
W 1/2
i•
=
I
X
i=1
W 1/2
i•
³
W 1/2
i•
S W 1/2
i•
´ ³
T + W 1/2
i•
S W 1/2
i•
´1 ³
bbµ  Bi
´
W 1/2
i•
=
I
X
i=1
W 1/2
i•
³
W 1/2
i•
S W 1/2
i•
´
W 1/2
i•
³
T + W 1/2
i•
S W 1/2
i•
´1 ³bbµ  Bi
´
= S T 1
I
X
i=1
T
³
T + W 1/2
i•
S W 1/2
i•
´1 ³
bbµ  Bi
´

7.3 The Multidimensional Bühlmann—Straub Model
185
= S T 1
I
X
i=1
Ai
³bbµ  Bi
´
= 0.
¤
7.3.4 Quadratic Loss
The quadratic loss of the multidimensional credibility estimators is directly
given by Theorem 7.5 and Theorem 7.6, where the credibility matrix Ai is
given by (7.37) and where Si = W 1/2
i•
S W 1/2
i•
is given by (7.38) (standard
assumption) or by (7.39) (alternative standard assumption).
7.3.5 Estimation of Structural Parameters
Already in the remarks to Model Assumptions 7.7 several forms of the covari-
ance matrix 	 (i) and, as a consequence, of the matrix S were discussed. In
the standard situation, these matrices are assumed to be diagonal. Below we
give estimators for this standard situation.
The diagonal elements of S and T can be estimated in the same way as the
structural parameters in the one-dimensional Bühlmann—Straub model. For
the non-diagonal elements of T we can use analogous statistics. This leads to
the following estimators:
Diagonal elements of S:
c
2
k = 1
I
I
X
i=1
1
n  1
n
X
j=1
w(k)
ij
³
X(k)
ij  B(k)
i
´2
.
Diagonal elements of T:
c
 2
k = min
³f
 2
k , 0
´
,
where
f
 2
k = c ·
(
I
I  1
I
X
i=1
w(k)
i•
w(k)
••
³
B(k)
i
 B
(k)´2
 Ic
2
k
w(k)
••
)
,
where c = I  1
I
( I
X
i=1
w(k)
i•
w(k)
••
Ã
1  w(k)
i•
w(k)
••
!)1
,
B
(k) =
I
X
i=1
w(k)
i•
w(k)
••
B(k)
i
.

186
7 Multidimensional Credibility
non-diagonal elements of T:
a straightforward calculation shows that the following two estimators are un-
biased estimators of  kl:
f
 kl
 = c1 ·
(
I
I  1
I
X
i=1
w(k)
i•
w(k)
••
³
B(k)
i
 B
(k)´ ³
B(l)
i
 B
(l)´)
,
where c1 = I  1
I
( I
X
i=1
w(k)
i•
w(k)
••
Ã
1  w(k)
i•
w(k)
••
!)1
,
f
 kl
 = c2 ·
(
I
I  1
I
X
i=1
w(l)
i•
w(l)
••
³
B(k)
i
 B
(k)´ ³
B(l)
i
 B
(l)´)
,
where c2 = I  1
I
( I
X
i=1
w(l)
i•
w(l)
••
Ã
1  w(l)
i•
w(l)
••
!)1
.
Since  2
kl   2
k  2
l , we suggest the following estimators:
c
 kl = signum
µ f
 kl
 + f
 kl

2
¶
· min
Ã¯¯f
 kl
 + f
 kl
¯¯
2
,
q
c
 2
k · b 2
l
!
.
(7.47)
Remarks:
•
If there is more structure in the model, then this structure should be
taken into account. For instance, if we apply multidimensional credibility
to estimate claim frequencies and if we assume the claim numbers to be
Poisson distributed, then we can use this structure to use another estimator
for 2
i analogously to those discussed in Section 4.10.
•
Since T is a covariance matrix, it is positive deﬁnite. However, for dimen-
sion p  3, the matrix bT resulting from (7.47) is not necessarily positive
deﬁnite. To achieve positive deﬁniteness the following procedure is often
applied in statistics: ﬁnd an orthogonal transformation O, such that
eT := O · bT
is diagonal. If all diagonal elements of eT are  0, then bT is positive deﬁ-
nite. If not, then replace the negative diagonal elements of eT by zero and
transform back to get a modiﬁed, positive (more precise: nonnegative def-
inite) deﬁnite estimator for T. The orthogonal transformation matrix O is
obtained by taking the eigenvectors of bT as columns of O.
An alternative to (7.47) is to take as “starting point” the matrix bT  with
the entries
c
 kl
 =
µ f
 kl
 + f
 kl

2
¶
(7.48)
and then to apply the above orthogonal transformation procedure on bT .

7.4 General Remarks About Data Compression and Its Optimality
187
7.4 General Remarks About Data Compression and Its
Optimality
7.4.1 Introduction
The basic idea behind multidimensional credibility is that the quantity µ()
to be estimated is multidimensional, i.e. a vector of length p. In Section 7.2
we assumed that in the “abstract” situation, there is exactly one data vector
X having the same dimension as µ(), for which we have E [X| ] = µ().
We have pointed out that in this “abstract” framework, the data vector X
is, as a rule, not the same as the observation vector, but is in most cases an
appropriate compression of the original data. We have, until now, left open the
question as to how one accomplishes this compression without losing relevant
information. In Section 7.3 we have shown what the data compression looks
like in the multidimensional Bühlmann—Straub model.
The reader who wants to understand what to do if X has a lower dimension
than the estimand µ() is referred to Chapter 10.
In this section we consider, quite generally, what the appropriate com-
pression is in the multidimensional case. We will see the validity of the intu-
itive general principle. We will also see that the compressed data are a linear
su!cient statistics, i.e. that the inhomogeneous as well as the homogeneous
credibility estimators depend only on the compressed data.
First, however, we want to investigate if we could proceed in another way,
in that we summarize all the data associated with one contract into one vector
X and then deﬁne the vector to be estimated as
µ() :=E [X| ] .
As mentioned in Section 7.2, we are in principle free in the choice of the vector
µ(). With this deﬁnition, we would be in the set-up of the deﬁned abstract
multidimensional credibility model described in Section 7.2, and we could ap-
ply the theory that we derived there. This procedure is theoretically correct,
but is not to be recommended. It leads to unnecessarily complicated inver-
sion of high-dimensional matrices. The problem is that we would be working
in too high a dimension. For example, in the simple (not multidimensional!)
Bühlmann—Straub model, the vector µ() would be composed of n compo-
nents all of which are equal to µ () . In this way we make a one-dimensional
problem into a complicated multidimensional problem. In general, we should
try to keep the dimension of µ() minimal: in particular, the elements of
µ() should not be linearly dependent.
7.4.2 General Multidimensional Data Structure
We assume the following, very general data structure. For each risk i = 1, . . . , I
let

188
7 Multidimensional Credibility
µ(i)0 = (µ1(i), . . . , µp(i))
be the vector to be estimated and let
X0
i = (X0
i1, X0
i2, . . . , X0
ini)
be the vector of observations.
In this general structure, multidimensional means that the vector to be
estimated, µ(i), is multidimensional, i.e. the length p is greater than one. On
the other hand, we summarize all “raw” observations associated with the ith
risk, whether one-dimensional or multidimensional, in one large observation
vector Xi.
Notice that we do not make any assumptions about the internal probability
structure of the vector Xi. In particular, some components can be (non-linear)
functions of the same observed random variable, e.g.
Xi1 = Y,
Xi2 = Y 2,
Xi3 = log Y,
etc.
The variables we choose to use as components depend on the vector µ(i)
which we want to estimate. For example, in the multidimensional Bühlmann—
Straub model, if we wanted to estimate the individual variances as well, then
we would also need beside
X0
ij = (X(1)
ij , . . . , X(p)
ij )
the vector of squared observations
Z0
ij = ((X(1)
ij )2, . . . , (X(p)
ij )2).
In this case the vector Xi would be the listing of all the relevant quantities
for the ith risk, i.e.
X0
i = (X0
i1, Z0
i1, X0
i2, Z0
i2, . . . , X0
in, Z0
in).
With this interpretation of the vector Xi of all observed variables, we can
assume that there exists a matrix Ci with the property that
E [CiXi| i] = µ(i),
i.e. µ(i) is linearly estimable from the data Xi.
On the other hand, the vectors Xi should not be too rich. For this reason
we make the additional assumption, that the conditional expectation of each
component of the vector Xi can be written as a linear combination of the
components of µ(i). In other words, the linear space spanned by the vectors
E [Xi| i] should be the same as the linear space spanned by the components
of µ(i). These considerations lead to the following model assumptions:
Model Assumptions 7.11
We are given a portfolio of I risks. Each risk i (i = 1, 2, . . . , I) is characterized
by its individual (unknown) risk proﬁle &i, which is itself the realization of a
random variable i. We assume that

7.4 General Remarks About Data Compression and Its Optimality
189
MD1: For each i there exists a matrix Yi for which conditionally, given i,
E [Xi| i] = Yi µ(i),
(7.49)
where Yi is a ni × p matrix of rank p.
MD2: The pairs (1, X1), (2, X2) , . . . are independent, and 1, 2, . . . are
independent and identically distributed.
Remarks:
•
On MD1: In the typical multidimensional credibility model, e.g. in the
multidimensional Bühlmann—Straub model, the matrix Yi is composed en-
tirely of the elements 1 and 0. In the regression case, which we will discuss
in the next chapter, the elements of Yi can be any real numbers for con-
tinuous covariates and 0 or 1 for categorical covariates.
•
By pre-multiplying (7.49) with Ci = (Y 0
i , Yi)1 Y 0
i we get
µ(i) = Ci E [Xi| i]
(7.50)
where Ci is a p × ni matrix of rank p.
7.4.3 Optimal Data Compression
By optimal data compression we mean the reduction of the vector Xi to a
vector Bi, having the same dimension as the vector µ(i) which is to be
estimated, without being penalized by losing precision, i.e. the credibility es-
timator depends on the data only through Bi. The following theorem shows
how the optimal compression looks under Model Assumptions 7.11.
Theorem 7.12 (optimal data compression in the multidimensional
case). The optimal data compression is given by
Bi := Pro (µ(i)| Lind
e
(Xi)),
(7.51)
where
Lind
e
(Xi) =
n
\
µ(i) : µk(i) =
X
j a(k)
ij Xij for k = 1, . . . , p;
E
h
\
µ(i)
¯¯¯ i
i
= µ(i).
o
Remarks:
•
Note that, because of MD1, the subspace Lind
e
(Xi) is not empty.
•
As in Chapter 6 (see remarks on page 150) we denote by Lind
e
(.) the
space of individually unbiased estimators. As in Chapter 6, the notation
of Lind
e
(.) does not reﬂect what quantity we want to estimate and what
the individual unbiasedness condition exactly means. However, this always
becomes clear from the context. For instance, it is clear how Lind
e
(Xi) in
(7.51) has to be interpreted: it is the space of estimators of µ(i) which
are linear in the components of Xi and whose conditional expected value
given i is equal to µ(i).

190
7 Multidimensional Credibility
Proof of Theorem 7.12:
We have to show that under Model Assumptions 7.11 the credibility estimator
depends on the observations Xi only via Bi. This is a consequence of the
following theorem.
¤
Theorem 7.13 (credibility estimator). The (inhomogeneous) credibility
estimator under Model Assumptions 7.11 is given by
\
\
µ(i) = AiBi + (I  Ai) µ,
(7.52)
where Ai = T (T + Si)1 ,
(7.53)
µ = E [µ(i)] ,
Si = E [Cov (Bi, B0
i| i)] ,
T = Cov
¡
µ (i) , µ (i)0¢
.
Remarks:
•
Because of the independence of the risks, the inhomogeneous credibility
estimator \
\
µ(i) depends only on the data from the ith risk.
•
Note that
Si = E
£
(Bi  µ (i)) (Bi  µ (i))0¤
= quadratic loss matrix of Bi (with respect to µ (i)),
T = E
¡
(µ  µ (i)) (µ  µ (i))0¢
= squared loss matrix of µ (with respect to µ (i)).
From this we see that (7.52) corresponds again to the general intuitive
principle that the credibility estimator is a weighted average of Bi (best
individual, unbiased estimator based on the data) and µ (best estima-
tor based on a priori knowledge) with weights being proportional to the
corresponding precisions (inverse of the quadratic loss).
•
The quadratic loss of the credibility estimator (7.52) is given by Theorem
7.5.
Proof of Theorem 7.13:
According to Theorem 7.2, (7.52) is the credibility estimator based on Bi and
therefore
µ(i)  \
\
µ(i) B Bi.
We must also show that this is the credibility estimator based on all the data,
i.e. that
µ(i)  \
\
µ(i) B Xi.
(7.54)
Hence (7.54) is equivalent to
µ(i)  \
\
µ(i) B Xi  YiBi,
(7.55)

7.4 General Remarks About Data Compression and Its Optimality
191
where Yi is the matrix given by (7.49). We can rewrite the left-hand side of
the above equation:
µ(i)  \
\
µ(i) = Ai (µ(i)  Bi) + (I  Ai) (µ(i)  µ) .
We ﬁrst show that the ﬁrst summand µ(i)  Bi B Xi  YiBi. Since Bi =
Pro(µ(i)| Lind
e
(Xi)) and YiBi = Pro(Yiµ(i)| Lind
e
(Xi)), we have
Yi (µ(i)Bi) B Xi  YiBi.
(7.56)
Since Yi has rank p, the left-hand side is composed of p linearly independent,
linear combinations of µ(i)  Bi, all of which are orthogonal to Xi  YiBi.
From this it follows that all of the components of µ(i)  Bi are orthogonal
to XiYiBi. (Formally, we can also calculate this by multiplying the left-hand
side of (7.56) by the matrix Ci given by (7.50), and then using the identity
CiYi = I (all matrices are of rank p).)
The orthogonality of the second summand µ(i)  µ is easy to see. If we
condition on i, we get that
E
£
(µ(i)  µ) · (Xi  YiBi)0¤
= 0.
This completes the proof of Theorem 7.13.
¤
The compression Bi contains, as we saw above, the full information of
the data in the inhomogeneous credibility formula. We would be surprised if
Bi did not also contain the full information for the homogeneous credibility
estimator. We formulate this fact in the next theorem.
Theorem 7.14 (linear su!cient statistic). {Bi : i = 1, 2, . . . , I} is a lin-
ear su!cient statistic, i.e. both the inhomogeneous and the homogeneous cred-
ibility estimator depend on the data only through this statistic.
Remark on the notation:
•
In the following proof and in the remaining part of this subsection, capital
I is used for the number of risks in the portfolio as well as for the identity
matrix. However the meaning of I is always clear from the context.
Proof of Theorem 7.14: We have already shown in Theorem 7.13 that the
inhomogeneous credibility estimator depends only on Bi. It remains only to
show that this is also true for the homogeneous credibility estimator. Accord-
ing to Theorem 7.13 we have that
\
\
µ(i) = Pro (µ(i)| L(1, X1, . . . , XI)) = AiBi + (I  Ai) µ.
Therefore, because of the normalized linearity property of projections on a!ne
spaces we have that

192
7 Multidimensional Credibility
\
\
µ (i)
hom
:= Pro (µ(i)| Le(X1, . . . , XI))
= Ai Bi + (I  Ai) bbµ ,
(7.57)
where bbµ = Pro (µ| Le(X1, . . . , XI)) .
By ﬁrst projecting on a larger space and using the iterativity property we get
bbµ = Pro (Pro (µ| Le(X1, . . . , XI, µ(1), . . . , µ(I)))| Le(X1, . . . , XI)).
It is intuitively obvious and easy to prove that
Pro (µ| Le(X1, . . . , XI, µ(1), . . . , µ(I))) = 1
I
I
X
i=1
µ (i) .
From the above equations we obtain
bbµ = Pro
Ã
1
I
I
X
i=1
µ (i)| Le(X1, . . . , XI)
!
= 1
I
I
X
i=1
\
\
µ (i)
hom
= 1
I
I
X
i=1
n
AiBi + (I  Ai) bbµ
o
.
(7.58)
In (7.58) only the compressed data vectors Bi appear, which completes the
proof of Theorem 7.14.
¤
Corollary 7.15 (homogeneous credibility estimator). The homogeneous
credibility estimator under Model Assumptions 7.11 is
\
\
µ (i)
hom
= Ai Bi + (I  Ai) bbµ ,
(7.59)
where Ai was deﬁned in (7.52) and where
bbµ =
Ã I
X
i=1
Ai
!1
I
X
i=1
AiBi.
(7.60)
Proof:
From (7.58) we get
I
X
i=1
AiBi 
Ã I
X
i=1
Ai
!
bbµ = 0.
The corollary then follows from (7.57).
¤
Remark
•
The quadratic loss of the homogeneous credibility estimator is given by
Theorem 7.6.

7.5 Exercises
193
7.5 Exercises
Exercise 7.1
Consider the situation of Exercise 6.1. Calculate the values of the (empirical)
homogeneous credibility estimators for each risk group i by considering the
observed claims ratios B(1)
i
(own company data) and B(2)
i
(other companies’
data) simultaneously. Assume that Model Assumptions 7.7 are fulﬁlled for the
tuples (B(1)
i
, B(2)
i
).
Beside the point estimates, calculate the same measure of precision as in
Exercise 6.1.
Exercise 7.2
Consider the same data set as in Exercise 4.6 and Exercise 6.2. We are in
particular interested in estimating the large claim frequency by making best
use of the data.
Calculate the homogeneous credibility estimator for the large claim fre-
quency in relative terms by looking for each risk group A1,. . . , B5 at the
observed standardized frequencies of both normal and large claims.
Remarks:
•
In order that the credibility matrix becomes easier to interpret, it is ad-
visable to bring both components onto the same scale and to look at the
standardized rather than at the absolute claim frequencies, where the stan-
dardized claim frequency for risk group i and component k is deﬁned as
eFi
(k) = F (k)
i
/F (k)
•
, where F (k)
•
is the observed claim frequency over the
whole collective. Note that eFi
(k) = N (k)
i• /(k)
i• , where (k)
i• = w(k)
i• F (k)
•
, i.e.
eFi
(k)is the frequency with respect to the weight (k)
i• .
•
Assume that the claim numbers are Poisson distributed. Estimate the
structural parameters 2
k and µk with an analogous iterative procedure
as described in Section 4.10 following Corollary 4.8, but now adapted to
the multidimensional case.
Exercise 7.3
Work with Model Assumptions 7.7. Assume that the observation vectors Xij
have dimension 2 and that the weights are equal for both components, i.e.
w(1)
ij = w(2)
ij = wij.
Show that the credibility estimators are then given by
\
\
µl (i) = µl + a(i)
l1 (B(i)
1
 µ1) + a(i)
l2 (B(i)
2
 µ1),
l = 1, 2,

194
7 Multidimensional Credibility
with credibility weights
a(i)
11 =
wi•
wi• + 1
µ
1 +
2
12+ 2
wi•
¶,
a(i)
22 =
wi•
wi• + 2
µ
1 +
2
12+ 1
wi•
¶,
a(i)
12 =

wi•
1
2
s12
³
1 +
1
wi•
´ ³
1 +
2
wi•
´
 2 ,
a(i)
21 =

wi•
2
1
s12
³
1 +
1
wi•
´ ³
1 +
2
wi•
´
 2 ,
where
l = 2
l
 2
l
, l = 1, 2,
 =  12
 1 2
=
Cov (µ1 (i) ,µ2 (i))
p
Var [µ1 (i)] · Var [µ2 (i)]
.
Exercise 7.4
Use the same model as in Exercise 7.3 (two-dimensional observations with
equal weights for the components), but now for the claim frequencies and
under the assumption that the claim numbers are conditionally, given i,
Poisson distributed.
a) Show that the credibility estimators for the standardized claim frequencies
ek (i) = k (i) /k are then given by
\
\
ek (i) = 1 + a(i)
k1 · ( eF (i)
1
 1) + a(i)
k2 · ( eF (i)
2
 1),
with credibility weights

7.5 Exercises
195
a(i)
11 =
(i)
1
(i)
1 + e1
Ã
1 +
2
12+ e2
(i)
2
!,
a(i)
12 =  ·
rµ2
µ1
·
q
e1
(i)
1
e2
(i)
2
µ
1 +
e1
(i)
1
¶ µ
1 +
e2
(i)
2
¶
 2
,
a(i)
21 =  ·
rµ1
µ2
·
q
e1
(i)
1
e2
(i)
2
µ
1 +
e1
(i)
1
¶ µ
1 +
e2
(i)
2
¶
 2
,
a(i)
22 =
(i)
2
(i)
2 + e2
Ã
1 +
2
12+ e1
(i)
1
!,
where
eF (i)
l
= observed relative frequencies, l = 1, 2,
el = Var
³
el (i)
´1
= CoVa (l (i))2 ,
l = 1, 2,
(i)
l
= wi•l = a priori expected claim number.
Remark:
Note that
el = l l.
b) Discuss the special cases  = 0 and  = 1.
Exercise 7.5
An actuary wanting to estimate the large claim frequency for dierent regions
is often faced with the following problem: the claims experience in some of the
small regions is very small and such regions get very small credibility weights
when applying the Bühlmann—Straub model. Often, neighbouring small re-
gions are then put together and treated as one and the same region. Indeed,
the risk proﬁles of neighbouring regions might often be similar, one reason
being that people living in one region are often driving to the neighbouring
region for work.
The conclusion is that there might be correlations between the risk proﬁles
of dierent regions and that this correlation might depend on the distance
between the regions.

196
7 Multidimensional Credibility
This situation can again be modelled with the multidimensional model. For
illustrative purposes and in order to better see the mechanics, we consider the
following simple situation with four regions.
Let Nk be the number of large claims in region k and let us assume that
the number of a priori expected claims k is known and is the same for all
regions, i.e. k =  for k = 1, 2, . . . , 4. The claim numbers Nk are assumed to
be conditionally Poisson distributed with Poisson parameter k = k and
that
E [k] = 1,
Var [k] = 0.22,
Corr
¡
, 0¢
=
3
E
E
C
1
0.2 0.2
0
0.2
1
0.2 0.7
0.2 0.2
1
0.7
0
0.7 0.7
1
4
F
F
D .
We want to estimate k for each region k < 1, 2, . . . , 4.
a) Calculate the multidimensional credibility matrix for  = 5, 10, 20.
b) Do you have an explanation as to why the credibility weight a14 6= 0, even
though the regions 1 and 4 are uncorrelated?
c) Calculate the values of the multidimensional credibility estimators if  = 5
and if the following observations have been made:
N1 = 1, N2 = 3, N3 = 6, N4 = 10.
d) The same as in c), but now by applying the Bühlmann—Straub model and
hence neglecting the correlations between the regions.
e) Compare the results of c) and d).
Exercise 7.6
In group life insurance, a company would like to estimate “individual disabil-
ity” curves in order to implement experience rating. Denote by ix the basis
disability curve showing the a priori disablement probabilities for the ages
x = 16, 17, . . . , 65. The aim is to estimate for the contracts i = 1, 2, . . . , I
individual disability curves iix.
For simplicity the company considers instead the ages x = 16, 17, . . . , 65 the
age groups A1 = [16, 20] , A2 = [21, 25] , . . . , A10 = [60, 65] . For a particular
contract the following observations have been made, where k denotes the
number of a priori expected disability cases according to the basis disability
curve ix and Nk the number of observed disability cases in the age groups Ak,
k = 1, 2, . . . , 10.

7.5 Exercises
197
age group
Qk
Nk
16-20
1.60
0
21-25
1.71
0
26-30
1.46
0
31-35
2.45
1
36-40
3.06
2
41-45
4.15
3
46-50
5.28
6
51-55
6.92
8
56-60
9.71
11
61-65
13.16
16
Total
49.50
47
As a basic model assumption we assume that the observed claim num-
bers Nk are conditionally Poisson distributed with Poisson parameter k =
kk and E [k] = 1. From portfolio knowledge the actuaries estimate the
dierences between contracts to be about ±25%, i.e. it is assumed that
p
Var (k) = 25%. The task is again to estimate k for k = 1, 2, . . . , 10.
a) Assume that the shape of the individual disability curve is the same as
the one of the basis disability curve, i.e. iix =  · ix respectively k = 
for k = 1, 2, . . . , 10. Estimate  by looking only at the ratio N•/• (total
observed number of disabilities divided by the total number of expected
number of disabilities) and by making use of the result of Corollary 4.10
(compare also with the methodology of Exercise 2.3).
b) As in a), but estimate now k by looking only at the ratio Nk/k of each
age group k = 1, 2, . . . , 10 separately.
c) Assume now that Corr(k, l) = |kl|. Calculate the values of the mul-
tidimensional credibility estimator for k, k = 1, 2, . . . , 10. Do the calcu-
lations for  = 0, 0.25, 0.50, 0.75, 1.00.
d) Compare the results found in c) together with the observed standardized
frequencies eFk = Nk/k for the dierent values of .
Compare the results for  = 0 and for  = 1 with the ones found in a) and
b).

8
Credibility in the Regression Case
8.1 Motivation
A real problem from insurance practice was the motivation for the well-known
paper by Hachemeister [Hac75]. Hachemeister wanted to forecast average
claim amounts for bodily injury claims in third party auto liability for various
states in the USA. Such data is aected by time trends due to inﬂation, so
that the homogeneity assumption of the Bühlmann—Straub model (E [Xij| i]
being independent of j) is not appropriate.
On ﬁtting regression lines to the data “observed average claim amounts
versus time”‚ Hachemeister noticed considerable dierences between the states
both in the slope of the ﬁtted regression line and in its intercept. He also
noticed that in particular the estimation of the slope was not reliable for the
“smaller” states due to the small sample sizes. It was natural to ﬁt also a
regression line to the country-wide data (data of all states together). Then
the question arises as to how much weight one should assign to the individual
regression line of a particular state based on the data of that state alone and
the regression line based on the collective experience for all the states.
Hachemeister’s work was, therefore, motivated by a practical problem
based on simple linear regression. However, he formulated the problem and
its solution, for the more general case of a general multiple regression model.
Before introducing the credibility regression model, in the next section we
summarize some results from classical regression theory. These results are
used to ﬁt a linear model (e.g. a regression line) to the individual data of
a particular risk (e.g. the claim sizes of a particular state in Hachemeister’s
problem).
8.2 The Classical Statistics Point of View
The general linear model in classical statistics is given by

200
8 Credibility in the Regression Case
X = Y ·  + %,
(8.1)
where X = obs. vector (elements are random variables) of dim. n × 1,
Y = known design matrix of dimension n × p (p  n),
 = unknown parameter vector of dimension p × 1,
% = vector of the random deviations of dimension n × 1,
with E [%] = 0 and Cov (%, %0) = 	,
i.e. the vector of random deviations has expected value zero and its covariance
matrix is denoted by 	. In the following we always assume that Y is of full
rank p.
Remark:
•
Important special cases are:
—
ordinary least squares
Then
	 = 2 · I .
(8.2)
—
weighted least squares
Then
	 = 2 · W 1,
(8.3)
where W =
3
E
C
w1
0
...
0
wn
4
F
D ,
w1, . . . , wn are known weights.
The following theorem is given without proof and can be found in most
books on classical statistics (e.g. [Wei05], [SL03]).
Theorem 8.1. The best linear unbiased estimator (BLUE) of  is given by
b =
¡
Y 0	1Y
¢1 Y 0	1X.
(8.4)
The covariance matrix of b is
	b =
¡
Y 0	1Y
¢1 .
(8.5)
Remarks:
•
In the case of ordinary least squares
¡
	 = 2 · I
¢
we have
b = (Y 0Y )1 Y 0X
and
	b = 2 · (Y 0Y )1 .

8.3 The Regression Credibility Model
201
•
In the case of weighted least squares
¡
	 = 2 · W 1¢
we have
b = (Y 0WY )1 Y 0WX
and
	b = 2 · (Y 0WY )1 .
(8.6)
•
“Best” estimator means that
E
·³
bi  i
´2¸
!= minimum
for i = 1, 2, . . . , p.
It is remarkable that this best estimator can be derived from the data as
the least squares estimator, i.e.
c
 =
;
A
A
A
A
A
A
A
A
A
A
A
?
A
A
A
A
A
A
A
A
A
A
A
=
arg min
1,...,p
nP
j=1
(Xj  (Y )j)2
for P = 2 · I,
arg min
1,...,p
nP
j=1
wj (Xj  (Y )j)2
for P = 2 · W 1,
arg min
1,...,p
nP
i,j=1
(Xi  (Y )i) 	1
ij (Xj  (Y )j) in the general case.
•
In classical statistics it is often further assumed that the %i’s are normally
distributed. If the %i’s are normally distributed, then the least squares
estimators are the best unbiased estimators of all unbiased estimators (not
just of all linear unbiased estimators). We usually do not make this further
assumption.
8.3 The Regression Credibility Model
We are given a portfolio of I risks and we let
X0
i = (Xi1, Xi2, . . . , Xin)
be the observation vector of the ith risk and w0
i = (wi1, . . . , win) the vector
of the associated known weights. For instance, in the Hachemeister problem
the entries Xij are the claims averages of state i in the quarter j and wij are
the corresponding number of claims.
We then assume that conditionally, given i, Xi fulﬁls the regression equa-
tion (8.1). This assumption leads to an interpretation of the regression vector
 which is somewhat dierent to that used in classical statistics: we do not
consider the components of  as ﬁxed quantities (which are unknown and
therefore must be estimated), but rather as random variables, having distrib-
utions which are determined by the structure of the collective. These consid-
erations lead us to the credibility regression models of Subsections 8.3.1 and
8.3.2.

202
8 Credibility in the Regression Case
8.3.1 The Standard Regression Model
Model Assumptions 8.2 (standard regression case)
The risk i is characterized by an individual risk proﬁle &i, which is itself the
realization of a random variable i. We make the following assumptions:
R1: Conditionally, given i, the entries Xij, j = 1, 2, . . . , n are independent
and we have
E [Xi | i]
|
{z
} = Yi
|{z} ·
 (i)
| {z } ,
(8.7)
n × 1
n × p
p × 1
where  (i) = regression vector of length p  n,
with linearly independent components,
Yi = known “design” matrix of rank p,
Var [Xij| i] = 2 (i)
wij
.
(8.8)
R2: The pairs (1, X1), (2, X2),. . . are independent, and 1, 2,. . . are
independent and identically distributed.
Remarks:
•
Assumption R1 means that conditionally, given i, the observations Xij
(j = 1, 2, . . . , n) fulﬁl the classical weighted regression assumptions (8.1)
and (8.3). The columns of the design matrix Yi correspond to the observed
design variables. Assumption R2 is the usual assumption that the risks are
independent of each other.
•
From the conditional independence and condition (8.8) follows that
Cov (Xi, X0
i| i) = 2 (i) · W 1
i
,
(8.9)
where Wi =
3
E
C
wi1
0
...
0
win
4
F
D .
•
All results in this subsection also hold true if the somewhat weaker condi-
tion
Si = E [Cov (Xi, X0
i| i)] = 2 · W 1
i
(8.10)
is fulﬁlled. This will become clear from the proofs of Subsection 8.3.2.
•
For the case where n < p and Yi is not of full rank p, we refer to the
remarks on page 242 relating to Corollary 9.9 in Section 9.7.
The goal is to determine the individual premium µa (i) = E [Xa| i] for
any given design vector a0 = (a1, a2, . . . , ap). Given the regression model, the
quantity of interest is therefore of the form

8.3 The Regression Credibility Model
203
µa (i) = a0  (i) .
(8.11)
In order to determine the credibility estimator for µa (i) for any a, we must
determine the credibility estimator for the vector  (i).
Notice that R1 and R2 are fully compatible with the assumptions MD1
and MD2 (Model Assumptions 7.11) for multidimensional credibility. We can
therefore directly apply the results from Chapter 7 (Theorem 7.13 and Corol-
lary 7.15). According to Theorem 7.14, in order to construct the credibil-
ity estimator, we need to ﬁnd a formula for the optimal data compression
Bi = Pro((i)| Lind
e
(Xi)).
Before we do that, we deﬁne the structural parameters in the standard
regression model and we look at a few examples. These structural parameters
are given by

|{z}
p×1
:= E [ (i)] ,
2 := E
£
2 (i)
¤
,
T
|{z}
p×p
:= Cov
¡
 (i) ,  (i)0¢
.
Remark:
•
In the following we always assume that T is of full rank.
The ﬁrst moment is given by
E [Xi| i] =
3
E
C
1
...
1
4
F
D µ (i) .
Here  (i) is one-dimensional and we have
 (i) = µ (i) ,
Yi = (1, . . . , 1)0 .
Example 8.1 (simple linear regression)
E [Xij | i] = 0 (i) + j1 (i)
or in matrix notation
E [Xi| i] =
3
E
E
E
E
E
E
C
1
1
1
2
...
3
...
...
1
n
4
F
F
F
F
F
F
D
|
{z
}
= Yi
µ0 (i)
1 (i)
¶
|
{z
}
= (i)
.

204
8 Credibility in the Regression Case
Next we derive the formula of the credibility estimator by use of the results
from multidimensional credibility.
Theorem 8.3 (data compression). Under Model Assumptions 8.2 (stan-
dard case) we have:
i) The best linear and individually unbiased estimator of  (i) is
Bi = (Y 0
i WiYi)1 Y 0
i WiXi.
(8.12)
ii) The quadratic loss matrix of Bi is
E
£
(Bi   (i)) · (Bi   (i))0¤
= 2 · (Y 0
i WiYi)1 .
(8.13)
Proof: Given i, we may ﬁrst ask what is the best unbiased linear estima-
tor from classical regression analysis. Theorem 8.1, resp. formula (8.5) tells
us that (8.12) is already the best unbiased linear estimator of (i). Since
the matrices of (8.12) do not depend on i, it must be the optimal data
compression. From (8.6), we also get that
Cov (Bi, B0
i| i) = 2 (i) · (Y 0
i WiYi)1 .
(8.14)
Since
Cov (Bi, B0
i| i) = E
£
(i   (i) (i   (i))0 |i
¤
(8.15)
and by taking the expected value of the right-hand side of (8.14), we obtain
(8.13). This ends the proof of Theorem 8.3.
¤
Theorem 8.4 (credibility formula standard case). Under Model As-
sumptions 8.2 we get that the credibility estimator for  (i) satisﬁes
\
\
 (i) = AiBi + (I  Ai)  ,
where
Ai = T
³
T + 2 (Y 0
i WiYi)1´1
.
The quadratic loss matrix is given by
E
"µ\
\
(i)  (i)
¶
·
µ\
\
(i)  (i)
¶0#
= (I  Ai) T.
Proof: Theorem 8.4 follows directly from Theorem 7.13 and Theorem 7.5
applied to the compressed data given by Theorem 8.3.
¤

8.3 The Regression Credibility Model
205
8.3.2 The General Regression Case (Hachemeister)
The only dierence from the standard regression case (Model Assumptions
8.2) is that the conditional independence assumption between the components
of Xi is dropped and that we allow any conditional covariance structure within
Xi.
Model Assumptions 8.5 (Hachemeister model)
The risk i is characterized by an individual risk proﬁle &i, which is itself the
realization of a random variable i. We make the following assumptions:
H1: Conditionally, given i, the entries Xij, j = 1,2,. . .,n, are independent
and we have
E [Xi | i]
|
{z
} = Yi
|{z} ·
 (i)
| {z } ,
(8.16)
n × 1
n × p
p × 1
where  (i) = regression vector of length p  n,
with linearly independent components,
Yi = known “design” matrix of rank p,
Cov (Xi, X0
i| i) = 	i (i) .
(8.17)
H2: The pairs (1,X1), (2, X2),. . . are independent, and 1, 2,. . . are
independent and identically distributed.
Remarks:
•
Of course, the Hachemeister model includes the standard regression as a
special case.
•
(8.17) implies that we have as structural parameters the matrices
Si = E [	i (i)]
(i = 1, 2, . . . , I)
instead of 2W 1
i
with only one parameter 2 in the standard regression
case.
•
Usually one assumes
	i (i) = W 1/2
i
	 (i) W 1/2
i
and hence
Si = W 1/2
i
S W 1/2
i
,
where
W 1/2
i
=
3
E
E
C
w1/2
i1
0
...
0
w1/2
in
4
F
F
D .

206
8 Credibility in the Regression Case
Even under this assumption, we still have many more structural parame-
ters than in the standard regression case.
Indeed the matrix
S = E [	 (i)]
contains n (n + 1) /2 structural parameters instead of only one parameter
2 in the standard regression model.
Again we want to ﬁnd the credibility estimator and again we ﬁrst focus on
the data compression.
Conditionally, given i, the optimal linear unbiased estimator resulting
from classical statistics (cf. Theorem 8.1) is
\
 (i) =
³
Y 0
i 	i (i)1 Yi
´1
Y 0
i 	i (i)1 Xi
(8.18)
and the covariance matrix is
	\
(i) =
³
Y 0
i 	i (i)1 Yi
´1
.
(8.19)
Unfortunately, the covariance matrix 	i (i) appearing on the right-hand
side of (8.18) depends on the unknown i and is therefore itself unknown.
Remembering that the structural parameter entering in the credibility weight
of the Bühlmann—Straub model is 2 = E
£
2 (i)
¤
, it suggests that the un-
known covariance matrix (8.18) should be replaced by the structural para-
meter matrix Si = E [	i (i)]. The next theorem shows that indeed we then
obtain the optimal data compression.
Theorem 8.6 (data compression). Under Model Assumptions 8.5
(Hachemeister) we have:
i) The best linear and individually unbiased estimator of  (i) based on Xi
is
Bi =
¡
Y 0
i S1
i
Yi
¢1 Y 0
i S1
i
Xi.
(8.20)
ii) The quadratic loss matrix of Bi is
E
h
(Bi   (i)) · (Bi   (i))
0i
=
¡
Y 0
i S1
i
Yi
¢1 .
(8.21)
Remarks:
•
Bi is individually unbiased, since
E [Bi| i] =
¡
Y 0
i S1
i
Yi
¢1 Y 0
i S1
i
E [Xi| i]
=
¡
Y 0
i S1
i
Yi
¢1 Y 0
i S1
i
Yi (i)
=  (i) .

8.3 The Regression Credibility Model
207
Proof of Theorem 8.6: We must show that the orthogonality condition
(i)  Bi B AXi  Bi
(8.22)
is satisﬁed for all matrices A with
E [AXi| i] = (i).
(8.23)
The orthogonality condition (8.22) can be written as
E
£
Cov
¡
Bi, (AXi)0¯¯ i
¢¤
= E [Cov (Bi, B0
i| i)] .
(8.24)
From (8.23) and Model Assumptions 8.5, formula (8.16), we have
AYi = I,
since E [AXi| i] = AYi(i) for all values of (i). Using (8.20) we ﬁnd
that the left-hand side of (8.24) is equal to
¡
Y 0
i S1
i
Yi
¢1 Y 0
i S1
i
SiA0 =
¡
Y 0
i S1
i
Yi
¢1 Y 0
i A0 =
¡
Y 0
i S1
i
Yi
¢1 .
Since the left-hand side of (8.24) is independent of A, it must also hold that
E [Cov (Bi, B0
i| i)] =
¡
Y 0
i S1
i
Yi
¢1 ,
(8.25)
which proves Theorem 8.6.
¤
The following theorem follows directly from Theorem 7.13 and Theorem
7.5 from Chapter 7 (Multidimensional Credibility) applied to the compression
Bi.
Theorem 8.7 (Hachemeister formula). Under Model Assumptions 8.5 we
get that the credibility estimator for  (i) satisﬁes
\
\
(i) = AiBi + (I  Ai) ,
(8.26)
where Ai = T
³
T +
¡
Y 0
i S1
i
Yi
¢1´1
,
Bi =
¡
Y 0
i S1
i
Yi
¢1 Y 0
i S1
i
Xi,
Si = E [	i (i)] = E [Cov (Xi, X0
i| i)] ,
T = Cov
¡
 (i) , (i)0¢
,
 = E [ (i)] .
The quadratic loss matrix is given by
E
"µ\
\
(i)  (i)
¶
·
µ\
\
(i)  (i)
¶0#
= (I  Ai) T.

208
8 Credibility in the Regression Case
8.3.3 Homogeneous Credibility Estimator and Quadratic Loss
The homogeneous credibility estimator as well as the quadratic loss of the
inhomogeneous and the homogeneous credibility estimator are given by the
results presented in Section 7.1 (Theorem 7.3, Theorem 7.5, Theorem 7.6) and
by inserting there the speciﬁc credibility matrix and the structural parameter
found in the standard regression case (Subsection 8.3.1) or in the general
regression case (Subsection 8.3.2).
8.4 The Simple Linear Regression Case (Linear Trend
Model)
The simple linear regression model with time as covariable (linear trend) was
the basis for Hachemeister’s original problem. In practice, this problem is still
the most important application of the Hachemeister regression model. For this
reason, we will examine this case more closely here.
In the simple linear regression model the regression equation is
E [Xij| i] = 0 (i) + j · 1 (i) ,
or in matrix notation
E [Xi| i] =
3
E
E
E
E
E
E
C
1
1
1
2
...
3
...
...
1
n
4
F
F
F
F
F
F
D
|
{z
}
= Yi
3
C
0 (i)
1 (i)
4
D
|
{z
}
= (i)
,
where 0 (i) is the intercept and 1 (i) is the slope.
Further we assume that we are in the standard regression case, resp. that
Si = E [Cov(Xi, Xi | i)] = 2 · W 1
i
,
where Wi =
3
E
E
E
C
wi1
0 . . .
0
0 wi2 . . .
0
...
...
...
...
0
0 . . . win
4
F
F
F
D .
Theoretically everything seems to be in good order. The model ﬁts ex-
actly into the framework of the credibility regression model. However, when
Hachemeister applied this model to his bodily injury data, he had an unwel-
come surprise. In some states, the obtained results were rather strange and

8.4 The Simple Linear Regression Case (Linear Trend Model)
209
contrary to commonsense judgement. For example in state number 4 (see Fig-
ure 8.1) the slope of the credibility adjusted regression line was smaller than
that in the collective as well as that for the individual risk and not somewhere
between the two, as one would expect.
1000
1200
1400
1600
1800
2000
2200
1
2
3
4
5
6
7
8
9
10
11
12
Severity
State 4
Countrywide
Credibility Adjusted
Fig. 8.1. State 4
For this reason the predictions based on the credibility regression line, say
for the next four periods (the Hachemeister data were quarterly data) were
very strange. They were less than what one would predict using either the
individual regression line for the state under consideration as well as being
less than the predictions one would make using all the states together. No
practising actuary would trust such a prediction. Hachemeister had found a
nice theory and an appealing theoretical result, but there still remained a
question mark: the method didn’t work well with the practical problem he
was faced with.
It is amazing that a satisfactory solution to this problem was found only
20 years later in [BG97]. As we will see, the “trick” consists of modelling the
intercept not in the time origin but rather in the centre of the time range.
First, however, we want to work with the original model with the intercept
at the time origin in order to understand where the di!culties arise.
Take the intuitively reasonable case, where the intercept and the slope are
independent of each other. This implies that the covariance matrix T has the
following form:

210
8 Credibility in the Regression Case
T = Cov( (i) ,  (i)0) =
µ 2
0 0
0  2
1
¶
.
(8.27)
To simplify the notation, in the following we will omit the subscript i.
Further we introduce the quantity
V := Y 0WY.
Further, also to simplify the notation we deﬁne the following quantities. We
regard the relative weights wj/w• as “sample weights” and denote with E(s)
or Var(s) the moments with respect to this distribution. We will also apply
these “operators” to quantities which are not random variables. Examples of
this notation are
E(s)[j] =
n
X
j=1
j wj
w•
,
E(s) [Xj] =
X wj
w•
Xj,
Var(s)[j] =
n
X
j=1
j2 wj
w•

3
C
n
X
j=1
j wj
w•
4
D
2
= E(s)[j2] 
³
E(s)[j]
´2
.
In the simple linear regression case we get
V =
µ1 1 . . . 1
1 2 . . . n
¶
3
E
E
E
C
w1 0 . . . 0
0 w2 . . . 0
...
... ...
...
0
0 . . . wn
4
F
F
F
D
3
E
E
E
C
1 1
1 2
... ...
1 n
4
F
F
F
D
= w•
3
E
E
E
E
C
nP
j=1
wj
w•
nP
j=1
j wj
w•
nP
j=1
j wj
w•
nP
j=1
j2 wj
w•
4
F
F
F
F
D
(8.28)
= w•
3
C
1
E(s)[j]
E(s)[j]
E(s)[j2]
4
D .
For the best linear and individually unbiased estimator we get

8.4 The Simple Linear Regression Case (Linear Trend Model)
211
B = V 1Y 0 W X
=
3
C
1
E(s)[j]
E(s)[j]
E(s)[j2]
4
D
1
3
E
E
E
C
P
j
wj
w•
Xj
P
j
wj
w•
jXj
4
F
F
F
D
=
1
Var(s)[j]
·
3
C
E(s)[j2]
E(s)[j]
E(s)[j]
1
4
D
3
C
E(s)[Xj]
E(s)[jXj]
4
D
=
1
Var(s)[j]
·
3
C
E(s)[j2] · E(s)[Xj]  E(s)[j] · E(s)[jXj]
E(s)[jXj]  E(s)[j] · E(s)[Xj]
4
D .
(8.29)
Next we want to calculate the credibility matrix
A = T
¡
T + 2V 1¢1 .
In order to reduce our calculations, we ﬁrst rewrite the matrix A:
A = T
¡
T + 2V 1¢1
=
¡
I + 2V 1T 1¢1
=
¡
V + 2T 1¢1 V.
(8.30)
For the inverse of T we get
T 1 =
1
 2
0 2
1
3
C
 2
1
0
0
 2
0
4
D
= 1
2
3
C
0
0
0
1
4
D ,
where 0 = 2
 2
0
,
1 = 2
 2
1
,
and thus
V + 2T 1 =
3
C
w• + 0
w•E(s)[j]
w•E(s)[j]
w•E(s)[j2] + 1
4
D .
From this we get

212
8 Credibility in the Regression Case
(V + 2T 1)1 = 1
N ·
3
C
w•E(s)[j2] + 1
(w•E(s)[j])
(w•E(s)[j])
w• + 0
4
D ,
where N = (w• + 0)
³
w•E(s)[j2] + 1
´
 (w•E(s)[j])2
= w2
•Var(s) [j] + 0w•E(s)[j2] + w•1 + 01.
Substituting these in (8.30) gives
A = w•
N ·
3
C
w•Var(s) [j] + 1
1E(s)[j]
0E(s)[j]
w•Var(s) [j] + 0E(s)[j2]
4
D .
(8.31)
The credibility matrix is a very complicated expression and it is di!cult
to interpret it. We see that the credibility matrix is not diagonal, even though
S and T are diagonal.
The fact that the credibility matrix is non-diagonal is the source of all the
unpleasantness and can lead to implausible results, as Hachemeister experi-
enced in his application of this method. Moreover, the parameters are di!cult
to interpret and their eect is hard to predict, which is a major disadvantage
in practice.
However, there is an astoundingly simple way of removing this di!culty:
one should take the intercept not at the origin of the time axis but rather at
the “centre of gravity” of the observed time range, which is deﬁned by
j0 = E(s)[j] =
n
X
j=1
j wj
w•
.
The regression equation is then
µj() = 0() + (j  E(s)[j]) · 1(),
and the design matrix becomes
Y =
3
E
E
E
C
1
1  E(s)[j]
1
2  E(s)[j]
...
...
1
n  E(s)[j]
4
F
F
F
D .
Remark:
•
It is well known that a linear transformation of the time axis (or more
generally of any covariable) has no eect on the credibility estimator (this
follows from the linearity property of the credibility estimator). But what

8.4 The Simple Linear Regression Case (Linear Trend Model)
213
we have done here is more than just a transformation of the time axis.
We have changed the original model in that 0 (i) now has a slightly
dierent meaning, namely the intercept at the “centre of gravity” of the
time variable (rather than at the zero of the time variable). We model
therefore a “new” vector and we assume that the covariance matrix T is
diagonal with respect to this “new” vector.
Repeating the calculations in (8.28) and (8.29) with the “new time” k = j
E(s) [j] and using E(s) [k] = 0 plus the fact that all variances and covariances
involving j are unaected by the time change, expression (8.29) — expressed
in the time variable j — becomes
B =
3
E
E
C
E(s)[Xj]
Cov(s)(j, Xj)
Var(s)(j)
4
F
F
D
(8.32)
and
A =
3
C
a11
0
0
a22
4
D ,
(8.33)
where
a11 =
w•
w• + 0
=
w•
w• + 2
 2
0
,
(8.34)
a22 =
w•Var(s)(j)
w•Var(s)(j) + 1
=
w• · Var(s)(j)
w• · Var(s)(j) + 2
 2
1
.
(8.35)
Notice that the credibility estimators for the components of () are given
by
\
\
0() = a11B0 + (1  a11)0,
(8.36)
\
\
1() = a22B1 + (1  a22)1,
(8.37)
where B0 and B1 were deﬁned in (8.32).
Under these assumptions, the credibility formula in the simple linear re-
gression model can then be split into two one-dimensional credibility formu-
lae. These have the simple form familiar from the Bühlmann—Straub model.
In particular, notice that the credibility weights a11 and a22 have the same
structure as the credibility weights in the Bühlmann—Straub model. The vol-
umes are w• for a11 and w•Var(s) [j] for a22, and the credibility coe!cients
are 2/ 2
0 for a11 and 2/ 2
1 for a22.
These are formulae that one can use directly in practice. The results that
we get with them make sense and reﬂect our intuitive expectations. The inter-
cept and slope of the credibility regression line lie between the corresponding

214
8 Credibility in the Regression Case
values for the individual and the collective regression models. Moreover, the
intercept and the slope can be separately estimated using already known tech-
niques from the Bühlmann—Straub model. This applies also to the estimator
of the structural parameters, which we will describe below. The structural
parameters have a direct meaning and we can see the inﬂuence that changes
in these will have on the result. If, for example,  2
1 is small compared to
2/
³
w•Var(s)(j)
´
, then the slope of the credibility line will lie close to the
slope of the collective line.
Mathematically, what we have done here, is to make the columns of the
design matrix Y mutually orthogonal. That is, the inner product of the col-
umn of 1’s and the centred column (1  E(s)[j], . . . , n  E(s)[j])0, deﬁned by
the E(s) operator, is zero. As a consequence, the credibility matrix A is diag-
onal, and the credibility adjustment to 0 (respectively 1), has no eect on
the credibility adjustment to 1 (respectively 0). Moreover, with this model
speciﬁcation, we have a more coherent view of our a priori beliefs: Classical
statistics tells us, when the columns of Y are mutually orthogonal, then the
estimators for the ﬁxed parameter 0 and 1 are stochastically uncorrelated
(conditional on , in this case). Assuming that the stochastic parameters 0
and 1 are mutually independent, therefore seems more reasonable when the
columns of Y are mutually orthogonal, than when they are not.
One point has been “brushed over” until now: the centre of gravity of the
time variable may be dierent from risk to risk. In practice, one very often
sees that the underlying volumes of the dierent risks don’t vary too much
over time and that they show a similar development pattern. In other words,
the centres of gravity lie in most cases close together. For example, in the
Hachemeister data, the observation period was 12 quarters and the centres
of gravity varied in a range between 6.41 and 6.70. The question remains,
however, as to how we should deﬁne the centre of gravity, and the natural
answer is that we take the centre of gravity of the collective, i.e.
j0 =
n
X
j=1
w•j
w• •
j.
In all situations, where the individual centres of gravity lie close together, we
recommend taking the collective centre of gravity and applying the credibility
formulae (8.36) and (8.37) developed above. The dierence between this result
and the exact credibility result will be negligible in most cases.
Figure 8.2 shows the result for state number 4, when the technique de-
scribed above is applied to the Hachemeister data.
The credibility lines now look reasonable. The predictions make sense. The
method delivers results which are useful. It seems to us that the Hachemeis-
ter problem is solved and the method is developed su!ciently to be used in
practice for the estimation of trends by means of credibility.
For the sake of completeness, we give the exact expression for the credibility
matrix when the centre of gravity of the time variable varies from one risk to

8.4 The Simple Linear Regression Case (Linear Trend Model)
215
1000
1200
1400
1600
1800
2000
2200
1
2
3
4
5
6
7
8
9
10
11
12
Severity
State 4
Countrywide
Credibility Adjusted
Fig. 8.2. State number 4 with intercept of centre of gravity
another. For the derivation, see the original article [BG97].
Ai = wi•
Ni
·
3
E
C
wi• · Var(si)[j] + 2
 2
1 + 2
i
2
 2
0
iVar(si)[j] 2
2
0
i 2
 2
0
(wi• + 2
 2
0 )Var(si)[j]
4
F
D ,
where Ni = (wi• + 2
 2
0
)(wi• · Var(si)[j] + 2
 2
1
) + wi•2
i
2
 2
0
,
i = E(si)[j]  j0
(deviation of the individual from the collective centre of gravity).
The credibility matrix is again quite complicated and is not diagonal. As we
have already said, in most cases in practice, the deviations i are small. In
this case the inﬂuence of the non-diagonal elements is negligible. Notice also,
that for i = 0 the above credibility matrix is identical with (8.33). For small
i the results that one gets with the above exact credibility formula are very
close to those that one gets with the far simpler one-dimensional credibility
formulae (8.36) and (8.37). In practice then, one can work with the simple
one-dimensional model and get results which are exact enough for practical
purposes.
In order to apply the methodology, we still have to estimate the structural
parameters. In the following we give estimators for the structural parameters
which are analogous to those in the Bühlmann—Straub model.

216
8 Credibility in the Regression Case
Consider
b2
i =
1
n  2
n
X
j=1
wij (Xij  bµij)2,
where bµij = ﬁtted values from the individual regression lines.
It is well known from classical statistics that the b2
i ’s are conditionally unbi-
ased estimators for the 2(i)’s.
A natural estimator for 2 is therefore
b2 = 1
I
I
X
i=1
b2
i .
From (8.6) and (8.28) we get that with time origin at the individual cen-
tre of gravity, the conditional covariance matrix of the individual regression
parameters is diagonal and given by
Cov (Bi, B0
i| i) = 2(i)
3
C
wi•
0
0
wi•di
4
D
1
,
(8.38)
where di = Var(si)(j) =
nP
j=1
wij
wi•
(j  j(i)
0 )2,
j(i)
0
= Pn
j=1
wij
wi• j.
(8.39)
In most cases in practice, the individual centres of gravity j(i)
0
vary little
from one risk to another. Then (8.38) and (8.39) are still approximately ful-
ﬁlled, if the individual centres of gravity j(i)
0
are replaced by the global centre
of gravity
j0 =
n
X
j=1
wij
w••
j.
The conditional variance of the elements of Bi in (8.38) have the same struc-
ture as the conditional variance of Xi in the Bühlmann—Straub model. If we
take the estimator which is analogous to the estimator in the Bühlmann—
Straub model, we get the following unbiased estimators:

8.5 Exercises
217
b 2
0 = c0 ·
(
1
I  1
I
X
i=1
wi•
w••
¡
B0i  B0
¢2  I c
2
w••
)
,
where c0 = I1
I
nPI
i=1
wi•
w••
³
1  wi•
w••
´o1
,
B0 = PI
i=1
wi•
w•• B0i.
b 2
1 = c1
(
1
I  1
I
X
i=1
w
i•
w••
¡
B1i  B1
¢2  I c
2
w••
)
,
where w
i• = di · wi•,
c1 = I1
I
nPI
i=1
w
i•
w••
³
1  w
i•
w••
´o1
,
B1 = PI
i=1
w
i•
w•• B1i.
8.5 Exercises
Exercise 8.1
To get a deeper understanding of the simple regression credibility model (see
Section 8.4), consider the following ﬁctitious situation: the number of obser-
vation years n is equal to 5 and the weights wij are all equal to 1. For the
collective regression line we obtained b0 = 130 for the intercept (at the centre
of gravity, which is 3 in this case) and b1 = 10 for the slope. For the individual
regression line we got B0 = 90 for the intercept and B1 = 0 for the slope.
We assume that (8.27) is fulﬁlled, i.e. T
= Cov
¡
 (i) ,  (i)0¢
=
µ 2
0 0
0  2
1
¶
.
a) Calculate the credibility regression line for the following structural para-
meters:
i)  = 20  0 = 5
 1 = 3
ii)  = 20  0 = 5
 1 = 0.00001
ii)  = 20  0 = 0.00001  1 = 3
b) Display the dierent regression lines (individual , collective and credibil-
ity) in a graph and interpret the results.

218
8 Credibility in the Regression Case
Exercise 8.2
The following table shows the claim number and the average claim amounts
of four risk groups of a motor liability portfolio.
1
2
3
4
1
2
3
4
year
1
6 244
4 067
2 455
 951
6 182
5 462
6 233
3 214
2
6 583
4 166
2 250
1 086
6 104
5 668
6 997
4 297
3
6 156
3 526
2 068
 883
6 574
6 143
6 680
4 112
4
6 297
3 432
1 974
 786
6 561
5 942
8 088
3 987
5
6 217
3 213
1 720
 744
6 479
7 112
6 232
7 132
6
6 363
3 151
1 633
 760
6 821
6 547
7 562
5 490
claim number
average claim amount
risk group
risk group
Table: average claim amounts of motor liability portfolio
a) Calculate the centre of gravity of time for each of the four risk groups
and check that they are close to each other. In the following neglect the
dierences in the centre of gravity.
b) Calculate the (empirical) credibility lines for the average claim amounts
for each risk group by applying formulae (8.36) and (8.37) and display
them together with the individual and the collective regression lines.
c) Calculate for each risk group the values of the (empirical) estimator of
the average claim amount for year 8.
d) As in c), but now under the a priori assumption that the slope is the same
for all risk groups.
Exercise 8.3
Write the Bühlmann—Straub model as a credibility regression model and ver-
ify that Theorem 8.4 yields the credibility formula of the Bühlmann—Straub
model.

9
Evolutionary Credibility Models and Recursive
Calculation
9.1 Motivation
In most of the credibility models which we have dealt with until now, e.g. the
simple Bühlmann model (Subsection 3.1.4) or the Bühlmann—Straub model
(Chapter 4), the best linear estimator for the individual premium µ () was
of the form
P cred = \
\
µ () =  X + (1  ) P coll,
a weighted average of the collective premium P coll = µ := E [µ ()] and the
individual, observed average X.
In the multidimensional case (Chapter 7) we also found that
\
\
µ () = A B + (I  A) µ,
where B can be interpreted as the observed average (best linear individually
unbiased estimator).
In many applications, the components of the observation vector X0 =
(X1, X2, . . . , Xn) represent the observed aggregate claim amounts over the
past n observation years. Formulae of the above type impose that in order to
calculate the credibility premium, one needs to have information about the
complete individual claims history of the last n years.
On the other hand, one of the ﬁrst and most well-known applications of
credibility in insurance practice was the development of Bonus—Malus systems
for motor insurance (see Section 2.4.1). Most Bonus—Malus systems used in
practice have the property that the premium in period n + 1 only depends
on the premium in period n and the newly observed claim experience (mostly
the number of claims) in year n. Such a system has the big advantage that
the “claim history” over many years is not required. This makes the system
for setting premiums easier both for the customer to understand and also for
the insurers to administer (data storage, IT systems, etc.).

220
9 Evolutionary Credibility Models and Recursive Calculation
Also, the methodology used earlier by the rating bureaus of the United
States (e.g. by the National Bureau of Casualty Underwriters or by the ISO)
calculated the new premiums based on old premiums, but adjusted for the
new claim experience, i.e.
Pn+1 = Pn + n (Xn  Pn) ,
(9.1)
where Pn = pure risk premium in period n,
Xn = claim experience in period n,
n = weight or “credibility measure”
for the most recent observation.
Formulae of the kind in (9.1) are called recursive premium formulae.
9.2 Recursive Credibility
In the following we consider a particular risk over time and we let:
P cred
n
be the credibility premium for the nth period based on the observations
from the years 1, 2, . . . , n  1,
X1, X2, . . . , Xn, Xn+1, . . . be the observed aggregate claim amounts in the
years j = 1, 2, . . . , n, n + 1, . . . and
P cred
1
, P cred
2
, . . . , P cred
n
, P cred
n+1, . . . be the associated premiums for the corre-
sponding years.
Deﬁnition 9.1. The credibility premium is recursive, if
P cred
n+1 = nXn + (1  n) P cred
n
(9.2)
= P cred
n
+ n
¡
Xn  P cred
n
¢
,
where P cred
n
denotes the credibility premium for year n based on the observa-
tions X1, X2, . . . , Xn1.
In the following we discuss in which cases the credibility premiums are
recursive, i.e. in which cases the credibility premium can be calculated recur-
sively over time by averaging the “old” credibility premium and the latest
observation.
From a practical point of view the problem is that of how to calculate, over
time, each year’s premium (e.g. for ﬁre insurance or motor insurance) for an
existing policy. If the credibility premium is recursive, then according to (9.2)
we have the very useful interpretation:
new premium = old premium + n · (deviation of the observed aggregate
claim amount Xn from the old premium Pn).

9.2 Recursive Credibility
221
Example 9.1 (simple Bühlmann model)
For the credibility premium in year n + 1we found that (Subsection 3.1.1,
Theorem 3.2)
P cred
n+1 = nX(n) + (1  n) µ,
(9.3)
where
n =
n
n + 2/ 2 ,
X(n) = 1
n
n
X
j=1
Xj.
One can easily verify that (9.3) can also be written recursively,
P cred
n+1 = nXn + (1  n) P cred
n
,
where n =
1
n + 2
 2
.
Example 9.2 (Bühlmann—Straub model)
For the credibility premium in year n+1 we found (Section 4.3, Theorem 4.2)
P cred
n+1 = nX(n) + (1  n) µ,
(9.4)
where
n =
w(n)
•
w(n)
•
+ 2
 2
,
w(n)
•
=
n
X
j=1
wj,
X(n) =
n
X
j=1
wj
w(n)
•
Xj.
Formula (9.4) can also be written recursively as follows:
P cred
n+1 = nXn + (1  n) P cred
n
,
where n =
wn
w(n)
•
+ 2
2
.
In both Example 9.1 and Example 9.2, the weights n tend to zero with
increasing observation period n and with bounded volume wn. Concluding
that premium adjustments for large n don’t achieve anything, however, is to
throw the baby out with the bathwater! The fact that in Examples 9.1 and
9.2 the weights n tend to zero with a growing observation period is a direct

222
9 Evolutionary Credibility Models and Recursive Calculation
consequence of the underlying model assumptions, where it is assumed that
the correct individual premium remains constant over time, i.e. that
P ind = µ () = E [Xj| ]
for all j.
In order to study situations in which the n do not tend to zero with
increasing n,we must therefore study models in which the individual premium
E [Xj| ]is not the same for every j, but rather changes with the passage
of time. Indeed the assumption of unchanging individual premiums over the
years in the simple Bühlmann model and in the Bühlmann—Straub model is
a simpliﬁed approach to reality (see also the remarks on Assumption BS1 on
page 80).
Before turning to the consideration of how we should model situations
where the correct individual premium changes over time, we take a look at
the case where the recursive premium formula has constant weights n = .
Example 9.3 (“geometric”premium formula)
We consider a recursive premium formula with constant weights n = ,with
0 <  < 1,i.e.
P1 = µ0,
Pn+1 = Xn + (1  ) Pn
for n  1.
(9.5)
It is illustrative to consider the development of the premium Pn over time
as a function of the observations Xj. We get
P1 = µ0,
P2 = X1 + (1  ) µ0,
P3 = X2 + (1  ) P2 = X2 +  (1  ) X1 + (1  )2 µ0,
...
(9.6)
Pn+1 =
n1
X
k=0
 (1  )k Xnk + (1  )n µ0.
Comparing this premium formula with the credibility premium in the simple
Bühlmann model is very enlightening. With the above recursive premium
formula, the a priori value µ0, and “older” claim experience is weighted less
and less as time goes on. It is intuitively obvious that the claim experience from
more distant years should be weighted less than more recent claim experience
in calculating this year’s premium. In contrast, the credibility formula (9.3)
gives the same weight to each of the observations. In practice, we accept this
because mostly (9.3) is used only over a very limited observation period, e.g.
over the last ﬁve years. The choice of the length of this observation period
is somewhat arbitrary and has the unpleasant consequence that e.g. a ﬁve-
year-old observation has the same weight as the newest observation, while the

9.3 Evolutionary Credibility Models
223
observation from six years back is totally ignored. In the geometric premium
formula, older observations get successively less weight, removing the need to
impose an artiﬁcial limit on the observation period. In particular, we note
that the starting value P1 = µ0 gets the smallest weight. For n su!ciently
large, i.e. for a process that runs for a very long time, this starting value has
a practically negligible inﬂuence on P cred
n+1.
Let us now address the modelling aspect: In the simple Bühlmann model,
the reason that all observations have the same weight is due to the assumption
that the correct individual premium does not change over time. In contrast,
lower weights for “older” observations as in the premium formula (9.6) can
only be theoretically justiﬁed when the risk changes with the passage of time
and older observations are less relevant than newer ones in the rating of the
current risk. In the next section we will propose a model for the situation
where the correct individual premium changes with time. It should be noted
that in the example with the geometric premium formula we just have written
down a recursive premium formula and that as yet, we have not demonstrated
any connection between this and the credibility premium as deﬁned in Chapter
3 (formula (3.17)). The question is, whether there exists a credibility model
with a resulting recursive credibility formula as in Example 9.3 and what this
model looks like. Amongst others, this question will be answered in Section
9.5 (Example 9.4).
9.3 Evolutionary Credibility Models
We will now describe situations in which the correct individual premium
changes with the passage of time.
We have already seen one such situation in the regression case considered
in Chapter 8. In the regression model, the individual premium in year j is
determined by the formula
E [Xj| ] = y0
j  () .
It depends on the design vector yj, which represents the values of the covari-
ates in year j. In this way we can model dependencies on known covariates
such as time, inﬂation, age, sex, etc., in the credibility framework. In the re-
gression approach the individual risk is described by the parameter vector
(), which stays constant with the passage of time. This approach has been
treated in Chapter 8 and is not the subject of this or the following section.
We will, however, come back to it in Section 9.6.
In many situations in insurance practice, the mechanics of the changes
in the correct individual premiums are unknown and cannot be described
by means of covariates in a regression model, be it because the information
needed to do this has not been collected by the insurer or it is not used
(see the comments under the thesis on page 2), or because the changes are a

224
9 Evolutionary Credibility Models and Recursive Calculation
result of random events which cannot be quantiﬁed a priori. Indeed, most real
risks are continually changing. For example, changes in living conditions like
starting a family, the birth of a child, divorce, change of profession, job loss,
can have an impact on the risk behaviour of the individual driver. For a variety
of reasons, such events are not recorded by the insurer and are not directly
used in the calculation of the premium and are therefore, from the point of
view of the insurer, of an unknown nature. In collective health and accident
insurance, the risk proﬁle of the business insured changes with ﬂuctuations in
personnel and the dierent risk behaviour and recreational activities of the
individual employees. In addition, we have to consider changes in the business
organization and in management, which may have an eect on things like the
work atmosphere, controls, etc., and therefore are not without inﬂuence on
the insured risk. It is obvious that all of these potential explanatory factors
cannot be observed by the insurer, let alone be quantiﬁed.
Such changes in the risk premiums, which cannot be explained by covariates
which have been collected by the insurer and used in the rating of risks, are
most easily understood as stochastic in nature. This approach leads us to
evolutionary models.
In the following we consider a particular individual risk. Let X0 =
(X1, . . . ) be the observed aggregate claim amounts of this risk in years j =
1, 2, . . . . This risk is characterized by its individual risk proﬁle, which is not
directly observed by the insurer but which, in this approach, is allowed to
change stochastically with the passage of time. This situation is described
mathematically by letting the risk proﬁle itself be a stochastic process, i.e. a
sequence of random variables
 = {1, 2, . . . , j, . . .} .
(9.7)
The components j are to be understood as the risk proﬁle in year j. We
assume that
E [Xj| ] = E [Xj| j] = µ (j) ,
(9.8)
Var [Xj|] = Var [Xj|j] = 2 (j)
wj
,
(9.9)
where the wj are appropriate weights.
Notice that E [Xj| ] (resp. Var [Xj|]) is the conditional expectation
(resp. the conditional variance) given the sequence , while E [Xj| j] (resp.
Var [Xj|j]) is the conditional expected value (resp. the conditional variance)
given the component j. Equations (9.8) and (9.9) express the fact that the
ﬁrst two moments of Xj depend only on the risk proﬁle j in the year j and
not on the other components {k : k 6= j}.
In this way, the correct individual premium becomes a real-valued stochas-
tic process
µ () = {µ (1) , µ (2) , . . . , µ (j) . . .} .
(9.10)
Further, we assume as always that the ﬁrst two moments exist and are ﬁnite.

9.3 Evolutionary Credibility Models
225
Deﬁnition 9.2. By evolutionary credibility models we mean models with the
structure given by (9.7)—(9.10).
Remarks on the evolutionary credibility models:
•
The sequence (9.10) stands for the sequence of correct individual premiums
in time order. In contrast to regression, where one can imagine that the
regression vector  () is chosen once and for all, and that the changes over
time for the correct individual premium are determined only by changes in
the covariables, the elements of the sequence (9.10) change stochastically.
•
Hachemeister’s credibility regression approach can be combined with the
ideas of evolutionary credibility in that we consider the components of the
regression vector  () to be non-constant over time, but rather to form
a stochastic process. This is an extension of the Hachemeister regression
model and will be treated later.
•
Purely formally, the simple Bühlmann model and the Bühlmann—Straub
model can be considered in the framework deﬁned here for the evolutionary
model. In this case, the stochastic process (9.10) has a “degenerate” form,
i.e. the sequence  is a repetition of the same random variable.
•
We have limited ourselves here to the description of a model for an in-
dividual risk. In order to embed this in a collective of independent risks
i = 1, 2, . . . , I we can proceed as we did in the previous chapters for the
“classical” models:
Each risk i (i = 1, 2, . . . , I) is characterized by its own risk proﬁle
i = {i1, i2, . . . , ij, . . .}
and the process of observations
Xi = {Xi1, Xi2, . . . , Xij, . . .} .
We assume that the pairs {(X1, 1) , (X2, 2) , . . . , (XI, I)} are inde-
pendent of each other and that {1, 2, . . . , I} are independent and
identically distributed.
With this embedding, nothing changes in our customary interpreta-
tion of the collective from the non-evolutionary situation. As in the pre-
vious chapters, it holds that in this case the credibility estimator for the
ith contract depends only on the observations from this contract and not
on those from the other contracts. The data from the collective are merely
used to estimate the structural parameters in the credibility estimator. The
credibility estimators that we derive in the following sections are therefore,
as earlier, the credibility formulae for the individual risks in the case of a
collective of independent risks. In certain applications, this interpretation
may be useful.
•
On the other hand, it must also be mentioned that in evolutionary models,
the assumption that the risk proﬁles of the dierent risks are independent
of each other is very incisive. In reality, it is easy to see situations where

226
9 Evolutionary Credibility Models and Recursive Calculation
this independence is not satisﬁed. This is especially the case when certain
changes (changes in the law, economic circumstances, weather, etc.) have
an eect on all risks in the risk collective at the same time. Modelling such
situations is possible, but for this we need the multidimensional evolution-
ary model which we will describe in Chapter 10.
As an alternative one might, however, try to ﬁrst ﬁlter out the “overall
premium development” (which aects all the risks together over time) and
then to apply the evolutionary model to the resulting “as if” data: Having
ﬁltered out the overall development, the assumption of independent, a
priori equal risks is again realistic.
9.4 Evolutionary Models and Recursive Credibility
In this section we want to determine for which evolutionary models the cred-
ibility premiums are recursive (cf. Deﬁnition 9.1).
It is very useful, conceptually, to split up the path from P cred
n
to P cred
n+1 into
two steps, namely:
a) Updating
Improve the estimation of µ (n) on the basis of the newest information
Xn,
b) Parameter movement
Change the estimation due to the switch of the parameter from µ (n) to
µ(n+1).
In this connection it is useful to introduce the usual terminology and notation
from state space models (see e.g. Abraham and Ledolter [AL83]):
µn|n1 := Pro (µ (n)| L (1, X1, . . . , Xn1)),
µn|n := Pro (µ (n)| L (1, X1, . . . , Xn)).
Notice that in this new notation
P cred
n
= \
\
µ (n) = µn|n1,
and that the steps described above entail:
a) Updating: Step from P cred
n
= µn|n1 to µn|n;
b) Parameter movement: Step from µn|n to µn+1|n = P cred
n+1.
In consideration of the recursiveness, we ask the following questions:
a) Under which conditions is the step from µn|n1 to µn|n recursive?
b) Under which conditions do we have recursiveness in the step from µn|n to
µn+1|n?

9.4 Evolutionary Models and Recursive Credibility
227
The following result gives the answer to question a).
Theorem 9.3. The updating of µn|n1 to µn|n is recursive, i.e.
µn|n = nXn + (1  n) µn|n1,
(9.11)
if and only if
E [Cov (Xk, Xj| )] = 0 for all k 6= j.
(9.12)
Remarks:
•
Formula (9.12) means that Xk and Xj are on the average conditionally
uncorrelated. In particular, (9.12) is fulﬁlled, if the components of the
observation vector are conditionally independent (standard assumption).
Proof of Theorem 9.3:
i)
“,”: From (9.11) it follows that (9.12) holds.
Let
µn|n = an0 +
n
X
j=1
anjXj,
µn|n1 = bn0 +
n1
X
j=1
bnjXj.
From (9.11) we get
anj = (1  n) bnj
j = 0, 1, . . . , n  1,
(9.13)
ann = n.
(9.14)
The normal equations (Corollary 3.17) for µn|n and µn|n1 are
Cov (µ (n) , Xk) =
n
X
j=1
anjCov (Xj, Xk)
for k  n,
(9.15)
Cov (µ (n) , Xk) =
n1
X
j=1
bnjCov (Xj, Xk)
for k  n  1.
(9.16)
Substituting the right-hand sides of (9.13) and (9.14) in (9.15) gives
Cov (µ (n) , Xk) = (1  n)
n1
X
j=1
bnjCov (Xj, Xk) + nCov (Xn, Xk) .
For k  n  1 and applying (9.16) we get
Cov (µ (n) , Xk) = (1  n) Cov (µ (n) , Xk) + nCov (Xn, Xk) ,

228
9 Evolutionary Credibility Models and Recursive Calculation
and with that
Cov (µ (n) , Xk) = Cov (Xn, Xk)
for k  n  1.
Using the fact that E [Xk| ] = µ (k) and the well-known identity
Cov (Xn, Xk) = Cov (µ (n) , µ (k)) + E [Cov (Xn, Xk|)] ,
we conclude that
E [Cov (Xn, Xk|)] = 0.
(9.17)
Formula (9.17) must be true for any n and k  n  1, which is equivalent
to (9.12), which is what we had to show.
ii) “+”: From (9.12) it follows that (9.11) holds.
From (9.15) we get for k  n
Cov (µ (n) , Xk) =
n1
X
j=1
anjCov (Xj, Xk) + annCov(Xn, Xk),
and thus from (9.12) for k  n  1
(1  ann) Cov (µ (n) , Xk) =
n1
X
j=1
anjCov (Xj, Xk) .
From the uniqueness of the solution for the system of equations (9.16) we
then have
anj = (1  ann) bnj
for j = 1, 2, . . . , n  1.
(9.18)
It remains to show that (9.18) is also true for j = 0.
Because of the collective unbiasedness of the estimators µn|n and
µn|n1 we have
E
5
7an0 +
n
X
j=1
anjXj
6
8 = E [µ (n)] ,
E
5
7an0 +
n1
X
j=1
anjXj
6
8 = (1  ann) E [µ (n)] ,
E
5
7bn0 +
n1
X
j=1
bnjXj
6
8 = E [µ (n)] .
From (9.18) it follows from the above system of equations that an0 =
(1  ann) bn0.

9.4 Evolutionary Models and Recursive Credibility
229
This completes the proof of Theorem 9.3.
¤
We turn now to the parameter movement of µ (n) to µ(n+1), or equiva-
lently the step b) of µn|n to µn+1|n. In order to get recursiveness also for the
parameter movement, the following assumption is very natural:
Pro(µ (n+1)| L (1, µ (1) , . . . , µ (n))) = µ (n) .
(9.19)
This means that the best linear estimator of µ (n+1) , given all earlier
“states” µ (1) , . . . , µ (n) , is equal to the last known state µ (n). Equa-
tion (9.19) is equivalent to saying that the process {µ (1) , µ (2) , . . .} has
orthogonal increments, i.e. that
Pro (µ (n+1)  µ (n) |L(1, µ (1) , . . . , µ (n))) = 0
for n  1.
(9.20)
This implies that the increments are uncorrelated and have expectation zero,
so that
Cov (µ (j+1)  µ (j) , µ (k+1)  µ (k)) = 0
for all j 6= k, (9.21)
E [µ (j+1)  µ (j)] = 0
for all j.
(9.22)
Note that (9.20) holds if {µ (1) , µ (2) , . . . } is a martingale sequence.
Theorem 9.4. If the Xj are, on average, conditionally uncorrelated and if the
process {µ (1) , µ (2) , . . .} has orthogonal increments, then we have that
µn+1|n = µn|n.
Proof: Because of the linearity property of projections we have that
µn+1|n = Pro(µ (n)| L(1, X1, . . . , Xn))
+ Pro(µ (n+1)  µ (n)| L(1, X1, . . . , Xn))
= µn|n + Pro(µ (n+1)  µ (n)| L(1, X1, . . . , Xn)).
From (9.20) we have that
E [(µ (n+1)  µ (n)) · 1] = 0.
It thus remains to show that
µ(n+1)  µ(n) B L(X1, . . . , Xn).
(9.23)
If we condition on , we get
E[(µ(n+1)  µ(n)) Xk] = E[(µ(n+1)  µ(n)) µ(k)]
= 0 for k = 1, 2, . . . , n,
where the second equality follows from (9.20). With this (9.23) is shown, which
completes the proof of Theorem 9.4.
¤
We get an important extension to our collection of models when we allow
linear transformations on the right-hand side of (9.19).

230
9 Evolutionary Credibility Models and Recursive Calculation
Corollary 9.5. If instead of (9.19) the condition
Pro (µ (n+1)| L (1, µ (1) . . . , µ (n))) = anµ (n) + bn
(9.24)
is satisﬁed, we then have
µn+1|n = anµn|n + bn.
(9.25)
Remarks:
•
(9.24) means that the process {µ (j) : j = 1, 2, . . .} satisﬁes the linear
Markov property.
•
(9.24) is the most general assumption, under which we can hope to have
recursiveness for updating.
•
The condition (9.24) implies that the elements of the sequence
{µ (n+1)  anµ (n)  bn : n = 1, 2, . . .}
are uncorrelated and have expected value zero. Things like inﬂation mea-
sured according to some given index can therefore be taken into account
by means of a linear transformation (change of scale and shift of origin).
•
In particular, (9.24) is satisﬁed when the process {µ (j) : j = 1, 2, . . .}
is an autoregressive process of order 1 with centered i.i.d. innovations
2, 3, . . . . Then we have
µ (n+1) = µ (n) + (1  ) µ + n+1
with || < 1,
and thus an =  and bn = (1  ) µ.
Proof: The corollary follows directly from Theorem 9.4 and the linearity
property of projections.
¤
9.5 Recursive Calculation Method (Kalman Filter)
In accordance with the general Kalman Filter method, we name the recur-
sive calculation algorithm described in Section 9.4, which is split into the two
steps “updating” and “parameter movement”, the Kalman Filter procedure.
The original application of the Kalman Filter can be found in the engineering
literature. The usual formulation leads to a more general formula (see Chap-
ter 10) than the one found in this section. But the essential component of
this general form is also the splitting of the calculation into the two steps of
updating and parameter movement.
Analogously to the notation in Section 9.4, we introduce the following
quantities for the expected quadratic loss of the corresponding estimators:
qn|n1 := E
·³
µn|n1  µ (n)
´2¸
,
qn|n := E
·³
µn|n  µ (n)
´2¸
.

9.5 Recursive Calculation Method (Kalman Filter)
231
It is also useful at this point to introduce the following notation for the
structural variance parameters, namely
2
j := E
£
2 (j)
¤
,
 2
j := Var [µ (j)] .
It is convenient, to set without loss of generality
2
j = 2
wj
,
where wj is an appropriate weight.
Theorem 9.6 (recursion formula in Kalman Filter notation). Under
the assumption that the Xj are, on the average, conditionally uncorrelated,
the following recursion formulae hold:
i) Anchoring (Period 1)
µ1|0 = E [µ (1)]
and
q1|0 =  2
1.
(9.27)
ii) Recursion (n  1)
a) Updating
µn|n = nXn + (1  n) µn|n1,
(9.28)
where n =
qn|n1
qn|n1 + 2
wn
=
wn
wn +
2
qn|n1
,
(9.29)
qn|n = (1  n) qn|n1.
(9.30)
b) Change from µ (n) to µ (n+1) (parameter movement)
Case I: The process {µ (j) : j = 1, 2, . . .} has orthogonal increments,
i.e. Pro (µ (n+1)| L (1, µ (1) . . . , µ (n)) = µ (n).
Then it holds that
µn+1|n = µn|n,
(9.31)
qn+1|n = qn|n + 2
n+1,
(9.32)
where 2
n+1 = Var[µ (n+1)  µ (n)].
Case II: Linear transformations are also allowed,
i.e. Pro (µ (n+1)| L (1, µ (1) . . . , µ (n)) = anµ (n) + bn.
Then it holds that
µn+1|n = anµn|n + bn
for n = 1, 2, . . . ,
(9.33)
qn+1|n = a2
n · qn|n + 2
n+1,
(9.34)
where 2
n+1 = Var [µ (n+1)  anµ (n)] .

232
9 Evolutionary Credibility Models and Recursive Calculation
Remarks:
•
Notice that, in the updating step, the quadratic loss always gets smaller.
Notice also, that in Case I, in the second step, the quadratic loss is in-
creased because of the change in the risk proﬁle, but that the credibility
estimator stays the same. This is a natural consequence of the assumption
that the µ (n) have orthogonal increments.
•
Notice that, in the updating step, the estimator (9.28) and its associated
quadratic loss (9.30) have the same form as for the credibility estima-
tor, respectively, the quadratic loss in the Bühlmann—Straub model. The
term µn|n1 = P cred
n
plays the role of the collective average and qn|n1
plays the role of the mean squared error of the individual premium to
be estimated. In a fully parameterized model, in which µn|n1 = P cred
n
is
equal to the conditional expectation E[µ(n)|X1, . . . , Xn1] (exact credi-
bility case), the quantity qn|n1 corresponds to the conditional variance of
µ(n), given the observations X1, . . . , Xn1.
•
(9.28) is a weighted average of µn|n1 and Xn, where the weights are again
proportional to the precisions (= reciprocal values of the mean squared er-
ror) of the single components. The “general intuitive principle” (Principle
3.3) also holds here.
Proof of Theorem 9.6: According to Theorem 9.3, µn|n is of the form (9.28).
We have yet to determine the value of n.
For the quadratic loss of µn|n we get
qn|n = E
·³
µ (n)  nXn  (1  n) µn|n1
´2¸
= 2
nE
h
(µ (n)  Xn)2i
+ (1  n)2 E
·³
µ (n)  µn|n1
´2¸
= 2
n
2
wn
+ (1  n)2 qn|n1.
(9.35)
To get the second equality, we use the fact that the Xj’s are on average
conditionally uncorrelated, which leads to the disappearance of the cross-term.
Setting the derivative of (9.35) with respect to n to zero (minimizing the
quadratic loss) we get immediately that the optimal choice of n satisﬁes
equation (9.29). Substituting n in (9.35), we get directly that
qn|n = (1  n) qn|n1.
Equation (9.31) follows directly from Theorem 9.4.
For the quadratic loss of µn+1|n we get in Case I

9.5 Recursive Calculation Method (Kalman Filter)
233
qn+1|n = E
·³
µn|n  µ (n) + µ (n)  µ (n+1)
´2¸
= E
·³
µn|n  µ (n)
´2¸
+ E
h
(µ (n)  µ (n+1))2i
= (1  n) qn|n1 + 2
n+1.
(9.36)
This is exactly equation (9.32).
In Case II the calculation is analogous and will therefore not be explained
in more detail here. The proof of Theorem 9.6 is thus complete.
¤
In Theorem 9.6 we consciously kept the two steps “updating” and “move-
ment in parameter space” separate from one another. This is useful, ﬁrstly, for
the purpose of interpretation and secondly, because in this way we can under-
stand the extension in ii b) of Case I to Case II. As we have already stated, we
call this two-step procedure Kalman Filter. The recursion formula can how-
ever be written more compactly by combining the two steps. We name this
combined procedure the recursive calculation of the credibility premium. This
is the subject of the following corollary that follows directly from Theorem
9.6 using the notation
P cred
n
:= µn|n1,
qn := qn|n1.
Corollary 9.7 (recursive calculation of the credibility premium). Un-
der the same assumptions as in Theorem 9.6 we have:
i) Anchoring (Period 1)
P cred
1
= E [µ (1)]
and
q1 =  2
1.
(9.37)
ii) Recursion (n  1)
Case I: {µ (j) : j = 1, 2, . . .} has orthogonal increments. Then it holds
that
P cred
n+1 = nXn + (1  n)P cred
n
,
(9.38)
where n =
qn
qn + 2
wn
=
wn
wn + 2
qn
;
qn+1 = (1  n) qn + 2
n+1,
(9.39)
where 2
n+1 = Var [µ (n+1)  µ (n)] .
Case II: Pro (µ (n+1)| L (1, µ (1) . . . , µ (n)) = anµ (n) + bn. Then it
holds that

234
9 Evolutionary Credibility Models and Recursive Calculation
P cred
n+1 = an
¡
nXn + (1  n)P cred
n
¢
+ bn,
(9.40)
where n =
qn
qn + 2
wn
=
wn
wn + 2
qn
;
qn+1 = a2
n (1  n) qn + 2
n+1,
(9.41)
where 2
n+1 = Var [µ (n+1)  anµ (n)] .
Remarks:
•
In Case I the credibility formula (9.38) is recursive (see Deﬁnition 9.1).
•
When, additionally, linear transformations are allowed (Case II), then ac-
cording to (9.40), the new credibility premium (in period n + 1) continues
to depend only on the newest observation Xn and the current credibility
premium (in period n). However, it is no longer of the strict recursive form
given in Deﬁnition 9.1.
Example 9.4 (Gerber and Jones model)
In this example treated in [GJ75b], it is assumed that µ (n) = µ (1)+2 +
. . . + n for n  2. Moreover, 2, 3, . . . are independent with E [j] = 0
and Var [j] = 2. Further, the random variables Xj are conditionally inde-
pendent, given , with Var [Xj|] = 2.
From Corollary 9.7 we get
P cred
1
= µ0,
q1 =  2
1,
P cred
n+1 = nXn + (1  n) P cred
n
,
where n =
1
1 + 2
qn
,
qn+1 = (1  n) qn + 2 =
2qn
2 + qn
+ 2.
One can show that the last equation deﬁnes a contraction with limit
qn
n$4
$ q =
2
µ
1 +
q
1 + 4 2
2
¶
2
.
(9.42)
If  2
1 = Var [µ (1)] is equal to the right-hand side of (9.42), then this is
true, not only asymptotically, but for every n. Notice that in this case all the
weights n are the same, i.e.
n =  =
1
1 + 2
q
.

9.5 Recursive Calculation Method (Kalman Filter)
235
Thus we have constructed a model which gives a geometric premium formula
as postulated in Example 9.3. The assumption that
 2
1 =
2
µ
1 +
q
1 + 4 2
2
¶
2
,
looks very artiﬁcial at ﬁrst. However, when we conceive that the underlying
process has been running for a long time before the time-point zero, it makes
sense to take this value from the stationary distribution.
General remarks on Example 9.4:
•
The model of Gerber and Jones may be appropriate when our interest is
in a single risk, the premium of which we need to calculate.
•
However, if we want to apply this model to a collective of independent and
“similar” risks (see also the two last points in the remarks on the evolu-
tionary credibility model on page 225), this model may be inappropriate
for many cases in practice. The reason for this is that, in the above model
Var [µ (n)] =  2
1 + (n  1) 2.
(9.43)
The variance of µ (n) therefore grows linearly with time. If we consider
a whole portfolio of contracts, independent of each other, which can be
described by this model, then (9.43) means that we are working with
a portfolio, whose heterogeneity increases constantly with time, that is
to say, a portfolio that somehow is spreading out. However, this feature
does not correspond to what is usually observed in practice. This critique
applies not only to the Gerber and Jones model, but to all models which
satisfy the requirements of Theorem 9.6 for Case I. This is because for all
such models, the orthogonal increments lead to the quantity Var [µ (j)]
growing with increasing j.
•
As the next example shows, we can avoid this growing heterogeneity by
allowing for linear transformations, which leads to models corresponding to
Case II of Theorem 9.6. In Section 10.4 we shall discuss a further approach
to dealing with this problem, namely that of multidimensional evolutionary
credibility (see also the discussion in the last point of the remarks on page
225).
Example 9.5 (autoregressive process of order 1)
Let the process {µ (j) : j = 1, 2, . . .} be an autoregressive process of order 1,
i.e.
µ (n+1) = µ (n) + (1  ) µ + n+1,
(9.44)
where E [µ(1)] = µ and the j are again uncorrelated with E [j] = 0 and
Var [j] = 2. We also assume that || < 1, so that Var [µ(j)] is bounded.

236
9 Evolutionary Credibility Models and Recursive Calculation
Further, we make the usual assumption that the Xj, conditionally, given ,
are uncorrelated with Var [Xj|] = 2.
As a consequence of Corollary 9.7 (Case II) we get the following recursion
formula for the credibility estimator and its quadratic loss:
P cred
1
= µ,
q1 =  2
1,
P cred
n+1 = 
¡
nXn + (1  n) P cred
n
¢
+ (1  ) µ,
where n =
1
1 + 2
qn
,
qn+1 = 2 (1  n) qn + 2.
Remarks:
•
For the process {µ (j) : j = 1, 2, . . .} we have
E [µ (j)] = µ
for j  1,
 2
n = Var [µ (n)]
n$4
$  2 :=
2
1  2 .
(9.45)
If we further assume that
Var [µ (1)] =  2 =
2
1  2 ,
(9.46)
then the process {µ (j) : j = 1, 2, . . .} is stationary with
Var [µ (n)] =  2,
Cov [µ (n+k) , µ (n)] = k  2.
•
One can show that — irrespective of the behaviour of  2
n — asymptotically
qn
n$4
$ q =
2 
¡
1  2¢
2 +
q¡
2  (1  2) 2¢2 + 422
2
.
(9.47)
In the case where E
h¡
P cred
1
 µ (1)
¢2i
is already the same as the right-
hand side of (9.47), this is true, not only asymptotically, but for all n, and
for the weights n, it then holds that
n =  =
q
q + 2 .
•
The conditions which lead to constant weights n = , and to a constant
quadratic loss qn = q for the credibility estimator, look very artiﬁcial at

9.5 Recursive Calculation Method (Kalman Filter)
237
ﬁrst glance. However, with the notion of the credibility estimator as a
yearly “rating revision” and a conceptually very long lasting process, the
recursion formula
P cred
n+1 = 
©
Xn + (1  ) P cred
n
ª
+ (1  )µ
for n = 1, 2, . . .
(9.48)
makes sense. We assume that our window of observation covers a time
period in which we are close enough to the asymptotic state. In other words
the time at which our observation period begins is not the same as that at
which the AR(1)-process (9.44) begins, and the process of the credibility
estimator P cred
n
as well as that of the µ (n) have already stabilized, so
that the “starting conditions” of the original processes no longer play a
role. The recursion (9.48) starts then with
P cred
1
= “premium in period 1”,
for which we have
E
h¡
P cred
1
 µ (1)
¢2i
= q.
(9.49)
For the anchoring we must be careful not to use P cred
1
= µ = E [µ (1)]
(collective mean), but rather the “premium in period 1” (which is assumed
to reﬂect the claims history before period one and to satisfy equation
(9.49)). The recursion formula (9.48) is then given by
P cred
n+1 = 
½
q
2 + q Xn +
2
2 + q P cred
n
¾
+ (1  )µ,
(9.50)
where
q = E
h¡
P Cred
n
 µ (n)
¢2i
for n  1,
2 = E
h
(Xn  µ (n))2i
.
•
For a portfolio of independent contracts obeying this model, Var [µ (j)]
is a measure of the heterogeneity of the portfolio at time j. In contrast
to Example 9.4, the portfolio does not spread out over time. Instead, in
this example we are modelling a portfolio with constant heterogeneity, a
property which seems reasonable to assume for many cases in practice.
•
If this model is to be used for a portfolio of independent, but similar,
contracts, one should note that the model describes a situation where,
over the passage of time, the correct individual premium of each contract
randomly varies around the same expected value. A more realistic model
would be one where the long-term average varied from one contract to
another and is drawn at random for each contract i. We will describe such
a model in the next section.

238
9 Evolutionary Credibility Models and Recursive Calculation
9.6 The Evolutionary Credibility Regression Model
As in the previous sections, we consider a particular risk over time, and we let
X1, X2, . . . , Xn, . . . be the observed claim data (e.g. aggregate claim amount,
claim ratio, claim frequency, etc.) of this risk in the years j = 1, 2, . . . , n, . . . .
Again, the goal is to calculate the pure risk premium for a future year.
It is often useful to relate the pure risk premium to a number of explanatory
parameters. Indeed, in most branches the premium depends on observed rating
criteria (e.g. in motor insurance these might be age, sex, region, kilometres
driven, engine size).
In the credibility regression model (Chapter 8) we saw how we could use a
credibility regression model to combine a priori criteria and credibility. How-
ever, in the regression model, the regression parameter vector  () remains
constant over time. We now extend the ideas of the evolutionary credibility
model from Sections 9.4 and 9.5 to the credibility regression case.
In the credibility regression model in Chapter 8, we have for the risk pre-
mium in year j the regression equation
E [Xj|] = y0
j  () ,
(9.51)
where y0
j contains the values of the covariables in year j and  () is the
regression parameter vector, the value of which depends on the risk proﬁle .
In the notation of Chapter 8 (see formula (8.7)), y0
j corresponds to the jth
row vector of the design matrix Y . The risk proﬁle  and thus also  () stay
unchanged over time.
In contrast, in the evolutionary case, we assume that the risk proﬁle can
change over time. The notation and the assumptions (9.7)—(9.9) can be taken
directly from Section 9.3, i.e.
 = {1, 2, . . .} ,
E [Xj|] = E [Xj|j] = µ (j) ,
Var [Xj|] = Var [Xj|j] = 2 (j)
wj
,
where the wj are appropriate weights.
In addition, the regression equation
E [Xj|] = µ (j) = y0
j (j)
(9.52)
is also assumed to hold. Note the dierence from the regression model of
Chapter 8 (dierence between (9.51) and (9.52)): instead of a parameter vector
 () which does not change with time, we have the sequence
 () = { (1) ,  (2) , . . .} .
Using the terminology of state-space models, we call  (j) the state vector
in the period j.

9.7 Recursive Calculation in the Evolutionary Regression Model
239
Analogously to Section 9.4 we introduce the following notation:
n|n1 := Pro ( (n) |L (1, X1, . . . , Xn1)) ,
n|n := Pro ( (n) |L (1, X1, . . . , Xn)) ,
Qn|n1 := E
·³
 (n)  n|n1
´ ³
 (n)  n|n1
´0¸
,
Qn|n := E
·³
 (n)  n|n
´ ³
 (n)  n|n
´0¸
.
Notice that
n|n1 = \
\
 (n) = credibility estimator of  (n) ,
and that Qn|n1, respectively Qn|n are the quadratic loss matrices of the
vector n|n1, respectively of the vector n|n.
We will now show that the results from Sections 9.4 and 9.5 can be carried
over to the regression case.
9.7 Recursive Calculation in the Evolutionary
Regression Model
As in Theorem 9.6, we assume that the Xj’s are, on average, uncorrelated,
i.e.
E [Cov (Xj,Xk|)] = 0
for j 6= k.
(9.53)
In most cases in practice, the condition (9.53) is a reasonable assumption,
because in most cases one can assume that, conditional on the risk proﬁle, the
observations in the dierent years are independent, i.e. that Cov (Xj,Xk|) =
0 for j 6= k.
In Section 9.4 we then imposed conditions on the process {µ (j) : j =
1, 2, . . .}. We saw that the credibility premium was recursive, as deﬁned in
Deﬁnition 9.1, if this process had orthogonal increments, which is equivalent
to saying that Pro (µ (n+1)| L (1, µ (1) , . . . , µ (n))) = µ (n) . Then we
weakened this condition somewhat, in that we allowed, in addition, for linear
transformations, i.e. we assumed that Pro (µ (n+1)| L (1, µ (1) , . . . , µ (n)))
= anµ (n) + bn for known constants an and bn. Here, we extend these con-
ditions to the sequence { (j) : j = 1, 2, . . .} in an appropriate manner. The
corresponding assumptions are
Pro ( (n+1) |L(1,  (1) ,  (2) , . . . ,  (n))) =  (n) ,
(9.54)
for Case I, respectively
Pro ( (n+1) |L(1,  (1) ,  (2) , . . . ,  (n))) = An (n) + bn,
(9.55)

240
9 Evolutionary Credibility Models and Recursive Calculation
for Case II.
Note that (9.54) is equivalent to saying that the process { (j) : j =
1, 2, . . .} has orthogonal increments, i.e. that
 (n+1)   (n) B L (1,  (1) , . . . ,  (n)) ,
(9.56)
or that
E [ (n+1)   (n)] = 0
and
E
£
( (n+1)   (n)) ·  (k)0¤
= 0
for k = 1, 2, . . . , n,
where on the right-hand side, by 0 we mean a vector or matrix full of zeroes.
As deﬁned in Section 9.5 we write without loss of generality
2
j := E [Var [Xj|j]] = 2
wj
,
where the wj’s are appropriate weights.
Theorem 9.8 Under the assumptions (9.53)—(9.55) we have the following
recursion formulae (Kalman Filter form):
i) Anchoring (period 1)
1|0 = E [ (1)] ,
Q1|0 = E
·³
 (1)  1|0
´
·
³
 (1)  1|0
´0¸
.
ii) Recursion (n  1)
a) Updating
n|n = n|n1 + n
³
Xn  y0
nn|n1
´
,
(9.57)
where n =
Qn|n1yn
y0nQn|n1yn + 2
wn
,
(9.58)
Qn|n = (I  ny0
n) Qn|n1.
(9.59)
b) Change from n to n+1 (movement in parameter space)
Case I:
n+1|n = n|n,
(9.60)
Qn+1|n = Qn|n + Dn+1,
(9.61)
where Dn+1 = E
£
( (n+1)   (n))
· ( (n+1)   (n))0 ¤
.

9.7 Recursive Calculation in the Evolutionary Regression Model
241
Case II:
n+1|n = Ann|n + bn,
(9.62)
Qn+1|n = AnQn|nA0
n + Dn+1,
(9.63)
where Dn+1 = E
£
( (n+1)  An (n)  bn)
· ( (n+1)  An (n)  bn)0 ¤
.
Analogously to Section 9.5, the recursive calculation of the credibility pre-
mium and its quadratic loss can be written more compactly by combining the
two steps “updating” and “movement in parameter space”, which have been
deliberately separated in the statement of the Theorem 9.8. This leads to the
following corollary which is an immediate consequence of Theorem 9.8 and
where we use the identities
\
\
 (n+1) := n+1|n,
Qn := Qn|n1.
Corollary 9.9 (recursive calculation of the credibility estimator of
the regression parameter). Under the same conditions as in Theorem 9.8,
we can calculate the credibility estimator \
\
 (n) and its quadratic loss recur-
sively as follows:
i) Anchoring (period 1)
\
\
 (1) = E [ (1)] ,
Q1 = E
"µ
 (1)  \
\
 (1)
¶ µ
 (1)  \
\
 (1)
¶0#
.
ii) Recursion (n  1)
Case I:
\
\
 (n+1) =
½ \
\
 (n) + n
µ
Xn  y0
n
\
\
 (n)
¶¾
,
(9.64)
where n =
Qnyn
y0nQnyn + 2
wn
,
(9.65)
Qn+1 = (I  ny0
n) Qn + Dn+1
(9.66)
= Qn (I  yn0
n) + Dn+1,
where Dn+1 = E
£
( (n+1)   (n))
· ( (n+1)   (n))0 ¤
.

242
9 Evolutionary Credibility Models and Recursive Calculation
Case II:
\
\
 (n+1) = An
½ \
\
 (n) + n ·
µ
Xn  y0
n
\
\
 (n)
¶¾
+ bn,
(9.67)
where n =
Qnyn
y0nQnyn + 2
wn
,
(9.68)
Qn+1 = An (I  ny0
n) QnA0
n + Dn+1
(9.69)
= AnQn (I  yn0
n) A0
n + Dn+1,
where Dn+1 = E
£
( (n+1)  An (n)  bn)
· ( (n+1)  An (n)  bn)0 ¤
.
Remarks:
•
Notice the analogy to Theorem 9.6 and Corollary 9.7.
•
One can easily show that the credibility estimator \
\
µ (n) := y0
n
\
\
 (n) is
also the credibility estimator (predictor) c
c
Xn of Xn. Notice that the second
summand in (9.57), which represents the “correction” or adjustment of
\
\
 (n) resulting from the newly arrived observation Xn, is of the form
n
µ
Xn  c
c
Xn
¶
.
(9.70)
The “direction vector” n gives the (shrinking) direction of the correction,
and the deviation of Xn from the predicted value c
c
Xn gives the size of the
correction.
•
The “non-evolutionary” credibility regression model (see Chapter 8, Model
Assumptions 8.2) is included in Case I). Because in this case  (n) =
 () for all n (the risk proﬁle doesn’t change), the matrix Dn+1 falls
out of (9.66). As in the Bühlmann—Straub model, the credibility estimator
of the standard regression model (cf. Model Assumptions 8.2) can also
be written recursively. In contrast to the Bühlmann–Straub model, the
transition from the non-recursive to the recursive formula is, however, not
so immediate. It is important to realize that the recursive formula is more
general, in that it allows one to also ﬁnd the credibility estimator in cases
where there is only one or very few observations and (Y 0Y ) is not of full
rank, where Y is the design matrix as deﬁned in (8.7).
•
By an appropriate choice of the components of  (n) (state space), as
well as application of linear transformations (movement equations), the
evolutionary regression model allows the modelling of a large number of
evolutionary phenomena. For example, in this way we can allow the compo-
nents of  (n) to be the correct individual premiums in a limited number
of earlier periods, so that
 (n)0 = (µ (n) , µ (n1) , . . . , µ (np+1)) .
(9.71)

9.7 Recursive Calculation in the Evolutionary Regression Model
243
Formally, the argument of  in (9.71) depends on (n, n1, . . . , np+1).
Nevertheless we have written  (n) as before.
In particular, we can model in this way all situations where the process
{µ (j) : j = 1, 2, . . .} is an ARMA process (autoregressive moving aver-
age). We can also model the situation described in Chapter 9 of a station-
ary AR(1) process with random mean µ () . After the proof of Theorem
9.8 we will give a number of examples from this rich family of time series
models.
Proof of Theorem 9.8: It is enough to prove the theorem for Case I. Case
II then follows directly from Case I and the linearity property of projections.
Let µn|n1, respectively µn|n, be estimators of µ (n) based on the ﬁrst
n1, respectively the ﬁrst n observations and qn|n1, respectively qn|n, be the
corresponding quadratic loss. From Theorem 9.3 and Theorem 9.6 we have
µn|n = nXn + (1  n) µn|n1,
(9.72)
where n =
qn|n1
qn|n1 + 2
wn
,
or written somewhat dierently
µn|n = µn|n1 +
qn|n1
qn|n1 + 2
wn
³
Xn  µn|n1
´
.
(9.73)
From the regression assumption (9.52) and the linearity property of projec-
tions we have also that
µn|n = y0
nn|n,
(9.74)
µn|n1 = y0
nn|n1,
(9.75)
qn|n1 = y0
nQn|n1yn.
(9.76)
Substituting (9.74)—(9.76) into (9.73) we get
y0
nn|n = y0
nn|n1 +
y0
nQn|n1yn
y0nQn|n1yn + 2
wn
³
Xn  y0
nn|n1
´
,
or
y0
nn|n = y0
n
³
n|n1 + n
³
Xn  y0
nn|n1
´´
.
(9.77)
where n was deﬁned in (9.58). Because (9.77) holds for every yn, we conjec-
ture that
n|n = n|n1 + n
³
Xn  y0
nn|n1
´
.
(9.78)
Note that (9.77) does not imply the conjecture, since yn appears also inside
the parentheses.

244
9 Evolutionary Credibility Models and Recursive Calculation
We prove the validity of (9.78) by checking that the right-hand side of
(9.78), which we denote by 
n|n, satisﬁes the normal equations (Corollary
3.17). We have then to show that
E
h
 (n)  
n|n
i
= 0,
(9.79)
E
h³
 (n)  
n|n
´
Xj
i
= 0
for j = 1, 2, . . . , n.
(9.80)
i)
From
E
h
 (n)  n|n1
i
= 0
and
E
h
Xn  y0
nn|n1
i
= E
h
E [Xn| n]  y0
nn|n1
i
= y0
nE
h
 (n)  n|n1
i
= 0,
(9.79) follows directly.
ii) Because n|n1 is the credibility estimator of  (n) based on the obser-
vations until period n  1, it holds for j = 1, 2, . . . , n  1 that
E
h³
 (n)  n|n1
´
Xj
i
= 0,
E
h³
Xn  y0
nn|n1
´
Xj
i
= E
h
y0
n
³
 (n)  n|n1
´
Xj
i
= y0
nE
h³
 (n)  n|n1
´
Xj
i
= 0.
Thus (9.80) is also satisﬁed for j = 1, 2, . . . , n  1.
iii) It remains to show that
E
h³
 (n)  
n|n
´
Xn
i
= E
h³
 (n)  
n|n
´ ³
Xn  µn|n1
´i
= 0,
(9.81)
where the insertion of µn|n1 is allowable because of i) and ii).
This is the same as saying that
E
h³
 (n)  n|n1
´ ³
Xn  µn|n1
´i
= nE
·³
Xn  µn|n1
´2¸
.
It holds that

9.7 Recursive Calculation in the Evolutionary Regression Model
245
E
h³
 (n)  n|n1
´ ³
Xn  µn|n1
´i
= E
·³
 (n)  n|n1
´ ³
 (n)  n|n1
´0
yn
¸
= Qn|n1 yn.
nE
·³
Xn  µ (n) + µ (n)  µn|n1
´2¸
= n
µ 2
wn
+ y0
nQn|n1y
¶
= Qn|n1 yn.
and thus (9.81) is shown.
This ends the proof for the updating formula (9.57) of Theorem 9.8.
¤
For the quadratic loss matrix, by explicit calculation we get
Qn|n = E
h³
 (n)  n|n1  n
³
Xn  µn|n1
´´
·
³
 (n)  n|n1  n
³
Xn  µn|n1
´´0 ¸
= E
·³
 (n)  n|n1
´
·
³
 (n)  n|n1
´0¸
 E
·³
 (n)  n|n1
´
·
³
 (n)  n|n1
´0¸
yn0
n
 ny0
n E
·³
 (n)  n|n1
´
·
³
 (n)  n|n1
´0¸
+ ny0
n E
·³
 (n)  n|n1
´
·
³
 (n)  n|n1
´0¸
yn0
n
+ nE
h
(Xn  µ (n))2i
0
n
= Qn|n1  Qn|n1yn0
n  ny0
nQn|n1
(9.82)
+ n
µ
y0
nQn|n1yn + 2
wn
¶
0
n.
Note that, for the term
y0
nQn|n1yn + 2
wn
,
which occurs in the numerator of n (see (9.58)), it holds that
n
µ
y0
nQn|n1yn + 2
wn
¶
0
n = Qn|n1yn0
n
and

246
9 Evolutionary Credibility Models and Recursive Calculation
n
µ
y0
nQn|n1yn + 2
wn
¶
0
n = ny0
nQn|n1.
Substituting into (9.82) we get
Qn|n = (I  ny0
n) Qn|n1 = Qn|n1 (I  yn0
n) ,
whereby the part “updating” of Theorem 9.8 is proved.
The validity of (9.60) and (9.61) can be proved exactly as in Theorem 9.4
and is a consequence of the requirement that the sequence { (j) : j = 1, . . .}
has orthogonal increments. We ﬁrst show that n+1|n = n|n. From the lin-
earity property of projections we have that
n+1|n = n|n + Pro ( (n+1)   (n) |L (1, X1, . . . , Xn)) .
Thus, we have to show that
 (n+1)   (n) B L (1, X1, . . . , Xn) .
(9.83)
From (9.56) it follows directly that
E [( (n+1)   (n)) · 1] = 0.
Further, we have that
E [( (n+1)   (n)) Xj] = E
£
( (n+1)   (n)) 0 (j)
¤
yj
= 0
for j = 1, 2, . . . , n.
And so (9.83) and (9.60) are shown.
For the quadratic loss of n+1|n we get
Qn+1|n = E
·³
n+1|n   (n+1)
´2¸
= E
·³
n|n   (n) +  (n)   (n+1)
´2¸
=
·
E
³
n|n   (n)
´2¸
+ E
h
( (n+1)   (n))2i
= Qn|n + Dn+1.
In the second equation we used the already proved fact, that n+1|n = n|n.
By conditioning on  and keeping in mind that E
h
n|n
¯¯¯ 
i
=  (n), it
becomes clear why the cross-term disappears in the third equation. With this
(9.61) is shown. This completes the proof of Theorem 9.8.
¤
In the following, for illustrative purposes, we present a few examples from
the family of ARMA processes. In each of these examples, we assume that
E [Cov (Xk, Xj| )] = 2kj
holds.

9.7 Recursive Calculation in the Evolutionary Regression Model
247
Example 9.6 (autoregressive process of order 1 with random mean)
We refer to Example 9.5. However, now the mean of the autoregressive process
is assumed not to be a constant µ, but a random variable, the value of which
depends on the individual risk proﬁle. In this way a collective of independent
and similar risks can be described, in which the individual, correct premium of
each contract varies randomly about a mean, which depends on the individual
risk proﬁle.
The model assumptions for the pure risk premiums of a particular risk are
given by
µ (n+1) = µ (n) + (1  ) µ (0) + n+1 for n = 1, 2, . . . ,
(9.84)
where the j are uncorrelated with E [j] = 0 and Var [j] = 2. We fur-
ther assume that, conditional on µ (0) , the process {µ (1) , µ (2) , . . .} is
a stationary process with
E [µ(j)|µ (0)] = µ (0) ,
Var [µ(j)|µ (0)] =
2
1  2
(cf. (9.46)).
µ (0) is therefore the stochastically drawn “mean”, around which the AR(1)
process of the correct individual premiums varies. For the unconditioned
process we have then that
E [µ (j)] = E [µ (0)] = µ
for j = 1, 2, . . . ,
Var [µ (j)] =
2
1  2 +  2,
(9.85)
 2 = Var [µ (0)].
Note: If we use this model to model a portfolio of independent risks, then
(9.85) means that the heterogeneity of the portfolio stays constant over the
passage of time — an assumption which is reasonable.
In order to ﬁnd the credibility estimator for µ(j), we want to use the
Kalman Filter technique (Theorem 9.8). To do this, we must ﬁrst deﬁne the
state or regression vector  (n). In our case it is given by
 (n) =
µµ (n)
µ (0)
¶
.
On the basis of (9.84) we get
 (n+1) =
3
C

1  
0
1
4
D  (n) +
3
C
n+1
0
4
D ,

248
9 Evolutionary Credibility Models and Recursive Calculation
and the regression equation is
µ (n+1) = (1, 0)  (n+1) .
We can now apply Theorem 9.8 and get:
i)
Anchoring
1|0 = 0 =
µµ
µ
¶
and
Q1|0 =
Ã
 2 +
2
12
 2
 2
 2
!
.
ii) Recursion
a) Updating
y0
n = (1, 0) for all n ,
n|n = n|n1 + n
³
Xn  (1, 0) n|n1
´
,
where n =
Qn|n1 (1, 0)0
(1, 0) Qn|n1 (1, 0)0 + 2 ,
= ﬁrst column of Qn|n1
q(11)
n|n1 + 2
,
where q(11)
n|n1 = upper left corner of Qn|n1,
2 = E [Var [Xj|]] .
Qn/n =
3
E
E
CI 
Qn|n1
µ1 0
0 0
¶
q(11)
n|n1 + 2
4
F
F
D Qn|n1.
After some calculations one also obtains that
Qn/n =
2
q(11)
n|n1 + 2
µ
Qn|n1 +
µ 0 0
0

2
¶¶
,
where  = det
¡
Qn|n1
¢
.
b) Movement in parameter space
n+1|n =
µ 1  
0
1
¶
n|n,
Qn+1|n =
µ 1  
0
1
¶
Qn|n
µ

0
1   1
¶
+
µ
2 0
0
0
¶
.

9.7 Recursive Calculation in the Evolutionary Regression Model
249
Example 9.7 (autoregressive process of order p with random mean)
All assumptions are analogous to Example 9.6, only instead of (9.84) we have
µ (n+1) = 1 (µ (n)  µ (0))+· · · p (µ (np+1)  µ (0))+µ (0)+n+1.
We choose
 (n) =
3
E
E
E
C
µ (n)
...
µ (np+1)
µ (0)
4
F
F
F
D
and get as movement equations
 (n+1) =
3
E
E
E
E
E
E
E
E
E
C
1 2 . . . . . . p 1 
pP
k=1
k
1
0 · · · · · · 0
0
0
1
0
0
0
... ... ... ... ...
0
0
0
1
0
0
0 · · · · · ·
0
0
1
4
F
F
F
F
F
F
F
F
F
D
 (n) +
3
E
E
E
E
E
E
E
E
E
E
E
E
C
n+1
0
...
...
...
...
0
4
F
F
F
F
F
F
F
F
F
F
F
F
D
.
Thus all of the conditions for Theorem 9.8 are satisﬁed and we can again use
the Kalman Filter to calculate the credibility estimator.
Remark on Examples 9.6 and 9.7:
•
These are very natural examples to illustrate that, for the evolutionary
credibility regression model, we may have a situation where the dimension
of the regression parameter is higher than the number of observations (see
fourth bullet of the remarks beginning on page 242).
Example 9.8 (Moving average process of order q)
Here also the assumptions are analogous to the previous examples, but instead
of (9.84) we have
µ (n+1) = µ (n) + n+1 + 1n + · · · + qnq.
We deﬁne
 (n) =
3
E
E
E
C
µ (n)
n
...
nq
4
F
F
F
D

250
9 Evolutionary Credibility Models and Recursive Calculation
and get the movement equations
 (n+1) =
3
E
E
E
E
E
E
E
E
E
C
1 1 · · · · · · · · · q
0 0 · · · · · · · · · 0
0 1
0
...
...
0
1
...
...
...
... ... ... ...
0 · · · · · ·
0
1
0
4
F
F
F
F
F
F
F
F
F
D
 (n) +
3
E
E
E
E
E
E
E
E
C
0
n+1
0
...
...
0
4
F
F
F
F
F
F
F
F
D
.
Thus we can also apply the Kalman Filter algorithm here.

10
Multidimensional Evolutionary Models and
Recursive Calculation
10.1 Introduction
We have already introduced multidimensional credibility in Chapter 7. It is
characterized by the fact that the quantity µ () to be estimated is multi-
dimensional. The observations or a suitable compression of the observations
are then described by vectors X, having the same dimension as µ () (see
abstract multidimensional credibility model, Section 7.2).
In Chapter 7 we discussed, as a typical example, the case where for each risk
i, the components of the vector Xi represent the claim frequencies of normal
and large claims. Other examples mentioned there were claim frequency as
one component and average claim amount as the other component or claims
observations of dierent layers or dierent claim types. In Chapter 9, in the
last point of the remarks beginning on page 225, we indicated that we can also
interpret the abstract vector X in another way, namely for each time point j
as vector Xj summarizing the individual observations of a whole collective of
risks at that time. As mentioned there, this last possibility has a particular
relevance in the evolutionary case and lends the evolutionary multidimensional
model, so to speak, an extra dimension, in that it allows the modelling of the
development over time of a collective in its entirety. We will deal with this
point more closely in the next section.
Let us now consider the vectors Xj. In the non-evolutionary case, discussed
in Chapter 7, we assumed that the risk proﬁle  remained constant over time,
i.e. that
µ () := E [Xj|]
for all j.
In contrast, in the evolutionary model, we assume analogously to chapter 9
that the risks change over time and that the risk proﬁle  is a stochastic
process
 = {1, 2, . . .} ,
(10.1)
where the components j represent the risk proﬁles in the corresponding years
j = 1, 2, . . .. The conditional expectations also change with time, i.e.

252
10 Multidimensional Evolutionary Models and Recursive Calculation
µ () = {µ (1) , µ (2) , . . .} .
Remarks:
•
As discussed above, depending on the application, the Xj can represent
the multidimensional observation of a single risk or the entirety of the
single observations from a whole collective in year j. In the ﬁrst case, we
have for each risk i, a multidimensional observation Xij. Its embedding in
a collective of similar risks can be modelled as it was done in Section 9.3.
The credibility estimator then depends only on the observation vectors of
the risk i under consideration, and not on the observations from the other
risks. The data from the collective are, however, used to determine the
structural parameter. In the second case, for each year only one observation
vector Xj is available. The credibility estimator for the ith component, i.e.
for the ith risk, then depends also on the other data from the collective.
On the other hand, because the whole collective is described by one single
vector, we must ﬁnd other ways to estimate the structural parameter.
•
Because in the following the letter I is reserved for the identity matrix,
throughout this chapter we denote the total number of risks by N, i.e. the
index i takes the values i = 1, 2, . . . , N.
10.2 On the Embedding of the Individual Risk in a
Collective
In Chapter 9, Section 9.3, (see the second last point in the remarks on the
evolutionary credibility model, page 226) we have characterized each risk i
(i = 1, 2, . . . , N) by its risk proﬁle
i = {i1, i2, . . . , ij, . . .}
and the process of observations
Xi = {Xi1, Xi2, . . . , Xij, . . .} .
The embedding in the collective, which we have carried out as in the non-
evolutionary
case,
has
then
led
to
the
assumptions
that
the
pairs
{(X1, 1) , (X2, 2) , . . . (XN, N)}
are
independent
and
that
{1, 2, . . . , N} are independent and identically distributed.
The problems associated with these assumptions have already been in-
dicated (page 225). In many cases, it may be true that the risk proﬁles
of the dierent individual risks are eected by common (and not indepen-
dent) changes. We also noted in Chapter 9 that some of the models handled
there (e.g. Gerber—Jones) led to collectives which drifted apart, i.e. whose
heterogeneity could become arbitrarily large. We rescued ourselves from this
di!culty by the introduction of appropriate linear transformations (or more
generally by the elimination of common trends).

10.3 Multidimensional Evolutionary Models
253
In this section, we choose a more radical procedure: we remove the above
assumptions. Instead, we describe and analyse all the risks i = 1, 2, . . . , N of
the collective simultaneously, i.e. we consider the multidimensional sequences
 = {1, 2, . . .} , where j = (ij) ,
i = 1, 2, . . . , N,
(10.2)
X = {X1, X2, . . .} , where Xj = (Xij) ,
i = 1, 2, . . . , N.
In this way, we allow arbitrary dependencies within (i.e. between the compo-
nents of) the multidimensional quantities j, Xj.
Notice that (10.2) ﬁts well with the general description (10.1), because
the j in (10.1) can be arbitrary random variables. In the case which we
discuss here, it is sensible to consider j as a vector with the components
ij (i = 1, 2, . . . , N), where ij is the risk proﬁle of the ith risk in year j.
Therefore, in view of the general meaning of the parameter i, we may use the
notation j instead of j also in cases where j represents a vector, which
we will do from now on.
Analogously to Section 9.3 it should also be true in the multidimensional
case that
E [Xj|] = E [Xj|j] =: µ (j) ,
E
£
Cov
¡
Xj, X0
j|
¢¤
= E
£
Cov
¡
Xj, X0
j|j
¢¤
=: Ej,
i.e. the ﬁrst two moments of the multidimensional quantity Xj depend only
on the current value of the risk proﬁle j. We also call j (non-observable)
state variables at time j.
Analogously to (9.12) we require that
E [Cov (Xj, X0
k|)] = 0
for j 6= k,
i.e. the observation vectors at dierent time points should, on the average, be
uncorrelated.
10.3 Multidimensional Evolutionary Models
Analogous to the dierentiation between Cases I and II in Theorem 9.6, re-
spectively between the assumptions “orthogonal increments” (formula 9.19)
and “linear Markov property” (formula 9.23), we want to dierentiate between
these two cases here.
•
Case I: The process {µ (j) : j = 1, 2, . . .} has orthogonal increments.
This means that
Pro [µ (j+1) |L (1, µ (1) , . . . , µ (j))] = µ (j) ,
(10.3)
which implies that the increments have expected value zero and that the
covariance of increments at dierent times is zero, i.e.

254
10 Multidimensional Evolutionary Models and Recursive Calculation
Cov
¡
µ (j+1)  µ (j) , (µ (k+1)  µ (k))0¢
= 0 for j 6= k,
E [µ (j+1)  µ (j)] = 0 for all j.
•
Case II: The process {µ (j) : j = 1, 2, . . .} satisﬁes the linear Markov
property.
This means that
Pro [µ (j+1) |L (1, µ (1) , . . . , µ (j))] = Aj+1 µ (j) + bj+1.
(10.4)
Note that Case II is a generalization of Case I, in that additionally lin-
ear transformations are allowed (transformation matrix Aj+1, shift vector
bj+1).
In the following we use the notation introduced in Chapter 9.
µn|k :=
Pro [µ (n) |L (1, X1, . . . , Xk)]
= projection on data until time k (k = n or k = n  1).
Qn|k :=
E
·³
µ (n)  µn|k
´
·
³
µ (n)  µn|k
´0¸
= loss matrix using data until time k.
Analogous to Theorem 9.6 the following recursive formulae hold.
Theorem 10.1. (multidimensional Kalman-Filter algorithm)
i) Anchoring (period 1)
µ1|0 = E [µ (1)] ,
Q1|0 = Cov (µ (1) , µ0 (1)) .
ii) Recursion (periods n  1)
a) Updating
µn|n = µn|n1 + Zn
³
Xn  µn|n1
´
,
(10.5)
where Zn = Qn|n1
¡
Qn|n1 + Sn
¢1 ,
Sn = E [Cov (Xn, X0
n|n)] ,
Qn|n = (I  Zn) Qn|n1.
(10.6)
b) Change from n to n+1 (movement in parameter space)
Case I: {µ (j) : j = 1, 2, . . .} has orthogonal increments (see (10.3)).
It then holds that
µn+1|n = µn|n,
(10.7)
Qn+1|n = Qn|n + Dn+1,
where

10.4 Modelling a Collective with Both Joint and Individual Movements
255
Dn+1 = E [µ (n+1)  µ (n) (µ (n+1)  µ (n))0] .
Case II: The process {µ (j) : j = 1, 2, . . .} satisﬁes the linear Markov
property (see (10.4)).
It then holds that
µn+1|n = An+1µn|n + bn+1,
(10.9)
Qn+1|n = An+1Qn|nA0
n+1 + Dn+1,
(10.10)
where
Dn+1 = E [(µ (n+1)  An+1µ (n)  bn+1)
(10.11)
· (µ (n+1)  An+1µ (n)  bn+1)0] .
Remark:
•
The matrices of the observation errors, i.e. the matrices Ej (j = 1, 2, . . .)
will have a diagonal form in many applications. The matrices of the in-
novation errors of the risk proﬁle process, i.e. the Dj (j = 1, 2, . . .) are
typically not diagonal. If this were the case (and if in addition Q1|0 is
diagonal), then the multidimensional algorithm just reduces to the indi-
vidual algorithm applied to each individual risk as presented in Chapter 9.
Proof of Theorem 10.1:
The proof follows the argument presented in Chapter 7. In the estimator
µn|n (formula (10.5)) µn|n1 assumes the role of the “collective average” and
Qn|n1 assumes the role of the loss matrix (deviations from the collective
average).
¤
10.4 Modelling a Collective with Both Joint and
Individual Movements
We saw in Sections 10.1 and 10.2 that the multidimensional model allows us
to model the development over time of the entire collective, and also to model
changes which aect all risks in the collective in a similar manner. In the
following, we present two examples in which we ﬁrst show how such a model
might look, and then how, using multidimensional techniques, we can ﬁnd the
credibility estimator.
As we already mentioned, in real contexts, it is frequently the case that the
risk proﬁle of an individual depends both on individual speciﬁc factors and
on global factors which aect all risks in the collective. For example, consider
the share prices of a ﬁrm: they depend on both global business conditions and
market trends, as well as developments which are speciﬁc to the ﬁrm itself. In
the insurance business, global factors could include things like changes in the

256
10 Multidimensional Evolutionary Models and Recursive Calculation
law, prevailing weather conditions, cyclical eects, all of which will aect all
risks in the collective at the same time.
In order to model such situations, it is convenient to divide the innovations
(changes to the correct individual premiums) into a collective and an individ-
ual part. This is what we will do in the following two examples. These are the
counterparts to Examples 9.4 (Gerber and Jones model) and 9.5 (autoregres-
sive process of order 1) with the dierence that now we also have movements
which aect all risks in the collective at the same time.
We write
Xj = µ (j) + %j,
(10.12)
i.e. %j is the vector of deviations of the observation vector Xj from the vector
µ (j) of the associated individual premiums.
Example 10.1 (Counterpart to Example 9.4)
Assumptions:
•
Movement
µ (n+1) = µ (n) + n+1
= µ (n) + n+11 + n+1.
(10.13)
The innovation of the ith risk (ith component of the vector n+1) is com-
posed of a component n+1 common to all risks in the collective and a
component i,n+1 which is individual speciﬁc.
Remark on the notation: in Chapter 9 we used n+1 for the innovations.
•
Independence between the components
©
j, ij, %ij : j = 1, 2, . . . ; i = 1, 2, . . . , N
ª
are
independent random variables and are also independent
of the components of µ (j1) .
•
Moments
E
£
j
¤
= E
£
ij
¤
= E [%ij] = 0 for all i and j,
Var
£
j
¤
= $2
for j = 1, 2, . . . ,
Var [%ij] = 2
for all i and j,
Var
£
ij
¤
=  2
for all i and j,
For the matrices Sn and Dn+1, which appeared in Theorem 10.1, we get
from the above assumptions
Sn = Var [%n] = 2I,
Dn+1 = Cov
¡
n+1, 0
n+1
¢
= D (independent of n),

10.4 Modelling a Collective with Both Joint and Individual Movements
257
where
D =
3
E
E
E
E
C
 2 + $2
$2
. . .
$2
$2
 2 + $2 . . .
...
...
...
...
$2
$2
. . .  2 + $2
4
F
F
F
F
D
.
(10.14)
It is useful to write the matrix D as follows:
D =  2I + $2E,
where I is the identity matrix and E is a matrix of 1’s.
We will see that in Example 10.1 (and also in Example 10.2), we can in
general restrict ourselves to matrices of the form
Dp,q = qI + pE,
q, p 5 R.
We will refer to a matrix of this form as being of the Dp,q-form. It is obvious
that we should also use a matrix of the Dp,q-form for the initial matrix Q1|0
in Theorem 10.1.
From Theorem 10.1 we get the following recursion formulae:
i)
Anchoring (period 1)
µ1|0 = E [µ (1)] = µ0,
(10.15)
Q1|0 = q1|0I + p1|0E.
(10.16)
ii) Recursion
a) Updating
µn|n = µn|n1 + Zn
³
Xn  µn|n1
´
,
(10.17)
where Zn = Qn|n1
¡
Qn|n1 + 2I
¢1 ,
(10.18)
Qn|n = (I  Zn) Qn|n1 .
(10.19)
b) Movement
µn+1|n = µn|n,
(10.20)
Qn+1|n = Qn|n + D.
(10.21)
The recursion formulae can be written out explicitly using the fact that all
of the matrices therein have the Dp,q-form, e.g. Qn|n1 = qn|n1I + pn|n1E.
We write this explicit representation componentwise, and we write µ(i)
n|n for
the ith component of µn|n. We will show that the following holds:

258
10 Multidimensional Evolutionary Models and Recursive Calculation
a) Updating
µ(i)
n|n = µ(i)
n|n1 + n
³
Xin  µ(i)
n|n1
´
+ (1  n) n
³
Xn  µn|n1
´
,
(10.22)
where
Xn = 1
N
N
X
i=1
Xin,
µn|n1 = 1
N
N
X
i=1
µ(i)
n|n1.
n =
qn|n1
qn|n1 + 2 ,
(10.23)
n =
Npn|n1
Npn|n1 + qn|n1 + 2 .
(10.24)
Qn|n = qn|nI + pn|nE,
(10.25)
where qn|n =
2
qn|n1 + 2 qn|n1
= (1  n) qn|n1,
(10.26)
pn|n =
2
qn|n1 + 2 ·
2
qn|n1 + 2 + Npn|n1
· pn|n1
= (1  n)2 (1  n) pn|n1.
(10.27)
b) Movement in parameter space
µ(i)
n+1|n = µ(i)
n|n,
(10.28)
Qn+1|n = qn+1|nI + pn|n+1E,
(10.29)
where
qn|n+1 = qn|n +  2,
(10.30)
pn+1|n = pn|n + $2.
(10.31)

10.4 Modelling a Collective with Both Joint and Individual Movements
259
Remarks:
•
(10.22) is a very intuitive result. The ﬁrst correction term gives the correc-
tion resulting from the latest individual claim experience. Included in that
is the estimation for the correction to the collective mean as a result of
that individual observation. The second term is the correction term based
on the collective experience and reﬂects the estimation of the collective
innovation based on all the data from the collective. The factor (1  n)
takes account of the fact that this collective innovation is already included
in the ﬁrst correction term with the credibility weight n.
•
Both in the updating step and in the step “movement in parameter space”,
the corresponding loss matrices Qn|n, respectively Qn|n1, can be calcu-
lated by updating the scalar quantities q and p using the formulae given
in (10.26) and (10.27), respectively (10.30) and (10.31).
In order to show the validity of (10.22)—(10.31), we need the following
lemma.
Lemma 10.2.
(qI + pE)1 = 1
q (I  kE) ,
where k =
p
(q + pN),
N = dimension of the matrix.
Proof:
The result is very easy to verify by multiplying out and using the identity
E2 = N · E.
¤
We carry out the calculations for the recursion formulae (10.17)—(10.19)
under the assumption that Qn|n1 has the Dp,q-form, i.e. that
Qn|n1 = qn|n1I + pn|n1E.
(10.32)
We will show at the end that Qn|n1 does indeed have this form.
From (10.32) and Lemma 10.2, we get
¡
Qn|n1 + 2I
¢1 =
1
qn|n1 + 2 I
(10.33)

pn|n1
¡
qn|n1 + 2¢ ¡
qn|n1 + 2 + Npn|n1
¢ E,

260
10 Multidimensional Evolutionary Models and Recursive Calculation
Zn = Qn|n1
¡
Qn|n1 + 2I
¢1
=
qn|n1
qn|n1 + 2 I
+
µ
2
qn|n1 + 2
¶ µ
pn|n1
qn|n1 + 2 + Npn|n1
¶
E.
This can also be written as
Zn = nI + 1
N (1  n) nE,
where
n =
qn|n1
qn|n1 + 2 ,
(10.34)
n =
Npn|n1
Npn|n1 + qn|n1 + 2 .
(10.35)
Plugging into (10.17) we thus get the update formula (10.22), which we have
written componentwise.
The next step in the recursion formula is the updating of the loss matrix
using (10.19). We get
(I  Zn) = (1  n)
³
I  n
N E
´
,
and after some calculation
(I  Zn) Qn/n1 = (1  n)
³
qn|n1I +
³
(1  n) pn|n1  n
N qn|n1
´
E
´
=
2qn|n1
qn|n1 + 2 I
+
2
qn|n1 + 2 ·
2pn|n1
qn|n1 + 2 + Npn|n1
E.
From this we get directly (10.25)—(10.27).
Finally we get formulae (10.28)—(10.31) for the movement in parameter
space from (10.14),(10.20), (10.21) as well as (10.25)—(10.27).
The starting point for the above derivation was that the matrix Qn|n1
has the Dp,q model form. We have shown that if this is the case then Qn+1|n
also has the Dp,q model form. We have yet to show that it is indeed the case
that Qn|n1 has the Dp,q model form. But this follows by induction from the
assumption that Q1|0 has the Dp,q model form.
¤

10.4 Modelling a Collective with Both Joint and Individual Movements
261
Remarks on Example 10.1:
•
If the individual components of the innovations are non-degenerate, i.e. if
 2 > 0, this example also describes a situation where, analogous to the
Gerber and Jones model, the heterogeneity of the portfolio grows without
limit, which does not correspond to anything one usually sees in practice.
Equally unrealistic is the situation where  2 = 0, which would imply that
the size of the changes to the correct individual premiums is the same for
all the risks.
•
In order to avoid the drifting-apart phenomenon and at the same time
to allow for individual changes, we may consider an autoregressive model
instead of a model with orthogonal increments. This leads to the next
example.
Example 10.2 (Counterpart to Example 9.5)
The dierence between this and Example 10.1 is that instead of the movement
equation (10.13) we have an autoregressive process of order 1, i.e. we have that
µ (n+1) = µ0 +  (µ (n)  µ0) + n+1,
(10.36)
where || < 1,
(10.37)
µ = E [µ (1)]
The innovations j and the deviations %j are deﬁned exactly as in Example
10.1 and satisfy the same conditions as there. As in Example 10.1, we further
assume that Cov (µ (1) , µ0 (1)) has the Dp,q model form.
Remarks:
•
Conceptually, one can also think of the individual premium as being di-
vided into an overall “collective component” and an “individual compo-
nent”. Assumption (10.36) is then equivalent to saying that the collective,
as well as the individual components are autoregressive with the same
contraction parameter . We will consider the case where the contraction
parameters for the individual and collective process are not the same, in
Section 10.6. The extension of Example 10.2 to this case will follow in
Example 10.4.
•
The conditions (10.36) and (10.37) together with the conditions about the
innovations n imply that (10.36), under “appropriate” assumptions for
Var (µ (1)) , is a stationary process (cf. (9.46) in Example 9.5). Note also,
that E [µ (j)] = µ for all j.
•
In contrast to Example 10.1, in this example the portfolio does not drift
apart.
The recursion formulae are derived using exactly the same considerations
as in Example 10.1. From the anchoring to the updating, nothing changes.

262
10 Multidimensional Evolutionary Models and Recursive Calculation
The corresponding formulae (10.15)—(10.19), resp. (10.22)—(10.27) derived in
Example 10.1 can be used without change.
Only the movement equations look dierent. Instead of (10.28) - (10.31),
we have
µ(i)
n+1|n = µi + 
³
µ(i)
n|n  µi
´
,
(10.38)
Qn+1|n = qn+1|nI + pn+1|nE,
(10.39)
where
qn+1|n = 2 qn|n +  2,
(10.40)
pn+1|n = 2 pn|n + $2.
(10.41)
These formulae follow from (10.36) and equations (10.9)—(10.10) in Theorem
10.1.
10.5 Multidimensional Evolutionary Regression Models
In contrast to the set-up in Section 10.3, where we directly modelled the
multidimensional process µ (1) , µ (2) , . . . , µ (n) , . . . , we take the regres-
sion approach (multidimensional version of the procedure in Theorem 9.6 and
Corollary 9.7). We assume that
µ (k) = Hk  (k) ,
(10.42)
where µ (k) = N × 1 vector,
 (k) = p × 1 vector,
Hk
= N × p matrix.
We model the process of the regressors
{ (1) ,  (2) , . . . ,  (n) , . . .} .
This generalization allows a greater ﬂexibility and variety of models. This is
because we have so much freedom in the choice of the regressors.
From the point of view of the statistician, since these regressors have to
be estimated from the data, we need to be careful in our choice of regressors.
While a very highly parameterized model may lead to a good ﬁt, it may have
the undesirable feature of having a large estimation error and therefore be a
poor predictor.
For the process of regressors, we make the following assumptions, where as
before (cf. Section 10.3), we consider two cases:
•
Case I: The process { (j) : j = 1, 2, . . .} is a multidimensional process
with orthogonal increments, i.e.
Pro [ (n+1) |L (1,  (1) , . . . ,  (n))] =  (n) .

10.5 Multidimensional Evolutionary Regression Models
263
•
Case II: The process { (j) : j = 1, 2, . . .} is a multidimensional process
having the linear Markov property, i.e.
Pro [ (n+1) |L (1,  (1) , . . . ,  (n))] = An+1  (n) + bn+1.
Theorem 10.3 is the multidimensional version of the Theorem 10.1. This
“general form of the Kalman Filter” corresponds to the form which is usually
referred to as the Kalman Filter in the literature.
Theorem 10.3 (General form of the Kalman Filter).
i) Anchoring (period 1)
1|0 = E [ (1)] ,
(10.43)
Q1|0 = Cov
¡
 (1) , 0 (1)
¢
.
(10.44)
ii) Recursion (periods n  1)
a) Updating
n|n = n|n1 + Gn
³
Xn  Hnn|n1
´
,
(10.45)
where Gn = Qn|n1H0
n
¡
HnQn|n1H0
n + Sn
¢1 , (10.46)
Sn = E [Cov (Xn, X0
n|n)] ,
Qn|n = (I  GnHn) Qn|n1.
(10.47)
b) Movement in parameter space
Case I:
n+1|n = n|n,
(10.48)
Qn+1|n = Qn|n + Dn+1,
(10.49)
where
Dn+1 = E
£
( (n+1)   (n)) · ( (n+1)   (n))0¤
.
Case II:
n+1|n = An+1n|n + bn+1,
(10.50)
Qn+1|n = An+1Qn|nA0
n+1 + Dn+1,
(10.51)
where
Dn+1 = E [( (n+1)  An+1 (n)  bn)
· ( (n+1)  An+1 (n)  bn)0] .

264
10 Multidimensional Evolutionary Models and Recursive Calculation
Remarks:
•
Notice the formal identity of Theorem 10.3 with Theorem 9.8. The row
vector y0
n in Theorem 9.8 will be replaced by the matrix Hn in Theorem
10.3.
•
In the literature, the matrix Gn used in (10.46) is referred to as the
“Kalman gain”.
•
The non-evolutionary regression model is included in Case I, because in
this case we have  (n) =  () for all n (compare third remark after
Corollary 9.9). The algorithm of Theorem 10.3 hence lends itself to ﬁnding
the credibility premium in the multidimensional case (Chapter 7) also if
the observation vector is of lower dimension than the estimand vector.
On the proof of Theorem 10.3
We omit a formal proof, because it follows exactly the same series of steps as
in Theorem 9.8, except that here we are in the multidimensional setting.
¤
10.6 Decomposition into an Individual and a Common
Component
As in Section 10.4, we treat here the realistic situation that the risk proﬁle of
an individual depends on both individual factors and global factors, aecting
all the risk proﬁles of all members of the collective.
As in Section 10.4, let
X = {X1, X2, . . . , Xj, . . .}
with Xj = (X1j, X2j, . . . , XNj)0
be the time series of the observations of all the risks i = 1, 2, . . . , N of the
collective, and let
 = {1, 2, . . . , j, . . .}
be the time series of the (multidimensional) risk proﬁles.
We also have the time series of the (multidimensional) individual premiums
µ () = {µ (1) , µ (2) , . . . , µ (j) , . . .} ,
where
µ (j) = {µi (j) : i = 1, 2, . . . N} ,
µi (j) = correct individual premium of the risk
i at timepoint j.
As in Section 10.4 we assume independence of errors, in particular
Xj = µ (j) + %j,
where

10.6 Decomposition into an Individual and a Common Component
265
E [%j] = 0,
Cov
³
%j, %
0
j
´
= 2I,
Cov
³
%j, %
0
k
´
= 0
for j 6= k.
However, for the movement in the parameter space, we now consider another
model.
In Section 10.4, in both Example 10.1 and Example 10.2, we merely split
each of the innovations n+1 into a collective and an individual component.
In this section, the innovations are again deﬁned as in the earlier examples,
but in addition we take the approach that the individual premium µ (j) is
composed of both a global and an individual part. For the correct premium
of the ith risk, we then have that
µi (j) = #j + ij,
(10.52)
where
#j = global component,
(10.53)
ij = individual component.
(10.54)
In order that the global and individual contributions are identiﬁable, we fur-
ther assume that
N
X
i=1
E [ij] = 0.
(10.55)
Note that (10.55) implies
1
N
N
X
i=1
E [µi (j)] = E
£
#j
¤
= #0.
Equations (10.52)—(10.54) in vector and matrix notation give that
µ (j) = H  (j) ,
(10.56)
where  (j)0 =
³
#j, 
0
j
´
=
¡
#j, 1j, . . . , Nj
¢
,
(10.57)
H =
3
E
E
E
E
C
1 1 0 . . . 0
... 0 ...
...
... ...
... 0
1 0 . . . 0 1
4
F
F
F
F
D
= (1, I) ,
(10.58)
where 1 is the vector of 1’s and I is the identity matrix of dimension N × N.
Equation (10.56) is a regression equation, and so the model approach from

266
10 Multidimensional Evolutionary Models and Recursive Calculation
Section 10.5 can be used here. Note also that equation (10.45) from Theorem
10.3 may also be written as
n|n = n|n1 + Gn
³
Xn  µn|n1
´
where µ(i)
n|n1 = #n|n1 + (i)
n|n1.
In the following we reconsider the Examples 10.1 and 10.2 from this point of
view of premium decomposition.
Example 10.3 (another form of Example 10.1)
As in Example 10.1 on page 256 it should hold for the movements that
µ (n+1) = µ (n) + n+11 + n+1.
(10.59)
Using the decomposition into global and individual components, we can also
write (10.59) as
#n+1 = #n + n+1,
i,n+1 = i,n + i,n+1,
where
©
j, ij, %ij : j = 1, 2, . . . ; i = 1, 2, . . . , N
ª
are independent random vari-
ables, which are also independent of the components of µ (j1) , with ﬁrst-
and second-order moments
E
£
j
¤
= E
£
ij
¤
= E [%ij] = 0 for all i and j,
Var [%ij] = 2
for all i and j,
Var
£
ij
¤
=  2
for all i and j,
Var
£
j
¤
= $2
for j = 1, 2, . . . .
The conditions for the multidimensional credibility regression models from
Section 10.5 are satisﬁed, where in the regression equation (10.42) the regres-
sion matrix Hk is replaced by H, as deﬁned in (10.58), and the regression
vector  (n) is given by (10.57). For the matrices Sn and Dn in Theorem
10.3 we have that
Sn = 2 I,
Dn =
3
E
E
E
C
$2
0
 2
...
0
 2
4
F
F
F
D =
µ
$2 0
0
0  2 I
¶
.
In order to apply Theorem 10.3, it remains to specify the initial values (10.43)
and (10.44). If we assume that the process for the global development

10.6 Decomposition into an Individual and a Common Component
267
©
#j : j = 0, 1, 2, . . .
ª
begins at the value #0 and that the superimposed individual process
{ij : j = 1, 2, . . .} ,
i = 1, 2, . . . , N
begins at the value 0, then we have
1|0 =
µ#0
0
¶
,
(10.60)
and
Q1|0 =
µ$2 00
0  2I
¶
.
(10.61)
Remark:
•
Assumption (10.61) can be easily generalized to the situation where we
have a stochastic starting point. The following recursion formulae still hold
and the initial matrix Q1|0 still has the special form (10.80), as deﬁned on
page 269.
Now, we can just apply the whole machinery of the Kalman Filter as de-
scribed in Theorem 10.3. However, as already done in Example 10.1, by updat-
ing the scalar quantities, the recursive formulae can be written out explicitly
using the results of Theorem 10.3.
Let
Qn|n1 =
3
C
sn|n1
tn|n1 10
tn|n1 1
qn|n1 I + rn|n1 E
4
D
be the loss matrix of n|n1, where 1 (respectively E) is a vector of length N
(respectively, a matrix of dimension N × N, the elements of which are 1’s).
This form of the loss matrix is a consequence of the fact that the elements
(i)
n|n1, i = 1, 2, . . . , are exchangeable.
As we will show, we get the following updating formulae for the components
of # and :
#n|n = #n|n1 + n (1  n)
³
Xn  µn|n1
´
(10.62)
(i)
n|n = (i)
n|n1 + n
³
Xin  µ(i)
n|n1
´
+ n (n  n)
³
Xn  µn|n1
´
.
(10.63)
The weights n, n, n can be calculated from the elements of Qn|n1 by ap-
plying the following formulae, where, for simplicity, we write s, t, etc. instead
of sn|n1, tn|n1, . . .:

268
10 Multidimensional Evolutionary Models and Recursive Calculation
n =
Np
Np + q + 2 , where p = s + 2t + r,
(10.64)
n =
q
q + 2 ,
(10.65)
n =
r + t
(r + t) + (s + t) = r + t
p
.
(10.66)
The updating of the loss matrix again gives a matrix of the form
Qn|n =
3
C
sn|n
tn|n · 10
tn|n · 1
qn|n I + rn|n E
4
D .
(10.67)
The parameters in Qn|n are given by (10.68)—(10.71), where again, for simplic-
ity, the corresponding elements of Qn|n are written with “”, so for example,
we write s instead of sn|n.
q = (1  n) q,
(10.68)
s = s  n (1  n)2 p,
(10.69)
t = n (1  n) 2
N  s,
(10.70)
r = n (n  n) 2
N  t.
(10.71)
Finally, for the movement in parameter space we get
#n+1|n = #n|n,
(10.72)
(i)
n+1|n = (i)
n|n,
(10.73)
Qn+1|n = Qn|n + Dn,
(10.74)
and by using the special form of the Q-matrices we ﬁnd
Qn+1|n =
3
C
sn+1|n
tn+1|n · 10
tn+1|n · 1
qn+1|n I + rn+1|n E
4
D ,
(10.75)
where
sn+1|n = sn|n + $2,
tn+1|n = tn|n,
qn+1|n = qn|n +  2,
rn+1|n = rn|n.
Remarks:
•
Note that

10.6 Decomposition into an Individual and a Common Component
269
µ(i)
n|n = #n|n + (i)
n|n
= µ(i)
n|n1 + n
³
Xin  µ(i)
n|n1
´
+ (1  n) n
³
Xn  µn|n1
´
.
(10.76)
This is identical to (10.22). But observe that in Example 10.3, in contrast
to Example 10.1, we now also have estimators for the global and for the
individual components, that we would not “intuitively” have “derived”
from (10.22).
•
Let eQn|n be the loss matrix of the vector with components µ(i)
n|n (i = 1, 2,
. . . , N). Then it holds that
eQn|n = HQn|nH0
= eqn|nI + epn|nE,
(10.77)
where
eqn|n = qn|n = (1  n) qn|n1,
(10.78)
epn|n = sn|n + 2 tn|n + rn|n
= n (1  n) 2
N
= (1  n) (1  n)2 epn|n1.
(10.79)
(10.77)—(10.79) are identical to (10.25)—(10.27).
•
In Example 10.1, we saw that the loss matrices Qn|n1 and Qn|n all have
the Dp,q-form qI + pE, q, p 5 R. Here, in Example 10.3, we see that the
loss matrices also have a very special structure. They are of the form
3
C
s
t · 10
t · 1
qI + rE
4
D
(10.80)
where s, t, q, r are real numbers. For the initial matrix (10.61) we have
t = 0 and r = 0, but one could just as well use an arbitrary matrix of the
form (10.80) as initial value and the whole procedure would still work.
Derivation of (10.62)—(10.71):
We write
Qn|n1 := Q =
3
C
s
t · 10
t · 1
qI + rE
4
D
and carry out the calculations as described in Theorem 10.3. It holds that

270
10 Multidimensional Evolutionary Models and Recursive Calculation
Hn = H = (1 , I) ,
Sn = 2I,
QH0 =
3
C
s
t · 10
t · 1
qI + rE
4
D
3
C
10
I
4
D
=
3
C
(s + t) 10
q I + (r + t) E
4
D .
(10.81)
Because HQH0 is the loss matrix of µn|n1, it follows from (10.33) that
¡
HQH0 + 2I
¢1 =
1
q + 2
³
I  
N E
´
,
 =
Np
Np + q + 2 ,
(cf. (10.35) and (10.24))
p = quadratic loss of µ(i)
n|n1
= s + 2t + r.
With this we get
Gn =
1
q + 2
3
C
(s + t) 10
qI + (r + t) E
4
D
³
I  
N E
´
=
3
C
a 10
I + bE
4
D ,
where  =
q
q + 2 ,
(cf. (10.34))
a = s + t
q + 2 (1  )
= 1
N
s + t
p

= 1
N  (1  ) ,
 =
r + t
(r + t) + (s + t) = r + t
p
,
b = r + t
q + 2 (1  ) 
q
q + 2

N
= 
N (  ) .

10.6 Decomposition into an Individual and a Common Component
271
With this we have shown (10.62)—(10.66).
For the updating of the loss matrix Qn|n1 we could also apply Theorem
10.3 and explicitly do the calculations. However, this is a tedious procedure
and leads to clumsy, di!cult to interpret formulae. For this reason, we ap-
proach the problem in another, more direct way. For convenience, we write
Q for Qn/n1 (with elements q, s, t, r) and Q for Qn/n (with elements q,
s, t, r). First we show the following relationships, which are interesting in
themselves. It holds that
(s + t) = n (1  n) 2
N ,
(10.82)
(r + t) = n (n  n) 2
N ,
(10.83)
q = n2 = (1  n) q.
(10.84)
Notice, that from equations (10.82) and (10.83) we get
p = s + 2t + r,
= n (1  n) 2
N ,
= (1  n) (1  n)2 p,
(10.85)
which is identical to formula (10.27).
Derivation of (10.82) and (10.83):
Let
µin = #n + in,
µn = 1
N
N
P
i=1
µin.
We have
s + t = E
h³
µn  µn|n
´ ³
#n  #n|n
´i
= E
h
µn
³
#n  #n|n
´i
= E
h¡
µn  Xn
¢ ³
#n  #n|n
´i
= E
h
%n
³
#n  #n|n1  n (1  n)
³
Xn  µn|n1
´´i
= E
£
%n
¡
n (1  n)
¡
Xn  µn
¢¢¤
= n (1  n) 2
N .

272
10 Multidimensional Evolutionary Models and Recursive Calculation
For the second and the third equality we have used the fact that #n|n is the
credibility estimator of #n and therefore #n  #n|n is orthogonal to µn|n and
Xn. Analogously we get
r + t = E
h³
µkn  µ(k)
n|n
´ ³
in  (i)
n|n
´i
(k 6= i)
= E
h
(µkn  Xkn)
³
in  (i)
n|n
´i
= E
h
%kn
³
in  (i)
n|n1  n
³
Xin  µ(i)
n|n1
´
 n (n  n)
³
Xn  µn|n1
´i
= E
£
%kn
¡
n (n  n)
¡
Xn  µn
¢¢¤
= n (n  n) 2
N .
Thus we have proved (10.82) and (10.83).
Next we show the validity of (10.69). We have that
s = E
·³
#n|n1  #n
´2¸
= E
·³
#n|n  #n
´2¸
+ E
·³
#n|n  #n|n1
´2¸
= s + E
·³
n (1  n)
³
Xn  µn|n1
´´2¸
= s + 2
n (1  n)2 E
·³
Xn  µn|n1
´2¸
.
E
·³
Xn  µn|n1
´2¸
= E
h¡
Xn  µn
¢2i
+ E
·³
µn  µn|n1
´2¸
= 2
N + 1
N 2 (10 (qI + pE) 1)
= 1
N
¡
2 + Np + q)
¢
= p
n
.
From this we get directly that
s = s  n (1  n)2 p,
(10.86)
which is what we had to show.
From equation (10.86) as well as (10.82)—(10.84) it follows that equations
(10.70) and (10.71) are true. Finally, equation (10.84) is identical to equation
(10.26), the truth of which was shown in example 10.1. This concludes the
proof of (10.62)—(10.71).
¤

10.6 Decomposition into an Individual and a Common Component
273
Example 10.4 (extended counterpart to Example 10.2)
Analogous to Example 10.2, the dierence between Example 10.4 and example
10.3 lies only in the movements in parameter space. All other conditions are
identical.
In Example 10.2 (see page 261) the movements in parameter space were
modelled by an autoregressive process
µ (n+1)  µ = (µ (n)  µ) + n+1
(10.87)
where || < 1,
µ = E [µ (1)] .
In this example we now assume that both the global components and the in-
dividual components can be modelled by two dierent autoregressive processes
#n+1  #0 = 0 (#n  #0) + n+1,
(10.88)
i,n+1  i0 = 1 (in  i0) + i,n+1,
(10.89)
where
#0 = E [#n] ,
i0 = E [in] ,
|0|, |1| < 1,
X
i
i0 = 0.
For the components of the µ (n)-process we still have
µ (n) = #n + in,
i.e. they are the sum of the processes of the individual and the global com-
ponents. Notice that the contraction parameter 0 for the global parameter
can be dierent to that for the individual process, 1 . This is not the same
as (10.87) (see also the ﬁrst point in the remarks on page 261). When we
consider (10.87) decomposed into individual components and global compo-
nents, then (10.87) means that both the global and the individual components
change with the same contraction parameter. Example 10.4 is therefore a true
extension of Example 10.2.
Analogous to Example 10.2, where the explicit formulae for the credibility
estimator can be derived, here the credibility formulae can easily be derived
from Example 10.3 and Theorem 10.3, (10.50)—(10.51).
From anchoring to updating, nothing changes from example 10.3. Thus,
the corresponding formulae can be directly taken from there:
Anchoring: formulae (10.60) and (10.61),
(10.90)
Updating: formulae (10.62)—(10.71).
(10.91)

274
10 Multidimensional Evolutionary Models and Recursive Calculation
Only the equations for the movement in parameter space look dierent. In-
stead of (10.72) and (10.73) we now have
#n+1|n = 0 #n|n + (1  0) #0,
(10.92)
(i)
n+1|n = 1 (i)
n|n + (1  1) i0.
(10.93)
For the loss matrix, we get from the movement equations and applying
Theorem 10.3, (10.50) and (10.51),
Qn+1|n =
3
C
sn+1|n
tn+1|n10
tn+1|n1
qn+1|nI+rn+1|nE
4
D .
(10.94)
where
sn+1|n = 2
0 sn|n + $2,
tn+1|n = 0 1 tn|n,
qn+1|n = 2
1 qn|n +  2,
rn+1|n = 2
1 rn|n.
Remarks:
•
The eect of the movements on the elements of the loss matrix is slightly
dierent from that in Example 10.3 (compare (10.94) with (10.75)).
•
Also in the new movement equations, in the step from Qn|n to Qn+1|n,
the structure (10.80) stays the same. This is the reason why the updating
formulae from Example 10.3 can be used without alteration.
•
If one is only interested in the sum of individual and global components
µni = #n + in,
then the updating formula (10.22) still holds for the credibility estimator.
In contrast, the recursion formulae (10.38)—(10.41) from Example 10.2 re-
main only correct in the case where 1 and 2 are equal.

A
Appendix A:
Basic Elements from Probability Theory
A.1 Random Variables, Distribution Functions and
Moments
i)
Distribution Function and Density
Let X be a real-valued random variable deﬁned on a probability space
(, A, P).
F(x) := P (X  x) deﬁned for every real argument x 5 R is called the
distribution function of the random variable X.
If there exists a real-valued function f (x) such that
F(x) =
x
Z
4
f(y)dy
for all x, this function is called the density of the random variable X.
If the random variable X takes only a countable number of values
{xi : i 5 A  N}, then X has a discrete distribution with discrete proba-
bilities pi := P (X = xi) .
Then we have
F (x) =
X
{i, xix}
pi.
ii) Expected Value
For a (Borel measurable) function g we deﬁne E [g (X)], the expected value
of g(X), as follows:
a) If X has a density f (x) then

276
A Appendix A:
Basic Elements from Probability Theory
E[g (X)] =
+4
Z
4
g (x) f(x)dx.
b) If X has a discrete distribution then
E[g (X)] =
X
i pi g (xi) .
c) In the general case the expected value is deﬁned by the Stieltjes integral
E[g (X)] =
Z
g (x) dF(x).
—
The more elementary way to interpret c) uses the Riemann—Stieltjes
integral. With this interpretation all the above integrals are im-
proper integrals and must converge absolutely (this absolute con-
vergence is also required for the case b)).
—
The more elegant advanced interpretation uses the Lebesgue—Stieltjes
integral.
Remark:
The special random variable IA, which takes the value 1 if A occurs and
0 otherwise, is called indicator function of the event A. Observe that
E [IA] = P (A) .
iii) Moments and Central Moments
moments:
µk(X) := E
£
Xk¤
,
central moments: k(X) := E[(X  E [X])k].
The most important moments are:
expected value: µX := E[X],
variance:
2
X := 2 (X) = E[(X  µX)2],
skewness:
 (X) :=
¡
3 (X) /3
X
¢
,
kurtosis:
 (X) := (4(X)/4
X)  3.
Derived quantities:
standard deviation:
X := p2
X =
s
variance,
coe!cient of variation: CoVa (X) := X/µX.
A.2 Special Functions
The following functions are sometimes useful:

A.3 Multidimensional Distributions
277
•
Moment Generating Function:
MX(z) := E[ezX] =
+4
R
4
ezxdFX(x).
The derivatives at zero reproduce the moments
MX(0) = 1,
M
0
X(0) = E[X],
M(k)
X (0) = E[Xk].
•
Cumulant Generating Function:
KX(z) := ln MX(z).
Its derivatives K(k)
X (0) at zero reproduce the cumulants k (k = 1, 2, . . .).
It holds, that
1 (X) = µ1 (X) = µX,
2 (X) = 2 (X) = 2
X ,
3 (X) = 3 (X) ,
but k 6= k (X) for k > 3.
A.3 Multidimensional Distributions
i)
Multidimensional Distribution Functions
Let X1, X2, . . . , Xn be random variables deﬁned on the probability space
(, A,P).
F (x1, x2, . . . , xn) := P (X1  x1, X2  x2, . . . , Xn  xn) deﬁned for every
real n-tuple (x1, x2, . . . , xn) 5 Rn is called the n-dimensional distribution
function of the random variables X1, X2, . . . , Xn.
The marginal distribution functions of the random variables Xk are
P (Xk  xk) = F (4, . . . , 4, xk, 4, . . . , 4) = F (xk) .
Remark on the notation:
To abbreviate the notation we often let the argument of the function tell
us what distribution function we are looking at. For instance, we denote by
F (x1, x2, . . . , xn) the n-dimensional distribution function of X1, X2, . . . ,
Xn, by F (xk) the marginal distribution function of Xk, by F (xl) the mar-
ginal distribution function of Xl. The same notation philosophy is also used
for other functions (densities, conditional distribution functions, etc.).
ii) Independence
The random variables X1, X2, . . . , Xn are independent if the n-dimensional

278
A Appendix A:
Basic Elements from Probability Theory
distribution function factorizes, i.e. if
F (x1, x2, . . . , xn) =
n
Y
k=1
F (xk) .
For independent random variables we have
E
" n
Y
k=1
gk (Xk)
#
=
n
Y
k=1
E [gk (Xk)]
for any (integrable) functions gk.
iii) Covariance and Correlation Coe!cient
The covariance between two random variables X and Y is deﬁned by
Cov (X, Y ) := E [(X  µX) (Y  µY )] .
If X and Y are independent then Cov (X, Y ) = 0. However, the converse
is not true.
From the covariance one obtains the correlation coe!cient
(X, Y ) := Cov (X, Y )
X · Y
.
It always holds that 1 5 (X, Y ) 5 +1. The border cases 1 and +1 are
obtained if X = aY + b.
A.4 Conditional Probability and Conditional
Expectation
i)
Conditional Probability
Let (, A, P) be a probability space.
For A, B 5 A and P (B) > 0, the conditional probability of A given B is
deﬁned by
P (A |B ) = P (A _ B)
P [B]
.
Theorem A.1 (Theorem of total probability).
Let Bi, i = 1, 2, . . . , I be a partition of , i.e.
I^
i=1Bi = ,
Bi _ Bk = ! for i 6= k. Then
P (A) =
I
X
i=1
P (A |Bi ) P (Bi) .

A.4 Conditional Probability and Conditional Expectation
279
Theorem A.2 (Bayes Theorem).
Let Bi, i = 1, 2, . . . , I, be a partition of  and P(A) > 0, then it holds that
P (Bi |A) =
P (A |Bi ) P (Bi)
IP
i=1
P (A |Bi ) P (Bi)
.
Remarks:
—
Let X and Y be two random variables with two-dimensional density
f (x, y) and marginal densities f (x) and f (y). Then the analogue to
the conditional probability is the conditional density of X given Y = y,
which is
f (x |y ) = f (x, y)
f (y) .
—
We further have
f (x) =
+4
Z
4
f (x |y ) f (y) dy
and
f (x |y ) = f (x, y)
f (y)
=
f (y |x) f (x)
+4
R
4
f (y |x) f (x) dx
.
ii) General Deﬁnition of Conditional Expectation and Conditional
Probability
a) The conditional expectation of X given Y is a random variable de-
noted by E[X| Y ], which takes for every realization Y = y the value
E [X| Y = y] . The y-valued function E[X| Y = y] is such that
E[X| Y = y]dF (y) =
+ 4
Z
x =  4
x dF (x, y) .
This notation is useful, but to understand its meaning one has to inte-
grate both sides over an arbitrary (measurable) y-set.
b) If one chooses the indicator function IA of the event A instead of X
this general deﬁnition also yields conditional probabilities
P [A |Y = y ] = E [IA |Y = y ] .
One sees that in the case of the existence of densities f (y) and f (x, y) we
get

280
A Appendix A:
Basic Elements from Probability Theory
E[X |Y = y ] =
+4
Z
x=4
x f (x, y)
f (y)
dx ,
=
+4
Z
4
x f (x |y ) dx,
where f (x |y ) = f(x,y)
f(y) is the conditional density of X given Y = y.
An analogous construction for conditional expectations is obtained if X
and Y have discrete probability distributions.
iii) Properties of Conditional Expectation
The following properties of conditional expectation are important and of-
ten used in the book:
•
E[ E[X |Y ]] = E[X],
•
E[E[X |Y, Z ] |Y ] = E[X |Y ],
•
If X = f (Y ) (more general, if X is Y -measurable) then
E[X |Y ] = X,
•
If X and Y are independent then E[X |Y ] = E[X].
•
Decomposition of covariance:
Cov (X, Y ) = E [Cov (X, Y |Z )] + Cov(E[X |Z ], E[Y |Z ]),
which leads for Y = X to
Var (X) = E[Var (X |Z )] + Var (E[X |Z ]) .
A.5 Two Useful Results
The following two results are often helpful and used in the book.
Theorem A.3. Let X1, X2, ... , XI be independent random variables with
E[Xi] = µ and V ar (Xi) = 2
i
for i = 1, 2, . . . , I.
Then the minimum variance unbiased linear estimator of µ is given by
ˆµ =
µXI
i=1 2
i
¶1 XI
i=1 2
i Xi,
i.e. a weighted mean with the inverse of the variance as weights.
Theorem A.4. Let X1, X2, . .. , XI be conditionally independent random
variables given  with E [Xi| ] = µ () and E
h
(Xi  µ ())2i
=  2
i for
i = 1, 2, . . . , I.
Then the best collectively unbiased linear estimator of µ () is given by

A.5 Two Useful Results
281
\
µ () =
µXI
i=1  2
i
¶1 XI
i=1  2
i Xi.
Remark:
•
By “best” we mean the estimator with minimum quadratic loss and by
“collectively unbiased”, that E
h
\
µ ()
i
= E [µ ()] for all possible proba-
bility measures.

B
Appendix B:
The Hilbert Space L2
In this appendix we summarize — as much as needed for this text — the theory
of the Hilbert space L2 of the real-valued square integrable random variables.
All results are given without proofs. Readers interested in the proofs and
more details are referred e.g. to Kolmogorov and Fomin [KF70] or — in the
credibility context — to F. De Vylder [DV77].
A Hilbert space is a closed (inﬁnite-dimensional) linear space endowed
with a scalar product. The basic idea of using such spaces is to relate abstract
probabilistic concepts to geometric intuition. In the following we deﬁne the
Hilbert space L2.
Deﬁnition B.1. We deﬁne by L2 the space of real-valued random variables
with ﬁnite ﬁrst- and second-order moments, i.e.
L2 := {X : X = real-valued r.v. with E[X2] < 4}.
Deﬁnition B.2. The inner product of two elements X and Y in L2 is deﬁned
by
<X, Y > := E [X · Y ] .
Based on the inner product we can deﬁne the norm, the distance and the
orthogonality relation between two elements in L2.
Deﬁnition B.3.
i) Norm of an element in L2:
kXk := E
£
X2¤1/2 ;
Deﬁnition B.4. Distance d(X,Y) between two elements in L2:
d(X, Y ) := kX  Y k.

284
B Appendix B:
The Hilbert Space L2
Remark:
•
Two random variables X and Y 5 L2 with d(X, Y ) = 0, i.e. two ran-
dom variables, which are equal almost everywhere (i.e. up to a set with
probability 0) are considered as the same element in L2.
Deﬁnition B.5. Two elements X and Y in L2 are orthogonal (X B Y ), if
<X, Y > = 0.
Remarks:
•
L2 is a linear space, i.e.
if X1, X2, . . . , Xn 5 L2 then each ﬁnite linear combination X = Pn
i=1 aiXi
5 L2 (ai 5 R).
•
L2 is generally inﬁnite dimensional (for inﬁnite probability spaces).
•
L2 is a closed space, i.e. every Cauchy sequence {X1, X2, . . .} with elements
Xi 5 L2 converges to an element in L2. {X1, X2, . . .} is a Cauchy sequence,
if for every % > 0 there exists a n% such that d (Xn, Xm) < % for n, m > n%.
•
As already mentioned, the advantage of looking at L2 as a Hilbert space
is that we can transfer our knowledge and intuition from linear spaces (for
instance the three-dimensional Euclidian space) to the space L2, which
makes it much easier to understand and to visualize things like orthogo-
nality relations, projections on subspaces, linearity and iterativity of the
projection operator.
Deﬁnition B.6. P  L2 is a subspace of L2, if P is non-empty and closed
with respect to ﬁnite linear combinations.
Remark:
•
For every subspace P it holds that the “degenerate” random variable 0 5
P.
Deﬁnition B.7. Q  L2 is an a!ne or translated subspace of L2 if
Q = Z + P := {X : X = Z + Y, Y 5 P} ,
where Z 5 L2 and P  L2 is a subspace of L2.
Remarks:
•
Q  L2 is an a!ne subspace of L2, if Q is non-empty and closed with
respect to all normed linear combinations (if Z1, . . . , Zn 5 Q, then X =
Pn
i=1 aiZ 5 Q for all ai 5 R with Pn
i=1 ai = 1).
•
If Q  L2 is an a!ne subspace of L2 and Z 5 Q, then P = QZ := {X :
X = Y  Z, Y 5 Q} is a subspace.
Special subspaces and a!ne subspaces:
Consider the random vector X = (X1,X2, . . . , Xn)0 with components Xi 5 L2.

B Appendix B:
The Hilbert Space L2
285
•
G(X) := {Z : Z = g(X), g =real-valued function and
g(X) square integrable}.
G(X) is a closed subspace.
•
L(X, 1) :=
n
Z : Z = a0 + Pn
j=1 ajXj,
a0, a1, . . . 5 R
o
.
L(X, 1) is a closed subspace.
•
Under the assumptions of Theorem A.4 in Appendix A we want to estimate
µ (). The collectively unbiased linear estimators of µ () form the closed
a!ne subspace
Le (X) := {Z : Z = Pn
j=1 ajXj,
a1, a2, . . . 5 R, E [Z] = E [µ ()]}.
Deﬁnition B.8. For a closed subspace (or a closed a!ne subspace) M  L2
we deﬁne the orthogonal projection of Y 5 L2 on M as follows: Y  5 M is
the orthogonal projection of Y on M (Y  = Pro (Y | M) ) if Y Y  B M,
i.e. Y  Y  B Z1  Z2 for all Z1, Z2 5 M.
Remark:
•
If M is a subspace, then the condition Y  Y BM can also be written as
<Y  Y , Z> = 0 for all Z 5 M.
Theorem B.9. Y  always exists and is unique.
Theorem B.10. The following statements are equivalent:
i) Y  = Pro (Y | M).
ii) Y  5 M and <Y  Y , Z  Y > = 0
for all Z 5 M.
iii) Y  5 M and kY  Y k  kY  Zk
for all Z 5 M.
Theorem B.11 (linearity of projections).
a) The following linearity property holds true for the projection on a closed
linear subspace P:
Pro (aX + bY | P) = a Pro (X| P) + b Pro (Y | P) .
b) The following “normed linearity property” holds true for the projection on
an a!ne linear subspace Q:
Pro
³
(a + b)1 (aX + bY )
¯¯¯ Q
´
= (a + b)1 (a Pro (X| Q)
+b Pro (Y | Q)).
Theorem B.12 (iterativity of projections).
Let M and M0 be closed
subspaces (or closed a!ne subspaces) of L2 with M  M0, then we have
Pro (Y |M ) = Pro (Pro (Y |M 0 ) |M )
and
kY  Pro (Y |M )k2 = kY  Pro (Y | M0)k2 + kPro (Y |M 0 )  Pro (Y |M )k2 .

286
B Appendix B:
The Hilbert Space L2
Remark:
•
Note that geometrically, the last equation corresponds to the Theorem of
Pythagoras.

C
Appendix C:
Solutions to the Exercises
C.1 Exercises to Chapter 2
Exercise 2.1
a)
& = good medium bad P coll
pind
300
500
1 000
u (&) 65%
30%
5%
395
b) With the Bayes-theorem we can calculate the posterior probabilities
u (& |x) and from that P Bayes = E
£
P ind¯¯ x
¤
.
x
& =
good medium
bad
P Bayes
P ind =
300
500
1 000
0
u (& |x) = 65.64% 29.67% 4.69%
392.14
1 000 u (& |x) = 49.37% 37.97% 12.66% 464.56
c) The observation X is now a two-dimensional vector with possible outcomes
x1 =(0, 0), x2 =(10 000, 0), x3 =(10, 10 000), x4 =(10 000, 10 000).
With the Bayes-theorem, we can again calculate the posterior probabil-
ity distributions u (& |x) and P Bayes.
x
& =
good
medium
bad
P Bayes
pind =
300
500
1 000
x1 u (& |x) = 66.27% 29.34%
4.39%
389.40
x2 u (& |x) = 50.22% 37.83% 11.95% 459.30
x3 u (& |x) = 50.22% 37.83% 11.95% 459.30
x4 u (& |x) = 31.88% 40.87% 27.25% 572.48

288
C Appendix C:
Solutions to the Exercises
Exercise 2.2
a) Moment method estimator of the parameters:
bµN = 0.089,
b2
N = 0.0976
,
b = 0.878,
b = 9.911.
Fit of the negative binomial distribution:
number of policies with k claims:
k =
0
1
2
3
4 >5
observed: 143 991 11 588 1 005 85
6
2
ﬁtted:
143 990 11 593
998 88
8
1
b)
CoVa () =
p
Var []
E []
= 1,
,
\
CoVa () = b1 = 1.07.
c) Let N3 be the claim number within the last three years of a randomly
drawn policy. N3 is conditionally, given , Poisson distributed with pa-
rameter 3 = 3. Hence N3 has a negative binomial distribution with
estimated parameters b3 = b and b3 = b/3.
, P (N3 = 0) =
Ã
b
b + 3
!b
= 0.793.
, impact on premium: estimated reduction = 0.15 · 0.793 = 11.9%.
d) For N3 = 0 we have

\
Bayes =
b
b + 3

d
coll,
 \
Bayes
d
coll
=
b
b + 3
= 76.8%.
, The discount rate obtained with the empirical Bayes estimator would be
23.2%. The no-claims discount of 15% is below that and on the conservative
side, which is reasonable.

C.1 Exercises to Chapter 2
289
Exercise 2.3
i is Gamma distributed with parameters ,  = .
CoVa (i) = 0.2
,
 = 25.
Bayes =  + N
 + µN
= 25 + 15
25 + 25 = 0.8.
Exercise 2.4
We denote by Nn, n = 1, 2, the claim number of the total ﬂeet in n years.
From CoVa (i) = 0.2 ,  = 25.
a)
Vehicle type # of risks
a priori
a priori expected claim
frequency in %o
numbers in one year
lorry
30
300
9.00
delivery van
30
100
3.00
passenger car
10
75
0.75
Total
70
12.75
Bayes =
25 + N1
25 + 12.75.
b)
Bayes =
½1.09 if N1 = 16,
0.89 if N2 = 20.
experience correction term =
½+9% if N1 = 16,
11% if N2 = 20.
c) A priori distribution of :  (, ) .
A posteriori distribution of  given N2 = 20 :  (25 + 20, 25 + 25.5) .
a priori-/a posteriori- *-Distributions
0
0.5
1
1.5
2
2.5
3
3.5
0.4
0.6
0.8
1
1.2
1.4
1.6
1.8
a priori
a posteriori

290
C Appendix C:
Solutions to the Exercises
Exercise 2.5
a)  q Beta (a, b) .
E [] =
a
a + b = 0.01,
CoVa () =
s
b
a (1 + a + b) = 0.5,
a = 3.95
,
b = 391.05.
Density of Beta Distribution
0.00
0.01
0.02
0.03
0.04
b) 13.6 %o.
c)
Bayes
i
=
3.95 + N
3.95 + 391.05 + wi
,
Decision rule =
;
?
=
+20% if Bayes
i
> 13%o,
20% if Bayes
i
< 7%o.
i)
wi = 500
Decision rule =
;
?
=
+20% if N > 8,
20% if N 6 2.
ii) wi = 2 000
Decision rule =
;
?
=
+20% if N > 28,
20% if N 6 12.

C.1 Exercises to Chapter 2
291
Exercise 2.6
a)
b&MLE = 1.70,
Bayes = 2.20.
b) Denote by n2m the expected number of claims exceeding 2 Million CHF,
by µ2m = E [X  2 Million | X > 2 Million] the expected value of these
claims and by P = n2m · µ2m the pure risk premium. With the dierent
estimators of the Pareto parameter we obtain:
Pareto parameter n2m
µ2m
P
Bayes
i
= 2.2
0.76
1.66 mio
1.26 mio
b&MLE = 1.7
1.08
2.87 mio
3.10 mio
coll = 2.5
0.62
1.33 mio
0.82 mio
Exercise 2.7
a) Family of the normal distributions.
b) Y ()
i
q Lognormal
¡
i, 2¢
.
i q Normal
¡
µ,  2¢
.
b&MLE = 1
n
n
X
y=1
ln (Yi) ,
Bayes
i
=  b&MLE + (1  ) µ,
where  =
n
n + 2
2
.
From CoVa
³
Y ()
i
|i
´
=
s
e2  1 = 4 , 2 = ln (17) = 2.8332.
From µ = 7.3 and CoVa (i) = 10% ,  2 = 0.5329.
c) The estimated expected values of the claim amount obtained with the dif-
ferent estimators of i are:
bµ(1)
Y
:= eb&MLE+ 2
2 , bµ(2)
Y
:= eBayes+ 2
2 , bµ(3)
Y
:= ecoll+ 2
2 .
Results:
i
b&MLE
Bayes
coll
bµ(1)
Y
bµ(2)
Y
bµ(3)
Y
observed
mean
1
6.85
7.01
7.30
3 906
4 561
6 103
15 396
2
7.45
7.37
7.30
7 118
6 576
6 103
3 347

292
C Appendix C:
Solutions to the Exercises
Comments:
The estimates bµ(2)
Y
(and bµ(1)
Y ) are bigger for the second class even if the
observed mean of the second class is much lower than the one of the ﬁrst
class. The point is that the observed mean of the ﬁrst class is highly inﬂu-
enced by one outlier observation, and that such a single outlier is weighed
down by the maximum-likelihood estimator.
Exercise 2.8
a) Family of the Beta distributions.
b)
Bayes =
a + n
a + b + n + X•
,
where X• =
n
X
j=1
Xj .
Exercise 2.9
XBayes
n+1
= G (X1, . . . , Xn) = g (X) ,
where
g (X) = arg min
h
E
h
(h (X)  Xn+1)2i
.
E
h
(h (X)  Xn+1)2i
= E
h
E
h
(h (X)  Xn+1)2¯¯¯ 
i
= E
h
E
h
(h (X)  µ () + µ ()  Xn+1)2¯¯¯ 
i
= E
h
(h (X)  µ ())2i
+ E
h
(Xn+1  µ ())2i
.
Hence
XBayes
n+1
= arg min
h
E
h
(h (X)  µ ())2i
,
, XBayes
n+1
= µ ()Bayes .

C.2 Exercises to Chapter 3
293
C.2 Exercises to Chapter 3
Exercise 3.1
a) The linearity property of the credibility estimator follows directly from the
linearity property of the projection-operator on a closed linear subspace.
b) We deﬁne
µk := E [µk ()] ,
k = 1, 2, . . . , p;
µ :=
p
X
k=1
akµk;
L(k)
e
(X) :=
;
?
=
\
µ () : \
µ () =
n
X
j=1
biXj, E
h
\
µ ()
i
 µk
<
@
> ;
Le (X) :=
;
?
=
\
µ () : \
µ () =
n
X
j=1
biXj, E
h
\
µ ()
i
 µ
<
@
> ;
L0 (X) :=
;
?
=
\
µ () : \
µ () =
n
X
j=1
biXj, E
h
\
µ ()
i
 0
<
@
> ;
“” means that the equality has to be fulﬁlled, whatever the probability
measure dP (X, &) resp. whatever the vector µ =
¡
µ1, . . . , µp
¢0 might be.
We have to show that
µ ()  \
\
µ ()
hom
B \
µ ()  \
\
µ ()
hom
for all \
µ () 5 Ll (X) .
First we note that
L(k)
e
(X) = \
\
µk ()
hom
+ L0 (X)
=
(
\
µk () : \
µk () = \
\
µk ()
hom
+ Y, Y 5 L0 (X)
)
,
Le (X) =
(
\
µ () : \
µ () =
P
X
k=1
ak \
µk (), \
µk () 5 L(k)
e
(X)
)
,
, for all \
µ () 5 Le (X) it holds that
µk ()  \
\
µk ()
hom
B \
µ ()  \
\
µe ()
hom
for all k, l = 1, 2, . . . , p.

294
C Appendix C:
Solutions to the Exercises
, for all \
µ () 5 Le (X) it holds that
µ ()  \
\
µk ()
hom
=
p
X
k=1
ak
Ã
µk ()  \
\
µk ()
hom!
is orthogonal to
\
µ () \
\
µk ()
hom
=
p
X
k=1
ak
Ã
µk ()  \
\
µk ()
hom!
.
Exercise 3.2
Let \
\
µ () be the credibility estimator of µ() based on X1. If X2 is indepen-
dent of X1 and µ(), we then have
Cov (µ(), X2j) = Cov
µ\
\
µ (), X2j
¶
= 0
for every component X2j of the vector X2. Hence the normal equations are also
fulﬁlled for X2, i.e. \
\
µ () is the credibility estimator based on X = (X0
1, X0
2)0.
Exercise 3.3
a)
bb
Xn+1 = Pro (Xn+1L |(1, X)) ,
= Pro (Pro (Xn+1 |L (1, µ () , X) |L (1, X)).
The inner projection is equal to µ (), which can easily be seen by checking,
that it fulﬁls the normal equations.
Hence
bb
Xn+1 = Pro (µ () |L (X, 1)) = \
\
µ ().
b)
E
"µ
bb
Xn+1  Xn+1
¶2#
= E
h
(Xn+1  µ ())2i
+ E
"µ
µ ()  \
\
µ ()
¶2#
= 2 + 2
n .

C.2 Exercises to Chapter 3
295
Exercise 3.4
Structural parameters: µ0 = 395, 2 = 3 766 500,  2 = 27 475.
a) n = 1,  = 0.72%.
\
\
µ () =
½392.14 if X = 0,
464.56 if X = 10 000.
b) n = 2,  = 1.44%.
\
\
µ () =
;
?
=
382.32 if X = 0
461.22 if X = 5 000
533.11 if X = 10 000.
c) For n = 1, P Cred = P Bayes, but for n = 2, this equality no longer holds.
Reason:
After one year’s claim experience, P Bayes is by deﬁnition a function of the
two possible outcomes of X, i.d.
P Bayes (X) =
½a0 if X = 0,
a1 if X = 10 000.
One can always draw a straight line through two points in the plane, hence
P Bayes (X) can always be written as a linear function of X. Since P Cred is
the best linear approximation to P Bayes, P Cred coincides with P Bayes.
After two years’ claim experience, P Bayes is by deﬁnition a function
of the four possible outcomes of the two-dimensional observation vec-
tor (X1, X2) , resp. a function of the three possible outcomes of X =
(X1 + X2) /2, i.e.
P Bayes ¡
X
¢
=
;
?
=
a0 if X = 0,
a1 if X = 5 000,
a2 if X = 10 000.
In general, one cannot draw a straight line through three points in the
plane. Therefore, P Cred is no longer equal to P Bayes, but it is still the best
(with respect to quadratic loss) linear approximation to P Bayes.
Exercise 3.5
n = number of claims (exposure),
N = number of large claims.
Given  (and n), N has a Binomial distribution with parameters n and .
For X = N
n , it holds that

296
C Appendix C:
Solutions to the Exercises
µ () = E [X |] = ,
2 () = Var [X |] = 1
n (1  ) .
Structural parameters:
µ = E [] = 2%,
 2 = Var [] = 0.01%,
2 = E
£
2 ()
¤
= 1
n
¡
µ   2  µ2¢
= 1
n (0.0196) ,
n = 120,
X =
6
120 = 5%,
 =
1
1 + 2
 2
= 38.0%,
bb = X + (1  )µ = 3.14%.
Alternative solution:
We approximate the Binomial distribution with the Poisson distribution, i.e.
we assume that N is conditionally Poisson-distributed with Poisson parameter
 = m. Then
2 () = Var [X |] = 1
n,
2 = E
£
2 ()
¤
= 1
n0.02,
 =
1
1 + 2
2
= 37.5%,
bb = X + (1  )µ = 3.13%.
C.3 Exercises to Chapter 4
Exercise 4.1
a)  = 3 000 mio, bµ0 = 0.80
Risk group
1
2
3
4
5 Total
i
59% 77% 59%
86% 41%
\
\
µ(i)
hom
0.93 0.42 1.06
0.89 0.72
0.78
wi · \
\
µ (i)
hom
4 038 4 239 4 628 16 268 1 517 30 690
b)  = 6 000 mio.
Risk group
1
2
3
4
5 Total
i
42% 63% 42%
75% 26%
\
\
µ (i)
hom
0.89 0.48 0.98
0.87 0.74
0.78
wi · \
\
µ (i)
hom
3 860 4 938 4 280 16 044 1 568 30 690

C.3 Exercises to Chapter 4
297
c) b2 = 261 mio, b 2 = 0.102 mio, b = 2 558 mio.
Risk group
1
2
3
4
5 Total
i
63% 80% 63%
88% 45%
\
\
µ (i)
hom
0.94 0.40 1.08
0.89 0.71
0.78
wi · \
\
µ (i)
hom
4 075 4 106 4 703 16 304 1 502 30 690
d) Obvious from the above tables.
e) b2 = 356 mio, b 2 = 0.066 mio, b = 5 404 mio.
Risk group
1
2
3
4
5 Total
µi
0.60 0.68 1.28
0.86 0.43
0.78
\
\
µ (i)
hom
0.75 0.45 1.26
0.89 0.46
0.78
wi · \
\
µ (i)
hom
3 261 4 635 5 493 16 340 962 30 690
Exercise 4.2
a) b 2 = 0 =, \
\
µ (i)
hom
= 482
for all i = 1, 2, . . . , 10.
b) b2 = 6 021 772, b 2 = 293, b = 20 577, bµ = 189.
Resulting credibility estimates: see table “Results of Exercise 4.2b)”.
region
# of years
at risk
(yr)
weight
est. of
relative
Di
P(4i)
P(4i)/Total
1
41 706
67%
183
0.95
2
9 301
31%
194
1.01
3
33 678
62%
210
1.09
4
3 082
13%
188
0.98
5
27 040
57%
169
0.88
6
44 188
68%
182
0.95
7
10 049
33%
178
0.93
8
30 591
60%
204
1.06
9
2 275
10%
185
0.96
10
109 831
84%
197
1.03
Total
311 741
192
1.00
cred. results
normal claims
Table: Results of Exercise 4.2b)
c) b 2 = 0 =, \
\
µ (i)
hom
= 290
for i = 1, 2, . . . , 10.
d) Summing up the results from b) and c) yields the estimates listed in the
table “Results of Exercise 4.2 d)”.

298
C Appendix C:
Solutions to the Exercises
region
# of years
at risk
(yr)
est. of
relative
P(4i)
P(4i)/Total
1
41 706
473
            
0.98
2
9 301
484
            
1.00
3
33 678
500
            
1.04
4
3 082
478
            
0.99
5
27 040
458
            
0.95
6
44 188
472
            
0.98
7
10 049
468
            
0.97
8
30 591
494
            
1.03
9
2 275
474
            
0.98
10
109 831
487
            
1.01
Total
311 741
482
1.00
all claims
Table: Results of Exercise 4.2d)
Exercise 4.3
region # of years
at risk
obs.
obs.
weight
absol.
relative
weight
absol.
relative
Di
O(4i) O(4i)/Tot.
Di
O(4i)
O(4i)/Tot.
1
41 706
62.2 98.7%
62.3
0.84
       
0.50 18.1%
0.68
0.94
       
2
9 301
82.0 94.5%
81.5
1.10
       
0.86
4.7%
0.73
1.01
       
3
33 678
98.0 98.4%
97.6
1.32
       
0.77 15.1%
0.73
1.01
       
4
3 082
75.6 85.0%
75.1
1.01
       
0.32
1.6%
0.71
0.99
       
5
27 040
61.8 98.0%
62.0
0.84
       
0.55 12.5%
0.70
0.97
       
6
44 188
70.1 98.8%
70.2
0.95
       
0.75 18.9%
0.72
1.00
       
7
10 049
62.8 94.9%
63.3
0.85
       
1.19
5.0%
0.74
1.03
       
8
30 591
79.4 98.3%
79.2
1.07
       
0.82 13.9%
0.73
1.02
       
9
2 275
51.0 80.7%
55.1
0.74
       
0.00
1.2%
0.71
0.98
       
10
109 831
75.1 99.5%
75.1
1.01
       
0.76 36.7%
0.74
1.02
       
Total
311 741
74.0
74.0
1.00
       
0.72
0.72
1.00
       
cred. results
cred. results
claim frequency in %o
normal claims
large claims
Exercise 4.4
a) Estimates of structural parameters:
bµ0 = 2 573,
b2 = 1.812E7, b 2 = 2.794E4, b = b2
b 2 = 648.
Credibility results:

C.3 Exercises to Chapter 4
299
region
claim  
number
obs.
Xi
(n)
DL
P4L
1
2 595
2 889
80%
2 826
2
 763
2 490
54%
2 528
3
3 302
2 273
84%
2 323
4
 233
2 403
26%
2 528
5
1 670
2 480
72%
2 506
6
3 099
2 558
83%
2 561
7
 631
2 471
49%
2 523
8
2 428
2 705
79%
2 677
9
 116
2 836
15%
2 613
10
8 246
2 651
93%
2 645
Total
23 083
2 593
2 593
cred. results 
average claim amount in CHF
normal claims  
b) b 2 = 0 =, \
\
µ (i)
hom
= 401 000
for i = 1, 2, . . . , 10.
Exercise 4.5
region
years 
at risk
at risk
obs.
ex. 4.3 
ex. 4.2
obs.
ex. 4.3 
ex. 4.2
and ex. 4.4
and ex. 4.4
1
41 706
422
449
473
0.88
0.93
0.98
2
9 301
626
499
484
1.30
1.04
1.00
3
33 678
446
520
500
0.93
1.08
1.04
4
3 082
246
477
478
0.51
0.99
0.99
5
27 040
413
435
458
0.86
0.90
0.95
6
44 188
566
470
472
1.18
0.98
0.98
7
10 049
569
457
468
1.18
0.95
0.97
8
30 591
473
507
494
0.98
1.05
1.03
9
2 275
145
418
474
0.30
0.87
0.98
10
109 831
494
494
487
1.03
1.03
1.01
Total
311 741
482
482
482
1.00
1.00
1.00
pure risk premium relative
 with results of
with results of
pure risk premium 
Short comment:
By comparing the ﬁgures in the two last columns it is clearly seen that the
results obtained by estimating the frequency and the average claim amount
dierentiate much better between regions than the results obtained by esti-
mating directly the pure risk premium based on the observed total claims cost
per year at risk.

300
C Appendix C:
Solutions to the Exercises
Exercise 4.6
a) Estimates of structural parameters:
bµ0 = 960,
b2 = 2.287E8, b 2 = 1.793E5, b = b2
b 2 = 1 275.
Estimate of the heterogeneity parameter CoVa (µ (i)) : b/bµ0 = 44%.(a
rather heterogeneous portfolio).
Resulting credibility estimates: see table “Results of Exercise 4.6a)”.
risk class
years at 
risk
Xi
Xi rel.
Di
P(4i)
P(4i) rel.
A1
17 309
 543
0.62
93%
 572
0.65
A2
41 446
 600
0.69
97%
 611
0.70
A3
2 956
 238
0.27
70%
 456
0.52
A4
4 691
 958
1.10
79%
 958
1.10
A5
19 336
1 151
1.32
94%
1 139
1.30
B1
 260
 646
0.74
17%
 907
1.04
B2
4 672
1 286
1.47
79%
1 216
1.39
B3
 326
 310
0.35
20%
 828
0.95
B4
1 216
1 884
2.15
49%
1 411
1.61
B5
15 406
1 549
1.77
92%
1 504
1.72
Total
107 618
 875
1.00
 875
1.00
observations
cred. estim. of
Table: Results of Exercise 4.6a)
b) Estimates of structural parameters:
Claim frequency:
b0 = 0.1163,
b2
F = b0 = 0.1163, b 2
F = 0.0020, bF = b2
b 2 = 58.
Estimate of the heterogeneity parameter CoVa ( (i)) : b F /b0 = 38%.
Claim severity:
b 2
Y = 0.
Resulting credibility estimates: see table “Results of Exercise 4.6b)”.
c) Estimates of structural parameters:
Normal claims: frequency
b0 = 0.1147, bF = 59,
severity
bµ0 = 3 953,
bY = 26.
Large claims:
frequency
b0 = 0.0014, bF = 3 723,
severity (in 1000) bµ0 = 339,
bY = 4 (b 2
Y = 0).
Credibility results: see tables “Results of Exercise 4.6c), normal claims”
and “Results of Exercise 4.6c), large claims”
Of course, the pure risk premium for the dierent risk classes is obtained
by summing up the pure risk premiums of the normal and large claims.

C.3 Exercises to Chapter 4
301
risk pr.
risk 
years at 
obs.
# of 
obs.
estim. of 
class
risk
Fi
Di
PF(4i) claims
Yi
Di
PY(4i)
P(4i)
A1
17 309
61
    
99.7%
61
1 058
8 885
0%
8 554
 524
A2
41 446
76
    
99.9%
76
3 146
7 902
0%
8 554
 650
A3
2 956
81
    
98.1%
81
 238
2 959
0%
8 554
 695
A4
4 691
93
    
98.8%
93
 434
10 355
0%
8 554
 794
A5
19 336
128
  
99.7%
128
2 481
8 971
0%
8 554
1 097
B1
 260
135
  
81.8%
131
 35
4 801
0%
8 554
1 123
B2
4 672
177
  
98.8%
176
 825
7 281
0%
8 554
1 504
B3
 326
98
    
84.9%
101
 32
3 163
0%
8 554
 863
B4
1 216
148
  
95.4%
147
 180
12 725
0%
8 554
1 254
B5
15 406
167
  
99.6%
167
2 577
9 259
0%
8 554
1 429
Total
107 618
102
102
11 006
8 554
8 554
 875
claim frequency in %o
cred. estim. 
average claim amount
cred. estim. 
Table: Results of Exercise 4.6b)
risk pr.
risk 
years at 
obs.
# of 
obs.
estim. of 
class
risk
Fi
Di
PF(4i) claims
Yi
Di
PY(4i)
P(4i)
A1
17 309
60
    
99.7%
60
1 043
3 179
97.5% 3 198
193
A2
41 446
75
    
99.9%
75
3 106
3 481
99.2% 3 485
261
A3
2 956
81
    
98.1%
81
 238
2 959
90.0% 3 058
248
A4
4 691
91
    
98.8%
92
 429
4 143
94.2% 4 132
379
A5
19 336
126
  
99.7%
126
2 446
4 804
98.9% 4 795
606
B1
 260
135
  
81.6%
131
 35
4 801
57.1% 4 437
581
B2
4 672
174
  
98.8%
174
 815
3 518
96.9% 3 532
613
B3
 326
98
    
84.7%
101
 32
3 163
54.9% 3 519
354
B4
1 216
143
  
95.4%
142
 174
3 786
86.9% 3 808
540
B5
15 406
165
  
99.6%
165
2 547
5 579
99.0% 5 562
919
Total
107 618
101
  
101
10 865
4 267
4 267
431
claim frequency in %o
average claim amount
cred. estim. 
cred. estim. 
Table: Results of Exercise 4.6 c) normal claims

302
C Appendix C:
Solutions to the Exercises
risk pr.
risk 
years at 
obs.
# of 
obs.
estim. of 
class
risk
Fi
Di
PF(4i) claims
Yi
Di
PY(4i)
P(4i)
A1
17 309
0.87
82.3%
0.97
15
406
      
0%
339
    
328
A2
41 446
0.97
91.8%
1.00
40
351
      
0%
339
    
340
A3
2 956
0.00
44.3%
0.80
0
-
          
0%
339
    
272
A4
4 691
1.07
55.8%
1.23
5
543
      
0%
339
    
417
A5
19 336
1.81
83.9%
1.75
35
300
      
0%
339
    
593
B1
 260
0.00
6.5%
1.35
0
-
          
0%
339
    
456
B2
4 672
2.14
55.7%
1.83
10
314
      
0%
339
    
620
B3
 326
0.00
8.1%
1.33
0
-
          
0%
339
    
449
B4
1 216
4.93
24.6%
2.30
6
272
      
0%
339
    
780
B5
15 406
1.95
80.5%
1.85
30
322
      
0%
339
    
626
Total
107 618
1.31
1.31
141
339
      
339
    
444
claim frequency in %o
average claim amount in 1'000
cred. estim. 
cred. estim. 
Table: Results of Exercise 4.6 c) large claims
d) The following table and graph summarize the estimates of the pure risk
premiums µ (i) obtained in a), b) and c)
risk 
years at 
class
risk
Xi
Xi rel.
a)
b)
c)
a)
b)
c)
A1
17 309
 543
0.62
 572
 524
 521
0.65
  
0.60
  
0.60
A2
41 446
 600
0.69
 611
 650
 602
0.70
  
0.74
  
0.69
A3
2 956
 238
0.27
 456
 695
 520
0.52
  
0.79
  
0.59
A4
4 691
 958
1.10
 958
 794
 796
1.10
  
0.91
  
0.91
A5
19 336
1 151
1.32
1 139
1 097 1 200
1.30
  
1.25
  
1.37
B1
 260
 646
0.74
 907
1 123 1 037
1.04
  
1.28
  
1.19
B2
4 672
1 286
1.47
1 216
1 504 1 234
1.39
  
1.72
  
1.41
B3
 326
 310
0.35
 828
 863
 803
0.95
  
0.99
  
0.92
B4
1 216
1 884
2.15
1 411
1 254 1 320
1.61
  
1.43
  
1.51
B5
15 406
1 549
1.77
1 504
1 429 1 545
1.72
  
1.63
  
1.77
Total
107 618
 875
1.00
 875
 875
 875
1.00
  
1.00
  
1.00
estimate of P(4i) rel.
observations
estimate of P(4i)
Table: Results of Exercise 4.6 d)

C.3 Exercises to Chapter 4
303
esimates of pure risk premiums
 200
 400
 600
 800
1 000
1 200
1 400
1 600
1 800
2 000
A1
A2
A3
A4
A5
B1
B2
B3
B4
B5
risk class
5 000
10 000
15 000
20 000
25 000
30 000
35 000
40 000
45 000
years at risk
years at risk
obs.
a)
b)
c)
Exercise 4.7
Estimates of sum of squares and of :
c
SStot = 9.017E12, SSb = 6.958E12,
c
SSw = c
SStot  SSb = 9.064E12,
b = 1 744.
Resulting credibility estimates: see table “Results of Exercise 4.7” below.
Exercise 4.8
Estimates of structural parameters:
Claim frequency:
b0 = b2 = 1.0541, b 2 = 0.0265, b = b2
b 2 = 40.
Resulting credibility estimates: see table “Results of Exercise 4.8”.
Exercise 4.10
Estimates of structural parameters:
b&0 = 1.3596, b 2 = 0.0229, b =
³
b&0
´2
/b 2 = 81.
Resulting credibility estimates: see table “Results of Exercise 4.9”.

304
C Appendix C:
Solutions to the Exercises
region
# of 
claims
Cred.-
weight
Xi
Xi rel
Di
P(4i)
P(4i) rel
1
5 424
4 593
0.98
76%
4 616
0.99
2
 160
4 514
0.96
8%
4 671
1.00
3
 885
4 216
0.90
34%
4 527
0.97
4
10 049
4 303
0.92
85%
4 360
0.93
5
2 469
4 350
0.93
59%
4 489
0.96
6
1 175
4 598
0.98
40%
4 650
0.99
7
2 496
4 897
1.05
59%
4 810
1.03
8
7 514
4 652
0.99
81%
4 659
0.99
9
 482
5 030
1.07
22%
4 760
1.02
10
2 892
4 693
1.00
62%
4 690
1.00
11
 839
5 097
1.09
32%
4 819
1.03
12
3 736
4 226
0.90
68%
4 372
0.93
13
2 832
4 879
1.04
62%
4 805
1.03
14
 548
4 603
0.98
24%
4 666
1.00
15
 406
4 555
0.97
19%
4 661
0.99
16
6 691
4 658
0.99
79%
4 664
1.00
17
1 187
4 734
1.01
40%
4 705
1.00
18
2 105
4 463
0.95
55%
4 564
0.97
19
1 533
4 693
1.00
47%
4 689
1.00
20
2 769
4 909
1.05
61%
4 822
1.03
21
5 602
5 078
1.08
76%
4 985
1.06
22
 283
4 443
0.95
14%
4 652
0.99
23
9 737
5 112
1.09
85%
5 047
1.08
24
2 839
5 187
1.11
62%
4 996
1.07
25
1 409
4 513
0.96
45%
4 608
0.98
25
20 267
4 630
0.99
92%
4 634
0.99
26
6 977
4 653
0.99
80%
4 660
0.99
Total
103 303
4 685
1.00
4 685
1.00
observed
Cred.est. of
average claim amount
Table: Results of Exercise 4.7

C.4 Exercises to Chapter 5
305
fleet
# of year
at risks obs. a priori
obs.
cred. 
cred. est. of
exp.
weight
4i
1
 103
 18
 23
0.78
37%
0.95
2
 257
 27
 16
1.69
29%
1.24
3
 25
 2
 4
0.50
9%
1.00
4
 84
 20
 17
1.18
30%
1.09
5
 523
 109
 120
0.91
75%
0.94
6
2 147
 518
 543
0.95
93%
0.96
7
 72
 11
 10
1.10
20%
1.06
8
 93
 16
 13
1.23
25%
1.10
9
 154
 116
 129
0.90
76%
0.94
10
 391
 156
 118
1.32
75%
1.25
Total
3 849
 993
 993
1.00
# of claims
standardized claim frequency
Table: Results of Exercise 4.8
group
1
2
3
4
5
6
# of claims
34
22
27
8
12
24
MLE* of 4i
1.77
1.58
1.30
1.00
0.87
1.04
cred. weight Di
28.2%
19.7%
23.5%
6.9%
10.9%
21.2%
cred. est. of 4i
1.48
1.40
1.35
1.33
1.31
1.29
Table: Results of Exercise 4.10
C.4 Exercises to Chapter 5
Exercise 5.1
a) The following table shows the values of
Z =
P
P + Z
,
R(m) = 2
XY Z,
if we replace the structural parameters in these formulae with the esti-
mated values given in the table of Exercise 5.1. From the graphs of R(m)
we can see, that this function is rather ﬂat and that we can choose the
truncation point within a large area without losing much accuracy. Indeed,
the main aim of credibility with truncation is to meet the requirement
that large premium jumps because of one or a few large claims should be
avoided.

306
C Appendix C:
Solutions to the Exercises
trunc.point
m
DZ
R(m)
DZ
R(m)
DZ
R(m)
f
25.7%
0.257
63.4%
0.634
85.2%
0.852
100 000
27.0%
0.267
64.9%
0.642
86.0%
0.851
95 000
27.2%
0.269
65.2%
0.644
86.2%
0.851
90 000
27.5%
0.271
65.5%
0.645
86.3%
0.851
85 000
27.8%
0.274
65.9%
0.648
86.5%
0.851
80 000
28.2%
0.276
66.2%
0.650
86.7%
0.851
75 000
28.5%
0.279
66.6%
0.652
86.9%
0.851
70 000
28.9%
0.282
67.0%
0.654
87.1%
0.851
65 000
29.3%
0.286
67.5%
0.658
87.4%
0.852
60 000
29.8%
0.290
68.0%
0.661
87.6%
0.852
55 000
30.5%
0.296
68.7%
0.666
88.0%
0.853
50 000
31.3%
0.303
69.5%
0.673
88.4%
0.856
45 000
32.6%
0.315
70.7%
0.684
89.0%
0.860
40 000
34.0%
0.328
72.0%
0.694
89.6%
0.863
35 000
35.5%
0.338
73.4%
0.699
90.2%
0.860
30 000
36.4%
0.348
74.1%
0.710
90.5%
0.867
25 000
37.6%
0.359
75.1%
0.717
90.9%
0.869
20 000
38.9%
0.363
76.1%
0.710
91.4%
0.853
15 000
41.4%
0.374
77.9%
0.704
92.2%
0.832
10 000
44.8%
0.373
80.2%
0.669
93.1%
0.777
5 000
50.0%
0.359
83.4%
0.598
94.3%
0.677
P = 60 000
P = 300 000
P = 1 000 000
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
5 000
15 000
25 000
35 000
45 000
55 000
65 000
75 000
85 000
95 000
R(m)
P = 60 000
P = 300 000
P = 1 000 000

C.4 Exercises to Chapter 5
307
b) The formulae for the correction factor are
\
\
µ (i) =
;
A
A
A
A
?
A
A
A
A
=
1 +
P
P+84 924 · (Z15 000  0.81) , if 20 000  P < 100 000,
1 +
P
P+105 033 · (Z30 000  0.90), if 100 000  P < 1 000 000,
1 +
P
P+173 531 · (X  1),
if 1 000 000  P.
For the ﬁve policies we get:
P
estimate of
original
with trunc.
original
with trunc.
PX(4i)
policy 1
20 000
 
0%
0%
0.82
policy 2
20 000
36 000
36 000
180%
180%
1.22
policy 3
20 000
36 000
19 000
180%
95%
1.03
policy 4
300 000
300 000
300 000
100%
100%
1.08
policy 5
300 000
360 000
220 000
120%
73%
0.87
total claim amount 
loss ratio
Remarks:
The claim free policy 1 gets a discount of 18% compared to the basic
premium rate. Policies 2 and 3 both have a very unfavourable claims
experience: the observed loss ratio is 180% for both. However, with policy
3, this high loss ratio is mainly caused by one large claim. Therefore, the
surcharge for policy 3 is only 3%, whereas it is 22% for policy 2. The
observed loss ratio of policy 4 coincides with the a priori expected value.
Nevertheless it gets a surcharge of 8%. The reason is that policy 4 had
a loss ratio of 100% despite the fact that it was a period without any
larger claim (above 30 000). Therefore the loss ratio of 100% is considered
an unfavourable observation. The opposite holds true for policy 5. Its
observed loss ratio is even higher, namely 120%. But it is caused by two
larger claims. Otherwise the claims experience was very good. Therefore
it gets a discount of 13%.
Exercise 5.2
The table “Results of Exercise 5.2” below shows the credibility estimates with
and without truncating the individual claims:

308
C Appendix C:
Solutions to the Exercises
region
# of claims original truncated
semilinear
Bü-Str
Xi
Yi
DX
(i)
DY
(i)
WXY/WY
2DY
(i)
PX
(f)(Ti)
PX
(BS)(Ti)
1
1  785 11  224
4  760
59%
61%
150%
9 182
10 092
2
  37
6  348
4  887
3%
3%
8%
8 536
8 415
3
  280 13  273
4  932
18%
20%
48%
8 904
10 818
4
3  880 11  754
4  631
76%
77%
190%
8 781
10 955
5
  846
6  559
4  275
40%
42%
105%
7 750
7 703
6
  464 10  045
5  071
27%
29%
71%
9 340
8 901
7
  136
5  968
4  174
10%
11%
26%
8 232
8 230
8
  853
5  407
3  974
41%
43%
105%
6 987
7 232
9
2  151
5  483
4  135
63%
65%
161%
6 820
6 583
10
  155
5  133
4  139
11%
12%
29%
8 177
8 108
11
  653
6  815
4  504
34%
36%
89%
8 347
7 906
12
  252 12  161
4  877
17%
18%
44%
8 810
9 262
13
1  228
8  670
4  849
50%
52%
127%
9 348
8 572
14
  865
6  780
4  482
41%
43%
106%
8 267
7 783
15
  145
6  273
4  949
10%
11%
28%
8 732
8 248
16
  127
6  694
4  070
9%
10%
25%
8 185
8 312
17
2  151
8  757
4  624
63%
65%
161%
8 707
8 654
18
  449
6  535
4  514
26%
28%
69%
8 393
7 963
19
  784
7  068
4  191
39%
41%
100%
7 580
7 934
20
  438 11  453
5  243
26%
28%
68%
9 586
10 287
21
1  011
9  010
5  224
45%
47%
115%
10 305
8 715
22
1  692
7  666
4  671
58%
60%
147%
8 853
8 010
23
  82
8  856
3  710
6%
7%
16%
8 139
8 500
24
2  813
7  967
4  094
69%
71%
175%
6 500
6 739
25
  729
9  213
4  523
37%
39%
96%
8 382
8 748
26
  329
6  727
5  157
21%
22%
55%
9 258
8 112
27
5  743
8  279
4  686
82%
83%
205%
9 077
8 314
28
3  002
8  149
4  491
71%
72%
178%
8 163
8 245
Total
33  080
8  486
4  555
8 421
8 486
cred. estimators
observed
Table: Results of Exercise 5.2
Exercise 5.3
a) Structural parameters:
bµX = 5 839,
b2
X = 2.843E + 09, b 2
X = 1.165E + 05, bX = b2
X
b2
X = 24 407.
The following table shows the resulting estimates of the credibility weights
(i)
X and of µX(i).

C.4 Exercises to Chapter 5
309
risk
# of
observations
group
claims
Xi
DX
(i)
PX(4i)
1
 92
3 478
0.4%
5 830
2
 542
5 204
2.2%
5 825
3
 57
2 092
0.2%
5 830
4
 317
4 437
1.3%
5 821
5
 902
4 676
3.6%
5 797
6
 137
6 469
0.6%
5 842
7
 48
12 285
0.2%
5 851
8
 528
3 717
2.1%
5 794
9
 183
14 062
0.7%
5 900
10
 365
9 799
1.5%
5 897
Total
3 171
5 825
5 825
cred. estimates
Note that due to the small credibility weights, the credibility estimates of
µX (i) are very close to each other.
b) Structural parameters:
bµY = 6.66,
b2
Y = 3.8149, b 2
Y = 0.0527, bY = b2
Y
b 2
Y = 72.
With these parameters we get the following estimates for (i)
Y , µY (i)
and µX (i) .
risk
# of
logarithms
estimate of
group
claims
Yi
DY
(i)
PY(4i)
PX(4i)
1
92
6.47
56%
6.56
    
4 737
2
542
6.78
88%
6.77
    
5 848
3
57
6.45
44%
6.57
    
4 806
4
317
6.73
81%
6.72
    
5 571
5
902
6.59
93%
6.60
    
4 930
6
137
6.60
65%
6.62
    
5 064
7
48
7.30
40%
6.92
    
6 805
8
528
6.40
88%
6.43
    
4 186
9
183
7.25
72%
7.08
    
8 035
10
365
6.33
83%
6.39
    
3 995
Total
3 171
6.62
5 125
cred. estimates

310
C Appendix C:
Solutions to the Exercises
c)
risk
# of
group
claims
obs.
obs.
a)
b)
a)
b)
1
92
3 478
5 830
4 737
0.597
    
1.001
    
0.924
    
2
542
5 204
5 825
5 848
0.893
    
1.000
    
1.141
    
3
57
2 092
5 830
4 806
0.359
    
1.001
    
0.938
    
4
317
4 437
5 821
5 571
0.762
    
0.999
    
1.087
    
5
902
4 676
5 797
4 930
0.803
    
0.995
    
0.962
    
6
137
6 469
5 842
5 064
1.110
    
1.003
    
0.988
    
7
48
12 285
5 851
6 805
2.109
    
1.004
    
1.328
    
8
528
3 717
5 794
4 186
0.638
    
0.995
    
0.817
    
9
183
14 062
5 900
8 035
2.414
    
1.013
    
1.568
    
10
365
9 799
5 897
3 995
1.682
    
1.012
    
0.780
    
Total
3 171
5 825
5 825
5 125
1.000
    
1.000
    
1.000
    
average claim size (relative)
estimated
estimated
average claim size (absolute)
Short comments:
Method a) (Bühlmann—Straub) yields nearly no dierences between risks.
This is of course due to the large claims having small credibility weights.
The results of method b) depend very much on the distributional assump-
tions. By taking the logarithms, the inﬂuence of large claims is weighed
down. The associated credibility weights attributed to the ”transformed”
claims are much higher, and therefore the results dier much more between
risks. However, contrary to the homogeneous estimator in the Bühlmann—
Straub model, the resulting average claim amount over the whole portfolio
does not coincide any more with the observed one. Indeed, in this case it
is much lower, namely 5 125 compared to an overall observed average of
5 825.
Exercise 5.4
a) The estimate of the structural parameter  2 is zero, i.e. \
\
µ (i)
emp
= 6 443
for all i.
Comment:
Possible underlying dierences between the risk groups cannot be recog-
nized because of the noise caused by the large claims.
b) For the large claims (bodily injury) the estimate of  2 is again zero. This
is not surprising and means, that the expected value of the large claims
is the same for all risk groups. However, the large claims do nevertheless
dierentiate between risk groups, because the probability that a claim is
a large claim is not the same for all risk groups. The table below shows
the observations and the resulting estimates.

C.5 Exercises to Chapter 6
311
risk
estimate of
group
ni
ni
(n)
ni
(l)
ni
(l)/ni
Xi
Xi
(n)
Xi
(l)
P(n)(Ti)
P(l)(Ti)
3i
P(Ti)
in 1 000
in 1 000
1
2 616
2 595
 21
0.80%
6'727
   
2'889
481
2 831
401 0.949%
6 613
2
 771
 763
 8
1.04%
7'548
   
2'490
490
2 526
401 0.966%
6 380
3
3 328
3 302
 26
0.78%
4'513
   
2'273
289
2 318
401 0.942%
6 080
4
 234
 233
 1
0.43%
3'239
   
2'403
198
2 524
401 0.959%
6 350
5
1 685
1 670
 15
0.89%
6'624
   
2'480
468
2 504
401 0.959%
6 331
6
3 132
3 099
 33
1.05%
7'989
   
2'558
518
2 560
401 0.974%
6 446
7
 643
 631
 12
1.87%
8'901
   
2'471
347
2 520
401 0.987%
6 456
8
2 453
2 428
 25
1.02%
5'898
   
2'705
316
2 679
401 0.969%
6 544
9
 116
 116
 
0.00%
2'836
   
2'836
0
2 616
401 0.960%
6 444
10
8 330
8 246
 84
1.01%
6'517
   
2'651
386
2 646
401 0.975%
6 535
Total 23 308 23 083  225
0.97%
6'443
   
2'593
401
2 593
401 0.967%
6 443
observations
credibility estimates of 
C.5 Exercises to Chapter 6
Exercise 6.1
a) Structural parameters:
bµ = 0.962,
b2 = 32.76,
b 2
1 = 0.0172, b1 = b2/b 2
1 = 1 900,
b 2
2 = 0.00897, b2 = b 2
1/b 2
2 = 1.992.
Credibility estimates:
own company
other companies
risk
cred. 
P0
Bh
(2)
Cred. cred.
B1
(1)
cred.
Cred.
B2
(1)
cred.
h
weight
estim. weight
estim. weight
estim.
1
45%
0.96
0.78
0.88
67%
0.81
0.83
88%
0.75
0.76
2
34%
0.96
0.89
0.94
38%
0.94
0.94
62%
0.86
0.89
3
41%
0.96
1.00
0.98
60%
0.93
0.95
71%
1.06
1.04
4
35%
0.96
0.98
0.97
37%
1.14
1.03
65%
0.89
0.92
5
35%
0.96
0.95
0.96
22%
0.73
0.91
83%
1.01
1.00
6
37%
0.96
0.93
0.95
41%
1.04
0.99
70%
0.86
0.89
7
37%
0.96
1.30
1.09
41%
1.48
1.25
70%
1.19
1.16
8
32%
0.96
0.90
0.94
33%
1.10
0.99
59%
0.79
0.85
cred. estim. on level 2
cred. estim. on level 1
b) Structural parameters:
bµ = 0.962,
b2 = 32.76,
b 2
1 = 0.0239, b1 = b2/b 2
1 = 1 368,
b 2
2 = 0.

312
C Appendix C:
Solutions to the Exercises
comp.
risk
other companies
h
cred. 
P0
Bh
(2) cred. 
i
cred.
B1
(1)
cred.
cred.
B2
(1)
cred.
weight
estim.
weight
estim.
weight
estim.
1 (own)
0%
0.96 1.02
0.96
1
74%
0.81
0.85
91%
0.75
0.77
   
2 (others)
0%
0.96 0.93
0.96
2
46%
0.94
0.95
69%
0.86
0.89
   
3
68%
0.93
0.94
77%
1.06
1.04
   
4
45%
1.14
1.04
72%
0.89
0.91
   
5
28%
0.73
0.90
87%
1.01
1.00
   
6
49%
1.04
1.00
77%
0.86
0.88
   
7
49%
1.48
1.22
77%
1.19
1.14
   
8
40%
1.10
1.02
67%
0.79
0.85
   
cred. estim. on level 2
cred. estim. on level 1
own company
Remark:
Since b 2
2 = 0, the credibility weights on the second level are zero and we
have to estimate µ0 by
bµ0 =
X
h
w(2)
h
w(2)
•
B(2)
h .
Of course, in this case one could forget about the second hierarchical level,
and the above results coincide with the ones obtained with the Bühlmann-
Straub model.
c) In model a), each of the eight risk groups is characterized by its proﬁle
h, and the company’s own portfolio in each of these risk groups is char-
acterized by further characteristics. In one risk group, the quality of the
individual risks of the company might be better, and in another risk group
worse than the quality of the risks with the other companies. In model b)
however, the company itself is characterized by its proﬁle and might attract
in general over all risk groups better or worse quality risks (for instance
because of its underwriting policy). The risk group appears only on the
second level. In the above example, a general dierence between the own
company and the total of the other companies could not be found on level
two from the data (b 2
2 was zero).

C.5 Exercises to Chapter 6
313
Exercise 6.2
a) Frequency of normal claims
use of
P
Bh
risk
Bi
car
in %o
in %o
Dh
(2)
P()h)
class
P()h) in %o
Di
(1)
P(4i)
A
117.3
 
86.8
   
94.2%
88.5
    
A1
88.5
60.3
98.8%
60.3
A2
88.5
74.9
99.5%
74.9
A3
88.5
80.5
93.2%
80.5
A4
88.5
91.5
95.6%
91.5
A5
88.5 126.5
98.9% 126.5
B
117.3
 
148.2
 
92.9%
146.0
  
B1
146.0 134.6
54.6% 134.6
B2
146.0 174.4
95.6% 174.4
B3
146.0
98.2
60.1%
98.2
B4
146.0 143.1
84.9% 143.1
B5
146.0 165.3
98.6% 165.3
cred. estim.
cred. estim. on level 2
cred. estim. on level 1
cred. estim.
Frequency of large claims
use of
P
Bh
risk
Bi
car
in %o in %o
Dh
(2)
P()h)
class P()h) in %o
Di
(1)
P(4i)
A
1.60
 
1.03
 
82.2%
1.13
    
A1
1.13
0.87
83.7%
0.91
A2
1.13
0.97
92.5%
0.98
A3
1.13
0.00
46.7%
0.60
A4
1.13
1.07
58.2%
1.09
A5
1.13
1.81
85.2%
1.71
B
1.60
 
2.27
 
69.7%
2.07
    
B1
2.07
0.00
7.2%
0.0
B2
2.07
2.14
58.1%
0.0
B3
2.07
0.00
8.8%
0.0
B4
2.07
4.93
26.5%
0.0
B5
2.07
1.95
82.1%
0.0
cred. estim. on level 2
cred. estim. on level 1
cred. estim.
cred. estim.

314
C Appendix C:
Solutions to the Exercises
C.6 Exercises to Chapter 7
Exercise 7.1
Structural parameters:
bµ1 = 1.020,
bµ2 = 0.932,
b2
1 = 33.2,
b2
2 = 32.3,
bT =
µ 0.279 0.203
0.203 0.198
¶
.
Results:
risk
categ.
cred. est. of
group
P
B
P(4i)
1
own
51.6%
44.7%
1.020
0.810
    
0.830
others
11.5%
79.3%
0.932
0.750
    
0.763
2
own
33.2%
44.9%
1.020
0.940
    
0.961
others
16.3%
54.4%
0.932
0.860
    
0.880
3
own
51.7%
36.7%
1.020
0.930
    
1.021
others
21.9%
57.3%
0.932
1.060
    
0.986
4
own
31.7%
47.7%
1.020
1.140
    
1.038
others
15.0%
57.6%
0.932
0.890
    
0.926
5
own
14.2%
74.6%
1.020
0.730
    
1.037
others
4.3%
80.9%
0.932
1.010
    
0.983
6
own
33.3%
50.1%
1.020
1.040
    
0.991
others
14.3%
62.4%
0.932
0.860
    
0.890
7
own
33.6%
50.1%
1.020
1.480
    
1.304
others
14.3%
62.7%
0.932
1.190
    
1.160
8
own
29.3%
45.3%
1.020
1.100
    
0.979
others
15.0%
52.8%
0.932
0.790
    
0.869
total
own
0.985
    
0.985
others
0.905
    
0.905
cred.matrix
Ai
The observations and the credibility estimates are displayed in Figure C.1.
Exercise 7.2
Structural parameters:
bµ1 = b2
1 = 1.092, bµ2 = b2
2 = 1.127,
b2
1 = 33.2, b2
2 = 32.3
bT =
µ 0.192 0.193
0.193 0.223
¶
resulting credibility matrices and credibility estimates: see table “Results of
Exercise 7.2”.

C.6 Exercises to Chapter 7
315
0.50
0.60
0.70
0.80
0.90
1.00
1.10
1.20
1.30
1.40
1.50
1
2
3
4
5
6
7
8
risk class
claims ratio
 0
2 000
4 000
6 000
8 000
10 000
12 000
14 000
16 000
weight
weight own
weight others
obs. own
cred. own
obs. others
cred. others
Fig. C.1. Observations and credibility estimates of Exercise 7.1
risk
categ.
cred. est. of
group
P
Fi rel
O(4i) rel
A1
normal
97.5%
2.1%
1.09
0.60
0.60
large
34.2%
57.6%
1.13
0.66
0.69
A2
normal
98.9%
0.9%
1.09
0.74
0.74
large
28.0%
69.3%
1.13
0.74
0.76
A3
normal
88.1%
10.1%
1.09
0.80
0.72
large
27.3%
33.2%
1.13
0.00
0.67
A4
normal
91.9%
7.0%
1.09
0.91
0.90
large
31.4%
40.0%
1.13
0.81
0.94
A5
normal
97.8%
1.9%
1.09
1.25
1.25
large
33.7%
59.0%
1.13
1.38
1.33
B1
normal
55.2%
32.5%
1.09
1.33
0.86
large
5.3%
6.0%
1.13
0.00
1.07
B2
normal
91.9%
7.0%
1.09
1.73
1.71
large
31.4%
39.9%
1.13
1.63
1.53
B3
normal
58.4%
31.2%
1.09
0.97
0.67
large
6.5%
7.4%
1.13
0.00
1.04
B4
normal
77.7%
18.6%
1.09
1.42
1.83
large
17.6%
20.3%
1.13
3.77
1.72
B5
normal
97.3%
2.4%
1.09
1.64
1.63
large
34.6%
56.1%
1.13
1.49
1.52
total
normal
1.00
large
1.00
cred.matrix
Ai
Table: Results of Exercise 7.2

316
C Appendix C:
Solutions to the Exercises
Exercise 7.5
a)
Credibility matrix for  = 5
A =
3
E
E
C
16.5% 2.8% 2.8% 0.6%
2.8% 15.4% 1.6%
9.7%
2.8%
1.6% 15.4% 9.7%
0.6% 9.7% 9.7% 14.4%
4
F
F
D
b)
The observations of region 2 and 3 are inﬂuenced from the characteris-
tics of region 4 because of the positive correlations between region 4 and
regions 2 and 3 (e.g. think of region 4 being a town and regions 2 and 3
agglomerations of this town; the observations of regions 2 and 3 are in-
ﬂuenced by persons travelling from the agglomeration to the town). The
negative value a14 can be interpreted as a correction of the region 4 eect
inherent in the observations of regions 2 and 3.
c), d) and e)
(Inhomogeneous) credibility estimates of :
Region:
1
2
3
4
Observation Nk/k 0.20 0.60 1.20 2.00
bbmultid.
0.86 1.02 1.10 1.13
bbB¨uStr.
0.87 0.93 1.03 1.17
Note the dierence between the two methods: because of the high cor-
relation (70%) between region 4 and regions 2 and 3 and the high ob-
served value in region 4, the multidimensional estimates for regions 2 and
3 are substantially higher than the one-dimensional Bühlmann—Straub
estimates.
Exercise 7.6
a) e = (Var [])1 =
¡
0.252¢1 = 16;
 • = 49.5;
 =  •/ ( • + e) = 76%;
eF• = N•/ • = 0.95;
bb = 1 + 
³
eF•  1
´
= 0.96.

C.6 Exercises to Chapter 7
317
b) k =  k/ ( k + e) ;
eFk = Nk/ k; bbk = 1 + k
³
eFk  1
´
.
age class k
1
2
3
4
5
6
7
8
9
10
 k 1.60 1.71 1.46
2.45
3.06
4.15
5.28
6.92
9.71 13.16
k 9.1% 9.7% 8.4% 13.3% 16.1% 20.6% 24.8% 30.2% 37.8% 45.1%
eFk 0.00 0.00 0.00
0.41
0.65
0.72
1.14
1.16
1.13
1.22
bbk 0.91 0.90 0.92
0.92
0.94
0.94
1.03
1.05
1.05
1.10
U=
U=
U=
U=
U=
0
0.25
0.5
0.75
1
age group       nk
Nk
Nk/nk
16-20
1.60
0
0.00
0.91
0.88
0.84
0.79
0.96
21-25
1.71
0
0.00
0.90
0.86
0.81
0.77
0.96
26-30
1.46
0
0.00
0.92
0.87
0.82
0.78
0.96
31-35
2.45
1
0.41
0.92
0.88
0.84
0.81
0.96
36-40
3.06
2
0.65
0.94
0.91
0.88
0.86
0.96
41-45
4.15
3
0.72
0.94
0.94
0.93
0.91
0.96
46-50
5.28
6
1.14
1.03
1.03
1.02
1.00
0.96
51-55
6.92
8
1.16
1.05
1.06
1.07
1.05
0.96
56-60
9.71
11
1.13
1.05
1.07
1.09
1.08
0.96
61-65
13.16
16
1.22
1.10
1.10
1.11
1.10
0.96
Total
49.50
47
0.95
Credibility estimate of Qk
c)
d) Note that the result for  = 1 is the same as the one found in a) and that
the results for  = 0 are identical to the ones found in b).
In general, the correlation will be between the two extremes. Let us con-
sider the case  = 0.75. Note the “pooling impact” of the multidimensional
estimator in the lower age groups: the favourable observations in the lower
age groups get more weight than if each of them is considered separately
as in a).
The following table shows the credibility matrix for  = 0.75:

318
C Appendix C:
Solutions to the Exercises
k
1
2
3
4
5
6
7
8
9
10
1
8.2%
5.9%
3.4%
3.7%
2.9%
2.4%
1.8%
1.3%
1.0%
0.7%
2
5.5%
8.3%
4.7%
5.1%
4.0%
3.3%
2.4%
1.8%
1.3%
1.0%
3
3.7%
5.5%
6.8%
7.3%
5.8%
4.7%
3.5%
2.5%
1.9%
1.4%
4
2.4%
3.6%
4.4% 10.5%
8.3%
6.8%
5.0%
3.6%
2.7%
2.0%
5
1.5%
2.3%
2.8%
6.6% 12.2% 10.0%
7.4%
5.4%
4.0%
3.0%
6
0.9%
1.4%
1.7%
4.0%
7.4% 15.2% 11.2%
8.2%
6.1%
4.5%
7
0.5%
0.8%
1.0%
2.3%
4.3%
8.8% 17.7% 12.9%
9.6%
7.1%
8
0.3%
0.4%
0.5%
1.3%
2.4%
4.9%
9.8% 21.1% 15.7% 11.7%
9
0.2%
0.2%
0.3%
0.7%
1.3%
2.6%
5.2% 11.2% 27.1% 20.3%
10
0.1%
0.1%
0.2%
0.4%
0.7%
1.4%
2.9%
6.2% 14.9% 37.6%
C.7 Exercises to Chapter 8
Exercise 8.1
a)
intercept slope
i)
107.8
4.0
ii)
107.8 10.0
iii)
130.0
4.0
i)
60
80
100
120
140
160
1
2
3
4
5
year
individual
credibility
collective

C.7 Exercises to Chapter 8
319
ii)
60
80
100
120
140
160
1
2
3
4
5
year
individual
credibility
collective
iii)
60
80
100
120
140
160
1
2
3
4
5
year
individual
credibility
collective
Comments:
i)
Intercept and slope are between collective and individual regression line.
ii) Since  2
1 is near to zero, the slope is the same as in the collective regression
line. Hence if we a priori assume, that the slope is the same for all risks
considered, we just have to choose  2
1 very small (compared to 2).
iii) The slope is the same as in i), but because  2
0 is near to zero, the intercept
coincides with the intercept of the collective regression line.

320
C Appendix C:
Solutions to the Exercises
Exercise 8.2
a)
risk groups
1
2
3
4
global (j0)
centres of gravity of time 3.50 3.33 3.26 3.30
3.40
Remark: the individual centres of gravity are very close to each other.
b)
individual regression lines collective regression line
risk groups
1
2
3
4
intercept (at j0) 6 425 6 113 6 856 4 996
6 098
slope
169
245
211
271
224
group 1
4 500
5 000
5 500
6 000
6 500
7 000
7 500
1
2
3
4
5
6
observed
individual
credibility
collective

C.7 Exercises to Chapter 8
321
group 2
4 500
5 000
5 500
6 000
6 500
7 000
7 500
1
2
3
4
5
6
observed
individual
credibility
collective
group 3
4 500
5 000
5 500
6 000
6 500
7 000
7 500
8 000
1
2
3
4
5
6
observed
individual
credibility
collective

322
C Appendix C:
Solutions to the Exercises
group 4
3 000
3 500
4 000
4 500
5 000
5 500
6 000
6 500
7 000
7 500
1
2
3
4
5
6
observed
individual
credibility
collective
c)
risk groups
1
2
3
4
credibility estimate for j = 8 7 202 7 239 7 829 6 244
d) The same slope for all risk groups is identical to the assumption that  2
1
is equal to zero. The estimator of the slope of the collective regression line
for  2
1 $ 0 is equal to
b1 =
4
X
j=1
w
i•
w••
Bi1 = 204.
We then get the following results:
credibility regression lines
risk groups
1
2
3
4
intercept (at j0) 6 425 6 113 6 856 4 996
slope
204
204
204
204
,
risk groups
1
2
3
4
credibility estimate for j = 8 7 362 7 050 7 793 5 933

References
[AL83]
B. Abraham and J. Ledolter. Statistical Methods for Forecasting. John
Wiley and Sons, New York, 1983.
[Bai45]
A. L. Bailey. A generalized theory of credibility. Proc. of Cas. Act. Soc.,
32:13—20, 1945.
[Bai50]
A. L. Bailey. Credibility procedures, Laplac’s generalization of Bayes’
Rule and the combination of collateral knowledge with observed data.
Proc. of Cas. Act. Soc., 37:7—23, 1950.
[BG97]
H. Bühlmann and A. Gisler. Credibility in the regression case revisited.
ASTIN Bulletin, 27:83—98, 1997.
[Bic64]
F. Bichsel.
Erfahrungstariﬁerung in der Motorfahrzeug-Haftpﬂicht-
Versicherung. Bulletin of Swiss Ass. of Act., pages 119—130, 1964.
[BJ87]
H. Bühlmann and W. S. Jewell. Hierarchical credibility revisited. Bulletin
of Swiss Ass. of Act., pages 35—54, 1987.
[BS70]
H. Bühlmann and E. Straub. Glaubwürdigkeit für Schadensätze. Bulletin
of Swiss Ass. of Act., pages 111—133, 1970.
[Büh64]
H. Bühlmann. Optimale Prämienstufensysteme. Bulletin of Swiss Ass.
of Act., pages 193—214, 1964.
[Büh67]
H. Bühlmann. Experience rating and credibility. ASTIN Bulletin, 4:199—
207, 1967.
[Büh69]
H. Bühlmann. Experience rating and credibility. ASTIN Bulletin, 5:157—
165, 1969.
[Büh70]
H. Bühlmann. Mathematical Methods in Risk Theory. Springer-Verlag,
Berlin, 1970.
[Dan94]
D. R. Dannenburg.
Some results on the estimation of the credibility
factor in the classical Bühlmann model.
Insurance: Mathematics and
Economics, 14:39—50, 1994.
[Dan96a]
D. R. Dannenburg. An autoregressive credibility IBNR model. Blätter der
deutschen Gesellschaft für Versicherungsmathematik, 22:235—248, 1996.
[Dan96b]
D. R. Dannenburg. Basic actuarial credibility models — Evaluations and
extensions. PhD thesis, Tinbergen Institute, Amsterdam, 1996.
[DeG70]
M. H. DeGroot. Optimal Statistical Decisions. McGraw-Hill, New York,
1970.
[Del65]
P. Delaporte. Tariﬁcation du risque individuel d’accidents d’automobiles
par la prime modelée sur le risque. ASTIN Bulletin, 3:251—271, 1965.

324
References
[DF64]
B. De Finetti. Sulla teoria della credibilità. Giornale dell’Instituto Ital-
iano degli Attuari, 27:219—231, 1964.
[DG81]
A. Dubey and A. Gisler. On parameter estimators in credibility. Bulletin
of Swiss Ass. of Act., pages 187—212, 1981.
[DKG96]
D. R. Dannenburg, R. Kaas, and M. J. Goovaerts.
Practical Actuar-
ial Credibility Models. Institute of Actuarial Science and Econometrics,
Amsterdam, 1996.
[DPDG76] N. De Pril, L. D’Hooge, and M. J. Goovaerts. A bibliography on credi-
bility theory and its applications. Journal of Computational and Applied
Mathematics, 2:55—62, 1976.
[DV76a]
F. De Vylder. Geometrical credibility. Scand. Act. J., pages 121—149,
1976.
[DV76b]
F. De Vylder. Optimal semilinear credibility. Bulletin of Swiss Ass. of
Act., pages 27—40, 1976.
[DV77]
F. De Vylder. Iterative credibility. Bulletin of Swiss Ass. of Act., pages
25—33, 1977.
[DV78]
F. De Vylder. Parameter estimation in credibility theory. ASTIN Bul-
letin, 10:99—112, 1978.
[DV81a]
F. De Vylder.
Practical credibility theory with emphasis on optimal
parameter estimation. ASTIN Bulletin, 12:115—131, 1981.
[DV81b]
F. De Vylder. Regression model with scalar credibility weights. Bulletin
of Swiss Ass. of Act., pages 27—39, 1981.
[DVB79]
F. De Vylder and Y. Ballegeer. A numerical illustration of optimal semi-
linear credibility. ASTIN Bulletin, 10:131—148, 1979.
[DVC94]
F. De Vylder and H. Cossette. Dependent contracts in Bühlmann’s cred-
ibility model. Bulletin of Swiss Ass. of Act., pages 117—147, 1994.
[DVG91]
F. De Vylder and M. Goovaerts.
Estimation of the heterogenity pa-
rameter in the Bühlmann-Straub credibility theory model. Insurance:
Mathematics and Economics, 11:233—238, 1991.
[DY79]
P. Diaconis and D. Ylvisaker. Conjugate priors for exponential families.
Annals of Statistics, 7:269—281, 1979.
[Fer73]
T. S. Ferguson. A Bayesian analysis of some nonparametric problems.
Annals of Statistics, 1:209—230, 1973.
[Ger79]
H. U. Gerber. An Introduction to Mathematical Risk Theory. Huebner
Foundation Monograph no 8, Richard D. Irwin Inc., Homewood, Illinois,
1979.
[Ger95]
H. U. Gerber. A teacher’s remark on exact credibility. ASTIN Bulletin,
25:189—192, 1995.
[GH87]
M. J. Goovaerts and W. J. Hoogstad.
Credibility theory.
Survey of
Acturial Studies, Nationale-Nederlanden, 4, 1987.
[Gis80]
A. Gisler. Optimum trimming of data in the credibility model. Bulletin
of Swiss Ass. of Act., pages 313—325, 1980.
[Gis89]
A. Gisler. Optimales Stutzen von Daten in der Credibility-Theorie. In
Schriftenreihe Angewandte Versicherungsmathematik, volume 22, pages
124—150. Verlag Versicherungswirtschaft, Karlsruhe, 1989.
[Gis90]
A. Gisler. Credibility-theory made easy. Bulletin of Swiss Ass. of Act.,
pages 75—100, 1990.
[Gis96]
A. Gisler.
Bonus-malus and tari segmentation.
ASTIN Colloquium,
1996.

References
325
[GJ75a]
H. U. Gerber and D. A. Jones.
Credibility formulae with geometric
weights. Transaction of the Society of Actuaries, 27:39—52, 1975.
[GJ75b]
H. U. Gerber and D. A. Jones. Credibility formulas of the updating type.
In P. M. Kahn, editor, Credibility: Theory and Applications, Academic
Press, New York, 1975.
[GR93]
A. Gisler and P. Reinhard. Robust credibility. ASTIN Bulletin, 23:117—
143, 1993.
[Hac75]
C. A. Hachemeister. Credibility for regression models with application
to trend. In P. M. Kahn, editor, Credibility: Theory and Applications,
Academic Press, New York, 1975.
[Her99]
T. N. Herzog. Introduction to Credibility Theory. ACTEX Publications,
Winsted, CT, USA, 1999.
[Hes91]
O. Hesselager. Prediction of outstanding claims, a hierachical credibility
approach. Scand. Act. J., pages 77—90, 1991.
[Hic75]
J. C. Hickman. Introduction and historical overview of credibility. In
P. M. Kahn, editor, Credibility: Theory and Applications, Academic
Press, New York, 1975.
[HP98]
M. R. Hardy and H. H. Panjer. A Credibility Approach to Mortality
Risk. ASTIN Bulletin, 28:269—283, 1998.
[Jew73]
W. S. Jewell. Multidimensional credibility. Report ORC Berkeley, 1973.
[Jew74a]
W. S. Jewell. Credibility means are exact Bayesian for exponential fam-
ilies. ASTIN Bulletin, 8:77—90, 1974.
[Jew74b]
W. S. Jewell. Exact multidimensional credibility. Bulletin of Swiss Ass.
of Act., pages 193—214, 1974.
[Jew75a]
W. S. Jewell.
Model variations in credibility theory.
In P. M. Kahn,
editor, Credibility: Theory and Applications, Academic Press, New York,
1975.
[Jew75b]
W. S. Jewell. Regularity conditions for exact credibility. ASTIN Bulletin,
8:336—341, 1975.
[Jew75c]
W. S. Jewell. The use of collateral data in credibility theory: a hierarchical
model. Giornale dell’Instituto Italiano degli Attuari, 38:1—16, 1975.
[Jew76a]
W. S. Jewell. Bayesian regression and credibility theory. Report ORC
Berkeley, 1976.
[Jew76b]
W. S. Jewell. A survey of credibility theory. Report ORC Berkeley, 1976.
[JZ83]
P. de Jong and B. Zehnwirth. Credibility theory and the Kalman ﬁlter.
Insurance: Mathematics and Economics, 2:281—286, 1983.
[Kal60]
R. E. Kalman. A new approach to linear ﬁltering and prediction prob-
lems. Transactions of ASME—Journal of Basic Engineering, 82:35—45,
1960.
[Kef29]
R. Keer. An experience rating formula. Transaction of the Society of
Actuaries, 15:223—235, 1929.
[KF70]
A. N. Kolmogorov and V. S. Fomin. Introductory Real Analysis. Dover
Publications, New York, 1970.
[Klu92]
S. A. Klugman. Bayesian Statistics in Actuarial Science: With Emphasis
on Credibility. Kluwer, 1992.
[Kre82]
E. Kremer. Credibility for some evolutionary models. Scand. Act. J.,
pages 129—142, 1982.
[Kün92]
H. R. Künsch. Robust methods for credibility. ASTIN Bulletin, 22:33—49,
1992.

326
References
[LC62]
L. H. Longley-Cook. An introduction to credibility theory. Proc. of Cas.
Act. Soc., 49:194—221, 1962.
[Leh86]
E. L. Lehmann. Testing Statistical Hypothesis. Wiley Series in Probability
and Mathematical Statistics: Probability and Mathematical Statistics,
New York, 1986.
[Lun40]
O. Lundberg. On random processes and their applications to sickness
and accident statistics. In University of Stockholm Thesis, Alquist and
Wiksells, Uppsala, 1940.
[May64]
A. L. Mayerson. A Bayesian view of credibility. Proc. of Cas. Act. Soc.,
51:85—104, 1964.
[Meh75]
R. K. Mehra. Credibility theory and Kalman ﬁltering with extensions.
Report RM 75-64, International Institute for Applied Systems Analysis,
Schloss Laxenburg, Austria, 1975.
[MN89]
P. McCullagh and J. A. Nelder. Generalized Linear Models. Chapman
and Hall, Cambridge, 2nd edition, 1989.
[Mow14]
A. H. Mowbray. How extensive a payroll exposure is necessary to give a
dependable pure premium. Proc. of Cas. Act. Soc., 1:24—30, 1914.
[Mow27]
A. H. Mowbray. Experience rating of risks for workmen’s compensation
insurance in the United States. Transaction of the 8th Int. Congr. of
Act., 1:324—335, 1927.
[Neu87]
W. Neuhaus. Early warning. Scand. Act. J., pages 128—156, 1987.
[Nor79]
R. Norberg. The credibility approach to experience rating. Scand. Act.
J., 4:181—221, 1979.
[Nor80]
R. Norberg. Empirical Bayes credibility. Scand. Act. J., 4:177—194, 1980.
[Nor82]
R. Norberg. On optimal parameter estimation in credibility. Insurance:
Mathematics and Economics, 1:73—90, 1982.
[Nor86]
R. Norberg. Hierarchical credibility: Analysis of a random eect linear
model with nested claissiﬁcation. Scand. Act. J., pages 204—222, 1986.
[Nor89]
R. Norberg. Experience rating in group life insurance. Scand. Act. J.,
pages 194—224, 1989.
[Nor04]
R. Norberg. Credibility theory. In J. L. Teugels and B. Sundt, editors,
Encyclopedia of Actuarial Science, Wiley, Chichester, UK, 2004.
[Per32]
F. S. Perryman.
Some notes on credibility.
Proc. of Cas. Act. Soc.,
19:65—84, 1932.
[Rob55]
H. Robbins. An empirical Bayes approach to statistics. In Berkeley Sym-
posium on Mathematical Statistics and Probability, University of Califor-
nia Press, Berkeley, 1955.
[Ryt90]
M. Rytgaard. Estimation in the Pareto distribution. ASTIN Bulletin,
20:201—216, 1990.
[SAS93]
SAS. The GENMOD procedure. Technical Report P-243, SAS/STAT
Software, 1993.
[Sch04]
R. Schnieper.
Robust Bayesian experience rating.
ASTIN Bulletin,
34:125—150, 2004.
[SL03]
G. A. F. Seber and A. J. Lee. Linear Regression Analysis. Wiley, New
York, 2003.
[SS04]
E. S. W. Shiu and F. Y. Sing. Credibility theory and geometry. Journal
of Actuarial Practice, 11:197—216, 2004.
[Sun79a]
B. Sundt. A hierarchical regression credibility model. Scand. Act. J.,
pages 107—114, 1979.

References
327
[Sun79b]
B. Sundt. An insurance model with collective seasonal random factors.
Bulletin of Swiss Ass. of Act., pages 57—64, 1979.
[Sun79c]
B. Sundt. On choice of statistics in credibility estimation. Scand. Act.
J., pages 115—123, 1979.
[Sun80]
B. Sundt. A multi-level hierarchical credibility regression model. Scand.
Act. J., 1:25—32, 1980.
[Sun81]
B. Sundt. Recursive credibility estimation. Scand. Act. J., 1:3—22, 1981.
[Sun82]
B. Sundt. Invariantly recursive credibility estimation. Insurance: Math-
ematics and Economics, 1:185—196, 1982.
[Sun83]
B.
Sundt.
Finite
credibility
formulae
in
evoluationary
models.
Scand. Act. J., pages 106—116, 1983.
[Sun84]
B. Sundt. An Introduction to Non-life Insurance Mathematics. Verlag
Versicherungswirtschaft, Karlsruhe, 1984.
[Sun97]
B. Sundt. Book review: Practical actuarial credibility models by D. R.
Dannenburg, R. Kaas and M. J. Goovaerts. Bulletin of Swiss Ass. of
Act., pages 89—93, 1997.
[Sun98]
B. Sundt. Homogeneous credibility estimators. Bulletin of Swiss Ass. of
Act., pages 193—209, 1998.
[Tay74]
G. C. Taylor. Experience rating with credibility adjustment of the manual
premium. ASTIN Bulletin, 7:323—336, 1974.
[Tay75]
G. C. Taylor. Credibility for time-heterogeneous loss ratios. In P. M.
Kahn, editor, Credibility: Theory and Applications, Academic Press, New
York, 1975.
[Tay79]
G. C. Taylor. Credibility analysis of a general hierarchical model. Scand.
Act. J., pages 1—12, 1979.
[Wei05]
S. Weisberg. Applied Linear Regression. Wiley, New York, 2005.
[Wen73]
H. Wenger. Eine Tariﬁerungsmethode im Feuer-Industriegeschäft. Bul-
letin of Swiss Ass. of Act., 1:95—111, 1973.
[Whi18]
A.W. Whitney. The theory of experience rating. Proc. of Cas. Act. Soc.,
4:274—292, 1918.
[Wi86]
Special issue on credibility theory. In G. W. De Wit, editor, Insurance
Abstracts and Reviews, Elsevier Science Publishers, Amsterdam, 1986.
[Zeh77]
B.
Zehnwirth.
The
mean
credibility
formula
is
a
Bayes
rule.
Scand. Act. J., pages 212—216, 1977.
[Zeh79a]
B. Zehnwirth. Credibility and the Dirichlet process. Scand. Act. J., pages
13—23, 1979.
[Zeh79b]
B. Zehnwirth. A hierarchical model for the estimation of claim rates in
a motor car insurance portfolio. Scand. Act. J., 2/3:75—82, 1979.
[Zeh84]
B. Zehnwirth.
Credibility: Estimation of structural parameters.
In
F. de Vylder M. Goovaerts and J. Haezendonck, editors, Premium Cal-
culation in Insurance, Reidel, 1984.
[Zeh85]
B. Zehnwirth.
Linear ﬁltering and recursive credibility estimation.
ASTIN Bulletin, 15:19—38, 1985.

Index
a posteriori distribution, 17
a priori distribution, 16, see also
structural distribution
a!ne subspace, 284
aggregate claim amount, 1
approximation error, 70
average claim amount, 77
balance property, 91, 113, 158, 184
Bayes estimator, 17, 18
as orthogonal projection, 69
Binomial—Beta, 32
exponential type — conjugate family,
41
Normal—Normal, 35
Pareto—Gamma, 48
Poisson—Gamma, 23, 31
Bayes models, 49
Binomial—Beta, 31, 44
exponential type — conjugate family,
40
Gamma—Gamma, 44
Geometric—Beta, 45
Normal—Normal, 34, 35, 45
Pareto—Gamma, 47
Poisson—Gamma, 21, 22, 29, 30, 43
Bayes premium, 14, 15, see also Bayes
estimator
Bayes risk, 17, 70
Bayesian statistics, 11, 18
claim frequency, 77
claim size, 1
claims ratio, 77, 78
coe!cient of variation, 108
collective, 2, 9, 13, 225, 252, 255
heterogeneous, 10
homogeneous, 10
collective premium, 10, 11, 13
conjugate family, 38, 39
construction of conjugate classes, 46
correct individual premium, 8—10
credibility coe!cient, 58, 84, 85, 108
credibility estimator, 55
as orthogonal projection, 69
autoregressive, 236
Bü-Str with a priori dierences, 112
Bühlmann-Straub, 89
evolutionary regression, 241
for claim amounts, 108
for claim frequencies, 99, 101, 102
for Pareto, 115
general deﬁnition
(inhomogeneous), 62, 65
homogeneous, 62, 65
Gerber and Jones, 234
Hachemeister (general regression),
207
hierarchical model, 148, 155, 157
multidimensional Bü-Str, 181, 183
multidimensional model, 172, 173,
190, 192
recursive calculation, 233
simple Bühlmann, 62
simple linear regression, 213
simple model, 57
standard regression case, 204

330
Index
Credibility in the regression case, 199,
see also credibility models
credibility models
autoregressive, 235
autoregressive with random mean,
247, 249
Bü-Str with a priori dierences, 112
Bühlmann-Straub, 77, 79
evolutionary, 225
evolutionary regression, 238
for claim amounts, 107
for claim frequencies, 98
for Pareto, 115
general regression, 205
general set-up, 64
Gerber and Jones, 234
Hachemeister (general regression),
205
hierarchical, 145
moving average, 249
multidimensional, 170
multidimensional Bü-Str, 178
simple Bühlmann, 60, 61
simple model, 56
standard regression, 202
credibility premium, 23, 36, 41, see also
credibility estimator
credibility theory, 6
credibility weight, 23, 41, 58
data compression, 150, 187, 189, 204,
206
decomposition of sum of squares, 96,
109
decomposition of the individual
premium, 264
global component, 265
individual component, 265
design matrix, 200
distance, 283
distribution of exponential type, 39
empirical Bayes, 10
empirical Bayes estimator, 26
empirical credibility estimator, 95
estimation of structural parameters
Bühlmann-Straub model, 93
for claim amounts, 109
for claim frequencies, 102
for Pareto, 116
hierarchical model, 162
multidimensional Bü-Str, 185
semilinear credibility, 130, 135
evolutionary credibility models, 219,
224
evolutionary credibility regression
model, 238, see also credibility
models
evolutionary regression model
recursive calculation, 238
exact credibility, 41, 49, 58, 232
experience rating, 14
general intuitive principle, 58, 84, 190
geometric credibilty formula, 222
heterogeneous portfolio, see collective
heterogenous collective, see also
collective
hierarchical credibility, see credibility
models
Hilbert space of square integrable
random variables, 67, 283
homogeneous collective, see also
collective
homogeneous credibility estimator, see
credibility estimator
independence property, 75
individual premium, 13, 14
individual risk, 7
inhomogeneous credibility estimator,
see credibility estimator
inner product, 283
inner product of two random variables,
68
innovation, 256
collective and individual movement,
256
iterativity of projections, 70, 285
Kalman Filter, 233, 257
autoregressive with random mean,
248
decomposition of individual premium,
267, 273
evolutionary regression, 240
general form, 263
recursion formula, 231

Index
331
recursive calculation, 254
large claims, 125, 135
linear Markov property, 230, 253, 254,
263
linear space, 284
linear su!cient statistics, 82, 156, 157,
187, 191
linearity of projections, 285
linearity property of credibility
estimators, 74
loss function, 16
multidimensiona evolutionary regression
model, 262
multidimensional credibility, 167, see
also credibility models
multidimensional data structure, 187
multidimensional evolutionary model,
251, see also credibility models
negative binomial distribution, 27
norm of a random variable, 68
normal equations, 71—73
number of claims, 1
observation vector, 61, 64
ordinary least squares, 200
orthogonal increments, 229, 253, 262
orthogonal projection, 68
orthogonality conditions, 69, 71, 73
orthogonality of two random variables,
68, 284
parameter movement, 226
pure risk premium, 9
quadratic loss, 18
of Bayes estimator
Binomial Beta, 32
Normal—Normal, 35
Poisson—Gamma, 23
simple model, 60
of Bayes premium, 20, see also
quadratic loss of Bayes estimator
of collective premium, 20
of credibility estimator
Bühlmann-Straub, 86, 92
general regression, 207
hierarchical model, 159, 160
multidimensional, 175, 176
multidimensional Bü-Str, 185
simple model, 59, 60
standard regression, 204
of semilinear credibility estimator,
128, 133
quadratic loss matrix, 175
recursive calculation, 233, 251
recursive calculation method, 230, see
also Kalman Filter
recursive credibility, 220
updating, 227
regression parameters (covariates)
best linear unbiased estimate
(BLUE), 200
risk, 1
risk function, 16
risk proﬁle, 8, 9
semilinear credibility, 125, 131
semilinear credibility estimator, 126,
128, 132
simple linear regression, 208
choice of intercept, 212
standardized claim frequency, 100
statistical decision theory, 15
structural distribution, see structural
function
structural function, 10
structural parameters, 58, see estima-
tion of structural parameters
subspace, 284
total error, 70
truncation, 126, 130, 131
truncation point, 129
two-urn model, 11
updating, 226, 227
volume measure, 78
weight, see volume measure
weighted least squares, 200

Universitext
Aguilar, M.; Gitler, S.; Prieto, C.: Alge-
braic Topology from a Homotopical View-
point
Aksoy, A.; Khamsi, M. A.:
Methods in
Fixed Point Theory
Alevras, D.; Padberg M. W.: Linear Opti-
mization and Extensions
Andersson, M.: Topics in Complex Analysis
Aoki, M.: State Space Modeling of Time Se-
ries
Arnold, V. I.: Lectures on Partial Diﬀeren-
tial Equations
Audin, M.: Geometry
Aupetit, B.: A Primer on Spectral Theory
Bachem, A.; Kern, W.: Linear Program-
ming Duality
Bachmann, G.; Narici, L.; Beckenstein, E.:
Fourier and Wavelet Analysis
Badescu, L.: Algebraic Surfaces
Balakrishnan,
R.;
Ranganathan,
K.:
A
Textbook of Graph Theory
Balser, W.: Formal Power Series and Linear
Systems of Meromorphic Ordinary Diﬀeren-
tial Equations
Bapat, R.B.: Linear Algebra and Linear
Models
Benedetti, R.; Petronio, C.: Lectures on
Hyperbolic Geometry
Benth, F. E.: Option Theory with Stochas-
tic Analysis
Berberian,
S. K.:
Fundamentals
of
Real
Analysis
Berger, M.: Geometry I, and II
Bliedtner, J.; Hansen, W.: Potential The-
ory
Blowey, J. F.; Coleman, J. P.; Craig, A. W.
(Eds.): Theory and Numerics of Diﬀerential
Equations
Blowey, J.; Craig, A.: Frontiers in Numeri-
cal Analysis. Durham 2004
Blyth, T. S.: Lattices and Ordered Algebraic
Structures
B¨orger, E.; Gr¨adel, E.; Gurevich, Y.: The
Classical Decision Problem
B¨ottcher, A; Silbermann, B.: Introduction
to Large Truncated Toeplitz Matrices
Boltyanski, V.; Martini, H.; Soltan, P. S.:
Excursions into Combinatorial Geometry
Boltyanskii, V. G.; Efremovich, V. A.: Intu-
itive Combinatorial Topology
Bonnans, J. F.; Gilbert, J. C.; Lemar´echal,
C.; Sagastiz´abal, C. A.: Numerical Opti-
mization
Booss, B.; Bleecker, D. D.: Topology and
Analysis
Borkar, V. S.: Probability Theory
Brunt B. van: The Calculus of Variations
B¨uhlmann, H.; Gisler, A.: A Course in
Credibility Theory and its Applications
Carleson, L.; Gamelin, T. W.: Complex
Dynamics
Cecil, T. E.: Lie Sphere Geometry: With
Applications of Submanifolds
Chae, S. B.: Lebesgue Integration
Chandrasekharan,
K.:
Classical
Fourier
Transform
Charlap, L. S.: Bieberbach Groups and Flat
Manifolds
Chern, S.: Complex Manifolds without Po-
tential Theory
Chorin, A. J.; Marsden, J. E.: Mathemati-
cal Introduction to Fluid Mechanics
Cohn, H.: A Classical Invitation to Alge-
braic Numbers and Class Fields
Curtis, M. L.: Abstract Linear Algebra
Curtis, M. L.: Matrix Groups
Cyganowski, S.; Kloeden, P.; Ombach, J.:
From Elementary Probability to Stochastic
Diﬀerential Equations with MAPLE
Dalen, D. van: Logic and Structure
Das, A.: The Special Theory of Relativity:
A Mathematical Exposition
Debarre, O.: Higher-Dimensional Algebraic
Geometry
Deitmar, A.: A First Course in Harmonic
Analysis
Demazure, M.: Bifurcations and Catastro-
phes

Devlin, K. J.: Fundamentals of Contempo-
rary Set Theory
DiBenedetto,
E.:
Degenerate
Parabolic
Equations
Diener, F.; Diener, M.(Eds.): Nonstandard
Analysis in Practice
Dimca, A.: Sheaves in Topology
Dimca, A.: Singularities and Topology of
Hypersurfaces
DoCarmo, M. P.: Diﬀerential Forms and
Applications
Duistermaat,
J. J.;
Kolk,
J. A. C.:
Lie
Groups
Edwards, R. E.: A Formal Background to
Higher Mathematics Ia, and Ib
Edwards, R. E.: A Formal Background to
Higher Mathematics IIa, and IIb
Emery, M.: Stochastic Calculus in Mani-
folds
Emmanouil, I.: Idempotent Matrices over
Complex Group Algebras
Endler, O.: Valuation Theory
Erez, B.: Galois Modules in Arithmetic
Everest, G.; Ward, T.: Heights of Polyno-
mials and Entropy in Algebraic Dynamics
Farenick, D. R.: Algebras of Linear Trans-
formations
Foulds, L. R.: Graph Theory Applications
Franke, J.; H¨ardle, W.; Hafner, C. M.: Sta-
tistics of Financial Markets: An Introduc-
tion
Frauenthal, J. C.: Mathematical Modeling
in Epidemiology
Freitag, E.; Busam, R.: Complex Analysis
Friedman, R.: Algebraic Surfaces and Holo-
morphic Vector Bundles
Fuks,
D. B.;
Rokhlin,
V. A.:
Beginner’s
Course in Topology
Fuhrmann, P. A.: A Polynomial Approach
to Linear Algebra
Gallot, S.; Hulin, D.; Lafontaine, J.: Rie-
mannian Geometry
Gardiner, C. F.: A First Course in Group
Theory
G˚arding, L.; Tambour, T.:
Algebra for
Computer Science
Godbillon, C.: Dynamical Systems on Sur-
faces
Godement, R.: Analysis I, and II
Godement, R.: Analysis II
Goldblatt, R.: Orthogonality and Spacetime
Geometry
Gouvˆea, F. Q.: p-Adic Numbers
Gross, M. et al.: Calabi-Yau Manifolds and
Related Geometries
Gustafson, K. E.; Rao, D. K. M.: Numerical
Range. The Field of Values of Linear Oper-
ators and Matrices
Gustafson, S. J.; Sigal, I. M.: Mathematical
Concepts of Quantum Mechanics
Hahn, A. J.: Quadratic Algebras, Cliﬀord
Algebras, and Arithmetic Witt Groups
H´ajek, P.; Havr´anek, T.: Mechanizing Hy-
pothesis Formation
Heinonen, J.: Lectures on Analysis on Met-
ric Spaces
Hlawka, E.; Schoißengeier, J.; Taschner,
R.: Geometric and Analytic Number The-
ory
Holmgren, R. A.: A First Course in Discrete
Dynamical Systems
Howe, R., Tan, E. Ch.: Non-Abelian Har-
monic Analysis
Howes, N. R.: Modern Analysis and Topol-
ogy
Hsieh, P.-F.; Sibuya, Y. (Eds.): Basic The-
ory of Ordinary Diﬀerential Equations
Humi, M., Miller, W.: Second Course in Or-
dinary Diﬀerential Equations for Scientists
and Engineers
Hurwitz,
A.;
Kritikos,
N.:
Lectures
on
Number Theory
Huybrechts, D.: Complex Geometry: An In-
troduction
Isaev, A.: Introduction to Mathematical
Methods in Bioinformatics
Istas, J.: Mathematical Modeling for the
Life Sciences
Iversen, B.: Cohomology of Sheaves
Jacod, J.; Protter, P.: Probability Essen-
tials
Jennings, G. A.: Modern Geometry with
Applications
Jones, A.; Morris, S. A.; Pearson, K. R.:
Abstract Algebra and Famous Inpossibili-
ties

Jost, J.: Compact Riemann Surfaces
Jost, J.: Dynamical Systems. Examples of
Complex Behaviour
Jost, J.: Postmodern Analysis
Jost, J.: Riemannian Geometry and Geo-
metric Analysis
Kac, V.; Cheung, P.: Quantum Calculus
Kannan,
R.;
Krueger,
C. K.:
Advanced
Analysis on the Real Line
Kelly,
P.;
Matthews,
G.:
The
Non-
Euclidean Hyperbolic Plane
Kempf, G.: Complex Abelian Varieties and
Theta Functions
Kitchens, B. P.: Symbolic Dynamics
Kloeden, P.; Ombach, J.; Cyganowski, S.:
From Elementary Probability to Stochastic
Diﬀerential Equations with MAPLE
Kloeden, P. E.; Platen; E.; Schurz, H.: Nu-
merical Solution of SDE Through Computer
Experiments
Kostrikin, A. I.: Introduction to Algebra
Krasnoselskii,
M. A.;
Pokrovskii,
A. V.:
Systems with Hysteresis
Kurzweil, H.; Stellmacher, B.: The Theory
of Finite Groups. An Introduction
Lang,
S.:
Introduction
to
Diﬀerentiable
Manifolds
Luecking,
D. H.,
Rubel,
L. A.:
Complex
Analysis. A Functional Analysis Approach
Ma, Zhi-Ming; Roeckner, M.: Introduction
to the Theory of (non-symmetric) Dirichlet
Forms
Mac Lane, S.; Moerdijk, I.: Sheaves in
Geometry and Logic
Marcus, D. A.: Number Fields
Martinez, A.: An Introduction to Semiclas-
sical and Microlocal Analysis
Matouˇsek, J.: Using the Borsuk-Ulam The-
orem
Matsuki, K.: Introduction to the Mori Pro-
gram
Mazzola, G.; Milmeister G.; Weissman J.:
Comprehensive Mathematics for Computer
Scientists 1
Mazzola, G.; Milmeister G.; Weissman J.:
Comprehensive Mathematics for Computer
Scientists 2
Mc Carthy, P. J.: Introduction to Arith-
metical Functions
McCrimmon, K.: A Taste of Jordan Alge-
bras
Meyer, R. M.: Essential Mathematics for
Applied Field
Meyer-Nieberg, P.: Banach Lattices
Mikosch, T.: Non-Life Insurance Mathe-
matics
Mines, R.; Richman, F.; Ruitenburg, W.: A
Course in Constructive Algebra
Moise,
E. E.:
Introductory
Problem
Courses in Analysis and Topology
Montesinos-Amilibia, J. M.: Classical Tes-
sellations and Three Manifolds
Morris, P.: Introduction to Game Theory
Nikulin, V. V.; Shafarevich, I. R.: Geome-
tries and Groups
Oden, J. J.; Reddy, J. N.: Variational Meth-
ods in Theoretical Mechanics
Øksendal, B.: Stochastic Diﬀerential Equa-
tions
Øksendal, B.; Sulem, A.: Applied Stochas-
tic Control of Jump Diﬀusions
Poizat, B.: A Course in Model Theory
Polster, B.: A Geometrical Picture Book
Porter, J. R.; Woods, R. G.: Extensions and
Absolutes of HausdorﬀSpaces
Radjavi, H.; Rosenthal, P.: Simultaneous
Triangularization
Ramsay, A.; Richtmeyer, R. D.: Introduc-
tion to Hyperbolic Geometry
Rees, E. G.: Notes on Geometry
Reisel, R. B.: Elementary Theory of Metric
Spaces
Rey, W. J. J.: Introduction to Robust and
Quasi-Robust Statistical Methods
Ribenboim, P.: Classical Theory of Alge-
braic Numbers
Rickart, C. E.: Natural Function Algebras
Roger G.: Analysis II
Rotman, J. J.: Galois Theory
Rubel, L. A.: Entire and Meromorphic Func-
tions
Ruiz-Tolosa, J. R.; Castillo E.: From Vec-
tors to Tensors
Runde, V.: A Taste of Topology
Rybakowski, K. P.: The Homotopy Index
and Partial Diﬀerential Equations

Sagan, H.: Space-Filling Curves
Samelson, H.: Notes on Lie Algebras
Schiﬀ, J. L.: Normal Families
Sengupta, J. K.: Optimal Decisions under
Uncertainty
S´eroul, R.: Programming for Mathemati-
cians
Seydel, R.: Tools for Computational Fi-
nance
Shafarevich, I. R.: Discourses on Algebra
Shapiro, J. H.: Composition Operators and
Classical Function Theory
Simonnet, M.: Measures and Probabilities
Smith, K. E.; Kahanp¨a¨a, L.; Kek¨al¨ainen,
P.; Traves, W.: An Invitation to Algebraic
Geometry
Smith, K. T.: Power Series from a Compu-
tational Point of View
Smory´nski, C.: Logical Number Theory I.
An Introduction
Stichtenoth, H.: Algebraic Function Fields
and Codes
Stillwell, J.: Geometry of Surfaces
Stroock, D. W.: An Introduction to the The-
ory of Large Deviations
Sunder, V. S.: An Invitation to von Neu-
mann Algebras
Tamme, G.: Introduction to ´Etale Coho-
mology
Tondeur,
P.:
Foliations
on
Riemannian
Manifolds
Toth, G.: Finite M¨obius Groups, Minimal
Immersions of Spheres, and Moduli
Verhulst, F.: Nonlinear Diﬀerential Equa-
tions and Dynamical Systems
Wong, M. W.: Weyl Transforms
Xamb´o-Descamps,
S.:
Block
Error-Cor-
recting Codes
Zaanen, A.C.: Continuity, Integration and
Fourier Theory
Zhang, F.: Matrix Theory
Zong, C.: Sphere Packings
Zong, C.: Strange Phenomena in Convex
and Discrete Geometry
Zorich, V. A.: Mathematical Analysis I
Zorich, V. A.: Mathematical Analysis II

